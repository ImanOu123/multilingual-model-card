{'en': 'Tohoku-AIP-NTT at WMT 2020 News Translation Task', 'ar': 'Tohoku-AIP-NTT في مهمة ترجمة الأخبار WMT 2020', 'fr': 'Tohoku-AIP-NTT au WMT 2020 News Translation Task', 'pt': 'Tohoku-AIP-NTT no WMT 2020 Tarefa de Tradução de Notícias', 'es': 'Tohoku-AIP-NTT en la tarea de traducción de noticias del WMT 2020', 'ja': 'WMT 2020ニュース翻訳タスクでTOHOKU - AIP - NTT', 'ru': 'Tohoku-AIP-NTT на WMT 2020 Задача по переводу новостей', 'zh': 'šłúŚĆó-AIP-NTTŚú®WMT 2020śĖįťóĽŤĮĎ', 'hi': 'Tohoku-AIP-NTT पर WMT 2020 समाचार अनुवाद कार्य', 'ga': 'Tohoku-AIP-NTT ag Tasc Aistriúcháin Nuachta WMT 2020', 'hu': 'Tohoku-AIP-NTT a WMT 2020 Hírek Fordítási feladata', 'el': 'Tohoku-AIP-NTT στο WMT 2020 Νέα Μεταφράσιμο Εργασία', 'ka': 'Comment', 'it': 'Tohoku-AIP-NTT al WMT 2020 News Translation Task', 'kk': 'WMT 2020 жаңалық аудару тапсырмасында Tohoku-AIP-NTT', 'ml': 'WMT 2020 വിവരങ്ങളുടെ ടോഹോകൂ- AIP- NTT', 'mk': 'Tohoku-AIP-NTT на задачата за преведување на вестите на WMT 2020', 'mt': 'Tohoku-AIP-NTT fil-Ħidma tat-Traduzzjoni tal-Aħbarijiet tad-WMT 2020', 'ms': 'Tohoku-AIP-NTT pada Tugas Terjemahan Berita WMT 2020', 'lt': 'Tohoku-AIP-NTT WMT 2020 naujienų vertimo užduotyje', 'pl': 'Tohoku-AIP-NTT na WMT 2020 Aktualności Tłumaczenie', 'ro': 'Tohoku-AIP-NTT la WMT 2020 News Translation Task', 'mn': 'WMT 2020 News Translation Task дээр Tohoku-AIP-NTT', 'sr': 'Tohoku-AIP-NTT na WMT 2020 novinskom prevodnom zadatku', 'si': 'ටොහොකු-AIP-NTT WMT-2020වාර්තාව අවවාද කරන වැඩේ', 'so': 'Tohoku-AIP-NTT at WMT 2020 News Translation Task', 'no': 'Tohoku-AIP-NTT på WMT 2020 News Translation Task', 'sv': 'Tohoku-AIP-NTT på WMT 2020 Nyheter Översättningsuppgift', 'ta': 'WMT 2020 செய்தி மொழிபெயர்ப்பு பணியில் Tohoku- AIP- NTT', 'ur': 'ٹوهوکو-AIP-NTT WMT 2020 نیویس ترجمہ ٹاکس میں', 'uz': 'WMT 2020 News tarjima vazifasi', 'vi': 'Tohoku-AIP-NTT tại WRT 2020 News Translation Task', 'bg': 'Тохоку-АИП-НТТ на задача за превод на новини', 'nl': 'Tohoku-AIP-NTT op WMT 2020 Nieuws Vertaling Taak', 'da': 'Tohoku-AIP-NTT på WMT 2020 Nyhedsoversættelsesopgave', 'hr': 'Tohoku-AIP-NTT na zadatku za prevod vijesti WMT 2020', 'de': 'Tohoku-AIP-NTT bei WMT 2020 News Übersetzungsaufgabe', 'ko': 'WMT 2020 뉴스 번역 임무 중 동북 AIP NTT', 'id': 'Tohoku-AIP-NTT di WMT 2020 News Translation Task', 'sw': 'Tohoku-AIP-NTT kwenye kazi ya Tafsiri ya Habari 2020 WMT', 'fa': 'توهوکو-AIP-NTT در ترجمه خبری WMT 2020', 'tr': 'Töhoku-AIP-NTT WMT 2020 Haýsy Terjime Görevi', 'af': 'Tohoku-AIP-NTT by WMT 2020 Nuusvertaling taak', 'hy': 'Տոհոկու-ԱԲԻՊ-ՆԹ-ը Համաշխարհի 2020 նորությունների թարգմանման գործում', 'sq': 'Tohoku-AIP-NTT në detyrën e përkthimit të lajmeve të WMT 2020', 'am': 'Tohoku-AIP-NTT at WMT 2020 News Translation Task', 'bs': 'Tohoku-AIP-NTT na WMT 2020 novinskom prevodnom zadatku', 'bn': 'Tohoku-AIP-NTT at WMT 2020 News Translation Task', 'cs': 'Tohoku-AIP-NTT na WMT 2020 Novinky Překladatelská úloha', 'az': 'WMT 2020 Haqq T톛rc칲m톛 G칬z톛li Tohoku-AIP-NTT', 'fi': 'Tohoku-AIP-NTT WMT 2020 -uutisten kääntämistehtävässä', 'et': 'Tohoku-AIP-NTT WMT 2020 Uudiste tõlke ülesanne', 'ca': 'Tohoku-AIP-NTT at WMT 2020 News Translation Task', 'ha': 'Tohoku-AIP-NTT at WMT 2020 News Translate Tasks', 'jv': 'Tohoku-AIP-ENTT nang WHAT 2020 Hawigan Terjamahan', 'bo': 'Tohoku-AIP-NTT at WMT 2020 News Translation Task', 'sk': 'Tohoku-AIP-NTT na WMT 2020 Prevajalska naloga novic', 'he': 'Tohoku-AIP-NTT במשימת התרגום חדשות WMT 2020'}
{'en': 'In this paper, we describe the submission of Tohoku-AIP-NTT to the WMT’20 news translation task. We participated in this task in two language pairs and four language directions : English   German and English   Japanese. Our system consists of techniques such as back-translation and fine-tuning, which are already widely adopted in translation tasks. We attempted to develop new methods for both synthetic data filtering and reranking. However, the methods turned out to be ineffective, and they provided us with no significant improvement over the baseline. We analyze these negative results to provide insights for future studies.', 'ar': "في هذه الورقة ، نصف تقديم Tohoku-AIP-NTT لمهمة ترجمة الأخبار WMT'20. شاركنا في هذه المهمة في لغتين وأربع اتجاهات لغوية: الإنجليزية - الألمانية والإنجليزية - اليابانية. يتكون نظامنا من تقنيات مثل الترجمة المرتدة والضبط الدقيق ، والتي تم اعتمادها بالفعل على نطاق واسع في مهام الترجمة. حاولنا تطوير طرق جديدة لكل من تصفية البيانات التركيبية وإعادة الترتيب. ومع ذلك ، فقد تبين أن الأساليب غير فعالة ، ولم توفر لنا أي تحسن ملحوظ عن خط الأساس. نقوم بتحليل هذه النتائج السلبية لتقديم رؤى للدراسات المستقبلية.", 'es': "En este artículo, describimos la sumisión de Tohoku-AIP-NTT a la tarea de traducción de noticias del WMT'20. Participamos en esta tarea en dos pares de idiomas y cuatro direcciones de idiomas: inglés — alemán e inglés — japonés. Nuestro sistema consiste en técnicas como la retrotraducción y el ajuste fino, que ya se han adoptado ampliamente en las tareas de traducción. Intentamos desarrollar nuevos métodos tanto para el filtrado de datos sintéticos como para la reclasificación. Sin embargo, los métodos resultaron ineficaces y no nos proporcionaron ninguna mejora significativa con respecto a la línea de base. Analizamos estos resultados negativos para proporcionar información para futuros estudios.", 'pt': "Neste artigo, descrevemos a submissão do Tohoku-AIP-NTT à tarefa de tradução de notícias do WMT'20. Participamos desta tarefa em dois pares de idiomas e em quatro direções linguísticas: inglês – alemão e inglês – japonês. Nosso sistema é composto por técnicas como back-translation e fine-tuning, que já são amplamente adotadas em tarefas de tradução. Tentamos desenvolver novos métodos para filtragem e reclassificação de dados sintéticos. No entanto, os métodos se mostraram ineficazes e não nos forneceram nenhuma melhora significativa em relação à linha de base. Analisamos esses resultados negativos para fornecer insights para estudos futuros.", 'fr': "Dans cet article, nous décrivons la soumission de Tohoku-AIP-NTT à la tâche de traduction des actualités du WMT'20. Nous avons participé à cette tâche dans deux paires de langues et quatre directions linguistiques\xa0: anglais — allemand et anglais-japonais. Notre système comprend des techniques telles que la rétro-traduction et le réglage fin, qui sont déjà largement adoptées dans les tâches de traduction. Nous avons essayé de développer de nouvelles méthodes pour le filtrage synthétique des données et le reclassement. Cependant, les méthodes se sont révélées inefficaces et ne nous ont apporté aucune amélioration significative par rapport à la base de référence. Nous analysons ces résultats négatifs afin de fournir des informations utiles pour de futures études.", 'ja': "本稿では、WMT '20ニュース翻訳タスクへの東北IP - NTTの提出について述べる。このタスクには、英語–ドイツ語と英語–日本語の2つの言語ペアと4つの言語の方向性で参加しました。当社のシステムは、すでに翻訳タスクで広く採用されているバック翻訳や微調整などのテクニックで構成されています。合成データのフィルタリングと再ランク付けの両方の新しい方法を開発しようとしました。しかし、これらの方法は効果がないことが判明し、ベースラインよりも有意な改善は見られませんでした。私たちはこれらの否定的な結果を分析し、将来の研究のための洞察を提供します。", 'zh': '本文中,述东北AIP-NTT向WMT20新闻译者。 二语与四语,英语 - 德语与英语 - 日语。 吾统由回译微,已博于译任。 我们试开发合成数据过漉和重新排名的新法。 然其效无效,无以资比基线有大改也。 论此负面终,为未来之论也。', 'hi': "इस पेपर में, हम WMT'20 समाचार अनुवाद कार्य के लिए Tohoku-AIP-NTT के प्रस्तुतीकरण का वर्णन करते हैं। हमने इस कार्य में दो भाषा जोड़े और चार भाषा दिशाओं में भाग लिया: अंग्रेजी - जर्मन और अंग्रेजी - जापानी। हमारे सिस्टम में बैक-ट्रांसलेशन और फाइन-ट्यूनिंग जैसी तकनीकें शामिल हैं, जो पहले से ही अनुवाद कार्यों में व्यापक रूप से अपनाई जाती हैं। हमने सिंथेटिक डेटा फ़िल्टरिंग और रीरैंकिंग दोनों के लिए नए तरीकों को विकसित करने का प्रयास किया। हालांकि, विधियां अप्रभावी हो गईं, और उन्होंने हमें बेसलाइन पर कोई महत्वपूर्ण सुधार प्रदान नहीं किया। हम भविष्य के अध्ययनों के लिए अंतर्दृष्टि प्रदान करने के लिए इन नकारात्मक परिणामों का विश्लेषण करते हैं।", 'ru': "В этой статье мы описываем представление Tohoku-AIP-NTT для задачи перевода новостей WMT'20. Мы участвовали в этом задании в двух языковых парах и четырех языковых направлениях: английский – немецкий и английский – японский. Наша система состоит из таких методов, как обратный перевод и тонкая настройка, которые уже широко используются в задачах перевода. Мы попытались разработать новые методы как для фильтрации синтетических данных, так и для рерайтинга. Однако методы оказались неэффективными, и они не обеспечили нам существенного улучшения по сравнению с базовым уровнем. Мы анализируем эти отрицательные результаты, чтобы предоставить информацию для будущих исследований.", 'ga': "Sa pháipéar seo, déanaimid cur síos ar chur isteach Tohoku-AIP-NTT do thasc aistriúcháin nuachta WMT'20. Ghlacamar páirt sa tasc seo in dhá phéire teanga agus ceithre threo teanga: Béarla – Gearmáinis agus Béarla – Seapáinis. Tá ár gcóras comhdhéanta de theicnící mar chúl-aistriúchán agus mionchoigeartú, a bhfuil glactha go forleathan leo cheana féin i dtascanna aistriúcháin. Rinneamar iarracht modhanna nua a fhorbairt chun sonraí sintéiseacha a scagadh agus a athrangú. Mar sin féin, ní raibh na modhanna éifeachtacha, agus níor thug siad aon fheabhsú suntasach dúinn ar an mbunlíne. Déanaimid anailís ar na torthaí diúltacha seo chun léargais a sholáthar do staidéir amach anseo.", 'el': "Σε αυτή την εργασία, περιγράφουμε την υποβολή του Tohoku-AIP-NTT στο έργο μετάφρασης ειδήσεων WMT'20. Συμμετείχαμε σε αυτό το έργο σε δύο γλωσσικά ζεύγη και τέσσερις γλωσσικές κατευθύνσεις: Αγγλικά-Γερμανικά και Αγγλικά-Ιαπωνικά. Το σύστημά μας αποτελείται από τεχνικές όπως η μεταγραφή και ο συντονισμός, οι οποίες έχουν ήδη υιοθετηθεί ευρέως σε μεταφραστικές εργασίες. Προσπαθήσαμε να αναπτύξουμε νέες μεθόδους τόσο για το συνθετικό φιλτράρισμα δεδομένων όσο και για την επανακατάταξη δεδομένων. Ωστόσο, οι μέθοδοι αποδείχθηκαν αναποτελεσματικές και δεν μας παρείχαν σημαντική βελτίωση έναντι της βάσης. Αναλύουμε αυτά τα αρνητικά αποτελέσματα για να παράσχουμε πληροφορίες για μελλοντικές μελέτες.", 'hu': "Ebben a tanulmányban bemutatjuk a Tohoku-AIP-NTT beküldését a WMT'20 hírfordítási feladatra. Ebben a feladatban két nyelvpárban és négy nyelvirányban vettünk részt: angol - német és angol - japán. Rendszerünk olyan technikákból áll, mint a háttérfordítás és finomhangolás, amelyeket már széles körben alkalmaznak fordítási feladatokban. Megpróbáltunk új módszereket fejleszteni mind a szintetikus adatszűrésre, mind pedig az újratöltésre. A módszerek azonban hatástalannak bizonyultak, és nem biztosítottak jelentős javulást az alaphelyzethez képest. Elemezzük ezeket a negatív eredményeket, hogy betekintést nyújtsunk a jövőbeli tanulmányokhoz.", 'ka': "ამ წიგნიში ჩვენ აღწერეთ Tohoku-AIP-NTT-ის გადატანა WMT'20 წიგნის გაგრძელება. ჩვენ ამ პარამეტრებში ორი ენაზე და ოთხი ენაზე დავწყებდით: ანგლისური - გერმანური და ინგლისური - იაპონური. ჩვენი სისტემა იყოს ტექნოგიები, როგორც დაბრუნება და კონფიგურაცია, რომლებიც უკვე უფრო გავაკეთებულია სარგუნებო საქმედებში. ჩვენ მოცდილობდით ახალი მეტოვების განვითარება სინტეტიკური მონაცემების ფილტრირებისა და განვითარებისთვის. მაგრამ მეტები გამოიყენებულია, რომ არაფექტიურია, და ისინი ჩვენ არაფექტიური წინასწორებას არაფექტიურია. ჩვენ გავაანალიზებთ ეს უარყოფილი შედეგების შესახებ მომავალეთ სწავლებისთვის.", 'kk': "Бұл қағазда, WMT' 20 жаңалық аудармалардың тапсырмасына Tohoku-AIP-NTT жіберуді таңдадық. Біз осы тапсырмаға екі тіл екі және төрт тіл бағыттарына қатынасыз: ағылшын - неміс және ағылшын - жапон. Біздің жүйеміз аудармалардың тапсырмаларында жалғыз аудармалы және жақсы баптаулар секілді техникалардан тұрады. Біз синтетикалық деректерді сүзгілеу және қайта бағыттау үшін жаңа әдістерді жасау әрекеттерін жасадық. Бірақ бұл әдістер әсер етпейді. Олар бізге негізгі жолда маңызды жақсарту жоқ берді. Біз бұл негативті нәтижелерді келесі зерттеулер үшін анықтау үшін анализирақ.", 'it': "In questo articolo, descriviamo la sottomissione di Tohoku-AIP-NTT al compito di traduzione delle notizie WMT'20. Abbiamo partecipato a questo compito in due coppie linguistiche e quattro direzioni linguistiche: inglese - tedesco e inglese - giapponese. Il nostro sistema è costituito da tecniche come back-translation e fine-tuning, che sono già ampiamente adottate nei compiti di traduzione. Abbiamo cercato di sviluppare nuovi metodi sia per il filtraggio dei dati sintetici che per il riallineamento. Tuttavia, i metodi si sono rivelati inefficaci e non ci hanno fornito alcun miglioramento significativo rispetto alla base di riferimento. Analizziamo questi risultati negativi per fornire approfondimenti per studi futuri.", 'lt': "Šiame dokumente apibūdiname Tohoku-AIP-NTT pateikimą WMT'20 žinių vertimo uždaviniui. Šioje užduotyje dalyvavome dviejose kalbų porose ir keturiose kalbų kryptimis: anglų - vokiečių ir anglų - japonų. Mūsų sistemą sudaro tokie metodai kaip vertimas atgal ir patobulinimas, kurie jau plačiai taikomi vertimo darbuose. Mes bandėme sukurti naujus metodus sintetinių duomenų filtravimui ir pakartotiniam ryšiui. Tačiau pasirodė, kad metodai neveiksmingi, ir jie mums nepateikė jokio reikšmingo pagerėjimo lyginant su pradiniu lygiu. Analizuojame šiuos neigiamus rezultatus, kad ateityje būtų galima sužinoti apie būsimus tyrimus.", 'mk': "Во овој весник го опишуваме предавањето на Тохоку-AIP-NTT на задачата за превод на вести на WMT'20. Ние учествувавме во оваа задача на два пара јазици и четири насоки на јазик: англиски - германски и англиски - јапонски. Нашиот систем се состои од техники како што се враќање на преводот и финетизирање, кои веќе се широко усвоени во преводните задачи. Се обидовме да развиеме нови методи за филтрирање и преврзување на синтетичките податоци. Сепак, методите се покажаа неефикасни и не обезбедија значително подобрување во однос на основата. Ние ги анализираме овие негативни резултати за да обезбедиме информации за идните студии.", 'ms': "Dalam kertas ini, kami menggambarkan penghantaran Tohoku-AIP-NTT kepada tugas terjemahan berita WMT'20. Kami berpartisipasi dalam tugas ini dalam dua pasangan bahasa dan empat arah bahasa: Inggeris - Jerman dan Inggeris - Jepun. Sistem kita terdiri dari teknik seperti terjemahan-balik dan penyesuaian-baik, yang telah diterima secara luas dalam tugas terjemahan. Kami cuba untuk mengembangkan kaedah baru untuk penapisan data sintetik dan penyelesaian semula. However, the methods turned out to be ineffective, and they provided us with no significant improvement over the baseline.  Kami menganalisis hasil negatif ini untuk memberikan pandangan untuk kajian masa depan.", 'ml': "ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ടോഹുകൂ-എപ്പ്-എഞ്ച്ടിയുടെ സന്ദേശം വിവരിച്ചുകൊടുക്കുന്നു. WMT'20 വാര്\u200dത്ത വിവരങ്ങള്\u200d പര ഞങ്ങള്\u200d ഈ ജോലിയില്\u200d പങ്കുചേര്\u200dത്തിരുന്നു. രണ്ടു ഭാഷ ഇണകളും നാലു ഭാഷ മാര്\u200dഗത്തില്\u200d: ഇംഗ്ലീഷ്- ജര്\u200dമ്മന്\u200d ഇ ഞങ്ങളുടെ സിസ്റ്റത്തില്\u200d പിന്നിലെ പരിഭാഷവും നല്ല പരിഭാഷവും പോലെയുള്ള സാങ്കേതികവിദ്യകങ്ങളുണ്ട്. അതിന്റെ പരി സിന്റെറ്റിക്ക് ഡേറ്റാ ഫില്\u200dറ്റര്\u200d ചെയ്യുന്നതിനും വീണ്ടും പുതിയ രീതികള്\u200d ഉണ്ടാക്കാനും ഞങ്ങള്\u200d ശ്രമി എന്നാലും ഈ രീതികള്\u200d പ്രവര്\u200dത്തനരഹിതമായിരുന്നു. അവര്\u200d ബെസ്റ്റലൈനില്\u200d വലിയ മെച്ചപ്പെടുത്തിയിരുന്നില്ല. ഭാവിയുടെ പഠനങ്ങള്\u200dക്ക് ഉള്ള കാഴ്ചകള്\u200d നല്\u200dകുന്നതിനായി നമ്മള്\u200d ഈ നെഗറേറ്റിവ് ഫലങ്ങള്\u200d അന്വേഷിക്", 'mt': "F'dan id-dokument, niddeskrivu s-sottomissjoni ta' Tohoku-AIP-NTT lill-kompitu tat-traduzzjoni tal-aħbarijiet tad-WMT'20. Parteċipajna f’dan il-kompitu f’żewġ pari lingwistiċi u erba’ direzzjonijiet lingwistiċi: Ingliż - Ġermaniż u Ingliż - Ġappuniż. Is-sistema tagħna tikkonsisti f’tekniki bħat-traduzzjoni lura u l-irfinar, li diġà huma adottati b’mod wiesa’ fil-kompiti tat-traduzzjoni. Ippruvajna niżviluppaw metodi ġodda kemm għall-filtrazzjoni tad-dejta sintetika kif ukoll għall-irankjar mill-ġdid. However, the methods turned out to be ineffective, and they provided us with no significant improvement over the baseline.  We analyze these negative results to provide insights for future studies.", 'no': "I denne papiret beskriver vi tilføring av Tohoku-AIP-NTT til WMT'20 nyhetskomsettingsoppgåva. Vi deltok i denne oppgåva i to språkopar og fire språkkretningar: engelsk - tysk og engelsk - japansk. Sistemet vårt inneheld teknikk som tilbakeomsetjing og finnstilling, som allereie er godtatt i omsetjingsprogrammer. Vi prøvde å utvikla nye metodar for både syntetiske datafiltrering og gjenoppretting. Metodane viste imidlertid til å vera utilgjende, og dei gjeve oss ingen betydelig forbedring over grunnlinja. Vi analyserer desse negative resultatene for å gje innsikt for framtidige studiar.", 'pl': "W niniejszym artykule opisujemy zgłoszenie Tohoku-AIP-NTT do zadania tłumaczenia wiadomości WMT'20. Uczestniczyliśmy w tym zadaniu w dwóch parach językowych i czterech kierunkach językowych: angielsko-niemiecki i angielsko-japoński. Nasz system składa się z technik takich jak tłumaczenie wsteczne i dostrajanie, które są już szeroko stosowane w zadaniach tłumaczeniowych. Próbowaliśmy opracować nowe metody zarówno syntetycznego filtrowania danych, jak i ponownego rankingu. Metody te okazały się jednak nieskuteczne i nie dostarczyły nam znaczącej poprawy nad bazą. Analizujemy te negatywne wyniki, aby dostarczyć informacji do przyszłych badań.", 'ro': "În această lucrare, descriem supunerea Tohoku-AIP-NTT la sarcina de traducere a știrilor WMT'20. Am participat la această sarcină în două perechi de limbi și patru direcții lingvistice: engleză - germană și engleză - japoneză. Sistemul nostru constă în tehnici precum traducerea înapoi și reglarea fină, care sunt deja adoptate pe scară largă în sarcinile de traducere. Am încercat să dezvoltăm noi metode atât pentru filtrarea datelor sintetice, cât și pentru re-ranking. Cu toate acestea, metodele s-au dovedit a fi ineficiente și nu ne-au oferit nicio îmbunătățire semnificativă față de bază. Analizăm aceste rezultate negative pentru a oferi perspective pentru studiile viitoare.", 'mn': "Энэ цаасан дээр бид Tohoku-AIP-NTT-г WMT'20 мэдээний хөрөнгө оруулах үйлдлийг тайлбарлаж байна. Бид энэ үйл ажилд хоёр хэл хоёр, дөрвөн хэл замаар оролцсон: Англи - Герман, Англи - Япон. Бидний систем дахин хөрөнгө оруулалт болон сайхан хөрөнгө оруулалт хийсэн технологиуд юм. Бид синтетик өгөгдлийн шинжилгээ болон дахин сэргээх шинэ арга зам бүтээхийг хичээсэн. Гэвч энэ арга нь үр дүнгүй болсон. Тэд бидэнд суурь шугам дээр ямар ч чухал сайжруулалт гаргахгүй. Бид эдгээр сөрөг үр дүнг ирээдүйн судалгаанд ойлголт өгөхийн тулд шинжилгээ хийдэг.", 'sr': "U ovom papiru opisujemo predavanje Tohoku-AIP-NTT na zadatak WMT'20 novinskog prevoda. Mi smo sudjelovali u ovom zadatku u dva jezička parova i četiri jezička uputa: Engleski - Njemački i Engleski - Japanci. Naš sistem se sastoji od tehnika poput prijevoza i fino podešavanja, koje su veæ široko usvojene u prijevoznim zadacima. Pokušali smo da razvijemo nove metode za filtreranje i preokretanje sintetičkih podataka. Međutim, metode su se ispostavile da su neiffektivne, a oni su nam pružili nikakvo značajno poboljšanje u početnoj liniji. Analiziramo ove negativne rezultate kako bi pružili uvid za buduće studije.", 'si': "මේ පත්තරේ අපි තොහොකු-AIP-NTT ගේ පිළිගන්න විස්තර කරනවා WMT'20 වාර්තාවක් අවවාද කරන වැඩට. අපි මේ වැඩේ භාෂාව දෙකක් සහ භාෂාව හතර ප්\u200dරවේශ කරනවා: ඉංග්\u200dරීසි - ජර්මානිස් සහ ඉංග්\u200dරීසිය -  අපේ පද්ධතියේ පිටිපස්සේ පරිවර්තනය සහ විශ්වාස කරන්න ප්\u200dරයෝජනයක් තියෙනවා, ඒ වගේම දැනටමත් වාර්තනය වැ අපි උත්සාහ කළා අලුත් විධානයක් විස්තර කරන්න සහ සංවිධානය දත්ත පරික්ෂණය සඳහා ආයෙත් ප්\u200dරති ඒත් ඒ විදියට පරීක්ෂණයක් නිර්භාවිත වෙලා තියෙනවා, ඒ වගේම එයාලා අපිට ප්\u200dරශ්නයක් නැති විදියට ප්\u200dරශ අපි මේ නරක ප්\u200dරතිචාර ප්\u200dරතිචාරය විශ්ලේෂණය කරනවා අනාගතය අධ්\u200dයානය සඳහා පරීක්ෂණාව", 'so': "In this paper, we describe the submission of Tohoku-AIP-NTT to the WMT'20 news translation task.  Waxaannu ka qeybqaadanay shaqadan laba labo oo af luuqadood ah iyo afar hagid: Ingiriis - Jarmal iyo Ingiriis - Jabanees. Systemkanaga waxaa ka mid ah teknikado sida turjumista dib-u-turjumista iyo suurad-wanaag, kuwaas oo horay loo isticmaalay shaqooyinka turjumista. Waxaynu isku daynay in aan horumarino qaabab cusub oo lagu barbaarinayo macluumaadka la xiriira iyo soo celinta. Si kastaba ha ahaatee, qaababka waxay u muuqatay inay shaqeeyaan, waxayna nagu keeneen hagaajin aad u weyn sameynta saldhigga. Analyayno resultiyadan negative si aan u helno waxyaabaha aan cilmiga soo socda.", 'sv': "I denna uppsats beskriver vi inlﾃ､mningen av Tohoku-AIP-NTT till nyhetsﾃｶversﾃ､ttningsuppgiften WMT'20. Vi deltog i denna uppgift i tvﾃ･ sprﾃ･kpar och fyra sprﾃ･kriktningar: engelska - tyska och engelska - japanska. Vﾃ･rt system bestﾃ･r av tekniker som back-translation och finjustering, som redan i stor utstrﾃ､ckning anvﾃ､nds i ﾃｶversﾃ､ttningsuppgifter. Vi fﾃｶrsﾃｶkte utveckla nya metoder fﾃｶr bﾃ･de syntetisk datafiltrering och ﾃ･terfﾃｶrankning. Metoderna visade sig dock vara ineffektiva och de gav oss ingen signifikant fﾃｶrbﾃ､ttring jﾃ､mfﾃｶrt med baslinjen. Vi analyserar dessa negativa resultat fﾃｶr att ge insikter fﾃｶr framtida studier.", 'ur': "ہم اس کاغذ میں توهوکو-AIP-NTT کے مطابق WMT'20 خبریں ترجمہ کے کام کی تعریف کرتے ہیں۔ ہم نے اس کام میں دو زبان جوڑوں اور چار زبان طریقوں میں شامل کیا: انگلیسی - جرمن اور انگلیسی - جاپانی. ہمارا سیستم ایسی تکنیکیوں میں ہے جیسے پیچھے ترجمہ اور نیک ترکینگ، جو پہلے سے ترجمہ کے کاموں میں پھیرے گئے ہیں. ہم نے سینٹیسی ڈیٹی فیلٹرینگ اور دوبارہ لینگ کے لئے نو طریقے بنانے کی کوشش کی۔ However, the methods turned out to be ineffective, and they provided us with no significant improvement on the baseline. ہم ان منفی نتائج کو تحقیق کرتے ہیں تاکہ آینده تحقیقات کے لئے بصیرت حاصل کریں۔", 'ta': "இந்த காகிதத்தில், நாம் விவரிக்கிறோம் Tohoku-AIP-NTT WMT'20 செய்தி மொழிபெயர்ப்பு பணியை விவரிக்கிறது. நாங்கள் இந்த பணியில் இரண்டு மொழி ஜோடி மற்றும் நான்கு மொழி திசைகளில் பங்கிட்டோம்: ஆங்கிலம் - ஜெர்மன் மற்ற மொழிபெயர்ப்பு பணிகளில் ஏற்கனவே பொருத்தப்பட்டுள்ள தொழில்நுட்ப மொழிபெயர்ப்பு மற்றும் நல்ல மொழிபெயர்ப்பு ப நாங்கள் புதிய முறைகளை உருவாக்க முயற்சி செய்தோம் கூட்டிணைப்பு தகவல் வடிகட்டி மற்றும் மீண்டும் முயற ஆனால், முறைகள் செயல்படாது என்பது தெரிந்தது, அடிப்படைக்கோட்டில் எங்களுக்கு முக்கியமான முன்னேற்றம் இல்லை. நாம் இந்த எதிர்மறை முடிவுகளை ஆராய்ந்து எதிர்கால ஆய்வுகளுக்கு உணர்வுகளை அளிக்க.", 'uz': "Bu takarda, biz Tohoku-AIP-NTT WMT'20 хабар tarjima vazifasini anglatamiz. Biz bu vazifani ikki tillar ikki xil va to'rtta tilning yo'nalarda qismga ega qildik: Inglizcha - Olmon va Inglizcha - Yaponcha. @ info Biz synthetik maʼlumotni filterlash va qaytadan qaytadan chiqish uchun yangi usulni yaratishga harakat qildik. Lekin, bu usullar muvaffaqiyatli bo'lgan edi va ular bizni asosiy satrda juda katta yaxshi o'zgarishga ega emas. Biz kelajakdagi o'qituvchilarga ko'rganish uchun bu negativ natijalarini nazar qilamiz.", 'vi': "Trong tờ giấy này, chúng tôi mô tả việc thuyết phục Toiku-AIP-NTT tổ chức dịch tin tức WRT'20. Chúng tôi tham gia vào nhiệm vụ này bằng hai cặp ngôn ngữ và bốn hướng ngôn ngữ: Tiếng Anh- Đức và Tiếng Anh- Nhật. Hệ thống của chúng tôi gồm các kỹ thuật quay lại và sửa chữa, những kỹ thuật đã được phát triển rộng rãi trong các công việc dịch chuyển. Chúng tôi đã cố gắng phát triển phương pháp mới cho cả việc lọc dữ liệu tổng hợp và nối lại. Tuy nhiên, các phương pháp hóa ra không hiệu quả, và chúng cho ta thấy không có cải thiện đáng kể trên cơ sở cơ bản. Chúng tôi phân tích kết quả tiêu cực này để cung cấp nghiên cứu tương lai.", 'da': "I denne artikel beskriver vi indsendelsen af Tohoku-AIP-NTT til WMT'20 nyhedsoversættelsesopgaven. Vi deltog i denne opgave i to sprogpar og fire sprogretninger: engelsk - tysk og engelsk - japansk. Vores system består af teknikker som back-oversættelse og finjustering, som allerede er bredt anvendt i oversættelsesopgaver. Vi forsøgte at udvikle nye metoder til både syntetisk datafiltrering og omlægning. Metoderne viste sig imidlertid at være ineffektive, og de gav os ingen væsentlig forbedring i forhold til basislinjen. Vi analyserer disse negative resultater for at give indsigt til fremtidige undersøgelser.", 'nl': "In dit artikel beschrijven we de inzending van Tohoku-AIP-NTT aan de WMT'20 nieuwsovertelling taak. We namen deel aan deze taak in twee taalparen en vier taalrichtingen: Engels-Duits en Engels-Japans. Ons systeem bestaat uit technieken zoals back-translation en fine-tuning, die al op grote schaal worden toegepast in vertaaltaken. We probeerden nieuwe methoden te ontwikkelen voor zowel synthetische gegevensfiltering als herranging. De methoden bleken echter ineffectief te zijn en leverden geen significante verbetering op ten opzichte van de basislijn. We analyseren deze negatieve resultaten om inzichten te geven voor toekomstige studies.", 'bg': "В настоящата статия описваме предаването на Тохоку-АИП-НТТ на задачата за превод на новини от WMT'20. Участвахме в тази задача в две езикови двойки и четири езикови направления: английски - немски и английски - японски. Системата ни се състои от техники като обратен превод и фина настройка, които вече са широко приети в преводните задачи. Опитахме се да разработим нови методи както за синтетично филтриране на данни, така и за пренареждане. Методите обаче се оказаха неефективни и не ни предоставиха значително подобрение спрямо базовата база. Анализираме тези отрицателни резултати, за да предоставим прозрения за бъдещи проучвания.", 'hr': "U ovom papiru opisujemo predavanje Tohoku-AIP-NTT na zadatak WMT'20 novinskog prevoda. Učestvovali smo u ovom zadatku dva jezička parova i četiri jezička uputa: Engleski - Njemački i Engleski - Japanci. Naš sustav se sastoji od tehnika poput prijevoza i dobrodošlice, koje su već široko usvojene u prijevoznim zadacima. Pokušali smo razviti nove metode za filtrovanje i preokretanje sintetičkih podataka. Međutim, metode su ispostavili da su djelotvorne, a oni nam nisu pružili značajno poboljšanje u početnoj liniji. Analiziramo te negativne rezultate kako bi pružili uvid za buduće ispitivanje.", 'ko': "본고에서 우리는 동북 AIP NTT가 WMT'20 뉴스 번역 임무에 제출한 상황을 묘사하였다.우리는 두 쌍의 언어와 네 개의 언어 방향으로 이 임무인 영어-독어와 영어-일본어에 참여했다.우리의 시스템은 번역과 마이크로스피커 등 기술로 구성되어 있으며, 이러한 기술은 이미 번역 임무에 광범위하게 응용되었다.우리는 합성 데이터의 필터와 재배열을 위해 새로운 방법을 개발하려고 한다.그러나 이러한 방법은 무효로 증명되었고, 기선에 비해 현저한 개선을 가져오지 못했다.우리는 이러한 부정적인 결과를 분석하여 미래의 연구에 견해를 제공한다.", 'de': "In diesem Beitrag beschreiben wir die Einreichung von Tohoku-AIP-NTT an die WMT'20 NachrichtenĂĽbersetzungsaufgabe. Wir haben an dieser Aufgabe in zwei Sprachpaaren und vier Sprachrichtungen teilgenommen: Englisch-Deutsch und Englisch-Japanisch. Unser System besteht aus Techniken wie Back-Translation und Fine-Tuning, die bereits in Ăśbersetzungsaufgaben weit verbreitet sind. Wir haben versucht, neue Methoden fĂĽr die synthetische Datenfilterung und das Reranking zu entwickeln. Die Methoden erwiesen sich jedoch als ineffektiv und lieferten keine signifikante Verbesserung gegenĂĽber der Basislinie. Wir analysieren diese negativen Ergebnisse, um Erkenntnisse fĂĽr zukĂĽnftige Studien zu liefern.", 'fa': "در این کاغذ، ما تحویل توهوکو-AIP-NTT را به وظیفه ترجمه خبری WMT'20 توصیف می کنیم. ما در این کار در دو جفت زبان و چهار راه زبان شرکت کردیم: انگلیسی - آلمانی و انگلیسی - ژاپنی. سیستم ما از تکنولوژی\u200cهایی مانند ترجمه\u200cهای پشتی و تنظیم\u200cکننده\u200cای است که در عملهای ترجمه قبلاً پذیرفته شده\u200cاند. ما سعی کردیم روش\u200cهای جدید برای فیلتر داده\u200cهای سینتیک و بازسازی. با این حال، روش\u200cهای بی\u200cتاثیر شدند، و آنها ما را هیچ بهبود بزرگی در زیرزمین ندادند. ما این نتایج منفی را برای تحقیقات آینده تحلیل می کنیم.", 'id': "Dalam kertas ini, kami menggambarkan pengiriman Tohoku-AIP-NTT ke tugas terjemahan berita WMT'20. Kami berpartisipasi dalam tugas ini dalam dua pasangan bahasa dan empat arah bahasa: Inggris - Jerman dan Inggris - Jepang. Sistem kita terdiri dari teknik seperti terjemahan belakang dan penyesuaian, yang sudah diadopsi secara luas dalam tugas terjemahan. Kami mencoba untuk mengembangkan metode baru untuk filtrasi data sintetis dan mengorbankan ulang. Namun, metode ternyata tidak efektif, dan mereka menyediakan kita dengan tidak ada peningkatan yang signifikan dibanding dasar. We analyze these negative results to provide insights for future studies.", 'tr': "Bu kagyzda, WMT'iň 20-nji täze terjime täblisasine Tohoku-AIP-NTT-iň berildigini tassykladyk. Biz bu işe iki dil çift we dört dil yönlerinde dahyl etdik: Iňlisçe - Almança we iňlisçe - Japonça. Biziň sistemamyz arka-terjime we düzeltmek ýaly tekniklerden, hemişe terjime etmek üçin ullanýarlar. Biz sintetik maglumatlary filtrelemek we ýene-de çykarmak üçin täze yöntemleri gelişmäge synanyşdyrdyk. Ýöne şu şekilde çözümler etkisiz bolup görünýärdi we olar bizi baseliniň üstünde hiç hili möhüm gelişmegi ýok etdiler. Biz bu negatif netijeleri gelejekde öwrenmeler üçin pikir etmäge çykýarys.", 'sw': "Katika karatasi hii, tunaelezea ujumbe wa Tohoku-AIP-NTT kwa kazi ya tafsiri ya habari ya WMT'20. Tumeshiriki katika juhudi hili katika mbili za lugha mbili na njia nne za lugha: Kiingereza - Kijerumani na Kiingereza - Kijapani. Our system consists of techniques such as back-translation and fine-tuning, which are already widely adopted in translation tasks.  Tulijaribu kuendeleza njia mpya za kuchuja taarifa za pamoja na kupata upya. Hata hivyo, mbinu hizo zilionekana kuwa hazina ufanisi, na zilitupatia maboresho makubwa zaidi ya msingi. Tunafahamu matokeo haya hasi ya kutoa maoni kwa ajili ya tafiti za baadaye.", 'af': "In hierdie papier beskrywe ons die onderskrywing van Tohoku-AIP-NTT aan die WMT'20 nuusvertaling taak. Ons het in hierdie taak gedeel in twee taal paar en vier taal rigtings: Engels - Duits en Engels - Japanse. Ons stelsel bestaan van teknike soos terugvertaling en fyn-tuning, wat reeds in vertaling opdragte aangeneem word. Ons het probeer om nuwe metodes te ontwikkel vir beide sintetiese data filtering en herankering. Maar die metodes het uitgedraai om oneffektief te wees, en hulle het ons gegee met geen betaling verbetering oor die basisline nie. Ons analyseer hierdie negatiewe resultate om insige vir toekomstige studie te verskaf.", 'hy': "In this paper, we describe the submission of Tohoku-AIP-NTT to the WMT'20 news translation task.  Մենք մասնակցեցինք այս խնդրին երկու լեզվի զույգերով և չորս լեզվի ուղղությամբ' անգլերեն, գերմաներեն և անգլերեն, ճապոներեն: Our system consists of techniques such as back-translation and fine-tuning, which are already widely adopted in translation tasks.  Մենք փորձեցինք զարգացնել նոր մեթոդներ՝ ինչպես սինթետիկ տվյալների ֆիլտրման, ինչպես նաև վերադառնալու համար: However, the methods turned out to be ineffective, and they provided us with no significant improvement over the baseline.  We analyze these negative results to provide insights for future studies.", 'sq': "Në këtë letër, ne përshkruajmë dorëzimin e Tohoku-AIP-NTT në detyrën e përkthimit të lajmeve WMT'20. Ne morëm pjesë në këtë detyrë në dy çifte gjuhësh dhe katër drejtime gjuhësh: anglisht - gjerman dhe anglisht - japonez. Sistemi ynë përbëhet nga teknika të tilla si përkthimi prapa dhe rregullimi i të cilave tashmë janë miratuar gjerësisht në detyrat e përkthimit. U përpoqëm të zhvillojmë metoda të reja për filtrimin e të dhënave sintetike dhe ripërlidhjen. However, the methods turned out to be ineffective, and they provided us with no significant improvement over the baseline.  Ne analizojmë këto rezultate negative për të dhënë kuptime për studimet e ardhshme.", 'bn': 'এই কাগজটিতে আমরা টোহুকু-এইপ-এনটিকে উইএমটি’২০ সংবাদ অনুবাদ কর্মসূচির প্রতি বর্ণনা করি। আমরা এই কাজে অংশগ্রহণ করেছি দুই ভাষা জোড়া এবং চার ভাষার দিকে: ইংরেজী- জার্মান এবং ইংরেজী- জাপানিজ। আমাদের সিস্টেমের প্রযুক্তিগুলোর মধ্যে রয়েছে যেমন ফিরে অনুবাদ এবং ভালো টিউনিং যারা ইতোমধ্যে অনুবাদের কাজে ব্য আমরা সিন্টেটিক ডাটা ফিল্টারিং এবং পুনরায় সংরক্ষণের জন্য নতুন পদ্ধতি তৈরি করার চেষ্টা করেছি। তবে এই পদ্ধতিগুলো কার্যকর হতে পারে এবং তারা আমাদের বেসেলাইনে কোন গুরুত্বপূর্ণ উন্নতি দেয় নি। ভবিষ্যতের গবেষণার জন্য আমরা এই নেতিবাচক ফলাফল বিশ্লেষণ করি।', 'ca': "En aquest article, descrivim la presentació de Tohoku-AIP-NTT a la tasca de traducció de notícies del WMT'20. We participated in this task in two language pairs and four language directions: English - German and English - Japanese.  El nostre sistema consisteix en tècniques com la retrotraducció i l'ajustament, que ja són ampliament adoptades en tasques de traducció. Vam intentar desenvolupar nous mètodes tant per filtrar les dades sintètiques com per reenvolupar. Tot i així, els mètodes van resultar ineficients i no ens van proporcionar cap millora significativa sobre la base. We analyze these negative results to provide insights for future studies.", 'cs': "V tomto článku popisujeme předložení Tohoku-AIP-NTT do úlohy překladu zpráv WMT'20. Na tomto úkolu jsme se podíleli ve dvou jazykových párech a ve čtyřech jazykových směrech: angličtině-němčině a angličtině-japonštině. Náš systém se skládá z technik, jako je zpětný překlad a jemné ladění, které jsou již široce uplatňovány v překladatelských úkolech. Snažili jsme se vyvinout nové metody jak pro syntetické filtrování dat, tak i pro přeřazování dat. Tyto metody se však ukázaly jako neúčinné a neposkytly nám žádné významné zlepšení oproti základnímu základu. Tyto negativní výsledky analyzujeme, abychom poskytli poznatky pro budoucí studie.", 'am': 'በዚህ ካላት፣ Tohoku-AIP-NTT ለWMT-20 ዜና ትርጓሜ ስራትን እናሳውቃለን፡፡ ይህንን ሥራ ሁለት ቋንቋ እና አራት ቋንቋ መንገዶች ተጋጠመን፤ እንግሊዝኛ - ጀርመን እና እንግሊዘኛ - ጃፓንኛ የስርዓታችን ተርጓሚዎች እና የመልካም ትርጓሜ እና በተርጓሚዎች ስርዓቶች በተዘጋጀ ነው፡፡ We attempted to develop new methods for both synthetic data filtering and reranking.  ምንም እንኳን የሥርዓት ሥርዓት ፍላጎት የሌለባቸው መሆኑን አሰናከሉ፡፡ ለኋለኛይቱ ትምህርት ማስታወቂያውን ለማግኘት እነዚህን የnegative ውጤቶች እናስተምርራለን፡፡', 'az': "Bu kańüńĪzda, WMT'in 20 x…ôb…ôr √ßeviri iŇüin…ô Tohoku-AIP-NTT'in t…ôblińü edilm…ôsini t…ôsdiql…ôyirik. Biz bu iŇü…ô iki dil √ßift v…ô d√∂rd dil y√∂n…ôltm…ôl…ôrin…ô katńĪldńĪq: ńįngilizce - Alman v…ô ńįngilizce - Japonca. Bizim sistemimiz t…ôkrarlama v…ô t…ôkrarlama kimi teknikl…ôrd…ôn olur, ki artńĪq t…ôkrarlama iŇül…ôrind…ô q…ôbul edilmiŇüdir. Biz sintetik m…ôlumat filtrl…ôm…ôsi v…ô yenid…ôn filtrl…ôm…ôsi √ľ√ß√ľn yeni metodlarńĪ t…ôhsil etm…ôy…ô √ßalńĪŇüdńĪq. Ancaq metodlar etkisiz olduqlarńĪ halda, onlar biz…ô baseline √ľz…ôrind…ô he√ß bir m√∂hk…ôm uzlaŇüma verm…ôdil…ôr. Biz bu negatif sonu√ßlarńĪ g…ôl…ôc…ôk t…ôhsiml…ôr…ô n…ôz…ôr verm…ôk √ľ√ß√ľn analiz edirik.", 'fi': "Tässä artikkelissa kuvailemme Tohoku-AIP-NTT:n lähettämistä WMT'20:n uutiskäännöstehtävään. Osallistuimme tähän tehtävään kahdessa kieliparissa ja neljässä kielisuunnassa: englanti - saksa ja englanti - japani. Järjestelmämme koostuu sellaisista tekniikoista kuin jälkikäännös ja hienosäätö, jotka ovat jo laajasti käytössä käännöstehtävissä. Pyrimme kehittämään uusia menetelmiä sekä synteettiseen datan suodatukseen että uudelleenjärjestelyyn. Menetelmät osoittautuivat kuitenkin tehottomiksi, eivätkä ne antaneet meille merkittävää parannusta lähtötilanteeseen verrattuna. Analysoimme näitä negatiivisia tuloksia tarjotaksemme oivalluksia tuleviin tutkimuksiin.", 'et': "Käesolevas töös kirjeldame Tohoku-AIP-NTT esitamist WMT'20 uudiste tõlkimise ülesandele. Osalesime selles ülesandes kahes keelepaaris ja neljas keelesuunas: inglise - saksa ja inglise - jaapani. Meie süsteem koosneb sellistest tehnikatest nagu tagantõlge ja peenhäälestus, mis on juba laialdaselt kasutusele võetud tõlketöödes. Püüdsime välja töötada uusi meetodeid nii sünteetiliseks andmete filtreerimiseks kui ka ümberpankimiseks. Siiski osutusid meetodid ebatõhusaks ja need ei andnud meile olulist paranemist võrreldes lähtetasemega. Analüüsime neid negatiivseid tulemusi, et anda teavet tulevaste uuringute jaoks.", 'bs': "U ovom papiru opisujemo predavanje Tohoku-AIP-NTT na zadatak WMT'20 novinskog prevoda. Učestvovali smo u ovom zadatku dva jezička parova i četiri jezička uputa: Engleski - Njemački i Engleski - Japanci. Naš sistem se sastoji od tehnika poput prevoda i fino-tuniranja, koje su već široko usvojene u zadacima prevoda. Pokušali smo razviti nove metode za filtrovanje i preokretanje sintetičkih podataka. Međutim, metode su ispostavili da su neiffektivne, i oni su nam pružili nikakvo značajno poboljšanje u početnoj liniji. Analiziramo ove negativne rezultate kako bi pružili uvid za buduće studije.", 'jv': "Nang pemilih iki, kita ngubah ngerasai kanggo nyeleh Tohoku-AIP-ENTT kanggo nganggo cara sing terjamahan ning WT'2 Awak dhéwé éntukno karo nggambar iki banget lan basa sing luwih: Inggris - German lan Inggris - Japon. Sistem awak dhéwé sistem sing sumelang teknik, kayata terjamah lan dibutuhke tarjamah, sing ngendalikno ngono nggawe tarjamahan. Awakdhéwé ngesaiki nggawe sistem sing bagian kanggo nyebutaké sistem sing isinté karo nggawe barang. Nanging, meh kuwi bisa ditambah sing ora nggawe layang-layang, lan wong iki ngono awak dhéwé kuwi nggawe layang-layang kanggo ngilangno sistêm kuwi. Awak dhéwé énalik perusahaan bendhikak kanggo nyengkap mulai nggawe barang kanggo ujian.", 'ha': "In this paper, we describe the submission of Tohoku-AIP-NTT to the WMT'20 news translation task.  Mun yi rabo da wannan aikin a cikin mazaɓa biyu cikin harshe biyu da wasu hanyõyi huɗu: Ingiriya - Jarman da Ingiriya - Jabaniya. @ info: tooltip Mun yi jarraba su buɗe hanyoyin sãbuwa wa filtering data na sami'a sami'a. A lokacin da, hanyoyinin sun bayyana ba ta kasance mai rauni, kuma ba su gaura mana da kyakkyawan gyãra ba a kan layin. Munã sanar da waɗannan matsalan haske zuwa ga su bãyar da gannai ga karatun masu gabani.", 'sk': "V prispevku opisujemo predložitev Tohoku-AIP-NTT v nalogo prevajanja novic WMT'20. Pri tej nalogi smo sodelovali v dveh jezikovnih parih in štirih jezikovnih smereh: angleščina - nemščina in angleščina - japonščina. Naš sistem sestavljajo tehnike, kot sta nazaj prevajanje in fine-tuning, ki so že široko sprejete pri prevajalskih nalogah. Poskušali smo razviti nove metode za sintetično filtriranje in preračunavanje podatkov. Vendar pa so se metode izkazale za neučinkovite in niso nam zagotovile bistvenega izboljšanja v primerjavi z izhodiščem. Te negativne rezultate analiziramo, da bi zagotovili vpogled v prihodnje študije.", 'he': "בעיתון הזה, אנחנו מתארים את ההעברה של Tohoku-AIP-NTT למשימת התרגום חדשות WMT'20. השתתפנו במשימה הזאת בשני זוגות שפות וארבעה כיוונים שפות: אנגלית, גרמנית, אנגלית, יפנית. המערכת שלנו מורכבת מטכניקות כמו התרגום האחורי ומתאים, שכבר מאושמים באופן רחב במשימות התרגום. We attempted to develop new methods for both synthetic data filtering and reranking.  עם זאת, התברר שהשיטות לא יעילות, והם סיפקו לנו שום שיפור משמעותי מעל הבסיס. אנו מנתחים את התוצאות השליליות האלה כדי לספק תובנות למחקרים עתידים.", 'bo': "འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་WMT'ཡི་བརྗོད་འགྲེལ་བཤད་པ་དེ་གིས་Tohoku-AIP-NTT གནང་ཡོད་པ་དང་། ང་ཚོས་སྐད ང་ཚོའི་མ་ལག་གིས་རྒྱབ་ལྗོངས་དང་གནད་དོན་མེད་པའི་ཐབས་ལམ་ལུགས་ནང་ཡོད་པ། ང་ཚོས་དབྱིབས་ཆ་སྒྲིག་ཆ་ཚིག་འཚོལ་བཤེར་དང་བསྐྱར་དུ་བཟོ་བྱེད་པའི་ཐབས་ལམ་གསར་བ་ཞིག་དགོས་བྱུང་། ཡིན་ནའང་། ཐབས་ལམ་དེ་འགྱུར་བ་མེད་པར་ནུས་ཡོད་པས། ཁོང་ཚོས་ང་ཚོར་གཞི་གཞི་རྟེན་དུ་ཉེན་ཁ་གཏོགས་ཀྱི་ཡར་རྒྱ ང་ཚོས་མ་འོངས་པར་ཕྱོགས་ཉུང་བའི་གནད་སྡུད་འདི་ལ་བལྟ་ཀློག་བྱེད་ཀྱི་ཡོད་པ་རེད།"}
{'en': 'NRC Systems for the 2020 Inuktitut-English News Translation Task', 'ar': 'أنظمة NRC لمهمة ترجمة أخبار Inuktitut-English لعام 2020', 'es': 'Sistemas NRC para la tarea de traducción de noticias Inuktitut-English 2020', 'fr': 'Les systèmes du CNRC pour la tâche de traduction des nouvelles en inuktitut-anglais 2020', 'pt': 'NRC Systems para a Tarefa de Tradução de Notícias Inuktitut-Inglês 2020', 'ja': '2020年Inuktitut - Englishニュース翻訳タスクのためのNRCシステム', 'zh': 'NRC系统公司为2020年以纽特人英语新闻翻译任', 'hi': '2020 Inuktitut-अंग्रेजी समाचार अनुवाद कार्य के लिए NRC सिस्टम', 'ru': 'Системы NRC для задачи по переводу новостей на инуктитут-английский язык 2020 года', 'ga': 'Córais NRC don Tasc Aistriúcháin Nuachta Ionúitis-Béarla 2020', 'ka': 'NRC Systems for the 2020 Inuktitut-English News Translation Task', 'hu': 'NRC rendszerek a 2020-as Inuktitut-Magyar Hírfordítási feladathoz', 'el': 'Συστήματα για το 2020 Inuktitut-Αγγλικά Νέα Μετάφραση Εργασία', 'it': 'Sistemi NRC per il compito di traduzione delle notizie Inuktitut-English 2020', 'kk': 'Inuktitut- English News Translation Task for the NRC Systems for the 2020 Inuktitut- English News Translation Task', 'lt': 'NRC sistemos, skirtos 2020 m. Inuktitut-English naujienų vertimo darbui', 'ms': 'Sistem NRC untuk Tugas Terjemahan Berita Inuktitut-English 2020', 'mk': 'НРЦ системи за задачата на Инуктитут-англиски превод на вести за 2020 година', 'ml': '2020 ഇംഗ്ലീഷ്- ഇംഗ്ലീഷ് വാര്\u200dത്തകള്\u200d ടാസ്കിനുള്ള NRC സിസ്റ്റം', 'mt': 'NRC Systems for the 2020 Inuktitut-English News Translation Task', 'mn': 'НRC Systems for the 2020 Inuktitut-English News Translation Task', 'no': 'NRC Systems for Inuktitut-English News Translation Task 2020', 'ro': 'Sisteme NRC pentru sarcina de traducere a știrilor Inuktitut-English 2020', 'pl': 'NRC Systems for the 2020 Inuktitut-English News Translation Task', 'si': 'NRC Systems for the 2020Inuktitut-English News translation Job', 'sr': 'NRC sistemi za zadatak Inuktitut-English News Translation Task 2020', 'so': 'NRC Systems for the 2020 Inuktitut-Ingiriis Translation News Task', 'sv': 'NRC-system fĂ¶r 2020 Inuktitut-Svenska nyhetsĂ¶versĂ¤ttningsuppgiften', 'ta': '2020 Inuktitut- ஆங்கிலம் செய்தி மொழிபெயர்ப்பு பணிக்கான NRC அமைப்புகள்', 'ur': '۲۰۰۲ اینوکیٹ-انگلیسی نیویس ترجمہ ٹاکس کے لئے NRC سیسٹم', 'uz': '2020 Inuktitut- Ingliz News tarjima vazifasi uchun NRC tizimi', 'vi': 'Hệ thống NRC cho nhiệm vụ dịch tin tức 2020 Name', 'bg': 'НРК Системи за задачата за превод на новини Инуктиту-английски 2020', 'da': 'NRC-systemer til 2020 Inuktitut-engelsk nyhedsoversættelsesopgave', 'hr': 'NRC sustavi za zadatak za prevod Inuktitut-Engleskih vijesti 2020.', 'nl': 'NRC-systemen voor de 2020 Inuktitut-Engels Nieuws Vertaling Taak', 'fa': 'سیستم NRC برای ترجمه خبرهای انگلیسی Inuktitut-English ۲۰۰۲', 'id': 'NRC Systems for the 2020 Inuktitut-English News Translation Task', 'de': 'NRC-Systeme für die 2020 Inuktitut-English News Translation Task', 'af': 'NRC Systems vir die Inuktitut- Engels Nuusvertaling Taak 2020', 'sw': 'Mfumo wa NRC kwa ajili ya kazi ya Tafsiri ya Habari za Kiingereza 2020', 'tr': 'Inuktitut-Iňlisçe Haýry terjime Görevi 2020', 'hy': 'NRC Systems for the 2020 Inuktitut-English News Translation Task', 'sq': 'NRC Systems for the 2020 Inuktitut-English News Translation Task', 'bn': '২০২০০ ইনুক্তিটি- ইংরেজি সংবাদ অনুবাদের কাজের জন্য এনআরসি সিস্টেম', 'am': 'የ2020 ኢንቱቅቲ-እንግሊዝኛ ዜና ትርጓሜ ስርዓት', 'ca': 'NRC Systems for the 2020 Inuktitut-English News Translation Task', 'ko': '2020년 뉴트라인 영어 뉴스 번역 임무 NRC 시스템', 'az': '2020 Inuktitut-ńįngiliz…ô Haber √áeviri G√∂z…ôli NRC Sisteml…ôri', 'fi': 'NRC-järjestelmät vuoden 2020 Inuktitut-English News Translation Task', 'bs': 'NRC sustavi za zadatak Inuktitut-English News Translation Task 2020', 'cs': 'NRC systémy pro rok 2020 Inuktitut-English News Translation Task', 'et': 'NRC süsteemid 2020. aasta Inuktitut-English uudiste tõlketööks', 'he': 'מערכות NRC עבור משימה התרגום חדשות אינוקטיטוט-אנגלית 2020', 'ha': 'KCharselect unicode block name', 'jv': 'NPN System kanggo 2020 Inukti-Inggris Haji Terjamahan', 'sk': 'Sistemi NRC za nalogo prevajanja novic Inuktitut-English 2020', 'bo': 'NRC Systems for the 2020 Inuktitut-English News Translation Task'}
{'en': 'We describe the National Research Council of Canada (NRC) submissions for the 2020 Inuktitut-English shared task on news translation at the Fifth Conference on Machine Translation (WMT20). Our submissions consist of ensembled domain-specific finetuned transformer models, trained using the Nunavut Hansard and news data and, in the case of Inuktitut-English, backtranslated news and parliamentary data. In this work we explore challenges related to the relatively small amount of parallel data, morphological complexity, and domain shifts.', 'ar': 'نصف تقارير المجلس القومي للبحوث في كندا (NRC) لمهمة 2020 Inuktitut-English المشتركة حول ترجمة الأخبار في المؤتمر الخامس للترجمة الآلية (WMT20). تتكون تقديماتنا من نماذج محولات مُجمَّعة محددة المجال ومُدرَّبة باستخدام Nunavut Hansard وبيانات الأخبار ، وفي حالة Inuktitut-English ، الأخبار المترجمة والبيانات البرلمانية. في هذا العمل ، نستكشف التحديات المتعلقة بالكمية الصغيرة نسبيًا من البيانات المتوازية ، والتعقيد المورفولوجي ، وتحولات المجال.', 'pt': 'Descrevemos as submissões do Conselho Nacional de Pesquisa do Canadá (NRC) para a tarefa compartilhada 2020 Inuktitut-Inglês sobre tradução de notícias na Quinta Conferência sobre Tradução Automática (WMT20). Nossas submissões consistem em modelos de transformadores ajustados específicos de domínio, treinados usando o Nunavut Hansard e dados de notícias e, no caso de inuktitut-inglês, notícias retrotraduzidas e dados parlamentares. Neste trabalho exploramos desafios relacionados à quantidade relativamente pequena de dados paralelos, complexidade morfológica e mudanças de domínio.', 'fr': "Nous décrivons les soumissions du Conseil national de recherches du Canada (CNRC) pour la tâche partagée inuktitut-anglais 2020 sur la traduction de nouvelles à la cinquième conférence sur la traduction automatique (WMT20). Nos soumissions consistent en un ensemble de modèles de transformateurs affinés spécifiques au domaine, formés à l'aide du hansard du Nunavut et des données d'actualité et, dans le cas de l'inuktitut-anglais, de nouvelles rétro-traduites et de données parlementaires. Dans ce travail, nous explorons les défis liés à la quantité relativement faible de données parallèles, à la complexité morphologique et aux changements de domaine.", 'es': 'Describimos las presentaciones del National Research Council of Canada (NRC) para la tarea compartida Inuktitut-English 2020 sobre traducción de noticias en la Quinta Conferencia sobre Traducción Automática (WMT20). Nuestras presentaciones consisten en modelos de transformadores ajustados específicos del dominio, entrenados con Nunavut Hansard y datos de noticias y, en el caso de Inuktitut-English, datos de noticias y parlamentarios retrotraducidos. En este trabajo exploramos los desafíos relacionados con la cantidad relativamente pequeña de datos paralelos, la complejidad morfológica y los cambios de dominio.', 'ja': '私たちは、第5回機械翻訳会議（ WMT 20 ）におけるニュース翻訳に関する2020 Inuktitut - English shared taskのためのカナダ国立研究評議会（ NRC ）の提出物について説明します。当社の提出物は、ドメイン固有の微調整された変圧器モデルを組み合わせ、Nunavut Hansardとニュースデータを使用してトレーニングし、Inuktitut - Englishの場合は、ニュースと議会データを翻訳します。この研究では、比較的少ない量の並列データ、形態的複雑性、およびドメインシフトに関連する課題を探求します。', 'zh': '述加拿大国家委员会(NRC)会议于第五届机器翻译(WMT20)为2020年因纽特 - 英语共享其新闻翻译。 凡提交之材,特定于领域之微变压器,用努纳武特汉萨德新闻之数,因纽特英语之情,回传新闻议会之数。 于是讨其并行,形复杂性和域偏移相关。', 'hi': 'हम मशीन अनुवाद (WMT20) पर पांचवें सम्मेलन में समाचार अनुवाद पर समाचार अनुवाद पर 2020 Inuktitut-English साझा कार्य के लिए कनाडा के राष्ट्रीय अनुसंधान परिषद (NRC) प्रस्तुतियों का वर्णन करते हैं। हमारे प्रस्तुतियों ensembled डोमेन-विशिष्ट finetuned ट्रांसफॉर्मर मॉडल, Nunavut Hansard और समाचार डेटा का उपयोग कर प्रशिक्षित और, Inuktitut-अंग्रेजी के मामले में, backtranslated समाचार और संसदीय डेटा के मामले में शामिल हैं. इस काम में हम समानांतर डेटा की अपेक्षाकृत छोटी मात्रा, रूपात्मक जटिलता और डोमेन शिफ्ट से संबंधित चुनौतियों का पता लगाते हैं।', 'ru': 'Мы описываем материалы, представленные Национальным исследовательским советом Канады (NRC) для совместной задачи Inuktitut-English 2020 по переводу новостей на пятой Конференции по машинному переводу (WMT20). Наши материалы состоят из собранных доменных тонко настроенных трансформаторных моделей, обученных с использованием Nunavut Hansard и новостных данных, а в случае с Inuktitut-English - новостных и парламентских данных, переведенных в обратном порядке. В этой работе мы исследуем проблемы, связанные с относительно небольшим объемом параллельных данных, морфологической сложностью и сдвигами в области.', 'ga': 'Déanaimid cur síos ar aighneachtaí Chomhairle Náisiúnta Taighde Cheanada (NRC) maidir le tasc comhroinnte 2020 Ionúitis-Béarla ar aistriúchán nuachta ag an gCúigiú Comhdháil ar Aistriúchán Meaisín (WMT20). Is éard atá inár n-aighneachtaí ná samhlacha claochladán mionchoigeartaithe a bhaineann go sonrach le fearann, arna n-oiliúint ag baint úsáide as Nunavut Hansard agus sonraí nuachta agus, i gcás Inuktitut-English, nuacht aisaistrithe agus sonraí parlaiminte. Sa obair seo déanaimid iniúchadh ar dhúshláin a bhaineann leis an méid réasúnta beag de shonraí comhthreomhara, castacht mhoirfeolaíoch, agus aistrithe fearainn.', 'hu': 'Leírjuk a Kanadai Nemzeti Kutatási Tanács (NRC) benyújtásait a 2020. évi Inuktitut-angol közös hírfordítási feladatra vonatkozó ötödik gépi fordítási konferencián (WMT20). Jelentkezéseink a Nunavut Hansard és a híradatok felhasználásával képzett, együttes domain-specifikus finomhangolt transzformátormodellekből állnak, illetve Inuktitut-angol esetében visszafordított hírekből és parlamenti adatokból állnak. Ebben a munkában a viszonylag kis mennyiségű párhuzamos adatokkal, morfológiai komplexitással és domain eltolódással kapcsolatos kihívásokat vizsgáljuk fel.', 'el': 'Περιγράφουμε τις αιτήσεις του Εθνικού Συμβουλίου Έρευνας του Καναδά (NRC) για την κοινή εργασία 2020 Inuktitut-English σχετικά με τη μετάφραση ειδήσεων στο 5ο Συνέδριο για τη Μηχανική Μετάφραση (WMT20). Οι αιτήσεις μας αποτελούνται από ολοκληρωμένα μοντέλα μετασχηματιστών ειδικά προσαρμοσμένα στον τομέα, εκπαιδευμένα με βάση τα δεδομένα και τα δεδομένα ειδήσεων και, στην περίπτωση του Ινουκtitut-Αγγλικά, από μεταφρασμένα νέα και κοινοβουλευτικά δεδομένα. Στην παρούσα εργασία διερευνούμε προκλήσεις που σχετίζονται με τη σχετικά μικρή ποσότητα παράλληλων δεδομένων, τη μορφολογική πολυπλοκότητα και τις μετατοπίσεις τομέων.', 'kk': 'Біз Канаданың (NRC) улық зерттеулер советінің 2020 жылы инуктитутты-ағылшын тілінде жаңалық аудармалардың жаңалық аудармаларды (WMT20) бесінші конференциясында жаңалық аудармаларды ортақтастыратын тап Біздің келтіріміз доменге арналған жақсы түрлендіруші үлгілері бар, Nunavut Hansard және жаңалық деректерімен оқылған және инуктитут-ағылшынша, ақпарат аударылған жаңалықтар және парламентарлық деректері болса. Бұл жұмыс ішінде біз параллель деректер, морфологиялық комплекстер және доменнің өзгерістеріне сәйкес келген мәселелерді зерттейміз.', 'it': 'Descriviamo le proposte del National Research Council of Canada (NRC) per il compito condiviso Inuktitut-English 2020 sulla traduzione di notizie alla Quinta Conferenza sulla traduzione automatica (WMT20). Le nostre proposte sono costituite da modelli di trasformatori assemblati specifici per il dominio, formati utilizzando Nunavut Hansard e dati di notizie e, nel caso di Inuktitut-English, notizie e dati parlamentari tradotti indietro. In questo lavoro esploriamo le sfide legate alla quantità relativamente piccola di dati paralleli, alla complessità morfologica e ai cambiamenti di dominio.', 'ka': 'ჩვენ აღწერეთ კანადიის ნაციონალური სწავლობის კონფიგურაცია (NRC) მისამართებები, რომლებიც 2020 წლის ინუკტიტუტი-ანგლისური გაყოფილი სამუშაო დავაწყობინებაზე ახალგაზ ჩვენი მომხმარებები შექმნილი დიომინის სპექტიფიკური ტრანფორმეტრის მოდელები, რომლებიც აკეთებულიან ნუნავარ ჰანსაპე და ნუტური მონაცემების გამოყენებით და, ინუკტიტური-ანგლისური შემთხვევაში ამ სამუშაოში ჩვენ ვაკვირდებით პარალელური მონაცემების, მორპოლოგიური კომპლექსიტების და დომინის შეცვლების პარალელურად პარალელური ზომაზე.', 'lt': 'Mes apibūdiname Kanados nacionalinės mokslinių tyrimų tarybos (NRC) pateiktus pasiūlymus dėl 2020 m. Inuktitut-English bendros užduoties dėl žinių vertimo penktojoje konferencijoje dėl mašinų vertimo (WMT20). Mūsų pasiūlymus sudaro surinkti specialios srities patobulinti transformatorių modeliai, parengti naudojant Nunavut Hansard ir naujienų duomenis, o Inuktitut-English atveju – atvirkščiai išversti naujienos ir parlamentiniai duomenys. Šiame darbe nagrinėjame iššūkius, susijusius su palyginti nedideliu lygiagrečių duomenų kiekiu, morfologiniu sudėtingumu ir srities pokyčiais.', 'mk': 'Ние ги опишуваме поднесувањата на Националниот истражувачки совет на Канада (НРЦ) за заедничката задача Инуктитут-англиски за 2020 година за превод на вести на Петтата конференција за машински превод (ВМТ20). Нашите поднесувања се состојат од заеднички модели на финетизирани трансформатори специфични за домен, обучени со употреба на податоците од Нунавт Хансард и вестите и, во случај на инуктитут-англиски, преведени вести и парламентарни податоци. Во оваа работа ги истражуваме предизвиците поврзани со релативно малата количина паралелни податоци, морфолошката комплексност и промените на домените.', 'ms': 'Kami menggambarkan cadangan Dewan Penelitian Nasional Kanada (NRC) untuk tugas kongsi Inuktitut-English 2020 mengenai terjemahan berita di Perkonferensi Kelima tentang Terjemahan Mesin (WMT20). Penghantaran kami terdiri dari model pengubah yang ditetapkan secara spesifik domain, dilatih menggunakan Nunavut Hansard dan data berita dan, dalam kes Inuktitut-English, berita terjemahan balik dan data parlemen. Dalam kerja ini kami mengeksplorasi cabaran berkaitan dengan jumlah relatif kecil data selari, kompleksiti morfologi, dan perubahan domain.', 'ml': '2020 ഇനുക്ട്രിട്ടി- ഇംഗ്ലീഷിന്റെ വിവരങ്ങള്\u200dക്ക് നാഷണല്\u200d പരിശോധന കൌണ്\u200dസില്\u200d (NRC) വിവരിച്ചുകൊടുക്കുന്നു. മെഷീന്\u200d പരിഭാഷണത്തിന്\u200dറെ ഫാമ്പതാം ക നമ്മുടെ കീഴ്പ്പെടുത്തിയ ഡൊമെയിന്\u200d പ്രത്യേകിച്ചുള്ള മാറ്റങ്ങളില്\u200d നിന്നും നുനാവൂത് ഹാന്\u200dസാര്\u200dഡും വാര്\u200dത്ത വിവരങ്ങളും ഉപയോഗിച്ചും നമ്മുടെ കീഴ്പ് ഈ ജോലിയില്\u200d നമ്മള്\u200d വിലാസങ്ങള്\u200d പരിശോധിക്കുന്നു, ചെറിയ അളവിലുള്ള ഡേറ്റ, മോര്\u200dഫോളജിക്കല്\u200d സംബന്ധിച്ചിടത്തോളം ചെറി', 'mt': 'Aħna niddeskrivu s-sottomissjonijiet tal-Kunsill Nazzjonali tar-Riċerka tal-Kanada (NRC) għall-kompitu konġunt Inuktitut-Ingliż tal-2020 dwar it-traduzzjoni tal-aħbarijiet fil-Ħames Konferenza dwar it-Traduzzjoni tal-Magni (WMT20). Is-sottomissjonijiet tagħna jikkonsistu f’mudelli ta’ trasformaturi ffinalizzati speċifiċi għad-dominju, imħarrġa bl-użu tan-Nunavut Hansard u d-dejta tal-aħbarijiet u, fil-każ tal-Inuktitut-English, aħbarijiet u dejta parlamentari tradotti b’lura. F’din il-ħidma nesploraw sfidi relatati mal-ammont relattivament żgħir ta’ dejta parallela, kumplessità morfoloġika, u bidliet fid-dominju.', 'no': 'Vi beskriver at den nasjonale forskningsrådet i Canada (NRC) er tilgjengelege for den delte oppgåva i Inuktitut-Engelsk 2020 på nyhetssomsetjinga på femte konferanse om maskinsomsetjinga (WMT20). I tillegg til Inuktitut-English, tilbakeomsette nyhetar og parlamentære data inneheld våre tilførselsar av finetuned transformeringsmodeller for domenespesifikke finetuned transformeringsmodeller. I dette arbeidet utforskar vi utfordringar som er relatert til relativt liten mengda parallelle data, morfologiske kompleksitet og domeneforskyving.', 'mn': 'Бид Канадын улсын судалгааны зөвлөгөө (NRC) 2020 оны инуктитут-Англи хэлний мэдээллийн хөгжлийн даалгаварын тухай мэдээллийн хөгжлийн даалгаварыг тайлбарлаж байна. Our submissions consist of ensembled domain-specific finetuned transformer models, trained using the Nunavut Hansard and news data and, in the case of Inuktitut-English, backtranslated news and parliamentary data. Энэ ажилд бид параллель өгөгдлийн, морфологик төвөгтэй, холбоотой өөрчлөлттэй харьцангуй жижиг хэмжээний сорилтуудыг судалж байна.', 'pl': 'Opisujemy zgłoszenia Narodowej Rady Badawczej Kanady (NRC) na wspólne zadanie Inuktitut-English w zakresie tłumaczenia wiadomości na Piątej Konferencji Tłumaczenia Maszynowego (WMT20). Nasze zgłoszenia składają się z zespołu precyzyjnie dostrojonych modeli transformatorów specyficznych dla domeny, przeszkolonych przy użyciu danych Nunavut Hansard i informacji wiadomościowych oraz, w przypadku Inuktitut-English, danych informacyjnych i parlamentarnych. W niniejszej pracy badamy wyzwania związane ze stosunkowo niewielką ilością danych równoległych, złożonością morfologiczną i zmianami domeny.', 'ro': 'Descriem propunerile Consiliului Național de Cercetare al Canadei (NRC) pentru sarcina comună Inuktitut-Engleză 2020 privind traducerea știrilor la cea de-a cincea conferință privind traducerea automată (WMT20). Înscrierile noastre constau în modele de transformare bine reglate specifice domeniului, instruite folosind Nunavut Hansard și date de știri și, în cazul Inuktitut-Engleză, știri și date parlamentare traduse înapoi. În această lucrare explorăm provocările legate de cantitatea relativ mică de date paralele, complexitatea morfologică și schimbările domeniului.', 'sr': 'Mi opisujemo podatke Nacionalnog istraživačkog vijeća Kanade (NRC) za zajednički zadatak Inuktitut-Engleski 2020. na petoj konferenciji o prevodu mašine (WMT20). Naše podatke sastavljaju se od kompletnih modela transformacije u domenu specifičnih fina, obučenih koristeći Nunavut Hansard i novinske podatke i, u slučaju Inuktituta-engleskog, povratnih vesti i parlamentarnih podataka. U ovom poslu istražujemo izazove povezane sa relativno malim količinom paralelnih podataka, morfološkog kompleksnosti i promjene domena.', 'sv': 'Vi beskriver National Research Council of Canada (NRC) bidrag till 2020 års gemensamma uppgift om nyhetsöversättning vid femte konferensen om maskinöversättning (WMT20). Våra bidrag består av sammansatta domänspecifika finjusterade transformatormodeller, utbildade med hjälp av Nunavut Hansard och nyhetsdata och, när det gäller Inuktitut-engelska, bakåtöversatta nyheter och riksdagsdata. I detta arbete undersöker vi utmaningar relaterade till den relativt små mängden parallella data, morfologisk komplexitet och domänförskjutningar.', 'so': 'Waxaannu sawiraynaa ururka baaritaanka qaranka (NRC) oo loo soo dhiibay 2020 Inuktitut-Ingiriis oo lagu sharaxay shaqo ku saabsan turjumista news at the Fifth Conference on Machine Translation (WMT20). Ogeysiintayada waxaa ka mid ah samooyin bedelka oo gaar ah ee domain-specific ah, lagu tababariyey isticmaalka Nunavut Hansard iyo macluumaadka warbixinta ee warbixinta, iyo xaalada Inuktitut-Ingiriis, warar turjuman iyo macluumaad baarlamaanka. Shaqadan waxaynu ka baaraanaynaa dhibaatooyin la xiriira tirada yar ee macluumaadka lambarka ah, murugta morphologiga iyo isbedelka gudaha.', 'si': 'අපි කැනාඩාවේ ජාතික පරීක්ෂණ කණ්ඩායම (NRC) ප්\u200dරවේශනය ප්\u200dරවේශනය ප්\u200dරවේශනය කරනවා 2020යි Inuktitut-English shared job on the news translation at the Fifth Conferance on machine translation (WMT20). අපේ සම්පූර්ණය සම්පූර්ණයෙන් සම්පූර්ණ විශේෂ විශේෂ ප්\u200dරවර්තනයක් තියෙනවා, නුනාවුට් හැන්සාර්ඩ් සහ ආරංචික දත්ත භාවිතා කරල මේ වැඩේ අපි පරීක්ෂණය කරන්නේ අභ්\u200dයාගයක් සම්බන්ධයෙන් සමාන්\u200dයයෙන් පොඩි තොරතුරු සම්බන්ධයෙන් සම්බන්ධයෙන', 'ta': 'நாங்கள் காண்டாவின் நாட்டு ஆராய்ச்சி கூட்டத்தை விவரிக்கிறோம் 2020 இனுக்கிட்ட- ஆங்கில மொழிபெயர்ப்பிற்கான செய்தி மொழிபெயர்ப்பில் பங எங்கள் கட்டளைகள் குறிப்பிட்ட களம்- குறிப்பிட்ட மாற்றும் மாதிரிகளில் உள்ளது, நுநாவூட் ஹான்சார்ட் மற்றும் செய்தி தகவல் இந்த வேலையில் நாம் சிறிய இணைப்பு தரவுகள், மருத்துவகையான சிக்கல் மற்றும் களம் மாற்றங்களுடன் தொடர்புடைய சவால்களை கண்டுபி', 'ur': 'ہم کاناڈا کے ملی تحقیقات کنویل (NRC) کے مطابق ۲۰۰۲ کے انگلیسی انگلیسی کے مطابق نیویٹ ترجمہ کے بارے میں نیویٹ ترجمہ کے بارے میں مطابق فینٹی کنفرانس کے مطابق مطابق (WMT20) کے مطاب ہماری مہمانی مطابق دامنی کے مطابق مصنوعی مطابق مصنوعی تغییر موڈل سے ہے جو نوناوٹ هانسارد اور نیویورڈ ڈاٹ کے مطابق تغییر کی جاتی ہے اور انگلیسی کے مطابق انگلیسی کے مطابق پیچھے ترجمہ خبریں اور پار ہم اس کام میں مشکلات کی تحقیق کرتے ہیں جو مقابلہ سے چھوٹی مقدار کے معاملہ میں موجود ہیں، موجود پیچیدگی، اور ڈومین تغییرات کے معاملہ میں ہیں.', 'uz': "Biz 2020 Inuktitut- Ingliz tilidagi Taifa Research Council (NRC) tashkilotlarini tahlil qilamiz. Mashine tarjima konferansining Fifth konferansa (WMT20) ta'lim bir xizmat tarjima qilingan vazifani tahrirlash. Bizning imkoniyatlarimiz nunavut Hansard va xabar maʼlumotidan foydalanishdan foydalanilgan domen-bir notoʻgʻri transformer modellarimizdan iborat, va Inuktitut- Ingliz tilida tarjima qilingan xabar va parlamentagi maʼlumot. Bu ishda biz juda qisqarli parallel maʼlumot, morfologik murakkablik va domen o'zgarishlar bilan murakkablarini aniqlamiz.", 'vi': 'Chúng tôi mô tả những kiến nghị của Hội đồng Nghiên cứu Quốc gia Canada (NRC) về công việc chia sẻ 2020 Dịch vụ thông tin tại Thượng Hội nghị Ngu Cơ Khí (WM29). Liên kết của chúng tôi gồm các mô hình máy biến đổi đặc trưng miền, được huấn luyện bằng kênh kênh kênh Nunavut Hansar và các dữ liệu tin tức, và, trong trường hợp nhập niệm-Anh, tin tức được dịch ngược lại và dữ liệu của Quốc gia. Trong công việc này, chúng tôi khám phá những thử thách liên quan tới lượng dữ liệu tương đối nhỏ song song, phức tạp theo lịch và thay đổi miền.', 'da': 'Vi beskriver National Research Council of Canada (NRC) indlæg til 2020 Inuktitut-engelsk delte opgave om nyhedsoversættelse på femte konference om maskinoversættelse (WMT20). Vores indlæg består af sammensatte domænespecifikke finjusterede transformatormodeller, trænet ved hjælp af Nunavut Hansard og nyhedsdata og, for Inuktitut-engelsk, bagoversatte nyheder og parlamentsdata. I dette arbejde undersøger vi udfordringer relateret til den relativt lille mængde parallelle data, morfologisk kompleksitet og domæneskift.', 'de': 'Wir beschreiben die Einreichungen des National Research Council of Canada (NRC) für die 2020 Inuktitut-English Shared Task on News Translation auf der fünften Konferenz zur maschinellen Übersetzung (WMT20). Unsere Einreichungen bestehen aus ensembled domänenspezifisch abgestimmten Transformatormodellen, trainiert mit Nunavut Hansard und Nachrichtendaten und, im Fall von Inuktitut-Englisch, rückübersetzten Nachrichten- und Parlamentsdaten. In dieser Arbeit untersuchen wir Herausforderungen im Zusammenhang mit der relativ geringen Menge an parallelen Daten, morphologischer Komplexität und Domänenverschiebungen.', 'bg': 'Описваме предложенията на Националния изследователски съвет на Канада (НРК) за съвместната задача по превод на новини за 2020 г. на Петата конференция по машинен превод. Нашите предложения се състоят от ансамблирани, специфични за домейна модели фино настроени трансформатори, обучени с помощта на Нунавут Хансард и новинарски данни, а в случая на Инуктитут-английски - обратен превод на новини и парламентарни данни. В тази работа изследваме предизвикателствата, свързани с относително малкото количество паралелни данни, морфологичната сложност и промените в домейна.', 'nl': 'We beschrijven de inzendingen van de National Research Council of Canada (NRC) voor de 2020 Inuktitut-English shared task on news translation tijdens de Vijfde Conferentie over Machine Translation (WMT20). Onze inzendingen bestaan uit samengestelde domeinspecifieke fijnafgestemde transformatormodellen, getraind met Nunavut Hansard en nieuwsgegevens en, in het geval van Inuktitut-Engels, backvertaalde nieuws- en parlementsgegevens. In dit werk onderzoeken we uitdagingen gerelateerd aan de relatief kleine hoeveelheid parallelle data, morfologische complexiteit en domeinverschuivingen.', 'hr': 'Opisujemo podatke Nacionalnog istraživačkog vijeća Kanade (NRC) za zajednički zadatak Inuktitut-engleski za 2020. na petoj konferenciji o prevodu strojeva (WMT20). Naše podatke sastavljaju se od obilježenih modela transformacije fino-specifičnih domena, obučenih s Nunavut Hansard i novinskim podacima i, u slučaju Inuktitut-engleskog, povratnih vijesti i parlamentarnih podataka. U ovom poslu istražujemo izazove povezane sa relativno malim količinom paralelnih podataka, morfološkog kompleksnosti i promjene domena.', 'id': 'Kami menggambarkan persembahan Dewan Penelitian Nasional Kanada (NRC) untuk tugas kongsi Inuktitut-Inggris 2020 tentang terjemahan berita di Konferensi Kelima tentang Terjemahan Mesin (WMT20). Pengiriman kami terdiri dari model transformer spesifik domain yang disempurnakan, dilatih menggunakan Nunavut Hansard dan data berita dan, dalam kasus Inuktitut-English, berita terjemahan belakang dan data parlamentar. Dalam pekerjaan ini kami mengeksplorasi tantangan yang berhubungan dengan jumlah relatif kecil data paralel, kompleksitas morfologi, dan perubahan domain.', 'ko': '캐나다 국가연구위원회(NRC)가 제5차 기계번역회의(WMT20)에 제출한 2020년 뉴트맨의 영어 뉴스 번역으로 공유 임무를 묘사했다.저희가 제출한 자료는 분야별 마이크로스피커 변압기 모형을 통합하고 Nunavut Hansard와 뉴스 데이터를 이용한 교육, Inuktitut 영어에 대해 역번역된 뉴스와 의회 데이터를 사용합니다.이 작업에서 우리는 상대적으로 적은 병행 데이터, 형태학적 복잡성과 영역 이동과 관련된 도전을 탐구했다.', 'fa': 'ما توصیف داده\u200cهای شورای تحقیقات ملی کانادا (NRC) برای کار مشترک انگلیسی Inuktitut-English ۲۰۰۲ در مورد ترجمه خبری در پنجم کنفرانس روی ترجمه ماشین (WMT20) توصیف می\u200cکنیم. تحویل ما از مدل تغییر دهنده\u200cهای قطعی ویژه\u200cای که با استفاده از داده\u200cهای نونوات هانسارد و اطلاعات اخبار آموزش داده شده\u200cاند، و در مورد انگلیسی انگلیسی، خبرهای پشتیبانی و داده\u200cهای پارلمانتری است. در این کار ما چالش\u200cها را در ارتباط با مقدار نسبتا کوچک داده\u200cهای متفاوت، پیچیدگی مورفولوژیک و تغییرات دامنی تحقیق می\u200cکنیم.', 'sw': 'Tunaelezea matamko ya Baraza la Taifa la Utafiti la Kanada (NRC) kwa ajili ya ujumbe wa 2020 wa Kiingereza wa Kiutafiti-Kiingereza ulisambazwa na kazi ya kutafsiri habari katika Mkutano wa Fifth wa Tafsiri wa Mashiniki (WMT20). Mawasiliano yetu yanajumuisha mifano maalum ya mabadiliko ya ndani, yanafundishwa kwa kutumia Nunavut Hansard na taarifa za habari na, katika kesi ya Kiingereza ya Kiuktitut-Kiingereza, habari na taarifa za bunge. Katika kazi hii tunachunguza changamoto zinazohusiana na kiasi kidogo cha data tofauti, utata wa kimaadilojia na mabadiliko ya ndani.', 'tr': 'Biz Kanada Milli Araştyrma Konferensiýasyny (NRC) 2020-nji ýylda Inuktitut-Iňlisçe täzeliklerini Maşynyň terjime edilmegi (WMT20) üçin Maşynyň Beşinji Konferensiýasynda bäsleşip ýörän zady tassykladyk. Biziň gönderilenimiz, nunavut Hansardyň we haberler maglumatyny ulanyp taýýarlanan domynyň hökmünde beýleki taýýarlanmış şekillerden döredildi. Bu çalışmada, paralel verilerin, morfolojik karmaşıklığıyla ilgili düşmanları keşfetiyoruz.', 'af': 'Ons beskrywe die nasionale Research Council van Kanada (NRC) onderskrifte vir die 2020 Inuktitut-Engels deel taak op nuusvertaling by die Vyfde Konferanse oor Masjien Vertaling (WMT20). Ons voorskrifte bestaan van gemaakte domein-spesifieke finetuned transformer modele, onderrig gebruik van die Nunavut Hansard en nuusdata en, in die geval van Inuktitut-Engels, terugvertrekde nuus en parlamentêre data. In hierdie werk ondersoek ons uitdagings wat verwante is met die relativief klein hoeveelheid parallele data, morfologiese kompleksiteit en domein verskuif.', 'am': 'የካናዳ ብሔራዊ ምርምርመራ ካውንስቲ (NRC) በ2020 የኢንቱቅቲ-እንግሊዘኛ የዜና ትርጓሜ ላይ በአምስተኛው የመኪን ትርጓሜ ጉዳይ (WMT20) በተለየ የዜና ትርጓሜዎችን እናሳውቃለን፡፡ የኖዌት ሃንሰርድ እና የዜና ዳታዎችን በመጠቀም ተማርከዋል፡፡ በዚህ ስራ ውስጥ በተለያዩ የዳታ፣ የሞፎሎጂ ግንኙነት እና የውይይት ቀውጢ የሚደረገውን ትንሽ ጥቃቄዎችን እንፈልጋለን፡፡', 'hy': 'Մենք նկարագրում ենք Կանադայի Ազգային Հետազոտությունների խորհրդի (ԿԱԿ) ներկայացումները 2020 թվականի ինուկտիտուտ-անգլերեն ընդհանուր հանձնարարության մասին նորությունների թարգմանման մասին Հինգերորդ մեքենայի թարգմանման կոնֆերանսի Մեր ներկայացումները կազմված են ամբողջ բնագավառի մասնավոր փորձարկված ձևափոխման մոդելներից, ովքեր վարժեցվել են Նունաուտ Հանսարդի և նորությունների տվյալների օգնությամբ, և ինուկտիտուտ-անգլերենի դեպքում, վերադարձված նորությունների և բանականության Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք մարտահրավերները, որոնք կապված են զուգահեռ տվյալների համեմատաբար փոքր քանակությամբ, մորֆոլոգիական բարդությամբ և բնագավառի փոփոխություններով:', 'az': 'Biz Kanada Milli AraŇütńĪrma Konseyi (NRC) il…ô 2020-ci Inuktitut-ńįngilizce ńįngilizceyi il…ô BeŇüinci Konferenci on Machine Translation (WMT20) il…ô haber √ßevirilm…ôsi haqqńĪnda paylaŇüńĪlan iŇüi t…ôsdiql…ôyirik. Bizim t…ôblińül…ôrimiz, Nunavut Hansard v…ô x…ôb…ôr veril…ôri v…ô Inuktitut-ńįngilizce m…ôs…ôl…ôsind…ô, geri √ßevirilmiŇü x…ôb…ôrl…ôr v…ô parlamentary veril…ôr vasit…ôsil…ô t…ôhsil edilmiŇüdir. Bu iŇüd…ô biz paralel m…ôlumatlarńĪn, morfolojik kompleksit…ôsi v…ô domenin d…ôyiŇüiklikl…ôrin…ô bańülńĪ √ß…ôtinlikl…ôri keŇüfetirik.', 'sq': 'Ne përshkruajmë paraqitjet e Këshillit Kombëtar të Kërkimit të Kanadës (NRC) për detyrën e përbashkët të Inuktitut-Anglisht për 2020 mbi përkthimin e lajmeve në Konferencën e Pestë mbi Përkthimin e Makinës (WMT20). Paraqitjet tona përbëhen nga modele të përbashkëta të transformuesve specifikë për domenin, të trajnuar duke përdorur Nunavut Hansard dhe të dhënat e lajmeve dhe, në rastin e Inuktitut-English, lajmet e përkthyera mbrapsht dhe të dhënat parlamentare. In this work we explore challenges related to the relatively small amount of parallel data, morphological complexity, and domain shifts.', 'bs': 'Opisujemo podatke Nacionalnog istraživačkog vijeća Kanade (NRC) za zajednički zadatak Inuktitut-Engleski 2020. na petoj konferenciji o prevodu mašine (WMT20). Naše podatke sastavljaju se od komplikovanih modela transformacije u domenu specifičnih finetuned, obučenih koristeći Nunavut Hansard i novinske podatke i, u slučaju Inuktitut-engleskog, povratnih vijesti i parlamentarnih podataka. U ovom poslu istražujemo izazove povezane sa relativno malim količinom paralelnih podataka, morfološkog kompleksnosti i promjene domena.', 'cs': 'Popisujeme příspěvky Národní výzkumné rady Kanady (NRC) pro sdílený úkol Inuktitut-English 2020 na páté konferenci strojového překladu (WMT20). Naše příspěvky se skládají z sestavených doménově vyladěných modelů transformátorů, trénovaných s využitím Nunavut Hansard a zpravodajských dat a v případě Inuktitut-English zpětně přeložených zpráv a parlamentních dat. V této práci zkoumáme problémy související s relativně malým množstvím paralelních dat, morfologickou složitostí a doménovými posuny.', 'bn': '২০২০ ইনুক্তিটি-ইংরেজী অনুবাদের জন্য আমরা জাতীয় গবেষণা কাউন্ডার কাউন্সিলের (এনআরসি) প্রদত্ত বিবরণের বর্ণনা করেছি মেশিন অনুবাদ সম্মেলনের ৫ম কনফা আমাদের প্রদত্ত প্রদত্ত ডোমেইন-নির্দিষ্ট বিনিময় পরিবর্তন মডেল, নুনাভুট হ্যানসার্ড এবং সংবাদ তথ্য ব্যবহার করে প্রশিক্ষণ প্রদান করা হয়েছে এবং ইনুক্তিত- ই এই কাজে আমরা চ্যালেঞ্জ খুঁজে বের করি যে পরিমাণ তথ্য, মরোফোলজিক্যাল জটিলতা এবং ডোমেইন পরিবর্তনগুলোর সাথে সম্পর্কিত ছোট ছোট', 'ca': 'Descrivem les presentacions del National Research Council of Canada (NRC) per la tasca compartida Inuktitut-English del 2020 sobre traducció de notícies a la Quinta Conferència sobre Traducció Màquina (WMT20). Our submissions consist of ensembled domain-specific finetuned transformer models, trained using the Nunavut Hansard and news data and, in the case of Inuktitut-English, backtranslated news and parliamentary data.  En aquesta feina explorem reptes relacionats amb la relativament petita quantitat de dades paralleles, complexitat morfològica i canvis de domini.', 'et': 'Kirjeldame Kanada Riikliku Teadusnõukogu (NRC) ettepanekuid 2020. aasta Inuktitut-English jagatud uudiste tõlkimise ülesandeks masintõlke viiendal konverentsil (WMT20). Meie ettepanekud koosnevad ansambleeritud domeenispetsiifilistest peenhäälestatud transformaatormudelitest, mis on koolitatud Nunavut Hansardi ja uudisteandmete abil ning Inuktitut-inglise puhul tagantõlgitud uudistest ja parlamentaarsetest andmetest. Käesolevas töös uurime paralleelsete andmete suhteliselt väikese hulga, morfoloogilise keerukuse ja valdkonna muutustega seotud probleeme.', 'fi': 'Kuvaamme Kanadan kansallisen tutkimusneuvoston (NRC) ehdotuksia vuoden 2020 Inuktitut-English jaettuun uutiskäännöstehtävään viidennessä konekäännöskonferenssissa (WMT20). Toimituksemme koostuvat yhdistetyistä toimialueekohtaisista hienoviritetyistä muuntajamalleista, jotka on koulutettu Nunavut Hansardin ja uutisaineiston avulla ja Inuktitut-englannin tapauksessa takaisinkäännetyistä uutisista ja parlamentaarisesta aineistosta. Tässä työssä selvitämme haasteita, jotka liittyvät suhteellisen pieneen rinnakkaisaineiston määrään, morfologiseen monimutkaisuuteen ja toimialueen muutoksiin.', 'jv': 'Awakdhéwé rak saka nggambar Kemerdekaan kanggo Kemerdekaan kanggo Kemerdekaan Winter 2020 InukTitut-Inggris barang nggawe tarjamahan kanggo Kemerdekaan sing wis lima Kongresisan kanggo Kemerdekaan Inggal Terjamahan Awak dhéwé nggunian karo model sing dibenalke-aké domain-Cetha transformer model, desaturan karo Nunavut Hayard lan data sing berarti ngono, njuk sak InukTitut-Inggris, backtranslation balita karo data dotasé In this job we istrage conflicts connected to the ratio small amount of Paralelel data, transformative komplicity, and domain shifts.', 'ha': 'Tuna describe the National Research Board of Kanada (NRC) elements for the 2020 Inuktit-English share job on news translation at the Fifth Conference on Machine Translate (WMT20). TsarinMu na ƙunsa da misãlai masu buɗe da aka buɗe shi, an yi wa amfani da Nunaut Hansard da data na lãbãri, kuma, a cikin case of Inuktit-Ingiriya, an translate na lãbãri da data na bunge. Daga wannan aikin, Munã jarraba musamman masu husũma da gwargwadon data masu tsakanin da mutane, da musanya na mutfologi.', 'sk': 'Opisujemo prispevke Nacionalnega raziskovalnega sveta Kanade (NRC) za skupno nalogo Inuktitut-angleščina o prevajanju novic 2020 na Peti konferenci o strojnem prevajanju (WMT20). Naše predloge sestavljajo kompletirani modeli transformatorjev, specifični za domeno, ki so bili usposobljeni z uporabo Nunavut Hansard in podatkov o novicah, v primeru Inuktitut-angleščine pa tudi z nazaj prevedenimi novicami in parlamentarnimi podatki. V tem delu raziskujemo izzive, povezane z relativno majhno količino vzporednih podatkov, morfološko kompleksnostjo in premiki domen.', 'he': 'אנחנו מתארים את ההעברות של מועצת המחקר הלאומית של קנדה (NRC) למשימה המשותפת של "אינוקטיטוט-אנגלית 2020" על תרגום חדשות במועדון החמישי על תרגום מכונות (WMT20). ההעברות שלנו מורכבות ממודלים מסויימים לתחום מסויימים, מאומנים באמצעות נונאווט הנסארד ומידע חדשות, ובמקרה אינוקטיטוט אנגלי, חדשות מתרגמות אחורה ומידע פרלמנטרי. בעבודה הזו אנו חוקרים אתגרים שקשורים לסכום קטן יחסית של נתונים מקבילים, מורפולוגי מורפולוגי, ושינויים בתחום.', 'bo': 'ང་ཚོས་Canada(NRC)རྒྱལ་ཁབ་ཀྱི་འཚོལ་ཞིབ་ཀྱི་ཚོལ་ཞིབ་ཀྱི་ལས་འགུལ་སྤྲོད་ཀྱི་དོན་ལྟོའི་ནང་དུ་བརྡ་སྤྲོད་ཀྱི་ཚོལ་ཞིབ Our submissions consist of ensembled domain-specific finetuned transformer models, trained using the Nunavut Hansard and news data and, in the case of Inuktitut-English, backtranslated news and parliamentary data. In this work we explore challenges related to the relatively small amount of parallel data, morphological complexity, and domain shifts.'}
{'en': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'ar': 'تقديم CUNI للغة Inuktitut في أخبار WMT 2020', 'fr': 'Soumission CUNI pour la langue inuktitut dans WMT News 2020', 'pt': 'Submissão CUNI para o idioma inuktitut no WMT News 2020', 'es': 'Presentación de CUNI para el idioma inuktitut en WMT News 2020', 'ja': 'WMTニュース2020でのイヌクティトゥット語のCuNi提出', 'hi': 'WMT समाचार 2020 में Inuktitut भाषा के लिए CUNI सबमिशन', 'zh': 'CUNI于WMT新闻2020中提交因纽特语', 'ru': 'Представление CUNI для языка инуктитут в WMT News 2020', 'ga': 'Aighneacht CUNI don Teanga Ionúitis i Nuacht WMT 2020', 'ka': 'CUNI გამოყენება WMT News 2020-ში Inuktitut ენაზე', 'el': 'Υποβολή του CUNI για τη γλώσσα του Ινουκτιτούτου στα Νέα 2020', 'hu': 'CUNI beadvány az inuktitut nyelvre a WMT Hírek 2020', 'it': 'Presentazione CUNI per la lingua inuktitut in WMT News 2020', 'kk': 'WMT News 2020 тіліндегі Inuktitut тілінің CUNI сумсиясы', 'ml': 'WMT വാര്\u200dത്തകള്\u200d 2020 ല്\u200d ഇനുക്ട്ടിറ്റി ഭാഷയ്ക്കുള്ള സിയുണിഐ സബ്മിഷന്\u200d', 'mt': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'mn': 'WMT News 2020 оны Inuktitut хэл дээр CUNI дамжуулалт', 'no': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'lt': 'CUNI pranešimas apie Inuktituto kalbą WMT News 2020', 'mk': 'КУНИ поднесување за јазикот на инуктитутот во ВМТ вестите 2020', 'pl': 'Zgłoszenie CUNI dla języka Inuktitut w WMT News 2020', 'ro': 'Subscriere CUNI pentru limba inuktitut în WMT News 2020', 'ms': 'Submission CUNI untuk Bahasa Inuktitut dalam berita WMT 2020', 'sr': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'sv': 'CUNI Bidrag till Inuktitut Språket i WMT Nyheter 2020', 'so': 'CUNI Submission for the Inuktitut language in WMT News 2020', 'si': 'WMT වාර්තාවයේ ඉනුක්ටිටුට් භාෂාව සඳහා CUNI සබමිෂ්ය', 'ta': 'WMT செய்திகள் 2020 ல் உள்ள Inuktitut மொழிக்கான சியுனி ஐ ஒப்பிடு', 'ur': 'WMT News 2020 میں Inuktitut Language کے لئے CUNI Submission', 'uz': 'Name', 'vi': 'Biểu hiện CUPS về ngôn ngữ nhập nghĩa trên bản tin WRT 2020', 'da': 'CUNI Indsendelse til Inuktitut Sprog i WMT Nyheder 2020', 'nl': 'CUNI inzending voor de Inuktitutaal in WMT Nieuws 2020', 'hr': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'de': 'CUNI Einreichung für die Inuktitut-Sprache in WMT News 2020', 'id': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'fa': 'Submission CUNI for the Inuktitut Language in WMT News 2020', 'sw': 'Ujumbe wa CUNI kwa lugha ya Kiuktitut katika Habari za WMT 2020', 'af': 'CUNI Submission vir die Inuktitut Taal in WMT News 2020', 'bg': 'Кандидатстване за езика на инуктита в ММТ Новини 2020', 'sq': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'tr': "WMT Haýsy 2020'da Inuktitut Dili üçin CUNI Submission", 'az': 'WMT News 2020 üçün Inuktitut Dili üçün CUNI Submission', 'bn': 'WMT সংবাদ ২০২০-এ ইনুক্তিটি ভাষার জন্য সিউনি আই সাবিমিশন', 'ko': '2020년 WMT 뉴스에서 뉴트랜드 언어의 CUNI로 제출', 'am': 'በWMT ዜና 2020 ውስጥ የኢንቁቲ ቋንቋ የCUNI አዋጅ', 'cs': 'Příspěvek CUNI pro jazyk Inuktitut ve WMT News 2020', 'et': 'CUNI kandideerimine inuktitut keele eest WMT Uudised 2020', 'ca': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'fi': 'CUNI-hakemus Inuktitut-kielelle WMT News 2020 -lehdessä', 'hy': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'bs': 'CUNI Submission for the Inuktitut Language in WMT News 2020', 'jv': 'CUNI Submis kanggo langgambar InukTitut kanggo WWT New 2020', 'sk': 'Oddaja CUNI za Inuktitut jezik v WMT News 2020', 'he': 'השימוש CUNI לשפה האינוקטיטוט בחדשות WMT 2020', 'ha': 'CUNI Submit to the Inuktit language in WMT News 2020', 'bo': 'CUNI Submission for the Inuktitut Language in WMT News 2020'}
{'en': 'This paper describes CUNI submission to the WMT 2020 News Translation Shared Task for the low-resource scenario InuktitutEnglish in both translation directions. Our system combines transfer learning from a CzechEnglish high-resource language pair and backtranslation. We notice surprising behaviour when using synthetic data, which can be possibly attributed to a narrow domain of training and test data. We are using the Transformer model in a constrained submission.', 'ar': 'تصف هذه الورقة تقديم CUNI إلى المهمة المشتركة لترجمة الأخبار WMT 2020 لسيناريو الموارد المنخفضة Inuktitut – English في كلا اتجاهي الترجمة. يجمع نظامنا بين التعلم المحول من زوج لغوي عالي الموارد بين التشيكية والإنجليزية والترجمة العكسية. نلاحظ سلوكًا مفاجئًا عند استخدام البيانات التركيبية ، والتي يمكن أن تُعزى إلى مجال ضيق من بيانات التدريب والاختبار. نحن نستخدم نموذج المحولات في تقديم مقيد.', 'fr': "Cet article décrit la soumission de CUNI à la tâche partagée de traduction des nouvelles du WMT 2020 pour le scénario à faibles ressources Inuktitut—Anglais dans les deux sens de traduction. Notre système combine l'apprentissage par transfert à partir d'une paire de langues à ressources élevées tchèque-anglais et la rétrotraduction. Nous remarquons des comportements surprenants lors de l'utilisation de données synthétiques, qui peuvent être attribués à un domaine restreint de données d'entraînement et de test. Nous utilisons le modèle Transformer dans une soumission contrainte.", 'pt': 'Este artigo descreve o envio da CUNI para a Tarefa Compartilhada de Tradução de Notícias do WMT 2020 para o cenário de poucos recursos Inuktitut–Inglês em ambas as direções de tradução. Nosso sistema combina o aprendizado por transferência de um par de idiomas tcheco-inglês de alto recurso e retrotradução. Notamos um comportamento surpreendente ao usar dados sintéticos, o que possivelmente pode ser atribuído a um domínio restrito de dados de treinamento e teste. Estamos usando o modelo Transformer em uma submissão restrita.', 'es': 'Este artículo describe la presentación de CUNI a la tarea compartida de traducción de noticias del WMT 2020 para el escenario de bajos recursos Inuktitut: inglés en ambas direcciones de traducción. Nuestro sistema combina el aprendizaje por transferencia de una combinación de idiomas de alto recurso checo-inglés y la traducción inversa. Observamos un comportamiento sorprendente al utilizar datos sintéticos, que posiblemente se atribuyan a un dominio limitado de datos de entrenamiento y pruebas. Estamos utilizando el modelo Transformer en una presentación restringida.', 'ja': 'この論文では、低資源シナリオInuktitut - EnglishのWMT 2020ニュース翻訳共有タスクへのCuNi提出について両方の翻訳方向で説明します。当社のシステムは、チェコ語と英語のハイリソース言語のペアからの転送学習とバックトランスレーションを組み合わせています。私たちは、合成データを使用する際の驚くべき行動に気づきます。これは、トレーニングおよびテストデータの狭い領域に起因する可能性があります。制約のあるサブミッションでトランスフォーマーモデルを使用しています。', 'zh': '本文 CUNI 向 WMT 2020 新闻翻译共享两译向下资源场因纽特语 - 英语。 我们的系统合了捷克语- 英语高资源言语对的迁学反向译。 合用之时,留意可讶,盖归因于训练测试数据狭域也。 用 Transformer 范于约束提交中。', 'ru': 'В этой статье описывается представление CUNI для совместной задачи перевода новостей WMT 2020 для сценария с низким уровнем ресурсов Inuktitut–English в обоих направлениях перевода. Наша система сочетает в себе трансферное обучение из чешско-английской высокоресурсной языковой пары и обратный перевод. Мы замечаем удивительное поведение при использовании синтетических данных, которое, возможно, можно отнести к узкой области данных обучения и тестирования. Мы используем модель трансформатора в ограниченном представлении.', 'hi': 'यह पेपर दोनों अनुवाद दिशाओं में कम-संसाधन परिदृश्य Inuktitut-अंग्रेजी के लिए WMT 2020 समाचार अनुवाद साझा कार्य के लिए CUNI सबमिशन का वर्णन करता है। हमारी प्रणाली एक चेक-अंग्रेजी उच्च संसाधन भाषा जोड़ी और बैकट्रांसलेशन से स्थानांतरण सीखने को जोड़ती है। सिंथेटिक डेटा का उपयोग करते समय हम आश्चर्यजनक व्यवहार को नोटिस करते हैं, जिसे संभवतः प्रशिक्षण और परीक्षण डेटा के संकीर्ण डोमेन के लिए जिम्मेदार ठहराया जा सकता है। हम एक विवश सबमिशन में ट्रांसफॉर्मर मॉडल का उपयोग कर रहे हैं।', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht CUNI chuig Tasc Comhroinnte Aistriúcháin Nuachta WMT 2020 don chás íseal-acmhainne Ionúitis–Béarla sa dá threo aistriúcháin. Comhcheanglaíonn ár gcóras foghlaim aistrithe ó phéire teanga ard-acmhainne Seice-Béarla agus aisaistriúchán. Tugaimid faoi deara iompar iontasach agus sonraí sintéiseacha á n-úsáid, ar féidir é a chur i leith réimse cúng de shonraí oiliúna agus tástála. Táimid ag baint úsáide as an tsamhail Transformer in aighneacht shrianta.', 'ka': 'ამ დოკუმენტი CUNI-ს შეტყობინება WMT 2020 გასაგულისხმების გასაგულისხმების გასაგულისხმების გასაგულისხმების გასაგულისხმებისთვის, რომელიც მარტივი რესურსისურსის სინარიო ჩვენი სისტემა ჩემი ჩემი შექი-ანგლისური უფრო მეტი სისტემა და მეტი სისტემადან გადაწყება. ჩვენ დავხედავთ საინტერესო ქცევა, როდესაც სინტეტიკური მონაცემების გამოყენება, რომელიც შესაძლოა შეიძლება ატრიბუტირება სტრინტიკური და ტესტის მონაც ჩვენ გამოვიყენებთ ტრანფორმეტრის მოდელის შესაძლებლობით დარწყვებულია.', 'hu': 'Ez a tanulmány mindkét fordítási irányban ismerteti a CUNI benyújtását a WMT 2020 News Translation Shared Task számára az Inuktitut-English alacsony erőforrású forgatókönyv esetében. Rendszerünk ötvözi a cseh-angol nyelvpárból származó transzfer tanulást és a visszafordítást. Meglepő viselkedést észlelünk a szintetikus adatok használata során, amelyek esetleg a képzési és tesztadatok szűk területének tulajdoníthatók. A Transformer modellt használjuk korlátozott benyújtásban.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή του CUNI στην κοινή εργασία μετάφρασης ειδήσεων για το σενάριο χαμηλής περιεκτικότητας σε πόρους και στις δύο κατευθύνσεις μετάφρασης. Το σύστημά μας συνδυάζει την εκμάθηση μεταφοράς από ένα τσεχικό-αγγλικό γλωσσικό ζεύγος υψηλών πόρων και την αντίστροφη μετάφραση. Παρατηρούμε αιφνιδιαστική συμπεριφορά όταν χρησιμοποιούμε συνθετικά δεδομένα, τα οποία μπορεί ενδεχομένως να αποδοθούν σε ένα στενό πεδίο δεδομένων κατάρτισης και δοκιμών. Χρησιμοποιούμε το μοντέλο μετασχηματιστή σε μια περιορισμένη υποβολή.', 'it': "Questo articolo descrive la presentazione di CUNI al WMT 2020 News Translation Shared Task per lo scenario Inuktitut-English a basso contenuto di risorse in entrambe le direzioni di traduzione. Il nostro sistema combina l'apprendimento di trasferimento da una coppia di lingue ceco-inglese ad alta risorsa e la traduzione inversa. Si nota un comportamento sorprendente quando si utilizzano dati sintetici, che possono essere attribuiti a un ristretto dominio di dati di allenamento e test. Stiamo utilizzando il modello Transformer in un invio vincolato.", 'kk': 'Бұл қағаз WMT 2020 жаңалық аудармалар ортақтастырылған тапсырманы төмен ресурс сценариясының инуктитут- ағылшынша жіберілуін анықтайды. Біздің жүйеіміз Чех- ағылшын тілінен көп ресурс тілдерінен және backtranslation тілдерін біріктіреді. Синтетикалық деректерді қолданғанда біз қызық әрекеттерді көреміз. Бұл мүмкін оқыту мен сынақтар деректерінің қызық доменге арналған болуы мүмкін. Біз түрлендіруші үлгісін шектелгенде қолданамыз.', 'lt': 'Šiame dokumente apibūdinamas CUNI pateiktas WMT 2020 naujienų vertimo bendras uždavinys mažų išteklių scenarijui Inuktitut-English abiem vertimo kryptimis. Mūsų sistema derina mokymąsi iš čekų ir anglų kalbų, turinčių didelių išteklių, ir vertimą atgal. Mes pastebime stebintį elgesį naudojant sintetinius duomenis, kurie gali būti priskiriami siaurai mokymo ir bandymų duomenų sričiai. Mes naudojame Transformuotojo model į ribotam pateikimui.', 'mk': 'Овој весник го опишува поднесувањето на КУНИ на Делената задача за преведување на вести на WMT 2020 за сценариото со ниски ресурси Инуктитут-англиски во двете насоки. Нашиот систем комбинира трансфер на учење од чешко-англиски јазик со високи ресурси и грб-превод. Забележуваме изненадувачко однесување кога користиме синтетички податоци, кои можат да се припишат на тесна област на обука и тестирање податоци. We are using the Transformer model in a constrained submission.', 'ms': 'Kertas ini menggambarkan penghantaran CUNI ke Tugas Berkongsi Penerjemahan Berita WMT 2020 untuk skenario sumber rendah Inuktitut-English dalam kedua-dua arah terjemahan. Sistem kita menggabungkan pemindahan belajar dari pasangan bahasa bahasa Czech-Inggeris sumber tinggi dan terjemahan belakang. Kami memperhatikan perilaku yang mengejutkan bila menggunakan data sintetik, yang mungkin ditambah kepada domain sempit latihan dan data ujian. Kami menggunakan model Transformer dalam penghantaran terhalang.', 'ml': 'ഈ പത്രത്തില്\u200d വിവരിക്കുന്നത് WMT 2020 വിവരങ്ങളുടെ വിവരങ്ങളിലേക്ക് സിയുനിയെ വിവരമറിയിക്കുന്നു. വിവരങ്ങളിലേക്ക് കുറഞ്ഞ വിഭവങ് ഞങ്ങളുടെ സിസ്റ്റം ചെക്ക്-ഇംഗ്ലീഷ് ഹൈസ്രോസ്സ് ഭാഷ ജോടിയും ബാക്ക്ട്രിന്\u200dറര്\u200dഷനുമായി പഠിക്കുന സിന്തെറ്റിക് ഡേറ്റ ഉപയോഗിക്കുമ്പോള്\u200d അത്ഭുതപ്പെടുന്ന സ്വഭാവം ഞങ്ങള്\u200d കാണുന്നു. അത് പരീക്ഷ വിവരങ്ങള്\u200dക്കും ഒരു ചെ നിര്\u200dബന്ധിതമായ ഒരു കീഴടങ്ങില്\u200d ഞങ്ങള്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200d മോഡല്\u200d ഉപയോഗിക്കുന്നു.', 'mt': "Dan id-dokument jiddeskrivi s-sottomissjoni tal-CUNI lill-Ħidma Kondiviża tat-Traduzzjoni tal-Aħbarijiet tad-WMT 2020 għax-xenarju b’riżorsi baxxi Inuktitut-English fiż-żewġ direzzjonijiet tat-traduzzjoni. Is-sistema tagħna tgħaqqad it-tagħlim tat-trasferiment minn par ta’ lingwi b’riżorsi għoljin Ċek-Ingliż u t-traduzzjoni b’lura. Aħna ninnota mġiba sorprendenti meta nużaw dejta sintetika, li possibbilment tista’ tiġi attribwita għal qasam dejjaq ta’ taħriġ u dejta tat-testijiet. Qed nużaw il-mudell Transformer f'sottomissjoni ristretta.", 'mn': 'Энэ цаас WMT 2020 News Translation Shared Task for the low-resource scenario Inuktitut-English 2 directions in the CUNI submission to the WMT 2020 News Translation. Бидний систем Чех-Англи хэл дээд боловсруулагч хэл хоёр болон backtranslation-ээс суралцах үйл ажиллагааг нэгтгэдэг. Бид синтетик өгөгдлийг ашиглах үед гайхалтай үйл ажиллагааг анзаарсан. Энэ нь бага сургалт болон шалгалт өгөгдлийн талаар байж болох юм. Бид Трансформерийн загварыг хязгаарлагдсан даалгавраар ашиглаж байна.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie CUNI do WMT 2020 News Translation Shared Task dla scenariusza niskich zasobów Inuktitut-English w obu kierunkach tłumaczenia. Nasz system łączy naukę transferową z czesko-angielskiej pary językowej o wysokich zasobach i backtranslation. Zaskakujące zachowanie zauważamy podczas wykorzystywania danych syntetycznych, które można ewentualnie przypisać wąskiej dziedzinie danych treningowych i testowych. Używamy modelu Transformera w ograniczonej zgłoszeniu.', 'no': 'Denne papiret beskriver CUNI-tilføring til WMT 2020 News Translation Shared Task for the low-resource scenario Inuktitut-English in both translation directions. Sistemet vårt kombinerer læring av overføring frå ein tsjekkisk- engelsk høg- ressursspråk- par og tilbakeomsetjing. Vi merker på overraskende atferd når du brukar syntetiske data, som kan kanskje bli attribuert til ein liten område av opplæring og testdata. Vi brukar transformeringsmodellen i ein begrenset tilføring.', 'ro': 'Această lucrare descrie transmiterea CUNI la WMT 2020 News Translation Shared Task pentru scenariul cu resurse reduse Inuktitut-English în ambele direcții de traducere. Sistemul nostru combină învățarea transferului dintr-o pereche de limbi cehă-engleză cu resurse ridicate și traducerea înapoi. Observăm un comportament surprinzător atunci când utilizăm date sintetice, care poate fi atribuit unui domeniu îngust al datelor de antrenament și test. Utilizăm modelul Transformer într-o transmitere restricționată.', 'sr': 'Ovaj papir opisuje podnošenje CUNI na podnošenje WMT 2020 Novinskog prevoda zajedničkog zadatka za scenario s niskim resursima Inuktitut-engleski u oba smjera prevoda. Naš sistem kombinira prevoz učenja iz češkog-engleskog visokog jezika i prevoz nazad. Primijetimo iznenađujuće ponašanje kada koristimo sintetičke podatke, koje se moguće odnose na usku domenu obuke i test podataka. Koristimo model Transformer a u ograničenoj podnožbi.', 'so': 'Kanu warqaddan ayaa CUNI u dhiibay WMT 2020 News Translation Shared Task for the low-resource scenario Inuktitut-Ingiriis labada hagid. Isticmaddeenu wuxuu ka kooban karaa barashada luuqada sare ee Czech-Ingiriis laba nooc iyo backtranslation. Waxaynu fiirinnaa dabeecado yaab leh marka lagu isticmaalayo macluumaad la xiriira, taas oo suurtagal ah in lagu dhigo xafiiska waxbarashada iyo imtixaanka. Waxaynu ku isticmaalaynaa model turjumista oo qasab ah.', 'sv': 'Denna uppsats beskriver CUNI inlämnande till WMT 2020 News Translation Shared Task för lågresursscenariot Inuktitut-English i båda översättningsriktningarna. Vårt system kombinerar överföring av lärande från ett tjeckiskt-engelskt högresursspråkpar och backöversättning. Vi märker överraskande beteende när vi använder syntetiska data, vilket möjligen kan tillskrivas en smal domän av tränings- och testdata. Vi använder Transformer-modellen i en begränsad inlämning.', 'ta': '@ info எங்கள் அமைப்பு செக்- ஆங்கிலத்திலிருந்து கற்றத்தை மாற்றுதல் ஜோடி மற்றும் பின்மொழிபெயர்ப்பு நாம் ஒரு சிறிய பயிற்சி மற்றும் சோதனை தரவுகளை பயன்படுத்தும் போது ஆச்சரியமான நடத்தையை கவனிக்கும் போது, அது ஒரு சிறிய தளத்த நாம் கட்டுப்படுத்தப்பட்ட மாதிரியை பயன்படுத்துகிறோம்.', 'si': 'මේ පැත්තේ CUNI ප්\u200dරවේශනය විස්තර කරනවා WMT 2020වාර්තාව අවවාදය සම්බන්ධ වැඩසටහන් වැඩසටහන් විස්තර කරනවා අඩුම සම්බන්ධ සි අපේ පද්ධතිය සම්බන්ධ කරනවා චෙක්-ඉංග්\u200dරීසි භාෂාවක් වලින් අධ්\u200dයාත්මක භාෂාවක් සහ පස් අපි බලන්න පුළුවන් පුදුම ව්\u200dයාපෘතියක් සංවිධානය දත්ත භාවිත කරන්න, ඒක පුළුවන් පුළුවන් පුදුම සංවිධ අපි ප්\u200dරවර්තනයක් පාවිච්චි කරනවා අවධානයක් තියෙන්නේ.', 'ur': 'This paper describes CUNI submission to the WMT 2020 News Translation Shared Task for the low-resource scenario Inuktitut-English in both translation directions. ہماری سیستم نے چک-انگلیسی میں سے ایک بڑے سرمایہ کی زبان جوڑے اور پچھلی ترجمہ سے تعلیم کی ترجمہ کرتی ہے. ہم تعجب کرنے والی رفتار کو دیکھتے ہیں جب سینٹیسی ڈیٹی استعمال کرتے ہیں، جو شاید ایک تنگ ڈیٹی اور آزمائش ڈیٹی کے ذریعہ تدبیر کر سکتی ہے۔ ہم تغییر مدل کو ایک محدود مسلمانوں میں استعمال کر رہے ہیں.', 'uz': "Bu qogʻoz WMT 2020 News tarjima tarjima haqida CUNI tarjima qiladi. Bu ikkita tarjima tarjima tarjima bilan kichkina resource scenario Inuktitut- Inglizchaga tarjima qiladigan vazifani aytadi. @ info: whatsthis Biz bir qanchalik amalga oshirishimiz amalni ko'rib turamiz. Bu foydalanuvchi va tizim maʼlumotlarining qisqa domain va tizim maʼlumotiga ega bo'lishi mumkin. Biz qanday qanday submit qilish uchun Transformer modeldan foydalanamiz.", 'vi': 'Tờ giấy này mô tả việc nộp CUPS để nghe dịch bản tin WRT 2020 đã chia sẻ Nhiệm vụ cho kịch bản ít tài nguyên trong cả hai hướng dịch. Hệ thống của chúng tôi kết hợp việc học chuyển nhượng từ một cặp ngôn ngữ cao cấp Séc-Anh và backtranslation. Chúng ta thấy một hành động bất ngờ khi dùng các dữ liệu nhân giống, có thể được quỷ là một tập đoạn của tập luyện và thử kiểm tra. Chúng tôi đang sử dụng mô hình transformer trong giới hạn giới hạn.', 'bg': 'Настоящата статия описва представянето на КУНИ на споделената задача за превод на новини за сценария с ниски ресурси Инуктитут-английски в двете посоки на превода. Нашата система съчетава трансферно обучение от чешко-английска езикова двойка с висок ресурс и обратен превод. Забелязваме изненадващо поведение при използването на синтетични данни, което може да бъде приписано на тясна област от данни за обучение и тестове. Използваме модела на трансформатора при ограничено подаване.', 'hr': 'Ovaj papir opisuje predavanje CUNI-a u zajedničkom zadatku za prevod vijesti WMT 2020 za scenario s niskim resursima Inuktitut-English u oba smjera prevoda. Naš sustav kombinira prevoz učenja iz češkog-engleskog visokog jezika i prevoz nazad. Primijetimo iznenađujuće ponašanje kada koristimo sintetičke podatke, koje se vjerojatno može priključiti uskoj domenu obuke i ispitivanja podataka. Koristimo model Transformer a u ograničenoj podnožbi.', 'da': 'Dette dokument beskriver CUNI-indsendelse til WMT 2020 News Translation Shared Task for lav ressource scenariet Inuktitut-English i begge oversættelsesvejledninger. Vores system kombinerer overførsel af læring fra et tjekkisk-engelsk sprogpar med høj ressource og baggrundsoversættelse. Vi bemærker overraskende adfærd ved brug af syntetiske data, som muligvis kan tilskrives et snævert område af trænings- og testdata. Vi bruger Transformer modellen i en begrænset indsendelse.', 'nl': 'Dit artikel beschrijft CUNI inzending aan de WMT 2020 News Translation Shared Task voor het low-resource scenario Inuktitut-English in beide vertaalrichtingen. Ons systeem combineert transferleren van een Tsjechisch-Engels taalpaar met hoge resources en backtranslation. We merken verrassend gedrag bij het gebruik van synthetische data, wat mogelijk kan worden toegeschreven aan een smal domein van trainings- en testdata. We gebruiken het Transformer model in een beperkte inzending.', 'de': 'Dieser Beitrag beschreibt die CUNI-Einreichung an die WMT 2020 News Translation Shared Task für das ressourcenarme Szenario Inuktitut-English in beide Übersetzungsrichtungen. Unser System kombiniert Transferlernen von einem Tschechisch-Englisch High-Resource Sprachpaar und Rückübersetzung. Wir bemerken überraschendes Verhalten bei der Verwendung synthetischer Daten, was möglicherweise auf eine enge Domäne von Trainings- und Testdaten zurückgeführt werden kann. Wir verwenden das Transformer-Modell in einer eingeschränkten Einreichung.', 'id': 'Kertas ini menjelaskan pengiriman CUNI ke Tugas Berkongsi Translation Berita WMT 2020 untuk skenario sumber daya rendah Inuktitut-English dalam kedua arah terjemahan. Our system combines transfer learning from a Czech-English high-resource language pair and backtranslation.  Kami memperhatikan perilaku yang mengejutkan ketika menggunakan data sintetis, yang mungkin ditanggung oleh domain sempit latihan dan data tes. Kami menggunakan model Transformer dalam penyerahan yang terbatas.', 'ko': '본고는 CUNI가 두 가지 번역 방향에서 WMT 2020 뉴스 번역 공유 임무에 제출한 저자원 장면인 Inuktitut English를 묘사한다.우리의 시스템은 체코 영어 고자원 언어의 이동 학습과 반역을 결합시켰다.합성 데이터를 사용할 때 우리는 놀라운 행동을 발견했다. 이는 훈련과 테스트 데이터의 좁은 영역 때문일 수 있다.제한된 제출에서 Transformer 모델을 사용합니다.', 'fa': 'این کاغذ تسلیم CUNI را به ترجمه خبری WMT 2020 برای سناریو کم منابع انگلیسی توصیف می\u200cکند. سیستم ما یادگیری را از یک جفت زبان بالا و پشت ترجمه زبان چک و انگلیسی ترجمه می کند. ما رفتار تعجب کننده را در زمان استفاده از داده\u200cهای سناتیک متوجه می\u200cکنیم که احتمالاً می\u200cتواند به یک دامنه کوچک از آموزش و داده\u200cهای آزمایش تعریف شود. ما از مدل تغییر دهنده در یک تسلیم محدود استفاده می کنیم.', 'sw': 'Gazeti hili linaelezea ujumbe wa CUNI kwa Tafsiri ya Habari WMT 2020 ulishirikisha kazi kwa ajili ya kituo cha rasilimali cha chini cha Kiingereza kwa njia zote za kutafsiri. Mfumo wetu unaunganisha kuhamisha kujifunza kutoka lugha ya asili ya Kizech-English na tafsiri ya nyuma. Tunaona tabia za kushangaza wakati kwa kutumia taarifa za pamoja, ambazo inaweza kuwa na uwezekano wa kuwepo kwa mafunzo na taarifa za jaribio. Tunatumia muundo wa zamani katika ujumbe uliohusika.', 'sq': 'Ky artikull përshkruan paraqitjen e CUNI në detyrën e përbashkët të përkthimit të lajmeve WMT 2020 për skenarin me burime të ulëta Inuktitut-English në të dy drejtimet e përkthimit. Sistemi ynë kombinon transferimin e mësimit nga një çek-anglez çek-gjuhë me burime të larta dhe përkthimin mbrapsht. Ne vëmë re sjellje të befasueshme kur përdorim të dhëna sintetike, të cilat mund të atribuohen me një fushë të ngushtë trainimit dhe testimit të të dhënave. Ne po përdorim model in Transformer në një dorëzim të kufizuar.', 'tr': 'Bu kagyz CUNI WMT 2020 Haýsy terjime etmegini iki terjime edip Inuktitut-Iňlisçe senaryo üçin paýlaşýar Biziň sistemimiz Çehiň-iňlisçe ýokary iňlis dilleriniň çift we arka terjime edilmesinden öwrenmegi birleşýär. Sintetik maglumatlary ulananda şa şırtýan davranyşy düşünýäris. Bu mümkin edýän we synaglaryň gysga sahypa süýtgebilir. Biz çykyş ýüzünde Transformer nusgasyny ulanýarys.', 'af': "Hierdie papier beskrywe CUNI onderskrywing na die WMT 2020 Nuus Vertaling Deel Taak vir die lae- hulpbron scenario Inuktitut- Engels in beide vertaling rigtings. Ons stelsel kombinieer oordrag leer van 'n Tsjeggies- Engels hoë- hulpbron taal paar en terugvertaling. Ons kennis verwonderende gedrag wanneer sintetiese data gebruik word, wat moontlik aan 'n sterk domein van onderwerp en toets data aangegee kan word. Ons gebruik die Transformer model in 'n beperkte ondersteuning.", 'am': 'ይህ ገጽ በሁለቱም ትርጓሜዎች ውስጥ የዝናብ resource scenario Inuktitut-እንግሊዘኛ ወደWMT 2020 ዜናዎች ትርጉም እንዲሰጥ CUNI አቀራቢ ይናገራል፡፡ ስርዓታችን ከቻክክ-እንግሊዘኛ ከፍተኛ-resource ቋንቋ ሁለት እና backtranslation የተማርከውን ትምህርት ማቀናቀል ያስተካክላል፡፡ የሲንተቲካዊ ዳታዎችን በመጠቀም ጊዜ የሚደነቂውን ድርጊት እናሳየዋለን፡፡ ይህም ሊገልጽ እና ለድምጽ ዳታዎችን ለመጠቀም የሚችል ስልጣን ነው፡፡ በተገኘው አዋጅ ውስጥ የፊተኛውን ምሳሌ እንጠይቃለን፡፡', 'hy': 'Այս աշխատանքը նկարագրում է Cuնին ներկայացումը ԱՄՆ 2020-ի նորությունների թարգմանման համագործակցած հանձնարարության համար ցածր ռեսուրսների սցենարի համար՝ ինուկտիտուտ-անգլերեն երկու ուղղությամբ: Our system combines transfer learning from a Czech-English high-resource language pair and backtranslation.  We notice surprising behaviour when using synthetic data, which can be possibly attributed to a narrow domain of training and test data.  Մենք օգտագործում ենք Transforme մոդելը սահմանափակ ներկայացման մեջ:', 'az': 'Bu kańüńĪt WMT 2020 Haqq √áeviri ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįkinci ńįŇükil…ôrin…ô t…ô Sistemimiz √á…ôk-ńįngilizce dilind…ôn √∂yr…ônm…ôk √∂yr…ônm…ôsini v…ô geri √ßevirilm…ôsini birl…ôŇüdirir. Sintetik m…ôlumatlarńĪ istifad…ô ed…ôrk…ôn t…ô…ôcc√ľbl√ľ davranńĪŇülarńĪ g√∂rd√ľk. Bu m√ľmk√ľn olaraq t…ôhsil v…ô sńĪnama m…ôlumatlarńĪnńĪn qńĪsa bir domain il…ô bańülńĪ olar. Biz Transformer modelini m√ľ…ôyy…ôn edilmiŇü t…ôslimd…ô istifad…ô edirik.', 'bs': 'Ovaj papir opisuje predavanje CUNI-a u zajedničkom zadatku za prevod novina WMT 2020 za scenario s niskim resursima Inuktitut-English u oba smjera prevoda. Naš sistem kombinira prevoz učenja iz češkog-engleskog visokog jezika i prevoz nazad. Primijetimo iznenađujuće ponašanje kada koristimo sintetičke podatke, koje se vjerojatno može pridružiti uskoj domenu obuke i test podataka. Koristimo model Transformer a u ograničenoj podnožbi.', 'bn': 'এই পত্রিকা উইএমটি ২০২০ সংবাদ অনুবাদের দুই দিকে অনুবাদের দিকে সিইউএনআই ব্যাখ্যা করেছে। আমাদের সিস্টেম একটি চেক-ইংরেজী হাই-রিসোর্স ভাষা জোড়া এবং ব্যাক-অনুবাদের কাছ থেকে কিছু শিক্ষা নিয়ে স আমরা বিস্ময়কর আচরণ লক্ষ্য করি যখন সিন্টেটিক ডাটা ব্যবহার করে, যা সম্ভবত প্রশিক্ষণ এবং পরীক্ষা তথ্যের ক্ষেত্রে একটি সংকীর্ণ ডোম আমরা ট্রান্সফ্রান্সফার মডেল ব্যবহার করছি নির্ধারিত আত্মসমর্পণের মধ্যে।', 'cs': 'Tento článek popisuje podání CUNI do WMT 2020 News Translation Shared Task pro scénář s nízkými zdroji Inuktitut-English v obou směrech překladu. Náš systém kombinuje transferové učení z česko-anglického jazykového páru s vysokými zdroji a zpětný překlad. Při používání syntetických dat si všimneme překvapivého chování, které lze možná přičíst úzké oblasti tréninkových a testovacích dat. Používáme model Transformer v omezeném podání.', 'fi': 'Tässä artikkelissa kuvataan CUNI:n lähettämistä WMT 2020 News Translation Shared Task -ohjelmaan vähäresurssisen Inuktitut-English -skenaarion osalta molemmissa käännössuunnissa. Järjestelmämme yhdistää siirtooppimisen tšekki-englanti-high-resource kieliparilta ja takaisinkäännöksen. Synteettistä dataa käytettäessä huomaamme yllättävän käyttäytymisen, minkä voi mahdollisesti johtua harjoittelu- ja testidatan kapeasta osasta. Käytämme Transformer-mallia rajoitetussa lähetyksessä.', 'et': 'Käesolevas artiklis kirjeldatakse CUNI esitamist WMT 2020 uudiste tõlkimise jagatud ülesandele vähese ressursiga stsenaariumi Inuktitut-English puhul mõlemas tõlkesuunas. Meie süsteem ühendab siirdeõppe tšehhi-inglise suure ressursiga keelepaarilt ja tagasitõlke. Sünteetiliste andmete kasutamisel märkame üllatavat käitumist, mida võib seostada koolitus- ja testiandmete kitsa valdkonnaga. Me kasutame Transformeri mudelit piiratud esitamisel.', 'ca': "Aquest article descriu la presentació de CUNI a la tasca compartida de traducció de notícies de WMT 2020 per l'escenari de baix recursos Inuktitut-English en ambdues direccions de traducció. El nostre sistema combina l'aprenentatge de transfer ènciad'un parell de llenguatges de alta qualitat cec-anglès i la traducció inversa. Notem comportament sorprenent quan utilitzem dades sintètiques, que poden ser atribuïdes a un petit domini d'entrenament i proves. Estem utilitzant el model Transformer en una presentació limitada.", 'jv': "Pesene iki rambarang CUNI nggawe gerambut kanggo tarjamahan 'WAT 2020 Where's this text Sistem awak dhéwé ngerasai nglanggar tarjamahan kanggo Kepek-Inggris barang langgar tanggal karo perusahaan banter. We Notify sursurpresing gesture when use verb data, that can be attributed to a small domain of Learning and test data. Awak dhéwé nggambar model Transformer nang ngerasah dumadhi.", 'sk': 'Ta prispevek opisuje predložitev CUNI za skupno nalogo prevajanja novic WMT 2020 za scenarij z nizkimi viri Inuktitut-angleščina v obeh smereh prevajanja. Naš sistem združuje transferno učenje iz češko-angleškega jezikovnega pare z visokimi viri in nazaj prevajanje. Pri uporabi sintetičnih podatkov opazimo presenetljivo vedenje, kar je mogoče pripisati ozkemu obsegu podatkov o usposabljanju in testiranju. Model transformatorja uporabljamo v omejeni predložitvi.', 'ha': "Wannan takardan na describe CUNI Islam zuwa the WMT 2020 News Translate Shared Tajik for the lower-resource cenario Inuktit-English in both direction. translation Tuna gane aikin da za'a yi mãmãki idan za'a yi amfani da data na synthetisk, wanda za'a iya iya amfani da wani wuri mai ƙaranci wa danne na shirin da aka jarraba. Munã amfani da misãlai na farko a cikin Musulunci wanda ya lazimta.", 'he': "העיתון הזה מתאר את ההעברה של CUNI למשימה המשותפת לתרגום חדשות WMT 2020 לתרחיש משאבים נמוכים Inuktitut-English בשני הכיוונים התרגום. המערכת שלנו שולבת את ההעברה של לימודים משפת טצ'י-אנגלית עם משאבים גבוהים ותרגום אחורה. אנו מבחינים בהתנהגות מפתיעה כשמשתמשים בנתונים סינטטיים, שאפשר להזכיר לתחום צר של מידע אימון ובדיקות. We are using the Transformer model in a constrained submission.", 'bo': 'ཤོག་བྱང་འདིས་CUNI་ཡིས་WMT 2020་བརྙན་ཞིག་ལ་སྤྱི་ཚོགས་ཀྱི་ལས ང་ཚོའི་མ་ལག We notice surprising behavior when using synthetic data, which can be possibly attributed to a narrow domain of training and test data. ང་ཚོས་ཚད་འཛིན་གྱི་དབྱིབས་བཟོ་བྱེད་མཁན་གྱི་མ་དཔེ་དབྱིབས་བེད་སྤྱོད་ཀྱི་ཡོད།'}
{'en': 'Speed-optimized, Compact Student Models that Distill Knowledge from a Larger Teacher Model : the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'ar': 'نماذج الطالب المدمجة والمُحسّنة للسرعة والتي تستخلص المعرفة من نموذج المعلم الأكبر: إرسال UEDIN-CUNI إلى مهمة ترجمة الأخبار WMT 2020', 'pt': 'Modelos de alunos compactos e otimizados para velocidade que destilam conhecimento de um modelo de professor maior: o envio UEDIN-CUNI para a tarefa de tradução de notícias do WMT 2020', 'fr': "Modèles étudiants compacts et optimisés pour la vitesse qui distillent les connaissances d'un modèle d'enseignant plus large\xa0: la soumission UEDIN-CUNI à la tâche de traduction de nouvelles du WMT 2020", 'es': 'Modelos de estudiantes compactos y optimizados para la velocidad que destilan el conocimiento de un modelo docente más amplio: la presentación de la UEDIN-CUNI a la tarea de traducción de noticias del WMT 2020', 'ja': 'より大きな教師モデルから知識を抽出するスピード最適化されたコンパクトな学生モデル： WMT 2020ニュース翻訳タスクへのUEDIN - CUNI提出', 'ru': 'Оптимизированные по скорости компактные модели учащихся, которые отделяют знания от более крупной модели преподавателя: подача UEDIN-CUNI к задаче перевода новостей WMT 2020', 'hi': 'स्पीड-ऑप्टिमाइज़्ड, कॉम्पैक्ट छात्र मॉडल जो एक बड़े शिक्षक मॉडल से ज्ञान को डिस्टिल करते हैं: WMT 2020 समाचार अनुवाद कार्य के लिए UEDIN-CUNI सबमिशन', 'zh': '从大教师模中提炼知识的速度优化、紧凑的学生模形,向 WMT 2020 新闻译职提交的 UEDIN-CUNI', 'ga': 'Múnlaí Dlúth-optamaithe, Luasmhéadaithe do Dhaltaí a Dhriogadh Eolas ó Mhúinteoir Níos Mó: Aighneacht UEDIN-CUNI chuig Tasc Aistriúcháin Nuacht WMT 2020', 'ka': 'სტუდენტიკური მოდელები, რომლებიც უფრო დიდი სტუდენტიკური მოდელიდან განსხვავებული მეცნიერება: UEDIN-CUNI სტუდენტი WMT 2020 ახალგაზრულების განსხვავება', 'hu': 'Sebességoptimalizált, kompakt diákmodellek, amelyek megkülönböztetik a tudást egy nagyobb tanármodellből: az UEDIN-CUNI beküldése a WMT 2020 Hírek Fordítási feladat', 'el': 'Βελτιστοποιημένα με ταχύτητα, συμπαγή μοντέλα μαθητών που διαχωρίζουν τη γνώση από ένα μεγαλύτερο μοντέλο δασκάλων: η υποβολή στο έργο μετάφρασης ειδήσεων', 'kk': 'Жылдамдық оптимизацияланған, үлкен ұстаздар үлгісінен білімділікті ұстаздардың компьютер үлгілері: WMT 2020 жаңалық аудару тапсырмасына UEDIN- CUNI жіберу', 'it': 'Modelli studenteschi compatti ottimizzati per la velocità che distillano le conoscenze da un modello di insegnante più grande: la presentazione UEDIN-CUNI al WMT 2020 News Translation Task', 'mk': 'Брзина оптимизирани, компактни студентски модели кои ги отстрануваат знаењата од поголем учителски модел: Предавањето на УЕДИН-КУНИ на задачата за преведување на вестите на WMT 2020', 'lt': 'Speed-optimized, Compact Student Models that Distill Knowledge from a Larger Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'ml': 'ഒരു വലിയ ടീച്ചര്\u200d മോഡലില്\u200d നിന്നും വേഗത്തില്\u200d നിന്നും പരിജ്ഞാനം വിതരണം ചെയ്യുന്ന വിദ്യാര്\u200dത്ഥ മോഡലുകള്\u200d: WMT 2020 വിവരങ്ങളുടെ വിവരങ്ങള്\u200d', 'ms': 'Model Pelajar Kompat yang Optimasi Kelajuan yang Menjauhkan Pengetahuan dari Model Guru Lebih Besar: Submission UEDIN-CUNI ke Tugas Terjemahan Berita WMT 2020', 'mt': 'Speed-optimized, Compact Student Models that Distill Knowledge from a Larger Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'mn': 'Хурдан сайжруулсан, том багш загварын шинжлэх ухааны төлөвлөгч загварууд: UEDIN-CUNI WMT 2020 News Translation Task', 'no': 'Fart-optimaliserte, kompakte studentmodeller som Distill Knowledge frå ein større læringsmodell: UEDIN-CUNI Submission til WMT 2020 News Translation Task', 'pl': 'Zoptymalizowane szybkość, kompaktowe modele studenckie, które dystrybuują wiedzę z większego modelu nauczyciela: zgłoszenie UEDIN-CUNI do WMT 2020 Aktualności Tłumaczenie', 'ro': 'Modele studențești compacte optimizate pentru viteză, care disting cunoștințele dintr-un model de profesor mai mare: depunerea UEDIN-CUNI la WMT 2020 Știri Sarcina de traducere', 'sr': 'Optimizirani brzinom, kompaktni studentski modeli koji su iskrivljeni znanje iz model većeg učitelja: podmission UEDIN-CUNI za prijevod novosti WMT 2020', 'si': 'වේගය හොඳයි, සම්ප්\u200dරේක්ට් විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපි', 'so': 'Speed-optimized, Compact Student Models that Distill Knowledge from a Larger Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'sv': 'Hastighetsoptimerade, kompakta studentmodeller som skiljer kunskap från en större lärarmodell: UEDIN-CUNI Inlämning till WMT 2020 Nyheter Översättningsuppgift', 'ta': 'பெரிய ஆசிரியர் மாதிரியிலிருந்து அறிவை வெளியேற்றும் வேகமாக மாற்றும் மாணவர் மாதிரிகளின் மாதிரிகள்: WMT 2020 செய்தி மொழிபெயர்ப்பு', 'ur': 'Speed-optimized, Compact Student Models that Distill Knowledge from a Larger Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'uz': 'Name', 'vi': 'Tốc độ, Chế độ Sinh viên Compact mà phân biệt sự hiểu biết từ một mô hình sư phụ lớn hơn: Sự Phục tùng của LHQ đến Nhiệm vụ dịch Tin tức WRT 2020', 'nl': 'Snelheidsgeoptimaliseerde, compacte studentenmodellen die kennis van een groter lerarenmodel distilleren: de UEDIN-CUNI inzending aan de WMT 2020 Nieuws Vertaaltaak', 'bg': 'Оптимизирани за скорост, компактни студентски модели, които извличат знания от по-голям модел на учител: представянето на задачата за превод на новини', 'da': 'Hastighedsoptimerede, kompakte studerende modeller, der adskiller viden fra en større lærermodel: UEDIN-CUNI Indsendelse til WMT 2020 Nyheder Oversættelsesopgave', 'de': 'Geschwindigkeitsoptimierte, kompakte Schülermodelle, die Wissen aus einem größeren Lehrermodell destillieren: die UEDIN-CUNI-Einreichung beim WMT 2020 News Übersetzungsaufgabe', 'hr': 'Optimizirani brzinom, kompaktni učenički modeli koji su iskrivljeni znanje iz model većeg učitelja: podatak UEDIN-CUNI na zadatak za prevod vijesti WMT 2020.', 'id': 'Model mahasiswa yang dipotomatisasi dengan kecepatan dan kompakt yang menjauhkan pengetahuan dari Model Guru Lebih Besar: Submission UEDIN-CUNI ke Tugas Translation Berita WMT 2020', 'tr': 'Häzirki Görniş Opşenler, Compact Students Models that Distill Knowledge from a Large Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'ko': '더 큰 교사 모델에서 지식을 추출할 수 있도록 최적화된 학생 모델: UEDIN-CUNI가 WMT 2020 뉴스 번역 임무에 제출', 'fa': 'مدل دانش آموزان با سرعت optimized, Compact Students that Distill Knowledge from a Larger Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'sq': 'Modelet e nxënësve të optimizuar me shpejtësi dhe kompakti që i largojnë njohuritë nga një model më i madh mësues: dërgimi i UEDIN-CUNI në detyrën e përkthimit të lajmeve WMT 2020', 'am': 'Speed-optimized, Compact Student Models that Disorder Knowledge from a Larger Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'sw': 'Mradi wa haraka, Mradi wa wanafunzi wa kompyuta unaosababisha maarifa kutoka kwenye Modeli ya Mwalimu Mkubwa: UEDIN-CUNI Kutumiwa UEDIN-CUNI kwa kazi ya Tafsiri ya Habari za WMT 2020', 'hy': 'Աշակերտների արագությամբ օպտիմացված, համեմատ մոդելներ, որոնք տարածում են գիտելիքը ավելի մեծ ուսուցիչ մոդելի միջոցով՝ UEdin-Cuնին ներկայացնելու աշխարհի 2020 նորությունների թարգմանման խնդիրը', 'bs': 'Optimizirani brzinom, kompaktni učenički modeli koji su iskrivljeni znanje iz model većeg učitelja: podatak UEDIN-CUNI na zadatak za prevod vijesti WMT 2020.', 'af': "Spoed-optimaliseer, kompakte Studente Modelle wat Distill Knowledge van 'n Groot onderwyser Model: die UEDIN-CUNI Submission na die WMT 2020 Nuus Vertaling Taak", 'cs': 'Rychlost optimalizované, kompaktní studentské modely, které distilují znalosti z většího učitelského modelu: UEDIN-CUNI podání do WMT 2020 Novinky Překladatelská úloha', 'et': 'Kiirusega optimeeritud, kompaktsed õpilasmudelid, mis eristavad teadmisi suuremast õpetajamudelist: UEDIN-CUNI esitamine WMT 2020 Uudiste tõlke ülesanne', 'bn': 'ব্যাপক শিক্ষক মডেল থেকে জ্ঞান নিষিদ্ধ করা হয়েছে: উইডিন-সিউনি-সাবিমিশন উইএমটি ২০২০ সংবাদ অনুবাদ করার কাজ', 'az': 'Hızlı-optimizləndirilmiş, Büyük Muhəmmədçi Modelindən Bilinməli Kompakt Öğrenci Modelləri: WMT 2020 Haqq Çeviri Gözəli UEDIN-CUNI Submission', 'ca': "Models d'estudiants compactes i optimitzats amb velocitat que dissimulen el coneixement d'un model d'ensenyador més gran: la Submissió UEDIN-CUNI a la tasca de traducció de notícies WMT 2020", 'fi': 'Nopeus-optimoidut, kompaktit opiskelijamallit, jotka erottavat tietoa suuremmasta opettajamallista: UEDIN-CUNI-julkaisu WMT 2020 -uutisten käännöstyökalulle', 'jv': 'Speed', 'sk': 'Hitrost optimizirani, kompaktni študentski modeli, ki ločijo znanje iz modela večjih učiteljev: predložitev UEDIN-CUNI na nalogo prevajanja novic WMT 2020', 'he': 'Speed-optimized, Compact Student Models that Distill Knowledge from a Larger Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task', 'ha': '@ action: button', 'bo': 'Speed-optimized Compact Student Models that Distill Knowledge from a Larger Teacher Model: the UEDIN-CUNI Submission to the WMT 2020 News Translation Task'}
{'en': 'We describe the joint submission of the University of Edinburgh and Charles University, Prague, to the Czech / English track in the WMT 2020 Shared Task on News Translation. Our fast and compact student models distill knowledge from a larger, slower teacher. They are designed to offer a good trade-off between translation quality and inference efficiency. On the WMT 2020 Czech   English test sets, they achieve translation speeds of over 700 whitespace-delimited source words per second on a single CPU thread, thus making neural translation feasible on consumer hardware without a GPU.', 'ar': 'نصف التقديم المشترك لجامعة إدنبرة وجامعة تشارلز في براغ إلى المسار التشيكي / الإنجليزي في المهمة المشتركة WMT 2020 حول ترجمة الأخبار. تعمل نماذج الطلاب السريعة والمضغوطة لدينا على استخلاص المعرفة من مدرس أكبر وأبطأ. وهي مصممة لتقديم مفاضلة جيدة بين جودة الترجمة وكفاءة الاستدلال. في مجموعات اختبار WMT 2020 Czech-English ، حققوا سرعات ترجمة تزيد عن 700 كلمة مصدر محددة بمسافات بيضاء في الثانية على مؤشر ترابط واحد لوحدة المعالجة المركزية ، مما يجعل الترجمة العصبية ممكنة على الأجهزة الاستهلاكية بدون وحدة معالجة الرسومات.', 'es': 'Describimos la presentación conjunta de la Universidad de Edimburgo y la Universidad Charles de Praga a la sección checo/inglés en la tarea compartida sobre traducción de noticias del WMT 2020. Nuestros modelos de estudiantes rápidos y compactos destilan el conocimiento de un profesor más grande y lento. Están diseñados para ofrecer una buena compensación entre la calidad de la traducción y la eficiencia de la inferencia. En los conjuntos de pruebas de inglés WMT 2020 Czech ↔, alcanzan velocidades de traducción de más de 700 palabras fuente delimitadas por espacios en blanco por segundo en un solo subproceso de CPU, lo que posibilita la traducción neuronal en hardware de consumo sin una GPU.', 'pt': 'Descrevemos a apresentação conjunta da Universidade de Edimburgo e da Universidade Charles, Praga, para a faixa tcheco/inglês na Tarefa Compartilhada do WMT 2020 sobre Tradução de Notícias. Nossos modelos de alunos rápidos e compactos destilam o conhecimento de um professor maior e mais lento. Eles são projetados para oferecer um bom equilíbrio entre qualidade de tradução e eficiência de inferência. Nos conjuntos de testes WMT 2020 Czech ↔ English, eles atingem velocidades de tradução de mais de 700 palavras de origem delimitadas por espaços em branco por segundo em um único thread de CPU, tornando a tradução neural viável em hardware de consumidor sem uma GPU.', 'fr': "Nous décrivons la soumission conjointe de l'Université d'Édimbourg et de l'Université Charles de Prague au volet tchèque/anglais dans le cadre de la tâche partagée WMT 2020 sur la traduction des actualités. Nos modèles étudiants rapides et compacts distillent les connaissances d'un enseignant plus grand et plus lent. Ils sont conçus pour offrir un bon compromis entre la qualité de la traduction et l'efficacité de l'inférence. Sur les ensembles de tests WMT 2020 Czech ↔ English, ils atteignent des vitesses de traduction de plus de 700 mots sources séparés par des espaces blancs par seconde sur un seul thread de processeur, rendant ainsi la traduction neuronale réalisable sur du matériel grand public sans processeur graphique.", 'ja': 'WMT 2020のニュース翻訳に関する共有タスクで、エディンバラ大学とプラハのチャールズ大学がチェコ語/英語のトラックに共同提出したことについて説明します。当社の高速でコンパクトな学生モデルは、より大きな、より遅い教師からの知識を抽出します。これらは、翻訳品質と推論効率の間に良いトレードオフを提供するように設計されています。WMT 2020チェコ↔語テストセットでは、1つのCPUスレッドで毎秒700以上の空白区切りのソースワードの翻訳速度を達成し、GPUなしのコンシューマーハードウェアでニューラル翻訳を実現します。', 'hi': 'हम एडिनबर्ग विश्वविद्यालय और चार्ल्स विश्वविद्यालय, प्राग के संयुक्त प्रस्तुतीकरण का वर्णन करते हैं, समाचार अनुवाद पर डब्ल्यूएमटी 2020 साझा कार्य में चेक / अंग्रेजी ट्रैक के लिए। हमारे तेज और कॉम्पैक्ट छात्र मॉडल एक बड़े, धीमे शिक्षक से ज्ञान को डिस्टिल करते हैं। वे अनुवाद गुणवत्ता और अनुमान दक्षता के बीच एक अच्छा व्यापार-बंद की पेशकश करने के लिए डिज़ाइन किए गए हैं। डब्ल्यूएमटी 2020 चेक ↔ अंग्रेजी परीक्षण सेट पर, वे एक सीपीयू थ्रेड पर प्रति सेकंड 700 से अधिक व्हाइटस्पेस-सीमांकित स्रोत शब्दों की अनुवाद गति प्राप्त करते हैं, इस प्रकार जीपीयू के बिना उपभोक्ता हार्डवेयर पर तंत्रिका अनुवाद संभव बनाते हैं।', 'zh': '述爱丁堡大学与布拉格查理大学于WMT 2020新闻译共事捷克语/英语轨道之合提。 吾徒趋凑从更大,更迟师处提炼出知识。 其旨在译质推理效率之间。 WMT 2020捷克↔英语试集上之,其成于单CPU线程每秒过于700空格隔之源单词,使神经译于无GPU之消费类硬件可也。', 'ru': 'Мы описываем совместное представление Эдинбургского университета и Карлова университета, Прага, на чешско-английский трек в совместной задаче WMT 2020 по переводу новостей. Наши быстрые и компактные модели учащихся отталкивают знания от более крупного, медленного учителя. Они предназначены для того, чтобы предложить хороший компромисс между качеством перевода и эффективностью вывода. На тестовых наборах WMT 2020 Czech ↔ English они достигают скорости перевода более 700 исходных слов с разделителями пробелов в секунду на одном потоке процессора, что делает нейронный перевод возможным на потребительском оборудовании без графического процессора.', 'ga': 'Déanaimid cur síos ar chomh-aighneacht Ollscoil Dhún Éideann agus Ollscoil Charles, Prág, chuig an rian Seiceach/Béarla i dTasc Comhroinnte WMT 2020 ar Aistriúchán Nuachta. Déanann ár múnlaí mac léinn tapa agus dlúth eolas ó mhúinteoir níos mó agus níos moille a dhriogadh. Tá siad deartha chun comhbhabhtáil mhaith a thairiscint idir cáilíocht an aistriúcháin agus éifeachtúlacht tátail. Ar thacair tástála Béarla WMT 2020 Seice ↔, baineann siad amach luasanna aistriúcháin os cionn 700 focal foinse teoranta spás bán in aghaidh an tsoicind ar aon snáithe LAP amháin, rud a fhágann go bhfuil aistriúchán néarach indéanta ar chrua-earraí tomhaltóra gan GPU.', 'ka': 'ჩვენ აღწერეთ ვებინდონის და ფარლისური სუნივერტის პრაგის შესახებ, ჩემი ჩემი/ანგლისური სიტყვაში WMT 2020-ის გაყოფილი საზოგადოების შესახებ. ჩვენი სტუდენტის მადელები ძალიან და კომპექტირებული სტუდენტის მეცნიერებას უფრო დიდ, ბალმად სტუდენტიდან განსხვავებენ. ისინი განსაზღვრებულია, რომ გადაწყვეტილების კალგატი და ინფრენციის ეფექციურობის შორის კალგატი გადაწყვეტილება. WMT 2020 ფექური ტესტის შესახებ, ისინი 700 სიტყვების განსხვავებული სიტყვების განსხვავებული სიტყვების განსხვავებული სიტყვების განსხვავება წუთში ერთი CPU სიტყვებში, ამიტომ იქნება ნეიროლური განსხვავება მომხმარებელ', 'hu': 'Az Edinburgh-i Egyetem és a Prágai Károly Egyetem közös benyújtását ismertetjük a WMT 2020 Shared Task on News Translation című cseh/angol pályára. Gyors és kompakt diákmodelleink egy nagyobb, lassabb tanár tudását lepárolják. Úgy tervezték, hogy jó kompromisszumot biztosítsanak a fordítási minőség és a következtetések hatékonysága között. A WMT 2020 cseh angol tesztkészleteken másodpercenként több mint 700 fehér térben határolt forrásszó fordítási sebességet érnek el egyetlen CPU szálon, így az idegi fordítás megvalósítható a fogyasztói hardvereken GPU nélkül.', 'el': 'Περιγράφουμε την κοινή υποβολή του Πανεπιστημίου του Εδιμβούργου και του Πανεπιστημίου του Κάρολου της Πράγας στο τσεχικό/αγγλικό κομμάτι στην κοινή εργασία για τη μετάφραση ειδήσεων. Τα γρήγορα και συμπαγή μοντέλα μαθητών μας αποσταλούν τη γνώση από έναν μεγαλύτερο, αργότερο δάσκαλο. Έχουν σχεδιαστεί για να προσφέρουν μια καλή ανταλλαγή μεταξύ της ποιότητας της μετάφρασης και της αποτελεσματικότητας των συμπερασμάτων. Στα σετ δοκιμών τσεχικών αγγλικών επιτυγχάνουν ταχύτητες μετάφρασης άνω των 700 λέξεων πηγής ανά δευτερόλεπτο σε ένα μόνο νήμα καθιστώντας έτσι εφικτή τη νευρωνική μετάφραση σε καταναλωτικό υλικό χωρίς GPU.', 'it': "Descriviamo la presentazione congiunta dell'Università di Edimburgo e della Charles University di Praga alla traccia ceco/inglese nel WMT 2020 Shared Task on News Translation. I nostri modelli di studenti veloci e compatti distillano la conoscenza da un insegnante più grande e più lento. Sono progettati per offrire un buon compromesso tra qualità di traduzione e efficienza di inferenza. Sui set di test WMT 2020 Czech English raggiungono velocità di traduzione di oltre 700 parole sorgente delimitate da spazi bianchi al secondo su un singolo thread CPU, rendendo così possibile la traduzione neurale su hardware consumer senza GPU.", 'mk': 'We describe the joint submission of the University of Edinburgh and Charles University, Prague, to the Czech/English track in the WMT 2020 Shared Task on News Translation.  Нашите брзи и компактни студентски модели го дестилираат знаењето од поголем, побавен учител. Тие се дизајнирани за да нудат добра размена помеѓу квалитетот на преводот и ефикасноста на конференцијата. На англиските тестови на ВМТ 2020, тие постигнуваат брзина на превод од повеќе од 700 изворни зборови на бел простор за секунда на една процесорска жица, со што нервниот превод ќе биде остварлив на потрошувачката хардвера без ГПУ.', 'kk': 'Біз Эдинбург және Чарльз Университетінің, Праг, WMT 2020 жаңалық аудармасындағы ортақ тапсырманы Чех/Ағылшын тізіміне жалғастырып тастадық. Біздің жылдам және сәйкес студенттердің моделдеріміз білімдерді үлкен, баяу мұғалімдерден айырады. Олар аудармалардың сапасы мен көпшіліктердің арасындағы жақсы тәртіпсіздігін көрсету үшін құрылған. WMT 2020 жылы чех тізімінде, ағылшын тізімінің аудармаларының жылдамдығы бір процессордың ілеспе бір секундта 700 бос орын шектелген көздегі сөздерді бір секундта жеткізеді, сондықтан GPU жоқ пайдаланушылардың жабдықтарына неврал', 'lt': 'We describe the joint submission of the University of Edinburgh and Charles University, Prague, to the Czech/English track in the WMT 2020 Shared Task on News Translation.  Mūsų greiti ir kompaktiniai student ų modeliai distiliuoja žinias iš didesnio, lėtesnio mokytojo. Jos skirtos užtikrinti gerą vertimo kokybės ir išvadų efektyvumo tarpusavio suderinimą. On the WMT 2020 Czech   English test sets, they achieve translation speeds of over 700 whitespace-delimited source words per second on a single CPU thread, thus making neural translation feasible on consumer hardware without a GPU.', 'ms': 'Kami menggambarkan penghantaran bersama Universiti Edinburgh dan Universiti Charles, Praha, ke trek Cek/Inggeris dalam Tugas Berkongsi WMT 2020 pada Penerjemahan Berita. Model pelajar kita yang cepat dan sempit menghasilkan pengetahuan dari guru yang lebih besar dan lebih lambat. Mereka direka untuk menawarkan perdagangan yang baik antara kualiti terjemahan dan kesudahan kesimpulan. Pada set ujian Bahasa Inggeris WMT 2020 Czech, mereka mencapai kelajuan terjemahan lebih 700 perkataan sumber yang dibenarkan ruang putih per saat pada benang CPU tunggal, sehingga terjemahan saraf boleh dilakukan pada perkakasan pengguna tanpa GPU.', 'ml': 'ഞങ്ങള്\u200d എഡിന്\u200dബര്\u200dഗിന്\u200dറെയും ചാര്\u200dള്\u200dസ് യൂണിറ്റിവേഴ്സിറ്റിയിലേയ്ക്കും വിവരിച്ചുകൊടുക്കുന്നു. വിവരങ്ങള്\u200d വിവരങ്ങളില്\u200d വെച്ച്/ഇം നമ്മുടെ വേഗത്തിലും വിദ്യാര്\u200dത്ഥികളുടെ മോഡലുകളും ഒരു വലിയ, പതുക്കെ ടീച്ചറില്\u200d നിന്നും അറിവ് വ്യത്യസ് പരിഭാഷക്കുറിച്ചുള്ള വ്യവസ്ഥയ്ക്കും അപകടത്തിനുമിടയില്\u200d നല്ല വ്യാപാര്\u200dത്തകം കൊടുക്കാനാണ് അവര്\u200d സൃ WMT 2020 ചെക്ക്- ഇംഗ്ലീഷ് പരീക്ഷണ സജ്ജീകരണങ്ങളില്\u200d, ഒരു സിപിയു ത്രീഡില്\u200d ഏകദേശം 700 വെളുത്ത വെളുത്ത വാക്കുകളുടെ വേഗത്തില്\u200d അവര്\u200d പരിഭാഷപ്പെടുത്തുന്നു. അതുക', 'mt': 'Aħna niddeskrivu s-sottomissjoni konġunta tal-Università ta’ Edinburgh u l-Università ta’ Charles, Praga, għat-triq Ċeka/Ingliża fil-Kompitu Konġunt tad-WMT 2020 dwar it-Traduzzjoni tal-Aħbarijiet. Our fast and compact student models distill knowledge from a larger, slower teacher.  Huma mfassla biex joffru kompromess tajjeb bejn il-kwalità tat-traduzzjoni u l-effiċjenza tal-inferenza. On the WMT 2020 Czech   English test sets, they achieve translation speeds of over 700 whitespace-delimited source words per second on a single CPU thread, thus making neural translation feasible on consumer hardware without a GPU.', 'mn': 'Бид Эдинбургийн, Чарльз Их Сургууль, Прага, Чех/Англи хэлбэрээр WMT 2020-ийн Хувьсан Үйлдлийн хуваалтын ажлыг тайлбарлаж байна. Бидний хурдан болон хамтран сурагчдын загварууд илүү удаан багш нараас мэдлэгийг ялгадаг. Тэд хөрөнгө оруулах чадвар болон халдварын үр дүнтэй хоорондох сайн худалдааны тусламжтайгаар зохион байгуулагдсан. WMT 2020 оны Чехид Англи хэлний тестийн хувьд нэг секундэд 700 гаруй орон зайд хуваагдсан эх үүсвэрийн үгнүүд хүртдэг. Иймээс хэрэглэгчийн техник хангамжийн тухай GPU-гүй мэдрэлийн хөрөнгө оруулах боломжтой болгодог.', 'no': 'Vi beskriver den samanlige oppføringa av Universiteten i Edimburg og Charles University, Prag, til den tsjekkiske/engelske sporen i WMT 2020 delte oppgåva om nyhetssomsetjinga. Våre raske og komprimerte studentmodeller distiller kunnskap frå ein større, langsomre lærar. Dei er designert for å tilbygge ein god utvikling mellom omsetjingskvalitet og infeksjonsfeilighet. På WMT 2020-testen av engelsk og tsjekkisk, oppnår dei omsetjingsfart med over 700 kjeldeord med mellomrom per sekund på ein enkel CPU-tråd, slik at det gjer neuralt omsetjing feilig på brukaravhengighet utan GPU.', 'pl': 'Opisujemy wspólne zgłoszenie Uniwersytetu Edynburga i Uniwersytetu Karola w Pradze do toru czesko-angielskiego w ramach WMT 2020 Shared Task on News Translation. Nasze szybkie i kompaktowe modele studenckie destylują wiedzę od większego, wolniejszego nauczyciela. Mają one na celu zapewnienie dobrego kompromisu między jakością tłumaczenia a efektywnością wnioskowania. W zestawach testowych WMT 2020 Czeski język angielski osiągają one szybkość tłumaczenia ponad 700 słów źródłowych rozdzielonych białą przestrzenią na sekundę na jednym wątku procesora, dzięki czemu tłumaczenie neuronowe jest możliwe na sprzęcie konsumenckim bez GPU.', 'ro': 'Descriem depunerea comună a Universității din Edinburgh și a Universității Charles din Praga la pista cehă/engleză în cadrul misiunii partajate WMT 2020 privind traducerea știrilor. Modelele noastre rapide și compacte de studenți distilează cunoștințele de la un profesor mai mare și mai lent. Acestea sunt concepute pentru a oferi un compromis bun între calitatea traducerii și eficiența deducerii. Pe seturile de testare WMT 2020 în limba engleză cehă, acestea ating viteze de traducere de peste 700 de cuvinte sursă delimitate de spații albe pe secundă pe un singur fir de procesor, făcând astfel traducerea neurală fezabilă pe hardware-ul consumatorilor fără GPU.', 'sr': 'Mi opisujemo zajedničku predanost Univerziteta Edinburga i Čarlsa Univerziteta, Praga, na češki/engleski trag na podjelnom zadatku WMT 2020 o prevodu novina. Naši brzi i komplektni studentski modeli razlikuju znanje od većeg, sporijeg učitelja. Oni su dizajnirani kako bi ponudili dobru trgovinu između kvalitete prevođenja i efikasnosti infekcije. Na češkim testovima WMT 2020. na engleskom nastavu postižu brzinu prevođenja preko 700 izvora riječi na sekundu na jednom nivou CPU-a, tako da je neuralno prevođenje moguće na hardver potroša ča bez GPU.', 'si': 'අපි ඇඩින්බ්\u200dරින්ග් වල ප්\u200dරාග් විශ්වාසිත්තාව සහ චාර්ල්ස් විශ්වාසිත්තාව, චෙක්/ඉංග්\u200dරීසි ට්\u200dරැක්ස් වල WMT 2020ව අපේ ඉක්මනින් හා සම්පූර්ණ විද්\u200dයාර්ථික විද්\u200dයාර්ථික විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපි ඔවුන් හොඳ ව්\u200dයාපාරයක් දෙන්න සිද්ධ වෙලා තියෙන්නේ, අවවාද ක්\u200dරියාත්මක සහ අපරාධ ක්\u200dරියා WMT 2020යි චෙක් වලින් ∙ ඉංග්\u200dරීසි පරීක්ෂණ සෙට් වලින්, ඔවුන් පරීක්ෂණ වේගය 700 ක් වඩා සුදුස්ථ ප්\u200dරමාණයක් තියෙන්නේ ප්\u200dරමාණයක් තියෙන්නේ', 'so': 'Waxaynu u qoraynaa wadajirka u soo diritaanka jaamacadda Edinburgh iyo Charles University, Prague, xagga koox/Ingiriis-track in the WMT 2020 Shared Task on News Translation. Tusaaleheenna dhaqso iyo isbardhiga ardayda waxay aqoonta ka kala duwan yihiin macallinka ka weyn ee gaaban. Waxaa loogu talogalay in la siiyo ganacsi wanaagsan oo u dhexeeya takhasuska turjumidda iyo waxyaabaha la’aanta. WMT 2020 Czech > Imtixaanka ingiriisiga, waxay gaadhaan fasaxa turjumaadda oo ka badan 700 whitespace-delimited sources words per second on a single CPU thread, thereby making neural translation possible on consumer hardware without a GPU.', 'sv': 'Vi beskriver den gemensamma inlämningen av University of Edinburgh och Charles University, Prag, till den tjeckiska/engelska spåret i WMT 2020 Shared Task on News Translation. Våra snabba och kompakta studentmodeller destillerar kunskap från en större, långsammare lärare. De är utformade för att erbjuda en bra avvägning mellan översättningskvalitet och inferenseffektivitet. På WMT 2020:s tjeckiska engelska testuppsättningar uppnår de översättningshastigheter på över 700 blanksteg-avgränsade källord per sekund på en enda processortråd, vilket gör neuralöversättning möjlig på konsumenthårdvara utan GPU.', 'ta': 'நாம் எடின்பர்க் மற்றும் சார்லஸ் கல்வியூரிக்கத்தின் இணைய வழிமுறையை விவரிக்கிறோம், செக்/ஆங்கிலத்தின் மொழிமாற்றியில் WMT 2020 பகிர எங்கள் வேகம் மற்றும் ஒப்பிடும் மாணவர் மாதிரிகள் பெரிய, மெதுவான ஆசிரியரிடமிருந்து அறிவை வித்திய மொழிபெயர்ப்பு தரம் மற்றும் குறைவான தாக்கத்திற்கும் இடையே ஒரு நல்ல வண்ணம் செய்ய வடிவமைக்கப்பட்டது. WMT 2020 செக்கு - ஆங்கிலத்தின் சோதனைகள் அமைப்புகளில், அவர்கள் ஒரு சிபியு நூற்றில் மொழிபெயர்ப்பின் வேகத்தை 700 க்கு மேற்பட்ட வெள்ளை வெற்றிடமுள்ள மூலம் வார்த்த', 'ur': 'ہم نے انڈینبورڈ اور چارلز یونیوریسٹ، پراگ کے یونیوریسٹ کے ساتھ چک/انگلیسی ٹریک کے ساتھ WMT 2020 میں نیویس ترجمہ کے بارے میں شریک ٹاکس کی تعریف کرتا ہے. ہمارے سریع اور پیچیدہ طالب نمونے ایک بڑے، آہستہ استاد سے علم جدا کرتے ہیں۔ ان کی طراحی کی گئی ہے کہ ان کی ترجمہ کیفیت اور نازل کی عمدگی کے درمیان اچھی تجارت کو پیش کریں۔ WMT 2020 چک پر انگلیسی تست سٹ پر، وہ 700 سے زیادہ سفید جگہ سے مترجم ہونے کی سرعت پہنچاتے ہیں، ایک سی پی یو ٹریڈ پر ایک سی پی یو ٹریڈ پر ایک سی پی یو ٹریڈ پر ایک سی پی یو ٹریڈ پر، اسی طرح مصرف حادثہ کے بغیر GP', 'vi': 'Chúng tôi mô tả sự đệ trình chung của Đại học Edinburgh và Charles University, Praha, đến đường ray Séc-Anh ở WM 2020 sẻ Nhiệm vụ Dịch Tin tức. Các mô hình học sinh nhanh gọn chưng cất kiến thức từ một giáo viên lớn, chậm hơn. Chúng được thiết kế để trao đổi tốt giữa chất lượng dịch chuyển và hiệu quả ngụ ý. Trên các tập thử nghiệm WM 2020 Tiếng Anh Séc, họ đạt được tốc độ dịch của quá 700, white-space-limted source words per second trên một chỉ mạng CPU, nhờ đó hệ thần kinh dịch được thực hiện trên máy tiêu dùng mà không có GPU.', 'uz': "Biz Edinburgh University va Charles Universitetdagi birlashtirilgan narsalarni yangi vazifa tarjima qiladigan WMT 2020 ta'lim tarjima uchun Chek/Ingliz tugmasini aytib beramiz. Bizning tez va qisqa o'quvchi modellarimiz katta va tez o'qituvchi o'qituvchidan o'rganadi. They are designed to offer a good trade-off between translation quality and inference efficiency.  Name", 'bg': 'Описваме съвместното представяне на Университета в Единбург и Чарлзовия Университет, Прага, на чешко-английски песен в Споделената задача за превод на новини 2020. Нашите бързи и компактни модели на ученици дестилират знания от по-голям, по-бавен учител. Те са предназначени да предложат добър компромис между качеството на превода и ефективността на изводите. По време на тестовите комплекти за чешки английски език те постигат скорост на превод от над 700 изходни думи в секунда, разделени с празни пространства, върху една нишка на процесора, като по този начин правят невронния превод осъществим на потребителския хардуер без GPU.', 'nl': 'We beschrijven de gezamenlijke inzending van de Universiteit van Edinburgh en de Charles University, Praag aan de Tsjechisch/Engelse track in de WMT 2020 Shared Task on News Translation. Onze snelle en compacte studentenmodellen distilleren kennis van een grotere, langzamere leraar. Ze zijn ontworpen om een goede afweging te bieden tussen vertaalkwaliteit en inferentieefficiëntie. Op de WMT 2020 Tsjechisch Engels testsets bereiken ze vertaalsnelheden van meer dan 700 witruimte gescheiden bronwoorden per seconde op één CPU thread, waardoor neurale vertaling haalbaar is op consumentenhardware zonder GPU.', 'id': 'Kami menggambarkan pengiriman bersama Universitas Edinburgh dan Universitas Charles, Praha, ke trek Cek/Inggris dalam WMT 2020 Shared Task on News Translation. Model mahasiswa cepat dan kompak kami menghasilkan pengetahuan dari guru yang lebih besar dan lambat. Mereka dirancang untuk menawarkan perdagangan yang baik antara kualitas terjemahan dan efisiensi kesimpulan. Pada set ujian bahasa Inggris WMT 2020 Czech, mereka mencapai kecepatan terjemahan lebih dari 700 kata sumber terbatas ruang putih per detik pada satu benang CPU, sehingga terjemahan saraf dapat dilakukan pada perangkat keras konsumen tanpa GPU.', 'hr': 'Opisujemo zajedničku predstavu Univerziteta Edinburga i Čarlsa Univerziteta, Praga, na češki/engleski trag u zajedničkom zadatku WMT 2020 o prevodu novina. Naši brzi i komplikovani studentski modeli razlikuju znanje od većeg, sporijeg učitelja. Oni su dizajnirani kako bi ponudili dobru trgovinu između kvalitete prevoda i učinkovitosti infekcije. Na testovima WMT 2020 čeških i engleskih testova postigli su brzinu prevođenja preko 700 slobodnih izvora riječi na sekundu na jednom nivou CPU-a, tako da je neuralno prevođenje moguće na hardver potroša ča bez GPU.', 'da': 'Vi beskriver den fælles indsendelse af University of Edinburgh og Charles University, Prag til den tjekkiske/engelske spor i WMT 2020 Shared Task on News Translation. Vores hurtige og kompakte elevmodeller destillerer viden fra en større, langsommere lærer. De er designet til at give en god afvejning mellem oversættelseskvalitet og inferenceeffektivitet. På WMT 2020 tjekkisk engelsk testsæt opnår de oversættelseshastigheder på over 700 hvidmellemrum-afgrænsede kildeord pr. sekund på en enkelt CPU tråd, hvilket gør neural oversættelse mulig på forbrugerhardware uden en GPU.', 'de': 'Wir beschreiben die gemeinsame Einreichung der Universität Edinburgh und der Karlsuniversität Prag in den tschechisch/englischen Track im WMT 2020 Shared Task on News Translation. Unsere schnellen und kompakten Schülermodelle destillieren Wissen von einem größeren, langsameren Lehrer. Sie sollen einen guten Kompromiss zwischen Übersetzungsqualität und Inferenzeffizienz bieten. Bei den Testsätzen für tschechisches Englisch WMT 2020 erreichen sie Übersetzungsgeschwindigkeiten von über 700 von Leerzeichen getrennten Quellwörtern pro Sekunde auf einem einzigen CPU-Thread, wodurch neuronale Übersetzung auf Consumer-Hardware ohne GPU möglich ist.', 'ko': '우리는 에든버러대와 프라하 찰스대가 WMT 2020 뉴스 번역 공유 임무에서 체코어/영어 과정을 공동으로 제출하는 상황을 묘사했다.우리의 빠르고 치밀한 학생 모형은 더 크고 더 느린 선생님으로부터 지식을 추출한다.그것들은 번역의 질과 추리 효율 사이의 양호한 균형을 제공하는 데 목적을 두고 있다.WMT 2020 체코 영어 시험집에서는 단일 CPU 스레드에서 초당 700여 개의 빈칸으로 구분된 소스 단어의 번역 속도를 기록해 GPU가 없는 소비류 하드웨어에서 신경 번역을 할 수 있게 했다.', 'tr': 'Biz Edimburg we Çarls Uniwersitetiniň Prague uniwersitetiniň WMT 2020-nji Haýsy terjimelerinde bölünen zadyny çäheň/iňlisçe tarapyna tassykladyk. Biziň tiz we çalt okuwçylarymyz nusgalarymyz bilemi uly, ýuwaşlyk mugallymymyzdan taparlar. Olar terjime etmek we azajyk etkinlik arasynda gowy terjime etmek üçin tasarlanýarlar. WMT 2020-nji Çehiýa “ Iňlisçe testi gurultaýynda, bir CPU ýüzünde näyral terjime edilen hatlaryň GPU-syz ýüze 700 sany iň boş seleňsiz kelimelerden üstine ýetirýärler.', 'af': "Ons beskrywe die saamste onderskrywing van die Universiteit van Edimburg en Charles Universiteit, Prag, na die Tschekiske/Engelske snit in die WMT 2020 deelde taak op Nuusvertaling. Ons vinnige en komplekteer studentmodele verskil kennis van 'n groter, stadiger onderwyser. Hulle is ontwerp om 'n goeie handel af te bring tussen vertaling kwaliteit en inferensie effektiviteit. Op die WMT 2020, Tsjechse ’Engelske toets stel, het hulle oorsettingsspeletjies van meer 700 spasieverdelimiteerde bron woorde per sekonde op 'n enkele CPU draad, sodat hulle neurale oorsetting vervaardig kan word op gebruikers hardware sonder 'n GPU.", 'fa': 'ما تعیین همگانی دانشگاه ادینبورگ و دانشگاه چارلز پراگ را توصیف می\u200cکنیم، به مسیر چک/انگلیسی در عملیات مشترک WMT 2020 در مورد ترجمه خبری. مدل های سریع و پیچیده دانش آموزان ما از یک معلم بزرگ و آهسته\u200cتر دانش را جدا می\u200cکنند. آنها طراحی شده\u200cاند تا یک تجارت خوب بین کیفیت ترجمه و عملکرد آلودگی پیشنهاد دهند. در سطح آزمایش انگلیسی WMT 2020 چک، سرعت ترجمه\u200cهای بیش از 700 کلمات منبع سفید در ثانیه در یک نقطه CPU، به همین دلیل ترجمه\u200cهای عصبی را بر hardware مصرف کننده بدون GPU می\u200cرسانند.', 'am': 'የኤዲንቡር ዩንቨርስቲ እና የCharles ዩንቨርስቲ፣ ፕራጉን በWMT 2020 የተለየ የዜና ትርጓሜ ትርጓሜ ላይ የቻክክ/እንግሊዘኛ መንገድን እናሳውቃለን፡፡ ቶሎ እና ተማሪዎችን ምሳሌዎች ከትልቅ፣ ቀይ አስተማሪ እውቀትን ለይተዋል፡፡ ትርጉም ብልሃት እና በጥቅምነት መካከል መልካም ንግድ ማድረግ ነው፡፡ በWMT 2020 Czech ፣ እንግሊዝኛ ፈተና ማድረግ፣ በ.ኤ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ', 'sw': 'Tunaelezea ujumbe wa pamoja wa Chuo Kikuu cha Edinburgh na Charles Chuo Kikuu cha Charles, Prague, kwa njia ya Kizech/Kiingereza katika Tafsiri ya Habari WMT 2020. Mfano wetu wa haraka na wanafunzi hufafanua maarifa kutoka kwa mwalimu mkubwa na polepole. Wanalengwa kutoa biashara nzuri kati ya ubora wa tafsiri na ufanisi wa uchunguzi. Kwenye mtandao wa WMT 2020 Czech ) vipimo vya majaribio ya Kiingereza, wanaweza kupata kiwango cha tafsiri cha maneno ya vyanzo vya habari vya anga 700 kwa sekunde moja kwenye mtindo wa CPU, na hivyo kufanya tafsiri ya kisasa inayowezekana kwa kutumia vifaa vya wateja bila GPU.', 'bn': 'আমরা বিশ্ববিদ্যালয়ের এডিনবার্গ এবং চার্লস বিশ্ববিদ্যালয়ের যৌথ প্রতিষ্ঠানের বর্ণনা করেছি ডিউএমটি ২০২০ সালের সংবাদ অনুবাদে শেয়ার আমাদের দ্রুত এবং শিক্ষার্থীর মডেল বড়, ধীরে শিক্ষকের কাছ থেকে জ্ঞান বিচ্ছিন্ন করে। তাদের পরিকল্পনা করা হয়েছে অনুবাদের মান এবং অকার্যকর কার্যক্রমের মধ্যে ভালো ব্যবসা আটকার জন্য। WMT ২০২০ চেক ) ইংরেজি পরীক্ষা সেটে তারা প্রতি সেকেন্ডের মধ্যে ৭০০ বেশী স্পেস-স্পেস-সিনেমিত উৎসের ব্যাপারে অনুবাদের গতি অর্জন করে, যার ফলে এক সিপিউ থ্রেডে নি', 'sq': 'Ne përshkruajmë paraqitjen e përbashkët të Universitetit të Edinburgut dhe Universitetit të Çarls, Pragës, në gjurmën çeke/angleze në WMT 2020 Task Shared on News Translation. Modelet tona të shpejtë dhe kompakte student ësh distillojnë njohurinë nga një mësues më i madh dhe më i ngadalshëm. Ato janë projektuar për të ofruar një kompromis të mirë midis cilësisë së përkthimit dhe efektshmërisë së përfundimeve. Në grupet e testimeve të WMT 2020 në anglisht, ata arrijnë shpejtësi përkthimi prej mbi 700 fjalësh burimi të kufizuara me hapësirë të bardhë për sekonda në një filë të vetëm CPU, duke bërë kështu përkthimin nervor të realizueshëm në hardware konsumues pa GPU.', 'hy': 'Մենք նկարագրում ենք Էդինբուրգի համալսարանի և Փրագայի Չեքսի և Անգլերենի համալսարանի համալսարանի ընդհանուր ներկայացումը ՀԱՄ 2020 համալսարանի նորությունների թարգմանման ընթացքում: Մեր արագ և խիստ ուսանողական մոդելները տարբերակում են գիտելիքը ավելի մեծ, դանդաղ ուսուցիչներից: They are designed to offer a good trade-off between translation quality and inference efficiency.  Անգլերեն թեստերի համակարգերից, որոնք կատարվում են World MT 2020-ում, նրանք հասնում են ավելի քան 700 սպիտակ սահմանափակված աղբյուրի բառերի թարգմանման արագություններին մեկ վայրկյանում մեկ պրոցեբույսի թելերի վրա, ինչը նյարդային թարգմանությունը դարձնում է հնարավոր սպա', 'az': 'Biz Edinburger Universitetinin v…ô √áarls Universitetinin, Prag, WMT 2020 il…ô Haqq √áeviri haqqńĪnda paylaŇüńĪlmńĪŇü iŇü iŇüin √ß…ôki/ńįngiliz…ô yoluna Ňü…ôri…ôt edirik. Bizim hńĪzlńĪ v…ô kompleks √∂ńürenci modell…ôrimiz elmi daha b√∂y√ľk, daha yavaŇü m√ľ…ôllimd…ôn ayńĪrńĪr. Onlar terc√ľm…ô kaliteti v…ô a ŇüańüńĪlńĪq efektivit…ôti arasńĪnda yaxŇüńĪ ticar…ôt etm…ôk √ľ√ß√ľn m√ľ…ôyy…ôn edilmiŇüdir. WMT 2020 √áehir sńĪnamasńĪnda, ńįngilizce sńĪnamasńĪ sńĪralarńĪnda, bir CPU sńĪralarńĪnda bir saniy…ôd…ô 700-d…ôn artńĪq whit yer ayńĪrńĪlmńĪŇü m…ônb…ô s√∂zl…ôrinin t…ôkrar s√ľr…ôtl…ôrini t…ôŇükil edirl…ôr, buna g√∂r…ô d…ô GPU olmadan istifad…ô√ßi hardwareyd…ô n√∂ral terc√ľm…ô ed…ô bil…ôr.', 'bs': 'Opišemo zajedničku predstavu Univerziteta Edinburga i Čarlsa Univerziteta, Praga, na češki/engleski trag na zajedničkom zadatku WMT 2020 o prevodu novina. Naši brzi i komplikovani studentski modeli razlikuju znanje od većeg, sporijeg učitelja. Oni su dizajnirani kako bi ponudili dobru trgovinu između kvalitete prevoda i učinkovitosti infekcije. Na testovima WMT 2020 čeških i engleskih testova postigli su brzinu prevođenja preko 700 izvorskih riječi na sekundu na jednom nivou CPU-a, tako da je neuralno prevođenje moguće na hardver potroša ča bez GPU.', 'fi': 'Kuvaamme Edinburghin yliopiston ja Prahan Kaarlen yliopiston yhteistä osallistumista tšekki-englantilaiseen kappaleeseen WMT 2020 Shared Task on News Translation -ohjelmassa. Nopeat ja kompaktit opiskelijamallit tislaavat tietoa suuremmalta ja hitaammalta opettajalta. Ne on suunniteltu tarjoamaan hyvä kompromissi käännöslaadun ja päättelytehokkuuden välillä. WMT 2020 Tšekin englannin testisarjoissa käännösnopeus on yli 700 tyhjävälilyönnin rajattua lähdesanaa sekunnissa yhdellä suorittimen kierteellä, mikä mahdollistaa neurokäännöksen kuluttajalaitteistossa ilman näytönohjainta.', 'cs': 'Popisujeme společné přihlášení Univerzity v Edinburghu a Univerzity Karlovy v Praze na česko-anglickou stopu v rámci WMT 2020 Shared Task on News Translation. Naše rychlé a kompaktní studentské modely destilují znalosti od většího, pomalejšího učitele. Jsou navrženy tak, aby nabízely dobrý kompromis mezi kvalitou překladu a efektivitou inference. U testovacích sad WMT 2020 Česká angličtina dosahují rychlosti překladu více než 700 zdrojových slov za sekundu vymezených bílými prostory na jednom procesorovém vlákně, čímž je neuronový překlad možný na spotřebitelském hardwaru bez GPU.', 'et': 'Kirjeldame Edinburghi Ülikooli ja Praha Charles Ülikooli ühist esitamist tšehhi/inglise keele rajale WMT 2020 ühises uudiste tõlkimise ülesandes. Meie kiired ja kompaktsed õpilasmudelid destilleerivad teadmisi suuremalt ja aeglasemalt õpetajalt. Nende eesmärk on pakkuda head kompromisse tõlkekvaliteedi ja järelduste tõhususe vahel. WMT 2020 Tšehhi inglise keele testikomplektidel saavutatakse tõlkekiirus üle 700 tühiku piiratud lähtesõna sekundis ühel protsessori lõngal, muutes seega neurotõlke võimalikuks tarbija riistvaral ilma GPU-ta.', 'ca': "We describe the joint submission of the University of Edinburgh and Charles University, Prague, to the Czech/English track in the WMT 2020 Shared Task on News Translation.  Our fast and compact student models distill knowledge from a larger, slower teacher.  Estàn dissenyats per oferir una bona compensació entre la qualitat de la traducció i l'eficiència de la inferència. On the WMT 2020 Czech   English test sets, they achieve translation speeds of over 700 whitespace-delimited source words per second on a single CPU thread, thus making neural translation feasible on consumer hardware without a GPU.", 'jv': 'Awakdhéwé rak beraksi nggawe ngupakan Universite di Etikèn karo Universite di Dikampungan, prag, kanggo nganggo track Cheek/Inggris nang WWT 2020 Tarjamahan kanggo Kemerdekaan Kasunyatan Hawé. Awakdhéwé éntuk karo model kuwi nggawe sawalik dhéwé ngerasakno karo perusahaan sing larang, mangkane. Awak dhéwé wis disenyarno kanggo ngerewake tarjamahan luwih-luwih ning katimbang kelas lan ijol-ijolan winih Nang WWT 2020 Cek , sampeyan ingkang dipun-ingkang dadi, wong dhéwé ngerasah tarjamahan luwih dolanan sing luwih apik, padha kapan tanggal dipun-ingkang dipun sekond sing ujaran perangkat dhéwé, dadi wis mbukakipun oleh operasi kapan ingkang dipunanggé', 'sk': 'Opisujemo skupno predložitev Univerze v Edinburgu in Karlove univerze v Pragi na češko-angleško stezo v okviru skupne naloge WMT 2020 o prevajanju novic. Naši hitri in kompaktni modeli učencev pridobijo znanje večjega, počasnejšega učitelja. Zasnovani so tako, da ponujajo dober kompromis med kakovostjo prevajanja in učinkovitostjo sklepanja. Na češkem angleškem testiranju WMT 2020 dosežejo hitrost prevajanja več kot 700 izvornih besed na sekundo, ločenih s praznim presledkom, na eni sami niti procesorja, kar omogoča nevronski prevod na potrošniški strojni opremi brez GPU.', 'he': "אנחנו מתארים את ההצגה המשותפת של אוניברסיטת אדינבורג ואוניברסיטת צ'ארלס, פראג, למסלול הצ'קי/אנגלי במשימה המשותפת של WMT 2020 על תרגום חדשות. דוגמני הסטודנטים המהירים והצמודים שלנו מרכיבים ידע ממורה גדול יותר ואטי יותר. הם מעוצבים כדי להציע התחלה טובה בין איכות התרגום לבין יעילות המסקנה. במערכת הניסויים האנגלית WMT 2020, הם משיגים מהירות התרגום של מעל 700 מילים מקורות מוגבלות בחלל לבן לשנייה על חוט אחד של CPU, כך הופכים לתרגום עצבי אפשרי על חומרי ציבור ללא GPU.", 'ha': "Tuna describe the Jordy Submition of the University of edinburg and charles University, prague, to the Czech/English trace in the WMT 2020 Shared Tax on News Translate. Misãlai masu karatun da sauri na gauraya, za'a bayyana ilmi daga macallin mafiya, kashi. Suna designar su bãyar da wani mai kyau wa fatauci daga tsakanin taƙaita ta fassarar da mafiya ƙaranci. On the WMT 2020 Czech ) KCharselect unicode block name", 'bo': 'We describe the joint submission of the University of Edinburgh and Charles University, Prague, to the Czech/English track in the WMT 2020 Shared Task on News Translation. ང་ཚོའི་མགྱོག་རྩལ་བ་དང་མཉམ་ཁག་པའི་མིག་གཟུགས་རིས་ཤེས་ཚད་ཆེ་བ་ཞིག་ནས་དབྱེ་བ་འགྱུར་བ། འདི་དག་ནི་ཚོར་སྤྱི་ཚོགས་དང་བཅས་ཀྱི་གནས་སྟངས་སུ་གཏོང་ཚད་ལྡན་དང་རྐྱེན་ཚད་བར་གཏོང་བ་ཞིག On the WMT 2020 Czech  English test sets, they achieve translation speeds of over 700 whitespace-delimited source words per second on a single CPU thread, thus making neural translation feasible on consumer hardware without a GPU.'}
{'en': 'The University of Edinburgh’s submission to the German-to-English and English-to-German Tracks in the WMT 2020 News Translation and Zero-shot Translation Robustness Tasks', 'ar': 'تقديم جامعة إدنبرة للمسارات من الألمانية إلى الإنجليزية ومن الإنجليزية إلى الألمانية في ترجمة الأخبار WMT 2020 ومهام قوة الترجمة الصفرية', 'es': 'La presentación de la Universidad de Edimburgo a los cursos de alemán a inglés y de inglés a alemán en las tareas de robustez de traducción de noticias y traducción cero del WMT 2020', 'fr': "Soumission de l'Université d'Édimbourg aux pistes de l'allemand vers l'anglais et de l'anglais vers l'allemand dans les tâches de traduction de nouvelles du WMT 2020 et de robustesse de la traduction Zero-shot", 'pt': 'A submissão da Universidade de Edimburgo para as faixas de alemão para inglês e inglês para alemão nas tarefas de tradução de notícias do WMT 2020 e robustez da tradução zero-shot', 'ja': 'WMT 2020ニュース翻訳およびゼロショット翻訳堅牢性タスクにおけるドイツ語から英語、および英語からドイツ語へのトラックへのエディンバラ大学の提出', 'hi': 'एडिनबर्ग विश्वविद्यालय के WMT 2020 समाचार अनुवाद और शून्य-शॉट अनुवाद मजबूती कार्यों में जर्मन-से-अंग्रेजी और अंग्रेजी-से-जर्मन पटरियों के लिए प्रस्तुत', 'zh': '爱丁堡大学于WMT 2020新闻译及零镜头译鲁棒性任中提交德语至英语、英语至德语轨道', 'ru': 'Представление Эдинбургского университета на немецко-английском и английско-немецком треках в задачах перевода новостей WMT 2020 и надежного перевода с нулевым выстрелом', 'ga': 'Aighneacht Ollscoil Dhún Éideann ar na Rianta Gearmáinis-go-Béarla agus Béarla-go-Gearmáinis i dTascanna Neartachta Aistriúcháin Nuachta WMT 2020 agus Nial-shots Aistriúcháin', 'ka': 'ვებინდონის სუნივერტუტის მისამართება გერმანეთიდან ანგლისურად და გერმანეთიდან მისამართებლად WMT 2020 წინატრუქციების გადაწყვეტა და Zero-shot წინატრუქციის პრობსტების', 'hu': 'Az Edinburgh-i Egyetem benyújtása a német-angol és angol-német sávokra a WMT 2020 Hírek Fordítási és Zero-Shot Fordítási Robusztussági feladatok', 'el': 'Η υποβολή του Πανεπιστημίου του Εδιμβούργου στα Γερμανικά-Αγγλικά και Αγγλικά-Γερμανικά Tracks στα Νέα Μετάφραση και Μετάφραση μηδενικού πυροβολισμού', 'it': "La presentazione dell'Università di Edimburgo alle tracce tedesco-inglese e inglese-tedesco nel WMT 2020 News Translation e Zero-shot Translation Tasks Robusteness", 'kk': 'Эдинбург университетінің WMT 2020 жаңалық аудару және Zero-shot аудару робостық тапсырмаларындағы неміс-ағылшын және ағылшын-неміс тілдеріне жіберу', 'lt': 'Edinburgo universiteto pranešimas vokiečių kalba anglų kalba ir anglų kalba vokiečių kalba WMT 2020 naujienų vertimo ir nulinio vertimo patikimumo užduotyse', 'mk': "The University of Edinburgh's submission to the German-to-English and English-to-German Tracks in the WMT 2020 News Translation and Zero-shot Translation Robustness Tasks", 'ms': 'Penghantaran Universiti Edinburgh kepada Jerman-ke-Inggeris dan Inggeris-ke-Jerman Trek dalam Perjemahan Berita WMT 2020 dan Tugas Kekuatan Terjemahan Zero-shot', 'ml': 'എഡിന്\u200dബര്\u200dഗിന്\u200dറെ യൂണിവേഴ്സിറ്റിയില്\u200d ജര്\u200dമ്മന്\u200d മുതല്\u200d ഇംഗ്ലീഷിലേക്കും ജെര്\u200dമ്മന്\u200d ട്രാക്കുകളിലേക്കും കീഴ്പെടുത്തുന്നു. WMT 2020 വ', 'mt': "Is-sottomissjoni tal-Università ta' Edinburgh lill-Ġermaniż-Ingliż u l-Ingliż-Ġermaniż-Traduzzjoni tal-Aħbarijiet tad-WMT 2020 u x-Xogħlijiet ta' Robustezza tat-Traduzzjoni Zero-shot", 'mn': 'Эдинбургын Их Сургууль WMT 2020 News Translation, Zero-shot Translation Robustness Tasks-д Герман, Англи, Герман-д', 'no': "University of Edinburgh's submission to the German to English and English to German Tracks in the WMT 2020 News Translation and Zero-shot Translation Robustness Tasks", 'pl': 'Zgłoszenie Uniwersytetu w Edynburgu do utworów z języka niemieckiego na angielski i angielsko-niemieckiego w WMT 2020 Aktualności Tłumaczenie i tłumaczenie zerowe', 'ro': 'Transmiterea Universității din Edinburgh la piesele germană-engleză și engleză-germană în cadrul programului WMT 2020 de traducere de știri și sarcini de rezistență a traducerii zero', 'sr': 'Predloženje Univerziteta Edinburga na njemačke na engleski i engleski na njemačke tragove u prijevozu novina WMT 2020 i robustnosti prevoda nulo-snimka', 'si': 'ඩිබන්ඩ්වර්න්ග් විශ්වාසයේ ජර්මන් වල ඉංග්\u200dරීසිය වලින් ඉංග්\u200dරීසිය වලින් ජර්මන් වලින් ප්\u200dරවේශය WMT 202 වාර්තාවක් අ', 'so': 'Jaamacadda Edinburgh waxay u soo dhiibtay Jarmal-to-Ingiriis- to-German Tracks in the WMT 2020 News Translation and Zero-shot Translation Robustness Tasks', 'sv': 'Universitetet i Edinburgh inlämnar sig till de tyska-engelska och engelska-tyska spåren i WMT 2020 Nyheter Översättning och nollskotts översättningsuppgifter Robusthet', 'ta': "The University of Edinburgh's submission to the German-to-English and English-to-German Tracks in the WMT 2020 News Translation and Zero-shot Translation Robustness Tasks", 'ur': 'ڈینڈینبور کی یونیوریس کے تحویل جرمن سے انگلیسی اور انگلیسی سے جرمن تراکس میں WMT 2020 نیویوریس ترجمہ اور Zero-shot ترجمہ روبوستنس ٹاکس میں', 'uz': 'Edinburgh Üniversitesi WMT 2020 News tarjima va Zero-shot tarjima vazifalarini Olmonchadan Inglizchaga va Inglizchaga-Olmonchaga Olmonchaga tahrirlash', 'vi': 'Sự đệ trình của Đại học Edinburgh đệ trình những đường mòn Đức-Anh-Anh-Anh-Đức trong the WRT 2020 News Translation and Zero-shot Translation Tasks', 'bg': 'Прилагането на Университета в Единбург към песните от немски на английски и английски на немски език в задачите за превеждане на новини и нулев превод', 'hr': 'Predloženje Univerziteta Edinburga na njemačke i engleske i njemačke tragove u prijevozu za vijesti WMT 2020-a i robustnosti prevode nulo-pucnjave', 'da': "University of Edinburgh's indsendelse til de tysk-til-engelsk og engelsk-til-tysk spor i WMT 2020 Nyheder Oversættelse og Zero-shot Oversættelse Robusthedsopgaver", 'nl': 'De inzending van de Universiteit van Edinburgh aan de Duits-naar-Engels en Engels-naar-Duits tracks in de WMT 2020 Nieuws Vertaling en Zero-shot vertaling Robustheid Taken', 'de': 'Die Einreichung der Universität Edinburgh bei den Tracks Deutsch-Englisch und Englisch-Deutsch im WMT 2020 News Translation and Zero-Shot Translation Robustheit Aufgaben', 'ko': '에든버러 대학이 WMT 2020 뉴스 번역과 제로 렌즈 번역 임무에서 독일어에서 영어와 영어, 독일어로 제출한 곡', 'fa': 'تحویل دانشگاه ادینبورگ به مسیرهای آلمانی به انگلیسی و انگلیسی به آلمانی در ترجمه خبرهای WMT 2020 و مسئله\u200cهای ترجمه\u200cکننده\u200cی نویسی Zero-shot', 'sw': 'Chuo Kikuu cha Edinburgh kinatolewa kwa ajili ya mabadiliko ya Ujerumani-hadi-Kiingereza na Ujerumani-hadi-Ujerumani katika Tafsiri ya Habari 2020 na Tafsiri zilizopigwa risasi zisizo na sifa', 'tr': 'WMT 2020 Haýsy terjime we Zero-shot terjime edilen Robustness Görevlerinde Edimburgyň Uniwersiteti Almança-iňlis we iňlis-iňlis dilinde', 'af': 'Die Universiteit van Edimburg se onderwerp aan die Duitse-na-Engels en Engels-na-Duitse Snitte in die WMT 2020 Nuusvertaling en Zero-shot Vertaling Robustness-taak', 'sq': 'Përdorimi i Universitetit të Edinburgut ndaj gjurmëve gjermane-angleze-në-gjermane dhe angleze-në-gjermane në detyrat e përkthimit të lajmeve WMT 2020 dhe të robustësisë s ë përkthimit zero-shot', 'am': 'የኤዲንቡር ዩንቨርስቲ በWMT 2020 ዜናዎች ትርጓሜ እና በዝርያ-shot ትርጓሜ ስራዎችን ለጀርመን እና እንግሊዘኛ-ወደ ጀርመን-ጀርመን-ጀርመን-ጀርመን Tracks በመስጠት', 'hy': 'Էդինբուրգի համալսարանի ներկայացումը Գերմանիայի-անգլերեն և Անգլերեն-գերմանիայի-անգլերեն երաժշտության մասին ԱՄԹ 2020 նորությունների թարգմանման և զրոյի թարգմանման հզորության առաջադրանքներում', 'az': 'Edinburgin 칖niversitesi WMT 2020 Haqq 칂eviri v톛 Zero-shot 칂eviri Robustness G칬revl톛rind톛 Alman-캻ngiliz톛 v톛 캻ngiliz톛-Alman 캻letikl톛rin톛 g칬nd톛rildi', 'bn': 'এডিনবার্গ বিশ্ববিদ্যালয়ের জার্মান-থেকে ইংরেজি এবং ইংরেজী থেকে জার্মান ট্র্যাকের প্রতি জমা দেয়া হয়েছে ডিএমটি ২০২০ সংবাদ অনুবাদ এব', 'bs': 'Predloženje Univerziteta Edinburga na njemačke na engleski i engleski na njemačke tragove u prijevozu novina WMT 2020 i robustnosti prevode nulo-snimka', 'cs': 'Podání univerzity v Edinburghu na německo-anglické a anglicko-německo-německé stopy ve WMT 2020 Novinky Překlad a nulový překlad robustní úkoly', 'id': 'Pengiriman Universitas Edinburgh ke Jerman-ke-Inggris dan Inggris-ke-Jerman Tracks dalam Tjemahan Berita WMT 2020 dan Tugas Kekuatan Terjemahan Zero-shot', 'et': 'Edinburghi Ülikooli esitamine saksa-inglise ja inglise-saksa rajadele WMT 2020 uudiste tõlkimise ja nullkõlke tugevuse ülesannetes', 'ca': "La subministració de la Universitat d'Edimburgu a les pistes alemanya-anglesa-alemana i anglesa-alemana en les tasques de traducció de notícies WMT 2020", 'fi': 'Edinburghin yliopiston esitys saksa-englanti- ja englanti-saksa-raidoille WMT 2020:n uutiskäännös- ja nollakäännöstehtävissä', 'ha': "University of edinburg' s Submit to the Jarman-to-English and English-to-Jarman Track in the WMT 2020 News Translate and Zero-shot Translate Tasks", 'sk': 'Oddaja Univerze v Edinburgu na sledi iz nemščine v angleščino in angleščine v nemščino v nalogah za prevajanje novic WMT 2020', 'jv': 'Ombudhakan Universite di ribungan kanggo kelas Basan sami Inggris karo Pak anu alaman sing nganggo WWT 2020 Habaganjur Terjamahan karo 0-shot Terjamahan Jobs', 'he': 'ההעברה של אוניברסיטת אדינבורג למסלולים הגרמניים לאנגליים ואנגליים לגרמנים בתרגום חדשות WMT 2020', 'bo': "The University of Edinburgh's submission to the German-to-English and English-to-German Tracks in the WMT 2020 News Translation and Zero-shot Translation Robustness Tasks"}
{'en': 'This paper describes the University of Edinburgh’s submission of German-English systems to the WMT2020 Shared Tasks on News Translation and Zero-shot Robustness.', 'pt': 'Este artigo descreve a submissão de sistemas alemão-inglês da Universidade de Edimburgo às Tarefas Compartilhadas do WMT2020 sobre Tradução de Notícias e Robustez Zero-shot.', 'ar': 'تصف هذه الورقة تقديم جامعة إدنبرة للأنظمة الألمانية والإنجليزية إلى WMT2020 للمهام المشتركة حول ترجمة الأخبار وقوة إطلاق النار الصفري.', 'es': 'Este artículo describe la presentación por parte de la Universidad de Edimburgo de los sistemas alemán-inglés a las Tareas Compartidas sobre Traducción de Noticias y Robustez Zero-shot del WMT2020.', 'fr': "Cet article décrit la soumission par l'Université d'Édimbourg de systèmes allemand-anglais aux tâches partagées WMT2020 sur la traduction des actualités et la robustesse Zero-shot.", 'ja': 'この論文では、エディンバラ大学がWMT 2020ニュース翻訳とゼロショット堅牢性に関する共有タスクにドイツ語と英語のシステムを提出したことについて説明します。', 'zh': '本文引爱丁堡大学WMT2020言德语 - 英语系统新闻翻译与零镜头鲁棒性共之。', 'hi': 'यह पेपर एडिनबर्ग विश्वविद्यालय के जर्मन - अंग्रेजी प्रणालियों को WMT2020 समाचार अनुवाद और शून्य-शॉट मजबूती पर साझा कार्यों के लिए प्रस्तुत करने का वर्णन करता है।', 'ru': 'В этой статье описывается подача Эдинбургским университетом немецко-английских систем на WMT2020 Shared Tasks on News Translation and Zero-shot Robustness.', 'ga': 'Déanann an páipéar seo cur síos ar an gcaoi a ndearna Ollscoil Dhún Éideann córais Ghearmánach - Bhéarla a chur isteach chuig Tascanna Comhroinnte WMT2020 ar Aistriúchán Nuachta agus ar Lánsheasmhacht Zero-shot.', 'ka': 'ეს დოკუნტი აღწერს ვებინდონის სუნივერტუტის გერმანეთის - ანგლისური სისტემის გასაგება WMT2020-ის გასაგებული საუბრიო გასაგრძელება და ნუ-სტიპის პრობსტისტი', 'hu': 'Ez a tanulmány bemutatja az Edinburgh-i Egyetem német-angol rendszereinek benyújtását a WMT2020 Shared Tasks on News Translation és Zero-Shot Robustness programra.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή γερμανικών-αγγλικών συστημάτων από το Πανεπιστήμιο του Εδιμβούργου στις κοινές εργασίες για τη μετάφραση ειδήσεων και την ανθεκτικότητα μηδενικού πυροβολισμού.', 'it': "Questo articolo descrive la presentazione da parte dell'Università di Edimburgo dei sistemi tedesco-inglese ai compiti condivisi WMT2020 sulla traduzione delle notizie e sulla robustezza zero-shot.", 'kk': 'Бұл қағаз Эдинбург университетінің неміс - ағылшын жүйелерін WMT2020 жаңалық аудару және Zero-shot Robustness-тың ортақтастырылған тапсырмаларына таңдайды.', 'lt': "This paper describes the University of Edinburgh's submission of German - English systems to the WMT2020 Shared Tasks on News Translation and Zero-shot Robustness.", 'mk': 'Овој весник го опишува поднесувањето на германско-англиските системи од страна на Универзитетот во Единбург на заедничките задачи на ВМТ2020 за превод на вести и нула-стрелачка robustness.', 'ms': 'Kertas ini menggambarkan penghantaran sistem Jerman - Inggeris dari Universiti Edinburgh kepada Tugas Berkongsi WMT2020 tentang Penerjemahan Berita dan Kekuatan Zero-shot.', 'ml': 'ഈ പത്രത്തില്\u200d എഡിന്\u200dബര്\u200dഗിന്\u200dറെ യൂണിവേഴ്സിറ്റിയില്\u200d ജര്\u200dമ്മനിക സിസ്റ്റീമുകള്\u200dക്ക് വിശദീകരിക്കുന്നു. വിവരങ്ങളുടെ വിവരങ്ങള്\u200d വിവരങ', 'mt': "Dan id-dokument jiddeskrivi s-sottomissjoni mill-Università ta' Edinburgh tas-sistemi Ġermaniżi-Ingliżi lill-Kompiti Konġunti tad-WMT2020 dwar it-Traduzzjoni tal-Aħbarijiet u r-Robustezza Zero-shot.", 'mn': 'Энэ цаас Эдинбургийн Их Сургууль Германы - Англи системийн WMT2020-ийн мэдээллийн хөрөнгө оруулалт болон Zero-shot Robustness-ын хуваалтын ажлыг тайлбарладаг.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie przez Uniwersytet Edynburgski systemów niemiecko-angielskich do WMT2020 Shared Tasks on News Translation i Zero-shot Robustheit.', 'no': "Denne papiret beskriver University of Edinburgh's submission of German - English systems to the WMT2020 Shared Tasks on News Translation and Zero-shot Robustness.", 'ro': 'Această lucrare descrie prezentarea de către Universitatea din Edinburgh a sistemelor german-engleză la misiunile partajate WMT2020 privind traducerea știrilor și robustețea zero-shot.', 'sr': 'Ovaj papir opisuje podnošenje njemačkih - engleskih sistema Univerziteta Edinburga na delovane zadatke WMT2020 o prevodu novina i robustnosti nulog snimka.', 'si': 'මේ පත්තුවෙන් එඩින්බ්\u200dරින්ග් විශ්වාසයේ ජර්මන් වලින් - ඉංග්\u200dරීසි පද්ධතිය WMT202 වලින් සමාගත වැඩක් සහ Zero-shot Robousness ව', 'so': 'Warqaddan waxaa ku qoran warqadda jaamacadda Edinburgh uu soo diro Jarmalka - nidaamka Ingiriiska ee WMT2020 lagu sharciyey shaqooyinka turjumidda News iyo Robustness Zero-shot.', 'sv': 'Denna uppsats beskriver University of Edinburgh inlämnande av tyska-engelska system till WMT2020 Shared Tasks on News Translation och Zero-Shot Robustness.', 'ur': 'یہ کاغذ ڈینڈینبور کی یونیوریس کی جرمانی - انگلیسی سیستموں کو WMT2020 کے نیویس ترجمہ اور Zero-shot Robustness کے بارے میں شریک تاسکیوں کی تعریف کرتا ہے.', 'ta': 'இந்த காகிதத்தில் எடின்பர்க் கல்லூரியில் ஜெர்மனியின் அனுப்புதலை விவரிக்கிறது - ஆங்கிலம் அமைப்புகள் WMT2020 செய்தி மொழிபெயர்ப்பு ம', 'vi': 'Tờ giấy này mô tả s ự giới thiệu của Đại học Edinburgh "Hệ thống Tiếng Anh Đức" với tập đoàn WM220 "Việc chia sẻ" về thông tin tức dịch chuyển và máy bay Zero-shot.', 'uz': "Бу саҳифа Edinburgh Üniversitesi - Olmoncha - Ingliz tizimlari WMT2020 ta'lim tarjimalari va Zero-shotgan Robustning vazifalarini WMT2020'ga qaytarilgan vazifalarni aytadi.", 'bg': 'Настоящата статия описва представянето на немски - английски системи от Университета в Единбург на споделените задачи за превод на новини и нулева устойчивост.', 'da': "Denne artikel beskriver University of Edinburgh's indsendelse af tysk-engelsk systemer til WMT2020 Shared Tasks om nyhedsoversættelse og Zero-Shot Robustness.", 'hr': 'Ovaj novinar opisuje podnošenje njemačkih - engleskih sustava Univerziteta Edinburga zajedničkim zadacima WMT2020-a o prevodu vijesti i robustnosti nulog snimka.', 'nl': 'Dit artikel beschrijft de indiening van Duits-Engels systemen door de Universiteit van Edinburgh aan de WMT2020 Shared Tasks on News Translation en Zero-shot Robustheid.', 'de': 'Dieser Beitrag beschreibt die Einreichung von Deutsch-Englisch-Systemen durch die Universität Edinburgh an die WMT2020 Shared Tasks on News Translation und Zero-Shot Robustheit.', 'id': "This paper describes the University of Edinburgh's submission of German - English systems to the WMT2020 Shared Tasks on News Translation and Zero-shot Robustness.", 'ko': '본고는 에든버러대학이 WMT2020에 제출한 뉴스 번역과 제로 포루팡성에 관한 독일어-영어 시스템 공유 임무를 묘사한다.', 'fa': 'این کاغذ تحویل دانشگاه ادینبورگ آلمانی - سیستم انگلیسی به عملهای مشترک WMT2020 در مورد ترجمه خبری و روبوستنس صفر شلیک می\u200cکند.', 'sw': 'Gazeti hili linaelezea ujumbe wa Chuo Kikuu cha Edinburgh wa Ujerumani - Mfumo wa Kiingereza wa WMT2020 wa Tafsiri ya Habari na Robustness inayopigwa risasi zisizo na sifa.', 'tr': "Bu kagyz Edimburgyň Uniwersiteti WMT2020'a Iňlisler sistemalarynyň WMT2020-nyň Haýsy terjime we 0-shot ýoly barada paýlaşdyrylýar.", 'af': 'Hierdie papier beskrywe die Universiteit van Edimburg se onderwerp van Duits - Engelske stelsels aan die WMT2020 Gedeelde Opdragte op Nuusvertaling en Zero-shot Robustness.', 'sq': 'Kjo gazetë përshkruan paraqitjen e sistemeve gjermane-angleze nga Universiteti i Edinburgut në detyrat e përbashkëta të WMT2020 për përkthimin e lajmeve dhe fuqinë zero-shot.', 'am': 'ይህ ገጽ የኤዲንቡር ዩንቨርስቲ የጀርመን - እንግሊዘኛ ስርዓቶችን WMT2020 የዜና ትርጓሜ እና በዝርያ-shot ሮቡስቴንስ የተሰራጨውን ስርዓቶች ይናገራል፡፡', 'hy': 'Այս հոդվածը նկարագրում է Էդինբուրգի համալսարանի ներկայացումը գերմաներեն-անգլերեն համակարգերին ԱՄԹ2020-ի ընդհանուր հանձնարարությունների վրա նորությունների թարգմանման և զրոյի հզորության մասին:', 'az': "Bu kağıt Edinburgin Universitetinin Almanca - İngilizce sistemlərinin WMT2020 Haqq Çeviri və Zero-shot Robustness'a paylaşılan işləri təsbit edir.", 'bn': 'এই পত্রিকা এডিনবার্গ বিশ্ববিদ্যালয়ের জার্মান- ইংরেজি ব্যবস্থার প্রতি উইএমটি২০০ সংবাদ অনুবাদ এবং জিরো গুলি রোবাস্টেন্সের বিভ', 'bs': 'Ovaj papir opisuje podnošenje njemačkih - engleskih sistema Univerziteta Edinburga na delove WMT2020-a o prevodu novina i robustnosti nulog snimanja.', 'ca': "Aquest article descriu la presentació de la Universitat d'Edimburgu dels sistemes alemanys-anglesos a la WMT2020 Shared Tasks on News Translation and Zero-shot Robustness.", 'et': 'Käesolevas dokumendis kirjeldatakse Edinburghi Ülikooli saksa-inglise süsteemide esitamist WMT22020 uudiste tõlkimise jagamise ülesannetele.', 'fi': 'Tässä artikkelissa kuvataan Edinburghin yliopiston toimittamia saksa-englanti-järjestelmiä WMT22020 Shared Tasks on News Translation and Zero-shot Robustness -ohjelmaan.', 'cs': 'Tento článek popisuje podání německo-anglických systémů Univerzity v Edinburghu do WMT2020 Shared Tasks on News Translation and Zero-shot Robustheit.', 'he': "This paper describes the University of Edinburgh's submission of German - English systems to the WMT2020 Shared Tasks on News Translation and Zero-shot Robustness.", 'sk': 'Ta prispevek opisuje predložitev nemško-angleških sistemov Univerze v Edinburgu na skupne naloge WMT2020 o prevajanju novic in robustnosti brez strela.', 'ha': "Wannan karatun na describe University of edinburg'ar da aka bãyar da wasiyyar da Jarman - na'urar Ingiriya zuwa WMT2020 Shared Tayyinin da aka Fassar Tarjima da Robustance.", 'bo': "ཤོག་བྱང་འདིས་Edimburg's University of Edinburgh's submission of German - English systems to the WMT2020 Shared Tasks on News Translation and Zero-shot Robustness.", 'jv': 'Perintah iki rambarang nggawe ngupakan Universite dhen eduniversi sing takon ning segala German - sistem Inggris kanggo awak dhéwé basa sing nyerangkaké WWT 2020 lan Perintah Balita kanggo Terjamahan karo 0-sho Robert.'}
{'en': 'SJTU-NICT’s Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task', 'ar': 'أنظمة الترجمة الآلية العصبية الخاضعة للإشراف وغير الخاضعة للإشراف من SJTU-NICT لمهمة ترجمة الأخبار WMT20', 'fr': 'Systèmes de traduction automatique neuronale supervisés et non supervisés de SJTU-NICT pour la tâche de traduction de nouvelles WMT20', 'pt': 'Sistemas de tradução automática neural supervisionada e não supervisionada da SJTU-NICT para a tarefa de tradução de notícias do WMT20', 'es': 'Sistemas de traducción automática neuronal supervisada y no supervisada de SJTU-NICT para la tarea de traducción de noticias WMT20', 'zh': '上海交通大学-NICT用于WMT20新闻翻译监督神经机器翻译统', 'ja': 'WMT 20ニュース翻訳タスクのためのSJTU - NICTの監督および監督されていない神経機械翻訳システム', 'hi': 'WMT20 समाचार अनुवाद कार्य के लिए SJTU-NICT की पर्यवेक्षित और असुरक्षित तंत्रिका मशीन अनुवाद प्रणाली', 'ru': 'SJTU-NICT Надзорные и Неконтролируемые Системы Перевода Нейронной Машины для Задачи Перевода Новостей WMT20', 'ga': 'Córais Néar-Aistriúcháin Néaracha Maoirsithe agus Neamhmhaoirsithe SJTU-NICT do Thasc Aistriúcháin Nuachta WMT20', 'ka': 'Name', 'el': 'Τα εποπτευόμενα και μη εποπτευόμενα νευρωνικά συστήματα μηχανικής μετάφρασης του για το έργο μετάφρασης ειδήσεων', 'hu': 'Az SJTU-NICT felügyelt és felügyelet nélküli idegfordító rendszerei a WMT20 Hírfordítási feladathoz', 'it': 'Sistemi di traduzione automatica neurale supervisionati e non supervisionati di SJTU-NICT per il compito di traduzione WMT20 News', 'kk': 'Comment', 'mk': "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", 'lt': 'SJTU-NICT prižiūrimos ir neprižiūrimos neurologinių mašinų vertimo sistemos, skirtos WMT20 naujienų vertimo darbui', 'ml': 'WMT20 വിവരങ്ങളുടെ വിവരങ്ങളുടെ പരിഭാഷ ടാസ്കിനുള്ള SJTU- NICT സൂപ്പര്\u200dവ്വപ്പെടുത്തിയിരിക്കുന്നു നെയുറല്\u200d മെഷീന്\u200d പരിഭാ', 'ms': 'Sistem Terjemahan Mesin Neural yang Dijaga dan Tidak Dijaga SJTU-NICT untuk Tugas Terjemahan Berita WMT20', 'mt': "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", 'mn': "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", 'no': 'Name', 'ro': 'Sistemele de traducere automată neurală supravegheate și nesupravegheate ale SJTU-NICT pentru sarcina de traducere a știrilor WMT20', 'pl': 'Nadzorowane i nienadzorowane systemy tłumaczenia maszynowego neuronu SJTU-NICT dla WMT20', 'sr': 'SJTU-NICT je nadgledan i neodređen Neuralni sistem prevoda za WMT20 novinski prevod zadatak', 'si': 'Name', 'so': "SJTU-NICT's Superwatched and Unsupervised Neural machine Translation Systems for the WMT20 News Translation Task", 'sv': 'SJTU-NICTs 철vervakade och o철vervakade neurala maskin철vers채ttningssystem f철r WMT20 News Translation Task', 'ta': 'WMT20 செய்தி மொழிபெயர்ப்பு பணி', 'ur': 'Name', 'uz': 'Comment', 'vi': 'Hệ thống dịch lắp lắp máy thần kinh không giám s át cho Công trình Dịch Tin WM20', 'bg': 'Наблюдавани и неконтролирани системи за невронен машинен превод на СЖТУ-НИКТ за задачата за превод на новини', 'da': 'SJTU-NICTs overvågede og ukontrollerede neurale maskinoversættelsessystemer til WMT20 Nyhedsoversættelsesopgaven', 'hr': 'SJTU-NICT-ov nadzorni i neodržani nervni sustavi prevoda za WMT20 novinski prevod', 'nl': "SJTU-NICT's Supervised en Onbegeleide Neural Machine Translation Systemen voor de WMT20 Nieuws Vertaling Taak", 'de': 'Die überwachten und unbeaufsichtigten neuronalen maschinellen Übersetzungssysteme der SJTU-NICT für die WMT20 News Translation Task', 'ko': 'WMT20 뉴스 번역 임무를 위한 SJTU-NICT 감독 및 무감독 신경기계 번역 시스템', 'fa': 'سیستم\u200cهای ترجمه\u200cهای ماشین عصبی تحت نظر و حفاظت از SJTU-NICT برای تابع ترجمه خبری WMT20', 'sw': "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", 'tr': "WMT20 Ha첵sy Terjime G철revi 체챌in SJTU-NICT'i흫 g철zle첵채n we Ta첵첵arlanmadyk Nural Makine Terjime Sistemleri", 'af': 'Name', 'am': "SJTU-NICT's Superwatched and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", 'az': 'WMT20 Haqq Çeviri Gözləşdirilmiş və Müdafiə edilməmiş Nüral Makina Çeviri Sistemləri SJTU-NICT', 'bn': "WMT20 সংবাদ অনুবাদ কাজের জন্য SJTU-NICT'র সুপারভিস্ট এবং অনভার্ভিশন নিউরাল মেশিন অনুবাদ সিস্টেম", 'id': "SJTU-NICT's Supervised and Unsupervised Machine Translation Systems for the WMT20 News Translation Task", 'bs': 'SJTU-NICT je nadgledan i neodređen Neuralni sistem prevoda za WMT20 novinski prevod', 'sq': "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", 'hy': 'SJTO-NYCT-ի Համաշխարհային ԶԼՄԹ20 նորությունների թարգմանման գործի վերահսկվող և անվերահսկվող նյարդային մեքենաների թարգմանման համակարգերը', 'ca': "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", 'fi': 'SJTU-NICT:n valvotut ja valvomattomat hermokonek채채nn철sj채rjestelm채t WMT20 News Translation -teht채v채채n', 'cs': 'Dohlížené a nekontrolované neuronové strojové překladatelské systémy SJTU-NICT pro WMT20 Novinky Překladatelská úloha', 'et': 'SJTU-NICTi järelevalvega ja järelevalveta neuromasintõlke süsteemid WMT20 uudiste tõlkimise ülesandeks', 'he': 'מערכות התרגום של מכונות עצביות מושלמות ולא מושלמות של SJTU-NICT למשימת התרגום חדשות WMT20', 'sk': 'SJTU-NICT nadzorovani in nenadzorovani sistemi nevralnega strojnega prevajanja za nalogo prevajanja novic WMT20', 'ha': '@ info: whatsthis', 'bo': "SJTU-NICT's Supervised and Unsupervised Neural Machine Translation Systems for the WMT20 News Translation Task", 'jv': "sjT-NITT's super-Vised lan Unuppe-Pasang Neral Mas Terjamah Sistem kanggo nggawe WW2 New Tarjamahan Job"}
{'en': 'In this paper, we introduced our joint team SJTU-NICT ‘s participation in the WMT 2020 machine translation shared task. In this shared task, we participated in four translation directions of three language pairs : English-Chinese, English-Polish on supervised machine translation track, German-Upper Sorbian on low-resource and unsupervised machine translation tracks. Based on different conditions of language pairs, we have experimented with diverse neural machine translation (NMT) techniques : document-enhanced NMT, XLM pre-trained language model enhanced NMT, bidirectional translation as a pre-training, reference language based UNMT, data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training. We also used the TF-IDF algorithm to filter the training set to obtain a domain more similar set with the test set for finetuning. In our submissions, the primary systems won the first place on English to Chinese, Polish to English, and German to Upper Sorbian translation directions.', 'ar': 'في هذه الورقة ، قدمنا مشاركة فريقنا المشترك SJTU-NICT في المهمة المشتركة للترجمة الآلية WMT 2020. في هذه المهمة المشتركة ، شاركنا في أربعة اتجاهات ترجمة لثلاث أزواج لغوية: الإنجليزية-الصينية ، والإنجليزية-البولندية على مسار الترجمة الآلية الخاضع للإشراف ، والألمانية-الصوربية العليا على مسارات الترجمة الآلية منخفضة الموارد وغير الخاضعة للإشراف. استنادًا إلى الظروف المختلفة للأزواج اللغوية ، جربنا تقنيات ترجمة آلية عصبية متنوعة (NMT): نموذج لغة NMT مُحسّن بالوثائق ، و XLM مُحسّن مسبقًا بلغة NMT ، وترجمة ثنائية الاتجاه كتدريب مسبق ، ولغة مرجعية تستند إلى UNMT ، وبيانات- الهدف السابق gaussian المعتمد ، والتدريب الذاتي للترشيح التعاوني BT-BLEU. استخدمنا أيضًا خوارزمية TF-IDF لتصفية مجموعة التدريب للحصول على مجال أكثر تشابهًا مع مجموعة الاختبار للضبط النهائي. في التقديمات التي قدمناها ، فازت الأنظمة الأساسية بالمركز الأول في اتجاهات الترجمة من الإنجليزية إلى الصينية ، ومن البولندية إلى الإنجليزية ، ومن الألمانية إلى الترجمة الصوربية العليا.', 'es': 'En este artículo, presentamos la participación de nuestro equipo conjunto SJTU-NICT en la tarea compartida de traducción automática del WMT 2020. En esta tarea compartida, participamos en cuatro direcciones de traducción de tres pares de idiomas: inglés-chino, inglés-polaco en la pista de traducción automática supervisada, alemán-sorabo superior en pistas de traducción automática sin supervisión y de pocos recursos. En función de las diferentes condiciones de los pares de idiomas, hemos experimentado con diversas técnicas de traducción automática neuronal (NMT): NMT mejorada con documentos, NMT mejorada con modelo de lenguaje preentrenado en XLM, traducción bidireccional como preentrenamiento, UNMT basada en el lenguaje de referencia, objetivo previo gaussiano dependiente de datos, y autoaprendizaje de filtrado colaborativo BT-BLEU. También utilizamos el algoritmo TF-IDF para filtrar el conjunto de entrenamiento para obtener un conjunto de dominio más similar con el conjunto de pruebas para el ajuste fino. En nuestras presentaciones, los sistemas principales ganaron el primer lugar en las direcciones de traducción del inglés al chino, del polaco al inglés y del alemán al sorabo superior.', 'fr': "Dans cet article, nous avons présenté la participation de notre équipe conjointe SJTU-NICT à la tâche partagée de traduction automatique WMT 2020. Dans le cadre de cette tâche partagée, nous avons participé à quatre directions de traduction de trois paires de langues\xa0: anglais-chinois, anglais-polonais sur la voie de la traduction automatique supervisée, et allemand-haut-sorabe sur des pistes de traduction automatique à faibles ressources et non supervisées. Sur la base de différentes conditions de paires de langues, nous avons expérimenté diverses techniques de traduction automatique neuronale (NMT)\xa0: NMT améliorée par document, NMT améliorée par modèle de langage XLM, traduction bidirectionnelle en tant que pré-apprentissage, UNMT basée sur un langage de référence, objectif préalable gaussien dépendant des données, et auto-formation sur le filtrage collaboratif BT-BLEU. Nous avons également utilisé l'algorithme TF-IDF pour filtrer le jeu d'apprentissage afin d'obtenir un ensemble de domaines plus similaire au jeu de test pour le réglage fin. Dans nos soumissions, les systèmes primaires ont remporté la première place dans les directions de traduction de l'anglais vers le chinois, du polonais vers l'anglais et de l'allemand vers le haut-sorabe.", 'pt': 'Neste artigo, apresentamos a participação de nossa equipe conjunta SJTU-NICT na tarefa compartilhada de tradução automática do WMT 2020. Nesta tarefa compartilhada, participamos de quatro direções de tradução de três pares de idiomas: inglês-chinês, inglês-polonês na faixa de tradução automática supervisionada, alemão-sérvio superior nas faixas de tradução automática de poucos recursos e não supervisionada. Com base em diferentes condições de pares de idiomas, experimentamos diversas técnicas de tradução automática neural (NMT): NMT aprimorado por documento, NMT aprimorado por modelo de idioma pré-treinado XLM, tradução bidirecional como pré-treinamento, UNMT baseado em idioma de referência, objetivo prévio gaussiano dependente e autotreinamento de filtragem colaborativa BT-BLEU. Também usamos o algoritmo TF-IDF para filtrar o conjunto de treinamento para obter um conjunto de domínio mais semelhante ao conjunto de teste para ajuste fino. Em nossas submissões, os sistemas primários ganharam o primeiro lugar nas direções de tradução de inglês para chinês, polonês para inglês e alemão para alto-sérvio.', 'ja': '本稿では、WMT 2020機械翻訳共有タスクへの共同チームSJTU - NICTの参加について紹介しました。 この共有タスクでは、3つの言語ペアの4つの翻訳ディレクションに参加しました。英語-中国語、監修された機械翻訳トラックの英語-ポーランド語、低リソースおよび監修されていない機械翻訳トラックのドイツ語-アッパーソルビア語です。 言語ペアのさまざまな条件に基づいて、私たちは多様なニューラル機械翻訳（ NMT ）技術を実験しました：文書強化NMT、XLM事前トレーニング言語モデル強化NMT、事前トレーニングとしての双方向翻訳、参照言語ベースのUNMT、データ依存ガウスの事前目標、およびBT - BLEU共同フィルタリング自己トレーニング。 また、ＴＦ － ＩＤＦアルゴリズムを使用して、トレーニングセットをフィルタリングし、微調整のための試験セットとより類似したドメインセットを取得した。 私たちの提出物では、プライマリシステムは英語から中国語、ポーランド語から英語、ドイツ語から上部ソルブ語の翻訳方向で1位を獲得しました。', 'zh': '本文引上海交通大学-NICT合团队与WMT 2020机器翻译共事。 当此之务,与三语对四译:英语 - 中文,英语 - 波兰语在监机器翻译,德语 - 上索布语在下机器翻译。 盖言语之异,试其异者神经机器翻译(NMT)术:文档强者NMT,XLM言者NMT,双向译者为之预训练,基于参言之UNMT,赖数之高BT-BLEU。 又用TF-IDF算法以过漉训练集,以得与测试集更相似者域集以行微调。 凡提交之材,主于英语至中文,波兰语至英语及德语上索布语译者第一。', 'ru': 'В этой статье мы представили участие нашей совместной команды SJTU-NICT в совместной задаче машинного перевода WMT 2020. В этом совместном задании мы участвовали в четырех направлениях перевода трех языковых пар: английско-китайское, английско-польское на поднадзорном треке машинного перевода, немецко-верхнесорбское на малоресурсном и неконтролируемом треке машинного перевода. Основываясь на различных условиях языковых пар, мы экспериментировали с различными методами нейронного машинного перевода (НМП): НМП с расширением документа, НМП с улучшенной языковой моделью XLM, двунаправленным переводом как предварительным обучением, ММП на основе эталонного языка, зависимой от данных гауссовой предшествующей целью и самообучением совместной фильтрации BT-BLEU. Мы также использовали алгоритм TF-IDF для фильтрации обучающего набора, чтобы получить более похожий набор доменов с набором тестов для тонкой настройки. В наших материалах первичные системы заняли первое место по направлениям перевода с английского на китайский, с польского на английский и с немецкого на верхний сорбский.', 'hi': 'इस पेपर में, हमने डब्ल्यूएमटी 2020 मशीन अनुवाद साझा कार्य में हमारी संयुक्त टीम एसजेटीयू-एनआईसीटी की भागीदारी पेश की। इस साझा कार्य में, हमने तीन भाषा जोड़े के चार अनुवाद दिशाओं में भाग लिया: पर्यवेक्षित मशीन अनुवाद ट्रैक पर अंग्रेजी-चीनी, अंग्रेजी-पोलिश, कम संसाधन और असुरक्षित मशीन अनुवाद पटरियों पर जर्मन-ऊपरी सोर्बियन। भाषा जोड़े की विभिन्न स्थितियों के आधार पर, हमने विविध तंत्रिका मशीन अनुवाद (एनएमटी) तकनीकों के साथ प्रयोग किया है: दस्तावेज़-संवर्धित एनएमटी, एक्सएलएम पूर्व-प्रशिक्षित भाषा मॉडल बढ़ाया एनएमटी, पूर्व-प्रशिक्षण के रूप में द्विदिश अनुवाद, संदर्भ भाषा आधारित यूएनएमटी, डेटा-निर्भर गाऊसी पूर्व उद्देश्य, और बीटी-बीएलईयू सहयोगी फ़िल्टरिंग आत्म-प्रशिक्षण। हमने टीएफ-आईडीएफ एल्गोरिथ्म का उपयोग प्रशिक्षण सेट को फ़िल्टर करने के लिए किया ताकि एक डोमेन को फाइनट्यूनिंग के लिए परीक्षण सेट के साथ अधिक समान सेट प्राप्त किया जा सके। हमारी प्रस्तुतियों में, प्राथमिक प्रणालियों ने चीनी के लिए अंग्रेजी, पोलिश से अंग्रेजी और जर्मन से ऊपरी सोर्बियन अनुवाद दिशाओं पर पहला स्थान जीता।', 'ga': "Sa pháipéar seo, thugamar isteach rannpháirtíocht ár gcomhfhoireann SJTU-NICT i dtasc comhroinnte aistriúcháin meaisín WMT 2020. Sa tasc comhroinnte seo, ghlacamar páirt i gceithre threoir aistriúcháin de thrí phéire teanga: Béarla-Sínis, Béarla-Polainnis ar rian aistriúcháin meaisín maoirsithe, Gearmáinis-Sorbais Uachtarach ar rianta aistrithe meaisín íseal-acmhainne agus gan mhaoirseacht. Bunaithe ar choinníollacha difriúla péirí teanga, rinneamar trialacha ar theicnící éagsúla néaraistriúcháin meaisín (NMT): NMT feabhsaithe doiciméad, NMT feabhsaithe samhail teanga réamh-oilte XLM, aistriúchán déthreoch mar réamh-oiliúint, teanga tagartha UNMT bunaithe, sonraí- cuspóir roimhe Gaissach spleách, agus féin-oiliúint scagtha comhoibríoch BT-BLEU. D'úsáideamar an t-algartam TF-IDF freisin chun an fhoireann oiliúna a scagadh chun fearann níos cosúla a fháil agus an tacar tástála le haghaidh mionchoigeartaithe. Inár n-aighneachtaí, bhuaigh na córais phríomha an chéad áit ar threoracha aistriúcháin Béarla go Sínis, Polainnis go Béarla, agus Gearmáinis go Soirbeach Uachtarach.", 'el': 'Σε αυτό το έγγραφο, παρουσιάσαμε τη συμμετοχή της κοινής ομάδας μας στο κοινό έργο μηχανικής μετάφρασης WMT 2020. Σε αυτό το κοινό έργο, συμμετείχαμε σε τέσσερις μεταφραστικές κατευθύνσεις τριών γλωσσικών ζευγαριών: Αγγλικά-Κινέζικα, Αγγλικά-Πολωνικά σε εποπτευόμενη διαδρομή μηχανικής μετάφρασης, Γερμανικά-Άνω Σορβικά σε διαδρομές μηχανικής μετάφρασης χαμηλού κόστους και χωρίς επίβλεψη. Βασιζόμενοι σε διαφορετικές συνθήκες γλωσσικών ζευγαριών, έχουμε πειραματιστεί με ποικίλες τεχνικές νευρωνικής μηχανικής μετάφρασης (NMT): ενισχυμένη με έγγραφα, προ-εκπαιδευμένη γλωσσική μοντέλο ενισχυμένη ΜΤ, αμφίδρομη μετάφραση ως προεκπαίδευση, βασισμένη στη γλώσσα αναφοράς, εξαρτώμενος από δεδομένα γάσσος προηγούμενος στόχος, και συνεργατική αυτοκατάρτιση φιλτραρίσματος BT-BLEU. Χρησιμοποιήσαμε επίσης τον αλγόριθμο για να φιλτράρουμε το σύνολο εκπαίδευσης για να αποκτήσουμε ένα πεδίο πιο παρόμοιο με το σύνολο δοκιμής για τον συντονισμό. Στις υποβολές μας, τα κύρια συστήματα κέρδισαν την πρώτη θέση στις οδηγίες μετάφρασης από Αγγλικά προς Κινέζικα, από Πολωνικά προς Αγγλικά και από Γερμανικά προς Άνω Σορβικά.', 'hu': 'Ebben a tanulmányban bemutattuk az SJTU-NICT közös csapatunk részvételét a WMT 2020 gépi fordítás megosztott feladatában. Ebben a közös feladatban három nyelvpár négy fordítási irányában vettünk részt: angol-kínai, angol-lengyel felügyelt gépi fordítási pályán, német-felső-szorbiai nyelven alacsony erőforrású és felügyelet nélküli gépi fordítási pályán. A nyelvpárok különböző feltételei alapján kísérleteztünk különböző neurális gépi fordítási (NMT) technikákkal: dokumentumokkal továbbfejlesztett NMT, XLM előképzett nyelvmodell továbbfejlesztett NMT, kétirányú fordítás előképzésként, referencia nyelven alapuló UNMT, adatfüggő gaussz előzetes célkitűzés és BT-BLEU kollaboratív szűrő önképzés. A TF-IDF algoritmust is használtuk az edzéskészlet szűrésére, hogy olyan domaint kapjunk, amely hasonlóbb a finomhangoláshoz szükséges tesztkészlettel. Pályázatainkban az elsődleges rendszerek nyerték el az első helyezést angolról kínára, lengyelről angolra és németről felső-szorbiai fordítási irányban.', 'ka': 'ამ დომენტში ჩვენ ჩვენი ერთადერთი ჯგუფი SJTU-NICT-ს გავაკეთეთ WMT 2020 მაქინის გადაწყვეტილი საქაღალდე. ამ გაყოფილი დავალებში, ჩვენ სამუშაობის სამუშაობის სამუშაობის სამუშაობის 4 წერტილების დაწყება: ანგლისური-კინელი, ანგლისური-პოლისური მანქანის დაწყება, გერმანეთი-სამუშაობის სამუშა ჩვენ განსხვავებული ენის ზოგების განსხვავებული შესახებ ვქცევრით განსხვავებული ნეიროლური მანქანის გაგრძელება (NMT) ტექნონებით: დოკუმენტი გაგრძელებული NMT, XLM წინ განსხვავებული ენის მოდელი გაგრძელებული NMT, მეორე განსხვავებული გაგრძელება როგორც წინ გაგრძელებული UNMT ჩვენ ასევე TF-IDF ალგორიტიმს გამოყენეთ, რომ ტრინტირებას სტრინტირება, რომელიც უფრო სხვადასხვა დიომინის მიღებად გამოიყენეთ ტესტის სტრინტირებას. ჩვენი შესახებ, პირველი სისტემები ინგლისური, პოლისური ანგლისური და გერმანური საზოგადო სორბური გადაწყვეტილება.', 'it': "In questo articolo, abbiamo presentato la partecipazione del nostro team congiunto SJTU-NICT al compito condiviso di traduzione automatica WMT 2020. In questo compito condiviso, abbiamo partecipato a quattro direzioni di traduzione di tre coppie linguistiche: inglese-cinese, inglese-polacco su pista di traduzione automatica supervisionata, tedesco-sorbiano su piste di traduzione automatica a basso costo e non supervisionate. Sulla base delle diverse condizioni delle coppie linguistiche, abbiamo sperimentato diverse tecniche di traduzione automatica neurale (NMT): NMT potenziato dai documenti, modello linguistico pre-addestrato XLM potenziato, traduzione bidirezionale come pre-formazione, UNMT basato sul linguaggio di riferimento, obiettivo gaussiano precedente dipendente dai dati e auto-training collaborativo BT-BLEU filtrante. Abbiamo anche usato l'algoritmo TF-IDF per filtrare il set di addestramento per ottenere un set di dominio più simile con il set di test per la finetuning. Nelle nostre proposte, i sistemi primari hanno vinto il primo posto nelle direzioni di traduzione dall'inglese al cinese, dal polacco all'inglese e dal tedesco all'Alta Sorbia.", 'lt': 'Šiame dokumente pristatėme mūs ų jungtinę komandą SJTU-NICT dalyvavimą bendroje WMT 2020 mašin ų vertimo užduotyje. Šioje bendroje užduotyje dalyvavome keturiose trijų kalbų poros vertimo kryptise: anglų-kinų, anglų-lenkų vertimo mašinomis kelyje, vokiečių-viršutinių sorbų kelyje, mažai išteklių turinčiose ir nepastebimose mašin ų vertimo kelėse. Atsižvelgdami į skirtingas kalbų poros sąlygas, eksperimentavome įvairiais nervinių mašinų vertimo (NMT) metodais: dokumentu patobulintas NMT, XLM iš anksto parengtas kalbų modelis patobulintas NMT, dvikryptis vertimas kaip išankstinis mokymas, referencine kalba pagrįstas UNMT, nuo duomenų priklausomas gausijos išankstinis tikslas ir BT-BLEU bendradarbiavimo filtravimo savarankiškas mokymas. Taip pat naudojome TF-IDF algoritmą, kad filtruotume mokymo rinkinį, kad gautume panašų domeno rinkinį su bandymų rinkiniu tobulinimui. Mūsų teiginiuose pagrindinės sistemos laimėjo pirmąją vietą anglų kalba kinų, lenkų kalba anglų kalba ir vokiečių kalba viršutinės sorbios vertimo kryptimis.', 'kk': 'Бұл қағазға біз бірге бірге бірге бірге бір командамыз SJTU-NICT WMT 2020 компьютердің ортақтастырылған тапсырмасына қатынасыз келді. Бұл ортақтастырылған тапсырманың төрт тіл екі аудармаларына қатынасыз: ағылшын- қытас, ағылшын- польша аудармалар жолында қатынасыз, неміс- Жоғарғы сорб тілінің төрт аудармаларына қатынасыз келді. Ағы Тілдердің басқа шарттарына негізделген, біз әртүрлі невралдық компьютердің аударуы (NMT) техникаларымен тәжірибедік: құжатты NMT, XLM алдын- оқылған тіл үлгісі NMT үлгісін өзгертіп, алдын- оқылған аударуы, UNMT негізделген сілтеме тілі, деректердің алдындағы гаусиялық мақ Біз сондай-ақ TF-IDF алгоритмін қолдандық, олардың бақылауын сүзгілеу үшін керек доменді сүзгілеу үшін, олардың бақылауын сүзгіледі. Біздің келтірімізде, негізгі жүйелер ағылшынша, Польша, ағылшынша және неміс тілінен жоғары сорб аудару бағыттарына алғашқы жетілді.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഞങ്ങളുടെ യൂട്ട് ടീം SJTU-NICT യുഎംടി 2020 മെഷീന്\u200d പരിഭാഷണത്തില്\u200d പങ്കുചേര്\u200dക്കുന്നതിന്\u200dറെ പങ്കാളിയില ഈ പങ്കാളിക്കപ്പെട്ട ജോലിയില്\u200d ഞങ്ങള്\u200d മൂന്നു ഭാഷകളുടെ ഭാഷകളുടെ നാലു പരിഭാഷത്തിന്റെ നേര്\u200dവഴികളില്\u200d പങ്കുചേര്\u200dന്നു. ഇംഗ്ലീഷ്- ചൈനീസ്, ഇംഗ്ലീഷ്- പോ ഭാഷ ജോടികളുടെ വ്യത്യസ്തമായ അവസ്ഥ അടിസ്ഥാനത്തില്\u200d നമ്മള്\u200d വ്യത്യസ്തമായി ന്യൂറല്\u200d മെഷീന്\u200d പരിശോധിച്ചിട്ടുണ്ട്: രേഖകള്\u200d മെച്ചപ്പെടുത്തിയ NMT, XLM മുന്\u200dപരിശീലിക്കപ്പെട്ട ഭാഷ മോഡല്\u200d NMT, മുന്\u200dപരിശീലനത്തിനു മുന്\u200d ടിഎഫ്-ഐഡിഎഫ് ആല്\u200dഗോരിത്മിനും ഞങ്ങള്\u200d ഉപയോഗിച്ചു ഫിന്തുണിങ്ങിനുള്ള പരീക്ഷണസെറ്റുകള്\u200d കൂടുതല്\u200d ഒരു ഡൊമെയിന്\u200d സെറ്റ്  ഞങ്ങളുടെ കീഴടങ്ങളില്\u200d, ആദ്യ സിസ്റ്റം ഇംഗ്ലീഷിലേക്ക് ചൈനീസിലേക്ക്, പോളിഷിലേക്കും ഇംഗ്ലീഷിലേക്കും ജര്\u200dമ്മനിലേക്', 'mk': 'Во овој весник, го претставивме учеството на нашиот заеднички тим СЈТУ-НИЦТ во заедничката задача за превод на машината WMT 2020. На оваа заедничка задача учествувавме во четири насоки за превод на три пара јазици: англиско-кинески, англиско-полски на надгледувана машинска трага, германско-горна Сорбијанка на ниски ресурси и ненадгледувани машински траги. Based on different conditions of language pairs, we have experimented with diverse neural machine translation (NMT) techniques: document-enhanced NMT, XLM pre-trained language model enhanced NMT, bidirectional translation as a pre-training, reference language based UNMT, data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training.  Исто така го користевме алгоритмот TF-IDF за филтрирање на тренингот за да добиеме посличен домен со тестот за финализација. Според нашите поднесувања, примарните системи освоија прво место на англиски на кинески, полски на англиски и германски на горниот сорбиски превод.', 'no': 'I denne papiret introdusere vi samfunnsgruppa SJTU-NICT i deltaket i WMT 2020-maskinsomsetjinga delt oppgåva. I denne delte oppgåva delta vi i fire omsetjingsrektingar med tre språkopar: Engelsk-kinesisk, engelsk-polsk på oversikt av maskineoversettelsspor, tysk-oppe-sorbisk på låg-ressursar og ikkje oppretta maskineoversettelsspor. Basert på forskjellige vilkår av språkparar, har vi eksperimentert med forskjellige teknikk for omsetjing av neiralmaskin (NMT): dokumentforbetra NMT, XLM-føretrained språk-modell forbetra NMT, bidireksjonal omsetjing som føreøving, referansspråk basert på UNMT, data-avhengig gaussisk føreøving, og BT-BLEU-samarbeidsfiltering selvøving. Vi brukte også TF-IDF-algoritmen for å filtrera øvingsinnstillingane for å få ein domene som er meir liknande med testinnstillingane for finetuning. I våre opplysningar vann primærsystema første plassen på engelsk til kinesisk, polsk til engelsk, og tysk til øvre sorbisk oversettelsesretningar.', 'pl': 'W niniejszym artykule przedstawiliśmy udział naszego wspólnego zespołu SJTU-NICT w wspólnym zadaniu tłumaczenia maszynowego WMT 2020. W tym wspólnym zadaniu uczestniczyliśmy w czterech kierunkach tłumaczenia trzech par językowych: angielsko-chiński, angielsko-polski na nadzorowanym ścieżce tłumaczenia maszynowego, niemiecki-górny na niskich zasobach i bez nadzoru ścieżkach tłumaczenia maszynowego. W oparciu o różne warunki par językowych, eksperymentowaliśmy z różnymi technikami neuronowego tłumaczenia maszynowego (NMT): wzmocnionym dokumentem NMT, wstępnie przeszkolonym modelem językowym XLM, dwukierunkowym tłumaczeniem jako szkoleniem przedszkoleniowym, językiem referencyjnym UNMT, zależnym od danych obiektem gazskim oraz samodzielnym szkoleniem filtrującym BT-BLEU. Wykorzystaliśmy również algorytm TF-IDF do filtrowania zestawu treningowego, aby uzyskać bardziej podobny zestaw domeny z zestawem testowym do finetuningu. W naszych zgłoszeniach systemy podstawowe zdobyły pierwsze miejsce w kierunkach tłumaczeń z angielskiego na chiński, polskiego na angielski oraz niemieckiego na górny sorbijski.', 'ro': 'În această lucrare, am prezentat participarea echipei noastre comune SJTU-NICT la sarcina comună de traducere automată WMT 2020. În această sarcină comună, am participat la patru direcții de traducere a trei perechi de limbi: engleză-chineză, engleză-poloneză pe pista de traducere automată supravegheată, germană-Sorbiană superioară pe piste de traducere automată cu resurse reduse și nesupravegheate. Pe baza diferitelor condiții ale perechilor de limbi, am experimentat diverse tehnici de traducere automată neurală (NMT): NMT îmbunătățit cu documente, modelul lingvistic pre-instruit XLM îmbunătățit, traducerea bidirecțională ca pre-instruire, limbajul de referință bazat pe UNMT, obiectivul anterior găuzian dependent de date și autoinstruirea prin filtrare colaborativă BT-BLEU. De asemenea, am folosit algoritmul TF-IDF pentru a filtra setul de instruire pentru a obține un set de domenii mai similar cu setul de test pentru finetuning. În propunerile noastre, sistemele primare au câștigat primul loc în direcțiile de traducere din engleză în chineză, poloneză în engleză și germană în Sorbiană Superioară.', 'ms': 'Dalam kertas ini, kami memperkenalkan persatuan pasukan SJTU-NICT dalam tugas terjemahan mesin WMT 2020. Dalam tugas berkongsi ini, kami berpartisipasi dalam empat arah terjemahan dari tiga pasangan bahasa: Bahasa Inggeris-Cina, Bahasa Inggeris-Polandia pada trek terjemahan mesin yang diawasi, Jerman-Upper Sorbian pada trek terjemahan mesin yang rendah sumber dan tidak diawasi. Berdasarkan keadaan berbeza pasangan bahasa, kami telah eksperimen dengan teknik terjemahan mesin saraf (NMT) berbeza: NMT berkembang dokumen, model bahasa dilatih-dilatih XLM berkembang NMT, terjemahan bidireksi sebagai praselatih, bahasa rujukan berdasarkan UNMT, objektif sebelumnya gausi tergantung pada data, dan penapisan kerjasama BT-BLEU self-training. Kami juga menggunakan algoritma TF-IDF untuk penapis set latihan untuk mendapatkan set domain yang lebih serupa dengan set ujian untuk penyesuaian. In our submissions, the primary systems won the first place on English to Chinese, Polish to English, and German to Upper Sorbian translation directions.', 'mt': 'F’dan id-dokument, introduċejna l-parteċipazzjoni tat-tim konġunt tagħna SJTU-NICT fil-kompitu konġunt tat-traduzzjoni tal-magni tad-WMT 2020. F’dan il-kompitu kondiviż, ipparteċipajna f’erba’ direzzjonijiet ta’ traduzzjoni ta’ tliet pari lingwistiċi: Ingliż-Ċiniż, Ingliż-Pollakk fuq binarji ta’ traduzzjoni bil-magni sorveljati, Ġermaniż-Sorbjan ta’ Fuq fuq binarji ta’ traduzzjoni bil-magni b’riżorsi baxxi u mhux sorveljati. Based on different conditions of language pairs, we have experimented with diverse neural machine translation (NMT) techniques: document-enhanced NMT, XLM pre-trained language model enhanced NMT, bidirectional translation as a pre-training, reference language based UNMT, data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training.  Użajna wkoll l-algoritmu TF-IDF biex niffiltraw is-sett tat-taħriġ biex inkisbu sett ta’ dominju aktar simili mas-sett tat-test għall-irfinar. In our submissions, the primary systems won the first place on English to Chinese, Polish to English, and German to Upper Sorbian translation directions.', 'sr': 'U ovom papiru, predstavili smo zajedničku ekipu SJTU-NICT sudjelovanje u zajedničkom zadatku za prevod mašine WMT 2020. U ovom zajedničkom zadatku, učestvovali smo u četiri smjera prevoda tri jezičkog parova: engleski kineski, engleski-poljski na nadziranom traku prevoda mašine, njemački-gornji sorbijanski na niskim resursima i neodređenim tragovima prevoda mašine. Na temelju različitih uvjeta jezičkih parova, eksperimentirali smo sa različitim tehnikama prevoda neuralnih mašina (NMT): unaprijeđenim NMT-om, XLM pre-obučenim jezičkim modelom unaprijeđenim NMT-om, dvoričnim prevodom kao predobuku, referentnim jezikom baziranim na UNMT-u, prethodnim ciljem gauzija ovisnom o podacima i autoobuku saradnje filtriranja BT-BLEU-a. Koristili smo i TF-IDF algoritam da filtriramo setu obuke kako bi dobili domenu sličniji sa testom za finetuning. U našim podacima, primarni sistem osvojio je prvo mesto na engleskom jeziku kineskom, poljskom na engleskom jeziku, i njemačkom na gornjem Sorbijskom prevodu.', 'sv': 'I denna uppsats presenterade vi vårt gemensamma team SJTU-NICT:s deltagande i WMT 2020:s gemensamma uppgift för maskinöversättning. I denna gemensamma uppgift deltog vi i fyra översättningsriktningar av tre språkpar: engelsk-kinesiska, engelsk-polska på övervakad maskinöversättning spår, tysk-övre sorbiska på lågresurs- och oövervakade maskinöversättningsspår. Baserat på olika förutsättningar för språkpar har vi experimenterat med olika tekniker för neural maskinöversättning (NMT): dokumentförbättrad NMT, XLM-förberedd språkmodell förbättrad NMT, dubbelriktad översättning som en pre-training, referensspråkbaserad UNMT, databeroende gaussiskt tidigare mål och BT-BLEU kollaborativ filtrering självträning. Vi använde även TF-IDF algoritmen för att filtrera träningsuppsättningen för att få en domän mer liknande uppsättning med testuppsättningen för finjustering. I våra bidrag vann de primära systemen förstaplatsen på engelska till kinesiska, polska till engelska och tyska till övre sorbiska översättningsriktningar.', 'si': 'මේ පත්තරේ අපි අපේ සම්බන්ධ කණ්ඩායම SJTU-NICT ` සම්බන්ධ කණ්ඩායම් විදිහට WMT-2020යි මැෂින් පරිවර්තනය සම මේ භාෂාවිත වැඩකට, අපි භාෂාවිතය තුනක් භාෂාවිතයේ භාෂාවිතයේ භාෂාවිතය හතර ප්\u200dරවේශ කරනවා: ඉංග්\u200dරීස්-චීනි, ඉංග්\u200dරීසි වෙනස් භාෂාවක් ජාති වලින් අවස්ථාවක් විසින් අවස්ථාවක් විසින් අපි පරීක්ෂා කරලා තියෙන්නේ වෙනස් න්\u200dයූරල් යන්ත්\u200dරය භාෂාව (NMT) තාක්ෂාවක් සමග: විශේෂ NMT, XLM ප්\u200dරීක්ෂාවිත භ අපි TF-IDF ඇල්ගෝරිතම් එක්ක භාවිතා කරලා ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් ලැබෙන්න ප්\u200dරශ්නයක් ස අපේ ප්\u200dරධාන පද්ධතියේ ඉංග්\u200dරීසියට පළමු ස්ථානය දින්නේ චීනි, පොලිෂ් ඉංග්\u200dරීසියට, ජර්මන් වල ඉංග්\u200dරී', 'so': "Qoraalkan waxan ku qornay kooxda wadajirka ah ee SJTU-NICT'da ka qayb galay tarjumaadka qoraalka WMT 2020. Markaas waxan lagu qeybinayay, waxaynu ka qeybqaadanay afar kooxaha turjuma oo saddex luuqadood ah: Ingiriis-Chinese, Ingiriis-Polish on supervised machine translation track, German-Upper Sorbian on low-resource and unsupervised machine translation tracks. Based on conditions kala duduwan oo luqada labo ah, we have experimented with various neural machine translation (NMT) techniques: document-enhanced NMT, XLM pre-trained model of language enhanced NMT, bidirectional translation as a pre-training, reference language based on UNMT, data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training. We also used the TF-IDF algorithm to filter the training set to obtain a domain more similar set with the test set for finetuning.  Isticmaalkanaga hoose waxay ku guulaysatay marka ugu horeysa ingiriisiga, Shiino, Boolis iyo Ingiriis, Jarmalkana waxay ku guuleysay hagitaanka turjumaadda Sorbiga sare.", 'ta': "இந்த காகிதத்தில், நாங்கள் எங்கள் இணைய குழு SJTU-NICT 'WMT 2020 இயந்திரம் மொழிபெயர்ப்பு பகிர்ந்த பணியில் கூடுதலாக அறிவித்தது. இந்த பகிர்ந்த பணியில், நாங்கள் மூன்று மொழி ஜோடிகளின் நான்கு மொழிபெயர்ப்பு திசைகளில் பங்கிடப்பட்டுள்ளோம்: ஆங்கிலம்- சீனா, ஆங்கிலம்- போலிஷ் மேலாளர்  @ info We also used the TF-IDF algorithm to filter the training set to obtain a domain more similar set with the test set for finetuning.  எங்கள் கொடுப்புகளில், முதல் அமைப்புகள் ஆங்கிலத்தில் முதல் இடத்தை சீன, போலிஷ் மேல் ஆங்கிலத்தில் வெற்றி கொண்டார்", 'mn': 'Энэ цаасан дээр бид WMT 2020-ийн машин орчуулагчийн ажлын хуваалцааны оролцоонд нийлүүлсэн багийг танилцуулсан. Энэ хуваалтын ажил дээр бид гурван хэл хоёрын төрлийн 4 давхарлалтын замаар оролцсон: Англи-Хятад, Англи-Польша, найдварлагдсан машин хөгжүүлэх замаар, Герман-Үд-Сорб хэл бага баялаг болон машин хөгжүүлэх зама Өөр хэл хоёр нөхцөлд бид өөр төрлийн мэдрэлийн машин хөрөнгө оруулалт (NMT) технологийг туршиж үзсэн. NMT, XLM өмнө сургалтын хэл загвар NMT-г нэмэгдүүлсэн бөгөөд хэл загвар нь өмнө сургалтын хөрөнгө оруулалт, UNMT-г багтаж байгаа Reference хэл, өгөгдлийн хамааралтай гаусийн өмнө зо Бид мөн TF-IDF алгоритмыг ашиглаж сургалтын сургалтыг шалгахын тулд илүү төстэй холбоотой холбоотой холбоотой байгуулах зорилготой. Бидний хэлэхэд анхны систем Англи хэлний, Польшийн, Англи хэлний, Герман хэлний дээд сорб хэлний орнуудад анхны анхны талаар ялсан.', 'ur': 'اس کاغذ میں ہم نے اپنے ملک تیم SJTU-NICT کو WMT 2020 ماشین ترجمہ کا مشترک کام میں مشترک کیا۔ ہم نے اس مشترک کام میں تین زبان جوڑوں کی چار ترجمہ کی طرف شامل کیا: انگلیسی-چینی، انگلیسی-پولچی ماشین ترجمہ ٹراک پر، جرمن-اوپر سوربیان کم-رسسور پر اور غیر قابل ترجمہ ماشین ترکیب پر۔ زبان جوڑوں کی مختلف شرایطوں پر، ہم نے مختلف نورول ماشین ترجمہ (NMT) ٹیکنیک کے ساتھ تجربہ کیا ہے: دکھائی-enhanced NMT, XLM pre-trained language model enhanced NMT، bidirectional translation as a pre-training, reference language based UNMT, data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training. ہم نے TF-IDF الگوریتم کو بھی استعمال کیا ہے کہ تدریس سٹ کو فلٹر کرنے کے لئے بہت سی ڈومین حاصل کرنے کے لئے آزمائش سٹ کے ساتھ۔ ہماری اطلاعات میں، نخستین سیستموں نے انگلیسی کی پہلی جگہ چینی، پولیش کی انگلیسی اور جرمانی کی اوپر سوربیان کی ترجمہ طریقوں پر غالب آئی۔', 'vi': 'Trong tờ giấy này, chúng tôi đã giới thiệu nhóm chung JT-NIST... tham gia vào công việc dịch chuyển máy WRT 2020. Trong nhiệm vụ chia sẻ này, chúng tôi đã tham gia bốn hướng dịch của ba cặp ngôn ngữ: Anh-Chinese, Anh-Polish trên một đường ray dịch-máy giám sát, German-Upper Sorbian trên đường ray dịch-máy ít tài nguyên và không giám sát. Dựa trên các điều kiện khác nhau của các cặp ngôn ngữ, chúng tôi đã thử nghiệm với các kỹ thuật dịch biến máy thần kinh khác nhau (NMB): phát triển văn bản NMT, XMM đã được đào tạo theo một mô hình ngôn ngữ nâng cao cao NMT, dịch trực tiếp như là tiền đào tạo, từ ngôn ngữ tham khảo ý nghĩa UNMT, nhờ dữ liệu dựa trên người người theo Chúng tôi cũng dùng thuật to án TF-IDF để lọc bộ sửa tập tin để đạt được một miền tương tự hơn so với bộ thử để đặt độ chính xác. Trong những tài liệu của chúng tôi, hệ thống chính đã chiếm vị trí đầu tiên về Anh ngữ với Trung Quốc, Ba Lan và Anh, và Đức với hướng dịch phân loại cao cấp.', 'uz': "Bu qogʻozda biz WMT 2020 maskin tarjimalari bilan birlashtirilgan vazifani SJTU-NICT'ning birlashtirishni anglatdik. Bu bir necha vazifani biz uchta tillar ikkita xitoblar uchun to'rt tarjima yoʻnalishga ega bo'lgan: Inglizcha- Xitoycha, Inglizcha- Polish, supervised maskin tarjima track, Olmon- Yuqori Sorbchadan lavha resource va saqlangan maskin tarjima tracks. @ info: status Biz ደግሞ TF-IDF algorithidan foydalanamiz, fintug'i uchun bir xil domen moslamani olish uchun tizimni filterlash uchun. Bizning imkoniyatlarimizda birinchi asosiy tizimlar ingliz tilida Xitoycha, Polish va Inglizchaga Olmonchaga yuqori Sorbchaga tarjima qilishga yetarlicha bo'ldi.", 'bg': 'В този доклад представихме участието на съвместния ни екип в съвместната задача за машинен превод. В тази споделена задача участвахме в четири направления за превод на три езикови двойки: английски-китайски, английски-полски на следен машинен превод, немски-горно сорбийски на следи с нисък ресурс и без надзор машинен превод. Въз основа на различни условия на езикови двойки, експериментирахме с различни техники за невронен машинен превод (НМТ): усъвършенстван с документи НМТ, усъвършенстван с предварително обучен езиков модел НМТ, двупосочен превод като предварителна подготовка, базиран на референтен език НМТ, зависима от данните гаусска предварителна цел и съвместно филтриране на самообучение. Използвахме и алгоритъма за филтриране на тренировъчния комплект, за да получим домейн по-подобен комплект с тестовия комплект за фино настройване. В нашите предложения първичните системи спечелиха първо място в направленията за превод от английски на китайски, полски на английски и немски на горно сорбийски.', 'nl': 'In dit artikel introduceerden we de deelname van ons gezamenlijk team SJTU-NICT aan de gedeelde taak voor machinevertaling WMT 2020. In deze gezamenlijke taak namen we deel aan vier vertaalrichtingen van drie taalparen: Engels-Chinees, Engels-Pools op begeleid machinevertaalspoor, Duits-Bovensorbisch op laag-resource en onbeheerde machinevertaalsporen. Gebaseerd op verschillende omstandigheden van taalparen, hebben we geëxperimenteerd met verschillende neurale machine translation (NMT) technieken: document-verbeterde NMT, XLM voorgetrainde taalmodel verbeterd NMT, bidirectionele vertaling als pre-training, referentietaal gebaseerd UNMT, data-afhankelijke gaussische voorafgaande doelstelling, en BT-BLEU collaboratieve filtering zelftraining. We gebruikten ook het TF-IDF algoritme om de trainingsset te filteren om een domein te verkrijgen dat meer vergelijkbaar is met de testset voor finetuning. In onze inzendingen wonnen de primaire systemen de eerste plaats op vertaalrichtingen van Engels naar Chinees, Pools naar Engels en Duits naar Opper-Sorbisch.', 'da': 'I denne artikel introducerede vi vores fælles team SJTU-NICT `s deltagelse i WMT 2020 maskinoversættelse delte opgave. I denne fælles opgave deltog vi i fire oversættelsesretninger af tre sprogpar: engelsk-kinesisk, engelsk-polsk på overvåget maskinoversættelsesspil, tysk-øversorbisk på lav ressource og ukontrolleret maskinoversættelsesspil. Baseret på forskellige betingelser for sprogpar, har vi eksperimenteret med forskellige neurale maskinoversættelsesteknikker (NMT): dokumentforbedret NMT, XLM forudtrænet sprogmodel forbedret NMT, bidirektionel oversættelse som forudtræning, referencesprogsbaseret UNMT, dataafhængig gaussisk forudgående mål og BT-BLEU samarbejdsfiltrering selvtræning. Vi brugte også TF-IDF algoritmen til at filtrere træningssættet for at opnå et domæne mere lignende sæt med testsættet til finjustering. I vores indlæg vandt de primære systemer førstepladsen på engelsk til kinesisk, polsk til engelsk og tysk til øverste sorbisk oversættelsesretninger.', 'hr': 'U ovom papiru smo predstavili zajedničku ekipu SJTU-NICT sudjelovanje u zajedničkom zadatku za prevod strojeva WMT 2020. U ovom zajedničkom zadatku, sudjelovali smo u četiri smjera prevođenja trih jezičkih parova: engleski kineski, engleski-poljski na nadzornom traku prevođenja strojeva, Njemački-Gornji Sorbijanski na nizim resursima i neodržavanim tragovima prevođenja strojeva. Na temelju različitih uvjeta jezičkih parova, eksperimentirali smo s različitim tehnikama prevoda neuralnih strojeva (NMT): povećan NMT, XLM predobučeni jezički model poboljšan NMT, dvorični prevod kao predobuku, referentni jezik baziran na UNMT-u, prednji cilj gausijskog objekta ovisnog o podacima i autoobuku saradnje filtriranja BT-BLEU-a. Također smo koristili algoritam TF-IDF-a kako bi filtrirali nastup obuke kako bi dobili domenu sličniji s testom za finetuning. U našim podacima, primarni sustavi osvojili su prvo mjesto na engleskom jeziku kineskom, poljskom na engleskom jeziku, i njemačkom na gornjem srpskom prevodu.', 'de': 'In diesem Beitrag stellten wir die Teilnahme unseres gemeinsamen Teams SJTU-NICT an der gemeinsamen Aufgabe der maschinellen Übersetzung WMT 2020 vor. In dieser gemeinsamen Aufgabe beteiligten wir uns an vier Übersetzungsrichtungen von drei Sprachpaaren: Englisch-Chinesisch, Englisch-Polnisch auf überwachten maschinellen Übersetzungsbahnen, Deutsch-Obersorbisch auf ressourcenarmen und unbeaufsichtigten maschinellen Übersetzungsbahnen. Basierend auf verschiedenen Bedingungen von Sprachpaaren haben wir mit verschiedenen neuronalen maschinellen Übersetzungstechniken (NMT) experimentiert: dokumentenverstärktes NMT, vortrainiertes XLM-Sprachmodell verbessertes NMT, bidirektionale Übersetzung als Vortraining, referenzsprachbasiertes UNMT, datenabhängiges gaussisches Vorziel und BT-BLEU kollaboratives Filtern Selbsttraining. Wir haben auch den TF-IDF Algorithmus verwendet, um den Trainingssatz zu filtern, um eine Domäne zu erhalten, die dem Testsatz zur Feinabstimmung ähnlicher ist. In unseren Einreichungen gewann das primäre System den ersten Platz in den Übersetzungsrichtungen Englisch nach Chinesisch, Polnisch nach Englisch und Deutsch nach Obersorbisch.', 'fa': 'در این کاغذ، ما تیم مشترک SJTU-NICT را در کار مشترک ترجمه ماشین WMT 2020 معرفی کردیم. در این کار مشترک، ما در چهار مسیر ترجمه\u200cای از سه جفت زبان شرکت کردیم: انگلیسی-چینی، انگلیسی-لهستانی در مسیر ترجمه\u200cهای ماشین تحت نظر گرفته، سوربانی آلمانی-بالا در مسیر ترجمه\u200cهای ماشین کم و غیرقابل تحت نظر گرفته. Based on different conditions of language pairs, we have experimented with various neural machine translation (NMT) techniques: document-enhanced NMT, XLM pre-trained language model enhanced NMT, binary translation as a pre-training, reference language based UNMT, data-dependent gaussian prior objective, and BT-BLEU self-training. ما همچنین از الگوریتم TF-IDF استفاده کردیم تا مجموعه تمرین را فیلتر دهیم تا یک مجموعه شبیه\u200cتری با مجموعه آزمایش برای آزمایش پاکیزه\u200cسازی داشته باشیم. در اطلاعات ما، سیستم اصلی اولین بار در انگلیسی به چینی، پولش به انگلیسی و آلمانی به ترجمه سوربی بالا برد.', 'ko': '본고에서 우리는 우리의 연합팀인 SJTU-NICT가 WMT 2020 기계번역 공유 임무에 참여한 상황을 소개했다.이 공유 임무에서 우리는 세 가지 언어가 맞는 네 가지 번역 방향에 참여했다. 그것이 바로 기계 번역 궤도에 있는 영어-중국어, 영어-폴란드어, 저자원과 무감독 기계 번역 궤도에 있는 독일어 상부어이다.서로 다른 언어 대조 조건을 바탕으로 우리는 서로 다른 신경기계번역(NMT) 기술을 시험했다. 문서증강 NMT, XLM예훈련 언어모델증강 NMT, 예훈련의 양방향 번역, 참고언어를 바탕으로 하는 UNMT, 데이터에 의존하는 고스 선험목표와 BT-BLEU가 함께 필터링을 실시했다.또한 TF-IDF 알고리즘을 사용하여 트레이닝 세트를 필터링하여 미세 조정을 위해 테스트 세트와 비슷한 도메인 세트를 얻습니다.우리가 제출한 자료 중 초급 시스템은 영어부터 중국어, 폴란드어부터 영어, 독일어부터 상소포어까지의 번역 방향에서 1위를 차지했다.', 'sw': 'Katika karatasi hii, tulitambua timu yetu ya pamoja ya SJTU-NICT ya kushiriki katika tafsiri ya mashine ya WMT 2020. Katika juhudi hili lililoshirikishwa, tulishiriki katika maelekezo minne ya tafsiri ya wanandoa watatu wa lugha: Kiingereza-China, Kiingereza-Polish juu ya mfumo wa kutafsiri mashine, Kijerumani-Sorbia wa Juu kwenye rasilimali chini na njia za tafsiri za mashine isiyo hifadhiwa. Kutokana na mazingira tofauti ya wanaume wa lugha, tumejaribu kwa mbinu mbalimbali za utafsiri wa mashine ya neurali (NMT): nyaraka zilizoongezeka NMT, Mradi wa lugha ya awali wa XLM uliongezea NMT, tafsiri ya kivitabu kama mafunzo ya mbele, kutafsiri lugha za maoni yenye UNMT, lengo la kigaussia wa data-tegemea kabla, na shirika la BT-BLEU kuchuja mafunzo ya kujifunza. Pia tulitumia utaratibu wa TF-IDF kuchuja mafunzo ya treni ili kupata kituo kama hicho kinachofanana na kituo cha majaribio kwa ajili ya kutafuta mafunzo. Katika ujumbe wetu, mifumo ya msingi ilishinda nafasi ya kwanza kwa Kiingereza kwa Kichina, Wapolesi na Kiingereza, na Ujerumani kwenda kwenye maelekezo ya tafsiri ya Sorbia ya juu.', 'tr': "Bu kagyzda, WMT 2020-nji maşynyň beýleki toparymyzy SJTU-NICT'yň goşulyşyny bardyk. Bu paylaşyk işinde, üç dil çift üçin terjime edilen dört gezek: Iňlisçe-Çin çe, Iňlisçe-Polonça maşynyň terjime täzisinde, Almança-Üst Sorbça iň az resurslar we masynyň terjime täzisinde goşuldyk. Dil çiftlikleriniň farklı şartlaryna görä, biz dürli neiral maşynyň terjimeleri (NMT) tehnikalary bilen synanyşdyrdyk: document-enhanced NMT, XLM öň-bilinmiş dil modeli NMT'i geliştirdik, terjime edil öň-okuwçysy hökmünde, UNMT tabanly referens dili, data-baglanyşlaryň öňki maksady we BT-BLEU filterlik özi-okuwçysy bilen birleştirildik Biz hem TF-IDF algoritmini finetuning testi üçin bir domein beýleki düzümlenmesi üçin filtrelemek üçin ullandyrdyk. Biziň görkezilişimizde ilkinji sistemalar iňlisçe, Polonça iňlisçe we Almança üst-sorbiýa terjime edilmeleri ýeňdi.", 'af': "In hierdie papier het ons ons joint team SJTU-NICT se deelnadering in die WMT 2020 masjien vertaling gedeelde taak ingestel. In hierdie gedeelde taak het ons gedeel in vier vertalingsdireksies van drie taal paar: Engels-Sjinees, Engels-Poles op besig masjien vertaling snit, Duits-Boppe-Sorbiese op lae-hulpbron en onbesig masjien vertaling snitte. Op verskillende voorwaardes van taal paar het ons eksperimenteer met verskillende neurale masjien vertaling (NMT) teknike: document-enhanced NMT, XLM pre-trained taal model verbeter NMT, bidireksjoneel vertaling as 'n voorvoerring, verwysingspraak gebaseer UNMT, data-afhanklik gaussian voorheede doel en BT-BLEU-collaborative filtering self-oerring. Ons het ook die TF-IDF-algoritme gebruik om die onderwerp stel te filter om 'n domein meer gelykbaar stel te kry met die toets stel vir finetuning. In ons voorskrifte het die primêre stelsels die eerste plek op Engels gewen aan Sinees, Poles tot Engels en Duitse tot Boonste Sorbiese vertalingsdireksies.", 'am': 'በዚህ ካላት፣ SJTU-NICT በWMT 2020 machine ትርጉም ላይ ተግባር ተግባራችንን እናሳውቃለን፡፡ በዚህ በተካፈሉት ስራ ላይ ሦስት ቋንቋዎች ዓይነቶች ላይ አራት ትርጉም መንገድ ተጋርተናል፤ እንግሊዘኛ-ቻይኛ፣ እንግሊዘኛ-ፖሊሽ በተጠበቀው የmachine ትርጉም ግንኙነት፣ ጀርመን-ላይኛ ሶርቢያ በዝቅተኛ-resource እና unsupervised machine translation tracks. Based on different conditions of language pairs, we have experimented with diverse neural machine translation (NMT) techniques: document-enhanced NMT, XLM pre-trained language model enhanced NMT, bidirectional translation as a pre-training, reference language based UNMT, data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training.  እናም TF-IDF-አልጎሪትምን ለመጠየቅ ተጠቃሚ ነበር፤ ለፍኒስቴን ለመፈተና የተደረገውን ዶሜን ለመግለጥ ይችላል፡፡ በተገኘን አዋጅ፣ የመጀመሪያው ስርዓቶች በንግግሊዝኛ፣ ፖሊሽ ወደ ኢንግሊዘኛ እና ጀርመን ወደ ላይኛይቱ ሶርባዊ ትርጉም መንገድ አሸነፈው፡፡', 'sq': 'Në këtë letër, ne paraqitëm pjesëmarrjen e ekipit tonë të përbashkët SJTU-NICT në detyrën e përkthimit të përbashkët të makinave WMT 2020. Në këtë detyrë të përbashkët, morëm pjesë në katër drejtime përkthimi të tre çifteve gjuhësh: anglisht-kinez, anglisht-polak në gjurmën e përkthimit të mbikqyrur nga makina, gjerman-sorbik në gjurmët e përkthimit të ulët nga burimet dhe të pa mbikqyrur nga makina. Bazuar në kushte të ndryshme të çifteve gjuhësh, ne kemi eksperimentuar me teknika të ndryshme të përkthimit të makinave nervore (NMT): NMT të përmirësuar me dokumente, model gjuhësh të paratrajnuar XLM të përmirësuar NMT, përkthimi dy-drejtues si një paratrajnim, gjuhë e referencës bazuar UNMT, objektiv të paraardhshëm gazian i varur nga të dhënat dhe BT-BLEU bashkëpunim filtrim vetë-trajnimi. Përdorëm gjithashtu algoritmin TF-IDF për të filtruar sistemin e trajnimit për të marrë një domeni më të ngjashëm me sistemin e testit për përmirësim. Në paraqitjet tona, sistemi kryesor fitoi vendin e parë në drejtimet e përkthimit të anglisht në kinez, polak në anglisht dhe gjerman në sorbin e lartë.', 'bn': 'এই কাগজটিতে আমরা আমাদের যৌথ দল SJTU-NICT-এর অংশগ্রহণের পরিচয় প্রদান করেছি WMT ২০২০ মেশিন অনুবাদের কাজ শেয়ার করেছে। এই শেয়ার কর্মসূচীতে আমরা তিন ভাষার জোড়ার চারটি অনুবাদে অংশগ্রহণ করেছি: ইংরেজী চীনা, ইংরেজী পোলিশ, পর্যবেক্ষণ করা মেশিন অনুবাদ ট্র্যাক, জার্মান-উপর সোরবিয়ান ভাষার বিভিন্ন পরিস্থিতির ভিত্তিতে আমরা বিভিন্ন নিউরেল মেশিন অনুবাদ (এনএমটি) প্রযুক্তি দিয়ে পরীক্ষা করেছি: ডকুমেন্ট-উন্নত NMT, XLM প্রাক্তন প্রশিক্ষিত ভাষার মডেল এনএমটি বাড়িয়ে দিয়েছে, পূর্ব-প্রশিক্ষণ, উ এছাড়াও আমরা টিএফ-আইডিএফ অ্যালগরিদম ব্যবহার করেছিলাম ফিনিস্টার করার জন্য প্রশিক্ষণের সেট ফিল্টার করার জন্য একটি ডোমেইনের মতো  আমাদের প্রধান ব্যবস্থা ইংরেজি থেকে চীনা, পোলিশ থেকে ইংরেজি এবং জার্মান উপর সোর্বিয়ার অনুবাদের নির্দেশে প্রথম স্থান জ', 'hy': "Այս թղթի մեջ մենք ներկայացրեցինք մեր համախմբված թիմի SJTO-Nikt-ի մասնակցությունը ՀԱՄ 2020-ի մեքենայի թարգմանման համախմբված հանձնարարության մեջ: Այս ընդհանուր խնդրում մենք մասնակցեցինք երեք լեզվի զույգերի թարգմանման չորս ուղղություններում' անգլերեն-չինարեն, անգլերեն-պոլլանդական մեքենայի թարգմանման հնարավորության վրա, գերմաներեն-վերևի սորբյան ցածր ռեսուրսների և անվեր Based on different conditions of language pairs, we have experimented with diverse neural machine translation (NMT) techniques: document-enhanced NMT, XLM pre-trained language model enhanced NMT, bidirectional translation as a pre-training, reference language based UNMT, data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training.  Մենք նաև օգտագործեցինք ԹՖ-IDF ալգորիթմը փորձարկումների սարքի ֆիլտրելու համար, որպեսզի ստանանք ավելի նման տիեզերք փորձարկումների սարքի հետ: Մեր ներկայացումներում հիմնական համակարգերը առաջին հերթին հաղթեցին անգլերեն չինարեն, պողաներեն անգլերեն և գերմաներեն բարձր սորբյան թարգմանման ուղղություններով:", 'bs': 'U ovom papiru smo predstavili zajedničku ekipu SJTU-NICT sudjelovanje u zajedničkom zadatku za prevod strojeva WMT 2020. U ovom zajedničkom zadatku, učestvovali smo u četiri smjera prevoda tri jezičkog parova: engleski kineski, engleski-poljski na nadzornom traku prevoda stroja, njemački-gornji sorbijanski na niskim resursima i neodređenim tragovima prevoda stroja. Na temelju različitih uvjeta jezičkih parova, eksperimentirali smo s različitim tehnikama prevoda neuronskih strojeva (NMT): povećan NMT, XLM predobučeni jezički model poboljšao je NMT, dvorični prevod kao predobuku, referentni jezik baziran na UNMT-u, prednji cilj gausijskog objekta ovisnog o podacima i autoobuku saradnje filtriranja BT-BLEU. Također smo koristili algoritam TF-IDF-a da filtriramo setu obuke kako bi dobili domenu sličniji sa testom za finetuning. U našim podacima, primarni sistem osvojio je prvo mjesto na engleskom jeziku kineskom, poljskom na engleskom jeziku, i njemačkom na nadzorskom prevodu.', 'az': 'Bu kağızda, WMT 2020 maşına çevirilməsi paylaşılan işlərdə birlikdə SJTU-NICT ekibimizi tanıdıq. Bu paylaşılmış işdə üç dil çiftlərinin dörd çeviri yollarına daxil olduq: İngilizce-Çinli, İngilizce-Polonca maşın çeviri yollarında, Alman-Yuxarı Sorbi düşük ressurs və maşın çeviri yollarında daxil olduq. Dil çiftlərinin müxtəlif şartlarına görə, biz müxtəlif nöral makina çeviri (NMT) tehnikləri ilə təcrübə etdik: document-enhanced NMT, XLM pre-trained dil modeli NMT-i artırdı, bidirectional çeviri ön təcrübə, referens dili UNMT-i dayanan, data-dependent gaussian əvvəlki məqsədili və BT-BLEU işbirlikli filtr təcrübəsi olaraq təcrübə etdik. Biz də TF-IDF algoritmi ilə finetuning üçün daha bənzər bir domena sahibi olmaq üçün təhsil quruğunu filtrləmək üçün istifadə etdik. Bizim təsdiqlərimizdə ilk sistemlər İngilizce dilində Çincə, Polonca dilində və Almanca dilində ən yüksək sorba çevirilməsi tərəfindən qaldılar.', 'id': "Dalam kertas ini, kami memperkenalkan tim bersama kami SJTU-NICT's berpartisipasi dalam tugas terjemahan mesin WMT 2020. In this shared task, we participated in four translation directions of three language pairs: English-Chinese, English-Polish on supervised machine translation track, German-Upper Sorbian on low-resource and unsupervised machine translation tracks.  Berdasarkan kondisi yang berbeda dari pasangan bahasa, kami telah eksperimen dengan teknik terjemahan mesin saraf berbeda (NMT): NMT yang diperbaiki dokumen, model bahasa yang dilatih-dilatih XLM yang diperbaiki NMT, terjemahan bidireksi sebagai prapelatih, bahasa referensi berdasarkan UNMT, objek sebelumnya gausi tergantung pada data, dan BT-BLEU koleboratif filtrasi self-training. Kami juga menggunakan algoritma TF-IDF untuk filter set latihan untuk mendapatkan domain yang lebih mirip set ujian untuk finetuning. Dalam pengiriman kami, sistem utama memenangkan tempat pertama dalam bahasa Inggris ke Cina, Polandia ke Inggris, dan Jerman ke arah terjemahan Sorbia Atas.", 'ca': "En aquest article vam presentar la participació del nostre equip conjunt SJTU-NICT en la tasca compartida de traducció de màquines WMT 2020. En aquesta tasca compartida, vam participar en quatre direccions de traducció de tres parells de llengües: anglès-xinès, anglès-polac en pista de traducció màquina supervisada, alemany-sorbia superior en pistes de traducció màquina de baix recursos i no supervisada. Sobre la base de diferents condicions dels parells de llenguatges, hem experimentat amb diverses tècniques de traducció neural de màquines (NMT): NMT millorat amb documents, model de llenguatge pré-entrenat XLM millorat NMT, traducció bidireccional com a pré-entrenament, UNMT basat en llenguatge de referència, objectiu anterior gaussià dependent de dades i autoentrenament de filtració col·laborativa BT-BLEU. També vam utilitzar l'algoritme TF-IDF per filtrar el conjunt d'entrenaments per aconseguir un conjunt de domini més similar amb el conjunt d'exàmens per a finar. En les nostres suposicions, els sistemes primàries van guanyar el primer lloc en direccions de traducció d'anglès a xinès, polac a anglès i alemany a sorbia superior.", 'cs': 'V tomto článku jsme představili účast našeho společného týmu SJTU-NICT na sdíleném úkolu strojového překladu WMT 2020. V rámci tohoto společného úkolu jsme se podíleli na čtyřech směrech překladu tří jazykových párů: anglicko-čínština, anglicko-polština na strojovém překladu s dohledem, německo-horní sorbština na strojovém překladu s nízkými zdroji a bez dozoru. Na základě různých podmínek jazykových párů jsme experimentovali s různými technikami neuronového strojového překladu (NMT): dokumentově vylepšeným NMT, předškoleným modelem jazyka XLM, obousměrným překladem jako předškolení, referenčním jazykovým UNMT, datově závislým gauským předchozím cílem a samostatným filtrováním BT-BLEU. Také jsme použili algoritmus TF-IDF k filtrování tréninkové sady, abychom získali doménu podobnější sadu s testovací sadou pro jemné ladění. V našich příspěvcích získaly primární systémy první místo v překladatelských směrech z angličtiny do čínštiny, z polštiny do angličtiny a z němčiny do hornosorbštiny.', 'fi': 'Tässä artikkelissa esittelimme yhteisen tiimimme SJTU-NICT:n osallistumisen WMT 2020 -konekäännöksen yhteiseen tehtävään. Tässä yhteisessä tehtävässä osallistuimme neljään käännössuuntaan kolmella kieliparilla: englanti-kiina, englanti-puola valvotulla konekäännösradalla, saksa-yläsorbian vähäresurssisilla ja valvomattomilla konekäännösradoilla. Kieliparien erilaisten olosuhteiden perusteella olemme kokeilleet erilaisia neurokonekäännöstekniikoita: dokumentti-tehostettua NMT:tä, XLM-esikoulutettua kielimallia, kaksisuuntaista kääntämistä esikoulutuksena, viitekielipohjaista UNMT:tä, datariippuvaista gaussilaista tavoitetta ja BT-BLEU:n yhteistoiminnallista suodatuskoulutusta. Käytimme myös TF-IDF-algoritmia suodattaaksemme harjoitusjoukon saadaksemme samanlaisen domeenin kuin hienosäätötestin kanssa. Pääasialliset järjestelmät voittivat julkaisuissamme ensimmäisen sijan englannin-kiinan, puolan-englannin ja saksan-yläsorbian käännösohjeissa.', 'et': 'Käesolevas töös tutvustasime oma ühismeeskonna SJTU-NICT osalemist WMT 2020 masintõlke jagatud ülesandes. Selles ühises ülesandes osalesime neljas tõlkesuunas kolmest keelepaarist: inglise-hiina, inglise-poola masintõlke jälgimise teel, saksa-ülemsorbia keel madala ressursiga ja järelevalveta masintõlke rajal. Tuginedes erinevatele keelepaaride tingimustele, oleme eksperimenteerinud mitmesuguseid neuraalse masintõlke (NMT) tehnikaid: dokumentidega täiustatud NMT, XLM eelõpetatud keelemudeli täiustatud NMT, kahesuunaline tõlge eelkoolitusena, võrdluskeel põhinev UNMT, andmetest sõltuv gausia eelnev eesmärk ja BT-BLEU koostöö filtreerimise eneseõpe. Samuti kasutasime TF-IDF algoritmi, et filtreerida treeningkomplekti, et saada domeeni sarnasem komplekt koos peenhäälestuse testikomplektiga. Meie ettepanekutes võitsid esmased süsteemid esimese koha inglise keelest hiina keelde, poola keelest inglise keelde ja saksa keelest Ülemsorbiini keelde.', 'sk': 'V prispevku smo predstavili sodelovanje skupne ekipe SJTU-NICT v skupni nalogi strojnega prevajanja WMT 2020. V tej skupni nalogi smo sodelovali v štirih prevajalskih smereh treh jezikovnih parov: angleščina-kitajščina, angleščina-poljščina na nadzorovani progi strojnega prevajanja, nemščina-zgornji sorbijščina na sledeh strojnega prevajanja z nizkimi viri in brez nadzora. Na podlagi različnih pogojev jezikovnih parov smo eksperimentirali z različnimi tehnikami nevronskega strojnega prevajanja (NMT): dokumentirano izboljšano NMT, XLM izboljšano NMT, dvosmerno prevajanje kot predusposabljanje, referenčno jezikovno osnovano UNMT, od podatkov odvisni gausski predhodni cilj in samousposabljanje BT-BLEU za filtriranje. Uporabili smo tudi algoritem TF-IDF za filtriranje nabora treningov, da bi dobili domeno bolj podoben naboru s testnim naborom za fino nastavitev. V naših prispevkih so osvojili prvo mesto na področju prevajanja angleščine v kitajščino, poljščine v angleščino in nemščine v zgornjo sorbijščino.', 'he': 'בעיתון הזה הצגנו את השתתפות של צוות המשותף שלנו SJTU-NICT בתרגום מכונות WMT 2020 משימה משותפת. במשימה המשותפת הזו, השתתפנו בארבעה כיוונים של שלושה זוגות שפות: אנגלית-סינית, אנגלית-פולנית על מסלול התרגום המכונה שמושגיח, גרמנית-סורבית על מסלולים התרגום המכונה נמוכים ולא מושגיחים. בהתבסס על תנאים שונים של זוגות שפות, ניסונו עם טכניקות מתרגמת מכונות עצביות (NMT) מגוונות: NMT משופרת על ידי מסמכים, מודל שפות מאומן מראש XLM משופרת על NMT, תורגם דו-כיוון בתור אימון מראש, שפת התייחסות מבוססת UNMT, אובייקטיב גאסי קודם תלוי בנתונים, וסנן משותף BT-BLEU שימו השתמשנו גם באלגוריתם TF-IDF כדי לסנן את קבוצת האימונים כדי להשיג שטח דומה יותר עם קבוצת הבדיקות לפינוי. בשימושינו, המערכות העיקריות זכו במקום הראשון באנגלית לסינית, פולנית לאנגלית, וגרמנית לכיוון התרגום הסורבית העליונה.', 'ha': "Ga wannan takardan, mun ƙara wa jama'arin SJTU-NICT'a cikin shirin tarjima na WMT 2020 mai fassarwa da aka raba aikin. @ info: whatsthis Bason hãli da aka ƙayyade nau'i biyu na harshen, mun jarraba game da translation masu yawa na neural mashine (NMT) tactiques: document-enhanced NMT, XLM pre-Training misalin harshen ya enhanced NMT, bitirectional translation as a pre-Training, Reference language based on UNMT, data-dependant gaussian pre-objective, and BT-BLEU co-filtering Self-Training. Mun yi amfani da algoritm na TF-IDF don mu filter a wa tsarin da za'a sami wata Domen da ke daidaita kwamfyuta don a yi amfani da jarraba wa finyutan. Daga da hannuwanmu, na'ura masu ƙaranci sun rinjãya ta farkon kwanza a kan Ingiriya zuwa China, Polish zuwa Ingiriya, kuma Jarman zuwa shiryoyin fassarar Sorbiya ta Sare.", 'jv': 'Nang pegatining iki, kita nyengkuyung nggawe perintah sing sabanjur ning sampeyan WjT-NIC` nang sampeyan karo perangkat urip bantuan pilihan WjT 2020 Nang task iki, kita sampeyan pating kanggo telu oleh operasi bangkat: Inggal-Cino, Inggal-Poleh kanggo tarjamahan karo ingkang telu, akeh-Yukaro ingkang dipulungan tarjamahan, Jeman-Yukaro Ngawe ngesabe kang karbot sing itlanjut karo pakem bangsa parat, kéné sampeyan karo pakem nglanggar tarjamahan karo pakem NeMT (NMT). We awso used the T F-ID Algorithm to film the Learning set to win a domain additional like set with the test set for Finetuning. Awak dhéwé sing nggawe, sistem tualke sampek dhéwé kuwi padha Inggris kanggo Itilis, Tulisan kanggo Inggris, lan Gambaran kanggo Itilis kanggo Itilis.', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་རྩོམ་པ་འདིའི་ནང་དུ་རྩོམ་པ་ཁང་གི་SJTU-NICT `s མཉམ་གྱི་སྤྱི་ཚོགས་ཀྱི་ལས་འགུལ་སྤྱོད་ཆ In this shared task, we participated in four translation directions of three language pairs: English-Chinese, English-Polish on supervised machine translation track, German-Upper Sorbian on low-resource and unsupervised machine translation tracks. Based on different conditions of language pairs, we have experimented with various neural machine translation (NMT) techniques: document-enhanced NMT, XLM pre-trained language model enhanced NMT, bidirectional translation as a pre-training, reference language based UNMT, data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training. We also used the TF-IDF algorithm to filter the training set to obtain a domain more similar set with the test set for finetuning. ང་ཚོའི་བསམ'}
{'en': 'CUNI English-Czech and English-Polish Systems in WMT20 : Robust Document-Level Training', 'fr': 'Systèmes CUNI anglais-tchèque et anglais-polonais dans le WMT20\xa0: formation robuste au niveau des documents', 'es': 'Sistemas CUNI inglés-checo e inglés-polaco en WMT20: capacitación sólida a nivel de documento', 'pt': 'Sistemas CUNI inglês-tcheco e inglês-polonês no WMT20: treinamento robusto em nível de documento', 'ar': 'أنظمة CUNI الإنجليزية-التشيكية والإنجليزية-البولندية في WMT20: تدريب قوي على مستوى المستندات', 'ja': 'WMT 20におけるCuNi英語-チェコ語および英語-ポーランド語システム：堅牢な文書レベルのトレーニング', 'zh': 'WMT20 中 CUNI 英语-捷克语与英语-波兰语系统:强文档级培训', 'hi': 'WMT20 में CUNI अंग्रेजी-चेक और अंग्रेजी-पोलिश सिस्टम: मजबूत दस्तावेज़-स्तर प्रशिक्षण', 'ru': 'АНГЛО-ЧЕШСКИЕ и англо-польские системы CUNI в WMT20: надежное обучение на уровне документов', 'ga': 'Córais Béarla-Seice agus Béarla-Polainnis CUNI i WMT20: Oiliúint Láidir ar Leibhéal Doiciméid', 'el': 'Αγγλικά-τσεχικά και αγγλικά-πολωνικά συστήματα σε εύρωστη εκπαίδευση σε επίπεδο εγγράφων', 'hu': 'CUNI angol-cseh és angol-lengyel rendszerek WMT20-ban: robusztus dokumentumszintű képzés', 'ka': 'Comment', 'kk': 'Comment', 'it': 'CUNI Sistemi inglese-cechi e inglese-polacchi in WMT20: una solida formazione a livello documentale', 'lt': 'CUNI anglų-čekų ir anglų-lenkų sistemos WMT20: tvirtas mokymas dokumentų lygiu', 'ms': 'CUNI English-Czech and English-Polish Systems in WMT20: Robust Document-Level Training', 'mk': 'КУНИ англиско-чешки и англиско-полски системи во ВМТ20: robust обука на ниво на документи', 'mn': 'CUNI Англи-Чех, Англи-Польшийн систем WMT20: Робст Документын түвшинд суралцах', 'mt': 'CUNI English-Czech and English-Polish Systems in WMT20: Robust Document-Level Training', 'ml': 'WMT20-ല്\u200d സിയുണി- ഇംഗ്ലീഷ്- ചെക്കും ഇംഗ്ലീഷ്- പോളിഷ് സിസ്റ്റമുകള്\u200d: റോബസ്റ്റ് രേഖ- നില പരിശീലനം', 'no': 'CUNI English- Czech and English- Polish Systems in WMT20: Robust Document- Level Training', 'sr': 'CUNI engleski češki i engleski poljski sustavi u WMT20: jačan trening na nivou dokumenta', 'pl': 'CUNI Angielsko-czeskie i angielsko-polskie systemy w WMT20: solidne szkolenie na poziomie dokumentów', 'ro': 'CUNI Sisteme engleză-cehă și engleză-poloneză în WMT20: Instruire robustă la nivel de document', 'so': 'CUNI Ingiriis-Czech and Ingiriis-Polish Systems in WMT20: Robust Document-Level Training', 'sv': 'CUNI engelsk-tjeckiska och engelsk-polska system i WMT20: Robust dokumentnivå utbildning', 'si': 'Comment', 'ta': 'CUNI ஆங்கிலம்- செக்ச் மற்றும் ஆங்கிலம்- போலிஷ் அமைப்புகள் WMT20: சுழற்சி ஆவணம்- மட்டம் பயிற்சி', 'ur': 'Name', 'uz': 'Name', 'vi': 'Tập đoàn hoạt động quốc tế Anh-Séc-Ba Lan ở WM20:', 'bg': 'Английско-чешки и английско-полски системи в системата за обучение на ниво документи', 'da': 'CUNI engelsk-tjekkiske og engelsk-polske systemer i WMT20: Robust dokumentuddannelse', 'nl': 'CUNI Engels-Tsjechisch en Engels-Pools systemen in WMT20: robuuste training op documentniveau', 'hr': 'CUNI engleski češki i engleski poljski sustavi u WMT20: Jako učenje na nivou dokumenta', 'de': 'CUNI Englisch-Tschechisch und Englisch-Polnisch Systeme in WMT20: Robustes Training auf Dokumentenebene', 'id': 'CUNI English-Czech and English-Polish Systems in WMT20: Robust Document-Level Training', 'ko': 'WMT20의 CUNI 영어 체코어 및 영어 폴란드어 시스템: 강력한 문서급 교육', 'sw': 'CUNI Kiingereza-Czech na Mfumo wa Kiingereza-Polish mjini WMT20: Ufundisho wa Sheria-Level', 'fa': 'Name', 'tr': "CUNI WMT20'de Iňlisçe-Çehiň we Iňlisçe-Polonça sistemalar: ýigrenç Sened derejesi Ewezam", 'af': 'Name', 'sq': 'CUNI English-Czech and English-Polish Systems in WMT20: Robust Document-Level Training', 'am': 'CUNI እንግሊዝኛ-ቻክክ እና እንግሊዝኛ-ፖሊስ ስምተቶች በWMT20: Robust Document-Level Training', 'hy': 'Քունի Անգլերեն-Չեխի և Անգլերեն-Փոլանդական համակարգերը Համաշխարհային Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միաց', 'az': 'WMT20 içində CUNI İngilizce-Çehir və İngilizce-Poloş Sistemləri: Qüvvətli Document-Level Training', 'bn': 'WMT20-এ সিইউনি- ইংরেজী চেক এবং ইংরেজী পোলিশ সিস্টেম: রোবাস্ট ডকুমেন্ট- স্তর প্রশিক্ষণ', 'ca': 'CUNI English-Czech and English-Polish Systems a WMT20: Robust Document-Level Training', 'cs': 'CUNI anglicko-české a anglicko-polské systémy ve WMT20: robustní školení na úrovni dokumentů', 'et': 'CUNI inglise-tšehhi ja inglise-poola süsteemid WMT20: tugev dokumenditasemel koolitus', 'fi': 'CUNI Englanti-tšekki ja englanti-puola järjestelmät WMT20: vankka dokumenttitason koulutus', 'bs': 'CUNI engleski češki i engleski poljski sustavi u WMT20: robotna obuka na nivou dokumenta', 'sk': 'CUNI angleško-češki in angleško-poljski sistemi v WMT20: Robustno usposabljanje na ravni dokumentov', 'ha': 'KCharselect unicode block name', 'he': "CUNI מערכות אנגלית-צ'צ'ית ואנגלית-פולנית ב-WMT20: אימונים חזקים ברמה מסמכים", 'jv': 'CUNI Ngucap Inggris-Cek lan Sistem Inggris-Pulan lan lan Wêm2n: Rebot Dokumen-Layer Opol-Ketokan', 'bo': 'CUNI English-Czech and English-Polish Systems in WMT20: Robust Document-Level Training'}
{'en': 'We describe our two NMT systems submitted to the WMT 2020 shared task in English-Czech and English-Polish news translation. One system is sentence level, translating each sentence independently. The second system is document level, translating multiple sentences, trained on multi-sentence sequences up to 3000 characters long.', 'ar': 'نحن نصف نظامي NMT المقدمين إلى مهمة WMT 2020 المشتركة بترجمة الأخبار الإنجليزية-التشيكية والإنجليزية-البولندية. نظام واحد هو مستوى الجملة ، ترجمة كل جملة بشكل مستقل. النظام الثاني هو مستوى المستند ، وهو يترجم جمل متعددة ، ويتم تدريبه على تسلسل متعدد الجمل يصل طوله إلى 3000 حرف.', 'es': 'Describimos nuestros dos sistemas de NMT presentados a la tarea compartida del WMT 2020 en traducción de noticias inglés-checo e inglés-polaco. Un sistema es el nivel de oración, traduciendo cada oración de forma independiente. El segundo sistema es a nivel de documento, traduciendo múltiples oraciones, entrenado en secuencias de varias oraciones de hasta 3000 caracteres.', 'fr': "Nous décrivons nos deux systèmes NMT soumis à la tâche partagée WMT 2020 en traduction d'actualités anglais-tchèque et anglais-polonais. Un système est le niveau de la phrase, traduisant chaque phrase indépendamment. Le deuxième système est au niveau du document, traduisant plusieurs phrases, entraîné sur des séquences de plusieurs phrases jusqu'à 3000 caractères.", 'pt': 'Descrevemos nossos dois sistemas NMT submetidos à tarefa compartilhada do WMT 2020 em tradução de notícias inglês-tcheco e inglês-polonês. Um sistema é o nível de sentença, traduzindo cada sentença independentemente. O segundo sistema é o nível de documento, traduzindo várias frases, treinado em sequências de várias frases de até 3.000 caracteres.', 'ja': 'WMT 2020共有タスクに提出された2つのNMTシステムについて、英語-チェコ語および英語-ポーランド語のニュース翻訳で説明します。1つのシステムは文章レベルで、各文章を個別に翻訳します。2番目のシステムは文書レベルで、複数の文章を翻訳し、最大3000文字のマルチ文章シーケンスでトレーニングします。', 'zh': '述交WMT 2020二NMT,英文 - 捷克语英语 - 波兰语新闻译。 一统为句,独译为句。 第二统为文档级,译数句,于长达3000个字符多句序训练。', 'hi': 'हम अंग्रेजी-चेक और अंग्रेजी-पोलिश समाचार अनुवाद में डब्ल्यूएमटी 2020 साझा कार्य के लिए प्रस्तुत किए गए हमारे दो एनएमटी सिस्टम का वर्णन करते हैं। एक प्रणाली वाक्य स्तर है, जो प्रत्येक वाक्य को स्वतंत्र रूप से अनुवाद करती है। दूसरी प्रणाली दस्तावेज़ स्तर है, जो कई वाक्यों का अनुवाद करती है, जो 3000 वर्णों तक के बहु-वाक्य अनुक्रमों पर प्रशिक्षित होती है।', 'ru': 'Мы описываем две наши системы NMT, представленные на совместную задачу WMT 2020, на английском и чешском языках и в переводе новостей на английский и польский языки. Одна система - это уровень предложения, который переводит каждое предложение независимо друг от друга. Вторая система - это уровень документа, перевод нескольких предложений, обучение по последовательностям из нескольких предложений длиной до 3000 символов.', 'ga': 'Déanaimid cur síos ar an dá chóras NMT a cuireadh isteach chuig tasc comhroinnte WMT 2020 in aistriúchán nuachta Béarla-Seice agus Béarla-Polainnis. Is é leibhéal na habairte córas amháin, a aistríonn gach abairt go neamhspleách. Tá an dara córas ag leibhéal doiciméad, a aistríonn abairtí iolracha, oilte ar sheichimh il-abairtí suas le 3000 carachtar ar fad.', 'ka': 'ჩვენ განახსენებთ ჩვენი ორი NMT სისტემი, რომელიც WMT 2020-ს გაყოფილი საერთო დავალება ინგლისურ-ფექურ და ინგლისურ-პოლიქური ნუზის გაგრძელებით. ერთი სისტემა არის სიტყვების დონე, რომელიც ყოველ სიტყვების განმავლობაში შეცვლა. მეორე სისტემა არის დოკუმენტის დონე, რამდენიმე სიტყვების გადატანაცია, რამდენიმე სიტყვების განსწავლებული მრავალ სიტყვების განსწავლებაში სამი 3000', 'el': 'Περιγράφουμε τα δύο συστήματα που υποβλήθηκαν στο κοινό έργο σε Αγγλικά-Τσεχικά και Αγγλικά-Πολωνικά νέα μετάφραση. Ένα σύστημα είναι το επίπεδο των προτάσεων, μεταφράζοντας κάθε πρόταση ανεξάρτητα. Το δεύτερο σύστημα είναι το επίπεδο εγγράφων, μεταφράζοντας πολλαπλές προτάσεις, εκπαιδευμένες σε ακολουθίες πολλών προτάσεων μέχρι 3000 χαρακτήρων.', 'hu': 'A WMT 2020 megosztott feladatra benyújtott két NMT rendszerünket angol-cseh és angol-lengyel híradításban ismertetjük. Az egyik rendszer a mondatszint, amely minden mondatot önállóan fordít le. A második rendszer dokumentum szintű, több mondat fordítása, több mondat szekvenciájára képzett, legfeljebb 3000 karakter hosszú.', 'kk': 'Екі NMT жүйесімізді WMT 2020 жылы ағылшын-чех және ағылшын-польша жаңалық аудармасында ортақ тапсырмаға жіберілді. Бір жүйе сөйлеменің деңгейі, әрбір сөйлемені тәуелсіз аудару. Екінші жүйе - құжаттың деңгейі, бірнеше сөздерді аударып, көп сөздер ретінде 3000 таңбаларға ұзынды.', 'it': 'Descriviamo i nostri due sistemi NMT sottoposti al compito condiviso WMT 2020 in traduzione di notizie inglese-ceca e inglese-polacca. Un sistema è il livello di frase, traducendo ogni frase in modo indipendente. Il secondo sistema è a livello di documento, traducendo più frasi, addestrato su sequenze multi-frase fino a 3000 caratteri di lunghezza.', 'ml': 'ഞങ്ങള്\u200d നമ്മുടെ രണ്ടു NMT സിസ്റ്റം വിവരിക്കുന്നു. WMT 2020-ലേക്ക് പങ്കെടുത്ത ജോലിയിലേക്ക് നല്\u200dകിയിരിക്കുന്നു. ഇ ഒരു സിസ്റ്റത്തിന്റെ വാക്ക് നില, ഓരോ വാക്കിനെയും സ്വാതന്ത്ര്യമായി അനുവാദിക്കുന്നു. രണ്ടാമത്തെ സിസ്റ്റമാണ് രേഖയുടെ നില, പല വാക്കുകളെ പരിശീലനം ചെയ്യുന്നത്, പല വാക്കുകളില്\u200d നീണ്ട 3000 അക്ഷരസഞ്ചരി', 'mk': 'We describe our two NMT systems submitted to the WMT 2020 shared task in English-Czech and English-Polish news translation.  Еден систем е нивото на реченици, преведувајќи ја секоја реченица независно. Вториот систем е нивото на документите, преведувајќи повеќе реченици, обучени за повеќето реченици долги до 3000 знаци.', 'lt': 'Aprašome savo dvi NMT sistemas, pateiktas WMT 2020 bendrai užduotims anglų-čekų ir anglų-lenkų žinių vertimu. Viena sistema yra sakinių lygis, kiekvieną sakinį verta nepriklausomai. Antroji sistema yra dokumentų lygis, vertimas keliais sakiniais, mokomas daugiakalbėse sekose iki 3000 ženklų ilgio.', 'mt': 'Aħna niddeskrivu ż-żewġ sistemi NMT tagħna ppreżentati għad-WMT 2020 kompitu komuni fit-traduzzjoni tal-aħbarijiet Ingliż-Ċek u Ingliż-Pollakk. Sistema waħda hija l-livell tas-sentenza, li tittraduċi kull sentenza b’mod indipendenti. It-tieni sistema hija l-livell ta’ dokumenti, li jittraduċu sentenzi multipli, imħarrġa fuq sekwenzi ta’ sentenzi multipli sa 3000 karattru twil.', 'no': 'Vi beskriver våre to NMT-systemet som er sendt til delt oppgåve WMT 2020 i engelsk-tsjekkisk og engelsk-polsk nyhetssomsetjing. Ein system er setningsnivå, som omsetjer kvar setning uavhengig. Den andre systemet er dokumentnivå, som omsetjer fleire setningar, treng på fleire setningsekvens opp til 3000 teikn lang.', 'ms': 'Kami menggambarkan dua sistem NMT kami dihantar ke tugas kongsi WMT 2020 dalam terjemahan berita bahasa Inggeris-Czech dan bahasa Inggeris-Polis. Satu sistem adalah aras kalimat, menerjemahkan setiap kalimat secara bebas. The second system is document level, translating multiple sentences, trained on multi-sentence sequences up to 3000 characters long.', 'ro': 'Descriem cele două sisteme NMT supuse sarcinii comune WMT 2020 în traducerea de știri engleză-cehă și engleză-poloneză. Un sistem este nivelul propoziției, traducând fiecare propoziție independent. Al doilea sistem este la nivel de document, traducând mai multe propoziții, instruite pe secvențe de mai multe propoziții de până la 3000 de caractere lungi.', 'mn': 'Бид WMT 2020-д Англи-Чех, Англи-Польшийн мэдээллийн орчуулалт дээр хуваалцагдсан хоёр NMT системийг тайлбарлаж байна. Нэг систем бол өгүүлбэрийн түвшин, өгүүлбэрийг өөрсдийгөө орчуулдаг. Хоёр дахь систем бол баримт түвшин, олон өгүүлбэрийг орлуулж, олон өгүүлбэрийн дарааллаас 3000 хүн урт суралцагдсан.', 'pl': 'Nasze dwa systemy NMT zgłoszone do wspólnego zadania WMT 2020 opisujemy w angielsko-czeskim i angielsko-polskim tłumaczeniu wiadomości. Jednym z systemów jest poziom zdania, tłumaczący każde zdanie niezależnie. Drugim systemem jest poziom dokumentu, tłumaczenie wielu zdań, trenowane na sekwencjach wielu zdań do 3000-znaków.', 'si': 'අපි අපේ NMT පද්ධතිය දෙකක් විස්තර කරනවා WMT 2020යි ඉංග්\u200dරිස්-චෙක් සහ ඉංග්\u200dරිස්-පෝලිෂ් ආරංචිකාවේ ස එක පද්ධතිය තමයි වාක්ය ස්ථානය, හැම වාක්ය ස්වයංක්\u200dරමයෙන් වාක්ය කරන්න. දෙවෙනි පද්ධතිය තමයි වාක්ෂාව ස්ථානය, වඩා වාක්ෂාවක් පද්ධතිය, වඩා වාක්ෂාවක් පද්ධතිය තියෙන්නේ අ', 'so': 'Waxaynu qoraynaa labadayada NMT ee loo soo dhiibay WMT 2020 oo lagu qaybiyey shaqada ku qoran Ingiriis-Czech iyo Ingiriis-Polish news translation. Isticmaal kaliya waa heer maxkamad, si xor ah u turjuma hal eray. Tirada labaad waa heer dokumenta, turjumidda hadal badan, lagu tababaray isku xir badan ilaa 3000 oo qoraal ah.', 'sr': 'Opišemo naše dve NMT sisteme koje su predate podijeljenom zadatku WMT 2020-a na prevodu vesti engleskog češkog i engleskog poljskog. Jedan sistem je nivo rečenice, prevodeći svaku rečenicu nezavisno. Drugi sistem je nivo dokumenta, prevodeći višestruke rečenice, obučen na višerečenim rečenicama do 3000 znakova dugih.', 'ta': 'WMT 2020 க்கு கொடுக்கப்பட்ட இரண்டு NMT அமைப்புகளை நாம் விவரிக்கிறோம் ஆங்கிலம்- செக்- போலிஷ் செய்தி மொழிபெயர்ப்பி ஒரு அமைப்பு வாக்கு நிலை, ஒவ்வொரு வாக்கியத்தை தனியாக மொழிபெயர்ப்புகிறது. இரண்டாவது கணினி', 'sv': 'Vi beskriver våra två NMT-system som skickats in till WMT 2020:s gemensamma uppgift i engelsk-tjeckiska och engelsk-polska nyhetsöversättning. Ett system är meningsnivå, som översätter varje mening självständigt. Det andra systemet är dokumentnivå, översätta flera meningar, tränade på flermeningssekvenser upp till 3000 tecken långa.', 'ur': 'ہم نے اپنے دو NMT سیستموں کو توصیح دیتے ہیں جو WMT 2020 میں انگلیسی-چیک اور انگلیسی-پولیش خبروں کی ترجمہ میں شریک کیے گئے ہیں۔ ایک سیسٹم یہ ہے کہ کلام سطح ہے، ہر کلام کو آزاد طور پر ترجمہ کرتا ہے۔ دوسری سیسٹم دکھونٹ سطح ہے، بہت سی جماعتوں کو ترجمہ کرتا ہے، بہت سی جماعتوں کے سطح پر تین کی جاتی ہے، ۳۰۰۰ سی جماعتوں تک۔', 'uz': "Biz bizning ikki NMT tizimimizni WMT 2020 dasturiga qayta ishga tayyorlangan ingliz- checha va Inglizcha- Polish news tarjima qilish tilida aytganmiz. Bir tizim bir so'zni boshqa tarjima qiladi. Ikkinchi tizim hujjat darajasi, bir nechta so'zlarni tarjima qilish, bir nechta so'zlar soni 3,000 harfga bir nechta tarjima qilinadi.", 'vi': 'Chúng tôi mô tả hai hệ thống NMT được giao dịch cho WRT 2020 bằng tiếng Anh-Séc-Ba Lan. Một hệ thống là cấp bản án, dịch mỗi bản một cách độc lập. Hệ thống thứ hai là cấp tài liệu, dịch ra nhiều câu, được đào tạo về dãy đa câu lên tới mức 30p các ký tự dài.', 'bg': 'Описваме двете ни системи на НМТ, подадени на съвместната задача на БМТ 2020, в превод на английски-чешки и английски-полски новини. Една система е ниво на изречение, превеждайки всяко изречение независимо. Втората система е документно ниво, превеждаща множество изречения, обучени върху многократни последователности с дължина до 3000 знака.', 'da': 'Vi beskriver vores to NMT-systemer indsendt til WMT 2020 delte opgave i engelsk-tjekkisk og engelsk-polsk nyhedsoversættelse. Et system er sætningsniveau, der oversætter hver sætning uafhængigt. Det andet system er dokumentniveau, der oversætter flere sætninger, trænet i flere sætninger sekvenser på op til 3000 tegn lange.', 'nl': 'We beschrijven onze twee NMT-systemen die zijn ingediend voor de gedeelde taak WMT 2020 in Engels-Tsjechisch en Engels-Pools nieuws vertaling. Eén systeem is zinnenniveau, waarbij elke zin onafhankelijk wordt vertaald. Het tweede systeem is documentniveau, het vertalen van meerdere zinnen, getraind op meerdere zinnen sequenties tot 3000 karakters lang.', 'hr': 'Opišemo naše dvije NMT sustave koje su podignute zajedničkom zadatku WMT 2020-a na prevodu vesti engleskog češkog i engleskog-poljskog. Jedan sustav je nivo rečenice, prevodeći svaku rečenicu nezavisno. Drugi sustav je razina dokumenta, prevodeći višestruke rečenice, obučena na višerečenim rečenicama do 3000 znakova dugih.', 'de': 'Wir beschreiben unsere beiden NMT-Systeme, die für die gemeinsame Aufgabe WMT 2020 eingereicht wurden, in Englisch-Tschechisch und Englisch-Polnisch Nachrichtenübersetzung. Ein System ist die Satzebene, die jeden Satz unabhängig übersetzt. Das zweite System ist Dokumentenebene, das mehrere Sätze übersetzt, trainiert auf mehrsätzlichen Sequenzen bis zu 3000-Zeichen lang.', 'id': 'Kami menggambarkan dua sistem NMT kami yang dihantar ke WMT 2020 tugas berbagi dalam terjemahan berita bahasa Inggris-Cek dan bahasa Inggris-Polandia. Satu sistem adalah tingkat kalimat, menerjemahkan setiap kalimat secara independen. Sistem kedua adalah tingkat dokumen, menerjemahkan beberapa kalimat, dilatih dalam urutan multi-kalimat hingga 3000 karakter panjang.', 'ko': '우리는 영어-체코어와 영어-폴란드어 뉴스 번역으로 WMT 2020 공유 임무에 제출된 두 개의 NMT 시스템을 묘사했다.하나의 시스템은 문장급으로 각 문장을 독립적으로 번역한다.두 번째 시스템은 문서급으로 여러 문장을 번역하고 3000글자에 달하는 다문장 서열에 따라 훈련한다.', 'sw': 'Tunaelezea mifumo yetu miwili ya NMT iliyotolewa kwenye kazi ya WMT 2020 iliyosambazwa kwa lugha ya Kiingereza-Kizech na Kiingereza-Polish. Mfumo mmoja ni kiwango cha hukumu, kutafsiri kila hukumu huru. Mfumo wa pili ni kiwango cha dokumentari, kutafsiri hukumu mbalimbali, imefundishwa kwa mfululizo wa sentence mbalimbali mpaka wahusika 3000.', 'tr': 'Biz öz iki NMT sistemamyzy WMT 2020-nji ýyllarda Iňlisçe we iňlisçe-polşa täzeliklerde bölýän zadymyzy tassykladyk. Bir sistem sözlem derejesi, her sözlemi özbaşdaky terjime edip otyr. Ikinji sistem sened derejesi, birnäçe sözleri terjime edip, birnäçe sözler terjime edilen üçin 3000 karakterlere uzan.', 'af': 'Ons beskrywe ons twee NMT-stelsels wat aan die WMT 2020 gedeelde taak in Engels-Tschekis en Engels-Poolse nuusvertaling ingestuur is. Een stelsel is setvlak, terwyl elke seting onveilig. Die tweede stelsel is dokumentvlak, vertaling veelvuldige teikens, onderwerp op veelvuldige teikens volgorde tot 3000 karakters lank.', 'sq': 'Ne përshkruajmë dy sistemet tona NMT të paraqitura në detyrën e përbashkët të WMT 2020 në përkthimin e lajmeve anglisht-çek dhe anglisht-polak. Një sistem është niveli i fjalëve, duke përkthyer çdo fjalë në mënyrë të pavarur. Sistemi i dytë është niveli i dokumentit, duke përkthyer fjalë të shumta, i trajnuar në sekuenca me shumë fjalë deri në 3000 karakterë të gjata.', 'am': 'በንግግሊዝኛ-ቻክና እንግሊዝኛ-ፖሊስ ዜና ትርጓሜ ውስጥ ለWMT 2020 የተሰራውን የሁለት የNMT ስርዓቶች እናሳውቃለን፡፡ አንድ ሲስተም የፍርድ ደረጃ ነው፣ ሁሉንም ንግግር በተለየ ትርጉም፡፡ ሁለተኛው ሲስተም የሰነድ ደረጃ ነው፣ በርካታ ቁጥሮች ትርጉም፣ በብዙ-sentence በቁጥጥር ላይ እስከ 3000 ፊደል ድረስ የተማረ ነው፡፡', 'hy': 'Մենք նկարագրում ենք մեր երկու NMT համակարգերը, որոնք ներկայացվել են ԱՄԹ 2020-ի ընդհանուր խնդիրը անգլերեն-ցեխ և անգլերեն-պոլերեն նորությունների թարգմանման մեջ: Մեկ համակարգը նախադասությունների մակարդակը է, յուրաքանչյուր նախադասություն անկախ թարգմանում: Երկրորդ համակարգը փաստաթղթի մակարդակն է, որը թարգմանում է բազմաթիվ նախադասություններ, որոնք պատրաստվում են բազմադասությունների հաջորդականությունների վրա մինչև 3000 սիրտ երկարությամբ:', 'az': 'İki NMT sistemimizi WMT 2020 ilə İngilizce-Çək və İngilizce-Polonya haqq çevirində paylaşılan işimizə təsdiq edirik. Bir sistem cümlənin səviyyəsidir, hər cümləni təkrar çevirir. İkinci sistem döküm seviyesidir, çoxlu cümlələri tercümə edir, çoxlu cümlələr seçməsində 3000 cümlələr uzunluğuna qədər təhsil edilir.', 'bn': 'আমরা আমাদের দুই এনএমটি সিস্টেম ব্যাখ্যা করেছি যা উইএমটি ২০২০ সালে প্রদান করা হয়েছে ইংরেজি-চেক এবং ইংরেজী পোলিশ সংবা একটি সিস্টেম হচ্ছে শাস্তি স্তর, প্রত্যেক বাক্য স্বাধীন অনুবাদ করা। দ্বিতীয় সিস্টেম হচ্ছে ডকুমেন্টের স্তর, বেশ কিছু বাক্য অনুবাদ করা হচ্ছে, অনুবাদ করা হচ্ছে বহুবাদী শাস্তি সংক্রান', 'bs': 'Opišemo naše dvije NMT sisteme koje su predate zajedničkom zadatku WMT 2020-a na prevodu vesti engleskog češkog i engleskog-poljskog. Jedan sistem je nivo rečenice, prevodeći svaku rečenicu nezavisno. Drugi sistem je nivo dokumenta, prevodeći višestruke rečenice, obučen na višerečenim rečenicama do 3000 znakova dugih.', 'ca': 'Descrivem els nostres dos sistemes NMT submetits a la tasca compartida WMT 2020 en traducció de notícies anglès-cec i anglès-polac. Un sistema és el nivell de frases, traduint cada frase de manera independent. The second system is document level, translating multiple sentences, trained on multi-sentence sequences up to 3000 characters long.', 'et': 'Kirjeldame WMT 2020 ühisele ülesandele esitatud kahte NMT-süsteemi inglise-tšehhi ja inglise-poola uudistetõlkes. Üks süsteem on lausetase, tõlkides iga lause iseseisvalt. Teine süsteem on dokumenditasandil, tõlkides mitut lauset, õpetades mitme lause järjestusi kuni 3000 tähemärki.', 'fi': 'Kuvaamme WMT 2020:n yhteiseen tehtävään lähetettyjä NMT-järjestelmiä englannin-tšekin ja englannin-puolan uutiskäännöksinä. Yksi järjestelmä on lausetaso, joka kääntää jokaisen lauseen itsenäisesti. Toinen järjestelmä on dokumenttitaso, joka kääntää useita lauseita, koulutettu usean lauseen sekvensseihin, jotka ovat jopa 3000 merkkiä pitkiä.', 'fa': 'ما دو سیستم NMT ما را توصیف می\u200cکنیم که به عملی WMT 2020 در ترجمه خبرهای انگلیسی چک و انگلیسی-لهستان ارائه داده شده است. یک سیستم سطح جمله است که هر جمله را به خصوصی ترجمه می کند. سیستم دوم سطح سند است که تعلیم جمله\u200cهای زیادی است، که در تعلیم جمله\u200cهای زیادی تا ۳۰۰۰ شخصیت طول آموزش داده شده است.', 'cs': 'Naše dva NMT systémy předložené do sdíleného úkolu WMT 2020 popisujeme v anglicko-českém a anglicko-polském překladu zpráv. Jeden systém je úroveň věty, která každou větu překládá nezávisle. Druhým systémem je úroveň dokumentů, překládající více vět, trénovaný na vícevětových sekvencích až 3000 znaků.', 'he': "אנחנו מתארים את שתי מערכות NMT שלנו שנשלחו למשימה משותפת WMT 2020 בתרגום חדשות אנגלי-צ'ק ואנגלית-פולנית. מערכת אחת היא רמת המשפטים, תורגם כל משפט באופן עצמאי. המערכת השנייה היא רמת המסמכים, תורגם משפטים רבים, מאומנים על רצפי משפטים רבים עד 3000 דמויות ארוכות.", 'sk': 'Naša dva NMT sistema, predložena skupni nalogi WMT 2020, opisujemo v angleško-češkem in angleško-poljskem prevodu novic. En sistem je nivo stavka, ki vsak stavek prevaja neodvisno. Drugi sistem je na ravni dokumenta, ki prevaja več stavkov, usposobljen za več stavkov, dolgih do 3000 znakov.', 'ha': '@ info: status @ action: button @ action: button', 'bo': 'We describe our NMT systems two submitted to the WMT 2020 shared task in English-Czech and English-Polish news translation. མ་ལག་གཅིག་ནི་ཚིག་ཡིག་གི་སྐྱེས་ཡིག་གཟུགས་རེ་རེར་སོ་སོའི་དབྱིབས་ཡོད་པ མ་ལག་གཉིས་པ་དེ་ཡིག་གི་སྒྲིག་འགོད་ཚད་ལྟར་ཡིག་གཟུགས་རིས་འདུག', 'jv': 'Awak dhéwé ngerasakno sistem NMT durung sampeyan nyebutaké nggawe WT 2020 nganggo cara sing nyebutaké barang Inggris-Cek karo Balikes-Paoles Laptop" and "Desktop Sistem wis nambah ing dokumen, ditambah banter'}
{'en': 'OPPO’s Machine Translation Systems for WMT20', 'ar': 'أنظمة الترجمة الآلية من OPPO لـ WMT20', 'es': 'Sistemas de traducción automática de OPPO para WMT20', 'fr': 'Systèmes de traduction automatique OPPO pour WMT20', 'pt': 'Sistemas de tradução automática da OPPO para WMT20', 'ja': 'WMT 20用OPPOの機械翻訳システム', 'zh': 'OPPO 之 WMT20 机器翻译统也', 'ru': 'Системы машинного перевода OPPO для WMT20', 'hi': 'WMT20 के लिए ओप्पो की मशीन अनुवाद प्रणाली', 'ga': 'Córais Aistriúcháin Meaisín OPPO do WMT20', 'hu': 'Az OPPO gépi fordító rendszerei WMT20 számára', 'el': 'Συστήματα μηχανικής μετάφρασης του ΟΠPO για το WMT20', 'ka': 'WMT20Comment', 'lt': 'OPPO WMT20 mašinų vertimo sistemos', 'it': 'Sistemi di traduzione automatica OPPO per WMT20', 'kk': 'Comment', 'mk': "OPPO's Machine Translation Systems for WMT20", 'ml': 'WMT20- നുള്ള ഓപ്പോപിയുടെ മെഷീന്\u200d പരിഭാഷ സിസ്റ്റമുകള്\u200d', 'ms': 'Sistem Terjemahan Mesin OPPO untuk WMT20', 'mn': 'OPPO-ын машин орчуулах систем WMT20', 'pl': 'Systemy tłumaczenia maszynowego OPPO dla WMT20', 'sr': 'OPPO-ov sistem za prevod mašine za WMT20', 'mt': 'Sistemi ta’ Traduzzjoni tal-Magni tal-OPPO għad-WMT20', 'so': "OPPO's Machine Translation Systems for WMT20", 'no': 'OPPO sin maskinsk omsetjingssystem for WMT20', 'sv': 'OPPO:s maskinĂ¶versĂ¤ttningssystem fĂ¶r WMT20', 'ta': 'WMT20 க்கான OPPO இயந்திரம் மொழிபெயர்ப்பு அமைப்புகள்', 'ro': 'Sistemele de traducere automată OPPO pentru WMT20', 'si': 'WMT20Comment', 'ur': "WMT20 کے لئے OPPO's Machine Translation Systems", 'uz': "OPPO's Machine Translation Systems for WMT20", 'vi': 'Hệ thống dịch cỗ máy OPPO cho WM210', 'bg': 'Системи за машинен превод на OPPO за WMT20', 'da': "OPPO's maskinoversættelsessystemer til WMT20", 'hr': 'OPPO-ovi sustavi za prevod stroja za WMT20', 'id': 'Sistem Translation Mesin OPPO untuk WMT20', 'ko': 'OPPO의 WMT20 번역 시스템', 'fa': 'سیستم ترجمه ماشین OPPO برای WMT20', 'nl': "OPPO's Machine Translation Systems voor WMT20", 'sw': 'Mfumo wa Tafsiri wa Mashine ya OPPO kwa WMT20', 'de': 'Die maschinellen Übersetzungssysteme der OPPO für WMT20', 'tr': "OPPO'yň WMT20 üçin Maşynyň terjime sistemleri", 'am': 'ምርጫዎች', 'sq': 'Sistemet e përkthimit të makinave të OPPO për WMT20', 'hy': "OPPO's Machine Translation Systems for WMT20", 'az': "WMT20 üçün OPPO'nun Makine Çeviri Sistemləri", 'ca': "Sistemes de traducció de màquines de l'OPPO per a WMT20", 'bn': "WMT20 এর জন্য OPPO'র মেশিন অনুবাদ সিস্টেম", 'bs': 'OPPO-ov sistem za prevod mašine za WMT20', 'et': 'OPPO masintõlke süsteemid WMT20 jaoks', 'cs': 'Strojové překladatelské systémy OPPO pro WMT20', 'fi': 'OPPO:n konekäännösjärjestelmät WMT20:lle', 'af': 'OPPO se Masjien Vertaling stelsels vir WMT20', 'jv': "OPOP's Masine Terusan Sistem kanggo WW2AN", 'ha': 'KCharselect unicode block name', 'he': 'מערכות תרגום מכונות של OPPO עבור WMT20', 'sk': 'OPPO sistemi strojnega prevajanja za WMT20', 'bo': "OPPO's Machine Translation Systems for WMT20"}
{'en': 'In this paper we demonstrate our (OPPO’s) machine translation systems for the WMT20 Shared Task on News Translation for all the 22 language pairs. We will give an overview of the common aspects across all the systems firstly, including two parts : the data preprocessing part will show how the data are preprocessed and filtered, and the system part will show our models architecture and the techniques we followed. Detailed information, such as training hyperparameters and the results generated by each technique will be depicted in the corresponding subsections. Our final submissions ranked top in 6 directions (English   Czech, English   Russian, French   German and Tamil   English), third in 2 directions (English   German, English   Japanese), and fourth in 2 directions (English   Pashto and and English   Tamil).\\leftrightarrow Czech, English \\leftrightarrow Russian, French \\rightarrow German and Tamil \\rightarrow English), third in 2 directions (English \\rightarrow German, English \\rightarrow Japanese), and fourth in 2 directions (English \\rightarrow Pashto and and English \\rightarrow Tamil).', 'ar': "نعرض في هذا البحث أنظمة الترجمة الآلية (OPPO's) الخاصة بنا للمهمة المشتركة WMT20 حول ترجمة الأخبار لجميع أزواج اللغات البالغ عددها 22 زوجًا. سنقدم نظرة عامة على الجوانب المشتركة في جميع الأنظمة أولاً ، بما في ذلك جزأين: سيُظهر جزء المعالجة المسبقة للبيانات كيفية معالجة البيانات وتصفيتها مسبقًا ، وسيعرض جزء النظام بنية النماذج والتقنيات التي اتبعناها. سيتم عرض المعلومات التفصيلية ، مثل المتغيرات الفائقة للتدريب والنتائج المتولدة عن كل تقنية في الأقسام الفرعية المقابلة. احتلت عروضنا النهائية المرتبة الأولى في 6 اتجاهات (الإنجليزية ↔ التشيكية ، الإنجليزية ↔ الروسية ، الفرنسية → الألمانية والتاميلية → الإنجليزية) ، والثالثة في اتجاهين (الإنجليزية → الألمانية ، الإنجليزية → اليابانية) ، والرابعة في اتجاهين (الإنجليزية → الباشتو و والإنجليزية → التاميلية).", 'es': 'En este artículo, demostramos nuestros sistemas de traducción automática (de OPPO) para la tarea compartida WMT20 sobre traducción de noticias para las 22 combinaciones de idiomas. En primer lugar, daremos una visión general de los aspectos comunes en todos los sistemas, incluidas dos partes: la parte de preprocesamiento de datos mostrará cómo se preprocesan y filtran los datos, y la parte del sistema mostrará la arquitectura de nuestros modelos y las técnicas que seguimos. La información detallada, como los hiperparámetros de entrenamiento y los resultados generados por cada técnica se representarán en las subsecciones correspondientes. Nuestros envíos finales ocuparon el primer lugar en 6 direcciones (inglés ↔ checo, inglés ↔ ruso, francés → alemán y tamil → inglés), el tercero en 2 direcciones (inglés → alemán, inglés → japonés) y el cuarto en 2 direcciones (inglés → pastún e inglés → tamil).', 'fr': "Dans cet article, nous présentons nos systèmes de traduction automatique (OPPO) pour la tâche partagée WMT20 sur la traduction des actualités pour les 22 paires de langues. Nous allons d'abord donner un aperçu des aspects communs à tous les systèmes, y compris deux parties\xa0: la partie prétraitement des données montrera comment les données sont prétraitées et filtrées, et la partie système montrera l'architecture de nos modèles et les techniques que nous avons suivies. Des informations détaillées, telles que les hyperparamètres d'entraînement et les résultats générés par chaque technique seront décrites dans les sous-sections correspondantes. Nos soumissions finales se sont classées en tête dans 6 directions (anglais ↔ tchèque, anglais ↔ russe, français → allemand et tamoul → anglais), troisième dans 2 directions (anglais → allemand, anglais → japonais) et quatrième dans 2 directions (anglais → pachto et anglais → tamoul).", 'pt': 'Neste artigo, demonstramos nossos sistemas de tradução automática (OPPO) para a tarefa compartilhada do WMT20 sobre tradução de notícias para todos os 22 pares de idiomas. Daremos uma visão geral dos aspectos comuns em todos os sistemas em primeiro lugar, incluindo duas partes: a parte de pré-processamento de dados mostrará como os dados são pré-processados e filtrados, e a parte do sistema mostrará nossa arquitetura de modelos e as técnicas que seguimos. Informações detalhadas, como hiperparâmetros de treinamento e os resultados gerados por cada técnica, serão apresentadas nas subseções correspondentes. Nossos envios finais ficaram em primeiro lugar em 6 direções (inglês ↔ tcheco, inglês ↔ russo, francês → alemão e tâmil → inglês), terceiro em 2 direções (inglês → alemão, inglês → japonês) e quarto em 2 direções (inglês → pashto e e Inglês → Tâmil).', 'ja': '本稿では、22の言語ペアすべてについて、WMT 20共有ニュース翻訳タスクのための（ OPPOの）機械翻訳システムを実演します。まず、2つの部分を含む、すべてのシステムに共通する側面の概要を説明します。データの前処理部分は、データがどのように前処理およびフィルタリングされているかを示し、システム部分は、モデルのアーキテクチャと従ったテクニックを示します。トレーニングのハイパーパラメータおよび各技術によって生成された結果などの詳細情報は、対応するサブセクションに示される。最終的な応募作品は、6方向（英語、↔チェコ語、英語、↔ロシア語、フランス語、→ドイツ語、タミル語、→英語）でトップ、2方向（英語、→ドイツ語、英語、→日本語）で3位、2方向（英語、→パシュトー語、英語、→タミル語）で4位でした。', 'hi': 'इस पेपर में हम सभी 22 भाषा जोड़े के लिए समाचार अनुवाद पर WMT20 साझा कार्य के लिए हमारे (ओप्पो के) मशीन अनुवाद प्रणालियों का प्रदर्शन करते हैं। हम दो भागों सहित सभी प्रणालियों में सामान्य पहलुओं का अवलोकन देंगे: डेटा प्रीप्रोसेसिंग भाग दिखाएगा कि डेटा को कैसे पूर्वसंसाधित और फ़िल्टर किया जाता है, और सिस्टम भाग हमारे मॉडल आर्किटेक्चर और हमारे द्वारा अनुसरण की जाने वाली तकनीकों को दिखाएगा। विस्तृत जानकारी, जैसे प्रशिक्षण हाइपरपैरामीटर और प्रत्येक तकनीक द्वारा उत्पन्न परिणामों को संबंधित उप-वर्गों में दर्शाया जाएगा। हमारी अंतिम प्रस्तुतियों को 6 दिशाओं (अंग्रेजी ↔ चेक, अंग्रेजी ↔ रूसी, फ्रेंच → जर्मन और तमिल → अंग्रेजी) में शीर्ष स्थान दिया गया, 2 दिशाओं में तीसरा (अंग्रेजी → जर्मन, अंग्रेजी → जापानी), और 2 दिशाओं में चौथे स्थान पर (अंग्रेजी → पश्तो और अंग्रेजी → तमिल)।', 'zh': '本文示我(OPPO)凡 22 言 WMT20 新闻翻译共事机器翻译统。 先概述其常见,二者:数者,预处理之预处理也;统者,体之体系结构也。 详细信息(如练超参数,每术生成)将述于子。 终于6方(英语捷克语↔,英语↔俄语,法语→德语、泰米尔语→英语)第一,2方(英语→德语,英语→日语)第三,第四于2(英语→普什图语、英语→泰米尔语)。', 'ru': 'В этой статье мы демонстрируем наши (OPPO) системы машинного перевода для совместной задачи WMT20 по переводу новостей для всех 22 языковых пар. Сначала мы дадим обзор общих аспектов всех систем, включая две части: часть предварительной обработки данных покажет, как данные предварительно обрабатываются и фильтруются, а часть системы покажет нашу архитектуру моделей и методы, которым мы следовали. Подробная информация, такая как обучающие гиперпараметры и результаты, полученные с помощью каждого метода, будут показаны в соответствующих подразделах. Наши финальные представления заняли первое место по 6 направлениям (английский, ↔ чешский, английский ↔ русский, французский, → немецкий и тамильский → английский), третье место по 2 направлениям (английский → немецкий, английский → японский) и четвертое место по 2 направлениям (английский → пушту и английский → тамильский).', 'ga': 'Sa pháipéar seo léirímid ár gcórais aistriúcháin mheaisín (OPPO) don Tasc Comhroinnte WMT20 ar Aistriúchán Nuachta do na 22 phéire teanga go léir. Tabharfaimid forbhreathnú ar na gnéithe coitianta thar na córais go léir ar dtús, lena n-áirítear dhá chuid: léireoidh an chuid réamhphróiseála sonraí conas a dhéantar na sonraí a réamhphróiseáil agus a scagadh, agus léireoidh an chuid den chóras ailtireacht na samhlacha agus na teicnící a leanamar. Léireofar faisnéis mhionsonraithe, amhail hipearpharaiméadair oiliúna agus na torthaí a ghineann gach teicníc sna fo-ailt chomhfhreagracha. Bhain ár n-aighneachtaí deiridh barr i 6 threoir (Béarla ↔ Seicis, Béarla ↔ Rúisis, Fraincis → Gearmáinis agus Tamailis → Béarla), sa tríú háit i 2 threoir (Béarla → Gearmáinis, Béarla → Seapáinis), agus sa cheathrú háit i 2 threoir (Béarla → Paistis agus agus Béarla → Tamailis).', 'hu': 'Ebben a tanulmányban bemutatjuk (OPPO) a WMT20 Shared Task on News Fordítással kapcsolatos gépi fordító rendszereinket mind a 22 nyelvpárra. Először is áttekintést adunk az összes rendszer közös vonatkozásairól, beleértve két részt: az adatfeldolgozó rész bemutatja, hogyan dolgozzák fel és szűrik az adatokat, a rendszer pedig bemutatja modelleink architektúráját és az általunk követett technikákat. A megfelelő alszakaszokban részletes információkat, mint például a hiperparaméterek edzése és az egyes technikák által generált eredmények. Utolsó pályázataink 6 irányban (angol cseh, angol orosz, francia német és tamil angol), harmadik irányban (angol német, angol japán), és negyedik irányban (angol pashto és angol tamil).', 'ka': "ამ გვერდიში ჩვენ ჩვენი (OPPO's) მანქანის გადატყვების სისტემა WMT20 გაყოფილი რაოდენობის გადატყვების შესახებ ყველა 22 ენის ზოგებისთვის. ჩვენ ყველა სისტემაში ერთადერთი აპექტების გადავიწყებთ, პირველად ორი ნაწილი: მონაცემების გარეშექმნა ნაწილად მონაცემების გარეშექმნა და ფილტრირებულია, და სისტემა ნაწილად ჩვენი მოდელური აპექტიქტიკ განსაკუთრებული ინფორმაცია, როგორც ჰიპეროპარამეტრები და ყველა ტექნექტიკის შექმნილი შედეგი, იქნება შესაბამისი სპექციონებში. ჩვენი ბოლო შესაბამისი შესაბამისი შესაბამისი შესაბამისი სამუშაო დაწყება 6 წერტილებში (ინგლისური, ფექური, ინგლისური, პრენუსი, ტრანუსი, გერმანური და ტამილური) სამუშაო 2 წერტილებში (ანგლისური, გერმანური, ანგლისური  ია", 'kk': 'Бұл қағазда біз WMT20 жаңалық аудармалардың ортақ тапсырмаларының (OPPO) компьютерінің аудармаларды көрсетедік. Біз біріншіден бүкіл жүйелердің жалпы аспекттерін, екі бөліктерді қоса, біріншіден біріншіден қалай өзгертілген деректерді алдын- ала өзгерту және сүзгілеу үшін көрсетеді. Жүйелік бөлігі өзіміздің үлгіле Егжей- тегжейі мәлімет, мысалы гиперпараметрлерді оқыту мен әрбір техникалық нәтижелері сәйкес бөлімдерінде көрсетіледі. Біздің соңғы жіберіміз 6 бағытта жоғары (ағылшын, ағылшын, ағылшын, француз, неміс және тамил, ағылшын), үшінші 2 бағытта (ағылшын, неміс, ағылшын, япон) және төртінші бағытта (ағылшын, пашто және ағылшын және тами', 'el': 'Στην παρούσα εργασία παρουσιάζουμε τα συστήματα μηχανικής μετάφρασης (ΟΠPO) για την κοινή εργασία για τη μετάφραση ειδήσεων για όλα τα 22-γλωσσικά ζεύγη. Θα δώσουμε μια επισκόπηση των κοινών πτυχών σε όλα τα συστήματα πρώτα, συμπεριλαμβανομένων δύο μερών: το μέρος προεπεξεργασίας δεδομένων θα δείξει πώς τα δεδομένα είναι προεπεξεργασμένα και φιλτραρισμένα, και το μέρος του συστήματος θα δείξει την αρχιτεκτονική των μοντέλων μας και τις τεχνικές που ακολουθήσαμε. Λεπτομερείς πληροφορίες, όπως οι υπερπαράμετροι προπόνησης και τα αποτελέσματα που προκύπτουν από κάθε τεχνική θα απεικονίζονται στις αντίστοιχες υποενότητες. Οι τελικές μας υποβολές κατατάχθηκαν στην κορυφή των έξι κατευθύνσεων (Αγγλικά Τσεχικά, Αγγλικά Ρωσικά, Γαλλικά Γερμανικά και Ταμίλ Αγγλικά), τρίτη στις δύο κατευθύνσεις (Αγγλικά Γερμανικά, Αγγλικά Ιαπωνικά) και τέταρτη στις δύο κατευθύνσεις (Αγγλικά Παστό και Αγγλικά Ταμίλ).', 'lt': 'Šiame dokumente demonstruojame savo (OPPO) mašinų vertimo sistemas, skirtas WMT20 bendram naujienų vertimui skirtam darbui visoms 22 kalbų poroms. Pirmiausia pateiksime bendrų visų sistemų aspektų apžvalgą, įskaitant dvi dalis: duomenų apdorojimo dalis parodys, kaip duomenys apdorojami ir filtruojami, o sistemos dalis parodys mūsų modelių architektūrą ir metodus, kurių ėmėmės. Išsami informacija, pavyzdžiui, mokymo hiperparatoriai ir kiekvieno metodo rezultatai, bus aprašyti atitinkamuose poskirsniuose. Mūsų galutiniai pareiškimai buvo suskirstyti į 6 kryptis (anglų, čekų, anglų, rusų, prancūzų, vokiečių ir tamilų), trečią į 2 kryptis (anglų, vokiečių, anglų, japonų), ir ketvirtą į 2 kryptis (anglų, pašto ir anglų, tamilų).', 'ms': 'Dalam kertas ini kami menunjukkan sistem terjemahan mesin kami (OPPO) untuk Tugas Berkongsi WMT20 pada Perjemahan Berita untuk semua 22 pasangan bahasa. Kita akan memberikan paparan ringkasan aspek umum di seluruh sistem pertama-tama, termasuk dua bahagian: bahagian pemprosesan data akan menunjukkan bagaimana data diproses dan ditapis, dan bahagian sistem akan menunjukkan arkitektur model kita dan teknik yang kita ikuti. Maklumat terperinci, seperti hyperparameter latihan dan keputusan yang dijana oleh setiap teknik akan ditampilkan dalam subseksyen yang sepadan. Pemberian akhir kami tertinggi dalam 6 arah (Bahasa Inggeris, Cek, Inggeris, Rusia, Perancis, Jerman dan Tamil, Inggeris), ketiga dalam 2 arah (Bahasa Inggeris, Inggeris, Jepun), dan keempat dalam 2 arah (Bahasa Inggeris, Pashto dan Inggeris, Tamil).', 'it': "In questo articolo mostriamo i nostri sistemi di traduzione automatica (OPPO) per il WMT20 Shared Task on News Translation per tutte le 22 coppie linguistiche. Daremo una panoramica degli aspetti comuni di tutti i sistemi in primo luogo, includendo due parti: la parte di pre-elaborazione dei dati mostrerà come i dati sono pre-elaborati e filtrati, e la parte di sistema mostrerà l'architettura dei nostri modelli e le tecniche che abbiamo seguito. Informazioni dettagliate, come gli iperparametri di allenamento e i risultati generati da ciascuna tecnica saranno illustrati nelle sottosezioni corrispondenti. I nostri contributi finali si sono classificati al primo posto in 6 direzioni (inglese ceco, inglese russo, francese tedesco e tamil inglese), terzo in 2 direzioni (inglese tedesco, inglese giapponese) e quarto in 2 direzioni (inglese pashto e inglese tamil).", 'mt': "F'dan id-dokument nagħmlu xhieda tas-sistemi tagħna ta' traduzzjoni bil-magni (tal-OPPO) għall-Kompitu Konġunt dwar it-Traduzzjoni tal-Aħbarijiet tad-WMT20 għat-22 pari lingwistiċi kollha. Aħna se nagħtu ħarsa ġenerali lejn l-aspetti komuni fis-sistemi kollha l-ewwel nett, inklużi żewġ partijiet: il-parti tal-ipproċessar tad-dejta se turi kif id-dejta tiġi pproċessata minn qabel u ffiltrata, u l-parti tas-sistema se turi l-arkitettura tal-mudelli tagħna u t-tekniki segwiti. Informazzjoni dettaljata, bħall-iperparatteri tat-taħriġ u r-riżultati ġġenerati minn kull teknika se tiġi deskritta fis-sottotaqsimiet korrispondenti. Is-sottomissjonijiet finali tagħna kienu kklassifikati fl-ogħla livell f’sitt direzzjonijiet (Ingliż © Ċek, Ingliż © Russu, Franċiż © Ġermaniż u Tamil © Ingliż), it-tielet f’żewġ direzzjonijiet (Ingliż © Ġermaniż, Ingliż © Ġappuniż), u r-raba’ f’żewġ direzzjonijiet (Ingliż © Pashto u Ingliż © Tamil).", 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഞങ്ങളുടെ (ഓപ്പോയുടെ) യന്ത്രത്തിന്\u200dറെ പരിഭാഷണ സിസ്റ്റം കാണിച്ചു കൊടുക്കുന്നു. WMT20 വേര്\u200dതിരിച്ച് വിവര ആദ്യം എല്ലാ സിസ്റ്റത്തിലും സാധാരണ സാക്ഷ്യങ്ങളെക്കുറിച്ചും നമുക്ക് കാണിക്കാം, രണ്ടു ഭാഗങ്ങളെക്കൊണ്ടുള്ളൂ: ഡേറ്റാ പ്രൊപ്രോസിക്രേഷന്\u200d ഭാഗമാണ് ഡേറ വിശദീകരിച്ച വിവരങ്ങള്\u200d, പ്രദര്\u200dശിപ്പിക്കുന്ന ഹൈപ്പര്\u200dപാര്\u200dമീറ്ററുകളും ഓരോ ടെക്നിക്ക് ഉണ്ടാക്കുന്ന ഫലങ്ങളും പ്രതിരോധ നമ്മുടെ അവസാന സമ്മരണങ്ങള്\u200d 6 ദിശയില്\u200d ഉയര്\u200dന്നിരിക്കുന്നു (ഇംഗ്ലീഷ്\u200c, ഇംഗ്ലീഷ്\u200c, റഷ്യന്\u200d , ഫ്രെഞ്ച്\u200c, ജര്\u200dമ്മന്\u200d , താമില്\u200d , ഇംഗ്ലീഷ്\u200c, മൂന്നാമത്തെ രണ്ടു ദിശയില്\u200d (ഇംഗ്ലീഷ്- ജര്\u200d', 'mk': 'Во овој весник ги демонстрираме нашите (ОППО) машински преведувачки системи за WMT20 Shared Task on News Translation за сите 22 јазички парови. Ќе дадеме преглед на заедничките аспекти низ сите системи прво, вклучувајќи ги и двата дела: делот од препроцесот на податоците ќе покаже како податоците се препроцесирани и филтрирани, а делот од системот ќе ја покаже нашата архитектура на моделите и техниките кои ги следевме. Деталирани информации, како што се обуката на хиперпараметрите и резултатите генерирани од секоја техника ќе бидат опишани во соодветните подсекции. Нашите последни поднесувања се рангираа во 6 насоки (англиски, чешки, англиски, руски, француски, германски и тамилски), трети во 2 насоки (англиски, германски, јапонски) и четврти во 2 насоки (англиски, пасто и англиски, тамилски).', 'mn': 'Энэ цаасан дээр бид WMT20 хуваалтын ажлын (OPPO-ын) машины хөрөнгө оруулалтын системийг харуулж байна. Бид эхлээд бүх системийн нийтлэг асуудлуудыг харуулъя. Эхлээд хоёр хэсэг ч мөн: өгөгдлийн аль боловсруулах хэсэг нь өгөгдлийн хэрхэн ажиллаж, сүзгүүлж байгааг харуулъя. Систем хэсэг нь бидний загварын архитектур болон бидний дагасан техникуудыг Илүү нарийвчлалтай мэдээлэл, жишээ нь хиперпараметр болон техник бүр үүсгэсэн үр дүнг харьцуулахад харьцуулна. Манай сүүлийн давталт нь 6 хэсэгт дээд орж ирсэн (Англи, Чех, Англи, Орос, Француз, Герман, Тамил, Англи, Англи, Герман, Англи, Япон), 4 хэсэгт 2 хэсэгт орж ирсэн.', 'no': 'I denne papiret viser vi våre (OPPO sin) maskinsomsetjingssystemet for WMT20 delt oppgåve om nyhetssomsetjing for alle 22 språkopla. Vi vil gje ei oversikt over dei vanlege aspektane i alle systema først, inkludert to deler: data-forhandteringsdelen viser korleis data vert forhandsama og filtrert, og systemdelen viser våre modellerarkitektur og teknikken vi følgjer. Detaljerte informasjon, slik som øvingshyperparametrar og resultatene genererte av kvar teknikk, vert vist i dei tilsvarande underseksjonane. Våre siste oppføringar rangerte toppen i 6 retningar (engelsk, tsjekkisk, engelsk, russisk, fransk, tysk og tamsk, engelsk), tredje i 2 retningar (engelsk, tysk, engelsk og japansk), og fjerde i 2 retningar (engelsk, pashto og engelsk).', 'sr': 'U ovom papiru pokazujemo naše (OPPO) sisteme prevoda mašine za WMT20 zajednički zadatak o prevodu novina za sve 22 jezičke parove. Prvo ćemo dati pregled zajedničkih aspekta u svim sistemima, uključujući dve dijelove: deo preprocessiranja podataka će pokazati kako se podaci preobrađuju i filtriraju, a deo sistema će pokazati naše modele arhitekture i tehnike koje smo pratili. Detaljne informacije, kao što su hiperparametri obuke i rezultati koji su stvorili svaka tehnika, pokazat će se u odgovarajućim podsekcijama. Naše poslednje predstave su bile najgore na 6 smjernica (engleski, češki, engleski, ruski, francuski, nemački i tamilski), treće na 2 smjernica (engleski, nemački, engleski i japanski) i četvrti na 2 smjernica (engleski, pashto i engleski i tamilski).', 'pl': 'W niniejszym artykule przedstawiamy nasze systemy tłumaczenia maszynowego (OPPO) dla WMT20 Shared Task on News Translation dla wszystkich 22 par językowych. W pierwszej kolejności podamy przegląd wspólnych aspektów wszystkich systemów, w tym dwóch części: część wstępnego przetwarzania danych pokaże, jak dane są wstępnie przetwarzane i filtrowane, a część systemowa pokaże architekturę naszych modeli i stosowane techniki. Szczegółowe informacje, takie jak hiperparametry treningowe oraz wyniki generowane przez każdą technikę, zostaną przedstawione w odpowiednich podsekcjach. Nasze ostateczne zgłoszenia zajęły się najlepszymi miejscami w sześciu kierunkach (angielski czeski, angielski rosyjski, francuski niemiecki i tamilski angielski), trzecimi w dwóch kierunkach (angielski niemiecki, angielski japoński) i czwartymi w dwóch kierunkach (angielski paszto i angielski tamil).', 'sv': 'I denna uppsats visar vi v疇ra (OPPO:s) maskin繹vers瓣ttningssystem f繹r WMT20 Shared Task on News Translation f繹r alla de 22 spr疇kparen. Vi kommer att ge en 繹versikt 繹ver de gemensamma aspekterna i alla system f繹rst och fr瓣mst, inklusive tv疇 delar: den databehandlande delen kommer att visa hur data f繹rbehandlas och filtreras, och systemdelen kommer att visa v疇r modellarkitektur och de tekniker vi f繹ljt. Detaljerad information, s疇som tr瓣ningshyperparametrar och resultat som genereras av varje teknik, visas i motsvarande underavsnitt. V疇ra sista bidrag rankades h繹gst i 6 riktningar (engelska tjeckiska, engelska ryska, franska tyska och tamil engelska), tredje i 2 riktningar (engelska tyska, engelska japanska) och fj瓣rde i 2 riktningar (engelska pashto och engelska tamil).', 'ro': 'În această lucrare demonstrăm sistemele noastre de traducere automată (OPPO) pentru WMT20 Shared Task on News Translation pentru toate cele 22 de perechi de limbi. Vom oferi o imagine de ansamblu asupra aspectelor comune din toate sistemele în primul rând, inclusiv două părți: partea de pre-procesare a datelor va arăta modul în care datele sunt pre-procesate și filtrate, iar partea de sistem va arăta arhitectura modelelor noastre și tehnicile pe care le-am urmat. Informații detaliate, cum ar fi hiperparametrii de formare și rezultatele generate de fiecare tehnică vor fi prezentate în subsecțiunile corespunzătoare. Ultimele noastre participări s-au clasat în top în 6 direcții (engleză cehă, engleză rusă, franceză germană și tamil engleză), al treilea în 2 direcții (engleză germană, engleză japoneză) și al patrulea în 2 direcții (engleză pashto și engleză tamil).', 'ta': 'இந்த காகிதத்தில் நாம் எங்கள் (OPPO) இயந்திர மொழிமாற்ற அமைப்புகளை காட்டுகிறோம் WMT20 பகிர்ந்த செய்தி மொழிமாற்றி மொழிமாற முதலில் நாம் அனைத்து கணினிகளுக்கும் பொதுவான பாகங்களையும் காட்டுவோம். முதலில் இரண்டு பகுதிகளையும் சேர்த்துக் கொண்டிருக்கும்: தரவு முன் செயல்படுத்தல் பக விவரமான தகவல், தொழில்நுட்பமால் பயிற்சி அளபுருக்கள் மற்றும் ஒவ்வொரு தொழில்நுட்பமால் உருவாக்கப்பட்ட முடிவு எங்கள் இறுதியாக ஒப்புக்கொடுப்புகள் 6 திசைகளில் மேலே உள்ளன (ஆங்கிலம்- செக்கு, ஆங்கிலத்தில் , ருஷ்சு, பிரெஞ்சு , ஜெர்மன் மற்றும் டாமில்/ ஆங்கிலம்), மூன்றாவது 2 திசைகளில் (ஆங்கிலம் - ஜ', 'si': "මේ පත්තරේ අපි පෙන්වන්නේ අපේ පත්තර (OPPO's) පත්තර පද්ධතිය WMT20 සමාගත වැඩසටහන් වැඩසටහන් සම්පූර්ණය භාෂාවිර්මා අපි ප්\u200dරධාන පද්ධතියෙන් සාමාන්\u200dය ප්\u200dරතිකෘතිය ගැන සාමාන්\u200dය ප්\u200dරතිකෘතියක් දෙන්නම්, ප්\u200dරධාන කොටස් දෙන්නම්: තොරතුරු ප්\u200dරතිකෘතිකරණය සහ ප විස්තර තොරතුරු වගේ, හරියට ප්\u200dරේෂණය හායිපර් ප්\u200dරමාණය සහ හැම ප්\u200dරමාණයෙන් නිර්මාණය කරලා තියෙන ප්\u200dරතික්\u200dරිය අපේ අන්තිම පිළිබඳු පිළිබඳු පිළිබඳු 6 පිළිබඳ (ඉංග්\u200dරීසිය  චෙක්, ඉංග්\u200dරීසිය  රුසියා, ෆ්\u200dරැන්සිය  ජර්මන් හා ටැමිල්  ඉංග්\u200dරීසියා), 3 පිළිබඳ", 'so': 'Qoraalkan waxaynu muujinnaa nidaamka turjumista machine (OPPO) ee WMT20 oo loo sharciyey shaqo turjumista News ee labada luqadood oo dhan. Isticmaalka oo dhan marka ugu horeysa waxaan ka fiirinaynaa dhinacyada caadiga ah, kuwaas oo ka mid ah labo qayb: qeybta ka baaraandegista macluumaadka ayaa ka muuqan doona sida looga hor baaraandegayo oo loo baaraandegay, qeybta nidaamkana wuxuu tusi doonaa dhismaha dhismaha iyo qalabka aan soo raacnay. Macluumaad faah’iido ah, tusaale ahaan tababarida heerarka hyperparameters iyo resultiyada teknikada walba ka soo baxa waxaa lagu soo bandhigi doonaa qeybaha ku habboon. Qoraalkayaga ugu dambeeyayna waxay ka sarraysaa 6 kooxo (Ingiriis, Kilish, Ingiriis, Ruush, Faraansiis, Jarmal iyo Tamil), saddexaadna waxay ku qoran 2 kooxood (Ingiriis- Jarmal, Ingiriis, Ingiriis, Jarmal, Jabanees), afraadna waxay ku qoran 2 kooxood (Ingiriis - Pashto iyo Ingiriis)', 'ur': "ہم اس کاغذ میں اپنے (OPPO's) ماشین ترجمہ سیسٹم کو WMT20 شریک ٹاکس کے لئے نیویس ترجمہ پر تمام 22 زبان جوڑوں کے لئے دکھاتے ہیں۔ ہم پہلی بار تمام سیستموں میں مشترک اثرات کا نظر دیں گے، دو حصہ شامل ہوگا: ڈاٹا پرپرپرس کرنا حصہ دکھائے گا کہ ڈاٹا کس طرح پیش پرس کرے گا اور فیلتر کیے جاتے ہیں، اور سیستموں حصہ ہماری مدل معماری اور تکنیک دکھائے گا جو ہم نے پیچھے کیا ہے. مفصل معلومات، جیسے تعلیم hiperparameters اور نتیجے جو ہر تکنیک کے ذریعے پیدا ہوئے ہیں، ان کے مطابق تعلیم کے ساتھ دکھائے جائیں گے. ہماری آخری مضبوطی چھ طریقوں میں (انگلیسی ،چک ،انگلیسی ،روسی ،فرانسوی ،جرمانی اور تامیل ،انگلیسی ،انگلیسی ،تیسری طریقوں میں) تیسری طریقوں میں (انگلیسی ،جرمانی ،انگلیسی ،جاپانی ،اور چوتھی طریقوں میں) دو طریقوں میں (انگلیسی ،پشت", 'uz': "Bu hujjatda biz hamma 22 tillar ikki xil uchun WMT20 tarjima qilingan vazifalarni (OPPO) mashinaning tarjima tizimini ko'rsatamiz. Biz hamma tizimlarning birinchi tarkibini ko'rib chiqaramiz, ikki qismlarda: ma'lumot boshqaruvchi qismi maʼlumot qanday boshqarishni va filterlashni koʻrsatiladi, va tizimning qismi modelimizning arxituvchisini va biz qidirilgan teknikalarni koʻrsatiladi. @ info Bizning oxirgi ilhomlarimiz 6 yordamida (engliz, inglizcha, Ruscha, Fransuzcha, Olmoncha va Tamil tilida) uchinchi xizmatda (Inglizcha, Inglizcha, Inglizcha, Inglizcha, Inglizcha va Inglizcha) va ikkinchi tomonda (Inglizcha ingliz tilida, ingliz tilida) birinchi tomonda (Inglizcha- Pashto va Inglizcha tilida).", 'vi': 'Trong tờ giấy này chúng tôi chứng minh hệ thống dịch chuyển máy của chúng tôi (OPPO) cho tập đoàn WRT20 đã chia s ẻ Nhiệm vụ Dịch Tin tức cho mọi trường hợp ngôn ngữ 22. Chúng tôi sẽ cung cấp một thông tin tổng quát về các khía cạnh chung trong tất cả các hệ thống. Đầu tiên, gồm hai phần: phần xử lý dữ liệu sẽ cho thấy cách xử lý và lọc dữ liệu, và phần hệ thống sẽ cho thấy cấu trúc mẫu của chúng tôi và kỹ thuật chúng tôi đã làm theo. Thông tin chi tiết, như các siêu tham gia huấn luyện và kết quả của mỗi kỹ thuật sẽ được mô tả trong các phần phụ tương ứng. Những đệ trình cuối cùng của chúng tôi xếp hạng trên sáu hướng (Anh, Anh, Anh Nga, Pháp, Anh Quốc, Anh Quốc, Anh Quốc, Anh Quốc, Anh Quốc) và hạng hai theo hướng (Anh Pashto và Anh Tamil).', 'bg': 'В тази статия демонстрираме нашите системи за машинен превод за споделената задача за превод на новини за всички 22 езикови двойки. Първо ще дадем преглед на общите аспекти на всички системи, включващи две части: частта за предварителна обработка на данните ще покаже как данните са предварително обработени и филтрирани, а частта за системата ще покаже архитектурата на нашите модели и техниките, които следваме. Подробна информация, като тренировъчни хиперпараметри и резултатите, генерирани от всяка техника, ще бъдат изобразени в съответните подраздели. Последните ни предложения се класираха на първо място в 6 посоки (английски чешки, английски руски, френски немски и тамилски английски), трето в 2 посоки (английски немски, английски японски) и четвърто в 2 посоки (английски пащо и английски тамил).', 'da': "I denne artikel demonstrerer vi vores (OPPO's) maskinoversættelsessystemer til WMT20 Shared Task on News Translation for alle de 22 sprogpar. Vi vil først give et overblik over de fælles aspekter på tværs af alle systemer, herunder to dele: Den dataforbearbejdende del vil vise, hvordan dataene forbearbejdes og filtreres, og systemdelen vil vise vores modelarkitektur og de teknikker, vi fulgte. Detaljerede oplysninger, såsom træningshyperparametre og de resultater, der genereres af hver teknik, vil blive afbildet i de tilsvarende underafsnit. Vores endelige indsendelser rangerede top i 6 retninger (engelsk tjekkisk, engelsk russisk, fransk tysk og tamil engelsk), tredje i 2 retninger (engelsk tysk, engelsk japansk), og fjerde i 2 retninger (engelsk pashto og engelsk tamil).", 'nl': "In dit artikel demonstreren we onze (OPPO's) machine translation systemen voor de WMT20 Shared Task on News Translation voor alle 22 taalparen. In de eerste plaats geven we een overzicht van de gemeenschappelijke aspecten van alle systemen, inclusief twee delen: het deel data preprocessing laat zien hoe de data vooraf verwerkt en gefilterd worden, en het systeemdeel toont onze modelarchitectuur en de technieken die we hebben gevolgd. Gedetailleerde informatie, zoals trainingshyperparameters en de resultaten die door elke techniek worden gegenereerd, worden weergegeven in de overeenkomstige subsecties. Onze laatste inzendingen stonden bovenaan in zes richtingen (Engels Tsjechisch, Engels Russisch, Frans Duits en Tamil Engels), derde in twee richtingen (Engels Duits, Engels Japans) en vierde in twee richtingen (Engels Pashto en Engels Tamil).", 'de': 'In diesem Beitrag zeigen wir unsere (OPPO) maschinellen Übersetzungssysteme für den WMT20 Shared Task on News Translation für alle 22-Sprachpaare. Wir werden zunächst einen Überblick über die gemeinsamen Aspekte aller Systeme geben, einschließlich zweier Teile: Der Teil der Datenvorverarbeitung zeigt, wie die Daten vorverarbeitet und gefiltert werden, und der Teil des Systems zeigt unsere Modellarchitektur und die Techniken, die wir befolgt haben. Detaillierte Informationen, wie Trainingshyperparameter und die Ergebnisse der einzelnen Techniken werden in den entsprechenden Unterabschnitten dargestellt. Unsere endgültigen Einreichungen belegten in sechs Richtungen (Englisch Tschechisch, Englisch Russisch, Französisch Deutsch und Tamil Englisch), in zwei Richtungen drei (Englisch Deutsch, Englisch Japanisch) und vierte in zwei Richtungen (Englisch Paschto und Englisch Tamil).', 'ko': '본고에서 우리는 22개 언어 쌍의 WMT20 뉴스 번역 공유 임무에 사용되는 우리(OPPO)의 기계 번역 시스템을 보여 주었다.우리는 먼저 모든 시스템의 공통점을 개술할 것이다. 두 가지 부분을 포함한다. 데이터 예처리 부분은 데이터를 어떻게 예처리하고 필터하는지를 보여주고 시스템 부분은 우리의 모델 구조와 우리가 따르는 기술을 보여줄 것이다.상세한 정보, 예를 들어 훈련 초파라미터와 각 기술이 발생하는 결과는 상응하는 소절에서 설명할 것이다.우리가 최종 제출한 자료는 6개 방향(영어-체코어, 영어-러시아어, 프랑스어-독일어·타밀어)에서 1위, 2개 방향(영어-독일어, 영어-일본어)에서 3위, 2개 방향(영어-푸슈투어·영어-타밀어)에서 4위였다.', 'hr': 'U ovom papiru pokazujemo naše (OPPO) sustave za prevod stroja za WMT20 zajednički zadatak o prevodu vijesti za sve 22 jezičke parove. Prvo ćemo dati pregled zajedničkih aspekta u svim sustavima, uključujući dvije dijelove: dio preprocessiranja podataka će pokazati kako su podaci preobrađeni i filtrirani, a dio sustava će pokazati naše modele arhitekture i tehnike koje smo slijedili. Detaljne informacije, poput hiperparametara obuke i rezultata proizvedenih od svake tehnike, pokazat će se u odgovarajućim podjelama. Naše posljednje predstave su postavljene na vrhu u 6 smjernica (engleski, češki, engleski, ruski, francuski, nemački i tamilski, engleski), treće u 2 smjernica (engleski, njemački, engleski i japanski) i četvrti u 2 smjernica (engleski, pashto i engleski i tamilski).', 'sw': 'Katika gazeti hili tunaonyesha mfumo wa kutafsiri mashine yetu (OPPO) kwa ajili ya kazi ya WMT20 iliyosambana kwenye Tafsiri ya Habari kwa ajili ya wanandoa wote wa lugha 22. Tutakuwa na mtazamo wa masuala ya kawaida katika mifumo yote ya kwanza, ikiwa ni pamoja na sehemu mbili: sehemu ya upasuaji wa data utaonyesha jinsi taarifa zinavyoendelea na kuchujwa, na sehemu ya mfumo utaonyesha ujenzi wetu na mbinu tulizofuata. Taarifa zilizoelezwa, kama vile mafunzo ya upasuaji na matokeo yaliyotengenezwa na kila teknolojia yataonekana katika vipande vinavyohitajika. Our final submissions ranked top in 6 directions (English   Czech, English   Russian, French   German and Tamil   English), third in 2 directions (English   German, English   Japanese), and fourth in 2 directions (English   Pashto and and English   Tamil).', 'af': "In hierdie papier vertoon on s (OPPO se) masjien vertaling stelsels vir die WMT20 Gedeelde Taak op Nuus Vertaling vir al die 22 taal paar. Ons sal 'n oorskou van die gemeenskaplike aspekte gee oor al die stelsels eerste, insluitend twee dele: die data voorprosessering deel sal vertoon hoe die data voorprosesseer en filterer word, en die stelsel deel sal ons modele arkitektuur en die teknike wat ons gevolg het vertoon. Gedetaileerde inligting, soos onderwerp hiperparameters en die resultate genereer deur elke tekniks sal in die ooreenstemmende subseksies vertoon word. Ons eindelike onderskrifte rangeer bo in 6 rigtings (Engels  Tschekis, Engels  Russe, Frans  Duits en Tamil  Engels), derde in 2 rigtings (Engels  Duits, Engels  Japanse), en vierde in 2 rigtings (Engels  Pashto en Engels  Tamil).", 'fa': 'در این کاغذ ما سیستم\u200cهای ترجمه ماشین\u200cمان (OPPO) را نشان می\u200cدهیم برای کار مشترک WMT20 در ترجمه خبری برای همه جفت\u200cهای ۲۲ زبان. ما اول از همه سیستم\u200cهای مشترک را به نظر می\u200cدهیم، شامل دو قسمت: قسمت پیش\u200cپردازی داده\u200cها نشان می\u200cدهند چگونه داده\u200cها پیش\u200cپردازی و فیلتر می\u200cشوند، و قسمت سیستم معماری مدل\u200cهای ما و تکنیک\u200cهای ما را نشان می\u200cدهد. اطلاعات جزئیات، مثل آموزش hiperparameters و نتیجه\u200cهای توسط هر تکنیک در قسمت\u200cهای متفاوت نشان داده می\u200cشوند. اخرين تسليم\u200cهامون در شش مسير بالا بود (انگليسي ،چک ،انگليسي ،روسي ،فرانسوي ،آلماني و تاميل ،انگليسي ،سومين در دو مسير (انگليسي ،آلماني ،انگليسي ،ژاپني ،و چهارمين در دو مسير) و چهارمين در دو مسير', 'tr': "WMT20 Iňlis terjimelerinde ähli 22 dil çiftleriň üçin Maşynyň (OPPO'yň) maşynyň terjime sistemlerini görkezýäris. Birinjisi hemme sistemalarda umumy aspektlary görüp bileris, iki bölümde dahil bolsa: veri öňünden işlemek üçin data öňünden işledilen we filtrellendirilen bölümleri görkeziler we sistem bölümi biziň modellerimiz arhitekturlygymyzy we geýillendirilen tekniklerimizi görkeziler. Ýöne hiperparametrlary we netijesi, her teknikiň tarapyndan döredilen detaylar maglumaty ýaly, näme üçin näme üçin bu sahypalarda görkezilecek. Biziň soňky gönderilenimiz 6 ýarym ýokary (iňlisçe  Çek, iňlisçe  Rusça, fransuzça  Almança we iňlisçe  Iňlisçe), 2 ýarym ýokary üçünji (iňlisçe  Almança, iňlisçe  Japonça) we 2 ýarym yönde dördünji (iňlisçe  Pashto we iňlisçe  Tamil).", 'id': 'Dalam kertas ini kami menunjukkan sistem terjemahan mesin kami (OPPO) untuk WMT20 Shared Task on News Translation untuk semua 22 pasangan bahasa. Kita akan memberikan pandangan dari aspek umum di seluruh sistem pertama-tama, termasuk dua bagian: bagian pemroses data akan menunjukkan bagaimana data diproses dan dipilter, dan bagian sistem akan menunjukkan arsitektur model kita dan teknik yang kita ikuti. Informasi terperinci, seperti hyperparameter pelatihan dan hasil yang dihasilkan oleh setiap teknik akan ditampilkan dalam subseksi yang sesuai. Our final submissions ranked top in 6 directions (English   Czech, English   Russian, French   German and Tamil   English), third in 2 directions (English   German, English   Japanese), and fourth in 2 directions (English   Pashto and and English   Tamil).', 'sq': "Në këtë letër ne demonstrojmë sistemet tona të përkthimit të makinave (OPPO's) për detyrën e përbashkët WMT20 për përkthimin e lajmeve për të gjithë 22 çiftet gjuhësh. Ne do të japim një përmbledhje të aspekteve të përbashkëta në të gjithë sistemet së pari, duke përfshirë dy pjesë: pjesa e përgatitjes së të dhënave do të tregojë se si të dhënat janë përgatitur dhe filtruar, dhe pjesa e sistemit do të tregojë modelet tona arkitekturë dhe teknikat që kemi ndjekur. Detailed information, such as training hyperparameters and the results generated by each technique will be depicted in the corresponding subsections.  Our final submissions ranked top in 6 directions (English   Czech, English   Russian, French   German and Tamil   English), third in 2 directions (English   German, English   Japanese), and fourth in 2 directions (English   Pashto and and English   Tamil).", 'az': "Bu kağızda WMT20'nin paylaşılmış işləri haqq çevirilməsi barəsində bütün 22 dil çift üçün (OPPO's) maşın çevirilməsi sistemlərini göstəririk. Biz ilk dəfə bütün sistemlərin ortaq aspektlərini, iki parçasını da dahil edəcəyik: məlumatların əvvəlcə işlədilməsi və filtrləndirilməsi üçün məlumatların necə işlədiklərini göstərəcək və sistem parçası modellərimizin arhitektürünü və bizim takib etdiyimiz teknikləri göstərəcək. Hər teknikin yaratdığı nəticələr kimi hiperparametrləri təhsil etmək və müəyyən edilən məlumatlar müəyyən edilənlər arasında göstəriləcəkdir. Əvvəlki məlumatlarımız 6 yönəldir (İngilizce, Çehir, İngilizce, Rus, Fransız, Almanca və Tamil, İngilizce, İngilizce, İngilizce, Almanca, İngilizce və Japonca), üçüncü 2 yönəldir (İngilizce, Pashto və İngilizce - Tamil).", 'bn': 'এই কাগজটিতে আমরা আমাদের (ওপিপোর) মেশিন অনুবাদ সিস্টেম প্রদর্শন করেছি যারা ২২ ভাষার জোড়ার জন্য উইএমটি২০ সংবাদ অনুবাদের জন্য সং We will give an overview of the common aspects across all the systems firstly, including two parts: the data preprocessing part will show how the data are preprocessed and filtered, and the system part will show our models architecture and the techniques we followed.  Detailed information, such as training hyperparameters and the results generated by each technique will be depicted in the corresponding subsections.  আমাদের চূড়ান্ত প্রদানের শেষ দিকে ছয় দিকে পরিচালিত হয়েছে (ইংরেজী, ইংরেজী, রুশ, ফ্রেঞ্চ, জার্মান এবং তামিল ইংরেজী), দুই দিকে তৃতীয় ভাষায় (ইংরেজী, জার্মানী, ইংরেজী, জাপানী),', 'am': 'በዚህ ገጾች ውስጥ ለ22 ቋንቋዎች ሁለት ዓይነቶች ሁሉ የWMT20 የዜና ትርጉም ማድረግ የተጋራጨውን ስርዓታችንን (OPPO) መሳሪያን ትርጉም ስርዓቶችን እናሳየዋለን፡፡ መጀመሪያ በሙሉ ስርዓቶች ሁሉ ላይ የሁኔታ ጉዳዮች እና ሁለት ክፍሎች እናሳያልን፤ የዳታ ፕሮግራም ክፍል ዳታዎችን እንዴት እንደተቃወመ እና እንዴት እንደተጠቃየቁ እና የሲስተም ክፍል ምሳሌዎቻችንን መዝገብ እና የተከተሉትን ስክሮች ያሳያል፡፡ የዝርዝር መረጃ፣ እንደማያስተምር hyperparameters እና በየቴክክሎጂው የደረገው ፍሬቶች በአስተያየት ክፍሎች ውስጥ ይታያል፡፡ የመጨረሻይቱ መልዕክታችን 6 መንገዶች (እንግሊዝኛ ፣ ቻክክ ፣ እንግሊዘኛ ፣ ሮሽኛ ፣ ፈረንሳይ የጀርመን እና ታሚሊ ፣ ሦስተኛው በ2 መንገዶች (እንግሊዝኛ ጀርመን ፣ እንግሊዘኛ ፣ ጃፓንኛ)፣ አራተኛ በመንገድ (እንግሊዝኛ ፓሽኮ እና እንግሊዝኛ ፣ ታሚሊ)።', 'ca': "En aquest article demostram els nostres (OPPO's) sistemes de traducció màquinària per a la Task Shared on News Translation WMT20 per tots els 22 parells de llengües. En primer lloc, donarem una visió general dels aspectes comuns de tots els sistemes, incloent dues parts: la part de la preprocessió de dades mostrarà com les dades són preprocesades i filtradas, i la part del sistema mostrarà la arquitectura dels nostres models i les tècniques que vam seguir. Informació detallada, com els hiperparamètres d'entrenament i els resultats generats per cada tècnica, es mostraran en les subseccions correspondents. Les nostres proposicions finals es van classificar en 6 direccions (anglès · cec, anglès · russ, francès · german i tamil · anglès), tercer en 2 direccions (anglès · german, anglès · japonès), i quart en 2 direccions (anglès · pashto i anglès · tamil).", 'bs': 'U ovom papiru pokazujemo naše (OPPO) sustave za prevod mašine za WMT20 zajednički zadatak o prevodu novina za sve 22 jezičke parove. Prvo ćemo dati pregled zajedničkih aspekta u svim sistemima, uključujući dvije dijelove: dio preprocessiranja podataka će pokazati kako su podaci preprocessirani i filtrirani, a dio sistema će pokazati naše modele arhitekture i tehnike koje smo slijedili. Detaljne informacije, poput hiperparametara obuke i rezultata koji su proizvedeni svakom tehnikom, pokazat će se u odgovarajućim podsekcijama. Naše poslednje predstave su bile najgore na 6 smjernica (engleski, češki, engleski, ruski, francuski, njemački i tamilski, engleski), treće na 2 smjernica (engleski, njemački, engleski i japanski), i četvrti na 2 smjernica (engleski, pashto i engleski i tamil).', 'et': 'Käesolevas dokumendis demonstreerime meie (OPPO) masintõlkesüsteeme WMT20 uudiste tõlkimise jagatud ülesande jaoks kõigile 22 keelepaarile. Esiteks anname ülevaate kõigi süsteemide ühistest aspektidest, sealhulgas kahest osast: andmete eeltöötluse osa näitab, kuidas andmeid eeltöötletakse ja filtreeritakse ning süsteemiosas näidatakse meie mudelite arhitektuuri ja järgitud tehnikaid. Üksikasjalik teave, näiteks treeningu hüperparameetrid ja iga tehnika tulemused on esitatud vastavates alapunktides. Meie lõplikud ettepanekud olid 6 suunas parimad (inglise tšehhi, inglise vene, prantsuse saksa ja tamili inglise), kolmandad kahes suunas (inglise saksa, inglise jaapani) ja neljandad kahes suunas (inglise pašto ja inglise tamil).', 'cs': 'V tomto článku demonstrujeme naše systémy strojového překladu pro WMT20 Shared Task on News Translation pro všechny 22 jazykové páry. Nejprve uvádíme přehled společných aspektů napříč všemi systémy, včetně dvou částí: část předzpracování dat ukáže, jak jsou data předzpracována a filtrována, a část systému ukáže architekturu našich modelů a techniky, které jsme sledovali. Podrobné informace, jako jsou hyperparametry tréninku a výsledky generované každou technikou, budou zobrazeny v příslušných podsekcích. Naše závěrečné příspěvky se dostaly do šesti směrů (angličtina čeština, angličtina ruština, francouzská němčina a tamilština), třetí ve dvou směrech (angličtina němčina, angličtina japonština) a čtvrté ve dvou směrech (angličtina paština a angličtina tamilština).', 'fi': 'T채ss채 artikkelissa esittelemme (OPPO:n) konek채채nn철sj채rjestelm채mme WMT20 Shared Task on News Translation kaikille 22 kieliparille. Annamme ensin yleiskatsauksen kaikkien j채rjestelmien yhteisist채 n채k철kohdista, mukaan lukien kaksi osaa: tietojen esik채sittelyosa n채ytet채채n, miten tiedot esiprosessoidaan ja suodatetaan, ja j채rjestelm채osassa esitell채채n malliarkkitehtuurimme ja k채ytt채m채mme tekniikat. Yksityiskohtaiset tiedot, kuten harjoitushyperparametrit ja kunkin tekniikan tuottamat tulokset esitet채채n vastaavissa alajaksoissa. Lopulliset tulokset sijoittuivat k채rkeen kuudessa suunnassa (englanti t큄ekki, englanti ven채j채, ranska saksa ja tamil englanti), kolmanneksi kahdessa suunnassa (englanti saksa, englanti japani) ja nelj채nneksi kahdessa suunnassa (englanti pa큄to ja englanti tamil).', 'hy': 'Այս թղթի մեջ մենք ցույց ենք տալիս մեր (ՕՊՕ-ի) մեքենային թարգմանման համակարգերը, որոնք օգտագործվում են ԱՄԹ20-ի ընդհանուր նորությունների թարգմանման խնդիրների համար բոլոր 22 լեզվով զույգերի համար: We will give an overview of the common aspects across all the systems firstly, including two parts: the data preprocessing part will show how the data are preprocessed and filtered, and the system part will show our models architecture and the techniques we followed.  Detailed information, such as training hyperparameters and the results generated by each technique will be depicted in the corresponding subsections.  Our final submissions ranked top in 6 directions (English   Czech, English   Russian, French   German and Tamil   English), third in 2 directions (English   German, English   Japanese), and fourth in 2 directions (English   Pashto and and English   Tamil).', 'jv': 'Nang pepulan iki kita maneh akeh sistem terjamahan (OPpo\'s) kanggo ngilanggar-sistem sing bisa WT 2 share task kanggo "New translation" kanggo nganggo kelas 22 bangsa. Awak dhéwé bakal ngewehke perusahaan anyar sampek karo hal-hal sistem sing berarti, nik sakjane durung: bukton dadi nggawe perusahaan sistem sing berarti perusahaan karo ngono nggawe sistem sing berarti, lan sakjane sampek sistem sing berarti architecture sampek lan teknik sing berarti dhéwé. Detayed information, like testing iperparameters and the output generated by every method will be depicted in the conflicting boxes. Awak dhéwé, kok luwih-luwih teluké teluké karo urip kayanjur kanggo nyebuté sing katêk kanggo karang kelas 6', 'he': "בעיתון הזה אנחנו מראים את מערכות התרגום המכונית שלנו (של OPPO) עבור המשימה המשותפת WMT20 על התרגום חדשות לכל 22 זוגות שפות. אנו נותנים תצוגה כללית של היבטים המשותפים בכל המערכות קודם כל, כולל שני חלקים: החלק ההעברה של נתונים יראה איך נתונים מועבדים ומסינים, והחלק מהמערכת יראה את הארכיטקטורה המודלים שלנו והטכניקות שעקבנו אחריהם. מידע מפורט, כמו היפרפרמטרים האימונים והתוצאות שנוצרו על ידי כל טכניקה, יוצג בתחתונים המתאימים. השימושים האחרונים שלנו התייצבו בשישה כיוונים (אנגלית, צ'צ'ית, אנגלית, רוסית, צרפתית, גרמנית וטמילית, אנגלית), השלישית בשני כיוונים (אנגלית, גרמנית, אנגלית, יפנית), ורביעית בשני כיוונים (אנגלית, פאשטו, אנגלית, טמילית).", 'ha': "In this paper we demonstrate our (OPPO's) machine translation systems for the WMT20 Shared Task on News Translation for all the 22 language pairs.  Za iya nuna kowace masu jama'a a cikin duk na'ura, farkon, tare da rabo biyu: rabin aiki da data za'a nuna yadda aka tsẽrar da data kuma aka filtera, kuma rabon na'ura zai nuna masu tsarin misalinmu da masu tsarin da aka bi mu. Agaji na bayyana, kamar mafarin parameters da matsalar da aka ƙãga kowace technical, za'a nuna su cikin ƙungiyõyi da ke daidai. GammayinMu na ƙarshen da aka ranar ta cikin 6 hanyõyi (Kicheki, Ingiriya , Ruushi, Faransa , Jarman da Tazil ), na uku cikin 2 hanyõyi (Ingiriya /Jarman, Ingiriya /Jabaniya), da na rubu cikin 2 hanyõyi (Ingiriiska /Pashto da Ingiriya )", 'sk': 'V tem prispevku predstavljamo naše (OPPO) sisteme strojnega prevajanja za WMT20 Shared Task on News Translation za vseh 22 jezikovnih parov. Najprej bomo predstavili pregled skupnih vidikov vseh sistemov, vključno z dvema deloma: del predobdelave podatkov bo pokazal, kako se podatki predobdelujejo in filtrirajo, sistemski del pa bo prikazal arhitekturo modelov in tehnike, ki smo jih sledili. Podrobne informacije, kot so hiperparametri usposabljanja in rezultati posamezne tehnike, bodo prikazani v ustreznih pododdelkih. Naši končni prispevki so se uvrstili na vrh v 6 smereh (angleški češčini, angleški ruščini, francoski nemščini in tamilski angleščini), tretji v 2 smereh (angleški nemščini, angleški japonščini) in četrti v 2 smereh (angleški pašto in angleški tamil).', 'bo': "In this paper we demonstrate our (OPPO's) machine translation system for the WMT20 Shared Task on News Translation for the 22 language pairs all. ང་ཚོའི་དབང་ཆ་དང་གཅིག་ཁར་མཐུན་གྱི་ཡིག་ཆ་གཅིག་ལས་དབང་ཆ་ཡོད་པ་དེ་རྟོགས་འོང་། Detailed information, such as training hyperparameters and the results generated by each technique will be depicted in the corresponding subsections. ང་བཅས་ཀྱི་མཐའ་མཇུག་གི་མིང་ཚོའི་ནང་དུ་བཏུབ་པའི་རྒྱབ་ཐག་ཅིག་ཡིན།"}
{'en': 'HW-TSC’s Participation in the WMT 2020 News Translation Shared Task', 'ar': 'مشاركة HW-TSC في المهمة المشتركة لترجمة الأخبار WMT 2020', 'es': 'Participación de HW-TSC en la tarea compartida de traducción de noticias del WMT 2020', 'pt': 'Participação do HW-TSC na tarefa compartilhada de tradução de notícias do WMT 2020', 'fr': 'Participation de HW-TSC à la tâche partagée de traduction des actualités WMT 2020', 'ja': 'HW - TSCのWMT 2020ニュース翻訳共有タスクへの参加', 'hi': 'WMT 2020 समाचार अनुवाद साझा कार्य में HW-TSC की भागीदारी', 'zh': 'HW-TSCšłéWMT 2020śĖįťóĽŤĮĎŚÖĪšļč', 'ru': 'Участие HW-TSC в совместной задаче по переводу новостей WMT 2020', 'ga': 'Rannpháirtíocht HW-TSC i dTasc Comhroinnte Aistriúcháin Nuachta WMT 2020', 'hu': 'A HW-TSC részvétele a WMT 2020 Hírek Fordítás Megosztott feladatában', 'el': 'Συμμετοχή του ΗΕ-ΤΣΕ στο Παγκόσμιο Μετάφραση 2020 Νέα Κοινή Εργασία', 'ka': 'HW-TSC-ის დაწყვეტილება WMT 2020 გასაგულისხმების გასაგულისხმების გასაგულისხმებით', 'it': 'La partecipazione di HW-TSC al WMT 2020 News Translation Shared Task', 'kk': 'HW- TSC WMT 2020 жаңалық аудару ортақтастырылған тапсырманың қатынасы', 'lt': 'HW-TSC dalyvavimas bendroje WMT 2020 naujienų vertimo užduotyje', 'ms': 'Pesertaan HW-TSC dalam Tugas Berkongsi Terjemahan Berita WMT 2020', 'mk': 'Учеството на ХВ-ТС во заедничката задача за преведување на вестите на WMT 2020', 'ml': "HW-TSC's Participation in the WMT 2020 News Translation Shared Task", 'mt': 'Il-Parteċipazzjoni tal-HW-TSC fil-Kompitu Konġunt tat-Traduzzjoni tal-Aħbarijiet tad-WMT 2020', 'ro': 'Participarea HW-TSC la activitatea partajată de traducere a știrilor WMT 2020', 'no': 'HW-TSC- deltakaren i WMT 2020- omsetjinga delt oppgåve', 'sr': 'Učestvo HW-TSC-a u zajedničkom zadatku za prevod novina WMT 2020', 'so': "HW-TSC's Participation in the WMT 2020 News Translation Shared Task", 'si': "HW-TSC's partition in the WMT 2020News translation shared Job", 'mn': "HW-TSC's Participation in the WMT 2020 News Translation Shared Task", 'ta': 'WMT 2020 செய்தி மொழிபெயர்ப்பு பங்கிடப்பட்ட பணி', 'ur': "HW-TSC's Participation in the WMT 2020 News Translation Shared Task", 'sv': 'HW-TSC:s deltagande i WMT 2020 Nyhetsöversättning delad uppgift', 'pl': 'Udział HW-TSC w WMT 2020 Aktualności Tłumaczenie Wspólne Zadanie', 'uz': 'WMT 2020 yangilari tarjima tarjimasi', 'vi': 'HW-TSC tham gia vào Nhiệm vụ chia s ẻ WM 2020.', 'bg': 'Участието на ХУ-ТСК в съвместна задача за превод на новини', 'nl': 'Deelname van HW-TSC aan de WMT 2020 Nieuws Vertaling Gedeelde taak', 'da': "HW-TSC's deltagelse i WMT 2020 Nyheder Oversættelse delt opgave", 'hr': 'Učestvo HW-TSC-a u zajedničkom zadatku za prevod vijesti WMT 2020', 'de': 'Teilnahme des HW-TSC an der WMT 2020 News Übersetzung Gemeinsame Aufgabe', 'id': "HW-TSC's Participation in the WMT 2020 News Translation Shared Task", 'fa': 'شرکت HW-TSC در ترجمه خبری WMT 2020', 'ko': 'WMT 2020 뉴스 번역 공유 임무에 HW-TSC 참여', 'sw': 'Ushiriki wa HW-TSC katika Tafsiri za Habari za WMT 2020', 'tr': "HW-TSC'nin WMT 2020 Haýsy Çeviri Paýlaşma Görevinde bölümleri", 'af': 'HW-TSC se Deelnadering in die WMT 2020 Nuusvertaling Gedeelde Taak', 'sq': 'Pjesëmarrja e HW-TSC në detyrën e përbashkët të përkthimit të lajmeve të WMT 2020', 'hy': 'ՀՈւ-ՏՍԿ-ի մասնակցությունը ԱՄԹ 2020-ի նորությունների թարգմանման կիսված խնդրում', 'az': 'HW-TSC WMT 2020 Haqq Çeviri paylaşılmış Taskdə Bölüm', 'am': 'WMT 2020 ዜናዎች ትርጓሜ ተርጓሚዎች የተShared ስራ', 'cs': 'Účast HW-TSC na WMT 2020 Novinky Překlad Sdílený úkol', 'bn': 'WMT ২০২০ সংবাদ অনুবাদ শেয়ার করা কাজে এইচউ-টিএসসির অংশগ্রহণ', 'bs': 'Učestvo HW-TSC-a u zajedničkom zadatku za prevod novina WMT 2020', 'ca': 'La participació de HW-TSC a la tasca compartida de traducció de notícies del WMT 2020', 'et': 'HW-TSC osalemine WMT 2020 Uudiste tõlkimine jagatud ülesanne', 'fi': 'HW-TSC:n osallistuminen WMT 2020 News Translation Shared Task', 'jv': "HWT-T-sck's Manyang sing nganggo WHAT 2020 Hawitan Terjamahan", 'sk': 'Sodelovanje HW-TSC v skupni nalogi prevajanja novic WMT 2020', 'he': "HW-TSC's Participation in the WMT 2020 News Translation Shared Task", 'ha': '@ info: whatsthis', 'bo': "HW-TSC's Participation in the WMT 2020 News Translation Shared Task"}
{'en': 'This paper presents our work in the WMT 2020 News Translation Shared Task. We participate in 3 language pairs including Zh / En, Km / En, and Ps / En and in both directions under the constrained condition. We use the standard Transformer-Big model as the baseline and obtain the best performance via two variants with larger parameter sizes. We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual dataset. Several commonly used strategies are used to train our models such as Back Translation, Ensemble Knowledge Distillation, etc. We also conduct experiment with similar language augmentation, which lead to positive results, although not used in our submission. Our submission obtains remarkable results in the final evaluation.', 'ar': 'تقدم هذه الورقة عملنا في المهمة المشتركة لترجمة الأخبار WMT 2020. نشارك في 3 أزواج لغوية بما في ذلك Zh / En و Km / En و Ps / En وفي كلا الاتجاهين في ظل الحالة المقيدة. نحن نستخدم نموذج Transformer-Big القياسي كخط أساس ونحصل على أفضل أداء عبر متغيرين بأحجام معلمات أكبر. نقوم بإجراء معالجة مسبقة وتصفية مفصلة على مجموعة البيانات واسعة النطاق المتوفرة ثنائية اللغة وأحادية اللغة. يتم استخدام العديد من الاستراتيجيات الشائعة الاستخدام لتدريب نماذجنا مثل الترجمة العكسية ، وتقطير المعرفة بالمجموعة ، وما إلى ذلك. ونجري أيضًا تجربة مع زيادة اللغة المماثلة ، مما يؤدي إلى نتائج إيجابية ، على الرغم من عدم استخدامها في تقديمنا. حصل تقديمنا على نتائج رائعة في التقييم النهائي.', 'pt': 'Este artigo apresenta nosso trabalho na Tarefa Compartilhada de Tradução de Notícias do WMT 2020. Participamos em 3 pares de idiomas incluindo Zh/En, Km/En e Ps/En e em ambas as direções sob condição restrita. Usamos o modelo padrão Transformer-Big como linha de base e obtemos o melhor desempenho por meio de duas variantes com tamanhos de parâmetros maiores. Realizamos pré-processamento e filtragem detalhados no conjunto de dados bilíngüe e monolíngue em grande escala fornecido. Várias estratégias comumente usadas são usadas para treinar nossos modelos, como Back Translation, Ensemble Knowledge Distillation, etc. Também realizamos experimentos com aprimoramento de linguagem semelhante, que levam a resultados positivos, embora não sejam usados em nossa submissão. Nossa submissão obtém resultados notáveis na avaliação final.', 'es': 'Este artículo presenta nuestro trabajo en la tarea compartida de traducción de noticias del WMT 2020. Participamos en 3 pares de idiomas, incluidos Zh/En, Km/En y Ps/En, y en ambas direcciones bajo la condición restringida. Utilizamos el modelo Transformer-Big estándar como referencia y obtenemos el mejor rendimiento a través de dos variantes con tamaños de parámetros más grandes. Realizamos preprocesamiento y filtrado detallados en el conjunto de datos bilingües y monolingües a gran escala proporcionado. Se utilizan varias estrategias de uso común para entrenar nuestros modelos, como la traducción inversa, la destilación de conocimientos conjuntos, etc. También realizamos experimentos con un aumento del lenguaje similar, que conduce a resultados positivos, aunque no se utilizan en nuestro envío. Nuestra presentación obtiene resultados notables en la evaluación final.', 'fr': "Cet article présente notre travail dans le cadre de la tâche partagée de traduction des actualités WMT 2020. Nous participons à 3 paires de langues, y compris Zh/En, Km/En et Ps/En et dans les deux directions sous la condition contrainte. Nous utilisons le modèle standard Transformer-Big comme référence et obtenons les meilleures performances via deux variantes avec des tailles de paramètres plus grandes. Nous effectuons un prétraitement et un filtrage détaillés sur le jeu de données bilingue et monolingue à grande échelle fourni. Plusieurs stratégies couramment utilisées sont utilisées pour entraîner nos modèles, telles que Back Translation, Ensemble Knowledge Distillation, etc. Nous menons également des expériences avec une augmentation du langage similaire, qui conduit à des résultats positifs, bien que non utilisées dans notre soumission. Notre soumission obtient des résultats remarquables lors de l'évaluation finale.", 'ja': '本稿では、WMT 2020ニュース翻訳共有タスクにおける私たちの仕事を紹介します。私たちは、Zh/En、Km/En、Ps/Enを含む3つの言語ペアに参加し、制約条件下で両方向に参加します。標準のTransformer - Bigモデルをベースラインとして使用し、より大きなパラメータサイズを持つ2つのバリアントを介して最高のパフォーマンスを得ます。私たちは、提供された大規模なバイリンガルおよびモノリンガルデータセットで詳細な前処理およびフィルタリングを実行します。バック翻訳、アンサンブルナレッジディスティレーションなど、当社のモデルをトレーニングするために、いくつかの一般的に使用される戦略が使用されています。また、同様の言語拡張の実験も行っており、提出物には使用されていませんが、肯定的な結果につながります。当社の提出物は、最終評価で目覚ましい結果を得ています。', 'hi': 'यह पेपर WMT 2020 समाचार अनुवाद साझा कार्य में हमारे काम को प्रस्तुत करता है। हम Zh / En, Km / En, और Ps / En सहित 3 भाषा जोड़े में भाग लेते हैं और विवश स्थिति के तहत दोनों दिशाओं में भाग लेते हैं। हम आधार रेखा के रूप में मानक ट्रांसफॉर्मर-बिग मॉडल का उपयोग करते हैं और बड़े पैरामीटर आकार के साथ दो संस्करणों के माध्यम से सबसे अच्छा प्रदर्शन प्राप्त करते हैं। हम प्रदान किए गए बड़े पैमाने पर द्विभाषी और मोनोलिंगुअल डेटासेट पर विस्तृत पूर्व-प्रसंस्करण और फ़िल्टरिंग करते हैं। कई आमतौर पर इस्तेमाल की जाने वाली रणनीतियों का उपयोग हमारे मॉडल को प्रशिक्षित करने के लिए किया जाता है जैसे कि बैक ट्रांसलेशन, एनसेम्बल नॉलेज आसवन, आदि। हम समान भाषा वृद्धि के साथ भी प्रयोग करते हैं, जो सकारात्मक परिणामों की ओर ले जाता है, हालांकि हमारे सबमिशन में उपयोग नहीं किया जाता है। हमारा सबमिशन अंतिम मूल्यांकन में उल्लेखनीय परिणाम प्राप्त करता है।', 'zh': '本文引WMT 2020新闻译共其事。 参3种语,包Zh / EnKm / EnPs / En,并在约束条件下两向上。 吾用度之 Transformer-Big ,以两大参数大小变体获得最佳性。 臣等大双语单语数集行详预处理漉。 有数常用之策以练吾模样,如回溯译集成提炼等。 语言增实验,实验生积极,虽在吾言而不用。 我们的提交终于评中得了显着。', 'ru': 'В этой статье представлена наша работа по общей задаче «Перевод новостей WMT 2020». Мы участвуем в 3 языковых парах, включая Zh/En, Km/En и Ps/En, и в обоих направлениях при ограниченном условии. Мы используем стандартную модель Transformer-Big в качестве базовой линии и получаем наилучшую производительность с помощью двух вариантов с большими размерами параметров. Мы выполняем детальную предварительную обработку и фильтрацию на предоставленном крупномасштабном двуязычном и одноязычном наборе данных. Несколько широко используемых стратегий используются для обучения наших моделей, таких как Back Translation, Ensemble Knowledge Distillation и т.д. Мы также проводим эксперимент с аналогичным языковым дополнением, которое приводит к положительным результатам, хотя и не используется в нашем представлении. Наше представление получает замечательные результаты в окончательной оценке.', 'ga': 'Cuireann an páipéar seo i láthair ár gcuid oibre i dTasc Comhroinnte Aistriúchán Nuachta WMT 2020. Glacaimid páirt i 3 phéire teanga lena n-áirítear Zh/E, Km/E, agus Ps/E agus sa dá threo faoin gcoinníoll srianta. Bainimid úsáid as an múnla caighdeánach Trasfhoirmeoir-Mór mar bhonnlíne agus faighimid an fheidhmíocht is fearr trí dhá leagan le méideanna paraiméadar níos mó. Déanaimid réamhphróiseáil agus scagadh mionsonraithe ar an tacar sonraí dátheangach agus aonteangach ar scála mór a chuirtear ar fáil. Baintear úsáid as go leor straitéisí a úsáidtear go coitianta chun ár múnlaí a oiliúint, mar shampla Aistriú Ar Ais, Driogadh Eolais Ensemble, srl. Déanaimid turgnamh freisin ar mhéadú teanga cosúil leis, as a dtagann torthaí dearfacha, cé nach n-úsáidtear é inár n-aighneacht. Tá torthaí suntasacha ar ár n-aighneacht sa mheastóireacht deiridh.', 'ka': 'ეს წიგნი ჩვენი სამუშაო WMT 2020 წიგნის თავისუფალი სამუშაო სამუშაო. ჩვენ სამუშაობით ენის ზოგში, სამუშაობით Zh/En, Km/En, Ps/En, და ორივე მხარდაჭერებში დავწყებთ ზოგჯერებული სურათში. ჩვენ გამოვიყენებთ სტანდარტრანსტრუმენტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრი-დიდ მოდელს ჩვენ გავაკეთებთ განსაზღვრებული მეორე ენგური და მონოლენგური მონაცემების კონფილურაციაზე. ბევრი საერთოდ გამოყენებული სტრატიგიები გამოიყენება ჩვენი მოდელების გარგება, როგორც Back Translation, Ensemble Knowledge Distillation, ანუ. ჩვენ ასევე ექსპერიმენტი გავაკეთებთ სხვადასხვა ენის augmentation, რომელიც მიიღება პოტიფიკაცი ჩვენი წარმოდგენება მიიღება შესანიშვნელოვანი წარმოდგენება საკუთარი оценებაში.', 'hu': 'Ez a tanulmány bemutatja a WMT 2020 News Translation Shared Task munkáját. 3 nyelvpárban veszünk részt, köztük Zh/En, Km/En és Ps/En, valamint mindkét irányban korlátozott feltételek mellett. Alapként a szabványos Transformer-Big modellt használjuk, és két nagyobb paraméterméretű változattal érjük el a legjobb teljesítményt. Részletes előfeldolgozást és szűrést végezünk a rendelkezésre álló nagyméretű kétnyelvű és egynyelvű adatkészleten. Több gyakran használt stratégiát használunk modelleink képzésére, mint például a Visszafordítás, az Ensemble Knowledge Distillation stb. Hasonló nyelvi kiterjesztéssel is kísérletezünk, ami pozitív eredményekhez vezet, bár nem használjuk a benyújtásunkat. Jelentkezésünk figyelemre méltó eredményeket ér el a végső értékelés során.', 'el': 'Η παρούσα εργασία παρουσιάζει το έργο μας στο πλαίσιο της κοινής εργασίας μετάφρασης ειδήσεων WMT 2020. Συμμετέχουμε σε τρία γλωσσικά ζεύγη συμπεριλαμβανομένων των Ζ/Εν, Χμ/Εν, και Πς/Εν και στις δύο κατευθύνσεις υπό την περιορισμένη συνθήκη. Χρησιμοποιούμε το πρότυπο μοντέλο ως βάση και επιτυγχάνουμε την καλύτερη απόδοση μέσω δύο παραλλαγών με μεγαλύτερα μεγέθη παραμέτρων. Πραγματοποιούμε λεπτομερή προεπεξεργασία και φιλτράρισμα στο παρεχόμενο δίγλωσσο και μονόγλωσσο σύνολο δεδομένων μεγάλης κλίμακας. Αρκετές κοινές στρατηγικές χρησιμοποιούνται για την εκπαίδευση των μοντέλων μας όπως η Πίσω Μετάφραση, η Αποστολή Γνώσης του συνόλου κ.λπ. Επίσης διεξάγουμε πειράματα με παρόμοια αύξηση της γλώσσας, τα οποία οδηγούν σε θετικά αποτελέσματα, αν και δεν χρησιμοποιούνται στην υποβολή μας. Η υποβολή μας επιτυγχάνει αξιοσημείωτα αποτελέσματα στην τελική αξιολόγηση.', 'it': 'Questo articolo presenta il nostro lavoro nel WMT 2020 News Translation Shared Task. Partecipiamo a 3 coppie linguistiche tra cui Zh/En, Km/En e Ps/En e in entrambe le direzioni sotto la condizione vincolata. Usiamo il modello standard Transformer-Big come base e otteniamo le migliori prestazioni tramite due varianti con dimensioni di parametri più grandi. Eseguiamo pre-elaborazione e filtraggio dettagliati sul set di dati bilingue e monolingue fornito su larga scala. Diverse strategie comunemente utilizzate sono utilizzate per formare i nostri modelli come Back Translation, Ensemble Knowledge Distillation, ecc. Conduciamo anche esperimenti con aumento del linguaggio simile, che portano a risultati positivi, anche se non utilizzati nella nostra presentazione. La nostra presentazione ottiene risultati notevoli nella valutazione finale.', 'kk': 'Бұл қағаз WMT 2020 жаңалық аудармаларды ортақ тапсырманың жұмысын көрсетеді. Біз Ж/Ен, Км/Ен, П/Ен және Ен және шектелген шарттың екі бағыттарына қатынасыз. Біз стандартты түрлендіруші үлкен үлгісін негізгі жол ретінде қолданып, екі вариант арқылы үлкен параметрлердің өлшемі арқылы ең жақсы әрекеттерді аламыз. Келтірілген үлкен тілдер мен монолингі деректер жиынында егжей- тегжейлі өңдеу және сүзгілеу жасадық. Көп қолданылатын стратегиялар біздің үлгілерімізді, мысалы Back Translation, Ensemble Knowledge Distillation және т.б. үлгілерімізді оқыту үшін қолданылады. Біз сондай-ақ ұқсас тілді жақсарту тәжірибелерімізді жасаймыз, біра Біздің келтіріміздің соңғы оқиғаларының белгілі нәтижесін алады.', 'lt': 'Šiame dokumente pristatomas mūsų darbas bendroje WMT 2020 naujienų vertimo užduotyje. Mes dalyvaujame 3 kalbų porose, įskaitant Zh/En, Km/En ir P/En ir abiejose kryptimis ribotos sąlygos. Mes naudojame standartinį „Transformer-Big“ model į kaip pradinį tašką ir gauname geriausius rezultatus naudojant du variantus su didesniais parametrų dydžiais. Atliekame išsamų išankstinį apdorojimą ir filtravimą pateiktame didelio masto dvikalbių ir vienakalbių duomenų rinkinyje. Kelios paprastai naudojamos strategijos naudojamos mokymui mūsų modeliams, pavyzdžiui, grįžtamojo vertimo, Ensemble Knowledge Distillation ir t. t. Taip pat atliekame eksperimentą su panašiu kalbos didinimu, kuris duoda teigiamų rezultatų, nors ir nenaudojamas mūsų pranešime. Mūsų pateiktame galutiniame vertinime gaunami nepaprasti rezultatai.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ ജോലിയെ WMT 2020 വിവരങ്ങള്\u200d പരിഭാഷപ്പെടുത്തുന്നത് പങ്കുചേര്\u200dത്ത പണിയിലാണ്. We participate in 3 language pairs including Zh/En, Km/En, and Ps/En and in both directions under the constrained condition.  നമ്മള്\u200d സാധാരണ ട്രാന്\u200dസ്റ്റര്\u200dഫോര്\u200dമാര്\u200d ബിഗ് മോഡല്\u200d ഉപയോഗിക്കുന്നത് ബെസ്റ്റ് ലൈന്\u200d ആയിരിക്കുകയും, ഏറ്റവും വലിയ അളവുകളു നമ്മള്\u200d വിശദീകരിക്കുന്നത് മുന്\u200dപ് പ്രവര്\u200dത്തിപ്പിക്കുന്നതിന്\u200dറെയും ഫില്\u200dറ്റര്\u200d ചെയ്യുന്നു. വലിയ ഭാഷക്കും മോ സാധാരണ ഉപയോഗിക്കപ്പെട്ട പല ക്രമങ്ങള്\u200d ഞങ്ങളുടെ മോഡലുകളെ പഠിപ്പിക്കാന്\u200d ഉപയോഗിക്കുന്നു. ബാക്ക് പരിഭാഷയിലെ പരിശീലനത്തിന് പോലെയുള്ള പരീക്ഷണങ്ങള്\u200d ഞങ്ങള്\u200d  നമ്മുടെ കീഴ്പ്പെടുത്തുന്നത് അവസാനത്തെ പരിശോധനത്തിന്റെ ഫലങ്ങളാണ്.', 'mt': 'Dan id-dokument jippreżenta x-xogħol tagħna fil-Kompitu Konġunt tat-Traduzzjoni tal-Aħbarijiet tal-WMT 2020. Nipparteċipaw fi tliet pari lingwistiċi inklużi Zh/En, Km/En, u Ps/En u fiż-żewġ direzzjonijiet taħt il-kundizzjoni ristretta. Aħna nużaw il-mudell standard Transformer-Big bħala l-linja bażi u niksbu l-aħjar prestazzjoni permezz ta’ żewġ varjanti b’daqsijiet akbar ta’ parametri. We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual dataset.  Diversi strateġiji użati b’mod komuni jintużaw biex jitħarrġu l-mudelli tagħna bħat-Traduzzjoni ta’ wara, id-Distillazzjoni ta’ l-Għarfien Ensemble, eċċ. Inwettqu wkoll esperimenti b’żieda simili fil-lingwa, li twassal għal riżultati pożittivi, għalkemm mhux użati fis-sottomissjoni tagħna. Is-sottomissjoni tagħna tikseb riżultati notevoli fl-evalwazzjoni finali.', 'mn': 'Энэ цаас WMT 2020 News Translation Shared Task-д бидний ажил илтгэдэг. Бид Ж/Эн, Км/Эн, Пс/Эн хоёр хэл хоёр талд холбоотой байдаг. Бид стандарт Трансформер-Биг загварыг суурь шугам гэж ашиглаж, 2 хувилбараас хамгийн сайн үйл ажиллагааг илүү том параметр хэмжээтэй авна. Бид маш их хэмжээтэй хоёр хэл болон ганц хэл өгөгдлийн суурь дээр шинжлэх ухаан болон фильтр хийдэг. Ихэнх олон хэрэглэгддэг стратеги нь Back Translation, Ensemble Knowledge Distillation, т.д. бидний загваруудыг суралцахын тулд хэрэглэгддэг. Мөн адилхан хэл нэмэгдүүлэх туршилттай туршилт хийдэг. Энэ нь эерэг үр дүнд хүргэх боломжтой. Бидний хүлээн зөвшөөрөл сүүлийн үнэлгээнд гайхалтай үр дүнг авдаг.', 'no': 'Denne papiret viser arbeidet vårt i delt oppgåve for WMT 2020- omsetjing. Vi deltar i tre språkport, inkludert Zh/En, Km/En, og Ps/En, og i begge retningar under begrenset tilstand. Vi bruker standard transformeringsmodellen som baselinja og får den beste utviklinga via to variantar med større parameter-storleik. Vi utfører detaljerte førehandsaming og filtrering på den tilgjengelege største bilingueldatasettet og monospråk. Mange vanleg brukte strategiar vert brukte til å trenja modelane våre, som tilbakeomsetjing, forstyring av kjennomsetjing osv. Vi gjer også eksperiment med liknande språk-augmentasjon, som fører til positiv resultat, men ikkje brukt i søknaden våre. Søket vårt får merkelige resultat i den siste evalueringa.', 'pl': 'Niniejszy artykuł prezentuje naszą pracę w ramach WMT 2020 News Translation Shared Task. Uczestniczymy w trzech parach językowych, w tym Zh/En, Km/En i Ps/En oraz w obu kierunkach w warunkach ograniczonych. Wykorzystujemy standardowy model Transformer-Big jako bazę podstawową i uzyskujemy najlepszą wydajność dzięki dwóm wariantom o większych rozmiarach parametrów. Wykonujemy szczegółowe wstępne przetwarzanie i filtrowanie na dostarczonym dużym zbiorze danych dwujęzycznych i jednojęzycznych. Do szkolenia naszych modeli stosowane są kilka powszechnie stosowanych strategii, takich jak tłumaczenie wsteczne, destylacja wiedzy zespołowej itp. Przeprowadzamy również eksperymenty z podobną powiększeniem języka, co prowadzi do pozytywnych wyników, choć nie wykorzystywane w naszym zgłoszeniu. Nasze zgłoszenie uzyskuje niezwykłe wyniki w ocenie końcowej.', 'mk': 'Овој весник ја претставува нашата работа во Делената задача за преведување на вестите на ВМТ 2020. We participate in 3 language pairs including Zh/En, Km/En, and Ps/En and in both directions under the constrained condition.  Го користиме стандардниот Трансформер-Голем модел како основа и ја добиваме најдобрата перформанса преку два варијанти со поголеми големини на параметри. Ние спроведуваме детално преобработување и филтрирање на обезбедените големи двојјазични и монојазични податоци. Неколку често употребени стратегии се користат за обука на нашите модели, како што е Back Translation, Ensemble Knowledge Distillation итн. Ние исто така спроведуваме експеримент со слични јазични зголемувања, кои водат до позитивни резултати, иако не се користат во нашето поднесување. Our submission obtains remarkable results in the final evaluation.', 'sr': 'Ovaj papir predstavlja naš rad u podjelnom zadatku za prevod novina WMT 2020. U tri jezička parova uključujući Zh/En, Km/En, i Ps/En i u oba smjera pod ograničenim stanjem. Koristimo standardni model transformera-Velikog kao početnu liniju i dobijamo najbolju izvedbu putem dva varianta sa većim veličinama parametara. Izvodimo detaljne predobrađivanje i filtriranje na pruženoj velikoj dvojezičkoj i monojezičkoj seti podataka. Nekoliko često korištenih strategija se koristi za obuku naših modela kao što su Back Translation, Ensemble Knowledge Distillation, itd. Takođe provodimo eksperiment sa sličnim jezikom povećanjem, koji vodi do pozitivnih rezultata, iako se ne koristi u našoj podnožji. Naša podnošenja dobija izvanredne rezultate u konačnoj procjeni.', 'ro': 'Această lucrare prezintă activitatea noastră în cadrul WMT 2020 News Translation Shared Task. Participăm la 3 perechi de limbi, inclusiv Zh/En, Km/En și Ps/En și în ambele direcții în condiția constrânsă. Folosim modelul standard Transformer-Big ca bază și obținem cea mai bună performanță prin intermediul a două variante cu dimensiuni mai mari ale parametrilor. Efectuăm prelucrarea și filtrarea detaliată a setului de date bilingve și monolingve furnizat la scară largă. Mai multe strategii utilizate în mod obișnuit sunt folosite pentru a instrui modelele noastre, cum ar fi traducerea spatelui, distilarea cunoștințelor ansamblului etc. De asemenea, efectuăm experimente cu augmentarea limbajului similar, care duc la rezultate pozitive, deși nu sunt utilizate în depunerea noastră. Trimiterea noastră obține rezultate remarcabile în evaluarea finală.', 'ms': 'Kertas ini memperkenalkan kerja kita dalam Tugas Berkongsi Penerjemahan Berita WMT 2020. We participate in 3 language pairs including Zh/En, Km/En, and Ps/En and in both directions under the constrained condition.  Kami menggunakan model Transformer-Big piawai sebagai as as dan mendapatkan prestasi terbaik melalui dua varian dengan saiz parameter yang lebih besar. Kami melakukan pemprosesan dan penapisan terperinci pada set data bilingual dan monobahasa yang diberikan pada skala besar. Beberapa strategi yang biasa digunakan untuk melatih model kita seperti Back Translation, Ensemble Knowledge Distillation, dll. Kami juga melakukan eksperimen dengan peningkatan bahasa yang sama, yang membawa kepada keputusan positif, walaupun tidak digunakan dalam penyerahan kami. Pemberian kami mendapat keputusan yang luar biasa dalam penilaian akhir.', 'so': "Kanu waa warqaddayada shaqadeeda ku qoran WMT 2020 News Translation Shaqada la Sharciyey. Waxaynu ka qeybqaadannaa saddex noocyo oo af ku qoran Zh/En, Km/En, Ps/En iyo labada kooxood oo ka hooseeya xaaladda qasabka ah. Tusaale ahaan u isticmaalnaa asalka ugu danbeedka ah ee ugu horeeya, waxaana helaynaa tababarka ugu wanaagsanaan labada kala duduwan oo ay leeyihiin tirada tirada waaweyn. Waxaannu sameynaa baaraandegista hore iyo baaritaanka lagu qoray labada luuqadood oo kala duduwan iyo labada luuqadood oo kala duduwan. Shaqooyin badan oo caadiga ah waxaa loo isticmaalaa in loo tababariyo tusaale ahaan turjumista dib-u-dhigista, cilmiga la'aanta, tusaale ahaan baaritaanka lagu kordhiyo afka la mid ah, taasoo sababtaa resulto positive ah, inkastoo aysan ku isticmaalin dhiirigayada. Our submission obtains remarkable results in the final evaluation.", 'sv': 'Denna uppsats presenterar vårt arbete i WMT 2020 News Translation Shared Task. Vi deltar i 3 språkpar inklusive Zh/En, Km/En och Ps/En och i båda riktningarna under det begränsade villkoret. Vi använder standardmodellen Transformer-Big som baslinje och får bästa prestanda via två varianter med större parameterstorlekar. Vi utför detaljerad förbehandling och filtrering på den storskaliga tvåspråkiga och enspråkiga datauppsättningen. Flera vanliga strategier används för att träna våra modeller såsom Back Translation, Ensemble Knowledge Distillation, etc. Vi genomför också experiment med liknande språkförstärkning, vilket leder till positiva resultat, även om de inte används i vårt bidrag. Vårt bidrag får anmärkningsvärda resultat i den slutliga utvärderingen.', 'ta': 'WMT 2020 செய்தி மொழிபெயர்ப்பு பகிர்ந்த பணியில் எங்கள் வேலையை இந்த காகிதத்தை கூறுகிறது. நாம் Zh/En, Km/En, மற்றும் Ps/En மற்றும் கட்டுப்படுத்தப்பட்ட நிலையின் கீழ் இரு திசையில் 3 மொழி ஜோடிகளை பங்கிடுகிற நாம் நிலையான மாற்றம் பெரிய மாதிரியை அடிப்படைக்கோட்டாக பயன்படுத்தி இரண்டு மாறிகள் மூலம் பெரிய அளவுரு அளவு நாங்கள் வழங்கப்பட்ட பெரிய அளவு இரு மொழி மற்றும் மொன்மொழி தகவல் அமைப்பில் விவரமான முன் செயல்படுத்தல் மற்றும் வடிகட் பின் மொழிபெயர்ப்பு, அறிவிப்பு திருப்பங்கள் மாதிரிகளை பயிற்சி செய்ய பல பொதுவாக பயன்படுத்தப்பட்ட திட்டங்களுக்கு பயன்படுத்தப்படுகிறது. இது போன்ற மொழியின் ம நம்முடைய சரணங்கள் மிகவும் அற்புதமான முடிவுகள் இறுதியாக ஆராய்ச்சியில் கிடைக்கும்.', 'si': 'මේ පත්තේ WMT 2020යි වාර්තාව වාර්තාව සමාගත වැඩක් තියෙනවා. අපි භාෂාව තුනක් දෙන්නේ ජී/එන්, Km/එන්, Ps/එන් එක්ක සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණය කරන්නේ. අපි ප්\u200dරමාණය වික්\u200dරමාණකය- ලොකු මොඩල් විදියට ප්\u200dරයෝජනය කරනවා මුළු ප්\u200dරමාණයක් විදියට හොඳම ප්\u200dරමාණයක් ද අපි ප්\u200dරශ්නයක් කලින් ප්\u200dරක්\u200dරියාස කරන්න සහ ප්\u200dරශ්නයක් කරන්න පුළුවන් විශාල භාෂාවක් සහ එක භාෂාවක සාමාන්\u200dයයෙන් භාවිත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dත විද්\u200dය අපේ පිළිගන්න පුළුවන් අන්තිම අවශ්\u200dය විශ්වාසයේ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් ලැබෙනවා.', 'ur': 'یہ کاغذ WMT 2020 News Translation Shared Task میں ہمارا کام پیش کرتا ہے. ہم تین زبان جوڑوں میں شامل ہوتے ہیں جی/ان، کیم/ان، اور پی/ان اور دونوں طریقوں میں محدودہ شرط کے اندر. ہم نے استاندارڈ ٹرنفسر-بزرگ موڈل کو بنیس لین کے طور پر استعمال کیا ہے اور دو فرینٹوں کے ذریعہ بہترین پاراینٹ اندازے کے ساتھ بہترین پاراینٹ فائدہ حاصل کیا ہے ہم پیش پردازی اور فیلترینگ کررہے ہیں جو بڑی اسکیل دو زبان اور ایک زبان ڈاٹ سٹ پر ہے. بہت سی استراتژی استعمال کیے جاتے ہیں کہ ہمارے موڈل کی تعلیم کریں جیسے Back Translation, Ensemble Knowledge Distillation، اور اگلے. ہم نے بھی ایسی زبان افزایش کے ساتھ آزمائش کریں جو مثبت نتیجے کو پہنچاتے ہیں، اگرچہ ہماری اطاعت میں استعمال نہیں کیا جاتا۔ ہمارے مسلمانوں کو آخری امتحان میں اچھا نتیجہ ملتا ہے۔', 'uz': "Bu qogʻoz WMT 2020 News tarjima qilingan vazifani ishga tayyorlaydi. Biz 3 tillar qo'llangan Zh/En, Km/En, Ps/En va qattiq holatda ikkita yordamga murojaat qilamiz. Biz Andoza Transfer- Big modeli asosiy satri sifatida foydalanamiz va ikkita variant katta parametr oʻlchami bilan eng yaxshi natijasini olib tashlamiz. Biz juda katta ko'p tillar va monolingan maʼlumotlar tarkibini bajaramiz. Ko'p qancha ishlatilgan strategiyalar esa bizning modellarimizni o'rganish uchun foydalanadi, Orqaga tarjima qilish, ta'lim tahrirlash va o'xshash tillarni oshirish mumkin. Bu natijaga ishlatilmagan bo'lsa ham yaxshi natijaga ega bo'ladi. Our submission obtains remarkable results in the final evaluation.", 'vi': 'Tờ giấy này trình bày công việc của chúng ta trong Công việc chia sẻ WM 2020. Chúng tôi tham gia các cặp ngôn ngữ ba gồm Zhang/En, Km/En, và Ps/En và cả hai hướng dưới sự hạn chế. Chúng tôi sử dụng mô hình biến hình transformer-Big làm đường cơ bản và đạt được hiệu suất tốt nhất qua hai biến thể với kích cỡ Tham số lớn hơn. Chúng tôi xử lý và lọc chi tiết trên bộ dữ liệu hai ngôn ngữ và chung ngôn ngữ được cung cấp. Một số chiến lược thường được dùng để huấn luyện các mô hình của chúng tôi như Back Translation, Ensemble Knowledge Desellation, v. Chúng tôi cũng thực hiện thí nghiệm với phát triển ngôn ngữ tương tự, dẫn đến kết quả tích cực, mặc dù không được dùng trong việc cung cấp. Việc đệ trình của chúng tôi đạt được kết quả đáng chú ý.', 'nl': 'Dit artikel presenteert ons werk in de WMT 2020 News Translation Shared Task. We nemen deel aan 3-taalparen waaronder Zh/En, Km/En, en Ps/En en in beide richtingen onder de beperkte voorwaarde. We gebruiken het standaard Transformer-Big model als uitgangspunt en verkrijgen de beste prestaties via twee varianten met grotere parametergroottes. We voeren gedetailleerde voorbewerking en filtering uit op de verstrekte grootschalige tweetalige en eentalige dataset. Verschillende veelgebruikte strategieën worden gebruikt om onze modellen te trainen, zoals Back Translation, Ensemble Knowledge Distillation, enz. We voeren ook experimenten uit met vergelijkbare taalvergroting, die leiden tot positieve resultaten, hoewel niet gebruikt in onze inzending. Onze inzending behaalt opmerkelijke resultaten in de eindbeoordeling.', 'bg': 'Настоящата статия представя нашата работа по споделената задача за превод на новини. Участваме в 3 езикови двойки, включително Ж/Ен, Км/Ен и Пс/Ен и в двете посоки при ограничени условия. Използваме стандартния модел и получаваме най-добра производителност чрез два варианта с по-големи размери параметри. Извършваме подробна предварителна обработка и филтриране на предоставения мащабен двуезичен и едноезичен набор от данни. Няколко често използвани стратегии се използват за обучение на нашите модели като Обратен превод, Ансамбъл Дестилация на знанието и др. Също така провеждаме експерименти с подобна езикова уголемяване, което води до положителни резултати, въпреки че не се използва в нашите предложения. Нашите предложения получават забележителни резултати в окончателната оценка.', 'da': 'Denne artikel præsenterer vores arbejde i WMT 2020 News Translation Shared Task. Vi deltager i 3 sprogpar herunder Zh/En, Km/En og Ps/En og i begge retninger under begrænset betingelse. Vi bruger standard Transformer-Big modellen som baseline og opnår den bedste ydeevne via to varianter med større parameterstørrelser. Vi udfører detaljeret forbearbejdning og filtrering på det leverede storstilede tosprogede og ensprogede datasæt. Flere almindeligt anvendte strategier bruges til at træne vores modeller såsom Back Translation, Ensemble Knowledge Distillation osv. Vi udfører også eksperimenter med lignende sprogforøgelse, hvilket fører til positive resultater, selvom de ikke bruges i vores indsendelse. Vores indsendelse opnår bemærkelsesværdige resultater i den endelige evaluering.', 'hr': 'Ovaj papir predstavlja naš rad u zajedničkom zadatku za prevod vijesti WMT 2020. Učestvujemo u tri jezičke parove uključujući Zh/En, Km/En, i Ps/En i u oba smjera pod ograničenim stanjem. Koristimo standardni model transformera-Velikog kao početnu liniju i dobijamo najbolju učinku putem dvije variante s većim veličinama parametara. Izvršili smo detaljne predobrađivanje i filtriranje na pruženoj velikoj dvojezičkoj i monojezičkoj seti podataka. Nekoliko često korišćenih strategija se koristi za obuku naših modela kao što su Back Translation, Ensemble Knowledge Distillation, itd. Također provodimo eksperiment s sličnim jezičkim povećanjem, što vodi do pozitivnih rezultata, iako se ne koristi u našoj podnožbi. Naša podnošenja dobiva izvanredne rezultate u konačnoj procjeni.', 'de': 'Dieses Papier stellt unsere Arbeit im Rahmen der WMT 2020 News Translation Shared Task vor. Wir nehmen an 3-Sprachpaaren teil, einschließlich Zh/En, Km/En und Ps/En und in beide Richtungen unter der eingeschränkten Bedingung. Wir verwenden das Standard-Transformer-Big-Modell als Basis und erzielen die beste Leistung über zwei Varianten mit größeren Parametergrößen. Wir führen eine detaillierte Vorverarbeitung und Filterung des bereitgestellten zweisprachigen und einsprachigen Datensatzes durch. Einige häufig verwendete Strategien werden verwendet, um unsere Modelle zu trainieren, wie Back Translation, Ensemble Knowledge Distillation, etc. Wir führen auch Experimente mit ähnlichen Spracherweiterungen durch, die zu positiven Ergebnissen führen, wenn auch nicht in unserer Einreichung verwendet. Unsere Einreichung erzielt bemerkenswerte Ergebnisse in der abschließenden Bewertung.', 'id': 'This paper presents our work in the WMT 2020 News Translation Shared Task.  Kami berpartisipasi dalam 3 pasangan bahasa termasuk Zh/En, Km/En, dan P/En dan dalam kedua arah di bawah kondisi terbatas. Kami menggunakan model Transformer-Big standar sebagai dasar dasar dan mendapatkan prestasi terbaik melalui dua varian dengan ukuran parameter yang lebih besar. We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual dataset.  Beberapa strategi yang biasa digunakan untuk melatih model kita seperti Back Translation, Ensemble Knowledge Distillation, dll. Kami juga melakukan eksperimen dengan peningkatan bahasa yang sama, yang membawa ke hasil positif, meskipun tidak digunakan dalam penyerahan kami. Pengiriman kami mendapatkan hasil yang luar biasa dalam evaluasi akhir.', 'ko': '본고는 우리가 WMT 2020 뉴스 번역 공유 임무에서의 업무를 소개한다.제약조건 하에서 우리는 두 방향에서 Zh/En, Km/En, Ps/En을 포함한 세 쌍의 언어에 참여했다.우리는 표준 변압기 대형 모델을 기선으로 삼아 두 개의 파라미터가 비교적 큰 변수를 통해 최상의 성능을 얻는다.우리는 제공된 대규모 이중 언어와 단어 데이터 집합에 대해 상세한 사전 처리와 필터를 진행했다.우리는 번역, 통합 지식 추출 등 몇 가지 자주 사용하는 전략을 사용하여 우리의 모델을 훈련시켰다. 우리는 유사한 언어 강화를 사용하여 실험을 진행했다. 비록 우리의 제출에서 사용되지는 않았지만 긍정적인 결과를 얻었다.우리가 제출한 자료는 최종 평가에서 현저한 결과를 얻었다.', 'fa': 'این کاغذ کار ما را در ترجمه خبری WMT 2020 نشان می دهد. ما در سه جفت زبان شامل Zh/En, Km/En و Ps/En و در هر دو مسیر زیر شرایط محدودیت شرکت می کنیم. ما از مدل تغییر\u200cپذیر استاندارد-بزرگ به عنوان خط پایین استفاده می\u200cکنیم و بهترین فعالیت را با اندازه\u200cهای پارامتر بزرگتر از طریق دو متفاوت دریافت می\u200cکنیم. ما در مجموعه داده\u200cهای دو زبان و یک زبان بزرگ پیش\u200cپردازی و فیلتر کردن جزئیات را انجام می\u200cدهیم. تعدادی استراتژی که معمولاً استفاده می\u200cشود برای آموزش مدل\u200cهایمان مانند ترجمه\u200cهای عقب، تغییر دانش پذیر و غیر از آن استفاده می\u200cشود. ما همچنین آزمایش\u200cهای مشابه با افزایش زبان مشابه انجام می\u200cدهیم، که به نتیجه مثبت می\u200cرسد، اگر تحويل ما نتايج فوق العاده اي در ارزيابي نهايي پيدا ميکنه', 'tr': 'Bu häzir WMT 2020 Haýsy Çeviri Beýleki Görevlerde biziň işimizi görkezýär. Biz 3 dil çift bolup Zh/En, Km/En, we Ps/En we her iki tarafta mümkin däldir. Biz standart Transformer-Büyük modelini baseline olarak kullanarak we iki çarpyşyň ön belleneni büyük parametrer ölçüsi bilen elimizden gelen şekilde ulaşarak. Biz uly ölçekli iki dilli we monodilli veri setirinde detaylar öňe işleýän we süýşirdik. Birnäçe köplenç ulanylýan strategiýalarymyz, arka terjime, Ensemble Bilim Distillation ýaly nusgalarymyzy öwretmek üçin ullanylýar. Biz hem meňzeş dil ýetişdirmegi bilen experimenta çykarýarys. Bu nusgalary pozitif netijelere gidýär, ýöne teslim etmäge ulanylmadyk. Biziň gönüşümiz soňky çykyşymyzda örän möhüm netijeleri bolup biler.', 'sw': 'This paper presents our work in the WMT 2020 News Translation Shared Task.  Tunashiriki katika maziwa matatu ya lugha ikiwa ni pamoja na Zh/En, Km/En, na Ps/En na katika maelekezo yote chini ya hali ya kulazimika. Tunatumia mtindo wa kawaida wa Transfer-Big kama msingi wa msingi na kupata ufanisi bora kwa kupitia tofauti mbili zenye ukubwa wa kipimo. Tunafanya taarifa zilizotolewa kwa lugha mbili na lugha za kiumbe. Mipango kadhaa iliyotumika kawaida inatumika kufundisha mifano yetu kama vile Tafsiri ya Uhambuzi, Utafiti wa Maghama, etc. Pia tunafanya majaribio yanayofanana na kuongezeka kwa lugha kama hizo, ambayo yanasababisha matokeo chanya, ingawa hatujatumika katika ujumbe wetu. Ujumbe wetu unapata matokeo mazuri ya uchambuzi wa mwisho.', 'af': 'Hierdie papier stel ons werk in die WMT 2020 Nuusvertaling Gedeelde Taak voor. Ons deel in 3 taal paar insluitend Zh/En, Km/En en Ps/En en in beide rigtings onder die beperkte voorwaardes. Ons gebruik die standaard Transformer- Big model as die basislien en kry die beste prestasie deur twee variante met groter parameter grootte. Ons uitvoer gedetaliseerde voorafverandering en filtering op die verskaf groot- skaal twee- tale en monolinglike datastel. Verskeie gewoonlik gebruikte strategies word gebruik om ons modele te oefen soos Back Translation, Ensemble Knowledge Distillation, etc. Ons doen ook eksperiment met gelyke taal augmentasie, wat lei na positiewe resultate, alhoewel nie gebruik word in ons onderwerp nie. Ons ondersteuning kry betekende resultate in die eindelike evaluering.', 'am': 'ይህ ገጽ በWMT 2020 ዜናዎች ትርጓሜያችን የተለየ ስራዎችን ያሳያል፡፡ Zh/En፣ ኪም/ዓይን እና Ps/ዓይን እና ከግድ ሀብት በታች በ3 ቋንቋዎች ሁለት ሁለት ዓይነቶች እናጋራለን፡፡ የተመሳሳይ ትልቁ ዓይነት እናስቀምጣለን፡፡ የደረጃ ቋንቋ እና የሞሎልቋል ዳታዎችን በመጠቀም ላይ የተዘረዘ የፊደል ጉዳይ እና አጣራ እናደርጋለን፡፡ በርካታ የተጠቀሙት ስርዓት ምሳሌዎቻችንን እንደ ጀርባ ትርጓሜ፣ እውቀት መግለጫ እና እናስተምር ዘንድ ይጠቀማሉ። በተለያዩ ቋንቋዎች አካባቢ እናደርጋለን፡፡ የፍጻሜው ውጤት አግኝቷል፡፡', 'az': 'Bu kağıt WMT 2020 Haqq Çeviri paylaşdırılmış iş işimizi göstərir. Biz Zh/En, Km/En, Ps/En və hər iki tərəfdə müəyyən bir şəkildə 3 dil çift katılırıq. Biz standart Transformer-Big modelini temel çizgi olaraq istifadə edirik və ən yaxşı performansı iki dəyişiklik vasitəsilə daha böyük parametr ölçüləri ilə alırıq. Biz böyük-ölçülü iki dil və monodil veri quruluğunda detaylı ön işləmə və filtrləmə işlədik. Bizim modellərimizi Back Translation, Ensemble Knowledge Distillation, etc. kimi təhsil etmək üçün təhsil edilən çox sınaqlar istifadə edilir. Biz də eyni dil yükselməsi ilə təhsil edirik, bu da pozitif sonuçları olar, amma müsəlmanlarımızda istifadə edilməmişdir. Bizim müsəlmanımız sonuncu değerlendirməkdə möhtərəm nəticələr alır.', 'hy': 'Այս թղթին ներկայացնում է մեր աշխատանքը ԱՄԹ 2020-ի նորությունների թարգմանման կիսված խնդրում: We participate in 3 language pairs including Zh/En, Km/En, and Ps/En and in both directions under the constrained condition.  Մենք օգտագործում ենք ստանդարտ Transforme-Big մոդելը որպես հիմք և ստանում ենք լավագույն արդյունքը երկու տարբերակի միջոցով, որոնք ունեն ավելի մեծ պարամետրերի չափսեր: We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual dataset.  Մենք նաև փորձեր ենք կատարում նման լեզվի աճի հետ, ինչը հանգեցնում է դրական արդյունքների, չնայած այն, որ մենք չենք օգտագործում մեր ներկայացման մեջ: Մեր ներկայացումը վերջնական գնահատման արդյունքներ է ստանում:', 'sq': 'Ky dokument paraqet punën tonë në detyrën e përbashkët të përkthimit të lajmeve të WMT 2020. Ne marrim pjesë në 3 çifte gjuhësh duke përfshirë Zh/En, Km/En dhe P/En dhe në të dy drejtimet nën kushtin e kufizuar. Ne përdorim modelin standard Transformer-Big si bazë dhe fitojmë performancën më të mirë nëpërmjet dy varianteve me madhësitë më të mëdha të parametrave. Ne kryejmë paraproçesin e detajuar dhe filtrimin në një set të dhënash të madhe dygjuhësh dhe monogjuhësh. Disa strategji të përdorura zakonisht përdoren për të trajnuar modelet tona të tilla si Traktati mbrapa, Distilimi i njohurive të përbashkëta, etj. Ne gjithashtu kryejmë eksperimente me rritje të ngjashme gjuhësh, që shpien në rezultate pozitive, megjithëse nuk përdoret në paraqitjen tonë. Përdorimi ynë merr rezultate të çuditshme në vlerësimin përfundimtar.', 'bn': 'এই পত্রিকাটি WMT ২০২০ সংবাদ অনুবাদ শেয়ার করা কাজে আমাদের কাজ উপস্থাপন করেছে। আমরা তিন ভাষার জোড়ায় অংশগ্রহণ করি, যার মধ্যে জিহ/এন, কিমি/এন, পি/এন এবং বাধ্যতামূলক অবস্থার নিচে দুটো দিকে অংশগ্রহণ করি। আমরা স্ট্যান্ডার্নাফার- বিগ মডেল ব্যবহার করি বেস্ট লাইন হিসেবে এবং দুটি ভেরিয়ার মাধ্যমে দুটি বৃহত্তর প্যারামারের আক আমরা বিস্তারিত পূর্ব প্রক্রিয়া এবং ফিল্টার করি বিস্তারিত দ্বিতীয় ভাষা এবং মোনোলিভাল ডাটাসেটের উপর। বেশ কয়েকটি কৌশল ব্যবহার করা হয়েছে আমাদের মডেল প্রশিক্ষণের জন্য যেমন ব্যাক ট্রান্সভার, বিশেষ জ্ঞান বিভ্রান্তি ইত্যাদি প্রশিক্ষণ প্রদান করা হয়েছে। আমরা একই ধরনের ভ আমাদের আত্মসমর্পণ শেষ পর্যায়ে চমৎকার ফলাফল পেয়েছে।', 'bs': 'Ovaj papir predstavlja naš rad u zajedničkom zadatku za prevod vijesti WMT 2020. Mi učestvujemo u tri jezička parova uključujući Zh/En, Km/En, i Ps/En i u oba smjera pod ograničenim stanjem. Koristimo standardni model transformera-Velikog kao početnu liniju i dobijamo najbolju funkciju putem dva varianta sa većim veličinama parametara. Mi obavljamo detaljne predobrađivanje i filtriranje na pruženoj velikoj dvojezičkoj i monojezičkoj seti podataka. Nekoliko često korišćenih strategija se koristi za obuku našeg modela kao što su Back Translation, Ensemble Knowledge Distillation, itd. Također provodimo eksperiment sa sličnim jezičkim povećanjem, koji vodi do pozitivnih rezultata, iako se ne koristi u našem podnošenju. Naša podnošenja dobija izvanredne rezultate u konačnoj procjeni.', 'cs': 'Tento článek představuje naši práci v rámci WMT 2020 News Translation Shared Task. Účastníme se tří jazykových párů včetně Zh/En, Km/En a Ps/En a v obou směrech za omezených podmínek. Jako základní základní model používáme standardní model Transformer-Big a dosahujeme nejlepšího výkonu prostřednictvím dvou variant s většími parametry. Provádíme detailní předzpracování a filtrování na poskytnutém rozsáhlém dvojjazyčném a jednojjazyčném datovém souboru. Pro trénink našich modelů se používá několik běžně používaných strategií, jako jsou Back Translation, Ensemble Knowledge Destillace apod. Dále provádíme experimenty s podobnou rozšířením jazyka, které vedou k pozitivním výsledkům, ačkoli v našem příspěvku nepoužíváme. Náš příspěvek dosahuje pozoruhodných výsledků v závěrečném hodnocení.', 'et': 'Käesolevas artiklis tutvustatakse meie tööd WMT 2020 uudiste tõlkimise jagatud ülesandes. Osaleme kolmes keelepaaris, sealhulgas Zh/En, Km/En ja Ps/En ning mõlemas suunas piiratud tingimustes. Me kasutame baasil standardset Transformer-Big mudelit ja saavutame parima jõudluse kahe suurema parameetri suurusega variandi kaudu. Me teostame üksikasjalikku eeltöötlust ja filtreerimist pakutava suure kaks- ja ühekeelse andmekogumi alusel. Meie mudelite koolitamiseks kasutatakse mitmeid tavaliselt kasutatavaid strateegiaid, nagu tagasitõlkimine, Ensemble Knowledge Distillation jne. Samuti teeme katseid sarnase keele suurendamisega, mis annab positiivseid tulemusi, kuigi meie esitamisel seda ei kasutata. Meie esitus annab lõpphindamisel märkimisväärseid tulemusi.', 'ca': "Aquest article presenta la nostra feina en la tasca compartida de traducció de notícies de WMT 2020. Participem en tres parells de llengües, com Zh/En, Km/En, i P/En i en ambdues direccions sota la condició restringida. Utilitzem el model normal Transformer-Big com a base i obtenim el millor rendiment a través de dues variants amb grans mida de paràmetres. Fem un pré-processament detallat i filtrar en el conjunt de dades bilingües i monolingües proporcionat a gran escala. Diverses estratègies comunament utilitzades s'utilitzen per formar els nostres models, com Back Translation, Ensemble Knowledge Distillation, etc. També fem experiments amb un augment de llenguatge similar, que porta a resultats positius, encara que no utilitzats en la nostra subministració. La nostra presentació obté resultats notables en l'evaluació final.", 'fi': 'Tämä artikkeli esittelee työtämme WMT 2020 News Translation Shared Task -ohjelmassa. Osallistumme kolmeen kielipariin, mukaan lukien Zh/En, Km/En ja Ps/En, ja molempiin suuntiin rajoitetuissa olosuhteissa. Käytämme vakiomallia Transformer-Big ja saavutamme parhaan suorituskyvyn kahdella variantilla, joilla on isommat parametrikoot. Suoritamme yksityiskohtaista esikäsittelyä ja suodatusta toimitetusta suuresta kaksikielisestä ja monikielisestä aineistosta. Useita yleisesti käytettyjä strategioita käytetään malliemme kouluttamiseen, kuten Back Translation, Ensemble Knowledge Distillation jne. Teemme myös kokeiluja vastaavanlaisella kielillä, mikä johtaa positiivisiin tuloksiin, vaikka niitä ei käytetä toimituksessamme. Toimituksemme saa merkittäviä tuloksia loppuarvioinnissa.', 'jv': 'Perintah iki rambarang nggawe uwis rambarang ning barêng kelas \'Awal 2020\' Awak dhéwé éntukno 3 nglanga pating-pating lan èh/en, Km/en, lan P/en karo hal durung sampeyan ingkang diwehhit durung bisa kontinuhaan winih. string" in "context_BAR_string Learn Mode Dafta sing akeh akeh akeh stipulan langgar sampeyan nggawe model sing koyo "Backtranslation, ENsemble Learn Distillition, njl. Awak dhéwé njaluk dhéwé ngerasakno ngono nggawe langgambar uwong, sing bakal terus akeh nyoto oleh operasi ingkang dibutuhé, awak dhéwé iso nggawe tarjamahan nggo ngerasakno Rasané awakdhéwé éntuk dhéwé sawetara barang tanggal gak dhéwé.', 'ha': "Gansa na gaya aikinmu a cikin WMT 2020 Tuna sami da mazauni 3 cikin harshen aiki kamar Zh/en, Km/en, da Ps/en, kuma da dukansu a ƙarƙashin hali da aka lazimta. Mu yi amfani da motsi na Transformer-Kigirma kamar ƙarƙashin kwamfyuta kuma za'a sami mafi kyaw game da tsohon sigar biyu masu girma. Munã cika fassarar-bayan-aiki da za'a filter a kan da aka bãyar da data masu tsawo biyu-bilimi da sauri. Ko da yawa aka yi amfani da kayan yi amfani da su tunkuɗe misalinmu kamar manyan Translate, Disappearance of Cilmi na Tilbake, etc. Kuma za mu yi jarrabo da fitina da kuma ƙaramako da misãlin harshen, wanda ke ƙara fassarar da fassarata masu gaba, kuma kõ da ba mu yi amfani da musuluntami ba. MusuluncinMu yana da matsayin mai kyau a ƙarshen rabon.", 'he': 'העיתון הזה מציג את עבודתנו במשימה המשותפת של התרגום חדשות WMT 2020. We participate in 3 language pairs including Zh/En, Km/En, and Ps/En and in both directions under the constrained condition.  We use the standard Transformer-Big model as the baseline and obtain the best performance via two variants with larger parameter sizes.  אנו מבצעים מעבדה מראש ומסרט מפורטת על קבוצת נתונים שתיים-שפותית ומונולשפותית. מספר אסטרטגיות משתמשות בדרך כלל משתמשות כדי לאמן את הדוגמנים שלנו, כמו תרגום מאחור, דיסטילציה של ידע סמום, וכו"כ. אנחנו גם מבצעים ניסוי עם גיבוי שפה דומה, שמובילים לתוצאות חיוביות, למרות שלא משתמשים בהכנעה שלנו. ההצגה שלנו מקבלת תוצאות מדהימות בהערכה הסופית.', 'sk': 'Prispevek predstavlja naše delo v okviru skupne naloge prevajanja novic WMT 2020. Sodelujemo v treh jezikovnih parih, vključno z Zh/En, Km/En in Ps/En in v obeh smereh pod omejenim pogojem. Kot osnovno izhodišče uporabljamo standardni model Transformer-Big in dosegamo najboljšo zmogljivost z dvema različicama z večjimi velikostmi parametrov. Izvajamo podrobno predobdelavo in filtriranje na zagotovljenem obsežnem dvojezičnem in enojezičnem naboru podatkov. Za usposabljanje naših modelov se uporablja več pogosto uporabljenih strategij, kot so Back Translation, Ensemble Knowledge Distillation itd. Prav tako izvajamo eksperimente s podobno jezikovno povečanje, kar vodi do pozitivnih rezultatov, čeprav v naši predlogi ni uporabljeno. Naša predložitev dosega izjemne rezultate v končni oceni.', 'bo': 'ཤོག་བྱང་འདིས་WMT 2020་བརྙན་ཞུ་ཚོར་སྤྱི་ཚོགས་ལས་བྱ་འགུལ་ནང་དུ་ང་ཚོའི་ལས་ཀ་སྟོན་པ ང་ཚོས་སྐད་ཡིག་ཆའི་མཐོ་ཚད་གཞུང་གི་ནང་དུ་Zh/En, Km/En, Ps/En དང་། སྐད་ཡིག་ཆ་གསུམ་ནང་མི་མཐུད་པས། We use the standard Transformer-Big model as the baseline and obtain the best performance via two variants with larger parameter sizes. ང་ཚོས་བྱིས་ཡོད་པའི་སྔོན་སྒྲིག་ཞིབ སྤྱིར་བཏང་བའི་ཐབས་ལམ་ལུགས་མང་པོ་ཞིག་ལག་ལེན་འཐབ་ཡོད་པ་ལས་ང་ཚོའི་མིག་དཔེར་ན། Back Translation, Ensemble Knowledge Distillation, etc. ང་ཚོའི་མཇུག་གི་རིམ་པ་ལ་མཐའ་མ་ཤེས་ཀྱི་རྐྱེན་འབྲས་བ་རེད།'}
{'en': 'The Volctrans Machine Translation System for WMT20', 'ar': 'نظام Volctrans للترجمة الآلية لـ WMT20', 'fr': 'Le système de traduction automatique Volctrans pour WMT20', 'es': 'El sistema de traducción automática Volctrans para WMT20', 'pt': 'O sistema de tradução automática Volctrans para WMT20', 'ja': 'WMT 20用Volctrans機械翻訳システム', 'zh': '以 WMT20 之 Volctrans 机器翻译统', 'hi': 'WMT20 के लिए Volctrans मशीन अनुवाद प्रणाली', 'ru': 'Система машинного перевода Volctrans для WMT20', 'ga': 'Córas Aistriúcháin Meaisín Volctrans do WMT20', 'ka': 'WMT20Name', 'el': 'Το σύστημα μηχανικής μετάφρασης Volctrans για το WMT20', 'hu': 'A Volctrans gépi fordító rendszer WMT20 számára', 'it': 'Il sistema di traduzione automatica Volctrans per WMT20', 'kk': 'WMT20 үшін Volctrans машинаны аудару жүйесі', 'mk': 'Волктранс машински преведувачки систем за WMT20', 'lt': 'WMT20 Volktranų mašinų vertimo sistema', 'ms': 'Sistem Terjemahan Mesin Volctrans untuk WMT20', 'ml': 'WMT20- നുള്ള വോള്\u200dക്ട്രാന്\u200d മെഷീന്\u200d പരിഭാഷ സിസ്റ്റം', 'mn': 'WMT20 Volctrans Machine Translation System', 'mt': 'Is-Sistema ta’ Traduzzjoni tal-Magni Volttrani għad-WMT20', 'no': 'Volctrans- maskinsomsetjingssystemet for WMT20', 'ro': 'Sistemul de traducere automată Volctrans pentru WMT20', 'pl': 'System tłumaczeń maszynowych Volctrans dla WMT20', 'sr': 'Volktorski sistem za prevod mašine za WMT20', 'so': 'Volctrans Mashine Translation System for WMT20', 'sv': 'Volctrans maskinĂ¶versĂ¤ttningssystem fĂ¶r WMT20', 'si': 'WMT20Comment', 'ta': 'WMT20 க்கான ஒல்க்ட்ரான்ஸ் இயந்திரம் மொழிபெயர்ப்பு அமைப்பு', 'ur': 'Name', 'uz': 'WMT20 uchun vositalar tarjima tizimi', 'vi': 'Hệ thống dịch máy điện từ WM20', 'bg': 'Системата за машинен превод на Volctrans за WMT20', 'da': 'Volctrans maskinoversættelsessystem til WMT20', 'hr': 'Volctrans uređajski sustav prevoda za WMT20', 'nl': 'Het Machine Translation System van Volctrans voor WMT20', 'de': 'Das maschinelle Übersetzungssystem von Volctrans für WMT20', 'id': 'Sistem Terjemahan Mesin Volktran untuk WMT20', 'ko': 'WMT20용 Volctrans 기계 번역 시스템', 'fa': 'سیستم ترجمه ماشین Volctrans برای WMT20Name', 'sw': 'Mfumo wa Tafsiri wa Mashine wa Volctrans kwa WMT20', 'tr': 'WMT20 üçin Volktrans Mazmunlar terjime sistemi', 'af': 'Name', 'sq': 'Sistemi i Translacionit të Makinës së Volktransit për WMT20', 'am': 'ምርጫዎች', 'hy': 'Հոլկտրանսի մեքենայի թարգմանման համակարգը', 'az': 'WMT20 üçün Volktrans Makina Çeviri Sistemi', 'bn': 'WMT20 এর জন্য ভল্কট্রান মেশিন অনুবাদ সিস্টেম', 'bs': 'Volctrans Machine Translation System za WMT20', 'ca': 'El sistema de traducció de màquines volcàries per a WMT20', 'cs': 'Strojový překlad systém Volctrans pro WMT20', 'et': 'Volctransi masintõlke süsteem WMT20 jaoks', 'fi': 'Volctrans Machine Translation System for WMT20', 'sk': 'Volctransov sistem strojnega prevajanja za WMT20', 'ha': 'Translate system for WMT20', 'bo': 'WMT20 ཡིས་Volctrans རྩིས་འཁོར་གཞུང་གི་ལུགས་སྒྱུར་མ་ལག', 'jv': 'Name', 'he': 'The Volctrans Machine Translation System for WMT20'}
{'en': 'This paper describes our submission systems for VolcTrans for WMT20 shared news translation task. We participated in 8 translation directions. Our basic systems are based on Transformer (CITATION), into which we also employed new architectures (bigger or deeper Transformers, dynamic convolution). The final systems include text pre-process, subword(a.k.a. BPE(CITATION)), baseline model training, iterative back-translation, model ensemble, knowledge distillation and multilingual pre-training.', 'es': 'Este artículo describe nuestros sistemas de envío para VolcTrans para la tarea de traducción de noticias compartidas de WMT20. Participamos en 8 direcciones de traducción. Nuestros sistemas básicos se basan en Transformer (CITATION), en el que también empleamos nuevas arquitecturas (Transformers más grandes o más profundos, convolución dinámica). Los sistemas finales incluyen el preproceso de texto, el subtexto (también conocido como BPE (CITATION)), la capacitación del modelo de referencia, la retrotraducción iterativa, el conjunto de modelos, la destilación de conocimientos y la capacitación previa multilingüe.', 'pt': 'Este artigo descreve nossos sistemas de envio para a tarefa de tradução de notícias compartilhadas do VolcTrans for WMT20. Participamos de 8 direções de tradução. Nossos sistemas básicos são baseados em Transformer (CITATION), no qual também empregamos novas arquiteturas (Transformers maiores ou mais profundos, convolução dinâmica). Os sistemas finais incluem pré-processamento de texto, subpalavra (a.k.a. BPE(CITATION)), treinamento de modelo de linha de base, retrotradução iterativa, conjunto de modelo, destilação de conhecimento e pré-treinamento multilíngue.', 'ar': 'تصف هذه الورقة أنظمة التقديم الخاصة بنا لـ VolcTrans لمهمة ترجمة الأخبار المشتركة WMT20. شاركنا في 8 اتجاهات ترجمة. تعتمد أنظمتنا الأساسية على Transformer (CITATION) ، والذي استخدمنا فيه أيضًا بنى جديدة (محولات أكبر أو أعمق ، التفاف ديناميكي). تشتمل الأنظمة النهائية على معالجة نصية مسبقة ، وكلمة فرعية (تُعرف أيضًا باسم BPE (CITATION)) ، وتدريب نموذج أساسي ، وترجمة رجعية تكرارية ، ومجموعة نموذجية ، وتقطير المعرفة ، والتدريب المسبق متعدد اللغات.', 'fr': "Cet article décrit nos systèmes de soumission pour VolcTrans pour la tâche de traduction d'actualités partagées WMT20. Nous avons participé à 8 directions de traduction. Nos systèmes de base sont basés sur Transformer (CITATION), dans lequel nous avons également utilisé de nouvelles architectures (transformateurs plus grands ou plus profonds, convolution dynamique). Les systèmes finaux comprennent le pré-traitement de texte, les sous-mots (également appelés BPE (CITATION)), la formation de modèle de base, la rétro-traduction itérative, l'ensemble de modèles, la distillation des connaissances et la pré-formation multilingue.", 'ja': '本稿では、WMT 20共有ニュース翻訳タスクのためのVolcTransの提出システムについて説明します。8つの翻訳ディレクションに参加しました。私たちの基本的なシステムは、トランスフォーマー（引用）に基づいており、そこには新しいアーキテクチャ（大きいトランスフォーマーまたは深いトランスフォーマー、動的畳み込み）も採用しました。最終的なシステムには、テキスト前処理、サブワード（別名BPE （引用） ）、ベースラインモデルトレーニング、反復バックトランスレーション、モデルアンサンブル、知識蒸留、および多言語の事前トレーニングが含まれます。', 'zh': '本文引我WMT20共享新闻译者VolcTrans之。 与8译方。 本乎Transformer(CITATION),用乎新架构(大乎Transformers,动乎卷积)。 终统包文本预处理,子词(一名BPE(CITATION)),基线模形训练,迭代反向译,模集成之,蒸馏多言预训练。', 'hi': 'यह पेपर WMT20 साझा समाचार अनुवाद कार्य के लिए VolcTrans के लिए हमारे सबमिशन सिस्टम का वर्णन करता है। हमने 8 अनुवाद दिशाओं में भाग लिया। हमारे मूल सिस्टम ट्रांसफॉर्मर (उद्धरण) पर आधारित हैं, जिसमें हमने नए आर्किटेक्चर (बड़े या गहरे ट्रांसफॉर्मर, गतिशील कनवल्शन) को भी नियोजित किया है। अंतिम प्रणालियों में पाठ पूर्व-प्रक्रिया, उप-शब्द (उर्फ बीपीई (प्रशस्ति पत्र)), बेसलाइन मॉडल प्रशिक्षण, पुनरावर्ती बैक-अनुवाद, मॉडल पहनावा, ज्ञान आसवन और बहुभाषी पूर्व-प्रशिक्षण शामिल हैं।', 'ru': 'В этой статье описываются наши системы подачи заявок на VolcTrans для задачи совместного перевода новостей WMT20. Мы приняли участие в 8 направлениях перевода. Наши базовые системы основаны на Трансформаторе (CITATION), в котором мы также использовали новые архитектуры (более крупные или глубокие Трансформаторы, динамическая свертка). Заключительные системы включают в себя текстовую предварительную обработку, подслово(также известное как BPE(ЦИТИРОВАНИЕ)), базовое обучение модели, итеративный обратный перевод, модельный ансамбль, дистилляцию знаний и многоязычное предварительное обучение.', 'ga': 'Déanann an páipéar seo cur síos ar ár gcórais aighneachta do VolcTrans do thasc aistriúcháin nuachta roinnte WMT20. Ghlacamar páirt i 8 dtreoir aistriúcháin. Tá ár gcórais bhunúsacha bunaithe ar Transformer (CITATION), inar úsáideamar ailtireachtaí nua freisin (Claochladáin níos mó nó níos doimhne, convolution dinimiciúil). Áirítear ar na córais deiridh réamhphróiseas téacs, fo-fhocal (aka BPE(CITATION))), oiliúint mhúnla bonnlíne, ais-aistriúchán atriallach, ensemble samhlacha, driogadh eolais agus réamhoiliúint ilteangach.', 'ka': 'Name ჩვენ 8 წინასწორედ დავამწევეთ. ჩვენი ფუნქციური სისტემები ტრანფორმაციის (CITATION) დაბაზიან, რომელსაც ჩვენ ახალი აქტიქტიქტურები (უფრო დიდი ან უფრო დინამიკი ტრანფორმაციები, დინამიკ ბოლო სისტემაში ტექსტის წინაპროცესი, წინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინ', 'el': 'Αυτή η εργασία περιγράφει τα συστήματα υποβολής για την κοινή εργασία μετάφρασης ειδήσεων VolcTrans για WMT20. Συμμετείχαμε σε οκτώ μεταφραστικές κατευθύνσεις. Τα βασικά μας συστήματα βασίζονται στον μετασχηματιστή (στον οποίο εφαρμόσαμε και νέες αρχιτεκτονικές (μεγαλύτεροι ή βαθύτεροι μετασχηματιστές, δυναμική σύγχυση). Τα τελικά συστήματα περιλαμβάνουν προεπεξεργασία κειμένου, υπολέξη (άλλως BPE(CITATION)), εκπαίδευση μοντέλου βάσης, επαναλαμβανόμενη μεταγραφή, σύνολο μοντέλων, απόσταξη γνώσεων και πολύγλωσση προεκπαίδευση.', 'hu': 'Ez a tanulmány bemutatja a VolcTrans WMT20 megosztott hírfordítási feladat benyújtási rendszerét. 8 fordítási irányban vettünk részt. Alapvető rendszereink a Transzformátoron (CITATION) alapulnak, amelyekbe új architektúrákat is alkalmaztunk (nagyobb vagy mélyebb Transzformátorok, dinamikus konvolúció). A végső rendszerek magukban foglalják a szöveg előkészítését, az alszót (más néven BPE(CITATION)), az alapvető modellképzést, az iteratív visszafordítást, a modellegyütteset, a tudás lepárlását és a többnyelvű előképzést.', 'it': "Questo articolo descrive i nostri sistemi di invio per VolcTrans per il compito condiviso di traduzione delle notizie WMT20. Abbiamo partecipato a 8 direzioni di traduzione. I nostri sistemi di base sono basati su Transformer (CITATION), in cui abbiamo utilizzato anche nuove architetture (Transformers più grandi o più profondi, convoluzione dinamica). I sistemi finali includono il pre-processo del testo, la sottoparola (alias BPE(CITATION)), la formazione dei modelli di base, la traduzione iterativa, l'insieme dei modelli, la distillazione della conoscenza e la pre-formazione multilingue.", 'mk': 'Овој весник ги опишува нашите системи за поднесување на VolcTrans за заедничката задача за превод на вести на WMT20. Учествувавме во 8 насоки за превод. Нашите основни системи се базирани на Трансформер (ЦИТАЦИЈА), во кој исто така вработувавме нови архитектури (поголеми или подлабоки Трансформери, динамични конволуции). Финалните системи вклучуваат текст-препроцес, подзбор(познат како БПЕ(CITATION)), основна обука на моделот, итеративна назад-превод, моделен ансембл, дистилација на знаење и мултијазичен преобука.', 'kk': 'Бұл қағаз WMT20 жаңалық аудару тапсырмасы үшін VolcTrans жүйелерімізді таңдайды. Біз 8 аудармалар бағыттарына қатынасыз. Біздің негізгі жүйелеріміз түрлендірушілеріне негізделген (СИТАЦИЯЛЫҚ) тәртіпке негізделген, сондай-ақ біз жаңа архитектураларды (үлкен немесе түрлендірушілер Соңғы жүйелерде мәтін алдын- процесс, субсөз( мысалы: BPE( CITATION)), негізгі үлгі оқыту, итеративті артқа аудару, үлгі ендіру, білім дистилация және көп тілді алдын- оқыту.', 'lt': 'Šiame dokumente apibūdinamos mūsų „VolcTrans“ pristatymo sistemos, skirtos bendroms žinių vertimo užduotims vykdyti WMT20. Dalyvavome 8 vertimo kryptimis. Mūsų pagrindinės sistemos grindžiamos Transformer (CITATION), į kurią taip pat įdiegėme naujas architektūras (didesnius arba gilesnius Transformers, dinaminę konvoliuciją). Galutinės sistemos apima teksto išankstinį procesą, paražodį (dar žinomą kaip BPE(CITATION)), pradinį modelio mokymą, pakartotinį grįžtamąjį vertimą, modelio kompleksą, žinių distiliavimą ir daugiakalbį išankstinį mokymą.', 'ms': 'Kertas ini menggambarkan sistem penghantaran kami untuk VolcTrans untuk tugas terjemahan berita berkongsi WMT20. Kami berpartisipasi dalam 8 arah terjemahan. Sistem asas kita berdasarkan Transformer (CITATION), di mana kita juga menggunakan arkitektur baru (Transformers yang lebih besar atau lebih dalam, konvolusi dinamik). Sistem akhir termasuk pre-proses teks, subword( alias BPE( CITATION)), latihan model asas, terjemahan-belakang iteratif, ensemble model, pengusiran pengetahuan dan pralatihan berbilang bahasa.', 'ml': 'ഈ പത്രത്തില്\u200d വോള്\u200dസ്ട്രാന്\u200d വേണ്ടി വിവരങ്ങള്\u200d വിവരിക്കുന്നു ഞങ്ങള്\u200d 8 പരിഭാഷത്തിന്റെ വഴികളില്\u200d പങ്കുചേര്\u200dന്നു. നമ്മുടെ അടിസ്ഥാനമായ സിസ്റ്റമുകള്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d അടിസ്ഥാനത്തിലാണ്. അവിടെ നമ്മള്\u200d പുതിയ ആര്\u200dക്കിട്ടുകളും ഉപയോഗിച്ചിരുന്ന അവസാനത്തെ സിസ്റ്റത്തില്\u200d പദാവലിയുടെ പ്രക്രിയയില്\u200d ഉള്\u200dപ്പെടുന്നു, സബ്വോര്\u200dഡ് (a. a. BPE( CITATION)), ബേസ്ലൈന്\u200d മോഡല്\u200d പരിശീലം, സാധാരണ പിന്തിരിച്ചറിയുന്', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi tagħna ta’ sottomissjoni għall-VolcTrans għall-kompitu ta’ traduzzjoni tal-aħbarijiet kondiviż tad-WMT20. Parteċipajna fi tmien direzzjonijiet ta’ traduzzjoni. Is-sistemi bażiċi tagħna huma bbażati fuq it-Transformer (CITATION), li fihom impjegajna wkoll arkitetturi ġodda (Transformers akbar jew aktar profondi, konvoluzzjoni dinamika). Is-sistemi finali jinkludu t-test ta’ qabel il-proċess, is-subkelma(magħrufa wkoll bħala BPE(CITATION)), it-taħriġ tal-mudell ta’ bażi, it-traduzzjoni ripetuta, l-ensemble tal-mudell, id-distillazzjoni tal-għarfien u t-taħriġ multilingwi ta’ qabel.', 'mn': 'Энэ цаас WMT20 хуваалцаагүй мэдээний орчуулалтын VolcTrans-ын дамжуулалтын системийг тайлбарладаг. Бид 8 орчуулах замаар оролцсон. Бидний үндсэн систем Трансформер (ЦИТАЦИЙ) дээр суурилсан. Мөн бид шинэ архитектуруудыг ажиллаж байсан. Сүүлчийн систем нь текст өмнөх процесс, суб-үг(жишээ нь BPE(CITATION)), суурь загварын сургалтын сургалтын хөдөлгөөн, iterative back-translation, загвар бүрдүүлэгч, мэдлэг сайжруулах, олон хэл өмнөх сургалтын сургалтын тухай.', 'pl': 'Niniejszy artykuł opisuje nasze systemy składania wiadomości dla wspólnego tłumaczenia wiadomości VolcTrans dla WMT20. Uczestniczyliśmy w ośmiu kierunkach tłumaczeniowych. Nasze podstawowe systemy bazują na Transformerze (CITATION), w którym zastosowaliśmy również nowe architektury (większe lub głębsze Transformery, dynamiczne zwojenie). Końcowe systemy obejmują wstępne procesy tekstowe, podsłowo(alias BPE(CITATION)), szkolenie modelu bazowego, iteracyjne tłumaczenie wsteczne, zespół modeli, destylację wiedzy i wielojęzyczne szkolenie wstępne.', 'ro': 'Această lucrare descrie sistemele noastre de depunere pentru sarcina de traducere a știrilor partajate VolcTrans pentru WMT20. Am participat la 8 direcţii de traducere. Sistemele noastre de bază se bazează pe Transformer (CITATION), în care am folosit și noi arhitecturi (Transformers mai mari sau mai profunde, convoluție dinamică). Sistemele finale includ prelucrarea textului, subcuvântul (cunoscut și sub-cuvântul BPE(CITATION)), formarea modelului de bază, traducerea iterativă, ansamblul modelului, distilarea cunoștințelor și pregătirea prealabilă multilingvă.', 'sr': 'Ovaj papir opisuje naše podnosne sisteme za VolcTrans za zadatak WMT20 zajedničkog prevoda vesti. Участили смо у 8 посока превода. Naši osnovni sistemi su zasnovani na transformaciji (CITATION), u kojima smo takođe zaposlili nove arhitekture (veće ili dublje transformacije, dinamične konvolucije). Posljednji sistem uključuje tekst pre-proces, podreč(poznat kao BPE(CITATION)), osnovnu obuku model a, iterativni prevod natrag, model ensemble, destilaciju znanja i multijezičku predobuku.', 'no': 'Name Vi delta i 8 oversettelsretningar. Grunnleggjande systemet våre er basert på Transformer (CITATION), der vi også arbeida nye arkitekturar (større eller dypere transformerer, dynamiske konvolusjon). Sistemene inneheld tekstførehandsvising, underordet(t.d. BPE(CITATION)), baselinjemodellen, iterativ tilbakeomsetjing, modell ensemble, kunnstillingsdistillasjon og fleirprøving.', 'so': 'Kanu wuxuu ku qoran yahay nidaamka soo gelinta ee VolcTrans ee WMT20 oo lagu sharciyey shaqada turjumista news. Waxaannu ka qeybqaadanay 8 kooxooyinka turjumidda. nidaamkayaga aasaasiga ah waxay ku saleysan yihiin Transfer (CITATION), taasoo aannu ku shaqeynay dhismo cusub (turjumayaasha weyn ama mool dheer, khilaafka dhaqdhaqaaqa). Isticmaalka ugu dambeeya waxaa k a mid ah qoraal-horaadka, qoraalka hoose-hadalka (e.g. BPE(CITATION)), waxbarashada modellka aasaasiga ah, wax-qorid ah dib-turjumista, model imtixaanka, kala sooc aqoonta iyo waxbarasho ka hor-qaadashada luuqadaha kala duduwan.', 'sv': 'Denna uppsats beskriver vﾃ･ra inlﾃ､mningssystem fﾃｶr VolcTrans fﾃｶr WMT20 delade nyhetsﾃｶversﾃ､ttningsuppgifter. Vi deltog i ﾃ･tta ﾃｶversﾃ､ttningsriktningar. Vﾃ･ra grundlﾃ､ggande system bygger pﾃ･ Transformer (CITATION), dﾃ､r vi ﾃ､ven anvﾃ､nde nya arkitekturer (stﾃｶrre eller djupare Transformers, dynamisk konvulution). De slutliga systemen omfattar textfﾃｶrfﾃｶrfarande, underord (ﾃ､ven kallat BPE(CITATION)), basmodell utbildning, iterativ backﾃｶversﾃ､ttning, modellensemble, kunskapsdestillation och flersprﾃ･kig fortbildning.', 'si': 'මේ පැත්තේ WMT20 සමාගත වාර්තාව භාවිත වැඩක් සඳහා VolcTrans සඳහා අපේ පිළිබඳ පද්ධති විස්තර කරනවා. අපි වාර්ථාව 8 පැත්තෙන් සමාගත්තා. අපේ මූලික පද්ධතිය ප්\u200dරවේශකය (CITATION) සඳහා ආධාරණය කරලා තියෙනවා, ඒ වගේම අපි අළුත් ස්ථාපනය (ලොකු හෝ ගොඩක් ස්ථ අන්තිම පද්ධතියේ පාළ ප්\u200dරක්\u200dරියාව, සබ්වවචන(a.k.a. BPE(CITATION)), පද්ධතිම පද්ධතිය ප්\u200dරක්\u200dරියාණය, ආයුතිමත පස්ථාපනය, පද්ධතිය පද්ධතිය', 'ta': 'WMT20 பகிர்ந்த செய்தி மொழிபெயர்ப்பு பணிக்கான எங்கள் ஒலிச்சு முறைமைகளை விளக்குகிறது. நாங்கள் 8 மொழிபெயர்ப்பு திசைகளில் பங்கிட்டோம். நம்முடைய அடிப்படை அமைப்புகள் மாற்றும் (CITATION) அடிப்படையிலாக இருக்கிறது, அதில் நாம் புதிய அடிப்படைகளை பயன்படுத்தினோம் (பெரிய அல்லது ஆ கடைசி அமைப்புகளில் உரை முன்னோட்டு செயல்பாடு, துணை வார்த்தை (a. k. BPE (CITATION)), அடிப்படைக்கோடு மாதிரி பயிற்சி, உருவாக்க மீள்மொழிபெயர்ப்பு, மாதிரி ஒள', 'ur': 'This paper describes our submission systems for VolcTrans for WMT20 shared news translation task. ہم 8 ترجمہ طریقوں میں شریک ہوئے۔ ہماری بنیادی سیسٹم ترنسفور (CITATION) پر بنیاد ہے، جس میں ہم نے نیا معماری (بڑی یا عمیقی ترنسفورٹر، ڈینمانیک ترنسفورٹر) بھی استعمال کیا ہے۔ آخری سیستموں میں متن پیش پرسس، سوبرویڈ(یعنی BPE(CITATION)، بنیادی لین موڈل کی آموزش، دوبارہ پیچھے ترجمہ، موڈل مضبوط، علم الٹیٹلیٹ اور بہت سی زبان پیش ترکین ہے.', 'uz': 'Bu qogĘ»oz WMT20 bilan bogĘ»liq yangiliklar tarjimasi uchun VolcTrans tizimimizni anglatadi. We participated in 8 translation directions.  Biz asosiy tizimmiz Transformer (CITATION) asosida asosida, bu yerda biz yangi maktablarni ishlatdik (katta yoki eng yuqori tarjimalar, dynamik muvaffaqiyatli). @ info: whatsthis', 'vi': 'Tờ giấy này mô tả hệ thống đăng nhập của chúng tôi cho VolcTrans for WM Bây giờ dịch tin chung. Chúng tôi tham gia hướng dịch tám. Hệ thống cơ bản của chúng ta dựa trên biến hình (độc lập), trong đó chúng ta cũng đã sử dụng các kiến trúc khác (các biến hình lớn hay sâu hơn, các xoắn khí động). Các hệ thống cuối cùng gồm: tiền án văn bản, chữ thứ (biệt danh BPE (COTINion)', 'bg': 'Тази статия описва нашите системи за подаване на информация за споделената задача за превод на новини. Участвахме в 8 направления за превод. Основните ни системи са базирани на трансформатор (ЦИТАЦИЯ), в който използвахме и нови архитектури (по-големи или по-дълбоки трансформатори, динамична конволюция). Окончателните системи включват предварителен процес на текст, поддума (известен още като BPE(CITATION)), обучение на базовия модел, итеративен обратен превод, моделен ансамбъл, дестилация на знания и многоезично предварително обучение.', 'da': 'Denne artikel beskriver vores indsendelsessystemer til VolcTrans for WMT20 delt nyhedsoversættelsesopgave. Vi deltog i 8 oversættelsesvejledninger. Vores grundlæggende systemer er baseret på Transformer (CITATION), hvor vi også anvendte nye arkitekturer (større eller dybere Transformers, dynamisk konvulution). De endelige systemer omfatter tekst pre-proces, underord (alias BPE(CITATION)), baseline model træning, iterativ back-oversættelse, model ensemble, viden destillation og flersproget pre-training.', 'nl': 'Dit document beschrijft onze indieningssystemen voor VolcTrans voor WMT20 gedeelde vertaaltaak voor nieuws. We namen deel aan acht vertaalrichtingen. Onze basissystemen zijn gebaseerd op Transformer (CITATION), waarin we ook nieuwe architecturen hebben toegepast (grotere of diepere Transformers, dynamische convolutie). De uiteindelijke systemen omvatten tekst pre-process, subwoord(ook bekend als BPE(CITATION)), basismodel training, iteratieve back-translation, model ensemble, kennisdistillatie en meertalige pre-training.', 'hr': 'Ovaj papir opisuje naše podnosne sustave za VolcTrans za zadatak WMT20 zajedničkog prevoda vijesti. Učestvovali smo u 8 smjera prevođenja. Naši osnovni sustavi su temeljeni na transformaciji (CITATION), u kojima smo također zaposlili nove arhitekture (veće ili dublje transformacije, dinamične konvolucije). Konačni sustavi uključuju tekst pred procesom, podriječ(također: BPE(CITATION)), početnu obuku model a, iterativni prevod natrag, model ensemble, destilaciju znanja i multijezičku predobuku.', 'id': 'Kertas ini menjelaskan sistem pengiriman kita untuk VolcTrans untuk tugas terjemahan berita berbagi WMT20. We participated in 8 translation directions.  Sistem dasar kita berdasarkan Transformer (CITATION), di mana kita juga menggunakan arsitektur baru (Transformers yang lebih besar atau lebih dalam, konvolusi dinamik). Sistem akhir termasuk pre-proses teks, subword(a.k.a. BPE(CITATION)), pelatihan model dasar, iteratif back-translation, model ensemble, distillation pengetahuan dan multilingual pre-pelatihan.', 'de': 'Dieses Papier beschreibt unsere Einreichungssysteme für VolcTrans for WMT20 Shared News Translation Task. Wir haben an acht Übersetzungsrichtungen teilgenommen. Unsere Basissysteme basieren auf Transformer (CITATION), in denen wir auch neue Architekturen (größere oder tiefere Transformer, dynamische Faltung) eingesetzt haben. Die abschließenden Systeme umfassen Textvorprozess, Subword(alias BPE(CITATION)), Basismodelltraining, iterative Rückübersetzung, Modellensemble, Wissensdestillation und mehrsprachige Vortrainings.', 'ko': '본고는 우리가 WMT20 공유 뉴스 번역 임무를 위한 Volctrans 제출 시스템을 묘사한다.우리는 여덟 개의 번역 지도에 참여했다.우리의 기본 시스템은 Transformer(인용)를 바탕으로 하고 새로운 체계 구조(더 크거나 더 깊은 Transformer, 동적 볼륨)를 채택했다.최종 시스템은 텍스트 예처리, 자사(BPE(인용문)), 기선 모형 훈련, 교체 반역, 모형 집적, 지식 추출과 다언어 예훈련을 포함한다.', 'fa': 'این کاغذ سیستم\u200cهای تحویل ما برای VolcTrans برای تابع نویسی مشترک WMT20 را توصیف می\u200cکند. ما در ۸ مسیر ترجمه شرکت کردیم. سیستم\u200cهای بنیادی ما بر اساس تغییر\u200cدهنده (CITATION) بنیاد دارند، در آن همچنین معماری\u200cهای جدید (تغییر\u200cدهنده\u200cهای بزرگ یا عمیق\u200cتر، تغییر\u200cدهنده\u200cهای دینامیک) استخدام می\u200cکردیم. سیستم نهایی شامل فرایند متن پیش از فرایند، زیر کلمه(به عنوان BPE(CITATION)، آموزش مدل پایین، ترجمه پشتی تکرار کننده، مدل انجمن، جدایی علم و پیش آموزش زیر زبان است.', 'tr': 'Bu kagyz WMT20 üçin VolcTrans üçin biziň jemgyýet sistemlerimizi ylalaýar. Biz 8 terjime edilen yönlerde chikanchasydyk. Biziň esasy sistemamyz Transformer (KITATION) tarapyna daýanýar, şol ýere täze arhitektarlar hem işe yaradyk. Soňky sistemalar metin öň-proses, subsöz(a.k.a. BPE(CITATION)), baz nusga okuwçysy, iteratiw arka terjime etmek üçin nusga görnüşi, bilim täzelenmesi we k öp dilli öň-okuwçysy bar.', 'sw': 'Gazeti hili linaelezea mfumo wetu wa kujitolea kwa ajili ya VolcTrans kwa ajili ya kazi ya kutafsiri habari za WMT20. Tumeshiriki katika njia 8 za kutafsiri. Mfumo wetu wa msingi unategemea Transfer (CITATION), ambapo pia tulitumia majengo mapya (Transformers kubwa au zaidi, mapinduzi ya kimaadili). Mifumo ya mwisho ni pamoja na mchakato wa matokeo ya kabla ya ujumbe wa ujumbe, maneno ya chini (kama. BPE(CITATION)), mafunzo ya model ya msingi, tafsiri ya msingi, mfumo wa mifano, utofauti wa maarifa na mafunzo ya lugha mbalimbali.', 'af': 'Hierdie papier beskryf ons onderskrywing stelsels vir VolcTrans vir WMT20 gedeelde nuusvertaling taak. Name Ons het gedeel in 8 vertaling rigtings. Ons basiese stelsels is gebaseer op Transformer (KYTATION), waarin ons ook nuwe arkitektuur gebruik het (groter of dieper Transformers, dinamiese konvolusie). Die eindelike stelsels insluit teks voor-proses, subwoord( a.k.a. BPE( CITATION)), basisline model onderwerking, iteratiewe terugvertaling, model ensemble, kennis destilasie en multilingse voor-onderwerking.', 'am': 'ይህ ገጽ ለWMT20 የዜና ትርጉም ስራዎችን ለፎልcTrans ጥያቄያችንን ይናገራል፡፡ 8 ትርጉም መንገድ ተካፈልን:: መሠረት ስርዓታችን ተርጓሚዎች (CITATION) በመሠረት ላይ ነው፤ በዚህም ደግሞ አዲስ መሠረቶች (ትልቅ ወይም ጥልቅ Transformers, dynamic ጉዳይ) እናገራለን፡፡ የመጨረሻው ስርዓቶች የጽሑፍ ቅድመ-ፕሮጀክት፣ ደብዳቤ ቃላት (a.g. BPE(CITATION)), የbaseline model training, የኢንተርኔት ጀርባ-ትርጉም፥ ሞዴል ምሳሌ፣ እውቀት ትርጉም እና የቋንቋ-ቋንቋ ቅድሚያ ትምህርት.', 'az': 'Bu kağıt WMT20 paylaşılmış xəbər qurğulaması üçün VolcTrans təklif sistemlərini təsdiqləyir. Biz 8 tercümə tərəfində səviyyət etdik. Bizim temel sistemlərimiz Transformer (CITATION) üzerində dayanılır, orada yeni arhitektarları da istifadə edirik (daha böyük və daha derin Transformers, dynamic convolution). Son sistemlərin metin ön prozesi, altsözləri(a.k.a. BPE(CITATION)), sinyal modeli təhsil edilməsi, iterativ arka çeviri, modeli ensemble, bilgi destilasyonu və çoxlu dil ön təhsil edilməsi barəsindədir.', 'sq': 'Ky dokument përshkruan sistemet tona të paraqitjes për VolcTrans për detyrën e përkthimit të lajmeve të përbashkëta WMT20. Ne morëm pjesë në 8 drejtime përkthimi. Sistemet tona bazë janë bazuar në Transformer (CITATION), në të cilin ne gjithashtu punësuam arkitektura të reja (Transformers më të mëdhenj apo më të thellë, konvolucion dinamik). The final systems include text pre-process, subword(a.k.a. BPE(CITATION)), baseline model training, iterative back-translation, model ensemble, knowledge distillation and multilingual pre-training.', 'hy': 'Այս հոդվածը նկարագրում է մեր համակարգերը, որոնք ներկայացնում են Վոլկտրանսը, աշխարհի աշխարհում 20-ի ընդհանուր նորությունների թարգմանման համար: Մենք մասնակցեցինք 8 թարգմանման ուղղություններում: Our basic systems are based on Transformer (CITATION), into which we also employed new architectures (bigger or deeper Transformers, dynamic convolution).  Վերջնական համակարգերը ներառում են տեքստի նախապրոցեսը, ենթաբառը (հայտնի է նաև Bpe(CITACtion), հիմնական մոդելի վարժեցումը, կրկնվող վերջնական թարգմանումը, մոդելի համակարգը, գիտելիքի դիսլիլացիան և բազմալեզու նախավարժեցում', 'bn': 'এই পত্রিকা উইএমটি২০-এর জন্য আমাদের ভলিস্ট্রান্সের সিস্টেম বর্ণনা করেছে সংবাদ অনুবাদ করার কাজ। আমরা ৮ টি অনুবাদের দিকে অংশগ্রহণ করেছি। Our basic systems are based on Transformer (CITATION), into which we also employed new architectures (bigger or deeper Transformers, dynamic convolution).  শেষ সিস্টেমের মধ্যে লেখা পূর্ব প্রক্রিয়া, সাবওয়ার্ড (উদাহরণস্বরূপ BPE(CITATION)), বেস্টালাইন মডেল প্রশিক্ষণ, ইটেটেরেটিভ ব্যাক-অনুবাদ, মডেল এনস্পেল', 'ca': 'Aquest article descriu els nostres sistemes de presentació de VolcTrans per a la tasca de traducció compartida de notícies WMT20. Vam participar en 8 direccions de traducció. Els nostres sistemes bàsics estan basats en la Transformer (CITATION), en la qual també vam utilitzar noves arquitectures (transformadors més grans o més profunds, convolució dinàmica). Els sistemes finals inclouen pre-procés de text, subparaula(anomenada BPE(CITATION)), entrenament de model de base, retrotraducció iterativa, conjunt de models, distillació del coneixement i pre-entrenament multilingüe.', 'cs': 'Tento článek popisuje naše systémy odesílání pro sdílenou úlohu překladu zpráv VolcTrans pro WMT20. Podíleli jsme se na osmi překladatelských směrech. Naše základní systémy jsou založeny na Transformeru (CITATION), do kterého jsme použili i nové architektury (větší nebo hlubší transformátory, dynamická konvoluce). Konečné systémy zahrnují textový předproces, podslovo (také znám jako BPE(CITATION)), výcvik základního modelu, iterativní zpětný překlad, soubor modelů, destilaci znalostí a vícejazyčné předškolení.', 'bs': 'Ovaj papir opisuje naše podnosne sisteme za VolcTrans za zadatak WMT20 zajedničkog prevoda vijesti. Mi smo sudjelovali u 8 uputa za prevod. Naši osnovni sistemi su temeljeni na transformaciji (CITATION), u kojima smo također zaposlili nove arhitekture (veće ili dublje transformacije, dinamične konvolucije). Konačni sustavi uključuju predproces teksta, podriječ(poznat. BPE(CITATION)), osnovnu obuku model a, iterativni prevod natrag, model ensemble, destilaciju znanja i multijezičku predobuku.', 'et': 'Käesolevas artiklis kirjeldatakse meie VolcTrans esitamise süsteeme WMT20 jagatud uudiste tõlkimise ülesandeks. Osalesime 8 tõlkejuhises. Meie põhisüsteemid põhinevad Transformeril (CITATION), milles kasutasime ka uusi arhitektuure (suuremad või sügavamad Transformerid, dünaamiline konvolutsioon). Lõplikud süsteemid hõlmavad teksti eelprotsessi, alamsõna (teise nimega BPE(CITATION)), baasmudeli koolitust, iteratiivset tagantõlkimist, mudeli ansamblit, teadmiste destilleerimist ja mitmekeelset eelkoolitust.', 'fi': 'Tässä artikkelissa kuvataan VolcTrans for WMT20 jaettujen uutisten käännöstehtävien lähetysjärjestelmiämme. Osallistuimme kahdeksaan käännösohjeeseen. Perusjärjestelmämme perustuvat Transformeriin (CITATION), johon käytimme myös uusia arkkitehtuureja (isompia tai syvempiä Transformereita, dynaaminen konvoluatio). Lopullisia järjestelmiä ovat tekstin esikäsittely, alasana (alias BPE(CITATION)), perusmallin koulutus, iteratiivinen takaisinkääntäminen, mallikokonaisuus, tiedon tislaus ja monikielinen esikoulutus.', 'ha': "Wannan takardan na faɗaɗa'uwanmu na jẽfa na'urar da suka yi wa tsarin da za'a iya haɗa aikin aiki na fassarar da WMT20. Mun yi rabo da shirin fassarar 8. Tsarinmu masu bincike ne a kan Transformer (CITATIon), inda muka yi amfani da wasu matsayi na'ura (masu ƙaranci ko mafi ƙaranci Transformers, tsumarnin damƙari). Ga ƙarshen na'ura yana da matsayin gaba-go, subword(a.k. BPA(CITATItion)), mai amfani da misalin ayuka na ƙarƙashin, mai fassarar da baka-tarjiwa, motel ɗin fanel, salon da ilmi da kuma mai amfani da takardar-na-gaban-zaman-zaman harshe.", 'sk': 'Ta prispevek opisuje naše sisteme oddaje za VolcTrans za WMT20 skupno nalogo prevajanja novic. Sodelovali smo v 8 prevajalskih smereh. Naši osnovni sistemi temeljijo na transformatorju (CITATION), v katerega smo uporabili tudi nove arhitekture (večje ali globlje transformatorje, dinamična konvolucija). Končni sistemi vključujejo predhodni proces besedila, podbesedo (tudi BPE(CITATION)), osnovno usposabljanje modela, iterativno prevajanje nazaj, model ansambel, destilacijo znanja in večjezično predusposabljanje.', 'jv': 'Ngerungan iki oleh nggawe sistem nunggo buktuan kanggo volkTran kanggo WWC2 tahun tulis nggawe barang. Awakdhéwé njaluk tanggal 8 tarjamahan Sistem dadi sing dibenakake gunakake Transformer (CITITIon), dadi awak dhéwé ngulinakake architectures Anyar (lak gawe lan padha Transformer, convolution Dinamsing). Sistem sistem tuku nggawe mulai teks ro-perusahaan, apakno', 'he': 'העיתון הזה מתאר את מערכות ההעברה שלנו עבור VolcTrans עבור משימה התרגום חדשות משותפת WMT20. השתתפנו בשמונה כיוונות תרגום. המערכות הבסיסיות שלנו מבוססות על Transformer (CITATION), שבה גם השתמשנו בארכיטקטורות חדשות (Transformers גדולים או עמוקים יותר, שינוי דינמי). The final systems include text pre-process, subword(a.k.a. BPE(CITATION)), baseline model training, iterative back-translation, model ensemble, knowledge distillation and multilingual pre-training.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་VolcTrans(VolcTrans)རྩ་ལག་ཆ་སྤྲོད་ཀྱི་མ་ལག་གི་འགྲེལ་བཤད་ཀྱི་ཡོད། ང་ཚོས་སྐད་ཡིག་གཟུགས་ཕྱོགས་འགྲུལ་བཞིན་པའི་འགྲེལ་བཤད་ཆགས་པ་རེད། ང་ཚོའི་རྨང་གཞུང་གི་མ་ལག་གིས་གཞི་འདི་བཟོ་བརྒྱུད་པ(CITATION)དང་ནང་དུ་ང་ཚོས་ཀྱིས་བཟོ་བརྩིས་གསར་བ་ཞིག་ལས་ཀློག The final systems include text pre-process, subword(a.k.a. BPE(CITATION)), baseline model training, iterative back-translation, model ensemble, knowledge distillation and multilingual pre-training.'}
{'en': 'The NiuTrans Machine Translation Systems for WMT20', 'ar': 'أنظمة الترجمة الآلية NiuTrans لـ WMT20', 'pt': 'Os sistemas de tradução automática NiuTrans para WMT20', 'fr': 'Les systèmes de traduction automatique NiuTrans pour WMT20', 'es': 'Los sistemas de traducción automática de NiuTrans para WMT20', 'ja': 'WMT 20用のNiuTrans機械翻訳システム', 'zh': '宜用 WMT20 牛川机器翻译系统', 'hi': 'WMT20 के लिए NiuTrans मशीन अनुवाद प्रणाली', 'ru': 'Системы машинного перевода NiuTrans для WMT20', 'ga': 'Na Córais Aistriúcháin Meaisín NiuTrans do WMT20', 'ka': 'WMT20Name', 'el': 'Τα συστήματα μηχανικής μετάφρασης NiuTrans για το WMT20', 'hu': 'A NiuTrans gépi fordító rendszerek WMT20 számára', 'it': 'I sistemi di traduzione automatica NiuTrans per WMT20', 'lt': 'The NiuTrans Machine Translation Systems for WMT20', 'kk': 'WMT20 NiuTrans машинаны аудару жүйелеріName', 'mk': 'Системите за преведување на NiuTrans машина за WMT20', 'ms': 'Sistem Terjemahan Mesin NiuTrans untuk WMT20', 'mn': 'WMT20-ын NiuTrans машин орчуулах системүүд', 'ml': 'WMT20- നുള്ള നിയുTrans Mashine Translation Systems', 'mt': 'Is-Sistemi tat-Traduzzjoni tal-Makkinarju NiuTrans għad-WMT20', 'no': 'Name', 'ro': 'Sistemele de traducere automată NiuTrans pentru WMT20', 'sr': 'NiuTrans mašinske prevodne sisteme za WMT20', 'sv': 'NiuTrans maskinĂ¶versĂ¤ttningssystem fĂ¶r WMT20', 'pl': 'Systemy tłumaczenia maszynowego NiuTrans dla WMT20', 'ta': 'WMT20 க்கான நியும் மொழி மொழிபெயர்ப்பு அமைப்புகள்', 'si': 'WMT20Comment', 'so': 'Isticmaalka tarjumaadda ee NiuTrans machine for WMT20', 'ur': 'Name', 'uz': 'Name', 'vi': 'Hệ thống dịch máy Ngưu cho WM20', 'bg': 'Системите за машинен превод на NiuTrans за WMT20', 'hr': 'NiuTrans uređajski sustav prevoda za WMT20', 'nl': 'De NiuTrans Machine Translation Systemen voor WMT20', 'da': 'NiuTrans maskinoversættelsessystemer til WMT20', 'de': 'Die NiuTrans Machine Translation Systeme für WMT20', 'fa': 'سیستم ترجمه ماشین NiuTrans برای WMT20Name', 'ko': 'WMT20용 기계 번역 시스템', 'id': 'Sistem Translation Mesin NiuTrans untuk WMT20', 'af': 'Name', 'tr': 'WMT20 üçin NiuTrans Maşynyň terjime sistemleri', 'sq': 'Sistemet e Translacionit të Makinës NiuTrans për WMT20', 'sw': 'Mfumo wa Tafsiri wa Mashine ya NiuTrans kwa WMT20', 'am': 'The NiuTrans Machine Translation Systems for WMT20', 'hy': 'ՆիուTrans մեքենայի թարգմանման համակարգերը', 'az': 'WMT20 üçün NiuTrans mašin Çeviri Sistemləri', 'bn': 'WMT20 এর জন্য নিউট্রান্স মেশিন অনুবাদ সিস্টেম', 'bs': 'NiuTrans mašinski sustav prevoda za WMT20', 'et': 'NiuTrans masintõlke süsteemid WMT20 jaoks', 'cs': 'Strojové překlady NiuTrans pro WMT20', 'ca': 'Els sistemes de traducció de la màquina NiuTrans per a WMT20', 'fi': 'NiuTrans Machine Translation Systems for WMT20', 'sk': 'NiuTrans strojni prevajalski sistemi za WMT20', 'ha': 'Transform Machine Translate Systems for WMT20', 'jv': 'Ngenyarno Sistem Terusan niu Trans kanggo WW2AN', 'bo': 'WMT20 ལ་NiuTrans མ་ལག་གི་ཚིག་སྒྱུར་གྱི་མ་ལག་ལུགས་པ', 'he': 'מערכות התרגום של מכונות ניו-טרנס עבור WMT20'}
{'en': 'This paper describes NiuTrans neural machine translation systems of the WMT20 news translation tasks. We participated in Japanese-English, English-Chinese, Inuktitut-English and Tamil-English total five tasks and rank first in Japanese-English both sides. We mainly utilized iterative back-translation, different depth and widen model architectures, iterative knowledge distillation and iterative fine-tuning. And we find that adequately widened and deepened the model simultaneously, the performance will significantly improve. Also, iterative fine-tuning strategy we implemented is effective during adapting domain. For Inuktitut-English and Tamil-English tasks, we built multilingual models separately and employed pretraining word embedding to obtain better performance.', 'ar': 'تصف هذه الورقة أنظمة الترجمة الآلية العصبية NiuTrans لمهام ترجمة الأخبار WMT20. شاركنا في خمس مهام باللغات اليابانية - الإنجليزية ، والإنجليزية - الصينية ، والإنكتيتوت - الإنجليزية ، والتاميلية - الإنجليزية ، واحتلت المرتبة الأولى في اللغتين اليابانية والإنجليزية. لقد استخدمنا بشكل أساسي الترجمة الخلفية التكرارية ، وبنى النماذج المختلفة العميقة والواسعة ، وتقطير المعرفة التكراري والضبط الدقيق التكراري. ووجدنا أنه تم توسيع النموذج وتعميقه بشكل كافٍ في وقت واحد ، وسيتحسن الأداء بشكل كبير. أيضًا ، استراتيجية الضبط التكراري التي نفذناها فعالة أثناء تكييف المجال. بالنسبة لمهام Inuktitut-English و Tamil-English ، قمنا ببناء نماذج متعددة اللغات بشكل منفصل واستخدمنا تضمين الكلمات قبل التدريب للحصول على أداء أفضل.', 'fr': "Cet article décrit les systèmes de traduction automatique neuronale NiuTrans des tâches de traduction de nouvelles du WMT20. Nous avons participé en japonais-anglais, anglais-chinois, inuktitut-anglais et tamoul-anglais au total cinq tâches et nous nous classons premiers en japonais-anglais des deux côtés. Nous avons principalement utilisé la rétro-traduction itérative, différentes architectures de modèles de profondeur et d'élargissement, la distillation itérative des connaissances et le réglage fin itératif. Et nous constatons qu'en élargissant et en approfondissant le modèle simultanément, les performances s'amélioreront considérablement. De plus, la stratégie itérative de réglage fin que nous avons mise en œuvre est efficace pendant l'adaptation du domaine. Pour les tâches en inuktitut-anglais et en tamoul anglais, nous avons créé des modèles multilingues séparément et avons utilisé l'intégration de mots avant la formation afin d'obtenir de meilleures performances.", 'es': 'Este artículo describe los sistemas de traducción automática neuronal de NIUTrans de las tareas de traducción de noticias del WMT20. Participamos en japonés-inglés, inglés-chino, inglés inuktitut y tamil-inglés en un total de cinco tareas y ocupamos el primer lugar en japonés-inglés de ambos lados. Utilizamos principalmente retrotraducción iterativa, diferentes arquitecturas de modelos de profundidad y ampliación, destilación iterativa de conocimiento y ajuste iterativo. Y encontramos que al ampliar y profundizar adecuadamente el modelo simultáneamente, el rendimiento mejorará significativamente. Además, la estrategia iterativa de ajuste fino que implementamos es efectiva durante la adaptación del dominio. Para las tareas de inglés inuktitut y tamil-inglés, creamos modelos multilingües por separado y empleamos la incorporación de palabras de preentrenamiento para obtener un mejor rendimiento.', 'pt': 'Este artigo descreve os sistemas de tradução automática neural NiuTrans das tarefas de tradução de notícias WMT20. Participamos de Japonês-Inglês, Inglês-Chinês, Inuktitut-Inglês e Tamil-Inglês totalizando cinco tarefas e ficamos em primeiro lugar em Japonês-Inglês em ambos os lados. Utilizamos principalmente retrotradução iterativa, diferentes arquiteturas de modelo de profundidade e ampliação, destilação de conhecimento iterativo e ajuste fino iterativo. E descobrimos que adequadamente ampliado e aprofundado o modelo simultaneamente, o desempenho melhorará significativamente. Além disso, a estratégia iterativa de ajuste fino que implementamos é eficaz durante a adaptação do domínio. Para tarefas de inuktitut-inglês e tâmil-inglês, construímos modelos multilíngues separadamente e empregamos a incorporação de palavras pré-treinamento para obter melhor desempenho.', 'ja': '本稿では、WMT 20ニュース翻訳タスクのNiuTransニューラルマシン翻訳システムについて説明する。日英、英中、イヌクティトゥット英、タミル英の計5つの任務に参加し、日英双方で1位となった。主に、反復逆変換、異なる深さと幅のモデルアーキテクチャ、反復知識蒸留、反復微調整を利用しました。そして、モデルを同時に十分に広げ、深めていくことで、パフォーマンスが大幅に向上することがわかります。また、私たちが実施した反復微調整戦略は、ドメインの適応中に有効です。Inuktitut - EnglishとTamil - Englishのタスクでは、多言語モデルを別々に構築し、より良いパフォーマンスを得るために事前トレーニングの単語埋め込みを採用しました。', 'zh': '本文言WMT20新闻翻译任者NiuTrans神经机器翻译统。 与日语 - 英语,英语 - 中文,以纽特语 - 英语泰米尔语 - 英语五务,日语 - 英语中均第一。 主迭代反译,深广模架构,迭代知迭代调。 且吾见广大与深化模形同时,性将显著。 此外迭代微调之策,有效于域中者也。 其于纽特语-英语泰米尔-英语,各构言语模样,以预训练词嵌之。', 'ru': 'В данной статье описаны системы нейронного машинного перевода NiuTrans задач перевода новостей WMT20. Мы участвовали в японско-английском, английско-китайском, инуктитут-английском и тамильско-английском в общей сложности пять задач и занимаем первое место в японско-английской обеих сторон. Мы в основном использовали итеративный обратный перевод, различные глубинные и расширенные архитектуры моделей, итеративную дистилляцию знаний и итеративную тонкую настройку. И мы обнаружили, что адекватно расширив и углубив модель одновременно, производительность значительно улучшится. Кроме того, итеративная стратегия тонкой настройки, которую мы реализовали, эффективна при адаптации домена. Для задач Inuktitut-English и Tamil-English мы построили многоязычные модели отдельно и использовали встраивание слов для предварительной подготовки, чтобы получить лучшую производительность.', 'hi': 'यह पेपर WMT20 समाचार अनुवाद कार्यों के NiuTrans तंत्रिका मशीन अनुवाद प्रणालियों का वर्णन करता है। हमने जापानी-अंग्रेजी, अंग्रेजी-चीनी, इनुक्टिट्यूट-अंग्रेजी और तमिल-अंग्रेजी कुल पांच कार्यों में भाग लिया और जापानी-अंग्रेजी दोनों पक्षों में पहले स्थान पर रहे। हमने मुख्य रूप से पुनरावर्ती बैक-ट्रांसलेशन, अलग-अलग गहराई और व्यापक मॉडल आर्किटेक्चर, पुनरावर्ती ज्ञान आसवन और पुनरावर्ती ठीक-ट्यूनिंग का उपयोग किया। और हम पाते हैं कि पर्याप्त रूप से चौड़ा और एक साथ मॉडल को गहरा किया, प्रदर्शन में काफी सुधार होगा। इसके अलावा, पुनरावर्ती ठीक ट्यूनिंग रणनीति हम लागू डोमेन अनुकूलन के दौरान प्रभावी है. Inuktitut-English और तमिल-अंग्रेजी कार्यों के लिए, हमने बहुभाषी मॉडल अलग-अलग बनाए और बेहतर प्रदर्शन प्राप्त करने के लिए प्रीट्रेनिंग शब्द एम्बेडिंग को नियोजित किया।', 'ga': 'Déanann an páipéar seo cur síos ar chórais néar-aistrithe meaisín NiuTrans ar thascanna aistriúcháin nuachta WMT20. Ghlacamar páirt i gcúig thasc san iomlán Seapáinis-Béarla, Béarla-Sínis, Ionúitis-Béarla agus Tamil-Béarla agus rangaíodh muid ar dtús sa tSeapáinis-Béarla ar an dá thaobh. Bhaineamar úsáid den chuid is mó as aisaistriúchán atriallach, as doimhneacht éagsúil agus ag leathnú ailtireachta samhlacha, as driogadh atriallach eolais agus as mionchoigeartú atriallach. Agus feicimid go ndearnadh an múnla a leathnú agus a dhoimhniú go leordhóthanach ag an am céanna, feabhsóidh an fheidhmíocht go suntasach. Chomh maith leis sin, tá an straitéis mionchoigeartaithe atriallach a chuireamar i bhfeidhm éifeachtach le linn an fhearainn a oiriúnú. Maidir le tascanna Ionúitis-Bhéarla agus Tamailis-Béarla, thógamar samhlacha ilteangacha ar leithligh agus d’úsáideamar leabú focal réamhoiliúint chun feidhmíocht níos fearr a bhaint amach.', 'ka': 'Name ჩვენ წაპონი-ანგლისური, ანგლისური-კინგლისური, ინუკტიტური-ანგლისური და ტამილური-ანგლისური ყველაფერი ხუთი დავალებით და პირველი წაპონი-ანგლისურ ჩვენ ძირითად გამოიყენეთ ინტერატიგური წინასწორება, განსხვავებული სიმაღლე და გაფარდებული მოდელური აქტიქტურები, ინტერატიგური მეცნიერების დისტლიაცია და ინტერატიგური წინ და ჩვენ ვფიქრობთ, რომ მართლაც უფრო გაფართებული და უფრო გაფართებული მოდელის ერთადერთად, პროცექტი უფრო მნიშვნელოვანია. ასევე, ჩვენ ინომპლექტირებულიან სტრატიგური კონფიგურაციის სტრატიგია, რომელიც ჩვენ ინომპლექტირებულია ეფექტიურია დემო Inuktitut-English და Tamil-English პარამეტრებისთვის, ჩვენ მრავალენგური მოდელები განსაკუთრებულად დავყენეთ და ჩვენ მუშაობელად დავწყენეთ სიტყვები, რომელიც უფრო უფრო მ', 'el': 'Η παρούσα εργασία περιγράφει τα νευρωνικά συστήματα μηχανικής μετάφρασης των εργασιών μετάφρασης ειδήσεων WMT20. Συμμετείχαμε σε Ιαπωνικά-Αγγλικά, Αγγλικά-Κινέζικα, Ινουκτίτ-Αγγλικά και Ταμίλ-Αγγλικά συνολικά πέντε καθήκοντα και κατατάξαμε πρώτος στα Ιαπωνικά-Αγγλικά και στις δύο πλευρές. Χρησιμοποιήσαμε κυρίως επαναληπτική μεταγραφή, διαφορετικό βάθος και διευρύνσεις αρχιτεκτονικών μοντέλων, επαναληπτική απόσταξη γνώσεων και επαναληπτικό συντονισμό. Και διαπιστώνουμε ότι επαρκώς διευρύνθηκε και εμβάθυνε το μοντέλο ταυτόχρονα, η απόδοση θα βελτιωθεί σημαντικά. Επίσης, η επαναλαμβανόμενη στρατηγική συντονισμού που εφαρμόσαμε είναι αποτελεσματική κατά την προσαρμογή του τομέα. Για τα Αγγλικά και τα Ταμίλ-Αγγλικά καθήκοντα, χτίσαμε τα πολυγλωσσικά μοντέλα ξεχωριστά και χρησιμοποιήσαμε την ενσωμάτωση λέξεων προεπιλογής για να αποκτήσουμε καλύτερη απόδοση.', 'it': "Questo articolo descrive i sistemi neurali di traduzione automatica NiuTrans dei compiti di traduzione delle notizie WMT20. Abbiamo partecipato in giapponese-inglese, inglese-cinese, inuktitut-inglese e tamil-inglese complessivamente cinque compiti e siamo al primo posto in giapponese-inglese entrambe le parti. Abbiamo utilizzato principalmente la back-translation iterativa, diverse architetture di modelli di profondità e ampliamento, distillazione iterativa della conoscenza e messa a punto iterativa. E scopriamo che adeguatamente ampliato e approfondito il modello contemporaneamente, le prestazioni miglioreranno significativamente. Inoltre, la strategia iterativa di fine tuning che abbiamo implementato è efficace durante l'adattamento del dominio. Per le attività Inuktitut-English e Tamil-English, abbiamo costruito modelli multilingue separatamente e utilizzato il pre-training word embedding per ottenere prestazioni migliori.", 'hu': 'Ez a tanulmány a WMT20 hírfordítási feladatok NiuTrans neurális gépi fordítási rendszereit ismerteti. A japán-angol, angol-kínai, inuktitut-angol és tamil-angol nyelven vettünk részt, összesen öt feladatot, és mindkét oldalon első helyen álltunk a japán-angol nyelven. Elsősorban iteratív visszafordítást, különböző mélységű és kiterjesztett modellarchitektúrákat, iteratív tudás desztillációt és iteratív finomhangolást alkalmaztunk. És úgy találjuk, hogy megfelelően bővítették és elmélyítették a modell egyidejűleg, a teljesítmény jelentősen javulni fog. Emellett az általunk bevezetett iteratív finomhangolási stratégia hatékony a domain adaptációja során. Az Inuktitut-angol és tamil-angol feladatokhoz külön-külön többnyelvű modelleket építettünk, és a jobb teljesítmény érdekében előkészítettük a szóbeágyazást.', 'lt': 'Šiame dokumente aprašomos WMT20 naujienų vertimo darbų NiuTrans nervinių mašinų vertimo sistemos. Iš viso dalyvavome Japonijos-anglų, anglų-kinų, Inuktituto-anglų ir tamilų-anglų kalbose penkiose užduotyse ir pirmoji eilutė buvo Japonijos-anglų kalba abiejose pusėse. Mes daugiausia panaudojome pakartotinį vertimą atgal, skirtingą gilumą ir platesnę modelių architektūrą, pakartotinę žinių distiliaciją ir pakartotinį patobulinimą. And we find that adequately widened and deepened the model simultaneously, the performance will significantly improve.  Be to, mūsų įgyvendinama pakartotinė patobulinimo strategija yra veiksminga pritaikant sritį. Inuktitut-English ir Tamil-English užduotims mes atskirai sukūrėme daugiakalbius modelius ir panaudojome išankstinio mokymo žodžių įterpimą siekiant geresnių rezultatų.', 'ms': 'Kertas ini menggambarkan sistem terjemahan mesin saraf NiuTrans bagi tugas terjemahan berita WMT20. Kami berpartisipasi dalam bahasa Jepun-Inggeris, Inggeris-Cina, Inuktitut-Inggeris dan Tamil-Inggeris total lima tugas dan berturut pertama dalam bahasa Jepun-Inggeris kedua-dua sisi. Kami terutama menggunakan terjemahan-belakang iteratif, kedalaman yang berbeza dan mendalam arkitektur model, pengetahuan-pengetahuan iteratif dan penyesuaian-penyesuaian iteratif. Dan kami mendapati bahawa dengan cukup memperluas dan mendalam model secara bersamaan, prestasi akan meningkat secara signifikan. Juga, strategi penyesuaian peribadi yang kita laksanakan berkesan semasa menyesuaikan domain. Untuk tugas Inuktitut-Inggeris dan Tamil-Inggeris, kami membina model berbilang bahasa secara terpisah dan menggunakan penerbangan perkataan sebelum latihan untuk mendapatkan prestasi yang lebih baik.', 'mk': 'Оваа вест ги опишува системите за превод на невропски машини на NiuTrans од задачите за превод на вестите на WMT20. Учествувавме на јапонско-англиски, англиски-кинески, инуктитут-англиски и тамилски-англиски вкупно пет задачи и се рангиравме први на јапонско-англиски двете страни. Главно користевме итеративен превод, различна длабочина и широка моделна архитектура, итеративна дистилација на знаење и итеративно финетирање. И откриваме дека соодветно го проширивме и го длабочивме моделот истовремено, резултатите значително ќе се подобрат. Исто така, итеративната стратегија за подобрување што ја спроведовме е ефикасна за време на адаптацијата на доменот. За инуктитут-англиски и тамиланглиски задачи, ние изградивме мултијазични модели одделно и употребивме претренинг збор вграден за да добиеме подобра изведба.', 'kk': 'Бұл қағаз WMT20 жаңалық аудару тапсырмаларының NiuTrans невралдық компьютерді аудару жүйелерін анықтайды. Name Біз жапон-ағылшын, ағылшын-қытайлық, инуктитут-ағылшын және тамилық-ағылшын тілінде бес тапсырмалар және бірінші жапон-ағылшын тілінде қатынасыз. Біз негізінде қайта аудару, түрлі тереңдік және кеңейтілген үлгі архитектураларды, қайта- түрлі білім дистилациясы және қайта- түрлі дұрыс баптауларын қолдандық. Біз үлгісін бірден жеткілікті жаю және түсіндіру керек деп ойлаймыз, әрекеттер өте жақсы жасайды. Сонымен қатар, біз іске асырып тұрған қайталау стратегиясы доменді адаптау кезінде эффективті. Инуктитут-ағылшын және тамил-ағылшын тапсырмалар үшін біз көптілік моделдерді бөлек құрып, жақсы істеу үшін енгізген сөздерді қолдану үшін көптілік моделдерді құры', 'ml': 'ഈ പത്രത്തില്\u200d നിയുട്ടാന്\u200d നിയുട്രാന്\u200d ന്യൂറല്\u200d മെഷീന്\u200d പരിശോധന സിസ്റ്റം വിവരിക്കുന്നു. WMT20 വാര്\u200dത്ത വി ഞങ്ങള്\u200d ജപ്പാനീസ്-ഇംഗ്ലീഷ്, ഇംഗ്ലീഷ്-ചൈനീസ്, ഇംഗ്ലീഷ്-ഇംഗ്ലീഷ്, താമില്\u200d-ഇംഗ്ലീഷ് മൊത്തം അഞ്ചു ജോലികളിലും പ പ്രധാനപ്പെട്ട വസ്തുക്കളുടെ പിന്നിലുള്ള പരിഭാഷങ്ങള്\u200d, വ്യത്യസ്തമായ ആഴത്തിലും വിശാലമായ മോഡല്\u200d ആര്\u200dക്കിട്ടുകള്\u200d, സ്ഥിതിവേക ജ പിന്നെ ഞങ്ങള്\u200d കണ്ടെത്തുന്നത് പ്രധാനപൂര്\u200dണ്ണമായും വിശാലമായും ഒരേ സമയത്ത് മോഡലിനെ ആഴത്തിലാക്കുകയും ചെയ്താല്\u200d പ പിന്നെ നമ്മള്\u200d പ്രവര്\u200dത്തിപ്പിച്ചിരിക്കുന്ന ഗുണപൂര്\u200dണ്ണമായ യോജ്യം ഡൊമെയിനെ മാറ്റുമ്പോള്\u200d പ്ര ഇംഗ്ലീഷ്-ഇംഗ്ലീഷിലേയും താമില്\u200d-ഇംഗ്ലീഷിലേയും ജോലികള്\u200dക്കും വേണ്ടി ഞങ്ങള്\u200d പല ഭാഷ മോഡലുകള്\u200d നിര്\u200dമ്മിച്ചു. വേര്\u200dതിരി', 'pl': 'Niniejszy artykuł opisuje neuronowe systemy tłumaczenia maszynowego NiuTrans dla zadań tłumaczenia wiadomości WMT20. Uczestniczyliśmy w pięciu zadaniach japońsko-angielskich, angielsko-chińskich, inuktitut-angielskich oraz tamilsko-angielskich i mieliśmy pierwsze miejsce w japońsko-angielskim obu stronach. Wykorzystaliśmy głównie iteracyjne tłumaczenie wsteczne, różną głębokość i poszerzenie architektur modeli, iteracyjną destylację wiedzy i iteracyjne dostrajanie. I okazujemy, że odpowiednio poszerzony i pogłębiony model jednocześnie, wydajność znacznie poprawi. Również wdrożona przez nas strategia iteracyjnego dostrajania jest skuteczna podczas adaptacji domeny. Do zadań Inuktitut-English i Tamil-English zbudowaliśmy oddzielnie wielojęzyczne modele i zastosowaliśmy wstępne osadzenie słów, aby uzyskać lepszą wydajność.', 'ro': 'Această lucrare descrie sistemele neurale de traducere automată NiuTrans ale sarcinilor de traducere a știrilor WMT20. Am participat în limbile japoneză-engleză, engleză-chineză, inuktitut-engleză și tamil-engleză total cinci sarcini și ocupă primul loc în japoneză-engleză ambele părți. Am folosit în principal traducerea iterativă înapoi, arhitecturile modelului diferite de adâncime și lărgire, distilarea iterativă a cunoștințelor și reglarea fină iterativă. Și constatăm că modelul lărgit și aprofundat în mod adecvat simultan, performanța se va îmbunătăți semnificativ. De asemenea, strategia iterativă de reglare fină implementată este eficientă în timpul adaptării domeniului. Pentru sarcinile Inuktitut-engleză și tamil-engleză, am construit modele multilingve separat și am folosit încorporarea prealabilă a cuvintelor pentru a obține performanțe mai bune.', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi tat-traduzzjoni tal-magni newrali NiuTrans tal-kompiti tat-traduzzjoni tal-aħbarijiet tad-WMT20. Parteċipajna f’ħames kompiti Ġappuniż-Ingliż, Ingliż-Ċiniż, Inuktitut-Ingliż u Tamil-Ingliż u kklassifikajna l-ewwel fiż-żewġ naħat Ġappuniż-Ingliż. Aħna użajna prinċipalment it-traduzzjoni lura iterattiva, arkitetturi differenti ta’ fond u mudelli wiesgħa, distillazzjoni ta’ għarfien iterattiv u rfinar iterattiv. U nsibu li l-mudell imwessa’ u approfondit b’mod adegwat fl-istess ħin, il-prestazzjoni se titjieb b’mod sinifikanti. Barra minn hekk, l-istrateġija ta’ rfinar iterattiv li implimentajna hija effettiva waqt l-adattament tad-dominju. Għall-kompiti Inuktitut-Ingliż u Tamil-Ingliż, inbnejna mudelli multilingwi separatament u impjegajna l-inkorporazzjoni ta’ kliem ta’ taħriġ minn qabel biex inkisbu prestazzjoni aħjar.', 'mn': 'Энэ цаас WMT20 мэдээллийн хөрөнгө оруулах ажлын NiuTrans мэдрэлийн мэдрэлийн машин хөрөнгө оруулах системийг тайлбарладаг. Бид Япон-Англи, Англи-Хятад, Инуктитут-Англи, Тамил-Англи хоёр талд анх таван ажлын хувьд оролцсон. Бид ихэнхдээ эргээд орчуулах, өөр гүн гүнзгий, өргөн загварын архитектур, итератив мэдлэгтэй сайжруулах, дахин давтагдах загварыг ашигласан. Бид загварыг адилхан өргөн, гүн гүнзгий болгож, үйл ажиллагаа маш чухал сайжруулах болно. Мөн бидний дасгал хийсэн дасгал хөгжүүлэх стратегийг зохион байгуулах үед үр дүнтэй болгодог. Inuktitut-Англи, Тамил-Англи хэлний ажлын тулд бид олон хэлний загвар бүтээсэн ба илүү сайн үйл ажиллагааны тулд нэмэгдсэн үг бий болгосон.', 'no': 'Name Vi deltok på japansk-engelsk, engelsk-kinesisk, Inuktitut-engelsk og Tamil-engelsk totalt fem oppgåver og rankerer først på begge sider i japansk-engelsk. Vi brukte hovudsakelig iterativ tilbakeomsetjing, ulike dybde og breidde modellerarkitektur, iterativ kunnskapsdistillasjon og iterativ finnstilling. Og vi finn at tilstrekkelig utvida og dyppa modellen samtidig, vil utviklinga betydelig forbetra. I tillegg til domene er det også effektivt gjennomsetjingsstrategi vi implementerte. For innuktitut-engelsk og Tamil-engelsk oppgåver bygge vi fleirspråk modeller separat og arbeidsgivert foretrekking av ord som innebygger for å få bedre utvikling.', 'sv': 'Denna uppsats beskriver NiuTrans neurala maskinﾃｶversﾃ､ttningssystem fﾃｶr WMT20 nyhetsﾃｶversﾃ､ttningsuppgifter. Vi deltog i japansk-engelska, engelsk-kinesiska, inuktitut-engelska och tamil-engelska totalt fem uppgifter och rankas fﾃｶrst pﾃ･ japansk-engelska bﾃ･da sidor. Vi anvﾃ､nde frﾃ､mst iterativ bakﾃ･tﾃｶversﾃ､ttning, olika djup- och breddarkitekturer, iterativ kunskapsdestillation och iterativ finjustering. Och vi finner att tillrﾃ､ckligt vidgade och fﾃｶrdjupade modellen samtidigt, prestandan kommer att fﾃｶrbﾃ､ttras avsevﾃ､rt. Dessutom ﾃ､r iterativ finjusteringsstrategi vi implementerat effektiv vid anpassning av domﾃ､nen. Fﾃｶr Inuktitut-engelska och tamil-engelska uppgifter byggde vi flersprﾃ･kiga modeller separat och anvﾃ､nde fﾃｶrklﾃ､dnad av ord fﾃｶr att uppnﾃ･ bﾃ､ttre prestanda.', 'sr': 'Ovaj papir opisuje NiuTrans neuromašinske sisteme prevoda WMT20 novinskih zadataka za prevod. Učestvovali smo na japanski-engleski, engleski-kineski, inuktitut-engleski i tamilski-engleski ukupno pet zadataka i prvi su na japanskom-engleskom obje strane. Uglavnom smo iskoristili iterativni povratni prevod, različite dubine i šire modele arhitekture, destilaciju iterativnih znanja i iterativno fino podešavanje. A mi smatramo da će to odgovarajuće proširiti i dubljati model istovremeno, izvedba značajno poboljšati. Takođe, iterativna strategija za finaliziranje koje smo proveli je efikasna tokom prilagodbe domena. Za Inuktitut-engleski i Tamil-engleski zadatak, izgradili smo višejezičke modele odvojeno i zaposleni pretvarajući riječ uključujući se da bi dobili bolju izvedbu.', 'si': 'Name අපි ජාපාන්-ඉංග්\u200dරීසි, ඉංග්\u200dරීසි-චීනි, ඉංග්\u200dරීසිය, තාමිල් ඉංග්\u200dරීසියේ සම්පූර්ණ වැඩ 5ක් සහ ජාපා අපි විශේෂයෙන් ප්\u200dරමාණයෙන් පිටිපස්සෙන් පස්සෙන් භාවිත කරලා තියෙන්නේ, වෙනස් ගොඩක් හා විශාල විශාල ස්ථාපනය අපිට හොයාගන්න පුළුවන් විශාල විශාල කරලා මොඩේල් එක්කෙනෙක් ගොඩක් විශාල කරලා තියෙනවා, ප්\u200dරවේශ ඒවගේම, අපි පරීක්ෂණය කරලා තියෙන්නේ ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක විද්\u200dයාත්මක විද්\u200dය ඉනුක්ටිටුට්-ඉංග්\u200dරීසි සහ ටැමිල්-ඉංග්\u200dරීසි වැඩක් වෙනුවෙන්, අපි ගොඩක් භාෂාවක් මොඩේල් හදලා තියෙන්නේ විත', 'so': 'Kanu waa qoraal ku qoran NiuTrans neural machine translation systems of the WMT20 news translation tasks. Waxaannu ka qeybqaadanay jabanees-Ingiriis, Ingiriis-Shiino, Inuktitut-Ingiriis iyo Tamil-Ingiriis dhammaantiis shan shaqo oo heer ugu horeysa labada dhinac ee Jabanees-Ingiriis. ugu horeyna waxaynu isticmaalnay waxyaabaha dib-turjumida, moolka kala duduwan iyo dhismaha model oo ballaadhan, isbedelka aqoonta iyo sawirida farsamada. Waxaynu ognahay in tusaalka si ku filan u ballaadhay oo u hoos geli karo isla markaasna horumarinta ayaa si weyn u kordhin doona. Also, iterative fine-tuning strategy we implemented is effective during adapting domain.  Shaqooyinka Inuktitut-Ingiriis iyo Tamil-Ingiriis ayaannu dhisnay tusaalooyin luuqado kala duduwan oo gooni ah, waxaana shaqeynay hadal ka soo baxaya si aan u helno shaqo wanaagsan.', 'ur': 'This paper describes NiuTrans neural machine translation systems of the WMT20 news translation tasks. ہم نے جاپانی-انگلیسی, انگلیسی-چینی, انگلیسی-انگلیسی اور تامیل-انگلیسی میں پانچ کام شریک کیا اور سب سے پہلے جاپانی-انگلیسی کے دونوں جانب میں رقم کیا۔ ہم نے عمدہ طور پر دوبارہ پیچھے ترجمہ کی استعمال کی، مختلف عمیق اور وسیع مدل معماری، دوبارہ علم کی تفریق اور دوبارہ تفریق کی۔ اور ہم دیکھتے ہیں کہ ایک دفعہ موڈل کو اچھی طرح پھیلایا اور عمدہ کردیا جائے گا، عمدہ اچھی طرح بہتر ہوگا۔ اور ہم نے دوبارہ نیک تنظیم استراتژی کو اضافہ کرنے کے موقع موثر ہے۔ Inuktitut-English and Tamil-English tasks for, we built multilingual models separately and used pretraining word embedding to obtain better performance.', 'ta': 'WMT20 செய்தி மொழிபெயர்ப்பு பணிகளின் நியுTrans புதிய இயந்திரம் மொழிபெயர்ப்பு அமைப்புகளை விளக்குகிறது. நாங்கள் ஜப்பானிஸ்- ஆங்கிலம், ஆங்கிலம்- சீனா, இனுக்டிட்ட்- ஆங்கிலம் மற்றும் டாமில்- ஆங்கிலம் மொத்தம் ஐந்து பணிகள் மற்றும நாங்கள் முக்கியமாக பின்பு மொழிபெயர்ப்பை பயன்படுத்தி வித்திய ஆழம் மற்றும் வித்தியாசமான மாதிரி உருவாக்கங்கள், உருவாக்க அறிவு  போதுமான மாதிரியை அதிகப்படுத்தி அதிகமாக ஆழமாக்குகிறது என்பதை நாம் கண்டுபிடிக்கிறோம், இந்த செயல்பாடு முக்கியம மேலும், நாம் செயல்படுத்தப்பட்ட சிறந்த துணுக்கும் திட்டத்திற்கு பயன்படுத்தப்பட்டுள்ளது களமை மாற்றும்  இனுக்கிட்டிட்- ஆங்கிலம் மற்றும் டாமில்- ஆங்கிலம் பணிகளுக்கு, நாங்கள் பல மொழி மாதிரிகளை தனியாக உருவாக்கி வேலை செய்து சிறந்த', 'vi': 'Tờ giấy này mô tả hệ thống dịch chuyển máy thần kinh bất dịch của WM20. Chúng tôi tham gia ở Nhật-Anh, Anh-Trung Quốc, Em-Anh và Tamil-Anh. Năm nhiệm vụ và đứng thứ nhất ở Nhật-Anh. Chúng tôi chủ yếu sử dụng phiên bản dịch ngược, độ sâu khác nhau và mở rộng các kiến trúc mẫu, chưng cất tri thức lặp lại và độ chín. Và chúng tôi thấy rằng mô hình đã được mở rộng và sâu sắc thích hợp đồng thời, hiệu quả sẽ cải thiện đáng kể. Thêm nữa, chiến lược lặp lại độ cẩn thận chúng ta thực hiện hiệu quả trong việc thích nghi. Đối với công việc Inuktit-English và Tamil-English, chúng tôi đã xây dựng các mẫu đa dạng riêng biệt và tuyển dụng sửa đổi từ ngữ để có hiệu suất tốt hơn.', 'uz': "Bu qogʻoz WMT20 news translation vazifalarining NiuTrans neyural maskin tarjima tizimlarini anglatadi. Biz Yaponchadan Inglizcha, inglizcha xitoycha, Inuktitut- Inglizcha va Tamil- Inglizchaga hamma 5 vazifalar bilan birinchi vazifalar va yaponcha- Inglizchaga birinchi darajaga ega bo'lgan. We mainly utilized iterative back-translation, different depth and widen model architectures, iterative knowledge distillation and iterative fine-tuning.  Biz o'ylaymiz, bu modelni juda yetarli ko'paytirishni va o'sha paytda, bajarishi juda ko'paytiriladi. Bu yerda, biz ishga tushirilgan yaxshi ko'proq strategiya domen o'zgartirishda ishlaydi. Inuktitut-Ingliz va Tamil-Ingliz ish vazifalari uchun biz bir tillar modellarini alohida yaratdik va yaxshi bajarish uchun bir so'zni ishlayotgan so'zlarni ishlab chiqardik.", 'da': 'Denne artikel beskriver NiuTrans neurale maskinoversættelsessystemer for WMT20 nyhedsoversættelsesopgaver. Vi deltog i japansk-engelsk, engelsk-kinesisk, inuktitut-engelsk og tamil-engelsk i alt fem opgaver og rangerer første i japansk-engelsk begge sider. Vi brugte hovedsageligt iterativ back-translation, forskellig dybde og udvide modelarkitekturer, iterativ viden destillation og iterativ finjustering. Og vi finder, at tilstrækkeligt udvidet og uddybet modellen samtidig, vil ydeevnen forbedres betydeligt. Også iterativ finjusteringsstrategi, vi implementerede, er effektiv under tilpasning af domæne. Til Inuktitut-engelsk og tamil-engelsk opgaver byggede vi flersprogede modeller separat og anvendte forudgående ordindlejring for at opnå bedre ydeevne.', 'nl': 'Dit artikel beschrijft NiuTrans neurale machine translation systemen van de WMT20 nieuwsberichten vertaaltaken. We hebben deelgenomen aan Japans-Engels, Engels-Chinees, Inuktitut-Engels en Tamil-Engels totaal vijf taken en staan op de eerste plaats in Japans-Engels beide kanten. We gebruikten voornamelijk iteratieve back-translation, verschillende diepte- en verbredingsmodellen, iteratieve kennisdistillatie en iteratieve fine-tuning. En we vinden dat adequaat verbreed en verdiept het model tegelijkertijd, de prestaties aanzienlijk zullen verbeteren. Ook is de iteratieve fine-tuning strategie die we hebben geïmplementeerd effectief tijdens het aanpassen van het domein. Voor Inuktitut-Engels en Tamil-Engels taken bouwden we meertalige modellen afzonderlijk en gebruikten we pretraining woord embedding om betere prestaties te verkrijgen.', 'bg': 'Тази статия описва невронните системи за машинен превод на новините от WMT20. Участвахме в японско-английски, английско-китайски, инуктиту-английски и тамилско-английски общо пет задачи и се класирахме първи в японско-английски и двете страни. Използвахме главно итеративен обратен превод, различна дълбочина и разширена архитектура на модела, итеративна дестилация на знанието и итеративна фина настройка. И откриваме, че адекватно разширени и задълбочени модела едновременно, производителността ще се подобри значително. Също така, итеративната стратегия за фина настройка, която внедрихме, е ефективна при адаптиране на домейна. За задачите на Инуктитут-английски и Тамил-английски създадохме многоезични модели отделно и използвахме предварително вграждане на думи, за да получим по-добра производителност.', 'id': 'Kertas ini menjelaskan sistem terjemahan mesin saraf NiuTrans dari tugas terjemahan berita WMT20. Kami berpartisipasi dalam bahasa Jepang-Inggris, Inggris-Cina, Inuktitut-Inggris dan Tamil-Inggris total lima tugas dan rank pertama dalam bahasa Jepang-Inggris kedua sisi. We mainly utilized iterative back-translation, different depth and widen model architectures, iterative knowledge distillation and iterative fine-tuning.  Dan kami menemukan bahwa dengan cukup memperluas dan mendalam model secara bersamaan, prestasi akan meningkat. Juga, strategi penyesuaian iteratif yang kita implementasikan adalah efektif selama mengadaptasi domain. For Inuktitut-English and Tamil-English tasks, we built multilingual models separately and employed pretraining word embedding to obtain better performance.', 'de': 'Diese Arbeit beschreibt NiuTrans neuronale maschinelle ﾃ彙ersetzungssysteme der WMT20 Nachrichtenﾃｼbersetzungsaufgaben. Wir nahmen an insgesamt fﾃｼnf Aufgaben teil und belegen den ersten Platz im Japanisch-Englisch auf beiden Seiten. Wir verwendeten hauptsﾃ､chlich iterative Rﾃｼckﾃｼbersetzung, unterschiedliche Tiefen- und Erweiterungsmodellarchitekturen, iterative Wissensdestillation und iterative Feinabstimmung. Und wir finden, dass angemessen erweitert und vertieft das Modell gleichzeitig, die Leistung deutlich verbessert wird. Auch die von uns implementierte iterative Feinabstimmungsstrategie ist bei der Anpassung der Domain effektiv. Fﾃｼr Inuktitut-Englisch und Tamil-Englisch Aufgaben haben wir mehrsprachige Modelle separat erstellt und Worteinbettungen im Vortraining eingesetzt, um eine bessere Leistung zu erzielen.', 'hr': 'Ovaj papir opisuje NiuTrans neuronske sustave prevoda za WMT20 vijesti. Učestvovali smo na japanski-engleski, engleski-kineski, inuktitut-engleski i tamilski-engleski ukupno pet zadataka i prvi su na japanskom-engleskom obje strane. Uglavnom smo iskoristili iterativni povratni prevod, različite dubine i šire modele arhitekture, destilaciju iterativnih znanja i iterativno fino ispravljanje. A mi smatramo da će odgovarajući proširiti i dubljati model istovremeno, izvedba značajno poboljšati. Također je iterativna strategija za finaliziranje koje smo proveli učinkovita tijekom prilagođenja domena. Za Inuktitut-engleski i Tamil-engleski zadatak, izgradili smo višejezičke modele odvojeno i zaposleni pretkivanje riječi uključujući se kako bi dobili bolju učinku.', 'ko': '본고는 WMT20 뉴스 번역 임무의 신경 기계 번역 시스템을 묘사하였다.우리는 일본어, 영어, 중국어, 뉴트인 영어와 테밀어 영어 등 총 다섯 가지 임무에 참가했고 일본어와 영어 분야에서 모두 1위를 차지했다.우리는 주로 교체 반역, 서로 다른 깊이와 넓이의 모델 구조, 교체 지식 추출과 교체 미조를 이용했다.우리는 동시에 모델을 충분히 넓히고 심화시키면 성능이 현저히 향상될 것이라는 것을 발견했다.그 밖에 우리가 실현한 교체 마이크로스피커 전략은 자체 적응 영역에서 효과적이다.뉴트릭의 영어와 테밀어의 영어 임무에 따라 우리는 각각 다국어 모델을 구축하고 단어 삽입을 미리 훈련하여 더욱 좋은 성능을 얻었다.', 'fa': 'این کاغذ سیستم ترجمه\u200cهای ماشین عصبی NiuTrans را توصیف می\u200cکند از کار ترجمه\u200cهای خبری WMT20. ما به ژاپن-انگلیسی، انگلیسی-چینی، انگلیسی-انگلیسی و تامیل-انگلیسی مشارکت کردیم، و در هر دو طرف اول پنج کاری در ژاپن-انگلیسی است. ما عموماً ترجمه پشتی، عمیق و معماری مدل گسترده را استفاده کرده\u200cایم، جدا کردن دانش\u200cهای تکرار و تنظیم\u200cکننده\u200cای دوباره. و ما فهمیدیم که مدل را به اندازه کافی گسترش داده و عمیق کرد، عملکرد بسیار بهتر خواهد شد. همچنین استراتژی تغییر تغییر دهنده\u200cای که ما انجام دادیم در زمان تغییر دادن دامنه موثر است. برای وظیفه\u200cهای انگلیسی و تامیل-انگلیسی، ما مدل\u200cهای زیادی زبان را جدا ساختیم و کلمه\u200cهای زیادی را استخدام کردیم که برای انجام بهتر استفاده می\u200cکنند.', 'sw': 'Gazeti hili linaelezea mfumo wa utafsiri wa mashine ya ubongo wa NiuTrans wa kazi za tafsiri za habari za WMT20. Tumeshiriki katika kazi tano na nafasi ya kwanza katika pande zote za Kijapani-Kiingereza, Kiingereza, Kiuktitut-Kiingereza na Kitamil-Kiingereza. Tulitumia zaidi kutafsiri vifaa vya nyuma, kina cha kina na maendeleo mengi ya mifano, utofauti wa maarifa makubwa na usawa wa vizuri. Na tunagundua kuwa uliongezeka kwa kiasi kikubwa na kuingiza mtindo huo kwa wakati mmoja, utendaji utaendelea kwa kiasi kikubwa. Also, iterative fine-tuning strategy we implemented is effective during adapting domain.  Kwa kazi za Kiingereza na Kiingereza na Kitamil-Kiingereza, tulijenga mifano ya lugha mbalimbali kwa tofauti na kutumika maneno yanayoingia ili kupata ufanisi bora zaidi.', 'tr': 'Bu kagyz WMT20 täzelikler täzelikleriniň NiuTrans neiral maşynyň terjime sistemlerini tassyýar. Biz Japonça-Iňlisçe, iňlisçe-Çin çe, Inuktitut-Iňlisçe we Tamil-Iňlisçe hem beş işleri we hem iňlisçe ilkinji gezek japonça-iňlis dilinde bäsleşirdik. Biz adatça iteratiw arka terjime edilen, farklı derinlikler we geniş nusgalar, iteratiw bilgi duýulamak we iterativ şekillerini ulandyk. Biz bu modelini bir gezek derecede genişletip, düzümlendirdik, eserleşmek örän gowurak bolar. Ayrıca, biziň implementetimiz tekrarat iňleşik taýýarlama stratejiýasy domeny üýtgetmekde täsirlidir. Inuktitut-Iňlisçe we Tamil-Iňlisçe işleri üçin biz gowy etmäge köp dilli nusgalary guradyk we köp dilli nusgalary diýip işleýärdik.', 'af': 'Hierdie papier beskryf NiuTrans neural masjien vertaling stelsels van die WMT20 nuusvertaling taak. Name Ons het gedeel in Japanse-Engels, Engels-Sjinese, Inuktitut-Engels en Tamil-Engels totaal vyf taak en eerste in Japanse-Engels in beide kante. Ons het heeltemal iteratiewe terugvertaling gebruik, verskillende diepte en breedte modele arkitektuur, iteratiewe kennis destilasie en iteratiewe fyn-tuning. En ons vind dat die model gelukkig vergroot en diepteer het, sal die prestasie betekens verbeter. Ook, iteratiewe fine-tuning strategie wat ons implementeer is effektief tydens aanpassing van domein. Vir Inuktitut-Engels en Tamil-Engels-opdragte het ons multitaalse modele geskillig gebou en werklik voortrek woord ingesluit om beter prestasie te kry.', 'sq': 'Ky artikull përshkruan sistemet e përkthimit nervor të makinave NiuTrans të detyrave të përkthimit të lajmeve WMT20. Ne morëm pjesë në japonezë-anglisht, anglisht-kinez, Inuktitut-anglisht dhe tamil-anglisht pesë detyra të përgjithshme dhe renditëm së pari në japonezë-anglisht të dy palët. Ne përdorim kryesisht përkthimin e përsëritur, thellësinë e ndryshme dhe arkitekturat e modelit të zgjeruar, distillacionin e njohurive të përsëritura dhe rregullimin e përsëritur. Dhe ne gjejmë se duke zgjeruar dhe thelluar në mënyrë të përshtatshme modelin në të njëjtën kohë, performanca do të përmirësohet ndjeshëm. Gjithashtu, strategjia e përshtatjes së përsëritur që zbatuam është e efektshme gjatë përshtatjes së domenit. Për detyrat Inuktitut-Anglisht dhe Tamil-Anglisht, ne ndërtuam modele shumëgjuhëse në mënyrë të veçantë dhe përdorëm fjalë paramësuese të përfshira për të fituar performancë më të mirë.', 'am': 'ይህ ፕሮግራም ኒዩTrans የነዌራዊ machine translation systems የWMT20 ዜና ትርጓሜ ስራዎችን ይገልጻል፡፡ በጃፓንኛ-እንግሊዘኛ፣ እንግሊዘኛ-ቻይና፣ ኢንቁስቲ-እንግሊዘኛ እና ታሚሊ-ኢንጂልኛ ላይ አምስት ስራ እና በመጀመሪያ በጃፓንኛ-እንግሊዘኛ ክፍል ተጋጅተናል፡፡ በተለየን ትርጉም፣ ልዩ ጥልቅ እና ሰፋፊ ሞዴል መሠረት፣ እውቀት ማውቀትን እና መፍጠርን በመጠቀም ነው፡፡ እናም በኩል ስፋት እና ምሳሌውን በተጨማሪው እና አግኝተናል፣ የሥርዓቱ ትክክል ይሻላል፡፡ ደግሞም፣ የተፈጸመውን የመልካም ጥያቄ ስርዓት ከዶሜን በመቀነስ ጥሩ ነው፡፡ ለኢንቁስቲ-እንግሊዘኛ እና ትሚሊ-እንግሊዘኛ ስራ፣ ለብቻው የቋንቋ ዓይነቶችን ሠራን እና የተሻለ ውጤት ለማግኘት የዘፈን ቃላትን ለመፍጠር አሠራን፡፡', 'hy': 'This paper describes NiuTrans neural machine translation systems of the WMT20 news translation tasks.  Մենք մասնակցեցինք ճապոներեն-անգլերեն, անգլերեն-չինարեն, ինուկտիտուտ-անգլերեն և թամիլ-անգլերեն համակարգով հինգ խնդիր և առաջինը դասավորվեցինք ճապոներեն-անգլերեն երկու կողմերում: Մենք հիմնականում օգտագործեցինք կրկնօրինակ թարգմանություն, տարբեր խորություններ և տարածված մոդելների ճարտարապետություն, կրկնօրինակ գիտելիքների դիսլիլացիա և կրկնօրինակ բարելավումներ: Եվ մենք հայտնաբերում ենք, որ միաժամանակ մոդելը բավականաչափ ընդլայնված և խորացված է, արդյունքները կբարելավվեն: Ավելին, մեր իրականացված կրկնվող փոփոխական ռազմավարությունը արդյունավետ է բնագավառի հարմարեցման ընթացքում: Ինուկտիտուտ-անգլերեն և թամիլ-անգլերեն խնդիրների համար մենք առանձին ստեղծեցինք բազմալեզու մոդելներ և օգտագործեցինք նախադասական բառեր, որոնք ներգրավված էին ավելի լավ արտադրողականության համար:', 'bn': 'এই পত্রিকা নিউট্রান্স নিউরাল মেশিন অনুবাদ সিস্টেমের ব্যাখ্যা করেছে WMT20 সংবাদ অনুবাদের কাজের। আমরা জাপানী-ইংরেজী, ইংরেজী-চীন, ইনকুক্তিটি-ইংরেজী এবং তামিল-ইংরেজি মোট পাঁচ কাজ এবং প্রথমে জাপানী ও ইংরেজি দুই পক্ষে  আমরা বিভিন্ন গভীর এবং প্রশস্ত মডেল কাঠামো ব্যবহার করেছি, বৈশিষ্ট্যাবলী জ্ঞান বিচ্ছিন্ন করা এবং বিন্যাসের সুনির্দিষ্ট ভাবে ব আর আমরা দেখতে পাচ্ছি যে মডেলটি যথেষ্ট বিস্তারিত এবং একই সাথে গভীরভাবে বৃদ্ধি করেছে, এই প্রদর্শনের কার্যকলাপ গুরুত্ব এছাড়াও, আমরা প্রযুক্তিগত ভালো টুনিং কৌশল প্রয়োগ করেছি ডোমেইনের মাধ্যমে কার্যকর। ইনুক্তিতি-ইংরেজী এবং তামিল-ইংরেজী কাজের জন্য আমরা বিভিন্ন ভাষায় বহুভাষার মডেল তৈরি করেছি এবং ভালো প্রদর্শনের জন্য বাক্যের প', 'az': 'Bu kağıt WMT20 xəbər çeviri işlərinin NiuTrans nöral maşın çeviri sistemlərini təsdiqləyir. Biz Japonca-İngilizce, İngilizce-Çincə, Inuktitut-İngilizce və Tamil-İngilizce toplam beş işə katıldıq və hər iki tərəfdə ilk dərəcə Japonca-İngilizce idik. Biz ilk dəfə iterativ arka çeviri, fərqli derinlik və genişliyi modellər, iterativ bilgi destilasyonu və iterativ təmizlənmi istifadə etdik. Və biz bu modeli təkcə genişləndirib çox genişləndirəcəyik. Ayrıca, bizim uyguladığımız iterativ düzəltmə stratejisi domena uyğunlaşdırma sırasında etkilidir. Inuktitut-İngilizce və Tamil-İngilizce işləri üçün çoxlu dil modelləri ayrı-ayrı inşa etdik və daha xeyirli performansı qazanmaq məqsədilə birlikdə sözləri gözləyirik.', 'cs': 'Tento článek popisuje neuronové strojové překladové systémy NiuTrans pro úlohy překladu zpráv WMT20. Účastnili jsme se celkem pěti úkolů japonsky-anglicky, anglicky-čínsky, inuktitutsky-anglicky a tamilsky-anglicky a místo prvního v japonsky-angličtině na obou stranách. Využili jsme především iterativní zpětný překlad, různé hloubky a rozšíření modelových architektur, iterativní destilaci znalostí a iterativní jemné ladění. A zjistili jsme, že adekvátně rozšířený a prohloubený model současně, výkon se výrazně zlepší. Také iterativní strategie jemného ladění, kterou jsme implementovali, je efektivní při adaptaci domény. Pro úkoly Inuktitut-English a Tamil-English jsme sestavili vícejazyčné modely samostatně a použili předškolené vložení slov pro získání lepšího výkonu.', 'bs': 'Ovaj papir opisuje NiuTrans neuromašinske sustave prevoda WMT20 novinskih zadataka za prevod. Učestvovali smo na japanski-engleski, engleski-kineski, inuktitut-engleski i tamilski-engleski ukupno pet zadataka i prvi su na japanskom-engleskom obje strane. Uglavnom smo iskoristili iterativni povratni prevod, različite dubine i šire modele arhitekture, destilaciju iterativnih znanja i iterativno fino podešavanje. A mi smatramo da će odgovarajući proširenje i dubljenje modela istovremeno, izvedba značajno poboljšati. Također, iterativna strategija za finaliziranje koje smo proveli je efikasna tijekom prilagodbe domena. Za Inuktitut-engleski i Tamil-engleski zadatak, izgradili smo multijezičke modele odvojeno i zaposleni pretvarajući riječ uključujući se kako bi dobili bolju izvršnost.', 'ca': "Aquest article descriu els sistemes de traducció neural de la màquina NiuTrans de les tasques de traducció de notícies WMT20. Vam participar en cinc tasques japonès-anglès, anglès-xinès, inuctitut-anglès i tamil-anglès i vam classer-nos primer a ambdós costats. Vam utilitzar principalment retrotraducció iterativa, arquitectures diferents de profunditat i models ampliats, distillació de coneixements iteratius i ajustament iteratiu. I trobem que al mateix temps, ampliant i profunditzant el model, el rendiment millorarà significativament. També, l'estratègia iterativa d'ajustament que vam implementar és efectiva durant l'adaptació del domini. Per a les tasques Inuktitut-English i Tamil-English, vam construir models multilingües per separat i vam utilitzar paraules de pré-formació incorporades per aconseguir millor rendiment.", 'et': 'Käesolevas töös kirjeldatakse WMT20 uudiste tõlkimise ülesannete NiuTrans neuraalseid masintõlkesüsteeme. Osalesime jaapani-inglise, inglise-hiina, inuktitu-inglise ja tamili-inglise ülesannetes kokku viis ülesannet ning saime mõlemal poolel jaapani-inglise keeles esimese koha. Peamiselt kasutasime iteratiivset tagasitõlket, erinevaid sügavus- ja laiendatud mudelite arhitektuure, iteratiivset teadmiste destilleerimist ja iteratiivset peenhäälestust. Ja me leiame, et mudeli samaaegselt piisavalt laiendatud ja süvendatud, jõudlus paraneb märkimisväärselt. Samuti on meie rakendatud iteratiivne peenhäälestusstrateegia efektiivne domeeni kohandamisel. Inuktitut-inglise ja tamil-inglise ülesannete jaoks ehitasime eraldi mitmekeelsed mudelid ja kasutasime parema jõudluse saavutamiseks eelõpetamist sõnade manustamist.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa kuvataan WMT20:n uutiskﾃ､ﾃ､nnﾃｶstehtﾃ､vien NiuTrans-neurokonekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmiﾃ､. Osallistuimme japani-englanti, englanti-kiina, inuktitut-englanti ja tamil-englanti yhteensﾃ､ viiteen tehtﾃ､vﾃ､ﾃ､n ja sijoittuimme molemmat puolet japani-englanti ensimmﾃ､isenﾃ､. Kﾃ､ytimme pﾃ､ﾃ､asiassa iteratiivista takaisinkﾃ､ﾃ､ntﾃ､mistﾃ､, erilaisia syvyys- ja levendar-malliarkkitehtuuria, iteratiivista tiedon tislausta ja iteratiivista hienosﾃ､ﾃ､tﾃｶﾃ､. Ja huomaamme, ettﾃ､ riittﾃ､vﾃ､sti laajennettu ja syvennetty mallia samanaikaisesti, suorituskyky paranee merkittﾃ､vﾃ､sti. Toteuttamamme iteratiivinen hienosﾃ､ﾃ､tﾃｶstrategia on myﾃｶs tehokas verkkotunnuksen mukauttamisessa. Inuktitut-englanti- ja tamil-englanti-tehtﾃ､viin rakensimme monikieliset mallit erikseen ja kﾃ､ytimme esikoulutusta sanan upottamiseksi paremman suorituskyvyn saavuttamiseksi.', 'jv': "Ngetong iki rambarang kelas pirsak-sistem itoleh niu Tras, nik sistem sing tarjamahan kanggo nganggo balêt, WW2D. Awak dhéwé ngerasakno tanggal Hapon-Inggris, Inggris-Cainan, InukTitut-Inggris lan Tamil-Inggris kuwi lima basa sing sampeyan nganggo dolanan sing katêpakan karo Pakan-Inggris. Awak dhéwé éntuk sistem item-tekyat mulai terjamahan, ngjewak bungan sakjane lan akeh pararampun sing gak nggawe, nggawe kesempatan item-tekyat lan basa item-tekyat sing apik. Kita mbukak lan akeh luwih-luwih dumaten lan jewak model sak ngono ngono ngono nggawe barang sujih dumateng. It's a bit of fun. It's a bit of fun. kanggo awak InukTitut-Inggris lan Tamil-Inggris, awak dhéwé nggawe model sing luwih-luwih lan ijol-ijolan kuwi nggawe gerakan awak dhéwé ngerasah luwih apik.", 'sk': 'V prispevku so opisani sistemi nevronskega strojnega prevajanja NiuTrans za naloge prevajanja novic WMT20. Sodelovali smo v japonsko-angleščini, angleško-kitajščini, inuktitu-angleščini in tamilsko-angleščini skupaj pet nalog in se uvrstili na prvo mesto v japonsko-angleščini obeh strani. V glavnem smo uporabili iterativno nazaj prevajanje, različne globinske in širše arhitekture modela, iterativno destilacijo znanja in iterativno fino nastavitev. In ugotavljamo, da je primerno razširil in poglobil model hkrati, se bo zmogljivost znatno izboljšala. Tudi iterativna strategija finega uravnavanja, ki smo jo izvedli, je učinkovita pri prilagajanju domene. Za naloge inuktitut-angleščine in tamilsko-angleščine smo izdelali ločeno večjezične modele in uporabili predurniško vgradnjo besed, da bi dosegli boljšo zmogljivost.', 'ha': "@ info: whatsthis Mun yi rabo da aikin japanese-Ingiriya, Ingiriya, Inuktit-Ingiriya da Tamilli-Ingiriya dukansa na aikin shan aikin na farko a cikin japanese-Ingiriya biyu. Ba mu yi amfani da abubuwa masu motsi na bakin-tarjiwa, masu buƙata da bakin-bakin-bakin-tarjiwa, masu buƙata da misalin ayuka, salon da sano masu daidaita da shiryoyin-tuning. Kuma munã gane cewa an shimfiɗa, da kuma ya ƙara misalin da shi daidai, za'a samar da shi mai girma. Da haka, kayan samar-tun mai kyau da muka samar shi yana da amfani da idan an sami mutane. Ga aikin Inuktit-Ingiriya da Tamilli-Ingiriya, mun samu misãlai masu mulki-lingui da suka rarraba, kuma mun yi aiki a kan sarrafa kalma ta samu da shi zuwa ga mafiya alhẽri.", 'bo': 'This paper describes NiuTrans neural machine translation systems of the WMT20 news translation tasks. ང་ཚོས་རྒྱ་ནག་ཡིག་གཟུགས་དང་། ཨིན་རིའི་དབྱིན་ཡིག་དང་། ཨིན་རིའི་སྡོམ་དང་ཐ་སྙད་ནང་གི་ནང་བཙུགས་ཀྱི་ཡོད་པ་དང་ལས་འཕགས་པ We mainly utilized iterative back-translation, different depth and widen model architectures, iterative knowledge distillation and iterative fine-tuning. ང་ཚོས་མཐོང་ན། མ་དཔེ་དབྱིབས་གཅིག་མཚུངས་པར་སྒྲིག་པ་ཞིག་ཏུ་ཆེ་མཐོང་བ་ཡིན། Also, iterative fine-tuning strategy we implemented is effective during adapting domain. For Inuktitut-English and Tamil-English tasks, we built multilingual models separately and employed pretraining word embedding to obtain better performance.', 'he': 'העיתון הזה מתאר מערכות התרגום של מכונות עצביות NiuTrans של משימות התרגום חדשות WMT20. השתתפנו באנגלית-יפנית, אנגלית-סינית, אנגלית-אינוקטיטוט ואנגלית-טמיל בסך הכל חמישה משימות והרמה הראשונה בשני הצדדים של אנגלית-יפנית. השתמשנו בעיקר בתרגום חזרה איטריטיבי, עמוק שונה וארכיטקטורות מודל רחב, משקה ידע איטריטיבי ומתאים איטריטיבי. And we find that adequately widened and deepened the model simultaneously, the performance will significantly improve.  בנוסף, אסטרטגיה איטרטיבית מתאימה שהפעלנו היא יעילה במהלך ההסתגלות לתחום. עבור משימות אינוקטיטוט-אנגלית וטמיל-אנגלית, בנינו דוגמנים רבות שפות בנפרד והשתמשנו במילה מראש-אימון מתכננת כדי להשיג ביצועים טובים יותר.'}
{'en': 'Gender Coreference and Bias Evaluation at WMT 2020', 'ar': 'المرجع الجنساني وتقييم التحيز في WMT 2020', 'pt': 'Correferência de gênero e avaliação de preconceito no WMT 2020', 'es': 'Evaluación de la correferencia y el sesgo de género en WMT 2020', 'fr': 'Coréférence hommes-femmes et évaluation des biais au WMT 2020', 'ja': 'WMT 2020におけるジェンダーコアレファレンスとバイアスの評価', 'zh': 'WMT 2020性别共商偏见评估', 'ru': 'Гендерная ориентация и оценка предвзятости на WMT 2020', 'hi': 'WMT 2020 में लिंग कोरेफेरेंस और पूर्वाग्रह मूल्यांकन', 'ga': 'Croílár Inscne agus Measúnú Laofachta ag WMT 2020', 'el': 'Συνασπισμός και αξιολόγηση της προκατάληψης των φύλων στο WMT 2020', 'hu': 'A nemek közötti korreferencia és Bias értékelés a WMT 2020-on', 'ka': 'WMT 2020 წლის განსაზღვრებით გენერების კონფერენცია და ბია განსაზღვრება', 'it': 'Coreferenza di genere e valutazione del bias al WMT 2020', 'kk': 'WMT 2020 жылы Gender Coreference және Bias Evaluation', 'ms': 'Penghargaan Kesuaian Gender dan Bias pada WMT 2020', 'lt': 'Lyčių santykių ir kliūčių vertinimas pagal 2020 m. MTP', 'mk': 'Евантирање на коференцијата на половите и негативностите на ВМТ 2020', 'ml': 'WMT 2020-ല്\u200d സെന്\u200dഡ് കോര്\u200dഫെന്\u200dസും ബൈയാസ് പ്രതിഫലം', 'mt': 'Gender Coreference and Bias Evaluation at WMT 2020', 'mn': 'WMT 2020 оны гендер удирдлага болон биas оценка', 'pl': 'Współpraca płci i ocena uprzedzeń w ramach WMT 2020', 'no': 'Gender Coreference and Bias Evaluation at WMT 2020', 'ro': 'Coreferența de gen și evaluarea Bias la WMT 2020', 'so': 'Koreference and Bias evaluation at WMT 2020', 'si': 'ජෙන්ඩර් කෝරෙෆෙරෙන්ස් සහ බියාස් විශ්ලේෂණය WMT 2020යි.', 'sr': 'Gender Koreferencija i procjena Bias na WMT 2020.', 'sv': 'Genus Coreference och Bias utvärdering vid WMT 2020', 'ta': 'WMT 2020-ல் பெண் மேற்கோள் மற்றும் பையா மதிப்பீடு', 'ur': 'WMT 2020 میں جنس سرپرست اور بیس ارزش', 'uz': 'Comment', 'vi': 'Cuộc thi tuyển lọc giới tính ở WRT 2020', 'bg': 'Корференция на половете и оценка на предразсъдъците по време на ОМТ 2020', 'nl': 'Gendercoreferentie en Bias Evaluatie op WMT 2020', 'hr': 'Poštovanje sposobnosti i procjena biologije na WMT 2020.', 'da': 'Gender Coreference og Bias Evaluering på WMT 2020', 'de': 'Gender Coreferenz und Bias Evaluation bei WMT 2020', 'ko': 'WMT 2020의 성 관련 및 편견 평가', 'id': 'Pertimbangan Gender Coreference dan Bias Evaluation di WMT 2020', 'fa': 'ارزش جنسی و ارزش بیس در WMT 2020', 'sw': 'Tathmini ya jinsia na Bias katika WMT 2020', 'tr': 'Häzirki Kareferensiýa we WBMT 2020-de Jaýyr Taýýarlama', 'af': 'Gender Coreference and Bias Evaluation at WMT 2020', 'sq': 'Koreferenca gjinore dhe vlerësimi i dëmtimeve në WMT 2020', 'am': 'Gender Coreference and Bias Evaluation at WMT 2020', 'hy': 'Գենտրոնային հարաբերակցությունը և վնասվածքի գնահատումը ԱՄԹ 2020-ի ժամանակ', 'az': 'WMT 2020-də Gender Coreference və Bias Evaluation', 'bn': 'উইএমটি ২০২০০-এ লিঙ্গ সংস্কার এবং বায়াস মূল্যায়ন', 'bs': 'Poštovanje muškaraca i procjena biologije na WMT 2020.', 'ca': "L'Evaluació de la Coreferència de Gènere i el Bias al WMT 2020", 'cs': 'Gender Coreference a hodnocení předsudků na WMT 2020', 'et': 'Soolise võrdõiguslikkuse ja eelarvamuste hindamine WMT 2020 raames', 'fi': 'Sukupuolten välisen vuoropuhelun ja ennakkoluulojen arviointi WMT 2020 -tapahtumassa', 'jv': 'Gender corefern lan Bias invaluation nang WWT 2020', 'he': 'ביקורת מין וביאס ב-WMT 2020', 'sk': 'Coreferenca spolov in ocena pristranskosti na WMT 2020', 'ha': 'KCharselect unicode block name', 'bo': 'Gender Coreference and Bias Evaluation at WMT 2020'}
{'en': 'Gender bias in machine translation can manifest when choosing gender inflections based on spurious gender correlations. For example, always translating doctors as men and nurses as women. This can be particularly harmful as models become more popular and deployed within commercial systems. Our work presents the largest evidence for the phenomenon in more than 19 systems submitted to the WMT over four diverse target languages : Czech, German, Polish, and Russian. To achieve this, we use WinoMT, a recent automatic test suite which examines gender coreference and bias when translating from English to languages with grammatical gender. We extend WinoMT to handle two new languages tested in WMT : Polish and Czech. We find that all systems consistently use spurious correlations in the data rather than meaningful contextual information.', 'ar': 'يمكن أن يظهر التحيز الجنساني في الترجمة الآلية عند اختيار التصريفات بين الجنسين بناءً على الارتباطات الزائفة بين الجنسين. على سبيل المثال ، ترجمة الأطباء دائمًا إلى رجال وممرضات كنساء. يمكن أن يكون هذا ضارًا بشكل خاص حيث تصبح النماذج أكثر شيوعًا ويتم نشرها في الأنظمة التجارية. يقدم عملنا أكبر دليل على هذه الظاهرة في أكثر من 19 نظامًا تم تقديمه إلى WMT عبر أربع لغات مستهدفة متنوعة: التشيكية والألمانية والبولندية والروسية. لتحقيق ذلك ، نستخدم WinoMT ، وهو عبارة عن مجموعة اختبارات تلقائية حديثة تختبر مرجعية النوع الاجتماعي والتحيز عند الترجمة من الإنجليزية إلى اللغات ذات الجنس النحوي. قمنا بتوسيع WinoMT للتعامل مع لغتين جديدتين تم اختبارهما في WMT: البولندية والتشيكية. نجد أن جميع الأنظمة تستخدم باستمرار ارتباطات زائفة في البيانات بدلاً من المعلومات السياقية ذات المعنى.', 'pt': 'O viés de gênero na tradução automática pode se manifestar ao escolher inflexões de gênero com base em correlações de gênero espúrias. Por exemplo, sempre traduzindo médicos como homens e enfermeiras como mulheres. Isso pode ser particularmente prejudicial à medida que os modelos se tornam mais populares e implantados em sistemas comerciais. Nosso trabalho apresenta a maior evidência para o fenômeno em mais de 19 sistemas submetidos ao WMT em quatro diferentes idiomas: tcheco, alemão, polonês e russo. Para conseguir isso, usamos o WinoMT, um conjunto de testes automáticos recente que examina a correferência e o viés de gênero ao traduzir do inglês para idiomas com gênero gramatical. Estendemos o WinoMT para lidar com dois novos idiomas testados no WMT: polonês e tcheco. Descobrimos que todos os sistemas usam consistentemente correlações espúrias nos dados, em vez de informações contextuais significativas.', 'es': 'El sesgo de género en la traducción automática puede manifestarse al elegir inflexiones de género basadas en correlaciones de género falsas. Por ejemplo, traducir siempre a los médicos como hombres y a las enfermeras como mujeres. Esto puede ser particularmente perjudicial a medida que los modelos se vuelven más populares y se implementan en los sistemas comerciales. Nuestro trabajo presenta la mayor evidencia del fenómeno en más de 19 sistemas presentados al WMT en cuatro idiomas de destino diferentes: checo, alemán, polaco y ruso. Para lograr esto, utilizamos WinOMT, un conjunto de pruebas automáticas reciente que examina la correferencia y el sesgo de género al traducir del inglés a idiomas con género gramatical. Ampliamos WinOMT para gestionar dos nuevos idiomas probados en WMT: el polaco y el checo. Descubrimos que todos los sistemas utilizan consistentemente correlaciones falsas en los datos en lugar de información contextual significativa.', 'fr': "Les préjugés sexistes dans la traduction automatique peuvent se manifester lorsque l'on choisit des inflexions de genre basées sur de fausses corrélations entre les sexes. Par exemple, toujours traduire les médecins par les hommes et les infirmières par les femmes. Cela peut être particulièrement préjudiciable à mesure que les modèles gagnent en popularité et qu'ils sont déployés dans des systèmes commerciaux. Notre travail présente les preuves les plus importantes du phénomène dans plus de 19 systèmes soumis au WMT dans quatre langues cibles différentes\xa0: le tchèque, l'allemand, le polonais et le russe. Pour ce faire, nous utilisons WinOMT, une suite de tests automatiques récente qui examine la coréférence et les biais de genre lors de la traduction de l'anglais vers des langues ayant un genre grammatical. Nous étendons WinOMT pour prendre en charge deux nouvelles langues testées dans WMT\xa0: le polonais et le tchèque. Nous constatons que tous les systèmes utilisent systématiquement de fausses corrélations dans les données plutôt que des informations contextuelles significatives.", 'ja': '機械翻訳におけるジェンダーバイアスは、偽のジェンダー相関に基づいてジェンダーインフレクションを選択するときに現れる可能性がある。例えば、医者を男性、看護師を女性と常に訳す。これは、モデルがより普及し、商用システム内に展開されるにつれて、特に有害である可能性があります。私たちの研究は、チェコ語、ドイツ語、ポーランド語、ロシア語の4つの多様なターゲット言語を介してWMTに提出された19以上のシステムにおけるこの現象の最大の証拠を提示しています。これを達成するために、私たちは最近の自動テストスイートであるWinoMTを使用して、英語から文法的な性別を持つ言語に翻訳する際のジェンダーコアレフィケーションとバイアスを検討しています。WMTでテストされたポーランド語とチェコ語の2つの新しい言語を処理するために、WinoMTを拡張しました。すべてのシステムは、有意義なコンテキスト情報ではなく、データ内で一貫して偽の相関関係を使用していることがわかります。', 'zh': '机器翻译之性别于虚假性别相关性选择性别变可见也。 常以医翻译成男,以护士翻译成女子。 随形转行,于商业系统中部分,其害尤甚。 吾事为WMT者过19一统之大者,四者之语:捷克语,德语,波兰语俄语。 所以然者,吾用WinoMT,此近自动测试套件也,所以检英语翻译成语法性言语之性别也。 广WinoMT以试WMT二新语:波兰语捷克语。 臣等观之,所有系统,始终于数中用虚相关性,非有义上下文信也。', 'ru': 'Гендерная предвзятость в машинном переводе может проявляться при выборе гендерных перекосов на основе ложных гендерных корреляций. Например, всегда переводить врачей как мужчин, а медсестер как женщин. Это может быть особенно вредно, поскольку модели становятся все более популярными и внедряются в коммерческих системах. Наша работа представляет собой крупнейшее доказательство этого явления в более чем 19 системах, представленных в WMT на четырех различных целевых языках: чешском, немецком, польском и русском. Для достижения этой цели мы используем WinoMT, недавний автоматический тестовый набор, который изучает гендерную ориентацию и предвзятость при переводе с английского языка на языки с грамматическим полом. Мы расширяем WinoMT для работы с двумя новыми языками, протестированными в WMT: польским и чешским. Мы обнаруживаем, что все системы последовательно используют ложные корреляции в данных, а не значимую контекстуальную информацию.', 'hi': 'मशीन अनुवाद में लिंग पूर्वाग्रह नकली लिंग सहसंबंधों के आधार पर लिंग inflections का चयन करते समय प्रकट हो सकता है। उदाहरण के लिए, हमेशा डॉक्टरों को पुरुषों के रूप में और नर्सों को महिलाओं के रूप में अनुवाद करना। यह विशेष रूप से हानिकारक हो सकता है क्योंकि मॉडल अधिक लोकप्रिय हो जाते हैं और वाणिज्यिक प्रणालियों के भीतर तैनात होते हैं। हमारा काम चार विविध लक्ष्य भाषाओं पर डब्ल्यूएमटी को प्रस्तुत किए गए 19 से अधिक प्रणालियों में घटना के लिए सबसे बड़ा सबूत प्रस्तुत करता है: चेक, जर्मन, पोलिश और रूसी। इसे प्राप्त करने के लिए, हम WinoMT का उपयोग करते हैं, जो हाल ही में एक स्वचालित परीक्षण सूट है जो अंग्रेजी से व्याकरणिक लिंग वाली भाषाओं में अनुवाद करते समय लिंग सह-संदर्भ और पूर्वाग्रह की जांच करता है। हम WMT में परीक्षण की गई दो नई भाषाओं को संभालने के लिए WinoMT का विस्तार करते हैं: पोलिश और चेक। हम पाते हैं कि सभी प्रणालियां लगातार सार्थक प्रासंगिक जानकारी के बजाय डेटा में नकली सहसंबंधों का उपयोग करती हैं।', 'ga': 'Is féidir le claonadh inscne san aistriúchán meaisín a léiriú nuair a bhíonn infhilleadh inscne á roghnú bunaithe ar chomhghaolta inscne amhrasacha. Mar shampla, dochtúirí a aistriú i gcónaí mar fhir agus altraí mar mhná. Féadfaidh sé seo a bheith díobhálach go háirithe de réir mar a éiríonn níos mó tóir ar shamhlacha agus go n-imscartar iad laistigh de chórais tráchtála. Cuireann ár gcuid oibre an fhianaise is mó i láthair faoin bhfeiniméan i níos mó ná 19 gcóras a cuireadh faoi bhráid an WMT thar cheithre sprioctheanga éagsúla: Seicis, Gearmáinis, Polainnis agus Rúisis. Chun é seo a bhaint amach, úsáidimid WinoMT, sraith tástála uathoibríoch a rinneadh le déanaí a scrúdaíonn croílárnacht agus claonadh inscne agus sinn ag aistriú ón mBéarla go teangacha le hinscne gramadaí. Síneann muid WinoMT chun dhá theanga nua a thástáiltear in WMT a láimhseáil: Polainnis agus Seicis. Feictear dúinn go n-úsáideann gach córas comhghaolta bréagacha go seasta sna sonraí seachas faisnéis bhríoch chomhthéacsúil.', 'ka': 'მანქანის გაგრძელებაში გენდერი წინტერექციები შეიძლება გაჩვენოთ, როდესაც გენდერი ინტერექციები განირჩევენ ძალიან გენდერი კორელექციების ბაზაზე. მაგალითად, ყოველთვის ექსტრუქები როგორც ადამიანები და მესტრუქები როგორც ქალები. ეს შეიძლება იყოს განსაკუთრებით სხვადასხვა, როგორც მოდელები უფრო პოლუბური და განვითარებული კომპერიოლური სისტემებში. ჩვენი სამუშაო უფრო დიდი წარმოდგენება, რომელიც 19-ზე მეტი სისტემებში WMT-ში გადაეტანა ოთხი განსხვავებული მისაღების ენაზე: ფექი, გერმანეთი, პოლიქური და პროსიური ამის გავაკეთებთ, WinoMT-ს გამოყენებთ, ახალი ავტომატიკური ტესტის სუტი, რომელიც გენექტური წარმოდგენების და წარმოდგენების შესახებ, როდესაც ანგლისგან გენექტური გენექტური ჩვენ WinoMT-ს გაფართვალობთ, რომ WMT-ში შემოწმებული ორი ახალი ენები გავაკეთოთ: პოლიქური და ფექური. ჩვენ ვიფიქრობთ, რომ ყველა სისტემა მუშაობელად გამოყენება ძალიან კოლექტური კოლექტურების მონაცემებში, არა ცნობიერი კონტექსტური ინ', 'el': 'Η προκατάληψη των φύλων στη μηχανική μετάφραση μπορεί να εκδηλωθεί κατά την επιλογή των διαστάσεων φύλου που βασίζονται σε ψευδείς συσχετισμούς φύλου. Για παράδειγμα, πάντα μεταφράζοντας γιατρούς ως άνδρες και νοσοκόμες ως γυναίκες. Αυτό μπορεί να είναι ιδιαίτερα επιβλαβές καθώς τα μοντέλα γίνονται πιο δημοφιλή και αναπτύσσονται μέσα στα εμπορικά συστήματα. Η εργασία μας παρουσιάζει τα μεγαλύτερα στοιχεία για το φαινόμενο σε περισσότερα από 19 συστήματα που υποβλήθηκαν στο WMT σε τέσσερις διαφορετικές γλώσσες-στόχους: τσεχικά, γερμανικά, πολωνικά και ρωσικά. Για να επιτευχθεί αυτό, χρησιμοποιούμε μια πρόσφατη αυτόματη σειρά δοκιμών που εξετάζει τη συσχέτιση και την προκατάληψη φύλου κατά τη μετάφραση από τα αγγλικά σε γλώσσες με γραμματικό φύλο. Επεκτείνουμε το WinoMT για να χειριστεί δύο νέες γλώσσες που έχουν δοκιμαστεί στο WMT: πολωνικά και τσεχικά. Διαπιστώνουμε ότι όλα τα συστήματα χρησιμοποιούν συνεχώς ψεύτικες συσχετίσεις στα δεδομένα και όχι ουσιαστικές πληροφορίες περιβάλλοντος.', 'hu': 'A nemi elfogultság a gépi fordításban megnyilvánulhat, ha hamis nemi összefüggések alapján választják ki a nemi inflexiókat. Például mindig az orvosokat férfiakként fordítja le, a nővéreket pedig nőkként. Ez különösen káros lehet, mivel a modellek egyre népszerűbbé válnak és kereskedelmi rendszerekben alkalmazhatók. Munkánk a jelenség legnagyobb bizonyítékát mutatja be több mint 19, a WMT-nek benyújtott rendszerben négy különböző célnyelven: cseh, német, lengyel és orosz. Ennek eléréséhez a WinoMT-t használjuk, egy nemrégiben működő automatikus tesztcsomagot, amely a nemek közötti korreferenciát és elfogultságot vizsgálja az angolról nyelvtani nemű nyelvekre történő fordítás során. Kibővítjük a WinoMT két új WMT-n tesztelt nyelvet: lengyel és cseh nyelvet. Úgy találjuk, hogy minden rendszer következetesen hamis korrelációkat használ az adatokban, nem pedig értelmes kontextuális információkat.', 'it': "Il pregiudizio di genere nella traduzione automatica può manifestarsi quando si scelgono inflessioni di genere basate su false correlazioni di genere. Ad esempio, tradurre sempre i medici come uomini e gli infermieri come donne. Ciò può essere particolarmente dannoso in quanto i modelli diventano più popolari e distribuiti all'interno dei sistemi commerciali. Il nostro lavoro presenta la più grande evidenza del fenomeno in più di 19 sistemi sottoposti alla WMT in quattro diverse lingue di destinazione: ceco, tedesco, polacco e russo. Per raggiungere questo obiettivo, utilizziamo WinoMT, una recente suite di test automatica che esamina la correferenza di genere e il bias nella traduzione dall'inglese a lingue con genere grammaticale. Estendiamo WinoMT per gestire due nuove lingue testate in WMT: polacco e ceco. Troviamo che tutti i sistemi utilizzano costantemente correlazioni false nei dati piuttosto che informazioni contestuali significative.", 'lt': 'Lyčių pusiausvyra vertimo mašinomis srityje gali pasireikšti pasirinkus lyties inflekciją, grindžiamą nepalankiomis lyčių koreliacijomis. Pavyzdžiui, visada verti gydytojus kaip vyrus ir slaugytojas kaip moteris. Tai gali būti ypač žalinga, nes modeliai tampa populiaresni ir diegiami komercinėse sistemose. Mūsų darbe pateikiami didžiausi šio reiškinio įrodymai daugiau kaip 19 sistemų, pateiktų WMT keturiomis įvairiomis tikslinėmis kalbomis: čekų, vokiečių, lenkų ir rusų. Siekdami to, naudojame WinoMT, neseniai atliktą automatinį bandymų rinkinį, kuriame nagrinėjama lyčių atitiktis ir pusiausvyra vertant iš anglų į gramatinę lytį turinčias kalbas. Mes išplečiame WinoMT, kad ji galėtų naudotis dviem naujomis WMT išbandytomis kalbomis: lenkų ir čekų kalbomis. Mes manome, kad visose sistemose duomenų srityje nuolat naudojamos neigiamos koreliacijos, o ne prasminga kontekstinė informacija.', 'kk': 'Машина аудармасында гендер инфлекцияларын таңдағанда гендер инфлекцияларын таңдай алады. Мысалы, дәрігерлерді әрқашан әйелдер мен медицинскерді әйелдер ретінде аударады. Бұл үлгілер көптеген және коммерциялық жүйелердің ішінде жақсы болып жатқан болуы мүмкін. Біздің жұмысамыз 19-ден артық жүйелерде WMT-ге төрт әртүрлі мақсатты тілдерінен жіберілген панельдердің ең үлкен құқықтарын көрсетеді: Чех, неміс, Польша және Русша Бұны жеткізу үшін, WinoMT- ді жаңа автоматты сынақтарды қолданамыз. Бұл гендердің қасиеттерін және қасиеттерін, ағылшын тілден грамматикалық гендердің тілдеріне аударғанда, ағылшын тілдеріне аударғанда Біз WMT: Польша және Чех тілдерінде тексерілген екі жаңа тілді басқару үшін WinoMT- ді кеңейту үшін. Біз барлық жүйелер мәліметті мәліметтің мәліметінің орнына деректерде тұрақты қатынастарды қолданады.', 'mk': 'Генералната предрасуда во машинскиот превод може да се манифестира кога се одбираат генерални инфекции базирани на незгодни генерални корелации. На пример, секогаш ги преведувам докторите како мажи и медицински сестри како жени. Ова може да биде особено штетно со оглед на тоа што моделите стануваат попопуларни и распоредени во комерцијалните системи. Нашата работа ги претставува најголемите докази за феноменот во повеќе од 19 системи поднесени на ВМТ во врска со четири различни метни јазици: чешки, германски, полски и руски. За да го постигнеме ова, користиме WinoMT, неодамнешно автоматско тестирање кое ги испитува половите кореференции и пристрасност кога се преведува од англиски на јазици со граматичен пол. Ние го прошируваме WinoMT за да се справи со два нови јазици тестирани на WMT: полски и чески. Најдовме дека сите системи постојано користат нејасни корелации во податоците наместо значајни контекстни информации.', 'ml': 'മെഷീന്\u200d പരിഭാഷയിലെ പെണ്\u200dകുട്ടികള്\u200dക്ക് വ്യക്തമാക്കാന്\u200d സാധിക്കുന്നു പ്രധാനപൂര്\u200dണ്ണമായ പെണ്\u200dകുട്ടികളുടെ  ഉദാഹരണത്തിന്, ഡോക്ടര്\u200dമാരെപ്പോഴും പുരുഷന്മാരെയും നേഴ്സുകളെയും സ്ത്രീകളായി പരിഭാഷപ്പെട മോഡലുകള്\u200d കൂടുതല്\u200d പ്രധാനപ്പെട്ടിരിക്കുന്നതും കച്ചവട സിസ്റ്റത്തില്\u200d അയച്ചിരിക്കുന്നതും കൊണ്ട് ഇത്  ഞങ്ങളുടെ ജോലി 19 സിസ്റ്റത്തില്\u200d ഏറ്റവും വലിയ തെളിവുകള്\u200d കാണിക്കുന്നു. WMT നാലു വ്യത്യസ്ത ലക്ഷ്യഭാഷകള്\u200dക്കും കൂടിയാണ് നല്\u200dകിയത്. ചെക്ക്, ജ ഇത് എത്തിക്കാന്\u200d, നമ്മള്\u200d വിനോഎംടി ഉപയോഗിക്കുന്നു, ഒരു സാമ്പത്തികമായ പരീക്ഷണ സ്യൂട്ട് ഉപയോഗിക്കുന്നു. അത് ലൈന്\u200dസ് കോര്\u200dഫെന്\u200dസ് പരിശോ WMT-ല്\u200d പരീക്ഷിക്കപ്പെട്ട രണ്ടു പുതിയ ഭാഷകള്\u200d കൈകാര്യം ചെയ്യാന്\u200d വിനോഎംടി നീട്ടുന്നു. എല്ലാ സിസ്റ്റത്തെയും വിവരങ്ങള്\u200dക്ക് വേണ്ടിയുള്ള വിവരങ്ങള്\u200dക്ക് പകരം വിവേകമുള്ള വിവരങ്ങള്\u200dക്ക് വേണ്ടി വിവ', 'ms': 'Biasa jenis dalam terjemahan mesin boleh muncul bila memilih pengaruh jenis berdasarkan korelasi jenis yang menggerunkan. Contohnya, sentiasa menerjemahkan doktor sebagai lelaki dan jururawat sebagai perempuan. Ini boleh sangat berbahaya kerana model menjadi lebih populer dan digunakan dalam sistem komersial. Kerja kami memperlihatkan bukti terbesar untuk fenomena ini dalam lebih dari 19 sistem yang dihantar ke WMT lebih dari empat bahasa sasaran berbeza: Czech, German, Polish, dan Russian. Untuk mencapai ini, kita menggunakan WinoMT, suite ujian automatik baru-baru ini yang memeriksa persamaan dan bias jenis bila diterjemahkan dari bahasa Inggeris ke bahasa dengan jenis gramatik. Kami memperluas WinoMT untuk menangani dua bahasa baru yang diuji dalam WMT: Polish dan Czech. Kami mendapati bahawa semua sistem secara konsisten menggunakan korelasi yang mengganggu dalam data daripada maklumat kontekstual yang bermakna.', 'mt': 'Il-preġudizzju bejn is-sessi fit-traduzzjoni tal-magni jista’ jidher meta jagħżel inflezzjonijiet bejn is-sessi bbażati fuq korrelazzjonijiet spurjużi bejn is-sessi. Pereżempju, dejjem jittraduċu t-tobba bħala irġiel u infermiera bħala nisa. Dan jista’ jkun partikolarment ta’ ħsara hekk kif il-mudelli jsiru aktar popolari u jintużaw fi ħdan is-sistemi kummerċjali. Ix-xogħol tagħna jippreżenta l-akbar evidenza għall-fenomenu f’aktar minn 19-il sistema ppreżentata lill-WMT fuq erba’ lingwi fil-mira differenti: iċ-Ċek, il-Ġermaniż, il-Pollakk, u r-Russu. Biex dan jinkiseb, a ħna nużaw WinoMT, sett ta’ testijiet awtomatiċi riċenti li jeżamina l-koerenza bejn is-sessi u l-preġudizzju meta jiġu tradotti mill-Ingliż għal lingwi b’sess grammatiku. Aħna jestendu WinoMT biex nimmaniġġjaw żewġ lingwi ġodda ttestjati fid-WMT: il-Pollakk u ċ-Ċek. Aħna nsibu li s-sistemi kollha jużaw b’mod konsistenti korrelazzjonijiet spurjużi fid-dejta aktar milli informazzjoni kuntestwali sinifikanti.', 'mn': 'Машин хөрөнгө оруулалтын гендер нөлөөлөлийг сонгох үед гендер нөлөөлөл байдлыг илэрхийлж чадна. Жишээлбэл эмч нарыг эмэгтэйчүүд болон эмэгтэйчүүд болгож байдаг. Энэ загварууд илүү алдартай болон худалдааны системд хуваалцагддаг учраас ялангуяа аюултай байж болно. Бидний ажил 19 гаруй системээс илүү олон үзэгдэл дээр WMT-д 4 төрлийн зорилготой хэл дээр дамжуулагдсан үзэгдэл дээр хамгийн их баталгаатай байна: Чех, Герман, Польш, Орос. Үүнийг олохын тулд бид WinoMT-г хэрэглэдэг. Сүүлийн автоматикийн шалгалт нь гендерийн хүндрэл, урамшуулалтыг судалдаг. Энэ нь англи хэлээс грамматикийн гендертэй хөгжүүлэхэд англи хэл руу хөгжүүлэх үед. Бид WinoMT-г WMT: Польша болон Чехид шалгалтын хоёр шинэ хэл зохицуулахын тулд нэмэгдүүлсэн. Бид бүх системүүд мэдээллийн тухай ойлголттой мэдээллийн оронд мэдээллийн холбоотой холбоотой байдлаар хэрэглэдэг.', 'pl': 'Uprzedzenia płci w tłumaczeniu maszynowym mogą objawiać się przy wyborze zmian płci opartych na fałszywych korelacjach płci. Na przykład, zawsze tłumaczy lekarzy jako mężczyźni, a pielęgniarki jako kobiety. Może to być szczególnie szkodliwe, ponieważ modele stają się coraz bardziej popularne i wdrażane w systemach komercyjnych. Nasza praca prezentuje największe dowody na to zjawisko w ponad 19-tych systemach zgłoszonych do WMT w czterech różnych językach docelowych: czeskim, niemieckim, polskim i rosyjskim. Aby to osiągnąć, używamy WinoMT, najnowszego automatycznego pakietu testów, który bada współzależność płci i uprzedzenia podczas tłumaczenia z języka angielskiego na języki o płci gramatycznej. Rozszerzamy WinoMT o dwa nowe języki testowane w WMT: polski i czeski. Odkrywamy, że wszystkie systemy konsekwentnie wykorzystują fałszywe korelacje w danych, a nie znaczące informacje kontekstowe.', 'no': 'Gender bias i maskinsomsetjinga kan manifestera når du veljer seks-infleksjonar basert på spurre sekskorrelasjonar. For eksempel, vert alltid omsetjinga av leger som menn og sykehus som kvinner. Dette kan vera særleg skade fordi modeller blir meir populærre og utvikla i kommersielle systemer. Arbeidet vårt viser dei største bevisene for fenomenen i fleire enn 19 systemer som er sendt til WMT over fire ulike målspråk: Tsjekkisk, tysk, polsk og russisk. For å oppnå dette, bruker vi WinoMT ein nyleg automatisk test suite som undersøker seks-koreferanse og bias når du omsetjer frå engelsk til språk med grammatisk seks. Vi utvidar WinoMT for å handtera to nye språk testa i WMT: Polsk og tsjekkisk. Vi finn at alle systema konsistent brukar korrelasjonar i dataene i staden for mening av kontekstinformasjon.', 'ro': 'Prejudecățile de gen în traducerea automată se pot manifesta atunci când alegeți inflexiuni de gen bazate pe corelații false de gen. De exemplu, traducerea doctorilor ca bărbaţi şi asistentele ca femei. Acest lucru poate fi deosebit de dăunător pe măsură ce modelele devin mai populare și implementate în sistemele comerciale. Lucrările noastre prezintă cele mai mari dovezi ale fenomenului în peste 19 sisteme prezentate la WMT în patru limbi țintă diferite: cehă, germană, poloneză și rusă. Pentru a realiza acest lucru, folosim WinoMT, o suită recentă de testare automată care examinează corefența de gen și părtinirea atunci când traducem din engleză în limbi cu gen gramatical. Extindem WinoMT pentru a gestiona două noi limbi testate în WMT: poloneză și cehă. Considerăm că toate sistemele folosesc în mod constant corelații false în date, mai degrabă decât informații contextuale semnificative.', 'si': 'ජෙන්ඩර් බයිස් මැෂින් වාර්ථාවේ ප්\u200dරදේශ කරන්න පුළුවන් ජෙන්ඩර් ප්\u200dරදේශය තෝරාගන්න පුළුවන්. උදාහරණයෙන්, හැමවෙලේම ඩොක්ටර්ස් වලින් පුරුද්ධ වලින් ගැහැණු වලින් පුරුද්ධ වලින මේක විශේෂයෙන් අනතුරක් වෙන්න පුළුවන් විදිහට මොඩල් ලෝක ප්\u200dරදේශයෙන් වෙන්න හා ව්\u200dයාපාර ප අපේ වැඩේ සාක්ෂියක් තියෙනවා විවිධිපද්ධති 19 වඩා වඩා විශාල සාක්ෂියක්: චෙක්, ජර්මන්, පොලිෂ්, රුසියානු වලින් WM To accompany this, we use WinoMT, a new autommatical testing suite that examples Genr corepherson and beas in translation from English to language with gram sex. අපි WinoMT විස්තර කරනවා WMT: පොලිෂ් සහ චෙක් වල අලුත් භාෂාවක් දෙකක් පරීක්ෂා කරනවා. අපිට හොයාගන්න පුළුවන් හැම පද්ධතියක්ම සාමාන්\u200dයයෙන්ම තොරතුරු තොරතුරු වෙනුවෙන් තොරතුරු තොරතුරු ව', 'sr': 'Ženska predrasuda u prevodu mašine može se pojaviti kada bira spolne utjecaje na temelju spolnih odnosa. Na primer, uvek prevode doktore kao muškarce i sestre kao žene. To može biti posebno štetnije jer modeli postaju popularniji i raspoređeniji u komercijalnim sistemima. Naš rad predstavlja najveći dokaz za fenomen u više od 19 sistema podignut WMT-u na četiri različite ciljne jezike: češki, nemački, poljski i ruski. Da bi to postigli, koristimo WinoMT, nedavni automatski test apartman koji pregleda seksualnu pristrasnost i predrasude kada prevodimo sa engleskog na jezike sa gramatičkim spolom. Proširimo WinoMT kako bi se nosili dve nove jezike testovane na WMT-u: poljski i češki. Mi smatramo da svi sistemi stalno koriste oštećene korelacije u podacima, a ne značajne kontekstske informacije.', 'so': "Tarjumaadda jinsiga waxaa muujin kara muujin kara marka uu dooranayo xiriirka jinsiga oo ku saleysan xiriirka jinsiga. Tusaale ahaan mar walba dhakhtarka sida rag iyo kalkaaliso caafimaad oo dumar ah u turjuma. Taasi si khatara ah waxyeelo u yeelan karo, marka qaababka ay u noqdaan mid aad u populan islamarkaasna lagu soo bandhigi karo nidaamka ganacsiga. Shaqadeena waxaa soo saara calaamadaha ugu waaweyn ee xaaladaha lagu sameeyo wax ka badan 19 nidaam oo WMT u soo dhiibay afar luuqadood oo kala duduwan: Czech, Jarmal, Boolish iyo Ruush. Si aan u gaadho waxan, waxaynu u isticmaalnaa WinoMT, kaas oo ku baaraya koontaha jinsiga iyo bandhigyada marka lagu turjumayo afka Ingiriiska ilaa luuqadaha lagu qorayo jinsiga. WMT: Boolis iyo Czech. Waxaynu helnaa in nidaamka oo dhammu ay si joogto ah ugu isticmaalaan xiriir faa'iido ah oo macluumaadka ku saabsan.", 'sv': 'Könsbias i maskinöversättning kan manifesteras när man väljer könsböjningar baserade på falska könskorrelationer. Till exempel, alltid översätta läkare som män och sjuksköterskor som kvinnor. Detta kan vara särskilt skadligt när modeller blir mer populära och distribueras inom kommersiella system. Vårt arbete presenterar de största bevisen för fenomenet i mer än 19 system som lämnats in till WMT över fyra olika målspråk: tjeckiska, tyska, polska och ryska. För att uppnå detta använder vi WinoMT, en nyligen genomförd automatisk testsvit som undersöker könskorrefens och bias vid översättning från engelska till språk med grammatiskt kön. Vi utökar WinoMT till att hantera två nya språk som testats i WMT: polska och tjeckiska. Vi finner att alla system konsekvent använder falska korrelationer i data snarare än meningsfull kontextuell information.', 'ta': 'இயந்திரம் மொழிபெயர்ப்பில் பெண்கள் பிரச்சினைகளை தேர்ந்தெடுக்கும் போது தெளிவாக்கலாம். எடுத்துக்காட்டாக, எப்போதும் மருத்துவர்களை பெண்களாக மொழிபெயர்ப்பார்கள். மாதிரிகள் அதிக மகிழ்ச்சியாக இருக்கும் மற்றும் வியாபாரம் அமைப்புகளில் வைத்திருக்கும் போது இது குறிப எங்கள் வேலை 19 முறைமைகளில் உள்ள பெரிய தெளிவான தெளிவுகளை கொடுக்கிறது WMT நான்கு மேற்பட்ட இலக்க மொழிகளுக்கு கொடுக்கப்பட்டுள்ளது: ச இதை அடைவதற்கு, நாம் வினோஎம்டி, சமீபத்தில் ஒரு தானியங்கி சோதனை முறையை பயன்படுத்துகிறோம். அது பெண் குறியீடு மற்றும் பியாஸ் மொழிகளை மொழிப WMT: போலிஷ் மற்றும் செக்ச். நாம் கணினிகள் அனைத்தும் தொடர்ந்து தகவலில் மிகவும் பெரிய இணைப்புகளை பயன்படுத்துகிறோம் என்பதை கண்டுபிடிக்கிற', 'ur': 'ماشین کی ترجمہ میں جنسی غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر مثال، دکتروں کو مردوں اور پرستاروں کو عورتوں کے طور پر تبدیل کرتے ہیں۔ یہ مخصوصا خطرناک ہوسکتا ہے کیونکہ موڈل زیادہ محبوب ہوجاتے ہیں اور تجارت سیستموں میں استعمال کئے جاتے ہیں. ہمارا کام 19 سے زیادہ سیستموں میں جو WMT میں چار مختلف موجود زبانوں پر پیش کئے گئے ہیں، چک، جرمن، پولش اور روسی کے لئے سب سے بڑی نشانیاں پیش کئے جاتے ہیں۔ اس کے لئے ہم WinoMT کو استعمال کرتے ہیں، ایک اخیر اٹوٹوٹ تست سوئٹ جو جنس کی مہربانی اور بغیر نظریہ کی تحقیق کرتا ہے جب انگلیسی سے گراماتیکی جنس کے ساتھ زبانوں کو ترجمہ کرتا ہے۔ ہم WinoMT کو ڈھیل دیتے ہیں کہ WMT میں آزمائش کی دو نئی زبانیں ہانڈ کریں: پولیش اور چک. ہم دیکھتے ہیں کہ تمام سیسٹم مطلب معلوم معلومات کے بغیر دھوپ کی تعلقات کے استعمال کرتے ہیں.', 'uz': "Name Masalan, har doktorlarni o'z ayollar sifatida o'rganadi. Bu modellar ko'proq va tizim tizimida ishlab chiqarishi mumkin. Bizning ishlarimiz 19 dan ortiq tizimdagi eng katta hujjatlarni WMT turli tillardan to'rt xil tildan qo'shilgan: Chek, Olmon, Polyak, Ruscha va Ruscha. Buni amalga oshirish uchun, biz yangi avtomatik sinov sotuvdan foydalanamiz. Bu tildan grammatikal jinsiya bilan tarjima qilayotganda jinsiyalar koʻrinishini aniqlanadi. Biz WMT'da bir necha tillarni boshqarish uchun WinoMT'ni uzoqchimiz: Polish va Chekscha. Biz hamma tizimlar davomida maʼlumot haqida muhim maʼlumotdan foydalanish mumkin.", 'vi': 'Giới tính nữ trong dịch chuyển cỗ máy có thể biểu hiện khi chọn sự trả đũa giới tính dựa trên mối liên hệ giới tính sai lệch. Thí dụ như, luôn dịch chuyển các bác sĩ như đàn ông và y tá như phụ nữ. Việc này có thể gây nguy hiểm đặc biệt khi các mô hình trở nên phổ biến và phát triển trong hệ thống thương mại. Công việc của chúng tôi là chứng cứ lớn nhất cho hiện tượng này trong nhiều hệ thống hơn 19 đã gửi tới WRT hơn bốn ngôn ngữ khác nhau: Séc, Đức, Ba Lan, Nga. Để đạt được điều này, chúng tôi sử dụng Winn, một phòng thí nghiệm tự động gần đây, xem xét khả năng giảm giới tính và khuynh hướng khi dịch từ tiếng Anh sang ngôn ngữ với giới tính ngữ. Chúng tôi mở rộng Winifred để xử lý hai ngôn ngữ mới được thử bằng WRT: Polish và Séc. Chúng tôi thấy rằng tất cả hệ thống đều liên tục sử dụng mối liên hệ giả tạo trong dữ liệu thay vì thông tin ngữ cảnh có ý nghĩa.', 'bg': 'Половото пристрастие в машинния превод може да се прояви при избора на полови наклонения въз основа на фалшиви полови корелации. Например, винаги превеждате лекарите като мъже и медицинските сестри като жени. Това може да бъде особено вредно, тъй като моделите стават все по-популярни и внедрени в търговските системи. Нашата работа представя най-голямото доказателство за явлението в повече от 19 системи, представени на четири различни целеви езика: чешки, немски, полски и руски. За да постигнем това, използваме скорошен автоматичен тест пакет, който изследва съпоставимостта на половете и отклоненията при превод от английски на езици с граматичен пол. Разширяваме WinoMT, за да обработва два нови езика, тествани в WMT: полски и чешки. Откриваме, че всички системи последователно използват фалшиви корелации в данните, а не смислена контекстуална информация.', 'hr': 'Gender bias in machine translation can be manifested when choosing gender inflections based on spurious gender correlations. Na primjer, uvijek prevode liječnike kao muškarce i sestre kao žene. To može biti posebno štetnije jer modeli postaju popularniji i raspoređeniji u komercijalnim sustavima. Naš rad predstavlja najveći dokaz za fenomen u više od 19 sustava podignut WMT-u na četiri različite ciljne jezike: češki, njemački, poljski i ruski. Da bi to postigli, koristimo WinoMT, nedavni automatski test apartman koji pregleda seksualnu pristojnost i predrasude kada se prevodi s engleskog na jezike s gramatičkim spolom. Proširimo WinoMT kako bi se nosili dvije nove jezike ispitivane na WMT-u: poljski i češki. Smatramo da svi sustavi konsekventno koriste oštećene korelacije u podacima umjesto značajnih contextualnih informacija.', 'nl': 'Genderbias in machine translation kan zich manifesteren bij het kiezen van gender flexies gebaseerd op valse gender correlaties. Bijvoorbeeld, altijd artsen vertalen als mannen en verpleegkundigen als vrouwen. Dit kan bijzonder schadelijk zijn naarmate modellen populairder worden en worden ingezet binnen commerciële systemen. Ons werk presenteert het grootste bewijs voor het fenomeen in meer dan 19-systemen die aan het WMT zijn voorgelegd in vier verschillende doeltalen: Tsjechisch, Duits, Pools en Russisch. Om dit te bereiken, gebruiken we WinoMT, een recente automatische test suite die gendercoreferentie en bias onderzoekt bij het vertalen van Engels naar talen met grammaticaal geslacht. We breiden WinoMT uit om twee nieuwe talen te verwerken die in WMT zijn getest: Pools en Tsjechisch. We merken dat alle systemen consequent valse correlaties in de data gebruiken in plaats van zinvolle contextuele informatie.', 'da': 'Kønsfordele i maskinoversættelse kan manifestere sig, når man vælger kønsbøjninger baseret på falske kønskorrelationer. For eksempel altid oversætte læger som mænd og sygeplejersker som kvinder. Dette kan være særligt skadeligt, efterhånden som modeller bliver mere populære og implementeret i kommercielle systemer. Vores arbejde præsenterer de største beviser for fænomenet i mere end 19 systemer indsendt til WMT over fire forskellige målsprog: tjekkisk, tysk, polsk og russisk. For at opnå dette bruger vi WinoMT, en nylig automatisk testpakke, der undersøger kønscoreference og bias ved oversættelse fra engelsk til sprog med grammatisk køn. Vi udvider WinoMT til at håndtere to nye sprog testet i WMT: polsk og tjekkisk. Vi finder ud af, at alle systemer konsekvent bruger falske korrelationer i dataene snarere end meningsfulde kontekstuelle oplysninger.', 'de': 'Gender Bias in der maschinellen Übersetzung kann sich manifestieren, wenn Geschlechterbindungen auf Basis falscher Geschlechterkorrelationen ausgewählt werden. Zum Beispiel, immer Ärzte als Männer und Krankenschwestern als Frauen zu übersetzen. Dies kann besonders schädlich sein, da Modelle immer beliebter und in kommerziellen Systemen eingesetzt werden. Unsere Arbeit präsentiert die größten Beweise für dieses Phänomen in mehr als 19-Systemen, die dem WMT in vier verschiedenen Zielsprachen vorgelegt wurden: Tschechisch, Deutsch, Polnisch und Russisch. Um dies zu erreichen, verwenden wir WinoMT, eine neue automatische Testsuite, die Geschlechterkorreferenz und -verzerrungen bei Übersetzungen aus dem Englischen in Sprachen mit grammatischem Geschlecht untersucht. Wir erweitern WinoMT um zwei neue Sprachen, die in WMT getestet wurden: Polnisch und Tschechisch. Wir stellen fest, dass alle Systeme konsistent falsche Korrelationen in den Daten anstatt aussagekräftige Kontextinformationen verwenden.', 'id': 'Kebiasaan jenis dalam terjemahan mesin dapat muncul ketika memilih infleksi jenis berdasarkan korelasi jenis yang mengganggu. For example, always translating doctors as men and nurses as women.  Ini bisa sangat berbahaya karena model menjadi lebih populer dan disebarkan dalam sistem komersial. Pekerjaan kami memperlihatkan bukti terbesar untuk fenomena ini dalam lebih dari 19 sistem yang dihantar ke WMT lebih dari empat bahasa target yang berbeda: Cek, Jerman, Polandia, dan Rusia. Untuk mencapai ini, kami menggunakan WinoMT, suite tes otomatis baru-baru ini yang memeriksa persamaan dan bias jenis ketika menerjemahkan dari bahasa Inggris ke bahasa dengan jenis gramatika. Kami memperluas WinoMT untuk menangani dua bahasa baru yang diuji di WMT: Polandia dan Ceko. Kami menemukan bahwa semua sistem secara konsisten menggunakan korelasi yang menggoda dalam data daripada informasi kontekstual yang berarti.', 'ko': '번역 중인 성별 편견은 거짓된 성별 관련성을 바탕으로 성별 변화를 선택할 때 나타난다.예를 들면, 항상 의사를 남자로, 간호사를 여자로 번역한다.모델이 점점 유행하고 상업 시스템에 배치되면서 특히 해로울 수 있다.WMT에 제출된 19개 이상의 시스템에서 우리의 업무는 이러한 현상에 가장 큰 증거를 제공했다. 체코어, 독일어, 폴란드어와 러시아어 네 가지 서로 다른 목표 언어와 관련된다.이를 실현하기 위해 우리는 WinoMT를 사용했다. 이것은 영어에서 문법적 성별 언어로 번역될 때의 성별 참조와 편견을 검사한 최신 자동 테스트 세트이다.WinoMT는 WMT에서 테스트된 두 가지 새로운 언어인 폴란드어와 체코어를 처리하기 위해 확장되었습니다.우리는 모든 시스템이 데이터에서 의미 있는 상하문 정보가 아니라 허위 관련성을 사용하는 것을 발견했다.', 'fa': 'جنسی در ترجمه ماشین می تواند وقتی انتخاب اثرات جنسی را بر اساس ارتباطات جنسی ناپذیر نشان دهد. برای مثال، همیشه دکترها را به عنوان مردان و پرستارها به عنوان زنان ترجمه می کنند. این می\u200cتواند به خصوصی خطرناک باشد چون مدل\u200cها محبوب\u200cتر می\u200cشوند و در سیستم\u200cهای تجاری استفاده می\u200cشوند. کارمون بزرگترین مدرک برای این پدیده در بیش از ۱۹ سیستم به WMT بر چهار زبان هدف مختلف نشان می دهد: چک، آلمان، لهستان و روسیه. برای رسیدن به این، ما از WinoMT استفاده می کنیم، یک سوئت آزمایش اتوماتیک اخیر که در زمان ترجمه کردن از انگلیسی به زبانها با جنس گراماتیک تحقیق می کند. ما WinoMT را گسترش می دهیم تا دو زبان جدید را در WMT آزمایش کنیم: پولش و چک. ما پیدا می\u200cکنیم که تمام سیستم\u200cها همیشه از ارتباط\u200cهای مختلف در داده\u200cها استفاده می\u200cکنند به جای اطلاعات موضوع معنی.', 'sw': 'Ubaguzi wa jinsia katika tafsiri ya mashine unaweza kuonyesha wakati wa kuchagua ushawishi wa kijinsia kutokana na mahusiano ya kijinsia. Kwa mfano, mara zote hutafsiri madaktari kama wanaume na wauguzi kama wanawake. Hii inaweza kuwa na madhara hasa kwa kuwa mifano inakuwa maarufu zaidi na kutumika ndani ya mfumo wa kibiashara. Kazi yetu inaonyesha ushahidi mkubwa wa hali hii katika zaidi ya mifumo 19 yaliyowasilishwa na WMT kwa lugha nne mbalimbali: Kizech, Ujerumani, Poland, na Urusi. Ili kufikia hili, tunatumia WinoMT, kituo cha majaribio cha hivi karibuni cha kujitegemea ambacho kinachunguza utaratibu wa kijinsia na upendeleo wakati utafsiri kutoka Kiingereza hadi lugha kwa jinsia za ukarabu. Tunaendelea WinoMT ili kukabiliana na lugha mbili mpya zilizojaribiwa katika WMT: Wapoland na Kizech. Tunapata kwamba mifumo yote inatumia uhusiano mkubwa katika taarifa badala ya taarifa za kisasa.', 'tr': "Maşynyň terjimesinde jentiller täsirlerini saýlap wagtynda jentiller täsirlerine garaşyp biler. Mesela, lukmanlary erkekler we hemşireler aýal ýaly terjime edýärler. Bu örän nusgalar komersiýa sistemalarda has hem meşhur we nusgasyz bolup biler. Biziň işimiz 19-den köp sistemada WBMT'a dört dürli maksady dilinde üýtgeden fenomeniň has möhüm kanıtlaryny görkezýär: Çehiýa, Almança, Polonça we Rusça. Muny ýetmek üçin, biz WinoMT'i soňky awtomatik barlamak sahypasyna ulanýarys, haçand a iňlisçe dillerden gramatik jentiller bilen iňlisçe terjime edeniňde nähili nähili barlanyşygy we biasy barlap. WBM: Polonýa we Çehiýada barlanýan iki täze dil çözmek üçin WinoMT'i uzatdyrys. Hemme sistemalar muny daty içinde nähili möhüm duýdury maglumatdan başga düýbünden aýratyn ylalaşyklary ulanýarlar.", 'af': "Gender bias in masjien vertaling kan manifesteer wanneer gevolg inflekvensies gebaseer word op speurde gevolg korrelasies. Byvoorbeeld, altyd vertaling dokters as manne en verpletter as vroue. Dit kan besonderlik skandelik wees as modele meer populaar word en in kommersiÃ«le stelsels uitgebruik word. Ons werk beveel die grootste getuienis vir die fenomen in meer as 19 stelsels wat aan die WMT ingestuur word oor vier verskillende doelstale: Tsjechse, Duitse, Poolse en Russe. Om dit te bereik, gebruik ons WinoMT, 'n onlangse outomatiese toets suite wat ondersoek geneemde hoereferenigheid en bias wanneer ons vertaling van Engels na tale met grammatiese geneem. Ons uitbrei WinoMT om twee nuwe tale te hanteer wat in WMT toegestel is: Poolse en Tschekis. Ons vind dat alle stelsels konsistentlik speurde korrelasies in die data gebruik as betekende contextual inligting.", 'sq': 'Përparësia gjinore në përkthimin e makinave mund të manifestohet kur zgjedh përkthimet gjinore bazuar në korrelacionet e zhvilluara gjinore. Për shembull, gjithmonë përkthimi i mjekëve si burra dhe infermiere si gra. Kjo mund të jetë veçanërisht e dëmshme pasi modelet bëhen më popullorë dhe përdoren brenda sistemeve komerciale. Our work presents the largest evidence for the phenomenon in more than 19 systems submitted to the WMT over four diverse target languages: Czech, German, Polish, and Russian.  To achieve this, we use WinoMT, a recent automatic test suite which examines gender coreference and bias when translating from English to languages with grammatical gender.  Ne zgjerojmë WinoMT për të trajtuar dy gjuhë të reja të testuara në WMT: polak dhe çek. Ne zbulojmë se të gjitha sistemet përdorin vazhdimisht korrelacione të nxitura në të dhënat në vend të informacionit kontekstual të kuptueshëm.', 'hy': "Սկնդի կողմնականությունը մեքենայի թարգմանման մեջ կարող է հայտնվել, երբ ընտրվում է գենդերային ազդեցություններ' հիմնված գենդերային հաղորդակցման վատ վրա: Օրինակ, բժիշկներին միշտ թարգմանում են տղամարդկանց և բուժքույրերի պես կանանց: Սա կարող է հատկապես վնասավոր լինել, քանի որ մոդելները ավելի հայտնի են դառնում և օգտագործվում են առևտրային համակարգերում: Մեր աշխատանքը ներկայացնում է այս երևույթի ամենամեծ ապացույցները ավելի քան 19 համակարգում, որոնք ներկայացվել են ԱՄԹ-ին չորս տարբեր նպատակային լեզուներում' Չեխ, գերմանացի, պոլանդացի և ռուսական: Սա հասնելու համար մենք օգտագործում ենք Windows MT-ը, վերջերս ավտոմատիկ փորձարկումներ, որոնք ուսումնասիրում են գենդերային համեմատությունը և կողմնականությունը, երբ թարգմանվում են անգլերենից գրամատիկական գենդերային լեզուներով: Մենք ընդլայնում ենք Windows MT-ը, որպեսզի աշխատենք երկու նոր լեզուներով, որոնք փորձարկվել են ՀՄԹ-ում' պոլանդական և ցեխական: Մենք հայտնաբերում ենք, որ բոլոր համակարգերը համընդհանուր կերպ օգտագործում են տարօրինակ հաղորդակցություններ տվյալների մեջ, ոչ թե իմաստալից կոնտեքստալ ինֆորմացիա:", 'az': "Makinelərin çevirindəki cins təsirlərini seçərkən cins təsirlərini göstərə bilər. Məsələn, həmişə doktorları erkəklər və hemşirələr qadınlar kimi çevirirlər. Bu, modellər daha məşhur və ticarət sistemlərində yayılmış olaraq, özlərinə də zərər verir. Bizim işimiz 19-dən çox sistemlərdə WMT'ə dörd müxtəlif məqsəd dilində müəyyən edilmiş fenomenin ən böyük dəlillərini göstərir: Çehir, Alman, Polşa və Rus dilində. Bunu başa düşmək üçün, WinoMT'i yeni avtomatik sınama suitini istifadə edirik ki, cins mərhəməti və bias dillərini grammatik cinslə İngilizdən dillərə çevirir. Biz WinoMT'i WMT: Polonya və Çehir dillərində sınağa çəkilmiş iki yeni dil vasitəsilə genişləyirik. Bütün sistemlər məlumatlarda dəyişiklik məlumatlarda dəyişiklik bağlantıları istifadə edirlər.", 'am': 'የዝሙት ውይይት በመሳዊ ትርጓሜ ውስጥ የሴቶችን ጉዳይ በመምረጥ የሴቶችን ጉዳይ በመምረጥ ይችላል፡፡ ለምሳሌ፣ ሁልጊዜ ሐኪሞችን ወንዶችና ሞግዚቶችን እንደ ሴት ትምህርት ይናገራሉ፡፡ በንግድ ስርዓት ውስጥ መሆኑን እና በንግድ ስርዓት ውስጥ የሚነካ መሆኑን ይችላል፡፡ ሥራችን ከ19 በላይ የተለየ የአሁኑ ደረጃ ቋንቋዎች ላይ ለWMT በሚገልጹት ስርዓቶች የሚበልጡትን ትልቁ ማስረጃ ያሳያል፤ ቻክክ፣ ጀርመን፣ ፖሊስ እና ራሽኛ፡፡ ይህንን ለማግኘት፣ አዲስ የኮንቨርስቲ ፍትሕ እና በንግግሊዝኛ ወደ ቋንቋዎች በመተርጓም እና በቋንቋዎች ላይ በግራማtical gender በመመርመርመር እና የውንዶች ኮርፌንሽን እና የውይይይት ጉዳይ የሚለውን WinoMT እንጠይቃለን፡፡ በWMT: ፖሊሽ እና ቻክክ የተፈተነውን ሁለት አዲስ ቋንቋዎች ለመቀበል WinoMT እናዘጋጅታለን፡፡ የድምፅ ስርዓቶች ሁሉ በጥያቄ መረጃዎች ላይ ከመጠቀም ይልቅ የጥያቄ ግንኙነት እንዲጠቀሙ እናገኛለን፡፡', 'bs': 'Ženska predrasuda u prevodu mašine može se pojaviti kada bira spolne utjecaje na temelju spolnih korelacija. Na primjer, uvek prevode liječnike kao muškarce i sestre kao žene. To može biti posebno štetnije jer modeli postaju popularniji i raspoređeniji u komercijalnim sistemima. Naš rad predstavlja najveći dokaz za fenomen u više od 19 sustava podignut WMT-u na četiri različite ciljne jezike: češki, nemački, poljski i ruski. Da bi to postigli, koristimo WinoMT, nedavni automatski test apartman koji pregleda seksualnu pristojnost i predrasude kada se prevodi sa engleskog na jezike sa gramatičkim spolom. Proširimo WinoMT kako bi rješavali dvije nove jezike testovane na WMT-u: poljski i češki. Mi smatramo da svi sistemi stalno koriste oštećene korelacije u podacima umjesto značajne kontekstske informacije.', 'bn': 'মেশিন অনুবাদে লিঙ্গের বিরুদ্ধে লিঙ্গের প্রভাব বেছে নেওয়ার সময় প্রকাশ করতে পারে। উদাহরণস্বরূপ, সবসময় ডাক্তারকে নারী হিসেবে অনুবাদ করে। এটা বিশেষ ক্ষতিগ্রস্ত হতে পারে যেহেতু মডেল আরো জনপ্রিয় এবং বাণিজ্যিক সিস্টেমের মধ্যে প্রস্তুত হয়। আমাদের কাজ ১৯টির বেশী বিভিন্ন লক্ষ্য ভাষায় উইএমটিকে প্রদান করা ১৯ সিস্টেমের বেশী বৃহত্তম প্রমাণ উপস্থাপন করেছে: চেক, জার্মান, পো এটা অর্জন করার জন্য আমরা উইনোএমটি ব্যবহার করি সাম্প্রতিক এক স্বয়ংক্রিয় পরীক্ষার স্যুট, যা লিঙ্গের কোরেফেন্স এবং বিয়াস পরীক্ষা করেছে যখন ইংরেজ উইনএমটি: পোলিশ এবং চেকে পরীক্ষা করার জন্য আমরা উইনোএমটিকে দুই নতুন ভাষাকে সামলাতে পারি। আমরা খুঁজে পাচ্ছি যে সকল সিস্টেমের সাথে তথ্যে বিদ্রূপ সম্পর্ক ব্যবহার করে যার মানে যুক্তিগত তথ্যের বদলে।', 'ca': "Gender bias in machine translation can manifest when choosing gender inflections based on spurious gender correlations.  Per exemple, sempre traduir metges com homes i infermeres com dones. Això pot ser particularment nociu a mesura que els models es fan més populars i s'implementen en sistemes comercials. La nostra feina presenta l'evidència més gran del fenomen en més de 19 sistemes submetits al WMT en quatre llengües d'objectiu diverses: cec, alemany, polac i rus. Per aconseguir això, utilitzem WinoMT, una suite de provas automàtiques recent que examina la coreferència de gènere i el bias quan es tradueix d'anglès a llengües amb gènere gramàtic. Estendem el WinoMT per manejar dues llengües noves testades en WMT: polac i cec. Trobem que tots els sistemes utilitzen correlacions esportives a les dades en comptes d'informació contextual significativa.", 'cs': 'Gender bias v strojovém překladu se může projevit při volbě genderových flexí založených na falešných genderových korelacích. Například vždy překládat lékaře jako muži a sestry jako ženy. To může být obzvláště škodlivé, protože modely se stávají oblíbenější a nasazené v komerčních systémech. Naše práce představuje největší důkazy o tomto jevu ve více než 19-tých systémech předložených WMT ve čtyřech různých cílových jazycích: češtině, němčině, polštině a ruštině. K dosažení tohoto cíle používáme WinoMT, nedávné automatické testovací sady, která zkoumá genderovou koreferenci a předsudky při překladu z angličtiny do jazyků s gramatickým pohlavím. Rozšiřujeme WinoMT o dva nové jazyky testované ve WMT: polštinu a češtinu. Zjišťujeme, že všechny systémy konzistentně používají falešné korelace v datech spíše než smysluplné kontextové informace.', 'et': 'Sooline eelarvamus masintõlkes võib ilmneda soolise paindlikkuse valimisel, mis põhineb võltsitud sookorrelatsioonidel. Näiteks alati tõlkida arste meesteks ja õdesid naisteks. See võib olla eriti kahjulik, kuna mudelid muutuvad populaarsemaks ja kasutusele võetakse kommertssüsteemides. Meie töö esitab suurimad tõendid selle nähtuse kohta enam kui 19 süsteemis, mis on esitatud WMT-le neljas erinevas sihtkeeles: tšehhi, saksa, poola ja vene keeles. Selle saavutamiseks kasutame WinoMT-i, hiljutist automaatset testikomplekti, mis uurib soolist sidusust ja erapooletust inglise keelest grammatilise sooga keeltesse tõlkimisel. Laiendame WinoMT-i kahele uuele WMT-keelele: poola ja tšehhi keelele. Leiame, et kõik süsteemid kasutavad andmetes pidevalt valesid korrelatsioone, mitte mõistlikku kontekstiteavet.', 'fi': 'Sukupuoliharha konekäännöksessä voi ilmetä valitessaan sukupuolen taipumuksia väärien sukupuolikorrelaatioiden perusteella. Esimerkiksi aina kääntää lääkäreitä miehiksi ja sairaanhoitajia naisiksi. Tämä voi olla erityisen haitallista, kun mallit yleistyvät ja ne otetaan käyttöön kaupallisissa järjestelmissä. Työssämme esitetään suurin todiste ilmiöstä yli 19:ssä WMT:lle toimitetussa järjestelmässä neljällä eri kohdekielellä: tšekki, saksa, puola ja venäjä. Tämän saavuttamiseksi käytämme WinoMT:tä, tuoretta automaattista testipakettia, joka tutkii sukupuolen vastaavuutta ja puolueellisuutta käännettäessä englannista kieliopillisen sukupuolen omaaville kielille. Laajennamme WinoMT:n käsittelemään kahta uutta WMT:llä testattua kieltä: puolaa ja tšekki. Havaitsemme, että kaikki järjestelmät käyttävät johdonmukaisesti vääriä korrelaatioita datassa sen sijaan, että merkityksellisiä kontekstitietoja.', 'jv': 'Genjer-bias kanggo tarjamahan dino, iso dianggo ngerasai kapan ijol-ijolan winih sing supoyo nggawe barang-ijolan winih. Na kesempatan, lagi ngguyu langkung saé dicopo karo perbudhakan lan nganggep dino. Iki iso ngomong karo akeh deweke sampeyan kaya model sing wis populer dan nguasai sistem komersir. Awakdhéwé éntuk nggawe perbudhakan kanggo akeh barêng dumadhi kanggo 19 sistem sing nyimpen kanggo WWT kuwi kapan langa sing kalah-kalah: Chek, German, polan lan Russisa. Rasané iki, awak dhéwé éntukno Wino MT, ngêngêngé surat perusahaan sistem otomatik sing isiné ngêngêngé karo ngêwongké (gérané) lan ujar-ujar terjamahan kanggo ngêngêngêng langta karo ngêngêngêng. Awak dhéwé luwih-luwih Wino MT kanggo ngegambar langa sing uwis seneng pisan WWT: Puoleh lan Cepek. Awak dhéwé luwih sistem punika dipun akeh perusahaan langgar sampeyan ingkang data karo informasi sing dikarepaké contextual.', 'ha': "@ action: button Misali, ko da yaushe, sunã fassarar dokumenta kamar maza da mace. This can be particularly harmful as models become more popular and deployed within commercial systems.  Kayinmu yana bayan mafi girma ga abu da ke cikin wasu na'uran 19 wanda aka saka wa WMT da wasu harshen huɗu masu turu: Kicheki, Jarman, Polushi da Ruushi. Yana amfani da WinoMT, a shekarar jarraba ɗin farat ɗaya, wanda ke jarraba littafin mutane da yin sauri idan an tarjima daga Ingiriya zuwa harshen zuwa jinin grammatisk. Munã shimfiɗa WinoMT dõmin ka yi amfani da harshen biyu na daba'a wanda aka jarraba cikin WMT: Polish da Czech. Muna gane cewa dukkan system sun yi amfani da tsaro masu ƙaranci a cikin data, kuma bã da muhimu ga information masu cikin guda.", 'he': "ההתמחות מינית בתרגום מכונות יכולה להתברר כשבוחרת השפעות מינית מבוססת על יחסי מין מרושעים. לדוגמה, תמיד תורגם רופאים כגברים ואחות כנשים. זה יכול להיות מזיק במיוחד כשדוגמנים הופכים לפופולריים יותר ומשתמשים בתוך מערכות מסחריות. העבודה שלנו מציגה את הראיות הגדולות ביותר לתופעה ב-19 מערכות שנשלחו אל WMT על ארבעה שפות מטרה מגוונות: צ'ק, גרמני, פולני, ורוסי. כדי להשיג את זה, אנו משתמשים בווינומט, סוויטה מבחן אוטומטית לאחרונה שבדקה את היחסים והתמונות של מין כשמתרגמים מאנגלית לשפות עם מין גרמטי. אנחנו ממשיכים את וינומט כדי לטפל בשתי שפות חדשות שנבחנות ב-WMT: פולנית וצ'קית. We find that all systems consistently use spurious correlations in the data rather than meaningful contextual information.", 'sk': 'Spolna pristranskost pri strojnem prevajanju se lahko kaže pri izbiri spolnih infleksij, ki temeljijo na lažnih spolnih korelacijah. Na primer, vedno prevajajo zdravnike kot moške in medicinske sestre kot ženske. To je lahko še posebej škodljivo, saj modeli postajajo bolj priljubljeni in se uporabljajo v komercialnih sistemih. Naše delo predstavlja največje dokaze za pojav v več kot 19 sistemih, predloženih WMT v štirih različnih ciljnih jezikih: češkem, nemškem, poljskem in ruskem. Za dosego tega uporabljamo WinoMT, nedavni avtomatski testni paket, ki proučuje povezanost spolov in pristranskost pri prevajanju iz angleščine v jezike s slovničnim spolom. WinoMT razširimo na dva nova jezika, testirana v WMT: poljščina in češčina. Ugotavljamo, da vsi sistemi dosledno uporabljajo lažne korelacije v podatkih namesto smiselnih kontekstnih informacij.', 'bo': 'དམིགས་འཛུགས་ཀྱི་སྐྱེས་ཚུལ་དང་མིའི་རྣམ་པ་ནང་གི་འགྲེལ་བཤད་པ་དེ་གསལ་བཤད་ཐུབ་པ་དང་། དཔེར་ན། སྨན་པ་རྟག་པར་སྐྱེས་པ་དང་། སྨན་ཞབས་མི་ཚོས་བུད་མེད་བཞིན་བསྐྱར། འདི་དག་མིག་གཟུགས་རིས་མང་ཤོས་མེད་པར་སྐྱུར་བརྗོད་བྱེད་ཆེས་པོ་ཞིག་ཡིན་ཏེ། ང་ཚོའི་ལས་ཀ་ལྟ་བུའི་སྐྱེས་ཆེ་ཤོས་གཅིག་པུ་ཡིན་པས་རིགས་ཆའི་ནང་གི་སྒེར་ཆས་༡༩་ལས་མང་ཤོས་ཀྱི་རྟོགས་བཤད་འདོད་པ་ཡིན། To achieve this, we use WinoMT, a recent automatic test suite which examines gender coreference and bias when translating from English to languages with grammatical gender. We extend WinoMT to handle two new languages tested in WMT: Polish and Czech. ང་ཚོས་མ་ལག་ཆ་ཡོངས་རྫོགས་གྱིས་གནས་ཚུལ་ནང་གི་མཉམ་དུ་མཐུན་འགྱུར་བ་སྤྱོད་ཡོད།'}
{'en': 'Translating Similar Languages : Role of Mutual Intelligibility in Multilingual Transformers', 'ar': 'ترجمة لغات مماثلة: دور الذكاء المتبادل في المحولات متعددة اللغات', 'pt': 'Traduzindo idiomas semelhantes: papel da inteligibilidade mútua em transformadores multilíngues', 'es': 'Traducción de idiomas similares: papel de la inteligibilidad mutua en los transformadores multilingües', 'fr': "Traduction de langues similaires\xa0: rôle de l'intelligibilité mutuelle dans les transformateurs multilingues", 'ja': '類似言語の翻訳：多言語変換における相互理解性の役割', 'hi': 'समान भाषाओं का अनुवाद: बहुभाषी ट्रांसफॉर्मर में पारस्परिक बोधगम्यता की भूमिका', 'zh': '译类语:互懂性在多言转换器中之用', 'ru': 'Перевод похожих языков: роль взаимной разборчивости в многоязычных трансформаторах', 'ga': 'Teangacha Comhchosúla a Aistriú: Ról na Comh-intleachta i gClaochladáin Ilteangacha', 'hu': 'Hasonló nyelvek fordítása: A kölcsönös értelmiség szerepe a többnyelvű transzformátorokban', 'el': 'Μετάφραση παρόμοιων γλωσσών: Ρόλος της αμοιβαίας ευφυΐας σε πολύγλωσσους μετασχηματιστές', 'it': "Tradurre lingue simili: ruolo dell'intelligibilità reciproca nei trasformatori multilingui", 'kk': 'Бұндай тілдерді аудару: Бірнеше тілдерді түрлендірушілердің біріктірімінің рөлі', 'lt': 'Panašių kalbų vertimas: abipusio išmintingumo vaidmuo daugiakalbėse transformacijose', 'ka': 'მრავალური ტრანფორმაციის პროლია', 'ml': 'സമമായ ഭാഷകള്\u200d പരിഭാഷപ്പെടുത്തുന്നു', 'mt': 'Translating Similar Languages: Role of Mutual Intelligibility in Multilingual Transformers', 'mn': 'Ийм төстэй хэлнүүд: Олон хэлний шилжүүлэгчдийн харилцааны үүрэг', 'no': 'Omsetjing på liknande språk: rolle av mellomtale integritet i fleirspråkstransformatorar', 'mk': 'Translating Similar Languages: Role of Mutual Intelligibility in Multilingual Transformers', 'pl': 'Tłumaczenie podobnych języków: Rola wzajemnej inteligencji w transformatorach wielojęzycznych', 'ro': 'Traducerea limbilor similare: Rolul inteligibilității reciproce în transformatorii multilingvi', 'sr': 'Prijevod sličnih jezika: uloga međusobne inteligencije u multijezičkim transformatorima', 'si': 'සමාන භාෂාවක් භාෂාවක් භාෂාවක්: භාෂාවක් සමාන්\u200dය තියෙන්න පුළුවන්', 'so': 'Turjumista luuqadaha isku mid ah: Role of Mutual Intellibility in turjumista luuqadaha badan', 'sv': 'Översättning av liknande språk: Den ömsesidiga intelligibilitetens roll i flerspråkiga transformatorer', 'ta': 'மொழிகளை மொழிபெயர்ப்பு', 'ur': 'Similar Languages Translating: Role of Mutual Intelligibility in Multilingual Transformers', 'ms': 'Menerjemahkan Bahasa Sama: Rol Kecerdasan Bersama-sama dalam Penukar Berbahasa', 'uz': 'Tillarni tarjima qilish', 'vi': 'Dịch Ngôn ngữ Tương tự: vai trò của khả năng chung chung', 'hr': 'Prijevod sličnih jezika: uloga međusobne inteligencije u multijezičkim transformatorima', 'bg': 'Превод на подобни езици: ролята на взаимната интелигентност в многоезичните трансформатори', 'nl': 'Vergelijkbare talen vertalen: De rol van wederzijdse intelligentie in meertalige transformatoren', 'da': 'Oversættelse af lignende sprog: Den gensidige intelligibilitets rolle i flersprogede transformatorer', 'de': 'Übersetzung ähnlicher Sprachen: Rolle der gegenseitigen Intelligenz in mehrsprachigen Transformatoren', 'id': 'Menerjemahkan Bahasa Sama: Rol Kecerdasan Bersama-sama dalam Transformer Berbahasa', 'fa': 'ترجمه زبانهای شبیه: نقش تغییردهنده\u200cهای زیادی زبان\u200cها', 'ko': '다언어 변환에서의 상호 이해 작용', 'sw': 'Lugha zinazotafsiri zinazofanana: Nafasi ya Uelelezi wa Haki katika Watafsiri wa lugha nyingi', 'sq': 'Përkthimi i gjuhëve të ngjashme: Roli i inteligjencës së ndërsjelltë në transformuesit shumëgjuhës', 'af': 'Vertaling van gelyke tale: rol van Mutual Inteligibility in Multilingual Transformers', 'tr': 'Durumlar', 'am': 'ቋንቋዎች', 'hy': 'Նմանատիպ լեզուներ թարգմանելը. Միաքին խելացիության դեր բազլեզու թարգմանիչներում', 'az': 'Aynı dilləri tercümə edir: Çoxlu dil transformatörlərində müxtəlif fikirləşirlərin rolü', 'bn': 'অনুবাদ করা হচ্ছে একই ভাষা: বহুভাষাভাষী ট্রান্সফর্মারের মাউটুয়েলিজিবিলিটির ভূমিকা', 'bs': 'Prijevod sličnih jezika: uloga međusobne inteligencije u multijezičkim transformatorima', 'ca': 'Traducció de llengües similars: El paper de la intel·ligibilitat mutua en transformadors multilingües', 'cs': 'Překlad podobných jazyků: Role vzájemné inteligence v multijazyčných transformátorech', 'et': 'Sarnaste keelte tõlkimine: vastastikuse arukuse roll mitmekeelsetes transformaatorites', 'fi': 'Samankaltaisten kielten kääntäminen: Keskinäisen älykkyyden rooli monikielisissä muuntajissa', 'ha': '@ label: listbox', 'jv': 'Ngubah Anyang Sampeyan: Ngubah Keterangan Puteran Ubah kanggo Keterangan Multilanggar', 'he': 'תורגם ע"י Qsubs מצוות', 'sk': 'Prevajanje podobnih jezikov: vloga medsebojne inteligentnosti v večjezičnih transformatorjih', 'bo': 'ཕན་ཚུན་འདུག་པའི་སྐད་ཡིག་དང་མཉམ་དུ་བསླབས་པའི་རིམ།'}
{'en': 'In this work we investigate different approaches to translate between similar languages despite low resource limitations. This work is done as the participation of the UBC NLP research group in the WMT 2019 Similar Languages Translation Shared Task. We participated in all language pairs and performed various experiments. We used a transformer architecture for all the models and used back-translation for one of the language pairs. We explore both bilingual and multi-lingual approaches. We describe the pre-processing, training, translation and results for each model. We also investigate the role of mutual intelligibility in model performance.', 'ar': 'في هذا العمل ، نتحرى عن طرق مختلفة للترجمة بين اللغات المتشابهة على الرغم من محدودية الموارد. يتم تنفيذ هذا العمل كمشاركة لمجموعة UBC NLP البحثية في المهمة المشتركة لترجمة اللغات المتشابهة لعام 2019 في WMT. شاركنا في جميع أزواج اللغات وأجرينا تجارب مختلفة. استخدمنا بنية المحولات لجميع النماذج واستخدمنا الترجمة الخلفية لأحد أزواج اللغات. نستكشف كل من المناهج ثنائية اللغة ومتعددة اللغات. نصف المعالجة المسبقة والتدريب والترجمة والنتائج لكل نموذج. نحن نحقق أيضًا في دور الوضوح المتبادل في أداء النموذج.', 'es': 'En este trabajo investigamos diferentes enfoques para traducir entre idiomas similares a pesar de las escasas limitaciones de recursos. Este trabajo se realiza como la participación del grupo de investigación de PNL de la UBC en la tarea compartida de traducción de idiomas similares del WMT 2019. Participamos en todos los pares de idiomas y realizamos varios experimentos. Utilizamos una arquitectura transformadora para todos los modelos y utilizamos la traducción inversa para uno de los pares de idiomas. Exploramos enfoques bilingües y multilingües. Describimos el procesamiento previo, la capacitación, la traducción y los resultados de cada modelo. También investigamos el papel de la inteligibilidad mutua en el rendimiento del modelo.', 'pt': 'Neste trabalho, investigamos diferentes abordagens para traduzir entre idiomas semelhantes, apesar das poucas limitações de recursos. Este trabalho é feito como a participação do grupo de pesquisa UBC NLP na Tarefa Compartilhada de Tradução de Idiomas Semelhantes do WMT 2019. Participamos de todos os pares de línguas e realizamos vários experimentos. Usamos uma arquitetura de transformador para todos os modelos e usamos a tradução reversa para um dos pares de idiomas. Exploramos abordagens bilíngües e multilíngues. Descrevemos o pré-processamento, treinamento, tradução e resultados para cada modelo. Também investigamos o papel da inteligibilidade mútua no desempenho do modelo.', 'fr': "Dans ce travail, nous étudions différentes approches pour traduire entre des langues similaires malgré de faibles ressources limitées. Ce travail est réalisé dans le cadre de la participation du groupe de recherche NLP de l'UBC à la tâche partagée de traduction des langues similaires WMT 2019. Nous avons participé à toutes les paires de langues et réalisé diverses expériences. Nous avons utilisé une architecture de transformateur pour tous les modèles et utilisé la rétro-traduction pour l'une des paires de langues. Nous explorons des approches bilingues et multilingues. Nous décrivons le prétraitement, la formation, la traduction et les résultats pour chaque modèle. Nous étudions également le rôle de l'intelligibilité mutuelle dans les performances des modèles.", 'ja': 'この研究では、リソースの制限が少ないにもかかわらず、類似の言語間で翻訳するための異なるアプローチを調査します。この作業は、WMT 2019類似言語翻訳共有タスクへのUBC NLP研究グループの参加として行われます。すべての言語ペアに参加し、様々な実験を行った。すべてのモデルに変圧器アーキテクチャを使用し、言語ペアの1つに逆翻訳を使用しました。バイリンガルとマルチリンガルの両方のアプローチを模索しています。各モデルの前処理、トレーニング、翻訳、結果について説明します。モデルの性能における相互理解性の役割についても調査します。', 'zh': '于此,臣等考之虽资源限下,而译者异于言语之间。 其为UBC NLP也小组与WMT 2019类言语译共其事而成之。 尽与诸实验。 凡诸模转换器架构,一言反译。 探双语多语法。 凡模预处理、教习、译和。 论相知性在模形性中。', 'hi': 'इस काम में हम कम संसाधन सीमाओं के बावजूद समान भाषाओं के बीच अनुवाद करने के लिए विभिन्न दृष्टिकोणों की जांच करते हैं। यह काम WMT 2019 समान भाषाओं अनुवाद साझा कार्य में UBC NLP अनुसंधान समूह की भागीदारी के रूप में किया जाता है। हमने सभी भाषा जोड़े में भाग लिया और विभिन्न प्रयोगों का प्रदर्शन किया। हमने सभी मॉडलों के लिए एक ट्रांसफॉर्मर आर्किटेक्चर का उपयोग किया और भाषा जोड़े में से एक के लिए बैक-ट्रांसलेशन का उपयोग किया। हम द्विभाषी और बहुभाषी दोनों दृष्टिकोणों का पता लगाते हैं। हम प्रत्येक मॉडल के लिए पूर्व-प्रसंस्करण, प्रशिक्षण, अनुवाद और परिणामों का वर्णन करते हैं। हम मॉडल प्रदर्शन में पारस्परिक स्पष्टता की भूमिका की भी जांच करते हैं।', 'ru': 'В этой работе мы исследуем различные подходы к переводу между похожими языками, несмотря на низкие ограничения ресурсов. Эта работа выполняется в качестве участия исследовательской группы UBC NLP в совместной задаче WMT 2019 по переводу на аналогичные языки. Мы участвовали во всех языковых парах и проводили различные эксперименты. Мы использовали трансформаторную архитектуру для всех моделей и использовали обратный перевод для одной из языковых пар. Мы изучаем как двуязычный, так и многоязычный подходы. Мы описываем предварительную обработку, обучение, перевод и результаты для каждой модели. Мы также исследуем роль взаимной разборчивости в эффективности модели.', 'ga': 'San obair seo déanaimid imscrúdú ar chuir chuige éagsúla chun aistriúchán a dhéanamh idir teangacha comhchosúla in ainneoin srianta ísle acmhainní. Déantar an obair seo mar rannpháirtíocht ghrúpa taighde UBC NLP i dTasc Comhroinnte Aistriú Teangacha Comhchosúla WMT 2019. Ghlacamar páirt i bpéirí teanga ar fad agus rinneamar turgnaimh éagsúla. D’úsáideamar ailtireacht chlaochladáin do na múnlaí ar fad agus d’úsáideamar cúl-aistriúchán do cheann de na péirí teanga. Déanaimid iniúchadh ar chur chuige dátheangacha agus ilteangacha araon. Déanaimid cur síos ar réamhphróiseáil, oiliúint, aistriúchán agus torthaí gach múnla. Déanaimid imscrúdú freisin ar an ról atá ag comhthuiscint i bhfeidhmiú samhla.', 'hu': 'Ebben a munkában különböző megközelítéseket vizsgálunk a hasonló nyelvek közötti fordításra, az alacsony erőforrás-korlátozás ellenére. Ez a munka az UBC NLP kutatócsoport részvételével történik a WMT 2019 Hasonló Nyelvek Fordítási Megosztott Feladatában. Minden nyelvpárban részt vettünk és különböző kísérleteket végeztünk. Az összes modellhez transzformátor architektúrát használtunk, az egyik nyelvpárhoz pedig háttérfordítást használtunk. Mind a kétnyelvű, mind a többnyelvű megközelítéseket vizsgáljuk. Minden modell előfeldolgozását, képzését, fordítását és eredményeit ismertetjük. Vizsgáljuk továbbá a kölcsönös érthetőség szerepét a modellteljesítményben.', 'it': "In questo lavoro esaminiamo diversi approcci per tradurre tra lingue simili nonostante le scarse limitazioni delle risorse. Questo lavoro viene svolto con la partecipazione del gruppo di ricerca UBC NLP al WMT 2019 Similar Languages Translation Shared Task. Abbiamo partecipato a tutte le coppie linguistiche ed eseguito vari esperimenti. Abbiamo usato un'architettura di trasformatore per tutti i modelli e usato la traduzione posteriore per una delle coppie linguistiche. Esploriamo approcci bilingui e multilingui. Descriviamo la pre-elaborazione, la formazione, la traduzione e i risultati per ogni modello. Esaminiamo anche il ruolo della mutua intelligibilità nelle prestazioni del modello.", 'el': 'Σε αυτή την εργασία διερευνούμε διαφορετικές προσεγγίσεις για τη μετάφραση μεταξύ παρόμοιων γλωσσών παρά τους χαμηλούς περιορισμούς πόρων. Το έργο αυτό γίνεται με τη συμμετοχή της ερευνητικής ομάδας στο κοινό έργο μετάφρασης παρόμοιων γλωσσών. Συμμετείχαμε σε όλα τα γλωσσικά ζευγάρια και πραγματοποιήσαμε διάφορα πειράματα. Χρησιμοποιήσαμε μια αρχιτεκτονική μετασχηματιστή για όλα τα μοντέλα και χρησιμοποιήσαμε αντίστροφη μετάφραση για ένα από τα γλωσσικά ζεύγη. Ερευνούμε τόσο δίγλωσσες όσο και πολυγλωσσικές προσεγγίσεις. Περιγράφουμε την προεπεξεργασία, την εκπαίδευση, τη μετάφραση και τα αποτελέσματα για κάθε μοντέλο. Ερευνούμε επίσης το ρόλο της αμοιβαίας κατανόησης στην απόδοση του μοντέλου.', 'kk': 'Бұл жұмыс ішінде біз ұқсас тілдер арасында аударуға арналған әртүрлі арқылы зерттеп, ресурстардың шектеулеріне қарай. Бұл жұмыс WMT 2019-нің UBC NLP зерттеу тобына ұқсас тілдерді аудару ортақ тапсырманың қатынасы ретінде істеді. Біз тіл екеуіне қатысу және әртүрлі тәжірибелерді істедік. Біз барлық үлгілер үшін түрлендіруші архитектурасын қолдандық және тілдердің біріне қайта аударуын қолдандық. Біз екі тілді және көп тілді жағдайларды зерттейміз. Біз әрбір үлгі үшін алдын- ала процесс, оқыту, аудару және нәтижелерді анықтаймыз. Біз сондай-ақ үлгі істеу үшін бір-бірінші интеллигиялық рөлін зерттейміз.', 'lt': 'In this work we investigate different approaches to translate between similar languages despite low resource limitations.  This work is done as the participation of the UBC NLP research group in the WMT 2019 Similar Languages Translation Shared Task.  We participated in all language pairs and performed various experiments.  We used a transformer architecture for all the models and used back-translation for one of the language pairs.  Mes tiriame dvikalbį ir daugiakalbį požiūrį. We describe the pre-processing, training, translation and results for each model.  Taip pat tiriame abipusio supratimo vaidmenį modelio veiklos rezultatuose.', 'ka': 'ამ სამუშაოში ჩვენ განსხვავებულ წარმოდგენების განსხვავება, რომელიც განსხვავებული ენების შორის განსხვავება, მაგრამ მინუს რესურსების განსხვავებ ეს სამუშაო გავაკეთება როგორც UBC NLP შესწავლობის ჯგუფის დამატება WMT 2019-ში, როგორც მსგავსი ენების გადასწავლობის გაყოფილი სამუშაო რაოდენობაში. ჩვენ ყველა ენის ზოგში დავამწევეთ და განსხვავებული ექსპერიმენტებში გავაკეთეთ. ჩვენ ყველა მოდელისთვის ტრანფორმეტრის არქტიქტურის გამოყენება და ერთი ენის ზოგებისთვის გამოყენება. ჩვენ ორივე ენგური და მრავალური ენგური მიღებების განსხვავება. ჩვენ ყველა მოდელის წინაპროცესის, განაცემის, განაცემის და შემდეგის შესახებ დავწერეთ. ჩვენ ასევე განსხვავებთ ერთმანეთის ინტელლიგიდაბულობის პროლია მოდელური მუშაობაში.', 'mk': 'Во оваа работа истражуваме различни пристапи за преведување помеѓу слични јазици и покрај ниските ограничувања на ресурсите. Оваа работа се врши како учество на истражувачката група на УБЦ НЛП во ВМТ 2019 на задачата на подедничките јазици за превод. Ние учествувавме во сите јазички парови и извршивме различни експерименти. Користевме трансформаторска архитектура за сите модели и користевме превод за еден од јазичките парови. We explore both bilingual and multi-lingual approaches.  Го опишуваме преобработувањето, обуката, преводот и резултатите за секој модел. Исто така ја истражуваме улогата на взаемната интелигибилитет во моделната изведба.', 'ms': 'Dalam kerja ini kami menyelidiki pendekatan yang berbeza untuk menerjemahkan antara bahasa yang sama walaupun keterangan sumber rendah. Kerja ini dilakukan sebagai pesertaan kumpulan penelitian NLP UBC dalam Tugas Terkongsi Perjemahan Bahasa Sama-sama WMT 2019. Kami berpartisipasi dalam semua pasangan bahasa dan melakukan pelbagai eksperimen. We used a transformer architecture for all the models and used back-translation for one of the language pairs.  Kami mengeksplorasi pendekatan dua bahasa dan berbilang bahasa. Kami menggambarkan praproses, latihan, terjemahan dan keputusan untuk setiap model. Kami juga menyelidiki peran pemahaman bersama dalam prestasi model.', 'mt': 'F’dan ix-xogħol ninvestigaw approċċi differenti għat-traduzzjoni bejn lingwi simili minkejja limitazzjonijiet baxxi tar-riżorsi. This work is done as the participation of the UBC NLP research group in the WMT 2019 Similar Languages Translation Shared Task.  Parteċipajna fil-pari lingwistiċi kollha u għamilna diversi esperimenti. Użajna arkitettura tat-trasformatur għall-mudelli kollha u użajna traduzzjoni lura għal wieħed mill-pari lingwistiċi. Aħna nesploraw approċċi kemm bilngwi kif ukoll multilingwi. Aħna niddeskrivu l-ipproċessar minn qabel, it-taħriġ, it-traduzzjoni u r-riżultati għal kull mudell. Investigaw ukoll ir-rwol tal-intelliġibbiltà reċiproka fil-prestazzjoni tal-mudell.', 'ml': 'ഈ ജോലിയില്\u200d വ്യത്യസ്ത ഭാഷകള്\u200dക്കിടയില്\u200d വ്യത്യസ്ത മാര്\u200dഗങ്ങള്\u200d പരിശോധിക്കുന്നു. വിഭവവിഭവങ്ങള്\u200d കുറ This work is done as the participation of the UBC NLP research group in the WMT 2019 Similar Languages Translation Shared Task.  ഞങ്ങള്\u200d എല്ലാ ഭാഷയിലും ജോടികളിലും പങ്കുചേര്\u200dന്നു വ്യത്യസ്ത പരീക്ഷണങ്ങള്\u200d ചെയ്തു. ഞങ്ങള്\u200d എല്ലാ മാതൃകങ്ങള്\u200dക്കും ഒരു മാറ്റം മാറ്റുന്ന ആര്\u200dക്കിട്ടറി ഉപയോഗിച്ച് ഭാഷ ജോടികള്\u200dക്ക് വേണ്ടി പിന നമ്മള്\u200d രണ്ടു ഭാഷക്കാരെയും പല ഭാഷക്കാരെയും പരിശോധിക്കുന്നു. എല്ലാ മോഡലിന്റെയും മുന്\u200dപ് പ്രോസിക്ക്, പരിശീലനം, പരിഭാഷകള്\u200d, ഫലങ്ങളും ഞങ്ങള്\u200d വിശദീകരിക്കുന്നു. മോഡല്\u200d പ്രകടനത്തില്\u200d തമ്മിലുള്ള ബുദ്ധിമുട്ടിയുടെ പങ്ക് ഞങ്ങള്\u200d അന്വേഷിക്കുന്നു.', 'mn': 'Энэ ажлын тулд бид ижил хэл хоорондох өөр арга замыг судалж, бага нөөцийн хязгаарлалттай ч гэсэн. Энэ ажлыг WMT 2019 оны UBC NLP судалгааны багийн хувьд хуваалцах ажлын хувьд хийсэн. Бид бүх хэл хоёрт оролцож, олон туршилтыг хийсэн. Бид бүх загваруудын хувьд шилжүүлэгч архитектурыг ашиглаж, хэл хоёрын нэг төрлийн хувьд дахин хөрөнгө оруулсан. Бид хоёр хэлний болон олон хэлний арга барилгыг судалж байна. Бид бүх загварын өмнө үйлдвэрлэл, дасгал хөдөлгөөн, орчуулалт болон үр дүнг тайлбарлаж байна. Бид мөн загварын үйл ажиллагаанд харилцааны ухаантай байдлыг судалдаг.', 'no': 'I dette arbeidet undersøker vi ulike tilnærmingar for å oversette mellom liknande språk, selv om det er låg ressursgrenser. Dette arbeidet er gjort som deltakaren av UBC NLP-forskningsgruppa i WMT 2019 delt delt oppgåve som liknar omsetjing av språk. Vi deltok på alle språkopar og utførte forskjellige eksperimenter. Vi brukte ein transformeringsarkitektur for alle modelane og brukte tilbakeomsetjing for ein av språkoplane. Vi undersøker både bilinguelt og fleirspråk tilnærmingar. Vi skildrar førehandsaming, trening, omsetjing og resultatet for kvar modell. Vi undersøker også rolen på mutual intelligibilitet i modellen.', 'pl': 'W niniejszej pracy badamy różne podejścia do tłumaczenia pomiędzy podobnymi językami pomimo niskich ograniczeń zasobów. Praca ta odbywa się w ramach udziału grupy badawczej UBC NLP w WMT 2019 Podobne Języki Translation Shared Task. Uczestniczyliśmy we wszystkich parach językowych i przeprowadziliśmy różne eksperymenty. Zastosowaliśmy architekturę transformatora dla wszystkich modeli i wykorzystaliśmy tłumaczenie wsteczne dla jednej z par językowych. Badamy zarówno podejście dwujęzyczne, jak i wielojęzyczne. Opisujemy wstępne przetwarzanie, szkolenie, tłumaczenie i wyniki dla każdego modelu. Badamy również rolę wzajemnej zrozumiałości w wydajności modelu.', 'ro': 'În această lucrare investigăm diferite abordări de traducere între limbi similare, în ciuda limitărilor reduse de resurse. Această lucrare se realizează ca participare a grupului de cercetare UBC PNL la activitatea partajată WMT 2019 Similar Languages Translation Shared Task. Am participat la toate perechile lingvistice și am efectuat diverse experimente. Am folosit o arhitectură transformatoare pentru toate modelele și am folosit traducerea înapoi pentru una dintre perechile de limbi. Explorăm atât abordări bilingve, cât și multilingve. Descriem pre-procesarea, instruirea, traducerea și rezultatele pentru fiecare model. De asemenea, investigăm rolul inteligibilității reciproce în performanța modelului.', 'si': 'මේ වැඩේ අපි වෙනස් භාෂාවක් අතර පරීක්ෂා කරනවා වගේ භාෂාවක් අතර පරීක්ෂා කරනවා. මේ වැඩ කරන්නේ UBC NLP පරීක්ෂණ කණ්ඩායමේ සමාන භාෂාවක් භාෂාව සමාන්\u200dය වැඩක් වලින් සමාන විශේෂ කණ්ඩායමේ ස අපි ඔක්කොම භාෂාවක් ජෝඩු වලට සම්බන්ධ කරලා විවිධ ප්\u200dරයෝජනය කරලා. අපි හැම මොඩේල්ස් වෙනුවෙන් ප්\u200dරවර්තනයක් පාවිච්චි කරලා භාෂාවක් ජෝඩාවක් වෙනුවෙන් පස්සේ ප අපි දෙකක් භාෂාවක් සහ බොහොම භාෂාවක් වගේ ප්\u200dරවේශනය කරනවා. අපි හැම මොඩේලට ප්\u200dරධාන පරික්ෂණය, ප්\u200dරීක්ෂණය, වාර්තාව සහ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති අපි පරීක්ෂණය කරනවා මොඩේල් ප්\u200dරමාණයේ සම්බන්ධ තේරුම්ගතාවක් ගැන.', 'so': 'Markaas waxan waxaynu baaritaan qaabab kala duduwan si aan u turjumno luqado kala duduwan inkastoo ay tahay xadiiqada rasmiga yar. Shaqadan waxaa loo sameeyaa sida qayb ka qaadashada kooxda waxbarashada ee UBC NLP ee WMT 2019 Turjumidda luqadaha u eg oo la mid ah. Waxaannu ka qeybqaadanay labada luqada oo dhan, waxaana sameynay imtixaano kala duduwan. Waxaan u isticmaalnay dhismaha bedela tusaalayaasha oo dhan, waxaana u isticmaalnay turjumid dib-tarjumid mid ka mid ah labada luqada. Waxaynu baaraynaa labada luuqadood oo kala duwan. Tusaale kasta baaraandegista, waxbarashada, turjumidda iyo resultiyada ayaannu u qornaa. Sidoo kale waxaynu baaraynaa qaybta garashada dhexe ee sameynta muusikada.', 'sv': 'I detta arbete undersöker vi olika sätt att översätta mellan liknande språk trots låga resursbegränsningar. Detta arbete görs som deltagande av UBC NLP forskargrupp i WMT 2019 Similar Languages Translation Shared Task. Vi deltog i alla språkpar och utförde olika experiment. Vi använde en transformatorarkitektur för alla modeller och använde backöversättning för ett av språkparen. Vi utforskar både tvåspråkiga och flerspråkiga tillvägagångssätt. Vi beskriver förbehandling, utbildning, översättning och resultat för varje modell. Vi undersöker också den ömsesidiga begriplighetens roll i modellprestanda.', 'ta': 'In this work we investigate different approaches to translate between similar languages despite low resource limitations.  Name நாங்கள் எல்லா மொழி ஜோடிகளிலும் பங்கிட்டோம் பல்வேறு சோதனைகளைச் செய்தோம். We used a transformer architecture for all the models and used back-translation for one of the language pairs.  இரண்டு மொழி மற்றும் பல மொழிகளின் அணுகுகளையும் நாம் கண்டறிகிறோம். ஒவ்வொரு மாதிரிக்கும் முன் செயல்பாடு, பயிற்சி, மொழிபெயர்ப்பு மற்றும் முடிவு நாம் மாதிரி செயல்பாட்டில் ஒருவருக்கொருவர் புரிந்துணர்வு விளையாடுகிறோம்.', 'sr': 'U ovom poslu istražujemo različite pristupe prevode između sličnih jezika uprkos niskim ograničenjima resursa. Ovaj rad se radi kao sudjelovanje UBC NLP istraživačke grupe u WMT 2019. sličnom delu prevoda jezika. Učestvovali smo u svim jezičkim parovima i izvršili različite eksperimente. Koristili smo transformatorsku arhitekturu za sve modele i koristili natrag prevod za jedan od jezičkih parova. Istražujemo i dvojezičke i višejezičke pristupe. Opišemo predobrazovanje, obuku, prevod i rezultate svakog modela. Istražujemo i ulogu međusobne inteligencije u modelu.', 'ur': 'ہم اس کام میں مختلف طریقوں کی تحقیق کرتے ہیں جو ان جیسی زبانوں کے درمیان تغییر دینے کے لئے مختلف طریقوں کی تحقیق کرتے ہیں، خواہ کم سرمایہ محدودیت کے ساتھ۔ یہ کام WBMT 2019 میں UBC NLP تحقیقات گروپ کی حصہ کے طور پر کیا گیا ہے۔ ہم نے تمام زبان جوڑوں میں شریک کیا اور مختلف تجربے کیا۔ ہم نے ہر مدل کے لئے ایک تغییر معمار بنانے کا استعمال کیا اور ایک زبان جوڑوں کے لئے پیچھے ترجمہ استعمال کیا۔ ہم دونوں زبانوں اور بہت سی زبانوں کی طریقوں کی تحقیق کرتے ہیں۔ ہم ہر موڈل کے لئے پیش پردازی، ترینس، ترینس اور نتیجے کا توصیح دیتے ہیں۔ ہم نے بھی مدل کی عملکرد میں ایک دوسرے سمجھنے والی رول کی تحقیق کی۔', 'uz': "Bu ishda biz bir xil manbaning chegaralari haqida turli tillar orasidagi boshqa usullarni o'rganamiz. Name Biz hamma tillar qo'l bilan murakkab qildik va har xil imtiyozlarni bajardik. Biz hamma modellar uchun o'zgarishni ishlatib, bir tilning ikkinchi xil uchun orqaga tarjima qilishni foydalandik. We explore both bilingual and multi-lingual approaches.  Biz har bir model uchun pre-processing, trening, tarjima va natijalarini anglatamiz. Biz model bajarishda bir necha intellektlarning rolini o'rganimiz.", 'vi': 'Trong công việc này, chúng tôi nghiên cứu các phương pháp khác nhau để dịch giữa các ngôn ngữ tương tự mặc dù có giới hạn tài nguyên thấp. Việc này được làm như là sự tham gia của nhóm nghiên cứu UBC NLP trong Công việc chia sẻ ngôn ngữ kiểu WRT bây giờ. Chúng tôi tham gia các cặp ngôn ngữ và thực hiện các thí nghiệm. Chúng tôi sử dụng một kiến trúc máy biến thế cho tất cả các mô hình và sử dụng dịch lại cho một trong những cặp ngôn ngữ. Chúng ta sẽ nghiên cứu hai thứ và ngôn ngữ rộng. Chúng tôi mô tả tiền chế, đào tạo, dịch và kết quả cho mỗi mô hình. Chúng tôi cũng điều tra vai trò trí tuệ lẫn nhau trong khả năng phục vụ mẫu.', 'bg': 'В тази работа изследваме различни подходи за превод между сходни езици въпреки ниските ресурсни ограничения. Тази работа се осъществява като участие на изследователската група за НЛП на ОБК в Споделената задача за превод на подобни езици. Участвахме във всички езикови двойки и проведохме различни експерименти. Използвахме трансформаторна архитектура за всички модели и обратен превод за една от езиковите двойки. Изследваме двуезичните и многоезичните подходи. Описваме предварителната обработка, обучението, превода и резултатите за всеки модел. Проучваме и ролята на взаимната разбираемост в представянето на модела.', 'hr': 'U ovom poslu istražujemo različite pristupe prevode između sličnih jezika uprkos niskim ograničenjima resursa. Ovaj rad se čini kao sudjelovanje UBC NLP istraživačke skupine u WMT 2019. sličnom zadatku za prevod jezika. Učestvovali smo u svim jezičkim parovima i izvršili različite eksperimente. Koristili smo transformacijsku arhitekturu za sve modele i koristili natrag prevod za jedan od jezičkih parova. Istražujemo i dvojezičke i višejezičke pristupe. Opišemo predobrazovanje, obuku, prevod i rezultate svakog modela. Istražujemo i ulogu međusobne inteligencije u modelu.', 'da': 'I dette arbejde undersøger vi forskellige tilgange til at oversætte mellem lignende sprog trods lave ressourcebegrænsninger. Dette arbejde udføres som deltagelse af UBC NLP-forskningsgruppen i WMT 2019 Similar Languages Translation Shared Task. Vi deltog i alle sprogpar og udførte forskellige eksperimenter. Vi brugte en transformer arkitektur til alle modellerne og brugte back-oversættelse til et af sprogparrene. Vi undersøger både tosprogede og flersprogede tilgange. Vi beskriver forbearbejdning, træning, oversættelse og resultater for hver model. Vi undersøger også den rolle, som gensidig forståelighed spiller i modelpræstation.', 'nl': 'In dit werk onderzoeken we verschillende benaderingen om te vertalen tussen vergelijkbare talen ondanks lage resourcebeperkingen. Dit werk wordt gedaan als de deelname van de UBC NLP onderzoeksgroep aan de WMT 2019 Vergelijkbare Talen Translation Shared Task. We namen deel aan alle taalparen en voerden verschillende experimenten uit. We gebruikten een transformatorarchitectuur voor alle modellen en gebruikten back-translation voor een van de taalparen. We onderzoeken zowel tweetalige als meertalige benaderingen. Voor elk model beschrijven we de voorbewerking, training, vertaling en resultaten. We onderzoeken ook de rol van wederzijdse verstaanbaarheid in modelprestaties.', 'de': 'In dieser Arbeit untersuchen wir verschiedene Ans채tze, um trotz geringer Ressourcenbeschr채nkungen zwischen 채hnlichen Sprachen zu 체bersetzen. Diese Arbeit erfolgt unter Beteiligung der UBC NLP Forschungsgruppe an der WMT 2019 횆hnliche Sprachen Translation Shared Task. Wir nahmen an allen Sprachpaaren teil und f체hrten verschiedene Experimente durch. Wir verwendeten eine Transformatorarchitektur f체r alle Modelle und eine R체ck체bersetzung f체r eines der Sprachpaare. Wir erforschen sowohl zweisprachige als auch mehrsprachige Ans채tze. Wir beschreiben die Vorverarbeitung, Schulung, 횥bersetzung und Ergebnisse f체r jedes Modell. Wir untersuchen auch die Rolle der gegenseitigen Verst채ndlichkeit in der Modellleistung.', 'ko': '이 작업에서, 우리는 자원에 한계가 있지만, 유사한 언어를 번역하는 다른 방법을 조사했다.이 작업은 UBC NLP 연구팀이 WMT 2019 유사 언어 번역 공유 임무에 참여한 가운데 수행됐다.우리는 모든 언어 배합에 참여했고 각종 실험을 진행했다.우리는 모든 모델에transformer 구조를 사용했고 그 중 한 언어에 대해 역번역을 사용했다.우리는 이중 언어와 다중 언어의 방법을 탐색한다.우리는 모든 모델의 예처리, 훈련, 번역과 결과를 묘사했다.우리는 또한 상호 이해성이 모델 성능에서의 작용을 연구했다.', 'id': 'Dalam pekerjaan ini kami menyelidiki pendekatan yang berbeda untuk menerjemahkan antara bahasa yang sama meskipun batasan sumber daya rendah. Pekerjaan ini dilakukan sebagai pesertaan kelompok penelitian NLP UBC di WMT 2019 Bahasa-bahasa Similar Translation Shared Task. Kami berpartisipasi dalam semua pasangan bahasa dan melakukan berbagai eksperimen. Kami menggunakan arsitektur transformer untuk semua model dan menggunakan terjemahan belakang untuk salah satu pasangan bahasa. Kami mengeksplorasi pendekatan dua bahasa dan berbilang bahasa. Kami menggambarkan praproses, pelatihan, terjemahan dan hasil untuk setiap model. Kami juga menyelidiki peran inteligibilitas bersama dalam pertunjukan model.', 'fa': 'در این کار ما روش\u200cهای مختلف را تحقیق می\u200cکنیم تا بین زبان\u200cهای مشابه، با وجود محدودیت منابع کم ترجمه کنیم. این کار به عنوان مشارکت گروه تحقیقات NLP UBC در گروه WMT 2019 در ترجمه\u200cهای شبیه زبان\u200cهای مشترک انجام می\u200cشود. ما در همه جفت زبان شرکت کردیم و آزمایشات مختلف انجام دادیم. ما از یک معماری تغییر دهنده برای همه مدل استفاده کردیم و برای یکی از جفت زبان استفاده کردیم. ما هر دو دسترسی زبان و کلی زبان را تحقیق می کنیم. ما برای هر مدل پیش\u200cپردازش، آموزش، ترجمه و نتایج را توصیف می\u200cکنیم. ما همچنین نقش خردمندی یکدیگر را در عملکرد مدل تحقیق می کنیم.', 'tr': 'Biz bu işde ýaly diller arasynda täsirli ýagdaýlary çykarmak üçin beýleki ýagdaýlary inceleýäris. Bu işi WMT 2019-nji ýylda UBC NLP araştyrma toparynyň çykyş bolup geçirildi. Biz ähli dil çiftlerde goşuldyk we dürli deneyler etdik. Biz ähli nusgalar üçin bir transformer arhitektura ulandyk we dil çiftleri üçin yzyna terjime etdik. Biz ikinji dilli we köp dilli nusgalary keşfetýäris. Biz her nusga üçin öňki işleýäni, okuwçy, terjime edeni we netijeleri tassyýarys. Biz hem bir-birimiziň akyllygynyň nusgasynda çykyşyrýarys.', 'sw': 'Katika kazi hii tunachunguza mbinu tofauti za kutafsiri kati ya lugha kama hizo licha ya vizuizi vidogo vya rasilimali. Kazi hii imefanywa kama ushiriki wa kikundi cha utafiti wa UBC NLP katika Tafsiri za lugha kama vile WMT 2019. Tumeshiriki katika mazoea yote ya lugha na kufanya majaribio mbalimbali. Tulitumia ujenzi wa mabadiliko kwa mifano yote na tulitumia tafsiri ya nyuma kwa moja ya wanandoa wa lugha. Tunafuta mbili na lugha nyingi. Tunaelezea utaratibu, mafunzo, tafsiri na matokeo kwa kila mfano. Pia tunachunguza jukumu la ufahamu wa pamoja katika utendaji wa mifano.', 'af': "In hierdie werk ondersoek ons verskillende toegang om tussen gelyke tale te vertaal, behalwe die lae hulpbron beperking. Hierdie werk is gedoen as die deelnadering van die UBC NLP-reseksgroep in die WMT 2019 gelyke tale-vertaling deelde taak. Ons het gedeel in alle taal paar en verskillende eksperimente uitgevoer. Ons het 'n transformeerder arkitektuur gebruik vir al die modele en terugvertaling gebruik vir een van die taal paar. Ons ondersoek beide twee tale en veelvuldige toegang. Ons beskrywe die voorafverwerking, oefening, vertaling en resultate vir elke model. Ons het ook die rol van gemeenskaplike intelligibiliteit in model effektuur ondersoek.", 'sq': 'Në këtë punë ne hetojmë metoda të ndryshme për të përkthyer mes gjuhëve të ngjashme pavarësisht nga kufizimet e ulëta të burimeve. Ky punë bëhet si pjesëmarrja e grupit të kërkimit të UBC NLP në WMT 2019 të Detyrës së Përkthimit të Përngjashëm të Gjuhave. Ne morëm pjesë në të gjitha çiftet gjuhësore dhe kryem eksperimente të ndryshme. Përdorëm një arkitekturë transformuese për të gjitha modelet dhe përdorëm përkthimin mbrapsht për një nga çiftet e gjuhëve. Ne eksplorojmë si metodat dygjuhëse ashtu edhe shumëgjuhëse. Ne përshkruajmë paraprocesimin, trajnimin, përkthimin dhe rezultatet për çdo model. Ne gjithashtu hetojmë rolin e inteligjencës së ndërsjelltë në paraqitjen e modelit.', 'hy': 'Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք տարբեր մոտեցումներ նման լեզուների միջև թարգմանելու համար, չնայած ցածր ռեսուրսների սահմանափակումներին: Այս աշխատանքը կատարվում է որպես UBC-ի ՆԼՊ հետազոտական խումբի մասնակցություն 2019 թվականին ՄԱԿ-ի Նմանատիպ լեզուներ թարգմանման կիսված խնդրում: Մենք մասնակցեցինք բոլոր լեզվի զույգերին և կատարեցինք տարբեր փորձեր: Մենք օգտագործեցինք փոխակերպող ճարտարապետություն բոլոր մոդելների համար և վերադարձ թարգմանություն լեզվի զույգերից մեկի համար: Մենք ուսումնասիրում ենք երկլեզու և բազլեզու մոտեցումներ: Մենք նկարագրում ենք յուրաքանչյուր մոդելի նախավերամշակման, պատրաստման, թարգմանման և արդյունքների մասին: Մենք նաև ուսումնասիրում ենք միմյանց հասկանալիության դերը մոդելի արտադրության մեջ:', 'az': 'Bu işdə, düşük ressurs sınırlarına baxmayaraq bənzər dillər arasında tərcümə etmək üçün fərqli tərzlərini incidirik. Bu işlər WMT 2019 ilə bənzər dillər tercüməsi paylaşılan işdə UBC NLP araştırma qrupunun paylaşılması kimi yapılır. Bütün dil çiftlərə katıldıq və müxtəlif təcrübələr etdik. Biz bütün modellər üçün transformer arhitektarını kullandıq və dil çiftlərindən birinə geri çevirildik. Biz ikili dil və çoxlu dil tərzlərini keşfetirik. Biz hər modeli üçün əvvəlcə işləmə, təhsil, tercümə və sonuçlarını təsdiqləyirik. Biz də modellərdə bir-birimizin inteligensiyalığın rolünü incidirik.', 'bn': 'এই কাজে আমরা অনুসন্ধান করি অন্যান্য ভাষার মধ্যে অনুবাদ করার বিভিন্ন উপায়, যদিও কম সম্পদ সীমাবদ্ধ থাকে। উইবিসি এনএলপি গবেষণা গ্রুপের অংশগ্রহণ হিসেবে এই কাজ করা হয়েছে যারা উইএমটি ২০১৯ সালের একই ভাষায় অনুবাদ শেয়ার করা কাজে অনু আমরা সব ভাষায় জোড়ায় অংশগ্রহণ করেছি এবং বিভিন্ন পরীক্ষা করেছি। আমরা সকল মডেলের জন্য একটি পরিবর্তন স্থাপত্য ব্যবহার করেছি এবং ভাষার জোড়ার জন্য পিছনে অনুবাদ ব্যবহার করেছি। আমরা দুই ভাষা এবং বহুভাষার প্রতিযোগিতা খুঁজে বের করি। আমরা প্রত্যেক মডেলের জন্য প্রক্রিয়া, প্রশিক্ষণ, অনুবাদ এবং ফলাফল বর্ণনা করি। আমরা মডেল প্রদর্শনের মাধ্যমে পরস্পর বুদ্ধিমানের ভূমিকা তদন্ত করি।', 'am': 'በዚህ ሥራ ውስጥ በተለያዩ ቋንቋዎች መካከል ምንም እንኳ የከብት ሀብት ግንኙነት ታናሽ ቢሆን ልዩ ልዩን ደረጃዎች እንመርምራለን፡፡ ይሄ ሥራ በዩብሲ NLP ምርጫው ቡድን በWMT 2019 በሚያያያየው ቋንቋዎች ትርጉም የተሰራጨው ስራ እንዲሆን ተግባር ነው፡፡ በቋንቋው ሁሉ ሁለት ሁለት ተጋጠመን እና ልዩ ፈተናዎችን አደረግን ። ለሁሉም ምሳሌዎች የለውጥ መሠረት እና ለቋንቋው ሁለት ዓይነቶች የጀርባ ትርጉም ተጠቀምን፡፡ ሁለት ቋንቋ እና ብዙ ቋንቋ ቃላትን እንፈልጋለን፡፡ ለሁሉም ምሳሌ የፊተኛ ጉዳይ፣ አስተማርና ትርጉም እና ፍሬዎችን እናሳውቃለን፡፡ እናም የብልሃትና የዓይነ አስተዋይ ትርጉም በሞዴል አድራጊ ላይ እናመርመራለን፡፡', 'ca': "En aquesta feina investigam diferents enfocaments de traducció entre llengües similars malgrat baixes limitacions de recursos. Aquesta feina es fa com la participació del grup de recerca NLP de l'UBC en la tasca compartida de traducció de llengües semblants del WMT 2019. Vam participar en tots els parells de llengües i vam fer diversos experiments. Vam utilitzar una arquitectura transformadora per tots els models i vam utilitzar traducció retrospectiva per un parell de llengües. Explorem els enfocaments bilingües i multilingües. Descrivem el pré-processament, l'entrenament, la traducció i els resultats de cada model. També investigam el paper de la intel·ligibilitat mútua en el rendiment del model.", 'et': 'Selles töös uurime erinevaid lähenemisviise tõlkimiseks sarnaste keelte vahel vaatamata madalatele ressursipiirangutele. See töö on tehtud UBC NLP uurimisrühma osalusena WMT 2019 Sarnaste keelte tõlke jagatud ülesandes. Osalesime kõigis keelepaarides ja tegime erinevaid eksperimente. Kõigi mudelite jaoks kasutasime trafoarhitektuuri ja ühe keelepaari jaoks tagasitõlget. Me uurime nii kaks- kui ka mitmekeelset lähenemisviisi. Kirjeldame iga mudeli eeltöötlust, koolitust, tõlkimist ja tulemusi. Samuti uurime vastastikuse arusaadavuse rolli mudeli jõudluses.', 'cs': 'V této práci zkoumáme různé přístupy k překladu mezi podobnými jazyky i přes nízké omezení zdrojů. Tato práce je prováděna za účasti výzkumné skupiny UBC NLP na WMT 2019 Podobné jazyky Translation Shared Task. Účastnili jsme se všech jazykových párů a prováděli různé experimenty. Pro všechny modely jsme použili transformátorovou architekturu a pro jeden z jazykových párů jsme použili zpětný překlad. Zkoumáme dvojjazyčné i vícejazyčné přístupy. Popisujeme předzpracování, školení, překlad a výsledky pro každý model. Dále zkoumáme roli vzájemné srozumitelnosti při výkonu modelu.', 'bs': 'U ovom poslu istražujemo različite pristupe prevode između sličnih jezika uprkos niskim ograničenjima resursa. Ovaj rad se čini kao sudjelovanje UBC NLP istraživačke grupe u WMT 2019. sličnom zadatku za prevod jezika. Učestvovali smo u svim jezičkim parovima i izvršili različite eksperimente. Koristili smo transformatorsku arhitekturu za sve modele i koristili natrag prevod za jedan od jezičkih parova. Istražujemo i dvojezičke i višejezičke pristupe. Opišemo predobrazovanje, obuku, prevod i rezultate svakog modela. Istražujemo i ulogu međusobne inteligencije u modelu izvedbe.', 'fi': 'Tässä työssä tutkitaan erilaisia lähestymistapoja kääntää samankaltaisten kielten välillä vähäisistä resurssirajoituksista huolimatta. Tämä työ on tehty UBC NLP -tutkimusryhmän osallistumisena WMT 2019 Similar Languages Translation Shared Task -tehtävään. Osallistuimme kaikkiin kielipareihin ja teimme erilaisia kokeiluja. Käytimme muuntajan arkkitehtuuria kaikissa malleissa ja taaksekääntämistä yhdessä kielipareista. Tutkimme sekä kaksikielisiä että monikielisiä lähestymistapoja. Kuvaamme kunkin mallin esikäsittelyn, koulutuksen, käännöksen ja tulokset. Tutkimme myös keskinäisen ymmärrettävyyden roolia mallin suorituskyvyssä.', 'jv': 'Nang iki trabah, kita ujaran kanggo ngerasai kapan sampeyan kanggo nganggo langkung sampeyan anyar Wunggu iki wis rampung dibenakaké ning kelompok UB NLP barêng kanggo ngilangno WT 2011 Similr Languages translation shared task. Awak dhéwé ngeraké kabèh pangan ning limu, lan gewis ngeraké sak ujaran Awak dhéwé nggunakake architecture transformer kanggo saben model lan ijol-terjamahan kanggo saben kelas barang langga. Awak dhéwé énsespéné kabèh lan akeh-akeh basa. Awak dhéwé ngerwih-ngerwih banter, nggawe, terjamah lan mbujalan kanggo saben model. Awakdhéwé njaluké karo perusahaan ingkang sampeyan ingkang dipun-sampeyan ngono nggawe modèl.', 'ha': "Yana cikin wannan aikin da Muke tambaya hanyoyin daban-daban dõmin mu rarraba tsakanin harshen masu daidaita ko da kuma ingawa masu ƙaranci resource. Wannan aikin za'a sami kamar shirin ƙungiyoyi na UBC NLP research group in the WMT 2019 Similar languages Translate Shared Taaikin. Mun yi shirin dukkan harshe biyu kuma muka aikata jarrabi dabam-dabam. Mun yi amfani da matsayin shishi ga dukkan misalin kuma muka yi amfani da bakin-translate wa ɗayan harshen. Munã jarraba kowane misãlai na lugha biyu da yawa. Tuna bayyana fassarar-aiki, shirin aiki, fassarar da matsalan kowace misali. Kayya, tuna karatun mafiya hankali a tsakanin misalin misalin.", 'he': 'בעבודה הזו אנחנו חוקרים גישות שונות לתרגם בין שפות דומות למרות מגבלות משאבים נמוכות. העבודה הזאת נעשית כהשתתפות של קבוצת המחקר של UBC NLP במשימה המשותפת של WMT 2019. השתתפנו בכל זוגות שפות ובצענו ניסויים שונים. השתמשנו בארכיטקטורה משתנה לכל הדוגמנים ושתמשנו בתרגום מאחור לאחד הזוגים של השפה. אנחנו חוקרים גישות שתיים-שפויות ומרבות-שפויות. אנחנו מתארים את התהליך הקדמי, האימונים, התרגום ותוצאות לכל מודל. We also investigate the role of mutual intelligibility in model performance.', 'sk': 'V tem delu raziskujemo različne pristope prevajanja med podobnimi jeziki kljub majhnim omejitvam virov. Delo poteka v okviru sodelovanja raziskovalne skupine NLP UBC v skupni nalogi prevajanja podobnih jezikov WMT 2019. Sodelovali smo v vseh jezikovnih parih in izvedli različne eksperimente. Za vse modele smo uporabili transformatorsko arhitekturo in za enega od jezikovnih parov uporabili nazaj prevod. Raziskujemo dvojezične in večjezične pristope. Opisujemo predhodno obdelavo, usposabljanje, prevajanje in rezultate za vsak model. Raziskujemo tudi vlogo medsebojne razumljivosti pri izvedbi modela.', 'bo': 'ལཱ་སྟངས་འདིའི་ནང་དུ་ང་ཚོས་མཐུན་རིམ་པ་དང་མཐུན་རྐྱེན་ཚད་ཉུང་བའི་རྐྱེན་འབྲེལ་རྒྱ་ནག་ནང་གི་བཟོ་ཚོགས་ས ལས་ཀ་འདི་ནི་UBC NLP འཚོལ་ཞིབ་ཀྱི་ཚོ་ཁག་གི་ནང་དུ་WMT 2019 དེ་ལྟ་བུའི་སྐད་ཡིག ང་ཚོས་སྐད་རིགས་གཉིས་ཀྱི་ནང་དུ་བྱ་འགུལ་བྱས་པ་ལས་སྐད་ཆ་འདི་དག་བརྟན་དཔྱད་བྱས། ང་ཚོས་རྣམ་གྲངས་ཡོད་ཚད་ལ་བཟོ་བཅོས་མཁན་གཟུགས་རིས་བེད་སྤྱོད་ཀྱི་ཡོད་པ་ཞིག་དང་སྐད་ཡིག་གཉིས་གཅིག ང་ཚོས་སྐད་ཡིག་དང་སྐད་ཡིག་ཆ་གཉིས་ཀྱི་གནད་དོན་གཉིས་ཀྱིས་འཚོལ་ཞིབ་བྱེད། ང་ཚོས་མ་དབྱིབས་སྔོན་གྱི་ལས་སྦྱོར་གཙོ་བྱེད་དང་། སློབ་གཙོ་བྱེད། དཔེ་དབྱིབས་ཡོད་ཚད་རེ་རེད། ང་ཚོས་རྣམས་ལས་དབྱིན་དཔྱད་ཆོས་ཀྱི་ལས་འགན་ཞིབ་དཔྱད་བྱེད་ཀྱི་ཡོད།'}
{'en': 'The IPN-CIC team system submission for the WMT 2020 similar language task', 'ar': 'تقديم نظام فريق IPN-CIC لمهمة اللغة المماثلة WMT 2020', 'es': 'La presentación del sistema de equipos IPN-CIC para la tarea de lenguaje similar al WMT 2020', 'fr': "Soumission du système d'équipe IPN-CIC pour la tâche de langage similaire WMT 2020", 'pt': 'O envio do sistema da equipe IPN-CIC para a tarefa de idioma semelhante do WMT 2020', 'ja': 'WMT 2020類似言語タスクのためのIPN - CICチームシステム提出', 'hi': 'WMT 2020 समान भाषा कार्य के लिए IPN-CIC टीम सिस्टम सबमिशन', 'zh': 'WMT 2020зұ»иЁҖдәӢиҖ…IPN-CICеӣўйҳҹзі»з»ҹжҸҗдәӨ', 'ru': 'Представление системы команды IPN-CIC для задачи на аналогичном языке WMT 2020', 'ga': 'Aighneacht chóras fhoireann IPN-CIC do thasc teanga comhchosúil WMT 2020', 'ka': 'IPN-CIC ჯგუფი სისტემის გამოყენება WMT 2020 მსგავსი ენის დავალებისთვის', 'it': "La presentazione del sistema del team IPN-CIC per l'attività linguistica simile WMT 2020", 'hu': 'Az IPN-CIC csoportrendszer benyújtása a WMT 2020 hasonló nyelvi feladatra', 'el': 'Η υποβολή συστήματος ομάδας IPN-CIC για την παρόμοια γλωσσική εργασία WMT 2020', 'kk': 'WMT 2020 тіл тапсырмасының IPN- CIC тобы жүйесі', 'ms': 'Penghantaran sistem pasukan IPN-CIC untuk tugas bahasa yang sama WMT 2020', 'lt': 'IPN-CIC komandos sistemos pateikimas panašiai kalbų užduotims pagal WMT 2020', 'mk': 'Пренесувањето на системот на ИПН-ЦИЦ за сличната јазичка задача на ВМТ 2020', 'ml': 'WMT 2020 പോലുള്ള ഭാഷ ജോലി', 'mn': 'IPN-CIC баг системийн WMT 2020-ийн төстэй хэл даалгаварын даалгавар', 'no': 'IPN-CIC-gruppesystemet for tilsvarande språksoppgåve WMT 2020', 'mt': 'Is-sottomissjoni tas-sistema tat-tim IPN-CIC għall-kompitu lingwistiku simili tad-WMT 2020', 'ro': 'Depunerea sistemului de echipă IPN-CIC pentru activitatea lingvistică similară WMT 2020', 'pl': 'Zgłoszenie systemu zespołu IPN-CIC do podobnego zadania językowego WMT 2020', 'sr': 'Prijava IPN-CIC tim sistema za slični jezički zadatak WMT 2020.', 'si': 'IPN-CIC කණ්ඩායම පද්ධතිය WMT-202 වගේ භාෂා වැඩ සඳහා පිළිගන්න', 'so': 'Kooxda IPN-CIC waxay u submit to the WMT 2020 oo u eg shaqo luqada', 'sv': 'Inlämning av IPN-CIC-teamsystemet för WMT 2020-liknande språkuppgift', 'ta': 'WMT 2020 போன்ற மொழி பணிக்கான IPN- CIC அணி அமைப்பு', 'ur': 'IPN-CIC ٹیم سیسٹم تحویل WMT 2020 کی جیسی زبان تابع کے لئے', 'uz': 'Name', 'vi': 'Thông tin hệ thống của đội IPN-C cho nhiệm vụ ngôn ngữ tương tự WRT 2020 Name', 'da': 'Indsendelse af IPN-CIC-teamsystemer til WMT 2020 lignende sprogopgave', 'nl': 'Het IPN-CIC team systeem indiening voor de WMT 2020 soortgelijke taaltaak', 'hr': 'Prijava IPN-CIC tim sustava za slični jezički zadatak WMT 2020.', 'bg': 'Подаване на екипната система на ИПН-ЦИК за подобна езикова задача', 'id': 'Pengiriman sistem tim IPN-CIC untuk tugas bahasa yang sama WMT 2020', 'ko': 'WMT 2020 유사 언어 작업에 대한 IPN-CIC 팀 시스템 커밋', 'de': 'Die IPN-CIC Team System Einreichung für die WMT 2020 ähnliche Sprachaufgabe', 'af': 'Die IPN-CIC-team stelsel onderskrywing vir die WMT 2020 soortgelyke taal taak', 'fa': 'تسلیم سیستم تیم IPN-CIC برای کار زبانی شبیه WMT 2020', 'am': 'የIPN-CIC ተሟጋቾች ለWMT 2020 የሚመስል ቋንቋ ስራ አቀልጠዋል', 'sw': 'Mfumo wa timu ya IPN-CIC unawasilisha kwa kazi ya lugha inayofanana na WMT 2020', 'tr': 'WMT 2020 dili buýruky üçin IPN-CIC topar sistemasy bejerilmesi', 'bn': 'WMT ২০২০০ এর সমতুল্য ভাষার কাজের জন্য আইপিএন-সিসি টিম সিস্টেম প্রদান করা হয়েছে', 'bs': 'Prijava IPN-CIC tim sistema za slični jezički zadatak WMT 2020.', 'sq': 'The IPN-CIC team system submission for the WMT 2020 similar language task', 'cs': 'Podání týmového systému IPN-CIC pro podobný jazykový úkol WMT 2020', 'az': 'WMT 2020 dil işləri üçün IPN-CIC takım sistemi göndərməsi', 'fi': 'IPN-CIC-tiimijärjestelmän lähettäminen WMT 2020 -vastaavaan kielitehtävään', 'hy': 'IPN-CIC թիմի համակարգի ներկայացումը', 'ca': 'The IPN-CIC team system submission for the WMT 2020 similar language task', 'et': 'IPN-CIC meeskonna süsteemi esitamine WMT 2020 sarnase keeleülesande jaoks', 'jv': "Ngubah kelompok ipN-CIC kang sampeyan kanggo nganggo pergambar luwih 'WT 2020'", 'ha': 'KCharselect unicode block name', 'sk': 'Oddaja ekipnega sistema IPN-CIC za podobno jezikovno nalogo WMT 2020', 'he': 'הגישה של מערכת צוות IPN-CIC למשימת השפה דומה WMT 2020', 'bo': 'WMT 2020 དེ་ལྟ་བུའི་སྐད་རིགས་ཀྱི་བཀོལ་སྤྱོད་ལ་IPN-CIC མ་ལག་གི་མཉམ་དུ་འཇུག་པ'}
{'en': 'This paper describes the participation of the NLP research team of the IPN Computer Research center in the WMT 2020 Similar Language Translation Task. We have submitted systems for the Spanish-Portuguese language pair (in both directions). The three submitted systems are based on the Transformer architecture and used fine tuning for domain Adaptation.', 'ar': 'تصف هذه الورقة مشاركة فريق أبحاث البرمجة اللغوية العصبية التابع لمركز أبحاث الكمبيوتر IPN في مهمة ترجمة اللغات المماثلة WMT 2020. لقد قدمنا أنظمة لزوج اللغتين الإسبانية والبرتغالية (في كلا الاتجاهين). تعتمد الأنظمة الثلاثة المقدمة على بنية المحولات وتستخدم الضبط الدقيق لتكييف المجال.', 'es': 'Este artículo describe la participación del equipo de investigación de PNL del Centro de Investigación Informática de IPN en la Tarea de Traducción de Idiomas Similares del WMT 2020. Hemos presentado sistemas para la combinación de idiomas español-portugués (en ambas direcciones). Los tres sistemas presentados se basan en la arquitectura Transformer y utilizan el ajuste fino para la adaptación de dominios.', 'fr': "Cet article décrit la participation de l'équipe de recherche en PNL du centre de recherche informatique IPN à la tâche de traduction en langage similaire WMT 2020. Nous avons soumis des systèmes pour la paire de langues espagnol-portugais (dans les deux directions). Les trois systèmes soumis sont basés sur l'architecture Transformer et ont utilisé un réglage fin pour l'adaptation de domaine.", 'pt': 'Este artigo descreve a participação da equipe de pesquisa em PNL do centro de pesquisa de computadores do IPN na tarefa de tradução de idiomas semelhantes do WMT 2020. Apresentamos sistemas para o par de idiomas espanhol-português (em ambas as direções). Os três sistemas apresentados são baseados na arquitetura Transformer e usam ajuste fino para Adaptação de domínio.', 'ja': '本稿では、IPNコンピュータ研究センターのNLP研究チームがWMT 2020類似言語翻訳タスクに参加していることについて説明する。スペイン語とポルトガル語のペア（両方向）のシステムを提出しました。提出された3つのシステムは、Transformerアーキテクチャに基づいており、ドメイン適応のための微調整に使用されます。', 'zh': '本文引IPN计算机究心NLP研团队参WMT 2020类言语译事。 已提西班牙语-葡萄牙语对统(双向)。 提交三统基于Transformer架构,施于域适配之微调。', 'ru': 'В этой статье описывается участие исследовательской группы NLP центра компьютерных исследований IPN в задаче по аналоговому языковому переводу WMT 2020. Мы представили системы для испано-португальской языковой пары (в обоих направлениях). Три представленные системы основаны на архитектуре трансформатора и используют точную настройку для адаптации домена.', 'hi': 'यह पेपर WMT 2020 समान भाषा अनुवाद कार्य में आईपीएन कंप्यूटर रिसर्च सेंटर की एनएलपी अनुसंधान टीम की भागीदारी का वर्णन करता है। हमने स्पेनिश-पुर्तगाली भाषा जोड़ी (दोनों दिशाओं में) के लिए सिस्टम प्रस्तुत किए हैं। तीन प्रस्तुत प्रणालियों ट्रांसफॉर्मर वास्तुकला पर आधारित हैं और डोमेन अनुकूलन के लिए ठीक ट्यूनिंग का उपयोग किया.', 'ga': 'Déanann an páipéar seo cur síos ar rannpháirtíocht fhoireann taighde NLP an Ionaid Taighde Ríomhaireachta IPN i dTasc Aistriúcháin Teangacha Comhchosúla WMT 2020. Tá córais curtha isteach againn don phéire teanga Spáinnis-Portaingéilis (sa dá threo). Tá na trí chóras a cuireadh isteach bunaithe ar ailtireacht an Trasfhoirmeora agus baineadh úsáid as mionchoigeartú le haghaidh Oiriúnú Fearainn.', 'el': 'Η παρούσα εργασία περιγράφει τη συμμετοχή της ερευνητικής ομάδας του Κέντρου Έρευνας Υπολογιστών του IPN στο έργο μετάφρασης παρόμοιων γλωσσών του WMT 2020. Έχουμε υποβάλει συστήματα για το ζευγάρι Ισπανικών-Πορτογαλικών γλωσσών (και προς τις δύο κατευθύνσεις). Τα τρία υποβαλλόμενα συστήματα βασίζονται στην αρχιτεκτονική μετασχηματιστή και χρησιμοποίησαν την προσαρμογή του τομέα.', 'ka': 'ეს დოკუმენტი აღწერა, რომ IPN კომპიუტერის სწავლობა ცენტრის NLP სწავლობას გადაწყვეტილება WMT 2020-ის მსგავსი ენის გადაწყვეტილება. ჩვენ ისპანელი-პორგუტეგიური ენის ზოგლის სისტემების გამოყენება (ორივე მხარეს). სამი შეტყობინებული სისტემები ტრანფორმეტრის აქტიქტიქტურის დაბაზეულია და გამოყენებულია კარგი კონფიგურაცია დემონის აეპტაციაზე.', 'hu': 'Ez a tanulmány bemutatja az IPN Számítógépes Kutatóközpont NLP kutatócsoportjának részvételét a WMT 2020 hasonló nyelvi fordítási feladatban. Küldtük be a spanyol-portugál nyelvpárra vonatkozó rendszereket (mindkét irányban). A három benyújtott rendszer a Transformer architektúrán alapul, és finomhangolást használt a domain Adaptációhoz.', 'kk': 'Бұл қағаз IPN компьютер зерттеу орталығындағы NLP зерттеу тобының қатынасын WMT 2020 деген ұқсас тіл аудару тапсырмасында таңдайды. Біз Испан- Португалия тілдерінің екі (екі жағында) жүйелерін жібердік. Үш жүйелік берілген жүйелер түрлендіруші архитектурасына негізделген және доменге адаптациялау үшін дұрыс түрлендіру қолданылады.', 'lt': 'This paper describes the participation of the NLP research team of the IPN Computer Research center in the WMT 2020 Similar Language Translation Task.  Mes pateikėme Ispanijos ir Portugalijos kalbų poros sistemas (abiem kryptimis). Trys pateiktos sistemos grindžiamos Transformer architektūra ir naudojamos tiksliai pritaikytos prie srities pritaikymo.', 'mk': 'Овој документ го опишува учеството на истражувачкиот тим на НЛП на Центарот за компјутерско истражување на ИПН во задачата за сличен јазик на ВМТ 2020. Ние ги поднесовме системите за парот шпанско-португалски јазик (во двете насоки). Трите поднесени системи се базирани на трансформената архитектура и се користат фино прилагодување за адаптација на домените.', 'it': "Questo articolo descrive la partecipazione del gruppo di ricerca PNL del centro di ricerca IPN Computer Research al WMT 2020 Similar Language Translation Task. Abbiamo presentato sistemi per la coppia di lingue spagnolo-portoghese (in entrambe le direzioni). I tre sistemi presentati si basano sull'architettura Transformer e utilizzano la messa a punto per il dominio Adaptation.", 'ml': 'ഈ പത്രത്തില്\u200d ഐപിഎന്\u200d കമ്പ്യൂട്ടര്\u200d പരിശോധന കേന്ദ്രത്തിന്റെ പങ്കെടുപ്പിന്റെ എംഎല്\u200dപി പഠിപ്പിന്റെ പങ്കെടുക്കുന്നത് വിവര We have submitted systems for the Spanish-Portuguese language pair (in both directions).  മൂന്നു സമ്മതിച്ച സിസ്റ്റമുകള്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആര്\u200dക്കിട്ടറിന്\u200dറെ അടിസ്ഥാനത്താണ് അടിസ്ഥാനമാക്കിയ', 'ms': 'Kertas ini menggambarkan participasi pasukan kajian NLP pusat kajian komputer IPN dalam Tugas Terjemahan Bahasa Serupa WMT 2020. Kami telah menghantar sistem untuk pasangan bahasa Spanyol-Portugis (dalam kedua-dua arah). Tiga sistem yang dihantar berdasarkan arkitektur Transformer dan digunakan penyesuaian baik untuk penyesuaian domain.', 'mn': 'Энэ цаасан нь IPN Компьютерийн судалгааны төв дээрх NLP судалгааны багийнхаа оролцоог WMT 2020-ийн төстэй хэл хөрөнгө оруулах ажлыг тайлбарладаг. Бид Испан-Португалийн хэл хоёр (хоёр талаар) системийг суулгасан. Гурван дамжуулагдсан систем нь Трансформер архитектур дээр суурилсан бөгөөд холбооны адаптацийн тусламжтайгаар сайн түүх хэрэглэгдсэн.', 'mt': 'Dan id-dokument jiddeskrivi l-parteċipazzjoni tat-tim tar-riċerka NLP taċ-ċentru tar-Riċerka tal-Kompjuter tal-IPN fil-Kompitu tat-Traduzzjoni tal-Lingwi Simili tad-WMT 2020. Issottomettejna sistemi għall-par tal-lingwa Spanjola-Portugiża (fiż-żewġ direzzjonijiet). It-tliet sistemi sottomessi huma bbażati fuq l-arkitettura tat-Transformer u jintużaw aġġustamenti fini għall-Adattament tad-dominju.', 'pl': 'Niniejszy artykuł opisuje udział zespołu badawczego NLP Centrum Badań Komputerowych IPN w zadaniu tłumaczenia podobnego języka WMT 2020. Przesłaliśmy systemy dla pary językowej hiszpańsko-portugalskiej (w obu kierunkach). Trzy przesłane systemy opierają się na architekturze Transformera i wykorzystują precyzyjne dostrajanie dla adaptacji domeny.', 'no': 'Denne papiret beskriver deltakaren av NLP- forskningsgruppa i IPN- dataforskningssenteret i WMT 2020 Similar språk- omsetjingspråk. Vi har sendt systema til spansk- portugisisk språk par (i begge retningar). Den tre innsende systema er basert på Transformeringsarkitekturen og brukt fint innstilling for domeneadaptasjon.', 'ro': 'Această lucrare descrie participarea echipei de cercetare PNL a centrului de cercetare IPN Computer Research la activitatea WMT 2020 Similar Language Translation Task. Am depus sisteme pentru perechea de limbi spaniolă-portugheză (în ambele direcții). Cele trei sisteme depuse se bazează pe arhitectura Transformer și au folosit ajustări fine pentru domeniul Adaptare.', 'sr': 'Ovaj papir opisuje sudjelovanje istraživačkog tima NLP-a IPN kompjuterskog istraživačkog centra u zadatku za prevod jezika WMT 2020. Predložili smo sisteme za španjolski-portugalski parov (u oba smjera). Tri podnošena sustava su temeljena na arhitekturi Transformera i koristila je dobru prilagodbu domena Adaptacije.', 'si': 'මේ පත්තුව පැහැදිලියා IPN පරීක්ෂක පරීක්ෂක මධ්\u200dයස්ථානයේ NLP පරීක්ෂණ කණ්ඩායමේ සමාන භාෂාව පරීක්ෂණ ක්\u200d අපි ස්පැනිස්-පොර්තුගුලි භාෂාවට පද්ධතියක් දාලා තියෙනවා. පිළිගන්න තුනක් පද්ධතිය පද්ධතිය අධාරණය කරලා තියෙන්නේ නිර්මාණකරණ ස්ථාපනය සහ ඩොමේන් අන', 'so': 'Warqaddan waxaa ku qoran qayb ka qaadashada kooxda waxbarashada ee IPN xarunta baaritaanka kambiyuutarka ee WMT 2020 oo u eg shaqo turjumista luuqada. Waxaan nidaamka u dhiibnay labada luqada Isbanish-Burtuqiis (labada dhinac). Saddexdaas nidaamka la soo dhiibay waxay ku saleysan yihiin dhismaha turjumista, waxaana lagu isticmaalaa hab wanaagsan oo la kordhiyo domain.', 'ur': 'This paper describes the participation of the NLP research team of the IPN Computer Research Center in the WMT 2020 Similar Language Translation Task. ہم نے اسپانیایی-پورتوگل زبان کے جوڑوں کے لئے سیستموں کو (دونوں طریقوں میں) پیش کیا ہے۔ تین ڈیمئن ڈیمین اڈپٹیٹ کے لئے بہترین تنظیم استعمال کیے گئے ہیں۔', 'sv': 'Denna uppsats beskriver deltagandet av NLP-forskargruppen vid IPN Computer Research Center i WMT 2020 Similar Language Translation Task. Vi har skickat in system för det spanska-portugisiska språkparet (i båda riktningarna). De tre inlämnade systemen är baserade på Transformer-arkitekturen och används finjustering för domänanpassning.', 'ta': 'This paper describes the participation of the NLP research team of the IPN Computer Research Center in the WMT 2020 Similar Language Translation Task. நாங்கள் ஸ்பானிஷ்- போர்த்துகீசிஷ் மொழி ஜோடி அமைப்புகளை ஒப்பிட்டுள்ளோம் (இரு திசைகளில்) மூன்று வழங்கப்பட்ட அமைப்புகள் மாற்றியமைப்பு உருவாக்கத்தை அடிப்படையில் உள்ளன மற்றும் டோமைன் அடிப்படையில்', 'uz': 'Бу саҳифа WMT 2020 Similar Til tarjima vazifasidagi IPN kompyuterni qidirish markazidagi NLP tarjima jamoasining qismini anglatadi. Biz ispancha-Portugalcha tillar ikki xil uchun tizimlarni joʻnatishdik (ikkita tarkibida). Uchta joʻnatilgan tizim Transformer architektorga asoslangan va domen Adaptation uchun yaxshi qismi ishlatiladi.', 'vi': 'Tờ giấy này mô tả sự tham gia của đội nghiên cứu Njala trong trung tâm nghiên cứu máy tính IPN trong Nhiệm vụ dịch ngôn ngữ WM 2020 Tương tự. Chúng tôi đã gửi hệ thống cho cặp ngôn ngữ Tây Ban Nha-Bồ Đào Nha (theo cả hai hướng). Ba hệ thống được gửi đến dựa trên kiến trúc transformer và dùng tinh chỉnh tinh thần thích nghi miền.', 'bg': 'Настоящата статия описва участието на изследователския екип на НЛП на Центъра за компютърни изследвания на МПН в задачата за превод на сходни езици 2020. Предложили сме системи за двойката испански-португалски език (и в двете посоки). Трите представени системи са базирани на архитектурата на трансформатора и използват фина настройка за адаптация на домейна.', 'da': 'Denne artikel beskriver deltagelsen af NLP-forskningsteamet i IPN Computer Research Center i WMT 2020 Lignende sprogoversættelsesopgave. Vi har indsendt systemer til det spansk-portugisiske sprogpar (i begge retninger). De tre indsendte systemer er baseret på Transformer-arkitekturen og brugt finjustering til domæneadaptation.', 'nl': 'Dit artikel beschrijft de deelname van het NLP onderzoeksteam van het IPN Computer Research Center aan de WMT 2020 Vergelijkbare Taalvertaaltaak. We hebben systemen ingediend voor het Spaans-Portugees taalpaar (in beide richtingen). De drie ingediende systemen zijn gebaseerd op de Transformer architectuur en gebruikt finetuning voor domein Adaptation.', 'de': 'Dieser Beitrag beschreibt die Beteiligung des NLP-Forschungsteams des IPN Computer Research Centers an der WMT 2020 Ähnliche Language Translation Task. Wir haben Systeme für das spanisch-portugiesische Sprachpaar (in beide Richtungen) eingereicht. Die drei eingereichten Systeme basieren auf der Transformer-Architektur und verwenden Finetuning für Domain Adaptation.', 'hr': 'Ovaj papir opisuje sudjelovanje istraživačkog tima NLP-a IPN računalnog istraživačkog centra u zadatku za prevod jezika WMT 2020. Predložili smo sustave za španjolski-portugalski par (u oba smjera). Tri podnošena sustava su temeljena na arhitekturi Transformera i koristila je dobru prilagodbu domena.', 'id': 'Kertas ini menggambarkan pesertaan tim penelitian NLP dari pusat penelitian komputer IPN dalam Tugas Terjemahan Bahasa Similar WMT 2020. We have submitted systems for the Spanish-Portuguese language pair (in both directions).  The three submitted systems are based on the Transformer architecture and used fine tuning for domain Adaptation.', 'tr': 'Bu kagyz NLP araştyrma toparynyň IPN Kompýuter Araştyrma Merkeziniň WMT 2020 Iň ýakyn dil terjime göreviniň chikanchasyny tassyklaýar. Biz espanyol-portugalça dil çift üçin sistemalary (her iki yönde). Üç gönderilen sistemler Transformer arhitekturuna daýanýar we domenýäplikeýşenler üçin gowy görkezme üçin ullanýar.', 'ko': '본고는 IPN 컴퓨터 연구센터 NLP 연구팀이 WMT 2020 유사 언어 번역 임무에 참여한 상황을 묘사한다.우리는 이미 스페인어-포르투갈어 대조 시스템(양방향)을 제출했다.제출된 세 시스템은 Transformer 구조를 바탕으로 마이크로스피커를 사용하여 도메인 적합성을 한다.', 'af': 'Hierdie papier beskryf die deelnadering van die NLP-reseksteam van die IPN rekenaar resekssentrum in die WMT 2020 gelyke taal vertaling taak. Ons het stelsels voorgestuur vir die Spaanse-Portugese taal paar (in beide rigtings). Die drie voorgestuurde stelsels is gebaseer op die Transformer-arkitektuur en gebruik fyn aanpassing vir domein-aanpassing.', 'fa': 'این کاغذ مشترک تیم تحقیقات NLP مرکز تحقیقات کامپیوتر IPN در مرکز تحقیقات زبان شبیه WMT 2020 را توصیف می\u200cکند. ما سیستم\u200cهایی برای جفت زبان اسپانیایی و پورتوژیک (در هر دو جهت) فرستادیم. این سه سیستم تحویل داده شده بر اساس معماری تغییر دهنده و برای تغییر دادن دامنی استفاده می\u200cکنند.', 'sw': 'This paper describes the participation of the NLP research team of the IPN Computer Research center in the WMT 2020 Similar Language Translation Task.  Tumetuma mfumo wa lugha mbili za Kihispania na Kireno (kwa njia zote). Mifumo mitatu iliyotolewa imetumiwa na mifumo ya Udhibiti na imetumiwa vizuri kwa ajili ya Adaptation Domain.', 'az': "Bu kağıt IPN Kompüter Araştırma Merkezi'nin NLP araştırma ekibinin WMT 2020 kimi Dil Çeviri Task in in paylaşmasını təsdiqləyir. Biz İspanyol-Portugal dillərin çift sistemlərini ( hər ikisi tərəfdə ) təbliğ etdik. Üç göndərilən sistemlər Transformer arhitektüsünə dayanan və domain Adaptation üçün gözəl tərzdə istifadə edilmişdir.", 'sq': 'Ky dokument përshkruan pjesëmarrjen e ekipit të kërkimit të NLP të qendrës së kërkimit të kompjuterit të IPN në detyrën e përkthimit të ngjashëm gjuhësh të WMT 2020. Kemi paraqitur sisteme për çiftin e gjuhës spanjollo-portugale (në të dy drejtimet). Të tre sistemet e paraqitura janë bazuar në arkitekturën Transformer dhe përdoren rregullime të mira për Adaptimin e Domenit.', 'bn': 'এই প্রবন্ধে এনএলপি গবেষণা দলের অংশগ্রহণের ব্যাখ্যা করছে WMT ২০২০ সালের একই ভাষা অনুবাদ করার কেন্দ্রে আইপিএন কম্পিউটার গবেষণা কেন্দ্ আমরা স্প্যানিশ-পর্তুগীজ ভাষার জোড়ার জন্য সিস্টেম জমা দিয়েছি (দুই দিকেই)। ট্রান্সফ্রান্সফার্ন আর্কিকেটের ভিত্তিতে তিনটি জমা দিয়েছে এবং ডোমেইন এডাপ্যাটেশনের জন্য ভালোভাবে স', 'am': 'ይህ ገጽ በWMT 2020 ብጤያዊ ቋንቋ ትርጉም ስራ የIPN ኮምፒዩተር መርምር ማዕከላዊው የNLP ምርጫዎች ተግባር ማዕከል ይናገራል፡፡ የስፓኒሽ-ፖርቱጋሊስ ቋንቋ ሁለት (በሁለቱ መንገዶች) ስርዓቶችን ሰጥተናል፡፡ ሦስቱ የተዘጋጀው ስርዓቶች በተለየው የፊደል መሠረት ላይ በመሠረቱ እና ለዶሜን አዳaptation በመጠቀም የተጠቃሚ ጥያቄ ነው፡፡', 'bs': 'Ovaj papir opisuje sudjelovanje istraživačkog tima NLP-a IPN računalnog istraživačkog centra u zadatku za prevod jezika WMT 2020. Predložili smo sisteme za parove španjolskog i portugalskog jezika (u oba smjera). Tri podnošena sustava su temeljena na arhitekturi Transformera i koristila je dobru priliku za adaptaciju domena.', 'et': 'Käesolevas dokumendis kirjeldatakse IPNi arvutiuuringute keskuse uue programmi uurimisrühma osalemist WMT 2020 sarnase keele tõlkimise ülesandes. Oleme esitanud süsteemid hispaania-portugali keele paari jaoks (mõlemas suunas). Kolm esitatud süsteemi põhinevad Transformeri arhitektuuril ja kasutati domeeni kohandamiseks peenhäälestust.', 'fi': 'Tässä artikkelissa kuvataan IPN Computer Research Centerin NLP-tutkimusryhmän osallistumista WMT 2020 Similar Language Translation Task -ohjelmaan. Olemme toimittaneet järjestelmiä espanjan ja portugalin kieliparille (molempiin suuntiin). Kolme toimitettua järjestelmää perustuvat Transformer-arkkitehtuuriin ja käytettiin hienosäätöä verkkotunnuksen mukauttamiseen.', 'hy': 'This paper describes the participation of the NLP research team of the IPN Computer Research center in the WMT 2020 Similar Language Translation Task.  We have submitted systems for the Spanish-Portuguese language pair (in both directions).  Երեք ներկայացված համակարգերը հիմնված են Թանֆորմերի ճարտարապետության վրա և օգտագործվում են գեղեցիկ հարմարեցման բնագավառի հարմարեցման համար:', 'ca': "Aquest paper descriu la participació de l'equip de recerca NLP del centre de recerca informàtica IPN en la tasca de traducció de llenguatges semblants de WMT 2020. Hem presentat sistemes per al parell espanyol-portuguès (en ambdues direccions). Els tres sistemes submetits estan basats en l'arquitectura Transformer i van utilitzar ajustes fins per l'Adaptació de Dominis.", 'cs': 'Tento článek popisuje účast výzkumného týmu NLP z počítačového výzkumného centra IPN na úkolu WMT 2020 Podobného jazyka překladu. Předložili jsme systémy pro španělsko-portugalský jazykový pár (v obou směrech). Tři předložené systémy jsou založeny na architektuře Transformeru a používány jemné ladění pro doménovou adaptaci.', 'jv': 'Gambar iki rambarang nggawe perintahaan karo kapun gransisan NLP ning sektor Prosisyon komputer ipN kanggo nggawe langgambar terjamahan Job WWT 2020 Awak dhéwé wis ngerti sistem kanggo kelas barang Spanish-portugis (ning suji kabèh basa). The third forwarded System are supported on the Transformer architecture and used Fining tuning for domain Adjustation.', 'sk': 'V prispevku je opisano sodelovanje raziskovalne skupine NLP računalniškega raziskovalnega centra IPN v nalogi prevajanja podobnih jezikov WMT 2020. Predložili smo sisteme za špansko-portugalski jezikovni par (v obeh smereh). Trije predloženi sistemi temeljijo na arhitekturi transformatorja in uporabljajo fino nastavitev za prilagoditev domene.', 'he': 'העיתון הזה מתאר את השתתפות של צוות מחקר NLP של מרכז מחקר מחשב IPN במשימת התרגום לשפה דומה WMT 2020. הגענו מערכות לזוג השפה הספרדית-פורטוגזית (בשני הכיוונים). שלושת המערכות המועברות מבוססות על הארכיטקטורה הטרנספורטרית והשתמשו בתרגיל יפה עבור ההתאמה לתחום.', 'ha': "Wannan karatun na describe the rolin the NLP research team of the IPN Research Centre in the WMT 2020 Similar Fassarar Lugha. We have submitted systems for the Spanish-Portuguese language pair (in both directions).  Wasu'ar da aka shigar da su aka ƙayyade matsayin Transformer, kuma ana yi amfani da tun mai kyau wa Adadation wa Domen.", 'bo': 'ཤོག ང་ཚོས་ཤེས་པའི་སྐད་རིགས་དབྱེ་བ་དང་པོ་རོཊ་སིའི་ཆ་གཉིས་ཀྱི་གཤམ་གྱི་ནང་དུ་འཇུག་ཡོད། The three submitted systems are based on the Transformer architecture and used fine tuning for domain Adaptation.'}
{'en': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'ar': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems لمهمة ترجمة لغة مماثلة @ WMT 2020', 'pt': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'fr': 'Systèmes de traduction automatique nuig-panlingua-KMI Hindi-Marathi pour tâche de traduction dans une langue similaire @ WMT 2020', 'es': 'Sistemas de MT hindi-marathi de NUIG-Panlingua-KMI para tareas de traducción de idiomas similares @ WMT 2020', 'ja': '類似言語翻訳タスクのためのNUIG - Panlingua - KMIヒンディー語-マラーティー語MTシステム@ WMT 2020', 'zh': 'NUIG-Panlingua-KMI印地语-马拉地语MT统于类译@ WMT 2020', 'hi': 'NUIG-Panlingua-KMI हिंदी-मराठी MT Systems for similar language translation task @ WMT 2020', 'ru': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for similar language translation task @ WMT 2020', 'ga': 'NUIG-Panlingua-KMI Hindi-Marathi Córais MT do Thasc Aistriúcháin Teangacha Comhchosúla @ WMT 2020', 'ka': 'Name', 'el': 'Συστήματα ΜΤ Χίντι-Μαραθί NUIG-Panlingua-KMI για εργασία μετάφρασης παρόμοιων γλωσσών', 'hu': 'NUIG-Panlingua-KMI Hindi-Marathi MT rendszerek hasonló nyelvű fordítási feladatokhoz @ WMT 2020', 'it': 'Sistemi MT NUIG-Panlingua-KMI Hindi-Marathi per attività di traduzione di lingue simili @ WMT 2020', 'kk': 'NUIG- Panlingua- KMI Hindi- Marathi MT тіл аудару тапсырмасының жүйелері @ WMT 2020', 'lt': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'mk': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'ms': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'ml': '@ WMT 2020', 'mt': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'pl': 'NUIG-Panlingua-KMI Hindi-Marathi systemy MT dla zadania tłumaczenia podobnego języka', 'ro': 'Sisteme MT NUIG-Panlingua-KMI Hindi-Marathi pentru sarcina de traducere a limbilor similare @ WMT 2020', 'no': 'NUIG- Panlingua- KMI Hindi- Marathi MT- systemer for liknande språk- omsetjingsverkt @ WMT 2020', 'so': '@ WMT 2020', 'sv': 'NUIG-Panlingua-KMI Hindi-Marathi MT-system för översättning av liknande språk @ WMT 2020', 'ta': '@ WMT 2020', 'sr': 'NUIG-Panlingua-KMI Hindi-Marathi MT sistemi za slični prevodni zadatak jezika @ WMT 2020', 'si': '@ WMT 2020Name', 'mn': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'ur': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'uz': '@ WMT 2020', 'vi': 'Hệ thống NIG-Panlinga-K Hindi-Marati MTV cho Công việc dịch ngôn ngữ tương tự... WM 2020', 'bg': 'Хинди-марати МТ системи за подобна задача за превод на езици @ УМТ 2020', 'nl': 'NUIG-Panlingua-KMI Hindi-Marathi MT-systemen voor vertaaltaken in vergelijkbare talen', 'da': 'NUIG-Panlingua-KMI Hindi-Marathi MT-systemer til oversættelse af lignende sprog opgave @ WMT 2020', 'de': 'NUIG-Panlingua-KMI Hindi-Marathi MT-Systeme für ähnliche Übersetzungsaufgaben (WMT 2020)', 'ko': '유사한 언어 번역 작업@WMT 2020용 NUIG Panlingua KMI Hindi Marathi 기계 번역 시스템', 'fa': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'sw': 'NUIG-Panlingua-KMI Hindi-Marathi MT Mfumo wa Tafsiri ya Lugha inayofanana', 'af': 'NUIG- Panlingua- KMI Hindi- Marathi MT stelsels vir gelyklike taal vertaling taak@ WMT 2020', 'tr': 'NUIG-Panlingua-KMI Hindi-Marathi MT Öňe Diller terjime görevi üçin sistemler @WMT 2020', 'hr': 'NUIG-Panlingua-KMI Hindi-Marathi MT sustavi za slični prevodni zadatak jezika @ WMT 2020', 'sq': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'am': 'የNUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task@WMT 2020', 'id': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'hy': 'Նմանատիպ լեզվի թարգմանման համակարգեր', 'az': 'NUIG-Panlingua-KMI Hindi-Marathi MT Similar Dil Çeviri Gözəli Sistemləri @ WMT 2020', 'bn': '@ WMT 2020', 'cs': 'NUIG-Panlingua-KMI Hindi-Marathi MT systémy pro překlad podobného jazyka', 'bs': 'NUIG-Panlingua-KMI Hindi-Marathi MT sistemi za slični prevodni zadatak jezika @ WMT 2020', 'ca': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'et': 'NUIG-Panlingua-KMI Hindi-Marathi MT süsteemid sarnase keele tõlke ülesandeks @ WMT 2020', 'fi': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'jv': 'NUIG-Panlanguage-kmI Hong-Marati MT Sistem kanggo Terjamahan Inggal Kabungan Panlanguage', 'ha': '@ WMT 2020', 'he': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020', 'sk': 'NUIG-Panlingua-KMI Hindi-Marathi MT sistemi za podobno prevajanje jezikov @ WMT 2020', 'bo': 'NUIG-Panlingua-KMI Hindi-Marathi MT Systems for Similar Language Translation Task @ WMT 2020'}
{'en': 'NUIG-Panlingua-KMI submission to WMT 2020 seeks to push the state-of-the-art in Similar Language Translation Task for HindiMarathi language pair. As part of these efforts, we conducteda series of experiments to address the challenges for translation between similar languages. Among the 4 MT systems prepared under this task, 1 PBSMT systems were prepared for HindiMarathi each and 1 NMT systems were developed for HindiMarathi using Byte PairEn-coding (BPE) into subwords. The results show that different architectures NMT could be an effective method for developing MT systems for closely related languages. Our Hindi-Marathi NMT system was ranked 8th among the 14 teams that participated and our Marathi-Hindi NMT system was ranked 8th among the 11 teams participated for the task.', 'fr': "La soumission de Nuig-Panlingua-KMI au WMT 2020 vise à améliorer la technologie de la tâche de traduction dans une langue similaire pour la paire de langues hindi ↔ marathi. Dans le cadre de ces efforts, nous avons mené une série d'expériences visant à relever les défis de la traduction entre des langues similaires. Parmi les 4 systèmes de MT préparés dans le cadre de cette tâche, 1 système PBSMT a été préparé pour Hindi ↔ Marathi chacun et 1 système NMT a été développé pour Hindi ↔ Marathi en utilisant le codage par paires d'octets (BPE) dans des sous-mots. Les résultats montrent que différentes architectures NMT pourraient être une méthode efficace pour développer des systèmes de TA pour des langues étroitement liées. Notre système NMT Hindi-Marathi a été classé 8e parmi les 14 équipes qui ont participé et notre système NMT marathi-hindi a été classé 8e parmi les 11 équipes participantes pour la tâche.", 'ar': 'يسعى تقديم NUIG-Panlingua-KMI إلى WMT 2020 إلى دفع مهمة ترجمة اللغة الأكثر حداثة لزوج اللغات الهندية الماراثية. كجزء من هذه الجهود ، أجرينا سلسلة من التجارب لمواجهة تحديات الترجمة بين اللغات المتشابهة. من بين أنظمة MT الأربعة التي تم إعدادها في إطار هذه المهمة ، تم إعداد 1 أنظمة PBSMT لكل من Hindi↔Marathi وتم تطوير 1 أنظمة NMT لـ Hindi -Marathi باستخدام Byte PairEn-coding (BPE) في كلمات فرعية. أظهرت النتائج أن البنى المختلفة NMT يمكن أن تكون طريقة فعالة لتطوير أنظمة الترجمة الآلية للغات وثيقة الصلة. تم تصنيف نظام Indian-Marathi NMT الخاص بنا في المرتبة الثامنة من بين 14 فريقًا شاركوا ، وتم تصنيف نظام Marathi-Indian NMT الخاص بنا في المرتبة 8 من بين 11 فريقًا شاركوا في المهمة.', 'pt': 'A submissão do NUIG-Panlingua-KMI ao WMT 2020 busca impulsionar o estado da arte na tarefa de tradução de idiomas semelhantes para o par de idiomas hindi↔marathi. Como parte desses esforços, realizamos uma série de experimentos para enfrentar os desafios da tradução entre idiomas semelhantes. Entre os 4 sistemas MT preparados para esta tarefa, 1 sistema PBSMT foi preparado para Hindi↔Marathi cada e 1 sistema NMT foi desenvolvido para Hindi↔Marathi usando a codificação Byte PairEn (BPE) em subpalavras. Os resultados mostram que diferentes arquiteturas NMT podem ser um método eficaz para o desenvolvimento de sistemas MT para linguagens intimamente relacionadas. Nosso sistema Hindi-Marathi NMT ficou em 8º lugar entre as 14 equipes que participaram e nosso sistema Marathi-Hindi NMT ficou em 8º lugar entre as 11 equipes que participaram da tarefa.', 'es': 'La presentación de NUIG-Panlingua-KMI al WMT 2020 busca impulsar el estado de la técnica en tareas de traducción de idiomas similares para el par de idiomas hindi ↔ marathi. Como parte de estos esfuerzos, realizamos una serie de experimentos para abordar los desafíos de la traducción entre idiomas similares. Entre los 4 sistemas MT preparados en esta tarea, se preparó 1 sistema PBSMT para Hindi ↔ Marathi cada uno y se desarrolló 1 sistema NMT para Hindi ↔ Marathi utilizando la codificación Byte Pair (BPE) en subpalabras. Los resultados muestran que diferentes arquitecturas NMT podrían ser un método eficaz para desarrollar sistemas de MT para lenguajes estrechamente relacionados. Nuestro sistema NMT hindi-marathi ocupó el octavo lugar entre los 14 equipos que participaron y nuestro sistema NMT marathi-hindi ocupó el octavo lugar entre los 11 equipos que participaron en la tarea.', 'ja': 'WMT 2020へのNUIG - Panlingua - KMI提出は、ヒンディー語と↔マラーティー語のペアのための類似言語翻訳タスクの最先端を推進しようとしています。これらの取り組みの一環として、同様の言語間の翻訳の課題に対処するための一連の実験を実施しました。このタスクの下で準備された4つのMTシステムのうち、1つのPBSMTシステムはヒンディー語↔マラーティー語のために各々準備され、1つのNMTシステムは、Byte PairEn - coding (BPE)をサブワードに使用してヒンディー語↔マラーティー語のために開発されました。結果は、異なるアーキテクチャNMTが密接に関連する言語のMTシステムを開発するための効果的な方法である可能性を示している。私たちのヒンディー・マラティNMTシステムは、参加した14チームの中で8位であり、私たちのマラティ・ヒンディーNMTシステムは、タスクのために参加した11チームの中で8位でした。', 'hi': 'डब्ल्यूएमटी 2020 को एनयूआईजी-पनलिंगुआ-केएमआई प्रस्तुत करने का उद्देश्य हिंदी↔मराठा भाषा जोड़ी के लिए समान भाषा अनुवाद कार्य में अत्याधुनिक को आगे बढ़ाना है। इन प्रयासों के हिस्से के रूप में, हमने समान भाषाओं के बीच अनुवाद के लिए चुनौतियों का सामना करने के लिए प्रयोगों की एक श्रृंखला आयोजित की। इस कार्य के तहत तैयार की गई 4 एमटी प्रणालियों में से, हिंदी↔मराठा के लिए 1 पीबीएसएमटी प्रणालियां तैयार की गई थीं और हिंदी↔मराठा के लिए बाइट पेयरएन-कोडिंग (बीपीई) को उप-शब्दों में उपयोग करके 1 एनएमटी प्रणालियों को विकसित किया गया था। परिणामों से पता चलता है कि विभिन्न आर्किटेक्चर एनएमटी निकटता से संबंधित भाषाओं के लिए एमटी सिस्टम विकसित करने के लिए एक प्रभावी तरीका हो सकता है। हमारी हिंदी-मराठी एनएमटी प्रणाली भाग लेने वाली 14 टीमों में 8 वें स्थान पर थी और हमारी मराठी-हिंदी एनएमटी प्रणाली को कार्य के लिए भाग लेने वाली 11 टीमों में से 8 वें स्थान पर रखा गया था।', 'zh': 'NUIG-Panlingua-KMI向WMT 2020文旨在推印地语↔马拉地语对类语译。 为此一分,列实验,以应类言。 以此4MT统,各为HindiMarathi↔备1PBSMT,用Byte PairEn编码(BPE)为HindiMarathi↔发1NMT统。 结果表明异架构NMT者,或为密言开机器翻译系统之效也。 吾印地语 - 马拉地语NMT系于参事者14一团队中排名第8位,吾马拉地语 - 印地语NMT系于参事者11团队中排名第8位。', 'ru': 'Представление NUIG-Panlingua-KMI на WMT 2020 направлено на продвижение современной задачи аналогичного перевода языка для↔ языковой пары хинди-маратхи. В рамках этих усилий мы провели серию экспериментов для решения проблем перевода между похожими языками. Среди 4 систем MT, подготовленных в соответствии с этой задачей, 1 система PBSMT была подготовлена для↔ каждого хинди-маратхи и 1 система NMT была разработана для хинди-маратхи с↔ использованием кодирования Byte PairEn (BPE) в подсловы. Результаты показывают, что различные архитектуры NMT могут быть эффективным методом разработки систем МП для тесно связанных языков. Наша система NMT Hindi-Marathi заняла 8-е место среди 14 команд, которые участвовали в задании, а наша система NMT Marathi-Hindi заняла 8-е место среди 11 команд, участвовавших в задании.', 'ga': 'Féachann aighneacht NUIG-Panlingua-KMI chuig WMT 2020 leis an Tasc Aistriúcháin Teanga den chéad scoth a bhrú chun cinn don phéire teangacha Hiondúis↔Maraitis. Mar chuid de na hiarrachtaí seo, rinneamar sraith turgnamh chun dul i ngleic leis na dúshláin a bhaineann le haistriúchán idir teangacha comhchosúla. I measc na 4 chóras MT a ullmhaíodh faoin tasc seo, ullmhaíodh 1 chóras PBSMT le haghaidh Hiondúis↔Maraitis an ceann agus forbraíodh 1 chóras NMT don Hindi↔Marathi ag baint úsáide as Byte PairEn-coding (BPE) ina bhfofhocail. Léiríonn na torthaí go bhféadfadh ailtireachtaí éagsúla NMT a bheith ina mhodh éifeachtach chun córais MT a fhorbairt do theangacha dlúthghaolmhara. Rangaíodh ár gcóras NMT Hiondúis-Maraitis san 8ú háit i measc na 14 fhoireann a ghlac páirt agus bhí ár gcóras NMT Maraitis-Hiondúis san 8ú háit i measc na 11 fhoireann a ghlac páirt sa tasc.', 'el': 'Η υποβολή του NUIG-Panlingua-KMI στο WMT 2020 επιδιώκει να προωθήσει την υπερσύγχρονη εργασία μετάφρασης παρόμοιων γλωσσών για το ζεύγος γλωσσών Χίντι Μαραθί. Στο πλαίσιο αυτών των προσπαθειών, πραγματοποιήσαμε μια σειρά πειραμάτων για την αντιμετώπιση των προκλήσεων για τη μετάφραση μεταξύ παρόμοιων γλωσσών. Μεταξύ των τεσσάρων συστημάτων MT που προετοιμάστηκαν στο πλαίσιο αυτού του έργου, προετοιμάστηκαν 1 συστήματα PBSMT για τα Hindi Marathi κάθε και 1 συστήματα NMT αναπτύχθηκαν για Hindi Marathi χρησιμοποιώντας την κωδικοποίηση Byte PairEn (BPE) σε υπολέξεις. Τα αποτελέσματα δείχνουν ότι οι διαφορετικές αρχιτεκτονικές θα μπορούσαν να αποτελέσουν αποτελεσματική μέθοδο για την ανάπτυξη συστημάτων ΜΤ για στενά συνδεδεμένες γλώσσες. Το σύστημα μας Χίντι-Μαραθί κατατάχθηκε 8η μεταξύ των 14ων ομάδων που συμμετείχαν και το σύστημα μας Μαραθί-Χίντι κατατάχθηκε 8η μεταξύ των 11ων ομάδων που συμμετείχαν για το έργο.', 'ka': 'NUIG-Panlingua-KMI WMT 2020-ს გადაწყვეტილებას ძირებს იგივე მსგავსი ენის გადაწყვეტილების რაოდენობაში ჰინდი მარატი ენის ზოგებისთვის გადაწყვეტილება. როგორც ამ ძალების ნაწილი, ჩვენ ექსპერიმენტების სერიონი გავაკეთეთ, როგორც იგივე ენების შორის გადაწყვეტილებისთვის გამოცდილება. 4 MT სისტემების განმავლობაში, ამ დავალების გამოყენებაში 1 PBSMT სისტემები ჰინდი მარატის განმავლობაში ყოველ და 1 NMT სისტემები ჰინდი მარატის გამოყენებაში გამოყენებული ბაიტი PairEn-coding (BPE) სისტემებში გავი შედეგი გამოჩვენება, რომ განსხვავებული არქტიქტურები NMT შეიძლება იყოს ეფექტიური პროცემი MT სისტემის განვითარება მხოლოდ დაკავშირებული ენებისთ ჩვენი ჰინდი-მარატი NMT სისტემა იყო 8-ი პრონეტი 14 ჯგუფი, რომელიც ჩვენი მარატი-ჰინდი NMT სისტემა იყო 8-ი პრონეტი 11 ჯგუფი განმავლობაში.', 'hu': 'A NUIG-Panlingua-KMI benyújtása a WMT 2020-ra törekszik arra, hogy előmozdítsa a hasonló nyelvű fordítási feladatokat a hindi marathi nyelvpár számára. Ezen erőfeszítések részeként kísérletsorozatot végeztünk a hasonló nyelvek közötti fordítás kihívásainak kezelésére. Az e feladat keretében előkészített 4 MT rendszer közül 1 PBSMT rendszert készítettek Hindi Marathi számára, 1 NMT rendszert pedig a Hindi Marathi számára Byte PairEn kódolással (BPE) fejlesztettek ki. Az eredmények azt mutatják, hogy a különböző architektúrák NMT hatékony módszer lehet MT rendszerek fejlesztésére szorosan kapcsolódó nyelvek számára. Hindi-Marathi NMT rendszerünk a 14 résztvevő csapat közül a 8. helyen állt, Marathi-Hindi NMT rendszerünk pedig a 8. helyen állt a feladatra részt vevő 11 csapat közül.', 'it': "La presentazione di NUIG-Panlingua-KMI a WMT 2020 mira a spingere lo stato dell'arte nella traduzione di lingue simili per la coppia di lingue Hindi Marathi. Nell'ambito di questi sforzi, abbiamo condotto una serie di esperimenti per affrontare le sfide della traduzione tra lingue simili. Tra i 4 sistemi MT preparati nell'ambito di questo compito, 1 sistemi PBSMT sono stati preparati per Hindi Marathi ciascuno e 1 sistemi NMT sono stati sviluppati per Hindi Marathi utilizzando la codifica Byte PairEn (BPE) in subparole. I risultati mostrano che diverse architetture NMT potrebbero essere un metodo efficace per sviluppare sistemi MT per linguaggi strettamente correlati. Il nostro sistema NMT Hindi-Marathi si è classificato ottavo tra le 14 squadre che hanno partecipato e il nostro sistema NMT Marathi-Hindi si è classificato ottavo tra le 11 squadre partecipanti al compito.", 'kk': 'NUIG-Panlingua-KMI WMT 2020 дегенге жіберу үшін хинди марати тілдерінің екі үшін ұқсас тілдерді аудару тапсырмасының күйін басып тастау керек. Бұл әрекеттердің бір бөлігі болса, біз ұқсас тілдер арасындағы аудармалардың өзгерістерін өзгерту үшін бірнеше тәжірибелерді жасадық. Бұл тапсырманың астындағы 4 MT жүйелердің арасында 1 PBSMT жүйелері инду марати үшін әрбір NMT жүйелері инду марати үшін Байт Пайеренкодирову (BPE) бағытты сөздерге жасалған. Нәтижелер NMT архитектуралары жақын тілдер үшін MT жүйелерін жасау әдісі болуы мүмкін. Біздің Хинди-Марати NMT жүйесіміз 14 топтардың 8-ші ретінде сақталды. Марати-Хинди NMT жүйесіміз 11 топтардың 8-ші ретінде сақталды.', 'lt': 'NUIG-Panlingua-KMI submission to WMT 2020 seeks to push the state-of-the-art in Similar Language Translation Task for Hindi Marathi language pair.  As part of these efforts, we conducteda series of experiments to address the challenges for translation between similar languages.  Iš 4 MT sistemų, parengtų pagal šią užduotį, viena PBSMT sistema buvo parengta Hindi Marathi, viena NMT sistema buvo parengta Hindi Marathi, o viena NMT sistema buvo sukurta Hindi Marathi, naudojant Byte PairEn kodavimą (BPE) į parašus. Rezultatai rodo, kad skirtingos NMT architektūros galėtų būti veiksmingas metodas plėtoti glaudžiai susijusių kalbų MT sistemas. Mūsų Hindi-Marathi NMT sistema buvo 8-oji iš 14 komandų, kurios dalyvavo, o mūsų Marathi-Hindi NMT sistema buvo 8-oji iš 11 komandų, kurios dalyvavo šioje užduotyje.', 'mk': 'Предложението на НУИГ-Панлингва-КМИ на ВМТ 2020 се обидува да ја притисне најновата техничка задача за преведување на слични јазици за парот на хиндиски маратски јазик. As part of these efforts, we conducteda series of experiments to address the challenges for translation between similar languages.  Among the 4 MT systems prepared under this task, 1 PBSMT systems were prepared for Hindi Marathi each and 1 NMT systems were developed for Hindi Marathi using Byte PairEn-coding (BPE) into subwords.  Резултатите покажуваат дека различните архитектури НМТ би можеле да бидат ефикасен метод за развој на МТ системи за блиски поврзани јазици. Нашиот хинди-маратски НМТ систем беше рангиран на осмиот место меѓу 14 тимови кои учествуваа, а нашиот марати-хинди НМТ систем беше рангиран на осмиот место меѓу 11 тимови кои учествуваа во задачата.', 'ml': 'ഹിന്ദി മാരാത്തി ഭാഷയുടെ ജോടികള്\u200dക്കുള്ള പോലുള്ള ഭാഷയിലെ സ്ഥിതിയുടെ രാജ്യത്തെ പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d ശ്രമിക്കുന്നു. ഇത്തരം പരീക്ഷണങ്ങളില്\u200d ഒരു ഭാഗമായി ഞങ്ങള്\u200d പരീക്ഷണങ്ങള്\u200d നടത്തിയിട്ടുണ്ട്. അതുപോലെയുള്ള ഭാഷകള്\u200dക്കിടയില്\u200d വ്യാ Among the 4 MT systems prepared under this task, 1 PBSMT systems were prepared for Hindi Marathi each and 1 NMT systems were developed for Hindi Marathi using Byte PairEn-coding (BPE) into subwords.  അതിന്റെ ഫലങ്ങള്\u200d ഞങ്ങളുടെ ഹിന്ദി-മാരാത്തി NMT സിസ്റ്റത്തില്\u200d പങ്കുചേര്\u200dന്ന 14 ഗ്രൂപ്പുകളില്\u200d എട്ടാമത്തെ റാഞ്ച് ചെയ്തു. ഞങ്ങളുടെ മാരാത്തി-ഹിന്ദി-എം', 'mn': 'NUIG-Panlingua-KMI WMT 2020-д хэлж байгаа нь Хинди Марати хэлний хоёрын төстэй хэлний хөрөнгө хөрөнгө оруулах үйл явц юм. Эдгээр хичээлийн нэг хэсэг болгон бид төстэй хэл хоорондоо орчуулахын тулд олон туршилтыг хийсэн. Энэ ажлын доор бэлдэн 4 MT системийн дотор 1 PBSMT систем нь Хинди Марати-д бүр 1 NMT систем бүрдүүлсэн бөгөөд Хинди Марати-д Байт PairEn-кодлог (BPE) гэсэн үг болгон хөгжүүлсэн. Үүний үр дүнд NMT-ийн өөр архитектурууд ойролцоогоор холбоотой хэлний MT системийг хөгжүүлэх эффективний арга болж чадна. Бидний Хинди-Марати NMT систем 14 багт оролцсон бөгөөд Марати-Хинди NMT систем 11 багт оролцсон бөгөөд 8-р багт оролцсон.', 'no': 'NUIG-Panlingua-KMI-submission to WMT 2020 seeks to push the state-of-the-art in similar Language Translation Task for Hindi Marathi language pair. Som ein del av desse forsøka har vi gjennomført rekkje eksperimenter for å handsama utfordringane for omsetjing mellom liknande språk. Av 4 MT-systema som er forberedt under denne oppgåva vart 1 PBSMT-systemet forberedt for Hindi-Marathi kvar og 1 NMT-systemet utvikla for Hindi-Marathi med byte-PairEn-koding (BPE) i underord. Resultatet viser at ulike arkitekturar NMT kan vera ein effektiv metode for å utvikla MT-systemet for nærare relaterte språk. Vårt Hindi-Marathi NMT-system var rankert 8. mellom de 14 gruppene som deltok, og vårt Marathi-Hindi NMT-system var rankert 8. mellom de 11 gruppene deltok i oppgåva.', 'pl': 'Zgłoszenie NUIG-Panlingua-KMI do WMT 2020 ma na celu przekształcenie najnowocześniejszych zadań tłumaczeniowych podobnych języków dla pary językowej Hindi Marathi. W ramach tych wysiłków przeprowadziliśmy serię eksperymentów mających na celu sprostanie wyzwaniom związanym z tłumaczeniem między podobnymi językami. Wśród 4-MT systemów przygotowanych w ramach tego zadania przygotowano systemy 1 PBSMT dla Hindi Marathi każdy i 1 NMT systemy zostały opracowane dla Hindi Marathi z wykorzystaniem kodowania Byte PairEn (BPE) w podsłowa. Wyniki pokazują, że różne architektury NMT mogłyby być skuteczną metodą tworzenia systemów MT dla blisko pokrewnych języków. Nasz system NMT Hindi-Marathi znalazł się ósmym miejscem wśród czternastu zespołów, które uczestniczyły, a nasz system NMT Marathi-Hindi znalazł się ósmym miejscem wśród jedenastu zespołów uczestniczących w tym zadaniu.', 'ro': 'Prezentarea NUIG-Panlingua-KMI la WMT 2020 urmărește să promoveze activitatea de ultimă generație în traducerea limbilor similare pentru perechea de limbi hindi marathi. Ca parte a acestor eforturi, am realizat o serie de experimente pentru a aborda provocările legate de traducerea între limbi similare. Dintre cele 4 sisteme MT pregătite în cadrul acestei sarcini, 1 sisteme PBSMT au fost pregătite fiecare pentru Hindi Marathi și 1 sisteme NMT au fost dezvoltate pentru Hindi Marathi folosind codificarea Byte PairEn (BPE) în subcuvinte. Rezultatele arată că diferite arhitecturi NMT ar putea fi o metodă eficientă pentru dezvoltarea sistemelor MT pentru limbi strâns conexe. Sistemul nostru NMT Hindi-Marathi a fost clasat pe locul 8 în rândul celor 14 echipe care au participat, iar sistemul nostru NMT Marathi-Hindi a fost clasat pe locul 8 în rândul celor 11 echipe participate la această sarcină.', 'sr': 'NUIG-Panlingua-KMI podnošenje WMT 2020 traži da gura državu umjetnosti u sličnom jezičkom prevodnom zadatku za indijske maratijske parove. Kao deo tih napora, proveli smo seriju eksperimenata da se riješimo izazovima za prevod između sličnih jezika. Između 4 MT sustava pripremljenih pod ovim zadatkom, 1 PBSMT sistem je pripremljen za Hindi Marathi i 1 NMT sistem je razvijen za Hindi Marathi koristeći Byte PairEn-kodiranje (BPE) u podreči. Rezultati pokazuju da bi različite arhitekture NMT mogle biti efikasni metod razvoja MT-sistema za bliski povezane jezike. Naš Hindi-Marathi NMT sistem je bio 8. red među 14 tima koji su sudjelovali, a naš Marathi-Hindi NMT sistem je bio 8. red među 11 tima koji su sudjelovali u tom zadatku.', 'so': 'NUIG-Panlingua-KMI ayaa u dhiibaya WMT 2020 wuxuu doonayaa inuu dhaqaajiyo xaalada-the-art oo ku qoran turjumista luqada isku mid ah ee Hindi Marathi labaad. Qayb ka mid ah hawlahaas, waxaan sameynay jirrabooyin badan si aan uga sheekeyno dhibaatooyinka turjumidda luuqadaha oo isku mid ah. 4 MT systems oo lagu diyaariyey shuqulkaas hoostiisa, 1 PBSMT nidaam waxaa loo diyaariyey Hindi Marathi mid kasta iyo 1 NMT systems waxaa loo horumariyey Hindi Marathi using Byte Pairen coding (BPE). Abaalku waxay muuqataa in dhismaha kala duwan ee NMT wuxuu noqon karaa qaab faa’iido ah oo u horumarinta nidaamka MT ee luuqadaha ku dhow ee la xidhiidha. Xindi-Marathi NMT nidaamkayagii waxaa lagu kala soocay 8aad oo ka mid ahaa kooxda 14 ee ka qayb galay, waxaana nidaamka Marathi-Hindi NMT lagu kala soocay 8aad oo ka mid ahaa kooxda u qayb galay shaqada.', 'si': 'NAIG-Panlinga-KMI WMT 2020ට පිළිගන්න සැලසුම් කරනවා හින්දි මාරාති භාෂාව සඳහා සමාන භාෂාව භාෂාව සඳහා සමාන භාෂාව සඳහා ක්\u200dරියා මේ උත්සහේ කොටසක් විදිහට, අපි පරීක්ෂණාවක් කරනවා වගේ භාෂාවක් අතර වාර්තාවක් සඳහා අභ්\u200dයාගයක් ස මේ වැඩේ හරි MT පද්ධති 4 අතර, 1 PBSMT පද්ධතිය හින්දි මාරාති වලට සූදානම් කරලා හින්දි මාරාති වලට බායිට් පයේරෙන් කෝඩින් වලට (BPE) භාවිත කරන් ප්\u200dරතිචාරය පෙන්වන්නේ වෙනස් ස්ථාපනය NMT විශේෂ විදිහට සම්බන්ධ භාෂාවක් සඳහා MT පද්ධතිය ව අපේ හින්දී-මාරාතී NMT පද්ධතිය අංශි අංශි අංශි අංශි අංශි අංශි අංශි අංශි අංශි අංශි අංශි අ', 'sv': 'NUIG-Panlingua-KMI inlämnande till WMT 2020 syftar till att driva den senaste uppgiften för översättning av liknande språk för hindi marathi språkpar. Som en del av dessa insatser genomförde vi en serie experiment för att ta itu med utmaningarna för översättning mellan liknande språk. Bland de 4 MT-system som utarbetats under denna uppgift förbereddes 1 PBSMT-system för Hindi Marathi var och en och 1 NMT-system utvecklades för Hindi Marathi med Byte PairEn-kodning (BPE) till underord. Resultaten visar att olika arkitekturer NMT kan vara en effektiv metod för att utveckla MT-system för närbesläktade språk. Vårt Hindi-Marathi NMT-system rankades 8:e bland de 14 lag som deltog och vårt Marathi-Hindi NMT-system rankades 8:e bland de 11 lag som deltog för uppgiften.', 'ta': 'Name இந்த முயற்சிகளின் பகுதி இந்த பணிக்கு கீழே தயாரிக்கப்பட்ட 4 MT அமைப்புகளில், 1 PBSMT அமைப்புகள் ஒவ்வொரு மற்றும் 1 NMT அமைப்புகள் துணை வார்த்தைகளில் பைட் பேரின் குறியீடு (BPE) பயன்படுத The results show that different architectures NMT could be an effective method for developing MT systems for closely related languages.  எங்கள் இந்தி-மாராத்தி என்எம்டி அமைப்பு பங்கிடப்பட்ட 14 குழுக்களில் 8வது பங்கிடப்பட்டது மற்றும் எங்கள் மாராத்தி-ஹின்டி-என்எம்டி அமைப்பு பணிக', 'ur': 'NUIG-Panlingua-KMI WMT 2020 کے تحویل کی کوشش ہے کہ ہندی مارتی زبان جوڑوں کے لئے سیدھی زبان ترجمہ ٹاکس میں فشار کرنا چاہتا ہے. ہم نے ان تلاشوں میں سے ایک حصہ کے طور پر ایک سری تجربے کی جگہ پہنچائیں جیسی زبانوں کے درمیان ترجمہ کرنے کے لئے چالیں کرنے کے لئے۔ اس کام کے نیچے تیار کیے گئے 4 MT سیستم میں 1 PBSMT سیستم ہندی ماراتی کے لئے تیار کیے گئے، ہر ایک NMT سیستم ہندی ماراتی کے لئے بائیٹ پایرن کوڈینگ (BPE) کے مطابق زیر کلمات کے لئے تیار کیے گئے۔ نتائج دکھاتے ہیں کہ مختلف معماری NMT ایک عمدہ طریقہ بن سکتا ہے MT سیستموں کے لئے نزدیک مرتبہ زبانوں کے لئے۔ ہماری ہندی ماراتی NMT سیسٹم 14 تیموں میں 8 رقم تھا اور ہماری ماراتی-ہندی NMT سیسٹم 11 تیموں میں 8 رقم تھا جو اس کام کے لئے شرکت کی تھی.', 'mt': 'NUIG-Panlingua-KMI submission to WMT 2020 seeks to push the state-of-the-art in Similar Language Translation Task for Hindi Marathi language pair.  Bħala parti minn dawn l-isforzi, wettaqna sensiela ta’ esperimenti biex nindirizzaw l-isfidi għat-traduzzjoni bejn lingwi simili. Among the 4 MT systems prepared under this task, 1 PBSMT systems were prepared for Hindi Marathi each and 1 NMT systems were developed for Hindi Marathi using Byte PairEn-coding (BPE) into subwords.  The results show that different architectures NMT could be an effective method for developing MT systems for closely related languages.  Our Hindi-Marathi NMT system was ranked 8th among the 14 teams that participated and our Marathi-Hindi NMT system was ranked 8th among the 11 teams participated for the task.', 'ms': 'NUIG-Panlingua-KMI submission to WMT 2020 seeks to push the state-of-the-art in Similar Language Translation Task for Hindi Marathi language pair.  As part of these efforts, we conducteda series of experiments to address the challenges for translation between similar languages.  Among the 4 MT systems prepared under this task, 1 PBSMT systems were prepared for Hindi Marathi each and 1 NMT systems were developed for Hindi Marathi using Byte PairEn-coding (BPE) into subwords.  The results show that different architectures NMT could be an effective method for developing MT systems for closely related languages.  Sistem NMT Hindi-Marathi kami ditetapkan ke-8 diantara 14 pasukan yang berpartisipasi dan sistem NMT Marathi-Hindi kami ditetapkan ke-8 diantara 11 pasukan yang berpartisipasi untuk tugas.', 'uz': "Name Bu jarayonlarning bir qismida biz bir necha tajribalarni bajardik, bu o'xshash tillar orasidagi tarjima qilish uchun muammolarni boshqarish uchun. Ushbu vazifa ichida tayyorlangan 4 MT tizimdan bir PBSMT tizimi Hindi Marathi uchun tayyorlangan va 1 NMT tizimi Byte Pairen kodlash (BPE) bilan bir xizmatga yaratildi. @ info Bizning Hindi-Marathi NMT tizimimiz ishga tayyorlangan 14 guruhdagi 8 ta ta ta'mindan boshlangan edi va bizning Marathi-Hindi NMT tizimimizning 11 guruhi uchun qiziqarishga ega bo'lgan 11 guruhdan 8 ta ta ta'mindan boshlanadi.", 'vi': 'Người cung cấp cho WRT 2020 đã tìm cách thúc đẩy tiến trình độ cao của ngôn ngữ tương tự dịch cho cá nhân Ấn Độ Độ Độ Độ Độ Độ Độ. Trong những nỗ lực này, chúng tôi tiến hành một loạt các thí nghiệm nhằm giải quyết các vấn đề dịch thuật giữa các ngôn ngữ tương tự. Trong những hệ thống 4 MTV được chuẩn bị trong phần này, 1 hệ thống PBSMT được chuẩn bị cho cá nhân Ấn Độ Marath và 1 hệ thống NMT được phát triển cho Hindi Marath, sử dụng Byte pair Ent-code (BPE) thành chữ phụ. Kết quả cho thấy cấu trúc khác nhau NMB có thể là một cách thức hiệu quả để phát triển hệ thống MTV cho các ngôn ngữ liên quan mật thiết. Hệ thống NMB của chúng tôi được phân loại 8th trong các đội bốn người đã tham gia và hệ thống NMB của chúng tôi được phân loại 8th trong các đội 11 đã tham gia nhiệm vụ.', 'da': 'NUIG-Panlingua-KMI indsendelse til WMT 2020 søger at skubbe den avancerede opgave inden for oversættelse af lignende sprog til hindi marathi sprogpar. Som led i disse bestræbelser gennemførte vi en række eksperimenter for at imødegå udfordringerne for oversættelse mellem lignende sprog. Blandt de 4 MT systemer, der blev udarbejdet under denne opgave, blev 1 PBSMT systemer forberedt til Hindi Marathi hver og 1 NMT systemer blev udviklet til Hindi Marathi ved hjælp af Byte PairEn-kodning (BPE) til underord. Resultaterne viser, at forskellige arkitekturer NMT kunne være en effektiv metode til udvikling af MT systemer til nært beslægtede sprog. Vores Hindi-Marathi NMT system blev placeret 8. blandt de 14 hold, der deltog, og vores Marathi-Hindi NMT system blev placeret 8. blandt de 11 hold, der deltog i opgaven.', 'nl': 'NUIG-Panlingua-KMI indiening aan WMT 2020 streeft ernaar de state-of-the-art in Vergelijkbare Taalvertaaltaak voor Hindi Marathi taalpaar te pushen. Als onderdeel van deze inspanningen hebben we een reeks experimenten uitgevoerd om de uitdagingen voor de vertaling tussen vergelijkbare talen aan te pakken. Onder de vier MT-systemen die onder deze taak werden voorbereid, werden 1 PBSMT-systemen voorbereid voor Hindi Marathi elk en 1 NMT-systemen werden ontwikkeld voor Hindi Marathi met behulp van Byte PairEn-codering (BPE) in subwoorden. De resultaten tonen aan dat verschillende architecturen NMT een effectieve methode zou kunnen zijn voor het ontwikkelen van MT systemen voor nauw verwante talen. Ons Hindi-Marathi NMT systeem werd 8e onder de 14-teams die deelnamen en ons Marathi-Hindi NMT systeem werd 8e geplaatst onder de elf teams die aan de taak deelnamen.', 'bg': 'Представянето на НУИГ-Панлингуа-КМИ за WMT 2020 се стреми да тласне най-съвременната задача за превод на сходни езици за езиковата двойка хинди марати. Като част от тези усилия проведохме серия от експерименти за справяне с предизвикателствата пред превода между сходни езици. Сред 4-те МТ системи, подготвени по тази задача, са изготвени по 1 ПБСМТ системи за хинди марати и 1 НМТ системи за хинди марати са разработени с помощта на байт pairEn кодиране (BPE) в поддуми. Резултатите показват, че различните архитектури могат да бъдат ефективен метод за разработване на МТ системи за тясно свързани езици. Нашата Хинди-Марати НМТ система бе класирана на 8-о място сред 14-те отбора, които участваха, а нашата Марати-Хинди НМТ система бе класирана на 8-о място сред 11-те отбора, участващи в задачата.', 'de': 'Die NUIG-Panlingua-KMI-Einreichung bei WMT 2020 zielt darauf ab, den Stand der Technik in der Übersetzungsaufgabe ähnlicher Sprachen für Hindi Marathi Sprachpaare voranzutreiben. Im Rahmen dieser Bemühungen führten wir eine Reihe von Experimenten durch, um die Herausforderungen bei der Übersetzung zwischen ähnlichen Sprachen anzugehen. Unter den vier MT-Systemen, die unter dieser Aufgabe vorbereitet wurden, wurden 1 PBSMT-Systeme für Hindi Marathi vorbereitet. Jedes NMT-System wurde für Hindi Marathi mit Byte PairEn-Coding (BPE) in Unterwörter entwickelt. Die Ergebnisse zeigen, dass verschiedene Architekturen NMT eine effektive Methode zur Entwicklung von MT-Systemen für eng verwandte Sprachen sein könnten. Unser Hindi-Marathi NMT-System wurde achtster unter den 14-Teams, die teilgenommen haben, und unser Marathi-Hindi NMT-System wurde achtster unter den elf Teams, die an dieser Aufgabe teilgenommen haben.', 'ko': 'NUIG Panlingua KMI가 WMT 2020에 제출한 문서는 비슷한 언어 번역 작업에 대한 인도어-말라디어의 최신 진전을 추진하기 위한 것이다.이러한 노력의 일부로서 우리는 유사한 언어 간의 번역 도전에 대응하기 위해 일련의 실험을 진행했다.이 임무에 준비된 4개 기계번역시스템 중 각 시스템은 인디언 말라디어를 위한 PBSMT 시스템을, 인디언 말라디어를 위한 NMT 시스템을 1개씩 개발해 바이트 쌍 코드(BPE)를 사용해 자자로 전환했다.그 결과 서로 다른 체계 구조의 NMT는 밀접한 관계를 가진 언어를 위해 기계 번역 시스템을 개발하는 효과적인 방법임이 밝혀졌다.우리의 인디언 말라티NMT 시스템은 14개 참가팀 중 8위, 우리의 말라티인디언NMT 시스템은 11개 참가팀 중 8위에 올랐다.', 'fa': 'NUIG-Panlingua-KMI submission to WMT 2020 seeks to push the state-of-the-art in Similar Language Translation Task for Hindi Marathi language pair. به عنوان بخشی از این تلاش، ما مجموعه آزمایشات را انجام دادیم تا چالش های ترجمه بین زبانهای مشابه را حل کنیم. بین سیستم\u200cهای ۴ MT آماده شده در زیر این کار، ۱ سیستم PBSMT برای ماراتی هندی آماده شده بود و ۱ سیستم NMT برای ماراتی هندی با استفاده از کید سایت پایرن (BPE) به زیر کلمه توسعه داده شد. نتیجه\u200cها نشان می\u200cدهند که معماری\u200cهای مختلف NMT می\u200cتواند روش موثری برای توسعه سیستم\u200cهای MT برای زبانهای نزدیک ارتباط باشد. سیستم NMT هندی-ماراتی ما از ۱۴ تیم شرکت کردند و سیستم NMT ماراتی-هندی ما از ۱۱ تیم شرکت کردند.', 'sw': 'NUIG-Panlingua-KMI inawasilisha WMT 2020 inakusudia kushinikiza hali ya sanaa inayofanana na kazi ya Tafsiri ya lugha ya Kihindi Marathi. As part of these efforts, we conducteda series of experiments to address the challenges for translation between similar languages.  Miongoni mwa mifumo minne ya MT iliyoandaliwa chini ya kazi hii, mifumo 1 ya PBSMT yaliandaliwa kwa ajili ya Mfumo wa Kihindi Marathi kila na moja ya NMT zilianzishwa kwa ajili ya Hindi Marathi kwa kutumia simu za Byte Pairen (BPE). Matokeo yanaonyesha kwamba majengo tofauti ya NMT inaweza kuwa njia yenye ufanisi wa kutengeneza mfumo wa MT kwa lugha zinazohusiana na karibu. Mfumo wetu wa NMT wa Hindi-Marathi ulikuwa wa rangi ya nane kati ya timu 14 zilizoshiriki na mfumo wetu wa Marathi-Hindi NMT ulikuwa wa rangi ya nane kati ya timu 11 walishiriki kufanya kazi hiyo.', 'tr': "NUIG-Panlingua-KMI WMT 2020'a teslim etmek isleýär. Hindi Marathi dil çiftleri üçin bir nusga meýdançasynyň durumyny täze etmek isleýär. Bu çabalaryň bir bölegi bolsa, meňzeş diller arasynda terjime etmek üçin kynçylyklary çözmek üçin birnäçe deneyler etdik. 4 MT sistemalarynda bu işiň altynda taýýarlanan, 1 PBSMT sistemalary Hindi Marathi üçin taýýarlandy we 1 NMT sistemalary Hindi Marathi üçin baýt PairEn-ködleme (BPE) dilinde döredildi. Netijiler NMT'iň farklı arhitektura ýakyn diller üçin MT sistemlerini geliştirmek üçin etkinlik bir yöntem bolup biler diýip görkezilýär. Biziň Hindi-Marathi NMT sistemamyz 14 topardan 8-nji düzüldi we Marathi-Hindi NMT sistemamyz 11 topardan bäri goşuldy.", 'af': "NUIG-Panlingua-KMI ondersoek na WMT 2020 soek om die staat-van-die-kuns in gelyke taal vertaling taak vir Hindi Marathi taal paar te druk. As deel van hierdie versoekte het ons reeks eksperimente gedoen om die uitdagings vir vertaling tussen gelyke tale te raak. onder die 4 MT stelsels wat onder hierdie taak gereed is, was 1 PBSMT stelsels berei vir Hindi Marathi elke en 1 NMT stelsels ontwikkel vir Hindi Marathi gebruik Byte PairEn-kodering (BPE) in subwoorde. Die resultate vertoon dat verskillende arkitektuure NMT 'n effektief metode kan wees vir ontwikkeling van MT stelsels vir naby verwante tale. Ons Hindi-Marathi-NMT stelsel is rankeerd 8de onder die 14 teams wat gedeel het en ons Marathi-Hindi NMT stelsel is rankeerd 8de onder die 11 teams gedeel het vir die taak.", 'sq': 'Subjektimi i NUIG-Panlingua-KMI në WMT 2020 kërkon të shtyjë gjendjen më të lartë në detyrën e përkthimit të gjuhës së ngjashme për çiftin e gjuhëve të marathisë së Hindi. Si pjesë e këtyre përpjekjeve, ne kryejmë një seri eksperimentesh për të trajtuar sfidat për përkthimin midis gjuhëve të ngjashme. Midis 4 sistemeve MT të përgatitura nën këtë detyrë, 1 sistem PBSMT u përgatit për Marathin Hindi secili dhe 1 sistem NMT u zhvilluan për Marathin Hindi duke përdorur Byte PairEn-kodimin (BPE) në nënfjalë. Rezultatet tregojnë se arkitektura të ndryshme NMT mund të jetë një metodë efektive për zhvillimin e sistemeve MT për gjuhë të lidhura ngushtë. Sistemi ynë i NMT-së Hindi-Marathi u rendit i teti midis 14 ekipave që morën pjesë dhe sistemi ynë i NMT-së Marathi-Hindi u rendit i teti midis 11 ekipave që morën pjesë në këtë detyrë.', 'hr': 'Predloženje NUIG-Panlingua-KMI WMT 2020-u pokušava gurati državu umjetnosti u sličnom jezičkom prevodnom zadatku za Hindi Marathi jezički par. Kao dio tih napora, provodili smo niz eksperimenata kako bi riješili izazove za prevod između sličnih jezika. Između 4 MT sustava pripremljenih pod ovim zadatkom, 1 PBSMT sustava je pripremljen za Hindi Marathi svaki i 1 NMT sustav je razvijen za Hindi Marathi koristeći Byte PairEn-kodiranje (BPE) u podriječi. Rezultati pokazuju da bi različite arhitekture NMT mogle biti učinkovit metod razvoja MT sustava za bliski povezane jezike. Naš Hindi-Marathi NMT sustav je bio 8. redak među 14 tim koji su sudjelovali, a naš Marathi-Hindi NMT sustav je bio 8. redak među 11 tima koji su sudjelovali u tom zadatku.', 'am': 'የNUIG-Panlingua-KMI ወደ WMT 2020 በመስጠት ይሻላል፤ በተለያዩ ቋንቋ ትርጉም ትርጉም ስራ ለHindi ማርታቲ ቋንቋ ሁለት. As part of these efforts, we conducteda series of experiments to address the challenges for translation between similar languages.  ከዚህ ስራ በታች የተዘጋጁት 4 MT ስርዓቶች ውስጥ 1 PBSMT ስርዓቶች ለHindi ማራታይ እና 1 NMT ስርዓቶች በByte Pairen-coding (BPE) በመጠቀም ለHindi ማራታይ የተዘጋጁ ናቸው፡፡ ፍጥረቱም ልዩ የመዝገብ ግንኙነት ለቋንቋዎች አካባቢ የሆኑት የMT ስርዓቶች ለመፍጠር የሚችል ሥርዓት እንዲሆን ያሳያል፡፡ የኪንዲ-ማርታይ NMT ስርዓታችን በአካባቢው 14 ጭፍሮች መካከል ስምንተኛው ተካፈለ፤ ማራታይ-Hindi NMT ስርዓታችንም ስምንተኛው ተካፈለ፡፡', 'id': 'NUIG-Panlingua-KMI submission to WMT 2020 seeks to push the state-of-the-art in Similar Language Translation Task for Hindi Marathi language pair.  As part of these efforts, we conducteda series of experiments to address the challenges for translation between similar languages.  Di antara 4 sistem MT yang disediakan di bawah tugas ini, 1 sistem PBSMT yang disediakan untuk Hindi Marathi masing-masing dan 1 sistem NMT yang dikembangkan untuk Hindi Marathi menggunakan Byte PairEn-coding (BPE) menjadi subkata. Hasilnya menunjukkan bahwa arsitektur yang berbeda NMT bisa menjadi metode efektif untuk mengembangkan sistem MT untuk bahasa yang berhubungan dekat. Sistem NMT Hindi-Marathi kami ditandai ke-8 diantara 14 tim yang berpartisipasi dan sistem NMT Marathi-Hindi kami ditandai ke-8 diantara 11 tim yang berpartisipasi untuk tugas.', 'hy': 'Նյուգ-Պանլեզու-ՔՄI-ի ներկայացումը Հինդի մարաթի լեզվի զույգի նմանատիպ լեզվի թարգմանման հանձնարարություններում փորձում է շարժվել: Այս ջանքերի մեջ մենք մի շարք փորձեր կատարեցինք, որպեսզի լուծենք նման լեզուների միջև թարգմանման խնդիրները: Այս խնդրի ընթացքում պատրաստված 4 ՄԹ համակարգերից մեկը Հինդի մարաթի համար պատրաստված էր, յուրաքանչյուրը մեկը՝ Հինդի մարաթի համար պատրաստված էր, օգտագործելով Բայթ Պարենի կոդավորումը (Bpe) ենթաբառերի մեջ: Արդյունքները ցույց են տալիս, որ տարբեր ճարտարապետությունները NMT-ը կարող է լինել արդյունավետ մեթոդ MT համակարգերի զարգացման համար միմյանց հետ կապված լեզուների համար: Մեր Հինդի-Հինդի NMT համակարգը 8-րդ դասակարգված էր 14 թիմերի մեջ, իսկ մեր Մարաթի-Հինդի NMT համակարգը 8-րդ դասակարգված էր 11 թիմերի մեջ, ովքեր մասնակցել էին այս խնդիրը:', 'bn': 'এনইজি-পাঙ্লিঙ্গুয়া- কেএমএমটি ২০২০ এর প্রতি জমা দেয়ার চেষ্টা করেছে যে হিন্দি মারাথি ভাষার জোড়ার জন্য অনুবাদের ভাষার অনুবাদের কাজের র এই প্রচেষ্টার অংশ হিসেবে আমরা অনুবাদের মধ্যে অনুবাদের চ্যালেঞ্জের বিভিন্ন পরীক্ষা করেছি। এই কাজের অধীনে প্রস্তুত ৪টি এমটি সিস্টেমের মধ্যে ১ পিবিএসএমটি সিস্টেম হিন্দি মারাথির জন্য প্রস্তুত হয়েছে এবং ১ এনএমটি সিস্টেম বাইট পাইরেন কোডিং (বিপেই ফলাফল দেখা যাচ্ছে যে ভিন্ন কাঠামো এনএমটি নিকটবর্তী ভাষার জন্য এমটি সিস্টেম উন্নয়নের কার্যকর পদ্ধতি হতে পারে। আমাদের হিন্দি-মারাথি এনএমটি সিস্টেম ১৪টি দলের মধ্যে আটতম রান্না হয়েছিল যারা অংশগ্রহণ করেছিল এবং আমাদের মারাথি হিন্দি এনএমটি সিস্টেম কাজে', 'ca': "La presentació de NUIG-Panlingua-KMI a WMT 2020 busca empenyar l'última tasca de traducció de llenguatges semblants per a un parell de llenguatges de marati hindí. As part of these efforts, we conducteda series of experiments to address the challenges for translation between similar languages.  Entre els 4 sistemes MT preparats sota aquesta tasca, 1 sistema PBSMT es van preparar per a Hindi Marathi cada un i 1 sistema NMT es van desenvolupar per a Hindi Marathi fent servir Byte PairEn coding (BPE) en subparaules. Els resultats mostran que diferents arquitectures NMT podrien ser un mètode eficaç per desenvolupar sistemes MT per llengües estretament relacionades. El nostre sistema NMT hindi-hindi va ser al 8è lloc entre els 14 equips que van participar i el nostre sistema NMT hindi-hindi va ser al 8è lloc entre els 11 equips que van participar a la tasca.", 'az': 'NUIG-Panlingua-KMI WMT 2020-ə təsdiqlənməsi Hindi Marathi dil çiftəsinə bənzər dil çeviri işində məşğul olmaq istəyir. Bu çabaların bir parçası kimi, bənzər dillər arasındakı tercümə üçün çətinlikləri çəkmək üçün bəzi təminatlar etdik. Bu işin altında hazırlanmış 4 MT sistemlərindən 1 PBSMT sistemi Hindi Marathi üçün hazırlanmış və 1 NMT sistemi Hindi Marathi üçün Bajt PairEn-kodlaması (BPE) ilə altı sözlərə təşkil edilmişdir. NMT müxtəlif arhitektarların yaxın dillər üçün MT sistemlərini inkişaf etmək üçün faydalı bir yol olaraq göstərir. Bizim Hindi-Marathi NMT sistemimiz 14 dəstədə səf edildi və Marathi-Hindi NMT sistemimiz 11 dəstədə işə katıldı.', 'bs': 'Predloženje NUIG-Panlingua-KMI na WMT 2020 pokušava gurati državu umjetnosti u sličnom jezičkom prevodnom zadatku za parove hindijskog marathija. Kao dio tih napora, provodili smo niz eksperimenata da riješimo izazove za prevod između sličnih jezika. Između 4 MT sustava pripremljenih pod ovim zadatkom, 1 PBSMT sustava je pripremljen za Hindi Marathi svaki i 1 NMT sustav je razvijen za Hindi Marathi koristeći Byte PairEn-kodiranje (BPE) u podriječi. Rezultati pokazuju da bi različite arhitekture NMT mogle biti efikasni metod razvoja MT-sistema za bliski povezane jezike. Naš Hindi-Marathi NMT sistem je bio 8. red među 14 tima koji su sudjelovali, a naš Marathi-Hindi NMT sistem je bio 8. red među 11 tima koji su sudjelovali u tom zadatku.', 'cs': 'Podání NUIG-Panlingua-KMI do WMT 2020 usiluje o posílení nejmodernějších úloh překladu podobného jazyka pro jazykový pár Hindi Marathi. V rámci těchto snah jsme prováděli sérii experimentů s cílem řešit výzvy při překladu mezi podobnými jazyky. Mezi čtyřmi MT systémy připravenými v rámci tohoto úkolu byly připraveny 1 PBSMT systémy pro Hindi Marathi každý a 1 NMT systémy byly vyvinuty pro Hindi Marathi pomocí Byte PairEn kódování (BPE) do podslov. Výsledky ukazují, že různé architektury NMT by mohly být efektivní metodou pro vývoj MT systémů pro úzce příbuzné jazyky. Náš hindi-marathi NMT systém byl osmý mezi čtrnácti týmy, které se zúčastnily, a náš marathi-hindi NMT systém byl osmý mezi jedenácti týmy zúčastněnými pro tento úkol.', 'et': 'NUIG-Panlingua-KMI esitamine WMT 2020 eesmärk on tõsta kaasaegset sarnase keele tõlke ülesannet hindi marathi keelepaari jaoks. Nende jõupingutuste raames viisime läbi mitmeid katseid, et käsitleda sarnaste keelte vahelise tõlke probleeme. Selle ülesande raames valmistatud neljast MT süsteemist valmistati igaühele hindi marathi jaoks ette 1 PBSMT süsteem ja hindi marathi jaoks välja 1 NMT süsteem, kasutades Byte PairEn-kodeerimist (BPE) alamsõnadeks. Tulemused näitavad, et erinevad arhitektuurid NMT võiksid olla tõhus meetod MT süsteemide arendamiseks tihedalt seotud keeltele. Meie Hindi-Marathi NMT süsteem oli 14 osalenud meeskonna seas 8. kohal ja meie Marathi-Hindi NMT süsteem oli 8. kohal 11 ülesandes osalenud meeskonna seas.', 'fi': 'NUIG-Panlingua-KMI-hakemus WMT 2020 -ohjelmaan pyrkii edistämään hindi marathi -kieliparille samanlaisten kielten käännöstehtävän viimeisintä kehitystä. Osana näitä pyrkimyksiä toteutimme useita kokeiluja vastaaaksemme samankaltaisten kielten välisiin käännöksiin liittyviin haasteisiin. Tässä tehtävässä tehdyistä neljästä MT-järjestelmästä valmistettiin yksi PBSMT-järjestelmä hindi-marathille kullekin ja yksi NMT-järjestelmä hindi-marathille kehitettiin Byte PairEn-koodauksella (BPE). Tulokset osoittavat, että eri arkkitehtuurit NMT voisivat olla tehokas tapa kehittää MT-järjestelmiä läheisesti toisiinsa liittyville kielille. Hindi-Marathi NMT -järjestelmämme sijoittui kahdeksanneksi 14 joukkueen joukossa ja Marathi-Hindi NMT -järjestelmämme sijoittui kahdeksanneksi tehtävään osallistuneista 11 tiimistä.', 'jv': 'NUIG Sampeyan karo perbudhakan iki, kita dadi sak ilang akeh operasi kanggo ngakses nggambar tarjamah ning langa sing luwih. Genjer-genjer 4 MT sistem sing wis ditambah nggunakake iki, sistem PGSMT 1 wis digasai kanggo masalah barang-barang mbut 1 NMT bisa ditambah kanggo masalah batir Marati nggawe barang-pakan (BBE). Rejalaké wong liyane karo akeh-akeh sing sampeyan NMT iso ngubah layang kanggo nggawe sistem MT kanggo langgambaran sing wis ana. Kita tatak-Marati NMT sistem sing wis rampun asat kanggo wong liyane 14 sing katêpakan karo sistèm Marati-Hong-NMT kuwi wis rampun asat karo 11 sing katêpakan karo pawartos.', 'ha': "@ item: inmenu Kama wani abu daga wannan aikinsa, mun samun jarrabi masu yawa dõmin mu yi addu'a ga masu motsari wa fassarar a tsakanin harshen daban. Bayan wasu na'urar MT da aka ƙayyade shi a lokacin wannan aikin, an yi amfani da Byte Pairen-coding (BLE) na buƙata 1 PBSMT na'urar wa matsayin Hindu Marati kodi kodi kodi kowace. The results show that different architectures NMT could be an effective method for developing MT systems for closely related languages.  SisteminMu na Hidi-Marati NMT na ranar da 8 daga jama'a 14 waɗanda suka yi shirin, kuma tsarin Marati-Hidi NMT ya ranar da 8 daga jama'a 11 waɗanda suka yi shiyya ga aikin.", 'he': 'השימוש של NUIG-Panlingua-KMI ל-WMT 2020 מנסה לדחוף את המצב המאודף במשימת התרגום לשפה דומה לזוג שפת האינדי מרתי. כחלק מהמאמצים האלה, ביצענו סדרה של ניסויים כדי להתמודד עם האתגרים לתרגום בין שפות דומות. בין 4 מערכות MT מוכנות תחת המשימה הזו, 1 מערכת PBSMT הוכנה למראתי הינדי כל מערכת NMT הופתחה למראתי הינדי בשימוש בקוד בייט פארן (BPE) לתת מילים. התוצאות מראות שארכיטקטורות שונות NMT יכולות להיות שיטה יעילה לפיתוח מערכות MT לשפות קרובות. מערכת NMT הינדי-הינדי שלנו הוצבה ב-8 בין 14 הקבוצות שהשתתפו והמערכת NMT הינדי-הינדי שלנו הוצבה ב-8 בין 11 הקבוצות השתתפו במשימה.', 'sk': 'Predložitev NUIG-Panlingua-KMI na WMT 2020 želi spodbuditi najsodobnejšo nalogo prevajanja podobnih jezikov za jezikovni par hindijskega maratha. V okviru teh prizadevanj smo izvedli vrsto eksperimentov za reševanje izzivov prevajanja med podobnimi jeziki. Med štirimi sistemi MT, pripravljenimi v okviru te naloge, je bil za Hindi Marathi pripravljen 1 sistem PBSMT, za Hindi Marathi pa je bil razvit 1 sistem NMT z uporabo Byte PairEn-kodiranja (BPE) v podbesedah. Rezultati kažejo, da bi različne arhitekture NMT lahko bile učinkovita metoda za razvoj MT sistemov za tesno sorodne jezike. Naš Hindi-Marathi NMT sistem se je uvrstil na 8. mesto med 14 ekipami, ki so sodelovale pri nalogi, naš Marathi-Hindi NMT sistem pa je bil 8. mesto med 11 ekipami, ki so sodelovale pri nalogi.', 'bo': 'NUIG-Panlingua-KMI WMT 2020 ཡིས་གནས་སྟངས་དང་འདྲ་བའི་སྐད་ཡིག་གནས་སྟངས་དང་མཉམ་དུ་སྤྲོད་ཀྱི་ཡོད། བྱ་ཚུལ་འདི་དག་གི་ཆ་ཤས་གཅིག་གི་ནང་དུ་ང་ཚོས་སྐྱེས་པའི་སྐད་རིགས་དབར་བཟོས་བའི་དཀའ་ངལ བྱ་འགུལ་འདིའི་འོག་ཏུ་MT མ་ལག་ཆ་འདིའི་ནང་དུ་གྲ་སྒྲིག་པ་ལས་ PBSMT་རིམ་པ་གཅིག་གིས་རྒྱ་གར་Marathi་རེ་རེའི་སྒྲིག་ཆ་གཅིག་དང་NMT་རིམ་པ་དེ་རྣམས་ལ་ཡར་བསྐྲ དབྱིབས་འབྲས་བྱས་ན། NMT བཟོ་སྒྲིག་འགོད་འདི་མ་འདྲ་བའི་སྐད་ཡིག་ཆ་དང་མཐུན་པ་མཚོན་པའི་འགྱུར་བ་ཞིག་ཡིན་པ ང་ཚོའི་རྒྱ་ནག་མ་རེ་ཤི་ཡི་(Hindi-Marathi NMT)མ་ལག་གི་ཆེད་དུ་འགྲོ་བཞིན་པའི་གནད་མེད་སྤྱི་ཚོགས་ཀྱི་ཕྱོགས་དང་། ང་ཚོའི་རེ་ཤི་ཡི་(Marathi-Hindi NMT)མ་ལག་གི་'}
{'en': 'Document Level NMT of Low-Resource Languages with Backtranslation', 'ar': 'مستوى المستند NMT للغات منخفضة الموارد مع Backtranslation', 'pt': 'NMT de nível de documento de idiomas de poucos recursos com retrotradução', 'fr': 'NMT au niveau du document pour les langues à faibles ressources avec rétrotraduction', 'es': 'NMT a nivel de documento de idiomas de bajos recursos con traducción inversa', 'ja': 'バックトランスレーションを伴う低リソース言語の文書レベルNMT', 'ru': 'Уровень документа НБ малоресурсных языков с обратным переводом', 'hi': 'बैकट्रांसलेशन के साथ कम-संसाधन भाषाओं का दस्तावेज़ स्तर NMT', 'zh': '有反译低资源语者文档级 NMT', 'ga': 'Leibhéal Doiciméad NMT na dTeangacha Íseal-Acmhainne le haisaistriúchán', 'ka': 'Comment', 'el': 'Επίπεδο εγγράφου γλωσσών χαμηλής περιεκτικότητας σε πόρους με αντίστροφη μετάφραση', 'hu': 'Alacsony erőforrású nyelvek dokumentumszintű NMT háttérfordítással', 'it': 'NMT a livello di documento di lingue a basso contenuto di risorse con backtranslation', 'lt': 'Document Level NMT of Low-Resource Languages with Backtranslation', 'kk': 'Comment', 'mk': 'Ниво на документот NMT на јазиците со ниски ресурси со Backtranslation', 'ms': 'translation', 'mt': 'Document Level NMT of Low-Resource Languages with Backtranslation', 'mn': 'Document Level NMT of Low-Resource Languages with Backtranslation', 'ml': '@ info', 'no': 'Comment', 'sr': 'Comment', 'pl': 'Poziom dokumentu NMT języków niskich zasobów z tłumaczeniem backtranslation', 'ro': 'NMT la nivel de document de limbi cu resurse reduse cu traducere în spate', 'so': 'Document Level NMT of Low-Resource Languages with Backtranslation', 'si': 'Backtranslation', 'sv': 'NMT på dokumentnivå för språk med låg resurs med Backtranslation', 'ta': '@ info: whatsthis', 'ur': 'Name', 'uz': 'translation', 'vi': 'Tài liệu cấp NMT của ngôn ngữ ít tài nguyên có bản sao', 'bg': 'Ниво на документа НМТ на нискоресурсни езици с обратен превод', 'da': 'NMT på dokumentniveau af lav ressource sprog med baggrundsoversættelse', 'nl': 'Document Level NMT van Low Resource Talen met Backtranslation', 'hr': 'Comment', 'de': 'Document Level NMT von ressourcenarmen Sprachen mit Backtranslation', 'id': 'Document Level NMT of Low-Resource Languages with Backtranslation', 'fa': 'Name', 'ko': '번역이 불가능한 저자원 언어가 포함된 문서 수준 NMT', 'af': 'Name', 'sw': 'translation', 'tr': '_Senedler', 'am': 'ሰነድ ደረጃ NMT of Low-Resource Languages with Backtranslation', 'hy': 'Comment', 'sq': 'Niveli i dokumentit NMT i gjuhëve me burime të ulta me Backtranslation', 'bn': 'ব্যাক- অনুবাদ সহযোগে নথি স্তর NMT', 'bs': 'Nivo dokumenta NMT jezika niskog resursa sa Backtranslation', 'cs': 'Úroveň dokumentu NMT jazyků s nízkými zdroji s backtranslationem', 'fi': 'Asiakirjatason NMT vähäresurssisten kielten taustakäännöksellä', 'az': 'Backtranslation', 'ca': 'Nivel de documents NMT de llengües de baix recursos amb Backtranslation', 'et': 'Dokumenditaseme NMT madala ressursiga keelte tagasitõlkega', 'ha': 'translation', 'jv': 'translation', 'he': 'רמת המסמך NMT של שפות משאבים נמוכות עם Backtranslation', 'sk': 'Nivo dokumenta NMT jezikov z nizkimi viri z nazaj prevajanjem', 'bo': 'རྒྱབ་སྐྱོར་ཡོད་པའི་སྐད་རིགས་ཀྱི་ཡིག་ཆའི་གནས་རིམ NMT'}
{'en': 'This paper describes our system submission to WMT20 shared task on similar language translation. We examined the use of documentlevel neural machine translation (NMT) systems for low-resource, similar language pair MarathiHindi. Our system is an extension of state-of-the-art Transformer architecture with hierarchical attention networks to incorporate contextual information. Since, NMT requires large amount of parallel data which is not available for this task, our approach is focused on utilizing monolingual data with back translation to train our models. Our experiments reveal that document-level NMT can be a reasonable alternative to sentence-level NMT for improving translation quality of low resourced languages even when used with synthetic data.', 'ar': 'تصف هذه الورقة إرسال نظامنا إلى مهمة WMT20 المشتركة حول ترجمة لغة مماثلة. قمنا بفحص استخدام أنظمة الترجمة الآلية العصبية (NMT) على مستوى الوثائق للزوج اللغوي المتشابه منخفض الموارد Marathi − Hindi. نظامنا هو امتداد لأحدث هندسة المحولات مع شبكات اهتمام هرمية لدمج المعلومات السياقية. نظرًا لأن NMT يتطلب قدرًا كبيرًا من البيانات المتوازية غير المتوفرة لهذه المهمة ، يركز نهجنا على استخدام البيانات أحادية اللغة مع الترجمة الخلفية لتدريب نماذجنا. تكشف تجاربنا أن NMT على مستوى المستند يمكن أن يكون بديلاً معقولاً لـ NMT على مستوى الجملة لتحسين جودة الترجمة للغات منخفضة الموارد حتى عند استخدامها مع البيانات التركيبية.', 'es': 'Este documento describe el envío de nuestro sistema a la tarea compartida de WMT20 sobre la traducción de idiomas similares. Examinamos el uso de sistemas de traducción automática neuronal (NMT) a nivel de documento para una combinación de idiomas similar y de pocos recursos, marathi e hindi. Nuestro sistema es una extensión de la arquitectura Transformer de última generación con redes de atención jerárquicas para incorporar información contextual. Dado que NMT requiere una gran cantidad de datos paralelos que no están disponibles para esta tarea, nuestro enfoque se centra en utilizar datos monolingües con traducción inversa para entrenar nuestros modelos. Nuestros experimentos revelan que la NMT a nivel de documento puede ser una alternativa razonable a la NMT a nivel de oración para mejorar la calidad de la traducción de idiomas de bajos recursos, incluso cuando se usa con datos sintéticos.', 'fr': "Ce document décrit la soumission de notre système à la tâche partagée WMT20 sur la traduction dans une langue similaire. Nous avons examiné l'utilisation de systèmes de traduction automatique neuronale (NMT) au niveau du document pour une paire de langues similaire à faible ressource marathi−hindi. Notre système est une extension de l'architecture de pointe des transformateurs avec des réseaux d'attention hiérarchiques pour intégrer des informations contextuelles. Étant donné que la NMT nécessite une grande quantité de données parallèles qui ne sont pas disponibles pour cette tâche, notre approche est axée sur l'utilisation de données monolingues avec rétro-traduction pour entraîner nos modèles. Nos expériences révèlent que la NMT au niveau du document peut constituer une alternative raisonnable à la NMT au niveau de la phrase pour améliorer la qualité de la traduction des langues à faibles ressources, même lorsqu'elles sont utilisées avec des données synthétiques.", 'pt': 'Este artigo descreve o envio do nosso sistema para a tarefa compartilhada do WMT20 em tradução de idioma semelhante. Examinamos o uso de sistemas de tradução automática neural em nível de documento (NMT) para pares de idiomas semelhantes de poucos recursos, Marathi-Hindi. Nosso sistema é uma extensão da arquitetura Transformer de última geração com redes de atenção hierárquicas para incorporar informações contextuais. Como o NMT requer uma grande quantidade de dados paralelos que não estão disponíveis para esta tarefa, nossa abordagem está focada na utilização de dados monolíngues com tradução reversa para treinar nossos modelos. Nossos experimentos revelam que a NMT em nível de documento pode ser uma alternativa razoável à NMT em nível de sentença para melhorar a qualidade da tradução de idiomas com poucos recursos, mesmo quando usada com dados sintéticos.', 'ja': '本稿では、同様の言語翻訳に関するWMT 20共有タスクへのシステムサブミッションについて説明します。私たちは、文書レベルのニューラル機械翻訳（ NMT ）システムを低資源、類似の言語ペアであるマラーティー語-ヒンディー語に使用することを検討しました。当社のシステムは、最先端のトランスフォーマーアーキテクチャの拡張であり、コンテキスト情報を組み込むための階層的な注意喚起ネットワークを備えています。NMTは、このタスクでは利用できない大量の並列データを必要とするため、私たちのアプローチは、モデルをトレーニングするためにバック翻訳付きのモノリンガルデータを利用することに焦点を当てています。私たちの実験は、合成データと共に使用される場合でも、低リソース言語の翻訳品質を向上させるために、文書レベルのNMTが文レベルのNMTの合理的な代替になる可能性があることを明らかにします。', 'zh': '本文引WMT20系统类言译共之。 臣等考文档级神经机器翻译(NMT)系于低资源,似语对马拉地语 - 印地语中用之。 先进之Transformer架构,重关网络,以整合上下文信息。 NMT 不可并行,故吾法侧重于因其反易单语数以习之。 臣等实验明,文档级NMT可为句级NMT理代方案,虽与合成数据并用,亦可以崇低资源言之译质。', 'hi': 'यह पेपर समान भाषा अनुवाद पर WMT20 साझा कार्य के लिए हमारे सिस्टम सबमिशन का वर्णन करता है। हमने कम संसाधन, समान भाषा जोड़ी मराठी-हिंदी के लिए दस्तावेज़ स्तरीय तंत्रिका मशीन अनुवाद (एनएमटी) प्रणालियों के उपयोग की जांच की। हमारी प्रणाली प्रासंगिक जानकारी को शामिल करने के लिए पदानुक्रमित ध्यान नेटवर्क के साथ अत्याधुनिक ट्रांसफॉर्मर आर्किटेक्चर का एक विस्तार है। चूंकि, एनएमटी को बड़ी मात्रा में समानांतर डेटा की आवश्यकता होती है जो इस कार्य के लिए उपलब्ध नहीं है, इसलिए हमारा दृष्टिकोण हमारे मॉडल को प्रशिक्षित करने के लिए बैक ट्रांसलेशन के साथ मोनोलिंगुअल डेटा का उपयोग करने पर केंद्रित है। हमारे प्रयोगों से पता चलता है कि दस्तावेज़-स्तर एनएमटी सिंथेटिक डेटा के साथ उपयोग किए जाने पर भी कम संसाधन वाली भाषाओं की अनुवाद गुणवत्ता में सुधार के लिए वाक्य-स्तरीय एनएमटी का एक उचित विकल्प हो सकता है।', 'ru': 'В этой статье описывается наша система представления WMT20 общей задачи на аналогичном переводе языка. Рассмотрено использование систем нейронного машинного перевода (НМП) документального уровня для малоресурсной, похожей языковой пары маратхи-хинди. Наша система представляет собой расширение современной архитектуры трансформатора с сетями иерархического внимания для включения контекстной информации. Поскольку NMT требует большого количества параллельных данных, которые недоступны для этой задачи, наш подход ориентирован на использование одноязычных данных с обратным переводом для обучения наших моделей. Наши эксперименты показывают, что NMT на уровне документа может быть разумной альтернативой NMT на уровне предложения для улучшения качества перевода языков с низким уровнем ресурсов даже при использовании с синтетическими данными.', 'ga': 'Déanann an páipéar seo cur síos ar ár n-aighneacht chórais chuig tasc comhroinnte WMT20 ar aistriúchán teanga comhchosúil. Scrúdaíomar an úsáid a bhaintear as córais néaraistriúcháin meaisín (NMT) ar leibhéal doiciméad le haghaidh Marathi–Hiondúis péire teangacha íseal-acmhainne. Is síneadh é ár gcóras ar ailtireacht Claochladáin den scoth le líonraí airde ordlathacha chun faisnéis chomhthéacsúil a ionchorprú. Ós rud é go bhfuil méid mór sonraí comhthreomhara de dhíth ar NMT nach bhfuil ar fáil don tasc seo, tá ár gcur chuige dírithe ar úsáid a bhaint as sonraí aonteangacha le ais-aistriúchán chun ár múnlaí a oiliúint. Léiríonn ár dturgnaimh gur féidir le NMT ar leibhéal doiciméad a bheith ina rogha réasúnta eile seachas NMT ag leibhéal abairte chun cáilíocht aistriúcháin teangacha íseal-acmhainní a fheabhsú fiú nuair a úsáidtear iad le sonraí sintéiseacha.', 'ka': 'ეს წიგნი ჩვენი სისტემის შემდეგ WMT20 გაყოფილი რაოდენობას განსხვავებულ ენის გაგრძელებაზე დააწერა. ჩვენ შევხედავთ დოკუმენტის დოკუმენტის ნეიროლური მანქანის გადაწყვეტილების (NMT) სისტემის გამოყენებას მარტი-ჰინდი, როგორც მარტი-ჰინდი ენის ჩვენი სისტემა არის კონტექსტიური ინფორმაციის სტრანსტრუქტურის აქტიქტიქტურის გაფართება, რომელიც იერაქტიური ინფორმაციის ქსელებით. NMT უნდა გავაკეთოთ დიდი პარალელური მონაცემები, რომელიც ამ დავალებისთვის არ არის ხელხი, ჩვენი მონაცემები მონოლენგური მონაცემების გამოყენებაზე, რომელიც ჩვენი მოდელების ჩვენი ექსპერიმენტები აღმოჩნენ, რომ დოკუმენტის დოკუმენტის NMT შეუძლია იყოს პარამეტური ალტენტიფიკაცია NMT დოკუმენტის განახლებისთვის, როგორც სინტეტიკური მონაცემე', 'el': 'Αυτή η εργασία περιγράφει την υποβολή του συστήματός μας στο κοινό έργο WMT20 σχετικά με τη μετάφραση παρόμοιων γλωσσών. Εξετάσαμε τη χρήση συστημάτων νευρολογικής μηχανικής μετάφρασης (NMT) σε επίπεδο εγγράφων για παρόμοιο γλωσσικό ζεύγος Μαράθι-Χίντι με χαμηλούς πόρους. Το σύστημά μας είναι μια επέκταση της τελευταίας τεχνολογίας αρχιτεκτονικής μετασχηματιστή με ιεραρχικά δίκτυα προσοχής για την ενσωμάτωση πληροφοριών περιβάλλοντος. Δεδομένου ότι η NMT απαιτεί μεγάλη ποσότητα παράλληλων δεδομένων που δεν είναι διαθέσιμα για αυτό το έργο, η προσέγγισή μας επικεντρώνεται στη χρήση μονογλωσσικών δεδομένων με μεταγραφή πίσω για την εκπαίδευση των μοντέλων μας. Τα πειράματά μας αποκαλύπτουν ότι το NMT σε επίπεδο εγγράφων μπορεί να αποτελέσει μια λογική εναλλακτική λύση στο NMT σε επίπεδο φράσεων για τη βελτίωση της ποιότητας της μετάφρασης γλωσσών με χαμηλούς πόρους ακόμη και όταν χρησιμοποιείται με συνθετικά δεδομένα.', 'hu': 'Ez a tanulmány ismerteti a WMT20 hasonló nyelvű fordítással kapcsolatos megosztott feladatunkat. Dokumentumszintű neurális gépi fordító (NMT) rendszerek használatát vizsgáltuk alacsony erőforrású, hasonló marathi-hindi nyelvpárban. Rendszerünk a legkorszerűbb Transformer architektúra kiterjesztése hierarchikus figyelemhálózatokkal, amelyek kontextuális információkat foglalnak magukba. Mivel az NMT nagy mennyiségű párhuzamos adatot igényel, amely nem áll rendelkezésre ehhez a feladathoz, megközelítésünk arra összpontosít, hogy egynyelvű adatokat használjunk visszafordítással modelleink képzéséhez. Kísérleteink azt mutatják, hogy a dokumentumszintű NMT ésszerű alternatívája lehet a mondatszintű NMT-nek, hogy javítsa az alacsony forrású nyelvek fordítási minőségét még szintetikus adatokkal is.', 'it': "Questo articolo descrive l'invio del nostro sistema al compito condiviso WMT20 sulla traduzione di lingue simili. Abbiamo esaminato l'uso di sistemi di traduzione automatica neurale (NMT) a livello documentale per coppie linguistiche simili Marathi-Hindi a basso contenuto di risorse. Il nostro sistema è un'estensione dell'architettura Transformer all'avanguardia con reti di attenzione gerarchiche per incorporare informazioni contestuali. Poiché NMT richiede una grande quantità di dati paralleli che non sono disponibili per questo compito, il nostro approccio è focalizzato sull'utilizzo di dati monolingue con traduzione posteriore per formare i nostri modelli. I nostri esperimenti rivelano che l'NMT a livello di documento può essere un'alternativa ragionevole all'NMT a livello di frase per migliorare la qualità della traduzione di lingue a basso contenuto di risorse anche quando utilizzato con dati sintetici.", 'kk': 'Бұл қағаз біздің жүйеңізді WMT20 тілді аудару үшін ортақ тапсырмаға жіберуді анықтайды. Біз құжат деңгейіндегі невралдық машинаны аудару (NMT) жүйелерін төмен ресурстар үшін, ұқсас тілдердің екі Marathi- Hindi қолдануын тексердік. Біздің жүйеміз мезгілдік мәліметті біріктіру үшін иерархиялық түрлендіру архитектурасының кеңейтуі. NMT бұл тапсырма үшін қол жеткізбеген параллель деректер үлкен көп санды талап етеді, біздің тәсіліміз монолингі деректерді модельді аудару үшін модельді аудару үшін қолданатын. Біздің тәжірибеміз NMT құжаттың деңгейі синтетикалық деректермен қолданылған тілдердің аудармасының сапатын жақсарту үшін мәселелер деңгейіндегі NMT- деңгейіне қарапайым альтернативі', 'mk': 'Овој весник го опишува нашето пренесување на системот на WMT20 споделена задача за сличен превод на јазик. Го проверивме употребата на системите на документарно ниво на нервен машински превод (НМТ) за системи со ниски ресурси, слични јазички пар Марати-Хинди. Нашиот систем е проширување на најсовремената трансформна архитектура со хиерархични мрежи на внимание за вклучување на контекстни информации. Бидејќи НМТ бара голема количина паралелни податоци кои не се достапни за оваа задача, нашиот пристап се фокусира на употребата на монојазични податоци со превод назад за обука на нашите модели. Нашите експерименти откриваат дека НМТ на ниво на документ може да биде разумна алтернатива на НМТ на ниво на реченици за подобрување на квалитетот на преводот на ниски ресурси јазици дури и кога се користат со синтетички податоци.', 'ms': 'This paper describes our system submission to WMT20 shared task on similar language translation.  We examined the use of documentlevel neural machine translation (NMT) systems for low-resource, similar language pair Marathi-Hindi.  Sistem kita adalah sambungan arkitektur Transformer yang terbaik dengan rangkaian perhatian hierarkis untuk memasukkan maklumat kontekstual. Since, NMT requires large amount of parallel data which is not available for this task, our approach is focused on utilizing monolingual data with back translation to train our models.  Our experiments reveal that document-level NMT can be a reasonable alternative to sentence-level NMT for improving translation quality of low resourced languages even when used with synthetic data.', 'lt': 'Šiame dokumente apibūdinamas mūsų sistemos pateikimas WMT20 bendrai užduotis panašaus kalbų vertimo srityje. Mes išnagrinėjome dokumentų lygmens nervinių mašinų vertimo (NMT) sistemų naudojimą mažai išteklių turinčioms panašioms kalbų poroms Maratis-Hindi. Mūsų sistema yra naujausios Transformos architektūros išplėtimas su hierarchiniais dėmesio tinklais, kad būtų įtraukta kontekstinė informacija. Kadangi NMT reikalauja didelio lygiagrečių duomenų, kurių šioje užduotyje nėra, mūsų požiūris yra sutelktas į vienkalbinių duomenų naudojimą su grįžtamuoju vertimu mokymui mūsų modeliams. Mūsų eksperimentai atskleidžia, kad dokumentų lygmens NMT gali būti pagrįsta alternatyva, palyginti su sakinių lygmeniu NMT, siekiant pagerinti mažai išteklių turinčių kalbų vertimo kokybę, net jei ji naudojama su sintetiniais duomenimis.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ സിസ്റ്റം WMT20 പങ്കെടുത്ത ജോലിയെ വിവരിച്ചുകൊടുക്കുന്നു. ഇതുപോലെ ഭാഷയി കുറഞ്ഞ വിഭവങ്ങള്\u200dക്ക്, പോലുള്ള ഭാഷ ജോടി മാരാതി-ഹിന്ദിയ്ക്കുള്ള രേഖന നിലയിലെ ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷകളുടെ ഉപയോഗം ഞങ് നമ്മുടെ സിസ്റ്റത്തിന്റെ സ്ഥാനത്തിന്റെ രാജ്യത്തെ വികസിപ്പിക്കുന്ന സ്ഥാനത്തിന്റെ ഒരു വിശാലമാണ് ഹിയെരാര്\u200dക്കി ഈ ജോലിയ്ക്ക് ലഭ്യമല്ലാത്ത പാരാളല്\u200d ഡേറ്റാ ആവശ്യമുണ്ട്, നമ്മുടെ പ്രായോഗ്യം മോണോളില്\u200d ഭാഷ വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നതിനാല്\u200d നമ്മു നമ്മുടെ പരീക്ഷണങ്ങള്\u200d വെളിപ്പെടുത്തിയിരിക്കുന്നു എന്\u200dഎംടി വാക്ക് നില NMT വ്യവസ്ഥയ്ക്ക് വേണ്ടിയുള്ള മാറ്റമാകുന്നു എന്ന്.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni tas-sistema tagħna lill-WMT20 kompitu komuni dwar traduzzjoni tal-lingwi simili. We examined the use of documentlevel neural machine translation (NMT) systems for low-resource, similar language pair Marathi-Hindi.  Is-sistema tagħna hija estensjoni tal-arkitettura tat-Trasformer l-aktar avvanzata b’netwerks ta’ attenzjoni ġerarkika biex tinkorpora informazzjoni kuntestwali. Minħabba li l-NMT teħtieġ ammont kbir ta’ dejta parallela li mhijiex disponibbli għal dan il-kompitu, l-approċċ tagħna huwa ffukat fuq l-użu ta’ dejta monolingwi bi traduzzjoni lura biex jitħarrġu l-mudelli tagħna. L-esperimenti tagħna juru li l-NMT fil-livell tad-dokument jista’ jkun alternattiva raġonevoli għall-NMT fil-livell tas-sentenzi għat-titjib tal-kwalità tat-traduzzjoni ta’ lingwi b’riżorsi baxxi anke meta użati ma’ dejta sintetika.', 'mn': 'Энэ цаас бидний системийн WMT20-д төстэй хэл хөрөнгө оруулах үйлдлийг тайлбарладаг. Бид баримтын түвшинд мэдрэлийн машины хөрөнгө оруулалт (NMT) бага нөөц, төстэй хэл хоёр Марати-Хинди гэх мэт системүүдийг судалсан. Бидний систем нөхцөл байдлын түвшин боловсруулагч архитектурын нэмэгдүүлэлт юм. Яагаад гэвэл NMT-д энэ ажил дээр байхгүй олон параллел өгөгдлийг хэрэглэдэг бөгөөд бидний арга хэлний өгөгдлийг буцаад орчуулахын тулд нэг хэлний өгөгдлийг ашиглах зорилготой. Бидний туршилтууд NMT-ийн баримт түвшинд өгүүлбэр-түвшинд NMT-ийн хөгжлийн хэлний хөгжлийн чанарыг сайжруулах боломжтой сонголт байж болно гэдгийг харуулдаг.', 'pl': 'Niniejszy artykuł opisuje nasz system zgłaszania do WMT20 wspólnego zadania dotyczącego tłumaczenia podobnego języka. Badaliśmy wykorzystanie systemów tłumaczenia neuronowego maszynowego (NMT) na poziomie dokumentu dla mało zasobów, podobnej pary językowej Marathi-Hindi. Nasz system jest rozszerzeniem najnowocześniejszej architektury Transformera o hierarchiczne sieci uwagi w celu uwzględnienia informacji kontekstowych. Ponieważ NMT wymaga dużej ilości danych równoległych, które nie są dostępne do tego zadania, nasze podejście koncentruje się na wykorzystaniu danych jednojęzycznych z tłumaczeniem wstecznym do treningu naszych modeli. Nasze eksperymenty ujawniają, że NMT na poziomie dokumentów może być rozsądną alternatywą dla NMT na poziomie zdań dla poprawy jakości tłumaczenia języków o niskich zasobach nawet w przypadku wykorzystania danych syntetycznych.', 'ro': 'Această lucrare descrie transmiterea sistemului nostru la activitatea partajată WMT20 privind traducerea limbilor similare. Am examinat utilizarea sistemelor de traducere automată neurală la nivel de document (NMT) pentru perechea de limbi similare Marathi-Hindi cu resurse reduse. Sistemul nostru este o extensie a arhitecturii Transformer de ultimă generație cu rețele ierarhice de atenție pentru a încorpora informații contextuale. Deoarece NMT necesită o cantitate mare de date paralele care nu sunt disponibile pentru această sarcină, abordarea noastră se concentrează pe utilizarea datelor monolingve cu traducere înapoi pentru a instrui modelele noastre. Experimentele noastre arată că NMT la nivel de document poate fi o alternativă rezonabilă la NMT la nivel de propoziții pentru îmbunătățirea calității traducerii limbilor cu resurse reduse chiar și atunci când sunt utilizate cu date sintetice.', 'so': 'Warqadan wuxuu ku qoraa in nidaamka uu u soo dhiibo shaqada loo qaybsaday WMT20 oo ku saabsan turjumista luuqada oo isku mid ah. Waan baaritay isticmaalka tarjumaadda qoraalka neurada (NMT) nidaamka hoos-resource, noocyo isku mid ah Marathi-Hindi. nidaamkayagu waa mid dheeraad ah dhismaha turjumista ee dowladda-sanada, kaas oo leh shabakado hierarchical focus ah si ay u soo geliyaan macluumaad soo socda. Tan darteed, NMT waxay u baahan tahay macluumaad badan oo is-barbar ah oo aan u helin shaqadan, dhaqdhaqaalahayagana waxaa ku focus ah isticmaalaya isticmaalka macluumaadka afka noocyada ah oo ku qoran turjumista dib si ay u tababarido modellkayaga. Imtixaanadayada ayaa muujin kara in heerka dukumentiga ee NMT uu noqon karo mid aad u bedelan karto heerka maxkamada NMT si ay u kordhiso turjumaadda qiimaha luuqadaha hoose ee lagu isticmaalo xittaa marka lagu isticmaalo macluumaadka synthetic.', 'sr': 'Ovaj papir opisuje naše podnošenje sistema WMT20 zajedničkom zadatku o sličnom prevodu jezika. Pregledali smo korištenje sustava neuralnog prevoda (NMT) za niske resurse, slični jezički par Marathi-Hindi. Naš sistem je produženje državne arhitekture transformera umetnosti sa hijerarhičkim mrežama pažnje za uključenje kontekstnih informacija. Pošto NMT zahteva veliku količinu paralelnih podataka koji nisu dostupni za ovaj zadatak, naš pristup je fokusiran na upotrebu monojezičkih podataka sa povratnim prevodom kako bi obučili naše modele. Naši eksperimenti otkrivaju da NMT-nivo dokumenta može biti razumna alternativa NMT-nivou rečenica za poboljšanje kvalitete prevođenja niskih izvornih jezika čak i kad se koristi sintetičkim podacima.', 'sv': 'Denna uppsats beskriver vår systeminlämning till WMT20 delade uppgift om liknande språköversättning. Vi undersökte användningen av dokumentnivå neurala maskinöversättningssystem (NMT) för lågresurs, liknande språkpar marathi-hindi. Vårt system är en förlängning av state-of-the-art Transformer arkitektur med hierarkiska uppmärksamhetsnätverk för att införliva kontextuell information. Eftersom NMT kräver stora mängder parallella data som inte finns tillgängliga för denna uppgift, fokuserar vårt tillvägagångssätt på att använda enspråkiga data med backöversättning för att träna våra modeller. Våra experiment visar att NMT på dokumentnivå kan vara ett rimligt alternativ till NMT på meningsnivå för att förbättra översättningskvaliteten på lågresursspråk även när de används med syntetiska data.', 'ta': '@ info @ info எங்கள் அமைப்பு தற்காலிக தகவல்களை சேர்க்க நிலையில் மாற்றும் கட்டுப்பாட்டின் நிலையை நீட்டுதலாகும். இந்த செயலுக்கு கிடைக்கவில்லை என்எம்டி பெரிய இணைப்பு தகவல் தேவைப்படுகிறது, எங்கள் முறைமையை மாதிரி மொழி மொழிபெயர்ப்பு தகவல் பயன்படுத் எங்கள் பரிசோதனைகள் என்னவென்றால் ஆவண- மட்டத்தில் NMT வாக்கியத்திற்கு ஒரு விருப்பத்தேர்வாக இருக்க முடியும் என்பது குறைந்த மூலங்களின்', 'si': 'මේ පැත්තේ WMT20 වගේ භාෂාව භාවිතයේ සමාන විදිහට අපේ පද්ධතිය පිළිගන්න විස්තර කරනවා. අපි පරීක්ෂා කරලා තොරතුරු ස්ථානයේ න්\u200dයූරාල් මැෂින් පද්ධතිය (NMT) පද්ධතිය අඩු ප්\u200dරධානය, වගේ භාෂාවක අපේ පද්ධතිය තමයි පද්ධතිය සම්බන්ධ තොරතුරු සම්බන්ධ වෙනුවෙන් ස්ථානයේ විස්තර විස්තර විස්තර විස්තර වි ඉතින්, NMT ට මේ වැඩ සමාන්\u200dය දත්ත අවශ්\u200dය වෙනවා මේ වැඩේ වෙනුවෙන් නොපුළුවන් ලොකු ප්\u200dරමාණයක් තියෙනවා, අපේ ප්\u200dරමාණය පුළුව අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට වාර්තාව NMT වලට වාර්තාවක් වෙන්න පුළුවන් විදිහට වාර්තාවක් වෙන්න පුළුවන් විදිහ', 'ur': 'یہ کاغذ ویسی زبان ترجمہ پر ہماری سیسٹم کے مطابق WMT20 کے مشترک کام کی توصیف کرتا ہے. ہم نے دکھانے والی سطح نیورل ماشین ترجمہ (NMT) سیستموں کی استعمال کی تحقیق کی، جیسی زبان جوڑی Marathi-Hindi کے لئے۔ ہمارا سیستم آرت ترنسفورر معماری کی تقسیم ہے کہ اس کے ساتھ تضمین معلومات میں شامل ہونے کے لئے حیراتیک توجه نیٹورک کے ساتھ۔ اس وجہ سے کہ NMT کے لئے بہت سی مقدار پارالیل ڈیٹا کی ضرورت ہے جو اس کام کے لئے موجود نہیں ہے، ہمارا طریقہ ایک زبان کی ڈیٹا استعمال کرنے کے لئے واپس ترجمہ کے ساتھ ہماری مدل کی تعلیم کے لئے مطابق ہے. ہماری آزمائش ظاہر کرتی ہے کہ سنٹیٹی ڈیٹی کے ساتھ استعمال ہونے کے لئے سنٹیٹی سطح NMT کے لئے بہترین ترجمہ کیفیت کے لئے دکھائے جاتے ہیں۔', 'no': 'Denne papiret skildrar systemoppføringa vårt til delt oppgåve WMT20 på liknande språk-omsetjing. Vi undersøkte bruken av dokumentnivået neuralmaskinsomsetjingar (NMT) for låg ressurs, liknande språkspar Marathi-Hindi. Systemet vårt er eit utviding av kunsttransformeringsarkitektur med hierarkiske oppmerksnettverk for å inkludere kontekstinformasjon. Sidan NMT krev stor mykje parallelle data som ikkje er tilgjengeleg for denne oppgåva, er tilnærminga vårt fokusert på å bruka monospråk data med tilbakeomsetjing for å trena modelane våre. Eksperimentane våre viser at NMT-nivå på dokumentet kan vera ein rett alternativ for setningsnivå NMT for å forbetra omsetjingskvalitet på lav ressurserte språk sjølv når det er brukt med syntetiske data.', 'uz': "Bu qogʻoz huddi tillar tarjimasida bizning tizimmizni WMT20'ga qayta boʻlgan vazifani anglatadi. Biz dokumentar darajadagi neyrolik tarjima (NMT) tizimini yaratdik, bir xil tilning bir xil Marathi-Hindi uchun. Bizning tizimmiz tahrirchik tarkibini bir xil maʼlumot qo'yish uchun tarmoqni o'zgartirish holatining holati kengayligi. Chunki, NMT shu vazifa uchun mavjud emas boʻlgan parallel maʼlumot uchun katta maʼlumot kerak, bizning usuli monolingual maʼlumot yordamida foydalanishimiz mumkin, modellarimizni o'rganish uchun qayta tarjima qilish uchun. Bizning imtiyozlarimiz hujjatning darajasi NMT imkoniyatlarini koʻpaytirish uchun soʻzning darajasi NMT bo'lishi mumkin.", 'vi': 'Tờ giấy này mô tả hệ thống của chúng tôi để chuyển sang lỗi chung của WM210...về dịch ngôn ngữ tương tự. Chúng tôi đã kiểm tra việc sử dụng các hệ thống dịch chuyển máy thần kinh trên tập tin ảnh (NMB) cho các tài nguyên thấp, tương tự cặp ngôn ngữ Marath-Hindi. Hệ thống của chúng tôi là phần mở rộng cấu trúc biến hình nền tiên tiến, với các mạng lưới chú ý cấp cao để bao gồm các thông tin ngữ cảnh. Vì công nghệ NMT cần rất nhiều dữ liệu song song mà không sẵn sàng cho nhiệm vụ này, chúng tôi hướng tới việc sử dụng thông tin ngôn ngữ chung với dịch phụ để đào tạo mẫu. Những thí nghiệm của chúng tôi cho thấy NMT cấp tài liệu có thể là một cách thay đổi hợp lý với công ty NMT cấp hạn tù để cải thiện chất lượng dịch của ngôn ngữ nghèo nguồn lực kể cả khi sử dụng bằng dữ liệu nhân tạo.', 'nl': 'Dit document beschrijft onze systeeminzending aan WMT20 gedeelde taak voor soortgelijke taalvertaling. We onderzochten het gebruik van documentlevel neural machine translation (NMT) systemen voor low-resource, vergelijkbaar taalpaar Marathi-Hindi. Ons systeem is een uitbreiding van state-of-the-art Transformer architectuur met hiërarchische aandachtsnetwerken om contextuele informatie op te nemen. Omdat NMT een grote hoeveelheid parallelle data vereist die niet beschikbaar is voor deze taak, is onze aanpak gericht op het gebruik van monolingual data met back translation om onze modellen te trainen. Onze experimenten tonen aan dat NMT op documentniveau een redelijk alternatief kan zijn voor NMT op zinnenniveau voor het verbeteren van de vertaalkwaliteit van talen met lage resources, zelfs wanneer gebruikt met synthetische gegevens.', 'da': 'Denne artikel beskriver vores systemindsendelse til WMT20 delte opgave om lignende sprogoversættelse. Vi undersøgte brugen af dokumentniveau neurale maskinoversættelsessystemer (NMT) til lav ressource, lignende sprogpar marathi-hindi. Vores system er en udvidelse af state-of-the-art Transformer arkitektur med hierarkiske opmærksomhedsnetværk til at indarbejde kontekstuel information. Da NMT kræver store mængder parallelle data, som ikke er tilgængelige til denne opgave, er vores tilgang fokuseret på at bruge ensprogede data med back-translation til at træne vores modeller. Vores eksperimenter afslører, at NMT på dokumentniveau kan være et rimeligt alternativ til NMT på sætningsniveau for at forbedre oversættelseskvaliteten af lav ressource sprog, selv når det bruges med syntetiske data.', 'bg': 'Тази статия описва нашата система за подаване на споделена задача за превод на подобен език. Разгледахме използването на системи за невронен машинен превод (НМТ) на ниво документация за нискоресурсна, подобна езикова двойка марати-хинди. Нашата система е разширение на най-съвременната архитектура на трансформаторите с йерархични мрежи за внимание, които включват контекстуална информация. Тъй като НМТ изисква голямо количество паралелни данни, които не са налични за тази задача, нашият подход е фокусиран върху използването на едноезични данни с обратен превод за обучение на нашите модели. Нашите експерименти показват, че НМТ на ниво документи може да бъде разумна алтернатива на НМТ на ниво изречение за подобряване качеството на превода на езици с ниски ресурси, дори когато се използват със синтетични данни.', 'hr': 'Ovaj papir opisuje naše podnošenje sustava WMT20 zajedničkom zadatku o sličnom prevodu jezika. Ispitivali smo korištenje sustava za prevod neuralnih strojeva na razini dokumentacije (NMT) za niske resurse, slični jezički par Marathi-Hindi. Naš sustav je produženje državne arhitekture transformera s hijerarhičkim mrežama pažnje za uključenje kontekstnih informacija. Pošto NMT zahtijeva veliku količinu paralelnih podataka koji nisu dostupni za ovaj zadatak, naš pristup je fokusiran na upotrebu monojezičkih podataka s prevodom natrag kako bi obučili naše modele. Naši eksperimenti otkrivaju da razina dokumenta NMT može biti razumna alternativa razini rečenica NMT za poboljšanje kvalitete prevoda niskih resursa jezika čak i kada se koristi sintetičkim podacima.', 'id': 'Kertas ini menjelaskan pengiriman sistem kita ke WMT20 tugas berbagi tentang terjemahan bahasa yang sama. We examined the use of documentlevel neural machine translation (NMT) systems for low-resource, similar language pair Marathi-Hindi.  Sistem kita adalah ekstensi dari arkitektur Transformer yang terbaik dengan jaringan perhatian hierarkis untuk memasukkan informasi kontekstual. Karena, NMT membutuhkan jumlah besar data paralel yang tidak tersedia untuk tugas ini, pendekatan kita fokus pada menggunakan data monobahasa dengan terjemahan belakang untuk melatih model kita. Eksperimen kami mengungkapkan bahwa NMT tingkat dokumen dapat menjadi alternatif yang masuk akal untuk NMT tingkat kalimat kalimat terjemahan bahasa sumber daya rendah bahkan ketika digunakan dengan data sintetis.', 'fa': 'این کاغذ تسلیم سیستم ما به کار مشترک WMT20 در ترجمه زبان مشترک توصیف می\u200cکند. ما استفاده از سیستم ترجمه\u200cهای ماشین عصبی (NMT) برای منابع کم، جفت زبان شبیه Marathi-Hindi را تحقیق کردیم. سیستم ما یک طولانی از معماری تغییر دهنده هنر با شبکه های توجه زیادی برای جمع اطلاعات موضوع است. از اونجایی که NMT نیاز دارد مقدار زیادی از داده های parallel که برای این کار موجود نیستند، روش ما روی استفاده از داده های یک زبان با ترجمه عقب برای آموزش مدلهای ما تمرکز شده است. آزمایشات ما نشان می دهند که سطح سند NMT می تواند جایگزینی منطقی به سطح جمله NMT باشد برای بهتر کردن کیفیت ترجمه کردن زبانهای منابع پایین حتی زمانی که با داده های سنت استفاده می شود.', 'sw': 'Gazeti hili linaelezea mfumo wetu wa kutoa ujumbe wa WMT20 katika tafsiri inayofanana na lugha. Tulijaribu matumizi ya mfumo wa kutafsiri mashine ya kisasa (NMT) kwa rasilimali chini, mbili mbili sawa na lugha Marathi-Hindi. Mfumo wetu ni mpango wa ujenzi wa zamani wa hali ya sanaa na mitandao ya uangalizi wa ufuatiliaji ili kuingiza taarifa za sasa. Tangu, NMT inahitaji kiasi kikubwa cha takwimu ambazo hazipatikani kwa ajili ya kazi hii, mbinu yetu inalenga kutumia taarifa za lugha za kifalme kwa kutafsiri kwa ajili ya kufundisha mifano yetu. Majaribio yetu yanaonyesha kuwa kiwango cha nyaraka cha NMT kinaweza kuwa mbadala sahihi ya kiwango cha sentenca cha NMT kwa kuboresha kiwango cha tafsiri cha lugha za chini za rasilimali hata kama inavyotumiwa kwa takwimu za pamoja.', 'de': 'Dieses Papier beschreibt unsere Systemübermittlung an WMT20 Shared Task zur Übersetzung ähnlicher Sprachen. Wir untersuchten den Einsatz von neuronalen maschinellen Übersetzungssystemen (NMT) auf Dokumentenebene für ressourcenarme, ähnliche Sprachpaare Marathi-Hindi. Unser System ist eine Erweiterung der hochmodernen Transformer-Architektur mit hierarchischen Aufmerksamkeitsnetzwerken, um kontextbezogene Informationen einzubinden. Da NMT eine große Menge an parallelen Daten benötigt, die für diese Aufgabe nicht verfügbar sind, konzentriert sich unser Ansatz auf die Verwendung von einsprachigen Daten mit Rückübersetzung, um unsere Modelle zu trainieren. Unsere Experimente zeigen, dass NMT auf Dokumentenebene eine vernünftige Alternative zu NMT auf Satzebene sein kann, um die Übersetzungsqualität von Sprachen mit geringen Ressourcen zu verbessern, selbst wenn sie mit synthetischen Daten verwendet werden.', 'ko': '본고는 우리 시스템이 WMT20에 제출한 유사한 언어 번역 공유 임무를 묘사한다.우리는 문서급 신경기계번역(NMT) 시스템이 저자원, 유사한 언어가 마라티-인디언에 대한 응용을 연구했다.우리의 시스템은 가장 선진적인 Transformer 구조의 확장으로 차원화된 주의 네트워크를 가지고 상하문 정보를 통합시킨다.NMT는 대량의 병렬 데이터를 필요로 하기 때문에 이 임무에 있어서 사용할 수 없기 때문에 우리의 방법은 단어 데이터를 이용하여 역역을 해서 우리의 모델을 훈련시키는 데 중심을 두었다.우리의 실험에 의하면 문서급 NMT는 문장급 NMT의 합리적인 대체 방안으로 저자원 언어의 번역 품질을 향상시키고 합성 데이터와 함께 사용하더라도 향상시킬 수 있다.', 'tr': 'Bu kagyz WMT20 we beýleki dil terjimesinde sistemimiziň ilatymyzy tassyýar. Biz sened derejesi neural maşynyň (NMT) sistemlerini iň az resurslar üçin, Marathi-Hindi dili çiftini bardyk. Biziň sistemimiz, mektup maglumaty dahil etmek üçin iýerarhiýa üns ýoldaşdyr. NMT-iň üçin bu zada ulaşan uly parallel maglumatlary gerek bolýar, biziň metodamyz modellerimizi öwretmek üçin monolingüs maglumatlaryny yzyna terjime etmek üçin guruldyrylýar. Biziň deneylerimiz NMT senetik derejesi NMT senetik maglumaty bilen ulanylan hatda, kellämiz düşük bolan dillerin terjime etmek üçin düşünjeli bir alternatiw bolup biler.', 'am': 'ይህም ገጽ በተለያዩ ቋንቋዎች ትርጓሜ ላይ ስራችንን ወደ WMT20 የተካፈሉት ስራዎችን የሚያሳውቃታል፡፡ የደብዳቤ ደረጃን የናውሬል መኪና ትርጉም (NMT) ስርዓት ለትንሽ-resource፣ ብጤው የቋንቋ ዓይነቶች ማርታቲ-Hindi ጥያቄን ሞክረናል፡፡ Our system is an extension of state-of-the-art Transformer architecture with hierarchical attention networks to incorporate contextual information.  ከ፣ NMT ለዚህ ስራ ያልተገኘ ብዙን ተያያይነት ዳታዎችን ያስፈልጋል፣ ልግስናችን በሞሎንቋል ዳታዎችን በመጠቀም በኋላ ትርጓሜዎቻችንን ለማስተማር ይታያል፡፡ ፈተናዎቻችን የሰነድ ደረጃን NMT በተጠቃሚ ዳታ እንኳ በተጠቀም ጊዜ እንኳ የዝቅተኛ የደረጃ ቋንቋዎች ጥያቄን ለማድረግ የሚችል ክፍል ነው ብለው ያስታውቃሉ፡፡', 'sq': 'This paper describes our system submission to WMT20 shared task on similar language translation.  We examined the use of documentlevel neural machine translation (NMT) systems for low-resource, similar language pair Marathi-Hindi.  Sistemi ynë është një zgjerim i arkitekturës së modernizuar të Transformës me rrjete të vëmendjes hierarkike për të përfshirë informacionin kontekstual. Që kur NMT kërkon sasi të madhe të dhënash paralele që nuk janë në dispozicion për këtë detyrë, qasja jonë është përqëndruar në përdorimin e të dhënave monogjuhësore me përkthimin mbrapa për të trajnuar modelet tona. Eksperimentet tona zbulojnë se niveli i dokumentit NMT mund të jetë një alternativë e arsyeshme për nivelin e fjalëve NMT për përmirësimin e cilësisë së përkthimit të gjuhëve me burime të ulta edhe kur përdoret me të dhëna sintetike.', 'az': 'Bu kağıt sistemimizin WMT20 vəzifəsinə bənzər dil çevirilməsi barəsində paylaşılan işləri təsdiqləyir. Və belə bir dil çift Marathi-Hindi üçün belə düşük çoxluğu üçün döküm seviyyəti nöral maşın çeviri sistemlərinin istifadəsini təsdiq etdik. Sistemimiz müxtəlif məlumatları birləşdirmək üçün hiyerarşik məlumatları olan sanat transformer arhitektarının çoxluğudur. NMT bu işin üçün faydalanmayan paralel məlumatların böyük dəyişiklikləri lazımdır, bizim metodumuz modellərimizi təhsil etmək üçün monodil məlumatlarını istifadə etməyə odaqlanır. Bizim təcrübələrimiz belə göstərir ki, NMT səviyyəsi sintetik məlumatları ilə istifadə ediləndə belə, cümlələr-səviyyəsi NMT üçün daha düşük ressurs dillərin çevirilməsi üçün münasibətli alternatifi olar.', 'bn': 'This paper describes our system submission to WMT20 shared task on similar language translation.  আমরা ডকুমেন্টেলের নিউরাল মেশিন অনুবাদ (এনএমটি) সিস্টেমের ব্যবহার পরীক্ষা করেছি নিম্ন সম্পদের জন্য, একই ধরনের ভাষার জোয়ার ম আমাদের সিস্টেম হচ্ছে প্রাক্তন তথ্য অন্তর্ভুক্ত করার জন্য রাষ্ট্র-শিল্পের পরিবর্তন কাঠামোর একটি বিস্তারিত স্থাপন। যেহেতু এনএমটির জন্য বিশাল পরিমাণ প্যারালেল ডাটা প্রয়োজন যা এই কাজের জন্য পাওয়া যাচ্ছে না, আমাদের প্রতিক্রিয়া আমাদের মডেল প্রশিক্ষণে আমাদের পরীক্ষা প্রকাশ করা হয়েছে যে ডকুমেন্ট-স্তর এনএমটি কারাদণ্ড-স্তরের বিকল্প হতে পারে যেহেতু সিন্টেটিক ডাটা সহ ব্যবহার করা হলেও কম সম', 'bs': 'Ovaj papir opisuje naše podnošenje sistema WMT20 zajedničkom zadatku o sličnom prevodu jezika. Pregledali smo korištenje sustava za prevod neuralnih strojeva na nivou dokumentacije (NMT) za niske resurse, slični jezički par Marathi-Hindi. Naš sistem je produženje državne arhitekture transformera sa hijerarhičkim mrežama pažnje za uključenje kontekstnih informacija. Pošto NMT zahtijeva veliku količinu paralelnih podataka koji nisu dostupni za ovaj zadatak, naš pristup je fokusiran na upotrebu monojezičkih podataka sa povratnim prevodom kako bi obučili naše modele. Naši eksperimenti otkrivaju da NMT-nivo dokumenta može biti razumna alternativa NMT-nivou kazne za poboljšanje kvalitete prevoda niskih resursa jezika čak i kada se koristi sintetičkim podacima.', 'cs': 'Tento článek popisuje náš systém odeslání do WMT20 sdílený úkol na podobný jazykový překlad. Zkoumali jsme využití systémů neuronového strojového překladu (NMT) na úrovni dokumentů pro nízké zdroje, podobný jazykový pár Marathi-Hindi. Náš systém je rozšířením nejmodernější architektury transformátoru o hierarchické pozornostní sítě zahrnující kontextové informace. Protože NMT vyžaduje velké množství paralelních dat, která pro tento úkol nejsou k dispozici, je náš přístup zaměřen na využití monojazyčných dat s zpětným překladem pro trénink našich modelů. Naše experimenty ukazují, že NMT na úrovni dokumentů může být rozumnou alternativou k NMT na úrovni věty pro zlepšení kvality překladu nízkých zdrojů jazyků i při použití syntetických dat.', 'hy': 'Այս հոդվածը նկարագրում է մեր համակարգի ներկայացումը ՀՄԹ20-ի համագործակցած հանձնարարությունը նման լեզվի թարգմանման մասին: Մենք ուսումնասիրեցինք փաստաթղթերի մակարդակի նյարդային մեքենայի թարգմանման (NMT) համակարգերի օգտագործումը ցածր ռեսուրսների, նմանատիպ լեզվի զույգերի համար: Մեր համակարգը վերջին տեխնոլոգիական տրանսֆերմերի ճարտարապետության ընդլայնումն է հիերարխիկ ուշադրության ցանցերով, որպեսզի ներառենք կոնտեքստալ ինֆորմացիա: Քանի որ NMT-ը պահանջում է մեծ քանակությամբ զուգահեռ տվյալներ, որոնք այս խնդրի համար հասանելի չեն, մեր մոտեցումը կենտրոնացված է միալեզվով տվյալների օգտագործման հետ հետադարձ թարգմանման մեջ մեր մոդելների ուսու Մեր փորձերը բացահայտում են, որ փաստաթղթի մակարդակի NMT-ը կարող է լինել բացատրական այլընտրանք նախադասությունների մակարդակի NMT-ի համար, որպեսզի բարելավվի ցածր ռեսուրսների լեզուների թարգմանման որակը նույնիսկ երբ', 'ca': "Aquest article descriu la nostra subministració al WMT20 a una tasca compartida sobre traducció de llenguatges similar. Vam examinar l'ús de sistemes de traducció neural de màquines (NMT) a nivell documental per a un parell de llenguatges similar de baix recursos marati-hindí. Our system is an extension of state-of-the-art Transformer architecture with hierarchical attention networks to incorporate contextual information.  Com que la NMT requereix una gran quantitat de dades paralleles que no està disponible per a aquesta tasca, el nostre enfocament està centrat en l'ús de dades monolingües amb traducció posterior per formar els nostres models. Els nostres experiments revelen que la NMT a nivell de document pot ser una alternativa raonable a la NMT a nivell de frases per millorar la qualitat de traducció de llengües amb baix recursos fins i tot quan es utilitza amb dades sintètiques.", 'et': 'Käesolevas artiklis kirjeldatakse meie süsteemi esitamist WMT20 jagatud ülesannet sarnase keele tõlkimisel. Uurisime dokumentaalse taseme neuraalse masintõlke (NMT) süsteemide kasutamist madala ressursiga sarnase keelepaari Marathi-Hindi jaoks. Meie süsteem on kaasaegse Transformeri arhitektuuri laiendus hierarhiliste tähelepanuvõrgustikega kontekstiteabe kaasamiseks. Kuna NMT nõuab suurt hulka paralleelseid andmeid, mis ei ole selleks ülesandeks kättesaadavad, on meie lähenemisviis keskendunud ühekeelsete andmete kasutamisele tagasitõlkega mudelite koolitamiseks. Meie eksperimendid näitavad, et dokumenditasemel NMT võib olla mõistlik alternatiiv lausetasemel NMT-le madala ressursiga keelte tõlkekvaliteedi parandamiseks isegi sünteetiliste andmetega kasutamisel.', 'af': "Hierdie papier beskryf ons stelsel onderwerp na WMT20 gedeelde taak op gelyklike taal vertaling. Ons ondersoek die gebruik van dokumentvlak neurale masjien vertaling (NMT) stelsels vir lae hulpbron, gelyke taal paar Marathi-Hindi. Ons stelsel is 'n uitbreiding van state-of-the-art Transformer-arkitektuur met hierarchiese aandagnetwerke om contextual inligting te inkorpreer. Omdat NMT groot hoeveelheid parallele data benodig wat nie beskikbaar is vir hierdie taak nie, is ons toegang fokus op die gebruik van monolinglike data met terugvertaling om ons modele te oefen. Ons eksperimente vertoon dat dokumentvlak NMT 'n redelike alternatief kan wees vir sentence-level NMT vir die verbetering van vertaling kwaliteit van lae hulpbron tale selfs wanneer gebruik word met sintetiese data.", 'fi': 'T채ss채 artikkelissa kuvataan j채rjestelm채mme l채hett채mist채 WMT20:n yhteiseen teht채v채채n samankaltaisen kielen k채채nt채misest채. Tutkimme dokumenttitason neurokonek채채nn철sj채rjestelmien (NMT) k채ytt철채 v채h채varaisille, samankaltaisille kieliparille Marathi-Hindi. J채rjestelm채mme on uusinta teknologiaa edustavan Transformer-arkkitehtuurin laajennus hierarkkisilla huomioverkostoilla, jotka sis채lt채v채t kontekstitietoa. Koska NMT vaatii paljon rinnakkaisdataa, jota ei ole saatavilla t채h채n teht채v채채n, l채hestymistapamme keskittyy monikielisen datan hy철dynt채miseen backtranslation avulla malliemme kouluttamiseen. Kokeet osoittavat, ett채 dokumenttitason NMT voi olla j채rkev채 vaihtoehto lausetason NMT:lle v채h채resurssisten kielten k채채nn철slaadun parantamisessa my철s synteettisen datan kanssa.', 'jv': 'Pesene iki rambarang nggawe sistem sing nyimpen kanggo WWT 2, kang dibutuhke tarjamahan kanggo kelas urip. Awak dhéwé éntuk nggambar sistem kanggo kelas perangkat seneng nggambar, kaya pak-pak nganggo barang nggambar, sawar kuwi Marati-endi. Sistem awak dhéwé iku tahun duwé ning stad-of-the-Art Transformer architecture karo architecture sing dikenalke diketekno ning basa contextual. Dino, NMT Awak dhéwé éntuk ngerasakno yang kelas NMT iso dianggap perusahaan anyar tentang kanggo nggawe kalitas itwasan sing paling dhéwé. Drongen dhéwé, NMT iso nggawe gerakan tarjamahan kanggo awak dhéwé éntuk terakhir nggo awak dhéwé.', 'ha': "Wannan takardan na bayyana zimanmu da ake saka wa WMT20 da aka raba wani aikin da aka raba shi a kan fassarar harshen nan daidai. Mun jarraba amfani da zane-zane na fassarar takardar neural na rubutu (NMT) na'urar-raye-resource, da misalin harshen biyu Marati-Hidi. Ubuntu na ƙunsa yana da tsarin-state-of-the-art Transformer game da zane-hierrchical listening to include information masu hushi. Tana da, NMT yana ƙayyade cikakken data mai girma da za'a iya buƙata wa wannan aikin, hanyarmu na da amfani da amfani da data na monoli-lugha da bakin fassarar-fassarar zuwa ya sanar da misalinmu. Kayan jarrabõnmu suka bayyana cewa, zan iya zama wata matsayi mai inganci wa zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane ko idan an yi amfani da da data na synthetic.", 'he': 'העיתון הזה מתאר את ההעברה שלנו למשימה משותפת WMT20 על תרגום שפה דומה. בדקנו את השימוש במערכות התרגום של מכונות עצביות ברמה מסמכים (NMT) עבור משאבים נמוכים, זוג שפה דומה מרתי-הינדי. המערכת שלנו היא התרחבות של ארכיטקטורה המפורסמת המאוחרת עם רשתות תשומת לב הייררכית כדי להכיל מידע קונטקסטי. Since, NMT requires large amount of parallel data which is not available for this task, our approach is focused on utilizing monolingual data with back translation to train our models.  Our experiments reveal that document-level NMT can be a reasonable alternative to sentence-level NMT for improving translation quality of low resourced languages even when used with synthetic data.', 'sk': 'Ta prispevek opisuje našo predložitev sistema WMT20 skupno nalogo za prevajanje podobnih jezikov. Preučili smo uporabo sistemov nevronskega strojnega prevajanja (NMT) dokumentacijskega nivoja za podobni jezikovni par Marathi-Hindi z nizkimi viri. Naš sistem je razširitev najsodobnejše arhitekture transformatorjev z hierarhičnimi mrežami pozornosti, ki vključujejo kontekstualne informacije. Ker NMT potrebuje veliko vzporednih podatkov, ki za to nalogo niso na voljo, je naš pristop osredotočen na uporabo enojezičnih podatkov s prevodom nazaj za usposabljanje naših modelov. Naši poskusi kažejo, da je NMT na ravni dokumentov lahko razumna alternativa NMT na ravni stavka za izboljšanje kakovosti prevajanja jezikov z nizkimi viri, tudi če se uporabljajo s sintetičnimi podatki.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག་གི་སྐྱེལ་འདྲེན་པ་WMT20 ལ་མཐུན་སྤྱོད་ཀྱི་ལས་འགུལ་ལ་སྤྱོད་བཞིན་ཡོད་པ ང་ཚོས་རྒྱ་ནག་གི་ཡིག་ཆ་ལ་ཉུང་བའི་ལག་འཁྱེར་གྱི་སྤྱོད་རྩིས་བ་ཅིག་གནད་དོན་དག་པ་ཞིབ་དཔྱད་བྱས་ན། མ་ཤེ་ཤི་རྒྱ་ནག་ ང་ཚོའི་མ་ལག་ནི་རྣམ་གྲངས་ཀྱི་གནས་སྟངས་གནས་སྟངས་གནས་སྟངས་འགྱུར་མཁན་གྱི་སྒྲིག་འགོད་དང་མཉམ་དུ་ཡུལ་སྒྲིག་ཡོད་པའི་ཆ་འཕྲིན Since, NMT requires a large amount of parallel data that are not available for this task, our approach is focused on using monolingual data with back translation to train our models. ང་ཚོའི་བརྟག་ཞིག་གིས་ཡིག་ཆ་ལྡན་པའི་NMT ཡིག་ཆ་འདི་ཚིག་སྒྲུང་ཕྱོགས་ཀྱི་གནད་སྤྲོད་རྒྱུ་དང་།'}
{'en': 'The University of Maryland’s Submissions to the WMT20 Chat Translation Task : Searching for More Data to Adapt Discourse-Aware Neural Machine Translation', 'ar': 'تقديمات جامعة ماريلاند إلى مهمة ترجمة الدردشة WMT20: البحث عن المزيد من البيانات لتكييف الترجمة الآلية العصبية الواعية للخطاب', 'pt': 'Submissões da Universidade de Maryland para a tarefa de tradução de bate-papo do WMT20: procurando mais dados para adaptar a tradução automática neural com reconhecimento de discurso', 'fr': "Soumissions de l'Université du Maryland à la tâche de traduction de chat WMT20\xa0: Recherche de plus de données pour adapter la traduction automatique neuronale consciente du discours", 'es': 'Presentaciones de la Universidad de Maryland a la tarea de traducción de chat WMT20: búsqueda de más datos para adaptar la traducción automática neuronal sensible al discurso', 'ja': 'WMT 20チャット翻訳タスクへのメリーランド大学の提出物： Discourse - Aware Neural Machine Translationに適応するためのより多くのデータの検索', 'hi': 'WMT20 चैट अनुवाद कार्य के लिए मैरीलैंड विश्वविद्यालय की प्रस्तुतियाँ: प्रवचन-जागरूक तंत्रिका मशीन अनुवाद को अनुकूलित करने के लिए अधिक डेटा की खोज', 'zh': '马里兰大学 WMT20 聊天译事:搜索更多,以应语感知神经机器翻译', 'ru': 'Материалы Университета Мэриленда для задачи перевода в чате WMT20: поиск дополнительных данных для адаптации нейронного машинного перевода с пониманием дискурса', 'ga': 'Aighneachtaí Ollscoil Maryland chuig Tasc Aistriúcháin Comhrá WMT20: Ag Cuardach do Shonraí Níos Mó chun Dioscúrsa a Chur in oiriúint-Aware Neural Machine Translation', 'ka': 'მარილანდის სამუშაო სუნივერსი WMT20 საუბრალო სამუშაო სამუშაო დაწყვებისთვის: უფრო მეტი მონაცემების ძიება განსაზღვრებისთვის განსაზღვრებისთვის ნეირო', 'el': 'Υποβολές του Πανεπιστημίου του Μέριλαντ στο μεταφραστικό έργο συνομιλίας Αναζήτηση περισσότερων δεδομένων για την προσαρμογή της νευρολογικής μηχανικής μετάφρασης', 'it': "Contributi dell'Università del Maryland al compito di traduzione della chat WMT20: ricerca di più dati per adattare la traduzione automatica neurale consapevole del discorso", 'hu': 'A Maryland Egyetem benyújtásai a WMT20 chat fordítási feladathoz: több adat keresése a beszédtudatos idegi fordítás adaptálásához', 'mk': 'Предлозите на Универзитетот во Мериленд на задачата за превод на разговорите на WMT20: Барање повеќе податоци за адаптирање на превод на неврални машини со свесност за дискурс', 'ml': 'WMT20 ചാറ്റ് പരിഭാഷക ക കാര്യത്തിലേക്ക് മേരിലാന്\u200dഡിന്\u200dറെ സബ്മിഷനുകള്\u200d: ഡിസ്കോര്\u200dസ്- അറിയുന്ന നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്ത', 'lt': 'Marylando universiteto pristatymai WMT20 pokalbių vertimo uždaviniui: ieškoti daugiau duomenų, kad būtų pritaikytas diskurso s ąmoningas neurologinis vertimas', 'mt': "The University of Maryland's Submissions to the WMT20 Chat Translation Task: Searching for More Data to Adapt Discourse-Aware Neural Machine Translation", 'kk': 'Мэрилендің университетінің WMT20 шат аудару тапсырмасына келтірілген тапсырмасы: Көбірек деректерді іздеу', 'pl': 'Zgłoszenia Uniwersytetu Maryland do zadania tłumaczenia czatu WMT20: poszukiwanie więcej danych w celu dostosowania tłumaczenia maszynowego świadomego dyskusji', 'ms': 'Submission University of Maryland to the WMT20 Chat Translation Task: Searching for More Data to Adapt Discourse-Aware Neural Machine Translation', 'ro': 'Depunerile Universității din Maryland la activitatea de traducere a conversațiilor WMT20: Căutarea mai multor date pentru adaptarea traducerii automate neurale conștiente de discurs', 'no': "University of Maryland's Submissions to the WMT20 Chat Translation Task: Searching for More Data to Adapt Discourse-Aware Neural Machine Translation", 'so': "Jaamacadda Maryland's Submissions to the WMT20 Chat Translation Task: Searching for more Data to Adapt Discourse-aware Neural Machine Translation", 'sv': 'University of Marylands bidrag till WMT20 chattöversättning Uppgift: Söka efter mer data för att anpassa diskursmedveten neural maskinöversättning', 'sr': 'Prevod Univerziteta Marylanda na zadatak WMT20 Chat Translation: Traženje više podataka za prilagođenje prevoda neuroloških strojeva', 'mn': 'Мариландын Их Сургууль WMT20 Chat Translation Task-д илүү өгөгдлийг хайж, илүү мэдээллийг зохион байгуулахын тулд', 'ta': 'WMT20 அரட்டை மொழிபெயர்ப்பு பணிக்கு மேரில்லாந்தின் உப மிஷன்கள்:', 'ur': 'ماریلنڈ کے یونیورسٹ یونورسٹ کے ساتھ WMT20 چاٹ ترجمہ ٹاکس کے لئے وینورسٹ بیٹ کی تعلیم کا کام ہے: ڈیسکورس-آگاہ نیورال ماشین ترجمہ کے لئے زیادہ ڈیٹا تلاش کرنا ہے', 'si': 'මැරිලෑන්ඩ්ගේ විශ්වාසිකය WMT20 චැට් භාවිතය වැඩකට විශ්වාස කරන්න: විශ්වාස කරන්න වැඩි දත්ත සොයාගැනීම සඳහා ප්\u200dරවේශය', 'uz': 'Name', 'vi': "The University of Maryland's Subissions to the WM20 Chat Translation Task: Đang tìm kiếm thêm dữ liệu để thích ứng Discourse-Nhận thức Neural Machine Translation", 'bg': 'Предложенията на Университета в Мериленд към задачата за чат превод: търсене на повече данни за адаптиране на невронния машинен превод, осъзнаващ дискурса', 'da': 'University of Marylands indlæg til WMT20 Chat Oversættelse Opgave: Søgning efter flere data til at tilpasse diskursbevidst neural maskinoversættelse', 'hr': 'Prevod Univerziteta Marylanda na zadatak WMT20 prijevoza: traženje više podataka za prilagođenje prijevoza neuroloških strojeva.', 'nl': 'De inzendingen van de Universiteit van Maryland aan de WMT20 Chat Translation Task: Zoeken naar meer gegevens om discourse-aware neuronale machinevertaling aan te passen', 'fa': 'تحویل دانشگاه ماریلند برای ترجمه ماشین عصبی WMT20', 'de': 'Beiträge der University of Maryland zur WMT20 Chat Translation Task: Suche nach mehr Daten zur Anpassung diskursbewusster neuronaler maschineller Übersetzung', 'ko': '마리란 대학 WMT20 채팅 번역 의뢰 제출: 더 많은 데이터를 검색하여 언어 감지 신경 기계 번역에 적응', 'af': 'Name', 'tr': 'WMT20 Çäpler terjime etmek üçin Marylandyň Üniwersitesi', 'sw': 'Tafsiri za Mazungumzo ya Chuo Kikuu cha Maryland kwenye Tafsiri ya WMT20: Anatafuta Takwimu zaidi ya Kutafuta Tafsiri ya Mashine ya Kiasili inayofahamika', 'hy': "Մարիլանդի համալսարանի ներկայացումները World MT20-ի խոսակցության թարգմանման առաջադրանքին' ավելի շատ տվյալներ փնտրելու, որպեսզի հարմարեցվի", 'sq': 'Dërgimet e Universitetit të Merilendit në detyrën e përkthimit të bisedës WMT20: Kërkimi për më shumë të dhëna për të përshtatur përkthimin e makinave nervore të njohura për diskursin', 'am': 'ማርየላንድ ዩንቨርስቲ አዋቂዎች ወደ WMT20 Chat ትርጉም ማድረግ: Search for more data to Adapt Discourse-aware Neural Machine translation', 'id': 'Submission University of Maryland to the WMT20 Chat Translation Task: Searching for More Data to Adapt Discourse-Aware Neural Machine Translation', 'az': 'Maryland Üniversitesi WMT20 Söhbət Çeviri Gözəli: Discourse-Aware Neural Machine Translation', 'cs': 'Příspěvky Univerzity v Marylandu na WMT20 Chat Translation Task: Hledání dalších dat pro adaptaci diskurzního neurálního strojového překladu', 'ca': 'Les Submissions de la Universitat de Maryland a la tasca de traducció de la conversa WMT20: Buscar més dades per adaptar la traducció de màquines neuronals conscients del discurs', 'bn': 'WMT20 চ্যাট ট ট্রান্সভার কাজে মেরিল্যান্ড বিশ্ববিদ্যালয়ের সাবমিশন: ডিসোর্স- জানিয়েছেন নিউরাল মেশিন অনুবাদের অনুবাদ অনুসন্', 'et': 'Marylandi Ülikooli esitused WMT20 vestluse tõlkimise ülesandele: rohkem andmeid diskursusteadliku neurotõlke kohandamiseks', 'fi': 'Marylandin yliopiston julkaisut WMT20 Chat Translation -tehtävään: lisää dataa diskurssitietoisen neurokääntämisen mukauttamiseksi', 'bs': 'Univerzitet Marylandske podatake na zadatak WMT20 prijevoza: traženje više podataka za prilagođenje prijevoza neuroloških strojeva.', 'sk': 'Prispevki Univerze v Marylandu k nalogi prevajanja klepeta WMT20: iskanje več podatkov za prilagoditev diskurznega živčnega strojnega prevajanja', 'jv': 'Submis Universite nang Marytan kanggo Terjamahan yang WWT 22', 'ha': '@ title: group', 'he': 'ההעברות של אוניברסיטת מרילנד למשימת השיחה WMT20: חיפוש אחר נתונים נוספים', 'bo': "The University of Maryland's Submissions to the WMT20 Chat Translation Task: Searching for More Data to Adapt Discourse-Aware Neural Machine Translation"}
{'en': 'This paper describes the University of Maryland’s submissions to the WMT20 Shared Task on Chat Translation. We focus on translating agent-side utterances from English to German. We started from an off-the-shelf BPE-based standard transformer model trained with WMT17 news and fine-tuned it with the provided in-domain training data. In addition, we augment the training set with its best matches in the WMT19 news dataset. Our primary submission uses a standard Transformer, while our contrastive submissions use multi-encoder Transformers to attend to previous utterances. Our primary submission achieves 56.7 BLEU on the agent side (ende), outperforming a baseline system provided by the task organizers by more than 13 BLEU points. Moreover, according to an evaluation on a set of carefully-designed examples, the multi-encoder architecture is able to generate more coherent translations.', 'ar': 'تصف هذه الورقة عمليات إرسال جامعة ماريلاند إلى مهمة WMT20 المشتركة حول ترجمة الدردشة. نحن نركز على ترجمة أقوال الوكيل من الإنجليزية إلى الألمانية. لقد بدأنا من نموذج محول قياسي قائم على BPE جاهز للاستخدام مع أخبار WMT17 وقمنا بضبطه باستخدام بيانات التدريب المتوفرة في المجال. بالإضافة إلى ذلك ، قمنا بزيادة مجموعة التدريب بأفضل مبارياتها في مجموعة بيانات الأخبار WMT19. يستخدم تقديمنا الأساسي محولًا قياسيًا ، بينما تستخدم عمليات الإرسال المتباينة محولات متعددة التشفير للانضمام إلى الأقوال السابقة. يحقق تقديمنا الأساسي 56.7 BLEU من جانب الوكيل (ar → de) ، متفوقًا على النظام الأساسي الذي يوفره منظمو المهام بأكثر من 13 نقطة BLEU. علاوة على ذلك ، وفقًا لتقييم تم إجراؤه على مجموعة من الأمثلة المصممة بعناية ، فإن بنية التشفير المتعدد قادرة على إنشاء ترجمات أكثر تماسكًا.', 'es': 'Este documento describe las presentaciones de la Universidad de Maryland a la tarea compartida de WMT20 sobre traducción de chat. Nos centramos en traducir las expresiones del lado del agente del inglés al alemán. Comenzamos con un modelo de transformador estándar estándar basado en BPE entrenado con las novedades de WMT17 y lo ajustamos con los datos de entrenamiento en el dominio proporcionados. Además, aumentamos el conjunto de entrenamiento con sus mejores partidos en el conjunto de datos de noticias del WMT19. Nuestra presentación principal utiliza un Transformer estándar, mientras que nuestras presentaciones contrastantes utilizan Transformers de múltiples codificadores para atender a enunciados anteriores. Nuestra presentación principal alcanza 56,7 BLEU en el lado del agente (es→de), superando en más de 13 puntos BLEU un sistema de referencia proporcionado por los organizadores de la tarea. Además, de acuerdo con una evaluación de un conjunto de ejemplos cuidadosamente diseñados, la arquitectura de múltiples codificadores es capaz de generar traducciones más coherentes.', 'fr': "Cet article décrit les soumissions de l'Université du Maryland à la tâche partagée WMT20 sur la traduction du chat. Nous nous concentrons sur la traduction des énoncés côté agent de l'anglais vers l'allemand. Nous sommes partis d'un modèle de transformateur standard standard basé sur le BPE, formé avec les actualités WMT17 et nous l'avons affiné avec les données de formation internes fournies. De plus, nous enrichissons l'ensemble d'entraînement avec ses meilleures correspondances dans le jeu de données d'actualités WMT19. Notre soumission principale utilise un Transformer standard, tandis que nos soumissions contrastives utilisent des transformateurs multi-encodeurs pour répondre aux énoncés précédents. Notre soumission principale atteint 56,7 UEBL côté agent (en→de), surpassant un système de base fourni par les organisateurs de tâches de plus de 13 points BLEU. De plus, selon une évaluation d'un ensemble d'exemples soigneusement conçus, l'architecture multi-encodeur est capable de générer des traductions plus cohérentes.", 'pt': 'Este artigo descreve os envios da Universidade de Maryland para a Tarefa Compartilhada do WMT20 sobre Tradução de Bate-papo. Nós nos concentramos na tradução de enunciados do lado do agente do inglês para o alemão. Partimos de um modelo de transformador padrão baseado em BPE pronto para uso treinado com notícias WMT17 e o ajustamos com os dados de treinamento no domínio fornecidos. Além disso, aumentamos o conjunto de treinamento com suas melhores correspondências no conjunto de dados de notícias do WMT19. Nosso envio primário usa um Transformer padrão, enquanto nossos envios contrastivos usam Transformers com vários codificadores para atender a enunciados anteriores. Nossa submissão primária atinge 56,7 BLEU no lado do agente (en→de), superando um sistema de linha de base fornecido pelos organizadores da tarefa em mais de 13 pontos BLEU. Além disso, de acordo com uma avaliação de um conjunto de exemplos cuidadosamente projetados, a arquitetura multi-encoder é capaz de gerar traduções mais coerentes.', 'ru': 'Этот документ описывает представления Университета Мэриленда к Общей задаче WMT20 на Переводе Чата. Мы фокусируемся на переводе высказываний на стороне агента с английского на немецкий. Мы начали с готовой стандартной модели трансформатора на основе BPE, обученной новостям WMT17, и отрегулировали ее с помощью предоставленных данных для обучения в домене. Кроме того, мы дополняем тренировочный набор лучшими матчами в наборе данных новостей WMT19. В нашем первичном представлении используется стандартный трансформатор, в то время как в наших контрастных представлениях используются мультикодирующие трансформаторы для учета предыдущих высказываний. Наша первичная подача достигает 56,7 BLEU на стороне агента (en→de), превосходя базовую систему, предоставленную организаторами задачи, более чем на 13 пунктов BLEU. Кроме того, согласно оценке на наборе тщательно разработанных примеров, архитектура мультикодера способна генерировать более согласованные переводы.', 'zh': '本文马里兰大学 WMT20 共事翻译。 注意将摄端语从英语翻译成德语。 吾自今 BPE 之准变压器始,教之以 WMT17 新闻 ,教之以域数。 此外又以 WMT19 新闻数集之最佳者项来扩充训练集。 吾主提交用格之 Transformer,而吾等比用多编码器 Transformers 以处前语。 要在摄端(en→de)上至于56.7 BLEU,比于任组织者基线系统高出13 BLEU分以上。 此外以精心设计示例评估,多编码器架构能成连贯之译。', 'ja': 'この論文では、メリーランド大学がチャット翻訳に関するWMT 20共有タスクに提出したものについて説明します。エージェント側の発言を英語からドイツ語に翻訳することに重点を置いています。私たちは、WMT 17ニュースでトレーニングされた既製のBPEベースの標準変圧器モデルから始め、提供されたドメイン内トレーニングデータで微調整しました。さらに、WMT 19ニュースデータセットで最高の一致をトレーニングセットに拡張します。当社の主な提出物は標準的なトランスフォーマーを使用し、対照的な提出物は以前の発話に対応するためにマルチエンコーダのトランスフォーマーを使用しています。当社の主な提出物は、エージェント側（ en→ de ）で56.7 BLEUを達成し、タスクオーガナイザーが提供するベースラインシステムを13点以上上回っています。さらに、慎重に設計された一連の例に対する評価によれば、マルチエンコーダアーキテクチャは、より一貫性のある翻訳を生成することができる。', 'hi': 'यह पेपर मैरीलैंड विश्वविद्यालय के चैट अनुवाद पर WMT20 साझा कार्य के लिए प्रस्तुतियों का वर्णन करता है। हम अंग्रेजी से जर्मन में एजेंट-साइड उच्चारण का अनुवाद करने पर ध्यान केंद्रित करते हैं। हमने एक ऑफ-द-शेल्फ बीपीई-आधारित मानक ट्रांसफॉर्मर मॉडल से शुरू किया जो WMT17 समाचार के साथ प्रशिक्षित किया गया था और इसे प्रदान किए गए इन-डोमेन प्रशिक्षण डेटा के साथ ठीक-ठाक किया गया था। इसके अलावा, हम WMT19 समाचार डेटासेट में अपने सर्वश्रेष्ठ मैचों के साथ प्रशिक्षण सेट को बढ़ाते हैं। हमारे प्राथमिक सबमिशन एक मानक ट्रांसफॉर्मर का उपयोग करता है, जबकि हमारे contrastive प्रस्तुतियाँ पिछले कथनों में भाग लेने के लिए बहु-एन्कोडर ट्रांसफॉर्मर का उपयोग करते हैं। हमारा प्राथमिक सबमिशन एजेंट पक्ष (en→de) पर 56.7 BLEU प्राप्त करता है, जो 13 से अधिक BLEU बिंदुओं द्वारा कार्य आयोजकों द्वारा प्रदान की गई बेसलाइन प्रणाली को पीछे छोड़ देता है। इसके अलावा, ध्यान से डिज़ाइन किए गए उदाहरणों के एक सेट पर मूल्यांकन के अनुसार, बहु-एन्कोडर आर्किटेक्चर अधिक सुसंगत अनुवाद उत्पन्न करने में सक्षम है।', 'ga': 'Déanann an páipéar seo cur síos ar aighneachtaí Ollscoil Maryland don Tasc Comhroinnte WMT20 ar Aistriúchán Comhrá. Dírímid ar chainteanna gníomhairí a aistriú ó Bhéarla go Gearmáinis. Chuireamar tús le múnla caighdeánach claochladán atá bunaithe ar BPE atá ar an tseilf agus a cuireadh oiliúint air le nuacht WMT17 agus rinneamar mionchoigeartú air leis na sonraí oiliúna in-fhearainn a cuireadh ar fáil. Ina theannta sin, cuirimid leis an tacar oiliúna lena mheaitseálacha is fearr i dtacar sonraí nuachta WMT19. Úsáideann ár bpríomhaighneacht Trasfhoirmeoir caighdeánach, agus úsáideann ár n-aighneachtaí codarsnacha Claochladáin il-ionchódóra chun freastal ar chainteanna roimhe seo. Baineann ár bpríomhaighneacht amach 56.7 BLEU ar thaobh na ngníomhairí (en→de), rud a sháraíonn córas bunlíne a chuir na heagraithe tasc ar fáil le níos mó ná 13 phointe BLEU. Ina theannta sin, de réir meastóireachta ar thacar samplaí atá deartha go cúramach, tá an ailtireacht il-ionchódóra in ann aistriúcháin níos soiléire a ghiniúint.', 'hu': 'Ez a tanulmány bemutatja a Maryland Egyetem beadványait a WMT20 Shared Task on Chat Fordításhoz. Az ügynökoldali szavak fordítására összpontosítunk angolról németre. A WMT17 hírekkel kiképzett BPE alapú szabványos transzformátormodellből indultunk, és finomhangoltuk a tartományon belüli képzési adatokkal. Ezenkívül a WMT19 híradataiban található legjobb mérkőzésekkel bővítjük az edzőkészletet. Elsődleges beküldésünk egy szabványos transzformátort használ, míg a kontrasztos beküldésünk többkódolós transzformátort használ a korábbi kimondásokhoz. Elsődleges beadványunk az ügynöki oldalon 56,7 BLEU-t ér el (en de), amely több mint 13 BLEU ponttal felülmúlja a feladatszervezők által biztosított alaprendszert. Ezenkívül a gondosan megtervezett példák értékelése szerint a többkódoló architektúra képes koherensebb fordításokat generálni.', 'ka': 'ამ დოკუმენტი მარილანდის სუნივერტის შეტყობინებების WMT20 საზოგადომი საქაღალდე შესაძლებელად აღწერა. ჩვენ ინგლისოდან გერმანეთისთვის ადვნენტის მხარეს გარგუნდეს. ჩვენ დავიწყეთ WMT17 ინფორმაციის მოდელი, რომელიც BPE-დაბათებული სტანდარტრანფერის მოდელიდან დავიწყეთ და ამას დააკეთებეთ მონაცემებით მონაცემებით. დამატებით, ჩვენ გავაკეთებთ საუკეთესო მონაცემები WMT19 მონაცემების სეტში. ჩვენი პირველური განმხმარება გამოყენებს სტანდარტრანფერმა, მაგრამ ჩვენი კონტრანსტიგური განმხმარებები მრავალური კონტრანფორმაციის განმხმარებელი გამ ჩვენი პირველური დამუშაობა 56.7 BLEU ადვნენტის მხარეს (en de), რომელიც უფრო მეტი BLEU წერტილებით დამუშაობენ სამუშაო სისტემა, რომელიც სამუშაო ორგანიზატორიები დამატებით, მრავალ კოდირების არქტიქტურაცია უფრო მსგავსი გადაწყვეტილების შესაძლებელია.', 'el': 'Η παρούσα εργασία περιγράφει τις υποβολές του Πανεπιστημίου του Μέριλαντ στην κοινή εργασία WMT20 για τη μετάφραση συνομιλίας. Εστιάζουμε στη μετάφραση προφορών από τα αγγλικά στα γερμανικά. Ξεκινήσαμε από ένα τυποποιημένο μοντέλο μετασχηματιστή βασισμένο σε BPE εκπαιδευμένο με ειδήσεις και το τελειοποιήσαμε με τα παρεχόμενα δεδομένα κατάρτισης εντός του τομέα. Επιπλέον, εμπλουτίζουμε το εκπαιδευτικό σύνολο με τους καλύτερους αγώνες του στο σύνολο δεδομένων ειδήσεων του WMT19. Η κύρια υποβολή μας χρησιμοποιεί έναν τυποποιημένο μετασχηματιστή, ενώ οι αντίθετες υποβολές μας χρησιμοποιούν μετασχηματιστές πολλαπλών κωδικοποιητών για να παρακολουθήσουν προηγούμενες δηλώσεις. Η κύρια υποβολή μας επιτυγχάνει 56.7 BLEU από την πλευρά των πρακτόρων (en de), ξεπερνώντας ένα σύστημα βάσης που παρέχεται από τους διοργανωτές εργασιών με περισσότερους από 13 πόντους BLEU. Επιπλέον, σύμφωνα με αξιολόγηση σε ένα σύνολο προσεκτικά σχεδιασμένων παραδειγμάτων, η αρχιτεκτονική πολλαπλών κωδικοποιητών είναι σε θέση να παράγει πιο συνεκτικές μεταφράσεις.', 'kk': 'Бұл қағаз Мариландың университетінің WMT20 ортақ тапсырмасына WMT20 ортақ тапсырмасына жіберілгенін анықтайды. Ағылшын тілінен неміс тіліне аудару үшін көңіл береміз. Біз WMT17 жаңалықтарымен оқылған стандартты transformer үлгісінен бастадық. Оларды домендегі оқыту деректерімен жақсы түзеттік. Қосымша, WMT19 жаңалық деректер қорындағы ең жақсы сәйкестіктерімен оқыту бағдарламасын көтеріп келеміз. Негізгі жіберіміз стандартты түрлендіруші қолданылады, бірақ контрастырлық жіберушілеріміз бірнеше кодтарды түрлендірушілерді алдыңғы сөздерге қатынау үшін қолданыла Негізгі тапсырмамыз 56,7 BLEU агент жағында (en de) жеткізеді, тапсырма бағдарламаларының 13 BLEU нүктелерінен артық жеткізетін негізгі жүйесіне жеткізеді. Сонымен қатар, бірнеше кодтар архитектурасы көптеген түрлендірілген мәселелердің бағалауына сәйкес келеді.', 'mk': 'Овој весник ги опишува поднесувањата на Универзитетот во Мериленд на WMT20 Shared Task on Chat Translation. Се фокусираме на преведувањето на изразите од страна на агентот од англиски на германски. We started from an off-the-shelf BPE-based standard transformer model trained with WMT17 news and fine-tuned it with the provided in-domain training data.  Покрај тоа, го зголемуваме тренингот со најдобрите совпаѓања во новинскиот компјутер WMT19. Нашето примарно поднесување користи стандарден Трансформер, додека нашите контрастни поднесувања користат мултикодерски Трансформери за да присуствуваат на претходните изрази. Нашето примарно поднесување достигнува 56,7 БЛЕ на страната на агентот (en de), надминувајќи го основниот систем обезбеден од организаторите на задачите за повеќе од 13 БЛЕ поени. Покрај тоа, според оценката на сет внимателно дизајнирани примери, мултикодерската архитектура е во можност да генерира покохерентни преведувања.', 'it': "Questo articolo descrive i contributi dell'Università del Maryland al WMT20 Shared Task on Chat Translation. Ci concentriamo sulla traduzione di espressioni lato agente dall'inglese al tedesco. Siamo partiti da un modello standard di trasformatore basato su BPE di serie addestrato con WMT17 news e perfezionato con i dati di formazione in-domain forniti. Inoltre, ampliamo il set di allenamento con le sue migliori partite nel set di notizie WMT19. La nostra presentazione primaria utilizza un Transformer standard, mentre le nostre presentazioni contrastanti utilizzano Transformer multi-encoder per assistere alle dichiarazioni precedenti. La nostra presentazione primaria raggiunge 56,7 BLEU sul lato agente (en de), superando un sistema di base fornito dagli organizzatori delle attività di più di 13 punti BLEU. Inoltre, secondo una valutazione su una serie di esempi attentamente progettati, l'architettura multi-encoder è in grado di generare traduzioni più coerenti.", 'ms': "This paper describes the University of Maryland's submissions to the WMT20 Shared Task on Chat Translation.  We focus on translating agent-side utterances from English to German.  Kami bermula dari model pengubah piawai berdasarkan BPE off-the-shelf dilatih dengan berita WMT17 dan menyesuaikannya dengan data latihan dalam domain yang disediakan. In addition, we augment the training set with its best matches in the WMT19 news dataset.  Our primary submission uses a standard Transformer, while our contrastive submissions use multi-encoder Transformers to attend to previous utterances.  Our primary submission achieves 56.7 BLEU on the agent side (en de), outperforming a baseline system provided by the task organizers by more than 13 BLEU points.  Selain itu, menurut penilaian pada set contoh yang direka dengan hati-hati, arkitektur multi-pengekod mampu menghasilkan terjemahan yang lebih konsisten.", 'lt': 'Šiame dokumente apibūdinami Marylando universiteto pareiškimai WMT20 bendrai uždaviniui dėl pokalbių vertimo. Mes sutelkiame dėmesį į agent ų kalbų vertimą iš anglų į vokiečių. We started from an off-the-shelf BPE-based standard transformer model trained with WMT17 news and fine-tuned it with the provided in-domain training data.  Be to, mes didiname mokymo rinkinį geriausiais WMT19 naujienų rinkinyje. Mūsų pirminis pristatymas naudoja standartinį Transformatorių, o mūsų kontrastiniai pristatymai naudoja daugiakodorius Transformatorius, kad galėtų dalyvauti ankstesniuose pareiškimuose. Our primary submission achieves 56.7 BLEU on the agent side (en de), outperforming a baseline system provided by the task organizers by more than 13 BLEU points.  Be to, remiantis kruopščiai suprojektuotų pavyzdžių vertinimu, daugiakodifikatorių architektūra gali sukurti nuoseklesnius vertimus.', 'ml': 'ഈ പത്രത്തില്\u200d മേരില്ലാന്\u200dഡിന്\u200dറെ യൂണിവേഴ്സിറ്റിയിലേക്ക് വിവരിച്ചുകൊടുക്കുന്നുണ്ടെങ്കില്\u200d ചാറ്റ്  ഇംഗ്ലീഷില്\u200d നിന്നും ജര്\u200dമ്മനിലേക്കും വാക്കുകള്\u200d പരിഭാഷപ്പെടുത്തുന്നു. ഞങ്ങള്\u200d വിഎംടി17 വാര്\u200dത്തയുമായി പഠിപ്പിക്കുന്ന ഒരു ഷെല്\u200dഫില്\u200d നിന്ന് തുടങ്ങി ഡോംമെയിന്\u200d ട്രെയിനിങ്ങളുടെ ഡേറ്റാന്\u200d ഡേറ്റാന കൂടാതെ, WMT19 വാര്\u200dത്തകാര്യങ്ങളുടെ ഏറ്റവും നല്ല മായ്ച്ചുകളുമായി ട്രെയിനിന്\u200d സെറ്റ് കൂട്ടുക നമ്മുടെ പ്രധാന സമ്മതം ഒരു സാധാരണ ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ഉപയോഗിക്കുന്നു. നമ്മുടെ എതിര്\u200dപ്പുള്ള സമ്മതം മുമ്പുള്ള വാക്കുകളി നമ്മുടെ പ്രധാനപ്പെടുത്തുന്നത് എജന്\u200dറിന്\u200dറെ (en de) ഭാഗത്ത് 56.7 ബില്ലൂ എത്തുന്നു. ജോലി സംഘടനക്കാര്\u200d 13 ബിലിയു പോയിന്\u200dറുകള്\u200d കൂ അതുകൊണ്ടും, സൂക്ഷ്മതയോടെ നിര്\u200dമ്മിക്കപ്പെട്ട ഉദാഹരണങ്ങളുടെ കൂട്ടത്തില്\u200d ഒരു വിലാസപ്രകാരം പ്രകാരം പല-കോഡെര്\u200d സ്ഥാനം കൂടു', 'no': 'Denne papiret beskriver Universiteten av Maryland sin tillegg til WMT20 delt oppgåve om prateomsetjinga. Vi fokuserer på å oversette agent-side-uttrykk frå engelsk til tysk. Vi starta frå eit standard transformeringsmodell som er basert på BPE-hjelp som er trent med WMT17 nyhetar og fint oppsett med dei oppgjevne treningsdata i domenet. I tillegg auker vi øvingssettet med den beste treff i WMT19-datasettet. Vårt primært innsending brukar ein standard transformer, mens våre kontrastende innsendingar brukar fleire koder for å delta på førre uttrykk. Vårt primære opplysning oppnår 56,7 BLEU på agentsside (en de), som utfører eit grunnlinjesystem som oppgåveorganisatorene har tilgjengeleg med meir enn 13 BLEU-punkt. I tillegg til eit evaluering på eit sett av forsiktige eksemplar, kan multikoderingsarkitekturen laga meir samanlige omsetjingar.', 'mt': "Dan id-dokument jiddeskrivi s-sottomissjonijiet tal-Università ta' Maryland lill-Ħidma Konġunta WMT20 dwar it-Traduzzjoni taċ-Ċatt. Aħna niffokaw fuq it-traduzzjoni ta’ dikjarazzjonijiet min-naħa tal-aġenti mill-Ingliż għall-Ġermaniż. Ibdew minn mudell standard tat-trasformatur ibbażat fuq il-BPE off-the-shelf imħarreġ bl-aħbarijiet WMT17 u rranġajnu bid-dejta pprovduta ta’ taħriġ fid-dominju. Barra minn hekk, aħna nżidu s-sett tat-taħriġ bl-aħjar logħob tiegħu fis-sett tad-dejta tal-aħbarijiet WMT19. Is-sottomissjoni primarja tagħna tuża Transformer standard, filwaqt li s-sottomissjonijiet kontrastivi tagħna jużaw Transformers b’kodiċi multiplu biex jattendu għal dikjarazzjonijiet preċedenti. Is-sottomissjoni primarja tagħna tikseb 56.7 BLEU fuq in-naħa tal-a ġent (en de), li tippreżenta sistema bażi pprovduta mill-organizzaturi tal-kompiti b’aktar minn 13-il punt BLEU. Barra minn hekk, skont evalwazzjoni fuq sett ta’ eżempji mfassla bir-reqqa, l-arkitettura b’ħafna kodifikaturi tista’ tiġġenera traduzzjonijiet aktar koerenti.", 'pl': 'Niniejszy artykuł opisuje zgłoszenia Uniwersytetu Maryland do WMT20 Shared Task on Chat Translation. Skupiamy się na tłumaczeniu wypowiedzi po stronie agenta z angielskiego na niemiecki. Zaczęliśmy od standardowego modelu transformatora opartego na BPE, przeszkolonego z wiadomościami WMT17 i dopracowaliśmy go z dostarczonymi w domenie danymi szkoleniowymi. Dodatkowo uzupełniamy zestaw treningowy o najlepsze dopasowania w zbiorze informacji WMT19. Nasze główne zgłoszenie wykorzystuje standardowy Transformer, podczas gdy nasze kontrastywne zgłoszenia używają transformerów wielokodorowych, aby uwzględnić poprzednie wypowiedzi. Nasza główna zgłoszenie osiąga 56.7 BLEU po stronie agenta (en de), przewyższając system bazowy dostarczany przez organizatorów zadań o więcej niż 13 punktów BLEU. Ponadto, zgodnie z oceną zestawu starannie zaprojektowanych przykładów, architektura wielokodorowa jest w stanie generować bardziej spójne tłumaczenia.', 'sr': 'Ovaj papir opisuje podatke Univerziteta Marylanda na WMT20 podeljeni zadatak o prevodu èeta. Fokusiramo se na prevod govora sa strane agenta od engleskog na njemaèkog. Počeli smo od standardnog transformatorskog modela, osnovanog na granici BPE, obučenog sa WMT17 vijestima, i ispravljali ga sa podacima o obuci u domenu. Osim toga, povećavamo obuku sa svojim najboljim poklapanjem u podacima WMT19. Naša primarna podnošenja koristi standardni transformator, dok naše kontrastivne podnošenje koriste multikoderske transformere da bi prisustvovali prethodnim rečenicama. Naša primarna predstava postiže 56,7 BLEU na strani agenta (en de), koji je nadmašio osnovni sistem koji su organizatori zadataka pružili više od 13 BLEU bodova. Osim toga, prema procjeni o setu pažljivo dizajniranih primjera, multikoderska arhitektura može stvoriti saslušnije prevode.', 'ro': 'Această lucrare descrie depunerile Universității din Maryland la misiunea partajată WMT20 privind traducerea chat. Ne concentrăm pe traducerea expresiilor din partea agentului din engleză în germană. Am pornit de la un model standard de transformator bazat pe BPE, instruit cu știrile WMT17 și l-am reglat fin cu datele de instruire furnizate în domeniu. În plus, îmbunătățim setul de antrenament cu cele mai bune meciuri din setul de știri WMT19. Trimiterea noastră principală folosește un Transformer standard, în timp ce trimiterile noastre contrastante folosesc Transformers multi-encoder pentru a participa la declarațiile anterioare. Trimiterea noastră primară atinge 56,7 BLEU pe partea de agent (en de), depășind un sistem de referință furnizat de organizatorii sarcinilor cu mai mult de 13 puncte BLEU. Mai mult decât atât, conform unei evaluări pe un set de exemple atent concepute, arhitectura multi-encoder este capabilă să genereze traduceri mai coerente.', 'si': 'මේ පැත්තේ මැරිලෑන්ඩ්ගේ විශ්වාසිත්තාව විශ්වාසයේ WMT20 සමාගත වැඩසටහන් විස්තර කරනවා. අපි ඉංග්\u200dරීසි වලින් ජර්මන් වලින් නියෝජිත වලින් පැත්තක් පරිවර්තනය කරනවා. අපි පටන් ගත්තා WMT17 වාර්තාව සඳහා ප්\u200dරධානය කරන්න ප්\u200dරාමාණික ප්\u200dරවේශකයෙන් ප්\u200dරාරංතිකරණය සඳහා ප්\u200dරාරංතිකරණය කරලා තිය ඒ වගේම, අපි WMT19 වාර්තාවක් තොරතුරු සෙට් එක්ක ප්\u200dරශ්නයක් වැඩ කරනවා. අපේ ප්\u200dරධාන සම්බන්ධතාවය ප්\u200dරමාණික වෙනස් කරන්න ප්\u200dරයෝජනය කරනවා, අපේ සම්බන්ධතාවක් සම්බන්ධතාවක් විසින් විසි අපේ ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධාන පද්ධතිය 56.7 BLUE වෙනවා නියෝජිත පැත්ත (en de), පද්ධතිය ප්\u200dරධාන පද්ධතියෙන් ප්\u200dරධ ඒවගේම, පරික්ෂාවෙන් සැකසුම් සිද්ධ විද්\u200dයාපිත උදාහරණයක් ගැන විශ්ලේෂණයක් අනුවෙන් විශ්ලේෂණය කරන්න පුළුවන', 'sv': 'Denna uppsats beskriver University of Marylands bidrag till WMT20 Shared Task on Chat Translation. Vi fokuserar på att översätta yttranden från agentsidan från engelska till tyska. Vi började från en BPE-baserad standardtransformatormodell utbildad med WMT17 nyheter och finjusterade den med de tillhandahållna utbildningsdata inom domänen. Dessutom utökar vi träningsuppsättningen med dess bästa matchningar i WMT19 nyhetsdataset. Vår primära inlämning använder en standard Transformer, medan våra kontrastiva inlämningar använder multi-encoder Transformers för att hantera tidigare uttalanden. Vår primära inlämning uppnår 56,7 BLEU på agentsidan (sv de), vilket överträffar ett baslinjesystem som tillhandahålls av uppgiftsorganisatorerna med mer än 13 BLEU-poäng. Dessutom, enligt en utvärdering på en uppsättning noggrant utformade exempel, kan multi-encoder arkitektur generera mer sammanhängande översättningar.', 'so': 'Warqadan wuxuu ku qoraa jaamacadda Maryland wargelinta WMT20 oo lagu sharciyey shaqo la turjumo Chat. Waxaynu ku kalsoonaynaa af turjumista afka afka Ingiriiska ilaa Jarmalka. Waxaan ka bilaabnay model isbedelka caalamiga ah ee BPE-ku saleysan, taasoo lagu baray warar WMT17 ah, waxaana ku qornay macluumaad aad u heshay waxbarashada internetka. Intaas waxaa dheer, waxaynu ku dareynaa koorasyada waxbarashada oo la dhigo mid u fiican mid ku filan macluumaadka WMT19. Madaxalkayaga ugu horeeyay wuxuu isticmaalaa kaalmada turjumista, isla markaasna suuqyadayada kala duwan ayaa isticmaalaya turjumidda badan si uu ugu tago hadallada hore. Madaxalka ugu horeeyay waxay gaadhaa 56.7 BLEU dhinaca dalbashada (en de), oo ay sameeyaan nidaamka hoose ee shaqaalaha ay qabanqaabiyaan wax ka badan 13 barta BLEU. Sida uu ku qiimeeyo tusaalooyin si taxadar ah loo qoray, dhismaha dhismaha badan ee kookookooyinka ayaa sameyn kara turjubaan badan.', 'ta': "This paper describes the University of Maryland's submissions to the WMT20 Shared Task on Chat Translation.  ஆங்கிலத்திலிருந்து ஜெர்மன் மொழிகளை மொழிபெயர்ப்போம். நாங்கள் WMT17 செய்திகளுடன் பயிற்சிக்கப்பட்டுள்ள நிலைமாற்றம் மாதிரியில் இருந்து தொடங்கினோம் வெளிப்பாட்டில் இருந்து அதை நன்ற மேலும், WMT19 செய்தி தகவல் அமைப்பில் சிறந்த பொருத்தங்களுடன் பயிற்சி அமைப்பை சேர்க்கிறோம். எங்கள் முதல் பரிமாற்றம் ஒரு நிலையான மாற்றுதலை பயன்படுத்துகிறது, எங்கள் எதிர்பார்ப்பு ஒப்புகள் பல குறியீட்டு மாற்றுபவர்களை ம எங்கள் முதன்மை பரிமாற்றம் 56. 7 பிலியு முகவரியின் பக்கத்தில் பெறுகிறது (en de), செயல் நிறுவுபவர்கள் 13 பிலியு புள்ளிகள் மூலம் வழங்கப்பட்ட மேலும், கவனமாக வடிவமைக்கப்பட்ட உதாரணங்களின் ஒரு சேர்ப்பு பொருளால், பல குறியீட்டாக்கி அமைப்பு மேலும் இணைய மொழிபெயர்ப்புகளை", 'mn': 'Энэ цаас Мариландын Их Сургуулийн WMT20-ын хуваалтын ажлыг Чат орчуулахын тулд тайлбарлаж байна. Бид англи хэлэхээс Герман руу агентын талаар яриаг орчуулахад анхаарлаа төвлөрүүлдэг. Бид WMT17 мэдээллээр сургалтын стандарт шилжүүлэгч загвараас эхэлсэн. Мөн холбоотой сургалтын өгөгдлийг сайжруулсан. Мөн бид WMT19 мэдээллийн сангийн хамгийн сайн тоглоомоор сургалтыг нэмэгдүүлнэ. Бидний анхны хүлээн авах нь стандарт Трансформатчийг ашигладаг. Харин бидний эсрэг хүлээн авах нь олон кодер Трансформатчийг өмнө хэлэлцүүлэхэд ашигладаг. Бидний анхны төлөвлөгөө нь агентын талд 56.7 БЛЕУ гарч ирнэ, ажлын зохион байгуулагчид 13 БЛЕУ цэгээс илүү олон цэгээр өгсөн суурь шугам системээс гадна гарч ирнэ. Дараа нь, анхаарлын төсөөлөгдсөн жишээн дээр олон коддогч архитектур илүү хамааралтай орчуулах боломжтой.', 'ur': "This paper describes the University of Maryland's submissions to the WMT20 Shared Task on Chat Translation. ہم انگلیسی سے جرمانی تک اگنٹ-سائڈ کی باتوں کو ترجمہ کرنے پر تمرکز کرتے ہیں۔ ہم نے WMT17 خبریں کے ساتھ آموزش کی استاندارڈ ترنسفور موڈل سے شروع کیا اور اس کو ڈومین ترینسی ڈیٹ کے ساتھ ٹھیک ترینسی کر دیا۔ اس کے علاوہ، ہم نے اس ترینس سٹ کو WMT19 نیویس ڈیٹ سٹ میں بہترین مطابق کے ساتھ بڑھا دیا۔ ہماری اولین تسلیم ایک استاندارڈ ترنسفور کا استعمال کرتا ہے، حالانکہ ہمارے کنٹرسیٹ تسلیم کے مطابق multi-encoder ترنسفورٹ استعمال کرتا ہے۔ ہماری اولین تحویل 56.7 بلیوس (en de) پر آئینٹ کے کنارے پر پہنچ جاتی ہے، جو 13 بلیوس پوینٹوں سے زیادہ زیادہ دیے جاتے ہیں تابع سازمان کرنے والوں کے ذریعہ ایک بنسلین سیستم سے زیادہ کام کرتی ہیں۔ اور اس کے مطابق، اچھی طرح طرح کی مثال کے ایک سٹ کے مطابق ایک ارزیابی کے مطابق، بہت سی انکوڈر معماری زیادہ مطابق ترجمہ پیدا کر سکتی ہے.", 'uz': "Bu qogʻoz Marylanding universitetet WMT20 shartlangan vazifani chat tarjima qiladigan vazifani anglatadi. Biz ingliz tildan Olmonchaga bir so'zlarni tarjima qilamiz. Biz WMT17 хабар bilan o'rganilgan BPE asosida standard transformer modeldan boshladik va uni domen taʼminlovchi maʼlumot bilan yaxshi ko'rsatdik. Ko'pchilik, biz WMT19 haqida eng yaxshi oʻxshash moslamalarni qo'shish mumkin. Bizning asosiy imkoniyatlarimiz andoza Transformer ishlatiladi, ammo bizning tarkibi imkoniyatlar oldingi so'zlarga qarshi uchun muloqodlar tarjimalarini foydalanadi. Bizning asosiy imzolarimiz agent (en de) bilan 56.7 BLEU (56.7 BLEU) bajaradi, vazifa mualliflari bilan 13 BLEU nuqtdan ortiq ishlatilgan asosiy tizimni bajaradi. Kodlash uchun ko'pchilik arxituvchisi bir tarjima qiladigan misollarda qiymatga ega bo'ladi. Kodlash mualliflari bir necha tarjimalarni yaratishi mumkin.", 'vi': 'Tờ giấy này mô tả những kiến nghị của Đại học Maryland về giải pháp chia s ẻ của WM20. Chúng tôi tập trung vào dịch những lời từ tiếng Anh sang tiếng Đức. Chúng tôi bắt đầu từ một mẫu máy biến hình dựa trên tầng cao được huấn luyện bằng bản tin WRT17 và chỉnh lại nó với dữ liệu huấn luyện nội địa cung cấp. Thêm vào đó, chúng tôi tăng cường tập luyện với những kết quả tốt nhất trong bộ dữ liệu thời sự WRT19. Việc đệ trình đầu tiên của chúng tôi sử dụng một transformer tiêu chuẩn, còn những thư trình bày tương phản của chúng tôi thì dùng robot biến hình đa mã hóa để nghe lời trước. Việc đệ trình đầu tiên của chúng tôi đạt đến 56 Hơn nữa, dựa trên một đánh giá về một loạt các ví dụ được thiết kế cẩn thận, cấu trúc đa mã hóa có thể tạo ra một bản dịch phù hợp hơn.', 'da': 'Dette dokument beskriver University of Marylands indlæg til WMT20 Shared Task on Chat Translation. Vi fokuserer på at oversætte udtalelser fra agentside fra engelsk til tysk. Vi startede fra en BPE-baseret standardtransformermodel uddannet med WMT17 nyheder og finjusterede den med de medfølgende træningsdata. Derudover udvider vi træningssættet med de bedste matches i WMT19 nyhedsdatasyttet. Vores primære indsendelse bruger en standard Transformer, mens vores kontrastive indsendelser bruger multi-encoder Transformers til at tage sig af tidligere udtalelser. Vores primære indsendelse opnår 56,7 BLEU på agentsiden (en de), hvilket overgår et basissystem leveret af opgavearrangørerne med mere end 13 BLEU point. Ifølge en evaluering på et sæt omhyggeligt designede eksempler er multi-encoder arkitekturen i stand til at generere mere sammenhængende oversættelser.', 'bg': 'Тази статия описва предложенията на Университета в Мериленд към споделената задача за превод на чат. Фокусираме се върху превода на речи от страна на агента от английски на немски. Започнахме от стандартен трансформатор, базиран на рафта, обучен с новини и го настроихме с предоставените в областта данни за обучение. Освен това разширихме тренировъчния набор с най-добрите му мачове в информационния набор. Нашето основно подаване използва стандартен трансформатор, докато нашите контрастни подавания използват мулти-кодер трансформатори, за да присъстват на предишни изказвания. Нашето основно подаване постига 56.7 от страна на агента, което надминава базовата система, предоставена от организаторите на задачите с повече от 13 точки. Освен това, според оценка на набор от внимателно проектирани примери, архитектурата на многокодер е в състояние да генерира по-последователни преводи.', 'hr': 'Ovaj papir opisuje podatke Univerziteta Marylanda na WMT20 zajednički zadatak o prevodu razgovora. Fokusiramo se na prevod govora sa strane agenta iz engleskog na njemačkog. Počeli smo sa standardnog transformatora model na osnovu BPE-a izvan police obučenog s WMT17 vijestima i dobro smo ga ispravili podacima o obuci u domenu. Osim toga, povećavamo obuku sa najboljim poklapanjem u podacima WMT19. Naša primarna podnošenja koristi standardni transformator, dok naše kontrastivne podnošenje koriste multikoderske transformere da bi prisustvovali prethodnim govorom. Naša primarna podnošenja postiže 56,7 BLEU na strani agenta (en de), nadmašući početni sustav koji organizatori zadataka pružaju više od 13 BLEU bodova. Osim toga, prema procjeni o skupini pažljivo dizajniranih primjera, multikoderska arhitektura može stvoriti saslušnije prevode.', 'nl': 'Dit artikel beschrijft de inzendingen van de Universiteit van Maryland aan de WMT20 Shared Task on Chat Translation. Wij richten ons op het vertalen van uitingen aan de kant van de agent van het Engels naar het Duits. We zijn begonnen met een standaard BPE-based standaard transformator model getraind met WMT17 nieuws en verfijnd met de verstrekte in-domain trainingsgegevens. Daarnaast breiden we de trainingsset uit met de beste matches in de WMT19 news dataset. Onze primaire inzending maakt gebruik van een standaard Transformer, terwijl onze contrastieve inzendingen multi-encoder Transformers gebruiken om eerdere uitingen te behandelen. Onze primaire inzending behaalt 56.7 BLEU aan de agentenzijde (nl) en presteert beter dan een basissysteem dat door de taakomganisaties wordt geleverd met meer dan 13 BLEU-punten. Bovendien is de multi-encoder architectuur volgens een evaluatie op een reeks zorgvuldig ontworpen voorbeelden in staat om meer coherente vertalingen te genereren.', 'fa': 'این کاغذ تحویل دانشگاه ماریلند به کار مشترک WMT20 در مورد ترجمه چات توصیف می\u200cکند. ما تمرکز میکنیم روی ترجمه کردن کلمات های مامور کنار از انگلیسی به آلمانی. ما از یک مدل تغییر\u200cپذیر استاندارد بنیاد BPE که با خبرهای WMT17 آموزش داده شده بود شروع کردیم و با داده\u200cهای آموزش\u200cپذیری در دامنه\u200cی دومین تغییر دادیم. علاوه بر این، ما مجموعه آموزش را با بهترین مسابقه\u200cهایش در مجموعه اطلاعات WMT19 افزایش می\u200cدهیم. تسلیم اولیه ما از یک تغییرات استاندارد استفاده می\u200cکند، در حالی که تسلیم\u200cهای متفاوت ما از تغییرات متفاوت\u200cکننده\u200cها استفاده می\u200cکنند تا به سخنرانی قبلی حاضر شوند. تحويل اوليه ما 56.7 بلوئوپ از طرف مامور (en de) رسيده است، با انجام سيستم پايه\u200cخط\u200cبندي که توسط سازمان\u200cکنندگان وظيفه\u200cها با بيشتر از 13 نقطه بلوئوپ پيدا شده است. در ضمن، بر اساس ارزیابی بر مجموعه مثالهای طراحی به دقت، معماری چندین کدهر قادر است که ترجمه\u200cهای متعددی بیشتری را ایجاد کند.', 'de': 'Dieser Beitrag beschreibt die Beiträge der University of Maryland zur WMT20 Shared Task on Chat Translation. Wir konzentrieren uns auf die Übersetzung von agentenseitigen Äußerungen aus dem Englischen ins Deutsche. Wir haben von einem Standard-BPE-basierten Standard-Transformator-Modell angefangen, das mit WMT17 News trainiert wurde und mit den bereitgestellten In-Domain-Trainingsdaten verfeinert wurde. Darüber hinaus erweitern wir das Trainingsset um die besten Matches im WMT19 News Dataset. Unsere primäre Einreichung verwendet einen Standard Transformer, während unsere kontrastiven Einreichungen Multi-Encoder Transformer verwenden, um frühere Äußerungen zu bearbeiten. Unsere primäre Einreichung erreicht 56.7 BLEU auf der Agentenseite (de) und übertrifft ein von den Aufgabenorganisationen bereitgestelltes Basissystem um mehr als 13 BLEU Punkte. Darüber hinaus ist die Multi-Encoder-Architektur in der Lage, kohärentere Übersetzungen zu generieren.', 'id': 'Kertas ini menjelaskan pengiriman Universitas Maryland ke WMT20 Shared Task on Chat Translation. Kami fokus pada menerjemahkan ucapan dari sisi agen dari Inggris ke Jerman. Kami mulai dari model transformator standar berdasarkan BPE off-the-shelf dilatih dengan berita WMT17 dan memperbaikinya dengan data pelatihan di domain yang diberikan. Selain itu, kita menambahkan set latihan dengan pertandingan terbaik di dataset berita WMT19. Pengiriman utama kami menggunakan Transformer standar, sementara pengiriman kontras kami menggunakan Transformers multi-encoder untuk menghadiri ucapan sebelumnya. Our primary submission achieves 56.7 BLEU on the agent side (en de), outperforming a baseline system provided by the task organizers by more than 13 BLEU points.  Moreover, according to an evaluation on a set of carefully-designed examples, the multi-encoder architecture is able to generate more coherent translations.', 'af': "Hierdie papier beskryf die Universiteit van Maryland se onderskrywings na die WMT20 Gedeelde Opdrag op Chat Translation. Ons fokus op die vertaling van agent-side uitspraak van Engels na Duits. Ons het begin van 'n af-die-shelf BPE-gebaseerde standaard transformeermodel wat opgelei is met WMT17 nuus en dit gevind het met die verskaf in-domein onderwerp data. In addition, we increase the training set with its best matches in the WMT19 news set. Ons primêre onderdrag gebruik 'n standaard Transformeerder, terwyl ons kontrastiewe onderdragte gebruik multi- enkoder Transformeerders om by vorige uitdrukkings te bied. Ons primêre onderdrag het 56.7 BLES op die agent-kant (en de), uitgevoer van 'n basis-stelsel wat deur die taak organiseerders deur meer as 13 BLEU-punte verskaf word. Ook, volgens 'n evaluasie op 'n stel van versigtig-ontwerp voorbeelde, kan die multikoder-arkitektuur meer koherente vertalings genereer.", 'sw': "This paper describes the University of Maryland's submissions to the WMT20 Shared Task on Chat Translation.  Tunaweza lengo la kutafsiri hotuba za mwingi kutoka Kiingereza hadi Ujerumani. Tulianza kutoka kwenye mtindo wa mabadiliko wa kiwango cha msingi wa BPE ulioelekezwa na habari za WMT17 na kupunguza vizuri kwa taarifa zilizotolewa ndani ya mafunzo. Kwa nyongeza, tunaongeza mafunzo yenye michezo bora zaidi katika seti ya habari za WMT19. Mawasiliano yetu ya msingi yanatumia Transfer wa Standard, wakati matamshi yetu yanayopingana kutumia WaTransformers wengi ili kuhudhuria kauli zilizopita. Ujumbe wetu wa msingi unafanikiwa BLEU 56.7 upande wa shirika hilo (en de), kuonyesha mfumo wa msingi unaotolewa na waandaaji wa kazi kwa zaidi ya pointi 13 BLEU. Zaidi ya hayo, kwa mujibu wa tathmini ya baadhi ya mifano zilizotengenezwa kwa tahadhari, ujenzi wa kodi wa kadhaa unaweza kutengeneza tafsiri za pamoja zaidi.", 'ko': '본고는 마리란 대학이 WMT20 채팅 번역 공유 임무에 대한 제출을 묘사한다.우리는 대리단의 말을 영어에서 독일어로 번역하는 데 전념했다.우리는 기존의 BPE 기반의 표준transformer 모델을 시작으로 이 모델은 WMT17뉴스를 사용하여 교육을 실시했고 제공된 역내 교육 데이터를 사용하여 이를 미세하게 조정했다.그 밖에 우리는 WMT19 뉴스 데이터 집합의 가장 좋은 일치로 훈련 집합을 확충했다.우리의 주요 제출은 표준 변환기를 사용하고, 우리의 비교 제출은 다중 인코더 변환기를 사용하여 이전의 발언을 처리한다.우리의 주요 제출은 에이전트(en de)가 56.7BLEU에 달했고 임무 조직자가 제공한 기선 시스템보다 13개의 BLEU점이 높았다.그 밖에 한 그룹의 정성스럽게 설계된 예시에 대한 평가에 따라 다중 인코더 구조는 더욱 일관된 번역을 생성할 수 있다.', 'am': 'ይህ ገጽ የመርየላንድ ዩንቨርስቲ ለWMT20 የተሰራጨውን ስራ በChat ትርጓሜ ላይ ያሳያል፡፡ እንግሊዝኛ ጀምሮ ጀምሮ ጀምሮ ጀምሮ ጀምሮ ጀርመን ያሉትን ቃላትን በመግለጽ ላይ እናቆማለን፡፡ በWMT17 ዜና የተጠቃጀን እና የውይይት ትምህርት ዳታዎችን በመጠቀም የBPE ስርዓት የተደረገውን የድምፅ ስርዓት ሞዴል ጀምረን፡፡ በተጨማሪም በWMT19 ዜና ዳታተር ውስጥ የተሻለውን ትምህርት ማድረግ እናጨምርባታለን፡፡ የፊደል አዋጅ አዋጅ የፊደል ትርጉም በተጠቀም ጊዜ በተቃውሞ ንግግር ለመጠቀም የፊደል የፊደል ቅርጾችን ለብዙዎች የፊደል ቅርጾች ተርጓሚዎች ይጠቀማሉ፡፡ የፊደል መልዕክታችን 56.7 ቢሊዩን በኤንቨርስቲ (en de) በተጨማሪው የስራ አካባቢዎች በ13 ቢልዩን ነጥቦች የሚጨመር የቤዜሊን ድምፅ ማሳየት ነው፡፡ በተጨማሪም በተመሳሳይ ምሳሌዎች ላይ እንደተፈጸመ፣ የብዙው የኮድ መሠረት መሠረት አብዛኛውን ትርጉም ማድረግ ይችላል፡፡', 'tr': 'Bu kagyz Marylandyň Uniwersitetiniň WMT20 Çäp terjimelerinde beýleki zadyny tassyklaýar. Biz adatça-tarap sözlerini iňlisçe Almança terjime etmäge üns berýäris. WMT17 haberler bilen eğitilen, bPE tabanly bir sistemden başladyk we domain eğitim maglumaty bilen edilen standart transformer modelden başladyk. Munuň üçin WMT19 haberdar setirinde has gowy eşleşmeleri bilen üýtgederis. Öňki çykyşymyz standart terjimeçisini ulanýar, we kontrast suratlarymyz öňki sözleriňe gatnaşmak üçin bir ködler terjimeçisini ulanýarlar. Biziň ilkinji teslimatymyz ajaýyr tarapyndan 56.7 BLEU-ny (en de) ýetip bilýär, işi düzenleyicileriň tarapyndan 13-den fazla BLEU noktalary tarapyndan berilen baz sistemasyny çykarýar. Mundan soňra, ünsli tasarlanýan örän çykyşyna görä, köp-ködler arhitektura köpräk terjime edip bilýär.', 'bn': 'এই পত্রিকাটি বিশ্ববিদ্যালয়ের বিশ্ববিদ্যালয়ের তদন্তের বর্ণনা করেছে বিশ্ববিদ্যালয়ের বিশ্ববিদ্যালয়ে We focus on translating agent-side utterances from English to German.  We started from an off-the-shelf BPE-based standard transformer model trained with WMT17 news and fine-tuned it with the provided in-domain training data.  এছাড়াও আমরা উইএমটি১৯ সংবাদ তথ্যের সেরা খেলায় প্রশিক্ষণের সেট যোগ করি। আমাদের প্রাথমিক প্রতিষ্ঠান একটি স্ট্যান্ডার্ন্যান্ডারফ্রান্সফার ব্যবহার করে, আর আমাদের বিরোধীতা প্রদান করা অনেক কোডা আমাদের প্রাথমিক প্রতিষ্ঠানটি এজেন্টের পাশে ৫৬. এছাড়াও, সাবধানে পরিকল্পিত উদাহরণের বিভিন্ন মূল্য অনুসারে বহুক্ত কোডারের স্থাপনাগুলো আরো অনুবাদ তৈরি করতে পারে।', 'sq': "This paper describes the University of Maryland's submissions to the WMT20 Shared Task on Chat Translation.  Ne përqëndrohemi në përkthimin e shprehjeve nga ana e agjentit nga anglisht në gjerman. Filluam nga një model i transformuesit standart i bazuar në BPE, i stërvitur me lajmet WMT17 dhe i përshtatëm me të dhënat e trajnimit në domeni. Përveç kësaj, ne shtojmë grupin e trajnimit me ndeshjet më të mira të tij në grupin e të dhënave të lajmeve WMT19. Përdorimi ynë kryesor përdor një Transformues standard, ndërsa paraqitjet tona kontraste përdorin Transformuesit multikodues për të ndjekur shprehjet e mëparshme. Our primary submission achieves 56.7 BLEU on the agent side (en de), outperforming a baseline system provided by the task organizers by more than 13 BLEU points.  Moreover, according to an evaluation on a set of carefully-designed examples, the multi-encoder architecture is able to generate more coherent translations.", 'hy': 'Այս հոդվածը նկարագրում է Մարիլանդի համալսարանի ներկայացումները ԱՄԹ20-ի Համաշխարհային Խոսային թարգմանման Համաշխարհային Միջական Միջական Միջական Միջական Միջական Միջական Միջա Մենք կենտրոնանում ենք անգլերենից գերմաներեն արտահայտությունների թարգմանման վրա: Մենք սկսեցինք ԲՓԵ-ի անդաշնական ստանդարտ ձևափոխման մոդելի վրա, որը պատրաստվել է ՎՄԹ17 նորություններով և կազմակերպել այն բիզնեսում տրամադրված ուսումնասիրության տվյալների հետ: Ավելին, մենք ավելացնում ենք կրթության համակարգը իր լավագույն համապատասխաններով աշխարհի MT19 նորությունների համակարգում: Մեր հիմնական ներկայացումը օգտագործում է ստանդարտ տրանսֆերմեր, մինչդեռ մեր հակադրական ներկայացումները օգտագործում են բազմակոդավոր տրանսֆերմերներ նախորդ արտահայտությունների համար: Մեր հիմնական ներկայացումը հասնում է 56.7 ԲԼԵՆ-ի գործիչների կողմից (en de), որը գերազանցում է առաջին համակարգը, որը կազմակերպողների կողմից տրամադրված է ավելի քան 13 ԲԼԵՆ-ի միավորով: Ավելին, ըստ մի շարք ուշադիր նախագծված օրինակների գնահատման, բազմակոդավոր ճարտարապետությունը կարող է ստեղծել ավելի համապատասխանատու թարգմանություններ:', 'ca': "Aquest article descriu les presentacions de la Universitat de Maryland al WMT20 Shared Task on Chat Translation. We focus on translating agent-side utterances from English to German.  Vam començar amb un model de transformador estàndard basat en BPE, entrenat amb notícies WMT17, i l'vam ajustar amb les dades d'entrenament en domini proporcionades. A més, augmentem el conjunt d'entrenament amb les seves millors partides del conjunt de dades de notícies WMT19. La nostra presentació primària utilitza un Transformer estàndard, mentre les nostres presentacions contrastàries utilitzen Transformers multicodificadors per atendre a expressions anteriors. La nostra presentació primària aconsegueix 56,7 BLEU a la banda de l'agent (en de), superant un sistema de base proporcionat pels organitzadors de tasques en més de 13 punts BLEU. A més, segons una evaluació d'un conjunt d'exemples ben dissenyats, l'arquitectura multicodificadora pot generar traduccions més coherents.", 'et': 'Käesolevas dokumendis kirjeldatakse Marylandi Ülikooli esitusi WMT20 vestluse tõlkimise jagatud ülesandele. Keskendume agendipoolsete sõnade tõlkimisele inglise keelest saksa keelde. Alustasime olemasolevast BPE-põhisest standardtrafo mudelist, mis oli koolitatud WMT17 uudistega, ja täpsustasime seda esitatud domeenisiseste koolitusandmetega. Lisaks täiendame treeningkomplekti parimate vastetega WMT19 uudiste andmekogumis. Meie esmane esitus kasutab standardset Transformerit, samas kui meie kontrastsed esitused kasutavad mitme kodeerijaga Transformereid, et hoolitseda varasemate kõnede eest. Meie esmane esitamine saavutab agendi poolel 56,7 BLEU (en de), mis ületab ülesannete korraldajate pakutava baassüsteemi rohkem kui 13 BLEU punkti võrra. Hoolikalt kavandatud näidete hindamise kohaselt suudab mitme kodeerija arhitektuur luua sidusamaid tõlkeid.', 'cs': 'Tento článek popisuje příspěvky University of Maryland k WMT20 Shared Task on Chat Translation. Zaměřujeme se na překlad agentských výroků z angličtiny do němčiny. Začali jsme od standardního modelu transformátoru založeného na BPE, vyškoleného s WMT17 novinkami a doladili ho s poskytnutými in-domain tréninkovými daty. Kromě toho rozšiřujeme tréninkovou sadu o nejlepší shody v datasetu WMT19. Naše primární příspěvky používají standardní Transformer, zatímco naše kontrastní příspěvky používají multi-kodérové Transformery, aby se věnovali předchozím výrokům. Naše primární předložení dosahuje 56.7 BLEU na straně agenta (en de), překonává základní systém poskytovaný organizátory úkolů o více než 13 BLEU body. Navíc podle hodnocení na sadě pečlivě navržených příkladů je architektura multikodéru schopna generovat koherentnější překlady.', 'fi': 'Tässä artikkelissa kuvataan Marylandin yliopiston ehdotuksia WMT20 Shared Task on Chat Translation -ohjelmaan. Keskitymme agenttipohjaisten sanontojen kääntämiseen englannista saksaksi. Aloitimme valmiista BPE-pohjaisesta vakiomuuntajamallista, joka oli koulutettu WMT17-uutisilla ja hienosäädimme sitä toimitetuilla koulutustiedoilla. Lisäksi täydennämme harjoitussettiä parhailla otteluilla WMT19 uutisaineistossa. Ensisijainen lähetyksemme käyttää vakiomuunninta, kun taas kontrastilähetyksemme käyttävät monikooderimuunninta aikaisempien sanontojen käsittelyyn. Ensisijainen lähetyksemme saavuttaa 56,7 BLEU agenttipoolella (en de), mikä ylittää tehtävien järjestäjien tarjoaman perusaikataulujärjestelmän yli 13 BLEU-pisteellä. Huolellisesti suunniteltujen esimerkkien arvioinnin mukaan monikooderiarkkitehtuuri pystyy myös luomaan johdonmukaisempia käännöksiä.', 'az': 'Bu kağıt Maryland Üniversitesinin WMT20 şəkli Tərcümə haqqında şəkli olaraq təbliğ etdiklərini təsdiqləyir. İngilizdən Almanca ağant tərəfindən sözləri tercümə etməyə odaqlanırıq. WMT17 xəbəri ilə təhsil edilmiş standart transformer modelindən başladıq və domain təhsil verilməsi məlumatları ilə təhsil etdik. Əvvəlcə, WMT19 xəbər veri qutusu ilə təhsil qutusunu artırdıq. Bizim ilk təklifimiz standart transformer istifadə edir, müxtəlif təklifimiz çoxlu kodlayıcı transformatçıları əvvəlki sözlərə katılmaq üçün istifadə edir. Bizim ilk təklifimiz, a ğantın tərəfində 56.7 BLEU nəticəsinə yetirir, 13 BLEU nöqtələrindən daha çox təklif etdikləri təklif sistemindən üstün olur. Daha sonra, dikkatli tasarlanmış nümunələrin müqayisəsinə görə, çoxlu kodlayıcı arhitektura daha uyğun tercümələr yarada bilər.', 'bs': 'Ovaj papir opisuje podatke Univerziteta Marylanda na WMT20 zajednički zadatak o prevodu razgovora. Fokusiramo se na prevod govora sa strane agenta iz engleskog na njemačkog. Počeli smo sa standardnog transformatorskog modela, osnovanog na granici BPE-a, obučenog sa WMT17 vijestima i ispravljali ga sa pruženim podacima o obuci u domenu. Osim toga, povećavamo obuku sa najboljim poklapanjem u podacima WMT19. Naša primarna podnošenja koristi standardni transformator, dok naše kontrastivne podnošenje koriste multikoderske transformere da bi prisustvovali prethodnim govorom. Naša primarna predstava postiže 56,7 BLEU na strani agenta (en de), nadmašući početni sistem koji organizatori zadataka pružaju više od 13 bodova BLEU-a. Osim toga, prema procjeni o setu pažljivo dizajniranih primjera, multikoderska arhitektura može stvoriti saslušnije prevode.', 'he': "This paper describes the University of Maryland's submissions to the WMT20 Shared Task on Chat Translation.  אנחנו מתמקדים בתרגום מילים צד הסוכן מאנגלית לגרמנית. התחלנו ממודל משינוי סטנדרטי מבוסס על BPE מחוץ למדף מאומן עם חדשות WMT17 ומתאים אותו עם נתוני האימונים בתחום המסופקים. בנוסף, אנחנו מגדילים את קבוצת האימונים עם התאמות הטובות ביותר שלה בסט הנתונים WMT19. השימוש העיקרי שלנו משתמש בטרנספורר סטנדרטי, בעוד השימוש ההתנגדי שלנו משתמש בטרנספורטרים multi-encoder כדי להשתתף במאמרים קודמים. השימוש הראשי שלנו מגיע ל-56.7 BLEU בצד הסוכן (en de), ביצוע מערכת בסיסית שנספקה על ידי מארגני המשימה על ידי יותר מ-13 נקודות BLEU. חוץ מזה, על פי עריכה על קבוצת דוגמאות מעוצבות בזהירות, הארכיטקטורה המולקודרת מסוגלת ליצור תרגומות יותר תואם.", 'sk': 'Ta prispevek opisuje prispevke Univerze v Marylandu k skupni nalogi WMT20 o prevajanju klepetov. Osredotočamo se na prevajanje izjav agentov iz angleščine v nemščino. Začeli smo s standardnim transformatorskim modelom, ki temelji na BPE, usposobljenim z WMT17 novicami, in ga natančno nastavili z zagotovljenimi podatki o usposabljanju. Poleg tega smo nabor treningov dopolnili z najboljšimi tekmami v naboru novic WMT19. Naša primarna predložitev uporablja standardni transformator, medtem ko naša kontrastna predložitev uporablja večkodirni transformatorji za uporabo prejšnjih izjav. Naša primarna predložitev doseže 56,7 BLEU na strani agenta (en de), kar presega osnovni sistem, ki ga zagotavljajo organizatorji opravil, za več kot 13 točk BLEU. Poleg tega je glede na oceno skrbno oblikovanih primerov arhitektura večkodirnikov sposobna ustvariti bolj skladne prevode.', 'ha': "Wannan karatun describes the University of Maryland's Submitions to the WMT20 Shared Takar on Chat Translate. Tuna fokus a kan fassarar magana na-side daga Ingiriya zuwa Jarmaya. Mun fara daga wata misalin transformation mai bassi da BPA-na-shelf wanda aka yi wa shirin da WMT17 na da tsari da aka bãyar da data na tsarin-Domen. Ina ƙara, za mu ƙara tsarin mafarin da ke da mafi kyaun mazauni cikin tsarin da na WMT19. Madagaskiyõyinmu na farko yana amfani da wani Transformer mai daidaita, kuma da masu motsi da musuluntu masu motsi, sai su yi amfani da multi-kode Transformers zuwa ga zaman lasari. Ubuntu na farko da aikinMu yana sãmu 55.7 BLEU a kan the actor side (en de), outperforming a system-base-line wanda the aikin organizers offers by over 13 BLEU points. Furan, kamar an ƙaddara a kan wasu misãlai masu taƙaita da aka ƙaddara shi, ana iya iya ƙiƙiro multi-kode-na'urar fassarar masu ƙaranci.", 'jv': 'Peraké iki rambaran isungkampun Universite Maryèn kanggo ngirim werak-werak WWT 2 Nang Tarjamahan kanggo Bewerak-terjamahan Awakdhéwé nglanggar-langgar kuwi nggambar apat-langgar kuwi basa Inggris kanggo aleman. We Started from an off-the-shell BPer-supported Standard transformer model that was contextual with Wt16 information and Fine-tuned it with the given in-domain Learning data. Nambah, awak dhéwé ngerti resan ngono dolanan sing luwih nggawe gerakan ning dataset sing luwih dumateng Winter 19. Awak dhéwé nggunakake tualkar gunakake Transformer awak dhéwé, terus nggunakake tarjamahan sing gunakake multi-koder Awakdhéwé éntuk tanggal nggawe barang-sangan sing luwih (en de), nggawe barang sistem sing nyimpen nggawe barang nggawe barang sistem sing nyebuté nggawe barang sistem sing perusahaan mrisi (task) Label, mengko karo asserti kanggo nambah sing dibutungane gambar, akeh multi-koder sing bisa ngelangke tarjamahan sing berarti.', 'bo': 'ཤོག་བྱང་འདིས་མ་རི་ལེནཌི་ཡིག་སློབ་ཆེན་ལོག་གྱི་WMT20 དང་མཉམ་སྤྱོད་ཀྱི་བྱ་འགུལ་ལ་འགྲེལ་བཤད་བྱེད་ཀྱི་ཡོད། ང་ཚོས་དབྱིན་ཡིག་ལས་སྐད་འགའ་ཕྱོགས་ཀྱི་གནད་དོན་དག་ལ་དབྱིན་ཡིག་གནང་། We started from an off-the-shelf BPE-based standard transformer model trained with WMT17 news and fine-tuned it with the provided in-domain training data. འོན་ཀྱང་། ང་ཚོས་WMT19 གསར་འགུལ་སྒྲིག་ཆ་འཕྲིན་གྱི་ཐད་རིམ་གྱི་མཐུན་སྒྲིག་འཛུགས་དུ་རྒྱས་གཏོང་། ང་ཚོའི་རྩ་བའི་དབྱིབས་གདོང་སྤྲོད་ཀྱིས་ཚད་རྩ་སྒྲིག་འགོད་པ་ཞིག་བེད་སྤྱོད་ཀྱི་ཡོད་ཚད། གདོང་རིས་བཤད་ཀྱིས་འདྲ་སྒྲིག ང་ཚོའི་རྨན་གཞུང་གི་ཞབས་ཞུ་འཇུག་སྣོད་ཀྱི་ཕྱོགས་ལས་ཉེན་ཆས་ལྡན་པ་(en de)དང་མཉམ་དུ་འཇུག་སྣོད་འཛིན་གྱི་ལས་རིམ་སྒྲིག འོན་ཀྱང་། ལྟ་བུའི་དཔེར་བརྗོད་ཀྱི་ནང་ལྟ་བུའི་དཔེར་བརྗོད་ནི་ཆ་རྩིས་བ་སྒྲིག་ཆ་རྩིས་འཁོར་གྱི་སྒྲིག་འགོད་འདི་ཕལ་ཆེན་སྐྱེས'}
{'en': 'Fast Interleaved Bidirectional Sequence Generation', 'ar': 'توليد تسلسل ثنائي الاتجاه سريع التشابك', 'es': 'Generación rápida de secuencias bidireccionales intercaladas', 'fr': 'Génération rapide de séquences bidirectionnelles entrelacées', 'pt': 'Geração de Sequência Bidirecional Intercalada Rápida', 'ja': '高速インターリーブ双方向シーケンス生成', 'zh': '疾错双向序成', 'hi': 'तेजी से interleaved द्विदिश अनुक्रम पीढ़ी', 'ru': 'Быстрое создание двунаправленной чередующейся последовательности', 'ga': 'Giniúint Seicheamhach Déthreo Idirdhuilleach Thapa', 'ka': 'სწრაფად ინტერფექციონალური ორედირექციონალური სკენსის შექმნა', 'el': 'Γρήγορη αλληλεπίδραση αμφίδρομης παραγωγής αλληλουχίας', 'it': 'Generazione rapida di sequenze bidirezionali interleave', 'hu': 'Gyors kölcsönös kétirányú sorozatgyártás', 'lt': 'Greitai tęsiamos dvikryptinės sekos generacijos', 'kk': 'Тез интерфейсті екі бағытты реттеу құрылғысы', 'mk': 'Генерација на брзи дворечни секвенции', 'ms': 'Penjanaan Sekuensi Dua Arah Terlambat Cepat', 'ml': 'വേഗം ഇന്റര്\u200dലീവ് ചെയ്ത ബൈഡഡിയല്\u200d സെക്കന്\u200dസ് ജനിപ്പിക്കുക', 'mn': 'Хурдан интерфейсийн хоёр багын дараагийн үржүүлэлт', 'no': 'Fast mellomsnittsfarga generering av to retning sekvens', 'mt': 'Fast Interleaved Bidirectional Sequence Generation', 'pl': 'Szybkie wzajemne generowanie sekwencji dwukierunkowej', 'si': 'වේගයෙන් අන්තර්ජාත්මක දෙපාර්ශික ප්\u200dරමාණය', 'ro': 'Generarea rapidă a secvențelor bidirecționale', 'sr': 'Brzo uključena generacija dvosmjerne sekvence', 'sv': 'Snabb inbördes dubbelriktad sekvensgenerering', 'ur': 'تیز انٹرلیف دودئیرسیٹن سکوئنس پیدائش', 'so': 'Fast Interleased Bidirectional Sequence Generation', 'ta': 'விரைவான இடைவெளியிடப்பட்ட இருதிசை வரிசை உருவாக்கம்', 'vi': 'Sắp xếp các dãy vuông', 'uz': 'Comment', 'da': 'Hurtig indbyrdes bidirektionel sekvensgenerering', 'bg': 'Бързо генериране на двупосочни последователности', 'de': 'Schnelle interleaved bidirektionale Sequenz-Generierung', 'nl': 'Snelle interleaved bidirectionele sequentie generatie', 'ko': '빠른 교차 양방향 시퀀스 생성', 'id': 'Fast Interleaved Bidirectional Sequence Generation', 'fa': 'نسخه سریع ترکیب دوجهانی', 'tr': 'Çaltylyk Bidirectional Girişi', 'sw': 'Uzalishaji wa mfululizo wa Bidirectional kwa haraka', 'af': 'Vinnige Interleaved Bidirectional Sequence Generasie', 'am': 'quick-mask-type', 'sq': 'Gjenerimi i Shpejtë i Sekuencës Dydrejtuese', 'hy': 'արագ ներթափանցված երկուղղային հաջորդականության ստեղծման', 'bn': 'Fast Interleaved Bidirectional Sequence Generation', 'bs': 'Brzo uključena generacija dvosmjerne sekvence', 'az': 'Hızlı İ-yönəlmiş İ-yönəlli Sequence Ünvanı', 'et': 'Kiire kahesuunalise järjestuse genereerimine', 'hr': 'Brzo uključena generacija dvosmjerne sekvence', 'fi': 'Nopea kaksisuuntaisen sekvenssin luominen', 'ca': 'La generació de seqüències bidireccionals de ràpid intercanvi', 'cs': 'Rychlé vzájemné generování obousměrných sekvencí', 'jv': 'drawable-action', 'he': 'יצירת רצף שתי כיוונים במהירות', 'bo': 'Fast Interleaved Bidirectional Sequence Generation', 'ha': 'KCharselect unicode block name', 'sk': 'Hitro ustvarjanje dvosmernega zaporedja med seboj'}
{'en': 'Independence assumptions during sequence generation can speed up inference, but parallel generation of highly inter-dependent tokens comes at a cost in quality. Instead of assuming independence between neighbouring tokens (semi-autoregressive decoding, SA), we take inspiration from bidirectional sequence generation and introduce a decoder that generates target words from the left-to-right and right-to-left directions simultaneously. We show that we can easily convert a standard architecture for unidirectional decoding into a bidirectional decoder by simply interleaving the two directions and adapting the word positions and selfattention masks. Our interleaved bidirectional decoder (IBDecoder) retains the model simplicity and training efficiency of the standard Transformer, and on five machine translation tasks and two document summarization tasks, achieves a decoding speedup of ~2x compared to autoregressive decoding with comparable quality. Notably, it outperforms left-to-right SA because the independence assumptions in IBDecoder are more felicitous. To achieve even higher speedups, we explore hybrid models where we either simultaneously predict multiple neighbouring tokens per direction, or perform multi-directional decoding by partitioning the target sequence. These methods achieve speedups to 4x11x across different tasks at the cost of 1 BLEU or 0.5 ROUGE (on average)', 'es': 'Las suposiciones de independencia durante la generación de secuencias pueden acelerar la inferencia, pero la generación paralela de tokens altamente interdependientes tiene un costo de calidad. En lugar de asumir la independencia entre los tokens vecinos (decodificación semiautorregresiva, SA), nos inspiramos en la generación de secuencias bidireccionales e introducimos un decodificador que genera palabras objetivo desde las direcciones de izquierda a derecha y de derecha a izquierda simultáneamente. Demostramos que podemos convertir fácilmente una arquitectura estándar para decodificación unidireccional en un decodificador bidireccional simplemente intercalando las dos direcciones y adaptando las posiciones de las palabras y las máscaras de autoatención. Nuestro decodificador bidireccional entrelazado (IBDecoder) mantiene la simplicidad del modelo y la eficiencia de entrenamiento del Transformer estándar, y en cinco tareas de traducción automática y dos tareas de resumen de documentos, logra una velocidad de decodificación de ~ 2 veces en comparación con la decodificación autorregresiva con una calidad comparable. En particular, supera a SA de izquierda a derecha porque las suposiciones de independencia en IBDecoder son más afortunadas. Para lograr aceleraciones aún mayores, exploramos modelos híbridos en los que predecimos simultáneamente múltiples tokens vecinos por dirección o realizamos una decodificación multidireccional dividiendo la secuencia objetivo. Estos métodos logran aceleraciones de 4 a 11 veces en diferentes tareas al costo de 1 BLEU o 0.5 ROUGE (en promedio)', 'pt': 'As suposições de independência durante a geração de sequência podem acelerar a inferência, mas a geração paralela de tokens altamente interdependentes tem um custo de qualidade. Em vez de assumir a independência entre tokens vizinhos (decodificação semiautoregressiva, SA), nos inspiramos na geração de sequência bidirecional e introduzimos um decodificador que gera palavras-alvo das direções da esquerda para a direita e da direita para a esquerda simultaneamente. Mostramos que podemos facilmente converter uma arquitetura padrão para decodificação unidirecional em um decodificador bidirecional simplesmente intercalando as duas direções e adaptando as posições das palavras e as máscaras de autoatenção. Nosso decodificador bidirecional intercalado (IBDecoder) mantém a simplicidade do modelo e a eficiência de treinamento do Transformer padrão e, em cinco tarefas de tradução automática e duas tarefas de resumo de documentos, atinge uma velocidade de decodificação de ~2x em comparação com a decodificação autorregressiva com qualidade comparável. Notavelmente, ele supera o SA da esquerda para a direita porque as suposições de independência no IBDecoder são mais favoráveis. Para atingir velocidades ainda maiores, exploramos modelos híbridos nos quais prevemos simultaneamente vários tokens vizinhos por direção ou realizamos decodificação multidirecional particionando a sequência de destino. Esses métodos atingem velocidades de 4x a 11x em diferentes tarefas ao custo de 1 BLEU ou 0,5 ROUGE (em média)', 'ar': 'يمكن أن تؤدي افتراضات الاستقلال أثناء إنشاء التسلسل إلى تسريع الاستدلال ، ولكن التوليد المتوازي للرموز شديدة الاعتماد على بعضها البعض يأتي بتكلفة من حيث الجودة. بدلاً من افتراض الاستقلال بين الرموز المميزة المجاورة (فك التشفير شبه التلقائي ، SA) ، فإننا نستلهم من إنشاء التسلسل ثنائي الاتجاه ونقدم وحدة فك ترميز تولد الكلمات المستهدفة من الاتجاهات من اليسار إلى اليمين ومن اليمين إلى اليسار في وقت واحد. نظهر أنه يمكننا بسهولة تحويل بنية قياسية لفك التشفير أحادي الاتجاه إلى وحدة فك ترميز ثنائية الاتجاه ببساطة عن طريق تشذير الاتجاهين وتكييف مواضع الكلمات وأقنعة الانتباه الذاتي. تحافظ وحدة فك التشفير ثنائية الاتجاه المشذرة (IBDecoder) على بساطة النموذج وكفاءة التدريب للمحول القياسي ، وفي خمس مهام للترجمة الآلية ومهمتين لتلخيص المستندات ، تحقق سرعة فك تشفير تبلغ 2x تقريبًا مقارنة بفك الترميز الذاتي بجودة مماثلة. والجدير بالذكر أنه يتفوق على SA من اليسار إلى اليمين لأن افتراضات الاستقلال في IBDecoder أكثر ملاءمة. لتحقيق تسريع أعلى ، نستكشف النماذج الهجينة حيث إما نتوقع في وقت واحد عدة رموز متجاورة لكل اتجاه ، أو نقوم بفك تشفير متعدد الاتجاهات عن طريق تقسيم التسلسل المستهدف. تحقق هذه الأساليب تسريعًا يصل إلى 4x-11x عبر مهام مختلفة بتكلفة 1 BLEU أو 0.5 ROUGE (في المتوسط)', 'fr': "Les hypothèses d'indépendance pendant la génération de séquences peuvent accélérer l'inférence, mais la génération parallèle de jetons hautement interdépendants a un coût en termes de qualité. Au lieu de supposer l'indépendance entre les jetons voisins (décodage semi-autorégressif, SA), nous nous inspirons de la génération de séquences bidirectionnelles et introduisons un décodeur qui génère des mots cibles de gauche à droite et de droite à gauche simultanément. Nous montrons que nous pouvons facilement convertir une architecture standard pour le décodage unidirectionnel en un décodeur bidirectionnel en entrelacant simplement les deux directions et en adaptant les positions des mots et les masques d'auto-attention. Notre décodeur bidirectionnel entrelacé (IBDecoder) conserve la simplicité du modèle et l'efficacité d'entraînement du Transformer standard. Pour cinq tâches de traduction automatique et deux tâches de synthèse de documents, il atteint une vitesse de décodage d'environ 2 fois plus rapide que le décodage autorégressif de qualité comparable. Notamment, il surpasse l'AS de gauche à droite car les hypothèses d'indépendance dans IBDecoder sont plus favorables. Pour obtenir des accélérations encore plus élevées, nous explorons des modèles hybrides dans lesquels nous prédisons simultanément plusieurs jetons voisins par direction ou effectuons un décodage multidirectionnel en partitionnant la séquence cible. Ces méthodes permettent d'atteindre des accélérations allant de 4 à 11 fois pour différentes tâches au coût de 1 UEBL ou 0,5 ROUGE (en moyenne)", 'ja': 'シーケンス生成中の独立性の仮定は推論を高速化することができますが、高度に相互依存したトークンの並列生成は、品質のコストがかかります。 隣接するトークン間の独立性（半自己回帰デコード、SA ）を想定する代わりに、双方向シーケンス生成からインスピレーションを得て、左から右、右から左方向から同時にターゲットワードを生成するデコーダを導入します。 一方向デコードの標準アーキテクチャを双方向デコーダに簡単に変換できることを示しています。 インターリーブされた双方向デコーダー（ IBDecoder ）は、標準トランスフォーマーのモデルの簡素さとトレーニング効率を維持し、5つの機械翻訳タスクと2つの文書要約タスクで、同等の品質の自動回帰デコードと比較して、約2倍のデコード速度を実現します。 特に、IBDecoderの独立性の仮定がより適切であるため、それは左から右へSAを上回っています。 さらに高速化を達成するために、方向ごとに複数の隣接トークンを同時に予測するか、ターゲットシーケンスを分割することによって多方向デコードを実行するハイブリッドモデルを探索します。 これらの方法は、1 BLEUまたは0.5ルージュ（平均）のコストで、異なるタスクにわたって4倍から11倍のスピードアップを達成します', 'zh': '序成者独立性设可疾推速,而并行相赖者令牌有质也。 无假邻令牌(半自动归解码,SA)之独立性,取灵感于双向序,引入一解码器,当解码器可以兼从左到右从右到左生单词。 吾言简而错之单词位与自注掩码,轻转单向解码准架构为双向解码器。 吾交双向解码器(IBDecoder)存准Transformer形简而教效率,且五机器翻译二文档摘要,与有质者自归解码,解码倍2。 值得注意者,其优于从左到右之SA,IBDecoder之独立而益宜也。 求其高下,索其混合,或同时而卜邻令牌,或区分而多向解码。 异务 4 倍–11 ,代为 1 BLEU 0.5 ROUGE(均)', 'hi': 'अनुक्रम पीढ़ी के दौरान स्वतंत्रता मान्यताएं अनुमान को गति दे सकती हैं, लेकिन अत्यधिक अंतर-निर्भर टोकन की समानांतर पीढ़ी गुणवत्ता में लागत पर आती है। पड़ोसी टोकन (अर्ध-ऑटोरिग्रेसिव डिकोडिंग, एसए) के बीच स्वतंत्रता को मानने के बजाय, हम द्विदिश अनुक्रम पीढ़ी से प्रेरणा लेते हैं और एक विकोडक पेश करते हैं जो बाएं से दाएं और दाएं-से-बाएं दिशाओं से एक साथ लक्ष्य शब्द उत्पन्न करता है। हम दिखाते हैं कि हम आसानी से यूनिडायरेक्शनल डिकोडिंग के लिए एक मानक वास्तुकला को द्विदिश विकोडक में परिवर्तित कर सकते हैं, बस दो दिशाओं को इंटरलीव करके और शब्द की स्थिति और आत्म-ध्यान मास्क को अनुकूलित करके। हमारे interleaved द्विदिश विकोडक (IBDecoder) मॉडल सादगी और मानक ट्रांसफॉर्मर के प्रशिक्षण दक्षता को बरकरार रखता है, और पांच मशीन अनुवाद कार्यों और दो दस्तावेज़ summarization कार्यों पर, तुलनीय गुणवत्ता के साथ autoregressive डिकोडिंग की तुलना में ~ 2x की एक डिकोडिंग स्पीडअप प्राप्त करता है। विशेष रूप से, यह बाएं-से-दाएं एसए को मात देता है क्योंकि IBDecoder में स्वतंत्रता मान्यताएं अधिक सम्मानजनक हैं। यहां तक कि उच्च स्पीडअप प्राप्त करने के लिए, हम हाइब्रिड मॉडल का पता लगाते हैं जहां हम या तो एक साथ प्रति दिशा कई पड़ोसी टोकन की भविष्यवाणी करते हैं, या लक्ष्य अनुक्रम को विभाजित करके बहु-दिशात्मक डिकोडिंग करते हैं। ये विधियां 1 BLEU या 0.5 रूज (औसतन) की कीमत पर विभिन्न कार्यों में 4x-11x के लिए speedups प्राप्त करती हैं', 'ru': 'Предположения о независимости во время генерации последовательности могут ускорить вывод, но параллельное генерации сильно взаимозависимых токенов приходит ценой качества. Вместо того, чтобы предполагать независимость между соседними токенами (полуавтономное регрессивное декодирование, SA), мы черпаем вдохновение из генерации двунаправленной последовательности и вводим декодер, который генерирует целевые слова из направления слева направо и справа налево одновременно. Мы показываем, что мы можем легко преобразовать стандартную архитектуру для однонаправленного декодирования в двунаправленный декодер, просто перемежая два направления и адаптируя позиции слов и маски самовнимания. Наш чередующийся двунаправленный декодер (IBDecoder) сохраняет простоту модели и эффективность обучения стандартного Трансформатора, а на пяти задачах машинного перевода и двух задачах обобщения документов достигает ускорения декодирования ~2x по сравнению с авторегрессивным декодированием с сопоставимым качеством. Примечательно, что он превосходит SA слева направо, потому что предположения о независимости в IBDecoder более удачны. Чтобы достичь еще более высоких скоростей, мы исследуем гибридные модели, где мы либо одновременно прогнозируем несколько соседних токенов в одном направлении, либо выполняем разнонаправленное декодирование путем разбиения целевой последовательности. Эти методы достигают ускорения до 4x-11x для различных задач по цене 1 BLEU или 0,5 ROUGE (в среднем)', 'ga': 'Is féidir le boinn tuisceana neamhspleáchais le linn giniúna seichimh tátal a bhrostú, ach tagann costas cáilíochta ar ghiniúint chomhthreomhar de chomharthaí idirspleácha. In ionad neamhspleáchas a ghlacadh idir comharthaí comharsanacha (díchódú leath-aischéimnitheach, SA), glacaimid inspioráid ó ghiniúint seicheamh déthreo agus tugaimid isteach díchódóir a ghineann spriocfhocail ó na treoracha clé go deas agus ó dheas go clé ag an am céanna. Léirímid gur féidir linn ailtireacht chaighdeánach le haghaidh díchódaithe aontreoch a thiontú go díchódóir déthreo go héasca tríd an dá threo a idirleathadh agus na suíomhanna focal agus maisc féinaird a oiriúnú. Coinníonn ár díchódóir déthreo idirdhuilleogach (IBDecoder) simplíocht mhúnla agus éifeachtúlacht oiliúna an Chaighdeáin Trasfhoirmeora, agus ar chúig thasc meaisín-aistriúcháin agus dhá thasc achoimrithe doiciméad, baintear amach luas díchódaithe ~2x i gcomparáid le díchódú uath-aischéimnitheach le cáilíocht inchomparáide. Go háirithe, is fearr leis na SA ó chlé go deas mar go bhfuil na boinn tuisceana neamhspleáchais in IDecoder níos boige. Chun luasghéarú níos airde fós a bhaint amach, déanaimid iniúchadh ar shamhlacha hibrideacha ina ndéanaimid réamh-mheastachán comhuaineach ar ilchomharthaí comharsanacha in aghaidh na treorach, nó ina ndéanaimid díchódú iltreoch tríd an sprioc-seicheamh a roinnt. Baineann na modhanna seo amach luas suas go 4x–11x thar thascanna éagsúla ar chostas 1 BLEU nó 0.5 ROUGE (ar an meán)', 'hu': 'A sorozatgyártás során a függetlenségi feltételezések felgyorsíthatják a következtetést, de a nagymértékben függő tokenek párhuzamos generálása minőségi költségekkel jár. Ahelyett, hogy függetlenséget vállalnánk a szomszédos tokenek között (félig-autoregresszív dekódolás, SA), inspirációt merítünk a kétirányú szekvencia generálásából és bevezetünk egy dekódot, amely egyidejűleg célszavakat generál balról jobbra és jobbról balra. Megmutatjuk, hogy az egyirányú dekódoláshoz szükséges szabványos architektúrát könnyen átalakíthatjuk kétirányú dekóderré, egyszerűen összekapcsolva a két irányt, illetve a szópozíciókat és az önfigyelem maszkokat. Az interleaved kétirányú dekódolónk (IBDecoder) megtartja a standard Transzformátor modellegyszerűségét és képzési hatékonyságát, és öt gépi fordítási feladat és két dokumentum összefoglalási feladat esetén ~2x dekódolási gyorsulást ér el a hasonló minőségű autoregresszív dekódoláshoz képest. Különösen azért, mert az IBDecoder függetlenségi feltételezései boldogabbak. A még nagyobb gyorsulás elérése érdekében hibrid modelleket vizsgálunk, ahol vagy egyszerre előrejelzünk több szomszédos tokent irányban, vagy többirányú dekódolást végezünk a célszekvencia partíciójával. Ezek a módszerek a különböző feladatok során 4x-11x gyorsulást érnek el 1 BLEU vagy 0,5 ROUGE áron (átlagosan)', 'el': 'Οι παραδοχές ανεξαρτησίας κατά τη διάρκεια της δημιουργίας ακολουθίας μπορούν να επιταχύνουν την εξαγωγή συμπερασμάτων, αλλά η παράλληλη παραγωγή εξαιρετικά αλληλοεξαρτώμενων σημάτων έρχεται με κόστος ποιότητας. Αντί να υποθέσουμε ανεξαρτησία μεταξύ γειτονικών σημάτων (ημι-αυτοανακριτική αποκωδικοποίηση, SA), αντλούμε έμπνευση από τη δημιουργία αμφίδρομης ακολουθίας και εισάγουμε έναν αποκωδικοποιητή που παράγει λέξεις-στόχους από την κατεύθυνση αριστερά-δεξιά και δεξιά-αριστερά ταυτόχρονα. Δείχνουμε ότι μπορούμε εύκολα να μετατρέψουμε μια τυποποιημένη αρχιτεκτονική για μονοκατευθυνόμενη αποκωδικοποίηση σε έναν αμφίδρομο αποκωδικοποιητή, απλά διασυνδεύοντας τις δύο κατευθύνσεις και προσαρμόζοντας τις θέσεις λέξεων και τις μάσκες αυτοπροσοχής. Ο παρεμβαλλόμενος αμφίδρομης αποκωδικοποιητής μας (διατηρεί την απλότητα του μοντέλου και την αποδοτικότητα εκπαίδευσης του τυποποιημένου μετασχηματιστή, και σε πέντε εργασίες μηχανικής μετάφρασης και δύο εργασίες σύνοψης εγγράφων, επιτυγχάνει μια επιτάχυνση αποκωδικοποίησης ~2σε σύγκριση με την αυτόματη αποκωδικοποίηση με συγκρίσιμη ποιότητα. Ιδιαίτερα, ξεπερνά τις επιδόσεις της αριστεράς προς δεξιά SA επειδή οι παραδοχές ανεξαρτησίας στο IBDecoder είναι πιο επιτυχείς. Για να επιτύχουμε ακόμα υψηλότερες ταχύτητες, εξερευνούμε υβριδικά μοντέλα όπου είτε προβλέπουμε ταυτόχρονα πολλαπλά γειτονικά σήματα ανά κατεύθυνση, είτε εκτελούμε πολυκατευθυνόμενη αποκωδικοποίηση διαιρώντας την ακολουθία στόχου. Αυτές οι μέθοδοι επιτυγχάνουν επιτάχυνση σε 4x-11σε διαφορετικές εργασίες με κόστος ενός ή 0.5 ROUGE (κατά μέσο όρο)', 'lt': 'Nepriklausomybės prielaidos sekos gamybos metu gali paspartinti išvadą, tačiau lygiagreti labai tarpusavyje priklausomų ženklų gamyba kainuoja kokybę. Užuot prisiėmę kaimyninių ženklų nepriklausomumą (pusiau autoregresinį dekodiavimą, SA), mes įkvėpime iš dvikryptinės sekos gamybos ir įdiegime dekodifikatorių, kuris tuo pačiu metu sukuria tikslinius žodžius iš kairės į dešinę ir iš dešinės į kairę. Mes parodome, kad galime lengvai pertvarkyti standartinę vienos krypties dekodizavimo architektūrą į dvikryptį dekodizavimą tiesiog sujungdami dvi kryptis ir pritaikant žodžių padėtį ir saviūpimo kaukes. Mūsų tarplaidinis dvikryptinis dekoderis (IBDecoder) išlaiko standartinio Transformerio modelio paprastumą ir mokymo efektyvumą, o penkių mašinų vertimo užduočių ir dviejų dokumentų santraukos užduočių atveju, palyginti su panašios kokybės autoregresiniu dekoderavimu, pasiektas ~2x dekoderavimo greitis. Notably, it outperforms left-to-right SA because the independence assumptions in IBDecoder are more felicitous.  To achieve even higher speedups, we explore hybrid models where we either simultaneously predict multiple neighbouring tokens per direction, or perform multi-directional decoding by partitioning the target sequence.  Taikant šiuos metodus įvairiose užduotyse greitis didėja iki 4x–11x už 1 BLEU arba 0,5 ROUGE (vidutiniškai).', 'it': "Le ipotesi di indipendenza durante la generazione di sequenze possono accelerare l'inferenza, ma la generazione parallela di token altamente interdipendenti ha un costo in termini di qualità. Invece di assumere l'indipendenza tra token vicini (decodifica semi-autoregressiva, SA), prendiamo ispirazione dalla generazione di sequenze bidirezionali e introduciamo un decoder che genera simultaneamente parole target dalle direzioni sinistra-destra e destra-sinistra. Dimostriamo che possiamo facilmente convertire un'architettura standard per la decodifica unidirezionale in un decoder bidirezionale semplicemente intrecciando le due direzioni e adattando le posizioni delle parole e le maschere di auto-attenzione. Il nostro decoder bidirezionale interleaved (IBDecoder) mantiene la semplicità del modello e l'efficienza formativa del Transformer standard, e su cinque compiti di traduzione automatica e due compiti di sintesi dei documenti, raggiunge una velocità di decodifica di ~ 2x rispetto alla decodifica autoregressiva con qualità comparabile. In particolare, supera le SA da sinistra a destra perché le ipotesi di indipendenza in IBDecoder sono più felici. Per ottenere velocità ancora più elevate, esploriamo modelli ibridi in cui prediciamo simultaneamente più token vicini per direzione, oppure eseguiamo la decodifica multidirezionale partizionando la sequenza di destinazione. Questi metodi raggiungono velocità fino a 4x-11x in diverse attività al costo di 1 BLEU o 0,5 ROUGE (in media)", 'mk': 'Претпоставувањата за независност за време на генерацијата на секвенца можат да ја забрзат инференцијата, но паралелната генерација на високо меѓузависни знаци доаѓа по цена во квалитетот. Instead of assuming independence between neighbouring tokens (semi-autoregressive decoding, SA), we take inspiration from bidirectional sequence generation and introduce a decoder that generates target words from the left-to-right and right-to-left directions simultaneously.  Ние покажуваме дека можеме лесно да ја претвориме стандардната архитектура за еднонасочно декодирање во двонасочен декодирач со едноставно прекинување на двете насоки и адаптирање на позициите на зборот и маски за себеси. Нашиот интерлексиран дводирективен декодер (IBDecoder) го задржува моделот на едноставност и ефикасност на обуката на стандардниот трансформер, и на пет машински преведувачки задачи и две задачи за резултат на документите, постигнува декодирање брзина од ~2x во споредба со авторегресивното декодирање Посебно, таа е поголема од лево во десно СА бидејќи претпоставувањата за независност во ИБДекодер се посреќни. За да постигнеме уште поголеми брзини, истражуваме хибридни модели каде или истовремено предвидуваме повеќе соседни знаци по насока, или извршуваме мултинасочно декодирање со поделба на целната секвенца. These methods achieve speedups to 4x-11x across different tasks at the cost of 1 BLEU or 0.5 ROUGE (on average)', 'ms': 'Independence assumptions during sequence generation can speed up inference, but parallel generation of highly inter-dependent tokens comes at a cost in quality.  Daripada menganggap kemerdekaan diantara token tetangga (pengekodan setengah-autoregresif, SA), kami mengambil inspirasi dari generasi urutan bidireksi dan memperkenalkan pengekod yang menghasilkan kata-kata sasaran dari arah kiri-ke-kanan dan kanan-ke-kiri secara bersamaan. Kita tunjukkan bahawa kita boleh mudah menukar arkitektur piawai untuk penyahkodan satu arah ke dalam penyahkod dua arah dengan hanya menyambungkan kedua arah dan menyesuaikan kedudukan perkataan dan topeng pencegahan diri. Dekoder bidireksi (IBDecoder) yang bersambung kami menyimpan kesederhanaan model dan efisiensi latihan Transformer piawai, dan pada lima tugas terjemahan mesin dan dua tugas penghuraian dokumen, mencapai kelajuan penyahkodan ~2x dibandingkan dengan penyahkodan autoregresif dengan kualiti yang sama. Nampaknya, ia melebihi SA kiri-ke-kanan kerana asumsi kemerdekaan dalam IBDecoder lebih berjaya. Untuk mencapai kelajuan yang lebih tinggi, kita mengeksplorasi model hibrid di mana kita sama ada meramalkan token tetangga berbilang setiap arah, atau lakukannya penyahkodan berbilang-arah dengan mengadakan jajaran sasaran. Kaedah ini mencapai kecepatan ke 4x-11x melalui tugas berbeza dengan biaya 1 BLEU atau 0.5 ROUGE (rata-rata)', 'ml': 'സെക്കന്\u200dസ് തലമുറയില്\u200d സ്വാതന്ത്ര്യം വേഗത്തിലാക്കാന്\u200d സാധ്യതയുള്ള ഊഹിക്കാന്\u200d കഴിയും, പക്ഷെ അത്യുത്തമമായി ആശ്രയിക്കുന്ന അടയ Instead of assuming independence between neighbouring tokens (semi-autoregressive decoding, SA), we take inspiration from bidirectional sequence generation and introduce a decoder that generates target words from the left-to-right and right-to-left directions simultaneously.  നമ്മള്\u200d കാണിച്ചു കൊടുക്കുന്നത് നമുക്ക് ഒരു സാധാരണ ആര്\u200dക്കിട്ടറിക്കാന്\u200d എളുപ്പമാണെന്നാണ് നമുക്ക് കാണിക്കാന്\u200d സാധിക്കുന്നത്. ഒരു സാധാരണ ഡികോഡ നമ്മുടെ ഇടയിലുള്ള ബിഡിയര്\u200dട്ടിക്കല്\u200d ഡെക്കോഡെര്\u200d (IBDecoder) സാധാരണ ട്രാന്\u200dസ്റ്റര്\u200d ട്രാന്\u200dസ്ഫ്രാന്\u200dസിന്\u200dറെ സാധാരണവും പരിശീലനവും അഞ്ച് മെഷീന്\u200d പരിശീലന ജോലികളിലും രണ്ട് രേഖയുടെ വിവരങ്ങളി കാരണം ഐബിഡെക്കോഡെരിലെ സ്വാതന്ത്ര്യം ഊഹിക്കുന്നത് കൂടുതല്\u200d വിജയിക്കുന്നു. കൂടുതല്\u200d വേഗത്തില്\u200d പെടുന്നതിന് വേണ്ടി, നമ്മള്\u200d ഹൈബ്രിഡ് മോഡലുകള്\u200d പരിശോധിക്കുന്നു, അവിടെ ഒരേ സമയത്ത് നമ്മള്\u200d അയല്\u200dവാസികളുടെ അടയാളങ്ങള്\u200d പ്രവചിക്കുന ഈ രീതികള്\u200d വ്യത്യസ്ത ജോലികളിലേക്ക് 4x-11x വരെ വേഗത്തിലേക്ക് എത്തുന്നു. 1 ബില്യൂ അല്ലെങ്കില്\u200d 0. 5 റൂജെയിന്\u200dറെ വില (ശരാശരി', 'mn': 'Дараагийн үеийн үндэслэл нь халдварыг хурдан нэмэгдүүлж чадна. Гэхдээ хоорондын хамааралтай тодорхойлолтуудын параллел үеийнх нь үнэтэй үнэтэй. Хөршүүн тэмдэгт хоорондын тусгаар тогтнол гэж бодохын оронд бид хоёр дахь дараагийн дарааллаас урам зориулж, зүүн, баруун, баруун, зүүн тийш зүүн тийш зориулсан үгсийг бий болгодог тэмдэглэгч бий болгодог. Бид зүгээр л хоёр чиглэлээс холбогдож, үгний байр суурь, өөрсдийгөө өөрчлөх гадаргуудыг өөрчилж чадна гэдгийг харуулж байна. Бидний хоорондоо холбогдсон хоёр бичлэгийн загвар (IBDecoder) стандарт Трансформацийн энгийн загвар болон сургалтын үр дүнтэй байдлыг хадгалдаг. Машин хөгжүүлэлтийн таван даалгавар болон хоёр бичлэгийн жимс хэвлэлтийн даалгавар дээр харьцуулагдах чанартай харьцуулахад ~ Энэ нь зүүн-зүүн-баруун SA-аас илүү үр дүнтэй. Учир нь IBDecoder-ын тогтнолтой байдал илүү амжилттай. Хэдийгээр өндөр хурдыг хүртэхийн тулд бид гибрид загваруудыг судалж байна. Эсвэл бид нэг зүгт хоорондын олон тоонуудыг тодорхойлдог эсвэл олон загварын шилжүүлэлт хийдэг. Эдгээр арга нь 1 BLEU эсвэл 0.5 ROUGE (дундаж)', 'mt': 'Is-suppożizzjonijiet ta’ indipendenza matul il-ġenerazzjoni tas-sekwenzi jistgħu jħaffu l-inferenza, iżda l-ġenerazzjoni parallel a ta’ tokens interdipendenti ħafna tiġi bi spiża fil-kwalità. Minflok nassumu l-indipendenza bejn it-tokens ġirien (dekodifikazzjoni semiawtoregressiva, SA), nieħdu ispirazzjoni mill-ġenerazzjoni tas-sekwenza bidirezzjonali u nintroduċu dekodifikatur li jiġġenera kliem fil-mira mid-direzzjonijiet tax-xellug għal-lemin u minn lemin għal-lemin fl-istess ħin. Aħna nuru li nistgħu faċilment nikkonvertiw arkitettura standard għad-dekodifikazzjoni unidirezzjonali f’dekodifikatur bidirezzjonali billi sempliċement inħallu bejniethom iż-żewġ direzzjonijiet u nadattaw il-pożizzjonijiet tal-kelma u l-maskri ta’ awtosistenza. Id-dekoder bidirezzjonali interleaved tagħna (IBDecoder) iżomm is-sempliċità mudell u l-effiċjenza tat-taħriġ tal-istandard Transformer, u fuq ħames kompiti ta’ traduzzjoni bil-magna u żewġ kompiti ta’ sommarju tad-dokumenti, jikseb veloċità ta’ dekodifikazzjoni ta’ ~2x meta mqabbel mad-dekodifikazzjoni awtoregressiva b’kwalità komparabbli. B’mod partikolari, hija taqbeż is-SA mix-xellug għal-lemin minħabba li s-suppożizzjonijiet ta’ indipendenza fl-IBDecoder huma aktar sodisfaċenti. To achieve even higher speedups, we explore hybrid models where we either simultaneously predict multiple neighbouring tokens per direction, or perform multi-directional decoding by partitioning the target sequence.  These methods achieve speedups to 4x-11x across different tasks at the cost of 1 BLEU or 0.5 ROUGE (on average)', 'no': 'Avhengighetsassumpsjonar ved følgjande av sekvensgenerasjon kan hastigheten opp infeksjon, men parallelle generasjon av høg mellomavhengige teikn kommer med ein kostnad i kvalitet. I staden for å anta uavhengighet mellom nabo-teikn (semi-autoregressiv dekoding, SA), tar vi inspirasjon frå generering av bidireksjonale sekvensar og introdusere eit dekoder som lagar målsord frå venstre-til-høgre og høgre-til-venstre retningar samtidig. Vi viser at vi kan enkelt konvertera ein standard arkitektur for unidireksjonal dekoding til ein bidireksjonal dekoder ved å gjera dei to retningane og tilpassa ordposisjonane og selfattingsmaske. Vårt interleaved bidireksjonal dekoder (IBDecoder) returnerer modellen enkelt og opplæringseffektivitet for standardformeren, og på fem maskineoversettelsesoppgåver og to oppgåver for samandringa av dokument, oppnår ein dekoderingsfart på ~2x samanlikna med autoregressiv dekoding med sammenlignbare kvalitet. Det utfører til venstre-til-høgre SA, fordi dei uavhengige assumpsjonane i IBDecoderen er meir felicit. For å oppnå enda høgare raskaren, utforskar vi hybridmodeller der vi anten foregår fleire nabo-teknar per retning, eller utfører fleire retning ved å partisjonare målskjefølgja. Desse metodane gjer raskaren til 4x-11x over ulike oppgåver ved kostnad av 1 BLEU eller 0,5 ROUGE (gjennomsnittlig)', 'pl': 'Założenia niezależności podczas generowania sekwencji mogą przyspieszyć wnioskowanie, ale równoległe generowanie wysoce zależnych tokenów jest kosztem jakości. Zamiast zakładać niezależność pomiędzy sąsiednimi tokenami (dekodowanie półautoregresywne, SA), czerpimy inspirację z dwukierunkowego generowania sekwencji i wprowadzamy dekoder generujący jednocześnie słowa docelowe z kierunku lewo-prawo i prawo-lewo-lewo. Pokazujemy, że możemy łatwo przekształcić standardową architekturę dekodowania jednokierunkowego w dekoder dwukierunkowy, po prostu przeplatając dwa kierunki i dostosowując pozycje słowa i maski samoobserwacyjne. Nasz przeplatany dekoder dwukierunkowy (IBDecoder) zachowuje prostotę modelu i wydajność szkoleniową standardowego transformatora, a na pięciu zadaniach tłumaczenia maszynowego i dwóch zadaniach podsumowywania dokumentów osiąga przyspieszenie dekodowania ~2x w porównaniu z dekodowaniem autoregresywnym o porównywalnej jakości. W szczególności przewyższa ona prawo-lewo SA, ponieważ założenia niezależności w IBDecoder są bardziej sprawiedliwe. Aby osiągnąć jeszcze większą prędkość, badamy modele hybrydowe, w których albo jednocześnie przewidujemy wiele sąsiadujących tokenów na kierunek, albo wykonujemy dekodowanie wielokierunkowe poprzez partycjonowanie sekwencji docelowej. Metody te zapewniają przyspieszenie do 4x-11x w różnych zadaniach kosztem 1 BLEU lub 0.5 ROUGE (średnio)', 'ro': 'Ipotezele de independență în timpul generarii secvențelor pot accelera inferența, dar generarea paralelă de jetoane foarte interdependente vine cu un cost în calitate. În loc să ne asumăm independența între jetoanele vecine (decodare semi-autoregresivă, SA), ne inspirăm din generarea secvențelor bidirecționale și introducem un decoder care generează simultan cuvinte țintă din direcțiile stânga-dreapta și dreapta-stânga. Aratăm că putem converti cu ușurință o arhitectură standard pentru decodarea unidirecțională într-un decoder bidirecțional prin simpla întreținere a celor două direcții și adaptarea pozițiilor cuvântului și a măștilor de auto-atenție. Decodorul nostru bidirecțional interleaved (IBDecoder) păstrează simplitatea modelului și eficiența de instruire a Transformerului standard, iar pe cinci sarcini de traducere automată și două sarcini de rezumare a documentelor, atinge o viteză de decodare de ~ 2x în comparație cu decodarea autoregresivă cu o calitate comparabilă. În mod remarcabil, acesta depășește SA de la stânga la dreapta deoarece ipotezele de independență din IBDecoder sunt mai fericite. Pentru a obține viteze și mai mari, explorăm modele hibride în care fie prezicem simultan mai multe jetoane vecine pe direcție, fie efectuăm decodarea multidirecțională prin partiționarea secvenței țintă. Aceste metode realizează viteze de până la 4x-11x în diferite sarcini, cu costul de 1 BLEU sau 0,5 ROUGE (în medie)', 'kk': 'Тәуелсіздік тәуелсіздік тапсырмалары реттік құрылғанда инференцияны жылдыруға болады, бірақ параллельдік тәуелсіздік таңбалардың параллелі құрылуы сапатты. Сол жақтан оң жақтан сол жақтан сол жақтан сөздерді құратын декодердің тәуелсіздігін алдында (жарты-авторегрессивні декодердің декодердің орнына, SA декодердің көтерілігін алдын аламыз. Біз бір бағытты декодтау үшін стандартты архитектураны бір бағытты декодтау үшін бір бағытты декодтау үшін оңай түрлендіре аламыз. Біз екі бағытты қайталап сөздердің орналасуын және өзіңіздің қа Біздің көмектесіміздің бидирекциялық декодеріміз (IBDecoder) стандартты түрлендірушінің қарапайым және оқыту мүмкіндігін сақтайды. Бес компьютердің аудару тапсырмаларында және екі құжатты тұжырымдау тапсырмаларында, автоregressивті декодердің са Бұл сол жақтан оң жақтан SA жасайды, себебі IBDecoder дегі тәуелсіздік таңдаулары көп жақсы. Жылдамдық жылдамдығын жеткізу үшін біз гибрид үлгілерін зерттейміз. Бұл жерде бірнеше бірнеше соңғы белгілерді бір бағыттағы белгілерді таңдаймыз, немесе бірнеше бағытты декодтау үшін мақса Бұл әдістер 1 BLEU немесе 0, 5 ROUGE (орташа) деген әртүрлі тапсырмалардың арасында 4x- 11x жылдамдығына жеткізеді.', 'ka': 'სექსეციის განვითარება შესაძლებელია სიჩქარე ინფრენციას, მაგრამ პარალელი განვითარება ძალიან საშუალებელი ინფრენციების განვითარება იქნება, რომელიც უფრო ღირებულ შემდეგ გავაგრძნოთ საზოგადოებო სიმბოლოების განმავლობას (სამხოლოდ ავტორეგრესიური ევკოდირება, SA), ჩვენ ვიღებთ განმავლობას ორიდერექციონალური სექციენტის განმავლობაზე და გამოყენებთ დეკოდირები, რომელიც მარცხენა მა ჩვენ ჩვენ ვაჩვენებთ, რომ ჩვენ შეგვიძლია ადვილად სტანდარტური აქტიქტიქტურაციას ერთეთრექციონალური რექტიქტურაციის რექტიქტურაციისთვის გადავიწყენოთ, როგორც ორი პერიციაციას გადა ჩვენი საშუალებული ბიდერექციონალური ევკოდეტორი (IBDecoder) სტანდარტრუქტურის მოდელური მხოლოდ და განაკეთებული ეფექტიურობა, და ხუთი მაქინის განაკეთება და ორი დოკუმენტის კუმენტურაციის დასაწყება ~2x-ის განაკეთება სიჩქარ წარმოდგენით, მარჯვნიდან მარჯვნიდან მუშაობს SA, რადგან IBDecoder-ში უფრო მუშაობელია. თუ უფრო მეტი სიჩქარე წარმოდგენისთვის, ჩვენ ჰიბრიდის მოდელების გამოვაკვირდებით, სადაც ჩვენ ერთადერთად მრავალურად წარმოდგენით მრავალური საზოგადოებული სიჩქარე, ან მრავალურად გან ამ პროცემებების განსხვავებული საქმედების განმავლობაში 4x-11x სიჩქარე გავაკეთებთ 1 BLEU ან 0.5 ROUGE-ს (სიცოცხლეში)', 'so': 'Fikiro xor ah xiliga qarniga xilliga dabaasha ayaa degdegi kara cudurada, laakiin qarni isbarbaro ah oo calaamado badan oo ay ku xiran yihiin waxaa ku imaanaya qiimaha qiimaha. Iska bedelkeeda xornimo u dhaxaysa calaamada deriska (saSA), waxaynu ka qaadannaa waxyaabaha aad ka muuqato qarniga bidixiga ah, waxaana soo bandhigaynaa qodolk oo ka soo bandhigaa erayo waxqabad xagga bidixda iyo xagga midigta iyo xagga bidixda. We show that we can easily convert a standard architecture for unidirectional decoding into a bidirectional decoder by simply interleaving the two directions and adapting the word positions and selfattention masks.  IBDecoder (IBDecoder) wuxuu haystaa noocyada fudud iyo waxbarashada koowaad ee gaadiidka standardka, wuxuuna ku qoran shan shaqooyin turjumista machine iyo laba shaqooyin oo summarinta labada dukumenti ah, wuxuuna gaadhaa deynta korsocodka ~2x, iyadoo la barbarbartay iskudarka u eg quality. Si kastaba ha ahaatee, waxay SA ka muuqataa dhanka midigta iyo midigta, sababtoo ah malaha xornimada ee IBDecoder waxay ku jirtaa liibaano ka badan. To achieve even higher speedups, we explore hybrid models where we either simultaneously predict multiple neighbouring tokens per direction, or perform multi-directional decoding by partitioning the target sequence.  Shaqooyinkaasu waxay gaadhaan degaanka 4x-11x oo ku socda shaqaalaha kala duduwan kharashka 1 BLEU ama 0.5 ROUGE (ugu dhexeeya)', 'sv': 'Oberoende antaganden under sekvensgenerering kan påskynda slutsatsen, men parallell generering av mycket inbördes beroende tokens kommer till en kostnad i kvalitet. Istället för att anta självständighet mellan angränsande tokens (semi-autoregressiv avkodning, SA), tar vi inspiration från tvåriktad sekvensgenerering och introducerar en dekoder som genererar målord från vänster-till-höger och höger-till-vänster riktningar samtidigt. Vi visar att vi enkelt kan omvandla en standardarkitektur för enkelriktad avkodning till en tvåriktad avkodning genom att helt enkelt sammanfläta de två riktningarna och anpassa ordpositioner och självuppmärksamhetsmasker. Vår interleaved dubbelriktade avkodare (IBDecoder) behåller modellenkelheten och utbildningseffektiviteten hos standard Transformer, och på fem maskinöversättningsuppgifter och två dokumentsammanfattningsuppgifter uppnår avkodningshastigheten på ~ 2x jämfört med autoregressiv avkodning med jämförbar kvalitet. Framförallt överträffar den SA från vänster till höger eftersom oberoende antaganden i IBDecoder är mer lyckosamma. För att uppnå ännu högre hastigheter utforskar vi hybridmodeller där vi antingen samtidigt förutspår flera angränsande tokens per riktning, eller utför flerriktad avkodning genom att partitionera målsekvensen. Dessa metoder ger hastigheter till 4x-11x över olika uppgifter till kostnaden för 1 BLEU eller 0,5 ROUGE (i genomsnitt)', 'ta': 'தொடர்ச்சி உருவாக்கும் போது சுதந்தி எண்ணங்கள் தொடர்ந்து கொண்டிருக்கும் போது துன்பத்தை வேகமாக்கும், ஆனால் இணைப்பு தலைமுறை  அண்டை குறியீடுகளுக்கிடையே சுதந்திரத்தை எண்ணுவதற்கு பதிலாக (பாதி தானியங்கி கட்டுப்படுத்தும் குறியீடுகளுக்கு இடையேயாக) நாம் தேவைப்படுத்துகிறோம், பிடிவின் வரி நாம் சுலபமாக ஒரு இயல்பான நிலையான கட்டுப்பாட்டு மாற்ற முடியும் என்று காண்பிக்கிறோம் என்றால் நாம் ஒரு தேர்ந்தெடுக்கப்பட்ட குறியீட்டை ஒரு ப நம்முடைய இடைவெளிப்படுத்தப்பட்ட பிடிவின் குறியீட்டாளர் (IBDecoder) இயல்பான மாதிரி எளிமையையும் பயிற்சியும் வைத்துக் கொள்ளும், ஐந்து இயந்திர மொழிபெயர்ப்பு பணிகள் மற்றும் இரண்டு ஆவண ம குறிப்பிட்டு, அது இடப்புறத்திலிருந்து வலப்புறத்திலிருந்து செயல்படுகிறது ஏனென்றால் IBDecoder யின் சுதந்திரமான எண To achieve even higher speedups, we explore hybrid models where we either simultaneously predict multiple neighbouring tokens per direction, or perform multi-directional decoding by partitioning the target sequence.  இந்த முறைமைகள் வேகத்தை 4x-11x வேகமாக பெறுகிறது வேறு வேலைகளை வெளியேறுகிறது 1 பிலியு அல்லது 0. 5 ரூஜெக் (சராசரி)', 'sr': 'Pretpostavke nezavisnosti tokom generacije sekvence mogu ubrzati infekciju, ali paralelna generacija veoma međuovisnih znakova dolazi po cijenu kvalitete. Umesto da pretpostavimo nezavisnost između susednih znakova (polu-autoregresivnog dekodiranja, SA), poduzimamo inspiraciju iz generacije bidirektivnih sekvencija i predstavljamo dekoder koji stvara ciljne reči iz lijeve na desne i desne na leve strane istovremeno. Pokazujemo da možemo lako pretvoriti standardnu arhitekturu za jednosmjernu dekodiranje u dvosmjernu dekodiranju, jednostavno prekidajući dve smjernice i prilagoditi riječne pozicije i maske sebičnosti. Naš interleaved bidirektivni dekoder (IBDecoder) zadržava model jednostavnost i učinkovitost obuke standardnog transformera, a na pet zadataka za prevod mašine i dva zadataka za sažetanje dokumenta postiže brzinu dekodiranja ~2x u usporedbi sa autoregresivnim dekodiranjem sa usporednom kvalitetom. U svakom slučaju, to iznosi levo-desno SA jer su pretpostavke nezavisnosti u IBDecoderu srećnije. Da bi postigli još veće brzine, istražujemo hibridne modele u kojima ili istovremeno predviđamo višestruke komšijske znakove po smjeru, ili izvršimo višesmjerne dekodiranje particijom ciljne sekvence. Ove metode postižu brzinu do 4x-11x u različitim zadatkima na troškovi od 1 BLEU ili 0,5 ROUGE (u prosjeku)', 'si': 'නිදහස් විශ්වාස නිර්මාණයක් පරීක්ෂණයක් වෙලාවට පරීක්ෂණයක් වේගය කරන්න පුළුවන්, ඒත් සාමාන්\u200dය විශ්වාසිත විශ පිටිපස්සේ තොකන්ස් අතර ස්වාභාවික විශේෂතාවක් විතරයි (Half-autoregressive decoding, SA), අපි බිදිරික්ෂණ පරීක්ෂණයෙන් ප්\u200dරශ්නයක් ගන්නවා වගේම ප්\u200dරශ්නයක් පිටිපස්සෙ අපි පෙන්වන්නේ අපිට පුළුවන් පුළුවන් පුළුවන් ස්ථානික විද්\u200dයාපනයක් වෙනස් කරන්න පුළුවන් විද්\u200dයාපනයක් වෙන්න පුළුවන් විදිහ අපේ ඉන්තර්ලීව් බිඩිරෙක්ෂන් ඩිකෝඩර් (IBDecoder) ප්\u200dරමාණය ප්\u200dරවර්තනය සහ ප්\u200dරයෝජනය සහ ප්\u200dරයෝජනය වැඩක් පහක් වලින් වාර්තාවක් සහ ලොකුණු සුම්පර්තනය වැඩක් දෙකක් ව අනිවාර්යෙන්ම, ඒක වැඩියෙන් වැඩියෙන් වැඩියෙන් තියෙන්නේ. මොකද IBdecoder වලින් ස්වතංක්\u200dරීය විශ්වාස විශ්ව අපි හිබ්\u200dරිඩ් මෝඩල් අවශ්\u200dය වෙනුවෙන් වැඩි වේගයක් ලැබෙන්න, අපි හිබ්\u200dරිඩ් මෝඩල් පරීක්ෂණය කරනවා කියලා, අපි එකම වෙනුවෙන් වෙනුවෙන් ගොඩ මේ විධානයෙන් වෙනස් වැඩක් වෙනස් වැඩක් වල 4x-11x වෙනුවෙන් ඉක්මන් වෙනුවෙන් ඉක්මන් කරන්න පුළුවන්', 'ur': 'سفارشی نسل کے درمیان غیر اخلاقیت کی فرضیات اسفارشی کی جلدی کر سکتے ہیں، لیکن بہت زیادہ اخلاقیت کے ٹوکینوں کی مختلف نسل ایک کیفیت کے مطابق آتی ہے. اس کے عوض ہم دوسری سطح کی نسل سے الهام لیتے ہیں اور ایک دکور کو معلوم کرتے ہیں جو بائیں طرف سے دائیں طرف سے اور دائیں طرف سے بائیں طرف سے ہدایت کی باتیں پیدا کرتا ہے۔ ہم نشان دیتے ہیں کہ ہم ایک سیدھی طریقہ کے لئے ایک سیدھی طریقہ کی معماری کو آسان طور پر بدل سکتے ہیں ایک دوسرے طریقے کے بغیر دوسرے طریقے سے اور کلمات کی موقعیت اور خود فساد ماسک کے مطابق اضافہ کر سکتے ہیں۔ ہمارا انٹرلیویڈ ڈیڈریکیشن ڈیکوڈر (IBDecoder) استاندارڈ ترنسفور کے موڈل کی سادگی اور ترینسی فعالیت کو رکھتا ہے، اور پانچ ماشین ترجمہ ٹیکسوں کے کاموں پر اور دو دکمینٹ ترجمہ ٹیکسوں پر ~2x کی ایک ڈیکوڈ کی سرعت پہنچ جاتی ہے، جیسے autoregressive ڈیکوڈ کی مقایسہ یقیناً یہ بائیں بائیں بائیں سے دائیں سی ا آس آس آس آس آسی سے زیادہ کامیابی کرتا ہے کیونکہ IBDecoder میں مستقل حدس سے زیادہ کامیاب ہیں۔ اور زیادہ سرعت تک پہنچانے کے لئے، ہم ہیبریڈ موڈل کو دیکھتے ہیں جہاں ہم ایک دفعہ ایک دوسرے کے ساتھ بہت سی مسابقات ٹوکنوں کو پیش بینی کرتے ہیں، یا بہت سی دفعہ ڈیکوڈ کر دیتے ہیں تابع سفارش کے ذریعہ۔ یہ طریقے ایک BLEU یا 0.5 ROUGE کے مطابق مختلف کاموں میں 4x-11x تک سرعت پہنچ رہے ہیں۔', 'vi': 'Những giả thiết độc lập trong quá trình sản xuất có thể làm tăng tốc nhận biết, nhưng sản xuất song song các thẻ liên quan đến giá trị chất lượng. Thay vì đảm bảo độc lập giữa những vật thể xung quanh (mô- tự vệ hóa nền, SA), chúng tôi lấy cảm hứng từ chuỗi phân sinh sinh hai thứ và giới thiệu một bộ giải mã phát ra từ hướng trái-phải-phải-phải-trái đồng thời. Chúng tôi cho thấy chúng tôi có thể dễ dàng chuyển đổi một kiến trúc tiêu chuẩn để giải mã hai hướng thành một bộ mã hai hướng bằng cách đơn giản nối lại hai hướng và sửa đổi tư thế và mặt nạ phòng tập trung. Máy giải mã hai trực tiếp của chúng ta (IBDecder) giữ được mô hình đơn giản và hiệu quả đào tạo của Tranlão tiêu chuẩn, và trong năm công việc dịch chuyển máy và hai công việc tổng hợp tài liệu, chúng ta đạt được một tốc độ giải mã nhanh chóng hơn... 2x so với lớp lọc tự vệ với chất lượng tương đối. Đặc biệt, nó vượt trội hơn hẳn SA bởi vì các giả thiết độc lập trong IBDecoder rất hạnh phúc. Để tăng tốc thậm chí cao hơn, chúng ta khám phá các mô hình hỗn hợp mà chúng ta có thể cùng lúc dự đoán nhiều vật tương tự xung quanh cho mỗi hướng, hoặc thực hiện giải mã đa hướng bằng cách phân tách dãy mục tiêu. Những phương pháp này giúp tăng tốc lên 4x-11x vượt qua các công việc khác nhau với giá trị của 1 TIẾNG LEU hoặc 0.5 ROSEME (trên trung bình)', 'uz': "Cheksiz avval davomida imkoniyatlarni tezlashtirish mumkin, lekin eng katta ishlatadigan belgilar sonlarining qiymatiga keladi. Name Biz oddiy ko'rsatishimiz mumkin, biz bir necha kodlash uchun andoza arxituvchini o'zgartirishimiz mumkin. Biz ikkita yoʻlni boshqarish va so'zlarni joylashtirish va o'zgarishni o'zgartirish mumkin. Bizning interfeysli cheksiz (IBDecoder) modelning oddiylik va ta'lim drayverini aniqlaydi, 5 mashina tarjima vazifalarida va ikkita hujjatni tahrirlash vazifalarini qaytadi. Avto-regressiv kodlash usulida o'xshash sifatida o'xshash boʻlishi mumkin. Ko'rsatganda, bu SA chapdan oʻng tomondan foydalanadi chunki IBDecoder'ning xolosi muvaffaqiyatli. Koʻproq tezlikga erishish uchun biz huddi paytda hech qancha ko'pchilik tegnlarini ko'rinishimizni ko'rsamiz yoki qanchalik seksiyatlarni qismlash orqali bir necha marta ko'proq kodlash usulini bajaramiz. Ushbu usullar boshqa vazifalar bilan 4x-11x uchun tezlikga ega bo'ladi. 1 BLEU yoki 0.5 ROUGE (o'rtacha)", 'bg': 'Предположенията за независимост по време на генерирането на последователност могат да ускорят заключенията, но паралелното генериране на силно взаимозависими токени идва с цена по качество. Вместо да приемем независимост между съседните токени (полу-авторегресивно декодиране, СА), ние се вдъхновяваме от генерирането на двупосочни последователности и въвеждаме декодер, който генерира целеви думи едновременно от ляво надясно и дясно наляво. Показваме, че лесно можем да преобразуваме стандартна архитектура за еднопосочно декодиране в двупосочен декодер, като просто пресичаме двете посоки и адаптираме позициите на думата и маските за самовнимание. Нашият двупосочен декодер запазва простотата на модела и ефективността на обучението на стандартния трансформатор, а при пет задачи за машинен превод и две задачи за обобщаване на документи постига скорост на декодиране от ~ 2x в сравнение с авторегресивното декодиране със сравнимо качество. По-специално, тя надминава от ляво на дясно SA, защото предположенията за независимост в IBDecoder са по-щастливи. За да постигнем още по-високи скорости, изследваме хибридни модели, при които едновременно прогнозираме няколко съседни токена в посока, или извършваме многопосочно декодиране чрез разделяне на целевата последователност. Тези методи постигат ускорения до 4х-11х при различни задачи на цената на 1 или 0,5 (средно)', 'da': 'Uafhængighedsantagelser under sekvensgenerering kan fremskynde slutningen, men parallel generering af stærkt indbyrdes afhængige tokens kommer til en pris i kvalitet. I stedet for at antage uafhængighed mellem nærliggende tokens (semi-autoregressiv dekodning, SA), tager vi inspiration fra bidirektionel sekvensgenerering og introducerer en dekoder, der genererer målord fra venstre mod højre og højre mod venstre retning samtidigt. Vi viser, at vi nemt kan konvertere en standardarkitektur til ensrettet afkodning til en bidirectional dekoder ved blot at sammenflette de to retninger og tilpasse ordpositioner og selvopmærksomhedsmasker. Vores interleaved bidirectional dekoder (IBDecoder) bevarer modellens enkelhed og uddannelseseffektivitet af standard Transformer, og på fem maskinoversættelsesopgaver og to dokumentopsummeringsopgaver opnår vi en afkodningshastighed på ~ 2x sammenlignet med autoregressiv dekodning med sammenlignelig kvalitet. Det er især bedre end venstre mod højre SA, fordi uafhængighedsantagelserne i IBDecoder er mere lykkelige. For at opnå endnu højere hastighedsforløb undersøger vi hybridmodeller, hvor vi enten samtidig forudsiger flere tilstødende tokens pr. retning eller udfører flerretningsbestemt afkodning ved at partitionere målsekvensen. Disse metoder opnår hastigheder til 4x-11x på tværs af forskellige opgaver til en pris af 1 BLEU eller 0,5 ROUGE (i gennemsnit)', 'id': 'Suposisi independensi selama generasi urutan dapat mempercepat kesimpulan, tetapi generasi paralel token yang sangat inter dependent datang dengan biaya dalam kualitas. Daripada menganggap kemerdekaan antara token tetangga (dekoding semi-autoregresif, SA), kami mengambil inspirasi dari generasi bidireksi urutan dan memperkenalkan dekoding yang menghasilkan kata-kata sasaran dari arah kiri ke kanan dan kanan ke kiri secara bersamaan. Kita menunjukkan bahwa kita dapat mudah mengubah arsitektur standar untuk dekodasi unidireksi menjadi dekodar bidireksi dengan hanya menginterlinkan dua arah dan menyesuaikan posisi kata dan topeng egois. Our interleaved bidirectional decoder (IBDecoder) retains the model simplicity and training efficiency of the standard Transformer, and on five machine translation tasks and two document summarization tasks, achieves a decoding speedup of ~2x compared to autoregressive decoding with comparable quality.  Terutama, ia lebih berharga dari SA kiri ke kanan karena asumsi independensi di IBDecoder lebih berhasil. To achieve even higher speedups, we explore hybrid models where we either simultaneously predict multiple neighbouring tokens per direction, or perform multi-directional decoding by partitioning the target sequence.  Metode ini mencapai speedups ke 4x-11x melalui tugas berbeda dengan biaya 1 BLEU atau 0,5 ROUGE (rata-rata)', 'de': 'Unabhängigkeitsannahmen während der Sequenzgeneration können die Inferenz beschleunigen, aber die parallele Generierung von stark voneinander abhängigen Token ist mit Qualitätskosten verbunden. Anstatt die Unabhängigkeit zwischen benachbarten Token (semi-autoregressive Decodierung, SA) anzunehmen, lassen wir uns von der bidirektionalen Sequenzgeneration inspirieren und führen einen Decoder ein, der Zielwörter aus links-rechts- und rechts-links-Richtungen gleichzeitig generiert. Wir zeigen, dass wir eine Standardarchitektur für unidirektionale Dekodierung leicht in einen bidirektionalen Decoder umwandeln können, indem wir die beiden Richtungen einfach ineinandergreifen und die Wortpositionen und Selbstaufmerksamkeitsmasken anpassen. Unser interleaved bidirektional decoder (IBDecoder) behält die Modelleinfachheit und Schulungseffizienz des Standard-Transformers bei und erreicht bei fünf maschinellen Übersetzungsaufgaben und zwei Dokumenten-Zusammenfassungsaufgaben eine Entschlüsselungsbeschleunigung von ~2x im Vergleich zur autoregressiven Decodierung mit vergleichbarer Qualität. Bemerkenswerterweise übertrifft es Links-nach-Rechts SA, da die Unabhängigkeitsannahmen in IBDecoder zufriedenstellender sind. Um noch höhere Geschwindigkeiten zu erreichen, erforschen wir hybride Modelle, bei denen wir entweder gleichzeitig mehrere benachbarte Token pro Richtung vorhersagen oder multidirektionale Dekodierung durch Partitionierung der Zielsequenz durchführen. Diese Methoden erreichen Beschleunigungen auf 4x-11x für verschiedene Aufgaben zu Kosten von 1,5 ROUGE (im Durchschnitt)', 'hr': 'Pretpostavke nezavisnosti tijekom generacije sekvence mogu ubrzati infekciju, ali paralelna generacija visoko međuovisnih znakova dolazi po cijenu kvalitete. Umjesto pretpostavke nezavisnosti između susjednih znakova (polu-autoregresivnog dekodiranja, SA), mi uzimamo inspiraciju iz generacije bidirektivnih sekvencija i predstavljamo dekodiranje koji stvara ciljne riječi iz lijeve na desno i desno na lijevo. Pokazujemo da možemo lako pretvoriti standardnu arhitekturu za jednosmjernu dekodiranje u dvosmjernu dekodiranju, jednostavno prekidajući dvije smjernice i prilagoditi riječne pozicije i maske sebičnosti. Naš interleaved bidirectional dekoder (IBDecoder) zadržava model jednostavnost i učinkovitost obuke standardnog transformera, a na pet zadataka za prevod strojeva i dva zadataka za sažetak dokumenta postiže brzinu dekodiranja ~2x u usporedbi s autoregresivnim dekodiranjem s usporednom kvalitetom. Obično, to iznosi lijevo-desno SA jer su pretpostavke nezavisnosti u IBDecoderu srećnije. Da bismo postigli još veće brzine, istražujemo hibridne modele u kojima ili istovremeno predviđamo višestruke komšijske znakove po smjeru, ili izvršili višesmjerne dekodiranje particijom ciljne sekvence. Ove metode postignu brzinu do 4x-11x u različitim zadatkima na troškovi od 1 BLEU ili 0,5 ROUGE (prosječno)', 'fa': 'فرضیه\u200cهای بی\u200cاعتماد در زمان نسل\u200cهای مختلف می\u200cتوانند آلودگی را سرعت دهند، ولی نسل\u200cهای متفاوتی از نشانه\u200cهای بین\u200cاعتماد با یک قیمت به کیفیت می\u200cآیند. به جای assumption of independence between neighboring tokens (semi-autoregressive decoding, SA), we take inspiration from the second sequence sequence and introduce a decoder that generates target words from the left to right and right to left at the same time. ما نشان می دهیم که می توانیم به آسانی یک معماری استاندارد را برای یک دستکاری متحده به یک دستکاری کودکان دوباره تبدیل کنیم، با ساده ترک کردن دو جهت و ساده کردن موقعیت کلمه و ماسک خودکشی را. دستگاه\u200cدهنده\u200cی دومین\u200cترکیب (IBDecoder) ما مدل ساده\u200cایی و آموزشی تغییر\u200cدهنده\u200cی استاندارد را نگه می\u200cدارد، و روی پنج تاریخ\u200cدهنده\u200cی ماشین و دو تاریخ\u200cدهنده\u200cی جمع\u200cآوری سند، سرعت\u200cدهنده\u200cای از ~2x در مقایسه با دستگاه\u200cدهنده\u200cی خودگریز با کیفیت قابل مخصوصاً این SA از چپ به سمت راست برخورد می\u200cکند چون فرضیه\u200cهای مستقل در IBDecoder موفقیت\u200cتر است. برای رسیدن به سرعتهای بیشتری، ما مدل های هیبریدی را تحقیق می کنیم که یا با همزمان نشانه های متعدد همسایه را در هر سمت پیش بینی می کنیم، یا با تقسیم کردن رده هدف طریقی متعدد طریقی انجام می دهیم. این روش\u200cها سرعت\u200cها تا 4x-11x در طول کار مختلف به هزینه ۱ BLEU یا ۰.۵ ROUGE می\u200cرسند (در متوسط)', 'sw': 'Independence assumptions during sequence generation can speed up inference, but parallel generation of highly inter-dependent tokens comes at a cost in quality.  Badala ya kudhani uhuru kati ya ishara za jirani (uchunguzi wa sekunde ya kudhibiti kandamizi, SA), tunachukua hamasa kutoka kizazi cha mfululizo wa mfululizo wa mfumo wa pili na tunaonyesha decodi inayoleta maneno yanayolenga kutoka kwenye maelekezo ya kushoto hadi kulia na kushoto kwa wakati mmoja. Tunaonyesha kuwa tunaweza kwa urahisi kubadilisha ujenzi wa kiwango cha kawaida kwa ajili ya kuandika kwa ajili ya kuondoka kwa njia mbili na kubadilisha nafasi za neno na vifaa vya kifo. Kodi letu la utaratibu (IBDecoder) linabakisha ufanisi wa urahisi na mafunzo ya usafiri wa hali ya kawaida, na juu ya kazi za kutafsiri mashine mitano na kazi za muhtasari wa nyaraka mbili, hupata ongezeko la kupunguza kwa kasi ya ~2x ukilinganisha na kupunguza kwa kiwango kikubwa. Hata hivyo, inaendesha Afrika Kusini kushoto hadi kulia kwa sababu dhana za uhuru nchini IBDecoder zinafanikiwa zaidi. Ili kupata kiwango kikubwa zaidi zaidi, tunachunguza mifano ya hybrid ambapo kwa wakati huo tunatabiri alama kadhaa za jirani kwa mwelekeo, au kufanya kupunguza kwa njia za kidete kwa kuchagua mfululizo wa lengo. Hatua hizi zinaweza kufikia kiwango cha 4x-11x katika kazi tofauti kwa gharama za BLEU 1 au 0.5 ROUGE (kwa wastani)', 'nl': 'Onafhankelijkheidsveronderstellingen tijdens het genereren van sequenties kunnen de inferentie versnellen, maar parallelle generatie van sterk onderling afhankelijke tokens heeft een kostprijs in kwaliteit. In plaats van onafhankelijkheid te veronderstellen tussen naburige tokens (semi-autoregressive decodering, SA), laten we ons inspireren door het genereren van bidirectionele sequenties en introduceren we een decoder die doelwoorden tegelijkertijd genereert vanuit de links-naar-rechts en rechts-naar-links richtingen. We laten zien dat we een standaard architectuur voor unidirectionele decodering gemakkelijk kunnen omzetten in een bidirectionele decoder door simpelweg de twee richtingen te interleaven en de woordposities en zelfaandachtsmaskers aan te passen. Onze interleaved bidirectionele decoder (IBDecoder) behoudt de eenvoud van het model en trainingsefficiëntie van de standaard Transformer, en bereikt op vijf machinevertaaltaken en twee documentsamenvattingstaken een decoderingssnelheid van ~2x in vergelijking met autoregressieve decodering met vergelijkbare kwaliteit. Het presteert vooral beter dan links-naar-rechts SA omdat de onafhankelijkheidsveronderstellingen in IBDecoder gelukkiger zijn. Om nog hogere snelheden te bereiken, verkennen we hybride modellen waarbij we ofwel tegelijkertijd meerdere naburige tokens per richting voorspellen, ofwel multi-directionele decodering uitvoeren door de doelreeks te partitioneren. Deze methoden bereiken versnellingen tot 4x-11x voor verschillende taken ten koste van 1.BLEU of 0.5 ROUGE (gemiddeld)', 'ko': '서열 생성 과정 중의 독립성 가설은 추리 속도를 높일 수 있으나, 고도로 서로 의존하는 영패를 병행하여 생성하는 것은 품질을 대가로 한다.우리는 쌍방향 서열 생성에서 시사점을 얻어 디코더를 도입하여 왼쪽에서 오른쪽과 오른쪽에서 왼쪽으로 목표어를 동시에 생성할 수 있으며 인접 표기 간의 독립성을 가정하지 않고 (반자귀환 디코딩, SA) 할 수 있다.우리는 간단하게 두 방향을 교차시키고 단어의 위치와 자기주의 마스크를 조정함으로써 단방향 디코딩의 표준 구조를 양방향 디코더로 쉽게 전환할 수 있음을 증명했다.우리의 교차 양방향 디코더(IBDecoder)는 표준 변환기의 모델 단순성과 훈련 효율을 유지했고 다섯 개의 기계 번역 임무와 두 개의 문서 요약 임무에서 질이 상당한 자귀환 디코딩에 비해 약 2배의 디코딩 가속화를 실현했다.특히 IBMDecoder의 독립성 가설이 더 적절하기 때문에 왼쪽에서 오른쪽으로 SA보다 우수하다.더 높은 가속도를 얻기 위해 우리는 혼합모델을 탐색했다. 그 중에서 우리는 각 방향의 여러 개의 인접 영패를 동시에 예측하거나 목표 서열에 대해 구역을 나누어 다방향 디코딩을 실행했다.이러한 접근 방식은 4x-11x의 평균 비용으로 1BLEU 또는 0.5 ruge', 'af': "Ongelikheidse aanvaardes tydens sekwensiegenerasie kan speur inferensie op, maar parallele generasie van hoë inter-afhanklike tekens kom op 'n koste in kwaliteit. In plaas van die aangeneem van onveiligheid tussen nabygeste tekens (semi-autoregressiewe dekodering, SA), neem ons inspirasie van bidireksjonale sekwensiegenerasie en introduseer ons 'n dekoder wat doel woorde genereer van die links-na-regs en regs-na-links rigtings simultaan. Ons wys dat ons maklik 'n standaard arkitektuur kan omskakel vir unidireksionale dekodering in 'n bidireksionale dekoder deur eenvoudig die twee rigtings te verlaat en die woord posisies en selffatteringsmaskers te pas. Ons interlearte bidireksjonale dekoder (IBDecoder) hou die model eenvoudigheid en onderwerp effektiviteit van die standaard transformeerder, en op vyf masjien vertaling opdragte en twee dokument opsomming opdragte, verkry 'n dekodering speeduip van ~2x vergelyk met autoregressief dekodering met vergelykbare kwaliteit. Gewoonlik, dit uitvoer links-na-regs SA omdat die onveiligheid-aanvaardes in IBDecoder meer gelukkig is. Om selfs hoër speedskoppe te bereik, ondersoek ons hybridmodele waar ons of samekoms veelvuldige nabyge tekens per rigting voorsoek, of multidireksionale dekodering uitvoer deur die doel sekvens te partisieer. Hierdie metodes bereik speedkoppe tot 4x-11x oor verskillende opdragte na die koste van 1 BLES of 0.5 ROUGE (op gemiddelde)", 'tr': "Seçmeli dökülme sırasında bağımsızlık tahminleri a şağılık hızlandırabilir, fakat paralel tarafından yüksek bağımsız tokanların üstüne bir keyfiye ulaşır. Komşu işaretlerden (semi-autoregressiv ködleme, SA) özgürlügini çaklamak ýerine, biz diýen sözlerimizden ilham alýarys we şu ýerde gurumlu sözleri soldan sagdan we sagdan soldan saýla yönlendirýän bir dekodere girdirýäris. Biz bir deňil dekoder üçin standart arhitektura a ňsatlyk edip, iki yönden aýryp, söz ýerlerini we özgürlük maskelerini täsirleýän şekilde üýtgedip bileris. Biziň öňündeki 2-deňlik dekoderimiz (IBDecoder) standart Transformer ýäniň basitlerligini we paýlamak etkinligini, we beş maşynyň terjime etmek zadynda we iki sened toplamak zadynda , awtomatik regressiv ködleme bilen karşılaşykly bir şekilde ~2x'iň depesini golaýlaşýar. Adatça, bu SA-dan soldan saga üstün edýär sebäbi IBDecoderde özgürlüginiň ynamlarynyň kän gazanlygyna seredýär. Hatta ýokary ýokary hızlanmak üçin, biz hybrid modellerini araştırıyoruz. Birden hem bir çeşit komşu işaretçiler tarapynda tahmin edip, ya da maksadyň dizisini bölüşerek birden çoklu yönde kodlamak üçin. Bu yönler 1 BLEU ýa 0.5 ROUGE üçin farklı işiň ýüzerinde 4x-11x derejesine ýetip bilýärler.", 'am': 'በተለያዩ ትውልድ ውስጥ የነፃነት ግንኙነት ግንኙነት ማድረግ ይችላል፤ ነገር ግን የበለጠ ተቃውሞ የሚታመሙ ምልክቶች በጥጋት ትክክል ይደርሳሉ፡፡ በባልንጀራው ምልክቶች መካከል ነፃነት (semi-autoregressive decoding, SA) በሚያሳየው ፋንታ አንቀላቅልናል፤ ከጥያቄ ትውልድ እና ከግራ ወደ ቀኝ ወደ ግራ እና ወደ ግራ በመንገድ የሚደረገውን የግል ቃላትን እናሳውቃለን፡፡ እናሳያቸዋለን የዓላማዊ መሠረት አካባቢ እና የሁለቱን መንገዶች እና የቃላትን ቦታ እና የፍላጎት መክፈቻን በመቀላቀል እናደርጋለን፡፡ እና በአምስት ማሻሻገር ትርጉም ስራዎችን እና ሁለት ሰነድ ማጠቃለያ አድራጊዎችን እና በራሱ አካባቢ ክፍል ማድረግ ማድረጊያውን እና ማህበራዊ ክፍል ማድረግ ማድረግ ማድረጊያውን እና ማህበራዊ ክፍተት ታደርጋለች፡፡ በተጨማሪም፣ የIBDecoder ነፃነት አካባቢ መሆኑን ከግራ ወደ ቀኝ ወደ አሜሪካ ይደርሳል፡፡ ከፍተኛ ፈጥኖችን ለማግኘት፣ የኬብሪዲ ሞዴላዎችን እናሳውቃለን፤ በዚህች ጊዜም በየመንገዱ ብዙ የአካባቢ ምልክቶችን እናሳውቃለን፤ ወይም አካሄዱን በክፍል በማካፈል ብዙዎችን የመግለጫ አካሄድን እናደርጋለን፡፡ እነዚህ ሥርዓቶች በ1 BLEU ወይም 0.5 ROUGE (በመተካከለኛ)', 'hy': 'Հաջորդականության ընթացքում անկախության ենթադրությունները կարող են արագացնել եզրակացությունը, բայց բարձր միմյանց կախված նշանների զուգահեռ սերունդը գնում է որակի վրա: Instead of assuming independence between neighbouring tokens (semi-autoregressive decoding, SA), we take inspiration from bidirectional sequence generation and introduce a decoder that generates target words from the left-to-right and right-to-left directions simultaneously.  Մենք ցույց ենք տալիս, որ մենք հեշտությամբ կարող ենք փոխակերպել միաուղղակի կոդավորման ստանդարտ ճարտարապետություն երկուղղակի կոդավորման միջոցով պարզապես փոխանցելով երկու ուղղությունները և հարմարեցնելով բառերի դիրքերը և ինքնաճարպակալման դիմակները: Մեր միջթղթային երկու ուղղությամբ դեկոդերը (IBDeKoder) պահպանում է ստանդարտ տրանսֆերմերի պարզությունը և ուսուցման արդյունավետությունը, և հինգ մեքենային թարգմանման և երկու փաստաթղթերի համառոտագրման խնդիրների վրա, հասնում է~ 2x արագությամբ կոդավորման համեմատական որակով համեմատական Հատկապես, այն ավելի լավ է քան ձախ-աջ ՍԱ-ն, քանի որ IBDeCOder-ի անկախության ենթադրությունները ավելի երջանիկ են: Ավելի բարձր արագությունների հասնելու համար մենք ուսումնասիրում ենք հիբրիդ մոդելներ, որտեղ կամ միաժամանակ կանխատեսում ենք հարևանյան բազմաթիվ նշաններ յուրաքանչյուր ուղղությամբ, կամ կատարում ենք բազմաուղղությամբ բաժանելով նպատակային հաջորդականություն Այս մեթոդները հասնում են 4x-11x արագությամբ տարբեր առաջադրանքների ընթացքում 1 ԲԼԵՎ կամ 0.5 ՌՈւԳ (միջինում)', 'az': "Seçmə nəsili sırasında təhlükəsizlik təhlükəsi infeksiyonu hızlandıra bilər, amma yüksək təhlükəsizlik möcüzələrinin paralel nəsili keyfiyyəti ilə gəlir. Komşu əlamətlər arasındakı bağımsızlıq (yarı-autoregressiv kodlama, SA) təşkil etmək yerinə, biz bir-birimiz dəyişiklik sequence nəsilindən ilham alırıq və sol-sağa və sol tərəflərindən məqsəd sözləri yaradan bir dekoderi təşkil edirik. Biz göstəririk ki, bir tərəfli kodlama üçün standart arhitektura asanlıqla iki tərəfdən ayrılıb, sözlərin məqamlarını və özlük maskələrini uygulamaq üçün müəyyən edərik. Bizim interleaved bidirectional decoder (IBDecoder) standart Transformer'in modelinin basitlığını və təhsil etkinliğini saxlayar, beş maşın çeviri işləri və iki dökümət təhsil işləri ilə müqayisədə ~2x'in kodlama hızlandırması ilə müqayisədə müəyyən qiymətlə qaytarır. Bəlkə, IBDecoderdə bağımsızlıq zənnələri daha çox uğursuzdur. Daha yüksək hızlandırmaq üçün hibrid modellərini keşfetirik. Biz ya bir-birimiz tərəfdə bir çox qoşun möcüzələrini təşkil edirik, ya da məqsəd seçməsini parçalayıb çoxlu tərəfli kodlama edərik. Bu metodlar 1 BLEU ya da 0,5 ROUGE müqabilində fərqli işlərdə 4x-11x hızlandırmağını sağlar.", 'bs': 'Pretpostavke nezavisnosti tijekom generacije sekvence mogu ubrzati infekciju, ali paralelna generacija visoko međuovisnih znakova dolazi po cijenu kvalitete. Umjesto da pretpostavimo nezavisnost između susjednih znakova (polu-autoregresivnog dekodiranja, SA), poduzimamo inspiraciju iz generacije bidirektivne sekvence i predstavljamo dekodiranje koji stvara ciljne riječi iz lijeve na desno i desno na lijevo. Pokazujemo da možemo lako pretvoriti standardnu arhitekturu za jednosmjernu dekodiranje u dvosmjernu dekodiranju, jednostavno prekidajući dvije smjernice i prilagoditi pozicije riječi i maske sebičnosti. Naš interleaved bidirectional dekoder (IBDecoder) zadržava model jednostavnosti i učinkovitosti obuke standardnog transformera, a na pet zadataka za prevod mašine i dva zadataka za sažetak dokumenta postiže brzinu dekodiranja ~2x u usporedbi s autoregresivnim dekodiranjem s usporednom kvalitetom. U svakom slučaju, to iznosi lijevo-desno SA jer su pretpostavke nezavisnosti u IBDecoderu srećnije. Da bi postigli još veće brzine, istražujemo hibridne modele u kojima ili istovremeno predviđamo višestruke komšijske znakove po smjeru, ili izvršimo višedirektivnu dekodiranje particijom ciljne sekvence. Ove metode postižu brzinu do 4x-11x u različitim zadatkima na troškovi od 1 BLEU ili 0,5 ROUGE (u prosjeku)', 'sq': 'Supozimet e pavarësisë gjatë gjenerimit të sekuencës mund të përshpejtojnë inferencën, por gjenerimi paralel i tokave shumë të ndërvarura vjen me një kosto në cilësi. Në vend që të marrim pavarësinë midis shenjave fqinjë (dekodim gjysmë-autoregresiv, SA), ne marrim frymëzim nga gjenerata e sekuencës dy-drejtuese dhe futim një dekodim që gjeneron fjalë objektive nga drejtimet e majtë në të djathtë dhe të djathtë në të majtë në të njëjtën kohë. Ne tregojmë se ne mund të konvertojmë lehtë një arkitekturë standard për dekodim njëdrejtues në një dekodim dy drejtues duke thjesht ndërlidhur dy drejtimet dhe duke përshtatur pozicionet e fjalës dhe maskat e vetëfat. Dekoduesi ynë dy-drejtues (IBDecoder) mban modelin e thjeshtësisë dhe efikasitetit të trajnimit të Transformuesit standard dhe në pesë detyra përkthimi automatik dhe dy detyra të përmbledhjes së dokumenteve, arrin një shpejtësi dekodimi prej ~2x krahasuar me dekodimin autoregressiv me cilësi të krahasueshme. Në mënyrë të veçantë, ajo është më e mirë se SA-ja e majtë në të djathtë sepse supozimet e pavarësisë në IBDecoder janë më të lumtur. Për të arritur edhe më shumë shpejtësi, ne eksplorojmë modele hibride ku ose parashikojmë njëkohësisht shumë shenja fqinjë për drejtim, ose kryejmë dekodimin shumëdrejtues duke ndarë sekuencën e objektivit. Këto metoda arrijnë shpejtësi në 4x-11x nëpërmjet detyrave të ndryshme me koston e 1 BLEU ose 0.5 ROUGE (mesatarisht)', 'bn': 'সেকেন্ড প্রজন্মের সময় স্বাধীনতা ধারণা বৃদ্ধি করতে পারে, কিন্তু প্রজন্ম অত্যন্ত নির্ভরিত প্রতীকের প্রজন্ম ম মানের মূল্যের দামের প্রতিবেশী চিহ্নের মধ্যে স্বাধীনতা ধারণা করার পরিবর্তে আমরা বিদ্যুত প্রজন্ম থেকে অনুপ্রেরণা নিয়েছি এবং একটি ডিকোডার তুলে ধরেছি যা বাম থেকে ডান থেকে বাম থেকে বাম থেকে বাম দিক আমরা দেখাচ্ছি যে আমরা সহজেই একটি স্থান্যান্ডার্ড কাঠামো পরিবর্তন করতে পারি একটি বিদ্যুত ডিকোডারের জন্য, কেবল দুটি দিক থেকে বেরিয়ে যেতে পারি এবং শব্দের আমাদের মধ্যে প্রতিষ্ঠিত বিটারেক্টর ডেকোডার (আইবিডেকোডার) স্বাভাবিক ট্রান্ডার ট্রান্সফারের সাধারণ এবং পাঁচটি মেশিন অনুবাদ কাজ এবং দুটি নথি সংক্রান্ত কাজের উপর মডেলের সাধারণ এবং প এটা বাম থেকে ডান দিক থেকে এসএ প্রকাশ করে কারণ আইবিডেকোডারের স্বাধীনতার ধারণা আরো সফল। এমনকি আরো বেশী গতি অর্জনের জন্য আমরা হাইব্রিড মডেল খুঁজে বের করি যেখানে আমরা একই সাথে প্রতি দিকে বেশ কিছু প্রতিবেশী চিহ্ন প্রতিবেশী প্রতীকের প্রতিটি দিক এই পদ্ধতিগুলো বিভিন্ন কাজের মধ্যে ৪x-১১x-এর গতি পৌঁছায় ১ বিলিউ অথবা ০. ৫ রুজের (গড়ে)', 'et': 'Sõltumatuse eeldused jada genereerimisel võivad kiirendada järeldusi, kuid väga omavahel sõltuvate tokenite paralleelne genereerimine toob kaasa kvaliteedi hinna. Selle asemel, et eeldada sõltumatust naabermärkide vahel (poolaurregressiivne dekodeerimine, SA), võtame inspiratsiooni kahesuunalisest jada genereerimisest ja tutvustame dekoderit, mis genereerib sihtsõnu samaaegselt vasakult paremale ja paremalt vasakule suunas. Näitame, et ühesuunalise dekodeerimise standardarhitektuuri saame lihtsalt kahesuunaliseks dekodeerimiseks muuta, lihtsalt vahetades kahe suuna ning kohandades sõna asendeid ja enesetähelepanu maske. Meie vahelduv kahesuunaline dekooder (IBDecoder) säilitab standardse Transformeri mudeli lihtsuse ja koolituse efektiivsuse ning viie masintõlke ülesande ja kahe dokumendi kokkuvõtte ülesande puhul saavutab dekodeerimise kiiruse ~2x võrreldes autoregressiivse dekodeerimisega võrreldes võrreldava kvaliteediga. Eelkõige ületab see vasakult paremale SA, sest IBDecoderi sõltumatuse eeldused on õnnelikumad. Veelgi suuremate kiiruste saavutamiseks uurime hübriidmudeleid, kus me kas ennustame üheaegselt mitut naabermärki suunas või teostame mitmesuunalist dekodeerimist sihtmärgi jaotamise teel. Nende meetoditega saavutatakse erinevate ülesannete puhul 4x-11x kiirendus 1 BLEU või 0,5 ROUGE (keskmiselt)', 'cs': 'Předpoklady nezávislosti během generování sekvencí mohou urychlit inferenci, ale paralelní generování vysoce vzájemně závislých tokenů přichází s náklady na kvalitu. Namísto toho, abychom předpokládali nezávislost mezi sousedními tokeny (semi-autoregresivní dekódování, SA), se inspirujeme obousměrným generováním sekvencí a zavádíme dekodér, který generuje cílová slova současně ze směru zleva doprava a zprava doleva. Ukazujeme, že můžeme snadno převést standardní architekturu pro jednosměrné dekódování na obousměrný dekodér jednoduchým prolínáním obou směrů a přizpůsobením slovních poloh a masek sebepozornosti. Náš prokládaný obousměrný dekodér (IBDecoder) zachovává jednoduchost modelu a efektivitu školení standardního transformátoru a na pěti úlohách strojového překladu a dvou úlohách shrnutí dokumentů dosahuje dekódování o ~2x ve srovnání s autoregresivním dekódováním se srovnatelnou kvalitou. Pozoruhodněji překonává levou doprava SA, protože předpoklady nezávislosti v IBDecoderu jsou správnější. Pro dosažení ještě vyšších rychlostí zkoumáme hybridní modely, kde buď současně předpovídáme více sousedních tokenů na směr, nebo provádíme vícesměrné dekódování rozdělením cílové sekvence. Tyto metody dosahují zrychlení na 4x-11x při různých úkolech za cenu 1 BLEU nebo 0,5 ROUGE (v průměru)', 'ca': "Les suposicions d'independència durant la generació de seqüències poden accelerar la inferència, però la generació paralèl·lela de fitxes altament inter dependent arriba a un cost de qualitat. En lloc d'assumir la independència entre les fitxes veïnes (decodificació semi-autoregressiva, SA), prenem inspiració de la generació de seqüències bidireccionals i introduim un decodificador que genera paraules alvo de les direccions esquerra a dreta i dreta a esquerra simultàneament. We show that we can easily convert a standard architecture for unidirectional decoding into a bidirectional decoder by simply interleaving the two directions and adapting the word positions and selfattention masks.  El nostre decodificador bidireccional interleaven (IBDecoder) manté la simplicitat del model i l'eficiència d'entrenament del Transformer standard, i en cinc tasques de traducció màquina i dues tasques de resum de documentos, aconsegueix una velocitat de decodificació de ~2x comparada amb la decodificació autoregressiva de qualitat comparable. En especial, supera la SA d'esquerra a dreta perquè les suposicions d'independència del IBDecoder són més felices. Per aconseguir una velocitat encara més alta, explorem models híbrids on o predim simultàniament múltiples fitxes veïnes per direcció, o fem una descodificació multidireccional dividint la seqüència d'objectiu. Aquests mètodes aconsegueixen velocitats fins a 4x-11x en diverses tasques al cost de 1 BLEU o 0,5 ROUGE (mitjana)", 'fi': 'Riippumattomuusoletukset sekvenssien luomisen aikana voivat nopeuttaa päättelyä, mutta hyvin riippuvaisten polettien rinnakkaisen tuottamisen laatu maksaa. Sen sijaan, että oletamme riippumattomuutta naapurimerkkien välillä (semi-autoregressive decoding, SA), otamme inspiraatiota kaksisuuntaisesta sekvenssin generoinnista ja esittelemme dekooderin, joka tuottaa kohdesanoja vasemmalta oikealle ja oikealta vasemmalle samanaikaisesti. Osoitamme, että voimme helposti muuntaa yksisuuntaisen dekooderin standardiarkkitehtuurin kaksisuuntaiseksi dekooderiksi yksinkertaisesti yhdistämällä kaksi suuntaa ja mukauttamalla sanan asentoja ja itsehuomiomaskeja. Interleaved kaksisuuntainen dekooderimme (IBDecoder) säilyttää vakiomuuntajan mallin yksinkertaisuuden ja koulutustehokkuuden, ja viidessä konekäännöstehtävässä ja kahdessa asiakirjayhteenvetotehtävässä dekooderin nopeus on ~ 2x verrattuna samanlaatuiseen autoregressiiviseen dekooderiin. Erityisesti se ylittää vasemmalta oikealle SA:n, koska IBDecoderin riippumattomuutta koskevat oletukset ovat onnellisempia. Saavuttaaksemme vieläkin suurempia nopeuksia tutkimme hybridimalleja, joissa joko ennustamme samanaikaisesti useita vierekkäisiä merkkiä kohti tai suoritamme monisuuntaista dekoodaamista jakamalla kohdesekvenssin. Näillä menetelmillä nopeutetaan jopa 4x-11x eri tehtävissä yhden BLEU:n tai 0,5 ROUGE:n hinnalla (keskimäärin)', 'jv': "Awakdhéwan dipuangkapuripun kanggo ngerasahan seneng dolanung sumunggal Tanian nguasai perusahaan ijol-ijolan gambar token (semi-autoRegresative decoding, S), kita nguasai alam sing ngendalikke tarjamahan seneng operasi wis diperaksi dan nguasai perusahaan winih sing ngendalikke tarjamahan sing wis alêr, iso nggawe nguasai perusahaan langkung sampeyan kaya-sampeyan kaya-sampeyan. Awak dhéwé ngerti, kita akeh perusahaan akeh liyane nggawe lan akeh basa luwih dumateng manut kanggo decoder biasane winih dhéwé. iki dadi wis dipun wae dadi iki bakal terus apik lan ngawe jane sampek ujaran gambar nggawe gerakan sampek awak dhéwé. Awak dhéwé interliwend Biireksyonal decoder Yok wis ngerti, iso iso iso nggawe kayah-kayah 'S' soalé mergane kuwi kaleh-kaya sing luwih basa ning IBDekoder bookmark Awak dhéwé éntuk kanggo kalawat kanggo 4x-11x dadi sampeyan kanggo kowe barang 1 B luwih kanggo 0.5 LOUGE (supayano sakjane)", 'ha': "Fikiron da ɗaitacce a lokacin kizayen sakan, za'a iya ƙara wata wagon kwamfyuta, kuma amma masu daidaita zayen wata masu sarrafa da baka-daban-dabar-daban, za'a zo da kyautar da nau'in. Badan ka yi kudai da kansa da jigon ayukan jiran (shekarar-fara-fara, SA), za mu yi wahayi da shi daga danni na ƙari na daban-daban kuma Mu ƙãga wani kodi wanda ke ƙara maganar hagu-dama da dama-hagu sami. Tuna nuna cewa, za mu iya iya musanya matsayin tsarin da ke daidaita wa kodi na koma zuwa kodi na dabar-daba'a, ka bar ta guda guda biyu kuma mu canza masu tsarin maganar da maɓallin mutane. @ info: whatsthis Ina sani, tanã fara SA daga hagu zuwa dama, kwani zato da ba'a so da ɗayan zato a cikin IBDeoder, za'a sami babban rabo. To, dõmin ka isa mafiya sauri, za'a sami misãlai ya yi hibiri, inda ko ko kuma muna yi bayani ko kuma ko ko ko kuma ka sami kodi da sauri masu motsi ko kuma don ka yi rabo da sauri masu motsi na goan. Waɗannan hanyoyin su sami fartowa zuwa 4x-11x kowace aikin dabam-dabam a kasar 1 BLEU ko 0.5 RUGE (mai daidaita)", 'sk': 'Predpostavke neodvisnosti med generacijo zaporedja lahko pospešijo sklepanje, vendar vzporedna generacija zelo medsebojno odvisnih žetonov prinaša ceno kakovosti. Namesto da bi prevzeli neodvisnost med sosednjimi žetoni (semi-avtoregresivno dekodiranje, SA), se navdihujemo iz dvosmernega zaporedja in uvajamo dekodir, ki hkrati ustvarja ciljne besede iz leve proti desni in desni proti levi smeri. Pokazujemo, da lahko standardno arhitekturo enosmernega dekodiranja zlahka pretvorimo v dvosmerni dekodir, tako da preprosto prepletamo obe smeri in prilagodimo položaje besed in maske samopozornosti. Naš medsebojni dvosmerni dekodirni (IBDecoder) ohranja preprostost modela in učinkovitost usposabljanja standardnega transformatorja, pri petih strojnem prevajanju in dveh nalogah povzemanja dokumentov pa doseže ~2x pospešitev dekodiranja v primerjavi s samoregresivnim dekodiranjem s primerljivo kakovostjo. Zlasti je boljša od leve proti desni SA, ker so predpostavke o neodvisnosti v IBDecoderju bolj zadovoljive. Da bi dosegli še večje hitrosti, raziskujemo hibridne modele, kjer hkrati napovedujemo več sosednjih žetonov na smer ali pa izvajamo večsmerno dekodiranje z razdelitvijo ciljnega zaporedja. S temi metodami dosežemo pospešitev do 4x-11x pri različnih nalogah za ceno 1 BLEU ali 0,5 ROUGE (v povprečju)', 'bo': 'རྒྱ་ནག དེ་ལས་ ཁྱིམ་ཚང་གི་དཔེ་མཚོན་རྟགས་དབར་གྱི་རང་བཞིན་གྱིས་བསམ་བློ་གཏོང་མི་སྦེ། འུ་ཅག་གིས་འདི་ང་ཚོས་རང་ཉིད་ཀྱིས་སྔོན་གྱི་བཟོ་བཀོད་པ་ཞིག་གི་གནས་སྟངས་གཅིག་གམ་གྲངས་སྒྲིག་ཆ་སྒྲིག་འཛིན་གྱི་གནས་སྟངས་དང་རང་ཉིད་མེད་གདོ Our interleaved bidirectional decoder (IBDecoder) retains the model simplicity and training efficiency of the standard Transformer, and on five machine translation tasks and two document summarization tasks, achieves a decoding speedup of ~2x compared to autoregressive decoding with comparable quality. ལྷན་མ་རེད། དེ་ནི་ཨ་སི་ཨ་ཕུང་ལ་གཡོན་ཕྱོགས་ཀྱི་ལས་འགན་འགྲོ་བ་རེད། གང་ལེགས་ཞེ་ན། IBDecoder ནང་གི་རང་ཉིད་སྟོན་རྟོགས་ To achieve even higher speedups, we explore hybrid models where we either simultaneously predict multiple neighbouring tokens per direction, or perform multi-directional decoding by partitioning the target sequence. To achieve even higher speedups ཐབས་ལམ་འདི་དག་གིས་བྱ་ཚིག་གཞན་ཞིག་ལ་4x-11x རིང་ཚད་མེད་སྐྱེས་པ་དང་། སྡེ་རིམ་༡ ཞིག་གནང་གི་ཚད་ལྡན་སྒྲིག', 'he': 'ההנחות של עצמאות במהלך הדור של רצף יכולות להאיץ את המצאה, אך דור מקביל של סימנים בין-תלויים מאוד מגיעים בעלות באיכות. במקום להניח עצמאות בין סימנים שכיניים (פיקוד חצי-אוטורגרסיבי, SA), אנו מקבלים השראה מדור רצף שתי כיוונים ומציג פיקוד שיוצר מילים מטרה מכיוון שמאל ימין ימין לשמאל באותו זמן. We show that we can easily convert a standard architecture for unidirectional decoding into a bidirectional decoder by simply interleaving the two directions and adapting the word positions and selfattention masks.  Our interleaved bidirectional decoder (IBDecoder) retains the model simplicity and training efficiency of the standard Transformer, and on five machine translation tasks and two document summarization tasks, achieves a decoding speedup of ~2x compared to autoregressive decoding with comparable quality.  במיוחד, הוא יוצא מעל SA שמאל לימין כי ההנחות על עצמאות ב IBDecoder הם יותר מאושרים. To achieve even higher speedups, we explore hybrid models where we either simultaneously predict multiple neighbouring tokens per direction, or perform multi-directional decoding by partitioning the target sequence.  These methods achieve speedups to 4x-11x across different tasks at the cost of 1 BLEU or 0.5 ROUGE (on average)'}
{'en': 'Towards Multimodal Simultaneous Neural Machine Translation', 'ar': 'نحو ترجمة آلية عصبية متعددة الوسائط', 'pt': 'Em direção à tradução automática neural simultânea multimodal', 'fr': 'Vers une traduction automatique neuronale simultanée multimodale', 'es': 'Hacia la traducción automática neuronal simultánea multimodal', 'ja': 'マルチモーダル同時神経機械翻訳に向けて', 'ru': 'К мультимодальному синхронному нейронному машинному переводу', 'zh': '迈向多模态同声传导神经机器翻译', 'hi': 'बहुआयामी एक साथ तंत्रिका मशीन अनुवाद की ओर', 'ga': 'I dTreo Aistriúchán Inneall Néarach Comhuaineach Ilmhódach', 'ka': 'Multimodal Simultaneous Neural Machine Translation', 'hu': 'A multimodális egyidejű neurális fordítás felé', 'el': 'Προς την πολυμodale ταυτόχρονη νευρωνική μηχανική μετάφραση', 'it': 'Verso la traduzione automatica neurale simultanea multimodale', 'lt': 'Towards Multimodal Simultaneous Neural Machine Translation', 'kk': 'Көп модельді бірдей нейрондық машинаның аудармасына қарсы', 'mk': 'КАД МУЛТОМОДАЛНА СИМУЛТЕНА НЕВРАЛНА Машина', 'ms': 'Ke arah Terjemahan Mesin Neural Simultaneous Multimodal', 'mt': 'Lejn Traduzzjoni Multimodali Simultanja ta’ Magna Newrali', 'ml': 'മുകളിലേക്ക് മള്\u200dമോഡല്\u200d പോലെ നെയുറല്\u200d യന്ത്രം പരിഭാഷപ്പെടുത്തുക', 'no': 'Til fleire modular simulert neuralmaskinsomsetjing', 'mn': 'Олон моделийн нэг төрлийн мэдрэлийн машин хөгжүүлэх рүү', 'pl': 'W kierunku multimodalnego jednoczesnego neuronowego tłumaczenia maszynowego', 'ro': 'Către traducerea automată neurală simultană multimodală', 'si': 'ගොඩමෝඩාල් සාමාන්\u200dය සාමාන්\u200dය මැෂින් පරිවර්තනයට', 'sr': 'Do multimodalnog simulacijskog prevoda neuromašine', 'so': 'Towards Multimodal Simultaneous Neural Machine Translation', 'sv': 'Mot multimodal simultan neural maskinöversättning', 'ta': 'மேலே பல மாற்று ஒரே நெருக்கி இயந்திரம் மொழிபெயர்ப்பு', 'ur': 'Multimodal Simultaneous Neural Machine Translation', 'uz': 'Name', 'vi': 'Dịch sang máy thần kinh đa chiều', 'bg': 'Към мултимодален едновременен неврален машинен превод', 'da': 'På vej mod multimodal simultan neural maskinoversættelse', 'nl': 'Naar multimodale gelijktijdige neurale machinevertaling', 'hr': 'Do multimodalnog sličnog neuronskog prevoda stroja', 'de': 'Auf dem Weg zur multimodalen simultanen neuronalen maschinellen Übersetzung', 'ko': '다중모드 동기화 신경', 'id': 'Menuju Multimodal Simultaneous Machine Neural Translation', 'fa': 'به سمت ترجمه ماشین عصبی چندین مدل', 'sw': 'Tafsiri ya Mashine ya Njerumani', 'af': 'Gaan na Multimodaal Simuleerde Neurale Masjien Vertaling', 'tr': 'Birnäçe modal Taýpli Neural Maşynyň Çeviri', 'sq': 'Në drejtim të përkthimit Multimodal Simultan të Makinës Neurale', 'am': 'ምርጫዎች', 'hy': 'Մոլորմոդալ միաժամանակ նյարդային մեքենայի թարգմանման ուղղությամբ', 'az': 'Multimodal Sim칲l N칬ral Makina 칂eviri t톛r톛find톛', 'bs': 'Do multimodalnog simuliranog neuronskog prevoda stroja', 'bn': 'মাল্টিমোডাল একই সাথে নিউরেল মেশিন অনুবাদ', 'ca': 'Vers la traducció simultànea de màquines neurones multimodals', 'cs': 'Směrem k multimodálnímu simultánnímu neuronovému strojovému překladu', 'et': 'Multimodaalse samaaegse neuroaalse masintõlke suunas', 'fi': 'Kohti multimodaalista samanaikaista neurokääntämistä', 'he': 'Towards Multimodal Simultaneous Neural Machine Translation', 'ha': '@ action', 'sk': 'K večmodalnemu sočasnemu živčnemu strojnemu prevajanju', 'jv': 'Tulung Multimodal Simultaneous Neral Masine Terjamahan', 'bo': 'སྣ་ཚོགས་འདྲ་བ་དང་བསྟུན་ནས་དབང་བའི་མིའི་ལག་འཁྱེར་ལ་བསྒྱུར་བ'}
{'en': 'Simultaneous translation involves translating a sentence before the speaker’s utterance is completed in order to realize real-time understanding in multiple languages. This task is significantly more challenging than the general full sentence translation because of the shortage of input information during decoding. To alleviate this shortage, we propose multimodal simultaneous neural machine translation (MSNMT), which leverages visual information as an additional modality. Our experiments with the Multi30k dataset showed that MSNMT significantly outperforms its text-only counterpart in more timely translation situations with low latency. Furthermore, we verified the importance of visual information during decoding by performing an adversarial evaluation of MSNMT, where we studied how models behaved with incongruent input modality and analyzed the effect of different word order between source and target languages.', 'ar': 'تتضمن الترجمة الفورية ترجمة جملة قبل أن يكتمل نطق المتحدث من أجل تحقيق فهم في الوقت الفعلي بلغات متعددة. تعتبر هذه المهمة أكثر صعوبة من الترجمة العامة للجملة الكاملة بسبب نقص معلومات الإدخال أثناء فك التشفير. للتخفيف من هذا النقص ، نقترح الترجمة الآلية العصبية المتزامنة متعددة الوسائط (MSNMT) ، والتي تستفيد من المعلومات المرئية كطريقة إضافية. أظهرت تجاربنا مع مجموعة البيانات Multi30k أن MSNMT يتفوق بشكل كبير على نظيره النصي فقط في مواقف الترجمة في الوقت المناسب مع زمن انتقال منخفض. علاوة على ذلك ، قمنا بالتحقق من أهمية المعلومات المرئية أثناء فك التشفير من خلال إجراء تقييم عدائي لـ MSNMT ، حيث درسنا كيف تتصرف النماذج بطريقة إدخال غير متطابقة وقمنا بتحليل تأثير ترتيب الكلمات المختلفة بين لغات المصدر والهدف.', 'es': 'La traducción simultánea implica traducir una oración antes de que se complete la expresión del orador para lograr una comprensión en tiempo real en varios idiomas. Esta tarea es significativamente más desafiante que la traducción general de oraciones completas debido a la escasez de información de entrada durante la decodificación. Para aliviar esta escasez, proponemos la traducción automática neuronal simultánea multimodal (MSNMT), que aprovecha la información visual como una modalidad adicional. Nuestros experimentos con el conjunto de datos Multi30k mostraron que MSNMT supera significativamente a su homólogo de solo texto en situaciones de traducción más oportunas con baja latencia. Además, verificamos la importancia de la información visual durante la decodificación mediante la realización de una evaluación contradictoria de MSNMT, donde estudiamos cómo se comportaban los modelos con una modalidad de entrada incongruente y analizamos el efecto de un orden de palabras diferente entre los idiomas de origen y de destino.', 'pt': 'A tradução simultânea envolve a tradução de uma frase antes que a fala do falante seja concluída, a fim de realizar a compreensão em tempo real em vários idiomas. Essa tarefa é significativamente mais desafiadora do que a tradução geral de frases completas devido à falta de informações de entrada durante a decodificação. Para aliviar essa escassez, propomos a tradução automática neural simultânea multimodal (MSNMT), que aproveita a informação visual como uma modalidade adicional. Nossos experimentos com o conjunto de dados Multi30k mostraram que o MSNMT supera significativamente sua contraparte somente de texto em situações de tradução mais oportunas com baixa latência. Além disso, verificamos a importância da informação visual durante a decodificação realizando uma avaliação adversarial do MSNMT, onde estudamos como os modelos se comportavam com a modalidade de entrada incongruente e analisamos o efeito da ordem diferente das palavras entre os idiomas de origem e de destino.', 'fr': "La traduction simultanée consiste à traduire une phrase avant que l'énoncé de l'orateur ne soit terminé afin de réaliser une compréhension en temps réel dans plusieurs langues. Cette tâche est nettement plus difficile que la traduction générale d'une phrase complète en raison du manque d'informations d'entrée pendant le décodage. Pour pallier cette pénurie, nous proposons la traduction automatique neuronale simultanée multimodale (MSNMT), qui exploite les informations visuelles comme modalité supplémentaire. Nos expériences avec le jeu de données Multi30K ont montré que MSNMT surpasse considérablement son équivalent texte uniquement dans des situations de traduction plus rapides avec une faible latence. En outre, nous avons vérifié l'importance des informations visuelles pendant le décodage en effectuant une évaluation contradictoire de MSNMT, où nous avons étudié le comportement des modèles avec une modalité d'entrée incongrue et analysé l'effet de l'ordre des mots différent entre les langues source et cible.", 'zh': '同声传译及言者成语之前译一句,以成多种语言之实时解。 解码输信息不足,故比全句译更具挑战性。 为解此短缺,多模态同声传神经机器翻译(MSNMT),以视息为额外式。 吾于 Multi30k 数集之实验,于更时转换,MSNMT 性明优其纯文本,而迟延愈下。 此外对抗性料MSNMT以验之解码视息之要,论模形于不调之模态,析言语之词序。', 'ja': '同時翻訳とは、複数の言語でリアルタイムの理解を実現するために、発話者の発話が完了する前に文章を翻訳することです。このタスクは、デコード中の入力情報が不足しているため、一般的な全文翻訳よりも著しく困難です。この不足を緩和するために、視覚情報を追加のモダリティとして活用するマルチモーダル同時ニューラル機械翻訳（ MSNMT ）を提案します。Multi 30 kデータセットの実験では、MSNMTは、低遅延でよりタイムリーな翻訳状況で、テキストのみの相手を大幅に上回っていることが示されました。さらに、MSNMTの対抗評価を行い、デコード中の視覚情報の重要性を検証し、モデルが不整合な入力モダリティとどのように振る舞うかを研究し、ソース言語とターゲット言語の間の異なる語順の効果を分析した。', 'ru': 'Синхронный перевод включает в себя перевод предложения до завершения речи говорящего, чтобы реализовать понимание в реальном времени на нескольких языках. Эта задача является значительно более сложной, чем общий полный перевод предложения из-за нехватки входной информации во время декодирования. Чтобы уменьшить этот дефицит, мы предлагаем мультимодальный синхронный нейронный машинный перевод (MSNMT), который использует визуальную информацию в качестве дополнительной модальности. Наши эксперименты с набором данных Multi30k показали, что MSNMT значительно превосходит свой текстовый аналог в более своевременных ситуациях перевода с низкой задержкой. Кроме того, мы проверили важность визуальной информации во время декодирования, выполнив состязательную оценку MSNMT, где мы изучили, как модели вели себя с несогласованной модальностью ввода и проанализировали влияние различного порядка слов между исходным и целевым языками.', 'hi': 'एक साथ अनुवाद में कई भाषाओं में वास्तविक समय की समझ का एहसास करने के लिए स्पीकर के उच्चारण को पूरा करने से पहले एक वाक्य का अनुवाद करना शामिल है। डिकोडिंग के दौरान इनपुट जानकारी की कमी के कारण यह कार्य सामान्य पूर्ण वाक्य अनुवाद की तुलना में काफी अधिक चुनौतीपूर्ण है। इस कमी को कम करने के लिए, हम मल्टीमॉडल एक साथ तंत्रिका मशीन अनुवाद (MSNMT) का प्रस्ताव करते हैं, जो एक अतिरिक्त रूपरेखा के रूप में दृश्य जानकारी का लाभ उठाता है। Multi30k डेटासेट के साथ हमारे प्रयोगों से पता चला है कि MSNMT कम विलंबता के साथ अधिक समय पर अनुवाद स्थितियों में अपने पाठ-केवल समकक्ष को काफी बेहतर बनाता है। इसके अलावा, हमने एमएसएनएमटी का एक प्रतिकूल मूल्यांकन करके डिकोडिंग के दौरान दृश्य जानकारी के महत्व को सत्यापित किया, जहां हमने अध्ययन किया कि मॉडल ने असंगत इनपुट रूपरेखा के साथ कैसे व्यवहार किया और स्रोत और लक्ष्य भाषाओं के बीच विभिन्न शब्द क्रम के प्रभाव का विश्लेषण किया।', 'ga': "Is éard atá i gceist le haistriúchán comhuaineach ná abairt a aistriú sula gcríochnaítear caint an chainteora chun tuiscint fíor-ama a bhaint amach ar iltheangacha. Tá an tasc seo i bhfad níos dúshlánaí ná an t-aistriúchán ginearálta iomlán ar na habairtí mar gheall ar an easpa eolais ionchuir le linn díchódaithe. Chun an ganntanas seo a mhaolú, molaimid aistriúchán meaisín néarach comhuaineach ilmhódach (MSNMT), a úsáideann faisnéis amhairc mar mhodhúlacht bhreise. Léirigh ár dturgnaimh leis an tacar sonraí Multi30k go sáraíonn MSNMT a mhacasamhail téacs-amháin go suntasach i gcásanna aistriúcháin níos tráthúla agus nach bhfuil mórán foighne ann. Ina theannta sin, d'fhíoraigh muid an tábhacht a bhaineann le faisnéis amhairc le linn díchódaithe trí mheastóireacht sáraíochta a dhéanamh ar MSNMT, áit a ndearnamar staidéar ar conas a d'fheidhmigh samhlacha le modhúlacht ionchuir neamhréir agus rinneamar anailís ar éifeacht ord focal difriúil idir fhoinse agus sprioctheanga.", 'hu': 'Az egyidejű fordítás magában foglalja egy mondat fordítását, mielőtt a felszólaló kimondása befejeződik, hogy valós idejű megértést valósítson meg több nyelven. Ez a feladat jelentősen nagyobb kihívást jelent, mint az általános teljes mondat fordítása, mivel a dekódolás során nem rendelkeznek beviteli információk. A hiány enyhítése érdekében multimodális szimultán neurális gépi fordítást (MSNMT) javasolunk, amely kiegészítő módszerként használja a vizuális információt. A Multi30k adatkészlettel végzett kísérleteink azt mutatták, hogy az MSNMT jelentősen felülmúlja a csak szöveges megfelelőjét időszerűbb, alacsony késleltetésű fordítási helyzetekben. Ezenkívül ellenőriztük a vizuális információ fontosságát a dekódolás során az MSNMT ellentétes értékelésével, ahol tanulmányoztuk, hogy a modellek hogyan viselkedtek inkonsekvent bemeneti módszerrel, és elemeztük a forrás- és célnyelvek közötti eltérő szósorrend hatását.', 'ka': 'სხვადასხვა შეტყობინება შესაძლებელია სიტყვების შეტყობინება, რომელიც სხვადასხვა ენაში მნიშვნელოვანი წარმოდგენა. ეს დავალება ძალიან უფრო შესაძლებელია, ვიდრე საერთო სიტყვების შეცვლა, რადგან გამოყენებული ინფორმაციის ცოცხლის შემდეგ შეუძლებელია. ჩვენ მრავალური ნეიროლური მაქანის გაგრძელება (MSNMT), რომელიც ვიზუალური ინფორმაციას დამატებული მოდიალურად გამოყენებს. ჩვენი ექსპერიმენტები Multi30k მონაცემების კონფიგურაციაში გამოჩნდა, რომ MSNMT მნიშვნელოვანად მხოლოდ ტექსტის კონფიგურაციას უფრო დროს გადატარებული სიტაციაში დამატებით, ჩვენ დავაკვირეთეთ ვიზუალური ინფორმაციის მნიშვნელობა, რომელიც MSNMT-ის განსაზღვრებით გავაკეთებთ, სადაც ჩვენ ვისწავლით, როგორ მოდელები არასწორად გავაკეთებენ მოდელური ინფორმაციის მოდელობით და', 'el': 'Η ταυτόχρονη μετάφραση περιλαμβάνει τη μετάφραση μιας πρότασης πριν ολοκληρωθεί η ομιλία του ομιλητή προκειμένου να επιτευχθεί κατανόηση σε πραγματικό χρόνο σε πολλές γλώσσες. Αυτό το έργο είναι σημαντικά πιο δύσκολο από τη γενική μετάφραση πλήρους φράσης λόγω της έλλειψης πληροφοριών εισόδου κατά την αποκωδικοποίηση. Για την ανακούφιση αυτής της έλλειψης, προτείνουμε την πολυμορφική ταυτόχρονη νευρωνική μηχανική μετάφραση (η οποία αξιοποιεί την οπτική πληροφορία ως πρόσθετη μέθοδο. Τα πειράματά μας με το σύνολο δεδομένων έδειξαν ότι το MSNMT ξεπερνά σημαντικά το αντίστοιχο του μόνο κειμένου σε πιο έγκαιρες μεταφραστικές καταστάσεις με χαμηλή καθυστέρηση. Επιπλέον, επαληθεύσαμε τη σημασία της οπτικής πληροφορίας κατά την αποκωδικοποίηση με την πραγματοποίηση μιας αντιπαραβαλλόμενης αξιολόγησης του όπου μελετήσαμε πώς συμπεριφέρονται τα μοντέλα με ασυμβίβαστη μέθοδο εισαγωγής και αναλύσαμε την επίδραση της διαφορετικής τάξης λέξεων μεταξύ γλώσσας προέλευσης και γλώσσας προορισμού.', 'it': "La traduzione simultanea implica la traduzione di una frase prima che l'espressione dell'oratore sia completata al fine di realizzare una comprensione in tempo reale in più lingue. Questo compito è significativamente più impegnativo della traduzione generale della frase intera a causa della carenza di informazioni di input durante la decodifica. Per alleviare questa carenza, proponiamo la traduzione automatica neurale simultanea multimodale (MSNMT), che sfrutta le informazioni visive come modalità aggiuntiva. I nostri esperimenti con il dataset Multi30k hanno dimostrato che MSNMT supera significativamente la sua controparte solo testuale in situazioni di traduzione più tempestive con bassa latenza. Inoltre, abbiamo verificato l'importanza delle informazioni visive durante la decodifica eseguendo una valutazione avversaria di MSNMT, dove abbiamo studiato come i modelli si comportavano con modalità di input incongruente e analizzato l'effetto di diverso ordine delle parole tra lingua di origine e lingua di destinazione.", 'kk': 'Бірнеше аудармасы бірнеше тілдерде шын уақытты түсініктіру үшін сөзді аудару үшін бірнеше тілдерде бір сөзді аяқтау үшін болады. Бұл тапсырма декодтау кезіндегі келтірілген мәліметтің қысқартылығының жалпы сөздердің аудармасынан артық көмегімен байланысты. Бұл қысқартылығын көшірмелеу үшін бірнеше рет невралдық машинаның аударуын (MSNMT) ұсынамыз. Бұл көрініс мәліметін қосымша модельдік ретінде көшірмелейтін. Біздің Multi30k деректер жиынындағы тәжірибелеріміз MSNMT тек мәтіннің қатынасының көбірек уақытты аудару жағдайларында төмен болып тұрады дегенді көрсетті. Қосымша, біз MSNMT бағдарламасының қарсы мәліметін декодтау кезінде көрінетін мәліметтің маңыздылығын тексердік. Бұл жерде моделдердің қалай дұрыс келтірілмеген кезде қалай іске асырып, көзі мен мақсатты тілдер ара', 'mk': 'Симултанеозен превод вклучува превод на реченица пред да се заврши изразот на говорникот со цел да се оствари разбирање во реално време на повеќе јазици. Оваа задача е значително поважна од општиот превод на целата реченица поради недостатокот на информации за внесување за време на декодирањето. За да го олесниме ова недостаток, предлагаме мултимодитален симултимодитален нервен машински превод (MSNMT), кој ги користи визуелните информации како дополнителна моделност. Нашите експерименти со компјутерот на податоци Мулти30к покажаа дека MSNMT значително го надминува својот експеримент само за текст во повремени преводни ситуации со ниска тајност. Furthermore, we verified the importance of visual information during decoding by performing an adversarial evaluation of MSNMT, where we studied how models behaved with incongruent input modality and analyzed the effect of different word order between source and target languages.', 'lt': 'Tuo pačiu metu vertimas reiškia žodžio vertimą prieš baigiant kalbėtojo kalbą, kad būtų galima realiu laiku suprasti daugeliu kalbų. Ši užduotis yra gerokai sunkesnė nei bendrasis visiško sakinio vertimas dėl informacijos apie įvestį trūkumo dekoduojant. Siekiant sumažinti šį trūkumą, siūlome daugiarūšį vienu metu naudojamą neurologinį vertimą (MSNMT), kuris sutelkia vizualinę informaciją kaip papildomą būdą. Mūsų eksperimentai su Multi30k duomenų rinkiniu parodė, kad MSNMT gerokai viršija tik teksto priešingą laiku vertimo situacijose su mažu vėlavimu. Be to, mes patikrinome vizualinės informacijos svarbą dekoderuojant atlikdami prieštaringą MSNMT vertinimą, kuriame tirėme, kaip modeliai elgėsi neatitinkančiu įvedimo būdu ir analizavome skirtingos žodžių tvarkos tarp šaltinio ir tikslinių kalbų poveikį.', 'ml': 'പ്രസംഗിക്കുന്ന വാക്കുകള്\u200d പൂര്\u200dത്തിയാകുന്നതിനു മുമ്പ് ഒരു വാക്ക് വിഭാഷപ്പെടുത്തുന്നതിനായി ഒരു വാക്ക് പരിഭ പൊതുവായ വാക്ക് പരിഭാഷപ്പെടുത്തുന്നതിനെക്കാള്\u200d ഈ ജോലിയാണ് കുറച്ച് വിലപാടാക്കുന്നത്. കോഡിങിങ്ങിനു ഈ കുറവ് ലഘൂകരിക്കാന്\u200d, ഒരേ സമയത്ത് നമ്മള്\u200d പല്ടിമോഡാല്\u200d നെയൂറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നു. അത് കൂടുതല്\u200d വിവരങ്ങള്\u200d കാണുന്നതായി  Multi30k ഡാറ്റാസെറ്റുകളുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു MSNMT അതിന്റെ ടെക്സ്റ്റ് മാത്രം വിഭാഗങ്ങള്\u200d കുറച്ച് സമയ Furthermore, we verified the importance of visual information during decoding by performing an adversarial evaluation of MSNMT, where we studied how models behaved with incongruent input modality and analyzed the effect of different word order between source and target languages.', 'mt': 'It-traduzzjoni simultanja tinvolvi t-traduzzjoni ta’ sentenza qabel ma jitlesta l-espressjoni tal-kelliem sabiex jiġi realizzat fehim f’ħin reali f’diversi lingwi. Dan il-kompitu huwa ferm aktar sfida mit-traduzzjoni ġenerali tas-sentenza sħiħa minħabba n-nuqqas ta’ informazzjoni input waqt id-dekodifikazzjoni. Biex itaffu dan in-nuqqas, nipproponu traduzzjoni multimodali simultanja tal-magni newrali (MSNMT), li tagħti spinta lill-informazzjoni viżwali bħala modalità addizzjonali. L-esperimenti tagħna bis-sett tad-dejta Multi30k urew li l-MSNMT qed tippreżenta b’mod sinifikanti l-kontroparti tagħha biss bit-test f’sitwazzjonijiet ta’ traduzzjoni aktar f’waqthom b’dewmien baxx. Furthermore, we verified the importance of visual information during decoding by performing an adversarial evaluation of MSNMT, where we studied how models behaved with incongruent input modality and analyzed the effect of different word order between source and target languages.', 'mn': 'Үүнтэй адилхан орчуулалт нь илтгэгчийн яриаг дуусахаас өмнө нэг үг орчуулах нь олон хэл дээр бодит цаг ойлголтыг ойлгохын тулд юм. Энэ үйл ажиллагаа бүрэн өгүүлбэрээс илүү хэцүү болж байгаа. Ингээд өгүүлбэрээр мэдээллийн бага байхаас илүү хэцүү. Энэ багасгалыг багасгахын тулд бид олон моделийн мэдрэлийн давхар машины хөрөнгө оруулалт (MSNMT) гэсэн санал болгодог. Энэ нь харааны мэдээллийг нэмэлт арга хэмжээнд ашиглана. Бидний Multi30k өгөгдлийн сангийн туршилтууд MSNMT нь текст зөвхөн хамтрагчдыг илүү цаг хугацаанд орчуулах нөхцөл байдлаар илүү чухал байдаг гэдгийг харуулсан. Үүнээс гадна бид MSNMT-ийн эсрэг дүгнэлт хийж, харааны мэдээллийн чухал ач холбогдолыг шийдсэн. Тэнд бид загварууд хэрхэн нөлөөлдөг орхих болон зорилготой хэлний хооронд өөр хэлний дарааллын нөлөөг шинжилсэн.', 'ms': 'Terjemahan bersamaan melibatkan terjemahan kalimat sebelum ucapan pembicara selesai untuk menyadari pemahaman masa-nyata dalam berbilang bahasa. Tugas ini jauh lebih mencabar daripada terjemahan kalimat penuh umum kerana kekurangan maklumat input semasa penyahkodan. To alleviate this shortage, we propose multimodal simultaneous neural machine translation (MSNMT), which leverages visual information as an additional modality.  Eksperimen kami dengan set data Multi30k menunjukkan bahawa MSNMT secara signifikan melebihi kontrak teks-sahaja dalam situasi terjemahan lebih tepat masa dengan kelemahan rendah. Selain itu, kami mengesahkan kepentingan maklumat visual semasa penyahkodan dengan melakukan penilaian musuh MSNMT, di mana kami mempelajari bagaimana model bertindak dengan modaliti input yang tidak sepadan dan menganalisis kesan tertib perkataan yang berbeza antara sumber dan bahasa sasaran.', 'no': 'Simulert oversettelse involverer oversettelse av eit setning før taleren er fullført for å forstå sanntidsforståelse på fleire språk. Denne oppgåva er betydelig meir vanskeleg enn den generelle fulle setninga omsetjinga på grunn av kor mange inndatainformasjon er i løpet av koding. For å redusera denne korta, foreslår vi fleire modular samtidig neuralmaskinsomsetjing (MSNMT), som leverer visuelle informasjon som ein ekstra modus. Eksperimentane våre med datasettet Multi30-k viste at MSNMT utfører tekst-berre i meir tidlegare omsetjingar med låg latens. I tillegg, vi verifiserte viktigheten for visuelle informasjon ved å dekode ved å utføra ein negativ evaluering av MSNMT, der vi studierte korleis modeller behandla med inkonstruente inndata modalitet og analysera effekten av ulike ordordrekkefølgje mellom kjelde og målspråk.', 'pl': 'Tłumaczenie jednoczesne polega na tłumaczeniu zdania przed zakończeniem wypowiedzi mówcy w celu realizacji zrozumienia w czasie rzeczywistym w wielu językach. Zadanie to jest znacznie trudniejsze niż ogólne tłumaczenie pełnego zdania ze względu na brak informacji wejściowych podczas dekodowania. Aby złagodzić ten niedobór, proponujemy multimodalne symultaniczne tłumaczenie maszynowe neuronowe (MSNMT), które wykorzystuje informacje wizualne jako dodatkową modalność. Nasze eksperymenty z zestawem danych Multi30k wykazały, że MSNMT znacznie przewyższa swój odpowiednik tylko tekstowy w bardziej terminowych sytuacjach tłumaczenia z niskimi opóźnieniami. Ponadto zweryfikowaliśmy znaczenie informacji wizualnej podczas dekodowania poprzez przeprowadzenie kontrowej oceny MSNMT, gdzie badaliśmy, jak modele zachowywały się z niezgodną modalnością wejściową oraz analizowaliśmy wpływ różnego porządku słów między językami źródłowymi i docelowymi.', 'ro': 'Traducerea simultană implică traducerea unei propoziții înainte de finalizarea pronunțării vorbitorului pentru a realiza înțelegerea în timp real în mai multe limbi. Această sarcină este mult mai dificilă decât traducerea generală a propoziției complete din cauza lipsei de informații introduse în timpul decodării. Pentru a atenua această lipsă, propunem traducerea automată neurală simultană multimodală (MSNMT), care valorifică informația vizuală ca modalitate suplimentară. Experimentele noastre cu setul de date Multi30k au arătat că MSNMT depășește semnificativ omologul său numai text în situații de traducere mai prompte și cu latență scăzută. În plus, am verificat importanța informației vizuale în timpul decodării prin efectuarea unei evaluări adversare a MSNMT, unde am studiat modul în care modelele s-au comportat cu modalitate de intrare incongruentă și am analizat efectul diferitelor ordine de cuvinte între limbile sursă și limbile țintă.', 'sr': 'Istodobni prevod uključuje prevod rečenice pre nego što se izgovornik završi kako bi shvatio razumijevanje pravog vremena na višestrukim jezicima. Ovaj zadatak je značajno mnogo izazovniji od općeg prevoda pune rečenice zbog nedostatka informacija o ulazu tijekom dekodiranja. Da bismo smanjili taj nedostatak, predlažemo multimodalni istovremeni prevod neuralnih strojeva (MSNMT), koji utiču na vizualne informacije kao dodatnu modalitetu. Naši eksperimenti sa multi30k podacima pokazali su da MSNMT značajno iznosi svoj jedini tekstni kolega u vremenskim situacijama sa niskom latencijom. Nadalje, proverili smo važnost vizuelnih informacija tokom dekodiranja provođenjem neprijateljske procjene MSNMT-a, gde smo studirali kako se modeli ponašali sa nepravednom modalitetom ulaska i analizirali učinak različitih reda riječi između izvora i ciljnih jezika.', 'si': 'සාමාන්\u200dය වාර්තාවක් සම්පූර්ණයෙන් වාර්තාවක් භාෂාවක් ඇත්තටම තේරුම් ගන්න පුළුවන් කලින් වාර්තාවක් අවශ මේ වැඩේ සාමාන්\u200dය වාක්ය භාවිතයට වඩා ප්\u200dරශ්නයක් වෙන්න පුළුවන් ප්\u200dරශ්නයක් තියෙනවා ඇතුළු තොරතුරු  මේ අඩුවෙන් අඩුවෙන්න, අපි ගොඩක් මාධ්\u200dයමාන්\u200dය පරිවර්තනය (MSNMT) කිරීමට ප්\u200dරයෝජනය කරනවා, ඒක තවත් ප්\u200dරයෝජනය විදිහට ප Multi30k දත්ත සැට් එක්ක අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට MSNMT විශේෂයෙන් ඔහුගේ පාළුවක් විතරයි පාළුවක් විතරය ඊටපස්සේ, අපි දර්ශණ තොරතුරු විශ්වාස කරලා තියෙන්නේ MSNMT විරුද්ධ විශ්වාස කරලා ප්\u200dරශ්නයක් පරීක්ෂණය කරලා තියෙන්නේ, තැන අපි පරීක්ෂණය කරලා ත', 'so': "Turjumista isla markaasna waxaa ku qoran turjumista hadalka ka hor inta uusan dhamaan hadalka qofka ku hadla si uu u ogaado waxgarashada waqtiga ah oo ku qoran luuqado kala duduwan. Shaqadaasu waa mid aad uga tacliin badan yahay turjumaadda dhamaanka ah sababtoo ah gaabanta macluumaadka input marka la qorayo. Si aan u fududeyno gaabankaas, waxaynu soo jeedaynaa tarjumaadka maskinada oo kala duduwan (MSNMT), kaasoo macluumaadka muuqashada u soo bandhigaya sida qaab dheeraad ah. Imtixaanadayada ee Multi30k dataset ayaa muujiyey in MSNMT si weyn ugu muujiyaa wadajirkiisa oo kaliya ee qoraalka oo ku saabsan wakhti dheer oo turjumaadda la xiriira dhaqdhaqaaq yar. Waxaa kaloo aan xaqiijinnay muhiimka macluumaadka aragga marka aad codsiga ku sameynayso qiimeynta ka geesta ah ee MSNMT, kaas oo aannu baranay siduu u dhaqdhaqaaqsanaa qaababka input la'aanta, waxaana analyeynay saamaynta amarka kala duduwan ee afka noocyada iyo luqadaha goalka ah dhexdooda.", 'sv': 'Samtidig översättning innebär att översätta en mening innan talarens yttrande är färdigt för att realisera realtidsförståelse på flera språk. Denna uppgift är betydligt mer utmanande än den allmänna fullmeningsöversättningen på grund av bristen på indata information under avkodningen. För att lindra denna brist föreslår vi multimodal simultan neural machine translation (MSNMT), som utnyttjar visuell information som en ytterligare metod. Våra experiment med Multi30k-datauppsättningen visade att MSNMT avsevärt överträffar sin motsvarighet med enbart text i mer aktuella översättningssituationer med låg fördröjning. Vidare verifierade vi betydelsen av visuell information under avkodning genom att utföra en kontradiktorisk utvärdering av MSNMT, där vi studerade hur modeller betedde sig med inkonsekvent inmatningsmetod och analyserade effekten av olika ordordning mellan käll- och målspråk.', 'ta': 'பேச்சாளரின் சொல்லை முடிக்கும் முன் ஒரு வாக்கியத்தை மொழிபெயர்ப்பு சொல்லும் மொழிபெயர்ப்பு சேர்க்கிறது பல மொழ @ info இந்த குறைப்பை நீக்க, அது கூடுதல் தகவலாக கொடுக்கும் பார்வையை மொழிமாற்றுகிறது. MSNMT மிகவும் குறைந்த நேரத்தில் மொழிபெயர்ப்பு நிலையில் மொழிபெயர்ப்பு நிலையில் மொழிபெயர்ப்பு செய்யும் பொழுது எம்எ மேலும், நாங்கள் எம்எம்எம்டியின் எதிர்மறை மதிப்பை செய்து பார்வை தகவல் குறியீட்டில் பார்வையின் முக்கியமானதை சரிபார்த்தோம். மூலம் மற்றும் சேர்க்கை மொழிகளு', 'ur': 'اس سے پہلے ایک جماعت کی تعبیر کا ترجمہ کرنا ہے کہ اسپیکر کی بات پوری ہو جائے تاکہ بہت سی زبانوں میں حقیقی زمانہ سمجھ سکے۔ یہ کام ڈیکوڈ کے وقت اینپیٹ معلومات کی کمی کی وجہ سے عمومی کلمز کی ترجمہ سے زیادہ مشکل ہے. اس کمزوری کو کمزور کرنے کے لئے، ہم ایک دوسرے نئورل ماشین کی ترجمہ (MSNMT) کے متعلق multimodal معلومات کو پیشنهاد کرتے ہیں، جو بصری معلومات کو اضافہ موڈلی کے طور پر ذخیره کرتا ہے. ہماری آزمائش Multi30k ڈیٹ سٹ کے ساتھ دکھائی گئی ہے کہ MSNMT نے اپنے پیغام کے علاوہ ایک ٹیکسٹ پارٹ کو زیادہ وقت کے ترجمہ موقعیت میں کم لٹینس کے ساتھ اضافہ کرتا ہے. اس کے علاوہ ہم نے MSNMT کی مخالف ارزیابی کے ذریعہ سے دکوڈ کرنے کے وقت visual information کی اثبات کی تصدیق کی، جہاں ہم نے مطالعہ کی کہ موڈل کس طرح غلطی اینٹ موڈلیٹ کے ساتھ عمل کرتے تھے اور موجود اور موجود زبانوں کے درمیان مختلف کلمات کا اثر تحقیق کیا۔', 'vi': 'Dịch đồng thời là thông qua một câu trước khi phát biểu của người phát biểu hoàn thành để thực hiện s ự hiểu biết thời gian thực tại bằng nhiều ngôn ngữ. Nhiệm vụ này khó khăn hơn nhiều so với bản dịch toàn phần bản do thiếu thông tin nhập trong thời gian giải mã. Để giảm thiểu thiểu này, chúng tôi đề xuất dịch cỗ máy thần kinh đồng thời đa chiều (MSNMT), dùng thông tin trực tiếp làm kích hoạt nội dung phụ. Những thí nghiệm với bộ dữ liệu đa 30k đã cho thấy MSNMT còn siêu hơn phần bản chỉ mình trong những trường hợp dịch kịp thời với độ trễ. Chúng tôi đã xác nhận tầm quan trọng của thông tin ảnh trong thời gian giải mã bằng cách tiến hành đánh giá đối nghịch của MSNMT, nơi chúng tôi đã nghiên cứu cách thức ứng xử của mô hình nhập không đúng cách và phân tích hiệu ứng của các từ khác nhau giữa nguồn và ngôn ngữ đích.', 'uz': "Name @ info Bu qisqartmalarni yoqish uchun, bir xil xil neyron tarjima (MSNMT) bilan bir xil tarjima qilamiz. Bu qoʻshimcha maʼlumot qoʻshish usuli sifatida qoʻllanmagan. Multi30k maʼlumotlar tarjimalari bilan taʼminlovchimizmiz MSNMT taʼminlovchi sohalarda juda katta vaqt tarjima qiladigan matn bilan bir tarjima qiladi. Kodlash paytida, MSNMT haqida ko'rinish muhimligini tasdiqlash mumkin. Bu yerda biz modellar muvaffaqiyatli input moduli bilan qanday harakat qilishni o'rganamiz va manba va target tillar orasidagi boshqa so'zlar tartibiga o'anadi.", 'bg': 'Едновременният превод включва превод на изречение, преди да завърши изказването на говорителя, за да се осъществи разбиране в реално време на няколко езика. Тази задача е значително по-предизвикателна от общия превод на пълно изречение поради недостига на входна информация по време на декодиране. За да облекчим този недостиг, предлагаме мултимодален симултанен невронен машинен превод (МНМТ), който използва визуалната информация като допълнителен модал. Нашите експерименти с набора от данни показаха, че MSNMT значително превъзхожда своя текстов контрагент в по-навременни ситуации на превод с ниска латентност. Освен това, ние проверихме значението на визуалната информация по време на декодирането чрез извършване на противоречива оценка на МНМТ, където изучавахме как моделите се държат с несъответстващ модал на въвеждане и анализирахме ефекта от различен ред на думите между изходните и целевите езици.', 'nl': 'Simultane vertaling omvat het vertalen van een zin voordat de uitspraak van de spreker is voltooid om real-time begrip in meerdere talen te realiseren. Deze taak is aanzienlijk uitdagender dan de algemene volledige zinsvertaling vanwege het tekort aan invoerinformatie tijdens het decoderen. Om dit tekort te verlichten, stellen we multimodale simultane neurale machinevertaling (MSNMT) voor, die visuele informatie als extra modaliteit gebruikt. Onze experimenten met de Multi30k dataset toonden aan dat MSNMT zijn tekst-only tegenhanger aanzienlijk overtreft in tijdige vertaalsituaties met lage latentie. Verder hebben we het belang van visuele informatie tijdens decodering geverifieerd door een tegenstrijdige evaluatie van MSNMT uit te voeren, waarbij we bestudeerden hoe modellen zich gedragen met incongruente invoermodaliteit en het effect van verschillende woordvolgorde tussen bron- en doeltalen analyseerden.', 'da': 'Samtidig oversættelse indebærer oversættelse af en sætning, før talerens udtalelse er afsluttet for at realisere real-time forståelse på flere sprog. Denne opgave er betydeligt mere udfordrende end den generelle fulde sætning oversættelse på grund af manglen på input oplysninger under afkodning. For at afhjælpe denne mangel foreslår vi multimodal simultan neural machine translation (MSNMT), som udnytter visuel information som en ekstra metode. Vores eksperimenter med Multi30k datasættet viste, at MSNMT betydeligt overgår sin tekstbetjente modpart i mere rettidige oversættelsessituationer med lav ventetid. Desuden verificerede vi vigtigheden af visuel information under afkodning ved at udføre en modstridende evaluering af MSNMT, hvor vi undersøgte, hvordan modeller opførte sig med inkonsekvent input modalitet og analyserede effekten af forskellig ordrækkefølge mellem kilde og målsprog.', 'hr': 'Istodobni prevod uključuje prevod rečenice prije nego se riječ govornika završi kako bi shvatio razumijevanje realnog vremena na višestrukim jezicima. Ovaj zadatak je značajno veći izazov od ukupnog prevoda cijele rečenice zbog nedostatka informacija o ulazu tijekom dekodiranja. Da bismo smanjili taj nedostatak, predlažemo multimodalni istovremeni prevod neuralnih strojeva (MSNMT), koji utiču na vizualne informacije kao dodatnu modalitetu. Naši eksperimenti s multi30k podacima pokazali su da MSNMT značajno iznosi svoj jedini tekstni kolega u vremenskim situacijama s niskom latencijom. Nadalje, provjerili smo važnost vizuelnih informacija tijekom dekodiranja provođenjem adversarne procjene MSNMT-a, gdje smo proučavali kako se modeli ponašaju s nepravednom modalitetom ulaska i analizirali učinak različitih reda riječi između izvora i ciljnih jezika.', 'de': 'Die Simultanübersetzung beinhaltet die Übersetzung eines Satzes, bevor die Rede abgeschlossen ist, um Echtzeitverständnis in mehreren Sprachen zu realisieren. Diese Aufgabe ist aufgrund des Mangels an Eingabeinformationen während der Dekodierung deutlich anspruchsvoller als die allgemeine Vollsatzübersetzung. Um diesen Mangel zu lindern, schlagen wir multimodale simultane neuronale maschinelle Übersetzung (MSNMT) vor, die visuelle Informationen als zusätzliche Modalität nutzt. Unsere Experimente mit dem Multi30k Datensatz zeigten, dass MSNMT in zeitnaheren Übersetzungssituationen mit geringer Latenz sein reines Text-Pendant deutlich übertrifft. Darüber hinaus haben wir die Bedeutung visueller Informationen während der Dekodierung durch eine adversariale Auswertung von MSNMT überprüft, in der wir untersuchten, wie sich Modelle mit inkongruenten Eingabemodalitäten verhalten und den Effekt unterschiedlicher Wortreihenfolge zwischen Quell- und Zielsprachen analysierten.', 'id': 'Terjemahan bersamaan melibatkan menerjemahkan kalimat sebelum ucapan pembicara selesai untuk menyadari pemahaman dalam waktu nyata dalam berbagai bahasa. Tugas ini jauh lebih menantang daripada terjemahan kalimat penuh umum karena kekurangan informasi input selama dekoding. Untuk mengurangi kekurangan ini, kami mengusulkan multimodal simultan mesin saraf terjemahan (MSNMT), yang menggunakan informasi visual sebagai modalitas tambahan. Eksperimen kami dengan dataset Multi30k menunjukkan bahwa MSNMT jauh melebihi rekan teks-hanya dalam situasi terjemahan lebih tepat waktu dengan keterlaluan rendah. Furthermore, we verified the importance of visual information during decoding by performing an adversarial evaluation of MSNMT, where we studied how models behaved with incongruent input modality and analyzed the effect of different word order between source and target languages.', 'ko': '동시통역은 말하는 사람의 말이 완성되기 전에 한 문장을 번역하여 다양한 언어에 대한 실시간 이해를 실현하는 것을 말한다.디코딩 과정에서 정보를 입력하는 부족함으로 인해 이 임무는 일반적인 완전한 문장 번역보다 더욱 도전적이다.이러한 부족함을 완화하기 위해 우리는 다중모드동기신경기계번역(MSNMT)을 제기했는데 시각정보를 부가모드로 이용한다.MSNMT는 Multi30k 데이터 세트에서의 실험을 통해 더 신속하고 지연이 적은 번역 상황에서 순수한 텍스트에 대응하는 번역보다 현저히 우수하다는 것을 알 수 있다.그 밖에 우리는 MSNMT에 대한 대항적 평가를 통해 디코딩 과정에서 시각적 정보의 중요성을 검증했고 모델이 일치하지 않는 입력 모델에서의 표현을 연구했으며 원시 언어와 목표 언어 간의 서로 다른 어순의 영향을 분석했다.', 'sw': 'Tafsiri kwa wakati ule unahusisha kutafsiri hukumu kabla hotuba ya mzungumzaji haijakamilika ili kuelewa uelewa wa muda halisi katika lugha mbalimbali. Kazi hii ina changamoto kubwa zaidi ya tafsiri ya hukumu ya jumla kwa sababu ya ukosefu wa taarifa za input wakati wa kupunguza. Ili kupunguza upungufu huu, tunapendekeza tafsiri ya mashine ya neura kwa wakati mmoja (MSNMT), ambayo inatoa taarifa za kuona kama njia ya ziada. Majaribio yetu na seti ya takwimu za Multi30k yalionyesha kuwa MSNMT inaonyesha kwa kiasi kikubwa utangazaji wake wa maandishi pekee katika mazingira ya kutafsiri kwa muda mrefu yenye kiwango kidogo cha hivi karibuni. Zaidi ya hayo, tulithibitisha umuhimu wa taarifa za kuona wakati wa kupunguza kwa kufanya uchunguzi wa upinzani wa chama cha MSNMT, ambapo tulisoma namna mifano ilivyotenda na hali isiyo na maana na kuchambua madhara ya amri tofauti ya maneno kati ya lugha za vyanzo na lengo.', 'fa': 'ترجمه\u200cهای مشابهی قبل از اینکه کلمه\u200cی صحبت\u200cکننده تموم شود، یک جمله را ترجمه می\u200cکند تا بفهمید که درک زمان واقعی در زبان\u200cهای مختلف است. این وظیفه به طور کلی از ترجمه کل جمله سخت\u200cتر است به دلیل کوتاهی اطلاعات ورودی در زمان دکوندن. برای کمبود این کوتاهی، ما پیشنهاد می\u200cکنیم ترجمه\u200cهای ماشین عصبی چندین مدل (MSNMT) که اطلاعات دیده\u200cای را به عنوان یک حالت اضافی تأثیر می\u200cدهد. آزمایش های ما با مجموعه داده های Multi30k نشان داده است که MSNMT تنها متن را در موقعیت های ترجمه زمانی بیشتری با تاریخ کم انجام می دهد. علاوه بر این، ما مهمترین اطلاعات دیدئویی را در زمان دکوندن با انجام ارزیابی دشمنی MSNMT تحقیق کردیم، جایی که ما مطالعه کردیم چگونه مدل ها با مدل ورودی غیرقابل رفتار کردند و تاثیر سفارش کلمات مختلف بین زبانهای منبع و هدف تحلیل کردیم.', 'sq': 'Përkthimi i njëkohëshëm përfshin përkthimin e një fjale përpara se të përfundojë shprehja e zëdhënësit me qëllim që të realizohet kuptimi në kohë reale në gjuhë të shumta. Kjo detyrë është shumë më sfiduese se përkthimi i përgjithshëm i plotë i fjalëve për shkak të mungesës së informacionit të hyrjes gjatë dekodimit. To alleviate this shortage, we propose multimodal simultaneous neural machine translation (MSNMT), which leverages visual information as an additional modality.  Eksperimentet tona me kompletin e të dhënave Multi30k treguan se MSNMT kryen në mënyrë të konsiderueshme homologun e vet të vetëm tekstit në situata më të përkthimit në kohë me vonesë të ulët. Përveç kësaj, ne verifikuam rëndësinë e informacionit vizual gjatë dekodimit duke kryer një vlerësim kundërshtar të MSNMT, ku studiuam se si modelet silleshin me modalitetin e brendshëm të papërshtatshëm dhe analizuam efektin e rendit të fjalëve të ndryshëm midis burimit dhe gjuhëve objektive.', 'am': 'በተሰዓት ትርጉም የንግግር ቃላት ሳይፈጸም በአካለ ቋንቋዎች እውነተኛውን ጊዜ ማስተዋል ለማስታወቅ ግንኙነትን በመግለጽ ያስተካክላል፡፡ ይህ ስራ ከጠቅላላ ሙሉ ግንኙነት ትርጓሜ ይልቅ በጣም አዋቂ ነው፡፡ To alleviate this shortage, we propose multimodal simultaneous neural machine translation (MSNMT), which leverages visual information as an additional modality.  በMulti30k ዳታተር ውስጥ ፈተናዎቻችን MSNMT በተለየ ጊዜው በተለየ ታናሽ በተርጓሚው ግንኙነት የጽሑፉን ብቻ ተቃዋሚ እንዲያሳየው ያሳያል፡፡ በተጨማሪም፣ የኢሜስቴን ተቃዋሚ ማስታወቂያ በማድረግ የራእይ መረጃ ግንኙነት አረጋገጥን፡፡', 'hy': 'Միևնույն թարգմանությունը ներառում է նախադասություն թարգմանել, մինչ խոսնակի արտահայտությունը ավարտվի, որպեսզի իրական ժամանակում հասկանալ բազմաթիվ լեզուներով: Այս խնդիրը շատ ավելի դժվար է, քան ընդհանուր ամբողջ նախադասությունների թարգմանությունը, քանի որ տեղեկատվությունը բացակայում է կոդավորման ընթացքում: Այս բացակայության նվազեցնելու համար մենք առաջարկում ենք բազմամոդալ միաժամանակ նեյրոնային մեքենայի թարգմանություն (MSNMT), որը օգտագործում է տեսողական տեղեկատվությունը որպես ավելացված մեթոդ: Մեր բազմաթիվ 30k տվյալների համակարգի փորձերը ցույց տվեցին, որ MSNMT-ը նշանակալիորեն գերազանցում է իր միայն տեքստի համեմատությունը ավելի ժամանակական թարգմանման իրավիճակներում, որոնք ցածր ուշացություն ունեն: Ավելին, մենք ստուգեցինք տեսողական ինֆորմացիայի կարևորությունը դեկոդավորման ընթացքում MSNMT-ի հակառակ գնահատման կատարելով, որտեղ մենք ուսումնասիրեցինք, թե ինչպես են մոդելները վարվել անհամապատասխան ներմուծի մեթոդով և վերլուծեցինք տարբեր բառերի կարգը աղբյուր և ն', 'az': "Sözlüyün s özünün tamamlanmasından əvvəl, həqiqət zamanlı anlayışını çoxlu dillərdə anlamaq üçün cümləni tərcümə edir. Bu işin kodlama sırasında girdi məlumatının azalığı üzündən genel cümlədən daha çox çətin olacaq. Bu küçüyü azaltmaq üçün çoxlu modal bir nöral maşına çevirimi (MSNMT) təbliğ edirik ki, bu görünür məlumatlarını artıq modalitə olaraq təbliğ edir. Multi30k veri quruluğumuz təcrübələrimiz, MSNMT ancaq metin-kompartesini daha zamanlı tərcümə məqsədilə azaltdığını göstərdi. Daha sonra, MSNMT'in düşmənçilik değerlendirməsi ilə görünüş məlumatının vacibətini təsdiq etdik. Biz modellərin necə uyğun girdi modalitəsi ilə davrandığını və mənbə və məqsəd dillərin arasında fərqli söz sırasının etkisini analiz etdik.", 'bn': 'একই সাথে অনুবাদ অনুবাদের বিভিন্ন ভাষায় বাক্য সমাপ্ত হওয়ার পূর্বে একটি বাক্য অনুবাদ করার ব্যাপারে অনুবাদ করা হয়েছে। সাধারণ বাক্য অনুবাদ অনুবাদের চেয়ে এই কাজের চ্যালেঞ্জের চেয়ে বেশী চ্যালেঞ্জ। এই সংক্রান্ত কমানোর জন্য আমরা বহুটিমোডাল একই সাথে একই সাথে নিউরেল মেশিন অনুবাদ প্রস্তাব করছি (এমএমএমটি), যা দৃশ্যমান তথ্য বাড়িয়ে দ মাল্টি৩০ক ডাটাসেট দিয়ে আমাদের পরীক্ষা প্রদর্শন করেছে যে এমএমএমটি বেশী সময়ের অনুবাদের পরিস্থিতিতে তাদের লেখক-শুধুমাত্র প্ এছাড়াও, আমরা দৃষ্টিভঙ্গিকার তথ্য নিশ্চিত করেছি এমএমএমটির বিরোধী মূল্যের মাধ্যমে, যেখানে আমরা শিক্ষা করেছিলাম কিভাবে মডেলের আচরণ করেছিলাম অযোগ্য ইনপুটের', 'tr': "Aýratyn terjime edil çykyşyň s özleriniň sözlerini bitirmeden öň sözleri terjime etmek üçin birnäçe dillerde düşünmek üçin bir terjime edilýär. Bu täblik komel sözlem terjimesinden has kynçylyk. Ködleme durmuşy üçin girdi maglumatynyň azalyşygy üçin. Bu az azalygy azaltmak üçin, bir zamanda näöral maşynyň terjimesini (MSNMT) teklip edip, görsel maglumaty eklendir. Multi30k veri setidiginiň deneylerimiz MSNMT özüniň diňe metin baglaýyşyny täsirli terjime edilýän ýagdaýda täsirli ýagdaýda gowy edip ýöredip bilýär. Munuň üçin biz MSNMT'iň täsirli deňlemesi ýagdaýynda görsel maglumatyň nähili möhümligini tassyklapdyk. Biz bu ýerde modelleriň düzgün girdi modalitesi bilen nähili hereket edip, çeşmeler we maksadyň arasyndaky söz düzümleriniň täsirini çözdik.", 'af': "Gelyklike vertaling involves the translation of a sentence before the speaker's utterance is completed in order to realize real-time understanding in multiple languages. Hierdie taak is betekeurig meer pragtige as die algemene volle seting vertaling vanweë die kortpad van invoer inligting tydens dekodering. Om hierdie kortpad te verminder, voorstel ons multimodaal eenmaal neurale masjien vertaling (MSNMT), wat visuale inligting as 'n addisionele modaliteit verwyder. Ons eksperimente met die Multi30k datastel het vertoon dat MSNMT betekenlik sy teks- slegs kunstenaar uitvoer in meer tydelike vertalingssituasies met lae latensie. Ons het ook die belangrikheid van visuele inligting bevestig tydens dekodering deur 'n teëstandige evaluering van MSNMT te doen, waar ons ondersoek hoe modele gedrag het met ongeregtige invoer modaliteit en die effek van verskillende woord volgorde tussen bron en doel tale analyseer.", 'bs': 'Istodobni prevod uključuje prevod rečenice prije nego se riječ govornika završi kako bi shvatio razumijevanje realnog vremena na višestrukim jezicima. Ovaj zadatak je značajno mnogo izazovniji od općeg prevoda pune rečenice zbog nedostatka informacija o ulazu tijekom dekodiranja. Da bismo ublažili tu nedostatak, predlažemo multimodalni istovremeni prevod neuralnih strojeva (MSNMT), koji utiču na vizualne informacije kao dodatnu modalitetu. Naši eksperimenti sa multi30k podacima pokazali su da MSNMT značajno iznosi svoj samo tekstni kolega u vremenskim situacijama sa niskom latencijom. Nadalje, provjerili smo važnost vizuelnih informacija tijekom dekodiranja provođenjem neprijateljske procjene MSNMT-a, gdje smo studirali kako se modeli ponašali s nepravednom modalitetom ulaska i analizirali učinak različitih reda riječi između izvora i ciljnih jezika.', 'ca': "La traducció simultànea implica la traducció d'una frase abans de completar l'expressió de l'orador per adonar-se d'una comprensió en temps real en múltiples llengües. Aquesta tasca és significativament més difícil que la traducció general de frases completas a causa de la falta d'informació d'entrada durant la descodificació. To alleviate this shortage, we propose multimodal simultaneous neural machine translation (MSNMT), which leverages visual information as an additional modality.  Els nostres experiments amb el conjunt de dades Multi30k van demostrar que MSNMT supera significativament la seva contrapartida només en text en situacions de traducció més oportunes amb baixa latencia. A més, vam verificar l'importància de la informació visual durant la decodificació fent una evaluació adversaria de MSNMT, on vam estudiar com els models es comportaven amb modalitats d'entrada incongruents i vam analitzar l'efecte d'un ordre de paraules diferent entre les llengües fonts i alvo.", 'cs': 'Současný překlad zahrnuje překlad věty před dokončením řečnického projevu s cílem realizovat porozumění v reálném čase ve více jazycích. Tento úkol je výrazně náročnější než obecný překlad celé věty kvůli nedostatku vstupních informací během dekódování. Pro zmírnění tohoto nedostatku navrhujeme multimodální simultánní neuronový strojový překlad (MSNMT), který využívá vizuální informace jako další modalitu. Naše experimenty s datovou sadou Multi30k ukázaly, že MSNMT výrazně překonává svůj protějšek pouze v textových situacích s nízkou latencí. Dále jsme ověřili význam vizuálních informací při dekódování provedením kontroverzního vyhodnocení MSNMT, kde jsme studovali, jak se modely chovají s nekongruentní vstupní modalitou a analyzovali vliv různého pořadí slov mezi zdrojovými a cílovými jazyky.', 'et': 'Sünkroontõlge hõlmab lause tõlkimist enne kõneleja sõnavõtu lõpetamist, et realiseerida reaalajas arusaam mitmes keeles. See ülesanne on märkimisväärselt keerulisem kui üldine lause tõlkimine, sest sisendteabe puudumine dekodeerimise ajal. Selle puudujäägi leevendamiseks pakume välja multimodaalse simultaalse neuraalse masintõlke (MSNMT), mis kasutab visuaalset informatsiooni täiendava viisina. Meie eksperimendid Multi30k andmekogumiga näitasid, et MSNMT suudab märkimisväärselt üle oma ainult teksti sisaldava vaste väikese latentsusega õigeaegsemates tõlketeenustes. Lisaks kontrollisime visuaalse informatsiooni tähtsust dekodeerimise ajal MSNMT vastastikuse hindamise abil, kus uurisime, kuidas mudelid käitusid ebaühtlase sisendusmeetodiga ning analüüsisime erineva sõnajärjekorra mõju lähte- ja sihtkeelte vahel.', 'fi': 'Simultaanikäännös tarkoittaa lauseen kääntämistä ennen puhujan lausuman valmistumista, jotta voidaan toteuttaa reaaliaikainen ymmärtäminen useilla kielillä. Tämä tehtävä on huomattavasti haastavampi kuin yleinen koko lauseen kääntäminen, koska syötetiedot ovat puutteellisia dekoodauksen aikana. Tämän puutteen lievittämiseksi ehdotamme multimodaalista samanaikaista neurokonekäännöstä (MSNMT), joka hyödyntää visuaalista tietoa lisämuotona. Kokeemme Multi30k-aineistolla osoittivat, että MSNMT suoriutuu huomattavasti enemmän kuin vain tekstissä oleva vastine ajoissa ja matalalla viiveellä olevissa käännöstilanteissa. Lisäksi varmistimme visuaalisen tiedon merkityksen dekoodauksen aikana tekemällä MSNMT:n vastakkaisen arvioinnin, jossa tutkittiin, miten mallit käyttäytyivät epäjohdonmukaisella syöttömenetelmällä ja analysoitiin eri sanajärjestyksen vaikutusta lähde- ja kohdekielten välillä.', 'ha': "Tsarin zaman shawarar da ke ƙunsa da fassarar da wata magana a gabãnin a cika maganar mai magana, dõmin ya gane fahimtar da gaskiyar-lokaci cikin wasu harshe. @ action: inmenu Domin sauƙi da wannan shortcut, Munã ƙayyade fassarar manyan neural da ke sami da shi, wanda ke ƙarfafa fassarar gannai kamar wani tsari na ƙaranci. Kayan jarrabayenmu da multi-30 aka nuna musamman da MANMT yana mai ƙayyade motsin text-only cikin mazaɓa da sauri cikin muhimman fassarar da ƙaranci. Da haka, Mun gaskata muhimu ga information na gani a lokacin da za'a yi kodi da ta samar wani rabo-ƙaddara wa MINMT, a inda muka karanta jinin misãlai da tsarin inki da ba'a taƙaita ba, kuma muka yi anayyari ga matsayin tsarin maganar dabam-dabam tsakanin sourcen da ake shagala.", 'jv': 'Tulung task Nyong ngomong alat iki, kita supoyo nggawe tarjamahan piral sampeyan (SMNMT), sing styrke nggawe informasi anyar sampeyan karo modalitat sing tambah. Kita perbudhakan karo Multi30 k dataset anyar neng sistem sing ditambah badasar SMNMT input pating langgar titing maneh dumateng kapan titing maneh Ngitompok, kéné wis ngerdekaan piye cara-piye yen nggawe informasi anyar neng akeh nguasai nggawe tarjamahan sing pakan karo SMNMT, ning awak dhéwé ngerasai model sing gawe nguasai modalité sing misingan akeh operasi lan ujaran ujaran gambaran langkung sampeyan karo perusahaan lan tarjamahan.', 'he': "Simultaneous translation involves translating a sentence before the speaker's utterance is completed in order to realize real-time understanding in multiple languages.  המשימה הזו מאתגרת במיוחד יותר מאשר התרגום הכללי של משפטים מלאים בגלל חסר מידע הכניסה במהלך הפענוח. כדי להקל על המחסור הזה, אנו מציעים תרגום של מכונות עצביות באופן רב-מודלית (MSNMT), אשר משתמש במידע ויזואלי כמודליות נוספת. הניסויים שלנו עם קבוצת נתונים Multi30k הראו ש MSNMT משפיע באופן משמעותי על השותף שלה רק טקסט במצבים התרגום בזמן יותר עם לאנטיות נמוכה. בנוסף, אישרנו את חשיבותו של מידע חזותי במהלך הפענוח על ידי ביצוע עריכה יריבית של MSNMT, שבו למדנו איך דוגמנים התנהגו עם מודיאליות כניסה לא תואמת ונבחנו את ההשפעה של סדר מילים שונה בין שפות מקור למטרה.", 'sk': 'Sočasno prevajanje vključuje prevod stavka pred zaključkom govornikovega izgovora, da se v realnem času uresniči razumevanje v več jezikih. Zaradi pomanjkanja vhodnih informacij med dekodiranjem je ta naloga bistveno bolj zahtevna od splošnega prevajanja celotnega stavka. Za ublažitev tega pomanjkanja predlagamo multimodalni simultani nevronski strojni prevod (MSNMT), ki kot dodatno modalnost uporablja vizualne informacije. Naši eksperimenti s podatkovnim naborom Multi30k so pokazali, da MSNMT bistveno presega svojo samo besedilno podporo v pravočasnejših prevajalskih situacijah z nizko latenco. Poleg tega smo preverili pomen vizualnih informacij med dekodiranjem z izvedbo kontradikatne ocene MSNMT, kjer smo proučili, kako se modeli obnašajo z neskladno vnosno modalnostjo in analizirali učinek različnega vrstnega reda besed med izvornimi in ciljnimi jeziki.', 'bo': 'འོན་ཀྱང་། དབྱེ་ཚིག་འདིས་སྐད་ཡིག་འདི་ཁོ་མོས་བཤད་ཀྱི་ཧ་གོ་མ་ཡིན་པའི་སྐད་ཡིག་ཆ་འདི་ལ་ཕར་ཆེན་རྟོགས་རྒྱུ་དང་། འོན་ཀྱང་། བྱ་འགུལ་འདིས་སྤྱིར་བཏང་བའི་ཚིག་རྐང་ཡིག་ཆ་འདིའི་ནང་དུ་གཏོང་མཁན་ལས་ཧ་ཅང་གཏོང་བ To alleviate this shortage, we propose multimodal neural machine translation (MSNMT), which leverages visual information as an additional modality. ང་ཚོའི་བརྟག་ཞིབ་སྣེ་30k གནད་སྡུད་ཚན་བྱས་པའི་སྒེར་གྱི་ནང་ནས་MSNMT ཡི་གེ་ཚིག་ཡིག་ཆ་ཁོ་ན་ཕན Furthermore, we verified the importance of visual information during decoding by performing an adversarial evaluation of MSNMT, where we studied how models behaved with incongruent input modality and analyzed the effect of different words order between source and target languages.'}
{'en': 'Document-aligned Japanese-English Conversation Parallel Corpus', 'ar': 'محاذاة الوثيقة لجسم متوازي للمحادثة اليابانية الإنجليزية', 'pt': 'Corpus paralelo de conversação japonês-inglês alinhado a documentos', 'fr': 'Corpus parallèle de conversation japonais-anglais aligné sur le document', 'es': 'Corpus paralelo de conversación japonés-inglés alineado con documentos', 'ja': 'ドキュメントに沿った日英会話パラレルコーパス', 'hi': 'दस्तावेज़-संरेखित जापानी-अंग्रेज़ी वार्तालाप समानांतर कॉर्पस', 'zh': '文档齐日语-英语会话并行语料库', 'ru': 'Согласованный с документами параллельный корпус японо-английского разговора', 'ga': 'Corpas Comhthreomhar Comhrá Seapáinise-Béarla atá ailínithe le doiciméid', 'ka': 'Name', 'hu': 'Dokumentumhoz igazított japán-angol beszélgetés Parallel Corpus', 'el': 'Παράλληλο σώμα συζήτησης Ιαπωνικά-Αγγλικά ευθυγραμμισμένο με έγγραφα', 'it': 'Conversazione giapponese-inglese allineata ai documenti', 'kk': 'Құжатты жапон- ағылшын сөйлесу параллелі корпус', 'lt': 'Document-aligned Japanese-English Conversation Parallel Corpus', 'mk': 'Паралелен корпус на јапонско-англиска конверзација во согласност со документите', 'mt': 'Korp Parallel tal-Konversazzjoni Ġappuniża-Ingliż allinjat mad-dokument', 'ml': 'ജാപ്പാനീസ്- ഇംഗ്ലീഷ് സംസാരിക്കുന്ന പാരാള്\u200d കോര്\u200dപ്പുസ്', 'no': 'Comment', 'pl': 'Konwersacja równoległa równoległego korpusu japońsko-angielskiego', 'ms': 'Korpus Paralel Perbualan Jepun-Inggeris disesuaikan dokumen', 'mn': 'Документ-хэвлэгдсэн Япон-Англи ярианы параллел хэлбэр', 'sr': 'Paralelni korpus razgovora japanski-engleski pored dokumenta', 'so': 'Japoniya-Ingiriis Talobixinta Parallel Corpus', 'ro': 'Conversație japoneză-engleză aliniată la documente Corpus paralel', 'sv': 'Dokumentjusterad japansk-engelska konversation Parallel Corpus', 'si': 'Comment', 'ur': 'Document-aligned Japanese-English Conversation Parallel Corpus', 'ta': 'ஆவணம்- ஒத்திசைப்படுத்தப்பட்ட ஜப்பானிஷ்- ஆங்கிலம் பேச்சு இணைப்பு பார்பல் கார்புஸ்', 'uz': 'Name', 'vi': 'KCharselect unicode block name', 'bg': 'Паралелен корпус на японско-английски разговор', 'nl': 'Op documenten uitgelijnd Japans-Engels conversatie Parallel Corpus', 'hr': 'Paralelni korpus razgovora japanskog-engleskog razgovora', 'da': 'Dokumentjusteret japansk-engelsk samtale Parallel Corpus', 'de': 'Paralleles Korpus der japanischen und englischen Konversation', 'id': 'Korpus Perbicaraan Paralel Jepang-Inggris disesuaikan dokumen', 'fa': 'مکالمه\u200cهای پاراللی ژاپن و انگلیسی با سند تنظیم شده', 'ko': '문서 정렬된 일영 세션 평행 자료 라이브러리', 'tr': '_Senedler', 'sw': 'Shirika la Mazungumzo ya Kijapani na Kiingereza', 'af': 'Dokument- aligned Japanese- English Conversation Parallel Corpus', 'am': '_ሰነድ', 'bn': 'ডকুমেন্ট- সংযুক্ত জাপানি- ইংরেজী কথোপকথন প্যারালেল কোর্পাস', 'bs': 'Paralelni korpus razgovora japanskog-engleskog razgovora', 'ca': 'Un corp paralèl·lel de conversació japonès-anglès alliniat amb documents', 'sq': 'Korpus paralel i konversimit japonez-anglez i rreshtuar me dokumente', 'hy': 'Comment', 'az': 'D…ôst…ôl…ôŇüdirilmiŇü Japon-ńįngilizce QonuŇümasńĪ Parallel Corpus', 'cs': 'Souběžný korpus japonsky-angličtiny konverzace zarovnaný na dokumenty', 'et': 'Dokumendiga joondatud jaapani-inglise vestluse paralleelkorpus', 'fi': 'Dokumenttilinjainen japanilais-englanti keskustelu rinnakkaiskorpus', 'jv': 'ProgressBar', 'sk': 'Dokumenti usklajeni japonsko-angleški pogovor vzporedni korpus', 'ha': 'Document-aligned Japanese-English Conversation Parallel Corpus', 'bo': 'ཡིག་གེའི་གྲལ་སྒྲིག', 'he': 'קורפוס משיחת שיחה יפנית-אנגלית מסוימת'}
{'en': 'Sentence-level (SL) machine translation (MT) has reached acceptable quality for many high-resourced languages, but not document-level (DL) MT, which is difficult to 1) train with little amount of DL data ; and 2) evaluate, as the main methods and data sets focus on SL evaluation. To address the first issue, we present a document-aligned Japanese-English conversation corpus, including balanced, high-quality business conversation data for tuning and testing. As for the second issue, we manually identify the main areas where SL MT fails to produce adequate translations in lack of context. We then create an evaluation set where these phenomena are annotated to alleviate automatic evaluation of DL systems. We train MT models using our corpus to demonstrate how using context leads to improvements.', 'ar': 'وصلت الترجمة الآلية على مستوى الجملة (SL) إلى جودة مقبولة للعديد من اللغات عالية الموارد ، ولكن ليس على مستوى المستندات (DL) MT ، والتي يصعب 1) التدريب عليها بكمية قليلة من بيانات DL ؛ 2) التقييم ، حيث تركز الأساليب ومجموعات البيانات الرئيسية على تقييم سبل العيش المستدام. لمعالجة المشكلة الأولى ، نقدم مجموعة محادثة يابانية-إنجليزية متوافقة مع المستندات ، بما في ذلك بيانات محادثة عمل متوازنة وعالية الجودة للضبط والاختبار. بالنسبة للمسألة الثانية ، نحدد يدويًا المجالات الرئيسية التي تفشل فيها SL MT في إنتاج ترجمات مناسبة في غياب السياق. نقوم بعد ذلك بإنشاء مجموعة تقييم حيث يتم شرح هذه الظواهر للتخفيف من التقييم التلقائي لأنظمة DL. نقوم بتدريب نماذج الترجمة الآلية باستخدام مجموعتنا لتوضيح كيف يؤدي استخدام السياق إلى تحسينات.', 'fr': "La traduction automatique (MT) au niveau de la phrase (SL) a atteint une qualité acceptable pour de nombreuses langues à ressources élevées, mais pas pour la traduction automatique au niveau du document (DL), qui est difficile à 1) entraîner avec peu de données DL\xa0; et 2) évaluer, car les principales méthodes et ensembles de données se concentrent sur l'évaluation du SL. Pour résoudre le premier problème, nous présentons un corpus de conversations japonais-anglais aligné sur les documents, comprenant des données de conversation professionnelles équilibrées et de haute qualité à des fins de réglage et de test. En ce qui concerne le deuxième numéro, nous identifierons manuellement les principaux domaines dans lesquels SL MT ne parvient pas à produire des traductions adéquates en l'absence de contexte. Nous créons ensuite un ensemble d'évaluation dans lequel ces phénomènes sont annotés afin de faciliter l'évaluation automatique des systèmes DL. Nous formons des modèles de TA à l'aide de notre corpus pour démontrer comment l'utilisation du contexte conduit à des améliorations.", 'pt': 'A tradução automática (MT) em nível de sentença (SL) atingiu uma qualidade aceitável para muitas linguagens com muitos recursos, mas não a MT em nível de documento (DL), que é difícil de 1) treinar com pouca quantidade de dados DL; e 2) avaliar, pois os principais métodos e conjuntos de dados se concentram na avaliação de LS. Para resolver o primeiro problema, apresentamos um corpus de conversação japonês-inglês alinhado a documentos, incluindo dados de conversação de negócios equilibrados e de alta qualidade para ajuste e teste. Quanto à segunda questão, identificamos manualmente as principais áreas em que o SL MT falha em produzir traduções adequadas por falta de contexto. Em seguida, criamos um conjunto de avaliação onde esses fenômenos são anotados para aliviar a avaliação automática de sistemas DL. Treinamos modelos de MT usando nosso corpus para demonstrar como o uso do contexto leva a melhorias.', 'es': 'La traducción automática (MT) a nivel de oración (SL) ha alcanzado una calidad aceptable para muchos idiomas de altos recursos, pero no para la MT a nivel de documento (DL), que es difícil de 1) entrenar con poca cantidad de datos de DL; y 2) evaluar, ya que los principales métodos y conjuntos de datos se centran en la evaluación de SL. Para abordar el primer problema, presentamos un corpus de conversación japonés-inglés alineado con documentos, que incluye datos de conversaciones comerciales equilibrados y de alta calidad para ajustes y pruebas. En cuanto a la segunda cuestión, identificamos manualmente las principales áreas en las que SL MT no produce traducciones adecuadas por falta de contexto. A continuación, creamos un conjunto de evaluación en el que se anotan estos fenómenos para facilitar la evaluación automática de los sistemas DL. Entrenamos modelos de MT utilizando nuestro corpus para demostrar cómo el uso del contexto conduce a mejoras.', 'zh': '句级(SL)机器翻译(MT)已多高资言语者受质,而文档级(DL)MT无,难1)练于少DL之数。 与2)评估,以为大法及数据集侧重于SL评估。 供一文档之日语-英语会语料库,平衡高质量业会话数据。 至于二者,手动定SL MT阙上下文无以生重译之要。 然后创一评估集,其注释之,以减DL统之自估。 我用语料库训机器翻译模形,以示上下文改进。', 'hi': 'वाक्य-स्तर (एसएल) मशीन अनुवाद (एमटी) कई उच्च-संसाधन वाली भाषाओं के लिए स्वीकार्य गुणवत्ता तक पहुंच गया है, लेकिन दस्तावेज़-स्तर (डीएल) एमटी नहीं है, जो 1 के लिए मुश्किल है) डीएल डेटा की थोड़ी मात्रा के साथ ट्रेन; और 2) मूल्यांकन, मुख्य विधियों और डेटा सेट SL मूल्यांकन पर ध्यान केंद्रित के रूप में। पहले मुद्दे को संबोधित करने के लिए, हम ट्यूनिंग और परीक्षण के लिए संतुलित, उच्च-गुणवत्ता वाले व्यावसायिक वार्तालाप डेटा सहित एक दस्तावेज़-संरेखित जापानी-अंग्रेजी वार्तालाप कॉर्पस प्रस्तुत करते हैं। दूसरे मुद्दे के लिए, हम मैन्युअल रूप से मुख्य क्षेत्रों की पहचान करते हैं जहां SL MT संदर्भ की कमी में पर्याप्त अनुवाद का उत्पादन करने में विफल रहता है। फिर हम एक मूल्यांकन सेट बनाते हैं जहां इन घटनाओं को डीएल सिस्टम के स्वचालित मूल्यांकन को कम करने के लिए एनोटेट किया जाता है। हम अपने कॉर्पस का उपयोग करके एमटी मॉडल को प्रशिक्षित करते हैं ताकि यह प्रदर्शित किया जा सके कि संदर्भ का उपयोग करने से सुधार कैसे होता है।', 'ja': '文レベル（ SL ）機械翻訳（ MT ）は、多くの高資源言語で許容可能な品質に達していますが、文書レベル（ DL ） MTではありません。これは、1 ） DLデータ量の少ないトレーニングでは困難です。2 ）主な方法とデータセットがSL評価に焦点を当てているため、評価します。最初の問題に対処するために、チューニングとテストのためのバランスのとれた高品質のビジネス会話データを含む、ドキュメントに沿った日英会話コーパスを提示します。2番目の問題については、文脈の欠如の中でSL MTが適切な翻訳を作成できない主な領域を手動で特定します。次に、これらの現象に注釈を付けてDLシステムの自動評価を緩和する評価セットを作成します。私たちはコーパスを使用してMTモデルをトレーニングし、コンテキストを使用することがどのように改善につながるかを実演します。', 'ru': 'Машинный перевод (МТ) на уровне предложения (SL) достиг приемлемого качества для многих языков с высоким уровнем ресурсов, но не на уровне документов (DL) MT, что трудно 1) обучить с небольшим объемом данных DL; и 2) оценить, поскольку основные методы и наборы данных сосредоточены на оценке SL. Для решения первого вопроса мы представляем согласованный с документами японо-английский корпус разговоров, включающий сбалансированные, высококачественные данные делового разговора для настройки и тестирования. Что касается второго вопроса, мы вручную определяем основные области, в которых SL MT не производит адекватных переводов в отсутствие контекста. Затем мы создаем набор оценок, где эти явления аннотируются, чтобы облегчить автоматическую оценку систем DL. Мы обучаем модели MT, используя наш корпус, чтобы продемонстрировать, как использование контекста приводит к улучшениям.', 'ga': 'Tá cáilíocht inghlactha bainte amach ag aistriúchán meaisín (MT) ag leibhéal abairtí (SL) do go leor teangacha ard-acmhainní, ach ní leibhéal doiciméad (DL) MT, rud atá deacair 1 a oiliúint gan mórán sonraí DL; agus 2) meastóireacht a dhéanamh, toisc go ndíríonn na príomh-mhodhanna agus na tacair sonraí ar mheastóireacht SL. Chun aghaidh a thabhairt ar an gcéad eagrán, cuirimid i láthair corpas comhrá Seapáinis-Béarla atá ailínithe le doiciméad, lena n-áirítear sonraí cothromaithe ardcháilíochta maidir le comhrá gnó le haghaidh tiúnadh agus tástála. Maidir leis an dara eagrán, sainaithnímid de láimh na príomhréimsí ina dteipeann ar SL MT aistriúcháin leordhóthanacha a tháirgeadh in easpa comhthéacs. Cruthaímid tacar meastóireachta ansin ina ndéantar na feiniméin seo a anótáil chun meastóireacht uathoibríoch ar chórais DL a mhaolú. Cuirimid oiliúint ar mhúnlaí MT ag baint úsáide as ár gcorpas chun a léiriú conas a thagann feabhsúcháin as comhthéacs a úsáid.', 'ka': 'სიტყვების დონე (SL) მანქანის გარგუმარება და 2) გავამუშაოთ, როგორც მნიშვნელოვანი მეტოვები და მონაცემები SL გავამუშაოთ. პირველი პრობლემენტის შესახებ, ჩვენ აღწერეთ დოკუმენტის-ინგლისური საუბლემენტის კოპპუუსს, რომელიც ბალანსური, მეტი კანოსური სამუშაო სამუ მეორე პრობლემაზე, ჩვენ ხელსახურად განვიცნობით მნიშვნელოვანი ადგილები, სადაც SL MT არ შეუძლებელია საკუთნტების არსებობით საკუთნტის შესაძლებელი გადაწ შემდეგ ჩვენ შევქმნით განსაზღვრება, სადაც ეს ფენომენები აღმოჩენიან DL სისტემების ავტომატური განსაზღვრებას. ჩვენ MT მოდელების გამოყენებას გამოყენებთ ჩვენი კორპუსს, როგორ გამოყენება კონტექსტის გამოყენებას გაუკეთება.', 'hu': 'A mondatszintű (SL) gépi fordítás (MT) számos nagy erőforrású nyelven elfogadható minőséget ért el, de nem dokumentumszintű (DL) MT, amelyet nehéz 1) tanítani kevés mennyiségű DL adattal; és 2) értékelni, mivel a fő módszerek és adatkészletek az SL értékelésére összpontosítanak. Az első probléma megoldásához bemutatunk egy dokumentumhoz igazított japán-angol beszélgetési korpuszt, amely kiegyensúlyozott, kiváló minőségű üzleti beszélgetési adatokat tartalmaz hangoláshoz és teszteléshez. Ami a második számot illeti, manuálisan azonosítjuk azokat a főbb területeket, ahol az SL MT kontextus hiányában nem készít megfelelő fordításokat. Ezután létrehozunk egy értékelő készletet, ahol ezeket a jelenségeket jegyzeteljük, hogy enyhítsük a DL rendszerek automatikus értékelését. Az MT modelleket a korpuszunkkal képezzük annak bemutatására, hogy a kontextus használata hogyan vezet fejlesztésekhez.', 'el': 'Η μηχανική μετάφραση σε επίπεδο φράσεων (SL) έχει φθάσει σε αποδεκτή ποιότητα για πολλές γλώσσες υψηλής περιεκτικότητας, αλλά όχι σε επίπεδο εγγράφων (DL) MT, η οποία είναι δύσκολο 1) να εκπαιδευτεί με μικρή ποσότητα δεδομένων DL· και 2) αξιολογούν, καθώς οι κύριες μέθοδοι και σύνολα δεδομένων επικεντρώνονται στην αξιολόγηση των SL. Για να αντιμετωπιστεί το πρώτο ζήτημα, παρουσιάζουμε ένα σώμα συζήτησης ιαπωνικά-αγγλικά ευθυγραμμισμένο με έγγραφα, το οποίο περιλαμβάνει ισορροπημένα, υψηλής ποιότητας δεδομένα επιχειρηματικών συζητήσεων για συντονισμό και δοκιμή. Όσον αφορά το δεύτερο ζήτημα, προσδιορίζουμε χειροκίνητα τους κύριους τομείς όπου η SL MT δεν παράγει επαρκείς μεταφράσεις λόγω έλλειψης πλαισίου. Στη συνέχεια, δημιουργούμε ένα σύνολο αξιολόγησης όπου αυτά τα φαινόμενα σχολιάζονται για την ανακούφιση της αυτόματης αξιολόγησης των συστημάτων DL. Εκπαιδεύουμε μοντέλα ΜΤ χρησιμοποιώντας το σώμα μας για να δείξουμε πώς η χρήση του πλαισίου οδηγεί σε βελτιώσεις.', 'it': "La traduzione automatica (SL) a livello di frase (MT) ha raggiunto una qualità accettabile per molte lingue con risorse elevate, ma non per MT a livello di documento (DL), che è difficile 1) allenarsi con poca quantità di dati DL; e 2) valutare, in quanto i principali metodi e set di dati si concentrano sulla valutazione SL. Per affrontare il primo problema, presentiamo un corpus di conversazione giapponese-inglese allineato ai documenti, che include dati bilanciati e di alta qualità delle conversazioni aziendali per la messa a punto e il test. Per quanto riguarda il secondo numero, identifichiamo manualmente le principali aree in cui SL MT non riesce a produrre traduzioni adeguate in mancanza di contesto. Creiamo quindi un set di valutazione in cui questi fenomeni sono annotati per alleviare la valutazione automatica dei sistemi DL. Formiamo modelli MT utilizzando il nostro corpus per dimostrare come l'utilizzo del contesto porti a miglioramenti.", 'lt': 'Sentencijų lygis (SL) mašininis vertimas (MT) pasiekė priimtiną kokybę daugeliui didelių išteklių turinčių kalbų, bet ne dokumentų lygis (DL) MT, kuris sunku 1) traukinys su mažu DL duomenų kiekiu; ir 2) įvertinti, kaip pagrindiniai metodai ir duomenų rinkiniai sutelkiami į SL vertinimą. Siekdami išspręsti pirmąjį klausimą, pristatysime dokumentu suderintą japonų ir anglų kalbų korpusą, įskaitant subalansuotus, aukštos kokybės verslo pokalbių duomenis koreguoti ir bandyti. Kalbant apie antrąjį klausimą, rankiniu būdu nustatome pagrindines sritis, kuriose SL MT nepateikia tinkamų vertimų trūkstant konteksto. Tada sukuriame vertinimo rinkinį, kuriame šie reiškiniai yra anotuoti siekiant palengvinti automatinį DL sistemų vertinimą. Mokome MT modelius naudojant savo korpusą, kad parodytume, kaip naudojant kontekstą galima pagerinti.', 'mk': 'Машински превод на ниво на реченици (SL) (MT) достигна прифатлив квалитет за многу јазици со високи ресурси, но не на ниво на документ (DL) MT, што е тешко да се обучува 1) со мала количина DL податоци; и 2) да проценат, како што главните методи и податоци се фокусираат на проценката на СЛ. За да го решиме првото прашање, претставуваме документиран јапонско-англиски разговарачки корпус, вклучувајќи балансирани, висококвалитетни податоци за бизнис разговор за налаштување и тестирање. As for the second issue, we manually identify the main areas where SL MT fails to produce adequate translations in lack of context.  Потоа создаваме сет на евалуација каде овие феномени се анотирани за олеснување на автоматската евалуација на DL системите. Тренираме мет модели користејќи го нашиот корпус за да демонстрираме како употребата на контекст води до подобрувања.', 'kk': 'Сөздік деңгейі (SL) машинаның аударуы (MT) көптеген көптеген көптеген тілдер үшін қабылданатын сапатты жеткізді, бірақ құжат деңгейі (DL) MT деңгейі емес, бұл 1- ге қиын) DL деректерінің кішкентай 2) негізгі әдістер мен деректер баптаулары SL баптауына назар аударылады. Бірінші мәселеге шешіміз үшін, жапон- ағылшын сөйлесу корпус құжаттарына теңдеу және сынақтау үшін балансияланған, жоғары сапатты бизнес сөйлесу деректерін келтірік Екінші мәселе туралы, SL MT-нің негізгі аудармаларды қолмен анықтаймыз. Содан кейін бұл пайдаланулар DL жүйелерді автоматты түрде бағалау үшін бағалау бағдарламасын құрамыз. Корпусты қолдану үшін MT үлгілерін жақсарту үшін көрсету үшін.', 'ml': 'ശിക്ഷ- നില (SL) മെഷീന്\u200d പരിഭാഷ (MT) വളരെ വിഭവങ്ങളുള്ള ഭാഷകള്\u200dക്ക് സ്വീകരിക്കുന്നതിനുള്ള ഗുണവിശേഷം എത്തിയിരിക്കുന്നു. പക്ഷെ രേഖയുടെ നില (DL 2) പ്രധാന രീതികളും ഡേറ്റാ സജ്ജീകരിക്കുന്നതിനാല്\u200d എസ്എല്\u200d വിലാസങ്ങളില്\u200d ശ്രദ്ധയോടെ ശ്രദ്ധിക്കുക. ആദ്യത്തെ പ്രശ്നത്തെക്കുറിച്ച് വിശദീകരിക്കാന്\u200d, നമ്മള്\u200d ഒരു രേഖയില്\u200d ചേര്\u200dത്തുനില്\u200dക്കുന്ന ജപ്പാനീസ്-ഇംഗ്ലീഷ് സം രണ്ടാമത്തെ പ്രശ്നത്തിനെക്കുറിച്ചാണ് നമ്മള്\u200d കൈകാര്യം പരിചയപ്പെടുത്തുന്നത്. എസ്എല്\u200d എംടി പരിശോധിക്കാന്\u200d പരാജയപ് പിന്നീട് നമ്മള്\u200d ഒരു വിലയ്ക്ക് സെറ്റ് ഉണ്ടാക്കുന്നു. ഡിഎല്\u200d സിസ്റ്റത്തിന്റെ ആത്മികമായി വിലാസപ്രകാരം ലഘൂകരിക് നമ്മുടെ കോര്\u200dപ്പസ് ഉപയോഗിച്ച് നമ്മള്\u200d എംടി മോഡലുകള്\u200d പരിശീലിപ്പിക്കുന്നു. കോണ്\u200dട്ടെക്സ്റ്റോക്', 'mt': 'Sentence-level (SL) machine translation (MT) has reached acceptable quality for many high-resourced languages, but not document-level (DL) MT, which is difficult to 1) train with little amount of DL data;  u 2) jevalwaw, billi l-metodi u s-settijiet ta’ dejta ewlenin jiffukaw fuq l-evalwazzjoni SL. Biex nindirizzaw l-ewwel kwistjoni, nippreżentaw korpus ta’ konverżjoni Ġappuniża-Ingliża allinjat mad-dokument, inkluż dejta bilanċjata u ta’ konverżjoni kummerċjali ta’ kwalità għolja għall-a ġġustament u l-ittestjar. Fir-rigward tat-tieni kwistjoni, nidentifikaw manwalment l-oqsma ewlenin fejn SL MT tonqos milli tipproduċi traduzzjonijiet adegwati fin-nuqqas ta’ kuntest. Imbagħad inħolqu sett ta’ evalwazzjoni fejn dawn il-fenomeni jiġu annotati biex itaffu l-evalwazzjoni awtomatika tas-sistemi DL. Aħna nħarrġu mudelli MT li jużaw il-korpus tagħna biex juru kif l-użu tal-kuntest iwassal għal titjib.', 'ms': 'Terjemahan mesin aras-hukuman (SL) (MT) telah mencapai kualiti yang diterima untuk banyak bahasa-bahasa sumber-tinggi, tetapi bukan aras-dokumen (DL) MT, yang sukar untuk 1) melatih dengan jumlah sedikit data DL; dan 2) menilai, sebagai kaedah utama dan set data fokus pada penilaian SL. Untuk mengatasi isu pertama, kami memperkenalkan sebuah korpus perbualan Jepun-Inggeris disesuaikan dokumen, termasuk data perbualan bisnes yang seimbang, berkualiti tinggi untuk penyesuaian dan ujian. Adapun isu kedua, kita secara manual mengenalpasti kawasan utama di mana SL MT gagal menghasilkan terjemahan yang sesuai dalam kekurangan konteks. Kemudian kita cipta set penilaian di mana fenomena ini dicatat untuk mengurangi penilaian automatik sistem DL. We train MT models using our corpus to demonstrate how using context leads to improvements.', 'pl': 'Tłumaczenie maszynowe na poziomie zdań (SL) osiągnęło akceptowalną jakość dla wielu języków o wysokich zasobach, ale nie dla poziomu dokumentów (DL), który jest trudny do przeszkolenia z niewielką ilością danych DL; oraz 2) oceny, gdyż główne metody i zbiory danych koncentrują się na ocenie SL. Aby rozwiązać pierwszy problem, przedstawiamy dostosowany do dokumentów korpus rozmów japońsko-angielskich, zawierający zrównoważone, wysokiej jakości dane rozmów biznesowych do strojenia i testowania. Jeśli chodzi o drugą kwestię, ręcznie identyfikujemy główne obszary, w których SL MT nie wytwarza odpowiednich tłumaczeń w braku kontekstu. Następnie tworzymy zestaw oceny, w którym te zjawiska są adnotacjonowane, aby ułatwić automatyczną ocenę systemów DL. Trenujemy modele MT wykorzystując nasz korpus, aby pokazać, jak wykorzystanie kontekstu prowadzi do ulepszeń.', 'no': 'Utsetningsnivå (SL) maskinsomsetjing (MT) har nådd godkjennig kvalitet for mange høg ressurserte språk, men ikkje dokumentnivå (DL) MT, som er vanskeleg for 1) treng med lite mengda DL- data. og 2) evaluer som hovudmetodane og datasettet fokuserer på SL-evaluering. For å handtera det første problemet, presenterer vi eit samtalekorpus med dokumentinnstillingar i japansk-engelsk samtaler, inkludert balansert, høg kvalitetsk samtaledata for oppsett og testing. I det andre problemet identifiserer vi manuelt hovudområdet der SL MT ikkje kan produsere tilgjengelege omsetjingar i mangling av kontekst. Vi oppretter så eit evalueringssett der desse fenomena er merka til å redusera automatisk evaluering av DL-systemet. Vi treng MT-modeller med korpus vårt for å demonstrare korleis bruk av kontekst fører til forbedringar.', 'mn': 'Хэрэглэгчийн түвшин (SL) машины хөрөнгө оруулалт (MT) олон өндөр байгууллагын хэл дээр хүлээн зөвшөөрөгдлийн сайн чанартай болсон, гэхдээ баримт түвшин (DL) MT биш, 1-д хэцүү) DL өгөгдлийн бага хэмжээтэй tren 2) SL оюутнуудын гол арга болон өгөгдлийн сангууд нь анхаарлаа төвлөрөх болно. Эхний асуудлыг асуухын тулд бид баримтуудыг япон-Англи-хэлний ярианы корпус болгож, баланслагдсан, өндөр чанартай бизнесийн ярианы мэдээллийг шалгах, шалгах боломжтой болгосон. Хоёр дахь асуудлын тухай бид SL MT-ийн үндсэн хэсэгт хангалттай орчуулалт гаргаж чадахгүй байдаг. Дараа нь бид эдгээр явдал нь DL системийн автоматик дүгнэлтийг багасгах боломжтой байдаг талаар үнэлгээ гаргадаг. Бид корпус ашиглаж MT загварын загварыг хэрхэн ашиглаж сайжруулах нөлөөлдөг талаар үзүүлдэг.', 'ro': 'Traducerea automată la nivel de sentință (SL) a atins o calitate acceptabilă pentru multe limbi cu resurse ridicate, dar nu la nivel de document (DL), care este dificil să se antreneze cu o cantitate redusă de date DL; și 2) evaluarea, deoarece principalele metode și seturi de date se concentrează pe evaluarea SL. Pentru a aborda prima problemă, vă prezentăm un corpus de conversații japoneză-engleză aliniat la documente, inclusiv date echilibrate și de înaltă calitate ale conversațiilor de afaceri pentru reglare și testare. În ceea ce privește a doua problemă, identificăm manual principalele domenii în care SL MT nu reușește să producă traduceri adecvate în lipsa contextului. Creăm apoi un set de evaluare în care aceste fenomene sunt adnotate pentru a ușura evaluarea automată a sistemelor DL. Instruim modele MT folosind corpul nostru pentru a demonstra modul în care utilizarea contextului duce la îmbunătățiri.', 'so': 'Turjumista machine (SL) wuxuu gaadhay qiimo la aqbali karo oo luuqado badan oo aad-resourceed ah, laakiin ma gaadhin heerka dokumenta (DL) MT, taasoo u adag 1) waxbarashada ku haysta tiro yar oo DL data ah; iyo 2) qiimeeya, sida qaababka ugu muhiimsan iyo macluumaadka ay ku kalsoonaadaan qiimeynta SL. Si aan ugu sheekeyno arrinta ugu horeeyay, waxaan soo bandhignaynaa qofka sameynta oo loo qoray japaniya-Ingiriis, kuwaas oo ku jira macluumaadka hadalka ganacsiga ee si siman ah oo u fiican, si loo tijaabiyo iyo imtixaanka. Dhibaatada labaad, waxaynu si rasmi ah u garanaynaa meelaha ugu horeeya ee SL MT aan u baahnayn inuu soo bixiyo turjubaan ku filan iyadoo aan u baahnayn kooxda. Markaas waxaynu abuurnaa koob qiimeynta ah oo ay ku dhibaataysan waxyaabahaas si aan u fududayno qiimeynta nidaamka DL. We train MT models using our corpus to demonstrate how using context leads to improvements.', 'sv': 'Maskinöversättning på meningsnivå (SL) har uppnått acceptabel kvalitet för många språk med hög resurs, men inte dokumentnivå (DL) MT, vilket är svårt att 1) träna med liten mängd DL-data. och 2) utvärdera, eftersom de viktigaste metoderna och datauppsättningarna fokuserar på SL-utvärdering. För att lösa det första problemet presenterar vi en dokumentanpassad japansk-engelska konversationskorpus, inklusive balanserade, högkvalitativa affärskonversationsdata för justering och testning. När det gäller den andra utgåvan identifierar vi manuellt de huvudområden där SL MT misslyckas med att producera adekvata översättningar i brist på sammanhang. Vi skapar sedan en utvärderingssats där dessa fenomen kommenteras för att underlätta automatisk utvärdering av DL-system. Vi tränar MT-modeller med hjälp av vår korpus för att visa hur kontextanvändning leder till förbättringar.', 'sr': 'Razina kazne (SL) prevod mašine (MT) postigla je prihvatljiva kvaliteta za mnoge jezike sa visokim resursima, ali ne na nivou dokumenta (DL) MT, što je teško za 1) vlakovati sa manjom količinom podataka DL-a; i 2) proceniti, kao glavne metode i podatke postavljaju fokus na procjenu SL-a. Da bi se riješili prvi problem, predstavljamo korpus razgovora japanskog-engleskog dokumenta, uključujući balancirani, visokokvalitetni bizniski razgovor podataka o naštimovanju i testiranju. Što se tiče drugog pitanja, ručno identifikujemo glavne oblasti u kojima SL MT ne proizvodi odgovarajuće prevode u nedostatku konteksta. Zatim stvaramo procjenu gde su ovi fenomeni annotirani kako bi olakšali automatsku procjenu DL-a. Mi treniramo MT modele koristeći naš korpus da pokažemo kako korištenje konteksta vodi do poboljšanja.', 'ta': 'வாக்கியம்- நிலை (SL) இயந்திர மொழிமாற்றி (MT) பல உயர்மூல மொழிகளுக்கு ஏற்றுக் கொள்ளும் தரம் அடைந்துள்ளது, ஆனால் ஆவண- நிலை (DL) MT அல்ல, அது 1 க்கு கடினமாக 2) முக்கிய முறைமைகள் மற்றும் தரவு அமைப்பை SL மதிப்பின் மீது கவனம் செலுத்துகிறது. முதல் பிரச்சினையை விளக்க, நாம் ஒரு ஆவணத்தை ஒத்திசைப்படுத்துகிறோம் ஜப்பானிய- ஆங்கிலம் பேச்சு குறிப்பை கொண்டு வருக இரண்டாவது பிரச்சினைக்காக, நாம் கைமுறையாக கண்டுபிடிக்கும் பொதுவான மொழிபெயர்ப்புகளை உருவாக்க இயலவில்லை. DL முறைமைகளின் தானியங்கி மதிப்பினையை எளிதாக்குவதற்கு இந்த பொருள்கள் எதிர்பார்க்கப்பட்டுள்ளது என்பதை நாம் ஒரு புள நாங்கள் எம்டி மாதிரிகளை எங்கள் கோர்பாஸ் பயன்படுத்தி முன்னேற்றத்தை எவ்வாறு பயன்படுத்துகிறது என்பதை காட்', 'ur': 'سنت سطح (SL) ماشین ترجمہ (MT) بہت سی عالی رسسور زبانوں کے لئے مناسب کیفیت پہنچ گئی ہے، لیکن سنت سطح (DL) MT نہیں ہے، جو 1 سے مشکل ہے، DL ڈائٹے کے اندر تھوڑے اندازے کے ساتھ ترینس کرتی ہے۔ اور 2) مطالعہ کریں، جیسے اصلی طریقے اور ڈیٹے SL مطالعہ پر تمرکز کریں۔ پہلی مسئلہ کے بارے میں ہم نے ایک دکھانے والی ژاپنی-انگلیسی صحبت کورپوس کو پیش کیا تھا، جیسے سامنال، بالکل کیفیت صحبت کے معاملہ میں تنظیم اور آزمائش کے لئے مطابق ہے. دوسرے مسئلہ کے بارے میں، ہم نے اسلام ٹی ٹی ٹی سی مٹی کے مطابق قابل ترجمہ پیدا کرنے کے لئے مطابق غیر قابل تعریف کرنے کے لئے اپنا ہاتھ سے پہچان لیا ہے. پھر ہم ایک ارزیابی مجموعہ بناتے ہیں جہاں یہ دکھائے جاتے ہیں کہ DL سیسٹموں کی اتمام ارزیابی کم کریں۔ ہم MT موڈلوں کو اپنے کورپوس کے مطابق تطابق دیتے ہیں کہ کانٹ کا استعمال کس طرح سیدھائی کے لئے چلتا ہے۔', 'si': 'වාර්තාව- මට්ටම (SL) පණිවිඩය (MT) අවශ්\u200dය භාෂාවට ප්\u200dරතික්\u200dරියාත්මක විශේෂ භාෂාවට ලැබුනා, ඒත් වාර්තාව- මට්ටම (DL) MT නෙමේ, ඒක ඒ වගේම 2) විශ්වාස කරන්න, ප්\u200dරධාන පද්ධතිය හා දත්තේ SL විශ්වාස සඳහා බලන්න. මුලින් ප්\u200dරශ්නයක් ලැබෙන්න, අපි ලිපිණිය සඳහා ජාපාන්-ඉංග්\u200dරීසි කතා කරුණාකරණ කරුණාකරණ කරුණාකරණය ස දෙවෙනි ප්\u200dරශ්නයක් ගැන, අපි අයිතියෙන් ප්\u200dරධාන ප්\u200dරශ්නයක් තියාගන්නේ SL MT කියලා සම්පූර්ණය නැති විදිය අපි පස්සේ DL පද්ධතියේ ස්වයංක්\u200dරීය විශ්ලේෂණයක් අඩංගුවන්න සැකසුම් සැකසුම් කරනවා. අපි MT මොඩල් එක ප්\u200dරයෝජනය කරනවා අපේ කොර්පස් එක්ක ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා කොහොමද සංවේදන', 'uz': "@ info: whatsthis va 2) qiymati qiling, asosiy usullar va maʼlumotlar SL qiymatlariga foydalanadi. Birinchi muammo bilan murojaat qilish uchun, biz Japoniya- ingliz tilida bir tashqi axborot kompyuterga ega qilamiz. Bu birinchi muammolarni birlashtirish va sinov qilish uchun balandlik, juda katta taʼminlovchi tashkilotlar maʼlumoti. Ikkinchi muammo bo'lsa, biz SL MT'ning asosiy maydonlarini qoʻlbola aniqlashimiz mumkin. Keyin biz DL tizimlarining avtomatik qiymatini yoqish uchun bu narsalarni yaramiz. Biz MT modellarimizni kopusizdan foydalanishni o'rganamiz. Konstant foydalanish muvaffaqiyatlarini o'zgartirib chiqaradi.", 'vi': 'Bản dịch tần số hình ảnh (SL) đã đạt đến mức độ tốt cho nhiều ngôn ngữ có nguồn lực cao, nhưng không phải cấp tài liệu (DL) MTV, mà rất khó khăn với 1) tập luyện với một lượng ít dữ liệu DL; và 2) đánh giá, vì các phương pháp và hệ thống dữ liệu chính tập trung vào đánh giá SL Để giải quyết vấn đề đầu tiên, chúng tôi giới thiệu một tập đoàn đối thoại Nhật-Anh chỉnh văn bản, gồm những dữ liệu đối thoại công việc chất lượng, chất lượng cao để chỉnh sửa và kiểm tra. Còn về vấn đề thứ hai, chúng tôi chỉ định thủ tục các khu vực chính nơi mà SL MTV không sản xuất bản dịch thích đáng khi thiếu bối cảnh. Sau đó chúng ta sẽ tạo ra một bộ đánh giá nơi những hiện tượng này được ghi chú để giảm giảm đánh giá tự động hệ thống DL. Chúng tôi huấn luyện các mô hình MTV dùng tập đoàn của chúng tôi để chứng minh cách sử dụng ngữ cảnh dẫn tới cải tiến.', 'bg': 'Машинният превод на ниво изречение (МТ) е достигнал приемливо качество за много езици с висок ресурс, но не и за ниво документ (МТ), което е трудно 1) да се обучава с малко количество данни; и 2) оценяват, като основните методи и набори от данни се фокусират върху оценката на СЛ. За да отговорим на първия въпрос, представяме кореспондент с документи на японско-английски разговор, включващ балансирани, висококачествени данни за бизнес разговори за настройка и тестване. Що се отнася до втория въпрос, ние ръчно идентифицираме основните области, в които SL MT не успява да създаде адекватни преводи при липса на контекст. След това създаваме набор от оценки, където тези явления са анотирани, за да облекчим автоматичната оценка на системите. Обучаваме модели, използвайки нашия корпус, за да демонстрираме как използването на контекста води до подобрения.', 'nl': 'Machine Translation (MT) op zinnenniveau (SL) heeft een aanvaardbare kwaliteit bereikt voor veel talen met hoge resources, maar niet voor MT op documentniveau (DL), dat moeilijk te trainen is met weinig DL-gegevens; en 2) evalueren, aangezien de belangrijkste methoden en gegevenssets zich richten op SL-evaluatie. Om het eerste probleem aan te pakken, presenteren we een Japans-Engels conversatiecorpus, inclusief gebalanceerde, hoogwaardige zakelijke conversatiegegevens voor afstemming en testen. Wat de tweede kwestie betreft, identificeren we handmatig de belangrijkste gebieden waar SL MT onvoldoende vertalingen produceert bij gebrek aan context. Vervolgens maken we een evaluatieset waarin deze fenomenen geannoteerd worden om automatische evaluatie van DL-systemen te verlichten. We trainen MT modellen met behulp van ons corpus om aan te tonen hoe het gebruik van context leidt tot verbeteringen.', 'da': 'Maskinoversættelse (SL) på sætningsniveau (MT) har nået acceptabel kvalitet for mange sprog med høj ressource, men ikke dokumentniveau (DL) MT, som er svært at træne med lille mængde DL data; og 2) evaluere, da de vigtigste metoder og datasæt fokuserer på SL evaluering. For at løse det første problem præsenterer vi et dokumentjusteret japansk-engelsk samtalekorpus, herunder afbalancerede forretningssamtalsdata af høj kvalitet til justering og test. Hvad angår det andet problem, identificerer vi manuelt de vigtigste områder, hvor SL MT ikke producerer tilstrækkelige oversættelser i mangel af kontekst. Vi laver derefter et evalueringssæt, hvor disse fænomener er noteret for at lette automatisk evaluering af DL-systemer. Vi træner MT modeller ved hjælp af vores korpus for at demonstrere, hvordan brug af kontekst fører til forbedringer.', 'hr': 'Razina kazne (SL) prevod stroja (MT) postigla je prihvatljiva kvaliteta za mnoge jezike s visokim resursima, ali ne razina dokumenta (DL) MT, što je teško 1) vlakovati s manjom količinom podataka DL-a; i 2) procijeniti kako su glavne metode i podaci usredotočeni na procjenu SL-a. Za rješavanje prvog pitanja predstavljamo korpus za razgovor s japanskim i engleskim dokumentima, uključujući balancirani, visokokvalitetni poslovni razgovor podataka o prilagodbi i testiranju. Što se tiče drugog pitanja, ručno identificiramo glavne područje gdje SL MT ne proizvodi odgovarajuće prevode u nedostatku konteksta. Zatim stvaramo procjenu gdje su ovi fenomeni annotirani kako bi se smanjili automatska procjena sustava DL-a. Vježbamo MT modele koristeći naš korpus kako bi pokazali kako korištenje konteksta vodi do poboljšanja.', 'id': 'Sentence-level (SL) machine translation (MT) has reached acceptable quality for many high-resourced languages, but not document-level (DL) MT, which is difficult to 1) train with little amount of DL data;  dan 2) mengevaluasi, sebagai metode utama dan set data fokus pada evaluasi SL. Untuk mengatasi masalah pertama, kami mempersembahkan sebuah dokumen-aligned Japanese-English conversation corpus, termasuk seimbang, kualitas tinggi data bisnis percakapan untuk tuning dan tes. Bagi isu kedua, kami secara manual mengidentifikasi daerah utama di mana SL MT gagal menghasilkan terjemahan yang cukup dalam kekurangan konteks. Kemudian kita menciptakan set evaluasi di mana fenomena ini dicatat untuk mengurangi evaluasi otomatis sistem DL. Kami melatih model MT menggunakan corpus kami untuk menunjukkan bagaimana menggunakan konteks mengarah kepada peningkatan.', 'de': 'Die maschinelle Übersetzung auf Satz-Ebene (SL) hat eine akzeptable Qualität für viele Sprachen mit hoher Ressourcenausstattung erreicht, aber nicht die maschinelle Übersetzung auf Dokumentenebene (DL), die nur schwer mit wenigen DL-Daten trainiert werden kann. und 2) evaluieren, da sich die wichtigsten Methoden und Datensätze auf die SL-Bewertung konzentrieren. Um das erste Problem anzugehen, stellen wir ein dokumentorientiertes japanisch-englisches Konversationskorpus vor, das ausgewogene, qualitativ hochwertige Geschäftskonversationsdaten zum Tuning und Testen enthält. Was die zweite Ausgabe betrifft, so identifizieren wir manuell die Hauptbereiche, in denen SL MT mangels Kontext keine adäquaten Übersetzungen produziert. Anschließend erstellen wir ein Evaluationsset, in dem diese Phänomene annotiert werden, um die automatische Auswertung von DL-Systemen zu erleichtern. Wir trainieren MT-Modelle mit unserem Korpus, um zu zeigen, wie die Nutzung von Kontext zu Verbesserungen führt.', 'sw': 'Tafsiri ya mashine ya adhabu (SL) imefikia kiwango kikubwa kwa lugha nyingi zenye rasilimali kubwa, lakini sio kiwango cha dokumentari (DL) MT, ambacho ni vigumu kwa 1) mafunzo yenye kiasi kidogo cha takwimu za DL; na 2) kutathmini, kama njia muhimu na taarifa zinazojikita kwenye tafiti ya SL. Ili kuzungumzia suala la kwanza, tunaweka makampuni ya mazungumzo yanayotengenezwa na Kijapani na Kiingereza, ikiwa ni pamoja na data za mazungumzo ya biashara yenye usawa wa juu kwa ajili ya kuhamasisha na kujaribu. Kuhusu suala la pili, tunatambua kwa manufaa maeneo muhimu ambapo SL MT haishindwi kutengeneza tafsiri za kutosha bila ukosefu wa muktadha. Kisha tunatengeneza kituo cha uchunguzi ambapo hali hii inasumbuliwa ili kupunguza tathmini za mifumo ya DL. Tunafunza mifano ya MT kwa kutumia vifaa vyetu ili kuonyesha namna ya kutumia muktadha unavyopelekea maboresho.', 'fa': 'ترجمه دستگاه (MT) سطح جمله (SL) برای زبانهای بسیاری از منابع بالا رسیده است، ولی نه سطح سند (DL) MT، که برای ۱ سخت است، با مقدار اندکی داده DL آموزش می\u200cدهد. و ۲) به عنوان روش\u200cهای اصلی و داده\u200cها روی ارزیابی SL، ارزیابی کنید. برای حل اولین مسئله، ما یک شرکت صحبت ژاپن و انگلیسی با صحبت کردن سند را پیشنهاد می\u200cکنیم، شامل اطلاعات صحبت تجارتی با مقایسه و کیفیت بالا برای تنظیم و آزمایش. در مورد مسئله دوم، ما به طور دستی منطقه اصلی را شناسایی می کنیم که SL MT به تولید ترجمه\u200cهای مناسب در غیر محیط قابل تولید نمی\u200cکند. سپس ما یک مجموعه ارزیابی ایجاد می کنیم که این پدیده\u200cها برای کمبود ارزیابی خودکار سیستم\u200cهای DL آزاد می\u200cشوند. ما مدل\u200cهای MT را با استفاده از کورپوس استفاده می\u200cکنیم تا نشان دهیم که چگونه استفاده از محیط\u200cها به سوی بهبود می\u200cرسد.', 'tr': "Sözler derejesi 2) Esasy yöntemler we maglumatlar SL deňlemesi üçin fokus çykýar. Ilkinji meselede çözmek üçin, japonça-iňlisçe söhbet korpusu bilen çykyp, düzelenmek we testirmek üçin ýokary kaliteli biznis sohbet maglumatyny görkezip otyrdyk. Ikinji meselede bolsa, SL MT'iň esasy bölekleriniň ýeterlik terjime edilmesinden ybaratdygyny elimizden tanyýarys. Sonra bu fenomenleriň otomatik deňlemesini küçütmek üçin hasaplamak düzenini bejerdik. Biz corpusymyzy ulanan MT modellerini öwredýäris nähili kontekstleriň gowularyna ýöretýändigini görkezmek üçin.", 'af': "Sentence- vlak (SL) masjien vertaling (MT) het aanvaarbaar kwaliteit bereik vir baie hoë- hulpbron tale, maar nie dokument- vlak (DL) MT, wat is moeilik na 1) trein met klein hoeveelheid DL data; en 2) evalueer, as die hoofmetode en data stel fokus op SL evaluering. Om die eerste probleem te raak, laat ons 'n document-aligned Japanese-English conversation corpus voorsien, insluitend balanseerde, hoë-kwaliteit besigheidskakel data vir tuning en toets. As vir die tweede probleem, ons identifiseer die hoofgebied waar SL MT misluk om adequate vertalings te produseer in ontbreek van konteks. Ons skep dan 'n evaluasie stel waar hierdie fenomene aangekies word om outomatiese evaluasie van DL stelsels te verminder. Ons tref MT-modelles deur ons korpus te gebruik om te wys hoe die gebruik van konteks na verbeteringe lei.", 'am': 'የሥርዓት ደረጃ (SL) machine ትርጉም (MT) ለብዙ ደረጃ-resource ቋንቋዎች የሚቀበል ጥሩ ደርሶአል፥ ነገር ግን የሰነድ-ደረጃ አይደለም (DL) MT, which is hard to 1) በተከፈለ ጥቂት DL ዳታዎችን ማግኘት ነው። 2) የዋነኛው ሥርዓት እና ዳራዎች SL አካሄሪውን እንደሚያስተካክሉ ነው፡፡ የመጀመሪያውን ጉዳይ ለመቀበል፣ የጃፓን-ኢንግሊዝኛ ንግግር ካርፓስ እና ለመግለጽ እና ለመፈተና እና ለማስታወቂያ የደረጃ የንግድ ዳታዎችን እናቀርባታለን፡፡ As for the second issue, we manually identify the main areas where SL MT fails to produce adequate translations in lack of context.  ከዚያም በኋላ እነዚህ ነገር የDL ስርዓቶች ማስታወቂያውን ለማቅረብ የሚደነግጡበትን ማስታወቂያ ዜና እናደርጋለን፡፡ የኮርፓስ ሞዴላዎችን በመጠቀም የሆኑትን ተግባር እንዴት እንደሚያሳድግ እናሳውቃለን፡፡', 'sq': 'Përkthimi automatik i nivelit të dënimeve (SL) (MT) ka arritur kualitetin e pranueshëm për shumë gjuhë me burime të larta, por jo nivelin e dokumentit (DL) MT, i cili është i vështirë të trajnohet me një sasi të vogël të dhënash DL; dhe 2) vlerësojnë, ndërsa metodat kryesore dhe grupet e të dhënave përqëndrohen në vlerësimin SL. Për të trajtuar çështjen e parë, ne paraqesim një korpus të bisedës japoneze-angleze të rreshtuar në dokument, duke përfshirë të dhënat e ekuilibruara, të cilësisë së lartë të bisedës së biznesit për tuning dhe testim. Sa për çështjen e dytë, ne identifikojmë manualisht fushat kryesore ku SL MT nuk prodhon përkthime të përshtatshme në mungesën e kontekstit. Pastaj krijojmë një sistem vlerësimi ku këto fenomene janë shënuar për të lehtësuar vlerësimin automatik të sistemeve DL. Ne trajnojmë modele MT duke përdorur korpusin tonë për të demonstruar se si përdorimi i kontekstit çon në përmirësime.', 'az': "Söz səviyyəsi (SL) maşın çevirimi (MT) çox yüksək qüvvətli dillər üçün qəbul edilən keyfiyyətə çatdı, amma döküm səviyyəsi (DL) MT deyildir, ki 1 üçün çətin ola bilər) az DL verilənləri ilə tren edilir; və 2) əsl metodlar və məlumatlar SL değerləşdirməsinə odaqlanır. İlk məsələdə çəkilmək üçün, çəkilmək və sınamaq üçün çəkilmək üçün, çəkilmiş, yüksək kaliteli biznis məlumatları olan Japon-İngilizce danışmaq korpusu təyin edirik. İkinci məsələdə gəldikdə, SL MT'nin məlumatlarının olmadığı yerdə uyğun tercümələr yaratmadığını öz əleyhinə tanıyırıq. Sonra bu parçaların DL sistemlərinin otomatik değerlendirməsini əskiltmək üçün nəzarətləndiriləcəyi bir qiyməti yaratdıq. Biz korpus vasitəsilə MT modellərini təhsil edirik ki, məlumatların istifadəsi necə yaxşılıqlara yol göstərir.", 'ko': '많은 자원이 풍부한 언어에 대해 문장급 기계번역(SL)은 이미 받아들일 수 있는 질에 도달했지만 문서급 기계번역(DL)은 받아들일 수 있는 질에 도달하지 못했다. 1) 소량의 DL 데이터로 훈련하기 어렵다.2) SL 평가에 초점을 둔 주요 방법 및 데이터 세트의 평가첫 번째 문제를 해결하기 위해, 우리는 문서와 일치하는 일영 회화 자료 라이브러리를 제공했는데, 이는 조정과 테스트에 사용되는 균형, 고품질의 비즈니스 회화 데이터를 포함한다.두 번째 문제는 SLMT가 위아래 문장이 부족한 상황에서 충분한 번역의 주요 영역을 형성하지 못한다는 것을 수동으로 확인하는 것이다.그런 다음 DL 시스템의 자동 평가를 줄이기 위해 평가 세트를 작성하여 이러한 현상에 대한 주석을 달았습니다.우리는 상하문 사용이 어떻게 개선되는지 보여주기 위해 우리의 어료 라이브러리를 사용하여 기계 번역 모델을 훈련한다.', 'bs': 'Razina kazne (SL) prevod mašine (MT) postigla je prihvatljiva kvaliteta za mnoge jezike sa visokim resursima, ali ne na razini dokumenta (DL) MT, koji je teško za 1) vlakovati sa manjim količinom podataka DL-a; i 2) procijeniti, kao glavne metode i postavke podataka fokusiraju se na procjenu SL-a. Da bi se riješili prvi problem, predstavljamo korpus za razgovor s japanskim i engleskim dokumentima, uključujući balancirani, visokokvalitetni bizniski razgovor podataka o prilagodbi i testiranju. Što se tiče drugog pitanja, ručno identificiramo glavne područje gdje SL MT ne proizvodi odgovarajuće prevode u nedostatku konteksta. Onda stvaramo procjenu gdje su ovi fenomeni annotirani kako bi olakšali automatsku procjenu sustava DL-a. Mi treniramo MT modele koristeći naš korpus kako bi pokazali kako korištenje konteksta vodi do poboljšanja.', 'bn': 'শাস্তি- স্তর (এসএল) মেশিন অনুবাদ (এমটি) অনেক উচ্চ সম্পদের ভাষার জন্য গ্রহণযোগ্য মান পৌঁছেছে, কিন্তু ডকুমেন্ট- স্তর (DL) এমটি নয়, যা ১ বেশ কঠিন) ট এবং ২) মূল্যায়ন করুন, যেহেতু প্রধান পদ্ধতি এবং তথ্য এসএল মূল্যায়নের উপর মনোযোগ দেয়। প্রথম বিষয়ের কথা বলার জন্য আমরা একটি নথিপত্রের সাথে সংযুক্ত করা হয়েছি জাপানী ইংরেজী কথোপকথন কর্পাস, যার মধ্যে রয়েছে বৈষম্য, উচ্চমা দ্বিতীয় বিষয়ের ব্যাপারে আমরা নিজেদের হাতে চিহ্নিত করি প্রধান এলাকায় যেখানে এসএলএমটি প্রাপ্ত অনুবাদের অভাবে যথে We then create an evaluation set where these phenomena are annotated to alleviate automatic evaluation of DL systems.  আমরা আমাদের কোর্পাস ব্যবহার করে এমটি মডেল প্রশিক্ষণ প্রদান করি যাতে প্রকাশ করা যায় কিভাবে ব্যবহার করে প্রকাশ করা', 'ca': "La traducció màquina de nivell de sentits (SL) ha aconseguit una qualitat acceptable per a moltes llengües amb recursos elevats, però no a nivell de document (DL) MT, que és difícil d'entrenar amb poca quantitat de dades DL; i 2) evaluar, com els principals mètodes i conjunts de dades es centren en l'evaluació SL. Per abordar la primera qüestió, presentem un corpus de conversació japonès-anglès alliniat amb documents, incloent dades equilibrades i d'alta qualitat de conversació comercial per ajustar i testar. Quant a la segona qüestió, identifiquem manualment les àrees principals on SL MT no produeix traduccions adequades en falta de context. Llavors creem un conjunt d'evaluació on aquests fenomens són anotats per aliviar l'evaluació automàtica dels sistemes DL. Ensenyem models MT utilitzant el nostre cos per demostrar com l'ús del context condueix a millors.", 'cs': 'Strojový překlad na úrovni vět (SL) dosáhl přijatelné kvality pro mnoho jazyků s vysokými zdroji, nikoli však MT na úrovni dokumentů (DL), což je obtížné 1) trénovat s malým množstvím dat DL; a 2) vyhodnocovat, protože hlavní metody a datové soubory se zaměřují na hodnocení SL. Pro řešení prvního problému představujeme japonsko-anglický konverzační korpus orientovaný na dokumenty, včetně vyvážených, vysoce kvalitních dat obchodních konverzací pro ladění a testování. Co se týče druhého čísla, ručně identifikujeme hlavní oblasti, kde SL MT nevytváří adekvátní překlady v nedostatku kontextu. Následně vytvoříme hodnotící sadu, kde jsou tyto jevy anotovány, aby se zmírnilo automatické hodnocení DL systémů. Školíme MT modely pomocí našeho korpusu, abychom demonstrovali, jak použití kontextu vede ke zlepšení.', 'et': 'Lausetasemel masintõlge (MT) on saavutanud vastuvõetava kvaliteedi paljudes suure ressursiga keeltes, kuid mitte dokumenditasemel (DL) MT, mida on raske 1) koolitada vähese hulga DL andmetega; ja 2) hinnata, sest peamised meetodid ja andmekogumid keskenduvad SL hindamisele. Esimese probleemi lahendamiseks esitame dokumendiga seotud jaapani-inglise vestluskorpuse, mis sisaldab tasakaalustatud ja kvaliteetseid ärivestluste andmeid häälestamiseks ja testimiseks. Mis puudutab teist küsimust, siis määrame käsitsi kindlaks peamised valdkonnad, kus SL MT ei suuda konteksti puudumisel piisavalt tõlkida. Seejärel loome hindamiskomplekti, kus need nähtused on märgitud, et leevendada DL süsteemide automaatset hindamist. Koolitame MT mudeleid, kasutades oma korpust, et näidata, kuidas konteksti kasutamine toob kaasa parandusi.', 'fi': 'Lausekkeen (SL) konekäännös (MT) on saavuttanut hyväksyttävän laadun monille suuriresurssisille kielille, mutta ei asiakirjatason (DL) MT, jota on vaikea 1) kouluttaa pienellä määrällä DL-dataa; ja 2) arvioida, sillä tärkeimmät menetelmät ja aineistot keskittyvät SL-arviointiin. Ensimmäiseen kysymykseen vastaamiseksi esittelemme dokumenttien mukaisen japanilais-englanninkielisen keskustelukorpusen, joka sisältää tasapainoisen ja laadukkaan liikekeskusteludatan viritystä ja testausta varten. Toisen kysymyksen osalta tunnistamme manuaalisesti tärkeimmät alueet, joilla SL MT ei pysty tuottamaan riittäviä käännöksiä asiayhteyden puuttuessa. Tämän jälkeen luomme arviointijoukon, jossa nämä ilmiöt merkitään helpottamaan DL-järjestelmien automaattista arviointia. Koulutamme MT-malleja korpusellamme osoittamaan, miten kontekstin käyttö johtaa parannuksiin.', 'hy': 'Բայց ոչ փաստաթղթի մակարդակի մակարդակի (DS) MT-ը, ինչը դժվար է 1-ի համար, փոքր քանակությամբ ուսումնասիրել ԴԼ տվյալներ: և 2) գնահատել, քանի որ հիմնական մեթոդները և տվյալների համակարգերը կենտրոնանում են ՍԼ-ի գնահատման վրա: Առաջին խնդիրը լուծելու համար մենք ներկայացնում ենք մի փաստաթղթերով համապատասխանված ճապոներեն-անգլերեն խոսակցության կորպոս, ներառյալ հավասարակշռություն, բարձր որակի բիզնես խոսակցության տվյալներ հարմարե Ինչ վերաբերում է երկրորդ խնդիրը, մենք ձեռքով բացահայտում ենք հիմնական ոլորտները, որտեղ ՍԼ ՄԹ-ը չի կարողանում բավարար թարգմանություններ ստանալ համատեքստի բացակայության դեպքում: Այնուհետև մենք ստեղծում ենք գնահատման համակարգ, որտեղ այս երևույթները նշումնավորված են, որպեսզի նվազեցնենք ԴԼ համակարգերի ավտոմատիկ գնահատումը: We train MT models using our corpus to demonstrate how using context leads to improvements.', 'jv': 'vertical-aligntextattr (2) Normal, text direction kanggo nganggo perusahaan sing perusahaan, kita lagi nggawe Dokumen-nggambar barang pangan Jepang-Inggris Ingo kanggo ngomong segondi iki, kita ngupakan manut kanggo ngerasai tanggal sing gak SL MT ora nggawe tarjamahan kanggo kulang kontext. Awak dhéwé éntuk perusahaan asseksi sing nggawe barang iki dadi, dadi kapan tanggal nggawe barang sistem DL. Name Awak dhéwé luwih model MT kuwi nggambar obah-obahan kanggo ngerasah piye bagian nguasai sampek sing bakal bantuan ngono nggawe ngubah bantuan.', 'bo': 'Sentence-level (SL) machine translation (MT)has reached acceptable quality for many high-resourced languages, but not document-level (DL) MT, which is difficult to 1) train with little amount of DL data; train with little amount of DL data (2) རྩ་བའི་ཐབས་ལམ་དང་གནས་ཚུལ་གྱིས་SL རིམ་དཔྱད་པར་དབྱིབས་བྱེད་ཀྱི་ཡོད། གནད་དོན་འདི་དང་པོ་དེ་ལ་བཤད་ན་ང་ཚོས་ཡིག་གེ་སྒྲིག་ཡིག་གི་གླེང་སྒྲོམ་གྱི་མཉམ་ཁང་ཞིག་བྱེད་ཀྱི་ཡོད། དོན་དག་གཉིས་པ་དེ་དངོས་ཡུལ་གཉིས་པ་དེ་ནི་SL MT ཡི་རྩ་བའི་གནས་སྟངས་ལག་ནས་ངོས་འཛིན་བྱེད་དགོས་མེད་པ་ཡིན་ན། དེ་ནས་འུ་ཅག་གིས་བྱ་ཚིག་འདི་དག་གི་རྗེས་སུ་རང་འགུལ་གྱིས་DL མ་ལག་གི་བཟོ་བཅོས་ལ་རང་འགུལ་གྱིས་བཟོ་བཅོས ང་ཚོས་མཐུན་པའི་མིག་དཔེ་གཟུགས་འགྱུར་བ་དེ་གོང་ཚོར་ལག་ནས་ཡོད་པའི་ཁྲོད་ཅིག་ཡར་རྒྱས་གཏོང་ཐབས་ཀྱི་ས', 'sk': 'Strojno prevajanje na ravni stavka (SL) je doseglo sprejemljivo kakovost za številne jezike z visokimi viri, ne pa tudi za strojno prevajanje na ravni dokumenta (DL), ki ga je težko 1) trenirati z malo količino podatkov DL; in 2) vrednotenje, saj se glavne metode in podatkovni nizi osredotočajo na vrednotenje SL. Za obravnavo prvega vprašanja predstavljamo korpus pogovorov v japonsko-angleščini, ki vključuje uravnotežene, visokokakovostne podatke o poslovnih pogovorih za nastavitev in testiranje. Kar zadeva drugo vprašanje, ročno opredelimo glavna področja, kjer SL MT brez konteksta ne uspe ustvariti ustreznih prevodov. Nato ustvarimo vrsto vrednotenja, kjer so ti pojavi označeni, da bi olajšali avtomatsko vrednotenje sistemov DL. Modele MT usposabljamo z uporabo našega korpusa, da prikažemo, kako uporaba konteksta vodi do izboljšav.', 'ha': "@ item: inmenu kuma 2) ka ƙaddara, kamar yadda madaidaita da data na daidaita yana cikin muhimmin ƙaddara SL. To, dõmin a yi magana ga masu farkon al'amarin, muna halatar da wata takardar mazaɓa da aka daidaita na japane-Ingiriya, tare da data na mazaɓa masu daidaita da inganci masu nauyi ga tunkuɗe da jarrabãwa. Ga masu sakan da na ƙara, za mu gane ruwan farko, inda SL MT bai kasa sami fassarar da inganci ba. Sa'an nan kuma Muke ƙãga wani salo da za'a zartar da waɗannan abu dõmin ya sauƙaƙara evaluation farat ɗaya na'ura na'ura na'ura. Tuna kõre misalin MT da ke amfani da kwamfyutan mu dõmin Mu nuna jinin amfani da mazaɓa na amfani da kwamfyutan ta ƙara improvement.", 'he': 'תרגום מכונת רמת הגזרה (SL) (MT) הגיע לאיכות קבלת לשפות רבות עם משאבים גבוהים, אבל לא רמת המסמכים (DL) MT, שזה קשה 1) הרכבת עם כמות קטנה של נתונים DL; 2) להעריך, כאשר השיטות והקבוצות המידע המרכזיות מתמקדות בהערכה SL. כדי להתמודד עם הנושא הראשון, אנחנו מציגים קופוס שיחה יפנית-אנגלית מסוים, כולל מידע שיחה עסקית מאוזן, באיכות גבוהה לתרגיל ובדיקות. בנוגע לנושא השני, אנו מזהה באופן ידני את האזורים הראשיים שבו SL MT לא יוצר תרגומות מתאימות בחסר הקשר. ואז נוצר קבוצת עריכה שבה התופעות האלה מצוינות כדי להקל על עריכה אוטומטית של מערכות DL. We train MT models using our corpus to demonstrate how using context leads to improvements.'}
{'en': 'Findings of the WMT 2020 Shared Task on Automatic Post-Editing', 'ar': 'نتائج مهمة WMT 2020 المشتركة حول التحرير التلقائي اللاحق', 'fr': 'Résultats de la tâche partagée WMT 2020 sur la post-édition automatique', 'es': 'Hallazgos de la tarea compartida del WMT 2020 sobre la postedición automática', 'pt': 'Descobertas da tarefa compartilhada do WMT 2020 na pós-edição automática', 'ja': '自動ポスト編集に関するWMT 2020共有タスクの調査結果', 'zh': 'WMT 2020 自译后编辑共之', 'hi': 'WMT 2020 के निष्कर्ष स्वचालित पोस्ट-संपादन पर साझा कार्य', 'ru': 'Результаты совместной задачи WMT 2020 по автоматическому постредагированию', 'ga': 'Torthaí Thasc Comhroinnte WMT 2020 ar Iar-Eagarthóireacht Uathoibríoch', 'el': 'Ευρήματα της κοινής εργασίας για την αυτόματη μετα-επεξεργασία του WMT 2020', 'hu': 'A WMT 2020 közös feladatának megállapításai az automatikus utószerkesztéssel kapcsolatban', 'it': "Risultati dell'attività condivisa WMT 2020 sulla post-modifica automatica", 'ka': 'WMT 2020 სხვადასხვა დავალების მონახვა ავტომატური პოსტი რედაქტირებაზე', 'kk': 'WMT 2020 автоматты түрде өңдеу үшін ортақтастырылған тапсырманың іздеу', 'lt': 'Bendros WMT 2020 užduoties dėl automatinio pakartotinio redagavimo išvados', 'mk': 'Најдовме заедничка задача на WMT 2020 за автоматско постуредување', 'ms': 'Carian Tugas Berkongsi WMT 2020 pada Penyunting-Automatik', 'ml': 'സ്വയം എഡിറ്ററിങ്ങില്\u200d വ്യുഎംടി 2020 പങ്കെടുത്ത ജോലിയുടെ കണ്ടുപിടിക്കുന്നു', 'mt': 'Sejbiet tal-Kompitu Konġunt tad-WMT 2020 dwar l-Edizzjoni Awtomatika wara l-Edizzjoni', 'mn': 'WMT 2020-ийн хуваалтын ажил автоматик Пошт-Editing дээр', 'no': 'Finn av delt oppgåve WMT 2020 på automatisk postredigering', 'pl': 'Wyniki wspólnego zadania WMT 2020 dotyczącego automatycznej edycji post-edycji', 'ro': 'Concluziile misiunii partajate WMT 2020 privind editarea automată', 'sr': 'Pronaðenja zajedničkog zadatka WMT 2020 o automatskom posledištu editiranja', 'si': 'WMT 2020යි ස්වයංක්\u200dරිය පොස්ට් සංපාදනයේ සමාගත වැඩක් හොයාගන්න', 'so': 'Findings of the WMT 2020 Shared Task on Automatic Post-Editing', 'sv': 'Resultat av WMT 2020:s gemensamma uppgift om automatisk efterredigering', 'ta': 'WMT 2020 பகிர்ந்த பணியின் தானியங்கி திருத்தும் பின் தொகுப்பில் WMT 2020 க்கு தேடுதல்', 'ur': 'WMT 2020 Shared Task on Automatic Post-Editing', 'uz': 'Comment', 'vi': 'Tìm thấy Nhiệm vụ chung của WRT 2020 về việc sửa đổi tự động', 'da': 'Resultater af WMT 2020 delte opgave om automatisk efterredigering', 'de': 'Ergebnisse der WMT 2020 Shared Task zur automatischen Nachbearbeitung', 'bg': 'Констатации на споделената задача за автоматичното следредактиране на ММТ 2020', 'hr': 'Pronaći zajednički zadatak WMT 2020 o automatskom posledištu redakcije', 'nl': 'Resultaten van de WMT 2020 Shared Task over automatische nabewerking', 'id': 'Penemuan dari Tugas Berkongsi WMT 2020 pada Post-Editing Otomatis', 'fa': 'پیدا کردن کار مشترک WMT ۲۰۰۲ در مورد ویرایش بعد از ویرایش خودکار', 'sw': 'Matokeo ya kazi ya kushirikiana na WMT 2020 kwenye Uhariri Huduma', 'tr': "WMT 2020'iň Otomatik Poz Editlemesi üzerinde Paýlaşan Göreviniň ahyrlyklary", 'af': 'Finnings van die WMT 2020 Gedeelde Opdrag op Outomatiese Post-Redigering', 'am': 'የአሁኑን ፋይል አስቀምጥ', 'ko': 'WMT 2020 자동 사후 편집 공유 작업 검색', 'az': 'WMT 2020 Otomatik Post-Editing iŇül…ôri', 'sq': 'Zbulimet e detyrës së përbashkët të WMT 2020 mbi posteditimin automatik', 'bn': 'Findings of the WMT 2020 Shared Task on Automatic Post-Editing', 'ca': 'Results of the WMT 2020 Shared Task on Automatic Post-Editing', 'et': 'WMT 2020 ühise ülesande tulemused automaatse järelredigeerimise kohta', 'bs': 'Pronaći zajednički zadatak WMT 2020 o automatskom posledištu editiranja', 'cs': 'Zjištění sdíleného úkolu WMT 2020 na automatické posteditování', 'fi': 'WMT 2020:n automaattista jälkimuokkausta koskevan yhteisen tehtävän havainnot', 'hy': 'Աշխարհային Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միացյալ Միաց', 'he': 'Findings of the WMT 2020 Shared Task on Automatic Post-Editing', 'ha': '@ action', 'sk': 'Ugotovitve skupne naloge WMT 2020 o samodejnem naknadnem urejanju', 'bo': 'རྗེས་ཀྱིས་རང་འགུལ་གྱིས་ཞུན་དག་པ་དང་མཉམ་སྤྱོད་པའི་WMT 2020་ཡི་ལས་ཀ་འདི་རྙེད་ཐོག་ཏེ།', 'jv': 'Finding'}
{'en': 'We present the results of the 6th round of the WMT task on MT Automatic Post-Editing. The task consists in automatically correcting the output of a black-box machine translation system by learning from existing human corrections of different sentences. This year, the challenge consisted of fixing the errors present in English Wikipedia pages translated into German and Chinese by state-ofthe-art, not domain-adapted neural MT (NMT) systems unknown to participants. Six teams participated in the English-German task, submitting a total of 11 runs. Two teams participated in the English-Chinese task submitting 2 runs each. Due to i) the different source / domain of data compared to the past (Wikipedia vs Information Technology), ii) the different quality of the initial translations to be corrected and iii) the introduction of a new language pair (English-Chinese), this year’s results are not directly comparable with last year’s round. However, on both language directions, participants’ submissions show considerable improvements over the baseline results. On English-German, the top ranked system improves over the baseline by -11.35 TER and +16.68 BLEU points, while on EnglishChinese the improvements are respectively up to -12.13 TER and +14.57 BLEU points. Overall, coherent gains are also highlighted by the outcomes of human evaluation, which confirms the effectiveness of APE to improve MT quality, especially in the new generic domain selected for this year’s round.', 'ar': 'نقدم نتائج الجولة السادسة من مهمة WMT في التحرير التلقائي اللاحق لـ MT. تتمثل المهمة في التصحيح التلقائي لمخرجات نظام الترجمة الآلية "الصندوق الأسود" من خلال التعلم من التصحيحات البشرية الحالية لجمل مختلفة. اشتمل التحدي هذا العام على إصلاح الأخطاء الموجودة في صفحات ويكيبيديا الإنجليزية المترجمة إلى الألمانية والصينية من خلال أحدث أنظمة MT العصبية (NMT) غير المتكيفة مع المجال والتي لا يعرفها المشاركون. شاركت ستة فرق في المهمة الإنجليزية الألمانية ، وقدمت ما مجموعه 11 جولة. شارك فريقان في المهمة الإنجليزية - الصينية حيث قدم كل منهما جولتين. بسبب 1) المصدر / المجال المختلف للبيانات مقارنة بالماضي (ويكيبيديا مقابل تكنولوجيا المعلومات) ، 2) الجودة المختلفة للترجمات الأولية المطلوب تصحيحها و 3) إدخال زوج لغوي جديد (الإنجليزية-الصينية) ، لا يمكن مقارنة نتائج هذا العام بشكل مباشر مع نتائج جولة العام الماضي. ومع ذلك ، في كلا الاتجاهين اللغويين ، تُظهر تقديمات المشاركين تحسينات كبيرة على نتائج خط الأساس. في اللغة الإنجليزية-الألمانية ، يتحسن النظام المصنف الأعلى على خط الأساس بمقدار -11.35 TER و +16.68 BLEU ، بينما في اللغة الإنجليزية الصينية ، تصل التحسينات إلى -12.13 TER و +14.57 BLEU على التوالي. بشكل عام ، يتم إبراز المكاسب المتماسكة أيضًا من خلال نتائج التقييم البشري ، مما يؤكد فعالية APE في تحسين جودة الترجمة الآلية ، لا سيما في المجال العام الجديد الذي تم اختياره لجولة هذا العام.', 'fr': "Nous présentons les résultats de la 6ème étape de la tâche WMT sur la post-édition automatique MT. La tâche consiste à corriger automatiquement la sortie d'un système de traduction automatique «\xa0boîte noire\xa0» en apprenant des corrections humaines existantes de différentes phrases. Cette année, le défi consistait à corriger les erreurs présentes dans les pages Wikipédia en anglais traduites en allemand et en chinois par des systèmes de TA neuronale (NMT) ultramodernes et non adaptés au domaine, inconnus des participants. Six équipes ont participé à l'épreuve anglais-allemand, soumettant un total de 11 points. Deux équipes ont participé à la tâche anglais-chinois en soumettant 2 points chacune. En raison i) de la différence de source/domaine de données par rapport au passé (Wikipédia vs informatique), ii) de la qualité différente des traductions initiales à corriger et iii) de l'introduction d'une nouvelle paire de langues (anglais-chinois), les résultats de cette année ne sont pas directement comparables à ceux de l'année dernière . Toutefois, dans les deux directions linguistiques, les soumissions des participants montrent des améliorations considérables par rapport aux résultats de base. En anglais-allemand, le système le mieux classé s'améliore par rapport à la base de -11,35 points TER et +16,68 points BLEU, tandis qu'en anglais-chinois, les améliorations sont respectivement de -12,13 TER et +14,57 points BLEU. Dans l'ensemble, les gains cohérents sont également mis en évidence par les résultats de l'évaluation humaine, qui confirme l'efficacité de l'APE pour améliorer la qualité de la MT, en particulier dans le nouveau domaine générique sélectionné pour cette année.", 'es': 'Presentamos los resultados de la sexta ronda de la tarea WMT sobre Postedición Automática de MT. La tarea consiste en corregir automáticamente el resultado de un sistema de traducción automática «caja negra» mediante el aprendizaje de las correcciones humanas existentes de diferentes oraciones. Este año, el desafío consistió en corregir los errores presentes en las páginas de Wikipedia en inglés traducidas al alemán y al chino por sistemas de MT neuronales (NMT) de última generación, no adaptados al dominio, desconocidos para los participantes. Seis equipos participaron en la tarea inglés-alemán, presentando un total de 11 carreras. Dos equipos participaron en la tarea inglés-chino presentando 2 carreras cada uno. Debido a i) la diferente fuente/dominio de los datos en comparación con el pasado (Wikipedia frente a tecnología de la información), ii) la diferente calidad de las traducciones iniciales que deben corregirse y iii) la introducción de un nuevo par de idiomas (inglés-chino), los resultados de este año no son directamente comparables con los del año pasado . Sin embargo, en ambas direcciones lingüísticas, las presentaciones de los participantes muestran mejoras considerables con respecto a los resultados de referencia. En inglés y alemán, el sistema mejor clasificado mejora con respecto a la línea de base en -11,35 puntos TER y +16,68 puntos BLEU, mientras que en inglés/chino las mejoras son, respectivamente, de hasta -12,13 puntos TER y +14,57 puntos BLEU. En general, los resultados de la evaluación humana también destacan los avances coherentes, lo que confirma la eficacia de APE para mejorar la calidad de la MT, especialmente en el nuevo dominio genérico seleccionado para la ronda de este año.', 'pt': 'Apresentamos os resultados da 6ª rodada da tarefa WMT em MT Automatic Post-Editing. A tarefa consiste em corrigir automaticamente a saída de um sistema de tradução automática “caixa preta” aprendendo com as correções humanas existentes de diferentes frases. Este ano, o desafio consistiu em corrigir os erros presentes nas páginas da Wikipedia em inglês traduzidas para o alemão e o chinês por sistemas de MT neural (NMT) de última geração, não adaptados ao domínio, desconhecidos dos participantes. Seis equipes participaram da prova inglês-alemã, apresentando um total de 11 corridas. Duas equipes participaram da tarefa inglês-chinesa apresentando 2 corridas cada. Devido i) à diferente fonte/domínio de dados em relação ao passado (Wikipedia vs Tecnologia da Informação), ii) à qualidade diferente das traduções iniciais a serem corrigidas e iii) à introdução de um novo par de idiomas (inglês-chinês), os resultados deste ano não são diretamente comparáveis com a rodada do ano passado. No entanto, em ambas as direções linguísticas, os envios dos participantes mostram melhorias consideráveis em relação aos resultados da linha de base. No inglês-alemão, o sistema de classificação superior melhora em relação à linha de base em -11,35 TER e +16,68 pontos BLEU, enquanto no inglês chinês as melhorias são, respectivamente, até -12,13 TER e +14,57 pontos BLEU. No geral, os ganhos coerentes também são destacados pelos resultados da avaliação humana, que confirma a eficácia do APE para melhorar a qualidade do MT, especialmente no novo domínio genérico selecionado para a rodada deste ano.', 'ja': 'MT自動ポストエディットに関するWMTタスクの第6ラウンドの結果を提示します。 タスクは、異なる文章の既存の人間による修正から学習することによって、「ブラックボックス」機械翻訳システムの出力を自動的に修正することです。 今年の課題は、参加者に知られていないドメイン適応型ニューラルMT （ NMT ）システムではなく、最新の技術によってドイツ語と中国語に翻訳された英語のウィキペディアページに存在するエラーを修正することでした。 イングランド・ドイツのタスクフォースには6チームが参加し、合計11回の出走を提出した。 英中2チームが参加し、それぞれ2走を提出した。 I ）過去と比較したデータのソース/ドメインの違い（ウィキペディアvs情報技術）、ii ）修正される初期翻訳の品質の違い、およびiii ）新しい言語ペア（英語-中国語）の導入のため、今年の結果は昨年のラウンドと直接比較できません。 しかし、両方の言語の方向性において、参加者の提出物は、ベースラインの結果よりもかなり改善されていることを示している。 英語とドイツ語では、トップランクのシステムはベースラインよりも-11.35 TERと+16.68 BLEUポイント向上し、英語と中国語ではそれぞれ-12.13 TERと+14.57 BLEUポイント向上します。 全体的に、一貫性のある利得は、特に今年のラウンドのために選択された新しいジェネリックドメインで、MT品質を改善するためのAPEの有効性を確認する人間評価の結果によっても強調されています。', 'zh': '吾言 MT 自译后辑第 6 轮 WMT 事也。 凡学异句者,见人工更正以自正黑匣子机器翻译系统者输之。 今年挑战修复英语维基百科页面之误,页面由先进,非参与者未知应领之神经机器翻译(NMT)系统翻译成德语中文也。 六军预英语-德语务,共交11次走。 二团队参英语 - 中文,每团队2次行。 i)比往时,数/异域(维基百科信息技术),ii)须更正译质不同,iii)引入新语对(英汉),今年与去年无径可比性。 然二语文之上,参与者材皆比基线大改。 英语 - 德语者,上统增于基线-11.35 TER与+16.68 BLEU分,而于英语中文,改进分至-12.13 TER+14.57 BLEU分。 总体而言人工评估,亦凸显一同之益,此证APE增机器翻译之有效性,特为今年新通领域也。', 'hi': 'हम MT स्वचालित पोस्ट-संपादन पर WMT कार्य के 6 वें दौर के परिणाम प्रस्तुत करते हैं। कार्य में विभिन्न वाक्यों के मौजूदा मानव सुधारों से सीखकर स्वचालित रूप से "ब्लैक-बॉक्स" मशीन अनुवाद प्रणाली के आउटपुट को सही करना शामिल है। इस वर्ष, चुनौती में अंग्रेजी विकिपीडिया पृष्ठों में मौजूद त्रुटियों को ठीक करना शामिल था, जो जर्मन और चीनी में स्टेट-ऑफ-द-आर्ट द्वारा अनुवादित थे, न कि डोमेन-अनुकूलित तंत्रिका एमटी (एनएमटी) सिस्टम प्रतिभागियों के लिए अज्ञात। छह टीमों ने अंग्रेजी-जर्मन कार्य में भाग लिया, कुल 11 रन प्रस्तुत किए। दो टीमों ने अंग्रेजी-चीनी कार्य में भाग लिया, जिसमें प्रत्येक ने 2 रन प्रस्तुत किए। i) अतीत (विकिपीडिया बनाम सूचना प्रौद्योगिकी) की तुलना में डेटा के विभिन्न स्रोत / डोमेन के कारण, ii) सही किए जाने वाले प्रारंभिक अनुवादों की विभिन्न गुणवत्ता और iii) एक नई भाषा जोड़ी (अंग्रेजी-चीनी) की शुरुआत, इस वर्ष के परिणाम सीधे पिछले साल के दौर के साथ तुलनीय नहीं हैं। हालांकि, दोनों भाषा निर्देशों पर, प्रतिभागियों की प्रस्तुतियां बेसलाइन परिणामों पर काफी सुधार दिखाती हैं। अंग्रेजी-जर्मन पर, शीर्ष रैंक वाली प्रणाली -11.35 TER और +16.68 BLEU अंकों से बेसलाइन पर सुधार करती है, जबकि इंग्लिशचीनी पर सुधार क्रमशः -12.13 TER और +14.57 BLEU अंक तक हैं। कुल मिलाकर, सुसंगत लाभ भी मानव मूल्यांकन के परिणामों से हाइलाइट किए जाते हैं, जो एमटी गुणवत्ता में सुधार के लिए एपीई की प्रभावशीलता की पुष्टि करता है, विशेष रूप से इस वर्ष के दौर के लिए चुने गए नए जेनेरिक डोमेन में।', 'ru': 'Представляем результаты 6 раунда задачи WMT на MT Automatic Post-Editing. Задача заключается в автоматической коррекции вывода системы машинного перевода «черного ящика» путем изучения существующих человеческих коррекций различных предложений. В этом году вызов заключался в исправлении ошибок, присутствующих на страницах английской Википедии, переведенных на немецкий и китайский языки с помощью неадаптированных к домену нейронных систем MT (NMT), неизвестных участникам. Шесть команд приняли участие в англо-немецкой задаче, представив в общей сложности 11 заездов. В английско-китайском задании участвовали две команды, представившие по 2 прохода. Из-за i) различий в источнике/домене данных по сравнению с прошлым (Википедия против информационных технологий), ii) различий в качестве первоначальных переводов, которые необходимо исправить, и iii) введения новой языковой пары (английский-китайский) результаты этого года не сопоставимы напрямую с результатами прошлогоднего цикла. Однако по обоим языковым направлениям представленные участниками материалы свидетельствуют о значительном улучшении по сравнению с исходными результатами. На англо-немецкой системе верхний рейтинг улучшается по сравнению с базовой на -11,35 ТЕР и +16,68 BLEU баллов, в то время как на английско-китайской улучшается соответственно до -12,13 ТЕР и +14,57 BLEU баллов. В целом, согласованные достижения также подчеркиваются результатами человеческой оценки, которые подтверждают эффективность APE для улучшения качества MT, особенно в новой общей области, выбранной для раунда этого года.', 'ga': 'Cuirimid i láthair torthaí an 6ú babhta de thasc WMT ar Iar-Eagarthóireacht Uathoibríoch MT. Is éard atá sa tasc ná an t-aschur ó chóras aistriúcháin meaisín “bosca dubh” a cheartú go huathoibríoch trí fhoghlaim ó cheartúcháin dhaonna atá ann cheana ar abairtí éagsúla. I mbliana, ba é an dúshlán ná na hearráidí a shocrú i leathanaigh Vicipéid Bhéarla a aistríodh go Gearmáinis agus go Sínis ag córais néarúla MT (NMT) úrscothacha nach bhfuil oiriúnaithe ag an bhfearann ar eolas ag na rannpháirtithe. Ghlac sé fhoireann páirt sa tasc Béarla-Gearmáinis, ag cur isteach iomlán de 11 rith. Ghlac dhá fhoireann páirt sa tasc Béarla-Síneach agus chuir siad isteach 2 rith an ceann. Mar gheall ar i) an fhoinse/fhearann difriúil sonraí i gcomparáid leis an am atá caite (Vicipéid vs Teicneolaíocht Faisnéise), ii) cáilíocht éagsúil na n-aistriúchán tosaigh atá le ceartú agus iii) tabhairt isteach péire teanga nua (Béarla-Sínis), níl torthaí na bliana seo inchomparáide go díreach le torthaí na bliana seo caite. Ar an dá threo teanga, áfach, léiríonn aighneachtaí na rannpháirtithe feabhas suntasach ar na torthaí bonnlíne. Maidir le Béarla-Gearmáinis, feabhsaítear an córas barrrangaithe thar an mbunlíne faoi -11.35 TER agus +16.68 pointe BLEU, agus ar an mBéarla-Síneach tá na feabhsuithe suas go dtí -12.13 TER agus +14.57 pointe BLEU faoi seach. Ar an iomlán, leagtar béim freisin ar ghnóthachain chomhleanúnacha ag torthaí na meastóireachta daonna, a dhearbhaíonn éifeachtacht APE chun cáilíocht MT a fheabhsú, go háirithe san fhearann cineálach nua a roghnaíodh do bhabhta na bliana seo.', 'hu': 'Bemutatjuk a WMT feladat 6. fordulójának eredményeit az MT automatikus utószerkesztéssel kapcsolatban. A feladat egy "fekete doboz" gépi fordító rendszer kimenetének automatikus javítása a különböző mondatok meglévő emberi javításaiból. Az idei kihívás az volt, hogy a résztvevők számára ismeretlen, korszerű, nem domain-adaptált neurális MT (NMT) rendszerekkel javítsák az angol Wikipédia oldalain jelen lévő hibákat. Hat csapat vett részt az angol-német feladatban, összesen 11 futást nyújtottak be. Két csapat vett részt az angol-kínai feladatban, melyek mindegyike 2 futást küldtek be. Mivel i) a múlthoz képest eltérő adatforrás/tartomány (Wikipédia vs Információs Technológia), ii) a javítandó kezdeti fordítások eltérő minősége és iii) egy új nyelvpár (angol-kínai) bevezetése miatt az idei eredmények nem hasonlíthatók közvetlenül a tavalyi fordulóhoz. Mindkét nyelvi irányban azonban a résztvevők beadványai jelentős javulást mutatnak az alapvető eredményekhez képest. Az angol-német esetben a legmagasabb rangú rendszer -11,35 TER és +16,68 BLEU ponttal javul a kiinduláshoz képest, az angol kínai esetben pedig -12,13 TER, illetve +14,57 BLEU ponttal. Összességében az emberi értékelés eredményei is kiemelik a koherens eredményeket, amelyek megerősítik az APE hatékonyságát a MT minőségének javítására, különösen az idei fordulóra kiválasztott új generikus területen.', 'el': 'Παρουσιάζουμε τα αποτελέσματα του 6ου γύρου της εργασίας για την αυτόματη μετα-επεξεργασία ΜΤ. Το έργο συνίσταται στην αυτόματη διόρθωση της εξόδου ενός συστήματος μηχανικής μετάφρασης "μαύρου κουτιού" μαθαίνοντας από υπάρχουσες ανθρώπινες διορθώσεις διαφορετικών προτάσεων. Φέτος, η πρόκληση συνίστατο στην επιδιόρθωση των σφαλμάτων που υπάρχουν στις σελίδες της Αγγλικής Βικιπαίδειας που μεταφράστηκαν στα γερμανικά και τα κινέζικα με σύγχρονα συστήματα νευρωνικού ΜΤ (NMT) που δεν είναι γνωστά στους συμμετέχοντες. Έξι ομάδες συμμετείχαν στην αγγλο-γερμανική εργασία, υποβάλλοντας συνολικά 11 γύρους. Δύο ομάδες συμμετείχαν στην αγγλο-κινεζική εργασία υποβάλλοντας δύο εκτελέσεις η καθεμία. Λόγω της διαφορετικής πηγής/τομέα δεδομένων σε σύγκριση με το παρελθόν (Βικιπαίδεια vs. Τεχνολογία Πληροφοριών), της διαφορετικής ποιότητας των αρχικών μεταφράσεων που πρέπει να διορθωθούν και της εισαγωγής ενός νέου γλωσσικού ζεύγους (Αγγλικά-Κινέζικα), τα αποτελέσματα της φετινής χρονιάς δεν είναι άμεσα συγκρίσιμα με τα πέρυσι. Ωστόσο, και στις δύο γλωσσικές κατευθύνσεις, οι παρατηρήσεις των συμμετεχόντων παρουσιάζουν σημαντικές βελτιώσεις σε σχέση με τα βασικά αποτελέσματα. Στα Αγγλικά-Γερμανικά, το κορυφαίο σύστημα βελτιώνεται έναντι της βάσης κατά τους -11.35 και +16.68 ενώ στα Αγγλικά οι βελτιώσεις είναι αντίστοιχα μέχρι -12.13 TER και +14.57 BLEU. Συνολικά, τα συνεπή κέρδη επισημαίνονται επίσης από τα αποτελέσματα της ανθρώπινης αξιολόγησης, η οποία επιβεβαιώνει την αποτελεσματικότητα του APE για τη βελτίωση της ποιότητας των ΜΤ, ιδίως στον νέο τομέα γενόσημων που επιλέχθηκε για τη φετινή χρονιά.', 'ka': "ჩვენ გავაჩვენეთ WMT დავალების 6-ი პროგრამის შედეგი MT ავტომატური პროგრამის რედაქტირებაში. დავალება ავტომატურად განსხვავებული სიტყვების 'შავ- ბოსტი' მაქინის განსხვავებული სისტემის გამოყენების შემდეგ შექმნა. ამ წლის შეცდომის შეცდომის შეცდომების განსაზღვრება ინგლისური Wikipedia გვერდებში გერმანეთში და ჩინეთში გადაწყენებული წარმოქმების გარეშე, არა დომინური განსაზღვრებული ნეიროლური MT (NMT) სისტემებით შვიდი ჯგუფი ინგლისური-გერმანური დავალებაში დაწყვეტილი, 11 წერტილის სამყარო წერტილი. ორი ჯგუფი ინგლისური-ჩინეთის დავალებაში გადაწყვეტი, რომელიც ორი გადაწყვეტი. i) მონაცემების განსხვავებული მხოლოდ/დიომენტის შეცდომა წინა (ვიკიპედია vs ინფორმაციის ტექნოლოგია), ii) განსხვავებული განსხვავებული წინასწორეების განსხვავება და iii) ახალი ენის ზოგების შეცდომა (ანგლისური-კინელი), ამ წლის მაგრამ, ორივე ენის დაწყებაში, მოთავსწავლებელების დაწყებაში მნიშვნელოვანი გაუკეთებების შესახებ. ანგლისური-გერმანური სისტემაში უფრო დიდი სისტემა უფრო მეტადება -11,35 TER და +16,68 BLEU წერტილებით, მაგრამ ანგლისური შინაში უფრო მეტადება -12,13 TER და +14,57 BLEU წერტილებით. ყველაფერად, შესაძლებელი წარმოდგენების შესაძლებლობაც ადამიანის განსაზღვრებისთვის გამოყენებულია, რომელიც APE-ის ეფექტიურობას დააწყებენ MT-ის გაუფლება, განსაკუთრებით ახალი საერთო დიომი", 'it': 'Presentiamo i risultati del 6° round del compito WMT su MT Automatic Post-Editing. Il compito consiste nel correggere automaticamente l\'output di un sistema di traduzione automatica "black-box" imparando dalle correzioni umane esistenti di frasi diverse. Quest\'anno, la sfida consisteva nel correggere gli errori presenti nelle pagine Wikipedia in inglese tradotte in tedesco e cinese da sistemi MT neurali all\'avanguardia, non adattati al dominio, sconosciuti ai partecipanti. Sei squadre hanno partecipato al compito inglese-tedesco, presentando un totale di 11 gare. Due squadre hanno partecipato al compito inglese-cinese presentando 2 corse ciascuna. A causa di i) la diversa fonte/dominio dei dati rispetto al passato (Wikipedia vs Information Technology), ii) la diversa qualità delle traduzioni iniziali da correggere e iii) l\'introduzione di una nuova coppia linguistica (inglese-cinese), i risultati di quest\'anno non sono direttamente comparabili con il round dello scorso anno. Tuttavia, in entrambe le direzioni linguistiche, i contributi dei partecipanti mostrano notevoli miglioramenti rispetto ai risultati di base. Sull\'inglese-tedesco, il sistema top ranked migliora rispetto al basale di -11,35 TER e +16,68 BLEU punti, mentre sull\'inglese cinese i miglioramenti sono rispettivamente fino a -12,13 TER e +14,57 BLEU punti. Nel complesso, i progressi coerenti sono evidenziati anche dai risultati della valutazione umana, che conferma l\'efficacia dell\'APE per migliorare la qualità della MT, soprattutto nel nuovo dominio generico selezionato per il round di quest\'anno.', 'lt': "Mes pristatome 6-ojo WMT užduoties MT automatinio po redagavimo rezultatus. The task consists in automatically correcting the output of a 'black-box' machine translation system by learning from existing human corrections of different sentences.  Šiais metais iššūkis buvo susijęs su klaidų, esančių anglų Vikipedijos puslapiuose, ištaisymu, kurie buvo išversti į vokiečių ir kinų kalbas pagal naujausias, nepritaikytas prie domeno nepriklausančias neurologines MT (NMT) sistemas, nežinomas dalyviams. Šešios komandos dalyvavo Anglijos ir Vokietijos užduotyje ir iš viso pateikė 11 runs. Two teams participated in the English-Chinese task submitting 2 runs each.  Dėl i) skirtingo duomenų šaltinio ir (arba) srities, palyginti su praeitimi (Wikipedia vs. Information Technology), ii) skirtingos pradinių vertimų, kurie turi būti pataisyti, kokybės ir iii) naujos kalbos poros (anglų ir kinų), ši ų metų rezultatai nėra tiesiogiai palyginami su praėjusiais metais. Tačiau abiejų kalbų krypčių požiūriu dalyvių pastabos rodo, kad pagrindiniai rezultatai gerokai pagerėjo. Anglų ir vokiečių kalbomis aukščiausio lygio sistema, palyginti su pradiniu lygiu, pagerėja -11,35 TER ir +16,68 BLEU taškų, o anglų ir Kinijos atveju pagerėjimai atitinkamai siekia -12,13 TER ir +14,57 BLEU taškų. Apskritai nuoseklią naudą taip pat pabrėžia žmogaus vertinimo rezultatai, kurie patvirtina APE veiksmingumą gerinant MT kokybę, ypač naujoje bendrojoje srityje, atrinktoje šiems metams.", 'mk': 'Ги претставуваме резултатите од 6-тиот круг на WMT задачата на MT Автоматско пост-уредување. Оваа задача се состои од автоматско корекција на излезот на машинскиот преведувачки систем „црна кутија“ со учење од постојните човечки корекции на различни реченици. Оваа година предизвикот се состои од поправање на грешките на англиските страници на Википедија преведени на германски и кинески од најсовремените, не адаптирани на домен неурални мет (НМТ) системи непознати за учесниците. Шест тимови учествуваа во англиско-германската задача, пренесувајќи вкупно 11 трки. Двајца тима учествуваа во англиско-кинеската задача која испраќа две работи секој. Поради i) различен извор/домен на податоци во споредба со минатото (Википедија против информатичка технологија), ii) различен квалитет на првичните преводи кои треба да се коригираат и iii) воведувањето на нов пар јазици (англиско-кинески), резултатите од оваа година не се директно споредливи со минатогодишниот круг. Сепак, во однос на двете јазички насоки, поднесувањата на учесниците покажуваат значителни подобрувања во однос на основните резултати. На англиско-германски, најрангираниот систем се подобрува во однос на основата за -11,35 ТЕР и +16,68 БЛЕ поени, додека на англиско-кинески подобрувањата достигнуваат -12,13 ТЕР и +14,57 БЛЕ поени. Вкупно, коеорентните добивки се истакнати и од резултатите на човечката проценка, која ја потврдува ефикасноста на АПЕ за подобрување на квалитетот на МТ, особено во новиот генерален домен избран за овогодинешниот круг.', 'kk': "Біз WMT тапсырманың 6- ші rundu MT автоматты түрде өңдеу үшін тапсырманың нәтижесін келтіреміз. Тапсырма басқа сөздерді түзету арқылы 'қара жазу' компьютерінің шығысын автоматты түрде түзету жүйесінде болады. Бұл жыл, ағылшынша Википедия парақтарында неміс мен қытайшаға аударылған қателерді түзету мәселесі болды. Қатысушыларға беймәлім емес, доменге адаптацияланған невралдық MT (NMT) жүйелері. Алты топ ағылшын- неміс тапсырмасына қатысу үшін 11 орынды жібереді. Екі топ ағылшын- қытайлық тапсырмасына 2 жұмыс істейді. i) өткен (Википедия және мәлімет технологиясы), ii) бастапқы аудармалардың әртүрлі сапасы мен iii) жаңа тіл екісін (ағылшын- қытайлық) кітапшасының (ағылшын- қытайлық) кітапшасының нәтижесі сәйкес келмейді. Бірақ қатысушылардың екі тіл бағыттарында негізгі жолдың нәтижелерінен көп жақсартуларын көрсетеді. Ағылшын- неміс тілінде жоғары жолдар жүйесі негізгі жолда - 11, 35 МЕР және +16, 68 БЛЕС нүктелерімен жақсы жасайды, бірақ ағылшын тілінде жақсы жасау - 12, 13 МЕР және +14, 57 БЛЕС нүктелері болады. Жалпы, адамдардың оқиғаларының нәтижелері қолданылады. Бұл APE-нің MT сапасын жақсарту үшін, осылай-ақ осы жылдың жаңа жалпы доменде таңдалған жалпы жалпы доменге дейін қолданылады.", 'ms': "Kami memperkenalkan hasil pusingan ke-6 tugas WMT pada MT Automatic Post-Editing. Tugas ini terdiri dalam membetulkan output sistem terjemahan mesin 'kotak hitam' secara automatik dengan belajar dari pembetulan manusia yang wujud bagi kalimat yang berbeza. Tahun ini, cabaran terdiri daripada memperbaiki ralat yang ada dalam halaman Wikipedia Inggeris terjemahan ke Jerman dan Cina oleh sistem MT saraf yang tidak disesuaikan dengan domain (NMT) yang tidak diketahui oleh peserta. Enam pasukan berpartisipasi dalam tugas Inggeris-Jerman, menghantar total 11 jalanan. Dua pasukan berpartisipasi dalam tugas Inggeris-Cina menghantar 2 berjalan masing-masing. Due to i) the different source/domain of data compared to the past (Wikipedia vs Information Technology), ii) the different quality of the initial translations to be corrected and iii) the introduction of a new language pair (English-Chinese), this year's results are not directly comparable with last year's round.  Namun, pada kedua-dua arah bahasa, penghantaran peserta menunjukkan peningkatan yang besar atas hasil asas. Dalam bahasa Inggeris-Jerman, sistem tertinggi tertinggi meningkat atas dasar dasar dengan -11.35 TER dan +16.68 titik BLEU, sementara pada bahasa Inggeris peningkatan tersebut sehingga -12.13 TER dan +14.57 titik BLEU. Secara keseluruhan, keuntungan konsisten juga ditandai oleh hasil penilaian manusia, yang mengesahkan kegunaan APE untuk meningkatkan kualiti MT, terutama dalam domain generik baru yang dipilih untuk bulatan tahun ini.", 'ml': "എംടി സ്വയം എഡിറ്ററിങ്ങില്\u200d WMT ജോലിയുടെ ആറാം റൌണ്ടിന്റെ ഫലങ്ങള്\u200d ഞങ്ങള്\u200d കാണിക്കുന്നു. വ്യത്യസ്തമായ വാക്കുകളില്\u200d നിന്നും നിലവിലുള്ള മനുഷ്യരുടെ പരിശോധനങ്ങളില്\u200d നിന്നും പഠിക്കുന്നതിനാല്\u200d 'കറുത്ത- ബോക്സ് ഈ വര്\u200dഷം, ഇംഗ്ലീഷ് വിക്കിപിഡിയയിലെ തെറ്റുകള്\u200d പരിഹരിക്കുന്നതിനായി വ്യാല്\u200dക്കിപ്പീഡിയയില്\u200d ഉണ്ടായിരുന്നു. രാഷ്ട്രീയ-ഫാര്\u200dട്ടില്\u200d പരിഭാഷപ്പെട ആറു ടീം ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d ജോലിയില്\u200d പങ്കുചേര്\u200dന്നു, ഒരു മൊത്തം 11 റോണ്\u200d കൊടുക്കുന്നു. രണ്ടു ടീം ഓരോരുത്തരും ഓടിക്കൊണ്ട് ഇംഗ്ലീഷ്-ചൈനീസ് ജോലിയില്\u200d പങ്കുചേര്\u200dന്നു. ആദ്യത്തെ പരിഭാഷകള്\u200d ശരിയാക്കാനുള്ള ആദ്യത്തെ പരിഭാഷകളുടെ വ്യത്യസ്തമായ സ്രോതസ്സ്/ഡോമെന്\u200d (വിക്കിപിഡിയ vs വിവരങ്ങള്\u200d ടെക്നോളജി), i i) ഒരു പുതിയ ഭാഷ ജോടിയുടെ (ഇംഗ്ലീഷ്-ചൈനീസ്) ന എങ്കിലും ഭാഷയുടെ രണ്ടു നേര്\u200dവഴിയില്\u200d പങ്കാളികളുടെ സമര്\u200dപ്പണങ്ങള്\u200d ബെസ്റ്റ്ലൈന്\u200d ഫലങ്ങളില്\u200d ഏറ്റവും മെച്ചപ്പെട ഇംഗ്ലീഷ്-ജര്\u200dമ്മനില്\u200d -11. 35 ടെറിയും 16. 68 ബെലിയു പോയിന്\u200dറുകളും മുകളില്\u200d ഉയര്\u200dത്തുന്ന സിസ്റ്റം മുന്\u200dകൂട്ടുന്നു. ഇംഗ്ലീഷ് ചൈനീസില്\u200d മെച്ചപ്പെടുത്തുന്നത്  മൊത്തം, മനുഷ്യരുടെ വിലയ്ക്കുള്ള ഫലങ്ങളുടെ കൂട്ടത്തില്\u200d കൂടുതല്\u200d കാണിച്ചുകൊടുക്കുന്നു. അത് എംടി ഗുണത്തെ മെച്ചപ്പെടുത്തുന്നതിന്റെ പ്രാവ", 'mt': 'Aħna nippreżentaw ir-riżultati tas-sitt sessjoni tal-kompitu WMT dwar MT Automatic Post-Editing. Il-kompitu jikkonsisti fil-korrezzjoni awtomatika tal-output ta’ sistema ta’ traduzzjoni tal-magna “black-box” billi jitgħallem minn korrezzjonijiet umani eżistenti ta’ sentenzi differenti. Din is-sena, l-isfida kienet tikkonsisti fl-iffissar tal-iżbalji preżenti fil-paġni Ingliżi tal-Wikipedia tradotti fil-Ġermaniż u ċ-Ċiniż minn sistemi moderni mhux adattati għad-dominju MT (NMT) mhux magħrufa għall-parteċipanti. Sitt timijiet ipparteċipaw fil-kompitu Ingliż-Ġermaniż, li ppreżentaw total ta’ 11-il runs. Żewġ timijiet ipparteċipaw fil-kompitu Ingliż-Ċiniż li ssottomettew żewġ eżerċizzji kull wieħed. Minħabba i) i s-sors/dominju differenti tad-dejta meta mqabbel mal-passat (Wikipedia vs Information Technology), ii) il-kwalità differenti tat-traduzzjonijiet inizjali li għandhom jiġu kkoreġuti u iii) l-introduzzjoni ta’ par ġdid ta’ lingwi (Ingliż-Ċiniż), ir-riżultati ta’ din is-sena mhumiex direttament komparabbli mar-round tas-sena l-oħra. Madankollu, fuq iż-żewġ direzzjonijiet lingwistiċi, is-sottomissjonijiet tal-parteċipanti juru titjib konsiderevoli fir-riżultati tal-linja bażi. Fuq l-Ingliż-Ġermaniż, is-sistema tal-ogħla klassifikazzjoni titjieb fuq il-linja bażi b’ -11.35 TER u +16.68 punti BLEU, filwaqt li fuq l-Ingliż-Ċiniż it-titjib huwa rispettivament sa -12.13 TER u +14.57 punti BLEU. B’mod ġenerali, il-kisbiet koerenti huma enfasizzati wkoll mir-riżultati tal-evalwazzjoni umana, li tikkonferma l-effettività tal-APE biex tittejjeb il-kwalità tal-MT, speċjalment fid-dominju ġeneriku l-ġdid magħżul għal din is-sena.', 'mn': "Бид WMT ажлын 6-р рууны үр дүнг MT-ийн автоматтын Post-Editing-д гаргаж байна. Энэ үйл ажил нь өөр өгүүлбэрээс суралцаж буй хүн төрөлхтний зөвшөөрүүлэхээс автоматаар хар-хайрцаг' машины орчуулах системийн үр дүнг засах болно. Энэ жил Англи хэлний Wikipedia хуудас дээр Герман болон Хятад улс орнуудын хувьд орчуулагдсан алдаа засах сорилт нь оролцогчдын хувьд алдаа засах байсан. Дөрвөн баг Англи-Германы ажил дээр оролцож, нийт 11 давхар нийтэд оролцсон. Хоёр баг Англи-Хятад даалгавраас 2 даалгавраар оролцсон. i) өнгөрсөн (Википедиа эсвэл мэдээллийн технологийг харьцуулахад өөр өөр эх үүсвэр/тоо баримт), ii) эхний хэл хоёр (Англи-Хятад) шинэ хэл хоёрын танилцуулалт нь өнгөрсөн жилийн турш шууд харьцуулагдахгүй. Гэхдээ хоёр хэл замаар оролцогчдын хүлээн зөвшөөрөл суурь шугамын үр дүн дээр маш их сайжруулагддаг. Англи-Германы хувьд хамгийн өндөр дүрс систем нь суурь шугам дээр -11,35 ДЕР болон +16,68 БЛЕС цэг дээр сайжруулдаг. Англи хэлний хувьд сайжруулалт нь -12,13 ДЕР болон +14,57 БЛЕС цэг дээр байдаг. Ихэнхдээ, хүн төрөлхтний оюун шалгалтын үр дүнээс хамааралтай ашиг нь МТ-ын сайн сайн сайжруулахын тулд APE-ын үр дүнг тодорхойлдог. Ялангуяа энэ жилийн турш сонгогдсон шинэ ерөнхий хэмжээнд ашигла", 'pl': 'Przedstawiamy wyniki szóstej rundy zadania WMT na MT Automatic Post-Editing. Zadanie polega na automatycznej korekcji wyników systemu tłumaczenia maszynowego "czarnej skrzynki" poprzez uczenie się na istniejących poprawkach różnych zdań ludzkich. W tym roku wyzwanie polegało na naprawieniu błędów występujących na angielskich stronach Wikipedii przetłumaczonych na język niemiecki i chiński za pomocą najnowocześniejszych, nie dostosowanych do domeny systemów neuronowych MT (NMT) nieznanych uczestnikom. W zadaniu angielsko-niemieckim uczestniczyło sześć zespołów, zgłaszając łącznie jedenaście biegów. W zadaniu angielsko-chińskim uczestniczyły dwie zespoły, składając każdy z nich dwa biegi. Ze względu na i) różne źródło/domenę danych w porównaniu z przeszłością (Wikipedia vs Informatyka), ii) różną jakość pierwotnych tłumaczeń, które mają być skorygowane oraz iii) wprowadzenie nowej pary językowej (angielsko-chiński), tegoroczne wyniki nie są bezpośrednio porównywalne z ubiegłoroczną. Jednakże w obu kierunkach językowych zgłoszenia uczestników wykazują znaczną poprawę w stosunku do wyników podstawowych. W przypadku angielsko-niemieckiego najwyższej klasyfikacji system poprawia się w porównaniu z linią bazową o punkty -11.35 TER i +16.68 BLEU, podczas gdy w angielskich poprawki wynoszą odpowiednio do punktów -12.13 TER i +14.57 BLEU. Ogólnie rzecz biorąc, spójne zyski podkreślają również wyniki oceny przez ludzi, co potwierdza skuteczność APE w zakresie poprawy jakości MT, zwłaszcza w nowej dziedzinie generycznej wybranej na tegoroczną rundę.', 'sr': 'Predstavljamo rezultate 6. runde WMT zadatka na automatskom posledištu MT-a. Taj zadatak se sastoji u automatskom korištenju izlaza "crne kutije" sistema prevoda mašine učeći od postojećih ljudskih korekcija različitih rečenica. Ove godine je izazov sastavio od popravljanja grešaka na engleskim Wikipedijskim stranicama prevedena na njemačke i kineske državnim umjetničkim sistemima, a ne na domenu prilagođenim neuralnim MT (NMT) sistemima nepoznatim učesnicima. Šest timova sudjelovalo je u engleskom-nemačkom zadatku, podnivši ukupno 11 trka. Dva timova su sudjelovala u engleskom-kineskom zadatku koji podnosi 2 vode svaki. Zbog i) različitih izvora/domena podataka u usporedbi s prošlošću (Wikipedia protiv informacione tehnologije), ii) različite kvalitete početnih prevoda koje treba ispraviti i iii) uvođenje novog jezičkog parova (engleski kineski), rezultati ove godine nisu direktno usporedni s a prošlogodišnjim krugom. Međutim, na obje jezičke upute, podaci učesnika pokazuju značajne poboljšanje u odnosu na početne rezultate. Na engleskom-njemačkom, najviši redoviti sistem se poboljšava preko početne linije za -11,35 TER i +16,68 BLEU to čke, a na engleskom kineskom su poboljšanja u odnosu na -12,13 TER i +14,57 BLEU točke. Uglavnom, saslušni dobiti su takođe istaknuti rezultatima ljudske procjene, koja potvrđuje učinkovitost APE-a da bi poboljšala kvalitet MT-a, posebno u novom generičkom domenu odabranom za ovu godinu okrugu.', 'ro': 'Vă prezentăm rezultatele celei de-a 6-a runde a sarcinii WMT pe MT Automatic Post-Editing. Sarcina constă în corectarea automată a rezultatelor unui sistem de traducere automată "cutie neagră" prin învățarea din corecțiile umane existente ale diferitelor propoziții. În acest an, provocarea a constat în remedierea erorilor prezente în paginile Wikipedia în limba engleză traduse în germană și chineză de sisteme MT neurale de ultimă generație, nu adaptate domeniului, necunoscute participanților. Șase echipe au participat la sarcina engleză-germană, trimițând un total de 11 run-uri. Două echipe au participat la sarcina engleză-chineză trimițând câte două rulări fiecare. Datorită i) sursei/domeniului diferit de date comparativ cu trecutul (Wikipedia vs Tehnologia Informației), ii) calității diferite a traducerilor inițiale care trebuie corectate și iii) introducerii unei noi perechi de limbi (engleză-chineză), rezultatele din acest an nu sunt direct comparabile cu runda de anul trecut. Cu toate acestea, în ambele direcții lingvistice, observațiile participanților arată îmbunătățiri considerabile față de rezultatele de referință. La engleză-germană, sistemul de top clasat se îmbunătățește față de bază cu -11.35 TER și +16.68 puncte BLEU, în timp ce la engleză chineză îmbunătățirile sunt de până la -12.13 TER și respectiv +14.57 puncte BLEU. În general, câștigurile coerente sunt evidențiate și de rezultatele evaluării umane, care confirmă eficacitatea APE în îmbunătățirea calității MT, în special în noul domeniu generic selectat pentru runda din acest an.', 'no': 'Vi viser resultatet av det 6. runda av WMT- oppgåva på MT- automatisk post- redigering. Oppgåva inneheld i automatisk korrigering av utdata av ein « svart boks » - maskinsomsetjingssystem ved å læra frå eksisterande menneske korrigeringar av ulike setningar. Dette året har utfordringen av å retta feilene som finst i engelsk Wikipedia-sider omsett til tysk og kinesisk ved tilstanden av kunsten, ikkje domenetilpassa neural MT (NMT) system ukjend til deltakarar. Sekst grupper delta i engelsk-tysk oppgåve og sender totalt 11 køyr. To grupper delta i engelsk-kinesisk oppgåve som sender 2 køyrer kvar. I grunn av i) den ulike kjelde/domenet av data sammenlignet med tidlegare (Wikipedia vs Information Technology), ii) den ulike kvaliteten til den opphavlege omsetjinga som skal korrigerast og iii) introduksjonen av ein ny språkopar (engelsk kinesisk), resultatet til denne året er ikkje direkte sammenlignbar med den siste årene runda. Med begge språkkretningar viser likevel deltakarane mykje forbedringar over grunnlinjesresultatene. På engelsk-tysk forbedrar den øvre rangerte systemet over baseline med -11,35 TER og +16,68 BLEU-punkt, mens på engelsk kinesisk er forbedringane opp til -12,13 TER og +14,57 BLEU-punkt. Generelt er det samsvarende oppnår også markert av resultatet av menneskelige evaluering, som stadfestar effektiviteten av APE for å forbetra MT-kvalitet, spesielt i den nye generiske domenet som er valde for året.', 'so': "Waxaan soo saaraynaa dhamaadka 6aad ee shaqada WMT ee MT Automatic Post-Editing. Shaqadu wuxuu ku qoran yahay hagaajinta midhaha lagu qorayo qoraalka machine-box-madow, marka aad ka barato hagitaanka biniaadamka oo kala duduwan erayo kala duduwan. Sannadan, dhibaatada waxaa ka mid ah hagitaanka khaladaha ku yaal bogagga Ingiriiska Wikipedia ee lagu turjumay Jarmal iyo Shiino, taasoo lagu qoray dowlad-of the-art, ma aha nidaam-adapted neural MT (NMT) ee aan aqoon kuwa ka shaqeeya. Lix koox ayaa ka qeybqaaday shaqada Ingiriiska-Jarmalka, wuxuuna sameynayay 11 runood oo dhan. Laba kooxood waxay ka qeybqaadatay shaqada Ingiriiska-Shiino oo keena 2 mid ah. Taas darteed (i) asalkii kala duduwan/domain ee macluumaadka oo la barbaran jiray hore (Wikipedia vs Info Technology), ii) qiimaha kala duduwan tarjumaadka hore oo la hagaajiyo iyo iii) soo saaridda labada luqada cusub (Ingiriis-Chinese), fashihiisa sanadkan si toos ah uma dhigo wareegga sannadkii hore. Si kastaba ha ahaatee labada kooxaha luqada ah waxaa ka muuqda koob-horumarinta ku saabsan dhamaadka aasaasiga ah. On English-German, the top ranked system improves over the baseline by -11.35 TER and +16.68 BLEU points, while on EnglishChinese the improvements are respectively up to -12.13 TER and +14.57 BLEU points.  Inta caadiga ah waxaa sidoo kale ku qoran faa'iidada kaartaynta biniaadamka, kaas oo xaqiijiya awoodda APE in la hagaajiyo qiimaha MT, khusuusan goobta cusub ee sanadkan la doortay.", 'sv': 'Vi presenterar resultaten av den sjätte omgången av WMT-uppgiften om MT Automatic Post-Editing. Uppgiften består i att automatiskt korrigera resultatet av en "svart låda" maskinöversättningssystem genom att lära sig av befintliga mänskliga korrigeringar av olika meningar. I år bestod utmaningen av att åtgärda de fel som finns på engelska Wikipedia sidor översatta till tyska och kinesiska av toppmoderna, inte domänanpassade neurala MT (NMT) system okända för deltagarna. Sex lag deltog i den engelsk-tyska uppgiften och lämnade in totalt 11 omgångar. Två team deltog i den engelsk-kinesiska uppgiften och skickade in två omgångar vardera. På grund av i) olika datakällor/domäner jämfört med tidigare (Wikipedia vs informationsteknik), ii) olika kvalitet på de ursprungliga översättningarna som ska korrigeras och iii) införandet av ett nytt språkpar (engelska-kinesiska), är årets resultat inte direkt jämförbara med förra årets omgång. På båda språkriktningarna visar dock deltagarnas bidrag betydande förbättringar jämfört med basresultaten. På engelsk-tyska förbättras det topprankade systemet jämfört med baslinjen med -11,35 TER och +16,68 BLEU poäng, medan på engelskkinesiska är förbättringarna upp till -12,13 TER respektive +14,57 BLEU poäng. Sammantaget framhävs konsekventa vinster också av resultaten av mänsklig utvärdering, vilket bekräftar APE:s effektivitet när det gäller att förbättra MT-kvaliteten, särskilt inom det nya generiska område som valts ut för årets runda.', 'si': "අපි MT ස්වයංක්\u200dරීය පොස්ට් සංපාදනය කරන්නේ WMT වැඩේ 6වෙනි රාන්ඩ් එකේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර කාර්ය ස්වයංක්\u200dරමයෙන් 'කළ- බොක්ස්' පද්ධතිය භාවිත පද්ධතියක් ස්වයංක්\u200dරමය කරන්න ස්වයංක්\u200dරියාවිතයෙන මේ අවුරුද්දේ, ඉංග්\u200dරීසි විකිපිඩියා පිටුම් වලින් ජර්මන් සහ චීනි වලින් වලින් ප්\u200dරවේශය සඳහා ප්\u200dරවේශය සඳහා ප්\u200dරවේශය සඳහා ප්\u200dරවේශය සඳහ කණ්ඩායම් හයක් ඉංග්\u200dරීසිය-ජර්මන් වැඩේ සම්පූර්ණයෙන් පැමිණිලි කරනවා. කණ්ඩායම් දෙකක් ඉංග්\u200dරීසිය-චීනි වැඩේ එක්කෙනෙක් දාන්න පුළුවන්. i) වෙනස් ප්\u200dරමාණය/ඩොමේනියාව අතීතය (විකිපිඩියා සහ තොරතුරු තොරතුරු තොරතුරු සඳහා සම්බන්ධ වෙනස් විදිහට (විකිපිඩියා සහ තොරතුරු තොරතුරු තොරතුරු සඳහා නමුත්, භාෂාව දෙන්නම් ප්\u200dරතිකාරයෝ පිළිබඳින් ප්\u200dරතිකාරයෝ ගැන ප්\u200dරතිකාරයෝ ප්\u200dරතිකාරයෝ ප ඉංග්\u200dරීසිය-ජර්මාන්සියේ උපස්ථ පද්ධතිය ප්\u200dරමාණය -11.35 TER සහ +16.68 BLUE ප්\u200dරමාණ වලින් වැඩි වෙනවා, ඉංග්\u200dරීසියානු චීන්සියානු වලින් වැඩි වැ සම්පූර්ණයෙන්, සම්පූර්ණයි, මිනිස්සු විශ්ලේෂණයේ ප්\u200dරතිචාරයෙන් ප්\u200dරතිශාලනය කරනවා, ඒකෙන් APE ගේ විශේෂතාවට MT කුළුවත් වැ", 'ta': 'MT தானியங்கி தொகுப்பு பின் தொகுப்பில் WMT பணியின் 6வது சுற்று முடிவை நாம் காண்பிக்கிறோம். கருப்பு- பெட்டியின் மொழிமாற்று அமைப்பின் வெளியீட்டை தானாகவே சரிசெய்யும் பணியில் இருக்கும் மாறுபாடுகளில் இருந இந்த வருடத்தில், ஆங்கிலம் விகிபிடியா பக்கங்களில் இருக்கும் பிழைகளை சரிபார்க்கும் சவால் இருந்தது ஜெர்மன் மற்றும் சீனா பக்கங்களில் மொழிமாற்றப்பட்டது, டொமைன்  ஆறு குழுக்கள் ஆங்கிலம்- ஜெர்மன் பணியில் பங்கிடப்பட்டனர், மொத்தமான 11 ஓட்டுகள் கொடுக்கின்றன. இரண்டு குழுக்கள் ஒவ்வொரு ஓட்டுகிறார்கள் ஆங்கில- சீனா பணியில் பங்கிடப்பட்டனர். நான் காரணமாக) முந்தைய (விகிபிடியா vs தகவல் தொழில்நுட்பத்திற்கு ஒப்பிடும் வேறு மூலத்தின் மூலம்/களம், i i) முதல் மொழிமாற்றங்களை சரிசெய்ய வேண்டிய மாறுபாடுகளின் தரம், மற்றும் iii) பு இரு மொழி திசைகளிலும், பங்கீட்டாளர்களின் கூறுதல்கள் அடிப்படைக்கோட்டின் முடிவுகளைக் காட்டுகிறது. ஆங்கிலத்தில்- ஜெர்மனில் மேல் சிறப்பு விரிவாக்கப்பட்ட அமைப்பு -11. 35 TER மற்றும் + 16. 68 பிலியு புள்ளிகள் மேல் மேம்படுத்தப்பட்டது, போது ஆங்கிலத்தில் சீன மேம்பட் மொத்தமாக, மனித மதிப்புகளின் விளைவுகள் முன்னிலைப்படுத்தப்படுகிறது, அது ஏபியின் விளைவை மேம்படுத்துகிறது, குறிப்பாக இந்த வருடத்தின் சுற்றில் தே', 'ur': "ہم نے MT اتوماٹی پوسٹ-ایڈیٹینگ پر WMT ٹیسٹ کے 6م رانڈ کے نتائج پیش کیے ہیں. یہ کام اپنے ساتھ مختلف جماعتوں کے موجود انسان کی اصلاح سے سیکھنے کے ذریعہ ایک 'سیاہ باکس' ماشین ترجمہ سیسٹم کی اپوٹٹ سیستم کی اصلاح کرتی ہے. آج سال، اس چال میں انگلیسی ویکیپیڈیا صفحے میں موجود خطاؤں کا اصلاح کرنا تھا جو جرمن اور چینی میں آرتی کے ذریعہ تبدیل کئے گئے ہیں، نہیں ڈومین کے اندازے سے نیورال MT (NMT) سیستموں کے ذریعہ حضار کرنے والے نہیں ہیں. چھ تیموں انگلیسی-جرمن کے کام میں شریک ہوئے، 11 رونڈ جمع کر رہے تھے. دو ٹیموں انگلیسی-چینی ٹیموں میں شامل ہوئے، ہر ایک دو چلنے والے ہیں۔ I) اگلے (ویکیپیڈیا علیھ السّلامٹیکنالوجی علیھ السّلامٹیکنالوجی علیھ السّلامکے مقابلہ میں) ایک نئی زبان جوڑی (انگلیسی-چینی) کی معلومات کے باعث مختلف سراسر/ڈومین (i i) پہلی سال کے راند سے مختلف کیفیت نہیں ہے. لیکن، دونوں زبان کی طرف، شرکت کرنے والوں کے مطابق بنیادی لین کے نتائج پر بہت اچھے سوداگری دکھاتے ہیں. انگلیسی-جرمنی پر بالا رینگ سیسٹم -11.35 TER اور +16.68 BLEU پوینٹ کے ذریعے بنیادی لین پر بہتر ہوتا ہے، حالانکہ انگلیسی چینی پر سوداگری -12.13 TER اور +14.57 BLEU پوینٹ تک ہوتی ہے. بالکل، انسان کی ارزیابی کا نتیجہ بھی مشتبہ ہوتا ہے، جس کی تصدیق کرتی ہے APE کی مثبت MT کیفیت کو بہتر کرنے کے لئے، مخصوصاً اس سال کے راندے کے لئے انتخاب کئے ہوئے نئی عمومی دامنی میں.", 'vi': 'Chúng tôi giới thiệu kết quả vòng thứ sáu của nhiệm vụ WRT trên mạng lưới mạng lưới mạng lưới Post-Editing Tự động. Nhiệm vụ này gồm việc sửa chữa tự động sản xuất của một hệ thống dịch thuật cỗ máy "hộp đen" bằng cách học từ những sửa chữa con người ở các câu khác nhau. Năm nay, thử thách bao gồm việc sửa lỗi trong trang Wikipedia đã được dịch thành Đức và Tàu bằng hệ thống truyền thống truyền thống truyền đạt sang Đức và Trung Quốc, chứ không phải hệ thống mạng lưới thần kinh cục bộ. (NMB) chưa được biết đến đối với các diễn viên. Sáu đội đã tham gia vào nhiệm vụ Anh-Đức, cung cấp một lượng lớn các kênh 11. Hai đội đã tham gia nhiệm vụ Anh-Trung Quốc gởi 2 chạy mỗi đội. Do i i) nguồn tin/miền khác nhau của dữ liệu so với trước (Wikipedia v.Information Technology) the different chất lượng of the initial translations to be Corresed and III) the Introduction of a new language pair (English-Chinese), the results of this year are not trực tiếp tương ứng với tuần trước. Tuy nhiên, dựa trên cả hai hướng ngôn ngữ, sự phát triển của cuộc họp cho thấy có những cải tiến đáng kể. Trên tiếng Anh-Đức, hệ thống cấp cao cải thiện trên so với cơ sở cơ sở của Mười.35 Số Số Số Số Số Số Số Số Số Số Số Số Và Số Hệ Sự Sự Sự Sự Hình Sự, Trong khi đó ở Anh Quốc, sự cải tiến là lên tới-12.13 Số Số Và Chỉ+14.57 Số Số Điểm ĐU. Về mặt chung, kết quả của đánh giá con người cũng được đánh dấu, xác nhận rằng APE có hiệu quả để cải thiện chất lượng MTV, đặc biệt là trong lĩnh vực mới được chọn chung cho vòng tròn năm nay.', 'uz': "Biz MT avtomatik tahrirlash uchun WMT vazifasi 6 chi harfdagi natijalarini koʻrsatimiz. Name Bu yilda, ingliz vikipedia sahifalarining xatolarini o'zgartirish uchun tarjima qilingan holatda Olmon va Xitoycha sahifalarga tarjima qiladigan, domen-adapted neural MT (NMT) tizimi nomaʼlum emas. Six guruhi ingliz tilida Olmonchaga ishga ega bo'lgan vazifani o'zgartirdi. Bu bir necha 11 ruxsat yordam beradi. Икки гуруҳ ҳар бирини икки ишлатган ই-Xitoycha vazifasiga অংশগ্রহণ қилганлар. Bu sababi, past (Wikipedia vs Maʼlumot Teknologiga) bilan bir xil maʼlumot manbasi/domen (Wikipedia vs Maʼlumot Teknolojiga kamaytirilgan), i i) oʻzgartirish uchun boshqa tarjimalarning turli sifatida (iii) yangi tillar ikki xitoz (Inglizcha- Xitoycha) qoʻyishni ishga tushirish mumkin, bu yil natijalari oxirgi yil sohasida to ʻgʻri bir xi Lekin, ikkita tilning ko'rini bilan bog'liqchilar imkoniyatlarini asosiy matn natijalariga juda ko'p yaxshi ko'rinadi. Inglizcha-Olmonchada eng yuqori tizim - 11.35 TER va +16.68 BLEU pointlari bilan bir necha darajada o'zgariladi. Inglizcha xitoycha sohasida taʼminlovchilar - 12.13 TER va + 14.57 BLEU pointlariga ega bo'ladi. Umumiy, bir necha muvaffaqiyatlarni inson qiymatning natijalarini ko'rsatadi. Bu yil ichida tanlangan yangi genetikal domen davrida APE tizimini bajarishga ishonch hosil qiladi.", 'bg': 'Представяме резултатите от 6-ия кръг на задачата за автоматична следредакция на МТ. Задачата се състои в автоматично коригиране на изхода на системата за машинен превод "черна кутия", като се учи от съществуващите човешки корекции на различни изречения. Тази година предизвикателството се състои в поправяне на грешките, присъстващи в английските страници на Уикипедия, преведени на немски и китайски, чрез най-съвременни, а не домейн-адаптирани неврални МТ (НМТ) системи, неизвестни за участниците. Шест отбора участваха в англо-германската задача, като представиха общо 11 проби. Два отбора участваха в англо-китайската задача с по 2 проби всеки. Поради i) различен източник/област на данни в сравнение с миналото (Уикипедия срещу информационни технологии), ii) различното качество на първоначалните преводи, които трябва да бъдат коригирани и iii) въвеждането на нова езикова двойка (английски-китайски), резултатите от тазгодишната година не са пряко сравними с миналия кръг. Въпреки това, и в двете езикови направления заявленията на участниците показват значителни подобрения спрямо изходните резултати. При английско-немски най-класираната система се подобрява спрямо базовата база с -11.35 точки, докато при английския китайски подобренията са съответно до -12.13 точки и +14.57 точки. Като цяло, съгласуваните ползи се подчертават и от резултатите от оценката на хората, което потвърждава ефективността на ЕПП за подобряване на качеството на МТ, особено в новата генерична област, избрана за тазгодишния кръг.', 'hr': 'Predstavljamo rezultate 6. runde zadatka WMT-a na automatskom posledištu MT-a. Taj zadatak se sastoji u automatskom korištenju izlaza sustava prevoda mašine "crne kutije" učeći od postojećih ljudskih korekcija različitih rečenica. Ove godine je izazov sastojio od rješavanja grešaka na engleskim Wikipedijskim stranicama prevedena na njemačke i kineske državnim umjetničkim sustavima, a ne na domenu prilagođenim neuralnim MT (NMT) sustavima nepoznatim učesnicima. Šest timova sudjelovalo je u engleskom i njemačkom zadatku, podnivši ukupno 11 trka. Dva timova su sudjelovala u engleskom-kineskom zadatku koji podnosi 2 vodi svaki. Zbog i) različitih izvora/domena podataka u usporedbi s prošlošću (Wikipedia protiv informacione tehnologije), ii) različite kvalitete početnih prevoda koje treba ispraviti i iii) uvođenje novog jezičkog parova (engleski kineski), rezultati ove godine nisu direktno usporedbeni s prošlogodišnjim krugom. Međutim, na obje jezičke upute, podaci učesnika pokazuju značajne poboljšanje u odnosu na početne rezultate. Na engleskom-njemačkom se najviši redoviti sustav poboljšava preko početne linije za -11,35 TER i +16,68 BLEU to čke, dok su na engleskom kineskom poboljšavanje u odnosu na -12,13 TER i +14,57 BLEU točke. U cjelokupnom slučaju, pristojne dobitke također su istaknute rezultatima ljudske procjene, koja potvrđuje učinkovitost APE-a kako bi poboljšala kvalitet MT-a, posebno u novoj generičkoj domenu odabranoj za ovu godinu okrugu.', 'da': 'Vi præsenterer resultaterne af den 6. runde af WMT-opgaven på MT Automatic Post-Editing. Opgaven består i automatisk at korrigere resultatet af et "sort boks"-maskinoversættelsessystem ved at lære af eksisterende menneskelige korrektioner af forskellige sætninger. I år bestod udfordringen i at rette fejlene på engelske Wikipedia-sider oversat til tysk og kinesisk af state-of-art, ikke domænetilpassede neurale MT (NMT) systemer ukendt for deltagerne. Seks hold deltog i den engelsk-tyske opgave og indsendte i alt 11 løb. To hold deltog i den engelsk-kinesiske opgave, der indsendte 2 kørsler hver. På grund af i) den forskellige datakilde/domæne i forhold til fortiden (Wikipedia vs informationsteknologi), ii) den forskellige kvalitet af de oprindelige oversættelser, der skal rettes, og iii) indførelsen af et nyt sprogpar (engelsk-kinesisk), er årets resultater ikke direkte sammenlignelige med sidste års runde. I begge sprogretninger viser deltagernes indlæg imidlertid betydelige forbedringer i forhold til basisresultaterne. På engelsk-tysk forbedres det toprangerede system i forhold til baseline med -11,35 TER og +16,68 BLEU point, mens forbedringerne på engelsk-kinesisk er henholdsvis op til -12,13 TER og +14,57 BLEU point. Samlet set fremhæves sammenhængende gevinster også af resultaterne af evalueringen af mennesker, som bekræfter APE\'s effektivitet til at forbedre MT-kvaliteten, især i det nye generiske domæne, der er udvalgt til årets runde.', 'nl': "We presenteren de resultaten van de 6e ronde van de WMT taak op MT Automatic Post-Editing. De taak bestaat in het automatisch corrigeren van de output van een 'black-box' machinevertaalsysteem door te leren van bestaande menselijke correcties van verschillende zinnen. Dit jaar bestond de uitdaging uit het verhelpen van de fouten die aanwezig waren in de Engelse Wikipedia pagina's vertaald naar het Duits en Chinees door state-of-art, niet domein-aangepaste neurale MT (NMT) systemen onbekend voor deelnemers. Zes teams namen deel aan de Engels-Duitse taak en leverden in totaal elf runs in. Twee teams namen deel aan de Engels-Chinese taak en leverden elk twee runs op. Vanwege i) de verschillende bron/domein van gegevens ten opzichte van het verleden (Wikipedia vs. Informatietechnologie), ii) de verschillende kwaliteit van de eerste te corrigeren vertalingen en iii) de introductie van een nieuw taalpaar (Engels-Chinees), zijn de resultaten van dit jaar niet direct vergelijkbaar met vorig jaar. Op beide taalrichtingen vertonen de inzendingen van de deelnemers echter aanzienlijke verbeteringen ten opzichte van de basisresultaten. Op Engels-Duits verbetert het best gerangschikte systeem ten opzichte van de baseline met -11.35 TER en +16.68 BLEU punten, terwijl op EngelsChinees de verbeteringen respectievelijk -12.13 TER en +14.57 BLEU punten zijn. Over het algemeen worden de coherente winsten ook benadrukt door de resultaten van menselijke evaluatie, die de effectiviteit van APE om de MT-kwaliteit te verbeteren, met name in het nieuwe generieke domein dat dit jaar is geselecteerd.", 'de': 'Wir präsentieren die Ergebnisse der sechsten Runde der WMT-Aufgabe auf MT Automatic Post-Editing. Die Aufgabe besteht darin, die Ausgabe eines "Black-Box"-maschinellen Übersetzungssystems automatisch zu korrigieren, indem aus vorhandenen menschlichen Korrekturen verschiedener Sätze gelernt wird. In diesem Jahr bestand die Herausforderung darin, die Fehler auf englischen Wikipedia-Seiten zu beheben, die in Deutsch und Chinesisch durch modernste, nicht domänenadaptimierte neuronale MT (NMT)-Systeme (neurale MT) übersetzt wurden, die den Teilnehmern unbekannt waren. Sechs Teams nahmen an der englisch-deutschen Aufgabe teil und reichten insgesamt elf Läufe ein. Zwei Teams haben an der englisch-chinesischen Aufgabe teilgenommen und jeweils zwei Läufe eingereicht. Aufgrund i) der unterschiedlichen Datenquelle/Domäne im Vergleich zur Vergangenheit (Wikipedia vs. Informationstechnologie), ii) der unterschiedlichen Qualität der zu korrigierenden Erstübersetzungen und iii) der Einführung eines neuen Sprachpaares (Englisch-Chinesisch) sind die diesjährigen Ergebnisse nicht direkt mit dem Vorjahr vergleichbar. In beiden Sprachrichtungen zeigen die Beiträge der Teilnehmer jedoch erhebliche Verbesserungen gegenüber den Ausgangsergebnissen. Auf Englisch-Deutsch verbessert sich das am besten platzierte System gegenüber der Baseline um -11.35 TER und +16.68 BLEU Punkte, während auf EnglischChinesisch die Verbesserungen jeweils bis zu -12.13 TER und +14.57 BLEU Punkte liegen. Insgesamt werden kohärente Gewinne auch durch die Ergebnisse der Humanbewertung hervorgehoben, die die Wirksamkeit von APE zur Verbesserung der MT-Qualität bestätigt, insbesondere in dem neuen generischen Bereich, der für dieses Jahr ausgewählt wurde.', 'id': "Kami memperkenalkan hasil pusingan ke-6 dari tugas WMT di MT Automatic Post-Editing. The task consists in automatically correcting the output of a 'black-box' machine translation system by learning from existing human corrections of different sentences.  Tahun ini, tantangan terdiri dari memperbaiki kesalahan yang ada di halaman Wikipedia Inggris terjemahan ke Jerman dan Cina oleh sistem MT saraf terbaik, tidak beradaptasi domain (NMT) yang tidak dikenal oleh peserta. Enam tim berpartisipasi dalam tugas Inggris-Jerman, mengirim total 11 runs. Two teams participated in the English-Chinese task submitting 2 runs each.  Karena i) sumber/domain data yang berbeda dibandingkan dengan masa lalu (Wikipedia vs Information Technology), ii) kualitas yang berbeda dari terjemahan awal yang harus diperbaiki dan iii) perkenalan pasangan bahasa baru (Inggris-Cina), hasil tahun ini tidak secara langsung dibandingkan dengan bulat tahun lalu. Namun, pada kedua arah bahasa, pengiriman peserta menunjukkan peningkatan yang konsiderel atas hasil dasar. Dalam bahasa Inggris-Jerman, sistem tertinggi berkembang di atas dasar dengan -11,35 TER dan +16,68 BLEU poin, sementara pada bahasa Inggris perbaikan secara harfiah sampai -12,13 TER dan +14,57 BLEU poin. Secara umum, keuntungan yang konsisten juga diperkirakan oleh hasil evaluasi manusia, yang mengkonfirmasi efektif APE untuk meningkatkan kualitas MT, terutama dalam domain generik baru yang dipilih untuk bulat tahun ini.", 'ko': '우리는 제6차 WMT 기계 번역 자동 후기 편집 임무의 결과를 보여 주었다.이 임무는 기존의 인류가 서로 다른 문장에 대한 정정을 학습함으로써 블랙박스 기계번역시스템의 출력을 자동으로 정정하는 것을 포함한다.올해 도전은 참여자가 알 수 없는 영역이 신경기계번역(NMT) 시스템에 적응하는 것이 아니라 최신 기술로 독일어와 중국어로 번역된 영문 위키백과 페이지에 존재하는 오류를 복구하는 것이다.여섯 팀은 영덕 임무에 참가해 모두 11점을 제출했다.두 그룹은 중국어와 영문 임무에 참가했고 각 그룹은 2점씩 제출했다.i) 데이터 출처/영역이 과거와 다르기 때문에(위키백과와 정보기술), ii가 수정해야 할 초기 번역의 질이 다르고, iii가 새로운 언어대(영한)를 도입했기 때문에 올해의 결과는 작년의 결과와 직접 비교할 수 없다.그러나 두 언어 방향에서 참여자가 제출한 내용은 모두 기선 결과보다 많이 개선되었다.영어 독일어에서는 상위 시스템이 기준선보다 -11.35점, +16.68점 높아졌고, 영어 중국어에서는 상위 시스템이 각각 -12.13점, +14.57점 올랐다.전체적으로 인류 평가 결과도 일치성 성과를 두드러지게 한 것은 APE가 기계 번역의 질을 높이는 데 있어 유효성을 입증했고 특히 올해 선정된 새로운 유니버설 분야가 그렇다.', 'fa': 'ما نتیجه\u200cهای ششمین مرحله عملیات WMT را توسط ویرایش خودکار MT نشان می\u200cدهیم. این وظیفه با یاد گرفتن از اصلاح انسانی موجود از جمله\u200cهای مختلف از سیاه بوکس سیاه استفاده می\u200cکند. در این سال، چالش از تعمیر اشتباهی که در صفحه ویکیپدیدی انگلیسی وجود دارند، توسط ایالت-هنر، نه سیستم\u200cهای عصبی (NMT) که برای شرکتگران ناشناخته می\u200cشوند، به آلمان و چینی ترجمه می\u200cشوند. شش تیم در کار انگلیسی و آلمانی شرکت کردند و جمعیت ۱۱ فرایند را ارسال کردند. دو تیم در وظیفه انگلیسی-چینی شرکت می\u200cکردند که در هر دو راه می\u200cروند. به دلیل i) منبع/دامنه\u200cهای متفاوت در مقایسه با تکنولوژی اطلاعات گذشته (ویکیپدیا vs اطلاعات) ii) کیفیت متفاوتی از ترجمه\u200cهای اولیه که به اصلاح می\u200cشود و iii) معرفی جفت زبان جدید (انگلیسی-چینی) نتیجه\u200cهای امسال مستقیماً با گردش سال گذشته قابل ولی در هر دو مسیر زبان، تحویل\u200cهای شرکتگران بر روی نتیجه\u200cهای پایه\u200cخط زیادی بهتر شدن را نشان می\u200cدهند. در انگلیسی-آلمان، سیستم بالای درجه بالا در خط بنیادی با -11.35 TER و +16.68 BLEU تغییر می\u200cدهد، در حالی که در انگلیسی چینی تغییرات به طور مختلف تا -12.13 TER و +14.57 BLEU هستند. در کل، پیروزی هماهنگی از نتایج ارزیابی انسان، که تایید می\u200cکند فعالیت APE برای بهترین کیفیت MT، مخصوصا در دامنه\u200cهای ژنرالی جدید برای این سال انتخاب شده است.', 'sw': "Tunaonyesha matokeo ya mzunguko wa sita wa kazi ya WMT kwenye MT ya Kuhariri Baada ya Uhuru. Kazi hiyo inajumuisha katika kurekebisha matokeo ya mfumo wa utafsiri wa mashine 'boksi nyeusi' kwa kujifunza kutoka kwa uharibifu wa binadamu wa sentensi tofauti. Mwaka huu, changamoto ilikuwa ni ya kurekebisha makosa yaliyopo katika kurasa za Wikipedia za Kiingereza zinazotafsiriwa kwa Kijerumani na Kichina na sanaa za serikali, na sio mfumo wa MT (NMT) ambao haujulikani kwa washiriki. Timu sita walishiriki katika kazi ya Kiingereza na Kijerumani, wakituma jumla ya rundo 11. Timu mbili walishiriki katika kazi ya Kiingereza na Kichina inayotoa ujumbe wa mbili huendesha kila mmoja. Kutokana na mimi) chanzo tofauti na taarifa tofauti tofauti ukilinganishwa na yale yaliyopita (Wikipedia vs Teknolojia ya Habari), i i) kiwango tofauti cha tafsiri za awali zinazosaidiwa na iii) kuanzishwa kwa lugha mpya (Kiingereza-China), matokeo ya mwaka huu hayafananishwi moja kwa moja na mzunguko wa mwaka uliopita. Hata hivyo, kwa maelekezo mawili ya lugha, ujumbe wa washiriki unaonyesha maendeleo makubwa zaidi ya matokeo ya msingi. Kuhusu Kiingereza-Ujerumani, mfumo wa juu unaongezeka zaidi kwenye msingi unaofanywa na -11.35 TER na +16.68 BLEU, wakati katika lugha ya Kiingereza maendeleo yanaweza kufikia -12.13 TER na +14.57 BLEU. Kwa ujumla, mafanikio ya pamoja pia yanaonyeshwa na matokeo ya uchunguzi wa binadamu, ambayo yanathibitisha ufanisi wa APE wa kuboresha kiwango cha viwango vya MT, hasa katika eneo jipya lililochaguliwa kwa ajili ya mwaka huu.", 'tr': "MT Otomatik Post-Editing üzerinde WMT işinin 6. turunculuğunu gösteriyoruz. Görev bolsa ''gara-box' maşynyň terjime sistemini bolan sözleriň düzeltmeginden öwrenip öz-özüne düzeltmekde. Bu ýyl, beýleki kynçylyk Iňlisçe Wikipedia sahypalarynda Almança we Çin çe çevirilen ýagdaýlary bejermek üçin bardyr. Alty topar iňlisçe-nemesçe görevlerde bäsleşipdir, toplamyň 11 bäsleşigini belleýärler. Iki topar Iňlisçe-Çin çe işine 2 işi gönderýär. I) geçen ýylyň(Wikipedia we Maglumat Teknolojisi) bilen görä görä görä be ýleki görnüş sanlaryň/domeny, i i) başlangyç terjimeleriň üýtgewleri düzeltilmeli we iii) täze dil çift(i ňlisçe-Çinçe) girişi, bu ýylyň netijesi geçen ýylyň içine çykyp biljek däl. Ýöne, iki dil görnüşinde, iştirakçileriniň görnüşleri baz çyzgylyň netijesinde möhüm gelişmeleri görkezýär. Iňlisçe-nemesçe, iň üst depler sistemasy baseline derejesinde -11,35 TER we +16,68 BLUE punktlary bilen gelişýär, iňlisçe Çinçe bilen gelişmeler -12,13 TER we +14,57 BLUE punktlary diýýär. Mundan hem, kohereket gazançlar ynsan değerlendirmegiň netijesi tarapyndan ýagtylaşdyrylýar. Bu da APE'nin MT kalitesini geliştirmegini tassyklaýar, ýöne bu ýylyň täze döwletlerinde saýlanan döwletlerde.", 'af': "Ons stel die resultate van die 6de ronde van die WMT taak op MT Outomatiese Post- Redigering voor. Die taak bestaan in automaties korrigeer die uitset van 'n 'swart- box' masjien vertaling stelsel deur te leer van bestaande menslike korreksies van verskillende setinge. Hierdie jaar het die uitdrukking bestaan van die opstelling van die foute wat in Engelse Wikipedia voorsien is, vertaal na Duitse en Sjinees deur staat-van die kuns, nie domein-aanpasde neurale MT (NMT) stelsels onbekende aan deelnaders nie. Ses teams het in die Engelse-Duitse taak gedeel en 'n totaal 11 loop aangestuur. Twee teams het gedeel in die Engels-Sjinese taak wat 2 loop elke. Dus i) die verskillende bron/domein van data vergelyk met die verlede (Wikipedia teen Informasie Tehnologie), ii) die verskillende kwaliteit van die aanvanklike vertalings om korrigeer te word en iii) die inligting van 'n nuwe taal paar (Engels-Sjinese), hierdie jaar se resultate i s nie direk vergelykbaar met die laaste jaar se rond nie. Maar, op beide taal rigtings vertoon die onderskrifte van deelnaders betekende verbeteringe oor die basilyn resultate. Op Engels-Duits, die boonste rangeerde stelsel verbeter oor die basisline deur -11,35 TER en +16,68 BLES punte, terwyl op Engelske Sjinese die verbeteringe is respektief tot -12,13 TER en +14,57 BLEU punte. Oorsaaklik, koherente verkrywings word ook verlig deur die outcome van die menslike evaluering, wat bevestig die effektiviteit van APE om MT-kwaliteit te verbeter, veral in die nuwe generieke domein gekies vir hierdie jaar se ronde.", 'am': "በMT አውቶማቲካዊ ፖት-አስተካክል ላይ የWMT ስራውን የስድስተኛው ዙሪያ ፍሬዎችን እናቀርባታለን፡፡ The task consists in automatically correcting the output of a 'black-box' machine translation system by learning from existing human corrections of different sentences.  በዚህች ዓመት ግንኙነት በንግግሊዝኛ Wikipedia ገጾች ውስጥ ያሉትን ስህተቶችን በመሠረት፣ በግርማዊ እና ቻይናዊ ገጾች በሀገር-የፊተኛ አርእስት፣ ዶሜን-አቀማጠለ ነዌራዊ MT (NMT) ስርዓቶች ሳይታወቁ ነው፡፡ ስድስት ቡድን በሙሉ 11 ሮኖች በመስጠት እንግሊዘኛ-ጀርመን ሥራ ተጋጠሙ። Two teams participated in the English-Chinese task submitting 2 runs each.  ከቀድሞው (Wikipedia vs Information Technology), i i) የመጀመሪያው ትርጓሜዎች ማቀናጃ እና iii) አዲስ ቋንቋ ሁለት (እንግሊዘኛ-ቻይና) መግለጫ የተለየ ሀብት/ዶሜን የዚህ ዓመታው ፍጻሜ ባለፈው ዓመታት ክፍል ቀጥተኛ አይተካከሉም፡፡ ነገር ግን በሁለቱ ቋንቋ መንገዶች፣ ተጋሪዎቹ የጥያቄ ውጤቶች የበለጠ ትክክል ማድረግ ያሳያል፡፡ እንግሊዝኛ-ጀርመን፣ የደረጃ ደረጃዎች የደረጃ ደረጃዎች - 11.35 TER እና +16.68 BLEU points በመጠቀም ይሻላል፤ እንግሊዝኛ ቻይንኛ ተደጋጋፊዎች ግን -12.13 ቴር እና +14.57 BLEU points. በጠቅላላ፣ የሰው ማስታወቂያ ውጤት እንዲያረጋግጥ፣ ለዚህም ዓመታት በተመረጠው አዲስ የብሔራዊ አዲስ ዶሜን አካባቢ አካባቢ የAPE ጥቅም እንዲያበጅል ነው፡፡", 'az': "Biz WMT işinin 6. runun sonuçlarını MT Otomatik Post Editing üçün göstəririk. Bu iş, müxtəlif cümlələr arasındakı insanların düzəltmələrindən öyrənib 'qara-qutu' maşın çevirim sisteminin çıxışını otomatik düzəltməsindədir. Bu il, İngilizə Wikipedia sayfalarında Almanca və Çin ə çevirilən xətaları təyin etməkdə idi. İşkilərə tanımayan domain-adapted neural MT (NMT) sistemləri deyildir. Altı dəstə İngilizce-Alman işin ə katıldı, 11 dəstə istifadə edirdi. İki dəstə İngilizə-Çinlə işləri ilə birlikdə iki dəstə ilə birlikdə idi. I) əvvəlkilərin (Wikipedia vs Information Technology) ilə qarşılaşdığı müxtəlif məlumatların mənbəs i/domeini, ii) ilk dəyişiklik təkrarlarının müxtəlif keyfiyyətini düzəltməsi və iii) yeni dil çift (İngilizce-Çinli) təkrarlaması, bu ilin sonuçları son ilinin ətrafında düzgün müəyyən edilməz. Lakin hər iki dil tərəfində, iştirakçıların tərəfindən baz çətinlərin sonuçlarında çox yaxşılıqları göstərir. İngilizce-Almanca tərəfindən ən ən yüksək səf sistemi tərəfindən - 11,35 TER və +16,68 BLEU noktaları ilə yaxşılaşdırır, İngilizce Çinliyə tərəfində yaxşılıqlar -12,13 TER və +14,57 BLEU noktaları ilə. Bütün bunlar, həmçin in insan değerlendirməsinin sonuçları ilə birləşdirilmiş qənimətlərin MT keyfiyyətini yaxşılaşdırmağını təsdiqləyir, özlərinə də bu il üçün seçilmiş yeni generic domeində.", 'bn': "এমটিটি স্বয়ংক্রিয় পোস্ট সম্পাদকে ডিউএমটি কাজের ছয় রাউন্ডের ফলাফল আমরা উপস্থাপন করছি। বিভিন্ন বাক্স থেকে বিদ্যমান মানুষের সংশোধন থেকে জানানোর মাধ্যমে একটি 'কালো-বক্স' মেশিন অনুবাদ সিস্টেমের আউটপুট এই বছর, ইংরেজী উইকিপিডিয়া পাতায় যে সমস্ত ভুল সংস্কার করা হয়েছে তা জার্মান এবং চীনা পাতায় অনুবাদ করা হয়েছে তা জার্মানী এবং চীনা পাতায়, তা ডোমেইন-adapted নিউরেল এম ছয়টি দল ইংরেজী জার্মান কাজে অংশগ্রহণ করেছে, ১১ টি রান প্রদান করেছে। দুই দল ইংরেজী ও চীনা কাজে অংশগ্রহণ করেছে যারা প্রত্যেকটি দুটি চালাচ্ছে। কারণ আমি) অতীতের (উইকিপিডিয়া বিভিন্ন তথ্য প্রযুক্তি), ২) প্রথম অনুবাদের বিভিন্ন ধরনের মান সংশোধন এবং আই) নতুন ভাষার জোয়ার (ইংরেজী-চীনা) প্রথম ভাষার সূত্র/ডোমেইন, এই বছরের ফলাফল গত বছর তবে এই দুই ভাষার দিকে অংশগ্রহণকারীদের প্রদত্ত প্রদান করা হয়েছে বেসাইলাইনের ফলাফলের ব্যাপক উন্নতি দেখাচ্ছে। ইংরেজি-জার্মানে সেরা সিস্টেম-১১. সাধারণত, মানুষের মূল্যের ফলাফলের সাথে একত্রিত অর্জন তুলে ধরা হয়েছে, যা এপিএসের কার্যক্রম নিশ্চিত করেছে এমটি মান উন্নত করার জন্য, বিশেষ করে এই বছরের সারার্", 'ca': "Presentam els resultats de la sexta ronda de la tasca WMT en MT Automatic Post-Editing. La tasca consisteix en corregir automàticament la producció d'un sistema de traducció d'una caixa negra aprenent de correccions humanes existents de diferents frases. Aquest any, el repte consistia en corregir els errors presents a les pàgines angleses de Wikipedia traduïts en alemany i xinès per sistemes MT neural moderns i no adaptats al domini desconeguts pels participants. Seis equips van participar en la tasca anglo-alemanya, enviant un total d'onze carreres. Dos equips van participar en la tasca anglo-xinesa enviant 2 execucions cada. Due to i) the different source/domain of data compared to the past (Wikipedia vs Information Technology), ii) the different quality of the initial translations to be corrected and iii) the introduction of a new language pair (English-Chinese), this year's results are not directly comparable with last year's round.  Tot i així, en les dues direccions lingüístices, les presentacions dels participants mostren millors considerables en comparació amb els resultats basals. On English-German, the top ranked system improves over the baseline by -11.35 TER and +16.68 BLEU points, while on EnglishChinese the improvements are respectively up to -12.13 TER and +14.57 BLEU points.  En general, els resultats de l'evaluació humana també destaquen els guanys coherent s, que confirma l'eficacia de l'APE per millorar la qualitat del MT, especialment en el nou domini genèric seleccionat per aquest any.", 'sq': "Ne paraqesim rezultatet e raundit të gjashtë të detyrës WMT në MT Automatic Post-Editing. The task consists in automatically correcting the output of a 'black-box' machine translation system by learning from existing human corrections of different sentences.  This year, the challenge consisted of fixing the errors present in English Wikipedia pages translated into German and Chinese by state-ofthe-art, not domain-adapted neural MT (NMT) systems unknown to participants.  Six teams participated in the English-German task, submitting a total of 11 runs.  Two teams participated in the English-Chinese task submitting 2 runs each.  Për shkak të i) burimit/domenit të ndryshëm të të dhënave krahasuar me të kaluarën (Wikipedia vs Information Technology), ii) cilës i s ë së ndryshme të përkthimeve fillestare që duhet korrigjuar dhe iii) futjes së një çifti të ri gjuhësh (anglisht-kinez), rezultatet e këtij viti nuk janë drejtpërdrejt të krahasueshme me raundin e vitit të kaluar. However, on both language directions, participants' submissions show considerable improvements over the baseline results.  On English-German, the top ranked system improves over the baseline by -11.35 TER and +16.68 BLEU points, while on EnglishChinese the improvements are respectively up to -12.13 TER and +14.57 BLEU points.  Overall, coherent gains are also highlighted by the outcomes of human evaluation, which confirms the effectiveness of APE to improve MT quality, especially in the new generic domain selected for this year's round.", 'cs': 'Představujeme výsledky šestého kola WMT úlohy na MT Automatic Post-Editing. Úkol spočívá v automatické korekci výstupu strojového překladu systému "černé skříňky" učením se z existujících lidských oprav různých vět. Úkolem letošního roku bylo opravit chyby přítomné na anglických stránkách Wikipedie přeložené do němčiny a čínštiny pomocí nejmodernějších, nikoli doménově adaptovaných neuronových MT (NMT) systémů, které účastníci neznají. Šest týmů se zúčastnilo anglicko-německého úkolu, předložilo celkem jedenáct běhů. Na anglicko-čínském úkolu se podílely dva týmy, které každý z nich odeslal dvě běhy. Vzhledem k i) odlišnému zdroji/doméně dat ve srovnání s minulostí (Wikipedie vs Informační technologie), ii) odlišné kvalitě původních překladů, které mají být opraveny a iii) zavedení nového jazykového páru (anglicko-čínština), letošní výsledky nejsou přímo srovnatelné s loňským rokem. V obou jazykových směrech však podání účastníků vykazují významné zlepšení oproti základním výsledkům. U anglicko-němčiny se nejlépe hodnocený systém zlepšuje oproti základním bodům o -11.35 TER a +16.68 BLEU body, zatímco u angličtiny jsou zlepšení až do -12.13 TER a +14.57 BLEU bodů. Celkově soudržné zisky jsou také zdůrazněny výsledky hodnocení lidí, které potvrzují účinnost APE ke zlepšení kvality MT, zejména v nové generické oblasti vybrané pro letošní kolo.', 'hy': "We present the results of the 6th round of the WMT task on MT Automatic Post-Editing.  The task consists in automatically correcting the output of a 'black-box' machine translation system by learning from existing human corrections of different sentences.  Այս տարի մարտահրավերն այն էր, որ անգլերեն Վիքիփեդիայի էջերում գտնվող սխալները վերականգնվեցին գերմաներեն և չինական տեխնոլոգիաների միջոցով, ոչ թե բնագավառներով հարմարեցված նյարդային MT (NMT) համակարգերի միջոցով, որոնք մասնակիցնե Six teams participated in the English-German task, submitting a total of 11 runs.  Two teams participated in the English-Chinese task submitting 2 runs each.  Due to i) the different source/domain of data compared to the past (Wikipedia vs Information Technology), ii) the different quality of the initial translations to be corrected and iii) the introduction of a new language pair (English-Chinese), this year's results are not directly comparable with last year's round.  Այնուամենայնիվ, երկու լեզվի ուղղություններում մասնակիցների ներկայացումները ցույց են տալիս նշանակալի բարելավումներ հիմնական արդյունքների համեմատ: On English-German, the top ranked system improves over the baseline by -11.35 TER and +16.68 BLEU points, while on EnglishChinese the improvements are respectively up to -12.13 TER and +14.57 BLEU points.  Overall, coherent gains are also highlighted by the outcomes of human evaluation, which confirms the effectiveness of APE to improve MT quality, especially in the new generic domain selected for this year's round.", 'et': 'Esitleme WMT ülesande 6. vooru tulemusi MT automaatse järeltöötluse kohta. Ülesanne seisneb mustast kastist masintõlkesüsteemi väljundi automaatses parandamises, õppides erinevate lausete olemasolevatest inimlikest parandustest. Sel aastal seisnes väljakutseks saksa ja hiina keelde tõlgitud Vikipeedia ingliskeelsetel lehekülgedel esinevate vigade parandamine osalejatele tundmatute kaasaegsete, mitte domeeniga kohandatud neuraalsete MT (NMT) süsteemide abil. Inglise-saksa ülesandes osales kuus meeskonda, kes esitasid kokku 11 jooksu. Inglise-Hiina ülesandes osalesid kaks meeskonda, kes esitasid igaühele 2 jooksu. Kuna i) andmeallikas/valdkond on varasemaga võrreldes erinev (Vikipeedia vs Infotehnoloogia), ii) parandatavate esialgsete tõlkete erinev kvaliteet ja iii) uue keelepaari (inglise-hiina) kasutuselevõtt ei ole selle aasta tulemused otseselt võrreldavad eelmise aasta vooruga. Mõlemas keelesuunas on osalejate esitatud märkimisväärselt paranenud võrreldes lähtetulemustega. Inglise-saksa keeles paraneb kõige paremini hinnatud süsteem võrreldes lähtetasemega -11,35 TER ja +16,68 BLEU punkti võrra, samas kui inglise keeles on paranemine vastavalt kuni -12,13 TER ja +14,57 BLEU punkti. Üldiselt rõhutavad ühtset kasu ka inimhindamise tulemused, mis kinnitavad APE tõhusust MT kvaliteedi parandamisel, eriti uues üldises valdkonnas, mis valitakse käesoleva aasta vooruks.', 'fi': 'Esittelemme WMT-tehtävän 6. kierroksen tulokset MT Automatic Post-Editing -osiossa. Tehtävänä on korjata automaattisesti mustan laatikon konekäännösjärjestelmän tuotos oppimalla olemassa olevista ihmisen korjauksista eri lauseisiin. Tänä vuonna haasteena oli korjata englanninkielisten Wikipedia-sivujen virheet, jotka käännettiin saksaksi ja kiinaksi osallistujille tuntemattomien huipputekniikan, ei domain-adaptoitujen neuro-MT (NMT) -järjestelmien avulla. Englannin ja Saksan väliseen tehtävään osallistui kuusi joukkuetta, jotka tekivät yhteensä 11 juoksua. Kaksi joukkuetta osallistui englanti-kiinalaiseen tehtävään tekemällä kukin 2 juoksua. Koska i) tietolähteet/toimialueet poikkeavat aikaisempaan verrattuna (Wikipedia vs. tietotekniikka), ii) korjattavien alkuperäisten käännösten laatu vaihtelee ja iii) uuden kieliparin (englanti-kiina) käyttöönotto, tämän vuoden tulokset eivät ole suoraan vertailukelpoisia viime vuoden kierroksen kanssa. Kummankin kielisuunnan osalta osallistujien lausunnot ovat kuitenkin parantuneet huomattavasti lähtötilanteen tuloksiin verrattuna. Englanninkielisessä ja saksassa korkeimmalla sijalla oleva järjestelmä paranee lähtötasoon verrattuna -11,35 TER-pistettä ja +16,68 BLEU-pistettä, kun taas englantikiinassa parannukset ovat jopa -12,13 TER-pistettä ja +14,57 BLEU-pistettä. Yleisesti ottaen johdonmukaisia hyötyjä korostavat myös ihmisten arvioinnin tulokset, jotka vahvistavat APE:n tehokkuuden MT:n laadun parantamisessa erityisesti uudella yleisluonteisella alalla, joka on valittu tämän vuoden kierrokselle.', 'bs': "Predstavljamo rezultate 6. runde WMT zadatka na automatskom posledištu MT-a. Taj zadatak se sastoji u automatskom korištenju izlaza sustava prevoda mašine 'crne kutije' učeći od postojećih ljudskih korekcija različitih rečenica. Ove godine je izazov sastavio od popravljanja grešaka na engleskim Wikipedijskim stranicama prevedena na njemačke i kineske državnim umjetničkim sistemima, a ne na domenu prilagođenim neuralnim MT (NMT) sistemima nepoznatim učesnicima. Šest timova sudjelovalo je u engleskom-njemačkom zadatku, predajući ukupno 11 trka. Dva timova su sudjelovala u engleskom-kineskom zadatku koji podnosi 2 vode svaki. Zbog i) različitih izvora/domena podataka u usporedbi s prošlošću (Wikipedia protiv informacione tehnologije), ii) različitih kvaliteta početnih prevoda koje treba ispraviti i iii) uvođenje novog jezičkog parova (engleski kineski), rezultati ove godine nisu direktno usporedbeni s prošlogodišnjim krugom. Međutim, na obje jezičke upute, podaci učesnika pokazuju značajne poboljšanje u odnosu na početne rezultate. Na engleskom-njemačkom, najviši redoviti sistem se poboljšava preko početne linije za -11,35 TER i +16,68 BLEU to čke, a na engleskom kineskom su poboljšanja u odnosu na -12,13 TER i +14,57 BLEU točke. U cjelokupnom slučaju, također se naglašavaju saslušni dobiti rezultati ljudske procjene, koji potvrđuje učinkovitost APE-a za poboljšanje kvalitete MT-a, posebno u novom generičkom domenu odabranom za ovu godinu okrugu.", 'he': "אנחנו מציגים את תוצאות הסיבוב השישי של משימה WMT על MT פוסט אוטומטי עורך. The task consists in automatically correcting the output of a 'black-box' machine translation system by learning from existing human corrections of different sentences.  This year, the challenge consisted of fixing the errors present in English Wikipedia pages translated into German and Chinese by state-ofthe-art, not domain-adapted neural MT (NMT) systems unknown to participants.  שישה קבוצות השתתפו במשימה אנגלית-גרמנית, שלחו בסך הכל 11 רצויות. Two teams participated in the English-Chinese task submitting 2 runs each.  בגלל i) המקור/שדה שונה של נתונים בהשוואה לעבר (ויקיפדיה נגד טכנולוגיה מידע), ii) איכות שונה של התרגשות הראשוניות לתקן iii) הכניסה של זוג שפה חדש (אנגלי-סיני), התוצאות של השנה אינן ישירות שוואות עם סיבוב השנה שעברה. However, on both language directions, participants' submissions show considerable improvements over the baseline results.  On English-German, the top ranked system improves over the baseline by -11.35 TER and +16.68 BLEU points, while on EnglishChinese the improvements are respectively up to -12.13 TER and +14.57 BLEU points.  Overall, coherent gains are also highlighted by the outcomes of human evaluation, which confirms the effectiveness of APE to improve MT quality, especially in the new generic domain selected for this year's round.", 'sk': 'Predstavljamo rezultate 6. kroga naloge WMT na MT samodejnem post-urejanju. Naloga vključuje samodejno popravljanje rezultatov sistema strojnega prevajanja "črne škatle" z učenjem iz obstoječih človeških popravkov različnih stavkov. Letos je bil izziv popravljanje napak, prisotnih na angleških Wikipedijskih straneh, prevedenih v nemščino in kitajščino, po najsodobnejših, ne domensko prilagojenih nevronskih MT (NMT) sistemih, ki jih udeleženci ne poznajo. V angleško-nemški nalogi je sodelovalo šest ekip, ki so jih skupaj oddali 11 tekov. Pri angleško-kitajski nalogi sta sodelovali dve ekipi, ki sta poslali po 2 teku. Zaradi i) različnega vira/domena podatkov v primerjavi s preteklostjo (Wikipedija proti informacijski tehnologiji), ii) različne kakovosti začetnih prevodov, ki jih je treba popraviti, in iii) uvedbe novega jezikovnega pare (angleščina-kitajščina), letošnji rezultati niso neposredno primerljivi z lanskim krogom. Vendar pa v obeh jezikovnih smereh prijave udeležencev kažejo precejšnje izboljšave v primerjavi z osnovnimi rezultati. V angleško-nemščini se najbolj uvrščeni sistem izboljša glede na izhodišče za -11,35 točke TER in +16,68 točke BLEU, v angleščini kitajščini pa so izboljšave do -12,13 točke TER in +14,57 točke BLEU. Na splošno skladne koristi poudarjajo tudi rezultati ocenjevanja ljudi, ki potrjujejo učinkovitost APE za izboljšanje kakovosti MT, zlasti na novem generičnem področju, izbranem za letošnji krog.', 'ha': "Munã halatar da fassaran na 6 na aikin WMT kan MT farat Editing Kayan aiki na ƙunsa da gyare na tsari farat ɗaya na tsari na tsarin tsarin mai shiryarwa na 'boxen-baƙi' da aka sanar da shi daga tsarin mutane masu buƙata. Yin shekara, shirin ya ƙunsa da kure masu gaba cikin harshen Wikimedia pages waɗanda aka fassara zuwa jeruman da China na rubutu, kuma ba da daidain-adaptan neural MT (NMT) system-waɗanda ba'a sani ba. Team 6 sun yi shirin aiki na Ingiriya-Jarman, kuma suka sami tare da jama'a 11 runs. Team biyu suka yi shirin aiki na Ingiriya-China wanda suka bãyar da 2 na tafiyar kõwane. Dukan da aka sammenliki masu yinin data da suka shige (Wikimedia vers information Technical), i i) da nau'in fassarar farko da za'a riga kuma (i) ya introduce wani nau'in harshen sau biyu (Inglizi-China), matsalan wannan bai sami daidai da runnin shekara ta shige. Haƙĩƙa, a kan shiryarwa biyu na harshe, masu gabatar da mushirikai na nuna mafiya ƙari masu girma a matsalan basuɗe. Ga Ingiriya-Jarman, surar ta sarki ya baza ta rufe maimakon da -11.35 TeR da+166.68 BLEU points, kuma a lokacin English, musamman za'a samu-12.13 TeR da+14.57 BLEU points. A jumla, ana ƙayyade fatauci na sambawa da matsayin rabon mutane, mai gaskata Effekt na Apple ta canza tsarin MT, da kuma haske a cikin shekara na yanzu-daman da aka zãɓe wa shekarar wannan shekara.", 'bo': "ང་ཚོས་ MT རང་འགུལ་གྱིས་ཞུན་དག་པ་ཐོག་ལས་ WMT དུས་བཀོལ་གྱི་རྗེས་ཐོག་གི་ཚབ་ལྗོངས་༦པ་ལ་སྟོན་པ། བྱ་འགུལ་འདི་ལ་རང་འགུལ་གྱིས་གནད་ཅིག་གནད་ཡིག་ཆའི་མ་ལག་གི་ཡིག་སྒྲུབ་གྱི་ནང་འཁོར་བ་བསྒྱུར་བཅོས་བྱེད་དུ་ཡོད་པ This year, the challenge consisted of fixing the errors present in English Wikipedia pages translated in to German and Chinese by state-ofthe-art, not domain-adapted neural MT (NMT) systems unknown to participants. དབུལ་གཞུང་གི་གནད་སྡུད་༦་དབུལ་ཡིག་ཆའི་ལས་ཀ་ལྟར་མཉམ་དུ་འགྲོ་བཞིན་ཡོད། ཚོ་ཁག་གཉིས་ཀྱིས་དབྱིན་ཡིག་དང་རྒྱ་ནག་གི་བྱ་སྤྱོད་ཀྱི་རེ་རེ་བཞིན་འགྲོ་བ་ཡིན། Due to i) the different source/domain of data compared to the past (Wikipedia vs Information Technology), ii) the different quality of the initial translations to be corrected and iii) the introduction of a new language pair (English-Chinese), this year's results are not directly comparable with last year's round. ཡིན་ནའང་། སྐད་ཡིག On English-German, the top ranked system improves over the baseline by -11.35 TER and +16.68 BLEU points, while on English Chinese the improvements are respectively up to -12.13 TER and +14.57 BLEU points. བསྡུར་བརྗོད་བྱས་པར། མཉམ་མཁན་གྱི་རྒྱལ་ཁབ་ཀྱིས་མིའི་དཔྱད་ལས་མཐོང་ནུས་ཀྱི་གནད་སྡུད་འདི་གི་རྒྱལ་ཁབ་སྐྱོར་བརྗོད་བྱེད་རྒྱུ་དང་།", 'jv': "We nyimpen ono wektu nggawe 6-uwong ning acara WmT ing MT Automatically After-Edit. Mampak sing ngewehi ditambah sistem 'bok-bok' sing otomatik yang dipoleh gambar nganggo perusahaan barang sampeyan karo kapan winih. Wis punika, aku sawar punika dipun nggawe nung akeh salamat kanggo tutunggal neng Peranci bukal bukal bukal ning alaman karo Cainan karo state-of-the-arts, ora domain-adaleteng Neral MT (NMT) sistem sing gak pawartos nang sampeyan ingkang sampeyan. Ana sampeyan sing nganggo barang Inggris-German, sampeyan nganggo 11 sampeyan. Grup durung sampeyan nganggo pawang Inggris-Chinese Tungé i) kayané pernik-pernik/domain dadi sing gawé nggawe karo terjamahan (wiipedya karo Informasi Teknôlogi), i ii) kalitas dianggawe tarjamahan sing dibutuhke tarjamahan karo iii) nggawe geranggap tarjamahan sing dibuté dhéwé (Genghis-Cinês), dadi sing paling dhéwé kuwi padha mêng, dibutêt karo padha tau sing Nanging, nggawe tarjamahan kanggo langkung sampeyan, tarjamahan kanggo ngerasah bantuan liyane Nanging Inggris-Geman, sistem sing paling-uwong telas telas telas telas telas nang -11.30 (telas)karo + 16.60 (blo), sampeyan nganggep Bukakipun, terus kanggo ngerayakno Hyang-Nggris sing bisa dianggo nyebute sampek kang -12.13 (telas) lan + 14.75 (blek). Diwong-wong, koweke nglanggar sampeyan nguasahan kelas nggawe barang kamu nggawe barang uwong, iki dipeneksi aplikasi Jaakan kanggo ngilanggar kalitas MT, ngomong dipeneksi barêng langgar sing gewuterus tambah sing paling dhéwé."}
{'en': 'Results of the WMT20 Metrics Shared Task', 'es': 'Resultados de la tarea compartida de métricas de WMT20', 'fr': 'Résultats de la tâche partagée WMT20 Metrics', 'pt': 'Resultados da tarefa compartilhada de métricas do WMT20', 'ar': 'نتائج مهمة مقاييس WMT20 المشتركة', 'hi': 'WMT20 मैट्रिक्स साझा कार्य के परिणाम', 'zh': 'WMT20 指标共其事', 'ja': 'WMT 20メトリクス共有タスクの結果', 'ru': 'Результаты совместной задачи по метрикам WMT20', 'ga': 'Torthaí Thasc Comhroinnte Méadracht WMT20', 'ka': 'WMT20 მეტრიკის გაყოფილი დავალების შედეგი', 'el': 'Αποτελέσματα της κοινής εργασίας μετρήσεων WMT20', 'it': "Risultati dell'attività condivisa WMT20 Metrics", 'lt': 'WMT20 metro bendros užduoties rezultatai', 'hu': 'A WMT20 Metrics megosztott feladat eredményei', 'ms': 'Hasil Tugas Berkongsi Metriks WMT20', 'ml': 'WMT20 മെറ്റിക്സ് പങ്കുചേര്\u200dത്ത ജോലിയുടെ ഫലങ്ങള്\u200d', 'kk': 'WMT20 метрикалық ортақтастырылған тапсырманың нәтижесі', 'mn': 'WMT20 метрик хуваалтын ажлын үр дүн', 'pl': 'Wyniki wspólnego zadania wspólnego z metrykami WMT20', 'mk': 'Results of the WMT20 Metrics Shared Task', 'ro': 'Rezultatele sarcinii partajate WMT20 Metrics', 'sr': 'Rezultati delovanog zadataka WMT20 metrika', 'mt': 'Riżultati tal-Kompitu Konġunt tal-Metriki tad-WMT20', 'sv': 'Resultat av den delade uppgiften WMT20 Metrics', 'si': 'WMT20 මෙට්\u200dරික්ස් සමාගත වැඩේ ප්\u200dරතිපත්තිය', 'no': 'Resultat av delt oppgåve WMT20 metrisk', 'so': 'Results of the WMT20 Metrics Shared Task', 'ta': 'WMT20 மீட்ரிக்கள் பகிர்ந்த பணியின் முடிவுகள்', 'ur': 'WMT20 متریک شریک ٹاکس کے نتائج', 'uz': 'Name', 'vi': 'Kết quả của công việc chia sẻ WM 2', 'hr': 'Rezultati zajedničkog zadatka WMT20 metrika', 'nl': 'Resultaten van de gedeelde taak WMT20 Metrics', 'de': 'Ergebnisse der gemeinsamen Aufgabe WMT20 Metrics', 'ko': 'WMT20 지표 공유 작업의 결과', 'id': 'Hasil Tugas Bersama Metrik WMT20', 'fa': 'نتیجه کار مشترک WMT20 متریک', 'tr': 'WMT20 metrik Mazmunlar Gözmesiniň netijesi', 'da': 'Resultater af WMT20 Metrics delte opgave', 'af': 'Resultate van die WMT20 metries deelde taak', 'sq': 'Rezultatet e detyrës së përbashkët të WMT20 Metrics', 'sw': 'Matokeo ya mbinu za WMT20 zilizoshiriki kazi', 'am': 'የWMT20 Metrics Shared Task Results', 'hy': 'Results of the WMT20 Metrics Shared Task', 'az': 'WMT20 metrik paylaşılan işlərin sonuçları', 'bn': 'WMT20 মিট্রিক শেয়ার করা কাজের ফলাফল', 'bs': 'Rezultati delovanog zadatka WMT20 metrika', 'ca': 'Results of the WMT20 Metrics Shared Task', 'et': 'WMT20 meetrite jagatud ülesande tulemused', 'fi': 'WMT20-mittareiden jaetun tehtävän tulokset', 'bg': 'Резултати от споделената задача за метрици WMT20', 'cs': 'Výsledky sdílené úlohy metrik WMT20', 'sk': 'Rezultati skupnega opravila meritev WMT20', 'ha': 'Result of the WMT20 Metrics Shared Taaikin', 'he': 'תוצאות המשימה המשותפת WMT20', 'bo': 'WMT2ཚད་རྩིས་བརྗོད་པའི་བྱ་འགུལ་གྱི་གྲུབ་འབྲས་མངོན་པ', 'jv': 'Validity sing uwong kelompok WB2Metric'}
{'en': 'This paper presents the results of the WMT20 Metrics Shared Task. Participants were asked to score the outputs of the translation systems competing in the WMT20 News Translation Task with automatic metrics. Ten research groups submitted 27 metrics, four of which are reference-less metrics. In addition, we computed five baseline metrics, including sentBLEU, BLEU, TER and using the SacreBLEU scorer. All metrics were evaluated on how well they correlate at the system-, document- and segment-level with the WMT20 official human scores. We present an extensive analysis on influence of different reference translations on metric reliability, how well automatic metrics score human translations, and we also flag major discrepancies between metric and human scores when evaluating MT systems. Finally, we investigate whether we can use automatic metrics to flag incorrect human ratings.', 'ar': 'تقدم هذه الورقة نتائج مهمة المقاييس المشتركة WMT20. طُلب من المشاركين تسجيل مخرجات أنظمة الترجمة المتنافسة في مهمة ترجمة الأخبار WMT20 باستخدام مقاييس تلقائية. قدمت عشر مجموعات بحثية 27 مقياسًا ، أربعة منها عبارة عن "مقاييس" أقل مرجعية. بالإضافة إلى ذلك ، قمنا بحساب خمسة مقاييس أساسية ، بما في ذلك sentBLEU و BLEU و TER واستخدام مسجل SacreBLEU. تم تقييم جميع المقاييس على أساس مدى ارتباطها على مستوى النظام والوثيقة والجزء مع الدرجات البشرية الرسمية WMT20. نقدم تحليلاً شاملاً حول تأثير الترجمات المرجعية المختلفة على موثوقية القياس ، ومدى نجاح المقاييس التلقائية في تحقيق الترجمات البشرية ، كما أننا نضع علامة على التناقضات الرئيسية بين الدرجات المترية والبشرية عند تقييم أنظمة الترجمة الآلية. أخيرًا ، نتحرى ما إذا كان بإمكاننا استخدام المقاييس التلقائية للإبلاغ عن التقييمات البشرية غير الصحيحة.', 'es': 'Este documento presenta los resultados de la tarea compartida de métricas de WMT20. Se pidió a los participantes que calificaran los resultados de los sistemas de traducción que competían en la tarea de traducción de noticias WMT20 con métricas automáticas. Diez grupos de investigación presentaron 27 métricas, cuatro de las cuales son «métricas» sin referencia. Además, calculamos cinco métricas de referencia, incluidas SentBleu, BLEU, TER y el marcador SacreBleu. Todas las métricas se evaluaron en función de qué tan bien se correlacionan a nivel de sistema, documento y segmento con los puntajes humanos oficiales del WMT20. Presentamos un análisis exhaustivo sobre la influencia de las diferentes traducciones de referencia en la confiabilidad de las métricas, cómo las métricas automáticas califican las traducciones humanas, y también detectamos discrepancias importantes entre las puntuaciones métricas y humanas al evaluar los sistemas de MT. Por último, investigamos si podemos usar métricas automáticas para marcar valoraciones humanas incorrectas.', 'fr': "Cet article présente les résultats de la tâche partagée WMT20 Metrics. Les participants ont été invités à noter les résultats des systèmes de traduction en compétition dans la tâche de traduction des nouvelles du WMT20 avec des métriques automatiques. Dix groupes de recherche ont soumis 27 mesures, dont quatre sont des «\xa0métriques\xa0» sans référence. De plus, nous avons calculé cinq mesures de base, y compris SentBleu, BLEU, TER et en utilisant le score SacreBleu. Toutes les mesures ont été évaluées en fonction de leur corrélation au niveau du système, du document et du segment avec les scores humains officiels du WMT20. Nous présentons une analyse approfondie de l'influence des différentes traductions de référence sur la fiabilité des métriques, de la façon dont les métriques automatiques évaluent les traductions humaines, et nous signalons également les écarts majeurs entre les scores métriques et humains lors de l'évaluation des systèmes de TA. Enfin, nous cherchons à savoir si nous pouvons utiliser des mesures automatiques pour signaler des évaluations humaines incorrectes.", 'pt': 'Este artigo apresenta os resultados da Tarefa Compartilhada de Métricas do WMT20. Os participantes foram solicitados a pontuar os resultados dos sistemas de tradução que competem na Tarefa de Tradução de Notícias do WMT20 com métricas automáticas. Dez grupos de pesquisa submeteram 27 métricas, quatro das quais são “métricas” sem referência. Além disso, computamos cinco métricas de linha de base, incluindo sentBLEU, BLEU, TER e usando o scorer SacreBLEU. Todas as métricas foram avaliadas em quão bem elas se correlacionam no nível do sistema, documento e segmento com as pontuações humanas oficiais do WMT20. Apresentamos uma extensa análise sobre a influência de diferentes traduções de referência na confiabilidade da métrica, quão bem as métricas automáticas pontuam as traduções humanas e também sinalizamos as principais discrepâncias entre as pontuações métricas e humanas ao avaliar os sistemas de MT. Por fim, investigamos se podemos usar métricas automáticas para sinalizar classificações humanas incorretas.', 'zh': '本文言WMT20指标共事也。 参与者自指标WMT20新闻译者争输评分。 十小组27指标,四曰指标。 计其五基线指标, sentBLEU、BLEU、TER 、用 SacreBLEU 评分器。 凡指标皆以系统、文档、细分级与WMT20官人分数之相关性而质之。 博论异指标可靠性,自指标人工之评分,论机器翻译统指标评分之大异也。 最后,我们勘得不用自己指标来标记不是人工评级。', 'ru': 'В настоящем документе представлены результаты совместной задачи по метрикам WMT20. Участников попросили оценить результаты систем перевода, конкурирующих в задаче перевода новостей WMT20 с автоматическими метриками. Десять исследовательских групп представили 27 метрик, четыре из которых являются «метриками» без ссылок. Кроме того, мы рассчитали пять базовых метрик, включая sentBLEU, BLEU, TER и с использованием показателя SacreBLEU. Все метрики оценивались по тому, насколько хорошо они коррелируют на системном, документарном и сегментном уровнях с официальными оценками WMT20 у человека. Мы представляем обширный анализ влияния различных эталонных переводов на надежность метрик, как хорошо автоматические метрики оценивают человеческие переводы, а также отмечаем значительные расхождения между метрическими и человеческими оценками при оценке систем MT. Наконец, мы выясняем, можем ли мы использовать автоматические метрики, чтобы отметить неверные оценки людей.', 'ja': '本稿では、WMT 20メトリクス共有タスクの結果を紹介する。参加者は、WMT 20ニュース翻訳タスクで競合する翻訳システムの出力を自動指標でスコアリングするように求められました。10の研究グループが27の指標を提出し、そのうち4つは参照なしの「指標」です。さらに、SacreBLEUスコアラーを使用して、sentBLEU、BLEU、TERを含む5つのベースラインメトリックを計算しました。すべての指標は、システム、文書、およびセグメントレベルでWMT 20公式のヒトスコアとどの程度相関があるかについて評価された。私たちは、さまざまな参照翻訳がメトリクスの信頼性に与える影響、自動メトリクスが人間の翻訳をどの程度良くスコアリングするかに関する広範な分析を提示し、また、MTシステムを評価するときにメトリクスと人間のスコアの間の大きな相違に注意を払います。最後に、自動指標を使用して誤った人間の評価にフラグを立てることができるかどうかを調査します。', 'hi': 'यह पेपर WMT20 मैट्रिक्स साझा कार्य के परिणाम प्रस्तुत करता है। प्रतिभागियों को स्वचालित मैट्रिक्स के साथ WMT20 समाचार अनुवाद कार्य में प्रतिस्पर्धा करने वाले अनुवाद प्रणालियों के आउटपुट स्कोर करने के लिए कहा गया था। दस शोध समूहों ने 27 मीट्रिक प्रस्तुत किए, जिनमें से चार संदर्भ-रहित "मीट्रिक" हैं। इसके अलावा, हमने पांच बेसलाइन मैट्रिक्स की गणना की, जिसमें sentBLEU, BLEU, TER और SacreBLEU स्कोरर का उपयोग करना शामिल है। सभी मैट्रिक्स का मूल्यांकन इस बात पर किया गया था कि वे WMT20 आधिकारिक मानव स्कोर के साथ सिस्टम-, दस्तावेज़- और सेगमेंट-स्तर पर कितनी अच्छी तरह से सहसंबंधित हैं। हम मीट्रिक विश्वसनीयता पर विभिन्न संदर्भ अनुवादों के प्रभाव पर एक व्यापक विश्लेषण प्रस्तुत करते हैं, कि स्वचालित मीट्रिक मानव अनुवाद को कितनी अच्छी तरह से स्कोर करते हैं, और हम एमटी सिस्टम का मूल्यांकन करते समय मीट्रिक और मानव स्कोर के बीच प्रमुख विसंगतियों को भी ध्वजांकित करते हैं। अंत में, हम जांच करते हैं कि क्या हम गलत मानव रेटिंग को ध्वजांकित करने के लिए स्वचालित मीट्रिक का उपयोग कर सकते हैं।', 'ga': 'Cuireann an páipéar seo i láthair torthaí Thasc Comhroinnte Méadracht WMT20. Iarradh ar rannpháirtithe aschuir na gcóras aistriúcháin atá san iomaíocht i dTasc Aistriúcháin Nuachta WMT20 a scóráil le méadracht uathoibríoch. Chuir deich ngrúpa taighde 27 méadracht isteach, agus is “méadracht” gan tagairtí iad ceithre cinn díobh. Ina theannta sin, rinneamar cúig mhéadracht bhonnlíne a ríomh, lena n-áirítear sentBLEU, BLEU, TER agus úsáid a bhaint as scóróir SacreBLEU. Rinneadh measúnú ar gach méadracht ar cé chomh maith agus a chomhghaolaíonn siad ag leibhéal an chórais, na doiciméid agus na míre le scóir dhaonna oifigiúla WMT20. Cuirimid i láthair anailís fhairsing ar thionchar na n-aistriúchán tagartha éagsúla ar iontaofacht mhéadrachta, cé chomh maith agus a scórálann méadracht uathoibríoch aistriúcháin dhaonna, agus tugaimid faoi deara freisin neamhréireachtaí móra idir scóir mhéadracha agus daonna agus córais MT á meas. Ar deireadh, déanaimid imscrúdú an féidir linn méadracht uathoibríoch a úsáid chun rátálacha daonna míchearta a chur in iúl.', 'hu': 'Ez a tanulmány bemutatja a WMT20 Metrics Shared Task eredményeit. A résztvevőket arra kérték, hogy a WMT20 News Translation Task keretében versenyző fordítási rendszerek eredményeit automatikus mérőszámokkal értékeljék. Tíz kutatócsoport 27 mutatót nyújtott be, amelyek közül négy referencia nélküli "mutatót". Ezenkívül öt alapvető mutatót számítottunk ki, beleértve a sentBLEU, BLEU, TER és a SacreBLEU scorer használatát. Az összes mutatót kiértékeltük annak alapján, hogy mennyire korrelálnak rendszer-, dokumentum- és szegmensszinten a WMT20 hivatalos humán pontszámokkal. Átfogó elemzést mutatunk be a különböző referencia-fordítások metrikus megbízhatóságra gyakorolt hatásáról, az automatikus mérőszámok mennyire pontoznak az emberi fordításokra, valamint a metrikus és emberi pontszámok közötti jelentős eltérésekről az MT rendszerek értékelésekor. Végül megvizsgáljuk, hogy automatikus mutatókat használhatunk-e a helytelen emberi minősítések megjelölésére.', 'ka': "Name დაწყვეტილებელი მოთხოვნილია, რომ WMT20 ახალი გადაწყვეტილების რაოდენობაში ავტომატიკური მეტრიკის შემდეგ გადაწყვეტილება. 10 შესწავლობის ჯგუფები 27 მეტრიკის გადატანა, ოთხი მათგანი არაფერი 'მეტრიკი'. დამატებით, ჩვენ დავწერეთ ხუთი ბაზლინური მეტრიკი, რომელიც sentBLEU, BLEU, TER და SacreBLEU წერტილის გამოყენება. ყველა მეტრიკის განსაზღვრება იყო თუ რამდენიმე კარგად ისინი სისტემის, დოკუმენტის და სეგმენტის დონე WMT20 ადამიანის მონაცემებით. ჩვენ განსხვავებული განსხვავებული განსხვავებული განსხვავებული განსხვავებების შესახებ მეტრიკური დარწმუნებელობაზე, რამდენი ავტომატიკური მეტრიკური განსხვავება ადამიანის განსხვავებაში, და ჩვენ ასევე გავიტანოთ საბოლოოდ, ჩვენ შევხედავთ თუ შეგვიძლია ავტომატური მეტრიკის გამოყენება, რომ ჩვენ შეცდომა ადამიანის რეტინგების შეცდომა.", 'el': 'Η παρούσα εργασία παρουσιάζει τα αποτελέσματα της κοινής εργασίας μετρήσεων WMT20. Ζητήθηκε από τους συμμετέχοντες να βαθμολογήσουν τα αποτελέσματα των μεταφραστικών συστημάτων που ανταγωνίζονται στο έργο μετάφρασης ειδήσεων με αυτόματες μετρήσεις. Δέκα ερευνητικές ομάδες υπέβαλαν 27 μετρήσεις, τέσσερις από τις οποίες είναι "μετρήσεις χωρίς αναφορά". Επιπλέον, υπολογίσαμε πέντε μετρήσεις βάσης, συμπεριλαμβανομένων των sentBLEU, BLEU, TER και χρησιμοποιώντας τον βαθμολογητή SacreBLEU. Όλες οι μετρήσεις αξιολογήθηκαν ως προς το πόσο καλά συσχετίζονται σε επίπεδο συστήματος, εγγράφου και τμήματος με τις επίσημες ανθρώπινες βαθμολογίες WMT20. Παρουσιάζουμε μια εκτενή ανάλυση σχετικά με την επίδραση των διαφορετικών μεταφράσεων αναφοράς στη μετρική αξιοπιστία, τον τρόπο με τον οποίο οι αυτόματες μετρήσεις βαθμολογούν ανθρώπινες μεταφράσεις και επισημαίνουμε επίσης σημαντικές αποκλίσεις μεταξύ μετρικών και ανθρώπινων βαθμολογιών κατά την αξιολόγηση συστημάτων ΜΤ. Τέλος, διερευνούμε αν μπορούμε να χρησιμοποιήσουμε αυτόματες μετρήσεις για να επισημάνουμε λανθασμένες ανθρώπινες αξιολογήσεις.', 'lt': 'Šiame dokumente pateikiami WMT20 Metrics bendros užduoties rezultatai. Dalyvių buvo paprašyta automatiškai įvertinti vertimo sistemų, konkuruojančių WMT20 naujienų vertimo užduotyje, rezultatus. Dešimt mokslinių tyrimų grupių pateikė 27 metrinius rodiklius, iš kurių keturios neturi nuorodų į "metrinius rodiklius". Be to, apskaičiuojome penkis pradinius rodiklius, įskaitant siunčiamą BLEU, BLEU, TER ir naudojant SacreBLEU rezultatorių. Visi rodikliai buvo įvertinti, kaip gerai jie koreliuoja sistemos, dokumentų ir segment ų lygiu su WMT20 oficialiais žmogaus rezultatais. Pateikiame išsamią įvairių vertimų įtakos metriniam patikimumui analizę, kiek gerai automatiniai metriniai rezultatai rodo žmogaus vertimus, taip pat nustatome didelius metrinių ir žmogaus rezultatų skirtumus vertinant MT sistemas. Galiausiai mes tiriame, ar galime naudoti automatinius rodiklius netinkamams žmogaus reitingams nustatyti.', 'kk': "Бұл қағаз WMT20 метрикалық ортақтастырылған тапсырманың нәтижесін көрсетеді. Қатысушыларға WMT20 жаңалық аудармалар тапсырмасында автоматты түрде метрикалық түрленген аудармалар жүйелердің шығысын есептеу сұралды. On research groups submitted 27 metrics, of which four are reference-less 'metrics'. Сонымен қатар, біз бес негізгі метрикалық есептеп, sentBLEU, BLEU, TER және SacreBLEU нүктеулерін қолданып тұрдық. Барлық метрикалар жүйе, құжат және сегмент деңгейінде WMT20 әкімші адамдардың нәтижелерімен қанша жақсы қатынау үшін бағалады. Біз метрикалық сенімділіктерінің әртүрлі сілтемелер аудармаларының қанша автоматтық метрикалық аудармаларының қанша жақсы талдауын көрсеткіздік, сондай-ақ метрикалық мен адамдардың соңында MT жүйелерін баға Соңында, біз автоматты метрикалық қолданатын адамдардың рейтинге дұрыс жалау үшін қолдануға болады.", 'ms': "Kertas ini memperkenalkan keputusan Tugas Berkongsi Metriks WMT20. Peserta diminta untuk skor output sistem terjemahan yang bersaing dalam Tugas Terjemahan Berita WMT20 dengan metrik automatik. Ten research groups submitted 27 metrics, four of which are reference-less 'metrics'.  Selain itu, kami menghitung lima metrik asas, termasuk sentBLEU, BLEU, TER dan menggunakan skor SacreBLEU. Semua metrik telah diuji bagaimana mereka berkorelasi dengan sistem, dokumen dan segmen-level dengan skor manusia rasmi WMT20. We present an extensive analysis on influence of different reference translations on metric reliability, how well automatic metrics score human translations, and we also flag major discrepancies between metric and human scores when evaluating MT systems.  Akhirnya, kita menyelidiki sama ada kita boleh menggunakan metrik automatik untuk menandai nilai manusia yang salah.", 'ml': 'ഈ പത്രത്തില്\u200d WMT20 മെറ്റിക്സ് പങ്കുചേര്\u200dത്ത ജോലിയുടെ ഫലങ്ങള്\u200d കാണിക്കുന്നു. പങ്കുകാരോട് ചോദിച്ചത് WMT20 വിവരങ്ങളുടെ ട്രാന്\u200dസിസ്റ്റമില്\u200d മത്സരിക്കുന്ന വിവരങ്ങളുടെ പുറത്തുകള്\u200d സ്കോര്\u200dട്ട് ചെയ്യ പത്തു പഠിക്കുന്ന ഗ്രൂപ്പുകള്\u200d 27 മെട്രിക്ക് സമ്മാനിച്ചിരിക്കുന്നു. അതില്\u200d നാലുപേര്\u200d മെറ്റിക്ക കൂടാതെ, ഞങ്ങള്\u200d അഞ്ച് ബേസ്ലൈന്\u200d മെട്രിക്കുകള്\u200d എണ്ണിച്ചു, സെന്\u200dറ്ബിലൂ, ബിലൂയു, ടെയര്\u200d, സാക്രീബിലൂയ് സ്കോര്\u200d ഉപയോഗിച്ച എല്ലാ മെട്രിക്കങ്ങളും വിലാസപ്പെടുത്തിയിരുന്നു. അവര്\u200d സിസ്റ്റത്തില്\u200d എത്ര നന്നായി ബന്ധപ്പെട്ടിരിക്കുന്നു-, രേഖകള്\u200d-  മെറ്റിക് വിശ്വാസത്തിന്റെ പ്രഭാവനത്തിന്റെ പ്രഭാവനത്തിന്റെ പ്രഭാവനത്തെക്കുറിച്ച് ഞങ്ങള്\u200d വിശാലമായ ഒരു അന്വേഷണം കൊടുക്കുന്നു. എംടി സിസ്റ്റത്തെ  അവസാനം, നമുക്ക് സ്വയം മെട്രിക്കങ്ങള്\u200d ഉപയോഗിക്കാന്\u200d പറ്റുമോ എന്ന് അന്വേഷിക്കാം.', 'it': 'Questo articolo presenta i risultati del WMT20 Metrics Shared Task. Ai partecipanti è stato chiesto di segnare i risultati dei sistemi di traduzione concorrenti nel WMT20 News Translation Task con metriche automatiche. Dieci gruppi di ricerca hanno presentato 27 metriche, quattro delle quali sono "metriche senza riferimento". Inoltre, abbiamo calcolato cinque metriche di base, tra cui sentBLEU, BLEU, TER e utilizzando il punteggio SacreBLEU. Tutte le metriche sono state valutate su quanto bene correlano a livello di sistema, documento e segmento con i punteggi umani ufficiali WMT20. Presentiamo un\'analisi approfondita sull\'influenza delle diverse traduzioni di riferimento sull\'affidabilità metrica, sul modo in cui le metriche automatiche segnano le traduzioni umane, e segnaliamo anche grandi discrepanze tra i punteggi metrici e umani nella valutazione dei sistemi MT. Infine, esaminiamo se possiamo utilizzare metriche automatiche per segnalare valutazioni umane errate.', 'no': 'Denne papiret viser resultatet av delt oppgåve i WMT20 metrikk. Deltakarane vart spurd om å rekna ut av omsetjingssystemet som konkurrer i WMT20 News Translation Task med automatisk metrika. Ten forskningsgrupper sendte 27 metriske, fire av dei er «metriske». I tillegg beregne vi fem baseline metrikar, inkludert sentBLEU, BLEU, TER og bruka SacreBLEU-poeng. Alle metrikane ble evaluerte på kor godt dei korrelaterte på systemet, dokumentet og segmentnivået med WMT20 offisielle menneskelige poeng. Vi presenterer eit utvida analyse på påvirkning av ulike referansoversettelsar på metrisk tryggleikskontroll, kor godt automatisk metriske skal score menneskelige oversettelsar, og vi flagg også store forskjeller mellom metriske og menneskelige poeng ved evaluering av MT-systemet. Etter slutt, vi undersøker om vi kan bruka automatiske metrikar for å flagga feil menneskeverdiar.', 'pl': 'W niniejszym artykule przedstawiono wyniki wspólnego zadania WMT20 Metrics Shared Task. Uczestnicy zostali poproszeni o ocenę wyników systemów tłumaczeniowych konkurujących w WMT20 News Translation Task z automatycznymi metrykami. Dziesięć grup badawczych przedstawiło 27 metryki, z których cztery są "metrykami bez referencji". Ponadto obliczyliśmy pięć wskaźników bazowych, w tym sentBLEU, BLEU, TER oraz za pomocą punktera SacreBLEU. Wszystkie wskaźniki zostały ocenione pod kątem ich korelacji na poziomie systemowym, dokumentowym i segmentowym z oficjalnymi wynikami ludzkimi WMT20. Przedstawiamy obszerną analizę wpływu różnych tłumaczeń referencyjnych na wiarygodność metryczną, jak dobrze automatyczne mierniki oceniają ludzkie tłumaczenia, a także identyfikujemy istotne rozbieżności między wynikami metrycznymi a ludzkimi podczas oceny systemów MT. Na koniec badamy, czy możemy użyć automatycznych wskaźników do oznaczania nieprawidłowych ocen ludzkich.', 'mk': 'This paper presents the results of the WMT20 Metrics Shared Task.  Учесниците беа побарани да ги оценат излезите на преводните системи кои се натпреваруваат во задачата за превод на вестите на WMT20 со автоматска метрика. Десет истражувачки групи поднесоа 27 метрики, од кои четири се безреферентни „метрики“. Покрај тоа, пресметавме пет основни метрики, вклучувајќи го и sentBLEU, BLEU, TER и користејќи го резултатот на SacreBLEU. Сите метрики беа проценети за тоа колку добро се корелираат на системско, документно и сегментно ниво со официјалните човечки оценки на ВМТ20. Презентираме екстремна анализа за влијанието на различните референциски преведувања на метричната доверливост, колку автоматски метрички оценки ги постигнуваат човечките преведувања, и исто така ги означуваме големите дискрепанции помеѓу метричките и човечките оценки при оценката Конечно, истражуваме дали можеме да користиме автоматска метрика за да означиме погрешни човечки оценки.', 'mt': 'Dan id-dokument jippreżenta r-riżultati tal-Kompitu Konġunt tal-Metriki WMT20. Il-parteċipanti ntalbu jagħmlu punteġġi fuq ir-riżultati tas-sistemi ta’ traduzzjoni li jikkompetu fil-Ħidma tat-Traduzzjoni tal-Aħbarijiet tad-WMT20 b’metriċi awtomatiċi. Għaxar gruppi ta’ riċerka ppreżentaw 27 metrika, li erbgħa minnhom huma ‘metriċi’ mingħajr referenza. Barra minn hekk, ikkalkulajna ħames metriċi bażi, inklużi sentBLEU, BLEU, TER u bl-użu tal-punteġġ SacreBLEU. Il-metriċi kollha ġew evalwati dwar kemm jikkorrelataw tajjeb fil-livell tas-sistema, tad-dokument u tas-segment mal-punteġġi uffiċjali tal-bniedem tad-WMT20. We present an extensive analysis on influence of different reference translations on metric reliability, how well automatic metrics score human translations, and we also flag major discrepancies between metric and human scores when evaluating MT systems.  Fl-aħħar nett, ninvestigaw jekk nistgħux nużaw metriċi awtomatiċi biex nimmarkaw klassifikazzjonijiet tal-bniedem mhux korretti.', 'mn': 'Энэ цаас WMT20 метрик хуваалтын ажлын үр дүнг харуулдаг. Хэрэглэгчдийн оролцогчдын WMT20 мэдээллийн орчуулах үйл ажиллагаанд автоматик метрикийн төлөө өрсөлдөг орчуулах системийн үр дүнг тооцоолох гэж асуусан. 10 судалгааны бүлгүүд 27 метрийг тавьсан. Тэдгээрийн дөрвөн нь "метрик" байхгүй. Мөн бид санBLEU, BLEU, TER болон SacreBLEU оноогчдыг ашиглаж таван суурь шугам метрийг тооцоолоо. Бүх метрик нь систем, баримт, загварын түвшинд хэр сайн холбоотой вэ гэдгийг баталсан. Бид метрийн итгэл итгэлтэй байдлын өөр өөр хариу төлөвлөгөөний нөлөөтэй талаар шинжилгээ үзүүлнэ. МТ системийг үнэлэхэд бид метрик болон хүн төрөлхтний тоонуудын хооронд маш их ялгаатай байдлыг харуулдаг. Эцэст нь, бид автоматически метрик ашиглаж хүн төрөлхтний дүрсийг буруу дүрсийг дүрслэх эсэхийг судалж болно.', 'si': "මේ පත්තුව WMT20 මෙට්\u200dරික්ස් කොටස් එක්ක වැඩේ ප්\u200dරතිචාරය පෙන්වනවා. අංශිකාරීන්ට කිව්වා WMT20 වාර්තාව වාර්තාව පද්ධතියේ ස්වයංක්\u200dරීය මෙට්\u200dරික්ස් එක්ක ස්වයංක්\u200dරීය විදියට පරීක්ෂණා කණ්ඩායම් දහයක් මෙට්\u200dරික් 27ක් දාලා තියෙනවා, ඒ වගේම හතරයි 'මෙට්\u200dරික්' කියලා. ඒ වගේම, අපි පස්සේ ප්\u200dරධාන මෙට්\u200dරික් පහක් ගණනය කළා, SenBLUE, BLUE, TER සහ සැක්රෙබ්ලූස් ප්\u200dරධාන පරික්ෂකය පා ඔක්කොම මෙට්\u200dරික්ස් විශ්වාස කරලා තියෙන්නේ ඔවුන් පද්ධතිය -, විස්තාරය- සහ සම්පූර්ණ- තත්වය WMT20 අධාරික ම අපි මෙට්\u200dරික් විශ්වාස විශ්වාසයේ විවිධ ප්\u200dරශ්නයක් ගැන ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා, කොච්චර ස්වයංක්\u200dරීය මෙට අන්තිමේදි, අපි පරීක්ෂණය කරන්න පුළුවන් කියලා, අපිට ස්වයංක්\u200dරීය මත්\u200dරය භාවිතා කරන්න පුළුවන් කි", 'sv': 'Denna uppsats presenterar resultaten av WMT20 Metrics Shared Task. Deltagarna ombads att få resultat från översättningssystemen som konkurrerade i WMT20 News Translation Task med automatiska mätvärden. Tio forskargrupper lämnade in 27 mätvärden, varav fyra är referensfria mätvärden. Dessutom beräknade vi fem basvärden, inklusive sentBLEU, BLEU, TER och med SacreBLEU scorer. Alla mätvärden utvärderades utifrån hur väl de korrelerar på system-, dokument- och segmentnivå med WMT20 officiella humanpoäng. Vi presenterar en omfattande analys av påverkan av olika referensöversättningar på metrisk tillförlitlighet, hur väl automatiska mätningar gör mänskliga översättningar, och vi flaggar också stora skillnader mellan metriska och mänskliga poäng när vi utvärderar MT-system. Slutligen undersöker vi om vi kan använda automatiska mätvärden för att flagga felaktiga mänskliga betyg.', 'ta': "WMT20 மெட்ரிக்ஸ் பகிர்ந்த பணியின் முடிவுகளை இந்த தாள் கூடுகிறது. WMT20 செய்தி மொழிபெயர்ப்பு பணியில் பொருத்தும் மொழிபெயர்ப்பு அமைப்புகளின் வெளியீடுகளை மதிப்பெடுக்க கேட்கப்பட்டுள Ten research groups submitted 27 metrics, four of which are reference-less 'metrics'.  மேலும், நாம் ஐந்து அடிப்படைகோட்டு மெட்ரிக்களை கணக்கிட்டோம், சென்ட்பிலி, பிலூயு, TER மற்றும் சாக்ரீபிலியு மதிப்பெண் அனைத்து மெட்ரிக்களும் முறைமையில் -, ஆவணம்- மற்றும் துண்டு மட்டத்தில் எவ்வளவு நன்றாக இணைக்கப்படும் என்பதை மதிப்பிடுகிறது WM மெட்ரிக் நம்பிக்கையின் மொழிப்பெயர்ப்புகளின் பாக்கியங்களை எவ்வாறு தானாகவே மெட்ரிக் மொழிபெயர்ப்புகளை மதிப்பிடும் என்பதை நாம் ஒரு விரிவான ஆய்வு கொடு இறுதியில், நாம் தானியங்கி மெட்ரிக்களை பயன்படுத்த முடியுமா என்று ஆராய்ச்சி செய்கிறோம் மனித விகிதத்தை", 'ro': 'Această lucrare prezintă rezultatele activității partajate WMT20 Metrics. Participanților li s-a cerut să înscrie rezultatele sistemelor de traducere concurente în cadrul WMT20 News Translation Task cu măsurători automate. Zece grupuri de cercetare au prezentat 27 de măsurători, dintre care patru sunt "măsurători" fără referință. În plus, am calculat cinci valori de bază, inclusiv sentBLEU, BLEU, TER și utilizând scorerul SacreBLEU. Toate măsurătorile au fost evaluate în funcție de cât de bine se corelează la nivel de sistem, document și segment cu scorurile umane oficiale WMT20. Prezentăm o analiză amplă asupra influenței diferitelor traduceri de referință asupra fiabilității metrice, cât de bine scorurile metrice automate scorează traducerile umane și, de asemenea, semnalăm discrepanțe majore între scorurile metrice și umane atunci când evaluăm sistemele MT. În cele din urmă, investigăm dacă putem folosi măsurători automate pentru a semnala evaluările umane incorecte.', 'so': 'Warqadan waxaa soo saara resultinta WMT20 Metrics Shared Shaqada. Ka qayb-qaadayaasha waxaa la weyddiiyey inay koobaan soo baxayaasha nidaamka turjumista ee ku qaybsan shaqooyinka turjumista WMT20 ee warqada turjumista ee WMT20 iyagoo isticmaalaya maamulka. Toban kooxood oo waxbarasho ah waxaa soo saaray 27 metric, waxaana ka mid ah afar kooxood oo ka yar ‘metric’. Waxaa kaloo aan xisaabnay shan metric oo hoose ah, kuwaas oo ah sentBLEU, BLEU, TER iyo isticmaalka sacreBLEU. Dhammaan metricooyinka waxaa lagu qiimeynayaa si fiican looga xiriiro nidaamka-, qoraalka- iyo qeybta iyo scoraha rasmiga ah ee WMT20. Anagaa sameynaya baaritaan aad u dheer oo saameyn ku saabsan tarjumaadyada kala duduwan ee ku saabsan aaminshaha metricka, sida ay automatiyadu u kooban yihiin turjumaadda dadka, sidoo kalena waxaynu baaraynaa qiimeynta waxyaabaha waaweyn ee u dhexeeya metric iyo scoraha dadka marka aan qiimeynayno nidaamka MT. Ugu dambaysta waxaynu baaraynaa in aan isticmaali karno qaababka maamulka ah si aan bangiyo qiimaha biniaadaha u khalad ah.', 'sr': 'Ovaj papir predstavlja rezultate podijeljenog zadatka WMT20 metrika. Učesnicima su zamolili da rezultate sustava prevoda koji se natječu u zadatku WMT20 novinskog prevoda sa automatskim metrikama. Deset istraživačkih grupa predali su 27 metrika, od kojih četiri su bez referencije "metrika". Osim toga, računali smo pet početnih metrika, uključujući sentBLEU, BLEU, TER i koristeći SacreBLEU rezultate. Sve metrike su procenile kako su dobro povezani na nivou sustava, dokumenta i segmenta sa zvaničnim ljudskim rezultatima WMT20. Predstavljamo ogromnu analizu na utjecaj različitih referentnih prevoda na metričku pouzdanost, koliko dobro automatski metrički rezultati ljudskih prevoda, a takođe zastupamo velike razlike između metričkih i ljudskih rezultata kada procjenjujemo MT sisteme. Konačno, istražujemo da li možemo koristiti automatsku metriku da zastavimo nepravedne ljudske ocjene.', 'ur': "This paper presents the results of the WMT20 Metrics Shared Task. شرکت کرنے والوں سے پوچھا گیا تھا کہ WMT20 نویس ترجمہ ٹاکس ٹاکس کے ساتھ آٹوٹ میٹریک کے ساتھ مسابقه کرنے والے ترجمہ سیسٹموں کے نتائج اسکور کریں۔ دس تحقیقات گروہوں نے 27 متریک مضبوط کیے، ان میں سے چار منظور بغیر 'متریک' ہیں۔ اس کے علاوہ ہم نے پانچ بنیاس لین متریک محاسبہ کردیا تھا، sentBLEU، BLEU، TER اور SacreBLEU scorer کے استعمال میں۔ سارے متریک کا ارزش کیا گیا تھا کہ وہ سیسٹم، دفتر اور سقم-سٹم-سٹم-سٹم کے ساتھ کس طرح اچھا تعلق ہے۔ ہم متریک اعتمادی پر مختلف فرقانوں کی تاثیر کے بارے میں ایک بڑی تحلیل پیش کریں گے، کیسے اپنا متریک متریک انسان کی تعلیمات کا اندازہ اچھا کرتا ہے، اور ہم متریک اور انسان کی اسکور کے درمیان بڑی اختلاف کریں گے جب MT سیستموں کا ارزش کرتے ہیں۔ آخر میں، ہم تحقیق کریں کہ کیا ہم انسان ریٹینگ غلط فیلگ کرنے کے لئے آٹوٹ میٹریک استعمال کر سکتے ہیں.", 'vi': "Tờ giấy này trình bày kết quả của công việc chia sẻ WM Metric0. Người tham gia được yêu cầu ghi kết quả của hệ thống dịch đang cạnh tranh trong Công tác Dịch Tin WM210 với âm lượng tử tự động. Mười nhóm nghiên cứu được cung cấp 72 metrics, bốn trong đó là'metrics'không phải là'metric'. Thêm vào đó, chúng tôi tính toán năm lượng tử lượng tử, bao gồm có lính gác, tiếng bíp, TER và dùng bảng điểm SacreLEU. Tất cả các âm lượng đã được đánh giá về mối liên hệ của hệ thống, tài liệu và tiểu đoạn với điểm số người của WM20. Chúng tôi đưa ra một phân tích tích tích rộng về ảnh hưởng của những dịch biến số khác nhau về tỉ lệ đáng tin cậy, tỉ lệ đo tử tự động ghi được nhiều bản dịch con người, và chúng tôi cũng nhận thấy sự khác biệt lớn giữa điểm đo mét và người khi đánh giá hệ thống MTV. Cuối cùng, chúng tôi cũng điều tra liệu chúng tôi có thể dùng âm lượng chính xác để đánh giá sai người.", 'uz': "Name @ info: whatsthis 10 ta taʼminlovchi guruhi 27 metrik gacha qoʻshilgan, ulardan to'rtta 'metrik' ma'lumot yoʻq. In addition, we computed five baseline metrics, including sentBLEU, BLEU, TER and using the SacreBLEU scorer.  Hamma metriklar WMT20 rasm oddiy foydalanuvchi darajada qanday bog'lash mumkin. Biz metrik ishonaligi, avtomatik metrik tarjimalarni inson tarjima qilishni qanday yaxshi ko'ra olamiz va biz MT tizimlarini qiymatlashda metrik va одамлар qiymatlari орасидаги eng muhim qiymatlarini bajaramiz. Oxirgi, biz inson rasmlarini noto'g'ri bilan avtomatik metriklardan foydalana olamiz.", 'bg': 'Настоящата статия представя резултатите от споделената задача за метрици WMT20. Участниците бяха помолени да оценят резултатите от системите за превод, състезаващи се в задачата за превод на новини с автоматични показатели. Десет изследователски групи представиха 27 показателя, четири от които са "показатели без референции". Освен това изчислихме пет базови показатели, включително и с помощта на резултата. Всички показатели бяха оценени за това колко добре те корелират на ниво система, документ и сегмент с официалните резултати за хора. Представяме обширен анализ на влиянието на различни референтни преводи върху надеждността на метричните показатели, колко добре автоматичните показатели оценяват човешките преводи, а също така отбелязваме големи несъответствия между метричните и човешките оценки при оценяването на системите. И накрая, изследваме дали можем да използваме автоматични показатели, за да маркираме неправилни оценки на хората.', 'hr': 'Ovaj papir predstavlja rezultate zajedničkog zadatka WMT20 metrika. Učesnicima su zamolili da rezultate sustava prevoda natječu u zadatku WMT20 novinskog prevoda s automatskim metrikama. Deset istraživačkih grupa podnelo je 27 metrika, od kojih četiri su bez referentnog "metrika". Osim toga, računali smo pet početnih metrika, uključujući sentBLEU, BLEU, TER i koristeći rezultate SacreBLEU-a. Sve metrike su procijenjene kako su dobro korelacije na razini sustava, dokumenta i segmenta s zvaničnim ljudskim rezultatima WMT20. Predstavljamo ogromnu analizu utjecaja različitih referentnih prevoda na metričku pouzdanost, koliko dobro automatski metrički rezultati ljudskih prevoda, i označavamo velike razlike između metričkih i ljudskih rezultata kada procjenjujemo MT sustave. Konačno, istražujemo da li možemo koristiti automatsku metriku kako bi zastavili nepravedne ljudske ocjene.', 'nl': "Dit artikel presenteert de resultaten van de WMT20 Metrics Shared Task. Deelnemers werden gevraagd om de outputs van de vertaalsystemen die concurreren in de WMT20 News Translation Task te scoren met automatische metrics. Tien onderzoeksgroepen hebben 27 metrics ingediend, waarvan vier referentieloze 'metrics' zijn. Daarnaast hebben we vijf baseline metrics berekend, waaronder sentBLEU, BLEU, TER en de SacreBLEU scorer. Alle statistieken werden geëvalueerd op hoe goed ze correleren op systeem-, document- en segmentniveau met de officiële WMT20 menselijke scores. We presenteren een uitgebreide analyse van de invloed van verschillende referentievertalingen op metrische betrouwbaarheid, hoe goed automatische metrics menselijke vertalingen scoren, en we signaleren ook grote verschillen tussen metrische en menselijke scores bij het evalueren van MT-systemen. Ten slotte onderzoeken we of we automatische statistieken kunnen gebruiken om onjuiste menselijke beoordelingen te markeren.", 'de': "Dieser Beitrag stellt die Ergebnisse der WMT20 Metrics Shared Task vor. Die Teilnehmer wurden gebeten, die Ergebnisse der im WMT20 News Translation Task konkurrierenden Übersetzungssysteme mit automatischen Metriken zu bewerten. Zehn Forschungsgruppen haben 27-Metriken eingereicht, von denen vier referenzlose 'Metriken' sind. Darüber hinaus haben wir fünf Basismetriken berechnet, darunter sentBLEU, BLEU, TER und der SacreBLEU Scorer. Alle Metriken wurden darauf ausgewertet, wie gut sie auf System-, Dokument- und Segmentebene mit den offiziellen WMT20 Human Scores korrelieren. Wir präsentieren eine umfassende Analyse des Einflusses verschiedener Referenzübersetzungen auf die Zuverlässigkeit von Metriken, wie gut automatische Metriken menschliche Übersetzungen bewerten, und wir identifizieren auch große Diskrepanzen zwischen metrischen und menschlichen Werten bei der Bewertung von MÜ-Systemen. Schließlich untersuchen wir, ob wir automatische Metriken verwenden können, um falsche menschliche Bewertungen zu kennzeichnen.", 'id': 'Kertas ini menunjukkan hasil dari Tugas Bersama Metrik WMT20. Peserta diminta untuk mencetak hasil dari sistem terjemahan yang bersaing dalam Tugas terjemahan berita WMT20 dengan metrik otomatis. Sepuluh kelompok penelitian mengirim 27 metrik, empat dari mereka adalah referensi-kurang metrik. Selain itu, kami menghitung lima metrik dasar, termasuk sentBLEU, BLEU, TER dan menggunakan skor SacreBLEU. Semua metrik diteliti seberapa baik mereka berkorelasi pada tingkat sistem, dokumen dan segmen dengan skor manusia resmi WMT20. Kami mempersembahkan analisis ekstensif tentang pengaruh dari terjemahan referensi yang berbeda pada kepercayaan metrik, seberapa baik metrik otomatis skor terjemahan manusia, dan kami juga menandai perbedaan besar antara skor metrik dan manusia ketika mengevaluasi sistem MT. Akhirnya, kita menyelidiki apakah kita dapat menggunakan metrik otomatis untuk menandai nilai manusia yang salah.', 'fa': 'این کاغذ نتیجه کار مشترک WMT20 متریک را نشان می دهد. شرکتگران از آن خواسته شد که نتیجه\u200cهای سیستم\u200cهای ترجمه\u200cکننده در مسابقه\u200cی ترجمه\u200cهای خبری WMT20 با متریک\u200cهای خودکار بررسی کنند. ده گروه تحقیقات 27 متری را ارسال کردند، چهار گروه از آن بی ارتباط "متریک". در addition, we computed five baseline metrics, including sentBLEU, BLEU, TER and using the SacreBLEU scorer. تمام متریک ها در مورد اینکه چقدر خوب در سیستم، سند و سطح بخش با امتیاز رسمی انسان WMT20 ارزیابی می کنند. ما یک تحلیل وسیع بر تأثیر ترجمه\u200cهای متفاوت بر اطمینان متریک نشان می\u200cدهیم، چقدر متریک\u200cهای اتوماتیک ترجمه\u200cهای انسان را دریافت می\u200cکنند، و همچنین ما جدایی بزرگی بین امتیاز متریک و انسان را در زمان ارزیابی سیستم\u200cهای MT را نشا بالاخره، ما تحقیق می\u200cکنیم که می\u200cتوانیم از متریک\u200cهای خودکار استفاده کنیم تا برچسب\u200cهای انسان غلط را پرچم کنیم.', 'sw': "Gazeti hili linaonyesha matokeo ya mbinu zilizoshirikishwa na WMT20. Washiriki waliulizwa kuchukua matokeo ya mifumo ya tafsiri yanayoshindana katika kazi ya Tafsiri ya Habari za WMT20 kwa njia za kujitegemea. Makundi kumi ya utafiti yaliwasilisha mita 27, kati yao wanne ni 'mitiri isiyo na maana'. Zaidi ya hayo, tulihesabu mbinu tano za msingi, ikiwa ni pamoja na sentBLEU, BLEU, TER na kutumia mchoro wa SacreBLEU. Tamko zote ziliangaliwa juu ya jinsi wanavyohusiana vizuri katika mfumo-, nyaraka- na ngazi za mchanganyiko na vipindi rasmi vya WMT20. Tunajaribu uchambuzi wa kina kuhusu ushawishi wa tafsiri tofauti za maoni juu ya uaminifu wa umeme, namna mbinu za automatika zinavyofafanua tafsiri za binadamu, na pia tunapanga ubaguzi mkubwa kati ya vipimo vya mafuta na watu wakati tunapopitia mfumo wa MT. Mwisho, tunachunguza kama tunaweza kutumia mbinu za kujitegemea ili kuingia bendera isiyo sahihi rasmi ya watu.", 'da': "Dette dokument præsenterer resultaterne af WMT20 Metrics Shared Task. Deltagerne blev bedt om at score output fra de oversættelsessystemer, der konkurrerede i WMT20 News Translation Task med automatiske målinger. Ti forskningsgrupper indsendte 27 målinger, hvoraf fire er referencefri 'målinger'. Derudover beregnede vi fem baseline metrics, herunder sentBLEU, BLEU, TER og ved hjælp af SacreBLEU scorer. Alle målinger blev evalueret på, hvor godt de korrelerer på system-, dokument- og segmentniveau med WMT20 officielle menneskelige scores. Vi præsenterer en omfattende analyse af indflydelsen af forskellige referenceoversættelser på metrisk pålidelighed, hvor godt automatiske målinger scorer menneskelige oversættelser, og vi markerer også store uoverensstemmelser mellem metriske og menneskelige scorer, når vi evaluerer MT-systemer. Endelig undersøger vi, om vi kan bruge automatiske målinger til at markere forkerte menneskelige vurderinger.", 'af': "Hierdie papier vertoon die resultate van die WMT20 metries deelde taak. Name Deelnaders is gevra om die uitvoerdes van die vertalingsstelsels te tel wat in die WMT20 Nuusvertalingstaak met outomatiese metrike konkurreer is. Teen ondersoek groepe het 27 metries ingestuur, vier van hulle is verwysing-minder 'metries'. In addition, we computed five baseline metrics, including sentBLEU, BLEU, TER and using the SacreBLEU scorer. Alle metries is geevalueer op hoe goed hulle korrelaat by die stelsel -, dokument- en segmentvlak met die WMT20 offisiele menslike punte. Ons stel 'n uitbreiding analiseer op influens van verskillende verwysing vertalings op metriese vertroulikheid, hoe goed automatiese metries verskaf menslike vertalings, en ons vlag ook groot verskilde tussen metriese en menslike punte wanneer MT stelsels evalueer. Eindelik, ons ondersoek of ons outomatiese metries kan gebruik om verkeerde menslike reitings te vlag.", 'am': 'ይህ ፕሮግራም የWMT20 ሜትሪክ የተሰራጨውን ስራ ውጤቶች ያሳያል፡፡ ተጋሪዎቹ በWMT20 ዜናዎች ትርጉም ስራ ውስጥ የሚከራከሩትን የትርጉም ስርዓቶች ውጤቶችን በራሱ ማተሚያዎች እንዲቆሙ ይጠይቃሉ። አሥር ምርምርጫዎች 27 ሜትሪኮች ሰጥተዋል፤ አራቱም ማህበረሰብ ከታናሹ ማተሚያዎች ናቸው፡፡ በተጨማሪም፣ ሳክሪብሊউ፣ ቢሊዩን፣ ቴር እና ሳክሪብሊዩን የተጠቃሚ ሚትርክቶችን ቆጠርን፡፡ ማተሚያዎች ሁሉ ከWMT20 ባለሥልጣዊ የሰው ነጥቦች ጋር እንዴት ያደጋግማሉ፡፡ We present an extensive analysis on influence of different reference translations on metric reliability, how well automatic metrics score human translations, and we also flag major discrepancies between metric and human scores when evaluating MT systems.  በመጨረሻም የሰው ክፍል ክፍተት ብናደርገው ማተሚያዎችን እናጠይቃለን፡፡', 'ko': '본고는 WMT20 도량 공유 임무의 결과를 제시했다.참가자들은 WMT20 뉴스 번역 임무에 참여하는 번역 시스템의 출력에 대해 자동으로 점수를 매겨야 한다.10개 연구팀은 27개의 지표를 제출했는데 그 중 4개는 참고할 수 없는 지표였다.또한 sentBLEU, BLEU, TER, SacreBLEU 점수기 사용 등 다섯 가지 기준지표를 계산했다.모든 지표는 시스템, 문서, 단편 차원에서 WMT20 공식 인류의 득점과 관련성에 따라 평가된다.우리는 서로 다른 참고 번역이 도량의 신뢰성에 미친 영향, 자동 도량이 인공 번역에 대한 평점 상황을 광범위하게 분석했고 기계 번역 시스템을 평가할 때 도량과 인공 평점 간의 주요 차이를 표시했다.마지막으로, 우리는 잘못된 인간 등급을 표시하기 위해 자동 도량을 사용할 수 있는지 연구한다.', 'tr': "Bu kagyz WMT20 metrikler bölüniş zadyň netijesini görkezýär. WBMT20 Haýry Terjime Görevini otomatik metrika bilen duşuşýan terjime sistemleriniň netijesini çykarmak üçin soralandyr. On research groups submitted 27 metrics, of which four are reference-less 'metrics'. Ayrıca, sentBLEU, BLEU, TER we SacreBLEU notlaryny ulanyp beş temel metrik hasapladyk. Hemme metrikler sistemde, sened we segment-derejesinde WMT20 resmi adamlaryň netijesi bilen nähili gowy görnüşinde deňlenýärler. Biz metrik ynamlylyk hakynda farklı referens terjimeleriniň täsirini çykarýarys, metrika nähili gowy awtomatik terjimeleri adamlary terjime edip bilýäris we hem metrik we adamlaryň sanlarynyň arasynda nähili döwletlerini çykarýarys. Iň soňunda, adamlaryň döwürmelerini nädogry ýalňyş sözlemek üçin awtomatik metriklerimizi ulanyp biljegimizi barlaýarys.", 'sq': "Ky dokument paraqet rezultatet e detyrës së përbashkët të WMT20 Metrics. Pjesëmarrësit u kërkuan të shënojnë rezultatet e sistemeve të përkthimit që konkurojnë në detyrën e përkthimit të lajmeve WMT20 me metrika automatike. Dhjetë grupe kërkimesh paraqitën 27 metrika, katër prej të cilave janë 'metrika' pa referencë. Përveç kësaj, ne llogaritëm pesë metrika bazë, duke përfshirë sendBLEU, BLEU, TER dhe duke përdorur shënuesin SacreBLEU. Të gjitha metrikat u vlerësuan se sa mirë korrelohen në nivelin e sistemit, dokumentit dhe segmentit me rezultatet zyrtare njerëzore të WMT20. Ne paraqesim një analizë të gjerë mbi ndikimin e përkthimeve të ndryshme referimi në besueshmërinë metrike, sa mirë metrika automatike shënon përkthimet njerëzore dhe ne gjithashtu shenojmë mospërputhje të mëdha midis rezultateve metrike dhe njerëzore kur vlerësojmë sistemet MT. Më në fund, ne hetojmë nëse mund të përdorim metrika automatike për të hedhur në shenjë vlerësime të gabuara njerëzore.", 'bn': "এই পত্রিকা WMT20 মেট্রিক শেয়ার করা কাজের ফলাফল উপস্থাপন করেছে। Participants were asked to score the outputs of the translation systems competing in the WMT20 News Translation Task with automatic metrics.  দশ গবেষণা গ্রুপ ২৭ মিট্রিক জমা দিয়েছে, যাদের মধ্যে চারটি উল্লেখযোগ্য 'মেট্রিক' কম। এছাড়াও আমরা পাঁচটি বেস্ট লাইন মেট্রিক গণনা করেছি, যার মধ্যে আছে সেন্ট্রিবিলু, বিলু, টের এবং স্যাক্রিবিলু স্কোরার ব্যবহা সকল মেট্রিক মূল্যায়ন করা হয়েছে যে তারা কিভাবে সিস্টেম, ডকুমেন্ট- এবং বিভিন্ন স্তরের সাথে সংশ্লিষ্ট মানুষের স্কোর দি আমরা মেট্রিক বিশ্বস্তির উপর ভিন্ন ভিন্ন ভিন্ন ভাষার অনুবাদের প্রভাবের উপর বিশেষ বিশ্লেষণ দিয়েছি, কিভাবে স্বয়ংক্রিয় মেট্রিক ভাবে মানুষের অনুবাদ স্কোর করে  অবশেষে, আমরা তদন্ত করি আমরা স্বয়ংক্রিয়ভাবে মেট্রিক ব্যবহার করতে পারি কিনা মানুষের রেজেন্ট ভুল করার জন্য।", 'az': 'Bu kağıt WMT20 metrik paylaşılan işin sonuçlarını göstərir. İşkilərdən WMT20 Haqq Çeviri Göndərilməsi ilə avtomatik metriklərlə müharibə edən tercümə sistemlərinin sonuçlarını göstərmək istədilər. On araştırma grupları 27 metrik tərəfindən tərəfindən dördüncü "metrik" deyildir. Biz də sentBLEU, BLEU, TER və SacreBLEU scorer vasitəsilə beş sinyal metrik hesabladıq. Bütün metriklər sistem, döküm və segment-seviyyəti WMT20 resmi insan nöqtələri ilə nə qədər yaxşı bağlantıları haqqında değerlendirildi. Biz metrik ticarətlərinin müxtəlif təkrarlarının təsirlərini, metriklərin insan təkrarlarını nə qədər gözəl təkrarlayır, metrik və insan təkrarlarının arasındakı böyük müxtəlif təkrarlarını belə göstəririk. Sonunda, insan qiymətlərini yanlış dəyişdirmək üçün avtomatik metrikləri istifadə edə biləcəyimizi incidirik.', 'bs': 'Ovaj papir predstavlja rezultate zajedničkog zadatka WMT20 metrika. Učesnicima su zamolili da rezultate sustava prevoda koji se natječu u zadatku WMT20 novinskog prevoda sa automatskim metrikama. Deset istraživačkih grupa podnelo je 27 metrika, od kojih četiri su bez referencije "metrika". Osim toga, računali smo pet početnih metrika, uključujući sentBLEU, BLEU, TER i korištenje rezultata SacreBLEU. Sve metrike su procjenjene kako su dobro povezani na nivou sustava, dokumenta i segmenta sa zvaničnim ljudskim rezultatima WMT20. Predstavljamo ogromnu analizu na utjecaj različitih referentnih prevoda na metričku pouzdanost, koliko dobro automatski metrički rezultati ljudskih prevoda, a također zastupamo velike razlike između metričkih i ljudskih rezultata kada procjenjujemo sisteme MT-a. Konačno, istražujemo da li možemo koristiti automatsku metriku da zastavimo nepravedne ljudske ocjene.', 'ca': 'This paper presents the results of the WMT20 Metrics Shared Task.  Els participants van demanar que puntuessin els resultats dels sistemes de traducció que competeixen en la tasca de traducció de notícies WMT20 amb mètriques automàtiques. Dez grups de recerca van presentar 27 mètriques, quatre de les quals no tenen referència a "mètriques". A més, vam calcular cinc mètriques de base, incloent la sentBLEU, BLEU, TER i utilitzant el puntuador SacreBLEU. Totes les mètriques van ser evaluades sobre com correlacionen a nivell sistemàtic, documental i segmental amb les puntuacions oficials de la WMT20. Presentam una an àlisi extensa sobre l\'influència de diferències traduccions de referència en la fiabilitat mètrica, la puntuació automàtica de les traduccions humanes, i també indicam grans discrepancies entre puntuacions mètrices i humans quan evaluem els sistemes MT. Finalment, investigam si podem utilitzar mètriques automàtiques per indicar valoracions humanes incorrectes.', 'cs': 'Tento článek prezentuje výsledky WMT20 Metrics Shared Task. Účastníci byli požádáni o skórování výstupů překladových systémů soutěžících v WMT20 News Translation Task s automatickými metrikami. Deset výzkumných skupin předložilo 27 metriky, z nichž čtyři jsou bezreferenční "metriky". Kromě toho jsme vypočítali pět základních metrik, včetně sentBLEU, BLEU, TER a použití SacreBLEU bodéru. Všechny metriky byly vyhodnoceny podle toho, jak dobře korelují na systémové, dokumentové a segmentové úrovni s oficiálními lidskými skóremi WMT20. Předkládáme rozsáhlou analýzu vlivu různých referenčních překladů na metrickou spolehlivost, jak dobře automatické metriky skórují lidské překlady a také upozorňujeme na zásadní rozdíly mezi metrickými a lidskými skóremi při hodnocení MT systémů. Nakonec zkoumáme, zda můžeme použít automatické metriky k označení nesprávných lidských hodnocení.', 'et': 'Käesolevas dokumendis esitatakse WMT20 meetrite jagatud ülesande tulemusi. Osalejatel paluti hinnata WMT20 uudiste tõlketöös konkureerivate tõlkesüsteemide väljundeid automaatsete mõõdikutega. Kümme uurimisrühma esitas 27 mõõdikut, millest neli on viitevabad mõõdikud. Lisaks arvutasime välja viis baasmõõturit, sealhulgas sentBLEU, BLEU, TER ja kasutasime SacreBLEU skoorijat. Kõiki mõõdikuid hinnati selle põhjal, kui hästi need vastavad süsteemi-, dokumendi- ja segmenditasandil WMT20 ametlike inimskooridega. Esitame ulatusliku analüüsi erinevate viitetõlkete mõju kohta meetrika usaldusväärsusele, kui hästi automaatsed mõõdikud hindavad inimtõlkeid, ning märgime ka suured erinevused meetrika ja inimskoori vahel MT süsteemide hindamisel. Lõpuks uurime, kas saame kasutada automaatseid mõõdikuid ebaõigete inimhinnangute tähistamiseks.', 'fi': 'Tässä artikkelissa esitellään WMT20 Metrics Shared Task -projektin tulokset. Osallistujia pyydettiin pisteyttämään WMT20 News Translation Taskissa kilpailevien käännösjärjestelmien tuotokset automaattisilla mittareilla. Kymmenen tutkimusryhmää toimitti 27 mittaria, joista neljä on viitteettömiä "mittareita". Lisäksi laskimme viisi perusmittaria, mukaan lukien sentBLEU, BLEU, TER ja SacreBLEU-pisteytystä käyttäen. Kaikki mittarit arvioitiin sen perusteella, kuinka hyvin ne korreloivat järjestelmä-, asiakirja- ja segmenttitasolla WMT20 virallisten ihmisten pistemäärien kanssa. Esitämme kattavan analyysin eri referenssikäännösten vaikutuksesta metriikkaluotettavuuteen, kuinka hyvin automaattiset metriikat arvioivat inhimillisiä käännöksiä ja merkitsemme myös merkittäviä eroja metristen ja inhimillisten pisteiden välillä MT-järjestelmien arvioinnissa. Lopuksi tutkimme, voimmeko käyttää automaattisia mittareita väärien ihmisten luokitusten merkitsemiseen.', 'hy': 'Այս հոդվածը ներկայացնում է World MT20 մետրիկի ընդհանուր հանձնարարության արդյունքները: մասնակիցներին խնդրեցին գնահատել թարգմանման համակարգերի արտադրանքները, որոնք մրցում են ԱՄԹ20 նորությունների թարգմանման գործում ավտոմատիկ մետրիկով: Տաս հետազոտությունների խումբ ներկայացրեց 27 մետր, որոնցից չորս անհամեմատական մետր են: Ավելին, մենք հաշվարկեցինք հինգ հիմնական չափությունը, ներառյալ ուղարկված ԲԼԵՎ-ը, ԲԼԵՎ-ը, ԹԵՌ-ը և օգտագործելով ՍաքրԲԼԵՎ-ը: All metrics were evaluated on how well they correlate at the system-, document- and segment-level with the WMT20 official human scores.  We present an extensive analysis on influence of different reference translations on metric reliability, how well automatic metrics score human translations, and we also flag major discrepancies between metric and human scores when evaluating MT systems.  Finally, we investigate whether we can use automatic metrics to flag incorrect human ratings.', 'jv': 'Gambar iki bakal ngewehke pejalaké mulasar uwong gawe task gawe Metric 2 Ombudhakan nganggep nggunakaké ngertuk sistem itoleh sing sampeyan ngono nggawe WWC2 Ten pangunasi nggawe mruput, kawit sampeyan tanggal Nambah, awak dhéwé isih basa sing nggambar barang sampek, misang seneng barang, CLUE, MER lan nggambar Punika SakRebleUE. Perintah sing dipatensi dipatensi kapan kelas kuwi masalah sak dadi aturan-, dokumen- lan kelas-segment sing ditambah sing masalah offisisi uwong, ora basa gambar dan papan sing perusahaan karo awak sing uwong. Awak dhéwé éntuk panelusuran sistem sing nggawe nggunakake tarjamahan kanggo nggunakake sistem Metik, sing dadi otomatik dadi nggunakake sistem sing uwong, lan kéné hukum sistem sing berarti kalagayaan tanggal nggawe gerakan tarjamahan sing nggawe metik lan sing sampeyan uwong sing gunakake sistem MT. Ero-jewih, kéné ujian sisakaké awak dhéwé iso nggunakake sistem mat otomatik kanggo nganggo cara-ratan sing uwong.', 'sk': 'V tem članku so predstavljeni rezultati opravila v skupni rabi meril WMT20. Udeleženci so bili pozvani, da ocenijo rezultate prevajalskih sistemov, ki tekmujejo v nalogi prevajanja novic WMT20, s samodejnimi metrikami. Deset raziskovalnih skupin je predložilo 27 meritev, od katerih so štiri "meritve brez referenc". Poleg tega smo izračunali pet osnovnih meritev, vključno s sentBLEU, BLEU, TER in z uporabo rezultata SacreBLEU. Vse meritve so ocenjevale glede na to, kako dobro se povezujejo na sistemski, dokumentski in segmentni ravni z uradnimi rezultati WMT20 za človeka. Predstavljamo obsežno analizo vpliva različnih referenčnih prevodov na zanesljivost metričnih podatkov, kako dobro avtomatične metrične podatke ocenjujejo človeške prevode, prav tako pa opozarjamo na velika razlika med metričnimi in človeškimi ocenami pri ocenjevanju sistemov MT. Nazadnje raziskujemo, ali lahko uporabimo samodejne meritve za označevanje nepravilnih ocen ljudi.', 'ha': "Wannan avir na bãyar da matsalan na WMT20 Metrics Shared Taaikin. An tambaye masu shirin auren zuwa kofi Outputs of the translation system competitin in the WMT20 News Translate Tafiyar da farat ɗaya. Kundari gõma na fassara da aka samar da 27 metrici, daga cikinsu akwai nau'i-ƙaranci 'metrics'. Ina ƙaranci, mun lissafa mitriki watan jama'a biyu, kamar centBLEU, BLEU, TeR da kuma za'a yi amfani da mai SacreBLEU. All metrics were evaluated on how well they correlate at the system-, document- and segment-level with the WMT20 official human scores.  Tuna gabatar da wani anayyari mai girma a kan fassarar misãlai masu hushi a kan mutane, ko da yaushe metric farat ɗaya ko masu shiryuwa na fassarar mutane, kuma ko da yawa, muna buga diffaniki masu girma a tsakanin metric da score na mutum idan an evaluce tsarin MT. Haƙĩƙa, Munã tambaya ko za'a iya amfani da metric farat ɗaya ko kuma mu yi amfani da flage rasmi na mutane.", 'he': 'העבודה הזו מציגה את תוצאות המשימה המשותפת של WMT20 מטריקס. השתתפים נבקשו להוציא תוצאות מערכות התרגום מתחרות במשימת התרגום WMT20 עם מטריקה אוטומטית. עשר קבוצות מחקרים הכניסו 27 מטריות, ארבעה מהן "מטריות ללא התייחסות". בנוסף, חישבנו חמישה מטריות בסיסית, כולל SenBLEU, BLEU, TER ושימוש בתוצאות SacreBLEU. All metrics were evaluated on how well they correlate at the system-, document- and segment-level with the WMT20 official human scores.  אנחנו מציגים ניתוח רחב על השפעה של תרגומות התייחסות שונות על אמינות מטרית, כמה טוב מטריות אוטומטיות קולטות תרגומות אנושיות, ואנחנו גם מדגלים אי-שונות גדולות בין נקודות מטריות לבין נקודות אנושיות בערכת מערכות MT. סוף סוף, אנחנו חוקרים אם אנחנו יכולים להשתמש במטריקה אוטומטית כדי לדגל ציונים אנושיים לא נכונים.', 'bo': "ཤོག་བྱང་འདིས་WMT200རྩིས་ཆ་རྩིས་བ་དང་མཉམ་སྤྱོད་པའི་གྲུབ་འབྲས་མངོན་འཆར་བྱེད་ཀྱི་ཡོད། Participants were asked to score the outputs of the translation systems competing in the WMT20 News Translation Task with automatic metrics. Ten research groups submitted 27 metrics, four of which are reference-less 'metrics'. In addition, we computed five baseline metrics, including sentBLEU, BLEU, TER and using the SacreBLEU scorer. All metrics were evaluated on how well they correlate at the system-, document- and segment-level with the WMT20 official human scores. We present an extensive analysis on influence of different reference translations on metric reliability, how well automatic metrics score human translations, and we also flag major discrepancies between metric and human scores when evaluating MT systems. Finally, we investigate whether we can use automatic metrics to flag incorrect human ratings."}
{'en': 'Cross-Lingual Transformers for Neural Automatic Post-Editing', 'pt': 'Transformadores multilíngues para pós-edição automática neural', 'ar': 'محولات عبر اللغات من أجل التحرير التلقائي العصبي اللاحق', 'es': 'Transformadores multilingües para la postedición automática neuronal', 'fr': 'Transformateurs multilingues pour la post-édition automatique neuronale', 'ja': 'ニューラル・オートマチック・ポストエディット用クロスリンガル・トランスフォーマー', 'zh': '神经自译后编辑跨语转换器', 'hi': 'तंत्रिका स्वचालित पोस्ट संपादन के लिए क्रॉस-लिंगुअल ट्रांसफॉर्मर', 'ru': 'Кросс-лингвальные трансформаторы для нейронного автоматического последующего редактирования', 'ga': 'Trasfhoirmeoirí Trastheangacha le haghaidh Iar-Eagarthóireacht Néar Uathoibríoch', 'hu': 'Többnyelvű transzformátorok a neurális automatikus utószerkesztéshez', 'el': 'Διασγλωσσικοί μετασχηματιστές για νευρολογική αυτόματη μετα-επεξεργασία', 'kk': 'Невралдық автоматты түрде өңдеу үшін тілікті көбейткен түрлендірушілері', 'it': 'Trasformatori cross-linguali per post-editing automatico neurale', 'lt': 'Daugiakalbiai transformatoriai neurologiniam automatiniam postredagavimui', 'ms': 'Penukar Selasa-Bahasa untuk Penyunting Automatik Neural', 'ml': 'നെയുറല്\u200d സ്വയം പിന്നോട്ട് എടുത്തുകൊടുക്കുന്നതിനുള്ള ക്രോസ്- ലിങ്ഗുവല്\u200d ട്രാന്\u200dസ്ഫോര്\u200dഫ', 'ka': 'Name', 'mk': 'Name', 'mt': 'Trasformaturi Cross-Lingwi għal Post-Editing Awtomatiku Newrali', 'no': 'Krysslingstransformerer for neirale postredigering', 'ro': 'Transformatoare interlingvistice pentru post-editare automată neurală', 'pl': 'Transformatory wielojęzykowe do automatycznej edycji neuronowej', 'si': 'න්\u200dයූරාල් ස්වයංක්\u200dරිය පොස් සංපාදනය සඳහා ක්\u200dරොස් ලින්ගුල් වෙනස් කරන්න', 'so': 'Cross-Lingual Transformers for Neural Automatic Post-Editing', 'sv': 'Tvärspråkiga transformatorer för Neural automatisk efterredigering', 'mn': 'Сэтгэл автоматик эцэст засварлах хэлбэрийн шилжүүлэгчид', 'sr': 'KrozLingualni transformatori za neuralno automatsko posturedjenje', 'ta': 'புதிய தானியங்கி தொகுப்புக்கான கிராஸ்- கோட்டு மாற்றுபவர்கள்', 'ur': 'نائرول اٹوٹوٹ پوسٹ ایڈیٹینگ کے لئے کرس-لینگئال ترنسفور', 'uz': 'Name', 'vi': 'Dịch biến hình chữ thập tự tử', 'hr': 'Cross-Lingual Transformers for Neural Automatic Post Editing', 'nl': 'Cross-Lingual Transformers voor Neural Automatische Post-Editing', 'bg': 'Междулингвистични трансформатори за автоматично следредактиране на неврони', 'da': 'Tværsprogede transformatorer til neural automatisk efterredigering', 'de': 'Sprachübergreifende Transformatoren für die automatische Neuralbearbeitung', 'id': 'Cross-Lingual Transformers for Neural Automatic Post-Editing', 'ko': '신경 자동 편집에 사용되는 다중 언어 변환기', 'fa': 'تغییردهنده\u200cهای متصل زبان برای ویرایش بعد از ویرایش خودکار عصبی', 'sw': 'Wasafiri wa lugha-Lingua kwa ajili ya kuhariri Baada ya Uhuru', 'sq': 'Transformuesit ndërgjuhës për Posteditimin Neural Automatik', 'tr': 'Neural Otomatik Po-Editlemek üçin Çapraz Dilli Täzeleşmeler', 'af': 'Name', 'am': 'Cross-Lingual Transformers for Neural Automatic Post-Editing', 'hy': 'Նյարդային ավտոմատիկ հետխմբագրման խաչլեզվային վերափոխողները', 'bn': 'নিউরাল স্বয়ংক্রিয় পোস্ট সম্পাদনের জন্য ক্রস- লিঙ্গুয়াল ট্রান্সফর্মার', 'bs': 'KrozLingualni transformatori za Neuralno automatsko posturedjenje', 'ca': 'Transformers translingües per a la postedició automàtica neuronal', 'et': 'Keeleülesed transformaatorid neuroaalseks automaatseks järelredigeerimiseks', 'fi': 'Cross-Lingual Transformers for Neural Automatic Post-Editing', 'az': 'Nöral Avtomatik Post-Editing üçün Xərc-Lingual Transformers', 'cs': 'Cross-lingvální transformátory pro neuronovou automatickou post-editaci', 'he': 'Cross-Lingual Transformers for Neural Automatic Post-Editing', 'sk': 'Medjezikovni transformatorji za avtomatsko živčno urejanje', 'ha': 'KCharselect unicode block name', 'jv': 'structural navigation', 'bo': 'ནད་དོན་རང་འགུལ་གྱི་རྗེས་བསྒྱུར་བཅོས་ལ་Cross-Lingual བཟོ་བཅོས་པ'}
{'en': 'In this paper, we describe the Bering Lab’s submission to the WMT 2020 Shared Task on Automatic Post-Editing (APE). First, we propose a cross-lingual Transformer architecture that takes a concatenation of a source sentence and a machine-translated (MT) sentence as an input to generate the post-edited (PE) output. For further improvement, we mask incorrect or missing words in the PE output based on word-level quality estimation and then predict the actual word for each mask based on the fine-tuned cross-lingual language model (XLM-RoBERTa). Finally, to address the over-correction problem, we select the final output among the PE outputs and the original MT sentence based on a sentence-level quality estimation. When evaluated on the WMT 2020 English-German APE test dataset, our system improves the NMT output by -3.95 and +4.50 in terms of TER and BLEU, respectively.', 'fr': "Dans cet article, nous décrivons la soumission du Bering Lab à la tâche partagée WMT 2020 sur la post-édition automatique (APE). Tout d'abord, nous proposons une architecture Transformer multilingue qui prend une concaténation d'une phrase source et d'une phrase traduite automatiquement (MT) comme entrée pour générer la sortie post-éditée (PE). Pour une amélioration supplémentaire, nous masquons les mots incorrects ou manquants dans la sortie PE sur la base d'une estimation de la qualité au niveau du mot, puis nous prédisons le mot réel pour chaque masque sur la base du modèle linguistique multilingue affiné (XLM-Roberta). Enfin, pour résoudre le problème de surcorrection, nous sélectionnons le résultat final parmi les sorties PE et la phrase MT originale sur la base d'une estimation de la qualité au niveau de la phrase. Lorsqu'il est évalué sur l'ensemble de données de test APE anglais-allemand WMT 2020, notre système améliore la sortie NMT de -3,95 et +4,50 en termes de TER et de BLEU, respectivement.", 'ar': 'في هذه الورقة ، نصف تقديم مختبر بيرنج إلى مهمة WMT 2020 المشتركة حول التحرير التلقائي اللاحق (APE). أولاً ، نقترح بنية Transformer متعددة اللغات تأخذ سلسلة من الجملة المصدر والجملة المترجمة آليًا (MT) كمدخل لتوليد الإخراج بعد التحرير (PE). لمزيد من التحسين ، نقوم بإخفاء الكلمات غير الصحيحة أو المفقودة في إخراج PE استنادًا إلى تقدير جودة مستوى الكلمة ثم توقع الكلمة الفعلية لكل قناع بناءً على نموذج اللغة عبر اللغات المضبوط بدقة (XLM-RoBERTa). أخيرًا ، لمعالجة مشكلة التصحيح الزائد ، نختار الناتج النهائي من بين مخرجات PE وجملة الترجمة الآلية الأصلية بناءً على تقدير الجودة على مستوى الجملة. عند تقييمه على مجموعة بيانات اختبار APE الإنجليزية-الألمانية WMT 2020 ، يعمل نظامنا على تحسين ناتج NMT بمقدار -3.95 و +4.50 من حيث TER و BLEU ، على التوالي.', 'es': 'En este artículo, describimos la presentación del Laboratorio de Bering a la Tarea Compartida sobre Postedición Automática (APE) del WMT 2020. Primero, proponemos una arquitectura Transformer multilingüe que toma una concatenación de una oración fuente y una oración traducida automáticamente (MT) como entrada para generar la salida post-editada (PE). Para mejorar aún más, enmascaramos las palabras incorrectas o faltantes en la salida de PE en función de la estimación de la calidad a nivel de palabra y, a continuación, predecimos la palabra real para cada máscara en función del modelo lingüístico multilingüe ajustado (XLM-Roberta). Finalmente, para abordar el problema de la sobrecorrección, seleccionamos la salida final entre las salidas de PE y la oración MT original en función de una estimación de calidad a nivel de oración. Cuando se evalúa en el conjunto de datos de prueba APE inglés-alemán del WMT 2020, nuestro sistema mejora la producción de NMT en -3,95 y +4,50 en términos de TER y BLEU, respectivamente.', 'pt': 'Neste artigo, descrevemos o envio do Bering Lab para a Tarefa Compartilhada do WMT 2020 sobre Pós-Edição Automática (APE). Primeiro, propomos uma arquitetura Transformer multilíngue que usa uma concatenação de uma frase de origem e uma frase traduzida por máquina (MT) como entrada para gerar a saída pós-editada (PE). Para melhorar ainda mais, mascaramos palavras incorretas ou ausentes na saída do PE com base na estimativa de qualidade em nível de palavra e, em seguida, prevemos a palavra real para cada máscara com base no modelo de linguagem multilíngue ajustado (XLM-RoBERTa). Finalmente, para resolver o problema de correção excessiva, selecionamos a saída final entre as saídas do PE e a sentença MT original com base em uma estimativa de qualidade no nível da sentença. Quando avaliado no conjunto de dados de teste APE inglês-alemão do WMT 2020, nosso sistema melhora a saída NMT em -3,95 e +4,50 em termos de TER e BLEU, respectivamente.', 'zh': '本文白令实验室向WMT 2020自译后辑(APE)共享。 首建跨语之Transformer架构,当架构以源句与机器翻译(MT)句联为输,以成编辑(PE)输。 以单词度掩之PE输中非是失之单词,然后以微跨语言(XLM-RoBERTa)占掩码之实单词。 最后,以句级量之,于 PE 输出 MT 句中择终输之。 WMT 2020英德APE测试数据集上评估,分输TERBLEUNMT-3.95+4.50。', 'ja': '本稿では、自動ポスト編集（ APE ）に関するWMT 2020共有タスクへのベーリングラボの提出について説明します。まず、ソース文と機械翻訳（ MT ）文の連結を入力とし、ポストエディット（ PE ）出力を生成するクロスリンガル変換アーキテクチャを提案する。さらなる改善のために、ワードレベルの品質推定に基づいてPE出力の誤った単語または欠落している単語をマスクし、その後、微調整されたクロスリンガル言語モデル（ XLM - RoBERTa ）に基づいて各マスクの実際の単語を予測します。最後に、過剰補正の問題に対処するために、文レベルの品質推定に基づいて、PE出力と元のMT文の中から最終出力を選択します。WMT 2020英独APE試験データセットで評価すると、当社のシステムはTERおよびBLEUの観点からNMT出力をそれぞれ-3.95および+4.50向上させます。', 'hi': 'इस पेपर में, हम स्वचालित पोस्ट-एडिटिंग (एपीई) पर डब्ल्यूएमटी 2020 साझा कार्य के लिए बेरिंग लैब के सबमिशन का वर्णन करते हैं। सबसे पहले, हम एक क्रॉस-भाषी ट्रांसफॉर्मर आर्किटेक्चर का प्रस्ताव करते हैं जो पोस्ट-एडिटेड (पीई) आउटपुट उत्पन्न करने के लिए इनपुट के रूप में एक स्रोत वाक्य और एक मशीन-अनुवादित (एमटी) वाक्य का एक संयोजन लेता है। आगे के सुधार के लिए, हम शब्द-स्तर की गुणवत्ता के अनुमान के आधार पर पीई आउटपुट में गलत या लापता शब्दों को मुखौटा करते हैं और फिर ठीक-ठाक क्रॉस-लिंगुअल भाषा मॉडल (XLM-RoBERTa) के आधार पर प्रत्येक मुखौटा के लिए वास्तविक शब्द की भविष्यवाणी करते हैं। अंत में, अति-सुधार समस्या को संबोधित करने के लिए, हम पीई आउटपुट और मूल एमटी वाक्य के बीच अंतिम आउटपुट का चयन करते हैं जो एक वाक्य-स्तर की गुणवत्ता अनुमान के आधार पर होता है। जब WMT 2020 अंग्रेजी-जर्मन एपीई परीक्षण डेटासेट पर मूल्यांकन किया जाता है, तो हमारा सिस्टम क्रमशः टीईआर और BLEU के संदर्भ में -3.95 और +4.50 द्वारा NMT आउटपुट में सुधार करता है।', 'ru': 'В этой статье мы описываем представление Лаборатории Беринга к Общей задаче WMT 2020 по автоматическому постредактированию (APE). Во-первых, мы предлагаем кросс-лингвистическую архитектуру Трансформатора, которая принимает объединение исходного предложения и предложения с машинным переводом (MT) в качестве входных данных для генерации пост-редактированного (PE) выхода. Для дальнейшего улучшения мы маскируем неправильные или отсутствующие слова в выводе PE на основе оценки качества на уровне слов, а затем прогнозируем фактическое слово для каждой маски на основе тонко настроенной модели межъязыкового языка (XLM-RoBERTa). Наконец, чтобы решить проблему чрезмерной коррекции, мы выбираем конечный результат среди результатов PE и исходное предложение MT на основе оценки качества на уровне предложения. При оценке по тестовому набору данных WMT 2020 English-German APE наша система улучшает выход NMT на -3,95 и +4,50 в терминах TER и BLEU соответственно.', 'ga': 'Sa pháipéar seo, déanaimid cur síos ar aighneacht Bering Lab do Thasc Comhroinnte WMT 2020 ar Iar-Eagarthóireacht Uathoibríoch (APE). Ar an gcéad dul síos, molaimid ailtireacht tras-teangach Trasfhoirmeora a thógann comhchatún abairt foinse agus abairt meaisín-aistrithe (MT) mar ionchur chun an t-aschur iar-eagarthóireachta (PE) a ghiniúint. Chun breis feabhais a chur air, clúdaíonn muid focail atá mícheart nó atá ar iarraidh san aschur Corpoideachais bunaithe ar mheastachán cáilíochta ar leibhéal na bhfocal agus ansin déanaimid réamh-mheas ar an bhfocal iarbhír do gach masc bunaithe ar an múnla teanga tras-teanga mionchoigeartaithe (XLM-RoBERTa). Ar deireadh, chun dul i ngleic leis an bhfadhb ró-cheartúcháin, roghnóimid an t-aschur deiridh i measc na n-aschur Corpoideachais agus an abairt MT bunaidh bunaithe ar mheastachán cáilíochta ar leibhéal na habairte. Nuair a dhéantar measúnú air ar thacar sonraí tástála APE Béarla-Gearmáinis WMT 2020, feabhsaítear ár gcóras aschur NMT faoi -3.95 agus +4.50 i dtéarmaí TER agus BLEU, faoi seach.', 'el': 'Σε αυτή την εργασία, περιγράφουμε την υποβολή του εργαστηρίου Bering στην κοινή εργασία WMT 2020 για την αυτόματη μετα-επεξεργασία (APE). Πρώτον, προτείνουμε μια δομή διασταυρούμενου μετασχηματιστή που λαμβάνει μια αλληλουχία μιας πρότασης προέλευσης και μιας πρότασης μηχανικής μετάφρασης (ΜΤ) ως εισαγωγή για να δημιουργήσει την έξοδο μετά την επεξεργασία (PE). Για περαιτέρω βελτίωση, αποκρύπτουμε λανθασμένες ή ελλείπουσες λέξεις στην έξοδο με βάση την εκτίμηση ποιότητας σε επίπεδο λέξεων και στη συνέχεια προβλέπουμε την πραγματική λέξη για κάθε μάσκα με βάση το εκλεπτυσμένο γλωσσικό μοντέλο (XLM-RoBERTa). Τέλος, για να αντιμετωπιστεί το πρόβλημα της υπερδιόρθωσης, επιλέγουμε το τελικό αποτέλεσμα μεταξύ των εξόδων PE και την αρχική πρόταση ΜΤ με βάση μια εκτίμηση ποιότητας σε επίπεδο πρότασης. Όταν αξιολογείται στο σύνολο δεδομένων της αγγλικής-γερμανικής δοκιμής το σύστημά μας βελτιώνει την παραγωγή κατά -3.95 και +4.50 από την άποψη της TER και της BLEU αντίστοιχα.', 'ka': 'ამ დომენტში, ჩვენ აღწერეთ ბერინგის ლაბოლობის შემდეგ WMT 2020 სხვადასხვა რაოდენობა ავტომატური დარედაქტირებაზე (APE). პირველი, ჩვენ მინდომა კრისი ენგური ტრანფორმეტრის აქტიქტიქტურაციას, რომელიც მინდომა მსგავსი წესების შემდეგ და მაქსინური ტრანფორმეტრის წესების შემდეგ შემდეგ შემდეგ (PE დამატებით გაუკეთესებისთვის, ჩვენ მაქსიკურებთ შეცდომა ან არსებული სიტყვები PE გამოსახულებაში სიტყვების კანოლიტურის განსახულებაზე და შემდეგ განსახულებთ ყველა მაქსისთვის სიტყვები, რომელიც განსახულ საბოლოოდ, დასაწყებელი პრობლემას გადასაწყებლად, ჩვენ PE გამოსახულების საბოლოო გამოსახულების და ორიგინალური MT წესების გამოსახულების განსაზღვრებაზე დავწყებთ. როდესაც WMT 2020-ის ინგლისური-გერმანური APE ტესტის მონაცემების შესახებ, ჩვენი სისტემა NMT გამოყენება -3,95 და +4,50-ზე შესახებ TER და BLEU-ის შესახებ.', 'it': "In questo articolo, descriviamo la presentazione del Bering Lab al WMT 2020 Shared Task on Automatic Post-Editing (APE). In primo luogo, proponiamo un'architettura Transformer cross-lingual che prende una concatenazione di una frase sorgente e una frase tradotta automaticamente (MT) come input per generare l'output post-editato (PE). Per ulteriori miglioramenti, mascheramo parole errate o mancanti nell'output PE in base alla stima della qualità a livello di parola e quindi prediciamo la parola effettiva per ogni maschera in base al modello di linguaggio cross-lingual perfezionato (XLM-RoBERTa). Infine, per affrontare il problema di sovracorrezione, selezioniamo l'output finale tra le uscite PE e la frase MT originale sulla base di una stima della qualità a livello di frase. Se valutato sul set di dati APE inglese-tedesco WMT 2020, il nostro sistema migliora l'uscita NMT rispettivamente di -3,95 e +4,50 in termini di TER e BLEU.", 'kk': 'Бұл қағазда, біз Беринг лабораториясының WMT 2020 автоматты түрде өңдеу (APE) үшін ортақтастырылған тапсырманы таңдап береміз. Біріншіден, біз көзгертілген (PE) шығысын құру үшін көзгертілген түрлендіруші архитектурасын жұмыс береміз. Қосымша жақсарту үшін, PE шығысында сөз деңгейінің сапасы бағалауына негізделген сөздер дұрыс немесе жоқ сөздерді қалқалап, кейін әрбір қалқаның шындық сөзді бір тіл үлгісіне негізделген көп тіл үлгісіне негізделген (X Соңында, жоғары түзету мәселесін шешу үшін, PE шығысының соңғы шығысын және бастапқы MT сөйлемесін сөйлеме деңгейінің сапасы бағалауына негізделген. WMT 2020-нің ағылшын-неміс APE тесті деректер жиынын бағалағанда, жүйеміз NMT шығысын - 3,95 және +4,50 TER және BLEU қасиетінде жасайды.', 'lt': 'Šiame dokumente apibūdiname Bering Lab pateiktą WMT 2020 bendros užduoties dėl automatinio pakartotinio redagavimo (APE) klausimą. First, we propose a cross-lingual Transformer architecture that takes a concatenation of a source sentence and a machine-translated (MT) sentence as an input to generate the post-edited (PE) output.  Siekiant tolesnio tobulinimo, mes paslėpiame klaidingus arba trūkstančius žodžius PE išėjime remiantis žodžių kokybės įvertinimu ir tada nuspėjame tikrąjį kiekvienos kaukės žodį, pagrįstą tiksliu tarpkalbiniu modeliu (XLM-RoBERTa). Galiausiai, norint išspręsti pernelyg didelio koregavimo problem ą, mes pasirinksime galutinį rezultatą tarp PE rezultatų ir pradinio MT sakinio remiantis sakinių kokybės vertinimu. When evaluated on the WMT 2020 English-German APE test dataset, our system improves the NMT output by -3.95 and +4.50 in terms of TER and BLEU, respectively.', 'hu': 'Ebben a tanulmányban bemutatjuk a Bering Lab benyújtását a WMT 2020 Shared Task on Automatic Post-Editing (APE) című dokumentumnak. Először is, egy többnyelvű transzformátor architektúrát javasolunk, amely bemenetként veszi egy forrás mondat és egy gépi fordítás (MT) mondat összekapcsolását az utólagos szerkesztés (PE) kimenet generálásához. A további fejlesztés érdekében a PE kimenetben a helytelen vagy hiányzó szavakat rejtjük el szószintű minőségbecslés alapján, majd az egyes maszkok tényleges szóját jósoljuk meg a finomhangolt nyelvi modell (XLM-RoBERTa) alapján. Végezetül a túlzott korrekciós probléma kezelésére a PE kimenetek közül a végső kimenetet és az eredeti MT mondatot mondatszintű minőségbecslés alapján választjuk ki. A WMT 2020 angol-német APE tesztadatkészleten történő értékelésekor rendszerünk -3,95-rel, illetve +4,50-rel javítja az NMT kimenetet TER és BLEU tekintetében.', 'ms': "In this paper, we describe the Bering Lab's submission to the WMT 2020 Shared Task on Automatic Post-Editing (APE).  First, we propose a cross-lingual Transformer architecture that takes a concatenation of a source sentence and a machine-translated (MT) sentence as an input to generate the post-edited (PE) output.  For further improvement, we mask incorrect or missing words in the PE output based on word-level quality estimation and then predict the actual word for each mask based on the fine-tuned cross-lingual language model (XLM-RoBERTa).  Akhirnya, untuk mengatasi masalah penyesuaian-berlebihan, kita pilih output akhir diantara output PE dan kalimat MT asal berdasarkan penilaian kualiti aras kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat When evaluated on the WMT 2020 English-German APE test dataset, our system improves the NMT output by -3.95 and +4.50 in terms of TER and BLEU, respectively.", 'mk': 'Во овој весник, ја опишуваме поднесувањето на Беринг лабораторијата на заедничката задача WMT 2020 за автоматско постуредување (APE). Прво, предложуваме крстојазична трансформна архитектура која зема концентација на изворна реченица и реченица преведена од машина (МТ) како влог за генерирање на пост-уредуваниот (ПЕ) излез. За понатамошно подобрување, ние маскираме погрешни или недостасувачки зборови во излезот на ПЕ врз основа на проценка на квалитетот на нивото на зборот и потоа предвидуваме вистински збор за секоја маска врз основа на фино прилагоден крстојазичен модел на јазик (XLM-RoBERTa). Конечно, за да се реши проблемот со прекумерната корекција, го избираме финалниот излез помеѓу излезите на ПЕ и оригиналната реченица MT врз основа на проценка на квалитетот на нивото на реченица. Кога ќе се процени на англиско-германското тестирање на АПЕ во ВМТ 2020, нашиот систем го подобрува излезот на НМТ за -3,95 и +4,50 во поглед на ТЕР и БЛЕУ, односно.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ബെരിംഗ് ലാബിന്\u200dറെ വിവരണങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. WMT 2020 പങ്കെടുക്കുന്ന പണിയില്\u200d സ്വയം പിന്ത ആദ്യം, നമ്മള്\u200d ഒരു ക്രിസ്ലിങ്ങ് ലാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആര്\u200dക്ടിക്കറ്റര്\u200d പ്രൊദ്ദേശിപ്പിക്കുന്നു. അത് ഒരു സോര്\u200dസ്സ് വാക്കിന്റെ കൂട്ടിയിടുന്നു. ഒരു യന കൂടുതല്\u200d മെച്ചപ്പെടുത്തുവാന്\u200d വേണ്ടി, പെയില്\u200d പുറത്തുള്ള വാക്കുകള്\u200d തെറ്റായിട്ടോ കാണാതിരിക്കുകയോ ചെയ്യുന്നു. വാക്ക്- നില മാതൃകയുടെ ഗുണപൂര്\u200dണ്ണമായ അവസാനം, വാക്ക്- നില മാന്യത്തിന്റെ ഗുണപൂര്\u200dണ്ണമായ പരിഹാരം വിശദീകരിക്കാന്\u200d, PE പുറത്തുള്ള അവസാനത്തെ ഫലം തെരഞ്ഞെടുക്കുന്നു.  WMT 2020 ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d ഏപി ടെസ്റ്റ് ഡാറ്റാസെറ്റില്\u200d വിലയിക്കുമ്പോള്\u200d നമ്മുടെ സിസ്റ്റത്തിന്റെ -3. 95 വിളക്കുന്നതിന്റെയും കൂടി ട', 'mt': "F'dan id-dokument, aħna niddeskrivu s-sottomissjoni tal-Bering Lab lill-WMT 2020 Shared Task on Automatic Post-Editing (APE). L-ewwel nett, qed nipproponu arkitettura translingwistika tat-Transformer li tieħu konċidenza ta’ sentenza tas-sors u sentenza tradotta bil-magna (MT) bħala input biex tiġġenera l-output post-editat (PE). Għal aktar titjib, aħna naħbu kliem mhux korrett jew nieqsa fil-ħruġ tal-PE abbażi tal-istima tal-kwalità tal-livell tal-kliem u mbagħad nipprojbixxu l-kelma attwali għal kull maskra bbażata fuq il-mudell tal-lingwa traslingwi rfinut (XLM-RoBERTa). Finally, to address the over-correction problem, we select the final output among the PE outputs and the original MT sentence based on a sentence-level quality estimation.  Meta evalwata fuq is-sett tad-dejta tat-test tal-APE Ingliż-Ġermaniż tad-WMT 2020, is-sistema tagħna ttejjeb il-produzzjoni tal-NMT bi -3.95 u +4.50 f’termini ta’ TER u BLEU, rispettivament.", 'pl': 'W niniejszym artykule opisujemy zgłoszenie Bering Lab do WMT 2020 Shared Task on Automatic Post-Editing (APE). Po pierwsze, proponujemy architekturę transformatora wielojęzycznego, która przyjmuje łączenie zdania źródłowego i zdania maszynowo przetłumaczonego (MT) jako wejście do generowania wyjścia po edycji (PE). W celu dalszej poprawy maskujemy nieprawidłowe lub brakujące słowa w wyjściu PE na podstawie oszacowania jakości słowa na poziomie słowa, a następnie przewidujemy rzeczywiste słowo dla każdej maski w oparciu o dopracowany model języka wielojęzycznego (XLM-RoBERTa). Wreszcie, aby rozwiązać problem nadmiernej korekty, wybieramy wyjście końcowe spośród wyjść PE i oryginalne zdanie MT na podstawie oszacowania jakości na poziomie zdania. Po ocenie na angielsko-niemieckim zestawie danych testowych APE WMT 2020 nasz system poprawia wyjście NMT odpowiednio o -3.95 i +4.50 pod względem TER i BLEU.', 'ro': 'În această lucrare, descriem depunerea laboratorului Bering la activitatea partajată WMT 2020 privind posteditarea automată (APE). În primul rând, propunem o arhitectură translingvă Transformer care ia concatenarea unei propoziții sursă și a unei propoziții traduse automat (MT) ca intrare pentru a genera ieșirea post-editată (PE). Pentru îmbunătățiri suplimentare, mascăm cuvintele incorecte sau lipsă în ieșirea PE pe baza estimării calității nivelului de cuvânt și apoi prezicem cuvântul real pentru fiecare mască pe baza modelului de limbă translingvistică reglat fin (XLM-RoBERTa). În cele din urmă, pentru a aborda problema supracorrecției, selectăm ieșirea finală dintre ieșirile PE și propoziția MT inițială pe baza unei estimări a calității la nivel de frază. Atunci când este evaluat pe setul de date de testare APE engleză-germană WMT 2020, sistemul nostru îmbunătățește ieșirea NMT cu -3,95 și +4,50 în termeni de TER și, respectiv, BLEU.', 'no': 'I denne papiret beskriver vi at Bering Lab s øker til delt oppgåve WMT 2020 på automatisk postredigering (APE). Først foreslår vi eit krysspråksomformeringsarkitektur som tar ein sammenlikning av ein kjeldesetning og ein teikn med maskin omsetjing (MT) som ein inndata for å laga etter redigerte (PE) utdata. For meir forbetringa maskerer vi feil eller manglar ord i PE-utdata basert på estimerasjon av ordnivåkvaliteten og så foregår vi det faktiske ordet for kvar maske basert på den fint krysspråk-modellen (XLM-RoBERTa). For å setja opp overkorrigeringsproblemet, vel vi den siste utdata mellom PE-utdata og den opprinnelige MT-setninga basert på ein estimation av setningsnivå. Når det er evaluert på datasettet WMT 2020 for anglestysk APE-testar, vert systemet vårt forbetra NMT-utdata med -3,95 og +4,50 i tillegg til TER og BLEU.', 'si': 'මේ පත්තරේ අපි බෙරින්ග් ලැබ් එකේ WMT 2020යි ස්වයංක්\u200dරියාත්මක පස්ස සංපාදනය (APE) ගැන සාමාන්\u200dය වැඩක් විස්තර කරනවා. මුලින්, අපි ක්\u200dරීස් භාෂාවක් වෙනස් විද්\u200dයාපක විද්\u200dයාපක විද්\u200dයාපක විද්\u200dයාපක විද්\u200dයාපක විද්\u200dයාපක විද්\u200dයාපක විද්\u200dයාපක විද්\u200dයාපක විද තවත් වැඩි වැඩි විස්තර සඳහා, අපි PE ප්\u200dරවෘත්තියේ වැරැද්දක් නැති වචන් අවස්ථාව කරනවා, පස්සේ වචන වචන වචන අවස්ථාව සඳහා පස්සේ ප්\u200dරවෘත්තිය වච අන්තිමේදි, ප්\u200dරශ්නයක් වැඩි වැඩි වැඩ කරන්න, අපි PE ප්\u200dරශ්නයක් අන්තිම ප්\u200dරශ්නයක් සහ ප්\u200dරශ්නයක් MT වාක්ය අනුවෙන් තෝ WMT 2020යි ඉංග්\u200dරීසිය-ජර්මන් APE පරීක්ෂණ දත්ත සැට විශ්වාස කළොත්, අපේ පද්ධතිය NMT ප්\u200dරවෘතිය -3.95 සහ +4.50 ටෙර් සහ BLUE වලින් ප', 'so': "Qoraalkan waxaynu ku qornaa warqaddan warqadda Bering Lab oo loo soo dhiibay WMT 2020 oo lagu sharciyey shaqo ku saabsan Automatic Post-Editing (APE). Marka ugu horeysa, waxaynu soo jeedaynaa dhismo ku qoran luuqadaha lagu turjumo oo ku qorayo xukunka sourceed iyo qoraalka machine-translated (MT) si uu u sameeyo soo bixinta ka dib-edited (PE). Si loo hagaajiyo dheeraad ah, waxaynu ku daboolnaa hadal aan hagaagsanayn ama aan ka baaqan hadalka PE, waxaynu ku qornaa qiimeynta qiimeynta heerka, kadibna waxaynu ka hor dhignaa hadalka rasmiga ah ee mask kasta oo ku saleysan tilmaamaha afka luuqada kala duwan (XLM-RoBERta). Ugu dambaysta, si aan u macaamiloono dhibaatada hagaajinta, waxaynu dooranaynaa dhamaadka soo baxa PE iyo go'aanka asalka ah ee MT oo ku saleysan qiimeynta qiimaha heerka. Marka lagu qiimeeyo qoraalka baaritaanka ee WMT 2020 Ingiriis-German APE, nidaamkayaga ayaa u hagaajiya soo bixinta NMT ee ugu qoran TER iyo BLEU.", 'sr': 'U ovom papiru opisujemo podatke Bering Lab-a na delovani zadatak WMT 2020 o automatskom posledištu editiranja (APE). Prvo, predlažemo krstojezičku arhitekturu transformera koja uzima potvrdu izvorne rečenice i rečenicu prevedenu mašinom (MT) kao ulaz kako bi stvorila post-editirani (PE) izlaz. Za daljnje poboljšanje, maskiramo nepravedne ili nestale reči u izveštaju PE-a na osnovu procjene kvalitete reči na nivou reči, a onda predviđamo pravu reč za svaku masku na osnovu fino napravljenog krsnojezičkog modela (XLM-RoBERTa). Konačno, da bi se riješili problem preko korekcije, odabrali smo konačni izlaz između ishoda PE-a i originalne rečenice MT-a na temelju procjene kvalitete rečenice na nivou rečenica. Kada je procjena na testu podataka WMT 2020-a na engleskom-nemačkom APE-u, naš sistem poboljšava proizvod NMT-a od -3,95 i +4,50 u odnosu na TER i BLEU.', 'mn': 'Энэ цаасан дээр бид Берингийн лабораторийн WMT 2020-ын автоматжуулалтын өмнө зохицуулах (APE) болон хуваалтын ажлыг тайлбарлаж байна. Эхлээд бид хэлний Төрвөлжүүлэгч архитектурыг санал болгож, эх үүсвэрийн өгүүлбэр болон машин орчуулагдсан (MT) өгүүлбэр (PE) үржүүлбэрийг үүсгэх боломжтой болгодог. Дараагийн сайжруулалтын тулд бид PE гаргасан үг буруу эсвэл алдагдсан үгсийг үг түвшинд баялагдсан, дараа нь хэл хэлний загварын үндсэн хэлбэрээр (XLM-RoBERTa) бүрт газрын зураг бүрт жинхэнэ үгсийг таамаглах болно. Эцэст нь, илүү зөв асуудлыг шийдэхийн тулд бид PE-ын үр дүнд хамгийн сүүлийн үр дүнг, мөн эхний MT өгүүлбэрийг өгүүлбэрийн түвшинд сайн баталсан. WMT 2020-н Англи-Герман APE тест өгөгдлийн санг үнэлэхэд бидний систем NMT-ын гаралтыг TER болон BLEU-н хувьд -3.95 болон +4.50-д сайжруулдаг.', 'sv': 'I denna uppsats beskriver vi Bering Labs bidrag till WMT 2020 Shared Task on Automatic Post-Editing (APE). Först föreslår vi en tvärspråklig transformatorarkitektur som tar en sammankoppling av en källmening och en maskinöversatt (MT) mening som en indata för att generera den efterredigerade (PE) utgången. För ytterligare förbättringar maskerar vi felaktiga eller saknade ord i PE-utmatningen baserat på kvalitetsuppskattning på ordnivå och förutsäger sedan det faktiska ordet för varje mask baserat på den finjusterade tvärspråksmodellen (XLM-RoBERTa). Slutligen, för att ta itu med problemet med överkorrektion, väljer vi slutresultatet bland PE-utgångarna och den ursprungliga MT-meningen baserat på en kvalitetsuppskattning på meningsnivå. När det utvärderas på WMT 2020 engelsk-tyska APE-testdatauppsättningen förbättrar vårt system NMT-utgången med -3,95 respektive +4,50 i termer av TER respektive BLEU.', 'ta': 'இந்த காகிதத்தில், நாம் விவரிக்கிறோம் பெரிங் லாப் 2020 பங்கிடப்பட்ட பணியை தானியங்கி திருத்தும் பின்தொகுப்பில் தானி முதலில், நாம் மொழி மாற்றும் உருவாக்கத்தை பரிந்துரைக்கிறோம். அது மூல வாக்கியத்தின் ஒன்றிணைக்கும் மற்றும் ஒரு இயந்திரம் மொழிமாற்றப்பட்ட வாக்கிய For further improvement, we mask incorrect or missing words in the PE output based on word-level quality estimation and then predict the actual word for each mask based on the fine-tuned cross-lingual language model (XLM-RoBERTa).  இறுதியாக, மேல் திருத்தம் பிரச்சனையை முடிவு செய்ய, PE வெளியீட்டிற்கும் இடையில் முடிவு வெளியீட்டை தேர்ந்தெடுக்க,  WMT 2020 ஆங்கிலம்- ஜெர்மன் APE சோதனை தரவுத்தளத்தில் மதிப்பிடப்பட்டால், எங்கள் அமைப்பு -3. 95 மற்றும் + 4. 50 TER மற்றும் BLEU க்கு மேலாக மாற்றுகிறது.', 'ur': 'اس کاغذ میں ہم نے برینگ لاب کے مطابق WMT 2020 شریک ٹاکس (APE) کے بارے میں سفارشی کرتا ہے۔ پہلے، ہم ایک کرس زبان ترنسفور معماری پیشنهاد کریں جو ایک سورس جماعت اور ایک ماشین ترجمہ (MT) جماعت کو پیچھے سمجھا ہوا (PE) آوٹ پیدا کرنے کے لئے اپنا اینپیٹ بنانا چاہتا ہے. اور اضافہ کے لئے، ہم PE اپوٹٹٹ میں غلط یا گم ہوئے کلمات کو کلمات کے کیفیت کا ارزش پر بنیاد رکھتے ہیں اور پھر ہر ماسک کے لئے واقعی کلمات کا ارزش پیش بینی کریں جو پاکیزہ کلمات کی مدل پر (XLM-RoBERTa) ہے۔ آخر میں، زیادہ سیدھی مسئلہ کے بارے میں، ہم PE آئٹپوٹ کے درمیان آخری آئٹپوٹ کا انتخاب کریں گے اور اصلی MT ویٹ ویٹ ویٹ ویٹ ویٹ ویٹ ویٹ ویٹ ویٹ کیلوٹ کی ارزش پر بنیاد رکھتے جبکہ WMT 2020 میں انگلیسی-جرمنی APE ٹیسٹ ڈیٹ سٹ پر ارزش کیا گیا تھا، ہماری سیسٹم نے NMT آئٹ آئٹ -3.95 اور +4.50 کے مطابق TER اور BLEU کے مطابق اضافہ کیا ہے۔', 'uz': "Bu qogʻozda biz 2020 yildan avtomatik tahrirlash (APE) vazifani WMT bilan birlashtirilgan vazifani aytishimiz mumkin. Birinchi so'zda, biz bir necha tillar tarjima etishni tahrirlash uchun bir manba soʻzni va bir mashina tarjima qiluvchi (MT) soʻzni kiritish uchun ishlatiladi. Koʻproq yaxshi ko'rib chiqarish uchun biz PE natijadagi notoʻgʻri so'zlarni qo'yishingiz yoki yoʻq so'zlar qiymatiga qarasamiz va keyin bir necha tillar modeli (XLM-RoBERTA) asosida ko'rsatish mumkin. @ info WMT 2020 Ingliz-Olmon APE sinov maʼlumotlari tarkibida qiymatda, bizning tizimimiz TER va BLEU bilan - 3.95 va + 4.50 tilida NMT natijasini o'zgartiradi.", 'vi': 'Trong tờ giấy này, chúng tôi mô tả việc giao nộp phòng thí nghiệm Bering cho Công việc chia s ẻ WRT 2020 về Automatic Post-Editing (APE). Đầu tiên, chúng tôi đề xuất một kiến trúc biến hình xuyên ngôn ngữ mà cần một sự kết hợp của một câu từ nguồn và một câu được dịch cỗ máy (MTV) để tạo ra kết quả sau biên tập (PE). Để cải tiến thêm, chúng tôi che giấu các từ không đúng hay bị mất trong đầu xuất thể hình nền dựa trên đánh giá chất lượng từ cấp và sau đó dự đoán các từ thực tế cho mỗi mặt nạ dựa trên mô hình ngôn ngữ được chỉnh lại (XLM-RoBERTa). Cuối cùng, để giải quyết vấn đề sửa chữa quá mức, chúng tôi chọn kết quả cuối cùng trong các xuất thể dục và câu cuối cùng trên kênh MTV dựa trên một đánh giá chất lượng bản án. Khi đánh giá trên tập tin thử nghiệm WM 2020 Tiếng Anh-Đức APE, hệ thống của chúng tôi cải thiện sản xuất NMB của....3.95 và hợp chất W và bắn liên tục.', 'bg': 'В тази статия описваме представянето на лабораторията Беринг в Споделената задача за автоматичното пост-редактиране (АПЕ) 2020. Първо, ние предлагаме междуезична архитектура на трансформатора, която приема конкатенацията на изречение източник и машинно преведено изречение (МТ) като вход за генериране на пост-редактирания (ПЕ) изход. За по-нататъшно подобрение маскираме неправилни или липсващи думи в изхода на ПЕ въз основа на оценка на качеството на думите и след това предсказваме действителната дума за всяка маска въз основа на фино настроения междуезичен език модел (XLM-RoBERTa). Накрая, за да се справим с проблема със свръхкорекцията, избираме крайния изход сред изходите на ПЕ и първоначалното МТ изречение въз основа на оценка на качеството на изречението. Когато се оценява на англо-немски тест набор от данни, нашата система подобрява изхода на НМТ съответно с -3.95 и +4.50 по отношение на ТЕР и БЛЕУ.', 'hr': 'U ovom papiru opisujemo podatke Bering Lab-a na zajednički zadatak WMT 2020 o automatskom posledištu editiranja (APE). Prvo, predlažemo ukrštenu arhitekturu transformatora koja uzima zaključavanje izvorne rečenice i rečenice prevedene na stroj (MT) kao ulaz kako bi stvorila posteditirani (PE) izlaz. Za daljnje poboljšanje, maskiramo nepravedne ili nestale riječi u izlazu PE-a na temelju procjene kvalitete riječi na razini, a onda predviđamo pravu riječ za svaku masku na temelju fino napravljenog krsnojezičkog modela (XLM-RoBERTa). Na kraju, kako bi se riješili problem preko korekcije, odabrali smo konačni izlaz između ishoda PE-a i originalnu rečenicu MT-a na temelju procjene kvalitete razine rečenica. Kada je procjena na kompletu podataka o testu engleskog i njemačkog APE-a WMT 2020, naš sustav poboljšava proizvod NMT-a od -3,95 i +4,50 u odnosu na TER i BLEU.', 'nl': 'In dit artikel beschrijven we de inzending van het Bering Lab aan de WMT 2020 Shared Task on Automatic Post-Editing (APE). Ten eerste stellen we een cross-lingual Transformer architectuur voor die een aaneenschakeling van een bronzin en een machine-vertaalde zin (MT) als input neemt om de post-edited (PE) output te genereren. Voor verdere verbetering maskeren we onjuiste of ontbrekende woorden in de PE-uitvoer op basis van schatting van de kwaliteit op woordniveau en voorspellen we vervolgens het werkelijke woord voor elk masker op basis van het verfijnde cross-lingual taalmodel (XLM-RoBERTa). Ten slotte, om het probleem van overcorrectie aan te pakken, selecteren we de uiteindelijke output uit de PE-output en de oorspronkelijke MT-zin op basis van een schatting van de kwaliteit van zinnen. Wanneer geëvalueerd op de WMT 2020 Engels-Duitse APE test dataset, verbetert ons systeem de NMT output met -3.95 en +4.50 in termen van respectievelijk TER en BLEU.', 'da': 'I denne artikel beskriver vi Bering Labs indsendelse til WMT 2020 Shared Task on Automatic Post-Editing (APE). For det første foreslår vi en tværsproget Transformer arkitektur, der tager en sammenkobling af en kildesætning og en maskinoversat (MT) sætning som input til at generere den post-redigerede (PE) output. For yderligere forbedringer maskerer vi forkerte eller manglende ord i PE output baseret på ordniveau kvalitetsestimering og forudsiger derefter det faktiske ord for hver maske baseret på den finjusterede tværsprogede sprogmodel (XLM-RoBERTa). Endelig, for at løse problemet med overkorrektion, vælger vi det endelige output blandt PE output og den oprindelige MT sætning baseret på et kvalitetsestimat på sætningsniveau. Når vores system vurderes på WMT 2020 engelsk-tysk APE testdatasæt, forbedrer NMT output med henholdsvis -3,95 og +4,50 med hensyn til TER og BLEU.', 'de': 'In diesem Beitrag beschreiben wir die Einreichung des Bering Lab an die WMT 2020 Shared Task on Automatic Post-Editing (APE). Zunächst schlagen wir eine sprachübergreifende Transformer-Architektur vor, die eine Verkettung eines Quellsatzes und eines maschinell übersetzten Satzes (MT) als Eingabe verwendet, um die post-edited (PE) Ausgabe zu generieren. Zur weiteren Verbesserung maskieren wir falsche oder fehlende Wörter in der PE-Ausgabe basierend auf der Qualitätsschätzung auf Wortebene und prognostizieren dann das tatsächliche Wort für jede Maske basierend auf dem fein abgestimmten crosslingualen Sprachmodell (XLM-RoBERTa). Um das Problem der Überkorrektur anzugehen, wählen wir schließlich die endgültige Ausgabe aus den PE-Ausgaben und den ursprünglichen MT-Satz basierend auf einer Qualitätsschätzung auf Satzebene aus. Bei Auswertung auf dem englisch-deutschen APE-Testdatensatz WMT 2020 verbessert unser System die NMT-Ausgabe um -3.95 und +4.50 in Bezug auf TER bzw. BLEU.', 'id': 'Dalam kertas ini, kami menggambarkan pengiriman Bering Lab ke WMT 2020 Shared Task on Automatic Post-Editing (APE). Pertama, kami mengusulkan arsitektur Transformer saling bahasa yang mengambil konsentrasi dari kalimat sumber dan kalimat terjemahan mesin (MT) sebagai input untuk menghasilkan output post-edited (PE). Untuk memperbaiki lebih lanjut, kita menyembunyikan kata-kata yang salah atau hilang dalam output PE berdasarkan penilaian kualitas tingkat kata dan kemudian memprediksi kata-kata sebenarnya untuk setiap topeng berdasarkan model bahasa saling berbicara (XLM-RoBERTa). Akhirnya, untuk mengatasi masalah over correction, kami memilih output akhir diantara output PE dan kalimat MT asli berdasarkan penilaian kualitas tingkat kalimat kalimat. Ketika diteliti di dataset ujian APE bahasa Inggris-Jerman WMT 2020, sistem kami meningkatkan output NMT dengan -3.95 dan +4.50 dalam terma TER dan BLEU, sesuai.', 'tr': "Bu kagyzda, Bering Lab'yň WMT 2020-iň Otomatik Post-Editing (APE) meselesine beýleki zady tassykladyk. Ilkinji gezek, biz çeşme sözläni we maşynyň terjime edilen (PE) çizgisini bejermek üçin bir çarpaz dilli terjime arhitekturuny teklip edip bilýäris. Diňeje gelişmeler üçin PE çiftinde ýalňyş ýada ýok sözleri maskara çykaryp, soňra sözleriň kaliteli deňleşdirmegi ýaly we soňra her maske üçin dogry sözleriň üstine (XLM-RoBERTa) düzgün bir dil nusgasyna daýanýar. Soňunda, üstüne düzeltmek meseläni çözmek üçin, PE netijesinden soňky çykyş we önüm MT sözläni sözläniň derejesi hökmünde görkezmek üçin saýlaýrys. WMT 2020-nji ýylda Iňlisçe-nemesçe APE testi sahypalarynda deňlenýän wagtymyz sistemamyz TER we BLEU bilen -3.95 we +4.50 derejesinde çykyşyny gowurar.", 'fa': 'در این کاغذ، ما تحویل آزمایشگاه برینگ به کار مشترک WMT 2020 در مورد ویرایش بعد از ویرایش خودکار (APE) توصیف می\u200cکنیم. اول، ما یک معماری تغییر دهنده متوسط زبان پیشنهاد می\u200cکنیم که یک جمله منبع و یک جمله ماشین ترجمه شده (MT) را به عنوان یک ورودی برای تولید نتیجه بعد از ویرایش (PE) می\u200cگیرد. برای پیشرفت بیشتری، ما کلمات اشتباهی یا گم شده را در نتیجه PE بر اساس ارزیابی کیفیت سطح کلمات ماسک ماسک می کنیم و بعد کلمات واقعی را برای هر ماسک پیش بینی کنیم بر اساس مدل کلمات متوسط زبان (XLM-RoBERTa) تنظیم می کنیم. بالاخره، برای حل مشکل زیادی از اصلاح، آخرین نتیجه بین نتیجه\u200cهای PE و جمله\u200cی MT اصلی را بر اساس ارزیابی کیفیت سطح جمله انتخاب می\u200cکنیم. وقتی روی مجموعه داده\u200cهای آزمایش انگلیسی و آلمانی APE WMT 2020 ارزیابی شد، سیستم ما نتیجه NMT را با -3.95 و +4.50 به عنوان TER و BLEU بهتر می\u200cکند.', 'ko': '본고에서 우리는 화이트닝 실험실이 WMT 2020 자동 후기 편집 공유 임무(APE)에 제출한 상황을 묘사했다.먼저, 우리는 소스 문장과 기계 번역(MT) 문장을 입력으로 연결하여 생성 후 편집(PE) 출력을 만드는 크로스 언어 변환기 구조를 제시했다.더욱 개선하기 위해 우리는 단어급 품질을 바탕으로 PE 출력의 오류나 부족한 단어를 추정한 다음에 미조정 크로스 언어 모델(XLM-RoBERTA)을 바탕으로 모든 차단된 실제 단어를 예측한다.마지막으로 과도한 오류 수정 문제를 해결하기 위해 우리는 문장급의 질량 평가를 바탕으로 PE 출력과 원시 기계 번역 문장에서 최종 출력을 선택한다.우리의 데이터 집합이 WMT.4와 WMT.4에서 각각 영어와 영어로 평가될 때.', 'sw': 'Katika gazeti hili, tunaelezea ujumbe wa mababu ya Bering kwa ajili ya WMT 2020 ulioshirikishwa na kazi ya kuhariri baada ya kujitegemea (APE). Kwanza, tunapendekeza ujenzi wa Kitambo cha Transfer kwa lugha inayochukua ushirikiano wa sentensi ya vyanzo na hukumu ya mashine inayotafsiriwa (MT) kama input ili kutengeneza matokeo ya baada ya kuharibiwa (PE). For further improvement, we mask incorrect or missing words in the PE output based on word-level quality estimation and then predict the actual word for each mask based on the fine-tuned cross-lingual language model (XLM-RoBERTa).  Mwisho, ili kutangaza tatizo la kuharibiwa zaidi, tunachagua matokeo ya mwisho kati ya matatizo ya chama cha PE na hukumu ya awali ya MT kwa kutumia estimation ya kiwango cha kiwango cha hukumu. Wakati utafiti wa taarifa za uchunguzi wa WMT 2020-Uingereza-Ujerumani APE, mfumo wetu unaboresha matokeo ya NMT kwa asilimia 3.95 na +4.50 kwa ajili ya TER na BLEU.', 'am': 'በዚህ ገጽ፣ በጦማሪያው 2020 የተሰራጨውን ስራ በራሱ ፖስታ አስተካክል (APE) ለWMT አካባቢ የቤሪing ላብ አዋጅ እናሳውቃለን፡፡ በመጀመሪያው፣ የቋንቋ-ቋንቋ የተለየ የመክፈት መሠረት እና የመከቻዊ ትርጉም (MT) ፍርድ እንዲወስድ የፖስታ-አስተካክል (PE) ውጤት እንዲወስድ እንደምናስፈልገው መግለጫ እና የመስኮት ትርጉም እንዲሆን መፍጠርን እናሳልጋለን፡፡ ለሌላ ክፍተት፣ የPE ውጤት ቃላትን በቃላት-ደረጃ ጥያቄ በመጠቀም ወይም በመጠቀም እና በክፍለ ቋንቋ ቋንቋ ሞዴል (XLM-RoBERTA) የተመሳሳይ የደረጃ ቃላትን ለመቀበል እናስታውቃለን፡፡ በመጨረሻው የክፍለ-ደረጃ ጉዳይ ለመቀበል የኋለኛውን ውጤት በPE ውጤት እና በክፍለ-ደረጃ ውጤት መጠቀሚያ እና የመጀመሪያውን MT ክፍል እንመርጣለን፡፡ When evaluated on the WMT 2020 English-German APE test dataset, our system improves the NMT output by -3.95 and +4.50 in terms of TER and BLEU, respectively.', 'hy': 'Այս աշխատանքում մենք նկարագրում ենք Բերինգ լաբորատորիայի ներկայացումը ԱՄԹ 2020-ի ավտոմատիկ հետխմբագրման (APE) ընդհանուր հանձնարարության վրա: Առաջինը, մենք առաջարկում ենք փոխլեզվով ճարտարապետություն, որը վերցնում է աղբյուր նախադասությունը և մեքենայով թարգմանված նախադասությունը որպես ներմուծք, որպեսզի ստեղծվի հետխմբագրված (ՓԵ) արտադրությունը: Ավելի բարելավման համար մենք ծածկում ենք սխալ կամ բացակայած բառերը, որոնք հիմնված են բառի մակարդակի որակի գնահատման վրա, և ապա կանխատեսում ենք յուրաքանչյուր բառի իրական բառը, հիմնված գեղեցիկ փոխլեզվային լեզվի մոդելի (XLM-ROBERta) վրա: Վերջապես, չափազանց բարելավման խնդիրը լուծելու համար, մենք ընտրում ենք վերջնական արտադրությունը պոտենսի արտադրությունների և սկզբնական MT նախադասության միջև, հիմնված նախադասության մակարդակի որակի գնահատման վրա: Երբ ԱՄԹ 2020-ի անգլերեն-գերմանացի APE թեստերի տվյալների համակարգում գնահատվում է, մեր համակարգը բարելավում է NMT-ի արտադրությունը -3.95 և +4.50 թվականով TER-ի և Blue-ի առումով:', 'sq': 'Në këtë letër, ne përshkruajmë paraqitjen e Bering Lab në WMT 2020 Task Shared on Automatic Post-Editing (APE). Së pari, ne propozojmë një arkitekturë Transformer ndërgjuhësore që merr një përmbledhje të një fjalie burimi dhe një fjalie të përkthyer nga makina (MT) si një hyrje për të gjeneruar daljen pas-edituar (PE). For further improvement, we mask incorrect or missing words in the PE output based on word-level quality estimation and then predict the actual word for each mask based on the fine-tuned cross-lingual language model (XLM-RoBERTa).  Finally, to address the over-correction problem, we select the final output among the PE outputs and the original MT sentence based on a sentence-level quality estimation.  Kur vlerësohet në grupin e të dhënave të testimit të APE anglisht-gjerman WMT 2020, sistemi ynë përmirëson daljen e NMT me -3.95 dhe +4.50 respektivisht lidhur me TER dhe BLEU.', 'af': "In hierdie papier beskrywe on s die Bering Lab se onderskrywing aan die WMT 2020 deelde taak op Outomatiese Post-Redigering (APE). Eerste, ons voorstel 'n kruistale transformeerder arkitektuur wat neem 'n samelewing van' n bron seting en 'n masjien-vertaalde (MT) seting as 'n invoer om die post-redigeerde (PE) uitset te genereer. Vir verdere verbetering, maskeer ons verkeerde of miskiede woorde in die PE uitvoer gebaseer op woord- vlak kwaliteit estimatie en dan voorskou die werklike woord vir elke masker gebaseer op die fyn- tuned kruistale taal model (XLM- RoBERTa). Eindelik, om die oor- korreksie probleem te adres, kies ons die eindelike uitvoer onder die PE uitvoer en die oorspronklike MT seting gebaseer op 'n seting- vlak kwaliteit estimatie. Wanneer die WMT 2020-Engels-Duits APE-toets datastel evalueer word, verbeter ons stelsel die NMT-uitset met -3.95 en +4.50, respectively in terms of TER en BLEU.", 'ca': "En aquest article, descrivim la presentació del Bering Lab al WMT 2020 Shared Task on Automatic Post-Editing (APE). First, we propose a cross-lingual Transformer architecture that takes a concatenation of a source sentence and a machine-translated (MT) sentence as an input to generate the post-edited (PE) output.  For further improvement, we mask incorrect or missing words in the PE output based on word-level quality estimation and then predict the actual word for each mask based on the fine-tuned cross-lingual language model (XLM-RoBERTa).  Finalment, per abordar el problem a de correcció excessiva, seleccionem la producció final entre els productes PE i la frase MT original basada en una estimació de qualitat del nivell de frases. Quan es valora en el conjunt de dades d'APE anglès-alemanya del WMT 2020, el nostre sistema millora la producció de NMT en -3,95 i +4,50 en termes de TER i BLEU, respectivament.", 'bs': 'U ovom papiru opisujemo podatke Bering Lab-a podijeljenom zadatku WMT 2020 o automatskom posledištu editiranja (APE). Prvo, predlažemo krstojezičku arhitekturu transformera koja uzima zaključavanje izvorne rečenice i rečenice prevedene na mašinu (MT) kao ulaz kako bi stvorila post-editirani (PE) izlaz. Za daljnje poboljšanje, maskiramo nepravedne ili nestale riječi u izveštaju PE-a na temelju procjene kvalitete riječi na nivou kvalitete, a onda predviđamo pravu riječ za svaku masku baziranu na finom krsnojezičkom modelu (XLM-RoBERTa). Konačno, da bi se riješili problem preko korekcije, odabrali smo konačni izlaz između ishoda PE-a i originalnu rečenicu MT-a na temelju procjene kvalitete razine rečenica. Kada je procjena na testu podataka WMT 2020-a na engleskom i njemačkom APE-u, naš sistem poboljšava proizvod NMT-a od -3,95 i +4,50 u odnosu na TER i BLEU.', 'bn': 'এই কাগজটিতে আমরা বেরিং ল্যাব ব্যাখ্যা করেছি উইএমটি ২০২০ স্বয়ংক্রিয় পোস্ট-সম্পাদনার (এপিই) কাজের প্রতি শেয়ার করা হয়েছে। প্রথমত, আমরা একটি ক্রস-ভাষাভাষী ট্রান্সফ্রান্সভার আর্কিটেক্টারের প্রস্তাব করছি যা একটি উৎসের বাক্য এবং একটি মেশিন অনুবাদ করা মেশিনের বাক্য হিসেবে একটি ই আরো উন্নয়নের জন্য আমরা পেরি আউটপুটের ভুল বা নিখোঁজ শব্দ মুখোশ করি শব্দের মানের মান হিসেবে ভিত্তিতে এবং তারপর ভবিষ্যদ্বাণী করি প্রত্যেক মুখোশের জন্য প্রকৃত শব্দে শেষ পর্যন্ত, বেশী সংশোধনী সমস্যার সাথে কথা বলার জন্য, আমরা পিএপি আউটপুটের মধ্যে চূড়ান্ত আউটপুট বেছে নিই এবং বাক্য-স্তরের মানের মূ যখন উইএমটি ২০২০ ইংরেজী ও জার্মান এপিই পরীক্ষার ডাটাসেটে মূল্য প্রদান করা হয়, তখন আমাদের সিস্টেম টের আর বিলিউ এর মাধ্যমে -৩. ৯৫ এবং ৪.', 'et': 'Käesolevas artiklis kirjeldame Beringi labori esitamist WMT 2020 ühisele automaatse järelredigeerimise ülesandele (APE). Esiteks pakume välja keeleülese transformaatori arhitektuuri, mis võtab lähtelause ja masintõlgitud lause (MT) ühendamise sisendina järeltediteeritud (PE) väljundi genereerimiseks. Täiendava täiustamise eesmärgil maskeerime PE väljundis valed või puuduvad sõnad sõnataseme kvaliteedi hindamise põhjal ja prognoosime seejärel iga maski tegeliku sõna peeneldatud keeleülese keelemudeli (XLM-RoBERTa) põhjal. Lõpuks valime ülekorrektsiooni probleemi lahendamiseks lõpliku väljundi PE väljundite hulgast ja algse MT lause lausetaseme kvaliteedi hindamise põhjal. Kui hinnatakse WMT 2020 inglise-saksa APE testiandmekogumit, parandab meie süsteem NMT väljundit vastavalt -3,95 ja +4,50 võrra TER ja BLEU osas.', 'az': "Bu kağızda, biz Bering Lab'ın WMT 2020'nin Avtomatik Post-Editing (APE) barəsində paylaşılmış işi təsdiqlədiyini təsdiqləyirik. İlk dəfə, çox dilli Transformer arhitektarını təbliğ edirik ki, mənbə cümləsini və maşına çevirilmiş cümləsini sonrakı (PE) çıxışını yaratmaq üçün bir giriş olar. Daha da yaxşılaşdırmaq üçün, PE çıxımında yanlış və ya qeyb sözləri sözlərin keyfiyyəti hesablamasına dayandırır və sonra hər mask ə üçün həqiqət sözləri müəyyən edilmiş çox dil modeli (XLM-RoBERTa) üzərində təmin edirik. Sonunda, çox düzəltmə problemini çəkmək üçün, PE çıxışları arasında son çıxışı seçdik və sözlərin seviyyəti qiymətinə dayanan original MT sözləri seçdik. WMT 2020-li İngilizə-Almanca APE sınama verilənləri təyin etdikdə, sistemimiz NMT çıxışını TER və BLEU ilə -3.95 və +4.50 ilə yaxşılaşdırır.", 'fi': 'Tässä artikkelissa kuvailemme Bering Labin osallistumista WMT 2020 Shared Task on Automatic Post-Editing (APE) -ohjelmaan. Ensin ehdotamme monikielistä Transformer-arkkitehtuuria, joka ottaa lähdelauseen ja konekäännetyn lauseen yhdistämisen syötteenä post-edited (PE) -tuotoksen tuottamiseen. Parannuksia varten peitämme PE-tuotoksessa virheelliset tai puuttuvat sanat sanatason laatuarvion perusteella ja ennustamme kunkin maskin todellisen sanan hienosääteisen kielimallin (XLM-RoBERTa) perusteella. Ylikorjausongelman ratkaisemiseksi valitaan lopputuotos PE-tuotoksista ja alkuperäinen MT-lause lausetason laatuarvion perusteella. WMT 2020:n englannin-saksan APE-testiaineistolla arvioituna järjestelmämme parantaa NMT-tuotosta -3,95 ja +4,50 TER:n ja BLEU:n osalta.', 'cs': 'V tomto článku popisujeme podání Beringovy laboratoře k WMT 2020 Shared Task on Automatic Post-Editing (APE). Nejprve navrhujeme architekturu transformátoru, která bere řetězení zdrojové věty a strojově přeložené věty jako vstup pro generování post-editovaného (PE) výstupu. Pro další zlepšení maskujeme nesprávná nebo chybějící slova ve výstupu PE na základě odhadu kvality slova na úrovni slova a pak předpovídáme skutečné slovo pro každou masku na základě jemně vyladěného cross-jazyčného modelu (XLM-RoBERTa). Na závěr, abychom řešili problém nadměrné korekce, vybereme konečný výstup mezi PE výstupy a původní MT větu na základě odhadu kvality na úrovni věty. Při hodnocení na anglicko-německém testovacím datu APE WMT 2020 náš systém zlepšuje NMT výstup o -3,95 a +4,50 z hlediska TER a BLEU.', 'ha': "Ga wannan takardan, Munã bayyana al'amarin na Bering Lab zuwa WMT 2020 Shared Tafiyar da aka yi wa shirin da shi na farat-Editing (Apple). Kayyar da, za'a goyyade wani matsayin Transformer na-linguin na fara-harshen-nau'in da ke samu wata kalma na cũtarwa da aka fassara (MT) kamar wata matsayi da aka shigar da shi don ya sami fitarwa na bayan-edited (PA). Ko dõmin ƙari, za'a rufe magana mai maras inganci ko kuma idan ba'a gane ba a cikin shirin PA kan kimar-daraja na ƙayyade maganar-daraja kuma ka yi ƙyacewa da magana na gaske kan kõwane fuskar kwamfyuta a kan misalin misalin harshen mai kyau-tunkuɗe (XLM-RoBERTA). Ga ƙarshe, dõmin a yi amfani da masu shirya, za'a zãɓe ƙarshen fitarwa a cikin shirin da ake fitarwa na PA da cewa na asalin MT a kan ƙidãya mai girma ga matsayin-daraja. Idan an evaluce shi a tsarin jarraba ɗin WMT 2020-Ingiriya-Jarman Apple ɗin, na'uranmu yana ƙarfafa gabatarwa na NMT da -3.95 da+4.50, game da gwargwadon TeR da BLEU.", 'he': 'בעיתון הזה, אנחנו מתארים את ההעברה של מעבדת ברינג למשימה המשותפת של WMT 2020 על העוררת אוטומטית (APE). First, we propose a cross-lingual Transformer architecture that takes a concatenation of a source sentence and a machine-translated (MT) sentence as an input to generate the post-edited (PE) output.  For further improvement, we mask incorrect or missing words in the PE output based on word-level quality estimation and then predict the actual word for each mask based on the fine-tuned cross-lingual language model (XLM-RoBERTa).  סוף סוף, כדי להתמודד עם בעיית תיקון יתר, אנחנו בוחרים את ההוצאה הסופית בין תוצאות PE והמשפט המקורי MT מבוסס על הערכת איכות רמת המשפט. כשהערכנו על קבוצת נתוני בדיקות APE אנגלית-גרמנית WMT 2020, המערכת שלנו משפר את יציאת NMT ב -3.95 ו +4.50 במונחים TER ו BLEU, בהתאם.', 'sk': 'V tem prispevku opisujemo predložitev Beringovega laboratorija v skupno nalogo WMT 2020 o samodejnem postnem urejanju (APE). Najprej predlagamo medjezično arhitekturo transformatorjev, ki uporablja konatenacijo izvornega stavka in strojno prevedenega stavka (MT) kot vhod za ustvarjanje post-urejenega (PE) izhoda. Za nadaljnje izboljšave prikrivamo napačne ali manjkajoče besede v izhodu PE na podlagi ocene kakovosti besed na ravni besed in nato napovedamo dejansko besedo za vsako masko na podlagi natančno nastavljenega medjezičnega jezikovnega modela (XLM-RoBERTa). Za reševanje problema prekomernega popravka izberemo končni izhod med izhodi PE in prvotni stavek MT na podlagi ocene kakovosti stavka. Pri ocenjevanju na angleško-nemškem naboru podatkov APE WMT 2020 naš sistem izboljša izhod NMT za -3,95 oziroma +4,50 v smislu TER oziroma BLEU.', 'jv': 'Nang pemilih iki, kita rambaran ngerasai masa Bering Lab kanggo ngilangno WT 2020 Tarjamahan sing gawe lan auto-Edit (ApE). Awak dhéwé, ngéwé ngeruhke karo-nggambar Transformer architecture sing teka saatur dhéwé source seneng karo milin-terjamahan (MT) seneng input kanggo nggawe output beke-edited (PA). Nyong-lungi luwih dumadhi, kita masa mengko akeh atawa ora mengko awak dhéwé mengko nggawe kalite kuwi mau, lan unyek wih apik dhéwé kuwi nggawe awak dhéwé kanggo saben mask basa sak versi sing wis dumadhi saben kelangan langgambar am model (XLM-RBERT). Fine Awak dhéwé éntuk kalih-kalih sing nyengkuyung ning dataset nggambar Iwak 2020-German, sistem sing nyengkuyung nggawe NMT kanggo nyengkuyung -3.5 lan +4.5 sing titimbang MER karo BEL, sing berarti tambah.', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཉེན་ཁ་བྱེད་པའི་ལྟ་བུའི་ནང་གི་མཉམ་སྤྱོད་ཀྱི་འཇུག་སྣོད་WMT 2020་ལ་རང་འགུལ First, we propose a cross-lingual Transformer architecture that takes a concatenation of a source sentence and a machine-translated (MT) sentence as an input to generate the post-edited (PE) output. For further improvement, we mask incorrect or missing words in the PE output based on word-level quality estimation and then predict the actual word for each mask based on the fine-tuned cross-language model (XLM-RoBERTa). Finally, to address the over-correction problem, we select the final output among the PE outputs and the original MT sentence based on a sentence-level quality estimation. When evaluated on the WMT 2020 English-German APE test dataset, our system improves the NMT output by -3.95 and +4.50 in terms of TER and BLEU, respectively.'}
{'en': 'POSTECH-ETRI’s Submission to the WMT2020 APE Shared Task : Automatic Post-Editing with Cross-lingual Language Model', 'ar': 'تقديم POSTECH-ETRI إلى المهمة المشتركة WMT2020 APE: التحرير التلقائي اللاحق باستخدام نموذج لغوي متعدد اللغات', 'pt': 'Submissão da POSTECH-ETRI à tarefa compartilhada WMT2020 APE: pós-edição automática com modelo de idioma multilíngue', 'es': 'Presentación de POSTECH-ETRI a la tarea compartida de APE WMT2020: Posedición automática con modelo de lenguaje multilingüe', 'fr': 'Soumission de POSTECH-ETRI à la tâche partagée WMT2020 APE\xa0: post-édition automatique avec modèle linguistique multilingue', 'ja': 'WMT 2020 APE共有タスクへのPOSTECH - ETRIの提出：クロスリンガルモデルによる自動ポストエディット', 'zh': 'POSTECH-ETRI向WMT2020 APE共事者提交:用跨语言自译后编辑', 'hi': 'POSTECH-ETRI का WMT2020 APE साझा कार्य के लिए सबमिशन: क्रॉस-भाषी भाषा मॉडल के साथ स्वचालित पोस्ट-एडिटिंग', 'ru': "POSTECH-ETRI 's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-lingual Language Model", 'ga': 'Aighneacht POSTECH-ETRI chuig Tasc Comhroinnte WMT2020 APE: Iar-Eagarthóireacht Uathoibríoch le Múnla Teanga Trasteangach', 'el': 'Υποβολή της στην Κοινή Εργασία του ΟΠΕ: Αυτόματη Μεταεπεξεργασία με Διάγλωσσο Γλωσσικό Μοντέλο', 'hu': 'A POSTECH-ETRI beküldése a WMT2020 APE megosztott feladathoz: automatikus utószerkesztés többnyelvű nyelvű modellel', 'it': 'Invio di POSTECH-ETRI al WMT2020 APE Shared Task: Post-Editing automatico con modello linguistico multilingue', 'kk': 'POSTECH-ETRI WMT2020 APE ортақтастырылған тапсырмасына жіберу: Қос тіл үлгісімен автоматты түрде өңдеу', 'lt': 'POSTECH-ETRI pristatymas prie WMT2020 APE bendros užduoties: automatinis po redakcijos su tarpkalbiniu kalbų modeliu', 'mk': 'Предавањето на POSTECH-ETRI на заедничката задача на WMT2020 APE: Автоматско постуредување со крстојазичен јазички модел', 'ka': 'POSTECH-ETRI-ის WMT2020 APE გაყოფილი დავალება: ავტომატური დარედაქტირება მრავალური ენის მოდელზე', 'ms': 'Submission POSTECH-ETRI to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-language Language Model', 'ml': 'WMT2020 APE പങ്കാളിയുള്ള ജോലിയിലേക്ക് പോസ്റ്റെച്ച്- എട്രിയിന്റെ സബ്മിഷന്\u200d: ക്രോസ്- ഭാഷ മോഡിള്\u200d ക്രോസ്സ്- ഭാഷ മോഡില', 'mn': "POSTECH-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-Language Model", 'mt': 'Is-Sottomissjoni ta’ POSTECH-ETRI għall-Kompitu Kondiviż tal-APE WMT2020: Post-Editing Awtomatiku b’Mudell tal-Lingwi Translingwi', 'sr': 'POSTECH-ETRI podnosi na delovani zadatak WMT2020 APE-a: automatski post-editing sa krstojezičkim modelom', 'ro': 'Trimiterea POSTECH-ETRI la WMT2020 APE Activitate partajată: Editare automată postlingvă cu modelul limbajului translingv', 'no': "POSTECH-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-Language Language Model", 'si': "POSTECH-ETRI's Sub-action to the WMT202E APE shared Job: Auto Post-edit with Cross-language Model", 'pl': 'Zgłoszenie POSTECH-ETRI do WMT2020 APE Wspólne Zadanie: Automatyczna edycja post-edycyjna z modelem językowym wielojęzycznym', 'sv': 'POSTECH-ETRI:s inlämning till WMT2020 APE delad uppgift: Automatisk efterredigering med flerspråkig språkmodell', 'ur': "POSTECH-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-Language Model", 'so': "POSTECH-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-language Model", 'ta': 'POSTECH- ETRI WMT2020 APE பகிர்ந்த பணிக்கு ஒப்பு', 'uz': 'Name', 'vi': 'Công việc chia s ẻ của POTECH-TERI: Automatic Post-Editing with Cross-ngôn ngữ rộng Model ngôn ngữ', 'da': "POSTECH-ETRI's indsendelse til WMT2020 APE delt opgave: Automatisk efterredigering med tværsproget sprogmodel", 'bg': 'Споделена задача на ПОТЕХ-ЕТРИ: Автоматично пост-редактиране с междуезичен езиков модел', 'nl': 'De inzending van POSTECH-ETRI aan de WMT2020 APE Shared Task: Automatische nabewerking met meertalig taalmodel', 'hr': 'POSTECH-ETRI podnosi zadatak WMT2020 APE-a: automatsko nakon redakcije s preko jezičkog modela', 'de': 'Beitrag von POSTECH-ETRI zur WMT2020 APE Shared Task: Automatische Nachbearbeitung mit sprachübergreifendem Modell', 'ko': 'POSTECH-ETRI가 WMT2020 APE 공유 작업에 제출: 다중 언어 모델을 사용한 자동 사후 편집', 'tr': "POSTECH-ETRI'nin WMT2020 APE paylaşılmış görevi: Cross-language Modeli ile otomatik Post-Editing", 'fa': 'Submission of POSTECH-ETRI to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-Language Model', 'sw': 'Ujumbe wa POSTECH-ETRI kwenye kazi ya WMT2020 APE ilishiriki: Kuhariri Uhuru wa kujitegemea na Modeli ya Lugha ya Kimataifa', 'sq': "POSTECH-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-lingual Language Model", 'af': 'POSTECH-ETRI se Submission na die WMT2020 APE deelde taak: Outomatiese Post-Redigering met Cross-lingual Taal Model', 'am': "POSTECH-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-language Model", 'hy': 'POSTACH-EtRI-ի ներկայացումը World MT2020 APE-ի ընդհանուր հանձնարարությանը՝ Ավտոմատիկ հետխմբագրությունը երկլեզվային լեզվի մոդելի հետ', 'az': "POSTECH-ETRI'nin WMT2020 APE paylaŇüńĪlmńĪŇü iŇüi il…ô istifad…ô etm…ôsi: X…ôrc dil modeli il…ô otomatik Post-Editing", 'bs': 'POSTECH-ETRI podnosi na delovani zadatak WMT2020 APE-a: automatsko post-editiranje sa krstojezičkim modelom', 'cs': 'Podání společnosti POSTECH-ETRI do sdíleného úkolu WMT2020 APE: Automatická post-editace s modelem cross-jazyčného jazyka', 'ca': "Posech-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-Language Model", 'et': 'POSTECH-ETRI esitus WMT22020 APE jagatud ülesandele: automaatne järelredigeerimine keeleülese mudeliga', 'fi': 'POSTECH-ETRI:n julkaisu WMT22020 APE:n jaettuun tehtävään: Automaattinen jälkimuokkaus monikielisellä kielimallilla', 'bn': "WMT2020 APE শেয়ার করার কাজে পোস্টেচ-ETRI's Submission: Cross-language mode", 'id': "POSTECH-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-language Language Model", 'jv': "po-ETRI's Submis to the WW2020 ApE shared tasks: Automatically After-Edit with Krot-language Language model", 'sk': 'Predložitev POSTECH-ETRI v skupno nalogo WMT2020 APE: samodejno postno urejanje z medjezičnim jezikovnim modelom', 'ha': 'KCharselect unicode block name', 'bo': "POSTECH-ETRI's Submission to the WMT2020 APE Shared Task: Automatic Post-Editing with Cross-lingual Language Model", 'he': 'המשימה המשותפת של POSTECH-ETRI למשימה WMT2020 APE:'}
{'en': 'This paper describes POSTECH-ETRI’s submission to WMT2020 for the shared task on automatic post-editing (APE) for 2 language pairs : English-German (En-De) and English-Chinese (En-Zh). We propose APE systems based on a cross-lingual language model, which jointly adopts translation language modeling (TLM) and masked language modeling (MLM) training objectives in the pre-training stage ; the APE models then utilize jointly learned language representations between the source language and the target language. In addition, we created 19 million new sythetic triplets as additional training data for our final ensemble model. According to experimental results on the WMT2020 APE development data set, our models showed an improvement over the baseline by TER of -3.58 and a BLEU score of +5.3 for the En-De subtask ; and TER of -5.29 and a BLEU score of +7.32 for the En-Zh subtask.', 'ar': 'تصف هذه الورقة تقديم POSTECH-ETRI إلى WMT2020 للمهمة المشتركة الخاصة بالتحرير التلقائي اللاحق (APE) لأزواج لغتين: الإنجليزية - الألمانية (En-De) والإنجليزية - الصينية (En-Zh). نقترح أنظمة APE على أساس نموذج لغوي متعدد اللغات ، والذي يتبنى بشكل مشترك أهداف تدريب نمذجة لغة الترجمة (TLM) ونمذجة اللغة المقنعة (MLM) في مرحلة ما قبل التدريب ؛ ثم تستخدم نماذج APE تمثيلات اللغة المكتسبة بشكل مشترك بين لغة المصدر واللغة الهدف. بالإضافة إلى ذلك ، أنشأنا 19 مليون مجموعة ثلاثية جديدة كبيانات تدريب إضافية لنموذج المجموعة النهائي. وفقًا للنتائج التجريبية على مجموعة بيانات تطوير APE WMT2020 ، أظهرت نماذجنا تحسنًا على خط الأساس بمقدار TER -3.58 ودرجة BLEU +5.3 للمهمة الفرعية En-De ؛ و TER من -5.29 ودرجة BLEU +7.32 للمهمة الفرعية En-Zh.', 'fr': "Cet article décrit la soumission de POSTECH-ETRI au WMT2020 pour la tâche partagée sur la post-édition automatique (APE) pour 2 paires de langues\xa0: anglais-allemand (en-de) et anglais-chinois (en-Zh). Nous proposons des systèmes APE basés sur un modèle linguistique multilingue, qui adopte conjointement des objectifs de formation de modélisation de langage de traduction (TLM) et de modélisation de langage masqué (MLM) au stade de pré-formation\xa0; les modèles APE utilisent ensuite des représentations linguistiques apprises conjointement entre la langue source et la langue cible langue. De plus, nous avons créé 19 millions de nouveaux triplets synthétiques en tant que données d'entraînement supplémentaires pour notre modèle d'ensemble final. Selon les résultats expérimentaux de l'ensemble de données de développement APE du WMT2020, nos modèles ont montré une amélioration par rapport à la ligne de base par rapport au TER de -3,58 et un score BLEU de +5,3 pour la sous-tâche En-De\xa0; et un TER de -5,29 et un score BLEU de +7,32 pour la sous-tâche En-Zh.", 'es': 'Este artículo describe la presentación de POSTECH-ETRI al WMT2020 para la tarea compartida de postedición automática (APE) para 2 combinaciones de idiomas: inglés-alemán (En-De) e inglés-chino (En-Zh). Proponemos sistemas APE basados en un modelo de lenguaje multilingüe, que adopta conjuntamente los objetivos de capacitación de modelado de lenguaje de traducción (TLM) y modelado de lenguaje enmascarado (MLM) en la etapa de preentrenamiento; los modelos APE utilizan representaciones lingüísticas aprendidas conjuntamente entre el idioma de origen y el idioma de destino. idioma. Además, creamos 19 millones de trillizos sintéticos nuevos como datos de entrenamiento adicionales para nuestro modelo de conjunto final. De acuerdo con los resultados experimentales del conjunto de datos de desarrollo de APE WMT2020, nuestros modelos mostraron una mejora con respecto a la línea de base por TER de -3,58 y una puntuación BLEU de +5,3 para la subtarea En-De; y TER de -5,29 y una puntuación BLEU de +7,32 para la subtarea En-Zh.', 'pt': 'Este artigo descreve a submissão da POSTECH-ETRI ao WMT2020 para a tarefa compartilhada de pós-edição automática (APE) para 2 pares de idiomas: inglês-alemão (En-De) e inglês-chinês (En-Zh). Propomos sistemas APE baseados em um modelo de linguagem multilíngue, que adota conjuntamente os objetivos de treinamento de modelagem de linguagem de tradução (TLM) e modelagem de linguagem mascarada (MLM) na fase de pré-treinamento; os modelos APE, então, utilizam representações de linguagem aprendidas em conjunto entre o idioma de origem e o idioma de destino. Além disso, criamos 19 milhões de novos trigêmeos sintéticos como dados de treinamento adicionais para nosso modelo de conjunto final. De acordo com resultados experimentais no conjunto de dados de desenvolvimento do WMT2020 APE, nossos modelos mostraram uma melhoria em relação à linha de base por TER de -3,58 e uma pontuação BLEU de +5,3 para a subtarefa En-De; e TER de -5,29 e pontuação BLEU de +7,32 para a subtarefa En-Zh.', 'ja': '本稿では、英語とドイツ語のペア（ En - De ）と英語と中国語のペア（ En - Zh ）の2つの言語の自動ポストエディット（ APE ）に関する共有タスクについて、POSTECH - ETRIがWMT 2020に提出したものについて説明する。私たちは、翻訳言語モデリング（ TLM ）とマスクド言語モデリング（ MLM ）のトレーニング目標を事前トレーニング段階で共同で採用するクロスリンガル言語モデルに基づいたAPEシステムを提案します。APEモデルは、ソース言語とターゲット言語の間の共同学習言語表現を利用します。さらに、最終的なアンサンブルモデルの追加トレーニングデータとして、1900万の新しい合成三重線を作成しました。WMT 2020 APE開発データセットの実験結果によると、我々のモデルは、En - Deサブタスクについて-3.58のTERおよび+5.3のBLEUスコア、ならびにEn - Zhサブタスクについて-5.29のTERおよび+7.32のBLEUスコアのベースラインを上回る改善を示した。', 'zh': '本文引POSTECH-ETRI向WMT2020所交2种语对自译后辑(APE)共享:英语 - 德语(En-De)、英语 - 中文(En-Zh)。 臣等立APE统于跨语,于预培训合译言建模(TLM)与蒙版言建模(MLM)培训。 然后APE以言语与言语相从者也。 创 1900 万个新符三元组,为终集模形额外训练。 以WMT2020 APE发数集之实验,吾形见,TER重于基线-3.58,En-De子之BLEU为+5.3。 TER 为 -5.29,En-Zh 子职BLEU分为 +7.32。', 'hi': 'यह पेपर 2 भाषा जोड़े के लिए स्वचालित पोस्ट-एडिटिंग (एपीई) पर साझा कार्य के लिए WMT2020 के लिए POSTECH-ETRI के सबमिशन का वर्णन करता है: अंग्रेजी-जर्मन (एन-डे) और अंग्रेजी-चीनी (एन-जेडएच)। हम एक क्रॉस-लिंगुअल भाषा मॉडल के आधार पर एपीई सिस्टम का प्रस्ताव करते हैं, जो संयुक्त रूप से पूर्व-प्रशिक्षण चरण में अनुवाद भाषा मॉडलिंग (टीएलएम) और नकाबपोश भाषा मॉडलिंग (एमएलएम) प्रशिक्षण उद्देश्यों को अपनाता है; एपीई मॉडल तब स्रोत भाषा और लक्ष्य भाषा के बीच संयुक्त रूप से सीखे गए भाषा प्रतिनिधित्व का उपयोग करते हैं। इसके अलावा, हमने अपने अंतिम पहनावा मॉडल के लिए अतिरिक्त प्रशिक्षण डेटा के रूप में 19 मिलियन नए सिथेटिक ट्रिपल बनाए। WMT2020 एपीई विकास डेटा सेट पर प्रयोगात्मक परिणामों के अनुसार, हमारे मॉडल ने -3.58 के टीईआर द्वारा बेसलाइन पर सुधार दिखाया और एन-डी सबटास्क के लिए +5.3 का एक BLEU स्कोर दिखाया; और -5.29 के TER और En-Zh subtask के लिए +7.32 का एक BLEU स्कोर।', 'ru': 'В этой статье описывается подача POSTECH-ETRI на WMT2020 для совместной задачи по автоматическому постредактированию (APE) для 2 языковых пар: английско-немецкой (En-De) и английско-китайской (En-Zh). Мы предлагаем системы APE, основанные на межъязыковой языковой модели, которая совместно принимает цели обучения моделированию языка перевода (TLM) и моделированию языка маскирования (MLM) на этапе предварительного обучения; затем модели APE используют совместно изученные языковые представления между исходным языком и целевым языком. Кроме того, мы создали 19 миллионов новых ситетических тройняшек в качестве дополнительных обучающих данных для нашей окончательной модели ансамбля. Согласно экспериментальным результатам по набору данных разработки WMT2020 APE, наши модели показали улучшение по сравнению с базовой линией на ТЭО -3,58 и балл BLEU +5,3 для подзадачи En-De; и ТЭО -5,29 и балл BLEU +7,32 для подзадачи En-Zh.', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht POSTECH-ETRI chuig WMT2020 don tasc roinnte ar iar-eagarthóireacht uathoibríoch (APE) le haghaidh 2 phéire teanga: Béarla-Gearmáinis (En-De) agus Béarla-Sínis (En-Zh). Molaimid córais APE bunaithe ar mhúnla teanga tras-teanga, a ghlacann le chéile cuspóirí oiliúna samhaltú teanga aistriúcháin (TLM) agus samhaltú teanga folaithe (MLM) ag céim na réamh-oiliúna; Úsáideann na samhlacha APE ansin léirithe teanga comhfhoghlama idir an teanga fhoinseach agus an sprioctheanga. Ina theannta sin, chruthaíomar 19 milliún triplets sythetic nua mar shonraí oiliúna breise dár samhail ensemble deiridh. De réir thorthaí turgnamhacha ar thacar sonraí forbartha WMT2020 APE, léirigh ár samhlacha feabhas thar an mbunlíne de réir TER de -3.58 agus scór BLEU de +5.3 don fhothasc En-De; agus TER de -5.29 agus scór BLEU de +7.32 don fhothasc En-Zh.', 'hu': 'Ez a tanulmány bemutatja a POSTECH-ETRI által a WMT2020-nak benyújtott feladatot az automatikus utószerkesztés (APE) megosztott feladatára 2 nyelvpárra: angol-német (En-De) és angol-kínai (En-Zh). Többnyelvű nyelvi modellre épülő APE rendszereket javasolunk, amelyek közösen fogadják el a fordítási nyelv modellezését (TLM) és a maszkos nyelv modellezését (MLM) a képzés előtti szakaszban; Az APE modellek ezután közösen tanult nyelvi reprezentációkat használnak a forrásnyelv és a célnyelv között. Ezenkívül 19 millió új szitetikus hármasot hoztunk létre, mint további edzési adatokat a végső együttesmodellünkhöz. A WMT2020 APE fejlesztési adatkészlet kísérleti eredményei szerint modelleink TER értékéhez képest -3,58-os javulást mutattak, az En-De részfeladathoz képest pedig +5,3 BLEU pontszámot mutattak; És TER -5,29 és BLEU pontszám +7,32 az En-Zh részfeladat.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή της στο WMT2020 για την κοινή εργασία για την αυτόματη μετα-επεξεργασία (APE) για δύο γλωσσικά ζεύγη: Αγγλικά-Γερμανικά (EN-DE) και Αγγλικά-Κινέζικα (EN-Ζ). Προτείνουμε συστήματα βασισμένα σε ένα γλωσσικό μοντέλο, το οποίο υιοθετεί από κοινού τους εκπαιδευτικούς στόχους μοντελοποίησης γλωσσών μετάφρασης (και μοντελοποίησης μασκαρισμένης γλώσσας (ΜΜΜ) στο στάδιο της προετοιμασίας. τα μοντέλα APE στη συνέχεια χρησιμοποιούν από κοινού διδαγμένες γλωσσικές αναπαραστάσεις μεταξύ της γλώσσας προέλευσης και της γλώσσας-στόχου. Επιπλέον, δημιουργήσαμε 19 εκατομμύρια νέα συστατικά τρίδυμα ως πρόσθετα δεδομένα εκπαίδευσης για το τελικό μοντέλο συνόλου. Σύμφωνα με πειραματικά αποτελέσματα στο σύνολο δεδομένων ανάπτυξης του WMT2020 APE, τα μοντέλα μας έδειξαν βελτίωση έναντι της βάσης κατά TER των -3.58 και βαθμολογία BLEU +5.3 για την υποταγή En-De. και TER των -5.29 και μια βαθμολογία BLEU +7.32 για την υποταγή En-Zh.', 'ka': 'ამ წიგნის შესახებ POSTECH-ETRI-ს WMT2020-ის გადატანა საერთო პარამეტრებისთვის, რომელიც საერთო წიგნის მორედაქტირება (APE) 2 ენის ზოგებისთვის: ანგლისური-გერმანული (En-De) და ანგლისური-კინელი ჩვენ APE სისტემები მრავალური ენების მოდელზე დაბაზეობით, რომელიც ერთადერთად მოვიტანებს თავისუფალური ენების მოდელები (TLM) და მაქსიკური ენების მოდელების მოდელები (MLM) საკუთარი საკუთარი მო APE მოდელები შემდეგ იყენებთ ერთადერთად სწავლილი ენის გამოსახულებების გამოსახულება მხოლოდ ენის და მისახულებული ენის შორის. დამატებით, ჩვენ 19 მილიონი ახალი სიტეტიკური სამყარო შექმნა, როგორც დამატებული განაკეთებული მონაცემები ჩვენი ბოლო ანსტემბლის მოდელზე. WMT2020 APE განვითარების მონაცემების შესახებ, ჩვენი მოდელები გამოსახულებული TER-ზე -3.58 და ან-დე სტპოკრატისთვის +5.3 მინუს BLEU-ის მონაცემების შესახებ გამოსახულება. -5.29 და ბლესო წერტილი +7.32 ან-ზო სტიპოსტისთვის.', 'it': 'Questo articolo descrive la presentazione di POSTECH-ETRI a WMT2020 per il compito condiviso sul post-editing automatico (APE) per 2 coppie di lingue: inglese-tedesco (En-De) e inglese-cinese (En-Zh). Proponiamo sistemi APE basati su un modello linguistico cross-lingual, che adotta congiuntamente obiettivi formativi di modellazione linguistica della traduzione (TLM) e modellazione linguistica mascherata (MLM) nella fase di pre-formazione; i modelli APE utilizzano quindi rappresentazioni linguistiche apprese congiuntamente tra la lingua di origine e la lingua di destinazione. Inoltre, abbiamo creato 19 milioni di nuovi tripletti setici come dati di allenamento aggiuntivi per il nostro modello finale di ensemble. Secondo i risultati sperimentali sul set di dati di sviluppo APE WMT2020, i nostri modelli hanno mostrato un miglioramento rispetto al basale per TER di -3,58 e un punteggio BLEU di +5,3 per la sottomissione En-De; e TER di -5,29 e un punteggio BLEU di +7,32 per la sottomissione En-Zh.', 'kk': 'Бұл қағаз POSTECH-ETRI WMT2020- ге 2 тілінің автоматты түрде өңдеу (APE) үшін ортақтастырылған тапсырманы: ағылшын- неміс (En- De) және ағылшын- қытайша (En- Zh) және ортақтастырылған тапсырманы таңдайд Біз APE жүйелерін бірнеше тіл үлгісіне негізделген, олар тілдерді моделдеу (TLM) мен қалқан тілдерді моделдеу (MLM) мақсаттарын алдындағы оқыту мақсаттарын қолданады. APE үлгілері көзі тілі мен мақсатты тіл арасындағы біріктірілген тілдерді қолданады. Қосымша, 19 миллион жаңа ситетикалық үшеметтерді соңғы ензембл үлгісінің қосымша оқыту деректері ретінде құрдық. WMT2020 APE жасау деректер жиынының тәжірибелі нәтижелеріне сәйкес, үлгілеріміз - 3,58 TER және En-De subtask үшін BLEU нәтижесін +5,3 деп жақсартып көрсетті. Ен-Ж субсұраныс үшін - 5,29 және BLEU нәтижесі +7,32.', 'mk': 'Овој весник го опишува поднесувањето на POSTECH-ETRI на WMT2020 за заедничката задача за автоматско постуредување (APE) за два пара јазици: англиско-германски (En-De) и англиско-кинески (En-Zh). Ние предложуваме APE системи базирани на меѓујазички модел, кој заеднички усвојува моделирање на преводниот јазик (TLM) и маскирано јазичко моделирање (MLM) обуки во фазата на предобуката; моделите на APE потоа користат заеднички научени јазички претставувања помеѓу изворниот јазик и метниот јазик. Покрај тоа, создадовме 19 милиони нови ситетски тројца како дополнителни податоци за обука за нашиот финален модел на ансемблот. Според експерименталните резултати на наборот на податоци за развој на ВМТ2020 АПЕ, нашите модели покажаа подобрување во однос на основната вредност од -3,58 за ТЕР и оценка БЛЕУ од +5,3 за подпрашањето Ен-Де; И ТЕР од -5,29 и БЛЕ оценка од +7,32 за потпрашањето на Ен-Ж.', 'lt': 'Šiame dokumente aprašomas POSTECH-ETRI pateiktas WMT2020 bendras uždavinys dėl dviejų kalbų poros: anglų-vokiečių (en-De) ir anglų-kinų (en-Zh) automatinio po redakcijos (APE). Siūlome APE sistemas, grindžiamas tarpkalbiniu kalbų modeliu, kuriame bendrai priimami vertimo kalbų modeliavimo (TLM) ir paslėpto kalbų modeliavimo (MLM) mokymo tikslai pasirengimo mokymui etape; po to APE modeliai naudoja bendrai mokomą kalbos atstovavimą tarp kilmės kalbos ir tikslinės kalbos. Be to, sukūrėme 19 mln. naujų sisteminių trijų elementų kaip papildomus mokymo duomenis mūsų galutiniam ensemblio modeliui. Remiantis eksperimentiniais WMT2020 APE vystymosi duomenų rinkinio rezultatais, mūsų modeliai parodė pagerėjimą, palyginti su pradiniu, pagal TER -3,58 ir BLEU rezultatą +5,3 en-De paklausos atveju; ir TER -5,29 ir BLEU rezultatas +7,32 En-Zh paklausos atveju.', 'ms': 'Kertas ini menggambarkan penghantaran POSTECH-ETRI ke WMT2020 untuk tugas berkongsi pada post-edisi automatik (APE) untuk 2 pasangan bahasa: Inggeris-Jerman (En-De) dan Inggeris-Cina (En-Zh). We propose APE systems based on a cross-lingual language model, which jointly adopts translation language modeling (TLM) and masked language modeling (MLM) training objectives in the pre-training stage;  model APE kemudian menggunakan perwakilan bahasa yang belajar bersama antara bahasa sumber dan bahasa sasaran. Selain itu, kami mencipta 19 juta tiga sistem baru sebagai data latihan tambahan untuk model ensemble akhir kami. Menurut hasil percubaan pada set data pembangunan APE WMT2020, model kami menunjukkan peningkatan dibanding dasar dengan TER -3.58 dan skor BLEU +5.3 untuk subtask En-De; dan TER -5.29 dan skor BLEU +7.32 untuk subtask En-Zh.', 'ml': 'ഈ പത്രത്തില്\u200d പോസ്റ്റെച്ച്-എട്രി-എട്രിയിന്റെ കീഴ്പ്പെടുത്തുന്നത് WMT2020-ലേക്ക് വിവരിക്കുന്നു. രണ്ടു ഭാഷ ഇണകള്\u200dക്ക് വേണ്ടി പങ്കെടുത്ത ജോലിയ ഒരു ക്രിസ്ലിങ്ങ് ഭാഷ മോഡലിന്\u200dറെ അടിസ്ഥാനത്താണ് ഞങ്ങള്\u200d APE സിസ്റ്റം പ്രൊദ്ദേശിപ്പിക്കുന്നത്. അത് ഒരുമിച്ച് ടിഎല്\u200dഎം ഭാഷ മോഡലിംഗ് ഉപയോഗിക് എപ്പിഇ മോഡലുകള്\u200d ഉപയോഗിക്കുന്നു. പിന്നീട് പഠിച്ച ഭാഷ സ്രോതഭാഷയ്ക്കും ലക്ഷ്യഭാഷയ്ക്കും തമ്മിലുള കൂടാതെ, ഞങ്ങള്\u200d 19 മില്ല്യണ്\u200d പുതിയ സിത്തിറ്റിക്ക് ട്രിപ്പിള്\u200d ഉണ്ടാക്കിയിരിക്കുന്നു. നമ്മുടെ അവസാന പ് WMT2020 എപ്പി വികസിപ്പിക്കുന്ന വിവരങ്ങളുടെ പരീക്ഷണ ഫലങ്ങള്\u200d അനുസരിച്ച്, നമ്മുടെ മോഡലുകള്\u200d ബെസ്ലൈനിന്റെ ബെസ്റ്റ് ലൈനില്\u200d മെച്ചപ്പെടുത്തിയിരിക -5.29 എന്നിട്ടും ഒരു ബില്ലൂ സ്കോര്\u200d + 7.32 എന്നും ഒരു ടെര്\u200d ഏന്\u200d -Zh സബ്ബ്ബര്\u200dസിനും വേണ്ടി.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni ta’ POSTECH-ETRI għad-WMT2020 għall-kompitu kondiviż dwar l-edizzjoni awtomatika wara l-edizzjoni (APE) għal żewġ pari lingwistiċi: Ingliż-Ġermaniż (En-De) u Ingliż-Ċiniż (En-Zh). Aħna nipproponu sistemi APE bbażati fuq mudell tal-lingwa translingwi, li b’mod konġunt jadotta l-mudell tal-lingwa tat-traduzzjoni (TLM) u l-objettivi tat-taħriġ tal-mudell tal-lingwa maskrat (MLM) fl-istadju ta’ qabel it-taħriġ; il-mudelli tal-APE mbagħad jużaw rappreżentazzjonijiet tal-lingwa mgħallma b’mod konġunt bejn il-lingwa tas-sors u l-lingwa fil-mira. Barra minn hekk, aħna ħolqu 19-il miljun triplet sistemiku ġdid bħala dejta addizzjonali ta’ taħriġ għall-mudell ta’ ensemble finali tagħna. Skont ir-riżultati sperimentali dwar is-sett tad-dejta tal-iżvilupp tal-APE WMT2020, il-mudelli tagħna wrew titjib mil-linja bażi permezz tat-TER ta’ -3.58 u punteġġ BLEU ta’ +5.3 għas-sottotalba En-De; u TER ta’ -5.29 u punteġġ BLEU ta’ +7.32 għas-sottotalba En-Zh.', 'mn': 'Энэ цаас POSTECH-ETRI-ын WMT2020-д 2 хэл хоёрын автоматжуулалтын (APE) хувьд хуваалцах үйл явцын тулд англи-Герман (En-De) болон Англи-Хятад (En-Zh) хэлний хэвлэлийг тайлбарладаг. Бид олон хэл загварын үндсэн APE системийг санал дэвшүүлдэг. Энэ нь хэл загварын моделийг (TLM) болон хэл загварын модель (MLM) суралцах зорилго урд суралцах талаар нийлүүлдэг. APE загвар нь эх үүсвэрийн хэл болон зорилготой хэл хоорондын хамтдаа сурсан хэл илэрхийллийг ашигладаг. Үүнээс гадна бид 19 сая шинэ системийн гурван зургийг эцсийн загварын дасгал суралцах өгөгдлийг бүтээсэн. WMT2020 APE хөгжлийн өгөгдлийн багц дээр туршилтын үр дүнд бидний загвар нь TER -3.58 болон En-De субталгаар +5.3-ын багш шугам дээр сайжруулсан байна. Эн-Ж субталгаар +7.32 хэмжээний ТР нь -5.29 болон БЛЕС хэмжээтэй.', 'no': 'Denne papiret beskriver at POSTECH-ETRI er sendt til WMT2020 for delt oppgåve om automatisk post-redigering (APE) for 2 språkopar: engelsk-tysk (En-De) og engelsk-kinesisk (En-Zh). Vi foreslår APE-systemet basert på eit krysspråk-modell, som kopla adopterer omsetjingsspråk-modellering (TLM) og maskerte språk-modellering (MLM) opplæringsmål i føreøvingsstaden. APE-modellen bruker så samtidig lærte språk-representasjonar mellom kjeldespråket og målspråket. I tillegg oppretta vi 19 millioner nye sytetiske treflettar som ekstra treningsdata for vår siste ensemblemmodell. Etter eksperimentelle resultater på utviklingsdata for WMT2020, viste modelane våre ein forbedring over grunnlinja med TER -3,58 og ein BLEU-score +5,3 for en-De-subtask. og TER av -5,29 og ein BLEU-score av +7,32 for en-Zh-subtask.', 'sr': 'Ovaj papir opisuje podnošenje POSTECH-ETRI WMT2020 za zajednièki zadatak o automatskom posteditingu (APE) za dva jezička parova: engleski-nemački (En-De) i engleski-kineski (En-Zh). Predlažemo APE sisteme na temelju preko jezičkog model a, koji zajedno usvoji ciljeve prevodnog jezika (TLM) i maskiranog jezika modela (MLM) obuke na fazi predobuke; modeli APE onda koriste zajedno naučene jezičke predstave između izvornog jezika i ciljnog jezika. Osim toga, stvorili smo 19 miliona novih sitetičkih trostruka kao dodatni podaci obuke za naš konačni model ensemble. Prema eksperimentalnim rezultatima na setu podataka za razvoj WMT2020 APE-a, naši modeli su pokazali poboljšanje na početnoj liniji TER-om od -3,58 i BLEU rezultat +5,3 za podpitanje En-De-a; i TER od -5,29 i BLEU rezultat +7,32 za podpitanje En-Zh-a.', 'ro': 'Această lucrare descrie depunerea POSTECH-ETRI la WMT2020 pentru sarcina partajată de post-editare automată (APE) pentru 2 perechi de limbi: engleză-germană (En-De) și engleză-chineză (En-Zh). Propunem sisteme APE bazate pe un model de limbă translingvistică, care adoptă în comun obiectivele de formare a modelării limbajului de traducere (TLM) și modelării limbajului mascat (MLM); Modelele APE utilizează apoi reprezentări lingvistice învățate în comun între limba sursă și limba țintă. În plus, am creat 19 milioane de tripleți setici noi ca date suplimentare de antrenament pentru modelul nostru final de ansamblu. Conform rezultatelor experimentale ale setului de date de dezvoltare WMT2020 APE, modelele noastre au arătat o îmbunătățire față de bază de TER de -3,58 și un scor BLEU de +5,3 pentru subsarcina En-De; și TER de -5.29 și un scor BLEU de +7.32 pentru subactivitatea En-Zh.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie POSTECH-ETRI do WMT2020 dla wspólnego zadania dotyczącego automatycznej edycji (APE) dla dwóch par językowych: angielsko-niemieckich (En-De) i angielsko-chińskich (En-Zh). Proponujemy systemy APE oparte na modelu języka wielojęzycznego, który wspólnie przyjmuje cele szkoleniowe modelowania języka tłumaczeniowego (TLM) i modelowania języka maskowanego (MLM) na etapie przedszkoleniowym; Modele APE wykorzystują następnie wspólnie nauczone reprezentacje językowe między językiem źródłowym a językiem docelowym. Ponadto stworzyliśmy 19-milionowe nowe trojaczki sytetyczne jako dodatkowe dane treningowe dla naszego ostatecznego modelu zespołu. Według wyników eksperymentalnych dotyczących zbioru danych rozwojowych WMT2020 APE, nasze modele wykazały poprawę nad bazą bazową o TER od -3.58 oraz wynik BLEU +5.3 dla podzadania En-De; I TER z -5.29 oraz wynik BLEU +7.32 dla podzadania En-Zh.', 'so': 'Kanu warqaddaas ayaa ku qoran warqada POSTECH-ETRI uu u dhiibay WMT2020, kaas oo loo qaybiyey shaqada bilowga post-editing (APE) ee labo luqad ah: Ingiriis-German (En-De) iyo Ingiriis-Chinese (En-Zh). Waxaan horay u soo jeedaynaa nidaamka APE oo ku saleysan qaab afka luuqada kala duwan ah, kaas oo si wada jir ah u qaata tusaale ahaan luuqadda turjumaadda (TLM) iyo tusaale ahaan muusikada luuqada maskaxda (MLM) oo ku qoran qorshaha waxbarashada horumarinta; noocyada APE kadibna waxaad isticmaali kartaa noocyada luqada aad u baratay oo u dhexeeya luqada asalka iyo luqada goalka ah. Taas waxaa dheer, waxaan u abuurnay 19 milyan oo labaad oo titiyaatik cusub oo ah data dheeraad oo waxbarashada tusaale ahaan ugu dambeeya. Sida uu ku sameeyo arimaha imtixaanka ee WMT2020 APE koritaanka, modelalkayaga ayaa ka muujiyay hagaajinta qoriga hoose ee TER -3.58 iyo kooxda BLEU oo ku qoran +5.3 iyo TER-5.29 iyo BLEU score +7.32 oo ku qoran En-Zh.', 'sv': 'Denna uppsats beskriver POSTECH-ETRI:s inlämning till WMT2020 för den delade uppgiften om automatisk efterredigering (APE) för två språkpar: engelsk-tyska (En-De) och engelsk-kinesiska (En-Zh). Vi föreslår APE-system baserade på en flerspråkig språkmodell, som gemensamt antar utbildningsmål för översättningsspråksmodellering (TLM) och maskerad språkmodellering (MLM). APE-modellerna använder sedan gemensamt lärda språkrepresentationer mellan källspråket och målspråket. Dessutom skapade vi 19 miljoner nya sytetiska trillingar som ytterligare träningsdata för vår slutliga ensemblemodell. Enligt experimentella resultat på WMT2020 APE utvecklingsdatauppsättningen visade våra modeller en förbättring jämfört med baslinjen med TER på -3,58 och en BLEU-poäng på +5,3 för En-De-subaktiviteten; och TER på -5,29 och en BLEU poäng på +7,32 för En-Zh subaktivitet.', 'si': 'මේ පත්තුව POSTECH-ETRI ගේ WMT202 වලට පිළිගන්න පුළුවන් විස්තර කරනවා භාෂා ජෝමින් දෙකට ස්වයංක්\u200dරිය පොස්ටෝක් සඳහා භාෂාවිත වැඩක් සඳහා  අපි APE පද්ධතිය ප්\u200dරශ්නය කරනවා විශාල භාෂාවක් මොඩේල් එක්ක අභිවාදය භාෂාව මොඩේලින් (TLM) සහ මුකුත් භාෂාව මොඩේලින් (MLM)  APE මොඩේල් පස්සේ ඉදිරිය භාෂාව සහ ඉලක්ක භාෂාව අතර සම්බන්ධ භාෂාව භාවිත කරන්න. ඒ වගේම, අපි අන්තිම අන්තිම අන්තිම අන්තිම අන්තිම අන්තිම අන්තිම අන්තිම අන්තිම අන්තිම අන්තිම අන් WMT202 APE විකාශ දත්ත සූදානයේ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරයක් අනුව, අපේ මොඩේල් ප්\u200dරතිචාරය ප්\u200dරතිචාරයක් ප්\u200d ඒ වගේම +7.32 ගැන +5.29 ගැන +7.32 ගැන', 'ur': "This paper describes POSTECH-ETRI's submission to WMT2020 for the shared task on automatic post-editing (APE) for 2 language pairs: English-German (En-De) and English-Chinese (En-Zh). ہم APE سیستموں کو ایک کرس زبان کی مدل پر بنیاد رکھتے ہیں جو ایک ساتھ ترجمہ زبان کی مدل (TLM) اور ماسک زبان کی مدل (MLM) کی آموزش اختیاروں کو پہلے ترکین سٹے میں پکڑتا ہے۔ اس کے بعد APE موڈلے سورج زبان اور موقع زبان کے درمیان ایک ساتھ سیکھی زبان کی تعلیمات استعمال کریں۔ اس کے علاوہ ہم نے 19 میلیون نو سیٹیٹیک تیرلیٹ پیدا کئے ہیں اور ہمارے آخری انسبل موڈل کے لئے اضافہ ترسین ڈیٹ کے طور پر۔ WMT2020 APE ڈیٹ ڈیٹ سٹ پر آزمائش نتیجے کے مطابق، ہمارے نمڈلے بنسٹ لین کے ذریعہ -3.58 اور انڈی سٹ پرس کے لئے +5.3 کا ایک بلیوس سکوٹ دکھائے گئے۔ -5.29 اور انجی سٹپوسٹ کے لئے +7.32 کا ایک بلیوس سکوٹ ہے۔", 'ta': 'இந்த தாள் POSTECH- ETRI WMT2020 க்கு வழங்கப்பட்ட பணியை குறிப்பிடுகிறது 2 மொழி ஜோடி: ஆங்கிலம்- ஜெர்மன் (En- De) மற்றும் ஆங்கிலம்- சீனா (En- Zh). மொழி மொழி மாதிரி மாதிரி அடிப்படையிலான APE அமைப்புகளை நாம் பரிந்துரைக்கிறோம். இது ஒன்றாக மொழி மாற்ற மாதிரி மாதிரி மாதிரி மாதிரி மாதிரி மாத APE மாதிரிகளை பயன்படுத்தி மூலத்தின் மொழி மற்றும் இலக்கு மொழிக்கும் இடையே கற்றப்பட்ட மொழியின் பிரிவினை மேலும், நாங்கள் 19 மில்லியன் புதிய துருப்பும் மூன்று முறை உருவாக்கினோம் எங்கள் இறுதியாக மாதிரி மாதிரி WMT2020 APE உருவாக்கும் தகவல் அமைப்பின் சோதனை முடிவு -5.29 மற்றும் ஒரு பிலூ புள்ளி மதிப்பு + 7.32 என்ற TER என்று எடுத்தார்கள்.', 'uz': 'Бу саҳифа WMT2020\'га POSTECH-ETRI\' ga bogʻliq vazifa 2 tillar qoʻllari uchun avtomatik tahrirlash (APE) va ingliz- Olmoncha (En-De) va Ingliz-Xitoycha (En-Zh) bilan bogʻliq vazifani anglatadi. Biz bir tarjima tilning modelini (TLM) va boshqa tillar modelini (MLM) yozib qo\'llash uchun APE tizimini taʼminlovchi oldingi darajada foydalanishga ega qilamiz; APE modellarini birlashtirish uchun o\'rganadigan tilni foydalanadi. In addition, we created 19 million new sythetic triplets as additional training data for our final ensemble model.  WMT2020 APE taʼminlovchi maʼlumotlar tarkibida taʼminlovchi natijalari davomida, modellarimiz - 3. 58 va En-De subvazifasi uchun BLEU scori + 5. 3 darajasini ko\'rsatadi; va "5.29" va "En-Zh" sub-vazifasi" uchun BLEU scori + 7.32.', 'vi': 'Tờ giấy này mô tả thuyết phục bưu kiện kết nối kết nối kết nối kết hợp với WTECH-ERI: Anh-Đức (Ent-De) và Anh-Chinese (Ent-Zhang). Chúng tôi đề xuất hệ APA dựa trên một mô hình ngôn ngữ ngữ ngữ khác nhau, nó đồng thời chấp nhận thiết kế ngôn ngữ dịch (TLS) và mục tiêu tạo mẫu ngôn ngữ đeo mặt nạ (MLM) trong giai đoạn huấn luyện trước; Các mô hình APA sau đó sử dụng các biểu tượng ngôn ngữ học cùng nhau giữa ngôn ngữ nguồn và ngôn ngữ đích. Thêm vào đó, chúng tôi đã tạo ra 19triệu triệu cỗ máy mới như các dữ liệu huấn luyện bổ sung cho mô hình kết hợp cuối cùng. Theo kết quả thử nghiệm của tập đoàn dữ liệu phát triển WM 2 APE, các mẫu của chúng tôi cho thấy có một cải tiến trên cơ sở con số theo quỹ đạo của TE3.58 và một lượng đứng chính thức của May trên mặt phụ đề A-De. và đo lường R5.29 và một số lượng NIU của +7.32 của các yêu cầu En-Zhang.', 'hr': 'Ovaj papir opisuje podnošenje POSTECH-ETRI WMT2020 za zajednički zadatak o automatskom posteditingu (APE) za dva jezička parova: engleski njemački (En-De) i engleski kineski (En-Zh). Predlažemo APE sustave na temelju prekograničnog jezičkog model a, koji zajedno usvoji ciljeve obrazovanja prevodnog jezika (TLM) i maskiranog jezika modela (MLM) na fazi predobuke; modeli APE onda koriste zajedno učene jezičke predstave između izvornog jezika i ciljnog jezika. Osim toga, stvorili smo 19 milijuna novih sitetičkih trostruka kao dodatne podatke obuke za naš konačni model ensemble. Prema eksperimentalnim rezultatima o setu podataka za razvoj WMT2020 APE-a, naši modeli su pokazali poboljšanje prema početnoj liniji TER-a od -3,58 i BLEU rezultat +5,3 za podpitanje En-De-a; i TER od -5,29 i BLEU rezultat +7,32 za podpitanje En-Zh-a.', 'da': "Dette dokument beskriver POSTECH-ETRI's indsendelse til WMT2020 til den delte opgave om automatisk post-redigering (APE) for 2 sprogpar: engelsk-tysk (En-De) og engelsk-kinesisk (En-Zh). Vi foreslår APE-systemer baseret på en tværsproget sprogmodel, som i fællesskab vedtager oversættelsessprogmodellering (TLM) og masked language modellering (MLM) træningsmål i forberedelsesfasen; APE-modellerne anvender derefter i fællesskab lærte sprogrepræsentationer mellem kildesproget og målsproget. Derudover har vi skabt 19 millioner nye sytetiske tripletter som yderligere træningsdata til vores endelige ensemblemodel. Ifølge eksperimentelle resultater på WMT2020 APE udviklingsdatasættet viste vores modeller en forbedring i forhold til baseline med TER på -3,58 og en BLEU score på +5,3 for En-De subaktivitet; og TER på -5,29 og en BLEU score på +7,32 for En-Zh underopgaven.", 'nl': 'Dit artikel beschrijft de inzending van POSTECH-ETRI aan WMT2020 voor de gedeelde taak automatische post-editing (APE) voor twee taalparen: Engels-Duits (En-De) en Engels-Chinees (En-Zh). We stellen APE-systemen voor die gebaseerd zijn op een meertalig taalmodel, dat gezamenlijk vertaaltaalmodellering (TLM) en gemaskeerde taalmodellering (MLM) trainingsdoelstellingen aanneemt in de pre-training fase; De APE modellen maken vervolgens gebruik van gezamenlijk aangeleerde taalrepresentaties tussen de brontaal en de doeltaal. Daarnaast creëerden we 19 miljoen nieuwe sythetische drielingen als extra trainingsgegevens voor ons uiteindelijke ensemblemodel. Volgens experimentele resultaten op de WMT2020 APE ontwikkelingsdataset toonden onze modellen een verbetering ten opzichte van de baseline met TER van -3.58 en een BLEU score van +5.3 voor de En-De subtaak; en TER van -5.29 en een BLEU score van +7.32 voor de En-Zh subtaak.', 'bg': 'Настоящата статия описва представянето на ПОТЕХ-ЕТРИ за споделената задача за автоматична пост-редактиране (АПЕ) за 2 езикови двойки: английски-немски (ен-де) и английски-китайски (ен-ж). Предлагаме системи, базирани на междуезичен езиков модел, който съвместно приема целите на обучението за моделиране на езика на превода (ТЛМ) и маскирано езиково моделиране (МЛМ) в предобучителния етап; моделите на АПЕ използват съвместно научени езикови представи между езика на изхода и целевия език. Освен това създадохме 19 милиона нови ситетични тризнаци като допълнителни данни за обучението за нашия окончателен ансамбъл модел. Според експерименталните резултати на набора от данни за разработка на АПЕ, нашите модели показаха подобрение спрямо базовата база с ТЕР от -3.58 и резултат от +5.3 за подзадачата Е-де; и ТЕР от -5.29 и резултат от +7.32 за подзадачата Ен-Ж.', 'id': 'Kertas ini menjelaskan pengiriman POSTECH-ETRI ke WMT2020 untuk tugas berbagi pada post-edisi otomatis (APE) untuk 2 pasangan bahasa: Inggris-Jerman (En-De) dan Inggris-Cina (En-Zh). We propose APE systems based on a cross-lingual language model, which jointly adopts translation language modeling (TLM) and masked language modeling (MLM) training objectives in the pre-training stage;  the APE models then utilize jointly learned language representations between the source language and the target language.  Selain itu, kami menciptakan 19 juta triplet sistem baru sebagai data pelatihan tambahan untuk model ensemble akhir kami. Menurut hasil percobaan pada set data pengembangan APE WMT2020, model kami menunjukkan peningkatan dibanding dasar dengan TER -3,58 dan skor BLEU +5,3 untuk subtask En-De; dan TER dari -5.29 dan nilai BLEU +7.32 untuk subtask En-Zh.', 'de': 'Dieser Beitrag beschreibt die Einreichung von POSTECH-ETRI an WMT2020 für die gemeinsame Aufgabe zur automatischen Nachbearbeitung (APE) für zwei Sprachpaare: Englisch-Deutsch (En-De) und Englisch-Chinesisch (En-Zh). Wir schlagen APE-Systeme vor, die auf einem sprachübergreifenden Sprachmodell basieren, das gemeinsam die Trainingsziele Translation Language Modeling (TLM) und Masked Language Modeling (MLM) in der Vorbereitungsphase übernimmt; Die APE-Modelle nutzen dann gemeinsam erlernte Sprachrepräsentationen zwischen Ausgangs- und Zielsprache. Zusätzlich haben wir 19-Millionen neue sythetische Triplets als zusätzliche Trainingsdaten für unser endgültiges Ensemblemodell erstellt. Nach experimentellen Ergebnissen des WMT2020 APE-Entwicklungsdatensatzes zeigten unsere Modelle eine Verbesserung gegenüber der Baseline um TER von -3.58 und einen BLEU-Score von +5.3 für den En-De-Subtask; und TER von -5.29 und eine BLEU-Punktzahl von +7.32 für den En-Zh Subtask.', 'ko': '본고는 POSTECH-ETRI가 WMT 2020에 제출한 두 가지 언어 쌍의 자동 후기 편집(APE) 공유 임무인 영어-독일어(En-De)와 영어-중국어(En-Zh)를 묘사한다.우리는 크로스 언어 모델을 바탕으로 하는 APE 시스템을 제시했는데 이 시스템은 훈련 전 단계에 번역 언어 모델링(TLM)과 가리개 언어 모델링(MLM) 훈련 목표를 연합하여 채택했다.그런 다음 APE 모델은 소스 언어와 대상 언어 간에 공통적으로 학습된 언어 표현을 사용합니다.이 밖에 우리는 1900만 개의 새로운 합성 세 쌍둥이를 만들어 최종 합주 모델의 추가 훈련 데이터로 삼았다.WMT 2020 APE 발달 데이터 세트의 실험 결과에 따르면 우리 모델에 따르면 베이스라인에 비해 En De 서브퀘스트의 TER는 -3.58, BLEU는 +5.3으로 개선되었다.En Zh 하위 임무의 TER는 -5.29이고 BLEU는 +7.32로 나뉜다.', 'fa': 'این کاغذ تحویل POSTECH-ETRI را به WMT2020 برای کار مشترک در بعد از ویرایش (APE) برای دو جفت زبان توصیف می\u200cکند: انگلیسی-آلمانی (En-De) و انگلیسی-چینی (En-Zh). ما سیستم\u200cهای APE را بر اساس یک مدل زبان متوسط پیشنهاد می\u200cکنیم که با هم مدل\u200cسازی زبان ترجمه (TLM) و مدل\u200cسازی زبان ماسک (MLM) را در مرحله پیش آموزش می\u200cگیرد. مدل APE سپس نمایش\u200cهای زبان یاد گرفته با هم استفاده می\u200cکند بین زبان منبع و زبان هدف. علاوه بر این، ما ۱۹ میلیون سیتتیک سه نفر جدید را به عنوان اطلاعات آموزش اضافه برای مدل آخرین انجمل ما خلق کردیم. طبق نتایج آزمایشی در مجموعه داده های توسعه WMT2020 APE، مدلهای ما توسعه TER -3.58 و یک نمونه BLEU از +5.3 برای پایتپرس En-De را نشان دادند. و TER از -5.29 و یک امتیاز BLEU از +7.32 برای پایتسپرس En-Zh.', 'tr': "Bu kagyz POSTECH-ETRI WMT2020'a 2 dil çift üçin olaryň ýene-düzenlemesi üçin beýleki zady üçin beýleki maksady ýazylýar: iňlisçe-nemesçe (En-De) we iňlisçe-Çinçe (En-Zh). Biz APE sistemalary çarpaz dil nusgasyna daýanýan, terjime dillerini modelleýän (TLM) we maskele diller modelleýän (MLM) sahypalarda öň-okuwçylyga görkezilýän maksadlary kabul edýäris; Sonra APE modelleri çeşme dili we maksady dili arasynda öwrenme suratlaryny ullan. Ayrıca, iňki ensemble modelimiz üçin 19 milliýon täze sytetik üçüpleri ekledik. WMT2020 APE ösümli maglumatyň düzümlenmegi üçin experimental netijelere görä, modellerimiz TER -3.58 we En-De subtask üçin +5.3 düzümlenmegi üýtgedigini görkezildi; we TER -5.29 we BLEU sany En-Zh subtask üçin +7.32.", 'sw': 'Gazeti hili linaelezea ujumbe wa POSTECH-ETRI wa WMT2020 kwa ajili ya jukumu lililoshirikishwa katika kuhariri mara moja kwa lugha mbili: Kiingereza-Ujerumani (En-De) na Kiingereza (En-Zh). Tunazipendekeza mfumo wa APE kwa kutumia muundo wa lugha yenye lugha tofauti, ambao kwa pamoja hutumia muundo wa utafsiri wa lugha (TLM) na muundo wa mafunzo ya lugha (MLM) katika hatua ya mafunzo ya kabla ya mafunzo; mifano ya APE baada ya kutumia uwakilizaji wa lugha zilizojifunza pamoja kati ya lugha ya asili na lugha ya lengo. In addition, we created 19 million new sythetic triplets as additional training data for our final ensemble model.  Kwa mujibu wa matokeo ya majaribio kuhusu takwimu za maendeleo ya WMT2020 APE, mifano yetu ilionyesha maendeleo ya msingi na TER ya -3.58 na vipimo vya BLEU +5.3 kwa ajili ya kazi za En-De; and TER of -5.29 and a BLEU score of +7.32 for the En-Zh subtask.', 'sq': 'Ky dokument përshkruan paraqitjen e POSTECH-ETRI në WMT2020 për detyrën e përbashkët mbi posteditimin automatik (APE) për dy çifte gjuhësh: anglisht-gjerman (En-De) dhe anglisht-kinez (En-Zh). Ne propozojmë sisteme APE bazuar në një model gjuhësh ndërgjuhësore, i cili miraton së bashku modelimin e gjuhës së përkthimit (TLM) dhe objektivat e trajnimit të modelimit të gjuhës së maskuar (MLM) në fazën e paratrajnimit; modelet APE përdorin përfaqësimet e gjuhës së mësuar së bashku midis gjuhës burimore dhe gjuhës objektive. Përveç kësaj, ne krijuam 19 milion të reja të tre sistemeve si të dhëna shtesë trainimi për modelin tonë final të ensembles. Sipas rezultateve eksperimentale në grupin e të dhënave të zhvillimit të APE WMT2020, modelet tona treguan një përmirësim mbi bazën nga TER prej -3.58 dhe një rezultat BLEU prej +5.3 për nënkërkesën En-De; and TER of -5.29 and a BLEU score of +7.32 for the En-Zh subtask.', 'am': 'ይህ ፕሮግራም የፖSTECH-ETRI ለWMT2020 ጥያቄ ለሁለት ቋንቋ-አካባቢዎች የፖስቴክስ-ኢትዮጵያ እና እንግሊዘኛ-ጀርመን (En-De) እና እንግሊዘኛ-ቻይንኛ (En-Zh) በተካፈሉት ስራ ይናገራል፡፡ በተለየ ቋንቋ ቋንቋ ምሳሌ ላይ በተመሳሳይ የAPE ስርዓቶችን በመጠቀም እና በተጠቃሚ ትርጉም ቋንቋ ምሳሌ (TLM) እና የቋንቋ ምሳሌ ምሳሌ (MLM) ማስጠንቀቂያ ተቃውሞ አቃውሞ ይዘረጋል፡፡ የAPE ዓይነቶች በኩል ቋንቋ እና በአካባቢው ቋንቋ መካከል የተማረ ቋንቋ ምሳሌዎችን በመጠቀም ይጠቅማል፡፡ በተጨማሪም፣ አሥራ 19 ሚሊዮን አዲስ ስቲትካዊ አዲስ ደብዳቤዎችን ለፍጻሜው ምሳሌ ማድረጊያ ዳታ አድርገን ፈጠርን፡፡ በWMT2020 APE አካባቢ ዳታ ላይ እንደፈተና ውጤቶች፣ ሞዴላዎቻችን የቴር-3.58 እና የዓይን-ዲ ደብዳቤ የBLEU score +5.3 የደረጃ ክፍል ያሳያል፡፡ የ-5.29 እና የቢሉስ ደረጃ +7.32 ለዓይን-Z ደብዳቤ ነው፡፡', 'af': "Hierdie papier beskrywe POSTECH-ETRI se onderskrywing na WMT2020 vir die gedeelde taak op outomatiese post-redigeering (APE) vir 2 taal paar: Engels-Duits (En-De) en Engels-Chinese (En-Zh). Ons voorstel APE stelsels gebaseer op 'n kruistale taal model, wat saamstig aanvaar vertaling taal modellering (TLM) en maskeerde taal modellering (MLM) onderwerp objekte in die voor-onderwerp stadium; die APE-modelles dan gebruik saamstig geleerde taal voorstellings tussen die bron taal en die doel taal. In addition, we created 19 million new sythetic triplets as additional training data for our final ensemble model. Volgens eksperimentele resultate op die WMT2020 APE-ontwikkelingsdata stel, het ons modele 'n verbetering oor die basisline deur TER van -3.58 en 'n BLES-aantal van +5.3 vir die En-De-subtask vertoon; en en TER van -5.29 en +7.32 vir die En-Zh subtask.", 'az': "Bu kağıt 2 dil cütü ilə birləşdirilmiş iş iş üçün WMT2020'ə POSTECH-ETRI'nin vəzifəsini: İngilizce-Almanca (En-De) və İngilizce-Çinli (En-Zh) ilə birləşdirilməsi üçün şəriət edir. Biz APE sistemlərini çoxlu dil modeli ilə təklif edirik, ki, əvvəl təhsil sahəsində təhsil etmə məqsədillərinə birlikdə çevirilmiş dil modeli (TLM) və maski dil modelləri (MLM) təhsil etmə məqsədillərini istifadə edir; Sonra APE modelləri mənbə dili və məqsəd dili arasında birlikdə öyrənmiş dil göstəricilərini istifadə edir. Əvvəlcə, 19 milyon yeni sitetik üçlük yaratdıq, son ensemble modeli üçün əlavə təhsil verilər olaraq. WMT2020 APE inkişaf məlumatlarının müxtəlif sonuçlarına görə modellərimiz, TER tərəfindən - 3.58 və En-De subtask üçün BLEU dərəcəsi +5.3 dərəcəsini göstərdi; En-Zh subtask üçün - 5.29 və BLEU dərəcəsi +7.32.", 'ca': "Aquest article descriu la presentació de POSTECH-ETRI a WMT2020 per la tasca compartida en post-edició automàtica (APE) per dos parells de llengües: anglès-alemany (En-De) i anglès-xinès (En-Zh). Proposem sistemes APE basats en un model de llenguatge translingüístic, que adopta conjuntament els objectius de formació de modelació de llenguatge de traducció (TLM) i modelació de llenguatge mascarada (MLM) a l'etapa de pré-formació; els models APE utilitzen les representacions de llenguatges aprenguts conjuntament entre el llenguatge d'origen i el llenguatge d'objectiu. A més, vam crear 19 milions de nous triplets sistètics com dades adicionals d'entrenament per al nostre model final. Segons els resultats experimentals del conjunt de dades de desenvolupament de l'APE WMT2020, els nostres models van mostrar una millora en comparació amb el valor basal per TER de -3,58 i una puntuació BLEU de +5,3 per la subtanya en-De; i TER de -5,29 i una puntuació BLEU de +7,32 per la subterrània en-Zh.", 'bs': 'Ovaj papir opisuje podnošenje POSTECH-ETRI WMT2020 za zajednički zadatak o automatskom posteditingu (APE) za dva jezička parova: engleski-nemački (En-De) i engleski-kineski (En-Zh). Predlažemo APE-ovim sistemima na temelju prekograničnog jezičkog model a, koji zajedno usvoji ciljeve obrazovanja prevodnog jezika (TLM) i maskiranog jezika modela (MLM) na fazi predobuke; modeli APE onda koriste zajedno učene jezičke predstave između izvornog jezika i ciljnog jezika. Osim toga, stvorili smo 19 miliona novih sitetičkih trostruka kao dodatne podatke o obuci za naš konačni model ensemble. Prema eksperimentalnim rezultatima o setu podataka za razvoj WMT2020 APE-a, naši modeli su pokazali poboljšanje na početnoj liniji TER-om od -3,58 i BLEU rezultat +5,3 za podpitanje En-De-a; i TER od -5,29 i BLEU rezultat +7,32 za podpitanje En-Zh-a.', 'bn': 'এই পত্রিকাটি দুই ভাষার জোড়ার জন্য পোস্টেচ-ইট্রিটি২০০-কে উইএমটি২০০-এর প্রতি প্রদান করা কাজের জন্য পোস্টেচ-ইট্রিটিকে বর্ণনা করেছে: ইংরেজী জার্মান (এন- প্রশিক্ষণের পূর্ব পর্যন্ত প্রশিক্ষণের উদ্দেশ্য (টিএলএম) অনুবাদ ভাষার মডেল (টিএলএম) এবং মুখোশিত ভাষার মডেলিং (এমএলএম) নিয়ে আমরা প্রস্তাব করি একটি ক এপিই মডেল তারপর সোর্স ভাষা এবং লক্ষ্য ভাষার মধ্যে যুক্ত ভাষার প্রতিনিধিত্ব ব্যবহার করে। এছাড়াও, আমরা ১৯ মিলিয়ন নতুন সিথিটিক ত্রিপট তৈরি করেছি আমাদের চূড়ান্ত প্রশিক্ষণ মডেলের জন্য আরো প্রশিক্ষণের ত ডিউএমটি২০২০০ এপি উন্নয়নের তথ্য সেটের পরীক্ষার ফলাফল অনুসারে আমাদের মডেল দেখিয়েছে টের-৩. এবং -৫. ২৯ এর টের এবং একটি বিলু স্কোর + ৭. ৩২ এর জন্য এন-Zh সাবটাবাজের জন্য।', 'cs': 'Tento článek popisuje předložení společnosti POSTECH-ETRI do WMT2020 pro sdílený úkol na automatické post-editaci (APE) pro dva jazykové páry: anglicko-němčina (En-De) a anglicko-čínština (En-Zh). Navrhujeme APE systémy založené na cross-jazyčném modelu, který společně přijímá cíle překladu jazyka modelování (TLM) a maskovaného jazyka modelování (MLM) v předškolení; APE modely pak využívají společně učené jazykové reprezentace mezi zdrojovým a cílovým jazykem. Kromě toho jsme vytvořili devatenáct milionů nových sytických trojčat jako další tréninková data pro náš finální souborový model. Podle experimentálních výsledků na vývojové sadě APE WMT2020 naše modely vykazovaly zlepšení oproti základnímu principu o TER z -3,58 a BLEU skóre +5,3 pro podúkol En-De; A TER z -5.29 a BLEU skóre +7.32 pro podúkol En-Zh.', 'hy': 'Այս աշխատանքում նկարագրվում է POSTACH-EtRI-ի ներկայացումը World MT2020-ին ավտոմատիկ հետխմբագրման (APE) ընդհանուր հանձնարարության համար երկու լեզու զույգերի համար՝ անգլերեն-գերմաներեն (en-de) և անգլերեն-չինարեն (en-Z). Մենք առաջարկում ենք APE համակարգեր, որոնք հիմնված են երկլեզվային լեզվի մոդելի վրա, որը միասին ընդունում է թարգմանման լեզվի մոդելը (TLM) և թաքնված լեզվի մոդելը (MLM) վարժեցման նպատակները նախավարժման փուլում: the APE models then utilize jointly learned language representations between the source language and the target language.  Ավելին, մենք ստեղծեցինք 19 միլիոն նոր համակարգչային երեք անգամ որպես ավելացված ուսուցման տվյալներ մեր վերջնական էնսբուլ մոդելի համար: According to experimental results on the WMT2020 APE development data set, our models showed an improvement over the baseline by TER of -3.58 and a BLEU score of +5.3 for the En-De subtask;  and TER of -5.29 and a BLEU score of +7.32 for the En-Zh subtask.', 'fi': 'Tässä artikkelissa kuvataan POSTECH-ETRI:n tekemää työtä WMT22020:lle automaattisen jälkimuokkauksen (APE) jakamista varten kahdelle kieliparille: englanti-saksa (en-de) ja englanti-kiina (en-zh). Ehdotamme monikieliseen kielimalliin perustuvia APE-järjestelmiä, jotka yhdessä omaksuvat käännöskielen mallinnuksen (TLM) ja masked language mallinnuksen (MLM) koulutustavoitteet esikoulutuksessa. APE-mallit hyödyntävät yhdessä opittuja kieliesityksiä lähdekielen ja kohdekielen välillä. Lisäksi loimme 19 miljoonaa uutta syseettistä kolmikkoa täydennyskoulutusdataksi lopulliseen ryhmämalliimme. WMT2020 APE-kehitysaineiston kokeellisten tulosten mukaan mallimme osoittivat parannuksen lähtötasoon verrattuna TER-3,58 ja BLEU-pisteen +5,3 En-De-alatehtävän osalta; Ja TER -5,29 ja BLEU-pisteet +7,32 En-Zh-alatehtävässä.', 'et': 'Käesolevas artiklis kirjeldatakse POSTECH-ETRI esitamist WMT22020-le automaatse järeltöötluse jagatud ülesandeks (APE) kahele keelepaarile: inglise-saksa (En-De) ja inglise-hiina (En-Zh). Pakume välja keeleülesel keelemudelil põhinevad APE süsteemid, mis võtavad koolituseelses etapis ühiselt vastu tõlkekeele modelleerimise (TLM) ja maskeeritud keele modelleerimise (MLM) koolituse eesmärgid; APE mudelid kasutavad seejärel algkeele ja sihtkeele ühiselt õppitud keelerepresentatsioone. Lisaks loosime lõpliku ansambli mudeli jaoks 19 miljonit uut süteetilist kolmikut. Vastavalt WMT22020 APE arendusandmete kogumi eksperimentaalsetele tulemustele näitasid meie mudelid lähtetasemega võrreldes paranemist TER-3,58 ja BLEU skoori +5,3 En-De alamülesande puhul; Ja TER -5,29 ja BLEU skoor +7,32 En-Zh alamülesande.', 'ha': "Wannan karatun na describes the PostanECha-ETRI's sender zuwa WMT2020 for the share of the job on farat editing (PAET) for 2 languages: English-Jarman (en-de) and English-China (en-Zh). Tuna buɗar da ɗabi'a na tsarin PAEs a kan wani misalin harshe na tsoron-lingui, wanda ke ɗauki kodi da misalin fassarar harshe na TLM (TLM) da misalin maganar (MLM) da aka rufe (MLM) gaba ga shirin da aka yi amfani da shi gaba ɗaya; @ action: button Kuma da wannan, mun halitta misalin misalin na ƙarami na shida wajen wata na shida bakwai. Li goren jarrabo masu tsari na WMT2020 Apple data na ƙarƙashin kwamfyuta, misalinmu na nuna mafiya kyau a kanan basalin ƙasalin na TeR na -3.58 da wata BLEU score na+5.3 wa bin aikin en-De; kuma TeR na -5.29 da na BLEU koyi na+7.32wa wa sub-aikin en-Zh.", 'sk': 'Ta prispevek opisuje predložitev POSTECH-ETRI WMT2020 za skupno nalogo avtomatskega post-urejanja (APE) za dva jezikovna para: angleško-nemško (En-De) in angleško-kitajsko (En-Ž). Predlagamo sisteme APE, ki temeljijo na medjezičnem jezikovnem modelu, ki skupaj sprejema cilje usposabljanja prevajalskega jezika (TLM) in masked language modeling (MLM) v fazi predusposabljanja; modeli APE nato uporabljajo skupno učene jezikovne reprezentacije med izvornim in ciljnim jezikom. Poleg tega smo ustvarili 19 milijonov novih sistetskih trojčkov kot dodatni podatki o usposabljanju za naš končni model ansambla. Po poskusnih rezultatih razvojnih podatkov WMT2020 APE so naši modeli pokazali izboljšanje glede na izhodišče za TER za -3,58 in rezultat BLEU za +5,3 za podnalogo En-De; in TER od -5,29 in BLEU rezultat +7,32 za En-Zh podopravilo.', 'jv': 'Gambar iki rambarang nggawe biasane pregunter-ETRI kanggo WTT2020 kanggo nganggo nggawe barang otomatik pri-editing (ApE) kanggo 2 nggambar barang: Inggris-German (en-de) lan Inggris-Chinese (en-Z). Awak dhéwé ngerti nggunakake ApE sistem sing basa saben model karo lenggal, sampeyan ngono nggawe tarjamahan ingkang model (T LM) lan model kuwi tindakan (MLM) sing wisasara alitèn nggawe layar, kuwi jenis-jenis layar seng wis prarampun; awak dhéwé ngerti model ApE kuwi ngubah bener podho akeh basa sampeyan kelas nang angkang sampeyan bangsa lan bukal. Nambah, kita lagi 19 milion dolar sing dibutun Tulung oleh sing perusahaan anyari dadi sing nggawe bakal dumadhi WW2020, model kita ngawe nyimpen langkung dibutuhke sing dibutuhke telu diangkat -3. Sampeyan ;', 'bo': 'ཤོག We propose APE systems based on a cross-language model, which jointly adopts translation language modeling (TLM) and masked language modeling (MLM) training objectives in the pre-training stage; and APE མིག་དཔེ་དབྱིབས་དང་། ཐོག་ཁུངས་དང་དམིགས་ཡུལ་སྐད་རིགས་དབར་གྱི་སྐད་རིགས་ཆ་མཐུན་སྤྱོད་པ་ཡིན། In addition, we created 19 million sythetic triplets as additional training data for our final ensemble model. According to experimental results on the WMT2020 APE development data set, our models showed an improvement over the baseline by TER of -3.58 and a BLEU score of +5.3 for the En-De subtask;  TER of -5.29 and a BLEU score of +7.32 for the En-Zh subtask.', 'he': 'העיתון הזה מתאר את ההעברה של POSTECH-ETRI WMT2020 למשימה המשותפת על העורר אוטומטי (APE) לשני זוגות שפות: אנגלי-גרמני (En-De) ואנגלי-סיני (En-Zh). אנו מציעים מערכות APE מבוססות על מודל שפת בין שפות, אשר מאמץ ביחד מודל שפת התרגום (TLM) ו מודל שפת מסוכן (MLM) מטרות אימון בשלב הקדמי אימון; דוגמני APE אז משתמשים בין מייצגי שפה ללמודים משותפים בין שפת המקור לשפת המטרה. בנוסף, יצרנו 19 מיליון שלושת סיטטיות חדשות בתור נתונים אימונים נוספים למודל האנסמבל הסופי שלנו. According to experimental results on the WMT2020 APE development data set, our models showed an improvement over the baseline by TER of -3.58 and a BLEU score of +5.3 for the En-De subtask;  ו-TER של -5.29 ו-BLEU נקודה של +7.32 עבור תחתונה אנ-ז.'}
{'en': 'Alibaba’s Submission for the WMT 2020 APE Shared Task : Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT', 'ar': 'تقديم Alibaba للمهمة المشتركة WMT 2020 APE: تحسين التحرير التلقائي بعد التحرير باستخدام BERT الشرطي عبر اللغات المدربين مسبقًا', 'es': 'Presentación de Alibaba para la tarea compartida de APE del WMT 2020: mejora de la postedición automática con BERT multilingüe condicional preentrenado', 'fr': "Soumission d'Alibaba pour la tâche partagée WMT 2020 APE\xa0: amélioration de la post-édition automatique avec BERT multilingue conditionnel pré-formé", 'pt': 'Apresentação do Alibaba para a tarefa compartilhada WMT 2020 APE: melhorar a pós-edição automática com BERT condicional pré-treinado', 'ja': 'WMT 2020 APE共有タスクのためのアリババの提出：事前トレーニングされた条件付きクロスリンガルBERTを使用した自動ポスト編集の改善', 'zh': '阿里巴巴提交WMT 2020 APE共同任务:用豫练BERT改自译后辑', 'hi': 'WMT 2020 APE साझा कार्य के लिए अलीबाबा का सबमिशन: पूर्व-प्रशिक्षित सशर्त क्रॉस-लिंगुअल BERT के साथ स्वचालित पोस्ट-एडिटिंग में सुधार', 'ru': 'Заявка Alibaba на участие в WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT', 'ga': 'Aighneacht Alibaba maidir le Tasc Comhroinnte WMT 2020 APE: Iar-Eagarthóireacht Uathoibríoch a Fheabhsú le BERT Trastheangach Coinníollach Réamhoilte', 'el': 'Υποβολή της Alibaba για την κοινή εργασία του WMT 2020: Βελτίωση της αυτόματης μετα-επεξεργασίας με προ-εκπαιδευμένο υπό όρους διαγλωσσικό BERT', 'ka': 'ალიბაბის მიღება WMT 2020 APE საზოგადომი დავალებისთვის: ავტომატური პოსტრედაქტირება წინასწარმოადგენებული კრისი-ლიგუალური BERT', 'hu': 'Az Alibaba benyújtása a WMT 2020 APE megosztott feladatára: az automatikus utószerkesztés javítása az előképzett feltételes nyelvközi BERT-vel', 'it': 'La presentazione di Alibaba per il WMT 2020 APE Shared Task: Migliorare il post-editing automatico con BERT condizionale cross-linguale pre-addestrato', 'mk': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'ms': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'mt': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'lt': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'ml': 'WMT 2020 എപ്പി പങ്കുചേര്\u200dത്ത ടാസ്കിനുള്ള അലിബാബാബാവിന്റെ സബ്മിഷന്\u200d: മുന്\u200dപ് പരിശീലിക്കപ്പെട്ട ക്രോസ്- ലിങ്കുവല്\u200d ബെര്\u200dടി', 'mn': "Алибаба's Submission for the WMT 2020 APE Shared Task: Automatic Post-Editing with Pre-Trained Conditional Cross-Lingual BERT", 'pl': 'Zgłoszenie Alibaba do WMT 2020 APE wspólnego zadania: poprawa automatycznej edycji poprzez wstępnie przeszkolone warunkowe BERT między językami', 'ro': 'Sublinierea Alibaba pentru WMT 2020 APE Activitate partajată: Îmbunătățirea editării automate cu BERT condiționat cross-lingvistic pre-instruit', 'sr': 'Alibaba podmission za podeljeni zadatak WMT 2020 APE: poboljšanje automatskog posledišnjeg redakcije sa predobučenim uslovnim krstoLingualnim BERT-om', 'no': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'si': 'අලිබාබාගේ WMT 202E සමාගත වැඩක් වෙනුවෙන් සබ්මිසියාව: ස්වයංක්\u200dරිය පොස් සංපාදනය සමග ප්\u200dරධාන ස්ථානය ක්\u200dරොස් ලින්ගුව', 'sv': 'Alibaba:s bidrag till WMT 2020 APE delad uppgift: Förbättra automatisk efterredigering med förbelagd villkorlig tvärspråklig BERT', 'so': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'ur': 'WMT 2020 APE شریک ٹاکس کے لئے آلیباب کا سپومیشن: پیش آموزش کی وضعیت کرس-لینگئال BERT کے ساتھ آٹوٹی پوسٹ-ایڈیٹینگ', 'kk': "WMT 2020 APE ортақ тапсырмасы үшін Alibaba's Submission for the APE Shared Task: Auto Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'ta': 'WMT 2020 APE பகிர்ந்த பணி', 'uz': 'Name', 'vi': 'Công việc chia s ẻ của Alibaba cho giải pháp WRT 2020 APE Chia sẻ Nhiệm vụ: Tăng cường lệnh tự động sau sửa chữa bằng hỗn hợp chữ thiếu chữ', 'hr': 'Alibaba podmission za zajednički zadatak WMT 2020 APE: poboljšanje automatskog posledišnjeg redakcije s predobučenim uvjetnim krstoLingualnim BERT-om', 'nl': "Alibaba's inzending voor de WMT 2020 APE Shared Task: het verbeteren van automatische post-editing met voorgetrainde voorwaardelijke cross-linguale BERT", 'bg': 'Споделена задача: Подобряване на автоматичното пост-редактиране с предварително обучени условни междулингвистични БЕРТ', 'id': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'da': "Alibaba's indsendelse til WMT 2020 APE delt opgave: Forbedring af automatisk efterredigering med forududdannet betinget tværsproget BERT", 'de': "Alibaba's Einreichung für die WMT 2020 APE Shared Task: Verbesserung der automatischen Nachbearbeitung mit vorgetrainiertem Conditional Cross-Lingual BERT", 'sw': 'Ujumbe wa Alibaba kwa ajili ya WMT 2020 APE ulishiriki kazi: Kuboresha Uhariri wa Uhuru wa Marekani na Udhibiti wa Kimataifa wa Uhalifu wa Taifa BERT', 'ko': '알리바바가 제출한 WMT 2020 APE 공유 작업: 사전 교육된 조건부 다국어 편집을 통해 자동 사후 편집 개선', 'fa': 'Submission of Alibaba for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-Trained Conditional Cross-Lingual BERT', 'tr': "Alibaba's Submission for the WMT 2020 APE Shared Task: Auto Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'af': 'Alibaba se Submission vir die WMT 2020 APE Gedeelde Opdrag: Verbeter Automatiese Post-Redigering met vooraf-onderwerp Voorgevorderde Kruis-Linguale BERT', 'am': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'sq': 'Submission of Alibaba for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-Trained Conditional Cross-Lingual BERT', 'bn': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'bs': 'Alibaba podmission za zajednički zadatak WMT 2020 APE-a: poboljšanje automatskog posledišnjeg redakcije sa predobučenim uslovnim krstoLingualnim BERT-om', 'az': "WMT 2020 APE paylaşılan işi üçün Alibaba's Submission: Öncə təhsil edilmiş Cənnət-Lingual BERT ilə Avtomatik Post-Editing Improved", 'cs': 'Podání společnosti Alibaba pro sdílený úkol WMT 2020 APE: zlepšení automatického posteditování pomocí předškoleného podmíněného crosslingválního BERT', 'ca': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-Trained Conditional Cross-Lingual BERT", 'fi': 'Alibaban hakemus WMT 2020 APE Shared Task: Automaattisen jälkimuokkauksen parantaminen esikoulutetulla ehdollisella monikielisellä BERT-ohjelmalla', 'et': 'Alibaba esitus WMT 2020 APE jagatud ülesandele: automaatse järelredigeerimise parandamine eelkoolitud tingimusliku keeleülese BERT-iga', 'hy': 'Ալիբաբայի ներկայացումը ՀԱՄ 2020-ի APE-ի ընդհանուր հանձնարարության համար՝ Ավտոմատիկ հետխմբագրման բարելավումը նախապատրաստված պայմանագրային խաչլեզվային BER-ի միջոցով', 'ha': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'sk': 'Alibabina predložitev za skupno nalogo WMT 2020 APE: izboljšanje samodejnega postnega urejanja s predhodno usposobljenim pogojnim medjezikovnim BERT', 'bo': "Alibaba's Submission for the WMT 2020 APE Shared Task: Improving Automatic Post-Editing with Pre-trained Conditional Cross-Lingual BERT", 'jv': "Alibab's Submis for the WT 2020 ApE shared task: Progress Automatically", 'he': 'השימוש של אליבאבה למשימה משותפת של WMT 2020 APE: שיפור לאחר העורר אוטומטי'}
{'en': 'The goal of Automatic Post-Editing (APE) is basically to examine the automatic methods for correcting translation errors generated by an unknown machine translation (MT) system. This paper describes Alibaba’s submissions to the WMT 2020 APE Shared Task for the English-German language pair. We design a two-stage training pipeline. First, a BERT-like cross-lingual language model is pre-trained by randomly masking target sentences alone. Then, an additional neural decoder on the top of the pre-trained model is jointly fine-tuned for the APE task. We also apply an imitation learning strategy to augment a reasonable amount of pseudo APE training data, potentially preventing the model to overfit on the limited real training data and boosting the performance on held-out data. To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task. The experiment results demonstrate that our system significantly outperforms all other baselines and achieves the state-of-the-art performance. The final results on the WMT 2020 test dataset show that our submission can achieve +5.56 BLEU and -4.57 TER with respect to the official MT baseline.', 'ar': 'الهدف من التحرير التلقائي اللاحق (APE) هو في الأساس فحص الطرق التلقائية لتصحيح أخطاء الترجمة الناتجة عن نظام ترجمة آلية غير معروف (MT). تصف هذه الورقة الطلبات المقدمة من علي بابا إلى المهمة المشتركة WMT 2020 APE لزوج اللغتين الإنجليزية والألمانية. نصمم خط أنابيب للتدريب على مرحلتين. أولاً ، يتم تدريب نموذج اللغة المتقاطعة الذي يشبه BERT مسبقًا عن طريق إخفاء الجمل المستهدفة بشكل عشوائي وحده. بعد ذلك ، يتم ضبط وحدة فك ترميز عصبية إضافية أعلى النموذج المدرب مسبقًا بشكل جيد لمهمة APE. نطبق أيضًا إستراتيجية تعلم تقليد لزيادة كمية معقولة من بيانات تدريب APE الزائفة ، مما يحتمل أن يمنع النموذج من الإفراط في استخدام بيانات التدريب الحقيقية المحدودة وتعزيز الأداء على البيانات المحتجزة. للتحقق من نموذجنا المقترح وزيادة البيانات ، نقوم بفحص نهجنا مع مجموعة البيانات الإنجليزية الألمانية المعروفة لقياس الأداء من مهمة WMT 2017 APE. توضح نتائج التجربة أن نظامنا يتفوق بشكل كبير على جميع خطوط الأساس الأخرى ويحقق أداءً متطورًا. تُظهر النتائج النهائية لمجموعة بيانات اختبار WMT 2020 أن إرسالنا يمكن أن يحقق +5.56 BLEU و -4.57 TER فيما يتعلق بخط الأساس الرسمي لـ MT.', 'pt': 'O objetivo da Pós-Edição Automática (APE) é basicamente examinar os métodos automáticos para corrigir erros de tradução gerados por um sistema de tradução automática (TA) desconhecido. Este artigo descreve os envios do Alibaba para a Tarefa Compartilhada do WMT 2020 APE para o par de idiomas inglês-alemão. Projetamos um pipeline de treinamento em dois estágios. Primeiro, um modelo de linguagem multilíngue do tipo BERT é pré-treinado, mascarando aleatoriamente apenas as frases-alvo. Em seguida, um decodificador neural adicional na parte superior do modelo pré-treinado é ajustado em conjunto para a tarefa APE. Também aplicamos uma estratégia de aprendizado de imitação para aumentar uma quantidade razoável de dados de treinamento de pseudo APE, potencialmente impedindo que o modelo se ajuste demais aos dados de treinamento reais limitados e aumentando o desempenho em dados retidos. Para verificar nosso modelo proposto e o aumento de dados, examinamos nossa abordagem com o conhecido conjunto de dados inglês-alemão de benchmarking da tarefa WMT 2017 APE. Os resultados do experimento demonstram que nosso sistema supera significativamente todas as outras linhas de base e alcança o desempenho de última geração. Os resultados finais no conjunto de dados de teste do WMT 2020 mostram que nosso envio pode atingir +5,56 BLEU e -4,57 TER em relação à linha de base oficial do MT.', 'fr': "L'objectif de la post-édition automatique (APE) est essentiellement d'examiner les méthodes automatiques de correction des erreurs de traduction générées par un système de traduction automatique (TA) inconnu. Cet article décrit les soumissions d'Alibaba à la tâche partagée WMT 2020 APE pour la paire de langues anglais-allemand. Nous concevons un pipeline de formation en deux étapes. Tout d'abord, un modèle de langage multilingue de type Bert est pré-entraîné en masquant aléatoirement les phrases cibles uniquement. Ensuite, un décodeur neuronal supplémentaire sur le dessus du modèle pré-entraîné est ajusté conjointement pour la tâche APE. Nous appliquons également une stratégie d'imitation d'apprentissage pour augmenter une quantité raisonnable de données d'entraînement pseudo-APE, empêchant potentiellement le modèle de s'adapter aux données d'entraînement réelles limitées et augmentant les performances sur les données d'entraînement en attente. Pour vérifier notre modèle proposé et l'augmentation des données, nous examinons notre approche avec le célèbre jeu de données de référence anglais-allemand de la tâche APE WMT 2017. Les résultats de l'expérience démontrent que notre système surpasse largement toutes les autres lignes de base et atteint les performances de pointe. Les résultats finaux de l'ensemble de données de test WMT 2020 montrent que notre soumission peut atteindre +5,56 UEBL et -4,57 TER par rapport à la base de référence MT officielle.", 'es': 'El objetivo de la Postedición Automática (APE) es básicamente examinar los métodos automáticos para corregir los errores de traducción generados por un sistema de traducción automática (MT) desconocido. Este documento describe los envíos de Alibaba a la Tarea Compartida APE del WMT 2020 para el par de idiomas inglés-alemán. Diseñamos un canal de formación en dos etapas. En primer lugar, un modelo de lenguaje multilingüe similar al de Bert se entrena previamente enmascarando al azar las oraciones objetivo solo. Luego, un decodificador neuronal adicional en la parte superior del modelo previamente entrenado se ajusta conjuntamente para la tarea APE. También aplicamos una estrategia de aprendizaje de imitación para aumentar una cantidad razonable de datos de entrenamiento pseudo APE, lo que podría evitar que el modelo se ajuste demasiado a los limitados datos de entrenamiento reales y aumentar el rendimiento de los datos retenidos. Para verificar nuestro modelo propuesto y el aumento de datos, examinamos nuestro enfoque con el conocido conjunto de datos de evaluación comparativa inglés-alemán de la tarea APE del WMT 2017. Los resultados del experimento demuestran que nuestro sistema supera significativamente a todas las demás líneas de base y logra un rendimiento de vanguardia. Los resultados finales del conjunto de datos de la prueba WMT 2020 muestran que nuestra presentación puede alcanzar +5,56 BLEU y -4,57 TER con respecto a la línea de base oficial de MT.', 'hi': 'स्वचालित पोस्ट-एडिटिंग (एपीई) का लक्ष्य मूल रूप से एक अज्ञात मशीन अनुवाद (एमटी) सिस्टम द्वारा उत्पन्न अनुवाद त्रुटियों को ठीक करने के लिए स्वचालित तरीकों की जांच करना है। यह पेपर अंग्रेजी-जर्मन भाषा जोड़ी के लिए डब्ल्यूएमटी 2020 एपीई साझा कार्य के लिए अलीबाबा की प्रस्तुतियों का वर्णन करता है। हम एक दो-चरण प्रशिक्षण पाइपलाइन डिजाइन करते हैं। सबसे पहले, एक BERT-like cross-lingual language model को अकेले लक्ष्य वाक्यों को बेतरतीब ढंग से मास्क करके पूर्व-प्रशिक्षित किया जाता है। फिर, पूर्व-प्रशिक्षित मॉडल के शीर्ष पर एक अतिरिक्त तंत्रिका विकोडक संयुक्त रूप से एपीई कार्य के लिए ठीक-ठाक है। हम छद्म एपीई प्रशिक्षण डेटा की उचित मात्रा को बढ़ाने के लिए एक नकल सीखने की रणनीति भी लागू करते हैं, संभावित रूप से मॉडल को सीमित वास्तविक प्रशिक्षण डेटा पर ओवरफिट करने और आयोजित-आउट डेटा पर प्रदर्शन को बढ़ावा देने से रोकते हैं। हमारे प्रस्तावित मॉडल और डेटा वृद्धि को सत्यापित करने के लिए, हम WMT 2017 APE कार्य से प्रसिद्ध बेंचमार्किंग अंग्रेजी-जर्मन डेटासेट के साथ हमारे दृष्टिकोण की जांच करते हैं। प्रयोग के परिणाम दर्शाते हैं कि हमारी प्रणाली अन्य सभी आधार रेखाओं को काफी हद तक बेहतर बनाती है और अत्याधुनिक प्रदर्शन प्राप्त करती है। WMT 2020 परीक्षण डेटासेट पर अंतिम परिणाम बताते हैं कि हमारा सबमिशन आधिकारिक एमटी बेसलाइन के संबंध में +5.56 BLEU और -4.57 TER प्राप्त कर सकता है।', 'ru': 'Целью автоматического пост-редактирования (APE) в основном является изучение автоматических методов исправления ошибок перевода, генерируемых неизвестной системой машинного перевода (MT). В этой статье описываются представления Alibaba для совместной задачи WMT 2020 APE для англо-немецкой языковой пары. Мы проектируем двухэтапный тренировочный конвейер. Во-первых, BERT-подобная модель межязыкового языка предварительно обучается, случайным образом маскируя только целевые предложения. Затем проводят совместную настройку дополнительного нейронного декодера на вершине предварительно обученной модели для задачи APE. Мы также применяем стратегию обучения подражанию, чтобы увеличить разумное количество обучающих данных псевдоприматов, потенциально предотвращая переоценку модели на ограниченных реальных обучающих данных и повышая производительность на удерживаемых данных. Для проверки предлагаемой нами модели и дополнения данных мы изучаем наш подход с помощью хорошо известного эталонного англо-германского набора данных из задачи APE WMT 2017. Результаты эксперимента показывают, что наша система значительно превосходит все другие базовые уровни и достигает самых современных показателей. Окончательные результаты тестового набора данных WMT 2020 показывают, что наша заявка может достичь +5,56 BLEU и -4,57 ТЕР по отношению к официальному базовому уровню MT.', 'ja': '自動ポストエディット（ APE ）の目的は、基本的に、未知の機械翻訳（ MT ）システムによって生成された翻訳エラーを修正するための自動方法を検討することです。 この論文では、英語とドイツ語のペアのWMT 2020 APE共有タスクへのアリババの提出について説明します。 2段階のトレーニングパイプラインを設計します。 まず、BERTのようなクロスリンガル言語モデルは、標的文だけをランダムにマスキングすることによって事前にトレーニングされる。 次いで、事前に訓練されたモデルの上部の追加のニューラルデコーダは、APEタスクのために共同で微調整される。 また、模倣学習戦略を適用して、合理的な量の擬似類人猿トレーニングデータを増強し、モデルが限られた実際のトレーニングデータに適合しすぎるのを防ぎ、ホールドアウトデータのパフォーマンスを向上させる可能性があります。 提案されているモデルとデータ拡張を検証するために、WMT 2017 APEタスクからの有名なベンチマーク英語-ドイツ語データセットを使用して、アプローチを検討します。 実験結果は、当社のシステムが他のすべてのベースラインを大幅に上回り、最先端のパフォーマンスを達成していることを示しています。 WMT 2020試験データセットの最終結果は、当社の提出物が公式のMTベースラインに対して+5.56 BLEUおよび-4.57 TERを達成できることを示しています。', 'zh': '自译后辑 (APE) 者,盖检用于未知机器翻译 (MT) 统成译误之自法也。 本文介阿里巴巴WMT 2020 APE共享英语 - 德语对。 设两阶培训管道。 先是,以随机屏蔽之句,预练类BERT跨语模样。 然后合 APE 调预练其神经解码器。 宜用一法学习策略以益伪APE,以防有限之真,以拟合其数,以存其数。 以验吾形与数,以WMT 2017 APE众所周知英语 - 德语数集来稽吾法。 实验结果表明,吾统明优于诸基线,而致其先进之性。 WMT 2020 测试数据集之终结果表明,相对于官 MT 基线,吾辈提交之BLEU可以致 +5.56 -4.57 TER。', 'ga': 'Is é an sprioc atá le hIar-Eagarthóireacht Uathoibríoch (APE) go bunúsach ná scrúdú a dhéanamh ar na modhanna uathoibríocha chun earráidí aistriúcháin a cheartú a ghineann córas aistriúcháin meaisín anaithnid (MT). Déanann an páipéar seo cur síos ar aighneachtaí Alibaba do Thasc Comhroinnte WMT 2020 APE don phéire Béarla-Gearmáinis. Dearaimid píblíne oiliúna dhá chéim. Ar an gcéad dul síos, déantar réamh-oiliúint ar mhúnla teanga tras-teanga ar nós BERT trí sprioc-abairtí a chumhdach go randamach amháin. Ansin, déantar díchódóir néaránach breise ar bharr an mhúnla réamhoilte a mhionchoigeartú don tasc APE. Cuirimid straitéis foghlama bréige i bhfeidhm freisin chun cur le méid réasúnta sonraí oiliúna APE bréige, rud a d’fhéadfadh cosc a chur ar an tsamhail rófheistiú ar na sonraí teoranta oiliúna agus chun an fheidhmíocht ar shonraí coinnithe amach a threisiú. Chun ár múnla molta agus an méadú sonraí a fhíorú, scrúdaímid ár gcur chuige leis an tacar sonraí tagarmharcála Béarla-Gearmáinis aitheanta ó thasc WMT 2017 APE. Léiríonn torthaí an turgnaimh go sáraíonn ár gcóras gach bonnlíne eile go suntasach agus go mbaineann sé an fheidhmíocht úrscothach amach. Léiríonn na torthaí deiridh ar thacar sonraí tástála WMT 2020 gur féidir lenár n-aighneacht +5.56 BLEU agus -4.57 TER a bhaint amach maidir leis an mbunlíne oifigiúil MT.', 'hu': 'Az Automatikus utószerkesztés (APE) célja alapvetően az, hogy megvizsgálja az ismeretlen gépi fordítási (MT) rendszer által generált fordítási hibák automatikus javításának módszereit. Ez a tanulmány bemutatja az Alibaba beadványait az angol-német nyelvpárra vonatkozó WMT 2020 APE Shared Task programhoz. Tervezünk egy kétlépcsős kiképzést. Először is, egy BERT-szerű, többnyelvű nyelvű modellt előkészítenek a célmondatok véletlenszerű maszkolásával. Ezután az előkészített modell tetején egy további neurális dekódolót közösen finomhangoltak az APE feladathoz. Alkalmazunk egy utánzó tanulási stratégiát is, hogy ésszerű mennyiségű pszeudo APE edzési adatot bővítsünk, potenciálisan megakadályozzuk, hogy a modell túlférjen a korlátozott valós edzési adatokhoz, és növeljük a tartott adatok teljesítményét. Javasolt modellünk és adatbővítésünk ellenőrzése érdekében megközelítésünket a WMT 2017 APE feladat jól ismert angol-német teljesítményértékelésével vizsgáljuk. A kísérleti eredmények azt mutatják, hogy rendszerünk jelentősen felülmúlja az összes többi alapvető értéket és eléri a legkorszerűbb teljesítményt. A WMT 2020 tesztadatkészlet végleges eredményei azt mutatják, hogy benyújtásunk +5,56 BLEU és -4,57 TER érhető el a hivatalos MT kiindulási értékhez képest.', 'el': "Ο στόχος της αυτόματης μετα-επεξεργασίας (ΑΠΕ) είναι βασικά να εξετάσει τις αυτόματες μεθόδους διόρθωσης μεταφραστικών σφαλμάτων που δημιουργούνται από ένα άγνωστο σύστημα μηχανικής μετάφρασης (ΜΤ). Αυτή η εργασία περιγράφει τις υποβολές της Alibaba στην κοινή εργασία WMT 2020 APE για το ζεύγος αγγλικής-γερμανικής γλώσσας. Σχεδιάζουμε δύο στάδια εκπαίδευσης. Κατ' αρχάς, ένα μοντέλο διασταυρούμενης γλώσσας που μοιάζει με το BERT προετοιμάζεται με τυχαία απόκρυψη των προτάσεων στόχων μόνο. Στη συνέχεια, ένας πρόσθετος νευρικός αποκωδικοποιητής στην κορυφή του προ-εκπαιδευμένου μοντέλου συντονίζεται από κοινού για την εργασία APE. Εφαρμόζουμε επίσης μια στρατηγική απομίμησης μάθησης για να αυξήσουμε ένα εύλογο ποσό ψευδο-εκπαιδευτικών δεδομένων, εμποδίζοντας ενδεχομένως το μοντέλο να υπερβεί τα περιορισμένα πραγματικά δεδομένα κατάρτισης και ενισχύοντας την απόδοση σε καθυστερημένα δεδομένα. Για να επαληθεύσουμε το προτεινόμενο μοντέλο και την αύξηση δεδομένων, εξετάζουμε την προσέγγισή μας με το γνωστό σύνολο δεδομένων συγκριτικής αξιολόγησης αγγλικά-γερμανικών από την εργασία του ΟΠΕ. Τα αποτελέσματα του πειράματος δείχνουν ότι το σύστημά μας ξεπερνά σημαντικά όλες τις άλλες γραμμές βάσης και επιτυγχάνει τις επιδόσεις τελευταίας τεχνολογίας. Τα τελικά αποτελέσματα του συνόλου δεδομένων δοκιμής δείχνουν ότι η υποβολή μας μπορεί να επιτύχει +5.56 BLEU και -4.57 TER σε σχέση με την επίσημη βάση ΜΤ.", 'it': "L'obiettivo di Automatic Post-Editing (APE) è fondamentalmente quello di esaminare i metodi automatici per correggere gli errori di traduzione generati da un sistema di traduzione automatica sconosciuto (MT). Questo articolo descrive i contributi di Alibaba al WMT 2020 APE Shared Task per la coppia di lingue inglese-tedesco. Progettiamo un percorso formativo in due fasi. In primo luogo, un modello linguistico multilingue simile a BERT è pre-addestrato mascherando casualmente solo le frasi target. Poi, un decoder neurale aggiuntivo sulla parte superiore del modello pre-addestrato è messo a punto congiuntamente per il compito APE. Applichiamo anche una strategia di apprendimento imitativo per aumentare una quantità ragionevole di dati di allenamento pseudo APE, impedendo potenzialmente al modello di sovraadattarsi ai dati di allenamento reali limitati e aumentando le prestazioni sui dati trattenuti. Per verificare il modello proposto e l'aumento dei dati, esaminiamo il nostro approccio con il noto set di dati inglese-tedesco del compito APE WMT 2017. I risultati dell'esperimento dimostrano che il nostro sistema supera significativamente tutte le altre linee di base e raggiunge le prestazioni all'avanguardia. I risultati finali sul set di dati di prova WMT 2020 mostrano che la nostra presentazione può raggiungere +5,56 BLEU e -4,57 TER rispetto alla base MT ufficiale.", 'kk': 'Автоматты кейін өңдеу (APE) мақсаты - беймәлім компьютер аудару (MT) жүйесінен құрылған аудару қатесін түзету арқылы автоматты түрде тексеру. Бұл қағаз Алибабаның WMT 2020 APE қосымшаларының ағылшын- неміс тілінің қосымшасына ортақ тапсырмасын таңдайды. Біз екі этап оқыту сызығын құрамыз. Біріншіден, BERT- секілді бірнеше тіл үлгісі бір- біріншіден кездейсоқ мақсатты сөздерді қалқалау үшін бірге оқылған. Содан кейін APE тапсырмасы үшін қосымша невралдық декодторы біріктіріледі. Сонымен қатар біз псевдо APE оқыту деректерін көбейту үшін ұқсас оқыту стратегиясын қолданып, үлгісін шектелген шындық оқыту деректеріне көбейту және сақталған деректерді көбейту үшін болады. Біздің келтірілген моделімізді және деректерді көбейту үшін WMT 2017 APE тапсырмасынан ағылшын- неміс деректерді бақылау бағдарламасын тексереміз. Тәжірибенің нәтижелері, жүйеміздің басқа негізгі сызықтарын өзгертіп, әртүрлі жағдайдың күйін жеткізеді. WMT 2020 сынақ деректер жиынының соңғы нәтижелері біздің жіберіміз +5,56 BLEU және -4,57 МЕТ негізгі MT негізгі жолына сәйкес жеткізуге болады.', 'mk': 'Целта на Автоматското постуредување (APE) е во основа да ги испита автоматските методи за корекција на грешките во преводот генерирани од непознат систем на машински превод (MT). Овој весник ги опишува поднесувањата на Алибаба на WMT 2020 APE Shared Task for the English-German language pair. Дизајнираме двофазивен гасовод за тренинг. First, a BERT-like cross-lingual language model is pre-trained by randomly masking target sentences alone.  Then, an additional neural decoder on the top of the pre-trained model is jointly fine-tuned for the APE task.  We also apply an imitation learning strategy to augment a reasonable amount of pseudo APE training data, potentially preventing the model to overfit on the limited real training data and boosting the performance on held-out data.  To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task.  Резултатите од експериментите покажуваат дека нашиот систем значително ги надминува сите други основни линии и постигнува најсовремени резултати. Конечните резултати на тестовите на ВМТ 2020 покажуваат дека нашето поднесување може да достигне +5,56 БЛЕУ и -4,57 ТЕР во однос на официјалната основа на МТ.', 'ms': "Tujuan Penyunting-Selepas Automatik (APE) adalah pada dasarnya untuk memeriksa kaedah automatik untuk memperbaiki ralat terjemahan yang dijana oleh sistem terjemahan mesin (MT) tidak diketahui. This paper describes Alibaba's submissions to the WMT 2020 APE Shared Task for the English-German language pair.  We design a two-stage training pipeline.  Pertama, model bahasa saling bahasa seperti BERT dilatih-dilatih secara rawak dengan menutup kalimat sasaran sahaja. Kemudian, dekoder saraf tambahan di atas model yang dilatih-dilatih disesuaikan bersama-sama untuk tugas APE. We also apply an imitation learning strategy to augment a reasonable amount of pseudo APE training data, potentially preventing the model to overfit on the limited real training data and boosting the performance on held-out data.  To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task.  Hasil eksperimen menunjukkan bahawa sistem kita jauh melebihi semua garis dasar lain dan mencapai prestasi state-of-the-art. Hasil akhir pada set data ujian WMT 2020 menunjukkan bahawa penghantaran kita boleh mencapai +5.56 BLEU dan -4.57 TER terhadap dasar MT rasmi.", 'ka': 'ავტომატური დარედაქტირება (APE) მისამართლად არის ავტომატური პროცემების შეცდომის რედაქტირება, რომელიც არაცნობი მაქსინური გაგრძელების (MT) სისტემიდან შექმნა. ამ დოკუმენტი აღწერს ალიბაბის გადასტანების WMT 2020 APE-ის გაყოფილი დავალება ინგლისურ-გერმანური ენის ზოგებისთვის. ჩვენ ორ ფაეჯის განსწავლების გარეშე. პირველად, BERT-ის კრესი ენგური მოდელი უნდა გააკეთებულია თავისუფალურად მისაღების მაქსირებით. შემდეგ, დამატებული ნეიროლური ევკოდირები პროგრამეტრებული მოდელის მარცხენა ერთადერთად აკეთება APE დავალებისთვის. ჩვენ ასევე მოვიყენებთ თმიტაციის სწავლების სტრატიფიკაციის სტრატიფიკაცია, რომელიც პესეუდო APE სწავლების მონაცემების რაოდენობას, რომელიც შეუძლებელია მოდელის მოწყობილობას, რომელიც დავ ჩვენი მოდელი და მონაცემების აზექტირებისთვის გადარწმუნოთ, ჩვენ ჩვენი მოხმარება უცნობიერი ბენქმინირებით ინგლისურ-გერმანური მონაცემების დანაცემებით WM ექსპერიმენტის წარმოდგენები აჩვენებენ, რომ ჩვენი სისტემა მნიშვნელოვანია ყველა სხვა ფესტური ხაზები და მიიღებენ სურათის წარმოდგენება. WMT 2020 ტესტის მონაცემების შესახებ, რომ ჩვენი მონაცემები შეუძლია +5,56 BLEU და -4,57 TER დაიწყება პროფიციალური MT ბაზლინის შესახებ.', 'mn': 'Автоматик ПостEdit (APE) гэх зорилго нь машины орчуулалт (MT) системээс гаргасан орчуулалтын алдаа зөвшөөрөх автоматик аргыг шалгах юм. Энэ цаас Англи-Германы хэл хоёрын WMT 2020 APE-ын хуваалцааны ажил дээр Алибабагийн хэвлэлийг тайлбарладаг. Бид хоёр дахь сургалтын хоолойн шугам бүтээж байна. Эхлээд, БЕРТ шиг олон хэл загвар нь зөвхөн зориулагдсан өгүүлбэрүүдийг газрын зурагтай болгож сургалтын өмнө сургалтын загвар юм. Дараа нь, өмнө сургалтын загварын дээд нэмэлт мэдрэлийн загвар нь APE ажлын төлөө нийлүүлэгддэг. Бид мөн адилхан суралцах стратеги ашиглаж APE суралцах өгөгдлийн санааг нэмэгдүүлэхэд зориулж, загварыг хязгаарлагдсан жинхэнэ суралцах өгөгдлийн талаар илүү тодорхойлох боломжтой болгодог. Бидний санал дэвшүүлсэн загвар болон өгөгдлийн нэмэгдүүлэлтийг шалгахын тулд бид WMT 2017 APE ажлын англи-Германы өгөгдлийн сангийн салбарын арга баримтыг судалж байна. Эдгээр туршилтын үр дүнд бидний систем бусад суурь шугам дээр илүү чухал болж, урлагийн үйл ажиллагааг гаргадаг. WMT 2020-ын тест өгөгдлийн сангийн сүүлийн үр дүнд бидний тайлбарлалт нь +5.56 БЛЕС болон -4.57 МДЭР гаргаж чадна.', 'no': 'Målet for automatisk postredigering (APE) er å undersøkja automatiske metodar for å retta omsetjingsfeilar laga av ein ukjend maskinsomsetjingssystem (MT). Denne papiret beskriver Alibaba sine tillegg til den delte oppgåva WMT 2020 for den engelske-tyske språkopla. Vi designerer ein to-stadsopplæringsrøyr. Først er eit BERT-like krysspråk-modell først utlært av tilfeldig maskering av målsettingar alene. Deretter er ein ekstra neuraldekoder på toppen av den først trengte modellen kopla til APE-oppgåva. Vi bruker også ein imitasjon-læringsstrategi for å auka ein raskt mengd pseudo-APE-læringsdata, som potensielt forebyr modellen å overpassa med dei begrensede faktiske opplæringsdata og styra utviklinga på behaldande data. For å stadfesta vårt foreslått modell og data-augmentasjon, ser vi tilnærminga vårt med den godt kjente benchmarking av dataset engelsk-tysk frå WMT-oppgåva 2017 APE. Eksperimentresultatet viser at systemet vår utfører dei andre grunnlinjene og oppnår kunsthandlinga. Den siste resultatene på WMT 2020-test dataset viser at vårt søknad kan oppnå +5,56 BLEU og -4,57 TER med respekt til den offisielle MT-baseline.', 'lt': "Automatinio pakartotinio redagavimo (APE) tikslas iš esmės yra išnagrinėti automatinius vertimo klaidų, kurias sukelia nežinoma mašininio vertimo (MT) sistema, koregavimo metodus. This paper describes Alibaba's submissions to the WMT 2020 APE Shared Task for the English-German language pair.  Mes suprojektuojame dviejų etapų mokymo vamzdyną. Pirma, į BERT panašus tarpkalbinis model is iš anksto mokomas tik atsitiktinai maskuojant tikslinius sakinius. Tuomet papildomas nervų dekoderis viršuje iš anksto apmokyto modelio kartu tiksliai pritaikomas APE uždaviniui. We also apply an imitation learning strategy to augment a reasonable amount of pseudo APE training data, potentially preventing the model to overfit on the limited real training data and boosting the performance on held-out data.  To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task.  Eksperimentų rezultatai rodo, kad mūsų sistema gerokai viršija visas kitas bazines linijas ir siekia pažangiausių rezultatų. Galutiniai WMT 2020 bandymų duomenų rinkinio rezultatai rodo, kad mūsų pateikta informacija gali pasiekti +5,56 BLEU ir -4,57 TER, palyginti su oficialia MT pradine verte.", 'ro': 'Scopul de Automatic Post-Editing (APE) este de a examina metodele automate de corectare a erorilor de traducere generate de un sistem necunoscut de traducere automată (MT). Această lucrare descrie observațiile Alibaba la WMT 2020 APE Shared Task pentru perechea de limbi engleză-germană. Proiectăm o conductă de instruire în două etape. În primul rând, un model de limbă interlingvistică asemănător BERT este pre-antrenat prin mascarea aleatorie a propozițiilor țintă numai. Apoi, un decoder neural suplimentar pe partea de sus a modelului pre-antrenat este împreună reglat fin pentru sarcina APE. De asemenea, aplicăm o strategie de imitație a învățării pentru a mări o cantitate rezonabilă de date de formare pseudo APE, potențial împiedicând modelul să depășească datele limitate reale de formare și creșterea performanței pe datele reținute. Pentru a verifica modelul propus și mărirea datelor, analizăm abordarea noastră cu binecunoscutul set de date engleză-germană de benchmarking din sarcina APE WMT 2017. Rezultatele experimentelor demonstrează că sistemul nostru depășește semnificativ toate celelalte linii de bază și atinge performanțele de ultimă generație. Rezultatele finale ale setului de date de testare WMT 2020 arată că depunerea noastră poate atinge +5,56 BLEU și -4,57 TER în raport cu valoarea de referință oficială MT.', 'pl': 'Celem Automatic Post-Editing (APE) jest zasadniczo zbadanie automatycznych metod korekcji błędów tłumaczeniowych generowanych przez nieznany system tłumaczenia maszynowego (MT). Niniejszy artykuł opisuje zgłoszenia Alibaba do WMT 2020 APE Shared Task dla pary językowej angielsko-niemieckiej. Zaprojektujemy dwustopniową linię szkoleniową. Po pierwsze, model językowy podobny do BERT jest wstępnie trenowany przez losowe maskowanie samych zdań docelowych. Następnie dodatkowy dekoder neuronowy na górze wstępnie przeszkolonego modelu jest wspólnie dostrojony do zadania APE. Stosujemy również strategię uczenia się imitacji, aby zwiększyć rozsądną ilość pseudo-APE danych treningowych, potencjalnie uniemożliwiając przepełnienie modelu na ograniczonych rzeczywistych danych treningowych i zwiększając wydajność przechowywanych danych. Aby zweryfikować proponowany model i rozszerzenie danych, badamy nasze podejście za pomocą znanego zestawu danych benchmarkingowych angielsko-niemieckich z zadania WMT 2017 APE. Wyniki eksperymentu pokazują, że nasz system znacznie przewyższa wszystkie inne linie bazowe i osiąga najnowocześniejszą wydajność. Ostateczne wyniki zbioru danych testowych WMT 2020 pokazują, że nasze zgłoszenie może osiągnąć +5.56 BLEU i -4.57 TER w odniesieniu do oficjalnej bazy danych MT.', 'ml': 'ഒരു അറിഞ്ഞിട്ടില്ലാത്ത മെഷീന്\u200d പരിഭാഷപ്പെടുത്തിയ പിശകുകള്\u200d പരിശോധിപ്പിക്കുന്നതിനുള്ള സ്വയം പിന്തിരിച്ചുചിട്ടുള്ള (APE)  ഈ പത്രത്തില്\u200d അലിബാബയുടെ കീഴ്പ്പെടുത്തിയിരിക്കുന്നു WMT 2020 എപ്പി പങ്കുചേര്\u200dത്ത ടാസ്ക് ഇംഗ്ലീഷ്-ജര്\u200dമ്മന We design a two-stage training pipeline.  ആദ്യം, ഒരു BERT-പോലെയുള്ള ക്രിസ്ലിങ്കുള്ള ഭാഷ മോഡല്\u200d മുമ്പ് പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു അപ്പോള്\u200d, മുന്\u200dപരിശീലിക്കപ്പെട്ട മോഡലിന്\u200dറെ മുകളില്\u200d കൂടുതല്\u200d ന്യൂറല്\u200d ഡെകോഡെര്\u200d എപ്പിഇ ജോലി നമ്മളും ഒരു അനുഭരണപഠിപ്പിക്കാനുള്ള ഒരു സാങ്കേതം പ്രയോഗിക്കുന്നു. ഒരു കാര്യം പെയുഡോ എപിഎം പരിശീലന വിവരങ്ങള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നതിനായി, ഞങ്ങളുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡലും ഡേറ്റാ കൂട്ടത്തെയും പരിശോധിക്കാന്\u200d വേണ്ടി ഞങ്ങള്\u200d ഞങ്ങളുടെ വഴിയെ പരിശോധിക്കുന്നു. WMT 2017 എപ The experiment results demonstrate that our system significantly outperforms all other baselines and achieves the state-of-the-art performance.  WMT 2020 ടെസ്റ്റ് ഡാറ്റാസെറ്റിന്റെ അവസാന ഫലങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു നമ്മുടെ സമ്മാനം 5.56 ബെല്ലൂ പിന്നെ നേടാന്\u200d സാധി', 'so': 'Ujeedada Automatic-Editing (APE) waa in aad baaritaan qaababka automatika ah ee hagitaanka qalabka turjumaadda oo lagu soo dhashay tarjumaadda machine (MT). Kanu warqaddan waxaa ku qoran warqada uu Alibaba u soo dhiibay WMT 2020 APE Shaqada loo sharciyey labada luqada Ingiriis-Jarmal. Waxaynu sameynaa heer waxbarasho labaad. Marka ugu horeysa, qaabka luqada oo BERT u eg waa mid horay loo tababaray oo uu gooni ahaantiis u gaaro xarumaha luqada. Markaas waxaa ku qoran kaarka neurada dheer oo ku qoran modelka hore ee lagu tababariyey si wadajir ah looga helo shaqada APE. Sidoo kale waxaynu u codsanaynaa qorshaha waxbarashada takhasuska ah si a an ugu kordhino macluumaad waxbarasho ee APE ah, si suurtowda ah uga hor jeedinno modelka si uu ugu dhaafo macluumaadka waxbarashada ee dhabta ah iyo horumarinta waxyaabaha lagu sameynayo. Si aan u xaqiijinno tilmaamaha la soo jeeday iyo kordhinta macluumaadka, waxaynu ku baaraynaa qaababka aad u yaqaan bangiga ingiriisiga-Jarmalka ee shaqada WMT 2017 APE. Imtixaanka waxaa ka muuqda in nidaamkayagu uu si muhiim ah u sameeyo saldhigyada kale oo dhan, wuxuuna gaadhaa bandhigyada farshaxanka. The final results on the WMT 2020 test dataset show that our submission can achieve +5.56 BLEU and -4.57 TER with respect to the official MT baseline.', 'sv': 'Målet med Automatisk efterredigering (APE) är i grund och botten att undersöka de automatiska metoderna för att korrigera översättningsfel som genereras av ett okänt maskinöversättningssystem (MT). Denna uppsats beskriver Alibabas bidrag till WMT 2020 APE Shared Task för engelsk-tyska språkparet. Vi designar en utbildningspipeline i två steg. För det första är en BERT-liknande tvärspråksmodell förklädd genom att slumpmässigt maskera målmeningar enbart. Sedan finjusteras en ytterligare neural avkodare ovanpå den förintränade modellen gemensamt för APE-uppgiften. Vi tillämpar också en imitationsinlärningsstrategi för att öka en rimlig mängd pseudo APE-träningsdata, vilket potentiellt hindrar modellen att överbelasta de begränsade verkliga träningsdata och ökar prestandan på utdragna data. För att verifiera vår föreslagna modell och dataökning undersöker vi vårt tillvägagångssätt med den välkända benchmarking engelsk-tyska datauppsättningen från WMT 2017 APE-uppgiften. Experimentresultaten visar att vårt system avsevärt överträffar alla andra baslinjer och uppnår toppmoderna prestanda. De slutliga resultaten på WMT 2020 testdatauppsättningen visar att vår inlämning kan uppnå +5,56 BLEU och -4,57 TER med avseende på den officiella MT baseline.', 'ta': "@ info This paper describes Alibaba's submissions to the WMT 2020 APE Shared Task for the English-German language pair.  நாம் இரண்டு நிலையில் பயிற்சி பைப்லைனை வடிவமைக்கிறோம். முதலில், ஒரு BERT-போன்ற மொழி மாதிரி மாதிரி முன் பயிற்சி முன் பயிற்சி செய்யப்பட்டுள்ளது குறிப்பில்லாத முகம் ம முன் பயிற்சிக்கப்பட்ட மாதிரியின் மேல் ஒரு கூடுதல் புதிய குறியீட்டாளர் APE செயலுக்கு ஒன்றாக நன்றாக ஒப்பிடுகிறது. நாம் ஒரு பின்பற்ற கற்றுக்கொள்ளும் திட்டத்தை பயன்படுத்துகிறோம் ஒரு விருப்பப்படுத்தல் திட்டம் APE பயிற்சியின் தகவலை அதிகப்படுத்துவதற்கு, மாதிரியை அதி எங்கள் பரிந்துரைக்கப்பட்ட மாதிரி மற்றும் தரவு கூட்டுதலை சரிபார் பரிசோதனை முடிவு WMT 2020 சோதனை தரவுத்தளத்தின் கடைசி முடிவு", 'ur': 'اٹوٹوٹ پیس ویڈینگ (APE) کا موقع اساساتی طریقے کی تحقیق کرنا ہے کہ ایک ناشناختہ ماشین ترجمہ (MT) سیسٹم کے ذریعہ پیدا کیا گیا ترجمہ خطاؤں کی اصلاح کرنے کے لئے آٹوٹی طریقے ہیں. یہ کاغذ الیباب کے مطابق WMT 2020 APE کے شریک ٹاکس کے لئے الیباب کے مطابق بیان کرتا ہے. ہم ایک دومرحلہ تطالب پیپ لین طراحی کرتے ہیں۔ پہلے، ایک BERT جیسی کرس زبان کی مدل ایک طرح کی زبان کے سامنے پہلے تدریس کی جاتی ہے تاہل جماعتوں کو اکیلے ماسک کرتی ہے۔ پھر ایک اضافہ نئورل ڈیکوڈر پہلے کی آموزش کی مدل کے اوپر سے APE کے کام کے لئے ایک جوڑا سامان کیا جاتا ہے. ہم نے بھی ایک مثال سیکھنے کی استراتژی کا استراتژی استراتژی کرنا چاہا ہے کہ مثال مثال مثال مثال مثال اپنا پیدائٹ اپنا استراتژی ڈیٹا زیادہ کرے، امکانات میں موڈل کو محدودہ حقیقی تربینی ڈیٹا پر زیادہ مضبو ہمارے پیغمبر کی مدل اور ڈیٹا اضافہ کی تصدیق کرنے کے لئے، ہم نے WMT 2017 APE کا کام سے پہچان رکھا ہے انگلیسی-جرمن ڈیٹ سٹ کے ساتھ ہماری طریقہ کی تحقیق کی۔ آزمائش کا نتیجہ دکھاتا ہے کہ ہماری سیسٹم بہت اضافہ ہے اور دوسری بنسٹلین کو کامل کرتا ہے WMT 2020 ٹیسٹ ڈیٹ سٹ کے آخرین نتائج دکھاتے ہیں کہ ہماری تحویل +5.56 BLEU اور -4.57 TER کو رسمی MT بنسٹ لین کے معاملہ میں پہنچ سکتی ہے.', 'mt': 'The goal of Automatic Post-Editing (APE) is basically to examine the automatic methods for correcting translation errors generated by an unknown machine translation (MT) system.  Dan id-dokument jiddeskrivi s-sottomissjonijiet ta’ Alibaba lill-APE Shared Task tad-WMT 2020 għall-par lingwistiku Ingliż-Ġermaniż. We design a two-stage training pipeline.  L-ewwel nett, mudell ta’ lingwa traslingwi bħal BERT huwa mħarreġ minn qabel billi b’mod każwali jaħbi sentenzi fil-mira waħedhom. Imbagħad, dekoder newrali addizzjonali fuq in-naħa ta’ fuq tal-mudell imħarreġ minn qabel huwa aġġustat b’mod konġunt għall-kompitu APE. We also apply an imitation learning strategy to augment a reasonable amount of pseudo APE training data, potentially preventing the model to overfit on the limited real training data and boosting the performance on held-out data.  To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task.  The experiment results demonstrate that our system significantly outperforms all other baselines and achieves the state-of-the-art performance.  Ir-riżultati finali dwar is-sett tad-dejta tat-test WMT 2020 juru li s-sottomissjoni tagħna tista’ tikseb +5.56 BLEU u -4.57 TER fir-rigward tal-linja bażi uffiċjali tal-MT.', 'sr': 'Цел автоматическог пострединга (APE) је у основном да прегледа автоматичне методе за исправљавање грешка превода произведен непознатим системом превода машина (MT). Ovaj papir opisuje podatke Alibaba na delovani zadatak WMT 2020 APE za parove engleskog-njemačkog jezika. Mi dizajniramo cijev za trening na dve faze. Prvo, kao BERT-ov preko jezika model je predobučen slučajno maskiranjem ciljnih rečenica. Onda je dodatni neuralni dekoder na vrhu predobučenog modela zajedno ispravljen za zadatak APE-a. Takođe primjenjujemo strategiju imitacije za povećanje razumne količine podataka o obuci pseudo APE-a, potencijalno sprečavajući model da se preuklapa na ograničene realne podatke o obuci i povećanje učinka o održanim podacima. Da bismo potvrdili naš predloženi model i povećanje podataka, pregledali smo naš pristup poznatim kriterijom engleskog-nemačkog podataka iz zadatka WMT-a APE 2017. Rezultati eksperimenta pokazuju da naš sistem značajno iznosi sve ostale osnovne linije i postiže stanje umjetnosti. Posljednji rezultati na setu podataka WMT 2020 pokazuju da naša predstava može postići +5,56 BLEU i -4,57 TER u odnosu na zvaničnu početnu liniju MT-a.', 'si': 'ස්වයංක්\u200dරිය පොස් සංපාදනය (APE) ගේ අරමුණය ස්වයංක්\u200dරිය විදියට පරීක්ෂා කරන්න ස්වයංක්\u200dරිය විදියට පරීක්ෂා කරන්න. මේ පත්තුව ඇලිබාබාගේ පිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපි අපි ස්ටේජ් දෙකක් පුහුණු පායිප්ලින් එකක් සැකසුම් කරනවා. මුලින්ම, BERT- වගේ ක්\u200dරිස් භාෂාවික භාෂාවික මොඩේලයක් ප්\u200dරධානය කරලා තියෙන්නේ මුලින්ම ඉලක්කු වච ඊට පස්සේ, ප්\u200dරීක්ෂණා කරලා තියෙන්න පුළුවන් මොඩල් එක්ක පුළුවන් න්\u200dයූරාල් ඩිකොඩර් එකක් APE වැඩකට සම්බ අපි සමහරවිට ප්\u200dරයෝජනයක් ඉගෙන ගන්න ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරන්න, ප්\u200dරයෝ අපේ ප්\u200dරාර්ථනා කරපු මොඩල් සහ දත්ත විශාලනය සහතිකරගන්න, අපි දන්නවා අපේ ප්\u200dරාර්ථනාව සමග ඉංග්\u200dරීසි-ජර්මන් දත්ත සෙට්  පරීක්ෂණයේ ප්\u200dරතිචාර පද්ධතිය පෙන්වන්නේ අපේ පද්ධතිය ගොඩක් විශේෂයෙන් අනිත් පද්ධතිය ප්\u200dරතිචාර කරනවා ක WMT 2020යි පරීක්ෂණ දත්ත සූදානයේ අන්තිම ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරත', 'vi': 'Mục đích của Automatic Post-Editing (APE) là cơ bản kiểm tra các phương pháp tự động sửa chữa lỗi dịch do hệ thống dịch chuyển không rõ (MTV). Tờ giấy này mô tả những kiến nghị của Alibaba với giải pháp WRT 2020 APE Chia s ẻ Nhiệm vụ cho cặp ngôn ngữ Anh-Đức. Chúng tôi thiết kế một đường ống huấn luyện hai cấp. Thứ nhất, một mô hình ngôn ngữ chữ vượt trường thiếu sót giống BERT được dạy trước bởi việc che dấu các câu đích. Sau đó, một bộ giải mã thần kinh bổ sung trên đỉnh của mô hình được huấn luyện được thiết lập cẩn thận cho nhiệm vụ APA. Chúng tôi cũng áp dụng một chiến lược nghiên cứu mô phỏng để tăng lượng thông tin giáo dục kiểu giả, có khả năng ngăn cản mô hình cho quá tải dữ liệu giáo dục thực tế giới hạn và tăng hiệu suất trên dữ liệu bị bỏ rơi. Để xác minh mô hình và gia tăng dữ liệu đã đề xuất, chúng tôi kiểm tra phương pháp của chúng tôi với một tập tin nổi tiếng Anh-Đức so sánh từ nhiệm vụ WRT bây giờ. Các kết quả thử nghiệm cho thấy hệ thống của chúng ta vượt trội hơn tất cả các nền tảng khác và đạt được trình độ hiện đại. Kết quả cuối cùng của tập tin thử nghiệm WRT 2020 đã cho thấy chúng tôi có thể cung cấp chúng tôi với liên kết đường cơ bản MTV chính thức.', 'uz': "@ info: whatsthis Bu qogʻoz Alibabaning WMT 2020 APE'ning bir ingliz-Olmon tili qo'lingi vazifani o'zgartirish tilini anglatadi. Biz ikki darajada o'rganish pipelinini dizayn qilamiz. Birinchi, BERT-ga oʻxshash tillar modeli bir necha tildan foydalanadi Keyin, oldingi taʼminlovchi modelning yuqorida qoʻshimcha neyron kodlash APE vazifasini birlashtirish mumkin. Biz o'rganish strategiyani qo'llashimiz mumkin, APE ta'lim maʼlumotini qoʻshish uchun juda haqiqiqiy ta'lim maʼlumotni qo'shish uchun modelni ko'paytirish mumkin, bu shaklga taʼminlovchi haqiqiqiy maʼlumot haqida o'zgarishni qo'shish mumkin. Taʼminlovchi modelimizni va maʼlumot yozishni tasdiqlash uchun biz yordamchimizni WMT 2017 APE vazifani yordamida yaxshi ko'rinadigan inglizcha- Olmoncha maʼlumotlar tarkibini tekshirib ko'raymiz. Tasavvur natijalari, bizning tizimmiz hamma boshqa asboblarni bajaradi va barcha sanat jarayonlarini bajaradi. @ info: status", 'bg': 'Целта на автоматичното пост-редактиране (АПЕ) е основно да се изследват автоматичните методи за коригиране на грешките в превода, генерирани от неизвестна система за машинен превод (МТ). Настоящата статия описва предложенията на Алиба към споделената задача на АПЕ 2020 за англо-германската езикова двойка. Проектираме двуетапен тренировъчен тръбопровод. Първо, междуезичен езиков модел е предварително обучен чрез случайно маскиране на целеви изречения. След това допълнителен невронен декодер на върха на предварително обучения модел се усъвършенства съвместно за задачата АПЕ. Също така прилагаме стратегия за имитация на обучение, за да увеличим разумно количество псевдо данни за обучение, потенциално предотвратявайки пренасочването на модела върху ограничените реални данни за обучение и повишавайки ефективността на задържаните данни. За да проверим предложения модел и увеличаване на данните, ние изследваме нашия подход с добре познатия англо-немски benchmarkiнг набор от данни от задачата АПЕ 2017. Резултатите от експеримента показват, че нашата система значително надминава всички останали базови линии и постига най-съвременните резултати. Окончателните резултати от тестовия набор от данни показват, че нашето представяне може да постигне +5.56 и -4.57 по отношение на официалната база МТ.', 'nl': "Het doel van Automatic Post-Editing (APE) is om de automatische methoden voor het corrigeren van vertaalfouten gegenereerd door een onbekend machine translation (MT) systeem te onderzoeken. Dit artikel beschrijft Alibaba's inzendingen aan de WMT 2020 APE Shared Task voor het Engels-Duitse taalpaar. We ontwerpen een tweetraps trainingspijplijn. Ten eerste wordt een BERT-achtig cross-lingual taalmodel vooraf getraind door willekeurig alleen doelzinnen te maskeren. Vervolgens wordt een extra neurale decoder bovenop het voorgetrainde model gezamenlijk verfijnd voor de APE-taak. We passen ook een imitatieleerstrategie toe om een redelijke hoeveelheid pseudo-APE-trainingsgegevens te vergroten, waardoor het model mogelijk niet overfitt op de beperkte reële trainingsgegevens en de prestaties op uitgestelde data verbetert. Om ons voorgestelde model en data augmentatie te verifiëren, onderzoeken we onze aanpak met de bekende benchmarking Engels-Duitse dataset uit de WMT 2017 APE taak. De experimentresultaten tonen aan dat ons systeem aanzienlijk beter presteert dan alle andere baselines en de state-of-the-art prestaties bereikt. De eindresultaten van de WMT 2020 testdataset laten zien dat onze inzending +5.56 BLEU en -4.57 TER kan bereiken met betrekking tot de officiële MT baseline.", 'hr': 'Cilj automatskog posledišnjeg uredjenja (APE) je u osnovi pregledati automatske metode za ispravljanje grešaka prevoda koji su stvorili nepoznat sustav prevoda stroja (MT). Ovaj papir opisuje podatke Alibaba na podatke zajedničkog zadatka WMT 2020 APE-a za parove engleskog-njemačkog jezika. Mi dizajniramo cijev za trening na dvije faze. Prvo, preko jezičkog model a sličnog BERT-a predobučen je slučajno maskiranjem ciljnih rečenica. Onda je dodatni neuralni dekoder na vrhu predobučenog modela zajedno ispravljen za zadatak APE-a. Također primjenjujemo strategiju učenja imitacije za povećanje razumne količine podataka o obuci pseudo APE-a, potencijalno sprječavajući model da se uklapa na ograničene realne podatke o obuci i povećanje učinka o održanim podacima. Da bismo potvrdili naš predloženi model i povećanje podataka, pregledali smo naš pristup poznatim kriterijom podataka engleskog-njemačkog podataka iz zadatka WMT-a APE 2017. Rezultati eksperimenta pokazuju da naš sustav značajno iznosi sve ostale osnovne linije i postigne stanje umjetnosti. Posljednji rezultati na kompletu podataka WMT 2020 pokazuju da naša podataka može postići +5,56 BLEU i -4,57 TER u odnosu na službenu početnu liniju MT-a.', 'da': "Målet med automatisk efterredigering (APE) er grundlæggende at undersøge de automatiske metoder til at korrigere oversættelsesfejl genereret af et ukendt maskinoversættelsessystem (MT). Dette dokument beskriver Alibaba's indlæg til WMT 2020 APE Shared Task for det engelsk-tyske sprogpar. Vi designer en to-trins træning pipeline. For det første er en BERT-lignende tværsproget sprogmodel forudtrænet ved tilfældigt at maskere målsætninger alene. Derefter finjusteres en ekstra neural dekoder på toppen af den prætrænede model i fællesskab til APE-opgaven. Vi anvender også en efterligningsstrategi for at øge en rimelig mængde pseudo APE-træningsdata, hvilket potentielt forhindrer modellen i at overpasse på de begrænsede reelle træningsdata og øge ydeevnen på udestående data. For at verificere vores foreslåede model og dataudvidelse undersøger vi vores tilgang med det velkendte benchmarking engelsk-tyske datasæt fra WMT 2017 APE opgaven. Eksperimentets resultater viser, at vores system overgår alle andre basislinjer betydeligt og opnår den nyeste ydeevne. De endelige resultater på WMT 2020 testdatasættet viser, at vores indsendelse kan opnå +5,56 BLEU og -4,57 TER i forhold til den officielle MT baseline.", 'id': 'Tujuan dari Automatic Post-Editing (APE) adalah pada dasarnya untuk memeriksa metode otomatis untuk memperbaiki kesalahan terjemahan yang dibuat oleh sistem terjemahan mesin (MT) yang tidak diketahui. Kertas ini menjelaskan pengiriman Alibaba ke WMT 2020 APE Shared Task untuk pasangan bahasa Inggris-Jerman. We design a two-stage training pipeline.  Pertama, model bahasa saling bahasa seperti BERT dilatih secara acak dengan menyembunyikan kalimat sasaran sendirian. Kemudian, dekoder saraf tambahan di atas model yang terlatih terlatih bersama-sama disesuaikan untuk tugas APE. Kami juga menerapkan strategi belajar imitasi untuk meningkatkan jumlah data pelatihan pseudo APE yang masuk akal, berpotensi mencegah model untuk melebihi data pelatihan nyata yang terbatas dan meningkatkan prestasi pada data yang tersembunyi. Untuk mengkonfirmasi model dan peningkatan data kami, kami memeriksa pendekatan kami dengan benchmarking Inggris-Jerman dataset dari tugas APE WMT 2017. Hasil eksperimen menunjukkan bahwa sistem kita jauh melebihi semua garis dasar lainnya dan mencapai prestasi terbaik. Hasil akhir dari set data ujian WMT 2020 menunjukkan bahwa pengiriman kita dapat mencapai +5,56 BLEU dan -4,57 TER dalam hal awal MT resmi.', 'de': "Das Ziel von Automatic Post-Editing (APE) besteht im Wesentlichen darin, die automatischen Methoden zur Korrektur von Übersetzungsfehlern zu untersuchen, die von einem unbekannten maschinellen Übersetzungssystem (MT) erzeugt werden. Dieses Papier beschreibt Alibaba's Einreichungen zur WMT 2020 APE Shared Task für das englisch-deutsche Sprachpaar. Wir entwerfen eine zweistufige Trainingspipeline. Zunächst wird ein BERT-ähnliches crosslinguales Sprachmodell durch zufälliges Maskieren von Zielsätzen trainiert. Anschließend wird ein zusätzlicher neuronaler Decoder oben auf dem vortrainierten Modell gemeinsam auf die APE-Aufgabe abgestimmt. Wir wenden auch eine Imitation-Learning-Strategie an, um eine angemessene Menge an Pseudo-APE-Trainingsdaten zu erweitern, wodurch möglicherweise verhindert wird, dass das Modell auf die begrenzten realen Trainingsdaten übertrifft und die Leistung von abgehaltenen Daten erhöht wird. Zur Verifizierung unseres vorgeschlagenen Modells und der Datenaugmentation untersuchen wir unseren Ansatz mit dem bekannten englisch-deutschen Benchmarking-Datensatz aus dem WMT 2017 APE Task. Die Versuchsergebnisse zeigen, dass unser System alle anderen Baselines deutlich übertrifft und die State-of-the-Art Performance erreicht. Die endgültigen Ergebnisse des WMT 2020 Testdatensatzes zeigen, dass unsere Einreichung +5.56 BLEU und -4.57 TER in Bezug auf die offizielle MT Baseline erreichen kann.", 'fa': 'هدف تغییر دادن بعد از ویرایش خودکار (APE) اساسا روش\u200cهای خودکار برای اصلاح خطاهای ترجمه توسط سیستم ترجمه\u200cهای ماشین ناشناخته (MT) است. این کاغذ تحویل آلیبابا را برای جفت زبان انگلیسی و آلمانی به WMT 2020 مشخص می\u200cکند. ما یک لوله تمرین دو مرحله طراحی می کنیم. اول، یک مدل زبان متفاوتی مانند BERT، با ماسک کردن جمله\u200cهای هدف تنها پیش آموزش می\u200cشود. سپس، یک dekoder عصبی اضافه روی بالای مدل پیش آموزش آموزش برای کار APE با هم درست شده است. ما همچنین استراتژی یادگیری شبیه\u200cسازی را برای افزایش اندازه\u200cای از داده\u200cهای آموزشی pseudo APE استفاده می\u200cکنیم، احتمالاً جلوگیری از مدل برای افزایش داده\u200cهای آموزشی واقعی محدود و افزایش عملکرد داده\u200cهای خارج شده است. برای تصدیق کردن مدل و افزایش داده\u200cهای پیشنهاد ما، روش\u200cهایمان را با مجموعه داده\u200cهای انگلیسی-آلمانی شناخته شده از وظیفه WMT ۲۰۰۷ تحقیق می\u200cکنیم. نتیجه آزمایش نشان می دهد که سیستم ما به طور معنی تمام خطوط پایین\u200cهای دیگر را انجام می\u200cدهد و به انجام وضعیت هنر رسیده است. نتیجه نهایی در مجموعه داده\u200cهای آزمایش WMT 2020 نشان می\u200cدهد که تسلیم ما می\u200cتواند +5.56 BLEU و -4.57 TER را درباره خط پایین رسمی MT به دست آورد.', 'ko': '자동 번역 후 편집(APE)의 목표는 기본적으로 알 수 없는 기계 번역(MT) 시스템에서 발생하는 번역 오류를 검사하고 바로잡는 자동 방법이다.본고는 알리바바가 WMT 2020 APE 공유 임무에 제출한 영어-독일어 언어 쌍을 설명한다.우리는 두 단계의 교육 파이프라인을 설계했다.우선 목표 문장을 단독으로 무작위로 엄폐함으로써 버트와 유사한 크로스 언어 모델을 미리 훈련시킨다.그리고 APE 임무에 대해 미리 훈련된 모델에 하나의 신경 디코더를 더해 연합 마이크로스피커를 한다.우리는 또한 모방 학습 전략을 이용하여 합리적인 수량의 위조 APE 훈련 데이터를 증가시켜 모델이 유한한 실제 훈련 데이터에서 과도하게 합성되는 것을 잠재적으로 방지하고 데이터 보존에 있어서의 성능을 향상시킨다.우리가 제시한 모델과 데이터 확충을 검증하기 위해 우리는 WMT 2017 APE 임무에서 유명한 기준 영어-독일어 데이터 집합을 사용하여 우리의 방법을 검증했다.실험 결과에 의하면 우리의 시스템은 모든 다른 기선보다 현저히 우수하고 가장 선진적인 성능에 이르렀다고 한다.WMT 2020 테스트 데이터 세트의 최종 결과에 따르면 우리가 제출한 데이터는 공식 MT 베이스라인에 비해 +5.56 BLEU와 -4.57 TER에 도달할 수 있습니다.', 'sw': 'Lengo la kuhariri baada ya kujitegemea (APE) ni kutafiti njia za kujitegemea kwa ajili ya kurekebisha makosa ya tafsiri yaliyotengenezwa na mfumo wa kutafsiri mashine (MT). Gazeti hili linaelezea ujumbe wa Alibaba wa WMT 2020 APE ulioshirikisha kazi kwa ajili ya wawili wa lugha ya Kiingereza na Kijerumani. Tunaweza kutengeneza pipeline ya mafunzo ya jukwaa mbili. Kwanza, muundo wa lugha inayofanana na BERT unafundishwa kabla kwa kufungua hukumu za lengo pekee. Kisha, kuongezea upande wa ubongo wa upande wa modeli iliyoendelea awali hupandishwa vizuri kwa ajili ya kazi hiyo ya APE. Pia tunatumia mkakati wa kujifunza kwa uchimbaji ili kuongeza kiasi cha taarifa sahihi za mafunzo ya APE, kwa uwezekano wa kuzuia mtindo wa kuingia kwenye taarifa za mafunzo halisi na kukuza utendaji wa taarifa zilizowekwa. Ili kuthibitisha muundo wetu wa pendekezo na kuongezeka kwa takwimu, tunachunguza hatua yetu kwa kutumia taarifa za Uingereza-Ujerumani kutoka kazi ya WMT 2017 APE. The experiment results demonstrate that our system significantly outperforms all other baselines and achieves the state-of-the-art performance.  Matokeo ya mwisho kwenye takwimu za jaribio la WMT 2020 yanaonyesha kuwa ujumbe wetu unaweza kupata+5.56 BLEU na -4.57 TER kwa kuhusiana na msingi rasmi wa MT.', 'tr': "Otomatik Poz Editlemek (APE) sistemi tarapyndan döredilen terjime hatalaryny düzeltmek üçin mykdary. Bu kagyz Alibaba'yň WMT 2020 APE'a hökmünde beýleki zadyny iňlisçe-nemesçe dil çiftleri üçin paýlaşýar. Biz iki sahypa eğitim pipelini tasarlýarys. Ilkinji gezek, BERT ýaly çatlaş dil nusgasy täzeden bir maksady sözleri diňe maskarap öňünde bilinmediler. Sonra, öňündeki bilim öňündeki bir nöral dekoderi APE görevi üçin birlikte düzenlenmiş. Biz hem imitaýýat öwrenmek strategiýasyny pseudo APE öwrenmek maglumatynyň akylly miktaryna üýtgetmek üçin ullanýarys, nusgasyny çykyş edilen hakyky öwrenmek maglumatynyň üstine geçirmegi we çykyş edilen maglumatyny bejermek üçin göz öňünde duru Biziň teklip eden nusganymyzy we maglumatlarymyzy barlamak üçin WMT 2017 APE zadynyň bilinýi benchmarklary bilen gurnaldyk. Denediň netijesi biziň sistemamyzyň beýleki esasy çyzygyny çykarýar we sungatyň durumyny çykarýar. WMT 2020 test setiniň soňky netijeleri olaryň çykyşymyz +5.56 BLEU we -4.57 TER resmi MT baseline barada ýetip biler diýip görkezilýär.", 'af': "Die doel van Outomatiese Post- Redigering (APE) is basies na ondersoek die outomatiese metodes vir korrigeer vertaling foute genereer deur 'n onbekende masjien vertaling (MT) stelsel. Hierdie papier beskrywe Alibaba se onderskrifte aan die WMT 2020 APE deelde taak vir die Engelse-Duitse taal paar. Ons ontwerp 'n twee stadige oefening pyplyn. Eerste is 'n BERT- soos kruistale taal model voor- opgelei deur willekeurig maskering van teikens alleen. Dan is 'n addisionele neuraldekoder op die bo van die voorafgeleerde model saamstig fyn-tuned vir die APE taak. Ons het ook 'n imitasie leer strategie aanwend om 'n redelike hoeveelheid pseudo APE onderwerking data te vergroot, potensieel voorkom die model om oorvloedig te pas op die beperkte reël onderwerking data en die prestasie op gehou-uitgevoerde data te vergroot. Om ons voorgestelde model en data vergroot te bevestig, ons ondersoek ons toegang met die bekende benchmarking van Engels-Duits datastel van die WMT 2017 APE taak. Die eksperimentresultate bevestig dat ons stelsel betekeurig uitvoer al die ander basisline en bereik die staat van die kunsten prestasie. Die eindelike resultate op die WMT 2020 toets datastel wys dat ons onderwerp +5.56 BLEU en -4.57 TER kan bereik met betrekking tot die offisiele MT baseline.", 'am': 'ቦታ ይህ ገጽ አሌባባ ለWMT 2020 APE ለኢንግሊዝኛ-ጀርመን ቋንቋ ሁኔታ የተሰራጨውን ስራ ይናገራል፡፡ የሁለት ደረጃዎች ተማሪ ኪፕላን እናሳውቃለን ። በመጀመሪያ፣ BERT-ምሳሌ የቋንቋ ቋንቋ ሞዴል ለብቻው የተማረከ ነው፡፡ ከዚህም በኋላ፣ በፊት ተማሪ ሞዴል ላይ ላይ የሚጨመር የኔural ቀድሚያ ለAPE ስራ የተጠቃሚ ጥሩ ነው፡፡ እና የአፍሪካ ትምህርት ትምህርት ስርዓት እናስቀምጣለን፡፡ To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task.  ፈተናው ውጤቶች ሲሞክሩ የሥርዓታችንን አካባቢ ሁሉ እንዲያሳየው እና የዐርድ ሥርዓት ግንኙነትን እንዲደርስ ያሳያል፡፡ በWMT 2020 ፈተና ዳታተር ላይ የመጨረሻው ውጤቶች የልግስታችንን አካሄድ +5.56 BLEU እና -4.57 ቴርር በአሥልጣኑ MT መቀመጫዎች ላይ እንዲያገኝ ያሳያል፡፡', 'az': "Avtomatik Post-Editing (APE) məqsədi, bilinmədən maşın çeviri sistemi (MT) ilə yaratdığı çeviri xətalarını düzəltmək üçün avtomatik metodları incidirməkdir. Bu kağıt Alibaba'nın WMT 2020 APE dil çiftərinin paylaşılmış iş işini tanımar. Biz iki səbəb təhsil boru təyin edirik. İlk dəfə, BERT kimi çox dil modeli təhsil edilən məqsəd cümlələrini yalnız gizlətməklə təhsil edilir. Sonra, əvvəlcə təhsil edilmiş modelinin üstündə bir nöral dekoderi APE işləri üçün birlikdə təmizlənir. Biz də müəyyən bir pseudo APE təhsil məlumatlarını artırmaq üçün imitasyon öyrənmə stratejisini uygulayıq, modeli həmin həqiqət təhsil məlumatlarına uyğunlaşdırmaq və müəyyən edilmiş məlumatların performansını artırmaq üçün mümkün olaraq maneçilik edirik. Bizim təbliğ etdiyimiz modellərimizi və veri artırmağımızı təsdiqləmək üçün, WMT 2017 APE işindən tanınmış benchmarking quruğumuzu təsdiqləyirik. Həqiqətən, eksperimentin sonuçları sistemimizin bütün baz çətinliklərdən çox üstün olduğunu göstərir və sanat performansını başa çatdırır. WMT 2020 sınama verilənlərin sonuncu nəticələri bizim təbliğ etməyimiz +5.56 BLEU və -4.57 TER olaraq resmi MT səviyyəsinə görə başa düşə bilər.", 'bn': 'স্বয়ংক্রিয় পোস্ট-সম্পাদক (APE) এর লক্ষ্য হচ্ছে একটি অজানা মেশিন অনুবাদ ব্যবস্থা (MT) সিস্টেমের দ্বারা তৈরি করা ভুল সংশোধনের জন্য স্ এই পত্রিকাটি আলিবাবার উইএমটি ২০২০ এপি শেয়ার করেছেন ইংরেজী জার্মান ভাষার জোড়ার জন্য। আমরা একটা দুই স্টেজ প্রশিক্ষণ পাইপেলাইন ডিজাইন করি। প্রথমত, বিরেট-এর মতো একটি বিভাষার ভাষার মডেল শুধুমাত্র টার্গেটের শাস্তি মুখোশ করার পূর্ব প্রশিক্ষণ প্রদান করা হয়। তারপর, পূর্ব প্রশিক্ষিত মডেলের উপরের আরো নিউরেল ডেকোডার এপিই কাজের জন্য যুক্ত ভালোভাবে সংযুক্ত। এছাড়াও আমরা একটি পরিমাণ শিক্ষা কৌশলও প্রয়োগ করি যাতে প্রায়শই এপিই প্রশিক্ষণের তথ্য যুক্তি বৃদ্ধি করতে পারি, সম্ভবত মোডেলের সীমিত প্রশিক্ষণের তথ্যে পার আমাদের প্রস্তাবিত মডেল এবং ডাটা যোগাযোগের জন্য আমরা আমাদের পদক্ষেপ পরীক্ষা করি উইএমটি ২০১৭ এপিই কাজ থেকে পরিচিত ইংরেজী জার্মান ড পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের সিস্টেম গুরুত্বপূর্ণ ভিত্তিক ভাবে অন্যান্য সব বেসারেলাইন প্রদর্শন করে এবং শিল্পের র উইএমটি ২০২০ টেস্ট ডেটাসেটের চূড়ান্ত ফলাফল দেখা যাচ্ছে যে আমাদের প্রতিষ্ঠান ৫.', 'sq': "Qëllimi i Automatic Post-Editing (APE) është në thelb të shqyrtojë metodat automatike për korrektimin e gabimeve të përkthimit të gjeneruar nga një sistem i panjohur përkthimi automatik (MT). This paper describes Alibaba's submissions to the WMT 2020 APE Shared Task for the English-German language pair.  Ne dizajnojmë një tubacion treinimi në dy faza. Së pari, një model gjuhësh ndërgjuhësore i ngjashëm me BERT është i stërvitur përpara duke maskuar rastësisht vetëm fjalët e objektivit. Pastaj, një dekoder nervor shtesë në majë të modelit të paratrajnuar është rregulluar së bashku për detyrën APE. Ne gjithashtu aplikojmë një strategji imitimi të mësimit për të rritur një sasi të arsyeshme të të dhënave të stërvitjes pseudo APE, duke parandaluar potencialisht modelin për të mbipërshtatur në të dhënat e kufizuara reale të stërvitjes dhe për të rritur performancën në të dhënat e mbajtura. To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task.  Rezultatet e eksperimentit demonstrojnë se sistemi ynë tejkalon në mënyrë të konsiderueshme të gjitha linjat bazë të tjera dhe arrin performancën më të lartë. Rezultatet përfundimtare në grupin e të dhënave të testit WMT 2020 tregojnë se paraqitja jonë mund të arrijë +5.56 BLEU dhe -4.57 TER lidhur me bazën zyrtare të MT.", 'cs': 'Cílem automatického post-editování (APE) je v zásadě zkoumat automatické metody opravy chyb překladu generované neznámým strojovým překladem (MT). Tento článek popisuje příspěvky společnosti Alibaba ke sdílenému úkolu WMT 2020 APE pro anglicko-německý jazykový pár. Navrhujeme dvoustupňový tréninkový plán. Za prvé, model křížového jazyka podobný BERT je předem trénován náhodným maskováním cílových vět samotných. Následně je další neuronový dekodér na horní části předtrénovaného modelu společně vyladěn pro úlohu APE. Používáme také strategii imitace učení, abychom rozšířili přiměřené množství pseudo APE tréninkových dat, potenciálně zabránili tomu, aby model překročil omezených reálných tréninkových dat a zvýšili výkon zadržených dat. Pro ověření navrženého modelu a rozšíření dat zkoumáme náš přístup pomocí známého benchmarkového anglicko-německého datového souboru z úlohy WMT 2017 APE. Výsledky experimentů ukazují, že náš systém výrazně překonává všechny ostatní základní linie a dosahuje nejmodernějšího výkonu. Konečné výsledky testovacích dat WMT 2020 ukazují, že naše podání může dosáhnout +5.56 BLEU a -4.57 TER s ohledem na oficiální MT základní hodnotu.', 'hy': 'Ավտոմատիկ հետխմբագրման (APE) նպատակն է հիմնականում ուսումնասիրել ավտոմատիկ մեթոդները թարգմանման սխալների ուղղությամբ, որոնք ստեղծվել են անհայտ մեքենայի թարգմանման (MT) համակարգով: Այս հոդվածը նկարագրում է Ալիբայի ներկայացումները Անգլերեն-գերմաներեն երկու անգլերեն համագործակցած APE 2020 թվականին: Մենք նախագծում ենք երկու փուլում սովորեցման խողովակաշար: First, a BERT-like cross-lingual language model is pre-trained by randomly masking target sentences alone.  Այնուհետև նախապատրաստված մոդելի վերևում ևս մեկ նյարդային դեկոդեր միասին կազմակերպված է APE-ի համար: Մենք նաև կիրառում ենք կրկնօրինակման սովորելու ռազմավարություն, որպեսզի բարձրացնենք կեղծ APE-ի ուսումնասիրության տվյալները, պոտենցիալ կանխելով մոդելը համապատասխանել սահմանափակ իրական ուսումնասիրության տվյալների վրա և բարձրացնել պահ Որպեսզի ստուգենք մեր առաջարկած մոդելը և տվյալների աճը, մենք ուսումնասիրում ենք մեր մոտեցումը հայտնի անգլերեն-գերմանացի տվյալների համակարգի վերաբերյալ 2017 թվականի ԱՄԹ-ի APE խնդիրից: Փորձարկումների արդյունքները ցույց են տալիս, որ մեր համակարգը նշանակալիորեն գերազանցում է բոլոր այլ հիմնական գծերը և հասնում է ամենաբարձր արդյունքներին: Վերջնական արդյունքները ԱՄԹ 2020-ի փորձարկումների տվյալների համակարգում ցույց են տալիս, որ մեր ներկայացումը կարող է հասնել +5.56 ԲԼԵՎ և -4.57 ԹԵՎ-ի վերաբերյալ պաշտոնական ՄԹ-ի հիմքի:', 'fi': 'Automaattisen jälkimuokkauksen (APE) tavoitteena on pohjimmiltaan tutkia automaattisia menetelmiä tuntemattoman konekäännösjärjestelmän (MT) aiheuttamien käännösvirheiden korjaamiseksi. Tässä artikkelissa kuvataan Alibaban ehdotuksia WMT 2020 APE Shared Task -ohjelmaan englannin ja saksan kieliparille. Suunnittelemme kaksivaiheisen koulutusputken. Ensinnäkin BERT-tyyppinen monikielinen kielimalli on esikoulutettu peittämällä satunnaisesti kohdelauseet yksin. Tämän jälkeen esikoulutetun mallin yläreunassa on ylimääräinen neurodekooderi, joka hienosäätää yhdessä APE-tehtävää varten. Sovellamme myös jäljitelmäoppimisstrategiaa lisätäksemme kohtuullisen määrän pseudo-APE-harjoitusdataa, estääksemme mallin ylikuormittumasta rajallisiin todellisiin harjoitustietoihin ja parantaaksemme suorituskykyä pitkillä harjoitustiedoilla. Vahvistaaksemme ehdotetun mallin ja datan lisäyksen tarkastelemme lähestymistapaamme WMT 2017 APE -tehtävän tunnetulla englannin-saksan benchmarking-aineistolla. Kokeiden tulokset osoittavat, että järjestelmämme suoriutuu merkittävästi kaikista muista lähtökohdista ja saavuttaa huipputason suorituskyvyn. WMT 2020 -testiaineiston lopulliset tulokset osoittavat, että julkaisumme voi saavuttaa +5,56 BLEU ja -4,57 TER viralliseen MT-lähtötasoon verrattuna.', 'bs': 'Cilj automatskog posledišnjeg redakcije (APE) je u osnovi pregledati automatske metode za korištenje grešaka prevođenja koji su stvorili nepoznat sistem prevođenja stroja (MT). Ovaj papir opisuje podatke Alibaba na delovani zadatak WMT 2020 APE za parove engleskog-njemačkog jezika. Mi dizajniramo cijev za trening dva faza. Prvo, preko jezičkog model a sličnog BERT-a predobučen je slučajno maskiranjem ciljnih rečenica. Onda je dodatni neuralni dekoder na vrhu predobučenog modela zajedno ispravljen za zadatak APE-a. Također primjenjujemo strategiju učenja imitacije za povećanje razumne količine podataka o obuci pseudo APE-a, potencijalno sprječavajući model da se uklapa na ograničene realne podatke o obuci i povećanje učinka o održanim podacima. Da bismo potvrdili naš predloženi model i povećanje podataka, pregledali smo naš pristup poznatim kriterijom Engleskog-Njemačkog seta podataka iz zadatka WMT-a APE 2017. Rezultati eksperimenta pokazuju da naš sistem značajno iznosi sve ostale osnovne linije i postigne stanje umjetnosti. Konačni rezultati na setu podataka WMT 2020 pokazuju da naša predstava može postići +5,56 BLEU i -4,57 TER u odnosu na zvaničnu početnu liniju MT-a.', 'ca': "L'objectiu de l'Automatic Post-Editing (APE) és bàsicament examinar els mètodes automàtics per corregir els errors de traducció generats per un sistema desconegut de traducció màquina (MT). Aquest article descriu les presentacions d'Alibaba al WMT 2020 APE Shared Task per al parell anglo-alemany. dissenyem un tub d'entrenament de dos etapes. En primer lloc, un model de llenguatge translingüístic semblant a BERT es pré-entrena mascant aleatoriament només les frases alvo. Després, un descodificador neural adicional a la part superior del model pré-entrenat es ajusta conjuntament a la tasca APE. També apliquem una estratègia d'aprenentatge de imitació per augmentar una quantitat raonable de dades d'entrenament pseudo APE, potencialment evitant que el model s'ajusti a les limitades dades reals d'entrenament i reforçant el rendiment de les dades retenues. Per verificar el nostre model proposat i l'augment de dades, examinem el nostre enfocament amb la coneguda comparació anglo-alemanya de la tasca APE WMT 2017. The experiment results demonstrate that our system significantly outperforms all other baselines and achieves the state-of-the-art performance.  The final results on the WMT 2020 test dataset show that our submission can achieve +5.56 BLEU and -4.57 TER with respect to the official MT baseline.", 'et': 'Automaatse järeltöötluse (APE) eesmärk on põhimõtteliselt uurida automaatseid meetodeid tundmatu masintõlke (MT) süsteemi tekitatud tõlkevigade parandamiseks. Käesolevas dokumendis kirjeldatakse Alibaba esitusi inglise-saksa keelepaari WMT 2020 APE jagatud ülesandele. Me projekteerime kaheastmelise koolitusjuhtme. Esiteks, BERT-sarnast keeleülest mudelit eelõpetatakse juhuslikult varjates sihtlauseid. Seejärel täpsustatakse APE ülesandeks ühiselt täiendav neurodekooder eelõpetatud mudeli peal. Samuti rakendame imitatsiooniõppe strateegiat, et suurendada mõistlikku hulka pseudo-APE treeninguandmeid, takistades potentsiaalselt mudeli liigset koormust piiratud tegelike treeninguandmetega ja suurendades tulemuslikkust väljajäetud andmetel. Pakutud mudeli ja andmete suurendamise kontrollimiseks uurime oma lähenemisviisi WMT 2017 APE ülesande tuntud inglise-saksa andmekogumi võrdlusanalüüsiga. Katsetulemused näitavad, et meie süsteem ületab oluliselt kõiki muid lähtejooni ja saavutab tipptasemel jõudluse. WMT 2020 katseandmete lõplikud tulemused näitavad, et meie esitatud tulemused võivad ametliku MT lähtetasemega võrreldes saavutada +5,56 BLEU ja -4,57 TER.', 'ha': "Jigon na shiryarwa na farat-editing (PAET) ne a kima domin jarraba shiryoyin ayuka farat ɗaya wa gyare-daidaita errors da aka ƙãga fassarar da na wata fassarar mashine da ba'a sani ba (MT). Wannan karatun describes Alibaba's Submitions to the WMT 2020 Apple Shared Takar for the English-Jarman language par. Tuna ƙayyade wani misalin na'ura biyu. Babban da, wata misalin harshen na BERT-kama na tsohon-lugha na yi amfani da shi gaba-tune ne da aka buɗe maganar zaren gaba ɗaya a ransoma. Sa'an nan, ana ƙara wata kodin neural da ke kan sama na shirin motsi na farko da aka yi wa shirin salon wa aikin EMET. Kayya, Munã amfani da kimar ta sanar da suriyako ko ko da yawan ma'anar mafarinta na Apple na daidaici, yana son ya kange misalin ya sami shi kan data masu tsari da gaskiyar kuma an a ƙara fasarin da aka samu. To, dõmin mu gaskata shirin ayukanmu da ƙaramakon data, sai mu jarraba hanyarmu da tsarin da aka sani wajen bangon Ingiriya-Jarman tsare daga aikin WMT 2017. Matarin jarrabai sun nuna cewa na'asarmu yana samar da duk bango na daban kuma yana isa ga halin-da-sanar. Ganda na ƙarshen matsala a danne ta WMT 2020 za'a nuna cewa ma'ananmu za ta ci+5.46 BLEU da -4.57 TR da kuma ma'anar MT basin.", 'sk': 'Cilj avtomatskega post-urejanja (APE) je v osnovi preučiti avtomatske metode za popravljanje napak pri prevajanju, ki jih povzroča sistem strojnega prevajanja (MT). V tem članku so opisani prispevki Alibabe k skupni nalogi WMT 2020 APE za angleško-nemški jezikovni par. Načrtujemo dvostopenjsko usposabljanje. Prvič, BERT-u podoben večjezični jezikovni model se predhodno usposablja tako, da se naključno prikrije ciljni stavki. Nato se dodaten nevronski dekoder na vrhu vnaprej usposobljenega modela skupaj natančno nastavi za nalogo APE. Uporabljamo tudi strategijo imitacijskega učenja za povečanje razumne količine psevdo APE podatkov o usposabljanju, s čimer lahko preprečimo, da bi model prekoračil omejene dejanske podatke o usposabljanju in povečujemo zmogljivost na podatkih, ki jih izvajamo. Za preverjanje našega predlaganega modela in povečanja podatkov preučimo naš pristop z znanim primerjalnim naborom angleško-nemških podatkov iz naloge WMT 2017 APE. Rezultati eksperimentov kažejo, da naš sistem znatno presega vse ostale osnovne linije in dosega najsodobnejše zmogljivosti. Končni rezultati testnih podatkov WMT 2020 kažejo, da lahko naša predložitev doseže +5,56 BLEU in -4,57 TER glede na uradno izhodišče MT.', 'jv': 'goal of Automatically Ngerti iki rambarang ngerasai Alibab kanggo ngerasai nggawe barang yang WWT 2020 ApE kanggo kelas Inggris-German. Awakdhéwé nggawe sistem sistem kuwi wis ramu. Nalika, sampeyan BERT-seneng kelas-pakan langgambar model kuwi wis mulasar tentang karo mulasar seneng galakno politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé éntuk sistem imitasi nggunakake sistem sing beraksi dadi psepseudhi, supoyo iso nggawe modèl kanggo ngerasakno data atuaman sing beraksi lan jewis ngerasakno dadi sing bakal terus nggawe gerakan. Ngawe Perintah-ingkang ngerasai model lan alam-ingkang data nyanggo ingkang sampeyan, awak dhéwé ngerasai layang kanggo ngerasai nggambar barang kanggo ngerasai dataset ingkang German-German sing gagal dhéwé gambar WWT-2011, ApE . Rejalaké sing berarti ning perintah sing bisalahan ning sistem dhéwé ngerasah barang kelas barang nggawe barang kotak dhéwé kuwi tindakan sing ngerasah barang kelas. Rejalaké sing berarti barêng dataset nggambar WêT 2020 kuwi nggawe geraksé awak dhéwé ngerasah +.', 'he': 'המטרה של העורר האטומטי לאחר העורר (APE) היא בעצם לבדוק את השיטות האוטומטיות לתיקון שגיאות התרגום שנוצרו על ידי מערכת התרגום מכונת לא ידועה (MT). העיתון הזה מתאר את ההעברות של אליבאבה למשימה המשותפת של WMT 2020 APE לזוג שפה אנגלית-גרמנית. אנחנו מעצבים צינור אימון בשתי שלבים. ראשית, דוגמנית שפת צלולת כמו BERT מאומנת מראש על ידי מסיכה אקראית משפטים מטרה בלבד. ואז, מפענח עצבי נוסף על גב המודל המאמן מראש מתאים משותף למשימה APE. אנחנו גם משתמשים באסטרטגיה ללמוד חיקוי כדי לגדל כמות סבירה של נתוני אימון אפ.פי.איי pseudo, פוטנציאלית למנוע את המודל להתאים יתר על נתוני אימון אמיתי מוגבל ולהגדיל את ההופעה על נתונים מחוסרים. To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task.  The experiment results demonstrate that our system significantly outperforms all other baselines and achieves the state-of-the-art performance.  התוצאות הסופיות על קבוצת הנתונים של WMT 2020 מראות שהשליחה שלנו יכולה להשיג +5.56 BLEU ו -4.57 TER בנוגע לבסיס MT רשמי.', 'bo': 'The goal of Automatic Post-Editing (APE) is basically to examine the automatic methods for correcting translation errors generated by an unknown machine translation (MT) system. ཤོག་བྱང་འདིས་ཨིན་ཇིའི་སྐད་ཆ་གཉིས་ཀྱི་དབྱེ་བ་དང་ཐོག་ལས་ Alibaba་ཡི་མཉམ་དུ་WMT 2020 APE་ལ་བཤད་ཀྱི་ཡོད་པ་རེད། ང་ཚོས་ཤོག་བྱེད་རྩོམ་འབྲེལ་གཉིས་ཀྱི་སྒྲིག་སྟངས་ཞིག་བྱེད་ཀྱི་ཡོད། དང་པོ་དེ། BERT-ལྟ་བུའི་སྐད་ཡིག དེ་ནས་སྔོན་གྱིས་མཐོང་སྣེ་མཐོང་བའི་དཔེ་གཞིར་གྱི་མགོ་རིམ་གཞན་ཞིག་ནི་APE ལས་ཀ་ལ་མཐུན་སྒྲིག་པ་རེད། ང་ཚོས་གནས་ཚུལ་གྱི་ཐབས་ལམ་ལུགས་སྤྲོད་ཀྱི་ཐབས་ལམ་ཞིག་གིས་ལན་གསལ་པོ་ཞིག་ཡོད་པ་ལས། To verify our proposed model and data augmentation, we examine our approach with the well-known benchmarking English-German dataset from the WMT 2017 APE task. གྲུབ་ཕྱོགས་གནད་སྡུད་དེ་ནི་ང་ཚོའི་མ་ལག་གི་གྲངས་གཙོ་རིམ་གཞན་མ་མང་ཕན་ཐོགས་ཏེ། The final results on the WMT 2020 test dataset show that our submission can achieve +5.56 BLEU and -4.57 TER with respect to the official MT baseline.'}
{'en': 'LIMSI @ WMT 2020', 'ar': 'افلام سكس، صور سكس، قصص سكس عربي، سكس محارم - صفحه 2020', 'es': 'LIMSI @WMT 2020', 'fr': 'LIMSI @WMT 2020', 'pt': 'LIMSI @ WMT 2020', 'ja': 'LIMSI @ WMT 2020', 'zh': 'LIMSI @ WMT 2020', 'hi': 'LIMSI @ WMT 2020', 'ru': 'LIMSI @ WMT 2020', 'ga': 'LIMSI @ WMT 2020', 'ka': 'LIMSI @ WMT 2020', 'el': 'LIMSI, WMT 2020', 'hu': 'LIMSI @ WMT 2020', 'kk': 'LIMSI @ WMT 2020', 'it': 'LIMSI @ WMT 2020', 'lt': 'LIMSI @ WMT 2020', 'mk': 'LIMSI @ WMT 2020', 'ms': 'LIMSI @ WMT 2020', 'no': 'LIMSI @ WMT 2020', 'mt': 'LIMSI @ WMT 2020', 'mn': 'LIMSI @ WMT 2020', 'ml': 'LIMSI@ WMT 2020', 'pl': 'LIMSI – WMT 2020', 'sr': 'LIMSI @ WMT 2020', 'ro': 'LIMSI @ WMT 2020', 'si': 'LIMSI @ WMT 2020Comment', 'so': 'LIMSI @WMT 2020', 'sv': 'LIMSI @ WMT 2020', 'ta': 'LIMSI@ WMT 2020', 'ur': 'LIMSI @ WMT 2020', 'uz': 'LIMSI@ WMT 2020', 'vi': 'LUSSI... WM 2020.', 'hr': 'LIMSI @ WMT 2020', 'da': 'LIMSI @ WMT 2020', 'bg': 'LIMSI @ WMT 2020', 'nl': 'LIMSI tot WMT 2020', 'id': 'LIMSI @ WMT 2020', 'de': 'LIMSI-WMT 2020', 'fa': 'LIMSI @ WMT 2020', 'ko': 'LIMSI@WMT 2020', 'sw': 'LIMSI @WMT 2020', 'tr': 'LIMSI @ WMT 2020', 'sq': 'LIMSI @ WMT 2020', 'af': 'LIMSI @ WMT 2020', 'am': 'LIMSI @WMT 2020', 'hy': 'LIMSI @ WMT 2020', 'az': 'LIMSI @ WMT 2020', 'bn': 'লাইমসি@উএমটি ২০২০', 'ca': 'LIMSI @ WMT 2020', 'bs': 'LIMSI @ WMT 2020', 'cs': 'LIMSI aWMT 2020', 'et': 'LIMSI @ WMT 2020', 'fi': 'LIMSI @ WMT 2020', 'sk': 'LIMSI @ WMT 2020', 'ha': 'LIMSI @ WMT 2020', 'he': 'LIMSI @ WMT 2020', 'jv': 'LISMI', 'bo': 'LIMSI @ WMT 2020'}
{'en': 'This paper describes LIMSI’s submissions to the translation shared tasks at WMT’20. This year we have focused our efforts on the biomedical translation task, developing a resource-heavy system for the translation of medical abstracts from English into French, using back-translated texts, terminological resources as well as multiple pre-processing pipelines, including pre-trained representations. Systems were also prepared for the robustness task for translating from English into German ; for this large-scale task we developed multi-domain, noise-robust, translation systems aim to handle the two test conditions : zero-shot and few-shot domain adaptation.', 'ar': "تصف هذه الورقة عمليات إرسال LIMSI إلى مهام الترجمة المشتركة في WMT'20. لقد ركزنا جهودنا هذا العام على مهمة الترجمة الطبية الحيوية ، وتطوير نظام كثيف الموارد لترجمة الملخصات الطبية من الإنجليزية إلى الفرنسية ، باستخدام نصوص مترجمة إلى الوراء ، ومصادر مصطلحات ، بالإضافة إلى خطوط أنابيب متعددة للمعالجة المسبقة ، بما في ذلك ما قبل تمثيلات مدربة. تم إعداد الأنظمة أيضًا لمهمة المتانة للترجمة من الإنجليزية إلى الألمانية ؛ من أجل هذه المهمة واسعة النطاق ، قمنا بتطوير أنظمة ترجمة متعددة المجالات وقوية الضوضاء تهدف إلى التعامل مع شرطي الاختبار: تكيف مجال اللقطة الصفرية وقليل اللقطات.", 'fr': "Cet article décrit les soumissions de LIMSI aux tâches partagées de traduction au WMT'20. Cette année, nous avons concentré nos efforts sur la tâche de traduction biomédicale, en développant un système gourmand en ressources pour la traduction de résumés médicaux de l'anglais vers le français, en utilisant des textes rétro-traduits, des ressources terminologiques ainsi que de multiples pipelines de prétraitement, y compris des représentations préformées. Des systèmes ont également été préparés pour la tâche de robustesse de la traduction de l'anglais vers l'allemand\xa0; pour cette tâche à grande échelle, nous avons développé des systèmes de traduction multidomaines, robustes au bruit, qui visent à gérer les deux conditions de test\xa0: adaptation de domaine zéro et de domaine à faible émission.", 'pt': "Este documento descreve as submissões da LIMSI para as tarefas compartilhadas de tradução no WMT'20. Este ano, concentramos nossos esforços na tarefa de tradução biomédica, desenvolvendo um sistema pesado de recursos para a tradução de resumos médicos do inglês para o francês, usando textos retrotraduzidos, recursos terminológicos e vários pipelines de pré-processamento, incluindo pré-tradução representações treinadas. Os sistemas também foram preparados para a tarefa de robustez de tradução do inglês para o alemão; para esta tarefa de larga escala, desenvolvemos sistemas de tradução multidomínio, robustos ao ruído, visando lidar com as duas condições de teste: adaptação de domínio zero-shot e poucos-shot.", 'es': "Este documento describe los envíos de LIMSI a las tareas compartidas de traducción en el WMT'20. Este año hemos centrado nuestros esfuerzos en la tarea de traducción biomédica, desarrollando un sistema que requiere muchos recursos para la traducción de resúmenes médicos del inglés al francés, utilizando textos retrotraducidos, recursos terminológicos y múltiples canales de procesamiento previo, incluidas representaciones previamente capacitadas. También se prepararon sistemas para la tarea de robustez de traducir del inglés al alemán; para esta tarea a gran escala, desarrollamos sistemas de traducción multidominio y resistentes al ruido que tienen como objetivo gestionar las dos condiciones de prueba: adaptación de dominio de tiro cero y adaptación de dominio de pocos disparos.", 'ja': "本稿では、WMT '20における翻訳共有タスクへのLIMSIの提出について説明する。今年は、生物医学的翻訳タスクに焦点を当て、英語からフランス語に医学的要約を翻訳するためのリソースが豊富なシステムを開発しました。翻訳されたテキスト、用語リソース、および事前にトレーニングされた表現を含む複数の前処理パイプラインを使用しています。英語からドイツ語に翻訳するための堅牢性タスクのためのシステムも準備されました。この大規模なタスクのために、私たちはマルチドメイン、ノイズロバスト、翻訳システムを開発し、ゼロショットと少数ショットのドメイン適応という2つのテスト条件に対処することを目指しました。", 'zh': "本文引LIMSI于WMT'20上向译共享其材。 今年重生物医学译,开一资源密集型系统,以施医学摘要从英语翻译成法语,用回译本,术语资源及数预处理管道,以备训练。 又为英语翻译成德语鲁棒性备系统。 其大务也,开多域、噪声鲁棒之转统,以处二试:零次、小次次之域。", 'hi': "यह पेपर WMT'20 में अनुवाद साझा कार्यों के लिए LIMSI की प्रस्तुतियों का वर्णन करता है। इस साल हमने बायोमेडिकल अनुवाद कार्य पर अपने प्रयासों पर ध्यान केंद्रित किया है, अंग्रेजी से फ्रेंच में चिकित्सा सार के अनुवाद के लिए एक संसाधन-भारी प्रणाली विकसित करना, बैक-अनूदित ग्रंथों, टर्मिनोलॉजिकल संसाधनों के साथ-साथ पूर्व-प्रशिक्षित प्रतिनिधित्व सहित कई पूर्व-प्रसंस्करण पाइपलाइनों का उपयोग करना। अंग्रेजी से जर्मन में अनुवाद करने के लिए मजबूती कार्य के लिए सिस्टम भी तैयार किए गए थे; इस बड़े पैमाने पर कार्य के लिए हमने बहु-डोमेन, शोर-मजबूत, अनुवाद प्रणालियों को विकसित किया है, जिसका उद्देश्य दो परीक्षण स्थितियों को संभालना है: शून्य-शॉट और कुछ-शॉट डोमेन अनुकूलन।", 'ru': "Этот документ описывает представления LIMSI к общим задачам перевода на WMT'20. В этом году мы сосредоточили наши усилия на задаче биомедицинского перевода, разрабатывая ресурсно-тяжелую систему для перевода медицинских рефератов с английского на французский, используя тексты с обратным переводом, терминологические ресурсы, а также несколько трубопроводов предварительной обработки, включая предварительно обученные представления. Системы также были подготовлены для задачи надежности для перевода с английского на немецкий язык; для этой масштабной задачи мы разработали многодоменные, шумостойкие, системы перевода, направленные на выполнение двух условий испытаний: адаптация домена с нулевым и малым выстрелом.", 'ga': "Déanann an páipéar seo cur síos ar aighneachtaí LIMSI maidir leis na tascanna comhroinnte aistriúcháin ag WMT'20. I mbliana dhíríomar ár n-iarrachtaí ar thasc an aistriúcháin bithleighis, ag forbairt córas a bhfuil acmhainní trom air chun achoimrí leighis a aistriú ó Bhéarla go Fraincis, ag úsáid téacsanna cúlaistrithe, acmhainní téarmaíochta chomh maith le píblínte réamhphróiseála iolracha, lena n-áirítear réamhphróiseáil. uiríll oilte. Ullmhaíodh córais freisin do thasc stóinsithe an aistriúcháin ó Bhéarla go Gearmáinis; don tasc mórscála seo d'fhorbraíomar córais aistriúcháin ilfhearainn, láidir torainn, a bhfuil sé d'aidhm acu an dá choinníoll tástála a láimhseáil: oiriúnú fearainn náid agus cúpla urchar.", 'hu': "Ez a tanulmány bemutatja a LIMSI beadványait a WMT'20 fordítási feladataihoz. Ebben az évben az orvostudományi fordítási feladatra összpontosítottuk erőfeszítéseinket, erőforrás-nehéz rendszert fejlesztettünk ki az orvosi absztraktok angolról franciára, visszafordított szövegeket, terminológiai forrásokat, valamint több előfeldolgozó csővezetéket, beleértve az előképzett reprezentációkat is. Az angol nyelvről németre történő fordítás robusztussági feladataira is előkészítették a rendszereket; Ehhez a nagyszabású feladathoz több domain, zajrobusztus fordítási rendszereket fejlesztettünk ki azzal a céllal, hogy kezeljük a két tesztfeltételt: zero-shot és kevés-shot domain adaptációt.", 'ka': "ამ დოკუმენტი აღწერა LIMSI-ს შეტყობინებების WMT'20-ში გასაგულისხმებისთვის გასაგულისხმებისთვის. ამ წლის ჩვენ ვაკეთებდით ჩვენი ძალადობები ბიომედიციო თავისუფალური თავისუფალური სარგებლად, რესურსების ძალიან ძალიან სისტემის განვითარება მედიციო აბსტრაკტების ინგლისურად ფრანგულად, ტერმინოლოგიური სისტემები ასევე იყო წარმოდგენებული სისტემებისთვის, რომელიც ინგლისოდან გერმანურად გადაწყენება; ამ დიდი დავალებისთვის, რომელიც ჩვენ განვითარებეთ მრავალეთ დიომინი, სიტყვა-ძალიან ძალიან, განვითარების სისტემის მისამართება ორი ტესტის შესახებ: ნულ-სტარტი და", 'el': "Η παρούσα εργασία περιγράφει τις υποβολές του LIMSI στα κοινά μεταφραστικά καθήκοντα στο WMT'20. Φέτος εστιάσαμε τις προσπάθειές μας στο έργο της βιοϊατρικής μετάφρασης, αναπτύσσοντας ένα πλούσιο σύστημα για τη μετάφραση ιατρικών αφηρημάτων από τα αγγλικά στα γαλλικά, χρησιμοποιώντας μεταγλωττιστικά κείμενα, ορολογικούς πόρους καθώς και πολλαπλούς αγωγούς προεπεξεργασίας, συμπεριλαμβανομένων των προ-εκπαιδευμένων αναπαραστάσεων. Προετοιμάστηκαν επίσης συστήματα για την εργασία ανθεκτικότητας για τη μετάφραση από τα αγγλικά στα γερμανικά. Για αυτό το έργο μεγάλης κλίμακας αναπτύξαμε συστήματα μετάφρασης πολλαπλών τομέων, ανθεκτικά στον θόρυβο, που στοχεύουν να χειριστούν τις δύο συνθήκες δοκιμής: την προσαρμογή του μηδενικού και του ελάχιστου πεδίου.", 'it': "Questo articolo descrive i contributi di LIMSI alle attività condivise di traduzione a WMT'20. Quest'anno abbiamo concentrato i nostri sforzi sul compito di traduzione biomedica, sviluppando un sistema ricco di risorse per la traduzione di abstract medici dall'inglese al francese, utilizzando testi retrotradotti, risorse terminologiche e molteplici pipeline di pre-elaborazione, comprese rappresentazioni pre-formate. Sono stati inoltre preparati sistemi per il compito di robustezza per la traduzione dall'inglese al tedesco; Per questo compito su larga scala abbiamo sviluppato sistemi di traduzione multi-dominio, robusti dal rumore, volti a gestire le due condizioni di test: zero-shot e pochi-shot domain adaptation.", 'kk': "Бұл қағаз WMT' 20- де LIMSI жіберілген тапсырмалар ортақтастырылған аудармаларға жіберілгенін анықтайды. Бұл жыл біз биомедицина аудару тапсырмасына көмектесіп, ағылшын тілінен ағылшын тілінен ағылшын тіліне медицина абстракттарын аудару үшін ресурс күшті жүйесін ағылшын тіліне аударып, қайта аударылған мәтіндерді, терминологи Жүйелер де ағылшын тілінен неміс тіліне аудару үшін дұрыс тапсырма үшін дайындалды; Бұл үлкен масштаб тапсырманың үшін біз көп-доменді, дыбыс-қуатты, аудармалы жүйелерді екі сынақ шарттарын өзгерту үшін жасадық: нөл-шарт және бірнеше шарт доменге ад", 'lt': "Šiame dokumente aprašomi LIMSI pranešimai dėl vertimo bendrų užduočių WMT'20. Šiais metais sutelkėme pastangas į biomedicinos vertimo užduotį, kuriant didelį išteklių kiekį turinčią medicininių abstraktų vertimo iš anglų į prancūzų sistemą, naudojant grįžtamuosius tekstus, terminologinius išteklius, taip pat kelis priešperdirbimo vamzdynus, įskaitant iš anksto parengtus atstovavimus. Be to, buvo parengtos sistemos, skirtos patikimumui vertti anglų kalba į vokiečių kalbą; šioje didelės apimties užduotyje sukūrėme daugiadominas, triukšmo stiprias vertimo sistemas, kuriomis siekiama išspręsti dvi bandymų sąlygas: pritaikymą nuliniam ir nedaug nuotraukų domenams.", 'mk': "Овој весник ги опишува пренесувањата на ЛИМСИ во преводот на заедничките задачи на WMT'20. Оваа година ги фокусиравме нашите напори на биомедицинската преведувачка задача, развивајќи систем со големи ресурси за преведување на медицинските апстракти од англиски на француски, користејќи преведени тексти, терминолошки ресурси, како и многуте препроцесорски гасоводи, вклучувајќи и пре Системите, исто така, беа подготвени за задачата на силноста за преведување од англиски на германски; за оваа голема задача развивме мултидоменички, силни, преводни системи кои имаат за цел да ги справат двете тестови услови: адаптација на домените со нула и неколку снимки.", 'ms': "Kertas ini menggambarkan penghantaran LIMSI kepada tugas terkongsi terjemahan di WMT'20. Tahun ini kita telah fokus usaha kita pada tugas terjemahan biomedis, mengembangkan sistem yang berat sumber untuk terjemahan abstrak perubatan dari Inggeris ke Perancis, menggunakan teks terjemahan-balik, sumber terminologi serta beberapa saluran paip-paip, termasuk perwakilan-prapraktek. Sistem juga disediakan untuk tugas ketat untuk menerjemahkan dari Inggeris ke Jerman; untuk tugas skala besar ini kami mengembangkan sistem terjemahan multi-domain, bunyi-robust bertujuan untuk menangani dua syarat ujian: penyesuaian domain 0-shot dan beberapa-shot.", 'ml': 'ഈ പേപ്പറിന്റെ വിവരങ്ങള്\u200d WMT-20-ല്\u200d പങ്കുചേര്\u200dത്ത ജോലികള്\u200dക്ക് ലിഎസ്ഐയുടെ സജ്ജീകരണങ്ങള്\u200d വിവരിച്ചുകൊ ഈ വര്\u200dഷം ഞങ്ങള്\u200d ജീവിയ മെഡിക്കല്\u200d പരിഭാഷണത്തിന്\u200dറെ ജോലിയില്\u200d ശ്രമിച്ചിരിക്കുന്നു. മുമ്പ് പരിശീലിക്കപ്പെട്ട പ്രതിനിധികള്\u200d ചേര്\u200dന്നുകൊണ്ട് മെഡിക്കല്\u200d അബ്രാക്ട്രാക്ടുകള ഇംഗ്ലീഷില്\u200d നിന്നും ജര്\u200dമ്മനിലേക്കും പരിഭാഷപ്പെടുത്താന്\u200d വേണ്ടി സിസ്റ്റമുകള്\u200d ഒരുക്കിയിരു ഈ വലിയ പ്രവര്\u200dത്തനങ്ങള്\u200dക്കായി ഞങ്ങള്\u200d പല-ഡൊമൈന്\u200d, ശബ്ദ-റോബോസ്റ്റ്, പരിശോധന സിസ്റ്റം രണ്ട് പരീക്ഷണസ്ഥിതികളെ കൈകാര്യം ചെയ്യാന്\u200d ഉദ്ദേശിച', 'mt': "Dan id-dokument jiddeskrivi s-sottomissjonijiet tal-LIMSI għat-traduzzjoni kompiti kondiviżi fid-WMT'20. Din is-sena ffukajna l-isforzi tagħna fuq il-kompitu tat-traduzzjoni bijomedika, l-iżvilupp ta’ sistema li tqila r-riżorsi għat-traduzzjoni ta’ astratti mediċi mill-Ingliż għall-Franċiż, bl-użu ta’ testi tradotti lura, riżorsi terminoloġiċi kif ukoll diversi pipelines ta’ qabel l-ipproċessar, inklużi rappreżentazzjonijiet imħarrġa minn qabel. Ġew ippreparati wkoll sistemi għall-kompitu ta’ robustezza għat-traduzzjoni mill-Ingliż għall-Ġermaniż; għal dan il-kompitu fuq skala kbira żviluppajna sistemi ta’ traduzzjoni b’ħafna dominji, b’saħħithom u b’ħafna storbju għandhom l-għan li jimmaniġġjaw iż-żewġ kundizzjonijiet tat-test: adattament tad-dominju b’żero shot u b’ftit shot.", 'mn': "Энэ цаас WMT'20 онд LIMSI-ын хуваалцааны даалгаврыг тайлбарладаг. Энэ жил бид биологийн эрүүл мэндийн хөрөнгө оруулалтын ажил дээр ажиллаж, Англи хэлний эмнэлгийн хэмжээсүүдийг французтой руу орлуулахын тулд эмнэлгийн хэмжээсүүдийг хөгжүүлж, эргээд орлуулсан текст, терминологийн нөөц болон олон хэмжээсүүди Мөн системүүд Англи хэлэхээс Герман руу орчуулахад хүчтэй ажилд бэлэн байлаа. Бид олон тоо хэмжээний үйл ажилд, дуу хөдөлгөөнтэй, хөгжүүлэх системүүд хоёр шалгалтын нөхцөл байдлыг удирдах зорилготой: 0-шууд болон хэдэн шалгалтын зохицуулалт.", 'no': "Denne papiret skildrar LIMSI sin tillegg til omsetjinga delte oppgåver på WMT' 20. I denne året har vi fokuserte våre forsøk på biomedisinske omsetjingsprogrammet, og utvikla eit ressurs-kraftig system for omsetjing av medisinske abstraktar frå engelsk til fransk, med tilbakeomsette tekstar, terminologiske ressursar og fleire førehandsamingsrøyr, inkludert føretrainerte representasjonar. Systemar vart også forberedt for robustoppgåva for å omsetja frå engelsk til tysk; for denne stor oppgåva vi utvikla fleire domene, noise-robust, omsetjingssystemet mål å handtera dei to testvilkåra: 0-shot og få-shot domenetilpassing.", 'pl': "Niniejszy artykuł opisuje zgłoszenia LIMSI do wspólnych zadań tłumaczeniowych w WMT'20. W tym roku skupiliśmy nasze wysiłki na zadaniu tłumaczenia biomedycznego, opracowaniu obciążonego zasobami systemu tłumaczenia streszczeń medycznych z języka angielskiego na francuski, z wykorzystaniem tekstów tłumaczonych wstecznie, zasobów terminologicznych oraz wielu rurociągów wstępnego przetłumaczenia, w tym wstępnie przeszkolonych reprezentacji. Przygotowano również systemy do zadania solidności tłumaczenia z języka angielskiego na niemiecki; Do tego zadania na dużą skalę opracowaliśmy wielododomenowe, odporne na szumy systemy tłumaczeniowe mające na celu obsługę dwóch warunków testowych: adaptacji domeny zero-shot i kilku-shot.", 'ro': "Această lucrare descrie trimiterile LIMSI la sarcinile partajate de traducere la WMT'20. Anul acesta ne-am concentrat eforturile asupra sarcinii de traducere biomedicală, dezvoltând un sistem greu de resurse pentru traducerea rezumatelor medicale din engleză în franceză, folosind texte retrotraduse, resurse terminologice, precum și multiple conducte de pre-procesare, inclusiv reprezentări pre-instruite. Sistemele au fost pregătite, de asemenea, pentru sarcina de robustețe pentru traducerea din engleză în germană; Pentru această sarcină pe scară largă, am dezvoltat sisteme de traducere multi-domeniu, robuste și cu zgomot, cu scopul de a face față celor două condiții de testare: adaptarea domeniului zero-shot și adaptarea domeniului puțin-shot.", 'sr': "Ovaj papir opisuje podatke LIMSI na podjele prevoda na WMT'20. Ove godine smo fokusirali svoje napore na zadatak biomedicinskog prevoda, razvijajući sistem teških resursa za prevod medicinskih abstrakta sa engleskog na francuski, koristeći tekst prevedeni nazad, terminološke resurse, kao i višestruke preobrazovanje cijevi, uključujući predobučene predstave. Sistemi su takođe pripremljeni za robustni zadatak za prevod sa engleskog na njemački; za ovaj veliki zadatak koji smo razvili višedomene, jačane buke, prevodne sustave ciljaju da se snađu na dva testa uslova: adaptacija na nulu i nekoliko snimanja domena.", 'sv': "Denna uppsats beskriver LIMSI:s bidrag till 철vers채ttningsuppgifterna p책 WMT'20. I 책r har vi fokuserat v책ra insatser p책 den biomedicinska 철vers채ttningsuppgiften genom att utveckla ett resurstungt system f철r 철vers채ttning av medicinska abstracts fr책n engelska till franska, med hj채lp av bak책t철versatta texter, terminologiska resurser samt flera f철rbehandlingspipelines, inklusive f철rutbildade representationer. Systemen f철rbereddes ocks책 f철r robusthetsuppgiften f철r 철vers채ttning fr책n engelska till tyska. F철r denna storskaliga uppgift utvecklade vi 철vers채ttningssystem med flera dom채ner, brust책liga, som syftar till att hantera de tv책 testf철rh책llandena: noll-skott och f책-skott dom채nanpassning.", 'si': "මේ පත්තුව LIMSI ගේ පිළිබඳය WMT' 20 වලින් භාවිත වැදගත් වැදගත් වැදගත් වැදගත්තා. මේ අවුරුද්දේ අපි අපේ උත්සාහ කළා ජීවිත වෛද්\u200dය වාර්ථාව වැඩකට, ඉංග්\u200dරීසියාවෙන් ඉංග්\u200dරීසියාවෙන් ඉන්ග්\u200dරීසියාවෙන් ප්\u200dරවේශනය කරලා ඉන්ග්\u200dර පද්ධතිය පද්ධතිය ලෑස්ති වුනා ඉංග්\u200dරීසියෙන් ජර්මන් වලට පරිවර්තනය කරන්න පුළුවන්. මේ ලොකු ප්\u200dරමාණ වැඩේ වැඩේ වැඩ කරන්න අපි ගොඩක් ඩොමේන් එක්ක, ශබ්ද විශ්වාසිය, වාර්තාව පද්ධතියේ අදහස් කරනවා පරීක්ෂණ අ", 'so': "Warqadan ayaa ku qoran LIMSI warqadaha turjumaadda ee lagu qeybiyey shaqada WMT'20. Sannadan waxaan ku kalsoonaynay hawlahayaga arimaha turjumidda biomedical ah, horumarinta nidaam aad u culus, si loo tarjumo qalabka dhakhaatiirta ee Ingiriiska ilaa Faraansiinta, isticmaalayo qoraal-tarjuman dib-translated, rasuul-xirfadeed, terminological resource iyo fursado badan oo ka hor-baaraandegista, kuwaas oo ka mid ah wakiilayaasha horay loo tababaray. Sidoo kale waxaa loo diyaariyey nidaamka shaqada boosaska lagu turjumo afka Ingiriis ilaa Jarmal; Shaqadan aad u weyn ee aan horumarinay goobo badan, cod-robid, nidaamka turjumaadda oo ku qoran labada xaaladood oo imtixaan ah: zero-shot iyo wax yar oo beddelaya domain.", 'ta': 'மொழிபெயர்ப்பு பங்கிடப்பட்ட பணிகளுக்கு LIMSI கூறுகளை விளக்குகிறது. இந்த வருடத்தில் நாம் உயிரியல் மொழிபெயர்ப்பு பணியின் மீது எங்கள் முயற்சிகளை கவனம் செலுத்தி இருக்கிறோம், முன் பயிற்சி செய்யப்பட்ட பிரதிநிதிகளைக் கொண்டு மருத்துவ ஒதுக்குகளை  ஆங்கிலத்திலிருந்து ஜெர்மனுக்கு மொழிபெயர்ப்புவதற்கான தொழில்நுட்ப பணிக்கு அமைப்புகளும் தயா இந்த பெரிய அளவிற்கான செயல்பாட்டிற்காக நாங்கள் பல- டோமைன், ஒலி ரோப்ட், மொழிபெயர்ப்பு அமைப்புகள் இரண்டு சோதனை நிபந்தனைகளை கையாளும் செய்', 'ur': "This paper describes LIMSI's submissions to the translation shared tasks at WMT'20. آج سال ہم نے اپنی کوشش کو بیولوڈیسی ترجمہ کے تابع پر، انگلیسی سے پچھلے ترجمہ ٹیکسٹوں کی ترجمہ کے لئے ایک سراسر-بوجھ سیستم کو فرانسوی میں ترجمہ کیا ہے، ٹیمینلوژیک سراسروں کا استعمال کرتا ہے اور بہت سی پیش پرسس پئیپلین کی ترجمہ کے ساتھ۔ سیستموں نے بھی انگلیسی سے جرمانی میں ترجمہ کرنے کے لئے مضبوط کام کے لئے تیار کیے گئے تھے۔ ہم نے ایک بڑی اسکیل کام کے لئے بہت سی ڈومین، صدا مضبوط، ترجمہ سیسٹم کو دو امتحان شرایطوں کی حفاظت کرنے کا ارادہ کیا ہے: صفر-شٹ اور کم-شٹ ڈومین ادامه.", 'uz': "Ushbu qogʻoz WMT 20'da tarjima qilingan vazifalarni LIMSI'ning imkoniyatlarini anglatadi. Bu yil biz biomediya tarjima vazifasini foydalanamiz, inglizcha tildan Fransuzchaga o'rganish tizimga murojaat qilish uchun juda qiyin tizimni yaratdik, orqali tarjima qiladigan textlarni, terminologik Resources va bir nechta avval tarjima qilish uchun bir necha qo'llangan qo'llanmalarni yaratdik. Tizimlar Inglizchadan Olmonchaga tarjima qilishga tayyorlangan edi; Bu katta vazifa uchun bir necha domen, tovush-robust, tarjima tizimni ikkita sinov holatni boshqarish uchun yaratdik: zero'yib qo'yish va bir necha qo'llangan domen adaptarini boshqarish uchun.", 'vi': "Tờ giấy này mô tả lời đệ trình của LISII cho dịch vụ chia s ẻ tại WRT'20. Năm nay chúng ta đã tập trung vào nhiệm vụ dịch chuyển y học, phát triển một hệ thống chuyên tốn kém trong việc dịch chuyển các loại thuốc men từ Anh sang Pháp, sử dụng các văn bản dịch lại, các nguồn ngôn ngữ học cũng như nhiều đường ống xử lý tiền, bao gồm các biểu hiện được huấn luyện trước. Hệ thống cũng được chuẩn bị cho nhiệm vụ kiên trì để dịch từ tiếng Anh sang tiếng Đức; Với nhiệm vụ lớn này, chúng tôi đã phát triển hệ thống dịch chuyển có nhiều miền, mạnh mẽ, nhằm giải quyết hai điều kiện thử nghiệm: sửa chữa miền dở và dở hơi.", 'bg': "Настоящата статия описва предложенията на LIMSI за споделените задачи за превод в WMT'20. Тази година ние съсредоточихме усилията си върху задачата по биомедицински превод, разработвайки система за превод на медицински резюмета от английски на френски език, използвайки обратно преведени текстове, терминологични ресурси, както и множество тръбопроводи за предварителна обработка, включително предварително обучени представителства. Подготвени са и системи за задачата за надеждност на превода от английски на немски; за тази мащабна задача разработихме многодомейни, шумоустойчиви преводни системи, които имат за цел да се справят с двете условия на изпитване: адаптация на нулев и маловажен домейн.", 'nl': "Dit artikel beschrijft de inzendingen van LIMSI voor de vertaaltaken die bij WMT'20 worden gedeeld. Dit jaar hebben we onze inspanningen gericht op de biomedische vertaaltaak, het ontwikkelen van een resourcezwaar systeem voor de vertaling van medische abstracts uit het Engels naar het Frans, met behulp van back-vertaalde teksten, terminologische bronnen en meerdere pre-processing pipelines, waaronder voorgetrainde representaties. Ook werden systemen voorbereid voor de robuustheidstaak voor het vertalen van het Engels naar het Duits; Voor deze grootschalige taak ontwikkelden we multi-domein, ruis-robuuste vertaalsystemen die de twee testomstandigheden aankunnen: zero-shot en few-shot domeinadaptatie.", 'hr': "Ovaj papir opisuje podatke LIMSI-a na podijeljene zadatke prevoda na WMT'20. Ove godine smo usredotočili svoje napore na zadatak biomedicinskog prevoda, razvoj sustava za prevod medicinskih apstrakta iz Engleskog na francuski, korištenje tekstova, terminoloških resursa, kao i višestruke preobrazovanje cijevi, uključujući predobučene predstave. Sistemi su također pripremljeni za robustni zadatak za prevod s engleskog na njemački; za ovaj veliki zadatak koji smo razvili višedomenički, snažni, prevodni sustavi ciljaju na rješavanje dva testnog uvjeta: prilagodba domenija nula-snimanja i manje snimanja.", 'da': "Dette papir beskriver LIMSI's indlæg til de delte oversættelsesopgaver på WMT'20. I år har vi fokuseret vores indsats på den biomedicinske oversættelsesopgave og udviklet et ressourcetungt system til oversættelse af medicinske abstracts fra engelsk til fransk ved hjælp af bagoversatte tekster, terminologiske ressourcer samt flere forhåndsbehandlingsrørledninger, herunder forududdannede repræsentationer. Der blev også udarbejdet systemer til robusthedsopgaven ved oversættelse fra engelsk til tysk; Til denne store opgave udviklede vi flerdomæner, støjsvage, oversættelsessystemer, der skal håndtere de to testforhold: nul-shot og få-shot domæne tilpasning.", 'de': "In diesem Beitrag werden die Beiträge von LIMSI zu den gemeinsamen Übersetzungsaufgaben bei WMT'20 beschrieben. In diesem Jahr haben wir uns auf die biomedizinische Übersetzungsaufgabe konzentriert, indem wir ein ressourcenintensives System für die Übersetzung medizinischer Abstracts aus dem Englischen ins Französische unter Verwendung rückübersetzter Texte, terminologischer Ressourcen sowie mehrerer Vorverarbeitungs-Pipelines einschließlich vortrainierter Repräsentationen entwickelt haben. Außerdem wurden Systeme für die Robustheitsaufgabe für die Übersetzung aus dem Englischen ins Deutsche vorbereitet; Für diese Großaufgabe haben wir multidomänen, rauschrobuste Übersetzungssysteme entwickelt, die die beiden Testbedingungen Zero-Shot und Few-Shot Domain Adaption bewältigen sollen.", 'id': "Kertas ini menjelaskan pengiriman LIMSI ke tugas terjemahan yang dibagi di WMT'20. Tahun ini kami telah fokus usaha kami pada tugas terjemahan biomedis, mengembangkan sistem yang berat sumber daya untuk terjemahan abstrak medis dari Inggris ke Perancis, menggunakan teks terjemahan kembali, sumber daya terminologi serta beberapa pipa-pipa pra-proses, termasuk reprezentasi pra-dilatih. Sistem juga disediakan untuk tugas ketat untuk menerjemahkan dari bahasa Inggris ke Jerman; for this large-scale task we developed multi-domain, noise-robust, translation systems aim to handle the two test conditions: zero-shot and few-shot domain adaptation.", 'ko': "본고는 LIMSI가 WMT'20에 제출한 번역 공유 임무를 설명한다.올해 우리는 생물의학 번역 임무에 중점을 두고 자원 집약형 시스템을 개발하여 의학 요약을 영어에서 프랑스어로 번역하고 번역 텍스트, 용어 자원과 여러 개의 예처리 파이프라인을 사용하는데 예교육 표현을 포함한다.시스템은 영어에서 독일어로 번역하는 안정성 임무도 준비했다.이 대규모 임무에 대해 우리는 다역, 소음 방지 번역 시스템을 개발하여 두 가지 테스트 조건인 영포와 소포역의 자체 적응을 처리하는 데 목적을 둔다.", 'fa': "این کاغذ تحویل LIMSI را به کارهای مشترک ترجمه در WMT'20 توصیف می\u200cکند. امسال ما تلاش\u200cهایمان را روی تکلیف ترجمه بیولوژیک تمرکز کردیم، یک سیستم سنگین منبع برای ترجمه\u200cهای پزشکی از انگلیسی به فرانسوی، استفاده از متن\u200cهای پشت ترجمه شده، منابع\u200cهای terminولوژیکی و بسیاری از لوله\u200cهای پیش\u200cپردازش، شامل نمایش\u200cهای پیش سیستم\u200cها همچنین برای کار سختی برای ترجمه از انگلیسی به آلمانی آماده شده\u200cاند. برای این کار بسیار بزرگ که ما سیستم\u200cهای ترجمه\u200cای که دارند، سیستم\u200cهای زیادی را توسعه می\u200cدهیم، سیستم\u200cهای زیادی، قوی و قوی و ترجمه\u200cای را هدف می\u200cدهند که دو شرایط آزمایش را حل کنند: صفر-شلیک و تعمیر کردن", 'sw': 'Gazeti hili linaelezea ujumbe wa LIMSI wa tafsiri uliosambazwa na kazi za WMT ya miaka 20. Mwaka huu tumejikita kwenye juhudi zetu za kutafsiri za kitabibu, kutengeneza mfumo mzito wa rasilimali kwa ajili ya kutafsiri vifaa vya afya kutoka Kiingereza hadi Ufaransa, kwa kutumia ujumbe wa kutafsiriwa kwa mara nyingi, rasilimali za kiutamaduni pamoja na mistari kadhaa za kabla ya kuchukua hatua, ikiwa ni pamoja na uwakilishi wa zamani uliofanyika. Mfumo pia uliandaliwa kwa ajili ya juhudi za kibiashara kwa kutafsiri kutoka Kiingereza hadi Ujerumani; kwa jukumu hili kubwa ambalo tuliunda maeneo mbalimbali, mabomu ya sauti, mfumo wa tafsiri unalenga kukabiliana na hali mbili za jaribio: mabadiliko yasiyo na mabadiliko madogo ya ndani.', 'tr': "Bu kagyz LIMSI'i흫 WMT'20-de b철l첵채n zadlary흫 terjime etmegini tassy첵ar. Bu 첵yl bizi흫 챌abalarymyzy biomedical terjime t채bligine 체ns berdik, t캇bbi abstraktlary흫 terjime etmesi 체챌in I흫lis dilinden Fransuz챌a 챌evirilmesi 체챌in 챌evirilip 첵체ze 챌ykdy. Mundan hem sistemalar i흫lis챌e Alman챌a terjime etmek 체챌in g체첵챌li zada ta첵첵arlandylar; Bu b체y체k 철l챌ekli zady흫 체챌in multi-domeny, g체rr체흫-g체첵챌li, terjime sistemleri iki testi 힊artlaryny 챌철zmek amac캇yla geli힊tirdik: 0-atly we az atly domeny adilamas캇.", 'af': "Hierdie papier beskrywe LIMSI se onderskrywings na die vertaling gedeelde taak by WMT' 20. Name Hierdie jaar het ons versoekte gefokus op die biomediese vertaling opdrag, ontwikkeling van 'n hulpbron-swaar stelsel vir die vertaling van mediese abstrakte van Engels na Frans, gebruik terugvertalinge teks, terminologiese hulpbronne en veelvuldige voorafverwerking pipelyne, insluitend voorafveroefende vertalings. Stelsels was ook berei vir die kragtige taak om van Engels na Duits te vertaling; vir hierdie groot-skaal taak ontwikkel ons multidomein, ruis-robust, vertalingsstelsels doel om die twee toets voorwaardes te hanteer: zero-skoot en paar-skoot domein aanpassing.", 'am': 'ይህ ገጽ የLIMSI ድጋፍ በWMT-20 የተካፈሉት ስራዎችን ለመተርጉም ይናገራል፡፡ በዚህች ዓመት የሕያማዊ ትርጉም ስራ ላይ ተግባራችንን እናሳውቃለን፤ ከንግግሊዝኛ ጀምሮ ወደ ፈረንሳይ ለመግለጽ የድህነትን ትርጉም፣ በተርታመሩ ጽሑፎች፣ ተርሚኖሎጂ ሀብት እና ከዚህ በፊት ተማርክቷል የተለየ ጥናት እና በብዙ የፊተኛ ጉዳይ መስመር ማዕከላዊ ስርዓት እና መፍጠር ነው፡፡ ከንግግሊዝኛ ጀምሮ ጀምሮ ጀምሮ ጀምሮ ጀምሮ ጀርመን ለመግለጽ የዕርቅ ሥራ ተዘጋጅቷል፡፡ ለዚህ ትልቅ ስራ ብዙ ድምፅ፣ ድምፅ-ሮቦት፣ የድምፅ ድምፅ፣ ትርጉም ሥርዓት የሁለቱን ፈተና ሥርዓቶች ለመቆጣጠር ነው፤ zero-shot እና ጥቂት የዶሜን አቀማመጥ ነው፡፡', 'sq': "Ky dokument përshkruan paraqitjet e LIMSI në detyrat e përkthimit të përbashkëta në WMT'20. Këtë vit ne kemi përqëndruar përpjekjet tona në detyrën e përkthimit biomedikal, duke zhvilluar një sistem të rëndë burimesh për përkthimin e abstraktave mjekësore nga anglisht në francez, duke përdorur tekste të përkthyera mbrapa, burime terminologjike si dhe tubacione të shumta paraprocesuese, duke përfshirë përfaqësime paratrajnuara. Sistemet u përgatitën gjithashtu për detyrën e fortësisë për përkthimin nga anglisht në gjerman; for this large-scale task we developed multi-domain, noise-robust, translation systems aim to handle the two test conditions: zero-shot and few-shot domain adaptation.", 'hy': "Այս հոդվածը նկարագրում է ԼիՄՍԻ-ի ներկայացումները թարգմանման համագործակցած հանձնարարություններին ՀԱՄ'20-ում: Այս տարի մենք կենտրոնացրել ենք մեր ջանքերը կենսաբժշկական թարգմանման խնդրի վրա, զարգացնել ռեսուրսների ծանր համակարգ անգլերենից դեպի ֆրանսերեն թարգմանելու համար, օգտագործելով թարգմանված տեքստեր, տերմինոլոգիական ռեսուրսներ, ինչպես նաև բազմաթիվ նախավերամ համակարգերը նաև պատրաստված էին անգլերենից գերմաներեն թարգմանելու ուժեղ առաջադրանքի համար, այս մեծ մասշտաբով խնդրի համար մենք զարգացրեցինք բազմաբնական, աղմուկի-ուժեղ թարգմանման համակարգերը, որոնց նպատակն է կառավարել երկու փորձարկման պայմանները' զրոյի և քիչ մասշտաբով բնական ադապտացիա:", 'az': "Bu kağıt WMT'20'də LIMSI'nin vəzifələrini WMT'də paylaşılan işlərə təlqin edir. Bu ilin bizim çabalarımızı biomedical tercümə görevi üzərində, İngilizdən İngilizdən fərqli abstraktların tercüməsi üçün çoxlu çoxlu qüvvət sistemini təhsil etdik, tercümə edilmiş məktubları, terminolojik kaynaqları və çoxlu əvvəlcə təhsil edilmiş məktubları birlikdə təhsil etdik. Sistemlər də İngilizdən Almanca çevirmək üçün qüvvətli işlər üçün hazırlanmışdır; Bu böyük ölçülü iş üçün çox-domani, səs-qüvvətli, tercümə sistemləri iki test şartlarını idarə etmək məqsədilə təşkil etdik: sıfır-vuruş və az-vuruş domena adaptasiyonu.", 'bn': "এই পত্রিকাটি উইএমটি'২০-এ অনুবাদের কাজ শেয়ার করার জন্য লিএমআই-এর প্রতিক্রিয়া বর্ণনা করেছে। এই বছর আমরা বায়োমেডিকেল অনুবাদের কাজের উপর আমাদের প্রচেষ্টার দিকে মনোযোগ প্রদান করেছি, ইংরেজি থেকে ফরাসী ভারী মেডিকেল বিভাগের অনুবাদের জন্য একটি রিসোর্স-ভারী সিস্টেম উন্নয়ন করে ইংরেজি থেকে জার্মানে অনুবাদ করার জন্য ব্যবস্থা প্রস্তুত করা হয়েছে; এই বড় স্ক্যালের কাজের জন্য আমরা বহুডোমেইন, শব্দ-রোবট, অনুবাদ সিস্টেম তৈরি করেছি যার লক্ষ্য হচ্ছে দুটি পরীক্ষার পরীক্ষা ব্যবস্থা: শুট এব", 'cs': "Tento článek popisuje příspěvky LIMSI k překladatelským sdíleným úkolům ve WMT'20. V letošním roce jsme se zaměřili na biomedicínský překladatelský úkol, vytvořili zdrojový systém pro překlad lékařských abstraktů z angličtiny do francouzštiny s využitím zpětně přeložených textů, terminologických zdrojů a několika předzpracovatelských potrubí, včetně předškolených reprezentací. Byly také připraveny systémy pro robustní úlohu překladu z angličtiny do němčiny; Pro tento rozsáhlý úkol jsme vyvinuli multi-doménové, šumově robustní překladové systémy, které mají zvládnout dvě testovací podmínky: nulovou a několik záběrů domény adaptace.", 'ca': "Aquest article descriu les presentacions de LIMSI a les tasques compartides de traducció a WMT'20. Aquest any hem centrat els nostres esforços en la tasca de traducció biomèdica, desenvolupant un sistema pesat en recursos per traduir abstractes mèdices d'anglès a francès, fent servir textos traduits en arriba, recursos terminològics i múltiples conductes de pré-processament, incloent representacions pré-entrenades. Els sistemes també estaven preparats per la tasca de robustetat de traducció d'anglès a alemany; per a aquesta tasca a gran escala vam desenvolupar sistemes de traducció multidominiu robustos i robustos en soroll que busquen gestionar les dues condicions d'assaig: adaptació a dominis amb dispars zero i pocs dispars.", 'bs': "Ovaj papir opisuje podatke LIMSI na podijeljene zadatke prevoda na WMT'20. Ove godine smo fokusirali svoje napore na zadatak biomedicinskog prevoda, razvijajući sistem težak resursa za prevod medicinskih abstrakta iz Engleskog na francuski, koristeći tekst prevedeni nazad, terminološke resurse, kao i višestruke preobrazovanje cijevi, uključujući predobučene predstave. Sistemi su također pripremljeni za robustni zadatak za prevod sa engleskog na njemački; za ovaj veliki zadatak koji smo razvili višedomene, jačane buke, sustave prevođenja ciljaju na rješavanje dva testnog uvjeta: adaptacija domena nule-pucnjave i nekoliko pucnjava.", 'fi': "Tässä artikkelissa kuvataan LIMSI:n ehdotuksia WMT'20:n yhteisiin käännöstehtäviin. Tänä vuonna olemme keskittyneet biolääketieteelliseen kääntämiseen kehittämällä resursseja vaativan järjestelmän lääketieteellisten tiivistelmien kääntämiseksi englannista ranskaksi käyttäen taaksekäännettyjä tekstejä, terminologisia resursseja sekä useita esikäsittelyputkintoja, mukaan lukien esikoulutettuja edustustoja. Järjestelmät valmisteltiin myös englannin kielestä saksaksi kääntämisen lujuustehtävään. Tähän laajamittaiseen tehtävään kehitimme moniulotteisia, kohinaa kestäviä käännösjärjestelmiä, joiden tarkoituksena on käsitellä kahta testiehtoa: nolla- ja harva-shot-domain-sopeutumista.", 'et': "Käesolevas dokumendis kirjeldatakse LIMSI esitusi WMT'20 ühistele tõlketeenustele. Sel aastal oleme keskendunud oma jõupingutused biomeditsiinilisele tõlkeülesandele, arendades välja ressursikahulise süsteemi meditsiiniliste kokkuvõtete tõlkimiseks inglise keelest prantsuse keelde, kasutades tagantõlgitud tekste, terminoloogilisi ressursse ja mitmeid eeltöötlusjuhtmeid, sealhulgas eeltöötlusega seotud esindusi. Süsteemid valmistati ette ka inglise keelest saksa keelde tõlkimise vastupidavuse ülesandeks; Selleks laiaulatuslikuks ülesandeks töötasime välja mitmevaldkondlikud, mürakindlad tõlkesüsteemid, mille eesmärk on toime tulla kahe katsetingimusega: null-shot ja vähe-shot domeen kohandamine.", 'sk': "Ta prispevek opisuje prispevke LIMSI za skupne naloge prevajanja na WMT'20. Letos smo svoja prizadevanja osredotočili na nalogo biomedicinskega prevajanja, pri čemer smo razvili sistem za prevajanje medicinskih povzetkov iz angleščine v francoščino z uporabo nazaj prevedenih besedil, terminoloških virov in več cevovodov predhodne obdelave, vključno s predhodno usposobljenimi predstavitvami. Pripravljeni so bili tudi sistemi za nalogo robustnosti prevajanja iz angleščine v nemščino; Za to obsežno nalogo smo razvili večdomenske, hrupno robustne prevajalske sisteme, katerih cilj je obvladovanje dveh preskusnih pogojev: prilagoditev ničelnega strela in prilagoditev manjšega strela domene.", 'jv': "Pamir iki rambarang tanggal LISMI nang mbukakipun dadi nggawe tarjamahan ning WWT'2000Name Tahun punika, kita wis nggunakake ingkang sampeyan ingkang kita nggawe gerakan ingkang nggunakake tarjamahan, nggawe sistem mengko-nggunakake sistem sing nggawe tarjamahan kanggo ingkang kang ingkang ingkang ingkang ingkang ingkang ingkang ingkang ingkang ingkang urip, gampang oleh-urip, gampang oleh-urip lan tambah bantuan ingkang cara-urip sing katora tau Sisit kuwi wis dilakon kanggo awakdhéwé kanggo nggawe gerakan kanggo terjamah ning Inggris kanggo ngerambah 'Alaman'; For this big-scale task we opened multi-domain, sound-bot, translation sistem goal to handle the second test conditions: 0-shot and some-shot domain modification.", 'he': "העיתון הזה מתאר את ההעברות של LIMSI לתרגום משימות משותפות ב WMT'20. השנה התמקדנו במאמצינו במשימת התרגום הביומדיקאית, בפיתוח מערכת כבדה משאבים לתרגום של אסטרקטים רפואיים מאנגלית לצרפתית, באמצעות טקסטים מתרגמים מאחור, משאבים טמינולוגיים, כמו גם צינורות רבים לפני העבודה, כולל מייצגים מתאמנים מראש. מערכות היו גם מוכנות למשימת החזקה לתרגום מאנגלית לגרמנית. עבור המשימה הגדולה הזו פיתחנו מערכות תרגום רבות, חזקות לרעש ומטרות לטפל בשני תנאי הבדיקה: אפס-ירי ומספר-ירי התאמה לתחום.", 'ha': "This paper describes LIMSI's submissions to the translation shared tasks at WMT'20.  Yin shekara, mun fokus aikin mu a kan aikin fassarar ɗin da aka yi bizartar da shi, tuna wata na'urar-nau'i wa fassarar madaidaici daga Ingiriya zuwa Faransa, mun yi amfani da mistakardar-fassaranta bakin-tarjima, masu fassarwa masu tsakanin turnolojiya da misalin misalin misalin-aiki, tare da misalin misalin misãlai masu yawa. An yi tattalin na'ura wa aikin kibiyoyi da za'a fassara daga Ingiriya zuwa Jarman; wa wannan aikin babba da muka buɗe multi-Domen, shirin sauri-sauri, na'urar fassarori don ya yi amfani da shiryoyin ayuka biyu: sifri-shot da adadin sauran da aka yi sauna.", 'bo': "ཤོག་བྱང་འདིས་WMT'200དུ་ཡིག་སྣོད་ནང་དུ་LIMSI's submissions to the translation shared tasks at WMT'20 This year we have focused our efforts on the biomedical translation task, developing a resource-heavy system for the translation of medical abstracts from English to French, using back-translated texts, terminological resources as well as multiple pre-processing pipelines, including pre-trained representations. Examples of translations include: ད་ལྟ་མ་ལག་གིས་དབུལ་ཡིག་ལས་སྐར་ཆེན་ལ་རང་ཉིད་ཀྱི་ལས་འགུལ་གྱིས་རྟོགས་པ་ཞིག་ཡིན། for this large-scale task we developed multi-domain, noise-robust, translation systems aim to handle the two test conditions: zero-shot and few-shot domain adaptation."}
{'en': 'Elhuyar submission to the Biomedical Translation Task 2020 on terminology and abstracts translation', 'fr': "Soumission d'Elhuyar au Biomedical Translation Task 2020 sur la traduction de la terminologie et des résumés", 'ar': 'تقديم الحير إلى مهمة الترجمة الطبية الحيوية 2020 حول ترجمة المصطلحات والملخصات', 'pt': 'Apresentação de Elhuyar para a Tarefa de Tradução Biomédica 2020 sobre tradução de terminologia e resumos', 'es': 'Presentación de Elhuyar a la Biomédica Translation Task 2020 sobre traducción de terminología y resúmenes', 'ja': '用語と要約の翻訳に関する生物医学翻訳タスク2020へのElhuyarの提出', 'zh': 'Elhuyar为2020年生物医学译者言术语、摘要译之论', 'ru': 'Представление Elhuyar к задаче «Биомедицинский перевод 2020» по терминологии и переводу тезисов', 'hi': 'शब्दावली और सार अनुवाद पर बायोमेडिकल अनुवाद कार्य 2020 के लिए Elhuyar प्रस्तुतीकरण', 'ga': 'Aighneacht Elhuyar do Thasc an Aistriúcháin Bithleighis 2020 ar théarmaíocht agus ar aistriúchán achoimrí', 'ka': 'ბიომედიციო თავისუფლების პროგრამა 2020 პროგრამაზე ტერმინოლოგია და აბსტრაქტურების გადასუფლება', 'el': 'Υποβολή του Ελχουγιάρ στο Βιοϊατρικό Μεταφραστικό Έργο 2020 για την ορολογία και τη μετάφραση αφηρημένων', 'hu': 'Elhuyar benyújtás a Bioorvosi Fordítási Feladat 2020 terminológiájáról és absztrakt fordításáról', 'it': 'Presentazione di Elhuyar al Biomedical Translation Task 2020 sulla traduzione terminologica e abstract', 'kk': 'Эльхуяр биомедицина аудару тапсырмасына терминология және абстрактерді аудару', 'lt': 'Elhuyar pristatymas Biomedicinos vertimo darbui „2020“ dėl terminologijos ir abstraktų vertimų', 'ms': 'Penghantaran Elhuyar ke Tugas Terjemahan Biomedik 2020 tentang terminologi dan terjemahan abstrak', 'mk': 'Пренесување на Елхујар на Биомедицинската преведувачка задача 2020 за терминологија и апстрактни преведувања', 'ml': 'എല്\u200dഹാര്\u200d ബൈയോമിക്കല്\u200d പരിഭാഷത്തിന്റെ ടാസ്ക് 2020 ടെര്\u200dമിനിലോളജിയിലും അബ്ട്രാക്ട് പരിഭാഷകളിലും', 'mt': 'Elhuyar submission to the Biomedical Translation Task 2020 on terminology and abstracts translation', 'mn': 'Elhuyar Biomedical Translation Task 2020 оны терминологи болон сайхан хөрөнгө оруулах', 'no': 'Elhuyar', 'ro': 'Prezentarea Elhuyar la Activitatea de Traducere Biomedicală 2020 privind traducerea terminologiei și rezumatelor', 'pl': 'Zgłoszenie Elhuyara do Zadania Tłumaczeniowego Biomedicznego 2020 dotyczącego terminologii i tłumaczenia streszczeń', 'si': 'ElHuyar Submit to the BioMedic translation Job 2020on Terminal ology and Apotracts translation', 'sr': 'Predloženje Elhujara biomedicinskom prevodnom zadatku 2020 o terminologiji i prevodu abstracta', 'sv': 'Elhuyar inlämnande till Biomedicinsk Översättningsuppgift 2020 om terminologi och abstracts översättning', 'ta': 'Elhuyar submission to the Biomedical Translation Task 2020 on terminology and abstracts translation', 'so': 'Elhuyar wuxuu u dhiibi karaa shaqooyinka tarjumaadda Biomedical 2020 ku saabsan terminology and abstracts translation', 'ur': 'بیولوڈیسین ترجمن ٹاکس 2020 کے ذریعہ ایلحیویر تحویل', 'uz': 'Name', 'vi': 'Bản dịch dịch y khoa học 2020 về thuật ngữ và Bản dịch tổng hợp', 'bg': 'Представяне на Елхуяр в Задача за биомедицински превод 2020 по превод на терминология и резюмета', 'nl': 'Elhuyar inzending aan de Biomedische vertaaltaak 2020 over terminologie en abstractvertaling', 'da': 'Elhuyar indsendelse til Biomedicinsk Oversættelsesopgave 2020 om terminologi og abstracts oversættelse', 'hr': 'Predloženje Elhuyara Biomedicinskom prevodnom zadatku 2020 o terminologiji i prevodu apstraktata', 'de': 'Elhuyar-Einreichung bei der Biomedizinischen Übersetzungsaufgabe 2020 zur Übersetzung von Terminologie und Abstracts', 'id': 'Pengiriman Elhuyar ke Tugas Terjemahan Biomedis 2020 tentang terminologi dan terjemahan abstrak', 'ko': 'Elhuyar가 2020년 생물의학 번역 임무에 용어와 요약 번역을 제출하다', 'fa': 'تحویل الهویار به تابع ترجمه بیولوژیک بیولوژیک ۲۰۰۲ در مورد ترجمه\u200cشناسی و ترجمه\u200cها', 'sw': 'Elhuyar anatoa ujumbe wa kazi ya Tafsiri ya Biomedical 2020 kuhusu utaratibu na tafsiri ya kidini', 'tr': 'Elhuyar Biýamedical Terjime Görevi 2020 terminologiýa we çykyş terjime etmegi üçin', 'af': 'Elhuyar-onderwerp aan die Biomediese Vertaling Opdrag 2020 oor terminologie en abstrakte vertaling', 'hy': 'Էլհույարը ներկայացնում է Բիոբիոբժշկական թարգմանման 2020-ի խնդիրը տերմինոլոգիայի և վերացական թարգմանման մասին', 'az': 'Elhuyar terminologiya v톛 abstraktlar terc칲m톛si bar톛sind톛 Biomedical Translation Task 2020 t톛r톛find톛n', 'sq': 'Elhuyar submission to the Biomedical Translation Task 2020 on terminology and abstracts translation', 'am': 'ኤልሃራር በ2020 ትርሚናሎጂ እና abstracts translation', 'bs': 'Predloženje Elhuyara biomedicinskom prevodnom zadatku 2020 o terminologiji i prevodu abstracta', 'bn': 'এলহার বায়োমিকাল অনুবাদের কাজ ২০২০ সালে তার্মিনিলজি এবং আটকানো অনুবাদ সম্পর্কে জমা দিয়েছেন', 'cs': 'Předložení Elhuyaru do biomedicínského překladu 2020 o překladu terminologie a abstraktů', 'ca': "La presentació d'Elhuyar a la tasca de traducció biomèdica 2020 sobre terminologia i traducció abstracta", 'et': 'Elhuyar esitab terminoloogia ja kokkuvõtete tõlke 2020. aasta biomeditsiinilise tõlke ülesandele', 'fi': 'Elhuyar toimittaa terminologian ja tiivistelmien kääntämisen Biomedical Translation Task 2020 -tapahtumaan', 'jv': 'elhujar menehi kanggo Bijodien Tarjamahan Taaksi 2020 kanggo terminal nggambar lan nganggo tarjamah', 'ha': '@ item Text character set', 'sk': 'Elhuyar oddaja na nalogo prevajanja biomedicinskega prevajanja 2020 o prevajanju terminologije in povzetkov', 'he': 'השימוש של אליואר למשימת התרגום ביורפואית 2020 על טרמונולוגיה ותרגום אוסטרקטי', 'bo': 'Elhuyar submission to the Biomedical Translation Task 2020 on terminology and abstracts translation'}
{'en': 'This article describes the systems submitted by Elhuyar to the 2020 Biomedical Translation Shared Task, specifically the systems presented in the subtasks of terminology translation for English-Basque and abstract translation for English-Basque and English-Spanish. In all cases a Transformer architecture was chosen and we studied different strategies to combine open domain data with biomedical domain data for building the training corpora. For the English-Basque pair, given the scarcity of parallel corpora in the biomedical domain, we set out to create domain training data in a synthetic way. The systems presented in the terminology and abstract translation subtasks for the English-Basque language pair ranked first in their respective tasks among four participants, achieving 0.78 accuracy for terminology translation and a BLEU of 0.1279 for the translation of abstracts. In the abstract translation task for the English-Spanish pair our team ranked second (BLEU=0.4498) in the case of OK sentences.', 'ar': 'تصف هذه المقالة الأنظمة التي قدمها Elhuyar إلى المهمة المشتركة للترجمة الطبية الحيوية لعام 2020 ، وتحديداً الأنظمة المقدمة في المهام الفرعية لترجمة المصطلحات للغة الإنجليزية الباسكية والترجمة المجردة للغة الإنجليزية - الباسكية والإنجليزية - الإسبانية. في جميع الحالات ، تم اختيار بنية المحولات ودرسنا استراتيجيات مختلفة لدمج بيانات المجال المفتوح مع بيانات المجال الطبي الحيوي لبناء هيئة التدريب. بالنسبة للزوج الإنجليزي الباسكي ، نظرًا لندرة الكيانات المتوازية في المجال الطبي الحيوي ، شرعنا في إنشاء بيانات تدريب المجال بطريقة تركيبية. احتلت الأنظمة المقدمة في المصطلحات والمهام الفرعية للترجمة المجردة لزوج اللغة الإنجليزية الباسكية المرتبة الأولى في مهام كل منهما من بين أربعة مشاركين ، وحققت دقة 0.78 لترجمة المصطلحات و BLEU بقيمة 0.1279 لترجمة الملخصات. في مهمة الترجمة المجردة للزوج الإنجليزي-الأسباني ، احتل فريقنا المرتبة الثانية (BLEU = 0.4498) في حالة الجمل الجيدة.', 'fr': "Cet article décrit les systèmes soumis par Elhuyar à la tâche partagée de traduction biomédicale 2020, en particulier les systèmes présentés dans les sous-tâches de traduction terminologique pour l'anglais-basque et de traduction abstraite pour l'anglais-basque et l'anglais-espagnol. Dans tous les cas, une architecture Transformer a été choisie et nous avons étudié différentes stratégies pour combiner des données de domaine ouvert avec des données du domaine biomédical afin de créer les corpus de formation. Pour le couple anglais-basque, compte tenu de la rareté des corpus parallèles dans le domaine biomédical, nous avons décidé de créer des données d'entraînement de domaine de manière synthétique. Les systèmes présentés dans les sous-tâches terminologiques et traduction des résumés pour la paire anglais-basque se sont classés premiers dans leurs tâches respectives parmi quatre participants, atteignant une précision de 0,78 pour la traduction terminologique et une UEBL de 0,1279 pour la traduction des résumés. Dans la tâche de traduction des résumés pour le couple anglais-espagnol, notre équipe s'est classée deuxième (BLEU = 0,4498) dans le cas des phrases OK.", 'pt': 'Este artigo descreve os sistemas submetidos por Elhuyar à Tarefa Compartilhada de Tradução Biomédica 2020, especificamente os sistemas apresentados nas subtarefas de tradução de terminologia para inglês-basco e tradução abstrata para inglês-basco e inglês-espanhol. Em todos os casos foi escolhida uma arquitetura Transformer e estudamos diferentes estratégias para combinar dados de domínio aberto com dados de domínio biomédico para construir os corpora de treinamento. Para o par inglês-basco, dada a escassez de corpora paralelos no domínio biomédico, nos propusemos a criar dados de treinamento de domínio de forma sintética. Os sistemas apresentados nas subtarefas de terminologia e tradução de resumos para o par de idiomas inglês-basco ficaram em primeiro lugar em suas respectivas tarefas entre quatro participantes, alcançando 0,78 de precisão para tradução de terminologia e um BLEU de 0,1279 para tradução de resumos. Na tarefa de tradução de resumos para o par inglês-espanhol nossa equipe ficou em segundo lugar (BLEU=0,4498) no caso de sentenças OK.', 'es': 'En este artículo se describen los sistemas presentados por Elhuyar a la Tarea Compartida de Traducción Biomédica 2020, específicamente los sistemas presentados en las subtareas de traducción de terminología para inglés-vasco y traducción de abstractos para inglés-vasco y inglés-español. En todos los casos se eligió una arquitectura Transformer y estudiamos diferentes estrategias para combinar datos de dominio abierto con datos de dominio biomédico para construir los cuerpos de formación. Para la pareja anglo-vasca, dada la escasez de corpus paralelos en el dominio biomédico, nos propusimos crear datos de entrenamiento de dominio de forma sintética. Los sistemas presentados en las subtareas de terminología y traducción de abstractos para la pareja de lenguas inglés-vasco ocuparon el primer lugar en sus respectivas tareas entre cuatro participantes, alcanzando una precisión de 0.78 para la traducción de terminología y un BLEU de 0.1279 para la traducción de resúmenes. En la tarea de traducción de resúmenes para el par inglés-español, nuestro equipo ocupó el segundo lugar (BLEU=0.4498) en el caso de las oraciones correctas.', 'ja': 'この記事では、Elhuyarが2020 Biomedical Translation Shared Taskに提出したシステム、具体的には、英語-バスク語の用語翻訳と英語-バスク語および英語-スペイン語の抽象翻訳のサブタスクで提示されたシステムについて説明します。 すべてのケースで、トランスフォーマーアーキテクチャが選択され、トレーニングコーポラを構築するためにオープンドメインデータとバイオメディカルドメインデータを組み合わせるためのさまざまな戦略を研究しました。 英語とバスク語のペアでは、生物医学領域での並列体の希少性を考慮して、合成的な方法でドメイントレーニングデータを作成することにしました。 英語とバスク語のペアの用語と抽象翻訳サブタスクで提示されたシステムは、4人の参加者の間でそれぞれのタスクで1位となり、用語翻訳の精度は0.78、抽象翻訳の精度は0.1279のBLEUを達成した。 英語とスペイン語のペアの抽象翻訳タスクでは、OK文の場合、チームは2位になりました（ BLEU = 0.4498 ）。', 'zh': '本文引Elhuyar提交给2020年生物医学译共享之统,特于英语 - 巴斯克语术语翻译、英语 - 巴斯克语、英语 - 西班牙语摘要翻译子职中呈系统。 凡此诸事,皆择Transformer架构,究其异策,将开域数合生物医学域数,以立训练语料库。 其于英语-巴斯克语也,鉴于生物医学域平行语料库之稀缺性,始以合式创域训数。 在英语-巴斯克语术语及摘要译子为第一,在四参与者中,术语译准确率为0.78,摘要译BLEU为0.1279。 英语 - 西班牙语对抽象译,团队于OK句第二(BLEU = 0.4498)。', 'ru': 'В этой статье описываются системы, представленные Elhuyar для совместной задачи биомедицинского перевода 2020 года, в частности системы, представленные в подзадачах терминологического перевода для английско-баскского и абстрактного перевода для английско-баскского и английско-испанского языков. Во всех случаях была выбрана архитектура Трансформера, и мы изучили различные стратегии объединения данных открытого домена с биомедицинскими данными домена для построения обучающих корпусов. Для английско-баскской пары, учитывая дефицит параллельных тел в биомедицинской области, мы поставили перед собой цель создать данные для обучения домену синтетическим способом. Системы, представленные в терминологии и подзадачах абстрактного перевода для английско-баскской языковой пары, заняли первое место в своих соответствующих задачах среди четырех участников, достигнув 0,78 точности для терминологического перевода и BLEU 0,1279 для перевода рефератов. В задаче абстрактного перевода для английско-испанской пары наша команда заняла второе место (BLEU= 0,4498) в случае предложений OK.', 'hi': 'यह आलेख 2020 बायोमेडिकल अनुवाद साझा कार्य के लिए Elhuyar द्वारा प्रस्तुत प्रणालियों का वर्णन करता है, विशेष रूप से अंग्रेजी-बास्क के लिए शब्दावली अनुवाद के उप-कार्यों में प्रस्तुत सिस्टम और अंग्रेजी-बास्क और अंग्रेजी-स्पेनिश के लिए अमूर्त अनुवाद। सभी मामलों में एक ट्रांसफॉर्मर आर्किटेक्चर चुना गया था और हमने प्रशिक्षण निगम के निर्माण के लिए बायोमेडिकल डोमेन डेटा के साथ खुले डोमेन डेटा को संयोजित करने के लिए विभिन्न रणनीतियों का अध्ययन किया था। अंग्रेजी-बास्क जोड़ी के लिए, बायोमेडिकल डोमेन में समानांतर कॉर्पोरेट की कमी को देखते हुए, हमने सिंथेटिक तरीके से डोमेन प्रशिक्षण डेटा बनाने के लिए सेट किया। अंग्रेजी-बास्क भाषा जोड़ी के लिए शब्दावली और अमूर्त अनुवाद उप-कार्यों में प्रस्तुत प्रणालियों को चार प्रतिभागियों के बीच अपने संबंधित कार्यों में पहले स्थान पर रखा गया है, जो शब्दावली अनुवाद के लिए 0.78 सटीकता और सार के अनुवाद के लिए 0.1279 का BLEU प्राप्त करता है। अंग्रेजी-स्पेनिश जोड़ी के लिए अमूर्त अनुवाद कार्य में हमारी टीम ठीक वाक्यों के मामले में दूसरे स्थान (BLEU = 0.4498) स्थान पर है।', 'ga': 'Déanann an t-alt seo cur síos ar na córais a chuir Elhuyar isteach don Tasc Comhroinnte um Aistriú Bithleighis 2020, go háirithe na córais a chuirtear i láthair sna fothascanna d’aistriúchán téarmaíochta don Bhéarla-Bascais agus d’aistriúchán teibí don Bhéarla-Bascais agus don Bhéarla-Spáinnis. I ngach cás roghnaíodh ailtireacht Trasfhoirmeora agus rinneamar staidéar ar straitéisí éagsúla chun sonraí fearainn oscailte a chomhcheangal le sonraí fearainn bithleighis chun an corpora oiliúna a thógáil. Maidir leis an bpéire Béarla-Bascach, agus ganntanas corpora comhthreomhar san fhearann bithleighis, thugamar faoi shonraí oiliúna fearainn a chruthú ar bhealach sintéiseach. Bhain na córais a chuirtear i láthair sna fo-thascanna aistriúcháin téarmaíochta agus teibí don phéire Béarla-Bascais sa chéad áit amach ina dtascanna faoi seach i measc na gceathrar rannpháirtí, bhain siad amach 0.78 cruinneas le haghaidh aistriúcháin téarmaíochta agus BLEU de 0.1279 maidir le haistriúchán achoimrí. Sa tasc aistriúcháin teibí don phéire Béarla-Spáinnis bhí ár bhfoireann sa dara háit (BLEU=0.4498) i gcás abairtí OK.', 'hu': 'Ez a cikk bemutatja az Elhuyar által a 2020. évi Bioorvosi Fordítási Közös Feladat részére benyújtott rendszereket, különösen az angol-baszk terminológiai fordítás alterületeiben bemutatott rendszereket, valamint az angol-baszk és az angol-spanyol absztrakt fordításokat. Minden esetben transzformátor architektúrát választottunk, és különböző stratégiákat tanulmányoztunk a nyílt domain adatok és az orvosbiológiai domain adatok kombinációjára a tréningvállalatok építéséhez. Az angol-baszk páros számára, tekintettel a párhuzamos corporák hiányára az orvosbiológiai területen, elkezdtük szintetikus módon létrehozni a domain képzési adatokat. Az angol-baszk nyelvpár terminológiai és absztrakt fordítási részfeladatában bemutatott rendszerek négy résztvevő között az első helyet értek el feladataikban, a terminológiai fordítás 0,78 pontosságát, az absztrakt fordítását pedig 0,1279 BLEU-t értek el. Az angol-spanyol páros absztrakt fordítási feladatában csapatunk az OK mondatok esetében a második helyen állt (BLEU=0,4498).', 'el': 'Αυτό το άρθρο περιγράφει τα συστήματα που υποβλήθηκαν από τον Ελχουγιάρ στην κοινή εργασία βιοϊατρικής μετάφρασης 2020, συγκεκριμένα τα συστήματα που παρουσιάζονται στις δευτερεύουσες εργασίες της μετάφρασης ορολογίας για Αγγλικά-Βασκικά και αφηρημένης μετάφρασης για Αγγλικά-Βασκικά και Αγγλικά-Ισπανικά. Σε όλες τις περιπτώσεις επιλέχθηκε μια αρχιτεκτονική μετασχηματιστή και μελετήσαμε διαφορετικές στρατηγικές για να συνδυάσουμε δεδομένα ανοιχτού τομέα με δεδομένα βιοϊατρικού τομέα για την κατασκευή των εκπαιδευτικών σωμάτων. Για το αγγλο-βασκικό ζευγάρι, δεδομένης της έλλειψης παράλληλων σωμάτων στον βιοϊατρικό τομέα, ξεκινήσαμε να δημιουργήσουμε δεδομένα κατάρτισης τομέα με συνθετικό τρόπο. Τα συστήματα που παρουσιάζονται στις δευτερεύουσες εργασίες ορολογίας και αφηρημένης μετάφρασης για το ζεύγος αγγλο-βασκικών γλωσσών κατατάχθηκαν πρώτοι στις αντίστοιχες εργασίες τους μεταξύ τεσσάρων συμμετεχόντων, επιτυγχάνοντας ακρίβεια 0.78 για τη μετάφραση ορολογίας και BLEU 0.1279 για τη μετάφραση αφηρημένων. Στην εργασία αφηρημένης μετάφρασης για το ζευγάρι Αγγλικά-Ισπανικά η ομάδα μας κατατάχθηκε δεύτερη (στην περίπτωση των ΟΚ προτάσεων).', 'ka': 'ამ წესტილის აღწერა სისტემები, რომლებიც Elhuyar-ის გამოყენებულია ბიომედიციური განცვლების მისამართლად 2020 წესტის საზოგადოება, განსაკუთრებით სისტემები, რომლებიც ტერმინოლოგიური განცვლების საზოგად ყველა შემთხვევაში ტრანფორმეტრის აქტიქტიქტურის არქტიქტურაცია იყენებულია და ჩვენ განსხვავებული სტრატიქტურაციების გახსნა დიომინის მონაცემებით ბიომედიცი ანგლისური-ბასკური ზოგისთვის, რომელიც ბიომედიციური დიომინში პარალელური კოპორაციის შესაძლებლობად, ჩვენ დავიწყეთ დიომინური განათლების მონაცემების შექმნა სინტე სისტემები, რომელიც ტერმინოლოგიაში და აბსტრაქტური განგორმაციაში ჩვენებული ინგლისური-ბასკური ენის ზოგიაში პირველი პირველ დაწყენებულია, ოთხი მოთავსწავლებელი შორის მუშაობაში, რომელიც ტერმინოლოგიის განგორმაციაზე 0. აბსტრაქტური გაგრძელება ანგლისურ-სპანელი ზოგლისთვის ჩვენი ჯგუფი ჩვენი გაგრძელება მეორე (BLEU=0,4498) სწორედ სიტყვების შემთხვევაში.', 'it': "Questo articolo descrive i sistemi presentati da Elhuyar al compito condiviso di traduzione biomedica 2020, in particolare i sistemi presentati nelle sottoattività della traduzione terminologica per l'inglese-basco e la traduzione astratta per l'inglese-basco e l'inglese-spagnolo. In tutti i casi è stata scelta un'architettura Transformer e abbiamo studiato diverse strategie per combinare dati open domain con dati biomedici a dominio per la costruzione dei corpora di formazione. Per la coppia inglese-basca, data la scarsità di corpi paralleli nel settore biomedico, abbiamo deciso di creare dati di formazione del dominio in modo sintetico. I sistemi presentati nelle sottoattività terminologiche e di traduzione astratta per la coppia di lingue inglese-basco si sono classificati al primo posto nei rispettivi compiti tra quattro partecipanti, raggiungendo una precisione di 0,78 per la traduzione terminologica e un BLEU di 0,1279 per la traduzione degli abstract. Nel compito di traduzione astratta per la coppia inglese-spagnola il nostro team si è classificato secondo (BLEU=0,4498) nel caso delle frasi OK.", 'kk': 'Бұл мақала, Эльхуяр 2020 жылы биомедикалық аудармалардың ортақ тапсырмасына жіберілген жүйелерді, әдетте ағылшын-баск және ағылшын-баск және ағылшын-ағылшын-испан тілдерінің терминологиялық аудармалардың астрон Барлық жағдайда Трансфер архитектурасы таңдалды және біз басқа стратегияларды оқу үшін домен деректерін биомедицина доменінің деректерін корпорасын құру үшін біріктіру үшін бір-бірі Ағылшын-Баск екі үшін биомедицина доменінде параллель корпораға жеткілікті болып, доменді оқыту деректерін синтетикалық түрде құру үшін таңдадық. Терминологияда және абстракты аудармалардың ағылшын- баск тілдерінің екеуі біріншіден төрт қатысушылардың арасындағы тапсырмаларда, терминологиялық аудармалардың 0, 78 дұрыстығын жеткізу және абстрактердің аудармаларының 0, 1279 BLEU. Ағылшын- испан тілдерінің абстракты аудару тапсырмасында біздің командамыз OK сөйлемелері болса екінші рет (BLEU=0, 4498).', 'lt': 'Šiame straipsnyje aprašomos Elhuyar programos „Biomedical Translation Shared Task 2020“ sistemos, konkrečiai sistemos, pateiktos anglų baskų ir anglų baskų terminologijos vertimo papunkčiuose, ir abstraktus anglų baskų ir anglų ispanų vertimas. Visais atvejais buvo pasirinkta Transformer architektūra ir mes ištyrėme įvairias strategijas, skirtas derinti atviros srities duomenis su biomedicinos srities duomenimis mokymo korporai statyti. Anglų ir baskų porai, atsižvelgiant į lygiagrečių korprų trūkumą biomedicinoje srityje, mes ketiname sintetiniu būdu sukurti domeno mokymo duomenis. Terminologijoje ir abstraktuose vertimo papunkčiuose pateiktos sistemos anglų ir baskų kalbų porai pirmą kartą priskiriamos prie jų atitinkamų užduočių tarp keturių dalyvių, o terminologijos vertimo tikslumas – 0,78, o abstraktų vertimo BLEU – 0,1279. Abstraktinėje anglų ir ispanų porai skirtoje vertimo užduotyje mūsų komanda buvo antroji (BLEU=0,4498) OK sakinių atveju.', 'mk': 'Оваа статија ги опишува системите пренесени од Елхујар на Соделената задача за биомедицински превод за 2020 година, специфично системите презентирани во подзадачите на терминолошкиот превод на англиско-баск и апстрактен превод на англиско-баск и англиско-шпански. Во сите случаи беше избрана трансформарна архитектура и ние проучувавме различни стратегии за комбинирање на податоци од отворени домени со податоци од биомедицински домени за изградба на обуката корпора. За англиско-баските парови, со оглед на недостатокот на паралелни корпора во биомедицинскиот домен, ние сакавме да создадеме податоци за обука на домени на синтетички начин. Системите презентирани во терминологијата и апстрактните преводи за парот англиско-баски јазик се рангираа прво во своите задачи меѓу четири учесници, постигнувајќи 0,78 точност за терминолошки превод и БЛЕ од 0,1279 за превод на апстракти. Во апстрактната преводна задача за англиско-шпанскиот пар нашиот тим се рангираше втор (БЛЕУ=0,4498) во случајот на ОК реченици.', 'ml': 'ഈ ലിപ്പോര്\u200dട്ടില്\u200d എല്\u200dഹാര്\u200d 2020 ബിയോമിക്കല്\u200d പരിഭാഷണത്തിലേക്ക് നല്\u200dകിയ സിസ്റ്റമുകള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. പ്രത്യേകിച്ച് ഇംഗ്ലീഷ്- ബാസ്കിന്റെ ഇ എല്ലാ കാര്യങ്ങളിലും ഒരു ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആര്\u200dക്ടിക്കേഷന്\u200d തെരഞ്ഞെടുക്കപ്പെട്ടിരുന്നു. പരിശീലന കോര്\u200dപ്പോരയില്\u200d പണിയാന്\u200d  ഇംഗ്ലീഷ്-ബാസ്ക് ജോടികള്\u200dക്ക്, ബൈയോമിക്കല്\u200d ഡൊമെയിനിലെ പാരാളല്\u200d കോര്\u200dപ്പോറിയുടെ പേടിയില്\u200d കൊണ്ട്, ഞങ്ങള്\u200d ഡൊമെയിന്\u200d ട്രെ ഇംഗ്ലീഷ്- ബാസ്ക് ഭാഷയുടെ ജോടികള്\u200dക്കായി ടെര്\u200dമിനോളജിയിലും അബ്രാക്ട്രാക്ട് പരിഭാഷണത്തിന്റെ സബ്ട്രാജ്യങ്ങളിലും കൊടുത്ത സിസ്റ്റുകള്\u200d ആദ്യം നാലു പങ്കാളികളുടെ ഇട ഇംഗ്ലീഷ്-സ്പാനിഷ് ജോടികള്\u200dക്കുള്ള അബ്രാക്ട്രാക്ട് പരിഭാഷണ ജോലിയില്\u200d നമ്മുടെ ടീം രണ്ടാമത്തെ റാങ്ങ് ചെയ്തു (ബില', 'no': 'Denne artikkelen beskriver systema som Elhuyar sender til den delte oppgåva for biomedisinsk omsetjing 2020, spesielt systema som er presentert i underoppgåva av terminologisk omsetjing for engelsk-bask og abstrakt omsetjing for engelsk-bask og engelsk-spansk. I alle tilfellene vart eit Transformeringsarkitektur valt, og vi studerte ulike strategiar for å kombinere opne domenedata med biomediske domenedata for å bygge opplæringskorpora. For den engelske-basske paren, som gjev feil av parallelle korpora i biomedisinske domene, har vi sett opp for å laga domeneopplæringsdata på ein syntetisk måte. Systema som er presentert i terminologien og abstrakt omsetjingssubspørsmål for engelsk-bask språkopla først rangerte i dei tilhøyrande oppgåva blant fire deltakarane, og fører til 0,78 nøyaktig for terminologisk omsetjing og ein BLEU av 0,1279 for omsetjinga av abstraktar. I den abstrakte omsetjinga for engelsk-spansk paren vår gruppa rangerte andre (BLEU=0,4498) i tilfelle til OK setningar.', 'mt': 'Dan l-artikolu jiddeskrivi s-sistemi ppreżentati minn Elhuyar għall-2020 Biomedical Translation Shared Task, speċifikament is-sistemi ppreżentati fis-sottomistoqsijiet tat-traduzzjoni terminoloġika għall-Ingliż-Bask u traduzzjoni astratta għall-Ingliż-Bask u l-Ingliż-Spanjol. Fil-każijiet kollha ntgħa żlet arkitettura Transformer u studjajna strateġiji differenti biex nikkombinaw dejta tad-dominju miftuħ ma’ dejta tad-dominju bijomediku għall-bini tal-korpora tat-taħriġ. Għall-par Ingliż-Bask, minħabba l-iskarsezza ta’ korpora parallel a fid-dominju bijomediku, a ħna bdejna nħolqu dejta dwar it-taħriġ tad-dominju b’mod sintetiku. Is-sistemi ppreżentati fit-terminoloġija u s-sottotalbiet astratti tat-traduzzjoni għall-par tal-lingwa Ingliż-Baska kklassifikati l-ewwel fil-kompiti rispettivi tagħhom fost erba’ parteċipanti, li kisbu preċiżjoni ta’ 0.78 għat-traduzzjoni tat-terminoloġija u BLEU ta’ 0.1279 għat-traduzzjoni tal-astratti. Fil-kompitu ta’ traduzzjoni astratt għall-par Ingliż-Spanjol it-tim tagħna kklassifika t-tieni (BLEU=0.4498) fil-każ ta’ sentenzi OK.', 'mn': 'Энэ баримт Эльхуяр 2020 оны биологийн эрүүл мэндийн хөрөнгө оруулагдсан системийг тодорхойлж байна. Ялангуяа Англи-Баск, Англи-Баск, Англи-Испан хэлний хэлний терминологийн хөрөнгө оруулагдсан системүүд. Бүх тохиолдолд Трансформер архитектур сонгогдсон бөгөөд бид өөр өөр стратегийг судалсан бөгөөд сургалтын корпора бүтээхэд биологийн эмнэлгийн мэдээллүүдтэй холбоотой. Англи-Баск хоёрын хувьд биологийн эрүүл мэндийн холбоотой параллел корпора багасгал байхад бид холбоотой сургалтын өгөгдлийг синтетик аргаар бий болгож байлаа. Терминологид харуулсан системүүд нь англи-Баск хэл хоёрын хувьд хамгийн түрүүнд 4 оролцогчдын тухай ажиллагаанд анх дүрслэгдсэн бөгөөд 0.78 терминологийн хөгжлийн зөв болон 0.1279 BLEU гэх зөв ажиллагааг гаргасан. Англи-Испанийн хоёр хоёрын abstract translation task дээр бидний баг хоёр дахь (BLEU=0.4498) нь ОК өгүүлбэрийн тухай.', 'pl': 'Niniejszy artykuł opisuje systemy zgłoszone przez Elhuyar do 2020 Biomedicznego Translation Shared Task, w szczególności systemy prezentowane w podzadaniach tłumaczenia terminologii dla angielsko-baskijskiego oraz abstrakcyjnego tłumaczenia dla angielsko-baskijskiego i angielsko-hiszpańskiego. We wszystkich przypadkach wybrano architekturę Transformera i zbadaliśmy różne strategie łączenia danych otwartych domen z danymi domen biomedycznych do budowy korpusów szkoleniowych. Dla pary angielsko-baskijskiej, biorąc pod uwagę niedobór równoległych korpusów w dziedzinie biomedycznej, postanowiliśmy tworzyć dane treningowe domeny w sposób syntetyczny. Systemy prezentowane w podzadaniach terminologicznych i abstrakcyjnych dla pary języków angielsko-baskijskich zajęły pierwsze miejsce w swoich zadaniach wśród czterech uczestników, osiągając dokładność 0,78 dla tłumaczenia terminologii oraz BLEU 0,1279 dla tłumaczenia abstrakcji. W abstrakcyjnym zadaniu tłumaczenia dla pary angielsko-hiszpańskiej nasz zespół zajął drugi miejsce (BLEU=0.4498) w przypadku zdań OK.', 'sr': 'Ovaj članak opisuje sisteme koje je Elhuyar predao zajedničkom zadatku za biomedicinsku prevod 2020. godine, posebno sustave koje su predstavljeni u podstavljanju prevoda terminologije za engleskog baskog i apstraktan prevod za engleskog baskog i engleskog španjolskog. U svim slučajevima je izabrana arhitektura transformera i proučavali smo različite strategije za kombinaciju otvorenih podataka domena sa podacima biomedicinskih domena za izgradnju treninga korpore. Za engleski-baskijski par, s obzirom na nedostatak paralelnog korporacije u biomedicinskom domenu, nastavili smo da stvorimo podatke o obuci domena na sintetički naèin. Sistemi koji su predstavljeni u terminologiji i apstraktivnim prevodnim suptraktama za pair engleskog-baskijskog jezika prvi su u svojim odgovarajućim zadacima među četiri sudionika, ostvarili točnost za prevod terminologije 0,78 i BLEU od 0,1279 za prevod abstraktata. U apstraktivnom prevodnom zadatku za engleski-španjolski par naš tim je bio drugi (BLEU=0,4498) u slučaju OK rečenica.', 'si': 'මේ ලේඛනය ප්\u200dරවේශනය කරනවා ElHuyar වලින් ප්\u200dරවේශණ පද්ධතිය යුද්ධ කරලා ඉංග්\u200dරීසිය-බාස්ක් වලින් ඉංග්\u200dරීසිය-බාස්ක් වලින් ඉංග්\u200dරීසියාන හැම ප්\u200dරශ්නයක්ම වෙනස් විදියට ට්\u200dරාන්ෆර් ස්ථාපනයක් තෝරාගත්තා, අපි වෙනස් ප්\u200dරශ්නයක් අධ්\u200dයාපනය කරලා තිය ඉංග්\u200dරීසි-බාස්ක් ජෝඩාවෙන්, ජීවිත වෛද්\u200dය ප්\u200dරදේශයේ සමාන්\u200dය කොර්පොරාගේ අවශ්\u200dයතාවක් දෙන්න, අපි ප්\u200dරදේශයේ ප The systems presed in the Terminal ology and extract translation subtascs for the English-Basque language pare ranged first in the cient roles of the 4partints, achiachiaching 0.78 Precracy for Terminal translation and a BLUE of 0.1279 for the translation of extratracts. ඉංග්\u200dරීස්-ස්පැනිස් ජෝඩියට අභිවාදක වැඩේ අපේ කණ්ඩායමේ දෙවෙනි කාර්යය (BLUE=0.4498) හොඳ වාක්ය වලට.', 'ro': 'Acest articol descrie sistemele prezentate de Elhuyar la sarcina comună de traducere biomedicală 2020, în special sistemele prezentate în subsarcinile traducerii terminologice pentru limba engleză-bască și traducerea abstractă pentru limba engleză-bască și engleză-spaniolă. În toate cazurile a fost aleasă o arhitectură Transformer și am studiat diferite strategii pentru a combina datele deschise cu domeniul biomedical pentru construirea corporelor de formare. Pentru perechea engleză-bască, având în vedere lipsa corporelor paralele în domeniul biomedical, ne-am propus să creăm date de formare a domeniului într-un mod sintetic. Sistemele prezentate în subsarcinile terminologice şi abstracte pentru perechea de limbi engleză-bască s-au clasat pe primul loc în sarcinile lor respective în rândul a patru participanţi, obţinând acurateţe de 0,78 pentru traducerea terminologiei şi o BLEU de 0,1279 pentru traducerea abstractelor. În sarcina de traducere abstractă pentru perechea engleză-spaniolă echipa noastră s-a clasat pe locul doi (BLEU=0.4498) în cazul propozițiilor OK.', 'sv': 'I den här artikeln beskrivs de system som Elhuyar lämnat in till 2020 års gemensamma uppgift för biomedicinsk översättning, särskilt de system som presenteras i underuppgifterna för terminologiöversättning för engelsk-baskisk och abstrakt översättning för engelsk-baskisk och engelsk-spanska. I samtliga fall valdes en Transformer arkitektur och vi studerade olika strategier för att kombinera öppen domändata med biomedicinsk domändata för att bygga träningscorpora. För det engelsk-baskiska paret, med tanke på bristen på parallella corpora inom den biomedicinska domänen, bestämde vi oss för att skapa domänträningsdata på ett syntetiskt sätt. Systemen som presenteras i underuppgifterna för terminologi och abstrakt översättning för det engelsk-baskiska språkparet rankades först i sina respektive uppgifter bland fyra deltagare, vilket uppnådde 0,78 noggrannhet för terminologiöversättning och en BLEU på 0,1279 för översättning av abstrakt. I den abstrakta översättningsuppgiften för det engelsk-spanska paret rankades vårt team tvåa (BLEU=0,4498) när det gäller OK meningar.', 'so': 'Warqadan wuxuu ku qoran yahay nidaamka Elhuyar u soo dhiibay 2020 Biomedical tarjumaadda Shared Shaqada, gaar ahaan nidaamka lagu soo qoray subtasyada tarjumaadda terminology ee Ingiriis-Basque iyo abstract tarjumaadda Ingiriis-Basque iyo Ingiriis-Spanish. Xaaladaha oo dhan waxaa la doortay dhismaha turjumista, waxaana baranay strategiyo kala duduwan si aan u soo wada ururiyo macluumaad furan oo lagu soo bandhigi karo macluumaadka dawooyinka ee dawlada si loo dhiso shirkadda waxbarashada. Jirta Ingiriiska-Basque, sababtoo ah baaritaanka shirkadda lambarka ah ee gudaha caafimaadka, waxaan u qornay in lagu sameyno macluumaad ku tababarida domain si qaliin ah. Isticmaalka ku qoran jardiino-terminology iyo abstract samooyin lagu qoray afka Ingiriis-Basque labadooda oo ugu horraysa hawshooyinkooda afarta ka qayb ah, waxayna gaadhaan 0.78 sax u ah turjumidda terminology iyo BLEU oo 0.1279 ku qoran turjumaadda abstracts. Shaqada abstract turjumista ee Ingiriis-Spanish labadiisa koox ayaa kooxdayaga ka soo baxay labaad (BLEU=0.4498) xaalada OK.', 'ms': 'Artikel ini menggambarkan sistem yang dihantar oleh Elhuyar kepada Tugas Berkongsi Terjemahan Biomedis 2020, khususnya sistem yang dihantar dalam subtaskan terjemahan terminologi untuk terjemahan Bahasa Inggeris dan abstrak untuk Bahasa Inggeris dan Bahasa Inggeris-Sepanyol. Dalam semua kes, arkitektur Transformer telah dipilih dan kami mempelajari strategi berbeza untuk menggabungkan data domain terbuka dengan data domain biomedikal untuk membina korpora latihan. Untuk pasangan Inggeris-Bask, mengingat kekurangan korpra selari dalam domain biomedis, kami bertujuan untuk mencipta data latihan domain dengan cara sintetik. Sistem yang dipaparkan dalam terminologi dan subtaskan terjemahan abstrak untuk pasangan bahasa Bahasa Inggeris-Bask berturut pertama dalam tugas masing-masing diantara empat peserta, mencapai ketepatan 0.78 untuk terjemahan terminologi dan BLEU 0.1279 untuk terjemahan abstrak. Dalam tugas terjemahan abstrak untuk pasangan Bahasa Inggeris-Sepanyol pasukan kami berturut kedua (BLEU=0.4498) dalam kes kalimat OK.', 'ur': 'یہ لکھا ہے کہ اِلهویر نے 2020 بیویڈیسی ترجمہ شریک ٹاکس کے لئے پیش کیا ہے، مخصوصاً انگلیسی-باسک اور انگلیسی-باسک اور انگلیسی-اسپانیایی کے لئے ٹیکرولوژی ترجمہ کے مطابق پیش کیے جاتے ہیں. ہر قسم میں ایک ٹرنفسر معمار کا انتخاب کیا گیا تھا اور ہم نے مختلف استراتژیکوں کا مطالعہ کیا تھا کہ روشن ڈومین ڈومین ڈاٹی کے ساتھ آغاز ہونے کے لئے تطالعہ کورپورا بنانے کے لئے۔ انگلیسی-باسکی جوڑے کے لئے، بیویڈیسی ڈومین میں parallel corpora کا کمزور دیا گیا تھا، ہم نے ڈومین کی تربیت ڈاٹی بنانے کے لئے ایک سینٹیسی طریقہ سے استعمال کیا۔ ترمینلوژی میں پیش کیے گئے سیستموں اور غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر انگلیسی-اسپانیایی جوڑوں کے لئے مختلف ترجمہ کا کام میں ہماری تیم ٹھیک جماعتوں کے مطابق دوسری (BLEU=0.4498) راندہ کیا گیا۔', 'ta': '@ info அனைத்து நிகழ்ச்சிகளிலும் ஒரு மாற்று உருவாக்கியம் தேர்ந்தெடுக்கப்பட்டது மற்றும் நாங்கள் வேறு திறந்த டோமைன் தகவல்களை ஜியோமரிக ஜோடி ஆங்கிலம்- பாஸ்க் ஜோடி, உயிரியல் மருத்துவதளத்தில் இணைய நிறுவனத்தை கொடுத்தால், நாம் டோமைன் பயிற்சி தகவலை ஒரு தொடர்ந்து முற ஆங்கிலத்தில்- பாஸ்க் மொழியில் ஜோடி முதலில் கொடுக்கப்பட்ட முறையியல் மற்றும் ஒதுக்கி மொழிபெயர்ப்பு துணை பணிகளில் உள்ள அமைப்புகள் முதலில் நான்கு பங்கீட்டாளர்களுக்கு  ஆங்கிலம்- ஸ்பானிஷ் ஜோடிக்கான ஒப்பிராக்ட் மொழிபெயர்ப்பு பணியில் எங்கள் குழு இரண்டாவது வாக்கியம் (BLEU=0. 4498) சரியான வா', 'uz': "Name Va barcha holatda, Transfer arkitektika tanlangan va biz o'rganish kompaniya uchun ochiq domen maʼlumotini birlashtirish uchun boshqa strategiyalarni o'rganamiz. Ingliz-Baski ikki ikkita so'zlari uchun biomediya domenasidagi parallel kompaniya haqida yaratganda, biz domen taʼminlovchi maʼlumotni bir tizimda yaratishga tayyorlamiz. Name Inglizcha-Ispanchaga o'rganish vazifani abstract tarjima qilish vazifasi o'xshash soʻzlar davomida guruhimiz ikkinchi soniyada (BLEU=0.4498).", 'vi': 'Bài viết này mô tả những hệ thống mà Elhuyar đã gửi cho công tác "Khoa học dược học đôi mươi" Trong mọi trường hợp, một kiến trúc biến hình đã được chọn và chúng tôi đã nghiên cứu các chiến lược khác nhau để kết hợp dữ liệu miền mở với nội quy sinh học để xây dựng tập đoàn. Với cặp đôi Anh-Basque, vì sự hạn chế của chữ "Bằng hữu song" trong lĩnh vực sinh học, chúng tôi đã lên kế hoạch tạo ra dữ liệu đào tạo miền theo một cách tổng hợp. Các hệ thống được bảo tới lời phiên dịch sở được phân ưu tiên tiên cho các tiếp ngôn ngữ Anh-Basque và đặt đầu tiên trong một bộ phẩn tham chiến của học, đã có một sự chính xác 0.78 về tiết thách sự tiết củ Trong nhiệm vụ phiên dịch trừu tượng cho cặp Anh-Tây Ban Nha đội chúng ta xếp hạng thứ hai (bleU=0.498) trong trường hợp có các câu « OK ».', 'da': 'Denne artikel beskriver de systemer, Elhuyar har indsendt til 2020 Biomedicinsk Translation Shared Task, specielt de systemer, der præsenteres i underopgaverne for terminologioversættelse til engelsk-baskisk og abstrakt oversættelse til engelsk-baskisk og engelsk-spansk. I alle tilfælde blev der valgt en Transformer arkitektur, og vi undersøgte forskellige strategier til at kombinere open domain data med biomedicinske domænedata til opbygning af træningskorpora. For det engelsk-baskiske par satte vi os i betragtning af knapheden på parallelle corpora på det biomedicinske domæne for at skabe domænetræningsdata på en syntetisk måde. De systemer, der præsenteres i underopgaverne terminologi og abstrakt oversættelse for det engelsk-baskiske sprogpar, rangerede første i deres respektive opgaver blandt fire deltagere, idet de opnåede 0,78 nøjagtighed for terminologioversættelse og en BLEU på 0,1279 for oversættelse af abstracts. I den abstrakte oversættelsesopgave for det engelsk-spanske par rangerede vores team andenpladsen (BLEU=0,4498) i tilfælde af OK sætninger.', 'nl': "Dit artikel beschrijft de systemen die Elhuyar heeft ingediend voor de 2020 Biomedische Translatie Shared Task, met name de systemen gepresenteerd in de subtaken van terminologie vertaling voor Engels-Baskisch en abstracte vertaling voor Engels-Baskisch en Engels-Spaans. In alle gevallen werd gekozen voor een Transformer architectuur en we bestudeerden verschillende strategieën om open domein data te combineren met biomedische domein data voor het bouwen van de trainingscorpora. Voor het Engels-Baskische paar, gezien de schaarste aan parallelle corpora's in het biomedisch domein, gingen we op een synthetische manier domeintrainingsgegevens creëren. De systemen gepresenteerd in de subtaken terminologie en abstracte vertaling voor het Engels-Baskische taalpaar stonden op de eerste plaats in hun respectieve taken onder vier deelnemers, met een nauwkeurigheid van 0,78 voor terminologie vertaling en een BLEU van 0,1279 voor de vertaling van abstracten. In de abstracte vertaaltaak voor het Engels-Spaanse paar werd ons team tweede (BLEU=0.4498) in het geval van OK zinnen.", 'bg': 'В настоящата статия са описани системите, представени от Елхуяр по Споделената задача за биомедицински превод 2020 г., по-конкретно системите, представени в подзадачите за терминологичен превод за английски-баски и абстрактен превод за английски-баски и английски-испански. Във всички случаи беше избрана архитектура на трансформатора и изучихме различни стратегии за комбиниране на данни от отворен домейн с данни от биомедицински домейн за изграждане на обучителните корпуси. За английско-баската двойка, предвид оскъдността на паралелни корпуси в биомедицинската област, ние се постарахме да създадем данни за обучение в областта по синтетичен начин. Представените системи в подзадачите за терминология и абстрактен превод за англо-баскийската езикова двойка се класираха на първо място в съответните си задачи сред четирима участници, постигайки 0,78 точност за терминологичен превод и 0,1279 за превод на абстрактни резюмета. В задачата за абстрактен превод за англо-испанската двойка екипът ни се класира на второ място (при ОК изречения).', 'hr': 'Ovaj članak opisuje sustave koje je Elhuyar podnio zajedničkom zadatku za biomedicinski prevod 2020., posebno sustave koje su predstavljeni u podstavljanju prevoda terminologije za engleski-baskijski i apstraktan prevod za engleski-baskijski i engleski-španjolski. U svim slučajevima je izabrana arhitektura transformera i proučavali smo različite strategije za kombinaciju otvorenih podataka domena s podacima biomedicinskih domena za izgradnju obuke. Za engleski-baskijski par, s obzirom na nedostatak paralelnog korporacije u biomedicinskom domenu, smislili smo da stvorimo podatke o obuci domena na sintetički način. Sistemi koji su predstavljeni u terminologiji i apstraktivnim prevodnim suptraktama za pair engleskog-baskijskog jezika prvi su u svojim odgovarajućim zadatkima među četiri sudionika, ostvarili točnost za prevod terminologije 0,78 i BLEU od 0,1279 za prevod abstraktata. U apstraktnom prevodnom zadatku za engleski-španjolski par naš tim je bio drugi (BLEU=0,4498) u slučaju OK rečenica.', 'de': 'Dieser Artikel beschreibt die Systeme, die Elhuyar im Rahmen der 2020 Biomedical Translation Shared Task eingereicht hat, insbesondere die Systeme, die in den Teilaufgaben der Terminologie-Übersetzung für Englisch-Baskisch und der abstrakten Übersetzung für Englisch-Baskisch und Englisch-Spanisch vorgestellt werden. In allen Fällen wurde eine Transformer-Architektur gewählt und wir untersuchten verschiedene Strategien, Open-Domain-Daten mit biomedizinischen Domänendaten für den Aufbau der Trainingskorpora zu kombinieren. Für das englisch-baskische Paar haben wir angesichts der Knappheit paralleler Korpora im biomedizinischen Bereich versucht, Domänentrainingsdaten auf synthetische Weise zu erstellen. Die Systeme, die in den Teilaufgaben Terminologie und abstrakte Übersetzung für das englisch-baskische Sprachpaar vorgestellt werden, rangierten bei ihren jeweiligen Aufgaben unter vier Teilnehmern an erster Stelle und erreichten eine Genauigkeit von 0,78 und eine BLEU von 0,1279 für die Übersetzung von Abstracts. Bei der abstrakten Übersetzungsaufgabe für das englisch-spanische Paar belegte unser Team den zweiten Platz (BLEU=0.4498) bei OK-Sätzen.', 'ko': '본고는 Elhuyar가 2020 생물의학 번역 공유 임무에 제출한 시스템, 특히 영어 바스크어 용어 번역과 영어 바스크어와 영어 스페인어 요약 번역 하위 임무에 나타난 시스템을 묘사한다.모든 상황에서 우리는 Transformer 구조를 선택했고 개방 분야 데이터와 생물의학 분야 데이터를 결합시키는 다양한 전략을 연구하여 훈련 자료 라이브러리를 구축했다.영국 바스케인에 대해 생물의학 분야에 평행어료고가 부족하다는 점을 감안하여 우리는 종합적인 방식으로 분야 훈련 데이터를 만들기 시작했다.참가자 4명 중 영어-바스크어 쌍의 용어와 요약 번역 하위 임무에 나타난 시스템은 각자의 임무 중 1위, 용어 번역의 정확도는 0.78, 요약 번역의 BLEU는 0.1279로 나타났다.영어-스페인어 쌍의 추상적 번역 임무 중 우리 팀은 OK 문장에서 2위(BLEU=0.4498)를 차지했다.', 'fa': 'این مقاله سیستم\u200cهایی را که توسط الهویار به دنبال ترجمه بیوژیک بیوژیک بیوژیک ۲۰۰۲ ارائه می\u200cدهد، مخصوصا سیستم\u200cهایی که توسط ترجمه\u200cشناسی برای ترجمه\u200cهای انگلیسی-باسک و ترجمه\u200cهای مطلق برای انگلیسی-باسک و انگلیسی- در همه موارد یک معماری تغییر\u200cپذیر انتخاب شد و ما استراتژی\u200cهای مختلف را مطالعه کردیم تا داده\u200cهای دامنی باز با داده\u200cهای دامنی بیولوپزشکی برای ساختن شرکت آموزش را ترکیب کنیم. برای جفت انگلیسی-باسک، به خاطر کمبود شرکت پارالی در دامنۀ بیولوژیک، ما برای ایجاد داده های آموزش دامنی به طریق سینتاتیک شروع کردیم. سیستم\u200cهایی که در ترمینالوژی و ترجمه\u200cهای ابتدایی برای جفت زبان انگلیسی-باسکی ارائه داده شده\u200cاند، برای جفت زبان انگلیسی و باسکی اول در کارهای مختلف خود در میان چهار شرکتگران، به رسیدن 0.78 دقیق ترجمه\u200cهای ترمینالوژی و BLEU از 0.1279 برای ترجمه\u200cهای ابتدایی. در مورد جفت\u200cهای انگلیسی-اسپانیایی، تیم ما در مورد جمله\u200cهای خوب، دوم (BLEU=0.4498) درجه\u200cی ترجمه\u200cای مطلق بود.', 'id': 'Artikel ini menjelaskan sistem yang dihantar oleh Elhuyar ke Tugas Bergabung Translasi Biomedis 2020, khususnya sistem yang dihantar dalam subtasks terjemahan terminologi untuk Bahasa Inggris dan terjemahan abstrak untuk Bahasa Inggris dan Bahasa Inggris-Spanyol. Dalam semua kasus arsitektur Transformer dipilih dan kami mempelajari strategi yang berbeda untuk menggabungkan data domain terbuka dengan data domain biomedis untuk membangun korpora latihan. Untuk pasangan Inggris-Basque, mengingat kekurangan corpora paralel dalam domain biomedis, kami memulai untuk menciptakan data latihan domain dengan cara sintetis. Sistem yang diperkenalkan dalam terminologi dan subtasks abstrak terjemahan untuk pasangan bahasa Inggris-Bask ditandai pertama dalam tugas mereka di antara empat peserta, mencapai akurasi 0,78 untuk terjemahan terminologi dan BLEU 0,1279 untuk terjemahan abstrak. Dalam tugas terjemahan abstrak untuk pasangan bahasa Inggris-Spanyol tim kami ranked kedua (BLEU=0,4498) dalam kasus kalimat OK.', 'sw': 'Makala hii inaelezea mfumo uliotolewa na Elhuyar kwa Tafsiri ya Biomedica ya 2020, hususani mfumo uliotolewa katika mifumo ya kutafsiri utafiti wa kimataifa kwa ajili ya Kiingereza-Baski na Kiingereza. Katika hali zote, ujenzi wa zamani ulichaguliwa na tulisoma mbinu mbalimbali za kuunganisha data za wazi za ndani kwa ajili ya kujenga kampuni ya mafunzo. Kwa ajili ya wawili wa Kiingereza-Basque, kwa kuzingatia uharibifu wa makampuni yanayofanana katika maeneo ya kitabibu, tuliamua kutengeneza taarifa za mafunzo ya ndani kwa njia ya pamoja. Mfumo uliotolewa katika juhudi za kutafsiri kwa lugha ya Kiingereza-Basque ziliandikwa kwanza katika kazi zao za kuheshimika kati ya washiriki wanne, wakipata sahihi 0.78 kwa tafsiri ya uchunguzi na BLEU 0.1279 kwa ajili ya tafsiri ya abstracts. Katika jukumu la kutafsiri kwa ajili ya wawili wawili wa Kiingereza na Kihispania, timu yetu ilipandisha nafasi ya pili (BLEU=0.4498) katika kesi ya hukumu sawa.', 'af': "Hierdie artikel beskrywe die stelsels wat deur Elhuyar aan die 2020 Biomediese Vertaling Gedeelde Taak voorgeskryf is, spesifieke die stelsels wat in die onderstrekings van terminologies vertaling is vir EngelsBask en abstrakte vertaling vir EngelsBask en Engelsk-Spaanse voorgestel is. In alle gevalle was 'n Transformer-arkitektuur gekies en ons het verskillende strategies studeer om oop domein-data te kombinieer met biomediese domein-data vir die opvoering-korpora te bou. Vir die Engelse-Baske paar, gegee ons die skaamte van parallele korpora in die biomediese domein, het ons uitgestel om domein onderwerp data op 'n sintetiese manier te skep. Die stelsels wat in die terminologie en abstrakte vertaling voorgeskryf word, ondersoek ondersoek vir die Engelse-Baskie taal paar wat eerste in hulle respektiewe taak onder vier deelnaders rangeer het, tot 0.78 beskikbaarheid vir terminologie vertaling en 'n BLEU van 0.1279 vir die vertaling van abstrakte. In die abstrakte vertaling taak vir die Engels-Spaanse paar, ons span het tweede rangeer (BLEU=0.4498) in die geval van OK setings.", 'sq': 'Ky artikull përshkruan sistemet e paraqitura nga Elhuyar në detyrën e përbashkët të përkthimit Biomjekësor 2020, veçanërisht sistemet e paraqitura në nëndetyrat e përkthimit të terminologjisë për përkthimin anglisht-bask dhe abstrakt për anglisht-bask dhe anglisht-spanjoll. Në të gjitha rastet u zgjodh një arkitekturë Transformer dhe ne studiuam strategji të ndryshme për të kombinuar të dhënat e dominit të hapur me të dhënat e dominit biomedikal për ndërtimin e korprës së trajnimit. Për çiftin anglo-bask, duke pasur parasysh mungesën e korprave paralele në domenin biomedikal, ne vendosëm të krijojmë të dhënat e trajnimit në domeni në një mënyrë sintetike. Sistemet e paraqitura në terminologji dhe nënkërkesat abstrakte të përkthimit për çiftin gjuhë anglo-baske u renditën së pari në detyrat e tyre respektive midis katër pjesëmarrësve, duke arritur 0.78 saktësi për përkthimin e terminologjisë dhe një BLEU prej 0.1279 për përkthimin e abstraktëve. Në detyrën abstrakte të përkthimit për çiftin anglo-spanjoll ekipi ynë u rendit i dyti (BLEU=0.4498) në rastin e fjalëve OK.', 'am': 'ይህ ጽሑፍ የኤልሃር ወደ 2020 ቢዮሚክ ትርጉም የተሰኘውን ስርዓት ይዘረዝራል፡፡ በተለይም እንግሊዝኛ-ባስክ እና እንግሊዝኛ-ባስኪ እና እንግሊዝኛ-ስፓኒሽ በተርሚሎጂ ትርጉም ውስጥ የተገኘውን ስርዓቶች ይዘረዝራል፡፡ በሁሉም ጉዳይ የተመረጠው የፊደል አካውንት የተመረጠው እና የተከፈቱትን የዶሜን ዳታ ከbiomedical ዲሜን ዳታ ለመቀነስ የተለየን የጥያቄ ኮርፖርት ለመሥራት ተማርነው ነበር፡፡ ለኢንግሊዝኛ-ባስክ ሁለቶች፣ የbiomedical ኮርፖር ደካማነት ሰጥቷል፣ የዶሜን ትምህርት ዳታዎችን በመስናዊ መንገድ ለመፍጠር አቆየን፡፡ በተርሚኖሎጂ እና የኢንጂልኛ-ባስክ ቋንቋ-ቋንቋ ደብዳቤዎችን በመጀመሪያ በአራቱ ተጋሪዎች መካከል የተለየ ስርዓቶች ውስጥ የተመሳሳይ ስርዓት እና ለተርሚኖሎጂ ትርጉም 0.78 እርግዝነት ለማግኘት የBLEU 0.1279 ለመትርጉም ነው፡፡ የኢንግሊዝኛ-ስፓኒሽ ሁለታችንን በጥብቅ ትርጓሜ አድራሻ ውስጥ የደኅንነት ፍርድ በተደረገ ሁለተኛ (BLEU=0.4498)።', 'tr': 'Bu maksada Elhuyar tarapyndan 2020-nji ýylyň biomedical terjime paýlaşan zada gönderilen sistemleri, iňlisçe-bask we iňlis-bask we iňlisçe-espaýnça terjime edilýän terjime edilýän sistemleri tassyklaýar. Hemme durumda bir Transformer arhitektegi seçildi we biz başka bir strateji öwrendik bu şekilde birleştirmek üçin biyomedical domenin verileri ile birleştirdik. Iňlisçe-Bask çift üçin, biomedical sahypasynda parallel korporatyň ýetmegine garaşdyrylyp, sahypalary syntetik şeklinde üýtgetmek üçin guruldyk. Terminologiýada we abstrakt terjime edilen sistemalar Iňlisçe-bask dilleriniň çiftleri üçin ilkinji gezek 4 işgärli adamlar arasynda bellenilýär. 0.78 terminologiýa terjime etmek üçin dogrylygyna we 0.1279 bolan BLEU. Iňlisçe-ispanyýaly çiftleriň abstrakt terjime täblisasynda biziň toparymyz OK sözleriň ýagdaýynda ikinji sany (BLEU=0.4498).', 'az': 'Bu məktub, Elhuyar tərəfindən 2020-ci Biomedical Translation Shared Task tərəfindən göndərilən sistemləri, özlərinə də İngilizce-Bask və İngilizce-Bask və İngilizce-İspanyol tərəfindən göstərilən terminoloji tərəfindən tərəfindən istifadə edir. Bütün məsələlərdə Transformer arhitektarı seçildi və təhsil korporasını inşa etmək üçün a çıq domenin məlumatlarını biomedical domenin məlumatları ilə birləşdirmək üçün fərqli stratejilər təhsil etdik. İngilizce-Basque çift üçün, biomedical domeində paralel korporanın zəif olması üçün, domena təhsil məlumatlarını sintetik yolla yaratmaq üçün hazırladıq. Terminoloji və abstraktlı tercümədə göstərilən sistemlər İngilizce-Basque dil çiftləri üçün ilk dəfə dörd iştirakçıların arasında, terminoloji tercüməsi üçün 0,78 ədaləti və abstraktların tercüməsi üçün 0,1279 BLEU ilə dəyişdirildilər. İngiliz-İspanyol çiftlərinin abstraktlı tercümə işində bizim ekibimiz OK cümlələri olaraq ikinci dəf etdi (BLEU=0,4498).', 'hy': 'Այս հոդվածը նկարագրում է Էլուայրի կողմից 2020 թվականի կենսաբժշկական թարգմանման ընդհանուր հանձնարարության համակարգերը, հատկապես համակարգերը, որոնք ներկայացված են անգլերեն-բասկի տերմինոլոգիայի թարգմանման ենթաթերմաններում և անգլերեն-բասկի և Բոլոր դեպքերում ընտրվել է տրանսֆերմերների ճարտարապետություն և ուսումնասիրեցինք տարբեր ռազմավարություններ՝ համադրելու բաց տիեզերական տվյալները կենսաբժշկական տիեզերական տվյալների հետ ուսումնասիրելու համար: Անգլերեն-բասկի զույգի համար, հաշվի առնելով կենսաբժշկական ոլորտի զուգահեռ օրգանիզմի բացակայությունը, մենք սկսեցինք ստեղծել տիեզերքի ուսումնասիրության տվյալներ սինթետիկ կերպ: Տերմինոլոգիայի և վերացական թարգմանման ենթաթերթերում ներկայացված համակարգերը անգլերեն-բասկական զույգի համար առաջինը դասակարգեցին իրենց համեմատական խնդիրներում չորս մասնակիցների միջև, հասնելով 0.78 ճշգրիտության տերմինոլոգիայի թարգմանման համար, իսկ վերացական թարգմանման In the abstract translation task for the English-Spanish pair our team ranked second (BLEU=0.4498) in the case of OK sentences.', 'bn': 'এই প্রবন্ধটি ব্যাখ্যা করেছে যে ২০২০ সালের বিয়োমিকাল অনুবাদ শেয়ার করার জন্য এলাহারের প্রদান করা সিস্টেমগুলোর ব্যাখ্যা করেছে, বিশেষ করে ইংরেজী বাস্ক এবং ইংরেজ সকল ক্ষেত্রে একটি ট্রান্সফার্নাফারের কাঠামো নির্বাচিত হয়েছে এবং আমরা বিভিন্ন কৌশল পড়েছি যাতে বায়োমেডিকেল ডোমেইন ডাটা সংয ইংরেজি-বাস্ক জোড়ার জন্য, বায়োমেডিকেল ডোমেইনে প্যারালেল কোর্পোরার ভয়াবহতা দিয়ে আমরা ডোমেইনের প্রশিক্ষণের তথ্য সৃষ্টি করার জন ইংরেজি-বাস্ক ভাষার জন্য টার্মিনোলজি এবং বিভ্রান্ত অনুবাদের সাবট্যাক্সে প্রকাশিত সিস্টেম প্রথমে চারজন অংশগ্রহণকারীদের মধ্যে তাদের নিজেদের কাজে রান্না করা হয়েছ ইংরেজি-স্প্যানিশ জোড়ার জন্য বিভিন্ন অনুবাদের কাজে আমাদের দল দ্বিতীয় সেকেন্ড (বিলিউ=0.', 'bs': 'Ovaj članak opisuje sisteme koje je Elhuyar predao zajedničkom zadatku za biomedicinsku prevodu 2020. godine, posebno sustave koje su predstavljene u podizama prevoda terminologije za engleski-baskijski i apstraktan prevod za engleski-baskijski i engleski-španjolski. U svim slučajevima je izabrana arhitektura transformera i proučavali smo različite strategije za kombinaciju otvorenih podataka domena sa podacima biomedicinskih domena za izgradnju treninga. Za engleski-baskijski par, s obzirom na nedostatak paralelnog korporacije u biomedicinskom domenu, smislili smo da stvorimo podatke o obuci domena na sintetički način. Sistemi koji su predstavljeni u terminologiji i apstraktivnim prevodnim suptraktama za pair engleskog-baskijskog jezika prvi su u svojim odgovarajućim zadacima među četiri sudionika, ostvarili točnost za prevod terminologije 0,78 i BLEU od 0,1279 za prevod abstraktata. U apstraktivnom prevodnom zadatku za engleski-španjolski par naš tim je bio drugi (BLEU=0,4498) u slučaju OK rečenica.', 'cs': 'Tento článek popisuje systémy předložené Elhuyarem do 2020 Biomedical Translation Shared Task, konkrétně systémy prezentované v podúkolech překladu terminologie pro anglicko-baskičtinu a abstraktní překlad pro anglicko-baskičtinu a anglicko-španělštinu. Ve všech případech byla zvolena architektura Transformeru a studovali jsme různé strategie kombinování dat otevřené domény s biomedicínskými doménovými daty pro budování tréninkových korpusů. Pro anglicko-baskický pár, vzhledem k nedostatku paralelních korpusů v biomedicínské oblasti, jsme se rozhodli vytvořit doménová tréninková data syntetickým způsobem. Systémy prezentované v terminologických a abstraktních překladatelských dílčích úkolech pro anglicko-baskický jazykový pár se ve svých příslušných úkolech zařadily na první místo mezi čtyřmi účastníky a dosahovaly 0,78 přesnosti pro překlad terminologie a BLEU 0,1279 pro překlad abstraktů. V abstraktním překladu pro anglicko-španělský pár se náš tým dostal na druhé místo (BLEU=0.4498) v případě vět OK.', 'ca': "Aquest article descriu els sistemes presentats per Elhuyar a la tasca compartida de traducció biomèdica del 2020, específicament els sistemes presentats en les subtaskes de traducció terminològica per traducció anglès-vesca i abstracta per anglès-vesc i anglès-espanyol. In all cases a Transformer architecture was chosen and we studied different strategies to combine open domain data with biomedical domain data for building the training corpora.  Per al parell anglès-vasc, dada la escassetat de corpores parallels en el domini biomèdic, vam començar a crear dades d'entrenament de domini d'una manera sintètica. Els sistemes presents en la terminologia i les subtaskes abstractes de traducció del parell anglo-vasc es van classificar primer en les seves respectives tasques entre quatre participants, aconseguint una precisió de 0,78 per la traducció terminològica i un BLEU de 0,1279 per la traducció d'abstracts. En la tasca de traducció abstracta del parell anglès-espanyol, el nostre equip es va classificar segon (BLEU=0,4498) en el cas de frases OK.", 'et': 'Käesolevas artiklis kirjeldatakse Elhuyari poolt 2020. aasta biomeditsiinilise tõlke jagatud ülesandele esitatud süsteeme, täpsemalt süsteeme, mis on esitatud inglise-baski terminoloogilise tõlke alamülesannetes ning inglise-baski ja inglise-hispaania abstraktse tõlke alamülesannetes. Kõigil juhtudel valiti Transformer arhitektuur ja uurisime erinevaid strateegiaid avatud domeeniandmete ja biomeditsiiniliste domeeniandmete kombineerimiseks koolituskorporate ehitamiseks. Inglise-baski paari jaoks, arvestades paralleelsete korpuste nappust biomeditsiinivaldkonnas, püüdsime luua domeenikoolituse andmeid sünteetilisel viisil. Inglise-baski keele paari terminoloogia ja abstraktse tõlke alamülesannetes esitatud süsteemid olid nelja osaleja seas esimesed, saavutades terminoloogilise tõlke täpsuse 0,78 ja kokkuvõtete tõlke BLEU 0,1279. Inglise-hispaania paari abstraktse tõlke ülesandes oli meie meeskond OK lausete puhul teisel kohal (BLEU=0,4498).', 'fi': 'Tässä artikkelissa kuvataan Elhuyarin vuoden 2020 Biomedical Translation Shared Task -tehtävään toimittamat järjestelmät, erityisesti englannin-baskin terminologian käännöksen alatehtävissä sekä englannin-baskin ja englannin-espanjan abstraktikäännöksen alatehtävissä esitetyt järjestelmät. Kaikissa tapauksissa valittiin Transformer-arkkitehtuuri ja tutkittiin erilaisia strategioita avoimen verkkotunnuksen ja biolääketieteen verkkotunnuksen yhdistämiseksi koulutuskorpusten rakentamiseksi. Koska rinnakkaisia korpusia ei ole riittävästi biolääketieteen alalla, päätimme luoda englannin ja baskin parille synteettistä koulutusdataa. Englannin ja baskin kieliparin terminologian ja abstraktien käännösten alatehtävissä esitellyt järjestelmät sijoittuivat ensimmäisiksi tehtävissään neljän osallistujan joukossa, saavuttaen 0,78 tarkkuutta terminologian käännöksessä ja 0,1279 BLEU tiivistelmien käännöksessä. Englannin ja espanjan parin abstraktissa käännöstyössä tiimimme sijoittui toiseksi (BLEU=0,4498) OK lauseiden osalta.', 'ha': "Wannan makala na describe the system sent by Elihar to the 2020 Biomedical Translate Shared Takar, specific the system that was introduced in the subtasks of therminogy translation for English- Basque and abractly translation for English- Basque and English-spanish. A cikin duk hãli, an zãɓi wani matsayin Transformer, kuma mun karanta takiyaikin daban-dabam dõmin a koma data da ake buɗe Domen da data na kabarin da aka samu da data za'a yi amfani da firma. Ga nau'in Ingiriya-Basque, da aka yi na zartar da korana mai parallel cikin matsayin da aka haife shi, za'a sami komai da za'a sami danne danne tsarin Domen. @ label: listbox In the obract translation job for the English-spanish par team ranked the other (BLEU=0.4498) in the case of the right words.", 'jv': 'Artik iki oleh nggambaran sistem sing nyimpen ning elhujar kanggo 2020 Biyang dipunanggé Trabah Biyang Terjamahan, supayano sistem sing nyelarane ning tarjamahan kanggo tarjamahan kanggo ngilanggar-Basque karo perusahaan ingles-Basque karo ingles-Basque karo ingles-spanipas. In all Case a Transformer architecture was elected and we undered Variable Astres to combine open domain data with BIMED domain data for rebuking the Learning Body. Genjer neng Biwih-Basque, nambah kegambar uwong karo perusahaan nganggep banter Sistem sing ngewehi ning terminal karo tarjamahan sing perusahaan anyar tentang kanggo ingkang Basque Nang kelas mbukakipun pancening nggambar kanggo kelas ingkang-Spanish', 'sk': 'V tem članku so opisani sistemi, ki jih je Elhuyar predložil za skupno nalogo biomedicinskega prevajanja 2020, zlasti sistemi, predstavljeni v podnalogah terminološkega prevajanja za angleško-baskovščino in prevajanja povzetkov za angleščino-baskovščino in angleščino-španščino. V vseh primerih smo izbrali transformatorsko arhitekturo in preučili različne strategije za kombiniranje podatkov odprte domene z biomedicinskimi domenskimi podatki za gradnjo korpusov usposabljanja. Za angleško-baskovski par smo se zaradi pomanjkanja vzporednih korpusov na biomedicinskem področju odločili ustvariti podatke o domenskem usposabljanju na sintetičen način. Sistemi, predstavljeni v podnalogah terminološkega in abstraktnega prevajanja za angleško-baskovski jezikovni par, so se med štirimi udeleženci uvrstili na prvo mesto pri svojih nalogah, dosegli 0,78 točnosti terminološkega prevajanja in 0,1279 točnost pri prevajanju povzetkov. V prevajalski nalogi povzetka za angleško-španski par se je naša ekipa uvrstila na drugo mesto (BLEU=0,4498) v primeru OK stavkov.', 'he': 'המאמר הזה מתאר את המערכות שנשלחו על ידי Elhuyar למשימה המשותפת של התרגום ביורפואי 2020, במיוחד את המערכות שנמצאות בתת-שאלות של התרגום הטרמולוגי לאנגלית-בסקית ותרגום אסטרקט לאנגלית-בסקית ואנגלית-ספרדית. בכל מקרים נבחרה ארכיטקטורה טרנספורטרית ולמדנו אסטרטגיות שונות כדי לשלב נתונים בתחום פתוח עם נתונים בתחום ביורפואי לבניית גופורה האימונים. For the English-Basque pair, given the scarcity of parallel corpora in the biomedical domain, we set out to create domain training data in a synthetic way.  המערכות המוציאות בטרמונולוגיה והתרגומות המתוקפות של זוג שפת אנגלית-בסקית מוצבות ראשונה במשימותיהם בין ארבעה משתתפים, להשיג מדויקה 0.78 לתרגום הטרמונולוגי ולא BLEU של 0.1279 לתרגום של המתוקפות. In the abstract translation task for the English-Spanish pair our team ranked second (BLEU=0.4498) in the case of OK sentences.', 'bo': 'This article describes the systems submitted by Elhuyar to the 2020 Biomedical Translation Shared Task, specifically the systems presented in the subtasks of terminology translation for English-Basque and abstract translation for English-Basque and English-Spanish. In all cases a Transformer architecture was chosen and we studied different strategies to combine open domain data with biomedical domain data for building the training corpora. For the English-Basque pair, given the scarcity of parallel corpora in the biomedical domain, we set out to create domain training data in a synthetic way. དབྱིན་ཡིག་གི་བརྡ་བཀོད་དང་འཚོལ་བཤེར་གྱི་ཡིག་ཆའི་ནང་དུ་བཀོད་ཡོད་པའི་མ་ལག་གི་ཆ་འཕྲིན་ཡིན། ང་ཚོའི་དབྱིན་ཡིག་དང་སྒྲ་སྐད་ཀྱི་ཚིག་རྩལ་མེད་པའི་ལས་འགུལ་གྱི་ནང་དུ་ཚོ་ཁག་གི་ཆ་རྐྱེན་གྱི་ནང་དུ།'}
{'en': 'YerevaNN’s Systems for WMT20 Biomedical Translation Task : The Effect of Fixing Misaligned Sentence Pairs', 'ar': 'أنظمة YerevaNN لمهمة الترجمة الطبية الحيوية WMT20: تأثير إصلاح أزواج الجمل غير المحاذية', 'pt': 'Tarefa de tradução biomédica dos sistemas da YerevaNN para WMT20: O efeito da correção de pares de frases desalinhadas', 'fr': "Tâche de traduction biomédicale Systèmes pour WMT20 de YerevAnn\xa0: l'effet de la correction des paires de phrases mal alignées", 'es': 'Tarea de traducción biomédica de Sistemas para WMT20 de YerEvann: El efecto de arreglar pares de oraciones desalineados', 'ja': 'YerevaNNのWMT 20生物医学翻訳タスクのためのシステム：整列されていない文章ペアを修正する効果', 'zh': 'YerevaNN之WMT20生物医学译者,修复未齐句之效也', 'hi': 'WMT20 बायोमेडिकल अनुवाद कार्य के लिए YerevaNN की प्रणालियां: Misaligned वाक्य जोड़े को ठीक करने का प्रभाव', 'ru': "YerevaNN 's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'ga': 'Córais YerevaNN do Thasc Aistriúcháin Bithleighis WMT20: An Tionchar a Bhaineann le Péirí Pianbhreithe Mí-ailínithe a Shocrú', 'hu': 'YerevaNN WMT20 Bioorvosi fordítási feladata: A hibás ítéletpárok javításának hatása', 'el': 'Συστήματα βιοϊατρικής μετάφρασης του Γιερεβάν: Η επίδραση της διόρθωσης λανθασμένων ζευγαριών ποινών', 'kk': 'YerevaNN WMT20 биомедикалық аудару тапсырмасының жүйелері: Жұмысты түзету эффекті', 'it': "Attività di traduzione biomedica dei sistemi di YerevANN per WMT20: l'effetto della correzione delle coppie di frasi disallineate", 'ka': 'Name', 'lt': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'mk': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'ms': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'mt': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'mn': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'no': 'YerevaNN- systemet for WMT20 biomedisinsk omsetjingsverkt: Effekten for å fiksa feil justert setningsverkt', 'pl': 'Systemy EriwaNN do zadania tłumaczenia biomedycznego WMT20: Efekt naprawy niedopasowanych par zdań', 'ro': 'Sistemele YerevanNN pentru traducerea biomedicală WMT20 Sarcină: Efectul remedierii perechilor de sentințe nealiniate', 'so': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'sv': 'JerevaNNs system för WMT20 biomedicinsk översättning Uppgift: Effekten av att åtgärda felaktiga meningspar', 'ta': "WMT20 பியோமிடிக்கல் மொழிபெயர்ப்பு பணிக்கான YerevaNN' s Systems: Fixing தவறான வாக்குறிப்பு பேர்களின் விளைவு", 'ur': 'Name', 'ml': 'WMT20 ബിയോമിക്കല്\u200d പരിഭാഷണ കാര്യങ്ങള്\u200d', 'si': 'Name', 'sr': 'YerevaNN-ovi sistemi za WMT20 biomedicinski prevod zadatak: Efekt popravljanja nepravilnih pare kazne', 'vi': 'Hệ thống của Yerevann cho WM210 Dịch vụ sinh học: Hiệu ứng của đánh giá sai phiếu', 'uz': 'Name', 'bg': 'Системите на ЕревАН за задача за биомедицински превод: Ефектът от поправянето на неравновесени двойки присъди', 'da': 'JerevaNNs systemer til WMT20 biomedicinsk oversættelse opgave: Effekten af at rette fejljusterede sætningspar', 'nl': "YereaNN's systemen voor WMT20 Biomedische vertaaltaak: het effect van het oplossen van verkeerd uitgelijnde zinnenparen", 'ko': '에리온의 WMT20 생물의학 번역 임무 시스템: 문장이 맞지 않는 효과 복구', 'de': 'JerevaNNs Systeme für WMT20 Biomedical Translation Task: Der Effekt der Behebung falsch ausgerichteter Satzpaare', 'id': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'fa': 'سیستم\u200cهای YerevaNN برای ترجمه\u200cهای زیست پزشکی WMT20', 'sw': 'Mfumo wa YerevaNN kwa ajili ya kazi ya Tafsiri ya Biomedica ya WMT20: Effect s of Fixing Upinzani', 'hr': 'YerevaNN sustavi za WMT20 biomedicinski prevod zadatak: učinak popravljanja nepravilnih pare kazne', 'am': 'የYerevaNN Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs', 'tr': 'YerevaNN WMT20 Biomedical Terjime Görevi: The Effect of Fixing Misaligned Sentence Pairs', 'af': 'Name', 'sq': 'Sistemet e YerevaNN për detyrën e përkthimit Biomjekësor WMT20: Efekti i rregullimit të çifteve të dënimeve të gabuara', 'az': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned sentence Pairs", 'bn': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'bs': 'YerevaNN-ovi sustavi za WMT20 biomedicinski prevod zadatak: Efekt popravljanja nepravilnih pare kazne', 'hy': 'Յերվավան', 'ca': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs", 'cs': 'Systémy YerevNN pro biomedicínský překlad WMT20: Účinek opravy nesprávně zarovnaných větových párů', 'fi': 'YerevaNN:n järjestelmät WMT20 Biomedical Translation Task: Virheellisten lauseparien korjaamisen vaikutus', 'et': 'YerevANi süsteemid WMT20 biomeditsiinilise tõlke ülesandeks: valejoondunud lausepaaride parandamise mõju', 'jv': 'layers-action', 'ha': 'KCharselect unicode block name', 'sk': 'YerevaNN-jevi sistemi za nalogo biomedicinskega prevajanja WMT20: učinek popravljanja napačnih kazenskih parov', 'he': 'מערכות YerevaNN עבור משימה התרגום ביורפואי WMT20:', 'bo': "YerevaNN's Systems for WMT20 Biomedical Translation Task: The Effect of Fixing Misaligned Sentence Pairs"}
{'en': 'This report describes YerevaNN’s neural machine translation systems and data processing pipelines developed for WMT20 biomedical translation task. We provide systems for English-Russian and English-German language pairs. For the English-Russian pair, our submissions achieve the best BLEU scores, with enru direction outperforming the other systems by a significant margin. We explain most of the improvements by our heavy data preprocessing pipeline which attempts to fix poorly aligned sentences in the parallel data.\\rightarrowru direction outperforming the other systems by a significant margin. We explain most of the improvements by our heavy data preprocessing pipeline which attempts to fix poorly aligned sentences in the parallel data.', 'ar': 'يصف هذا التقرير أنظمة الترجمة الآلية العصبية وخطوط أنابيب معالجة البيانات الخاصة بـ YerevaNN والتي تم تطويرها لمهمة الترجمة الطبية الحيوية WMT20. نحن نقدم أنظمة لأزواج اللغتين الإنجليزية والروسية والإنجليزية والألمانية. بالنسبة للزوج الإنجليزي-الروسي ، حققت عروضنا أفضل درجات BLEU ، مع تفوق اتجاه en → ru على الأنظمة الأخرى بهامش كبير. نفسر معظم التحسينات من خلال خط أنابيب المعالجة المسبقة للبيانات الثقيلة لدينا والذي يحاول إصلاح الجمل المحاذاة بشكل سيئ في البيانات المتوازية.', 'fr': 'Ce rapport décrit les systèmes de traduction automatique neuronale de YerevAnn et les pipelines de traitement de données développés pour la tâche de traduction biomédicale WMT20. Nous fournissons des systèmes pour les paires de langues anglais-russe et anglais-allemand. Pour la paire anglais-russe, nos soumissions obtiennent les meilleurs scores BLEU, la direction en→ru surpassant les autres systèmes de manière significative. Nous expliquons la plupart des améliorations par notre lourd pipeline de prétraitement des données qui tente de corriger les phrases mal alignées dans les données parallèles.', 'es': 'Este informe describe los sistemas de traducción automática neuronal de YerEvanN y los canales de procesamiento de datos desarrollados para la tarea de traducción biomédica WMT20. Ofrecemos sistemas para la combinación de idiomas inglés-ruso e inglés-alemán. Para la pareja ruso-inglés, nuestras propuestas obtienen los mejores puntajes BLEU, con una dirección en→ru que supera a los demás sistemas por un margen significativo. Explicamos la mayoría de las mejoras de nuestra canalización de preprocesamiento de datos pesados, que intenta corregir frases mal alineadas en los datos paralelos.', 'pt': 'Este relatório descreve os sistemas de tradução automática neural da YerevaNN e os pipelines de processamento de dados desenvolvidos para a tarefa de tradução biomédica WMT20. Fornecemos sistemas para pares de idiomas inglês-russo e inglês-alemão. Para o par inglês-russo, nossas submissões alcançam as melhores pontuações BLEU, com direção en→ru superando os outros sistemas por uma margem significativa. Explicamos a maioria das melhorias pelo nosso pipeline de pré-processamento de dados pesado, que tenta corrigir frases mal alinhadas nos dados paralelos.', 'ja': 'このレポートでは、WMT 20生物医学翻訳タスクのために開発されたYerevaNNのニューラル機械翻訳システムとデータ処理パイプラインについて説明します。英語-ロシア語と英語-ドイツ語のペアのためのシステムを提供しています。英語とロシア語のペアでは、私たちの提案は最高のBLEUスコアを達成し、en→ ru方向は他のシステムを大幅に上回っています。私たちは、並列データ内の不適切に整列した文章を修正しようとする重いデータ前処理パイプラインによる改善のほとんどを説明します。', 'hi': 'यह रिपोर्ट YerevaNN के तंत्रिका मशीन अनुवाद प्रणालियों और WMT20 जैव चिकित्सा अनुवाद कार्य के लिए विकसित डेटा प्रसंस्करण पाइपलाइनों का वर्णन करती है। हम अंग्रेजी-रूसी और अंग्रेजी-जर्मन भाषा जोड़े के लिए सिस्टम प्रदान करते हैं। अंग्रेजी-रूसी जोड़ी के लिए, हमारी प्रस्तुतियां सबसे अच्छा BLEU स्कोर प्राप्त करती हैं, जिसमें en→ru दिशा एक महत्वपूर्ण मार्जिन से अन्य प्रणालियों को पछाड़ती है। हम अपने भारी डेटा प्रीप्रोसेसिंग पाइपलाइन द्वारा अधिकांश सुधारों की व्याख्या करते हैं जो समानांतर डेटा में खराब संरेखित वाक्यों को ठीक करने का प्रयास करता है।', 'zh': '本言YerevaNN为WMT20生物医学译者神经机器翻译系统数据处理管道。 共英语-俄语与英语-德语对。 其于英语 - 俄语也,言得至BLEU,en→ru方显优于他统。 繁数预处理管说多改,管道试修并行数。', 'ru': 'Этот отчет описывает системы нейронного машинного перевода YerevaNN и трубопроводы обработки данных, разработанные для задачи биомедицинского перевода WMT20. Мы предоставляем системы для англо-русских и англо-немецких языковых пар. Для английско-российской пары наши представления достигают лучших баллов BLEU, с направлением en→ru, превосходящим другие системы со значительным запасом. Большую часть улучшений мы объясняем нашим тяжелым конвейером предварительной обработки данных, который пытается исправить плохо выровненные предложения в параллельных данных.', 'ga': 'Déanann an tuarascáil seo cur síos ar chórais néar-aistriúcháin meaisín YerevaNN agus ar phíblínte próiseála sonraí a forbraíodh do thasc aistriúcháin bithleighis WMT20. Cuirimid córais ar fáil do phéirí teanga Béarla-Rúisis agus Béarla-Gearmáinis. Maidir leis an bpéire Béarla-Rúisis, sroicheann ár n-aighneachtaí na scóir BLEU is fearr, le treo en→ru ag feidhmiú níos fearr ná na córais eile le corrlach suntasach. Mínímid an chuid is mó de na feabhsuithe ag ár bpíblíne trom réamhphróiseála sonraí a dhéanann iarracht abairtí droch-ailínithe a shocrú sna sonraí comhthreomhara.', 'el': 'Η παρούσα έκθεση περιγράφει τα νευρωνικά συστήματα μηχανικής μετάφρασης και τους αγωγούς επεξεργασίας δεδομένων που αναπτύχθηκαν για την εργασία βιοϊατρικής μετάφρασης WMT20. Παρέχουμε συστήματα για ζεύγη αγγλικής-ρωσικής και αγγλικής-γερμανικής γλώσσας. Για το αγγλο-ρωσικό ζευγάρι, οι αιτήσεις μας επιτυγχάνουν τις καλύτερες βαθμολογίες της BLEU, με την εν ru κατεύθυνση να ξεπερνά σημαντικά τα άλλα συστήματα. Εξηγούμε τις περισσότερες από τις βελτιώσεις από τον αγωγό προεπεξεργασίας βαρέων δεδομένων που προσπαθεί να διορθώσει κακώς ευθυγραμμισμένες προτάσεις στα παράλληλα δεδομένα.', 'hu': 'Ez a jelentés bemutatja a YerevaNN idegi gépi fordító rendszereit és adatfeldolgozó csővezetékeit, amelyeket WMT20 orvosbiológiai fordítási feladatra fejlesztettek ki. Angol-orosz és angol-német nyelvpárok számára biztosítunk rendszereket. Az angol-orosz páros esetében beadványaink a legjobb BLEU pontszámot érik el, az en ru irányban jelentős mértékben felülmúlják a többi rendszert. A fejlesztések nagy részét a nehéz adatok előfeldolgozásával foglalkozó csatornánk magyarázza el, amely megpróbálja javítani a rosszul igazított mondatokat a párhuzamos adatokban.', 'kk': 'Бұл хабарлама WMT20 биомедикалық аудару тапсырмасы үшін жасалған YerevaNN невралдық машинаның аудару жүйелерін және деректерді өңдеу қабырғыларын таңдайды. Біз ағылшын- рус және ағылшын- неміс тілдерінің екі жүйелерін береміз. Ағылшын және руссиялық екеуі үшін біздің жұмыстарымыз ең жақсы BLEU нәтижелерін жеткізеді. Біздің жұмыстарымыз өзгертілген жұмыстардың артықшылығына артықшылық шект Біз қатты деректеріміздің көпшілігін параллель деректерінде жақсы түзетуге тырыстық.', 'lt': 'Šiame pranešime aprašomos YerevaNN nervinių mašinų vertimo sistemos ir duomenų apdorojimo vamzdynai, sukurti WMT20 biomedicinės vertimo užduotims atlikti. Mes sukuriame anglų-rusų ir anglų-vokiečių kalbų poroms skirtas sistemas. Anglų ir Rusijos poros atveju mūsų pasiūlymai pasiekia geriausius BLEU rezultatus, o en ru kryptimi kitų sistemų rezultatai gerokai viršija. Mes paaiškiname daugumą mūsų didelio duomenų apdorojimo vamzdyno patobulinimų, kurie bando nustatyti blogai suderintus sakinius lygiagrečiais duomenimis.', 'ka': 'ამ შეტყობინებაში, WMT20 ბიომედიციური გადაწყვეტილების სამუშაოდ განვითარებული მონაცემის ნეიროლური მაქინის გადაწყვეტილების სისტემი და მონაცემის გადაწყვე ჩვენ ინგლისური და ინგლისური და გერმანური ენის ზოგებისთვის სისტემები დავიყენებთ. ანგლისური-პროსური ზოგებისთვის ჩვენი წინაწერები უკეთესი ბლესური წინაწერებისთვის, რომელიც პროგრამის წინაწერებისთვის უფრო მნიშვნელოვანი სისტემის ჩვენ უფრო მეტი მოწყობილობას ჩვენი ძალიან მონაცემების გარემოქმედებით, რომელიც მოცდილობა გარემოქმედებით დასაწყებული სიტყვები პარალელი მონაცემებში.', 'mk': 'Овој извештај ги опишува нервните машински преведувачки системи на YerevaNN и гасоводите за обработување на податоци развиени за биомедицинската преведувачка задача на WMT20. Ние обезбедуваме системи за парови англиско-руски и англиско-германски јазик. За англиско-рускиот пар, нашите поднесувања ги постигнуваат најдобрите оценки на БЛЕУ, при што en ru насока ги надминува другите системи со значителна маргина. Ги објаснуваме поголемиот дел од подобрувањата од нашиот тежок гасовод за препроцес на податоци кој се обидува да ги поправи лошо изедначените реченици во паралелните податоци.', 'ml': '@ info ഞങ്ങള്\u200d ഇംഗ്ലീഷ് റഷ്യനും ഇംഗ്ലീഷ് ജര്\u200dമ്മന്\u200d ഭാഷ ജോടികള്\u200dക്ക് സിസ്റ്റമുണ്ട്. ഇംഗ്ലീഷ്-റഷ്യന്\u200d ജോട്ടികള്\u200dക്ക്, നമ്മുടെ കീഴ്പ്പെടുത്തുന്നത് ഏറ്റവും നല്ല ബില്ലൂ സ്കോര്\u200d നേടുന്നു. മറ്റു സിസ്റ്റത്തിന We explain most of the improvements by our heavy data preprocessing pipeline which attempts to fix poorly aligned sentences in the parallel data.', 'it': 'Questo rapporto descrive i sistemi neurali di traduzione automatica di YerevaNN e le pipeline di elaborazione dati sviluppate per il compito di traduzione biomedica WMT20. Forniamo sistemi per coppie di lingue inglese-russo e inglese-tedesco. Per la coppia inglese-russa, le nostre proposte raggiungono i migliori punteggi BLEU, con una direzione in ru che supera gli altri sistemi di un margine significativo. Spieghiamo la maggior parte dei miglioramenti apportati dalla pipeline di preelaborazione di dati pesanti che tenta di correggere frasi mal allineate nei dati paralleli.', 'mt': "This report describes YerevaNN's neural machine translation systems and data processing pipelines developed for WMT20 biomedical translation task.  Aħna nipprovdu sistemi għall-pari lingwistiċi Ingliż-Russu u Ingliż-Ġermaniż. Għall-par Ingliż-Russu, is-sottomissjonijiet tagħna jiksbu l-a ħjar punteġġi BLEU, b’direzzjoni en ru li taqbeż is-sistemi l-oħra b’marġini sinifikanti. Aħna nistpjegaw il-biċċa l-kbira tat-titjib permezz tal-pipeline tagħna ta’ pproċessar qawwi tad-dejta li tipprova tiffissa sentenzi mhux allinjati tajjeb fid-dejta parallela.", 'ms': "This report describes YerevaNN's neural machine translation systems and data processing pipelines developed for WMT20 biomedical translation task.  Kami menyediakan sistem untuk pasangan bahasa Inggeris-Rusia dan bahasa Inggeris-Jerman. Untuk pasangan Inggeris-Rusia, penghantaran kami mencapai skor BLEU terbaik, dengan arah en ru melebihi sistem lain dengan margin yang signifikan. Kami menjelaskan kebanyakan peningkatan dengan saluran paip pemprosesan data berat yang cuba untuk memperbaiki kalimat yang tidak sepadan dengan baik dalam data selari.", 'mn': 'Энэ мэдээллийг WMT20 биологийн эрүүл мэндийн хөгжлийн ажлын төлөө хөгжүүлсэн YerevaNN-ын мэдрэлийн машин хөгжлийн систем болон өгөгдлийн үйлдвэрлэлийн хоолойн шугамнуудыг тайлбарладаг. Бид Англи-Орос, Англи-Герман хэл хоёрын системийг хангадаг. Англи-Орос хоёрын хувьд бидний дэвшүүлэлт БЛЕУ-ын хамгийн сайн оноо гарч ирнэ. Бусад системүүдийг тодорхой хэмжээгээр илүү өндөр руу чиглэлт гарч ирнэ. Бид хүнд өгөгдлийн сайжруулалтын ихэнх сайжруулалтыг харуулж байна. Энэ нь параллель өгөгдлийн хувьд зөвхөн зөвхөн дүрслэгдсэн өгөгдлийг засах гэж оролдож байгаа.', 'no': 'Denne rapporten beskriver omsetjingssystemet for YerevaNN sin neuralmaskin og datahandsamingsrøyr utvikla for WMT20 biomedisinsk omsetjingssystem. Vi tilbyr systemet for engelsk- russisk og engelsk- tysk språk par. For engelsk-russisk par, søknadene våre oppnår dei beste BLEU-poeng, med en ru-retning som utfører dei andre systemene med ein signifikant margin. Vi forklarer dei fleste forbedringane av våre kraftige data som prøver å retta ugyldig justerte setningar i parallelle data.', 'ro': 'Acest raport descrie sistemele neurale de traducere automată ale YerevaNN și conductele de prelucrare a datelor dezvoltate pentru sarcina de traducere biomedicală WMT20. Oferim sisteme pentru perechile de limbi engleză-rusă și engleză-germană. Pentru perechea engleză-rusă, depunerile noastre obțin cele mai bune scoruri BLEU, direcția en ru depășind cu o marjă semnificativă celelalte sisteme. Explicăm majoritatea îmbunătățirilor prin intermediul conductei noastre de prelucrare a datelor grele, care încearcă să remedieze propozițiile slab aliniate în datele paralele.', 'pl': 'Niniejszy raport opisuje neuronowe systemy tłumaczenia maszynowego oraz rurociągi przetwarzania danych opracowane dla zadania tłumaczenia biomedycznego WMT20. Dostarczamy systemy dla par językowych angielsko-rosyjsko oraz angielsko-niemieckich. Dla pary angielsko-rosyjskiej nasze zgłoszenia osiągają najlepsze wyniki BLEU, a kierunek en ru znacznie przewyższa inne systemy. Większość ulepszeń wyjaśniamy za pomocą naszego rurociągu przetwarzania ciężkich danych, który próbuje naprawić źle wyrównane zdania w danych równoległych.', 'so': 'Riyadaasu waxay ku qoran yihiin nidaamka neural machine tarjumidda ee YerevaNN iyo sawirada baaritaanka oo loo qoray shaqada biomedical translation ee WMT20. Waxaan nidaam u siinaynaa labada luuqada Ingiriis-Ruush iyo Ingiriis-Jarmal. Jirta ingiriisiga iyo Ruushka, soo diritaankayagu waxay gaadhaan qiimaha ugu wanaagsan ee BLEU, waxayna ku jirtaa hagaajinta rugta oo ku soo bandhiga nidaamka kale oo aad u weyn. Wax badan oo horumarinta ah ayaannu ku caddaynaynaa daboolka baaraandegista macluumaadkayaga culus, kaas oo isku dayaya in uu hagaajiyo xuquuqda looga dhigo macluumaadka lambarka ah.', 'sv': 'Denna rapport beskriver JerevaNN:s neurala maskin철vers채ttningssystem och databehandlingsledningar utvecklade f철r WMT20 biomedicinsk 철vers채ttning. Vi tillhandah책ller system f철r engelsk-ryska och engelsk-tyska spr책kpar. F철r det engelsk-ryska paret uppn책r v책ra bidrag de b채sta BLEU-po채ngen, med en ru direction 철vertr채ffar de andra systemen med en betydande marginal. Vi f철rklarar de flesta av f철rb채ttringarna genom v책r omfattande databehandling pipeline som f철rs철ker 책tg채rda d책ligt anpassade meningar i parallella data.', 'ta': '@ info நாங்கள் ஆங்கிலம்- ரஷ்சிய மற்றும் ஆங்கிலம்- ஜெர்மன் ஜோடிகளுக்கான அமைப்புகளை வழங்கு ஆங்கிலம்-ரஷ்ய ஜோடி, எங்கள் ஒப்புக்கொள்கைகள் சிறந்த பிலியு மதிப்பெண்கள் அடையும், மற்ற அமைப்புகளை முக்கியமான முறையில் செயல் நாம் எங்கள் கனமான தரவு முன்செயல்படுத்தல் முன்னேற்றங்களை விளக்குகிறோம். இணைப்பு தரவில் தவறான ஒழுங்கிய வாக்குகளை சரிபார', 'sr': 'Ovaj izveštaj opisuje sisteme prevoda neuromašine YerevaNN i cijevi obrade podataka razvijene za zadatak biomedicinskog prevoda WMT20. Mi pružamo sisteme za parove engleskog-ruskog i engleskog-njemačkog jezika. Za engleski-ruski par, naši podaci ostvaruju najbolji rezultat BLEU-a, sa u ru smjeru koji je nadmašio ostale sisteme sa značajnom marginom. Objašnjavamo većinu poboljšanja naših teških podataka koji predobrađuju cijev koji pokušavaju da popravi loše usklađene rečenice u paralelnim podacima.', 'si': 'මේ වාර්තාව යෙරෙවන්න්න්න්ගේ න්\u200dයූරල් මැෂින් වාර්තාව පද්ධතිය සහ දත්ත පරිස්සම් පායිප්ලයින් WMT20 බිය අපි ඉංග්\u200dරීසි-රුසියානු සහ ඉංග්\u200dරීසිය-ජර්මන් භාෂාවට පද්ධතිය ලබානවා. ඉංග්\u200dරීසිය-රුසියානු ජෝඩාවෙන්, අපේ පිළිගන්නේ හොඳම BLUE ප්\u200dරමාණය, අනිත් පද්ධතියට අනිත් පද්ධතියට විශේෂ අපි පැහැදිලි කරනවා අපේ ගොඩක් දත්ත ප්\u200dරක්\u200dරියාස කරනවා පායිප්ලින් එක්ක. ඒ වගේම ප්\u200dරක්\u200dරියාස කරනවා වචන වචන වචන වල්', 'ur': 'اس راپورت نے اروفان ن کے نیورال ماشین ترجمہ سیسٹم اور ڈاکٹی پرسس پائپ لین کو WMT20 بیوڈیسی ترجمہ کا کام بنایا ہے. ہم انگلیسی-روسی اور انگلیسی-جرمنی زبان جوڑوں کے لئے سیستمات دیتے ہیں۔ انگلیسی اور روسی جوڑوں کے لئے ہماری مضبوطی بہترین BLEU اسکور پہنچ جاتی ہیں، اور اس طرح روسی طریقے کے ساتھ دوسری سیستموں کو ایک بڑی محدودیت کے ذریعہ سے نکلتے ہیں۔ ہم بہت سی سیدھی توفیق دیتے ہیں جو ہمارے بھاری ڈاٹے کے ذریعہ سے پیپی پی پی پرس کرتی ہیں جو برائی کے مطابق مطابق فیصلہ کرنے کی کوشش کرتی ہے۔', 'uz': "@ info Biz ingliz tilida Ruscha va Ingliz tilida ko'pchilik tili bo'lgan tizimlarni yaratdik. Ingliz-Ruscha ikki xil uchun bizning imkoniyatlarimiz eng yaxshi BLEU scorlarini topadi, boshqa tizimlarni juda muhim margin bilan bajarishga ruxsat qiladi. Biz ko'pchilik taʼminlovchimizni qiyin maʼlumotni koʻpaytirish uchun o'zlarimizning ko'pchiligini o'rganamiz. Bu parametrlarni to ʻgʻri soʻzlarni toʻgʻrilashni istaysiz.", 'vi': 'Bài báo cáo này mô tả hệ thống dịch chuyển máy thần kinh của Yerevann và hệ thống xử lý dữ liệu được phát triển cho dịch chuyển sinh học của WM2lô. Chúng tôi cung cấp hệ thống ngôn ngữ Anh-Nga và Anh-Đức. Với cặp đôi Anh-Nga, chúng tôi hoàn thành điểm tốt nhất của Tổ chức May Mắn, với một khả năng chi tiết còn lại của một hệ thống khác. Chúng tôi giải thích hầu hết những cải tiến của đường ống xử lý dữ liệu nặng, đang cố gắng khắc phục các câu đặt theo cách không đúng đắn trong dữ liệu song song.', 'bg': 'Този доклад описва невронните системи за машинен превод и тръбопроводи за обработка на данни, разработени за задачата за биомедицински превод WMT20. Ние предлагаме системи за английски-руски и английски-немски езикови двойки. За английско-руската двойка нашите предложения постигат най-добрите резултати, като в ру посока надминават останалите системи със значителен марж. Обясняваме повечето подобрения чрез нашия тръбопровод за предварителна обработка на тежки данни, който се опитва да коригира лошо подравнени изречения в паралелните данни.', 'de': 'Dieser Bericht beschreibt die neuronalen maschinellen Übersetzungssysteme und Datenverarbeitungs-Pipelines von JerevaNN, die für die biomedizinische Übersetzungsaufgabe WMT20 entwickelt wurden. Wir bieten Systeme für Englisch-Russisch und Englisch-Deutsch Sprachpaare. Für das englisch-russische Paar erzielen unsere Einreichungen die besten BLEU-Werte, wobei die en ru-Richtung die anderen Systeme deutlich übertrifft. Wir erklären die meisten Verbesserungen durch unsere Heavy Data Preprocessing Pipeline, die versucht, schlecht ausgerichtete Sätze in den parallelen Daten zu beheben.', 'da': "Denne rapport beskriver JerevaNN's neurale maskinoversættelsessystemer og databehandlingsrørledninger udviklet til WMT20 biomedicinsk oversættelsesopgave. Vi leverer systemer til engelsk-russisk og engelsk-tysk sprogpar. For det engelsk-russiske par opnår vores indsendelser de bedste BLEU scorer, hvor en ru retning overgår de andre systemer med en betydelig margin. Vi forklarer de fleste af forbedringerne ved vores forhåndsbehandling af tunge data pipeline, som forsøger at rette dårligt justerede sætninger i parallelle data.", 'id': 'Laporan ini menjelaskan sistem terjemahan mesin saraf YerevaNN dan pipa proses data yang dikembangkan untuk tugas terjemahan biomedis WMT20. Kami menyediakan sistem untuk pasangan bahasa Inggris-Rusia dan bahasa Inggris-Jerman. Untuk pasangan Inggris-Rusia, pengiriman kami mencapai nilai BLEU terbaik, dengan arah en ru melebihi sistem lain dengan margin yang signifikan. Kami menjelaskan kebanyakan peningkatan dengan saluran pemproses data berat yang mencoba untuk memperbaiki kalimat yang tidak sesuai dengan data paralel.', 'fa': 'این گزارش سیستم ترجمه ماشین عصبی YerevaNN را توصیف می\u200cکند و خط\u200cهای پردازش داده\u200cها را برای تابع ترجمه بیوپزشکی WMT20 توسعه می\u200cدهد. ما سیستم\u200cهایی برای جفت زبان انگلیسی و روسی و انگلیسی و آلمانی فراهم می\u200cکنیم. برای جفت انگلیسی و روسی، تحویل\u200cهای ما بهترین امتیاز BLEU را می\u200cرسانند، با توجه en ru که سیستم\u200cهای دیگر را با یک مرز بزرگی انجام می\u200cدهند. ما اکثر بهترین توسط داده های سنگین ما توضیح می دهیم که تلاش می کنند که جمله های بدی در داده های متفاوت تعمیر کنند.', 'sw': 'Ripoti hii inaelezea mfumo wa utafsiri wa mashine ya kiserikali ya YerevaNN na mistari ya upasuaji wa data zilizotengenezwa kwa ajili ya kazi ya tafsiri ya kitabibu cha WMT20. Tunatoa mfumo wa lugha ya Kiingereza na Kiingereza na Kijerumani. Kwa ajili ya wawili wa Kiingereza na Urusi, ujumbe wetu unafanikiwa vipimo vyema vya BLEU, na mwelekeo wa ru ru unaofanya mifumo mingine kwa kiwango kikubwa. Tunaelezea maendeleo mengi yanayotokana na pipeli ya taarifa zito za kupambana na taarifa ambazo zinajaribu kurekebisha hukumu zilizowekwa vibaya katika takwimu zilizofanana.', 'nl': 'Dit rapport beschrijft de neurale machine translation systemen en dataverwerkingspipelines van JerevaNN ontwikkeld voor WMT20 biomedische vertaaltaak. Wij bieden systemen voor Engels-Russisch en Engels-Duits taalparen. Voor het Engels-Russische paar behalen onze inzendingen de beste BLEU-scores, waarbij en ru direction de andere systemen aanzienlijk overtreft. We leggen de meeste verbeteringen uit door onze heavy data preprocessing pipeline, die probeert slecht uitgelijnde zinnen in de parallelle data op te lossen.', 'tr': "Bu rapor, YerevaNN'yň näural maşynyň terjime sistemlerini we WMT20 biomedical terjime täblisasy üçin gelinýän data-processing pipelini tassyýar. Biz iňlisçe-Rus we iňlisçe-nemesçe diller üçin sistemalary berýäris. Iňlisçe-Rus çift üçin biziň gönderişimiz BLEU notlarynyň iň gowyny ýetip bilýär, we en ru yönünde başga sistemalary möhüm gabdaly bilen üstüne çykýar. Biz öz agyr maglumatlarymyzdan öň köp gelişmelerimizi parallel maglumatlarynda çykarmak isleýäris.", 'sq': 'Ky raport përshkruan sistemet e përkthimit nervor të makinës YerevaNN dhe tubacionet e përdorimit të të dhënave të zhvilluar për detyrën e përkthimit biomedik WMT20. Ne ofrojmë sisteme për çifte gjuhësh anglo-ruse dhe anglo-gjermane. Për çiftin anglo-rusë, paraqitjet tona arrijnë rezultatet më të mira të BLEU-së, me drejtimin e ru që tejkalon sistemet e tjera me një margin të rëndësishëm. Ne shpjegojmë shumicën e përmirësimeve nga tubacioni ynë i rëndë për përdorimin e të dhënave që përpiqet të rregullojë fjalët e pakufishme në të dhënat paralele.', 'am': 'ይህ ሪፖርት የኤርብኤን የናቡራል መሣሪያን ትርጉም ስርዓቶችን እና የዳታ ማቀናጃ ፕላይኖችን ለWMT20 biomedical ትርጓሜ ስርዓት የተዘጋጀውን ጥናት ይናገራል፡፡ We provide systems for English-Russian and English-German language pairs.  እንግሊዝኛ-ራሽኛ ሁለቶች፣ የባሕላዊ ደረጃዎች የBLEU ሁኔታ አግኝተዋል፡፡ በአካባቢው ዳታዎች ውስጥ የክፋት ቃላትን ለማፍሰስ የሚሞክሩት የድህነታችንን ብዙውን አካሄድ እናብራራለን፡፡', 'hy': 'Այս զեկույցը նկարագրում է YereveaN-ի նյարդային մեքենայի թարգմանման համակարգերը և տվյալների վերաբերյալ խողովակաշարերը, որոնք զարգացվել են աշխարհի կենսաբժշկական թարգմանման գործի համար: Մենք ապահովում ենք համակարգեր անգլերեն-ռուսերեն և անգլերեն-գերմաներեն զույգերի համար: Անգլերեն-ռուսերեն զույգի համար մեր ներկայացումները հասնում են ամենալավ գնահատականներին, երբ en ru ուղղությամբ գերազանցում են մյուս համակարգերը նշանակալի սահմաններով: We explain most of the improvements by our heavy data preprocessing pipeline which attempts to fix poorly aligned sentences in the parallel data.', 'hr': 'Ovaj izvještaj opisuje sustave prevoda neuromašine YerevaNN-a i cijevi obrade podataka razvijene za zadatak biomedicinskog prevoda WMT20. Mi pružamo sisteme za parove engleskog i ruskog i njemačkog jezika. Za engleski-ruski par, naši podaci postignu najbolji rezultat BLEU-a, a u ru smjeru iznosi ostale sustave značajnom marginom. Objašnjavamo većinu poboljšanja naših teških podataka koji predobrađuju cijev koji pokušavaju popraviti loše usklađene rečenice u paralelnim podacima.', 'af': "Hierdie raporteer beskryf YerevaNN se neurale masjien vertalingsstelsels en data verwerking pyplyn ontwikkel vir WMT20 biomediese vertalingstaak. Ons verskaf stelsels vir Engels-Russe en Engels-Duitse taal pare. Vir die Engelse-Russiese paar, ons onderwyselings bereik die beste BLES-punte, met en ru-rigting wat die ander stelsels uitvoer deur 'n betekende marjin. Ons verduidelik die meeste van die verbeteringe deur ons swaar data voor verwerking van pyplyn wat probeer om swaar gelykte setinge in die parallele data te herstel.", 'bn': 'এই রিপোর্ট ইয়েরেভানএনের নিউরাল মেশিন অনুবাদ সিস্টেম এবং ডাটা প্রক্রিয়া পাইপেলেন উইএমটি২০ বায়োমেডিকেল অনুবাদের ক We provide systems for English-Russian and English-German language pairs.  ইংরেজি-রাশিয়ান জোড়ার জন্য, আমাদের অনুপ্রদত্ত বিলিউ স্কোর অর্জন করা হয়েছে, আর অন্যান্য সিস্টেমের দিকে গুরুত্বপূর্ণ মার্গ আমরা আমাদের ভারী তথ্য প্রক্রিয়ার পাইপেলাইনের মাধ্যমে বেশীরভাগ উন্নতি ব্যাখ্যা করি যা প্যারালেল ডাটাতে খারাপ সাজানোর', 'ko': '이 보고서는 에리온이 WMT20 생물의학 번역 임무를 위해 개발한 신경 기계 번역 시스템과 데이터 처리 파이프라인을 기술했다.우리는 영어-러시아어와 영어-독일어 언어에 대해 시스템을 제공한다.영어-러시아어 조합에 대해 우리가 제출한 데이터는 최상의 BLEU 점수에 달했고 엔루 방향의 표현은 다른 시스템보다 현저히 우수했다.우리는 대량의 데이터 예처리 파이프의 대부분 개선을 설명했는데, 이 파이프는 병렬 데이터에서 잘못된 문장을 복원하려고 시도했다.', 'bs': 'Ovaj izvještaj opisuje sisteme prevoda neuromašine YerevaNN i cijevi obrade podataka razvijene za zadatak biomedicinskog prevoda WMT20. Mi pružamo sisteme za parove engleskog-ruskog i engleskog-njemačkog jezika. Za engleski-ruski par, naši podaci postignu najbolji rezultat BLEU-a, s u ru smjeru koji je nadmašio ostale sisteme značajnom marginom. Objašnjavamo većinu poboljšanja naših teških podataka koji predobrađuju cijev koji pokušavaju popraviti loše usklađene rečenice u paralelnim podacima.', 'az': "Bu xəbər YerevaNN'in nöral maşın çevirim sistemlərini və WMT20 biomedicin çevirim işi üçün ürəkləndirilmiş məlumatlar təşkil edilməsi üçün təşkil edir. Biz İngilis-Rus və İngilis-Alman dillərinin çift sistemlərini təmin edirik. İngilizə-Rus çift üçün, bizim təbliğlərimiz ən yaxşı BLEU nöqtələrini başa çatdırır, digər sistemləri böyük bir margin ilə en ru yönəldir. Biz ağır məlumatlarımızın çoxunu paralel məlumatlarında pis çəkilən cümlələri düzəltməyə çalışan pipeline təşkil edirik.", 'cs': 'Tato zpráva popisuje systémy neuronového strojového překladu YereaNN a potrubí pro zpracování dat vyvinuté pro úlohu biomedicínského překladu WMT20. Poskytujeme systémy pro anglicko-ruské a anglicko-německé jazykové páry. U anglicko-ruského páru dosahují naše příspěvky nejlepších bodů BLEU, přičemž směr en ru výrazně překonává ostatní systémy. Většinu vylepšení vysvětlujeme naším těžkým datovým předzpracováním, které se snaží opravit špatně zarovnané věty v paralelních datech.', 'et': 'Käesolevas aruandes kirjeldatakse YerevANi neuromasintõlke süsteeme ja andmetöötluse torujuhtmeid, mis on välja töötatud WMT20 biomeditsiinilise tõlke ülesandeks. Pakume süsteeme inglise-vene ja inglise-saksa keele paaridele. Inglise-Vene paari puhul saavutavad meie esitatud tulemused parimad BLEU skoorid, kusjuures en ru suunas ületab märkimisväärselt teisi süsteeme. Enamikku täiustusi selgitame meie raskete andmete eeltöötluse toru abil, mis püüab parandada halvasti joondatud lauseid paralleelsetes andmetes.', 'fi': 'T채ss채 raportissa kuvataan YerevaNN:n neurokonek채채nn철sj채rjestelm채t ja tietojenk채sittelyputket, jotka on kehitetty WMT20-biol채채ketieteellist채 k채채nn철st채 varten. Tarjoamme j채rjestelmi채 englanti-ven채j채 ja englanti-saksa kielipareille. Englannin ja ven채l채isen parin osalta ehdotuksemme saavuttavat parhaat BLEU-pisteet, ja en ru suunta ylitt채채 muut j채rjestelm채t merkitt채v채ll채 marginaalilla. Selit채mme suurimman osan parannuksista raskaan datan esik채sittelyputkellamme, joka yritt채채 korjata huonosti linjattuja lauseita rinnakkaisissa tiedoissa.', 'ca': 'Aquest informe descriu els sistemes neuromèdics de traducció de YerevaNN i els conductes de processament de dades desenvolupats per a la tasca de traducció biomèdica WMT20. We provide systems for English-Russian and English-German language pairs.  Per al parell anglès-russo, les nostres presentacions aconsegueixen els millors puntuacions BLEU, amb una direcció en ru que supera els altres sistemes per un marge significatiu. Explicam la majoria de les millores del nostre pesat tub de preprocessió de dades que intenta arreglar frases mal allinjades en les dades paralleles.', 'jv': 'Ndelengkat iki rambarang ng sistem tarjamahan nang jerebaNN netal karo perusahaan data-perusahaan nggawe kanggo nggambar terjamahan, kiwih dumateng kanggo perangkat biyoteng, WB2Name Awak dhéwé ngewehke sistem kanggo barang Inggris-Rus karo Perancis-Perancis. Genjer neng alih-russisan ingkang dipambah, gunakake sing paling dhéwé nggawe gerakan sing lunak meluak blok, karo en ru direction sing menyang sampek sistem sing wis ngerasah sistem sing bisa pasar sing larang. Awak dhéwé ngerasah akeh langkung dipuluhayo ning awak dhéwé kuwi nggawe perusahaan winih kanggo ngilangno kuwi nggawe aturan sing paling nggawe', 'ha': "@ info Munã samar da system ga nau'i biyu na harshen Ingiriya da Ingiriya. Ga nau'in Ingiriya-Ruushi, musammuninmu za'a sami mafi kyaun score BLEU, da wata shirin ruwan ta sami wasu na'ura da margin mai girma. Munã bayyana mafiya kyakkyawan improve da piilen da data masu nau'i da za'a yi amfani da shi a sami-daidai.", 'sk': 'To poročilo opisuje sisteme nevronskega strojnega prevajanja podjetja YerevaNN in cevovode za obdelavo podatkov, razvite za nalogo biomedicinskega prevajanja WMT20. Nudimo sisteme za angleško-ruske in angleško-nemške jezikovne pare. Pri angleško-ruskem paru naši prispevki dosegajo najboljše rezultate BLEU, pri čemer je en ru smer precej boljši od drugih sistemov. Večino izboljšav pojasnjujemo z našim cevovodom za predobdelavo težkih podatkov, ki poskuša popraviti slabo poravnane stavke v vzporednih podatkih.', 'he': 'הדו"ח הזה מתאר את מערכות התרגום המכונה העצבית של YerevaNN ואת צינורות מעבדת נתונים שפותחים עבור משימה התרגום ביומדיקני WMT20. We provide systems for English-Russian and English-German language pairs.  עבור הזוג האנגלי-רוסי, השימושים שלנו מגיעים לתוצאות BLEU הטובות ביותר, עם כיוון RU מעליף את המערכות האחרות על ידי שווה משמעותית. אנחנו מסבירים את רוב השיפורים על ידי צינור ההעברה של נתונים כבדים שלנו שמנסה לתקן משפטים מסוימים לא טוב במידע המזומן.', 'bo': "This report describes YerevaNN's neural machine translation systems and data processing pipelines developed for WMT20 biomedical translation task. ང་ཚོས་དབྱིན་ཡིག་དང་རྒྱ་རིས་དང་དབྱིན་ཡིག་ཆའི་སྐད་ཀྱི་གཉིས་ཆ་ལ་ལག་ལེན་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་བསམ་འཛམ་གླིང་-རུ་སྨྲ་བརྗོད་ཀྱི་གྲངས་ཚད་མང་ཤོས་ཡོད་ཚད་ལྡན་མང་ཤོས་རྒྱུ་ཡིན། ང་ཚོས་རང་ཉིད་ཀྱི་འཇུག་བརྡན་གྱི་སྔོན་སྒྲིག་གི་བྱ་ཚིག་གི་ཆེ་རྐྱེན་དུ་འགྲེལ་བཤད་བྱས།"}
{'en': 'Pretrained Language Models and Backtranslation for English-Basque Biomedical Neural Machine Translation', 'ar': 'نماذج اللغة المحددة مسبقًا والترجمة الخلفية للترجمة الآلية العصبية الطبية الحيوية الإنجليزية الباسكية', 'fr': 'Modèles linguistiques préformés et rétrotraduction pour la traduction automatique neuronale biomédicale anglais-basque', 'es': 'Modelos lingüísticos preentrenados y traducción inversa para la traducción automática neuronal biomédica inglés-vasco', 'pt': 'Modelos de linguagem pré-treinados e retrotradução para tradução automática biomédica biomédica inglês-basco', 'ja': '英語-バスク語バイオメディカル神経機械翻訳のための事前訓練された言語モデルとバックトランスレーション', 'zh': '以英语-巴斯克生物医学神经机器翻译预训言语模样及反向译', 'hi': 'अंग्रेजी-बास्क बायोमेडिकल न्यूरल मशीन अनुवाद के लिए पूर्व प्रशिक्षित भाषा मॉडल और बैकट्रांसलेशन', 'ru': 'Предварительно обученные языковые модели и обратный перевод для английско-баскского биомедицинского нейронного машинного перевода', 'ga': "Múnlaí Teanga Réamhthraenáilte agus Aistriú Siar d'Aistriúchán Inneall Néarach Bithleighis Béarla-Bascais", 'ka': 'Name', 'hu': 'Előkészített nyelvi modellek és háttérfordítás angol-baszk biomedicini neurális fordításhoz', 'el': 'Προκατασκευασμένα Γλωσσικά Μοντέλα και Αντιμετάφραση για Αγγλικά-Βασκική Βιοιατρική Νευρική Μηχανική Μετάφραση', 'it': 'Modelli linguistici pretrained e backtranslation per traduzione automatica biomedica neuronale inglese-basca', 'mk': 'Претренирани јазички модели и превод за англиско-баски биомедицински превод на невропски машини', 'kk': 'Ағылшын- Баск биомедикалық невралдық машинаны аудару үшін тіл үлгілері және Backtranslation', 'lt': 'Išankstinio mokymo kalbos modeliai ir grįžtamasis vertimas anglų-baskų biologinės medicinos neurologinės mašinos vertimui', 'ms': 'Translation for English-Basque Biomedical Neural Machine Translation', 'ml': 'translation', 'mt': 'Mudelli tal-Lingwa Mħarrġa minn Qabel u Traduzzjoni Ġenerali għat-Traduzzjoni tal-Magna Newrali Bijomediċina Ingliż-Baska', 'mn': 'Pretrained Language Models and Backtranslation for English-Basque Biomedical Neural Machine Translation', 'no': 'Name', 'pl': 'Wstępne modele językowe i tłumaczenie wsteczne dla angielsko-baskijsko Biomediczne neuronalne tłumaczenie maszynowe', 'ro': 'Modele lingvistice pretrainate și backtranslation pentru traducerea automată biomedicală neuronală engleză-bască', 'sr': 'Preklinjeni jezički modeli i prevod za engleski-baskijski biomedicinski neuromedicinski prevod', 'si': 'Name', 'so': 'translation for English-Basque Biomedical Neural Machine', 'sv': 'Förtränade språkmodeller och bakåtöversättning för engelsk-baskisk biomedicinsk neural maskinöversättning', 'ta': 'முன்பயிற்சிக்கப்பட்ட மொழி மாதிரி மற்றும் பின்னணி மொழிமாற்றங்கள்', 'ur': 'Name', 'uz': 'Pretrained Language Models and Backtranslation for English-Basque Biomedical Neural Machine Translation', 'vi': 'Chế độ Ngôn ngữ đã đóng giả và Dịch phụ cho Dịch Phòng Sinh Lý học Anh-Basque', 'bg': 'Претренирани езикови модели и бекпревод за английски-баски биомедицински неврален машинен превод', 'nl': 'Voorgetrainde Taalmodellen en Backtranslation voor Engels-Baskische Biomedische Neurale Machine Translation', 'da': 'Prætrænede sprogmodeller og baggrundsoversættelse til engelsk-baskisk biomedicinsk neural maskinoversættelse', 'hr': 'Preklinjeni jezički modeli i povratak za prevod engleskog-baskijskog biomedicinskog neuromedicinskog uređaja', 'de': 'Vortrainierte Sprachmodelle und Backtranslation für Deutsch-Baskisch Biomedizinische Neuronale Maschinelle Übersetzung', 'ko': '영어 바스크 생물 의학 신경 기계 번역의 예비 훈련 언어 모델과 반역', 'id': 'Pretrained Language Models and Backtranslation for English-Basque Biomedical Neural Machine Translation', 'fa': 'مدل زبان و ترجمه پشتی برای ترجمه ماشین عصبی انگلیسی باسکی', 'sq': 'Modelet e gjuhës dhe përkthimi prapa për përkthimin anglisht-bask të makinës neurologjike', 'tr': 'Iňlisçe-Bask Biwomedik Nural Maşynyň terjimesi üçin gözlenýän Diller we arka terjime', 'af': 'Name', 'sw': 'translation for English-Basque Biomedical Neural Tafsiri', 'am': 'translation for English- Basque Biomedical Neural Machine translation', 'az': '캻ngilizci-Basq Biyomedicini N칲ral Makinesi T톛rc칲m톛 칲칞칲n S칲l Modell톛ri v톛 Backtranslation', 'hy': 'Անգլերենի-բասկի բիոբիոբժշկական նյարդային մեքենայի թարգմանման', 'bn': '@ info', 'bs': 'Preklinjeni jezički modeli i prevod za prevod engleskog-baskijskog biomedicinskog neuromedicinskog uređaja', 'et': 'Eeltreenitud keelemudelid ja tagantõlge inglise-baski biomeditsiinilise neuroaalse masintõlke jaoks', 'cs': 'Předtrénované jazykové modely a zpětný překlad pro anglicko-baskický biomedicínský neuronový strojový překlad', 'ca': 'Models de llenguatge pré-entrenats i retrotraducció per traducció de màquines neuromèdiques biomèdiques anglès-vasques', 'fi': 'Pretrained Language Models and Backtranslation for English-Baski Biomedical Neural Machine Translation', 'sk': 'Predtrenirani jezikovni modeli in retroprevod za angleško-baskovsko biomedicinsko nevralno strojno prevajanje', 'he': 'דוגמני שפה מתאמנים מראש ותרגום אחורי לתרגום מכונת נוירולית ביורפואית אנגלית-בסקה', 'ha': 'translation for English- Basque Biomedical Neural Translate', 'bo': 'Pretrained Language Models and Backtranslation for English-Basque Biomedical Neural Machine Translation', 'jv': 'Language'}
{'en': 'This paper describes the machine translation systems proposed by the University of Technology Sydney Natural Language Processing (UTS_NLP) team for the WMT20 English-Basque biomedical translation tasks. Due to the limited parallel corpora available, we have proposed to train a BERT-fused NMT model that leverages the use of pretrained language models. Furthermore, we have augmented the training corpus by backtranslating monolingual data. Our experiments show that NMT models in low-resource scenarios can benefit from combining these two training techniques, with improvements of up to 6.16 BLEU percentual points in the case of biomedical abstract translations.', 'ar': 'تصف هذه الورقة أنظمة الترجمة الآلية التي اقترحها فريق معالجة اللغات الطبيعية بجامعة سيدني للتكنولوجيا (UTS_NLP) لمهام الترجمة الطبية الحيوية باللغة الإنجليزية إلى لغة الباسك في WMT20. نظرًا لمحدودية المجموعات المتوازية المتاحة ، فقد اقترحنا تدريب نموذج NMT مدمج في BERT والذي يعزز استخدام نماذج اللغة المدربة مسبقًا. علاوة على ذلك ، قمنا بزيادة مجموعة التدريب عن طريق الترجمة العكسية للبيانات أحادية اللغة. تُظهر تجاربنا أن نماذج NMT في سيناريوهات الموارد المنخفضة يمكن أن تستفيد من الجمع بين هاتين الطريقتين التدريبيتين ، مع تحسينات تصل إلى 6.16 نقطة مئوية BLEU في حالة الترجمات الطبية الحيوية المجردة.', 'fr': "Cet article décrit les systèmes de traduction automatique proposés par l'équipe UTS_NLP (University of Technology Sydney Natural Language Processing) pour les tâches de traduction biomédicale anglais-basque du WMT20. En raison du nombre limité de corpus parallèles disponibles, nous avons proposé de former un modèle NMT fusionné par BERT qui tire parti de l'utilisation de modèles de langage préformés. De plus, nous avons augmenté le corpus de formation en rétro-traduisant les données monolingues. Nos expériences montrent que les modèles NMT dans des scénarios à faibles ressources peuvent bénéficier de la combinaison de ces deux techniques de formation, avec des améliorations allant jusqu'à 6,16 points de pourcentage UEBL dans le cas de traductions abstraites biomédicales.", 'pt': 'Este artigo descreve os sistemas de tradução automática propostos pela equipe de processamento de linguagem natural da Universidade de Tecnologia de Sydney (UTS_NLP) para as tarefas de tradução biomédica inglês-basco do WMT20. Devido aos limitados corpora paralelos disponíveis, propusemos treinar um modelo NMT fundido com BERT que alavanca o uso de modelos de linguagem pré-treinados. Além disso, aumentamos o corpus de treinamento por meio da retrotradução de dados monolíngues. Nossos experimentos mostram que modelos NMT em cenários de poucos recursos podem se beneficiar da combinação dessas duas técnicas de treinamento, com melhorias de até 6,16 pontos percentuais de BLEU no caso de traduções de resumos biomédicos.', 'es': 'Este artículo describe los sistemas de traducción automática propuestos por el equipo de Procesamiento del Lenguaje Natural (UTS_NLP) de la Universidad Tecnológica de Sídney para las tareas de traducción biomédica del inglés al vasco WMT20. Debido a los limitados corpus paralelos disponibles, hemos propuesto entrenar un modelo de NMT fusionado con BERT que aproveche el uso de modelos de lenguaje previamente entrenados. Además, hemos ampliado el corpus de capacitación mediante la retrotraducción de datos monolingües. Nuestros experimentos muestran que los modelos de NMT en escenarios de bajos recursos pueden beneficiarse de la combinación de estas dos técnicas de capacitación, con mejoras de hasta 6,16 puntos porcentuales de BLEU en el caso de las traducciones de resúmenes biomédicos.', 'ja': '本稿では、シドニー工科大学自然言語処理（ UTS_NLP ）チームがWMT 20英語-バスク語生物医学翻訳タスクのために提案した機械翻訳システムについて説明します。利用可能な並列コーパスが限られているため、事前に訓練された言語モデルの使用を活用したBERT融合NMTモデルを訓練することを提案しました。さらに、単語データを逆翻訳することで、トレーニングコーパスを拡張しました。私たちの実験は、低資源シナリオにおけるNMTモデルが、生物医学的抽象翻訳の場合に最大6.16 BLEUパーセンテージポイントの改善を伴って、これら2つのトレーニング技術を組み合わせることによって利益を得ることができることを示しています。', 'zh': '本文言悉尼科技大学自然语言处(UTS_NLP)团队为WMT20英语-巴斯克生物医学译机器翻译统。 可用者并行语料库有限,请练一BERT融合之NMT,以预练言语模形之用。 又因反向译单语数据以增练语料库。 臣等实验明,于资源匮乏之中,NMT模形可以受益于二者,生物医学摘要译者,NMT模者改进率高达6.16 BLEU百分点。', 'ru': 'Эта бумага описывает системы машинного перевода предложенные командой Обработки Естественного Языка Сиднейского Университета (UTS_NLP) для задач биомедицинского перевода WMT20 английско-баскского языка. В связи с ограниченным количеством доступных параллельных корпусов, мы предложили обучить слитую с BERT модель NMT, которая использует использование предварительно подготовленных языковых моделей. Кроме того, мы расширили учебный корпус, переведя назад одноязычные данные. Наши эксперименты показывают, что модели NMT в сценариях с низкими ресурсами могут извлечь выгоду из сочетания этих двух методов обучения с улучшениями до 6,16 процентных пунктов BLEU в случае биомедицинских абстрактных переводов.', 'hi': 'यह पेपर WMT20 अंग्रेजी-बास्क बायोमेडिकल अनुवाद कार्यों के लिए प्रौद्योगिकी विश्वविद्यालय सिडनी प्राकृतिक भाषा प्रसंस्करण (UTS_NLP) टीम द्वारा प्रस्तावित मशीन अनुवाद प्रणालियों का वर्णन करता है। उपलब्ध सीमित समानांतर कॉर्पोरेट के कारण, हमने एक BERT-फ्यूज्ड NMT मॉडल को प्रशिक्षित करने का प्रस्ताव दिया है जो पूर्वप्रशिक्षित भाषा मॉडल के उपयोग का लाभ उठाता है। इसके अलावा, हमने मोनोलिंगुअल डेटा को बैकट्रांसलेट करके प्रशिक्षण कॉर्पस को बढ़ाया है। हमारे प्रयोगों से पता चलता है कि कम संसाधन परिदृश्यों में एनएमटी मॉडल इन दो प्रशिक्षण तकनीकों के संयोजन से लाभान्वित हो सकते हैं, बायोमेडिकल अमूर्त अनुवाद के मामले में 6.16 BLEU प्रतिशत अंक तक के सुधार के साथ।', 'ga': 'Déanann an páipéar seo cur síos ar na córais aistriúcháin mheaisín atá molta ag foireann Próiseáil Teanga Nádúrtha Ollscoil Teicneolaíochta Sydney (UTS_NLP) le haghaidh tascanna aistriúcháin bithleighis Béarla-Bascais WMT20. Mar gheall ar an gcorpas comhuaineach teoranta atá ar fáil, tá sé beartaithe againn múnla NMT comhcheangailte le BERT a thraenáil chun úsáid na múnlaí teanga réamh-oilte a úsáid. Ina theannta sin, chuireamar leis an gcorpas oiliúna trí shonraí aonteangacha a ais-aistriú. Léiríonn ár dturgnaimh gur féidir le samhlacha NMT i gcásanna íseal-acmhainne leas a bhaint as an dá theicníc oiliúna seo a chomhcheangal, le feabhsuithe suas le 6.16 pointe céatadáin BLEU i gcás aistriúcháin teibí bithleighis.', 'ka': 'ეს დოკუმენტი აღწერს მანქანის გაგრძელების სისტემი, რომლებიც WMT20 ინგლისური-ბასკური ბიომედიციური გაგრძელების სამუშაო გაგრძელების სამუშაო ტექნოლოგიის სუ ჩვენ გვეძლევა, რომ BERT-ს დაბრუნებული NMT მოდელის გამოყენებას გამოყენება, რომელიც გამოყენება წარმოადგენული ენის მოდელის გამოყენებას. დამატებით, ჩვენ მონოლენგური მონაცემებით განვითარებით კოპუსს აზრუმენტით. ჩვენი ექსპერიმენტები გამოჩვენება, რომ NMT მოდელები ცოტა რესურსის სინარიოში შეუძლია გამოიყენება ამ ორი განსწავლების ტექნოგიების შესაძლებლობა, რომელიც 6,16 BLEU პროცენტულ წერტილებების შესაძლებ', 'el': 'Η παρούσα εργασία περιγράφει τα συστήματα μηχανικής μετάφρασης που προτείνονται από την ομάδα επεξεργασίας φυσικής γλώσσας του Πανεπιστημίου του Σίδνεϊ (UTS_NLP) για τις εργασίες της αγγλικής-βασκικής βιοϊατρικής μετάφρασης WMT20. Λόγω των περιορισμένων διαθέσιμων παράλληλων σωμάτων, έχουμε προτείνει να εκπαιδεύσουμε ένα μοντέλο που θα αξιοποιεί τη χρήση προκαθορισμένων γλωσσικών μοντέλων. Επιπλέον, έχουμε διευρύνει το εκπαιδευτικό σώμα μεταφράζοντας μονογλωσσικά δεδομένα. Τα πειράματά μας δείχνουν ότι τα μοντέλα σε σενάρια χαμηλής περιεκτικότητας σε πόρους μπορούν να επωφεληθούν από τον συνδυασμό αυτών των δύο τεχνικών κατάρτισης, με βελτιώσεις μέχρι 6.16 ποσοστών στην περίπτωση των βιοϊατρικών αφηρημένων μεταφράσεων.', 'hu': 'A tanulmány bemutatja a University of Technology Sydney Natural Language Processing (UTS_NLP) csapata által javasolt gépi fordítási rendszereket a WMT20 angol-baszk orvosbiológiai fordítási feladatokhoz. A rendelkezésre álló korlátozott párhuzamos korlátozások miatt javasoltunk egy BERT-kapcsolódású NMT modell képzését, amely kihasználja az előkészített nyelvi modellek használatát. Továbbá a képzési korpuszt egynyelvű adatok visszafordításával bővítettük. Kísérleteink azt mutatják, hogy az NMT modellek alacsony erőforrású forgatókönyvekben előnyösek lehetnek e két képzési technika kombinációjából, orvosbiológiai absztrakt fordítások esetében akár 6,16 BLEU százalékpontos fejlesztéssel.', 'it': "Questo articolo descrive i sistemi di traduzione automatica proposti dal team di elaborazione del linguaggio naturale della University of Technology Sydney (UTS_NLP) per le attività di traduzione biomedica inglese-basca WMT20. A causa della limitata disponibilità di corpi paralleli, abbiamo proposto di formare un modello NMT fuso con BERT che sfrutta l'uso di modelli linguistici pre-addestrati. Inoltre, abbiamo ampliato il corpus formativo traducendo i dati monolingue. I nostri esperimenti dimostrano che i modelli NMT in scenari a basso consumo di risorse possono trarre vantaggio dalla combinazione di queste due tecniche di formazione, con miglioramenti fino a 6,16 punti percentuali BLEU nel caso di traduzioni biomediche astratte.", 'kk': 'Бұл қағаз WMT20 ағылшын- Баск биомедикалық аудармалар тапсырмалары үшін Технология Университеті Сидни Түзіндік тіл процессоры (UTS_ NLP) бағдарламасының аудармалар жүйелерін таңдайды. Қол жеткізетін параллель корпора шектелген сияқты, біз BERT-тің біріктірілген NMT үлгісін оқыту үшін ұсындық. Бұл өзгертілген тіл үлгілерін қолдану үшін. Сонымен қатар, біз монолингі деректерді аударып оқыту корпусын көтердік. Біздің тәжірибеміздің NMT үлгілері бағасы ресурстардың сценариясында, бұл екі оқыту техникаларын біріктіру үшін, биомедикалық абстракты аудармаларда 6,16 BLEU пайыздық нүктелерін жақсарту үшін пайдалану', 'lt': 'Šiame dokumente aprašomos technologijų universiteto Sydney Natural Language Processing (UTS_NLP) komandos WMT20 anglų–baskų biomedicinės vertimo užduotims siūlomos mašinų vertimo sistemos. Atsižvelgdami į ribotą lygiagrečią korporą, mes pasiūlėme treniruoti BERT sujungtą NMT model į, kuris leistų naudoti išankstinio mokymo kalbų modelius. Be to, mes padidinome mokymo korpusą vertdami vienakalbius duomenis. Mūsų eksperimentai rodo, kad mažai išteklių naudojančių NMT modelių nauda gali būti teikiama derinant šiuos du mokymo metodus, o biomedicinų abstraktų vertimų atveju – iki 6,16 BLEU procentinio punkto.', 'ms': 'Kertas ini menggambarkan sistem terjemahan mesin yang diusulkan oleh pasukan Perprosesan Bahasa Alami Sydney University of Technology (UTS_NLP) untuk tugas terjemahan biomedikal Inggeris-Bask WMT20. Kerana korpra selari terbatas yang tersedia, kami telah melatih model NMT berfungsi BERT yang menggunakan model bahasa yang dilatih. Selain itu, kami telah meningkatkan korpus latihan dengan menerjemahkan balik data monobahasa. Eksperimen kami menunjukkan bahawa model NMT dalam skenario sumber rendah boleh berguna daripada menggabungkan dua teknik latihan ini, dengan peningkatan sehingga 6.16 poin persentasi BLEU dalam kes terjemahan abstrak biomedikal.', 'ml': 'ഈ പേപ്പറിന്റെ വിവരിക്കുന്നു WMT20 ഇംഗ്ലീഷ്-ബാസ്ക്-ബാസ്ക് ബാസ്ക് ബാസ്ക് ബാസ്ക് ബാസ്ക് ബാക്ക് ബാക്കില്\u200d പരിഭാഷണ ജോലിക്കുകള്\u200dക്കായി  പരിധിയില്ലാത്ത പാരാളല്\u200d കോര്\u200dപ്പോരാ ലഭ്യമല്ലാത്തതിനാല്\u200d, നമ്മള്\u200d പരിശീലിപ്പിച്ചിരിക്കുന്നു പ്രെയിനേറ്റ് ഭാഷ മോഡലുകളുടെ  അതിനുശേഷം, നമ്മള്\u200d പരിശീലനത്തിന്റെ കോര്\u200dപ്പുസിനെ കൂട്ടിച്ചേര്\u200dത്തിട്ടുണ്ട്. മോനോളില്\u200dഭാഷ വിവരങ് നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു ഈ രണ്ട് ട്രെയിനിങ്കിന്റെ സാങ്കേതികവിദ്യയിലെ NMT മോഡലുകള്\u200d കൂട്ടിക്കൊണ്ടിരിക്കുന്നതില', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi ta’ traduzzjoni bil-magna proposti mit-tim tal-Proċess tal-Lingwa Naturali tal-Università tat-Teknoloġija ta’ Sydney (UTS_NLP) għall-kompiti ta’ traduzzjoni bijomedika Ingliż-Bask tad-WMT20. Minħabba l-korpra parallel a limitata disponibbli, ipproponejna li nħarrġu mudell NMT iffużat mill-BERT li jagħti spinta lill-użu ta’ mudelli lingwistiċi mħarrġa minn qabel. Barra minn hekk, żiedu l-korpus tat-taħriġ billi ttrasferijna lura d-dejta monolingwistika. Our experiments show that NMT models in low-resource scenarios can benefit from combining these two training techniques, with improvements of up to 6.16 BLEU percentual points in the case of biomedical abstract translations.', 'no': 'Denne papiret beskriver maskinsomsetjingssystemet som er foreslått av Universiteten av Teknologi Sydney Natural Language Processing (UTS_NLP) for WMT20 English-Basque biomedical translation tasks. På grunn av den grensene parallelle korporen som er tilgjengelege, har vi foreslått å trenja ein BERT-fusert NMT-modell som leverer bruken av språk-modeller. I tillegg har vi økt opplæringskorpusen ved å oversette monospråk-data. Eksperimentane våre viser at NMT-modeller i låg ressurs-scenarioar kan nytte til å kombinere desse to treningsteknikkene, med forbetringar i opp til 6,16 BLEU-prosentpunkt i tilfelle for biomediske abstrakte omsetjingar.', 'pl': 'Niniejszy artykuł opisuje systemy tłumaczenia maszynowego zaproponowane przez zespół University of Technology Sydney Natural Language Processing (UTS_NLP) dla zadań tłumaczenia biomedycznego WMT20. Ze względu na ograniczoną dostępność równoległych korpusów, zaproponowaliśmy trening modelu NMT połączonego z BERT, który wykorzystuje wstępnie przeszkolone modele językowe. Ponadto rozszerzyliśmy korpus szkoleniowy o backtranslację danych jednojęzycznych. Nasze eksperymenty pokazują, że modele NMT w scenariuszach niskich zasobów mogą skorzystać z połączenia tych dwóch technik szkoleniowych z udoskonaleniem do 6,16 punktów procentowych BLEU w przypadku biomedycznych tłumaczeń abstrakcyjnych.', 'mn': 'Энэ цаас WMT20 Англи-Баск биологийн эрүүл мэндийн хөгжлийн ажлын төлөө технологийн Их Сургуулийн Сидни Байгалийн Холбоо Процесс (UTS_NLP) багийн санал дэвшүүлсэн машины хөгжлийн системийг тайлбарладаг. Хязгаарлагдсан параллель корпора болохоор бид BERT-тэй холбогдсон NMT загварын загварыг суралцах боломжтой болсон. Мөн бид дасгал хөдөлгөөнийг нэг хэл өгөгдлийг буцаад орчуулж нэмэгдүүлсэн. Бидний туршилтууд NMT-ын төлөвлөгөө бага нөөцийн хувилбаруудад эдгээр хоёр сургалтын техникуудыг нэгтгэхээс ашиглаж чадна гэдгийг харуулж байна. Биологийн эмнэлгийн abstract орнуудын тулд 6.16 BLEU хувилбарын цэгүүдэд сайжруул', 'ro': 'Această lucrare descrie sistemele de traducere automată propuse de echipa de procesare a limbajului natural al Universității de Tehnologie Sydney (UTS_NLP) pentru sarcinile de traducere biomedicală engleză-bască WMT20. Datorită corpurilor paralele limitate disponibile, am propus instruirea unui model NMT fuzionat cu BERT care valorifică utilizarea modelelor lingvistice pre-instruite. În plus, am extins corpul de instruire prin traducerea înapoi a datelor monolingve. Experimentele noastre arată că modelele NMT în scenarii cu resurse reduse pot beneficia de combinarea acestor două tehnici de formare, cu îmbunătățiri de până la 6,16 puncte percentuale BLEU în cazul traducerilor biomedicale abstracte.', 'sr': 'Ovaj papir opisuje sisteme za prevod mašine koje je predložio tim Univerziteta tehnologije Sydney Natural Language Processing (UTS_NLP) za zadatke za prevod biomedicinskih tehnologija WMT20. Zbog ograničenog paralelnog korporacije dostupnog, predložili smo trenirati model NMT-a koji uključuje korištenje jezičkih modela. Osim toga, povećali smo trening korpus prevodeći monojezičke podatke. Naši eksperimenti pokazuju da modeli NMT u scenarijima niskih resursa mogu koristiti od kombinacije tih dva tehnika obuke, sa poboljšanjem do 6,16 procentnih bodova BLEU-a u slučaju biomedicinskih abstrakta prevoda.', 'si': 'මේ පැත්තේ WMT20 ඉංග්\u200dරීසි බාස්කි ජීවිත්\u200dය භාෂාවික භාෂාව ප්\u200dරශ්නය (UTS_NLP) කණ්ඩායම සඳහා ප්\u200dරශ්නය කරලා තියෙන් සීමාවිත සාමාන්\u200dය කොර්පෝරා පුළුවන් නිසා, අපිට BERT-සම්බන්ධ NMT මොඩේල් එකක් ප්\u200dරයෝජනය කරන්න පුළුවන් වෙන්න පුළුව තවත්, අපි ප්\u200dරශ්නයක් කොර්පුස් එක්ක භාෂාවක් තොරතුරු පස්සේ පස්සෙන් වාර්තා කරලා තියෙනවා. අපේ පරීක්ෂණය පෙන්වන්නේ NMT මොඩේල් අඩු සම්බන්ධ විදියට ප්\u200dරයෝජනය කරන්න පුළුවන් මේ පරීක්ෂණ පද්ධතිය දෙකක් සම්බන්ධ කරන්න, බියෝබි', 'so': 'Kanu waa qoraal ku qoran nidaamka turjumista machine ee lagu soo jeedo jaamacadda Technology Sydney Sydney Processing afka natural (UTS_NLP) team for the WMT20 Ingiriis-Basque shaqooyin biomedical translation. Xilliga shirkadda lambarka ah ee ay leedahay darteed, waxaan soo jeednay in aan tababarinno muusikada NMT ee BERT-fuuleeyey, kaas oo kordhiya isticmaalka noocyada afka hore. Furthermore, we have augmented the training corpus by backtranslating monolingual data.  Imtixaanadeena waxay muuqan karaan in sameynta labadan tacliin waxbarasho ay ka faa’iido qaadaan karto ugu badnaan boqolkiiba 6.16 BLEU marka lagu turjumo turjumaadka dhakhaatiirta dhakhaatiirta.', 'mk': 'Овој весник ги опишува машинските преведувачки системи предложени од тимот на универзитетот за технологија Сиднеј природен јазик процесор (UTS_NLP) за задачите на англиско-баски биомедициски превод на WMT20. Поради ограничената паралелна корпора достапна, предложивме да обучуваме модел на НМТ со БЕРТ, кој го користи употребата на предобучени јазички модели. Покрај тоа, го зголемивме обукниот корпус со преведување на монојазични податоци. Нашите експерименти покажуваат дека моделите на НМТ во сценарија со ниски ресурси можат да имаат корист од комбинацијата на овие две техники на обука, со подобрувања од 6,16 процентни поени на БЛЕ во случајот на биомедицински апстрактни преводи.', 'sv': 'Denna uppsats beskriver de maskin철vers채ttningssystem som f철resl책s av University of Technology Sydney Natural Language Processing (UTS_NLP) team f철r WMT20 biomedicinsk 철vers채ttning. P책 grund av de begr채nsade parallella korpora som finns tillg채ngliga har vi f철reslagit att tr채na en BERT-fusionerad NMT-modell som utnyttjar anv채ndningen av f철rkr채nade spr책kmodeller. Dessutom har vi ut철kat utbildningscorpus genom att 철vers채tta enspr책kiga data bak책t. V책ra experiment visar att NMT-modeller i l책gresursscenarier kan dra nytta av att kombinera dessa tv책 utbildningstekniker, med f철rb채ttringar av upp till 6,16 BLEU-procentenheter vid biomedicinska abstrakta 철vers채ttningar.', 'ta': 'WMT20 ஆங்கிலத்தில் பாஸ்க் மருத்துவம் மொழிமாற்றும் பணிகளுக்கான தொழில்நுட்பத்தில் சைட்னி இயல்பான மொழி செயல்பாடு (UTS_ NLP) குழு மொழிமாற வரையறுக்கப்பட்ட இணைப்பு நிறுவனம் கிடைக்கும் காரணத்தால், நாங்கள் பரிந்துரைக்கிறோம் முன்னோக்கிய மொழி மாதிரிகளின் பயன்பாட்டை பயன மேலும், நாங்கள் பயிற்சி குறியீட்டை அதிகரித்துள்ளோம் மொன்மொழிமொழிபெயர்ப்பு தகவல் மூலம். எங்கள் சோதனைகள் காண்பிக்கிறது என்றால் குறைந்த மூலத்தில் NMT மாதிரிகள் இந்த இரண்டு பயிற்சி தொழில்நுட்பத்தை ஒன்றிணைக்க முடியும், உயிரியல் சிகிச்சை', 'ur': 'This paper describes the machine translation systems proposed by the University of Technology Sydney Natural Language Processing (UTS_NLP) team for the WMT20 English-Basque biomedical translation tasks. محدودہ مشابہ کورپورا کے باعث ہم نے ایک BERT-fused NMT موڈل کو ترینس کرنے کی پیشنهاد کی ہے جو پہلی زبان موڈل کا استعمال کرتا ہے۔ اور ہم نے ایک زبان کی اطلاعات کو پچھلے ترجمہ سے ترکینس کورپوس کو بڑھا دیا ہے۔ ہمارے آزمائش دکھاتے ہیں کہ NMT موڈل کم منطقی سناریوں میں ان دو تدریس ٹیکنیکوں کو جوڑنے سے فائدہ پہنچا سکتے ہیں، جو 6.16 BLEU فیصد پوینٹوں تک زیادہ سیدھی بیوڈیسی غلط ترجمہ کے مطابق ہے۔', 'vi': 'Bài viết này mô tả hệ thống dịch thuật cỗ máy do đội điền kinh của trường đại học Sydney Comment Do có hạ sĩ song song giới hạn, chúng tôi đã đề nghị huấn luyện một mô hình NMB kết hợp BERT, nhờ đó sử dụng các mô hình ngôn ngữ sẵn sàng. Hơn nữa, chúng tôi đã tăng cường tập đoàn bằng cách đảo ngược dữ liệu ngôn ngữ. Các thí nghiệm của chúng tôi cho thấy các mô hình NMT trong các viễn cảnh thấp nguồn có thể sử dụng kết hợp hai kỹ thuật đào tạo này với những cải tiến thời điểm theo hướng 6.16́hợp lệ trong trường hợp dịch sơ sinh học.', 'uz': "Bu gaz WMT20 Ingliz- Baskcha biomedical tarjima vazifalari uchun PHP (UTS_NLP) yaratilgan Mashine tarjima tizimini anglatadi. Koʻrsatilgan parallel kompaniya sabab, biz o'ylab turgan NMT modelini o'rganish davom etishni davom etishga davom etishni istaysiz. Ko'rsatganda, biz monolingual maʼlumot tarjima qilish uchun ta'lim kopusini qo'shishga qo'shishdik. Bizning tajribalarimizni ko'rsatadi, bu ikkita trening teknologiya birlashtirish uchun NMT modellarini ko'rsatadi, biomediya abstrakt tarjimalari davomida 6.16 BLEU foizga oshirish mumkin.", 'bg': 'Настоящата статия описва системите за машинен превод, предложени от екипа на Техническия университет за обработка на естествения език в Сидни (UTS_NLP) за англо-баските биомедицински преводи. Поради ограничените паралелни корпуси, ние предложихме да се обучи модел, който използва предварително обучени езикови модели. Освен това разширихме обучителния корпус чрез обратен превод на едноезични данни. Нашите експерименти показват, че моделите в сценарии с нисък ресурс могат да се възползват от комбинирането на тези две техники за обучение с подобрения до 6,16 процентни пункта в случай на биомедицински абстрактни преводи.', 'hr': 'Ovaj papir opisuje sustave prevođenja strojeva koje je predložio tim Univerziteta tehnologije Sydney Natural Language Processing (UTS_NLP) za zadatke za prevođenje biomedicinskog prevođenja WMT20 engleskog-baskog. Zbog ograničenog paralelnog korporacije dostupnog, predložili smo trenirati model NMT-a koji uključuje uporabu jezičkih modela. Osim toga, povećali smo trening korpus prevodeći monojezičke podatke. Naši eksperimenti pokazuju da modeli NMT u scenarijima niskih resursa mogu koristiti od kombinacije tih dva tehnika obuke s poboljšanjem do 6,16 procentnih to čka BLEU-a u slučaju biomedicinskih apstrakta prevoda.', 'da': 'Denne artikel beskriver de maskinoversættelsessystemer, der er foreslået af University of Technology Sydney Natural Language Processing (UTS_NLP) team til WMT20 engelsk-baskisk biomedicinsk oversættelse opgaver. På grund af de begrænsede parallelle korpora til rådighed, har vi foreslået at træne en BERT-fusioneret NMT model, der udnytter brugen af forudtrænede sprogmodeller. Desuden har vi udvidet uddannelseskorpusset ved at tilbageføre ensprogede data. Vores eksperimenter viser, at NMT-modeller i low-resource scenarier kan drage fordel af at kombinere disse to træningsteknikker med forbedringer på op til 6,16 BLEU procentpoint i tilfælde af biomedicinske abstrakte oversættelser.', 'de': 'Diese Arbeit beschreibt die maschinellen Übersetzungssysteme, die vom Team der University of Technology Sydney Natural Language Processing (UTS_NLP) für die WMT20 biomedizinischen Übersetzungsaufgaben vorgeschlagen wurden. Aufgrund der begrenzten Anzahl paralleler Korpora haben wir vorgeschlagen, ein BERT-fused NMT-Modell zu trainieren, das die Verwendung von vortrainierten Sprachmodellen nutzt. Darüber hinaus haben wir das Trainingskorpus durch Rückübersetzung von einsprachigen Daten erweitert. Unsere Experimente zeigen, dass NMT-Modelle in ressourcenarmen Szenarien von der Kombination dieser beiden Trainingstechniken profitieren können, mit Verbesserungen von bis zu 6,16 BLEU-Prozentpunkten bei biomedizinischen abstrakten Übersetzungen.', 'nl': "Deze paper beschrijft de machine translation systemen voorgesteld door het University of Technology Sydney Natural Language Processing (UTS_NLP) team voor de WMT20 Engels-Baskische biomedische vertaaltaken. Vanwege de beperkte parallelle corpora beschikbaar, hebben we voorgesteld om een BERT-gefused NMT model te trainen dat gebruik maakt van vooraf getrainde taalmodellen. Verder hebben we het trainingscorpus uitgebreid door eentalige data terug te vertalen. Onze experimenten tonen aan dat NMT modellen in low-resource scenario's baat kunnen hebben bij het combineren van deze twee trainingstechnieken, met verbeteringen van maximaal 6,16 BLEU percentuele punten in het geval van biomedische abstracte vertalingen.", 'id': 'Kertas ini menjelaskan sistem terjemahan mesin yang diusulkan oleh tim Perprosesan Bahasa Alami Sydney University of Technology (UTS_NLP) untuk tugas terjemahan biomedis Inggris-Basque WMT20. Karena corpora paralel terbatas yang tersedia, kami telah mengusulkan untuk melatih model NMT BERT-fusion yang menggunakan model bahasa yang dilatih sebelumnya. Selain itu, kami telah meningkatkan tubuh pelatihan dengan menerjemahkan kembali data monobahasa. Eksperimen kami menunjukkan bahwa model NMT dalam skenario sumber daya rendah dapat berguna dari kombinasi dua teknik latihan ini, dengan peningkatan sampai 6,16 poin persentasi BLEU dalam kasus terjemahan abstrak biomedis.', 'sw': 'Gazeti hili linaelezea mfumo wa tafsiri za mashine unapendekezwa na Chuo Kikuu cha Teknolojia Sydney Utafiti wa lugha ya asili (UTS_NLP) timu ya tafsiri za kitabibu za Kiingereza na Basque. Kutokana na kampuni isiyo na kiwango kikubwa, tumependekeza kufundisha muundo wa NMT wa BERT ambao umefukuzwa kwa matumizi ya mifano ya lugha iliyopigwa. Zaidi ya hayo, tumeongeza makampuni ya mafunzo kwa kutafsiri takwimu za lugha za kiutamaduni. Majaribio yetu yanaonyesha kuwa mifano ya NMT katika mitindo ya rasilimali ya chini inaweza kunufaika na kuunganisha mbinu hizi mbili za mafunzo, na maboresho ya hadi asilimia 6.16 BLEU katika kesi ya tafsiri za kitabibu.', 'ko': '본고는 시드니이공대학 자연언어처리(UTS NLP)팀이 WMT20 영어 바스크 생물의학 번역 임무를 위해 제시한 기계번역 시스템을 묘사한다.사용 가능한 병렬 언어 자료 라이브러리에 한계가 있기 때문에, 우리는 예비 훈련 언어 모델을 이용한 BERT 융합 NMT 모델을 훈련하는 것을 권장합니다.이 밖에 우리는 단어 데이터를 번역함으로써 훈련 자료 라이브러리를 확충한다.우리의 실험에 의하면 저자원 장면 중의 NMT 모델은 이 두 가지 훈련 기술의 결합에 이익을 얻을 수 있고 생물의학 요약 번역의 경우 6.16개의 BLEU 백분율 수를 높일 수 있다.', 'sq': 'Ky dokument përshkruan sistemet e përkthimit të makinave të propozuar nga ekipi i Procesimit të Gjuhave Natyrore të Universitetit të Teknologjisë Sydney (UTS_NLP) për detyrat e përkthimit biomedik anglez-bask WMT20. Për shkak të korprës paralele të kufizuar në dispozicion, ne kemi propozuar të trajnojmë një model NMT të fusionuar me BERT që nxjerr përdorimin e modeleve të gjuhës së paratrajnuar. Përveç kësaj, ne kemi rritur korpusin e trajnimit duke përkthyer prapa të dhënat monogjuhësore. Our experiments show that NMT models in low-resource scenarios can benefit from combining these two training techniques, with improvements of up to 6.16 BLEU percentual points in the case of biomedical abstract translations.', 'tr': 'Bu kagyz WMT20 Iňlisçe-Bask biomedikal terjime täblikleri üçin Uniwersitet Sydney Tehnologiýanyň Dabiýal Dil işlemesi (UTS_NLP) tarapyndan teknolojiň terjime sistemlerini tassyýar. Barlanmış parallel korporasy üçin BERT bilen birleşmiş NMT nusgasyny öňünden geçirilen dil nusgalaryny ulanmakdan çykarmak üçin teklip etdik. Mundan hem, monodil maglumatlaryny terjime eden bilim korpusyny üýtgetdik. Biziñ deneylerimiz NMT nusgalarynyň azak resurslar senaryýasynda bu iki okuw tekniklerini birleştirmekden fayda ýetirebilir we biomedical abstrakt terjimelerinde 6,16 BLEU ýüzüniň ýokarynda ýokarylyk bilen gelişmeleri bilen üýtgedip biler.', 'am': 'ይህ ፕሮግራም የቴክኖሎጂ ዩንቨርስቲ ሲዲኒ የናትሬል ቋንቋ ፕሮግራም (UTS_NLP) ተሟጋቾችን ለWMT20 እንግሊዘኛ-ባስክ የbiomedical ትርጓሜ ስርዓቶች የተዘጋጀውን የመኪና ትርጉም ስርዓቶች ይናገራል፡፡ በተደረገው ተቃራኒ ኮርፖር ምክንያት የፊርሬት ቋንቋ ሞዴላዎችን ለመጠቀም BERT-ፈተና የNMT ሞዴል አሰብተናል፡፡ ከዚህም በላይ የሞሎንቋዊ ዳታዎችን በመመለስ የግንኙነትን ኮፓስ አጨማርተናል፡፡ ፈተናዎቻችን የነፃ resource ሳናተር የNMT models እነዚህን ሁለቱን ተማሪዎችን ማቀናቀል ይጠቅማል፡፡', 'az': 'Bu kağıt WMT20 İngilizce-Basque biomedicin çeviri işləri üçün Təknoloji Üniversitesi Sydney Təknoloji Dil İşlemi (UTS_NLP) təklif edilmiş maşın çeviri sistemlərini təsdiq edir. Qasıtlı paralel korpora görə, BERT-dən birləşdirilmiş NMT modeli təhsil etmək üçün təklif etdik ki, əvvəlki dil modellerinin istifadəsini dəyişdirir. Daha sonra, təhsil korpusu monodil məlumatlarını geri çevirib artırdıq. Bizim təcrübələrimiz göstərir ki, bu iki təcrübə tekniklərini birləşdirmək üçün NMT modelləri, biomedical abstraktlı tercümələri olaraq 6,16 BLEU prosentlik nöqtələrinə qədər yaxşılaşdırılır.', 'fa': 'این کاغذ سیستم\u200cهای ترجمه ماشین را توصیف می\u200cکند که توسط دانشگاه تکنولوژی سیدنی تکنولوژی (UTS_NLP) تیم تحلیل زبان طبیعی (عملیات ترجمه\u200cهای بیولوژیک انگلیسی-باسک WMT20) برای عملیات ترجم به دلیل شرکت پارالی محدودیت موجود، ما پیشنهاد دادیم که یک مدل NMT متصل BERT را آموزش دهیم که استفاده از مدل زبانی پیش از آن را تأثیر می دهد. به علاوه، ما شرکت آموزش را با تغییر دادن داده های یک زبان افزایش دادیم. آزمایشات ما نشان می دهند که مدل NMT در سیناریو های کم منبع می تواند از ترکیب این دو تکنیک آموزش را سود دهد، با توسعه\u200cهای تا ۶.۱۶ درصد نقطه\u200cهای BLEU در مورد ترجمه\u200cهای مطلق بیولوژیک بیولوژیک.', 'bn': 'এই পত্রিকাটি বিশ্ববিদ্যালয়ের প্রযুক্তি বিশ্ববিদ্যালয়ের প্রস্তাবিত মেশিন অনুবাদ সিদ্নি ন্যাশনাল ভাষা প্রক্রিয়া (ইউটিএস_এনএলপি) দলের ব সীমিত প্যারালেল কর্পোরার কারণে আমরা প্রস্তাব করেছি বিবেরেট-ফ্লাসেড এনএমটি মডেল প্রশিক্ষণের জন্য যা প্রেমিক ভাষার মডেলের ব্যবহা এছাড়াও, আমরা প্রশিক্ষণ কোর্পাস বাড়িয়ে দিয়েছি মোনোলিভাষার তথ্য অনুবাদ করে। আমাদের পরীক্ষাগুলো দেখাচ্ছে যে নীচের সম্পদের এনএমটি মডেল এই দুটি প্রশিক্ষণ কৌশল সম্পর্কে সুবিধা প্রদান করতে পারে, যার ফলে বায়োমেডিকেল বিভাগের ভাষায় ৬', 'af': "Hierdie papier beskryf die masjien vertalingsstelsels wat voorgestel word deur die Universiteit van Tehnologie Sydney Natuurlike Taal Prosessering (UTS_NLP) vir die WMT20 Engels-Basque biomediese vertalingstaak. Omdat ons die beperkte parallele korpora beskikbaar is, het ons voorgestel om 'n BERT-verfoeisde NMT-model te trein wat die gebruik van vorreënde taal modele verwyder. Ons het ook die oefening korpus vergroot deur monolinglike data terugvertaling. Ons eksperimente wys dat NMT-modelles in lae-hulpbron-scenarios kan voordeel van die kombinasie van hierdie twee onderwerp-teknike, met verbeteringe van tot 6.16 BLEU persentpunte in die geval van biomediese abstrakte vertalings.", 'bs': 'Ovaj papir opisuje sisteme prevođenja mašine koje je predložio tim Univerziteta tehnologije Sydney Natural Language Processing (UTS_NLP) za zadatke za prevođenje biomedicinskog prevođenja WMT20 engleskog-baskog. Zbog ograničenog paralelnog korporacije dostupnog, predložili smo trenirati model NMT-a koji uključuje uporabu jezičkih modela. Osim toga, povećali smo trening korpus prevodeći monojezičke podatke. Naši eksperimenti pokazuju da modeli NMT u scenarijima niskih resursa mogu imati koristi od kombinacije tih dva tehnika obuke, s poboljšanjem do 6,16 procentnih bodova BLEU-a u slučaju biomedicinskih abstrakta prevoda.', 'cs': 'Tento článek popisuje systémy strojového překladu navržené týmem UTS_NLP (University of Technology Sydney Natural Language Processing) pro úlohy WMT20 anglicko-baskického biomedicínského překladu. Vzhledem k omezenému dostupnému paralelnímu korpusu jsme navrhli trénovat model NMT fúzovaný BERT, který využívá předem trénovaných jazykových modelů. Kromě toho jsme rozšířili tréninkový korpus zpětným překladem jednojzyčných dat. Naše experimenty ukazují, že NMT modely v scénářích s nízkými zdroji mohou těžit z kombinace těchto dvou tréninkových technik s vylepšením až 6,16 BLEU procentuálních bodů v případě biomedicínských abstraktních překladů.', 'et': 'Käesolevas artiklis kirjeldatakse Sydney Tehnikaülikooli looduskeele töötlemise (UTS_NLP) meeskonna poolt pakutud masintõlkesüsteeme WMT20 inglise-baski biomeditsiinilise tõlke ülesannete jaoks. Piiratud paralleelsete korpuste tõttu oleme teinud ettepaneku koolitada BERT-iga ühendatud NMT mudel, mis võimendab eelõpetatud keelemudelite kasutamist. Lisaks oleme koolituskorpust täiendanud ühekeelsete andmete tagasitõlkimisega. Meie eksperimendid näitavad, et NMT mudelid madala ressursiga stsenaariumides saavad kasu nende kahe koolitusmeetodi kombineerimisest, parandades biomeditsiiniliste abstraktsete tõlkete puhul kuni 6,16 BLEU protsendipunkti.', 'hy': 'Այս աշխատանքում նկարագրված են Սիդնեի տեխնոլոգիայի համալսարանի տեխնոլոգիաների բնական լեզվի մշակույթի (UDS_NSP) խումբի առաջարկած մեքենային թարգմանման համակարգերը, որոնք աշխատում են Անգլերեն-Բասկի բիոբեկնա Քանի որ հասանելի է սահմանափակ զուգահեռ կառուցվածք, մենք առաջարկել ենք մի BER-ով միացված NMT մոդել վարժեցնել, որը օգտագործում է նախավարժված լեզվի մոդելներ: Ավելին, մենք ավելացրել ենք ուսուցման մարմինը մեկլեզու տվյալներ վերադարձնելով: Մեր փորձարկումները ցույց են տալիս, որ ցածր ռեսուրսների սցենարներում NMT-ի մոդելները կարող են շահույթ ունենալ այս երկու ուսումնասիրության մեթոդների համակցումից մինչև 6.16 տոկոսով բարելավման համար բիոբժշկական վերացական թարգմանությունների դեպքում', 'ca': "This paper describes the machine translation systems proposed by the University of Technology Sydney Natural Language Processing (UTS_NLP) team for the WMT20 English-Basque biomedical translation tasks.  Gràcies a la limitada quantitat de corpores paralèls disponibles, hem proposat formar un model NMT fusionat amb BERT que aprofiti l'ús de models de llenguatge pré-entrenats. A més, hem augmentat el cos d'entrenament traduïnt les dades monolingües. Our experiments show that NMT models in low-resource scenarios can benefit from combining these two training techniques, with improvements of up to 6.16 BLEU percentual points in the case of biomedical abstract translations.", 'fi': 'Tässä artikkelissa kuvataan konekäännösjärjestelmiä, joita University of Technology Sydney Natural Language Processing (UTS_NLP) -tiimi on ehdottanut WMT20 englanti-baski biolääketieteen käännöstehtäviin. Koska saatavilla on rajallisia rinnakkaisia korpusia, olemme ehdottaneet BERT-fuusioitua NMT-mallia, joka hyödyntää esikoulutettujen kielimallien käyttöä. Lisäksi olemme lisänneet koulutuskokonaisuutta kääntämällä yksikielistä tietoa taaksepäin. Kokeemme osoittavat, että NMT-mallit vähäresurssisissa skenaarioissa voivat hyötyä näiden kahden koulutustekniikan yhdistämisestä ja jopa 6,16 BLEU-prosenttiyksikön parannuksista biolääketieteellisten abstraktien käännösten tapauksessa.', 'jv': 'Perintah iki oleh pancen sistem tarjamahan sing gawe nggawe ngubah Universite Teknêji Sidni Normal Language Procesing Ngomongé karo perusahaan nganggo coro-perusahaan sing wis rampung, awak dhéwé wis supoyo nggawe model BERT-nambah NMT sing bisa ngelarang modèl langgambar uwong. liyane, awak dhéwé wis ngerasakno nggo ngerasakno karo perusahaan anyar luwih dumateng. Awak dhéwé éntuk ngéwangé sawetara model NMT nang sekènari apat-apat kanggo nggawe teknik sing nyimpen iki, lan bantayan kanggo ngerayakno ujaran 6.16% sing ujaran kanggo kowé sing bakal terus nyong bisa basa.', 'ha': "Wannan karatun na bayyana tsarin masu fassarar mashine na'urar da aka buɗe wa Universitin Technical Syddani Due to the limited parallel corpora available, we have proposed to train a BERT-fused NMT model that leverages the use of pretrained language models.  Da haka, mun ƙara kowacin mafarin da aka baka fassarwa data na monoli. Kayan jarrabõyinmu, za'a nuna misalin NMT cikin fassarar-resource na ƙaranci, za'a iya amfani da su koma wannan tufãfin mafarin biyu, da mafariko ko taki a shekara 6.16BLEU a cikin fassarar mutane idan an sami fassarori na bizarci.", 'he': 'העיתון הזה מתאר את מערכות התרגום המכונית שהצעה על ידי צוות התרגום טבעי של אוניברסיטת הטכנולוגיה סידני (UTS_NLP) עבור משימות התרגום הביומדיקני אנגלי-בסקית WMT20. בגלל הקופורה המקבילה המוגבלת זמינה, הצענו לאמן מודל NMT מבולבל BERT שמעלה את השימוש של דוגמני שפה מתאמנים מראש. חוץ מזה, הגדלנו את הקורפוס של האימונים על ידי התרגמות אחורה של נתונים monolingual. הניסויים שלנו מראים שדוגמנים NMT בתרחישות משאבים נמוכים יכולים להשתמש בשלב שילוב שני טכניקות אימונים אלה, עם שיפורים עד 6.16 נקודות אחוזיות BLEU במקרה של תרגומות ביולומדיקות אוסטרקטיות.', 'sk': 'V prispevku so opisani sistemi strojnega prevajanja, ki jih je predlagala ekipa Univerze za tehnološko obdelavo naravnega jezika v Sydneyu (UTS_NLP) za naloge biomedicinskega prevajanja WMT20 angleško-baskovsko. Zaradi omejenih razpoložljivih vzporednih korpusov smo predlagali usposabljanje modela NMT z BERT-om spojenega, ki izkorišča uporabo predtreniranih jezikovnih modelov. Poleg tega smo s prevajanjem enojezičnih podatkov povečali korpus usposabljanja. Naši eksperimenti kažejo, da lahko NMT modeli v scenarijih z nizkimi viri koristijo od kombinacije teh dveh tehnik usposabljanja z izboljšavami do 6,16 odstotnih točk BLEU v primeru biomedicinskih abstraktnih prevodov.', 'bo': 'ཤོག་བྱང་འདིས་རྩིས་འཁོར་གྱི་ལུགས་སྤྲོད་ཀྱི་མ་ལག་གི་ཆ་འཕྲིན་ཡིག་ཆའི་ནང་དུ་སྤྲོད་ཡོད་པའི་ཆ་འཕྲིན་ལུགས་ཀྱི་གནས་སྟངས་ལ་འགྲེལ་བཤད་བ སྦུང་མཐུད་མཁན་དབུགས་ཆེན་པོ་ཞིག་ལ་བསྟེན་ནས་ ང་ཚོའི་ནང་དུ་BERT-fused NMT མིག་གཟུགས་རིས་ལ་སྤྱོད་ཀྱི་རྒྱུ་དངོས་ཉེན་འདུག ད་དུང་། ང་ཚོས་སྒེར་གྱི་དབུགས་ཆ་ལ་རྒྱབ་སྐྱོར་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་བརྟག་ཞིབ་ཀྱིས་NMT མ་དཔེ་གཞི་རྒྱ་ཆེ་བ་དག་གི་གནས་སྟངས་འདི་གཉིས་ཀྱི་མཉམ་དུ་བསྡད་ཐབས་ལམ་གཉིས་མཉམ་དུ་སྤྱོད་ཐུབ།'}
{'en': 'Lite Training Strategies for Portuguese-English and English-Portuguese Translation', 'ar': 'استراتيجيات تدريب لايت للترجمة البرتغالية-الإنجليزية والترجمة الإنجليزية-البرتغالية', 'pt': 'Estratégias de Treinamento Lite para Tradução Português-Inglês e Inglês-Português', 'es': 'Estrategias de formación básica para la traducción portugués-inglés e inglés-portugués', 'fr': 'Stratégies de formation allégées pour la traduction portugais-anglais et anglais-portugais', 'ja': 'ポルトガル語-英語および英語-ポルトガル語翻訳のためのLITEトレーニング戦略', 'zh': '葡萄牙语-英语与英语-葡萄牙语译之精简版培训策', 'hi': 'पुर्तगाली-अंग्रेजी और अंग्रेजी-पुर्तगाली अनुवाद के लिए लाइट प्रशिक्षण रणनीतियाँ', 'ru': 'Lite Стратегии обучения для португальско-английского и английско-португальского перевода', 'ga': 'Straitéisí Oiliúna Lite don Aistriúchán Portaingéilis-Béarla agus Béarla-Portaingéilis', 'ka': 'Lite Training Strategies for Portuguese-English and English-Portuguese Translation', 'hu': 'Lite tréning stratégiák portugál-angol és angol-portugál fordításhoz', 'el': 'Στρατηγικές κατάρτισης για πορτογαλικά-αγγλικά και αγγλικά-πορτογαλικά μετάφραση', 'lt': 'Lite Training Strategies for Portuguese-English and English-Portuguese Translation', 'kk': 'Португалия- ағылшын және ағылшын- португалық аудармасының Lite оқыту стратегиясы', 'mk': 'Стратегии за мало обука за португалско-англиско и англиско-португалско преведување', 'it': 'Strategie di formazione Lite per traduzione portoghese-inglese e inglese-portoghese', 'ml': 'പോര്\u200dട്ടുഗീഷ്- ഇംഗ്ലീഷ്- ഇംഗ്ലീഷ്- പോര്\u200dട്ടുഗീഷ് പരിശീലന സ്ട്രേറ്റേജികള്\u200d', 'mt': 'Strateġiji ta’ Taħriġ Litwali għat-Traduzzjoni Portugiża-Ingliża u Ingliża-Portugiża', 'ms': 'Strategi Latihan Lite untuk Terjemahan Portugis-Inggeris dan Inggeris-Portugis', 'mn': 'Португали, Англи, Англи-Португали хөгжлийн дасгал хөгжлийн стратеги', 'sr': 'Strategije za obuku Lite za prevod portugalskog-engleskog i engleskog-portugalskog', 'ro': 'Strategii de instruire Lite pentru traducerea portugheză-engleză și engleză-portugheză', 'no': 'Lite- treningsstrategiar for portugisisk og engelsk- portugisisk omsetjing', 'pl': 'Strategia szkoleniowa Lite dla tłumaczeń portugalsko-angielski i angielsko-portugalski', 'si': 'Name', 'so': 'Lit Training Strategies for Burtuqiis- Ingiriis- Ingiriis- Ingiriis- Burtuqiis', 'sv': 'Lite utbildningsstrategier för portugisiska-engelska och engelsk-portugisiska översättning', 'ta': 'Name', 'ur': 'پورٹوگل-انگلیسی اور انگلیسی-پورٹوگلیسی ترینسی استراتژی', 'uz': 'Name', 'vi': 'Các phương pháp giáo dục Tiếng Bồ Đào Nha và Tiếng Anh-Bồ Đào Nha', 'bg': 'Стратегии за обучение на португалско-английски и английски-португалски превод', 'nl': 'Lite Opleidingsstrategieën voor Portugees-Engels en Engels-Portugees Vertalen', 'da': 'Lite træningsstrategier til portugisisk-engelsk og engelsk-portugisisk oversættelse', 'hr': 'Lite Training Strategies for Portuguese-English and English-Portuguese Translation', 'id': 'Strategi Pelatihan Lite untuk Translation Portugis-Inggris dan Inggris-Portugis', 'de': 'Lite Trainingsstrategien für Portugiesisch-Englisch und Englisch-Portugiesisch Übersetzung', 'fa': 'استراتژی\u200cهای آموزش Lite برای ترجمه\u200cهای پورتوژیک-انگلیسی و انگلیسی-پورتوژیک', 'sw': 'Mitizo michache ya mafunzo kwa Tafsiri ya Kireno-Kiingereza na Kiingereza-Kireno', 'tr': 'Portugalça-Iňlisçe we Ingilisçe-Portugalça terjime etmek üçin Lite Ewezam Strateýatlary', 'ko': '포르투갈어-영어와 영어-포르투갈어 번역의 Lite 교육 전략', 'sq': 'Strategjitë e trajnimit të vogël për përkthimin portugal-anglez dhe anglez-portugal', 'af': 'Lite Oefening Strategies vir Portugees- Engels en Engels- Portugees Vertaling', 'am': 'የፖርቱጋልኛ-እንግሊዘኛ እና እንግሊዝኛ-ፖርቱጋልኛ ትርጉም', 'hy': 'Պորտուգալերեն-անգլերեն և անգլերեն-պորտուգալերեն թարգմանման կարճ ուսումնասիրությունները', 'az': 'Portugalca-İngilizce və İngilizce-Portugalca çeviri üçün Lite Training Strategies', 'bn': 'পর্তুগীজ- ইংরেজী এবং ইংরেজী পর্তুগীজ অনুবাদের জন্য লাইট প্রশিক্ষণ কৌশল', 'ca': 'Lite Training Strategies for Portuguese-English and English-Portuguese Translation', 'bs': 'Lite Training Strategies for Portuguese-English and English-Portuguese Translation', 'cs': 'Lite tréninkové strategie pro portugalsko-anglický a anglicko-portugalský překlad', 'et': 'Lite koolitusstrateegiad portugali-inglise ja inglise-portugali tõlke jaoks', 'fi': 'Lite-koulutusstrategiat portugali-englanti ja englanti-portugali kääntämiseen', 'ha': 'KCharselect unicode block name', 'sk': 'Lite strategije usposabljanja za prevajanje portugalsko-angleščina in angleščino-portugalščina', 'jv': 'Language', 'he': 'אסטרטגיות אימונים קטנות לתרגום פורטוגזי-אנגלי ואנגלי-פורטוגזי', 'bo': 'Lite Training Strategies for Portuguese-English and English-Portuguese Translation'}
{'en': 'Despite the widespread adoption of deep learning for machine translation, it is still expensive to develop high-quality translation models. In this work, we investigate the use of pre-trained models, such as T5 for Portuguese-English and English-Portuguese translation tasks using low-cost hardware. We explore the use of Portuguese and English pre-trained language models and propose an adaptation of the English tokenizer to represent Portuguese characters, such as diaeresis, acute and grave accents. We compare our models to the Google Translate API and MarianMT on a subset of the ParaCrawl dataset, as well as to the winning submission to the WMT19 Biomedical Translation Shared Task. We also describe our submission to the WMT20 Biomedical Translation Shared Task. Our results show that our models have a competitive performance to state-of-the-art models while being trained on modest hardware (a single 8 GB gaming GPU for nine days). Our data, models and code are available in our GitHub repository.', 'ar': 'على الرغم من التبني الواسع للتعلم العميق للترجمة الآلية ، لا يزال تطوير نماذج ترجمة عالية الجودة مكلفًا. في هذا العمل ، نحقق في استخدام النماذج المدربة مسبقًا ، مثل T5 لمهام الترجمة البرتغالية-الإنجليزية ، والإنجليزية-البرتغالية باستخدام أجهزة منخفضة التكلفة. نستكشف استخدام نماذج اللغة البرتغالية والإنجليزية المدربة مسبقًا ونقترح تكييف الرمز المميز للغة الإنجليزية لتمثيل الأحرف البرتغالية ، مثل الاختلاف ، واللهجات الحادة والخطيرة. قارنا نماذجنا بواجهة برمجة تطبيقات الترجمة من Google و MarianMT في مجموعة فرعية من مجموعة بيانات ParaCrawl ، بالإضافة إلى التقديم الفائز إلى المهمة المشتركة للترجمة الطبية الحيوية WMT19. نصف أيضًا تقديمنا إلى المهمة المشتركة للترجمة الطبية الحيوية WMT20. تظهر نتائجنا أن طرازاتنا تتمتع بأداء تنافسي مقارنة بأحدث الموديلات أثناء تدريبها على أجهزة متواضعة (وحدة معالجة رسومات واحدة بحجم 8 جيجابايت لمدة تسعة أيام). تتوفر بياناتنا ونماذجنا ورموزنا في مستودع GitHub الخاص بنا.', 'fr': "Malgré l'adoption généralisée du deep learning pour la traduction automatique, le développement de modèles de traduction de haute qualité reste onéreux. Dans ce travail, nous étudions l'utilisation de modèles pré-entraînés, tels que T5 pour les tâches de traduction portugais-anglais et anglais-portugais à l'aide de matériel peu coûteux. Nous explorons l'utilisation de modèles linguistiques pré-formés en portugais et en anglais et proposons une adaptation du tokenizer anglais pour représenter les caractères portugais, tels que le tréma, les accents aigus et graves. Nous comparons nos modèles à l'API Google Translate et à MarianMT sur un sous-ensemble du jeu de données ParaCrawl, ainsi qu'à la soumission gagnante pour la tâche partagée de traduction biomédicale WMT19. Nous décrivons également notre soumission à la tâche partagée de traduction biomédicale WMT20. Nos résultats montrent que nos modèles offrent des performances compétitives par rapport aux modèles de pointe tout en étant formés sur du matériel modeste (un seul GPU de jeu de 8 Go pendant neuf jours). Nos données, modèles et code sont disponibles dans notre référentiel GitHub.", 'es': 'A pesar de la adopción generalizada del aprendizaje profundo para la traducción automática, sigue siendo caro desarrollar modelos de traducción de alta calidad. En este trabajo, investigamos el uso de modelos previamente entrenados, como el T5 para las tareas de traducción portugués-inglés e inglés-portugués con hardware de bajo costo. Exploramos el uso de modelos lingüísticos preentrenados en portugués e inglés y proponemos una adaptación del tokenizador inglés para representar caracteres portugueses, como diéresis, acentos agudos y graves. Comparamos nuestros modelos con la API de Google Translate y MarianMT en un subconjunto del conjunto de datos de ParaCrawl, así como con la presentación ganadora de la Tarea Compartida de Traducción Biomédica WMT19. También describimos nuestra presentación a la tarea compartida de traducción biomédica del WMT20. Nuestros resultados muestran que nuestros modelos tienen un rendimiento competitivo con respecto a los modelos de última generación, a la vez que reciben capacitación en hardware modesto (una sola GPU para juegos de 8 GB durante nueve días). Nuestros datos, modelos y código están disponibles en nuestro repositorio de GitHub.', 'pt': 'Apesar da ampla adoção do aprendizado profundo para tradução automática, ainda é caro desenvolver modelos de tradução de alta qualidade. Neste trabalho, investigamos o uso de modelos pré-treinados, como o T5, para tarefas de tradução português-inglês e inglês-português usando hardware de baixo custo. Exploramos o uso de modelos de linguagem pré-treinados em português e inglês e propomos uma adaptação do tokenizer inglês para representar caracteres portugueses, como trema, acentos agudos e graves. Comparamos nossos modelos com a API do Google Translate e MarianMT em um subconjunto do conjunto de dados ParaCrawl, bem como com o envio vencedor para a Tarefa Compartilhada de Tradução Biomédica WMT19. Também descrevemos nosso envio para a Tarefa Compartilhada de Tradução Biomédica do WMT20. Nossos resultados mostram que nossos modelos têm um desempenho competitivo para modelos de última geração enquanto são treinados em hardware modesto (uma única GPU de jogos de 8 GB por nove dias). Nossos dados, modelos e código estão disponíveis em nosso repositório GitHub.', 'ja': '機械翻訳にディープラーニングが広く採用されているにもかかわらず、高品質の翻訳モデルを開発するには依然としてコストがかかります。 この作業では、ポルトガル語-英語および英語-ポルトガル語の翻訳タスクのためのT 5など、事前にトレーニングされたモデルの使用について、低コストのハードウェアを使用して調査します。 私たちは、ポルトガル語と英語の事前トレーニングされた言語モデルの使用を探求し、ダイアレシス、急性および墓のアクセントなどのポルトガル文字を表すための英語のトークナイザーの適応を提案します。 Googleでは、モデルをParaCrawlデータセットのサブセットにあるGoogle Translate APIとMarianMTと比較し、WMT 19 Biomedical Translation Shared Taskへの応募の結果と比較しています。 また、WMT 20 Biomedical Translation Shared Taskへの提出についても説明します。 私たちの結果は、私たちのモデルは、控えめなハードウェアでトレーニングを受けながら、最先端のモデルと競争力のあるパフォーマンスを持っていることを示しています（ 9日間、単一の8 GBゲーミングGPU ）。 当社のデータ、モデル、コードは、当社のGitHubリポジトリで入手できます。', 'hi': 'मशीन अनुवाद के लिए गहरी शिक्षा के व्यापक रूप से अपनाने के बावजूद, उच्च गुणवत्ता वाले अनुवाद मॉडल विकसित करना अभी भी महंगा है। इस काम में, हम पूर्व-प्रशिक्षित मॉडल के उपयोग की जांच करते हैं, जैसे कि कम लागत वाले हार्डवेयर का उपयोग करके पुर्तगाली-अंग्रेजी और अंग्रेजी-पुर्तगाली अनुवाद कार्यों के लिए टी 5। हम पुर्तगाली और अंग्रेजी पूर्व-प्रशिक्षित भाषा मॉडल के उपयोग का पता लगाते हैं और पुर्तगाली पात्रों का प्रतिनिधित्व करने के लिए अंग्रेजी टोकनाइज़र के अनुकूलन का प्रस्ताव करते हैं, जैसे डायएरिसिस, तीव्र और गंभीर उच्चारण। हम अपने मॉडल की तुलना ParaCrawl डेटासेट के सबसेट पर Google Translate API और MarianMT से करते हैं, साथ ही साथ WMT19 Biomedical Translation Shared Task के लिए विजेता सबमिशन के लिए भी करते हैं। हम WMT20 बायोमेडिकल अनुवाद साझा कार्य के लिए हमारे सबमिशन का भी वर्णन करते हैं। हमारे परिणामों से पता चलता है कि हमारे मॉडल में मामूली हार्डवेयर (नौ दिनों के लिए एक एकल 8 जीबी गेमिंग जीपीयू) पर प्रशिक्षित होने के दौरान अत्याधुनिक मॉडल के लिए एक प्रतिस्पर्धी प्रदर्शन है। हमारे डेटा, मॉडल और कोड हमारे GitHub भंडार में उपलब्ध हैं।', 'zh': '虽深学广于机器翻译,而开高质量之译模犹贵。 于是考用豫教,如T5用葡萄牙语 - 英语用低成本硬件英语 - 葡萄牙语译。 探葡萄牙语英语预训语形之用,立英语表器改编,以示葡萄牙语字符,如diaeresis,锐甚之音。 以吾形与ParaCrawl数集上之Google Translate API与MarianMT及WMT19生物医学译共之获奖言之。 述我WMT20生物医学译共其文。 吾之的结果表明,吾硬件(一8GB之戏GPU九日)教习之时,有先入之竞争力。 吾数、模形、代码可得于吾 GitHub 储库。', 'ru': 'Несмотря на широкое распространение глубокого обучения машинному переводу, разработка высококачественных моделей перевода все еще является дорогостоящей. В этой работе мы исследуем использование предварительно обученных моделей, таких как T5 для задач португальско-английского и английско-португальского перевода с использованием недорогого оборудования. Мы изучаем использование португальских и английских предварительно обученных языковых моделей и предлагаем адаптацию английского токенизатора для представления португальских символов, таких как диарезис, острый и серьезный акценты. Мы сравниваем наши модели с Google Translate API и MarianMT на подмножестве данных ParaCrawl, а также с победным представлением на WMT19 Biomedical Translation Shared Task. Мы также описываем наше представление к Общей задаче Биомедицинского Перевода WMT20. Наши результаты показывают, что наши модели обладают конкурентоспособной производительностью по сравнению с самыми современными моделями, обучаясь на скромном оборудовании (один игровой графический процессор на 8 ГБ в течение девяти дней). Наши данные, модели и код доступны в нашем репозитории GitHub.', 'ga': 'In ainneoin go nglactar go forleathan le foghlaim dhomhain le haghaidh aistriúcháin mheaisín, tá sé costasach fós samhlacha aistriúcháin ardchaighdeáin a fhorbairt. San obair seo, déanaimid imscrúdú ar úsáid samhlacha réamh-oilte, mar T5 le haghaidh tascanna aistriúcháin Portaingéilis-Béarla agus Béarla-Portaingéilis ag baint úsáide as crua-earraí ar chostas íseal. Déanaimid iniúchadh ar mhúnlaí teanga réamh-oilte na Portaingéile agus an Bhéarla agus molaimid oiriúnú ar an chomharthaí Béarla chun carachtair na Portaingéile a léiriú, ar nós diaeresis, accents géara agus uaigheanna. Déanaimid ár samhlacha a chur i gcomparáid le API Google Translate agus MarianMT ar fho-thacar den tacar sonraí ParaCrawl, chomh maith leis an aighneacht bhuaiteach chuig Tasc Comhroinnte Aistriúcháin Bithleighis WMT19. Déanaimid cur síos freisin ar ár n-aighneacht do Thasc Comhroinnte um Aistriú Bithleighis WMT20. Léiríonn ár dtorthaí go bhfuil feidhmíocht iomaíoch ag ár samhlacha i gcomparáid le samhlacha úrscothacha agus iad á n-oiliúint ar chrua-earraí measartha (GPU cluichíochta aonair 8GB ar feadh naoi lá). Tá ár sonraí, ár samhlacha agus ár gcód ar fáil inár stór GitHub.', 'ka': 'მაქსინური გადაწყვეტილებისთვის უფრო დიდი სწავლების მიღება, მაქსინური გადაწყვეტილებისთვის უფრო ძალიან ძალიან საკუთარი გადაწყვეტილება. ამ სამუშაოში, ჩვენ განვიყენებთ წინ განვიყენებული მოდელების გამოყენება, როგორც T5 პორგუტებური-ანგლისური და ინგლისური-პორგუტებური განვიყენებული სამუშაო დავა ჩვენ პორგუტებური და ინგლისური წინასწარმოადგენის მოდელების გამოყენებას გამოყენებთ და ინგლისური ტოკენიზერის აკაპექტირებას გამოყენება პორგუტებური სიმბოლოების, როგორც დიაერიზ ჩვენ ჩვენი მოდელები Google Translate API და MarianMT-თან პარაკრალის მონაცემების სუბსეტიდან შემდგენებთ, და WMT19 Biomedical Translation Shared Task-თან დავიწყებთ. ჩვენ ასევე აღწერეთ ჩვენი გადაწყვეტილება WMT20 ბიომედიციური გადაწყვეტილი საქმე. ჩვენი წარმოდგენები ჩვენი მოდელების კონპექციური გამოსახულება სახელსაწყისი მოდელებისთვის, როდესაც კონპექციური ჰაპექტირებში განაკეთებულია (ერთი 8GB GPU-ს 9 დღეს და ჩვენი მონაცემები, მოდელები და კოდი გვაქვს ჩვენი GitHub რეპოზიტორიში.', 'el': 'Παρά την ευρεία υιοθέτηση της βαθιάς μάθησης για τη μηχανική μετάφραση, η ανάπτυξη μοντέλων μετάφρασης υψηλής ποιότητας εξακολουθεί να είναι δαπανηρή. Σε αυτή την εργασία, διερευνούμε τη χρήση προ-εκπαιδευμένων μοντέλων, όπως το Τ5 για εργασίες πορτογαλικής-αγγλικής και αγγλικής-πορτογαλικής μετάφρασης χρησιμοποιώντας χαμηλού κόστους υλικό. Εξετάζουμε τη χρήση πορτογαλικών και αγγλικών προ-εκπαιδευμένων γλωσσικών μοντέλων και προτείνουμε μια προσαρμογή του αγγλικού Tokenizer για να αναπαραστήσει πορτογαλικούς χαρακτήρες, όπως διαέραση, οξείες και σοβαρές προφορές. Συγκρίνουμε τα μοντέλα μας με το API και το MarianMT σε ένα υποσύνολο του συνόλου δεδομένων καθώς και με την επιτυχημένη υποβολή στην κοινή εργασία βιοϊατρικής μετάφρασης. Περιγράφουμε επίσης την υποβολή μας στην Κοινή Εργασία Βιοϊατρικής Μετάφρασης. Τα αποτελέσματά μας δείχνουν ότι τα μοντέλα μας έχουν ανταγωνιστική απόδοση σε σχέση με τα σύγχρονα μοντέλα ενώ εκπαιδεύονται σε μέτριο υλικό (ένα μόνο 8για εννέα ημέρες). Τα δεδομένα, τα μοντέλα και ο κώδικας μας είναι διαθέσιμα στο αποθετήριο μας.', 'hu': 'Annak ellenére, hogy széles körben alkalmazzák a mélytanulást a gépi fordításban, még mindig drága a kiváló minőségű fordítási modellek kidolgozása. Ebben a munkában megvizsgáljuk az előre képzett modellek, mint például a T5 portugál-angol és angol-portugál fordítási feladatok használatát, olcsó hardverekkel. Feltárjuk a portugál és angol előképzett nyelvi modellek használatát, és javasoljuk az angol tokenizer adaptációját a portugál karakterek, mint például diaeresis, akut és súlyos akcentusok ábrázolására. Modelljeinket összehasonlítjuk a ParaCrawl adatkészlet Google Translate API-jával és MarianMT-jével, valamint a WMT19 Biomedical Translation Shared Task nyertes beadványával. Azt is ismertetjük, hogy benyújtottunk a WMT20 Biomedical Translation Shared Task részére. Eredményeink azt mutatják, hogy modelleink versenyképes teljesítménnyel rendelkeznek a korszerű modellekhez képest, miközben szerény hardveren (egyetlen 8 GB-os játékprocesszor kilenc napig). Adataink, modelleink és kódjaink elérhetőek a GitHub adattárunkban.', 'kk': 'Компьютердің аудармасының үлкен түсінікті оқыту үшін көтерілікті көтеріліп тұрғанша, әлі сапатты аудармасының үлгілерін жасау үшін бұл ә Бұл жұмыс ішінде біз алдын- оқылған моделдерді қолданып, мысалы, Португализ- ағылшын және ағылшын- Португализ аудармалардың тапсырмаларын қолдануға зерттейміз. Біз португалдық және ағылшын тіл үлгілерін зерттеп, ағылшын токенизаторының адаптациясын қолдану үшін португалдық таңбаларын, мысалы диаэрис, акценттері, артық және маңызды акценттерін көр Біз үлгілерімізді Google Translate API және MarianMT дегенге ParaCrawl деректер қорларының ішінде салыстырып, WMT19 биомедикалық аудармалардың ортақтастырылған тапсырмасына жұмсау үшін салыстырамыз. Мұндай-ақ WMT20 биомедикалық аудармалардың ортақ тапсырмасына жіберімізді таңдаймыз. Біздің нәтижелеріміздің моделдеріміздің күй- жай моделдеріне бұл күй- жай бағдарламаларда оқылғанда (9 күн бойынша 8Гб GPU ойынының бір жалғыз болып жатқанын көрсетеді). Біздің деректеріміз, моделдеріміз мен кодымыз GitHub репозиториясында бар.', 'lt': 'Despite the widespread adoption of deep learning for machine translation, it is still expensive to develop high-quality translation models.  Šiame darbe tiriame iš anksto parengtų modelių, pavyzdžiui, T5, naudojimą vertimo portugalų, anglų ir portugalų kalbomis užduotims naudojant pigią techninę įrangą. Mes tiriame iš anksto išmokytų kalbų portugalų ir anglų kalbų modelių naudojimą ir siūlome pritaikyti anglų kalbos ženklą, kad būtų atstovaujami portugalų ženklams, pvz., diaerezei, ūminiams ir sunkiems akcentams. Palyginame savo modelius su Google Translate API ir MarianMT pagal ParaCrawl duomenų rinkinio pogrupį, taip pat su laimėjusia paraiška WMT19 Biomedical Translation Shared Task. Mes taip pat apibūdiname savo pareiškimą WMT20 Biomedicinos vertimo bendru uždaviniu. Mūsų rezultatai rodo, kad mūsų modeliai veikia konkurencingai moderniausių modelių atžvilgiu, tuo pačiu metu jie mokomi nedidelėje techninėje įrangoje (vienoje 8 GB žaidimų GPU devynias dienas). Mūsų duomenys, modeliai ir kodai yra prieinami mūsų GitHub saugykloje.', 'it': "Nonostante l'adozione diffusa del deep learning per la traduzione automatica, è ancora costoso sviluppare modelli di traduzione di alta qualità. In questo lavoro, esaminiamo l'uso di modelli pre-formati, come T5 per le attività di traduzione portoghese-inglese e inglese-portoghese utilizzando hardware a basso costo. Esploriamo l'uso di modelli di lingua portoghese e inglese pre-addestrati e proponiamo un adattamento del tokenizer inglese per rappresentare caratteri portoghesi, come diaeresi, accenti acuti e gravi. Confrontiamo i nostri modelli con l'API Google Translate e MarianMT su un sottoinsieme del dataset ParaCrawl, così come con la presentazione vincente al WMT19 Biomedical Translation Shared Task. Descriviamo anche la nostra presentazione al WMT20 Biomedical Translation Shared Task. I nostri risultati mostrano che i nostri modelli hanno prestazioni competitive rispetto ai modelli all'avanguardia pur essendo addestrati su hardware modesto (una singola GPU da gaming da 8 GB per nove giorni). I nostri dati, modelli e codice sono disponibili nel nostro repository GitHub.", 'mk': 'И покрај широкото усвојување на длабоко учење за машински превод, сé уште е скапо да се развијат висококвалитетни преводни модели. Во оваа работа, ние ја истражуваме употребата на предобучени модели, како што е Т5 за португалско-англиско и англиско-португалско преводни задачи користејќи нискотрошен хардвер. Го истражуваме употребата на португалски и англиски предобучени јазички модели и предложуваме адаптација на англискиот токенизатор за да ги претставува португалските ликови, како што се диереза, акутни и гробни акценти. Ги споредуваме нашите модели со Google Translate API и MarianMT на подгрупата на ParaCrawl датотеките, како и со победничкото поднесување на WMT19 Biomedical Translation Shared Task. Ние, исто така, го опишуваме нашето поднесување на WMT20 Биомедицинска преводна задача. Нашите резултати покажуваат дека нашите модели имаат конкурентна резултат со најновите модели додека се тренираат на скромен хардвер (еден GPU од 8ГБ играње за девет дена). Нашите податоци, модели и код се достапни во нашиот резервоар на GitHub.', 'ms': 'Walaupun penerimaan yang luas belajar dalam untuk terjemahan mesin, ia masih mahal untuk mengembangkan model terjemahan berkualiti tinggi. Dalam kerja ini, kami menyelidiki penggunaan model yang dilatih, seperti T5 untuk tugas terjemahan Portugis-Inggeris dan Inggeris-Portugis menggunakan perkakasan yang mahal. Kami mengeksplorasi penggunaan model bahasa Portugis dan bahasa Inggeris yang dilatih-dilatih dan melamar penyesuaian tokenizer Inggeris untuk mewakili aksara Portugis, seperti diaeresis, aksen akut dan kubur. Kami membandingkan model kami dengan Google Translate API dan MarianMT pada subset set data ParaCrawl, serta dengan penghantaran yang menang ke WMT19 Biomedical Translation Shared Task. Kami juga menggambarkan penghantaran kami kepada Tugas Berkongsi Perjemahan Biomedis WMT20. Hasil kita menunjukkan bahawa model kita mempunyai prestasi kompetitif untuk model terbaik semasa dilatih pada perkakasan sederhana (GPU permainan 8GB tunggal selama sembilan hari). Data, model dan kod kita tersedia dalam repositori GitHub kita.', 'ml': 'മെഷിന്\u200d പരിഭാഷക്കുവേണ്ടി ആഴത്തെ പഠിപ്പിക്കുന്നതിന്റെ വിശാലമായ പ്രദര്\u200dശിപ്പിക്കുന്നതിന് ശേഷം, അതിന്റെ ഉയര ഈ ജോലിയില്\u200d ഞങ്ങള്\u200d പരിശീലിക്കപ്പെട്ട മോഡലുകള്\u200d ഉപയോഗിക്കുന്നത് പരിശോധിക്കുന്നു. പോര്\u200dട്ടുഗീഷ്- ഇംഗ്ലീഷ്- ഇംഗ്ലീഷ്- പോര ഞങ്ങള്\u200d പോര്\u200dട്ടൂഗീഷിലെയും ഇംഗ്ലീഷിലെയും ഉപയോഗിക്കുന്നത് പരിശോധിക്കുന്നത് മുന്\u200dപ് പരിശീലിക്കപ്പെട്ട ഭാഷ മോഡലുകളിലാണ്. പോര്\u200dട്ടുഗീഷ്  ഞങ്ങള്\u200d ഞങ്ങളുടെ മോഡലുകളെ ഗൂഗിള്\u200d ട്രാന്\u200dസ്ട്രാന്\u200dസ് എപിഐ, മറിയാന്\u200dഎംടിയുടെയും, പാരാക്രൌള്\u200d ഡാറ്റാസെറ്റിന്\u200dറെ ഒരു സബ്ബട്ടില്\u200d താല്\u200dക്കാലി WMT20 ബിയോമിക്കല്\u200d പരിഭാഷണത്തിന് ഞങ്ങളുടെ കീഴടങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. Our results show that our models have a competitive performance to state-of-the-art models while being trained on modest hardware (a single 8GB gaming GPU for nine days).  ഞങ്ങളുടെ വിവരങ്ങള്\u200d, മോഡലുകളും കോഡുകളും നമ്മുടെ ഗിറ്റ്ഹുബ് റിപോസിറ്ററിയില്\u200d ലഭ്യമാണ്.', 'mn': 'Машин хөгжлийн гүн гүнзгий сургалтын хүлээн зөвхөн өндөр чанартай хөгжлийн загварыг хөгжүүлэх үнэтэй. Энэ ажлын хувьд бид өмнө сургалтын загварын хэрэглээ судалж, яг л Португали-Англи, Англи-Португали-Португали хөрөнгө оруулалтын ажлын тулд T5-г ашигладаг. Бид португал болон Англи хэлний сургалтын өмнө сургалтын загварын хэрэглээ судалж, Португалийн загваруудыг илэрхийлэхийн тулд англи тэмдэглэгчийн адилтгал зааж өгдөг. Бид өөрсдийн загварыг Google Translate API болон MarianMT-тай ParaCrawl өгөгдлийн сангийн нэг хэсэгт харьцуулж, мөн WMT19 Biomedical Translation Shared Task-д ялагдана. Мөн бид WMT20 биологийн эрүүл мэндийн хөгжлийн хуваалцааны ажлыг тайлбарладаг. Манай үр дүнд бидний загваруудын урлагийн загваруудын өрсөлдөг үйл ажиллагааг харуулж байна. Харин бага зэрэг төхөөрөмжийн технологи дээр суралцаж байхад (9 өдрийн турш 8ГБ тоглоомын GPU ганц нэг). Бидний өгөгдлийн, загвар, код бидний GitHub repository дээр гарч байна.', 'mt': 'Minkejja l-adozzjoni mifruxa ta’ tagħlim profond għat-traduzzjoni bil-magni, għadu għali li jiġu żviluppati mudelli ta’ traduzzjoni ta’ kwalità għolja. In this work, we investigate the use of pre-trained models, such as T5 for Portuguese-English and English-Portuguese translation tasks using low-cost hardware.  Aħna nesploraw l-użu ta’ mudelli tal-lingwa Portugiża u Ingliża mħarrġa minn qabel u nipproponu adattament tat-tokenizer Ingliż biex jirrappreżenta karattri Portugiżi, bħad-dijaereżi, l-aċċenti akuti u gravi. Aħna nqabblu l-mudelli tagħna mal-API Google Translate u MarianMT fuq sottosett tas-sett tad-dejta ParaCrawl, kif ukoll mas-sottomissjoni rebbieħa għall-Kompitu Konġunt tat-Traduzzjoni Bijomediċina WMT19. Aħna niddeskrivu wkoll is-sottomissjoni tagħna għall-Kompitu Konġunt tat-Traduzzjoni Bijomediċina WMT20. Ir-riżultati tagħna juru li l-mudelli tagħna għandhom prestazzjoni kompetittiva għall-mudelli l-aktar avvanzati waqt li qed jiġu mħarrġa fuq hardware modest (GPU wieħed tal-logħob tal-logħob 8GB għal disa’ ijiem). Id-dejta, il-mudelli u l-kodiċi tagħna huma disponibbli fir-repożitorju tagħna GitHub.', 'ro': 'În ciuda adoptării pe scară largă a învățării profunde pentru traducerea automată, este încă costisitor să se dezvolte modele de traducere de înaltă calitate. În această lucrare, investigăm utilizarea modelelor pre-instruite, cum ar fi T5 pentru sarcini de traducere portugheză-engleză și engleză-portugheză, folosind hardware low-cost. Explorăm utilizarea modelelor de limbă portugheză și engleză pre-instruite și propunem o adaptare a tokenizerului englez pentru a reprezenta caractere portugheze, cum ar fi diaereza, accentele acute și grave. Comparăm modelele noastre cu Google Translate API și MarianMT pe un subset al setului de date ParaCrawl, precum și cu trimiterea câștigătoare la WMT19 Biomedical Translation Shared Task. De asemenea, descriem trimiterea noastră la misiunea partajată de traducere biomedicală WMT20. Rezultatele noastre arată că modelele noastre au o performanță competitivă față de modelele de ultimă generație, în timp ce sunt instruite pe hardware modest (o singură GPU de gaming de 8 GB timp de nouă zile). Datele, modelele și codul nostru sunt disponibile în depozitul nostru GitHub.', 'pl': 'Pomimo powszechnego przyjęcia głębokiego uczenia się do tłumaczenia maszynowego, opracowanie wysokiej jakości modeli tłumaczeń jest nadal kosztowne. W niniejszej pracy badamy wykorzystanie wstępnie przeszkolonych modeli, takich jak T5 do zadań tłumaczeniowych portugalsko-angielsko i angielsko-portugalsko z wykorzystaniem taniego sprzętu. Badamy wykorzystanie portugalskich i angielskich wstępnie przeszkolonych modeli językowych i proponujemy adaptację angielskiego tokenizera do reprezentowania portugalskich znaków, takich jak diaerzeza, ostre i poważne akcenty. Nasze modele porównujemy z API Google Translate i MarianMT na podzbiorze danych ParaCrawl, a także z zwycięską zgłoszeniem do WMT19 Biomedical Translation Shared Task. Opisujemy również nasze zgłoszenie do WMT20 Biomedical Translation Shared Task. Nasze wyniki pokazują, że nasze modele mają konkurencyjną wydajność w stosunku do najnowocześniejszych modeli, jednocześnie są trenowane na skromnym sprzęcie (pojedynczy 8GB GPU do gier przez dziewięć dni). Nasze dane, modele i kod są dostępne w naszym repozytorium GitHub.', 'no': 'Til tross utvida av dyppa læring for maskinsomsetjing, er det fortsatt dyppa å utvikla høg kvalitetsverdimodeller. I denne arbeida undersøker vi bruken av føretrainerte modeller, som T5 for portugisisk-engelsk og engelsk-portugisisk omsetjingsprogrammer med låg kostnadsmaskinvare. Vi undersøker bruken av portugisisk og engelsk føretrainerte språk- modeller og foreslår ein tilpassing av engelsk tokenisering for å representera portugisisk teikn, som diaeresis, akutt og grav aksent. Vi samanliknar våre modeller med Google Translate API og MarianMT på ein undergruppe av ParaCrawl- datasettet, og med den vanlege tilføring til WMT19- delt oppgåve for biomediske omsetjingar. Vi beskriver også tillegget vårt til WMT20, delt oppgåve for biomedisinsk omsetjing. Resultatet våre viser at modelane våre har ein konkurentivt utvikling til kunstmodeller mens det vert trent på modeste maskinvare (ein enkel 8GB GPU for ni dagar). Data, modeller og kode våre er tilgjengeleg i GitHub-laget vårt.', 'sr': 'Uprkos širom usvajanju dubokog učenja za prevod mašine, još je skupo razviti modele prevoda kvalitete. U ovom poslu istražujemo korištenje predobučenih modela, kao što je T5 za portugalski engleski i engleski portugalski prevodni zadatak koristeći nisku koštanu hardver. Istražujemo korištenje portugalskih i engleskih predobučenih jezičkih modela i predlažemo adaptaciju engleskog tokenizera da predstavljamo portugalske likove, poput dijareze, akutnih i groznih akcenta. Uspoređujemo naše modele sa Google Translate API i MarianMT na podskupini ParaCrawl podataka, kao i sa pobjedničkim predstavljanjem WMT19 zajedničkog zadatka za biomedicinsku prevodu. Takoðe opisujemo svoju predanost WMT20 zajedničkom zadatku za biomedicinsku prevodu. Naši rezultati pokazuju da naši modeli imaju konkurentnu izvedbu za modele state-of-the-art dok se treniraju na skromnom hardveru (jedan 8GB GPU igre devet dana). Naši podaci, modeli i kodovi su dostupni u našem depozitu GitHub.', 'si': 'මැෂින් වාර්ථාව සඳහා ගොඩක් ඉගෙන ගන්න පුළුවන් විශාල විදියට නමුත්, ඒක තවමත් ගොඩක් විශේෂ විදිය මේ වැඩේ අපි පරීක්ෂා කරනවා පුර්තුජි ඉංග්\u200dරීසිය සහ ඉංග්\u200dරීසිය-පුර්තුතියි පරික්ෂා කරපු වැඩේ ප්\u200dරයෝජනය කරන් අපි පෝටුගිලි සහ ඉංග්\u200dරීසි වලින් ප්\u200dරධානය කරපු භාෂාව ප්\u200dරයෝජනය කරනවා ඒ වගේම ඉංග්\u200dරීසි ටොකෙනිසර් වලින් ප්\u200dරයෝජනය ක අපි අපේ මොඩේල්ස් එක්ක ගුගුල් භාවිත API සහ MarianMT එක්ක පැරක්රල් දත්ත සෙට් එක්ක සම්බන්ධ වෙනුවෙන්, සහ WMT19 ජීවිත්\u200dයාත්මක වාර්තාව සමාග අපි තියෙන්නේ WMT20 ජීවිත වෛද්\u200dය විවාහය සමාගත වැඩකට අපේ පිළිගන්න. අපේ ප්\u200dරතිචාරය පෙන්වන්නේ අපේ මොඩල් එක්ක තරගයක් තියෙනවා කියලා, ස්ථානයේ ක්\u200dරියාත්මක මොඩල් එක්ක සාමාන්ත්\u200dරීය විදියට (ද අපේ දත්ත, මොඩේල් හා කෝඩ් එක අපේ GitHub ස්ථානයේ තියෙනවා.', 'so': 'Inta kastoo aad u ballaadhan korsashada waxbarashada aad u dheer ee turjumista machineedka, waxaa weli qaali ah in loo horumariyo modelalka turjumista sare. Markaas waxan waxaynu baaritaan isticmaalka tusaale ahaan Tusaale-tababar horay loo tababaray, tusaale ahaan T5 oo lagu isticmaalo qalabka turjumaadda Burtuqiis-Ingiriis iyo Ingiriis-Burtuqiis. Waxaynu baaraynaa isticmaalka qaababka afka Burtuqiis iyo ingiriisiga horay loo tababaray, waxaana soo jeedinaynaa in loo beddelo alaabta afka Ingiriiska si uu u represento qoraalka Burtuqiis, tusaale ahaan diaeresis, degdeg ah oo aad u dhaqsahay. Tusaalooyinkayada waxaannu isbarbardhignaa tarjumaadka API iyo MarianMT oo ka mid ah koob ka tirsan macluumaadka ParaCrawl, sidoo kale sameynta guulaysashada shaqada sharciga tarjumaadka Biomedicka ee WMT19. Waxaynu sidoo kale u qoraynaa warqadeena loo soo dirayo Shaqada loo sharciyey WMT20 Biomedical. Abaalkayaga waxay muuqataa in modelalkayagu ay leeyihiin tababar adag oo u tababareeya tusaalaha farshaxanka marka lagu tababariyo qalabka gaaban (hal 8GB ciyaar oo GPU ku ciyaaro sagaal maalmood). Macluumaadyadeena, modeliyada iyo codyadeena waxay ku jiraan bakaaradda GitHub.', 'ur': 'ماشین ترجمہ کے لئے عمیق تعلیم کی پھیلا ہوئی تعلیم کے بغیر بھی، یہ تو بالکل کیفیت ترجمہ موڈل کی تولید کرنے کے لئے بہت گران ہے. اس کام میں ہم پہلے تدریس کیے ہوئے موڈل کے استعمال کی تحقیق کرتے ہیں، جیسے ٹی پنج پورٹوگل-انگلیسی اور انگلیسی-پورٹوگل کی ترجمہ کے کاموں کے لئے کم قیمت هارڈر کے مطابق۔ ہم پورٹوګیز اور انگلیسی کی پیش آموزش کی زبان مدلکوں کا استعمال کررہے ہیں اور انگلیسی ٹوکینیزر کی تعمیر کرنے کی پیشنهاد کررہے ہیں پورٹوګیز شخصیتوں کو دکھانے کے لئے، جیسے ڈائیئریس، مضبوط اور گریب اگنٹ ہم نے اپنے مدلکوں کو Google Translate API اور MarianMT کے مطابق پاراکرول ڈیٹ سٹ کے ساتھ مقایسہ کیا ہے اور WMT19 Biomedical Translation Shared Task کے مطابق جو غالب آئے۔ ہم نے WMT20 Biomedical Translation Shared Task کے لئے ہماری اطلاعات کو بھی توصیح دی۔ ہمارے نتیجے دکھاتے ہیں کہ ہمارے مدلکوں کو نہن دن کے لئے استعمال کرنے کے لئے ایک مسابقه کامپیوتر ہے۔ ہمارے ڈاکٹے، موڈل اور کوڈ ہمارے GitHub رپوسٹری میں موجود ہیں.', 'sv': 'Trots det utbredda införandet av djupinlärning för maskinöversättning är det fortfarande dyrt att utveckla högkvalitativa översättningsmodeller. I detta arbete undersöker vi användningen av färdigutbildade modeller, till exempel T5 för portugisisk-engelska och engelsk-portugisiska översättningsuppgifter med billig hårdvara. Vi undersöker användningen av portugisiska och engelska förklädda språkmodeller och föreslår en anpassning av engelska tokenizer för att representera portugisiska tecken, såsom diaeresis, akuta och allvarliga accenter. Vi jämför våra modeller med Google Translate API och MarianMT på en delmängd av ParaCrawl datauppsättningen, samt med den vinnande inlämningen till WMT19 Biomedical Translation Shared Task. Vi beskriver också vårt bidrag till WMT20 Biomedical Translation Shared Task. Våra resultat visar att våra modeller har en konkurrenskraftig prestanda jämfört med toppmoderna modeller samtidigt som de utbildas på blygsam hårdvara (en enda 8GB gaming GPU i nio dagar). Våra data, modeller och kod finns tillgängliga i vårt GitHub arkiv.', 'ta': 'இயந்திரம் மொழிபெயர்ப்பிற்கான ஆழமான கற்றுப்பொறியை அகலமாக எடுத்துக் கொள்ளும் போதிலும், அது உயர்தரமான மொழிபெயர்ப இந்த வேலையில், நாம் முன் பயிற்சிக்கப்பட்ட மாதிரிகளின் பயன்பாட்டை ஆய்வு செய்கிறோம், போர்த்துகிசி- ஆங்கிலத்திற்கு T5 மற்று நாங்கள் போர்த்துகீசிஷ் மற்றும் ஆங்கிலத்தின் முன் பயிற்சி மொழி மாதிரிகளை பயன்படுத்தி போர்த்துகீசிஷ் எழுத்துகளை பார்த்துகீச்சில் க நாங்கள் எங்கள் மாதிரிகளை கூகுல் மொழிபெயர்ப்பு API மற்றும் MarianMT பாராக்குருகல் தகவல் அமைப்பின் துணையில் ஒப்பிடுகிறோம், மற்றும் வெற்றி WMT19 பை WMT20 பையோமிடியூடிய மொழிபெயர்ப்பு பகிர்ந்த பணிக்கு எங்கள் சரணங்களை விவரிக்கிறோம். முடிவு எங்கள் தகவல், மாதிரி மற்றும் குறியீடு எங்கள் GitHub கிடங்கில் கிடைக்கும்.', 'uz': "Masofin tarjima qilish uchun eng yuqori o'rganishni qo'shish uchun juda qiymati. Bu ishda, biz birinchi taʼminlovchi modellardan foydalanishni o'rganamiz, bir nechta qiymati hardware yordamida Portugalcha- Ingliz- Portugalcha tarjima vazifalari uchun T5 ishlatishni tahrirlamiz. Biz birinchi o'rganishdan oldin tillar modellarini foydalanamiz va birinchi tillar modelini o'rganamiz va Portugalcha shakllarini tashkilotga ega qilishni anglatamiz, huddi diaeresis, yaqin va katta aksiyatlar kabi. Biz modellarimizni ParaCrawl maʼlumotlar tarjimasiga va WMT19 Biomedical tarjima vazifasiga qaytarilgan vazifani bajarish uchun Google Translate API va MarianMT bilan kamaytamiz. Biz WMT20 Biomedical tarjima vazifa bilan birlashtirilgan vazifani qaramamiz. Natijalamizning natijalarimiz esa modellarimizning holatning holati modellarida rivojlanish natijasi bor va moddalar sohasida o'rganadi (9 kun uchun bir 8GB oʻyinib GPU oʻyiniladi). Bizning maʼlumotlarimiz, modellar va kodlar GitHub repositorimizda mavjud.", 'vi': 'Mặc dù đã trải qua nhiều phương pháp học sâu để dịch thuật cỗ máy, nhưng vẫn tốn kém để phát triển các mô hình dịch chất lượng cao. Trong công việc này, chúng tôi điều tra việc sử dụng các mô hình đã được đào tạo, như T5 cho việc dịch chuyển Bồ Đào Nha-Anh-Bồ Đào Nha và Tiếng Anh-Bồ Đào Nha bằng vũ khí rẻ tiền. Chúng tôi khám phá việc sử dụng các mô hình tiếng Bồ Đào Nha và Anh được đào tạo từ trước và đề xuất một sự thích hợp của vật trưng bày của người Bồ Đào Nha, như Diaereis, giọng trầm tính và châm biếm. Chúng tôi so sánh các mẫu của chúng tôi với Google Dịch API và Mariano MT trên một phần mẫu dữ liệu của Paracrap, cũng như giao nộp thắng cuộc cho Công việc chia sẻ WM T119 Dịch Sinh Tiến. Chúng tôi cũng mô tả sự tham gia của chúng tôi vào Nhiệm vụ Dịch phụ Khoa học WM. Những kết quả của chúng tôi cho thấy các mô hình của chúng tôi có khả năng cạnh tranh với các mô hình hiện đại nhất trong khi được huấn luyện về phần cứng khiêm tốn (một loại 8GB cho chín ngày). Dữ liệu, mẫu và mã của chúng ta có trong kho lưu trữ Gita.', 'bg': 'Въпреки широко разпространеното приемане на дълбоко обучение за машинен превод, разработването на висококачествени модели за превод все още е скъпо. В тази работа изследваме използването на предварително обучени модели като Т5 за преводни задачи от португалско-английски и английски-португалски език, използвайки евтин хардуер. Изследваме използването на португалски и английски предварително обучени езикови модели и предлагаме адаптация на английския токенизатор, за да представяме португалски знаци като диаереза, остри и тежки акценти. Сравняваме моделите си с интерфейса за превод на Гугъл и Мариан МТ в поднабор от данни както и с печелившите предложения за споделената задача за биомедицински превод. Също така описваме нашето представяне на споделената задача за биомедицински превод. Нашите резултати показват, че нашите модели имат конкурентна производителност спрямо най-съвременните модели, докато са обучени на скромен хардуер (един 8 ГБ игрален GPU за девет дни). Нашите данни, модели и код са достъпни в хранилището ни.', 'da': 'På trods af den udbredte anvendelse af dyb læring til maskinoversættelse er det stadig dyrt at udvikle oversættelsesmodeller af høj kvalitet. I dette arbejde undersøger vi brugen af forududdannede modeller, såsom T5 til portugisisk-engelsk og engelsk-portugisisk oversættelsesopgaver ved hjælp af billig hardware. Vi undersøger brugen af portugisiske og engelske præuddannede sprogmodeller og foreslår en tilpasning af den engelske tokenizer til at repræsentere portugisiske tegn, såsom diaerese, akutte og alvorlige accenter. Vi sammenligner vores modeller med Google Translate API og MarianMT på en delmængde af ParaCrawl datasættet, samt med den vindende indsendelse til WMT19 Biomedical Translation Shared Task. Vi beskriver også vores indsendelse til WMT20 Biomedical Translation Shared Task. Vores resultater viser, at vores modeller har en konkurrencedygtig ydeevne i forhold til state-of-the-art modeller, mens de er trænet på beskeden hardware (en enkelt 8GB gaming GPU i ni dage). Vores data, modeller og kode er tilgængelige i vores GitHub lager.', 'hr': 'Uprkos širom usvajanju dubokog učenja za prevod strojeva, još uvijek je skupo razviti modele prevoda visokokvalitete. U ovom poslu istražujemo korištenje predobučenih modela, kao što je T5 za portugalski-engleski i engleski-portugalski prevodni zadatak koristeći nisku koštanu hardver. Istražujemo korištenje portugalskih i engleskih predobučenih jezičkih modela i predlažemo prilagodbu engleskog tokenizera za predstavljanje portugalskih znakova, poput diaeresis, akutnih i groznih akcenta. Uspoređujemo naše modele sa Google Translate API i MarianMT na podskupini ParaCrawl podataka, kao i pobjedničkom predstavljanju zajedničkom zadatku za biomedicinsku prevodu WMT19. Također opisujemo svoju predanost WMT20 zajedničkom zadatku za biomedicinsku prevodu. Naši rezultati pokazuju da naši modeli imaju konkurentnu funkciju za modele state-of-the-art dok se obučavaju na skromnom hardveru (jedan 8GB GPU igre devet dana). Naši podaci, modeli i kodovi su dostupni u našem skladištu GitHub.', 'nl': 'Ondanks de wijdverbreide toepassing van deep learning voor machinevertaling is het nog steeds duur om hoogwaardige vertaalmodellen te ontwikkelen. In dit werk onderzoeken we het gebruik van voorgetrainde modellen, zoals T5 voor Portugees-Engels en Engels-Portugees vertaaltaken met behulp van goedkope hardware. We onderzoeken het gebruik van Portugese en Engelse voorgetrainde taalmodellen en stellen een aanpassing van de Engelse tokenizer voor om Portugese karakters weer te geven, zoals diaerese, acute en ernstige accenten. We vergelijken onze modellen met de Google Translate API en MarianMT op een subset van de ParaCrawl dataset, evenals met de winnende inzending aan de WMT19 Biomedical Translation Shared Task. We beschrijven ook onze inzending aan de WMT20 Biomedical Translation Shared Task. Onze resultaten tonen aan dat onze modellen concurrerend presteren ten opzichte van state-of-the-art modellen terwijl ze getraind worden op bescheiden hardware (een enkele 8GB gaming GPU gedurende negen dagen). Onze data, modellen en code zijn beschikbaar in onze GitHub repository.', 'de': 'Trotz der weit verbreiteten Einführung von Deep Learning für maschinelle Übersetzungen ist es immer noch teuer, qualitativ hochwertige Übersetzungsmodelle zu entwickeln. In dieser Arbeit untersuchen wir den Einsatz von vortrainierten Modellen wie T5 für Übersetzungsaufgaben Portugiesisch-Englisch und Englisch-Portugiesisch mit kostengünstiger Hardware. Wir untersuchen die Verwendung von portugiesischen und englischen vortrainierten Sprachmodellen und schlagen eine Anpassung des englischen Tokenizers vor, um portugiesische Zeichen wie Diaerese, akute und gravierende Akzente darzustellen. Wir vergleichen unsere Modelle mit der Google Translate API und MarianMT auf einer Teilmenge des ParaCrawl-Datensatzes sowie mit der erfolgreichen Einreichung für die WMT19 Biomedical Translation Shared Task. Wir beschreiben auch unsere Einreichung zur WMT20 Biomedical Translation Shared Task. Unsere Ergebnisse zeigen, dass unsere Modelle eine wettbewerbsfähige Leistung gegenüber modernen Modellen haben und gleichzeitig auf bescheidener Hardware trainiert werden (eine einzelne 8GB Gaming-GPU für neun Tage). Unsere Daten, Modelle und Code sind in unserem GitHub Repository verfügbar.', 'id': 'Meskipun adopsi yang luas dari belajar dalam untuk terjemahan mesin, masih mahal untuk mengembangkan model terjemahan kualitas tinggi. Dalam pekerjaan ini, kami menyelidiki penggunaan model prapelatih, seperti T5 untuk tugas terjemahan Portugis-Inggris dan Inggris-Portugis menggunakan perangkat keras yang mahal. Kami mengeksplorasi penggunaan model bahasa Portugis dan bahasa Inggris yang terlatih dan mengusulkan adaptasi tokenizer Inggris untuk mewakili karakter Portugis, seperti diaeresis, aksen akut dan kubur. Kami membandingkan model kami dengan Google Translate API dan MarianMT pada subset set data ParaCrawl, serta dengan pengiriman yang menang ke WMT19 Biomedical Translation Shared Task. Kami juga menjelaskan pengiriman kami ke WMT20 Biomedical Translation Shared Task. Hasil kami menunjukkan bahwa model kami memiliki prestasi kompetitif untuk model terbaik sementara dilatih di hardware sederhana (GPU permainan 8GB tunggal selama sembilan hari). Data, model dan kode kita tersedia di repositori GitHub kita.', 'ko': '비록 기계 번역은 광범위하게 심도 있는 학습을 채택하지만, 고품질의 번역 모델을 개발하는 것은 여전히 매우 비싸다.이 작업에서 우리는 저비용 하드웨어를 사용하여 포르투갈어-영어와 영어-포르투갈어 번역 임무를 수행하는 T5와 같은 미리 훈련된 모델을 어떻게 사용하는지 연구했다.우리는 포르투갈어와 영어가 미리 훈련한 언어 모델의 사용을 탐색하고 포르투갈어 문자, 예를 들어 분음부, 날카롭고 엄숙한 발음을 나타내는 영어 표기부의 개편을 제시했다.Google 모델은 ParaCrawl 데이터 세트의 하위 세트에 있는 Google Translate API와 MarianMT를 비교하고 WMT19 생물의학 번역 공유 임무의 수상 제출과 비교합니다.WMT20 생물의학 번역 공유 임무에 제출된 상황도 설명했습니다.우리의 연구 결과에 따르면 우리의 모델은 일반 하드웨어(8GB 게임 GPU 9일)를 사용하여 교육을 진행하는 동시에 가장 선진적인 모델에 비해 경쟁력 있는 성능을 가진다.GitHub 저장소에서 데이터, 모델 및 코드를 찾을 수 있습니다.', 'sw': 'Pamoja na kutangazwa kwa upana wa kujifunza kwa ajili ya kutafsiri mashine, bado ni ghali kwa kuendeleza mifano ya tafsiri yenye sifa kubwa. Katika kazi hii, tunachunguza matumizi ya mifano iliyoendeshwa kabla, kama vile T5 kwa ajili ya kazi za tafsiri za Kiingereza na Kiingereza na Kireno kwa kutumia vifaa vya gharama vya chini. Tunapunguza matumizi ya mifano ya lugha za Kireno na Kiingereza zilizofunzwa kabla na tunapendekeza kubadilishwa kwa mtaalamu wa Kiingereza kuwawakilisha wahusika wa Kireno, kama vile ugonjwa wa hali ya hewa, na upatikanaji wa haraka. Tunawalinganisha mifano yetu na Tafsiri ya API na MarianMT kwenye mfululizo wa taarifa za ParaCrawl, pamoja na ushindi wa ushindi wa Tafsiri ya Biomedica ya WMT19. Pia tunaelezea ujumbe wetu wa Tafsiri ya Biomedica ya WMT20. Our results show that our models have a competitive performance to state-of-the-art models while being trained on modest hardware (a single 8GB gaming GPU for nine days).  Takwimu zetu, mifano na kodi zinapatikana katika makazi yetu ya GitHub.', 'fa': 'با وجود adoption of widespread learning deep for machine translation, it is still expensive to develop high quality translation models. در این کار، ما استفاده از مدلهای پیش آموزش شده را تحقیق می کنیم، مثل T5 برای کار ترجمه\u200cهای پورتوژیک-انگلیسی و انگلیسی-پورتوژیک با استفاده از hardware هزینه کم. ما استفاده از مدل های پیش آموزش زبان پورتوژیک و انگلیسی را تحقیق می کنیم و پیشنهاد می کنیم تغییر دادن یک توکنیزگر انگلیسی برای نمایش شخصیت پورتوژیک\u200cها، مثل دیاریس، دقیق و مهربان. ما مدل\u200cهایمان را با Google Translate API و MarianMT در یک زیر مجموعه داده\u200cهای پاراکرول مقایسه می\u200cکنیم، همچنین با پیروزی برنده به مسئله\u200cی ترجمه\u200cهای زیست\u200cپزشکی WMT19 مشترک شده است. ما همچنین تسلیم کردن ما به ترجمه بیوژیک بیوژیک WMT20 را توصیف می کنیم. نتیجه\u200cهای ما نشان می\u200cدهند که مدل\u200cهای ما اجرای مسابقه\u200cای برای مدل\u200cهای هنر در حال آموزش روی ساختمان\u200cهای ناتوانی (یک GPU تنها 8GB برای 9 روز) دارند. اطلاعات، مدل و کد ما در محفوظه GitHub موجود هستند.', 'af': "Onthou die vaste aanvaar van diep leer vir masjien vertaling, is dit nog koste om hoë-kwaliteit vertaling modele te ontwikkel. In hierdie werk, ondersoek ons die gebruik van voor-opgelei modele, soos T5 vir Portugese-Engels en Engels-Portugese vertaling opdragte gebruik van lae koste hardwerf. Ons ondersoek die gebruik van Portugese en Engelske vooraf-opgelei taal modele en voorstel 'n aanpassing van die Engelse tokeniseer om Portugese karakters te verteenwoordig, soos diaeresis, akute en groot aksente. Ons vergelyk ons modelles met die Google Translate API en MarianMT op 'n subdele van die ParaCrawl datastel, en ook met die winning submission aan die WMT19 Biomedical Vertaling Gedeelde Taak. Ons beskryf ook ons onderskrywing aan die WMT20 Biomediese Vertaling Gedeelde Taak. Ons resultate wys dat ons modele 'n medelyk uitvoering het vir staat-van-kunste modele terwyl onderwerp word op modeste hardwerp ( 'n enkele 8GB speletjie GPU vir nege dae). Ons data, modele en kode is beskikbaar in ons GitHub stoorplek.", 'tr': "Maşynyň terjime edilmegi üçin gaty uly öwrenmek üçin täsirli uýgunlaşdyrylmagyň ýöne-täsirli terjime nusgalaryny bejermek üçin has bagly. Bu işde, biz öňünden öňünden eğitilen nusgalaryň, Portugalça-iňlisçe we Ingilisçe-Portugalça terjime eden täzelikleri üçin ulanmagyny barlaýarys. Biz portugalça we iňlisçe öňünden bilim taýýarlanan dil nusgalaryny keşfedip, portugalça karakterleriň, diýeresi, akut we möhüm akcentleriň üýtgetmegini teklip edýäris. Biziň modellerimizi Google Translate API we MarianMT'a ParaCrawl veri setiriniň subgrupunda we WMT19 Biomedical terjime paýlaşan zada we ýeňiji teslim edenlerimize karşılaştyrýarys. Biz hem WMT20 Biomedical terjime edilen zada rugsat berdik. Biziň netijelerimiz nusgalarymyzyň modellerimiziň modellerinde örän möhüm taýýarlanmagy üçin döredijili ukyplarymyz bardygyny görkezýärler (9 gün diýip 8GB GPU oýnap otyrylýan). Biziň bergilerimiz, modellerimiz we kodymyz GitHub depositegimizde bar.", 'sq': 'Megjithë miratimin e përhapur të mësimit të thellë për përkthimin e makinave, është ende e shtrenjtë të zhvillohen modele përkthimi të cilësisë së lartë. Në këtë punë, ne hetojmë përdorimin e modeleve të paratrajnuar, të tillë si T5 për detyrat e përkthimit portugal-anglez dhe anglez-portugal duke përdorur hardware me kosto të ulët. Ne eksplorojmë përdorimin e modeleve të gjuhës portugale dhe angleze të paratrajnuar dhe propozojmë një përshtatje të tokenizerit anglez për të përfaqësuar karakteret portugale, të tilla si diaereza, theks akut dhe të varrit. Ne krahasojmë modelet tona me API Google Translate dhe MarianMT në një nëngrup të dataset ParaCrawl si dhe me dorëzimin fitues në WMT19 Biomedical Translation Shared Task. Ne përshkruajmë gjithashtu dorëzimin tonë në WMT20 Biomedical Translation Shared Task. Rezultatet tona tregojnë se modelet tona kanë një shfaqje konkurruese për modelet më të moderne ndërsa janë trajnuar në hardware modeste (një GPU të vetme 8 GB për nëntë ditë). Të dhënat tona, modelet dhe kodet janë në dispozicion në depozitorin tonë GitHub.', 'am': 'ምንም እንኳን የጥልቅ ትምህርት ለመዘርጋት ስፋት ቢሰፋው የmachine ትርጉም መግለጫ፣ ከፍተኛ-quality ትርጉም ሞዴላዎችን ለማሻሻል ዋጋ ነው፡፡ በዚህ ሥራ፣ ለፖርቱጋልኛ-እንግሊዘኛ እና የፖርቱጋሊስ-ፖርቱጋዊ-የፖርቱጋዊ-የፖርቱጋዊ ትርጓሜ ስራዎችን በመጠቀም በፊት ተማሪ ሞዴላዎችን እናመርመራለን፡፡ የፖርቱጋልኛ እና እንግሊዘኛ በፊት ተማሪዎች የቋንቋ ሞዴላዎችን እና የፖርቱጋሊስ አካላት፣ አቅራቢያ እና ጉዳዮች የፖርቱጋዊ አካላት እንዲያስተካክሉ እንገልጻለን፡፡ እና ምሳሌዎቻችንን ከጎግል ትርጉም API እና ማርያanMT በፓራካል ዳታተር አካባቢ እና ወደ WMT19 Biomedical ትርጉም በተለየ ስራ አሸራፊውን እናሳስል፡፡ We also describe our submission to the WMT20 Biomedical Translation Shared Task.  ፍሬቶቻችንም ሞዴላዎቻችን የ-የ-ዐርድ ዓይነቶች አካባቢ አካባቢ ሀብት ላይ ሲያስተማሩ የዘጠኝ ቀን የGPU ጨዋታ አካባቢ ነው፡፡ ዳራቶቻችንን፥ ሞዴሎችንና ኮዱን በGitHub ሰፊ ውስጥ ይገኛሉ፡፡', 'hy': 'Չնայած մեքենայի թարգմանման համար խորը ուսումնասիրության տարածված ընդունությանը, դեռևս թանկ է զարգացնել բարձր որակի թարգմանման մոդելներ: Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք նախապատրաստված մոդելների օգտագործումը, ինչպիսիք են օրինակ T5-ը պորտուգալերեն-անգլերեն և անգլերեն-պորտուգալերեն թարգմանման գործառույթները, օգտագործելով ցած Մենք ուսումնասիրում ենք պորտուգալերեն և անգլերեն նախապատրաստված լեզվի մոդելների օգտագործումը և առաջարկում ենք անգլերեն մոդելների ադապտացիա, որպեսզի ներկայացնենք պորտուգալերեն հիերոգլիացիներ, ինչպիսիք են դայարեզը, ակ Մենք համեմատում ենք մեր մոդելները Google Translate API-ի և "ՄարիանՄԹ"-ի հետ պարաCrawle տվյալների համակարգի մի ենթախումբի վրա, ինչպես նաև հաղթանակի ներկայացումը World MT19 կենսաբժշկական թարգմանության կիսված խնդրի վրա: Մենք նաև նկարագրում ենք մեր ներկայացումը World MT20 Բիոբիոբժշկական թարգմանման կիսված խնդիրը: Մեր արդյունքները ցույց են տալիս, որ մեր մոդելները մրցակցություն ունեն ամենաբարձր մոդելների համար, մինչ նրանք սովորեցվում են համեստ սարքավորումների վրա (մեկ 8ԳԲ խաղի GPU ինն օրվա ընթացքում): Մեր տվյալները, մոդելները և կոդը հասանելի են մեր ԳիթՀուբ պահեստակում:', 'bn': 'মেশিন অনুবাদের জন্য গভীর শিক্ষা গভীর শিক্ষা প্রশস্ত হওয়া সত্ত্বেও, উচ্চমান অনুবাদ মডেল উন্নয়নের জন্য এটা এখনো বেশী দাম এই কাজে আমরা পূর্ব প্রশিক্ষিত মডেল ব্যবহারের তদন্ত করি, যেমন পর্তুগীজ-ইংরেজী এবং ইংরেজী পর্তুগীজ-অনুবাদের কাজের জন্য টি৫ ব্যবহার করা হয় আমরা পর্তুগীজ এবং ইংরেজি পূর্ব প্রশিক্ষিত ভাষার মডেল ব্যবহার করে অনুসন্ধান করি এবং পোর্টুগীজের চরিত্রের প্রতিনিধিত্ব করার জন্য ইংরেজী টোকানিজ প্যারাক্রাউল ডাটাসেটের সাবটেটে গুগল অনুবাদ এবং মারিয়ানএমটির সাথে আমরা আমাদের মডেলের তুলনা করি এবং উইএমটি১৯ বায়োমিকাল অনুবাদ শেয়ার করার কাজে আমরা উইএমটি২০ বায়োমিক্যাল অনুবাদের প্রতি আমাদের প্রতিষ্ঠান বর্ণনা করেছি। Our results show that our models have a competitive performance to state-of-the-art models while being trained on modest hardware (a single 8GB gaming GPU for nine days).  আমাদের তথ্য, মডেল এবং কোড আমাদের গিটহাব রিপোজিটির মধ্যে পাওয়া যাচ্ছে।', 'bs': 'Uprkos širom usvajanju dubokog učenja za prevod strojeva, još uvijek je skupo razviti modele prevoda visokokvalitete. U ovom poslu istražujemo korištenje predobučenih modela, kao što je T5 za portugalski-engleski i engleski-portugalski prevodni zadatak koristeći nisku koštanu hardver. Istražujemo korištenje portugalskih i engleskih predobučenih jezičkih modela i predlažemo adaptaciju engleskog tokenizača za predstavljanje portugalskih likova, poput dijareze, akutnih i groznih akcenta. Uspoređujemo naše modele sa Google Translate API i MarianMT na podskupini ParaCrawl podataka, kao i sa pobjedničkim predstavljanjem zajedničkog zadatka WMT19 biomedicinskog prevoda. Također opisujemo svoju predanost WMT20 zajedničkom zadatku za biomedicinsku prevodu. Naši rezultati pokazuju da naši modeli imaju konkurentnu izvedbu za modele state-of-the-art dok se obučavaju na skromnom hardveru (jedan 8GB GPU igre devet dana). Naši podaci, modeli i kodovi su dostupni u našem skladištu GitHub.', 'az': "Makina çevirilməsi üçün geniş öyrənmək üçün çox geniş öyrənməyə rağmen, yüksək kaliteli çevirim modellərini təşkil etmək hələ də xərcləndir. Bu işdə, T5 Portugalca-İngilizce və İngilizce-Portugalca təhsil işlərinin istifadəsini təhsil edirik. Biz Portugalca və İngilizce dillərin əvvəlcə təhsil edilmiş dil modellerinin istifadəsini keşfetirik və portugalca karakterlərini, diaeresis, acı və ağır akcentlər kimi təhsil edirik. Biz modellərimizi Google Translate API və MarianMT ilə ParaCrawl veri quruluğunun subgruplarına və WMT19 Biomedical Translation Shared Task'a qələbə müvəffəqiyyətinə salırıq. Biz də WMT20 Biomedical Translation Shared Task'a müvəffəqiyyətimizi təsdiqləyirik. Sonuçlarımız modellərimizin dokuz günlük GPU oyunu təhsil edilən modellərə müəllif göstərilir. Məlumatlarımız, modellərimiz və kodlarımız GitHub depositorimizdə faydalanır.", 'ca': "Malgrat l'adopció generalitzada d'aprenentatge profund per a la traducció automàtica, encara és cara desenvolupar models de traducció d'alta qualitat. En aquest treball, investigam l'ús de models pré-entrenats, com T5 per a tasques de traducció portuguesa-anglès i anglès-portuguès utilitzant hardware de baix cost. Explorem l'ús de models de llenguatge portuguès i anglès pré-entrenats i proposem una adaptació del fitografiador anglès per representar personatges portuguesos, com la diàeresi, els accents aguts i graves. We compare our models to the Google Translate API and MarianMT on a subset of the ParaCrawl dataset, as well as to the winning submission to the WMT19 Biomedical Translation Shared Task.  També descrivim la nostra subministració a la tasca compartida de traducció biomèdica WMT20. Els nostres resultats demostren que els nostres models tenen un rendiment competitiu als models més avançats mentre estan entrenats en hardware modest (un GPU de joc de 8GB durant nou dies). Les nostres dades, models i codis estan disponibles al nostre repositori GitHub.", 'cs': 'Navzdory rozšířenému přijetí hlubokého učení pro strojový překlad je stále nákladné vyvíjet vysoce kvalitní překladové modely. V této práci zkoumáme využití předškolených modelů, jako je T5 pro portugalsko-anglické a anglicko-portugalské překladatelské úlohy s využitím levného hardwaru. Zkoumáme využití portugalských a anglických předškolených jazykových modelů a navrhujeme adaptaci anglického tokenizeru pro reprezentaci portugalských znaků, jako je diaeréza, akutní a vážné akcenty. Naše modely porovnáváme s Google Translate API a MarianMT na podmnožině dat ParaCrawl, stejně jako s vítězným podáním do WMT19 Biomedical Translation Shared Task. Dále popisujeme náš příspěvek k WMT20 Biomedical Translation Shared Task. Naše výsledky ukazují, že naše modely mají konkurenceschopný výkon oproti moderním modelům a zároveň jsou trénovány na skromném hardwaru (jeden 8GB herní GPU po dobu devěti dní). Naše data, modely a kód jsou k dispozici v našem repozitáři GitHub.', 'et': 'Vaatamata masintõlke sügavõppe laialdasele kasutuselevõtule on kvaliteetsete tõlkemudelite väljatöötamine endiselt kallis. Käesolevas töös uurime eelkoolitud mudelite, näiteks T5 kasutamist portugali-inglise ja inglise-portugali tõlketöödeks odava riistvara abil. Uurime portugali ja inglise keele eelõpetatud keelemudelite kasutamist ning pakume välja inglise keele tokeniseri kohandamise, et esindada portugali tähemärke, näiteks diaereesi, akuutseid ja raskeid aktsente. Võrdleme oma mudeleid ParaCrawli andmekogumi alamhulgas Google Translate API ja MarianMT-ga ning WMT19 biomeditsiinilise tõlke jagatud ülesande võiduga. Samuti kirjeldame oma esitamist WMT20 biomeditsiinilise tõlke jagatud ülesandele. Meie tulemused näitavad, et meie mudelid on konkurentsivõimelised tipptasemel mudelitega, samas kui neid treenitakse tagasihoidlikul riistvaral (üks 8GB mängugraafik üheksa päeva jooksul). Meie andmed, mudelid ja kood on kättesaadavad meie GitHub hoidlas.', 'fi': 'Huolimatta syväoppimisen laajasta käyttöönotosta konekääntämiseen on edelleen kallista kehittää korkealaatuisia käännösmalleja. Tässä työssä tutkitaan esikoulutettujen mallien, kuten T5:n käyttöä portugali-englanti- ja englanti-portugali-käännöstehtäviin edullisilla laitteistoilla. Tutkimme portugalin ja englannin esikoulutettujen kielimallien käyttöä ja ehdotamme englannin tokenizerin mukauttamista portugalilaisten merkkien, kuten diaereesin, akuutin ja vakavan aksentin esittämiseen. Vertaamme malliamme Google Translate API:hen ja MarianMT:hen ParaCrawl-aineiston osajoukon osalta sekä voittaneeseen WMT19 Biomedical Translation Shared Task -tehtävään. Kuvaamme myös, miten toimitamme WMT20 Biomedical Translation Shared Task -ohjelman. Tuloksemme osoittavat, että malleillamme on kilpailukykyinen suorituskyky huippuluokan malleihin verrattuna samalla kun niitä koulutetaan vaatimattomalla laitteistolla (yksi 8 Gt:n pelinäytönohjain yhdeksän päivän ajan). Tietomme, mallimme ja koodimme ovat saatavilla GitHub-arkistostamme.', 'ha': "Bayyai da faɗaɗawa ya ɗauki inuwa da aka sanar da masu ƙari wa fassarar maɓallin, sai yana kasancewa masu kwaɗayi wa a buɗe misãlai masu fassarar-nau'in-nau'i. Daga wannan aikin, munã ƙidãya amfani da misãlai waɗanda aka yi wa zaman tsari, kamar T5 na yi amfani da aikin fassarar-Ingiriya da Ingiriya-Portugueski na ƙaranci. Tuna ƙidãya amfani da misãlai na harshen Portugueski da Ingiriya ta gabã ɗaya kuma Munã buƙata wata adapta na Ingiriya zuwa a matsayin bango, kamar diare, sabo da sauri. @ info: status Tuna bayyana musuluncinmu zuwa Tafiyar da aka Share shi na WMT20 Biomedical. MatamayinMu na nũna cewa misalinmu yana da wani mai ƙidido zuwa misalin-na-sanar a lokacin da aka sanar da shi a kan jerin-kiyayyu masu tsari (tare da 8GB-gamin GPU a cikin kwanan na guda). FayinMu, misalin da kodi za'a iya cikin bakin GitHub.", 'sk': 'Kljub razširjeni uporabi globokega učenja za strojno prevajanje je razvoj visokokakovostnih prevajalskih modelov še vedno drago. V tem delu smo raziskali uporabo vnaprej usposobljenih modelov, kot je T5 za prevajanje portugalsko-angleščine in angleščino-portugalščine z nizkocenovno strojno opremo. Raziskujemo uporabo portugalskih in angleških vnaprej usposobljenih jezikovnih modelov in predlagamo prilagoditev angleškega žetonizerja za predstavitev portugalskih znakov, kot so diaereza, akutni in hudi poudarki. Naše modele primerjamo z Google Translate API in MarianMT na podnaboru podatkov ParaCrawl, kot tudi z zmagovalno prijavo na WMT19 Biomedicine Translation Shared Task. Opisujemo tudi našo predložitev v skupno nalogo WMT20 Biomedicinskega prevajanja. Naši rezultati kažejo, da imajo naši modeli konkurenčno zmogljivost v primerjavi z najsodobnejšimi modeli, medtem ko so usposobljeni na skromni strojni opremi (en 8 GB igralni GPU za devet dni). Naši podatki, modeli in koda so na voljo v našem repozitoriju GitHub.', 'he': 'למרות האימוץ המפורסם של לימוד עמוק לתרגום מכונות, עדיין יקר לפתח דוגמנים התרגום של איכות גבוהה. בעבודה הזאת, אנו חוקרים את השימוש בדוגמנים מאומנים מראש, כמו T5 עבור משימות התרגום פורטוגזית-אנגלית ואנגלית-פורטוגזית באמצעות חומר בעלות מחיר נמוך. אנו חוקרים את השימוש בדוגמנים של שפה פורטוגזית ואנגלית מאומנות מראש ולהציע שינוי של הטוקניזר האנגלית כדי לייצג דמויות פורטוגזיות, כמו דיירזה, מבטאים חמורים וקברים. אנחנו משוותים את הדוגמנים שלנו עם API Google Translate ומריanMT על תת-קבוצה של קבוצת נתונים ParaCrawl, כמו גם לשלוח הנצחון למשימה WMT19 Biomedical Translation Shared Task. We also describe our submission to the WMT20 Biomedical Translation Shared Task.  התוצאות שלנו מראות שלדוגמנים שלנו יש ביצועים תחרותיים למדוגמנים חדשים בזמן שהם מתאמנים על חומר צנוע (GPU משחק אחד של 8GB במשך תשעה ימים). נתונים, דוגמנים וקוד שלנו זמינים במחסן הגיט-האב שלנו.', 'bo': 'རྒྱ་ཆེ་བ་གཞུང་གི་སྤྱིར་བཏང་བ་ཡིན་ནམ་ཡང་མེད་པར། དེ་འདྲ་ཞིག་ནི་ཇུས་མཐུན་རྐྱེན་ཐབས་ལམ་ལུགས་སུ་མཐུན་དང་མཐུན་ར In this work, we investigate the use of pre-trained models, such as T5 for Portuguese-English and English-Portuguese translation tasks using low-cost hardware. We explore the use of Portuguese and English pre-trained language models and propose an adaptation of the English tokenizer to represent Portuguese characters, such as diaeresis, acute and grave accents. We compare our models to the Google Translate API and MarianMT on a subset of the ParaCrawl dataset, as well as to the winning submission to the WMT19 Biomedical Translation Shared Task. ང་ཚོས་ཀྱང་WMT20 Biomedical Translation Shared Task ལ་ང་ཚོའི་གནད་དོན་འགྲེལ་བཤད་ཀྱི་ཡོད། ང་ཚོའི་གྲུབ་འབྲས་བ་ཅིག་དེ་མིག་སྔར་སྒྲིག་ཆས་གཞུང་བཟོ་བའི་མཛུགས་ཆས་ལ་རྒྱལ་སྐྱོར་མེད་པའི་སྐྱེས་ཆས་ཡོད་པ ང་ཚོའི་གནས་སྡུད་དང་མིག་དཔེ་དབྱིབས་དང་རྣམ་གྲངས་འདི་ང་ཚོའི་GitHub མཛུབ་ཁང་ནང་དུ་སྤྱོད་ཐུབ་པ', 'jv': 'Nanging kabèh akeh sing paling-upat kanggo ingkang deep karo terjamahan, dadi luwih akeh kudu nggawe modele terjamahan sing apik. Nang barêng-barêng iki, kéné ujês nggunakake usaha model sing wis antar-cara, kaya ngono t5 kanggo ingkang portugis-ingkang karo ingkang-portugis kanggo tarjamahan sing bisa basa hardware sing kelas-kota. Awak dhéwé éntukno nggambar model sing ngenggukasi lan ingles kuwi padha nyebutuhan karo tokenizer Inggris kanggo gambar caratar portugis, koyo ngono diareres, aku lan alam sing berarti. Awak dhéwé ngerasai model sing karo Google translation Api karo marianMT nganggo perusahaan dataset ParaCurl, lan nggawe ngupakan tanggal nggawe biyané kebebasané surat kanggo nyengkuyung nggawe WWT 19 Awakdhéwé mungkin ngerasakno kanggo nyenengaké awak dhéwé ning kompik, terjamahan kanggo Kemerdekaan surat biyoten. Rejalekan dhéwé ngomong nik model sing sampeyan akeh pengaturan karo model state-of-the-arts Awakdhéwé, model lan kode kuwi wis ana ing depolasi Gethub.'}
{'en': 'Addressing Exposure Bias With Document Minimum Risk Training : Cambridge at the WMT20 Biomedical Translation Task', 'fr': "Aborder le biais d'exposition avec une formation sur les risques minimaux\xa0: Cambridge à la tâche de traduction biomédicale WMT20", 'es': 'Abordar el sesgo de exposición con la capacitación sobre riesgos mínimos de documentos: Cambridge en la tarea de traducción biomédica WMT', 'ar': 'معالجة تحيز التعرض من خلال تدريب الحد الأدنى من المخاطر للوثائق: كامبريدج في WMT20 مهمة الترجمة الطبية الحيوية', 'pt': 'Lidando com o viés de exposição com treinamento de risco mínimo de documentos: Cambridge na tarefa de tradução biomédica do WMT20', 'zh': '因文档最卑风险培训解露倚:剑桥在WMT20生物医学译', 'ja': '最小限のリスクトレーニングを文書化した露出バイアスへの対処： WMT 20生物医学翻訳タスクのケンブリッジ', 'hi': 'दस्तावेज़ न्यूनतम जोखिम प्रशिक्षण के साथ एक्सपोज़र पूर्वाग्रह को संबोधित करना: WMT20 बायोमेडिकल अनुवाद कार्य में कैम्ब्रिज', 'ru': 'Решение проблемы смещения экспозиции с обучением минимальному риску документа: Кембридж на задаче биомедицинского перевода WMT20', 'ga': 'Ag Tabhairt Aghaidh ar Laofacht Nochta le hOiliúint Riosca Íosta Doiciméid: Cambridge ag Tasc Aistriúcháin Bithleighis WMT20', 'ka': 'Comment', 'el': 'Αντιμετώπιση των προκαταλήψεων έκθεσης με εκπαίδευση ελάχιστου κινδύνου εγγράφων: το Κέιμπριτζ στο έργο βιοϊατρικής μετάφρασης', 'hu': 'Az expozíciós hiányosságok kezelése dokumentum minimális kockázati képzéssel: Cambridge a WMT20 biomedicini fordítási feladaton', 'it': "Affrontare i bias dell'esposizione con la formazione sul rischio minimo dei documenti: Cambridge al WMT20 Biomedical Translation Task", 'lt': 'Atsižvelgiant į nepalankias aplinkybes, susijusias su apšvita, rengiant minimalią riziką dokumentuose: Kambrižas WMT20 Biomedicinos vertimo darbe', 'mk': 'Адресирање на непријатностите во изложбата со минимално обука за ризик во документот: Кембриџ на задачата за биомедицински превод на WMT20', 'kk': 'Құжаттың минимал қауіпсіздік оқытуы: WMT20 биомедикалық аудару тапсырмасында Кембридж', 'ms': 'Alamat Kecelakaan Eksposisi Dengan Latihan Risiko Minimum Dokumen: Cambridge di Tugas Terjemahan Biomedis WMT20', 'ml': 'രേഖയുടെ ഏറ്റവും കുറഞ്ഞ അപകടത്തിലുള്ള രീതിയുടെ പരിശീലിയുമായി എക്സ്പോഷ്ട്രെയിസ് ബിയാസുകള്\u200d വിലാസപ്പെടുത്തുന്', 'mt': 'L-indirizzar tal-ħsara fl-espożizzjoni bit-Taħriġ tar-Riskju Minimu fid-Dokument: Cambridge fil-kompitu tat-traduzzjoni bijomedika WMT20', 'pl': 'Rozwiązywanie problemów narażenia poprzez szkolenie minimalnego ryzyka dokumentu: Cambridge na WMT20 Biomediczne Tłumaczenie Biomediczne', 'no': 'Addressing Exposure Bias With Document Minimum Risk Training: Cambridge at the WMT20 Biomedical Translation Task', 'mn': 'Документын хамгийн багахан эрсдэлийн сургалт: Кембридж WMT20 Biomedical Translation Task', 'ro': 'Abordarea obstacolelor de expunere cu instruirea privind riscul minim al documentelor: Cambridge la sarcina de traducere biomedicală WMT20', 'sr': 'Obraèunanje izloženog biæa sa minimalnim obukom rizika dokumenta: Cambridge na WMT20 biomedicinskom prevodnom zadatku', 'so': 'Addressing Exposure Bias With Document Minimum Risk Training: Cambridge at the WMT20 Biomedical Translation Task', 'si': 'Comment', 'sv': 'Ta itu med exponeringssjukdomar med utbildning för dokumentminimirisker: Cambridge vid WMT20 Biomedical Translation Task', 'ta': 'ஆவணத்தின் குறைந்தபட்ச ஆபத்து பயிற்சியுடன் வெளியீட்டு பையாவுகளை முகவரி', 'ur': 'کمبریج WMT20 Biomedical Translation Task میں', 'uz': 'Name', 'vi': 'Đối phó với vạch trần với tài liệu đào tạo rủi ro tối thiểu: Cambridge tại Nhiệm vụ dịch hạch Khoa học Y học WM20', 'bg': 'Обучение за минимален риск: Кеймбридж в задачата за биомедицински превод', 'da': 'Håndtering af eksponeringsforhold med dokumentminimumsrisikotræning: Cambridge ved WMT20 Biomedicinsk Oversættelsesopgave', 'nl': 'Aanpakken van blootstellingsbias met Document Minimum Risk Training: Cambridge bij de WMT20 Biomedische vertaaltaak', 'hr': 'Obraćanje izloženog bića s minimalnim obukom rizika dokumenta: Cambridge na zadatku za prevod biomedicinskih prijevoza WMT20', 'id': 'Mengatasi Kecelakaan Eksposisi Dengan Pelatihan Risiko Minimum Dokumen: Cambridge di Tugas Terjemahan Biomedis WMT20', 'de': 'Umgang mit Exposition Bias mit Dokument Minimum Risk Training: Cambridge bei der WMT20 Biomedical Translation Task', 'ko': '문서 최소 위험 교육을 통한 노출 문제 해결: 캠브리지 대학 WMT20 생물의학 번역 임무', 'fa': 'درباره\u200cی تحویل بین\u200cهای انفجار با تطالعه minimum Risk Training: Cambridge در WBMT20 توسط ترجمه بیوژیک بیوژیک', 'sw': 'Akizungumzia Bias kwa mafunzo ya Kichini ya Hatari: Kambridge kwenye Task la Tafsiri ya Biomedical WMT20', 'tr': 'WMT20 Biomedical terjime zady', 'sq': 'Duke trajnuar dëmet e ekspozitave me trajnimin e rrezikut minimal të dokumentit: Cambridge në detyrën e përkthimit biomedikal WMT20', 'af': 'Name', 'hy': 'Բիոբրիջյան Բիոբիոբժշկական թարգմանման աշխատանքում', 'am': 'አዲስ ዶሴ ፍጠር', 'bn': 'ডকুমেন্টের সর্বোচ্চ ঝুঁকি প্রশিক্ষণ সহ এক্সপোর্ট বায়াসের ঠিকানা: WMT20 বায়োমিকাল অনুবাদ করার ক্যাম্ব্রিজ', 'az': 'Dəstə Minimum Risk Training: Cambridge at the WMT20 Biomedical Translation Task', 'bs': 'Obraćanje ekspozicije Bias sa minimalnim obukom rizika dokumenta: Cambridge na WMT20 biomedicinskom prevodnom zadatku', 'ca': 'Addressing Exposure Bias With Document Minimum Risk Training: Cambridge at the WMT20 Biomedical Translation Task', 'cs': 'Řešení expozičních předpokladů školením dokumentů s minimálním rizikem: Cambridge na WMT20 Biomedicínské překlady', 'et': 'Kokkupuute kallakute käsitlemine dokumendi minimaalse riski koolitusega: Cambridge WMT20 biomeditsiinilise tõlke ülesandes', 'fi': 'Altistumisvaihtoehtojen käsitteleminen dokumentin minimiriskin koulutuksen avulla: Cambridge WMT20 Biomedical Translation Task', 'sk': 'Obravnavanje nagnjenosti izpostavljenosti z usposabljanjem o minimalnem tveganju za dokumente: Cambridge na nalogi prevajanja biomedicinskega prevajanja WMT20', 'ha': 'Addressing Exposure Bias With Document Minimum Risk Training: Cambridge at the WMT20 Biomedical Translation Task', 'jv': 'Ngubah Resolèh Expose Bias Perkaran Dokumen minimum Rik Learning: Kembridèn ngangge WWC2', 'he': "מתמודד עם סכנה מינימלית של המסמך: קמברידג' במשימת ההתרשמות ביורפואית WMT20", 'bo': 'Addressing Exposure Bias With Document Minimum Risk Training: Cambridge at the WMT20 Biomedical Translation Task'}
{'en': 'The 2020 WMT Biomedical translation task evaluated Medline abstract translations. This is a small-domain translation task, meaning limited relevant training data with very distinct style and vocabulary. Models trained on such data are susceptible to exposure bias effects, particularly when training sentence pairs are imperfect translations of each other. This can result in poor behaviour during inference if the model learns to neglect the source sentence. The UNICAM entry addresses this problem during fine-tuning using a robust variant on Minimum Risk Training. We contrast this approach with data-filtering to remove ‘problem’ training examples. Under MRT fine-tuning we obtain good results for both directions of English-German and English-Spanish biomedical translation. In particular we achieve the best English-to-Spanish translation result and second-best Spanish-to-English result, despite using only single models with no ensembling.', 'ar': 'قامت مهمة الترجمة الطبية الحيوية لعام 2020 WMT بتقييم ترجمات Medline المجردة. هذه مهمة ترجمة ذات نطاق صغير ، مما يعني وجود بيانات تدريب محدودة ذات صلة بأسلوب ومفردات مميزة للغاية. النماذج المدربة على مثل هذه البيانات عرضة لتأثيرات انحياز التعرض ، لا سيما عندما يكون تدريب أزواج الجمل عبارة عن ترجمات غير كاملة لبعضها البعض. يمكن أن يؤدي هذا إلى سوء السلوك أثناء الاستدلال إذا تعلم النموذج إهمال الجملة المصدر. يعالج إدخال UNICAM هذه المشكلة أثناء الضبط الدقيق باستخدام متغير قوي في تدريب الحد الأدنى من المخاطر. نحن نقارن هذا النهج مع تصفية البيانات لإزالة أمثلة التدريب "المشكلة". في ظل الضبط الدقيق لـ MRT ، نحصل على نتائج جيدة لكل من اتجاهي الترجمة الطبية الحيوية الإنجليزية-الألمانية والإنجليزية-الإسبانية. على وجه الخصوص ، نحقق أفضل نتيجة ترجمة من الإنجليزية إلى الإسبانية وثاني أفضل نتيجة من الإسبانية إلى الإنجليزية ، على الرغم من استخدام نماذج فردية فقط بدون تجميع.', 'fr': "La tâche de traduction biomédicale WMT 2020 a évalué les traductions de résumés Medline. Il s'agit d'une tâche de traduction de petit domaine, ce qui signifie que des données de formation pertinentes limitées ont un style et un vocabulaire très distincts Les modèles formés à partir de telles données sont sensibles aux effets de biais d'exposition, en particulier lorsque les paires de phrases d'apprentissage sont des traductions imparfaites les unes des autres. Cela peut entraîner un mauvais comportement lors de l'inférence si le modèle apprend à négliger la phrase source. L'entrée UNICAM résout ce problème lors de la mise au point à l'aide d'une variante robuste de la formation au risque minimal. Nous comparons cette approche au filtrage des données pour supprimer les exemples de formation «\xa0problématiques\xa0». Grâce au réglage fin de la MRT, nous obtenons de bons résultats dans les deux sens de la traduction biomédicale anglais-allemand et anglais-espagnol. En particulier, nous obtenons le meilleur résultat de traduction de l'anglais vers l'espagnol et le deuxième meilleur résultat de l'espagnol vers l'anglais, malgré l'utilisation de modèles uniques sans assemblage.", 'es': 'La tarea de traducción biomédica del WMT 2020 evaluó las traducciones de resúmenes de Medline. Se trata de una tarea de traducción de dominio pequeño, lo que significa datos de entrenamiento relevantes limitados con un estilo y un vocabulario muy distintos. Los modelos entrenados con estos datos son susceptibles a los efectos del sesgo de exposición, particularmente cuando los pares de oraciones de entrenamiento son traducciones imperfectas entre sí. Esto puede resultar en un comportamiento deficiente durante la inferencia si el modelo aprende a descuidar la oración fuente. La entrada de UNICAM aborda este problema durante la puesta a punto utilizando una variante robusta de Entrenamiento de Riesgo Mínimo. Comparamos este enfoque con el filtrado de datos para eliminar ejemplos de capacitación «problemáticos». Con el ajuste fino de MRT obtenemos buenos resultados en ambas direcciones de traducción biomédica inglés-alemán y inglés-español. En particular, logramos el mejor resultado de traducción de inglés a español y el segundo mejor resultado de español a inglés, a pesar de usar solo modelos individuales sin ensamblaje.', 'pt': "A tarefa de tradução do WMT Biomedical de 2020 avaliou as traduções de resumos do Medline. Esta é uma tarefa de tradução de pequeno domínio, o que significa dados de treinamento relevantes limitados com estilo e vocabulário muito distintos. Modelos treinados com esses dados são suscetíveis a efeitos de viés de exposição, principalmente quando os pares de frases de treinamento são traduções imperfeitas um do outro. Isso pode resultar em mau comportamento durante a inferência se o modelo aprender a negligenciar a sentença fonte. A entrada UNICAM aborda esse problema durante o ajuste fino usando uma variante robusta do Treinamento de Risco Mínimo. Comparamos essa abordagem com a filtragem de dados para remover exemplos de treinamento 'problemáticos'. Sob o ajuste fino do MRT, obtemos bons resultados para ambas as direções de tradução biomédica inglês-alemão e inglês-espanhol. Em particular, alcançamos o melhor resultado de tradução de inglês para espanhol e o segundo melhor resultado de espanhol para inglês, apesar de usar apenas modelos únicos sem ensembling.", 'ja': '2020年のWMT生物医学翻訳タスクは、Medlineの抽象翻訳を評価した。これは小ドメイン翻訳タスクであり、非常に特徴的なスタイルと語彙を持つ限定的な関連トレーニングデータを意味します。そのようなデータでトレーニングされたモデルは、特にトレーニング文のペアが互いに不完全な翻訳である場合、露出バイアス効果を受けやすい。これは、モデルがソース文を無視することを学習した場合、推論中の不適切な振る舞いをもたらす可能性があります。UniCamエントリは、最小リスクトレーニングの堅牢なバリアントを使用して微調整中にこの問題に対処します。このアプローチをデータフィルタリングと対比して、「問題」トレーニングの例を削除します。MRT微調整の下で、英語-ドイツ語および英語-スペイン語の生物医学翻訳の両方で良好な結果を得ています。特に、アンサンブルなしの単一モデルのみを使用しているにもかかわらず、最高の英語からスペイン語への翻訳結果と、2番目に優れたスペイン語から英語への翻訳結果を達成しています。', 'zh': '2020年WMT生物医学译Medline摘要译。 此一小域译之任,此特特之风,与词汇之有限培训数也。 据此数者,易见偏效,特当训句对是彼此不完译时。 若夫模学会略源句,庶几推理之不善也。 UNICAM 条目在微调之间,用"最卑风险培训"者,变体解之。 比之漉数,以删"问"训示例。 MRT微调,英语 - 德语英语 - 西班牙语生物医学两方俱得。 至英语至西班牙语译第二西班牙语至英语,虽单形而不集。', 'ru': 'Задача по переводу WMT Biomedical 2020 года оценивала абстрактные переводы Medline. Это небольшая задача перевода, что означает ограниченные соответствующие обучающие данные с очень четким стилем и словарным запасом. Модели, подготовленные на основе таких данных, подвержены воздействию смещения экспозиции, особенно в тех случаях, когда обучающие пары предложений являются несовершенными переводами друг друга. Это может привести к плохому поведению во время вывода, если модель научится пренебрегать исходным предложением. Запись UNICAM решает эту проблему во время тонкой настройки с использованием надежного варианта обучения минимальному риску. Мы сравниваем этот подход с фильтрацией данных для удаления «проблемных» учебных примеров. Под точной настройкой MRT мы получаем хорошие результаты по обоим направлениям английско-немецкого и английско-испанского биомедицинского перевода. В частности, мы достигаем лучшего результата перевода с английского на испанский и второго лучшего результата перевода с испанского на английский, несмотря на использование только одиночных моделей без ансамбля.', 'hi': "2020 WMT बायोमेडिकल अनुवाद कार्य ने मेडलाइन अमूर्त अनुवादों का मूल्यांकन किया। यह एक छोटा-डोमेन अनुवाद कार्य है, जिसका अर्थ है कि बहुत ही अलग शैली और शब्दावली के साथ सीमित प्रासंगिक प्रशिक्षण डेटा। इस तरह के डेटा पर प्रशिक्षित मॉडल एक्सपोजर पूर्वाग्रह प्रभावों के लिए अतिसंवेदनशील होते हैं, खासकर जब प्रशिक्षण वाक्य जोड़े एक दूसरे के अपूर्ण अनुवाद होते हैं। इसके परिणामस्वरूप अनुमान के दौरान खराब व्यवहार हो सकता है यदि मॉडल स्रोत वाक्य की उपेक्षा करना सीखता है। UNICAM प्रविष्टि न्यूनतम जोखिम प्रशिक्षण पर एक मजबूत संस्करण का उपयोग कर ठीक ट्यूनिंग के दौरान इस समस्या को संबोधित करता है। हम 'समस्या' प्रशिक्षण उदाहरणों को हटाने के लिए डेटा-फ़िल्टरिंग के साथ इस दृष्टिकोण के विपरीत हैं। एमआरटी ठीक ट्यूनिंग के तहत हम अंग्रेजी-जर्मन और अंग्रेजी-स्पेनिश बायोमेडिकल अनुवाद के दोनों दिशाओं के लिए अच्छे परिणाम प्राप्त करते हैं। विशेष रूप से हम सबसे अच्छा अंग्रेजी-से-स्पेनिश अनुवाद परिणाम और दूसरा-सबसे अच्छा स्पेनिश-से-अंग्रेजी परिणाम प्राप्त करते हैं, बिना किसी ensembling के साथ केवल एकल मॉडल का उपयोग करने के बावजूद।", 'ga': "Rinne tasc aistriúcháin Bithleighis WMT 2020 measúnú ar aistriúcháin teibí Medline. Is tasc aistriúcháin fearainn bhig é seo, rud a chiallaíonn sonraí teoranta oiliúna ábhartha le stíl agus stór focal an-difriúil. Tá múnlaí atá oilte ar shonraí den sórt sin so-ghabhálach d’éifeachtaí laofachta, go háirithe nuair is aistriúcháin neamhfhoirfe ar a chéile iad péirí pianbhreithe oiliúna. D’fhéadfadh droch-iompraíocht a bheith mar thoradh air seo le linn tátail má fhoghlaimíonn an múnla faillí a dhéanamh sa bhun-abairt. Tugann iontráil UNICAM aghaidh ar an bhfadhb seo le linn mionchoigeartaithe ag baint úsáide as malairt láidir ar Oiliúint Íos-riosca. Déanaimid codarsnacht idir an cur chuige seo agus scagadh sonraí chun samplaí oiliúna `fadhb' a bhaint. Faoi mhionchoigeartú MRT faighimid torthaí maithe don aistriúchán bithleighis Béarla-Gearmáinis agus Béarla-Spáinnis araon. Go háirithe bainimid amach an toradh aistriúcháin Béarla-go-Spáinnis is fearr agus an dara toradh is fearr ó Spáinnis go Béarla, in ainneoin nach n-úsáidtear ach samhlacha aonair gan aon ensemble.", 'hu': 'A 2020-as WMT Biomedical fordítási feladat értékelte a Medline absztrakt fordításokat. Ez egy kis tartományú fordítási feladat, ami azt jelenti, hogy korlátozott, releváns képzési adatok nagyon különböző stílusú és szókincsekkel. Az ilyen adatokra képzett modellek érzékenyek az expozíciós előírások hatására, különösen akkor, ha a mondatpárok képzése egymás tökéletlen fordításai. Ez rossz viselkedést eredményezhet a következtetés során, ha a modell megtanulja elhanyagolni a forrás mondatot. Az UNICAM bejegyzés ezt a problémát a finomhangolás során a minimális kockázati képzés robusztus változata segítségével oldja meg. Ezt a megközelítést az adatszűréssel ellentétesítjük, hogy eltávolítsuk a "probléma" oktatási példákat. Az MRT finomhangolásával jó eredményeket érünk el az angol-német és angol-spanyol orvostudományi fordítás mindkét irányában. Különösen a legjobb angol-spanyol fordítási eredményt és a második legjobb spanyol-angol eredményt érjük el, annak ellenére, hogy csak egyetlen modellt használunk összeállítás nélkül.', 'ka': "WMT ბიომედიციური გადაწყვეტილების რაოდენობაში მედილინის აბსტრაკური გადაწყვეტილება. ეს არის პატარა დიომინის გადაწყვეტილება, რომელიც ნიშნავს, რომ უფრო განსხვავებული სტილია და სიტყვებულია შესახებ შესახებ მნიშვნელოვანი განსხვავებ ამ მონაცემებისთვის მოდელები გასწავლილი იქნება, განსაკუთრებით, როდესაც მასწავლის კონფიგურაციის ზოგები ერთმანეთისთვის უკეთესი გასწავლებელია. ეს შეიძლება შეუძლებელია ცოტა ქცევა ინფრენციის განმავლობაში, თუ მოდელის სწავლის, რომ მისი წესების გადარჩენა. UNICAM მოწყობილობა ამ პრობლემების მისამართება მინიმულ რისკის განსწავლებაში გამოყენებული ძალიან გარიანტი. მონაცემების ფილტრირებისთვის ამ პროგრამის გარეშე `პრობლემები' მაგალითების გარეშე. MRT-ის კონტურაციაში ჩვენ მივიღეთ კარგი შედეგები ინგლისური-გერმანური და ინგლისური-სპანელი ბიომედიციური გაგრძელების ორივე მიერ. განსაკუთრებით ჩვენ მივიღეთ ყველაზე საუკეთესი ანგლისური-სპანელი შედეგი და მეორე-საუკეთესი სპანელი-ანგლისური შედეგი, მაგრამ გამოყენება მხოლოდ ერთი მოდე", 'el': 'Η εργασία βιοϊατρικής μετάφρασης 2020 αξιολόγησε αφηρημένες μεταφράσεις της Medline. Πρόκειται για μια εργασία μετάφρασης μικρού τομέα, που σημαίνει περιορισμένα σχετικά δεδομένα κατάρτισης με πολύ ξεχωριστό στυλ και λεξιλόγιο. Τα μοντέλα που εκπαιδεύονται σε τέτοια δεδομένα είναι ευαίσθητα σε επιδράσεις προκατάλειψης έκθεσης, ιδιαίτερα όταν τα ζεύγη εκπαιδευτικών προτάσεων είναι ατελείς μεταφράσεις μεταξύ τους. Αυτό μπορεί να οδηγήσει σε κακή συμπεριφορά κατά την εξαγωγή συμπερασμάτων εάν το μοντέλο μάθει να παραμελεί την πρόταση προέλευσης. Η καταχώρηση αντιμετωπίζει αυτό το πρόβλημα κατά τη διάρκεια του συντονισμού χρησιμοποιώντας μια ισχυρή παραλλαγή στην εκπαίδευση ελάχιστου κινδύνου. Αντιθέτουμε αυτή την προσέγγιση με το φιλτράρισμα δεδομένων για να αφαιρέσουμε τα παραδείγματα κατάρτισης "προβλήματος". Στο πλαίσιο του συντονισμού επιτυγχάνουμε καλά αποτελέσματα και για τις δύο κατευθύνσεις της αγγλο-γερμανικής και αγγλο-ισπανικής βιοϊατρικής μετάφρασης. Ειδικότερα επιτυγχάνουμε το καλύτερο αποτέλεσμα της αγγλικής-ισπανικής μετάφρασης και το δεύτερο καλύτερο αποτέλεσμα της ισπανικής-αγγλικής, παρά τη χρήση μόνο μεμονωμένων μοντέλων χωρίς σύνολο.', 'kk': 'WMT биомедикалық аудармалар тапсырмасы "Medline" абстракты аудармаларды бағалады. Бұл кішкентай доменді аудару тапсырмасы. Сонымен қатар маңызды оқыту деректері өте бөлек стиль мен сөздік тізімі бар. Бұл деректерге ұқсас берілген үлгілер көзгертілген эффекттерді көрсетуге мүмкіндік береді, өйткені бұл үлгілер бір-бірінің аяқталмаған аудармалары емес. Бұл үлгі көздегі сөйлемені шешіруді үйренген болса, бақылау кезінде керек әрекет болады. UNICAM жазуы минималдық қауіпсіздік оқыту үшін дұрыс түзету кезінде осы мәселеді адрестеді. Бұл жағдайды деректерді сүзгілеу үшін \'мәселе\' оқыту мысалдарын алып тастау үшін қарсы қарсы. МРТ жақсы түзету арқылы біз ағылшын-неміс және ағылшын-испан биомедикалық аудармасының екі жақсы нәтижелерін аламыз. Әрине біз ағылшын тілінен испан тілінен ең жақсы аудару нәтижесін және екінші жақсы испан тілінен ағылшын тілінен ең жақсы нәтижесін жеткіземіз. Бірақ тек бір моделі қо', 'it': 'Il compito di traduzione biomedica WMT 2020 ha valutato le traduzioni astratte Medline. Si tratta di un compito di traduzione di piccolo dominio, il che significa dati formativi rilevanti limitati con stile e vocabolario molto distinti. I modelli formati su tali dati sono suscettibili agli effetti di distorsione dell\'esposizione, in particolare quando le coppie di frasi di allenamento sono traduzioni imperfette l\'una dell\'altra. Questo può comportare un cattivo comportamento durante l\'inferenza se il modello impara a trascurare la frase di origine. La voce UNICAM affronta questo problema durante la messa a punto utilizzando una variante robusta sulla formazione a rischio minimo. Contrastiamo questo approccio con il filtraggio dei dati per rimuovere esempi di formazione "problematici". Con la messa a punto MRT otteniamo buoni risultati per entrambe le direzioni di traduzione biomedica inglese-tedesca e inglese-spagnola. In particolare, otteniamo il miglior risultato di traduzione dall\'inglese allo spagnolo e il secondo miglior risultato dall\'italiano all\'inglese, pur utilizzando solo modelli singoli senza ensembling.', 'lt': "2020 m. WMT Biomedical vertimo užduotyje įvertinti Medline abstraktūs vertimai. Tai nedidelės srities vertimo užduotis, t. y. riboti atitinkami mokymo duomenys su labai skirtingu stiliu ir žodynu. Tokiais duomenimis parengti pavyzdžiai gali turėti neigiamą poveikį apšvitai, ypač kai mokymo sakinių poros yra nepakankamai išverstos viena kitą. Tai gali sukelti blogą elgesį, jei modelis išmoks pamiršti pradinį sakinį. UNICAM įrašas šią problem ą sprendžia koreguojant naudojant patikimą minimalios rizikos mokymo variant ą. We contrast this approach with data-filtering to remove `problem' training examples.  Under MRT fine-tuning we obtain good results for both directions of English-German and English-Spanish biomedical translation.  Visų pirma mes pasiekiame geriausią vertimo anglų kalba į ispanų kalbą rezultatą ir antrąjį geriausią vertimo ispanų kalba į anglų kalbą rezultatą, nepaisant to, kad naudojame tik vienus modelius be ensemblių.", 'mk': 'Задачата за превод на БИМТ за 2020 година ги процени апстрактните преводи на Медлин. Ова е задача за превод на мали домени, што значи ограничени релевантни податоци за обука со многу различни стили и зборови. Моделите обучени на вакви податоци се чувствителни на предрасудни ефекти на изложеност, особено кога обучувањето на парови на реченици е несовршено преведување еден на друг. Ова може да резултира со лошо однесување за време на конференцијата ако моделот научи да ја заборави изворната реченица. Влезот на УНИКАМ го решава овој проблем за време на фино прилагодување користејќи силен варијант за минимално обука за ризик. Го контрастираме овој пристап со филтрирање на податоци за да ги отстраниме примерите за обука на „ проблем “. Под МРТ финетизирање добиваме добри резултати за двете насоки на англиско-германско и англиско-шпанско биомедицинско превод. Посебно го постигнуваме најдобриот резултат на англиско-шпанско превод и вториот најдобар резултат на шпанско-англиско превод, и покрај тоа што користиме само еден модел без ансемблирање.', 'mt': 'Il-kompitu tat-traduzzjoni bijomedika tal-2020 tal-WMT evalwa t-traduzzjonijiet astratti tal-Medline. Dan huwa kompitu ta’ traduzzjoni f’dominju żgħir, li jfisser dejta ta’ taħriġ rilevanti limitata bi stil u vokabulari distinti ħafna. Models trained on such data are susceptible to exposure bias effects, particularly when training sentence pairs are imperfect translations of each other.  Dan jista’ jirriżulta f’imġiba ħażina matul l-inferenza jekk il-mudell jitgħallem jinjora s-sentenza tas-sors. L-annotazzjoni tal-UNICAM tindirizza din il-problem a waqt l-irfinar bl-użu ta’ varjant robust dwar it-Taħriġ tar-Riskju Minimu. Aħna nikkuntrastaw dan l-approċċ mal-filtrazzjoni tad-dejta biex neħħew eżempji ta\' taħriġ ta\' "problema". Taħt l-aġġustament tal-MRT inkisbu riżultati tajbin għaż-żewġ direzzjonijiet tat-traduzzjoni bijomedika Ingliż-Ġermaniż u Ingliż-Spanjol. B’mod partikolari nilħqu l-aħjar riżultat tat-traduzzjoni Ingliż-Spanjol u t-tieni l-aħjar riżultat Spanjol-Ingliż, minkejja li nużaw biss mudelli singoli mingħajr ġabra.', 'ms': "Tugas terjemahan Biomedik WMT 2020 menilai terjemahan abstrak Medline. Ini adalah tugas terjemahan domain kecil, bermakna data latihan berkaitan terhad dengan gaya dan vokbulari yang sangat berbeza. Model yang dilatih pada data seperti ini susah untuk kesan bias pengungkapan, terutama apabila pasangan kalimat latihan adalah terjemahan yang tidak sempurna satu sama lain. Ini boleh menghasilkan perilaku buruk semasa kesimpulan jika model belajar untuk mengabaikan kalimat sumber. Masukan UNICAM mengatasi masalah ini semasa penyesuaian baik menggunakan varian yang kuat dalam Latihan Risiko Minimum. We contrast this approach with data-filtering to remove `problem' training examples.  Di bawah penyesuaian MRT kami mendapat keputusan yang baik untuk kedua-dua arah terjemahan biomedikal Inggeris-Jerman dan Inggeris-Sepanyol. Terutama, kita mencapai hasil terjemahan bahasa Inggeris ke Sepanyol yang terbaik dan hasil bahasa Sepanyol ke Inggeris yang kedua yang terbaik, walaupun hanya menggunakan model tunggal tanpa kumpulan.", 'mn': "2020 оны WMT биологийн эрүүл мэндийн хөгжлийн даалгавар нь Medline abstract хөгжлийг үнэлдэг. Энэ бол жижиг хэлбэрээр орчуулах үйл ажиллагаа. Энэ нь маш өөр өөр хэлбэртэй болон үг хэлбэрээр хамааралтай боловсруулах мэдээлэл юм. Эдгээр өгөгдлийн талаар сургалтын загварууд нөлөөлөх нөлөөлөх боломжтой. Ялангуяа өгөгдлийн хоорондоо сургалтын хоорондоо бүтэлгүйтгэл хөрөнгө оруулах боломжгүй. Хэрэв загвар эх үүсвэрийн өгүүлбэрийг алдахыг сурах юм бол энэ нь халдварын үед ядуу үйл явдал болох юм. UNICAM-ын оролцоо нь энэ асуудлыг багасгах үед хамгийн багасгал эрсдэлийн дасгал хөгжүүлэхэд хүчтэй хувьцаа ашигладаг. Бид энэ арга замыг 'асуудал' сургалтын жишээг устгахын тулд өгөгдлийн сүзүүлэлтийн тулд эсэргүүцдэг. Бид Англи-Герман, Англи-Испан биологийн эрүүл мэндийн хөгжлийн хоёр талаар сайн үр дүнг авдаг. Ялангуяа бид Англи-ээс Испан-ээс хамгийн шилдэг орчуулалт, хоёр дахь шилдэг Испан-ээс англи-ээс хамгийн сайн үр дүн гаргадаг. Гэхдээ зөвхөн ганц загвар ашиглаж байгаагаар ч.", 'ml': "2020 WMT ബിയോമിഡിക്കല്\u200d പരിഭാഷക്കുറിച്ച് മെഡിലൈന്\u200d അബ്രാക്ട്രാക്റ്റ് ഭാഷകങ്ങള്\u200d പരിശോധിച്ചു. ഇതൊരു ചെറിയ ഡൊമെയിന്\u200d പരിശീലന ജോലിയാണ്. അതിന്റെ അര്\u200dത്ഥം വളരെ വ്യത്യസ്തമായ ശൈലിയും പദവിശേഷവുമുള്ള പരിശീലന വ Models trained on such data are susceptible to exposure bias effects, particularly when training sentence pairs are imperfect translations of each other.  സോര്\u200dസ് വാക്ക് ഉപേക്ഷിക്കാന്\u200d മോഡല്\u200d പഠിക്കുന്നുവെങ്കില്\u200d അസാധാരണമായ പ്രവര്\u200dത്തനത്തിന്റെ പ്രകൃ യുനിസാമിന്റെ എന്\u200dട്രിയില്\u200d ഏറ്റവും കുറഞ്ഞ അപകടത്തിന്റെ പരിശീലനത്തില്\u200d റോബോസ്റ്റ് വേറെന്റ് ഉപയോഗിച്ച് ഈ പ്ര 'പ്രശ്നം' പരിശീലനത്തിന്റെ ഉപമകള്\u200d നീക്കം ചെയ്യാന്\u200d വേണ്ടി ഡാറ്റ-ഫില്\u200dറ്റര്\u200d ചെയ്യുന്ന ഈ പ് എംആര്\u200dടിംടി സുന്ദരിയുടെ അടിസ്ഥാനത്ത് നമുക്ക് നല്ല ഫലങ്ങള്\u200d കിട്ടുന്നു ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d രണ്ട് വഴികള്\u200dക്കും ഇംഗ പ്രത്യേകിച്ച് നമ്മള്\u200d ഏറ്റവും നല്ല ഇംഗ്ലീഷില്\u200d നിന്നും സ്പാനിഷ് പരിഭാഷയില്\u200d നിന്നും രണ്ടാമത്തെ ഏറ്റവും നല്ല സ്പാനിഷ് മുതല്\u200d ഇംഗ്", 'pl': 'Zadanie tłumaczenia biomedyczne 2020 WMT oceniło tłumaczenia abstrakcyjne Medline. Jest to zadanie tłumaczenia małej domeny, co oznacza ograniczone istotne dane szkoleniowe o bardzo wyraźnym stylu i słownictwie. Modele przeszkolone na podstawie takich danych są podatne na efekty stronnicze ekspozycji, zwłaszcza gdy pary zdań treningowych są niedoskonałymi tłumaczeniami siebie nawzajem. Może to prowadzić do złego zachowania podczas wnioskowania, jeśli model nauczy się zaniedbywać zdanie źródłowe. Wpis UNICAM rozwiązuje ten problem podczas dostrajania za pomocą solidnego wariantu na szkoleniu minimalnego ryzyka. Porównujemy to podejście z filtrowaniem danych, aby usunąć przykłady szkoleń problemowych. W ramach dostrajania MRT uzyskujemy dobre wyniki dla obu kierunków tłumaczenia biomedycznego angielsko-niemieckiego i angielsko-hiszpańskiego. W szczególności osiągamy najlepszy wynik tłumaczenia z języka angielskiego na hiszpański i drugi najlepszy wynik z języka hiszpański na angielski, pomimo użycia tylko pojedynczych modeli bez zestawu.', 'ro': 'Sarcina de traducere WMT Biomedical 2020 a evaluat traducerile abstracte Medline. Aceasta este o sarcină de traducere cu domenii mici, ceea ce înseamnă date de formare relevante limitate, cu stil și vocabular foarte distincte. Modelele instruite pe baza unor astfel de date sunt susceptibile la efecte de distorsiune a expunerii, în special atunci când perechile de fraze de formare sunt traduceri imperfecte reciproce. Acest lucru poate duce la comportament slab în timpul deducerii dacă modelul învață să neglijeze propoziția sursă. Înregistrarea UNICAM abordează această problemă în timpul reglării fine folosind o variantă robustă de instruire privind riscul minim. Contrastăm această abordare cu filtrarea datelor pentru a elimina exemplele de instruire "probleme". În cadrul reglajului fin MRT obținem rezultate bune pentru ambele direcții de traducere biomedicală engleză-germană și engleză-spaniolă. În special, obținem cel mai bun rezultat de traducere din engleză în spaniolă și al doilea cel mai bun rezultat din spaniolă în engleză, în ciuda faptului că folosim doar modele unice fără ansamblu.', 'no': 'Den biomediske omsetjinga for WMT 2020 evaluerte Medline abstrakt omsetjingar. Dette er eit lite domeneomsetjingsdata, som betyr begrenset relevante opplæringsdata med veldig skilt stil og ordbok. Modellar trengte på slike data er tværleg til eksponeringseffektar, særleg når setningar er ikkje fullstendig oversettelsar av kvarandre. Dette kan føre til dårlig oppførsel under infeksjon dersom modellen lærer å forstørra kjeldesetninga. UNICAM- oppføringa adresserer dette problemet under finnstilling ved hjelp av ein robust variant på minimumrisikotrening. Vi kontrastrerer denne tilnærminga med datafiltrering for å fjerna eksemplar for opplæring av «problem». Under MRT-finnstilling får vi gode resultat for både retningar av engelsk-tysk og engelsk-spansk biomedisk omsetjing. I særskilt oppnår vi det beste resultatet for omsetjing av engelsk til spansk og det andre beste spansk til engelsk resultatet, selv om berre brukar enkle modeller med ingen ensembling.', 'sr': 'Zadatak WMT biomedicinskog prevoda za 2020. procenio je apstraktne prevode Medline. Ovo je zadatak za prevod malih domena, koji znači ograničeni relevantni podaci za obuku sa veoma različitim stilom i rečnikom. Modeli obučeni na takvim podacima su osjetljivi na efekte predrasude izloženja, posebno kada su par odvjetničkih rečenica neprometni prevodi jedni druge. To može rezultirati loše ponašanje tokom infekcije ako model nauči da zanemari izvornu rečenicu. UniCAM ulaz rješava ovaj problem tijekom finalnog prilagodbe koristeći jačan variant na minimalnoj obuci rizika. Kontrastujemo ovaj pristup filtriranjem podataka kako bi uklonili primjere obuke "problema". Pod MRT-om izvršavanjem dobijamo dobre rezultate za obe upute o biomedicinskom prevodu engleskog i njemačkog i engleskog i španjolskog jezika. Posebno postižemo najbolji rezultat prevođenja engleskog do španjolskog i drugi najbolji rezultat španjolskog do engleskog, uprkos korištenjem jedinih modela bez ensembliranja.', 'si': "WMT ජීවිත වෛද්\u200dය විද්\u200dයාපාර ක්\u200dරියාව මෙඩ්ලායින් නිර්මාණය විශ්වාස කළා. මේක පුංචි ඩොමේන් වාර්ථාපනය වැඩක්, අදහස් විශේෂ විදිහට සම්බන්ධ විදිහට ප්\u200dරශ්නය දත්ත ස අනිවාර්ය දත්තේ ප්\u200dරධානය කරලා තියෙන ප්\u200dරභාවිත විදිහට ප්\u200dරභාවිත වෙන්න පුළුවන්, විශේෂයෙන්ම වාක්ය දෙන මේකට පුළුවන් පුළුවන් පරීක්ෂණයක් වෙලාවේ අනතුරු වාර්තාවක් වෙනුවෙන් මොඩේල් ඉගෙන ගන්න පුළ UNICAM ඇතුලට මේ ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරන්න ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරන්න පුළුවන් අඩුම භා අපි මේ ප්\u200dරවේශනය 'ප්\u200dරශ්නයක්' ප්\u200dරශ්නයක් අතිරික්ෂණය කරන්න දත්ත පරික්ෂණය සඳහා ප්\u200dරවේශනය කර MRT හොඳ සංවිධානය සඳහා අපි ඉංග්\u200dරීස්-ජර්මාන් සහ ඉංග්\u200dරීස්-ස්පැනිස් බියෝඩික් භාෂාවක් දෙ විශේෂයෙන්ම අපි ඉංග්\u200dරීසියෙන් ඉංග්\u200dරීසියෙන් ඉංග්\u200dරීසියෙන් ඉංග්\u200dරීසියෙන් ඉංග්\u200dරීසියෙන් හොඳම ප්\u200dරත", 'so': "The 2020 WMT Biomedical translation mission evaluated Medline abstract translations. Kanu waa shaqada turjumista yar ee domain, taas oo micnaheedu yahay macluumaad la xiriira waxbarashada oo aad u kala duduwan iyo hadal kala duduwan. Models trained on such data are susceptible to exposure bias effects, particularly when training sentence pairs are imperfect translations of each other.  Markaas waxaa sabab u noqon kara tababar baaraandegista marka loo jiro, haddii uu samoolku ogaado in uu ka tago xukunka asalka ah. Guurka UNICAM ayaa dhibaatadan ku habboonaya marka loo isticmaalo isbedelka arimaha ugu yaraan waxbarashada khatar. Waxaynu ka duwan nahay qaababkan baaritaanka macluumaadka si aan u qaadno tusaalayaal tababarida `dhibaatada'. Dalka MRT-ka hoostiisa waxaa laga helaa midhaha wanaagsan ee labada hagitaan afka Ingiriis-Jarmal iyo afka Ingiriis-Isbanish-turjumista biomedical ah. Si gaar ah waxaynu gaadhaynaa arimaha ugu wanaagsan ee turjumista Ingiriiska-ilaa Isbanish iyo resultinta labaad ee ugu wanaagsan Isbanish-ilaa Ingiriis, inkastoo aan isticmaalno modello kaliya oo aan la mid ahayn.", 'sv': '2020 års WMT Biomedical översättningsuppgift utvärderade Medline abstrakta översättningar. Detta är en översättningsuppgift med små domäner, vilket innebär begränsade relevanta utbildningsdata med mycket distinkt stil och ordförråd. Modeller som tränas på sådana data är känsliga för exponeringsskador effekter, särskilt när träningsmeningar är ofullständiga översättningar av varandra. Detta kan resultera i dåligt beteende under inferensen om modellen lär sig att försumma källmeningen. UNICAM-posten behandlar detta problem under finjustering med hjälp av en robust variant på Minimum Risk Training. Vi kontrasterar detta tillvägagångssätt med datafiltrering för att ta bort "problem"-utbildningsexempel. Under MRT finjustering får vi goda resultat för båda riktningarna av engelsk-tyska och engelsk-spanska biomedicinsk översättning. Framför allt uppnår vi det bästa översättningsresultatet från engelska till spanska och näst bästa resultat från spanska till engelska, trots att vi endast använder enstaka modeller utan sammansättning.', 'ta': "2020 WMT Biomedical translation task evaluated Medline abstract translations. kgm இது சிறிய- domain மொழிபெயர்ப்பு பணி இந்த தரவில் பயிற்சி மாதிரிகள் பியாஸ் விளைவுகளை வெளிப்படுத்துவதற்கு சந்தேகமாக இருக்கிறது, குறிப்பாக பயிற்சி சொல் ஜோட இந்த மூல வாக்கியத்தை தவிர்க்க முடியும் போது பாதிப்புக் குறையான நடத்தைக்கு முடியும். UNICAM உள்ளீடு குறைந்தபட்ச ஆபத்து பயிற்சி 'பிரச்சனை' பயிற்சி உதாரணங்களை நீக்க இந்த அணுக்கத்தை தரவு-வடிகட்டியுடன் மாற்றுகிறோம். MRT சரியான தூண்டுதல் கீழே நாங்கள் நன்றாக முடிவுகள் பெறுகிறோம் ஆங்கிலம்- ஜெர்மன் மற்றும் ஆங்கிலம்- ஸ்பானிஷ் உயி குறிப்பிட்ட ஆங்கிலத்தில் இருந்து ஸ்பானிஷ் மொழிபெயர்ப்பு முடிவுகள் மற்றும் இரண்டாவது சிறந்த ஸ்பானிஷ் முதல் ஆங்கிலம் முட", 'ur': "۲۰۰۲ WMT Biomedical translation task evaluated Medline abstract translations. یہ ایک چھوٹی ڈومین ترجمہ کا کام ہے، یعنی بسیار مختلف طریقے اور لکھائی کے ساتھ محدودہ تعلیم دیٹا ہے۔ ایسے ڈیٹے پر آموزش کی مدلس بغیر اثرات کے لئے مضبوط ہیں، مخصوصا جب مجلس جوڑوں کی آموزش کی جڑ ایک دوسرے کی ناکام ترجمہ کی جاتی ہیں. اگر موڈل سورج جماعت کو غافل کرنا سکھے تو اس کا نتیجہ ضرورت کے وقت بدبخت رفتار کا نتیجہ ہوتا ہے. UNICAM ننوت اس مسئلہ کو اچھی ریسک ٹرینینگ پر مضبوط بدلنے کے موقع فائدہ تنظیم کرنے کے لئے سمجھتا ہے. ہم اس طریقے سے ڈیٹا فیلٹرینگ کے ساتھ مخالفت کرتے ہیں کہ `مشکل' تعلیم مثالیں دور کریں۔ ہم انگلیسی-جرمن اور انگلیسی-اسپانیایی بیوڈیسی ترجمہ کے دونوں طریقوں کے لئے اچھے نتائج حاصل کرتے ہیں. مخصوصا ہم انگلیسی سے اسپانیایی ترجمہ نتیجہ پہنچاتے ہیں اور دوسرے سے بہترین اسپانیایی سے انگلیسی نتیجہ پہنچاتے ہیں، بغیر اس کے کہ صرف ایک نمڈل کا استعمال کرتا ہے کہ کوئی انگلیسی نہیں ہے۔", 'uz': "@ info: whatsthis This is a small-domain translation task, meaning limited relevant training data with very distinct style and vocabulary.  Bu maʼlumot uchun o'rganilgan Modellar biz effektlarini ko'rsatish mumkin. Hullas, gapning ikkita so'zlari birлари birga tarjima qilish muvaffaqiyatsiz emas. Bu asboblar manba soʻzni saqlashni o'rganadi. Name @ info: whatsthis MRT'ning yaxshi darajada biz ingliz- Olmoncha va ingliz-ispancha biomediya tarjima haqida yaxshi natijalar olib kelamiz. Biz eng yaxshi ingliz tiliga Ispanchaga tarjima natijalarini bajaramiz va ikkinchi eng tildan eng eng yaxshi ingliz natijalarini bajaramiz.", 'vi': 'Bài dịch dịch sơ cứu mạng mạng mạng 2020 đã đánh giá cao Medline trừu tượng. Đây là một nhiệm vụ dịch chuyển nhỏ miền, nghĩa là chỉ có các dữ liệu đào tạo liên quan với phong cách và từ điển rất khác nhau. Những mẫu được huấn luyện trên dữ liệu này có khả năng gây thiên vị phơi nhiễm, đặc biệt khi các cặp câu huấn luyện là những bản dịch chưa hoàn hảo của nhau. Điều này có thể dẫn đến một hành vi sai lầm trong khi nhận ra người mẫu học cách bỏ quên câu phát âm. Việc nhập vào UNIX sẽ giải quyết vấn đề này khi nghiên cứu cẩn thận bằng cách sử dụng phương pháp nghiên cứu rủi ro tối thiểu. Chúng tôi đối lập phương pháp này với bộ lọc dữ liệu để xóa các trường hợp "vấn đề". Dưới sự nghiên cứu kỹ thuật của MRX Chúng tôi có kết quả tốt cho cả hai hướng dịch sinh học Anh-Đức và Anh-Tây Ban Nha. Chúng tôi đặc biệt đạt được kết quả dịch chuyển tốt nhất Anh-Tây-Ban-Nha và kết quả tốt thứ hai giữa Tây Ban Nha và Anh, mặc dù chỉ sử dụng mô hình đơn lẻ mà không có dàn hợp.', 'da': 'WMT Biomedical oversættelsesopgave i 2020 evaluerede Medline abstrakte oversættelser. Dette er en oversættelsesopgave med små domæner, hvilket betyder begrænsede relevante træningsdata med meget tydelig stil og ordforråd. Modeller, der er trænet på sådanne data, er modtagelige for eksponeringsskævhedseffekter, især når træningspar er ufuldstændige oversættelser af hinanden. Dette kan resultere i dårlig adfærd under konklusionen, hvis modellen lærer at forsømme kildesætningen. UNICAM-indgangen løser dette problem under finjustering ved hjælp af en robust variant på Minimum Risk Training. Vi sammenligner denne tilgang med datafiltrering for at fjerne eksempler på problemtræning. Under MRT finjustering opnår vi gode resultater for begge retninger af engelsk-tysk og engelsk-spansk biomedicinsk oversættelse. Især opnår vi det bedste engelsk-til-spansk oversættelsesresultat og næstbedste spansk-til-engelsk resultat, selvom vi kun bruger enkeltmodeller uden sammensætning.', 'bg': 'Задачата за превод на Биомедицински превод за 2020 г. оцени абстрактните преводи на Медлайн. Това е задача за превод с малък домейн, което означава ограничени подходящи данни за обучение с много различен стил и речник. Моделите, обучени по такива данни, са податливи на въздействие на отклонения от експозицията, особено когато двойките тренировъчни изречения са несъвършени преводи един на друг. Това може да доведе до лошо поведение по време на заключението, ако моделът се научи да пренебрегва изходното изречение. Вписването на УНИКАМ решава този проблем по време на фина настройка, използвайки стабилен вариант на обучение за минимален риск. Контрастираме този подход с филтрирането на данни, за да премахнем примерите за обучение с "проблеми". При фината настройка на МРТ получаваме добри резултати и в двете посоки на англо-немски и англо-испански биомедицински превод. По-специално постигаме най-добрия резултат от превод от английски на испански и втори най-добър резултат от испански на английски, въпреки че използваме само единични модели без ансамблиране.', 'hr': 'Zapovjednik WMT biomedicinskog prevoda za 2020. godinu procijenio je apstraktne prevode Medline. To je zadatak za prevod malih domena, znači ograničeni relevantni podaci obuke s vrlo različitim stilom i riječnikom. Modeli obučeni na takvim podacima su osjetljivi na učinak predrasude izloženosti, posebno kada su par odvjetničke rečenice nepovršeni prevodi jedni druge. To može rezultirati loše ponašanje tijekom infekcije ako model nauči da zanemari izvornu rečenicu. UNICAM ulazak rješava ovaj problem tijekom finalnog prilagođenja koristeći jaku variantu na minimalnom obuku rizika. Kontrastiramo ovaj pristup filtriranjem podataka kako bi uklonili primjere obuke «problema». Pod MRT-ovom finom prilagodbom dobijamo dobre rezultate za obe upute o biomedicinskom prevodu engleskog-njemačkog i engleskog-španjolskog jezika. Posebno postignemo najbolji rezultat prevoda engleskog do španjolskog i drugi najbolji rezultat španjolskog do engleskog, uprkos korištenju jedinih modela bez ensembliranja.', 'nl': "De 2020 WMT Biomedische vertaaltaak beoordeelde abstracte vertalingen van Medline. Dit is een vertaaltaak voor een klein domein, wat betekent beperkte relevante trainingsgegevens met een zeer duidelijke stijl en woordenschat. Modellen getraind op dergelijke gegevens zijn gevoelig voor blootstellingsbias effecten, vooral wanneer trainingszinnenparen onvolledige vertalingen van elkaar zijn. Dit kan resulteren in slecht gedrag tijdens inferentie als het model leert de bronzin te verwaarlozen. De UNICAM-vermelding lost dit probleem op tijdens finetuning met behulp van een robuuste variant op Minimum Risk Training. We contrasteren deze aanpak met data-filtering om 'probleem' trainingsvoorbeelden te verwijderen. Onder MRT finetuning krijgen we goede resultaten voor beide richtingen van Engels-Duits en Engels-Spaans biomedische vertaling. Met name bereiken we het beste Engels-naar-Spaans vertaalresultaat en het tweede beste Spaans-naar-Engels resultaat, ondanks het gebruik van slechts enkele modellen zonder ensemblage.", 'de': 'Die 2020 WMT Biomedical Translation Task evaluierte Medline abstrakte Übersetzungen. Dies ist eine kleine Übersetzungsaufgabe, d.h. begrenzte relevante Trainingsdaten mit sehr ausgeprägtem Stil und Wortschatz. Modelle, die auf solchen Daten trainiert werden, sind anfällig für Exposure Bias Effekte, insbesondere wenn Trainingssatzpaare unvollkommene Übersetzungen voneinander sind. Dies kann zu schlechtem Verhalten während der Inferenz führen, wenn das Modell lernt, den Ausgangssatz zu vernachlässigen. Der UNICAM-Eintrag löst dieses Problem bei der Feinabstimmung mit einer robusten Variante auf Minimum Risk Training. Wir kontrastieren diesen Ansatz mit Datenfilterung, um Problemtrainingsbeispiele zu entfernen. Unter MRT-Feinabstimmung erzielen wir gute Ergebnisse für beide Richtungen der englisch-deutschen und englisch-spanischen biomedizinischen Übersetzung. Insbesondere erzielen wir das beste Deutsch-ins-Spanisch Übersetzungsergebnis und das zweitbeste Spanisch-ins-Englisch Ergebnis, obwohl wir nur einzelne Modelle ohne Ensemble verwenden.', 'fa': 'وظیفه ترجمه زیست پزشکی WMT ۲۰۰۲، ترجمه\u200cهای مطلق مدلین را ارزیابی کرد. این یک وظیفه ترجمه کوچک دامنی است که یعنی داده های آموزش مربوط به عنوان طرح و کلمات بسیار متفاوت محدود است. Models trained on such data are susceptible to exposure bias effects, particularly when training pairs of sentence are incomplete translations of each other. اگر مدل یاد بگیرد که کلمه منبع را نادیده بگیرد، این نتیجه به رفتار بدی در زمان بیماری است. وارد UNICAM این مشکل را در زمان تنظیم کردن با استفاده از یک تغییر قوی در آموزش Minimum Risk به کار می\u200cدهد. ما این روش را با فیلتر داده\u200cها تفاوت می\u200cکنیم تا مثال آموزش «مشکل» را حذف کنیم. ما نتیجه\u200cهای خوب برای ترجمه زیست پزشکی انگلیسی-آلمانی و انگلیسی-اسپانیایی به دست آوردیم. مخصوصاً ما بهترین نتیجه ترجمه انگلیسی به اسپانیایی و نتیجه دوم بهترین اسپانیایی به انگلیسی را رسیدیم، با وجود استفاده از تنها مدل\u200cهای تنها بدون انگلیسی.', 'id': "The 2020 WMT Biomedical translation task evaluated Medline abstract translations.  Ini adalah tugas terjemahan domain kecil, artinya data latihan relevan terbatas dengan gaya dan vokal yang sangat berbeda. Model yang dilatih pada data seperti ini susceptible untuk efek bias eksposisi, terutama ketika pasangan kalimat pelatihan adalah terjemahan yang tidak sempurna satu sama lain. Ini bisa menyebabkan perilaku buruk selama kesimpulan jika model belajar untuk mengabaikan kalimat sumber. Entri UNICAM mengatasi masalah ini selama penyesuaian dengan menggunakan varian yang kuat dalam Pelatihan Risiko Minimum. Kami bertentangan pendekatan ini dengan penapisan data untuk menghapus contoh pelatihan `masalah'. Di bawah penyesuaian MRT kami mendapatkan hasil yang baik untuk kedua arah dari terjemahan biomedis Inggris-Jerman dan Inggris-Spanyol. Terutama kita mencapai hasil terjemahan terbaik bahasa Inggris-Spanyol dan hasil kedua terbaik bahasa Spanyol-Inggris, meskipun hanya menggunakan model tunggal tanpa ensembling.", 'ko': '2020년 WMT 생물의학 번역 임무는 메드린 요약 번역을 평가했다.이것은 소규모 분야의 번역 임무로 관련 교육 데이터가 유한하고 스타일과 어휘가 매우 독특하다는 것을 의미한다.이러한 데이터 훈련 모델은 노출 편차 효과의 영향을 받기 쉽다. 특히 훈련 문장이 서로의 번역에 완벽하지 않을 때.만약 모델 학습이 원문구를 소홀히 한다면 추리 과정 중의 불량 행위를 초래할 수 있다.UNICAM 항목은 미세 조정 과정에서 최소한의 위험 교육에 관한 건장한 변체를 사용하여 이 문제를 해결했다.우리는 이러한 방법과 데이터 필터를 비교하여 문제 훈련 예시를 삭제할 것이다.MRT 미세조정으로 우리는 영어-독일어와 영어-스페인어 생물의학 번역의 두 방향에서 모두 좋은 결과를 얻었다.특히 우리는 가장 좋은 영어에서 스페인어로 번역된 결과와 두 번째 좋은 스페인어에서 영어로 번역된 결과를 실현했고 단일 모델만 사용했지만 통합되지 않았다.', 'sw': "Kazi ya tafsiri ya Biomedical ya WMT 2020 ilitathmini tafsiri za kisasa za kutetea. Hii ni kazi ya tafsiri ndogo ya ndani, ina maana ya taarifa za mafunzo yenye tofauti na lugha. Modeli zilizofundishwa katika takwimu hizi zina mashaka ya kuonyesha madhara ya upendeleo, hususani wakati mafunzo ya wanandoa wa hukumu ni tafsiri isiyo sahihi kwa wao. This can result in poor behaviour during inference if the model learns to neglect the source sentence.  Uingizi wa UNICAM huzungumzia tatizo hili wakati wa kutangaza vizuri kwa kutumia mabadiliko ya kijinsia kuhusu mafunzo ya hatari ya chini. Tunafanana tofauti na mbinu hii na kuchuja taarifa ili kuondoa mifano ya mafunzo ya 'tatizo' . Chini ya mafunzo mazuri ya MRT tunapata matokeo mazuri kwa maelekezo mawili ya tafsiri ya kitabibu cha Kiingereza na Kiingereza na Kihispania. Kwa hakika tunafanikiwa matokeo bora ya tafsiri ya Kiingereza hadi Kihispania na matokeo ya pili bora ya Kihispania-hadi Kiingereza, pamoja na kutumia mifano moja tu bila kuchochea.", 'tr': "WMT Biwomedicin terjime täblisasy Medline abstrakt terjimelerini çykdy. Bu kiçi-domain terjime täblisasidir, meýilleşdirýän eğitim maglumaty örän üýtgeşik stil we sözleşik bilen nähili möhüm bolan terjime täblisasidir. Bärde maglumatlar üçin bilinmeli nusgalar nähili gabat täsirlerini görünşine mümkin däldir, ýöne-de sözleşim çiftleri bir-biriniň terjimeleri boýunça däldir. Eger modeli çeşme sözlerini unutmak üçin öwrenen bolsa, bu azajyk wagtynda erbet hereket edip biler. UNICAM girişi Minimal Risk Eğitiminde güýçli bir wariant ullanýan wagtynda bu mesele çözdi. Biz bu ýagdaýy 'problema' okuwçysyny ýitirmek üçin data filtrelemek bilen tertibleýäris MRT-yň gowy düzümlenmesi bilen iňlisçe-nemes we iňlisçe-ispanyýa biomedical terjimesiniň hem döwletlerinde gowy netijesi bar. Iňlisçe-we Spanish terjime edeniň iň gowy netijesini ýetip bilýäris we iňlisçe 2-nji gowy iňlisçe netijesi bilen ýetip bilýäris, ýöne diňe bir nusga ýok däldir.", 'af': "Die WMT Biomediese vertaling taak van 2020 het Medline abstrakte vertalings evalueer. Hierdie is 'n klein domein vertaling opdrag, beteken beperk relevante onderwerp data met baie uitdelike styl en woordeboek. Modelle wat op sodanige data onderwerp is, is aanvaardig na eksponering bias effekte, spesifieke wanneer oefening van sin paar is onvolledige vertalings van mekaar. Hierdie kan resultaat in arm gedrag tydens inferensie as die model leer om die bron seting te verwerp. Die UNICAM inskrywing adres hierdie probleem tydens fyn- tuning met gebruik van 'n kragtige variant op Minimum Risk Oefening. Ons kontras hierdie toegang met data- filtering om 'problem' onderwerp voorbeelde te verwyder. Ons kry goeie resultate vir beide rigtinge van Engels-Duits en Engels-Spaanse biomediese vertaling. In besonderhede het ons die beste resultaat van Engels-na-Spaanse vertaling en tweede beste Spaanse-na-Engels bereik, selfs net enkele modele gebruik met geen ensembling nie.", 'sq': "Detyra e përkthimit Biomjekësor WMT 2020 vlerësoi përkthimet abstrakte të Medline. Kjo është një detyrë përkthimi në një domeni të vogël, që do të thotë të dhëna të kufizuara të trajnimit me stil shumë të veçantë dhe fjalor. Modelet e stërvitura në të dhëna të tilla janë të ndjeshme për efektet e paragjykimit, veçanërisht kur çiftet e stërvitjes së fjalëve janë përkthime të papërkryera të njëri-tjetrit. Kjo mund të rezultojë në sjellje të dobët gjatë përfundimit nëse modeli mëson të harrojë fjalën e burimit. Hyrja e UNICAM-it trajton këtë problem gjatë rregullimit të mirë duke përdorur një variant të fortë për trajnimin e rrezikut minimal. Ne e kontrastojmë këtë qasje me filtrimin e të dhënave për të hequr shembujt e trajnimit `problem'. Sipas rregullimit të MRT ne marrim rezultate të mira për të dy drejtimet e përkthimit biomedik anglisht-gjerman dhe anglisht-spanjoll. Në veçanti ne arrijmë rezultatin më të mirë të përkthimit anglez-në-spanjoll dhe rezultatin më të mirë të dytë spanjoll-në-anglez, pavarësisht nga përdorimi i vetëm modeleve të vetme pa mbledhje.", 'am': "የ2020 WMT Biomedical ትርጉም ስራ የMedline abstract translation. ይሄ ትንሽ-domain ትርጉም ስራ ነው፣ ማለት በተለየ ልዩ ዓይነት እና vocabulary የተለየ ተማሪ ዳታ ነው፡፡ እንደነዚህ ዳታዎች የተማሩ ሞዴል የውይይት ጥያቄዎችን ለማሳየት የሚጠራጠሩ ናቸው፤ ይልቁንም የፍርድ ክፍል ሁለት እኩሌቶቹ እርስ በርሳቸው መተርጓሜ አይደሉም፡፡ ይህም ምሳሌው የኩነታችንን ፍርድ ለመውሰድ በተማረ ጊዜ ድሀ ድርጊት እንዲያገኝ ይችላል፡፡ የUNICAM ጥያቄ ይህን ጉዳይ በመጠቀም ጊዜ በመጠቀም ላይ የሮቦት variant በመጠቀም ላይ የሚያስጨምረው ነው፡፡ የ`ችግር'-ምርጫዎችን ለማስወገድ ዳታ-አጣራዎችን እናስቃርላለን፡፡ ከ MRT ጥሩ ድምፅ በታች እንግሊዝኛ-ጀርመን እና እንግሊዝኛ-ስፓኒሽ የbiomedical ትርጓሜ ወደሚገኘው ጥሩ ፍሬዎችን አግኝተናል፡፡ በተለይም እንግሊዘኛ-ወደ ስፓኒሽ-የፊደል ትርጓሜ እና ሁለተኛ የበለጠ ስፓኒሽ-ወደ እንግሊዘኛ ፍጻሜን አግኝተናል፡፡ ምንም እንኳን ብጤት ሳይኖር አንዲት ሞዴል ብቻ በመጠቀም እንችላለን፡፡", 'hy': '2020 թվականին ԱՄԹ Բիոբիոբժշկական թարգմանման խնդիրը գնահատեց Մեդլայնի վերացական թարգմանությունները: Սա փոքրիկ բնագավառների թարգմանման խնդիր է, ինչը նշանակում է սահմանափակ համապատասխան ուսուցման տվյալներ շատ տարբեր ոճով և բառարանով: Այսպիսի տվյալների վրա վարժեցված մոդելները զգալի են արտահայտության կողմնակի ազդեցությունների վրա, հատկապես երբ նախադասությունների զույգերի վարժեցման ժամանակ միմյանց անկատարյալ թարգմանություններ են: Սա կարող է հանգեցնել սխալ վարքագծի հետևանքի ընթացքում, եթե մոդելը սովորի անտեսել նախադասությունը: UNICAM-ի մուտքը լուծում է այս խնդիրը լավագույն հարմարեցման ժամանակ՝ օգտագործելով միմինիմալ ռիսկի վարժման ուժեղ տարբերակը: Մենք հակադրում ենք այս մոտեցումը տվյալների ֆիլտրման հետ, որպեսզի հեռացնենք «խնդիր» ուսումնասիրության օրինակները: ՄՌԹ-ի բարձրացման միջոցով մենք լավ արդյունքներ ենք ստանում անգլերեն-գերմաներեն և անգլերեն-իսպանական կենսաբժշկական թարգմանման երկու ուղղությունների համար: Մենք հատկապես հասնում ենք լավագույն անգլերեն-իսպաներեն թարգմանման արդյունքին և երկրորդ լավագույն իսպաներեն-անգլերեն թարգմանման արդյունքին, չնայած միայն մեկ մոդել օգտագործելուն առանց համակարգման:', 'bn': "২০২০ ডাব্লিউএমটি বায়োমিকাল অনুবাদের কাজের মাধ্যমে মিডিনের আবশ্যক অনুবাদের মূল্যায়ন করেছে। এটি একটি ছোট- ডোমেইন অনুবাদ কাজ, এর মানে সীমিত প্রশিক্ষণের তথ্য খুব বিশেষ ধরন এবং শব্দভাণ্ডারের সাথে সীমিত। এই ধরনের তথ্যে প্রশিক্ষিত মডেল বিভিন্ন প্রভাব প্রকাশ করার জন্য সন্দেহজনক, বিশেষ করে যখন শাস্তি প্রশিক্ষণ জোড়ার জোড়া একে অপরের অন যদি মডেলটি উৎসের বাক্য উপেক্ষা করতে শিখে থাকে তাহলে সংক্রান্ত বিপর্যয়ের সময় দুর্বল আচরণের ফলে তা হতে পারে। ইউনিসাম এন্ট্রি সর্বোচ্চ রাস্তা প্রশিক্ষণের সময় সুন্দর টানিং ব্যবহার করে এই সমস্যাটিকে ঠিক করেছে। 'সমস্যা' প্রশিক্ষণের উদাহরণ মুছে ফেলার জন্য ডাটা ফিল্টারিং দ্বারা আমরা এই পদ্ধতিকে তৈরি করি। এমআরটি ভালো টাইনিং এর নীচে আমরা ইংরেজি জার্মান এবং ইংরেজী স্প্যানিশ বায়োমেডিকেল অনুবাদের দুটো দিকেই ভাল ফলাফল পেয় বিশেষ করে আমরা সেরা ইংরেজি থেকে স্প্যানিশ ভাষায় অনুবাদের ফলাফল অর্জন করি এবং দ্বিতীয় স্প্যানিশ থেকে ইংরেজি ফলাফল, যদিও শুধুমাত্", 'bs': 'Zakon WMT biomedicinskog prevoda za 2020. procijenio je apstraktne prevode Medline. Ovo je zadatak za prevod malih domena, znači ograničeni relevantni podaci za obuku sa vrlo različitim stilom i riječnikom. Modeli obučeni na takvim podacima su osjetljivi na efekte predrasude izloženja, posebno kada su pare treninga nesavršene prevode jedni druge. To može rezultirati loše ponašanje tijekom infekcije ako model nauči da zanemari izvornu rečenicu. UniCAM ulazak rješava ovaj problem tijekom fino prilagođenja koristeći jaku varijantu na minimalnoj obuci rizika. Kontrastiramo ovaj pristup filtriranjem podataka kako bi uklonili primjere obuke "problema". Pod MRT-ovom finom prilagodbom dobijamo dobre rezultate za obe upute o biomedicinskom prevodu engleskog-njemačkog i engleskog-španjolskog jezika. Posebno postignemo najbolji rezultat prevođenja engleskog do španjolskog i drugi najbolji rezultat španjolskog do engleskog, uprkos korištenjem jedinih modela bez ensembliranja.', 'ca': 'La tasca de traducció biomèdica del WMT del 2020 va evaluar les traduccions abstractes de Medline. Això és una tasca de traducció de petit domini, que vol dir dades limitades de capacitació pertinents amb estil i vocabulari molt distints. Els models entrenats en aquestes dades són susceptibles a efectes prejudicials d\'exposició, sobretot quan les parelles de frases d\'entrenament són traduccions imperfectes entre elles. Això pot resultar en un comportament dolent durant la inferència si el model aprenen a ignorar la frase original. L\'entrada UNICAM aborda aquest problem a durant l\'ajustament fent servir una variant robusta d\'entrenament de risc mínim. Contrastem aquest enfocament amb la filtració de dades per eliminar exemples d\'entrenament "problema". Sobre l\'ajustament MRT obtenim bons resultats per ambdues direccions de traducció biomèdica anglès-alemanya i anglès-espanyol. En particular, aconsegueixem el millor resultat de traducció anglès-espanyol i el segon resultat d\'espanyol-anglès, malgrat utilitzar només models senza conjunt.', 'az': "2020-ci WMT Biomedical tercümə işləri Medline abstrakt tercümələrini değerləşdirdi. Bu, kiçik-domena tercümə işləridir. Bu, çox müxtəlif təhsil və sözlər ilə müəyyən edilən təhsil məlumatları anlamına gəlir. Bütün məlumatlarda təhsil edilən modellər təhsil edilən bias effektlərini göstərməyə müvəffəqidir, özlərinə də cümlələrin çift təhsil edilməsi birbirlərinin tamamilə təhsil edilməsi mümkün deyildir. Əgər modellər mənbə cümləsini unutmaq öyrənsə, böyük davranışların başına gələ bilər. UNICAM girişi bu problemi minimal Risk Training istifadəsində möhkəm dəyişiklik vasitəsilə düzəltdi. Biz bu metodları 'problem' təhsil örnəklərini silmək üçün verilən filtrləmə ilə dəyişdiririk. MRT təmizlənməsi altında İngilizce-Alman və İngilizce-İspanyol biomedical tercüməsinin hər ikisi üçün yaxşı sonuçlar alırıq. Özellikle biz İngilizə-İspanyola çevirilən ən yaxşı nəticəsini və ikinci-yaxşı İspanyola-İngilizə nəticəsini tapırıq, yalnız bir modeli istifadə etməyə rağmen.", 'cs': 'Úkol 2020 WMT Biomedicínský překlad hodnotil abstraktní překlady Medline. Jedná se o malou doménu překladu úkolů, což znamená omezené relevantní tréninkové údaje s velmi odlišným stylem a slovní zásobou. Modely trénované na těchto datech jsou náchylné k efektům expozice bias, zejména když tréninkové páry vět jsou nedokonalé překlady jednoho druhého. To může mít za následek špatné chování během inference, pokud se model naučí zanedbávat zdrojovou větu. Položka UNICAM řeší tento problém během jemného ladění pomocí robustní varianty na tréninku minimálního rizika. Tento přístup kontrastujeme s filtrováním dat, abychom odstranili příklady školení problémů. V rámci MRT jemného ladění dosahujeme dobrých výsledků pro obě směry anglicko-německého a anglicko-španělského biomedicínského překladu. Zejména dosahujeme nejlepšího výsledku překladu z angličtiny do španělštiny a druhého nejlepšího výsledku z angličtiny do angličtiny, i když používáme pouze jednotlivé modely bez souboru.', 'et': '2020. aasta WMT Biomeditsiinilise tõlke ülesandel hinnati Medline abstraktseid tõlkeid. See on väikese domeeniga tõlketöö, mis tähendab piiratud asjakohaseid koolitusandmeid väga erineva stiili ja sõnavaraga. Selliste andmete põhjal koolitatud mudelid on vastuvõtlikud kokkupuute kallutamisele, eriti kui treeninglausepaarid on üksteise ebatäiuslikud tõlged. See võib põhjustada halva käitumise järelduse ajal, kui mudel õpib lähtelauset eirama. UNICAMi kirjes käsitletakse seda probleemi peenhäälestuse ajal, kasutades minimaalse riski koolituse tugevat varianti. Me võrdleme seda lähenemisviisi andmete filtreerimisega, et eemaldada probleemsed koolitusnäited. MRT täpsustamise käigus saame head tulemused nii inglise-saksa kui inglise-hispaania biomeditsiinilise tõlke mõlemas suunas. Eelkõige saavutame parima inglise-hispaania tõlketulemuse ja teise parima hispaania-inglise tulemuse, vaatamata sellele, et kasutame ainult üksikuid mudeleid ilma ansambliteta.', 'fi': 'Vuoden 2020 WMT Biomedical -k채채nn철sty철ss채 arvioitiin Medline-abstraktik채채nn철ksi채. T채m채 on pieni k채채nn철steht채v채, joka tarkoittaa rajallista asiaankuuluvaa koulutustietoa, jossa on hyvin erilainen tyyli ja sanasto. T채llaisten tietojen perusteella koulutetut mallit ovat alttiita altistumisen v채채ristymiselle erityisesti silloin, kun harjoituslauseparit ovat ep채t채ydellisi채 toistensa k채채nn철ksi채. T채m채 voi johtaa huonoon k채ytt채ytymiseen p채채ttelyn aikana, jos malli oppii laiminly철m채채n l채hdelauseen. UNICAM-merkint채 k채sittelee t채t채 ongelmaa hienos채채t철jen aikana k채ytt채m채ll채 vankkaa versiota minimiriskin koulutuksesta. T채t채 l채hestymistapaa verrataan datan suodatukseen, jotta voidaan poistaa ongelmakoulutusesimerkkej채. MRT-hienos채채d철ll채 saamme hyvi채 tuloksia molempiin suuntiin englanti-saksa ja englanti-espanja biol채채ketieteellinen k채채nn철s. Erityisesti saavutamme parhaan englannin-espanjan k채채nn철stuloksen ja toiseksi parhaan espanjan-englannin tuloksen, vaikka k채yt채mme vain yksitt채isi채 malleja ilman kokoonpanoa.', 'jv': "Tambah 2020 WWT Biwotan Terjamahan sing berarti medline kang tarjamahan. This is a small-domain translation task, means limited maneh Digawe Masukan UNIKAM kang diputamong perbudhakan iki ning njon-njon iki bakal ngulinakake variant apa-perbudhakan kanggo minimum Rik Learning. text-tool-action Dhewe iso nggambar luwih-luwih pisan MRT lan kelas kuwi padha pawaran gambar kanggo tarjamahan ingles-German karo Spanyol-Spanish. Juk-Juk'eng sampeyan awak dhéwé kuwi duluran pangan Inggris-karo Spanyala kuwi padha sing luwih apik lan kabèh dumateng pancen karo inggris, sane kuwi jenis model sing beraksi ora tau ngono ngregani.", 'ha': "@ info: whatsthis Wannan wani aikin fassarar-Domen mai ƙarami ne, yana madaidaita da tsaro masu hushi da kuma tsari mai girma. Models trained on such data are susceptible to exposure bias effects, particularly when training sentence pairs are imperfect translations of each other.  Wannan yana iya ƙara wa aikin matalauci a lokacin da za'a zartar da shi idan an sanar da misalin ayuka ya manta. @ info: whatsthis Munã tsohatar da wannan hanyor da filtering ɗin da za'a tafiyar da misãlai masu amfani da 'matalauci'. Under MRT-tuning, we get the best matsayi for both direction of Ingiriya-Jarman da Ingiriya-spanish biblical. Kuma da ƙayyadadde, muna sãmun fassarar fassarar Ingiriya-zuwa-spanish da fassarar-na'ura ta sauki-zuwa-Ingiriya, kuma kõ da ya yi amfani da misãlai guda kawai, ba da wani faniki.", 'sk': 'Prevajalska naloga WMT Biomedicine 2020 je ocenila Medlineove prevode povzetkov. To je prevajalska naloga z majhnimi domenami, kar pomeni omejene ustrezne podatke o usposabljanju z zelo različnim slogom in besediščem. Modeli, usposobljeni na podlagi takih podatkov, so dovzetni za učinke pristranskosti izpostavljenosti, zlasti kadar so pari vadbenih stavkov nepopolni prevodi med seboj. To lahko povzroči slabo vedenje med sklepanjem, če se model nauči zanemarjati izvorni stavek. Vnos UNICAM obravnava to težavo med finim uravnavanjem z uporabo robustne različice usposabljanja za minimalno tveganje. Ta pristop nasprotujemo s filtriranjem podatkov za odstranitev primerov usposabljanja s problemi. V okviru finega uravnavanja MRT dobimo dobre rezultate za obe smeri angleško-nemškega in angleško-španskega biomedicinskega prevoda. Zlasti dosegamo najboljši rezultat prevodov angleščine v španščino in drugi najboljši rezultat španščine v angleščino, kljub uporabi samo posameznih modelov brez ansambla.', 'he': 'משימת התרגום ביורפואית של WMT 2020 הערכה את התרגומות המתוספות של Medline. This is a small-domain translation task, meaning limited relevant training data with very distinct style and vocabulary.  דוגמנים מאומנים על נתונים כאלה הם רגישים להשפעות חיסוי, במיוחד כשזוגות משפטים מאימנים הם תרגומות לא מושלמות אחד לשני. זה יכול לגרום להתנהגות גרועה במהלך המסקנה אם המודל לומד להזנח את המשפט המקורי. הכניסה של UNICAM מתייחסת לבעיה הזאת במהלך התרגיל מתאים בשימוש שונה חזקה על אימון סיכון מינימי. אנו שונים את הגישה הזאת עם מסנן נתונים כדי להסיר דוגמאות אימונים של "בעיה". תחת התרגיל MRT אנחנו מקבלים תוצאות טובות לשני הכיוונים של התרגיל ביו-רפואי אנגלי-גרמני ואנגלי-ספרדי. במיוחד אנחנו משיגים את תוצאה הטובה ביותר של התרגום אנגלי-לספרדית והתוצאה השנייה הטובה ביותר של הספרדית-לאנגלית, למרות השימוש בדוגמנים בודדים בלבד ללא סמל.', 'bo': '2020 WMT Biomedical translation task evaluated Medline abstract translations. This is a small-domain translation task, meaning limited relevant training data with very distinct style and vocabulary. གཟུགས་རིས་འདིའི་ནང་གི་མིག་གཟུགས་རིས་ལ་རང་ཉིད་ཀྱི་དབྱེ་རིགས་ཡོད་པས། གལ་སྲིད། འདིས་རྣམ་པ་ནང་གི་མ་དབྱིབས་འགྱུར་བའི་སྐབས་ལྟར་ཉེན་ངང་བྱེད་དགོས། UNICAM འཇུག་སྣོད་ནང་དུ་ཆུང་ཆུང་བའི་རྐྱེན་སྒྲིག་ནང་དུ་བློ་གཏོང་བའི་དཀའ་ངལ་འདི་ལྟ་བུ་གཏོང་བ ང་ཚོས་རང་ཉིད་ཀྱི་གནད་སྤེལ་བྱ་ཚིག་དང་མཉམ་ལས་རྟགས་བཀལ་ངལ། MRT ལྟ་བུའི་ནང་དུ་འུ་ཅག་གིས་དབྱིན་ཡིག་དང་སྐར་ཡིག་དང་སྐར་ཡིག་གི་biomedical སྤྱི་ཚོགས་ཀྱི་གནད་དོན་གཉིས་ལས་དགའ ངེད་ཚོས་ཁྱད་པར་ངེད་ཚོའི་དབྱིན་ཡིག་ལས་སྐད་རིགས་ཤིག་ཚད་མང་ཤོས་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Unbabel’s Participation in the WMT20 Metrics Shared Task', 'fr': "Participation d'Unbabel à la tâche partagée WMT20 Metrics", 'pt': 'Participação da Unbabel na Tarefa Partilhada de Métricas WMT20', 'es': 'Participación de Unbabel en la tarea compartida de métricas de WMT20', 'ar': 'مشاركة Unbabel في مهمة مقاييس WMT20 المشتركة', 'ja': 'UnbabelのWMT 20メトリクス共有タスクへの参加', 'zh': 'Unbabel 与 WMT20 指标共事', 'ru': 'Участие Unbabel в совместном задании по метрикам WMT20', 'hi': 'WMT20 मैट्रिक्स साझा कार्य में अनबेबल की भागीदारी', 'ga': 'Rannpháirtíocht Unbabel i dTasc Comhroinnte Méadracht WMT20', 'el': 'Συμμετοχή του Unbabel στην κοινή εργασία μετρήσεων WMT20', 'ka': 'WMT20 მეტრიკის გაყოფილი საქმე', 'hu': 'Unbabel részvétele a WMT20 Metrics megosztott feladatban', 'it': 'La partecipazione di Unbabel al compito condiviso WMT20 Metrics', 'lt': 'Unbabel dalyvavimas WMT20 metro bendroje užduotyje', 'mk': "Unbabel's Participation in the WMT20 Metrics Shared Task", 'ms': "Unbabel's Participation in the WMT20 Metrics Shared Task", 'kk': 'WMT20 метрикалық ортақтастырылған тапсырманың қатысуы', 'mn': "Unbabel's Participation in the WMT20 Metrics Shared Task", 'mt': "Il-Parteċipazzjoni ta' Unbabel fil-Kompitu Konġunt tal-Metriki tad-WMT20", 'no': 'Unbabel- deltakaren i WMT20- metriske delt oppgåve', 'ml': 'WMT20 മെറ്റിക്സ് പങ്കെടുത്ത ജോലിയില്\u200d ഉന്\u200dബാബേലിന്\u200dറെ പങ്കാളി', 'ro': 'Participarea Unbabel la activitatea partajată WMT20 Metrics', 'pl': 'Uczestnictwo Unbabel w wspólnym zadaniu metryków WMT20', 'sv': 'Unbabels deltagande i WMT20 Metrics delade uppgift', 'so': "Unbabel's Participation in the WMT20 Metrics Shared Task", 'ta': "WMT20 மெட்ரிக்ஸ் பகிர்ந்த பணியில் Unbabel's participation", 'ur': 'WMT20 متریک شریک ٹاکس میں غیر بابل کا حصہ', 'sr': 'Unbabelovo učestvovanje u delu WMT20 metrika', 'si': 'WMT20 මෙට්\u200dරික්ස් සමාගත වැඩේ අන්බාබෙල්ගේ භාගයක්', 'uz': 'Name', 'vi': 'Không người định tham gia vào công việc chia s ẻ WM Metrics', 'nl': 'Deelname van Unbabel aan de WMT20 Metrics Shared Task', 'bg': 'Участието на Унбабел в споделената задача по метриците на WMT20', 'de': 'Die Teilnahme von Unbabel an der gemeinsamen Aufgabe WMT20 Metrics', 'da': 'Unbabels deltagelse i WMT20 Metrics delte opgave', 'hr': 'Unbabelovo učestvovanje u podjelnom zadatku WMT20 metrika', 'sw': 'Ushiriki wa Unbabel katika mbinu za WMT20', 'ko': 'WMT20 지표 공유 작업에 Unbabel 참여', 'af': 'Onbabel se Deelnadering in die WMT20 metries Gedeelde Opdrag', 'fa': 'شرکت نابابل در کار مشترک WMT20 متریک', 'sq': "Unbabel's Participation in the WMT20 Metrics Shared Task", 'am': "Unbabel's Participation in WMT20 Metrics Shared Task", 'tr': 'WMT20 metrikler Paýlaşmış Görevde Beýik Gaýşartmaky', 'id': "Unbabel's Participation in the WMT20 Metrics Shared Task", 'hy': 'Ումբաբելի մասնակցությունը', 'bn': 'উইএমটি২০ মেট্রিক শেয়ার কর্মসূচিতে আনবেলের অংশগ্রহণ', 'cs': 'Unbabelova účast na sdíleném úkolu metrik WMT20', 'az': 'WMT20 metrik paylaşılmış işlərdə Bütün Bölümlər', 'et': 'Unbabeli osalemine WMT20 meetrite jagatud ülesandes', 'fi': 'Unbabelin osallistuminen WMT20 Metrics Shared Task -ohjelmaan', 'bs': 'Unbabelovo učestvovanje u delu WMT20 metrika', 'ca': "La participació d'Unbabel a la tasca compartida de la WMT20 Metrics", 'jv': 'Ngubah Jejaring Unbabel ning barêng-barêng WWT 2 Metric', 'ha': '@ action', 'sk': 'Udeležba Unbabel v skupni nalogi meril WMT20', 'he': 'השתתפות של אונבאבל במשימה המשותפת של WMT20', 'bo': "Unbabel's Participation in the WMT20 Metrics Shared Task"}
{'en': 'We present the contribution of the Unbabel team to the WMT 2020 Shared Task on Metrics. We intend to participate on the segmentlevel, document-level and system-level tracks on all language pairs, as well as the QE as a Metric track. Accordingly, we illustrate results of our models in these tracks with reference to test sets from the previous year. Our submissions build upon the recently proposed COMET framework : we train several estimator models to regress on different humangenerated quality scores and a novel ranking model trained on relative ranks obtained from Direct Assessments. We also propose a simple technique for converting segment-level predictions into a document-level score. Overall, our systems achieve strong results for all language pairs on previous test sets and in many cases set a new state-of-the-art.', 'ar': 'نقدم مساهمة فريق Unbabel في مهمة WMT 2020 المشتركة حول المقاييس. نعتزم المشاركة على مستوى المقطع ومستوى المستند والمسارات على مستوى النظام على جميع أزواج اللغات ، بالإضافة إلى مسار "QE as a Metric". وفقًا لذلك ، نوضح نتائج نماذجنا في هذه المسارات بالإشارة إلى مجموعات الاختبار من العام السابق. تعتمد تقديماتنا على إطار عمل COMET المقترح مؤخرًا: نقوم بتدريب عدة نماذج مقدر للتراجع عن درجات جودة مختلفة مأخوذة من الإنسان ونموذج تصنيف جديد تم تدريبه على الرتب النسبية التي تم الحصول عليها من التقييمات المباشرة. نقترح أيضًا أسلوبًا بسيطًا لتحويل التنبؤات على مستوى القطاع إلى درجة على مستوى المستند. بشكل عام ، تحقق أنظمتنا نتائج قوية لجميع الأزواج اللغوية في مجموعات الاختبار السابقة وفي كثير من الحالات تحدد حالة جديدة من الفن.', 'fr': "Nous présentons la contribution de l'équipe Unbabel à la tâche partagée WMT 2020 sur les métriques. Nous avons l'intention de participer aux filières au niveau du segment, du document et du système pour toutes les paires de langues, ainsi qu'au volet «\xa0QE as a Metric\xa0». En conséquence, nous illustrons les résultats de nos modèles sur ces pistes en référence à des ensembles de tests de l'année précédente. Nos soumissions s'appuient sur le cadre COMET récemment proposé\xa0: nous entraînons plusieurs modèles d'estimateurs à régresser sur différents scores de qualité générés par l'homme et un nouveau modèle de classement formé sur des classements relatifs obtenus à partir d'évaluations directes. Nous proposons également une technique simple pour convertir les prédictions au niveau du segment en une note au niveau du document. Dans l'ensemble, nos systèmes obtiennent de bons résultats pour toutes les paires de langues lors des tests précédents et, dans de nombreux cas, établissent une nouvelle technologie de pointe.", 'es': 'Presentamos la contribución del equipo de Unbabel a la Tarea Compartida sobre Métricas del WMT 2020. Tenemos la intención de participar en los cursos a nivel de segmento, de documento y de sistema en todos los pares de idiomas, así como en el de «QE as a Metric». En consecuencia, ilustramos los resultados de nuestros modelos en estas pistas con referencia a los conjuntos de pruebas del año anterior. Nuestras presentaciones se basan en el marco COMET propuesto recientemente: capacitamos varios modelos de estimadores para que retrocedan en diferentes puntuaciones de calidad generadas por humanos y un nuevo modelo de clasificación entrenado en rangos relativos obtenidos de evaluaciones directas. También proponemos una técnica sencilla para convertir las predicciones a nivel de segmento en una puntuación a nivel de documento. En general, nuestros sistemas logran resultados sólidos para todas las combinaciones de idiomas en series de pruebas anteriores y, en muchos casos, establecen un nuevo estado de la técnica.', 'pt': 'Apresentamos o contributo da equipa da Unbabel para a Tarefa Partilhada de Métricas do WMT 2020. Pretendemos participar das trilhas em nível de segmento, nível de documento e nível de sistema em todos os pares de idiomas, bem como na trilha “QE as a Metric”. Assim, ilustramos os resultados de nossos modelos nessas faixas com referência aos conjuntos de teste do ano anterior. Nossas submissões se baseiam na estrutura COMET recentemente proposta: treinamos vários modelos de estimadores para regredir em diferentes pontuações de qualidade geradas por humanos e um novo modelo de classificação treinado em classificações relativas obtidas de Avaliações Diretas. Também propomos uma técnica simples para converter previsões em nível de segmento em uma pontuação em nível de documento. No geral, nossos sistemas alcançam resultados fortes para todos os pares de idiomas em conjuntos de testes anteriores e, em muitos casos, estabelecem um novo estado da arte.', 'ja': '私たちは、メトリクスに関するWMT 2020共有タスクへのUnbabelチームの貢献を提示します。すべての言語ペアのセグメントレベル、文書レベル、システムレベルのトラック、および「メトリックとしてのQE」トラックに参加するつもりです。そこで，前年度の試験器を参考に，これらの実績をモデル化した。私たちの提出物は、最近提案されたCOMETフレームワークに基づいています。私たちは、人間が生成したさまざまな品質スコアに回帰するためにいくつかの推定モデルをトレーニングし、直接評価から得られた相対的なランクに基づいてトレーニングされた新しいランキングモデルをトレーニングします。また、セグメントレベルの予測を文書レベルのスコアに変換する簡単な手法も提案します。全体的に、当社のシステムは、以前のテストセットのすべての言語ペアで優れた結果を達成し、多くの場合、新しい最先端を設定します。', 'hi': 'हम मीट्रिक पर WMT 2020 साझा कार्य के लिए अनबाबेल टीम के योगदान को प्रस्तुत करते हैं। हम सभी भाषा जोड़े पर सेगमेंट स्तर, दस्तावेज़-स्तर और सिस्टम-स्तर के पटरियों के साथ-साथ "एक मीट्रिक के रूप में क्यूई" ट्रैक पर भाग लेने का इरादा रखते हैं। तदनुसार, हम पिछले वर्ष से परीक्षण सेट के संदर्भ में इन पटरियों में हमारे मॉडल के परिणामों को चित्रित करते हैं। हमारी प्रस्तुतियां हाल ही में प्रस्तावित धूमकेतु ढांचे पर निर्माण करती हैं: हम विभिन्न मानवजनित गुणवत्ता स्कोर और प्रत्यक्ष मूल्यांकन से प्राप्त सापेक्ष रैंकों पर प्रशिक्षित एक उपन्यास रैंकिंग मॉडल पर पीछे हटने के लिए कई अनुमानक मॉडल को प्रशिक्षित करते हैं। हम सेगमेंट-स्तर की भविष्यवाणियों को दस्तावेज़-स्तर के स्कोर में परिवर्तित करने के लिए एक सरल तकनीक का भी प्रस्ताव करते हैं। कुल मिलाकर, हमारे सिस्टम पिछले परीक्षण सेट पर सभी भाषा जोड़े के लिए मजबूत परिणाम प्राप्त करते हैं और कई मामलों में एक नया अत्याधुनिक सेट करते हैं।', 'zh': '吾言 Unbabel 团队 WMT 2020 指标共功。 欲与诸语言细分级、文档级、系统等踵之,及"QE 为指标"踵之。 是以参考前岁之试集来以明其模范之效也。 臣等提交基于近COMET框架:我等练了几个度量器模形,以在不同的人生质量分数上倒退,并据直评得的对排名训练一种新排名模形。 又立细分级转换为文档分数之术。 总体而言,吾统以前试集上为一切言语皆得其效,而设新语于众。', 'ru': 'Мы представляем вклад команды Unbabel в совместное задание WMT 2020 по метрикам. Мы намерены участвовать на сегментном, документарном и системном треках по всем языковым парам, а также на треке «QE как метрика». Соответственно, мы иллюстрируем результаты наших моделей на этих треках со ссылкой на тестовые наборы за предыдущий год. Наши представления основаны на недавно предложенной структуре КОМЕТ: мы обучаем несколько моделей оценки, чтобы регрессировать на различных человеческих оценках качества и новой модели ранжирования, обученной на относительных рангах, полученных из прямых оценок. Мы также предлагаем простую методику преобразования прогнозов на уровне сегмента в оценку на уровне документа. В целом, наши системы достигают сильных результатов для всех языковых пар на предыдущих тестовых наборах и во многих случаях устанавливают новый современный уровень.', 'ga': 'Cuirimid i láthair rannchuidiú fhoireann Unbabel le Tasc Comhroinnte WMT 2020 ar Mhéadracht. Tá sé ar intinn againn a bheith rannpháirteach ar na rianta ar leibhéal deighleogach, ar leibhéal doiciméad agus ar leibhéal córais ar na péirí teangacha go léir, chomh maith leis an rian “QE as a Metric”. Dá réir sin, léirímid torthaí ár samhlacha sna rianta seo agus tagairt á déanamh againn do thacair tástála ón mbliain roimhe sin. Tógann ár n-aighneachtaí ar an gcreat COMET a moladh le déanaí: cuirimid oiliúint ar roinnt samhlacha meastóirí chun cúlú ar scóir cháilíochta éagsúla ginte ag an duine agus múnla rangaithe nua atá oilte ar na céimeanna coibhneasta a fhaightear ó Mheasúnuithe Díreacha. Molaimid freisin teicníocht shimplí chun tuar ar leibhéal na míre a thiontú ina scór ar leibhéal na doiciméid. Tríd is tríd, baineann ár gcórais torthaí láidre amach do na péirí teanga go léir ar thacair trialacha roimhe seo agus i go leor cásanna socraítear staid nua-aimseartha.', 'el': 'Παρουσιάζουμε τη συνεισφορά της ομάδας στην Κοινή Εργασία Μετρικών του WMT 2020. Σκοπεύουμε να συμμετάσχουμε σε κομμάτια σε επίπεδο τμήματος, σε επίπεδο εγγράφου και σε επίπεδο συστήματος σε όλα τα γλωσσικά ζεύγη, καθώς και στο κομμάτι "QE as a Metric". Ως εκ τούτου, απεικονίζουμε τα αποτελέσματα των μοντέλων μας σε αυτές τις διαδρομές με αναφορά σε σετ δοκιμών από το προηγούμενο έτος. Οι υποβολές μας βασίζονται στο πρόσφατα προτεινόμενο πλαίσιο COMET: εκπαιδεύουμε διάφορα μοντέλα εκτιμήσεων για να αναδρομούν σε διαφορετικές βαθμολογίες ποιότητας που παράγονται από τον άνθρωπο και ένα νέο μοντέλο κατάταξης εκπαιδευμένο σε σχετικές τάξεις που λαμβάνονται από Άμεσες Αξιολογήσεις. Προτείνουμε επίσης μια απλή τεχνική για τη μετατροπή προβλέψεων σε επίπεδο τμήματος σε βαθμολογία σε επίπεδο εγγράφου. Συνολικά, τα συστήματά μας επιτυγχάνουν ισχυρά αποτελέσματα για όλα τα γλωσσικά ζεύγη σε προηγούμενα σετ δοκιμών και σε πολλές περιπτώσεις θέτουν μια νέα κατάσταση τεχνολογίας.', 'hu': 'Bemutatjuk az Unbabel csapat hozzájárulását a WMT 2020 Shared Task on Metrics-hez. Szegmensszintű, dokumentumszintű és rendszerszintű sávokon kívánunk részt venni minden nyelvpáron, valamint a "QE as a Metric" sávon. Ennek megfelelően modelleink eredményeit az előző évi tesztkészletekkel illusztráljuk. Jelentkezéseink a nemrégiben javasolt COMET keretrendszerre épülnek: több becslőmodellt képzünk ki a különböző humán által generált minőségi pontszámok visszaesésére, valamint egy új rangsorolási modellt képzünk a Direct Assessments relatív rangsorokra. Javasoljuk továbbá egy egyszerű technikát a szegmensszintű előrejelzések dokumentum szintű pontszámmá történő átalakítására. Összességében rendszereink erős eredményeket érnek el az összes nyelvpár tekintetében a korábbi tesztkészleteken, és sok esetben új korszerűséget állítanak elő.', 'it': 'Presentiamo il contributo del team Unbabel al WMT 2020 Shared Task on Metrics. Intendiamo partecipare alle tracce a livello di segmentazione, documento e sistema su tutte le coppie linguistiche, nonché alla traccia "QE as a Metric". Di conseguenza, illustreremo i risultati dei nostri modelli in queste piste con riferimento ai set di prova dell\'anno precedente. Le nostre proposte si basano sul framework COMET recentemente proposto: formiamo diversi modelli di stimatori per regredire su diversi punteggi di qualità generati dall\'uomo e un nuovo modello di ranking addestrato sui ranghi relativi ottenuti da valutazioni dirette. Proponiamo anche una semplice tecnica per convertire le previsioni a livello di segmento in un punteggio a livello di documento. Nel complesso, i nostri sistemi raggiungono risultati forti per tutte le coppie linguistiche sui set di test precedenti e in molti casi impostano un nuovo stato dell\'arte.', 'ka': "ჩვენ Unbabel ჯგუფის დამატებით მეტრიკის WMT 2020-ის საზოგადომი საქმე. ჩვენ მინდომენობით, რომ მოთავსდებით სეგმენტის დოკუმენტის დოკუმენტის და სისტემის დოკუმენტის სიტყვის ყველა ენახის ზოგების, და 'QE როგორც მეტრიკის' სი ამიტომ, ჩვენ მოდელების შედეგების ჩვენი მოდელების შედეგების გამოყენება წინ წლის შედეგების გამოყენება. ჩვენი მომხმარებები ახლა მხოლოდ გამოყენებული COMET ფრამეტრის შესახებ: ჩვენ განვიწყებთ რამდენიმე მოდელები, რომლებიც განსხვავებული ადამიანისთვის კალგატიური წერტილებზე და პრომენტის რენგრენტის მოდელ ჩვენ ასევე უფრო მარტივი ტექნოგია, რომელიც წარმოდგენების წარმოდგენების წარმოდგენისთვის დოკუმენტის წარმოდგენისთვის. ჩვენი სისტემები ყველა ენის ზოგებისთვის ძალიან შესაძლებლობების შესაძლებლობა წინასწარმოდგენა წინასწარმოდგენა ტესტის ზოგებისთვის და მრავალში შესაძლებლობ", 'kk': "Біз Unbabel тобының WMT 2020 метрикалық ортақ тапсырмасына қатынасын таңдаймыз. Біз сегмент деңгейінде, құжат деңгейінде жүйелік деңгейінде және жүйелік деңгейіндегі жолдарда, және 'QE - метрикалық' жолдарында қатысу керек. Сондықтан бұл жолдарда моделдердің нәтижесін өткен жылдан сынақтар жиындарының сілтемесімен көрсетеді. Біздің келтірімдеріміз жаңа келтірілген COMET фрейміне қолданылады: біз бірнеше бағалау үлгілерін әртүрлі адамдардың сапатты нәтижелеріне қайта қайта қарау үшін және тікелей оқиғалардан алған қатынастық жолд Біз сондай-ақ сегменттің деңгейінің алдын- ала құжаттың деңгейінің нәтижесіне аудару үшін қарапайым техникасын ұсынамыз. Барлық жүйелеріміз алдыңғы сынақтағы тіл екеуінің күшті нәтижелерін жеткізеді. Көпшілігінде жаңа орындау күйін орнату.", 'ml': 'ഞങ്ങള്\u200d ആന്\u200dബാബേല്\u200d ടീമിലെ പങ്ക് മെട്രിക്സില്\u200d 2020 ഷേര്\u200dഡ് ടാസ്കിലേക്ക് കൊടുക്കുന്നു. എല്ലാ ഭാഷയുടെയും ജോടികളുടെയും മെറ്റ്രിക്കിന്റെയും ട്രാക്കില്\u200d നമുക്ക് സെഗ്മെന്\u200dറ് നില, രേഖയുടെ നില, സിസ്റ്റത്തിലെ നി അതുകൊണ്ട്, നമ്മുടെ മോഡലുകളുടെ ഫലങ്ങള്\u200d ഈ ട്രാക്കുകളില്\u200d വെളിപ്പെടുത്തുന്നു. കഴിഞ്ഞ വര്\u200dഷം മുതല്\u200d പരീക്ഷിക്കാ നമ്മുടെ അടുത്തുള്ള പ്രായശ്ചിത്ത കൊമെറ്റ് ഫ്രെയിമെക്കില്\u200d നമ്മുടെ സമ്മാനങ്ങള്\u200d പണിയുന്നു: നേരിട്ടുള്ള ആസ്റ്റിമെറ്റര്\u200d മോഡലുകളില്\u200d നാം വ്യത ഒരു രേഖയുടെ നില സ്കോര്\u200dട്ടിലേക്ക് പ്രവചനങ്ങള്\u200d മാറ്റുന്നതിന് ഞങ്ങള്\u200d ഒരു സാധാരണ ടെക്കെന്റിക്ക് പ്രൊദ്ദ മൊത്തം, മുമ്പുള്ള പരീക്ഷണസെറ്റില്\u200d എല്ലാ ഭാഷകള്\u200dക്കും ശക്തമായ ഫലങ്ങള്\u200d നമ്മുടെ സിസ്റ്റമുണ്ടാക്കുന്നു. പല കാര്യങ്', 'mk': 'Го претставуваме придонесот на тимот на Унбабел за заедничката задача на ВМТ 2020 за метрика. Ние имаме намера да учествуваме на сегментарното ниво, на документното ниво и на системското ниво на сите јазички парови, како и на песната „QE како метрика“. Според тоа, ги илустрираме резултатите на нашите модели на овие траги со референција на тестовите од претходната година. Our submissions build upon the recently proposed COMET framework: we train several estimator models to regress on different humangenerated quality scores and a novel ranking model trained on relative ranks obtained from Direct Assessments.  Ние, исто така, предложуваме едноставна техника за претворање на предвидувања на ниво на сегменти во резултат на ниво на документ. Вкупно, нашите системи постигнуваат силни резултати за сите јазички парови на претходните тестови и во многу случаи постигнуваат нова современа состојба.', 'lt': 'We present the contribution of the Unbabel team to the WMT 2020 Shared Task on Metrics.  Mes ketiname dalyvauti visų kalbų porų segmentų, dokumentų ir sistemų lygio takeliuose, taip pat "QE kaip metro" takeliuose. Atitinkamai parodomi mūsų modelių rezultatai šiuose keliuose, atsižvelgiant į praėjusių metų bandymų rinkinius. Mūsų pasiūlymai grindžiami neseniai pasiūlyta COMET sistema: mes rengiame keletą vertinimo modelių, skirtų susigrįžti prie skirtingų žmogaus sukurtų kokybės rezultatų, ir naują vertinimo model į, parengtą santykinėmis eilutėmis, gautomis iš tiesioginių vertinimų. We also propose a simple technique for converting segment-level predictions into a document-level score.  Apskritai, mūsų sistemose pasiekti tvirti rezultatai visoms kalbų poroms ankstesniuose bandymų rinkiniuose ir daugeliu atvejų nustatoma nauja pažanga.', 'ms': "We present the contribution of the Unbabel team to the WMT 2020 Shared Task on Metrics.  We intend to participate on the segmentlevel, document-level and system-level tracks on all language pairs, as well as the 'QE as a Metric' track.  Oleh sebab itu, kami memperlihatkan keputusan model kami dalam trek ini dengan rujukan kepada set ujian dari tahun lepas. Pemberian kami membina pada kerangka COMET yang telah diusulkan baru-baru ini: kami melatih beberapa model penghargaan untuk mengembalikan pada skor kualiti manusia yang berbeza dan model peringkat baru dilatih pada peringkat relatif yang diperoleh dari penilaian langsung. Kami juga melamar teknik sederhana untuk mengubah ramalan aras segmen ke skor aras dokumen. Secara keseluruhan, sistem kita mencapai keputusan yang kuat untuk semua pasangan bahasa pada set ujian sebelumnya dan dalam banyak kes menetapkan keadaan baru.", 'pl': 'Przedstawiamy wkład zespołu Unbabel w WMT 2020 Shared Task on Metrics. Zamierzamy uczestniczyć w ścieżkach segmentowych, dokumentowych i systemowych na wszystkich parach językowych, a także w ścieżce "QE as a Metric". W związku z tym na tych torach ilustrujemy wyniki naszych modeli w odniesieniu do zestawów testowych z poprzedniego roku. Nasze zgłoszenia opierają się na niedawno zaproponowanym frameworku COMET: szkolimy kilka modeli szacujących do regresji na różnych wynikach jakości generowanych przez człowieka oraz nowy model rankingu przeszkolony na względnych rangach uzyskanych z bezpośrednich ocen. Proponujemy również prostą technikę konwersji przewidywań na poziomie segmentów na wynik na poziomie dokumentu. Ogólnie rzecz biorąc, nasze systemy osiągają silne wyniki dla wszystkich par językowych na poprzednich zestawach testowych i w wielu przypadkach ustalają nowy state-of-the-art.', 'mt': "Aħna nippreżentaw il-kontribut tat-tim Unbabel għall-Kompitu Konġunt dwar il-Metriks tad-WMT 2020. We intend to participate on the segmentlevel, document-level and system-level tracks on all language pairs, as well as the 'QE as a Metric' track.  Għaldaqstant, nagħmlu xhieda tar-riżultati tal-mudelli tagħna f’dawn il-binarji b’referenza għas-settijiet tat-testijiet tas-sena preċedenti. Is-sottomissjonijiet tagħna jibnu fuq il-qafas COMET propost reċentement: a ħna nħarrġu bosta mudelli ta’ stimaturi biex nirregressaw fuq punteġġi ta’ kwalità ġġenerati mill-bniedem differenti u mudell ġdid ta’ klassifikazzjoni mħarrġa fuq gradi relattivi miksuba minn Valutazzjonijiet Diretti. Nipproponu wkoll teknika sempliċi għall-konverżjoni tat-tbassir fil-livell tas-segmenti f’punteġġ fil-livell tad-dokument. B’mod ġenerali, is-sistemi tagħna jiksbu riżultati b’saħħithom għall-pari lingwistiċi kollha fuq settijiet ta’ testijiet preċedenti u f’ħafna każijiet jistabbilixxu avvanz ġdid.", 'no': 'Vi presenterer bidrag av Unbabel-gruppa til delt oppgåve WMT 2020 på metrikk. Vi vil delta på segmentnivået, dokumentnivå og systemnivåspor på alle språkparar, og «QE som eit metrisk»-sporet. Derfor illustrerer vi resultata av modelane våre i disse spora med referanse til testsett frå førre år. Våre oppføringar bygger på den nyleg foreslåde COMET-rammeverket: vi treng fleire estimatormodeller for å regressera på ulike menneskelige kvalitetscorer og eit roman rankingsmodell trent på relative rankar som får frå direkte vurdering. Vi foreslår også ein enkel teknikk for å konvertera segmentnivåforhåndsvisingar til eit dokumentnivåscore. I alt har systemet våre oppnådd sterke resultat for alle språkparar på førre testsett, og i mange tilfeller sett eit nytt kunsttilstand.', 'mn': 'Бид Unbabel багийнхаа хуваалтын ажилд WMT 2020 оны метриктикийн хуваалтын ажилд зориулсан. Бид бүх хэл хоорондоо загварын түвшинд, баримт түвшинд, системийн түвшинд оролцох төлөвлөгөө, мөн "QE as a Metric" хэлбэрээр оролцох гэж байна. Тиймээс бид өмнөх жилийн туршилтын дагуулын үр дүнг эдгээр загваруудыг харуулж байна. Бид саяхан COMET-ийн санал дэвшүүлсэн хэмжээний даалгаврын даалгаврын төлөө бий болгосон: бид өөр хүн төрөлхтний чанарын тоо, харьцангуй хэмжээнд сургалтын шинэ хэмжээний загварыг удирдаж байна. Бид мөн загварын түвшинд хэмжээний таамаглалыг баримт түвшинд шилжүүлэх энгийн техник санал болгож байна. Ихэнх тохиолдолд бидний систем өмнөх шалгалт дээрх бүх хэл хоорондоо хүчтэй үр дүнг гаргадаг.', 'ro': 'Vă prezentăm contribuția echipei Unbabel la activitatea partajată WMT 2020 privind metricile. Intenționăm să participăm la nivel de segment, la nivel de document și la nivel de sistem pe toate perechile de limbi, precum și la piesa "QE as a Metric". În consecință, ilustrăm rezultatele modelelor noastre pe aceste piste cu referire la seturile de testare din anul precedent. Lucrările noastre se bazează pe cadrul COMET propus recent: pregătim mai multe modele de estimatoare pentru a regresa pe diferite scoruri de calitate generate de om și un nou model de clasament instruit pe rangurile relative obținute din Evaluări directe. De asemenea, propunem o tehnică simplă pentru conversia previziunilor la nivel de segment într-un scor la nivel de document. În general, sistemele noastre obțin rezultate puternice pentru toate perechile de limbi în seturile anterioare de teste și, în multe cazuri, stabilesc o nouă stare de ultimă generație.', 'sr': 'Predstavljamo doprinos Unbabelovog tima u zajednički zadatak WMT 2020 o metrikama. Namjeravamo da učestvujemo na nivou segmenta, nivou dokumenta i sistemski tragovi na svim jezičkim parovima, kao i stazi "QE kao metrik". Stoga, ilustrujemo rezultate naših modela u ovim tragovima s referencijom na testove iz prethodne godine. Naši podaci su izgradili na nedavno predloženom okviru COMET-a: trenirali smo nekoliko modela procjene da regresiramo na različitim rezultatima kvalitete humanjerenog kvaliteta i nov model rendža obučen na relativnim redovima koji su dobili iz direktne procjene. Takođe predlažemo jednostavnu tehniku preobraćanja predviđanja na nivou segment a u rezultat nivoa dokumenta. U svemu, naši sistemi postižu jake rezultate za sve jezičke pare na prethodnim testovima i u mnogim slučajevima postavljaju novi stanje umjetnosti.', 'sv': 'Vi presenterar Unbabels bidrag till WMT 2020 Shared Task on Metrics. Vi avser att delta på segmentnivå, dokumentnivå och systemnivå spår på alla språkpar, samt "QE as a Metric"-spår. Följaktligen illustrerar vi resultaten av våra modeller i dessa banor med hänvisning till testset från föregående år. Våra bidrag bygger på det nyligen föreslagna ramverket COMET: vi tränar flera estimatormodeller för att regresera på olika humangenererade kvalitetspoäng och en ny rankingsmodell utbildad på relativa rankningar erhållna från Direct Assessments. Vi föreslår också en enkel teknik för att konvertera prognoser på segmentnivå till en dokumentnivå poäng. Sammantaget uppnår våra system starka resultat för alla språkpar på tidigare testuppsättningar och sätter i många fall en ny state-of-the-art.', 'ta': "நாங்கள் மெட்ரிக்ஸ் மீது பங்கிடப்பட்ட வேலைக்கு Unbabel குழுவின் பங்கை அளிக்கிறோம். துண்டத்தின் மட்டத்தில், ஆவணமட்டத்தில் மற்றும் கணினி மட்டத்தில் நாம் பங்கிட வேண்டும் எல்லா மொழி ஜோடிகளிலும் மற்றும் 'QE மெட் ஆகையால், முந்தைய ஆண்டில் இருந்து சோதனையின் அமைப்புகளை குறிப்பிட இந்த தடங்களில் எங்கள் மாதிரிகளின் முடிவு எங்கள் கட்டளைகள் சமீபத்தில் COMET சட்டத்தில் கட்டப்படுகிறது: நாங்கள் பல கணக்கீட்டாளர் மாதிரிகளை பயிற்சி செய்து வேறு மனித உருவாக்கப்பட்ட தரம் மதிப்புகள் மீண் நாம் ஒரு சுலபமான தொழில்நுட்பம் துண்டு மட்டத்தின் முன்னோட்டங்களை ஆவண மட்டத்தின் மதிப்புக்கு மாற்றுவதற்கா மொத்த, எங்கள் கணினிகள் முந்தைய சோதனையில் எல்லா மொழி ஜோடிகளுக்கும் வலிமையான விளைவுகள் பெறுகிறது மற்றும் பல நிகழ்வு", 'si': "අපි අන්බාබෙල් කණ්ඩායමේ සම්පූර්ණය පෙන්වන්නේ WMT 2020යි මෙට්\u200dරික්ස් වලට සමාගත වැඩ කරන්න. අපි හැම භාෂාවක් ජෝඩාවෙන් 'QE as a Metric' ට්\u200dරැක් එක්ක භාෂාවක් ලේවල්, ලේවල් සහ පද්ධති ලේවල් ට්\u200dරැක් එක්ක භාගයක්  ඉතින්, අපි පරීක්ෂණයේ අවුරුද්දෙන් පරීක්ෂණය සඳහා පරීක්ෂණය කරන්න ප්\u200dරතිචාරයක් පෙන්වන්නේ. අපේ සම්පූර්ණයක් නිර්මාණය කරනවා අවස්ථාවෙන් COMET සංවේදනය: අපි වෙනස් මිනිස්සුන්ගෙන් විශේෂ විශේෂ ප්\u200dරමාණය සහ සම්පූර්ණ සංවේද අපි ප්\u200dරශ්නයක් තියෙනවා සමාන ප්\u200dරශ්නයක් තත්වයක් ලේවල් ප්\u200dරශ්නයක් වෙනස් කරන්න. සම්පූර්ණයෙන්ම, අපේ පද්ධතිය පරීක්ෂණය සම්පූර්ණයෙන් සියළු භාෂා ජෝඩාවට ශක්තිමත් ප්\u200dරතිප්\u200dරතිප්\u200dර", 'so': "Dhaqaalaha kooxda Unbaal waxan u keenaynaa WMT 2020 ee lagu sharciyey shaqo metrics. Waxaynu ka qeybqaadanaynaa heerka kooxaha, heerka wargeyska iyo kooxa nidaamka, labada labo oo luqada ah oo dhan, sidoo kale wadamada 'QE waa Metric'. Sababtaas darteed waxaynu muujinnaa midowyadeena tusaalooyinkaas oo ku saabsan imtixaanka sanadkii hore. Sujumaadyadayada ayaa ku dhisan dhaqdhaqaaqa loo soo jeeday COMET: waxaynu ku tababarannaa tusaalooyin qiimeynta ah si aan u soo celino qiimeynta kala duduwan ee dadka dhalay iyo model sameynta saxda ah oo lagu baray shahaadada qaraabada ee ka helay Direct Assessments. Sidoo kale waxaynu horumarinaynaa tekniko fudud si aan ugu beddelno wixii loo sii sheegay heerka heerka lagu sameeyo kooxda wargeyska. Sida caadiga ah nidaamkayagu wuxuu heli karaa resulto xoog leh oo ay u helaan labada labo oo luqada ah oo ku yaal kooxaha jirrabka hore, xaaladaha qaarkoodna waxay ka dhigaan xaalad cusub oo farshaxan ah.", 'ur': "ہم Unbabel تیم کے حصہ کو متریک کے بارے میں WMT 2020 شریک ٹاکس میں پیش کرتے ہیں. ہم چاہتے ہیں کہ سب زبان جوڑوں پر سقم لئویل، دکمان لئویل اور سیسٹم لئویل ٹراک میں شرکت کریں، اور 'QE as a Metric' ٹراک پر بھی۔ اسی طرح ہم اپنے نمڈلوں کے نتیجے ان ٹریکیوں میں دکھاتے ہیں جو پہلے سال سے آزمائش سٹوں کے ذریعہ سے آزمائش کریں۔ ہم نے اچھی طرح پیشنهاد کی COMET فرمیک پر تعلیم دی ہے: ہم مختلف انسانوں کے مقابلہ کیفیت اسکوروں پر دوبارہ تکلیف کرنے کے لئے بہت سی مطالب موڈل سکھائی کرتے ہیں اور ایک نئی رنگ موڈل جو مستقیم آزمائش سے حاصل کئے گئے رشتوں پر تعلیم کی جاتی ہے۔ ہم نے بھی ایک ساده تکنیک پیش آزمائش کی پیش آزمائش کے لئے ایک دفتر سطح سطح سکور میں تبدیل کرنے کے لئے پیش آئیں۔ بالکل، ہمارے سیستموں کو پہلے کی امتحان سٹوں میں تمام زبان جوڑوں کے لئے مضبوط نتیجے پہنچ سکتے ہیں اور بہت سی حالت میں ایک نئی حالت آرتی کا مقرر کیا جاتا ہے.", 'vi': 'Chúng tôi xin giới thiệu sự đóng góp của nhóm Unbabel cho giải pháp WRT 2020 đã chia sẻ Nhiệm vụ sản xuất Metrics. Chúng tôi dự định sẽ tham gia vào việc phân đoạn, trình giấy tờ và hệ thống trên tất cả các cặp ngôn ngữ, cũng như bài "Trả lời nhanh như Mets." Vì vậy, chúng tôi mô tả kết quả của những mô hình này trên đường ray với những bộ thử từ năm trước. Những tài liệu của chúng tôi dựa trên cơ cấu sắp xếp chung kết vừa được đề xuất: chúng tôi đào tạo một số mô hình tiêu chuẩn để thụt lùi các điểm chất lượng nhân loại khác nhau và một kiểu xếp hạng mới được rèn luyện theo hạng tương đối từ các mặt mặt trận Phân tích trực tiếp. Chúng tôi cũng đề nghị một kỹ thuật đơn giản để chuyển lời tiên đoán cấp đoạn thành số lượng tài liệu. Toàn bộ, hệ thống của chúng tôi đạt được kết quả mạnh cho mọi cặp ngôn ngữ trên các bộ thử trước và trong nhiều trường hợp đặt một trạng thái mới.', 'uz': "Biz Unbabel guruhini Metrics bilan birlashtirilgan vazifani WMT 2020'ga qaramaymiz. Biz hamma tillar qoʻllari va 'QE'ni Metric' sifatida qoʻllanmiz. Shunday qilib, biz bu tugmalardagi modellarning natijalarini o'rganamiz, oldingi yildan sinov sonlarini sinash mumkin. Yaqinda davom etilgan COMET freymini yaratamiz: biz bir necha qiymatlar modellarini boshqa odamlar yaratilgan sifatida qayta yuborish va boshqa shaklga o'rganish modelini boshqa shaklga o'rganamiz va ta'minlovchi darajadagi darajada o'rganish modeli. We also propose a simple technique for converting segment-level predictions into a document-level score.  Umumiy, bizning tizimlarimiz oldingi sinov sohasida hamma tillar qoʻllari uchun katta natijalarini bajaradi va ko'pchilik holatda yangi soʻzni saqlaydi.", 'da': "Vi præsenterer Unbabel-holdets bidrag til WMT 2020 Shared Task on Metrics. Vi har til hensigt at deltage på segmentniveau, dokumentniveau og systemniveau spor på alle sprogpar, samt 'QE as a Metric'-sporet. Derfor illustrerer vi resultaterne af vores modeller på disse spor med henvisning til testsæt fra det foregående år. Vores indlæg bygger på den nyligt foreslåede COMET ramme: Vi træner flere estimatormodeller til at regredere på forskellige menneskegenererede kvalitetsscorer og en ny rangmodel trænet på relative ranglister opnået fra Direct Assessments. Vi foreslår også en enkel teknik til at konvertere segment-niveau forudsigelser til en dokumentniveau score. Samlet set opnår vores systemer stærke resultater for alle sprogpar på tidligere testsæt og sætter i mange tilfælde nyt state-of-the-art.", 'bg': 'Представяме приноса на екипа на Унбабел към Споделената задача за измерване на показателите. Възнамеряваме да участваме на ниво сегмент, ниво документ и ниво система на всички езикови двойки, както и на пистата "КЕ като метрична". Съответно илюстрираме резултатите от нашите модели в тези писти с позоваване на тестови комплекти от предходната година. Нашите предложения се основават на наскоро предложената рамка Ние обучаваме няколко модела на оценяване, които да регресират по различни човешки генерирани качествени оценки и нов модел на класиране, обучен по относителни рангове, получени от директни оценки. Предлагаме и проста техника за преобразуване на прогнози на ниво сегмент в оценка на ниво документ. Като цяло нашите системи постигат силни резултати за всички езикови двойки на предишни тестове и в много случаи създават ново състояние на изкуството.', 'nl': "We presenteren de bijdrage van het Unbabel team aan de WMT 2020 Shared Task on Metrics. We zijn van plan om deel te nemen aan segmentniveau, document-niveau en systeem-niveau tracks op alle taalparen, evenals de 'QE as a Metric' track. Daarom illustreren we resultaten van onze modellen in deze tracks aan de hand van testsets uit het voorgaande jaar. Onze inzendingen bouwen voort op het recent voorgestelde COMET framework: we trainen verschillende schatormodellen om te regresseren op verschillende human generated quality scores en een nieuw rankingmodel dat getraind is op relatieve rangen verkregen uit Direct Assessments. We stellen ook een eenvoudige techniek voor om segmentvoorspellingen om te zetten in een score op documentniveau. Over het algemeen bereiken onze systemen sterke resultaten voor alle taalparen op eerdere testsets en zetten in veel gevallen een nieuwe state-of-the-art.", 'de': 'Wir stellen den Beitrag des Unbabel-Teams zur WMT 2020 Shared Task on Metrics vor. Wir beabsichtigen, an den Segmentebenen, Dokumenten- und Systemebenen auf allen Sprachpaaren teilzunehmen, sowie am Track "QE as a Metric". Entsprechend illustrieren wir die Ergebnisse unserer Modelle in diesen Tracks anhand von Testsets aus dem Vorjahr. Unsere Einreichungen bauen auf dem kürzlich vorgeschlagenen COMET-Framework auf: Wir trainieren mehrere Schätzungsmodelle, um auf verschiedenen human generated quality scores zu regressen, und ein neuartiges Ranking-Modell, das auf relativen Rängen trainiert wurde, die aus Direct Assessments gewonnen wurden. Wir schlagen auch eine einfache Technik vor, um Vorhersagen auf Segmentebene in eine Punktzahl auf Dokumentenebene umzuwandeln. Insgesamt erzielen unsere Systeme für alle Sprachpaare auf früheren Testsets starke Ergebnisse und setzen in vielen Fällen einen neuen Stand der Technik.', 'ko': "WMT 2020 지표 공유 임무에 대한 Unbabel 팀의 기여를 소개했다.우리는 모든 언어의 단계별, 문서, 시스템 추적에 참여하고, '양적완화를 평가 기준으로 삼는' 추적에 참여할 계획이다.그래서 우리는 전년도의 테스트집을 참고하여 이 궤도에서 우리 모델의 결과를 보여 주었다.우리가 제출한 문서는 최근에 제기된 COMET 구조를 토대로 몇 개의 평가기 모델을 훈련시켜 서로 다른 인류가 생성한 품질 점수에 따라 회귀하고 새로운 랭킹 모델을 훈련시켰다. 이 모델은 직접 평가를 통해 얻은 상대적인 랭킹에 따라 훈련한다.우리는 또한 단계별 예측을 문서급 점수로 바꾸는 간단한 기술도 제시했다.전반적으로 말하자면 우리의 시스템은 이전의 테스트 집합에서 모든 언어에 대해 좋은 결과를 얻었고 많은 상황에서 우리의 시스템이 가장 선진적이다.", 'id': "Kami memperkenalkan kontribusi tim Unbabel ke WMT 2020 Shared Task on Metrics. We intend to participate on the segmentlevel, document-level and system-level tracks on all language pairs, as well as the 'QE as a Metric' track.  Oleh karena itu, kami memperlihatkan hasil dari model kami di trek ini dengan referensi ke set tes dari tahun sebelumnya. Pemberian kami membangun pada cadangan COMET yang baru-baru ini diusulkan: kami melatih beberapa model penghargaan untuk kembali pada skor kualitas yang dibuat oleh manusia berbeda dan model rangkaian baru dilatih pada rangkaian relatif yang diperoleh dari penilaian langsung. Kami juga mengusulkan teknik sederhana untuk mengubah prediksi tingkat segment menjadi skor tingkat dokumen. Secara umum, sistem kita mencapai hasil yang kuat untuk semua pasangan bahasa pada set tes sebelumnya dan dalam banyak kasus menetapkan state-of-the-art baru.", 'sw': "Tunaonyesha mchango wa timu ya Unbabel katika Tamko la WMT 2020 lililoshirikiana na kazi za Metric. Tunahitaji kushiriki katika kiwango cha sekta, kiwango cha nyaraka na kiwango cha mfumo kwa ajili ya viwili vyote vya lugha, pamoja na mfumo wa 'QE kama njia ya Metric'. Kwa hiyo, tunaelezea matokeo ya mifano yetu katika njia hizi kwa maana ya kujaribu kuanzia mwaka uliopita. Mawasiliano yetu yanajenga kwenye mfumo wa hivi karibuni unapendekezwa COMET: tunafundisha mifano kadhaa ya kuchekeza upya juu ya vituo tofauti vya ubora uliotengenezwa na watu na mtindo wa riwaya uliojifundishwa kwa vyeo vinavyohusiana na matokeo ya moja kwa moja. Pia tunapendekeza teknolojia rahisi kwa kubadilisha utabiri wa kiwango cha ngazi katika kiwango cha nyaraka. Kwa ujumla, mifumo yetu hupata matokeo makubwa kwa ajili ya wanandoa wa lugha zote katika seti za majaribio yaliyopita na katika matukio mengi yanaweka hali mpya ya sanaa.", 'fa': 'ما مشترک تیم انبابل را به کار مشترک WMT 2020 در متریک پیشنهاد می کنیم. ما قصد داریم روی سطح بخش، سطح سند و سطح سیستم در همه جفت زبان، همچنین سیستم QE به عنوان یک متریک شرکت کنیم. به همین دلیل، نتیجه\u200cهای مدل\u200cهایمان را توضیح می\u200cدهیم در این ترکیب با ارتباط به مجموعه\u200cهای آزمایش از سال قبل. تحویل\u200cهای ما بر روی چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهار ما همچنین یک تکنیک ساده برای تغییر پیش بینی سطح بخش به عنوان یک نقطه سطح سند پیشنهاد می کنیم. در کل، سیستم\u200cهای ما نتایج قوی برای هر جفت زبان در مجموعه\u200cهای آزمایش قبلی و در بسیاری موارد یک حالت جدید هنر را مقرر می\u200cکنند.', 'tr': "Biz Unbabel toparynyň WBMT 2020-nji Metriklerde Paylaşyk Görevine goşulýarys. Biz segment derejesinde, sened derejesinde we sistem derejesinde ähli dil çizgilerinde bolmagy niýetlenýäk, we 'QE bir metrik derejesinde bolmagy niýetlenýäk. Şol sebäpli biz bu hatlarda nusgalarymyzy geçen ýyldan testiň düzümlerini görkez. Biziň görnüşlerimiz son günlerde COMET frameworkynda guruldylar: biz birnäçe deň daýarlyk nusgalaryny düzümlendirmek üçin düzümlenmäge görä taýýarlanmak üçin düzümlenmäge we düzümlenmäge hakyky düzümlenmäge hakyky düzümlenmäge hakyky düzümlenmä Biz hem segment derejesi önümlerini sened derejesine üýtgetmek üçin basit bir teknik tekniki teklip edýäris. Munuň ýagdaýynda, sistemamyz öňki synagda ähli dil çiftleri üçin güýçli netijede ýetip bilýär. Köp wagtlarda täze bir sanat taýýarlapdyr.", 'af': "Ons stel die bydraag van die Unbabel-span aan die WMT 2020 deelde taak op metries voor. Ons intend na deelnadeer op die segmentvlak, dokumentvlak en stelsel vlak snitte op alle taal pare, en ook die 'QE as 'n metrik' snit. Ons illustreer die resultate van ons modele in hierdie snitte met verwysing na toets stel van die vorige jaar. Ons onderstellings bou op die onlangs voorgestelde COMET raamwerk: ons tref verskeie estimatoerde modele om te regresseer op verskillende humangenereerde kwaliteit telling en 'n roman ranking model onderstelling op relatiewe ranke ontvang van Direkte Assensies. Ons voorstel ook 'n eenvoudige tekniks om segmentvlak voorskou te omskakel in 'n dokumentvlak telling. Oorsaak, ons stelsels bereik sterk resultate vir alle taal pare op vorige toets stel en in baie gevalle stel 'n nuwe staat van die kuns.", 'am': "አናባቢል ቡድን በሜትሪክ ላይ 2020 የተሰራጨውን ስራ እናቀርባለን፡፡ በቋንቋዎች ሁኔታ ላይ፣ ሰነድ-ደረጃ እና የሥርዓት ደረጃዎች በሙሉ ቋንቋዎች ሁኔታ ላይ እና በ'QE እንደ ማተርክ' መጠን እናጋራለን፡፡ ስለዚህም፣ የሞዴላዎቻችንን ፍሬዎች በሚያሳየው የቀድሞው ዓመታት መፈትናት እናስታውሳለን፡፡ የቅርብ ዘመን በተፈቀደው COMET ፍሬም ላይ አካባቢዎች አካባቢዎችን እናስተምረዋለን፡፡ የsegment-ደረጃን ትንቢት ወደ ሰነድ-ደረጃ ደረጃ ለመለወጥ ቀላል ስህተት እናሳስባታለን፡፡ በተጨማሪም፣ ስርዓቶቻችን ለቋንቋዎች ሁሉም ዓይነቶችን የበረቱ ፍሬዎችን ያገኛሉ፡፡", 'hy': 'Մենք ներկայացնում ենք Օնբաբելի թիմի ներդրումը Մետրիկայի Համաշխարհային Միջային Միջային Հետազոտություն 2020 թվականին: Մենք պատրաստվում ենք մասնակցել սեգմենտային մակարդակի, փաստաթղթի և համակարգի մակարդակի հետքերի վրա բոլոր լեզվի զույգերի վրա, ինչպես նաև "QE որպես մետրիկ" հետքերի վրա: Հետևաբար, մենք ներկայացնում ենք մեր մոդելների արդյունքները այս գնացքներում վերաբերյալ նախորդ տարվա փորձարկումներին: Մեր ներկայացումները հիմնված են վերջերս առաջարկված համակարգի համակարգի վրա. մենք սովորեցնում ենք մի քանի գնահատողական մոդելներ վերադառնալու մարդկային ստեղծված տարբեր որակային գնահատականների վրա և նոր գնահատականների մոդել, որը սովորեցվում է անմիջական գնահատակ Մենք նաև առաջարկում ենք մի պարզ մեթոդ, որպեսզի սեգմենտի մակարդակի կանխատեսումները վերածվեն փաստաթղթի մակարդակի գնահատականի: Ընդհանուր առմամբ, մեր համակարգերը հասնում են ամբողջ լեզվի զույգերի համար ուժեղ արդյունքներ նախորդ փորձարկումների ընթացքում և շատ դեպքերում նոր տեխնոլոգիա են սահմանում:', 'hr': 'Predstavljamo doprinos Unbabelovog tima u zajednički zadatak WMT 2020 o metrikama. Namjeravamo sudjelovati na razini segmenta, razini dokumenta i sustava na svim jezičkim parovima, kao i na stazi "QE kao metrika". Stoga, ilustrujemo rezultate našeg modela u ovim tragovima s reference na test setove iz prethodne godine. Naši podaci su izgradili na nedavno predloženom okviru COMET-a: treniramo nekoliko modela procjenjivanja kako bi regresirali na različitim rezultatima kvalitete humanjerenog kvaliteta i nov model reda obučen na relativnim redovima koji su dobili iz direktne procjene. Također predlažemo jednostavnu tehniku preobraćanja predviđanja na nivou segment a u rezultat nivoa dokumenta. Nakon svega, naši sustavi postignu jake rezultate za sve jezičke pare na prethodnim testovima i u mnogim slučajevima postavljaju novi stanje umjetnosti.', 'az': "Unbabel takımının WMT 2020 Metrics'in paylaşılmış işinə kömək göstəririk. Biz bütün dil çiftlərdə segment seviyyətində, dökümət seviyyətində və sistem seviyyətində, həmçinin 'QE metrik kimi' parças ına katılmaq istəyirik. Beləliklə, bu yollarda modellərin sonuçlarını əvvəlki ilindən sınamaq üçün göstəririk. Bizim təbliğlərimiz yeni təbliğ edilmiş COMET framework ünün üstünə inşa edir: biz insanların müxtəlif kaliteli nöqtələri və düzgün təcrübələrindən alınan qohum səf dərəcələrində təhsil edilən yeni səf modeli təhsil edirik. Biz həmçinin segment səviyyəsi tədbirlərini dökümə səviyyəsinə çevirmək üçün basit bir tekniki təklif edirik. Həqiqətən, sistemlərimiz əvvəlki sınama qurğularında dil çiftlərinin güclü sonuçlarına nail olacaq və çoxlu məsələlərdə yeni bir sanatın durumu təyin edirlər.", 'bn': "আমরা আনবাবেল দলের অবদান মেট্রিক্সে উইএমটি ২০২০ শেয়ার করা কাজের কাছে উপস্থাপন করছি। আমরা সেগমেন্টেল, নথিপত্র-স্তর এবং সিস্টেম-স্তরে অংশগ্রহণ করতে চাই সকল ভাষার জোড়া জোড়ায়, এবং একই সাথে 'কিউই মেট্রিক' ট্র্যাক হি যার ফলে আমরা এই ট্র্যাকে আমাদের মডেলের ফলাফল বর্ণনা করি গত বছর থেকে পরীক্ষা করার উদ্দেশ্যে। সাম্প্রতিক প্রস্তাবিত কমেট ফ্রেমের উপর আমাদের উপস্থাপনা তৈরি করা হয়েছে: আমরা বিভিন্ন মানুষের গঠনের মান নির্মিত মানের স্কোরে পুনরায় প্রশিক্ষণ করি এবং দ্ এছাড়াও আমরা একটি সাধারণ প্রযুক্তি প্রস্তাব করি যাতে বিভিন্ন স্তরের ভবিষ্যদ্বাণী একটি নথিভুক্ত স্কোরে পরিবর্ সাধারণত, আমাদের সিস্টেম পূর্ববর্তী পরীক্ষার সেটে সকল ভাষার জোড়ার জন্য শক্তিশালী ফলাফল অর্জন করে এবং অনেক ক্ষেত্রে নতুন", 'cs': 'Představujeme příspěvek týmu Unbabel k WMT 2020 Shared Task on Metrics. Chceme se podílet na segmentové, dokumentové a systémové stopě na všech jazykových párech, stejně jako na stopě "QE as a Metric". V těchto tratích tedy ilustrujeme výsledky našich modelů s odkazem na testovací sady z minulého roku. Naše příspěvky vycházejí z nedávno navrženého rámce COMET: trénujeme několik odhadovacích modelů k regresi na různých lidských skórích kvality generovaných a nový žebříčkový model trénovaný na relativních hodnotách získaných z přímých hodnocení. Navrhujeme také jednoduchou techniku převodu predikcí na úrovni segmentů na skóre na úrovni dokumentu. Celkově dosahují naše systémy výrazných výsledků pro všechny jazykové páry na předchozích testovacích sadách a v mnoha případech nastavují nový state-of-the-art.', 'et': 'Tutvustame Unbabeli meeskonna panust WMT 2020 meetodite jagatud ülesandesse. Me kavatseme osaleda segmenditaseme, dokumendi- ja süsteemitaseme radadel kõigil keelepaaridel, samuti "QE as a Metric" rajal. Sellest tulenevalt illustreerime nendel radadel oma mudelite tulemusi eelmise aasta katsekomplektide põhjal. Meie ettepanekud tuginevad hiljuti väljapakutud COMET raamistikule: koolitame mitmeid hindamismudeleid regresseerima erinevate inimese loodud kvaliteediskooride põhjal ning uudset järjestusmudelit, mis on koolitatud otseste hindamiste tulemuste põhjal saadud suhteliste astmete põhjal. Samuti pakume välja lihtsa tehnika segmendi taseme prognooside teisendamiseks dokumenditaseme skooriks. Üldiselt saavutavad meie süsteemid varasemate testide puhul tugevaid tulemusi kõigi keelepaaride puhul ja paljudel juhtudel uue tehnika taseme.', 'fi': 'Esittelemme Unbabel-tiimin panoksen WMT 2020 Shared Task on Metrics -ohjelmaan. Aiomme osallistua segmenttitasolla, dokumenttitasolla ja järjestelmätasolla kaikilla kielipareilla sekä QE as a Metric -radalla. Näin ollen havainnollistamme malliemme tuloksia näillä radoilla edellisen vuoden testisarjojen perusteella. Raporttimme pohjautuvat äskettäin ehdotettuun COMET-viitekehykseen: koulutamme useita estimaattorimalleja regressoimaan eri ihmisen tuottamiin laatupisteisiin ja uudenlaista ranking-mallia, joka on koulutettu suorista arvioinneista saatuihin suhteellisiin arvoihin. Ehdotamme myös yksinkertaista tekniikkaa segmenttitason ennusteiden muuntamiseksi dokumenttitason pistemääräksi. Kaiken kaikkiaan järjestelmämme saavuttavat vahvoja tuloksia kaikille kielipareille aiemmissa testisarjoissa ja monissa tapauksissa asettavat uuden state of the art.', 'sq': "Ne paraqesim kontributin e ekipit të Unbabel në detyrën e përbashkët të WMT 2020 mbi Metriks. Ne synojmë të marrim pjesë në nivelin e segmentit, nivelin e dokumentit dhe nivelin e sistemit në të gjitha çiftet gjuhësore si dhe në pistën 'QE si një Metrik'. Për shkak të kësaj, ne ilustrojmë rezultatet e modeleve tona në këto gjurmë me referim në grupet e testit nga viti i mëparshëm. Paraqitjet tona mbështeten në kuadrin COMET të propozuar kohët e fundit: ne trajnojmë disa modele vlerësimi për të rikthyer në rezultate të ndryshme të cilësisë së prodhuara nga njerëzit dhe një model i renditjes së re të trajnuar në renditë relative të fituar nga vlerësimet e drejtpërdrejta. Ne propozojmë gjithashtu një teknikë të thjeshtë për konvertimin e parashikimeve të nivelit të segmentit në një pikë të nivelit të dokumentit. Në përgjithësi, sistemet tona arrijnë rezultate të forta për të gjitha çiftet gjuhësore në grupet e testuara të mëparshme dhe në shumë raste vendosin një state-of-the-art të ri.", 'bs': "Predstavljamo doprinos Unbabelovog tima u zajednički zadatak WMT 2020 o metrikama. Namjeravamo učestvovati na nivou segmenta, nivou dokumenta i sustava na svim jezičkim parovima, kao i stazi 'QE kao metrika'. Stoga, ilustrujemo rezultate naših modela u ovim tragovima s referencijom na testove iz prethodne godine. Naši podaci su izgradili na nedavno predloženom okviru COMET-a: treniramo nekoliko modela procjenjivanja kako bi regresirali na različitim rezultatima kvalitete humanjerenog kvaliteta i nov model reda obučen na relativnim redovima dobijenim iz direktne procjene. Također predlažemo jednostavnu tehniku preobraćanja predviđanja na nivou segment a u rezultat nivoa dokumenta. Uglavnom, naši sustavi postignu jake rezultate za sve jezičke pare na prethodnim testovima i u mnogim slučajevima postavljaju novo stanje umjetnosti.", 'ca': 'We present the contribution of the Unbabel team to the WMT 2020 Shared Task on Metrics.  Tenim l\'intenció de participar a nivell segmental, documental i sistemal en tots els parells de llengües, així com en la pista "QE com a Metric". Per tant, il·lustrem els resultats dels nostres models en aquestes pistes en referència a grups de prova de l\'any anterior. Les nostres presentacions es basan en el marc COMET proposat recentment: entrenem varis models d\'estimació per regresar en diferents puntuacions de qualitat generats per a la humanitat i un nou model de classificació entrenat en rangs relativs obtenits a partir d\'Evaluacions Directes. We also propose a simple technique for converting segment-level predictions into a document-level score.  En general, els nostres sistemes aconsegueixen resultats forts per a tots els parells de llengües en conjunts de provas anteriors i en molts casos establen un nou avançat.', 'ha': "Tuna halatar da rabon jama'ar Unbabel zuwa WMT 2020 Shared Tafiyar da Metrics. Tuna nufin mu yi shirin cikin daraja, daraja da takardar-daraja da tsari kan duk nau'i biyu cikin harshen, da kuma hangon 'QU kamar wata Metric'. Kamar haka, muna bayyana fassarar misalinmu cikin wannan hanyõyin da za'a yi amfani da jarraba tsaro daga shekara ta farko. Emulyasiyarmu na samar a kan firam na COMET na farkon da aka buƙata: Munã kõre misãlai masu ƙidãya wa su kõma a kan wasu score masu ƙidãyaywa na mutane da aka ƙididdige sifar da kuma an sanar da wani motel mai fassarawa na danganta a kan danganta daga Directs Assessements. We also propose a simple technique for converting segment-level predictions into a document-level score.  Ga da jumla, na'asarmu za'a sami matsala masu ƙarfi wa dukkan harshen sauran da aka riga-jarrabi, kuma a cikin masu yawa, za'a sami wani halin-da-art.", 'sk': 'Predstavljamo prispevek ekipe Unbabel k skupni nalogi na področju meritev WMT 2020. Na vseh jezikovnih parih se nameravamo udeležiti sledi segmentnih, dokumentnih in sistemskih ravneh ter na skladbi QE as a Metric. V skladu s tem ponazarjamo rezultate naših modelov na teh progah s sklicevanjem na preskusne sklope iz prejšnjega leta. Naše prispevke temeljijo na nedavno predlaganem okviru COMET: usposabljamo več modelov ocenjevalcev za regresijo na različne človeško ustvarjene ocene kakovosti in nov model razvrščanja, usposobljen za relativne ocene, pridobljene z neposrednimi ocenami. Predlagamo tudi enostavno tehniko pretvorbe napovedi na ravni segmenta v oceno na ravni dokumenta. Na splošno naši sistemi dosegajo močne rezultate za vse jezikovne pare na prejšnjih testnih sklopih in v mnogih primerih postavljajo novo stanje tehnike.', 'he': 'אנחנו מציגים את התרומה של צוות אונבאבל למשימה המשותפת של WMT 2020 על מטריקס. אנחנו מתכוונים להשתתף ברמה של המסמכים, ברמה של מסמכים ורמה של מערכת בכל זוגות שפות, כמו גם במסלול "QE כמטריק". לכן, אנו מציגים תוצאות של הדוגמנים שלנו במסלולים האלה בהקשר לסטיטים מבחנים מהשנה הקודמת. השימושים שלנו בונים על סגרת COMET הציעה לאחרונה: אנחנו מאמן כמה דוגמנים מערכות לחזור על נקודות איכות נוצרות אנושיות שונות ומודל רמה חדש מאומן על רמות יחסיות שנקבלו מערכות ישירות. אנחנו גם מציעים טכניקה פשוטה להפוך חזיונות ברמה של חלקים לתוצאה ברמה של מסמכים. באופן כללי, המערכות שלנו מגיעות לתוצאות חזקות לכל זוגות שפות על קבוצות מבחנים קודמות ובמקרים רבים קובעות מציאה חדשה.', 'jv': "Awakdhéwé nganggo perusahaan kelompok Unbabel kanggo ngilangno WWT 2020 Tarjamahan kanggo Metric Awak dhéwé nambah kang nggawé ning segment, document-evel lan sistem-evel kuwi kabèh dilané, lan 'qE' lan 'Metric' track. Yukono, awake dhéwé ngerasakno dadi model sing ditambah ning acara dadi sing nyimpen banget kanggo ujian sisan mroleh dumadhi. Awakdhéwé nggawe sistem sing berarti nggawe COMETS nggawe sistem sing berarti: kéné sistem sistem dadi yang kamu tanggal nggawe barang-sistem sing gawe ngupakan perbudhakan karo sistem sing paling-perbudhakan sing paling-perbudhakan karo perbudhakan winih sing gawe nguasai model sing cara nggawe basa rangnun Gender Diwong-wong, sistematik dhéwé ngerasah barang nggawe gerakan kanggo masara urip sing dumadhi iki banget kanggo kalah-sangan ngono akeh gadanan sing beraksi Where is the new state of the arts", 'bo': "ང་ཚོས་WMT 2020་དང་མཐུན་སྣེ་གྲངས་ཀྱི་གནད་དོན་མེད་པའི་གླེང་མོལ་གྱི་ནང་དུ་འཇུག་སྟོན་པ། We intend to participate on the segmentlevel, document-level and system-level tracks on all language pairs, as well as the 'QE as a Metric' track. འུ་ཅག་གི་གླིང་རྡེའི་ནང་གི་མཐོང་སྣང་ཚུལ་མངོན་གསལ་བྱེད་པ་ཡིན་པས། Our submissions build on the recently proposed COMET framework: we train several estimator models to regress on different humangenerated quality scores and a novel ranking model trained on relative ranks obtained from Direct Assessments. We also propose a simple technique for converting segment-level predictions into a document-level score. ཡིན་ཡང་། ང་ཚོའི་མ་ལག་གི་སྔོན་གྱི་བརྟག་ཞིབ་གི་ཆ་འཕྲིན་ཡོད་ཚད་ལྟར་མཐུན་རྐྱེན་བྱས་པར་མཐུན་རྐྱེན་ཡོད།"}
{'en': 'Incorporate Semantic Structures into Machine Translation Evaluation via UCCA', 'ar': 'دمج الهياكل الدلالية في تقييم الترجمة الآلية عبر UCCA', 'fr': "Intégrer des structures sémantiques dans l'évaluation de traduction automatique via UCCA", 'pt': 'Incorporar estruturas semânticas na avaliação de tradução automática via UCCA', 'es': 'Incorporar estructuras semánticas en la evaluación de traducción automática a través de UCCA', 'ja': 'UCCAを介した機械翻訳評価にセマンティック構造を組み込む', 'zh': '因 UCCA 将语义结构整合至机器翻译评估中', 'ru': 'Включение семантических структур в оценку машинного перевода через UCCA', 'ga': 'Struchtúir Shéimeantacha a Ionchorprú i Meastóireacht ar Aistriúchán Meaisín trí UCCA', 'hi': 'यूसीसीए के माध्यम से मशीन अनुवाद मूल्यांकन में शब्दार्थ संरचनाओं को शामिल करें', 'el': 'Ενσωμάτωση Σημματικών Δομών στην Αξιολόγηση Μηχανικής Μετάφρασης μέσω του UCCA', 'ka': 'UCCA- ის გამოყენებაში სემონტიკური სტრუქტურები მაქსინური გადაწყენებაში', 'hu': 'Szemantikus struktúrák beépítése a gépi fordítás értékelésébe UCCA-n keresztül', 'it': 'Incorporare strutture semantiche nella valutazione della traduzione automatica tramite UCCA', 'kk': 'UCCA арқылы машинаны аудару оқиғаларына семантикалық құрылғыларды ендіру', 'lt': 'Įtraukti Semantines struktūras į mašinų vertimo vertinimą per UCCA', 'mk': 'Incorporate Semantic Structures into Machine Translation Evaluation via UCCA', 'ms': 'Incorporate Semantic Structures into Machine Translation Evaluation via UCCA', 'ml': 'മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിലേക്കുള്ള സെമാന്റിക് സ്ട്രാക്ട്രാക്റ്ററുകള്\u200d യുസികിഎ മുഖാന', 'mt': 'Incorporate Semantic Structures into Machine Translation Evaluation via UCCA', 'mn': 'UCCA-ын хувьд машины хөрөнгө оруулах оюутнуудын семантик бүтэц', 'pl': 'Włączenie struktur semantycznych do oceny tłumaczeń maszynowych za pośrednictwem UCCA', 'no': 'Inkorporate semantiske strukturar i maskineoversettelsevaluering via UCCA', 'ro': 'Incorporarea structurilor semantice în evaluarea traducerii automate prin UCCA', 'sr': 'Ukorporacija semantičkih struktura u procenu prevoda mašine preko UCCA-a', 'sv': 'Integrera semantiska strukturer i utvärderingen av maskinöversättning via UCCA', 'ta': 'Incorporate Semantic Structures into Machine Translation Evaluation via UCCA', 'si': 'UCCA මධ්\u200dයමයෙන් සෙමැන්ටික් සංවිධානය සම්බන්ධ වාර්ථාව අවශ්\u200dය', 'so': 'Inorporate Semantic Structures into machine Translation Evaluation via UCCA', 'ur': 'UCCA کے ذریعے ماشین ترجمہ ارزیابی میں سیمنٹی ساخترات شامل کریں', 'uz': 'Name', 'vi': 'Cấu trúc Semantic into Machine Translation Đánh giá qua UCCA', 'bg': 'Включване на семантични структури в оценката на машинния превод чрез UCCA', 'hr': 'Uključite semantičke strukture u procjenu prevoda strojeva preko UCCA-a', 'nl': 'Semantische structuren integreren in Machine Translation Evaluation via UCCA', 'da': 'Integrere semantiske strukturer i maskinoversættelsesvurdering via UCCA', 'de': 'Einbindung von semantischen Strukturen in die maschinelle Übersetzungsbewertung über UCCA', 'id': 'Incorporate Semantic Structures into Machine Translation Evaluation via UCCA', 'ko': 'UCCA를 통해 의미 구조를 기계 번역 평가에 포함시키다', 'fa': 'ساختارهای سیمانتیک را در ارزیابی ترجمه ماشین از طریق UCCA شامل کنید', 'sw': 'Kuingiza Miundombinu ya Semantic katika Utafiti wa Tafsiri wa Mashiniki kupitia UCCA', 'tr': 'UCCA tarapyndan Semantik strukturlary maşynyň terjime çykyşyna girdir', 'am': 'ምርጫዎች', 'sq': 'Futja e strukturave Semantike në vlerësimin e përkthimit të makinave nëpërmjet UCCA', 'af': 'Inkorporeer Semantiese strukture binne Masjien Vertaling Evaluering deur UCCA', 'hy': 'Ներառել սեմանտիկ կառուցվածքները UCCA-ի միջոցով մեքենայի թարգմանման գնահատման մեջ', 'bn': 'ইউসিকিএ মাধ্যমে মেশিন অনুবাদ প্রদানের মাধ্যমে সেম্যান্টিক ক্ষেত্রে ইনকর্পোরেট করুন', 'bs': 'Uključite semantičke strukture u procjenu prevoda mašine preko UCCA-a', 'az': 'UCCA vasit…ôsil…ô maŇüńĪna √ßeviril…ôn m…ôlumat qurularńĪnńĪ birl…ôŇüdir', 'ca': "Incorporar estructures semàntiques a l'Evaluació de la traducció màquina a través de la UCCA", 'et': 'Semantiliste struktuuride kaasamine masintõlke hindamisse UCCA kaudu', 'fi': 'Semanttisten rakenteiden sisällyttäminen konekäännösten arviointiin UCCA:n kautta', 'cs': 'Začlenění sémantických struktur do hodnocení strojového překladu prostřednictvím UCCA', 'he': 'להכניס מבנים סמנטיים לבדיקת התרגשות מכונות דרך UCCA', 'jv': 'Incomporate semanti structural to Masine translation Units', 'ha': '@ info: whatsthis', 'sk': 'Vključitev semantičnih struktur v vrednotenje strojnega prevajanja prek UCCA', 'bo': 'Incorporate Semantic Structures into Machine Translation Evaluation via UCCA'}
{'en': 'Copying mechanism has been commonly used in neural paraphrasing networks and other text generation tasks, in which some important words in the input sequence are preserved in the output sequence. Similarly, in machine translation, we notice that there are certain words or phrases appearing in all good translations of one source text, and these words tend to convey important semantic information. Therefore, in this work, we define words carrying important semantic meanings in sentences as semantic core words. Moreover, we propose an MT evaluation approach named Semantically Weighted Sentence Similarity (SWSS). It leverages the power of UCCA to identify semantic core words, and then calculates sentence similarity scores on the overlap of semantic core words. Experimental results show that SWSS can consistently improve the performance of popular MT evaluation metrics which are based on lexical similarity.', 'ar': 'تم استخدام آلية النسخ بشكل شائع في شبكات إعادة الصياغة العصبية ومهام إنشاء النص الأخرى ، حيث يتم الاحتفاظ ببعض الكلمات المهمة في تسلسل الإدخال في تسلسل الإخراج. وبالمثل ، في الترجمة الآلية ، نلاحظ أن هناك كلمات أو عبارات معينة تظهر في جميع الترجمات الجيدة لنص مصدر واحد ، وتميل هذه الكلمات إلى نقل معلومات دلالية مهمة. لذلك ، في هذا العمل ، نحدد الكلمات التي تحمل معاني دلالية مهمة في الجمل ككلمات أساسية دلالية. علاوة على ذلك ، نقترح نهج تقييم الترجمة الآلية المسمى تشابه الجمل الموزونة الدلالي (SWSS). إنه يستفيد من قوة UCCA لتحديد الكلمات الأساسية الدلالية ، ثم يحسب درجات تشابه الجملة على تداخل الكلمات الأساسية الدلالية. تظهر النتائج التجريبية أن SWSS يمكن أن تحسن باستمرار أداء مقاييس تقييم الترجمة الآلية الشائعة والتي تستند إلى التشابه المعجمي.', 'es': 'El mecanismo de copia se ha utilizado comúnmente en redes de paráfrasis neuronales y otras tareas de generación de texto, en las que algunas palabras importantes de la secuencia de entrada se conservan en la secuencia de salida. Del mismo modo, en la traducción automática, observamos que hay ciertas palabras o frases que aparecen en todas las traducciones correctas de un texto original, y estas palabras tienden a transmitir información semántica importante. Por lo tanto, en este trabajo definimos palabras que llevan significados semánticos importantes en oraciones como palabras centrales semánticas. Además, proponemos un enfoque de evaluación de MT denominado Semantically Weighted Sentence Similarity (SWSS). Aprovecha el poder de UCCA para identificar palabras centrales semánticas y luego calcula las puntuaciones de similitud de oraciones en función de la superposición de palabras centrales semánticas. Los resultados experimentales muestran que el SWSS puede mejorar constantemente el rendimiento de las métricas de evaluación de MT populares que se basan en la similitud léxica.', 'fr': "Le mécanisme de copie est couramment utilisé dans les réseaux de paraphrase neuronale et d'autres tâches de génération de texte, dans lesquelles certains mots importants de la séquence d'entrée sont conservés dans la séquence de sortie. De même, dans la traduction automatique, nous remarquons que certains mots ou phrases apparaissent dans toutes les bonnes traductions d'un texte source, et que ces mots ont tendance à transmettre des informations sémantiques importantes. C'est pourquoi, dans ce travail, nous définissons des mots porteurs de significations sémantiques importantes dans des phrases comme des mots sémantiques de base. De plus, nous proposons une approche d'évaluation MT appelée Similarité de phrase pondérée sémantique (SWSS). Il tire parti de la puissance de l'UCCA pour identifier les mots sémantiques principaux, puis calcule les scores de similarité de phrases sur le chevauchement des mots sémantiques principaux. Les résultats expérimentaux montrent que SWSS peut constamment améliorer les performances des métriques d'évaluation MT populaires qui sont basées sur la similitude lexicale.", 'pt': 'O mecanismo de cópia tem sido comumente usado em redes neurais de paráfrase e outras tarefas de geração de texto, nas quais algumas palavras importantes na sequência de entrada são preservadas na sequência de saída. Da mesma forma, na tradução automática, notamos que certas palavras ou frases aparecem em todas as boas traduções de um texto de origem, e essas palavras tendem a transmitir informações semânticas importantes. Portanto, neste trabalho, definimos palavras que carregam significados semânticos importantes em frases como palavras do núcleo semântico. Além disso, propomos uma abordagem de avaliação MT chamada Semantically Weighted Sentence Similarity (SWSS). Ele aproveita o poder do UCCA para identificar palavras centrais semânticas e, em seguida, calcula pontuações de similaridade de frases na sobreposição de palavras centrais semânticas. Resultados experimentais mostram que o SWSS pode melhorar consistentemente o desempenho de métricas populares de avaliação de TA que são baseadas em similaridade lexical.', 'ja': 'コピー機構は、入力シーケンス内のいくつかの重要な単語が出力シーケンス内に保持される、ニューラルパラフレーズネットワーク及び他のテキスト生成タスクにおいて一般的に使用されてきた。同様に、機械翻訳では、1つのソーステキストのすべての良い翻訳に特定の単語またはフレーズが現れ、これらの単語は重要な意味情報を伝える傾向があることに気づきます。したがって、この著作では、文に重要な意味を持つ単語を意味論的中核単語として定義している。さらに、意味的加重文類似性（ SWSS ）と名付けられたMT評価アプローチを提案します。セマンティックコアの単語を識別するためにUCCAの力を活用し、セマンティックコアの単語の重複に関する文の類似性スコアを計算します。実験結果は、SWSSが語彙類似性に基づく人気のあるMT評価指標のパフォーマンスを一貫して向上させることができることを示しています。', 'zh': '复制制常用于神经释义网络及他文本生事,其输序之要单词存于输序。 机器翻译之中,一源文本诸良译皆有单词短语,而单词向传重语义。 故句有大语义义者单词义为语义核。 又语义加权句相似性(SWSS)MT评法。 以UCCA力识语义核心词,然后计语义重句相似性分数。 实验结果表明,SWSS能继高词法相似性常以机器翻译评指标之性。', 'ru': 'Механизм копирования широко используется в нейронных перефразирующих сетях и других задачах генерации текста, в которых некоторые важные слова во входной последовательности сохраняются в выходной последовательности. Аналогичным образом, в машинном переводе мы замечаем, что во всех хороших переводах одного исходного текста появляются определенные слова или фразы, и эти слова, как правило, передают важную семантическую информацию. Поэтому в этой работе мы определяем слова, несущие важные смысловые значения в предложениях, как семантические ключевые слова. Кроме того, мы предлагаем подход к оценке MT под названием «Сходство семантически взвешенных предложений» (SWSS). Он использует возможности UCCA для идентификации семантических ключевых слов, а затем вычисляет баллы сходства предложений на перекрытии семантических ключевых слов. Экспериментальные результаты показывают, что SWSS может последовательно улучшать производительность популярных метрик оценки MT, которые основаны на лексическом сходстве.', 'hi': 'कॉपी तंत्र का उपयोग आमतौर पर तंत्रिका पैराफ्रेसिंग नेटवर्क और अन्य टेक्स्ट जनरेशन कार्यों में किया जाता है, जिसमें इनपुट अनुक्रम में कुछ महत्वपूर्ण शब्द आउटपुट अनुक्रम में संरक्षित होते हैं। इसी तरह, मशीन अनुवाद में, हम देखते हैं कि एक स्रोत पाठ के सभी अच्छे अनुवादों में कुछ शब्द या वाक्यांश दिखाई देते हैं, और ये शब्द महत्वपूर्ण शब्दार्थ जानकारी व्यक्त करते हैं। इसलिए, इस काम में, हम वाक्यों में महत्वपूर्ण शब्दार्थ अर्थों को ले जाने वाले शब्दों को शब्दार्थ मूल शब्दों के रूप में परिभाषित करते हैं। इसके अलावा, हम एक एमटी मूल्यांकन दृष्टिकोण का प्रस्ताव करते हैं जिसका नाम Semantically भारित वाक्य समानता (SWSS) है। यह शब्दार्थ कोर शब्दों की पहचान करने के लिए यूसीसीए की शक्ति का लाभ उठाता है, और फिर शब्दार्थ कोर शब्दों के ओवरलैप पर वाक्य समानता स्कोर की गणना करता है। प्रयोगात्मक परिणामों से पता चलता है कि SWSS लगातार लोकप्रिय एमटी मूल्यांकन मैट्रिक्स के प्रदर्शन में सुधार कर सकता है जो लेक्सिकल समानता पर आधारित हैं।', 'ga': 'Baineadh úsáid go coitianta as meicníocht chóipeála i líonraí néaracha athfhriotail agus i dtascanna giniúna téacs eile, ina gcaomhnaítear roinnt focail thábhachtacha sa seicheamh ionchuir sa seicheamh aschuir. Mar an gcéanna, in aistriúchán meaisín, tugaimid faoi deara go bhfuil focail nó frásaí áirithe le feiceáil i ngach aistriúchán maith ar bhuntéacs amháin, agus is gnách go gcuireann na focail seo faisnéis shéimeantach thábhachtach in iúl. Mar sin, sa saothar seo, sainímid focail a bhfuil bríonna shéimeantacha tábhachtacha in abairtí mar chroífhocail shéimeantacha. Ina theannta sin, molaimid cur chuige meastóireachta MT darb ainm Cosúlacht Pianbhreithe Ualaithe go Séimeantach (SWSS). Úsáideann sé cumhacht UCCA croífhocail shéimeantacha a aithint, agus ansin ríomhann sé scóir chosúlachta abairtí ar fhorluí croífhocail shéimeantacha. Léiríonn torthaí turgnamhacha gur féidir le SWSS feabhas comhsheasmhach a chur ar fheidhmíocht méadracht mheastóireachta MT a bhfuil tóir orthu atá bunaithe ar chosúlachtaí foclóireachta.', 'hu': 'A másolási mechanizmust gyakran használják neurális parafrazáló hálózatokban és más szöveggenerálási feladatokban, amelyekben a bemeneti sorozat fontos szavai megmaradnak a kimeneti sorozatban. Hasonlóképpen a gépi fordításban észrevettük, hogy bizonyos szavak vagy kifejezések jelennek meg egy forrásszöveg minden jó fordításában, és ezek a szavak hajlamosak fontos szemantikai információkat közvetíteni. Ezért ebben a munkában fontos szemantikai jelentést hordozó szavakat definiálunk szemantikai alapszóként. Továbbá javaslatot teszünk egy MT értékelési megközelítésre, melynek neve Szemantikusan Weighted Sentence Similarity (SWSS). Kihasználja az UCCA erejét a szemantikai alapszavak azonosítására, majd kiszámítja a mondatok hasonlósági pontszámait a szemantikai alapszavak átfedésére. Kísérleti eredmények azt mutatják, hogy az SWSS következetesen javíthatja a népszerű MT értékelési mutatók teljesítményét, amelyek lexikai hasonlóságon alapulnak.', 'el': 'Ο μηχανισμός αντιγραφής έχει χρησιμοποιηθεί συνήθως σε νευρωνικά δίκτυα παράφρασης και άλλες εργασίες δημιουργίας κειμένου, στις οποίες ορισμένες σημαντικές λέξεις στην ακολουθία εισαγωγής διατηρούνται στην ακολουθία εξόδου. Ομοίως, στη μηχανική μετάφραση, παρατηρούμε ότι υπάρχουν ορισμένες λέξεις ή φράσεις που εμφανίζονται σε όλες τις καλές μεταφράσεις ενός κειμένου προέλευσης, και αυτές οι λέξεις τείνουν να μεταφέρουν σημαντικές σημασιολογικές πληροφορίες. Ως εκ τούτου, στην παρούσα εργασία, ορίζουμε λέξεις που φέρουν σημαντικές σημασιολογικές έννοιες σε προτάσεις ως σημασιολογικές βασικές λέξεις. Επιπλέον, προτείνουμε μια προσέγγιση αξιολόγησης ΜΤ με την ονομασία Σημαντικά Ζυγισμένη Ομοιότητα των Προτάσεων. Αξιοποιεί τη δύναμη του για να εντοπίσει σημασιολογικές βασικές λέξεις και στη συνέχεια υπολογίζει βαθμολογίες ομοιότητας προτάσεων για την επικάλυψη σημασιολογικών βασικών λέξεων. Τα πειραματικά αποτελέσματα δείχνουν ότι μπορεί να βελτιώσει σταθερά την απόδοση των δημοφιλών μετρήσεων αξιολόγησης ΜΤ που βασίζονται στη λεξική ομοιότητα.', 'ka': 'შექმნის კოპერაციის მექანიზმი უბრალოდ გამოყენებულია ნეიროლური პარაფრაზების ქსელში და სხვა ტექსტის შექმნის დავალებში, რომლებიც შექმნის შემდეგი მნიშვნელოვანი სიტყ ასე იგივეა, მაქინის გაგრძელებაში, ჩვენ დავხედავთ, რომ არსებობს განსაკუთრებული სიტყვები ან სიტყვები, რომელიც ერთი მხოლოდ ტექსტის ყველა კარგი გაგრძელებაში, და ეს სიტყ ამიტომ, ამ სამუშაოში, ჩვენ განსაზღვრებით სიტყვები, რომელიც მნიშვნელოვანი სენმანტიკური სიტყვებში გადატანა. დამატებით, ჩვენ მინდომა MT გავამუშაოთ გავამუშაოთ სახელი Semantically Weighted Sentence Similarity (SWSS). ეს უფრო ძალიან გამოიყენება UCCA-ის სინათლის სინათლის განსაზღვრება, და შემდეგ გამოყენება სინათლის სინათლის განსაზღვრებაში სინათლის განსაზღვრება. ექსპერიმენტიური წარმოდგენები ჩვენებს, რომ SWSS შეუძლიათ წარმოდგენოთ პოლუმენტიური MT განსაზღვრების მეტრიკის მუშაობას, რომელიც ლექსიკალური ს', 'it': 'Il meccanismo di copia è stato comunemente usato nelle reti neurali di parafrasi e in altre attività di generazione di testo, in cui alcune parole importanti nella sequenza di input sono conservate nella sequenza di output. Allo stesso modo, nella traduzione automatica, notiamo che alcune parole o frasi appaiono in tutte le buone traduzioni di un testo sorgente, e queste parole tendono a trasmettere importanti informazioni semantiche. Pertanto, in questo lavoro, definiamo parole che portano importanti significati semantici nelle frasi come parole chiave semantiche. Inoltre, proponiamo un approccio di valutazione MT denominato Semantically Weighted Sentence Similarity (SWSS). Sfrutta il potere di UCCA per identificare le parole chiave semantiche e quindi calcola i punteggi di somiglianza delle frasi sulla sovrapposizione delle parole chiave semantiche. I risultati sperimentali mostrano che SWSS può migliorare costantemente le prestazioni delle metriche di valutazione MT popolari basate sulla somiglianza lessicale.', 'mk': 'Механизмот за копирање е често употребен во нервните парафразирачки мрежи и други задачи за генерација на текст, во кои некои важни зборови во вводната секвенца се зачуваат во излезната секвенца. Исто така, во машинскиот превод, забележуваме дека постојат одредени зборови или фрази кои се појавуваат во сите добри преводи на еден извор текст, а овие зборови имаат тенденција да пренесуваат важни семантични информации. Затоа, во оваа работа, ги дефинираме зборовите кои носат важни семантични значења во речениците како семантични основни зборови. Покрај тоа, предложуваме пристап на проценка на МТ наречен Семантично тежирана судска сличност (СВС). Истиот ја искористува моќта на УККА за идентификување семантични основни зборови, а потоа ги пресметува оценките на сличност на речениците на прекривањето на семантичните основни зборови. Експерименталните резултати покажуваат дека СВС константно може да ја подобри резултатот на популарните метрики за проценка на МТ кои се базирани на лексикална сличност.', 'lt': 'Kopijavimo mechanizmas dažnai naudojamas nervinių parafrazių tinkluose ir kitose tekstų kūrimo užduotyse, kuriose kai kurie svarbi įvedimo sekos žodžiai išsaugojami išvedimo sekoje. Similarly, in machine translation, we notice that there are certain words or phrases appearing in all good translations of one source text, and these words tend to convey important semantic information.  Todėl šiame darbe žodžiai, turintys svarbias semantines reikšmes sakiniuose, apibrėžiami kaip semantiniai pagrindiniai žodžiai. Be to, siūlome MT vertinimo metodą, vadinamą Semantiškai svertinio bausmės panašumu (SWSS). Ji sutelkia UCCA galią nustatyti semantinius pagrindinius žodžius, o paskui apskaičiuoja sakinių panašumo rezultatus dėl semantinių pagrindinių žodžių dubliavimo. Eksperimentiniai rezultatai rodo, kad SWSS gali nuosekliai pagerinti populiarių MT vertinimo metrijų, pagrįstų leksiniu panašumu, veiksmingumą.', 'kk': 'Көшірмелеу механизмі кәдімгі невралдық парафраз желінде және басқа мәтін құру тапсырмаларында қолданылады. Кіріс ретінде кейбір маңызды сөздер шығыс ретінде сақталады. Мұндай секілде, машинаның аудармасында бір көздегі мәтіннің барлық жақсы аудармасында сөздер не сөздер бар екенін білеміз. Бұл сөздер маңызды семантикалық мәліметті береді. Сондықтан бұл жұмыс ішінде сөздердің маңызды семантикалық мәліметтерін семантикалық сөздер ретінде анықтаймыз. Сонымен қатар, біз Semantically Weighted Sentence Similarity (SWSS) деп аталатын MT бағалау тәсілдігін ұсынамыз. Бұл симантикалық негізгі сөздерді анықтау үшін UCCA қуатын өзгертеді, содан кейін симантикалық негізгі сөздердің тең нәтижесін есептеп береді. Эксперименталдық нәтижелер SWSS лексикалық ұқсас тәсілдігіне негізделген MT оқу метрикаларының әсерін жақсартуға болады.', 'ml': 'ന്യൂറല്\u200d പാരാഫ്രസിങ്ങ് നെറ്റുറല്\u200d പ്രവർത്തകങ്ങളിലും മറ്റു ടെക്സ്റ്റ് തലമുറയുടെ ജോലികളിലും പകര്\u200dത്തുന്ന മെക്കനിസം സാധാരണ ഉപയോഗി Similarly, in machine translation, we notice that there are certain words or phrases appearing in all good translations of one source text, and these words tend to convey important semantic information.  അതുകൊണ്ട്, ഈ ജോലിയില്\u200d, നമ്മള്\u200d വാക്കുകള്\u200d വാക്കുകളില്\u200d പ്രധാനപ്പെട്ട സെമാന്\u200dറിക് അര്\u200dത്ഥങ്ങള്\u200d നടത്തുന്നത്  അതുകൊണ്ടും, സെമാന്റിക്കല്\u200d വീണ്ടെടുക്കപ്പെട്ട ശിക്ഷ സമമാണ് എന്\u200dറെ എംടി വിലാസപ്രകാരം പ്രായശ്ചിത്തം ചെയ് അത് സെമാന്റിക് കോര്\u200d വാക്കുകളെ തിരിച്ചറിയാനുള്ള UCCA ശക്തിയെ ഉപയോഗിക്കുന്നു. പിന്നെ വാക്കിന്റെ പോലെയുള്ള സ്കോര്\u200dട് പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു ലെക്സിക്സിക്കല്\u200d സമമാണ് അടിസ്ഥാനമാക്കിയ എംടി വിലാസങ്ങളുടെ പ്രകടനത്തിന് സ', 'ms': 'Mekanisme salinan telah biasanya digunakan dalam rangkaian parafrasasi saraf dan tugas generasi teks lain, di mana beberapa perkataan penting dalam urutan input disimpan dalam urutan output. Dengan cara yang sama, dalam terjemahan mesin, kita perasan bahawa terdapat perkataan atau frasa tertentu yang muncul dalam semua terjemahan yang baik bagi satu teks sumber, dan perkataan ini cenderung untuk menyebarkan maklumat semantik penting. Oleh itu, dalam kerja ini, kita menentukan perkataan yang membawa makna semantik penting dalam kalimat sebagai perkataan utama semantik. Lagipun, kami cadangkan pendekatan penilaian MT bernama Semantically Weighted Sentence Similarity (SWSS). Ia menggunakan kuasa UCCA untuk mengenalpasti perkataan utama semantik, dan kemudian menghitung skor persamaan kalimat pada meliputi perkataan utama semantik. Experimental results show that SWSS can consistently improve the performance of popular MT evaluation metrics which are based on lexical similarity.', 'mt': 'Il-mekkaniżmu tal-ikkopjar intuża b’mod komuni fin-netwerks ta’ parafrażizzazzjoni newrali u kompiti oħra ta’ ġenerazzjoni tat-test, li fihom jinżammu xi kliem importanti fis-sekwenza tal-input fis-sekwenza tal-output. Bl-istess mod, fit-traduzzjoni bil-magna, ninnota li hemm ċerti kliem jew frażijiet li jidhru fit-traduzzjonijiet tajbin kollha ta’ test ta’ sors wieħed, u dawn il-kliem għandhom it-tendenza li jgħaddu informazzjoni semantika importanti. Għalhekk, f’dan ix-xogħol, niddefinixxu kliem li jġorru tifsiriet semantiċi importanti fis-sentenzi bħala kliem ċentrali semantiku. Barra minn hekk, qed nipproponu approċċ ta’ evalwazzjoni MT imsejjaħ Similarità tas-Sentenza Piżata Semantikament (SWSS). Jixpruna s-saħħa tal-UCCA biex tidentifika l-kliem ċentrali semantiku, u mbagħad jikkalkula l-punteġġi ta’ similarità tas-sentenza fuq l-irduppjar tal-kliem ċentrali semantiku. Riżultati sperimentali juru li SWSS jista’ jtejjeb b’mod konsistenti l-prestazzjoni tal-metriċi popolari tal-evalwazzjoni MT li huma bbażati fuq similarità lexika.', 'mn': 'Бичлэгийн хуулийн механизм нь мэдрэлийн парафраз сүлжээ болон бусад текст бүтээлтийн даалгавруудад хэрэглэгддэг. Ингэснээр зарим чухал үгнүүд гаргалтын дарааллаар хадгалагддаг. Мөн машины орчуулалт бид нэг эх үүсвэрийн бүх сайн орчуулалт дээр тодорхой үг эсвэл үг байдаг гэдгийг анзаарсан. Эдгээр үг нь чухал хэмжээний мэдээлэл өгдөг. Тиймээс бид энэ ажилд өгүүлбэрт чухал семантик утгатай үгсийг semantic core words гэж тодорхойлдог. Мөн бид Semantically Weighted Sentence Similarity (SWSS) гэдэг MT үнэлгээний арга замыг санал болгож байна. Энэ нь УККА-ын эрх мэдлийг семантик үндсэн үгийг тодорхойлох, дараа нь өгүүлбэр ижил хэмжээний үндсэн үгийг тооцоолж байна. Үүний туршилтын үр дүнг нь SWSS нь Лексийн төстэй төстэй төстэй олон хүн төрлийн MT оюун үнэлгээний үйлдлийг сайжруулж чадна.', 'no': 'Kopieringsmekanismen er vanlegvis brukt i nøyralparafrasing- nettverk og andre tekstoppgåver, der nokre viktige ord i inndatasekvensen vert lagra i utdata- sekvensen. I maskineoversettelsa har vi merke på at det finst nokre ord eller frasar som dukkar opp i alle gode oversettelsar av eitt kjeldetekst, og desse ord har tendens til å senda viktig semantisk informasjon. I dette arbeidet definerer vi ordet som inneheld viktige semantiske betaling i setningar som semantiske kjerneord. I tillegg foreslår vi ein MT-evalueringstilnærming med namn på semantisk vekt sentelslikhet (SWSS). Det leverer makten på UCCA til å identifisera semantiske kjerneord, og deretter reknar ut setningslingspoeng på overlappen av semantiske kjerneord. Eksperimentale resultat viser at SWSS kan konsekvent forbedra utviklinga av populære MT-evalueringsmetrikar som er basert på leksiske likningar.', 'pl': 'Mechanizm kopiowania jest powszechnie stosowany w neuronowych sieciach parafrazowania i innych zadaniach generowania tekstu, w których niektóre ważne słowa w sekwencji wejściowej są zachowane w sekwencji wyjściowej. Podobnie w tłumaczeniu maszynowym zauważamy, że we wszystkich dobrych tłumaczeniach jednego tekstu źródłowego pojawiają się pewne słowa lub zwroty, które mają tendencję do przekazywania ważnych informacji semantycznych. Dlatego w niniejszej pracy definiujemy słowa o ważnych znaczeniach semantycznych w zdaniach jako słowa podstawowe semantyczne. Ponadto proponujemy metodę oceny MT o nazwie Semantycznie ważona podobność zdań (SWSS). Wykorzystuje moc UCCA do identyfikacji semantycznych słów podstawowych, a następnie oblicza punkty podobieństwa zdań na nakładanie się semantycznych słów podstawowych. Wyniki eksperymentalne pokazują, że SWSS może konsekwentnie poprawić wydajność popularnych wskaźników oceny MT opartych na podobieństwie leksykalnym.', 'sr': 'Mehanizam kopiranja je uobičajeno korišćen u nervnim parafrazacijskim mrežama i drugim zadacima za proizvodnju teksta, u kojima se određuju neke važne reči u sekvenci ulaska. Isto tako, u prevodu mašine, primećujemo da postoje određene reči ili rečenice koje se pojavljuju u svim dobrim prevodima jednog izvornog teksta, a ove reči obično prenose važne semantičke informacije. Stoga, u ovom poslu definišemo reči koje nose važne semantičke značenje rečenica kao semantične jezgre reči. Osim toga, predlažemo pristup procjene MT-a po imenu Semantički svjetljena sličnost kazne (SWSS). To utiče na moć UCCA-a da identifikuje semantičke jezgre riječi, a onda računa rezultate sličnosti rečenica na preklapanje semantičkih jezgre riječi. Eksperimentalni rezultati pokazuju da SWSS može konsekventno poboljšati učinkovitost popularnih MT procjene metrika koja se temelji na leksičkoj sličnosti.', 'ro': 'Mecanismul de copiere a fost folosit frecvent în rețelele neurale de parafrazare și alte sarcini de generare a textului, în care unele cuvinte importante din secvența de intrare sunt păstrate în secvența de ieșire. În mod similar, în traducerea automată, observăm că există anumite cuvinte sau fraze care apar în toate traducerile bune ale unui text sursă, iar aceste cuvinte tind să transmită informații semantice importante. Prin urmare, în această lucrare, definim cuvintele care purtă semnificații semantice importante în propoziții ca cuvinte esențiale semantice. În plus, propunem o abordare de evaluare MT numită Semantically Weighted Sentence Similarity (SWSS). Folosește puterea UCCA de a identifica cuvintele de bază semantice și apoi calculează punctajele de similitudine ale frazelor pe suprapunerea cuvintelor de bază semantice. Rezultatele experimentale arată că SWSS poate îmbunătăți în mod constant performanța măsurătorilor populare de evaluare MT care se bazează pe similitudinea lexicală.', 'si': 'ප්\u200dරතිලිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළ ඒ වගේම, පණිවිඩයට, අපි දැනගත්තා විශේෂ වචන නැත්තම් වචනයක් තියෙනවා කියලා, එක ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d ඉතින්, මේ වැඩේ අපි වැදගත්තා වචන් වැදගත් වැදගත් සෙමාන්ටික් අදහස් වචන වචන වගේ. තවත්, අපි MT විශ්ලේෂණයක් ප්\u200dරතිස්ථාපනයක් සෙමාන්ටිකාලික විශ්ලේෂණයක් කිරීම සම්බන්ධතාවක් කියල ඒක UCCA ගේ ශක්තිය ප්\u200dරවේශ කරනවා සෙමැන්ටික් මධ්\u200dයම වචන පරීක්ෂණය කරන්න, ඊට පස්සේ වාක්ය සමාන වචන වලින් ප්\u200dරවේශ කරනවා. පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ SWSS පුළුවන් ප්\u200dරජාතික MT විශ්ලේෂණ මෙට්\u200dරික්ස් එක්ක ප්\u200dරතිච', 'so': 'Maamulka koobsashada waxaa inta badan lagu isticmaalay shabakado baaritaanka neurada ah iyo shaqooyin kale oo macluumaad ah, kuwaas oo lagu ilaaliyaa qaar erayo muhiim ah oo ku jira dabaqa soo baxa. Sidoo kale, turjumidda machine, waxaynu fiirinaynaa in erayo cayiman ama hadallo ka muuqata turjumaadda oo dhan oo wanaagsan ee qoraalka kooban, erayadanna waxay u baahan yihiin inay soo bandhigaan macluumaad muhiim ah. Sidaa darteed waxaynu ku qornaa hadallo ku saabsan waxyaabaha muhiimka ah oo ku saabsan hadalka qaybta ah. Sidoo kale waxaynu soo jeedinnaa qaab qiimeyn ah oo la odhan jiray Semantically Weighted Sentence Similarity (SWSS). Waxay u dhiibtaa xoogga UCCA si ay u aqoonsato hadalka kooxaha ah, markaasna waxay xisaabtaa xisaabta isku mid ah oo ku qoran hadalka kooxaha ah. Imtixaanka waxaa ka muuqda in SWSS si joogto ah u hagaajin karo sameynta qiimeynta metrikada maamulka ah ee ku saleysan isku mid ah leksikal.', 'sv': 'Kopieringsmekanism har ofta använts i neurala parafraseringsnätverk och andra textgenereringsuppgifter, där några viktiga ord i inmatningssekvensen bevaras i utmatningssekvensen. På samma sätt, i maskinöversättning, märker vi att det finns vissa ord eller fraser som förekommer i alla bra översättningar av en källtext, och dessa ord tenderar att förmedla viktig semantisk information. Därför definierar vi i detta arbete ord som bär viktiga semantiska betydelser i meningar som semantiska kärnord. Dessutom föreslår vi en MT utvärderingsmetod som heter Semantically Weighted Sentence Similarity (SWSS). Den utnyttjar kraften hos UCCA för att identifiera semantiska kärnord och beräknar sedan meningsliknande poäng på överlappningen av semantiska kärnord. Experimentella resultat visar att SWSS konsekvent kan förbättra prestandan för populära MT-utvärderingsmetoder som baseras på lexikal likhet.', 'ta': 'நகல் முறைமையை பொதுவாக புதிய சொற்றொடர் வலைப்பின்னலில் பயன்படுத்தப்பட்டுள்ளது மற்றும் உரை உரை உருவாக்கும் பணிகளில், அதில் உள்ளீட்டு வரிசை அதே போல, இயந்திர மொழிபெயர்ப்பில், சில வார்த்தைகள் அல்லது சொற்றொடர்கள் ஒரு மூல உரையின் அனைத்து நல்ல மொழிபெயர்ப்பில் தெரியும் என்பதை  எனவே, இந்த வேலையில், நாம் வாக்கியங்களில் முக்கியமான அர்த்தத்தை அரை மூல வார்த்தைகளாக வரையறுக்கிறோம். மேலும், நாம் ஒரு MT மதிப்பீடு முறைமையை தேர்ந்தெடுக்கிறோம் சென்டிக்காக வாக்குறிப்பு சமமாக (SWSS). அது அமைப்பு மூல வார்த்தைகளை கண்டுபிடி சோதனை முடிவு', 'ur': 'نائورل پارفریزنگ نیٹورک اور دوسری ٹکسٹ نسل کے کاموں میں کپی مکانیزن استعمال کیا گیا ہے، جہاں ان کے اندر اپنا اہم کلمات آئوٹ سٹر میں حفاظت کیے جاتے ہیں. اسی طرح، ماشین ترجمہ میں، ہم نے سمجھ لیا ہے کہ ایک سورج کے تمام اچھے ترجمہ میں کچھ کلمات یا کلمات ظاہر ہوتے ہیں، اور یہ کلمات اہم سیمانٹیکی معلومات پہنچاتے ہیں. لہٰذا، اس کام میں ہم کلمات کی تعریف کرتے ہیں جو کلمات میں ضروری سیمانتی معنی اٹھاتے ہیں۔ اور ہم ایک MT evaluation approach (SWSS) کی پیشنهاد کرتے ہیں جس کا نام Semantically Weighted Sentence Similarity (SWSS) ہے. یہ UCCA کی طاقت کو سیمنٹی اصلی کلمات کی شناسایی کرنے کے لئے لگا رہا ہے اور پھر کلمات کی مثال سیمنٹی اصلی کلمات کے اورلپ پر محاسبات کرتا ہے. آزمائش نتیجے دکھاتے ہیں کہ SWSS لکھنے والی برابری پر بنیاد رکھتے ہیں لکھنے والی MT ارزیابی متریک کے عملکرد کو ثابت قدم کر سکتے ہیں.', 'uz': "@ info: whatsthis Shunday qilib, mashina tarjima qilishda biz bir necha so'zlar yoki so'zlar bir manba matn tarjimalarining hamma yaxshi tarjima qiladigan va bu so'zlar muhim semantik maʼlumotini aytadi. Shunday qilib, bu ishda, biz bir so'zlarda muhim semantik ma'nolarini semantik core so'zlari sifatida aniqlash. Moreover, we propose an MT evaluation approach named Semantically Weighted Sentence Similarity (SWSS).  Ikkinchi so'zlarni aniqlash uchun UCCA қувватини қўллаб-қувватланади, va keyin so'zni semantik tugma soʻzlarini koʻpaytirish mumkin. Tekshirish natijalarini koʻrsatish: SWSS доимо toʻxtatish, leksikal likligi asosida yaratilgan Umumiy MT qiymati metriklarini bajarishi mumkin.", 'vi': 'Bộ tạo bản sao thường được sử dụng trong các mạng cắt ảnh thần kinh và các công việc tạo văn bản khác, trong đó một số từ quan trọng trong chuỗi nhập được bảo quản trong chuỗi xuất. Tương tự, trong dịch vụ máy, chúng tôi nhận ra rằng có những từ hay cụm từ xuất hiện trong tất cả các bản dịch tốt của một nguồn, và những từ này có xu hướng truyền tải thông tin ngữ pháp quan trọng. Do đó, trong công việc này, chúng tôi định nghĩa những từ mang theo nghĩa ngữ nghĩa quan trọng trong các câu như là những từ cơ bản. Hơn nữa, chúng tôi đề nghị một phương pháp đánh giá MTV được gọi là Semantical Weight Similarity (SWS). Nó dùng để điều khiển sức mạnh của ECCA để xác định các từ cơ bản theo ngữ nghĩa thì sau đó tính to án điểm giống nhau của câu ở sự chồng chéo giữa các từ cơ bản. Các kết quả thử nghiệm cho thấy SWAT có thể hoàn toàn cải thiện khả năng của các lượng tử đánh giá MTV nổi tiếng dựa trên tính mạng.', 'bg': 'Копиращият механизъм често се използва в невронни парафразиращи мрежи и други задачи за генериране на текст, при които някои важни думи в входната последователност са запазени в изходната последователност. По същия начин при машинния превод забелязваме, че във всички добри преводи на един изходен текст се появяват определени думи или фрази и тези думи са склонни да предават важна семантична информация. Затова в тази работа дефинираме думи, носещи важни семантични значения в изреченията, като семантични основни думи. Освен това, предлагаме подход за оценка на МТ, наречен Семантично претеглена сходство на присъдата (СУСС). Той използва силата на UCCA да идентифицира семантични основни думи и след това изчислява оценките за сходство на изреченията при припокриване на семантични основни думи. Експерименталните резултати показват, че могат последователно да подобрят ефективността на популярните измервателни показатели за МТ, които се основават на лексикална прилика.', 'nl': 'Kopiëringsmechanisme is vaak gebruikt in neurale parafraseernetwerken en andere tekstgeneratietaken, waarbij enkele belangrijke woorden in de invoersequentie behouden blijven in de uitvoersequentie. Op dezelfde manier merken we bij machinevertaling dat er bepaalde woorden of zinnen voorkomen in alle goede vertalingen van één brontekst, en deze woorden hebben de neiging om belangrijke semantische informatie over te brengen. Daarom definiëren we in dit werk woorden met belangrijke semantische betekenissen in zinnen als semantische kernwoorden. Bovendien stellen we een MT evaluatiebenadering voor genaamd Semantically Weighted Sentence Similarity (SWSS). Het maakt gebruik van de kracht van UCCA om semantische kernwoorden te identificeren en berekent vervolgens zinsgelijkenisscores op de overlap van semantische kernwoorden. Experimentele resultaten tonen aan dat SWSS consistent de prestaties van populaire MT evaluatiestatistieken kan verbeteren die gebaseerd zijn op lexicale gelijkenis.', 'da': "Kopieringsmekanisme er almindeligt anvendt i neurale parafraseringsnetværk og andre tekstgenereringsopgaver, hvor nogle vigtige ord i inputsekvensen bevares i outputsekvensen. På samme måde bemærker vi i maskinoversættelse, at der findes visse ord eller sætninger i alle gode oversættelser af én kildetekst, og disse ord har tendens til at formidle vigtig semantisk information. Derfor definerer vi i dette arbejde ord, der bærer vigtige semantiske betydninger i sætninger, som semantiske kerneord. Desuden foreslår vi en MT evalueringsmetode kaldet Semantically Weighted Sentence Similarity (SWSS). Det udnytter UCCA's kraft til at identificere semantiske kerneord og beregner derefter sætningernes lighedsscorer på overlapningen af semantiske kerneord. Eksperimentelle resultater viser, at SWSS konsekvent kan forbedre ydeevnen af populære MT evalueringsmetrics, der er baseret på lexikal lighed.", 'de': 'Kopiermechanismus wurde häufig in neuronalen Paraphrasierungsnetzwerken und anderen Textgenerierungsaufgaben verwendet, bei denen einige wichtige Wörter in der Eingabesequenz in der Ausgabesequenz erhalten bleiben. Ähnlich bemerken wir bei der maschinellen Übersetzung, dass in allen guten Übersetzungen eines Ausgangstextes bestimmte Wörter oder Phrasen vorkommen, die dazu neigen, wichtige semantische Informationen zu vermitteln. Daher definieren wir in dieser Arbeit Wörter mit wichtigen semantischen Bedeutungen in Sätzen als semantische Kernwörter. Darüber hinaus schlagen wir einen MT-Evaluierungsansatz namens Semantically Weighted Satence Similarity (SWSS) vor. Es nutzt die Leistungsfähigkeit von UCCA, um semantische Kernwörter zu identifizieren, und berechnet dann Satzähnlichkeitswerte für die Überlappung semantischer Kernwörter. Experimentelle Ergebnisse zeigen, dass SWSS die Leistung gängiger MT-Bewertungsmetriken, die auf lexikalischer Ähnlichkeit basieren, konsequent verbessern kann.', 'hr': 'Mehanizam kopiranja uobičajeno se koristi u mrežama neuroparafrazacije i drugim zadacima za proizvodnju teksta, u kojima se čuvaju neke važne riječi u redoslijedu ulaza u redoslijedu izlaza. Isto tako, u prevodu strojeva, primjećujemo da postoje određene riječi ili rečenice koje se pojavljuju u svim dobrim prevodima jednog izvornog teksta, a ove riječi tendiraju prenijeti važne semantičke informacije. Stoga, u ovom poslu definiramo riječi koje nose važne semantičke značenje u rečenicama kao semantičke jezgre riječi. Osim toga, predlažemo pristup procjene MT-a po imenu Semantički svjetljena sličnost kazne (SWSS). To utječe na moć UCCA-a da identificira semantičke jezgre riječi, a onda proračuna rezultate sličnosti rečenica na preklapanju semantičkih jezgre riječi. Eksperimentalni rezultati pokazuju da SWSS može konsekventno poboljšati učinkovitost popularnih MT procjene metrika koja se temelji na leksičkoj sličnosti.', 'id': 'Copying mechanism has been commonly used in neural paraphrasing networks and other text generation tasks, in which some important words in the input sequence are preserved in the output sequence.  Sama seperti, dalam terjemahan mesin, kita melihat bahwa ada kata-kata atau frasa tertentu muncul dalam semua terjemahan yang baik dari satu teks sumber, dan kata-kata ini cenderung untuk menyebarkan informasi semantis penting. Therefore, in this work, we define words carrying important semantic meanings in sentences as semantic core words.  Selain itu, kami mengusulkan pendekatan evaluasi MT bernama Semantically Weighted Sentence Similarity (SWSS). Ini menggunakan kekuatan UCCA untuk mengidentifikasi kata-kata utama semantis, dan kemudian menghitung skor persamaan kalimat pada salitan kata-kata utama semantis. Hasil eksperimen menunjukkan bahwa SWSS dapat secara konsisten meningkatkan prestasi dari metrik evaluasi MT populer yang berdasarkan persamaan lexik.', 'ko': '복제 메커니즘은 신경 해석 네트워크와 다른 텍스트 생성 작업에 광범위하게 응용되었는데, 그 중에서 입력 시퀀스 중의 일부 중요한 단어는 출력 시퀀스에 보존되어 있다.이와 유사하게 기계 번역에서 우리는 원본 텍스트의 모든 양호한 번역에 어떤 단어나 단어가 나타나는데 이런 단어들은 중요한 의미 정보를 전달하는 경우가 많다는 것을 알아차렸다.따라서 본고는 문장에서 중요한 의미를 가진 단어를 의미 핵심어로 정의한다.그 밖에 우리는 기계 번역 평가 방법인 의미 가중 문장 유사도(SWSS)도 제시했다.UCCA의 능력을 이용해 의미 핵심어를 식별한 뒤 의미 핵심어의 중첩에 따라 문장의 싱크로율 점수를 계산한다.실험 결과 SWSS는 어휘 유사도를 바탕으로 하는 상용 기계 번역 평가 지표의 성능을 지속적으로 향상시킬 수 있음을 나타냈다.', 'sw': 'Mfumo wa kukipata nakala umetumiwa mara nyingi katika mitandao ya mabadiliko ya kijamii na kazi nyingine za vizazi vya maandishi, ambapo maneno muhimu katika mfululizo wa kujiunga huhifadhiwa katika mfululizo wa matokeo. Vivyo hivyo, katika tafsiri ya mashine, tunagundua kuwa kuna maneno au maneno fulani yanayoonekana katika tafsiri zote nzuri ya maandishi moja ya vyanzo vya habari, na maneno haya yanajumuisha taarifa muhimu za kigaidi. Kwa hiyo, katika kazi hii, tunaelezea maneno yenye maana muhimu ya kimapenzi katika hukumu kama maneno ya msingi. Zaidi ya hayo, tunapendekeza mbinu ya uchunguzi wa MT inayoitwa Semantically Weighted Sentence Similani (SWSS). Inatumia nguvu ya UCCA kutambua maneno ya msingi ya kimapenzi, na baadae inakadiria vipimo sawa vya hukumu juu ya upande wa maneno ya kisasa. Experimental results show that SWSS can consistently improve the performance of popular MT evaluation metrics which are based on lexical similarity.', 'fa': 'مکانیسم کپی کردن معمولاً در شبکه\u200cهای پارافریز عصبی و کارهای دیگر تولید متن استفاده می\u200cشود، در حالی که بعضی کلمات مهم در ترکیب ورودی در ترکیب خروجی محافظت می\u200cشوند. همچنین، در ترجمه ماشین، متوجه می\u200cشویم که کلمات یا جمله\u200cهای خاص در تمام ترجمه\u200cهای خوب از یک متن منبع وجود دارد، و این کلمات معمولاً اطلاعات semantic مهم را می\u200cدهند. بنابراین، در این کار، ما کلمات را تعریف می\u200cکنیم که معنی\u200cهای سنتی مهم در جمله\u200cها به عنوان کلمات اصلی سنتی است. به علاوه، ما پیشنهاد می\u200cکنیم یک روش ارزیابی MT به نام شبیه sentences Semantically Weighted (SWSS). قدرت UCCA را تأثیر می\u200cدهد تا کلمات اصلی semantic را شناسایی کند، و سپس امتیاز شبیه\u200cی جمله\u200cها را بر بالای کلمات اصلی semantic محاسبه می\u200cکند. نتیجه\u200cهای تجربه نشان می\u200cدهد که SWSS می\u200cتواند عملکرد متریک ارزیابی MT محبوب را بهتر کند که بر اساس شباهت زبانی است.', 'tr': "Nural parafrazlikler aňlarda we başga metin döredilişinde ullanýar, içinde girdi dizinde birnäçe wajyp sözler çykyş dizinde goralýar. Şu ýaly maşynyň terjimesinde, bir çeşme metiniň ähli gowy terjimelerinde belli sözler ýa-da sözler bar we bu sözler möhüm semantik maglumaty terjime edip bilýärler. Şonuň üçin bu işde, sözleriň semantik esasy sözlerinde möhüm semantik anlamlyklary taýýarlanan sözlerimizi düşünýäris. Ayrıca, Semantically Weighted Sentence Similarity (SWSS) adlı MT değerlendirme metodlarını teklif ediyoruz. Bu semantik çekim sözlerini tanımlamak için UCCA'nin gücünü etkinleýär we soňra sözlerin simantik çekim sözlerinin üstündeki notlarını hesaplar. Durmançylyk netijeleri SWSS-iň popüler MT deňleme metrikleriniň eserlerini leksiýaly meňzeşliklere daýan edip biljekdigini görkezip bilýär.", 'af': "Kopierende mekanisme is gewoonlik gebruik in neurale parafrasing netwerke en ander teks generasie taak, waarin sommige belangrike woorde in die invoer volgorde word in die uitset volgorde bewaar. Liks, in masjien vertaling, is ons aanmerk dat daar sekere woorde of frase in alle goeie vertalings van een bron teks verskyn word, en hierdie woorde moet belangrik semantiese inligting vertel. Daarom, in hierdie werk, definieer ons woorde wat belangrike semantiese betekenings in setnings as semantiese kjernewoorde dra. Maar ons voorstel 'n MT evalueringstoegang genaamd Semantiese Gewigte Sentenis Similariteit (SWSS). Dit verwyder die krag van UCCA om semantiese kjernewoorde te identifiseer, en dan bereken die teikens gelykenis telling op die oorlaap van semantiese kjernewoorde. Eksperimentale resultate wys dat SWSS kan konsistentlik die prestasie van populêre MT evalueringsmetries verbeter wat op leksiese gelykenis gebaseer is.", 'sq': 'Mekanizmi i kopjimit është përdorur zakonisht në rrjetet e parafrazimit nervor dhe detyra të tjera të gjenerimit të tekstit, në të cilat disa fjalë të rëndësishme në sekuencën e hyrjes janë ruajtur në sekuencën e daljes. Në mënyrë të ngjashme, në përkthimin e makinave, ne vëmë re se ka disa fjalë apo fraza që shfaqen në të gjitha përkthimet e mira të një teksti burimi, dhe këto fjalë tenderojnë të transmetojnë informacion semantik të rëndësishëm. Prandaj, në këtë punë, ne përcaktojmë fjalë që mbajnë kuptime semantike të rëndësishme në fjalë si fjalë themelore semantike. Përveç kësaj, ne propozojmë një qasje vlerësimi MT të quajtur Similaritë e Dënimeve Semantikisht të Peshuara (SWSS). Ajo nxjerr fuqinë e UCCA për të identifikuar fjalët themelore semantike, dhe pastaj llogarit rezultatet e ngjashmërisë së fjalëve themelore semantike. Rezultatet eksperimentale tregojnë se SWSS mund të përmirësojë vazhdimisht performancën e metrikave popullore të vlerësimit MT që janë bazuar në ngjashmërinë lexike.', 'am': 'የጽሑፍ ትውልድ አድራሻ እና ሌሎች የጽሑፍ ትውልድ ስራዎችን በመጠቀም የተጠቃሚ አካሄድ ተጠቃሚ ሆኖአል፡፡ እንደዚህም፣ በመሳዊ ትርጉም፣ አንዲት ዓይነት ጽሑፍ በመልካም ትርጓሜ የሚኖሩ ቃላት ወይም ቃላት እንዲገኙ እናስታውቃለን፡፡ ስለዚህም በዚህ ሥራ፣ አስፈላጊ የsemantic አእምሮዎች የሚሸከሙትን ቃላት እንደ semantic አካል ቃላት እናሳውቃለን፡፡ ደግሞም፣ የስሜናክሎ የስህተት ብጤት (SWSS) የሚባልን የMT ማስታወቂያ ልውጤት እናሳልጋለን፡፡ የUCCA ሥልጣን የsemantic core ቃላትን ለማሳየት እና በኋላም የተሰናክል ቃላትን በመጠቀም ይቆጥራል፡፡ ፈተና ውጤቶች SWSS በቁጥር በብዛት የተመሳሳይ የMT ማስታወቂያ ማድረግ ማድረግ እንዲችል ያሳያል፡፡', 'hy': 'Կոպիայի մեխանիզմը սովորաբար օգտագործվում է նյարդային պարաֆրազիայի ցանցերում և այլ տեքստի ստեղծման գործերում, որտեղ որոշ կարևոր բառեր են պահպանվում ներմուծի հաջորդականության մեջ: Similarly, in machine translation, we notice that there are certain words or phrases appearing in all good translations of one source text, and these words tend to convey important semantic information.  Այսպիսով, այս աշխատանքում մենք սահմանում ենք բառերը, որոնք նշանակալի սեմանտիկ իմաստ ունեն նախադասություններում, որպես սեմանտիկ հիմնական բառեր: Moreover, we propose an MT evaluation approach named Semantically Weighted Sentence Similarity (SWSS).  Այն օգտագործում է UCCA-ի ուժը սեմանտիկ հիմնական բառերի հայտնաբերելու համար և հետո հաշվարկում է նախադասությունների նմանության գնահատականները սեմանտիկ հիմնական բառերի գերակշռության վրա: Փորձարկվող արդյունքները ցույց են տալիս, որ SW-ն կարող է մշտապես բարելավել MT գնահատման հայտնի մետրիկների արդյունքը, որոնք հիմնված են լեքսիկական նմանության վրա:', 'bn': 'নিউরুল প্যারাফ্রেসিং নেটওয়ার্ক এবং অন্যান্য টেক্সট প্রজন্মের কাজে কপি করা মেক্সিমেন্ট ব্যবহার করা হয়েছে, যেখানে ইনপুটের সেকেন্ডে  একই সাথে মেশিন অনুবাদে আমরা লক্ষ্য করি যে একটি সোর্স টেক্সটের সকল ভাল অনুবাদে বিশেষ কিছু শব্দ বা বাক্য দেখা যাচ্ছে, আর এই শব্দগুলো গুরুত তাই এই কাজে আমরা বিশেষ করি যে কারাদণ্ডে গুরুত্বপূর্ণ সেমেন্টিক অর্থ বহন করছে সেমেন্টিক মূল শব্দ হিসেবে। এছাড়াও, আমরা সেম্যান্টিক্যালিকভাবে উঠে যাওয়া শাস্তি একই ধরনের (এসডিউএসএস) নামের একটি এমটি মূল্যায়নের প্রস্তা এটি সেমেন্টিক ভূমিকা শব্দ চিহ্নিত করার জন্য ইউসিকার ক্ষমতাকে বাড়িয়ে দেয় এবং তারপর সেমেন্টিক ভূমিক শব্দের আপলোডের উপর রায়ের সং পরীক্ষার ফলাফল দেখা যাচ্ছে যে এসওয়াইএসএস জনপ্রিয় এমটির মূল্যায়ন মেট্রিকের কার্যক্রম উন্নত করতে পারে, যা লেক্সিক্সিয়াল সমতুল্', 'az': "Nöral parafrazi ağlarında və başqa mətn nəzəriyyəti işlərində təkrarlama mehanizmisi yayınlıqlarda istifadə edilmişdir. Bunlarda giriş seçməsində bəzi möhüm sözlər çıxış seçməsində qorunurlar. Beləcə, maşın çevirində, bir mənbənin mətnlərin bütün yaxşı çevirilərdə bəzi sözlər və sözlər görünür və bu sözlər möhüm semantik məlumatları təbliğ edirlər. Buna görə də bu işdə, sözlərdə möhüm semantik anlama daşıyan sözləri semantik ilk sözlər kimi tanımlıyıq. Daha sonra, Semantically Weighted Sentence Similarity (SWSS) adlı MT değerlendirmə approach təklif edirik. Bu, SKA'nın semantik ilk sözlərini tanıtmaq üçün gücünü dəyişdirir, sonra sözlərin simantik ilk sözlərin üstünü hesablar. Həqiqətən, SWSS-in leksik bənzərinə dayanan popular MT değerlendirmə metriklərinin performansını daha yaxşı göstərir.", 'ca': "El mecanisme de copia s'ha utilitzat comument en xarxes de parafrases neurals i altres tasques de generació de text, en les que algunes paraules importants de la seqüència d'entrada es conserven en la seqüència d'entrada. Similarly, in machine translation, we notice that there are certain words or phrases appearing in all good translations of one source text, and these words tend to convey important semantic information.  Per tant, en aquesta feina, definim paraules portant significats semàntics importants en frases com paraules essencials semàntiques. A més, proposem un enfocament d'evaluació MT anomenat Semantically Weighted Sentence Similarity (SWSS). Utilitza el poder de la UCCA per identificar paraules essencials semàntiques, i després calcula puntuacions de similitud de frases sobre la sobreposió de paraules essencials semàntiques. Els resultats experimentals mostren que la SWSS pot millorar constantment el rendiment de les mètriques populars d'evaluació MT basades en la similitud lexical.", 'cs': 'Kopírovací mechanismus je běžně používán v neuronových parafrázovacích sítích a dalších úkolech generování textu, při kterých jsou ve výstupní sekvenci zachována některá důležitá slova ve vstupní sekvenci. Podobně i při strojovém překladu si všimneme, že ve všech dobrých překladech jednoho zdrojového textu se objevují určitá slova nebo fráze a tato slova mají tendenci předávat důležité sémantické informace. Proto v této práci definujeme slova nesoucí důležité sémantické významy ve větách jako sémantická jádrová slova. Navíc navrhujeme metodu hodnocení MT s názvem Sémanticky vážená věta podobnost (SWSS). Využívá sílu UCCA k identifikaci sémantických jádrových slov a pak vypočítá skóre podobnosti vět na překrytí sémantických jádrových slov. Experimentální výsledky ukazují, že SWSS může důsledně zlepšovat výkon populárních metrik hodnocení MT, které jsou založeny na lexikální podobnosti.', 'bs': 'Mehanizam kopiranja je uobičajeno korišćen u nervnim parafrazacijskim mrežama i drugim zadacima za proizvodnju teksta, u kojima se čuvaju neke važne riječi u sekvenci ulaska. Isto tako, u prevodu strojeva, primjećujemo da postoje određene riječi ili rečenice koje se pojavljuju u svim dobrim prevodima jednog izvornog teksta, a ove riječi tendiraju da prenose važne semantičke informacije. Stoga, u ovom poslu definišemo riječi koje nose važne semantičke značenje u rečenicama kao semantičke jezgre riječi. Osim toga, predlažemo pristup procjene MT-a po imenu Semantički svjetljena sličnost kazne (SWSS). To utiče na moć UCCA-a da identificira semantičke jezgra riječi, a onda proračuna rezultate sličnosti rečenica na preklapanju semantičkih jezgra riječi. Eksperimentalni rezultati pokazuju da SWSS može konsekventno poboljšati učinkovitost popularne MT procjene metrike koje su temeljene na leksičkoj sličnosti.', 'et': 'Kopeerimismehhanismi on tavaliselt kasutatud neuraalsetes parafraseerimisvõrkudes ja muudes teksti genereerimise ülesannetes, kus mõned olulised sõnad sisendjärjestuses säilitatakse väljundjärjestuses. Samamoodi märkame masintõlkes, et ühe lähteteksti heades tõlketes esinevad teatud sõnad või fraasid ning need sõnad kipuvad edastama olulist semantilist teavet. Seetõttu määratleme käesolevas töös lausetes olulisi semantilisi tähendusi kandvaid sõnu semantiliste põhisõnadena. Lisaks pakume välja MT hindamise lähenemisviisi nimega Semantiliselt kaalutud lausesarnasus (SWSS). See kasutab UCCA võimu semantiliste põhisõnade tuvastamiseks ja arvutab seejärel lausesarnasuse skoorid semantiliste põhisõnade kattumisel. Eksperimentaalsed tulemused näitavad, et SWSS suudab järjekindlalt parandada populaarsete MT hindamismeetikate tulemuslikkust, mis põhinevad leksikaalsel sarnasusel.', 'fi': 'Kopiointimekanismia on yleisesti k채ytetty neuroparafrasointiverkoissa ja muissa tekstintuotantoteht채viss채, joissa sy철tt철sekvenssin t채rkeit채 sanoja s채ilytet채채n tulossekvenssiss채. Vastaavasti konek채채nn철ksess채 huomaamme, ett채 kaikissa yhden l채hdetekstin hyviss채 k채채nn철ksiss채 esiintyy tiettyj채 sanoja tai lauseita, ja n채m채 sanat yleens채 v채litt채v채t t채rke채채 semanttista tietoa. Siksi t채ss채 ty철ss채 m채채rittelemme lauseissa t채rkeit채 semanttisia merkityksi채 kantavia sanoja semanttisiksi ydinsanoiksi. Lis채ksi ehdotamme MT-arviointimenetelm채채 nimelt채 Semantically Weighted Sentence Similarity (SWSS). Se hy철dynt채채 UCCA:n voimaa semanttisten ydinsanojen tunnistamiseen ja laskee sitten lauseidensamankaltaisuuspisteet semanttisten ydinsanojen p채채llekk채isyydest채. Kokeelliset tulokset osoittavat, ett채 SWSS voi johdonmukaisesti parantaa suosittujen, leksikaaliseen samankaltaisuuteen perustuvien MT-arviointimittarien suorituskyky채.', 'jv': 'Perintah sing dipunanggunian kang dipunanggo oleh dumateng seneng pisan Neral dipunanggunian tambah lan basa sing oleh nggawe text in, ning kebonang langkung kelangan seneng pisan seneng dipunanggunian sing wis dipunanggo sekondirno online. Sak sakak, ning sithik teljamahan, kita dicopo kaya kelas apat karo kapan kelas opo-kapan anyar terjamahan ing sampeyan sampek, lan kelas kuwi kudu kelas informasi sematik. Kaya, ning arep iki, kita diwuri pawaran kuwi nggawe sematik bukal ning kelas kuwi pawaran sematik. Nambah, kita nggunakake tarjamahan MT ngegambar semanti-Kemerdekaan Sentense Similrity (sWSS). Punika dipunangé kapan universi ingkang dipunangé semanti kuwi, lan tambah saiki dadi pangunangé perusahaan langgar sampeyan ingkang dipunangé semanti kuwi. Rasalih sing dipontrolan nêmên daké, sWSS iso nguasai njaluk kanggo ngerasai pancene éntuk MT sing basa Manual', 'ha': 'An amfani da shirin kopiya cikin zanayen parametering na neural da wasu aikin matsayi, a cikinsa akwai wasu masu muhimu masu tsare cikin sequence na shiga. Kamar hakan, a cikin fassarar mashine, muna gane cewa akwai wasu kalmõmi ko magana masu nuna cikin duk fassarori mai kyau na rubutun kowandan kwanza, kuma wannan magana ana ƙara su bãyar da lãbãri masu muhimu na semantic. Sabõda haka, a cikin wannan aikin, Munã bayyana maganar wanda ke ɗaukar ma\'anar semanti da muhimmi cikin maganar mutane kamar maganar bakwai. Da haka, Munã goyyar da wata matsayin evaluation na MT da aka sune "Semantically Weited Cincin Similarity" (SWSS). It leverages the power of UCCA to identify semantic core words, and then calculates sentence similarity scores on the overlap of semantic core words.  Matarin jarrabawa na nuna cewa SWSS yana iya ƙara gabanin aikin muhalli na MT da aka ƙaddara a kan daidaici na leksi.', 'sk': 'Kopiralni mehanizem se pogosto uporablja v nevralnih parafrazijskih omrežjih in drugih nalogah ustvarjanja besedila, pri katerih so nekatere pomembne besede v vhodnem zaporedju ohranjene v izhodnem zaporedju. Podobno pri strojnem prevajanju opazimo, da se v vseh dobrih prevodih enega izvornega besedila pojavljajo določene besede ali fraze in te besede ponavadi prenašajo pomembne semantične informacije. Zato smo v tem delu definirali besede, ki nosijo pomembne semantične pomene v stavkih, kot semantične jedrne besede. Poleg tega predlagamo pristop ocenjevanja MT imenovan Semantično tehtana podobnost stavkov (SWSS). Izkorišča moč UCCA za prepoznavanje semantičnih jedrnih besed in nato izračuna ocene podobnosti stavkov na podlagi prekrivanja semantičnih jedrnih besed. Poskusni rezultati kažejo, da lahko SWSS dosledno izboljšuje učinkovitost priljubljenih meritev ocenjevanja MT, ki temeljijo na leksikalni podobnosti.', 'he': 'מנגנון העתק השתמש באופן רגיל ברשתות הפרפרייזיה העצבית ומשימות יוצרת טקסט אחרות, שבהן כמה מילים חשובות ברצף הכניסה נשמרות ברצף ההוצאה. באופן דומה, בתרגום מכונות, אנו שמים לב שיש מילים או משפטים מסויימים שמופיעים בכל התרגמות טובות של טקסט מקור אחד, והמילים האלה נוטים להעביר מידע סמנטי חשוב. לכן, בעבודה הזו, אנחנו מגדירים מילים ששומרות משמעות סמנטיות חשובות במשפטים כמילים סמנטיות. בנוסף, אנו מציעים גישה עריכה MT בשם דמיון משקל סמנטי (SWSS). הוא משתמש בכוח של UCCA לזהות מילים סימנטיות לבסיס, ואז מחשב נקודות דומות משפטים על התקפות של מילים סימנטיות לבסיס. Experimental results show that SWSS can consistently improve the performance of popular MT evaluation metrics which are based on lexical similarity.', 'bo': 'Copying mechanism has been commonly used in neural paraphrasing networks and other text generation tasks, in which some important words in the input sequence are preserved in the output sequence. དེ་ལྟ་བུའི་རྩིས་འཁོར་གྱི་སྐད་ཡིག་ནང་དུ་ང་ཚོས་ཚིག་དང་ཚིག་རྐང་ཁ་ཤས་ཡོད་པ་རྟོགས་ཡོད། དེར་བརྟེན། འུ་ཚོས་བྱ་ཚིག་ནང་དུ་ཚིག་འདི་ལྟ་བུའི་དོན་དག་གི་ཚིག་རྟགས་གལ་ཆེན་པོ་ཡོད་པའི་ཚིག་རྟགས་བཀོད་ས འོན་ཀྱང་། ང་ཚོས་MT ཞིབ་དཔྱད་ཀྱི་ཐབས་ལམ་ལ་རྒྱ་ཆེ་མཐོང་པ་དེ་སྦྲེལ་བ་གཞན་ཞིག་བཤད་འདོད། It leverages the power of UCCA to identify semantic core words, and then calculates sentence similarity scores on the overlap of semantic core words. Experimental results show that SWSS can consistently improve the performance of popular MT evaluation metrics that are based on lexical similarity.'}
{'en': 'Filtering Noisy Parallel Corpus using Transformers with Proxy Task Learning', 'ar': 'تصفية المجموعة المتوازية الصاخبة باستخدام المحولات مع تعلم مهام الوكيل', 'fr': "Filtrage de corpus parallèles bruités à l'aide de transformateurs avec apprentissage par tâche", 'es': 'Filtrado de corpus paralelos ruidosos mediante Transformers con aprendizaje de tareas proxy', 'pt': 'Filtrando Corpus Paralelo Ruído usando Transformers com Aprendizagem de Tarefas de Proxy', 'ja': 'プロキシタスクラーニングを使用した変圧器を使用したノイズの多いパラレルコーパスのフィルタリング', 'hi': 'फ़िल्टरिंग शोर समानांतर कॉर्पस प्रॉक्सी कार्य सीखने के साथ ट्रांसफॉर्मर का उपयोग कर', 'ru': 'Фильтрация шумного параллельного корпуса с помощью трансформаторов с обучением прокси-задач', 'zh': '用有摄学者转换器漉噪声行语料库', 'ga': 'Corpas Comhthreomhar Noiseach a Scagadh ag úsáid Claochladáin le Tasc Foghlama Seachfhreastalaí', 'el': 'Φιλτράρισμα θορυβωδών παράλληλων σωμάτων χρησιμοποιώντας μετασχηματιστές με μάθηση εργασιών μεσολάβησης', 'ka': 'Name', 'hu': 'Zajos párhuzamos korpusz szűrése transzformátorokkal Proxy Task Learning segítségével', 'kk': 'Прокси тапсырмаларды оқытуға арналған түрлендірушілерді қолдану үшін дыбыс параллелі корпусты сүзгілеу', 'lt': 'Filtering Noise Parallel Corpus using Transformers with Proxy Task Learning', 'mk': 'Name', 'it': 'Filtrare Noisy Parallel Corpus utilizzando Transformer con Proxy Task Learning', 'ms': 'Penapis Korpus Paralel Bunyi menggunakan Penukar dengan Pembelajaran Tugas Proksi', 'ml': 'പ്രോക്സി ടാസ്ക് പഠിപ്പിക്കുന്നതുമായി ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ഉപയോഗിച്ച് നോസി പാര്\u200dവല്\u200d കോര്\u200dപ്പു', 'mt': 'Filtering Noisy Parallel Corpus using Transformers with Proxy Task Learning', 'mn': 'Прокси үйл ажиллагааны суралцах Трансформацуудыг ашиглан шууд параллел хөрөнгө сүзүүлэх', 'no': 'Name', 'ro': 'Filtrarea Corpus paralel zgomotos folosind transformatoare cu procesul de învățare a sarcinilor proxy', 'sr': 'Филтрирање параллелног курпуса користећи трансформаторе са научањем прокси задача', 'si': 'Name', 'so': 'Barbaarinta baarlamaha Noisy Corpus using Transformers with Proxy Task Learning', 'sv': 'Filtrera bullrig parallell corpus med hjälp av transformatorer med proxy Task Learning', 'ta': 'Name', 'ur': 'Name', 'pl': 'Filtrowanie Noisy Parallel Corpus za pomocą transformatorów z uczeniem się zadań proxy', 'uz': 'Name', 'vi': 'Bộ lọc nhiễu Parallel Corpus, dùng Transformers with Proxy Task Learning', 'hr': 'Filtriranje Parallelnog korpusa glasa koristeći transformere sa učenjem proksi zadataka', 'bg': 'Филтриране на шумен паралелен корпус с помощта на трансформатори с обучение на прокси задачи', 'nl': 'Noisy Parallel Corpus filteren met behulp van Transformers met Proxy Task Learning', 'da': 'Filtrering af støjende parallelle korpus ved hjælp af transformatorer med Proxy Task Learning', 'de': 'Filtern von Noisy Parallel Corpus mithilfe von Transformers mit Proxy Task Learning', 'ko': '프록시 작업 학습 기반 변압기 필터 잡음 병렬 자료 라이브러리', 'id': 'Filtering Noisy Parallel Corpus menggunakan Transformers with Proxy Task Learning', 'fa': 'Name', 'sq': 'Filtering Noisy Parallel Corpus using Transformers with Proxy Task Learning', 'sw': 'Ujumbe wa Kimbunga cha Noisy Noisy using Transformers with Proxy Learning Task', 'af': 'Name', 'tr': 'Proxy Taýry öwrenmek bilen Transformerçiler ullanýar', 'bn': 'প্রক্সি কাজ শিক্ষা সহযোগে ট্রান্সফর্মার ব্যবহার করে নোজি প্যারেল কোর্পাস ফিল্টার করা হচ্ছে', 'hy': 'Comment', 'am': 'undo-type', 'az': 'Proksi G칬zm칲 칐yr톛nm톛si il톛 Transformer칞il톛ri istifad톛 ed톛r톛k s톛s Parallel Corpusu filtrl톛yir', 'cs': 'Filtrování šumového paralelního korpusu pomocí transformátorů s učením úloh proxy', 'ca': 'Filtrant Noisy Parallel Corpus utilitzant Transformers amb Proxy Task Learning', 'bs': 'Filtrirajući Paralelni korpus glasina koristeći transformere sa učenjem proksi zadataka', 'et': 'Müraka paralleelse korpuse filtreerimine puhverserveri ülesannete õppega Transformerite abil', 'fi': 'Meluisan Parallel Corpuksen suodattaminen muuntajien avulla Proxy-tehtäväoppimisella', 'jv': 'job', 'sk': 'Filtriranje hrupnega vzporednega korpusa s pomočjo transformatorjev z učenjem opravil proxy', 'ha': 'KCharselect unicode block name', 'he': 'מסנן קורפוס פעמוני רעש באמצעות מעצבים עם לימוד משימות פרוקסי', 'bo': 'ཚབ་བྱེད་ཀྱི་ལས་འགུལ་སློང་ནུས་པའི་ཚོར་བ་སྔོན་སྒྲིག་མཁན་གཙང་རིས་འདྲ་བཤུ་བྱེད་པ'}
{'en': 'This paper illustrates Huawei’s submission to the WMT20 low-resource parallel corpus filtering shared task. Our approach focuses on developing a proxy task learner on top of a transformer-based multilingual pre-trained language model to boost the filtering capability for noisy parallel corpora. Such a supervised task also helps us to iterate much more quickly than using an existing neural machine translation system to perform the same task. After performing empirical analyses of the finetuning task, we benchmark our approach by comparing the results with past years’ state-of-theart records. This paper wraps up with a discussion of limitations and future work. The scripts for this study will be made publicly available.', 'ar': 'توضح هذه الورقة تقديم Huawei إلى المهمة المشتركة لتصفية المجموعة المتوازية منخفضة الموارد WMT20. يركز نهجنا على تطوير متعلم مهام وكيل على رأس نموذج لغة مُدرَّب مسبقًا متعدد اللغات قائم على المحولات لتعزيز قدرة التصفية للمجموعة المتوازية الصاخبة. تساعدنا هذه المهمة الخاضعة للإشراف أيضًا على التكرار بشكل أسرع بكثير من استخدام نظام ترجمة آلي عصبي لأداء نفس المهمة. بعد إجراء التحليلات التجريبية لمهمة التوليف الدقيق ، قمنا بقياس نهجنا من خلال مقارنة النتائج مع سجلات السنوات الماضية. تختتم هذه الورقة بمناقشة القيود والعمل المستقبلي. نصوص هذه الدراسة ستكون متاحة للجمهور.', 'fr': "Cet article illustre la soumission de Huawei à la tâche partagée de filtrage de corpus parallèle à faibles ressources WMT20. Notre approche se concentre sur le développement d'un apprenant de tâches par procuration sur un modèle de langage pré-formé multilingue basé sur un transformateur afin de renforcer la capacité de filtrage des corpus parallèles bruyants. Une telle tâche supervisée nous aide également à itérer beaucoup plus rapidement que l'utilisation d'un système de traduction automatique neuronale existant pour effectuer la même tâche. Après avoir effectué des analyses empiriques de la tâche de réglage fin, nous comparons notre approche en comparant les résultats avec les records de pointe des dernières années. Ce document se termine par une discussion sur les limites et les travaux futurs. Les scripts de cette étude seront mis à la disposition du public.", 'es': 'Este documento ilustra la presentación de Huawei a la tarea compartida de filtrado de corpus paralelos de bajos recursos del WMT20. Nuestro enfoque se centra en desarrollar un aprendiz de tareas proxy sobre un modelo lingüístico multilingüe preentrenado basado en transformadores para aumentar la capacidad de filtrado de cuerpos paralelos ruidosos. Esta tarea supervisada también nos ayuda a iterar mucho más rápido que usar un sistema de traducción automática neuronal existente para realizar la misma tarea. Después de realizar análisis empíricos de la tarea de ajuste, comparamos nuestro enfoque comparando los resultados con los registros de última generación de años anteriores. Este documento concluye con una discusión sobre las limitaciones y el trabajo futuro. Los guiones de este estudio se pondrán a disposición del público.', 'pt': 'Este artigo ilustra a submissão da Huawei à tarefa compartilhada de filtragem de corpus paralela de baixo recurso WMT20. Nossa abordagem se concentra no desenvolvimento de um aprendiz de tarefa de proxy em cima de um modelo de linguagem pré-treinado multilíngue baseado em transformador para aumentar a capacidade de filtragem de corpora paralelos ruidosos. Essa tarefa supervisionada também nos ajuda a iterar muito mais rapidamente do que usar um sistema de tradução automática neural existente para executar a mesma tarefa. Depois de realizar análises empíricas da tarefa de ajuste fino, comparamos nossa abordagem comparando os resultados com os registros de última geração. Este artigo termina com uma discussão sobre limitações e trabalhos futuros. Os roteiros para este estudo serão disponibilizados publicamente.', 'ja': 'この論文は、WMT 20低資源並列コーパスフィルタリング共有タスクへのファーウェイのサブミッションを例示しています。私たちのアプローチは、変圧器ベースの多言語事前トレーニング言語モデルに基づいて、ノイズの多い並列コーラのフィルタリング機能を強化する代用タスク学習者を開発することに焦点を当てています。このような監視されたタスクは、同じタスクを実行するために既存のニューラル機械翻訳システムを使用するよりもはるかに速く繰り返すのにも役立ちます。微調整タスクの実証的分析を行った後、結果を過去数年間の最先端の記録と比較することによって、アプローチをベンチマークします。本稿では、限界と今後の仕事についての議論をまとめます。この研究のスクリプトは一般公開されます。', 'zh': '本文述华为向WMT20提交低资源并行语料库漉共之。 吾法侧重于于转换器多言预训习语言模样之上,开摄任学器,以崇噪声并行语料库之过。 此监之所以助用今神经机器翻译者更快迭代也。 既析其务,将校诸往岁最新记,以准吾法。 本文最后论局限性及未来事。 本治脚本将布于众。', 'hi': 'यह पेपर WMT20 कम-संसाधन समानांतर कॉर्पस फ़िल्टरिंग साझा कार्य के लिए Huawei के सबमिशन को दिखाता है। हमारा दृष्टिकोण एक ट्रांसफार्मर-आधारित बहुभाषी पूर्व-प्रशिक्षित भाषा मॉडल के शीर्ष पर एक प्रॉक्सी कार्य शिक्षार्थी विकसित करने पर केंद्रित है ताकि शोर समानांतर कॉर्पोरेट के लिए फ़िल्टरिंग क्षमता को बढ़ावा दिया जा सके। इस तरह के एक पर्यवेक्षित कार्य भी हमें एक ही कार्य करने के लिए एक मौजूदा तंत्रिका मशीन अनुवाद प्रणाली का उपयोग करने की तुलना में बहुत अधिक तेज़ी से पुनरावृत्ति करने में मदद करता है। फाइनट्यूनिंग कार्य के अनुभवजन्य विश्लेषण करने के बाद, हम पिछले वर्षों के अत्याधुनिक रिकॉर्ड के साथ परिणामों की तुलना करके अपने दृष्टिकोण को बेंचमार्क करते हैं। यह पेपर सीमाओं और भविष्य के काम की चर्चा के साथ लपेटता है। इस अध्ययन के लिए स्क्रिप्ट सार्वजनिक रूप से उपलब्ध कराई जाएगी।', 'ru': 'Эта статья иллюстрирует представление Huawei к общей задаче фильтрации параллельных корпусов WMT20 с низкими ресурсами. Наш подход сфокусирован на разработке прокси-обучаемого задания поверх многоязычной предварительно обученной языковой модели на основе трансформатора, чтобы повысить способность фильтрации для шумных параллельных корпусов. Такая контролируемая задача также помогает нам итерировать гораздо быстрее, чем использовать существующую систему нейронного машинного перевода для выполнения той же задачи. Выполнив эмпирический анализ задачи тонкой настройки, мы сравниваем наш подход, сравнивая результаты с современными записями прошлых лет. Настоящий документ завершается обсуждением ограничений и будущей работы. Сценарии этого исследования будут обнародованы.', 'ga': 'Léiríonn an páipéar seo aighneacht Huawei chuig tasc comhroinnte scagtha corpais comhthreomhar íseal-acmhainní WMT20. Díríonn ár gcur chuige ar fhoghlaimeoir tasc seachfhreastalaí a fhorbairt anuas ar mhúnla teanga réamh-oilte ilteangach atá bunaithe ar chlaochladán chun an cumas scagtha do chorpas comhuaineach torannach a threisiú. Cuidíonn tasc maoirsithe den sórt sin linn athrá i bhfad níos tapúla ná úsáid a bhaint as córas néarchóras aistriúcháin atá ann cheana féin chun an tasc céanna a dhéanamh. Tar éis anailísí eimpíreacha a dhéanamh ar an tasc mionchoigeartaithe, déanaimid ár gcur chuige a thagarmharcáil trí na torthaí a chur i gcomparáid le taifid úrscothacha na mblianta atá caite. Filleann an páipéar seo le plé ar na teorainneacha agus obair amach anseo. Cuirfear na scripteanna don staidéar seo ar fáil go poiblí.', 'el': 'Αυτή η εργασία απεικονίζει την υποβολή της στην κοινή εργασία φιλτραρίσματος σώματος χαμηλού πόρων. Η προσέγγισή μας επικεντρώνεται στην ανάπτυξη ενός μαθητή εργασίας μεσολάβησης πάνω από ένα πολύγλωσσο προ-εκπαιδευμένο μοντέλο γλώσσας βασισμένο στον μετασχηματιστή για να ενισχύσει την ικανότητα φιλτραρίσματος για θορυβώδη παράλληλα σώματα. Μια τέτοια εποπτευόμενη εργασία μας βοηθά επίσης να επαναλάβουμε πολύ πιο γρήγορα από τη χρήση ενός υπάρχοντος νευρικού συστήματος μηχανικής μετάφρασης για να εκτελέσουμε την ίδια εργασία. Μετά την πραγματοποίηση εμπειρικών αναλύσεων του έργου συντονισμού, αξιολογούμε την προσέγγισή μας συγκρίνοντας τα αποτελέσματα με τα αρχεία των προηγούμενων ετών. Η παρούσα εργασία ολοκληρώνεται με μια συζήτηση των περιορισμών και της μελλοντικής εργασίας. Τα σενάρια αυτής της μελέτης θα δημοσιοποιηθούν.', 'ka': 'ეს დოკუმენტი ილუსტრისტურებს ჰუვავის სამუშაოდ WMT20 პარალელური კოპლისური ფილტრინტის დამატებული დავალება. ჩვენი პროგრამის შესახებ პროქსი დავალების სწავლისთვის განვითარებაში მრავალენგური წინატრიქტირებული მრავალენგური წინატრიქტირებული მოდელზე, რომელიც ფულტრიქტირების შესაძლებლობას ასეთი მონაცემული დავალება გვეხმარებს, რომ უფრო ბეჭირად გადავიწყებთ, ვიდრე მსგავსი ნეიროლური მაქინის გადატვირთვალის სისტემის გამოყენება იგივე შემდეგ ემპერიკური ანალიზების შემდეგ, ჩვენ ჩვენი წარმოდგენების გადასრულებით წარმოდგენების წარმოდგენებით. ეს დოკუმენტი გადასრულებულია განსაზღვრებით და მომავალეთ სამუშაო განსაზღვრებით. სკრიპტი ამ სწავლებისთვის იქნება ადამიანის ხელსახულება.', 'hu': 'Ez a tanulmány bemutatja, hogy a Huawei a WMT20 alacsony erőforrású párhuzamos korpusz szűrési megosztott feladatnak való benyújtását. Megközelítésünk középpontjában egy proxy feladat tanuló fejlesztése áll egy transzformátor alapú, többnyelvű, előre képzett nyelvi modell tetején, hogy növelje a zajos párhuzamos corporák szűrési képességét. Egy ilyen felügyelt feladat segít abban is, hogy sokkal gyorsabban ismételjünk, mint egy meglévő neurális gépi fordító rendszer használata ugyanezen feladat elvégzéséhez. A finomhangolási feladat empirikus elemzését követően megközelítésünket úgy hasonlítjuk össze, hogy összehasonlítjuk az eredményeket az elmúlt évek korszerű rekordjaival. Ez a tanulmány a korlátokról és a jövőbeli munkáról szóló vitával zárul. A tanulmány forgatókönyveit nyilvánosan hozzáférhetővé teszik.', 'it': "Questo articolo illustra la sottomissione di Huawei all'attività condivisa di filtraggio parallelo WMT20 a basso contenuto di risorse. Il nostro approccio si concentra sullo sviluppo di uno studente proxy task in cima a un modello linguistico pre-addestrato multilingue basato su trasformatori per aumentare la capacità di filtraggio dei corpi paralleli rumorosi. Un tale compito supervisionato ci aiuta anche a iterare molto più rapidamente rispetto all'utilizzo di un sistema di traduzione automatica neurale esistente per eseguire lo stesso compito. Dopo aver eseguito analisi empiriche del compito di finetuning, valutiamo il nostro approccio confrontando i risultati con i record di stato dell'arte degli anni passati. Questo articolo si conclude con una discussione sui limiti e sul lavoro futuro. Gli script di questo studio saranno resi pubblici.", 'lt': 'Šis dokumentas parodo Huawei pateiktą WMT20 mažai išteklių lygiagrečios korpuso filtravimo užduotį. Mūsų požiūris daugiausia dėmesio skiria proxy užduočių mokytojo plėtojimui, kuris papildytų transformatoriumi pagrįstą daugiakalbį iš anksto parengtą kalbų model į, kad būtų sustiprintas triukšmingų lygiagrečių korprų filtravimo pajėgumas. Such a supervised task also helps us to iterate much more quickly than using an existing neural machine translation system to perform the same task.  Atlikę empirinę tikslinimo užduoties analizę, lyginame savo požiūrį palygindami rezultatus su praėjusių metų būsenos įrašais. Šis dokumentas baigiasi diskusijomis apie apribojimus ir būsimą darbą. Šio tyrimo scenarijai bus paskelbti viešai.', 'kk': 'Бұл қағаз Huawei- ның WMT20- нің төмен ресурстар параллелі корпус сүзгісін ортақтастыру тапсырмасына сүзгіледі. Біздің қасиетіміз прокси тапсырманы оқытуға көптеген көптілік алдын- оқылған тіл үлгісінің үстінен ауыстыру үшін, параллель корпораға сүзгілеу мүмкіндігін көтеру үшін кө Бұл басқару тапсырмасы да бір тапсырманы орындау үшін невралдық компьютерді аудару жүйесін қолдану үшін көмектеседі. Тапсырманың эмпирикалық анализацияларынан кейін, өткен жылдың күй- жай жазуларымызды салыстырып, өткен жазуларымызды салыстырып тұрамыз. Бұл қағаз шектеулерді және болашақ жұмыс туралы талқылады. Бұл зерттеулердің скрипттері жалпы жеткізіледі.', 'ml': 'ഈ പത്രത്തില്\u200d ഹുവായിയുടെ കീഴ്പെടുത്തുന്നത് WMT20 ലേക്ക് കുറഞ്ഞ വിഭവങ്ങള്\u200d പാരാളല്\u200d കോര്\u200dപ്പുസ് ഫില്\u200dറ്റര്\u200dട് നമ്മുടെ പ്രോക്സി ജോലി പഠിപ്പിക്കുന്നതിന് ശ്രദ്ധിക്കുന്നത് മുകളില്\u200d മാറ്റിമാറ്റങ്ങള്\u200d അടിസ്ഥാനമാക്കുന്ന പല ഭാഷ മോഡലിന്റെ മുകളിലാ ഇത്തരം നിരീക്ഷിക്കപ്പെട്ട ജോലിയും ഒരേ ജോലി പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനെക്കാള്\u200d നിലവിലുള്ള ന്യൂറല്\u200d മെഷീന്\u200d പരിഭ മുന്\u200dകൂട്ടുന്ന ജോലിയുടെ കാര്യത്തില്\u200d ശാസ്ത്രീകരണങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിച്ചശേഷം, കഴിഞ്ഞ വര്\u200dഷങ്ങളുടെ സ്ഥിതിയുടെ രേഖകള്\u200d  ഈ പത്രത്തില്\u200d പരിധികളെയും ഭാവിയുടെ ജോലിയെയും സംസാരിക്കുന്ന ഒരു ചര്\u200dച്ച ചെയ്യുന്നു. ഈ പഠനത്തിന്റെ സ്ക്രിപ്റ്റുകള്\u200d പ്രശസ്തമായി ലഭ്യമാക്കും.', 'ms': 'Kertas ini menunjukkan penghantaran Huawei ke tugas kongsi penapisan corpus sumber rendah-paralel WMT20. Our approach focuses on developing a proxy task learner on top of a transformer-based multilingual pre-trained language model to boost the filtering capability for noisy parallel corpora.  Tugas tersebut juga membantu kita mengulang lebih cepat daripada menggunakan sistem terjemahan mesin saraf yang ada untuk melakukan tugas yang sama. Selepas melakukan analisis empirik tugas penyesuaian, kita benchmark pendekatan kita dengan membandingkan hasil dengan rekod tahun-tahun terakhir. Kertas ini dibungkus dengan perbincangan terhadap keterangan dan kerja masa depan. Skrip untuk kajian ini akan diterima secara umum.', 'mk': "This paper illustrates Huawei's submission to the WMT20 low-resource parallel corpus filtering shared task.  Нашиот пристап се фокусира на развојот на прокси-ученик на задачи на врвот на мултијазичен предобучен јазик модел базиран на трансформатори за зајакнување на способноста за филтрирање на бучни паралелни корпора. Таква надгледувана задача, исто така, ни помага да ја повториме многу побрзо отколку да користиме постоечки систем на превод на неврални машини за да ја извршиме истата задача. По спроведувањето емпирички анализи на задачата за финетизирање, го споредуваме нашиот пристап споредувајќи ги резултатите со минатите години на состојба на театрот. Овој весник завршува со дискусија за ограничувања и идна работа. Скриптите за оваа студија ќе бидат јавно достапни.", 'mt': "Dan id-dokument juri s-sottomissjoni ta' Huawei lill-kompitu kondiviż ta' filtrazzjoni ta' korpus paralleli b'riżorsi baxxi tad-WMT20. L-approċċ tagħna jiffoka fuq l-iżvilupp ta’ apprendist ta’ kompiti proxy fuq mudell multilingwi mħarreġ minn qabel ibbażat fuq it-trasformatur biex isaħħa ħ il-kapaċità ta’ filtrazzjoni għal korpra parallel a storbjuża. Tali kompitu sorveljat jgħinuna wkoll nititeraw ħafna aktar malajr milli tuża sistema eżistenti ta’ traduzzjoni ta’ magni newrali biex twettaq l-istess kompitu. Wara li nagħmlu analiżi empirika tal-kompitu ta’ rfinar, nagħmlu referenza għall-approċċ tagħna billi nqabblu r-riżultati mar-rekords attwali tas-snin li għaddew. Dan id-dokument jikkonkludi diskussjoni dwar il-limitazzjonijiet u x-xogħol futur. L-iskripti għal dan l-istudju se jkunu disponibbli għall-pubbliku.", 'no': 'Denne papiret illustrerer Huawei sin tilføring til WMT20- parallelle korpusfiltrering av delte oppgåve i låg ressursar. Tilnærminga vårt fokuserer på å utvikla ein mellomtenar-oppgåvelærar på toppen av ein transformeringsbasert fleirspråk-foretrekkt språk-modell for å auka filteret for støyparallelle korpora. Ein oversikt oppgåve hjelper oss også å gjentaka mykje raskere enn å bruka eit eksisterande neuralmaskinsomsetjingssystem for å utføra det same oppgåve. Etter å utføra empiriske analyser av finetuning-oppgåva, benchmarkerer vi tilnærminga vårt ved å sammenligne resultatet med tidlegare årstilstand-oppgåver. Denne papiret brytar opp med eit diskusjon om grenser og framtidige arbeid. Skriptene for denne studien vil bli tilgjengeleg offentlig.', 'pl': 'Niniejszy artykuł ilustruje zgłoszenie Huawei do wspólnego zadania filtrowania korpusu o niskich zasobach WMT20. Nasze podejście koncentruje się na opracowaniu uczącego się zadań proxy na szczycie opartego na transformatorze wielojęzycznego, wstępnie przeszkolonego modelu językowego, aby zwiększyć możliwość filtrowania dla hałaśliwych korpusów równoległych. Takie nadzorowane zadanie pomaga nam również iterować znacznie szybciej niż wykorzystanie istniejącego neuronowego systemu tłumaczenia maszynowego do wykonywania tego samego zadania. Po przeprowadzeniu empirycznych analiz zadania precyzyjnego, porównujemy nasze podejście poprzez porównanie wyników z zapisami z ostatnich lat. Niniejszy artykuł kończy się dyskusją na temat ograniczeń i przyszłych prac. Scenariusze do tego badania zostaną udostępnione publicznie.', 'mn': 'Энэ цаас Huawei-ын WMT20-д бага боловсролын параллел корпус цэвэрлэх ажлыг харуулдаг. Бидний арга барилга нь прокси ажлын сурагч боловсруулагч болох олон хэл дээр сургалтын өмнө сургалтын загварын дээд төвлөрүүлж байгаа юм. Ийм ажил нь бидэнд ижил ажил хийхээс илүү хурдан давтах боломжтой. Үүний үр дүнг өнгөрсөн жилийн урлагийн бичлэгтэй харьцуулахад бид ажлыг эзэмшигтэй шинжилгээний дараа багтана. Энэ цаас хязгаарлалт болон ирээдүйн ажлын талаар ярилцдаг. Энэ судалгааны бичгийг олон нийтэд ашиглах болно.', 'sr': 'Ovaj papir ilustruje podnošenje Huaweijevog podnošenja WMT20 paralelnom korpusu filtriranju zajedničkog zadatka. Naš pristup se fokusira na razvoj učitelja proksijskih zadataka na vrhu multijezičkog predobučenog jezičkog model a na transformaciji kako bi povećala filtriranje sposobnosti za buku paralelnu korporu. Takav nadzorni zadatak nam takođe pomaže da ponovimo mnogo brže nego da koristimo postojeći sistem neuronskog prevoda mašine kako bi izvršili isti zadatak. Nakon što smo izvršili empiričke analize zadatka finetuniranja, uspoređujemo naš pristup uspoređivanjem rezultata sa prošlim godinama podacima o stanju umetnosti. Ovaj papir završava sa raspravom o ograničenjima i budućim poslovima. Skriptovi za ovu studiju biće publicno dostupni.', 'ro': 'Această lucrare ilustrează supunerea Huawei la activitatea partajată de filtrare paralelă a corpurilor WMT20 cu resurse reduse. Abordarea noastră se concentrează pe dezvoltarea unui elev proxy sarcini pe partea de sus a unui model de limbă multilingvă pre-instruit bazat pe transformator pentru a spori capacitatea de filtrare a corpurilor paralele zgomotoase. O astfel de sarcină supravegheată ne ajută, de asemenea, să iterăm mult mai rapid decât utilizarea unui sistem de traducere automată neurală existent pentru a efectua aceeași sarcină. După efectuarea analizelor empirice ale sarcinii de fintuning, analizăm abordarea noastră prin compararea rezultatelor cu înregistrările din ultimii ani. Această lucrare se încheie cu o discuție despre limitări și munca viitoare. Scripturile pentru acest studiu vor fi puse la dispoziția publicului.', 'si': 'මේ පැත්තේ හුවේයිගේ පිළිබඳුම WMT20 අඩු සමාන්\u200dය සමාන්\u200dය කොර්පුස් පිළිබඳු වැඩසටහන් වෙනුවෙන්. අපේ ප්\u200dරොක්සි වැඩක් ඉගෙන ගන්න ප්\u200dරොක්සි වැඩක් ඉගෙන ගන්න ප්\u200dරොක්සි වැඩක් ඉගෙන ගන්න ප්\u200dරොක්සි වැඩක් වෙනුවෙන් ප්\u200dරොක්සි වැඩක මෙච්චර පරීක්ෂා කරපු වැඩක් අපිට එකම වැඩක් කරන්න පුළුවන් ඉක්මනට වඩා ඉක්මනින් ඉක්මන් වෙන්න උදව් කරනවා. අන්තිම විශ්ලේෂණ කරපු පස්සේ අපි අවුරුද්ධ විශ්ලේෂණ කරපු විදිහට පස්සේ අවුරුද්ධ අවුරුද්ධ විස්තාරය සමග ප්\u200dර මේ පත්තුව සීමාව සහ අනාගතය වැඩක් ගැන කතා කරනවා. මේ පරීක්ෂණය සඳහා ස්ක්\u200dරිප්ට් ප්\u200dරතිකාරයෙන් ප්\u200dරතිකාරයෙන් ලැබෙන්න පුළුවන්.', 'sv': 'Denna uppsats illustrerar Huaweis underkastelse till WMT20 låg resurs parallell korpusfiltrering delad uppgift. Vårt tillvägagångssätt fokuserar på att utveckla en proxy uppgiftslärare ovanpå en transformatorbaserad flerspråkig förklädd språkmodell för att öka filtreringsförmågan för bullriga parallella korpora. En sådan övervakad uppgift hjälper oss också att iterera mycket snabbare än att använda ett befintligt neuralt maskinöversättningssystem för att utföra samma uppgift. Efter att ha utfört empiriska analyser av finjusteringsuppgiften benchmarkar vi vårt tillvägagångssätt genom att jämföra resultaten med tidigare års state-of-the-art rekord. Denna uppsats avslutas med en diskussion om begränsningar och framtida arbete. Manuskripten till denna studie kommer att göras offentligt tillgängliga.', 'ta': 'இந்த தாள் WMT20 குறைந்த மூலத்திற்கு குறைந்த இணைப்பு கோர்ப்ஸ் வடிகட்டி பகிர்ந்த பணியை குறிப்பிடுகிறது. எங்கள் செயல்பாடு மாற்றத்தை மாற்றும் முன் பயிற்சி மொழி மாதிரியின் மேல் ஒரு ப்ராக்சி பணி கற்றுக்கொள்ளும் மேல் கவனம் செலுத்துகிறது சப்தம இத்தகைய கண்காணிக்கப்பட்ட செயல் அதே செயலை செய்ய ஒரு இருக்கும் புதிய கணினி மொழிபெயர்ப்பு அமைப்பை பயன்படுத்தி விட அதிக வேகம முன்னேற்றும் வேலையை முடிக்கும் பிறகு, கடந்த வருடங்களின் நிலையில் திட்டம் பதிவுகளை ஒப்பிடும் மூலம் நாம் எங்கள் வழியை குறி இந்த தாள் எல்லைகளையும் எதிர்கால வேலையையும் பற்றி ஒரு விவாதத்தை மூடுகிறது. இந்த படிப்பாட்டிற்கான சிறுநிரல்கள் பொதுவாக கிடைக்கப்படும்.', 'so': 'Warqaddan waxaa looga jeedaa in Huawei uu u dhiibo WMT20 hoos-resource parallel corpus filtering sharciga ah. Dhaqdhaqaaqyadeenu waxay ku hagaysaa horumarinta shaqo proxy ah oo ku qoran model af kala duwan oo af kala duduwan ah, si uu u kordhiyo awoodda filteritaanka ee shirkadda qaylada oo siman. Shaqada maamulka ah waxaa sidoo kale inaga caawinaya in aad si dhaqso ah u sameyn karto nidaamka turjumista maskinada ee jiraya si uu u sameeyo isku shaqo. Markaas kadib waxaynu sameynnaa baaritaanka qiimeynta shaqada hore, waxaynu soo bandhignaynaa dhaqdhaqaalahayaga si aynu ugu barbaranayno arimaha sameynta xaaladda farshaxanka ee sanadkii hore. Kanu wuxuu ku qoran yahay sheekeysi xadiiqada iyo shaqada mustaqbalka ah. Shaqadaha waxbarashadan waxaa si bayaan ah loo heli karaa.', 'ur': 'یہ کاغذ ہوائئی کے مطابق WMT20 کم منطقی کورپوس فیلٹرینگ کے مشترک کام کی تصویر کرتا ہے. ہمارا طریقہ ایک پیروکسی تاسک یادگار کو تغییر دینے والی multilingual pre-trained زبان کی مدل کے اوپر تغییر دینے والی ایک پیروکسی تاسک یادگار کی تغییر دینے کے لئے تمرکز کرتا ہے کہ آواز پارالیل کورورا کے لئے فیلٹر اس طرح ایک نظارت کی تابع ہمیں اس سے زیادہ سریع تکرار کرنے کی مدد کرتی ہے کہ ایک ہی تابع کریں۔ ہم نے اچھے سالوں کی حالت ریکورد کے مطابق نتیجے کا مقایسہ کر کے اپنے طریقے کو سنچم لیا۔ یہ کاغذ محدودیت اور مستقبل کام کے بارے میں ایک بحث پر پورا ہوتا ہے۔ اس پڑھنے کے لیے کتاب کھول کھول دیے جائیں گے', 'uz': "Bu qogʻoz Huawei WMT20 yordamida qisqa manba parametrlar filterini koʻrsatish mumkin. Bizning fikrimimiz proksi vazifani o'rganishga o'zgarishga o'rganish bir necha tildan oldingi tilning modelini o'rganish uchun filterlash qobiliyatini oshirish mumkin. Bu yerda taʼminlovchi vazifa bu vazifani shu vazifani bajarish uchun juda tez tez qilishiga yordam beradi. Bu vazifani aniqlashni bajarishdan keyin biz past yillar davlat haqida o'xshash natijalarimizni o'rganamiz. Bu qogʻoz cheksiz va kelajakdagi ishni taqdim qiladi. Ushbu studio uchun skriptlar toʻgʻri mavjud boʻladi.", 'vi': 'Tờ giấy này minh họa việc Hoài Cảnh giao cho WM2h0 việc chia s ẻ tập tin siêu nhỏ. Cách tiếp cận của chúng ta tập trung vào việc phát triển tập tin ủy nhiệm trên đỉnh của mô hình ngôn ngữ đa dạng chuyển thế dựa trên để tăng cường khả năng lọc cho tính năng đồng thể ồn ào. Một nhiệm vụ được giám sát này cũng giúp chúng tôi lặp lại nhanh hơn nhiều so với sử dụng một hệ thống dịch chuyển máy thần kinh tồn tại để thực hiện cùng một nhiệm vụ. Sau khi thực hiện các phân tích hành động khi nghiên cứu cẩn thận, chúng tôi so sánh phương pháp của chúng tôi bằng cách so sánh kết quả với hồ sơ tình trạng của năm trước. Bài báo này kết thúc với một cuộc thảo luận về giới hạn và công việc tương lai. Các tập lệnh cho nghiên cứu này sẽ được công khai.', 'bg': 'Тази статия илюстрира представянето на Уайвай на споделената задача за филтриране на паралелни корпуси с нисък ресурс. Нашият подход се фокусира върху разработването на прокси задача обучаващ се върху трансформаторно базиран многоезичен предварително обучен езиков модел, за да се подобри способността за филтриране на шумни паралелни корпуси. Подобна надзорна задача също ни помага да итерираме много по-бързо, отколкото да използваме съществуваща система за невронен машинен превод, за да изпълним същата задача. След извършване на емпирични анализи на задачата за фина настройка, сравняваме нашия подход с резултатите от последните години. Тази статия завършва с дискусия за ограниченията и бъдещата работа. Сценарите за това изследване ще бъдат публично достъпни.', 'da': 'Denne artikel illustrerer Huaweis indlæg til WMT20 low-resource parallel corpus filtrering delt opgave. Vores tilgang fokuserer på at udvikle en proxy opgave elev oven på en transformer-baseret flersproget prætrænet sprogmodel for at øge filtreringsevnen for støjende parallelle korpora. En sådan overvåget opgave hjælper os også med at gentage meget hurtigere end at bruge et eksisterende neuralt maskinoversættelsessystem til at udføre den samme opgave. Efter at have udført empiriske analyser af finjusteringsopgaven sammenligner vi vores tilgang ved at sammenligne resultaterne med tidligere års state-of-theart records. Denne artikel afsluttes med en diskussion om begrænsninger og fremtidigt arbejde. Manuskripterne til denne undersøgelse vil blive gjort offentligt tilgængelige.', 'nl': "Dit document illustreert Huawei's inzending aan de WMT20 low-resource parallelle corpusfiltering gedeelde taak. Onze aanpak richt zich op het ontwikkelen van een proxy task leaner bovenop een transformator-gebaseerd meertalig voorgetraind taalmodel om de filtercapaciteit voor ruige parallelle corpora's te verbeteren. Zo'n begeleide taak helpt ons ook om veel sneller te itereren dan het gebruik van een bestaand neural machine translation systeem om dezelfde taak uit te voeren. Na het uitvoeren van empirische analyses van de finetuning-taak, benchmarken we onze aanpak door de resultaten te vergelijken met de stand-of-the-art records van afgelopen jaren. Dit artikel sluit af met een discussie over beperkingen en toekomstig werk. De scripts voor deze studie worden openbaar gemaakt.", 'hr': 'Ovaj papir ilustruje podnošenje Huaweijeva podnošenje WMT20 paralelnom korpusu filtriranju zajedničkog zadatka. Naš pristup se fokusira na razvoj učitelja proksičnih zadataka na vrhu multijezičkog predobučenog jezičkog model a na transformatoru kako bi se povećala filtriranje sposobnosti za buku paralelnu korporu. Takav nadzorni zadatak nam također pomaže da ponovimo mnogo brže nego koristimo postojeći sustav prevoda neuralnih strojeva kako bi izvršili isti zadatak. Nakon provođenja empiričkih analiza zadatka finetuniranja, mi smo povezani naš pristup uspoređivanjem rezultata s prošlim godinama podacima o stanju umjetnosti. Ovaj papir završava raspravom o ograničenjima i budućem radu. Skriptovi za ovu studiju bit će publicno dostupni.', 'id': "Kertas ini menunjukkan pengiriman Huawei ke WMT20 sumber daya rendah paralel corpus penyaringan tugas berbagi. Pendekatan kami fokus pada mengembangkan pembelajar tugas proksi di atas model bahasa multibahasa berdasarkan transformer yang dilatih untuk meningkatkan kemampuan filtrasi untuk kopora paralel berisik. Tugas tersebut juga membantu kita untuk mengulang lebih cepat daripada menggunakan sistem terjemahan mesin saraf yang ada untuk melakukan tugas yang sama. After performing empirical analyses of the finetuning task, we benchmark our approach by comparing the results with past years' state-of-theart records.  Kertas ini mengakhiri diskusi tentang batasan dan pekerjaan masa depan. Skrip untuk studi ini akan dibuat publik tersedia.", 'de': "Dieses Papier veranschaulicht Huawei's Einreichung zur WMT20 Low-Resource Parallel Corpus Filtering Shared Task. Unser Ansatz konzentriert sich auf die Entwicklung eines Proxy-Task-Lernenden auf Basis eines transformatorbasierten mehrsprachigen vortrainierten Sprachmodells, um die Filterfähigkeit für laute parallele Korpora zu verbessern. Eine solche überwachte Aufgabe hilft uns auch, viel schneller zu iterieren, als mit einem bestehenden neuronalen maschinellen Übersetzungssystem dieselbe Aufgabe auszuführen. Nach empirischen Analysen der Feinabstimmungsaufgabe vergleichen wir unseren Ansatz, indem wir die Ergebnisse mit dem Stand der letzten Jahre vergleichen. Dieser Beitrag schließt mit einer Diskussion über Grenzen und zukünftige Arbeiten ab. Die Skripte für diese Studie werden öffentlich zugänglich gemacht.", 'ko': '본고는 화웨이가 WMT20 저자원 병행 자료 라이브러리에 공유 임무를 제출하는 과정을 논술했다.우리의 방법은 변환기를 바탕으로 하는 다중 언어 예비 훈련 언어 모델을 바탕으로 대리 임무 학습기를 개발하여 소음 병행 자료 라이브러리에 대한 필터 능력을 강화하는 데 중심을 두었다.기존의 신경기계 번역 시스템을 사용하여 같은 임무를 수행하는 것보다 이런 감독적인 임무는 우리가 더욱 빨리 교체하는 것을 도울 수 있다.마이크로 조정 임무에 대해 실증 분석을 한 후에 우리는 결과를 과거 몇 년 동안의 선진 기록과 비교하고 우리의 방법에 대해 기준 테스트를 실시했다.본고는 마지막으로 한계성과 미래의 일을 토론하였다.이 연구의 각본은 공개될 것이다.', 'fa': 'این کاغذ نشان می\u200cدهد که تسلیم Huawei را به کار مشترک فیلتر کردن کورپوس کم\u200cمنبع WMT20 نشان می\u200cدهد. دستور ما روی توسعه کردن یک یادگیر کار پروکسی روی یک مدل پیش آموزش زبانی متغییر زبان متغییر شده است تا بتواند توانایی فیلترینگ برای شرکت پارالی صوتی افزایش دهد. این وظیفه تحت نظر همچنین به ما کمک می کند که سریع تر از استفاده از یک سیستم ترجمه ماشین عصبی موجود باشیم تا یک وظیفه را انجام دهیم. بعد از تحلیل امپراتیکی از وظیفه\u200cای که نیکوکار می\u200cشود، با مقایسه کردن نتیجه\u200cها با ثبت\u200cهای سال\u200cهای گذشته، روش\u200cهایمان را ترکیب می\u200cکنیم. این کاغذ با بحث محدودیت و کار آینده بسته است. نامه\u200cهایی برای این مطالعه به طور عمومی دسترسی می\u200cشود.', 'sw': 'Gazeti hili linaonyesha ujumbe wa Huawei uliofanywa na vyanzo vya chini vya WMT20 vilivyofanana na kuchuja vifaa vya fedha vilivyosambazwa. Hatua yetu inakusudia kutengeneza mwandishi wa kazi za proxy juu ya modeli ya lugha iliyoendeshwa kwa lugha mbalimbali ili kuongeza uwezo wa kuchuja filamu kwa kampuni inayofanana na kelele. Kazi hiyo inayofuatiliwa pia inatusaidia kutengeneza haraka zaidi ya kutumia mfumo wa kutafsiri mashine ya kijamii kufanya kazi moja. Baada ya kufanya uchambuzi wa msisitizo wa kazi hiyo, tunaweka hatua yetu kwa kulinganisha matokeo na rekodi za sanaa zilizopita. Gazeti hili linajumuisha mjadala wa mipaka na kazi za baadaye. Makala kwa utafiti huu yatapatikana hadharani.', 'af': "Hierdie papier illustreer Huawei se onderwerp na die WMT20 lae hulpbron parallele korpusfiltering gedeelde taak. Name Ons toegang fokus op die ontwikkeling van 'n volmag taak leerder op bo van' n transformeerder-gebaseerde multitaal voor-opgelei taal model om die filtering kapasiteit vir geluid parallele korpora te vermeerder. So 'n ondersoekte taak help ons ook om baie vinniger te herhaal as 'n bestaande neurale masjien vertaling stelsel te gebruik om dieselfde taak te doen. Na die uitvoer van empiriese analiserings van die finetuning opdrag, ons benchmark ons toegang deur die resultate te vergelyk met die verlede jaar se staat van die kunstenrekord. Hierdie papier oorvloei met 'n diskusie van beperkings en toekomstige werk. Die skripte vir hierdie studie sal openlik beskikbaar word.", 'sq': 'Ky dokument ilustron dorëzimin e Huaweit ndaj detyrës s ë përbashkët të filtrimit të korpusit me burime të ulta paralele të WMT20. Përqasja jonë përqëndrohet në zhvillimin e një nxënësi të detyrave proxy në krye të një modeli gjuhësh shumë-gjuhësor të trajnuar përpara për të rritur aftësinë e filtrimit për korpra të zhurmshme paralele. Një detyrë e tillë e mbikqyrur na ndihmon gjithashtu të përsërisim shumë më shpejt sesa të përdorim një sistem ekzistues përkthimi i makinave nervore për të kryer të njëjtën detyrë. Pas kryerjes së analizave empirike të detyrës së përmirësimit, ne përcaktojmë qasjen tonë duke krahasuar rezultatet me regjistrimet e viteve të kaluara. Kjo letër përfundon me një diskutim të kufizimeve dhe punës së ardhshme. Skriptet për këtë studim do të jenë të disponueshme publikisht.', 'am': 'ይህ ገጽ Huawei የWMT20 ዋናው የኮርፓስ አጣራ የተካፈለውን ስራ ማሳየት የሚያሳውቃታል፡፡ የደረጃችን ሥርዓት ለድምፅ በተለወጠው የቋንቋ ቋንቋ ሞዴሌ ላይ የፕሮክሲ ስራ የሚያስተማርን ማሳየት ለድምፅ ተቃውሞ የኮርፖርት ስልጣኑን ለማበዛት ነው፡፡ እንደዚህ የተጠበቀው ስራ ደግሞ አንድ ስራ ለመፈጸም የሚኖረውን የነዌብ መሣሪያን ትርጉም ስርዓት ከመጠቀም ይልቅ ፈጥኖ እንዲያሳየን ይረዳናል፡፡ የድምፅ አካባቢ ትርጓሜን በማስተካከል፣ የቀድሞው ዓመታት የራስ ሥርዓት ሀብት የመረጃ ታሪክ እናስተያየዋለን፡፡ ይህ ገጽ ግንኙነቶችን እና የመጨረሻውን ሥራ የተጠቃሚ ውይይት ነው፡፡ ለዚህ ትምህርት ጽሑፎች ግልፅ ይደረጋሉ።', 'hy': "Այս թղթին ցույց է տալիս Հուավեյի ներկայացումը ԱՄԹ20-ի ցածր ռեսուրսներով զուգահեռ կորպուսի ֆիլտրող ընդհանուր խնդիրը: Մեր մոտեցումը կենտրոնանում է պրոքսի առաջադրանքի ուսանողի զարգացմանը վերևում է վերափոխողի հիմնված բազմալեզու նախապատրաստված լեզվի մոդելի, որպեսզի բարձրացվի աղմկոտ զուգահեռ մարմնի ֆիլտրող ունակությունը Այսպիսի վերահսկված խնդիր նաև օգնում է մեզ ավելի արագ կրկնվել, քան օգտագործել գոյություն ունեցող նյարդային մեքենայի թարգմանման համակարգը նույն խնդիրը կատարելու համար: Փաստավորման խնդրի էմպիրիկ վերլուծություններից հետո մենք համեմատում ենք մեր մոտեցումը' համեմատելով արդյունքները անցյալ տարիների թատրոնային ձայնագրությունների հետ: Այս աշխատանքը ավարտվում է սահմանափակումների և ապագա աշխատանքի քննարկումների հետ: Այս ուսումնասիրության գրքերը հասանելի կլինեն:", 'az': "Bu kağıt Huawei'nin WMT20-nin düşük kaynağı paralel korpus filtrləyici işini göstərir. Bizim tərəfimiz bir proksi işin öyrənməsinə çoxlu dil əvvəl təhsil edilmiş dil modelinin üstündə təhsil edir ki, səs paralel korpora üçün filtrləmə qabiliyyətini artırsın. Bu təhlükəsizli işlər həmçinin aynı işləri yerinə yetirmək üçün mevcut bir nöral maşına çevirmə sistemini istifadə etməkdən daha tez təkrarlanmamıza kömək edir. İmpariki analizi etdikdən sonra, sonuçlarımızı son illərin müəyyən məlumatı ilə qarşılaşdırmaq üçün özümüzə yaxınlığımızı çəkirik. Bu kağıt hədləri və gələcək işlər barəsində mübahisə edir. Bu təhsil üçün yazılar açıq-aşkar mövcud ediləcək.", 'tr': "Bu kagyz Huaweiniň WMT20'a eýik resurslary parallel korpus filtreşigini görkezýär. Biziň ýaryşymyz vekili täzim öwrenmegi çykyşymyza, çerçewletli öňünden bilim öňünden bilim öwrenmegi üçin filtrelemek üçin parallel korpora mümkinçilik ukyplaryny bejermek üçin fokus edýär. Bärde gözetlenýän zady hem bolan neural maşynyň terjime sistemini bir zady edip bilmek üçin bize kömekleyär. Iňlemeli zadyň empirik analyzasyny çykardan soňra, netijelerimizi geçen ýylyň durum-teorisi kayıtlary bilen gurlap çykýarys. Bu kagyz çykyşlar we gelejekde işler barada gürrüňleýär. Bu okuw üçin skriptler publika meşgullanar.", 'bs': 'Ovaj papir ilustruje podnošenje Huaweijeva podnošenje WMT20 paralelnom korpusu filtriranju zajedničkog zadatka. Naš pristup se fokusira na razvoj učitelja proksijskih zadataka na vrhu multijezičkog predobučenog jezičkog model a na transformaciji kako bi povećala filtriranje sposobnosti za buku paralelnu korporu. Takav nadzorni zadatak nam također pomaže da ponovimo mnogo brže nego da koristimo postojeći sustav prevoda neuralnih strojeva kako bi izvršili isti zadatak. Nakon što smo izvršili empiričke analize zadatka finetuniranja, uspoređujemo naš pristup uspoređivanjem rezultata sa prošlim godinama podacima o stanju umjetnosti. Ovaj papir završava sa raspravom o ograničenjima i budućim radovima. Skriptovi za ovu studiju biće publicno dostupni.', 'bn': 'এই পত্রিকাটি উইএমটি২০ নীচের রিসোর্স প্যারালেল কোর্পাস ফিল্টারিং শেয়ার কর্মসূচীর প্রতি হুয়াই-এর প্রতি জমা দি আমাদের প্রতিক্রিয়া একটি প্রক্সি কাজ শিক্ষার উপর মনোযোগ প্রদান করেছে একটি পরিবর্তনের ভিত্তিক ভিত্তিক বহুভাষী প্রশিক্ষিত ভাষার মডেলের উপর যাতে আওয়া Such a supervised task also helps us to iterate much more quickly than using an existing neural machine translation system to perform the same task.  বিশেষ কর্মসূচীর বিশ্লেষণের পরে আমরা গত বছরের রাষ্ট্রের রেকর্ডের সাথে তুলনা করে আমাদের পদক্ষেপের মাধ্যমে ক্ষমা করি। এই পত্রিকাটি সীমাবদ্ধ এবং ভবিষ্যতের কাজের আলোচনার সাথে লেখা আছে। এই গবেষণার জন্য স্ক্রিপ্ট প্রকাশ করা হবে।', 'ca': "This paper illustrates Huawei's submission to the WMT20 low-resource parallel corpus filtering shared task.  El nostre enfocament es centra en desenvolupar un aprenent de tasques proxy a sobre d'un model de llenguatge multillenguatge pré-entrenat basat en transformadors per reforçar la capacitat de filtració de corpores paralèls ruidosos. Such a supervised task also helps us to iterate much more quickly than using an existing neural machine translation system to perform the same task.  Després de fer anàlisis empíriques de la tasca d'ajustament, comparem el nostre enfocament comparant els resultats amb els registres actuals dels últims anys. Aquest paper acaba amb una discussió sobre limitacions i treball futur. Les escriptures d'aquest estudi estaran publicades.", 'cs': 'Tento článek ilustruje podání společnosti Huawei ke sdílenému úkolu WMT20 s nízkými zdroji paralelního korpusového filtrování. Náš přístup se zaměřuje na vývoj učitele proxy úloh na vrcholu transformátorového vícejazyčného předškoleného jazykového modelu, který zvýší schopnost filtrování hlučných paralelních korpusů. Takový kontrolovaný úkol nám také pomáhá iterovat mnohem rychleji než použití stávajícího neuronového strojového překladu k provedení stejného úkolu. Po provedení empirických analýz úlohy jemného ladění porovnáme náš přístup porovnáním výsledků se záznamy z minulých let. Tento článek zakončuje diskusi o omezeních a budoucí práci. Scénáře této studie budou zpřístupněny veřejně.', 'et': 'Käesolevas artiklis illustreeritakse Huawei esitamist WMT20 vähese ressursiga paralleelse korpuse filtreerimise ühisülesandele. Meie lähenemisviis keskendub proxy ülesande õppija arendamisele transformaatoril põhineva mitmekeelse eelõpetatud keelemudeli peal, et suurendada mürakate paralleelsete korpuste filtreerimisvõimet. Selline järelevalveülesanne aitab meil ka itereerida palju kiiremini kui kasutada olemasolevat neuromasintõlkesüsteemi sama ülesande täitmiseks. Pärast peenhäälestusülesande empiirilisi analüüse võrdleme oma lähenemisviisi, võrreldes tulemusi eelmiste aastate olukorra kirjetega. Käesolev raamat lõpetab arutelu piirangute ja tulevase töö. Käesoleva uuringu skriptid tehakse avalikkusele kättesaadavaks.', 'fi': 'Tämä artikkeli havainnollistaa Huawein siirtymistä WMT20:n vähäresurssiseen rinnakkaiskorpussuodatukseen jaettuun tehtävään. Lähestymistapamme keskittyy kehittämään proxy-tehtäväoppijaa muuntajapohjaisen monikielisen esikoulutetun kielimallin päälle, joka parantaa meluisten rinnakkaiskorpusten suodatusta. Tällainen valvottu tehtävä auttaa meitä myös iteroimaan paljon nopeammin kuin käyttämällä olemassa olevaa neurokonekäännösjärjestelmää saman tehtävän suorittamiseen. Suoritettuamme empiiriset analyysit hienosäätötehtävästä vertailemme lähestymistapaamme vertaamalla tuloksia edellisten vuosien nykytilanteeseen. Tämä paperi lopettaa keskustelun rajoituksista ja tulevasta työstä. Tämän tutkimuksen käsikirjoitukset julkistetaan.', 'sk': 'Ta prispevek ponazarja predložitev Huawei opravilu skupnega filtriranja vzporednih korpusov WMT20 z nizkimi viri. Naš pristop se osredotoča na razvoj posredniškega učenca na vrhu večjezičnega vnaprej usposobljenega jezikovnega modela, ki temelji na transformatorju, da bi povečal zmogljivost filtriranja hrupnih vzporednih korpusov. Takšna nadzorovana naloga nam pomaga tudi ponoviti veliko hitreje kot uporaba obstoječega sistema nevronskega strojnega prevajanja za opravljanje iste naloge. Po izvedbi empiričnih analiz naloge fine tuning primerjamo naš pristop s primerjavo rezultatov s stanjem zadnjih let. Ta prispevek zaključuje z razpravo o omejitvah in prihodnjem delu. Scenariji za to študijo bodo javno dostopni.', 'ha': "Wannan takardan na bayyana al'amarin Huewi zuwa WMT20 na wuri-resource da parallel Cornau filtering na raba aiki. Mataimakinmu na fokus a kan developer wani mai sanar da aikin proksi kan saman wani misalin na shifo-bakin mulki-lingui da aka sanar da shi na zaman-wa-zaman-lingui dõmin ya boost abincin filteriyar wa firam wa firam da shirin tsãwa. Wannan aikin wanda aka tsare shi yana taimakon mu da in samu'a matsayin farat ɗaya ko ya yi amfani da wani tsarin tarjibu na ƙarami wanda ke cikin maɓallin neural da ke gabatar da shi. Kayyan da ya cika rabo mai amfani da aikin finfintuation, sai mu haƙur da hanyarmu da sammenliki da matsala na-state-of-theart rekodi. Wannan takardan na rufe da wata jayayya masu husũma na kanana da aikin ajalin. The scripts for this study will be made publicly available.", 'he': "This paper illustrates Huawei's submission to the WMT20 low-resource parallel corpus filtering shared task.  הגישה שלנו מתמקדת בפיתוח לומד משימות פרוקסי על גבי מודל שפת רב-שפתי מואמן מראש מבוסס על מעבר משימה שכזו מושגת גם עוזרת לנו לחזור הרבה יותר מהר מאשר להשתמש במערכת התרגום של מכונות עצביות קיימת כדי לבצע את אותה משימה. לאחר שעשינו ניתוחים אמפיריים של המשימה המיוחדת, אנו שווים את הגישה שלנו על ידי השוואה של התוצאות עם רשומות המצב של התיארט של השנים האחרונות. העיתון הזה מסתיים עם דיון על הגבלות ועבודה עתידית. התסריטים למחקר הזה יהיו פנויים לציבור.", 'jv': 'Perkara iki dipulutan nganggo tresnaning nang huawei nang daftar perangkalan karo koyo barang dumadhi kawit karo perangkalan banget Awakdhéwé nggunakake kuwi nggawe proxy task lewat diungamulai supra padha multi-languangka sing basa supra-cadan kanggo ngubah bantuan ingkang dipoleraning kapasitaké kanggo ngilanggar bantuan. Laptop" and "Desktop Learn Mode Pamir iki wae wrap nganggo perusahaan kanggo nggunakaké lan mangkat apa. Seneng kanggo kelas nang ujaran iki bakal nggawe publika.', 'bo': "ཤོག་བྱང་འདིས་Huawei's submission་ཀྱི་ཉེ་ཆུང་ཉུང་བའི་རྒྱུ་དངོས་ཡུལ་ཆ་ཉུང་བའི་དབུལ་སྟངས་དང་མཉམ་དུ་བསྡུར་ཡོད། ང་ཚོའི་གཟུགས་སྐོར་ནི་ཚབ་བྱེད་ཀྱི་ལས་འགུལ་གྱི་ཤེས་པ་ཞིག་ལ་གཞི་བསྒྱུར་བའི་སྐད་རིགས་སྔོན་བསླབ་པའི་སྐད་ཡིག་ཐབས་ལམ་ལ་ཡར་བསྐྱེད་ འདིའི་ལྟ་རྟོག་བྱས་པའི་བྱ་འགུལ་གྱིས་ང་ཚོར་དུ་གནས་ཡོད་པའི་ནུས་པ་ལག་ལེན་འཐབ་རྩོད་འཁོར་གྱི་མ་ལག མཐའ་འཁོར་གྱི་ལས་འགུལ་གྱི་གནད་སྡུད་དབྱེ་ཞིབ་བྱེད་རྗེས་སུ། ང་ཚོས་རང་གི་ཐབས་ལམ་འདི་རྗེས་སུ་ཚོར་བ་དང་འདས་བའི་ལོ་ཚོགས་ཀྱི་ ཤོག་བྱང་འདིས་དུས་ཡོད་ཚད་དང་ང་ཚོའི་ལས་ཁུངས་སྐོར་གྱི་གཏོང་ལེན་བྱེད་ཀྱི་ཡོད། ལག་ལེན་བྱེད་པའི་སྒྲིག་ཡིག་ཆ་དེ་མང་ཆོས་སུ་སྤྱོད་སྲིད་པ་རེད།"}
{'en': 'Score Combination for Improved Parallel Corpus Filtering for Low Resource Conditions', 'ar': 'مجموعة النقاط لتحسين تصفية المجموعة المتوازية لظروف الموارد المنخفضة', 'es': 'Combinación de puntuaciones para mejorar el filtrado de cuerpos paralelos para condiciones de bajos recursos', 'pt': 'Combinação de pontuação para filtragem de corpus paralela aprimorada para condições de recursos baixos', 'fr': 'Combinaison de scores pour un filtrage de corpus parallèle amélioré dans des conditions de ressources faibles', 'ja': '低リソース条件のためのパラレルコーパスフィルタリングの改善のためのスコアの組み合わせ', 'zh': '所以改进低资源并行语料库筛选之分', 'hi': 'कम संसाधन शर्तों के लिए बेहतर समानांतर कॉर्पस फ़िल्टरिंग के लिए स्कोर संयोजन', 'ru': 'Комбинация баллов для улучшенной параллельной фильтрации по корпусу для условий низкого ресурса', 'ga': 'Teaglaim Scór le haghaidh Scagtha Corpais Chomhthreomhar Feabhsaithe le haghaidh Coinníollacha Íseal Acmhainní', 'ka': 'დამატებული პარალელური კოპუსის ფილტრირების შესაძლებელი წარმოდგენების კომბინაცია', 'hu': 'Pontszámkombináció a jobb párhuzamos Corpus szűréshez alacsony erőforrási körülmények között', 'el': 'Συνδυασμός βαθμολογίας για βελτιωμένο παράλληλο φιλτράρισμα σώματος για συνθήκες χαμηλού πόρου', 'it': 'Combinazione di punteggi per migliorare il filtraggio parallelo di Corpus per condizioni di risorse ridotte', 'kk': 'Қосымша ресурстар шарттарының жақсы параллель жұмыс сүзгісінің сәйкестігі', 'lt': 'Rezultatų derinys gerinant paralelinio korpuso filtravimą mažų išteklių sąlygomis', 'mk': 'Комбинација на оценки за подобрено паралелно филтрирање на корпус за ниски ресурси', 'mt': 'Kombinazzjoni ta’ Punteġġi għal Filtrar Paralleli mtejjeb tal-Korpus għal Kundizzjonijiet ta’ Riżorsi Baxxi', 'ms': 'Kombinasi Skor untuk Penapis Korpus Paralel Terbaik untuk Syarat Sumber Terrendah', 'ml': 'മെച്ചപ്പെടുത്തിയ പാറല്\u200d കോര്\u200dപ്പുസ് ഫില്\u200dറ്റര്\u200d ചെയ്യുന്നതിനുള്ള സ്കോര്\u200d കൊമ്മിണേഷന്\u200d', 'mn': 'Бага боловсролын нөхцөлд сайжруулсан параллел биеийн сүзэг', 'ro': 'Combinație de scoruri pentru filtrarea paralelă îmbunătățită a corpului pentru condiții scăzute de resurse', 'no': 'Poengkombinasjon for forbetra parallelle korpusfiltering for låge ressurs', 'pl': 'Kombinacja wyników dla ulepszonego równoległego filtrowania korpusu dla warunków niskich zasobów', 'sr': 'Kombinacija rezultata za poboljšanje paralelnog korpusa za filtriranje niskih resursa', 'so': 'Score Combination for Improved Parallel Corpus Filtering for Low Resource Conditions', 'sv': 'Poängkombination för förbättrad parallell corpusfiltrering för låga resursförhållanden', 'si': 'ප්\u200dරමාණය සම්පූර්ණ කෝර්පුස් පරික්ෂණය සඳහා ප්\u200dරමාණය සම්පූර්ණය', 'ta': 'மேம்படுத்தப்பட்ட இணைப்பு கோர்புஸ் வடிகட்டிக்கான மதிப்பெண் சேர்ப்பு', 'ur': 'نیچے سراسر شرایط کے لئے استعمال پارالئل کورپوس فیلٹرینگ کے لئے Score Combination for Improved Parallel Corpus Filtering', 'vi': 'Phân số điểm cho Điều chỉnh sửa ti vi thấp', 'uz': 'Name', 'hr': 'Kombinacija rezultata za poboljšanje paralelnog filtra korpusa za niske resurse', 'bg': 'Комбинация от оценки за подобрено паралелно филтриране на корпус за условия с ниски ресурси', 'da': 'Score kombination for forbedret parallel corpus filtrering for lave ressourceforhold', 'nl': 'Scorecombinatie voor verbeterde parallelle corpusfiltering voor lage resource condities', 'fa': 'ترکیب امتیاز برای پالایٹر جسد پارالی بهتر برای شرایط منابع کم', 'de': 'Punktekombination für verbesserte parallele Korpusfilterung für ressourcenarme Bedingungen', 'id': 'Kombinasi Skor untuk Penapis Korpus Paralel Terbaik untuk Kondisi Sumber Terrendah', 'ko': '점수 조합은 낮은 자원 조건에서 개선된 병렬 자료 라이브러리 필터에 사용됩니다', 'sw': 'Uunganishaji wa Tuzo kwa ajili ya Ufilipoti wa Umoja wa Parallel kwa Hali ndogo ya rasilimali', 'tr': 'Gelişmiş Parallel Kötür Durumlar üçin Score Combination', 'sq': 'Score Combination for Improved Parallel Corpus Filtering for Low Resource Conditions', 'af': 'Telling kombinasie vir Geverbeterde Parallele Korpus Filtering vir Lae Hulpbron Bedinge', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Նվագ ռեսուրսների պայմաններում բարելավված զուգահեռ կորպուսի ֆիլտրման գնահատականների համակցությունը', 'az': 'Düşük ressurs şartları üçün Improved Parallel Corpus Filtering', 'bs': 'Kombinacija rezultata za poboljšanje paralelnog korpusa filtriranja za niske resurse', 'ca': 'Combinació de puntuacions per a millorar el filtrat paralèl·lel del còrpus en condicions de baix recursos', 'bn': 'উন্নত প্যারেল কোর্পাস ফিল্টারের জন্য স্কোর কমান্ড', 'cs': 'Kombinace skóre pro lepší paralelní filtrování korpusu pro nízké zdroje', 'et': 'Skoorikombinatsioon paremaks paralleelseks Corpuse filtreerimiseks vähese ressursi tingimustes', 'fi': 'Pisteyhdistelmä parannettuun rinnakkaiseen Corpus-suodatukseen alhaisen resurssin olosuhteissa', 'jv': 'ProgressBarUpdates', 'ha': 'KCharselect unicode block name', 'he': 'שילוב נקודות לסנן גוף Parallel משפר לתנאי משאבים נמוכים', 'sk': 'Kombinacija ocen za izboljšano vzporedno filtriranje Corpus za pogoje z nizkimi viri', 'bo': 'Improved Parallel Corpus Filtering for Low Resource Conditions'}
{'en': 'This paper presents the description of our submission to WMT20 sentence filtering task. We combine scores from custom LASER built for each source language, a classifier built to distinguish positive and negative pairs and the original scores provided with the task. For the mBART setup, provided by the organizers, our method shows 7 % and 5 % relative improvement, over the baseline, in sacreBLEU score on the test set for Pashto and Khmer respectively.', 'ar': 'تقدم هذه الورقة وصفًا لتقديمنا إلى مهمة تصفية الجملة في WMT20. نحن نجمع الدرجات من LASER المخصص المصمم لكل لغة مصدر ، وهو مصنف مصمم للتمييز بين الأزواج الإيجابية والسلبية والنتائج الأصلية المتوفرة مع المهمة. بالنسبة لإعداد mBART ، الذي قدمه المنظمون ، تُظهر طريقتنا تحسنًا نسبيًا بنسبة 7٪ و 5٪ ، على خط الأساس ، في درجة sacreBLEU في مجموعة الاختبار للباشتو والخمير على التوالي.', 'fr': "Cet article présente la description de notre soumission à la tâche de filtrage de phrases WMT20. Nous combinons les scores du LASER personnalisé créé pour chaque langue source, un classificateur conçu pour distinguer les paires positives et négatives et les scores originaux fournis avec la tâche. Pour la configuration mBart, fournie par les organisateurs, notre méthode montre une amélioration relative de 7\xa0% et 5\xa0%, par rapport à la base, du score SacreBleu sur l'ensemble de test pour le pachto et le khmer respectivement.", 'pt': 'Este artigo apresenta a descrição de nossa submissão à tarefa de filtragem de frases do WMT20. Combinamos pontuações de LASER personalizados construídos para cada idioma de origem, um classificador construído para distinguir pares positivos e negativos e as pontuações originais fornecidas com a tarefa. Para a configuração do mBART, fornecida pelos organizadores, nosso método mostra uma melhora relativa de 7% e 5%, em relação à linha de base, na pontuação sacreBLEU no conjunto de testes para pashto e khmer, respectivamente.', 'es': 'Este artículo presenta la descripción de nuestro envío a la tarea de filtrado de frases WMT20. Combinamos puntajes de LASER personalizado creado para cada idioma de origen, un clasificador creado para distinguir pares positivos y negativos y los puntajes originales proporcionados con la tarea. Para la configuración de mBart, proporcionada por los organizadores, nuestro método muestra una mejora relativa del 7% y 5%, con respecto a la línea de base, en la puntuación de SacreBleu en la prueba establecida para pastún y jemer, respectivamente.', 'ja': '本稿では、WMT 20文フィルタリングタスクへの提出について説明します。私たちは、各ソース言語用に構築されたカスタムレーザーからのスコア、ポジティブとネガティブのペアを区別するために構築された分類子、およびタスクに提供された元のスコアを組み合わせます。主催者によって提供されるｍＢＡＲＴの設定について、本方法は、ベースラインを超えて、パシュトー及びクメール人についての試験セットのｓａｃｒｅＢＬＥＵスコアにそれぞれ７ ％及び５ ％の相対的改善を示す。', 'hi': 'यह पेपर WMT20 वाक्य फ़िल्टरिंग कार्य के लिए हमारे सबमिशन का विवरण प्रस्तुत करता है। हम प्रत्येक स्रोत भाषा के लिए निर्मित कस्टम लेजर से स्कोर को जोड़ते हैं, सकारात्मक और नकारात्मक जोड़े और कार्य के साथ प्रदान किए गए मूल स्कोर को अलग करने के लिए बनाया गया एक क्लासिफायर। आयोजकों द्वारा प्रदान किए गए mBART सेटअप के लिए, हमारी विधि 7% और 5% सापेक्ष सुधार दिखाती है, बेसलाइन पर, क्रमशः पश्तो और खमेर के लिए परीक्षण सेट पर sacreBLEU स्कोर में।', 'zh': '本文引我们提交给WMT20句子过去的描述。 结为每源言语构定LASER之分,一以分正对负对之器,随事供始分之分。 于组织者供mBART设,吾法各于普什图语、高棉语试集之sacreBLEU分数中示比基线有7%5%改善。', 'ru': 'В данной статье представлено описание нашего представления на решение задачи фильтрации предложений WMT20. Мы объединяем баллы из пользовательского ЛАЗЕРА, построенного для каждого исходного языка, классификатора, построенного для различения положительных и отрицательных пар, и исходных баллов, предоставленных с заданием. Для установки mBART, предоставленной организаторами, наш метод показывает относительное улучшение на 7% и 5% по сравнению с исходным уровнем в баллах sacreBLEU на тестовом наборе для пушту и кхмеров соответственно.', 'ga': 'Cuireann an páipéar seo i láthair an cur síos ar ár n-aighneacht do thasc scagtha abairtí WMT20. Comhcheanglaímid scóir ó LASER saincheaptha a tógadh do gach teanga foinse, aicmitheoir a tógadh chun idirdhealú a dhéanamh idir péirí dearfacha agus diúltacha agus na scóir bhunaidh a soláthraíodh leis an tasc. Maidir le socrú mBART, a sholáthraíonn na heagraithe, taispeánann ár modh feabhas coibhneasta 7% agus 5%, thar an mbunlíne, i scór sacreBLEU ar an tacar tástála do Pashto agus Khmer faoi seach.', 'hu': 'Ez a tanulmány bemutatja a WMT20 mondatszűrési feladat bemutatásának leírását. Kombináljuk az egyéni forrásnyelvekhez készült lézeres pontszámokat, a pozitív és negatív párok megkülönböztetésére épített osztályozót és a feladathoz kapcsolódó eredeti pontszámokat. A szervezők által biztosított mBART beállítás esetén a módszerünk 7%-os, illetve 5%-os relatív javulást mutat az alaphelyzethez képest a sacreBLEU pontszámban a Pashto és Khmer tesztkészleten.', 'el': 'Αυτή η εργασία παρουσιάζει την περιγραφή της υποβολής μας στο έργο φιλτραρίσματος προτάσεων WMT20. Συνδυάζουμε βαθμολογίες από προσαρμοσμένα σχεδιασμένα για κάθε γλώσσα προέλευσης, έναν ταξινομητή κατασκευασμένο για να διακρίνει θετικά και αρνητικά ζεύγη και τις αρχικές βαθμολογίες που παρέχονται με την εργασία. Για τη ρύθμιση που παρέχεται από τους διοργανωτές, η μέθοδος μας δείχνει 7% και 5% σχετική βελτίωση, σε σχέση με τη βάση, στο σκορ στο σετ δοκιμών για Παστό και Χμερ αντίστοιχα.', 'ka': 'ეს წიგნი WMT20 წიგნის ფილტრინტის რაოდენობაში ჩვენი წიგნის აღწერა. ჩვენ ყველა მხოლოდ მხოლოდ მხოლოდ LASER-ის წერტილების შექმნა, კლასიფიკაცია, რომელიც შექმნა პოტიფიკაციურ და ნეტივიურ წერტილების განსაზღვრებისთვის და პირველ წერტი mBART-ის დასრულებაში, რომელიც ორგანიზატორებით დაეხმარებული, ჩვენი მეტი ჩვენი გასაკეთებელი დასრულებაში 7% და 5% დასრულებაში, პირდაპირველი წერტილის შესაბამისი წერტილის შესაბამისი წერტილის შე', 'it': 'Questo articolo presenta la descrizione della nostra sottomissione al compito di filtraggio delle frasi WMT20. Combiniamo punteggi dal LASER personalizzato costruito per ogni lingua di origine, un classificatore costruito per distinguere coppie positive e negative e i punteggi originali forniti con il compito. Per il setup mBART, fornito dagli organizzatori, il nostro metodo mostra un miglioramento relativo del 7% e del 5% rispetto al basale, nel punteggio sacreBLEU sul set di test per Pashto e Khmer rispettivamente.', 'kk': 'Бұл қағаз WMT20 сөздерді сүзгілеу тапсырмасына жіберудің сипаттамасын көрсетеді. Біз әрбір көзінің тіліне құрылған LASER- ның сандарын біріктіреміз, оң және негативті екі мен тапсырмаға келтірілген бастапқы сандарды біріктіру үшін құрылған классификатор. Ұйымдастырушылар келтірілген mBART баптаулары үшін біздің әдіміміз Пашто және Хмер сынақтарындағы мәліметтердің негізгі жолында 7% мен 5% салыстырмалы жақсартылығын көрсетеді.', 'lt': 'Šiame dokumente pateikiamas mūsų pateikto WMT20 sakinių filtravimo uždavinio aprašymas. Mes deriname kiekvienai šaltinio kalbai sukurtą savarankišką LASER rezultatus, klasifikatorių, sukurtą siekiant atskirti teigiamas ir neigiamas poras, ir pradinius rezultatus, pateiktus užduotyje. Organizatorių pateiktame mBART nustatymo metode parodomas santykinis 7 % ir 5 % pagerėjimas, palyginti su pradiniu lygiu, santykinis santykinis santykinis BLEU rezultatas atitinkamai Pashto ir Khmer bandymuose.', 'mk': 'Овој весник го претставува описот на нашето поднесување на задачата за филтрирање на речениците WMT20. We combine scores from custom LASER built for each source language, a classifier built to distinguish positive and negative pairs and the original scores provided with the task.  За поставувањето на mBART, обезбедено од организаторите, нашиот метод покажува релативно подобрување од 7 отсто и 5 отсто, во однос на основата, во светиот БЛЕУ резултат на тестот поставен за Пашто и Хмер, односно.', 'ms': 'Kertas ini memperkenalkan keterangan penghantaran kami ke tugas penapisan kalimat WMT20. Kami menggabungkan skor dari LASER suai yang dibina untuk setiap bahasa sumber, pengklasifikasi yang dibina untuk membedakan pasangan positif dan negatif dan skor asal yang diberikan dengan tugas. Untuk setup mBART, disediakan oleh pengatur, kaedah kami menunjukkan 7% dan 5% peningkatan relatif, atas dasar asas, dalam skor sacreBLEU pada set ujian untuk Pashto dan Khmer berdasarkan.', 'mt': 'Dan id-dokument jippreżenta d-deskrizzjoni tas-sottomissjoni tagħna għall-kompitu ta’ filtrazzjoni tas-sentenzi WMT20. Nikkombinaw punteġġi minn LASER personalizzat mibnija għal kull lingwa tas-sors, klassifikatur mibni biex jiddistingwi pari pożittivi u negattivi u l-punteġġi oriġinali pprovduti bil-kompitu. Għall-istabbiliment tal-mBART, ipprovdut mill-organizzaturi, il-metodu tagħna juri titjib relattiv ta’ 7% u 5%, fuq il-linja bażi, fil-punteġġ sacreBLEU fuq it-test stabbilit għal Pashto u Khmer rispettivament.', 'ml': 'This paper presents the description of our submission to WMT20 sentence filtering task.  എല്ലാ സ്രോതസ്സുകള്\u200dക്കും വേണ്ടി നിര്\u200dമ്മിക്കപ്പെട്ട സ്കോര്\u200d ലാസെരില്\u200d നിന്നും നമ്മള്\u200d ഒരുമിച്ചുകൂട്ടുന്നു. ജോലിയുടെ മ സംഘടനക്കാര്\u200d നല്\u200dകിയ MBART സജ്ജീകരണങ്ങള്\u200dക്ക്, നമ്മുടെ രീതിയില്\u200d ഏഴ് ശതമാനത്തിനും 5% മെച്ചപ്പെടുത്തിയിരിക്കുന്നു. അടിസ്ഥാനത്തിനു മുകളില്\u200d, സാ', 'mn': 'Энэ цаас WMT20 өгүүлбэр шүүмжлэх ажлын тухай ярьж байна. Бид эх үүсвэрийн хэл бүрт бүтээгдэхүүний дараагийн, сөрөг хоёр болон ажлын эхний тоонуудыг ялгаалан бүтээсэн LASER-ээс гаргасан тоонуудыг нэгтгэдэг. Организагчид өгсөн mBART-ын төлөвлөгөөнд бидний арга нь Пашто болон Хмерийн шалгалтын шалгалтын хувьд 7% болон 5% харьцаатай сайжруулалтыг харуулдаг.', 'no': 'Denne papiret viser beskrivelsen av tillegget vår til WMT20- setningsfiltering. Vi kombinerer poeng frå sjølvvald LASER bygd for kvar kjeldespråk, ein klassifiser bygd for å skilja positiv og negative par og opprinnelige poeng i oppgåva. For mBART-oppsettet, oppgjeven av organisatorene, viser vårt metode 7 % og 5 % relativt forbedring, over grunnlinja, i heilt BLEU-poeng på testet sett for Pashto og Khmer.', 'pl': 'Niniejszy artykuł przedstawia opis naszej zgłoszenia do zadania filtrowania zdań WMT20. Łączymy wyniki z niestandardowego LASER zbudowanego dla każdego języka źródłowego, klasyfikatora zbudowanego w celu odróżnienia par dodatnich i ujemnych oraz oryginalnych wyników dostarczonych do zadania. W przypadku konfiguracji mBART, dostarczonej przez organizatorów, nasza metoda pokazuje 7% i 5% względną poprawę, w porównaniu z linią bazową, w wyniku sacreBLEU na zestawie testowym odpowiednio dla Paszto i Khmer.', 'ro': 'Această lucrare prezintă descrierea depunerii noastre la sarcina de filtrare a frazelor WMT20. Combinăm scoruri de la LASER personalizat construit pentru fiecare limbă sursă, un clasificator construit pentru a distinge perechile pozitive și negative și scorurile originale furnizate cu sarcina. Pentru configurarea mBART, furnizată de organizatori, metoda noastră arată o îmbunătățire relativă de 7% și 5% față de valoarea inițială a scorului sacreBLEU pe setul de teste pentru Pashto și respectiv Khmer.', 'si': 'මේ පත්තේ WMT20 වාක්ය පරීක්ෂණය වැඩකට අපේ පිළිගන්න විස්තර දෙනවා. අපි හැම මූල භාෂාව සඳහා නිර්මාණය කරපු LASER වලින් පරික්ෂණාවක් සම්බන්ධ කරනවා, විශේෂකයෙක් විශේෂකය සහ අනාකාර mBART සැකසුම් වෙනුවෙන්, සංයෝජකයෝ දෙනුවෙන්, අපේ විධානය 7% සහ 5% සාමාන්\u200dය වැඩි වැඩි වෙනුවෙන්, පෂ්ටෝ සහ ක්මෙර් වලට පරීක්ෂණා ස', 'sr': 'Ovaj papir predstavlja opis našeg podnošenja zadatku filtriranja rečenica WMT20. Kombiniramo rezultate iz posebnog LASER izgrađenog za svaki izvorni jezik, klasifikatora izgrađenog za razliku pozitivnih i negativnih pare i originalnih rezultata koji su pruženi zadatkom. Za postavku mBART, pruženu organizatorima, naš metod pokazuje relativno poboljšanje 7% i 5%, na osnovnoj liniji, u svetom BLEU rezultatu na testu postavljenom za Pashto i Khmer.', 'so': 'This paper presents the description of our submission to WMT20 sentence filtering task.  Iskuulaa scoraha caadada LASER oo loo dhisay luqad kasta oo asal ah, fasax oo loo dhisay si loo kala sooco noocyo positive iyo negative iyo scoraha asalka ah ee shaqada la siiyo. Qoraalka MBART, ee ay qabanqaabiyaan, qaababkayagu wuxuu ka muujiyaa 7% iyo 5% kordhin habboon, kooxda hoose ee sacreBLEU waxay ku qoran yihiin imtixaanka u qoran Pashto iyo Khmer.', 'sv': 'Denna uppsats presenterar beskrivningen av vår inlämning till WMT20 meningsfiltrering uppgift. Vi kombinerar poäng från anpassade LASER byggda för varje källspråk, en klassificerare byggd för att skilja positiva och negativa par och de ursprungliga poängen som tillhandahålls med uppgiften. För mBART setup, som tillhandahålls av arrangörerna, visar vår metod 7% och 5% relativ förbättring, jämfört med baslinjen, i sacreBLEU poäng på testuppsättningen för Pashto respektive Khmer.', 'ta': 'இந்த தாள் WMT20 வாக்கியத்தின் வடிகட்டி செயல்பாட்டிற்கு எங்கள் submissionை விவரிப்பதை கூட்டுகிறது. நாம் ஒவ்வொரு மூலத்திற்கும் உருவாக்கப்பட்ட LASER மதிப்புகளை சேர் MBART அமைப்புக்கு, நிறுவனங்களால் வழங்கப்பட்டது, எங்கள் முறைமையில் 7% மற்றும் 5% சார்ந்த முன்னேற்றத்தை காட்டும், அடிப்படைக்கோட்டில், சாக்ரெப', 'ur': 'This paper presents the description of our submission to the WMT20 sentence filtering task. ہم ہر سراسر زبان کے لئے بنائے ہوئے LASER سے اسکور کو ترکیب کرتے ہیں، ایک کلاسیر جو مثبت اور منفی جوڑوں کو جدائی کرنے کے لئے بنایا گیا ہے اور اس کام کے ذریعہ منفی اسکور کو جدائی کرنے کے لئے بنایا گیا ہے. mBART سٹاپ کے لئے، سازمان کرنے والوں کے لئے، ہمارا طریقہ پاشٹو اور کمر کے لئے مقدس سٹ کے ذریعہ سے 7% اور 5% مقدس اضافہ دکھاتا ہے۔', 'uz': "Bu hujjat WMT20 soʻzni filterlash vazifasini koʻrsatiladi. Biz har bir manba tilning uchun yaratilgan SISER sonlarini birlashtiramiz, vazifani aniqlash uchun yaxshi va negativ qonlarni ajratuvchi darajaga va asl scorlarni birlashtiramiz. MBART tugmalar birikmasi uchun ishga tayyorlangan tugmalar birikmasi Pashto va Khmer bo'lgan sinov sohasida 7% va 5% yaxshi o'zgarishni ko'rsatadi.", 'vi': 'Tờ giấy này mô tả việc chúng ta chịu trách nhiệm lọc các bản địa của WM22. Chúng tôi kết hợp điểm từ LAERR tự đặt cho mỗi ngôn ngữ nguồn, một người phân loại được xây dựng để phân biệt các cặp dương và âm và điểm gốc được cung cấp với nhiệm vụ. Đối với thiết lập mBART, được sắp xếp bởi tổ chức, phương pháp của chúng ta hiển thị vi 7. và 5. vi. cải tiến tương đối, trên đường cơ bản, trong số lượng kí kết đặt thử nghiệm cho Pashto và Khmer.', 'bg': 'Тази статия представя описанието на нашата задача за филтриране на изречения. Комбинираме оценки от персонализиран лазер, създаден за всеки изходен език, класификатор, създаден за разграничаване на положителни и отрицателни двойки и оригиналните оценки, предоставени със задачата. За настройката на mBART, предоставена от организаторите, нашият метод показва относително подобрение от 7% и 5% спрямо изходната стойност в резултат на теста съответно за пашто и кхмер.', 'nl': 'Deze paper presenteert de beschrijving van onze inzending aan WMT20 zinnenfiltering taak. We combineren scores van aangepaste LASER gebouwd voor elke brontaal, een classificator gebouwd om positieve en negatieve paren te onderscheiden en de originele scores geleverd bij de taak. Voor de mBART setup, verstrekt door de organisatoren, toont onze methode 7% en 5% relatieve verbetering, ten opzichte van de baseline, in sacreBLEU score op de testset voor respectievelijk Pashto en Khmer.', 'da': 'Dette papir præsenterer beskrivelsen af vores indsendelse til WMT20 sætningsfiltrering opgave. Vi kombinerer scoringer fra brugerdefinerede LASER bygget til hvert kildesprog, en klassificering bygget til at skelne mellem positive og negative par og de oprindelige scorer, der leveres med opgaven. For mBART setup, leveret af arrangørerne, viser vores metode 7% og 5% relativ forbedring, i forhold til baseline, i sacreBLEU score på testsættet for henholdsvis Pashto og Khmer.', 'hr': 'Ovaj papir predstavlja opis našeg podnošenja zadatku filtriranja rečenica WMT20. Kombiniramo rezultate iz osobnog LASER-a izgrađenog za svaki izvorni jezik, klasifikatora izgrađenog kako bi razdvojili pozitivne i negativne pare i originalne rezultate koje su pružene zadatkom. Za uspostavu mBART-a, predviđenu organizatorima, naša metoda pokazuje relativno poboljšanje 7% i 5%, na početnoj liniji, u svetom rezultatu Svetog BLEU-a o testu postavljenom za Pashto i Khmer.', 'de': 'In diesem Beitrag wird die Beschreibung unserer Einreichung an WMT20 Satzfilteraufgabe vorgestellt. Wir kombinieren Noten aus benutzerdefiniertem LASER, der für jede Ausgangssprache erstellt wurde, einen Klassifikator, der entwickelt wurde, um positive und negative Paare zu unterscheiden, und die ursprünglichen Ergebnisse, die mit der Aufgabe geliefert werden. Für das von den Organisatoren bereitgestellte mBART-Setup zeigt unsere Methode 7% und 5% relative Verbesserung gegenüber der Baseline im sacreBLEU-Score auf dem Testset für Pashto bzw. Khmer.', 'id': 'Kertas ini menunjukkan deskripsi pengiriman kita ke tugas penapisan kalimat WMT20. Kami menggabungkan skor dari LASER sendiri yang dibuat untuk setiap bahasa sumber, klasifikasi yang dibuat untuk membedakan pasangan positif dan negatif dan skor asli yang diberikan dengan tugas. Untuk setup mBART, yang disediakan oleh organisasi, metode kami menunjukkan 7% dan 5% peningkatan relatif, atas dasar dasar, dalam skor sacreBLEU pada set tes untuk Pashto dan Khmer berdasarkan.', 'fa': 'این کاغذ توضیح تحویل ما به کار فیلتر دادن جمله WMT20 را نشان می دهد. ما امتیاز\u200cها را از LASER شخصی برای هر زبان منبع ساخته می\u200cکنیم، یک گروهی ساخته می\u200cشود تا جفت مثبت و منفی و امتیاز اصلی که با این وظیفه ارائه داده می\u200cشود جدا کند. برای سازمان mBART، که توسط سازمان\u200cکنندگان ارائه می\u200cدهند، روش ما به عنوان تغییر پاستو و کرمر 7 درصد و 5 درصد تغییر ارائه می\u200cدهد.', 'ko': '본고는 우리가 WMT20 문장에 제출한 필터 작업의 과정을 묘사한다.우리는 모든 원본 언어를 위한 LASER의 점수, 양과 음의 구분을 위한 분류기, 그리고 작업에 제공된 원시 점수를 결합시켰다.조직자가 제공한 mBART 설정에 대해 우리의 방법에 따르면 푸시투어와 고면어 시험집에서 사클레블러어의 점수는 각각 기선 수준보다 7%와 5% 높아졌다.', 'tr': 'Bu kagyz WMT20 sözleriň süýtgetmesi täblisasine jogaplarymyzyň waspyny görkezýär. Biz her çeşme dilinde inşa edilen LASER sanlaryndan, pozitif we negatif çiftlerni we netijesi bilen beren sanlaryny bölmek üçin guruldyrýarys. Düzenleyiciler tarapyndan berilen mBART düzenlemesi üçin biziň metodamyz 7% we 5% ködleşiklik gelişmelerini görkez.', 'sw': 'Gazeti hili linaelezea maelezo ya ujumbe wetu kwa kazi ya kuchuja hukumu ya WMT20. Tunaunganisha vipimo vya LASER vilivyojengwa kwa kila lugha ya vyanzo, mtangazaji aliyejengwa kwa ajili ya kutofautisha wanaume chanya na wasio na hasi na vipande vya awali vilivyotolewa na kazi hiyo. Kwa taasisi ya mBART, inayotolewa na waandaaji, mbinu yetu inaonyesha asilimia 7 na asilimia 5 ya kuboreshwa kwa asilimia ya msingi, kwenye vituo vya sacreBLEU kuhusu jaribio lililowekwa kwa ajili ya Pashto na Khmer.', 'am': 'ይህ ገጽ የውይይት አጣራዎችን ወደ WMT20 አጣራ አድራሻ የሚያቀርብ ነው፡፡ We combine scores from custom LASER built for each source language, a classifier built to distinguish positive and negative pairs and the original scores provided with the task.  አዳራጆች የተሰናከሉ የMBART ግንኙነት፣ ሥርዓታችን በመቶ 7 በመቶ እና 5 በመቶ የአባቢው ክፍል፣ ለፓሽቶና ለክሜር ተፈተና በተደረገ የሳክሬBLEU score በሚያሳየው ነው፡፡', 'sq': 'This paper presents the description of our submission to WMT20 sentence filtering task.  Ne kombinojmë rezultate nga LASER të personalizuar të ndërtuar për çdo gjuhë burimi, një klasifikues i ndërtuar për të dalluar çiftet pozitive dhe negative dhe rezultatet origjinale të ofruar me detyrën. Për ngritjen e mBART, të siguruar nga organizatorët, metoda jonë tregon përmirësim relativ 7% dhe 5% mbi bazën, në pikën e shenjtë BLEU në test in e vënë respektivisht për Pashto dhe Khmer.', 'af': "Hierdie papier stel die beskrywing van ons onderskrywing aan WMT20 teikens filtering taak. Name Ons kombinieer telling van pasmaak LASER gebou vir elke bron taal, 'n klassifiseerder gebou om positiewe en negatiewe paar en die oorspronklike telling wat verskaf is met die taak. Vir die mBART-opstelling, verskaf deur die organiseerders, vertoon ons metode 7% en 5% relatiewe verbetering, oor die basisline, in die heilige BLES-aantal op die toets stel vir Pashto en Khmer respektief.", 'az': 'Bu kağıt WMT20 sözləri filtrləmə işinə göndərməyimizin tərzini göstərir. Biz hər mənbə dilinə inşa edilmiş, pozitif və negatif çiftləri və işlərdə təmin edilmiş orijinal nöqtələrini ayırmaq üçün yaratdığımız xüsusi LASER tərzindən müəyyən etdik. Organizatorlar təyin etdiyi mBART quruluşu üçün, metodumuz Pashto və Khmer testi təyin etdiyi sınaqların üstündə müqəddəs səhifələrində 7%-5%-i yaxşılaşdırma göstərir.', 'hy': 'Այս թղթին ներկայացնում է մեր ներկայացման նկարագրությունը We combine scores from custom LASER built for each source language, a classifier built to distinguish positive and negative pairs and the original scores provided with the task.  mBAR-ի կառուցվածքի համար, որը կազմակերպել են կազմակերպողները, մեր մեթոդը ցույց է տալիս 7 և 5 տոկոսի հարաբերական զարգացում ըստ հիմքի, պաշտո և հմերի թեստերի սրբուբլեուի գնահատվածի:', 'bn': 'This paper presents the description of our submission to WMT20 sentence filtering task.  আমরা স্বনির্বাচিত ল্যাসের স্কোর সংযুক্ত করি প্রত্যেক সোর্স ভাষার জন্য নির্মাণ করা হয়েছে, যা ক্লাসিফার বানানো হয়েছে ইতিবাচক প্রতিষ্ঠাতাদের দ্বারা প্রদান করা এমবিআর্ট সেটের জন্য আমাদের পদ্ধতি প্রদর্শন করা হয়েছে ৭% এবং ৫% আত্মিক উন্নতি দেখাচ্ছে, বেসারেলাইনে পাশ্তো এবং খেম', 'bs': 'Ovaj papir predstavlja opis našeg podnošenja zadatku filtriranja rečenica WMT20. Kombiniramo rezultate iz običnog LASER-a izgrađenog za svaki izvorni jezik, klasifikatora izgrađenog kako bi razlikovali pozitivne i negativne pare i originalne rezultate koje su pružene zadatkom. Za uspostavu mBART, pruženu organizatorima, naš metod pokazuje relativno poboljšanje 7% i 5%, na početnoj liniji, u svetom BLEU rezultatu na testu postavljenom za Pashto i Khmer.', 'ca': "Aquest article presenta la descripció de la nostra subministració a la tasca de filtrar frases WMT20. Combnem puntuacions de LASER personalitzats construïdes per cada llenguatge de font, un classificador construït per distingir parells positius i negatius i les puntuacions originals proporcionades amb la tasca. Per a la configuració mBART, proporcionada pels organitzadors, el nostre mètode mostra una millora relativa del 7% i del 5%, sobre la base, en la puntuació sagrada BLEU en el conjunt d'exàmens per Pashto i Khmer respectivament.", 'cs': 'Tento článek představuje popis našeho podání do WMT20 filtrování vět. Kombinujeme skóre z vlastního LASER postaveného pro každý zdrojový jazyk, klasifikátor postavený pro rozlišení kladných a záporných párů a původní skóre poskytnuté s úkolem. Pro nastavení mBART, poskytnuté organizátory, naše metoda ukazuje 7% a 5% relativní zlepšení, oproti základnímu bodu, v sacreBLEU skóre na testovací sadě pro Pashto a Khmer.', 'et': 'Käesolevas artiklis esitatakse kirjeldus meie esitamise WMT20 lausefiltreerimise ülesanne. Kombineerime iga lähtekeele jaoks loodud kohandatud LASERi tulemused, positiivsete ja negatiivsete paaride eristamiseks loodud klassifitseerija ja ülesandega kaasnevad algsed tulemused. Korraldajate poolt esitatud mBART seadistuse puhul näitab meie meetod 7% ja 5% suhtelist paranemist võrreldes lähtetasemega vastavalt Pashto ja Khmeri testikomplektiga.', 'fi': 'Tässä artikkelissa esitellään kuvaus siitä, miten WMT20 lauseiden suodatus suoritetaan. Yhdistämme kullekin lähdekielelle rakennetun kustomoidun LASER-luokituksen tulokset, positiivisten ja negatiivisten parien erottamiseen rakennetun luokituksen ja tehtävän mukana toimitetut alkuperäiset pisteet. Järjestäjien toimittamassa mBART-kokoonpanossa menetelmämme osoittaa 7% ja 5% suhteellista parannusta lähtötilanteeseen verrattuna sakreBLEU-pisteissä testisarjassa Pashto ja Khmer.', 'jv': 'Workspace 1 Awak dh챕w챕 tambah menyang paling LASER pawang nggawe kanggo saben kelas, padha sekondirno sing dibalik dh챕w챕 nggawe gerapakan bukar lan nganggo dolanan sing titik dh챕w챕 lan nganggo dolanan sing paling dh챕w챕. Nambah sing nggawe mLPRT , ngebah nambah ning acara iki, awak dh챕w챕 wis 7% lan 5% sing nyimpen nggawe barang kelas telas, n챗m챗r sing nyimpen n챗m챗r, n챗m챗r sing ngebah etik dh챕w챕 kanggo nyenggawe Pash챕 karo Kemerdekaan sing berarti tambah.', 'ha': "Wannan takardan na bãyar da description ga aikin mu zuwa filin maganar WMT20. Tuna haɗa score daga ɗabi'a na MASAR wanda aka gina wa duk harshen na source, wani fassarar da aka gina dõmin rarraba nau'i masu shirya da negative da score na farko da aka ba da aikin. @ action: button", 'sk': 'Ta prispevek predstavlja opis naše predložitve opravila filtriranja stavkov WMT20. Združujemo rezultate LASER po meri, zgrajenih za vsak izvorni jezik, klasifikatorja, zgrajenega za razlikovanje pozitivnih in negativnih parov ter originalnih rezultatov, ki jih zagotavlja naloga. Za nastavitev mBART, ki so jo zagotovili organizatorji, naša metoda kaže 7% relativno izboljšanje rezultata sacreBLEU glede na izhodiščno vrednost na testnem nizu za pašto oziroma Khmer.', 'bo': 'WMT2ཚིག་གི་ཚིག་རྟགས་ཚགས་ཀྱི་དུས་ཚོད་ལ་ང་ཚོའི་འཇུག་སྣོད་ཀྱི་འགྲེལ་བཤད་འདི་སྟོན་པ་ཡིན། We combine scores from custom LASER built for each source language, a classifier built to distinguish positive and negative pairs and the original scores provided with the task. དབྱེ་སྤྱོད་མཁན་གྱི་སྒྲིག་འགོད་ལ་ང་ཚོའི་ཐབས་ལམ་ལ་ཕྱིར་མཐོང་ནི་(mBART)ཡི་གྲངས་སྒྲིག་རྒྱུ་དང་།', 'he': 'הנייר הזה מציג את התיאור של ההעברה שלנו למשימת פינר משפטים WMT20. אנו משלבים נקודות מ-LASER מתאים בנויים לכל שפה מקור, מסווג שנבנה כדי להבחין זוגות חיוביים ושליליים והנקודות המקוריות שנספקו עם המשימה. למערכת mBART, שנספקה על ידי המארגנים, השיטה שלנו מראה שיפור יחסי של 7% ו-5%, מעל הבסיס, בתוצאה הקדושה של BLEU על המבחן של פאשטו והKhmer בהתאם.'}
{'en': 'An exploratory approach to the Parallel Corpus Filtering shared task WMT20', 'ar': 'نهج استكشافي للمهمة المشتركة Parallel Corpus Filtering WMT20', 'fr': 'Une approche exploratoire de la tâche partagée WMT20 de filtrage parallèle de corpus', 'pt': 'Uma abordagem exploratória para a tarefa compartilhada de Filtragem de Corpus Paralela WMT20', 'es': 'Un enfoque exploratorio de la tarea compartida WMT20 de Filtrado de Corpus Paralelo', 'ja': 'パラレルコーパスフィルタリング共有タスクWMT 20への探索的アプローチ', 'zh': '并行语料库漉共事 WMT20 探索性法', 'hi': 'समानांतर कॉर्पस फ़िल्टरिंग साझा कार्य WMT20 के लिए एक खोजपूर्ण दृष्टिकोण', 'ru': 'Исследовательский подход к общей задаче параллельной фильтрации корпусов WMT20', 'ga': 'Cur chuige taiscéalaíoch i leith an chomhthasc Scagtha Corpais Chomhthreomhair WMT20', 'el': 'Μια διερευνητική προσέγγιση στην κοινή εργασία Φιλτράρισμα παράλληλου σώματος WMT20', 'ka': 'Name', 'hu': 'Feltáró megközelítés a Parallel Corpus Filtering megosztott feladathoz WMT20', 'it': 'Un approccio esplorativo al compito condiviso Parallel Corpus Filtering WMT20', 'kk': 'Parallel Corpus сүзгісінің ортақ тапсырманы WMT20 сүзгісінің зерттеу арқылыName', 'lt': 'Paralelinio korpuso filtravimo bendros užduoties WMT20 tiriamasis metodas', 'mk': 'Истражувачки пристап до заедничката задача на Филтрирање на паралелниот корпус WMT20', 'ms': 'Name', 'mt': 'Approċċ esploratorju għall-kompitu kondiviż tal-Filtrar tal-Korp Paralleli WMT20', 'mn': 'Parallel Corpus Filtering-ын судалгааны арга зам WMT20', 'ml': 'പാരാളല്\u200d കോര്\u200dപ്പുസ് ഫില്\u200dറ്റര്\u200d ചെയ്യുന്നതിലേക്ക് ഒരു പരിശോധന നടപടി', 'ro': 'O abordare exploratorie a sarcinii partajate de filtrare a corpului paralel WMT20', 'no': 'Name', 'pl': 'Podejście eksploracyjne do wspólnego zadania filtrowania korpusu równoległego WMT20', 'sr': 'Istraživački pristup paralelnom korpusu filtriranju zajedničkog zadatka WMT20', 'sv': 'Ett utforskande tillvägagångssätt för den delade uppgiften Parallel Corpus Filtering WMT20', 'so': 'Xafiiska baaritaanka ee baaritaanka baaritaanka baaritaanka ee Parallel Corpus Filtering (WMT20)', 'si': 'Name', 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': 'Cách tiếp cận thăm dò đến công việc chia sẻ ma tuý của Parallel Corpus', 'da': 'En udforskende tilgang til Parallel Corpus Filtering delte opgave WMT20', 'bg': 'Изследователски подход към съвместната задача за паралелно филтриране на корпуса WMT20', 'nl': 'Een verkennende benadering van de gedeelde taak Parallel Corpus Filtering WMT20', 'hr': 'Istraživački pristup filtriranju paralelnog korpusa zajedničkog zadatka WMT20', 'id': 'Sebuah pendekatan eksplorator untuk tugas bersama Penapis Korpus Paralel WMT20', 'fa': 'Name', 'de': 'Ein explorativer Ansatz für die gemeinsame Aufgabe Parallel Corpus Filtering WMT20', 'ko': '병렬 자료 라이브러리 필터 공유 작업 WMT20 탐색', 'tr': "Parallel Corpus'un paylaşık görevi WMT20'e gözlenen bir gezek", 'sw': 'Utafiti wa uchunguzi wa Uchunguzi wa Parallel ulisambazwa kazi WMT20', 'af': 'Name', 'sq': 'Një qasje eksploruese ndaj detyrës së përbashkët të filtrimit të Korpus Paralel WMT20', 'am': 'አዲስ ዶሴ ፍጠር', 'hy': 'Փարալել Կորպուսի ֆիլտրելը համագործակցած աշխատանքի ուսումնասիրության մոտեցումը', 'az': 'Parallel Corpus Filtering paylaşılan işləri WMT20 üçün keşif tərzi', 'bn': 'প্যারালেল কোর্পাস ফিল্টারিং এর কাছে একটি সন্ত্রাসী উপায় ওয়াএমটি২০ শেয়ার করা হয়েছে', 'ca': 'Un enfocament exploratori a la tasca compartida WMT20 del Parallel Corpus Filtering', 'bs': 'Istraživački pristup filtriranju paralelnog korpusa zajedničkog zadatka WMT20', 'et': 'Uuriv lähenemisviis paralleelse korpuse filtreerimise ühisele ülesandele WMT20', 'cs': 'Průzkumný přístup ke sdílenému úkolu filtrování paralelního korpusu WMT20', 'fi': 'Tutkiva lähestymistapa yhteiseen WMT20-tehtävään Parallel Corpus Filtering', 'jv': 'Name', 'ha': 'An sami wata mataimaki zuwa Filin aiki na Parallel da aka raba shi WMT20', 'sk': 'Raziskovalni pristop k skupni nalogi vzporednega filtriranja korpusa WMT20', 'he': 'גישה חוקרית למשימה המשותפת של "סינון קורפוס Parallel"', 'bo': 'Parallel Corpus Filtering shared task WMT20 ལ་འཚོལ་ཞིབ་བྱེད་ཀྱི་ཐབས་ལམ་ཞིག་ཡིན།'}
{'en': 'In this document we describe our submission to the parallel corpus filtering task using multilingual word embedding, language models and an ensemble of pre and post filtering rules. We use the norms of embedding and the perplexities of language models along with pre / post filtering rules to complement the LASER baseline scores and in the end get an improvement on the dev set in both language pairs.', 'ar': 'في هذا المستند ، نصف إرسالنا إلى مهمة تصفية المجموعة المتوازية باستخدام تضمين الكلمات بلغات متعددة ، ونماذج اللغة ومجموعة من قواعد التصفية السابقة واللاحقة. نحن نستخدم معايير التضمين وحيرة النماذج اللغوية جنبًا إلى جنب مع قواعد التصفية السابقة / اللاحقة لتكملة درجات خط الأساس LASER وفي النهاية نحصل على تحسين على مجموعة التطوير في كلا الزوجين اللغويين.', 'fr': "Dans ce document, nous décrivons notre soumission à la tâche de filtrage de corpus parallèle à l'aide de l'intégration de mots multilingues, de modèles linguistiques et d'un ensemble de règles de pré-filtrage et de post-filtrage. Nous utilisons les normes d'intégration et les perplexités des modèles de langage ainsi que les règles de pré-filtrage pour compléter les scores de base LASER et, au final, améliorer le jeu de développement dans les deux paires de langues.", 'es': 'En este documento describimos nuestro envío a la tarea de filtrado de corpus paralelos mediante la incrustación de palabras multilingües, modelos de lenguaje y un conjunto de reglas de filtrado previo y posterior. Utilizamos las normas de incrustación y las perplejidades de los modelos lingüísticos junto con las reglas de pre/post filtrado para complementar las puntuaciones de referencia de LASER y, al final, obtener una mejora en el conjunto de desarrollo en ambos pares de idiomas.', 'pt': 'Neste documento, descrevemos nossa submissão à tarefa de filtragem de corpus paralela usando incorporação de palavras multilíngue, modelos de linguagem e um conjunto de regras de pré e pós-filtragem. Usamos as normas de embedding e as perplexidades dos modelos de linguagem juntamente com regras de pré/pós-filtragem para complementar as pontuações da linha de base do LASER e, no final, obter uma melhoria no conjunto dev em ambos os pares de idiomas.', 'ja': 'このドキュメントでは、多言語の単語埋め込み、言語モデル、および事前フィルタリングルールと事後フィルタリングルールのアンサンブルを使用して、並列コーパスフィルタリングタスクへの送信について説明します。私たちは、レーザーベースラインスコアを補完するために、事前/事後フィルタリングルールと共に、言語モデルの埋め込みと複雑さの規範を使用し、両方の言語ペアの開発セットを改善します。', 'zh': '在本文档中,我们将用多语言词嵌入、语言模样及一系前后过漉法来描述我们向并行语料库过漉的提交。 臣等用嵌范及言语困惑及前/漉则以补LASER基线分数,而终于两言开集上改进。', 'ru': 'В этом документе мы описываем наше участие в задаче параллельной корпусной фильтрации с использованием многоязычного встраивания слов, языковых моделей и набора правил предварительной и последующей фильтрации. Мы используем нормы встраивания и недоумения языковых моделей наряду с правилами фильтрации до/после, чтобы дополнить базовые баллы ЛАЗЕРА и в конце концов получить улучшение набора dev в обеих языковых парах.', 'hi': 'इस दस्तावेज़ में हम बहुभाषी शब्द एम्बेडिंग, भाषा मॉडल और पूर्व और पोस्ट फ़िल्टरिंग नियमों की एक टुकड़ी का उपयोग करके समानांतर कॉर्पस फ़िल्टरिंग कार्य के लिए हमारे सबमिशन का वर्णन करते हैं। हम लेजर बेसलाइन स्कोर के पूरक के लिए पूर्व / पोस्ट फ़िल्टरिंग नियमों के साथ एम्बेडिंग के मानदंडों और भाषा मॉडल की उलझनों का उपयोग करते हैं और अंत में दोनों भाषा जोड़े में देव सेट पर सुधार प्राप्त करते हैं।', 'ga': 'Sa doiciméad seo déanaimid cur síos ar ár n-aighneacht don tasc scagtha corpais comhthreomhar ag baint úsáide as leabú focal ilteangach, samhlacha teanga agus ensemble de rialacha réamhscagtha agus iarscagtha. Bainimid úsáid as noirm leabú agus seachnaidí na múnlaí teanga mar aon le rialacha réamhscagtha/tar éis scagacháin chun na scóir bhunlíne LASER a chomhlánú agus sa deireadh faighimid feabhas ar an tacar forbartha sa dá phéire teanga.', 'el': 'Σε αυτό το έγγραφο περιγράφουμε την υποβολή μας στην εργασία παράλληλου φιλτραρίσματος σώματος χρησιμοποιώντας πολυγλωσσική ενσωμάτωση λέξεων, γλωσσικά μοντέλα και ένα σύνολο κανόνων προ και μετά φιλτραρίσματος. Χρησιμοποιούμε τους κανόνες ενσωμάτωσης και τις αμηχανία των γλωσσικών μοντέλων μαζί με κανόνες προ/μετά φιλτραρίσματος για να συμπληρώσουμε τις βαθμολογίες βάσης και στο τέλος να έχουμε μια βελτίωση στο σύνολο ανάπτυξης και στα δύο γλωσσικά ζεύγη.', 'hu': 'Ebben a dokumentumban többnyelvű szóbeágyazással, nyelvi modellekkel, valamint elő- és utószűrési szabályok együttese segítségével ismertetjük a párhuzamos korpuszűrési feladathoz való benyújtásunkat. A beágyazás normáit és a nyelvi modellek zavaróságait, valamint az elő/utólagos szűrési szabályokat használjuk, hogy kiegészítsük a LASER alapszintű pontszámokat és végül javuljunk a fejlesztési készleten mindkét nyelvpárban.', 'ka': 'ამ დოკუმენტში ჩვენ ჩვენი წარმოდგენებას პარალელური კორპუსს ფილტრინტის რაოდენობაში გამოყენებთ მრავალენგური სიტყვები, ენის მოდელები და წარმოდგენება წარმოდგენებების ჩვენ გამოვიყენებთ ნორმები, რომლებიც სახელის მოდელების შესაძლებლობა და სახელის შესაძლებლობა, რომლებიც სახელის/პოსტის ფილტრირების წესების შესაძლებელად LASER ბაზილური წესების შესაძლებელად და საკუთ', 'kk': 'Бұл құжатта біз параллелі корпус сүзгілеу тапсырмасына көп тілді сөздерді ендіру, тіл үлгілерін және алдын- ала сүзгілеу ережелерін қолданып жібереміз. Біз LASER негізгі сүзгілеу ережелерін доғару үшін тіл үлгілерінің нормаларын және тіл үлгілерінің тәуелсіздігін қолданып, соңында екеуі тіл екеуінде жақсарту үшін қолданамыз.', 'it': "In questo documento descriviamo la nostra sottomissione all'attività di filtraggio del corpus parallelo utilizzando incorporazione di parole multilingue, modelli linguistici e un insieme di regole di filtraggio pre e post. Usiamo le norme di embedding e le perplessità dei modelli linguistici insieme alle regole di filtraggio pre/post per integrare i punteggi di base LASER e alla fine ottenere un miglioramento sul set di sviluppo in entrambe le coppie linguistiche.", 'lt': 'Šiame dokumente mes apibūdiname savo pateiktumą lygiagrečiai korpuso filtravimo užduotims naudojant daugiakalbį žodžių įterpimą, kalbų modelius ir prieš ir po filtravimo taisyklių rinkinį. Siekdami papildyti LASER pradinius taškus naudojame kalbų modelių įtraukimo normas ir perpleksijas, taip pat prieš ir po filtravimo taisykles ir galiausiai pagerinti dev nustatymą abiejose kalbų porose.', 'mk': 'Во овој документ го опишуваме нашето поднесување на паралелната задача за филтрирање на корпус користејќи мултијазични зборови вградување, јазички модели и ансембл на правила за пре- и постфилтрирање. Ние ги користиме нормите за вложување и збунувањата на јазичките модели заедно со правилата за филтрирање пред/по филтрирање за да ги комплиментираме основните резултати на ЛАСЕР и на крајот да добиеме подобрување на сетот на dev во двете јазички парови.', 'ms': 'Dalam dokumen ini kami menggambarkan penghantaran kami ke tugas penapisan corpus selari menggunakan penyembedding perkataan berbilang bahasa, model bahasa dan kumpulan peraturan penapisan pra dan pos. Kami menggunakan norm penyembedding dan kekacauan model bahasa bersama-sama dengan peraturan penapisan pre/post untuk menambahkan skor dasar LASER dan akhirnya mendapat peningkatan pada set dev dalam kedua-dua pasangan bahasa.', 'ml': 'ഈ രേഖയില്\u200d ഞങ്ങള്\u200d നമ്മുടെ മുഴുവന്\u200d പാരല്\u200d കോര്\u200dപ്പുസ് ഫില്\u200dറ്റര്\u200d ജോലിയിലേക്ക് വിശദീകരിക്കുന്നു. പല ഭാഷ വാക്കുകള്\u200d അകത്തേക്ക്, ഭാ ലാസെര്\u200d ബെസ്ലൈന്\u200d സ്കോര്\u200d പൂര്\u200dത്തീകരിക്കാന്\u200d മുമ്പ്/പോസ്റ്റ് ഫില്\u200dറ്റര്\u200d നിയമങ്ങളോടൊപ്പം ഞങ്ങള്\u200d ഭാഷ മോഡലുകളുടെ നിയമങ്ങളും ഉപയോഗിക്കുന്ന', 'mt': 'F’dan id-dokument niddeskrivu s-sottomissjoni tagħna għall-kompitu parallelu ta’ filtrazzjoni tal-korpus bl-użu ta’ inkorporazzjoni multilingwi ta’ kliem, mudelli lingwistiċi u ensemble ta’ regoli ta’ qabel u ta’ wara l-filtrazzjoni. Aħna nużaw in-normi ta’ inkorporazzjoni u l-perplessitajiet tal-mudelli lingwistiċi flimkien mar-regoli ta’ filtrazzjoni ta’ qabel/wara biex jikkumplimentaw il-punteġġi tal-linja bażi LASER u fl-aħħar mill-aħħar jiksbu titjib fis-sett dev fiż-żewġ pari lingwistiċi.', 'mn': 'Энэ баримтын дотор бид параллел корпус цэвэрлэх даалгаварыг олон хэл хэлний нэвтрүүлэх, хэл загварууд болон цэвэрлэх загваруудыг ашиглан тайлбарлаж байна. Бид хэл загварын хөгжлийн нормуудыг ашиглаж LASER суурь шулууны оноо нэмэгдүүлэхэд хэл загварын хөгжлийн хувьд хөгжлийг ашигладаг.', 'pl': 'W niniejszym dokumencie opisujemy nasze poddanie się zadaniu filtrowania równoległego korpusu przy użyciu wielojęzycznego osadzania słów, modeli językowych oraz zestawu reguł filtrowania wstępnego i post. Wykorzystujemy normy osadzenia i zagadnienia modeli językowych wraz z regułami filtrowania pre/post, aby uzupełnić wyniki bazowe LASER i w końcu uzyskać poprawę zestawu dev w obu parach językowych.', 'no': 'I dette dokumentet beskriver vi tillegget vårt til den parallelle filteringsoppgåva korpus med fleire språk innebygging, språk- modeller og ein ensembel av filterreglane før og post. Vi bruker standardene for innbygging og kompleksiteten av språk-modeller saman med filterreglane før/post for å komplementa LASER-baseline-poeng og i slutten får ein forbedring på dev-modeller sett i begge språk-par.', 'ro': 'În acest document descriem depunerea noastră la sarcina de filtrare paralelă a corpurilor folosind încorporarea cuvintelor multilingve, modele lingvistice și un ansamblu de reguli de filtrare pre și post. Folosim normele de încorporare și perplexitățile modelelor lingvistice împreună cu regulile de filtrare pre / post pentru a completa scorurile de bază LASER și, în cele din urmă, obține o îmbunătățire a setului de dezvoltare în ambele perechi de limbi.', 'so': 'Qoraalkan waxaynu ku qornaa lifaaqyadeena u dhiibannaa qasabka filteriga ee lambarka ah ee lagu isticmaalayo hadalka luuqadaha kala duduwan oo ku qoran, tusaale ahaan luuqada iyo koob ka mid ah qaynuunnada firaaqada. We use the norms of embedding and the perplexities of language models along with pre/post filtering rules to complement the LASER baseline scores and in the end get an improvement on the dev set in both language pairs.', 'sr': 'U ovom dokumentu opisujemo svoju predanost paralelnom filtriranju korpusa koristeći multijezičke reči uključujući, jezičke modele i ensemble pravila pre i post filtriranja. Koristimo norme uključenja i kompleksnosti jezičkih modela zajedno sa pravilima filtriranja pre/post kako bi dodali početne rezultate LASER-a i na kraju dobili poboljšanje dev postavljenog u obje jezičke pare.', 'si': 'මේ විස්තාරයේ අපි අපේ සමාන්\u200dය කොර්පුස් පරීක්ෂණ කාර්යාවට පැහැදිලි කරනවා වගේ භාෂාවික වචනය සම්බන්ධ කරනවා, භාෂාවික අපි භාෂාව මොඩේල්ස් එක්ක සංවිධානය සහ භාෂාව මොඩේල්ස් එක්ක ප්\u200dරතිස්ථාපනය කරන්න ප්\u200dරමාණය භාවිතා කරනවා LASER මූලික ප්\u200dරමාණය සම්පූර', 'sv': 'I det här dokumentet beskriver vi vår inlämning till den parallella korpusfiltreringsuppgiften med flerspråkig ordinbäddning, språkmodeller och en uppsättning regler för och efter filtrering. Vi använder normerna för inbäddning och förvirringar i språkmodeller tillsammans med regler för pre/post filtrering för att komplettera LASER baslinjepoäng och i slutändan få en förbättring av utvecklingsuppsättningen i båda språkparen.', 'ta': 'இந்த ஆவணத்தில் நாம் இணைய கோர்புஸ் வடிகட்டி செயலை விவரிக்கிறோம் பல மொழி வார்த்தை உள்ளடக்கம், மொழி மாதிரிகள் மற்றும் முன்னால் ஒரு ஒதுக நாம் மொழி மாதிரிகளின் உள்ளடக்கம் மற்றும் சிக்கல்களின் முன்/போஸ்ட் வடிகட்டி விதிகளுடன் பயன்படுத்தி LASER அடிப்படைக்கோடு மதிப்புகளை நிறைவேற்றுவதற்க', 'ur': 'ہم اس دکھانے میں اپنے تسلیم کو مشابل کورپوس فیلٹرینگ کی تابع کے مطابق مختلف زبان کلمات کے مطابق بیان کرتے ہیں، زبان مدلکوں اور پیش اور پوسٹ فیلٹرینگ قانون کے ایک انسبیل کے مطابق۔ ہم زبان نمڈلوں کے مطابق اسکور اور زبان نمڈلوں کے مطابق پیش/پوسٹ فیلٹرینگ قانون کے ساتھ استعمال کرتے ہیں LASER بنیس لین اسکور کے مطابق اور آخر میں دونوں زبان جوڑوں میں ڈیو سیٹ کے مطابق اضافہ ہوتے ہیں.', 'uz': "Ushbu hujjatda biz bir necha tildagi so'zlar ichiga, tillar modellari va oldin filterlash qoidalari yordamida qoʻllanmalarni parallel corpus filterlash vazifasini ifodalamiz. Biz lug modellarini koʻpaytirish uchun oldin/posting filterlash qoidalari bilan foydalanamiz va oxirida, AQSH asosiy qoidani bajarish uchun dasturlarni ishlatish va ikkita tillar ikkita xil bo'lgan dev'da yaxshi ko'paydi.", 'vi': 'Trong tài liệu này, chúng tôi mô tả sự cung cấp của chúng tôi cho công việc lọc tập hợp song song, dùng sự nhúng vào từ nhiều dạng, các mô hình ngôn ngữ và một kết hợp của các quy tắc trước và sau khi lọc. Chúng tôi sử dụng các tiêu chuẩn của sự nhúng mũi và sự phức tạp của các mô- đun ngôn ngữ cùng với các quy tắc lọc trước/sau để bổ sung cho điểm cơ sở cơ bản LAERR và cuối cùng đạt được một cải thiện thiết lập nhiệt trong cả hai cặp ngôn ngữ.', 'bg': 'В този документ описваме нашето подаване на задачата за паралелно филтриране на корпуси, използвайки многоезично вграждане на думи, езикови модели и ансамбъл от правила за предварително и след филтриране. Използваме нормите за вграждане и объркването на езиковите модели заедно с правилата за предварително/след филтриране, за да допълним базовите оценки на Лазера и в крайна сметка да получим подобрение на разработката в двете езикови двойки.', 'hr': 'U ovom dokumentu opisujemo svoju predanost paralelnom filtriranju korpusa koristeći multijezičke riječi uključujući, jezičke modele i ensemble pravila pre i post filtriranja. Koristimo norme uključenja i kompleksnosti jezičkih modela zajedno s pravilima filtriranja pre/post kako bi dodali početne rezultate LASER-a i na kraju dobili poboljšanje dev postavljenog u obje jezičke pare.', 'nl': 'In dit document beschrijven we onze inzending aan de parallelle corpusfiltertaak met behulp van meertalige woord embedding, taalmodellen en een ensemble van pre- en post filterregels. We gebruiken de normen van embedding en de verwarring van taalmodellen samen met pre/post filterregels om de LASER baseline scores aan te vullen en uiteindelijk een verbetering te krijgen op de dev set in beide taalparen.', 'da': 'I dette dokument beskriver vi vores indsendelse til den parallelle korpusfiltreringsopgave ved hjælp af flersprogede ordindlejring, sprogmodeller og et sæt regler for pre og post filtrering. Vi bruger normerne for indlejring og forvirring af sprogmodeller sammen med pre/post filtreringsregler for at supplere LASER baseline scores og i sidste ende få en forbedring af udviklingssættet i begge sprogpar.', 'de': 'In diesem Dokument beschreiben wir unsere Einreichung zur parallelen Korpusfilteraufgabe mit mehrsprachiger Worteinbettung, Sprachmodellen und einem Ensemble von Vor- und Nachfilterregeln. Wir verwenden die Normen der Einbettung und die Verwirrungen von Sprachmodellen zusammen mit Pre/Post Filterregeln, um die LASER Baseline Scores zu ergänzen und am Ende eine Verbesserung des Entwicklersets in beiden Sprachpaaren zu erzielen.', 'id': 'Dalam dokumen ini kami menggambarkan pengiriman kami ke tugas penyaringan corpus paralel menggunakan penyaringan kata berbagai bahasa, model bahasa dan sebuah ensemble peraturan pre- dan post-filtering. Kami menggunakan norma penyembedding dan perplexitas model bahasa bersama dengan peraturan pre/post filtering untuk menambahkan nilai dasar LASER dan akhirnya mendapatkan peningkatan pada set dev dalam kedua pasangan bahasa.', 'fa': 'در این سند ما تسلیم کردن ما به وظیفه فیلترینگ کورپوس متفاوت را با استفاده از کلمه\u200cهای متعدد زبان، مدل\u200cهای زبان و نشان\u200cهای قانون فیلترینگ پیش و پست توصیف می\u200cکنیم. ما از قوانین استفاده می\u200cکنیم که مدل\u200cهای زبان\u200cها و قانون\u200cهای فیلترینگ پیش/پست استفاده می\u200cکنند تا نمایش\u200cهای پایین\u200cخط LASER را تعمل کنیم و در نهایت، توسعه\u200cی توسعه\u200cی توسعه\u200cهای توسعه در هر دو جفت زبان\u200cها بهتر شود', 'sw': 'Katika nyaraka hii tunaelezea ujumbe wetu wa kuchuja vifaa vya vifaa vinavyofanana kwa kutumia maneno ya lugha mbalimbali, mifano ya lugha na kiungo cha sheria za kabla na kuweka nyaraka za kuchuja. Tunatumia utamaduni wa kuingia na matatizo ya mifano ya lugha pamoja na kanuni za kuchuja/posti ili kutimiza vipindi vya msingi vya LASER na hatimaye kupata maendeleo juu ya mpango ulioandaliwa katika viwili viwili vya lugha.', 'sq': 'In this document we describe our submission to the parallel corpus filtering task using multilingual word embedding, language models and an ensemble of pre and post filtering rules.  Ne përdorim normat e përfshirjes dhe ngatërresat e modeleve gjuhësore së bashku me rregullat e filtrimit para/pas për të komplementuar rezultatet bazë të LASER dhe në fund të marrim një përmirësim në dev-set në të dy palët gjuhësore.', 'tr': 'Bu senede biz öz yönümizi paralel korpus filtrelemesi täblisasyny multi dil sözleri girişinde, dil nusgalaryny we ön we post filtrelemesi täblisasyny ulanýarys. Biz LASER baseline notlaryny suppllemek üçin düzenlemek we dil nusgalarynyň sarhoşylygyny we bellenenlerde düzenlemek üçin ullanýarys.', 'af': "In hierdie dokument beskrywe ons onderwerp tot die parallele korpus filtering taak met gebruik van multilinglike woord inbêring, taal modele en 'n ensemble van voor en post filtering reëls. Ons gebruik die norme van inbêding en die perpleksies van taal modelles saam met voor/post filtering reëls om die LASER basisline telling te voldoen en in die einde kry 'n verbetering op die dev stel in beide taal pare.", 'hy': 'Այս փաստաթղթի մեջ մենք նկարագրում ենք մեր ներկայացումը զուգահեռ կորպոս ֆիլտրելու առաջադրանքին օգտագործելով բառերի բառերի ներկայացումը, լեզվի մոդելները և նախաֆիլտրման և հետագա կանոնների համակարգը: Մենք օգտագործում ենք լեզվի մոդելների ներգրավման նորմերը և խառնաշփոթությունները, նախ-հետո ֆիլտրելու կանոնները, որպեսզի լրացնենք LASER-ի հիմնական գնահատականները, և վերջապես ստանանք բարելավում երկու լեզվի զույգերի Dev-ի վերաբերյալ:', 'az': 'Bu səhifədə bizim müdafiyyətimizi paralel korpus filtrləmə görevinə çoxlu dil sözləri, dil modelləri və filtrləmə qaydalarını istifadə edirik. Biz LASER səhifələrini tamamlamaq üçün dil modellərin və filtrləmə qaydaları ilə birlikdə dil modellərin müxtəlifliyini və sonunda da dev qoyulması üçün hər iki dil çiftində yaxşılaşdırmaq üçün istifadə edirik.', 'am': 'በዚህ ሰነድ ውስጥ የባሕላዊ ቃላት አካባቢ፣ ቋንቋ ሞዴላዎችን እና የፊደል አጣራዎች ሥርዓቶችን በመጠቀም እና አጣራዎችን ለመጠቀም እናሳውቃለን፡፡ የቋንቋዎች አካባቢ እና የፊደል/ፖስታ አጣራ ሥርዓቶችን ለመጨመር እና በመጨረሻው የLASER መደገፊያ ሳጥን ለመጨመር እና በሁለቱም ቋንቋዎች ሁለት ዓይነቶች ላይ የሚደረገውን አካባቢ እናደርጋለን፡፡', 'bs': 'U ovom dokumentu opisujemo našu predanost paralelnom filtriranju korpusa koristeći multijezičke riječi uključujući, jezičke modele i ensemble pravila pre i post filtriranja. Koristimo norme uključenja i kompleksnosti jezičkih modela zajedno sa pravilima filtriranja pre/post kako bi se doprinosili početnim rezultatima LASER-a i na kraju dobili poboljšanje dev postavljenog u oba jezičkog pare.', 'ca': "En aquest document descrivim la nostra subministració a la tasca paral·lela de filtració de corpus fent servir l'incorporació de paraules multilingües, models de llenguatge i un conjunt de regles de pre- i post-filtració. Utilitzem les normes d'incorporació i les perplexitats dels models de llenguatge juntament amb les regles de filtració pre/post per complementar les puntuacions de base LASER i finalment obtenim una millora en el set de dev en ambdós parells de llenguatges.", 'bn': 'এই নথিতে আমরা প্যারালেল কোর্পাস ফিল্টারিং কাজের প্রতি আমাদের জমা বর্ণনা করি বহুভাষী শব্দ, ভাষা মডেল এবং পূর্ববর্তী নিয়ম পোস্ট করে  আমরা ভাষার মডেলের পূর্ব/পোস্ট ফিল্টারিং নিয়মের সাথে ব্যবহার করি ল্যাসের বেসাইন স্কোর পূর্ণ করার জন্য এবং শেষে দুই ভাষার জোড়ায় ডিভি নির্ধারণ করা', 'ko': '본고에서 우리는 다중 언어 단어 삽입, 언어 모델과 전후 필터 규칙의 집합을 사용하여 병렬 언어 자료 라이브러리 필터 작업의 제출을 설명한다.우리는 삽입 규범과 언어 모델의 복잡성 및 전/후 필터 규칙을 사용하여 레이저 기선 점수를 보충하고 최종적으로 두 언어의 dev집을 개선한다.', 'fi': 'Tässä asiakirjassa kuvailemme rinnakkaisen korpusen suodatustehtävän suorittamista monikielisen sanaupotuksen, kielimallien ja ennen- ja jälkisuodatussääntöjen yhdistelmän avulla. Käytämme upotusnormeja ja kielimallien hämmennyksiä sekä ennen/jälkeen suodatussääntöjä täydentämään LASER-lähtökohtia ja lopulta parannamme molempien kieliparien kehitystasoa.', 'et': 'Selles dokumendis kirjeldame oma esitamist paralleelse korpuse filtreerimise ülesandele, kasutades mitmekeelset sõna manustamist, keelemudeleid ning eel- ja järelhiltreeglite ansamblit. Kasutame keelemudelite põimimise norme ja segadust koos eelneva/järgse filtreerimise reeglitega LASER baaskooride täiendamiseks ning lõpuks parandame mõlema keelepaari arenduskomplekti.', 'cs': 'V tomto dokumentu popisujeme naše podání paralelnímu korpusovému filtrování pomocí vícejazyčného vložení slov, jazykových modelů a souboru pravidel předfiltrování a post filtrování. Využíváme normy vkládání a zmatenosti jazykových modelů spolu s pravidly pre/post filtrování k doplnění základního skóre LASER a nakonec získáme zlepšení vývojářské sady v obou jazykových párech.', 'jv': 'Nang dokumen iki, kita dadi nglanggar sampeyan mrogram kuwi nggawe barang sampeyan karo perusahaan kelangan bangsa bukisan, model dan ingkang sampeyan karo perusahaan bantuan karo Last.fm Awak dhéwé', 'ha': "Daga wannan takardan, muna bayyana inyanzu zuwa aikin filteri na parallel-nau'in rubutu da ke amfani da shiryoyin ayuka masu cikin multi-lingui, misalin harshe da wani embemboli na gaba da kuma a lokacin rubutun filteri. Tuna amfani da shiryoyin ayuka da masu shakka cikin harshen sami da sharuɗun filtering na gaba/poste, dõmin su cika score-kwanan LDASR kuma a ƙarami, za'a samar da kayan daidaita kan dasa cikin biyu-harshe.", 'sk': 'V tem dokumentu opisujemo našo predložitev opravila vzporednega filtriranja korpusov z uporabo večjezičnega vdelanja besed, jezikovnih modelov in skupine pravil pred in po filtriranju. Za dopolnitev osnovnih rezultatov LASER uporabljamo norme vdelave in zmedenosti jezikovnih modelov skupaj s pravili pred/po filtriranju in na koncu dobimo izboljšanje razvojnega nabora v obeh jezikovnih parih.', 'he': 'In this document we describe our submission to the parallel corpus filtering task using multilingual word embedding, language models and an ensemble of pre and post filtering rules.  We use the norms of embedding and the perplexities of language models along with pre/post filtering rules to complement the LASER baseline scores and in the end get an improvement on the dev set in both language pairs.', 'bo': 'ཡིག་གེའི་ནང་དུ་ང་ཚོས་དབུགས་ཆ་མཐུན་གྱི་དབུགས་ཆ་སྒྲིག་ཀྱི་འཚོལ་ཞིབ་ཡོད་པའི་བྱ་ཚིག We use the norms of embedding and the perplexities of language models along with pre/post filtering rules to complement the LASER baseline scores and in the end get an improvement on the dev set in both language pairs.'}
{'en': 'PATQUEST : Papago Translation Quality Estimation', 'es': 'PATQUEST: Estimación de calidad de traducción de Papago', 'ar': 'PATQUEST: تقدير جودة ترجمة Papago', 'pt': 'PATQUEST: Estimativa da Qualidade da Tradução Papago', 'fr': 'PATQUEST\xa0: Estimation de la qualité de traduction Papago', 'ja': 'PATQUEST: Papago Translation Quality Estimation', 'zh': 'PATQUEST:日晖译质评估', 'ru': 'PATQUEST: Оценка качества перевода Papago', 'hi': 'PATQUEST: Papago अनुवाद गुणवत्ता अनुमान', 'ga': 'PATQUEST: Meastachán Cáilíochta Aistriúcháin Papago', 'ka': 'პატარა', 'el': 'PATQUEST: Εκτίμηση ποιότητας μετάφρασης Papago', 'hu': 'PATQUEST: Papago fordítási minőségbecslés', 'it': 'PATQUEST: Valutazione della qualità della traduzione di Papago', 'kk': 'PATQUEST: Papago аудару сапасының оқиғасы', 'lt': 'PATQUEST: Papago vertimo kokybės vertinimas', 'mk': 'Оценка на квалитетот на преводот на Папаго', 'ms': 'PATQUEST: Penghargaan Kualiti Terjemahan Papago', 'ml': 'പാട്ട്ക്യൂസ്റ്റ്: പാപ്പാഗോയുടെ പരിഭാഷപൂര്\u200dണ്ണമായ എസ്റ്റിമേഷന്\u200d', 'mt': 'PATQUEST: Stima tal-Kwalità tat-Traduzzjoni Papago', 'mn': 'ШАБЛАГАН: Papago Translation Quality Estimation', 'no': 'PATQUEST: Estimasjon av omsetjingskvalitet Papago', 'pl': 'PATQUEST: Ocena jakości tłumaczeń Papago', 'ro': 'PATQUEST: Estimarea calității traducerii Papago', 'sr': 'Oèekivanje kvalitete prevoda Papago', 'si': 'PATQUEST: Papago අවවාද කුළුවත් අනුමාණය', 'so': 'PATQUEST: Papago Translation Quality Estimation', 'ta': 'PATQUEST: Papago மொழிபெயர்ப்பு தரம் கணக்கீடு', 'ur': 'پاٹ کیسٹ: پاپاگو ترجمہ کیفیت کا ارزش', 'sv': 'PATQUEST: Bedömning av kvaliteten på översättning från Papago', 'uz': 'Tarjima taĘĽminlovchi', 'vi': 'bảng phân tích chất lượng Papago', 'bg': 'Оценка на качеството на превода на Папаго', 'nl': 'PATQUEST: schatting van de vertaalkwaliteit van Papago', 'da': 'PATQUEST: Vurdering af kvaliteten på oversættelse af Papago', 'hr': 'Očekivanje kvalitete prevoda Papago', 'de': 'PATQUEST: Schätzung der Übersetzungsqualität von Papago', 'id': 'PATQUEST: Papago Translation Quality Estimation', 'fa': 'تقریبا کیفیت ترجمه پاپاگو', 'ko': 'PATQUEST:Papago 번역 품질 평가', 'sw': 'HABARI: Utafiti wa Tafsiri wa Papago', 'af': 'Vertaling Kwaliteit', 'tr': 'Çeviri', 'sq': 'PATQUEST: Vlerësimi i cilësisë së Papago Translation', 'am': 'Papago Translation Quality Estimation', 'hy': 'Պափագո թարգմանության որակի գնահատումը', 'bn': 'প্যাটকুয়েস্ট: পাপাগো অনুবাদের মান গণনা', 'az': 'PATQUEST: Papago T…ôrc√ºm…ô N…ôviyy…ôti Qƒ±ymeti', 'bs': 'Procjena kvalitete prevoda Papago', 'ca': 'PATQUEST: Estimació de la qualitat de la traducció del Papago', 'cs': 'PATQUEST: Odhad kvality překladu Papago', 'et': 'PATQUEST: Papago tõlkekvaliteedi hindamine', 'fi': 'PATQUEST: Papago Translation Quality Estimation', 'sk': 'PATQUEST: Ocena kakovosti prevoda Papago', 'jv': 'NILO: Terjamahan kang Pak-Pak Terjamahan', 'he': 'PATQUEST: Papago Translation Quality Estimation', 'bo': 'PATQUEST: Papago Translation Quality Estimation', 'ha': 'KCharselect unicode block name'}
{'en': 'This paper describes the system submitted by Papago team for the quality estimation task at WMT 2020. It proposes two key strategies for quality estimation : (1) task-specific pretraining scheme, and (2) task-specific data augmentation. The former focuses on devising learning signals for pretraining that are closely related to the downstream task. We also present data augmentation techniques that simulate the varying levels of errors that the downstream dataset may contain. Thus, our PATQUEST models are exposed to erroneous translations in both stages of task-specific pretraining and finetuning, effectively enhancing their generalization capability. Our submitted models achieve significant improvement over the baselines for Task 1 (Sentence-Level Direct Assessment ; EN-DE only), and Task 3 (Document-Level Score).', 'ar': 'تصف هذه الورقة النظام الذي قدمه فريق Papago لمهمة تقدير الجودة في WMT 2020. وتقترح استراتيجيتين رئيسيتين لتقدير الجودة: (1) مخطط التدريب المسبق الخاص بالمهمة ، و (2) زيادة البيانات الخاصة بالمهمة. يركز الأول على ابتكار إشارات تعليمية للتدريب المسبق والتي ترتبط ارتباطًا وثيقًا بمهمة المصب. نقدم أيضًا تقنيات زيادة البيانات التي تحاكي المستويات المتفاوتة من الأخطاء التي قد تحتويها مجموعة البيانات النهائية. وبالتالي ، تتعرض نماذج PATQUEST الخاصة بنا لترجمات خاطئة في كلتا مرحلتي التدريب المسبق والضبط الدقيق الخاصين بالمهمة ، مما يعزز بشكل فعال قدرتها على التعميم. تحقق نماذجنا المقدمة تحسينًا ملحوظًا على خطوط الأساس للمهمة 1 (التقييم المباشر على مستوى الجملة ؛ EN-DE فقط) والمهمة 3 (درجة مستوى المستند).', 'pt': 'Este artigo descreve o sistema apresentado pela equipe Papago para a tarefa de estimativa de qualidade no WMT 2020. Ele propõe duas estratégias principais para a estimativa de qualidade: (1) esquema de pré-treinamento específico da tarefa e (2) aumento de dados específico da tarefa. O primeiro se concentra na criação de sinais de aprendizado para pré-treinamento que estão intimamente relacionados à tarefa posterior. Também apresentamos técnicas de aumento de dados que simulam os vários níveis de erros que o conjunto de dados downstream pode conter. Assim, nossos modelos PATQUEST são expostos a traduções errôneas em ambos os estágios de pré-treinamento e ajuste fino de tarefas específicas, aumentando efetivamente sua capacidade de generalização. Nossos modelos submetidos alcançam melhorias significativas em relação às linhas de base para a Tarefa 1 (Avaliação direta em nível de sentença; somente EN-DE) e Tarefa 3 (Pontuação em nível de documento).', 'fr': "Cet article décrit le système soumis par l'équipe de Papago pour la tâche d'estimation de la qualité lors du WMT 2020. Il propose deux stratégies clés pour l'estimation de la qualité\xa0: (1) un programme de pré-entraînement spécifique à la tâche et (2) l'augmentation des données spécifiques à la tâche. Le premier se concentre sur la conception de signaux d'apprentissage pour la préformation qui sont étroitement liés à la tâche en aval. Nous présentons également des techniques d'augmentation de données qui simulent les différents niveaux d'erreurs que l'ensemble de données en aval peut contenir. Ainsi, nos modèles PATQUEST sont exposés à des traductions erronées lors des deux étapes de pré-entraînement et de réglage fin spécifiques aux tâches, ce qui améliore efficacement leur capacité de généralisation. Nos modèles soumis obtiennent une amélioration significative par rapport aux niveaux de référence pour la tâche 1 (évaluation directe au niveau de la phrase\xa0; EN-DE uniquement) et la tâche 3 (note au niveau du document).", 'es': 'Este artículo describe el sistema presentado por el equipo de Papago para la tarea de estimación de la calidad en el WMT 2020. Propone dos estrategias clave para la estimación de la calidad: (1) esquema de preentrenamiento específico de la tarea y (2) aumento de datos específico de la tarea. El primero se centra en diseñar señales de aprendizaje para el preentrenamiento que estén estrechamente relacionadas con la tarea posterior. También presentamos técnicas de aumento de datos que simulan los diferentes niveles de errores que puede contener el conjunto de datos descendente. Por lo tanto, nuestros modelos PATQUEST están expuestos a traducciones erróneas en ambas etapas de preentrenamiento específico de la tarea y puesta a punto, lo que mejora eficazmente su capacidad de generalización. Nuestros modelos presentados logran una mejora significativa con respecto a las líneas de base para la Tarea 1 (Evaluación directa a nivel de oración; solo EN-DE) y la Tarea 3 (Puntuación a nivel de documento).', 'hi': 'यह पेपर डब्ल्यूएमटी 2020 में गुणवत्ता अनुमान कार्य के लिए पापागो टीम द्वारा प्रस्तुत प्रणाली का वर्णन करता है। यह गुणवत्ता आकलन के लिए दो प्रमुख रणनीतियों का प्रस्ताव करता है: (1) कार्य-विशिष्ट प्रीट्रेनिंग योजना, और (2) कार्य-विशिष्ट डेटा वृद्धि। पूर्व प्रीट्रेनिंग के लिए सीखने के संकेतों को तैयार करने पर केंद्रित है जो डाउनस्ट्रीम कार्य से निकटता से संबंधित हैं। हम डेटा संवर्धन तकनीकों को भी प्रस्तुत करते हैं जो त्रुटियों के विभिन्न स्तरों का अनुकरण करते हैं जो डाउनस्ट्रीम डेटासेट में हो सकते हैं। इस प्रकार, हमारे PATQUEST मॉडल कार्य-विशिष्ट pretraining और finetuning के दोनों चरणों में गलत अनुवाद के संपर्क में हैं, प्रभावी रूप से उनकी सामान्यीकरण क्षमता को बढ़ाने. हमारे प्रस्तुत मॉडल कार्य 1 (वाक्य-स्तर प्रत्यक्ष मूल्यांकन) के लिए बेसलाइन पर महत्वपूर्ण सुधार प्राप्त करते हैं; केवल EN-DE), और कार्य 3 (दस्तावेज़-स्तर स्कोर).', 'ja': '本稿では、WMT 2020の品質推定タスクのためにPapagoチームが提出したシステムについて説明する。これは、品質推定のための2つの主要な戦略を提案しています。（ 1 ）タスク固有の事前トレーニングスキーム、および（ 2 ）タスク固有のデータ拡張。前者は、下流の課題に密接に関連する事前トレーニングのための学習シグナルを考案することに焦点を当てている。また、ダウンストリームデータセットに含まれる可能性のあるさまざまなレベルのエラーをシミュレートするデータ拡張技術も提示しています。したがって、当社のPATQUESTモデルは、タスク固有の事前トレーニングと微調整の両方の段階で誤った翻訳にさらされ、一般化能力を効果的に向上させます。提出されたモデルは、タスク1 （ Sentence - Level Direct Assessment; EN - DEのみ）とタスク3 （ Document - Level Score ）のベースラインを大幅に改善しています。', 'zh': '本文引Papago团队为WMT 2020质质提交之统。 立二要策:(1)务特定预练方略,及(2)任特定之数增强。 前者侧重于计与下流相关者预习信号。 又引数增强之术,可以模拟下流数据集或包含之差谬。 是以PATQUEST形特定于预练微调,皆露于非译,有益于泛化能。 我们提交的模形比任1(句子直评。 仅限 EN-DE)任 3(文档级分)。', 'ru': 'В настоящем документе описывается система, представленная группой Papago для задачи оценки качества на WMT 2020. В нем предлагаются две ключевые стратегии оценки качества: (1) схема предварительной подготовки по конкретным задачам и (2) расширение данных по конкретным задачам. Первое направление сосредоточено на разработке обучающих сигналов для предварительной подготовки, которые тесно связаны с задачей последующего этапа. Мы также предлагаем методы дополнения данных, которые имитируют различные уровни ошибок, которые может содержать последующий набор данных. Таким образом, наши модели PATQUEST подвергаются ошибочным переводам на обоих этапах предварительного обучения и тонкой настройки, что эффективно повышает их способность к обобщению. Наши представленные модели достигают значительного улучшения по сравнению с исходными данными для задачи 1 (прямая оценка на уровне предложения; только EN-DE) и задачи 3 (оценка на уровне документа).', 'ga': 'Déanann an páipéar seo cur síos ar an gcóras a chuir foireann Papago isteach don tasc um mheastachán cáilíochta ag WMT 2020. Molann sé dhá phríomhstraitéis le haghaidh meastachán cáilíochta: (1) scéim réamhoiliúna tasc-shonracha, agus (2) méadú sonraí tasc-shonracha. Díríonn an chéad cheann ar chomharthaí foghlama a cheapadh don réamhoiliúint a bhaineann go dlúth leis an tasc iartheachtacha. Cuirimid i láthair freisin teicnící méadaithe sonraí a shamhlaíonn na leibhéil éagsúla earráidí a d’fhéadfadh a bheith sa tacar sonraí iartheachtacha. Mar sin, tá ár samhlacha PATQUEST nochta d’aistriúcháin earráideacha sa dá chéim den réamhoiliúint agus mionchoigeartú tasc-shonrach, rud a chuireann lena gcumas ginearálaithe go héifeachtach. Tá feabhas suntasach bainte amach ag na samhlacha a cuireadh isteach againn thar na bonnlínte do Thasc 1 (Measúnú Díreach ar Leibhéal Pianbhreithe; EN-DE amháin), agus do Thasc 3 (Scór Leibhéil an Doiciméid).', 'ka': 'ამ დოკუნტის სისტემა, რომელიც ბაპაგოგის ჯგუფის გადატანა WMT 2020-ში საკუთარი განსაზღვრებისთვის. იგი წყველას ორი კლავის სტრატიგური განსაზღვრებისთვის: პირველი იყო სწავლების სიგნალების შესაძლებლობა, რომლებიც მხოლოდ დაკავშირებულია ჩვენი საქმე. ჩვენ ასევე მონაცემების აგგენტიკაციის ტექნოგიები, რომლებიც შეცდომის განსხვავებული დონეების სიმულაციას, რომლებიც შეიძლება შეიძლება ჩვენ ჩვენ ამიტომ, ჩვენი PATQUEST მოდელები გამოიყენება შეცდომა გადატყვებების ორივე ფაესებში საქმედებო სპექტიფიკური გადატყვებების და საქმედებო შესაძლებლობას, ეფექტიურად უფრო მეტი ჩვენი მოდულების მოდელები გავაკეთებთ მნიშვნელოვანი გაუკეთება 1. დავალებისთვის (მხოლოდ სიტყვების დონეზე მისაღები; მხოლოდ EN-DE) და 3. დავალება (დოკუმენტის დონეზე).', 'el': 'Η παρούσα εργασία περιγράφει το σύστημα που υπέβαλε η ομάδα Παπαγό για την εργασία εκτίμησης ποιότητας στο WMT 2020. Προτείνει δύο βασικές στρατηγικές για την εκτίμηση της ποιότητας: (1) πρόγραμμα προετοιμασίας για κάθε εργασία και (2) αύξηση δεδομένων για κάθε εργασία. Το πρώτο επικεντρώνεται στην εκπόνηση μαθησιακών σημάτων για την προ-εκπαίδευση που σχετίζονται στενά με το μεταγενέστερο έργο. Παρουσιάζουμε επίσης τεχνικές αύξησης δεδομένων που προσομοιώνουν τα ποικίλα επίπεδα σφαλμάτων που μπορεί να περιέχει το μεταγενέστερο σύνολο δεδομένων. Έτσι, τα μοντέλα μας εκτίθενται σε εσφαλμένες μεταφράσεις και στα δύο στάδια της προετοιμασίας και του συντονισμού των εργασιών, ενισχύοντας αποτελεσματικά την ικανότητα γενικοποίησης τους. Τα υποβαλλόμενα μοντέλα επιτυγχάνουν σημαντική βελτίωση σε σχέση με τις γραμμές βάσης για την εργασία 1 (άμεση αξιολόγηση σε επίπεδο φράσεων, μόνο ΕΝ-DE) και την εργασία 3 (βαθμολογία σε επίπεδο εγγράφου).', 'hu': 'Ez a tanulmány bemutatja a Papago csapat által a WMT 2020 minőségbecslési feladatához benyújtott rendszert. A minőségbecslés két kulcsfontosságú stratégiáját javasolja: (1) feladatspecifikus előképzési rendszer és (2) feladatspecifikus adatok bővítése. Az előbbi a képzés előtti tanulási jelek kidolgozására összpontosít, amelyek szorosan kapcsolódnak a downstream feladathoz. Bemutatjuk továbbá az adatbővítési technikákat, amelyek szimulálják a downstream adatkészletben található különböző hibaszinteket. Így PATQUEST modelleink hibás fordításoknak vannak kitéve a feladatspecifikus előkészítés és finomhangolás mindkét szakaszában, hatékonyan javítva általánosítási képességüket. A benyújtott modellek jelentős javulást érnek el az 1. feladat (mondatszintű közvetlen értékelés; csak EN-DE) és a 3. feladat (dokumentumszintű pontszám) alapjaihoz képest.', 'it': "Questo articolo descrive il sistema presentato dal team Papago per il compito di stima della qualità al WMT 2020. Propone due strategie chiave per la stima della qualità: (1) schema di pre-formazione specifico per attività e (2) aumento dei dati specifico per attività. Il primo si concentra sulla creazione di segnali di apprendimento per il pre-training strettamente correlati al compito a valle. Presentiamo anche tecniche di aumento dei dati che simulano i vari livelli di errori che il set di dati a valle può contenere. Pertanto, i nostri modelli PATQUEST sono esposti a traduzioni errate in entrambe le fasi di pretraining e finetuning specifici per attività, migliorando efficacemente la loro capacità di generalizzazione. I nostri modelli presentati ottengono un miglioramento significativo rispetto alle linee di base per l'attività 1 (valutazione diretta a livello di frase; solo EN-DE) e l'attività 3 (punteggio a livello di documento).", 'lt': 'Šiame dokumente apibūdinama Papago grupės pateikta sistema, skirta kokybės vertinimo užduotims įgyvendinti WMT 2020. Jame siūlomos dvi pagrindinės kokybės vertinimo strategijos: 1) konkrečiai užduotims skirta išankstinio mokymo sistema ir 2) konkrečiai užduotims skirtų duomenų didinimas. Pirmajame dokumente daugiausia dėmesio skiriama mokymosi signalų parengimui, kurie yra glaudžiai susiję su tolesne užduotimi. Taip pat pristatome duomenų didinimo metodus, kurie imituoja įvairius klaidų lygius, kuriuos gali turėti tolesnis duomenų rinkinys. Taigi mūsų PATQUEST modeliams taikomi klaidingi vertimai abiejuose konkrečiai užduotims skirto išankstinio mokymo ir tobulinimo etapuose, veiksmingai didinant jų generalizacijos gebėjimus. Mūsų pateiktuose modeliuose gerokai pagerėjo 1 užduoties (tiesioginio bausmės lygio vertinimo, tik EN-DE) ir 3 užduoties (dokumentų lygio vertinimo) bazės.', 'mk': 'Овој документ го опишува системот поднесен од тимот Папаго за задачата за проценка на квалитетот на ВМТ 2020. It proposes two key strategies for quality estimation: (1) task-specific pretraining scheme, and (2) task-specific data augmentation.  The former focuses on devising learning signals for pretraining that are closely related to the downstream task.  Ние, исто така, претставуваме техники за зголемување на податоците кои ги симулираат различните нивоа на грешки што може да ги содржи низ текот на податоците. Така, нашите PATQUEST модели се изложени на грешни преводи во двете фази на претренирање и финетизирање специфични задачи, ефикасно зголемувајќи ги нивните генерализациски способности. Нашите поднесени модели постигнуваат значително подобрување во однос на основните линии за задачата 1 (директна оценка на нивото на судбина; само EN-DE) и задачата 3 (оценка на нивото на документ).', 'kk': 'Бұл қағаз Папаго тобы WMT 2020 жылы сапатты бағалау тапсырмасының жүйесін таңдайды. Ол сапатты бағалау үшін екі негізгі стратегияларды ұсынады: (1) тапсырманың ерекшелігі жасау сұлбасы, және (2) тапсырманың ерекшелігі деген деректерді жасау. Бірінші тапсырманың жақын жағынан қатынау үшін оқыту сигналдарын құру үшін көңіл береді. Сонымен қатар, бағытталған деректер жинағындағы қателердің түрлі деңгейін симулирайтын деректерді көптеу техникаларын көрсетедік. Біздің PATQUEST үлгілеріміз тапсырмалардың екі қате аудармаларына қате аударылады. Олардың жалпы түрлендіру мүмкіндігін өзгерту үшін. Біздің келтірілген үлгілеріміз 1- тапсырма негізгі жолдарында (сөз- деңгейінің дұрыс оценкасы; тек EN- DE) және 3- тапсырма (Құжат- деңгейінің нөмірі).', 'ms': 'Kertas ini menggambarkan sistem yang dihantar oleh pasukan Papago untuk tugas penghargaan kualiti di WMT 2020. Ia mencadangkan dua strategi kunci untuk penilaian kualiti: (1) skema latihan awal khusus tugas, dan (2) peningkatan data khusus tugas. Pertama fokus pada merancang isyarat belajar untuk pretraining yang berkaitan dengan tugas turun. Kami juga memperkenalkan teknik peningkatan data yang simulasikan tahap-tahap yang berbeza ralat yang seting data turun mungkin mengandungi. Oleh itu, model PATQUEST kami terkena terjemahan yang salah dalam kedua-dua tahap latihan dan penyelesaian khusus tugas, meningkatkan kemampuan umum mereka. Model yang dihantar kami mencapai peningkatan yang signifikan atas garis dasar untuk Tugas 1 (Pengesahan Aras-Perkataan Langsung; EN-DE sahaja), dan Tugas 3 (Skor Aras-Dokumen).', 'ml': 'ഈ പേപ്പറിന്റെ വിശദീകരിക്കുന്നു പാപ്പാഗോ ടീമില്\u200d നിന്ന് നല്\u200dകിയ സിസ്റ്റം വിവരിച്ചത് WMT 2020-ലെ ഗുണ ഗുണപൂര്\u200dണ്ണത്തിനുള്ള രണ്ടു താക്കോല്\u200d പ്രായോഗിക്കുന്നു: (1) ജോലി- പ്രത്യേക പ്രത്യേകിച്ച് മഴപ്പദ്ധതിയും, ജോലി- പ് The former focuses on devising learning signals for pretraining that are closely related to the downstream task.  ഞങ്ങള്\u200d ഡേറ്റാ കൂട്ടിക്കൊണ്ടിരിക്കുന്ന സാങ്കേതികവിദ്യയുടെ വ്യത്യസ്തമായ തെറ്റുകളുടെ നിലങ്ങള്\u200d പോലെയാക്ക അതുകൊണ്ട്, നമ്മുടെ പാട്ക്യൂസ്റ്റ് മോഡലുകള്\u200d തെറ്റായ പരിഭാഷകങ്ങള്\u200dക്ക് വെളിപ്പെടുത്തിയിരിക്കുന്നു. ജോലിയുടെ പ്രത്യേക പ്രത് ഞങ്ങളുടെ സമ്മതിച്ച മോഡലുകള്\u200d ടാസ്ക് 1- ന്റെ അടിസ്ഥാനത്തില്\u200d വലിയ മെച്ചപ്പെടുത്തുന്നതാണ് (ശിക്ഷ- നിലവില നേരിട്ട വിശ്വാസം; EN-DE മാത്രം', 'mt': 'Dan id-dokument jiddeskrivi s-sistema ppreżentata mit-tim Papago għall-kompitu tal-istima tal-kwalità fid-WMT 2020. Hija tipproponi żewġ strateġiji ewlenin għall-istima tal-kwalità: (1) skema ta’ taħriġ minn qabel speċifika għall-kompiti, u (2) żieda fid-dejta speċifika għall-kompiti. L-ewwel tiffoka fuq it-tfassil ta’ sinjali ta’ tagħlim għat-taħriġ minn qabel li huma relatati mill-qrib mal-kompitu downstream. Aħna nippreżentaw ukoll tekniki ta’ żieda tad-dejta li jissimulaw il-livelli varji ta’ żbalji li jista’ jkun fihom is-sett ta’ dejta downstream. Għalhekk, il-mudelli PATQUEST tagħna huma esposti għal traduzzjonijiet żbaljati fiż-żewġ stadji ta’ taħriġ minn qabel u rfinar speċifiku għall-kompiti, u b’mod effettiv itejbu l-kapaċità ta’ ġeneralizzazzjoni tagħhom. Il-mudelli sottomessi tagħna jiksbu titjib sinifikanti fuq il-linji bażi għall-Kompitu 1 (Valutazzjoni Diretta tal-Livell tas-Sentenza; EN-DE biss), u l-Kompitu 3 (Punteġġ tal-Livell tad-Dokument).', 'ro': 'Această lucrare descrie sistemul prezentat de echipa Papago pentru sarcina de estimare a calității la WMT 2020. Acesta propune două strategii cheie pentru estimarea calității: (1) schema de pregătire specifică sarcinilor și (2) augmentarea datelor specifice sarcinilor. Primul se concentrează pe elaborarea semnalelor de învățare pentru pregătire care sunt strâns legate de sarcina din aval. De asemenea, prezentăm tehnici de augmentare a datelor care simulează diferitele niveluri de erori pe care setul de date din aval le poate conține. Astfel, modelele noastre PATQUEST sunt expuse traducerilor eronate în ambele etape ale pregătirii și finajării specifice sarcinilor, sporind eficient capacitatea lor de generalizare. Modelele noastre prezentate obțin îmbunătățiri semnificative față de liniile de referință pentru Sarcina 1 (Evaluare directă la nivel de sentință; numai EN-DE) și Sarcina 3 (Scor la nivel de document).', 'no': 'Denne papiret beskriver systemet som Papago-gruppa sender for kvalitetestimeringsoppgåva på WMT 2020. Det foreslår to nøkkelstrategiar for kvalitetestisering: (1) oppgåvespesifisert område og (2) oppgåvespesifisert data-økning. Den tidlegare fokuserer på å laga læringssignaler for å trekke som er nærare relatert til nedstrekkoppgåva. Vi presenterer også dataaugmentasjonsteknologikar som simulerer dei ulike feilnivåa som nedstrømmedatasettet kan innehalda. Dette er våre PATQUEST-modeller eksponert til feil oversettelsar i begge stader av oppgåvespesifiserte område og finetuning, og effektivt forbetrar sine generelliseringskapasitet. Våre tildelte modeller gjer signifikante forbedring over baselinjene for oppgåve 1 (rett vurdering av teikn-nivå; bare EN-DE) og oppgåve 3 (dokumentnivåpunkt).', 'pl': 'Niniejszy artykuł opisuje system zgłoszony przez zespół Papago do zadania oceny jakości WMT 2020. Proponuje dwie kluczowe strategie oceny jakości: (1) schemat wstępnego szkolenia specyficznego dla zadania oraz (2) powiększania danych specyficznych dla zadania. Pierwszy koncentruje się na opracowywaniu sygnałów uczenia się do treningu wstępnego, które są ściśle związane z dalszym zadaniem. Przedstawiamy również techniki powiększania danych, które symulują różne poziomy błędów, które mogą zawierać kolejny zestaw danych. W ten sposób nasze modele PATQUEST są narażone na błędne tłumaczenia w obu etapach szkolenia wstępnego i precyzyjnego, skutecznie zwiększając ich możliwości uogólniania. Nasze przesłane modele osiągają znaczną poprawę w stosunku do linii bazowych dla zadania 1 (bezpośrednia ocena na poziomie zdań; tylko EN-DE) i zadania 3 (wynik na poziomie dokumentu).', 'mn': 'Энэ цаас нь Папаго багийнхан WMT 2020 оны сайн талаар дүгнэх ажлын системийг тайлбарладаг. Энэ нь чанарын тооцоололтын хоёр түлхүүр стратегийг санал болгож байна: (1) ажлын тооцоололтой тооцоололтын төлөвлөгөө, мөн (2) ажлын тооцоололтой өгөгдлийн нэмэлт. Өмнөх нь суралцах сигналуудын төлөвлөгөөнд анхаарлаа төвлөрүүлдэг. Мөн бид өгөгдлийн нэмэлт техникуудыг дамжуулж өгөгдлийн сангийн багтаах өөр өөр хэмжээсүүдийг шинэчлэх боломжтой. Тиймээс бидний PATQUEST загварууд ажлын хоёр дахь даалгавар дээр алдаа орчуулагддаг. Тэдний ерөнхийлөгч чадварыг нэмэгдүүлдэг. Бидний загвар өгсөн загвар нь 1-р ажлын суурь шугам дээр маш чухал сайжруулалт гаргадаг.', 'sr': 'Ovaj papir opisuje sistem koji je Papagonski tim predao za zadatak za procjenu kvalitete na WMT 2020. On predlaže dve ključne strategije za procjenu kvalitete: (1) shema predstavljanja određenih zadataka i (2) povećanje podataka određenih zadataka. Bivši se fokusiraju na stvaranje znakova učenja za pretkivanje koje su blisko povezane sa zadatkom koji se nalazi. Takođe predstavljamo tehnike povećanja podataka koje simuliraju različite nivoe grešaka koje mogu sadržati niz podataka. Dakle, naši PATQUEST modeli su izloženi pogrešnim prevodima u oba faza predavanja i finetuniranja posebnih zadataka, učinkovito povećavajući njihovu generalizaciju. Naši podnošeni modeli postignu značajno poboljšanje na osnovnim linijama za zadatak 1 (direktna procjena na nivou kazne; samo EN-DE) i zadatak 3 (rezultat nivoa dokumenta).', 'so': 'Kanu wuxuu ku qoraa nidaamka kooxda Papago ee loo soo dhiibay shaqada qiimeynta qiimeynta ee WMT 2020. Waxay soo jeedaa laba qalabka muhiimka ah oo qiimeynta qiimeynta qiimeynta qiimeynta: (1) qorshaha shaqada oo gaar ah oo ku qoran qorshaha hore-roobinta, iyo (2) kordhidda macluumaad gaar ah oo shaqo. Qorigii hore wuxuu ku kalsoonaadaa in uu qorsheyo sawirada barashada iyo in uu iska daahiriyo kuwa ku dhow la xiriira shaqada hoose. Sidoo kale waxaynu soo bandhignaa qalabka kordhinta macluumaadka oo u eg heerarka khaladda oo kala duduwan, kaas oo ku qoran karta macluumaadka hoose. Sidaa darteed modelalkayaga PATQUEST waxaa loo muujiyaa turjumyo qalad ah labada fasalka shaqaalaha oo gaar ah oo ku qoran tababarka iyo daboolidda, si faa’iido leh ayaa u kordhiya awoodkooda dhalashada. Tusaaladayada la soo dhiibay waxay gaadhaa hagaag aad u weyn oo ka kordhiya aasaaska shaqada 1 (Heeganka-Level Direct Assessment; EN-DE oo kaliya) iyo shaqo 3 (Shahaadada-Level).', 'sv': 'Denna uppsats beskriver det system som Papago-teamet l채mnat in f철r kvalitetsbed철mningsuppgiften vid WMT 2020. I f철rslaget f철resl책s tv책 nyckelstrategier f철r kvalitetsuppskattning: 1) uppgiftsspecifik f철rhandsutbildning och 2) uppgiftsspecifik data철kning. Den f철rra fokuserar p책 att utforma inl채rningssignaler f철r pre-training som 채r n채ra relaterade till nedstr철msuppgiften. Vi presenterar ocks책 dataf철rst채rkningstekniker som simulerar de olika niv책erna av fel som nedstr철msdata kan inneh책lla. S책ledes uts채tts v책ra PATQUEST-modeller f철r felaktiga 철vers채ttningar i b책da stadierna av uppgiftsspecifik f철rberedelse och finjustering, vilket effektivt f철rb채ttrar deras generaliseringsf철rm책ga. V책ra inl채mnade modeller uppn책r betydande f철rb채ttringar j채mf철rt med baslinjerna f철r Uppgift 1 (Direktbed철mning p책 meningsniv책; endast EN-DE) och Uppgift 3 (Dokument-Level Score).', 'si': 'මේ පැත්තේ පාපාගෝ කණ්ඩායමේ පද්ධතිය විස්තර කරනවා WMT 2020දී ක්\u200dරියාත්මක විශේෂ විශ්වාස කරන වැඩ ඒක ප්\u200dරශ්ණතාව අනුමාණය සඳහා යතුරු ප්\u200dරශ්ණතාවක් දෙකක් ප්\u200dරශ්ණතා කරනවා: (1) වැඩක් විශේෂ ප්\u200dරශ්ණත ප්\u200dරශ් මුලින් ප්\u200dරධාන සංඥාවක් හොයාගන්න පුළුවන් සංඥාවක් හොයාගන්න පුළුවන් විදිහට අවධානය කර අපි දත්ත විශාලනය ප්\u200dරවේශනය කරනවා ඒ වගේම දත්ත විශාලනය කරන්න පුළුවන් වෙනස් ස්ථානයක් ප්\u200dරවේශනය කරනව ඉතින්, අපේ PATQUEST මෝඩේල් වැරදි භාවිතාවට ප්\u200dරතික්\u200dරියා කරලා තියෙන්නේ වැරදි භාවිතාවක් දෙන්නම් ප්\u200dරතික්\u200dරියාත්මක සහ ප්\u200dරත අපේ පිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළ', 'ta': 'This paper describes the system submitted by Papago team for the quality estimation task of WMT 2020. இது தரம் மதிப்பிற்கான இரண்டு விசை துறைமுறைகளை பரிந்துரைக்கிறது: (1) செயல்- குறிப்பிட்ட முன்னெழுத்து முறைமையை மற்றும் ( முந்தைய குறியீடுகளை கற்றுக்கொள்வதற்கான முன்னாள் கவனம் செலுத்துகிறது கீழே நீர் பணியுடன் அருகில் உள்ளது. நாம் தரவு கூட்டுதல் தொழில்நுட்பத்தை கொண்டிருக்கிறோம். அது மாறுபட்ட நிலைகளை ஒப்பிடுகிறது. கீழ்தள்ளும் தகவல் அமை எனவே, எங்கள் PATQUEST மாதிரிகள் தவறான மொழிபெயர்ப்புகளுக்கு தெரியும் பணியின் குறிப்பிட்ட மாதிரிகளிலும் குறிப்பிட்ட மாதிரியிலும்  எங்கள் வழங்கப்பட்ட மாதிரிகள் பணியின் அடிப்படைகளில் முக்கியமான முன்னேற்றத்தை பெறுகிறது (வாக்கியம்- நேரடி மதிப்பு; EN- DE மட்டும்) மற்றும் பணி 3', 'ur': 'اس کاغذ نے پاپاپاگو ٹیم کے ذریعے WMT 2020 میں کیلوٹی ارزش کا کام کے لئے سٹم کی توصیف کرتی ہے. اس نے کیفیت کی ارزیابی کے لئے دو کلید استراتژی پیشنهاد کرتا ہے: (1) task-specific pretraining scheme, اور (2) task-specific data augmentation. اس سے پہلے لوگوں نے سیگنالوں کی تدبیر کی ہے جو نیچے نرم کام کے ساتھ نزدیک مرتبہ ہیں۔ ہم نے بھی ڈیٹا افزایش ٹیکنیک پیش کیے ہیں جن کی مختلف خطاؤں کی سطح سیمولیٹ کرتی ہیں جن کے اندر ڈیٹ سٹ میں شامل ہو سکتی ہے. اسی طرح ہمارے PATQUEST موڈلیوں کو غلط ترجمہ پر ظاہر کر دیا گیا ہے اور ان کی عمومی ترجمہ قابلیت کو اثبات سے زیادہ زیادہ کر رہا ہے۔ ہمارے فرستادہ موڈلے ٹاکس ۱ کے بنسس لینوں پر بہترین سوداگری حاصل کر رہے ہیں (سنت-سطح مستقیم آزمائش، صرف EN-DE) اور ٹاکس ۳ (سنت-سطح Score).', 'uz': "This paper describes the system submitted by Papago team for the quality estimation task at WMT 2020.  Bu qiymatni qiymatlash uchun ikkita tugma strategiya rivojlanadi: (1) vazifa- specific prerain qolipini va (2) vazifa- xossa maʼlumotni qoʻshish. Oldingi odamlar o'rganish imkoniyatlarini o'rganish uchun eng muhimi o'zgarishga qaramadi. Biz esa quyidagi maʼlumot qoʻshish teknologizni hozir qilamiz. Ushbu soʻzning quyidagi maʼlumotlar maʼlumotlar tarkibini o'xshash mumkin. Shunday qilib, bizning PATQUEST modellarimiz vazifa haqida noto'g'ri tarjimalarni ko'rsatadi. Bunday holatda o'zgarishni qo'shishga ishlatadi. Joʻnatilgan modellarimiz Vazifaning 1 (Sentence- darajasi direktoriya Assessment; EN-DE) va Vazifa 3 (hujjat darajasi qiymati) bajaradi.", 'vi': 'Tờ giấy này mô tả hệ thống gởi bởi đội Papago để làm nhiệm vụ đánh giá chất lượng ở WRT 2020. Nó đề xuất hai chiến lược quan trọng để đánh giá chất lượng: Đầu tiên tập trung vào việc phát hiện ra các tín hiệu học trước khi mưa rơi có liên quan đến nhiệm vụ xuôi dòng. Chúng tôi cũng đưa ra các kỹ thuật gia tăng dữ liệu mô phỏng các độ sai lệch khác nhau mà bộ dữ liệu xuôi dòng có thể chứa. Do đó, các mô hình PATCâu của chúng tôi bị phơi nhiễm những bản dịch sai ở cả hai giai đoạn trước và độ chín của nhiệm vụ, tăng hiệu quả khả năng khai thác. Những mẫu được gửi đi đạt được tiến bộ đáng kể hơn các đường cơ bản cho công việc 1 (Chỉ đánh giá trực tiếp đường câu, chỉ yêu thích một người Do Thái) và Task 3 (Score cấp tài liệu).', 'bg': 'Настоящата статия описва системата, внесена от екипа на Папаго за задачата за оценка на качеството на ОМТ 2020. В него се предлагат две ключови стратегии за оценка на качеството: (1) специфична за задачата схема за предварително обучение и (2) увеличение на специфичните за задачата данни. Първият се фокусира върху разработването на учебни сигнали за предобучение, които са тясно свързани със задачата надолу по веригата. Представяме и техники за увеличаване на данните, които симулират различните нива на грешки, които наборът от данни надолу по веригата може да съдържа. По този начин нашите модели са изложени на грешни преводи и в двата етапа на специфичното за задачата предварително обучение и фино настройване, ефективно подобрявайки тяхната способност за обобщаване. Нашите представени модели постигат значително подобрение спрямо базовите линии за задача 1 (директна оценка на ниво изречение; само EN-DE) и задача 3 (оценка на ниво документ).', 'da': 'Denne artikel beskriver det system, som Papago-teamet har indsendt til kvalitetsestimeringsopgaven på WMT 2020. Den foreslår to nøglestrategier for kvalitetsestimering: (1) opgavespecifik forududdannelsesordning og (2) opgavespecifik dataforøgelse. Førstnævnte fokuserer på at udvikle læringssignaler til foruddannelse, der er tæt relateret til downstream-opgaven. Vi præsenterer også datateknikker, der simulerer de forskellige niveauer af fejl, som downstream datasættet kan indeholde. Således udsættes vores PATQUEST modeller for fejlagtige oversættelser i begge faser af opgavespecifikke forudtræning og finjustering, hvilket effektivt forbedrer deres generaliseringsevne. Vores indsendte modeller opnår en betydelig forbedring i forhold til basislinjerne for opgave 1 (direkte vurdering på sætningsniveau; kun EN-DE) og opgave 3 (dokumentniveau score).', 'nl': 'Deze paper beschrijft het systeem dat door het Papago team is ingediend voor de kwaliteitsschattingstak bij WMT 2020. Het stelt twee belangrijke strategieën voor kwaliteitsschatting voor: (1) taakspecifiek pretraining schema en (2) taakspecifieke data augmentatie. De eerste richt zich op het ontwikkelen van leersignalen voor pretraining die nauw gerelateerd zijn aan de downstream taak. We presenteren ook data augmentation technieken die de verschillende niveaus van fouten simuleren die de downstream dataset kan bevatten. Zo worden onze PATQUEST-modellen blootgesteld aan foutieve vertalingen in beide fasen van taakspecifieke pretraining en finetuning, waardoor hun generalisatievermogen effectief wordt verbeterd. Onze ingediende modellen bereiken significante verbeteringen ten opzichte van de basislijnen voor Taak 1 (Direct Assessment op zinsniveau; alleen EN-DE) en Taak 3 (Document Level Score).', 'hr': 'Ovaj papir opisuje sustav koji je Papagonski tim predao za zadatak za procjenu kvalitete na WMT 2020. On predlaže dvije ključne strategije za procjenu kvalitete: (1) sustav predstavljanja određenih zadataka i (2) povećanje podataka određenih zadataka. Bivši se fokusiraju na izradu učenjskih signala za pretkivanje koje su blisko povezane s zadatkom u donjem nivou. Također predstavljamo tehnike povećanja podataka koje simuliraju različite razine grešaka koje mogu sadržati niz podataka. Dakle, naši PATQUEST modeli su izloženi pogrešnim prevodima u obje faze određenog zadatka pretvaranja i finetuniranja, učinkovito poboljšavajući njihovu sposobnost generalizacije. Naši podignuti modeli postignu značajno poboljšanje na osnovnim linijama za zadatak 1 (direktna procjena na razini kazne; samo EN-DE) i zadatak 3 (rezultat na razini dokumenta).', 'de': 'Diese Arbeit beschreibt das System, das Papago-Team fﾃｼr die Qualitﾃ､tsschﾃ､tzungsaufgabe bei WMT 2020 eingereicht hat. Es werden zwei Schlﾃｼsselstrategien fﾃｼr die Qualitﾃ､tsschﾃ､tzung vorgeschlagen: (1) aufgabenspezifisches Vorbereitungsschema und (2) aufgabenspezifische Datenerweiterung. Ersteres konzentriert sich auf die Entwicklung von Lernsignalen fﾃｼr das Vortraining, die eng mit der nachgelagerten Aufgabe zusammenhﾃ､ngen. Darﾃｼber hinaus stellen wir Techniken zur Datenauswertung vor, die die unterschiedlichen Fehlerstufen simulieren, die der nachgeschaltete Datensatz enthalten kann. So sind unsere PATQUEST-Modelle in beiden Phasen des aufgabenspezifischen Vortrainings und der Feinabstimmung fehlerhaften ﾃ彙ersetzungen ausgesetzt, wodurch ihre Generalisierungsfﾃ､higkeit effektiv verbessert wird. Unsere eingereichten Modelle erzielen deutliche Verbesserungen gegenﾃｼber den Basislinien fﾃｼr Task 1 (Satzence-Level Direct Assessment; nur EN-DE) und Task 3 (Document-Level Score).', 'id': 'This paper describes the system submitted by Papago team for the quality estimation task at WMT 2020.  It proposes two key strategies for quality estimation: (1) task-specific pretraining scheme, and (2) task-specific data augmentation.  Sebelumnya fokus pada merancang sinyal belajar untuk pretraining yang dekat berhubungan dengan tugas turun. Kami juga mempersembahkan teknik peningkatan data yang simulasi tingkat-tingkat yang berbeda dari kesalahan yang dataset turun mungkin mengandung. Jadi, model PATQUEST kami terkena terjemahan yang salah dalam kedua tahap dari perkelahian dan penelitian khusus tugas, dengan efektif meningkatkan kemampuan generalisasi mereka. Model yang kami kirimkan mencapai peningkatan yang signifikan atas garis dasar untuk Tugas 1 (Penghargaan langsung Tingkat Sentensi; EN-DE saja), dan Tugas 3 (Skor Tingkat Dokumen).', 'fa': 'این کاغذ سیستم را توسط تیم پاپاگو برای کار ارزیابی کیفیت در WMT 2020 توصیف می\u200cکند. این دو استراتژی کلیدی برای ارزیابی کیفیت پیشنهاد می\u200cکند: (۱) برنامه\u200cی پیشنهاد مخصوص کار، و (۲) افزایش داده\u200cهای خاص کار. پیشینیان روی ساختن سیگنال یادگیری برای تغییر کردن که نزدیک به کار پایین ارتباط دارند تمرکز می\u200cکند. ما همچنین تکنیک افزایش داده ها را نشان می دهیم که سطح مختلف اشتباهی را شبیه سازی می کنند که مجموعه داده های پایین\u200cترین شاید شامل باشد. بنابراین، مدلهای PATQUEST ما در هر دو مرحله\u200cای از تغییرات اشتباهی و تغییرات و تغییرات مخصوص کار، به طور تاثیر افزایش توانایی عمومی\u200cشان هستند. مدل\u200cهای فرستاده شده\u200cمان بر خطوط\u200cهای بنیادی برای تابع ۱ (ارزیابی مستقیم مرحله\u200cی جمله\u200cی عبارت، تنها EN-DE) و تابع ۳ (امتیاز سطح سند\u200cها).', 'ko': '본고는 파파고팀이 WMT 2020의 품질 평가 임무를 제출하는 시스템을 묘사한다.이것은 두 가지 관건적인 품질 평가 전략을 제시했다. (1) 임무가 특정한 예비 훈련 방안, (2) 임무가 특정한 데이터 확충이다.전자는 하류 임무와 밀접한 관계를 가진 훈련 전 학습 신호를 설계하는 데 중심을 두었다.아날로그 하위 데이터 집합에 포함될 수 있는 서로 다른 오류 단계의 데이터 강화 기술도 소개했다.따라서 우리의 PATQUEST 모델은 특정 임무의 예비 훈련과 미세 조정 두 단계에서 잘못된 번역이 발생하여 그들의 범위화 능력을 효과적으로 강화할 수 있다.우리가 제출한 모델은 임무 1(문장급 직접 평가, EN-DE만)과 임무 3(문서급 점수)의 기선보다 현저히 개선되었다.', 'sw': 'Gazeti hili linaelezea mfumo uliotolewa na timu ya Papago kwa ajili ya kazi ya uchimbaji wa kiwango cha estimation katika WMT 2020. Inapendekeza mikakati miwili muhimu kwa ajili ya kutathmini kiwango cha ubora: (1) mpango maalum wa matumizi ya mvua, na (2) kuongeza taarifa maalum za kazi. Wazazi wa zamani wanajikita kwenye mipango ya kupanga ishara za kujifunza kwa kutengeneza mvua inayohusiana na kazi hiyo ya chini ya mto. Pia tunaweka mbinu za kuongeza taarifa zinazofananisha kiwango tofauti cha makosa ambacho taarifa za mito inaweza kuwepo. Thus, our PATQUEST models are exposed to erroneous translations in both stages of task-specific pretraining and finetuning, effectively enhancing their generalization capability.  Miradi yetu iliyotolewa inafanikiwa kuboreshwa kwa kiwango kikubwa zaidi ya msingi wa kazi 1 (Tafiti la moja kwa moja la Heshima; EN-DE pekee), na kazi 3 (Tuzo ya Sheria-Level).', 'af': 'Hierdie papier beskryf die stelsel wat deur Papago-span ingestuur is vir die kwaliteit-estimatiese taak op WMT 2020. Dit voorstel twee sleutel strategies vir kwaliteit-estimatie: (1) taak-spesifieke pretraining skema, en (2) taak-spesifieke data-augmentasie. Die vorige fokus op die uitwerking van leersignaals vir voorskryfing wat naby verwante is met die onderstreem taak. Ons stel ook data augmentasie tekens wat die verskillende vlakke van foute simuleer wat die onderstreem datastel kan bevat. So is ons PATQUEST-modelles uitgespreek tot verkeerde vertalings in beide stadige van taak-spesifieke pretraining en finetuning, effektief hulle generalisering-kapasiteit verbeter. Ons ingestuurde modele bereik betaling verbetering oor die basisline vir taak 1 (Sagte-Vlak Direkte Assensie; Ene-DE slegs), en Opdrag 3 (Dokument-Vlak telling).', 'sq': 'Ky dokument përshkruan sistemin e paraqitur nga ekipi i Papagos për detyrën e vlerësimit të cilësisë në WMT 2020. Ajo propozon dy strategji kyçe për vlerësimin e cilësisë: (1) skemë paratrajnimi specifike për detyrat dhe (2) rritje e të dhënave specifike për detyrat. E para përqëndrohet në hartimin e sinjaleve të mësimit për parastërvitjen që janë të lidhura ngushtë me detyrën poshtë. Ne prezantojmë gjithashtu teknika të rritjes së të dhënave që simulojnë nivelet e ndryshme të gabimeve që mund të përmbajnë grupi i të dhënave poshtë. Kështu, modelet tona PATQUEST janë ekspozuar për përkthime të gabuara në të dy fazat e parastërvitjes dhe përmirësimit specifik të detyrave, duke përmirësuar efektivisht aftësinë e tyre të gjeneralizimit. Modelet tona të paraqitura arrijnë përmirësim të rëndësishëm mbi linjat bazë për detyrën 1 (vlerësim i drejtpërdrejtë të nivelit të dënimit; vetëm EN-DE) dhe detyrën 3 (pikëpamje e nivelit të dokumentit).', 'tr': 'Bu kagyz Papago toparynyň WMT 2020-nji ýyldaky hökmünde gönderilen sistemini tassyýar. Häzirki kwalitet taýýarlanmasy üçin iki açyk strateji teklip edýär: (1) täblisaň häzirki pretraining taslaýyşy, we (2) täblisaň häzirki maglumat gaýdalanmasyny. Öňki görnüş işine ýakyn ýakyn şekilde öwrenme signallaryny taýýarlamak üçin üns berýär. Biz hem daşaryk maglumat düzümleriniň görkezilişi ýalňyşyň düzümlerini görkezip biljek maglumatlar üçin maglumatlary ýetişdirýäris. Şonuň üçin, biziň PATKIST nusgalarymyz hem işiň häsiýetli taýýarlarynda ýalňyş terjimelere gollaşdyrylýar, olaryň jenerallyk ukyplaryny täsirleşdirýär. Bizim gönderilen nusgalarymyz 1-nji Görev üçin esasy düzümlerniň üstünde önemli gelişmegi başarýar (sözlem-derejesi dogry düzümlenme; diňe EN-DE), we 3-nji Görev (Sened-derejesi Derjesi Derjesi).', 'am': 'ይህ ገጽ የባቡክ ቡድን በWMT 2020 የጥሩ ጉዳይ የደረሰባውን ድምፅ ይናገራል፡፡ የሥርዓት-ምርጫዎች ለጥቅምት ሁለት የቁልፎች ስርዓት ያስጀምርበታል:(1) ስራ-specific ዝርዝር እና (2) ስራ-specific ዳታ ማጨመር ያሳርፋል፡፡ የቀድሞው የውሃ ቀዳሚ ስራ ጋር ለመማር ሲክሎችን በመዘርጋት ላይ ትኩረት ነው፡፡ የውኃው ዳታ ማሰናከል የሚችለውን የስሕተት ደረጃዎችን በሚመስል እናስቀርባለን፡፡ Thus, our PATQUEST models are exposed to erroneous translations in both stages of task-specific pretraining and finetuning, effectively enhancing their generalization capability.  ወደ ስራ 1 (የሥርዓት-ደረጃ ቀጥተኛ ጉዳይ; EN-DE ብቻ) እና ስራ 3 (ሰነድ-ደረጃን ነጥብ) መሠረት አግኝቷል፡፡', 'hy': 'This paper describes the system submitted by Papago team for the quality estimation task at WMT 2020.  Այն առաջարկում է որակի գնահատման երկու կարևոր ռազմավարություն: (1) խնդիրների հատուկ նախադասական ծրագիր և (2) խնդիրների հատուկ տվյալների աճ: Առաջինը կենտրոնանում է ուսուցման ազդանշանների ստեղծման վրա, որոնք խիստ կապված են հետագա խնդրի հետ: Մենք նաև ներկայացնում ենք տվյալների աճի մեթոդներ, որոնք նմանեցնում են սխալների տարբեր մակարդակները, որոնք կարող են պարունակել հետագա տվյալների համակարգը: Այսպիսով, մեր "ՊԱՏՔԵՍՏ" մոդելները բացահայտվում են սխալ թարգմանությունների դեպքերում, որոնք վերաբերվում են խնդիրներին հատուկ նախապատրաստման և փոքրացման երկու փուլում, և արդյունավետ բարելավում են իրենց ընդհանուր ընդունակությունները: Մեր ներկայացված մոդելները նշանակալի բարելավում են 1-ի (Առաջին դատողության մակարդակի ուղղակի գնահատման, միայն ԵՆ-ԴԵ) և 3-ի (Թղթերի մակարդակի գնահատման) հիմնական գծերը:', 'az': 'Bu kağıt, WMT 2020-də Papago takımının göndərilmiş sistemini təsbiq edir. O, keyfiyyət təcrübəsi üçün iki açar strateji təklif edir: (1) task-specific pretraining scheme, və (2) task-specific data incrementation. Əvvəlkilər aşağı yüksək iş ilə yaxınlaşdırılmış öyrənmə sinyallərini təyin etməyə odaqlanır. Biz həmçinin daxilində daxilində olan xətaların müxtəlif səviyyələrini simulatəşdirən məlumatları artırmaq tekniklərini də göstəririk. Beləliklə, bizim PATQUEST modellərimiz hər işin müəyyən edilmiş tərzlərində xətasız tercümələrə göstərilmişdir. Onların generalizasyon qabiliyyətini artırar. Bizim göndərilmiş modellərimiz 1. iş üçün əsas sətirlərin üstündə möhkəm uzlaşdırmasını başa çatdırır (Sözü-səviyyə düzgün vuruşması; ancaq EN-DE) və 3. Task (Document-Level Score).', 'bn': 'এই পত্রিকাটি ব্যাখ্যা করেছে পাপাগোর দলের জমা দিয়েছে উইএমটি ২০২০ সালের মান হিসাবের কাজের জন্য। এটি মান হিসেবের জন্য দুটি গুরুত্বপূর্ণ কৌশল প্রস্তাব করে: (1) কাজ-বিশেষ প্রাপ্ত বৃষ্টির পরিকল্পনা এবং (2) কাজ-নির্দিষ্ The former focuses on devising learning signals for pretraining that are closely related to the downstream task.  এছাড়াও আমরা তথ্য যোগাযোগ প্রযুক্তি উপস্থাপন করি যা বিভিন্ন ভুল পর্যায়ের সমতুল্য করে যে তথ্য নিচের তথ্যের ডাটাসেট তাই, আমাদের প্যাটকুয়েস্ট মডেল তাদের জেনারেলেশনের ক্ষমতা বৃদ্ধি করার ক্ষমতা বৃদ্ধি করার জন্য ভুল অনুবাদের প্রকাশ করা হয়েছে। আমাদের উপস্থিত মডেল টাস্ক ১ এর বেসারে গুরুত্বপূর্ণ উন্নতি পেয়েছে (শাস্তি-স্তর সরাসরি মিস্টেম; এনডি-ডি) এবং কাজ ৩ (ডকুমেন্ট- স্তরের স্ক', 'cs': 'Tento článek popisuje systém předložený týmem Papago pro úlohu odhadu kvality na WMT 2020. Navrhuje dvě klíčové strategie pro odhad kvality: (1) schéma předškolení specifického pro úkoly a (2) rozšíření dat specifických pro úkoly. První se zaměřuje na navrhování vzdělávacích signálů pro předškolení, které úzce souvisejí s následným úkolem. Představujeme také techniky rozšíření dat, které simulují různé úrovně chyb, které následná datová sada může obsahovat. Proto jsou naše modely PATQUEST vystaveny chybným překladům v obou fázích předškolení a jemného ladění specifických úkolů, což efektivně zvyšuje jejich zobecnění schopnosti. Naše předložené modely dosahují výrazného zlepšení oproti základním liniím pro úkol 1 (přímé hodnocení na úrovni vět; pouze EN-DE) a úkol 3 (skóre na úrovni dokumentů).', 'ca': "Aquest paper descriu el sistema presentat per l'equip Papago per a la tasca d'estimació de qualitat a WMT 2020. Propone dues estratègies clau per estimar la qualitat: (1) esquema de pré-capacitació específic per a les tasques, i (2) augment de dades específices per a les tasques. The former focuses on devising learning signals for pretraining that are closely related to the downstream task.  També presentem tècniques d'augmentació de dades que simulan els diferents nivells d'errors que pot contenir el conjunt de dades avall. Així doncs, els nostres models PATQUEST estan exposats a traduccions errònies en les dues etapes de pré-entrenament i finament específics de les tasques, millorant efectivament la seva capacitat de generalització. Els nostres models presentats aconsegueixen una millora significativa sobre les línies de base de la tasca 1 (Evaluació directa del nivell de sentencia; només EN-DE) i la tasca 3 (Puntuació del nivell de documentació).", 'bs': 'Ovaj papir opisuje sistem koji je Papagonski tim predao za zadatak za procjenu kvalitete na WMT 2020. On predlaže dvije ključne strategije za procjenu kvalitete: (1) shema predstavljanja određenih zadataka i (2) povećanje podataka određenih zadataka. Bivši se fokusiraju na stvaranje znakova učenja za pretkivanje koje su blizu povezane sa zadatkom koji se nalazi. Također predstavljamo tehnike povećanja podataka koje simuliraju različite nivoe grešaka koje mogu sadržati niz podataka. Dakle, naši PATQUEST modeli su izloženi pogrešnim prevodima u oba faza predavanja i finetuniranja posebnih zadataka, učinkovito povećavajući njihovu generalizaciju. Naši podignuti modeli postignu značajno poboljšanje na osnovnim linijama za zadatak 1 (direktna procjena na nivou kazne; samo EN-DE) i zadatak 3 (rezultat nivoa dokumenta).', 'et': 'Käesolevas töös kirjeldatakse Papago meeskonna poolt WMT 2020 kvaliteedi hindamise ülesandeks esitatud süsteemi. Selles pakutakse välja kaks kvaliteedi hindamise peamist strateegiat: 1) ülesandepõhine koolituskeem ja 2) ülesandepõhine andmete suurendamine. Esimene keskendub õppimiseelsete signaalide väljatöötamisele, mis on tihedalt seotud järgmise etapi ülesandega. Samuti tutvustame andmete suurendamise tehnikaid, mis simuleerivad järgmise etapi andmekogumi erinevaid vigu. Seega on meie PATQUEST mudelid ekslikud tõlked mõlemas ülesandespetsiifilise eeltreeningu ja peenhäälestuse etapis, suurendades tõhusalt nende üldistamisvõimet. Meie esitatud mudelid saavutavad märkimisväärset paranemist ülesande 1 (lausetaseme otsene hindamine; ainult EN-DE) ja ülesande 3 (dokumenditaseme skoor) lähtejoonega võrreldes.', 'fi': 'T채ss채 artikkelissa kuvataan Papago-tiimin toimittamaa j채rjestelm채채 WMT 2020:n laadunarviointiteht채v채채n. Siin채 ehdotetaan kahta keskeist채 laadunvarmistusstrategiaa: (1) teht채v채kohtainen esikoulutusj채rjestelm채 ja (2) teht채v채kohtainen datan lis채채minen. Ensimm채isess채 keskityt채채n kehitt채m채채n esikoulutukseen liittyvi채 oppimissignaaleja, jotka liittyv채t l채heisesti loppup채채n teht채v채채n. Esittelemme my철s datan lis채ystekniikoita, jotka simuloivat loppup채채n tietoaineiston mahdollisesti sis채lt채mi채 erilaisia virhetasoja. N채in ollen PATQUEST-mallimme altistuvat virheellisille k채채nn철ksille teht채v채kohtaisen esikoulutuksen ja hienos채채t철n molemmissa vaiheissa, mik채 parantaa tehokkaasti niiden yleistymiskyky채. Toimitetut mallit parantavat merkitt채v채sti teht채v채채n 1 (lausetason suora arviointi; vain EN-DE) ja teht채v채채n 3 (asiakirjatason pisteytys) verrattuna.', 'sk': 'V prispevku je opisan sistem, ki ga je ekipa Papago predložila za nalogo ocenjevanja kakovosti na WMT 2020. Predlaga dve ključni strategiji za ocenjevanje kakovosti: (1) shema predusposabljanja za posamezno nalogo in (2) povečanje podatkov za posamezno nalogo. Prvi se osredotoča na oblikovanje učnih signalov za predusposabljanje, ki so tesno povezani z nadaljnjo nalogo. Predstavljamo tudi tehnike povečanja podatkov, ki simulirajo različne stopnje napak, ki jih lahko vsebuje niz podatkov. Tako so naši modeli PATQUEST izpostavljeni napačnim prevodom v obeh fazah predusposabljanja in natančnega nastavitve, kar učinkovito izboljšuje njihovo sposobnost posploševanja. Naši predloženi modeli dosegajo znatno izboljšanje v primerjavi z osnovnimi vrsticami za nalogo 1 (neposredna ocena na ravni stavka; samo EN-DE) in nalogo 3 (ocena na ravni dokumenta).', 'ha': "Wannan takardan na bayyana na'urar da aka saka shi na tsarin Fargaba na wajen aikin inganci a WMT 2020. Yana ƙayyade kayan biyu masu ƙayyade wa kima wa qiimar nau'i: (1) ƙayyade wa aikin-ƙayyade preraining na ƙayyade, da kuma (2) ƙaramako da data masu ƙayyade wa aikin. Ga ta zaman fokus a kan shirin karatun ayukan da za'a sami da wa'anar da za'a yi wa'anar wa'anar ta zama mafi kusantar da aikin na ƙarami. Tuna ƙunsa da zane-zanen ƙararrawa da ke daidaita zane-zane-zane-zane-zane-zane-zane da za'a ƙunsa da. Kamar haka, misalinmu na PATQUEST za'a sami fassarar masu ɓata a cikin jujjun-muhimman aikin da aka ƙayyade bakwai-mai ƙayyade, kuma ana ƙara awon mai gabatar da su. @ action: button", 'jv': 'Perintah iki rambaran sistem sing paling kelompok Bapak nggawe nggawe gerasane nggawe kalite sing bakal terus \'WT 2020\' (1) task-special Laptop" and "Desktop Awak dhéwé éntuk sistem anyari dadi nggawe akeh perusahaan anyar sampeyan kanggo barang nggawe dataset dibutuhke sakjane Lakok, model PAT-KUERT nambah kang dipoleh akeh operasi kanggo ditambah pancene yen karo hal-hal dadi nggawe gerakan karo nggawe barang nggawe barang nggawe gerakan, iso nglanggar nggawe kapasituran sistem sing apik dhéwé. Awak dhéwé nggawe model sing rumangsa akeh banter nggawe barang nggawe barang nggawe task 1', 'he': 'העיתון הזה מתאר את המערכת שנשלחה על ידי צוות פאפגו למשימת הערכה איכותית ב-WMT 2020. הוא מציע שתי אסטרטגיות מפתחיות לערכת איכות: (1) תכנית שימוש מוקדם ספציפית למשימה, ו (2) גידול נתונים ספציפיים למשימה. הקודם מתמקד בתכנית אותות למידה למחזור אימונים שקשורים מקרוב למשימה התחתונה. אנחנו גם מציגים טכניקות גידול נתונים שמדמיינות את רמות השתנות של טעויות שאפשר להכיל את קבוצת נתונים למטה. כך, דוגמני PATQUEST שלנו חושפים לתרגומות שגויות בשני שלבים של שימוש מוקדם מסויים למשימות ולהתאים, משפר בעובדה את יכולת הגנרליזציה שלהם. הדוגמנים המועברים שלנו משיגים שיפור משמעותי מעל קווי הבסיס למשימה 1 (הערכה ישירה ברמה גזרה; EN-DE בלבד), ומשימה 3 (נקודת רמה מסמכים).', 'bo': 'ཤོག་བྱང་འདིས་རྩོམ་པ་པོའི་ནང་དུ་རྩོམ་པ་གྱི་རྒྱལ་ཁབ་སྤྲོད་ཀྱི་དོན་ལ་མཚམས་སྤྱོད་བཞིན་པ It proposes two key strategies for quality estimation: (1) task-specific pretraining scheme, and (2) task-specific data increase. སྔོན་པ་དེ་དག་གི་འཇུག་ཟམ་དབྱིབས་མཐུན་གྱི་མིང་རྟགས་བཀོད་ནི་བཟོ་བཅོས་བྱེད་མ་ཟད། We also present data augmentation techniques that simulate the various levels of errors that the downstream dataset may contain. དེར་བརྟེན། ང་ཚོའི་PATQUEST མིག་དཔེ་དབྱིབས་ནོར་འཁྲུལ་གྱི་སྐབས་རིགས་གཉིས་ཀྱི་ནང་དུ་འཇུག་སྣོད་གཙང་མེད་པར། དེ་ཚོའི་སྤྱིར་བཏང་ནུས་ཡོད་ཚད་ Our submitted models achieve significant improvement over the baselines for Task 1 (Sentence-Level Direct Assessment; EN-DE only), and Task 3 (Document-Level Score).'}
{'en': 'Two-Phase Cross-Lingual Language Model Fine-Tuning for Machine Translation Quality Estimation', 'ar': 'نموذج لغوي متعدد اللغات ثنائي الطور الضبط الدقيق لتقدير جودة الترجمة الآلية', 'es': 'Ajuste fino del modelo lingüístico multilingüe de dos fases para la estimación de la calidad de la traducción automática', 'pt': 'Ajuste fino do modelo de idioma multilíngue de duas fases para estimativa de qualidade da tradução automática', 'fr': "Réglage fin du modèle linguistique multilingue en deux phases pour l'estimation de la qualité de la traduction automatique", 'ja': '機械翻訳品質推定のための二相クロスリンガルモデル微調整', 'zh': '以机器翻译质评估两段跨语言模样微调', 'hi': 'मशीन अनुवाद गुणवत्ता अनुमान के लिए दो चरण क्रॉस-भाषाई भाषा मॉडल ठीक ट्यूनिंग', 'ru': 'Точная настройка двухфазной кросс-лингвальной языковой модели для оценки качества машинного перевода', 'ga': 'Mionchoigeartú Múnla Teanga Trastheangach Dhá Chéim le haghaidh Meastachán Cáilíochta an Aistriúcháin Inneall', 'ka': 'მაქინის გადაწყვეტილების კვალეტის განსაზღვრება', 'el': 'Διφασικό διαγλωσσικό μοντέλο γλώσσας για εκτίμηση ποιότητας μηχανικής μετάφρασης', 'hu': 'Kétfázisú nyelvi modell finomhangolás a gépi fordítás minőségbecsléséhez', 'it': 'Modello linguistico bidirezionale Cross-Lingual Fine-Tuning per la stima della qualità della traduzione automatica', 'lt': 'Dviejų fazių tarpkalbinio modelio tikslus koregavimas mašinų vertimo kokybės vertinimui', 'mk': 'Две фази крослингвален модел на фино прилагодување за проценка на квалитетот на преводот на машината', 'ml': 'Name', 'mt': 'Two-Phase Cross-Lingual Language Model Fine-Tuning for Machine Translation Quality Estimation', 'ms': 'Model Bahasa Selasa-Bahasa Dua-Fasa Penyesuaian Baik untuk Estimasi Kualiti Terjemahan Mesin', 'mn': 'Хоёр давхар хэл загвар Машин орчуулах чадварын тооцоололтын хоёр давхар хэл загвар', 'no': 'Name', 'pl': 'Dwufazowy model języka wielojęzykowego dostrojenie dla oszacowania jakości tłumaczenia maszynowego', 'ro': 'Modelul de limbaj translingvistic bifazat pentru estimarea calitatii traducerii automate', 'sr': 'Два фаза кроз-лингуални модел добро наблюдање за оценку качества превода машина', 'kk': 'Компьютердің аудару сапасы бағалау үшін екі- қатар тілінің көтерілі үлгісі', 'so': 'Fine-Tuning for Machine Translation Quality Estimation', 'sv': 'Tvåfasöverskridande språkmodell finjustering för kvalitetsberäkning av maskinöversättning', 'si': 'දෙවෙනි පද්ධති වාර්ථාව ක්\u200dරොස් ලින්ගුල් භාෂාව මොඩේල් හොඳ අවශ්\u200dය අවශ්\u200dය', 'ta': 'Name', 'ur': 'ماشین ترجمہ کی کیفیت ارزیابی کے لئے دو فاز کرس-لینگول زبان موڈل اچھی ٹونگ', 'uz': 'Name', 'vi': 'Độ sâu ngôn ngữ chữ hai giai đoạn', 'bg': 'Двуфазен междуезиков модел за прецизно настройване за оценка на качеството на машинния превод', 'nl': 'Tweefasige Cross-Lingual Taalmodel Fine-Tuning voor Machine Translation Quality Estimation', 'hr': 'Procjena kvalitete prevoda strojeva', 'da': 'To-faset tværsproget sprogmodel finjustering for maskinoversættelseskvalitetsestimering', 'id': 'Model Bahasa Selasa-Bahasa Dua Fasa Penyesuaian Baik untuk Perkiraan Kualitas Translation Mesin', 'de': 'Zweiphasiges Cross-Lingual Language Model Feinabstimmung für die Qualitätsschätzung maschineller Übersetzungen', 'ko': '기계 번역 품질 평가의 2단계 크로스 언어 모델 미세 조정', 'tr': 'Maşynyň terjime Quality Taýýarlama üçin iki-fäze geçişik Dili', 'sw': 'Utamaduni wa Utamaduni wa Utafiti wa Utafiti wa Utafiti wa Mashine', 'fa': 'نماد زبان\u200cهای دو فصل برای ارزیابی کیفیت ترجمه ماشین', 'af': 'Twee- fase Kruis- Linguaal Taal Model Fine- Tuning vir Masjien Vertaling Kwaliteit Estimasie', 'sq': 'Modeli i gjuhës me dy faza të ndërgjuhës rregullon mirë për vlerësimin e cilësisë së përkthimit të makinës', 'am': 'ቋንቋዎች', 'hy': 'Մեքենայի թարգմանման որակի գնահատման համար', 'az': 'Makinat 칂eviri N톛viyy톛ti 칐l칞칲s칲 칲칞칲n 캻ki Faz 칂ift Dili Modeli', 'bs': 'Procjena kvalitete prevoda mašine', 'bn': 'Name', 'cs': 'Dvoufázový crosslingvální jazykový model jemné ladění pro odhad kvality strojového překladu', 'et': 'Kahefaasiline keeleülene mudel masintõlke kvaliteedi hindamiseks', 'fi': 'Kaksivaiheinen monikielinen kielimalli hienosäätö konekäännöksen laadun arviointiin', 'ca': 'Model de llenguatge translíngua de dues fases de millorament per a estimar la qualitat de la traducció de màquines', 'he': 'דוגמנית שפת משולבת שתי שלבים מתאימה למערכת איכות התרגום של מכונות', 'jv': 'Two-phase', 'ha': '@ action', 'sk': 'Dvofazno medjezikovno natančno nastavitev modela za oceno kakovosti strojnega prevoda', 'bo': 'Two-Phase Cross-Lingual Language Model Fine-Tuning for Machine Translation Quality Estimation'}
{'en': 'In this paper, we describe the Bering Lab’s submission to the WMT 2020 Shared Task on Quality Estimation (QE). For word-level and sentence-level translation quality estimation, we fine-tune XLM-RoBERTa, the state-of-the-art cross-lingual language model, with a few additional parameters. Model training consists of two phases. We first pre-train our model on a huge artificially generated QE dataset, and then we fine-tune the model with a human-labeled dataset. When evaluated on the WMT 2020 English-German QE test set, our systems achieve the best result on the target-side of word-level QE and the second best results on the source-side of word-level QE and sentence-level QE among all submissions.', 'ar': 'في هذه الورقة ، نصف تقديم مختبر بيرنغ إلى مهمة WMT 2020 المشتركة حول تقدير الجودة (QE). لتقدير جودة الترجمة على مستوى الكلمات والجمل ، قمنا بضبط XLM-RoBERTa ، نموذج اللغة عبر اللغات الأكثر حداثة ، مع بعض المعلمات الإضافية. تدريب النموذج يتكون من مرحلتين. نقوم أولاً بتدريب نموذجنا مسبقًا على مجموعة بيانات QE ضخمة مُنشأة بشكل مصطنع ، ثم نقوم بضبط النموذج باستخدام مجموعة بيانات تحمل علامة بشرية. عند تقييمها على مجموعة اختبار WMT 2020 الإنجليزية-الألمانية QE ، تحقق أنظمتنا أفضل نتيجة على الجانب المستهدف من QE على مستوى الكلمات وثاني أفضل النتائج على جانب المصدر من QE على مستوى الكلمة و QE على مستوى الجملة بين كل التقديمات.', 'es': 'En este artículo, describimos la presentación del Laboratorio de Bering a la Tarea Compartida sobre Estimación de la Calidad (QE) del WMT 2020. Para estimar la calidad de la traducción a nivel de palabras y oraciones, ajustamos XLM-Roberta, el modelo lingüístico multilingüe de última generación, con algunos parámetros adicionales. La formación de modelos consta de dos fases. Primero entrenamos previamente nuestro modelo en un enorme conjunto de datos de QE generado artificialmente, y luego ajustamos el modelo con un conjunto de datos etiquetado por humanos. Cuando se evalúan en el conjunto de pruebas de QE inglés-alemán del WMT 2020, nuestros sistemas logran el mejor resultado en el lado objetivo de la QE a nivel de palabra y los segundos mejores resultados en el lado de la fuente de la QE a nivel de palabra y la QE a nivel de frase entre todas las presentaciones.', 'pt': 'Neste artigo, descrevemos a submissão do Bering Lab à Tarefa Compartilhada do WMT 2020 sobre Estimativa de Qualidade (QE). Para estimar a qualidade da tradução em nível de palavra e frase, ajustamos o XLM-RoBERTa, o modelo de linguagem multilíngue de última geração, com alguns parâmetros adicionais. O treinamento do modelo consiste em duas fases. Primeiro, pré-treinamos nosso modelo em um enorme conjunto de dados QE gerado artificialmente e, em seguida, ajustamos o modelo com um conjunto de dados rotulado por humanos. Quando avaliados no conjunto de testes QE inglês-alemão do WMT 2020, nossos sistemas alcançam o melhor resultado no lado alvo do QE no nível da palavra e os segundos melhores resultados no lado da fonte do QE no nível da palavra e no QE no nível da frase entre todas as submissões.', 'fr': "Dans cet article, nous décrivons la soumission du laboratoire de Bering à la tâche partagée WMT 2020 sur l'estimation de la qualité (QE). Pour l'estimation de la qualité de la traduction au niveau des mots et des phrases, nous affinons XLM-Roberta, le modèle linguistique multilingue de pointe, avec quelques paramètres supplémentaires. La formation sur les modèles comprend deux phases. Nous préentraînons d'abord notre modèle sur un énorme jeu de données QE généré artificiellement, puis nous affinons le modèle avec un ensemble de données étiqueté par un humain. Lorsqu'ils sont évalués sur l'ensemble de tests QE anglais-allemand WMT 2020, nos systèmes obtiennent les meilleurs résultats du côté cible du QE au niveau des mots et les deuxièmes meilleurs résultats du côté source du QE au niveau des mots et du QE au niveau de la phrase parmi toutes les soumissions.", 'ja': '本稿では、WMT 2020 Shared Task on Quality Estimation （ QE ）へのベーリングラボの提出について説明する。ワードレベルと文レベルの翻訳品質の推定には、最先端のクロスリンガル言語モデルであるXLM - RoBERTaをいくつかの追加パラメータで微調整します。モデルトレーニングは2つのフェーズで構成されています。まず、巨大な人工的に生成されたQEデータセットでモデルを事前にトレーニングし、次に人間が標識したデータセットでモデルを微調整します。WMT 2020英独QEテストセットで評価すると、当社のシステムは、ワードレベルQEのターゲットサイドで最高の結果を達成し、すべての提出物の中でワードレベルQEと文レベルQEのソースサイドで2番目に最高の結果を達成します。', 'zh': '本文述白令实验室WMT 2020质评(QE)共享其文。 单词级与句级译量,微调最先进跨语言XLM-RoBERTa,并给额外参数。 模则训练两端。 吾先于大工之QE集上预练吾形,而后吾以人之表数集微之。 WMT 2020英语-德语QE试集上评,统于单词级QE者取上,单词QE者取次。', 'hi': 'इस पेपर में, हम गुणवत्ता अनुमान (क्यूई) पर डब्ल्यूएमटी 2020 साझा कार्य के लिए बेरिंग लैब के सबमिशन का वर्णन करते हैं। शब्द-स्तर और वाक्य-स्तर के अनुवाद गुणवत्ता अनुमान के लिए, हम कुछ अतिरिक्त मापदंडों के साथ XLM-RoBERTa, अत्याधुनिक क्रॉस-भाषी भाषा मॉडल को ठीक करते हैं। मॉडल प्रशिक्षण में दो चरण होते हैं। हम पहले एक विशाल कृत्रिम रूप से उत्पन्न क्यूई डेटासेट पर अपने मॉडल को पूर्व-प्रशिक्षित करते हैं, और फिर हम मानव-लेबल वाले डेटासेट के साथ मॉडल को ठीक करते हैं। जब WMT 2020 अंग्रेजी-जर्मन QE परीक्षण सेट पर मूल्यांकन किया जाता है, तो हमारे सिस्टम शब्द-स्तर QE के लक्ष्य-पक्ष पर सबसे अच्छा परिणाम प्राप्त करते हैं और सभी प्रस्तुतियों के बीच शब्द-स्तर QE और वाक्य-स्तर QE के स्रोत-पक्ष पर दूसरा सबसे अच्छा परिणाम प्राप्त करते हैं।', 'ru': 'В этой статье мы описываем представление Bering Lab к совместной задаче WMT 2020 по оценке качества (QE). Для оценки качества перевода на уровне слов и предложений мы тонко настраиваем XLM-RoBERTa, ультрасовременную модель межъязыкового языка, с несколькими дополнительными параметрами. Типовое обучение состоит из двух этапов. Сначала мы предварительно обучаем нашу модель на огромном искусственно сгенерированном наборе данных QE, а затем тонко настраиваем модель с набором данных, помеченным человеком. При оценке на наборе тестов WMT 2020 English-German QE наши системы достигают лучшего результата на целевой стороне QE уровня слова и второго лучшего результата на исходной стороне QE уровня слова и QE уровня предложения среди всех представлений.', 'ga': 'Sa pháipéar seo, déanaimid cur síos ar aighneacht Bering Lab do Thasc Comhroinnte WMT 2020 ar Mheastachán Cáilíochta (QE). Chun meastachán a dhéanamh ar cháilíocht an aistriúcháin ar leibhéal na bhfocal agus ar leibhéal na habairte, déanaimid mionchoigeartú ar XLM-RoBERTa, an tsamhail teanga thrastheangach nua-aimseartha, le roinnt paraiméadair bhreise. Tá dhá chéim i gceist le hoiliúint mhúnla. Déanaimid ár múnla a réamhthraenáil ar dtús ar thacar sonraí QE ollmhór a ghintear go saorga, agus ansin déanaimid mionchoigeartú ar an tsamhail le tacar sonraí lipéadaithe daonna. Nuair a dhéantar measúnú orthu ar thacar tástála QE Béarla-Gearmáinis WMT 2020, baineann ár gcórais an toradh is fearr amach ar thaobh sprice QE leibhéal na bhfocal agus na torthaí is fearr ar an dara taobh foinse de QE leibhéal na bhfocal agus QE leibhéal na habairte ina measc. gach aighneacht.', 'hu': 'Ebben a tanulmányban ismertetjük a Bering Lab benyújtását a WMT 2020 Shared Task on Quality Estimation (QE) című dokumentumnak. A szó- és mondatszintű fordítási minőségbecslés érdekében finomhangoljuk az XLM-RoBERTa, a korszerű nyelvi modellt, néhány további paraméterrel. A modellképzés két szakaszból áll. Először előkészítjük modellünket egy hatalmas mesterségesen generált QE adatkészletre, majd finomhangoljuk a modellt egy emberi jelölésű adatkészlettel. A WMT 2020 angol-német minőségi tesztkészleten történő értékelésekor rendszereink a szószintű minőségi teszt céloldalán a legjobb eredményt érik el, és a második legjobb eredményt a szószintű minőségi és mondatszintű minőségi teszt forrásoldalán az összes beadvány között.', 'el': 'Σε αυτή την εργασία, περιγράφουμε την υποβολή του εργαστηρίου Μπέρινγκ στην Κοινή Εργασία Εκτίμησης Ποιότητας του WMT 2020. Για την εκτίμηση της ποιότητας της μετάφρασης σε επίπεδο λέξεων και προτάσεων, συντονίζουμε το υπερσύγχρονο γλωσσικό μοντέλο, με μερικές πρόσθετες παραμέτρους. Το πρότυπο εκπαίδευσης αποτελείται από δύο φάσεις. Πρώτα εκπαιδεύουμε το μοντέλο μας σε ένα τεράστιο τεχνητά παραγόμενο σύνολο δεδομένων QE και στη συνέχεια συντονίζουμε το μοντέλο με ένα σύνολο δεδομένων με ανθρώπινη ετικέτα. Όταν αξιολογούνται με το σετ τεστ αγγλικής-γερμανικής QE, τα συστήματά μας επιτυγχάνουν το καλύτερο αποτέλεσμα στην πλευρά στόχου της QE σε επίπεδο λέξης και τα δεύτερα καλύτερα αποτελέσματα στην πλευρά προέλευσης της QE σε επίπεδο λέξης και σε επίπεδο πρότασης μεταξύ όλων των υποβαλλόμενων αιτήσεων.', 'it': "In questo articolo, descriviamo la presentazione del Bering Lab al WMT 2020 Shared Task on Quality Estimation (QE). Per la valutazione della qualità della traduzione a livello di parola e frase, perfezioniamo XLM-RoBERTa, il modello linguistico multilingue all'avanguardia, con alcuni parametri aggiuntivi. La formazione dei modelli consiste in due fasi. Prima addestriamo il nostro modello su un enorme set di dati QE generato artificialmente, e poi perfezioniamo il modello con un set di dati etichettato dall'uomo. Se valutati sul set di test QE inglese-tedesco WMT 2020, i nostri sistemi raggiungono i migliori risultati sul lato target del QE a livello di parola e i secondi migliori risultati sul lato sorgente del QE a livello di parola e di frase tra tutte le proposte.", 'lt': 'Šiame dokumente apibūdiname Bering Lab pateiktą WMT 2020 bendros kokybės vertinimo užduoties (QE) klausimą. Kalbant apie žodžių ir sakinių vertimo kokybės vertinimą, mes patobuliname XLM-RoBERTa, naujausias tarpkalbinis modelis, su keliais papildomais parametrais. Mokymo modelį sudaro du etapai. Pirmiausia parengiame savo model į didžiuliu dirbtinai sukurtu QE duomenų rinkiniu, o tada patobuliname modelį žmogaus pažymėtu duomenų rinkiniu. Vertindamos WMT 2020 anglų ir vokiečių QE bandymų rinkinį, mūsų sistemose pasiektas geriausias rezultatas žodžių lygio QE tikslinėje pusėje ir antrasis geriausias rezultatas žodžių lygio QE ir sakinių lygio QE pradinėje pusėje.', 'kk': 'Бұл қағазда, біз Беринг лабораториясының WMT 2020 сапаттық оқиға (QE) ортақ тапсырмасына жіберілген тапсырманы түсіндіреміз. Сөздің деңгейі және сөздің деңгейі аудару сапатын бағалау үшін біз XLM- RoBERTa деңгейін, әртүрлі тіл үлгісінің күйі, бірнеше қосымша параметрлері бар. Үлгі оқыту үлгісі екі этап болады. Біз біріншіден өзіміздің моделімізді QE деректер тізіміне көп құрылған, кейін адамдардың жарлық деректер тізіміне үлгілеу үлгісін таңдадық. WMT 2020-нің ағылшын тілінің QE сынақтарын бағалағанда, жүйелеріміз сөз деңгейіндегі QE- нің нақты жақсы нәтижесін және сөз деңгейіндегі QE және сөз деңгейіндегі QE- нәтижесінің екінші жақсы нәтижесін бар', 'ms': 'Dalam kertas ini, kami menggambarkan penghantaran Lab Bering kepada Tugas Berkongsi WMT 2020 tentang Estimasi Kualiti (QE). Untuk penilaian kualiti terjemahan aras-perkataan dan kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat. Latihan model terdiri dari dua tahap. Kita pertama-tama melatih model kita pada set data QE yang besar secara buatan, dan kemudian kita memperbaiki model dengan set data yang ditabel manusia. Apabila diteliti pada set ujian QE Inggeris-Jerman WMT 2020, sistem kita mencapai keputusan terbaik pada sisi sasaran-aras perkataan QE dan keputusan terbaik kedua pada sisi sumber-aras perkataan QE dan aras-kalimat QE diantara semua penghantaran.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ബെരിംഗ് ലാബിന്\u200dറെ കീഴ്പെടുത്തുന്നത് വിവരിച്ചുകൊടുക്കുന്നു. വിഎംടി 2020 പങ്കെടുത്തിരിക്ക വാക്ക്- നിലം, വാക്ക്- നില വിവരങ്ങളുടെ വിവരങ്ങളുടെ ഗുണവിശേഷത്തിനായി നമ്മള്\u200d കൂടുതല്\u200d പരാമീറ്ററുകളുമായി എക്സ്ലെയി- റോബെര്\u200dട്ട, സ്റ്റേറ മോഡല്\u200d ട്രെയിനിങ്ങള്\u200dക്ക് രണ്ട് കാലം ഉണ്ട്. ഞങ്ങള്\u200d ആദ്യം നമ്മുടെ മോഡല്\u200d ട്രെയിന്\u200d ചെയ്യുന്നത് ഒരു വലിയ ക്യൂയി ഡാറ്റാസറ്റ് ഉണ്ടാക്കിയിരിക്കുന്നു. പിന്നെ നമ്മള്\u200d മോഡലിനെ  WMT 2020 ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d ക്യൂയി ടെസ്റ്റ് സെറ്റില്\u200d വിലപിക്കപ്പെട്ടപ്പോള്\u200d നമ്മുടെ സിസ്റ്റമുകള്\u200d വാക്ക്-നില ക്യൂയിയുടെ ലക്ഷ്യത്തിന്റെ ഏറ്റവും നല്ല ഫലം എത', 'mk': 'Во овој весник, ја опишуваме поднесувањето на Беринг лабораторијата на заедничката задача на ВМТ 2020 за проценка на квалитетот. За проценка на квалитетот на преводот на ниво на зборови и реченици, ние финетизираме XLM-RoBERTa, најсовремениот модел на меѓујазички јазик, со неколку дополнителни параметри. Моделот на тренинг се состои од две фази. Прво го предупредуваме нашиот модел на огромен вештачки генериран QE датотек, а потоа го поправиме моделот со човек означен податок. Кога ќе се процени на тестот WMT 2020 англиско-германски QE, нашите системи го постигнуваат најдобриот резултат на целната страна на QE на зборот и вториот најдобар резултат на изворот на QE на зборот и QE на реченицата меѓу сите поднесувања.', 'ka': 'ამ დოკუნტში ჩვენ აღწერეთ ბერინგის ლაბოლობის გადასტანაცია WMT 2020-ის გაყოფილი დავალების განსაზღვრებაზე (QE). სიტყვების დონეზე და სიტყვების დონეზე გადაწყვეტილების განსაზღვრებისთვის, ჩვენ XLM-RoBERTa-ს, სამყარო სიტყვების კრესიენგური ენგური მოდელზე, რამდენიმე დამატებული პარამეტრებით მოდელური განსწავლება ორი ფაესების შეფარდება. ჩვენ პირველად ჩვენი მოდელის წინასწარმოადგენა დიდი კულტურად შექმნა QE მონაცემების შესახებ, და შემდეგ ჩვენ მოდელის შესახებ ადამიანის მონაცემების შესახებ დავწერ როდესაც WMT 2020-ის ინგლისურ-გერმანური QE ტესტის შესაბამისად გაუმუშავებულია, ჩვენი სისტემები ყველაზე საუკეთესო შესაბამისათვის საუკეთესო შესაბამისათვის QE და ყველა შესაბამისათვის საუკეთესო შესა', 'mt': "F'dan id-dokument, aħna niddeskrivu s-sottomissjoni tal-Bering Lab lill-WMT 2020 Shared Task on Quality Estimation (QE). Għall-istima tal-kwalità tat-traduzzjoni fil-livell tal-kelma u fil-livell tas-sentenza, a ħna nirranġaw XLM-RoBERTa, l-aktar mudell avvanzat tal-lingwa trasversali, bi ftit parametri addizzjonali. It-taħriġ mudell jikkonsisti f’żewġ fażijiet. L-ewwel a ħna nħarrġu minn qabel il-mudell tagħna fuq sett ta’ dejta kbir iġġenerat artifiċjalment dwar il-QE, u mbagħad aħna nħarrġu l-mudell b’sett ta’ dejta ttikkettat mill-bniedem. Meta evalwati fuq is-sett tat-test QE Ingliż-Ġermaniż tad-WMT 2020, is-sistemi tagħna jiksbu l-aħjar riżultat fuq in-naħa mmirata tal-livell tal-kelma QE u t-tieni l-aħjar riżultati fuq in-naħa sors tal-livell tal-kelma QE u l-livell tas-sentenza QE fost is-sottomissjonijiet kollha.", 'mn': 'Энэ цаасан дээр бид Берингийн лабораторийн WMT 2020-ийн хуваалтын ажлыг (QE) хэлэхэд тайлбарлаж байна. Үүний түвшинд, өгүүлбэр-түвшинд орчуулах чадварыг тодорхойлох үед бид XLM-RoBERTa, урлагийн хэл давхар хэл загварын тухай хэдэн нэмэлт параметрлүүдтэй холбоотой. Загварын дасгал хөдөлгөөн нь хоёр дасгал байдаг. Эхлээд бид өөрсдийн загварыг уран бүтээлч QE өгөгдлийн суурь дээр сургаж, дараа нь хүн төрөлхтний нэрлэгдсэн өгөгдлийн суурь дээр загварыг тодорхойлох болно. WMT 2020-н Англи-Герман QE тест хэмжээнд үнэлэхэд бидний систем үгийн түвшинд QE-н хамгийн сайн үр дүнг гаргаж, үгийн түвшинд QE болон өгүүлбэрийн түвшинд хамгийн сайн үр дүнг гаргадаг.', 'no': 'I denne papiret beskriver vi Bering Lab-tillegget til delt oppgåve WMT 2020 om kvalitetestimering (QE). For estimating av ordnivå og setningsnivå for omsetjingskvalitet, finn vi XLM-RoBERTa, mønsteret for kunsten krysspråk, med nokre ekstra parametrar. Modellæring inneheld to fasar. Vi først treng modellen vårt på ein stor kunstifisk generert QE-datasett, og så finn vi opp modellen med eit menneskelige datasett. Når det er evaluert på WMT 2020-engelsk-tysk QE-testet, oppnår systemet våre beste resultatet på målside av ordnivå QE og den andre beste resultatet på kjeldesida av ordnivå QE og setningnivå QE mellom alle undersøkingar.', 'pl': 'W niniejszym artykule opisujemy zgłoszenie Bering Lab do WMT 2020 Shared Task on Quality Estimation (QE). W celu oszacowania jakości tłumaczeń na poziomie słów i zdań dostosowujemy XLM-RoBERTa, najnowocześniejszy model języka wielojęzycznego, z kilkoma dodatkowymi parametrami. Szkolenie modelowe składa się z dwóch faz. Najpierw wstępnie trenujemy nasz model na ogromnym sztucznie wygenerowanym zbiorze danych QE, a następnie dostrajamy model z oznaczonym przez człowieka zestawem danych. Po ocenie zestawu testów WMT 2020 angielsko-niemieckiego QE nasze systemy osiągają najlepszy wynik po stronie docelowej QE na poziomie słowa oraz drugie najlepsze wyniki po stronie źródłowej QE na poziomie słowa i QE na poziomie zdań spośród wszystkich zgłoszeń.', 'ro': 'În această lucrare, descriem prezentarea laboratorului Bering la misiunea partajată WMT 2020 privind estimarea calității (QE). Pentru estimarea calității traducerii la nivel de cuvinte și propoziții, optimizăm XLM-RoBERTa, modelul de limbă translingvistică de ultimă generație, cu câțiva parametri suplimentari. Formarea modelului constă în două faze. Mai întâi pregătim modelul nostru pe un set imens de date QE generat artificial, apoi reglăm modelul cu un set de date etichetat de om. Atunci când sunt evaluate pe setul de teste QE engleză-germană WMT 2020, sistemele noastre obțin cel mai bun rezultat pe partea țintă a QE la nivel de cuvânt și al doilea cel mai bun rezultat pe partea sursă a QE la nivel de cuvânt și QE la nivel de frază printre toate depunerile.', 'si': 'මේ පැත්තට, අපි බෙරින්ග් ලැබ් එකේ විස්තර කරන්නේ WMT 2020ක් විශේෂ විශේෂතාව අනුමාණය (QE) ගැන සමාගත වැඩ කරන්න. වචන ස්ථානය සහ වාක්ෂා ස්ථානය අවශ්\u200dය අවශ්\u200dය විශ්වාස කරන්න, අපි XLM-RoBERTa විශ්වාස කරනවා, ක්\u200dරිස්ට් භාෂාවික භාෂාවික විශ මෝඩල් ප්\u200dරශ්නයක් තියෙන්නේ පද්ධති දෙකක් තියෙන්නේ. අපි මුලින්ම අපේ මොඩල් ප්\u200dරධානයක් විශාල විශාල විදිහට QE දත්ත සූද්ධයක් නිර්මාණය කරනවා, ඊට පස්සේ අපි මිනිස්සු ලබ WMT 2020යි ඉංග්\u200dරීසිය-ජර්මන් QE පරීක්ෂණ සෙට් එකේ විශ්වාස කළාම, අපේ පද්ධති පද්ධතියේ වාර්තාවක් QE වලින් ලක්ෂණ පැත්තේ හොඳම ප්\u200dරතිප්\u200dරතිප්\u200d', 'so': 'Qoraalkan waxaynu ku qoraynaa warqaddan warqadda la soo dhiibay labka Bering ee WMT 2020 ee loo sharciyey shaqo qiimaanshaha (QE). Qiimeynta qiimaha turjumaadda ee heerka iyo heerka afka, waxaynu qornaa XLM-RoBERTA, modelka afka-art oo afka kala duduwan, waxayna leedahay dhawr parameters oo kale. Waxbarashada qaababka waxaa ka mid ah laba marxaladood. Tusaalka hore waxaynu ku tababarinaynaa sawir aad u weyn oo QE ah, kadibna waxaynu sameynaa modelka oo ku qoran sawirada dadka. Markii lagu qiimeeyo qoraalka imtixaanka ee WMT 2020-Jarmalka QE, nidaamkayagu wuxuu gaadhaa dhamaanka ugu wanaagsan ee ugu jeeda heerka QE iyo resultiyada labaad ee ugu wanaagsan ee ku saabsan meesha ugu horraysa QE iyo heerka xafiiska QE.', 'sv': 'I denna uppsats beskriver vi Bering Labs bidrag till WMT 2020 Shared Task on Quality Estimation (QE). För bedömning av översättningskvalitet på ordnivå och meningsnivå finjusterar vi XLM-RoBERTa, den toppmoderna språkmodellen, med några ytterligare parametrar. Modellutbildningen består av två faser. Vi tränar först vår modell på ett enormt artificiellt genererat QE-dataset, och sedan finjusterar vi modellen med ett mänskligt märkt dataset. När de utvärderas på WMT 2020 engelsk-tyska QE-testuppsättningen uppnår våra system det bästa resultatet på målsidan av ordnivå QE och det näst bästa resultatet på källsidan av ordnivå QE och meningsnivå QE bland alla inlämningar.', 'sr': 'U ovom papiru opisujemo podatke Bering Lab-a na delovani zadatak WMT 2020 o procjeni kvalitete (QE). Za procjenu kvalitete prevoda na nivou riječi i rečenica, ispravljamo XLM-RoBERTu, stanju umjetničkog preko jezika, sa nekoliko dodatnih parametara. Modelni trening se sastoji od dve faze. Prvo smo trenirali naš model na ogromnom umjetnički proizvedenom setu podataka QE-a, a zatim ćemo srediti model sa ljudskim označenim setom podataka. Kada su procenili na setu testa na engleskom i njemačkom QE WMT 2020, naši sistemi postigli najbolji rezultat na ciljnoj strani QE nivoa riječi i drugim najboljim rezultatima na izvornoj strani QE nivoa riječi i QE nivoa rečenica među svim podacima.', 'ta': 'இந்த காகிதத்தில், நாம் பெரிங் லாப் குறிப்பிடுகிறோம் WMT 2020 பகிர்ந்த பணியின் தரம் கணக்கீடு (QE) மீது கூட்டிய பணியை க For word-level and sentence-level translation quality estimation, we fine-tune XLM-RoBERTa, the state-of-the-art cross-lingual language model, with a few additional parameters.  மாதிரி பயிற்சி இரண்டு நிலைகளில் உள்ளது. நாங்கள் முதல் பயிற்சி முறைமையில் எங்கள் மாதிரியை ஒரு பெரிய கியூ தரவு அமைப்பில் பயிற்சி செய்து, பின்னர் நாம் மாதிரியை ஒரு மனித WMT 2020 ஆங்கிலம்- ஜெர்மன் கியூயி சோதனையின் அமைப்பில் மதிப்பெடுக்கப்பட்ட போது, எங்கள் கணினிகள் சிறந்த முடிவு வார்த்தை நிலையின் சேர்க்கையின் சேர்க்கையின் கு', 'ur': 'اس کاغذ میں ہم نے برینگ لاب کے مطابق WMT 2020 کے شریک ٹاکس (QE) کے بارے میں مشخص کیا ہے۔ کلمات سطح اور کلمات سطح کی ترجمہ کیفیت کا ارزش کے لئے ہم XLM-RoBERTa کو ٹھیک ٹونڈ کریں گے، آرت کے کرس زبان کی موڈل کے ساتھ کچھ اضافہ پارامتر ہیں۔ Model training consists of two phases. ہم پہلی بار اپنے مدل کو ایک بڑے مصنوعی طریقے سے پیدا کیا گیا QE ڈاٹ سٹ پر ترین کریں، پھر ہم نے مدل کو ایک انسان کے لابلیٹ ڈاٹ سٹ کے ساتھ ٹھیک ٹھیک ٹھیک کر دیا۔ جبکہ WMT 2020 میں انگلیسی-جرمنی QE امتحان سٹ پر ارزش کیا گیا تھا، ہماری سیستموں نے کلمات-سطح QE کے سب سے بہترین نتیجہ پہنچائی اور کلمات-سطح QE اور کلمات-سطح-سطح QE کے دوسرے بہترین نتیجہ پر سب سے زیادہ اچھے نتیجے پہنچا', 'vi': 'Trong tờ giấy này, chúng tôi mô tả việc giao nộp phòng thí nghiệm Bering cho công việc chia s ẻ WM 2020 về ước lượng chất lượng (QE). Để đánh giá chất lượng từ cấp và mức án, chúng tôi tinh chỉnh XLM-RoBERTa, mô hình ngôn ngữ khác nhau bậc hiện đại, với một vài tham số khác. Mô hình huấn luyện gồm hai giai đoạn. Đầu tiên chúng tôi khởi tạo mẫu dựa trên một bộ dữ liệu cá nhân tạo ra lớn, và sau đó chúng tôi chỉnh sửa mẫu với một bộ dữ liệu có nhãn con người. Khi được đánh giá trên thử nghiệm WM 2020, hệ thống của chúng tôi đạt được kết quả tốt nhất trên mục tiêu của cấp QE, và kết quả tốt thứ hai về mặt gốc của cấp QE từ và mức án QE trong tất cả các tài liệu.', 'uz': 'Bu qogʻozda biz 2020-yil WMT (QE) bilan birlashtirilgan vazifani qiymatga qaramaymiz. @ info: whatsthis Model taʼminlovchisi ikki darajaga ega. Biz birinchi avval modelimizni QE maʼlumotlar sohasida yaratishimiz mumkin, keyin biz modelni inson tuzilgan maʼlumotlar soni bilan yaxshilamiz. WMT 2020 Ingliz-Olmon QE sinov sohasida qiymatda, bizning tizimlarimiz QE soʻzning eng yaxshi natijalarini bajaradi va hamma imkoniyatlarning birinchi eng eng yaxshi natijalarini xabar qiladi.', 'bg': 'В настоящата статия описваме представянето на Беринг Лаборатория към Споделената задача за оценка на качеството (ОВ) 2020. За оценка на качеството на превода на ниво дума и изречение ние финализираме най-съвременния междуезичен езиков модел с няколко допълнителни параметри. Моделното обучение се състои от две фази. Първо предварително тренираме модела си върху огромен изкуствено генериран набор от данни, а след това фино настройваме модела с набор от данни, обозначен от човека. Когато се оценява на англо-немски тест набор, нашите системи постигат най-добрия резултат от целевата страна на ниво дума и вторият най-добър резултат от източника на ниво дума и ниво изречение сред всички подадени предложения.', 'hr': 'U ovom papiru opisujemo podatke Bering Lab-a podijeljenom zadatku WMT 2020 o procjeni kvalitete (QE). Za procjenu kvalitete prevoda na razini riječi i razini rečenica, dobro određujemo XLM-RoBERTa, model umjetnosti preko jezika s nekoliko dodatnih parametara. Modelna obuka se sastoji od dvije faze. Prvo predvježbamo naš model na ogromnoj umjetnički proizvedenoj QE dataset, a zatim ćemo srediti model sa ljudskim označenim podacima. Kada su procijenjeni na setu testa na engleskom i njemačkom QE-u WMT 2020, naši sustavi postigli najbolji rezultat na ciljnoj strani QE-a riječi i drugim najboljim rezultatima na izvornoj strani riječi nivoa QE i razini rečenica QE među svim podacima.', 'nl': 'In dit artikel beschrijven we de inzending van het Bering Lab aan de WMT 2020 Shared Task on Quality Estimation (QE). Voor de schatting van de vertaalkwaliteit op woord- en zinnenniveau verfijnen we XLM-RoBERTa, het state-of-the-art cross-lingual taalmodel, met een paar extra parameters. De modeltraining bestaat uit twee fasen. We trainen ons model eerst vooraf op een enorme kunstmatig gegenereerde QE dataset, en dan verfijnen we het model met een door mensen gelabelde dataset. Wanneer deze worden geëvalueerd op de WMT 2020 Engels-Duitse QE testset, bereiken onze systemen het beste resultaat op de doelkant van QE op woordniveau en de tweede beste resultaten op de bronkant van QE op woordniveau en QE op zinnniveau onder alle inzendingen.', 'da': 'I denne artikel beskriver vi Bering Labs indsendelse til WMT 2020 Shared Task on Quality Estimation (QE). Til vurdering af oversættelseskvalitet på ordniveau og sætningsniveau finjusterer vi XLM-RoBERTa, den avancerede tværsprogede sprogmodel, med et par yderligere parametre. Modelutræning består af to faser. Vi forudtræner først vores model på et enormt kunstigt genereret QE datasæt, og derefter finjusterer vi modellen med et menneskeligt mærket datasæt. Når vores systemer evalueres på WMT 2020 engelsk-tysk QE testsæt, opnår vores systemer det bedste resultat på målsiden af ordniveau QE og de næstbedste resultater på kildesiden af ordniveau QE og sætningsniveau QE blandt alle indsendelser.', 'de': 'In diesem Beitrag beschreiben wir die Einreichung des Bering Lab zur WMT 2020 Shared Task on Quality Estimation (QE). Für die Schätzung der Übersetzungsqualität auf Wort- und Satzebene optimieren wir XLM-RoBERTa, das hochmoderne crosslinguale Sprachmodell, mit einigen zusätzlichen Parametern. Die Modellausbildung besteht aus zwei Phasen. Zunächst trainieren wir unser Modell auf einem riesigen künstlich generierten QE-Datensatz, und dann verfeinern wir das Modell mit einem human-labeled Datensatz. Mit dem WMT 2020 Englisch-Deutsch QE Testset erzielen unsere Systeme das beste Ergebnis auf der Zielseite von QE auf Wortebene und die zweitbesten Ergebnisse auf der Quellseite von QE auf Wortebene und QE auf Satzebene unter allen Einreichungen.', 'id': 'Dalam kertas ini, kami menggambarkan pengiriman Bering Lab ke WMT 2020 Shared Task on Quality Estimation (QE). Untuk penilaian kualitas terjemahan tingkat kata dan kalimat kalimat kalimat kalimat kalimat, kami memperbaiki XLM-RoBERTa, model bahasa saling bahasa state-of-the-art, dengan beberapa parameter tambahan. Latihan model terdiri dari dua tahap. Pertama kita melatih model kita pada set data QE yang besar yang dibuat secara buatan, dan kemudian kita memperbaiki model dengan set data yang ditabel manusia. Ketika diteliti di set ujian QE Inggris-Jerman WMT 2020, sistem kami mencapai hasil terbaik di sisi sasaran dari tingkat kata QE dan hasil terbaik kedua di sisi sumber dari tingkat kata QE dan tingkat kalimat QE diantara semua pengiriman.', 'ko': '본고에서 우리는 백령실험실이 WMT 2020 품질평가 공유임무(QE)에 제출한 상황을 묘사했다.단어급과 문장급의 번역 품질 평가에 대해 우리는 XLM RoBERTA, 즉 가장 선진적인 다중 언어 언어 모델을 미세하게 조정하고 추가 파라미터를 추가했다.모형 훈련은 두 단계로 나뉜다.우리는 먼저 거대한 인공적으로 생성된QE 데이터 집합에서 우리의 모델을 미리 훈련한 다음에 인류가 표시한 데이터 집합으로 모델을 미세하게 조정한다.WMT 2020 영독 QE 테스트집에서 평가를 할 때 우리 시스템은 단어급 QE의 목표단에서 가장 좋은 결과를 얻었고, 제출된 모든 테스트에서 단어급 QE와 문장급 QE의 원본에서 두 번째로 좋은 결과를 얻었다.', 'sw': 'Katika gazeti hili, tunaelezea ujumbe wa Lab ya Bering kwa ajili ya Tamko la WMT 2020 lililoshirikishwa kwenye Hesabu (QE). Kwa kiwango cha maneno na kiwango cha tafsiri cha kiwango cha hukumu, tunaonyesha vizuri XLM-RoBERTa, mtindo wa lugha ya asili ya sanaa, na kipimo cha ziada. mafunzo ya Modeli yanajumuisha hatua mbili. Kwanza tunamfundisha muundo wetu kwenye seti kubwa ya takwimu za QE kwa ubunifu, na kisha tunaweka vizuri kwa mfumo wa taarifa za binadamu. Wakati ulipopitiwa kwenye kituo cha testi cha WMT 2020 cha Kiingereza na Kijerumani cha QE, mifumo yetu inapata matokeo bora zaidi kwenye upande wa ngazi ya maneno na matokeo ya pili bora kwenye upande wa ngazi ya QE na kiwango cha hukumu cha QE kati ya mawasiliano yote.', 'tr': "Bu kagyzda, Bering Lab'yň WMT 2020-iň Quality Taýýarlama (QE) aýratynyň berilmegini tassykladyk. Sözler derejesi we sözlemler derejesi terjime etmek üçin XLM-RoBERTa, sanat çarp dil nusgasyna gollanýarys we birnäçe ekleýän parameterler bilen düzümlendiris. Bu nusga taýýarlanmasy iki fasydan bar. Biz ilkinji gezek nusgamyzy örän uly adam görkezilen QE veri setinde öňünden öňünden çykardyk we soňra nusgamyzy adam bilen etiket edilen veri setinde çykardyk. WMT 2020-nji iňlisçe-nemesçe QE testi düzeninde deňlendirildiklerinde, sistemamyz söz derejesiniň QE-niň iň gowy netijesini we söz derejesiniň QE-niň we söz derejesiniň iň gowy netijesini berilýär.", 'af': "In hierdie papier beskrywe on s die Bering Lab se onderskrywing aan die WMT 2020 deelde taak op Kwaliteit Estimasie (QE). Vir woord-vlak en sentence-vlak-oorsetting van kwaliteit-estimatie, ons fin-tune XLM-RoBERTa, die staat-van-die-kuns kruistaal-model, met 'n paar addisionele parameters. Model oefening bestaan van twee fase. Ons het eerste voor-trein ons model op 'n groot kunstenaar genereer QE datastel, en dan het ons die model met 'n mens-etiketeerde datastel gevind. Wanneer die WMT 2020-Engelse-Duitse QE toets stel evalueer word, ons stelsels bereik die beste resultaat op die doel-kant van woord-vlak QE en die tweede beste resultate op die bron-kant van woord-vlak QE en sentence-vlak QE onder alle onderskrifte.", 'fa': 'در این کاغذ، ما تحویل آزمایشگاه برینگ به کار مشترک WMT 2020 در مورد ارزیابی کیفیت (QE) توصیف می\u200cکنیم. برای ارزیابی کیفیت ترجمه کردن سطح کلمه و جمله جمله، با چند پارامتر اضافه\u200cای XLM-RoBERTa، موقعیت زبان\u200cهای متوسط زبان هنری را با چند تنظیم می\u200cکنیم. آموزش مدل از دو مرحله است. ما اولین بار مدل خود را روی یک مجموعه داده های QE بسیار مصنوعی تولید کردیم، و بعد مدل را با یک مجموعه داده های انسان به عنوان نقاشی مشخص کردیم. وقتی در مجموعه امتحان انگلیسی و آلمانی QE WMT 2020 ارزیابی شد، سیستم\u200cهای ما بهترین نتیجه\u200cای را در مقابل هدف سطح کلمه QE می\u200cرسانند و نتیجه دومین بهترین نتیجه\u200cهای منبع سطح کلمه QE و سطح مجموعه QE در میان تمام تحویل\u200cها.', 'am': 'በዚህ ካላት፣ በ2020 ሰዓት ላይ የተሰራጨውን ስራ (QE) የብሬንግ ላብ አዋጅ እናሳውቃለን፡፡ ለቃላት-ደረጃ እና ለቋንቋ-ደረጃ ትርጉም ጥያቄ መጠቀሚያ፣ የግዛት-የቋንቋ-ቋንቋ-ቋንቋ ሞዴል፣ በጥቂት ምርጫዎች እናስቀምጣለን፡፡ የሞዴል ትምህርት ሁለት ደረጃዎች ነው:: መጀመሪያ ሞዴሌያችንን በብዙ ፈተና የQE ዳታ setet ላይ እናሳድጋለን፤ ከዚያም በኋላ ሞዴላውን በሰው የዳታ ማህበረሰብ እናስጠጋለን፡፡ When evaluated on the WMT 2020 English-German QE test set, our systems achieve the best result on the target-side of word-level QE and the second best results on the source-side of word-level QE and sentence-level QE among all submissions.', 'hy': 'Այս թղթի մեջ մենք նկարագրում ենք Բերինգ լաբորատորիայի ներկայացումը ՈւՄԹ 2020-ի որակի գնահատման ընդհանուր խնդիրը: Բառի և նախադասության մակարդակի թարգմանման որակի գնահատման համար մենք բարձրացնում ենք XLM-ROBERta-ը, ամենաբարձր լեզվի միջև լեզվի մոդելը, մի քանի պարամետրերով: Մոդելի ուսումնասիրությունը կազմված է երկու փուլում: Սկզբում մենք նախապատրաստում ենք մեր մոդելը հսկայական արվեստի ստեղծված QE տվյալների համակարգի վրա, և հետո մենք կազմակերպում ենք մոդելը մարդկային նշաններով: Երբ ԱՄԹ 2020-ի անգլերեն-գերմանացի QE թեստերի համակարգի արդյունքը գնահատվում է, մեր համակարգերը հասնում են ամենալավ արդյունքը բառի մակարդակի QE նպատակային կողմում և երկրորդ լավագույն արդյունքները բառի մակարդակի QE և նախադասության մակարդակի QE բոլոր ներ', 'az': "Bu kağızda, Bering Lab'ın WMT 2020'nin paylaşılmış Cənnət Gözəltməsi (QE) barəsində təsdiqlənməsini tarif edirik. Söz səviyyəsi və cümlələr-səviyyəsi tərcümə qiyməti üçün XLM-RoBERTa, sanatın çox dil modelini, bir neçə əlavə parametru ilə müəyyən edirik. Model təhsil iki fəzi var. Biz ilk dəfə modeliyimizi böyük bir sanatlı QE veri seti ilə təhsil edirik, sonra modeli insan etiketli veri seti ilə təhsil edirik. WMT 2020-ci İngiliz-Alman QE test seti ilə değerləşdikdə, sistemlərimiz söz-seviyyətinin QE-nin ən yaxşı sonuçlarını və söz-seviyyətinin QE-nin və söz-seviyyətinin QE-nin ikinci ən yaxşı sonuçlarını bütün göndərmələri arasında ən yaxşı sonuçlarına nail olur.", 'sq': 'Në këtë letër, ne e përshkruajmë paraqitjen e Bering Lab në WMT 2020 Task Shared on Quality Estimation (QE). Për vlerësimin e cilësisë së përkthimit në nivel fjalësh dhe fjalësh, ne rregullojmë XLM-RoBERTa, modelin e gjuhës me disa parametra shtesë. Trenimi i modelit përbëhet nga dy faza. Ne së pari paratrajnojmë modelin tonë në një set të madh të dhënash QE të gjeneruar artificialisht, dhe pastaj e rregullojmë modelin me një set të dhënash me etiketë njerëzore. Kur vlerësohen në grupin e testit QE anglo-gjerman WMT 2020, sistemet tona arrijnë rezultatin më të mirë në anën e objektivit të nivelit të fjalës QE dhe rezultatet e dyta më të mira në anën e burimit të nivelit të fjalës QE dhe nivelit të fjalës QE midis të gjitha paraqitjeve.', 'bn': "In this paper, we describe the Bering Lab's submission to the WMT 2020 Shared Task on Quality Estimation (QE).  শব্দ-স্তর এবং বাক্য-স্তরের অনুবাদের মান হিসেবে আমরা ভালোভাবে এক্সএলM-রোবের্তা, রাষ্ট্র-শিল্পের ক্রস-ভাষার মডেল, আরো কয়েকটি প্যারামেটা মোডেল প্রশিক্ষণ দুই প্যাসের মধ্যে রয়েছে। আমরা প্রথমে আমাদের মডেলটি প্রশিক্ষণ করি বিশাল কৌশলে কিউই ডাটাসেট তৈরি করেছিলাম, তারপর আমরা মানুষের লেবেলেড ডাটাসেটের সাথে মডেলে WMT ২০২০ ইংরেজী জার্মান কিউই পরীক্ষার সেটে মূল্য প্রদান করা হলে আমাদের সিস্টেম শব্দ-স্তর কিউই-এর লক্ষ্যবস্তুতে সবচেয়ে ভাল ফলাফল পেতে পারে এবং কিউই-এর উৎসের দ্বিতী", 'bs': 'U ovom papiru opisujemo podatke Bering Lab-a podijeljenom zadatku WMT 2020 o procjeni kvalitete (QE). Za procjenu kvalitete prevoda na nivou riječi i rečenice, dobro određujemo XLM-RoBERTa, model umjetnosti kroz jezik, sa nekoliko dodatnih parametara. Modelna obuka se sastoji od dvije faze. Prvo smo trenirali naš model na ogromnom umjetnički proizvedenom setu podataka QE-a, a zatim ćemo srediti model sa ljudskim označenim setom podataka. Kada su procijenjeni na setu testa na engleskom i njemačkom QE-u WMT 2020, naši sistemi postigli najbolji rezultat na ciljnoj strani QE-a riječi i drugim najboljim rezultatima na izvornoj strani QE-a i rečenice-nivoa QE među svim podacima.', 'cs': 'V tomto článku popisujeme podání Beringovy laboratoře na WMT 2020 Shared Task on Quality Estimation (QE). Pro odhad kvality překladu na úrovni slova a věty jemně ladíme XLM-RoBERTa, nejmodernější model cross-jazykového jazyka, s několika dalšími parametry. Model tréninku se skládá ze dvou fází. Nejprve předškolíme náš model na obrovské uměle generované QE datové sadě a pak jej doladíme s datovou sadou označenými lidmi. Při hodnocení na testovací sadě WMT 2020 anglicko-německé QE dosahují naše systémy nejlepšího výsledku na cílové straně QE na úrovni slova a druhého nejlepšího výsledku na zdrojové straně QE na úrovni slova a QE na úrovni věty mezi všemi příspěvky.', 'et': 'Käesolevas dokumendis kirjeldame Beringi labori esitamist WMT 2020 kvaliteedi hindamise jagatud ülesandele (QE). Sõna- ja lausetasemelise tõlkekvaliteedi hindamiseks täpsustame kaasaegset keeleülest keelemudelit XLM-RoBERTa koos mõne lisaparameetriga. Mudelkoolitus koosneb kahest etapist. Kõigepealt treenime oma mudeli suure kunstlikult genereeritud QE andmekogumi põhjal ja seejärel häälestame mudeli inimmärgistatud andmekogumiga. Kui hinnatakse WMT 2020 inglise-saksa kvaliteedi kvaliteedi testikomplekti, saavutavad meie süsteemid kõigi esitatud tulemuste hulgas parima tulemuse sõnataseme kvaliteedi sihtpoolel ja teise parima tulemuse sõnataseme kvaliteedi lähtepoolel ja lausetaseme kvaliteedi lähtepoolel.', 'fi': 'Tässä artikkelissa kuvailemme Bering Labin osallistumista WMT 2020:n laatuarviointiin (QE). Sana- ja lausetason käännösten laadun arviointia varten hienosäädämme XLM-RoBERTa-mallia, joka on huipputekninen monikielinen kielimalli, muutamalla lisäparametrilla. Mallikoulutus koostuu kahdesta vaiheesta. Ensin esikoulutamme mallimme valtavaan keinotekoisesti luotuun QE-aineistoon, ja sitten hienosäädämme mallia ihmisen merkitsemällä aineistolla. WMT 2020:n englannin-saksan QE-testissä järjestelmämme saavuttavat parhaan tuloksen sanatason QE:n tavoitepuolella ja toiseksi parhaan tuloksen sanatason QE:n lähdepuolella ja lausetason QE:n lähdepuolella.', 'ca': "En aquest article, descrivim la presentació del Bering Lab a la Task Shared on Quality Estimation (QE) del WMT 2020. Per estimar la qualitat de la traducció en nivell de paraules i frases, ajuntem XLM-RoBERTa, el model de llenguatge transversal més avançat, amb alguns paràmetres adicionals. L'entrenament model consisteix en dues fases. Primer pré-entrenem el nostre model en un gran conjunt de dades QE generat artificialment, i després fine-tunem el model amb un conjunt de dades etiquetat com a humà. Quan es valora en el conjunt d'exàmens QE anglès-alemanès de WMT 2020, els nostres sistemes aconsegueixen el millor resultat a la banda d'objectiu del nivell de paraula QE i el segon millor resultat a la banda d'origen del nivell de paraula QE i el nivell de frases QE entre totes les presentacions.", 'jv': "Nang pepulan iki, kita nguasai nggawe Bering Lab sampeyan kanggo ngilanggar nggawe Tarjamahan 'WT 2020' kanggo Kealitas Ukusampeyan (XE). Tulung langgambar lan nggambar-langgambar Kemerdekaan kalite, kita lagi nggambar XLM-RBERT, model-langgambar banter structural navigation Awak dhéwé mulai-tolakake sing perusahaan model sing ditambah akeh barang kelas ditambah Awak dhéwé éntuk sing beraksi barêng-barêng sing ngenggukahaan Wêt 2020 Gras-German", 'ha': "In this paper, we describe the Bering Lab's submission to the WMT 2020 Shared Task on Quality Estimation (QE).  @ info: whatsthis Tayyar da Model na ƙunsa da fasa biyu. Kayyar da farko, za'a tunkuɗe misalinmu a kan wani tsari mai girma wanda ya halicci QEK, kuma sa'an nan kuma za mu yi amfani da misalin da wani tsarin da aka rubũta shi ga mutum. Idan an ƙaddara a kan jarrabar WMT 2020-Ingiriya-Jarman QEki, na'urayinmu za'a sãmu mafi kyaun matsayi a kan hagun-side-maganar QEyi da kuma da matsalan biyu masu kyãwo a kanan-side QU da matsayin-daraja na QU.", 'sk': 'V tem prispevku opisujemo predložitev Bering Lab v skupno nalogo WMT 2020 o oceni kakovosti (QE). Za ocenjevanje kakovosti prevodov na ravni besed in stavkov natančno nastavimo XLM-RoBERTa, najsodobnejši medjezični jezikovni model, z nekaj dodatnimi parametri. Modelno usposabljanje je sestavljeno iz dveh faz. Najprej predtreniramo naš model na ogromnem umetno ustvarjenem naboru podatkov QE, nato pa ga natančno nastavimo z naborom podatkov, označenim s človekom. Pri ocenjevanju na angleško-nemškem naboru testiranja QE WMT 2020 naši sistemi dosegajo najboljše rezultate na ciljni strani QE na ravni besede in druge najboljše rezultate na izvorni strani QE na ravni besede in QE stavka med vsemi predloženimi prispevki.', 'he': 'בעיתון הזה, אנחנו מתארים את ההעברה של מעבדת ברינג למשימה משותפת WMT 2020 על הערכת איכות (QE). עבור הערכת איכות תרגום רמת מילים ורמת משפטים, אנו מתאימים את XLM-RoBERTa, המודל השפה הצלבית של המדינה, עם כמה פרמטרים נוספים. אימון מודל מורכב משני שלבים. אנחנו קודם מאמן את המודל שלנו על קבוצת מידע QE ענקית יוצרת באופן מלאכותי, ואז אנחנו מתאימים את המודל עם קבוצת מידע עם תווים אנושיים. כשהערכנו על קבוצת מבחן QE אנגלי-גרמנית WMT 2020, המערכות שלנו משיגות את התוצאה הטובה ביותר בצד המטרה של רמת המילים QE והתוצאות הטובות השנייה בצד המקור של רמת המילים QE ורמת המשפטים QE בין כל ההעברות.', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་བྱིན་པོའི་ལྟ་བུའི་འཇུག་སྣོད་ཀྱི་མཉམ་དུ་མཉམ་སྤྱོད་ཀྱི་བྱ་རིམ(QE)ལ་སྒྲིག For word-level and sentence-level translation quality estimation, we fine-tune XLM-RoBERTa, the state-of-the-art cross-lingual language model, with a few additional parameters. རྣམ་གྲངས་གྱི་སྒྲིག་འགོད་མིག་དུས་མཚམས་གཉིས་ཡོད། We first pre-train our model on a huge artificially generated QE dataset, and then we fine-tune the model with a human-labeled dataset. WMT 2020-Germanic QE བརྟག་ཞིབ་ཀྱི་ཚད་གཞི་ལྟ་བུ་བཏོན་ཡོད་པ་ལས་ ང་ཚོའི་མ་ལག་གིས་ཚིག་གི་དམིགས་ཡུལ་ཕྱོགས་ཀྱི་གནད་སྡུད་ཟུར་བ་རྗེས་ཟུར་གསུམ་དང་གནད་སྡུད་གཉི'}
{'en': 'IST-Unbabel Participation in the WMT20 Quality Estimation Shared Task', 'ar': 'مشاركة IST-Unbabel في المهمة المشتركة لتقدير الجودة WMT20', 'pt': 'Participação do IST-Unbabel na Tarefa Partilhada de Estimativa de Qualidade WMT20', 'es': 'Participación de IST-Unbabel en la tarea compartida de estimación de calidad WMT20', 'fr': "Participation d'IST-Unbabel à la tâche partagée d'estimation de la qualité WMT20", 'ja': 'WMT 20品質推定共有タスクへのIST - Unbabelの参加', 'zh': 'IST-Unbabel 与 WMT20 质评共事', 'ru': 'Участие IST-Unbabel в совместной задаче оценки качества WMT20', 'hi': 'WMT20 गुणवत्ता अनुमान साझा कार्य में IST-अनबेबल सहभागिता', 'ga': 'Rannpháirtíocht IST-Unbabel i dTasc Comhroinnte um Mheastachán Cáilíochta WMT20', 'el': 'IST-Unbabel Συμμετοχή στην Κοινή Εργασία Εκτίμησης Ποιότητας WMT20', 'hu': 'IST-Unbabel Részvétel a WMT20 minőségbecslési megosztott feladatában', 'ka': 'IST- Unbabel მოწყობილობა WMT20 კვალეტის განსაზღვრებული დავალებაში', 'it': 'IST-Unbabel Partecipazione al compito condiviso di stima della qualità WMT20', 'kk': 'IST- Unbabel WMT20 сапасы оқиға ортақ тапсырманың қатынасы', 'lt': 'IST-Unbabel dalyvavimas WMT20 kokybės vertinimo bendroje užduotyje', 'mk': 'Учеството на IST-Унбабел во заедничката задача за проценка на квалитетот на WMT20', 'ms': 'Bahagian IST-Unbabel dalam Tugas Berkongsi Penghargaan Kualiti WMT20', 'ml': 'WMT20 ഗുണത്തിന്റെ എസ്റ്റിമേഷന്\u200d പങ്കുചേര്\u200dത്ത ജോലിയില്\u200d IST- Unbabel പങ്കുചേര്\u200dക്കുന്നത്', 'mt': 'IST-Unbabel Participation in the WMT20 Quality Estimation Shared Task', 'mn': 'IST-Unbabel WMT20 Quality Estimation Shared Task-д оролцоо', 'no': 'IST- Unbabel- deltakar i WMT20- kvalitetevaluering delt oppgåve', 'pl': 'IST-Unbabel Udział w wspólnym zadaniu oceny jakości WMT20', 'ro': 'IST-Unbabel Participarea la activitatea partajată de estimare a calității WMT20', 'sr': 'IST-Unbabel sudjelovanje u procjeni kvalitete WMT20 zajedničkog zadatka', 'si': 'IST-Unbabel භාගයක් WMT20 කුළුවත් අවශ්\u200dය අවශ්\u200dයාවක් සමාගත වැඩක් තියෙන්න', 'so': 'IST-Unbabel ka qayb-qaadashada WMT20 Quality Estimation Shared Shaqada', 'sv': 'IST-Unbabel Deltagande i den delade uppgiften WMT20-kvalitetsbedömning', 'ta': 'WMT20 தரமான கணக்கீட்டு பகிர்ந்த பணியில் IST- Unbabel பகிர்ந்தல்', 'ur': 'IST-Unbabel Participation in the WMT20 Quality Estimation Shared Task', 'uz': 'Name', 'vi': 'Trình dự trữ chất lượng cho người dùng Comment', 'bg': 'Участие на IST-Unbabel в споделената задача за оценка на качеството на WMT20', 'hr': 'IST-Unbabel učestvovanje u procjeni kvalitete WMT20 zajedničkog zadatka', 'nl': 'IST-Unbabel Deelname aan de WMT20 Kwaliteitsschatting Gedeelde Task', 'da': 'IST-Unbabel Deltagelse i WMT20 Kvalitetsestimering delt opgave', 'fa': 'شرکت IST-Unbabel در ارزیابی مشترک کیفیت WMT20', 'ko': 'WMT20 Quality Assessment 공유 작업에 IST 태그 해제', 'id': 'IST-Unbabel Participation in the WMT20 Quality Estimation Shared Task', 'de': 'IST-Unbabel Teilnahme an der WMT20 Qualitätsschätzung Shared Task', 'tr': 'WMT20 Quality Taýýarlama Mazmunlary Oýun Gaýşartmak', 'af': 'Ist- Unbabel Deelnadering in die WMT20 Kwaliteit Estimasie Gedeelde Opdrag', 'sw': 'Ushiriki wa IST-Unbabel katika Uwango wa WMT20 ulishiriki kazi', 'sq': 'Pjesëmarrja IST-Unbabel në detyrën e përbashkët të vlerësimit të cilësisë WMT20', 'am': 'IST-Unbabel ተካባቢ በWMT20 ጥሩ ማስታወሻ የተሳካ ስራ', 'az': 'IST-Unbabel WMT20 kaliteli GĂ¶rĂ¼ntĂ¼lmÉ™ BĂ¶lĂ¼ÅŸĂ¼ GĂ¶rĂ¼ntĂ¼lmÉ™si', 'hy': 'Իստ-Ունբաբելի մասնակցությունը ԱՄԹ20 որակի գնահատման ընդհանուր խնդրում', 'bn': 'ডাব্লিউএমটি২০ সংক্রান্ত পরিমাণে IST-আনবেল অংশগ্রহণকারী', 'ca': 'IST-Unbabel Participation in the WMT20 Quality Estimation Shared Task', 'bs': 'IST-Unbabel učestvovanje u procjeni kvalitete WMT20 zajedničkog zadatka', 'et': 'IST-Unbabeli osalemine WMT20 kvaliteedihindamise ühises ülesandes', 'cs': 'IST-Unbabel Účast na odhadu kvality WMT20 Shared Task', 'fi': 'IST-Unbabel Osallistuminen WMT20-laatuarviointiin jaettuun tehtävään', 'he': 'IST-Unbabel Participation in the WMT20 Quality Estimation Shared Task', 'ha': 'Page size', 'sk': 'Udeležba IST-Unbabel v skupni nalogi ocene kakovosti WMT20', 'jv': 'partition', 'bo': 'IST-Unbabel Participation in the WMT20 Quality Estimation Shared Task'}
{'en': 'We present the joint contribution of IST and Unbabel to the WMT 2020 Shared Task on Quality Estimation. Our team participated on all tracks (Direct Assessment, Post-Editing Effort, Document-Level), encompassing a total of 14 submissions. Our submitted systems were developed by extending the OpenKiwi framework to a transformer-based predictor-estimator architecture, and to cope with glass-box, uncertainty-based features coming from neural machine translation systems.', 'fr': "Nous présentons la contribution conjointe d'IST et d'Unbabel à la tâche partagée WMT 2020 sur l'estimation de la qualité. Notre équipe a participé à toutes les pistes (évaluation directe, effort de post-édition, niveau document), englobant un total de 14 soumissions. Les systèmes que nous avons soumis ont été développés en étendant le framework OpenKiwi à une architecture de prédicteur-estimateur basée sur un transformateur, et pour faire face aux fonctionnalités basées sur l'incertitude issues de systèmes de traduction automatique neuronale.", 'ar': 'نقدم مساهمة IST و Unbabel المشتركة في مهمة WMT 2020 المشتركة بشأن تقدير الجودة. شارك فريقنا في جميع المسارات (التقييم المباشر ، جهود ما بعد التحرير ، مستوى المستند) ، بما في ذلك ما مجموعه 14 مشاركة. تم تطوير أنظمتنا المقدمة من خلال توسيع إطار عمل OpenKiwi إلى بنية متنبئ ومقدر قائم على المحولات ، وللتعامل مع الصندوق الزجاجي ، والميزات القائمة على عدم اليقين القادمة من أنظمة الترجمة الآلية العصبية.', 'es': 'Presentamos la contribución conjunta de IST y Unbabel a la Tarea Compartida sobre Estimación de la Calidad del WMT 2020. Nuestro equipo participó en todos los temas (evaluación directa, esfuerzo posterior a la edición, nivel de documento), que abarcaron un total de 14 presentaciones. Nuestros sistemas presentados se desarrollaron ampliando el marco de OpenKiwi a una arquitectura predictor-estimador basada en transformadores, y para hacer frente a las características cristalinas basadas en la incertidumbre que provienen de los sistemas de traducción automática neuronal.', 'pt': 'Apresentamos o contributo conjunto do IST e da Unbabel para o WMT 2020 Shared Task on Quality Estimation. Nossa equipe participou de todas as trilhas (Avaliação Direta, Esforço de Pós-Edição, Nível de Documento), totalizando 14 submissões. Nossos sistemas submetidos foram desenvolvidos estendendo a estrutura OpenKiwi para uma arquitetura de preditor-estimador baseada em transformador e para lidar com recursos baseados em incertezas de caixa de vidro provenientes de sistemas de tradução automática neural.', 'ja': '私たちは、品質推定に関するWMT 2020共有タスクへのISTとUnbabelの共同貢献を提示します。私たちのチームは、合計14件の提出物を含むすべてのトラック（直接評価、編集後の取り組み、文書レベル）に参加しました。当社の提出したシステムは、OpenKiwiフレームワークを変圧器ベースの予測-推定アーキテクチャに拡張し、ニューラル機械翻訳システムから来るガラス箱、不確実性ベースの機能に対応するために開発されました。', 'zh': '吾言IST与UnbabelWMT 2020质评共同任务者同功。 臣等团队参诸项目(直评估、译后辑事、文档级),共提 14 分。 吾道者,所以广OpenKiwi框架于变压器之预测器度器架构而发也,所以应神经机器翻译统之基于不确定性玻璃盒也。', 'hi': 'हम गुणवत्ता आकलन पर डब्ल्यूएमटी 2020 साझा कार्य में आईएसटी और अनबाबेल का संयुक्त योगदान प्रस्तुत करते हैं। हमारी टीम ने सभी पटरियों (प्रत्यक्ष मूल्यांकन, पोस्ट-एडिटिंग प्रयास, दस्तावेज़-स्तर) पर भाग लिया, जिसमें कुल 14 प्रस्तुतियां शामिल थीं। हमारे प्रस्तुत प्रणालियों को एक ट्रांसफॉर्मर-आधारित भविष्यवक्ता-अनुमानक वास्तुकला के लिए OpenKiwi ढांचे का विस्तार करके विकसित किया गया था, और ग्लास-बॉक्स, तंत्रिका मशीन अनुवाद प्रणालियों से आने वाली अनिश्चितता-आधारित सुविधाओं का सामना करने के लिए।', 'ru': 'Мы представляем совместный вклад IST и Unbabel в совместную задачу WMT 2020 по оценке качества. Наша команда участвовала во всех направлениях (прямая оценка, усилия после редактирования, уровень документов), охватывая в общей сложности 14 представлений. Наши представленные системы были разработаны путем расширения фреймворка OpenKiwi до архитектуры предиктора-оценщика на основе трансформатора, а также для того, чтобы справиться со стеклянными коробками, функциями на основе неопределенности, поступающими от нейронных систем машинного перевода.', 'ga': 'Cuirimid i láthair rannpháirtíocht IST agus Unbabel le Tasc Comhroinnte WMT 2020 ar Mheastachán Cáilíochta. Ghlac ár bhfoireann páirt ar gach traic (Measúnú Díreach, Iarracht Iar-Eagarthóireachta, Leibhéal Doiciméad), a chuimsigh 14 aighneacht san iomlán. Forbraíodh ár gcórais a cuireadh isteach trí chreat OpenKiwi a leathnú chuig ailtireacht meastacháin-mheastacháin atá bunaithe ar chlaochladán, agus chun dul i ngleic le gnéithe bosca gloine, atá bunaithe ar éiginnteacht a thagann ó chórais néar-aistriúcháin meaisín.', 'hu': 'Bemutatjuk az IST és az Unbabel közös hozzájárulását a WMT 2020 közös minőségbecslési feladatához. Csapatunk minden pályán (Direct Assessment, Post-Editing Efort, Document-Level) vett részt, összesen 14 beadványban. Bejelentett rendszereinket úgy fejlesztettük ki, hogy az OpenKiwi keretrendszert egy transzformátor alapú prediktor-becslő architektúrára kiterjesztettük, és hogy megbirkózzanak a neurális gépi fordító rendszerekből származó üvegdoboz, bizonytalanság alapú tulajdonságokkal.', 'ka': 'ჩვენ გავაჩვენოთ IST და Unbabel-ის ერთადერთი დამატება WMT 2020-ის საზოგადომი დავალების განსაზღვრებისთვის. ჩვენი ჯგუფი ყველა მონაცემებში (Direkt Assessment, Post-Editing Effort, Document-Level) დაწყებულია 14 მონაცემები. ჩვენი გაგზავნილი სისტემები განვითარებულია, რომელიც OpenKiwi ფრამეტრის გაფარგებით ტრანფორმეტრის დაფარგებული პროგრამეტრის აქტიქტურაციაში, და გავაკეთოთ ფაქტობის კონფიგურაცია, დაფარგებული', 'el': 'Παρουσιάζουμε την κοινή συνεισφορά της IST και της Unbabel στην κοινή εργασία WMT 2020 για την εκτίμηση της ποιότητας. Η ομάδα μας συμμετείχε σε όλα τα κομμάτια (Άμεση Αξιολόγηση, Προσπάθεια Μετασύνταξης, Επίπεδο Έγγραφου), που περιελάμβαναν συνολικά δεκατέσσερις υποβολές. Τα υποβαλλόμενα συστήματά μας αναπτύχθηκαν επεκτείνοντας το πλαίσιο OpenKiwi σε μια αρχιτεκτονική προγνωστών-εκτιμητών με βάση τον μετασχηματιστή, και για να αντιμετωπίσουμε τα χαρακτηριστικά που βασίζονται στην αβεβαιότητα που προέρχονται από νευρωνικά συστήματα μηχανικής μετάφρασης.', 'it': "Presentiamo il contributo congiunto di IST e Unbabel al compito condiviso WMT 2020 sulla stima della qualità. Il nostro team ha partecipato a tutti i brani (valutazione diretta, sforzo post-editing, livello di documento), comprendendo un totale di 14 contributi. I nostri sistemi presentati sono stati sviluppati estendendo il framework OpenKiwi a un'architettura predittore-estimatore basata su trasformatori e per far fronte a caratteristiche glass-box basate sull'incertezza provenienti dai sistemi di traduzione automatica neurale.", 'kk': 'Біз IST және Unbabel бағдарламасының WMT 2020 сапалық оқиғаларының ортақ тапсырмасын біріктіреміз. Біздің командамыз барлық жолдарда қатысу үшін (Direkt Assessment, Post Editing Effort, Document- Level), 14 жіберілген жіберіліктер бар. Біздің келтірілген жүйелеріміз OpenKiwi бағдарламасын түрлендіруші бағдарлама архитектурасына кеңейту арқылы жасалған және невралдық компьютердің аудару жүйелерінен келтірілген қасиеттерді жасауға арналған.', 'lt': 'Mes pristatome bendrą IST ir Unbabelio indėlį į bendrą WMT 2020 m. kokybės vertinimo užduotį. Mūsų komanda dalyvavo visuose keliuose (tiesioginis vertinimas, pastangos po redakcijos, dokumentų lygis), kuriuose iš viso buvo 14 paraiškų. Mūsų pateiktos sistemos buvo sukurtos išplečiant OpenKiwi sistemą iki transformatoriumi pagrįstos prognozatorių apskaičiavimo architektūros ir sprendžiant stiklo dėžutės, neapibrėžties pagrindu pagrįstus požymius, gautus iš nervinių mašinų vertimo sistemų.', 'mk': 'Го претставуваме заедничкиот придонес на ИСТ и Унбабел за заедничката задача на ВМТ 2020 за проценка на квалитетот. Нашиот тим учествуваше на сите траги (директна проценка, напори по уредување, ниво на документи), вклучувајќи вкупно 14 поднесувања. Нашите поднесени системи беа развиени со проширување на рамките на OpenKiwi на архитектура на предвидувачи-проценки базирана на трансформатори и за справување со стаклените кутии, карактеристики базирани на несигурност кои доаѓаат од нервните машински преведувачки системи.', 'ms': 'Kami memperkenalkan kontribusi bersama IST dan Unbabel kepada Tugas Berkongsi WMT 2020 tentang Penghargaan Kualiti. Pasukan kami berpartisipasi dalam semua trek (Pemeriksaan Langsung, Effort Setelah Editan, Aras Dokumen), meliputi total 14 penghantaran. Our submitted systems were developed by extending the OpenKiwi framework to a transformer-based predictor-estimator architecture, and to cope with glass-box, uncertainty-based features coming from neural machine translation systems.', 'ml': 'നമ്മള്\u200d ഐസിറ്റിന്റെയും ഉന്ബാബേലിന്റെയും കൂട്ടിചേര്\u200dത്ത പങ്ക് എസ്റ്റിമേഷന്\u200dറെയും വ്യുഎംടി 2020 പങ്കുചേ ഞങ്ങളുടെ ടീം എല്ലാ ട്രാക്കുകളിലും പങ്കുചേര്\u200dന്നു (നേരിട്ട് വിശ്വാസം, പിന്നീട് ചിട്ടപ്പെടുത്തുന്ന പരിശ്രമം, രേഖ- നില)  ഞങ്ങളുടെ സമ്മതിച്ച സിസ്റ്റത്തിന്റെ സംവിധാനങ്ങള്\u200d ഓപ്പെന്\u200dകിവി ഫ്രെയിമ്പുകള്\u200d മാറ്റുന്നതിന്റെ അടിസ്ഥാനത്തുള്ള പ്രവചനങ്ങള്\u200dക്ക് വികസിപ്പിക്കുന്നതിന', 'mt': 'Aħna nippreżentaw il-kontribut konġunt tal-IST u l-Unbabel għall-Ħidma Konġunta tal-WMT 2020 dwar l-Istima tal-Kwalità. It-tim tagħna pparteċipa fil-binarji kollha (Valutazzjoni Diretta, Sforz ta’ wara l-Edizzjoni, Livell ta’ Dokument), li jinkludu total ta’ 14-il sottomissjoni. Our submitted systems were developed by extending the OpenKiwi framework to a transformer-based predictor-estimator architecture, and to cope with glass-box, uncertainty-based features coming from neural machine translation systems.', 'mn': 'Бид IST болон Unbabel-ын хамтран нийлүүлэлтийг WMT 2020-ийн хуваалтын ажилд гаргаж байна. Бидний баг бүх загварууд дээр оролцсон (шууд оценка, цахим загвар, документ-түвшин), 14 дахь нийтлэг нийтлэг хүмүүсийг хамтдаа. Бидний тайлбарласан системүүд OpenKiwi-г өөрчлөгчийн төлөөлөгчийн багш барилга руу нэмэгдүүлж, шилэн хайрцаг, мэдрэлийн машины орчуулах системээс гарч ирсэн тодорхойгүй байдлаар хөгжүүлсэн.', 'no': 'Vi presenterer den samanlige bidraga av IST og Unbabel til delt oppgåve WMT 2020 om kvalitetestimaet. Gruppet vårt delta på alle spor (direkte vurdering, post- redigeringseffort, dokumentnivå), med totalt 14 tillegg. Våre tildelte systemet ble utvikla ved å utvide OpenKiwi-rammeverket til ein transformeringsbasert predictor-estimator-arkitektur, og for å kopla med glass-boks, usikkerhetsbaserte funksjonar som kommer frå neuralmaskinsomsetjingssystemer.', 'ro': 'Vă prezentăm contribuția comună a IST și Unbabel la misiunea partajată WMT 2020 privind estimarea calității. Echipa noastră a participat la toate piesele (Evaluare directă, Efort post-editare, Document-Level), cuprinzând un total de 14 depuneri. Sistemele noastre prezentate au fost dezvoltate prin extinderea cadrului OpenKiwi la o arhitectură predictor-estimatoare bazată pe transformator și pentru a face față caracteristicilor de sticlă, bazate pe incertitudine provenind din sistemele neuronale de traducere automată.', 'pl': 'Przedstawiamy wspólny wkład IST i Unbabel we wspólne zadanie WMT 2020 w zakresie oceny jakości. Nasz zespół uczestniczył we wszystkich ścieżkach (bezpośrednia ocena, wysiłek post-edycyjny, poziom dokumentów), obejmujących łącznie czternaście zgłoszeń. Nasze przesłane systemy zostały opracowane przez rozszerzenie frameworku OpenKiwi o architekturę predykcyjno-estymatora opartą na transformatorach oraz w celu radzenia sobie z funkcjami opartymi na szklanej skrzynce opartymi na niepewności pochodzącymi z neuronowych systemów tłumaczenia maszynowego.', 'si': 'අපි IST සහ අන්බාබෙල්ගේ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ වැ අපේ කණ්ඩායම හැම ප්\u200dරකාරයක්ම සම්බන්ධ වෙලා තියෙන්නේ (ප්\u200dරතිකාරණ අවශ්\u200dය, පස්ස සංපාදනය සම්බන්ධය, විස්තාරණ ප අපේ පිළිබඳු පද්ධතියක් විස්තර කරලා OpenKiwi වේ පද්ධතිය විස්තර කරලා තියෙන්නේ නිර්මාණකය සඳහා පද්ධතියක් විස්තර කරනවා, ග්\u200dලාස් බොක්ස් එක', 'sr': 'Predstavljamo zajednički doprinos IST-a i Unbabela na zajednički zadatak WMT 2020 o procjeni kvalitete. Naš tim je sudjelovao na svim tragovima (direktna procjena, posturedna snaga, nivo dokumenta), uključujući ukupno 14 podataka. Naši podnošeni sistemi su razvili proširenjem okvira OpenKiwija na arhitekturu predviđa ča na transformaciji, i da se suočimo sa staklenim kutijama, neodređenim karakteristikama koji dolaze iz sustava prevoda neuronskih mašina.', 'sv': 'Vi presenterar IST och Unbabels gemensamma bidrag till WMT 2020 Shared Task on Quality Estimation. Vårt team deltog i alla spår (direkt bedömning, efterredigering ansträngning, dokumentnivå) och omfattade totalt 14 inlämningar. Våra inlämnade system utvecklades genom att utvidga OpenKiwi-ramverket till en transformatorbaserad prediktor-estimator arkitektur, och för att klara glaslåda, osäkerhetsbaserade funktioner som kommer från neurala maskinöversättningssystem.', 'so': 'Waxaannu wadajirka ah ku qeybqaadashada IST iyo Unbaal ee WMT 2020 ee loo sharciyey shaqo qiimaanshaha. Timaheenu waxay ka qeybqaadatay dhammaan wadooyin (Direct Assessment, Post-Editing Effekt, Document-Level), kaas oo kooban 14 submissions. nidaamka la soo dhiibay ayaa la hormariyey, waxaana ku fidinayaa firaaqada OpenKiwi oo loo bedelay dhismaha beddelinta oo lagu beddelayo wax lagu beddelayo, iyo in lagu koobi karo tijaabada baabuurta ah oo aan la garanayn nidaamka turjumidda neurada.', 'ta': 'நாம் IST மற்றும் Unbabel யுஎம்ட் 2020 பங்கிடப்பட்ட பணியை தரம் கணக்கீட்டில் பகிர்ந்த பணி எங்கள் குழு எல்லா தடங்களிலும் பங்கிடப்பட்டது (நேரடி பரிசோதனை, தொகுப்பு பின் முயற்சி, ஆவண- மட்டத்தில், மொத்தமான 14 ஒப்புக்களை சுற்ற எங்கள் வழங்கப்பட்ட அமைப்புகள் ஓபன்கிவி சட்டத்தை மாற்றும் அடிப்படையில் மாற்றும் முறைமுறையாக்கி மதிப்பீட்டாளர் அமைப்புகளுக்கு உருவாக்கி மற்றும் கணினி', 'ur': 'ہم IST اور Unbabel کے ساتھ ملے ہوئے مسائل کو WMT 2020 میں مشترک کام کے ذریعے پیش کرتے ہیں۔ ہماری تیم تمام ٹریکیوں میں شریک ہوئی (مستقیم Assessment, Post-Editing Effort, Document-Level), 14 submissions کی جمع جمع ہوئی۔ ہمارے تحویل دیے ہوئے سیستموں کو اپنا کیوی فرمیک کو تغییر دینے کے ذریعہ تغییر دینے والی پیش بینی کرنے والی معماری تک پہنچا دیا گیا تھا اور گلاس باکس کے ساتھ جواب دینے والی غیر یقین کی بنیاد رکھی ہوئی ویٹیوں کو نیورل ماشین', 'uz': "@ info Bizning guruhimiz hamma yo'nalar bilan bogʻliq edi (Direct Assessment, Post- Editing Effekt, Document- Level), butun 14 submit yordamchiga qaraydi. Bizning joʻnatilgan tizimmiz OpenKiwi freymini o'zgartirish-estimator arxituvchiga qo'yish va murakkab qutisi bilan nusxa olish uchun oddiy moslamalar neyural kompyuteri tarjima tizimdan keladigan.", 'vi': 'Chúng tôi xin giới thiệu các đóng góp chung của IST và bất khả thi cho công việc chia sẻ WM 2020 về ước lượng chất lượng. Đội của chúng tôi đã tham gia tất cả các dấu vết (bộ đánh giá trực tiếp, công tác sau sửa đổi, cấp tài liệu), gồm cả một số tài liệu 4. Các hệ thống được gửi đến được phát triển bằng cách mở rộng cơ cấu hình OpenKiwi thành một kiến trúc dự đoán-Bộ đánh giá bộ máy biến đổi, và để đối phó với các tính năng mơ hồ xuất phát từ hệ thống dịch cỗ máy thần kinh.', 'bg': 'Представяме съвместния принос на ИСТ и Унбабел към общата задача за оценка на качеството на ОМТ 2020. Екипът ни участва във всички песни (директна оценка, усилия след редактиране, ниво на документа), включващи общо 14 предложения. Нашите представени системи са разработени чрез разширяване на рамката до трансформаторна архитектура на предсказател-оценител и за справяне със стъклени кутии, базирани на неопределеност функции, идващи от невронните системи за машинен превод.', 'da': 'Vi præsenterer IST og Unbabels fælles bidrag til WMT 2020 Shared Task on Quality Estimation. Vores team deltog på alle spor (direkte vurdering, post-redigering indsats, dokument-niveau), omfattende i alt 14 indsendelser. Vores indsendte systemer blev udviklet ved at udvide OpenKiwi framework til en transformer-baseret predictor-estimator arkitektur, og for at håndtere glaskasse, usikkerhedsbaserede funktioner, der kommer fra neurale maskinoversættelsessystemer.', 'nl': 'We presenteren de gezamenlijke bijdrage van IST en Unbabel aan de WMT 2020 Shared Task on Quality Estimation. Ons team nam deel aan alle tracks (Direct Assessment, Post-Editing Effort, Document Level), inclusief een totaal van veertien inzendingen. Onze ingediende systemen zijn ontwikkeld door het OpenKiwi framework uit te breiden naar een transformatorgebaseerde predictor-estimator architectuur, en om te kunnen omgaan met glasbox, onzekerheidsgebaseerde kenmerken afkomstig van neurale machine translation systemen.', 'hr': 'Predstavljamo zajednički doprinos IST-a i Unbabela na zajednički zadatak WMT 2020 o procjeni kvalitete. Naš tim je sudjelovao na svim tragovima (Direktna procjena, posturedna snaga, razina dokumenta), uključujući ukupno 14 podataka. Naši podnošeni sustavi su razvijeni proširenjem okvira OpenKiwija u arhitekturu predviđa ča na transformaciji i suočavanjem sa staklenim kutijama, neodređenim karakteristikama koji dolaze iz sustava prevoda neuronskih strojeva.', 'de': 'Wir stellen den gemeinsamen Beitrag von IST und Unbabel zur WMT 2020 Shared Task on Quality Estimation vor. Unser Team beteiligte sich an allen Tracks (Direct Assessment, Post-Editing Effort, Document Level), die insgesamt 14-mal Einreichungen umfassten. Unsere eingereichten Systeme wurden entwickelt, indem wir das OpenKiwi-Framework auf eine transformatorbasierte Prädiktor-Schätzer-Architektur erweitern und mit Glass-Box, Unsicherheits-basierten Features umgehen, die von neuronalen maschinellen Übersetzungssystemen stammen.', 'id': 'Kami mempersembahkan kontribusi bersama dari IST dan Unbabel untuk WMT 2020 Shared Task on Quality Estimation. Tim kami berpartisipasi di semua jejak (Penghargaan langsung, Efor Setelah Editing, Tingkat Dokumen), meliputi total 14 pengiriman. Our submitted systems were developed by extending the OpenKiwi framework to a transformer-based predictor-estimator architecture, and to cope with glass-box, uncertainty-based features coming from neural machine translation systems.', 'ko': 'WMT 2020 품질 평가 공유 임무에 대한 IST와 Unbabel의 공동 기여를 소개했다.우리 팀은 모든 방면(직접 평가, 후기 편집 업무, 문서 등급)에 참여했고 모두 14개의 의견서를 제출했다.우리가 제출한 시스템은 OpenKiwi 프레임워크를 변압기 기반 예측-추정기 구조로 확장하고 신경기계 번역 시스템에서 나온 유리 케이스를 처리하며 불확실성 특징을 바탕으로 개발되었다.', 'fa': 'ما مشترک مشترک IST و Unbabel را به وظیفه مشترک WMT 2020 در ارزیابی کیفیت پیشنهاد می\u200cکنیم. تیم ما در تمام ردها (ارزیابی مستقیم، تلاش بعد از ویرایش، سطح سند) شرکت می\u200cکردند، در جمله ۱۴ تسلیم شده است. سیستم\u200cهای پیشنهاد ما توسعه داده شده\u200cاند با گسترش چهارچوب OpenKiwi به یک معماری پیش\u200cبینی\u200cکننده بر اساس تغییر دهنده و با جعبه\u200cهای شیشه، ویژگی\u200cهای بنیاد بی\u200cیقین از سیستم\u200cهای ترجمه\u200cهای ماشین عصبی آمده\u200cاند.', 'sw': 'Tunawasilisha mchango wa pamoja wa IST na Unbabel kwenye kazi ya WMT 2020 inayoshirikishwa na Uhisabu. Timu yetu ilishiriki katika njia zote (Utafiti wa moja kwa moja, Jaribio la Kuhariri baada ya Uhariri, kiwango cha dokumentari), ikijumuisha jumla ya ujumbe wa 14. Mfumo wetu uliotolewa uliundwa kwa kuongeza mfumo wa OpenKiwi kwenye ujenzi wa mtabiri wa mabadiliko, na kupambana na sanduku za glasi, tabia isiyo na uhakika zinazotoka kwenye mfumo wa utafsiri wa mashine ya kisasa.', 'tr': "Biz IST we Unbabel'yň WBMT 2020-nji Kwalyk Taýýarlama bilen ylalaşyk işine görkezip berýäris. Biziň topamyz ähli hatlarda (Direkt Assessment, Post-Editing Effort, Sened-Level), 14 sahypalary bar. OpenKiwi çerçewlerini üýtgetmek üçin biziň gönderilen sistemamyz geliştirildi we näuro maşynyň terjime sistemalaryndan gelen a ýratyn guty bilen üýtgetmek üçin.", 'af': "Ons stel die saamste bydraag van IST en Unbabel aan die WMT 2020 deelde taak op Kwaliteit Estimatie. Ons span het gedeel op alle snitte (Direkte Assensie, Post-Editing Effort, Document-Vlak), omsluit 'n totaal van 14 onderskrifte. Ons ingestuurde stelsels is ontwikkel deur die OpenKiwi raamwerk te verleng na 'n transformeerder-gebaseerde voorskouer-estimatoerde arkitektuur, en om te koppel met glasboks, onsekerlik-gebaseerde funksies van neurale masjien vertaling stelsels.", 'sq': 'Ne paraqesim kontributin e përbashkët të IST dhe Unbabel në detyrën e përbashkët të WMT 2020 për vlerësimin e cilësisë. Ekipi ynë mori pjesë në të gjitha gjurmët (vlerësim i drejtpërdrejtë, përpjekje pas redaksionit, Niveli i Dokumenteve), duke përfshirë një total prej 14 paraqitjesh. Sistemet tona të paraqitura u zhvilluan duke zgjeruar kuadrin OpenKiwi në një arkitekturë parashikuese-vlerësuese bazuar në transformues dhe për të përballur me elementet e xhami-kutisë, bazuar në pasiguri që vijnë nga sistemet e përkthimit të makinave nervore.', 'am': 'የIST እና Unbabel ድርጅት በቁጥር ላይ 2020 የተሰራጨውን ስራ ለWMT እናቀርባለን፡፡ የጦማሪያችን አካባቢ 14 ጥያቄዎች በሙሉ አካባቢ፣ የፖስታ ማቀናጃ ፍቃድ፣ ሰነድ-ደረጃዎች፡፡ የOpenKiwi ሥርዓት የፍሬማት ምርጫዎችን ለመዘርጋት እና የግልባር ቦታዎች፣ የናውሬው መሣሪያ ትርጉም ስርዓት ከሆነው የግልፅ ምርጫዎች ለመቀናቀል እና ለመቀላቀል የግልፅ ቦታዎች በመጠቀም ነው፡፡', 'hy': 'We present the joint contribution of IST and Unbabel to the WMT 2020 Shared Task on Quality Estimation.  Մեր թիմը մասնակցել է բոլոր ճանապարհորդություններին (ուղղակի գնահատում, հետխմբագրման ջանքեր, փաստաթղթերի մակարդակ), որոնք ներառում են ընդհանուր 14 ներկայացումներ: Մեր ներկայացված համակարգերը զարգացել են OpenKiWi-ի շրջանակը ընդլայնելով դեպի վերափոխողների հիմնված կանխատեսողների-գնահատողների ճարտարապետություն և հաղթահարելու ապակի արկղի, անորոշության հիմնված հատկությունների հետ, որոնք գալիս են նյարդային մեքե', 'az': "Biz IST və Unbabel'in birləşdirilməsini WMT 2020-nin paylaşılmış Cənnət Tahməsi haqqında təmin edirik. Ekibimiz bütün parçalara (Direkt Assessment, Post Editing Effort, Document-Level) katıldı, bütün 14 tərəflərlə birlikdə. Bizim göndərilmiş sistemlərimiz OpenKiwi framework ünü transformer-based predictor-estimator arhitektarına uzatmaq üçün təşkil edilmişdir. Nəyral maşın çevirim sistemlərindən gələn möhkəmlik qutusu ilə çəkilmək üçün.", 'bn': 'আমরা আইএসটি এবং আনব্যাবেলের যৌথ অংশগ্রহণের সাথে উইএমটি ২০২০ শেয়ার করা কাজ সম্পর্কে উপস্থাপন করছি। Our team participated on all tracks (Direct Assessment, Post-Editing Effort, Document-Level), encompassing a total of 14 submissions.  ওপেনকিউই ফ্রেম বাড়িয়ে দিয়ে আমাদের জমা দেওয়া সিস্টেম উন্নয়ন করা হয়েছে একটি পরিবর্তনের ভিত্তিক ভবিষ্যৎকার-হিসাবের কাঠামোর দিকে আর গ্লাস-বক্সের সাথে সংয', 'bs': 'Predstavljamo zajednički doprinos IST-a i Unbabela na zajednički zadatak WMT 2020 o procjeni kvalitete. Naš tim je sudjelovao na svim tragovima (Direktna procjena, posturedna snaga, nivo dokumenta), uključujući ukupno 14 podataka. Naši podnošeni sustavi su razvijeni proširenjem okvira OpenKiwija u arhitekturu predviđa ča na transformaciji, i da se suočimo sa staklenim kutijama, neodređenim karakteristikama koji dolaze iz sustava prevoda neuronskih strojeva.', 'ca': "Presentam la contribució conjunta de la IST i l'Unbabel a la Task Shared on Quality Estimation del WMT 2020. El nostre equip va participar en totes les pistes (Evaluació Direct a, Post-Editing Effort, Document-Level), amb un total de 14 presentacions. Els nostres sistemes submetits van ser desenvolupats extendient el marc OpenKiwi a una arquitectura de preditors-estimadors basada en transformadors, i per afrontar les característiques basades en una caixa de vidre i incertituds que provienen de sistemes neuromàtics de traducció.", 'cs': 'Představujeme společný příspěvek IST a Unbabel ke sdílenému úkolu WMT 2020 v oblasti odhadu kvality. Náš tým se podílel na všech tratích (přímé hodnocení, post-editing snaha, dokumentová úroveň), zahrnujících celkem čtrnáct příspěvků. Naše předložené systémy byly vyvinuty rozšířením OpenKiwi frameworku na transformátorovou architekturu prediktorů-odhadů a také pro zvládnutí skelných skříní, nejistoty založených na neuronových strojových překladech.', 'et': 'Tutvustame IST ja Unbabeli ühist panust WMT 2020 kvaliteedi hindamise ühisesse ülesandesse. Meie meeskond osales kõigil radadel (otsene hindamine, redigeerimisjärgne jõupingutus, dokumentide tasandil), mis hõlmasid kokku 14 esitust. Meie esitatud süsteemid on välja töötatud OpenKiwi raamistiku laiendamisega trafopõhisele ennustaja-hindaja arhitektuurile ning selleks, et toime tulla klaaskastiga, määramatusel põhinevate funktsioonidega, mis tulenevad neuraalsetest masintõlkesüsteemidest.', 'fi': 'Esittelemme IST:n ja Unbabelin yhteisen panoksen WMT 2020:n laatuarviointiin liittyvään yhteiseen tehtävään. Tiimimme osallistui kaikkiin kappaleisiin (suora arviointi, post-editing effort, dokumenttitaso), joihin kuului yhteensä 14 hakemusta. Toimitetut järjestelmämme kehitettiin laajentamalla OpenKiwi-viitekehystä muuntajapohjaiseen ennuste-estimaattoriarkkitehtuuriin ja selviytymään neurokonekäännösjärjestelmistä tulevista lasilaatikoihin perustuvista epävarmuuteen perustuvista ominaisuuksista.', 'sk': 'Predstavljamo skupni prispevek IST in Unbabel k skupni nalogi WMT 2020 o oceni kakovosti. Naša ekipa je sodelovala na vseh skladbah (neposredna ocena, prizadevanja po urejanju, raven dokumenta), ki so zajemale skupaj 14 prispevkov. Naši predloženi sistemi so bili razviti z razširitvijo okvira OpenKiwi na transformatorsko arhitekturo napovedovalcev-ocenjevalcev in za spopadanje s steklenimi škatlami, ki temeljijo na negotovosti, ki prihajajo iz nevralnih strojnih prevajalskih sistemov.', 'jv': 'Awak dhéwé nggawe nyumbang nggawe IsT lan Unbabel kanggo ngilangno WWT 2020 Tarjamahan sing gawe kalite Awakdhéwé wis nambah nganggo gak track (directi assessment, after-editing Effor, document-evel), sanggunaké 14 sisané surjamahan Awak dhéwé ono nggawe sistem sing nggawe ngupakan lan ugat Open Kiwi aturan kanggo tukang karo architecture sing supoyo nggawe tarjamahan lan ugat nggo nggawe barang-box, sing wis ngerasakno karo sistem sing toljamahan karo netranal.', 'ha': "Tuna halatar da wadan rabon aiki na Shirin da aka Shirin da shi a WMT 2020 Our team participated on all tracks (Direct Assessment, Post-Editing Effort, Document-Level), encompassing a total of 14 submissions.  An developed system-yiwunmu da aka shimfiɗa firam ɗin Open Kiwi zuwa wani matsayin mai bassi da aka bada-bassi, kuma dõmin a yi kodi da sigar-sigar, da fassarar-bassi, masu bastarwa da ba'a sani ba daga tsarin fassarar ɗin neurar.", 'bo': 'ང་ཚོས་IST དང་Unbabel འི་མཐུན་སྒྲིག་གི་གནད་སྡུད་གླེང་ཚད་ལ་མཉམ་སྤྱོད་པའི་བྱ་རིམ་སྟོན་པ་ཡིན། Our team participated on all tracks (Direct Assessment, Post-Editing Effort, Document-Level), encompassing a total of 14 submissions. Our submitted systems were developed by extending the OpenKiwi framework to a transformer-based predictor-estimator architecture, and to cope with glass-box, uncertainty-based features coming from neural machine translation systems.', 'he': 'אנחנו מציגים את התרומה המשותפת של IST ואונבאבל למשימה המשותפת של WMT 2020 על הערכת איכות. הצוות שלנו השתתף בכל המסלולים (הערכה ישירה, מאמץ לאחר הערכה, רמת המסמכים), מכיל בסך הכל 14 הודעות. המערכות המועברות שלנו התפתחו על ידי הרחבת המסגרת של OpenKiwi לארכיטקטורה המבוססת על מערכת צפייה-מערכת המעבר, ולהתמודד עם תכונות זכוכית-קופסת, מבוססות על אי-בטוחות שמגיעות מערכות התרגום של מכונות עצביות.'}
{'en': 'TransQuest at WMT2020 : Sentence-Level Direct Assessment', 'ar': 'TransQuest في WMT2020: التقييم المباشر على مستوى الجملة', 'es': 'TransQuest en el WMT2020: evaluación directa a nivel de oración', 'pt': 'TransQuest no WMT2020: Avaliação direta em nível de sentença', 'fr': 'TransQuest au WMT2020\xa0: évaluation directe au niveau de la peine', 'ja': 'WMT 2020でのトランスクエスト：文章レベルの直接評価', 'zh': 'WMT2020ä¸ŠTransQuest:ĺŹĄçş§ç›´čŻ„', 'ru': 'TransQuest на WMT2020: прямая оценка на уровне предложения', 'hi': 'WMT2020 पर TransQuest: वाक्य-स्तर प्रत्यक्ष मूल्यांकन', 'ga': 'TransQuest ag WMT2020: Measúnú Díreach ar Leibhéal Pianbhreithe', 'ka': 'Comment', 'el': 'TransQuest στο WMT2020: Άμεση Αξιολόγηση σε επίπεδο ποινής', 'hu': 'TransQuest a WMT2020-on: mondatszintű közvetlen értékelés', 'lt': 'TransQuest at WMT2020: Sentence-Level Direct Assessment', 'mk': 'TransQuest на WMT2020: Директна проценка на нивото на пресуда', 'it': 'TransQuest a WMT2020: valutazione diretta a livello di frase', 'kk': 'WMT2020- дегі трансквест: сөз- деңгейінің тікелей оценкасы', 'ms': 'TransQuest at WMT2020: Sentence-Level Direct Assessment', 'mn': 'WMT2020 оны трансквест: өгүүлбэр-түвшинд шууд оценка', 'ml': 'WMT2020- ലെ ട്രാന്\u200dസ്ക്വിസ്റ്റ്Quest: Sentence- Level Direct Assessment', 'mt': 'TransQuest fid-WMT2020: Valutazzjoni Diretta tal-Livell tas-Sentenza', 'pl': 'TransQuest na WMT2020: Bezpośrednia ocena na poziomie zdań', 'sr': 'TransQuest na WMT2020: Direktna procjena na nivou kazne', 'no': 'TransQuest ved WMT2020: Rett- uttrykk- nivå', 'ro': 'TransQuest la WMT2020: Evaluare directă la nivel de sentință', 'si': 'Comment', 'so': 'Translation at WMT2020: Sentence-Level Direct Assessment', 'sv': 'TransQuest vid WMT2020: Direkt bedömning på meningsnivå', 'ta': 'WMT2020: வாக்கு- நேரடி மதிப்பு', 'ur': 'WMT2020 میں ترنس کوسٹ: سنٹنس-لئویل مستقیم آزمائش', 'uz': 'Quest at WMT2020: Sentence- Level Direct Assessment', 'vi': 'Biên dịch ở WM220: đánh giá trực tiếp', 'bg': 'ТрансQuest при WMT22020: пряка оценка на ниво присъда', 'hr': 'TransQuest na WMT2020: Direktna procjena razine kazne', 'da': 'TransQuest på WMT2020: Direkte vurdering på sætningsniveau', 'nl': 'TransQuest op WMT2020: Directe beoordeling op zinsniveau', 'de': 'TransQuest auf WMT2020: Direkte Bewertung auf Satzebene', 'id': 'TransQuest di WMT2020: penilaian langsung tingkat hukuman', 'ko': 'WMT 2020의 TransQuest: 문장급 직접 평가', 'fa': 'TransQuest at WMT2020: Assessment Direct Level sentence', 'af': 'TransQuest by WMT2020: Sentence- Level Direct Assessment', 'sq': 'TransQuest në WMT2020: vlerësim i drejtpërdrejtë i nivelit të dënimit', 'sw': 'Questi at WMT2020: Sentence-Level Direct Assessment', 'tr': "WMT2020'de TransQuest: Söze-Seviye Doğru Düzenlenme", 'am': 'ትርጉም በWMT2020: Sentence-Level Direct Assessment', 'bn': 'WMT2020-এ অনুসন্ধান', 'hy': 'TransQuest-ը World MT2020-ում. Առաջին գնահատում դատաստանի մակարդակի վրա', 'az': 'WMT2020-də TransQuest: Sözü-Seviye Direkt Assessment', 'bs': 'TransQuest na WMT2020: Direktna procjena na nivou kazne', 'ca': 'TransQuest a WMT2020: Evaluació directa del nivell de sentencia', 'fi': 'TransQuest at WMT22020: Tuomiotason suora arviointi', 'cs': 'TransQuest na WMT2020: Přímé hodnocení na úrovni vět', 'et': 'TransQuest at WMT22020: karistuse tasandi otsene hindamine', 'jv': 'Name', 'he': 'TransQuest ב WMT2020: הערכה ישירה רמת גזר', 'sk': 'TransQuest na WMT22020: neposredna ocena na ravni kazni', 'ha': 'QWebPage', 'bo': 'TransQuest at WMT2020: Sentence-Level Direct Assessment'}
{'en': 'This paper presents the team TransQuest’s participation in Sentence-Level Direct Assessment shared task in WMT 2020. We introduce a simple QE framework based on cross-lingual transformers, and we use it to implement and evaluate two different neural architectures. The proposed methods achieve state-of-the-art results surpassing the results obtained by OpenKiwi, the baseline used in the shared task. We further fine tune the QE framework by performing ensemble and data augmentation. Our approach is the winning solution in all of the language pairs according to the WMT 2020 official results.', 'ar': 'تقدم هذه الورقة مشاركة فريق TransQuest في المهمة المشتركة للتقييم المباشر على مستوى الجملة في WMT 2020. نقدم إطار عمل QE بسيطًا يعتمد على محولات متعددة اللغات ، ونستخدمها لتنفيذ وتقييم بنيتين عصبيتين مختلفتين. تحقق الطرق المقترحة نتائج متطورة تتجاوز النتائج التي تم الحصول عليها بواسطة OpenKiwi ، وهو الأساس المستخدم في المهمة المشتركة. نقوم كذلك بضبط إطار عمل التيسير الكمي من خلال أداء التجميع وزيادة البيانات. نهجنا هو الحل الفائز في جميع أزواج اللغات وفقًا للنتائج الرسمية لـ WMT 2020.', 'fr': "Cet article présente la participation de l'équipe TransQuest à la tâche partagée Sentence-Level Direct Assessment dans le cadre du WMT 2020. Nous introduisons un framework QE simple basé sur des transformateurs interlinguaux, et nous l'utilisons pour implémenter et évaluer deux architectures neuronales différentes. Les méthodes proposées permettent d'obtenir des résultats de pointe dépassant les résultats obtenus par OpenKiwi, la base de référence utilisée dans la tâche partagée. Nous affinons davantage le cadre d'assouplissement quantitatif en augmentant l'ensemble et les données. Notre approche est la solution gagnante pour toutes les paires de langues selon les résultats officiels du WMT 2020.", 'es': 'Este documento presenta la participación del equipo de TransQuest en la tarea compartida de evaluación directa a nivel de oración en el WMT 2020. Presentamos un marco de QE simple basado en transformadores multilingües y lo utilizamos para implementar y evaluar dos arquitecturas neuronales diferentes. Los métodos propuestos logran resultados de vanguardia que superan los resultados obtenidos por OpenKiwi, la línea de base utilizada en la tarea compartida. Ajustamos aún más el marco de QE mediante el aumento de conjuntos y datos. Nuestro enfoque es la solución ganadora en todos los pares de idiomas según los resultados oficiales del WMT 2020.', 'pt': 'Este artigo apresenta a participação da equipe TransQuest na tarefa compartilhada Sentence-Level Direct Assessment no WMT 2020. Apresentamos uma estrutura QE simples baseada em transformadores de idiomas cruzados e a usamos para implementar e avaliar duas arquiteturas neurais diferentes. Os métodos propostos alcançam resultados de última geração superando os resultados obtidos pelo OpenKiwi, a linha de base utilizada na tarefa compartilhada. Ajustamos ainda mais a estrutura QE realizando aumento de conjunto e dados. Nossa abordagem é a solução vencedora em todos os pares de idiomas de acordo com os resultados oficiais do WMT 2020.', 'ja': 'この論文では、WMT 2020におけるSentence - Level Direct Assessmentの共有タスクへのチームTransQuestの参加について紹介します。私たちは、クロスリンガル変換器に基づいた単純なQEフレームワークを導入し、それを使用して2つの異なるニューラルアーキテクチャを実装し、評価します。提案された方法は、共有タスクで使用されるベースラインであるOpenKiwiで得られた結果を上回る最先端の結果を達成します。アンサンブルとデータ拡張を実行して、QEフレームワークをさらに微調整します。私たちのアプローチは、WMT 2020の公式結果によると、すべての言語ペアにおける勝利のソリューションです。', 'hi': 'यह पेपर WMT 2020 में वाक्य-स्तरीय प्रत्यक्ष मूल्यांकन साझा कार्य में टीम ट्रांसक्वेस्ट की भागीदारी प्रस्तुत करता है। हम क्रॉस-लिंगुअल ट्रांसफॉर्मर के आधार पर एक सरल क्यूई फ्रेमवर्क पेश करते हैं, और हम इसका उपयोग दो अलग-अलग तंत्रिका आर्किटेक्चर को लागू करने और मूल्यांकन करने के लिए करते हैं। प्रस्तावित विधियां OpenKiwi द्वारा प्राप्त परिणामों को पार करते हुए अत्याधुनिक परिणाम प्राप्त करती हैं, जो साझा कार्य में उपयोग की जाने वाली आधार रेखा है। हम आगे पहनावा और डेटा वृद्धि प्रदर्शन करके क्यूई ढांचे को ठीक करते हैं। हमारा दृष्टिकोण डब्ल्यूएमटी 2020 के आधिकारिक परिणामों के अनुसार सभी भाषा जोड़े में विजेता समाधान है।', 'zh': '本文引TransQuest团队于WMT 2020中参句级直评共事。 引入一基转换器言语简QE框架,以成其神经架构。 所言最先进者,过于OpenKiwi,OpenKiwi共事之基线也。 行集数以益QE框架。 据WMT 2020官方,凡诸语言,皆制胜解决方案。', 'ru': 'В этом документе представлено участие команды TransQuest в совместной задаче «Прямая оценка на уровне предложения» в WMT 2020. Мы вводим простой каркас QE, основанный на кросс-лингвистических трансформаторах, и используем его для реализации и оценки двух различных нейронных архитектур. Предлагаемые методы позволяют достичь самых современных результатов, превосходящих результаты, полученные с помощью OpenKiwi, базовой линии, используемой в общей задаче. Мы дополнительно дорабатываем структуру QE, выполняя ансамбль и увеличение данных. Наш подход - это выигрышное решение во всех языковых парах по официальным результатам WMT 2020.', 'ga': 'Cuireann an páipéar seo i láthair rannpháirtíocht TransQuest na foirne i Measúnú Díreach ar Leibhéal Pianbhreithe i WMT 2020. Tugaimid isteach creat QE simplí bunaithe ar chlaochladáin tras-teangacha, agus úsáidimid é chun dhá ailtireacht néaracha éagsúla a chur i bhfeidhm agus a mheas. Baineann na modhanna molta torthaí úrscothacha amach a sháraíonn na torthaí a fhaigheann OpenKiwi, an bonnlíne a úsáidtear sa tasc comhroinnte. Déanaimid mionchoigeartú breise ar an gcreat QE trí ensemble agus méadú sonraí a dhéanamh. Is é ár gcur chuige an réiteach buaiteach i ngach ceann de na péirí teanga de réir thorthaí oifigiúla WMT 2020.', 'hu': 'Ez a tanulmány bemutatja a TransQuest csapat részvételét a WMT 2020 mondatszintű közvetlen értékelésben. Egy egyszerű, keresztnyelvű transzformátorokon alapuló QE keretrendszert vezetünk be, amelyet két különböző neurális architektúra megvalósítására és értékelésére használunk. A javasolt módszerek korszerű eredményeket érnek el, amelyek meghaladják a megosztott feladatban használt OpenKiwi által elért eredményeket. A QE keretrendszert tovább finomhangoljuk együttes- és adatbővítéssel. A WMT 2020 hivatalos eredményei szerint minden nyelvpárban a mi megközelítésünk a nyertes megoldás.', 'el': 'Η παρούσα εργασία παρουσιάζει τη συμμετοχή της ομάδας στην κοινή εργασία άμεσης αξιολόγησης σε επίπεδο ποινών στο WMT 2020. Εισάγουμε ένα απλό πλαίσιο QE βασισμένο σε διγλωσσικούς μετασχηματιστές, και το χρησιμοποιούμε για να εφαρμόσουμε και να αξιολογήσουμε δύο διαφορετικές νευρωνικές αρχιτεκτονικές. Οι προτεινόμενες μέθοδοι επιτυγχάνουν αποτελέσματα τελευταίας τεχνολογίας που ξεπερνούν τα αποτελέσματα που λαμβάνονται από το OpenKiwi, τη βάση βάσης που χρησιμοποιείται στην κοινή εργασία. Περαιτέρω τελειοποιούμε το πλαίσιο QE εκτελώντας την αύξηση συνόλων και δεδομένων. Η προσέγγισή μας είναι η νικηφόρα λύση σε όλα τα γλωσσικά ζεύγη σύμφωνα με τα επίσημα αποτελέσματα του WMT 2020.', 'lt': 'Šiame dokumente pristatomas TransQuest grupės dalyvavimas bendroje nuosprendžių lygio tiesioginio vertinimo užduotyje „WMT 2020“. Įdiegiame paprastą QE sistemą, grindžiamą tarpkalbiniais transformatoriais, ir naudojame ją dviem skirtingoms nervų architektūroms įgyvendinti ir įvertinti. Siūlomais metodais pasiekti naujausi rezultatai, viršijantys OpenKiwi gautus rezultatus, kurie yra bendros užduoties pagrindas. We further fine tune the QE framework by performing ensemble and data augmentation.  Our approach is the winning solution in all of the language pairs according to the WMT 2020 official results.', 'ka': 'ეს დოკუმენტი გამოსახულება ტრანსკვისტის დამატებით WMT 2020-ში საზოგადომი განსახულებაში. ჩვენ გავიყენებთ საერთო QE ფრამეტრი, რომელიც მრავალენგიური ტრანფორმეტრების ბაზეულია, და ჩვენ გამოყენებთ ის გამოყენება და გავამუშაოთ ორი განსხვავებული ნე პროგრამეტრების შესაძლებლობები გავაკეთებთ განსაზღვრებული წარმოდგენების შესაძლებლობა, რომელიც OpenKiwi-ის მიღებული წარმოდგენების შესაძლებლობა, რომელიც საზოგადოებული ჩვენ უფრო სრულად QE ფრამეტრის გავაკეთებთ, რომელიც მონაცემები და მონაცემების აღექტირებას გავაკეთებთ. ჩვენი პროგორმა არის ყველა ენის ზოგების წინასწორება, რომლებიც WMT 2020-ის официальных результатების შესახებ.', 'it': "Questo articolo presenta la partecipazione del team TransQuest al compito condiviso di valutazione diretta a livello di frase in WMT 2020. Introduciamo un semplice framework QE basato su trasformatori cross-lingual, e lo usiamo per implementare e valutare due diverse architetture neurali. I metodi proposti raggiungono risultati all'avanguardia superando i risultati ottenuti da OpenKiwi, la linea di base utilizzata nell'attività condivisa. Aggiungiamo ulteriormente il framework QE eseguendo ensemble e data augmentation. Il nostro approccio è la soluzione vincente in tutte le coppie linguistiche secondo i risultati ufficiali WMT 2020.", 'mk': 'Овој документ го претставува учеството на тимот Транскест во заедничката задача за проценка на ниво на судски реченици во ВМТ 2020. Ние воведуваме едноставна QE рамка базирана на меѓујазични трансформатори, и ја користиме за имплементирање и оценка на две различни нервни архитектури. Предложените методи постигнуваат најсовремени резултати кои ги надминуваат резултатите добиени од OpenKiwi, основниот резултат кој се користи во заедничката задача. Понатаму ја прилагодуваме QE рамката со изведување на ансембл и зголемување на податоците. Нашиот пристап е победничкото решение во сите парови јазици според официјалните резултати на ВМТ 2020.', 'kk': 'Бұл қағаз WMT 2020 жылы сөз деңгейіндегі тікелей оценкасында TransQuest командасының қатынасын көрсетеді. Біз көп тілді түрлендірушерге негізделген QE бағдарламасын келтіреміз. Біз оны екі түрлі невралдық архитектураларды орындау мен оқу үшін қолданамыз. Келтірілген әдістер ортақтастырылған тапсырманың негізгі жолы OpenKiwi- ның нәтижелерінен артық болады. Біз QE бағдарламасын ензембл және деректерді көптеу арқылы баптаймыз. Біздің ұқсатымыз - WMT 2020 ресми нәтижелеріне сәйкес тілдердің барлық түрлерінің шешімі.', 'ml': 'ഈ പത്രത്തില്\u200d ടീം ട്രാന്\u200dസ്ക്വെസ്റ്റിന്റെ പങ്കെടുക്കുന്നത് WMT 2020 ല്\u200d പങ്കെടുത്ത ജോലി നമ്മള്\u200d ക്രിസ്ലിങ്ങില്\u200d മാറ്റങ്ങള്\u200d അടിസ്ഥാനമായി ഒരു എളുപ്പമുള്ള ക്യൂ ഫ്രെയിമെക്ക് പരിചയപ്പെടുത്തുന്നു. അതിനാല്\u200d രണ്ടു വ പങ്കെടുക്കുന്ന ജോലിയില്\u200d ഉപയോഗിക്കുന്ന ബെസ്ലൈന്\u200d ഉപയോഗിക്കുന്ന ഫലങ്ങള്\u200d ഓപ്പെന്\u200dകിവിയില്\u200d ലഭ്യമാക്കിയ സ്ഥാനം We further fine tune the QE framework by performing ensemble and data augmentation.  WMT 2020 ഓഫീസിലെ ഫലങ്ങള്\u200dക്ക് അനുസരിച്ച് നമ്മുടെ വഴിയില്\u200d എല്ലാ ഭാഷയിലും ജയിക്കുന്ന പരിഹാരം ആണ്.', 'ms': 'Kertas ini memperkenalkan pesertaan Pasukan TransQuest dalam penilaian langsung tahap hukuman tugas berkongsi dalam WMT 2020. Kami memperkenalkan kerangka QE sederhana berdasarkan pengubah saling bahasa, dan kami menggunakannya untuk melaksanakan dan menilai dua arkitektur saraf yang berbeza. Kaedah yang diusulkan mencapai keputusan-state-of-the-art melebihi keputusan yang diperoleh oleh OpenKiwi, dasar yang digunakan dalam tugas terkongsi. Kami lebih baik menyesuaikan kerangka QE dengan melakukan ensemble dan peningkatan data. pendekatan kita adalah penyelesaian yang menang dalam semua pasangan bahasa menurut hasil resmi WMT 2020.', 'mn': 'Энэ цаас WMT 2020 онд хэлсэн ажил дээр Транскест багийнхаа хувьд оролцож байна. Бид олон хэлний шилжүүлэгчид дээр суурилсан энгийн QE хэлбэрийг танилцуулдаг. Бид үүнийг 2 өөр мэдрэлийн архитектурыг хэрэглэж, үнэлэх гэж ашигладаг. Өөрчлөлтийн арга зам нь хуваалцагдсан ажлын үндсэн шугам OpenKiwi-ын үр дүн дээр гарч ирнэ. Бид QE-ийн хэмжээсүүдийг бага зэрэг тоон болон өгөгдлийн нэмэгдүүлэлт хийж болно. Бидний ойлголт бол WMT 2020-ын ерөнхий төрийн үр дүнтэй адил бүх хэл хоорондын ялах шийдэл юм.', 'pl': 'W artykule przedstawiono udział zespołu TransQuest w wspólnym zadaniu oceny bezpośredniej na poziomie zdań w WMT 2020. Wprowadzamy prosty framework QE oparty na transformatorach wielojęzycznych i wykorzystujemy go do wdrożenia i oceny dwóch różnych architektur neuronowych. Proponowane metody osiągają najnowocześniejsze wyniki przewyższające wyniki uzyskane przez OpenKiwi, bazę wykorzystywaną w wspólnym zadaniu. Dodatkowo dostosowujemy framework QE poprzez wykonywanie zespołu i powiększania danych. Nasze podejście jest zwycięskim rozwiązaniem we wszystkich parach językowych według oficjalnych wyników WMT 2020.', 'no': 'Denne papiret viser at gruppa TransQuest deltar i uttrykk-nivå direkte vurdering delt oppgåve i WMT 2020. Vi introduserer eit enkel QE-rammeverk basert på krysspråk transformatorar, og vi bruker det for å implementera og evaluera to ulike neuralarkitektur. Dette første metodane gjer tilstanden av kunsten til resultatet over resultatet gjevne av OpenKiwi, baselinja som brukar i delt oppgåve. Vi finn framover QE-rammeverket ved å utføra ensemble og data augmentasjon. Tilnærminga vårt er den vinnende løysinga i alle språkparene etter det offisielle resultatet WMT 2020.', 'mt': 'Dan id-dokument jippreżenta l-parteċipazzjoni tat-tim TransQuest fil-ħidma kondiviża tal-Valutazzjoni Diretta tal-Livell tas-Sentenzi fid-WMT 2020. Aħna nintroduċu qafas sempliċi ta’ QE ibbażat fuq trasformaturi translingwi, u a ħna nużaw dan biex nimplimentaw u jivvalutaw żewġ arkitetturi newrali differenti. Il-metodi proposti jiksbu riżultati moderni li jaqbżu r-riżultati miksuba minn OpenKiwi, il-linja bażi użata fil-kompitu kondiviż. Aħna nistabbilixxu aktar il-qafas tal-QE billi nagħmlu ensemble u żieda fid-dejta. L-approċċ tagħna huwa s-soluzzjoni rebbieħa fil-pari lingwistiċi kollha skont ir-riżultati uffiċjali tad-WMT 2020.', 'sr': 'Ovaj papir predstavlja sudjelovanje tima TransQuesta u direktnoj ocjeni kazne na nivou direktne ocjene zadataka WMT 2020. Upoznajemo jednostavan QE okvir na temelju preko jezika transformatora, i koristimo ga za implementaciju i procjenu dve različite neuralne arhitekture. Predložene metode postignu rezultate umetnosti koji su iznosili rezultate koje su dobili OpenKiwi, početnu liniju koja se koristi u zajedničkom zadatku. Nadalje ćemo dobro srediti QE okvir provođenjem ensemble i povećanjem podataka. Naš pristup je pobedničko rješenje u svim jezičkim parovima prema zvaničnim rezultatima WMT 2020.', 'si': 'මේ පත්තුව ට්\u200dරාන්ස්ක්වෙස්ට් කණ්ඩායම් එක්ක වාර්තා කරන්න පුළුවන් විදිහට ප්\u200dරතික්\u200dරියාත්මක විශ්වාස කරන් අපි විශේෂ භාෂාවික වෙනස් කරණාකරුවන්ගේ අධාරිත QE සාමාන්\u200dය ක්\u200dරියාම්ප්\u200dරමාණයක් පෙනුම් කරනවා, අපි ඒක ප්\u200dර ප්\u200dරයෝජනය විධානයේ ස්ථානය-of-the-art ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d අපි QE ෆ්\u200dරේම්ටර්ම් එක විශේෂය සහ දත්ත විශේෂය කරනවා. අපේ ප්\u200dරවේශනය තමයි ජයග්\u200dරහණ විසිද්ධ වෙන්නේ WMT 2020යි අධාරික ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d', 'ro': 'Această lucrare prezintă participarea echipei TransQuest la sarcina comună de evaluare directă la nivel de sentință în WMT 2020. Introducem un cadru QE simplu bazat pe transformatoare interlingvistice și îl folosim pentru a implementa și evalua două arhitecturi neurale diferite. Metodele propuse obțin rezultate de ultimă generație depășind rezultatele obținute de OpenKiwi, baza utilizată în sarcina partajată. Ajustăm în continuare cadrul QE prin efectuarea de ansamblu și de mărire a datelor. Abordarea noastră este soluția câștigătoare în toate perechile lingvistice conform rezultatelor oficiale WMT 2020.', 'ta': 'இந்த தாள் மாற்று குழு மாற்றுக்குழு வாக்கியம்- நேரடி நேரடி Assessment பகிர்ந்த பணியில் பங்கிடப்பட்டதை கூட்டுகிறது. மொழிமாற்றங்களை அடிப்படையில் சுலபமான QE சட்டத்தை நாம் குறிப்பிடுகிறோம், மற்றும் நாம் அதை பயன்படுத்தி இரண்டு வேறு வேறு நெருக பரிந்துரைக்கப்பட்ட முறைமைகள் பகிர்ந்த செயல்பாட்டில் பயன்படுத்தப்பட்ட முடிவுகளை ஓபன்கிவியால் பெற்ற முடிவு நாம் மேலும் கியூஎ சட்டத்தை கூடுதல் மூலம் மற்றும் தரவு அதிகரிப்பை செய்து கொண்டு WMT 2020 ஆசிரியர் முடிவுகளை பொருத்தி அனைத்து மொழி ஜோடிகளிலும் வெற்றி தீர்வு தீர்வு.', 'ur': "This paper presents the team TransQuest's participation in Sentence-Level Direct Assessment shared task in WMT 2020. ہم ایک ساده QE فرمیک کرس زبان تبدیل کرنے والوں پر بنیاد رکھتے ہیں، اور ہم اس کا استعمال کرتے ہیں دو مختلف نئورل معماری کے لئے اور ارزش کرتے ہیں. پیشنهاد کی طریقے شرکت کا نتیجہ پہنچ رہے ہیں اوپنکیوی کے نتیجے سے زیادہ گزر رہے ہیں، شرکت کے کام میں استعمال کیا جاتا ہے. ہم اضافہ QE فرمیک کو اضافہ کرنے کے ذریعہ اضافہ کر رہے ہیں۔ ہمارا تقریبا تمام زبان جوڑوں میں غالب حل ہے WMT 2020 رسمی نتائج کے مطابق.", 'sv': 'Denna uppsats presenterar teamet TransQuests deltagande i Sentence-Level Direct Assessment delad uppgift i WMT 2020. Vi introducerar ett enkelt QE-ramverk baserat på tvärspråkiga transformatorer och använder det för att implementera och utvärdera två olika neurala arkitekturer. De föreslagna metoderna uppnår toppmoderna resultat som överträffar resultaten från OpenKiwi, baslinjen som används i den delade uppgiften. Vi finjusterar QE-ramverket ytterligare genom att utföra ensemble- och dataförstärkning. Vårt tillvägagångssätt är den vinnande lösningen i alla språkpar enligt WMT 2020 officiella resultat.', 'so': 'Kanu warqaddaas wuxuu kooxda TransQuest ka qayb galay xisaabta-Level Direct Assessment ee loo qaybiyey shaqada WMT 2020. Waxaynu soo bandhignaa firaaqad QE oo fudud oo ku saleysan isbedelka luuqadaha kala duduwan, waxaynu isticmaalnaa si aan u sameeyo iyo qiimeyno labada dhismaha neurada oo kala duduwan. Dhaqdooyinka la soo jeeday waxay gaadhaan xaaladda farshaxanta, iyagoo dhaafaya resultiyada uu soo helay OpenKiwi, asalka lagu isticmaalay shaqada la qaybsan. We further fine tune the QE framework by performing ensemble and data augmentation.  Dhaqdhaheenna waa xalliga guulaysashada labada nooc oo luqada ah sida uu u qabto resultada rasmiga ah WMT 2020.', 'uz': "Ushbu hujjat WMT 2020 yilda shaxsiy tashkilotni TransQuest guruhga ega beradi. Biz bir oddiy QE freymini ko'p tillar o'zgarishlar asosida yaratishimiz va biz uni ikkita boshqa neyrol maktablarni bajarish va qiymatlashga ishlatimiz. Name Biz biror yaxshi ko'proq QE freymini foydalanish va maʼlumot yozib qo'shish orqali bajaramiz. Bizning fikrimiz WMT 2020 rasm natijasi davomida hamma tillar qo'lingizda muvaffaqiyatli o'zgarishdir.", 'vi': 'Tờ giấy này giới thiệu nhóm TransQuest tham gia đánh giá trực tiếp Sensence-cấp chung nhiệm vụ ở WRT 2020. Chúng tôi tạo ra một hệ thống QE đơn giản dựa trên bộ chuyển hóa ngôn ngữ khác nhau, và chúng tôi dùng nó để triển khai và đánh giá hai kiến trúc thần kinh khác nhau. Các phương pháp đề nghị đạt được kết quả hiện đại vượt qua kết quả của công việc chung của OpenKiwi. Chúng tôi còn chỉnh lại hệ thống QE bằng cách kết hợp và tăng trưởng dữ liệu. Cách tiếp cận của chúng ta là giải pháp chiến thắng trong tất cả các cặp ngôn ngữ theo kết quả chính thức WRT 2020.', 'bg': 'Настоящата статия представя участието на екипа в споделената задача за директна оценка на ниво присъда в ММТ 2020. Въвеждаме проста рамка на базата на междуезични трансформатори и я използваме за внедряване и оценка на две различни невронни архитектури. Предложените методи постигат най-съвременни резултати, надхвърлящи резултатите, получени от базата, използвана в споделената задача. Освен това фино настройваме рамката чрез извършване на ансамбъл и увеличаване на данните. Нашият подход е печелившото решение във всички езикови двойки според официалните резултати на ММТ 2020.', 'hr': 'Ovaj papir predstavlja sudjelovanje tima TransQuest u direktnoj ocjeni na razini kazne u WMT 2020. godini. Upoznajemo jednostavan QE okvir na temelju transferenta preko jezika i koristimo ga za provedbu i procjenu dva različit a neuronske arhitekture. Predložene metode postignu rezultate stanja umjetnosti iznad rezultata koje su dobili OpenKiwi, početna linija koja se koristi u zajedničkom zadatku. Nadalje ćemo ispraviti QE okvir provođenjem ensemble i povećanjem podataka. Naš pristup je pobjedničko rješenje u svim jezičkim parovima prema zvaničnim rezultatima WMT 2020.', 'nl': 'Deze paper presenteert de deelname van het team TransQuest aan de gedeelde taak van het Sentence-Level Direct Assessment in WMT 2020. We introduceren een eenvoudig QE framework gebaseerd op cross-lingual transformators en gebruiken het om twee verschillende neurale architecturen te implementeren en te evalueren. De voorgestelde methoden bereiken state-of-the-art resultaten die overtreffen de resultaten verkregen door OpenKiwi, de baseline gebruikt in de gedeelde taak. We verfijnen het QE framework verder door ensemble en data augmentatie uit te voeren. Onze aanpak is de winnende oplossing in alle taalparen volgens de officiële resultaten van WMT 2020.', 'da': 'Denne artikel præsenterer holdet TransQuests deltagelse i fælles opgave på sætningsniveau direkte vurdering i WMT 2020. Vi introducerer et simpelt QE framework baseret på tværsprogede transformatorer, og vi bruger det til at implementere og evaluere to forskellige neurale arkitekturer. De foreslåede metoder opnår state-of-the-art resultater, der overgår resultaterne opnået af OpenKiwi, den oprindelige linje, der anvendes i den delte opgave. Vi finjusterer yderligere QE framework ved at udføre ensemble og data augmentation. Vores tilgang er den vindende løsning i alle sprogpar ifølge WMT 2020 officielle resultater.', 'de': 'In diesem Beitrag wird die Teilnahme des Teams TransQuest an der gemeinsamen Aufgabe für die direkte Bewertung auf Satz-Ebene in WMT 2020 vorgestellt. Wir führen ein einfaches QE-Framework auf Basis von crosslingualen Transformatoren ein und verwenden es, um zwei verschiedene neuronale Architekturen zu implementieren und zu bewerten. Die vorgeschlagenen Methoden erzielen State-of-the-Art Ergebnisse, die die Ergebnisse von OpenKiwi, der Ausgangsbasis für die gemeinsame Aufgabe, übertreffen. Wir verfeinern das QE-Framework weiter, indem wir Ensemble- und Datenerweiterungen durchführen. Unser Ansatz ist die Siegerlösung in allen Sprachpaaren gemäß den offiziellen Ergebnissen der WMT 2020.', 'fa': 'این کاغذ مشارکت تیم TransQuest را در ارزیابی سطح مستقیما در WMT 2020 نشان می دهد. ما یک چهارچوب QE ساده را معرفی می کنیم که بر اساس تغییردهندگان متفاوت زبان است، و از آن استفاده می کنیم تا دو معماری عصبی متفاوت را انجام دهیم و ارزیابی کنیم. روش پیشنهاد به نتیجه\u200cهای وضعیت هنری رسیده می\u200cشود که از نتیجه\u200cهایی که توسط OpenKiwi گرفته\u200cاند، پایین\u200cخط استفاده می\u200cشود در کار مشترک. ما چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهار دستور ما راه حل برنده در همه جفت زبان است بر اساس نتایج رسمی WMT 2020.', 'ko': '본고는 TransQuest팀이 WMT 2020에서 문장급 직접 평가 공유 임무에 참여한 상황을 소개한다.크로스 언어 변환기를 기반으로 한 간단한 QE 프레임워크를 소개하고 이를 통해 두 가지 서로 다른 신경 구조를 실현하고 평가했다.제시된 방법은 가장 선진적인 결과를 실현했고 공유 임무에서 사용된 기선인 OpenKiwi가 얻은 결과를 초과했다.통합 및 데이터 향상을 통해 QE 프레임워크를 더욱 미세하게 조정합니다.WMT 2020의 공식 결과에 따르면 우리의 방법은 모든 언어가 중국을 이기는 해결 방안이다.', 'sw': 'Gazeti hili linaonyesha ushiriki wa timu ya TransQuest katika Utafiti wa Direct Assessment of Sentence-Level Direct Assessment shared task in WMT 2020. Tunaweza kutengeneza mfumo rahisi wa QE kwa kutumia mabadiliko ya lugha mbalimbali, na tunatumia kutekeleza na kutathmini majengo mawili tofauti ya neura. mbinu zilizopendekezwa zinafanikiwa matokeo ya sanaa yanayopitia matokeo yaliyopatikana na OpenKiwi, msingi uliotumiwa katika kazi hiyo ya ushirikiano. Tunapata vizuri zaidi muundo wa QE kwa kutengeneza vifaa na kuongeza taarifa. Hatua yetu ni suluhisho la kushinda katika viwili vyote vya lugha kwa mujibu wa matokeo rasmi ya WMT 2020.', 'tr': 'Bu kagyz TransQuest toparyň WBMT 2020-nji ýylda Senes-Level Direkt Taýýarlamagynda bäsleşigini aýdýar Biz çarpaz dil üýtgetmenlere dayanan basit bir QE çerçevesini tanyşdyrýarys we muny etmäge we çykarmak üçin ullanýarys. Mazmunlar üçin OpenKiwi tarapyndan berilen netijeden üstün gelen ýagdaýlary tapylýar. Biz QE çerçevesini ensemble we veri yükselmesini yaparak daha iyi düzenleyiriz. Biziň ýaryşymyz WMT 2020 resmi netijelerine görä dil kopynyň ýeňiji çözümi.', 'id': 'Kertas ini memperkenalkan pesertaan tim TransQuest dalam penilaian langsung tingkat hukuman tugas berbagi di WMT 2020. Kami memperkenalkan rangkaian QE sederhana berdasarkan transformator saling bahasa, dan kami menggunakannya untuk mengimplementasikan dan mengevaluasikan dua arsitektur saraf yang berbeda. Metode yang diusulkan mencapai hasil terbaik melebihi hasil yang diperoleh oleh OpenKiwi, dasar yang digunakan dalam tugas bersama. Kami lebih lanjut memperbaiki kuadrat QE dengan melakukan ensemble dan peningkatan data. pendekatan kita adalah solusi yang menang dalam semua pasangan bahasa menurut hasil resmi WMT 2020.', 'sq': 'Ky dokument paraqet pjesëmarrjen e ekipit TransQuest në vlerësimin e përbashkët të nivelit të dënimit në WMT 2020. Ne futim një kuadër QE të thjeshtë bazuar në transformuesit ndërgjuhësorë, dhe e përdorim për të zbatuar dhe vlerësuar dy arkitektura të ndryshme neuronale. Metodat e propozuara arrijnë rezultate më të larta se rezultatet e fituara nga OpenKiwi, baza e përdorur në detyrën e përbashkët. We further fine tune the QE framework by performing ensemble and data augmentation.  Përqasja jonë është zgjidhja fituese në të gjitha çiftet gjuhësore sipas rezultateve zyrtare të WMT 2020.', 'af': "Hierdie papier stel die team TransQuest se deelheid in Woord-Vlak Direkte Assensie gedeelde taak in WMT 2020 voorsien. Ons introduiseer 'n eenvoudige QE raamwerk gebaseer op kruistale transformeerders, en ons gebruik dit om twee verskillende neurale arkitektuure te implementeer en te evalueer. Die voorgestelde metodes verkry state-of-the-art resultate oor die resultate wat deur OpenKiwi ontvang word, die basisline wat gebruik word in die gedeelde taak. Ons verder fyn die QE raamwerk deur ensemble en data augmentasie te doen. Ons toegang is die vinnige oplossing in al die taal paar volgens die offisiele resultate van WMT 2020.", 'am': 'ይህም ፕሮግራም የፋንስ-ደረጃ አካባቢ አካባቢ በWMT 2020 ውስጥ የተካፈለውን ስራ የፋንስ-ደረጃ አካባቢ ታሳየዋለች፡፡ የቋንቋ-ቋንቋ ለውጦችን በመሠረት ላይ ቀላል የQE ፍሬማት እናሳውቃለን፣ ሁለትን ልዩ የናቡር መሠረት እናስተምርበት ዘንድ እናጠቃታለን፡፡ የተዘጋጁ ሥርዓቶች የ-የ-አርእስት ውጤቶችን በOpenKiwi የተገኘውን ውጤቶች በመጠቀም አግኝተዋል፡፡ የQE ፍሬማዎችን እና የዳታ አካባቢ በማድረግ እና በማድረግ ጥሩ እናደርጋለን፡፡ የቋንቋው ሁሉ ሁለት ዓይነቶችን እንደWMT 2020 ባለሥልጣን ውጤቶች ማሸንፋት ነው፡፡', 'az': 'Bu kağıt, WMT 2020-də Sözü-Seviye Direkt Assessment işində TransQuest tayfasının paylaşılmasını göstərir. Biz çoxlu dil transformatörlərinə dayanan QE framework ünü təşkil edirik, və bunu iki müxtəlif nöral arhitektarını təşkil etmək və değerlendirmək üçün istifadə edirik. Önülləşdirilmiş metodlar, paylaşılmış işlərdə istifadə edilən OpenKiwi təcrübəsinin nəticələrindən üstün gəlir. Biz QE framework ünü ensemble və veri artırmaq üçün daha yaxşı düzəltdik. Bizim yaxınlığımız WMT 2020 olaraq bütün dil çiftlərində qələbə çətinlikdir.', 'bs': 'Ovaj papir predstavlja sudjelovanje tima TransQuesta u direktnoj ocjeni na razini kazna u WMT 2020. godini. Predstavljamo jednostavan QE okvir na temelju preko jezičkih transformatora, i koristimo ga za implementaciju i procjenu dva različit a neuralna arhitektura. Predložene metode postignu rezultate države umjetnosti iznad rezultata koji su dobili OpenKiwi, početna linija koja se koristi u zajedničkom zadatku. Dalje ćemo dobro srediti QE okvir provođenjem ensemble i povećanjem podataka. Naš pristup je pobjedničko rješenje u svim jezičkim parovima prema zvaničnim rezultatima WMT 2020.', 'hy': 'Այս հոդվածը ներկայացնում է TransQuest թիմի մասնակցությունը դատաստանի մակարդակի ուղղակի գնահատման համագործակցած հանձնարարությունը ԱՄԹ 2020-ում: Մենք ներկայացնում ենք մի պարզ QE կառուցվածք, որը հիմնված է լեզվային փոխակերպողների վրա, և օգտագործում ենք այն իրականացնելու և գնահատելու համար երկու տարբեր նյարդային ճարտարապետություններ: Առաջարկված մեթոդները հասնում են ամենաբարձր արդյունքներին, որոնք գերազանցում են OpenKiWi-ի ստացած արդյունքները, հիմքերը, որոնք օգտագործվում են ընդհանուր խնդրում: Մենք ավելի լավ կազմակերպում ենք QE-ի կառուցվածքը, կատարելով համակարգը և տվյալների աճը: Our approach is the winning solution in all of the language pairs according to the WMT 2020 official results.', 'bn': 'এই পত্রিকা টিম ট্রান্সকয়েস্টের শাস্তি-স্তরের সরাসরি বিজয়ে অংশগ্রহণের প্রতি উপস্থাপন করেছে WMT ২০২০ এ শেয়ার করা কাজ। আমরা একটি সাধারণ কিউই ফ্রেম পরিচিতি দেখাচ্ছি যা ক্রস-ভাষাভাষার পরিবর্তনের ভিত্তিতে ভিত্তিক, আর আমরা এটি ব্যবহার করি দুটি ভিন্ন নিউর প্রস্তাবিত পদ্ধতি শিল্পের রাষ্ট্রের ফলাফল প্রাপ্ত হয়েছে, যা প্রস্তাবিত হয়েছে ওপেনকিউই-এর ফলাফল পার করেছে, যা শেয়ার করা কা আমরা আরো ভালো কিউ ইউ ফ্রেম কার্যক্রমের মাধ্যমে এক্সপেবল এবং তথ্য বাড়ানোর মাধ্যমে। WMT ২০২০ সরকারী ফলাফল অনুসারে আমাদের প্রতিটি ভাষার জোড়ায় জয়ী সমাধান।', 'cs': 'Tento článek představuje účast týmu TransQuest na společném úkolu přímého hodnocení na úrovni vět ve WMT 2020. Představujeme jednoduchý QE framework založený na cross-jazyčných transformátorech a používáme ho k implementaci a vyhodnocení dvou různých neuronových architektur. Navržené metody dosahují nejmodernějších výsledků, které překonávají výsledky získané OpenKiwi, základním bodem použitým ve sdíleném úkolu. Dále doladíme QE framework prováděním souborové a datové rozšíření. Náš přístup je vítězným řešením ve všech jazykových párech podle oficiálních výsledků WMT 2020.', 'et': 'Käesolevas dokumendis tutvustatakse TransQuesti meeskonna osalemist kohtuotsusetaseme otsese hindamise ühises ülesandes WMT 2020 raames. Tutvustame lihtsat QE raamistikku, mis põhineb keeleülestel transformaatoritel ning kasutame seda kahe erineva neuroarhitektuuri rakendamiseks ja hindamiseks. Kavandatud meetoditega saavutatakse tipptasemel tulemusi, mis ületavad OpenKiwi tulemusi, mida kasutatakse jagatud ülesandes. Täiendavalt täpsustame QE raamistikku, teostades ansambli ja andmete suurendamist. Meie lähenemine on võitnud lahendus kõigis keelepaarides vastavalt WMT 2020 ametlikele tulemustele.', 'fi': 'Tässä artikkelissa esitellään TransQuestin tiimin osallistumista Sentence-Level Direct Assessment -tehtävään WMT 2020:ssä. Esittelemme yksinkertaisen monikielisiin muuntajiin perustuvan QE-kehyksen, jonka avulla toteutamme ja arvioimme kahta eri neuroarkkitehtuuria. Ehdotetuilla menetelmillä saavutetaan huipputason tuloksia, jotka ylittävät OpenKiwin, yhteisen tehtävän perusmallin, tulokset. Lisäksi hiomme QE-kehystä tekemällä ensemble- ja datan lisäyksiä. Lähestymistapamme on voittava ratkaisu kaikissa kielipareissa WMT 2020:n virallisten tulosten mukaan.', 'ca': "Aquest paper presenta la participació de l'equip TransQuest en la tasca compartida d'Evaluació Directa a nivell de Sentence s a WMT 2020. Introduïm un senzill marc QE basat en transformadors translingües, i l'utilitzem per implementar i evaluar dues arquitectures neuronals diferents. Els mètodes proposats aconsegueixen resultats més avançats que els resultats obtinguts per OpenKiwi, la base empregada en la tasca compartida. We further fine tune the QE framework by performing ensemble and data augmentation.  El nostre enfocament és la solució guanyadora en tots els parells de llengües segons els resultats oficials del WMT 2020.", 'jv': 'Ngerungke kuwi nggawe barang kanggo ngilangno karo hal bantayan de Awak dhéwé nyenggunaké un barang kelangan, sisaké karo nggawe barang langgar tarjamahan, lan unyangno nggawe ngulinakake tarjamahan karo akeh alat iki ulih apik dhéwé. Perintah sing dipunangé nggawe stad-of-the-arts banjur mulai dadi Open Kiwi, dadi wis dipunangé kanggo nggawe barang nggawe barang. Awak dhéwé luwih-luwih ngerasakno akeh Njupuk-luwih ngono nggawe barang nggawe barang data. Awakdhéwé nglanggar sampek iso nggawe barang nggawe gerakan kanggo masara urip sing terus nggawe barang, sing uwis rambarang bakal terus tambah sing bakal terus tambah sing kaké WT 2020.', 'ha': "Wannan takardan na gaurar wa team Trans We introduce a simple QE framework based on cross-lingual transformers, and we use it to implement and evaluate two different neural architectures.  @ action: button Mu sami kyautar firam na QEK da za'a sami samun ƙaramako da data. Mataimakinmu ne mafiya rinjãya a cikin duk harshe-nau'in da matsalar rasmi na WMT 2020.", 'sk': 'V prispevku je predstavljeno sodelovanje ekipe TransQuest v skupni nalogi ocenjevanja neposrednih kazni v WMT 2020. Predstavljamo preprost QE okvir, ki temelji na medjezičnih transformatorjih in ga uporabljamo za implementacijo in vrednotenje dveh različnih nevralnih arhitektur. Predlagane metode dosegajo najsodobnejše rezultate, ki presegajo rezultate OpenKiwi, osnovno osnovo, uporabljeno v skupni nalogi. Okvir QE nadalje natančno nastavimo z izvajanjem ansambla in povečanja podatkov. Naš pristop je zmagovalna rešitev v vseh jezikovnih parih po uradnih rezultatih WMT 2020.', 'he': 'העיתון הזה מציג את השתתפות של הקבוצה טרנסקוסט בהערכה ישירה ברמה גזרה משותפת ב-WMT 2020. אנחנו מציגים מסגרת QE פשוטה מבוססת על משתנים שפתיים, ואנחנו משתמשים בה כדי להפעיל ולעריך שני ארכיטקטורות עצביות שונות. השיטות המוצעות מגיעות לתוצאות חדשות מעליות את התוצאות שנקבלו על ידי OpenKiwi, הבסיס המשתמש במשימה המשותפת. אנחנו מתאימים יותר את המסגרת QE על ידי ביצוע אנסמבל וגדלת נתונים. הגישה שלנו היא הפתרון המנצח בכל זוגות השפה לפי התוצאות הרשמיות של WMT 2020.', 'bo': "This paper presents the team TransQuest's participation in Sentence-Level Direct Assessment shared task in WMT 2020. ང་ཚོས་སྐད་ཡིག་ཆ་འདྲ་བཟོ་བྱེད་མཁན་གྱི་QE་གཞུང་ཞིག གྲོས་འཆར ང་ཚོས་རྟགས་ཞིབ་དང་གསལ་བཤད་ཀྱི་རྩིས་གཞུང་ལ་ཇེ་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་ཐབས་ལམ་ལྟར་རྒྱལ་ཁབ་ཀྱི་སྐད་ཡིག་ཆ་ཚང་མཉམ་དུ་རྒྱལ་ཁབ་ཀྱི་ཐབས་ཤེས་རེད། WMT 2020་ལས་གཞུང་འབྲེལ"}
{'en': 'Tencent submission for WMT20 Quality Estimation Shared Task', 'pt': 'Envio Tencent para Tarefa Compartilhada de Estimativa de Qualidade WMT20', 'ar': 'إرسال Tencent للمهمة المشتركة لتقدير الجودة WMT20', 'fr': "Soumission Tencent pour la tâche partagée d'estimation de la qualité WMT20", 'es': 'Presentación de Tencent para la tarea compartida de estimación de calidad WMT20', 'ja': 'WMT 20品質推定共有タスクのテンセント提出', 'hi': 'WMT20 गुणवत्ता अनुमान साझा कार्य के लिए Tencent प्रस्तुतीकरण', 'zh': '腾讯交WMT20质测评共其事', 'ru': 'Представление Tencent для совместной задачи оценки качества WMT20', 'ga': 'Aighneacht Tencent do Thasc Comhroinnte Meastachán Cáilíochta WMT20', 'el': 'Δεκαετή υποβολή για κοινή εργασία εκτίμησης ποιότητας WMT20', 'ka': 'Comment', 'hu': 'A WMT20 minőségbecslési megosztott feladatra vonatkozó tízes benyújtás', 'kk': 'WMT20 сапасы оқу үшін ортақтастырылған тапсырманың тең жіберу', 'it': "Invio di dieci centesimi per l'attività condivisa di stima della qualità WMT20", 'lt': 'WMT20 kokybės vertinimo bendros užduoties tendencijos pateikimas', 'mk': 'Tencent submission for WMT20 Quality Estimation Shared Task', 'ml': 'WMT20 ഗുണത്തിനുള്ള എസ്റ്റിമേഷന്\u200d പങ്കുചേര്\u200dത്ത പണിയ്ക്കു', 'ms': 'Penghantaran tegang untuk Tugas Berkongsi Estimasi Kualiti WMT20', 'mt': 'Sottomissjoni tat-tensjoni għal Kompitu Kondiviż għall-Istima tal-Kwalità tal-WMT20', 'mn': 'WMT20 Quality Estimation Shared Task', 'no': 'Comment', 'pl': 'Dziesięć lat zgłoszenia do WMT20 Quality Estimation Shared Task', 'ro': 'Trimiterea de 10 cenți pentru activitatea partajată de estimare a calității WMT20', 'sr': 'Deset podataka za procjenu kvalitete WMT20 zajedničkog zadatka', 'so': 'Tencent submission for WMT20 Quality Estimation Shared Shaqo', 'si': 'WMT20 කුළුවත් අවශ්\u200dය අනුමාණය සමාගත වැඩක් විතරයි.', 'sv': 'Tencent inlämning för WMT20 Quality Estimation Shared Task', 'ta': 'WMT20 தரமான கணக்கீட்டு பகிர்ந்த பணி', 'ur': 'WMT20 کیلوٹی ارزش شریک ٹاکس کے لئے تنسنت تحویل', 'uz': 'Name', 'vi': 'tiết kiệm cho công việc chia sẻ chất lượng WM', 'bg': 'Предложение за десет цента за обща задача за оценка на качеството WMT20', 'hr': 'Deset podataka za procjenu kvalitete WMT20 zajedničkog zadatka', 'nl': 'Tencent indiening voor WMT20 Quality Estimation Shared Task', 'da': 'Tencent indsendelse af WMT20 Quality Estimation Shared Task', 'de': 'Zehnte Einreichung für WMT20 Quality Estimation Shared Task', 'id': 'Pengiriman cenderung untuk Tugas Berkongsi Penghargaan Kualitas WMT20', 'ko': '텐센트가 WMT20 품질 평가 공유 작업 제출', 'fa': 'تحویل دهم برای ارزیابی کیفیت WMT20 وظیفه مشترک', 'sw': 'Mawasiliano ya asilimia kwa ajili ya Uhindi wa WMT20', 'tr': 'WMT20 Quality Taýýarlama Mazmunlary Gaýşartmak üçin Tencent submisiýa', 'af': 'Tensente onderskrywing vir WMT20 Kwaliteit Estimasie Gedeelde Opdrag', 'sq': 'Paraqitja e ashpër për detyrën e përbashkët të vlerësimit të cilësisë WMT20', 'am': 'አዲስ ዶሴ ፍጠር', 'hy': 'Աշխարհային աշխարհի 20 որակի գնահատման ընդհանուր հանձնարարությունը', 'az': 'WMT20 keyfiyyəti Nömrəsi Bölüşdürülən Task üçün Tencent submission', 'bn': 'WMT20 মান সম্মান শেয়ার করা কাজের জন্য দশমেন্ট প্রদান করুন', 'bs': 'Deset podataka za procjenu kvalitete WMT20 zajedničkog zadatka', 'cs': 'Desetinásobné podání pro odhad kvality WMT20 Shared Task', 'ca': "Tenència de presentació per a la tasca compartida d'estimació de qualitat WMT20", 'et': 'Kümnendi esitamine WMT20 kvaliteedi hindamise jagatud ülesande kohta', 'fi': 'Kymmenen senttiä WMT20 Quality Estimation Shared Task -ohjelmasta', 'jv': 'Tanent penting kanggo nggawe task sing dipune-perusahaan karo WWC2', 'sk': 'Oddaja desetih centov za skupno nalogo ocene kakovosti WMT20', 'he': 'הגישה עקשנית למשימה משותפת בערכת איכות WMT20', 'ha': 'KCharselect unicode block name', 'bo': 'WMT20 རིགས་གཟུགས་རིས་བསམ་བྱས་པའི་བྱ་འགུལ་ལ་བརྗོད་པ'}
{'en': 'This paper presents Tencent’s submission to the WMT20 Quality Estimation (QE) Shared Task : Sentence-Level Post-editing Effort for English-Chinese in Task 2. Our system ensembles two architectures, XLM-based and Transformer-based Predictor-Estimator models. For the XLM-based Predictor-Estimator architecture, the predictor produces two types of contextualized token representations, i.e., masked XLM and non-masked XLM ; the LSTM-estimator and Transformer-estimator employ two effective strategies, top-K and multi-head attention, to enhance the sentence feature representation. For Transformer-based Predictor-Estimator architecture, we improve a top-performing model by conducting three modifications : using multi-decoding in machine translation module, creating a new model by replacing the transformer-based predictor with XLM-based predictor, and finally integrating two models by a weighted average. Our submission achieves a Pearson correlation of 0.664, ranking first (tied) on English-Chinese.', 'ar': 'تقدم هذه الورقة تقديم Tencent إلى المهمة المشتركة لتقدير جودة WMT20 (QE): جهد التحرير اللاحق على مستوى الجملة للغة الإنجليزية-الصينية في المهمة 2. يتألف نظامنا من بنيتين ، نماذج توقع-مقدر تستند إلى XLM وقائمة على المحولات. بالنسبة لمعمارية Predictor-Estimator المستندة إلى XLM ، ينتج المتنبئ نوعين من تمثيلات الرموز السياقية ، أي XLM المقنع و XLM غير المقنع ؛ يستخدم مقدر LSTM ومقدر المحولات استراتيجيتين فعالتين ، الانتباه من أعلى إلى K و متعدد الرؤوس ، لتعزيز تمثيل ميزة الجملة. بالنسبة إلى بنية Predictor-Estimator القائمة على المحولات ، نقوم بتحسين النموذج الأفضل أداءً من خلال إجراء ثلاثة تعديلات: استخدام فك التشفير المتعدد في وحدة الترجمة الآلية ، وإنشاء نموذج جديد عن طريق استبدال المتنبئ المستند إلى المحول بمتنبئ يعتمد على XLM ، وأخيراً دمج نموذجين بمتوسط مرجح. حقق تقديمنا ارتباط Pearson بمقدار 0.664 ، لتحتل المرتبة الأولى (تعادل) في اللغة الإنجليزية الصينية.', 'es': 'Este artículo presenta la presentación de Tencent a la tarea compartida de estimación de calidad (QE) de WMT20: Esfuerzo de post-edición a nivel de oración para inglés-chino en la tarea 2. Nuestro sistema agrupa dos arquitecturas, modelos Predictor-Estimator basados en XLM y basados en Transformer. Para la arquitectura Predictor-Estimator basada en XLM, el predictor produce dos tipos de representaciones de token contextualizadas, es decir, XLM enmascarado y XLM no enmascarado; el estimador LSTM y el estimador transformador-estimador emplean dos estrategias efectivas, atención de cabecera superior y atención de múltiples cabezas, para mejorar la función de oración representación. Para la arquitectura de predictor-estimador basada en transformadores, mejoramos un modelo de alto rendimiento mediante la realización de tres modificaciones: usar la decodificación múltiple en el módulo de traducción automática, crear un nuevo modelo al reemplazar el predictor basado en transformador por un predictor basado en XLM y, finalmente, integrar dos modelos por un media ponderada. Nuestra propuesta logra una correlación de Pearson de 0.664, ocupando el primer lugar (empatado) en inglés-chino.', 'pt': 'Este artigo apresenta a submissão da Tencent à Tarefa Compartilhada WMT20 Quality Estimation (QE): Esforço de Pós-edição em Nível de Sentença para Inglês-Chinês na Tarefa 2. Nosso sistema combina duas arquiteturas, modelos de Preditor-Estimador baseado em XLM e baseado em Transformer. Para a arquitetura Predictor-Estimator baseada em XLM, o preditor produz dois tipos de representações de token contextualizadas, ou seja, XLM mascarado e XLM não mascarado; o LSTM-estimator e o Transformer-estimator empregam duas estratégias eficazes, atenção top-K e multi-head, para melhorar a representação do recurso de sentença. Para a arquitetura Predictor-Estimator baseada em transformador, melhoramos um modelo de alto desempenho realizando três modificações: usando multi-decodificação no módulo de tradução automática, criando um novo modelo substituindo o preditor baseado em transformador pelo preditor baseado em XLM e, finalmente, integrando dois modelos por uma média ponderada. Nossa submissão alcança uma correlação de Pearson de 0,664, ficando em primeiro lugar (empatada) em inglês-chinês.', 'fr': "Cet article présente la soumission de Tencent à la tâche partagée d'estimation de la qualité (QE) WMT20\xa0: effort de post-édition au niveau de la phrase pour l'anglais-chinois dans la tâche 2. Notre système met en place deux architectures, des modèles Predictor-Estimator basés sur XLM et basés sur Transformer. Pour l'architecture Predictor-Estimator basée sur XLM, le prédicteur produit deux types de représentations de jetons contextualisées, à savoir XLM masqué et XLM non masqué\xa0; l'estimateur LSTM et l'estimateur de transformateurs-estimateurs utilisent deux stratégies efficaces, Top-K et attention multi-têtes, pour améliorer la caractéristique de phrase représentation. Pour l'architecture Predictor-Estimator basée sur Transformer, nous améliorons un modèle performant en effectuant trois modifications\xa0: utilisation du décodage multiple dans le module de traduction automatique, création d'un nouveau modèle en remplaçant le prédicteur basé sur transformateur par un prédicteur basé sur XLM, et enfin intégration de deux modèles par un moyenne pondérée. Notre soumission atteint une corrélation Pearson de 0,664, se classant au premier rang (à égalité) sur l'anglais-chinois.", 'ja': '本稿では、WMT 20 Quality Estimation (QE) Shared Task: Sentence - Level Post - editing Effort for English - Chinese in Task 2へのテンセントの提出を紹介する。 当社のシステムは、2つのアーキテクチャ、XLMベースとトランスフォーマーベースの予測-推定モデルを組み合わせています。 XLMベースの予測子-推定器アーキテクチャの場合、予測子は、マスクされたXLMおよびマスクされていないXLMという2種類のコンテキスト化されたトークン表現を生成し、LSTM -推定器およびトランスフォーマー-推定器は、文の特徴表現を強化するために、トップ- Kおよびマルチヘッド注意という2つの効果的な戦略を採用する。 Transformer - based Predictor - Estimatorアーキテクチャでは、機械翻訳モジュールでマルチデコードを使用し、Transformer - based predictorをXLM - based predictorに置き換えて新しいモデルを作成し、最終的に2つのモデルを加重平均で統合するという3つの修正を行い、トップパフォーマンスモデルを改善します。 当社の提出物は、英語と中国語の相関が0.664であり、英語と中国語の相関が1位（同率）になります。', 'hi': 'यह पेपर WMT20 गुणवत्ता अनुमान (QE) साझा कार्य के लिए Tencent के सबमिशन को प्रस्तुत करता है: कार्य 2 में अंग्रेजी-चीनी के लिए वाक्य-स्तर के बाद-संपादन प्रयास। हमारे सिस्टम ensembles दो आर्किटेक्चर, XLM आधारित और ट्रांसफॉर्मर आधारित भविष्यवक्ता-अनुमानक मॉडल. XLM-आधारित Predictor-Estimator आर्किटेक्चर के लिए, predictor दो प्रकार के contextualized टोकन अभ्यावेदन का उत्पादन करता है, यानी, नकाबपोश XLM और गैर-नकाबपोश XLM; LSTM-अनुमानक और ट्रांसफॉर्मर-अनुमानक दो प्रभावी रणनीतियों, शीर्ष-कश्मीर और बहु-सिर ध्यान को नियोजित करते हैं, ताकि वाक्य सुविधा प्रतिनिधित्व को बढ़ाया जा सके। ट्रांसफॉर्मर-आधारित भविष्यवक्ता-अनुमानक वास्तुकला के लिए, हम तीन संशोधनों का संचालन करके एक शीर्ष प्रदर्शन करने वाले मॉडल में सुधार करते हैं: मशीन अनुवाद मॉड्यूल में मल्टी-डिकोडिंग का उपयोग करके, एक्सएलएम-आधारित भविष्यवक्ता के साथ ट्रांसफॉर्मर-आधारित भविष्यवक्ता को बदलकर एक नया मॉडल बनाना, और अंत में भारित औसत द्वारा दो मॉडलों को एकीकृत करना। हमारा सबमिशन 0.664 का एक पियर्सन सहसंबंध प्राप्त करता है, जो अंग्रेजी-चीनी पर पहले (बंधे) स्थान पर है।', 'ru': 'Этот документ представляет представление Tencent к Общей Задаче Оценки Качества (QE) WMT20: Усилия Пост-редактирования Уровня Приговора для Английского-Китай в Задаче 2. Наша система объединяет две архитектуры, модели Predictor-Estimator на основе XLM и Transformer. Для основанной на XLM архитектуры Predictor-Estimator, предиктор производит два типа контекстуализированных представлений токенов, то есть, маскированный XLM и немаскированный XLM; LSTM-оценщик и Transformer-оценщик используют две эффективные стратегии, top-K и multi-head attention, для улучшения представления признаков предложения. Для архитектуры Transformer-based Predictor-Estimator мы улучшаем топовую модель, проводя три модификации: использование мультидекодирования в модуле машинного перевода, создание новой модели путем замены предиктора на основе трансформатора на предиктор на основе XLM и, наконец, интеграция двух моделей на средневзвешенное значение. Наша подача достигает корреляции Пирсона 0,664, занимая первое место (привязанное) на английском и китайском языках.', 'zh': '本文引腾讯WMT20质评(QE)共事:务2中英汉语句级译后辑事提交之材。 吾系统集成二架构, XLM 之与转换器之预测器-度器模型。 XLM 之预测器-度器体系结构,预测器成上下文令牌,屏蔽 XLM 非屏蔽 XLM。 LSTM度器变压器估计器用二策,top-K多头注意,以强句意。 其于 Transformer 之预测器-Estimator 架构,吾三改而易之:机器之转模块用多重解码,因其转换器之预测器而易之 XLM 预测器以创之,终以加权平均值为二。 提交Pearson相关性为0.664,英汉关系中第一(并列)。', 'ga': 'Cuireann an páipéar seo aighneacht Tencent i láthair don Tasc Comhroinnte um Mheastachán Cáilíochta (QE) WMT20: Iarracht Iar-eagarthóireachta ar Leibhéal Pianbhreithe don Bhéarla-Síneach i dTasc 2. Déanann ár gcóras ensembles dhá ailtireacht, samhlacha XLM-bhunaithe agus Trasfhoirmeoir-bhunaithe Predictor-Estimator. Maidir leis an ailtireacht Predictor-Estimator atá bunaithe ar XLM, táirgeann an réamhaithriseoir dhá chineál de chomharthaí comhthéacsúla, i.e., XLM chumhdaithe agus XLM neamh-mhaisithe; Úsáideann an Meastóir LSTM agus an Meastóir Trasfhoirmeoir dhá straitéis éifeachtacha, barr-K agus aird ilcheann, chun léiriú gné na habairte a fheabhsú. Maidir le hailtireacht Predictor-Estimator Trasfhoirmeoir-bhunaithe, feabhsaítear samhail barrfheidhmíochta trí bhíthin trí mhodhnú a dhéanamh: úsáid a bhaint as il-dhíchódú i modúl aistriúcháin meaisín, ag cruthú múnla nua trí thuarthóir XLM-bhunaithe a chur in ionad an réamhaithriseora atá bunaithe ar chlaochladán, agus ar deireadh comhtháthú. dhá mhúnla ar mheán ualaithe. Baineann ár n-aighneacht amach comhghaol Pearson de 0.664, rangú ar dtús (ceangailte) ar an mBéarla-Síneach.', 'hu': 'Ez a tanulmány bemutatja Tencent benyújtását a WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-Editing Efort for English-Chinese in Task 2. Rendszerünk két architektúrát alkot, XLM alapú és Transformer alapú Predictor-Estimator modellt. Az XLM alapú Predictor-Estimator architektúra esetében a prediktor kétféle kontextuális token reprezentációt hoz létre, azaz maszkos XLM és nem maszkos XLM; Az LSTM-becslő és a Transzformátor-becslő két hatékony stratégiát alkalmaz, a top-K és a multi-head figyelmet, hogy fokozza a mondat jellemzőinek ábrázolását. A transzformátor alapú előrejelző-becslő architektúra esetében három módosítással javítjuk a legmagasabb teljesítményű modellt: több dekódolás használatával a gépi fordító modulban, új modell létrehozásával a transzformátor alapú előrejelzőt XLM alapú előrejelzőre cseréljük, és végül két modellt integrálunk súlyozott átlaggal. Jelentkezésünk Pearson korrelációt ér el 0,664, első helyen (döntetlen) az angol-kínai nyelven.', 'el': 'Η παρούσα εργασία παρουσιάζει την υποβολή του στην Κοινή Εργασία Εκτίμησης Ποιότητας (QE): Προσπάθεια Μεταεπεξεργασίας σε επίπεδο ποινής για Αγγλικά-Κινέζικα στην Εργασία 2. Το σύστημά μας συνδυάζει δύο αρχιτεκτονικές, βασισμένα σε XLM και βασισμένα σε μετασχηματιστή μοντέλα Predictor-Estimator. Για την αρχιτεκτονική Predictor-Estimator με βάση το XLM, ο προγνωστής παράγει δύο τύπους αναπαραστάσεων συμβολαίων με βάση το πλαίσιο, δηλαδή αποκρυπτόμενες και μη αποκρυπτόμενες. ο εκτιμητής LSTM και ο εκτιμητής μετασχηματιστών χρησιμοποιούν δύο αποτελεσματικές στρατηγικές, την προσοχή κορυφής Κ και πολλαπλών κεφαλών, για να ενισχύσουν την αναπαράσταση χαρακτηριστικών της πρότασης. Για την αρχιτεκτονική Predictor-Estimator βασισμένη στον μετασχηματιστή, βελτιώνουμε ένα μοντέλο κορυφαίας απόδοσης πραγματοποιώντας τρεις τροποποιήσεις: χρησιμοποιώντας την πολυαποκωδικοποίηση στην ενότητα μηχανικής μετάφρασης, δημιουργώντας ένα νέο μοντέλο αντικαθιστώντας τον Predictor βασισμένο στον μετασχηματιστή με τον Predictor βασισμένο στο και τέλος ενσωματώνοντας δύο μοντέλα με έναν σταθμισμένο μέσο όρο. Η υποβολή μας επιτυγχάνει συσχέτιση Pearson 0.664, με την πρώτη θέση (ισοπαλία) στα Αγγλικά-Κινέζικα.', 'ka': 'ეს დოკუმენტი გამოსახულება WMT20 კაalitეტის განსაზღვრებას (QE) გაყოფილი რაოდენობა: წესების დოკუმენტის დარედაქტირების შესაძლებლობა ინგლისურ- ჩინეთებისთვის საქმენოში. ჩვენი სისტემა იყენებს ორი არქტიქტურები, XLM-დაბათი და ტრანფორმაციის დაბათი პრედიქტორი-ესტიმატორი მოდელები. XLM-ის პრედიქტორი-ესტიმატორი აქტიქტიქტურისთვის პრედიქტორი გამოიყენება ორი ტიპი კონტექსტუალურად გამოსახულებების, მასკურად XLM და არ-მასკურად XLM-ს; LSTM-სტიმატორი და ტრანფორმატორი-სტიმატორი გამოყენებს ორი ეფექტიური სტრატეგრატიები, top-K და multi-head ინტერნექტირება, რომელიც გამოყენებს სიტყვების განსაზღვრულებ რპანჟტორმენტერის დაბათი პრედიქტორის-ვსტიმატორის აქტიქტიქტურისთვის, ჩვენ სამი შეცდომების გავაკეთებთ მანქანის გადარგუნების მოდულის მრავალე გამოყენება, ახალი მოდულის შექმნა, XLM დაბათი პროგრამეტრის გადარგუნებით, და სანამ ორი ჩვენი წარმოდგენა პერსონის კორელაციას 0,664-ის, პირველი (დაკავშირებული) ინგლისური-კინელი.', 'it': "Questo articolo presenta la presentazione di Tencent al WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-Editing Effort for English-Chinese in Task 2. Il nostro sistema comprende due architetture, modelli Predictor-Estimator basati su XLM e Transformer. Per l'architettura Predictor-Estimator basata su XLM, il predittore produce due tipi di rappresentazioni di token contestualizzate, cioè XLM mascherato e XLM non mascherato; Lo stimatore LSTM e lo stimatore Transformer impiegano due strategie efficaci, l'attenzione top-K e multi-head, per migliorare la rappresentazione delle caratteristiche della frase. Per l'architettura Predictor-Estimator basata su Transformer, miglioriamo un modello performante effettuando tre modifiche: utilizzando la multi-decodifica nel modulo di traduzione automatica, creando un nuovo modello sostituendo il predittore basato su trasformatore con il predittore basato su XLM e infine integrando due modelli con una media ponderata. La nostra presentazione raggiunge una correlazione Pearson di 0,664, classificandosi al primo posto (pari) sull'inglese-cinese.", 'kk': 'Бұл қағаз WMT20 сапасы оқиға (QE) ортақтастырылған тапсырмасына Tencent- деңгейін келтіріп береді: 2- тапсырма ағылшын- қытайша тілдерінің ағылшын- қытайша оқиғаларына сәйкес жұмысы. Біздің жүйеміз екі архитектура, XLM негізінде және түрлендіруші негізінде Predictor-Estimator үлгілерін ұстайды. XLM- негіздеген Predictor- Estimator архитектурасы үшін предсказушы екі түрлі контекстуалды белгілерді көрсетеді, мысалы, XLM қалқалаған және қалқаламаған XLM қалқалаған түрлерді жасайды; LSTM бағалаушы және түрлендіруші бағалаушы екі эффективні стратегия, жоғарғы K және көп басқа бағалаушы, сөйлендіру мүмкіндігін көтеру үшін қолданылады. Трансформацияны негіздеген предиктор оқу архитектурасы үш өзгерту үшін жоғары оқу үлгісін жақсартық: машинаның аудару модулінде көп декодтамасын қолданып, XLM негіздеген прогнозерді алмастыру үшін жаңа үлгісін құрып, екі үлгісін бағалау орташасына Біздің сәйкестігіміз Персондың 0,664-нің корелациясын жеткізеді. Бірінші (тіркелген) ағылшын-қытайша тіркелген (тіркелген).', 'lt': "This paper presents Tencent's submission to the WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-editing Effort for English-Chinese in Task 2.  Mūsų sistema susideda iš dviejų architektūrų, XLM pagrįstų ir transformatorių pagrįstų Prediktoriaus-Estimatoriaus modelių. XLM pagrįstos prognozatorių ir prognozatorių architektūros atveju prognozatorius gamina dviejų tipų kontekstinius žymenų atvaizdavimus, t. y. paslėptą XLM ir neslėptą XLM; LSTM apskaičiuotojas ir Transformer apskaičiuotojas taiko dvi veiksmingas strategijas – didžiausią K ir daugiapakopį dėmesį, kad sustiprintų bausmės charakteristikų atstovavimą. Transformuojant pagrįstą prognozatorių ir prognozatorių architektūrą, mes tobuliname geriausią model į atlikdami tris pakeitimus: naudojant daugiadokodavimą mašin ų vertimo modulyje, sukuriant naują modelį pakeičiant transformatorių pagrįstą prognozatorių XLM pagrįstu prognozatoriu ir galiausiai integruojant du modelius svertiniu vidurkiu. Mūsų teiginyje Pearson koreliacija siekia 0,664, pirmasis rankingas (susietas) anglų ir kinų kalbomis.", 'mk': 'Овој весник го претставува поднесувањето на Тенсент на заедничката задача за проценка на квалитетот на WMT20 (QE): напори на постуредување на речениците за англиско-кинески во задачата 2. Нашиот систем собира две архитектури, XLM-базирани и трансформни предвидувачи-проценувачи модели. За архитектурата на предвидувач-проценувач базирана на XLM, предвидувачот произведува два вида контекстуализирани претставувања на знаци, т.е. маскирани XLM и немаскирани XLM; проценувачот на ЛСТМ и проценувачот на Трансформ користат две ефикасни стратегии, највисокото внимание на К и повеќето глави, за да ја зголемат претставувачката на речениците. За трансформарната архитектура на предвидувач-проценувач, го подобруваме најдобриот модел со спроведување на три модификации: користење на мултидекодирање во модулот за машински превод, создавање на нов модел со замена на предвидувачот базиран на трансформатор со предвидувач базиран на XLM, и конечно интеграција на два модел Нашето поднесување постигнува корелација на Пирсон од 0,664, рангирајќи се прво (врзано) на англиско-кинески.', 'ms': 'Kertas ini memperkenalkan penghantaran Tencent kepada Perkiraan Kualiti WMT20 (QE) Tugas Berkongsi: Effort Sentence-Level Post-Editing untuk Bahasa Inggeris-Cina dalam Tugas 2. Sistem kita mengumpulkan dua arkitektur, XLM-berdasarkan dan Transformer-berdasarkan Predictor-Estimator model. Untuk arkitektur Prediktor-Estimator berasaskan XLM, prediktor menghasilkan dua jenis perwakilan token kontekstualisasi, iaitu XLM bertopeng dan XLM tidak bertopeng; penghargaan LSTM dan penghargaan Transformer menggunakan dua strategi yang berkesan, perhatian atas-K dan berbilang-kepala, untuk meningkatkan perwakilan ciri kalimat. Untuk arkitektur Prediktor-Estimator Berasas Transformer, kami meningkatkan model berfungsi terbaik dengan melaksanakan tiga ubahsuaian: menggunakan multi-dekoding dalam modul terjemahan mesin, mencipta model baru dengan menggantikan prediktor berasaskan transformer dengan prediktor berasaskan XLM, dan akhirnya mengintegrasikan dua model dengan rata-rata berat. Pemberian kami mencapai korelasi Pearson 0.664, ranking pertama (terikat) pada bahasa Inggeris-Cina.', 'mt': 'Dan id-dokument jippreżenta s-sottomissjoni ta’ Tencent lill-Istima tal-Kwalità WMT20 (QE) Kompitu Konġunt: Sforz ta’ wara l-Edizzjoni tal-Livell tas-Sentenza għall-Ingliż-Ċiniż fil-Kompitu 2. Is-sistema tagħna tiġbor flimkien żewġ arkitetturi, mudelli ta’ Predikatur-Estimatur ibbażati fuq XLM u Transformer. Għall-arkitettura tal-Predikatur-Estimatur ibbażata fuq XLM, il-predikatur jipproduċi żewġ tipi ta’ rappreżentazzjonijiet kuntestwalizzati tat-tokens, jiġifieri XLM maskrat u XLM mhux maskrat; l-istimatur tal-LSTM u l-istimatur tat-Transformer jimpjegaw żewġ strateġiji effettivi, l-attenzjoni ta’ fuq K u b’ħafna nies, biex itejbu r-rappreżentanza tal-karatteristiċi tas-sentenza. For Transformer-based Predictor-Estimator architecture, we improve a top-performing model by conducting three modifications: using multi-decoding in machine translation module, creating a new model by replacing the transformer-based predictor with XLM-based predictor, and finally integrating two models by a weighted average.  Is-sottomissjoni tagħna tikseb korrelazzjoni ta’ Pearson ta’ 0.664, bl-ewwel klassifikazzjoni (marbuta) fuq l-Ingliż-Ċiniż.', 'ml': 'ഈ പത്രത്തില്\u200d ഡന്\u200dസെന്\u200dറിന്\u200dറെ കീഴടങ്ങള്\u200d WMT20 ഗുണത്തിന്\u200dറെ എസ്റ്റിമേഷന്\u200d (ക്യൂയി) പങ്കുചേര്\u200dത്ത പണിയിലേക്ക് കൊടുക്കുന്നു. ടാസ്ക് 2 നമ്മുടെ സിസ്റ്റത്തിന്റെ രണ്ട് ആര്\u200dക്കിട്ടറുകള്\u200d, എക്സ്\u200cഎംഎംഎസ്റ്റിമേറ്റര്\u200d അടിസ്ഥാനമായിട്ടുള്ള എക്സ എക്സ്എല്\u200dഎം അടിസ്ഥാനത്തുള്ള പ്രിസ്ട്രിക്ടര്\u200d- എസ്റ്റിമേറ്റര്\u200d ആര്\u200dക്ടിക്കറ്റര്\u200d, പ്രവചിക്കുന്നവന്\u200d രണ്ടു തരം പ്രതിനിധികള്\u200d ഉണ്ടാക്കുന്നു, അതായത ഈ വാക്കിന്റെ പ്രതിനിധിയെ മെച്ചപ്പെടുത്തുന്നതിനായി എല്\u200dഎസ്റ്റിംഎസ്റ്റരും ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200d എസ്റ്റര്\u200d എസ്റ്റിമെന്റി മൂന്നു മാറ്റങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനാല്\u200d മുകളില്\u200d പ്രിസ്ട്രിക്ടര്\u200d എസ്റ്റിമേറ്റര്\u200d എസ്റ്റിമേറ്റര്\u200d സ്ഥാപിക്കുന്ന ഒരു മോഡല്\u200d മെച്ചപ്പെടുത്തുന്നതാണ്: മെഷീന്\u200d പരിഭാഷപ്രഖ്യ ഘടകം  ഞങ്ങളുടെ കീഴ്പ്പെടുത്തിയിരിക്കുന്നത് 0. 664-ന്റെ ബന്ധമാണ്, ആദ്യം ഇംഗ്ലീഷ്-ചൈനീസില്\u200d റാങ്ങിംഗ് ചെയ', 'mn': 'Энэ цаас WMT20 Quality Estimation (QE) хуваалцааны ажил дээр Tencent-ын тайлбарлалтыг тайлбарлаж байна: Хятад хэлний Англи-Хятад хэлний ажил 2-д өгүүлэх үеийн дараа хэвлэх хүсэл. Бидний систем хоёр архитектур, XLM-д суурилсан, Трансформатор-дээр суурилсан Predictor-Estimator загварыг агуулдаг. XLM-д суурилсан Predictor-Estimator архитектурын хувьд таамаглаач нь хоёр төрлийн туршлагатай тодорхойлолтуудыг бүтээж, яг л XLM, гадаргуу биш XLM-г гадаргуулдаг. LSTM-г хүлээн зөвшөөрөх болон Төрвөлдөгч-эрчим хүлээн зөвшөөрөх нь хоёр үр дүнтэй стратеги, дээд-K болон олон толгой анхаарлыг ашигладаг. Трансформатор-суурь дэвшүүлэгч-Estimator архитектурын хувьд бид 3 өөрчлөлт хийж дээд дамжуулагч загварыг сайжруулж, машины орчуулах модульд олон загварыг ашиглаж, XLM-д суурилсан таамаглагчийг өөрчлөхөд шинэ загвар бий болгодог. Эцэст нь 2 загварыг дундаж хэмжээ Бидний хүлээн зөвшөөрөл нь Персон 0.664-тэй холбоотой. Англи-Хятадад анхны холбоотой.', 'no': 'Denne papiret viser Tencent s innføring til WMT20- kvalitetevalueringa (QE) delt oppgåve: Uttrykk- nivå etter redigering av uttrykk for engelsk- kinesisk i oppgåve 2. Sistemet vårt inneheld to arkitektur, XLM-basert og transformeringsbasert førehandsamingsmodeller. For den XLM-baserte arkitekturen «Predictor-Estimator», produserer forhåndsvisinga to typar kontekstualiserte representasjonar, t.d. maskerte XLM og ikkje-maskerte XLM. LSTM-estimatoren og transformeringsestimatoren brukar to effektiv strategiar, topp-K og fleirkopp-oppmerksomhet for å forbetra setningsformet. For transformeringsbasert predikator-estimatingsarkitektur, forbedrar vi ein øvre utføringsmodul ved å gjera tre endringar: bruk fleire dekoding i maskineoversettelsmodulen, laga eit nytt modell ved å byta ut transformeringsbasert predikator med XLM-basert predikator, og til slutt integrerer to modell med ein vekte gjennomsnitt. Vårt søknad oppnår ein Pearson-korrelasjon med 0,664, som rankerer første (tied) på engelsk-kinesisk.', 'ro': 'Această lucrare prezintă depunerea lui Tencent la activitatea partajată WMT20 Quality Estimation (QE): efortul post-editare la nivel de sentință pentru engleză-chineză în activitatea 2. Sistemul nostru combină două arhitecturi, modele bazate pe XLM și modele bazate pe Transformer Predictor-Estimator. Pentru arhitectura Predictor-Estimator bazată pe XLM, predictorul produce două tipuri de reprezentări de token contextualizate, și anume XLM mascat și XLM non-mascat; LSTM-estimatorul și Transformer-estimatorul utilizează două strategii eficiente, top-K și multi-cap atenție, pentru a îmbunătăți reprezentarea caracteristicilor propoziției. Pentru arhitectura Predictor-Estimator bazată pe Transformer, îmbunătățim un model de performanță maximă prin efectuarea a trei modificări: utilizarea decodificării multiple în modulul de traducere automată, crearea unui nou model prin înlocuirea predictorului bazat pe transformator cu predictorul bazat pe XLM și, în cele din urmă, integrarea a două modele cu o medie ponderată. Trimiterea noastră atinge o corelație Pearson de 0.664, clasând primul (egal) pe limba engleză-chineză.', 'pl': 'Niniejszy artykuł przedstawia zgłoszenie Tencent do WMT20 Quality Estimation (QE) Shared Task: Wysiłek post-editing na poziomie zdań dla angielsko-chińskiego w zadaniu 2. Nasz system składa się z dwóch architektur, bazujących na XLM i opartych na Transformerze modeli Predictor-Estimator. W przypadku architektury predictor-Estimator opartej na XLM, predyktor tworzy dwa rodzaje kontekstualizowanych reprezentacji tokenów, tj. maskowany XLM i niemaskowany XLM; LSTM-estymator i Transformer-estymator wykorzystują dwie skuteczne strategie, górną K i wielogłową uwagę, aby zwiększyć reprezentację cech zdania. W przypadku architektury Predictor-Estimator opartej na transformatorze ulepszamy model najwyższej wydajności poprzez przeprowadzenie trzech modyfikacji: wykorzystanie wielokodowania w modułie tłumaczenia maszynowego, tworzenie nowego modelu poprzez zastąpienie predyktora opartego na transformatorze predyktorem opartym na XLM, a na koniec integrację dwóch modeli średnią ważoną. Nasza zgłoszenie osiąga korelację Pearsona o 0.664, rankingu pierwszego (remisowanego) na angielsko-chińskim.', 'sr': 'Ovaj papir predstavlja Tencent podnošenje procjene kvalitete WMT20 (QE) zajedničkog zadatka: nastojanje posledišnjeg redakcije kazne-nivoa za engleski-kineski u zadatku 2. Naš sistem uključuje dve arhitekture, na XLM-bazirane i na transformeru bazirane modele Prediktora-procenatora. Za arhitekturu predsednika-procenatora na XLM-u predsednik proizvodi dve vrste kontekstualiziranih predstavljanja znakova, tj. maskirane XLM i neomaskirane XLM; LSTM-ocjenjivač i procjenjivač transformera koriste dve efikasne strategije, top-K i multiglavne pažnje, kako bi poboljšao predstavljanje rečenice. Za arhitekturu predsednika-procenatora na transformaciji, poboljšavamo vrhunski model provedbe provedbe tri modifikacije: korištenje multidekodiranja u modulu prevoda mašine, stvaranje novog model a zamjenom predsednika na transformaciji baziranog na XLM-u i konačno integriranje dva modela prosječnim težinom. Naša podnošenja postiže korelaciju Pearsona od 0,664, prvi (vezan) na engleski kineski.', 'si': 'මේ පත්තුව ටෙන්සින්ට්ගේ පිළිබඳය WMT20 කුළුවත් අනුමාණය (QE) සමාගත වැඩිය: වාර්තාව- තත්වය පස්සේ සංපාදනය කරන්නේ ඉංග්\u200dරීස්-ච අපේ පද්ධතිය ස්ථාපනය දෙකක්, XLM-පද්ධතිය සහ වෙනස්ථාපනය අධ්\u200dයාපනය කරන්න ප්\u200dරධානකය- අනුමාණකය මදුල් XLM-ආධාරිත ප්\u200dරධානකය-ස්ටිමේටර් ස්ථාපනය සඳහා, ප්\u200dරධානකයෙන් ප්\u200dරධානයක් සඳහා ප්\u200dරධානයක් දෙකක් ප්\u200dරධානයක් තියෙනවා, ඉතින LSTM-විශ්වාස කරනවා සහ ප්\u200dරවර්තනය කරනවා විශ්වාස කරන්න ප්\u200dරයෝජනය දෙකක් ප්\u200dරයෝජනය කරනවා. Name අපේ පර්සන් එක්ක 0.664 වලින් පියර්සන් එක්ක සම්බන්ධයක් ලැබෙනවා, ඉංග්\u200dරීස්-චීනි වලින් පළමු ස්ථානය', 'so': "Kanu warqaddan waxay u dhiibtaa Tencent's submission to the WMT20 Quality Estimation (QE): Sentence-Level post-editing Effort for Ingiriis-Chinese in Task 2. Our system ensembles two architectures, XLM-based and Transformer-based Predictor-Estimator models.  Maxaa yeelay, dhismaha dhismaha XLM e e XLM ku saleysan wuxuu soo saaraa laba nooc oo ka mid ah calaamada xilliga, tusaale ahaan XLM iyo XLM oo aan masked; Qoraalka LSTM-ku qiimeeyaha iyo tartanka hore waxay shaqaynayaan laba strategiyo oo faa’iido leh, labada iskuul-K iyo madax badan, si ay u kordhiso qeybta qaabilsan. Waxaan bedeshaa dhismaha bedelka hore-Estimator, si aan u sameeyo saddex is-beddelka: isticmaalka qalabka tarjumaadda machine badan, oo sameynaya model cusub si uu ugu beddelo predictor-based XLM, ugu dambaystana waxaan ku beddelaynaa laba model oo qiyaas ah. Guushkeennu wuxuu gaadhaa Pearson xiriir 0.664 oo ku qoran afka ingiriiska iyo Shiino.", 'sv': 'Denna uppsats presenterar Tencents bidrag till WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-Editing Ansträngning för engelsk-kinesiska i Uppgift 2. Vårt system består av två arkitekturer, XLM-baserade och Transformer-baserade Predictor-Estimator modeller. För den XLM-baserade Predictor-Estimator-arkitekturen producerar prediktorn två typer av kontextualiserade token representationer, dvs. maskerad XLM och icke-maskerad XLM; LSTM-estimatorn och Transformer-estimatorn använder två effektiva strategier, top-K och multi-head uppmärksamhet, för att förbättra meningsfunktionens representation. För Transformer-baserad Predictor-Estimator arkitektur förbättrar vi en topppresterande modell genom att genomföra tre modifieringar: genom att använda multi-avkodning i maskinöversättningsmodulen, skapa en ny modell genom att ersätta transformatorbaserad prediktor med XLM-baserad prediktor, och slutligen integrera två modeller med ett vägt genomsnitt. Vårt bidrag uppnår en Pearson korrelation på 0,664, rankas först (oavgjort) på engelsk-kinesiska.', 'ta': 'இந்த தாள் WMT20 தரம் கணக்கீடு (QE) பகிர்ந்த பணிக்கு பத்தெண்டின் கூட்டுதலை கூட்டுகிறது: வாக்கியம்- நிலை பின்தொகுப்பு முயற்சியை ஆங்கிலத் எங்கள் கணினியில் இரண்டு கட்டகங்கள், XLM அடிப்படையில் மற்றும் மாற்றி அடிப்படையிலான முன்னேற்றல் எஸ்டிமேடார் மாதி XLM- அடிப்படையிலான முன்னிருப்பாளர் எஸ்டிமேட்டர் உருவாக்குதலுக்கு, முன்னோக்கி இரண்டு வகையான குறியீட்டு பிரிவுகளை உருவாக்கு எல்எஸ்டிஎம் மதிப்பீட்டாளர் மற்றும் மாற்றி மதிப்பீட்டாளர் இரண்டு விளைவான திட்டங்களை, மேல் K மற்றும் பல தலைப்புகள் கவனத்தை மேலேற்றும மாற்றி அடிப்படையிலான முன்னாட்டாளர்- எஸ்டிமேட்டர் உருவாக்கி மூன்று மாற்றங்களை செயல்படுத்தி மாதிரி முறைமையை மேல் செய்ய மாதிரி முறைமையை மேம்பட்டுவிடுகிறோம்: இயந்திர மொழிமாற்றுப் பக எங்கள் சரணங்கள் 0. 664 ஒரு பீர்சன் இணைப்பு பெறுகிறது, ஆங்கிலத்தில்-சீன்களில் முதல் ராங்கிங் முதல் (கட்டியிருக', 'ur': "This paper presents Tencent's submission to the WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-editing effort for English-Chinese in Task 2. ہمارا سیستم دو معماری، XLM بنیاد اور ترنسفور بنیاد پر پیشدیکتور-اسٹیموٹر موڈلز جمع کرتا ہے۔ XLM-based Predictor-Estimator architecture کے لئے، پیش بینی کرنے والا دو نوع متوسط ٹوکنوں کی نمایش کرتا ہے، یعنی XLM اور non-masked XLM کا ماسک کرتا ہے; LSTM-estimator and Transformer-estimator use two effective strategies, top-K and multi-head attention, to enhance the sentence feature representation. تغییر دیکتور-اسٹمیٹر معمار کے لئے، ہم تین بدلوں کے ذریعہ ایک بالا-عملہ موڈل کو بہتر کر رہے ہیں: ماشین ترجمہ موڈلیل میں multi-decoding استعمال کرتے ہیں، تغییر دیکتور-بنیادی پیشگوئر کو XLM-بنیادی پیشگوئر کے ساتھ بدل دیتے ہیں، اور بالاخره دو موڈلیوں کو ایک وزن میڈیل کے ذریعہ ت ہماری مسلمانیت 0.664 کی پیرسون کی تعلق پہنچاتی ہے، انگلیسی-چینی پر پہلی مرتبہ ہے۔", 'uz': "Name Bizning tizimmiz ikkita arxivlar, XLM asosida va Transformer asosiy predictor- Estimator modellarini yaratadi. Name LSTM tashkilotlari va Transfer-Animator ikkita effektiv strategiya, eng yuqori K va ko'plab boshqa boshqaruv fikrlarini oshirish uchun. Transfer- asosiy predictor- Estimator arxituvchisi uchun biz uch oʻzgarishlarni bajarish modelini bajaramiz: Mashining tarjima modulida ko'plab kodlash usuli yordamida yangi modelni yaratish, transformer asosida muhit qiluvchini XLM asosida yaratish uchun yangi modelni yaratish va oxirgi qiymati darajada ikkita modelni birlashtirish mumkin. Bizning imzolarimiz ingliz-Xitoycha (eng xitoycha) bilan birinchi (bog'liq) darajaga 0.664 birinchi darajaga ega bo'ladi.", 'vi': 'Tờ giấy này trình bày s ự đệ trình của nhịn tới dự báo chất lượng WM (QE) với công việc chia sẻ: công việc "Sensence-level Post-eding effort for English-Chinese in Task 2. Hệ thống cho kết hợp hai kiến trúc, mô hình Predator-Estonia dựa vào XMM và Transformer. Đối với cấu trúc Predator-Estonia của XLM, Người dự đoán sản xuất hai kiểu biểu tượng bầu cử theo hình thức, gồm: đeo mặt nạ XLM và XLM không đeo mặt nạ; The LSTM-estimater và Transform-estimater tuyển dụng hai chiến lược hiệu quả, top-K và đa-head attention, to increasing the mast Đặc trưng. Đối với kiến trúc Predactor-Essửa, chúng tôi cải tiến một mô hình đỉnh bằng cách tiến hành ba cải tiến: sử dụng nhiều giải mã trong mô- đun dịch cỗ máy, tạo ra một mô hình mới bằng cách thay thế hệ thống dự đoán dựa vào máy biến hình với bộ đoán dựa trên XLM, và cuối cùng nhập hai mẫu bằng một trung bình cân nặng. Việc đệ trình của chúng tôi đạt đến mối tương quan giữa 0.642, thứ hạng nhất (buộc) và người Anh-Trung Quốc.', 'bg': 'Настоящата статия представя представянето на Тенсънт към споделената задача за оценка на качеството: усилие на ниво присъда за англо-китайски език в задача 2. Нашата система обединява две архитектури, базирани на базата и базирани на трансформатори модели Предсказател-Оценител. За архитектурата на прогнозитор-оценител базирана на XLM, предсказателят произвежда два вида контекстуализирани символни представяния, т.е. маскирани XLM и не маскирани XLM; ЛСТМ-оценителят и трансформаторът-оценителят използват две ефективни стратегии, отгоре-К и многоглавото внимание, за да подобрят представянето на характеристиките на изречението. За архитектурата, базирана на трансформатор, ние подобряваме най-ефективния модел чрез провеждане на три модификации: използване на мулти декодиране в модул за машинен превод, създаване на нов модел чрез замяна на трансформатор базиран предсказател с базиран на и накрая интегриране на два модела с претеглена средна стойност. Нашето представяне постига корелация на Пиърсън от 0.664, класирайки се първо (равенство) на английски-китайски.', 'da': 'Dette indlæg præsenterer Tencents indlæg til WMT20 Quality Estimation (QE) Shared Opgave: Sætningsniveau Post-redigering Indsats for engelsk-kinesisk i Opgave 2. Vores system samler to arkitekturer, XLM-baserede og Transformer-baserede Predictor-Estimator modeller. For den XLM-baserede Predictor-Estimator arkitektur producerer forudsigeren to typer kontekstualiserede token repræsentationer, dvs. maskeret XLM og ikke-maskeret XLM; LSTM-estimatoren og Transformer-estimatoren anvender to effektive strategier, top-K og multi-head opmærksomhed, for at forbedre sætningsfunktionens repræsentation. For Transformer-baseret Predictor-Estimator arkitektur forbedrer vi en topydende model ved at udføre tre ændringer: Brug multi-dekodning i maskinoversættelsesmodulet, skabe en ny model ved at erstatte transformer-baseret predictor med XLM-baseret predictor, og endelig integrere to modeller med et vægtet gennemsnit. Vores indsendelse opnår en Pearson korrelation på 0,664, rangerer først (uafgjort) på engelsk-kinesisk.', 'nl': "Deze paper presenteert Tencent's inzending aan de WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-editing Effort voor Engels-Chinees in Task 2. Ons systeem combineert twee architecturen, XLM-gebaseerde en Transformer-gebaseerde Predictor-Estimator modellen. Voor de op XLM gebaseerde Predictor-Estimator-architectuur produceert de voorspeller twee soorten contextualiseerde tokenrepresentaties, namelijk gemaskerde XLM en niet-gemaskerde XLM; De LSTM-schatter en Transformer-schatter gebruiken twee effectieve strategieën, top-K en multi-head aandacht, om de weergave van de zinnenfunctie te verbeteren. Voor Transformer-gebaseerde Predictor-Estimator architectuur verbeteren we een topmodel door drie aanpassingen uit te voeren: multi-decodering in de machine translation module gebruiken, een nieuw model maken door de transformator gebaseerde predictor te vervangen door een XLM-gebaseerde predictor en ten slotte twee modellen te integreren door een gewogen gemiddelde. Onze inzending bereikt een Pearson correlatie van 0.664, die als eerste (gelijktijdig) staat op Engels-Chinees.", 'hr': 'Ovaj papir predstavlja prijedlog Tencenta procjeni kvalitete WMT20 (QE) zajedničkog zadatka: posturedbeni napor na razini kazne i kazne za engleski kineski u zadatku 2. Naš sustav uključuje dvije arhitekture, XLM-bazirane i transformirane modele predsjednika procjene. Za arhitekturu predsjednika-procjenjivača na XLM-u predsjednik proizvodi dvije vrste kontekstualiziranih predstavljanja znakova, tj. maskirane XLM i neomaskirane XLM; LSTM-ocjenjivač i procjenjivač transformera koriste dvije učinkovite strategije, vrhunsku pažnju K i višeglavnu pažnju kako bi poboljšala predstavljanje rečenice. Za arhitekturu predsjednika-procjenjivača na transformaciji, poboljšavamo vrhunski model provedbe provođenjem tri modifikacije: korištenjem multidekodiranja u modulu prevoda stroja, stvaranjem novog modela zamjenom predsjednika na transformaciji baziranog predsjednika na XLM-u i konačno integriranjem dva modela prosječnim težinom. Naša podnošenja postigne Pearsonovu korelaciju od 0,664, koja prvo postavlja (vezana) na engleski-kineski.', 'de': "Dieses Papier stellt Tencent's Einreichung an die WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-Editing Effort für Englisch-Chinesisch in Task 2 vor. Unser System kombiniert zwei Architekturen, XLM-basierte und Transformer-basierte Predictor-Estimator-Modelle. Für die XLM-basierte Predictor-Estimator-Architektur erzeugt der Prädiktor zwei Arten von kontextualisierten Token-Darstellungen, d. h. maskierte XLM und nicht maskierte XLM; Der LSTM-Schätzer und der Transformer-Schätzer verwenden zwei effektive Strategien, Top-K und Multi-Head Aufmerksamkeit, um die Darstellung von Satzmerkmalen zu verbessern. Für Transformer-basierte Predictor-Estimator-Architektur verbessern wir ein leistungsstärkstes Modell, indem wir drei Modifikationen durchführen: Multi-Decoding im Modul für maschinelle Übersetzung, Erstellen eines neuen Modells durch Ersetzen des transformatorbasierten Prädiktors durch XLM-basierten Prädiktor und schließlich Integration von zwei Modellen durch einen gewichteten Durchschnitt. Unsere Einreichung erreicht eine Pearson Korrelation von 0.664 und rangiert auf Englisch-Chinesisch als Erster (gleichberechtigt).", 'fa': 'این کاغذ تسلیم تنسنت را به ارزیابی کیفیت WMT20 (QE) مشترک کرده است: تلاش بعد از ویرایش مجوز-سطح مجوز برای انگلیسی-چینی در کار ۲. سیستم ما دو معماری را جمع می\u200cکند، مدل\u200cهای پیشدیکتور-ارزیابی بر اساس XLM و تغییر\u200cپذیر بر اساس XLM. برای معماری پیش\u200cدیکتور-ارزیابی بر اساس XLM، پیش\u200cبینی\u200cکننده دو نوع نمایش\u200cهای نشانه\u200cهای متوسطی، یعنی XLM و XLM را ماسک نمی\u200cکند، تولید می\u200cکند. ارزیابی LSTM و ارزیابی ترجمه\u200cکننده دو استراتژی موثر، توجه بالا-K و چند سر، برای افزایش نمایش ویژه\u200cهای جمله استفاده می\u200cکند. برای معماری پیش\u200cنمایش\u200cکننده\u200cی پیش\u200cنمایش\u200cکننده\u200cی پیش\u200cنمایش\u200cکننده\u200cی تغییر\u200cکننده\u200cی تغییر\u200cکننده\u200cی تغییر\u200cکننده، ما یک مدل بالا\u200cنمایش\u200cکننده را با انجام سه تغییر\u200cکننده بهتر می\u200cکنیم: استفاده از مدل\u200cهای تغییر\u200cدهنده\u200cی چندین\u200cدستی در مولد تغییر\u200c تسلیم ما به ارتباط پیرسون 0.664 رسیده است که اولین مرتبط به انگلیسی-چینی است.', 'id': 'Kertas ini memperlihatkan pengiriman Tencent ke Perkiraan Kualitas WMT20 (QE) Tugas Berkongsi: Effort Sentence-Level Post-Editing untuk Bahasa Inggris-Cina dalam Tugas 2. Sistem kita mengumpulkan dua arsitektur, XLM-berdasarkan dan Transformer-berdasarkan Predictor-Estimator model. Untuk arsitektur Prediktor-Estimator berdasarkan XLM, prediktor memproduksi dua jenis representation token kontekstualisasi, i.e., XLM bertopeng dan XLM tanpa bertopeng; penghargaan LSTM dan penghargaan Transformer menggunakan dua strategi efektif, perhatian atas-K dan multi-kepala, untuk meningkatkan representation karakter kalimat. Untuk arsitektur Prediktor-Estimator Berdasarkan Transformer, kami meningkatkan model yang berfungsi terbaik dengan melakukan tiga modifikasi: menggunakan multi-dekoding dalam modul terjemahan mesin, menciptakan model baru dengan menggantikan prediktor berdasarkan transformer dengan prediktor berdasarkan XLM, dan akhirnya mengintegrasikan dua model dengan rata-rata berat. Pengiriman kami mencapai korelasi Pearson 0,664, ranking pertama (terikat) pada Inggris-Cina.', 'sw': 'Gazeti hili linaonyesha ujumbe wa asilimia ya 10 kwa ajili ya Hesabu ya WMT20 (QE) Kushirikishwa na kazi: Jaribio la kuhariri Sentena-Level baada ya Uingereza kwa ajili ya Kiingereza-China katika kazi 2. Mfumo wetu unajumuisha majengo mawili, miundo mbili yenye msingi wa XLM na Mradi wa Udhibiti wa zamani. Kwa ujenzi wa Udhibiti Mkuu wa XLM anayeishi XLM, mtabiri huyo anatengeneza aina mbili ya uwakilishi wa alama za kisiasa, yaani, kifua cha XLM na kifua cha XLM; Mchambuzi wa LSTM na mtazamaji wa zamani wanatumia mikakati miwili yenye ufanisi, mkakati wa juu-K na vichwa vingi, ili kuongeza uwakilishi wa hukumu hiyo. Kwa ajili ya ujenzi wa Udhibiti-Estimator anayeishi zamani, tunaboresha modeli ya juu kwa kufanya mabadiliko matatu: kwa kutumia vifaa vingi vya kutafsiri mashine, kutengeneza muundo mpya kwa kubadilisha mtabiri anayeishi mabadiliko na mtabiri anayeishi XLM, na hatimaye kuunganisha mifano miwili kwa wastani wa wastani. Mawasiliano yetu yanafanikiwa kiungo cha Pearson cha 0.664, cheo cha kwanza (kilichofungwa) katika Kiingereza na Kichina.', 'ko': '본고는 텐센트가 제출한 WMT20 품질 평가(QE) 공유 임무인 임무 2의 영한 문장급 후기 편집 업무를 소개한다.우리 시스템은 XLM과 변압기 기반 예측-추정기 모델을 바탕으로 두 가지 구조를 통합시켰다.XLM을 바탕으로 하는 예측기-추측기 체계 구조에 대해 예측기는 두 가지 상하 문화의 영패 표시, 즉 XLM 차단과 비차단 XLM 차단을 형성한다.LSTM 추정기와 Transformer 추정기는 top-K와 다중 주의 두 가지 효과적인 전략으로 문장의 특징 표시를 강화한다.변압기 기반의 예측기 - 예측기 체계 구조에 대해 우리는 세 가지 수정을 통해 성능이 가장 좋은 모델을 개선했다. 기계 번역 모듈에서 다중 디코딩을 사용하고 변압기 기반의 예측기를 XLM 기반의 예측기로 바꾸어 새로운 모델을 만들고 마지막으로 가중 평균을 통해 두 모델을 집적했다.우리가 제출한 자료의 필슨 상관수는 0.664로 영한 두 언어 중 1위(병렬)였다.', 'tr': "Bu kagyz WMT20 Quality Taýýarlama (QE) Mazmunlary üçin Tensentiň jemgyýetini görkezýär Bizim sistemimiz XLM'e daýanýan we Transformer-daýanýan Prediktor-Estimator nusgalaryny kömekleýär XLM tabanly Prediktor-Taryhçy arhitektura üçin, öňdöwziçi iki tür contekstualized i şaretçilik täze eden, mesela maskeli XLM we maskeli bolmadyk XLM döredir; LSTM-tanyşçy we Transformer-tanyşçy iki täsirli strategiýany, üst-K we köp kelläp ünsüni ýüklemek üçin işleýär. Transformer-daýry Prediktor-Taýramçy arhitektura üçin, üç üýtgewirilýän üçin üst-týtgewirilýän nusgasyny gowurap ýöredýäris: maşynyň terjime modinde multi-ködleme ulanarak, täze bir nusgasyny transformer-daýry öngörünçä XLM tabanly öngörünçä bilen ewez eden, we nihayet iki nusgasyny a ğırlylyk Biziň muňzamyz Pearsonyň 0,664-njy bilen baglanýan ilkinji gezek iňlisçe-Çinçe derejesi bardyr.", 'sq': 'Ky artikull paraqet paraqitjen e Tencensit në WMT20 Quality Estimation (QE) Task Shared: Sentence-Level Post-editing Effort for English-Chinese in Task 2. Sistemi ynë mbledh dy arkitektura, modele me bazë në XLM dhe modele me bazë në Transformer Predictor-Estimator. Për arkitekturën e parashikuesit-vlerësimit me bazë në XLM, parashikuesi prodhon dy lloje përfaqësimesh kontekstuale token, pra XLM të maskuar dhe XLM jo të maskuar; LSTM-vlerësimi dhe Transformer-vlerësimi përdorin dy strategji efektive, vëmendje të lartë K dhe shumë kokash, për të përmirësuar përfaqësimin e karakteristikave të fjalës. Për arkitekturën e parashikuesit me bazë në Transformer, ne përmirësojmë një model me rezultate të larta duke kryer tre modifikime: duke përdorur multi-dekodimin në modulin e përkthimit të makinave, duke krijuar një model të ri duke zëvendësuar parashikuesin me bazë në transformues me parashikuesin me XLM dhe përfundimisht duke integruar dy modele me një mesatare të peshuar. Përdorimi ynë arrin një korrelacion Pearson prej 0.664, renditje e parë (e lidhur) në anglisht-kinez.', 'am': 'ይህ ገጽ የWMT20 ብጤት ስርዓት (QE) የተሰራረበ ስራ ለድንጋጤት-ደረጃ በኋላ አስተካክል ጥቅም ለኢንጂልኛ-ቻይንኛ ስርዓት 2 ያቀርባል፡፡ Our system ensembles two architectures, XLM-based and Transformer-based Predictor-Estimator models.  የXLM-መሠረት መሠረት አካባቢው፣ ትንቢት የሁለት ዓይነት ዓይነት የቆጣጠር ምልክቶች ምረጡ ያቀርባል፤ ምናልባት የXLM እና ያልmasked XLM ነው፡፡ የLSTM-አስተዳደር እና የፊርቨርስቲው ተሟጋቾች፣ በላይ-K እና በብዙ ራስ ጥያቄን ለማበዛት ሁለት ጥያቄዎችን ያስተካክላሉ፡፡ ለTransformer-based Predictor-Estimator መሠረተ ሠንጠረዥ፣ ሦስት ለውጦች በመፈለግ የራስ-አካባቢ ሞዴል እናሳድጋለን፤ በመሳሪያው ትርጉም ሞዴል ውስጥ በብዙ-decoding በመጠቀም እና አዲስ ሞዴል በመለወጥ-based ትንቢት በመለስ በXLM-based ትንቢት በመለስ እናደርጋለን፣ በመጨረሻም ሁለት ዓይነቶች በሚዛን በመተካከል በመጠቀም እናካክላለን። የፊደላችን መልዕክት በንግግሊዝና-ቻይኖች መጀመሪያ (የታሰረ) የርዕስ ግንኙነት 0.664 አግኝቷል፡፡', 'af': "Hierdie papier stel Tencent se onderwerp aan die WMT20 Kwaliteit Estimasie (QE) Gedeelde Opdrag: Sentence- Vlak Post- Redigering Verskaf vir Engels- Sjinees in Taak 2. Ons stelsel versamel twee arkitekturke, XLM-gebaseerde en Transformer-gebaseerde voordektor-Estimator-modele. Vir die XLM-gebaseerde Predictor-Estimator-arkitektuur, produseer die voorskouer twee tipe kontekstualiseerde teken-voorskou, t.d. maskeerde XLM en nie-maskeerde XLM; en Die LSTM-estimatiseerder en Transformer-estimatiseerder gebruik twee effektief strategies, bo-K en multikop aandag, om die sin-funksie voorstelling te verbeter. Vir Transformer-gebaseerde Predictor-Estimator-arkitektuur, verbeter ons 'n bo-uitvoerde model deur drie veranderinge te doen: gebruik multi-dekoding in masjien vertaling module, skep 'n nuwe model deur die transformer-gebaseerde voorskouer met XLM-gebaseerde voorskouer te vervang, en eindelik integreer twee modele deur 'n gewigte gemiddelde. Ons ondersteuning verkry 'n Pearson korrelasie van 0,664, ranking eerste (verbind) op Engels-Sinees.", 'hy': "Այս հոդվածը ներկայացնում է Թենսենսի ներկայացումը ԱՄԹ20-ի որակի գնահատման (QE) ընդհանուր հանձնարարության համար. 2-րդ հանձնարարության ընթացքում անգլերեն-չինական հանձնարարություն: Մեր համակարգը համադրում է երկու ճարտարապետական կառուցվածք, XLM-ի և Transforme-ի հիմնված կանխատեսողի-գնահատողի մոդելներ: XLM-ի հիմնված կանխատեսողի-գնահատողի ճարտարապետության համար կանխատեսողը ստեղծում է երկու տեսակի կոնտեքստիալացված նշանների ներկայացումներ, այսինքն, XLM-ի պատկերացումը և ոչ-պատկերված XLM-ը: LSMT-ի և Transforme-ի գնահատողները օգտագործում են երկու արդյունավետ ստրատեգիաներ, լավագույն K-ի և բազմագլխավոր ուշադրություն, որպեսզի բարելավեն նախադասությունների ներկայացումը: Երեք փոփոխություններ կատարելագործելով' օգտագործելով բազմակոդացման մեխանիզմի թարգմանման մոդուլը, ստեղծելով նոր մոդել, փոխարինելով թարգմանման հիմնված կանխատեսողը XLM-ով և վերջապես ինտեգրելով երկու մոդելը կշռված միջինով: Մեր ներկայացումը հասնում է Պիրսոնի հարաբերակցության 0,664-ի, առաջինը (կապված) է անգլերեն-չինարեն:", 'bn': 'এই পত্রিকাটি WMT20 মান গণনা (কিউই) শেয়ার করা কাজের প্রতি টেনেন্সেন্ট প্রদান করেছে: কাজে ইংরেজী ও চীনের জন্য শাস্তি-স্তরের পরিসম্পাদনের প্ আমাদের সিস্টেম দুটি প্রতিষ্ঠান, এক্সএলএম ভিত্তিক এবং ট্রান্সফার ভিত্তিক প্রেসিডেক্টর-এস্টিমেটর মডেল এক্সএলএম-ভিত্তিক প্রেসিক্রেটর-এস্টিমেটর আর্কিটারেক্টারের জন্য প্রাক্ষদর্শী দুটি ধরনের প্রতিনিধিত্ব তৈরি করেন, যেমন এক্সএলএম ম মুখোশিত এলস্টিএম-হিসাবেক্টর এবং ট্রান্সফেক্রান্সভার হিসেবে দুটি কার্যকর কৌশল, শীর্ষ কে- এবং বহুমাথার মনোযোগ প্রদান করে, যাতে এই বাক ট্রান্সফারের ভিত্তিক ভিত্তিক প্রেসিক্রেটর-এস্টিমেটর আর্কিটেক্টারের জন্য আমরা তিনটি পরিবর্তন করার মাধ্যমে একটি শীর্ষ-প্রদর্শনী মডেল উন্নত করি: মেশিন অনুবাদ মডিউলে বহুভিত্তিক ডিকোডিং ব্যবহার করে, এক নত আমাদের আত্মসমর্পণের মাধ্যমে পেয়ারসনের সংশ্লিষ্ট সংশ্লিষ্ট প্রাপ্ত হয়েছে, যা ইংরেজী ও চীনের প্রথম (বাধা)', 'bs': 'Ovaj papir predstavlja podatke Tencenta na procjenu kvalitete WMT20 (QE) zajedničkog zadatka: nastojanje posle editiranja kazne-nivoa za engleski-kineski u zadatku 2. Naš sistem uključuje dvije arhitekture, na XLM-bazirane i na transformaciji bazirane predsjedničke procjene. Za arhitekturu predsjednika-procjenator na XLM-u predsjednik proizvodi dvije vrste kontekstualiziranih predstavljanja znakova, tj. maskirane XLM i ne maskirane XLM; LSTM-procjenjivač i procjenjivač transformera koriste dvije efikasne strategije, top-K i multiglavne pažnje, kako bi poboljšao predstavljanje rečenice. Za arhitekturu predsjednika-procjenjivača na transformaciji, poboljšavamo vrhunski model provedbe provođenjem tri modifikacije: korištenjem multidekodiranja u modulu prevoda mašine, stvaranjem novog modela zamjenom predsjednika na transformaciji baziranog predsjednika na XLM-u i konačno integriranjem dva modela prosječnim težinom. Naša podnošenja postiže Pearsonovu korelaciju od 0,664, koja prvo postavlja (vezana) na engleski-kineski.', 'ca': "Aquest article presenta la presentació del Tencent a la tasca compartida d'estimació de qualitat WMT20: esforç post-edició de nivell de condemna per anglès-xinès a la tasca 2. El nostre sistema agrupa dues arquitectures, models de Predictor-Estimator basats en XLM i Transformer. Per a l'arquitectura de Predictor-Estimator basada en XLM, el predicator produeix dos tipus de representacions contextualitzades de fitxes, és a dir, XLM mascarat i XLM no mascarat; l'estimador LSTM i l'estimador Transformer empreguen dues estratègies efectives, atenció superior a K i multicapa, per millorar la representació de les característiques de frases. Per a l'arquitectura de Predictor-Estimator basada en Transformer, millorem un model de millor rendiment fent tres modificacions: utilitzant multidecodificació en módul de traducció de màquines, creant un nou model substituint el preditor basat en transformador per un preditor basat en XLM, i finalment integrant dos models per una mitjana ponderada. Our submission achieves a Pearson correlation of 0.664, ranking first (tied) on English-Chinese.", 'az': "Bu kağıt WMT20 keyfiyyəti Nömrəs in ə (QE) paylaşdırılmış Gözməyə Tencent'in göndərilməsini göstərir: Sözüm-seviyyəti İngilizə-Çinlizə 2. Gözmədə İngilizə-Çinlizə müəyyən edilməsi üçün QE. Bizim sistemimiz iki arhitektir, XLM-ə dayanan və Transformer-ə dayanan Predictor-Estimator modellərini yazır. XLM-ə dayanan Predictor-Estimator arhitektüsü üçün öndəyici iki növ contextualized token göstəricisi, məsələn, maski XLM və maski olmayan XLM yaradır; LSTM-estimator və Transformer-estimator iki effektiv strateji, top-K və çox başlıq təsirini artırmaq üçün istifadə edir. Transformer-tabanlı Predictor-Estimator arhitektüsü üçün, üç dəyişiklik işlədərək üst-performans modelini yaxşılaşdırırıq: maşın çeviri modulunda çoxlu kodlama işlədirik, transformer-tabanlı predictor XLM-ə dayanan predictor ilə yeni modeli yaradırıq, sonunda iki modeli a ğırlı ortalama ilə birləşdiririk. Bizim müsəlmanımız Pearson'un 0,664 ilə ilk dərəcə İngilizə-Çinlə bağlı bir bağlantısını başa çatdı.", 'et': 'Käesolevas dokumendis esitatakse Tencenti esitus WMT20 kvaliteedi hindamise (QE) jagatud ülesandele: lausetaseme järeltöötamise jõupingutus inglise-hiina keele jaoks ülesandes 2. Meie süsteem koosneb kahest arhitektuurist, XLM-põhisest ja Transformer-based Predictor-Estimator mudelist. XLM-põhise ennustaja-estimaatori arhitektuuri puhul toodab ennustaja kahte tüüpi kontekstualiseeritud märgi esitusi, st maskeeritud XLM ja maskeeritud XLM; LSTM-estimaator ja Transformer-estimator kasutavad kahte tõhusat strateegiat, top-K ja multi-head tähelepanu, et parandada lausefunktsioonide esitust. Transformer-based Predictor-Estimator arhitektuuri puhul parandame tipptasemel mudelit, viies läbi kolme modifikatsiooni: mitme dekodeerimise kasutamine masintõlkemoodulis, uue mudeli loomine, asendades trafopõhise prognoosi XLM-põhise prognoosiga ja lõpuks integreerides kaks mudelit kaalutud keskmise abil. Meie esitus saavutab Pearsoni korrelatsiooni 0,664, mis on esimene (viigis) inglise-hiina keeles.', 'cs': 'Tento příspěvek představuje Tencent podání k WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-editing Effort pro anglicko-čínštinu v úkolu 2. Náš systém sestavuje dvě architektury, založené na XLM a Transformer-based Predictor-Estimator modely. Pro architekturu prediktoru a odhadu založenou na XLM vytváří prediktor dva typy kontextualizovaných reprezentací tokenů, tj. maskovaný XLM a nemaskovaný XLM; LSTM-estimátor a Transformer-estimátor používají dvě efektivní strategie, top-K a multi-head pozornost, ke zlepšení reprezentace prvků věty. Pro architekturu prediktorů-odhadů založenou na transformátoru zlepšujeme nejvýkonnější model provedením tří modifikací: použitím multidekódování v modulu strojového překladu, vytvořením nového modelu nahrazením prediktoru založeného na transformátoru prediktorem založeným na XLM a nakonec integrací dvou modelů váženým průměrem. Náš příspěvek dosahuje Pearsonovy korelace 0.664, která se na anglicko-čínštině pořadí jako první.', 'fi': 'Tämä artikkeli esittelee Tencentin julkaisun WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-editing Effort for English-Chinese in Task 2. Järjestelmämme koostuu kahdesta arkkitehtuurista, XLM-pohjaisesta ja Transformer-pohjaisesta Predictor-Estimator-mallista. XLM-pohjaisessa Predictor-Estimator-arkkitehtuurissa ennuste tuottaa kahdentyyppisiä kontekstualisoituja token-esityksiä, eli masked XLM ja non masked XLM; LSTM-estimaattori ja Transformer-estimaattori käyttävät kahta tehokasta strategiaa, top-K ja multi-head huomio, parantamaan lauseen ominaisuuksia. Transformer-based Predictor-Estimator -arkkitehtuurissa parannamme huippusuorituskykyistä mallia tekemällä kolme modifikaatiota: käyttämällä monidekoodausta konekäännösmoduulissa, luomalla uuden mallin korvaamalla muuntajapohjainen ennuste XLM-pohjaisella ennusteella ja lopuksi integroimalla kaksi mallia painotetulla keskiarvolla. Toimituksemme saavuttaa Pearsonin korrelaation 0,664, sijoittuen ensin (tasan) englanti-kiinan.', 'he': 'העבודה הזו מציגה את השימוש של טנסנט למשימה משותפת של הערכת איכות WMT20: מאמץ לאחר העורה של גזר-גזר למשימה 2 לאנגלית-סינית. המערכת שלנו מארגנת שני ארכיטקטורות, דוגמנים ממבוססים על XLM ומבוססים על Transformer-Predictor-Estimator. עבור הארכיטקטורה של המערכת הקדמית המבוססת על XLM, הקדמית מייצרת שני סוגים של מיצוגי סימנים קונטוקטואליזציאלים, כלומר, XLM מסוכים ולא מסוכים XLM; מערכת LSTM והמערכת טרנספורר משתמשות בשני אסטרטגיות יעילות, תשומת לב גבוהה של K ומרבה ראשים, כדי לשפר את מייצג תכונות המשפט. עבור ארכיטקטורת המבוססת על "Predictor-Estimator-Transformer", אנחנו משתפרים מודל מופעיל ביותר על ידי ביצוע שלושה שינויים: בשימוש של multi-decoding במודל התרגום מכונות, ליצור מודל חדש על ידי החליפה של המבוסס על "Predictor-based predictor" על ידי "XLM-based predictor", ולבסוף לשתלב שני מודלים על ידי ממוצ השימוש שלנו משיג קשר פירסון של 0.664, הדרגה הראשונה (קשורה) על אנגלי-סיני.', 'sk': 'Ta prispevek predstavlja Tencentovo predložitev skupni nalogi ocene kakovosti WMT20: napor po urejanju na ravni stavkov za angleško-kitajsko v nalogi 2. Naš sistem sestavlja dve arhitekturi, XLM-osnovani in transformatorski modeli Predictor-Estimator. Za arhitekturo Predictor-Estimator, ki temelji na XLM, napovedovalec proizvaja dve vrsti kontekstualiziranih predstavitev žetonov, tj. maskirane XLM in nemaskirane XLM; LSTM-estimator in Transformer-estimator uporabljata dve učinkoviti strategiji, top-K in multi-head pozornost, da izboljšata predstavitev stavka. Pri arhitekturi Predictor-Estimator na podlagi transformatorjev smo izboljšali najboljši model z izvedbo treh modifikacij: z uporabo več dekodiranja v modulu strojnega prevajanja, ustvarjanjem novega modela z zamenjavo napovednika na podlagi transformatorja z napovednikom na osnovi XLM in končno integracijo dveh modelov s tehtanim povprečjem. Naša predložitev doseže Pearsonovo korelacijo 0,664 in se uvršča na prvo mesto (izenačeno) na angleško-kitajsko.', 'jv': 'Gambar iki nggawe Sistem aturan kanggo Sistem penting kanggo nggawe kalite luwih nggambar WWT (XE) Sampeyan Taaksi: Sentense-evel Sistem awak dhéwé énglemi sistem iki architecture, XLM-basa lan Transformer-basa predikor-Esmatior model. Ngawe architecture prediktor-estema sing basa gambar XLM, supoyo penanguntator kuwi angkang sampeyan duwé kalih pawaran Manual contextual, t.d. XLM karo akeh basa gambar dan XLM kuwi mau; yo sampeyan lan tambah penting For Transformer Awakdhéwé nggunaké perusahaan nggawe 0,6, dadi tanggal tuakaké Inggris-Chinese.', 'ha': "@ item Spelling dictionary Our system ensembles two architectures, XLM-based and Transformer-based Predictor-Estimator models.  @ label: listbox Mai gaskatawa na LTRM da mai fassarar-mai fassarar aiki na aikin takwai biyu masu inganci, ma'abũcin-K da mulki-nau'in, dõmin ya ƙara muhimmin rubutun. @ info: whatsthis MusuluncinMu ya sami wani ma'aunin Pearson na 0.664, rankin ta farko (banda) a kan Ingiriya-Kiitcha.", 'bo': 'ཤོག་བྱང་འདིས་WMT20 རིགས་གཟུགས་རིས་ལ་བསམ་བློ་གཏོང་པ་དང་མཉམ་དུ་སྤྱད་ན། བློ་གཏོང་ནི་གནས་ཚུལ་གཞི་གནས་སྟངས་ལ་བསྒྱུར་བཅོས་བྱེད་ནི་ཨིན་ར ང་ཚོའི་མ་ལག་གིས་བཟོ་བརྩིས་གཞི་གཉིས་དང་། XLM་གཞི་བརྟེན་ནས་བཟོ་བཅོས་བྱེད་ཀྱི་Predictor-Estimator Model ལ་མཚོན་གྱི་ཡོད། XLM-based Predictor-Estimator architecture, the predictor produces two types of contextualized token representations, i.e., masked XLM and non-masked XLM; for the XLM based Predictor-Estimator architecture; the LSTM-estimator and Transformer-estimator employ two effective strategies, top-K and multi-head attention, to enhance the sentence feature representation. For Transformer-based Predictor-Estimator architecture, we improve a top-performing model by conducting three modifications: using multi-decoding in machine translation module, creating a new model by replacing the transformer-based predictor with XLM-based predictor, and finally integrating two models by a weighted average. ང་ཚོའི་དབྱིབས་ཡུལ་གྱི་ཚོར་མཐུན་འགྱུར་བ་ཞིག་དང་མཐུན་རྐྱེན་ཐུབ་ཀྱི་ཡོད།'}
{'en': 'NLPRL System for Very Low Resource Supervised Machine Translation', 'ar': 'نظام NLPRL للترجمة الآلية الخاضعة للإشراف منخفضة الموارد', 'fr': 'Système NLPRL pour la traduction automatique supervisée à très faibles ressources', 'pt': 'Sistema NLPRL para Tradução Automática Supervisionada de Recursos Muito Baixos', 'es': 'Sistema NLPRL para traducción automática supervisada de muy pocos recursos', 'ja': '非常に低いリソースで監視された機械翻訳のためのNLPRLシステム', 'zh': '用于极低资源监机器翻译之 NLPRL 统', 'hi': 'बहुत कम संसाधन पर्यवेक्षित मशीन अनुवाद के लिए NLPRL प्रणाली', 'ru': 'Система NLPRL для очень низкого ресурса контролируемого машинного перевода', 'ga': "Córas NLPRL d'Aistriúchán Meaisín faoi Mhaoirseacht Acmhainne An-Íseal", 'ka': 'Name', 'el': 'Σύστημα μηχανικής μετάφρασης με πολύ χαμηλή εποπτεία πόρων', 'hu': 'NLPRL rendszer a nagyon alacsony erőforrás-felügyelt gépi fordításhoz', 'it': 'Sistema NLPRL per traduzione automatica supervisionata con risorse molto basse', 'lt': 'NLPRL sistema, skirta labai mažų išteklių kontroliuojamam mašinų vertimui', 'mk': 'Name', 'kk': 'Comment', 'ms': 'NLPRL System for Very Low Resource Supervised Machine Translation', 'ml': 'വളരെ കുറഞ്ഞ വിഭവങ്ങള്\u200dക്കുള്ള NLPRL സിസ്റ്റം', 'mt': 'Sistema NLPRL għat-Traduzzjoni ta’ Makkinarju b’Riżorsi Bażi Ħafna Sorveljat', 'mn': 'NLPRL Бага Баасны Машины Хэрэглэгчийн Үйлдлийн систем', 'no': 'NLPRL- systemet for svært låg ressursoversikt av maskineomsetjing', 'pl': 'System NLPRL dla tłumaczeń maszynowych nadzorowanych bardzo niskimi zasobami', 'sr': 'Name', 'ro': 'Sistem NLPRL pentru traducere automată supravegheată cu resurse foarte scăzute', 'si': 'Name', 'so': 'NLPRL System for Very Low Resource Supervised Machine Translation', 'ta': 'மிகவும் குறைந்த மூலத்திற்கான NLPRL அமைப்பு', 'sv': 'NLPRL System för mycket låg resursövervakad maskinöversättning', 'ur': 'Name', 'uz': 'Name', 'vi': 'Hệ thống NLLLRL cho trình dịch phụ tùng nhiều tài nguyên thấp', 'da': 'NLPRL System til meget lav ressource overvåget maskinoversættelse', 'bg': 'Система за машинен превод с много ниски ресурси', 'hr': 'Name', 'nl': 'NLPRL-systeem voor zeer lage resource supervised machinevertaling', 'de': 'NLPRL System für maschinelle Übersetzung mit sehr geringem Ressourcenaufwand', 'ko': '최소 리소스 모니터링 머신 번역을 위한 NLPRL 시스템', 'sw': 'Mfumo wa NLPRL kwa rasilimali chini unaohusu Tafsiri ya Mashine', 'tr': 'NLPRL Mazmunlar Bejerilmiş Mazmunlar terjimesi üçin Mazmunlar', 'af': 'Name', 'fa': 'Name', 'am': 'ምርጫዎች', 'hy': 'Շատ ցածր ռեսուրսների վերահսկվող մեքենայի թարգմանման համար', 'sq': 'NLPRL System for Very Low Resources Supervised Machine Translation', 'az': 'NLPRL Çox düşük ressurs Gözlənmiş Makin Çeviri Sistemi', 'bn': 'Name', 'id': 'Sistem NLPRL untuk Penerjemahan Mesin yang DiSupervisi Sumber Banyak', 'et': 'NLPRL süsteem väga madala ressursi järelevalvega masintõlke jaoks', 'cs': 'NLPRL systém pro strojový překlad s velmi nízkými zdroji', 'fi': 'NLPRL-järjestelmä erittäin alhaisen resurssin valvottuun konekäännökseen', 'bs': 'Name', 'ca': 'NLPRL System for Very Low Resources Supervised Machine Translation', 'jv': 'NLPRL System kanggo Perintah sing paling kelompok', 'sk': 'Sistem NLPRL za strojno prevajanje z zelo nizkimi viri', 'bo': 'NLPRL མ་ཟད་པོ་རྫུན་པ་ལྟ་རུང་བའི་མ་ལག་གི་སྐད་ཡིག་གནང་འཇུག་བྱེད་པ', 'ha': '@ action', 'he': 'Name'}
{'en': 'This paper describes the results of the system that we used for the WMT20 very low resource (VLR) supervised MT shared task. For our experiments, we use a byte-level version of BPE, which requires a base vocabulary of size 256 only. BPE based models are a kind of sub-word models. Such models try to address the Out of Vocabulary (OOV) word problem by performing word segmentation so that segments correspond to morphological units. They are also reported to work across different languages, especially similar languages due to their sub-word nature. Based on BLEU cased score, our NLPRL systems ranked ninth for HSB to GER and tenth in GER to HSB translation scenario.', 'ar': 'تصف هذه الورقة نتائج النظام الذي استخدمناه لمهمة MT المشتركة الخاضعة للإشراف WMT20 منخفضة للغاية (VLR). بالنسبة لتجاربنا ، نستخدم إصدارًا على مستوى البايت من BPE ، والذي يتطلب مفردات أساسية بحجم 256 فقط. النماذج القائمة على BPE هي نوع من نماذج الكلمات الفرعية. تحاول مثل هذه النماذج معالجة مشكلة الكلمات خارج المفردات (OOV) عن طريق إجراء تجزئة للكلمات بحيث تتوافق المقاطع مع الوحدات الصرفية. تم الإبلاغ أيضًا عن عملهم عبر لغات مختلفة ، لا سيما اللغات المتشابهة نظرًا لطبيعة الكلمات الفرعية. استنادًا إلى درجة حالة BLEU ، احتلت أنظمة NLPRL المرتبة التاسعة بالنسبة لـ HSB إلى GER والعاشر في سيناريو الترجمة من GER إلى HSB.', 'fr': 'Cet article décrit les résultats du système que nous avons utilisé pour la tâche partagée MT supervisée WMT20 à très faible ressource (VLR). Pour nos expériences, nous utilisons une version au niveau octet de BPE, qui nécessite un vocabulaire de base de taille 256 uniquement. Les modèles basés sur le BPE sont une sorte de modèles de sous-mots. De tels modèles tentent de résoudre le problème des mots hors vocabulaire (OOV) en effectuant une segmentation des mots de sorte que les segments correspondent à des unités morphologiques. Ils travailleraient également dans différentes langues, en particulier des langues similaires en raison de leur nature de sous-mots. Sur la base du score cased de BLEU, nos systèmes NLPRL se sont classés neuvième pour le scénario de traduction HSB vers GER et dixième pour le scénario de traduction GER vers HSB.', 'pt': 'Este artigo descreve os resultados do sistema que usamos para a tarefa compartilhada de MT supervisionada de recursos muito baixos (VLR) do WMT20. Para nossos experimentos, usamos uma versão de nível de byte do BPE, que requer apenas um vocabulário básico de tamanho 256. Os modelos baseados em BPE são uma espécie de modelos de subpalavras. Esses modelos tentam resolver o problema da palavra Fora do Vocabulário (OOV) realizando a segmentação de palavras de modo que os segmentos correspondam a unidades morfológicas. Eles também são relatados para trabalhar em diferentes idiomas, especialmente idiomas semelhantes devido à sua natureza de subpalavra. Com base na pontuação do BLEU, nossos sistemas NLPRL ficaram em nono lugar para HSB para GER e décimo no cenário de tradução de GER para HSB.', 'es': 'Este documento describe los resultados del sistema que utilizamos para la tarea compartida de MT supervisada de muy pocos recursos (VLR) de WMT20. Para nuestros experimentos, utilizamos una versión de BPE a nivel de bytes, que requiere un vocabulario base de tamaño 256 únicamente. Los modelos basados en BPE son una especie de modelos de subpalabras. Estos modelos tratan de abordar el problema verbal Out of Vocabulary (OOV) mediante la segmentación de palabras de manera que los segmentos correspondan a unidades morfológicas. También se dice que funcionan en diferentes idiomas, especialmente en idiomas similares debido a la naturaleza de sus subpalabras. Según la puntuación de casos de BLEU, nuestros sistemas NLPRL ocuparon el noveno lugar en el escenario de traducción de HSB a GER y el décimo en el escenario de traducción de GER a HSB.', 'ja': 'WMT 20の超低資源（ VLR ）監視型MT共有タスクに使用したシステムの結果を説明した。実験では、サイズ256の基本語彙のみを必要とするBPEのバイトレベルのバージョンを使用します。BPEベースのモデルは、サブワードモデルの一種。そのようなモデルは、セグメントが形態的単位に対応するように、単語セグメンテーションを実行することによって、Out of Vocabulary （ OOV ）単語の問題に対処しようとする。また、サブワードの性質上、異なる言語、特に類似の言語で動作することも報告されています。BLEUケーススコアに基づいて、当社のNLPRLシステムは、HSBからGERで9位、GERからHSBへの翻訳シナリオで10位でした。', 'hi': 'यह पेपर उस सिस्टम के परिणामों का वर्णन करता है जिसका उपयोग हमने WMT20 बहुत कम संसाधन (VLR) पर्यवेक्षित एमटी साझा कार्य के लिए किया था। हमारे प्रयोगों के लिए, हम बीपीई के बाइट-स्तर के संस्करण का उपयोग करते हैं, जिसके लिए केवल आकार 256 की आधार शब्दावली की आवश्यकता होती है। बीपीई आधारित मॉडल एक प्रकार के उप-शब्द मॉडल हैं। इस तरह के मॉडल शब्द विभाजन का प्रदर्शन करके शब्दावली से बाहर (ओओवी) शब्द समस्या को संबोधित करने का प्रयास करते हैं ताकि खंड रूपात्मक इकाइयों के अनुरूप हों। उन्हें विभिन्न भाषाओं में काम करने की भी सूचना दी जाती है, विशेष रूप से उनकी उप-शब्द प्रकृति के कारण समान भाषाएं। BLEU cased स्कोर के आधार पर, हमारे NLPRL सिस्टम HSB के लिए GER के लिए नौवें स्थान पर और HSB अनुवाद परिदृश्य के लिए GER में दसवें स्थान पर हैं।', 'ru': 'В этой статье описываются результаты системы, которую мы использовали для совместной задачи MT с очень низким уровнем ресурсов (VLR) под надзором WMT20. Для наших экспериментов мы используем версию BPE на уровне байтов, которая требует только базового словаря размера 256. Модели, основанные на BPE, являются своего рода моделями подслов. Такие модели пытаются решить проблему слов из словаря (OOV), выполняя сегментацию слов таким образом, чтобы сегменты соответствовали морфологическим единицам. Сообщается также, что они работают на разных языках, особенно на аналогичных языках, в силу их подсловного характера. Основываясь на оценке по BLEU, наши системы NLPRL заняли девятое место по HSB по сравнению с GER и десятое по GER по сравнению со сценарием перевода HSB.', 'zh': '本文引我以 WMT20 极低资源 (VLR) 监之机器翻译共其统也。 于我实验,我用字节级版本之 BPE,惟大小为 256 词汇表。 基于BPE者,一子词也。 尝试分词以决之词汇量不足 (OOV) 单词,以应形势。 据报道,他还用不同的语言,特别由于子词性质而相似的语言。 据BLEU例得分,余 NLPRL 系统于 HSB 至 GER 中第九,于 GER 至 HSB 译场中第十。', 'ga': 'Déanann an páipéar seo cur síos ar thorthaí an chórais a d’úsáideamar don tasc comhroinnte MT faoi acmhainn an-íseal (VLR) WMT20. Le haghaidh ár dturgnaimh, bainimid úsáid as leagan leibhéal beart de BPE, a éilíonn foclóir bonn de mhéid 256 amháin. Is cineál samhlacha fo-fhocail iad samhlacha atá bunaithe ar BPE. Déanann samhlacha dá leithéid iarracht aghaidh a thabhairt ar fhadhb na bhfocal As Stór Focal (OOV) trí dheighilt focal a dhéanamh ionas go gcomhfhreagraíonn míreanna d’aonaid mhoirfeolaíocha. Tuairiscítear freisin go n-oibríonn siad thar theangacha éagsúla, go háirithe teangacha comhchosúla mar gheall ar a nádúr fo-fhocail. Bunaithe ar scór cásáilte BLEU, bhí ár gcórais NLPRL sa naoú háit do HSB go GER agus sa deichiú háit i gcás aistriúcháin GER go HSB.', 'el': 'Αυτή η εργασία περιγράφει τα αποτελέσματα του συστήματος που χρησιμοποιήσαμε για την εποπτευόμενη κοινή εργασία ΜΤ με πολύ χαμηλούς πόρους (VLR). Για τα πειράματά μας, χρησιμοποιούμε μια έκδοση σε επίπεδο Byte, η οποία απαιτεί ένα βασικό λεξιλόγιο μεγέθους 256 μόνο. Τα μοντέλα που βασίζονται σε BPE είναι ένα είδος υπολέξεων μοντέλα. Τέτοια μοντέλα προσπαθούν να αντιμετωπίσουν το πρόβλημα λέξεων εκτός λεξιλογίου (OOV) με την εκτέλεση τμημάτων λέξεων έτσι ώστε τα τμήματα να αντιστοιχούν σε μορφολογικές μονάδες. Αναφέρεται επίσης ότι λειτουργούν σε διαφορετικές γλώσσες, ειδικά σε παρόμοιες γλώσσες λόγω της φύσης των υπολέξεων. Βάσει της βαθμολογίας των περιπτώσεων BLEU, τα συστήματά μας κατατάχθηκαν ένατη για HSB σε GER και δέκατη στο σενάριο μετάφρασης GER σε HSB.', 'hu': 'Ez a tanulmány a WMT20 nagyon alacsony erőforrás (VLR) felügyelt MT megosztott feladathoz használt rendszer eredményeit ismerteti. Kísérleteinkhez a BPE bájtszintű verzióját használjuk, amely csak 256-os méretű alapszókincset igényel. A BPE alapú modellek egyfajta alszó modellek. Az ilyen modellek megpróbálják megoldani a szókincsen kívüli (OOV) szóproblémát a szegmentálás végrehajtásával, hogy a szegmensek megfeleljenek a morfológiai egységeknek. A jelentések szerint különböző nyelveken dolgoznak, különösen hasonló nyelveken az alszó jellegük miatt. A BLEU-s eredmények alapján NLPRL rendszereink a 9. helyen álltak a HSB-GER fordítási forgatókönyvben és a 10. helyen a GER-HSB fordítási forgatókönyvben.', 'it': "Questo articolo descrive i risultati del sistema che abbiamo utilizzato per l'attività condivisa MT supervisionata da WMT20 very low resource (VLR). Per i nostri esperimenti, utilizziamo una versione a livello di byte di BPE, che richiede un vocabolario di base di dimensioni 256 solo. I modelli basati su BPE sono una sorta di modelli sotto-parola. Tali modelli cercano di risolvere il problema delle parole Out of Vocabulary (OOV) eseguendo la segmentazione delle parole in modo che i segmenti corrispondano alle unità morfologiche. Si dice inoltre che lavorano in diverse lingue, specialmente lingue simili a causa della loro natura sotto-parola. Sulla base del punteggio cased BLEU, i nostri sistemi NLPRL si sono classificati noni per HSB a GER e decimo nello scenario di traduzione GER a HSB.", 'kk': 'Бұл қағаз WMT20 ресурстар (VLR) үшін қолданылатын жүйенің нәтижесін таңдайды. MT ортақ тапсырманы бақылады. Біздің тәжірибеміз үшін біз BPE байт деңгейінің нұсқасын қолданамыз. Бұл тек 256 өлшемінің негізгі сөздер керек. BPE негіздеген үлгілер бір түрлі ішкі сөз үлгілері. Бұл үлгілер сөздерді шектеу мәселесін өзгерту үшін, сегменттер морфологиялық бірліктерге сәйкес келеді. Олар әртүрлі тілдерде жұмыс істейді, әдетте олардың ішкі сөздерінің қасиетіне сәйкес тілдері. BLEU мөлшерлеріне негізделген NLPRL жүйелеріміз HSB үшін 9-ші ретінде GER және 10-ші GER үшін HSB аудару сценариясына қарады.', 'lt': 'Šiame dokumente apibūdinami sistemos, kuri buvo naudojama WMT20 labai mažai išteklių (VLR) prižiūrimoms bendroms MT užduotims, rezultatai. Mūsų eksperimentams naudojame BPE versiją, kuri reikalauja tik 256 dydžio bazinio žodyno. BPE pagrįsti modeliai yra panašūs į pakalbinius modelius. Tokie modeliai bando išspręsti žodžių problem ą ne žodyne (OOV), atliekant žodžių segmentaciją, kad segmentai atitiktų morfologinius vienetus. Taip pat pranešama, kad jos veikia skirtingose kalbose, ypač panašiose kalbose dėl jų žodžių paviršiaus. Remiantis BLEU įskaičiuotais rezultatais, mūsų NLPRL sistemos buvo devynioji HSB – GER ir dešimtoji GER – HSB vertimo scenarijus.', 'mk': 'Овој документ ги опишува резултатите од системот кој го користевме за многу ниското ресурсно (ВЛР) надгледувана MT заедничка задача. За нашите експерименти, користиме верзија на бајт ниво на БПЕ, која бара базичен речник од големина 256. Моделите базирани на БПЕ се еден вид на модели со подзборови. Таквите модели се обидуваат да го решат проблемот со зборовите надвор од речникот (OOV) со спроведување на сегментација на зборовите за сегментите да одговараат на морфолошките единици. Тие, исто така, се известува дека работат низ различни јазици, особено слични јазици поради нивната природа на подзборот. Based on BLEU cased score, our NLPRL systems ranked ninth for HSB to GER and tenth in GER to HSB translation scenario.', 'ms': 'Kertas ini menggambarkan keputusan sistem yang kami gunakan untuk tugas berkongsi MT yang diawasi oleh sumber WMT20 yang sangat rendah (VLR). Untuk eksperimen kami, kami menggunakan versi aras bait BPE, yang memerlukan vokbulari asas saiz 256 sahaja. Model berdasarkan BPE adalah jenis model sub-kata. Model seperti ini cuba untuk mengatasi masalah perkataan Out of Vocabulary (OOV) dengan melakukan segmen perkataan sehingga segmen sepadan dengan unit morfologik. Mereka juga dilaporkan untuk bekerja melalui bahasa yang berbeza, terutama bahasa yang sama disebabkan sifat sub-kata mereka. Berdasarkan skor BLEU, sistem NLPRL kami berturut sembilan untuk HSB ke GER dan sepuluh dalam skenario terjemahan GER ke HSB.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d WMT20 ഉപയോഗിച്ച സിസ്റ്റത്തിന്റെ ഫലങ്ങള്\u200d വിശദീകരിക്കുന്നു. എംടി പങ്കുചേര്\u200dക്കുന്ന ജോലിയെ വളരെ കുറ For our experiments, we use a byte-level version of BPE, which requires a base vocabulary of size 256 only.  ബിപെയിന്\u200dറെ അടിസ്ഥാനമായ മോഡലുകള്\u200d ഒരു തരം സബ്\u200cവോര്\u200dഡ് മോഡലുകളാണ്. ഈ മോഡലുകള്\u200d വാക്കിന്റെ വാക്കിന്റെ പ്രശ്നം പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനാല്\u200d വാക്കിന്റെ വാക്കുകള്\u200d പ്രശ്നമാക്കുവാന്\u200d ശ്രമി അവയും വ്യത്യസ്ത ഭാഷകളില്\u200d ജോലി ചെയ്യാന്\u200d റിപ്പോര്\u200dട്ട് ചെയ്യപ്പെടുന്നു, പ്രത്യേകിച്ചും അതേ ഭാഷകള്\u200d  ബില്ലു സ്കോര്\u200d അടിസ്ഥാനത്തില്\u200d നമ്മുടെ NLPRL സിസ്റ്റമുകള്\u200d എംഎസ്ബിയ്ക്ക് ഒന്\u200dപതാമത്തേയും GER-ലേക്ക് പത്താമത്തേയും എസ്ബി പരിഭാ', 'mt': "Dan id-dokument jiddeskrivi r-riżultati tas-sistema li użajna għall-kompitu kondiviż ta’ MT superviż b’riżorsa baxxa ħafna (VLR) tad-WMT20. Għall-esperimenti tagħna, a ħna nużaw verżjoni fil-livell tal-byte tal-BPE, li teħtieġ vokabulari bażi tad-daqs 256 biss. Il-mudelli bbażati fuq il-BPE huma tip ta’ mudelli ta’ sottokliem. Dawn il-mudelli jippruvaw jindirizzaw il-problema tal-kliem 'l barra mill-Vokabularju (OOV) billi jwettqu segmentazzjoni tal-kliem sabiex is-segmenti jikkorrispondu ma' unitajiet morfoloġiċi. Huma rrappurtati wkoll li jaħdmu f’lingwi differenti, speċjalment lingwi simili minħabba n-natura ta’ subkelma tagħhom. Abbażi tal-punteġġ ikkawżat mill-BLEU, is-sistemi NLPRL tagħna kklassifikaw id-disa’ għal HSB sa GER u l-għaxar fix-xenarju tat-traduzzjoni GER sa HSB.", 'ka': 'ამ დოკუნტის გამოყენება სისტემის შედეგები, რომლებიც WMT20 მნიშვნელოვანი რესურსისთვის (VLR) გამოყენებული MT გაყოფილი საქმე. ჩვენი ექსპერიმენტებისთვის, ჩვენ გამოვიყენებთ BPE-ის ბაიტის დონეზე ვერსია, რომელიც მხოლოდ 256 ზომის ბაზი სიტყვებულია. BPE ბაზეული მოდელები არიან სუბსიტყვის მოდელები. ასეთი მოდელები მოცდილობენ სიტყვებლის გარეშე (OOV) სიტყვებლის პრობლემების შესახებ სიტყვებლის სექმენტის შესახებ, რომ სექმენტები მოპოროლოგიური ერთეულ ისინი ასევე აღწერებულია განსხვავებული ენების მუშაობას, განსაკუთრებით განსხვავებული ენების მიხედვით. Based on BLEU cased score, our NLPRL systems ranked 9 for HSB to GER and 10 in GER to HSB translation scenario.', 'no': 'Denne papiret beskriver resultatet av systemet vi bruka for WMT20 svært låg ressurs (VLR) som oversikt MT delt oppgåve. For eksperimentet våre bruker vi ein byte- nivåversjon av BPE, som krev berre ein grunnslokkord med storleik 256. BPE-baserte modeller er ein slags underordmodeller. Desse modeller prøver å handsama ordproblemet frå Ut av ordbokstaven (OOV) ved å utføra ordsegmentasjon slik at segmentar tilsvarar morfologiske einingar. Dei er også rapportert om å arbeide på ulike språk, spesielt liknande språk på grunn av underordnaturen. Basert på BLEU-cased score, våre NLPRL-systemet rangerte ni for HSB til GER og tiende i GER til HSB-oversettelsscenario.', 'mn': 'Энэ цаас бидний WMT20-д маш бага боловсруулагч (VLR) MT хуваалцааны ажил дээр хэрэглэсэн системийн үр дүнг тайлбарладаг. Бидний туршилтын тулд бид BPE-ийн байт түвшинд хэрэглэдэг. Энэ нь зөвхөн 256 хэмжээний суурь үг хэрэгтэй. BPE-ын суурь загварууд бол нэг төрлийн суурь үг загвар юм. Ийм загварууд үг хэмжээсүүдтэй холбогдохын тулд үг хэмжээсүүдтэй холбогдохыг хичээдэг. Мөн тэд өөр хэл дээр ажилладаг, ялангуяа адилхан хэл гэх мэт хэл байдаг. БЛЕУ-ын мөнгө тооны үндсэнээр, NLPRL систем нь HSB-ийн 9-нд GER-т, GER-ийн 10-нд HSB-ийн орчуулалтын хувилбар юм.', 'ro': 'Această lucrare descrie rezultatele sistemului pe care l-am folosit pentru activitatea partajată MT supravegheată de WMT20 cu resurse foarte scăzute (VLR). Pentru experimentele noastre, folosim o versiune la nivel de octeți a BPE, care necesită un vocabular de bază de dimensiune 256 numai. Modelele bazate pe BPE sunt un fel de sub-cuvinte modele. Astfel de modele încearcă să abordeze problema cuvântului Out of Vocabulary (OOV) prin efectuarea segmentării cuvintelor astfel încât segmentele să corespundă unităților morfologice. Se raportează, de asemenea, că lucrează în diferite limbi, în special în limbi similare, datorită naturii lor sub-cuvânt. Pe baza scorului cazat BLEU, sistemele noastre NLPRL au ocupat locul 9 pentru HSB la GER și al zecelea în scenariul de traducere GER la HSB.', 'pl': 'Niniejszy artykuł opisuje wyniki systemu, który wykorzystaliśmy do wspólnego zadania MT nadzorowanego przez WMT20 bardzo niskimi zasobami (VLR). Do naszych eksperymentów używamy bajtowej wersji BPE, która wymaga podstawowego słownictwa o rozmiarze 256. Modele oparte na BPE są rodzajem modeli podsłownych. Takie modele próbują rozwiązać problem słowa poza słownictwem (OOV) poprzez wykonanie segmentacji słów tak, aby segmenty odpowiadały jednostkom morfologicznym. Zgłasza się również, że działają w różnych językach, zwłaszcza podobnych językach ze względu na ich podsłowowy charakter. Na podstawie wyników BLEU, nasze systemy NLPRL zajęły dziewiąte miejsce dla HSB na GER i dziesiąte w scenariuszu tłumaczenia GER na HSB.', 'si': 'මේ පත්තේ අපි WMT20 ගැන භාවිත කරපු පද්ධතියේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර අපේ පරීක්ෂණාවට, අපි BPE ගේ බායිට් ස්ථානයක් පාවිච්චි කරනවා, ඒකෙන් ප්\u200dරමාණයක් 256 විතරයි අධාරණ ශබ්ධ BPE අධාරිත මොඩල් වගේ ප්\u200dරමාණයක්. Name ඔවුන්ට වෙනස් භාෂාවල් වලට වැඩ කරන්න පුළුවන්, විශේෂයෙන්ම වගේ භාෂාවල් වලට ඔවුන්ගේ සබ්  BLUE සම්පූර්ණ ස්කෝර් පද්ධතිය පද්ධතියෙන්, අපේ NLPRL පද්ධතියේ HSB සඳහා GER සඳහා GER සඳහා දහසවෙනි HSB පද්ධතියේ ස්කෝර', 'sr': 'Ovaj papir opisuje rezultate sistema koji smo koristili za WMT20 veoma niski resurs (VLR) nadzirani zadatak koji je podijeljen MT. Za naše eksperimente koristimo verziju BPE nivoa bajtova, koja zahteva samo baznu rečnicu veličine 256. Modeli bazirani na BPE-u su vrsta podrečenih modela. Takvi modeli pokušavaju rješavati problem rijeèi iz reèi iz reèi iz rijeèi (OOV) izvršavajuæi segmentaciju reèi tako da segmenti odgovaraju morfološkim jedinicama. Takođe su prijavljeni da rade na različitim jezicima, posebno sličnim jezicima zbog prirode podriječi. Na temelju novčanog rezultata BLEU, naši NLPRL sistemi su bili deveti za HSB do GER i deseti u GER do HSB prevodnog scenarija.', 'sv': 'Denna uppsats beskriver resultaten av det system som vi använde för WMT20 very low resource (VLR) övervakade MT shared task. För våra experiment använder vi en byte-nivå version av BPE, som kräver ett basordförråd av storlek 256 endast. BPE-baserade modeller är ett slags underordsmodeller. Sådana modeller försöker ta itu med ordproblemet Out of Vocabulary (OOV) genom att utföra ordsegmentering så att segment motsvarar morfologiska enheter. De rapporteras också arbeta på olika språk, särskilt liknande språk på grund av deras underordsnatur. Baserat på BLEU-poäng rankades våra NLPRL-system på nionde plats för HSB till GER och tionde i GER till HSB översättningsscenario.', 'so': 'Qoraalkan wuxuu ku qoraa resultinta nidaamka aan u isticmaalnay WMT20, aad u yar resource (VLR) oo maamulay shaqada MT oo la qaybsaday. Imtixaanadeena waxaynu isticmaalnaa warqad heer ah BPE, taasoo loo baahan yahay hadal aasaasi ah oo kaliya qiyaas 256. Tusaalooyinka BPE ee ku saleysan waa noocyo hoos-hadal ah. Such models try to address the Out of Vocabulary (OOV) word problem by performing word segmentation so that segments correspond to morphological units.  Waxaa sidoo kale looga sheegaa in lagu shaqeeyo luuqado kala duwan, khusuusan luuqado kala duwan, sababtoo ah dabiicadooda hoose-hadalka. Sida uu ku saleysan BLEU score cash, nidaamka NLPRL waxay HSB u sawireen sagaalaad ilaa GER iyo toban meelood oo meel ilaa HSB turjumista.', 'ta': 'WMT20 மிகவும் குறைந்த மூலத்திற்காக நாம் பயன்படுத்திய அமைப்பின் முடிவுகளை இந்த காகிதத்தை விளக்குகிறது MT பகிர்ந்த பணி எங்கள் சோதனைகளுக்கு, BPE-ன் பைட் மட்டத்தின் பதிப்பை பயன்படுத்துகிறோம், அது 256 மட்டும் அடிப்படையான சொல்வளத்தை தேவை. BPE அடிப்படையில் உள்ள மாதிரிகள் துணை வார்த்தை மாதிரிகள். இவ்வாறு மாதிரிகள் சொற்கோவையின் வெளியே வார்த்தையின் பிரச்சினையை முயற்சிக்க முயற்சி செய்கிறார்கள். அதனால் பிரிவுகள் மோ மேலும் அவைகள் வேறு மொழிகளில் வேலை செய்ய அறிவிக்கப்படுகின்றன, குறிப்பாக உச்சொல்லின் இயற்கையால பிலூ பணம் புள்ளியை அடிப்படையில், எங்கள் NLPRL அமைப்புகள் HSB க்கான ஒன்பது முறைமைகள் GER மற்றும் பத்தாவது GER-ல் HSB மொழிபெயர்ப்பு க', 'ur': 'This paper describes the results of the system that we used for the WMT20 very low resource (VLR) supervised MT shared task. ہمارے آزمائش کے لئے، ہم BPE کی ایک بایت سطح نسخہ استعمال کرتے ہیں، جو صرف 256 سایز کی بنیاد لکھنے کی ضرورت ہے. BPE بنیادی موڈل ایک طرح زیب کلام موڈل ہیں۔ ایسے موڈلے لکھنے کے ذریعہ لکھنے کی کوشش کرتے ہیں لکھنے کے ذریعہ لکھنے کے لئے لکھے ہوئے لکھے ہوئے لکھے ہوئے لکھے ہوئے واحدوں کے سامنے ملتے ہیں۔ ان کو بھی مختلف زبانوں میں کام کرنے کی خبر دی جاتی ہے، مخصوصاً ان کے زیب کلمات کی طبیعت کے باعث مشابہ زبانیں۔ BLEU کاسڈ اسکور پر بنیاد ہے، ہماری NLPRL سیستموں نے HSB کے لئے نیویں نسبت GER اور دسویں نسبت GER کے لئے HSB کی ترجمہ سیناریو تک رنگ کیا۔', 'uz': "Bu qogʻoz biz WMT20 uchun ishlatilgan tizimning natijalarini qisqaradi MT bilan birlashtirilgan vazifani juda kamaytirish mumkin. Bizning tajribalarimiz uchun biz BPE versiyasini bayt darajada foydalanamiz, bu faqat 256 oʻlchami asosiy soʻzni kerak. BPE asosida modellar sub-word modellari. Ushbu modellar so ʻzni ajratish uchun soʻzni ajratish mumkin va soʻzni morfologik birlikga bogʻliq boʻlishi mumkin. Ularning tub so'zlar asosiy sababda boshqa tillarda ishlash haqida hisoblanadi. BLEU kash scori asosida, bizning NLPRL tizimlarimiz HSB uchun 9 marta GER va 10 marta HSB tarjima scenariga kiritdi.", 'vi': 'Tờ giấy này mô tả kết quả của hệ thống chúng ta dùng cho giải pháp WM2h0, một nguồn tài nguyên rỗng (VHR) được giám sát gần với tập tin chia sẻ. Cho thí nghiệm của chúng tôi, chúng tôi sử dụng một phiên bản gồm byte-cấp của BPE, đòi hỏi một Từ vựng nền chỉ cỡ 256. Mẫu dựa trên BPE là một loại mô hình chữ phụ. Những mẫu này cố giải quyết vấn đề từ vựng bên ngoài (OOOV) bằng cách tạo phân đoạn từ để phân loại tương ứng với các đơn vị morphical. They are also reported to work across various languages, especially similar languages due to their sub word nature. Dựa trên vụ làm loạn của NILLL, hệ thống NILLL được xếp hạng chín cho HSB đến Trình Trình Sinh và số mười theo Trình phân dịch HSB.', 'hr': 'Ovaj papir opisuje rezultate sustava koji smo koristili za WMT20 vrlo nisko resurse (VLR) nadzirani zajednički zadatak MT-a. Za naše eksperimente, koristimo verziju BPE-a na nivou bajtova, koja zahtijeva samo baznu riječ veličine 256. Modeli bazirani na BPE-u su vrsta podriječnih modela. Takvi modeli pokušavaju rješavati problem riječi iz riječi riječi (OOV) izvršavajući segmentaciju riječi kako bi segmenti odgovarali morfološkim jedinicama. Također su prijavljeni da rade na različitim jezicima, posebno sličnim jezicima zbog prirode podriječi. Na temelju novčanog rezultata BLEU-a, naši NLPRL sustavi su 9. redovili za HSB do GER-a i 10. u GER-u do HSB prevodnog scenarija.', 'de': 'Diese Arbeit beschreibt die Ergebnisse des Systems, das wir für die WMT20 sehr low resource (VLR) überwachte MT Shared Task verwendet haben. Für unsere Experimente verwenden wir eine Byte-Level-Version von BPE, die nur ein Basisvokabular der Größe 256 benötigt. BPE-basierte Modelle sind eine Art Unterwortmodelle. Solche Modelle versuchen, das Out of Vocabulary (OOV) Wortproblem anzugehen, indem sie Wortsegmentierung durchführen, so dass Segmente morphologischen Einheiten entsprechen. Es wird auch berichtet, dass sie in verschiedenen Sprachen arbeiten, insbesondere in ähnlichen Sprachen aufgrund ihres Unterwortcharakters. Basierend auf der BLEU-Fallbewertung belegten unsere NLPRL-Systeme den neunten Platz für HSB nach GER und zehnten Platz im GER nach HSB-Übersetzungsszenario.', 'bg': 'Тази статия описва резултатите от системата, която използвахме за споделената задача с много нисък ресурс (ВЛР), контролирана от МТ. За нашите експерименти използваме версия на ниво байт на БПЕ, която изисква базов речник с размер 256. Моделите, базирани на BPE, са вид поддумични модели. Такива модели се опитват да се справят с проблема с думата извън речника чрез извършване на сегментация на думата, така че сегментите да съответстват на морфологични единици. Те също така работят на различни езици, особено сходни езици поради техния характер на поддумата. Въз основа на оценката на случаите, нашите системи се класираха на деветото място за превод от ГЕР до ГЕР и на десето място в сценария за превод от ГЕР до ГЕР.', 'da': 'Dette dokument beskriver resultaterne af det system, vi brugte til WMT20 meget low resource (VLR) overvåget MT delt opgave. Til vores eksperimenter bruger vi en byte-niveau version af BPE, som kræver et basisforråd af størrelse 256 kun. BPE baserede modeller er en slags underordsmodeller. Sådanne modeller forsøger at løse problemet med Out of Vocabulary (OOV) ved at udføre ordsegmentering, så segmenter svarer til morfologiske enheder. De rapporteres også at arbejde på tværs af forskellige sprog, især lignende sprog på grund af deres underords karakter. Baseret på BLEU cased score, vores NLPRL systemer rangerede niende for HSB til GER og tiende i GER til HSB oversættelse scenarie.', 'nl': 'Dit document beschrijft de resultaten van het systeem dat we gebruikten voor de WMT20 very low resource (VLR) supervised MT shared task. Voor onze experimenten gebruiken we een byte-level versie van BPE, die alleen een basiswoordenschat van grootte 256 vereist. BPE gebaseerde modellen zijn een soort sub-word modellen. Dergelijke modellen proberen het Out of Vocabulary (OOV) woordprobleem aan te pakken door woordsegmentatie uit te voeren zodat segmenten overeenkomen met morfologische eenheden. Ze werken ook in verschillende talen, vooral in vergelijkbare talen vanwege hun sub-woord aard. Op basis van BLEU cased score scoorden onze NLPRL systemen negende voor HSB naar GER en tiende in GER naar HSB vertaalscenario.', 'sw': 'Gazeti hili linaelezea matokeo ya mfumo ambao tulitumia kwa ajili ya rasilimali ndogo sana za WMT20 (VLR) ilifuatiliwa na kazi ya MT ilizoshirikishwa. Kwa majaribio yetu, tunatumia toleo la kiwango cha rangi la BPE, ambalo linahitaji lugha ya msingi yenye ukubwa wa 256 tu. Mifano yenye msingi wa BPE ni aina ya mifano ya maneno ya subira. Mfano huu unajaribu kuonyesha tatizo la neno la Utaratibu (OOV) kwa kutekeleza mgawanyiko wa maneno ili vipengele vinavyohusiana na vitengo vya kimaadilojia. Pia, wanaripotiwa kufanya kazi katika lugha mbalimbali, hususani lugha kama hizo kwa sababu ya asili yao ya maneno. Kutokana na vipimo vya fedha vya BLEU, mifumo yetu ya NLPRL iliweka nafasi ya tisa kwa ajili ya HSB ya GER na kumi katika GER hadi kituo cha tafsiri cha HSB.', 'tr': 'Bu kagyz WMT20 üçin ullanýan sistemiň netijesini (VLR) MT paylaşyk işini bejerýär. Synaglarymyz üçin BPE\'iň baýt derejesini ulanýarys. Bu diňe 256-nji ölçüdeki esasy sözleriň gerek. BPE tabanly nusgalar sub-söz nusgalardyr. Bütün modeller kelime segmentasyony çözerek "Out of Vocabulary (OOV) söz meselesini çözmek üçin bu şekilde segmentler morfolojik birimlere uyuşuyor. Olar ýene-de birnäçe diller arasynda işleýän bolýarlar, ýöne birnäçe sözleriniň tebigatyna sebäbi meňzeşli diller. BLEU ködleme sanatyna daýanýar, NLPRL sistemamyz HSB üçin on sany GER we on sany GER üçin HSB terjime senaryýasyna daýanýar.', 'af': "Hierdie papier beskrywe die resultate van die stelsel wat ons gebruik het vir die WMT20 baie lae hulpbron (VLR) wat MT gedeelde taak beheer het. Vir ons eksperimente gebruik ons 'n byte-vlak weergawe van BPE, wat benodig 'n basis woordeboek met slegs 256 grootte. BPE gebaseerde modele is 'n soort van sub- woord modele. Soos modelles probeer na adres die Woordeskat uit (OOV) woord probleem deur word segmentasie te uitvoer sodat segmente ooreenstem na morfologiese eenhede. Hulle is ook verspreek om te werk oor verskillende tale, veral soos tale vanweë hul sub-woord natuur. Basies op BLEU geskaf telling, ons NLPRL stelsels rangeer negende vir HSB tot GER en tiende in GER tot HSB vertaling scenario.", 'ko': '본고는 우리가 WMT20의 매우 낮은 자원(VLR)에서 MT 공유 임무를 감독하는 데 사용된 시스템의 결과를 묘사한다.우리의 실험에서, 우리는 바이트 단계의 BPE 버전을 사용했는데, 그것은 256 크기의 기본 어휘표만 필요로 했다.BPE 기반 모델은 시드어 모델입니다.이런 모델은 단어를 집행함으로써 어휘표 밖(OOV)의 단어 문제를 해결하고 단어를 형태 단위에 대응시키려고 한다.보도에 따르면, 그것들은 서로 다른 언어, 특히 유사한 언어를 뛰어넘을 수 있는데, 왜냐하면 그들의 자사 성질 때문이다.BLEU 사례 점수에 따르면 우리 NLPRL 시스템은 HSB에서 GER로 이어지는 번역 장면 중 9위, GER에서 HSB로 이어지는 번역 장면 중 10위에 올랐다.', 'sq': 'Ky dokument përshkruan rezultatet e sistemit që përdorëm për punën e përbashkët të MT-së të mbikqyrur me burime shumë të ulta (VLR). Për eksperimentet tona, ne përdorim një version në nivel byte të BPE, që kërkon vetëm një fjalor bazë me madhësi 256. BPE based models are a kind of sub-word models.  Modelet e tilla përpiqen të trajtojnë problemin e fjalëve të jashtme nga fjalëkalimi (OOV) duke kryer segmentimin e fjalëve në mënyrë që segmentet të korrespondojnë me njësitë morfologjike. Ato raportohen gjithashtu të punojnë nëpërmjet gjuhëve të ndryshme, veçanërisht gjuhëve të ngjashme për shkak të natyrës së tyre nënfjalore. Based on BLEU cased score, our NLPRL systems ranked ninth for HSB to GER and tenth in GER to HSB translation scenario.', 'fa': 'این کاغذ نتایج سیستم را که برای منابع کم WMT20 (VLR) مشخص کرده\u200cایم توصیف می\u200cکند. برای آزمایش\u200cهای ما، ما از نسخه سطح بایت\u200cهای BPE استفاده می\u200cکنیم، که فقط یک کلمه بنیادی از اندازه ۲۵۶ نیاز دارد. مدل بنیاد BPE یک جور مدل زیر کلمه است. چنین مدلها سعی می\u200cکنند مشکل کلمه\u200cهای بیرون کلمه\u200cای (OOV) را با اجرای جدایی کلمه\u200cها حل کند تا بخش\u200cها با واحدهای مورفولوژیک ارتباط دارند. آنها همچنین گزارش داده می\u200cشوند که در زبان\u200cهای مختلف کار می\u200cکنند، مخصوصاً زبان\u200cهای مشابه به خاطر طبیعت زیر کلمه\u200cهایشان. Based on BLEU cash score, the NLPRL systems we ranked nine for HSB to GER and tenth in GER to HSB translation scenario.', 'hy': 'Այս աշխատանքը նկարագրում է համակարգի արդյունքները, որոնք մենք օգտագործել էինք ՄԹԹ20-ի շատ ցածր ռեսուրսների (VLR) վերահսկվող ընդհանուր հանձնարարության համար: For our experiments, we use a byte-level version of BPE, which requires a base vocabulary of size 256 only.  ԲՓԵ հիմնված մոդելները բառերի ենթամոդելներ են: Այս մոդելները փորձում են լուծել բառային խնդիրը բառային բառերից դուրս, կատարելով բառային սեգմետրացիան, որպեսզի սեգմերները համապատասխանեն մորֆոլոգիական միավորներին: Նրանք նույնպես աշխատում են տարբեր լեզուներում, հատկապես նման լեզուներում իրենց բառերի ենթաբնույթի պատճառով: Հաշվի առնելով ԲԼԵՎ-ի կազմակերպված գնահատականների վրա, մեր ՆԼՊԼ համակարգերը HSB-ի իններորդ դասակարգում էին մինչև GeR-ի տասներորդ դասակարգում՝ մինչև HSB-ի թարգմանման սցենարը:', 'id': 'This paper describes the results of the system that we used for the WMT20 very low resource (VLR) supervised MT shared task.  For our experiments, we use a byte-level version of BPE, which requires a base vocabulary of size 256 only.  BPE based models are a kind of sub-word models.  Model seperti ini mencoba untuk mengatasi masalah kata Out of Vocabulary (OOV) dengan melakukan segmen kata sehingga segmen cocok dengan unit morfologi. Mereka juga dilaporkan bekerja di berbagai bahasa, terutama bahasa yang sama karena alami sub-kata mereka. Berdasarkan nilai BLEU, sistem NLPRL kami berturut-turut sembilan untuk HSB ke GER dan sepuluh dalam GER ke skenario terjemahan HSB.', 'am': 'This paper describes the results of the system that we used for the WMT20 very low resource (VLR) supervised MT shared task.  ለፈተናዎቻችን፣ የBPE የደረጃ ክፍል እናስቀምጣለን፡፡ የBPE መሠረት ሞዴላዎች የ-ቃላት ዓይነት ናቸው እንደዚህ ምሳሌዎች የ ቃላት ውጭ (OOV) ቃላትን መግለጫ ማድረግ ይሞክራሉ፡፡ በተለያዩ ቋንቋዎች፣ በተለዩ ልዩ ቋንቋዎች፣ በተለያዩ ልዩ ቋንቋዎች በጥቅምት ቃላት የተደረገ ነው፡፡ በBLEU ዋጋ የተደረገ ቁጥጥር፣ NLPRL ስርዓታችን ለHSB ዘጠኝኛው ለGER እና አሥረኛው ወደ HSB ትርጉም ማዕከላዊ ስዕይት ደረሰ፡፡', 'az': 'Bu kağıt WMT20 üçün istifadə etdiyimiz sistemin sonuçlarını müəyyən edir ki, MT paylaşılmış işləri gözləyir. Bizim təcrübələrimiz üçün BPE\'nin bajt səviyyəsini istifadə edirik, bu isə yalnızca 256 boyutlu əsas sözləri lazım edir. BPE tabanlı modellər bir tür sub-söz modellərdir. Bütün modellər söz segmentasiyası ilə "Out of the Vocabulary" (OOV) söz problemini çəkməyə çalışırlar ki, segmentlər morfolojik ünvanlara uyuşar. Onlara da müxtəlif dillərdə çalışmaq lazımdır, özlərinə də eyni dillərdir. BLEU malik nöqtəsinə görə, NLPRL sistemimiz HSB üçün doqquz dərəcədə GER və on dərəcədə GER üçün HSB tercümə scenariosına dərəcədə oldu.', 'bn': 'This paper describes the results of the system that we used for the WMT20 very low resource (VLR) supervised MT shared task.  For our experiments, we use a byte-level version of BPE, which requires a base vocabulary of size 256 only.  BPE ভিত্তিক মডেল একটি ধরনের সাব-ওয়ার্ড মডেল। এই ধরনের মডেলগুলো শব্দভাণ্ডারের বাইরে (OOV) শব্দভাণ্ডারের সমস্যা নিয়ে কথা বলার চেষ্টা করার চেষ্টা করে যাতে মোরফোলিক্যাল ইউন এছাড়াও তাদের সাব-শব্দের প্রকৃতির কারণে বিভিন্ন ভাষায় কাজ করার সংবাদ প্রদান করা হয়েছে। বিলু টাকা স্কোরের ভিত্তিতে আমাদের NLPRL সিস্টেম এইচএসবির জন্য নয়টি রান্না করেছে যাতে জেআরে দশটির জন্য এইচএসবি অনুবাদের স্থান', 'ca': 'Aquest paper descriu els resultats del sistema que vam utilitzar per a la tasca compartida de MT supervisada amb recursos molt baixos (VLR). Per als nostres experiments, utilitzem una versió a nivell de bytes de BPE, que requereix només un vocabulari bàsic de mida 256. BPE based models are a kind of sub-word models.  Aquests models intenten abordar el problema de paraules fora del vocabulari (OOV) fent segmentació de paraules de manera que els segments correspondeixin a unitats morfològiques. També es diu que treballen a diferents llengües, especialment llengües similars per la seva naturalesa sub-paraula. Based on BLEU cased score, our NLPRL systems ranked ninth for HSB to GER and tenth in GER to HSB translation scenario.', 'bs': 'Ovaj papir opisuje rezultate sustava koji smo koristili za WMT20 vrlo nisko resurse (VLR) nadzirani zajednički zadatak MT-a. Za naše eksperimente koristimo verziju BPE nivoa bajtova, koja zahtijeva samo baznu rečnicu veličine 256. Modeli bazirani na BPE-u su vrsta podriječnih modela. Takvi modeli pokušavaju rješavati problem riječi iz riječi riječi (OOV) izvršavajući segmentaciju riječi tako da segmenti odgovaraju morfološkim jedinicama. Također se prijavljuju da rade na različitim jezicima, posebno sličnim jezicima zbog prirode podriječi. Na temelju rezultata BLEU-a, naši NLPRL sistemi su bili deveti za HSB do GER-a i deseti u GER-u do HSB prevodnog scenarija.', 'cs': 'Tento článek popisuje výsledky systému, který jsme použili pro WMT20 velmi nízké zdroje (VLR) dohlížené MT sdílené úlohy. Pro naše experimenty používáme bajtovou verzi BPE, která vyžaduje pouze základní slovní zásobu velikosti 256. Modely založené na BPE jsou druh podslovných modelů. Tyto modely se snaží řešit problém slova mimo slovní zásobu (OOV) provedením segmentace slov tak, aby segmenty odpovídaly morfologickým jednotkám. Je také hlášeno, že pracují napříč různými jazyky, zejména podobnými jazyky kvůli jejich podslovné povaze. Na základě případového skóre BLEU se naše systémy NLPRL dostaly deváté místo pro HSB do GER a desáté v překladovém scénáři GER do HSB.', 'et': 'Käesolevas artiklis kirjeldatakse tulemusi süsteemist, mida me kasutasime WMT20 väga madala ressursi (VLR) järelevalvega MT jagatud ülesande jaoks. Meie eksperimentideks kasutame BPE baiditaseme versiooni, mis nõuab ainult baassõnavara suurusega 256. BPE-põhised mudelid on omamoodi alamsõna mudelid. Sellised mudelid püüavad lahendada sõnavara (OOV) probleemi, tehes sõna segmenteerimise nii, et segmendid vastaksid morfoloogilistele üksustele. Samuti on teatatud, et nad töötavad erinevates keeltes, eriti sarnastes keeltes nende alamsõna olemuse tõttu. BLEU-skoori põhjal olid meie NLPRL-süsteemid HSB-le GER-ile üheksandal kohal ja GER-le HSB-le tõlke stsenaariumis kümnendal kohal.', 'fi': 'Tässä artikkelissa kuvataan tulokset järjestelmästä, jota käytimme WMT20 erittäin matalan resurssin (VLR) valvotussa MT-jaetussa tehtävässä. Kokeiluissa käytämme tavutason versiota BPE:stä, joka vaatii vain 256-kokoisen perussanaston. BPE-pohjaiset mallit ovat eräänlaisia alasanamalleja. Tällaiset mallit pyrkivät ratkaisemaan sanaston ulkopuolisen ongelman suorittamalla sanasegmentoinnin siten, että segmentit vastaavat morfologisia yksiköitä. Niiden on myös raportoitu työskentelevän eri kielillä, erityisesti samankaltaisilla kielillä niiden alasanaluonteen vuoksi. BLEUn tapauskohtaisen pistemäärän perusteella NLPRL-järjestelmämme sijoittuivat yhdeksänneksi HSB:stä GER:ään ja kymmenenneksi GER:stä HSB:hen käännöskenaarioon.', 'jv': 'Laptop" and "Desktop Nyong barêng-barêng kéné, kita gambar versi bajil-sampek BPer, sing kudu nyimpen dikenayro kuwi 250 BPI Batine model kuwi model dadi apa-awak. Laptop" and "Desktop Awak dhéwé éntuk ngertuakaké karo akeh luwih-luwih, langgar-luwih sakjane kanggo langgar tarjamahan. Mungkin dadi sing ditambah sing blok banget, sistem NLPRL sing ditambah tanggal 9 kanggo HsB karo GER karo 10 kanggo GER karo seneng perusahaan HsB', 'ha': "Wannan takardar na bayyana matsalar na'urar da muka yi amfani da shi na WMT20 mai wuri da resource (vLR) mai wato aikin MT wanda aka yi raba shi. For our experiments, we use a byte-level version of BPE, which requires a base vocabulary of size 256 only.  @ info: whatsthis Wannan misãlai sun yi jarraba su zartar da matsalar maganar (OOV) da za'a zartar da cire-faɗi ga magana don a yi sauna da sauri da sunayen su daidaita da sunayen morfologi. Ana Rayya da su yi aiki a cikin wasu harshe dabam-dabam, da hususanci kamar harshen dabam-dabam, saboda haka da tsarin sunansu. Basan da BLEU ya casa score, na'urarmu na NLPRL na ranked na HSB na sagai zuwa GER da kumalin cikin GER zuwa HSB fassarori.", 'he': 'This paper describes the results of the system that we used for the WMT20 very low resource (VLR) supervised MT shared task.  לניסויים שלנו, אנחנו משתמשים בגרסה ברמה בייט של BPE, שדורשת מילון בסיסי בגודל 256 בלבד. דוגמנים מבוססים על BPE הם סוג של דוגמנים תחת מילים. דוגמנים כאלה מנסים להתמודד עם בעיית מילים מחוץ למילה (OOV) על ידי ביצוע סגמנציה מילים כך שסגמנים מתאימים ליחידות מורפולוגיות. הם גם מדווחים לעבוד על ידי שפות שונות, במיוחד שפות דומות בגלל טבע המילה התחתונה שלהם. Based on BLEU cased score, our NLPRL systems ranked ninth for HSB to GER and tenth in GER to HSB translation scenario.', 'bo': 'ང་ཚོའི་ཤོག་བྱང་འདིས་WMT20 དེ་དཀའ་ངལ་ཁོངས་དང་མཐུན་སྐྱོང་བའི་རྒྱུ་དངོས་ཐོག་མཛོད་ཀྱི་རྒྱབ་སྐྱོར་ཡོད། ང་ཚོའི་བརྟག་ཞིབ་ལ་ང་ཚོས་BPE(byte-level)ཡི་ཐོན་རིམ་ཅིག་བེད་སྤྱོད་དགོས་པ BPE་གཞི་བརྟེན་པའི་མིག་དཔེ་དབྱིབས་ཡིག་གཟུགས་བཀོད་པ་ཞིག་ཡིན། Such models try to address the Out of Vocabulary (OOV) word problem by performing word segmentation so that segments correspond to morphological units. ཁོང་ཚོས་སྐད་རིགས་མི་འདྲ་བའི་ནང་དུ་ལས་ཀ་ཡིག་གཟུགས་གཅིག་མཐུན་གྱི་སྐད་རིགས་དང་ཁྱད་པར་ཨ་རིགས། BLEU ཡི་སྐུལ་གྲངས་ཀ་གཟུགས་རིས་གཞི་རྟེན། ང་ཚོའི་NLPRL མ་ལག་གིས་HSB་ལ་བསྡད་པའི་དུམ་པ་གཟུགས་བ་དང་ GER འདི་HSB་ལ་ཚིག་སྐབས་འ', 'sk': 'Ta prispevek opisuje rezultate sistema, ki smo ga uporabili za opravilo MT nadzorovano z zelo nizkimi viri WMT20 (VLR). Za naše poskuse uporabljamo bajtno različico BPE, ki zahteva osnovni besednjak velikosti 256. Modeli, ki temeljijo na BPE, so neke vrste modeli podbesed. Takšni modeli poskušajo rešiti težavo besed izven besedišča (OOV) z izvajanjem segmentacije besed tako, da segmenti ustrezajo morfološkim enotam. Poročajo se tudi, da delajo v različnih jezikih, zlasti podobnih jezikih zaradi svoje podbesede. Na podlagi rezultatov BLEU so se naši sistemi NLPRL uvrstili na deveto mesto za HSB v GER in deseto mesto za scenarij prevajanja GER v HSB.'}
{'en': 'UdS-DFKI@WMT20 : Unsupervised MT and Very Low Resource Supervised MT for German-Upper Sorbian', 'ar': 'UdS-DFKI @ WMT20: الترجمة الآلية غير الخاضعة للإشراف وموارد الترجمة الآلية منخفضة جدًا للغة الألمانية الصربية العليا', 'fr': "UDS-DFKI @WMT20\xa0: MT non supervisée et MT supervisée à très faibles ressources pour l'allemand-haut-sorabe", 'es': 'UDS-DFKI @WMT20: MT no supervisada y MT supervisada de muy pocos recursos para alemán-alto sorabo', 'pt': 'UdS-DFKI@WMT20: MT não supervisionado e MT supervisionado com recursos muito baixos para alemão-sérvio superior', 'ja': 'UdS - DFKI @ WMT 20 ：監督されていないMTと非常にリソースの少ない監督されたドイツ-アッパーソルビア人のためのMT', 'zh': 'UdS-DFKI@WMT20:德语-上索布语无监MT极低资源监MT', 'hi': 'UdS-DFKI@WMT20: जर्मन-ऊपरी सोर्बियन के लिए असुरक्षित एमटी और बहुत कम संसाधन पर्यवेक्षित एमटी', 'ru': 'UdS-DFKI@WMT20: неконтролируемый MT и очень низкие ресурсы контролируемого MT для немецко-верхнесорбского', 'ga': 'UdS-DFKI@WMT20: MT gan Maoirseacht agus MT faoi Mhaoirseacht Acmhainní an-Íseal don tSorbais Uachtarach Gearmánach', 'ka': 'სეჟ... DFKI@WMT20 MT და მნიშვნელოვანი რესურსის დანახვა MT- ს გერმანული- ზემო სორბიული', 'hu': 'UdS... DFKI@WMT20 Felügyelet nélküli MT és nagyon alacsony erőforrás felügyelet MT német-Felső-Szorbia számára', 'el': 'UdS- DFKI@WMT20 Μη εποπτευόμενη ΜΤ και ΜΤ με πολύ χαμηλό επίπεδο πόρων για γερμανικά-ανώτερα σορβικά', 'kk': 'UdS- DFKI@WMT20 : Жоғарғы сорбияның MT және өте төмен ресурстарды бақылау MT', 'it': "UdS... DFKI@WMT20 MT non supervisionato e MT supervisionato a bassissimo livello di risorse per l'Alta Sorbia tedesca", 'ms': 'UdS- DFKI@WMT20 : MT tanpa pengawasan dan Sumber Terrendah Terpengawasan MT untuk Sorbian Jerman-Atas', 'mk': 'УДС... DFKI@WMT20 : Ненадгледуван MT и многу ниски ресурси надгледуван MT за германско-горна Сорбијанка', 'ml': 'UdS- DFKI@WMT20 : പരിശോധിക്കപ്പെടാത്ത എംടിയും വളരെ കുറഞ്ഞ വിഭവങ്ങളും ജര്\u200dമ്മന്\u200d- മുകളില്\u200d സോര്\u200dബിയന്\u200d', 'mt': 'UdS- DFKI@WMT20 : MT mhux sorveljat u MT Sorveljat b’Riżorsi Baxxi Ħafna għal Sorbjan Ġermaniż-ta’ Fuq', 'mn': 'UdS DFKI@WMT20 Германы-дээд орбийн MT болон маш бага нөөц багасгасан MT', 'no': 'UdS- DFKI@WMT20 : Usupervisert MT og svært låg ressursoversikt MT for tysk- oppe- sorbisk', 'pl': 'UdS- DFKI@WMT20 MT bez nadzoru i nadzoru nad bardzo niskimi zasobami dla języka niemiecko-górnego', 'ro': 'UdS... DFKI@WMT20 MT nesupravegheată și MT supravegheată cu resurse foarte scăzute pentru Sorbia Superioară germană', 'lt': 'UdS... DFKI@WMT20 : Unsupervised MT and Very Low Resource Supervised MT for German-Upper Sorbian', 'so': 'UdS- DFKI@WMT20 : Unsupervised MT and Very Low Resource Supervised MT for German-Upper Sorbian', 'sv': 'UdS- DFKI@WMT20 Oserverad MT och mycket låg resursövervakad MT för tysk-övre sorbiska', 'sr': 'UdS... DFKI@WMT20 Nepotrebna MT i vrlo niska resursa nadgledana MT za njemački-gornji sorbijanski', 'si': 'UdS- DFKI@WMT20 සර්මාන්\u200dය- උපර සෝර්බියාන් වෙනුවෙන් MT සහ ගොඩක් අඩු සම්බන්ධ සම්බන්ධ MT', 'ta': 'UdS- DFKI@WMT20 : கண்காணிக்கப்படவில்லை', 'ur': 'اوڈس - DFKI@WMT20 : غیر محافظت MT اور بہت کم سرمایہ جرمن-اوپر Sorbian کے لئے MT نظارت کی گئی', 'uz': "UdS- DFKI@WMT20 : Koʻrsatilmagan MT va juda katta manbani Olmonchadan yuqori Sorbchaga MT'ni ajratilgan", 'vi': 'Được. DFKI@WMT20 Không giám sát MTV và quản lý tài nguyên rất thấp MTV cho người Đức-Upper Sorbian', 'bg': 'УДС... DFKI@WMT20 Неконтролиран МТ и много нисък ресурсен надзор МТ за германско-горно сорбийски език', 'hr': 'UdS- DFKI@WMT20 Nepotrebna MT i vrlo niska resursa nadzirana MT za njemački-gornji sorbijanski', 'da': 'UdS- DFKI@WMT20 Ikke-overvåget MT og meget lavt ressourceovervåget MT til tysk-øversorbisk', 'nl': 'UdS- DFKI@WMT20 Niet-begeleide MT en zeer lage resource supervised MT voor Duits-Bovensorbisch', 'id': 'UdS- DFKI@WMT20 : MT tanpa pengawasan dan sangat rendah Sumber Terpengawasan MT untuk Jerman-Upper Sorbian', 'de': 'UdS- DFKI@WMT20 Unbeaufsichtigte MT und sehr ressourcenschonende MT für Deutsch-Obersorbisch', 'ko': 'UdS-DFKI@WMT20: 독일 상소포급 무감독기계번역 및 극저자원감독기계번역', 'sw': 'UdS- DFKI@WMT20 : Kufuatiliwa kwa MT na rasilimali ndogo iliyotumiwa na MT kwa Kijerumani-Upper Sorbia', 'fa': 'اودس DFKI@WMT20 MT و منابع بسیار کم تحت نظارت MT برای سوربیان آلمانی-بالا', 'sq': 'UdS- DFKI@WMT20 : MT pa mbikqyrje dhe MT me burime shumë të ulta të mbikqyrura për Gjermanisht-Sorbiken e Lartë', 'af': 'UdS- DFKI@WMT20 Onondersoekte MT en baie lae hulpbron ondersoekte MT vir Duits- bo SorbisName', 'am': 'UdS- DFKI@WMT20 : Unsupervised MT and Very Low Resource Supervised MT for German-Upper Sorbian', 'tr': 'UdS- DFKI@WMT20 German-Upper Sorbian 체챌in g철zle첵채n MT we gaty d체힊체k Resmi', 'hy': 'Օդ... DFKI@WMT20 Առաջին սորբյան գերմաներեն', 'bn': 'UdS- DFKI@WMT20 জার্মান-আপার সোর্বিয়ানের জন্য এমটি এবং খুব কম সম্পদ সাপার্ভিভেট করা হয়েছে।', 'az': 'UdS- DFKI@WMT20 Nəmin-Yukarı Sorbiski MT və çox düşük resursu gözləyir.', 'ca': 'UdS- DFKI@WMT20 : MT no supervisada i MT molt baix de recursos supervisada per alemanya-sorbia superior', 'cs': 'UdS- DFKI@WMT20 Nehlídané MT a velmi nízké zdroje kontrolované MT pro německo-horní Sorbii', 'bs': 'UdS... DFKI@WMT20 Nepotrebna MT i vrlo niska resursa nadzirana MT za njemački-gornji sorbijanski', 'et': 'UDS- DFKI@WMT20 Järelevalveta MT ja väga madala ressursi järelevalvega MT Saksa-Ülem-Sorbia jaoks', 'fi': 'UDS- DFKI@WMT20 : Valvontaton MT ja erittäin vähän resursseja valvottu MT Saksan-Ylä-Sorbian', 'ha': 'UdS- DFKI@WMT20 QRegExp', 'jv': 'udS- DFKI@WMT20 MT Gak-Pas Yukono perusahaan MT karo akeh-perusahaan mulalah', 'sk': 'UDS- DFKI@WMT20 Nenadzorovana MT in nadzorovana MT z zelo nizkimi viri za nemško-zgornjo Sorbijo', 'he': 'אודס... DFKI@WMT20 : MT ללא השגחה, MT ללא משאבים נמוכים מאוד', 'bo': 'UdS- DFKI@WMT20 : སྔོན་ཤུགས་མེད་པའི་MT དང་ཐུག་ཁུངས་ལ་ཉུང་བའི་རྒྱུ་ཆ་མཐོང་བསྒྲགས་མེད་པ་ཡིན།'}
{'en': 'This paper describes the UdS-DFKI submission to the shared task for unsupervised machine translation (MT) and very low-resource supervised MT between German (de) and Upper Sorbian (hsb) at the Fifth Conference of Machine Translation (WMT20). We submit systems for both the supervised and unsupervised tracks. Apart from various experimental approaches like bitext mining, model pre-training, and iterative back-translation, we employ a factored machine translation approach on a small BPE vocabulary.', 'ar': 'تصف هذه الورقة تقديم UdS-DFKI للمهمة المشتركة للترجمة الآلية غير الخاضعة للإشراف (MT) و MT ذات الموارد المنخفضة للغاية تحت الإشراف بين الألمانية (de) والصربية العليا (hsb) في المؤتمر الخامس للترجمة الآلية (WMT20). نقدم أنظمة لكل من المسارات الخاضعة للإشراف وغير الخاضعة للإشراف. بصرف النظر عن الأساليب التجريبية المختلفة مثل التنقيب عن البتات ، والتدريب المسبق للنموذج ، والترجمة الخلفية التكرارية ، فإننا نستخدم نهج ترجمة آلية مُصنَّف على مفردات BPE صغيرة.', 'pt': 'Este artigo descreve a submissão UdS-DFKI para a tarefa compartilhada para tradução automática não supervisionada (MT) e MT supervisionada de recursos muito baixos entre o alemão (de) e o Alto Sorbian (hsb) na Quinta Conferência de Tradução Automática (WMT20). Enviamos sistemas para as trilhas supervisionadas e não supervisionadas. Além de várias abordagens experimentais, como mineração bitexto, pré-treinamento de modelo e tradução reversa iterativa, empregamos uma abordagem de tradução automática fatorada em um pequeno vocabulário BPE.', 'fr': "Cet article décrit la soumission de l'UDS-DFKI à la tâche partagée de traduction automatique non supervisée (MT) et de MT supervisée à très faible ressources entre l'allemand (de) et le haut-sorabe (hsb) lors de la cinquième conférence de traduction automatique (WMT20). Nous soumettons des systèmes pour les pistes supervisées et non supervisées. Outre diverses approches expérimentales telles que l'exploration bitexte, la pré-formation de modèles et la rétro-traduction itérative, nous utilisons une approche de traduction automatique factorielle sur un petit vocabulaire BPE.", 'es': 'Este artículo describe el envío de UDS-DFKI a la tarea compartida de traducción automática no supervisada (MT) y MT supervisada de muy pocos recursos entre alemán (de) y sorabo alto (hsb) en la Quinta Conferencia de Traducción Automática (WMT20). Presentamos sistemas para las pistas supervisadas y no supervisadas. Además de varios enfoques experimentales, como la minería de bitextos, el preentrenamiento de modelos y la retrotraducción iterativa, empleamos un enfoque de traducción automática factorizada en un vocabulario pequeño de BPE.', 'ja': '本稿では、第5回機械翻訳会議（ WMT 20 ）におけるドイツ語（ de ）と上部ソルブ語（ hsb ）の間の無監督機械翻訳（ MT ）と非常に低資源の監督機械翻訳（ MT ）の共有タスクへのUdS - DFKI提出について説明する。監視されたトラックと監視されていないトラックの両方のシステムを提出します。ビットテキストマイニング、モデル事前トレーニング、反復バックトランスレーションなどのさまざまな実験的アプローチとは別に、小さなBPEボキャブラリーに因数分解された機械翻訳アプローチを採用しています。', 'zh': '本文述在第五届机器翻译会议 (WMT20) 上,UdS-DFKI 向德语 (de) 与上索布语 (hsb) 之间无监督机器翻译 (MT) 与极低资源监督机器翻译 (MT) 共享。 我们提交受监督和无监督轨道的系统。 除诸实验法(如双文本掘、模形预训练、迭代回译)之外,又于小 BPE 词汇表用因子化机器翻译法。', 'hi': 'यह पेपर यूडीएस-डीएफकेआई को असुरक्षित मशीन अनुवाद (एमटी) के लिए साझा कार्य के लिए प्रस्तुत करने का वर्णन करता है और मशीन अनुवाद के पांचवें सम्मेलन (WMT20) में जर्मन (डी) और ऊपरी सोर्बियन (एचएसबी) के बीच बहुत कम संसाधन पर्यवेक्षित एमटी का वर्णन करता है। हम पर्यवेक्षित और असुरक्षित दोनों पटरियों के लिए सिस्टम सबमिट करते हैं। Bitext खनन, मॉडल पूर्व प्रशिक्षण, और पुनरावर्ती बैक-अनुवाद जैसे विभिन्न प्रयोगात्मक दृष्टिकोणों के अलावा, हम एक छोटे से बीपीई शब्दावली पर एक कारक मशीन अनुवाद दृष्टिकोण को नियोजित करते हैं।', 'ru': 'Эта статья описывает представление UDS-DFKI для общей задачи для неконтролируемого машинного перевода (MT) и очень мало ресурсов контролируемого MT между немецким (de) и верхнесорбским (hsb) на пятой Конференции машинного перевода (WMT20). Мы представляем системы как для контролируемых, так и для неконтролируемых путей. Помимо различных экспериментальных подходов, таких как битекстовый майнинг, предварительное обучение модели и итеративный обратный перевод, мы используем факторный подход машинного перевода для небольшого словаря BPE.', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht UdS-DFKI don tasc roinnte maidir le haistriúchán meaisín gan mhaoirseacht (MT) agus MT maoirsithe ar acmhainní an-íseal idir Gearmáinis (de) agus Sorbais Uachtarach (hsb) ag an gCúigiú Comhdháil um Aistriú Meaisín (WMT20). Cuirimid isteach córais do na rianta maoirsithe agus neamh-mhaoirsithe araon. Seachas cineálacha cur chuige turgnamhacha éagsúla cosúil le mianadóireacht bhitéacs, réamhoiliúint eiseamláireach, agus aisaistriúchán atriallach, bainimid úsáid as cur chuige meaisín-aistriúcháin ar stór focal beag BPE.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή του UdS-DFKI στο κοινό έργο για τη μη εποπτευόμενη μηχανική μετάφραση (ΜΤ) και την εποπτευόμενη ΜΤ με πολύ χαμηλούς πόρους μεταξύ γερμανικών (de) και ανώτερων σορβικών (hsb) στο πέμπτο συνέδριο μηχανικής μετάφρασης (WMT20). Υποβάλλουμε συστήματα τόσο για τις εποπτευόμενες όσο και για τις ανεξέλεγκτες διαδρομές. Εκτός από διάφορες πειραματικές προσεγγίσεις όπως η εξόρυξη bitext, η προ-εκπαίδευση μοντέλων και η επαναληπτική πίσω μετάφραση, χρησιμοποιούμε μια προσέγγιση μηχανικής μετάφρασης σε ένα μικρό λεξιλόγιο BPE.', 'hu': 'Ez a tanulmány bemutatja az UdS-DFKI benyújtását a felügyelet nélküli gépi fordítás (MT) és a nagyon alacsony erőforrással felügyelt MT közös feladatára a német (de) és Felső-Szorbia (hsb) között az ötödik gépi fordítási konferencián (WMT20). Rendszereket küldünk mind a felügyelt, mind a felügyelet nélküli sávokra. A különböző kísérleti megközelítések mellett, mint például bitext bányászat, modell előképzés és iteratív visszafordítás, faktorozott gépi fordítási megközelítést alkalmazunk egy kis BPE szókincsen.', 'lt': 'Šiame dokumente aprašoma UdS-DFKI pateikta penktojoje mašinų vertimo konferencijoje (WMT20) penktojoje mašinų vertimo konferencijoje (angl. Mes teikiame sistemas tiek prižiūrimams, tiek nekontroliuojamiems keliams. Be įvairių eksperimentinių metodų, pavyzdžiui, bitext kasybos, modelio parengiamojo mokymo ir pakartotinio grįžtamojo vertimo, mažame BPE žodyne naudojame faktorinį mašinų vertimo metodą.', 'ka': 'ამ დოკუნტაში UdS-DFKI გააჩვენება საზოგადოებელი სამუშაო სამუშაო მოქმედებისთვის (MT) და მნიშვნელოვანი სამუშაო რესურსების დამართებული MT-ს გერმანეთის (de) და სამუშაო სორბული (hsb) შორის მეხუთე ჩვენ სისტემები დავუყენებთ მონაცემებული და არაფერიზებული სისტემებისთვის. განსხვავებული ექსპერიმენტის გარეშე, როგორც წიგნის წიგნის, მოდელის წინ გარეშე, და ინტერატიგური წიგნის გარეშე, ჩვენ გამოვიყენებთ ფაქტორიული მაქინის გარეშე წიგნის გარეშე პატ', 'it': 'Questo articolo descrive la presentazione di UdS-DFKI al compito condiviso per la traduzione automatica non supervisionata (MT) e MT supervisionate a bassissime risorse tra tedesco (de) e Alto Sorbiano (hsb) alla Quinta Conferenza di traduzione automatica (WMT20). Inviamo sistemi sia per le tracce sorvegliate che non sorvegliate. Oltre a vari approcci sperimentali come bitext mining, pre-training dei modelli e back-translation iterativo, utilizziamo un approccio di traduzione automatica fattorizzata su un piccolo vocabolario BPE.', 'kk': 'Бұл қағаз UdS- DFKI машинаны аудару (MT) және неміс (de) және жоғары сорбиян (hsb) арасындағы бесінші аудару конференциясы (WMT20) үшін ортақтастырылмаған тапсырмаға (ортақтастырылмаған) MT және өте төмен ресурстарды бақылау үші Біз басқару жүйелерін және басқару жолдарының жүйелерін жібереміз. Біз бірнеше тәжірибелі түрлі тәжірибеліктердің көмегімен, бірнеше тәжірибеліктердің алдын- оқыту үлгісін, қайта- аудару үлгісін қоса, біз кішкентай BPE сөздерінде машинаны аудар', 'ms': 'Kertas ini menggambarkan penghantaran UdS-DFKI kepada tugas berkongsi untuk terjemahan mesin tidak diawasi (MT) dan MT yang mengawasi sumber yang sangat rendah diantara Jerman (de) dan Upper Sorbian (hsb) pada Persidangan Kelima Terjemahan Mesin (WMT20). Kami menghantar sistem untuk kedua-dua trek yang diawasi dan tidak diawasi. Selain berbagai pendekatan eksperimen seperti perlombaan bitext, pralatihan model, dan terjemahan-belakang berulang-ulang, kami menggunakan pendekatan terjemahan mesin faktor pada vocabulari BPE kecil.', 'mk': 'Овој весник го опишува поднесувањето на UdS-DFKI на заедничката задача за ненадгледуван машински превод (MT) и многу нискоресурсно надгледуван MT помеѓу германската (de) и горната сорбијанка (hsb) на Петтата конференција за машински превод (WMT20). Ние ги поднесуваме системите за надгледуваните и ненадгледуваните траги. Освен различните експериментални пристапи, како што се рударството со bitext, предобуката на моделот и повторниот превод, употребуваме факториран пристап на машински превод на мал речник на BPE.', 'ml': 'ഈ പേപ്പറിന്റെ വിവരിച്ചുകൊടുക്കുന്നു, സംരക്ഷിക്കപ്പെടാത്ത മെഷിന്\u200d പരിഭാഷയ്ക്കുള്ള പങ്കെടുത്ത ജോലിയിലേക്ക് UdS-DFKI സമര്\u200dപ്പിക്കുന്നു. വളരെ കുറഞ്ഞ വിഭവങ്ങള്\u200d ജര്\u200dമ് നമ്മള്\u200d സിസ്റ്റീമുകള്\u200d സൂക്ഷിക്കുന്നതും സൂക്ഷിക്കാത്ത ട്രാക്കുകള്\u200dക്കും വേണ്ടിയാണ്. വ്യത്യസ്ത പരീക്ഷണങ്ങളില്\u200d നിന്നുള്ള പരീക്ഷണങ്ങള്\u200dക്ക് മാത്രമേ ബിക്സ്റ്റ് മിനിങ്ങ്, മോഡല്\u200d മുമ്പ് പരിശീലനത്തിനും പിന്നീട് ട്രെയിന്\u200dഷനും', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni tal-UdS-DFKI għall-kompitu kondiviż għat-traduzzjoni tal-magni mhux sorveljata (MT) u MT sorveljata b’riżorsi baxxi ħafna bejn il-Ġermaniż (de) u l-ogħla Sorbjan (hsb) fil-Ħames Konferenza tat-Traduzzjoni tal-Magni (WMT20). Aħna nippreżentaw sistemi kemm għall-binarji sorveljati kif ukoll dawk mhux sorveljati. Minbarra diversi approċċi sperimentali bħat-tħaffir fil-minjieri bit-test, it-taħriġ minn qabel tal-mudell, u t-traduzzjoni lura iterattiva, a ħna nużaw approċċ fatturat tat-traduzzjoni tal-magni fuq vokabulari żgħir tal-BPE.', 'mn': 'Энэ цаас UdS-DFKI-г машины хөрөнгө оруулалт (MT) болон Герман (de) болон дээд Sorbian (hsb) хоорондын 5-р Конференцийн Машины хөрөнгө оруулалт (WMT20) болон маш бага нөөц хөрөнгө оруулагдсан MT-ын хуваалцаагүй ажлыг тайлбарладаг. Бид удирдлагагүй, хариуцлагагүй загваруудын системийг дамжуулдаг. Өөр төрлийн туршилтын ойлголтын дотор бид жижиг BPE үг дээр машин хөгжүүлэх аргыг ашигладаг.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie UdS-DFKI do wspólnego zadania bez nadzoru tłumaczenia maszynowego (MT) i bardzo niskosorbowego nadzorowanego MT między językiem niemieckim (de) i górnym sorbijskim (hsb) na Piątej Konferencji Tłumaczenia Maszynowego (WMT20). Przedkładamy systemy zarówno dla torów nadzorowanych, jak i bez nadzoru. Oprócz różnych podejść eksperymentalnych, takich jak eksploracja bitekstów, szkolenie wstępne modeli i iteracyjne tłumaczenie wsteczne, stosujemy podejście do tłumaczenia maszynowego w małym słownictwie BPE.', 'ro': 'Această lucrare descrie transmiterea UdS-DFKI la sarcina comună pentru traducerea automată nesupravegheată (MT) și MT supravegheată cu resurse foarte reduse între germană (de) și Sorbiană Superioară (hsb) la cea de-a cincea Conferință de traducere automată (WMT20). Depunem sisteme atât pentru piesele supravegheate, cât și pentru cele nesupravegheate. În afară de diferite abordări experimentale, cum ar fi mining bitext, pre-training model și back-translation iterativ, folosim o abordare de traducere automată factored pe un vocabular BPE mic.', 'no': 'Denne papiret beskriver UdS-DFKI-tillegget til delt oppgåve for ulike maskinsomsetjing (MT) og svært lite ressurs oversikt av MT mellom tysk (de) og øvre Sorbian (hsb) på femte konferanse av maskinsomsetjing (WMT20). Vi sender systemet for både oversikte og ikkje-oppretta spor. I siden av forskjellige eksperimentelle tilnærmingar som bitext-mining, modell før-trening og iterativ tilbakeomsetjing, bruker vi ein faktorisert maskinsomsetjingslinjering på ein liten BPE-ordbok.', 'so': 'Kanu warqaddan ayaa ku qoran UdS-DFKI oo u soo dhiibay shaqada la qaybsan oo u qoran maamulka unsupervised machine translation (MT) iyo very low-resource supervised MT between German (de) and Upper Sorbian (hsb) at the Fifth Conference of Machine Translation (WMT20). Waxaan sameynaa nidaamka jidadka ilaalinaysan iyo aan ilaalinayn. Waxyaabo baaritaanka oo kala duduwan sida qashinka qaniinka, modelka horumarinta, iyo tarjumaadda dib-u-turjumidda, waxaynu u shaqeynaa qaab turjumid ah oo ku qoran qoraalka BPE oo yar.', 'ta': 'இந்த paper describes the UdS- DFKI submit to the shared task for unsuperved machine translation (MT) and very low- resource supervised MT between German (de) and Upper Sorbian (hsb) at the Fifth Conference of Machine Translation (WMT20). நாம் கண்காணிக்கப்பட்ட மற்றும் பாதுகாப்பாக்கப்படாத தடங்களுக்கு அமைப்புகளை ஒப்பிடுகிறோம். பல்வேறு சோதனையின் முன்னோக்கம் போன்ற பிட்டிக் கிங்க், மாதிரி பயிற்சி போன்ற மற்றும் உருவாக்கு மீண்டும் மொழிபெயர்ப்பு, நாம் ஒரு சிறிய', 'si': 'මේ පැත්තේ UdS-DFKI සම්පූර්ණය කරනවා ජර්මන් (de) සහ උපර සෝර්බියාන් (fsb) සම්පූර්ණ වාර්ථාවක් සඳහා සම්පූර්ණ වැඩක් සඳහා සම්පූර්ණ වැඩක් සඳහා ස අපි පරීක්ෂා කරලා බලන්න හා නැති පරීක්ෂා කරලා තියෙනවා. විවිධ ප්\u200dරශ්නයක් විතරයි ප්\u200dරශ්නයක් විතරයි බිට්කේස්ට් ප්\u200dරශ්නයක් වගේ, ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වගේ, සහ ප්\u200dරශ්නයක් පි', 'sv': 'Denna uppsats beskriver UdS-DFKI:s bidrag till den gemensamma uppgiften för oövervakad maskinöversättning (MT) och mycket resursövervakad MT mellan tyska (de) och övre sorbiska (hsb) vid femte konferensen för maskinöversättning (WMT20). Vi skickar in system för både övervakade och obevakade spår. Förutom olika experimentella tillvägagångssätt som bitextmining, modell pre-training och iterativ back-translation använder vi en faktorerad maskinöversättning på ett litet BPE-ordförråd.', 'sr': 'Ovaj papir opisuje podnošenje UdS-DFKI na zajednièki zadatak za neodređeni prevod mašine (MT) i vrlo niskog resursa nadziranog MT između njemačkog (de) i gornjeg Sorbijanskog (hsb) na petoj konferenciji prevoda mašine (WMT20). Predajemo sisteme za nadzorne i nepotrebne tragove. Osim različitih eksperimentalnih pristupa poput rudarstva ugriza, model a predobuke i iterativnog prevoda natrag, koristimo faktorizirani pristup prevoda mašine na malim rečniku BPE.', 'ur': 'This paper describes the UdS-DFKI submission to the shared task for unsupervised machine translation (MT) and very low-resource supervised MT between German (de) and Upper Sorbian (hsb) at the Fifth Conference of Machine Translation (WMT20). ہم ہر ایک پر نظام رکھتے ہیں اور ہر ایک پر نظام نہیں رکھتے ہم ایک چھوٹے BPE لکھنے والی بات پر ماشین ترجمہ کی طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح کرتے ہیں۔', 'uz': "Name Biz taʼminlovchi va saqlanmagan yo'llar uchun tizimni qoʻllamiz. Biz bir kichkina BPE vositasiga bir xil tajriba tarjima qilishdan oldin, model oldin o'rganish va tizim tarjima qilishdan foydalanamiz.", 'vi': 'Tờ giấy này mô tả việc UdS-DKI chịu trách nhiệm chia sẻ dịch vụ không giám sát máy (MTV) và kênh được giám sát với tài nguyên rất thấp giữa Đức (de) và Upper Sorbian (hsb) tại phiên bản dịch cơ bản thứ năm (WRT20). Chúng tôi đăng ký hệ thống cho cả những đường ray giám sát lẫn không giám sát. Ngoài các phương pháp thử nghiệm khác nhau như việc khai thác sản phẩm gen, theo mẫu tiền đào tạo, và phiên dịch phụ lặp lại, chúng tôi sử dụng một phương pháp dịch phụ nhân tạo trên một từ của tập thể nhỏ.', 'nl': 'Dit artikel beschrijft de UdS-DFKI inzending aan de gedeelde taak voor onbeheerde machinevertaling (MT) en supervised MT met zeer weinig middelen tussen Duits (de) en Oppersorbisch (hsb) tijdens de vijfde conferentie voor machinevertaling (WMT20). We sturen systemen in voor zowel de begeleide als onbeheerde sporen. Naast verschillende experimentele benaderingen zoals bitext mining, model pre-training en iteratieve back-translation gebruiken we een factored machine translation benadering op een kleine BPE woordenschat.', 'bg': 'Настоящата статия описва подчинението на УДС-ДФКИ към споделената задача за ненадзорен машинен превод (МТ) и много нискоресурсно надзорен МТ между немски (де) и горносорбийски (ХСБ) на Петата конференция по машинен превод (WMT20). Предоставяме системи както за надзорните, така и за ненадзорните писти. Освен различни експериментални подходи като добив на битекст, предварително обучение на модели и итеративен обратен превод, ние използваме факториран подход за машинен превод на малък речник.', 'da': "Dette dokument beskriver UdS-DFKI's indlæg til den fælles opgave for maskinoversættelse (MT) og meget lav ressource-overvåget MT mellem tysk (de) og øversorbisk (hsb) på femte konference om maskinoversættelse (WMT20). Vi indsender systemer til både overvågede og ubevågede spor. Bortset fra forskellige eksperimentelle tilgange som bitext mining, model pre-training og iterativ back-oversættelse, anvender vi en factored machine oversættelse tilgang på et lille BPE ordforråd.", 'hr': 'Ovaj papir opisuje podatak UdS-DFKI na zajednički zadatak za neodržavani prevod strojeva (MT) i vrlo nisko resursno nadzirani MT između njemačkog (de) i gornjeg Sorbijanskog (hsb) na petoj konferenciji prevoda strojeva (WMT20). Predajemo sustave za nadzorne i nepotrebne tragove. Osim različitih eksperimentalnih pristupa poput rudarstva ugriza, model a predobuke i iterativnog prevoda natrag, koristimo faktorirani pristup prevoda strojeva na malim riječniku BPE.', 'id': 'Kertas ini menggambarkan pengiriman UdS-DFKI ke tugas berbagi untuk terjemahan mesin yang tidak diawasi (MT) dan MT yang mengawasi sumber daya yang sangat rendah antara Jerman (de) dan Upper Sorbian (hsb) di Konferensi Kelima Perjemahan mesin (WMT20). We submit systems for both the supervised and unsupervised tracks.  Selain berbagai pendekatan percobaan seperti perlombongan bitext, model pre-pelatihan, dan iteratif back-translation, kami menggunakan pendekatan terjemahan mesin faktor pada sebuah vocabulari BPE kecil.', 'de': 'Dieser Beitrag beschreibt die UdS-DFKI-Einreichung zur gemeinsamen Aufgabe für unüberwachte maschinelle Übersetzung (MT) und sehr ressourcenschonende überwachte MT zwischen Deutsch (de) und Obersorbisch (hsb) auf der Fünften Konferenz für maschinelle Übersetzung (WMT20). Wir reichen Systeme sowohl für die überwachten als auch für die unbeaufsichtigten Strecken ein. Neben verschiedenen experimentellen Ansätzen wie Bitext Mining, Model Pre-Training und iterativer Rückübersetzung verwenden wir einen faktorierten maschinellen Übersetzungsansatz auf einem kleinen BPE-Vokabular.', 'fa': 'این کاغذ تسلیم UdS-DFKI را به کار مشترک برای ترجمه ماشین غیرقابل تسلیم (MT) و MT را بین آلمان (de) و سوربیان بالا (hsb) در کنفرانس پنجم ترجمه ماشین (WMT20) توضیح می\u200cدهد. ما سیستم\u200cها را برای نقاشی\u200cهای تحت نظر و تحت نظر قرار می\u200cدهیم. غیر از دسترسی\u200cهای مختلف آزمایشی مثل خروج آب\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب، مدل پیش\u200cآموزش\u200cآب\u200cآموزش و ترجمه\u200cهای پشت\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب\u200cآب\u200c', 'sw': 'Gazeti hili linaelezea ujumbe wa UdS-DFKI kwa kazi ya ushirikiano kwa kutafsiri mashine isiyo sahihi (MT) na rasilimali ndogo inayofuatiliwa na MT kati ya Ujerumani (de) na Sorbia ya Juu (hsb) katika Mkutano wa Fifth wa Tafsiri ya Mashiniki (WMT20). Tunasilisha mifumo kwa ajili ya zote zinazofuatiliwa na zile zisizo hifadhiwa. Pamoja na mbinu mbalimbali za majaribio kama vile uchimbaji madini, mifano ya mafunzo ya zamani, na tafsiri ya pili, tunatumia mbinu za kutafsiri mashine yenye uhalisia katika lugha ndogo ya BPE.', 'ko': '본고는 UdS DFKI가 제5회 기계번역대회(WMT20)에서 독일어(de)와 상소포어(hsb) 사이에 제출한 무감독기계번역(MT)과 극저자원감독기계번역(MT) 공유 임무의 상황을 묘사한다.우리는 감독과 비감독 궤도를 위해 시스템을 제출한다.각종 실험 방법, 예를 들어 이중 텍스트 발굴, 모형 예훈련과 반복 번역 등을 제외하고 우리는 작은 BPE 어휘표에 분해기계 번역 방법을 사용했다.', 'af': "Hierdie papier beskrywe die UdS- DFKI onderskrywing na die gedeelde taak vir onverondersoekte masjien vertaling (MT) en baie lae- hulpbron onderskrywe MT tussen Duits (de) en Boonste Sorbian (hsb) by die Vyfde Konferanse van Masjien Vertaling (WMT20). Ons stuur stelsels vir beide die ondersoekte en onondersoekte snitte. Behalwe van verskeie eksperimentele toegang soos byteks-minering, model voor-onderwerp en iteratiewe terugvertaling, gebruik ons 'n faktoreerde masjien-vertaling toegang op 'n klein BPE woordeboek.", 'sq': 'This paper describes the UdS-DFKI submission to the shared task for unsupervised machine translation (MT) and very low-resource supervised MT between German (de) and Upper Sorbian (hsb) at the Fifth Conference of Machine Translation (WMT20).  Ne dërgojmë sisteme si për gjurmët e mbikqyrura, ashtu edhe për gjurmët e pa mbikqyrura. Përveç metodave eksperimentale të ndryshme si miniera bitext, paratrajnimi i modelit dhe përkthimi i përsëritur prapa, ne përdorim një metodë përkthimi automatik faktorizuar në një fjalor të vogël BPE.', 'tr': 'Bu kagyz UdS-DFKI maşynyň terjime edilmegi (MT) we Almança (de) we üst Sorbiýa (hsb) arasyndaky MT we Beşinji Konferansiň (WMT20) üçin ylalaşyk zada beýleki zady tassyklaýar. Biz gözlemýän we daşary edilmedik hatlar üçin sistemleri jemgylaýarys. Bittekst küçürmegi ýaly çarpyşyklaryň, örän öň-okuwçy we ýene-täzeden terjime etmek ýaly çarpyşyklaryň ýöne kiçi BPE sözlerinde maşynyň terjime edilmegi üçin bir nusgasyny ulanýarys.', 'am': 'ይህ ፕሮግራም UdS-DFKI ወደተካፈለ ስራ ለunsupervised machine translation (MT) እና very low resource supervised MT between German (de) and Upper Sorbian (hsb) at the Fifth Machine Conference (WMT20). የስርዓቶችን ስርዓት ለመጠበቅ እና ለማይጠበቅ መንገዶች እናስገዛለን፡፡ ከሌሎችም ፈተና ግንኙነት፣ የቅድመ ግንኙነት፣ ሞዴል በፊት ትምህርት እና የኢትሬትሬት ትርጓሜ ካልሆነ በቀር፣ ትንሽ BPE ቃላት ላይ የመረጃ ትርጉም ግንኙነት እናስገድዳለን፡፡', 'hy': 'Այս աշխատանքում նկարագրվում է UDS-DFKI-ի ներկայացումը անվերահսկված մեքենայի թարգմանման (MT) և շատ ցածր ռեսուրսների վերահսկվող MT-ի հանդեպ 5-րդ մեքենայի թարգմանման կոնֆերանսի (VMT20) միջև: Մենք ներկայացնում ենք համակարգեր վերահսկված և անվերահսկված ուղիների համար: Բացի տարբեր փորձարկվող մոտեցումներից, ինչպիսիք են բիթքսթ հանքագործությունը, մոդելը նախապատրաստման և կրկնվող վերջնական թարգմանությունը, մենք օգտագործում ենք մեխանիզմի թարգմանման գործոնային մոտեցում փոքր BP բառարանում:', 'az': "Bu kağıt UdS-DFKI'nin paylaşılmamış maşın tercüməsi (MT) və Beşinci Maşın Tercüməsi (WMT20) arasındakı MT arasındakı çox düşük kaynaqlar üçün paylaşılmış iş iş tərzini təsdiqləyir. Biz gözlənilmiş və gözlənilməmiş yollar üçün sistemlər göndəririk. Çeşitmiş təcrübə məhsullarından istisna olmaqla, modeli əvvəl təcrübə və iterativ geri çeviriş kimi, küçük BPE sözlərində fəxr edilmiş maşın çeviriş metodlarını istifadə edirik.", 'bn': 'এই পত্রিকাটি ব্যাখ্যা করেছে যে UdS-DFKI অরক্ষণশীল মেশিন অনুবাদ (এমটি) এবং জার্মান (ডি) এবং উপর সোর্বিয়ান (এসএমটি) ফাঞ্চ মেশিন অনুবাদ সম্মেলন (উইএমটি২০) সম্মেলনে অনুবাদের মধ্ আমরা সিস্টেমগুলো দুজনেই পর্যবেক্ষন এবং সংরক্ষিত ট্র্যাকের জন্য জমা দিচ্ছি। বিভিন্ন পরীক্ষার উপায় ছাড়া বিভিন্ন পরীক্ষার প্রতিক্রিয়া ছাড়া, মডেল প্রশিক্ষণ, এবং বিষয়বস্তুর প্রশিক্ষণ, আমরা একটি ছোট বিপের শব্দভাণ্ডারে একটি', 'bs': 'Ovaj papir opisuje podatke UdS-DFKI na zajednički zadatak za nepovjeren prevod strojeva (MT) i vrlo niskog resursa nadziranog MT između njemačkog (de) i gornjeg Sorbijanskog (hsb) na petoj konferenciji prevoda strojeva (WMT20). Predajemo sisteme za nadzorne i nepotrebne tragove. Osim različitih eksperimentalnih pristupa poput rudarstva ugriza, model a predobuke i iterativnog prevoda natrag, koristimo faktorirani pristup prevoda mašine na malim rečniku BPE.', 'ca': "Aquest paper descriu la presentació d'UdS-DFKI a la tasca compartida de traducció automàtica no supervisada (MT) i MT supervisada amb molt baix recursos entre alemanya (de) i alta sorbia (hsb) a la Quinta Conferència de traducció automàtica (WMT20). Ens submetem sistemes tant per les pistes supervisades com per les que no. A part de diversos enfocaments experimentals com la mineria bitext, el model de pré-entrenament i la traducció repetitiva, fem servir un enfocament de traducció de màquines a un petit vocabulari BPE.", 'cs': 'Tento příspěvek popisuje podání UdS-DFKI do sdíleného úkolu pro strojový překlad bez dozoru (MT) a velmi nízké zdroje dohledované MT mezi němčinou (de) a horním sorbštinou (hsb) na páté konferenci strojového překladu (WMT20). Předkládáme systémy pro dohlížené i bez dozoru tratě. Kromě různých experimentálních přístupů, jako je těžba bitextu, předškolení modelů a iterativní zpětný překlad, používáme faktorovaný strojový překlad na malou slovní zásobu BPE.', 'et': 'Käesolevas dokumendis kirjeldatakse UDS-DFKI alluvust järelevalveta masintõlke (MT) ja väga vähese ressursiga järelevalvega masintõlke (de) ja Ülem-Sorbia (hsb) jagatud ülesandele viiendal masintõlke konverentsil (WMT20). Me esitame süsteeme nii järelevalve- kui ka järelevalveta radadele. Lisaks mitmesugustele eksperimentaalsetele lähenemisviisidele, nagu bitekstide kaevandamine, mudelite eelkoolitus ja iteratiivne tagantõlge, kasutame faktoriga masintõlke lähenemisviisi väikeses BPE sõnavaras.', 'fi': 'T채ss채 artikkelissa kuvataan UdS-DFKI:n osallistumista yhteiseen teht채v채채n valvomattomaan konek채채nn철kseen (MT) ja eritt채in v채h채n resursseja valvottuun konek채채nn철kseen saksan (de) ja yl채sorbian (hsb) v채lill채 viidenness채 konek채채nn철skonferenssissa (WMT20). Toimitamme j채rjestelmi채 sek채 valvotuille ett채 valvomattomille radoille. Lukuun ottamatta erilaisia kokeellisia l채hestymistapoja, kuten bitekstin louhinta, mallien esikoulutus ja iteratiivinen takaisink채채nn철s, k채yt채mme faktorisoitua konek채채nn철st채 pienell채 BPE-sanastolla.', 'jv': 'Perintah iki rambarang nggawe UbS-DFKi kanggo ngilangno karo penting sing gak perusahaan mulai kanggo terjamahan (MT) lan akeh akeh barang-warni nyanggo dolang nyang mulasai MT karo German (de) lan Yupper Sarbian (rsb) ning Kenggo Komerén Universi yang Panjenengan Trabaganjur (WWT 2). Awak dhéwé ngeremu sistem kanggo nik kabèh dumadhakan lan ora bisa nguasah Yala ngilanggar sampeyan operasi sing dibutung kaya banter, model telutung banter, lan mulai terjamahan, ingkang sampeyan operasi tarjamahan karo nganggo urip banter.', 'sk': 'Ta prispevek opisuje predložitev UdS-DFKI skupni nalogi za strojno prevajanje brez nadzora (MT) in nadzorovano strojno prevajanje z zelo nizkimi viri med nemščino (de) in zgornjo sorbijščino (hsb) na Peti konferenci strojnega prevajanja (WMT20). Pošiljamo sisteme tako za nadzorovane kot tudi nenadzorovane proge. Poleg različnih eksperimentalnih pristopov, kot so bitext rudarjenje, predusposabljanje modelov in iterativni retroprevod, uporabljamo faktorski strojni prevod na majhnem besedišču BPE.', 'he': 'העיתון הזה מתאר את ההעברה של UdS-DFKI למשימה המשותפת לתרגום מכונות ללא השגחה (MT) וממשאבים נמוכים מאוד בשגחה של MT בין גרמנית (de) לבין הסורבית העליונה (hsb) במועדון החמישי של התרגום מכונות (WMT20). אנחנו שולחים מערכות גם למסלולים המפוקחים ולא המפוקחים. מלבד גישות ניסויים שונות כמו כריית ביטקסט, אימון מראש, ותרגום חזרה איטרטיבי, אנו משתמשים גישה מתרגם מכונות מפורסמת על מילון קטן BPE.', 'ha': "Wannan karatun na describe the UdS-DFKI wasiyyar da shi zuwa the share job for unsupdated translation of mashine (MT) and extremely lower-resource controlled MT between Jarman (de) and Upper Sorbian (hb) at the Fifth Conference of Machine Translate (WMT20). Muna sami tsarin tsari da ba da tsari ba. Babu daga masu jarrabi masu amfani da kwamfyuta kamar misalin birawikin, misalin shirin da ke yi amfani da shi gaba ɗaya, da kuma masu fassari da bakin-tarjiwa, za'a yi amfani da matsarori masu fassarar kuma a kan wani abu kaɗan na BLE.", 'bo': 'ཤོག ང་ཚོས་ལྟ་རྟོག་པ་དང་ལག་སྟར་མེད་པའི་གླུ་རིམ་གཉིས་ཀྱི་མ་ལག་ཆ་སྤྲོད་པ་ཡིན། Apart from various experimental approaches like bitext mining, model pre-training, and iterative back-translation, we employ a factored machine translation approach on a small BPE vocabulary.'}
{'en': 'CUNI Systems for the Unsupervised and Very Low Resource Translation Task in WMT20', 'ar': 'أنظمة CUNI لمهمة الترجمة غير الخاضعة للإشراف وذات الموارد المنخفضة جدًا في WMT20', 'fr': 'Systèmes CUNI pour la tâche de traduction non supervisée et à très faibles ressources dans WMT20', 'pt': 'Sistemas CUNI para a tarefa de tradução de recursos não supervisionados e muito baixos no WMT20', 'es': 'Sistemas CUNI para la tarea de traducción no supervisada y con muy pocos recursos en WMT20', 'ja': 'WMT 20で監督されていない非常に低いリソースの翻訳タスクのためのCuNiシステム', 'zh': '以 WMT20 无监极低资源转换者 CUNI 统', 'ru': 'Системы CUNI для Неконтролируемого и Очень Низкого Задачи Перевода Ресурсов в WMT20', 'hi': 'WMT20 में असुरक्षित और बहुत कम संसाधन अनुवाद कार्य के लिए CUNI सिस्टम्स', 'ga': 'Córais CUNI don Tasc Aistriú Acmhainní Gan Maoirseacht agus An-Íseal in WMT20', 'el': 'Συστήματα για το έργο μετάφρασης χωρίς επιτήρηση και πολύ χαμηλών πόρων στο WMT20', 'hu': 'CUNI rendszerek a felügyelet nélküli és nagyon alacsony erőforrású fordítási feladatokhoz WMT20', 'kk': 'WMT20 ресурстардың аудару тапсырмасының CUNI жүйелеріName', 'lt': 'CUNI sistemos, skirtos nekontroliuojamai ir labai mažai išteklių vertimo darbui WMT20', 'ms': 'Sistem CUNI untuk Tugas Terjemahan Sumber Tidak Dijaga dan Sangat Rendah dalam WMT20', 'ka': 'Comment', 'ml': 'നിരീക്ഷിക്കപ്പെടാത്ത വിഭവങ്ങള്\u200d', 'it': 'Sistemi CUNI per il compito di traduzione non supervisionato e molto basso di risorse in WMT20', 'mt': 'CUNI Systems for the Unsupervised and Very Low Resource Translation Task in WMT20', 'mn': 'WMT20-д маш бага болон бага боловсролын хөрөнгө оруулалтын CUNI системүүд', 'no': 'Name', 'mk': 'CUNI системи за ненадгледуваната и многу ниска транслекција на ресурси во WMT20', 'ro': 'Sisteme CUNI pentru sarcina de traducere nesupravegheată și cu resurse foarte reduse în WMT20', 'sr': 'CUNI sistemi za neodržavani i vrlo niski prijevod resursa u WMT20', 'pl': 'Systemy CUNI dla zadań tłumaczeniowych nienadzorowanych i bardzo niskich zasobów w WMT20', 'so': 'CUNI Systems for the Unsupervised and Very Low Resource Translation Task in WMT20', 'ta': 'கண்காணிக்கப்படாத மற்றும் மிகவும் குறைந்த மூலம் மொழிபெயர்ப்பு பணிக்கான CUNI அமைப்புகள்', 'ur': 'Name', 'si': 'Name', 'sv': 'CUNI-system för oövervakad översättningsuppgift med mycket låga resurser i WMT20', 'uz': 'QUnicodeControlCharacterMenu', 'vi': 'Pha chế tạo nguồn gốc cho nhiệm vụ dịch không giám sát và rất thấp ở WM20', 'bg': 'Системи за задача за превод без надзор и с много ниски ресурси в WMT20', 'hr': 'CUNI sustavi za neodržavani i vrlo niski prijevod resursa u WMT20', 'da': 'CUNI-systemer til oversættelsesopgaven uden overvågning og meget lav ressource i WMT20', 'nl': 'CUNI-systemen voor de niet-gecontroleerde en zeer lage resource vertaaltaak in WMT20', 'de': 'CUNI Systeme für die unbeaufsichtigte und sehr ressourcenarme Übersetzungsaufgabe in WMT20', 'id': 'Sistem CUNI untuk Tugas Terjemahan Sumber Tak Tersupervisi dan Sangat Rendah di WMT20', 'fa': 'Name', 'ko': 'WMT20에서 감독 없이 리소스가 매우 낮은 번역 작업에 사용되는 CUNI 시스템', 'sw': 'Mfumo wa CUNI kwa ajili ya kazi ya Tafsiri za rasilimali zisizo tazama na zisizo chini sana katika WMT20', 'tr': "WMT20'de Mazmunlar we Aýik Ressurat Terjime Görevleri üçin CUNI Sistemler", 'sq': 'CUNI Systems for the Unsupervised and Very Low Resource Translation Task in WMT20', 'af': 'Name', 'am': 'CUNI Systems for the Unsupervised and Very Low Resource Translation Task in WMT20', 'hy': 'Comment', 'bn': 'WMT20-এ অনুবাদ করা ও খুব কম উৎস অনুবাদ করার জন্য CUNI সিস্টেম', 'az': 'WMT20 içində qeyd edilməmiş və çox düşük Resource Translation Task üçün CUNI Sistemləri', 'bs': 'CUNI sistemi za zadatak neodržavanog i vrlo niskog prevoda resursa u WMT20', 'ca': 'CUNI Systems for the Unsupervised and Very Low Resource Translation Task at WMT20', 'cs': 'CUNI systémy pro nekontrolovaný a velmi nízký překlad zdrojů ve WMT20', 'fi': 'CUNI-järjestelmät WMT20:n valvomattomaan ja erittäin vähäresurssiseen kääntämiseen', 'et': 'CUNI süsteemid järelevalveta ja väga madala ressursiga tõlketöö jaoks WMT20', 'jv': 'CUNI Sistem kanggo ngilangno Sak ora bisa perusahaan lan ganyang bebas kanggo rerambungan aksi Lan sing titik kanggo WWC2Name', 'sk': 'Sistemi CUNI za nalogo prevajanja brez nadzora in zelo nizkih virov v WMT20', 'he': 'מערכות CUNI עבור משימה ההתרשמות של משאבים בלתי מפקחת ומאוד נמוכה', 'ha': 'KCharselect unicode block name', 'bo': 'CUNI WMT20 ནང་དུ་རྒྱབ་སྐྱོར་མེད་པ་དང་ཐུན་ཁུངས་ལ་ཉུང་བའི་ཚིག་ཡིག་སྤྱོད་ཀྱི་ལས་འགུལ་འཁོར་ཡོད།'}
{'en': 'This paper presents a description of CUNI systems submitted to the WMT20 task on unsupervised and very low-resource supervised machine translation between German and Upper Sorbian. We experimented with training on synthetic data and pre-training on a related language pair. In the fully unsupervised scenario, we achieved 25.5 and 23.7 BLEU translating from and into Upper Sorbian, respectively. Our low-resource systems relied on transfer learning from German-Czech parallel data and achieved 57.4 BLEU and 56.1 BLEU, which is an improvement of 10 BLEU points over the baseline trained only on the available small German-Upper Sorbian parallel corpus.', 'es': 'Este artículo presenta una descripción de los sistemas CUNI presentados a la tarea del WMT20 sobre traducción automática supervisada sin supervisión y con muy pocos recursos entre alemán y alto sorabo. Experimentamos con el entrenamiento en datos sintéticos y el entrenamiento previo en un par de idiomas relacionados. En el escenario sin supervisión, logramos 25,5 y 23,7 BLEU traduciendo desde y hacia el alto sorabo, respectivamente. Nuestros sistemas de bajos recursos se basaron en el aprendizaje de transferencia de datos paralelos germano-checo y lograron 57,4 BLEU y 56,1 BLEU, lo que supone una mejora de 10 puntos BLEU con respecto a la línea de base entrenada solo en el pequeño corpus paralelo alemán-sorabo superior disponible.', 'pt': 'Este artigo apresenta uma descrição dos sistemas CUNI submetidos à tarefa WMT20 sobre tradução automática supervisionada não supervisionada e com recursos muito baixos entre alemão e alto-sérvio. Experimentamos treinamento em dados sintéticos e pré-treinamento em um par de idiomas relacionado. No cenário totalmente não supervisionado, alcançamos 25,5 e 23,7 BLEU traduzindo de e para o Alto Sorábio, respectivamente. Nossos sistemas de poucos recursos contaram com o aprendizado de transferência de dados paralelos alemão-tcheco e alcançaram 57,4 BLEU e 56,1 BLEU, o que representa uma melhoria de 10 pontos BLEU em relação à linha de base treinada apenas no pequeno corpus paralelo alemão-sérvio superior disponível.', 'ar': 'تقدم هذه الورقة وصفًا لأنظمة CUNI المقدمة إلى مهمة WMT20 بشأن الترجمة الآلية الخاضعة للإشراف وغير الخاضعة للإشراف والتي تتطلب موارد منخفضة للغاية بين الألمانية والصربية العليا. جربنا التدريب على البيانات التركيبية والتدريب المسبق على زوج لغوي ذي صلة. في السيناريو غير الخاضع للإشراف بالكامل ، حققنا 25.5 و 23.7 BLEU تترجم من وإلى الصوربية العليا ، على التوالي. اعتمدت أنظمتنا منخفضة الموارد على نقل التعلم من البيانات الموازية الألمانية والتشيكية وحققت 57.4 BLEU و 56.1 BLEU ، وهو تحسن بمقدار 10 نقاط BLEU عن خط الأساس الذي تم تدريبه فقط على المجموعة المتوازية الصغيرة المتاحة من الألمانية والصربية العليا.', 'fr': "Cet article présente une description des systèmes CUNI soumis à la tâche WMT20 sur la traduction automatique supervisée non supervisée et à très peu de ressources entre l'allemand et le haut-sorabe. Nous avons expérimenté une formation sur des données synthétiques et une pré-formation sur une paire de langues apparentée. Dans le scénario entièrement non supervisé, nous avons obtenu 25,5 et 23,7 UEBL traduisant depuis et vers le haut-sorabe, respectivement. Nos systèmes à faibles ressources reposaient sur l'apprentissage par transfert à partir de données parallèles germano-tchèques et ont atteint 57,4 UEBL et 56,1 UEBL, soit une amélioration de 10 points UEBL par rapport à la base de référence formée uniquement sur le petit corpus parallèle germano-haut-sorabe disponible.", 'ja': 'この論文では、ドイツ語と上部ソルブ語の間の無監督および非常に低資源の監督機械翻訳に関するWMT 20タスクに提出されたCuNiシステムの説明を紹介します。合成データのトレーニングと関連する言語ペアの事前トレーニングを実験しました。完全に監督されていないシナリオでは、BLEUを上部ソルブ語からとにそれぞれ翻訳することで25.5と23.7を達成しました。当社の低資源システムは、ドイツ-チェコの並列データからの転送学習に依存し、57.4 BLEUと56.1 BLEUを達成しました。これは、利用可能な小さなドイツ-アッパーソルビアの並列コーパスでのみトレーニングされたベースラインよりも10 BLEUポイントの改善です。', 'ru': 'В этой статье представлено описание систем CUNI, представленных для задачи WMT20 по неконтролируемому и очень малоресурсному контролируемому машинному переводу между немецким и верхнесорбским языками. Мы экспериментировали с обучением синтетическим данным и предварительным обучением по связанной языковой паре. В полностью неконтролируемом сценарии мы достигли 25,5 и 23,7 БЛЮ, переведя с и на верхний сорбский соответственно. Наши малоресурсные системы опирались на трансферное обучение из немецко-чешских параллельных данных и достигли 57,4 BLEU и 56,1 BLEU, что представляет собой улучшение на 10 пунктов по сравнению с базовым уровнем, обученным только на имеющемся небольшом немецко-верхнесорбском параллельном корпусе.', 'zh': '本文引WMT20之CUNI统,其事及德语、上索布语之间无监督、非常低资源监机器翻译。 试合成数据,相关言语预训练。 全无监督处,分得25.523.7 BLEU索布语翻译成上索布语。 吾低资源系统赖于从德语-捷克语并行数据而迁学,遂其57.4 BLEU56.1 BLEU,比仅于可用之小德语-索布并行语料库训练之基线10 BLEU矣。', 'hi': 'यह पेपर जर्मन और ऊपरी सोर्बियन के बीच असुरक्षित और बहुत कम संसाधन पर्यवेक्षित मशीन अनुवाद पर WMT20 कार्य के लिए प्रस्तुत CUNI प्रणालियों का विवरण प्रस्तुत करता है। हमने सिंथेटिक डेटा पर प्रशिक्षण और संबंधित भाषा जोड़ी पर पूर्व-प्रशिक्षण के साथ प्रयोग किया। पूरी तरह से असुरक्षित परिदृश्य में, हमने क्रमशः ऊपरी सोर्बियन से और में अनुवाद करते हुए 25.5 और 23.7 बीएलईयू प्राप्त किया। हमारे कम संसाधन प्रणालियों ने जर्मन-चेक समानांतर डेटा से स्थानांतरण सीखने पर भरोसा किया और 57.4 BLEU और 56.1 BLEU प्राप्त किया, जो केवल उपलब्ध छोटे जर्मन-ऊपरी सोर्बियन समानांतर कॉर्पस पर प्रशिक्षित बेसलाइन पर 10 BLEU अंकों का सुधार है।', 'ga': 'Cuireann an páipéar seo cur síos ar chórais CUNI a cuireadh faoi bhráid thasc WMT20 ar aistriúchán meaisín maoirsithe gan mhaoirseacht agus acmhainní an-íseal idir Gearmáinis agus Sorbais Uachtarach. Rinneamar turgnamh le hoiliúint ar shonraí sintéiseacha agus réamh-oiliúint ar phéire teangacha gaolmhara. Sa chás gan mhaoirseacht iomlán, bhaineamar amach 25.5 agus 23.7 BLEU ag aistriú ó agus isteach sa Sorbais Uachtarach, faoi seach. Bhí ár gcórais íseal-acmhainne ag brath ar fhoghlaim aistrithe ó shonraí comhthreomhara Gearmánach-Seice agus bhain siad amach 57.4 BLEU agus 56.1 BLEU, rud atá ina fheabhsú de 10 bpointe BLEU thar an mbunlíne oilte ar an gcorpas comhthreomhar beag Gearmánach-Sorbeach atá ar fáil amháin.', 'el': 'Η παρούσα εργασία παρουσιάζει μια περιγραφή των συστημάτων CUNI που υποβλήθηκαν στο έργο WMT20 για τη μηχανική μετάφραση χωρίς επίβλεψη και με πολύ χαμηλούς πόρους εποπτευόμενη μεταξύ γερμανικών και ανώτερων σορβικών. Πειραματιστήκαμε με εκπαίδευση σε συνθετικά δεδομένα και προεκπαίδευση σε ένα σχετικό γλωσσικό ζευγάρι. Στο σενάριο χωρίς επίβλεψη, πετύχαμε 25.5 και 23.7 BLEU μεταφράζοντας από και προς τα Άνω Σορβικά αντίστοιχα. Τα συστήματα μας με χαμηλούς πόρους βασίστηκαν στη μάθηση μεταφοράς από γερμανικά-τσεχικά παράλληλα δεδομένα και πέτυχαν 57.4 και 56.1 BLEU, η οποία αποτελεί βελτίωση των 10 σημείων BLEU έναντι της βάσης που εκπαιδεύτηκαν μόνο στο διαθέσιμο μικρό γερμανικό-ανώτερο σορβικό παράλληλο σώμα.', 'ka': 'ეს დოკუნტი გამოსახულება CUNI სისტემების გამოსახულება, რომელიც WMT20 დავამუშავებული დავამუშავებული და ძალიან მარტივი რესურსების შესახებ გერმანეთის და ზემო სორბიული შორის შ ჩვენ ვკერიმენტირებდით სინტეტიკური მონაცემებით და წინ განაკეთებული ენაზების ზოგზე. საუკეთესოდ განსხვავებული სენარიოში, ჩვენ 25,5 და 23,7 BLEU გადავიწყეთ, რომელიც მარტივი სორბიანიდან და ზედან. ჩვენი ნაკლები რესურსების სისტემები დარწმუნებულია გერმანული-ფექის პარალელური მონაცემებისგან გასწავლებით და 57,4 BLEU და 56,1 BLEU-ის მიღებულია, რომელიც 10 BLEU-ის გასრულება ბაზილური ფუნტებისგან გასრულებული მხო', 'hu': 'Ez a tanulmány bemutatja a WMT20 feladathoz benyújtott CUNI rendszerek leírását a felügyelet nélküli és nagyon alacsony erőforrással felügyelt gépi fordítással kapcsolatban német és Felső-Szorbia között. Kísérleteztünk szintetikus adatokon végzett képzéssel és előképzéssel egy kapcsolódó nyelvpáron. A teljes mértékben felügyelet nélküli forgatókönyvben 25,5, illetve 23,7 BLEU-t értünk el Felső-Szorbiáról, illetve nyelvre történő fordítással. Alacsony erőforrású rendszereink a német-cseh párhuzamos adatokból származó transzfer tanulásra támaszkodtak, és 57,4 BLEU-t és 56,1 BLEU-t értek el, ami 10 BLEU ponttal javult a kiindulási ponthoz képest, amely csak a rendelkezésre álló kis német-Felső-Szorbia párhuzamos korpuszon képzett.', 'it': "Questo articolo presenta una descrizione dei sistemi CUNI sottoposti al compito WMT20 sulla traduzione automatica non supervisionata e supervisionata a bassissime risorse tra tedesco e Alto Sorbiano. Abbiamo sperimentato formazione su dati sintetici e pre-formazione su una coppia linguistica correlata. Nello scenario completamente non supervisionato, abbiamo raggiunto il 25,5 e il 23,7 BLEU traducendo rispettivamente da e verso l'Alta Sorbia. I nostri sistemi a basse risorse si sono basati sull'apprendimento di trasferimento da dati paralleli tedesco-cechi e hanno raggiunto 57,4 BLEU e 56,1 BLEU, che rappresentano un miglioramento di 10 punti BLEU rispetto al basale addestrato solo sul piccolo corpus parallelo tedesco-alta Sorbia disponibile.", 'mk': 'Овој документ претставува опис на системите CUNI пренесени на задачата WMT20 за ненадгледуван и многу ниски ресурси надгледуван машински превод помеѓу германската и горната сорбијанка. Експериментиравме со обука на синтетички податоци и предобука на поврзан јазик пар. Во целосно ненадгледуваниот сценарио, постигнавме 25,5 и 23,7 БЛЕУ преведувања од и на Горна Сорбија, односно. Нашите системи со ниски ресурси се потпираа на трансфер на учење од германско-чешки паралелни податоци и постигнаа 57,4 БЛЕУ и 56,1 БЛЕУ, што претставува подобрување од 10 БЛЕУ поени во однос на основната основа обучена само на достапниот мал германско-горен сор', 'ms': 'Kertas ini memperkenalkan keterangan sistem CUNI dihantar ke tugas WMT20 pada terjemahan mesin yang tidak diawasi dan yang mengawasi sumber-rendah diantara Jerman dan Upper Sorbian. Kami eksperimen dengan latihan pada data sintetik dan praselatihan pada pasangan bahasa yang berkaitan. Dalam skenario yang tidak diawasi sepenuhnya, kami mencapai 25.5 dan 23.7 BLEU terjemahan dari dan ke Upper Sorbian, berdasarkan. Sistem sumber rendah kami bergantung pada pemindahan belajar dari data selari Jerman-Czech dan mencapai 57.4 BLEU dan 56.1 BLEU, yang merupakan peningkatan 10 BLEU titik atas asas dilatih hanya pada corpus selari kecil Jerman-Upper Sorbian yang tersedia.', 'kk': 'Бұл қағаз WMT20 тапсырмасына жіберілген CUNI жүйелердің сипаттамасын неміс мен жоғарғы сорб арасындағы машинаның аудармасының және өте төмен ресурстар аудармасында жіберілген. Біз синтетикалық деректерді және алдыңғы оқыту үшін тіл екісін тәжірибедік. Бұл сценарияда 25,5 және 23,7 BLEU сорб тілінен және жоғары сорб тіліне аударды. Біздің төменгі ресурстар жүйелеріміз неміс- Чех параллелі деректерінен үйрену оқытуға көмектеседі, 57,4 BLEU және 56,1 BLEU жеткіздік. Бұл жеткілікті неміс- Жоғарғы сорб параллелі корпус үшін тек 10 BLEU нүктеле', 'ml': 'ഈ പത്രത്തില്\u200d ജെര്\u200dമ്മനിലേക്കും മുകളിലേക്കുള്ള സോര്\u200dബിയനിലേക്കും മുകളിലേക്കുള്ള മെഷിന്\u200d പരിഭാഷപ്പെടുത്തിയ സിയുനി സിയുണി സിസ്റ സിന്റെറ്റിക്ക് ഡേറ്റായും മുമ്പ് പരിശീലനത്തിനും പരിശീലനം നടത്തിയിരുന്നു. പൂര്\u200dണ്ണമായും സൂക്ഷിച്ചിട്ടില്ലാത്ത കാഴ്ചപ്പാടില്\u200d ഞങ്ങള്\u200d 25.5, 23.7 ബിലിയു എത്തിയെടുത്തു. അതില്\u200d നിന്നും മുകളില്\u200d നിന Our low-resource systems relied on transfer learning from German-Czech parallel data and achieved 57.4 BLEU and 56.1 BLEU, which is an improvement of 10 BLEU points over the baseline trained only on the available small German-Upper Sorbian parallel corpus.', 'mt': 'Dan id-dokument jippreżenta deskrizzjoni tas-sistemi CUNI sottomessi għall-kompitu WMT20 dwar traduzzjoni tal-magni mhux sorveljata u sorveljata b’riżorsi baxxi ħafna bejn il-Ġermaniż u s-Sorbjan ta’ Fuq. Esperimentajna bit-taħriġ dwar id-dejta sintetika u t-taħriġ minn qabel fuq par lingwistiku relatat. Fix-xenarju kompletament mhux sorveljat, laħaqna 25.5 u 23.7 BLEU li ttrasferixxew minn u lejn in-Upper Sorbian, rispettivament. Is-sistemi tagħna b’riżorsi baxxi kienu jiddependu fuq it-tagħlim tat-trasferiment minn dejta parallela Ġermaniża-Ċeka u kisbu 57.4 BLEU u 56.1 BLEU, li huwa titjib ta’ 10 punti BLEU fuq il-linja bażi mħarrġa biss fuq il-korpus parallelu żgħir Ġermaniż-Sorbjan ta’ Fuq disponibbli.', 'lt': 'Šiame dokumente pateikiamas CUNI sistemų, pateiktų WMT20 uždaviniui dėl nepastebimo ir labai mažai išteklių prižiūrimo mašininio vertimo tarp vokiečių ir viršutinių sorbų, aprašymas. Eksperimentavome su mokymu dėl sintetinių duomenų ir parengiamuoju mokymu dėl susijusios kalbos poros. Atlikus visiškai nepastebimą scenarijų, pasiekėme atitinkamai 25,5 ir 23,7 BLEU vertimo iš ir į viršutinę Sorbą. Mūsų mažai išteklių naudojančios sistemos grindžiamos tuo pačiu metu gautais Vokietijos ir Čekijos duomenimis gautais mokymosi perdavimu ir pasiekė 57,4 BLEU ir 56,1 BLEU, t. y. 10 BLEU taškų pagerėjimas palyginti su pradiniu lygiu, apmokytais tik turimu mažu Vokietijos ir Aukščiausiosios Sorbos lygiagrečiu korpusu.', 'no': 'Denne papiret viser ei skildring av CUNI- systemet som er sendt til WMT20- oppgåva på ikkje- oppretta og veldig låg- ressursoverført maskinsomsetjing mellom tysk og øvre sorbisk. Vi eksperimenterte med opplæring på syntetiske data og føreøving på eit relatert språk par. I den fullstendig usikkerte scenarioen har vi oppnådd 25,5 og 23,7 BLEU som oversetter frå og til øvre sorbiske. Våre låg ressurssystemet er avhengig av læring av overføring frå tysk-tsjekkisk parallelle data og oppnådd 57,4 BLEU og 56,1 BLEU, som er forbedring av 10 BLEU-punkt over baselinja som berre trengte på den tilgjengelege små tysk-oppe sorbiske parallelle korpusen.', 'pl': 'W artykule przedstawiono opis systemów CUNI zgłoszonych do zadania WMT20 dotyczących tłumaczenia maszynowego pomiędzy językiem niemieckim i górnym sorbijskim bez nadzoru i bardzo niskim zasobem. Eksperymentowaliśmy ze szkoleniami na danych syntetycznych i przedszkoleniami na pokrewnej parze językowej. W scenariuszu całkowicie bez nadzoru osiągnęliśmy 25.5 i 23.7 BLEU tłumacząc odpowiednio z i na język górny. Nasze systemy o niskich zasobach opierały się na nauce transferowej z niemiecko-czeskich danych równoległych i osiągnęły 57.4 BLEU i 56.1 BLEU, co stanowi poprawę 10 punktów BLEU w porównaniu z linią bazową szkoloną tylko na dostępnym małym niemiecko-górnym korpusie równoległym.', 'sr': 'Ovaj papir predstavlja opis sistema CUNI koji su podignuti zadatku WMT20 o neodređenom i vrlo niskom resursu nadzornom prevodu mašine između njemačkog i gornjeg Sorbijanskog. Eksperimentirali smo sa obukom o sintetičkim podacima i predobukom na povezanom jezičkom parovu. U potpuno neodređenom scenariju, postigli smo 25,5 i 23,7 BLEU, prevodeći se od i na gornji Sorbijanski. Naši sistemi niskih resursa oslanjaju se na učenje prijenosa iz njemačkih i čeških paralelnih podataka i ostvarili su 57,4 BLEU i 56,1 BLEU, što je poboljšanje 10 BLEU bodova na početnoj liniji obučeno samo na dostupnom malom njemačkom i gornjem sorbijskom paralelnom korpusu.', 'mn': 'Энэ цаас WMT20 ажлын тухай CUNI системийн тодорхойлолтыг Герман болон Жерхэн Сорбийн хоорондын машин хөгжүүлэх болон бага бага нөөцийг удирдаггүй машин хөгжүүлэх тухай тайлбарладаг. Бид хоорондоо холбоотой хэлний хоорондоо синтетик өгөгдлийн талаар сургалтыг туршиж үзсэн. Мөн чанаргүй хувилбарт бид 25.5, 23.7 БЛЕУ-аас, дээд сорб руу шилжүүлж байна. Манай бага эдийн засгийн систем Герман-Чеийн параллел мэдээллээс суралцах болон 57.4 БЛЕС болон 56.1 БЛЕС хүртэл хадгалагдсан. Энэ нь үндсэн цэг дээр 10 БЛЕС цэгүүдийн сайжруулалт юм.', 'ro': 'Lucrarea prezintă o descriere a sistemelor CUNI supuse misiunii WMT20 privind traducerea automată nesupravegheată și supravegheată cu resurse foarte reduse între germană și Sorbiană Superioară. Am experimentat cu formare pe date sintetice și pre-training pe o pereche de limbi conexe. În scenariul complet nesupravegheat, am realizat 25,5 și 23,7 BLEU traducând din Sorbia Superioară și respectiv în Sorbia Superioară. Sistemele noastre cu resurse reduse s-au bazat pe transferul de învățare din date paralele german-cehe și au obținut 57,4 BLEU și 56,1 BLEU, ceea ce reprezintă o îmbunătățire de 10 puncte BLEU față de bază instruită numai pe corpul paralel german-Sorbian superior disponibil.', 'si': 'මේ පත්තේ CUNI පද්ධතියේ විස්තරයක් තියෙනවා WMT20 කාර්යාවට පිළිගන්න බැරි සහ ගොඩක් අඩු සම්බන්ධ පද්ධතිය පද්ධතිය පද්ධතිය අපි සම්බන්ධ භාෂා ජෝඩාවක් ගැන සංස්ථානය දත්ත සහ ප්\u200dරධානය සඳහා පරීක්ෂණය සඳහා ප්\u200dරයෝ සම්පූර්ණයෙන් නැති සිනාරියෝ වලින්, අපි 25.5 සහ 23.7 බ්ලූස් වලින් සෝර්බියාන් වලින් පටන් ගත්තා. අපේ අඩු ප්\u200dරධාන පද්ධතියක් ජර්මාන්-චෙක් සමාන්\u200dය දත්තෙන් ඉගෙන ගන්න පුළුවන් විදිහට විශ්වාස කරලා තියෙන්නේ ජර්මාන්-චෙක් වලින් සාමාන්\u200dය දත්ත 57', 'ta': 'This paper presents a description of CUNI systems submitted to the WMT20 task on unservised and very low- resource supervised machine translation between German and Upper Sorbian. நாங்கள் ஒரு தொடர்புடைய மொழி ஜோடியை பயிற்சியுடன் பரிசோதித்தோம். முழு பாதுகாப்பாக்கப்படாத காட்சியில், நாங்கள் முழுமையாக 25.5 மற்றும் 23.7 பிலியு மொழிபெயர்ப்பில் இருந்து மேல் சோபி Our low-resource systems relied on transfer learning from German-Czech parallel data and achieved 57.4 BLEU and 56.1 BLEU, which is an improvement of 10 BLEU points over the baseline trained only on the available small German-Upper Sorbian parallel corpus.', 'sv': 'Denna uppsats presenterar en beskrivning av CUNI-system som lämnats in för WMT20-uppgiften om oövervakad och mycket resursövervakad maskinöversättning mellan tyska och övre Sorbiska. Vi experimenterade med utbildning på syntetiska data och pre-training på ett relaterat språkpar. I det helt obevakade scenariot uppnådde vi 25,5 respektive 23,7 BLEU-översättningar från och till Övre Sorbiana. Våra lågresurssystem förlitade sig på överföring av lärande från tysk-tjeckiska parallella data och uppnådde 57,4 BLEU och 56,1 BLEU, vilket är en förbättring med 10 BLEU-poäng jämfört med baslinjen som endast tränats på den tillgängliga lilla tysk-övre sorbiska parallella korpusen.', 'ur': 'This paper presents a description of CUNI systems submitted to the WMT20 task on unsupervised and very low-resource supervised machine translation between German and Upper Sorbian. ہم نے ایک مرتبہ زبان جوڑے پر سینٹیٹیک ڈیٹے اور پہلے ترکینس کے ذریعہ تطارین کے ساتھ تجربہ کی۔ پورے غیرقابل نظریہ میں ہم نے 25.5 اور 23.7 بلیوس کو پورے سوربیان سے اور اوپر سے ترجمہ کیا۔ ہمارے نیچے منبع سیستموں نے جرمن-چک کے پارالل ڈاٹ سے تعلیم کی ترافیس پر اعتماد کی اور 57.4 بلیوس اور 56.1 بلیوس کو پہنچا، جو بنیس لین پر 10 بلیوس پوینٹوں کی تدریس کی ہے جو صرف موجود تھوڑی جرمن-اوپر سوربی پارالل کورپوس پر آموزش کی گئی تھ', 'so': 'This paper presents a description of CUNI systems submitted to the WMT20 task on unsupervised and very low-resource supervised machine translation between German and Upper Sorbian.  Waxaannu ku jirrabnay waxbarasho ku saabsan macluumaadka la xiriira iyo waxbarashada ka horraysa labada luqadood. Muuqashada aan dhamaan la ilaalinayn ayaannu gaadhnay qiyaas ahaan 25,5 iyo 23.7 BLEU, taasoo looga tarayo iyo ilaa Sorbiya Yuqoriga sare. nidaamkayaga hoose-resource waxay ku xiran tahay wareejinta waxbarashada qoraalka Jarmalka-Czech, waxayna gaadhay 57.4 BLEU iyo 56.1 BLEU, taasoo ah hagaajinta 10 BLEU points oo ku qoran baseline oo keliya lagu baran karo jarmal-Upper Sorbian parallel corpus.', 'uz': "Name Biz bir xil tilning bir xil bo'lgan tizim haqida o'rganishni o'rganamiz. Butun muvaffaqiyatli saqlanmagan tashkilotda, biz har xil 25.5 va 23.7 BLEU tarjima qildik, yuqori Sorbchaga va yuqori Sorbiga. Bizning kichkina resource tizimimiz Olmon-Chech parallel maʼlumotdan o'rganishga ishonchini ishlatadi va 57.4 BLEU va 56.1 BLEU imkoniyatlariga ega bo'ldi. Bu faqat yaxshi Olmon-Yuqori Sorbiy parallel korpusda o'rganilgan kichkina Olmon-Yuqori bo'lgan 10 BLEU nuqta o'zgartiradi.", 'vi': 'Tờ giấy này mô tả hệ thống CUPS được gửi đến nhiệm vụ WM210 theo dịch vụ không giám sát và tài nguyên nhỏ được giám sát bằng máy giữa Đức và Upper Sorbian. Chúng tôi thí nghiệm với huấn luyện về các dữ liệu nhân tạo và huấn luyện về một cặp ngôn ngữ liên quan. Trong một kịch bản hoàn toàn không được giám sát, chúng tôi đã đạt được 25.5 và 23.7 BleU dịch từ và sang Upper Sorbian. Hệ thống ít tài nguyên dựa trên việc học cách truyền thông từ dữ liệu song song Đức-Séc và đạt được 57.4 LELIU và 56.1 LELIU, đó là một sự cải thiện mười nguyên tắc trên cơ sở cơ bản được đào tạo chỉ dựa trên tập hợp song dòng Đức-Upper Sorbian.', 'bg': 'Настоящата статия представя описание на системите на CUNI, подложени на задачата WMT20 за машинен превод без надзор и много нисък ресурс между немски и горно сорбийски. Експериментирахме с обучение по синтетични данни и предварителна подготовка на съответна езикова двойка. В напълно незаблюдавания сценарий постигнахме 25.5 и 23.7 преводи съответно от и на Горно-сорбийски. Нашите нискоресурсни системи разчитаха на трансферно обучение от германско-чешки паралелни данни и постигнаха 57.4 и 56.1 което представлява подобрение с 10 точки спрямо базовата база, обучавани само на наличния малък германско-горно сорбийски паралелен корпус.', 'nl': 'Dit document presenteert een beschrijving van CUNI-systemen die zijn ingediend voor de WMT20-taak op onbeheerde en zeer lage resource begeleide machinevertaling tussen Duits en Opper-Sorbisch. We experimenteerden met training op synthetische data en pre-training op een verwant taalpaar. In het volledig onbeheerde scenario hebben we 25.5 en 23.7 BLEU behaald met respectievelijk vertalen van en naar het Oppersorbisch. Onze low-resource systemen steunden op transfer learning van Duits-Tsjechisch parallelle data en behaalden 57.4 BLEU en 56.1 BLEU, wat een verbetering is van 10 BLEU punten ten opzichte van de basislijn die alleen werd getraind op het beschikbare kleine Duits-Bovensorbische parallelle corpus.', 'de': 'In diesem Beitrag werden CUNI-Systeme beschrieben, die für die WMT20-Aufgabe zur unbeaufsichtigten und sehr ressourcenschonenden maschinellen Übersetzung zwischen Deutsch und Obersorbisch eingereicht wurden. Wir experimentierten mit Training auf synthetischen Daten und Vortraining auf einem verwandten Sprachpaar. Im völlig unbeaufsichtigten Szenario erreichten wir 25.5 und 23.7 BLEU Übersetzungen aus und ins Obersorbische. Unsere ressourcenarmen Systeme setzten auf Transferlernen aus deutsch-tschechischen parallelen Daten und erreichten 57.4 BLEU und 56.1 BLEU, was eine Verbesserung von 10 BLEU-Punkten gegenüber der Basislinie ist, die nur auf dem verfügbaren kleinen deutsch-obersorbischen Parallelkorpus trainiert wurde.', 'hr': 'Ovaj papir predstavlja opis sustava CUNI-a predan zadatku WMT20 o neodržavanom i vrlo niskom resursu nadziranom prevodu strojeva između njemačkog i gornjeg Sorbijanskog. Eksperimentirali smo s obukom o sintetičkim podacima i predobukom o povezanim jezičkim parovima. U potpuno neodređenom scenariju, postigli smo 25,5 i 23,7 BLEU, prevodeći se od i na gornji Sorbijanski. Naši sustavi niskih resursa oslanjaju se na učenje prijenosa iz njemačkih i čeških paralelnih podataka i ostvarili su 57,4 BLEU i 56,1 BLEU, što je poboljšanje 10 BLEU bodova na početnoj liniji obučeno samo na dostupnom malom njemačkom i gornjem sorbijskom paralelnom korpusu.', 'id': 'Kertas ini menampilkan deskripsi sistem CUNI yang dihantar ke tugas WMT20 pada terjemahan mesin yang tidak diawasi dan sangat rendah sumber daya yang diawasi antara Jerman dan Upper Sorbian. We experimented with training on synthetic data and pre-training on a related language pair.  Dalam skenario yang sepenuhnya tidak diawasi, kami mencapai 25,5 dan 23,7 BLEU terjemahan dari dan ke Upper Sorbian, sesuai. Sistem sumber daya rendah kami bergantung pada transfer belajar dari data paralel Jerman-Ceko dan mencapai 57,4 BLEU dan 56,1 BLEU, yang merupakan peningkatan 10 BLEU titik di atas dasar terlatih hanya pada corpus paralel kecil Jerman-Upper Sorbian yang tersedia.', 'sw': 'This paper presents a description of CUNI systems submitted to the WMT20 task on unsupervised and very low-resource supervised machine translation between German and Upper Sorbian.  Tulijaribu kwa mafunzo kuhusu taarifa za pamoja na mafunzo ya awali kuhusu mbili za lugha zinazohusiana. Katika tukio hilo lisiloeleweka, tulifanikiwa BLEU 25.5 na 23.7 yenye tafsiri kutoka na kwenda kwa Ki-Sorbia Kuu. Mfumo wetu wa rasilimali zisizo chini ulitegemea kuhamisha kujifunza kutoka kwa takwimu zinazofanana na Ujerumani-Czech na kupata vifaa 57.4 BLEU na 56.1 BLEU, ambavyo ni maendeleo ya pointi 10 BLEU juu ya msingi ulioelekezwa tu kwenye makampuni madogo yanayopatikana na Kijerumani-Upper Sorbia.', 'ko': '본고는 WMT20 임무에 제출된 CUNI 시스템을 묘사하는데 이 임무는 독일어와 상소포어 간의 무감독과 극저 자원 감독 기계 번역을 포함한다.우리는 합성 데이터에 대해 훈련을 하고 관련 언어에 대해 예비 훈련을 한다.전혀 감독이 없는 상황에서 우리는 각각 25.5개와 23.7개의 BLEU가 상삭포계에서 상삭포계까지의 번역을 실현하였다.우리의 저자원 시스템은 독일어-체코어 평행 데이터의 이동 학습에 의존하여 57.4BLEU와 56.1BLEU를 얻었고 사용 가능한 소형 독일어에서만 삭브어 평행 어료 라이브러리에서 훈련하는 기선보다 10BLEU점을 높였다.', 'fa': 'این کاغذ تعریف سیستم\u200cهای CUNI را به کار WMT20 ارائه می\u200cدهد که در مورد ترجمه دستگاه\u200cهای ناتوان و بسیار کم منابع تحت نظر بین آلمان و سوربیان بالا است. ما با تمرین روی داده های سناتیک و پیش آموزش روی یک جفت زبان رابطه آزمایش کردیم. در سناریو کاملا غیر قابل تحقیق، ما 25.5 و 23.7 بلوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئ سیستم\u200cهای کمترین منابع ما بر یادگیری انتقال از داده\u200cهای parallel آلمان و چک بستگی دارند و به 57.4 BLEU و 56.1 BLEU رسیدند، که بهترین 10 نقطه\u200cهای BLEU بر اساس خط پایین آموزش داده شده تنها بر اساس کوچک parallel آلمان و بالا سوربیان کوچک موجود است.', 'tr': 'Bu kagyz WMT20 we üst-sorbiň arasynda masynyň terjime edilmegi üçin CUNI sistemalaryň waspyny görkezýär. Biz sintetik maglumatlar we baglanyş dil çift bilen öňünden öňünden okuwçy bilen synanyşdyrdyk. Doly tassyklanmadyk senaryýada 25.5 we 23.7 BLEU-dan we üst-sorbiýa terjime edip bardyk. Biziň iň az resurslarymyz Germaniýa-Çehiýanyň parallel maglumatlaryndan öwrenmegi öwrenmegine güýçlendi we 57', 'da': 'Denne artikel præsenterer en beskrivelse af CUNI-systemer, der er indsendt til WMT20-opgaven om maskinoversættelse uden overvågning og meget lav ressource mellem tysk og øversorbisk. Vi eksperimenterede med træning på syntetiske data og pre-træning på et beslægtet sprogpar. I det fuldt ud uautoriserede scenario opnåede vi 25,5 og 23,7 BLEU-oversættelser fra og til Øversorbisk. Vores systemer med lav ressource baserede sig på overførsel af læring fra tysk-tjekkisk parallelle data og opnåede 57,4 BLEU og 56,1 BLEU, hvilket er en forbedring på 10 BLEU point i forhold til baseline kun uddannet på den tilgængelige lille tysk-øversorbiske parallelkorpus.', 'af': "Hierdie papier voorstel 'n beskrywing van CUNI stelsels wat na die WMT20 taak ondersteun is op ongeondersteunde en baie lae- hulpbron ondersoekte masjien vertaling tussen Duits en Boppe Sorbiese. Ons het eksperimenteer met onderwerp op sintetiese data en voorwerp op 'n verwante taal paar. In die volledige onverondersteunde scenario het ons 25,5 en 23,7 BLES, wat respectively van en na Bo-Sorbiese vertaling het. Ons lae-hulpbronne stelsels het op oordrag leer van Duitse-Tsjeë parallele data geloop en 57.4 BLEU en 56.1 BLEU bereik, wat is 'n verbetering van 10 BLES punte oor die basisline wat slegs op die beskikbare klein Duitse-Boppe-Sorbise parallele korpus opgelei het.", 'sq': 'This paper presents a description of CUNI systems submitted to the WMT20 task on unsupervised and very low-resource supervised machine translation between German and Upper Sorbian.  Eksperimentuam me trajnimin e të dhënave sintetike dhe paratrajnimin në një çift gjuhësh të lidhura. Në skenarin plotësisht të papërgjidhur, arritëm 25.5 dhe 23.7 BLEU që përkthyen respektivisht nga dhe në Upper Sorbian. Sistemet tona me burime të ulëta mbështeteshin në transferimin e mësimit nga të dhënat paralele gjermano-çeke dhe arritën 57.4 BLEU dhe 56.1 BLEU, që është një përmirësim prej 10 pikësh BLEU mbi bazën e trajnuar vetëm në korpus paralel të vogël gjermano-sorbik të lartë në dispozicion.', 'am': 'ይህ ፕሮግራም በጀርመን እና በላይ ሶርብኛ መካከል የተጠበቀው የCUNI ስርዓቶች በWMT20 ስራ ላይ የተዘጋጁትን ትርጓሜ የሚያቀርብ ነው፡፡ በቋንቋው ሁኔታ ላይ የስንቲካዊ ዳታዎችን እና ቀድሞ ትምህርት ተፈትተናል፡፡ በተፈጸመ ስዕይት ውስጥ 25.5 እና 23.7 ቡሊউ አግኝተናል፡፡ ከጀርመን-ቻክክ ተቃውሞ ዳታ ትምህርታችንን በመስጠት ታድጋለች፤ 57.4 BLEU እና 56.1 BLEU አግኝቷል፤ ይህም ከታናሽ ጀርመን-ላይኛይቱ ሶርብኛ ተለይቶ በተገኘው የብሊዩን የደረጃ መስኮት ብቻ ነው፡፡', 'az': "Bu kağıt WMT20 vəsiyyətinə müdafiə edilməmiş və çox düşük çoxlu çoxlu istifadə edilmiş maşın tərzini Alman və Üst Sorbi arasında tərzi edilən CUNI sistemlərinin tərzini göstərir. Biz sintetik məlumatlar və əvvəlcə təhsil edilən dil çift üçün təhsil etdik. Tam təmizlənmədiyimiz scenariyada 25,5 və 23,7 BLEU-nin üst Sorbistan və üst Sorbistan'a çevirildik. Bizim düşük ressurs sistemimiz Alman-Çək paralel məlumatlarından öyrənmək öyrənməyə təvəkkül etdi və 57.4 BLEU və 56.1 BLEU-a yetişdi. Bu, əsas səhifələrində təhsil edilən 10 BLEU nöqtələrində yalnız mövcud Alman-Yuxarı Sorba paralel korpusu üzərində təhsil edilmişdir.", 'bn': 'এই পত্রিকাটি জার্মান এবং উপর সোর্বিয়ানের মধ্যে অনুবাদ করা মেশিনের অনুবাদের উপর ডিএমটি২০ কাজে প্রদান করা সিইউনি সিস্টেমের একটি বর্ণনা দিয়েছে। আমরা সিন্টেটিক ডাটা এবং সংশ্লিষ্ট ভাষার জোড়ায় প্রশিক্ষণ নিয়ে পরীক্ষা করেছি। সম্পূর্ণ অরক্ষিত দৃশ্যে আমরা ২৫. ৫ এবং ২৩. আমাদের নীচের সম্পদ ব্যবস্থা জার্মান-চেকের প্যারালেল ডাটা থেকে শিক্ষা নির্ভর করে এবং ৫৭. ৪ বিলিউ এবং 56. ১ বিলিউ অর্জন করেছে, যা বেসেলাইনের মাধ্যমে প্রশিক্ষণ করা হয়েছে শুধুমাত্র জ', 'bs': 'Ovaj papir predstavlja opis sistema CUNI koji su podignuti zadatku WMT20 o neodređenom i vrlo niskom resursu nadziranom prevodu mašine između njemačkog i gornjeg Sorbijanskog. Eksperimentirali smo sa obukom o sintetičkim podacima i predobukom o povezanim jezičkim parovima. U potpuno neodređenom scenariju, postigli smo 25,5 i 23,7 BLEU, prevodeći se odnosno iz i na gornju Sorbiju. Naši sistemi niskih resursa oslanjaju se na učenje prijenosa iz paralelnih podataka njemačkog i češkog i ostvarili su 57,4 BLEU i 56,1 BLEU, što je poboljšanje 10 BLEU bodova na početnoj liniji obučeno samo na dostupnom malom njemačkom i gornjem sorbijskom paralelnom korpusu.', 'hy': 'Այս աշխատանքը ներկայացնում է CuNY համակարգերի նկարագրությունը, որը ներկայացված է աշխարհի աշխարհի 20 խնդիրներին անվերահսկվող և շատ ցածր ռեսուրսների վերահսկվող մեքենային թարգմանման մասին գերմանացի և վերևի սորբյան միջև: Մենք փորձարկում էինք սինթետիկ տվյալների ուսումնասիրության և նախապատրաստման հետ կապված լեզվի զույգի հետ: Ամբողջ անվերահսկվող սցենարիայում մենք հասանք 25.5 և 23.7 ԲԼԵԵ-ի թարգմանման վերևի սորբյան լեզվով: Մեր ցածր ռեսուրսների համակարգերը հիմնվեցին գերմաներեն-ցեխերեն զուգահեռ տվյալներից ստացված ուսումնասիրության վրա և հասան 57.4 ԲԼԵՎ և 56.1 ԲԼԵՎ, ինչը 10 բԼԵՎ միավոր բարելավում է հիմքի վրա, որը կրթություն է ստացվում միայն գերմաներեն-վեր', 'ca': "This paper presents a description of CUNI systems submitted to the WMT20 task on unsupervised and very low-resource supervised machine translation between German and Upper Sorbian.  Hem experimentat amb entrenament en dades sintètiques i pré-entrenament en un parell de llenguatges relacionats. In the fully unsupervised scenario, we achieved 25.5 and 23.7 BLEU translating from and into Upper Sorbian, respectively.  Els nostres sistemes de baix recursos van basar-se en l'aprenentatge de transfer ència de dades paralleles alemanya-ceca i van aconseguir 57,4 BLEU i 56,1 BLEU, que és una millora de 10 BLEU punts sobre el basal entrenat només en el petit corpus parallel alemanya-Alta Sorbia disponible.", 'et': 'Käesolevas töös esitatakse CUNI süsteemide kirjeldus, mis on esitatud WMT20 ülesandele järelevalveta ja väga vähese ressursiga järelevalvega masintõlke saksa ja Ülem-Sorbia keele vahel. Eksperimenteerisime sünteetiliste andmete koolitusega ja eelkoolitusega seotud keelepaaril. Täielikult järelevalveta stsenaariumis saavutasime 25,5 ja 23,7 BLEU tõlkes vastavalt Ülem-sorbiini keelest ja Ülem-sorbiini keelde. Meie madala ressursiga süsteemid tuginesid Saksa-Tšehhi paralleelsetest andmetest saadud siirdeõppele ja saavutasid 57,4 BLEU ja 56,1 BLEU, mis tähendab 10 BLEU-punkti paranemist võrreldes lähtetasemega, mida koolitati ainult olemasoleva väikese Saksa-Ülem-Sorbia paralleelse korpusega.', 'cs': 'Tento článek představuje popis systémů CUNI předložených k úkolu WMT20 na strojovém překladu bez dohledu a s velmi nízkými zdroji. Experimentovali jsme se školením na syntetických datech a předškolením na příbuzném jazykovém páru. Ve scénáři plně bez dozoru jsme dosáhli 25.5 a 23.7 BLEU překladu z horního sorbštiny a do horního. Naše systémy s nízkými zdroji spoléhaly na transferové učení z německo-českých paralelních dat a dosáhly 57.4 BLEU a 56.1 BLEU, což je zlepšení deseti BLEU bodů oproti základnímu tréninku trénovaných pouze na dostupném malém německo-hornosorbském paralelním korpusu.', 'fi': 'Tässä artikkelissa esitetään kuvaus CUNI-järjestelmistä, jotka on lähetetty WMT20-tehtävään valvomattomassa ja erittäin vähän resursseja valvotussa konekäännöksessä saksan ja yläsorbian välillä. Kokeilimme synteettistä dataa koskevaa koulutusta ja esikoulutusta vastaavalla kieliparilla. Täysin valvomattomassa skenaariossa saavutimme 25,5 ja 23,7 BLEU:n käännökset yläsorbiasta. Vähävaraiset järjestelmämme luottivat siirtooppimiseen saksa-tšekkiläisestä rinnakkaisaineistosta ja saavuttivat 57,4 BLEU:n ja 56,1 BLEU:n, mikä merkitsee 10 BLEU:n parannusta lähtötasoon verrattuna, joka on koulutettu vain saatavilla olevalla pienellä saksa-yläsorbialaisella rinnakkaiskorpusella.', 'jv': 'Perintah iki dadi nggawe sistem CUNI sing nyimpen mruput kanggo ngerasai WWC2 karo akeh basa sing gak ngregani apat lan akeh barang pengguna-apat kanggo ngerasai perusahaan karo WWC2. Awak dhéwé éntuk nggambar barang seneng dadi seneng pisan-arahan lan mulasar seneng nggawe barang langgambar. Nanging perusahaan sing gak perusahaan, kita sampeyan panjenengan tanggal wih-wih kanggo nganggo alam sing katêpakan dengan nguasar suarané Awak dhéwé sistem sing paling-pernik sing paling-pernik kuwi nggawe barang kelas karo data yang alaman-Chek kuwi dianggap gampang kanggo nyengkuyé awak dhéwé. Awak dhéwé, sing paling-teka sing paling-teka sing paling-tatang kanggo awak dhéwé ning sampek isi alaman-pakan.', 'sk': 'V prispevku je predstavljen opis sistemov CUNI, predloženih v nalogo WMT20 za strojno prevajanje brez nadzora in zelo nizkih virov med nemščino in zgornjo sorbijščino. Eksperimentirali smo usposabljanje na sintetičnih podatkih in predusposabljanje na sorodnem jezikovnem paru. V popolnoma neobzorovanem scenariju smo dosegli 25,5 in 23,7 BLEU prevajanja iz zgornje sorbijskega jezika. Naši sistemi z nizkimi viri so se zanašali na transferno učenje iz nemško-čeških vzporednih podatkov in dosegli 57,4 BLEU in 56,1 BLEU, kar je izboljšanje za 10 točk BLEU v primerjavi z izhodiščem, usposobljeno samo na razpoložljivem majhnem nemško-zgornjosorbijskem vzporednem korpusu.', 'he': "הנייר הזה מציג תיאור של מערכות CUNI שנשלחו למשימה WMT20 על תרגום מכונות ללא משמר וממשאבים נמוכים מאוד בין גרמנית לסורבית העליונה. We experimented with training on synthetic data and pre-training on a related language pair.  In the fully unsupervised scenario, we achieved 25.5 and 23.7 BLEU translating from and into Upper Sorbian, respectively.  מערכות המשאבים הנמוכות שלנו הסמכו על ההעברה של לימוד ממידע מקביל גרמני-צ'קי והשגעו 57.4 BLEU ו-56.1 BLEU, שזה שיפור של 10 נקודות BLEU מעל הבסיס מאומנים רק על הקורפוס הקטן הגרמני-סורבי הקטן זמין.", 'ha': "Wannan karatun na bãyar da description of CUNI's system wanda aka saka zuwa the WMT20 aikin da aka yi wa bada tsare da kuma mafi ƙasƙanci-resource-wato translation of mashine between Jarman da kuma Sorbian na Samare. We experimented with training on synthetic data and pre-training on a related language pair.  In the cikakken unsupdated zone, we achieve a shekara 25.5 da 23.7 BLEU wanda aka fassara daga kuma zuwa Sorbian Juu. Rufiyõyinmu na ƙaranci-resource sun dõgara a kan transfer da aka sanar da shi daga jeron-Czech parallel data kuma suka sami 57.4 BLEU da 64.1 BLEU, wannan yana da gyãra wa 10 BLEU points a kan basalin linje wanda aka yi wa amfani da shi kawai na ƙarami jama'in-jama'ar-Upper Sorbian parallel.", 'bo': 'ཤོག་བྱང་འདིས་CUNI མ་ལག་གི་སྔོན་ལ་དུ་WMT20 ལས་བྱ་འགུལ་གྱི་འགྲེལ་བཤད་མང་ཙམ་སྟོན་པ་ཡིན་ནམ་རྫུན་མི་སྒྲིག་ཆས་ལ་ཆོག་ཉུང་ཡི ང་ཚོས་སྦྲེལ་བའི་སྐད་ཆ་གཉིས་ཀྱིས་དབྱེ་སྟངས་དང་སྔོན་གྱི་གནད་དོན་དག་གནང་བ་རེད། མ་ཤེས་པའི་དཔེར་བརྗོད་འདི་ནང་གི་ངེད་ཚོར་སྐྱོན་བརྗོད་མེད་པའི་སྐྱེས་ཆེན་གཉིས་དང་འགྲོ་གཉིས་ཡུལ། ང་ཚོའི་རྒྱུ་ཆས་ཆུང་བའི་མ་དངུལ་དུ་དམིགས་ཡུལ་ནི་སྐོར་ལས་ཕར་ཆེན་ལས་ཕར་ཆེན་བྲིས་German-Czech་ལས་སྦྱོར་ཡོད་པའི་ཚད་གཞི་བཞག་སྟངས་ལ་བསྐྱེད་ཡོདཔ། དེ་ནི་ཕར་ཆེན་སྐྱེལ་'}
{'en': 'The University of Helsinki and Aalto University submissions to the WMT 2020 news and low-resource translation tasks', 'ar': 'تقدم جامعة هلسنكي وجامعة آلتو أخبار WMT 2020 ومهام الترجمة منخفضة الموارد', 'es': 'La Universidad de Helsinki y la Universidad de Aalto presentan al WMT 2020 noticias y tareas de traducción con pocos recursos', 'pt': 'As submissões da Universidade de Helsinque e da Universidade de Aalto para as notícias do WMT 2020 e tarefas de tradução de poucos recursos', 'fr': "L'Université d'Helsinki et l'Université Aalto soumettent leurs candidatures aux actualités du WMT 2020 et aux tâches de traduction à faibles ressources", 'zh': '赫尔辛基大学与阿尔托大学提交WMT 2020新闻资源匮译', 'ja': 'ヘルシンキ大学とアールト大学がWMT 2020ニュースと低リソース翻訳タスクに提出', 'hi': 'हेलसिंकी विश्वविद्यालय और Alto University WMT 2020 समाचार और कम संसाधन अनुवाद कार्यों के लिए प्रस्तुतियाँ', 'ru': 'Университет Хельсинки и Университет Аалто подают заявки на выполнение задач по переводу новостей и малоресурсных ресурсов WMT 2020', 'ga': 'Déanann Ollscoil Heilsincí agus Ollscoil Aalto aighneachtaí do thascanna aistriúcháin nuachta agus acmhainní ísle WMT 2020', 'ka': 'ჰელსინკის და ალტო სუნივერტის სუნივერტის გასაგებით WMT 2020 ნუზების და დაბალი რესურსის გასაგების სამუშაოდ', 'it': "Le candidature dell'Università di Helsinki e dell'Università di Aalto alle notizie WMT 2020 e alle attività di traduzione a basso contenuto di risorse", 'hu': 'A Helsinki Egyetem és az Aalto Egyetem beadványai a WMT 2020 hírekre és alacsony forrásból álló fordítási feladatokra', 'el': 'Υποβολές του Πανεπιστημίου του Ελσίνκι και του Πανεπιστημίου Aalto στις ειδήσεις WMT 2020 και εργασίες μετάφρασης χαμηλού κόστους', 'lt': 'Helsinkio universitetas ir Aalto universitetas pateikė WMT 2020 naujienų ir mažai išteklių turinčių vertimo užduočių pasiūlymus', 'kk': 'Helsinki және Aalto университетінің WMT 2020 жаңалықтарына және төмен ресурстарды аудару тапсырмаларына жіберу', 'mk': 'Универзитетот во Хелсинки и Универзитетот Алто ги поднесуваат вестите на ВМТ 2020 и задачите за превод со ниски ресурси', 'ms': 'Universiti Helsinki dan Universiti Aalto menghantar berita WMT 2020 dan tugas terjemahan sumber rendah', 'ml': 'ഹെല്\u200dസിങ്കിയുടെ യൂണിവേഴ്സിറ്റിയും ആല്\u200dട്ടോ യൂണിവേഴ്സിറ്റിയും WMT 2020 വാര്\u200dത്തകള്\u200dക്കും കുറഞ്ഞ വിവരങ്ങള്\u200d', 'mt': 'The University of Helsinki and Aalto University submissions to the WMT 2020 news and low-resource translation tasks', 'pl': 'Uniwersytet Helsiński i Uniwersytet Aalto zgłoszenia do wiadomości WMT 2020 i zadań tłumaczeniowych o niskich zasobach', 'ro': 'Universitatea din Helsinki și Universitatea Aalto participă la știrile WMT 2020 și la sarcinile de traducere cu resurse reduse', 'no': 'University of Helsinki and Aalto University submissions to the WMT 2020 news and low-resource translation tasks', 'mn': 'Хельсинки болон Алто Их Сургуулийн Их Сургууль WMT 2020 оны мэдээг болон бага боломжтой хөрөнгө оруулалт', 'sv': 'Helsingfors universitet och Aalto-universitetets bidrag till WMT 2020-nyheterna och 繹vers瓣ttningsuppgifterna med l疇ga resurser', 'so': 'Jaamacadda Helsinki iyo Jaamacadda Aalto waxay u dhiibeen wararka WMT 2020 iyo shaqooyinka turjumista hoose resource', 'ur': 'ہلسینکی اور آلتو یونیورسٹی یونیورسٹی کے واسطے WMT 2020 نیویورسٹ اور کم رسورسٹ ترجمہ کے کاموں کے لئے', 'ta': 'ஹெல்சிங்கி கல்லாசிரி மற்றும் Aalto University WMT 2020 செய்திகள் மற்றும் குறைந்த மூலம் மொழிபெயர்ப்பு பணிகளுக்கு ஒப்பு', 'sr': 'Univerzitet Helsinki i Aalto Univerziteta podnosi na vijesti WMT 2020 i zadatke za prevod niskih resursa', 'si': 'හෙල්සින්කි සහ ආල්ටෝ විශ්වාසික විද්\u200dයාපිත්ත විද්\u200dයාපිත්ත විද්\u200dයාපිත්ත විද්\u200dයාපිත්ත විද්\u200dයාපි', 'uz': 'Helsinki Universitet va Aalto University WMT 2020 xabar va low resource tarjima vazifalarini', 'vi': 'Chi viện của Helsinki và Aalto Đại học Sẽ đưa tin cho WRT 2020 và việc dịch chuyển với nguồn lực ít ỏi', 'bg': 'Университетът в Хелзинки и Университетът в Айло кандидатстват за новините и задачите за превод с нисък ресурс', 'da': 'Helsinki Universitet og Aalto Universitet indsender til WMT 2020 nyheder og oversættelsesopgaver med lav ressource', 'hr': 'Predložbe Univerziteta Helsinki i Aalto Univerziteta na vijesti WMT 2020 i zadatke prevoda s niskim resursima', 'de': 'Einreichungen der Universität Helsinki und der Aalto Universität zu WMT 2020 Nachrichten und ressourcenschonende Übersetzungsaufgaben', 'nl': 'De Universiteit van Helsinki en de Aalto Universiteit inzendingen aan het WMT 2020 nieuws en low-resource vertaaltaken', 'ko': '헬싱키 대학과 알토 대학이 WMT 2020 뉴스 및 저자원 번역 과제에 제출', 'fa': 'دانشگاه هلسینکی و دانشگاه آلتو به اخبار WMT 2020 و وظیفه ترجمه کم منابع', 'af': 'Die Universiteit van Helsinki en Aalto Universiteit onderskrywings aan die WMT 2020 nuus en lae-hulpbron vertalingstaak', 'id': 'Universitas Helsinki dan Universitas Aalto menyerahkan berita WMT 2020 dan tugas terjemahan sumber daya rendah', 'am': 'የኬልስኪን ዩንቨርስቲ እና አሌት ዩንቨርስቲ በWMT 2020 ዜና እና ዋናዊ resource ትርጉም ማድረግ ሰጥተዋል፡፡', 'sw': 'Chuo Kikuu cha Helsinki na Chuo Kikuu cha Aalto kinawasilisha habari za WMT 2020 na tafsiri za rasilimali chini', 'bn': 'বিশ্ববিদ্যালয়ের হেল্সিঙ্কি এবং আল্টো বিশ্ববিদ্যালয় উইএমটি ২০২০ সংবাদ এবং কম সম্পদ অনুবাদের কাজের প্রতি অনুপ', 'az': 'Helsinki və Aalto Universitetinin WMT 2020 xəbərlərinə və düşük ressurs çeviri işlərinə göndərilir.', 'tr': 'Helsinki we Aalto Uniwersiteti WMT 2020 täzeliklerine we iň az resurslar terjime etmek zadyna teslim edip otyr', 'bs': 'Predaje Univerzitet Helsinki i Aalto Univerziteta na vijesti WMT 2020 i zadatke za prevod niskih resursa', 'ca': 'The University of Helsinki and Aalto University submissions to the WMT 2020 news and low-resource translation tasks', 'cs': 'Helsinská univerzita a Aalto University příspěvky na WMT 2020 zprávy a úkoly s nízkými zdroji', 'et': 'Helsingi Ülikool ja Aalto Ülikool esitasid WMT 2020 uudiste ja vähese ressursiga tõlketeenuste ülesanded', 'sq': 'Universiteti i Helsinkit dhe Universiteti Aalto paraqesin lajmet e WMT 2020 dhe detyrat e përkthimit me burime të ulta', 'fi': 'Helsingin yliopisto ja Aalto-yliopisto ilmoittautuvat WMT 2020 -uutisiin ja vähävaraisiin käännöstoimiin', 'hy': 'Հելսինկի և Ալտո համալսարանի համալսարանը ներկայացնում է ԱՄԹ 2020-ի նորությունների և ցածր ռեսուրսների թարգմանման խնդիրները', 'jv': 'Universite ning helsini karo Aalto Universite entuk ingkang balita WT 2020 lan kelas perangkat kelas', 'he': 'האוניברסיטת הלסינקי ואוניברסיטת אלטו הוציאה את חדשות WMT 2020 ומשימות התרגום עם משאבים נמוכים', 'sk': 'Univerza v Helsinkih in Aalto University sta prispevala k novicam WMT 2020 in prevajalskim nalogam z nizkimi viri', 'ha': 'University of Hersinki da Aalto University Submits to the WMT 2020 news and lower-resource translation tasks', 'bo': 'Helsinki དང་ཨཱལ་ཐོའི་ཆེན་ཡོངས་ནང་གི་WMT 2020་བརྡ་ཞིག་དང་ཐོག་ཁུངས་ཆ་རྐྱེན་ཀྱི་ལས་འགུལ་བ་མང་པོ་ཡོད།'}
{'en': 'This paper describes the joint participation of University of Helsinki and Aalto University to two shared tasks of WMT 2020 : the news translation between Inuktitut and English and the low-resource translation between German and Upper Sorbian. For both tasks, our efforts concentrate on efficient use of monolingual and related bilingual corpora with scheduled multi-task learning as well as an optimized subword segmentation with sampling. Our submission obtained the highest score for Upper Sorbian-German and was ranked second for German-Upper Sorbian according to BLEU scores. For EnglishInuktitut, we reached ranks 8 and 10 out of 11 according to BLEU scores.', 'ar': 'تصف هذه الورقة المشاركة المشتركة لجامعة هلسنكي وجامعة آلتو في مهمتين مشتركتين في WMT 2020: ترجمة الأخبار بين Inuktitut والإنجليزية والترجمة منخفضة الموارد بين الألمانية والصربية العليا. لكلتا المهمتين ، تركز جهودنا على الاستخدام الفعال للمؤسسات أحادية اللغة وذات الصلة ثنائية اللغة مع التعلم المجدول متعدد المهام بالإضافة إلى تقسيم الكلمات الفرعية المحسّن مع أخذ العينات. حصل تقديمنا على أعلى الدرجات للصوربية العليا - الألمانية واحتلت المرتبة الثانية للألمانية - الصوربية العليا وفقًا لنتائج BLEU. بالنسبة للغة الإنجليزية- Inuktitut ، وصلنا إلى المراتب 8 و 10 من أصل 11 وفقًا لنتائج BLEU.', 'fr': "Cet article décrit la participation conjointe de l'Université d'Helsinki et de l'Université Aalto à deux tâches communes du WMT 2020\xa0: la traduction de nouvelles entre l'inuktitut et l'anglais et la traduction à faibles ressources entre l'allemand et le haut-sorabe. Pour les deux tâches, nos efforts se concentrent sur l'utilisation efficace des corpus unilingues et bilingues associés avec un apprentissage multitâche planifié ainsi qu'une segmentation optimisée des sous-mots avec échantillonnage. Notre soumission a obtenu le meilleur score pour le haut-sorabe - allemand et a été classée deuxième pour l'allemand - haut-sorabe selon les scores de l'UEBL. Pour l'anglais-inuktitut, nous avons atteint les rangs 8 et 10 sur 11 selon les scores de l'UEBL.", 'es': 'Este artículo describe la participación conjunta de la Universidad de Helsinki y la Universidad de Aalto en dos tareas compartidas del WMT 2020: la traducción de noticias entre el inuktitut y el inglés y la traducción de pocos recursos entre el alemán y el alto sorabo. Para ambas tareas, nuestros esfuerzos se centran en el uso eficiente de los corpus monolingües y bilingües relacionados con el aprendizaje multitarea programado, así como una segmentación optimizada de subpalabras con muestreo. Nuestra propuesta obtuvo la puntuación más alta para el alto sorabo - alemán y ocupó el segundo lugar para el alemán - alto sorabo según las puntuaciones BLEU. Para el inglés — Inuktitut, alcanzamos los rangos 8 y 10 de 11 según los puntajes de BLEU.', 'pt': 'Este artigo descreve a participação conjunta da Universidade de Helsinque e da Universidade de Aalto em duas tarefas compartilhadas do WMT 2020: a tradução de notícias entre o inuktitut e o inglês e a tradução de poucos recursos entre o alemão e o alto-sérvio. Para ambas as tarefas, nossos esforços se concentram no uso eficiente de corpora monolíngües e bilíngues relacionados com aprendizado multitarefa programado, bem como uma segmentação otimizada de subpalavras com amostragem. Nossa submissão obteve a pontuação mais alta para Alto Sorbio - Alemão e ficou em segundo lugar para Alemão - Alto Sorbio de acordo com as pontuações do BLEU. Para inglês-inuktitut, alcançamos as classificações 8 e 10 de 11 de acordo com as pontuações do BLEU.', 'ja': 'この論文では、WMT 2020の2つの共有されたタスクへのヘルシンキ大学とアールト大学の共同参加について説明します。すなわち、イヌクティトゥット語と英語のニュース翻訳と、ドイツ語と上部ソルブ語の低資源翻訳です。両方のタスクについて、私たちの努力は、スケジュールされたマルチタスク学習と、サンプリングによる最適化されたサブワードセグメンテーションを備えた単一言語および関連するバイリンガル組織の効率的な使用に集中しています。私たちの提案は、上部ソルブ語-ドイツ語の最高スコアを獲得し、BLEUスコアに従ってドイツ語-上部ソルブ語の2位にランク付けされました。英語-イヌクティトゥット語については、BLEUのスコアに従って、11のうち8位と10位に達しました。', 'zh': '本文述赫尔辛基大学与阿尔托大学同参WMT 2020二事:以纽特语、英语之间新闻翻译及德语、上索布语之低资源译。 凡此二者,吾事专于用单语与相关双语语料库,设多任务学及采样优化子词分之。 据BLEU分数,提交得上索布语 - 德语最高分,德语 - 上索布语第二。 其于英语 - 因纽特语,据BLEU分数,在11中排名第8第10位。', 'ru': 'В этой статье описывается совместное участие Хельсинкского университета и Университета Аалто в двух общих задачах WMT 2020: перевод новостей между инуктитутом и английским языком и перевод с небольшим объемом ресурсов между немецким и верхнесорбским языками. Для обеих задач наши усилия сосредоточены на эффективном использовании одноязычных и связанных с ними двуязычных корпусов с запланированным многозадачным обучением, а также оптимизированной сегментации подсловов с выборкой. Наша презентация получила наивысший балл для верхнесербского - немецкого и заняла второе место для верхнесербского по баллам BLEU. Для English–Inuktitut мы достигли 8 и 10 места из 11 по баллам BLEU.', 'hi': 'यह पेपर WMT 2020 के दो साझा कार्यों के लिए हेलसिंकी विश्वविद्यालय और आल्टो विश्वविद्यालय की संयुक्त भागीदारी का वर्णन करता है: Inuktitut और अंग्रेजी के बीच समाचार अनुवाद और जर्मन और ऊपरी सोर्बियन के बीच कम संसाधन अनुवाद। दोनों कार्यों के लिए, हमारे प्रयास अनुसूचित बहु-कार्य सीखने के साथ-साथ नमूनाकरण के साथ एक अनुकूलित उप-शब्द विभाजन के साथ मोनोलिंगुअल और संबंधित द्विभाषी कॉर्पोरेट के कुशल उपयोग पर ध्यान केंद्रित करते हैं। हमारे सबमिशन ने ऊपरी सोर्बियन के लिए उच्चतम स्कोर प्राप्त किया - जर्मन और BLEU स्कोर के अनुसार जर्मन - ऊपरी सोर्बियन के लिए दूसरा स्थान दिया गया था। अंग्रेजी-Inuktitut के लिए, हम BLEU स्कोर के अनुसार 11 में से 8 और 10 रैंक तक पहुंच गए।', 'ga': 'Déanann an páipéar seo cur síos ar chomh-rannpháirtíocht Ollscoil Heilsincí agus Ollscoil Aalto i dhá thasc chomhroinnte WMT 2020: an t-aistriúchán nuachta idir Ionúitis agus Béarla agus an t-aistriúchán íseal-acmhainne idir Gearmáinis agus Sorbais Uachtarach. Don dá thasc, dírítear ár n-iarrachtaí ar úsáid éifeachtach a bhaint as corpora aonteangacha agus dátheangacha gaolmhara le foghlaim il-thasc sceidealta chomh maith le deighilt barrfheabhsaithe fofhocail le sampláil. Fuair ár n-aighneacht an scór ab airde do Shorbais Uachtarach - Gearmáinis agus bhí sé sa dara háit do Ghearmáinis - Sorbais Uachtarach de réir scóir BLEU. Maidir le Béarla-Ionúitis, shroicheamar céimeanna 8 agus 10 as 11 de réir scóir BLEU.', 'ka': 'ამ დოკუნტის შესახებ ჰელსინკის და ალტო სუნივერსიის ერთმანეთი დაწყვეტილება WMT 2020-ის ორი გაყოფილი საქმედებისთვის: ინუკტიუტის და ინგლისურის შორის ახალი რესურსის გადაწყვეტილება და გერმანეთის და ზემო ს ორივე დავალებისთვის ჩვენი ძალები კონტენსტირებულია მონოლენგური და დაკავშირებული ორიენგური კოპორაზე გამოყენებაზე, რომელიც წარმოდგენა მრავალური დავალების სწავლებას, და სუპტიმიზებ ჩვენი მომხმარება მიიღეთ უფრო დიდი სოპერბული - გერმანეთი და გერმანეთისთვის მეორე - ზედან სოპერბული, BLEU წერტილებისთვის. ანგლისური-ინუკტიტუტისთვის, ჩვენ 11-დან 8 და 10 წერტილებს მივიღეთ BLEU წერტილებისთვის.', 'hu': 'Ez a tanulmány bemutatja a Helsinki Egyetem és az Aalto Egyetem közös részvételét a WMT 2020 két közös feladatában: az Inuktitut és az angol hírfordítás, valamint a német és Felső-Szorbia közötti alacsony forrású fordítás. Mindkét feladat esetében erőfeszítéseink az egynyelvű és kapcsolódó kétnyelvű korpuszok hatékony használatára összpontosítanak ütemezett többfeladatos tanulással, valamint a mintavétellel történő optimalizált alszószegmentációra összpontosítanak. Jelentkezésünk a legmagasabb pontszámot kapta Felső-Szorbia-Német kategóriában, és a második helyen állt a Német-Felső-Szorbia kategóriában BLEU pontszámok alapján. Az English-Inuktitut esetében a BLEU pontszáma szerint a 11-ből 8. és 10. helyet értünk el.', 'it': "Questo articolo descrive la partecipazione congiunta dell'Università di Helsinki e dell'Università Aalto a due compiti condivisi di WMT 2020: la traduzione di notizie tra Inuktitut e l'inglese e la traduzione a basso contenuto di risorse tra tedesco e Alto Sorbiano. Per entrambi i compiti, i nostri sforzi si concentrano sull'uso efficiente dei corpora bilingui monolingue e correlati con apprendimento multi-task programmato e una segmentazione ottimizzata delle sottoparole con campionamento. La nostra presentazione ha ottenuto il punteggio più alto per Alta Sorbia - Tedesco ed è stata classificata seconda per Tedesco - Alta Sorbia secondo i punteggi BLEU. Per English-Inuktitut, abbiamo raggiunto i ranghi 8 e 10 su 11 secondo i punteggi BLEU.", 'mk': 'Овој весник го опишува заедничкото учество на Универзитетот Хелсинки и Универзитетот Алто на две заеднички задачи на ВМТ 2020: преводот на вестите помеѓу Инуктитут и англискиот и преводот со ниски ресурси помеѓу германската и горната Сорбијанка. За двете задачи, нашите напори се концентрираат на ефикасна употреба на монојазични и поврзани двојјазични корпора со закажано мултизадачно учење, како и оптимизирана сегментација на подзборови со примерок. Our submission obtained the highest score for Upper Sorbian - German and was ranked second for German - Upper Sorbian according to BLEU scores.  За англиско-инуктитут, достигнавме рангови 8 и 10 од 11 според оценките на БЛЕУ.', 'el': 'Η παρούσα εργασία περιγράφει την κοινή συμμετοχή του Πανεπιστημίου του Ελσίνκι και του Πανεπιστημίου Aalto σε δύο κοινά καθήκοντα του WMT 2020: τη μετάφραση ειδήσεων μεταξύ Inuktitut και Αγγλικών και τη μετάφραση χαμηλών πόρων μεταξύ γερμανικών και ανώτερων σορβικών. Και για τις δύο εργασίες, οι προσπάθειές μας επικεντρώνονται στην αποτελεσματική χρήση μονογλωσσικών και συναφών δίγλωσσων σωμάτων με προγραμματισμένη εκμάθηση πολλαπλών εργασιών καθώς και στη βελτιστοποιημένη τμηματοποίηση υπολέξεων με δειγματοληψία. Η υποβολή μας απέκτησε την υψηλότερη βαθμολογία για Ανώτερα Σορβικά στα Γερμανικά και κατατάχθηκε δεύτερη για Γερμανικά στα Ανώτερα Σορβικά σύμφωνα με τις βαθμολογίες του BLEU. Για το Αγγλικό-Ινουκτίτ, φτάσαμε στις τάξεις 8 και 10 στις 11 σύμφωνα με τις βαθμολογίες του BLEU.', 'ms': 'Kertas ini menggambarkan ketertarikan bersama Universiti Helsinki dan Universiti Aalto kepada dua tugas berkongsi WMT 2020: terjemahan berita antara Inuktitut dan Inggeris dan terjemahan sumber rendah antara Jerman dan Upper Sorbian. Untuk kedua-dua tugas, usaha kita berkonsentrasi pada penggunaan efisien dari corpora bilingual monobahasa dan berkaitan dengan pembelajaran multi-tugas dijadualkan serta segmen subkata yang optimal dengan pengumpulan sampel. Our submission obtained the highest score for Upper Sorbian - German and was ranked second for German - Upper Sorbian according to BLEU scores.  Untuk Inggeris-Inuktitut, kami mencapai peringkat 8 dan 10 daripada 11 mengikut skor BLEU.', 'ml': 'ഈ പത്രത്തില്\u200d ഹെല്\u200dസിങ്കിയുടെയും ആല്\u200dട്ടോ യൂണിവേഴ്സിറ്റിയുടെയും പങ്കെടുപ്പ് വിവരിക്കുന്നു. WMT 2020-ലേക്ക് രണ്ടു പങ്കാളികളായ ജോലികളിലേക്ക്:  രണ്ടു ജോലികള്\u200dക്കും നമ്മുടെ ശ്രമം മോണോളില്\u200dഭാഷിക്കും ബന്ധപ്പെട്ട രണ്ടു ഭാഷ കോര്\u200dപ്പോര്\u200dണയുടെയും പ്രധാനപ്പെട്ട ഉപയോഗിക്കുന്നതിനെക്കുറിച ഞങ്ങളുടെ സമ്മാനം മുകളില്\u200d സോര്\u200dബിയന്\u200d - ജര്\u200dമ്മനിലെ ഏറ്റവും ഉയര്\u200dന്ന സ്കോര്\u200d കിട്ടിയിരുന്നു. ജര്\u200dമ്മനിലേക്ക് രണ്ടാമത്തെ റാഞ് For English-Inuktitut, we reached ranks 8 and 10 out of 11 according to BLEU scores.', 'lt': 'Šiame dokumente aprašomas bendras Helsinkio ir Aalto universiteto dalyvavimas dviejose bendrose WMT 2020 užduotyse: Inuktituto ir anglų žinių vertimas ir mažai išteklių vertimas vokiečių ir aukštojo sorbų kalbomis. Abiejų užduočių atžvilgiu mūsų pastangos sutelkiamos į efektyvų vienokalbių ir susijusių dvikalbių kūnų naudojimą, atliekant planuojamą daugiakalbį mokymąsi, taip pat optimizuotą subžodžių segmentaciją, atliekant mėginių ėmimą. Mūsų pareiškimas pasiekė aukščiausią aukščiausiosios sorbios – vokiečių – rezultatus ir buvo antras vokiečių – aukščiausiosios sorbios – rezultatus pagal BLEU rezultatus. For English-Inuktitut, we reached ranks 8 and 10 out of 11 according to BLEU scores.', 'kk': 'Бұл қағаз Хельсинки және Алто университетінің WMT 2020-нің екі ортақ тапсырмаларына қатынастығын түсіндіреді: инуктитут мен ағылшын тілінің жаңалық аудармасы мен неміс және жоғары сорб тілінің ортасындағы төмен ресурста Екі тапсырма үшін біздің көп тапсырмаларды оқыту үшін монолингі және қатынастырылған екі тілді корпорасының ефективті пайдалануына көмектеседі, мәліметті оқыту үшін оптимизацияланған суб Біздің сәйкестігіміз жоғары сорбияның - неміс тілінде ең жоғары нәтижесін алды және неміс тілінде екінші нәтижесі болды - жоғары сорбияның BLEU нәтижесіне сә Ағылшын-инуктитут үшін БЛЕС нәтижелеріне сәйкес 8 мен 10 деңгейіне жеттік.', 'no': 'Denne papiret beskriver felles deltaka av Universiteten Helsinki og Aalto til to delte oppgåver i WMT 2020: omsetjinga mellom Inuktitut og engelsk og omsetjinga mellom tysk og opphavsorbisk. For begge oppgåver, våre forsøk koncentrerer seg på effektivt bruk av monospråk og relaterte bilinguelkorpora med planlagt multioppgåver- læring, og ein optimalisert underordsegmentering med prøve. Vårt søknad har fått den høgste poeng for toppesorbiansk – tysk – og var rankert sekund for tysk – toppesorbiansk etter BLEU-poeng. For engelsk-Inuktitut har vi nådd rank 8 og 10 av 11 etter BLEU-scorer.', 'mt': 'Dan id-dokument jiddeskrivi l-parteċipazzjoni konġunta tal-Università ta’ Ħelsinki u l-Università ta’ Aalto f’żewġ kompiti kondiviżi tad-WMT 2020: it-traduzzjoni tal-aħbarijiet bejn l-Inuktitut u l-Ingliż u t-traduzzjoni b’riżorsi baxxi bejn il-Ġermaniż u l-Għoli tas-Sorbja. Għaż-żewġ kompiti, l-isforzi tagħna jikkonċentraw fuq l-użu effiċjenti ta’ korpra bilingwi monolingwi u relatata mat-tagħlim skedat b’ħafna kompiti kif ukoll segmentazzjoni ottimizzata tas-sottokliem bit-teħid ta’ kampjuni. Is-sottomissjoni tagħna kisbet l-ogħla punteġġ għal Upper Sorbian - Ġermaniż u kienet ikklassifikata t-tieni għal Ġermaniż - Upper Sorbian skont il-punteġġi BLEU. Għall-Ingliż-Inuktitut, laħaqna l-gradi 8 u 10 minn 11 skont il-punteġġi BLEU.', 'mn': 'Энэ цаас Хельсинки болон Алто Их Сургуулийн хоёр WMT 2020-ийн хуваалцаагүй ажил дээр хамтран оролцохыг тайлбарладаг: Инуктит болон Англи хэл болон Герман болон Үүний Сорб хоорондын бага нөөцийн хөрөнгө оруулалтын мэдээний хөрөн Хоёр даалгаварын тулд бидний хичээл нь нэг хэл болон хоёр хэл хоёр даалгавартай корпора ашиглахын тулд үр дүнтэй байдаг. Бидний хүлээн зөвшөөрсөн нь дээд сорбян - Германы хамгийн өндөр оноо авсан бөгөөд Германы хувьд хоёр дахь оноо авсан бөгөөд БЛЕС тооны хувьд дээд сорбян хүмүүсийн хувьд 2 дах Англи-инуктитутын хувьд бид БЛЕУ-ын тооны хувьд 11-аас 8, 10-г хүртсэн.', 'ro': 'Această lucrare descrie participarea comună a Universității din Helsinki și a Universității Aalto la două sarcini comune ale WMT 2020: traducerea știrilor între Inuktitut și engleză și traducerea cu resurse reduse între germană și Sorbiană Superioară. Pentru ambele sarcini, eforturile noastre se concentrează pe utilizarea eficientă a corporelor bilingve monolingve și conexe cu învățare programată multi-task, precum și pe segmentarea optimizată a subcuvintelor cu eșantionare. Participarea noastră a obținut cel mai mare scor pentru Sorbia Superioară - Germană și a fost clasată pe locul doi pentru Sorbia Superioară conform scorurilor BLEU. Pentru English-Inuktitut, am ajuns pe locurile 8 și 10 din 11 conform scorurilor BLEU.', 'sr': 'Ovaj papir opisuje zajedničko sudjelovanje Univerziteta Helsinki i Aalto na dve zajedničke zadatke WMT 2020: prevod vesti između Inuktituta i engleskog i prevoda niskog resursa između njemačkog i gornjeg sorbijskog. Za obe zadatke, naši napori se koncentriraju na efikasnu upotrebu jednojezičkog i povezanog dvojezičkog korpora sa raspoređenim multizadatkom učenjem, kao i optimiziranom segmentacijom podriječja sa uzorakom. Naša predstava je dobila najveći rezultat za Gornji Sorbijanski - Njemački i bio je drugi za njemački - Gornji Sorbijanski prema rezultatima BLEU-a. Za engleski Inuktitut, postigli smo redove 8 i 10 od 11 prema BLEU rezultatima.', 'pl': 'Niniejszy artykuł opisuje wspólny udział Uniwersytetu Helsińskiego i Uniwersytetu Aalto w dwóch wspólnych zadaniach WMT 2020: tłumaczeniu wiadomości pomiędzy Inuktitut a angielskim oraz tłumaczeniu niskich zasobów między językiem niemieckim i górnym. Dla obu zadań nasze wysiłki koncentrują się na efektywnym wykorzystaniu jednojęzycznych i powiązanych dwujęzycznych korpusów z zaplanowanym wielozadaniowym uczeniem się, a także zoptymalizowanej segmentacji podsłów z próbkowaniem. Nasze zgłoszenie uzyskało najwyższy wynik dla Górnego Sorbiańskiego – Niemieckiego i drugie miejsce dla Niemieckiego – Górnego Sorbiańskiego według wyników BLEU. Dla English-Inuktitut osiągnęliśmy rangę 8 i 10 na 11 według wyników BLEU.', 'si': 'මේ පැත්තේ හෙල්සින්කි හා ආල්ටෝ විද්\u200dයාපිත්තියේ සම්බන්ධ විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයා වැඩක් දෙන්නම්, අපේ උත්සාහ කරනවා එක භාෂාවක් සහ සම්බන්ධ දෙන්නම් භාෂාවක් ප්\u200dරයෝජනය සඳහා වැඩි වැඩි වැඩක් ඉගෙනීම සහ හොඳ වැ අපේ පිළිගන්නේ උපර සෝර්බියාන් වලට උපරිම ප්\u200dරමාණය ලැබුනා - ජර්මන් වලින් තරම් ප්\u200dරමාණය සහ ජර්මන් වලින් ප්\u200dරමාණය ස ඉංග්\u200dරීසිය-ඉනුක්ටිටුට්ටුට් වෙනුවෙන්, අපි ඉංග්\u200dරීසියෙන් ඉංක්ටිටුට්ටුට් එක්කෙන් අඩු', 'sv': 'Denna uppsats beskriver Helsingfors universitets och Aalto-universitetets gemensamma deltagande i två gemensamma uppgifter för WMT 2020: nyhetsöversättningen mellan Inuktitut och engelska och den resurssnåla översättningen mellan tyska och Övre Sorbiana. För båda uppgifterna fokuserar vi på effektiv användning av enspråkiga och relaterade tvåspråkiga korpor med schemalagd flerfunktionsinlärning samt optimerad underordssegmentering med sampling. Vårt bidrag fick högsta poäng för Övre Sorbian - Tyska och rankades tvåa för Tyska - Övre Sorbian enligt BLEU poäng. För English-Inuktitut nådde vi ranking 8 och 10 av 11 enligt BLEU poäng.', 'so': 'Warqadan waxaa ku qoran wadajirka ka qeybqaadashada jaamacadda Helsinki iyo Aalto jaamacadda oo u dhexeeya laba shaqooyin oo kala qaybsan WMT 2020: tarjumaadka u dhexeeya Inuktitut iyo Ingiriis iyo tarjumaadka hoose-resource ee u dhexeeya Jarmal iyo Sorbian ka sarreeya. Shaqooyinkayada labadoodaba waxay ku kalsoonaan jireen isticmaalka afafka afka ah iyo shirkadaha labada luuqadood ee la xiriira, taasoo lagu qorsheeyey waxbarasho badan iyo qeybta hoose ee sameynta. Madaxalkayagii wuxuu helay qiimaha ugu sarreeya Sorbiya-Jarmalka sare, waxaana lagu soo bandhigay labaad Jarmalka- Sorbiya Kore si waafaqsan scoraha BLEU. Ingiriiska-Inuktitut waxaynu ka nimid fasalka 8 iyo 10 si waafaqsan scorada BLEU.', 'ta': 'இந்த காகிதத்தில் ஹெல்சின்சினி மற்றும் ஆல்டோ கல்வியூரிக்கத்தின் இணைய பகிர்ந்து WMT 2020-ன் இரண்டு பகிர்ந்த பணிகளை விவரிக்கிறது: ஜெர்மன் மற்றும் மேல் ச இரண்டு பணிகளுக்கும், எங்கள் முயற்சிகள் ஒலிமொழி மற்றும் தொடர்புடைய இரு மொழி நிறுவனத்தின் பயன்பாட்டின் மீது கவனம் செலுத்துகிறது, பல பணி கற்றல் மற்றும் மா மேல் சோர்பியன் - ஜெர்மன் மற்றும் ஜெர்மன் மற்றும் பிலியு மதிப்புகளை பொறுத்து மேல் சோர்பியன் வரை இரண்டாவது வரிசைப்பட்டது. ஆங்கிலம்- இனுக்கிட்டிக்கு, நாங்கள் பிலியு மதிப்புகள் பொருத்தி 11 ல் 8 மற்றும் 10 வரிசையில் அடைந்தோம்.', 'ur': 'یہ کاغذ ہلسینکی اور آلٹو یونیوریسٹیو کی یونیوریسٹی کے ساتھ دو مشترکین کام کی تعریف کرتا ہے: انوکیٹ اور انگلیسی کے درمیان خبریں ترجمہ اور جرمانی اور اوپر سوربیان کے درمیان کم منبع ترجمہ. دونوں کاموں کے لئے ہماری کوشش ایک زبان اور دو زبان شرکت کے مطابق استعمال کے ذریعہ مطابق کرتی ہے اور ایک نمونہ کے ساتھ مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق کرتی ہے. ہمارے مسلمانوں نے اوپر سوربیان کے لئے سب سے زیادہ امتیاز حاصل کی اور جرمن کے لئے دوسری امتیاز حاصل کی گئی - بل یوس کے امتیاز کے مطابق اوپر سوربیان کے لئے دوسری امتیاز حاصل کی گئی۔ انگلیسی انوکیٹ کے لئے ہم ۱۱ سے ۸ اور ۱۰ درجے پہنچ گئے۔', 'uz': "Bu karatasi Helsinki Universitetdagi birlashtirish va Aalto University WMT 2020 yili ikkita bir nechta ishlarga aytish mumkin: Ingliz va Olmon va Yuqori Sorbchaga bir xil tarjima tarjima tarjima qiladi. Bu ikkita vazifalar uchun biz jarayonlarimiz muloqat vazifani o'rganish va samol bilan ko'paytirilgan tub soʻzning qismlarini tasavvur qiladi. Bizning imkoniyatlarimiz yuqori Sorbiy- Olmoncha eng yuqori darajaga ega bo'ldi va Buyuqori Sorbiy qiymatda Buyuqori BLEU qiymatlari bilan birinchi darajaga o'xshash bo'lgan. Ingliz-Inuktitut uchun biz BLEU scorlari davomida 11 dan 8 va 10 darajaga yetdik.", 'vi': 'Tờ giấy này mô tả sự tham gia chung của Đại học Helsinki và Học viện Aalto với hai nhiệm vụ chia sẻ của WRT 2020: Bản dịch tin giữa Inuktit và Anh và bản dịch ít tài nguyên giữa Đức và Upper Sorbian. Đối với cả hai nhiệm vụ, nỗ lực của chúng ta tập trung vào việc sử dụng triệt để chức năng hai ngôn ngữ và liên quan với việc học đa các công việc theo kế hoạch, cùng với việc phân biệt các chữ hoa tiêu tối đa với mẫu. Bài đệ trình của chúng tôi đạt được điểm cao nhất của Upper Sorbian- German and was được xếp hạng nhì for German(Upper Sorbian under bleU strikes. Với tiếng Anh-nhập nghĩa, chúng tôi đã đạt được cấp độ 8 và 10 trên 11 theo tỉ số của đại liên lạc.', 'bg': 'Настоящата статия описва съвместното участие на Университета в Хелзинки и Университета в Алто в две общи задачи на ММТ 2020: превода на новини между Инуктитут и английски език и превода с нисък ресурс между немски и горносорбийски език. За двете задачи усилията ни се концентрират върху ефективното използване на едноезични и свързани двуезични корпуси с планирано многозадачично обучение, както и оптимизирана сегментация на поддуми с извадка. Нашето предложение получи най-висока оценка за Горно-сорбийски - немски и се класира на второ място за Германо-горно сорбийски според оценките на БЮ. За английско-инуктитута достигнахме 8-ми и 10-ми ранг от 11 според оценките на БЮ.', 'nl': "Deze paper beschrijft de gezamenlijke deelname van de Universiteit van Helsinki en de Aalto Universiteit aan twee gedeelde taken van WMT 2020: de nieuwsovertelling tussen Inuktitut en Engels en de low-resource vertaling tussen Duits en Opper-Sorbisch. Voor beide taken concentreren onze inspanningen zich op efficiënt gebruik van eentalige en verwante tweetalige corpora's met gepland meertalig leren en een geoptimaliseerde subwoordsegmentatie met sampling. Onze inzending behaalde de hoogste score voor Oppersorbisch-Duits en werd tweede voor Duits-Oppersorbisch volgens BLEU-scores. Voor Engels-Inuktitut bereikten we ranglijsten 8 en 10 van 11 volgens BLEU scores.", 'da': 'Denne artikel beskriver Helsinki Universitets og Aalto Universitets fælles deltagelse i to fælles opgaver i WMT 2020: nyhedsoversættelsen mellem Inuktitut og engelsk og oversættelsen med lav ressource mellem tysk og øversorbisk. For begge opgaver fokuserer vores indsats på effektiv brug af ensprogede og relaterede tosprogede korpora med planlagt multi-task læring samt en optimeret underordssegmentering med sampling. Vores indsendelse opnåede den højeste score for Øvre Sorbian - Tysk og blev rangeret andenplads for Tysk - Øvre Sorbian i henhold til BLEU scorer. For English-Inuktitut nåede vi rang 8 og 10 ud af 11 ifølge BLEU score.', 'hr': 'Ovaj papir opisuje zajedničko sudjelovanje Univerziteta Helsinki i Aalto na dvije zajedničke zadatke WMT 2020: prevod vijesti između Inuktituta i engleskog i prevod niskog resursa između njemačkog i gornjeg sorbijskog. Za oba zadatka, naši napori se koncentriraju na učinkovitu uporabu monojezičkog i povezanih dvojezičkog korpora s raspoređenim multizadatkom učenjem, kao i optimiziranom podriječjom segmentacijom s uzorakom. Naša predstava je dobila najveći rezultat za Gornji Sorbijanski - Njemački i bio je drugi za njemački - Gornji Sorbijanski prema rezultatima BLEU-a. Za engleski Inuktitut postigli smo redove 8 i 10 od 11 prema BLEU rezultatima.', 'de': 'Dieser Beitrag beschreibt die gemeinsame Beteiligung von Universität Helsinki und Aalto University an zwei gemeinsamen Aufgaben von WMT 2020: der Nachrichtenübersetzung zwischen Inuktitut und Englisch und der ressourcenarmen Übersetzung zwischen Deutsch und Obersorbisch. Für beide Aufgaben konzentrieren sich unsere Bemühungen auf die effiziente Nutzung von einsprachigen und verwandten zweisprachigen Korpora mit planmäßigem Mehraufgabenlernen sowie einer optimierten Unterwortsegmentierung mit Sampling. Unsere Einreichung erzielte die höchste Punktzahl für Obersorbisch-Deutsch und wurde für Deutsch-Obersorbisch nach BLEU-Werten Zweiter für Deutsch-Obersorbisch. Für English-Inuktitut erreichten wir die Plätze 8 und 10 von 11 nach BLEU-Werten.', 'fa': 'این کاغذ مشترک مشترک دانشگاه هلسینکی و دانشگاه آلتو را به دو کار مشترک WMT 2020 توصیف می\u200cکند: ترجمه خبری بین اینوکیت و انگلیسی و ترجمه منابع کم بین آلمان و سوربیان بالا. برای هر دو وظیفه، تلاش ما روی استفاده موثرتی از شرکت یک زبان و مربوط به دو زبان با یادگیری بسیاری از وظیفه\u200cهای برنامه\u200cریزی و بخش\u200cهای زیر کلمه\u200cهای optimized با نمونه\u200cبندی تمرکز می\u200cکنند. تحويل ما بالاترين امتياز براي سوربيان بالا گرفته شده و دومين امتياز براي آلماني بود به عنوان انگلیسی-انوکیت، ما به عنوان امتیاز بلوئیس ۸ و ۱۰ درجه رسیدیم.', 'id': 'Kertas ini menjelaskan parteċipasi bersama Universitas Helsinki dan Universitas Aalto pada dua tugas bersama WMT 2020: terjemahan berita antara Inuktitut dan Inggris dan terjemahan sumber daya rendah antara Jerman dan Upper Sorbian. Untuk kedua tugas, usaha kita berkonsentrasi pada penggunaan efisien dari corpora bilingual monobahasa dan terkait dengan pelajaran multi-tugas yang dijadwalkan serta segmen subword yang optimisasi dengan sampel. Pemberian kami mendapat skor tertinggi untuk Upper Sorbian - Jerman dan dipilih kedua untuk Jerman - Upper Sorbian menurut skor BLEU. For English-Inuktitut, we reached ranks 8 and 10 out of 11 according to BLEU scores.', 'ko': '본고는 헬싱키대학과 알토대학이 WMT 2020에 공동으로 참여하는 두 가지 공동 임무인 뉴트어와 영어 간의 뉴스 번역, 독일어와 상소포어 간의 저자원 번역을 묘사한다.이 두 가지 임무에 대해 우리는 단어와 관련된 이중 언어 자료 라이브러리를 효율적으로 사용하고 계획된 다중 임무 학습을 실시하며 샘플링을 통해 자어를 최적화하는 데 주력한다.BLEU 점수에 따르면 우리가 제출한 자료는 상삭부어-독일어 중 가장 높은 점수를 받았고, 독일어-상삭부어 중 2위를 차지했다.BLEU 점수에 따르면 영어는 뉴트교가 11명의 학생 중 8위와 10위에 올랐다.', 'sw': 'Gazeti hili linaelezea ushiriki wa pamoja wa Chuo Kikuu cha Helsinki na Aalto katika kazi mbili zilizoshirikiana na WMT 2020: tafsiri ya habari kati ya Kiuktitut na Kiingereza na tafsiri ya rasilimali chini kati ya Ujerumani na KiSorbia Kuu. Kwa kazi zote mbili, juhudi zetu zinajikita kwenye matumizi ya ufanisi ya kampuni ya lugha za kiutaifa na inayohusiana na lugha mbili zilizopangwa na kujifunza kwa kazi nyingi pamoja na kutenganishwa kwa maneno ya chini kwa sampuli. Ujumbe wetu ulipata kipaumbele cha juu kwa Ki-Sorbia Kuu - Kijerumani na ulikuwa ni wa pili kwa ajili ya Ujerumani - KiSorbia Kuu kwa mujibu wa score za BLEU. Kwa Kiingereza-Inuktitut, tulifika daraja 8 na 10 kati ya 11 kwa mujibu wa vipindi vya BLEU.', 'tr': 'Bu kagyz Helsinki we Aalto Uniwersitetiniň WMT 2020-nji ýylyň iki işi bilen bölünýän işi ýazylýar: Iňlisçe we Iňlisçe bagly terjime edil nemesçe we üst-sorbiýanyň arasyndaky azajyk çevirisi. Iki zadymyz üçin, biziň çabalarymyz monodil we bilim dilli korporatyň täsirli ulanylygyny daýynlandyrylýan bir multi-täbli öwrenmek bilen we örnek bilen optimizləndirilen sübde segmentasiýasyna üns berilýär. Biziň gönüşümiz üst-sorbisce üçin iň üst depler gazandy - Almança üçin ikinji depler boldy - üst-sorbisce BLEU noktalaryna görä. Iňlisçe-Inuktitutyň üçin BLEU sanlaryna görä 8 we 10 derejesine ýetdik.', 'af': "Hierdie papier beskrywe die saamste deelnadering van Universiteit van Helsinki en Aalto Universiteit tot twee deelde taak van WMT 2020: die nuusvertaling tussen Inuktitut en Engels en die lae-hulpbron vertaling tussen Duits en Boppesorbiese. Vir beide opdragte, ons versoekte konsentreer op effektief gebruik van monolinglike en verwante twee tale korpora met geskeduleerde multi-opdrag leer en ook 'n optimaliseerde subwoord segmentasie met versameling. Ons ondersoek het die hoogste telling vir Boonste Sorbiese - Duits en is tweede rangeerd vir Duits - Boonste Sorbiese volgens BLEU-punte. Vir Engels-Inuktitut het ons ranke 8 en 10 van 11 bereik volgens BLEU-rekening.", 'am': 'ይህ ገጽ የኬልስኪን ዩንቨርስቲ እና አሌት ዩንቨርስቲ የዩንቨርስቲ ተካባቢ እና በጀርመን እና በላይ ሶርቢያ መካከል የዜና ትርጓሜ እና በጀርመን እና በዩንቨርስቲ መካከል ታናሽነት ትርጓሜ ይናገራል፡፡ ለሁለቱ ስራ፣ ሥራችን በሙሉ ቋንቋ እና በተለየ የሁለት ቋንቋ ኮርፖርት በማጠቃቀሚያ እና በተመሳሳይ የተለየ ደብዳቤ ትምህርት እና በተለየ ደብዳቤ ትምህርት ማቀናቀል እና በተለየ ምሳሌ በተለየ ጥያቄ እየተለየ ነው፡፡ አዋጅ ለላይኛይቱ ሶርባዊ - ጀርመን እና የጀርመን ሁለተኛይቱን የሻለይ ሶርባዊ ትርጉም እንደBLEU score አግኝቷል፡፡ እንግሊዝኛ-ኢንቱቅቲ፣ BLEU የደረጃ ቁጥር 8 እና 10 ደረጃዎች ደረስን፡፡', 'sq': 'Ky dokument përshkruan pjesëmarrjen e përbashkët të Universitetit të Helsinkit dhe Universitetit të Aaltos në dy detyra të përbashkëta të WMT 2020: përkthimin e lajmeve midis Inuktitut dhe anglisht dhe përkthimin me burime të ulëta midis gjermanisë dhe sorbikes së lartë. Për të dy detyrat, përpjekjet tona përqëndrohen në përdorimin e efektshëm të korprave monogjuhësore dhe të lidhura dygjuhësore me mësimin e planifikuar me shumë detyra si dhe në një segmentim optimizuar të nënfjalëve me kampionat. Subjekti ynë mori rezultatin më të lartë për Upper Sorbian - Gjerman dhe u rendit i dyti për Gjermanin - Upper Sorbian sipas rezultateve të BLEU. Për anglisht-inuktitut, arritëm rendin 8 dhe 10 nga 11 sipas rezultateve të BLEU.', 'hy': 'This paper describes the joint participation of University of Helsinki and Aalto University to two shared tasks of WMT 2020: the news translation between Inuktitut and English and the low-resource translation between German and Upper Sorbian.  For both tasks, our efforts concentrate on efficient use of monolingual and related bilingual corpora with scheduled multi-task learning as well as an optimized subword segmentation with sampling.  Մեր ներկայացումը ստացավ ամենաբարձր գնահատականը գերմանացի և երկրորդ գնահատականը գերմանացի և ամենաբարձր սորբացի համար, ըստ ԲԼԵՎ գնահատականների: For English-Inuktitut, we reached ranks 8 and 10 out of 11 according to BLEU scores.', 'bn': 'এই পত্রিকা হেল্সিঙ্কি বিশ্ববিদ্যালয়ের যৌথ অংশগ্রহণ এবং আল্টো বিশ্ববিদ্যালয়ের অংশগ্রহণের বিষয়টি উইএমটি ২০২০ এর দুটি শেয়ার কর্মসূচীর দিকে বর্ণনা কর দুটো কাজের জন্য আমাদের প্রচেষ্টা মোনোলিভাষী এবং সম্পর্কিত দুই ভাষার ব্যবহারের উপর কার্যকর ব্যবহারের উপর মনোযোগ দিয়ে মনোযোগ দিয়েছে যারা নির্ধারিত বহ আমাদের প্রতিষ্ঠান বিলিউ স্কোর অনুসারে উপরের সোর্বিয়ান-জার্মানের জন্য সর্বোচ্চ স্কোর পেয়েছে এবং জার্মানের জন্য দ্বি For English-Inuktitut, we reached ranks 8 and 10 out of 11 according to BLEU scores.', 'az': 'Bu kağıt Helsinki Universitetinin və Aalto Universitetinin birlikdə birlikdə WMT 2020-nin iki paylaşılmış işlərini təsdiqləyir: Inuktitut və İngilizə ilə Alman və Üst Sorbi arasındakı düşük kaynaqlar tercüməsi arasında xəbərlər tercüməsini təsdiqləyir. İki iş üçün, bizim çabalarımız monodil və bilik dil korporasının müəyyən edilmiş çoxlu işlər öyrənməsi ilə və nümunələrlə optimizləndirilmiş alt sözlər segmentasiyası ilə müvəffəqiyyətli istifadə etməyə başladı. Bizim təbliğ etdiyimiz ən yüksək sərvalı - Almanlıq və Almanlıq üçün ikinci dərəcə verilmiş - Uçur Sorbiski BLEU qiymətlərinə görə. İngilizce-Inuktitut üçün, BLEU nöqtələrinə görə 8 və 10 dərəcələrə ulaşdıq.', 'et': 'Käesolevas dokumendis kirjeldatakse Helsingi Ülikooli ja Aalto Ülikooli ühist osalemist WMT 2020 kahes ühises ülesandes: uudiste tõlkimine Inuktitut ja inglise keele vahel ning madala ressursiga tõlkimine saksa ja Ülem-Sorbia keele vahel. Mõlema ülesande puhul keskendume meie jõupingutused ühekeelsete ja nendega seotud kakskeelsete korpuste tõhusale kasutamisele koos planeeritud mitme ülesandega ning optimeeritud alamsõna segmenteerimisele koos proovivõtuga. Meie esitus sai kõige suurema skoori Ülem-Sorbia - Saksa ja oli BLEU skoori järgi teisel kohal Saksa - Ülem-Sorbia. Inglise-inuktitu puhul jõudsime BLEU skoori järgi 8. ja 10. astmele 11-st.', 'bs': 'Ovaj papir opisuje zajedničko sudjelovanje Univerziteta Helsinki i Aalto na dvije zajedničke zadatke WMT 2020: prevod vijesti između Inuktituta i engleskog i prevod niskog resursa između njemačkog i gornjesorbijskog. Za obe zadatke, naši napori se koncentriraju na efikasnu upotrebu jednojezičkog i povezanog dvojezičkog korpora sa raspoređenim multizadatkom učenjem, kao i optimiziranom segmentacijom podriječja sa uzorakom. Naša predstava je dobila najveći rezultat za Gornji Sorbijanski - Njemački i bio je drugi za njemački - Gornji Sorbijanski, prema rezultatima BLEU-a. Za engleski Inuktitut, postigli smo redove 8 i 10 od 11 prema BLEU rezultatima.', 'cs': 'Tento článek popisuje společnou účast Helsinské univerzity a Aalto University na dvou společných úkolech WMT 2020: překlad zpráv mezi Inuktitutem a angličtinou a překlad nízkých zdrojů mezi němčinou a horním sorbštinou. U obou úkolů se naše úsilí soustředí na efektivní využití jednojjazyčných a souvisejících dvojjazyčných korpusů s plánovaným víceúkolovým učením a optimalizovanou segmentací podslov se vzorkováním. Náš příspěvek získal nejvyšší skóre pro hornosorbštinu v němčině a byl druhý v němčině a hornosorbštině podle skóre BLEU. Pro anglicky-Inuktitut jsme dosáhli pořadí 8 a 10 z jedenácti podle skóre BLEU.', 'fi': 'Tässä artikkelissa kuvataan Helsingin yliopiston ja Aalto-yliopiston yhteistä osallistumista WMT 2020:n kahteen yhteiseen tehtävään: uutiskäännökseen Inuktitutin ja englannin välillä sekä vähäresurssiseen käännökseen saksan ja yläsorbian välillä. Molemmissa tehtävissä keskitymme yksikielisten ja niihin liittyvien kaksikielisten korpusten tehokkaaseen käyttöön ajoitetulla monitehtäväoppimisella sekä optimoituun alasanasegmentointiin näytteenoton avulla. Toimituksemme sai korkeimmat pisteet ylemmän sorbian - saksa ja sijoittui toiseksi saksan - yläsorbian BLEU-pisteiden mukaan. English-Inuktitutilla saavutimme BLEU-pisteiden mukaan 8. ja 10. sijalla 11.', 'ca': "This paper describes the joint participation of University of Helsinki and Aalto University to two shared tasks of WMT 2020: the news translation between Inuktitut and English and the low-resource translation between German and Upper Sorbian.  For both tasks, our efforts concentrate on efficient use of monolingual and related bilingual corpora with scheduled multi-task learning as well as an optimized subword segmentation with sampling.  La nostra presentació va obtenir la puntuació més alta per a l'Alta Sorbia - Alemanya i va ser segona per a l'Alemanya - Alta Sorbia segons les puntuacions BLEU. For English-Inuktitut, we reached ranks 8 and 10 out of 11 according to BLEU scores.", 'ha': "Wannan karatun describes the Jordon tãrayyar of Universities Halsinki and Aalto University to share jobs biyu of WMT 2020: the news translation between Inuktit and English and the lower-resource translation between Jarman and Upper Sorbian. Ga aikin dukansu, aikinmu sun yi makõmi ga amfani da ma'abũcin harshen sau biyu da aka yi wa shirin karatun mulki-aikin da kuma a sami da sami-sami na sauri. MusuluncinMu ya sãmu koki mafi kyauta wa Sorbian a Samar Sorbiya - Jarman kuma aka ranked na rubutun - Sorbian a Samar da rubutun kamar rubutun BLEU. Ga Ingiriya-Inuktit, mun isa darajõji 8 da 10 daga 11 kamar rubutun BLEU.", 'he': 'העיתון הזה מתאר את השתתפות המשותפת של אוניברסיטת הלסינקי ואולטו לשני משימות משותפת של WMT 2020: התרגום החדשות בין אינוקטיטוט לאנגלית ותרגום משאבים נמוכים בין גרמנית לסורבית העליונה. עבור שני המשימות, המאמצים שלנו מתמקדים בשימוש יעיל של גופורה דו-שפתית וקשורה עם לימוד דו-שפתי מוזמני השיחה שלנו השיגה את התוצאה הגבוהה ביותר עבור הסורבית העליונה - גרמנית והייתה מדרגה שנייה עבור הסורבית הגרמנית - העליונה לפי תוצאות BLEU. For English-Inuktitut, we reached ranks 8 and 10 out of 11 according to BLEU scores.', 'sk': 'V prispevku je opisana skupna udeležba Univerze v Helsinkih in Univerze Aalto pri dveh skupnih nalogah WMT 2020: prevajanju novic med Inuktitut in angleščino ter prevajanju nizkih virov med nemščino in zgornjo sorbijščino. Pri obeh nalogah se naša prizadevanja osredotočajo na učinkovito uporabo enojezičnih in sorodnih dvojezičnih korpusov z načrtovanim večopravilnim učenjem ter optimizirano segmentacijo podbesed z vzorčenjem. Naša predložitev je dobila najvišjo oceno za zgornji sorbijski - nemški in je bila po rezultatih BLEU uvrščena na drugo mesto za nemški - zgornji sorbijski. Za angleško-inuktitut smo po rezultatih BLEU dosegli 8. in 10. mesto od 11.', 'jv': "Perintah iki rambarang nggawe ngulinakake Universite Hellsina karo Aalto Universite iki dadi ono mulasai sing berarti karo WWT 2020: terjamahan balêh gambar InukTitut karo Inggris banjur mbukakipun ciptaaken kelas karo Pak Bewaran Saiki nggo sawar, ditambah-sawar iku, akeh onhal-awak dhéwé nguasai sistem sing perusahaan winih lan ijol-ijolan winih dhéwé uga multi-task lan saiki iki dadi wis antara supra-awak dhéwé tanggal nggo samplit. Awak dhéwé sing paling dhéwé nggawe kelompok sing gak dhéwé karo perthi-perthi, alam kuwi wis ngerasah sekondi kanggo ngerambah sing dirampak dhéwé, kuwi wis ngerasah sing karo perthi-perthi kanggo ngilanggar-InukTitut, kita wis rampunga 8 lan 10 sampek 11 sing mengko tarjamahan 'B-L'", 'bo': 'ཤོག་བྱང་འདིས་Helsinki་དང་Aalto་ཡུལ་ཚོགས་གྱི་ནང་དུ་WMT 2020་གི་བྱ་འགུལ་གཉིས་ཀྱི་མཉམ་དུ་འགྲེལ་བཤད་ཀྱི་ཡོད། ངའི་བྱ་བ་གཉིས་ལས་དུས་འགན་གཉིས་ཀྱིས་སྐད་ཡིག་དང་འབྲེལ་བའི་མཐུན་འབྲེལ་གྱི་སྤྱོད་སྟངས་ལ་དམིགས་གཏང་བྱེད། ང་ཚོའི་བཤད་འཛིན་གྱི་རྣམ་པ་དེ་ སྙར་ཐུག་མར་ཆེ་ཤོས་རྙེད་ཐུབ་པ་དང་། སྐར་མར་ཉུང་ལ་གཉིས་པ་དང་། སྤྱི་ཚོགས་རྣམ་པ་ ས དབྱིན་ཡིག་གི་ནང་ཐིག་འགྲུལ་ལ་བཤད་པ་ལས་ང་ཚོ་༡༡༨་དང་། ༡༠་རེད།'}
{'en': 'The NITS-CNLP System for the Unsupervised MT Task at WMT 2020', 'ar': 'نظام NITS-CNLP لمهمة الترجمة الآلية غير الخاضعة للإشراف في WMT 2020', 'pt': 'O sistema NITS-CNLP para a tarefa MT não supervisionada no WMT 2020', 'es': 'El sistema NITS-CNLP para la tarea de MT no supervisada en el WMT 2020', 'fr': 'Le système NITS-CNLP pour la tâche de TA non supervisée au WMT 2020', 'ja': 'WMT 2020で監督されていないMTタスクのためのNITS - CNLPシステム', 'zh': 'ä»ĄWMT 2020ć—\xa0ç›‘MTč€…NITS-CNLPç»ź', 'hi': 'WMT 2020 में Unsupervised MT कार्य के लिए NITS-CNLP सिस्टम', 'ru': 'Система NITS-CNLP для неконтролируемой задачи MT на WMT 2020', 'ga': 'Córas NITS-CNLP don Tasc MT Gan Maoirseacht ag WMT 2020', 'ka': 'NITS-CNLP სისტემა WMT 2020-ში არაფერიზებული MT დავალებისთვის', 'hu': 'A felügyelet nélküli MT-feladat NITS-CNLP rendszere a WMT 2020-on', 'el': 'Το σύστημα NITS-CNLP για την Μη Εποπτευμένη Εργασία ΜΤ στο WMT 2020', 'it': 'Il sistema NITS-CNLP per il compito MT non supervisionato al WMT 2020', 'kk': 'WMT 2020 жылы MIT тапсырмасының NITS- CNLP жүйесі', 'lt': 'NITS ir CNLP sistema, skirta nekontroliuojamai MT užduotims WMT 2020', 'mk': 'Системот НИТС-ЦНЛП за ненадгледуваната MT задача на WMT 2020', 'ms': 'Sistem NITS-CNLP untuk Tugas MT Tidak Dikawal pada WMT 2020', 'ml': 'നിരീക്ഷിക്കപ്പെടാത്ത MT ജോലിക്കുള്ള NITS-CNLP സിസ്റ്റം WMT 2020-ല്\u200d', 'mt': 'Is-Sistema NITS-CNLP għall-Kompitu MT Mhux Sorveljat fid-WMT 2020', 'mn': 'NITS-CNLP System for the Unsupervised MT Task at WMT 2020', 'no': 'NITS-CNLP-systemet for den ugjennomsiktige MT-oppgåva på WMT 2020', 'ro': 'Sistemul NITS-CNLP pentru activitatea MT nesupravegheată la WMT 2020', 'sr': 'NITS-CNLP sistem za neodržavani MT zadatak na WMT 2020.', 'pl': 'System NITS-CNLP dla nienadzorowanego zadania MT w WMT 2020', 'ta': 'WMT 2020 ல் கண்காணிக்கப்படாத MT பணிக்கான NITS- CNLP அமைப்பு', 'si': 'NITS-CNLP පද්ධති', 'so': 'NITS-CNLP System for the Unsupervised MT Task at WMT 2020', 'sv': 'NITS-CNLP-systemet för den ouppvakade MT-uppgiften vid WMT 2020', 'ur': 'WMT 2020 میں ناپابندی MT ٹاکس کے لئے NITS-CNLP سیسٹم', 'uz': 'Comment', 'vi': 'Hệ thống NITS-CNLP của tập đoàn chưa được giám sát ở WRT 2020.', 'da': 'NITS-CNLP-systemet til den ukontrollerede MT-opgave på WMT 2020', 'nl': 'Het NITS-CNLP Systeem voor de Onbegeleide MT Task bij WMT 2020', 'bg': 'Системата НИTS-CNLP за необузданата МТ задача на МТ 2020', 'hr': 'NITS-CNLP sustav za neodržavani MT zadatak na WMT 2020.', 'de': 'Das NITS-CNLP-System für die unbeaufsichtigte MT-Aufgabe bei WMT 2020', 'ko': 'WMT 2020 MT 작업을 감독하지 않는 NITS-CNLP 시스템', 'id': 'Sistem NITS-CNLP untuk Tugas MT Tidak Disupervisi di WMT 2020', 'sw': 'Mfumo wa NITS-CNLP kwa ajili ya kazi ya MT isiyofuatiliwa wakati wa WMT 2020', 'fa': 'سیستم NITS-CNLP برای وظیفه MT ناحفاظت در WMT 2020', 'tr': "WMT 2020'de gaýd edilmedik MT işi üçin NITS-CNLP Sistemi", 'am': 'ßŗ©NITS-CNLP ßłĄßłŁßŗōßēĄ ßēĀWMT 2020', 'hy': 'Աշխարհային ՄԹԹ 2020-ի ժամանակ անվերահսկված MT-հանձնարարության ՆիԹՍ-CNLP համակարգը', 'af': 'Die NITS-CNLP stelsel vir die Ononderwerpende MT taak by WMT 2020', 'az': "WMT 2020'də qeyd edilməmiş MT işi üçün NITS-CNLP Sistemi", 'bn': 'WMT ২০২০০-এ অনভার্ভার করা MT কাজের জন্য NITS-CNLP সিস্টেম', 'cs': 'Systém NITS-CNLP pro nekontrolovaný MT úkol na WMT 2020', 'ca': 'El sistema NITS-CNLP per a la tasca de MT sense supervisió a WMT 2020', 'et': 'NITS-CNLP süsteem järelevalveta MT ülesandeks WMT 2020', 'bs': 'NITS-CNLP sistem za neodržavani MT zadatak na WMT 2020.', 'fi': 'NITS-CNLP-järjestelmä valvomattomaan MT-tehtävään WMT 2020 -messuilla', 'sq': 'Sistemi NITS-CNLP për Detyrën e Pambikqyrur MT në WMT 2020', 'jv': 'NITS-KNLP System kanggo MT task gak Cocok nggo WT 2020', 'sk': 'Sistem NITS-CNLP za nenadzorovano nalogo MT na WMT 2020', 'he': 'מערכת NITS-CNLP למשימה MT ללא השגחה ב-WMT 2020', 'ha': '@ item: inmenu', 'bo': 'NITS-CNLP System for the Unsupervised MT Task at WMT 2020'}
{'en': 'We describe NITS-CNLP’s submission to WMT 2020 unsupervised machine translation shared task for German language (de) to Upper Sorbian (hsb) in a constrained setting i.e, using only the data provided by the organizers. We train our unsupervised model using monolingual data from both the languages by jointly pre-training the encoder and decoder and fine-tune using backtranslation loss. The final model uses the source side (de) monolingual data and the target side (hsb) synthetic data as a pseudo-parallel data to train a pseudo-supervised system which is tuned using the provided development set(dev set).', 'ar': 'نحن نصف إرسال NITS-CNLP إلى مهمة الترجمة الآلية غير الخاضعة للرقابة WMT 2020 للغة الألمانية (de) إلى الصوربية العليا (hsb) في إعداد مقيد ، أي باستخدام البيانات المقدمة فقط من قبل المنظمين. نقوم بتدريب نموذجنا غير الخاضع للإشراف باستخدام بيانات أحادية اللغة من كلتا اللغتين من خلال التدريب المسبق المشترك لجهاز التشفير وفك التشفير والضبط الدقيق باستخدام فقدان الترجمة العكسية. يستخدم النموذج النهائي بيانات المصدر (de) أحادية اللغة والجانب المستهدف (hsb) البيانات الاصطناعية كبيانات شبه متوازية لتدريب نظام خاضع للإشراف الزائف يتم ضبطه باستخدام مجموعة التطوير المتوفرة (مجموعة التطوير).', 'es': 'Describimos la presentación de NITS-CNLP a la tarea compartida de traducción automática no supervisada del WMT 2020 para el idioma alemán (de) al sorabo superior (hsb) en un entorno limitado, es decir, utilizando solo los datos proporcionados por los organizadores. Entrenamos nuestro modelo no supervisado con datos monolingües de ambos idiomas mediante el entrenamiento previo conjunto del codificador y el decodificador y el ajuste fino mediante la pérdida de retrotraducción. El modelo final utiliza los datos monolingües (des) del lado de la fuente y los datos sintéticos del lado del objetivo (hsb) como datos pseudoparalelos para entrenar un sistema pseudosupervisado que se ajusta utilizando el conjunto de desarrollo proporcionado (dev set).', 'fr': "Nous décrivons la soumission de NITS-CNLP à la tâche partagée de traduction automatique non supervisée WMT 2020 pour la langue allemande (de) vers le haut-sorabe (hsb) dans un cadre restreint, c'est-à-dire en utilisant uniquement les données fournies par les organisateurs. Nous entraînons notre modèle non supervisé à l'aide de données monolingues provenant des deux langues en préentraînant conjointement l'encodeur et le décodeur et en ajustant avec précision à l'aide de la perte de rétrotranslation. Le modèle final utilise les données synthétiques côté source (dé) et les données synthétiques côté cible (hsb) en tant que données pseudo-parallèles pour entraîner un système pseudo-supervisé qui est réglé à l'aide de l'ensemble de développement fourni (jeu de développement).", 'pt': 'Descrevemos a submissão do NITS-CNLP à tarefa compartilhada de tradução automática não supervisionada do WMT 2020 para o idioma alemão (de) para o Alto Sorábio (hsb) em um ambiente restrito, ou seja, usando apenas os dados fornecidos pelos organizadores. Treinamos nosso modelo não supervisionado usando dados monolíngues de ambos os idiomas pré-treinando em conjunto o codificador e o decodificador e ajustando usando a perda de retrotradução. O modelo final usa os dados monolíngues do lado de origem (de) e os dados sintéticos do lado de destino (hsb) como dados pseudo-paralelos para treinar um sistema pseudo-supervisionado que é ajustado usando o conjunto de desenvolvimento fornecido (conjunto de desenvolvimento).', 'ja': '私たちは、NITS - CNLPがWMT 2020に提出したドイツ語（ DE ）の無監督機械翻訳共有タスクを制約された設定（すなわち、主催者が提供したデータのみを使用して）で上部ソルブ語（ HSB ）に説明します。私たちは、エンコーダとデコーダを共同で事前にトレーニングし、逆翻訳ロスを使用して微調整することによって、両言語のモノリンガルデータを使用して、監督されていないモデルをトレーニングします。最終モデルは、ソース側（ DE ）のモノリンガルデータとターゲット側（ HSB ）の合成データを擬似並列データとして使用し、提供された開発セット（開発セット）を使用してチューニングされる擬似監視システムをトレーニングする。', 'zh': '臣等述NITS-CNLP于受限置中WMT 2020无监督机器翻译共之,德语(de)至上索布语(hsb),即仅用组织者数。 吾用二语单语数以练吾无监模,同预训练编码器解码器,反译损耗。 终于用源侧(de)单语数与期端(hsb)合数以为伪并行数以练伪监统,其开发集(dev set)调优之。', 'hi': 'हम एनआईटीएस-सीएनएलपी के डब्ल्यूएमटी 2020 के लिए प्रस्तुत करने का वर्णन करते हैं, जर्मन भाषा (डी) के लिए अपर सोर्बियन (एचएसबी) के लिए एक विवश सेटिंग में साझा किए गए कार्य को असुरक्षित मशीन अनुवाद साझा कार्य में, यानी, आयोजकों द्वारा प्रदान किए गए केवल डेटा का उपयोग करके। हम दोनों भाषाओं से मोनोलिंगुअल डेटा का उपयोग करके अपने असुरक्षित मॉडल को संयुक्त रूप से एनकोडर और डिकोडर और बैकट्रांसलेशन हानि का उपयोग करके ठीक-ट्यून को पूर्व-प्रशिक्षण देकर प्रशिक्षित करते हैं। अंतिम मॉडल स्रोत पक्ष (डी) मोनोलिंगुअल डेटा और लक्ष्य पक्ष (एचएसबी) सिंथेटिक डेटा का उपयोग एक छद्म-समानांतर डेटा के रूप में करता है ताकि एक छद्म-पर्यवेक्षित प्रणाली को प्रशिक्षित किया जा सके जो प्रदान किए गए विकास सेट (देव सेट) का उपयोग करके ट्यून किया जाता है।', 'ru': 'Мы описываем подачу NITS-CNLP на WMT 2020 неконтролируемого машинного перевода общей задачи для немецкого языка (de) на верхний сорбский (hsb) в ограниченной установке, т.е., используя только данные, предоставленные организаторами. Мы обучаем нашу неконтролируемую модель, используя одноязычные данные с обоих языков, совместно предварительно обучая кодер и декодер и тонко настраивая с использованием потери обратного перевода. Окончательная модель использует одноязычные данные на стороне источника (de) и синтетические данные на стороне цели (hsb) в качестве псевдопараллельных данных для обучения псевдонадзорной системы, которая настраивается с использованием предоставленного набора разработок (dev set).', 'ga': 'Déanaimid cur síos ar aighneacht NITS-CNLP chuig tasc roinnte aistriúcháin meaisín gan mhaoirseacht don Ghearmáinis (de) go Gearmáinis Uachtarach (hsb) WMT 2020 go Sorbais Uachtarach (hsb) i suíomh srianta .i., ag baint úsáide as na sonraí a chuir na heagraithe ar fáil amháin. Déanaimid ár múnla neamh-mhaoirsithe a thraenáil agus úsáid á baint as sonraí aonteangacha ón dá theanga trí réamhthraenáil a dhéanamh ar an ionchódóir agus ar an díchódóir agus ar mhionchoigeartú ag baint úsáide as caillteanas aisaistriúcháin. Úsáideann an tsamhail deiridh sonraí sintéiseacha taobh foinse (de) aonteangach agus an taobh sprice (hsb) mar shonraí pseudo-comhthreomhara chun córas maoirsithe bréige a oiliúint atá tiúnta ag baint úsáide as an tacar forbartha (dev set) a chuirtear ar fáil.', 'ka': 'ჩვენ აღწერეთ NITS-CNLP-ის გადაწყვეტილება WMT 2020-ში, რომელიც არ განსხვავებული მანქანის გადაწყვეტილების სამუშაო რაოდენობა გერმანეთის ენაზე (de) ზემოდ სორბიული (hsb) სხვადასხვადასხვადასხვადასხვადასხვადასხვ ჩვენ ჩვენი არსებული მოდელეში მონოლენგური მონაცემების გამოყენებით ორივე ენებიდან ერთადერთად განაკეთებით კოდერი და განაკეთებას და კოდერების გამოყენებას გამოყენებით. საბოლოო მოდელი გამოყენება მონოლენგური მონაცემები და მიზემი მხარეს სინტეტიკური მონაცემები (hsb) როგორც პესეუდო- პარალელური მონაცემები, რომელიც პესეუდო- დანარწმუნებული სისტემის შესა', 'el': 'Περιγράφουμε την υποβολή της στο WMT 2020 χωρίς επίβλεψη κοινής εργασίας μηχανικής μετάφρασης για τη γερμανική γλώσσα (de) στα Άνω Σορβικά (hsb) σε περιορισμένο περιβάλλον, δηλαδή χρησιμοποιώντας μόνο τα δεδομένα που παρέχονται από τους διοργανωτές. Εκπαιδεύουμε το μοντέλο μας χωρίς επίβλεψη χρησιμοποιώντας μονογλωσσικά δεδομένα και από τις δύο γλώσσες προεκπαίδευσε από κοινού τον κωδικοποιητή και τον αποκωδικοποιητή και συντονίζουμε με τη χρήση απώλειας αντίστροφης μετάφρασης. Το τελικό μοντέλο χρησιμοποιεί τα μονογλωσσικά δεδομένα από την πλευρά της πηγής (de) και τα συνθετικά δεδομένα από την πλευρά του στόχου (hsb) ως ψευδο-παράλληλα δεδομένα για την εκπαίδευση ενός ψευδο-εποπτευόμενου συστήματος το οποίο συντονίζεται χρησιμοποιώντας το παρεχόμενο σύνολο ανάπτυξης (dev set).', 'hu': 'A NITS-CNLP felügyelet nélküli gépi fordítási feladatra történő benyújtását korlátozott körülmények között, azaz csak a szervezők által megadott adatok felhasználásával írjuk le. Felügyelet nélküli modellünket mindkét nyelvről származó egynyelvű adatok felhasználásával oktatjuk, közösen előkészítjük a kódolót és dekódolót, és finomhangoljuk a backtranslation veszteség használatával. A végső modell a forrásoldali (de) egynyelvű adatokat és a céloldali (hsb) szintetikus adatokat pszeudopárhuzamos adatként használja egy pszeudo-felügyelt rendszer kiképzésére, amelyet a megadott fejlesztési halmaz (dev halmaz) segítségével hangolnak.', 'it': "Descriviamo l'invio di NITS-CNLP al compito condiviso di traduzione automatica non supervisionata di WMT 2020 per la lingua tedesca (de) all'Alta Sorbiana (hsb) in un'impostazione vincolata, cioè utilizzando solo i dati forniti dagli organizzatori. Formiamo il nostro modello non supervisionato utilizzando dati monolingue provenienti da entrambe le lingue, predisponendo congiuntamente encoder e decoder e perfezionando utilizzando la perdita di backtranslation. Il modello finale utilizza i dati monolingui del lato sorgente (de) e i dati sintetici del lato target (hsb) come dati pseudo-paralleli per formare un sistema pseudo-supervisionato che viene sintonizzato utilizzando il set di sviluppo fornito (dev set).", 'mk': 'Ја опишуваме поднесувањето на НИТС-ЦНЛП на WMT 2020 ненадгледуван машински превод заедничка задача за германски јазик (de) на Горна Сорбија (hsb) во ограничено поставување, т.е. користејќи ги само податоците што ги обезбедуваат организаторите. Ние го тренираме нашиот ненадгледуван модел користејќи монојазични податоци од двата јазици со заеднички претренирање на кодерот и декодерот и финетизирање користејќи загуба на враќање. The final model uses the source side (de) monolingual data and the target side (hsb) synthetic data as a pseudo-parallel data to train a pseudo-supervised system which is tuned using the provided development set(dev set).', 'lt': 'Mes apibūdiname NITS-CNLP pateiktą WMT 2020 nepriži ūrėtą mašin ų vertimo bendrą užduotį vokiečių kalba (de) viršutinei sorbų kalbai (hsb) ribotos s ąlygos, t. y. naudojant tik organizatorių pateiktus duomenis. Mokome savo nepastebimą model į naudojant abiejų kalbų vienkalbinius duomenis kartu parengdami kodatorių, dekoderių ir patobulinimą naudojant vertimo atgal nuostolius. Galutiniame modelyje naudojami šaltinio (de) monokalbiniai duomenys ir tikslinės pusės (hsb) sintetiniai duomenys kaip pseudolygiagretūs duomenys pseudo kontroliuojamai sistemai, pritaikytai naudojant pateiktą vystymo rinkinį (dev rinkinį).', 'kk': 'Біз NITS-CNLP WMT 2020 дегенге ортақтастырылмаған машинаның ортақтастырылмаған тапсырманы неміс тілінің (de) жоғары сорбиян (hsb) тіліне сәйкестірімізді, мысалы, құрастырушылар ғана берілген деректерді қолданып, шектелген м Біз қолданылмаған моделімізді бір тілден бір тілден біріктіріп кодерді, декодерді және қарау аудармаларды жоғалтып қолданатын монолинг деректерін қолдануға жұмыс істейміз. Соңғы үлгі көзі (de) монолингвиялық деректерді және мақсат жағына (hsb) синтетикалық деректерді псевдо- параллелі деректер ретінде қолданып, келтірілген жасау бағдарламасын (dev set) қолдану үшін псевдо- бақылау жүйесі ба', 'ms': 'Kami menggambarkan penghantaran NITS-CNLP ke tugas terjemahan mesin WMT 2020 yang tidak diawasi berkongsi untuk bahasa Jerman (de) ke Sorbian Atas (hsb) dalam tetapan yang diharamkan, iaitu hanya menggunakan data yang diberikan oleh penyesuaian. Kami melatih model kami yang tidak diawasi menggunakan data monobahasa dari kedua-dua bahasa dengan melatih bersama-sama pengekod dan dekoder dan tune-fine menggunakan kehilangan terjemahan belakang. The final model uses the source side (de) monolingual data and the target side (hsb) synthetic data as a pseudo-parallel data to train a pseudo-supervised system which is tuned using the provided development set(dev set).', 'ml': 'നിര്\u200dബന്ധിതമായ ഒരു സോര്\u200dബിയനിലേക്ക് മേല്\u200dനോട്ട് പങ്കെടുത്ത മെഷിന്\u200d പരിശോധിക്കുന്ന ജോലി സംരക്ഷിക്കപ്പെടാത്ത മോഡല്\u200d ഞങ്ങള്\u200d രണ്ടു ഭാഷകളില്\u200d നിന്നും മോണോളില്\u200d നിന്നും വിവരങ്ങള്\u200d ഉപയോഗിച്ച് നമ്മുടെ സംരക്ഷിക്കുന്നു. ബാക്ക അവസാനത്തെ മോഡല്\u200d സോര്\u200dസ്സ് ഭാഗം (de) മോണോളില്\u200dഗ്ലാന്\u200d ഡേറ്റാ ഉപയോഗിക്കുന്നു, ലക്ഷ്യഭാഗത്തുള്ള (hsb) സിന്തെറ്റിക്ക് ഡേറ്റായിരിക്കുന്നു. ഡെവിസെറ്', 'mt': "Aħna niddeskrivu s-sottomissjoni tal-NITS-CNLP lid-WMT 2020 għat-traduzzjoni tal-magni mhux sorveljata kompitu kondiviż għall-lingwa Ġermaniża (de) lill-ogħla Sorbjana (hsb) f'ambjent ristrett jiġifieri bl-użu biss tad-dejta pprovduta mill-organizzaturi. Aħna nħarrġu l-mudell mhux sorveljat tagħna bl-użu ta’ dejta monolingwistika miż-żewġ lingwi billi nħarrġu b’mod konġunt minn qabel il-kodifikatur u d-dekoder u nħarrġu bl-użu ta’ telf ta’ traduzzjoni b’lura. Il-mudell finali juża d-dejta monolingwistika fuq in-naħa tas-sors (de) u d-dejta sintetika fuq in-naħa fil-mira (hsb) bħala dejta psewdo-parallel għat-taħriġ ta’ sistema psewdo-superviża li hija a ġġustata bl-użu tas-sett ta’ żvilupp ipprovdut (dev set).", 'mn': 'Бид NITS-CNLP-ын WMT 2020-д зөвхөн зохион байгуулагчдын өгөгдлийг ашиглаж, Германы хэл (de) дээд Сорб (hsb) руу хуваалцаагүй машины хөрөнгө оруулалтын даалгаварыг хэлж өгдөг. Бид хоёр хэл дээр ганц хэлний өгөгдлийг ашиглаж чаддаггүй загваруудыг багш суралцаж, кодчууд, шийдвэрлэгч болон багш tune-г backtranslation loss ашиглаж чаддаг. Эцсийн загвар нь эх үүсвэрийн талыг (de) ганц хэлний өгөгдлийг, зорилготой талыг (hsb) синтетик өгөгдлийг pseudo-параллел өгөгдлийн хувьд хэрэглэдэг бөгөөд pseudo-supervised системийг хангалттай хөгжлийн суурь(dev set) ашигладаг.', 'no': 'Vi beskriver NITS-CNLP s in tilføring til WMT 2020, delt maskinsomsetjing for tysk språk (de) til øvre Sorbian (hsb) i eit avgrensa innstilling, dvs. berre med data som organisatorene gjev. Vi treng vårt unsupporterte modell ved å bruka monospråk- data frå begge språka ved å kopla opplæringa av koderen og dekoderen og finnstillinga med tap av tilbakeomsetjingar. Den siste modellen brukar kjeldeside (de) monospråk- data og målside- syntetiske data (hsb) som pseudoparallelle data for å trena eit pseudo- oversikt- systemet som er sett opp ved hjelp av den oppgjevne utviklingssett (dev set).', 'pl': 'Opisujemy zgłoszenie NITS-CNLP do WMT 2020 bez nadzoru zadania wspólnego tłumaczenia maszynowego dla języka niemieckiego (de) na Górny Sorb (hsb) w warunkach ograniczonych tj. wykorzystując tylko dane dostarczone przez organizatorów. Szkolimy nasz model bez nadzoru z wykorzystaniem jednojęzycznych danych z obu języków poprzez wspólne szkolenie kodera i dekodera oraz precyzyjne dostrajanie przy użyciu straty backtranslacji. Ostateczny model wykorzystuje dane jednojęzyczne ze strony źródłowej (de) oraz syntetyczne ze strony docelowej (hsb) jako pseudo-równoległe dane do szkolenia pseudo-nadzorowanego systemu, który jest dostrojony przy użyciu dostarczonego zestawu rozwojowego (zestawu dev).', 'ro': 'Descriem transmiterea NITS-CNLP la WMT 2020, fără supraveghere, sarcina partajată de traducere automată pentru limba germană (de) în Sorbiană Superioară (hsb), într-o setare restricționată, adică folosind doar datele furnizate de organizatori. Instruim modelul nostru nesupravegheat folosind date monolingve din ambele limbi prin pregătirea comună a codificatorului și a decodorului și reglarea fină utilizând pierderea traducerii înapoi. Modelul final utilizează datele monolingve din partea sursă (de) și datele sintetice din partea țintă (hsb) ca date pseudo-paralele pentru a instrui un sistem pseudo-supravegheat care este reglat folosind setul de dezvoltare furnizat (set de dezvoltare).', 'sr': 'Mi opisujemo podnošenje NITS-CNLP na WMT 2020-u neodređeni zadatak za prevod mašin e za njemački jezik (de) na gornji sorbijski (hsb) u ograničenom stanju, tj. koristeći samo podatke koje su pružili organizatori. Vježbamo svoj neodređeni model koristeći monojezičke podatke od obje jezika zajedno predobučavajući kodera i dekodera i dobre tune koristeći gubitak backtranslation. Konačni model koristi izvornu stranu (de) monojezičkih podataka i ciljne strane (hsb) sintetičke podatke kao pseudoparalelne podatke za obuku pseudo-nadzornog sistema koji se navodi uz obezbeđeni set razvoja (dev set).', 'so': "We describe NITS-CNLP's submission to WMT 2020 unsupervised machine translation shared task for German language (de) to Upper Sorbian (hsb) in a constrained setting i.e, using only the data provided by the organizers.  Tusaalkayaga aan la ilaalinayn ayaannu ku tababarinnaa isticmaalka macluumaadka luuqadaha labadooda luqadood, si wadajir ah ayaannu ugu tababarinno koordirada, codcodsiga iyo hagitaanka, isticmaalka khasaarada dib-turjumidda. Tusaale ugu dambeyso wuxuu isticmaalaa dhanka noocyada (de) ee noocyada afka (hsb) iyo dhanka kooxaha (hsb) si ay u tababaridaan nidaamka pseudo-ilaalinaysan oo lagu isticmaalo saxda horumarinta (dev set).", 'sv': 'Vi beskriver NITS-CNLP:s inlämning till WMT 2020 oövervakad maskinöversättning delad uppgift för tyska språket (de) till Övre Sorbiska (hsb) i en begränsad inställning, dvs. endast med hjälp av de uppgifter som tillhandahålls av arrangörerna. Vi tränar vår oövervakade modell med enspråkiga data från båda språken genom att gemensamt förbereda kodaren och avkodaren och finjustera med backtranslation loss. Den slutliga modellen använder källsidan (de) enspråkiga data och målsidan (hsb) syntetiska data som pseudoparallella data för att träna ett pseudo-övervakat system som justeras med hjälp av den tillhandahållna utvecklingsuppsättningen (dev set).', 'si': 'අපි NITS-CNLP ගේ පිළිබඳුම WMT 2020ට අවශ්\u200dයාවක් නැති ජර්මන් භාෂාව (de) වෙනුවෙන් ජර්මන් භාෂාව (dsb) වෙනුවෙන් උපර සොර්බියාන් (dsb) වෙනුවෙන් ප අපි භාෂාවල් දෙන්නම් එක්ක භාෂාවික දත්ත භාවිතා කරන්න අපේ නිර්භාෂිත මොඩේල් එක්ක නිර්භාෂ කරනවා කොඩර් සහ ඩිකොඩ අන්තිම මොඩල් භාෂාවක් පැත්ත (de) එක භාෂාවක් තොරතුරු සහ ඉලක්ක පැත්ත (fsb) සංවිධානය දත්ත (pseudo-Parallel data as a pseudo-supervised system that is tuned by the user.', 'ta': '@ info மொழிகளிலிருந்தும் இரு மொழிகளிலிருந்து கடைசி மாதிரி வழங்கப்பட்ட உருவாக்க அமைப்பை பயன்படுத்தும் மூலத்தின் பக்கம் (de) மொத்த மொழிமொழி தகவல் மற்றும் இலக்க பக்கத்தில் (hsb) கூட்டு- ஒத்திசைப்படுத்தும் தக', 'ur': 'ہم نے NITS-CNLP کی تحویل WMT 2020 کے لئے بغیر قابل تحویل کے مطابق جرمن زبان کے لئے (de) اوپر سوربیان (hsb) کے لئے ایک محدودہ مقررہ مقررہ مقررہ مقررہ مقررہ مقررہ مقررہ مقررہ مقررہ مقررہ مقررہ مقررہ مقررہ مقر ہم ایک زبان سے ایک زبان کی ڈیٹا کے مطابق اپنے غیرقابل مدل کی تربیت کرتے ہیں، ایک دوسرے زبان سے ایک دوسرے سے کوڈر اور ڈیکوڈر اور نیک ٹونس کے مطابق پیدا کریں۔ آخری موڈل سورس سائڈ (de) monolingual data اور موقع سائڈ (hsb) سینٹیسی ڈائٹ (pseudo-parallel data) کے طور پر استعمال کرتا ہے کہ ایک pseudo-supervised سیسٹم کو تطالب کرے جو پیش کئے گئے ڈولوپ سٹ (dev set) کے مطابق تنظیم کیا جاتا ہے.', 'uz': 'Biz NITS-CNLP WMT 2020 tomonidan xavfsiz qilmagan mashinalar tarjima qilishini anglatamiz. Olmoncha tili (de) yuqori Sorbiya (hsb) uchun yuqori sorbiy (hsb) bilan birlashtirilgan vazifani tahlil qilamiz. Masalan, tashkilotlar tomonidan foydalanadigan maʼlumot yordamida foydalanamiz. @ info: whatsthis The final model uses the source side (de) monolingual data and the target side (hsb) synthetic data as a pseudo-parallel data to train a pseudo-supervised system which is tuned using the provided development set(dev set).', 'vi': 'Chúng tôi mô tả việc NITS-CNLP bị hư hại bởi WRT 2020 đã không giám s át việc dịch chuyển máy chung một nhiệm vụ cho ngôn ngữ Đức (de) tới Upper Sorbian (hsb) trong một thiết lập bị hạn, tức là chỉ dùng dữ liệu do tổ chức cung cấp. Chúng tôi huấn luyện mô hình không giám sát của mình bằng cách sử dụng dữ liệu ngôn ngữ từ cả hai ngôn ngữ bằng việc huấn luyện mã hóa và mã hóa và tinh thần bằng cách thua lỗ do bản dịch. The final model using the source side (de) monolingal data and the dest side (hsb) Synthetic data as a pseudo-parallel data to train a pseudo-giám sát system which is tunted using the provided development set(dev set).', 'bg': 'Описваме предаването на НИТС-ЦНЛП в ММТ 2020 без надзор на споделената задача за немски език (де) на Горносорбийски (хсб) в ограничена настройка, т.е. използвайки само данните, предоставени от организаторите. Ние тренираме нашия модел без надзор, използвайки едноезични данни от двата езика, като съвместно предварително обучаваме кодера и декодера и фино настройваме чрез загуба на обратен превод. Крайният модел използва едноезичните данни от източника и синтетичните данни от целевата страна като псевдопаралелни данни за обучение на псевдонадзорна система, която се настройва с помощта на предоставения набор от разработки (dev set).', 'nl': 'We beschrijven de inzending van NITS-CNLP aan WMT 2020 onbeheerde machine translation shared task voor Duitse taal (de) naar het Opper-Sorbisch (hsb) in een beperkte setting, d.w.z. met alleen de gegevens die door de organisatoren worden verstrekt. We trainen ons onbeheerde model met eentalige gegevens uit beide talen door gezamenlijk de encoder en decoder voor te trainen en af te stemmen met backtranslation loss. Het uiteindelijke model gebruikt de bronzijde (de) eentalige gegevens en de doelzijde (hsb) synthetische gegevens als pseudo-parallelle gegevens om een pseudo-supervised systeem te trainen dat is afgestemd met behulp van de meegeleverde dev set.', 'da': "Vi beskriver NITS-CNLP's indsendelse til WMT 2020 uden opsyn med maskinoversættelse delt opgave for tysk sprog (de) til Øversorbisk (hsb) i en begrænset indstilling, dvs. ved hjælp af de data, arrangørerne har leveret. Vi træner vores uautoriserede model ved hjælp af ensprogede data fra begge sprog ved i fællesskab at forudtræne encoder og dekoder og finjustere ved hjælp af backtranslation tab. Den endelige model bruger kildesidens (de) ensprogede data og målsidens (hsb) syntetiske data som pseudo-parallelle data til at træne et pseudo-overvåget system, som justeres ved hjælp af det medfølgende udviklingssæt (dev-sæt).", 'ko': 'NITS-CNLP가 제한된 환경에서 WMT 2020에 제출한 독일어 (de) 에서 상소포어 (hsb) 에 이르기까지의 무감독 기계 번역 공유 작업, 즉 조직자가 제공한 데이터만 사용하는 것을 설명합니다.우리는 두 언어에서 나온 단어 데이터를 사용하여 예비 훈련 인코더와 디코더를 연합하여 우리의 무감독 모델을 훈련시키고 번역 손실을 미세하게 조정한다.최종 모델은 원본(de) 단어 데이터와 목표단(hsb)의 합성 데이터를 위조 병행 데이터로 위조 감독 시스템을 훈련하고 이 시스템은 제공된 개발집(dev집)을 사용하여 조정한다.', 'hr': 'Mi opisujemo podatke NITS-CNLP-a na WMT 2020-u podatke koji su podijeljeni za njemački jezik (de) na gornji Sorbijanski (hsb) u ograničenom stanju, tj. koristeći samo podatke koje su predavali organizatori. Vježbamo svoj neodređeni model koristeći monojezičke podatke od obje jezika zajedno predobučavajući kodera i dekodera i dobre tune koristeći gubitak povratka. Konačni model koristi izvorne strane (de) monojezičke podatke i ciljne strane (hsb) sintetičke podatke kao pseudoparalelne podatke za obuku pseudo-nadziranog sustava koji se navodi s pruženim razvojnim setom (dev set).', 'id': "We describe NITS-CNLP's submission to WMT 2020 unsupervised machine translation shared task for German language (de) to Upper Sorbian (hsb) in a constrained setting i.e, using only the data provided by the organizers.  Kami melatih model kami yang tidak diawasi menggunakan data monobahasa dari kedua bahasa dengan bersama-sama melatih prekoder dan dekoder dan fine-tune menggunakan kehilangan backtranslation. Model akhir menggunakan data monobahasa sisi sumber (de) dan data sintetis sisi sasaran (hsb) sebagai data pseudo-paralel untuk melatih sistem pseudo-supervised yang disesuaikan menggunakan set perkembangan yang disediakan (dev set).", 'fa': 'ما تحویل NITS-CNLP را به WMT 2020 توصیف می\u200cکنیم که جز از داده\u200cهایی که توسط سازمان\u200cکنندگان داده شده\u200cاند، برای زبان آلمانی (de) به سوربیان بالا (hsb) در تنظیم محدودیت است. ما با استفاده از داده های تک زبانی از هر دو زبان با پیش آموزش پیش از آموزش پیدا کردن کودهر و دکوردر و آهنگ زیادی از دست دادن ترجمه پشتی آموزش می کنیم. مدل نهایی از جانب منبع (de) داده\u200cهای یک زبان و داده\u200cهای متن\u200cزبان (hsb) به عنوان داده\u200cهای متن\u200cآمیز pseudo-parallel استفاده می\u200cکند تا یک سیستم تحت نظر pseudo-supervised که با استفاده از مجموعه\u200cی توسعه\u200cدهنده (dev set) تنظیم می\u200cشود.', 'tr': "Biz NITS-CNLP'i ň WMT 2020'a mümkinçiligini alman dilinde (de) üst-Sorbiýa (hsb) maşynyň terjime edilmesi diňe düzenleyiciler tarapyndan berilen maglumatlaryny ulanýarys. Biz özümiziň gaýd edilmedik nusgymyzy hem dillerden hem enkoderi hem kodeýäni hem kodeýäni hem kodeýäni hem gowy kodeýäni hem özümizi terjime etmek üçin ulanyp öwredýäris. Soňky nusga çeşme sahypasyny (de) monodil maglumatlaryny we maksady tarapyny (hsb) pseudo-parallel maglumatlar üçin pseudo-kontrol sistemini öwrenmek üçin ullanýar.", 'de': 'Wir beschreiben die Einreichung von NITS-CNLP an WMT 2020 unüberwachte maschinelle Übersetzungsaufgabe für die deutsche Sprache (de) nach Obersorbisch (hsb) in einem eingeschränkten Rahmen, d.h. nur mit den von den Organisatoren bereitgestellten Daten. Wir trainieren unser unbeaufsichtigtes Modell mit einsprachigen Daten aus beiden Sprachen, indem wir Encoder und Decoder gemeinsam vortrainieren und mit Rückübersetzungsverlust feinjustieren. Das endgültige Modell nutzt die quellenseitigen (de) einsprachigen Daten und die zielseitigen (hsb) synthetischen Daten als pseudo-parallele Daten, um ein pseudo-überwachtes System zu trainieren, das mit dem bereitgestellten Entwicklungsset (dev set) abgestimmt wird.', 'sw': 'Tunaelezea ujumbe wa Shirika la NITS-CNLP kwa WMT 2020 usio na uhakika wa mashine ilishirikishwa kazi kwa lugha ya Ujerumani (de) kwenda Sorbia ya Juu (hsb) katika kitengo kikubwa, yaani, kwa kutumia taarifa tu zilizotolewa na waandaaji. We train our unsupervised model using monolingual data from both the languages by jointly pre-training the encoder and decoder and fine-tune using backtranslation loss.  Mfano wa mwisho unatumia taarifa za asili za lugha (de) na taarifa za ushirikiano (hsb) kama data zinazofanana na pseudo ili kufundisha mfumo uliotangaliwa na pseudo unaotumiwa kwa kutumia seti ya maendeleo (dev set).', 'am': 'እና NITS-CNLP ለWMT 2020 ያልጠበቀው መሣሪያን ትርጓሜ ለጀርመን ቋንቋ (de) ወደ ላይኛይቱ ሶርቢያ (hsb) በተገኘ ማዘጋጀት ላይ የተሰራጨውን ሥራ እናሳውቃለን፡፡ በሁለቱም ቋንቋዎች ያሉትን የሞዴል ዳታዎችን በመጠቀም የኮድ እና ቀድሞ ማጠቃለያውን በመጠቀም ጥሩ እና በጥቅምት በተጠቃሚ ጥያቄን እናስተምራለን፡፡ የመጨረሻው ሞዴል የክፍለ ቋንቋ ዳታ (de) እና የስኬት ዳታ (hsb) ሰንተቲካዊ ዳታ (pseudo-parallel data) ይጠቅማል፡፡', 'sq': "We describe NITS-CNLP's submission to WMT 2020 unsupervised machine translation shared task for German language (de) to Upper Sorbian (hsb) in a constrained setting i.e, using only the data provided by the organizers.  We train our unsupervised model using monolingual data from both the languages by jointly pre-training the encoder and decoder and fine-tune using backtranslation loss.  Modeli përfundimtar përdor të dhënat monogjuhësore të anës së burimit (de) dhe të dhënat sintetike të anës së objektivit (hsb) si një të dhënë pseudo-paralele për të trajnuar një sistem pseudo-mbikqyrur i cili është rregulluar duke përdorur set të siguruar zhvillimi (set dev).", 'af': "Ons beskryf NITS-CNLP s e onderskrywing na WMT 2020 onverondersteunde masjien vertaling gedeelde taak vir Duitse taal (de) na Boonste Sorbiese (hsb) in 'n beperkende instelling, t.e. gebruik slegs die data verskaf deur die organiseerders. Ons tref ons ongeonderwerpende model met gebruik van monolinglike data van beide die taal deur joint voorwerp van die enkoder en dekoder en fin- tune te gebruik terugvertaling verlies. Die eindelike model gebruik die bron kant (de) monolinglike data en die doel kant (hsb) sintetiese data as 'n pseudo- parallele data om 'n pseudo- superviseerde stelsel te trein wat is aangestel deur die verskaf ontwikkelingsstel( dev set).", 'bn': 'আমরা এনআইটিএস-সিএনএলপিকে উইএমটি ২০২০ সালে আপসংরক্ষিত মেশিন অনুবাদ প্রদান করেছি যা জার্মান ভাষার জন্য (ডি) উপার সোর্বিয়ান (এইচবি) প্রকাশিত কাজের জন্য শেয়ার কর আমরা আমাদের অরক্ষিত মডেলের প্রশিক্ষণ প্রশিক্ষণ দিচ্ছি ব্যাক-ট্রেনিং ক্ষতি ব্যবহার করে দুই ভাষা থেকে মোনোলিভাল ডাটা ব্যবহার করে। চূড়ান্ত মডেল মোনোলিভাল ডাটা এবং লক্ষ্য পার্টিক ডাটা (এইচবি) সিন্টেটিক ডাটা হিসেবে ব্যবহার করে একটি পিসুডো-প্যারালেল ডাটা হিসেবে প্রশিক্ষণ করে যা প্রদান', 'bs': 'Opišemo podatke NITS-CNLP-a na WMT 2020, koji nije podržavao zajednički zadatak za prevod mašin e za njemački jezik (de) na gornji Sorbijanski (hsb) u ograničenom stanju, tj. koristeći samo podatke koje su pružili organizatori. Vježbamo svoj neodređeni model koristeći monojezičke podatke od obje jezika zajedno predobučavajući kodera i dekodera i dobre tune koristeći gubitak povratka. Konačni model koristi izvorne strane (de) monojezičke podatke i ciljne strane (hsb) sintetičke podatke kao pseudoparalelne podatke za obuku pseudo-nadzornog sistema koji se prilagođuje koristeći predviđeni set razvoja(dev set).', 'az': "Biz NITS-CNLP'in WMT 2020-…ô m√ľ…ôyy…ôn edilm…ôs i olaraq, Alman dili (de) il…ô YuxarńĪ Sorbian (hsb) il…ô birlikd…ô m√ľ…ôyy…ôn edilm…ômiŇü maŇüńĪn √ßeviri i Ňüini t…ôsdiql…ôyirik, yoxsa organizatorlarńĪn veril…ôn m…ôlumatlarńĪ istifad…ô edirik. Biz √∂z√ľm√ľz…ô m√ľ…ôyy…ôn edilm…ômiŇü modell…ôri h…ôr dild…ôn monodil veril…ôn m…ôlumatlarńĪ il…ô birlikd…ô kodlayńĪcńĪ, dekoderi v…ô d√ľzg√ľn t…ôhsil etm…ôk √ľ√ß√ľn t…ôhsil edirik. Son modell…ôr m…ônb…ô t…ôr…ôfind…ôn (de) monodil veril…ônl…ôri v…ô m…ôqs…ôd t…ôr…ôfind…ôn (hsb) sintetik veril…ônl…ôri pseudo-paralel veril…ônl…ôri t…ôhsil etm…ôk √ľ√ß√ľn pseudo-supervised sistemi t…ôhsil etm…ôk √ľ√ß√ľn t…ôhsil edil…ôn t…ôhsil t…ôr…ôfind…ôn istifad…ô edir.", 'ca': "Descrivem la subministració del NITS-CNLP a la traducció automàtica no supervisada de WMT 2020, tasca compartida per a la llengua alemana (de) a la Alta Sorbia (hsb) en un entorn limitat, és a dir, utilitzant només les dades proporcionades pels organitzadors. Ensenyem el nostre model sense supervisió fent servir dades monolingües de les dues llengües preparant conjuntament el codificador, el decodificador i ajustar fent servir la pèrdua de retrotraducció. El model final utilitza les dades monolingües del costat d'origen (de) i les dades sintètiques del costat d'origen (hsb) com a dades pseudoparallels per formar un sistema pseudosupervisat que està ajustad usant el conjunt de desenvolupament proporcionat (dev set).", 'et': 'Kirjeldame NITS-CNLP esitamist WMT 2020 järelevalveta masintõlke jagatud ülesandele saksakeeles (de) Ülemsorbiini (hsb) piiratud seadistuses, st kasutades ainult korraldajate esitatud andmeid. Me treenime oma järelevalveta mudelit, kasutades mõlema keele ühekeelseid andmeid, koolitades ühiselt kodeerijat ja dekooderit ning peenhäälestades tagantõlkekaotuse abil. Lõplikus mudelis kasutatakse lähtepoolseid (de) ühekeelseid andmeid ja sihtpoolseid (hsb) sünteetilisi andmeid pseudoparalleelsete andmetena pseudojärelevalvega süsteemi koolitamiseks, mis on häälestatud kasutades esitatud arenduskomplekti (dev set).', 'cs': 'Popisujeme podání NITS-CNLP do WMT 2020 bez dozoru sdílené úlohy strojového překladu pro německý jazyk (de) do hornosorbštiny (hsb) v omezeném prostředí, tj. s využitím pouze dat poskytnutých organizátory. Náš model bez dozoru trénujeme s využitím jednojzyčných dat z obou jazyků společným předškolením kodéru a dekodéru a jemným laděním pomocí ztráty zpětného překladu. Konečný model využívá jednojjazyčná data na zdrojové straně (de) a syntetická data na cílové straně (hsb) jako pseudo-paralelní data k tréninku pseudo-supervisovaného systému, který je laděn pomocí poskytnuté vývojové sady (dev set).', 'hy': "Մենք նկարագրում ենք, թե ինչպես է Նիթս-ՍՆԼՊ-ը ներկայացնում ԱՄԹ 2020-ի անվերահսկված մեքենային թարգմանման համագործակցությունը գերմանացի լեզվի համար (de) Արևի Սորբյան լեզվին (HSB) սահմանափակ պայմաններում, այսինքն՝ միայն կազմակերպողների տրամադրված տվ Մենք սովորեցնում ենք մեր անվերահսկված մոդելը օգտագործելով երկու լեզուներից մեկլեզու տվյալներ' միասին նախապատրաստելով կոդավորիչը, կոդավորիչը և փոփոխությունը' օգտագործելով թարգմանման կորուստը: Վերջնական մոդելը օգտագործում է աղբյուրի կողմը (de) միալեզվով տվյալները և նպատակային կողմի (HSb) սինթետիկ տվյալները որպես կեղծ-զուգահեռ տվյալներ կեղծ-վերահսկված համակարգի ուսումնասիրելու համար, որը կազմված է օգտագործելով տրամադրված զարգաց", 'fi': 'Kuvaamme NITS-CNLP:n lähettämän WMT 2020:n valvomattoman konekäännöksen yhteisen tehtävän saksankieliseksi (de) yläsorbiaksi (hsb) rajoitetussa asetuksessa eli käyttäen vain järjestäjien antamia tietoja. Harjoittelemme valvomatonta malliamme käyttäen molempien kielten monokielistä dataa esikouluttamalla koodaajaa ja dekooderia yhdessä ja hienosäätämällä jälkikäännöksen menetystä käyttäen. Lopullinen malli käyttää lähdepuolen (de) yksikielistä dataa ja kohdepuolen (hsb) synteettistä dataa pseudorinnakkaisena datana pseudovalvotun järjestelmän kouluttamiseksi, joka viritetään käyttäen annettua kehitysjoukkoa (dev set).', 'ha': "Tuna bayyana al'amarin NItS-CNLP da aka bãyar da zuwa WMT 2020, wanda aka tsare na mashine mai fassarar da aka yi rabo da aikin Jajeruman (de) zuwa Upper Sorbian (hb) a cikin tsarin da aka ƙudurta, misali, yana amfani da data wanda ake bãyar da shi kawai. Tuna kõre misalinmu wanda ba'a tsare ba da shi, don mu yi amfani da data masu motsi daga cikin harshen biyu, ko kuma mu yi amfani da hasara na bayan-fassarar. @ info: whatsthis", 'jv': 'Awakdhéwé nglebah tarjamahan NITS-KNLP kanggo mbatalungi WT 2020 kuwi nggawe perusahaan mulai nggawe barang kelangan kanggo nganggep banter Awak dhéwé luwih-luwih akeh model sing gak nggawe gerang-luwih dumateng manut karo ingkang sampeyan kuwi tindakan. model tuku', 'sk': 'Opisujemo oddajo NITS-CNLP na WMT 2020 breznadzorovano strojno prevajanje skupne naloge nemškega jezika (de) v zgornjo sorbijščino (hsb) v omejeni nastavitvi, tj. z uporabo samo podatkov organizatorjev. Svoj neobzorovan model treniramo z enojezičnimi podatki iz obeh jezikov s skupnim predusposabljanjem kodirnika in dekoderja ter natančno nastavitvijo z izgubo nazaj prevajanja. Končni model uporablja izvorne (de) enojezične podatke in sintetične podatke ciljne strani (hsb) kot psevdo-paralelne podatke za usposabljanje psevdo nadzorovanega sistema, ki je nastavljen z uporabo zagotovljenega razvojnega niza (dev set).', 'bo': "ང་ཚོས་NITS-CNLP's submission to WMT 2020 unsupervised machine translation shared task for German language (de) to Upper Sorbian (hsb)in a constrained setting i.e. using only the data provided by the organizers. We train our unsupervised model using monolingual data from both languages by jointly training the encoder and decoder and fine-tune using backtranslation loss. The final model uses the source side (de) monolingual data and the target side (hsb) synthetic data as a pseudo-parallel data to train a pseudo-supervised system which is tuned using the provided development set(dev set).", 'he': 'אנחנו מתארים את ההעברה של NITS-CNLP לתרגום מכונות ללא השגחה של WMT 2020 משימה משותפת לשפה גרמנית (de) לשפה הגרמנית העליונה (hsb) במצב מוגבל, כלומר, בשימוש רק נתונים שנוספים על ידי המארגנים. אנו מאמן את המודל שלנו ללא השגחה באמצעות נתונים מונושפתיים משני השפות על ידי אימון משותף קודם את הקודר והדקודר הדוגמא הסופית משתמשת במידע מונושפתי הצד המקורי (de) והמידע הסינטטי הצד המטרה (hsb) בתור מידע פסאודו-מקביל לאימון מערכת ששולטת על פסאודו שמתאורת באמצעות קבוצת התפתחות (dev set) הנוספת.'}
{'en': 'Adobe AMPS’s Submission for Very Low Resource Supervised Translation Task at WMT20', 'pt': 'Submissão do Adobe AMPS para tarefa de tradução supervisionada de recursos muito baixos no WMT20', 'es': 'Presentación de Adobe AMPS para la tarea de traducción supervisada de muy pocos recursos en WMT20', 'ar': 'إرسال Adobe AMPS لمهمة الترجمة الخاضعة للإشراف ذات الموارد المنخفضة جدًا في WMT20', 'fr': "Soumission d'Adobe AMPS pour une tâche de traduction supervisée à très faibles ressources au WMT20", 'ja': 'WMT 20での非常に低いリソース監視翻訳タスクのためのAdobe AMPの提出', 'hi': 'WMT20 में बहुत कम संसाधन पर्यवेक्षित अनुवाद कार्य के लिए एडोब AMPS का सबमिशन', 'ru': 'Заявка Adobe AMP на выполнение задачи по переводу под руководством специалистов с очень низким уровнем ресурсов на WMT20', 'zh': 'Adobe AMPS 于 WMT20 上提交非常低资源监督译事', 'ga': 'Aighneacht Adobe AMPS do Thasc Aistriúcháin Faoi Mhaoirseacht Acmhainní An-Íseal ag WMT20', 'ka': 'Comment', 'el': 'Υποβολή της για εργασία μετάφρασης με πολύ χαμηλό επίπεδο πόρων στο WMT20', 'hu': 'Az Adobe AMPS beküldése a WMT20 rendkívül alacsony erőforrással felügyelt fordítási feladataira', 'it': "Invio di Adobe AMPS per un'attività di traduzione supervisionata con risorse molto basse a WMT20", 'kk': 'Comment', 'ml': 'ഏറ്റവും കുറഞ്ഞ വിഭവങ്ങള്\u200dക്കുള്ള അഡോബി എമ്പിഎസ്സിന്റെ സബ്മിഷന്\u200d', 'mk': 'Предавањето на Адабо АМПС за задача на превод надгледувана со многу ниски ресурси на WMT20', 'mt': "Is-sottomissjoni tal-AMPS għall-kompitu ta' traduzzjoni sorveljata b'riżorsi baxxi ħafna fid-WMT20", 'lt': 'Adobe AMPS pateiktas labai mažų išteklių prižiūrimos vertimo darbas WMT20', 'mn': "Adobe AMPS's Submission for Very Low Resource Supervised Translation Task at WMT20", 'no': 'Adobe AMPS- undermission for veldig låg ressursoversikt omsetjingsverkt på WMT20', 'pl': 'Zgłoszenie Adobe AMPS do zadań tłumaczeniowych nadzorowanych bardzo niskimi zasobami w WMT20', 'ms': 'Submission Adobe AMPS untuk Tugas Terjemahan Terjaga Sumber Terrendah di WMT20', 'ro': 'Trimiterea Adobe AMPS pentru activitatea de traducere supravegheată cu resurse foarte reduse la WMT20', 'sv': 'Adobe AMPS:s inlämning för mycket låg resursövervakad översättningsuppgift på WMT20', 'sr': 'Adobe AMPS podmission za vrlo niski prijevozni zadatak za prevod na WMT20-u', 'si': 'Name', 'so': 'Adobe AMPS Submission for Very Low Resource Supervised Translation Task at WMT20', 'ta': 'மிகவும் குறைந்த மூலத்திற்கான Adobe AMPS துணைப்பு', 'ur': "WMT20 میں بہت کم رسسور زیادہ تحقیر کی ترجمہ ٹاکس کے لئے Adobe AMPS's Submission for Very Low Resource Supervised Translation Task", 'uz': 'Comment', 'vi': 'Kiểm tra lại chất lượng của phòng hợp chất lượng rất thấp người quản lý dịch tại WM20', 'da': "Adobe AMPS's indsendelse til oversættelsesopgave med meget lav ressource på WMT20", 'bg': 'Подаване на задача за превод с много ниски ресурси, контролирана от надзор в WMT20', 'hr': 'Submission Adobe AMPS-a za vrlo niski prijevozni zadatak za prevod na WMT20-u', 'nl': "Adobe AMPS's indiening voor vertaaltaak met een zeer lage resource supervised bij WMT20", 'de': 'Einreichung von Adobe AMPS für Übersetzungsaufgaben mit sehr geringen Ressourcen bei WMT20', 'id': "Adobe AMPS's Submission for Very Low Resource Supervised Translation Task at WMT20", 'ko': 'Adobe AMPS가 WMT20에서 매우 낮은 리소스 감독 번역 작업을 제출했습니다.', 'fa': 'Submission of Adobe AMPS for Very Low Resource Supervised Translation Task at WMT20', 'sw': "Adobe AMPS's Submission for Very Low Resource Supervised Translation Task at WMT20", 'tr': "Adobe AMPS's Submission for Very Low Resource Supervised Translation Task at WMT20", 'af': 'Adobe AMPS se Submission vir baie lae hulpbron ondersoek vertaling taak by WMT20', 'sq': 'Submission of Adobe AMPS for Very Low Resource s Supervised Translation Task at WMT20', 'hy': 'Ադոբի ԱՄՊՍ-ի ներկայացումը շատ ցածր ռեսուրսների վերահսկվող թարգմանման գործի համար', 'am': 'አዲስ ዶሴ ፍጠር', 'az': "Adobe AMPS's Submission for Very Low Resource Supervised Translation Task at WMT20", 'bn': 'WMT20-এ অনুবাদ করা অনুবাদের কাজের জন্য Adob AMPS সাবমিশন', 'bs': 'Podatak Adobe AMPS-a za vrlo niski prevodni zadatak na WMT20-u', 'ca': "Adobe's AMPS's Submission for Very Low Resources Supervised Translation Task at WMT20", 'et': 'Adobe AMPS esitab väga väikese ressursi järelevalvega tõlketöö WMT20', 'cs': 'Podání společnosti Adobe AMPS pro překladatelskou úlohu s velmi nízkými zdroji na WMT20', 'fi': 'Adobe AMPS:n toimittama eritt채in v채h채n resursseja valvottu k채채nn철sty철 WMT20:ssa', 'he': 'המשימה של Adobe AMPS למשימה של משאבים נמוכים מאוד מתרגמים בשליטה על משאבים WMT20', 'sk': 'Predložitev Adobe AMPS za prevajalsko opravilo nadzorovano z zelo nizkimi viri na WMT20', 'ha': '@ item Text character set', 'jv': "adobe AM's Submis kanggo extreme low Ressures super-Vised translation tasks at WW2C", 'bo': "Adobe AMPS's Submission for Very Low Resource Supervised Translation Task at WMT20"}
{'en': 'In this paper, we describe our systems submitted to the very low resource supervised translation task at WMT20. We participate in both translation directions for Upper Sorbian-German language pair. Our primary submission is a subword-level Transformer-based neural machine translation model trained on original training bitext. We also conduct several experiments with backtranslation using limited monolingual data in our post-submission work and include our results for the same. In one such experiment, we observe jumps of up to 2.6 BLEU points over the primary system by pretraining on a synthetic, backtranslated corpus followed by fine-tuning on the original parallel training data.', 'ar': 'في هذه الورقة ، نصف أنظمتنا المقدمة إلى مهمة الترجمة الخاضعة للإشراف منخفضة الموارد في WMT20. نشارك في كلا اتجاهي الترجمة للزوج اللغوي العلوي الصربي الألماني. تقديمنا الأساسي هو نموذج ترجمة آلية عصبية على مستوى الكلمات الفرعية يعتمد على المحولات ومدرب على نص تدريب أصلي. نجري أيضًا العديد من التجارب مع الترجمة العكسية باستخدام بيانات محدودة أحادية اللغة في عملنا بعد التقديم ونقوم بتضمين نتائجنا لنفسه. في إحدى هذه التجارب ، لاحظنا قفزات تصل إلى 2.6 نقطة BLEU فوق النظام الأساسي عن طريق التدريب المسبق على جسم تركيبي مترجم عكسيًا متبوعًا بضبط دقيق لبيانات التدريب الموازي الأصلية.', 'pt': 'Neste artigo, descrevemos nossos sistemas submetidos à tarefa de tradução supervisionada de recursos muito baixos no WMT20. Participamos em ambas as direções de tradução para o par de idiomas alto-sérvio-alemão. Nosso envio principal é um modelo de tradução automática neural baseado em Transformer em nível de subpalavra treinado em bitexto de treinamento original. Também realizamos vários experimentos com retrotradução usando dados monolíngues limitados em nosso trabalho pós-submissão e incluímos nossos resultados para o mesmo. Em um desses experimentos, observamos saltos de até 2,6 pontos BLEU sobre o sistema primário por pré-treinamento em um corpus sintético, retrotraduzido, seguido de ajuste fino nos dados de treinamento paralelo originais.', 'es': 'En este artículo, describimos nuestros sistemas sometidos a la tarea de traducción supervisada de muy pocos recursos en el WMT20. Participamos en ambas direcciones de traducción para el par de lenguas sorbo-alemán superior. Nuestro envío principal es un modelo de traducción automática neuronal basado en Transformer a nivel de subpalabra entrenado en bitexto de entrenamiento original. También realizamos varios experimentos con retrotraducción utilizando datos monolingües limitados en nuestro trabajo posterior al envío e incluimos nuestros resultados para el mismo. En uno de estos experimentos, observamos saltos de hasta 2.6 puntos BLEU sobre el sistema primario mediante el entrenamiento previo en un corpus sintético retrotraducido seguido de un ajuste fino de los datos de entrenamiento paralelos originales.', 'fr': "Dans cet article, nous décrivons nos systèmes soumis à la tâche de traduction supervisée à très faibles ressources du WMT20. Nous intervenons dans les deux directions de traduction pour le couple linguistique haut-sorabe-allemand. Notre soumission principale est un modèle de traduction automatique neuronale basé sur Transformer au niveau des sous-mots, formé sur un bitexte d'entraînement original. Nous menons également plusieurs expériences de rétrotraduction en utilisant des données monolingues limitées dans notre travail post-soumission et incluons nos résultats pour le même. Dans une de ces expériences, nous observons des sauts allant jusqu'à 2,6 points UEBL sur le système primaire par un pré-entraînement sur un corpus synthétique rétrotraduit, suivi d'un ajustement précis sur les données d'entraînement parallèles d'origine.", 'ja': '本稿では、WMT 20の非常に低いリソース監視翻訳タスクに提出されたシステムについて説明します。上部ソルブ語とドイツ語のペアの両方の翻訳方向に参加しています。当社の主な提出物は、オリジナルのトレーニングビットテキストでトレーニングされたサブワードレベルのTransformerベースのニューラルマシン翻訳モデルです。また、提出後の作業で限られたモノリンガルデータを使用したバックトランスレーションの実験をいくつか行い、その結果を含めています。そのような実験の１つでは、合成された逆並進コーパス上で事前に訓練を行い、続いて元の並列訓練データを微調整することによって、一次システム上で最大２ ． ６ Ｂｌｅｕポイントのジャンプを観察する。', 'zh': '本文中,述提交WMT20中资源非常低监译之统。 与上索布语-德语对二译。 凡我大要,基于子词级Transformer之神经机器翻译,教之于始双文本。 用有限者单语数反译实验而尽之。 实验此者,以翻译语料库为先,然后并行数调,以观其统之踊跃2.6 BLEU也。', 'ru': 'В этой статье мы описываем наши системы, представленные для очень низкой задачи под надзором ресурсов перевода на WMT20. Мы участвуем в обоих направлениях перевода для верхнесербско-немецкой языковой пары. Наше основное представление - это модель нейронного машинного перевода на основе подслова Transformer, обученная на оригинальном обучающем битексте. Мы также проводим несколько экспериментов с обратным переводом, используя ограниченные одноязычные данные в нашей работе после подачи заявки и включаем наши результаты для того же. В одном таком эксперименте мы наблюдаем скачки до 2,6 пунктов БЛЮ над первичной системой путем предварительной подготовки на синтетическом, обратно-переведенном корпусе с последующей точной настройкой на исходных параллельных данных обучения.', 'hi': 'इस पेपर में, हम WMT20 में बहुत कम संसाधन पर्यवेक्षित अनुवाद कार्य के लिए प्रस्तुत हमारे सिस्टम का वर्णन करते हैं। हम ऊपरी सोर्बियन-जर्मन भाषा जोड़ी के लिए दोनों अनुवाद दिशाओं में भाग लेते हैं। हमारा प्राथमिक सबमिशन एक सबवर्ड-स्तर ट्रांसफॉर्मर-आधारित तंत्रिका मशीन अनुवाद मॉडल है जो मूल प्रशिक्षण bitext पर प्रशिक्षित है। हम अपने पोस्ट-सबमिशन कार्य में सीमित मोनोलिंगुअल डेटा का उपयोग करके बैकट्रांसलेशन के साथ कई प्रयोग भी करते हैं और उसी के लिए हमारे परिणामों को शामिल करते हैं। इस तरह के एक प्रयोग में, हम मूल समानांतर प्रशिक्षण डेटा पर ठीक-ट्यूनिंग के बाद सिंथेटिक, बैकट्रान्स्टेड कॉर्पस पर प्रीट्रेनिंग करके प्राथमिक प्रणाली पर 2.6 BLEU बिंदुओं तक की छलांग का निरीक्षण करते हैं।', 'ga': 'Sa pháipéar seo, déanaimid cur síos ar ár gcórais a cuireadh isteach don tasc aistriúcháin faoi mhaoirseacht acmhainní an-íseal ag WMT20. Glacaimid páirt sa dá threo aistriúcháin don péire teanga Sorbais Uachtarach-Gearmáinis. Is é ár bpríomhaighneacht ná samhail aistriúcháin néarchóras atá bunaithe ar chlaochladán ar leibhéal fofhocail atá oilte ar bhun-ghiothéacs oiliúna. Déanaimid roinnt turgnamh freisin le haisaistriúchán ag baint úsáide as sonraí teoranta aonteangacha inár gcuid oibre iar-aighneachta agus áirímid ár dtorthaí maidir leo sin. I dturgnamh amháin den sórt sin, breathnaimid ar léimeanna suas le 2.6 pointe BLEU thar an gcóras príomhúil trí réamhoiliúint a dhéanamh ar chorpas sintéiseach, ais-aistrithe agus mionchoigeartú a dhéanamh ar na bunshonraí oiliúna comhthreomhara ina dhiaidh sin.', 'ka': 'ჩვენ ჩვენი სისტემები WMT20-ში მნიშვნელოვანი რესურსისთვის დავამწერებთ. ჩვენ ორივე გაგრძელებული სამუშაო სამუშაო სამუშაო-გერმანული სამუშაო ზოგში დავწევთ. ჩვენი პირველი შემდეგ იყო საბეჭდომა სიტყვების ტრანფორმაციის განსაგულებული ნეირალური მაქინის განსაგულებული მოდელი, რომელიც პირველური განსაგულებული ს ჩვენ ასევე ვიყავით რამდენიმე ექსპერიმენტები, რომელიც backtranslation გამოყენებული მონოლენგური მონაცემების გამოყენებაში ჩვენი პოსპესპესპეციის სამუშა ერთი ასეთი ექსპერიმენტიში, ჩვენ დავხედავთ 2,6 BLEU პირველ სისტემის წინასწორებაზე, რომლებიც სინტეტიკური, დაბრუნებული კორპუსს, რომლებიც კონფიგურაცია ორიველ პარალელური განაცემის', 'el': 'Σε αυτή την εργασία, περιγράφουμε τα συστήματά μας που υποβλήθηκαν στο έργο επίβλεψης πολύ χαμηλών πόρων στο WMT20. Συμμετέχουμε και στις δύο κατευθύνσεις μετάφρασης για το ζεύγος Ανώτερης Σορβίας-Γερμανικής γλώσσας. Η κύρια υποβολή μας είναι ένα μοντέλο νευρολογικής μηχανικής μετάφρασης σε επίπεδο υπολέξεων βασισμένο στον μετασχηματιστή, εκπαιδευμένο σε αρχικό εκπαιδευτικό bitext. Επίσης, διεξάγουμε αρκετά πειράματα με τη χρήση περιορισμένων μονογλωσσικών δεδομένων στη μετεκφραστική εργασία μας και συμπεριλαμβάνουμε τα αποτελέσματά μας για το ίδιο. Σε ένα τέτοιο πείραμα, παρατηρούμε άλματα μέχρι 2.6 σημείων πάνω από το αρχικό σύστημα με προεπιλογή σε ένα συνθετικό, μεταγλωττισμένο σώμα ακολουθούμενο από Feinabstimmung στα αρχικά δεδομένα παράλληλης προπόνησης.', 'hu': 'Ebben a tanulmányban ismertetjük a WMT20 rendszerének nagyon alacsony erőforrással felügyelt fordítási feladatának alávetett rendszereit. Mindkét fordítási irányban részt veszünk a Felső-Szorbia-Német nyelvpár számára. Az elsődleges benyújtásunk egy alszó szintű transzformátor alapú neurális gépi fordítási modell, amely eredeti képzési bitextre képzett. Több kísérletet is végezünk a visszafordítással, korlátozott egynyelvű adatok felhasználásával a benyújtást követő munkánkban, és ezzel kapcsolatos eredményeinket is feltüntetjük. Egy ilyen kísérletben akár 2,6 BLEU pontos ugrásokat figyelünk meg az elsődleges rendszeren, egy szintetikus, visszafordított korpusz előkészítésével, majd az eredeti párhuzamos edzési adatok finomhangolásával.', 'it': 'In questo articolo, descriviamo i nostri sistemi sottoposti al compito di traduzione supervisionata a bassissime risorse presso WMT20. Partecipiamo a entrambe le direzioni di traduzione per la coppia linguistica Alta Sorbiano-Tedesco. La nostra presentazione principale è un modello di traduzione automatica neurale basato su Transformer a livello subword addestrato su bitest di addestramento originale. Conduciamo anche diversi esperimenti con backtranslation utilizzando dati monolingue limitati nel nostro lavoro post-invio e includiamo i nostri risultati per lo stesso. In uno di questi esperimenti, osserviamo salti fino a 2,6 punti BLEU sul sistema primario pretraining su un corpus sintetico retrotradotto seguito da una messa a punto dei dati originali di allenamento parallelo.', 'mk': 'Во овој весник, ги опишуваме нашите системи поднесени на многу ниското ресурсно надгледувана преводна задача на WMT20. Ние учествуваме во двете насоки на превод за пар горен сорбиски-германски јазик. Нашата примарна поднесувачка е модел за превод на нервни машини со база на подзборови, трениран на оригинален тренинг. Ние, исто така, спроведуваме неколку експерименти со превод со ограничени монојазични податоци во нашата пост-пренесувачка работа и ги вклучуваме нашите резултати за истото. Во еден ваков експеримент, набљудуваме скоци од до 2,6 БЛЕУ поени над примарниот систем со претренирање на синтетичкиот, преведен корпус, по кој следи финетизирање на оригиналните паралелни податоци за тренинг.', 'lt': 'Šiame dokumente apibūdinamos mūsų sistemos, pateiktos labai mažai išteklių prižiūrimam vertimo darbui WMT20. Mes dalyvaujame abiejose vertimo gairėse aukščiausiosios sorbio ir vokiečių kalbų porai. Mūsų pirminis pristatymas yra subžodžio lygio Transformuotoju pagrįstas nervinės mašinos vertimo model is, parengtas pradiniame mokymo bitekste. Mes taip pat atliekame keletą eksperimentų su grįžtamuoju vertimu naudojant ribotus monokalbinius duomenis mūsų darbe po pateikimo ir įtraukiame savo rezultatus į tą patį. Viename tokiame eksperimente pastebime iki 2,6 BLEU taškų virš pirminės sistemos išankstinį mokymą naudojant sintetinį, atvirkščiai išverstą korpusą, po to tiksliai koreguojami pirminiai lygiagretaus mokymo duomenys.', 'kk': 'Бұл қағазда, біз жүйелерімізді WMT20- дегі аудармалы тапсырмасына көп ресурстар бақылайтын аудармалы тапсырмаға жіберілген. Жоғарғы сорб- неміс тілінің екі аудармалар бағыттарына қатынасыз. Біздің негізгі жіберіміз - негізгі оқыту мәтініне оқыту үшін негізгі сөз деңгейіндегі түрлендіруші негізгі неврал машинаның аудару үлгісі. Сонымен қатар бірнеше аудармалар арқылы бірнеше тәжірибелерді бірнеше тілік мәліметтерімізді көмектесіп, бірнеше тәжірибелерді бірдей тәжірибелерімізді Бұл тәжірибеде, негізгі жүйеңізде 2,6 BLEU нүктелеріне көтеріп, синтетикалық, backtranslated корпус арқылы, бастапқы параллель оқыту деректеріне тәртіпті баптауға келеді.', 'ms': 'Dalam kertas ini, kami menggambarkan sistem kami dihantar ke tugas terjemahan yang sangat rendah di WMT20. Kami berpartisipasi dalam kedua-dua arah terjemahan untuk pasangan bahasa Upper Sorbian-Jerman. Penghantaran utama kami ialah model penyerjemahan mesin saraf berasaskan subword-level Transformer yang dilatih pada bitext latihan asal. Kami juga melakukan beberapa eksperimen dengan terjemahan belakang menggunakan data monobahasa terbatas dalam kerja selepas penghantaran kami dan termasuk keputusan kami untuk perkara yang sama. Dalam satu percubaan seperti ini, kita mengamati lompatan hingga 2.6 titik BLEU di atas sistem utama dengan berlatih di atas korpus sintetik, terterjemahan belakang diikuti oleh penyesuaian baik pada data latihan paralel asal.', 'mt': 'F’dan id-dokument, aħna niddeskrivu s-sistemi tagħna ppreżentati għall-kompitu ta’ traduzzjoni taħt superviżjoni tar-riżorsi baxxi ħafna fid-WMT20. Aħna qed jipparteċipaw fiż-żewġ direzzjonijiet ta’ traduzzjoni għall-pari tal-lingwa Sorbika-Ġermaniża ta’ fuq. Is-sottomissjoni primarja tagħna hija mudell tat-traduzzjoni tal-magna newrali bbażata fuq it-Transformer ibbażat fuq livell ta’ subkliem imħarreġ fuq bitext tat-taħriġ oriġinali. Inwettqu wkoll diversi esperimenti b’backtranslation bl-użu ta’ dejta monolingwi limitata fil-ħidma tagħna ta’ wara s-sottomissjoni u ninkludu r-riżultati tagħna għall-istess. F’esperiment wieħed bħal dan, naraw qabżiet sa 2.6 punti BLEU fuq is-sistema primarja billi nħarrġu minn qabel fuq korpus sintetiku u tradott b’lura segwit minn rfinar fuq id-dejta oriġinali parallel a tat-taħriġ.', 'mn': 'Энэ цаасан дээр бид өөрсдийн системийг WMT20 дээрх маш бага боловсруулагдсан хөрөнгө оруулагдсан ажлыг тайлбарлаж байна. Бид хоёр дахь сорб-Германы хэл хоёр дахь орчуулалт руу холбоотой. Бидний анхны сургалтын хэмжээнд суурь хэмжээний түвшинд суурь хэмжээний түвшинд суурь хэмжээний мэдрэлийн дасгал хөрөнгө оруулах загвар юм. Бид мөн олон туршилтуудыг backtranslation-аар хийж, хязгаарлагдсан ганц хэл өгөгдлийг бидний дараа дамжуулах ажлын дараа хийж, бидний үр дүн нь адилхан байх болно. Нэг иймэрхүү туршилтанд бид анхны системийн 2.6 BLEU цэг дээр суулгаж, синтетик, backtranslated корпус дээр суулгаж, эхний параллел дасгал өгөгдлийн дээр сайхан түвшингийн тусламжтайгаар ажиглаж байлаа.', 'no': 'I denne papiret beskriver vi systemet våre som er sendt til den svært lave ressursoppgåva som er oversikt over omsetjinga på WMT20. Vi deltar i begge oversettelsesretningar for toppesorbisk- tysk språkspar. Vårt primær oppføring er ein underordnivå transformeringsmodell for neuralmaskinsomsetjing som treng på opprinnelege øvingspunkt. Vi gjer også fleire eksperimenter med tilbakeomsetjing med begrenset monospråk-data i vårt post-submiseringsarbeid og inkluderer våre resultat for det samme. I ein slik eksperiment observerer vi hopp opp til 2,6 BLEU-punkt over primærsystemet ved å trekke på eit syntetisk, tilgjengeleg korpus etter fin-tuning på den opprinnelige parallelle opplæringsdata.', 'pl': 'W niniejszym artykule opisujemy nasze systemy poddane bardzo niskiemu zadaniu nadzorowanemu tłumaczeniu w WMT20. Uczestniczymy w obu kierunkach tłumaczenia dla pary językowej górno-niemieckiej. Naszym głównym zgłoszeniem jest neuronowy model tłumaczenia maszynowego na poziomie podsłów oparty na Transformerze, przeszkolony na oryginalnym bitekscie treningowym. Przeprowadzamy również kilka eksperymentów z backtranslacją z wykorzystaniem ograniczonych danych jednojęzycznych w naszej pracy po zgłoszeniu i uwzględniamy nasze wyniki dla tego samego. W jednym z takich eksperymentów obserwujemy skoki do 2.6 punktów BLEU nad systemem podstawowym poprzez wstępne trening na syntetycznym, wstecznie przetłumaczonym korpusie, a następnie drobne dostrajanie oryginalnych danych treningowych równoległych.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d വിവരിക്കുന്നു, ഞങ്ങളുടെ സിസ്റ്റമുകള്\u200d WMT20-ല്\u200d ഏറ്റവും കുറഞ്ഞ വിഭവങ്ങള്\u200dക്ക് കീഴ്പെടുത്ത മുകളില്\u200d സോര്\u200dബിയന്\u200d -ജര്\u200dമ്മന്\u200d ഭാഷ ജോടികള്\u200dക്കുള്ള രണ്ട് പരിഭാഷത്തിന്\u200dറെ ദിശയങ്ങളില്\u200d ഞങ്ങള്\u200d പങ്കുച നമ്മുടെ പ്രധാനപ്രകാരം പരിശീലനത്തിന്റെ അടിസ്ഥാനമായി ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200d അടിസ്ഥാനമായി ന്യൂറല്\u200d പരിഭാഷ മോഡല്\u200d  നമ്മുടെ പോസ്റ്റ് അയയ്ക്കുന്ന ജോലിയില്\u200d നിര്\u200dണ്ണയിക്കുന്ന മണ്ണോലിഗ്ലാന്\u200dസ് ഡേറ്റാ ഉപയോഗിച്ച് ഞങ്ങള്\u200d പല ഒരു പരീക്ഷണത്തില്\u200d, പ്രധാന പരീക്ഷണത്തിന്\u200dറെ മേല്\u200d 2.6 ബിലിയു പോയിന്\u200dറുകളില്\u200d ചാടുന്നത് നാം കാണുന്നു. ഒരു സിന്തെറ്റിക്ക്, പിന്നീട് പരിശീലിക്കുന', 'ro': 'În această lucrare, descriem sistemele noastre supuse sarcinii de traducere supravegheate cu resurse foarte reduse la WMT20. Participăm la ambele direcții de traducere pentru perechea de limbi Sorbiană Superioară-Germană. Sublinierea noastră principală este un model de traducere automată neurală bazat pe un subcuvânt, instruit pe bitext de instruire originală. De asemenea, efectuăm mai multe experimente cu traducerea înapoi folosind date monolingve limitate în lucrările noastre post-depunere și includ rezultatele noastre pentru același lucru. Într-un astfel de experiment, observăm salturi de până la 2,6 puncte BLEU peste sistemul primar prin pregătirea unui corpus sintetic, tradus înapoi, urmat de reglarea fină a datelor originale de antrenament paralel.', 'sr': 'U ovom papiru opisujemo naše sisteme podignute na vrlo niski zadatak prevođenja resursa na WMT20-u. Mi sudjelujemo u obe upute za prevođenje za pare na gornjem sorbijskom i njemačkom jeziku. Naša primarna podnošenja je model prevođenja neuralnih mašina na podrečenoj nivou transformera koji je obučen na originalnom tekstu obuke. Također provodimo nekoliko eksperimenata sa backtranslation koristeći ograničene monojezičke podatke u našem posle podnošenja i uključujemo naše rezultate za isto. U jednom takvom eksperimentu, posmatramo skokove do 2,6 BLEU bodova na osnovni sistem, pretvarajući se na sintetički, potvrđeni korpus, praćeni ispravnim prilagođavanjem originalnih paralelnih podataka o obuci.', 'so': 'Qoraalkan waxaynu ku qornaa nidaamka ay u soo dhiibeen shaqada turjumista ee WMT20. Waxaynu ka qeybqaadannaa labada hagaha turjumidda ee labada luqada sare ee Sorbian-Jarmal. Madaxalkayaga ugu horeeya waa qoraal hoos-word-level Transformer-based neural translation model of machine tarjumaad oo lagu tababaray koob-ori waxbarasho. Sidoo kale waxaynu sameynaa imtixaamo badan oo ku qoran turjumidda dib-tarjumidda, sida loo isticmaalayo macluumaadka kooban ee qofka laga soo diro shaqadeeda la soo diro, waxaana ku qornaa arimahayaga isku mid ah. isku imtixaan oo kale, waxaynu fiirinaynaa barbaarrada ugu dhow 2.6 BLEU oo ku qoran nidaamka asalka ah, iyadoo lagu soo daabacay qoraalka kooxda ah oo la soo turjumay, waxaana soo daba soconayaa sawir ku saabsan macluumaadka waxbarashada rasmiga ah.', 'si': 'මේ පැත්තට, අපි අපේ පද්ධතිය විවෘත කරන්නේ WMT20 වලින් අඩුම සම්බන්ධ විවෘත වැඩක් විවෘත කරන්න. අපි උපර සෝර්බියාන්-ජර්මන් භාෂා ජෝමියාව සඳහා භාෂාවක් දෙන්නම් පාලනය කරනවා. අපේ ප්\u200dරධාන පණිවිඩය තමයි ප්\u200dරධාන පණිවිඩය සබ් වචන පණිවිඩය සඳහා පණිවිඩය සඳහා ප්\u200dරධාන පණිවිඩ අපි සමහරවිට පරීක්ෂණය සමග පරීක්ෂණය කරන්න පුළුවන් පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය ස ඒ වගේ පරීක්ෂණයෙන්, අපි බලන්නේ ප්\u200dරධාන පද්ධතියේ ප්\u200dරධාන පද්ධතියෙන් 2.6 බ්ලූස් ප්\u200dරතික්ෂණයෙන් ප්\u200dරතික්ෂණය කරන්න, බැක්ස් පද්ධත', 'sv': 'I denna uppsats beskriver vi våra system som genomgått den mycket låga resursövervakade översättningsuppgiften på WMT20. Vi deltar i båda översättningsriktningarna för övre sorbiska-tyska språkparet. Vår primära inlämning är en transformatorbaserad neural maskinöversättningsmodell som är utbildad på original träningsbitext. Vi genomför även flera experiment med backtranslation med begränsad enspråkig data i vårt efterinlämningsarbete och inkluderar våra resultat för samma. I ett sådant experiment observerar vi hopp på upp till 2,6 BLEU-punkter över primärsystemet genom att förbereda på en syntetisk, bakåtöversatt korpus följt av finjustering på original parallell träningsdata.', 'ta': 'இந்த காகிதத்தில், நாம் எங்கள் கணினிகளை விவரிக்கிறோம் WMT20-ல் மிகவும் குறைந்த மூலத்திற்கு கொடுக்கப்பட்ட மொ மேல் சோர்பியன்- ஜெர்மன் மொழி ஜோடி இருவருக்கும் மொழிபெயர்ப்பு திசைகளில் நாம் இரண்டு பகிர்ந்து க Our primary submission is a subword-level Transformer-based neural machine translation model trained on original training bitext.  நாம் பின்மொழிபெயர்ப்பில் வரம்பு மொழிமொழிபெயர்ப்பு தகவல்களை பயன்படுத்தி பல பரிசோதனைகளை செய்து அதே முடிவுகளை சேர் ஒரு போன்ற சோதனையில், நாம் முதல் முறைமையில் 2.6 பிலி புள்ளிகள் குறிப்புகளை பார்க்கிறோம். ஒரு கூட்டிணைப்பு, பின்பு மொழிபெயர்க்கப்பட்ட கோப்ப', 'ur': 'اس کاغذ میں، ہم نے اپنے سیستموں کو WMT20 میں زیادہ کم سراسر کے ذریعے تحویل کی ترجمہ کا تابع بنایا ہے۔ ہم سوربی-جرمانی زبان جوڑوں کے لئے دونوں ترجمہ طریقوں میں شریک ہوتے ہیں۔ ہماری اصلی تحویل ایک سوبرویڈ سطح تغییر دینے والی نیورل ماشین تغییر موڈل ہے جو اصلی ترسین بیٹکس پر آموزش کی جاتی ہے. ہم نے بہت سی آزمائش پچھلی ترجمہ کے مطابق محدودہ ایک زبان کے معاملات کے مطابق انجام دیں اور ہمارے نتائج اسی طرح شامل کریں۔ اس طرح کی آزمائش میں ہم نے 2.6 بلیوس پوینٹوں کو پہلی سیسٹم پر پہنچنے کے ذریعہ دیکھا ہے کہ ایک سینٹٹیسی، پچھلی ٹرینگ کورپوس پر پہنچنے کے ذریعہ ایک سائل ٹرینگ ڈیٹے پر پاکیزہ ٹرینگ کریں۔', 'uz': "Bu qogʻozda biz WMT20'da juda kam manba tarjima qiladigan tizimmizni anglatamiz. Biz Buyuqori Sorbiy-Olmon tilning ikkita tarjima yordamlariga murojaat qilamiz. Our primary submission is a subword-level Transformer-based neural machine translation model trained on original training bitext.  Biz bir necha tajriba qilamiz, bir necha tajriba bilan bir necha tajriba qilamiz, bizning posting joʻnatish vazifasini qo'yish uchun cheksiz munosabatlar maʼlumotimizni bajaramiz va bir xil natijalarimizni bir Bu tajribada biz bir necha tizimga 2.6 BLEU nuqta bo'lgan boshqalarni ko'rib turamiz, bir nechta tarjima qiladigan korpusni birinchi asl parallel taʼminlov maʼlumotida yaxshi ko'payapmiz.", 'vi': 'Trong tờ giấy này, chúng tôi mô tả hệ thống của chúng tôi được giao dịch dưới sự giám sát tài nguyên rất thấp ở WM20. Chúng tôi tham gia cả hai hướng dịch cho cặp ngôn ngữ Upper Sorbian-Đức. Việc đệ trình chính của chúng tôi là một mô hình Dịch biến hình nền nền chữ phụ, được đào tạo trên thực tập cắn bản gốc. Chúng tôi cũng tiến hành vài thí nghiệm với bản dịch ngầm, sử dụng các dữ liệu độc ngôn ngữ giới hạn trong công việc đăng ký sau đó, và bao gồm kết quả tương tự. Trong một thí nghiệm như vậy, chúng tôi quan sát những bước nhảy từ lên 2.6 LEU trên hệ thống chính bằng cách sử dụng trước một tập thể tổng hợp, dịch ngược, sau đó phải chỉnh lại dữ liệu huấn luyện song song song.', 'bg': 'В тази статия описваме нашите системи, подложени на задачата за превод с много нисък ресурс в WMT20. Участваме и в двете посоки за превод на горносорбийско-немски езикова двойка. Нашето основно представяне е трансформаторно базиран неврален машинен превод модел, обучен на оригинален тренировъчен биттекст. Също така провеждаме няколко експеримента с обратен превод, използвайки ограничени едноезични данни в нашата работа след подаване и включваме нашите резултати за същото. В един такъв експеримент наблюдаваме скокове от до 2,6 точки над основната система чрез предварително обучение върху синтетичен, обратно преведен корпус, последван от фина настройка на оригиналните паралелни данни за обучение.', 'hr': 'U ovom papiru opisujemo naše sustave podignute vrlo niskom zadatku za prevod nad nadzorom resursa na WMT20. Učestvujemo u oba smjera prevođenja za pare na gornjem sorbijskom i njemačkom jeziku. Naša primarna podnošenja je model prevoda neuralnih strojeva na podriječju razini transformera koji je obučen na originalnom ugrizu obuke. Također provodimo nekoliko eksperimenata sa backtranslation koristeći ograničene monojezičke podatke u našem poslije podnošenja i uključujemo naše rezultate za isto. U jednom takvom eksperimentu, posmatramo skokove do 2,6 BLEU bodova nad osnovnim sustavom, pretvarajući se na sintetički, potvrđeni korpus, slijedeći finalnim prilagođavanjem originalnih paralelnih podataka o obuci.', 'da': 'I denne artikel beskriver vi vores systemer, der er underlagt den meget lave ressourceovervågede oversættelsesopgave hos WMT20. Vi deltager i begge oversættelsesvejledninger for øversorbisk-tysk sprogpar. Vores primære indsendelse er en transformer-baseret neural maskinoversættelsesmodel trænet på original træningsbitekst. Vi udfører også flere eksperimenter med backtranslation ved hjælp af begrænsede ensprogede data i vores post-indsendelse arbejde og inkluderer vores resultater for det samme. I et sådant eksperiment observerer vi spring på op til 2,6 BLEU point over det primære system ved at forudtræne på et syntetisk, bagoversat korpus efterfulgt af finjustering på de oprindelige parallelle træningsdata.', 'nl': 'In dit artikel beschrijven we onze systemen die zijn onderworpen aan de zeer lage resource supervised vertaaltaak bij WMT20. We nemen deel aan beide vertaalrichtingen voor het Oppersorbisch-Duits taalpaar. Onze primaire inzending is een subword-level Transformer gebaseerd neural machine translation model getraind op originele trainingsbitext. We voeren ook verschillende experimenten uit met backtranslation met beperkte eentalige gegevens in ons post-indiening werk en nemen onze resultaten voor hetzelfde op. In een dergelijk experiment observeren we sprongen van maximaal 2.6 BLEU-punten over het primaire systeem door vooraf te trainen op een synthetisch, backtranslated corpus gevolgd door finetuning op de originele parallelle trainingsgegevens.', 'de': 'In diesem Beitrag beschreiben wir unsere Systeme, die bei WMT20 der sehr ressourcenarmen überwachten Übersetzungsaufgabe unterzogen werden. Wir beteiligen uns an beiden Übersetzungsrichtungen für das obersorbisch-deutsche Sprachpaar. Unsere primäre Einreichung ist ein Subword-Level Transformer-basiertes neuronales maschinelles Übersetzungsmodell, das auf originalem Trainingsbitext trainiert wurde. Wir führen auch mehrere Experimente mit Backtranslation durch, indem wir begrenzte monolinguale Daten in unsere Post-Submission-Arbeit verwenden und unsere Ergebnisse für dasselbe einbeziehen. In einem solchen Experiment beobachten wir Sprünge von bis zu 2,6 BLEU Punkten über das Primärsystem durch Vortraining auf einem synthetischen, rückübersetzten Korpus gefolgt von Feinabstimmung der ursprünglichen parallelen Trainingsdaten.', 'id': 'Dalam kertas ini, kami menggambarkan sistem kami yang dikirim ke tugas terjemahan yang sangat rendah sumber daya yang diawasi di WMT20. Kami berpartisipasi dalam kedua arah terjemahan untuk pasangan bahasa Upper Sorbian-Jerman. Pengiriman utama kami adalah model penerjemah mesin saraf berbasis subword-level Transformer yang dilatih pada bitext latihan asli. Kami juga melakukan beberapa eksperimen dengan terjemahan belakang menggunakan data monobahasa terbatas dalam pekerjaan setelah pengiriman kami dan termasuk hasil kami untuk hal yang sama. Dalam satu percobaan seperti itu, kami mengamati lompatan hingga 2,6 poin BLEU di atas sistem utama dengan berlatih di atas korpus sintetis, terterjemahan belakang diikuti dengan penyesuaian pada data latihan paralel asli.', 'fa': 'در این کاغذ، سیستم\u200cهایمان را توصیف می\u200cکنیم که به عملیات ترجمه\u200cهای زیادی در WMT20 تحویل داده شده است. ما در هر دو مسیر ترجمه برای جفت زبان سوربیان و آلمان شرکت می کنیم. تسلیم اولیه ما یک مدل ترجمه\u200cکننده\u200cی ماشین عصبی بر اساس سطح زیر کلمه\u200cها آموزش داده شده است. ما همچنین چند آزمایش را با ترجمه پشتیبانی با استفاده از داده های محدودیت یک زبان در کار بعد از تسلیم کردن ما انجام می دهیم و نتیجه های ما را برای همین تسلیم کنیم. در یک آزمایش چنین، ما می بینیم که بالا به ۲.۶ نقطه بلوپ روی سیستم اولیه از طریق تغییر روی یک کورپوس سینتاتیک، پشتیبانی ترجمه شده، سپس از تغییر داده های آموزش متناسب اصلی، از طریق تغییر داده شده است.', 'ko': '본고에서 우리는 우리가 WMT20에 제출한 극히 낮은 자원 감독 번역 임무를 가진 시스템을 묘사했다.우리는 상부 독일어 쌍의 두 번역 방향에 참여했다.우리가 주로 제출한 것은 하위 단어급 변환기를 바탕으로 하는 신경기계 번역 모델인데 이 모델은 원시 훈련을 바탕으로 두 텍스트를 훈련한다.제출한 후에 우리는 유한한 단어 데이터를 사용하여 몇 차례의 반역 실험을 실시했고 우리의 결과를 포함했다.이러한 실험에서 우리는 합성되고 반역된 어료 라이브러리에 대해 예비 훈련을 한 다음에 원시적인 병행 훈련 데이터를 미세하게 조정하여 초급 시스템에서 2.6개의 BLEU점에 이르는 점프를 관찰했다.', 'sw': 'Katika gazeti hili, tunaelezea mifumo yetu iliyotolewa kwa rasilimali ya chini inayofuatiliwa na kazi ya tafsiri katika WMT20. Tunashiriki katika maelekezo mawili ya tafsiri kwa ajili ya wawili wa lugha ya Upper Sorbian-Ujerumani. Our primary submission is a subword-level Transformer-based neural machine translation model trained on original training bitext.  Pia tunafanya majaribio kadhaa yenye kutafsiri kwa kutumia taarifa za lugha zisizo na kiwango cha kidini katika kazi zetu za baada ya ujumbe wetu na pia tunajumuisha matokeo yetu kwa hilo. Katika jaribio moja la aina hiyo, tunaangalia jump za hadi 2.6 BLEU juu ya mfumo wa msingi kwa kutengeneza viungo vya ufundi, vinavyotafsiriwa vizuri kufuatia taarifa za mafunzo ya awali.', 'tr': "Bu kagyzda, biz sistemamyzy WMT20'de iň az resurslar taýýarlanýan terjime täbligine tassykladyk. Biz serbçe-nemesçe dil çift üçin ikimiz terjime edip barýarys. Biziň ilkinji teslimaty subsöz derejesi terjime edip görkezilen näral maşynyň terjime nusgasy. Öňki okuwçysy üçin okuwçylýan. Biz hem arka terjime etmek bilen birnäçe deneyler çykarýarys we olaryň netijelerimizi hem bir şekilde çykarýarys. Böyle bir deneyde, biz başlangyç sisteme 2.6-a kadar BLEU noktalaryny syntetik, arka terjime edilen korpusa süýtgeden başlangyç parallel okuwçy maglumatlaryna süýtgeden atlamaklary görýäris.", 'sq': 'Në këtë letër, ne përshkruajmë sistemet tona të paraqitura në detyrën e përkthimit shumë të ulët të mbikqyrur nga burimet në WMT20. Ne marrim pjesë në të dy drejtimet e përkthimit për çiftin e gjuhës Upper Sorbian-Gjermane. Përdorimi ynë kryesor është një model i përkthimit të makinave nervore me bazë në nënfjalë, i stërvitur në ushtrimin origjinal. Ne gjithashtu kryejmë disa eksperimente me përkthime prapa duke përdorur të dhëna të kufizuara monogjuhësore në punën tonë pas paraqitjes dhe përfshijmë rezultatet tona për të njëjtën gjë. Në një eksperiment të tillë, ne vëzhgojmë kërcime deri në 2.6 pikë BLEU mbi sistemin kryesor duke parastërvitur mbi një korpus sintetik, të përkthyer mbrapa, pasuar nga rregullimi i të dhënave origjinale paralele të trainimit.', 'af': "In hierdie papier beskryf ons stelsels aan die baie lae hulpbron wat oorspronklik oorspronklike taak by WMT20 aangestuur is. Ons deel in beide vertaling rigtings vir Boonste Sorbiese-Duitse taal paar. Ons primêre onderwerp is 'n subwoord- vlak Transformer- gebaseerde neurale masjien vertaling model wat op oorspronklike onderwerp byteks ontvang is. Ons doen ook verskeie eksperimente met agtervertaling met gebruik van beperkte monolinglike data in ons post-onderskyning werk en insluit ons resultate vir dieselfde. In een sodanige eksperiment, ons observer jumps van up to 2.6 BLEU punte oor die primêre stelsel deur voorskou op 'n sintetiese, terugvertrekde korpus gevolg deur fyn-tuning op die oorspronklike parallele onderwerking data.", 'am': 'በዚህ ፕሮግራም፣ ድምጾችን በWMT20 ላይ ወደሚገልጸው ትርጉም አድራሻ የተዘጋጁትን እናሳውቃለን፡፡ በሁለቱ ትርጉም መንገድ ላይ ሶርባዊ-ጀርመን ቋንቋ ሁለትን እናጋራለን፡፡ የፊደል መልዕክታችን መጀመሪያ የደብዳቤ-ደረጃ ተቃውሞ የተመሳሳይ የነዌብ ትርጉም ሞዴል ነው፡፡ በኋላ ትርጓሜ እናደርጋለን፡፡ በአንድ ተፈተና፣ በመጀመሪያው ስርዓት ላይ የ2.6 ቢሌU ጥያቄዎችን በመስመር ላይ በመዘርጋት፣ በተመለከተው የኮርፓስ ጥያቄ በመጀመሪያው ተማሪ ዳታዎችን በመጠቀም በመጠቀም እናደርጋለን፡፡', 'hy': "Այս թղթի մեջ մենք նկարագրում ենք մեր համակարգերը, որոնք ներկայացվել են շատ ցածր ռեսուրսների վերահսկվող թարգմանման խնդիրներին ՀՄԹ20-ում: Մենք մասնակցում ենք բարձր սորբյան-գերմանացի լեզվի զույգի երկու թարգմանման ուղղություններում: Մեր հիմնական ներկայացումը ենթաբառի մակարդակի տրանֆերմերների հիմնված նյարդային մեքենայի թարգմանման մոդելն է, որը պատրաստված է սկզբնական վարժեցման փորձի վրա: We also conduct several experiments with backtranslation using limited monolingual data in our post-submission work and include our results for the same.  Այսպիսի փորձարկումների ընթացքում մենք դիտում ենք սկզբնական համակարգի վրա մինչև 2.6 բլեւ կետի թռիչքներ' նախապատրաստվելով սինթետիկ, վերադարձված կորպուսի վրա, հետո նախապատրաստվելով սկզբնական զուգահեռ ուսումնասիրության տվյալների", 'az': "Bu kağızda, WMT20'deki çox düşük kaynaqlar tərzində təkrar edilmiş sistemlərimizi təsdiqləyirik. Biz hər ikimizin üst Sorbi-Alman dil çift üçün tərcümə yollarına katılırıq. Bizim ilk təklifimiz ilk sözlərlə transformer-tabanlı nöral maşın çevirim modeli, təklifimiz təklifimizdə təhsil edilmişdir. Biz həmçin in bir neçə təkrarlama təkrarlama ilə müəyyən edilmiş monodil məlumatlarını istifadə etdik və sonuçlarımızı da aynı şekilde daxil edirik. Bütün bu təcrübələrdə, ilk sistemin üstündə 2.6 BLEU nöqtələrini sintetik, arxa çevirilmiş korpus ilə başlangıç paralel təcrübə məlumatının üstündə düzəltməsini gözləyirik.", 'bn': 'এই কাগজটিতে আমরা আমাদের সিস্টেম ব্যাখ্যা করছি যা উইএমটি২০-এ অনুবাদের পর্যবেক্ষণ করা অনুবাদ করা হয়েছে। We participate in both translation directions for Upper Sorbian-German language pair.  আমাদের প্রাথমিক প্রশিক্ষণের ক্ষেত্রে প্রশিক্ষণ প্রদান করা একটি সাবওয়ার্ড-স্তরের ট্রান্সফারের ভিত্তিক নিউরে এছাড়াও আমরা ব্যাক-ট্রান্সটার্নেশনের সাথে বিভিন্ন পরীক্ষা করি আমাদের পোস্ট-পোস্ট করার কাজে সীমিত মোনোলিভা এই ধরনের এক পরীক্ষায় আমরা প্রাথমিক বিভিন্ন ব্যবস্থার উপর লাফ দিয়ে দেখছি একটি সিন্টেটিক, পিছনে অনুবাদ কর্পাসের মূল প্রশিক্ষণের তথ্যে ভালোভাবে বৃষ্টি', 'bs': 'U ovom papiru opisujemo naše sisteme podignute na vrlo niski zadatak prevoda nad nadzorom resursa na WMT20. Mi učestvujemo u oba smjera prevođenja za pare na gornjem sorbijskom i njemačkom jeziku. Naša primarna podnošenja je model prevoda neuralnih strojeva na podriječju nivou transformera koji je obučen na originalnom ugrizu obuke. Također provodimo nekoliko eksperimenata sa backtranslation koristeći ograničene monojezičke podatke u našem posle podnošenja i uključujemo naše rezultate za isto. U jednom takvom eksperimentu, posmatramo skokove do 2,6 BLEU bodova nad osnovnim sustavom, pretvarajući se na sintetički, potvrđeni korpus, slijedeći finalnim prilagođavanjem originalnih paralelnih podataka o obuci.', 'cs': 'V tomto článku popisujeme naše systémy, které byly předloženy pro velmi nízké zdroje kontrolované překlady ve WMT20. Podílíme se na obou směrech překladu pro hornosorbština-německý jazykový pár. Naším primárním předložením je model neuronového strojového překladu na úrovni podslov, který je založen na transformátoru vycvičeném na původním tréninkovém bitextu. Také provádíme několik experimentů s backtranslací s využitím omezených jednojjazyčných dat v naší post-submission práci a zahrnujeme naše výsledky pro stejné. V jednom z takových experimentů pozorujeme skoky až 2,6 BLEU bodů nad primárním systémem předtrénováním na syntetickém, zpětně přeloženém korpusu a následným doladěním původních paralelních tréninkových dat.', 'ca': "En aquest paper, descrivim els nostres sistemes submetits a la tasca de traducció supervisada amb baix recursos a WMT20. Participem en les dues direccions de traducció del parell de llenguatge sorbiano-alemany superior. La nostra subministració primària és un model de traducció neuromàquina basat en Transformer de nivell subparaula, entrenat en bitext d'entrenament original. També fem varis experiments amb traducció inversa utilitzant dades monolingües limitades en la nostra feina de després de la presentació i inclouem els nostres resultats del mateix. En un d'aquests experiments observem salts de fins a 2,6 punts BLEU sobre el sistema primàri pré-treinant en un cos sintètic i traduit inversament seguit d'ajustes a les dades d'entrenament parallels originals.", 'et': 'Käesolevas töös kirjeldame meie süsteeme, mis on allutatud väga madala ressursi järelevalvega tõlke ülesandele WMT20. Osaleme Ülem-Sorbia keele paari mõlemas tõlkesuunas. Meie esmane esitus on alamsõna tasemel Transformer-põhine neuraalne masintõlke mudel, mis on koolitatud originaalse treeningu biteksti põhjal. Samuti teostame mitmeid tagasitõlkimise katseid, kasutades piiratud ühekeelseid andmeid oma esitamisjärgses töös ja lisame oma tulemused sama kohta. Ühes sellises eksperimendis jälgime kuni 2,6 BLEU punkti hüppeid üle esmase süsteemi, treenides sünteetilisel, tagasitõlgitud korpusel, millele järgneb peenhäälestus originaalsetel paralleelsetel treeninguandmetel.', 'fi': 'T채ss채 artikkelissa kuvailemme j채rjestelmi채mme, jotka ovat joutuneet WMT20:n eritt채in v채h채n resursseja valvottuun k채채nn철st철철n. Osallistumme yl채sorbian ja saksan kieliparin molempiin k채채nn철ssuhteisiin. Ensisijainen julkaisumme on alasanatason Transformer-pohjainen neurokonek채채nn철smalli, joka on koulutettu alkuper채iseen harjoittelubitekstiin. Teemme my철s useita backtranslation-kokeiluja k채ytt채en rajallista yksikielist채 tietoa toimituksen j채lkeisess채 ty철ss채 ja sis채llyt채mme tulokset samasta. Yhdess채 t채llaisessa kokeessa havainnoimme jopa 2,6 BLEU-pisteen hyppyj채 perusj채rjestelm채n yli harjoittelemalla synteettisell채, takaisink채채nnetyll채 korpusella ja hienos채채t채m채ll채 alkuper채isi채 rinnakkaisharjoitustietoja.', 'he': 'בעיתון הזה, אנחנו מתארים את המערכות שלנו שנשלחו למשימת התרגום הנמוכה ביותר על משאבי המשאבים במשרד WMT20. אנחנו משתתפים בשני הכיוונים של זוג שפה סורבית-גרמנית העליונה. ההצגה העיקרית שלנו היא דוגמא התרגום של מכונת עצבית מבוססת על רמה תת-מילים מאומנת על ביטקסט אימון מקורי. אנחנו גם מבצעים מספר ניסויים עם התרגום האחורי בשימוש נתונים מונושפות מוגבלות בעבודה שלאחר ההעברה שלנו וכלולים את התוצאות שלנו באותו הדבר. בניסוי אחד כזה, אנו רואים קפיצות של עד 2.6 נקודות BLEU מעל המערכת העיקרית על ידי אימון מראש על קורפוס סינטטי ומתורגם אחורה ואחרי כן על ידי התאים על נתוני האימון המקוריים המזוריים.', 'jv': 'Nang paper iki, kita rambaran sistem anyar biasane supoyata ning titik-titik nyebuturan kanggo kelas supoyatan kanggo tarjamahan ning WB2Name Awak dhéwé énjaraké akèh tarjamahan kanggo nyelaraké Perancis-Perancis kuwi duluran. Awak dhéwé nggunaké tualke kuwi sawar-kuwi, Transformer kuwi basa gambar, kuwi model kuwi nggunaké perintal maneh. textattr Awak dhéwé éntuk nglebok karo permaneh sing nggawe tarjamahan karo permaneh ingkang dadi, ingkang sampek kapan ingkang mulai nggawe barang dhéwé. Nang sampeyan paran sing dumadhi, kita ngulinakake supong tanggal 2.6', 'sk': 'V tem prispevku opisujemo naše sisteme, ki so bili predmet prevajanja z zelo nizkimi viri v WMT20. Sodelujemo v obeh smereh prevajanja za zgornjo sorbijsko-nemški jezikovni par. Naša glavna predložitev je transformatorski model nevronskega strojnega prevajanja na ravni podbesed, usposobljen na izvirnem treningu bitexta. Prav tako izvajamo več eksperimentov z nazaj prevajanjem z omejenimi enojezičnimi podatki v našem delu po oddaji in vključimo naše rezultate za isto. V enem takšnem eksperimentu opazujemo skoke do 2,6 točke BLEU nad primarnim sistemom s predtreningom na sintetičnem, nazaj prevedenem korpusu, ki mu sledi natančno nastavitev prvotnih podatkov o vzporednem treningu.', 'ha': "In this paper, we describe our systems submitted to the very low resource supervised translation task at WMT20.  Tuna sami da shiryarwa biyu na fassarar wa sauran-Jarman. @ action: button Kayya, muna sami wasu jarrabo da baktranslation, da kuma ana yi amfani da data masu tsari na monoli cikin aikin bayan-sender kuma munã shigar da matsalanmu da shi daidai. Daga wani jarrabo daga wannan, Munã ganin jumko ko 2.6 BLEU points a kan system na ƙarami da za'a yi izgili a sami-na'ura, da kuma a baka-tarjiwa korpoon ta sami da tuntuntun a kan data na zaman shawarar da aka yi parallel.", 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་རྒྱབ་སྐྱོར་མེད་པའི་ལག་ཁྱེར་ཚོའི་ནང་དུ་WMT20 ལ་མཐོང་ནུས་དུ་རྒྱུ་དངོས་ཡིན་པ་ལ ང་ཚོས་རྒྱལ་ཁབ་གཉིས་ཀྱི་སྐད་ཡིག་གཟུགས་གཅིག་ལས་དབུགས་གནང་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་རྩ་བའི་མཉམ་དུ་འཇུག་འདོགས་ནི་གནད་གཟུགས་རིས་ལྕགས་ཅན་གྱིས་གཞི་བཞག ང་ཚོས་རྒྱབ་སྐྱོར་ལྗོངས་ཀྱི་ཆ་འཕྲིན་ཡིག In one such experiment, we observe jumps of up to 2.6 BLEU points over the primary system by pretraining on a synthetic, backtranslated corpus followed by fine-tuning on the original parallel training data.'}
{'en': 'Human-Paraphrased References Improve Neural Machine Translation', 'ar': 'تعمل المراجع المعاد صياغتها على تحسين الترجمة الآلية العصبية', 'es': 'Las referencias parafraseadas por humanos mejoran la traducción automática neuronal', 'fr': "Les références paraphrasées par l'homme améliorent la traduction automatique neuronale", 'pt': 'Referências parafraseadas por humanos melhoram a tradução automática neural', 'ja': '人間が言い換えた参照は、神経機械翻訳を向上させる', 'zh': '人工释义者参考文献改入神经机器翻译', 'hi': 'मानव-व्याख्यात्मक संदर्भ न्यूरल मशीन अनुवाद में सुधार', 'ru': 'Человеко-парафинированные ссылки улучшают нейронный машинный перевод', 'ga': 'Tagairtí Daonna-Pharóiste Feabhsaítear Aistriú Meaisín Néarach', 'ka': 'ადამიანის პარაფრაზესების რეფერენციების შემდეგ ნეიროლური მაქინის გადატყვება', 'hu': 'Az emberi parafrázisú referenciák javítják a neurális gépi fordítást', 'el': 'Οι παραπομπές από άνθρωπο βελτιώνουν τη νευρωνική μηχανική μετάφραση', 'kk': 'Адам парафразы сілтемелері нейрондық машинаның аудармасын жақсарту', 'it': 'Riferimenti umani parafrasi migliorano la traduzione automatica neurale', 'lt': 'Žmogaus parafrazėmis nurodytos nuorodos gerina nervinių mašinų vertimą', 'mk': 'Човечки парафразирани референции подобруваат преведување на невралните машини', 'ml': 'മനുഷ്യന്\u200d - പാരാപ്പരേഷന്\u200d നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുക', 'ms': 'Human-Paraphrased References Improve Neural Machine Translation', 'mt': 'Human-Paraphrased References Improve Neural Machine Translation', 'mn': 'Хүн-парафраз хэлбэрүүдийн санаа сэтгэл мэдрэлийн машин хөгжүүлэх', 'sr': 'Ljudski parafrazirani referenci poboljšavaju neuronski prevod mašine', 'si': 'මිනිස්සු-පැරැෆ්\u200dරේස් සංවේදනය සුදුසුම් කරන්න', 'pl': 'Odniesienia parafrazowane przez człowieka poprawiają neuronowe tłumaczenie maszynowe', 'so': 'References Improve Neural machine Translation', 'sv': 'Referenser med mänskliga parafraser Förbättra neural maskinöversättning', 'ta': 'மனிதன்- அளப்ராசெட்ட குறிப்புகள் நெயுரல் இயந்திரம் மொழிபெயர்ப்பை மேம்படுத்து', 'ro': 'Referințe parafrazate umane îmbunătățesc traducerea automată neurală', 'ur': 'انسان-پارافریزڈ ریفرنس نیورال ماشین کی ترجمہ اضافہ کرتی ہے', 'no': 'Menneskapparafraserte referanser forbedra neuralmaskinsomsetjing', 'uz': 'Name', 'vi': 'KCharselect unicode block name', 'bg': 'Човешко-парафразираните препратки подобряват невралния машинен превод', 'hr': 'Ljudski parafrazirani referenci poboljšavaju neuronski prevod strojeva', 'da': 'Menneskelige parafraserede referencer forbedrer neural maskinoversættelse', 'nl': 'Human-Parafrased Referenties Verbeteren Neurale Machine Translation', 'de': 'Human-Paraphrasierte Referenzen verbessern neuronale maschinelle Übersetzung', 'id': 'Referensi Parafrasa Manusia meningkatkan Translation Mesin Neural', 'fa': 'تعریف\u200cهای پارافریز انسان به ترجمه ماشین عصبی', 'sw': 'Maoni yanayotolewa na binadamu yanaboresha Tafsiri ya Mashine ya Kifaransa', 'tr': 'İnsan-Paraphrazça Referanslar Neural Makina terjimesini geliştir', 'af': 'Mens- Parafraseerde Verwysings Verbeter Neurale Masjien Vertaling', 'sq': 'Human-Paraphrased References Improve Neural Machine Translation', 'am': 'ምርጫዎች', 'hy': 'Մարդկային պարաֆրազիայի վերաբերյալները բարելավում են նյարդային մեքենայի թարգմանությունը', 'az': 'İnsan-Parafrazlı Referanslar Nöral Makina Çeviri', 'bn': 'Human-Paraphrased References Improve Neural Machine Translation', 'bs': 'Ljudski parafrazirani referenci poboljšavaju neuronski prevod strojeva', 'ca': 'Les referències parafrasitzades per humans milloren la traducció de la màquina neuronal', 'et': 'Inimese parafraseeritud viited parandavad neuroaalset masintõlket', 'ko': '인공 해석 참고 문헌 개선 신경 기계 번역', 'cs': 'Člověk-parafrázované reference zlepšují neuronový strojový překlad', 'fi': 'Ihmisen parafrasoidut viittaukset parantavat hermojen konekäännöstä', 'ha': 'KCharselect unicode block name', 'he': 'התייחסות בני אדם משפר את התרגום של מכונות נוירות', 'jv': 'Refs', 'sk': 'Človeško-parafrazirane reference izboljšajo strojno prevajanje nevronov', 'bo': 'Human-Paraphrased References Improved Neural Machine Translation'}
{'en': 'Automatic evaluation comparing candidate translations to human-generated paraphrases of reference translations has recently been proposed by freitag2020bleu. When used in place of original references, the paraphrased versions produce metric scores that correlate better with human judgment. This effect holds for a variety of different automatic metrics, and tends to favor natural formulations over more literal (translationese) ones. In this paper we compare the results of performing end-to-end system development using standard and paraphrased references. With state-of-the-art English-German NMT components, we show that tuning to paraphrased references produces a system that is ignificantly better according to human judgment, but 5 BLEU points worse when tested on standard references. Our work confirms the finding that paraphrased references yield metric scores that correlate better with human judgment, and demonstrates for the first time that using these scores for system development can lead to significant improvements.', 'ar': 'تم اقتراح التقييم التلقائي الذي يقارن الترجمات المرشحة بإعادة صياغة الترجمة المرجعية من قبل الإنسان مؤخرًا بواسطة freitag2020bleu. عند استخدامها بدلاً من المراجع الأصلية ، تنتج النسخ المعاد صياغتها درجات مترية ترتبط بشكل أفضل بالحكم البشري. ينطبق هذا التأثير على مجموعة متنوعة من المقاييس التلقائية المختلفة ، ويميل إلى تفضيل الصيغ الطبيعية على الصيغ الحرفية (المترجمة). في هذا البحث ، قمنا بمقارنة نتائج إجراء تطوير شامل للنظام باستخدام المراجع المعيارية والمعاد صياغتها. مع أحدث مكونات NMT الإنجليزية-الألمانية ، نظهر أن الضبط على المراجع المعاد صياغتها ينتج نظامًا أفضل بشكل ملحوظ وفقًا للحكم البشري ، ولكن 5 نقاط BLEU أسوأ عند اختبارها على المراجع القياسية. يؤكد عملنا النتيجة التي توصلت إليها أن المراجع المعاد صياغتها تسفر عن درجات مترية ترتبط بشكل أفضل بالحكم البشري ، ويوضح لأول مرة أن استخدام هذه الدرجات لتطوير النظام يمكن أن يؤدي إلى تحسينات كبيرة.', 'pt': 'A avaliação automática comparando traduções candidatas a paráfrases geradas por humanos de traduções de referência foi recentemente proposta por freitag2020bleu. Quando usadas no lugar de referências originais, as versões parafraseadas produzem pontuações métricas que se correlacionam melhor com o julgamento humano. Esse efeito vale para uma variedade de métricas automáticas diferentes e tende a favorecer formulações naturais sobre as mais literais (traduzidas). Neste artigo, comparamos os resultados da execução do desenvolvimento de sistemas de ponta a ponta usando referências padrão e parafraseadas. Com componentes NMT inglês-alemão de última geração, mostramos que o ajuste de referências parafraseadas produz um sistema que é significativamente melhor de acordo com o julgamento humano, mas 5 pontos BLEU pior quando testado em referências padrão. Nosso trabalho confirma a descoberta de que as referências parafraseadas produzem pontuações métricas que se correlacionam melhor com o julgamento humano e demonstra pela primeira vez que o uso dessas pontuações para o desenvolvimento de sistemas pode levar a melhorias significativas.', 'es': 'Freitag2020bleu ha propuesto recientemente una evaluación automática que compara traducciones candidatas con paráfrasis de traducciones de referencia generadas por humanos. Cuando se utilizan en lugar de las referencias originales, las versiones parafraseadas producen puntuaciones métricas que se correlacionan mejor con el juicio humano. Este efecto se aplica a una variedad de métricas automáticas diferentes y tiende a favorecer las formulaciones naturales sobre las más literales (traducibles). En este artículo comparamos los resultados de realizar el desarrollo de sistemas de principio a fin utilizando referencias estándar y parafraseadas. Con componentes NMT inglés-alemán de última generación, demostramos que el ajuste a referencias parafraseadas produce un sistema que es significativamente mejor según el juicio humano, pero 5 puntos BLEU peor cuando se prueba en referencias estándar. Nuestro trabajo confirma el hallazgo de que las referencias parafraseadas producen puntuaciones métricas que se correlacionan mejor con el juicio humano, y demuestra por primera vez que el uso de estas puntuaciones para el desarrollo del sistema puede conducir a mejoras significativas.', 'fr': "Une évaluation automatique comparant les traductions candidates aux paraphrases générées par l'homme de traductions de référence a récemment été proposée par freitag2020bleu. Lorsqu'elles sont utilisées à la place des références originales, les versions paraphrasées produisent des scores métriques qui sont mieux corrélés avec le jugement humain. Cet effet est valable pour une variété de mesures automatiques différentes et tend à favoriser les formulations naturelles par rapport aux formulations plus littérales (traduites). Dans cet article, nous comparons les résultats du développement de systèmes de bout en bout à l'aide de références standard et paraphrasées. Avec des composants NMT anglais-allemand de pointe, nous montrons que le réglage sur des références paraphrasées produit un système nettement meilleur selon le jugement humain, mais moins de 5 points BLEU lorsqu'il est testé sur des références standard. Nos travaux confirment la conclusion selon laquelle les références paraphrasées produisent des scores métriques qui sont mieux corrélés avec le jugement humain, et démontrent pour la première fois que l'utilisation de ces scores pour le développement de systèmes peut conduire à des améliorations significatives.", 'ja': '候補の翻訳を人間が生成した参照翻訳のパラフレーズと比較する自動評価は、freitag 2020bleuによって最近提案されています。 元の参照の代わりに使用される場合、パラフレーズされたバージョンは、人間の判断とより良く相関する指標スコアを生成します。 この効果は、さまざまな自動指標に適用され、より文字通りの（翻訳された）指標よりも自然な指標を優先する傾向があります。 本稿では，エンドツーエンドのシステム開発を行った結果を，標準的な文献と言い換えた文献を用いて比較する． 最先端の英語-ドイツ語NMTコンポーネントを使用すると、パラフレーズ化された参照へのチューニングは、人間の判断によれば無視できるほど優れたシステムを生み出すことが示されますが、標準的な参照でテストした場合、5 BLEUポイントが悪化します。 私たちの研究は、言い換えられた参照が、人間の判断とより良く相関する指標スコアをもたらすという調査結果を確認し、これらのスコアをシステム開発に使用することが大幅な改善につながることを初めて実証します。', 'zh': 'freitag2020bleu近议将候选翻译与人工生成者参校释义自校。 当用代始引时,释义版本生指标分数。 宜用于自指标,而向于自然公式非直白(译)之公式也。 于本文中,较用格释义参行端到端系统开发。 以至先进之英语 - 德语NMT组件,以人类之断,调释义之参考文献,生一微之统,试之于参考文献,统差5 BLEU分。 臣等证之,即转述参考文献所生指标分与人相关性更善,首证其分数于统发可见者改进。', 'hi': 'संदर्भ अनुवाद के मानव-जनित पैराफ्रेसेस के लिए उम्मीदवार अनुवादों की तुलना करने वाले स्वचालित मूल्यांकन को हाल ही में freitag2020bleu द्वारा प्रस्तावित किया गया है। जब मूल संदर्भों के स्थान पर उपयोग किया जाता है, तो संक्षिप्त संस्करण मीट्रिक स्कोर का उत्पादन करते हैं जो मानव निर्णय के साथ बेहतर सहसंबंधित होते हैं। यह प्रभाव विभिन्न स्वचालित मीट्रिक की एक किस्म के लिए रखता है, और अधिक शाब्दिक (अनुवादी) वाले लोगों पर प्राकृतिक योगों का पक्ष लेता है। इस पेपर में हम मानक और संक्षिप्त संदर्भों का उपयोग करके एंड-टू-एंड सिस्टम विकास करने के परिणामों की तुलना करते हैं। अत्याधुनिक अंग्रेजी-जर्मन एनएमटी घटकों के साथ, हम दिखाते हैं कि व्याख्या किए गए संदर्भों के लिए ट्यूनिंग एक ऐसी प्रणाली का उत्पादन करती है जो मानव निर्णय के अनुसार स्पष्ट रूप से बेहतर है, लेकिन मानक संदर्भों पर परीक्षण किए जाने पर 5 BLEU अंक बदतर हैं। हमारा काम इस खोज की पुष्टि करता है कि संक्षिप्त संदर्भ मीट्रिक स्कोर उत्पन्न करते हैं जो मानव निर्णय के साथ बेहतर सहसंबंध रखते हैं, और पहली बार प्रदर्शित करते हैं कि सिस्टम विकास के लिए इन स्कोर का उपयोग करने से महत्वपूर्ण सुधार हो सकते हैं।', 'ru': 'Недавно freitag2020bleu предложил автоматическую оценку, сравнивающую переводы-кандидаты с созданными человеком парафразами эталонных переводов. При использовании вместо исходных ссылок перефразированные версии дают метрические баллы, которые лучше коррелируют с человеческим суждением. Этот эффект сохраняется для различных автоматических метрик и имеет тенденцию отдавать предпочтение натуральным формулировкам по сравнению с более буквальными (переводческими). В этой статье мы сравниваем результаты выполнения сквозной разработки системы с использованием стандартных и перефразированных ссылок. С современными английско-немецкими компонентами NMT мы показываем, что настройка на перефразированные ссылки производит систему, которая незначительно лучше в соответствии с человеческим суждением, но на 5 пунктов хуже при тестировании на стандартных ссылках. Наша работа подтверждает вывод о том, что перефразированные ссылки дают метрические баллы, которые лучше коррелируют с человеческим суждением, и впервые демонстрирует, что использование этих баллов для разработки системы может привести к значительным улучшениям.', 'ga': 'Mhol freitag2020bleu le déanaí meastóireacht uathoibríoch a dhéanann comparáid idir aistriúcháin iarrthóra agus athróga arna nginiúint ag an duine d’aistriúcháin tagartha. Nuair a úsáidtear iad in ionad na dtagairtí bunaidh, táirgeann na leaganacha athfhrása scóir mhéadracha a bhfuil comhghaolú níos fearr acu le breithiúnas an duine. Seasann an éifeacht seo d’éagsúlacht méadrachtaí uathoibríocha éagsúla, agus bíonn claonadh i bhfabhar foirmlithe nádúrtha seachas foirmlithe níos litriúla (aistriúcháin). Sa pháipéar seo déanaimid comparáid idir na torthaí a bhaineann le forbairt córas ceann go ceann a dhéanamh agus úsáid á baint as tagairtí caighdeánacha agus athfhrása. Le comhpháirteanna nua-aimseartha NMT Béarla-Gearmáinis, léirímid go dtáirgeann tiúnadh ar thagairtí athfhrása córas atá i bhfad níos fearr de réir breithiúnas an duine, ach 5 phointe BLEU níos measa nuair a dhéantar tástáil orthu ar thagairtí caighdeánacha. Deimhníonn ár gcuid oibre an toradh go n-éiríonn le tagairtí athfhrása scóir mhéadracha a chomhghaolann níos fearr le breithiúnas an duine, agus léiríonn sé don chéad uair go bhféadfadh feabhsuithe suntasacha teacht as na scóir seo chun córais a fhorbairt.', 'ka': 'ადამიანის შექმნილი პარაფრაზებისთვის ავტომატური განსაზღვრება, რომელიც კანდიდენტების განსაზღვრებას შემდეგ განსაზღვრებული ფრაფრაზებისთვის განსაზღვრება ახლა როდესაც გამოყენებულია ორიგინალური რეფერენციების საცვლად, პარაფრაზაციული ვერსიები მეტრიკური წარმოდგენება, რომელიც ადამიანის წარმოდგენებით უფრო ეს ეფექტი არსებობს განსხვავებული ავტომატიკური მეტრიკის განსხვავებას, და უფრო ლეტრალიტური (ტრანლაციონული) განსხვავებულია. ამ დომენტში ჩვენ სტანდარტული და პარაფრაზული რეფერენციების გამოყენებით სტანდარტული სისტემის განვითარებას შემდეგ შემდეგ შემდეგ შემდეგ შემდეგ. ანგლისური-გერმანური NMT კომპონენტებით, ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ პარაფრესური რეფერენციების შესახებ სისტემა, რომელიც ადამიანის წინასწორედ უკეთესია, მაგრამ 5 BLEU უკეთესია, როდესაც ს ჩვენი სამუშაო დარწმუნდება, რომ პარაფრაზესი რეფერეციები მიიღება მეტრიკური წარმოდგენები, რომელიც უფრო უფრო კარგად ადამიანის წარმოდგენისთვის, და პირველად მოდენსტრაცია, რომ', 'hu': 'A freitag2020bleu nemrégiben javasolta az automatikus értékelést, amely összehasonlítja a jelöltek fordításait az ember által generált parafrázisokkal. Az eredeti hivatkozások helyett a parafrázott változatok olyan metrikus pontszámokat eredményeznek, amelyek jobban összefüggnek az emberi ítélőképességgel. Ez a hatás különböző automatikus mutatókra vonatkozik, és hajlamos a természetes megfogalmazásokat előnyben részesíteni a szó szerinti (translationéz) megfogalmazásokkal szemben. Ebben a tanulmányban összehasonlítjuk a teljes körű rendszerfejlesztés eredményeit standard és parafrazált referenciákkal. A legkorszerűbb angol-német NMT komponensekkel megmutatjuk, hogy a parafrázott referenciákra való hangolás egy olyan rendszert eredményez, amely az emberi ítélőképesség szerint jelentősen jobb, de 5 BLEU pont rosszabb, ha standard referenciákon tesztelik. Munkánk megerősíti azt a megállapítást, hogy a parafrázott referenciák metrikus pontszámokat eredményeznek, amelyek jobban korrelálnak az emberi ítélőképességgel, és első alkalommal bizonyítja, hogy ezeknek a pontszámoknak a rendszerfejlesztéshez való használata jelentős javulást eredményezhet.', 'el': 'Πρόσφατα πρότεινε η ελεύθερη 2020μπλέ αυτόματη αξιολόγηση που συγκρίνει τις υποψήφιες μεταφράσεις με τις παραφράσεις των μεταφράσεων αναφοράς που δημιουργούνται από ανθρώπους. Όταν χρησιμοποιούνται στη θέση των αρχικών αναφορών, οι παραφράσεις παράγουν μετρικές βαθμολογίες που συσχετίζονται καλύτερα με την ανθρώπινη κρίση. Αυτό το αποτέλεσμα ισχύει για μια ποικιλία διαφορετικών αυτόματων μετρήσεων, και τείνει να ευνοεί τις φυσικές διατυπώσεις έναντι των πιο κυριολεκτικών (μεταφρασμένων) αυτών. Στην παρούσα εργασία συγκρίνουμε τα αποτελέσματα της εκτέλεσης ολοκληρωμένης ανάπτυξης συστημάτων χρησιμοποιώντας τυποποιημένες και παράφρασες αναφορές. Με τα υπερσύγχρονα αγγλικά-γερμανικά εξαρτήματα καταδεικνύουμε ότι ο συντονισμός σε παράφρασες παραπομπές παράγει ένα σύστημα που είναι αξιοσημείωτα καλύτερο σύμφωνα με την ανθρώπινη κρίση, αλλά 5 σημεία BLEU χειρότερα όταν δοκιμάζονται σε τυποποιημένες αναφορές. Η εργασία μας επιβεβαιώνει το συμπέρασμα ότι οι παράφρασες αναφορές αποδίδουν μετρικές βαθμολογίες που συσχετίζονται καλύτερα με την ανθρώπινη κρίση, και αποδεικνύει για πρώτη φορά ότι η χρήση αυτών των βαθμολογιών για την ανάπτυξη συστημάτων μπορεί να οδηγήσει σε σημαντικές βελτιώσεις.', 'it': "Di recente freitag2020bleu ha proposto una valutazione automatica che confronta le traduzioni dei candidati con le parafrasi generate dall'uomo delle traduzioni di riferimento. Quando utilizzate al posto dei riferimenti originali, le versioni parafrase producono punteggi metrici che meglio si correlano con il giudizio umano. Questo effetto vale per una varietà di metriche automatiche diverse, e tende a favorire formulazioni naturali rispetto a quelle più letterali (translationese). In questo articolo confrontiamo i risultati dello sviluppo di sistemi end-to-end utilizzando riferimenti standard e parafrasi. Con componenti NMT inglese-tedesco all'avanguardia, mostriamo che la sintonizzazione su riferimenti parafrasati produce un sistema significativamente migliore secondo il giudizio umano, ma 5 punti BLEU peggiori se testato su riferimenti standard. Il nostro lavoro conferma il risultato che i riferimenti parafrasati producono punteggi metrici che si correlano meglio con il giudizio umano, e dimostra per la prima volta che l'utilizzo di questi punteggi per lo sviluppo del sistema può portare a miglioramenti significativi.", 'kk': 'Кандидаттардың аудармаларын адамдардың құрылған парафразтарына салыстыру автоматты түрде бағалау жұмыс салыстырылды: freitag2020bleu. Бастапқы сілтемелер орнына қолданылса, парафразылған нұсқалар адамдардың шешіміне жақсы сәйкес келетін метрикалық нұсқаларды жасайды. Бұл эффект бірнеше түрлі автоматты метрикалық метрикалық түрлерге бар және табиғи формулацияларды көптеген әріпті (аудармалық) формулацияларға арналған. Бұл қағазда біз стандартты және парафразты сілтемелерді қолдану жүйесінің соңындағы жасау нәтижесін салыстырық. Ағылшын-неміс NMT компоненттерінің күйінде парафраз сілтемелерінің баптауы адамдардың сәйкестігіне сәйкес жақсы жақсы жүйесін жасайды, бірақ 5 BLEU стандартты сілтемелерді тексергенде әсер етеді. Біздің жұмысамыз парафраз сілтемелерін адамдардың оқиғаларымен жақсы салыстыратын метрикалық нөмірлерді табуды тексереді. Бұл нөмірлерді жүйелік жасау үшін қолдану үшін бірінші рет көрсетеді.', 'lt': 'Fretag2020bleu neseniai pasiūlė automatinį vertimų kandidatais ir žmogaus sukeltų vertimų vertimų parafrazių palyginimą. Kai naudojamos vietoj pirminių nuorodų, parafrazėse pateikiami metriniai taškai, kurie geriau atitinka žmogaus vertinimą. Šis poveikis taikomas įvairioms skirtingoms automatinėms metrijoms ir paprastai skatina gamtines formuluotes, palyginti su labiau literaliomis (vertimosi) formuluotėmis. Šiame dokumente palyginame sistemų plėtojimo nuo pabaigos rezultatus naudojant standartines ir parafrazės nuorodas. Naujausiomis anglų ir vokiečių NMT sudedamosiomis dalimis mes rodome, kad pritaikymas prie parafraziuotų nuorodų sukuria sistemą, kuri pagal žmogaus sprendimą yra žymiai geresnė, tačiau 5 BLEU taškai blogesni, kai bandoma pagal standartines nuorodas. Mūsų darbas patvirtina išvadą, kad parafrazuotos nuorodos duoda metrinius taškus, kurie geriau koreliuoja su žmogaus vertinimu, ir pirmą kartą rodo, kad naudojant šiuos taškus sistemos kūrimui gali būti gerokai pagerinta.', 'mk': 'Automatic evaluation comparing candidate translations to human-generated paraphrases of reference translations has recently been proposed by freitag2020bleu.  Кога се користат наместо оригиналните референции, парафразираните верзии произведуваат метрични оценки кои се подобро кореларираат со човечката судбина. Овој ефект се одржува за различни автоматски метрики, и има тенденција да ги услужи природните формулации над побуквалните (преведени). In this paper we compare the results of performing end-to-end system development using standard and paraphrased references.  Со најсовремените англиско-германски компоненти на НМТ, покажуваме дека прилагодувањето на парафразираните референции произведува систем кој е значително подобар според човечката пресуда, но 5 БЛЕ поени полоши кога се тестираат на стандардни референции. Нашата работа го потврдува откритието дека парафразираните референции даваат метрички оценки кои се подобро поврзани со човечкото судење и за првпат покажува дека употребата на овие оценки за развој на системот може да доведе до значителни подобрувања.', 'ms': 'Evaluasi automatik membandingkan terjemahan calon dengan parafrasa terjemahan rujukan yang dijana oleh manusia telah diusulkan oleh freitag2020bleu. Apabila digunakan sebagai ganti rujukan asal, versi parafrasa menghasilkan skor metrik yang berkorrelasi dengan penilaian manusia. Kesan ini mengandungi pelbagai metrik automatik yang berbeza, dan cenderung untuk menyokong formulasi semulajadi daripada yang lebih literal (terjemahan). Dalam kertas ini kita membandingkan hasil pembangunan sistem akhir-akhir menggunakan rujukan piawai dan parafrasa. Dengan komponen NMT Inggeris-Jerman yang terbaik, kami menunjukkan bahawa penyesuaian kepada rujukan parafrasa menghasilkan sistem yang jauh lebih baik menurut penilaian manusia, tetapi 5 titik BLEU lebih buruk bila diuji pada rujukan piawai. Kerja kami mengesahkan penemuan bahawa rujukan parafrasa memberikan skor metrik yang berkorrelasi lebih baik dengan penilaian manusia, dan menunjukkan untuk pertama kalinya bahawa menggunakan skor ini untuk pembangunan sistem boleh membawa kepada peningkatan yang signifikan.', 'mt': 'L-evalwazzjoni awtomatika li tqabbel it-traduzzjonijiet kandidati mal-parafrażijiet tat-traduzzjonijiet ta’ referenza ġġenerati mill-bniedem reċentement ġiet proposta mill-freitag2020bleu. Meta jintużaw minflok referenzi oriġinali, il-verżjonijiet parafrażizzati jipproduċu punteġġi metriċi li jikkorrelaw aħjar mal-ġudizzju uman. Dan l-effett jgħodd għal varjetà ta’ metriċi awtomatiċi differenti, u għandu t-tendenza li jiffavorixxi formulazzjonijiet naturali fuq dawk aktar letterali (traduzzjonati). F’dan id-dokument inqabblu r-riżultati tat-twettiq tal-iżvilupp tas-sistema minn tarf sa tarf bl-użu ta’ referenzi standard u parafrażizzati. Bl-aktar komponenti moderni tal-NMT Ingliż-Ġermaniż, nuru li l-a ġġustament għar-referenzi parafrażizzati jipproduċi sistema li hija sinifikament aħjar skont is-sentenza umana, iżda 5 punti BLEU agħar meta ttestjati fuq referenzi standard. Ix-xogħol tagħna jikkonferma s-sejba li referenzi parafrażizzati jagħtu punteġġi metriċi li jikkorrelaw aħjar mal-ġudizzju uman, u juri għall-ewwel darba li l-użu ta’ dawn il-punteġġi għall-iżvilupp tas-sistema jista’ jwassal għal titjib sinifikanti.', 'ml': 'പ്രാര്\u200dത്ഥിതിയുടെ വിവരങ്ങള്\u200d മനുഷ്യന്\u200d ജനിപ്പിക്കപ്പെട്ട പാരാഫര്\u200dഷനുമായി താല്\u200dക്കീകരിക്കുന്നതിനായി സ്വയം വിലാസങ്ങള്\u200d പ യഥാര്\u200dത്ഥ വിവരങ്ങള്\u200dക്കുപകരം ഉപയോഗിക്കുമ്പോള്\u200d, പാരാഫ്രാസ്റ്റ് പതിപ്പുകള്\u200d മെറ്റിക്ക് സ്കോര്\u200d ഉല്\u200dപാദിക് ഈ പ്രഭാവം വ്യത്യസ്ത്രീയ മെട്രിക്കങ്ങള്\u200dക്ക് വേറെയും വ്യത്യസ്ത്രീയ മെറ്റിക്കങ്ങള്\u200dക്ക് വേണ്ടിയുള്ള പ്രഭാവ ഈ പത്രത്തില്\u200d നാം അവസാന സിസ്റ്റത്തിന്റെ അവസാന വികസ്ഥയുടെ ഫലങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനെ തുല്യമാക്കുന്ന സ്റ്റേറ്റ് ഓഫ് ഇംഗ്ലീഷ്-ജെര്\u200dമ്മന്\u200d എംഎംടി സംഘങ്ങളുടെ കൂട്ടത്തില്\u200d ഞങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു പാരാഫ്രേഷന്\u200d പരിഗണനങ്ങളുടെ കൂട്ടത്തില നമ്മുടെ പ്രവര്\u200dത്തനങ്ങള്\u200d തെളിയിക്കുന്നുണ്ടെന്ന് തെളിയിക്കുന്നു, മനുഷ്യരുടെ ന്യായവിധിയോട് കൂടുതല്\u200d മെറ്റിക് സ്കോര്\u200dട്രിക്ക് കൊണ്ട് വര', 'mn': 'Саяхан Freitag2020bleu-д хүн төрөлхтний хөгжлийн хэлбэртэй харьцуулсан автоматически оюун шалгалт хийгдсэн. Гэхдээ анхны холбоонуудын оронд хэрэглэгддэг үе хувилбарууд нь хүн төрөлхтний шүүмжтэй илүү холбоотой метрик тоонуудыг бий болгодог. Энэ нөлөө нь олон өөр өөр автоматикийн метриктикийн төлөө байдаг. Байгалийн томъёог илүү бичил хэлбэртэй (орчуулан) томъёог ашигладаг. Энэ цаасан дээр бид стандарт болон парафразын холбоо ашиглан төгсгөл системийн хөгжлийн үр дүнг харьцуулдаг. Англи-Германы NMT хэмжээсүүдийн хувьд бид хэлбэртэй тэмдэглэх нь хүн төрөлхтний шүүмжлээс үнэхээр илүү сайн системийг гаргадаг гэдгийг харуулж байна. Гэхдээ 5 BLEU стандарт тэмдэглэх үед илүү зөвхөн тодорхойлж байна. Бидний ажлын ажлын тодорхойлолт нь хүн төрөлхтний шүүмжтэй илүү холбоотой метрик тоонуудыг гаргаж, системийн хөгжлийн хувьд эдгээр тоонуудыг ашиглан хамгийн түрүүнд сайжруулж чадна гэдгийг баталдаг.', 'no': 'Automatisk evaluering som samanliknar kandidatomsetjingar til menneske genererte parafrasar av referansomsetjingar er nyleg foreslått av freitag2020bleu. Når det vert brukt i staden for originale referanser, vil parafraserte versjonane produsere metriske poeng som korrelater bedre med menneske sprøym. Denne effekten inneheld for mange ulike automatiske metrikar, og tenderer til å sjå naturformasjonar over fleire bokstavar (translationese). I denne papiret samanliknar vi resultatet av utviklinga av ende- til- sluttsystemet med standard og parafraserte referanser. Med kunsttilstanden til engelsk-tysk NMT-komponentar viser vi at oppsettet til parafraserte referanser produserer eit systemet som er oftast bedre etter menneske uttrykk, men 5 BLEU påvirkar dørre når testet på standardferanser. Arbeidet vårt stadfestar å finna at parafraserte referanser gjer metriske poeng som korrelasjonar betre med menneske sprøytebruk, og viser for første gang at bruken av desse poeng for systemutvikling kan føre til signifikante forbedringar.', 'pl': 'Automatyczna ocena porównywania tłumaczeń kandydatów z parafrazami tłumaczeń referencyjnych generowanymi przez człowieka została ostatnio zaproponowana przez freitag2020bleu. Używane w miejscu oryginalnych odniesień wersje parafrazowane tworzą wyniki metryczne, które lepiej korelują z ludzkim osądem. Efekt ten dotyczy wielu różnych automatycznych wskaźników i ma tendencję do faworyzowania naturalnych preparatów niż bardziej dosłownych (tłumaczeniowych). W artykule porównujemy wyniki przeprowadzania kompleksowego rozwoju systemu przy użyciu referencji standardowych i parafrazowanych. Dzięki najnowocześniejszym angielsko-niemieckim komponentom NMT pokazujemy, że dostrojenie do parafrazowanych odniesień daje system, który jest znacznie lepszy według ludzkiego osądu, ale 5 BLEU punkty gorsze, gdy testuje na standardowych referencjach. Nasze prace potwierdzają stwierdzenie, że parafrazowane odniesienia dają wyniki metryczne lepiej korelujące z ludzką oceną i po raz pierwszy pokazują, że wykorzystanie tych wyników do rozwoju systemu może prowadzić do znaczącej poprawy.', 'ro': 'Recent, freitag2020bleu a propus evaluarea automată care compară traducerile candidaților cu parafrazele generate de om ale traducerilor de referință. Atunci când sunt utilizate în locul referințelor originale, versiunile parafrazate produc scoruri metrice care corelează mai bine cu judecata umană. Acest efect este valabil pentru o varietate de măsurători automate diferite și tinde să favorizeze formulările naturale față de cele mai literale (translationeze). În această lucrare comparăm rezultatele efectuării de dezvoltare end-to-end a sistemelor folosind referințe standard și parafrazate. Cu componente NMT engleză-germană de ultimă oră, arătăm că reglarea referințelor parafrazate produce un sistem semnificativ mai bun conform judecății umane, dar 5 puncte BLEU mai rele atunci când este testat pe referințe standard. Lucrările noastre confirmă constatarea că referințele parafrazate produc scoruri metrice care se corelează mai bine cu judecata umană și demonstrează pentru prima dată că utilizarea acestor scoruri pentru dezvoltarea sistemului poate duce la îmbunătățiri semnificative.', 'so': 'Qiimeynta bilowga ah oo u sameynaya tarjumaadyada kandidada oo u eg paraphrases of reference translations recently is proposed by freitag20bleu. Marka lagu isticmaalo warqadaha asalka ah, warqadaha la soo bandhigay ayaa soo saara kooxo metric oo la xiriira xukunka biniaadamka. Saamayntan waxay leedahay metricooyin kala duduwan oo iskumar ah, waxayna ka raalli yihiin noocyada dabiicadda ah oo ka badan qoraal rasmi ah (turjumis). Warqadan waxaynu isbarbardhignaa resultinta sameynta horumarinta nidaamka ugu dhammaadka ugu dambaysta, si aan ugu isticmaalno references standard iyo paraphras. Markaas qaybaha afka Ingiriiska-Jarmalka-Jarmalka NMT, waxaynu tusnaynaa in la xiriiro qoraalka lagu qoray ay ay soo bixisaa nidaam si aan aqoon u fiican sida xukunka dadka, laakiin 5 BLEU waxay leedahay mid ka sii daran marka lagu tijaabiyo reference standard. Shaqo-kayagu wuxuu xaqiijiyaa in horumarinta loo qoray ay ay soo bixisaa qiimeeya lagu xiriira xukunka biniaadamka, wuxuuna muujiyaa marka ugu horraysa in lagu isticmaalo qiimeeyan horumarinta nidaamka lagu kordhiyo wuxuu noqon karaa hagaajiyo aad u weyn.', 'sv': 'Automatisk utvärdering som jämför kandidatöversättningar med humangenererade parafraser av referensöversättningar har nyligen föreslagits av freitag2020bleu. När de används i stället för originalreferenser ger de parafraserade versionerna metriska poäng som bättre korrelerar med mänsklig bedömning. Denna effekt gäller för en mängd olika automatiska mätvärden, och tenderar att gynna naturliga formuleringar framför mer bokstavliga (translationesiska) sådana. I den här uppsatsen jämför vi resultaten av att utföra end-to-end systemutveckling med hjälp av standard- och parafraserade referenser. Med toppmoderna engelsk-tyska NMT-komponenter visar vi att inställning till parafraserade referenser ger ett system som är markant bättre enligt mänsklig bedömning, men 5 BLEU-poäng sämre när de testas på standardreferenser. Vårt arbete bekräftar upptäckten att parafraserade referenser ger metriska poäng som bättre korrelerar med mänskligt omdöme, och visar för första gången att användningen av dessa poäng för systemutveckling kan leda till betydande förbättringar.', 'si': 'ස්වයංක්\u200dරියාත්මක විශ්ලේෂණය සම්බන්ධයෙන් මිනිස්සු නිර්මාණය කරපු පැරැෆ්\u200dරේස් වලින් සම්බන්ධයෙන්  ප්\u200dරධාන ප්\u200dරතිපත්තිය ස්ථානයෙන් භාවිත කරලා තියෙනම්, ප්\u200dරතිපත්තිය සංවිධානය ප්\u200dරතිපත්තිය මෙට මේ පරීක්ෂණය වෙනස් ස්වයංක්\u200dරීය මීටරික් වලින් වෙනස් වෙනස් විදියට තියෙනවා, ඒ වගේම ස්වයංක්\u200dරීය විදියට ස්වය මේ පත්තරේ අපි ප්\u200dරමාණය සහ ප්\u200dරමාණය සඳහා ප්\u200dරමාණය සඳහා අන්තිම පද්ධති විකාශයේ පද්ධති විකාශයේ ප්\u200dරතිච ඉංග්\u200dරීසිය-ජර්මාන් අංක්\u200dරියාත්මක අංක්\u200dරියාත්මක සමඟ, අපි පෙන්වන්නේ පැරැෆ්\u200dරේසිය් අංක්\u200dරියාත්මක සංවේදනය සඳහා පද්ධතිය ප්\u200d අපේ වැඩේ ස්ථාපනය කරනවා පැරැෆ්රේස් ප්\u200dරතිපත්තිය ප්\u200dරතිපත්තිය ප්\u200dරතිපත්තියේ මිනිස්සු විශ්වාසයෙන් හොඳයි කියලා මිනිස්සු වි', 'sr': 'U nedavno je predloženo freitag2020bleu automatska procjena usporedbe prevoda kandidata na ljudske parafraze referentnih prevoda. Kada se koristi umjesto originalnih referencija, parafrazirane verzije proizvode metričke rezultate koje bolje povezuju sa ljudskim presudima. Ovaj efekat drži različite automatske metrike i koristi prirodne formulacije preko doslovnijih (translationeza). U ovom papiru uspoređujemo rezultate razvoja sustava kraja do kraja koristeći standardne i parafraze. S komponentima engleskog-nemačkog NMT-a iz države umjetnosti, pokazujemo da korištenje parafraziranih referencija proizvodi sistem koji je izuzetno bolji prema ljudskom osuđivanju, ali 5 BLEU pokazuje gore kada se testira na standardnim referencijama. Naš rad potvrđuje pronalaženje da parafrazirane referencije donose metričke rezultate koje su bolje povezani sa ljudskim presudima, i pokazuje prvi put da koristeći te rezultate za razvoj sistema može dovesti do značajnih poboljšanja.', 'ta': 'மொழிபெயர்ப்புகளின் மொழிபெயர்ப்புகளை மனித உருவாக்கப்பட்ட மொழிபெயர்ப்புகளை ஒப்பிடும் மாற்று தானாக மதிப்பிடு மூல குறிப்புகளின் இடத்தில் பயன்படுத்தப்பட்டால், வார்த்தப்பட்ட பதிப்புகள் மெட்ரிக் மதிப்புகளை உருவாக்குகிறது, அது  இந்த விளைவு பல்வேறு தன்னியக்கமான மெட்ரிக்களுக்கு கொண்டுள்ளது, மற்றும் மேலும் மொழிபெயர்ப்பு (மொழிபெயர்ப்பு) ஒன்றுக இந்த காகிதத்தில் நாம் நிலையான மற்றும் paraphrased குறிப்புகளை பயன்படுத்தி முடிவு முடிவு முறைமை உருவாக்கும் முட மாநிலை - கலை ஆங்கிலம்- ஜெர்மன் NMT பொருள்களுடன் நாம் காட்டுகிறோம் என்றால் குறிப்பிட்ட குறிப்பிட்ட குறிப்பிட்ட குறிப்புகளை ஒதுங்குதல் மனித நிய எங்கள் வேலை உறுதிப்படுத்துகிறது என்று குறிப்பிட்ட குறிப்புகள் மெட்ரிக் மதிப்புகள் கொடுக்கும் அது மனித நியாயத்துடன் சிறந்த நிலையை இணைக்கும', 'ur': 'فاریٹاگ 2020bleu کے ذریعہ اپنا فریٹاگ پیدا کیا گیا ہے۔ جب اصلی نسبتوں کی جگہ استعمال کی جاتی ہے، پارافریز نسبتوں نے متریک اسکور پیدا کیے جو انسان کے فیصلے سے بہتر تعلق رکھتے ہیں۔ یہ اثر مختلف مختلف متریک کے لئے ہے، اور زیادہ صحیح (ترجمن) پر طبیعی فرمول کا احسان کرنا چاہتا ہے. ہم اس کاغذ میں استاندارڈ اور پارافریزڈ نسبتوں کے مطابق فیصلہ کرنے کے نتیجے کا مقایسہ کرتے ہیں۔ انگلیسی-جرمنی NMT رشتہ جماعتوں کے ساتھ ہم دکھاتے ہیں کہ پارافریز رشتوں کے ساتھ تنظیم کرنا ایک سیستم پیدا کرتا ہے جو انسان کے فیصلہ کے مطابق زیادہ بہتر ہے، لیکن پنج بلیوس کے مطابق استاندارڈ رشتوں پر آزمائش کی حالت میں بدتر ہے. ہمارا کام اس بات کی تصدیق کرتا ہے کہ پارافریزہ ارتباط متریک اسکور کے ساتھ اچھی نسبت ہے اور پہلی بار دکھاتا ہے کہ ان اسکوروں کے استعمال کرنے کے لئے سیسٹم کی توسعہ کے لئے بہترین توسعہ کا ذریعہ ہے.', 'uz': "@ info: whatsthis Asl parametrlar joyida ishlatilganda, paraphrased versiyalari inson xususiyatlarida yaxshi bogʻ'langan metrik qiymatni yaratadi. Ushbu effekti boshqa boshqa avtomatik metriklarga ega bo'ladi, va asboblar formulalarini ko'proq tahrirlik (tarjima) bilan ko'proq shaklga oshirish mumkin. In this paper we compare the results of performing end-to-end system development using standard and paraphrased references.  Bu holatda, ingliz tili-Olmon NMT komponentlarini ko'rsatishimiz mumkin, paraphrasing parametrlarini o'rganish imkoniyatlariga o'xshagan tizimni aniqlaydi, lekin standard referansa tizimga tizimni sinab ko'rib chiqaradi. Bizning ishlarimizni aniqlash imkoniyatini ishlatish imkoniyatini ishlatish imkoniyatini ishlatish mumkin. Ular inson xuddi yaxshi bog'lash mumkin, va bu tizim taʼminlovchisini ishlatish uchun birinchi marta o'zgarishga juda muhim yaxshi o'zgarishga ega bo'ladi.", 'vi': 'Tự động đánh giá để so sánh bản dịch ứng cử viên với những diễn văn người tạo ra của dịch thuật. Khi được sử dụng thay vì những chỉ dẫn ban đầu, các phiên bản bị liệt sẽ tạo ra điểm số phù hợp tốt hơn với phán đoán con người. Hiệu ứng này dành cho nhiều loại âm lượng tự động khác nhau, và có xu hướng thích công thức tự nhiên hơn các công thức dịch ngữ thường hơn. Trong tờ giấy này chúng tôi so sánh kết quả của việc phát triển hệ thống cuối cùng bằng các chỉ dẫn chuẩn và liệt kê. Với các thành phần Anh-Đức-Anh Quốc Quốc Quốc Quốc Gia, chúng tôi cho thấy việc chỉnh sửa các chỉ dẫn bị liệt sẽ tạo ra một hệ thống rõ ràng hơn theo sự phán xét của con người nhưng năm nguyên tắc còn tệ hơn khi được thử nghiệm trên các chỉ dẫn tiêu chuẩn. Công việc của chúng tôi xác nhận việc xác nhận rằng những chỉ số liệu được liệt kê mang lại điểm kết hợp tốt hơn với phán đoán con người, và cho lần đầu tiên chứng minh rằng sử dụng số điểm này để phát triển hệ thống có thể dẫn đến cải tiến đáng kể.', 'bg': 'Автоматична оценка, сравняваща кандидат преводи с генерирани от човека парафрази на референтни преводи наскоро беше предложена от Фрейтаг2020блеу. Когато се използват вместо оригинални препратки, парафразираните версии произвеждат метрични оценки, които корелират по-добре с човешката преценка. Този ефект важи за различни автоматични показатели и има тенденция да предпочита естествените формулировки пред по-буквалните (преводачески) такива. В настоящата статия сравняваме резултатите от извършването на цялостно разработване на системи, използвайки стандартни и парафразирани референции. С най-съвременните английски-немски компоненти показваме, че настройката към парафразирани референции произвежда система, която е значително по-добра според човешката преценка, но 5 точки по-лоши при тестване на стандартни референции. Нашата работа потвърждава констатацията, че парафразираните референции дават метрични оценки, които корелират по-добре с човешката преценка, и демонстрира за първи път, че използването на тези оценки за развитие на системата може да доведе до значителни подобрения.', 'hr': 'Nedavno je predložio freitag2020bleu automatsku procjenu usporedbe prevoda kandidata na parafraze referentnih prevoda. Kada se koristi umjesto originalnih referencija, parafrazirane verzije proizvode metričke rezultate koji bolji povezuju s ljudskim presudima. Ovaj učinak drži različite automatske metrike i tendencija se koristi prirodne formulacije preko doslovnijih (translationeza). U ovom papiru uspoređujemo rezultate razvoja sustava kraja do kraja koristeći standardne i parafraze. S članovima engleskog-njemačkog NMT-a iz države umjetnosti, pokazujemo da prilagodba parafraziranih referencija proizvodi sustav koji je izuzetno bolji prema ljudskom sudjenju, ali 5 BLEU pokazuje gore kada se testira na standardnim referencijama. Naš rad potvrđuje pronalaženje da parafrazirane referencije donose metričke rezultate koji su bolje povezani s ljudskim presudima, i prvi put pokazuje da koristeći te rezultate za razvoj sustava može dovesti do značajnih poboljšanja.', 'da': 'Automatisk evaluering, der sammenligner kandidatoversættelser med menneskeskabte parafraser af referenceoversættelser, er for nylig blevet foreslået af freitag2020bleu. Når de bruges i stedet for oprindelige referencer, producerer de parafraserede versioner metriske scores, der bedre korrelerer med menneskelig dømmekraft. Denne effekt gælder for en række forskellige automatiske målinger, og har tendens til at favorisere naturlige formuleringer frem for mere bogstavelige (translationese) dem. I denne artikel sammenligner vi resultaterne af at udføre end-to-end systemudvikling ved hjælp af standard- og parafraserede referencer. Med avancerede engelsk-tyske NMT-komponenter viser vi, at justering til parafraserede referencer giver et system, der er markant bedre ifølge menneskelig dømmekraft, men 5 BLEU-punkter værre, når de testes på standardreferencer. Vores arbejde bekræfter, at parafraserede referencer giver metriske scores, der korrelerer bedre med menneskelig dømmekraft, og demonstrerer for første gang, at brugen af disse scores til systemudvikling kan føre til betydelige forbedringer.', 'nl': 'Recent is door freitag2020bleu een automatische evaluatie voorgesteld die kandidaat-vertalingen vergelijkt met door mensen gegenereerde parafrases van referentievertalingen. In plaats van originele referenties produceren de geparfraseerde versies metrische scores die beter correleren met menselijk oordeel. Dit effect geldt voor een verscheidenheid aan verschillende automatische metrics, en neigt om natuurlijke formuleringen te verkiezen boven meer letterlijke (translationese) formuleringen. In dit artikel vergelijken we de resultaten van het uitvoeren van end-to-end systeemontwikkeling met behulp van standaard en parafraseerde referenties. Met state-of-the-art Engels-Duitse NMT componenten laten we zien dat afstemmen op parafraseerde referenties een systeem oplevert dat volgens menselijk oordeel aanzienlijk beter is, maar 5 BLEU punten slechter wanneer getest op standaard referenties. Ons werk bevestigt de bevinding dat parafraseerde referenties metrische scores opleveren die beter correleren met menselijk oordeel, en toont voor het eerst aan dat het gebruik van deze scores voor systeemontwikkeling kan leiden tot aanzienlijke verbeteringen.', 'fa': 'ارزیابی خودکار با مقایسه ترجمه\u200cهای کاندیداتی با پارافریز\u200cهای متن\u200cنویسی که تولید شده\u200cاند انسان، اخیرا توسط freitag2020bleu پیشنهاد شده است. زمانی که در جای ارتباط اصلی استفاده می\u200cشود، نسخه\u200cهای متریک را تولید می\u200cکنند که با حکم انسان بهتر ارتباط دارند. این تاثیر برای مختلف متریک اتوماتیک متفاوتی دارد، و به عنوان فرمولهای طبیعی بر فرمولهای حرفه\u200cای بیشتری (ترجمه\u200cسازی) استفاده می\u200cکند. در این کاغذ نتایج توسعه سیستم پایان و پایان را با استفاده از ارتباطات استاندارد و پارافریز مقایسه می کنیم. با عناصر انگلیسی-آلمانی-آلمانی NMT، ما نشان می دهیم که تنظیم به ارتباط\u200cهای پارافریز یک سیستم را تولید می\u200cکند که در طبق قضاوت انسان بسیار بهتر است، ولی ۵ BLEU هنگامی که روی ارتباط\u200cهای استاندارد آزمایش می\u200cشود بدتر نشان می دهد. کار ما تصدیق می\u200cکند که یادآوری\u200cهای پارافریز به عنوان نمونه\u200cهای متریک ارتباط می\u200cدهد که با قضاوت انسان بهتر ارتباط دارند، و برای اولین بار نشان می\u200cدهد که استفاده از این نمونه\u200cها برای توسعه سیستم می\u200cتواند به بهترین پیشرفت\u200cهای بزرگ', 'de': 'Die automatische Evaluierung von Kandidatenübersetzungen mit menschengenerierten Paraphrasen von Referenzübersetzungen wurde kürzlich von freitag2020bleu vorgeschlagen. Wenn sie anstelle von Originalreferenzen verwendet werden, produzieren die paraphrasierten Versionen metrische Scores, die besser mit menschlichem Urteilsvermögen korrelieren. Dieser Effekt gilt für eine Vielzahl verschiedener automatischer Metriken und neigt dazu, natürliche Formulierungen gegenüber wörtlicheren (translationesischen) zu bevorzugen. In diesem Beitrag vergleichen wir die Ergebnisse der End-to-End Systementwicklung unter Verwendung von Standard- und paraphrasierten Referenzen. Mit modernsten englisch-deutschen NMT-Komponenten zeigen wir, dass die Abstimmung auf paraphrasierte Referenzen ein System erzeugt, das nach menschlichem Urteil deutlich besser ist, aber 5 BLEU-Punkte schlechter, wenn es auf Standardreferenzen getestet wird. Unsere Arbeit bestätigt die Erkenntnis, dass paraphrasierte Referenzen metrische Scores liefern, die besser mit menschlichem Urteilsvermögen korrelieren, und zeigt erstmals, dass die Verwendung dieser Scores für die Systementwicklung zu signifikanten Verbesserungen führen kann.', 'ko': 'freitag 2020bleu는 최근 후보 번역문과 참고 번역문의 인공 해석을 비교하는 자동 평가를 제기했다.원시 참고 문헌을 대체할 때 해석 판본은 인류 판단과 더욱 관련이 있는 도량 점수를 만들어 낸다.이런 효과는 여러 가지 서로 다른 자동 도량에 적용되고 자연 공식이 아니라 더 표면적인 공식에 치우친다.본고에서 우리는 표준 참고 문헌과 해석 참고 문헌을 이용하여 처음부터 끝까지 체계적으로 개발한 결과를 비교했다.가장 선진적인 영어-독일어 NMT 구성 요소를 사용함으로써 우리는 인류의 판단에 따라 해석 인용으로 조정하면 현저하고 더 좋은 시스템이 생길 수 있으나 표준 인용에서 테스트할 때 5개의 BLEU점이 모자란다는 것을 알 수 있다.우리의 작업은 이러한 발견을 증명했다. 즉, 해석에서 인용된 도량분수는 인류의 판단과 더욱 좋은 관련성을 가지며, 이러한 점수를 시스템 개발에 사용하면 현저한 개선을 가져올 수 있다는 것을 처음으로 증명했다.', 'id': 'Evaluasi otomatis membandingkan terjemahan kandidat dengan parafrasa terjemahan yang dibuat oleh manusia baru-baru ini telah diusulkan oleh freitag2020bleu. Ketika digunakan sebagai ganti referensi asli, versi parafrasa menghasilkan skor metrik yang berkorelasi lebih baik dengan penilaian manusia. Efek ini memegang untuk berbagai macam metrik otomatis yang berbeda, dan cenderung untuk mendukung formulasi alami daripada formulasi yang lebih harfiah. Dalam kertas ini kita membandingkan hasil dari melakukan pembangunan sistem akhir-akhir menggunakan referensi standar dan parafrasa. Dengan komponen NMT Inggris-Jerman yang terbaik, kami menunjukkan bahwa tuning ke referensi parafrasa menghasilkan sistem yang jauh lebih baik menurut penilaian manusia, tetapi 5 BLEU poin lebih buruk ketika diuji pada referensi standar. Pekerjaan kami mengkonfirmasi penemuan bahwa referensi parafrasa memberikan skor metrik yang berkorelasi lebih baik dengan penilaian manusia, dan menunjukkan untuk pertama kalinya bahwa menggunakan skor ini untuk pembangunan sistem dapat menyebabkan peningkatan yang signifikan.', 'sw': 'Tathmini za kujitegemea zinazolinganisha tafsiri za wagombea kwa misingi zilizotengenezwa kwa binadamu ya tafsiri za reference hivi karibuni imependekezwa na freitag20bleu. Wakati umetumiwa badala ya maoni ya awali, toleo hilo lililotolewa linaleta viwango vinavyofananisha vizuri zaidi na uamuzi wa binadamu. Athari hii inatumia mbinu mbalimbali za kujitegemea, na huenda kuupenda ubunifu wa asili zaidi ya zile za kitafsiri. Katika gazeti hili tunalinganisha matokeo ya kutekeleza maendeleo ya mfumo wa mwisho kwa kutumia maoni ya kawaida na yanayoelezwa. Kuhusu vifaa vya Kiingereza-Kiingereza-Ujerumani NMT, tunaonyesha kuwa kuingilia maoni yaliyotolewa yanaleta mfumo unaotengeneza vizuri zaidi kwa mujibu wa hukumu ya binadamu, lakini BLEU inaonyesha vibaya zaidi pale ilipojaribiwa kwa maoni ya kawaida. Kazi yetu inathibitisha kutambua kuwa maoni yaliyotolewa yanaleta vipimo vya umeme ambavyo vinaweza kuunganisha vizuri zaidi na uamuzi wa binadamu, na kuonyesha kwa mara ya kwanza kwamba kutumia vipimo hivi kwa ajili ya maendeleo ya mfumo unaweza kusababisha maboresho makubwa.', 'tr': 'Kanadatça terjimeleri adamlaryň döredilen paraphrazlaryna karşılaştyrylýan, oňa freitag2020bleu tarapyndan üýtgedildi. Öňki referenslar ýerine ullanynda, parafraze wersiýalar adamlaryň hökmünde has gowy bir şekilde meýilleşdirilýär. Bu etki birçok farklı otomatik metrilere sahip, doğal formüllerini daha yazılı (tercüme edilen) şeklinde destekliyor. Bu kagyzda soňky we soňky sistemiň önümlerini standart we parafrazlikler bilen çykyşyň netijesini çykarýarys. Iňlisçe-Alman NMT jemgyýetleri bilen parafraz derejesi döredilmek adama görä has gowy bir sisteme döretýär ýöne 5 BLEU standart derejesi bilen synanyşdyrylanda erbet derejesi çykýar. Biziň işimiz parafraz sanlaryň metriýa düýşürmegiň gowylaşdyrylygyny tapandygyny tassyklaýar we bu sanlaryň sistem gelişmesi üçin bu sanlary ulanmaklygyny ilkinji gezek gowylaşdyryp biler.', 'sq': 'Vlerësimi automatik që krahason përkthimet kandidate me parafrazat e përkthimeve të prodhuara nga njerëzit është propozuar kohët e fundit nga freitag2020bleu. Kur përdoren në vend të referencave origjinale, versionet parafrazuara prodhojnë rezultate metrike që korrelohen më mirë me gjykimin njerëzor. Ky efekt mban për një shumicë metrike të ndryshme automatike dhe ka tendencë të favorizojë formulimet natyrore mbi a to më literale. Në këtë letër krahasojmë rezultatet e kryerjes së zhvillimit të sistemit nga fundi në fund duke përdorur referenca standarde dhe parafrazuese. Me komponentet e NMT anglisht-gjerman më të moderne, ne tregojmë se përputhja me referencat parafrazuara prodhon një sistem që është shumë më i mirë sipas gjykimit njerëzor, por 5 BLEU pikë më të keqe kur testohet në referencat standarde. Puna jonë konfirmon gjetjen se referencat parafrazuara japin rezultate metrike që korrelohen më mirë me gjykimin njerëzor dhe demonstron për herë të parë se përdorimi i këtyre rezultateve për zhvillimin e sistemit mund të çojë në përmirësime të rëndësishme.', 'am': 'በአሁኑ ጊዜ በfreitag20bleu የተዘጋጀ ነው፡፡ በመጀመሪያው መልዕክቶች በተጠቀሙ ጊዜ፣ የተለየው የፊደል መልዕክቶች ከሰው ፍርድ የተሻለ ሚትሪክ ነጥቦችን የሚያደርጉ ናቸው፡፡ ይህ ጥያቄ በተለያዩ የተለየ ባሕላዊ ማተሚያዎች ላይ ይኖራል፡፡ በዚህ ፕሮግራም የፍጻሜውን የፍጻሜውን የድምፅ አካባቢ እና የግንኙነቶችን እና የግንኙነት ምርጫዎችን እናሳያታለን፡፡ የኢንግሊዝኛ-የጀርመን-የግሪክ-ጀርመን NMT ተቃውሞ በመቀበል እናሳየዋለን፡፡ በተለየ የፊደል references ማቀናቀል በሰው ፍርድ ሳይታወቅ ይሻላል፡፡ ሥራችን የፓራፊል መልዕክቶች ከሰው ፍርድ ጋር የሚሻለውን የሜትሪክ ነጥቦች እንዲያወጣ የሚያረጋግጥ ነው፤ እነዚህንም ቀለሞች ለስርዓት ማውጣት በመጀመሪያ ጊዜ እንዲጠቀም ትልቅ ማድረግ እንዲያሳየው ይችላል፡፡', 'af': "Outomatiese evaluering met vergelyking van kandidate vertalings na mensgenereerde parafrase van verwysing vertalings is onlangs voorgestel deur freitag2020bleu. Wanneer gebruik word in plek van oorspronklike verwysings, produseer die parafraseerde weergawes metriese telling wat beter met menslike oordeel korrelaat. Hierdie effek hou vir 'n verskeie van verskillende outomatiese metries, en tendeer om natuurlike formulasies te guns oor meer literale (translationese) ones. In hierdie papier vergelyk ons die resultate van die uitvoering van einde-tot-einde stelsel ontwikkeling met gebruik van standaard en parafraseerde verwysings. Met staat-van-die-kuns-Engels-Duits NMT komponente, wys ons dat toepassing na parafrase verwysing produseer 'n stelsel wat onheilig beter is volgens menslike oordeel, maar 5 BLEU wys verder wanneer toets op standaard verwysing is. Ons werk bevestig die opvinding dat parafrase verwysings metriese punte wat beter met menslike oordeel vergelyk, en bevestig vir die eerste keer dat hierdie punte gebruik vir stelsel ontwikkeling kan lei na beter verbeteringe.", 'hy': 'Մարդկային կողմից ստեղծված հաղորդակցման թարգմանությունների պարաֆրեսների հետ համեմատելու ավտոմատիկ գնահատականը վերջերս առաջարկվել է Freital 2020Blue-ի կողմից: Երբ այն օգտագործվում է սկզբնական հաղորդակցությունների փոխարեն, պարաֆրեզիաները ստեղծում են մետրական գնահատականներ, որոնք ավելի լավ համապատասխանում են մարդկային դատողության հետ: Այս էֆեկտը պահպանվում է տարբեր ավտոմատիկ մետրիկների համար, և հակված է աջակցել բնական ձևավորումները ավելի բառացիորեն (թարգմանված) ձևերի փոխարեն: Այս թղթի մեջ մենք համեմատում ենք վերջ-վերջ համակարգի զարգացման արդյունքները, օգտագործելով ստանդարտ և պարաֆրանսավորված հղումներ: Անգլերեն-գերմանացի նորագույն NMT-ի բաղադրիչների միջոցով մենք ցույց ենք տալիս, որ պարաֆրանսավորված հաղորդակցությունների հարմարեցման արդյունքում ստեղծում է համակարգ, որը նշանակաբար ավելի լավ է համապատասխանում մարդկային դատողության վրա, բայց հինգ ԲԼԵՎ Մեր աշխատանքը հաստատում է այն եզրակացությունը, որ պարաֆրեզված հաղորդակցությունները բերում են մետրական գնահատականներ, որոնք ավելի լավ կապված են մարդկային դատողության հետ, և առաջին անգամ ցույց է տալիս, որ այս գնահատականները համակարգի զարգացման համար կարող են հանգեցնել', 'az': 'İnsanların yaratdığı fərqli çevirilərə qarşılaşdığı avtomatik değerlendirmək, freitag2020bleu təbliğ edilmişdir. Əvvəlki referans yerində istifadə edildikdə, parafrazlı versiyonlar insan hökmünü daha yaxşı ilə əlaqə edən metrik nöqtələri yaradır. Bu təsiri müxtəlif avtomatik metriklərə sahib edir və təbiətli formüllərə daha çox yazılı (tercümə) olaraq faydalanır. Bu kağızda standart və parafrazli referans vasitəsilə end-to-end sistem təhsilinin sonuçlarını salırıq. İngilizə-Almanca NMT komponentləri ilə, parafrazlərə tərzim etmək insan hökmünə görə çox xeyirli bir sistemin yaratdığını göstərdik, amma 5 BLEU standart referansları ilə test edildikdə daha pisini göstərir. Bizim işimiz, parafraz referans insan hökmünü daha yaxşı ilə bağlayan metrik nöqtələrini təsdiqləyir və ilk dəfə bu nöqtələri sistem gelişməsi üçün istifadə edəcəyini göstərir.', 'bn': 'স্বয়ংক্রিয়ভাবে প্রার্থীর অনুবাদ মানুষ-তৈরি করা প্যারার্থীর অনুবাদের তুলনায় স্বয়ংক্রিয়ভাবে মূল্যায়ন করা হয়েছে ফ্রিট মূল উল্লেখের স্থানে যখন ব্যবহার করা হয়, প্যারাফ্রেক্ট সংস্করণ মেট্রিক স্কোর তৈরি করে যা মানুষের বিচারের সাথে  এই প্রভাব বিভিন্ন ভিন্ন স্বয়ংক্রিয় মেট্রিকের জন্য রয়েছে এবং প্রাকৃতিক বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভি এই পত্রিকায় আমরা স্ট্যান্ডার্ড এবং প্যারাফ্রেসেড ব্যবহার করে শেষ পর্যন্ত সিস্টেম উন্নয়নের ফলাফলের তুলনা করি। রাষ্ট্র-অফ-ইংরেজি-জার্মান এনএমটি সংক্রান্ত উপাদানের সাথে আমরা দেখাচ্ছি যে প্যারাফ্রেক্রেশনের সংক্রান্ত সংক্রান্ত সিস্টেম তৈরি করে যা মান আমাদের কাজ নিশ্চিত করেছে যে প্যারাফ্রেক্টের রেফারেশনগুলো মেট্রিক স্কোর দেয় যা মানুষের বিচারের সাথে সংশ্লিষ্ট এবং প্রথমবারের প্রতিব', 'bs': 'Nedavno je predložio freitag2020bleu automatsku procjenu usporedbe prevoda kandidata na parafraze referentnih prevoda. Kada se koristi umjesto originalnih referencija, parafrazirane verzije proizvode metričke rezultate koji bolji odnose na ljudsko procenjenje. Ovaj učinak drži različite automatske metrike i tendencija se koristi prirodne formulacije nad doslovnijim (translationalnim) formulacijama. U ovom papiru uspoređujemo rezultate razvoja sustava kraja do kraja koristeći standardne i parafraze. S komponentima engleskog-njemačkog NMT-a iz države umjetnosti pokazujemo da je punjenje parafraziranih referencija proizvodi sistem koji je izuzetno bolji prema ljudskom procjeni, ali 5 BLEU pokazuje gore kada se testira na standardnim referencijama. Naš rad potvrđuje pronalaženje da parafrazirane referencije donose metričke rezultate koji su bolje povezani s ljudskim presudima, i prvi put pokazuje da koristeći te rezultate za razvoj sistema može dovesti do značajnih poboljšanja.', 'ca': 'La freitag2020bleu ha proposat recentment una evaluació automàtica que compara les traduccions candidates amb parafrases de traduccions de referència generades per humans. Quan es fan servir en lloc de referències originals, les versions parafrasitzades produeixen puntuacions mètriques que correlacionen millor amb el judici humà. Aquest efecte es manté per una varietat de mètriques automàtiques diferents, i tendeix a favorir formulacions naturals en comparació amb formulacions més literals. En aquest article comparem els resultats del desenvolupament del sistema de final a final utilitzant referències estandards i parafrases. Amb els components NMT anglès-alemanès més moderns, demostram que ajustar a les referències parafrasitzades produeix un sistema que és significativament millor segons el judici humà, però 5 punts BLEU pitjors quan es testen en referències estándar. La nostra feina confirma el descobriment que les referències parafrasitzades donen puntuacions mètriques que correlacionen millor amb el judici humà, i demostra per primera vegada que utilitzar aquestes puntuacions per al desenvolupament del sistema pot portar a millores significatives.', 'cs': 'Automatické vyhodnocení porovnávání překladů kandidátů s parafrázemi referenčních překladů generovanými člověkem bylo nedávno navrženo freitag2020bleu. Při použití místo originálních odkazů parafrázované verze vytvářejí metrické skóre, které lépe korelují s lidským úsudkem. Tento efekt platí pro celou řadu různých automatických metrik a má tendenci upřednostňovat přírodní formulace před doslovnějšími (translačními) formulacemi. V tomto článku porovnáváme výsledky provádění komplexního vývoje systémů pomocí standardních a parafrázovaných referencí. S nejmodernějšími anglicko-německými NMT komponenty ukazujeme, že ladění na parafrázované reference vytváří systém, který je podle lidského úsudku značně lepší, ale 5 BLEU body horší při testování na standardních referencích. Naše práce potvrzuje zjištění, že parafrázované reference poskytují metrické skóre, které lépe korelují s lidským úsudkem, a poprvé ukazuje, že použití těchto skóre pro vývoj systému může vést k významným zlepšením.', 'fi': 'freitag2020bleu on äskettäin ehdottanut automaattista arviointia, jossa vertaillaan ehdokaskäännöksiä ihmisen tuottamiin viitekäännösten parafraaseihin. Kun niitä käytetään alkuperäisten viitteiden sijasta, ne tuottavat metrisiä pisteitä, jotka korreloivat paremmin ihmisen arvostelukyvyn kanssa. Tämä vaikutus pätee erilaisiin automaattisiin mittareihin ja pyrkii suosimaan luonnollisia formulaatioita kirjaimellisempien (translationese) sijaan. Tässä työssä vertaillaan end-to-end-järjestelmäkehityksen tuloksia standardi- ja parafraasiviitteillä. Moderneilla englannin-saksan NMT-komponenteilla osoitamme, että muokkaus parafrasoituihin viittauksiin tuottaa järjestelmän, joka on merkittävästi parempi ihmisen arvion mukaan, mutta 5 BLEU pistettä huonompi standardireferenssillä testattuna. Työssämme vahvistetaan havainto, että parafrasoidut referenssit tuottavat metrisiä pisteitä, jotka korreloivat paremmin ihmisen arviointiin, ja osoitetaan ensimmäistä kertaa, että näiden pisteiden käyttäminen järjestelmän kehittämiseen voi johtaa merkittäviin parannuksiin.', 'et': 'Hiljuti pakkus freitag2020bleu välja automaatse hindamise, võrreldes kandidaattõlkeid inimese loodud viitetõlkete parafraasidega. Kui neid kasutatakse algsete viitete asemel, annavad parafraasitud versioonid meetrilised skoorid, mis vastavad paremini inimese otsustusvõimele. See efekt kehtib erinevate automaatsete mõõdikute puhul ja kaldub eelistama looduslikke vorminguid sõnasõnalisemate (translationese) vormide asemel. Käesolevas töös võrdleme süsteemi lõpp-lõpuni arendamise tulemusi standardsete ja parasõnastatud viidete abil. Tipptasemel inglise-saksa NMT komponentidega näitame, et parasõnastatud viidetele häälestamine annab süsteemi, mis on inimese hinnangul märkimisväärselt parem, kuid 5 BLEU punkti halvem, kui testitakse standardviidetel. Meie töö kinnitab järeldust, et parasõnastatud viited annavad meetriliste skooride, mis on paremini korrelatsioonis inimese otsustusvõimega, ja näitab esmakordselt, et nende skooride kasutamine süsteemi arendamiseks võib tuua kaasa märkimisväärseid paranemisi.', 'jv': '#a11y <joanie> hello!<joanie> hello! Anyone Efek iki dadi akeh akeh sistem sing sampeyan akeh sistem otomatik, lan kashukane nggawe perusahaan pribadi supoyo perusahaan (tertulatione) Nang pepulan iki, kita komparasi sistem tukong kelompok end-to-end nggawe ngubah ujian usul karo perusahaan barang. Suara permaneh-permaneh sing sampeyan ingles-alaman NMT, kita ngomong nik nganggo permaneh kanggo ngerasakno Awak dhéwé nggunakake nggawe barang-barang iki dadi perusahaan banget nggawe barang-barang kotak tentang karo hukum sing luwih apik, lan nambah perusahaan kanggo nguasai perusahaan sing iki banget kanggo nggawe sistem sing bisa bisa dianggap bantuan liyane', 'ha': "@ info: whatsthis Idan an yi amfani da a shige ga masu origina, versions parametered zata nau'in matric wanda ke sami da mafiya amfani da hukuncin mutum. Wannan Effekt yana da wa wasu mitori daban-daban farat ɗaya, kuma yana yarda da tsari masu natura kan masu littãfi (fassarar) masu yawa. A cikin wannan takarda, muna samãrar da matsalar da za'a samar da mafarinta na system-ƙari zuwa-ƙarshen, ana yi amfani da takarda da fassarar da aka daidaita. Ana nuna da shirin-state-of-the-art-English-Jarman NMT compound, za'a nuna cewa, tunkuɗe wa mistakardar da aka faɗa shi, yana da wata na'ura wanda bã ya fi kyau a kama da hukuncin mutum, kuma amma 5 BLEU yana pointar da mafi sharri idan an jarraba a kan mistakardan aiki na daidaita. Kayan aikinMu yana gaskata cewa misalin parameter za'a fitar nufi na mitriki wanda ke da mafiya amfani da hukuncin mutum, kuma yana nuna kwance a farkon da za'a yi amfani da waɗannan score wa mafanicin system, za'a iya ƙara mafiya girma.", 'sk': 'Avtomatsko ocenjevanje primerjave kandidatnih prevodov s človeško ustvarjenimi parafrazami referenčnih prevodov je pred kratkim predlagal freitag2020bleu. Če se uporabljajo namesto originalnih referenc, parafrazirane različice proizvajajo metrične rezultate, ki se bolje korelacirajo s človeško presojo. Ta učinek velja za različne različne avtomatske meritve in ponavadi daje prednost naravnim formulacijam pred bolj dobesednimi (translationeznimi) formulacijami. V prispevku primerjamo rezultate izvedbe razvoja sistema od konca do konca s standardnimi in parafraziranimi referencami. Z najsodobnejšimi angleško-nemškimi NMT komponentami pokažemo, da nastavitev parafraziranih referenc ustvarja sistem, ki je po človeški presoji znatno boljši, 5 točk BLEU pa slabši pri testiranju na standardnih referencah. Naše delo potrjuje ugotovitev, da parafrazirane reference prinašajo metrične rezultate, ki se bolje povezujejo s človeško presojo, in prvič dokazuje, da lahko uporaba teh rezultatov za razvoj sistema privede do pomembnih izboljšav.', 'he': 'הערכה אוטומטית בהשוואה של התרגשות מועמדות למפרסמות התרגשות שנוצרות ע"י האדם הציעה לאחרונה על ידי freitag2020bleu. כאשר משתמשים במקום התייחסות המקוריות, הגרסאות המפרסמות יוצרות נקודות מטריות שמתאמות יותר לשיפוט אנושי. This effect holds for a variety of different automatic metrics, and tends to favor natural formulations over more literal (translationese) ones.  In this paper we compare the results of performing end-to-end system development using standard and paraphrased references.  עם רכיבי NMT אנגלי-גרמני מוקדמים, אנו מראים שההתאמה לתייחסים מופרסים יוצרת מערכת טובה בהחלט לפי שיפוט אנושי, אבל 5 נקודות BLEU גרועות יותר כשנבדקות על התייחסים סטנדרטיים. העבודה שלנו מאשרת את המצאה שההתייחסות המפרסמות נותנות נקודות מטריות שמתאמות יותר לשיפוט אנושי, ומוכיחת בפעם הראשונה שהשימוש בתוצאות הללו לפיתוח מערכת יכול להוביל לשיפורים משמעותיים.', 'bo': 'རང་བཞིན་གྱིས་ཞིབ་པ་རྣམས་ལྟ་ཞིབ་བྱེད་པའི་སྐད་ཡིག་གཟུགས་རིས་འདྲ་བཤུ་བྱེད་བཞིན་ཡོད། When used in place of original references, the paraphrased versions produce metric scores that correlate better with human judgment. This effect holds for a variety of different automatic metrics, and tends to favor natural formulations over more literal (translationese) ones. ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་རྒྱབ་སྐྱོར་མིན་ཐག་རིང་གི་ཡར་རྒྱས་གཞི་ལ་མཇུག་བསྡུས་པའི་མཐུན་འབྲས་བ་དང་བར With state-of-the-art English-German NMT components, we show that tuning to paraphrased references produces a system that is ignificantly better according to the human judgment, but 5 BLEU points worse when tested on standard references. Our work confirms the finding that paraphrased references yield metric scores that correlate better with human judgment, and demonstrates for the first time that using these scores for system development can lead to significant improvements.'}
{'en': 'Incorporating Terminology Constraints in Automatic Post-Editing', 'ar': 'دمج قيود المصطلحات في التحرير التلقائي اللاحق', 'fr': 'Intégration des contraintes terminologiques dans la post-édition automatique', 'es': 'Incorporación de restricciones terminológicas en la post-edición automática', 'ja': '自動ポストエディットに用語の制約を組み込む', 'pt': 'Incorporando restrições de terminologia na pós-edição automática', 'zh': '自译后编辑入术语约束', 'hi': 'स्वत: पोस्ट-संपादन में शब्दावली बाधाओं को शामिल करना', 'ru': 'Включение терминологических ограничений в автоматическое постредактирование', 'ga': 'Srianta Téarmaíochta a Ionchorprú san Iar-Eagarthóireacht Uathoibríoch', 'ka': 'ტერმინოლოგიის კონფორტირება', 'hu': 'Terminológiai kényszerek beépítése az automatikus utószerkesztésbe', 'el': 'Ενσωμάτωση περιορισμών ορολογίας στην αυτόματη μετα-επεξεργασία', 'it': 'Incorporare vincoli terminologici nella post-modifica automatica', 'lt': 'Įtraukti terminologijos apribojimus į automatinį redagavimą', 'mk': 'Вклучување на терминолошки ограничувања во автоматското постуредување', 'kk': 'Автоматты түрде өңдеу үшін терминология шектерін ендіру', 'ms': 'Mengangkut Kebatasan Terminologi dalam Penyunting-Selepas Automatik', 'mn': 'Терминологийг автоматтын дараа засварлах хязгаарлалт', 'mt': 'L-inkorporazzjoni ta’ Restrizzjonijiet Terminoloġiċi f’Post-Editar Awtomatiku', 'ml': 'ടെര്\u200dമിനോളജി കോണ്\u200dട്രെന്റുകള്\u200d സ്വയം പിന്നോട്ട് എഡിറ്റിങില്\u200d കൂട്ടുന്നു', 'no': 'Inkorporering av terminologiske begrensningar i automatisk post- redigering', 'pl': 'Włączanie ograniczeń terminologicznych do automatycznej edycji post-edycji', 'ro': 'Incorporarea constrângerilor terminologice în editarea automată', 'si': 'ස්වයංක්\u200dරිය පොස්ට් සංපාදනය කරනවා තාර්මිනෝලෝගික සීමාව', 'sr': 'Uključujući terminološke ograničenje u automatskom posledištu', 'so': 'Waxbarashada Terminology in Automatic Editing', 'sv': 'Inf√∂rande av terminologibegr√§nsningar i automatisk efterredigering', 'ta': 'Incorporating Terminology Constraints in Automatic Post-Editing', 'ur': 'ترمیمینولوژی محدودیت', 'uz': 'Terminalogni avtomatik tahrirlash', 'vi': 'KCharselect unicode block name', 'bg': 'Включване на терминологични ограничения в автоматичното последващо редактиране', 'da': 'Inddragelse af terminologibegrænsninger i automatisk efterredigering', 'hr': 'Uključujući terminološke ograničenje u automatskom posledištu', 'nl': 'Opnemen van terminologiebeperkingen in automatische nabewerking', 'de': 'Einbeziehung von TerminologiebeschrĂ¤nkungen in die automatische Nachbearbeitung', 'fa': 'محدودیت ترمینالوژی در محدودیت بعد از ویرایش خودکار', 'id': 'Menginkorporasi Kebatasan Terminologi dalam Pengeditan Otomatis', 'ko': '자동 사후 편집에 용어 구속조건 추가하기', 'sw': 'Kuingiza Mashitaka ya Terminalology katika Mhariri wa Ufaransa', 'tr': 'Otomatik Post Editlemekde Terminologiýa Buýruklar', 'af': 'Inkorporeer Terminologie Begrense in Outomatiese Post- Redigering', 'am': 'አውቶማቲክ', 'hy': 'Comment', 'az': 'Avtomatik Sonra D√ºz…ôltm…ôsind…ô Terminoloji Qƒ±dƒ±rlarƒ±', 'bn': 'স্বয়ংক্রিয় পোস্ট সম্পাদনায় টার্মিনোলজি কনস্ট্রেন্ট', 'bs': 'Uključujući terminološke ograničenje u automatskim posledicama', 'ca': 'Incorporar restriccions de terminologia en la postedició automàtica', 'cs': 'Začlenění omezení terminologie do automatického posteditování', 'et': 'Terminoloogia piirangute lisamine automaatsesse järeltöötlusse', 'fi': 'Terminologiarajoitusten sisällyttäminen automaattiseen jälkimuokkaukseen', 'sq': 'Përmbajtja e kufizimeve të terminologjisë në Posteditimin Automatik', 'sk': 'Vključevanje terminoloških omejitev v samodejno postno urejanje', 'ha': 'KCharselect unicode block name', 'jv': 'miter', 'he': 'מכיל מחסומות טרמינולוגיה בעורגה אוטומטית לאחר', 'bo': 'རང་འགུལ་གྱི་ཤུལ་བསྒྱུར་བཅོས་ནང་དུ་ཚུད་སྒྲིག་འཇུག་མཐའ་རིམ་ལུགས་ཚད་གཞུང་'}
{'en': 'Users of machine translation (MT) may want to ensure the use of specific lexical terminologies. While there exist techniques for incorporating terminology constraints during inference for MT, current APE approaches can not ensure that they will appear in the final translation. In this paper, we present both autoregressive and non-autoregressive models for lexically constrained APE, demonstrating that our approach enables preservation of 95 % of the terminologies and also improves translation quality on English-German benchmarks. Even when applied to lexically constrained MT output, our approach is able to improve preservation of the terminologies. However, we show that our models do not learn to copy constraints systematically and suggest a simple data augmentation technique that leads to improved performance and robustness.', 'ar': 'قد يرغب مستخدمو الترجمة الآلية (MT) في ضمان استخدام مصطلحات معجمية معينة. على الرغم من وجود تقنيات لدمج قيود المصطلحات أثناء الاستدلال على الترجمة الآلية ، فإن مناهج APE الحالية لا يمكنها ضمان ظهورها في الترجمة النهائية. في هذه الورقة ، نقدم كلًا من نماذج الانحدار الذاتي وغير الانحدار الذاتي لـ APE المقيدة معجمًا ، مما يدل على أن نهجنا يتيح الحفاظ على 95 ٪ من المصطلحات ويحسن أيضًا جودة الترجمة وفقًا للمعايير الإنجليزية الألمانية. حتى عند تطبيقه على مخرجات الترجمة الآلية المقيدة معجمًا ، فإن نهجنا قادر على تحسين الحفاظ على المصطلحات. ومع ذلك ، نظهر أن نماذجنا لا تتعلم نسخ القيود بشكل منهجي ونقترح تقنية بسيطة لزيادة البيانات تؤدي إلى تحسين الأداء والمتانة.', 'pt': 'Os usuários de tradução automática (TA) podem querer garantir o uso de terminologias lexicais específicas. Embora existam técnicas para incorporar restrições de terminologia durante a inferência para MT, as abordagens atuais de APE não podem garantir que elas apareçam na tradução final. Neste artigo, apresentamos modelos autorregressivos e não autorregressivos para APE lexicalmente restrito, demonstrando que nossa abordagem permite a preservação de 95% das terminologias e também melhora a qualidade da tradução em benchmarks inglês-alemão. Mesmo quando aplicada à saída de TA com restrição léxica, nossa abordagem é capaz de melhorar a preservação das terminologias. No entanto, mostramos que nossos modelos não aprendem a copiar restrições sistematicamente e sugerimos uma técnica simples de aumento de dados que leva a um melhor desempenho e robustez.', 'fr': "Les utilisateurs de la traduction automatique (TA) peuvent vouloir s'assurer de l'utilisation de terminologies lexicales spécifiques. Bien qu'il existe des techniques pour intégrer les contraintes terminologiques lors de l'inférence pour la traduction automatique, les approches APE actuelles ne peuvent garantir qu'elles apparaîtront dans la traduction finale. Dans cet article, nous présentons des modèles autorégressifs et non autorégressifs pour l'APE à contraintes lexicales, démontrant que notre approche permet de préserver 95\xa0% des terminologies et améliore également la qualité de la traduction sur les benchmarks anglais-allemand. Même lorsqu'elle est appliquée à des sorties de TA à contraintes lexicales, notre approche est capable d'améliorer la préservation des terminologies. Cependant, nous montrons que nos modèles n'apprennent pas à copier systématiquement les contraintes et nous suggérons une technique simple d'augmentation des données qui permet d'améliorer les performances et la robustesse.", 'es': 'Es posible que los usuarios de traducción automática (MT) deseen garantizar el uso de terminologías léxicas específicas. Si bien existen técnicas para incorporar restricciones terminológicas durante la inferencia de MT, los enfoques actuales de APE no pueden garantizar que aparezcan en la traducción final. En este artículo, presentamos modelos autorregresivos y no autorregresivos para APE con restricciones léxicas, lo que demuestra que nuestro enfoque permite preservar el 95% de las terminologías y también mejora la calidad de la traducción en los puntos de referencia inglés-alemán. Incluso cuando se aplica a la producción de MT con restricciones léxicas, nuestro enfoque puede mejorar la conservación de las terminologías. Sin embargo, demostramos que nuestros modelos no aprenden a copiar restricciones de forma sistemática y sugerimos una técnica simple de aumento de datos que mejora el rendimiento y la robustez.', 'ja': '機械翻訳（ MT ）のユーザーは、特定の語彙用語の使用を確実にすることを望むかもしれない。MTの推論中に用語の制約を組み込むための技術があるが、現在の類人猿のアプローチでは、それらが最終的な翻訳に現れることは保証できない。この論文では、語彙的に制約された類人猿のための自己回帰モデルと非自己回帰モデルの両方を提示し、私たちのアプローチが95%の用語の保存を可能にし、また英語-ドイツ語のベンチマークの翻訳品質を向上させることを示しています。語彙的に制約されたMT出力に適用された場合でも、当社のアプローチは用語の保存を改善することができます。しかし、私たちのモデルは制約を体系的にコピーすることを学んでおらず、パフォーマンスと堅牢性の向上につながる単純なデータ拡張技術を提案しています。', 'zh': '机器翻译 (MT) 之用户庶几保用特定之词汇术语。 虽在机器翻译理入术语约束之术,而APE法不能保其终译也。 本文中,发词汇受限APE自归非自,证吾法存95%术语,并增英语 - 德语准译。 虽应用于词汇限之机器翻译,吾法亦能改善术语者存之。 然则吾形无系统地复制约束,立简数以益术,以成性鲁棒性。', 'hi': 'मशीन अनुवाद (एमटी) के उपयोगकर्ता विशिष्ट लेक्सिकल शब्दावली के उपयोग को सुनिश्चित करना चाह सकते हैं। जबकि एमटी के लिए अनुमान के दौरान शब्दावली बाधाओं को शामिल करने के लिए तकनीकें मौजूद हैं, वर्तमान एपीई दृष्टिकोण यह सुनिश्चित नहीं कर सकते हैं कि वे अंतिम अनुवाद में दिखाई देंगे। इस पेपर में, हम लेक्सिकल रूप से विवश एपीई के लिए ऑटोरिग्रेसिव और गैर-ऑटोरिग्रेसिव मॉडल दोनों प्रस्तुत करते हैं, यह प्रदर्शित करते हुए कि हमारा दृष्टिकोण 95% शब्दावली के संरक्षण को सक्षम बनाता है और अंग्रेजी-जर्मन बेंचमार्क पर अनुवाद की गुणवत्ता में भी सुधार करता है। यहां तक कि जब लेक्सिकल रूप से विवश एमटी आउटपुट पर लागू किया जाता है, तो हमारा दृष्टिकोण शब्दावली के संरक्षण में सुधार करने में सक्षम है। हालांकि, हम दिखाते हैं कि हमारे मॉडल बाधाओं को व्यवस्थित रूप से कॉपी करना नहीं सीखते हैं और एक साधारण डेटा संवर्धन तकनीक का सुझाव देते हैं जो बेहतर प्रदर्शन और मजबूती की ओर जाता है।', 'ru': 'Пользователи машинного перевода (МП) могут пожелать обеспечить использование конкретных лексических терминов. Хотя существуют методы включения терминологических ограничений во время вывода для MT, текущие подходы APE не могут гарантировать, что они появятся в окончательном переводе. В этой статье мы представляем как авторегрессивные, так и не-авторегрессивные модели для лексически ограниченных ОБЕЗЬЯН, демонстрируя, что наш подход позволяет сохранить 95% терминологии, а также улучшает качество перевода на англо-немецких эталонах. Даже при применении к лексически ограниченному выходу МТ наш подход способен улучшить сохранение терминологии. Тем не менее, мы показываем, что наши модели не учатся систематически копировать ограничения и предлагаем простой метод дополнения данных, который приводит к улучшению производительности и надежности.', 'ga': 'B’fhéidir gur mhaith le húsáideoirí aistriúcháin meaisín (MT) a chinntiú go n-úsáidfear téarmaíocht ar leith foclóireachta. Cé go bhfuil teicníochtaí ann chun srianta téarmaíochta a ionchorprú le linn tátail do MT, ní féidir le cur chuige reatha APE a chinntiú go mbeidh siad le feiceáil san aistriúchán deiridh. Sa pháipéar seo, cuirimid i láthair múnlaí uath-aischéimnitheacha agus neamh-uathchéimnitheacha le haghaidh APE atá srianta ó thaobh na foclóireachta de, rud a thaispeánann go gcumasaíonn ár gcur chuige 95% de na téarmaíochtaí a chaomhnú agus go bhfeabhsaíonn sé cáilíocht aistriúcháin ar thagarmharcanna Béarla-Gearmáinis. Fiú nuair a chuirtear i bhfeidhm é ar aschur MT atá srianta ó thaobh na foclóireachta de, tá ár gcur chuige in ann caomhnú na dtéarmaí a fheabhsú. Léirímid, áfach, nach bhfoghlaimíonn ár samhlacha conas srianta a chóipeáil go córasach agus go molaimid teicníc shimplí mhéadaithe sonraí as a dtagann feidhmíocht agus stóinseacht fheabhsaithe.', 'hu': 'A gépi fordítás (MT) felhasználói biztosítani szeretnék a speciális lexikai terminológiák használatát. Bár léteznek technikák a terminológiai korlátozások beépítésére a MT következtetésekor, a jelenlegi APE megközelítések nem biztosítják, hogy azok megjelenjenek a végleges fordításban. Jelen tanulmányban bemutatjuk az autoregresszív és nem autoregresszív modelleket a lexikailag korlátozott APE esetében, bizonyítva, hogy megközelítésünk lehetővé teszi a terminológia 95%-ának megőrzését, valamint javítja a fordítási minőséget az angol-német referenciaértékeken. Még akkor is, ha lexikailag korlátozott MT kimenetre alkalmazzuk, megközelítésünk képes javítani a terminológia megőrzését. Megmutatjuk azonban, hogy modelleink nem tanulják meg rendszeresen másolni a korlátozásokat, és egy egyszerű adatbővítési technikát javasolnak, amely javítja a teljesítményt és a robusztusságot.', 'el': 'Οι χρήστες μηχανικής μετάφρασης (ΜΤ) μπορεί να θέλουν να εξασφαλίσουν τη χρήση συγκεκριμένων λεξικών ορολογίων. Ενώ υπάρχουν τεχνικές για την ενσωμάτωση των περιορισμών ορολογίας κατά την εξαγωγή των συμπερασμάτων για τη ΜΤ, οι τρέχουσες προσεγγίσεις APE δεν μπορούν να εξασφαλίσουν ότι θα εμφανιστούν στην τελική μετάφραση. Στην παρούσα εργασία, παρουσιάζουμε τόσο αυτοανακριτικά όσο και μη αυτοανακριτικά μοντέλα για λεξικά περιορισμένα ΑΠΕ, αποδεικνύοντας ότι η προσέγγισή μας επιτρέπει τη διατήρηση 95% των ορολογίων και βελτιώνει επίσης την ποιότητα της μετάφρασης σε αγγλο-γερμανικά κριτήρια αναφοράς. Ακόμη και όταν εφαρμόζεται σε λεξικά περιορισμένη παραγωγή ΜΤ, η προσέγγισή μας είναι σε θέση να βελτιώσει τη διατήρηση των ορολογίων. Ωστόσο, αποδεικνύουμε ότι τα μοντέλα μας δεν μαθαίνουν να αντιγράφουν συστηματικά τους περιορισμούς και προτείνουν μια απλή τεχνική αύξησης δεδομένων που οδηγεί σε βελτιωμένη απόδοση και ανθεκτικότητα.', 'ka': 'მაქინის გაგრძელების მომხმარებელი (MT) შეიძლება უნდა დარწმუნოთ განსაკუთრებული ლექსიკალური ტერმინოლოგიების გამოყენება. მაგრამ არსებობს ტერმინოლოგიური შედგა MT-ის ინფრენციის განმავლობაში, მიმდინარე APE მიღებები არ შეუძლიათ დარწმუნოთ, რომ ისინი დასაწყისში მოხდება. ამ დოკუნეში ჩვენ აჩვენ აჩვენებთ ლექსიკურად დარწყებული APE-ის ავტორეგრესიგური და არ-ავტორეგრესიგური მოდელები, რომლებიც ჩვენი პროგრამის შესაძლებლობა ტერმინოლოგიების 95%-ის შესაძლებლობა და ასევე გაუფლებ კიდევ, როდესაც ლექსიკურად შეუძლებელია MT გამოყენებას, ჩვენი პროგრამა შეუძლებელია ტერმინოლოგიების შესახებ. მაგრამ ჩვენ ჩვენი მოდელები არ ვისწავლოთ სისტემატიკურად კოპირაციას და უკეთესი მონაცემების აგგენტაციის ტექნოგია, რომელიც უფრო უფრო მუშაობას და ძალიან გა', 'it': "Gli utenti della traduzione automatica (MT) potrebbero voler garantire l'uso di terminologie lessicali specifiche. Sebbene esistano tecniche per incorporare vincoli terminologici durante l'inferenza per MT, gli attuali approcci APE non possono garantire che essi appaiano nella traduzione finale. In questo articolo presentiamo sia modelli autoregressivi che non autoregressivi per APE lessicamente vincolati, dimostrando che il nostro approccio consente la conservazione del 95% delle terminologie e migliora anche la qualità della traduzione sui benchmark inglese-tedesco. Anche se applicato a output MT lessicamente vincolati, il nostro approccio è in grado di migliorare la conservazione della terminologia. Tuttavia, mostriamo che i nostri modelli non imparano a copiare sistematicamente i vincoli e suggeriscono una semplice tecnica di aumento dei dati che porta a migliorare le prestazioni e la robustezza.", 'lt': 'Mašininio vertimo (MT) naudotojai gali pageidauti užtikrinti, kad būtų naudojamos specialios leksinės terminologijos. While there exist techniques for incorporating terminology constraints during inference for MT, current APE approaches cannot ensure that they will appear in the final translation.  Šiame dokumente pristatome tiek autoregresinius, tiek ne autoregresinius modelius, skirtus lexiškai apribotai APE, įrodančius, kad mūsų metodas leidžia išsaugoti 95 % terminologijų ir taip pat gerina vertimo kokybę anglų ir vokiečių lyginamuosiuose rodikliuose. Net kai jis taikomas lengvai ribotam MT išėjimui, mūsų metodas gali pagerinti terminologijų išsaugojimą. Tačiau mes rodome, kad mūsų modeliai nesugeba sistemingai kopijuoti apribojimų ir siūlo paprastą duomenų didinimo metodą, kuris padėtų gerinti veiksmingumą ir patikimumą.', 'mk': 'Корисниците на машински превод (MT) можеби сакаат да осигураат употреба на специфични лексикални терминологии. Иако постојат техники за вклучување на терминолошки ограничувања за време на инференцијата за МТ, актуелните пристапи на АПЕ не можат да осигураат дека ќе се појават во конечниот превод. Во овој весник, претставуваме и авторегресивни, и неавторегресивни модели за лексички ограничени АПЕ, демонстрирајќи дека нашиот пристап овозможува зачувување на 95 отсто од терминологиите и исто така го подобрува квалитетот на преводот на англиско-германските референтни значки. Even when applied to lexically constrained MT output, our approach is able to improve preservation of the terminologies.  Сепак, покажуваме дека нашите модели не учат да ги копираат ограничувањата систематски и предлагаат едноставна техника за зголемување на податоците која води до подобрена перформанса и robustness.', 'kk': 'Компьютердің аудармасының (MT) пайдаланушылары керек лексикалық терминологияларды қолдану керек болуы мүмкін. MT- ге аудару кезінде терминологиялық шектеулерді ендіру технологиялар бар болғанда, назардағы APE- нің жағдайлары соңғы аудармасында көрсетілетінін тексеруге болмайды. Бұл қағазда, лексикалық шектелген APE үшін авторегрессиялық және авторегрессиялық үлгілерді көрсетедік. Біздің тәсіліміздің терминологиялардың 95% сақтауға мүмкіндік береді және ағылшын- неміс бағдарламалардың Лексикалық MT шығысына шектеу үшін қолданылса да, біздің тәсіліміз терминологияларды сақтауға болады. Бірақ біз үлгілеріміздің жүйелік шектеулерді көшірмелеуді оқылмайды және қарапайым деректерді көтеру техникасын көрсету үшін жұмыс істеу және қуаттылығын жақсы жасайтын.', 'ml': 'മെഷിന്\u200d പരിഭാഷ (എംടി) ഉപയോക്താക്കള്\u200d പ്രത്യേകം ലെക്സിക്കല്\u200d ടെര്\u200dമിനോളജികള്\u200d ഉപയോഗിക്കുന്നത് ഉറപ്പാക്ക എംടിയുടെ പരിഭാഗത്തിനുള്ള സമയത്ത് ടെര്\u200dമിനോളജി നിര്\u200dബന്ധങ്ങള്\u200d ചേര്\u200dക്കുന്നതിനുള്ള സാങ്കേതികവിദ്യകള്\u200d ഉണ്ടെങ്കില്\u200d, ഇപ്പോഴ In this paper, we present both autoregressive and non-autoregressive models for lexically constrained APE, demonstrating that our approach enables preservation of 95% of the terminologies and also improves translation quality on English-German benchmarks.  എംടി പുറത്ത് നിര്\u200dബന്ധിക്കപ്പെട്ടിരിക്കുന്നതിന് പോലും നമ്മുടെ സമ്പാദം ടെര്\u200dമിനോളജികളുടെ സംരക്ഷണത്തിന് മു എങ്കിലും നമ്മുടെ മോഡലുകള്\u200d സിസ്ട്രീമികമായി നിര്\u200dബന്ധങ്ങള്\u200d പകര്\u200dത്താന്\u200d പഠിക്കാന്\u200d പഠിക്കുന്നില്ല എന്നിട്ടും സാധാരണ വിവരങ്ങള്\u200d', 'ms': 'Pengguna terjemahan mesin (MT) mungkin ingin memastikan penggunaan terminologi leksikal khusus. Walaupun terdapat teknik untuk memasukkan keterangan terminologi semasa kesimpulan untuk MT, pendekatan APE semasa tidak dapat memastikan bahawa ia akan muncul dalam terjemahan terakhir. Dalam kertas ini, kami memperkenalkan kedua-dua model autoregressif dan bukan-autoregressif untuk APE yang dikuasai secara leksik, menunjukkan bahawa pendekatan kami memungkinkan penyimpanan 95% terminologi dan juga meningkatkan kualiti terjemahan pada tanda referensi Inggeris-Jerman. Walaupun bila dilaksanakan pada output MT yang dikuasai secara lexik, pendekatan kita mampu memperbaiki penyimpanan terminologi. Namun, kita menunjukkan bahawa model kita tidak belajar untuk salin keterangan secara sistematik dan menyarankan teknik peningkatan data sederhana yang membawa kepada prestasi dan kepekatan yang lebih baik.', 'mt': 'L-utenti tat-traduzzjoni bil-magna (MT) jistgħu jixtiequ jiżguraw l-użu ta’ terminoloġiji lexiċi speċifiċi. Filwaqt li jeżistu tekniki għall-inkorporazzjoni ta’ restrizzjonijiet terminoloġiċi matul l-inferenza għall-MT, l-approċċi attwali tal-APE ma jistgħux jiżguraw li jidhru fit-traduzzjoni finali. F’dan id-dokument, qed nippreżentaw kemm mudelli awtoregressivi kif ukoll mhux awtoregressivi għal APE ristretta b’mod lexiku, li juru li l-approċċ tagħna jippermetti l-preservazzjoni ta’ 95% tat-terminoloġiji u jtejjeb ukoll il-kwalità tat-traduzzjoni fuq il-punti ta’ riferiment Ingliż-Ġermaniżi. Anki meta applikat għall-output MT ristrett b’mod lexiku, l-approċċ tagħna huwa kapaċi jtejjeb il-preżervazzjoni tat-terminoloġiji. Madankollu, a ħna nuru li l-mudelli tagħna ma jitgħallmux jikkopjaw ir-restrizzjonijiet sistematikament u jissuġġerixxu teknika sempliċi ta’ żieda tad-dejta li twassal għal prestazzjoni u robustezza mtejba.', 'mn': 'Компьютерийн орчуулалтын хэрэглэгчид тодорхой лексикийн терминологи ашиглахыг хүсч болно. MT-ийн халдварын үед терминологийн хязгаарлалтыг нэгтгэх технологиуд байдаг ч одоогийн APE-ийн арга баримтууд эцсийн орчлолд гарч ирэхийг баталж чадахгүй. Энэ цаасан дээр бид Лексийн хязгаарлагдсан APE-ын автоregressive болон автоregressive загваруудыг харуулж байна. Бидний арга загвар терминологийн 95% нь хадгалах боломжтой, мөн Англи-Германы хэмжээний хэмжээсүүд дээр орчуулах чадварыг сайжруулж байна. Лексийн хэмжээнд хязгаарлагдсан MT гаралт дээр хэрэглэгдэхэд ч бидний арга нь терминологийг хадгалах боломжтой. Гэхдээ бидний загварууд систематик хязгаарыг хуулбарлаж суралцдаггүй гэдгийг харуулж, хөгжүүлэх, хүчтэй байдлыг сайжруулдаг энгийн өгөгдлийн нэмэлт техник гэдгийг сануулж байна.', 'pl': 'Użytkownicy tłumaczenia maszynowego (MT) mogą chcieć zapewnić stosowanie określonych terminologii leksykalnych. Chociaż istnieją techniki włączania ograniczeń terminologicznych podczas wnioskowania dla MT, obecne podejścia APE nie mogą zapewnić, że pojawią się one w końcowym tłumaczeniu. W niniejszym artykule przedstawiamy zarówno autoregresywne, jak i nieautoresywne modele dla leksycznie ograniczonych APE, pokazując, że nasze podejście umożliwia zachowanie 95% terminologii, a także poprawę jakości tłumaczeń na angielsko-niemieckich wskaźnikach referencyjnych. Nawet w przypadku zastosowania do wyjścia MT ograniczonego leksycznie, nasze podejście jest w stanie poprawić zachowanie terminologii. Pokazujemy jednak, że nasze modele nie uczą się systematycznie kopiować ograniczeń i sugerują prostą technikę powiększania danych, która prowadzi do poprawy wydajności i solidności.', 'no': 'Brukarar av maskinsomsetjing (MT) kan vera sikker på at bruken av spesifikke leksiske terminologiar skal vera bruka. Mens det finst teknikk for å inkludere terminologiske begrensningar under infeksjon av MT, kan det ikkje sikra at dei vert viste i den siste omsetjinga. I denne papiret presenterer vi både autoregressiv og ikkje-autoregressiv modeller for leksisk begrenset APE, som demonstrerer at tilnærminga vårt kan lagra 95 % av terminologiane og også forbedra omsetjingskvalitet på engelsk-tysk benchmarker. Sjølv når det er brukt til lysisk begrenset MT-utdata, kan tilnærminga vårt forbetra konservasjonen av terminologiane. Men vi viser at modelane våre ikkje lærer å kopiera begrensningar systematisk og foreslår ein enkel dataaugmentasjonstekk som fører til forbetra utvikling og kraftighet.', 'ro': 'Utilizatorii traducerii automate (MT) ar putea dori să asigure utilizarea unor terminologii lexicale specifice. Deși există tehnici pentru încorporarea constrângerilor terminologice în timpul inferenței pentru MT, abordările APE actuale nu pot asigura că acestea vor apărea în traducerea finală. În această lucrare, prezentăm atât modele autoregresive, cât și non-autoregresive pentru APE cu constrângere lexicală, demonstrând că abordarea noastră permite păstrarea a 95% din terminologii și, de asemenea, îmbunătățește calitatea traducerii pe criteriile de referință engleză-germană. Chiar și atunci când se aplică la ieșirea MT constrânsă lexic, abordarea noastră este capabilă să îmbunătățească conservarea terminologiilor. Cu toate acestea, demonstrăm că modelele noastre nu învață să copieze constrângerile în mod sistematic și sugerează o tehnică simplă de augmentare a datelor care duce la îmbunătățirea performanței și robusteții.', 'sr': 'Korisnici prevoda mašine (MT) možda žele da osiguraju upotrebu specifičnih leksičkih terminologija. Iako postoje tehnike za uključenje terminologijskih ograničenja tijekom infekcije MT-a, trenutni pristupi APE-a ne mogu osigurati da će se pojaviti u konačnom prevodu. U ovom papiru predstavljamo i autoregresivne i ne-autoregresivne modele za leksički ograničene APE-e, pokazujući da naš pristup omogućava čuvanje 95% terminologija i poboljšavanje kvalitete prevođenja na engleskim-nemačkim kriterijama. Čak i kad se primjenjuje na leksički ograničeni izlaz MT-a, naš pristup može poboljšati zaštitu terminologija. Međutim, mi pokazujemo da naše modele ne nauče da kopiraju ograničenja sistematski i predlažemo jednostavnu tehniku povećanja podataka koja vodi ka poboljšanju izvođenja i robustnosti.', 'so': 'Isticmaalayaasha turjumidda machineyda (MT) waxay suurtagal yihiin in ay isticmaalaan isticmaalka terminologies gaar ah ee leksikal. Intii ay jirto qalabka ku qoran baaritaanka terminology waqtiga uu MT ka baaraandegayo, dhaqdhaqaalaha APE waxey ka hubin kari waayaan in turjumaadda ugu dambeeya ay ka muuqan doonaan. In this paper, we present both autoregressive and non-autoregressive models for lexically constrained APE, demonstrating that our approach enables preservation of 95% of the terminologies and also improves translation quality on English-German benchmarks.  Xataa marka lagu codsado soo bixinta MT ee la qasbay, dhaqdhaqaalahayaga ayaa awoodi kara inuu horumariyo ilaalinta terminologies. Si kastaba ha ahaatee waxaynu tusnaynaa in modelalkayagu uusan si habar ah u barin inay koobaan xaduudaha, waxaana soo jeedinayaa teknikada kordhiska macluumaadka oo fudud oo ku hagaajiya horumarinta tababarka iyo waxyaabaha.', 'sv': 'Användare av maskinöversättning (MT) kanske vill se till att specifika lexikala terminologier används. Även om det finns tekniker för att införliva terminologibegränsningar under slutresultatet för MT, kan nuvarande APE-metoder inte garantera att de kommer att visas i den slutliga översättningen. I denna uppsats presenterar vi både autoregressiva och icke-autoregressiva modeller för lexiskt begränsade APE, vilket visar att vårt tillvägagångssätt möjliggör bevarande av 95% av terminologin och förbättrar översättningskvaliteten på engelsk-tyska riktmärken. Även när det tillämpas på lexikalt begränsad MT-output kan vårt tillvägagångssätt förbättra bevarandet av terminologin. Vi visar dock att våra modeller inte lär sig att kopiera begränsningar systematiskt och föreslår en enkel dataförstärkningsteknik som leder till förbättrad prestanda och robusthet.', 'si': 'පද්ධතිය පරිවර්තනය (MT) ප්\u200dරයෝජකයන්ට පුළුවන් විශේෂ ලෙක්සිකල් පරිවර්තනය භාවිතා කරන්න ඕන MT වෙනුවෙන් පරීක්ෂණය වෙනුවෙන් අවශ්\u200dය විධානය සම්බන්ධ විධානය සම්බන්ධ වෙනුවෙන් තාක්ෂණය තියෙනවා නමුත්, ප්\u200d මේ පත්තරේ අපි ස්වයංක්\u200dරීය සහ නොස්වයංක්\u200dරීයාත්මක ප්\u200dරමාණය සඳහා ප්\u200dරතික්\u200dරියාත්මක වෙනුවෙන් ප්\u200dරතික්\u200dරියාත්මක කරන්න, ප්\u200dරතික්\u200dරියාත්මක කරන්නේ අපේ  ලෙක්සිකාලික විශේෂයෙන් MT ප්\u200dරවෘත්තිය සඳහා භාවිත කරන්න පුළුවන් වුනත්, අපේ ප්\u200dරවෘත්තිය තර්මින් ඒත් අපි පෙන්වන්නේ අපේ මොඩේල් එක පද්ධතියෙන් ප්\u200dරතිකාර කරගන්න ඉගෙන ගන්නේ නැහැ ඒ වගේම සාමාන්\u200dය දත්ත විශාල විද්\u200dයාප්\u200dත', 'ta': 'இயந்திரத்தின் மொழிபெயர்ப்பாளர்கள் (MT) குறிப்பிட்ட லெக்சிக்கல் முனையத்தை பயன்படுத்த வேண்டும். MT க்கான நோய் கட்டுப்பாட்டில் சேர்க்கும் போது தற்போது APE செயல்பாடுகள் கடைசி மொழிபெயர்ப்பில் தெரிய முடியாது. இந்த காக்கியத்தில், நாம் தானியங்கி கட்டுப்படுத்தும் மற்றும் தானியங்கி கட்டுப்பாடு மாதிரிகளை காண்பிக்கிறோம். எங்கள் வழிமுறையை முனையத்தில் 95% பேண்டும்  எம்டி வெளியீட்டிற்கு செயல்படுத்தப்பட்ட போதும், முனையத்தைப் பாதுகாப்பு முடியும். ஆனால், நாம் காண்பிக்கிறோம் என்றால், எங்கள் மாதிரிகள் கணினியில் கட்டுப்பாடுகளை நகலெடுக்க முடியாது மற்றும் சுலபமான தரவு மேற்படுத', 'ur': 'ماشین ترجمہ (MT) کا کارساز ممکن ہے کہ مخصوص لکسیکل ٹریمولوژ کا استعمال مطمئن کرنا چاہے۔ While there are techniques for incorporating terminology constraints during inference for MT, current APE approaches cannot ensure that they will appear in the final translation. اس کاغذ میں ہم لکھی ہوئی APE کے لئے autoregressive اور non-autoregressive موڈل کو پیش کرتے ہیں، نشان دیتے ہیں کہ ہمارا طریقہ ٹریمولوژوں میں 95% کی حفاظت کرتا ہے اور انگلیسی-جرمن بانچمارک پر ترجمہ کی کیفیت بھی بہتر کرتا ہے۔ Even when applied to lexically restricted MT output, our approach can improve conservation of the terminology. لیکن ہم نشان دیتے ہیں کہ ہمارے مدلکوں سیستماتیک طریقے سے محدودیت کی کاپی نہیں سکتے اور ایک ساده ڈیٹا اضافہ ٹیکنیک کی پیشنهاد کرتی ہے جو عملکرد اور قوت کے ساتھ اضافہ کرتی ہے۔', 'uz': "Name MT uchun murakkab bo'lgan terminalogik tartibiqlarini birlashtirish uchun teknologiya mavjud boʻlsa, joriy APE usullarini охиратда tarjima qilishga ishonch hosil qilmaydi. Bu qogʻozda, biz leksik qo'llangan APE uchun avtomatik boshqaruvchi va avtomatik boshqaruvchi modellarni ko'rganamiz, bizning usuli terminologiyalarning 95% davomida saqlash imkoniyatlarini bajaradi va ingliz- Olmonchadan foydalanishni bajaradi. Ko'pchilik MT tashkilotlariga qoʻllanilganda, bizning qismimiz terminologlarni saqlash mumkin. Lekin, biz modellarimiz tizim tarkibida qanday nusxa olishni o'rganimaymiz va oddiy maʼlumot soʻzlashtirish teknologiga imkoniyat qilamiz, bajarishni bajarishi va ustiqligini oshirish mumkin.", 'vi': 'Người dùng dịch cỗ máy (MTV) có thể muốn đảm bảo sử dụng các ngôn ngữ văn học cụ thể. Trong khi có các kỹ thuật gia nhập các ràng buộc về thuật ngữ trong thời hạn của MTV, các phương pháp APE hiện thời không thể đảm bảo rằng chúng sẽ xuất hiện trong phiên dịch cuối cùng. Trong tờ giấy này, chúng tôi giới thiệu cả các mô hình tự vệ lẫn không tự động của APE bị hạn chế, cho thấy phương pháp của chúng tôi giúp bảo vệ được tê bố số, và cũng cải thiện chất lượng dịch trên tiêu chuẩn Anh-Đức. Ngay cả khi áp dụng vào các sản phẩm MTV bị hạn từ vựng, phương pháp của chúng ta vẫn có thể cải tiến sự bảo tồn các mãi học. Tuy nhiên, chúng tôi cho thấy các mẫu của chúng tôi không học cách chép các giới hạn một cách thường xuyên và đề xuất một kỹ thuật gia tăng dữ liệu đơn giản dẫn tới hiệu quả và độ bền vững.', 'bg': 'Потребителите на машинен превод (МТ) може да искат да осигурят използването на специфични лексикални терминологии. Въпреки че съществуват техники за включване на терминологични ограничения по време на заключенията за МТ, настоящите подходи на ЕПП не могат да гарантират, че те ще се появят в окончателния превод. В настоящата статия представяме както авторегресивни, така и неавторегресивни модели за лексично ограничени АПЕ, като демонстрираме, че нашият подход позволява запазване на 95% от терминологиите и подобрява качеството на превода по англо-немски референтни показатели. Дори когато се прилага за лексически ограничени МТ изходи, нашият подход е в състояние да подобри запазването на терминологиите. Въпреки това, ние показваме, че нашите модели не се научават да копират ограниченията систематично и предлагат проста техника за увеличаване на данните, която води до подобрена производителност и здравина.', 'da': 'Brugere af maskinoversættelse (MT) ønsker måske at sikre brugen af specifikke leksikologiske terminologier. Selv om der findes teknikker til at indarbejde terminologibegrænsninger under konklusionen for MT, kan nuværende APE-metoder ikke sikre, at de vil blive vist i den endelige oversættelse. I denne artikel præsenterer vi både autoregressive og ikke-autoregressive modeller for leksiksk begrænset APE, hvilket viser, at vores tilgang muliggør bevarelse af 95% af terminologierne og også forbedrer oversættelseskvaliteten på engelsk-tysk benchmarks. Selv når det anvendes på leksiksk begrænset MT output, er vores tilgang i stand til at forbedre bevarelsen af terminologien. Vi viser dog, at vores modeller ikke lærer at kopiere begrænsninger systematisk og foreslår en simpel dataaugmentationsteknik, der fører til forbedret ydeevne og robusthed.', 'nl': 'Gebruikers van machinevertaling (MT) kunnen het gebruik van specifieke lexicale terminologieën willen waarborgen. Hoewel er technieken bestaan voor het opnemen van terminologische beperkingen tijdens inferentie voor MT, kunnen de huidige APE-benaderingen niet garanderen dat deze in de uiteindelijke vertaling zullen verschijnen. In dit artikel presenteren we zowel autoregressieve als niet-autoregressieve modellen voor lexicaal beperkte APE, waaruit blijkt dat onze aanpak het behoud van 95% van de terminologieën mogelijk maakt en ook de vertaalkwaliteit verbetert op Engels-Duitse benchmarks. Zelfs bij toepassing op lexicaal beperkte MT-output is onze aanpak in staat om het behoud van de terminologieën te verbeteren. We laten echter zien dat onze modellen niet leren om beperkingen systematisch te kopiëren en suggereren een eenvoudige data augmentation techniek die leidt tot verbeterde prestaties en robuustheid.', 'de': 'Benutzer der maschinellen Übersetzung (MT) möchten möglicherweise die Verwendung spezifischer lexikalischer Terminologien sicherstellen. Zwar gibt es Techniken zur Einbeziehung terminologischer Einschränkungen bei der Inferenz für MT, aber die derzeitigen APE-Ansätze können nicht sicherstellen, dass sie in der endgültigen Übersetzung erscheinen. In diesem Beitrag stellen wir sowohl autoregressive als auch nicht autoregressive Modelle für lexikalisch eingeschränkte APE vor, die zeigen, dass unser Ansatz die Erhaltung von 95% der Terminologien ermöglicht und die Übersetzungsqualität auf englisch-deutschen Benchmarks verbessert. Selbst wenn wir auf lexikalisch eingeschränkte MT-Ausgabe angewendet werden, ist unser Ansatz in der Lage, die Erhaltung der Terminologien zu verbessern. Wir zeigen jedoch, dass unsere Modelle nicht lernen, Einschränkungen systematisch zu kopieren und eine einfache Datenauswertungstechnik vorschlagen, die zu verbesserter Leistung und Robustheit führt.', 'hr': 'Korisnici prevoda stroja (MT) možda žele osigurati uporabu specifičnih leksičkih terminologija. Iako postoje tehnike za uključenje ograničenja terminologije tijekom infekcije MT-a, trenutni pristupi APE-a ne mogu osigurati da će se pojaviti u konačnom prevodu. U ovom papiru predstavljamo i autoregresivne i ne-autoregresivne modele za leksički ograničene APE-e, pokazujući da naš pristup omogućava čuvanje 95% terminologija i poboljšavanje kvalitete prevođenja na standardima engleskog-njemačkog. Čak i kad se primjenjuje na leksički ograničeni izlaz MT-a, naš pristup može poboljšati očuvanje terminologija. Međutim, mi pokazujemo da naše modele ne uče sistematski kopirati ograničenja i predlažemo jednostavnu tehniku povećanja podataka koja dovodi do poboljšanja učinka i robustnosti.', 'sw': 'Watumiaji wa utafsiri wa mashine (MT) wanaweza kutaka kuhakikisha matumizi ya utambulisho maalum wa kiuchunguzi. Wakati kuna mbinu za kuingiza vizuizi vya ngono vya ngono wakati wa maambukizi ya MT, mbinu za sasa za APE haziweza kuhakikisha kuwa watajitokeza kwenye tafsiri ya mwisho. Katika karatasi hii, tunaweka mbinu za kudhibiti na zisizo na mamlaka za kujitegemea kwa ajili ya APE zilizolazimishwa kwa lexico, tunaonyesha kwamba mbinu yetu inawezesha kulinda asilimia 95 ya maadhimili na pia kuboresha ubora wa tafsiri kuhusu bendera za Kiingereza na Kijerumani. Hata pale ambapo kutumika kwa matokeo ya MT yanayolazimishwa kwa kemikali, hatua yetu inaweza kuboresha uhifadhi wa mitaani. However, we show that our models do not learn to copy constraints systematically and suggest a simple data augmentation technique that leads to improved performance and robustness.', 'fa': 'کاربران ترجمه ماشین (MT) ممکن است بخواهند استفاده از ترمینالوژی\u200cهای زبانی خاص را مطمئن کنند. در حالی که تکنولوژی وجود دارد که در طول بیماری MT محدودیت ترمینالوژی وجود دارد، دسترسی\u200cهای فعلی APE نمی\u200cتوانند مطمئن شوند که در ترجمه نهایی ظاهر خواهند شد. در این کاغذ، ما هر دو مدل\u200cهای خودگریسی و غیر خودگریسی را برای APE محدود به زبان نشان می\u200cدهیم، و نشان می\u200cدهیم که دستور ما به محافظت 95 درصد ترمینالوژی توان می\u200cدهد، و همچنین کیفیت ترجمه\u200cهای انگلیسی و آلمانی را بهتر می\u200cکند. حتی وقتی به نتیجه MT محدود به زبان استفاده می\u200cشود، دستور ما می\u200cتواند حفاظت ترمینالوژی را بهتر کند. ولی ما نشان می دهیم که مدلهای ما یاد نمی گیرند که محدودیت را سیستماتیک کپی کنیم و یک تکنیک افزایش داده ساده را پیشنهاد می دهیم که به عملکرد و ثابت پیشرفت می کند.', 'ko': '기계 번역(MT) 사용자는 특정한 어휘 용어를 사용하기를 원할 수도 있다.기계 번역 추리 과정에서 용어의 제약을 포함하는 기술이 존재하지만 현재의 APE 방법으로는 최종 번역에 나타나지 않는다.본고에서 우리는 어휘가 제한된 APE의 자귀환과 비자귀환 모델을 제시하여 우리의 방법이 95%의 용어를 보존할 수 있음을 증명하고 영어-독일어 기준의 번역의 질을 향상시켰다.어휘가 제한된 기계 번역 출력에 적용되더라도 우리의 방법은 용어의 보존을 개선할 수 있다.그러나 우리는 우리의 모델이 체계적으로 복제 제약을 배우지 않고 간단한 데이터 강화 기술을 제시하여 성능과 노봉성을 향상시켰다는 것을 보여준다.', 'tr': "Ullançy tenzim sistemini (MT) ullanyşylar spesifik terminologiýalaryň ullanyşyny barlamak isleýär. MT'iň hasaplanjak wagtynda terminologiýanyň hasaplanjak üçin teknikler bardyr. Häzirki APE golaýlary soňky terjimede görünip bolmagyny garaşyp bilmeýär. Bu kagyzda hem awtomatik-regressiv hem-autoregressiv modelleri hat edip görýäris. Bu ýazşymyzyň terminologlaryň 95% sagdyna mümkin edýändigini görkezýäris we hem Iňlis-Almanyň çerçewçiliklerinde terjime etijilerini gowuraýar. Hatda luksuz mümkin MT çizgisine uygulanan bolsa hem, terminologilary goramagymyz gowylaşdyryp biler. Ýöne, modellerimiziň sistematik ýagdaýlary kopyalamagy öwrenmeýändigini we üstünlik we güýçlendirmegi üçin basit maglumatlaryň ýetişdirilip tekniklerini maslahat berýäris.", 'sq': 'Përdoruesit e përkthimit të makinave (MT) mund të duan të sigurojnë përdorimin e terminologjive specifike lexike. Ndërsa ekzistojnë teknika për përfshirjen e kufizimeve terminologjike gjatë përfundimit për MT, qasjet aktuale të APE nuk mund të sigurojnë se ato do të shfaqen në përkthimin përfundimtar. Në këtë letër, ne paraqesim si modele autoregressive ashtu edhe jo-autoregressive për APE të kufizuar lexikisht, duke demonstruar se qasja jonë mundëson ruajtjen e 95% të terminologjive dhe gjithashtu përmirëson cilësinë e përkthimit në normat anglo-gjermane. Edhe kur zbatohet në output MT të kufizuar lexikisht, metoda jonë është në gjendje të përmirësojë ruajtjen e terminologjive. Megjithatë, ne tregojmë se modelet tona nuk mësojnë të kopjojnë kufizimet sistematikisht dhe sugjerojnë një teknikë të thjeshtë shtimi të të dhënave që çon në përmirësim të performancës dhe të qëndrueshmërisë.', 'af': "Gebruikers van masjien vertaling (MT) dalk mag wil hê na seker die gebruik van spesifieke leksiese terminologies. Alhoewel daar bestaan teknike vir die inkorporering van terminologies beheinings tydens inferensie vir MT, kan huidige APE-toegang nie seker dat hulle in die eindelike vertaling sal verskyn nie. In hierdie papier stel ons beide autoregressiewe en nie-autoregressiewe modele voor die lexiese beperkte APE, wat wys dat ons toegang 95% van die terminologies opslaan kan word en ook verbeter vertalingskwaliteit op Engels-Duitse benchmarke. Selfs wanneer toepassing is op lexiese beperkte MT uitvoer, kan ons toegang die bewaring van die terminologies verbeter. Maar ons wys dat ons modele nie leer om begrense sistematies te kopieer nie en voorstel 'n eenvoudige data augmentasie tekniks wat lei na verbeterde prestasie en robustheid.", 'id': 'Pengguna terjemahan mesin (MT) mungkin ingin memastikan penggunaan terminologi leksik spesifik. While there exist techniques for incorporating terminology constraints during inference for MT, current APE approaches cannot ensure that they will appear in the final translation.  Dalam kertas ini, kami mempersembahkan model autoregresif dan tidak autoregresif untuk APE yang dikuasai secara lexik, menunjukkan bahwa pendekatan kami memungkinkan memelihara 95% dari terminologi dan juga meningkatkan kualitas terjemahan pada benchmark Inggris-Jerman. Bahkan ketika diterapkan pada output MT yang dikuasai secara lexik, pendekatan kita mampu memperbaiki pemeliharaan terminologi. Namun, kami menunjukkan bahwa model kami tidak belajar untuk menyalin batas secara sistematis dan menyarankan teknik data yang sederhana meningkatkan yang mengarah ke prestasi dan kepekatan yang lebih baik.', 'am': 'የመኪና ትርጉም (MT) ተጠቃሚ የተጠቃሚ የሊክሲካል ተርሚኖጂዎችን እንዲጠቀም ይፈልጋል፡፡ የ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ በዚህ ገጽ፣ የራሳቸውን ሥልጣን እና ለሌክሲካዊ ግንኙነት አካባቢ አካባቢዎች እና የኢሜይል ምሳሌዎችን እናሳየዋለን፡፡ የግንኙነታችን ግንኙነት የ95% ተርሚሎጂዎችን እንዲጠበቅ እና በንግግሊዘኛ-የጀርመን-የግሪክ ደጋፊዎች ላይ ትርጉም ጥቅም እንዲያበዛል እናስታውቃለን፡፡ የ.አ.ቴ ውጤት በተገኘው ጊዜ እንኳ፣ የቴርሚኖሎጂን መጠበቅ ማሻሻል ይችላል፡፡ ነገር ግን ሞዴላዎቻችን በሥርዓት ግንኙነታችንን ለመቀልፍ እንዳይማሩ እና የድህነትን እና የልብስነትን ለመሻል የሚችል ቀላል የዳታ አካባቢ ቴክክኖስን እናሳውቃለን፡፡', 'bn': 'মেশিন অনুবাদ (এমটি) ব্যবহারকারীরা নিশ্চিত লেক্সিকাল টার্মিনোলজির ব্যবহার নিশ্চিত করতে চায়। এমটির সংক্রান্ত সময় টার্মিনোলজি নিষেধাজ্ঞা যোগাযোগ করার প্রযুক্তিগুলোর মধ্যে রয়েছে, তবে বর্তমান এপিই প্রযুক্তি নিশ্চিত করতে  এই কাগজটিতে আমরা স্বয়ংক্রিয়ভাবে নিয়ন্ত্রণ এবং স্বয়ংক্রিয়ভাবে নিয়ন্ত্রণের মডেল দেখাচ্ছি যে আমাদের প্রতিযোগিতা তার্মিনোলজির ৯৫% সংরক্ষণ করে এবং ইংরেজী জা এমএমটি আউটপুটের প্রযুক্তি ব্যবহার করা হলেও টার্মিনোলজির সংরক্ষণের ক্ষেত্রে আমাদের পদক্ষেপ উন্নতি করতে পারে। তবে আমরা দেখাচ্ছি যে আমাদের মডেল স্বাভাবিকভাবে নিয়মিত কপি করতে শিখে না এবং সাধারণ তথ্য যোগাযোগের প্রযুক্তির পরামর্শ দিচ্ছি যা প্', 'hy': 'Միգուցե մեքենայի թարգմանման (MT) օգտագործողները ուզում են վստահել հատուկ լեքսիկական տերմինոլոգիաների օգտագործումը: Մինչդեռ MT-ի հետևանքների ժամանակ տերմինոլոգիական սահմանափակումներ ներառելու մեթոդներ կան, ներկայիս APE մոտեցումները չեն կարող վստահել, որ դրանք կհայտնվեն վերջնական թարգմանման մեջ: Այս թղթի մեջ մենք ներկայացնում ենք լեքսիկապես սահմանափակված APE-ի ինքնաարձագանքային և ոչ ինքնաարձագանքային մոդելներ, որոնք ցույց են տալիս, որ մեր մոտեցումը հնարավորություն է տալիս պահպանել տերմինոլոգիաների 95 տոկոսը, ինչպես նաև բարելավել է անգլերեն-գերմանացի համե Նույնիսկ երբ կիրառվում է լեքսիկական սահմանափակ MT արտադրության վրա, մեր մոտեցումը կարող է բարելավել տերմինոլոգիաների պահպանությունը: Այնուամենայնիվ, մենք ցույց ենք տալիս, որ մեր մոդելները չեն սովորում սահմանափակումներ սիստեմատիկ կոպիանել և առաջարկում են պարզ տվյալների բարձրացման տեխնիկա, որը հանգեցնում է բարելավված արդյունքների և կայունության:', 'az': "Makinelərin qurğulaması (MT) istifadəçiləri müəyyən edilmiş leksik terminoloqların istifadəsini əmin etmək istəyirlər. MT'nin infeksyon sırasında terminoloji müəyyənləşdirilməsi üçün tekniklər vardır. Şimdiki APE yaxınlıqları son dəyişiklikdə görünəcəklərini əmin edə bilməz. Bu kağıtda, biz özümüzə rərgressiv və özünüzə rərgressiv modelləri təyin edirik ki, təsirimizin terminoloğunun 95%-ini qoruması və İngiliz-Alman benchmarkləri barəsində tercümə keyfiyyətini daha yaxşılaşdırır. Laxiki müəyyən MT çıxışına uyğun olsa da, bizim tərzimiz terminologilərin qorumasını daha yaxşılaşdıra bilər. Lakin, modellərimiz sistematik sıxıntıları kopyalamağı öyrənmirik və sadəcə məlumatları artırmaq tekniklərini təbliğ edirik ki, performans və qüvvətliyi daha yaxşılaşdırır.", 'ca': "Els usuaris de la traducció màquina (MT) poden voler assegurar l'ús de terminologies lècsiques específices. Mentre hi ha tècniques d'incorporació de restriccions terminològices durant la inferència de MT, els enfocaments APE actuals no poden assegurar que apareixin a la traducció final. En aquest paper, presentem models tant autoregressius com no autoregressius per a APE restringida lècsicament, demostrant que el nostre enfocament permet conservar el 95% de les terminologies i també millora la qualitat de traducció dels punts de referència anglo-alemanès. Fins i tot quan s'aplica a la producció de MT limitada lexicament, el nostre enfocament és capaç de millorar la preservació de les terminologies. Tot i així, demostram que els nostres models no aprenen a copiar les restriccions sistemàticament i suggereixen una tècnica senzilla d'augmentació de dades que porta a millorar el rendiment i la robustet.", 'cs': 'Uživatelé strojového překladu (MT) mohou chtít zajistit použití specifických lexikálních terminologií. Zatímco existují techniky pro začlenění terminologických omezení během inference pro MT, současné APE přístupy nemohou zajistit, že se objeví v konečném překladu. V tomto článku prezentujeme autoregresivní i neinegresivní modely pro lexicky omezené APE, což ukazuje, že náš přístup umožňuje zachování 95% terminologie a zároveň zlepšuje kvalitu překladu na anglicko-německých referencích. I při aplikaci na lexicky omezený MT výstup je náš přístup schopen zlepšit zachování terminologie. Ukazujeme však, že naše modely se neučí systematicky kopírovat omezení a navrhujeme jednoduchou techniku rozšíření dat, která vede ke zlepšení výkonu a robustnosti.', 'bs': 'Korisnici prevoda stroja (MT) možda žele osigurati upotrebu specifičnih leksičkih terminologija. Iako postoje tehnike za uključenje terminologijskih ograničenja tijekom infekcije MT-a, trenutni pristupi APE-a ne mogu osigurati da će se pojaviti u konačnom prevodu. U ovom papiru predstavljamo i autoregresivne i ne-autoregresivne modele za leksički ograničene APE-e, pokazujući da naš pristup omogućava čuvanje 95% terminologija i poboljšavanje kvalitete prevođenja na englesko-njemačkim kriterijama. Čak i kad se primjenjuje na leksički ograničeni izlaz MT-a, naš pristup može poboljšati očuvanje terminologija. Međutim, mi pokazujemo da naše modele ne uče da kopiraju ograničenja sistematski i predlažemo jednostavnu tehniku povećanja podataka koja vodi ka poboljšanju izvođenja i robustnosti.', 'et': 'Masintõlke (MT) kasutajad võivad soovida tagada spetsiifiliste leksikaalsete terminoloogiate kasutamise. Kuigi on olemas meetodeid terminoloogiliste piirangute lisamiseks MT järelduste tegemisel, ei saa praegused APE lähenemisviisid tagada, et need ilmuvad lõplikus tõlkes. Käesolevas töös tutvustame nii autorregressiivseid kui ka mittearregressiivseid mudeleid leksiliselt piiratud APE jaoks, näidates, et meie lähenemine võimaldab säilitada 95% terminoloogiast ja parandab ka inglise-saksa võrdlusnäitajate tõlkekvaliteeti. Isegi leksikaalselt piiratud MT väljundi puhul on meie lähenemisviis võimeline parandama terminoloogiate säilimist. Siiski näitame, et meie mudelid ei õpi piiranguid süstemaatiliselt kopeerima ja soovitame lihtsat andmete suurendamise tehnikat, mis viib parema jõudluse ja töökindluseni.', 'fi': 'Konekäännöksen käyttäjät saattavat haluta varmistaa tiettyjen sanastotermien käytön. Vaikka on olemassa tekniikoita terminologisten rajoitusten sisällyttämiseksi MT:n johtopäätöksiin, nykyiset APE-lähestymistavat eivät voi varmistaa, että ne näkyvät lopullisessa käännöksessä. Tässä artikkelissa esittelemme sekä autoregressiivisia että ei-autoregressiivisiä malleja leksisesti rajoitetulle APE:lle, mikä osoittaa, että lähestymistapamme mahdollistaa 95% terminologiasta säilymisen ja parantaa käännöksen laatua englannin-saksan vertailuarvoissa. Lähestymistapamme pystyy parantamaan terminologian säilymistä myös sanastollisesti rajoitetussa MT-tuotoksessa. Osoitamme kuitenkin, että mallimme eivät opi kopioimaan rajoituksia järjestelmällisesti ja ehdotamme yksinkertaista datan lisäystekniikkaa, joka parantaa suorituskykyä ja kestävyyttä.', 'jv': 'Ngawe Perintah pengguna tarjamahan (MT) iso disimpen nggo yen nggawe Genjer-genjer saiki wis ana teknik kanggo nggawe nguasai aturan terminal sing nggawe MT, dadi kapan-kapan nggawe barang nggawe sapa-kapan dhewe nguasai tarjamahan kanggo ngwalikno. Nang pepul iki, kita mulai model sing autoRegresve lan ora autoRegresve nggawe layang kelas nggawe barang kelas aplikasi padha kelas nggawe bener tentang kanggo ngerasai Ninggis-German. Slackfree Saiki, kéné menehi tindang model awak dhéwé ora ngerasai nggambar aturan sistematik lan suggerekan sistem sing beraksi teknik awak dhéwé nggawe gerakan kanggo ngerasakno operasi lan jewisan sing bakal terus.', 'sk': 'Uporabniki strojnega prevajanja (MT) bi morda želeli zagotoviti uporabo posebnih leksikalnih terminologij. Medtem ko obstajajo tehnike za vključevanje terminoloških omejitev med sklepanjem za MT, sedanji pristopi APE ne morejo zagotoviti, da se bodo pojavili v končnem prevodu. V prispevku predstavljamo avtoregresivne in neavtoregresivne modele za leksično omejeno APE, kar dokazuje, da naš pristop omogoča ohranitev 95% terminologij in izboljšuje kakovost prevajanja na angleško-nemških referenčnih vrednostih. Tudi če se uporablja za leksično omejeno MT izhodišče, lahko naš pristop izboljša ohranitev terminologije. Vendar pa pokažemo, da se naši modeli ne naučijo sistematično kopirati omejitev in predlagamo preprosto tehniko povečanja podatkov, ki vodi k boljši zmogljivosti in robustnosti.', 'ha': "@ label: listbox KDE style Kuma a lokacin da za'a ƙunsa da bakwai taƙaitõji na ƙararra wa MT, masu amfani da amfani da ake kai yanzu ba za'a tabbatar da su zo cikin fassarar ƙarshen. Ga wannan takardan, Munã halatar da misãlai farat-regressive da ba-kandam da aka lazimta PAEke, kuma Muke nuna cewa hanyoyinmu yana iya tsaron tsarin 95% na garwayalojiya kuma yana ƙara sifar fassarar ta cikin bangon Ingiriya-Jarman. Haƙĩƙa idan an applied zuwa matsayin MT da aka lazimta, hanyarmu na iya ƙara tsarin taswai. However, we show that our models do not learn to copy constraints systematically and suggest a simple data augmentation technique that leads to improved performance and robustness.", 'bo': 'Users of machine translation (MT) may want to ensure the use of specific lexical terminologies. While there are techniques for incorporating terminology constraints during inference for MT, current APE approaches cannot ensure that they will appear in the final translation. འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་རང་འགུལ་གྱིས་རྣམ་པ་ལས་རང་འགུལ་གྱིས་མེད་པའི་མིན་དཔེ་གཏོང་ཚད་མེད་པའི་APE་ལ་ཡོད་པ་དང་། Even when applied to lexically constrained MT output, our approach is able to improve preservation of the terminologies. ཡིན་ནའང་ང་ཚོའི་མིག་དཔེ་དབྱིབས་རྩིས་པ་ལྟར་སྒྲིག་འགོད་མི་བྱེད་པར།', 'he': 'משתמשים בתרגום מכונות (MT) אולי רוצים להבטיח שימוש בטרמונולוגיות לקסיות ספציפיות. למרות שיש טכניקות להכניס מחסומים בטרמולוגיה במהלך ההנחה של MT, גישות APE הנוכחיות לא יכולות להבטיח שהם יופיעו בתרגום הסופי. בעיתון הזה, אנו מציגים דוגמנים אוטו-אגרסיביים ולא-אוטו-אגרסיביים עבור APE מוגבלת ללקסית, שמוכיחים שהגישה שלנו מאפשרת לשמור על 95% מהטרמונולוגיות Even when applied to lexically constrained MT output, our approach is able to improve preservation of the terminologies.  בכל אופן, אנחנו מראים שהדוגמנים שלנו לא לומדים לעתק מחסומות באופן שיטתי ולהציע טכניקה פשוטה של גידול נתונים שמובילה לביצוע משפר וחזקה.'}
