{'en': 'Unsupervised Parallel Sentence Extraction from Comparable Corpora', 'es': 'Extracción paralela no supervisada de cuerpos comparables', 'fr': 'Extraction parallèle non supervisée de phrases à partir de corpus comparables', 'ar': 'استخراج الجمل المتوازية غير الخاضعة للرقابة من Corpora المقارن', 'pt': 'Extração de sentenças paralelas não supervisionadas de corpora comparáveis', 'ja': '比較可能なコーラからの監督なしの並列文抽出', 'ru': 'Неконтролируемое извлечение параллельных предложений из сопоставимых тел', 'ga': 'Sliocht Pianbhreithe Comhthreomhar Neamh-mhaoirsithe as Corpora Inchomparáide', 'zh': '取可较语料库无监督并行句', 'hi': 'तुलनीय निगम से असुरक्षित समानांतर वाक्य निष्कर्षण', 'ka': 'შემდგომარებული კოპორადან პარალელი სიტყვების გამოყენება', 'hu': 'Felügyelet nélküli párhuzamos mondat kivonás az összehasonlítható Corporából', 'el': 'Μη εποπτευόμενη παράλληλη εξαγωγή προτάσεων από συγκρίσιμο σώμα', 'it': 'Estrazione di sentenze parallele non sorvegliate da Corpora comparabile', 'kk': 'Сәйкесті Корпорадан параллел сөз тарқатуы', 'lt': 'Neaprižiūrimas lygiagrečių sakinių ekstrahavimas iš palyginamosios korporos', 'mk': 'Ненадгледувана екстракција на паралелна реченица од Comparable Corpora', 'ms': 'Unsupervised Parallel Sentence Extraction from Comparable Corpora', 'ml': 'പരാലല്\u200d ശിക്ഷ പുറത്താക്കുന്നതിനു് നിരീക്ഷിക്കപ്പെടാത്തതു്', 'mn': 'Хэрэв харьцуулагдах Корпораас харьцуулагдаагүй параллел өгүүлбэр', 'mt': 'Estrazzjoni tas-Sentenza Paralela Mhux Sorveljata minn Korpora Komparabbli', 'no': 'Ikkje oppretta parallell utpakking frå kompatibelt korpora', 'pl': 'Niekontrolowana równoległa ekstrakcja zdań z porównywalnego korpusu', 'sr': 'Neodređena paralelna izvlačenja kazne iz kompatibilne korpore', 'ro': 'Extragerea sentinței paralele nesupravegheate din Corpora Comparabilă', 'si': 'සම්පූර්ණ කොර්පෝරා වලින් සම්පූර්ණ වාර්තාව නිර්මාණය කරන්න', 'so': 'Ka soo guurista xuquuqda baaritaanka aan ilaalinayn korporada', 'sv': 'Icke övervakad parallell mening extraktion från jämförbar Corpora', 'ta': 'ஒப்பீடுபடும் கோர்போரிலிருந்து பராமரிக்கப்படாத அமர்வு', 'ur': 'comparable Corpora', 'uz': 'Izoh', 'vi': 'Xuất bản thơ song song không có từ Corpus', 'bg': 'Извличане на паралелна присъда без надзор от сравним корпор', 'da': 'Ikke-overvåget parallel sætning uddrag fra sammenlignelig Corpora', 'hr': 'Neodređena paralelna izvlačenja kazne iz komparabilne korpore', 'nl': 'Ongecontroleerde parallelle zinsextractie uit vergelijkbaar corpora', 'de': 'Unbeaufsichtigte parallele Satztextraktion aus vergleichbarem Korpora', 'ko': '비교 가능한 자료 라이브러리 기반의 무감독 평행문 추출', 'fa': 'استخراج مجوز پارالل غیرقابل تحویل از شرکت قابل مقایسه', 'id': 'Ekstraksi Hukuman Paralel Tidak Disupervisi Dari Korpora Dibandingkan', 'sw': 'Kuondolewa kwa Makazi ya Kibunge kutokana na Corpora inayofanana', 'tr': 'Saglanmadyk Parallel söz Açmak Maglumaty Kopordan', 'sq': 'Ekstrakti i padukshëm i dënimit paralel nga korpora e krahasueshme', 'af': 'Onondersteunde Parallele Sentence Uitpakking van Vergelykbare Korpora', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'az': 'Qısqancılı Korporadan Parallel Sözü Çıqışması', 'hy': 'Համեմատական Կորպորայից առանց վերահսկվող համեմատական նախադասությունների հանման', 'bn': 'তুলনা কর্পোরা থেকে প্যারালেলের শাস্তি প্রসারিত', 'bs': 'Neodređena paralelna izvlačenja kazne iz kompatibilne korpore', 'ca': 'Extracció paralèl·lela sense supervisió de la Comparable Corpora', 'cs': 'Nebezpečovaná paralelní extrakce vět z srovnatelného korpusu', 'et': 'Järelevalveta paralleelse lause väljavõte võrreldavast korpusest', 'fi': 'Tarkkailematon rinnakkaislauseen poisto vertailukelpoisesta korpusesta', 'jv': 'structural navigation', 'he': 'הוצאת גזר משפט פעמוני ללא השגחה מחברה שווה', 'ha': 'Socket error code ConnectionTimedOut', 'sk': 'Nenadzorovan vzporedni izvleček kazni iz primerljivih korpusov', 'bo': 'མཉམ་སྦྲགས་པའི་ཚོར་བ་སྔོན་སྒྲིག་མེད་པའི་བརྗོད་རྟགས་ཕྱིར་འདོར་བ'}
{'en': 'Mining parallel sentences from comparable corpora is of great interest for many downstream tasks. In the BUCC 2017 shared task,  systems  performed well by training on gold standard parallel sentences. However, we often want to mine  parallel sentences  without bilingual supervision. We present a simple approach relying on bilingual word embeddings trained in an unsupervised fashion. We incorporate orthographic similarity in order to handle words with similar surface forms. In addition, we propose a dynamic threshold method to decide if a candidate sentence-pair is parallel which eliminates the need to fine tune a static value for different datasets. Since we do not employ any language specific engineering our approach is highly generic. We show that our approach is effective, on three language-pairs, without the use of any bilingual signal which is important because parallel sentence mining is most useful in low resource scenarios.', 'ar': 'يعد استخراج الجمل المتوازية من مجموعات مماثلة ذا أهمية كبيرة للعديد من المهام النهائية. في مهمة BUCC 2017 المشتركة ، كان أداء الأنظمة جيدًا من خلال التدريب على الجمل الموازية ذات المعيار الذهبي. ومع ذلك ، فإننا غالبًا ما نرغب في استخراج جمل متوازية دون إشراف ثنائي اللغة. نقدم نهجًا بسيطًا يعتمد على حفلات الزفاف ثنائية اللغة التي يتم تدريبها بطريقة غير خاضعة للرقابة. نقوم بدمج التشابه الهجائي من أجل التعامل مع الكلمات ذات الأشكال السطحية المتشابهة. بالإضافة إلى ذلك ، نقترح طريقة عتبة ديناميكية لتحديد ما إذا كان زوج الجملة المرشح متوازيًا مما يلغي الحاجة إلى ضبط قيمة ثابتة لمجموعات البيانات المختلفة. نظرًا لأننا لا نستخدم أي هندسة خاصة بلغة معينة ، فإن نهجنا عام للغاية. نظهر أن نهجنا فعال ، على ثلاثة أزواج لغوية ، دون استخدام أي إشارة ثنائية اللغة وهو أمر مهم لأن التنقيب عن الجمل المتوازية يكون مفيدًا للغاية في سيناريوهات الموارد المنخفضة.', 'pt': 'A mineração de sentenças paralelas de corpora comparáveis é de grande interesse para muitas tarefas posteriores. Na tarefa compartilhada do BUCC 2017, os sistemas tiveram bom desempenho treinando em sentenças paralelas padrão ouro. No entanto, muitas vezes queremos minerar frases paralelas sem supervisão bilíngue. Apresentamos uma abordagem simples com base em incorporações de palavras bilíngues treinadas de forma não supervisionada. Incorporamos similaridade ortográfica para lidar com palavras com formas de superfície semelhantes. Além disso, propomos um método de limiar dinâmico para decidir se um par de sentenças candidato é paralelo, o que elimina a necessidade de ajustar um valor estático para diferentes conjuntos de dados. Como não empregamos nenhuma engenharia específica de linguagem, nossa abordagem é altamente genérica. Mostramos que nossa abordagem é eficaz, em três pares de idiomas, sem o uso de qualquer sinal bilíngue, o que é importante porque a mineração paralela de frases é mais útil em cenários de poucos recursos.', 'fr': "L'extraction de phrases parallèles à partir de corpus comparables présente un grand intérêt pour de nombreuses tâches en aval. Dans la tâche partagée BUCC 2017, les systèmes ont bien fonctionné grâce à la formation sur des phrases parallèles de référence. Cependant, nous voulons souvent miner des phrases parallèles sans supervision bilingue. Nous présentons une approche simple qui repose sur des intégrations de mots bilingues formées de manière non supervisée. Nous intégrons la similitude orthographique afin de traiter des mots ayant des formes de surface similaires. En outre, nous proposons une méthode de seuil dynamique pour décider si une paire de phrases candidates est parallèle, ce qui élimine le besoin d'affiner une valeur statique pour différents ensembles de données. Comme nous n'employons aucune ingénierie spécifique à la langue, notre approche est hautement générique. Nous montrons que notre approche est efficace, sur trois paires de langues, sans utiliser de signal bilingue, ce qui est important car l'exploration de phrases parallèle est très utile dans les scénarios à faibles ressources.", 'es': 'La extracción de oraciones paralelas de cuerpos comparables es de gran interés para muchas tareas posteriores. En la tarea compartida de BUCC 2017, los sistemas funcionaron bien mediante el entrenamiento en oraciones paralelas estándar de oro. Sin embargo, a menudo queremos extraer oraciones paralelas sin supervisión bilingüe. Presentamos un enfoque simple que se basa en incrustaciones de palabras bilingües entrenadas de manera no supervisada. Incorporamos similitud ortográfica para manejar palabras con formas superficiales similares. Además, proponemos un método de umbral dinámico para decidir si un par de oraciones candidato es paralelo, lo que elimina la necesidad de ajustar un valor estático para diferentes conjuntos de datos. Como no empleamos ninguna ingeniería específica del idioma, nuestro enfoque es muy genérico. Demostramos que nuestro enfoque es efectivo, en tres pares de idiomas, sin el uso de ninguna señal bilingüe, lo cual es importante porque la minería de oraciones paralelas es más útil en escenarios de bajos recursos.', 'ja': '同等のコーラから並行文をマイニングすることは、多くの下流タスクにとって非常に興味深いことです。BUCC 2017の共有タスクシステムでは、ゴールドスタンダードの並列文に関するトレーニングによって、システムは良好に機能しました。しかし、私たちはバイリンガルの監督なしに並行文を採掘したいと考えていることがよくあります。私たちは、監督されていない方法でトレーニングされたバイリンガルワード埋め込みに依存するシンプルなアプローチを提示します。表面の形が似ている単語を扱うために、正書法の類似性を取り入れています。さらに、異なるデータセットの静的値を微調整する必要がなく、候補文ペアが並列であるかどうかを決定するための動的しきい値メソッドを提案します。言語固有のエンジニアリングを採用していないため、アプローチは非常に一般的です。私たちは、私たちのアプローチが効果的であることを示しています。3つの言語ペアでは、バイリンガルシグナルを使用せずに。これは、並列文マイニングがリソースの少ないシナリオで最も有用であるために重要です。', 'ru': 'Майнинг параллельных предложений из сопоставимых тел представляет большой интерес для многих задач ниже по потоку. В совместной задаче BUCC 2017 системы показали хорошие результаты, обучая параллельным предложениям золотого стандарта. Тем не менее, мы часто хотим добывать параллельные предложения без двуязычного надзора. Мы представляем простой подход, основанный на двуязычных словарных вложениях, обученных неконтролируемым образом. Мы используем орфографическое сходство для того, чтобы обрабатывать слова со схожими поверхностными формами. Кроме того, мы предлагаем метод динамического порога, чтобы решить, является ли пара предложений-кандидатов параллельной, что исключает необходимость точной настройки статического значения для различных наборов данных. Поскольку мы не используем какую-либо языковую инженерию, наш подход является весьма общим. Мы показываем, что наш подход эффективен, на трех языковых парах, без использования какого-либо двуязычного сигнала, что важно, потому что параллельный майнинг предложений наиболее полезен в сценариях с низким уровнем ресурсов.', 'ga': 'Is díol spéise é mianadóireacht abairtí comhthreomhara ó chorpora inchomparáide le haghaidh go leor tascanna iartheachtacha. I dtasc comhroinnte BUCC 2017, d’fheidhmigh córais go maith trí oiliúint ar abairtí comhthreomhara caighdeánacha óir. Mar sin féin, is minic a theastaíonn uainn abairtí comhthreomhara a dhéanamh gan maoirseacht dhátheangach. Cuirimid cur chuige simplí i láthair ag brath ar leabú focal dátheangach oilte ar bhealach gan mhaoirseacht. Ionchorpraímid cosúlacht ortagrafach chun focail a láimhseáil le foirmeacha dromchla comhchosúla. Ina theannta sin, molaimid modh dinimiciúil tairsí chun a chinneadh an bhfuil péire abairtí iarrthóra comhthreomhar lena gcuirtear deireadh leis an ngá luach statach a mhionchoigeartú do thacair shonraí éagsúla. Toisc nach n-úsáidtear aon innealtóireacht a bhaineann go sonrach le teanga, tá ár gcur chuige an-chineálach. Léirímid go bhfuil ár gcur chuige éifeachtach, ar thrí phéire teanga, gan úsáid a bhaint as aon chomhartha dátheangach, rud atá tábhachtach toisc go bhfuil mionú abairtí comhthreomhara is úsáidí i gcásanna acmhainní ísle.', 'zh': '从类语料库中掘并行句于诸下流甚乐。 BUCC 2017 年之共同任务,统黄金而练之。 然常欲于无双语监掘平行句。 吾建一简之法,赖以无监督之双语词嵌之。 吾合正字法相似性,以处相似之单词。 此外立一动阈值法以定选句,以消静数之需。 我不用特定言之功,我法甚通。 吾证吾法于三语有效,而无双语信号,甚要也,盖并行句掘于低资源场中最有用也。', 'hi': 'तुलनीय कॉर्पोरेट से खनन समानांतर वाक्य कई डाउनस्ट्रीम कार्यों के लिए बहुत रुचि रखते हैं। BUCC 2017 साझा कार्य में, सिस्टम ने सोने के मानक समानांतर वाक्यों पर प्रशिक्षण द्वारा अच्छा प्रदर्शन किया। हालांकि, हम अक्सर द्विभाषी पर्यवेक्षण के बिना समानांतर वाक्यों को खदान करना चाहते हैं। हम द्विभाषी शब्द embeddings पर भरोसा एक सरल दृष्टिकोण प्रस्तुत एक unsupervised फैशन में प्रशिक्षित. हम समान सतह रूपों वाले शब्दों को संभालने के लिए ऑर्थोग्राफिक समानता को शामिल करते हैं। इसके अलावा, हम यह तय करने के लिए एक गतिशील थ्रेशोल्ड विधि का प्रस्ताव करते हैं कि क्या एक उम्मीदवार वाक्य-जोड़ी समानांतर है जो विभिन्न डेटासेट के लिए एक स्थिर मूल्य को ठीक करने की आवश्यकता को समाप्त करती है। चूंकि हम किसी भी भाषा विशिष्ट इंजीनियरिंग को नियोजित नहीं करते हैं, इसलिए हमारा दृष्टिकोण अत्यधिक सामान्य है। हम दिखाते हैं कि हमारा दृष्टिकोण प्रभावी है, तीन भाषा-जोड़े पर, किसी भी द्विभाषी संकेत के उपयोग के बिना, जो महत्वपूर्ण है क्योंकि समानांतर वाक्य खनन कम संसाधन परिदृश्यों में सबसे उपयोगी है।', 'el': 'Η εξόρυξη παράλληλων προτάσεων από συγκρίσιμα σώματα έχει μεγάλο ενδιαφέρον για πολλές μεταγενέστερες εργασίες. Στην κοινή εργασία, τα συστήματα επιτελούνταν καλά με την εκπαίδευση σε χρυσές τυποποιημένες παράλληλες προτάσεις. Ωστόσο, συχνά θέλουμε να εξορύξουμε παράλληλες προτάσεις χωρίς δίγλωσση επίβλεψη. Παρουσιάζουμε μια απλή προσέγγιση που βασίζεται σε δίγλωσσες ενσωμάτωση λέξεων εκπαιδευμένες με τρόπο χωρίς επίβλεψη. Ενσωματώνουμε ορθογραφική ομοιότητα για να χειριστούμε λέξεις με παρόμοιες επιφανειακές μορφές. Επιπλέον, προτείνουμε μια δυναμική μέθοδο κατώτατου ορίου για να αποφασίσουμε αν ένα υποψήφιο ζευγάρι προτάσεων είναι παράλληλο, γεγονός που εξαλείφει την ανάγκη να τελειοποιηθεί μια στατική τιμή για διαφορετικά σύνολα δεδομένων. Δεδομένου ότι δεν χρησιμοποιούμε καμία γλωσσική μηχανική, η προσέγγισή μας είναι ιδιαίτερα γενική. Δείχνουμε ότι η προσέγγισή μας είναι αποτελεσματική, σε τρία γλωσσικά ζεύγη, χωρίς τη χρήση οποιουδήποτε δίγλωσσου σήματος, το οποίο είναι σημαντικό γιατί η παράλληλη εξόρυξη προτάσεων είναι πιο χρήσιμη σε σενάρια χαμηλού πόρου.', 'ka': 'პარალელური სიტყვები შემდგომარებული კორპორადან იყო დიდი ინტერესტი მრავალური დავალებისთვის. BUCC 2017-ში გაყოფილი დავალება, სისტემები ძალიან გავაკეთებული gold standard parallel sentences-ზე. მაგრამ ჩვენ გვინდა ჩემი პარალელური სიტყვები, რომელიც ორიენგური მონახილობად არ გვინდა. ჩვენ ჩვენ გავაჩვენოთ ერთი ადგილური პროგრამა, რომელიც ორიენგური სიტყვების შესაბამისი სიტყვების შესაბამისი შესაბამისი არაფერიზებულ მოდით. ჩვენ დავყენებთ ორტოგრაფიკური განსხვავებას, რომელიც სხვადასხვა გვერდის ფორმებით გამოყენებული სიტყვები. დამატებით, ჩვენ განვითარებით დინამიკური მნიშვნელობის მეტი, რომელიც განსხვავებული მონაცემების სტატიკური მნიშვნელობის განსხვავება, თუ კონდიდენტის მნიშვნელობა პარალელია. რადგან ჩვენ არ ვიყენებთ ენის სპექტიფიკალური ინეზინერიონი, ჩვენი მიღება ძალიან გენერიკულია. ჩვენ გამოჩვენებთ, რომ ჩვენი პროგრამა ეფექტიურია, სამი ენახური ორივე სიგნალის გამოყენება, რომელიც უფრო მნიშვნელოვანია, რადგან პარალელი სიტყვების მინიღება საკმაოდ', 'kk': 'Салыстырылатын корпорадан параллельді сөйлемелерді салыстыру көптеген тапсырмалар үшін көп қызықты. БУCC 2017 жылы ортақ тапсырманың жүйелері алтын стандартты параллель сөйлемелерді бақылап жатқан. Бірақ біз көбінесе екі тілі қарау жоқ параллел сөйлемелерді өзгертуді қалаймыз. Екі тілі сөздерді ендіру үшін қарапайым арқылы көрсетеді. Сөздерді ұқсас поверхностық пішімдермен әсер ету үшін ортографикалық ұқсастығын қоса аламыз. Қосымша, біз басқа деректер жиындарының статикалық мәнін баптау керектігін шешу үшін динамикалық шегінің әдісін таңдаймыз. Өйткені біз тілдердің ерекше инженерліктерін қолданбаймыз, өте жалпы. Біз біздің тәртібіміздің үш тілді екі сигналын қолдану үшін әсер ететінді көрсетейміз, өйткені параллель сөздердің бағыттауы ресурстар сценариясында ең пайдалы.', 'it': "Estrarre frasi parallele da corpora comparabili è di grande interesse per molti compiti a valle. Nel compito condiviso BUCC 2017, i sistemi hanno funzionato bene allenandosi sulle frasi parallele gold standard. Tuttavia, spesso vogliamo estrarre frasi parallele senza supervisione bilingue. Presentiamo un approccio semplice basato su embedding di parole bilingui addestrati in modo non supervisionato. Incorporamo somiglianze ortografiche per gestire parole con forme superficiali simili. Inoltre, proponiamo un metodo di soglia dinamica per decidere se una coppia di frasi candidate è parallela che elimina la necessità di regolare un valore statico per diversi set di dati. Poiché non utilizziamo alcuna ingegneria linguistica specifica, il nostro approccio è altamente generico. Dimostriamo che il nostro approccio è efficace, su tre coppie linguistiche, senza l'uso di alcun segnale bilingue che è importante perché il mining di frasi parallele è più utile in scenari a basso contenuto di risorse.", 'hu': 'Hasonló corporák párhuzamos mondataiból való bányászat nagy érdeklődést jelent számos downstream feladat számára. A BUCC 2017-es közös feladatában a rendszerek jól teljesítették az aranyszabású párhuzamos mondatok képzését. Ugyanakkor gyakran szeretnénk párhuzamos mondatokat bányászni kétnyelvű felügyelet nélkül. Egy egyszerű megközelítést mutatunk be, amely felügyelet nélkül kétnyelvű szóbeágyazásokra épül. Helyesírási hasonlóságot alkalmazunk a hasonló felületi formájú szavak kezelésére. Emellett egy dinamikus küszöbérték módszert javasolunk annak eldöntésére, hogy egy jelölt mondatpár párhuzamos-e, ami kiküszöböli a statikus érték finomhangolásának szükségességét a különböző adatkészletek esetében. Mivel nem alkalmazunk semmilyen nyelvspecifikus tervezést, a megközelítésünk rendkívül általános. Megmutatjuk, hogy a megközelítésünk három nyelvpáron hatékony, kétnyelvű jel használata nélkül, ami fontos, mert a párhuzamos mondatbányászat a leghasznosabb alacsony erőforrású forgatókönyvekben.', 'ms': 'Menyembah kalimat selari dari korpra yang boleh dibandingkan adalah berminat besar untuk banyak tugas turun. Dalam tugas berkongsi BUCC 2017, sistem dilakukan dengan baik dengan latihan pada kalimat selari piawai emas. Namun, kita sering mahu tambah kalimat selari tanpa pengawasan dua bahasa. Kami memperkenalkan pendekatan sederhana bergantung pada penyelesaian perkataan dua bahasa dilatih dengan cara yang tidak diawasi. Kami memasukkan persamaan ortografik untuk mengendalikan perkataan dengan bentuk permukaan yang sama. Selain itu, kami cadangkan kaedah ambang dinamik untuk memutuskan jika pasangan kalimat calon selari yang menghapuskan keperluan untuk menyesuaikan nilai statik untuk set data yang berbeza. Since we do not employ any language specific engineering our approach is highly generic.  Kami menunjukkan bahawa pendekatan kita adalah berkesan, pada tiga pasangan bahasa, tanpa menggunakan mana-mana isyarat dua bahasa yang penting kerana penambangan kalimat selari adalah paling berguna dalam skenario sumber rendah.', 'ml': 'സമ്പൂര്\u200dണ്ണമായ കോര്\u200dപ്പോരയില്\u200d നിന്നുള്ള പാരാളിലെ വാക്കുകള്\u200d കുറച്ച് താഴെ നദിയുടെ ജോലികള്\u200dക്ക് വളരെ ത ബുസിസി 2017-ല്\u200d പങ്കെടുത്ത ജോലിയില്\u200d സ്വര്\u200dണ്ണസ്റ്റാര്\u200dട്ടാള്\u200d പാരാളില്\u200d വാക്കുകള്\u200d പ്രവര്\u200dത്തിക്കുന്നതി എന്നാലും, നമുക്ക് എപ്പോഴും രണ്ടു ഭാഷ കാര്യങ്ങള്\u200d ഇല്ലാതെ പാരാളല്\u200d വാക്കുകള്\u200d എന്\u200dറെ ആവശ്യമുണ്ട്. രണ്ടു ഭാഷ വാക്കുകളില്\u200d ആശ്രയിക്കുന്ന ഒരു എളുപ്പമായ വഴിയാണ് ഞങ്ങള്\u200d കൊണ്ടുവരുന്നത്. ഒരു സംരക്ഷിതമായ രീതിയില്\u200d പര ഇതുപോലുള്ള വാക്കുകള്\u200d സംരക്ഷിക്കാന്\u200d വേണ്ടി ഞങ്ങള്\u200d ഓര്\u200dടോഗ്രാഫിക് സമമാണ് ചേര്\u200dക്കുന്നത്. In addition, we propose a dynamic threshold method to decide if a candidate sentence-pair is parallel which eliminates the need to fine tune a static value for different datasets.  നമ്മള്\u200d ഭാഷ പ്രത്യേകിച്ചൊരു എഞ്ചിനീയറിങ്ങിനെക്കുറിച്ചും ജോലി ചെയ്യാത്തതിനാല്\u200d നമ്മുടെ പ്രാ ഞങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ പ്രായോഗ്യം മൂന്നു ഭാഷ-ജോട്ടികളില്\u200d പ്രധാനപ്പെട്ടതാണെന്ന്, രണ്ടു ഭാഷ സിഗ്നല്\u200d ഉപയോഗിക്കാതെ', 'lt': 'Palyginamų korporų lygiagrečių bausmių kasyba yra labai svarbi daugeliui tolesnių užduočių. 2017 m. BUCC bendroje užduotyje sistemos gerai veikia rengiant aukso standartinius lygiagrečius sakinius. Vis dėlto dažnai norime panaudoti lygiagrečius sakinius be dvikalbės priežiūros. Mes pristatome paprastą požiūrį, grindžiamą dvikalbėmis žodžių įtraukomis, mokomomis nepastebimu būdu. Įtraukiame ortografinius panašumus, kad galėtume tvarkyti žodžius panašiomis paviršiaus formomis. Be to, siūlome dinamišką ribinio dydžio metodą, pagal kurį būtų galima nuspręsti, ar kandidatų sakinių pora yra lygiagreti, kuris pašalintų poreikį patikslinti statinę vertę skirtingiems duomenų rinkiniams. Kadangi mes nenaudojame jokios kalbos specifinės inžinerijos, mūsų požiūris yra labai generinis. Mes parodome, kad mūsų požiūris yra veiksmingas trijų kalbų porų atžvilgiu, nenaudojant jokio dvikalbio signalo, kuris yra svarbus, nes lygiagreti sakinių kasyba yra naudingiausia mažų išteklių scenarijuose.', 'mn': 'Хэрэв харьцуулагдмал корпоратын параллел өгүүлбэрүүдийг багасгах нь олон доорх үйл ажиллагаанд маш их сонирхолтой. БУК 2017 оны хуваалцааны ажил дээр алтын стандарт параллел өгүүлбэрийн сургалтыг сайн хийсэн. Гэхдээ бид ихэвчлэн хоёр хэлний даалгаваргүй параллел өгүүлбөрүүдийг хиймээр байна. Бид хоёр хэл хэлний үгийг сургалтын тухай энгийн арга зам илэрхийлж байна. Бид тохиромжтой гадаргуу хэлбэртэй үгсийг дамжуулахын тулд ортографик төстэй нэгтгэдэг. Үүнээс гадна бид өөр өгөгдлийн сангуудын статистик утгыг сайжруулах хэрэгтэй эсэхийг шийдэхийн тулд динамик хэмжээний арга зааж байна. Бид хэл тодорхой инженерчлэлийг ашиглаж чадахгүй учраас бидний ойлголт маш ерөнхий. Бид 3 хэл хоёр давхар дээр бидний арга зам нь үр дүнтэй гэдгийг харуулж байна. Яагаад гэвэл параллел өгүүлбөр цэвэрлэх нь бага хэл хувилбарт хамгийн хэрэгтэй.', 'mk': 'Работата на паралелни реченици од споредливи корпорации е од голем интерес за многу должни задачи. Во заедничката задача на БУКЦ 2017, системите беа добро спроведени со обука за златни стандардни паралелни реченици. Сепак, честопати сакаме да ги минуваме паралелните реченици без двојазичен надзор. Презентираме едноставен пристап кој се потпира на двојјазични зборови вградени на ненадгледуван начин. Вклучуваме ортографска сличност со цел да ги решиме зборовите со слични површини. Покрај тоа, предложуваме динамичен метод за одлучување дали кандидатскиот пар реченици е паралелен, што ја елиминира потребата да се поправи статичка вредност за различни податоци. Бидејќи не користиме никаков јазик специфичен инженер, нашиот пристап е многу генеричен. Ние покажуваме дека нашиот пристап е ефикасен, на три јазички парови, без употреба на било кој двојјазичен сигнал кој е важен бидејќи паралелното рудање на реченици е најкорисно во сценарија со ниски ресурси.', 'mt': 'It-tħaffir ta’ sentenzi paralleli minn korpura komparabbli huwa ta’ interess kbir għal ħafna kompiti downstream. Fil-kompitu kondiviż tal-BUCC 2017, is-sistemi twettqu tajjeb bit-taħriġ dwar sentenzi paralleli standard tad-deheb. Madankollu, ħafna drabi nixtiequ nimminaw sentenzi paralleli mingħajr superviżjoni bilingwi. We present a simple approach relying on bilingual word embeddings trained in an unsupervised fashion.  Inkorporaw similarità ortografika sabiex in ħaddmu kliem b’forom simili ta’ wiċċ. Barra minn hekk, qed nipproponu metodu dinamiku ta’ limitu biex niddeċiedu jekk pari ta’ sentenzi kandidati huwiex parallel li jeliminax il-ħtieġa li jiġi rfinut valur statiku għal settijiet ta’ dejta differenti. Minħabba li ma nużaw l-ebda inġinerija speċifika għall-lingwi, l-approċċ tagħna huwa ġeneriku ħafna. Aħna nuru li l-approċċ tagħna huwa effettiv, fuq tliet pari lingwistiċi, mingħajr l-użu ta’ kwalunkwe sinjal bilingwi li huwa importanti minħabba li t-tħaffir parallel tas-sentenzi huwa l-aktar utli f’xenarji ta’ riżorsi baxxi.', 'sr': 'Pravljenje paralelnih rečenica iz usporednog korporacije je od velikog interesa za mnoge poslove. U zajedničkom zadatku BUCC 2017, sistemi su dobro proveli treniranjem zlatnih standardnih paralelnih rečenica. Međutim, često želimo da moja paralelna rečenica bez dvojezičkog nadzora. Predstavljamo jednostavan pristup koji se oslanja na dvojezičke reèi ukljuèene na neodreðen način. Uključujemo ortografsku sličnost kako bismo riječi riječima riječima sličnim površinskim oblicima. Osim toga, predlažemo dinamičnu prašku metodu da odlučimo da li je par kandidata paralelna koja eliminiše potrebu da ispravi statičnu vrijednost za različite datasete. Pošto ne zapošljavamo nikakve jezičke inženjerstvo, naš pristup je veoma generičan. Pokazujemo da je naš pristup efikasan, na tri jezička parova, bez upotrebe bilo kojeg dvojezičkog signala koji je važan jer je paralelno rudarstvo rečenica najkorisnije u nizim scenarijama resursa.', 'no': 'Mining av parallelle setningar frå sammenlignbare korpora er av stor interesse for mange nedstrekkoppgåver. I BUCC 2017 delt oppgåve har systemet utført godt ved opplæring av gull standard parallelle setningar. Men vi ønskjer ofte å minne parallelle setningar utan bilinguelt oversikt. Vi viser ein enkel tilnærming som vert tilbakekalla på bilinguelt ord-innbygging som trengte på ein ukjend måte. Vi inkluderer ortografisk likning for å handtera ord med liknande overflateformar. I tillegg foreslår vi ein dynamisk terskelmetode for å bestemma om ein kandidat setningpar er parallell som eliminerer behov for å finna ein statisk verdi for ulike datasett. Sidan vi ikkje bruker nokon språk spesifikk ingeniæring, er tilnærminga vår ganske generiske. Vi viser at tilnærminga vårt er effektiv på tre språkopar, utan bruk av eit bilinguelt signal som er viktig, fordi parallell setningsmanning er mest nyttig i låge ressursscenarioar.', 'pl': 'Wydobywanie zdań równoległych z porównywalnych korpusów jest bardzo interesujące dla wielu dalszych zadań. W ramach wspólnego zadania BUCC 2017 systemy sprawdzały się dobrze poprzez szkolenie na złotym standardzie równoległych zdaniach. Często jednak chcemy kopiować zdania równoległe bez dwujęzycznego nadzoru. Prezentujemy proste podejście polegające na dwujęzycznych osadzeniach słów przeszkolonych w sposób bez nadzoru. Wykorzystujemy podobieństwo ortograficzne w celu obsługi słów o podobnych formach powierzchniowych. Ponadto proponujemy dynamiczną metodę progową, aby zdecydować, czy para zdań kandydujących jest równoległa, co eliminuje konieczność dostrojenia wartości statycznej dla różnych zbiorów danych. Ponieważ nie stosujemy żadnej specyficznej inżynierii językowej, nasze podejście jest bardzo ogólne. Pokazujemy, że nasze podejście jest skuteczne, na trzech parach językowych, bez użycia jakiegokolwiek dwujęzycznego sygnału, co jest ważne, ponieważ równoległe wydobywanie zdań jest najbardziej przydatne w scenariuszach niskich zasobów.', 'si': 'සාමාන්\u200dය වාක්ය පිළිගන්න පුළුවන් කොර්පෝරා වලින් පිළිගන්න පුළුවන් වාක්ය වෙනුවෙන් ගො BUCC 2017 වැදගත් වැඩේ පද්ධතිය හොඳයි, සුන්ද්\u200dරව්\u200dය ප්\u200dරමාණය සමාන්\u200dය වාක්ය වලින් සුන්ද්\u200dරව්\u200dය ප්\u200dරශ් නමුත්, අපිට සාමාන්\u200dය වාර්තාවෙන් මගේ සමාන්\u200dය වචනයක් අවශ්\u200dය වෙන්න ඕනේ දෙවල් භාෂාවක් බල අපි සාමාන්\u200dය ප්\u200dරවේශනයක් පෙන්වන්නේ දෙවල් භාෂාවක් වචනයක් ප්\u200dරවේශනයක් නැති ප්\u200dරවේශනයක් විදිහට. අපි සමාන පුළුවන් වර්ගයෙන් වචනය කරන්න පුළුවන් වර්ගයෙන් වචනය කරනවා. ඒ වගේම, අපි වෙනස් දත්ත සෙට්ටුවට ස්ථිර අවශ්\u200dයය සඳහා ස්ථිර අවශ්\u200dයය නිර්මාණය කරන්න ප්\u200dරශ්නයක් තීරණය කරනවා. අපි කිසිම භාෂාවක් විශේෂ ඉංජිනේරියාවක් භාවිත කරන්නේ නැති නිසා අපේ ප්\u200dරවේශනය ගොඩ අපි පෙන්වන්නේ අපේ ප්\u200dරවේශනය ප්\u200dරශ්නයක්, භාෂා තුන්දෙනුවෙන්, කිසිම දෙවල් භාෂාවක් සංඥානයක් ප්\u200dරවේශනයක් නැති වි', 'ro': 'Mining propoziții paralele de la corpore comparabile este de mare interes pentru multe sarcini din aval. În sarcina comună BUCC 2017, sistemele s-au descurcat bine prin instruirea pe fraze paralele gold standard. Cu toate acestea, adesea dorim să extragem propoziții paralele fără supraveghere bilingvă. Vă prezentăm o abordare simplă bazată pe încorporări bilingve de cuvinte instruite într-un mod nesupravegheat. Încorporăm similitudinea ortografică pentru a gestiona cuvintele cu forme de suprafață similare. În plus, propunem o metodă de prag dinamic pentru a decide dacă o pereche de propoziții candidate este paralelă, ceea ce elimină necesitatea reglării fine a unei valori statice pentru diferite seturi de date. Deoarece nu folosim nici o inginerie lingvistică specifică, abordarea noastră este foarte generică. Noi arătăm că abordarea noastră este eficientă, pe trei perechi de limbi, fără a utiliza niciun semnal bilingv, ceea ce este important pentru că mineritul paralel de propoziții este cel mai util în scenarii cu resurse reduse.', 'sv': 'Utvinning av parallella meningar från jämförbara corpora är av stort intresse för många nedströmsuppgifter. I BUCC 2017 delade uppgift fungerade systemen bra genom att träna på guldstandard parallella meningar. Men vi vill ofta gruva parallella meningar utan tvåspråkig övervakning. Vi presenterar ett enkelt tillvägagångssätt som bygger på tvåspråkiga ord inbäddningar utbildade på ett oövervakat sätt. Vi införlivar ortografisk likhet för att hantera ord med liknande ytformer. Dessutom föreslår vi en dynamisk tröskelmetod för att avgöra om ett kandidatmeningspar är parallellt vilket eliminerar behovet av att finjustera ett statiskt värde för olika datauppsättningar. Eftersom vi inte använder någon språkspecifik teknik är vårt tillvägagångssätt mycket generellt. Vi visar att vårt tillvägagångssätt är effektivt, på tre språkpar, utan användning av någon tvåspråkig signal vilket är viktigt eftersom parallell meningsminkning är mest användbart i lågresursscenarier.', 'so': 'Xilsiinta xukunka lambarka ah ee shirkadaha isbarbarbarka ah waa mid aad u xiiseynaya hawsha badan oo hoose yaal. Shaqooyinka la qaybsaday ee BUCC 2017, nidaamka waxaa si wanaagsan lagu sameeyaa waxbarasho ku saabsan imtixaanka u dhexeeya waxyaabaha habka ah. However, we often want to mine parallel sentences without bilingual supervision.  Waxaynu keennaa qaab fudud oo ku kalsoonaan hadal labaad oo af ah oo lagu baro qaab a an la ilaalin. Waxaynu u qornaa isku mid ahaanshaha, si aan u xambaarano hadal u eg foomka dhulka oo kale. Intaas waxaa dheer, waxaynu soo jeedaynaa qaab aad u dhaqdhaqaaqsan karto si aan go’aan u gaarno in qofka kandida ah uu u eg yahay labo isku mid ah, kaas oo eliya baahida uu u baahanyahay si fiican u qoro qiimaha taranka ee sawirada kala duduwan. Tan darteed aan shaqaynin luuqad cayiman oo injiilkeena ah waa mid caadi ah. Waxaynu muujinnaa in dhaqdhaqaalahayagu ay faa’iido u leedahay sadex luqadood oo aan isticmaalin calaamada labada luqadood oo muhiim ah, sababtuna waa mid ugu faa’iido badan in laga sameeyo qoraalka isbedelka ee midhaha hoose.', 'ta': 'ஒப்பீட்டு நிறுவனத்தில் இருந்து இணைய வாக்குகளை சுருக்குவது பல கீழே நீர் பணிகளுக்கு மிகவும் வட்டி உள்ளது. BUCC 2017-ல் பகிர்ந்த பணியில், தங்க இயல்பான இணைப்பு வாக்குகள் மூலம் அமைப்புகள் நன்றாக இயக்கப்பட்டது. ஆனால், நாங்கள் பெரும்பாலாக இரு மொழி கண்காணிப்பு இல்லாமல் இணைய வாக்குகளை என்னை விரும்புகிறோம். நாம் ஒரு சுலபமான வழியை காண்பிக்கப்படாத முறையில் இரு மொழி வார்த்தைகளை நம்புகிறோம். வார்த்தைகளை போன்ற மேற்கோள் வடிவங்களை கையாள வேண்டும் பொருட்களை நாம் ஒப்பிடுகிறோம். மேலும், ஒரு தேர்ந்தெடுக்கப்பட்ட வாக்கு- ஜோடி இணையாக இருந்தால், வேறு தரவு அமைப்புகளுக்கு நிலையான மதிப்பை நீக்க வேண்டுமா என்று தீர்ம நாங்கள் எந்த மொழி குறிப்பிட்ட பொறியியலையும் வேலை செய்யாது ஏனெனில் நமது செயல்பாடு மிகவும் பொது நாம் காண்பிக்கிறோம் நாம் எங்கள் அணுகும் செயல்பாடு மூன்று மொழி ஜோடி என்பது, எந்த இரண்டு மொழி குறியீடுகளையும் பயன்படுத்தாமல், ஏனென்றால்', 'ur': 'مقابلہ قائم کرپورا سے مشابلہ جماعتوں کا ذخیره کرنا بہت سی نیچے کاموں کے لئے بہت زیادہ علاقه ہے۔ بوسی ۲۰۱۷ میں مشترک کام میں، سیستموں کو سونے کی استاندارڈ پارالٹ جماعتوں پر آموزش کے ذریعہ اچھی طرح انجام دیا گیا ہے. لیکن ہم اکثر دوزبانی نظارت کے بغیر مشابہ کلمات کو میرے لئے چاہتے ہیں۔ ہم ایک آسان طریقہ پیش کرتے ہیں جو دو زبان کی باتوں پر بھروسہ رکھتی ہے جو غیر قابل تعلیم کی جاتی ہیں ہم ایک طرح کے سطح فرموں کے ساتھ کلمات کو سمجھانے کے لئے اورٹوگرافیک برابری میں شامل کرتے ہیں۔ اس کے علاوہ، ہم ایک ڈینامیٹ ترشلڈ طریقہ پیشنهاد کرتے ہیں کہ فیصلہ کریں کہ کیا ایک کڈینڈیٹ جماعت جوڑ parallel ہے جو مختلف ڈاٹ سٹ کے لئے ایک ایسی مقدار مقدار کو مٹا دینے کی ضرورت کو مٹا دیتا ہے. اس وجہ سے کہ ہم کسی زبان کی مخصوص انجینریسی کے مطابق استعمال نہیں کرتے، ہمارا طریقہ بہت معمولی ہے۔ ہم دکھاتے ہیں کہ ہمارا طریقہ تین زبان جوڑوں پر اثر ہے، کسی دوسری زبان سیگنال کے استعمال کے بغیر کہ یہ اثر ہے کیونکہ parallel sentence mining کم resource scenarios میں بہت فائدہ ہے.', 'uz': "Kompyuterdagi parallel so'zlarni qo'yish, bu ko'pchilik vazifalar uchun juda qiziqarli. 2017-yilda BUCC bilan birlashtirilgan vazifalar, tizimlar yuqori standard parallel soʻzlarda bajariladi. Lekin, ko'pincha biz ikki tilni boshqaruvchi so'zlarni o'zgartirmoqchimiz. Biz ikki tillar so'zlariga ishlatadigan oddiy usul bilan xavfsiz qilmagan usulni ishlash mumkin. Biz ko'proq surf formatlarini boshqarish uchun ortografik tilini birlashtiramiz. Koʻrsatgich, biz oddiy chegara usulni boshqa maʼlumot sahifalar uchun statik qiymatni olib tashlash kerak. Chunki biz hech qanday tilni muhandiya ishlashmaymiz, bizning usuli juda umumiy. Biz shunday ko'rayapmiz, bizning usuli uchta tillar ikkita xil imkoniyatini ishlatish mumkin, chunki eng muhim so'zning qismlarini qisqarish juda kam foydalanadi.", 'vi': 'Việc khai thác các câu song song từ đối tượng có thể làm việc theo dòng chảy rất quan trọng. Trong tập luyện BUCC đấm bốc một công việc chia sẻ, hệ thống được thực hiện tốt nhờ luyện tập những câu song song song bằng vàng. Tuy nhiên, chúng tôi vẫn thường muốn trích song song mà không có sự giám sát. Chúng tôi đưa ra một phương pháp đơn giản dựa trên sự hiểu biết hai chữ được huấn luyện theo một cách không giám sát. Chúng tôi có hệ thống giống nhau theo cách dùng từ với dạng bề mặt tương tự. Bên cạnh đó, chúng tôi đề xuất một phương pháp ngưỡng cửa động để quyết định nếu một ứng cử viên ghép câu có song song, loại bỏ khả năng thay đổi giá trị tĩnh cho các bộ dữ liệu khác nhau. Vì chúng ta không sử dụng bất kỳ kỹ thuật ngôn ngữ cụ thể nào, nên phương pháp này rất chung. Chúng tôi cho thấy phương pháp của chúng tôi có hiệu quả, với ba cặp ngôn ngữ, mà không có sự sử dụng tín hiệu hai thứ tiếng nào quan trọng vì khai thác chữ song song song là hữu dụng nhất trong các viễn cảnh nguồn ít.', 'bg': 'Изваждането на паралелни изречения от сравними корпуси е от голям интерес за много задачи надолу по веригата. В БУК 2017 споделената задача системите се представиха добре чрез обучение по златни стандарти успоредни изречения. Често обаче искаме да минем паралелни изречения без двуезичен надзор. Представяме един прост подход, който се основава на двуезични вграждания на думи, обучени без надзор. Включваме ортографско сходство, за да обработваме думи със сходни повърхностни форми. В допълнение, ние предлагаме динамичен праг метод за решаване дали кандидат двойка изречения е успоредна, което елиминира необходимостта от фино настройване на статична стойност за различни набори от данни. Тъй като не използваме специфично езиково инженерство, подходът ни е много общ. Показваме, че нашият подход е ефективен, на три езикови двойки, без използването на двуезичен сигнал, което е важно, защото успоредното извличане на изречения е най-полезно в сценарии с ниски ресурси.', 'nl': "Het mining van parallelle zinnen uit vergelijkbare corpora is van groot belang voor veel downstream taken. In de BUCC 2017 gedeelde taak presteerden systemen goed door te trainen op gouden standaard parallelle zinnen. We willen echter vaak parallelle zinnen mineren zonder tweetalige begeleiding. We presenteren een eenvoudige aanpak die gebaseerd is op tweetalige woordinbeddingen die zonder toezicht zijn opgeleid. We integreren orthografische gelijkenis om woorden met vergelijkbare oppervlaktevormen te behandelen. Daarnaast stellen we een dynamische drempelmethode voor om te bepalen of een kandidaat-zinnenpaar parallel is, wat de noodzaak elimineert om een statische waarde voor verschillende datasets te finetunen. Omdat we geen taalspecifieke engineering gebruiken, is onze aanpak zeer generiek. We laten zien dat onze aanpak effectief is, op drie taalparen, zonder het gebruik van een tweetalig signaal, wat belangrijk is omdat parallelle zinsmining het meest nuttig is in scenario's met weinig middelen.", 'da': 'At udvinde parallelle sætninger fra sammenlignelige corpora er af stor interesse for mange downstream opgaver. I BUCC 2017 delte opgave klarede systemerne sig godt ved at træne i guld standard parallelle sætninger. Men vi ønsker ofte at udvinde parallelle sætninger uden tosproget tilsyn. Vi præsenterer en enkel tilgang baseret på tosprogede ord indlejringer trænet på en uautoriseret måde. Vi indarbejder ortografisk lighed for at håndtere ord med lignende overfladeformer. Derudover foreslår vi en dynamisk tærskelmetode til at afgøre, om et kandidatsætningspar er parallelt, hvilket eliminerer behovet for at finjustere en statisk værdi for forskellige datasæt. Da vi ikke anvender nogen sprogspecifik teknik, er vores tilgang yderst generisk. Vi viser, at vores tilgang er effektiv, på tre sprogpar, uden brug af noget tosproget signal, hvilket er vigtigt, fordi parallel sætning mining er mest nyttigt i scenarier med lave ressourcer.', 'hr': 'Paralelne rečenice iz usporednog tijela imaju veliki interes za mnoge nedaleko zadatke. U zajedničkom zadatku BUCC 2017, sustavi su dobro obavljeni vježbama o zlatnim standardnim paralelnim kaznama. Međutim, često želimo uzeti paralelne rečenice bez dvojezičkog nadzora. Predstavljamo jednostavan pristup koji se oslanja na dvojezičke riječi uključene na neodređeni način. Uključujemo ortografsku sličnost kako bismo riječi riječima riječima sličnim površinskim oblicima. Osim toga, predlažemo dinamičnu prašku metodu da odlučimo da li je par kandidata paralelna koja eliminira potrebu da se odredi stanična vrijednost za različite datasete. Budući da ne zapošljavamo jezički inženjering, naš pristup je veoma generičan. Pokazujemo da je naš pristup učinkovit, na tri jezička parova, bez upotrebe bilo kojeg dvojezičkog signala koji je važan jer je paralelno rudarstvo rečenica najkorisnije u nizim scenarijama resursa.', 'de': 'Das Mining von parallelen Sätzen aus vergleichbaren Korpora ist für viele nachgelagerte Aufgaben von großem Interesse. In der gemeinsamen Aufgabe BUCC 2017 haben Systeme durch Training auf Gold Standard parallele Sätze gut funktioniert. Allerdings wollen wir oft parallele Sätze ohne zweisprachige Aufsicht abbauen. Wir präsentieren einen einfachen Ansatz, der sich auf zweisprachige Worteinbettungen stützt, die in einer unbeaufsichtigten Weise trainiert wurden. Wir integrieren orthographische Ähnlichkeit, um Wörter mit ähnlichen Oberflächenformen zu verarbeiten. Darüber hinaus schlagen wir eine dynamische Schwellenmethode vor, um zu entscheiden, ob ein Kandidatenpaar parallel ist, wodurch die Notwendigkeit entfällt, einen statischen Wert für verschiedene Datensätze zu verfeinern. Da wir kein sprachspezifisches Engineering einsetzen, ist unser Ansatz sehr generisch. Wir zeigen, dass unser Ansatz effektiv ist, auf drei Sprachpaaren, ohne die Verwendung eines zweisprachigen Signals, was wichtig ist, da paralleles Satz Mining am nützlichsten in ressourcenarmen Szenarien ist.', 'id': 'Menambah kalimat paralel dari corpora yang bisa dibandingkan adalah minat besar untuk banyak tugas turun. Dalam tugas berbagi BUCC 2017, sistem berhasil dengan latihan pada kalimat paralel standar emas. Namun, kita sering ingin menimbulkan kalimat paralel tanpa pengawasan dua bahasa. Kami mempersembahkan pendekatan sederhana bergantung pada pembangunan kata dua bahasa dilatih dengan cara yang tidak diawasi. Kami memasukkan persamaan ortografik untuk menangani kata-kata dengan bentuk permukaan yang sama. Selain itu, kami mengusulkan metode ambang dinamik untuk memutuskan apakah sepasang kalimat kandidat adalah paralel yang menghapuskan kebutuhan untuk memperbaiki nilai statis untuk set data yang berbeda. Since we do not employ any language specific engineering our approach is highly generic.  Kami menunjukkan bahwa pendekatan kita efektif, pada tiga pasangan bahasa, tanpa menggunakan sinyal dua bahasa apapun yang penting karena penggunaan kalimat paralel adalah paling berguna dalam skenario sumber daya rendah.', 'fa': 'جمله\u200cهای متفاوتی از شرکت قابل مقایسه برای بسیاری از کارهای پایین، علاقه\u200cای بزرگ است. در کار مشترک BUCC ۲۰۱۷، سیستم\u200cها با تمرین کردن جمله\u200cهای پارالی طلا به خوبی انجام می\u200cدادند. ولی ما اغلب می\u200cخواهیم جمله\u200cهای متفاوتی را بدون مراقبت دوزبانی منتقل کنیم. ما روش ساده\u200cای را پیش می\u200cنماییم که بر کلمه\u200cهای دو زبان تهیه می\u200cشود که در حالی ناپایدار آموزش داده شده است. ما شباهت orthographic را برای استفاده از کلمات با فرم های سطح مشابه جمع می کنیم. در addition, we propose a dynamic threshold method to decide whether a candidate sentence-pair is parallel which eliminates the need to fine tune a static value for different datasets. از اونجایی که ما هیچ مهندسی مخصوص زبانی را استفاده نمی کنیم، روش ما خیلی معمولی است. ما نشان می دهیم که روش ما در سه جفت زبان موثر است، بدون استفاده از هر سیگنال دو زبان که مهم است، زیرا تولید کردن جمله\u200cهای متفاوتی در سناریو کم منابع است.', 'ko': '비교 가능한 자료 라이브러리에서 평행문을 발굴하는 것은 많은 하류 임무에 큰 의미를 가진다.BUCC 2017 공유 임무에서 시스템은 황금 표준 평행문 교육을 통해 양호한 모습을 보였다.그러나 우리는 이중 언어의 감독이 없는 상황에서 평행문장을 발굴하기를 바란다.우리는 무감독 방식으로 훈련된 이중 언어 단어에 의존하는 간단한 방법을 제시했다.비슷한 표면 형식의 단어를 처리하기 위해 우리는 맞춤법의 유사성을 넣었다.그 밖에 우리는 동적 한도값 방법을 제시하여 후보 문장이 평행 여부를 확정함으로써 서로 다른 데이터 집합의 정적 값을 미세하게 조정하는 수요를 없앴다.우리는 언어에 특정한 공정을 채택하지 않기 때문에, 우리의 방법은 매우 통용된다.우리는 우리의 방법이 세 가지 언어에 효과가 있고 이중 언어 신호를 사용하지 않는다는 것을 증명했다. 이 점은 매우 중요하다. 왜냐하면 병행 문장 발굴은 저자원 장면에서 가장 유용하기 때문이다.', 'sw': 'Mining parallel sentences from comparable corpora is of great interest for many downstream tasks.  Katika jukumu la BUCC 2017, mifumo ilifanya vizuri kwa mafunzo ya sheria za dhahabu zilizofanana. Hata hivyo, mara nyingi tunataka kuangalia hukumu mbalimbali bila kufuatilia lugha mbili. Tunaweka mbinu rahisi za kutegemea maneno ya lugha mbili yaliyofundishwa kwa namna isiyo sahihi. Tunajenga sawa na upande wa kiraia ili kukabiliana na maneno yanayofanana na sura hiyo. Zaidi ya hayo, tunapendekeza njia ya utaratibu wa kisasa kuamua kama mgombea wa sentence wawili na wawili ni sawa na kinachoondoa haja ya kuboresha thamani ya takwimu tofauti. Kwa sababu hatutumii lugha yoyote mahususi ya uhandisi mwelekeo wetu ni wa kawaida sana. Tunaonyesha kwamba mbinu yetu ni yenye ufanisi, katika lugha tatu, bila kutumia ishara yoyote ya lugha mbili ambazo ni muhimu kwa sababu uchimbaji wa hukumu uliofanana ni muhimu sana katika maeneo ya rasilimali ya chini.', 'tr': 'Köp görşikli korpoýanyň parallel sözleriň azalmak birnäçe indiki işleriň üçin gaty gyzyklanýar. BUCC 2017-nji ýylda bölünen işi, sistemalar altyn standart parallel sözleri üçin gowy işleýärler. Ýöne biz köplenç çift sözlerimizi, paralleli sözlerimizi diýmek isleýäris. Biz iki dilli söz içinde bilinmedik şeklinde bilinmedik bir ýagdaýa güýçli bir ýagdaýy görkeýäris. Sözleri benzer bir yüze şeklinde çözmek için ortografik benzeri bölünmüz. Munuň üstine, biz dinamik süýşik yöntemi üýtgetmek üçin bir karar bermek üçin bir süýşik gijesi teklif edip görýäris. Çünki biz hiç hili dil takyk enjiniýasyny ulanmaýarys, biziň ýaryşymyz gaty döredik. Biz özümiziň ýaryşymyz üç dil çift üçin täsirli bolandygyny görkeýäris. Bu iki dil sinyalynyň ullanmasynyň wajypdyr, sebäbi parallel sözleriň taýýarlanmasy iň az sanlarynda has bagly.', 'sq': 'Minimi i dënimeve paralele nga korpra të krahasueshme është me interes të madh për shumë detyra poshtë. Në detyrën e përbashkët të BUCC 2017, sistemet u kryen mirë duke trajnuar me fjalë paralele të arta. Megjithatë, ne shpesh duam të miniojmë dënime paralele pa mbikqyrje dygjuhe. Ne paraqesim një qasje të thjeshtë mbështetur në përfshirje të fjalëve dygjuhëse të stërvitura në një mënyrë të pazgjidhur. Ne përfshijmë ngjashmëri ortografike në mënyrë që të trajtojmë fjalë me forma të ngjashme sipërfaqe. Përveç kësaj, ne propozojmë një metodë dinamike pragu për të vendosur nëse një çift fjalësh kandidate është paralel që eleminon nevojën për të rregulluar një vlerë statike për të dhëna të ndryshme. Sepse ne nuk përdorim asnjë inxhinier specifik gjuhësh metoda jonë është shumë gjenerike. Ne tregojmë se metoda jonë është e efektshme, në tre çifte gjuhësh, pa përdorimin e ndonjë sinjali dygjuhës që është e rëndësishme sepse miniera paralele e fjalëve është më e dobishme në skenarët e ulët të burimeve.', 'af': "Mining parallele setings van vergelykbare korpora is van groot belang vir baie onderstreem taak. In die BUCC 2017 deel taak, stelsels wat goed uitgevoer het deur onderwerp op goud standaard parallele teikens. Maar ons wil dikwels die parallele setnings sonder twee tale supervisie myne. Ons stel 'n eenvoudige toegang wat vertrou op twee tonge woord inbêding wat in 'n ononderwerpende manier opgelei is. Ons inkorporeer orthografiese gelykenis om woorde te hanteer met gelyke oorspronklike vorms. In addition, we propose a dynamic threshold method to decide if a candidate sentence-pair is parallel which eliminates the need to fine tune a static value for different datasets. Omdat ons nie enige taal spesifieke inženiering gebruik nie, is ons toegang baie generiek. Ons wys dat ons toegang effektief is, op drie taal-paar, sonder die gebruik van enige twee tale sein wat belangrik is, omdat parallele setingemining is mees nuttig in lae hulpbron-scenarios.", 'am': 'ከአስተያየት ኮርፖርት የሚደረገውን ተቃውሞ በማስተካከል ለብዙ ፈሳሾች ትርጉም ነው፡፡ በBUCC 2017 የተካፈሉ ስራዎችን፣ ስርዓቶች በወርቅ standard በሚያሳየው ፍርድ ማስተማርን በመልካም ያደርጋሉ፡፡ ነገር ግን ብዙ ጊዜ በሁለት ቋንቋዎች ላይ ሳይኖር የምናስተያየት ፍርድ ልናደርግ እንፈልጋለን፡፡ በሁለት ቋንቋ ቃላት ላይ የሚታመን ቀላል ሥርዓት እናደርጋለን፡፡ እና ቃላትን በመስመር ላይ እናስቀራለን፡፡ በተጨማሪም፣ የአካባቢው የቁጥጥር ሁለት ዓይነቶች ቢተካከሉ እናስቆጣለን፡፡ ምንም ቋንቋ ያላገኘን የግንኙነታችንን አካባቢ ነው፡፡ አካሄዳችን በሦስት ቋንቋ-ዓይነቶች ላይ ጥቅም እንደሆነ እናሳያቸዋለን፤ የግንኙነት ግንኙነት ግንኙነት አነስተኛ ከታናሽ ክፍል የተጠቃሚ ነው፡፡', 'hy': 'Mining parallel sentences from comparable corpora is of great interest for many downstream tasks.  2017 թվականին ընդհանուր աշխատանքի ընթացքում համակարգերը լավ աշխատեցին՝ վարժեցնելով ոսկու ստանդարտ զուգահեռ նախադասություններ: Այնուամենայնիվ, մենք հաճախ ցանկանում ենք հանել զուգահեռ նախադասություններ առանց երկլեզու վերահսկողության: Մենք ներկայացնում ենք պարզ մոտեցում, որը հիմնված է երկլեզու բառերի ներգրավման վրա, որոնք սովորեցվել են անվերահսկված կերպով: Մենք ներառում ենք օրտոգրաֆիկ նմանությունը, որպեսզի բառերը վերաբերվեն նմանատիպ մակերևույթի ձևերով: Ավելին, մենք առաջարկում ենք դինամիկ խորհրդային մեթոդ որոշելու համար, թե արդյոք թեկնածու նախադասությունների զույգ զույգ է, որը վերացնում է տարբեր տվյալների համակարգերի վիճակագրական արժեքը բարձրացնելու կարիքը: Քանի որ մենք ոչ մի լեզվի մասնավոր ճարտարագիտություն չենք օգտագործում, մեր մոտեցումը շատ ընդհանուր է: Մենք ցույց ենք տալիս, որ մեր մոտեցումը արդյունավետ է երեք լեզվի զույգերի վրա, առանց որևէ երկլեզու ազդանշանի օգտագործման, ինչը կարևոր է, քանի որ զուգահեռ նախադասությունների հանքահանումը ամենաօգտակար է ցածր ռեսուրսների', 'bn': 'তুলনামূলক কোর্পোরা থেকে প্যারালেল শাস্তি নিয়ে অনেক নিচের কাজের জন্য খুবই আগ্রহী। বিউসিসি ২০১৭ সালে ভাগাভাগি করা কাজে সোনার স্ট্যান্ডারেল স্যান্ডারেলের প্রশিক্ষণের মাধ্যমে সিস্টে তবে আমরা প্রায়শই দুই ভাষা পর্যবেক্ষন ছাড়া প্যারালেলিটি শাস্তি আমাদের কাজ করতে চাই। আমরা দুই ভাষার শব্দের উপর নির্ভর করার একটি সহজ উপায় উপস্থাপন করি অরক্ষিত ফ্যাশনে প্রশিক্ষিত। আমরা একই ধরনের পৃষ্ঠার মাধ্যমে শব্দগুলোকে সামলাতে orthografi সমতুল্য করি। তাছাড়াও, আমরা একটি ডায়ান্ডামিক স্থানীয় পদ্ধতি প্রস্তাব করি যেন সিদ্ধান্ত নিতে পারি কোন প্রার্থীকের বাক্য-জোড়া প্রার্থীর সাথে যু যেহেতু আমরা কোন ভাষা নির্দিষ্ট ইঞ্জিনিয়ারের কাজ করি না আমাদের প্রতিযোগিতা অত্যন্ত সাধারণ। আমরা দেখাচ্ছি যে আমাদের প্রতিযোগিতা কার্যকর, তিন ভাষার জোড়ায়, কোন দুই ভাষার সিগন্যাল ব্যবহার ছাড়া, যা গুরুত্বপূর্ণ কারণ প্যারালেল', 'az': 'Körüncül korporadan paralel sözləri dağıtmaq bir çox aşağı işlər üçün çox maraqlıdır. BUCC 2017 ilə paylaşılan işdə, sistemlər altın standart paralel sözlərinin təhsil edilməsi ilə yaxşı işlədilər. Ancaq biz sık-sıq dil gözləmədən paralel cümlələrimi mənimlə etmək istəyirik. Biz iki dil sözlərinə bağlı, müəyyən edilməmiş bir şəkildə təhsil edilməyən tərzdə asan bir approach göstəririk. Bütün sözləri bənzər surat formları ilə istifadə etmək üçün ortografik bənzəri birləşdiririk. Əvvəlcə, biz müxtəlif verilən qurğular üçün statik qiyməti təyin etmək üçün müəyyən edilən cümlənin çift paralel olduğuna karar vermək üçün dinamik hissə metodu təklif edirik. Biz heç bir dil mühendisliyini istifadə etmədikdən sonra, bizim tərəfimiz çox generikdir. Bizim tərəfimiz üç dil çiftində, hər iki dil sinyali istifadə etmədən faydalandığını göstəririk, çünki paralel sözlər madencisi düşük ressurs senaryolarında ən faydalandırır.', 'ca': "Miniar frases paralleles de corpores comparables és molt interessant per moltes tasques avall. A la tasca compartida del BUCC 2017, els sistemes van funcionar bé treinant frases paralleles d'or. Però sovint volem minerar frases paralleles sense supervisió bilingüe. Presentam un enfocament senzill basant-nos en les integracions bilingües entrenades de manera no supervisada. Incorporem la similitud ortogràfica per manejar paraules amb formes similars de superfície. A més, proposem un mètode dinàmic de umbre per decidir si un parell de frases candidats és paral·lel que elimina la necessitat de ajustar un valor estatic per a diferents conjunts de dades. Com que no utilitzem enginyeria específica de llenguatges, el nostre enfocament és molt genèric. Mostrem que el nostre enfocament és eficaç, en tres parelles de llenguatges, sense l'ús de cap senyal bilingüe que sigui important perquè la mineria paralèl·lela de frases és més útil en escenaris de baix recursos.", 'bs': 'Pranje paralelnih rečenica iz usporednog korporacije je od velikog interesa za mnoge zadatke. U zajedničkom zadatku BUCC 2017, sistemi su dobro obavljeni obukom zlatnih standardnih paralelnih rečenica. Međutim, često želimo uzeti paralelne rečenice bez dvojezičkog nadzora. Predstavljamo jednostavan pristup koji se oslanja na dvojezičke riječi ugrađene na neodređenom načinu. Uključujemo ortografsku sličnost kako bismo riječi riječima riječima sličnim oblicima površine. Osim toga, predlažemo dinamičnu prašku metodu da odlučimo da li je par kandidata paralelna koja eliminira potrebu da ispravi statičnu vrijednost za različite datasete. Pošto ne zapošljavamo nikakve jezičke inženjerstvo, naš pristup je veoma generičan. Pokazujemo da je naš pristup efikasan, na tri jezička parova, bez upotrebe bilo kojeg dvojezičkog signala koji je važan jer je paralelno rudarstvo rečenica najkorisnije u nizim scenarijama resursa.', 'fi': 'Rinnakkaisten lauseiden louhinta vertailukelpoisista korpusista on erittäin kiinnostavaa monissa jatkojalostustehtävissä. BUCC 2017:n yhteisessä tehtävässä järjestelmät suoriutuivat hyvin harjoittelemalla kultaisia rinnakkaislauseita. Haluamme kuitenkin usein loukata rinnakkaisia lauseita ilman kaksikielistä valvontaa. Esitämme yksinkertaisen lähestymistavan, joka perustuu kaksikielisiin sanaupotuksiin, jotka on koulutettu valvomattomasti. Käytämme ortografista samankaltaisuutta, jotta voimme käsitellä sanoja, joilla on samanlaisia pintamuotoja. Lisäksi ehdotamme dynaamista kynnysmenetelmää sen määrittämiseksi, onko ehdokkaan lausepari rinnakkain, mikä poistaa tarpeen hienosäätää staattista arvoa eri aineistoille. Koska emme käytä mitään kielispesifistä tekniikkaa, lähestymistapamme on hyvin yleinen. Osoitamme, että lähestymistapamme on tehokas, kolmella kieliparilla, ilman kaksikielistä signaalia, mikä on tärkeää, koska rinnakkaislauseiden louhinta on hyödyllisintä vähävaraisissa skenaarioissa.', 'cs': 'Dolování paralelních vět ze srovnatelných korpusů je velkým zájmem pro mnoho následných úkolů. Ve sdíleném úkolu BUCC 2017 se systémy provedly dobře tréninkem na zlatém standardu paralelních vět. Často však chceme těžit paralelní věty bez dvojjazyčného dohledu. Představujeme jednoduchý přístup spoléhající na dvojjazyčné vložení slov trénované bez dohledu. Zahrnujeme ortografickou podobnost, abychom zpracovali slova s podobnými povrchovými tvary. Navíc navrhujeme dynamickou metodu prahové hodnoty, která rozhodne, zda je kandidátský pár vět paralelní, což eliminuje potřebu doladit statickou hodnotu pro různé datové sady. Protože nepoužíváme žádné jazykové inženýrství, je náš přístup velmi obecný. Ukazujeme, že náš přístup je efektivní, na třech jazykových párech, bez použití jakéhokoliv dvojjazyčného signálu, což je důležité, protože paralelní dolování vět je nejvíce užitečné v scénářích s nízkými zdroji.', 'et': 'Paralleelsete lausete kaevandamine võrreldavatest korpustest on paljude järgnevate ülesannete jaoks väga huvitav. BUCC 2017 jagatud ülesandes said süsteemid hästi hakkama kuldstandardite paralleelsete lausete koolitamisega. Siiski tahame sageli kaevandada paralleelseid lauseid ilma kahekeelse järelevalveta. Esitame lihtsa lähenemisviisi, mis tugineb kahekeelsetele sõnade manustamisele, mis on treenitud järelevalveta. Sisaldame ortograafilist sarnasust, et käsitleda sarnaste pinnavormidega sõnu. Lisaks pakume välja dünaamilise läve meetodi, et otsustada, kas kandidaat lausepaar on paralleelne, mis välistab vajaduse täpsustada staatilist väärtust erinevate andmekogumite jaoks. Kuna me ei kasuta keelespetsiifilist tehnikat, on meie lähenemisviis väga üldine. Näitame, et meie lähenemisviis on tõhus kolme keelepaari puhul, ilma kahekeelse signaali kasutamata, mis on oluline, sest paralleelne lausekaevandamine on kõige kasulikum vähese ressursiga stsenaariumides.', 'he': 'משפטים משותפים משותפים משותפים זה מעניין גדול עבור משימות רבות מתחתיות. במשימה המשותפת של BUCC 2017, מערכות הופעו היטב באמצעות אימון על משפטים מקבילים סטנדרטיים זהב. עם זאת, לעתים קרובות אנחנו רוצים למחוק משפטים מקבילים ללא פיקוח שתיים. אנו מציגים גישה פשוטה תלויה בתכניות מילים שתיים ששונות מאומנות באופן בלתי משגיח. אנחנו מכילים דמיון אורטוגרפי כדי לטפל במילים עם צורות פנים דומות. בנוסף, אנו מציעים שיטת גבול דינמית כדי להחליט אם זוג משפט מועמד הוא מקביל, מה ששומר את הצורך לתקן ערך סטטי עבור קבוצות נתונים שונים. מכיוון שאנחנו לא משתמשים בהנדסה ספציפית לשפה הגישה שלנו היא גנרלית מאוד. We show that our approach is effective, on three language-pairs, without the use of any bilingual signal which is important because parallel sentence mining is most useful in low resource scenarios.', 'sk': 'Pridobivanje vzporednih stavkov iz primerljivih korpusov je zelo zanimivo za številne nadaljnje naloge. V skupni nalogi BUCC 2017 so sistemi uspešni z usposabljanjem o vzporednih stavkih zlatih standardov. Vendar pa pogosto želimo izkopati vzporedne stavke brez dvojezičnega nadzora. Predstavljamo preprost pristop, ki temelji na dvojezičnih besednih vdelavah, usposobljenih na nenadzorovan način. Vključujemo ortografsko podobnost za obravnavo besed s podobnimi površinskimi oblikami. Poleg tega predlagamo metodo dinamičnega praga za odločitev, ali je kandidatni par stavkov vzporeden, kar odpravlja potrebo po natančnem nastavitvi statične vrednosti za različne nabore podatkov. Ker ne uporabljamo nobenega jezikovnega inženiringa, je naš pristop zelo generičen. Pokazujemo, da je naš pristop učinkovit, pri treh jezikovnih parih, brez uporabe dvojezičnega signala, kar je pomembno, ker je vzporedno rudarjenje stavkov najbolj uporabno v scenarijih z nizkimi viri.', 'ha': "Ki ƙara da saurãre masu daidaita daga makampuni na kamata, yana da amfani mai girma wa masu aiki mãsu yawa na ƙarƙashin mito. In the BUCC 2017 share job, the system performs properly by learning on the normal filename of gull parallel. Kayya, ko da yawa munã so da cuta kalmõmi masu daidaita, bã da wani suryau na biyu. Kuma Munã zuwa wani mataimaki mai sauƙi wanda ke dõgara a kan maganar biyu da aka sanar da shi a cikin wani bakin da ba'a tsare ba. Munã shigar da shirin orthografi don ka yi amfani da wasu kalmõmi da ke daidaita. Da wannan, Munã buɗa wata hanyor tunci mai gyare-gyare don ka ƙayyade cewa wani ma'anar sigar-biyu ne da za'a cire kwamfyuta don a gyara wani kima na static wa daidaita danne-daban. Kayya da ba mu aiki wani harshe na'ura masu muhimmada ne mai girma. Tuna nũna cewa hanyarmu yana da amfani, a kan misalin harshe-sau uku, kuma bã da amfani da wani alama na biyu wanda ke da muhimu, kwani ƙaramin maganar da aka daidaita shi yana da amfani mafi ƙaranci a cikin fassarar wuri.", 'jv': 'Gujaring Nang negori bangsane UEC-1997, sistem sing ditambahak segala macem nganggo perusahaan segala ping cadang dolanan. Pilih, awak dh챕w챕 ngerti kapan kuwi nggo langgar lawang kuwi dulihan y챔n. Awak dh챕w챕 챕ntuk sistem sing sampeyan ing nguasai iki dadi sak sekang awak dh챕w챕 nggawe barang apik. Awak dh챕w챕 챕ntuk akses ortograf sampeyan nggawe gambar aturan karo ngono pergambar param. Mungkin Suara awak dh챕w챕 ora nggunakake ing sakjan챕 kanggo ingkang dipunang챕, dadi sing kat챗pakan j챗n챗r. Awak dh챕w챕 ngerasakno punika diangkat awak dh챕w챕, ning telu nggawe gerakan karo sistem sing gak dh챕w챕, kuwi nggawe sistem sing gak dh챕w챕, kuwi nggawe Perintah terangk챕 kuwi tindakan sing paling dh챕w챕 kuwi nggawe', 'bo': 'མཐུན་རྐྱེན་པའི་ཚོང་ཁང་ལས་སྒྲིག་འཇུག་པའི་ཚིག་རྣམས་ལས་མཐུན་པ་མང་པོ་ཞིག་ཡིན་པ། BUCC ལོ༢༧༠ལ་སྤྱི་ཚོགས་ཀྱི་ལས་འགན་སྤྱད་པ་དེ་ནི་་རིམ་པ་གྱི་ཚད་རྟགས་མཐུན་གྱི་ཚིག་རྩལ་ལས་སྦྱོར་བྱེ ཡིན་ནའང་། ང་ཚོས་རྒྱུན་དུ་ངའི་ཚིག་རྟགས་ཕུང་ལྟ་བུ་མི་འདུག་པས་ ང་ཚོས་སྐད་ཡིག་གཟུགས་རིས་ཀྱི་ཐབས་ལམ་ལ་སླེབས་པའི་ནང་གི་མཐུན་སྣེ་གསལ་པོ་ཞིག་སྟོན་ཡོད། We incorporate orthographic similarity in order to handle words with similar surface forms. འོན་ཀྱང་། ང་ཚོས་རྣམ་པ་ཞིག་གི་ཆ་འཕྲིན་གྱི་ཚད་ལྡན་ཐབས་ལམ་ཞིག་སྤྲོད་དགོས་མིན་ན། ང་ཚོས་སྐད་ཡིག་ཆ་དམིགས་འཛུགས་ཀྱི་ལས་འགུལ་གྱི་བཟོ་བཅོས་གང་ཡང་བེད་སྤྱོད་མེད་ལས་བརྟེན། We show that our approach is effective, on three language-pairs, without the use of any bilingual signal which is important because parallel sentence mining is most useful in low resource scenarios.'}
{'en': 'Analyzing Knowledge Distillation in Neural Machine Translation', 'ar': 'تحليل تقطير المعرفة في الترجمة الآلية العصبية', 'es': 'Análisis de la destilación del conocimiento en la traducción automática neuronal', 'pt': 'Analisando a Destilação do Conhecimento na Tradução Automática Neural', 'fr': 'Analyse de la distillation des connaissances en traduction automatique neuronale', 'zh': '析神经机器翻译中知识提炼', 'ja': '神経機械翻訳における知識蒸留の分析', 'hi': 'न्यूरल मशीन अनुवाद में ज्ञान आसवन का विश्लेषण', 'ru': 'Анализ дистилляции знаний в нейронном машинном переводе', 'ga': 'Anailís a dhéanamh ar Dhriogadh Eolais i Néar-Aistriúchán Meaisín', 'ka': 'Name', 'hu': 'A tudás desztillációjának elemzése a neurális gépi fordításban', 'el': 'Ανάλυση της απόσταξης γνώσης στη νευρωνική μηχανική μετάφραση', 'mk': 'Анализирање на дистилација на знаење во превод на неврална машина', 'it': 'Analisi della distillazione della conoscenza nella traduzione automatica neurale', 'kk': 'Нейрондық машинаның аудармасында білім бөлімін талдау', 'lt': 'Mokslinių žinių distiliacijos neurologinių mašin ų vertimuose analizė', 'ml': 'നെയുറല്\u200d യന്ത്രത്തിലെ അറിവുകളുടെ വിവരങ്ങള്\u200d അന്വേഷിക്കുന്നു', 'ms': 'Menganalisis Distillasi Pengetahuan dalam Terjemahan Mesin Neural', 'mt': 'Analiżi tad-Distillazzjoni tal-Għarfien fit-Traduzzjoni tal-Magna Newrali', 'mn': 'Сэтгэл машины хөрөнгө оруулалтын мэдлэгийг шинжилгээ', 'ro': 'Analiza distilarii cunoștințelor în traducerea automată neurală', 'pl': 'Analiza destylacji wiedzy w neuronowym tłumaczeniu maszynowym', 'no': 'Analiserer forstyring av kunnskap i neuralmaskineomsetjing', 'sr': 'Analiziranje destilacije znanja u Neuralnom prevodu mašine', 'si': 'Name', 'sv': 'Analysera kunskapsdestillation i neural maskinöversättning', 'ta': 'Analyzing Knowledge Distillation in Neural Machine Translation', 'so': 'Analysis sharciga aqoonta ee turjumidda maskinenta Neural', 'ur': 'نیورال ماشین ترجمہ میں علم دیسٹیل تحلیل کرتا ہے', 'uz': 'Tarjima qilish', 'vi': 'Phân tách tri thức trong dịch sang máy thần kinh', 'bg': 'Анализиране на дестилацията на знанието в невралния машинен превод', 'nl': 'Analyse van kennisdestillatie in neuronale machinevertaling', 'hr': 'Analiziranje destilacije znanja u prevodu neuroloških strojeva', 'da': 'Analyse af videndedestillation i neural maskinoversættelse', 'ko': '신경 기계 번역 중의 지식 추출 분석', 'fa': 'تحلیل کردن تحلیل دانش در ترجمه ماشین عصبی', 'id': 'Analisasi Distillasi Pengetahuan dalam Translation Mesin Neural', 'de': 'Analyse der Wissensdestillation in der neuronalen maschinellen Übersetzung', 'sw': 'Anachambua Kutokana na maarifa katika Tafsiri ya Mashiniki ya Neurali', 'tr': 'Nural Makina terjimesinde Bilim Taýdalygyny çözümleme', 'sq': 'Analizimi i distilacionit të njohurive në përkthimin e makinës nervore', 'af': 'Analiseer kennis verspreiding in Neurale Masjien Vertaling', 'am': 'ምርጫዎች', 'hy': 'Նյարդային մեքենայի թարգմանման մեջ գիտելիքների դիստիլացիայի վերլուծությունը', 'az': 'N√∂ral Makin √áevirm…ôsind…ô Bilim Daƒüƒ±lmasƒ±', 'bn': 'নিউরাল মেশিন অনুবাদে জ্ঞান বিভ্রান্তি বিশ্লেষণ করা হচ্ছে', 'bs': 'Analiziranje destilacije znanja u neurološkom prevodu strojeva', 'ca': 'Analitzar la distilació del coneixement en la traducció de la màquina neuronal', 'et': 'Teadmiste destillatsiooni analüüsimine neuroaalses masintõlkes', 'cs': 'Analýza destilace znalostí v neuronovém strojovém překladu', 'fi': 'Tietojen tislauksen analysointi neurokonekäännöksessä', 'jv': 'Ngubah Isotol Bilih nang Terjamahan Neral', 'he': 'ניתוח דיסטיל ידע בתרגום מכונות נוירות', 'ha': 'Ana Ana Ana Ana Cilmi cikin Tarjima na Maine na Neural', 'sk': 'Analiza destilacije znanja v nevralnem strojnem prevajanju', 'bo': 'Neural Machine Translation ནང་དུ་ཤེས་པའི་སྐོར་གྱི་དབྱིབས་རྩིས་ཞིབ་དཔྱད་བྱེད་ཀྱི་ཡོད་པ'}
{'en': 'Knowledge distillation has recently been successfully applied to  neural machine translation . It allows for building shrunk networks while the resulting  systems  retain most of the quality of the original  model . Despite the fact that many authors report on the benefits of knowledge distillation, few have discussed the actual reasons why it works, especially in the context of neural MT. In this paper, we conduct several experiments aimed at understanding why and how  distillation  impacts  accuracy  on an English-German translation task. We show that translation complexity is actually reduced when building a distilled / synthesised bi-text when compared to the reference bi-text. We further remove noisy data from synthesised translations and merge filtered synthesised data together with original reference, thus achieving additional gains in terms of  accuracy .', 'fr': "La distillation des connaissances a récemment été appliquée avec succès à la traduction automatique neuronale. Il permet de construire des réseaux réduits alors que les systèmes qui en résultent conservent la plus grande partie de la qualité du modèle d'origine. Malgré le fait que de nombreux auteurs font état des avantages de la distillation des connaissances, peu ont discuté des raisons réelles pour lesquelles elle fonctionne, en particulier dans le contexte de la magnétoscopie neuronale. Dans cet article, nous menons plusieurs expériences visant à comprendre pourquoi et comment la distillation affecte la précision d'une tâche de traduction anglais-allemand. Nous montrons que la complexité de la traduction est en fait réduite lors de la création d'un bi-texte distillé/synthétisé par rapport au bi-texte de référence. Nous supprimons également les données bruyantes des traductions synthétisées et fusionnons les données synthétisées filtrées avec la référence d'origine, ce qui permet d'obtenir des gains supplémentaires en termes de précision.", 'pt': 'A destilação do conhecimento foi recentemente aplicada com sucesso à tradução automática neural. Ele permite a construção de redes reduzidas enquanto os sistemas resultantes mantêm a maior parte da qualidade do modelo original. Apesar de muitos autores relatarem os benefícios da destilação do conhecimento, poucos discutiram as reais razões pelas quais ela funciona, especialmente no contexto da MT neural. Neste artigo, realizamos vários experimentos com o objetivo de entender por que e como a destilação afeta a precisão em uma tarefa de tradução inglês-alemão. Mostramos que a complexidade da tradução é realmente reduzida ao construir um bitexto destilado/sintetizado quando comparado ao bitexto de referência. Além disso, removemos os dados ruidosos das traduções sintetizadas e mesclamos os dados sintetizados filtrados com a referência original, obtendo ganhos adicionais em termos de precisão.', 'ar': 'تم مؤخرًا تطبيق تقطير المعرفة بنجاح على الترجمة الآلية العصبية. يسمح ببناء شبكات منكمشة بينما تحتفظ الأنظمة الناتجة بمعظم جودة النموذج الأصلي. على الرغم من حقيقة أن العديد من المؤلفين يقدمون تقارير عن فوائد تقطير المعرفة ، إلا أن القليل منهم ناقش الأسباب الفعلية وراء نجاحه ، لا سيما في سياق الترجمة الآلية العصبية. في هذه الورقة ، نجري العديد من التجارب التي تهدف إلى فهم سبب وكيفية تأثير التقطير على الدقة في مهمة ترجمة من الإنجليزية إلى الألمانية. نظهر أن تعقيد الترجمة يتم تقليله فعليًا عند بناء نص ثنائي مقطر / مركب عند مقارنته بالنص الثنائي المرجعي. نقوم كذلك بإزالة البيانات المزعجة من الترجمات المركبة ودمج البيانات المركبة المصفاة مع المرجع الأصلي ، وبالتالي تحقيق مكاسب إضافية من حيث الدقة.', 'es': 'La destilación del conocimiento se ha aplicado recientemente con éxito a la traducción automática neuronal. Permite construir redes reducidas, mientras que los sistemas resultantes conservan la mayor parte de la calidad del modelo original. A pesar de que muchos autores informan sobre los beneficios de la destilación del conocimiento, pocos han discutido las razones reales por las que funciona, especialmente en el contexto de la MT neuronal. En este artículo, realizamos varios experimentos con el objetivo de comprender por qué y cómo la destilación afecta la precisión en una tarea de traducción del inglés al alemán. Demostramos que la complejidad de la traducción en realidad se reduce al crear un bitexto destilado o sintetizado en comparación con el bitexto de referencia. Eliminamos aún más los datos ruidosos de las traducciones sintetizadas y combinamos los datos sintetizados filtrados con la referencia original, logrando así ganancias adicionales en términos de precisión.', 'zh': '知蒸馏近成功用于神经机器翻译。 其许构缩小之网络,同时生成之统存其大体。 虽众作者陈知蒸馏之利,而罕论其实,特在神经机器翻译之背景。 于本文中,行数实验,旨在知蒸馏,何及英语 - 德语翻译之准确性。 明与参双文本相比,构/合双文本,译复杂性实降。 更于综译中除噪声数,并漉后合数与原始参合,以获额外之益于准确性。', 'ja': 'ナレッジ蒸留は最近、神経機械翻訳にうまく適用されました。これにより、縮小されたネットワークを構築することができますが、結果として生じるシステムは、元のモデルの品質のほとんどを保持します。多くの著者が知識蒸留の利点について報告しているにもかかわらず、特にニューラルMTの文脈では、実際の理由を議論することはほとんどありません。この論文では、蒸留が英独翻訳タスクの精度に影響を与える理由と方法を理解することを目的としたいくつかの実験を行っています。我々は、実際には、参照バイテキストと比較して、蒸留/合成されたバイテキストを構築するときに翻訳の複雑性が低下することを示している。さらに、合成された翻訳からノイズの多いデータを削除し、フィルタリングされた合成データを元の参照とともにマージすることで、正確性の観点からさらなる利得を達成します。', 'hi': 'ज्ञान आसवन हाल ही में सफलतापूर्वक तंत्रिका मशीन अनुवाद के लिए लागू किया गया है। यह सिकुड़े हुए नेटवर्क के निर्माण की अनुमति देता है जबकि परिणामी सिस्टम मूल मॉडल की अधिकांश गुणवत्ता को बनाए रखते हैं। इस तथ्य के बावजूद कि कई लेखक ज्ञान आसवन के लाभों पर रिपोर्ट करते हैं, कुछ ने वास्तविक कारणों पर चर्चा की है कि यह क्यों काम करता है, खासकर तंत्रिका एमटी के संदर्भ में। इस पेपर में, हम यह समझने के उद्देश्य से कई प्रयोग करते हैं कि आसवन एक अंग्रेजी-जर्मन अनुवाद कार्य पर सटीकता को क्यों और कैसे प्रभावित करता है। हम दिखाते हैं कि अनुवाद की जटिलता वास्तव में कम हो जाती है जब संदर्भ द्वि-पाठ की तुलना में एक आसुत / संश्लेषित द्वि-पाठ का निर्माण होता है। हम आगे संश्लेषित अनुवादों से शोर डेटा को हटा देते हैं और मूल संदर्भ के साथ फ़िल्टर किए गए संश्लेषित डेटा को मर्ज करते हैं, इस प्रकार सटीकता के संदर्भ में अतिरिक्त लाभ प्राप्त करते हैं।', 'ru': 'Дистилляция знаний недавно была успешно применена к нейронному машинному переводу. Это позволяет строить усаженные сети, в то время как полученные системы сохраняют большинство качества оригинальной модели. Несмотря на то, что многие авторы сообщают о преимуществах дистилляции знаний, лишь немногие обсуждают фактические причины, почему она работает, особенно в контексте нейронного МП. В этой статье мы проводим несколько экспериментов, направленных на понимание того, почему и как дистилляция влияет на точность при переводе с английского на немецкий. Мы показываем, что сложность перевода на самом деле уменьшается при создании дистиллированного/синтезированного битекста по сравнению с эталонным битекстом. Кроме того, мы удаляем шумные данные из синтезированных переводов и объединяем отфильтрованные синтезированные данные вместе с исходным эталоном, тем самым достигая дополнительных преимуществ с точки зрения точности.', 'ga': 'Cuireadh driogadh eolais i bhfeidhm go rathúil le déanaí ar aistriúchán meaisín néarach. Ligeann sé do líonraí laghdaithe a thógáil agus coimeádann na córais a eascraíonn as seo an chuid is mó de cháilíocht na samhla bunaidh. In ainneoin go dtugann go leor údair tuairisc ar na buntáistí a bhaineann le driogadh eolais, is beag duine a phléigh na cúiseanna iarbhír a n-oibríonn sé, go háirithe i gcomhthéacs MT neural. Sa pháipéar seo, déanaimid roinnt turgnamh atá dírithe ar thuiscint cén fáth agus conas a théann driogadh i bhfeidhm ar chruinneas tasc aistriúcháin Béarla-Gearmáinis. Léirímid go laghdaítear castacht an aistriúcháin i ndáiríre agus déthéacs driogtha/sintéisithe á thógáil i gcomparáid leis an déthéacs tagartha. Bainimid sonraí callánacha ó na haistriúcháin sintéisithe a thuilleadh agus déanaimid sonraí scagtha sintéise a chumasc leis an mbuntagairt, rud a bhainimid amach gnóthachain bhreise i dtéarmaí cruinnis.', 'el': 'Η απόσταξη γνώσης έχει εφαρμοστεί πρόσφατα με επιτυχία στην νευρολογική μηχανική μετάφραση. Επιτρέπει την κατασκευή συρρικνωμένων δικτύων ενώ τα προκύπτουσα συστήματα διατηρούν το μεγαλύτερο μέρος της ποιότητας του αρχικού μοντέλου. Παρά το γεγονός ότι πολλοί συγγραφείς αναφέρουν τα οφέλη της απόσταξης γνώσης, λίγοι έχουν συζητήσει τους πραγματικούς λόγους για τους οποίους λειτουργεί, ειδικά στο πλαίσιο της νευρωνικής Σε αυτή την εργασία, διεξάγουμε διάφορα πειράματα που στοχεύουν στην κατανόηση του γιατί και πώς η απόσταξη επηρεάζει την ακρίβεια σε μια αγγλο-γερμανική μεταφραστική εργασία. Δείχνουμε ότι η πολυπλοκότητα της μετάφρασης μειώνεται στην πραγματικότητα όταν δημιουργείται ένα αποσταγμένο/συνθετικό δίκείμενο σε σύγκριση με το δίκείμενο αναφοράς. Αφαιρούμε περαιτέρω τα θορυβώδη δεδομένα από τις συνθετικές μεταφράσεις και συγχωνεύουμε τα φιλτραρισμένα συνθετικά δεδομένα μαζί με την αρχική αναφορά, επιτυγχάνοντας έτσι πρόσθετα οφέλη όσον αφορά την ακρίβεια.', 'it': 'La distillazione della conoscenza è stata recentemente applicata con successo alla traduzione automatica neurale. Permette di costruire reti ristrette mentre i sistemi risultanti mantengono la maggior parte della qualità del modello originale. Nonostante molti autori riferiscano sui benefici della distillazione della conoscenza, pochi hanno discusso le reali ragioni per cui funziona, soprattutto nel contesto della MT neurale. In questo articolo, conduciamo diversi esperimenti volti a capire perché e come la distillazione influisce sulla precisione su un compito di traduzione inglese-tedesco. Dimostriamo che la complessità della traduzione è effettivamente ridotta quando si costruisce un bi-testo distillato/sintetizzato rispetto al bi-testo di riferimento. Rimuoviamo ulteriormente i dati rumorosi dalle traduzioni sintetizzate e uniamo i dati sintetizzati filtrati insieme ai riferimenti originali, ottenendo così ulteriori vantaggi in termini di accuratezza.', 'hu': 'A tudás desztillációt a közelmúltban sikeresen alkalmazták az idegi gépi fordításra. Lehetővé teszi a zsugorodott hálózatok építését, miközben az így kapott rendszerek megtartják az eredeti modell minőségének nagy részét. Annak ellenére, hogy sok szerző beszámol a tudás desztilláció előnyeiről, kevesen vitatták meg, hogy miért működik, különösen a neurális MT kontextusában. Ebben a tanulmányban több kísérletet végeztünk annak megértésére, hogy miért és hogyan befolyásolja a desztilláció pontosságát egy angol-német fordítási feladatra. Megmutatjuk, hogy a fordítási komplexitás valójában csökken a desztillált/szintetizált kétszöveg készítésénél a referencia kétszöveghez képest. Továbbá eltávolítjuk a zajos adatokat a szintetizált fordításokból, és egyesítjük a szűrt szintetizált adatokat az eredeti referenciával, így további pontossági előnyöket érünk el.', 'ka': 'Name ეს შესაძლებელია დახმარებას ქსელების შექმნა, როდესაც შემდეგ სისტემები უფრო მეტი ორიგინალური მოდელის კავილეტის შესაძლებელია. თუმცა ბევრი ავტორები განსხვავებულების გამოსახულების შესახებ, რამდენიმე განსხვავებული მიზეზები განსხვავებულია, რატომ ის მუშაობს, განსაკუთრებით ნეიროლა MT-ის კონტექსტში. ამ დოგომაში, ჩვენ ვიყავთ რამდენიმე ექსპერი ჩვენ ჩვენ აჩვენებთ, რომ გაგრძელების კომპლექსიტეტი ნამდვილად შემცირებულია, როდესაც განსხვავებული/სინტექსირებულია ორ-ტექსტის შემცირებულია,  ჩვენ შემდეგ სინტესზიზიზიზიზებული თავსუფლების მონაცემების გადასტანა და ფილტრუქტირებული სინტესზიზიზებული მონაცემების შემდეგ ორიგინალური რეფერენციის შემდეგ', 'mk': 'Дестилацијата на знаење неодамна успешно се примени на преводот на невровните машини. Тоа овозможува изградба на намалени мрежи додека резултатите на системите го задржуваат поголемиот дел од квалитетот на оригиналниот модел. Despite the fact that many authors report on the benefits of knowledge distillation, few have discussed the actual reasons why it works, especially in the context of neural MT. In this paper, we conduct several experiments aimed at understanding why and how distillation impacts accuracy on an English-German translation task.  Ние покажуваме дека комплексноста на преводот е всушност намалена кога се гради дистилиран/синтезиран битекст во споредба со референтниот битекст. Понатаму ги отстрануваме звучните податоци од синтезираните преводи и ги спојуваме филтрираните синтезирани податоци заедно со оригиналната референција, со што ќе постигнеме дополнителни добивки во поглед на прецизноста.', 'kk': 'Мәліметтердің дистриляциясы невралдық компьютердің аудармасына сәтті қолданылды. Бұл желілерді құруға мүмкіндік береді, жүйелердің негізгі үлгісінің көпшілігін сақтау үшін. Бұл қағазда білім дистилациясының мүмкіндіктері туралы көптеген авторлар туралы хабарлап беріп тұрғанда, оның неге жұмыс істейтін себептерін, осы қағазда невралдық MT контекстінде, көптеген тәжірибелерді түсінімізге жұмыс істеп тұрып Біз аудармалардың тәжірибесінің бір мәтіннің сілтемесіне салыстырғанда, бөлек/синтезацияланған екі мәтіннің құрылғанда, шынымен қысқартылады. Біз синтезацияланған аудармалардан дыбыс деректерін өшіріп, сүзгілеген синтезацияланған деректерді бастапқы сілтемелерден бірге біріктіреміз, сондықтан оның дұрыс тәртібімен қосымша жетілдір', 'mt': 'Dan l-aħħar ġiet applikata b’suċċess id-distillazzjoni tal-għarfien għat-traduzzjoni tal-magni newrali. Dan jippermetti li jinbnew netwerks imnaqqsa filwaqt li s-sistemi li jirriżultaw iżommu l-biċċa l-kbira tal-kwalità tal-mudell oriġinali. Minkejja l-fatt li ħafna awturi jirrappurtaw dwar il-benefiċċji tad-distillazzjoni tal-għarfien, ftit iddiskutew ir-raġunijiet attwali għaliex taħdem, speċjalment fil-kuntest tal-MT newrali. F’dan id-dokument, nieħdu diversi esperimenti mmirati biex nifhmu għaliex u kif id-distillazzjoni taffettwa l-preċiżjoni fuq kompitu ta’ traduzzjoni Ingliż-Ġermaniż. Aħna nuru li l-kumplessità tat-traduzzjoni titnaqqas fil-fatt fil-bini ta’ żewġ testi distillati/sintetizzati meta mqabbla mal-żewġ testi ta’ referenza. We further remove noisy data from synthesised translations and merge filtered synthesised data together with original reference, thus achieving additional gains in terms of accuracy.', 'lt': 'Neseniai žinių distiliavimas buvo sėkmingai taikomas nervinių mašinų vertimui. Ji leidžia kurti sutrumpintus tinklus, o iš jų gautos sistemos išlaiko didžiąją originalaus modelio kokybę. Nepaisant to, kad daugelis autorių praneša apie žinių distiliacijos naudą, nedaugelis aptarė faktines priežastis, kodėl ji veikia, ypač neurologinio MT kontekste. Šiame dokumente atliekame keletą eksperimentų, kuriais siekiama suprasti, kodėl ir kaip distiliacija daro poveikį tikslumui anglų ir vokiečių vertimo užduotyje. Mes rodome, kad vertimo sudėtingumas iš tikrųjų mažėja, kai kuriamas distiliuotas ir (arba) sintezuotas dvitekstas, palyginti su nuoroda dvitekstu. Toliau pašaliname triukšmingus duomenis iš sintezuotų vertimų ir sujungiame filtruotus sintezuotus duomenis kartu su pradine nuoroda, taip užtikrinant papildomą tikslumo didinimą.', 'ms': 'Pengesahan pengetahuan baru-baru ini telah berjaya dilaksanakan pada terjemahan mesin saraf. Ia membolehkan membina rangkaian yang berkurang sementara sistem hasilnya menyimpan sebahagian besar kualiti model asal. Despite the fact that many authors report on the benefits of knowledge distillation, few have discussed the actual reasons why it works, especially in the context of neural MT. In this paper, we conduct several experiments aimed at understanding why and how distillation impacts accuracy on an English-German translation task.  Kami menunjukkan bahawa kompleksiti terjemahan sebenarnya dikurangkan apabila membina bi-teks yang dipotong/disintesis apabila dibandingkan dengan bi-teks rujukan. Kita akan menghapuskan data bunyi dari terjemahan sintesis dan gabungkan data sintesis penapis bersama rujukan asal, dengan cara itu mencapai keuntungan tambahan dalam terma ketepatan.', 'no': 'Kjentsdistillasjon er nyleg brukt i nøyralmaskinsomsetjinga. Dette kan bygge minske nettverk mens resultatet systemet held meste av kvaliteten til den opprinnelige modellen. I tross av det faktum at mange utviklarane rapporterer om fordelene av kunnskapselerasjon, har få diskutert dei faktiske grunnene til at det fungerer, spesielt i konteksten av neural MT. I denne papiret gjer vi fleire eksperimenter med mål til å forstå hvorfor og korleis destilasjon påvirkar nøyaktighet på eit engelsk-tysk oversettelsoppgåve. Vi viser at omsetjingskompleksitet er faktisk redusert når du bygger ein distilert/syntisert bi-tekst når du samanliknar med referansen bi-tekst. Vi fjernar meir støydata frå syntiserte omsetjingar og fleire filtrerte syntiserte data saman med originale referanse, slik at det gjer tilleggsvising med nøyaktighet.', 'ml': 'പരിജ്ഞാനം വേര്\u200dതിരിക്കുന്നത് അടുത്ത് ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷക്ക് വിജയിച്ചിരിക്കുന്നു. അത് നിര്\u200dമ്മിക്കാന്\u200d അനുവദിക്കുന്നു. അനുഭവിക്കുന്ന സിസ്റ്റത്തിന്റെ ആദ്യമായ മോഡലിന്റെ ഗുണപൂര്\u200dണ്ണമായ അറിവ് വിവേചനത്തിന്റെ ഉപകരണങ്ങളെക്കുറിച്ച് അധികപേരും റിപ്പോര്\u200dട്ട് ചെയ്തിട്ടുണ്ടെങ്കിലും കുറച്ചു കാരണങ്ങള്\u200d സംസാരിച്ചിട്ടുണ്ട്, അതെന്തിനാണ് പ്രധാനപ്പെടുന് ബി-ടെക്സ്റ്റിനോട് താല്\u200dപ്പിക്കുമ്പോള്\u200d പരിഭാഷപ്പെടുത്തുന്ന പരിഭാഷണത്തിന്റെ കുഴപ്പത്തില്\u200d കുറവ് വരുത്തുന് നമ്മള്\u200d കൂടുതല്\u200d ശബ്ദ വിവരങ്ങള്\u200d സങ്കല്\u200dപിക്കപ്പെട്ട വിവരങ്ങളില്\u200d നിന്ന് നീക്കം ചെയ്യുകയും, ഫില്\u200dറ്റര്\u200d ചെയ്ത സിനിസ്റ്ററിസ്റ്', 'pl': 'Destylacja wiedzy została ostatnio z powodzeniem zastosowana do neuronowego tłumaczenia maszynowego. Pozwala na budowę skurczonych sieci, a powstałe systemy zachowują większość jakości oryginalnego modelu. Pomimo faktu, że wielu autorów raportuje o korzyściach płynących z destylacji wiedzy, niewielu omówiło faktyczne powody, dla których działa, zwłaszcza w kontekście neuronowej MT. W niniejszym artykule przeprowadzamy kilka eksperymentów mających na celu zrozumienie, dlaczego i jak destylacja wpływa na dokładność zadania tłumaczeniowego angielsko-niemieckiego. Pokazujemy, że złożoność tłumaczenia jest rzeczywiście zmniejszona podczas budowy destylowanego/syntetyzowanego dwutekstu w porównaniu do odniesienia do dwutekstu. Ponadto usuwamy szumowne dane z syntetyzowanych tłumaczeń i łączymy filtrowane syntetyzowane dane wraz z oryginalnym odniesieniem, osiągając w ten sposób dodatkowe zyski pod względem dokładności.', 'ro': 'Distilarea cunoștințelor a fost recent aplicată cu succes traducerii automate neurale. Acesta permite construirea de rețele restrânse, în timp ce sistemele rezultate păstrează cea mai mare parte a calității modelului original. În ciuda faptului că mulți autori raportează despre beneficiile distilarii cunoștințelor, puțini au discutat motivele reale pentru care funcționează, în special în contextul MT neural. În această lucrare, efectuăm mai multe experimente menite să înțelegem de ce și cum distilarea influențează acuratețea asupra unei sarcini de traducere engleză-germană. Aratăm că complexitatea traducerii este de fapt redusă atunci când construim un bi-text distilat/sintetizat în comparație cu bi-text de referință. În plus, eliminăm datele zgomotoase din traducerile sintetizate și combinăm datele sintetizate filtrate împreună cu referința originală, obținând astfel câștiguri suplimentare în ceea ce privește acuratețea.', 'mn': 'Сүүлийн үед мэдлэгтэй саяхан мэдлэгтэй хуваалцах нь мэдрэлийн машины хөгжүүлэлт амжилттай хэрэглэгдсэн. Үүний үр дүнтэй системүүд эхний загварын сайн чанарын ихэнхдээ багасгах сүлжээг бүтээх боломж олгодог. Ихэнх зохиолчдын мэдлэг сайжруулах хэрэгтэй талаар мэдээллийн тухай ярьж байгаа ч, хэд хэдэн хүн үүнийг яагаад ажилладаг вэ гэхээр, ялангуяа сэтгэл хөдлөлийн тухай ярьж байна. Энэ цаасан дээр бид олон туршилт хийж байгаа бөгөөд бид Англи-Германы орчуулах ажил дээр я Бид орчуулалтын цогцуудыг багасгаж байна гэдгийг харуулж байна. Бид илүү шууд өгөгдлийг нэгтгэгдсэн орнуудаас хамтдаа цэвэрлэгдсэн шинжлэх ухааны өгөгдлийг үндсэн холбоотой холбоотой. Иймээс зөв байдалд нэмэлт ашиг гаргаж чадна.', 'so': "Soo gaarista aqoonta waxaa ugu dhowaad liibaansan loo codsaday turjumaadda machine neurada. Waxay u ogolaan karaan dhisidda shabakada burburka marka nidaamka lagu soo jeedo ay ku haystaan tijaabada asalka ah. Inta kastoo ay dad badan wargeliyaan faa'iidada aqoonta, qaar yar ayaa ka sheekaynaya sababaha runta ah ee ay ka shaqeeyaan, khusuusan ku jirto xaaladaha neurada MT. Warqadan waxaan sameeyaa jirrabo badan oo ku qoran waxyaabaha ay garanayaan sababta iyo si saxda ah ugu saameyn karto shaqada ingiriisiga-Jarmalka. Waxaynu muujinnaa in turjumista ay ku adag tahay marka la dhiso qoraal kala duduwan/la-soocay bi-text marka la barbaranayo qoraalka bi-text. Sidoo kale ayaannu macluumaadka codka ka ka qaadnaa turjumaadda la-ururiyey, waxaana ku soo ururinnaa macluumaad la-soocay oo la isku dayo afka hore, sidaa darteed waxaynu gaadhnaa faa'iido dheeraad ah si saxda ah.", 'si': 'Name ඒකෙන් ප්\u200dරතිචාර පද්ධතියේ ප්\u200dරතිචාරයේ විශේෂතාවක් තියාගන්න පුළුවන් විතරයි. ගොඩක් ලේඛකයෝ දන්නවගේ ප්\u200dරයෝජනය ගැන ප්\u200dරයෝජනය කරනවා නමුත්, කීපයක් කතා කරලා තියෙනවා ඇයි ඒක වැඩ කරන්නේ, විශේෂයෙන්ම න්\u200dයූරාල් MT කාරණයේ සම්බන්ධයෙන්, අපි මේ  අපි පෙන්වන්නේ වාර්ථාව සංවිධානය ඇත්තටම විශේෂ/සංවිධානයක් නිර්මාණය කරලා තියෙන්නේ ප්\u200dරතිකාරය අපි සම්බන්ධ වාර්තාවයෙන් සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් සම්බන්ධ', 'sr': 'Destilacija znanja nedavno je uspešno primjenjena na prevod neuralne mašine. To omogućava izgradnju smanjenih mreža dok rezultatni sistemi drže većinu kvalitete originalnog modela. Uprkos činjenici da mnogi autori izvještaju o koristima destilacije znanja, nekoliko su razgovarali o stvarnim razlogom zašto radi, posebno u kontekstu neuralnog MT-a. U ovom papiru, provodimo nekoliko eksperimenata usmjerenih na razumevanje zašto i kako destilacija utiče na tačnost na posao prevođenja engleskog i njemačkog jezika. Pokazujemo da je kompleksnost prevođenja zapravo smanjena kada izgradimo destilirani/sintezirani bi-tekst u usporedbi sa referentnim bi-tekstom. Dalje uklonimo bučne podatke iz sinteziranih prevoda i spojimo filtrerane sintezirane podatke zajedno s originalnom referencijom, tako da postižemo dodatne dobitke u smislu tačnosti.', 'sv': 'Kunskapsdestillation har nyligen framgångsrikt tillämpats på neural maskinöversättning. Det gör det möjligt att bygga krympta nätverk medan de resulterande systemen behåller större delen av kvaliteten på den ursprungliga modellen. Trots att många författare rapporterar om fördelarna med kunskapsdestillation har få diskuterat de faktiska orsakerna till varför den fungerar, särskilt i samband med neural MT. I denna uppsats genomför vi flera experiment som syftar till att förstå varför och hur destillation påverkar noggrannheten på en engelsk-tysk översättningsuppgift. Vi visar att översättningskomplexiteten faktiskt minskar när man bygger en destillerad/syntetiserad bi-text jämfört med referensbi-text. Vi tar bort bullriga data från syntetiserade översättningar och sammanfogar filtrerade syntetiserade data med originalreferens, vilket ger ytterligare förbättringar i fråga om noggrannhet.', 'ur': 'علم distillation has been successfully applied to neural machine translation. یہ کم نیٹ ورک بنانے کے لئے اجازت دیتا ہے جبکہ نتیجہ سیستموں کی اکثریت اصلی موڈل کی کیفیت رکھتی ہے۔ اگرچہ بہت سے لکھنے والے علم کے فائدے کے بارے میں گزارتے ہیں، کم لوگ اس کے کام کیوں کر رہے ہیں، مخصوصاً نئورل ٹی.ٹی.ٹی کے متعلق میں. اس کاغذ میں ہم بہت سی تجربے کر رہے ہیں جو سمجھنے کے مطابق کیوں اور کس طرح تفریق کا دقیق اثر کرتا ہے انگلیسی-جرمن کی ترجمہ کا ہم دکھاتے ہیں کہ ترجمہ پیچیدگی حقیقت میں کم ہوتی ہے جب ایک متفرق/متفرق دو متفرق بناتے ہیں جب متفرق دو متفرق کے مقابلہ میں۔ ہم اس سے زیادہ صوتی ڈیٹا کو سینٹیزیز ترجمہ سے دور کر دیتے ہیں اور فیلٹریز سینٹیزیز ڈیٹا کو اصلی مرتبہ کے ساتھ ملتے ہیں، اسی طرح دقیق کے مطابق اضافہ فائدہ پہنچاتے ہیں۔', 'ta': 'அறிவு பிரிப்பு சமீபத்தில் புதிய இயந்திரம் மொழிபெயர்ப்பிற்கு வெற்றிகரமாக பயன்படுத்தப்பட்டது. இது முடிவு கணினிகள் முதல் மாதிரியின் தரம் பெரும்பாலான பிணையத்தை உருவாக்க அனுமதிக்கிறது. நிறைய ஆசிரியர்கள் அறிவு பிரிப்பு நன்மைகளை பற்றி அறிகிறார்கள் என்றாலும் குறைந்தவர்கள் ஏன் அது வேலை செய்கிறது என்பது உண்மையான காரணங்களை விவாதம் செய்துள்ளார்கள். குறிப்பாக இந மொழிபெயர்ப்பு சிக்கல் உண்மையில் ஒரு வித்தியாசமாக/ஒருங்கிணைக்கப்பட்ட பி உரையை உருவாக்கும் போது மொழிபெயர்ப்பு சி நாம் மேலும் ஒருங்கிணைக்கப்பட்ட மொழிபெயர்ப்புகளிலிருந்து ஒலி தகவலை நீக்கி வடிகட்டப்பட்ட தகவல்களை மூல குறிப்புகளுடன் ஒன்றாக்கு', 'uz': "Yaqinda maʼlumotni ajratish muvaffaqiyatsiz tugadi. It allows for building shrunk networks while the resulting systems retain most of the quality of the original model.  Agar ko'pchilik mualliflar ilmiy ta'rif tafaqiyatlarining foydalanishi haqida xabar beradi, qanday qilib, u nima uchun ishlaydi, hususan neyron MT muvaffaqiyatlarida ko'pchilik imtiyozni bajaramiz, nima uchun va ajratish imkoniyatini angliz-Olmon tarjima vazifani qanday tasavvur qiladi. Biz bir tarjima murakkablarini ko'rsatganimiz, bi-matnni bir-birga tenglangan va bir-bir matnni birga kamaytirishda o'zgarish murakkablarini kamaytirish mumkin. @ info: whatsthis", 'vi': 'Việc chưng cất tri thức gần đây đã được áp dụng với dịch thuật máy thần kinh. Nó cho phép xây dựng các mạng lưới thu nhỏ, trong khi hệ thống kết quả giữ hầu hết chất lượng của mô hình gốc. Mặc dù rất nhiều tác giả có trình báo về lợi ích của việc chưng cất tri thức, một số ít đã thảo luận về lý do thực tế nó hoạt động, đặc biệt là trong trường hợp sóng thần kinh. Trong bài báo này, chúng tôi tiến hành nhiều thí nghiệm nhằm hiểu tại sao và cách nào việc chưng cất tác động chính xác lên một nhiệm vụ dịch dịch chuyển Anh-Đức. Chúng tôi cho thấy mức độ phức tạp của dịch sẽ thực sự giảm khi xây dựng hai đoạn chưng cất và tổng hợp khi so với hai chữ tham chiếu. Chúng tôi còn gỡ bỏ những dữ liệu ồn ào từ dịch tổng hợp và kết hợp những dữ liệu đã được lọc với những chỉ dẫn gốc, để đạt thêm lợi nhuận về độ chính xác.', 'bg': 'Наскоро дестилацията на знанието се прилага успешно при невронния машинен превод. Тя позволява изграждането на свити мрежи, докато получените системи запазват по-голямата част от качеството на оригиналния модел. Въпреки факта, че много автори докладват за ползите от дестилацията на знанието, малцина са обсъдили действителните причини, поради които тя работи, особено в контекста на невралната В тази статия провеждаме няколко експеримента, целящи да разберем защо и как дестилацията влияе върху точността на англо-немски превод задача. Показваме, че сложността на превода всъщност е намалена при изграждането на дестилиран/синтезиран двутекст в сравнение с препратката двутекст. Освен това премахваме шумните данни от синтезираните преводи и сливаме филтрираните синтезирани данни заедно с оригиналната справка, като по този начин постигаме допълнителни печалби по отношение на точността.', 'da': 'Vidensdestillation er for nylig blevet anvendt med succes på neural maskinoversættelse. Det giver mulighed for at opbygge krympede netværk, mens de resulterende systemer bevarer det meste af kvaliteten af den oprindelige model. På trods af at mange forfattere rapporterer om fordelene ved vidensdestillation, har få diskuteret de faktiske årsager til, at den virker, især i forbindelse med neural MT. I denne artikel gennemfører vi flere eksperimenter med henblik på at forstå hvorfor og hvordan destillation påvirker nøjagtigheden på en engelsk-tysk oversættelsesopgave. Vi viser, at oversættelseskompleksiteten faktisk reduceres ved opbygning af en destilleret/syntetiseret bi-tekst sammenlignet med referencebi-teksten. Vi fjerner yderligere støjende data fra syntetiserede oversættelser og fletter filtrerede syntetiserede data sammen med original reference, hvilket opnår yderligere gevinster i form af nøjagtighed.', 'nl': 'Kennisdestillatie is onlangs met succes toegepast op neurale machinevertaling. Het maakt het mogelijk om gekrompen netwerken te bouwen terwijl de resulterende systemen het grootste deel van de kwaliteit van het oorspronkelijke model behouden. Ondanks het feit dat veel auteurs rapporteren over de voordelen van kennisdestillatie, hebben weinig de werkelijke redenen besproken waarom het werkt, vooral in de context van neurale MT. In dit artikel voeren we verschillende experimenten uit om te begrijpen waarom en hoe distillatie de nauwkeurigheid van een Engels-Duitse vertaaltaak beïnvloedt. We laten zien dat de vertaalcomplexiteit daadwerkelijk verminderd wordt bij het bouwen van een gedistilleerde/gesynthetiseerde bi-tekst in vergelijking met de referentie-bi-tekst. Verder verwijderen we ruisige gegevens uit gesynthetiseerde vertalingen en voegen we gefilterde gesynthetiseerde gegevens samen met originele referenties, waardoor we extra voordelen in termen van nauwkeurigheid behalen.', 'de': 'Wissensdestillation wurde kürzlich erfolgreich auf neuronale maschinelle Übersetzung angewendet. Es ermöglicht den Aufbau geschrumpfter Netzwerke, während die resultierenden Systeme den größten Teil der Qualität des ursprünglichen Modells beibehalten. Trotz der Tatsache, dass viele Autoren über die Vorteile der Wissensdestillation berichten, haben nur wenige die tatsächlichen Gründe diskutiert, warum sie funktioniert, insbesondere im Kontext neuronaler MT. In diesem Beitrag führen wir mehrere Experimente durch, um zu verstehen, warum und wie Destillation die Genauigkeit einer englisch-deutschen Übersetzungsaufgabe beeinflusst. Wir zeigen, dass die Übersetzungskomplexität beim Aufbau eines destillierten/synthetisierten Bitextes im Vergleich zum Referenzbi-Text tatsächlich reduziert wird. Darüber hinaus entfernen wir rauschende Daten aus synthetisierten Übersetzungen und führen gefilterte synthetisierte Daten mit Originalreferenzen zusammen, um zusätzliche Genauigkeitsgewinne zu erzielen.', 'hr': 'Destilacija znanja nedavno je uspješno primjenjena na prevod neuralnih strojeva. To omogućava izgradnju smanjenih mreža dok rezultatni sustavi drže većinu kvalitete originalnog modela. Unatoč činjenici da mnogi autori izvještaju o koristima destilacije znanja, nekoliko su razgovarali o stvarnim razlogom zašto radi, posebno u kontekstu neuralnog MT-a. U ovom papiru, provodimo nekoliko eksperimenata s ciljem razumijevanja zašto i kako destilacija utječe na preciznost prema zadatku prevođenja engleskog i njemačkog jezika. Pokazujemo da se kompleksnost prevođenja zapravo smanjuje kada izgradimo destilirani/sintezirani bi-tekst u usporedbi s referentnim bi-tekstom. Dalje uklonimo bučne podatke iz sinteziranih prevoda i ujedinimo filtrirane sintezirane podatke zajedno s originalnom referencijom, tako da postignemo dodatne dobitke u smislu tačnosti.', 'id': 'Distillasi pengetahuan baru-baru ini telah berhasil dipakai untuk terjemahan mesin saraf. Ini memungkinkan untuk membangun jaringan kecil sementara sistem hasilnya memelihara sebagian besar kualitas model asli. Meskipun banyak penulis melaporkan keuntungan dari destilasi pengetahuan, sedikit telah mendiskusikan alasan sebenarnya mengapa ia bekerja, terutama dalam konteks MT saraf. Dalam kertas ini, kami melakukan beberapa eksperimen yang bertujuan untuk memahami mengapa dan bagaimana destilasi mempengaruhi akurasi pada tugas terjemahan Inggris-Jerman. We show that translation complexity is actually reduced when building a distilled/synthesised bi-text when compared to the reference bi-text.  Kami lebih lanjut menghapus data bunyi dari terjemahan sintesis dan gabungkan data sintesis filter bersama dengan referensi asli, sehingga mencapai keuntungan tambahan dalam terma akurasi.', 'ko': '최근 지식 추출은 신경 기계 번역에 성공적으로 응용되었다.그것은 축소된 네트워크를 구축할 수 있고, 생성된 시스템은 원시 모델의 대부분 품질을 보존한다.비록 많은 작가들이 지식 추출의 장점을 보고했지만, 그 작업의 실제 원인, 특히 신경기계 번역의 배경에서 토론하는 사람은 드물다. 본고에서 우리는 추출이 왜, 그리고 어떻게 영덕 번역 임무의 정확성에 영향을 미치는지 이해하기 위해 몇 가지 실험을 진행했다.우리는 비 텍스트를 참고하는 것보다 비 텍스트를 추출/합성할 때 번역의 복잡도가 실제로 낮아진 것을 발견했다.우리는 더욱 나아가 합성 번역에서 소음 데이터를 제거하고 여과된 합성 데이터를 원시 참고와 합쳐서 정확성에 있어서 추가 수익을 얻는다.', 'sw': 'Kutofautiana na maarifa hivi karibuni imetumiwa mafanikio katika tafsiri ya mashine ya kisasa. Inaruhusu kujenga mitandao ya kupungua wakati mfumo wa matokeo unabaki ubora wa mifano ya asili. Pamoja na ukweli kwamba waandishi wengi wanaripoti kuhusu faida za utofauti wa maarifa, wachache wamejadili sababu za kweli kwa nini inafanya kazi, hususani katika muktadha wa MT. Katika karatasi hii, tunafanya majaribio kadhaa yanayolenga kuelewa kwa nini na jinsi tofauti inavyoathiri ukweli juu ya kazi ya utafsiri wa Kiingereza na Kijerumani. Tunaonyesha kwamba utata wa tafsiri unapunguzwa kwa kweli pale unaposengeneza ujumbe wa kibiashara unaofanana na maandishi ya bi-text. We further remove noisy data from synthesised translations and merge filtered synthesised data together with original reference, thus achieving additional gains in terms of accuracy.', 'af': "Die kennis-destilasie is onlangs suksesvol aangepas na neurale masjien-vertaling. Dit laat toe vir die bou van gemakke netwerke terwyl die resulteerde stelsels meeste van die kwaliteit van die oorspronklike model hou. Onthou die feit dat baie outeure rapporteer oor die voordele van kennis destilasie, het sommige gespreek oor die werklike redes waarom dit werk, veral in die konteks van neurale MT. In hierdie papier, het ons verskeie eksperimente gedoen om te verstaan waarom en hoe destilasie die presisiteit op 'n Engelse-Duitse vertaling taak invloek. Ons wys dat vertalingskompleksiteit eintlik verduur word wanneer 'n destiliseerde/sintetiseerde bi-teks bou wanneer vergelyk word met die verwysing bi-teks. Ons verder verwyder geluid data van sintetiseerde vertalings en saam met oorspronklike verwysing van filtereerde sintetiseerde data saam met oorspronklike verwysing, sodat addisionele verkrywings ingevolge waarsheid bereik word.", 'fa': 'جدایی دانش اخیرا به موفقیت بر ترجمه ماشین عصبی کاربرد شده است. در حالی که سیستم\u200cهای نتیجه بیشتر کیفیت مدل اصلی را حفظ می\u200cکند، اجازه می\u200cدهد شبکه\u200cهای کاهش را ساخت. با وجود این حقیقت که بسیاری از نویسندگان در مورد سود تفاوت دانش گزارش می\u200cدهند، کمی از دلایل واقعی که این کار می\u200cکند، مخصوصاً در محیط MT عصبی. در این کاغذ، ما چند آزمایش را انجام می\u200cدهیم که هدف می\u200cگیریم بفهمیم چرا و چگونه تفاوت دقیق روی یک کار تغییر انگلیسی ما نشان می دهیم که پیچیدگی ترجمه در واقع در زمان ساختن یک متن دو متن متفرق/متفرق شده در مقایسه با متن دو متن متفرق کاهش می شود. ما اطلاعات صوتی را از ترجمه\u200cهای متصل می\u200cکنیم و اطلاعات متصل شده فیلتر را با ارتباط اصلی جمع می\u200cکنیم، به نتیجه رسیدن پیروزی اضافه به صورت دقیق.', 'sq': 'Distillimi i njohurive është aplikuar me sukses në përkthimin e makinave nervore. Ajo lejon për ndërtimin e rrjeteve të shkurtra ndërsa sistemet që rezultojnë mbajnë shumicën e cilësisë së modelit origjinal. Pavarësisht nga fakti se shumë autorë raportojnë mbi përfitimet e distillacionit të njohurive, pak kanë diskutuar arsyet faktike pse funksionon, veçan ërisht në kontekstin e MT nervore. Në këtë letër, ne kryejmë disa eksperimente që synojnë të kuptojnë pse dhe si distillacioni ndikon në saktësinë e një detyre përkthimi anglo-gjerman. Ne tregojmë se kompleksiteti i përkthimit është në fakt reduktuar kur ndërtohet një dy-tekst distilluar/sintetizuar kur krahasohet me referencën dy-tekst. Ne heqim më tej të dhënat e zhurmshme nga përkthimet e sintetizuara dhe bashkojmë të dhënat e sintetizuara të filtruara së bashku me referencën origjinale, duke arritur kështu fitime shtesë në lidhje me saktësinë.', 'tr': 'Bilgi öňden näyral maşynyň terjimesine üýtgedildi. Näme üçin sistemalar başlangyç nusgasynda azalýan syýallar inşa etmäge mümkin edýär. Köp awtorlaryň bilim taýýarlamasynyň faydasyny barada bildirip ýörän bilýän sebäplerini, iňlisçe Näme üçin işleýän sebäplerini, iňlisçe Näme üçin Näme üçin tapawutlandyrylygyny barada gürrüň edýäris. Bu kagyzda biz birnäçe deneyler çykyp gidýäris we iňlis-nemesçe Biz terjime edilen karmaşıklygyny çykarýan we çykarýan bir metin guranda, çykarýan/sintezleşen bir tekst diýip süýtgedendigini görkez. Biz sesli Maglumaty sintezleýän terjimelerden çykar we filtreli sintezleýän maglumaty original Referans bilen birleşdirdik, şonuň ýagdaýynyň dogry ýagdaýyndan artyk gazanýar.', 'am': 'የእውቀት ትርጉም በቅርብ ጊዜ በጠቅላላ ማሻሻሻን ትርጉም የተጠቀመ ሆኖአል፡፡ ይፈቅዳል፡፡ ምንም እንኳን ብዙ ጸሐፊዎች ስለ እውቀት ግንኙነት የሚለውጥ ጥቅሞችን እንደዘረጉበት፣ ጥቂቶች የሚያንቀሳቅሱት ስለምን ይሠራል፣ ይልቁንም በዚህ ካላት የናውሮል MT ክፍል ውስጥ ስለምን እና እንዴት ትርጉም በአንግሊዝኛ-የጀርመን ትርጓሜ ስራ ላይ እንዴት እንደሚያፈስስ ብዙዎችን ፈተናዎች እናደርጋለን፡፡ በተለየ ቢ-ጽሑፍ በተያሳየው ጊዜ ትርጉም አካባቢ እናሳያቸዋለን፡፡ የድምፅ ድምፅ አዳራጮችን ከመሰናከል እናስወግዳለን እና የተጣራ መረጃዎችን በአንድነት በመጀመሪያው reference እናስቀራለን፡፡', 'hy': 'Վերջերս գիտելիքի տարածումը հաջողությամբ կիրառվել է նյարդային մեքենայի թարգմանման համար: Այն թույլ է տալիս կառուցել փոքր ցանցեր, մինչդեռ արդյունքում ստացված համակարգերը պահպանում են սկզբնական մոդելի որակի մեծ մասը: Չնայած այն փաստին, որ շատ հեղինակներ զեկուցում են գիտելիքի դիսլիլացիայի առավելությունների մասին, մի քանիսը քննարկել են այն իրական պատճառները, թե ինչու է այն աշխատում, հատկապես նյարդային ՄԹ-ի կոնտեքստում։ Այս աշխատանքում մենք կատարում ենք մի քանի փորձեր, որոնք նպատակով են հասկանալ, թե We show that translation complexity is actually reduced when building a distilled/synthesised bi-text when compared to the reference bi-text.  Մենք նաև հեռացնում ենք աղմկոտ տվյալները սինթեզված թարգմանություններից և միավորում ենք ֆիլտրված սինթեզված տվյալները միասին սկզբնական հաղորդակցման հետ, որպեսզի ստանանք ավելին բարելավումներ ճշգրտության առումով:', 'az': 'Bilim destilyası yenidən nöral maşına çevirməsinə müvəffəqiyyətlə uyğunlaşdırıldı. Növbəti sistemlərin ən çox modelinin keyfiyyətini saxlayarkən, küçük ağları inşa edə bilər. Həqiqətən, çox yazıcılar elm destilyasının faydalarını bildirməyə rağmen, çox az insan onun nə üçün çalışdığını, özellikle nöral MT-nin kontekstündə mübahisə etdi. Bu kağızda, biz bir neçə təcrübələrin niyə və nəyə destilyasının inklis-Alman çeviri işin ə nörətdiyini anlamaq və nəyə dəyişiklik etmişdir. Biz tərcümə kompleksitəsini, həqiqətən, div-metin inşa etdikdə, div-metin inşa etdikdə əslində azaldığını göstəririk. Biz sintezləşdirilmiş tercümələrdən səs verilər çəkirik və filtrlənmiş sintezləşdirilmiş məlumatları orijinal referans ilə birlikdə birlikdə birlikdə birlikdə birlikdə birlikdə silahlı məlumatları çəkirik, buna görə də həqiqiliyə qazanmaq üçün daha ço', 'bn': 'সম্প্রতি জ্ঞান বিচ্ছিন্ন করা হয়েছে নিউরুল মেশিন অনুবাদের জন্য। এটি ক্রান্ত নেটওয়ার্ক নির্মাণের জন্য অনুমতি দেয় যখন ফলাফলের সিস্টেম মূল মডেলের বেশীরভাগ মান ধরে রাখে। বাস্তবতা সত্ত্বেও অনেক লেখক জ্ঞান বিভাগের সুবিধা সম্পর্কে রিপোর্ট করেছেন, কয়েকজন বাস্তবতা নিয়ে আলোচনা করেছেন কেন এটা কাজ করছে, বিশেষ করে এই কাগজটিতে নিউরেল এমটির প্রেক্ষ আমরা দেখাচ্ছি যে অনুবাদের জটিলতা সত্যিই কমে যাচ্ছে যখন একটি বিভিন্ন বিটেক্সট নির্মাণ করা হচ্ছে বি-টেক্সটের তুলনায় বিভিন আমরা অনুবাদ থেকে আরো আওয়াজের তথ্য মুছে ফেলি এবং মূল সংক্রান্ত তথ্যের সাথে একত্রিত করি, যার ফলে সঠিকভাবে আরো অর্জন পাওয়া যায়।', 'ca': "Recentment la destilació del coneixement s'ha aplicat amb èxit a la traducció neuromàtica. Permet construir xarxes reduïdes mentre els sistemes resultants conserven la majoria de la qualitat del model original. Despite the fact that many authors report on the benefits of knowledge distillation, few have discussed the actual reasons why it works, especially in the context of neural MT. In this paper, we conduct several experiments aimed at understanding why and how distillation impacts accuracy on an English-German translation task.  Mostrem que la complexitat de la traducció es redueix quan construeix un bi-text destilat/sintetitzat en comparació amb el bi-text de referència. We further remove noisy data from synthesised translations and merge filtered synthesised data together with original reference, thus achieving additional gains in terms of accuracy.", 'cs': 'Destilace znalostí byla v poslední době úspěšně aplikována na neuronový strojový překlad. Umožňuje budování zmenšených sítí, zatímco výsledné systémy si zachovávají většinu kvality původního modelu. Navzdory skutečnosti, že mnoho autorů popisuje přínosy destilace znalostí, jen málokdo diskutoval o skutečných důvodech, proč funguje, zejména v kontextu neuronové MT. V tomto článku provádíme několik experimentů zaměřených na pochopení, proč a jak destilace ovlivňuje přesnost na anglicko-německý překlad. Ukazujeme, že složitost překladu je skutečně snížena při tvorbě destilovaného/syntetického bi-textu ve srovnání s referenčním bi-textem. Dále odstraňujeme hlučná data ze syntetických překladů a sloučíme filtrovaná syntetická data s originální referencí, čímž docílíme dalších zisků z hlediska přesnosti.', 'et': 'Teadmiste destilleerimist on hiljuti edukalt rakendatud neuraalse masintõlke valdkonnas. See võimaldab ehitada kahanenud võrgustikke, samas kui tulemusena saadud süsteemid säilitavad suurema osa algse mudeli kvaliteedist. Vaatamata asjaolule, et paljud autorid annavad aru teadmiste destilleerimise eelistest, on vähesed arutanud tegelikke põhjusi, miks see toimib, eriti neuraalse MT kontekstis. Käesolevas töös teeme mitmeid katseid, mille eesmärk on mõista, miks ja kuidas destilleerimine mõjutab täpsust inglise-saksa tõlketöö. Me näitame, et tõlke keerukus on tegelikult vähenenud destilleeritud/sünteesitud bi-teksti ehitamisel võrreldes viitega bi-teksti. Lisaks eemaldame sünteesitud tõlketest mürakad andmed ja ühendame filtreeritud sünteesitud andmed originaalse viitega, saavutades seega täiendava täpsuse.', 'bs': 'Destilacija znanja nedavno je uspješno primjenjena na prevod neuralne mašine. To omogućava izgradnju smanjenih mreža dok rezultatni sistemi drže većinu kvalitete originalnog modela. Unatoč činjenici da mnogi autori izvještaju o koristima destilacije znanja, nekoliko su razgovarali o stvarnim razlogom zašto radi, posebno u kontekstu neuralnog MT-a. U ovom papiru, provodimo nekoliko eksperimenata usmjerenih na razumijevanje zašto i kako destilacija utječe na preciznost na posao prevoda engleskog i njemačkog jezika. Pokazujemo da se kompleksnost prevođenja zapravo smanjuje kada izgradimo destilirani/sintezirani bi-tekst u usporedbi sa referentnim bi-tekstom. Dalje uklonimo bučne podatke iz sinteziranih prevoda i spojimo filtrirane sintezirane podatke zajedno s originalnom referencijom, tako da postignemo dodatne dobitke u smislu tačnosti.', 'fi': 'Tietotislausta on viime aikoina sovellettu menestyksekkäästi neurokonekääntämiseen. Se mahdollistaa kutistuneiden verkkojen rakentamisen, kun taas tuloksena olevat järjestelmät säilyttävät suurimman osan alkuperäisen mallin laadusta. Huolimatta siitä, että monet kirjoittajat raportoivat tietämyksen tislauksen hyödyistä, harvat ovat keskustelleet todellisista syistä, miksi se toimii, erityisesti neuraalisen MT:n yhteydessä. Tässä työssä teemme useita kokeita, joiden tarkoituksena on ymmärtää, miksi ja miten tislaus vaikuttaa tarkkuuteen englannin-saksan käännöstehtävässä. Osoitamme, että käännöksen monimutkaisuus vähenee tislattua/syntetisoitua bi-tekstiä rakennettaessa verrattuna viitebi-tekstiin. Lisäksi poistamme meluisaa tietoa syntetisoiduista käännöksistä ja yhdistämme suodatetut syntetisoidut tiedot alkuperäisiin viittauksiin, mikä lisää tarkkuutta.', 'jv': 'Learn Ndheke iso nggawe tambah sing wis nggawe, nik sistem sing wis ditambah sedhaya padha apik kealitas ning model sing dituluk. Nanging ngomong nek akeh autor sing paling nggawe bener nggawe barang nggawe kesalahan kelas karo nggawe barang nggawe bener, dadi sing nggawe barang nggawe bener, ngomong kapan karo MT miner. Awak dhéwé ngerasakno karo akeh tarjamahan kanggo mbatalungkur sampeyan seneng nggawe barang langgar sampeyan seneng pisan-seneng pisan. Awak dhéwé menehi pernik-pernik nik rabi kanggo tarjamahan seneng pisan karo ingkang dipun dadi seneng pisan sing diranggunaké karo reference sing dumadhi, wih-wih apik dhéwé, ngono iso nglanggar sumelang sing apik dhéwé.', 'sk': 'Destilacija znanja se je v zadnjem času uspešno uporabljala za nevronsko strojno prevajanje. Omogoča gradnjo skrčenih omrežij, medtem ko nastali sistemi ohranjajo večino kakovosti prvotnega modela. Kljub temu, da številni avtorji poročajo o koristih destilacije znanja, redki razpravljajo o dejanskih razlogih, zakaj deluje, zlasti v kontekstu nevronske MT. V tem prispevku izvajamo več eksperimentov, katerih cilj je razumeti, zakaj in kako destilacija vpliva na natančnost na angleško-nemško prevajalsko nalogo. Pokazali smo, da je kompleksnost prevodov dejansko zmanjšana pri gradnji destiliranega/sintetiziranega bi-besedila v primerjavi z referenčnim bi-besedilom. Nadalje odstranimo hrupne podatke iz sintetiziranih prevodov in združujemo filtrirane sintetizirane podatke skupaj z originalnimi referencami, s čimer dosežemo dodatne pridobitve v smislu natančnosti.', 'he': 'משקה ידע הופעל לאחרונה בהצלחה לתרגום מכונות עצביות. It allows for building shrunk networks while the resulting systems retain most of the quality of the original model.  למרות העובדה שרבים סופרים מדווחים על היתרונות של משקה ידע, מעט דיברו על הסיבות האמיתיות מדוע זה עובד, במיוחד בקשר ל MT עצבי. בעיתון הזה, אנו מבצעים כמה ניסויים שמתכוונים להבין מדוע ואיך המשקה משפיע על מדויקה על משימה תרגום אנגלי-גרמנית. אנו מראים שהמורכבות התרגום למעשה מופחית כשבניית שתי-טקסט מסוטל/סינטזי בהשוואה לבי-טקסט התייחסות. נוסף להסיר נתונים רעשים מהתרגומות הסינטזיות ולמזג נתונים סינטזיים מסונטזים יחד עם התייחסות המקורית, כך להשיג תרוויחים נוספים במונחים מדויקים.', 'ha': "@ action: button Ina yarda da ka gina zanen cire-samun masu ƙaranci a lokacin da matsayin na'ura su tsari mafi yawan tsarin motsi na farko. Babu da gaskiyar da mãsu yawa ma'abũta sunayen da aka rarrabe zane, sai kaɗan sun yi jayayya masu kwanza za za ta yi aiki, da haske cikin muhimman muhimmin MT. A cikin wannan takarda, Munã aikin wasu jarrabo masu amfani da wajen fahimta ga mẽne da da rarrabẽwa yana kan aikin wani aikin Ingiriya-Jerumani. Tuna nũna cewa, muhimmin translation za'a ƙara idan an gina wani littãfi da aka raba/haɗa shi na bi-text idan an sammenliki da matsayin bi-text. We further remove noisy data from synthesised translations and merge filtered synthesised data together with original reference, thus achieving additional gains in terms of accuracy.", 'bo': 'མི་ཤེས་པའི་དབྱེ་རིགས་སྟངས་ཉེ་ཆར་ལ་རང་ཉིད་ཀྱི་མ་ལག་འཁྱེར་གྱི་འགྲེལ་བརྗོད་ལ་འཇུག་བྱས་ཡོད། དེ་ནི་དབྱིབས་མ་ལག་གི་མཐུན་ཚད་ཆེ་ཤོས་གཅིག་མཐུན་བཟོ་བཅོས་པ་ཡིན། རྩོམ་པ་པོ་མང་པོ་ཞིག་གིས་མཐུན་བརྗོད་ཀྱི་ལེགས་སྐོར་ལས། ང་ཚོའི་རྒྱུ་མཚན་ཉུང་ཉུང་ཡིན་ནའང་(neural MT)ཡི་སྟོང་ཚུལ་ནང་དུ་གཏོང་བ་འདུག We show that translation complexity is actually reduced when building a distilled/synthesised bi-text when compared to the reference bi-text. The following example is "shift". We further remove noisy data from synthesized translations and merge filtered synthesised data together with original reference, thus achieving additional gains in terms of accuracy.'}
{'en': 'Multi-Source Neural Machine Translation with Data Augmentation', 'ar': 'الترجمة الآلية العصبية متعددة المصادر مع زيادة البيانات', 'pt': 'Tradução automática neural de várias fontes com aumento de dados', 'fr': 'Traduction automatique neuronale multisource avec augmentation des données', 'es': 'Traducción automática neuronal de múltiples fuentes con aumento de datos', 'ja': 'データ拡張機能を備えたマルチソース神経機械翻訳', 'zh': '有数增功能之多源神经机器翻译', 'hi': 'डेटा वृद्धि के साथ बहु स्रोत तंत्रिका मशीन अनुवाद', 'ru': 'Многоисточниковый нейронный машинный перевод с расширением данных', 'ga': 'Aistriúchán Meaisín Néarach Ilfhoinse le Méadú Sonraí', 'ka': 'მონაცემების აგგენტაციათან მრავალური წიგნის ნეიროლური მაქინის გადატყვება', 'el': 'Νευρική μηχανική μετάφραση πολλαπλών πηγών με αύξηση δεδομένων', 'hu': 'Többforrású neurális gépi fordítás adatbővítéssel', 'kk': 'Көптеген көздегі нейралық машиналық аудармалары деректерді көтеру үшін', 'it': 'Traduzione automatica neurale multi-sorgente con aumento dei dati', 'ms': 'Penerjemahan Mesin Neural Berberapa Sumber dengan Penyulitan Data', 'mt': 'Traduzzjoni ta’ Makkinarju Newrali b’Sorsi Multi b’Aġġustament tad-Dejta', 'lt': 'Daugiašaltinio nervinės mašinos vertimas su duomenų augmentacija', 'mk': 'Name', 'pl': 'Wieloźródłowe neuronowe tłumaczenie maszynowe z rozszerzeniem danych', 'ml': 'ഡേറ്റാ ആഗ്മെന്റേഷനുമായി പല- സ്രോതസ്സോര്\u200dസ്സ് നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുക', 'sr': 'Multiizvorno neuronski prevod sa povećanjem podataka', 'mn': 'Мөн олон эх үүсвэрийн мэдрэлийн машины хөгжүүлэлт өгөгдлийн нэмэгдүүлэлт', 'no': 'Oversett av fleirkjelde neuralmaskin med dataaugmentasjon', 'sv': 'Neural maskinöversättning med flera källor med dataförstärkning', 'ro': 'Traducere automată neurală multi-sursă cu augmentarea datelor', 'si': 'ගොඩක් ප්\u200dරභාවක් නිර්මාණ මැෂින් පරිවර්තනය', 'so': 'Turjumista Maamulka Neural ee Multi-Source Neural machine with Data Augmentation', 'ta': 'Multi-Source Neural Machine Translation with Data Augmentation', 'ur': 'Multi-Source Neural Machine Translation with Data Augmentation', 'uz': 'Name', 'vi': 'Dịch đa nguồn máy thần kinh với sự gia tăng dữ liệu', 'bg': 'Многоизточников неврален машинен превод с увеличаване на данните', 'hr': 'Višeizvorno neurološki prevod uređaja s povećanjem podataka', 'nl': 'Multi-Source Neural Machine Translation met Data Augmentation', 'da': 'Neural maskinoversættelse med flere kilder med dataudvidelse', 'de': 'Multi-Source neuronale maschinelle Übersetzung mit Datenauswertung', 'id': 'Multi-Source Neural Machine Translation with Data Augmentation', 'ko': '데이터 기반 확장 다원 신경 기계 번역', 'fa': 'ترجمه ماشین عصبی چند منبع با افزایش داده', 'sw': 'Tafsiri ya Mashine ya Kifaransa ya Kifaransa kwa Utafiti wa Data', 'sq': 'Multi-Source Neural Machine Translation with Data Augmentation', 'af': 'Name', 'tr': 'Çoklu-Çeşme Niýal Maşynyň Maglumaty Aýagdasy bilen terjime', 'hy': 'Բազմաաղբյուր նեյրոնային մեքենայի թարգմանություն տվյալների աճման հետ', 'az': '쎇潸汵⁋慹湡歬쒱⁎쎼牡氠䵡歩湡琠哉饲揃뱭즙獩⁖敲椠䇄齡揄녬쒱쒟쒱祬愊', 'bn': 'Name', 'bs': 'Multiizvorska neuronska prevoda sa povećanjem podataka', 'ca': 'Una traducció de màquines neuronals de múltiples fonts amb augmentació de dades', 'cs': 'Multizdrojový neuronový strojový překlad s rozšířením dat', 'et': 'Mitme allika neuraalne masintõlge koos andmete suurendamisega', 'fi': 'Monilähdeinen neurokonekäännös datan lisäämisellä', 'am': 'ምርጫዎች', 'ha': 'translation', 'he': 'תרגום מכונת נוירולית ממקורים רבים עם גידול נתונים', 'sk': 'Več virov nevralnega strojnega prevajanja s povečanjem podatkov', 'jv': "Menu item to Open 'Search for Open Files' dialog", 'bo': 'Multi-Source Neural Machine Translation with Data Augmentation'}
{'en': 'Multi-source translation systems translate from multiple languages to a single target language. By using information from these multiple sources, these  systems  achieve large gains in  accuracy . To train these systems, it is necessary to have corpora with parallel text in multiple sources and the target language. However, these  corpora  are rarely complete in practice due to the difficulty of providing human translations in all of the relevant languages. In this paper, we propose a data augmentation approach to fill such incomplete parts using multi-source neural machine translation (NMT). In our experiments, results varied over different language combinations but significant gains were observed when using a source language similar to the target language.', 'ar': 'تترجم أنظمة الترجمة متعددة المصادر من لغات متعددة إلى لغة هدف واحدة. باستخدام المعلومات من هذه المصادر المتعددة ، تحقق هذه الأنظمة مكاسب كبيرة في الدقة. لتدريب هذه الأنظمة ، من الضروري وجود مجموعة نصوص موازية في مصادر متعددة واللغة الهدف. ومع ذلك ، نادرًا ما تكتمل هذه المجموعات من الناحية العملية نظرًا لصعوبة تقديم ترجمات بشرية في جميع اللغات ذات الصلة. في هذا البحث ، نقترح نهجًا لزيادة البيانات لملء هذه الأجزاء غير المكتملة باستخدام الترجمة الآلية العصبية متعددة المصادر (NMT). في تجاربنا ، اختلفت النتائج باختلاف تركيبات اللغات ولكن لوحظت مكاسب كبيرة عند استخدام لغة مصدر مشابهة للغة الهدف.', 'fr': "Les systèmes de traduction multisources traduisent de plusieurs langues vers une seule langue cible. En utilisant les informations provenant de ces sources multiples, ces systèmes obtiennent d'importants gains de précision. Pour entraîner ces systèmes, il est nécessaire d'avoir des corpus avec texte parallèle dans plusieurs sources et dans la langue cible. Cependant, ces corpus sont rarement complets en pratique en raison de la difficulté de fournir des traductions humaines dans toutes les langues pertinentes. Dans cet article, nous proposons une approche d'augmentation des données pour remplir de telles parties incomplètes à l'aide de la traduction automatique neuronale (NMT) multi-sources. Dans nos expériences, les résultats variaient selon les combinaisons de langues, mais des gains significatifs ont été observés lors de l'utilisation d'une langue source similaire à la langue cible.", 'es': 'Los sistemas de traducción de múltiples fuentes traducen de varios idiomas a un solo idioma de destino. Al utilizar la información de estas múltiples fuentes, estos sistemas logran grandes ganancias en precisión. Para entrenar estos sistemas, es necesario tener corpus con texto paralelo en múltiples fuentes y el idioma de destino. Sin embargo, estos corpus rara vez están completos en la práctica debido a la dificultad de proporcionar traducciones humanas en todos los idiomas pertinentes. En este artículo, proponemos un enfoque de aumento de datos para llenar estas partes incompletas mediante la traducción automática neuronal (NMT) de múltiples fuentes. En nuestros experimentos, los resultados variaron según las diferentes combinaciones lingüísticas, pero se observaron avances significativos al utilizar un idioma de origen similar al idioma de destino.', 'pt': 'Os sistemas de tradução de várias fontes traduzem de vários idiomas para um único idioma de destino. Ao usar informações dessas múltiplas fontes, esses sistemas obtêm grandes ganhos de precisão. Para treinar esses sistemas, é necessário ter corpora com texto paralelo em várias fontes e no idioma de chegada. No entanto, esses corpora raramente são completos na prática devido à dificuldade de fornecer traduções humanas em todos os idiomas relevantes. Neste artigo, propomos uma abordagem de aumento de dados para preencher essas partes incompletas usando tradução automática neural de várias fontes (NMT). Em nossos experimentos, os resultados variaram em diferentes combinações de idiomas, mas ganhos significativos foram observados ao usar um idioma de origem semelhante ao idioma de destino.', 'ja': 'マルチソース翻訳システムは、複数の言語から単一のターゲット言語に翻訳されます。これらの複数の情報源からの情報を使用することで、これらのシステムは高い精度を実現します。これらのシステムをトレーニングするには、複数のソースとターゲット言語の並列テキストを持つコーパが必要です。しかし、関連するすべての言語で人間による翻訳を提供することが困難であるため、これらのコーポラは実際にはほとんど完全ではありません。本稿では，このような不完全な部分をマルチソースのニューラル機械翻訳（ NMT ）を用いて埋めるためのデータ拡張アプローチを提案する．我々の実験では、結果は異なる言語の組み合わせにわたって変化したが、ターゲット言語と同様のソース言語を使用した場合に有意な利得が観察された。', 'zh': '多源译系统从多种语言翻译成单一。 用此数息者,准确性之大者也。 所以练其统者,必于数源语言之中,有并行文本之语料库。 然难给人工翻译,语料库在实践中少完。 本文中,立数增强之法,以用多源神经机器翻译(NMT)充其不全者。 于我实验中,异言异实,然当用类于语言,以观其益。', 'hi': 'बहु-स्रोत अनुवाद प्रणालियाँ एकाधिक भाषाओं से एक ही लक्ष्य भाषा में अनुवाद करती हैं. इन एकाधिक स्रोतों से जानकारी का उपयोग करके, ये सिस्टम सटीकता में बड़े लाभ प्राप्त करते हैं। इन प्रणालियों को प्रशिक्षित करने के लिए, कई स्रोतों और लक्ष्य भाषा में समानांतर पाठ के साथ कॉर्पोरेट होना आवश्यक है। हालांकि, ये कॉर्पोरेट शायद ही कभी सभी प्रासंगिक भाषाओं में मानव अनुवाद प्रदान करने की कठिनाई के कारण व्यवहार में पूर्ण होते हैं। इस पेपर में, हम बहु-स्रोत तंत्रिका मशीन अनुवाद (एनएमटी) का उपयोग करके इस तरह के अधूरे भागों को भरने के लिए एक डेटा वृद्धि दृष्टिकोण का प्रस्ताव करते हैं। हमारे प्रयोगों में, परिणाम विभिन्न भाषा संयोजनों पर भिन्न होते हैं, लेकिन लक्ष्य भाषा के समान स्रोत भाषा का उपयोग करते समय महत्वपूर्ण लाभ देखे गए थे।', 'ru': 'Мультиисточники систем перевода переводят с нескольких языков на один целевой язык. Используя информацию из этих многочисленных источников, эти системы добиваются значительного повышения точности. Для обучения этих систем необходимо иметь корпуса с параллельным текстом в нескольких источниках и целевом языке. Однако на практике эти корпуса редко бывают полными из-за трудностей с предоставлением человеческих переводов на все соответствующие языки. В данной работе мы предлагаем подход к увеличению данных для заполнения таких неполных частей с использованием многоисточника нейронного машинного перевода (НМП). В наших экспериментах результаты варьировались для разных языковых комбинаций, но при использовании исходного языка, аналогичного целевому языку, наблюдались значительные улучшения.', 'ga': 'Aistrítear córais aistriúcháin ilfhoinse ó iliomad teangacha go sprioctheanga amháin. Trí fhaisnéis ó na foinsí iolracha seo a úsáid, baineann na córais seo gnóthachain mhóra amach i gcruinneas. Chun na córais seo a oiliúint, is gá corpora a bheith ann le téacs comhthreomhar i bhfoinsí iolracha agus sa sprioctheanga. Mar sin féin, is annamh a bhíonn na corpora seo críochnaithe i gcleachtas mar gheall ar an deacracht a bhaineann le haistriúcháin daonna a sholáthar sna teangacha ábhartha ar fad. Sa pháipéar seo, molaimid cur chuige méadaithe sonraí chun páirteanna neamhiomlána den sórt sin a líonadh ag baint úsáide as aistriúchán meaisín néarúil ilfhoinse (NMT). Inár dturgnaimh, bhí éagsúlacht sna torthaí thar theaglaim éagsúla teanga ach chonacthas dul chun cinn suntasach nuair a bhí teanga foinse cosúil leis an sprioctheanga in úsáid.', 'ka': 'Multi source translation systems translate from multiple languages to a single target language. ამ მრავალ გამოყენებული ინფორმაციის გამოყენებით, ეს სისტემები ძალიან წარმოიდგინდება მართლად. ამ სისტემის გასწავლისთვის, უნდა იყოს კოპორა, რომელიც მრავალური წიგნებში და მიზეზი ენაში პარალელური ტექსტი აქვს. მაგრამ, ეს კოპორაცია არაფერად დასრულებულია პრაქტიკში, რადგან ადამიანის წარმატების შეცვლის ყველა შესაბამისი ენაში. ამ დომენტში ჩვენ მოვიწყებთ მონაცემების აგგენტირება, რომელიც ასეთი უკვე დასრულებული ნაწილები გამოყენებული მრავალური ნეიროლური მაქინის გარგუმარება ( ჩვენი ექსპერიმენტებში, შედეგები განსხვავებულია განსხვავებული ენის კომბინციების შესახებ, მაგრამ მნიშვნელოვანი წარმოიდგინეთ, როდესაც მისახედვილი ენის გამ', 'el': 'Τα μεταφραστικά συστήματα πολλαπλών πηγών μεταφράσουν από πολλές γλώσσες σε μια ενιαία γλώσσα-στόχο. Χρησιμοποιώντας πληροφορίες από αυτές τις πολλαπλές πηγές, αυτά τα συστήματα επιτυγχάνουν μεγάλα κέρδη στην ακρίβεια. Για να εκπαιδεύσετε αυτά τα συστήματα, είναι απαραίτητο να έχετε σώματα με παράλληλο κείμενο σε πολλαπλές πηγές και τη γλώσσα προορισμού. Ωστόσο, αυτά τα σώματα σπάνια είναι ολοκληρωμένα στην πράξη λόγω της δυσκολίας παροχής ανθρώπινων μεταφράσεων σε όλες τις σχετικές γλώσσες. Στην παρούσα εργασία, προτείνουμε μια προσέγγιση αύξησης δεδομένων για την πλήρωση τέτοιων ελλιπών τμημάτων χρησιμοποιώντας πολλαπλές πηγές νευρωνική μηχανική μετάφραση (NMT). Στα πειράματά μας, τα αποτελέσματα ποικίλησαν σε διαφορετικούς γλωσσικούς συνδυασμούς, αλλά παρατηρήθηκαν σημαντικά οφέλη όταν χρησιμοποιείται μια γλώσσα προέλευσης παρόμοια με τη γλώσσα-στόχο.', 'it': "I sistemi di traduzione multi-source traducono da più lingue a un'unica lingua di destinazione. Utilizzando informazioni provenienti da queste fonti multiple, questi sistemi ottengono grandi guadagni in precisione. Per formare questi sistemi, è necessario avere corpora con testo parallelo in più fonti e la lingua di destinazione. Tuttavia, questi corpora sono raramente completi nella pratica a causa della difficoltà di fornire traduzioni umane in tutte le lingue pertinenti. In questo articolo, proponiamo un approccio di aumento dei dati per riempire tali parti incomplete utilizzando la traduzione automatica neurale multi-source (NMT). Nei nostri esperimenti, i risultati variavano su diverse combinazioni linguistiche, ma sono stati osservati guadagni significativi utilizzando una lingua di origine simile alla lingua di destinazione.", 'lt': 'Daugiašaltinių vertimo sistemos išverstos iš įvairių kalbų į vieną tikslinę kalbą. Naudojant informaciją iš šių įvairių šaltinių šios sistemos gauna didelį tikslumo padidėjimą. Siekiant apmokyti šias sistemas, būtina turėti korprą su lygiagrečiu tekstu įvairiais šaltiniais ir tiksline kalba. Tačiau praktikoje šie korporai retai baigiami dėl sunkumų teikti vertimus žmonėmis visomis atitinkamomis kalbomis. Šiame dokumente siūlome duomenų didinimo metodą, kad būtų užpildytos tokios neišsamios dalys naudojant daugialypį neurologinį vertimą (NMT). Mūsų eksperimentuose rezultatai skirtingais kalbų deriniais skyrėsi, tačiau buvo pastebėtas didelis pasiekimas naudojant šaltinio kalbą, panašią į tikslinę kalbą.', 'hu': 'Többforráskódú fordítási rendszerek több nyelvről fordítanak le egyetlen célnyelvre. A többféle forrásból származó információk felhasználásával ezek a rendszerek nagy pontosságnövekedést érnek el. Ezeknek a rendszereknek a képzéséhez párhuzamos szövegű korpuszoknak kell lenniük több forrásban és a célnyelven. Ezek a korpuszok azonban ritkán teljesek a gyakorlatban, mivel nehéz emberi fordításokat biztosítani az összes releváns nyelven. Ebben a tanulmányban egy adatbővítési megközelítést javasolunk az ilyen hiányos részek többforrású neurális gépi fordítás (NMT) segítségével történő kitöltésére. Kísérleteink során az eredmények különböző nyelvkombinációkban változtak, de jelentős előnyöket figyeltek meg a célnyelvhez hasonló forrásnyelv használata során.', 'ms': 'Sistem terjemahan-sumber berbilang terjemahan dari bahasa berbilang ke bahasa sasaran tunggal. Dengan menggunakan maklumat dari sumber berbilang ini, sistem ini mencapai keuntungan besar dalam ketepatan. Untuk melatih sistem ini, perlu ada korpra dengan teks selari dalam sumber berbilang dan bahasa sasaran. Namun, corpora ini jarang selesai dalam praktek kerana kesulitan menyediakan terjemahan manusia dalam semua bahasa yang relevan. Dalam kertas ini, kami cadangkan pendekatan peningkatan data untuk mengisi bahagian yang tidak lengkap dengan menggunakan terjemahan mesin saraf berbilang sumber (NMT). Dalam eksperimen kami, keputusan berbeza dalam kombinasi bahasa berbeza tetapi keuntungan yang signifikan dilihat apabila menggunakan bahasa sumber yang sama dengan bahasa sasaran.', 'kk': 'Көп көзі аудару жүйелері бірнеше тілден бір мақсатты тілде аударылады. Бұл бірнеше көзінен мәліметті қолдану үшін бұл жүйелер дұрыс жеткізеді. Бұл жүйелерді оқыту үшін корпора бірнеше көзі мен мақсатты тілде параллелі мәтін болу керек. Бірақ бұл корпора тәжірибеде адамдардың аудармаларын барлық тілдерде беру қиындығынан бітпейді. Бұл қағазда біз оны бірнеше көп көзі негізгі невралдық компьютердің аудармасын (NMT) қолданып толтыру үшін деректерді көптегендіру тәртібін ұсынамыз. Біздің тәжірибемізде, нәтижелер түрлі тіл комбинацияларынан айырмалы, бірақ мақсатты тіліне ұқсас көзінің тілін қолданғанда маңызды жетілдерді көрсетілді.', 'mk': 'Мулти- изворни преведувачки системи преведуваат од повеќе јазици на еден јазик на цел. Со употреба на информации од овие многуте извори, овие системи постигнуваат големи зголемувања во прецизноста. За да се обучат овие системи, е потребно да се има корпора со паралелен текст во повеќе извори и јазик на целта. Сепак, овие корпора ретко се комплетни во практиката поради тешкотијата да се обезбедат човечки преводи на сите релевантни јазици. Во овој документ, предложуваме пристап за зголемување на податоците за пополнување на вакви некомплетни делови со користење на мултиизворен нервен превод (НМТ). Во нашите експерименти, резултатите се разликуваа во различни јазички комбинации, но значителни добивки беа забележани кога се користи изворен јазик сличен на метниот јазик.', 'ml': 'Multi- source translation systems translate multiple languages from multiple languages to a single target language. ഈ പല സ്രോതസ്സുകളില്\u200d നിന്നും വിവരങ്ങള്\u200d ഉപയോഗിച്ച്, ഈ സിസ്റ്റമുകള്\u200d കൃത്രിമമായ വിഭവങ്ങളില്\u200d നിന്നും  ഈ സിസ്റ്റമുകളെ പരിശീലിപ്പിക്കാന്\u200d, പല സ്രോതസ്സുകളിലും ലക്ഷ്യമുള്ള ഭാഷയിലും പദാവലിയുമുള്ള കോര്\u200dപ്പോറയുടെ വാ എന്നാലും ഈ കോർപ്പോരാ പ്രവര്\u200dത്തനത്തില്\u200d പൂര്\u200dണ്ണമായി പൂര്\u200dണ്ണമായിരിക്കുന്നു. എല്ലാ വിചാരകങ്ങളിലും മനുഷ്യരുടെ ഭ ഈ പത്രത്തില്\u200d, ഇത്തരം അപരിപൂര്\u200dണ്ണമായ ഭാഗങ്ങള്\u200d നിറയ്ക്കാന്\u200d ഞങ്ങള്\u200d ഒരു ഡേറ്റാ ആഗ്രഹിക്കുന്നു In our experiments, results varied over different language combinations but significant gains were observed when using a source language similar to the target language.', 'mt': 'Sistemi ta’ traduzzjoni b’sorsi multipli jittraduċu minn lingwi multipli għal lingwa waħda fil-mira. Permezz tal-użu ta’ informazzjoni minn dawn is-sorsi multipli, dawn is-sistemi jiksbu kisbiet kbar fil-preċiżjoni. Biex jitħarrġu dawn is-sistemi, jeħtieġ li jkun hemm corpora b’test parallel f’diversi sorsi u l-lingwa fil-mira. Madankollu, dawn il-korpi rarament ikunu kompleti fil-prattika minħabba d-diffikultà li jiġu pprovduti traduzzjonijiet umani fil-lingwi rilevanti kollha. F’dan id-dokument, qed nipproponu approċċ ta’ żieda fid-dejta biex timtela partijiet mhux kompluti bħal dawn bl-użu ta’ traduzzjoni ta’ magni newrali b’diversi sorsi (NMT). Fl-esperimenti tagħna, ir-riżultati varjaw fuq kombinazzjonijiet differenti ta’ lingwi iżda kien osservat kisbiet sinifikanti meta ntuża lingwa tas-sors simili għall-lingwa fil-mira.', 'mn': 'Олон эх үүсвэрийн орчуулах системүүд олон хэлд нэг зорилготой хэл руу орчуулдаг. Эдгээр олон эх үүсвэрээс мэдээллийг ашиглан эдгээр системүүд зөв байдалд том ашигтай болдог. Эдгээр системүүдийг суралцахын тулд олон эх үүсвэр болон зорилготой хэл дээр корпора байх хэрэгтэй. Гэхдээ эдгээр корпора нь хүн төрөлхтний хөгжлийн хэл дээр хүмүүсийн хөгжлийн хөгжлийн хэцүү хэлбэрээр бага зэрэг төгсгөл байдаг. Энэ цаасан дээр бид олон эх үүсвэрийн мэдрэлийн механикийн хөрөнгө оруулалтыг ашиглан ийм төгс хэсгийг дүүргэхэд өгөгдлийн нэмэгдүүлэх арга зам санал өгдөг. Бидний туршилтанд үр дүнг олон хэл холбогдолтоос өөрчлөгдсөн, гэхдээ зорилготой хэл шиг эх үүсвэрийн хэл ашиглах үед маш чухал ашигтай байлаа.', 'ro': 'Sistemele de traducere multi-sursă traduc din mai multe limbi într-o singură limbă țintă. Utilizând informații din aceste surse multiple, aceste sisteme obțin câștiguri mari în precizie. Pentru a instrui aceste sisteme, este necesar să aveți corpore cu text paralel în mai multe surse și limba țintă. Cu toate acestea, aceste corpore sunt rareori complete în practică din cauza dificultății de a furniza traduceri umane în toate limbile relevante. În această lucrare, propunem o abordare de augmentare a datelor pentru a umple astfel de părți incomplete folosind traducerea automată neurală multi-sursă (NMT). În experimentele noastre, rezultatele au variat pe diferite combinații lingvistice, dar au fost observate câștiguri semnificative atunci când se utilizează o limbă sursă similară limbii țintă.', 'si': 'ගොඩක් ප්\u200dරමාණ පද්ධතිය භාෂාවල් වලින් එක්ක ඉලක්ෂ භාෂාවට පරිවර්තන කරන්න. මේ ගොඩක් මුළුවන්ගෙන් තොරතුරු භාවිත කරන්න, මේ පද්ධතිය ලොකු ප්\u200dරමාණයක් හරියට ලැබෙනවා. මේ පද්ධතියට ප්\u200dරධානය කරන්න, ඒක අවශ්\u200dය වෙන්නේ කොර්පෝරා එක්ක සාමාන්\u200dය පාළුවක් තියෙන්න සහ ඉලක් නමුත්, මේ කොර්පෝරා අවශ්\u200dය භාෂාවල් සියලුම් භාෂාවලට මිනිස්සුන්ගේ භාෂාව අවශ්\u200dය දෙන්න අවශ මේ පත්තරේ අපි දත්ත විශාලනයක් ප්\u200dරයෝජනය කරනවා ඒ වගේ අමුල්පූර්ණ කොටස් පුරවන්න සඳහා ගොඩක් ප්\u200dරයෝජනය නි අපේ පරීක්ෂණයේ ප්\u200dරතිචාරයක් වෙනස් භාෂාව සම්බන්ධයෙන් වෙනස් වෙනුවෙන් වෙනස් වෙනුවෙන් තියෙන්නේ නමුත්', 'so': "Isticmaalka tarjumaadda badan waxay ku tartamaan luuqado badan ilaa luqad kaliya. Wixii macluumaadka laga isticmaalayo sourceadan kala duduwan, nidaamkan wuxuu ku gaadhaa faa'iido badan si saxda ah. Si aad u tababarido nidaamkan waxaa u baahan in shirkad ay leedahay qoraal lambar ah oo ay leeyihiin noocyo badan iyo luqada waxqabadka. Si kastaba ha ahaatee shirkaddaas wax yar ayeey ku dhamaadaan tababarida sababtoo ah dhibaatada ay ku jirto bixinta turjumaadda dadka oo luqadaha la xiriira oo dhan. Qoraalkan waxaynu ka soo jeedaynaa qaabilaad ku kordhiya macluumaadka si aan u buuxino qeybahaas aan dhammayn, sida loo isticmaalo tarjumaadda machine neural ah (NMT). Imtixaanadayada, resultiyadu waxay ku kala duwanyihiin isku xiriirka luuqadaha kala duduwan, laakiin waxaa la arkay faa'iido badan marka lagu isticmaalo luqada sourceed oo u eg luqada goalka.", 'pl': 'Systemy tłumaczeń wielu źródeł tłumaczą z wielu języków na jeden język docelowy. Dzięki wykorzystaniu informacji z tych wielu źródeł systemy te osiągają duży wzrost dokładności. Aby trenować te systemy, konieczne jest posiadanie korpusów z tekstem równoległym w wielu źródłach i języku docelowym. Jednak korpusy te rzadko są kompletne w praktyce ze względu na trudności z dostarczeniem ludzkich tłumaczeń we wszystkich odpowiednich językach. W niniejszym artykule proponujemy podejście do powiększania danych w celu wypełnienia takich niekompletnych części za pomocą multi-source neuron machine translation (NMT). W naszych eksperymentach wyniki różniły się w zależności od różnych kombinacji językowych, ale zaobserwowano istotne zyski podczas stosowania języka źródłowego podobnego do języka docelowego.', 'no': 'Oversett av fleire kjeldeomsetjingssystemer frå fleire språk til ei enkelt målspråk. Ved å bruka informasjon frå desse fleire kjeldene, oppnår desse systema store forskjeller i nøyaktighet. For å trenja desse systema må det ha korpora med parallelle tekst i fleire kilder og målspråket. Desse korporane er likevel ofte fullførte i praksis på grunn av vanskeligheten for å gi menneske oversettelsar i alle dei relevante språka. I denne papiret foreslår vi ein dataaugmentasjonstilnærming for å fylle slike ufullstende deler med fleire kjelde neuralmaskinsomsetjing (NMT). I eksperimentene våre varierte resultat over ulike språk-kombinasjonar, men det var observert signifikante forståking ved bruk av kjeldespråk som liknar målspråket.', 'sv': 'Översättningssystem med flera källor översätter från flera språk till ett enda målspråk. Genom att använda information från dessa flera källor uppnår dessa system stora vinster i noggrannhet. För att träna dessa system är det nödvändigt att ha korpora med parallell text i flera källor och målspråket. Dessa korpor är dock sällan fullständiga i praktiken på grund av svårigheten att tillhandahålla mänskliga översättningar på alla relevanta språk. I denna uppsats föreslår vi en dataaugmentationsmetod för att fylla sådana ofullständiga delar med hjälp av multi-source neural machine translation (NMT). I våra experiment varierade resultaten över olika språkkombinationer men signifikanta vinster observerades vid användning av ett källspråk som liknar målspråket.', 'ta': 'பல- மூல மொழி மொழிபெயர்ப்பு அமைப்புகள் இந்த பல மூலங்களிலிருந்து தகவல்களை பயன்படுத்தி, இந்த அமைப்புகள் சரியான முறையில் பெரிய வெற்றியடைகிறது. இந்த அமைப்புகளை பயிற்சி செய்ய, பல மூலங்களிலும் இலக்கு மொழியிலும் இணைய உரையுடனும் குறிப்பிட வேண்டும். ஆனால், இந்த நிறுவனம் முழுமையாக முடிந்தது அனைத்து தொடர்புடைய மொழிகளிலும் மனித மொழிபெயர்ப்புகளை வழங்குவதினால இந்த காகிதத்தில், நாம் இத்தகைய முழுமையான பகுதிகளை நிரப்ப முடியும் தகவல் கூட்டுதல் முறைமையை பயன்படுத்தி பல மூல மூல புதிய இயந எங்கள் சோதனைகளில், முடிவுகள் வேறு மொழி இணைப்புகளில் மாறுபட்டுள்ளது ஆனால் இலக்கு மொழியின் போன்ற மூல மொழியை பயன்படுத்', 'sr': 'Višeizvorski prevodni sistemi prevode od višestrukih jezika na jedan ciljni jezik. Koristeæi informacije iz ovih višestrukih izvora, ovi sistemi postižu velike dobitke taènosti. Da bi obučili te sisteme, potrebno je imati korporu sa paralelnim tekstom u višestrukim izvorima i ciljnim jezikom. Međutim, ove korporacije su rijetko potpune u praksi zbog teškoće pružanja ljudskih prevoda na svim relevantnim jezicima. U ovom papiru predlažemo povećanje pristupa podataka kako bi napunili takve nepotpune dijelove koristeći multiizvornu neuralnu mašinu prevod (NMT). U našim eksperimentima, rezultati su različiti zbog različitih jezičkih kombinacija, ali značajne dobitke su primijećene kada su koristili izvorni jezik sličan ciljnom jeziku.', 'ur': 'Multi-source translation systems translate from multiple languages to a single target language. یہ بہت سی سراسروں سے معلومات استعمال کرتے ہیں، یہ سیسٹم بہت سی کامیابی حاصل کرتے ہیں۔ ان سیستموں کی تعلیم کرنے کے لئے، بہت سی سورجوں اور موجود زبان میں قابل متن کے ساتھ کورپورا ہونا ضرورت ہے. لیکن یہ شرکت کم کم کامل ہوتی ہے کہ انسان کی تعبیر کی سختی کے باعث تمام معاملات زبانوں میں۔ اس کاغذ میں ہم ایک ڈیٹا اگنٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈی ہمارے آزمائش میں، نتیجے مختلف زبان ترکیب پر متفاوت ہوتے ہیں لیکن جب موجود زبان کے مطابق ایک سراسر زبان کا استعمال کرتا ہے تو اہم کامیاب ہوتے ہیں.', 'uz': "@ info: whatsthis Ushbu bir necha manbalar bilan maʼlumot yordamida bu tizimlar tashkilotga katta muvaffaqiyatli bajaradi. Bu tizimlarni tahrirlash uchun, bir necha manbalar bilan parallel matn bilan ishlatish kerak. Lekin, bu kompaniya barcha bog'liq tilda inson tarjimalarni tarjima qilish muvaffaqiyatsiz tugadi. Bu hujjatda biz bir necha manba uchun neyural tarjima (NMT) yordamida bu narsalarni to ʻldirish uchun maʼlumot qoʻshish usulini talab qilamiz. Bizning tajribalarimizda natijalar boshqa tillar bir xil bog'liqlarida o'zgarilgan, lekin maktab tilni ishlatish uchun juda muhim muvaffaqiyatlarni ko'rsatadi.", 'vi': 'Dịch vụ đa nguồn dịch dịch dịch chuyển từ nhiều ngôn ngữ thành một ngôn ngữ chung. Bằng cách sử dụng thông tin từ nhiều nguồn khác nhau, những hệ thống này đạt được độ chính xác lớn. Để huấn luyện những hệ thống này, cần phải có hạ sĩ có chữ song song trong nhiều nguồn và ngôn ngữ đích. Tuy nhiên, thực tế họ hiếm khi hoàn thành vì khó khăn cung cấp bản dịch con người ở tất cả các ngôn ngữ liên quan. Trong tờ giấy này, chúng tôi đề nghị một phương pháp gia tăng dữ liệu để điền vào các bộ phận chưa hoàn chỉnh bằng cách dịch chuyển máy thần kinh đa nguồn (NMB). Trong các thí nghiệm của chúng tôi, kết quả đã thay đổi nhiều ngôn ngữ khác nhau nhưng những lợi ích quan trọng đã được quan sát khi sử dụng ngôn ngữ nguồn tương tự với ngôn ngữ đích.', 'bg': 'Системите за превод с множество източници превеждат от няколко езика на един целеви език. Използвайки информация от тези множество източници, тези системи постигат големи печалби в точността. За да се обучават тези системи, е необходимо да има корпуси с паралелен текст в множество източници и целевия език. Въпреки това, тези корпуси рядко са пълни на практика поради трудността да се предоставят човешки преводи на всички съответни езици. В настоящата статия предлагаме подход за увеличаване на данните за запълване на такива непълни части с помощта на многоизточник невронен машинен превод (НМТ). В нашите експерименти резултатите варират в различните езикови комбинации, но значителни ползи са наблюдавани при използване на изходен език, подобен на целевия език.', 'hr': 'Višeizvorni sustavi prevoda iz višestrukih jezika na jedan ciljni jezik. Koristeći informacije iz ovih višestrukih izvora, ovi sustavi ostvaruju veliku pobjedu u točnosti. Da bi obučili te sustave, potrebno je imati tijelo s paralelnim tekstom u višestrukim izvorima i ciljnim jezikom. Međutim, ta tijela su rijetko potpuna u praksi zbog teškoće pružanja ljudskih prevoda na svim relevantnim jezicima. U ovom papiru predlažemo pristup povećanja podataka kako bi napunili takve nepotpune dijelove koristeći multiizvorno prevod neuralnih strojeva (NMT). U našim eksperimentima, rezultati su različiti preko različitih jezičkih kombinacija, ali značajne dobitke su primijećene kada su koristili izvorni jezik sličan ciljnom jeziku.', 'da': 'Oversættelsessystemer med flere kilder oversætter fra flere sprog til et enkelt målsprog. Ved at bruge oplysninger fra disse flere kilder opnår disse systemer store gevinster i nøjagtighed. For at træne disse systemer er det nødvendigt at have corpora med parallel tekst i flere kilder og målsproget. Men disse corpora er sjældent komplette i praksis på grund af vanskelighederne med at levere menneskelige oversættelser på alle de relevante sprog. I denne artikel foreslår vi en dataaugmentation tilgang til at udfylde sådanne ufuldstændige dele ved hjælp af multi-source neural machine translation (NMT). I vores eksperimenter varierede resultaterne over forskellige sprogkombinationer, men der blev observeret betydelige gevinster ved brug af et kildesprog svarende til målsproget.', 'nl': "Multi-source vertaalsystemen vertalen van meerdere talen naar één doeltaal. Door gebruik te maken van informatie uit deze meerdere bronnen, bereiken deze systemen grote winsten in nauwkeurigheid. Om deze systemen te trainen, is het noodzakelijk om corpora's met parallelle tekst in meerdere bronnen en de doeltaal te hebben. Deze corpora's zijn in de praktijk echter zelden compleet vanwege de moeilijkheid om menselijke vertalingen in alle relevante talen te leveren. In dit artikel stellen we een data augmentatie benadering voor om dergelijke onvolledige delen te vullen met behulp van multi-source neural machine translation (NMT). In onze experimenten varieerden de resultaten over verschillende taalcombinaties, maar er werden significante winsten waargenomen bij het gebruik van een brontaal vergelijkbaar met de doeltaal.", 'de': 'Multi-Source-Übersetzungssysteme übersetzen aus mehreren Sprachen in eine einzige Zielsprache. Durch die Verwendung von Informationen aus diesen verschiedenen Quellen erzielen diese Systeme große Genauigkeitsgewinne. Um diese Systeme zu trainieren, ist es notwendig, Korpora mit parallelem Text in mehreren Quellen und in der Zielsprache zu haben. Allerdings sind diese Korpora in der Praxis selten vollständig, da es schwierig ist, menschliche Übersetzungen in alle relevanten Sprachen bereitzustellen. In diesem Beitrag schlagen wir einen Datenaugementationsansatz vor, um solche unvollständigen Teile mittels Multi-Source Neural Machine Translation (NMT) zu füllen. In unseren Experimenten variierten die Ergebnisse über verschiedene Sprachkombinationen, aber bei Verwendung einer der Zielsprache ähnlichen Ausgangssprache konnten signifikante Gewinne beobachtet werden.', 'ko': '다원 번역 시스템은 여러 언어를 단일 목표 언어로 번역한다.이러한 여러 출처에서 나온 정보를 사용함으로써 이 시스템들은 정확성이 크게 향상되었다.이러한 시스템을 훈련하기 위해서는 여러 개의 출처와 목표 언어에 평행 텍스트를 가진 자료 라이브러리를 구축할 필요가 있다.그러나 모든 관련 언어의 인공 번역을 제공하기 어려워서 이런 어료 라이브러리는 실천에서 완전하지 않다.본고에서 우리는 다원신경기계번역(NMT)을 이용하여 이러한 불완전한 부분을 채우는 데이터 강화 방법을 제시했다.우리의 실험에서 서로 다른 언어 조합의 결과는 각각 다르지만 목표 언어와 비슷한 원시 언어를 사용할 때 현저한 수익을 관찰했다.', 'id': 'Sistem terjemahan multisumber terjemahan dari berbagai bahasa ke bahasa sasaran tunggal. Dengan menggunakan informasi dari berbagai sumber ini, sistem ini mencapai keuntungan besar dalam akurasi. Untuk melatih sistem-sistem ini, perlu memiliki corpora dengan teks paralel dalam berbagai sumber dan bahasa sasaran. Namun, corpora ini jarang lengkap dalam praktek karena kesulitan menyediakan terjemahan manusia dalam semua bahasa relevan. Dalam kertas ini, kami mengusulkan pendekatan peningkatan data untuk mengisi bagian yang tidak lengkap dengan menggunakan terjemahan mesin saraf multisumber (NMT). Dalam eksperimen kami, hasil berbeda dalam kombinasi bahasa yang berbeda tetapi keuntungan yang signifikan telah diperhatikan ketika menggunakan bahasa sumber yang mirip dengan bahasa sasaran.', 'fa': 'سیستم\u200cهای ترجمه\u200cهای زیادی منبع از زبانهای زیادی به زبان هدف ترجمه می\u200cکند. با استفاده از اطلاعات از این منبع متعدد، این سیستم\u200cها در دقیقا به سود بزرگ رسیده است. برای آموزش این سیستم، لازم است که شرکت با متن متفاوتی در منبع های متعدد و زبان هدف داشته باشد. با این حال، این شرکت کمی در تمرین به دلیل سختی که ترجمه\u200cهای انسان را در تمام زبان\u200cهای مربوط به انجام دادن کامل می\u200cشوند. در این کاغذ، ما پیشنهاد می\u200cکنیم روش افزایش داده\u200cها برای پر کردن چنین قسمت غیر کامل با ترجمه ماشین\u200cهای عصبی\u200cهای متعدد منبع (NMT). در آزمایشات ما، نتیجه\u200cها در ترکیب زبان\u200cهای مختلف متفاوت شدند، ولی در زمان استفاده از زبان منبع شبیه به زبان هدف، پیروزی مهمتری مشاهده شد.', 'sw': 'Mfumo wa utafsiri wa vyanzo vingi unatafsiri kutoka lugha mbalimbali hadi lugha moja kwa lengo. Kwa kutumia taarifa kutoka vyanzo vingi hivi, mifumo hii hupata mafanikio makubwa kwa uhakika. Ili kufundisha mifumo hii, inahitaji kuwa na kampuni yenye maandishi yanayofanana kwa vyanzo vingi na lugha ya lengo. Hata hivyo, makampuni haya ni nadra sana yanakamilika katika mazoea kutokana na vigumu vya kutoa tafsiri za binadamu katika lugha zote zinazohusiana. Katika gazeti hili, tunapendekeza mbinu ya kuongeza taarifa ili kuzijaza sehemu hizo zisizo kamili kwa kutumia tafsiri ya mashine yenye chanzo cha neurali (NMT). Katika majaribio yetu, matokeo yalikuwa tofauti zaidi ya muungano wa lugha tofauti lakini mafanikio makubwa yalionekana pale kwa kutumia lugha ya asili inayofanana na lugha ya lengo.', 'am': 'Multi-source translation systems translate from multiple languages to a single target language. ከዚህም ብዙዎች ምንጮች መረጃ በመጠቀም እነዚህ ሲስተማሮች በጥሩ ትልቅ ትርፍ ያገኛሉ፡፡ እነዚህን ስርዓቶች ለማስተምር፣ ኮርፖርት በተለይ ጽሑፎች እና በተለያዩ ቋንቋዎች ውስጥ ጽሑፍ ማግኘት ያስፈልጋል፡፡ ነገር ግን እነዚህ ኮርፖርት በአካባቢው ቋንቋዎች ሁሉ የሰው ትርጓሜዎችን በመስጠት ግጭት ሲሞሉ በጣም ጥቂት ነው፡፡ በዚህ ካላት፣ እንደነዚህ የሙሉ ክፍሎች ለመሙላት የዳታ አካባቢ ማተርጓሜዎችን (NMT) ለመጠቀም እናስጀምራለን፡፡ በተፈተናችን ውስጥ ፍሬዎቹ በተለየ ቋንቋ ግንኙነት የተለየ ነገር ግን በተለያዩ ቋንቋ ቋንቋ በሚያሳየው ቋንቋ በመጠቀም የኩነቶች ግንኙነት ታየ፡፡', 'sq': 'Sistemet e përkthimit me shumë burime përkthyen nga gjuhë të shumta në një gjuhë të vetme objektive. Duke përdorur informacion nga këto burime të shumta, këto sisteme arrijnë fitime të mëdha në saktësi. Për të trajnuar këto sisteme, është e nevojshme të ketë korpra me tekst paralel në burime të shumta dhe gjuhën objektive. Megjithatë, këto korpra janë rrallë të plota në praktikë për shkak të vështirësisë së ofrimit të përkthimeve njerëzore në të gjitha gjuhët relevante. Në këtë letër, propozojmë një qasje rritjeje të të dhënave për të mbushur pjesë të tilla të pakomplete duke përdorur përkthimin e makinave nervore me shumë burime (NMT). Në eksperimentet tona, rezultatet ndryshuan në lidhje me kombinime të ndryshme gjuhësh por u vëzhguan fitime të rëndësishme kur përdorën një gjuhë burimi të ngjashme me gjuhën objektive.', 'af': "Veelbronne vertaling stelsels vertaling van veelvuldige tale na 'n enkele doel taal. Deur inligting van hierdie veelvuldige bronne te gebruik, word hierdie stelsels groot verskaf in presisiteit bereik. Om hierdie stelsels te trein, is dit nodig om korpora te hê met parallele teks in veelvuldige bronne en die doel taal. Maar hierdie korpora is selfs in praksie volkome vanweë die moeilikheid van die verskaffing van menslike vertalings in al die relevante tale. In hierdie papier voorstel ons 'n data augmentasie toegang om sodanige onvolledige dele te vul met multibronne neurale masjien vertaling (NMT). In ons eksperimente het resultate verskillig oor verskillende taal kombinasies, maar betekende verkrywings was aangesien wanneer 'n bron taal soos die doel taal gebruik word.", 'hy': 'Բազմաաղբյուրների թարգմանման համակարգերը թարգմանվում են բազմալեզուներից մեկ նպատակային լեզու: Այս բազմաթիվ աղբյուրներից ստացված տեղեկատվությունը օգտագործելով, այս համակարգերը հասնում են ճշգրտության մեծ բարձրացումներին: Այս համակարգերի ուսումնասիրելու համար անհրաժեշտ է մարմին ունենալ զուգահեռ տեքստով բազմաթիվ աղբյուրներում և նպատակային լեզուներում: Այնուամենայնիվ, այս կառուցվածքները հազվադեպ են ավարտվում իրականության մեջ, քանի որ դժվարությամբ է մարդկային թարգմանություններ տրամադրել բոլոր հարկավոր լեզուներով: Այս թղթի մեջ մենք առաջարկում ենք տվյալների աճի մոտեցում, որպեսզի լրացնենք այդպիսի անկատարյալ մասեր՝ օգտագործելով բազմաաղբյուր նեյրոնային մեքենայի (NMT) թարգմանումը: Մեր փորձարկումների ընթացքում արդյունքները տարբեր լեզվի համադրությունների մեջ տարբերվում էին, բայց նշանակալի շահույթներ են նկատել, երբ օգտագործվում են նպատակային լեզուն նման աղբյուր լեզու:', 'bn': 'অনেক ভাষা থেকে একটি লক্ষ্য ভাষায় অনুবাদ করা হয়েছে। এই বিভিন্ন সূত্র থেকে তথ্য ব্যবহার করে এই সিস্টেম সঠিকভাবে বিশাল অর্জন পায়। এই সিস্টেম প্রশিক্ষণ করার জন্য কোর্পোরাকে অনেক সূত্র এবং লক্ষ্য ভাষায় প্যারালেল ল লেখা আছে। তবে এই কোর্পোরাগুলো প্রক্রিয়ায় খুব কমই সম্পূর্ণ হয়ে গেছে যার কারণে মানুষের সমস্ত ভাষায় অনুবাদ প্রদান করা কঠিন। এই পত্রিকায় আমরা এই ধরনের অসম্পূর্ণ অংশ পূরণ করার জন্য তথ্য যোগাযোগের প্রস্তাব দিচ্ছি (এনএমটি)। আমাদের পরীক্ষায় ফলাফল ভিন্ন ভাষার সংযোগের বিভিন্ন ভিন্ন ভাষার বিভিন্ন ভিন্ন কিন্তু গুরুত্বপূর্ণ অর্জনের দৃষ', 'az': 'Çoxlu mənbə çeviri sistemləri çoxlu dillərdən tək məqsəd dilinə çevirir. Bu çoxlu mənbələrdən məlumatları istifadə edərək, bu sistemlər dəqiqliklə böyük qənimətlər yetirir. Bu sistemləri təhsil etmək üçün, çoxlu mənbələr və məqsəd dilində paralel metin olan korpora olmalıdır. Ancaq bu korpora, insanların dəyişiklik dillərdə insanların tercümələrini vermək çətinlikləri üzündən çox az tamamlanır. Bu kağızda, çoxlu mənbə nöral maşına çevirməsi (NMT) ilə bu mütləq parçaları doldurmaq üçün məlumatları artırmaq approach təklif edirik. Bizim təcrübələrimizdə sonuçlar müxtəlif dil kombinasyonlarında dəyişdi, amma məqsəd dilinə bənzər mənbə dilini istifadə etdikdə möhkəm qənimətlər göründü.', 'ca': "Els sistemes de traducció de múltiples llengües a un únic llenguatge. Utilitzant informació d'aquestes múltiples fonts, aquests sistemes aconsegueixen grans guanys en la precisió. Per formar aquests sistemes, és necessari tenir corpora amb text paral·lel en múltiples fonts i el llenguatge alvo. No obstant això, aquests corpores rarament són complets a la pràctica degut a la dificultat de proporcionar traduccions humanes en totes les llengües pertinents. En aquest paper, proposem un enfocament d'augment de dades per omplir parts tan incompletes fent servir la traducció de màquines neurals de múltiples fonts (NMT). En els nostres experiments, els resultats van variar en diferents combinacions de llenguatges però es van observar avanços significatius quan es va utilitzar un llenguatge de fonts similar al llenguatge d'objectiu.", 'cs': 'Více zdrojových překladatelských systémů překládají z více jazyků do jednoho cílového jazyka. Použitím informací z těchto více zdrojů dosahují tyto systémy velkého zvýšení přesnosti. Pro trénink těchto systémů je nutné mít korpusy s paralelním textem ve více zdrojích a cílovém jazyce. Nicméně, tyto korpusy jsou v praxi zřídka kompletní kvůli obtížnosti poskytovat lidské překlady ve všech relevantních jazycích. V tomto článku navrhujeme přístup rozšíření dat k vyplnění těchto neúplných částí pomocí multizdrojového neuronového strojového překladu (NMT). V našich experimentech se výsledky lišily v různých jazykových kombinacích, ale významné zisky byly pozorovány při použití zdrojového jazyka podobného cílovému jazyku.', 'tr': '횉oklu 챌e힊me terjime sistemleri birn채챌e dilden bir maksady diline terjime edir. Bu birn채챌e 챌e힊me 챌e힊melerden maglumat ulanarak, bu sistemler dogry gazan첵arlar. Bu sistemalary 철wrenmek 체챌in korpora birn채챌e 챌e힊melerde we maksady dilde parallel metin bolmaly. 횦철ne bu korporada adamlary흫 terjimelerini 채hli m철h체m dillerde bermek kyn kyn챌ylygyna seb채bi praktika edip otyr첵arlar. Bu kagyzda, biz bu 첵agda첵da 첵agda첵 b철l체mleri doldurmak 체챌in bir maglumat 첵eti힊dirmegi teklip edip otyr첵arys. Bizi흫 deneylerimizde, netijelerimiz d체rli dil bilen 체첵tge힊iril첵채r 첵철ne maksady diline me흫ze힊 bir 챌e힊me dilini ulananda m철h체m gazan챌lar g철r체ndi.', 'et': 'Mitme allika tõlkesüsteemid tõlgivad mitmest keelest ühte sihtkeelde. Nendest mitmest allikast pärit teavet kasutades saavutavad need süsteemid suure täpsuse. Nende süsteemide koolitamiseks on vaja paralleelse tekstiga korpuseid mitmes allikas ja sihtkeeles. Kuid need korpused on praktikas harva täielikud, sest inimtõlgete pakkumine kõikidesse asjakohastesse keeltesse on raske. Käesolevas töös pakume välja andmete suurendamise lähenemisviisi selliste mittetäielike osade täitmiseks, kasutades mitmeallilist neuraalset masintõlket (NMT). Meie eksperimentides varieerusid tulemused erinevate keelekombinatsioonide vahel, kuid märkimisväärset kasu täheldati sihtkeelega sarnase lähtekeele kasutamisel.', 'fi': 'Monil채hdek채채nn철sj채rjestelm채t k채채nt채v채t useista kielist채 yhdelle kohdekielelle. K채ytt채m채ll채 tietoa n채ist채 monista l채hteist채 n채m채 j채rjestelm채t saavuttavat suuria tarkkuutta. N채iden j채rjestelmien kouluttamiseksi tarvitaan korpusia, joissa on rinnakkaisteksti useissa l채hteiss채 ja kohdekielell채. K채yt채nn철ss채 n채m채 korpuset ovat kuitenkin harvoin t채ydellisi채, koska ihmisille on vaikea tarjota k채채nn철ksi채 kaikilla asiaankuuluvilla kielill채. T채ss채 ty철ss채 ehdotamme datan lis채채mist채 t채llaisten ep채t채ydellisten osien t채ytt채miseksi k채ytt채m채ll채 monil채hdeist채 neurokonek채채nn철st채 (NMT). Kokeissamme tulokset vaihtelivat eri kieliyhdistelmiss채, mutta merkitt채vi채 hy철tyj채 havaittiin kohdekielen kaltaista l채hdekielt채 k채ytett채ess채.', 'bs': 'Višeizvorni sustavi prevoda iz višestrukih jezika na jedan ciljni jezik. Koristeći informacije iz ovih višestrukih izvora, ovi sistemi ostvaruju veliku pobjedu tačnosti. Da bi obučili te sisteme, potrebno je imati tijelo sa paralelnim tekstom u višestrukim izvorima i ciljnim jezikom. Međutim, ove korporacije su rijetko potpune u praksi zbog teškoće pružanja ljudskih prevoda na svim relevantnim jezicima. U ovom papiru predlažemo povećanje pristupa podataka kako bi napunili takve nepotpune dijelove korištenjem multiizvornog prevoda neuralnih strojeva (NMT). U našim eksperimentima, rezultati su različiti preko različitih jezičkih kombinacija, ali značajne dobitke su primijećene kada su koristili izvorni jezik sličan ciljnom jeziku.', 'jv': 'Tulung sistem sing akeh-bukun terjamahan kanggo saben bangsa sampeyan kanggo saben tarjamahan. Ngawe ngubah informasi sing ngenggo akèh dumateng iki, sistem iki dadi ono akeh apik dhéwé, nik awak dhéwé kuwi diapakan. Ngawe luwih sistem iki, kudu kelakon sampeyan kanggo teks kang sampeyan banget kanggo sekang tarjamahan lan banget. Nanging, kawula-kawula karo perusahaan iki dadi akeh peugot nang praksi kaya nguasai kanggo nggawe tarjamahan ning wong liyane Nang pebuk iki, kita supoyo biasane sampeyan data nyang mulai perusahaan sing sampeyan karo pirang-sampeyan karo penting multi-source Neral (NMT). Nang ujaran-ujaran anyar, dadi kapan mulai gak bener neng sampeyan ingkang dipun', 'ha': "@ info: whatsthis Ga ku yi amfani da information daga wannan sources masu yawa, waɗannan na'ura suna sãmun kashi mai girma a taƙaita. To, don ka yi amfani da wannan na'ura, sai ana buƙata koma da matsayi mai daidaita cikin wasu sources da aka yi amfani da shi. A lokacin da haka, waɗannan makampuni yana kamfata cikin aikin da kamaki, saboda haka kuma ma'abuta ya bãyar da fassarar mutane cikin duk harshe masu husũma. Daga wannan takardan, Munã buɗa wata hanyor ƙaramako da data dõmin a cika wannan abu ba'a koma ba da amfani da fassarar zane-zane na ƙarƙashin neural (NMT). Daga jarrabõyinmu, matsalar sun sãɓã wa jumuiya masu cikin harshen daban, kuma amma an gane mafiya girma a lokacin da za'a yi amfani da wata harshe na source kamar harshen wanda ya yi amfani da shi.", 'sk': 'Prevajalski sistemi več virov prevajajo iz več jezikov v en ciljni jezik. Z uporabo informacij iz teh več virov ti sistemi dosegajo veliko večjo natančnost. Za usposabljanje teh sistemov je potrebno imeti korpuse z vzporednim besedilom v več virih in ciljnem jeziku. Vendar pa so ti korpusi v praksi redko popolni zaradi težav pri zagotavljanju človeških prevodov v vse ustrezne jezike. V prispevku predlagamo pristop povečanja podatkov za polnjenje takšnih nepopolnih delov z uporabo več-viranega nevronskega strojnega prevajanja (NMT). V naših eksperimentih so se rezultati razlikovali v različnih jezikovnih kombinacijah, vendar so opazili pomembne koristi pri uporabi izvornega jezika, podobnega ciljnemu jeziku.', 'he': 'מערכות תרגום ממקורים רבים מתרגמות משפות רבות לשפה היחידה. על ידי השימוש במידע ממקורים רבים אלה, המערכות האלה משיגות רווחות גדולות בדיוק. כדי לאמן את המערכות האלה, צריך להיות גופרה עם טקסט מקביל במקורים רבים ושפה המטרה. בכל אופן, הקופורות האלה נדירות מושלמות בפרקטיקה בגלל הקשה לספק תרגומות אנושיות בכל השפות הרלוונטיות. In this paper, we propose a data augmentation approach to fill such incomplete parts using multi-source neural machine translation (NMT).  בניסויים שלנו, התוצאות השתנו על פי שילובים שפותיים שונים, אך התבוננות היתרונות משמעותיות כאשר השתמשו בשפה המקורית דומה לשפה המטרה.', 'bo': 'སྐད་རིགས་མང་ཙམ་འབྱུང་བའི་ཡིག་ཆ་ལ་སྐད་རིགས་གཅིག་མཚུངས་ཡིན་པ ཐོག མ་ལག་འདི་དག་གི་སྣེ་ཚོགས་གཅིག་མཐུན་བཟོ་བྱེད་དགོས་པ་ཡིན་ན། ཡིན་ནའང་། སྒེར་གྱི་རྩིས་མོ་འདི་དག་གིས་ལག་ལེན་འཐབ་པ་ལས་ཀར་ཆེ་བ་ཡིན། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཡིག ང་ཚོའི་བརྟག་ཞིབ་ཕྱོགས་ནང་དུ་སྐད་རིགས་གཅིག་མཐུན་པར་མཐུན་འགྱུར་བ་ཡིན་ནའང་། འབྱུང་ཁུངས་སྐད་ཡིག'}
{'en': 'The USTC-NEL Speech Translation system at IWSLT 2018 USTC - NEL  Speech Translation system at  IWSLT  2018', 'ar': 'نظام ترجمة الكلام USTC-NEL في IWSLT 2018', 'fr': "Le système de traduction vocale USTC-NEL à l'IWSLT 2018", 'pt': 'O sistema de tradução de fala USTC-NEL no IWSLT 2018', 'es': 'El sistema de traducción de voz USTC-NEL en IWSLT 2018', 'hi': 'IWSLT 2018 में USTC-NEL स्पीच ट्रांसलेशन सिस्टम', 'zh': '2018年IWSLTUSTC-NEL语音译系统', 'ja': 'IWSLT 2018のUSTC - NELスピーチ翻訳システム', 'ru': 'Система перевода речи USTC-NEL на IWSLT 2018', 'ga': 'Córas Aistriúcháin Urlabhra USTC-NEL ag IWSLT 2018', 'el': 'Το σύστημα μετάφρασης ομιλίας USTC-NEL στο IWSLT 2018', 'ka': 'USTC- NEL სიტყვების შეცვლის სისტემა IWSLT 2018-ში', 'hu': 'Az USTC-NEL beszédfordító rendszer az IWSLT 2018-on', 'lt': 'USTC-NEL kalbos vertimo sistema IWSLT 2018 m.', 'it': 'Il sistema di traduzione vocale USTC-NEL a IWSLT 2018', 'kk': 'USTC- NEL сөз аудару жүйесі IWSLT 2018 жылы', 'ms': 'The USTC-NEL Speech Translation system at IWSLT 2018', 'ml': 'IWSLT 2018-ലെ USTC-NEL സ്പീക് പരിഭാഷ സിസ്റ്റം', 'mn': 'USTC-NEL ярианы хөгжлийн систем IWSLT 2018 онд', 'no': 'USTC- NEL taleomsetjingssystemet på IWSLT 2018', 'pl': 'System tłumaczenia mowy USTC-NEL w IWSLT 2018', 'ro': 'Sistemul USTC-NEL de traducere a vorbirii la IWSLT 2018', 'sr': 'USTC-NEL govorni prevodni sistem na IWSLT 2018.', 'si': 'USTC- NEL කතා පද්ධතිය IWSLT 2018 වල', 'so': 'USTC-NEL Speech System of Translation at IWSLT 2018', 'sv': 'USTC-NEL Speech Translation System på IWSLT 2018', 'ta': 'IWSLT 2018 ல் USTC- NEL பேச்சு மொழிபெயர்ப்பு அமைப்பு', 'ur': 'USTC-NEL Speech Translation System at IWSLT 2018', 'mk': 'USTC-NEL преведувачки систем на IWSLT 2018', 'mt': 'Is-sistema tat-traduzzjoni tal-kelma USTC-NEL fl-IWSLT 2018', 'vi': 'Hệ thống dịch ngôn ngữ USTC-NEL tại IWSLT 208', 'uz': 'Name', 'bg': 'Системата за превод на реч на УСТЦ-НЕЛ в ИВСЛТ 2018', 'nl': 'Het USTC-NEL Spraakvertaalsysteem op IWSLT 2018', 'hr': 'USTC-NEL govorni sustav prevoda na IWSLT 2018.', 'da': 'USTC-NEL Speech Translation systemet på IWSLT 2018', 'ko': '2018년 IWSLT의 USTC-NEL 음성 번역 시스템', 'sw': 'Mfumo wa Tafsiri wa Utafsiri wa USTC-NEL katika IWSLT 2018', 'de': 'Das USTC-NEL SprachĂ¼bersetzungssystem auf der IWSLT 2018', 'id': 'The USTC-NEL Speech Translation system at IWSLT 2018', 'tr': 'USTC-NEL Sözler terjime sistemi IWSLT 2018-de', 'sq': 'Sistemi i përkthimit të fjalëve USTC-NEL në IWSLT 2018', 'am': 'The USTC-NEL Speech Translation system at IWSLT 2018', 'fa': 'سیستم ترجمه سخنرانی USTC-NEL در IWSLT 2018', 'hy': 'USTN-Net խոսքի թարգմանման համակարգը IwSLT 2018 թվականին', 'az': 'USTC-NEL Söz Çeviri Sistemi IWSLT 2018-də', 'bs': 'USTC-NEL govorni sustav prevoda na IWSLT 2018.', 'af': 'Die USTC- NEL Spraak Vertaling stelsel op IWSLT 2018', 'cs': 'Systém překladu řeči USTC-NEL na IWSLT 2018', 'fi': 'USTC-NEL puhekäännösjärjestelmä IWSLT 2018 -messuilla', 'et': 'USTC-NEL kõne tõlke süsteem IWSLT 2018', 'bn': 'The USTC-NEL Speech Translation system at IWSLT 2018', 'ca': 'The USTC-NEL Speech Translation system at IWSLT 2018', 'jv': 'Sistem Panjenengan UST-NeL Terjamahan nang IWSLT 2013', 'he': 'מערכת התרגום דיבורים USTC-NEL ב IWSLT 2018', 'ha': '@ item license', 'sk': 'Sistem prevajanja govora USTC-NEL na IWSLT 2018', 'bo': 'USTC-NEL Speech Translation system at IWSLT 2018'}
{'en': 'This paper describes the USTC-NEL (short for National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china) system to the speech translation task of the IWSLT Evaluation 2018. The system is a conventional  pipeline system  which contains 3 modules :  speech recognition ,  post-processing  and  machine translation . We train a group of hybrid-HMM models for our  speech recognition , and for  machine translation  we train transformer based neural machine translation models with speech recognition output style text as input. Experiments conducted on the IWSLT 2018 task indicate that, compared to baseline system from KIT, our  system  achieved 14.9 BLEU improvement.', 'ar': 'تصف هذه الورقة نظام USTC-NEL (باختصار "المختبر الهندسي الوطني لمعالجة الكلام واللغة بجامعة العلوم والتكنولوجيا في الصين") لمهمة ترجمة الكلام في تقييم IWSLT 2018. النظام عبارة عن نظام خطوط أنابيب تقليدي يحتوي على 3 وحدات: التعرف على الكلام والمعالجة اللاحقة والترجمة الآلية. نقوم بتدريب مجموعة من نماذج HMM المختلطة للتعرف على الكلام لدينا ، وللترجمة الآلية ، نقوم بتدريب نماذج الترجمة الآلية العصبية القائمة على المحولات مع نص نمط إخراج التعرف على الكلام كمدخل. تشير التجارب التي تم إجراؤها على مهمة IWSLT 2018 إلى أن نظامنا حقق 14.9 تحسينًا لـ BLEU مقارنة بالنظام الأساسي من KIT.', 'fr': "Cet article décrit le système USTC-NEL (abréviation de «\xa0National Engineering Laboratory for Speech and Language Information Processing University of Science and Technology of China\xa0») pour la tâche de traduction vocale de l'IWSLT Evaluation 2018. Le système est un système de pipeline classique qui contient 3 modules\xa0: reconnaissance vocale, post-traitement et traduction automatique. Nous formons un groupe de modèles HMM hybrides pour notre reconnaissance vocale, et pour la traduction automatique, nous entraînons des modèles de traduction automatique neuronale basés sur des transformateurs avec un texte de style de sortie de reconnaissance vocale comme entrée. Les expériences menées sur la tâche IWSLT 2018 indiquent que, par rapport au système de base du KIT, notre système a obtenu une amélioration de 14,9 BLEU.", 'pt': 'Este artigo descreve o sistema USTC-NEL (abreviação de "National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china") para a tarefa de tradução de fala da Avaliação IWSLT 2018. O sistema é um sistema de pipeline convencional que contém 3 módulos: reconhecimento de voz, pós-processamento e tradução automática. Treinamos um grupo de modelos HMM híbridos para nosso reconhecimento de fala e, para tradução automática, treinamos modelos de tradução automática neural baseados em transformadores com texto de estilo de saída de reconhecimento de fala como entrada. Experimentos realizados na tarefa IWSLT 2018 indicam que, em comparação com o sistema de linha de base do KIT, nosso sistema alcançou uma melhoria de 14,9 BLEU.', 'es': 'Este artículo describe el sistema USTC-NEL (abreviatura de «Laboratorio Nacional de Ingeniería para el Procesamiento de la Información del Habla y el Lenguaje de la Universidad de Ciencia y Tecnología de China») para la tarea de traducción de voz de la Evaluación IWSLT 2018. El sistema es un sistema de canalización convencional que contiene 3 módulos: reconocimiento de voz, posprocesamiento y traducción automática. Entrenamos un grupo de modelos HMM híbridos para nuestro reconocimiento de voz, y para la traducción automática entrenamos modelos de traducción automática neuronal basados en transformadores con texto de estilo de salida de reconocimiento de voz como entrada. Los experimentos realizados en la tarea IWSLT 2018 indican que, en comparación con el sistema de referencia del KIT, nuestro sistema logró una mejora de 14,9 BLEU.', 'ja': '本稿では、IWSLT評価2018の音声翻訳タスクに対するUSTC - NEL （中国科学技術大学音声言語情報処理国立工学研究所の略）システムについて説明する。このシステムは、音声認識、後処理、機械翻訳の3つのモジュールを含む従来のパイプラインシステムです。私たちは、音声認識のためのハイブリッド- HMMモデルのグループをトレーニングし、機械翻訳のために、音声認識出力スタイルテキストを入力として、変圧器ベースのニューラル機械翻訳モデルをトレーニングします。IWSLT 2018タスクで実施された実験では、KITからのベースラインシステムと比較して、当社のシステムは14.9 BLEU改善を達成したことが示されています。', 'ru': 'В этой статье описывается система USTC-NEL (сокращение от «Национальная инженерная лаборатория для обработки речи и языковой информации Университета науки и техники Китая») для задачи перевода речи IWSLT Evaluation 2018. Система представляет собой традиционную трубопроводную систему, которая содержит 3 модуля: распознавание речи, постобработка и машинный перевод. Мы обучаем группу гибридных моделей HMM для нашего распознавания речи, а для машинного перевода мы обучаем основанные на трансформаторах модели нейронного машинного перевода с текстом стиля речевого распознавания в качестве входных данных. Эксперименты, проведенные по задаче IWSLT 2018, показывают, что по сравнению с базовой системой из KIT, наша система достигла улучшения 14,9 BLEU.', 'zh': '本文引USTC-NEL("中国科学技术大学语音与语言信息处理国工实验室")系统对2018年IWSLT评语译事。 统者,道之统也,含3模块:语音别,后处理机器翻译。 吾等习合 HMM 模形于语音,于机器翻译,以语音输式文本为输入以练转换器神经机器翻译模形。 IWSLT 2018事之实验明,比于KIT之基线统,则吾道14.9 BLEU改矣。', 'hi': 'यह पेपर यूएसटीसी-एनईएल ("चीन के विज्ञान और प्रौद्योगिकी के भाषण और भाषा सूचना प्रसंस्करण विश्वविद्यालय के लिए राष्ट्रीय इंजीनियरिंग प्रयोगशाला" के लिए संक्षिप्त) प्रणाली का वर्णन करता है, जो आईडब्ल्यूएसएलटी मूल्यांकन 2018 के भाषण अनुवाद कार्य के लिए है। सिस्टम एक पारंपरिक पाइपलाइन प्रणाली है जिसमें 3 मॉड्यूल होते हैं: भाषण मान्यता, पोस्ट-प्रोसेसिंग और मशीन अनुवाद। हम अपने भाषण मान्यता के लिए हाइब्रिड-एचएमएम मॉडल के एक समूह को प्रशिक्षित करते हैं, और मशीन अनुवाद के लिए हम इनपुट के रूप में भाषण मान्यता आउटपुट शैली पाठ के साथ ट्रांसफॉर्मर आधारित तंत्रिका मशीन अनुवाद मॉडल को प्रशिक्षित करते हैं। IWSLT 2018 कार्य पर किए गए प्रयोगों से संकेत मिलता है कि, KIT से बेसलाइन सिस्टम की तुलना में, हमारे सिस्टम ने 14.9 BLEU सुधार हासिल किया।', 'ga': 'Déanann an páipéar seo cur síos ar an gcóras USTC-NEL (gearr don chóras “An tSaotharlann Náisiúnta Innealtóireachta um Phróiseáil Faisnéise Urlabhra agus Teanga Ollscoil na heolaíochta agus na teicneolaíochta poircealláin”) don tasc aistriúcháin cainte i Meastóireacht IWSLT 2018. Is córas píblíne traidisiúnta é an córas ina bhfuil 3 mhodúl: aithint cainte, iar-phróiseáil agus aistriúchán meaisín. Cuirimid oiliúint ar ghrúpa samhlacha hibrideach-HMM le haghaidh ár n-aitheantas cainte, agus le haghaidh aistriúcháin mheaisín cuirimid oiliúint ar mhúnlaí néar-aistriúcháin atá bunaithe ar chlaochladán le téacs stíl aschuir aitheantais cainte mar ionchur. Léiríonn turgnaimh a rinneadh ar thasc IWSLT 2018, i gcomparáid leis an gcóras bunlíne ó KIT, gur bhain ár gcóras 14.9 feabhsú BLEU amach.', 'el': 'Η παρούσα εργασία περιγράφει το σύστημα στο έργο μετάφρασης ομιλίας της αξιολόγησης 2018. Το σύστημα είναι ένα συμβατικό σύστημα αγωγών που περιέχει τρεις ενότητες: αναγνώριση ομιλίας, μετεπεξεργασία και μηχανική μετάφραση. Εκπαιδεύουμε μια ομάδα υβριδικών μοντέλων για την αναγνώριση ομιλίας μας, και για τη μηχανική μετάφραση εκπαιδεύουμε μοντέλα νευρωνικής μηχανικής μετάφρασης βασισμένα σε μετασχηματιστές με κείμενο ύφους εξόδου αναγνώρισης ομιλίας ως εισαγωγή. Τα πειράματα που διεξήχθησαν στο έργο δείχνουν ότι, σε σύγκριση με το σύστημα βάσης του KIT, το σύστημά μας πέτυχε βελτίωση 14.9.', 'hu': 'Ez a tanulmány bemutatja az USTC-NEL (a kínai Tudományos és Technológiai Egyetem Nemzeti Mérnöki Laboratóriuma a beszéd- és Nyelvinformációfeldolgozási Egyetem rövidítése) rendszerét az IWSLT Értékelés 2018 beszédfordítási feladataira. A rendszer egy hagyományos csővezeték rendszer, amely 3 modult tartalmaz: beszédfelismerés, utófeldolgozás és gépi fordítás. Hibrid-HMM modellek csoportját képezzük a beszédfelismeréshez, a gépi fordításhoz pedig transzformátor alapú neurális gépi fordítási modelleket képezünk beszédfelismerő kimeneti stílusú szöveggel. Az IWSLT 2018 feladatával végzett kísérletek azt mutatják, hogy a KIT alapvető rendszeréhez képest rendszerünk 14,9 BLEU javulást ért el.', 'ka': 'ამ წიგნის შესახებ USTC-NEL სისტემის სისტემის შესახებ (ჩინეთის მეცნიერო და ტექნოლოგიის განსახებების ნაციონალური ინგენერიური ლაბორატორია) სისტემის შესახებ IWSLT განსახებების 2018 წიგნის გან Name ჩვენ ჰიბრიდი-HMM მოდელების ჯგუფის განვიცნობისთვის და მაქინის განვიცნობისთვის ჩვენ განვიცნობისთვის შევცნობით ტრანფორმაციის განვიცნობისთვის ნეიროლა მაქინის განვიცნობის გამოცდილება, რომელიც IWSLT 2018-ის დავალებაში გავაკეთებულია, ჩვენი სისტემა 14,9 BLEU-ის გაუკეთებას გავაკეთებულია.', 'it': "Questo articolo descrive il sistema USTC-NEL (abbreviazione di 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') per il compito di traduzione vocale della valutazione IWSLT 2018. Il sistema è un sistema di pipeline convenzionale che contiene 3 moduli: riconoscimento vocale, post-elaborazione e traduzione automatica. Formiamo un gruppo di modelli ibridi-HMM per il nostro riconoscimento vocale, e per la traduzione automatica formiamo modelli di traduzione automatica neurale basati su trasformatori con testo in stile di output di riconoscimento vocale come input. Gli esperimenti condotti sul task IWSLT 2018 indicano che, rispetto al sistema base del KIT, il nostro sistema ha ottenuto un miglioramento di 14,9 BLEU.", 'mk': 'Овој весник го опишува USTC-NEL (кратко за „Националната инженерска лабораторија за обработување на информации за говор и јазик на универзитетот за наука и технологија на кинеската) на задачата за превод на говорот на IWSLT Evaluation 2018. Системот е конвенционален гасоводски систем кој содржи 3 модули: препознавање на говорот, постобработување и машински превод. Тренираме група хибриди-ХММ модели за нашето препознавање на говорот, и за машински превод тренираме модели за превод на нервни машини базирани на трансформаторите со текст на стилот на препознавање на говорот како влез. Експериментите спроведени во врска со задачата на ИВСЛТ 2018 покажуваат дека, во споредба со основниот систем од КИТ, нашиот систем постигна 14,9 подобрување на БЛЕУ.', 'lt': 'Šiame dokumente apibūdinama USTC-NEL sistema (trumpa „Nacionalinė kalbos ir kalbos informacijos apdorojimo laboratorija, Kinijos mokslo ir technologijų universitetas“) pagal IWSLT vertinimo 2018 m. kalbos vertimo užduotį. Sistema yra įprastinė vamzdynų sistema, kurioje yra 3 moduliai: kalbos atpažinimas, apdorojimas ir mašinų vertimas. Mes mokome hibridinių HMM modelių grupę mūsų kalbos atpažinimui, o mašinų vertimui mes mokome transformatoriumi pagrįstus nervinių mašinų vertimo modelius su kalbos atpažinimo išėjimo stiliu tekstu kaip įvestis. 2018 m. IWSLT užduoties tyrimai rodo, kad, palyginti su pradine KIT sistema, mūsų sistema pasiekė 14,9 BLEU patobulinimų.', 'ml': 'ഈ പത്രത്തില്\u200d USTC-NEL (നാഷണല്\u200d എഞ്ചിനീയറിങ്ങ് ലാബ്രറിയില്\u200dനിന്നും ഭാഷ വിവരങ്ങളുടെ വിവരങ്ങള്\u200d ശാസ്ത്രജ്ഞാനവും സാങ്കേതികവിദ്യ യ യൂണിസ്റ്റിയിലേക് സിസ്റ്റത്തില്\u200d 3 ഘടകങ്ങളുള്ള സാധാരണ പൈപ്പെലൈന്\u200d സിസ്റ്റമാണു്: സംസാരം തിരിച്ചറിയുന്നതു്, പിന്നീട് പ്രവര്\u200d ഞങ്ങളുടെ സംസാരം തിരിച്ചറിയാനുള്ള ഹൈബ്രിഡ്-എംഎം മോഡലുകളെ ഞങ്ങള്\u200d പരിശീലിപ്പിക്കുന്നു. മെഷിന്\u200d പരിഭാഷകള്\u200dക്കും ഞങ്ങള്\u200d സംസാരിക്കുന് IWSLT 2018 ജോലിയില്\u200d നടത്തിയ പരീക്ഷണങ്ങള്\u200d തെളിയിക്കുന്നു, കിടിയില്\u200d നിന്നും അടിസ്ഥാന സിസ്റ്റമില്\u200d നിന്നും താല്\u200dക്കാലികമായി', 'ms': "Kertas ini menggambarkan sistem USTC-NEL (pendek untuk 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of China') ke tugas terjemahan ucapan Evaluation IWSLT 2018. Sistem adalah sistem saluran paip konvensional yang mengandungi 3 modul: pengenalan ucapan, pos-proses dan terjemahan mesin. Kami melatih kumpulan model HMM-hibrid untuk pengenalan ucapan kami, dan untuk terjemahan mesin kami melatih model terjemahan mesin saraf berasaskan pengubah dengan teks gaya pengenalan ucapan sebagai input. Eksperimen yang dilakukan pada tugas IWSLT 2018 menunjukkan bahawa, dibandingkan dengan sistem asas dari KIT, sistem kita mencapai 14.9 peningkatan BLEU.", 'mt': 'Dan id-dokument jiddeskrivi s-sistema USTC-NEL (qasira għal "Laboratorju Nazzjonali tal-Inġinerija għall-Università tal-IWSLT tal-IWSLT tal-IWSLT tal-IWSLT għall-IWSLT tal-IWSLT tal-IWSLT tal-IWSLT tal-IWSLT tal-IWSLT tal-IWSLT tal-2018. The system is a conventional pipeline system which contains 3 modules: speech recognition, post-processing and machine translation.  Aħna nħarrġu grupp ta’ mudelli ibridi-HMM għar-rikonoxximent tad-diskors tagħna, u għat-traduzzjoni tal-magni a ħna nħarrġu mudelli ta’ traduzzjoni tal-magni newrali bbażati fuq it-trasformatur b’test tal-istil ta’ ħruġ tar-rikonoxximent tad L-esperimenti mwettqa fuq il-kompitu tal-IWSLT 2018 jindikaw li, meta mqabbla mas-sistema bażi mill-KIT, is-sistema tagħna kisbet titjib ta’ 14.9 BLEU.', 'mn': 'Энэ цаас нь "Хятад шинжлэх ухаан болон технологийн Инженерчлэлийн лабораторийн жижиг хэлбэрийн Инженерчлэлийн Лабораторийг" 2018 оны IWSLT Evaluation-ын илтгэл хөрөнгө оруулах үйл ажиллагаанд USTC-NEL-г тайлбарладаг. Энэ систем бол 3 модуль агуулдаг энгийн хоолойн систем: илтгэл таних, дараа үйлдвэрлэх, машины хөрөнгө оруулалт. Бид хибрид-HMM загваруудыг илтгэл танихын тулд суралцаж, машины хөрөнгө оруулахын тулд мэдрэлийн машины хөрөнгө оруулах загваруудыг илтгэл танихын арга хэлбэрээр оруулсан. IWSLT 2018 даалгаварын туршилтын туршилт нь KIT-ын суурь шугамын системтэй харьцуулахад бидний систем 14.9 БЛЕУ-ын сайжруулалт гарч ирсэн.', 'pl': 'Niniejszy artykuł opisuje system USTC-NEL (skrót od "National Engineering Laboratory for Speech and Language Information Processing University of Science and Technology of Chiny") do zadania tłumaczenia mowy w ramach oceny IWSLT 2018. System jest konwencjonalnym systemem rurociągów, który zawiera trzy moduły: rozpoznawanie mowy, przetwarzanie i tłumaczenie maszynowe. Szkolimy grupę hybrydowych modeli HMM do rozpoznawania mowy, a do tłumaczenia maszynowego trenujemy neuronowe modele tłumaczeń maszynowych oparte na transformatorach z tekstem wyjściowym w stylu rozpoznawania mowy jako wejście. Eksperymenty przeprowadzone na zadaniu IWSLT 2018 wskazują, że w porównaniu z systemem bazowym KIT nasz system osiągnął poprawę 14.9 BLEU.', 'kk': 'Бұл қағаз USTC- NEL (2018 жылдың IWSLT оқиғасының сөйлеу және тіл мәліметі процессорының ғылым мен технологиялық университетінің ұлттық инженерлік лабораториясы үшін қысқартылады). Жүйелік - 3 модульдер бар кәдімгі конвейер жүйесі: сөзді анықтау, өткізу кейін және машинаның аударуы. Біз сөйлеуді анықтау үшін гибрид- HMM үлгілерін ұстап береміз. Мысалы аудару үшін аудару үлгілеріне негізделген невралдық машинаны аудару үлгілерін сөйлеуді анықтау стилінің мәтіні келтіру IWSLT 2018 тапсырмасындағы тәжірибелер KIT-ден негізгі жүйесіне салыстырып, жүйеміздің 14,9 BLEU жақсартуын жетті.', 'no': 'Denne papiret beskriver USTC-NEL (kort for « National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china ») systemet til taleomsetjinga i IWSLT Evaluation 2018. Systemet er ein konvensjonell røyringssystem som inneheld 3 modular: talegjenkjenning, post- handsaming og maskinsomsetjing. Vi treng ein gruppe hybrid- HMM- modeller for tale vårt gjenkjenning, og for maskineomsetjing treng vi transformeringsmodeller basert på neuralmaskineomsetjingar med tekst for utgangsstil tale som inndata. Eksperiment gjennomført på oppgåva IWSLT 2018 tyder på at, samanlikning med baselinjesystemet frå KIT, har vårt systemet oppnådd 14,9 BLEU-forbetringa.', 'ro': "Această lucrare descrie sistemul USTC-NEL (prescurtarea pentru 'Laboratorul Național de Inginerie pentru Procesarea Informațiilor Vorbirii și Limbii Universitatea de Știință și Tehnologie din China') pentru sarcina de traducere a vorbirii din cadrul IWSLT Evaluare 2018. Sistemul este un sistem convențional de conducte care conține 3 module: recunoaștere vocală, post-procesare și traducere automată. Instruim un grup de modele hibrid-HMM pentru recunoașterea vorbirii noastre, iar pentru traducerea automată instruim modele de traducere automată neurală bazate pe transformatoare cu text în stil de ieșire de recunoaștere vocală ca intrare. Experimentele efectuate pe sarcina IWSLT 2018 indică faptul că, în comparație cu sistemul de bază din KIT, sistemul nostru a obținut o îmbunătățire de 14,9 BLEU.", 'sr': "Ovaj papir opisuje USTC-NEL (kratak za 'Nacionalnu inženjersku laboratoriju za obrađivanje govora i jezičkih informacija Univerziteta nauke i tehnologije Kine') sistem za prevod govora u procjeni IWSLT 2018. godine. Sistem je konvencionalni sistem cijevi koji sadrži 3 modula: priznanje govora, postprocessiranje i prevod mašine. Treniramo grupu hibridnih HMM modela za prepoznavanje govora, i za prevod mašine treniramo modele prevoda neuralnih mašina na osnovu transformacije sa tekstom stila prepoznavanja govora kao input. Eksperimenti provedeni na zadatku IWSLT 2018 ukazuju na to da je u usporedbi sa početnim sistemom KIT naš sistem postigao poboljšanje BLEU 14,9.", 'si': 'මේ පත්තුව USTC-NEL (ජාතික ඉන්ජිනරිකාරීය සංවිධානය සහ භාෂා තොරතුරු සංවිධානය සහ චිනා තොරතුරු විද්\u200dයාප්\u200dරධානය සහ ප්\u200dරවිධ පද්ධතිය සාමාන්\u200dය පායිප්ලායින් පද්ධතියක්, මොඩියුල් 3ක් තියෙන්නේ: කතා පරීක්ෂණය, පස්සේ ප්\u200dරක්\u200dරි අපි හයිබ්\u200dරිඩ්-HMM මෝඩේල්ස් කණ්ඩායම් කණ්ඩායමක් පුළුවන් වෙනුවෙන්, ඒ වගේම මැෂින් වාර්තාවක් වෙනුවෙන් අපි පරිවර් IWSLT 2018 ක්\u200dරියාවේ පරීක්ෂණය පෙන්වන්න පුළුවන් වෙනවා කියලා, KIT වලින් පද්ධතියේ පද්ධතියෙන් පරීක්ෂණයෙන් ප්\u200dරවේශන', 'so': "Kanu waa qoraalka lagu qoraa USTC-NEL (short for 'National Engineering Laboratory for Speech and Language Information Processing University of Science and Technical of China') system for the translation of speech work of the IWSLT evaluation 2018. Isticmaalku waa nidaam dabeecada ah oo ku jira 3 modules: aqoonsashada hadalka, baaraandegista kadib iyo turjumidda machine. Waxaynu ku tababarinnaa koox ka mid ah hybrid-HMM tusaalayaasha aqoonsashada hadalkayaga, waxaana u tababarinnaa turjumidda machine-based modellada turjumidda neurada ah oo ku qoran qoraalka aqoonsashada muusikada dhamaanka ee hadalka sida input. Imtixaanka IWSLT 2018 shaqo waxay muujinaysaa in, barbardhig nidaamka hoose ee KIT, nidaamkayaga waxay gaadhay 14.9 BLEU beddelan.", 'sv': "Denna uppsats beskriver USTC-NEL (förkortning för 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') systemet till talöversättningsuppgiften för IWSLT Evaluation 2018. Systemet är ett konventionellt pipeline system som innehåller 3 moduler: taligenkänning, efterbehandling och maskinöversättning. Vi tränar en grupp hybrid-HMM-modeller för vår taligenkänning, och för maskinöversättning tränar vi transformatorbaserade neurala maskinöversättningsmodeller med taligenkänningstyp som inmatning. Experiment utförda på IWSLT 2018-uppgiften indikerar att vårt system uppnådde 14,9 BLEU-förbättring jämfört med baslinjesystemet från KIT.", 'ta': 'இந்த தாள் USTC- NEL (சீனாவின் அறிவியல் மற்றும் தொழில் தகவல் செயல்பாடு கல்வி மற்றும் தொழில்நுட்பத்திற்கான நாட்டு இயந்திரம் நூலகத்திற்கான சுருக்கமாக வ கணினி ஒரு வழக்கமான பைப்லைன் முறைமையாகும், அதில் 3 கூறுகள் உள்ளது: பேச்சு அடையாளம், பின் செயல்படுத்தல் மற்றும் இயந் நாங்கள் ஹைப்ரிட்- HMM மாதிரிகளை எங்கள் பேச்சு அடையாளத்திற்கு பயிற்சி செய்ய பயிற்சி செய்கிறோம், மற்றும் இயந்திரம் மொழிபெயர்ப்பு மாற IWSLT 2018 செயல்பாட்டில் செயல்படுத்தப்பட்ட சோதனைகள் குறிப்பிடுகிறது, KIT இருந்து ஒப்பிட்டால், எங்கள் கணினியில் 14. 9 பிலியு மேம்', 'ur': "This paper describes the USTC-NEL (short for 'National Engineering Laboratory for Speech and Language Information Processing University of Science and technology of China') system to the speech translation task of the IWSLT Evaluation 2018. سیسٹم ایک منطقی پیپ لین سیسٹم ہے جس میں 3 موڈولے لگتے ہیں: سخنرانی شناسایی، پوسٹ پریشینگ اور ماشین ترجمہ. ہم ایک گروپ ہیبراڈ-HMM موڈل کی تعلیم دیتے ہیں اپنی بات کی شناسایی کے لئے اور ماشین ترجمہ کے لئے ہم ترجمہ کرنے والے نیورال ماشین ترجمہ موڈل کی تعلیم دیتے ہیں جو زبان کی شناسایی آئٹ پیٹ استیلہ کے طور پر استیلہ کے ساتھ IWSLT 2018 کے تابع پر عمل کی تجربیات دکھاتی ہے کہ کیٹی سے بنیاس لین سیسٹم کے مقابلہ میں ہماری سیسٹم 14.9 بلیوس کی تحقیق پہنچ گئی۔", 'uz': "This paper describes the USTC-NEL (short for 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') system to the speech translation task of the IWSLT Evaluation 2018.  Name Biz gapiruvchimizni tasdiqlash uchun bir guruhni hybrid-HMM modellarini o'rganamiz, va mashinaning tarjima uchun biz o'zgarishni o'rganamiz va o'zgarishga asosiy neyrolik tarjima modellarini o'rganamiz va gapirish natijasini tasdiqlash uslubi matnni kiritish uchun Comment", 'vi': 'Tờ giấy này mô tả hệ thống dịch giọng nói của USTC-NEL (viết tắt cho "Phòng Kỹ thuật quốc gia cho phát âm và khoa học và công nghệ thông tin Ngôn ngữ) thuộc về Trung Quốc). Hệ thống này là một hệ thống đường ống thông thường chứa 3-mô-đun: nhận dạng ngôn ngữ, xử lý nối tiếp và dịch chuyển máy. Chúng tôi đào tạo một nhóm các mô hình hỗn hợp-HMX cho việc nhận dạng giọng nói của chúng tôi, và để dịch cỗ máy chúng tôi đào tạo các mô hình dịch cỗ máy thần kinh bằng cách nhận dạng giọng nói, bằng chữ nhập. Thử nghiệm trong nhiệm vụ IWSLT 88 cho thấy rằng, so với hệ thống cơ bản của KIM, hệ thống đã đạt được sự cải tiến 49LEU.', 'bg': 'Настоящата статия описва системата на Националната инженерна лаборатория за речова и езикова информационна обработка на Университета по наука и технологии в Китай към задачата за речен превод на Оценка 2018. Системата е конвенционална тръбопроводна система, която съдържа 3 модула: разпознаване на реч, последваща обработка и машинен превод. Обучаваме група хибридни модели за разпознаване на реч, а за машинен превод обучаваме трансформаторни модели на невронен машинен превод с изходен текст в стил разпознаване на реч като вход. Експериментите, проведени по задачата показват, че в сравнение с базовата система от КИТ, нашата система е постигнала 14.9 подобрение.', 'hr': "Ovaj papir opisuje USTC-NEL (kratko za 'Nacionalnu inženjersku laboratoriju za obrađivanje govora i jezičkih informacija Univerziteta nauke i tehnologije Kine') sistem za prevod govora u procjeni IWSLT 2018. godine. Sistem je konvencionalni cjevovodni sustav koji sadrži 3 modula: priznanje govora, nakon obrade i prevod stroja. Uvježbamo skupinu hibridnih modela HMM-a za priznanje govora, a za prevod uređaja treniramo modele prevoda neuralnih strojeva na temelju transformatora sa tekstom stila priznanja govora kao ulaz. Eksperimenti provedeni na zadatku IWSLT 2018 ukazuju na to da je u usporedbi s početnim sustavom KIT naš sustav postigao poboljšanje BLEU 14,9.", 'da': "Dette dokument beskriver USTC-NEL (forkortelse for 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') systemet til taleoversættelsesopgaven i IWSLT Evaluation 2018. Systemet er et konventionelt pipeline system, der indeholder 3 moduler: talegenkendelse, efterbehandling og maskinoversættelse. Vi træner en gruppe hybrid-HMM modeller til vores talegenkendelse, og til maskinoversættelse træner vi transformer baserede neurale maskinoversættelsesmodeller med talegenkendelse outputtekst som input. Eksperimenter udført på IWSLT 2018 opgaven indikerer, at vores system, sammenlignet med baseline system fra KIT, opnåede 14,9 BLEU forbedring.", 'de': 'Dieser Beitrag beschreibt das USTC-NEL (Abkürzung für "National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china") System zur Sprachübersetzungsaufgabe der IWSLT Evaluation 2018. Das System ist ein herkömmliches Pipeline-System, das drei Module enthält: Spracherkennung, Nachbearbeitung und maschinelle Übersetzung. Wir trainieren eine Gruppe von Hybrid-HMM-Modellen für unsere Spracherkennung und für die maschinelle Übersetzung trainieren wir transformatorbasierte neuronale maschinelle Übersetzungsmodelle mit Spracherkennungsausgabe Text als Eingabe. Experimente an der Aufgabe IWSLT 2018 zeigen, dass unser System im Vergleich zum Basissystem des KIT eine 14.9 BLEU-Verbesserung erzielt hat.', 'ko': "본고는 USTC-NEL(약칭'중국과학기술대학 음성과 언어정보처리국가공정실험실') 시스템이 2018년 IWSLT에 대한 평가를 위한 음성 번역 임무를 소개한다.이 시스템은 전통적인 유수선 시스템으로 세 가지 모듈을 포함하는데 그것이 바로 음성인식, 후처리와 기계번역이다.우리는 우리의 음성인식을 위해 혼합 HMM 모델을 훈련시켰고, 기계번역을 위해 음성인식 출력 양식의 텍스트를 입력하는 변환기 기반의 신경기계번역 모델을 훈련시켰다.IWSLT 2018 임무에서 진행된 실험에 따르면 KIT의 베이스라인 시스템에 비해 우리 시스템은 14.9BLEU 개선을 실현했다.", 'sw': "This paper describes the USTC-NEL (short for 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') system to the speech translation task of the IWSLT Evaluation 2018.  Mfumo huo ni mfumo wa pipesi wa kawaida unaohusika vifaa 3: kutambua hotuba, kutafsiri baada ya upasuaji na tafsiri ya mashine. Tunawafunza kikundi cha mifano ya hybrid-HMM kwa ajili ya kutambua hotuba yetu, na kwa kutafsiri mashine tunafundisha mifano ya kutafsiri mashine yenye msingi wa kisasa ya kijinsia kwa kutumia ujumbe wa mazingira ya kutambua hotuba kama input. Majaribio yaliyofanyika katika kazi ya IWSLT 2018 yanaonyesha kuwa, ukilinganishwa na mfumo wa msingi wa KIT, mfumo wetu ulipata maboresho 14.9 BLEU.", 'nl': "Dit artikel beschrijft het USTC-NEL (afkorting voor 'National Engineering Laboratory for Speech and Language Information Processing University of Science and Technology of China') systeem voor de spraakvertaaltaak van de IWSLT Evaluation 2018. Het systeem is een conventioneel pijpleidingsysteem dat drie modules bevat: spraakherkenning, nabewerking en machinevertaling. We trainen een groep hybride-HMM-modellen voor onze spraakherkenning, en voor machinevertaling trainen we transformatorgebaseerde neurale machinevertaalmodellen met tekst van spraakherkenning als input. Uit experimenten met de IWSLT 2018-taak blijkt dat ons systeem, vergeleken met het basissysteem van KIT, 14.9 BLEU-verbetering heeft bereikt.", 'af': "Hierdie papier beskrywe die USTC-NEL (kort vir 'Nasionale Ingenieringslaboratorie vir Spraak en Taal Informasie Verwerking Universiteit van wetenskap en teknologie van Kina') stelsel na die sprekkoorsetting taak van die IWSLT Evaluering 2018. Die stelsel is 'n konvensionele pyplyn stelsel wat bevat 3 modules: spreek herken, post- prosessering en masjien vertaling. Ons tref 'n groep van hybrid-HMM modele vir ons spreek herken, en vir masjien vertaling tref ons transformeerder gebaseerde neurale masjien vertaling modele met spreek herken uitset styl teks as invoer. Experiments conducted on the IWSLT 2018 task indicate that, compared to baseline system from KIT, our system achieved 14.9 BLEU improvement.", 'fa': "این کاغذ سیستم USTC-NEL را توصیف می\u200cکند (کوتاه برای 'آزمایشگاه مهندسی ملی برای تحلیل کردن دانشگاه علم و تکنولوژی چین در دانشگاه سخنرانی و زبان) به کار ترجمه سخنرانی ارزیابی IWSLT ۲۰۱۸. سیستم یک سیستم لوله\u200cهای معمولی است که شامل ۳ مدول است: شناسایی سخنرانی، پس پردازش و ترجمه ماشین. ما گروهی از مدل های hybrid-HMM را برای شناسایی سخنرانی ما آموزش می دهیم، و برای ترجمه ماشین ما مدل های ترجمه ماشین عصبی بنیاد ترجمه کننده را آموزش می دهیم با متن سبک تشخیص شکل خروجی سخنرانی به عنوان ورودی. تجربه\u200cهای روی کار IWSLT ۲۰۱۸ نشان می\u200cدهند که در مقایسه با سیستم بنیادی از KIT، سیستم ما به بهبود ۱۴.۹ BLEU رسید.", 'sq': "This paper describes the USTC-NEL (short for 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') system to the speech translation task of the IWSLT Evaluation 2018.  Sistemi është një sistem tubacioni konvencional që përmban 3 module: njohje e fjalës, pas-procesimi dhe përkthimi i makinave. Ne trajnojmë një grup modelesh hibridë-HMM për njohjen tonë të fjalës, dhe për përkthimin e makinave ne trajnojmë modele përkthimi nervor të makinave me stilin e njohjes së fjalës tekst si hyrje. Eksperimentet e kryera në detyrën e IWSLT 2018 tregojnë se, krahasuar me sistemin bazë nga KIT, sistemi ynë arriti përmirësimin e 14.9 BLEU.", 'tr': "Bu kagyz USTC-NEL (IWSLT Ýardamçylygynyň 2018-nji ýylda IWSLT Taýýarlamagynyň çykyş täblisasyna 'Milli Inženjeriýa Laboratoriýasy for Speech and Language Information Processing University of China') sistemini tassyklady. Bu sistem 3 modüli içinde adatça bir pipeline sistemidir: çykyş tanaýmasy, işlemden soňra we maşynyň terjimesi. Biz çykyş tanımlamak üçin bir topar hybrid-HMM modellerini öwredýäris we makine terjime etmek üçin transformatör tabanly neural makine terjime modellerini çykyş etmek üçin çykyş şeklini tanıyan metini girdi şeklinde öwredýäris. IWSLT 2018 zadynda provenimiz KIT'den baz sistemasyna görä sistemamyz 14.9 BLES gelişmegi başardy.", 'id': "This paper describes the USTC-NEL (short for 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') system to the speech translation task of the IWSLT Evaluation 2018.  The system is a conventional pipeline system which contains 3 modules: speech recognition, post-processing and machine translation.  Kami melatih kelompok model hibrid-HMM untuk pengenalan pidato kami, dan untuk terjemahan mesin kami melatih model terjemahan mesin saraf berdasarkan transformer dengan teks gaya pengenalan pidato sebagai input. Experiments conducted on the IWSLT 2018 task indicate that, compared to baseline system from KIT, our system achieved 14.9 BLEU improvement.", 'bn': 'এই প্রবন্ধে ইউএসটিসি-নেল (জাতীয় ইঞ্জিনিয়েনিয়ার্জিনিয়ার বিজ্ঞান ও প্রক্রিয়া বিশ্ববিদ্যালয়ের বিজ্ঞান ও প্রযুক্তির জন্য সংক্ষিপ্ত ব্যবস্থ The system is a conventional pipeline system which contains 3 modules: speech recognition, post-processing and machine translation.  আমরা একটি দল হাইব্রিড-এইচএমএম মডেল প্রশিক্ষণ করি আমাদের বক্তৃতা স্বীকৃতির জন্য, এবং মেশিন অনুবাদের জন্য আমরা ভিত্তিক নিউরেল মেশিন অনুবাদ মডেল প IWSLT ২০১৮ কাজে অনুষ্ঠিত পরীক্ষার পরীক্ষা নির্দেশ করছে যে কিটি থেকে বেসাইলাইন সিস্টেমের তুলনায় আমাদের সিস্টেম ১৪. ৯ বিলিউ', 'az': 'Bu kağıt, 2018-ci IWSLT Evaluyasının söz çevirilməsi üçün USTC-NEL (National Engineering Laboratory for Speech and Language Information Processing University of China) sistemini təsbiq edir. Sistem 3 modulu içərilən conventional pipeline sistemidir: danışma tanıması, işləmə sonrası və maşın çevirisi. Biz sözlərimizi tanıtmaq üçün hibrid-HMM modellərinin qrupu təhsil edirik, maşın çevirilməsi üçün transformatör sistemi təhsil edirik, sözləri tanıtmaq təhsil təhsil təhsil etdik. IWSLT 2018 təcrübəsində işlədilən təcrübələr KIT-dən başlanğıç sistemi ilə salıb sistemimizin 14,9 BLEU yaxşılıqlarını başa düşdüyünü göstərir.', 'am': 'ይህ ገጽ የኢዮጵስልቲ ኢንጂንቨርስቲ እና የቋንቋ መረጃ ፕሮግራም ዩኒቨርስቲ የቻይና የቴክኖክዩንቨርስቲ ለንግግር እና የቋንቋ መረጃ ፕሮግራም ማህበረታዊ (የUSTC-NEL) ስርዓት ለIWSLT አካላት ትርጓሜ ስርዓት በሚገልጽ ሲስተም 3 ሰነዶች የሚኖሩት የባሕላዊ ስርዓት ነው፤ የንግግር ማስታወቂያ፣ በፖስታ ክፈት እና የመኪን ትርጉም። የhybrid-HMM ምሳሌዎችን ለንግግር ማስታወቂያውን እናስተምራለን፤ እና ለmachine ትርጉም የተመሳሳይ የናውሬል መሣሪያን ትርጉም ምሳሌዎችን በንግግር ማስታወቂያ የድረ ገጽ ጽሑፎችን እንደ input እናስተምራለን፡፡ በIWSLT 2018 ስራ ላይ የተደረገውን ፈተናዎች ከKIT ጀምሮ ቢተካክሉ ሲስተካከላችን 14.9 BLEU አካባቢ አግኝቷል፡፡', 'bs': "Ovaj papir opisuje USTC-NEL (kratko za 'Nacionalnu inženjersku laboratoriju za obradu govora i jezičkih informacija Univerziteta nauke i tehnologije Kine') sistem za prevod govora u procjeni IWSLT 2018. godine. Sistem je konvencionalni cijevinski sistem koji sadrži 3 modula: priznanje govora, nakon obrade i prevod strojeva. Treniramo grupu hibridnih modela HMM-a za priznanje govora, a za prevod mašine treniramo modele prevoda neuralnih mašina na osnovu transformacije sa tekstom stila prepoznavanja govora kao input. Eksperimenti provedeni na zadatku IWSLT 2018 ukazuju na to da je u usporedbi s početnim sistemom KIT naš sistem postigao poboljšanje BLEU 14,9.", 'cs': 'Tento článek popisuje USTC-NEL (zkratka pro "Národní inženýrská laboratoř pro zpracování řeči a jazykových informací University of Science and Technology of China") systém pro úlohu překladu řeči IWSLT Evaluation 2018. Systém je konvenční potrubní systém, který obsahuje tři moduly: rozpoznávání řeči, post-processing a strojový překlad. Pro rozpoznávání řeči trénujeme skupinu hybridních HMM modelů a pro strojový překlad trénujeme neuronové strojové modely založené na transformátorech s textem ve stylu rozpoznávání řeči jako vstup. Experimenty provedené na úkolu IWSLT 2018 ukazují, že náš systém ve srovnání se základním systémem KIT dosáhl 14.9 BLEU zlepšení.', 'et': 'Käesolevas artiklis kirjeldatakse USTC-NEL (lühend "Hiina teadus- ja tehnoloogiaülikooli riiklik insenerilabor kõne- ja keeleteabe töötlemiseks") süsteemi IWSLT hindamise 2018. aasta kõnetõlke ülesandeks. Süsteem on tavaline torustik, mis sisaldab 3 moodulit: kõnetuvastus, järeltöötlus ja masintõlge. Koolitame oma kõnetuvastuseks hübriid-HMM-mudeleid ning masintõlke jaoks koolitame trafopõhiseid neuromasintõlke mudeleid, millel on sisendina kõnetuvastuse väljundtekst. IWSLT 2018 ülesandega läbi viidud eksperimendid näitavad, et võrreldes KIT baassüsteemiga saavutas meie süsteem 14,9 BLEU paranemist.', 'fi': "Tässä artikkelissa kuvataan USTC-NEL (lyhenne sanoista 'National Engineering Laboratory for Speech and Language Information Processing University of China') järjestelmää IWSLT Evaluation 2018 puheen kääntämiseen. Järjestelmä on perinteinen putkijärjestelmä, joka sisältää kolme moduulia: puheentunnistus, jälkikäsittely ja konekäännös. Koulutamme joukon hybridi-HMM-malleja puheentunnistukseen ja konekääntämiseen valmennamme muuntajapohjaisia neurokonekäännösmalleja, joissa on puheentunnistustyylinen teksti syötteenä. IWSLT 2018 -tehtävällä tehdyt kokeet osoittavat, että KIT:n perusjärjestelmään verrattuna järjestelmämme saavutti 14,9 BLEU-parannuksen.", 'hy': "This paper describes the USTC-NEL (short for 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') system to the speech translation task of the IWSLT Evaluation 2018.  Համակարգը ավանդական խողովակաշարերի համակարգ է, որը պարունակում է 3 մոդուլներ՝ խոսքի ճանաչելը, հետմշակման և մեքենային թարգմանումը: Մենք վարժեցնում ենք հիբրիդ-ՀՄՄ մոդելների մի խոսքի ճանաչելու համար, և մեքենային թարգմանման համար մենք վարժեցնում ենք թարգմանիչների հիմնված նյարդային մեքենայի թարգմանման մոդելներ խոսքի ճանաչելու հնարավորության տեսքով,  2018 թվականի IW-ՍԼԹ խնդրի վրա կատարված փորձարկումները ցույց են տալիս, որ համեմատելով KIT-ի հիմնական համակարգին, մեր համակարգը հասավ 14.9 բլեուզ բարելավման:", 'ca': 'Aquest article descriu el sistema USTC-NEL (breu per "National Engineering Laboratory for Speech and Language Information Processing University of science and technology of China") a la tasca de traducció del discurs de l\'IWSLT Evaluation 2018. El sistema és un sistema convencional de tubacions que conté tres móduls: reconeixement de la voz, postprocessament i traducció màquina. Ensenyem un grup de models híbrids-HMM per al nostre reconeixement del discurs, i per a la traducció màquina entrenem models de traducció neuromàquina basats en transformadors amb text d\'estil de sortida del reconeixement del discurs com entrada. Els experiments efectuats en la tasca IWSLT 2018 indican que, comparat amb el sistema basal de KIT, el nostre sistema va aconseguir 14,9 millors de BLEU.', 'jv': 'Gambar iki rambarang UST-NeL Sistem sing sistem konnek kang dadi tanggal sing nduwe 3 modul: kang sesuk, kang pisan mulai karo perusahaan lan kang sampeyan. Awakdhéwé karo nggawe group of HyBridge-HPM model para awakdhéwé nggawe barang nggawe lan karo perintah pengaturan sing guruté transformer Isoporsya sing gagal ning task IWSLT 2013 menehi nggawe sapa sistem sing bisa perusahaan kanggo nggawe Sistem sisan kanggo KT, Sistem dhéwé iso dianggap kanggo nyusun kanggo 14.9 MB.', 'ha': "Bu karatun na describe the United TC-NEL (short for the 'National Engineer Laptory for Spelling and Lingui information Performance University of Sayansi da Technical of China') system to the translation job of the IWSLT Assistance 2018. @ action: button Tuna kõre wani misãlai na Hybri-HMM wa ganin magana, kuma dõmin fassarar masu motsi da za'a sanar da transformer masu bakin ayuka na bakin neural na ƙidãya da misãlai masu sunana na bakin ayuka da matsalin abun da aka shiga. Tajarakin da aka aikata a kan aikin IWSLT 2018 yana indiyar cẽwa, sammenlikin da aka kamata na tsarin Baselin na KIT, na'uranmu ya sami 14.9 BLEU.", 'sk': "V prispevku je opisan sistem USTC-NEL (kratka za 'Nacionalni inženirski laboratorij za obdelavo govora in jezikovnih informacij Univerza znanosti in tehnologije Kitajske') za nalogo prevajanja govora IWSLT Evaluation 2018. Sistem je konvencionalni cevovodni sistem, ki vsebuje 3 module: prepoznavanje govora, naknadno obdelavo in strojno prevajanje. Za prepoznavanje govora usposabljamo skupino hibridnih HMM modelov, za strojno prevajanje pa usposabljamo transformatorske nevralne strojne prevajalske modele z izhodnim slogom prepoznavanja govora kot vhodnim besedilom. Eksperimenti, opravljeni na nalogi IWSLT 2018, kažejo, da je naš sistem v primerjavi z osnovnim sistemom KIT dosegel 14,9 BLEU izboljšave.", 'bo': "This paper describes the USTC-NEL (short for 'National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china') system to the speech translation task of the IWSLT Evaluation 2018. The system is a conventional pipeline system which contains 3 modules: speech recognition, post-processing and machine translation. We train a group of hybrid-HMM models for our speech recognition, and for machine translation we train transformer based neural machine translation models with speech recognition output style text as input. IWSLT 2018་ལ་ལས་འགན་པའི་བརྟག་ཞིབ་ཀྱིས་KIT ལས་གཞི་རིམ་པ་དང་མཉམ་དུ་འགྱུར་བ", 'he': 'העיתון הזה מתאר את מערכת USTC-NEL (קצרה עבור "Laboratory National Engineering for Speech and Language Information Processing University of Science and Technology of China") למשימת התרגום הנאום של הערכת IWSLT 2018. המערכת היא מערכת צינורות קונבנציונלית שמכילה 3 מודולים: זיהוי נאום, אחרי העבודה ותרגום מכונות. אנו מאמנים קבוצה של דוגמנים HMM היברידים לזהות הנאום שלנו, ולהתרגום מכונת אנו מאמנים דוגמנים של מכונת התרגום העצבית המבוססת Experiments conducted on the IWSLT 2018 task indicate that, compared to baseline system from KIT, our system achieved 14.9 BLEU improvement.'}
{'en': 'The ADAPT System Description for the IWSLT 2018 Basque to English Translation Task ADAPT  System Description for the  IWSLT  2018  B asque to  E nglish Translation Task', 'ar': 'وصف نظام التكيف لمهمة الترجمة الباسكية إلى الإنجليزية IWSLT 2018', 'pt': 'A descrição do sistema ADAPT para a tarefa de tradução de basco para inglês do IWSLT 2018', 'es': 'Descripción del sistema ADAPT para la tarea de traducción del euskera al inglés IWSLT 2018', 'fr': 'Description du système ADAPT pour la tâche de traduction basque vers anglais IWSLT 2018', 'ja': 'IWSLT 2018バスク語から英語への翻訳タスクのADAPTシステム説明', 'ru': 'Описание системы ADAPT для задачи перевода с баскского на английский язык IWSLT 2018', 'ga': 'Cur síos ar an gCóras ADAPT do Thasc Aistriúcháin Bascais go Béarla IWSLT 2018', 'zh': 'IWSLT 2018 巴斯克语至英语翻译者 ADAPT 统言之', 'hi': 'IWSLT 2018 बास्क के लिए अंग्रेजी अनुवाद कार्य के लिए ADAPT सिस्टम विवरण', 'el': 'Η περιγραφή του συστήματος για το έργο της βασκικής σε αγγλική μετάφραση', 'hu': 'Az ADAPT rendszer leírása az IWSLT 2018 baszk-angol fordítási feladathoz', 'ka': 'ADAPT სისტემის გამოსახულება IWSLT 2018 ბასკის ანგლისური განსახულების საქმე', 'it': "Descrizione del sistema ADAPT per il compito di traduzione dal basco all'inglese IWSLT 2018", 'kk': 'ADAPT жүйелік IWSLT 2018 баскша ағылшын аудару тапсырмасының сипаттамасы', 'mk': 'АДАПТ системски опис за IWSLT 2018 коски на англиски превод', 'ms': 'Huraian Sistem ADAPT untuk Tugas Terjemahan Bahasa ke Inggeris IWSLT 2018', 'lt': 'ADAPT sistemos aprašymas IWSLT 2018 Baskų ir anglų vertimo darbui', 'ml': 'IWSLT 2018 ബാസ്കിനുള്ള ADAPT സിസ്റ്റം വിവരണം ഇംഗ്ലീഷ് പരിഭാഷ ടാസ്കിലേക്കു്', 'mt': 'Id-Deskrizzjoni tas-Sistema ADAPT għall-IWSLT 2018 Kompitu ta’ Traduzzjoni Baska għall-Ingliż', 'no': 'ADAPT-systemskildring for IWSLT-2018 bask til engelsk omsetjingsverkt', 'mn': 'ADAPT системийн тодорхойлолт нь IWSLT 2018 оны Баск-д Англи хэлний хөрөнгө оруулах', 'pl': 'Opis systemu ADAPT dla zadania tłumaczeniowego IWSLT 2018', 'ro': 'Descrierea sistemului ADAPT pentru sarcina de traducere din limba bască în engleză IWSLT 2018', 'sr': 'Описане АДАПТ Система за IWSLT 2018 Баски на английски транспортни задatak', 'si': 'The ADAPT System Description for the IWSLT 2018 Basque to English translation Job', 'sv': 'Beskrivning av systemet ADAPT för IWSLT 2018 baskiska till engelska översättningsuppgifter', 'so': 'Description of the ADAPT system for the IWSLT 2018 Basque to Ingiriis Task Translation', 'ta': 'IWSLT 2018 பாஸ்க் ஆங்கிலம் மொழிபெயர்ப்பு பணிக்கு ADAPT அமைப்பு விவரம்', 'ur': 'IWSLT 2018 کے لئے باسک انگلیسی ترجمہ ٹاکس کے لئے ADAPT سیسٹم کا سپرت', 'uz': 'Name', 'vi': 'Mô tả hệ thống ADAP cho Nhiệm vụ IWSLT 88 Dịch sang tiếng Anh', 'nl': 'De ADAPT systeembeschrijving voor de IWSLT 2018 Baskisch naar Engels vertaaltaak', 'da': 'ADAPT System Beskrivelse af IWSLT 2018 Baskisk til Engelsk Oversættelse Opgave', 'hr': 'Opis ADAPT sustava za IWSLT 2018 Baskijski na engleski prevodni zadatak', 'id': 'Deskripsi Sistem ADAPT untuk Tugas Terjemahan Bahasa Inggris IWSLT 2018', 'ko': 'IWSLT 2018 바스크 영어 번역 임무의 사용자 적응 시스템 설명', 'de': 'Die ADAPT Systembeschreibung für die IWSLT 2018 Baskisch to English Übersetzungsaufgabe', 'tr': 'ADAPT sistemi Wasp', 'fa': 'Description of the ADAPT System for the IWSLT 2018 Basque to English Translation Task', 'sw': 'Maelezo ya Mfumo wa ADAPT kwa ajili ya IWSLT 2018 Basque kwa ajili ya Tafsiri ya Kiingereza', 'af': 'Die ADAPT Stelsel Beskrywing vir die IWSLT 2018 Basque na Engelske Vertaling Taak', 'bg': 'Описание на системата АДАПТ за задачата за превод от баски на английски език 2018', 'sq': 'Description of the ADAPT System for the IWSLT 2018 Basque to English Translation Task', 'am': 'The ADAPT System Description for the IWSLT 2018 Basque to English translation Task', 'az': 'IWSLT 2018 Basque il톛 캻ngiliz 칂eviri G칬z톛li 칲칞칲n ADAPT Sistemi T톛rc칲m톛', 'bn': 'IWSLT ২০১৮ বাস্কের জন্য ADAPT সিস্টেমের বর্ণনা ইংরেজি অনুবাদ করার জন্য', 'hy': '2018 թվականի բասկի դեպի անգլերեն թարգմանման գործի ADAPT համակարգի նկարագրությունը', 'bs': 'ADAPT sistemski opis za IWSLT 2018 Baskijski na engleski prevodni zadatak', 'ca': 'La descripció del sistema ADAPT per la tasca de traducció vasca a anglès IWSLT 2018', 'et': 'ADAPT süsteemi kirjeldus IWSLT 2018 baski-inglise tõlketöö jaoks', 'fi': 'ADAPT-järjestelmän kuvaus IWSLT 2018 baskista englantiin -käännöstehtävään', 'cs': 'Popis systému ADAPT pro IWSLT 2018 Baskičtina do angličtiny Překlad úlohy', 'jv': 'tab-style', 'sk': 'Opis sistema ADAPT za prevajalsko nalogo IWSLT 2018 iz baskovščine v angleščino', 'he': 'Description of the ADAPT System for the IWSLT 2018 Basque to English Translation Task', 'ha': 'Description for the IWSLT 2018 Basque to English translation job', 'bo': 'ADAPT མ་ལག་གི་འགྲེལ་བཤད་ཀྱི་IWSLT 2018 ས་ཡིག་གཟུགས་ལས་དབྱིན་ཡིག་སྐད་འགྲེལ་བཤད།'}
{'en': 'In this paper we present the ADAPT system built for the Basque to English Low Resource MT Evaluation Campaign. Basque is a low-resourced, morphologically-rich language. This poses a challenge for Neural Machine Translation models which usually achieve better performance when trained with large sets of data. Accordingly, we used  synthetic data  to improve the translation quality produced by a  model  built using only authentic data. Our proposal uses back-translated data to : (a) create new sentences, so the system can be trained with more data ; and (b) translate sentences that are close to the test set, so the model can be fine-tuned to the document to be translated.', 'ar': 'نقدم في هذا البحث نظام ADAPT المصمم لحملة تقييم مسرح ماجنت منخفضة الموارد من الباسك إلى الإنجليزية. لغة الباسك هي لغة منخفضة الموارد وغنية من الناحية الشكلية. يشكل هذا تحديًا لنماذج الترجمة الآلية العصبية التي عادةً ما تحقق أداءً أفضل عند تدريبها باستخدام مجموعات كبيرة من البيانات. وفقًا لذلك ، استخدمنا البيانات التركيبية لتحسين جودة الترجمة التي ينتجها نموذج تم إنشاؤه باستخدام بيانات أصلية فقط. يستخدم اقتراحنا البيانات المُعاد ترجمتها من أجل: (أ) إنشاء جمل جديدة ، بحيث يمكن تدريب النظام بمزيد من البيانات ؛ و (ب) ترجمة الجمل القريبة من مجموعة الاختبار ، بحيث يمكن ضبط النموذج بدقة على المستند المراد ترجمته.', 'fr': "Dans cet article, nous présentons le système ADAPT conçu pour la campagne d'évaluation de MT basque-anglais à faible ressource. Le basque est une langue riche en ressources morphologiques. Cela pose un défi pour les modèles de traduction automatique neuronale qui obtiennent généralement de meilleures performances lorsqu'ils sont entraînés avec de grands ensembles de données. Par conséquent, nous avons utilisé des données synthétiques pour améliorer la qualité de la traduction produite par un modèle construit uniquement à partir de données authentiques. Notre proposition utilise des données rétro-traduites pour\xa0: (a) créer de nouvelles phrases, afin que le système puisse être entraîné avec plus de données\xa0; et (b) traduire des phrases proches de l'ensemble de test, afin que le modèle puisse être affiné en fonction du document à traduire.", 'es': 'En este artículo presentamos el sistema ADAPT creado para la campaña de evaluación de MT de bajos recursos del euskera al inglés. El euskera es una lengua de pocos recursos y rica en morfología. Esto plantea un desafío para los modelos de traducción automática neuronal que, por lo general, logran un mejor rendimiento cuando se entrenan con grandes conjuntos de datos. En consecuencia, utilizamos datos sintéticos para mejorar la calidad de la traducción producida por un modelo creado solo con datos auténticos. Nuestra propuesta utiliza datos retrotraducidos para: (a) crear nuevas oraciones, para que el sistema pueda entrenarse con más datos; y (b) traducir oraciones que estén cerca del conjunto de pruebas, de modo que el modelo se pueda ajustar al documento que se va a traducir.', 'pt': 'Neste artigo apresentamos o sistema ADAPT construído para a Campanha de Avaliação de MT de Baixo Recurso Basco para Inglês. O basco é uma língua de poucos recursos e morfologicamente rica. Isso representa um desafio para os modelos de tradução automática neural, que geralmente obtêm melhor desempenho quando treinados com grandes conjuntos de dados. Assim, usamos dados sintéticos para melhorar a qualidade da tradução produzida por um modelo construído usando apenas dados autênticos. Nossa proposta utiliza dados retrotraduzidos para: (a) criar novas sentenças, para que o sistema possa ser treinado com mais dados; e (b) traduzir sentenças próximas ao conjunto de teste, para que o modelo possa ser ajustado ao documento a ser traduzido.', 'ja': '本稿では、バスク語から英語への低資源MT評価キャンペーンのために構築された適応システムを紹介する。バスク語は低資源で形態豊富な言語である。これは、大規模なデータセットで訓練された場合に通常より優れたパフォーマンスを達成するニューラル・マシン・トランスレーション・モデルにとって課題となる。そこで、合成データを活用し、真正なデータのみを用いて構築されたモデルによって、翻訳品質を向上させました。当社の提案では、逆翻訳されたデータを使用して次のことを行います。(a)新しい文章を作成して、より多くのデータを使用してシステムをトレーニングできるようにします。(b)テストセットに近い文章を翻訳して、翻訳されるドキュメントにモデルを微調整できるようにします。', 'ru': 'В этой статье мы представляем адаптированную СИСТЕМУ, созданную для Баскской кампании по оценке МТ с низким уровнем ресурсов. Баскский язык - это не обеспеченный ресурсами, морфологически богатый язык. Это создает проблему для моделей нейронного машинного перевода, которые обычно достигают лучшей производительности при обучении с большими наборами данных. Соответственно, мы использовали синтетические данные для улучшения качества перевода, созданного моделью, построенной с использованием только аутентичных данных. В нашем предложении используются данные, переведенные в обратном порядке, для: a) создания новых предложений, с тем чтобы система могла быть обучена большему количеству данных; и b) перевода предложений, которые близки к тестовому набору, с тем чтобы модель могла быть доработана с учетом документа, подлежащего переводу.', 'ga': 'Sa pháipéar seo cuirimid i láthair an córas ADAPT a tógadh don Fheachtas Measúnaithe MT ó Bhascach go Béarla. Is teanga íseal-acmhainní í an Bhascais, atá saibhir ó thaobh moirfeolaíochta de. Cruthaíonn sé seo dúshlán do mhúnlaí Néar-Aistriúcháin Meaisín a ghnóthaíonn feidhmíocht níos fearr de ghnáth nuair a chuirtear oiliúint orthu le tacair mhóra sonraí. Dá réir sin, d’úsáideamar sonraí sintéiseacha chun feabhas a chur ar cháilíocht an aistriúcháin a tháirgtear trí mhúnla a tógadh ag úsáid sonraí barántúla amháin. Úsáideann ár dtogra sonraí aisaistrithe chun: (a) abairtí nua a chruthú, ionas gur féidir an córas a oiliúint le tuilleadh sonraí; agus (b) abairtí atá gar don tacar trialach a aistriú, ionas gur féidir an tsamhail a mhionchoigeartú don doiciméad atá le haistriú.', 'zh': '于本文中,引为巴斯克语至英语低资源MT评估结构之ADAPT系统。 巴斯克语者,资也,形多言也。 为神经机器翻译挑战,以大集教之。 故我用合成数以崇真数所生译质。 臣等议用回译数:(a) 创新句,以统可以多数;(b) 创新句,以统可以多数;(b) 创新句;(c) 创新句;(d (b)译近试集之句,以模形微调其文档。', 'hi': 'इस पेपर में हम अंग्रेजी कम संसाधन एमटी मूल्यांकन अभियान के लिए बास्क के लिए निर्मित ADAPT प्रणाली प्रस्तुत करते हैं। बास्क एक कम संसाधन वाली, रूपात्मक रूप से समृद्ध भाषा है। यह न्यूरल मशीन ट्रांसलेशन मॉडल के लिए एक चुनौती है जो आमतौर पर डेटा के बड़े सेट के साथ प्रशिक्षित होने पर बेहतर प्रदर्शन प्राप्त करते हैं। तदनुसार, हमने केवल प्रामाणिक डेटा का उपयोग करके बनाए गए मॉडल द्वारा उत्पादित अनुवाद की गुणवत्ता में सुधार करने के लिए सिंथेटिक डेटा का उपयोग किया। हमारा प्रस्ताव बैक-अनूदित डेटा का उपयोग करता है: (ए) नए वाक्यों को बनाएं, ताकि सिस्टम को अधिक डेटा के साथ प्रशिक्षित किया जा सके; और (बी) उन वाक्यों का अनुवाद करें जो परीक्षण सेट के करीब हैं, इसलिए मॉडल को अनुवादित किए जाने वाले दस्तावेज़ के लिए ठीक किया जा सकता है।', 'ka': 'ამ დომენტში ჩვენ აჩვენებთ ADAPT სისტემა, რომელიც ბასკის გასაკეთებელად ინგლისური მინუს რესურსის MT გასაკეთებელი კამპანიაში. ბასკი არის ცოტა რესურსური, მორპოლოგიურად ბედნიერი ენაა. ეს აჩვენებს ნეიროლური მაქსინის გადაწყვეტილების მოდელებისთვის, რომლებიც საშუალოდ უკეთესი გამოყენება, როდესაც დიდი მონაცემებით გადაწყვეტილი მო ამიტომ, ჩვენ სინტეტიკური მონაცემები გამოყენეთ, რომ გაუქმნათ მოდელის გამოყენება მხოლოდ ავტონტიკური მონაცემებით. ჩვენი პროგრამები გამოყენება ახალი სიტყვების შექმნა, რადგან სისტემა უფრო მეტად მონაცემებით შეიძლება ახალი სიტყვების შექმნა; (b) ტესტის სეტის დაბრუნებული წარმოდგენების შემდეგ მოდელი შეიძლება გადაწყენოთ დოკუმენტის შემდეგ.', 'hu': 'Ebben a tanulmányban bemutatjuk a baszk-angol alacsony erőforrású MT értékelési kampány ADAPT rendszerét. A baszk egy alacsony erőforrású, morfológiailag gazdag nyelv. Ez kihívást jelent a Neural Machine Translation modellek számára, amelyek általában jobb teljesítményt érnek el nagy adatkészletekkel történő kiképzés esetén. Ennek megfelelően szintetikus adatokat használtunk a kizárólag hiteles adatokat felhasználó modell által készített fordítási minőség javítására. Javaslatunk visszafordított adatokat használ a következőkre: (a) új mondatok létrehozására, így a rendszer több adattal képezhető; és (b) fordítson le olyan mondatokat, amelyek közel vannak a tesztkészlethez, így a modell finomhangolható a fordítandó dokumentumhoz.', 'el': 'Στην παρούσα εργασία παρουσιάζουμε το σύστημα που κατασκευάστηκε για την καμπάνια αξιολόγησης των βασκικών προς αγγλικών χαμηλών πόρων ΜΤ. Τα βασκικά είναι μια γλώσσα με χαμηλούς πόρους και μορφολογικά πλούσια. Αυτό αποτελεί πρόκληση για τα μοντέλα Νευρικής Μηχανικής Μετάφρασης τα οποία συνήθως επιτυγχάνουν καλύτερη απόδοση όταν εκπαιδεύονται με μεγάλα σύνολα δεδομένων. Ως εκ τούτου, χρησιμοποιήσαμε συνθετικά δεδομένα για να βελτιώσουμε την ποιότητα της μετάφρασης που παράγεται από ένα μοντέλο κατασκευασμένο μόνο με αυθεντικά δεδομένα. Η πρότασή μας χρησιμοποιεί μεταγραφικά δεδομένα για: (α) να δημιουργήσει νέες προτάσεις, ώστε το σύστημα να μπορεί να εκπαιδευτεί με περισσότερα δεδομένα. και β) μεταφράσουν προτάσεις που είναι κοντά στο σετ δοκιμών, έτσι ώστε το μοντέλο να μπορεί να προσαρμοστεί στο έγγραφο που θα μεταφραστεί.', 'lt': 'Šiame dokumente pristatome ADAPT sistemą, sukurtą baskų ir anglų žemųjų išteklių MT vertinimo kampanijai. Baskų kalba yra mažai išteklių turinti, morfologiškai turtinga kalba. Tai kelia iššūkį neurologinių mašinų vertimo modeliams, kurie paprastai pasiekia geresnius rezultatus rengiant didelius duomenų rinkinius. Todėl naudojame sintetinius duomenis, kad pagerintume vertimo kokybę, gautą naudojant model į, kuriame naudojami tik autentiški duomenys. Mūsų pasiūlyme naudojami grįžtamieji duomenys: a) sukurti naujus sakinius, kad sistema galėtų būti apmokoma daugiau duomenų; ir b) verti sakinius, kurie yra artimi bandymų rinkiniui, kad modelis galėtų b ūti tiksliai pritaikytas prie vertimo dokumento.', 'mk': 'Во овој весник го претставуваме АДАПТ системот изграден за Баски до Англиска кампања за евалуација на МТ со ниски ресурси. Коски е нискоресурсен, морфолошки богат јазик. Ова претставува предизвик за моделите за превод на неврални машини кои обично постигнуваат подобра резултат кога се обучуваат со големи податоци. Според тоа, користевме синтетички податоци за подобрување на квалитетот на превод произведен од модел изграден користејќи само автентични податоци. Нашиот предлог користи преведени податоци за: (a) да создаде нови реченици, за системот да може да биде обучен со повеќе податоци; и (b) преведување реченици кои се блиски до тестот, за моделот да може да биде фино прилагоден на документот кој ќе биде преведен.', 'it': "In questo articolo presentiamo il sistema ADAPT costruito per la campagna di valutazione MT dal basco all'inglese Low Resource. Il basco è una lingua ricca di risorse e morfologicamente ricca. Ciò rappresenta una sfida per i modelli Neural Machine Translation, che di solito raggiungono prestazioni migliori se addestrati con grandi insiemi di dati. Di conseguenza, abbiamo utilizzato dati sintetici per migliorare la qualità della traduzione prodotta da un modello costruito utilizzando solo dati autentici. La nostra proposta utilizza i dati tradotti indietro per: (a) creare nuove frasi, in modo che il sistema possa essere addestrato con più dati; e (b) tradurre frasi vicine al set di test, in modo che il modello possa essere perfezionato al documento da tradurre.", 'kk': 'Бұл қағазда баск жүйесіне MT бағаттау кампаниясы үшін төменгі ресурстарды ағылшын тіліне құрылған ADAPT жүйесін таңдаймыз. Баск - көп ресурс, морфологиялық баяны тіл. Бұл нейрондық компьютерді аудару үлгілерінде көп деректерді оқыту үшін жақсы жұмыс істейтін үлгілер үшін мәселе береді. Сондықтан біз тек аутентификациялық деректерді қолдану үшін синтетикалық деректерді қолдандық. Біздің ұсынысымыз қайта аударылған деректерді: a) жаңа сөздерді құру үшін жүйеңіз көптеген деректермен оқылмай алады. және b) сынақтар жиынына жақын сөздерді аудару үшін үлгі құжатты аудару үшін дұрыс түзетуге болады.', 'ms': 'Dalam kertas ini kami perkenalkan sistem ADAPT yang dibina untuk Kampanye Evaluasi MT Sumber Terrendah Bahasa Bask ke Inggeris. Basque is a low-resourced, morphologically-rich language.  Ini menghasilkan cabaran untuk model Perjemahan Mesin Neural yang biasanya mencapai prestasi yang lebih baik bila dilatih dengan set data yang besar. Oleh sebab itu, kami menggunakan data sintetik untuk meningkatkan kualiti terjemahan yang dihasilkan oleh model yang dibina hanya menggunakan data yang sah. cadangan kami menggunakan data terjemahan semula untuk: (a) mencipta kalimat baru, supaya sistem boleh dilatih dengan lebih banyak data; and (b) translate sentences that are close to the test set, so the model can be fine-tuned to the document to be translated.', 'mt': 'F’dan id-dokument nippreżentaw is-sistema ADAPT mibnija għall-Kampanja ta’ Valutazzjoni MT Baska għal Ingliż b’Riżorsi Baxxi. Il-Bask huwa lingwa b’riżorsi baxxi u rikka morfoloġikament. Dan joħloq sfida għall-mudelli tat-Traduzzjoni tal-Magni Newrali li normalment jiksbu prestazzjoni a ħjar meta jitħarrġu b’settijiet kbar ta’ dejta. Għaldaqstant, użajna dejta sintetika biex ittejjeb il-kwalità tat-traduzzjoni prodotta minn mudell mibni bl-użu ta’ dejta awtentika biss. Our proposal uses back-translated data to: (a) create new sentences, so the system can be trained with more data;  and (b) translate sentences that are close to the test set, so the model can be fine-tuned to the document to be translated.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ബാസ്കിന് വേണ്ടി ഉണ്ടാക്കിയ ADAPT സിസ്റ്റത്തെ ഇംഗ്ലീഷ് വിഭവങ്ങള്\u200dക്ക് കുറഞ്ഞ എംടി വിവരണ ബാസ്ക് ഒരു കുറഞ്ഞ വിഭവങ്ങളാണ്, മോര്\u200dഫോളജിക്കല്\u200d സമ്പന്നമായ ഭാഷ. This poses a challenge for Neural Machine Translation models which usually achieve better performance when trained with large sets of data.  അതുകൊണ്ട്, ഞങ്ങള്\u200d സിന്തെറ്റിക്ക് ഡേറ്റായി ഉപയോഗിച്ച് ഒരു മോഡല്\u200d ഉണ്ടാക്കിയിരിക്കുന്ന പരിഭാഷക്കിന്റെ ഗ ഞങ്ങളുടെ പ്രൊദ്ദേശിപ്പ് പിന്നില്\u200d പരിഭാഷ വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നു: (a) പുതിയ വാക്കുകള്\u200d ഉണ്ടാക്കുക, അതുക (b) പരീക്ഷ സജ്ജീകരണത്തിന് അടുത്തുള്ള വാക്കുകള്\u200d പരിശോധിക്കുക, അതുകൊണ്ട് രേഖയില്\u200d പരിഭാഷപ്പെടുത്താന്\u200d മോഡല', 'mn': 'Энэ цаасан дээр бид Баск хэлний бага боловсролын MT оценки кампанийг бүтээсэн ADAPT системийг илтгэнэ. Баск бол бага эрчим хүчтэй, морфологийн баян хэл. Энэ нь мэдээллийн олон хэмжээний мэдээллээр суралцах үед илүү сайн үйл ажиллагааг гаргадаг мэдрэлийн машин хөгжүүлэх загварын сорилт юм. Тиймээс бид зөвхөн зөвхөн үнэн өгөгдлийг ашиглан бүтээсэн загварын хөгжүүлэх хэмжээсүүдийг сайжруулахын тулд синтетик өгөгдлийг ашигласан. Бидний санал буцаад орчуулсан өгөгдлийг (a) шинэ өгөгдлийг бий болгож, системийг олон өгөгдлийн дасгал суралцаж болно. (b) шалгалтын хэлбэрээс ойрхон өгүүлбэрийг орлуулж болно. Тиймээс загвар нь баримт орлуулах боломжтой болно.', 'no': 'I denne papiret presenterer vi ADAPT-systemet bygd for baskisk til anglesk låg ressurs MT-evalueringskampanjen. Bask er ein låg ressursert, morfologisk rikt språk. Dette viser eit utfordring for neuralmaskineomsetjingsmodular som vanlegvis oppnår bedre utføringar når opplært med store datasett. I tillegg brukte vi syntetiske data for å forbetra omsetjingskvaliteten produsert av eit modell bygd med berre autentisk data. Vår forslag brukar tilbakeomsette data til: a) opprett nye setningar, slik at systemet kan trenast med fleire data. og b) oversetter setningar som er nær testsettet, slik at modellen kan setjast inn i dokumentet som skal oversettest.', 'ro': 'În această lucrare prezentăm sistemul ADAPT construit pentru campania de evaluare a MT din bască în engleză cu resurse reduse. Basca este o limbă bogată din punct de vedere morfologic cu resurse scăzute. Acest lucru reprezintă o provocare pentru modelele Neural Machine Translation, care, de obicei, obțin performanțe mai bune atunci când sunt instruite cu seturi mari de date. În consecință, am folosit date sintetice pentru a îmbunătăți calitatea traducerii produsă de un model construit doar cu date autentice. Propunerea noastră folosește date traduse înapoi pentru: (a) crearea de propoziții noi, astfel încât sistemul să poată fi instruit cu mai multe date; și (b) traduc propoziții care sunt aproape de setul de test, astfel încât modelul să poată fi reglat fin la documentul care urmează să fie tradus.', 'pl': 'W artykule przedstawiamy system ADAPT zbudowany dla baskijsko-angielskiej kampanii oceny niskich zasobów MT. Baskijski jest językiem o niskich zasobach, bogatym morfologicznie. Stanowi to wyzwanie dla modeli neuronowego tłumaczenia maszynowego, które zazwyczaj osiągają lepszą wydajność podczas treningu z dużymi zbiorami danych. W związku z tym wykorzystaliśmy dane syntetyczne do poprawy jakości tłumaczenia wytwarzanego przez model zbudowany wyłącznie z autentycznymi danymi. Nasza propozycja wykorzystuje dane przetłumaczone wstecznie do: (a) tworzenia nowych zdań, dzięki czemu system może być przeszkolony z większą ilością danych; i b) tłumaczyć zdania, które są blisko zestawu testowego, aby model mógł być dostosowany do dokumentu, który ma być tłumaczony.', 'sr': 'U ovom papiru predstavljamo sistem ADAPT izgrađen za baskijsku kampanju za procjenu MT za manje resurse na engleskom jeziku. Baskijski je nizak izvor, morfološki bogat jezik. To predstavlja izazov za modele neurološkog prevoda, koji obično postižu bolju izvršnost kada su obučeni velikim serijama podataka. Stoga smo koristili sintetičke podatke kako bi poboljšali kvalitet prevođenja izgrađenim modelom koji koristi samo autentične podatke. Naš prijedlog koristi prevedeni podaci na: a) stvoriti nove rečenice, tako da sistem može biti obučen sa više podataka; i b) prevedite rečenice koje su blizu seta testa, tako da se model može dobro uključiti dokumentu za prevedenje.', 'si': 'මේ පත්තරේ අපි ADAPT පද්ධතිය පෙන්වන්නේ බාස්ක් පද්ධතිය ඉංග්\u200dරීසියේ අඩු ප්\u200dරධාන MT විශ්ලේෂණ කම්පැන් බාස්ක් තමයි අඩුම ප්\u200dරධානයක්, මොර්ෆෝලෝජික විශාල භාෂාවක්. මේක ප්\u200dරශ්නයක් තියෙනවා න්\u200dයූරල් මැෂින් වාර්ථාපනය මොඩේල්ස් එක්ක ප්\u200dරශ්නයක් වෙනුවෙන් හොඳ ප්\u200dරශ ඉතින්, අපි සින්ටෙටික් දත්ත භාවිතා කරනවා වාර්ථාව ප්\u200dරමාණයක් නිර්මාණය කරලා නිර්මාණය කරපු මදුල්ය අපේ ප්\u200dරයෝජනය පිටිපස්සේ පරිවර්තන දත්ත භාවිත කරනවා: a) අළුත් වචන සිද්ධා කරන්න, ඉතින් පද්ධතිය තව තො සහ (b) පරීක්ෂණ සෙට්ටුවට ලඟ ඉන්න ප්\u200dරවේශයක් පරීක්ෂණය කරන්න, ඉතින් මොඩේල් හරියට පරික්ෂණය කරන්න පුළුවන්', 'so': 'Warqadan waxaan ku qornaa ADAPT-ka ee loo dhisay Basque-ka-Ingiriis Resource Low MT Evaluation Campaign. Basque waa luqad hoos-resourceed, morphologically-rich. Taasi waxay leedahay dhibaato u ah tusaalaha tarjumidda Neural machine, kaas oo inta badan gaadha bandhig ka wanaagsan marka lagu tababariyo koox badan oo macluumaad. Sidaas darteed, waxaynu isticmaalnay macluumaadka la-talinta si aan u hagno takhasada turjumaadda oo model ah oo lagu dhisay isticmaalka macluumaadka rasmi ah oo kaliya. Furriinkeennu wuxuu isticmaalaa macluumaadyo dib u turjuman: (a) u abuura erayo cusub, si aan nidaamka lagu baran karo macluumaad dheeraad ah; (b) turjuma erayada ku dhow saxda imtixaanka, sidaa darteed samoolka waxaa lagu turjumi karaa si loo turjumo.', 'sv': 'I denna uppsats presenterar vi ADAPT-systemet byggt för baskisk till engelsk lågresurs MT Evaluation Campaign. Baskiska är ett språk med låg resurs och morfologiskt rikt. Detta innebär en utmaning för Neural Machine Translation modeller som vanligtvis uppnår bättre prestanda när de tränas med stora datamängder. Därför använde vi syntetiska data för att förbättra översättningskvaliteten som producerats av en modell byggd med enbart autentiska data. Vårt förslag använder bakåtöversatta data för att: (a) skapa nya meningar, så att systemet kan utbildas med mer data; och (b) översätta meningar som ligger nära testuppsättningen, så att modellen kan finjusteras till det dokument som ska översättas.', 'ta': 'இந்த காகிதத்தில் நாம் பாஸ்க் அமைப்பை காண்பிக்கிறோம் ஆங்கிலத்திற்கு குறைந்த மூலம் MT evaluation campaign. பாஸ்க் ஒரு குறைந்த வளர்ந்த மொழி. இது பெரிய தகவல்களுடன் பயிற்சி செய்யப்பட்ட போது நியூரல் இயந்திரம் மொழிபெயர்ப்பு மாதிரிகளுக்கு ஒரு சவால் ஆகும். ஆகையால், நாங்கள் ஒரு மாதிரி உருவாக்கப்பட்டுள்ள மொழிபெயர்ப்பு தரவை மேம்படுத்த பயன்படுத்தினோம் உண்மையான தகவலை மட் எங்கள் பரிந்துரையின் மீண்டும் மொழிபெயர்ப்பிடப்பட்ட தரவை பயன்படுத்துகிறது: (a) புதிய வாக்கியங்களை உருவாக்கு (b) சோதனை அமைப்புக்கு அருகிலுள்ள வாக்கியங்களை மொழிபெயர்த்து, மாதிரியின் மொழியை மொழிபெயர்க்க முடியும்.', 'ur': 'اس کاغذ میں ہم نے باسک کے لئے ساختہ ADAPT سیسٹم کو انگلیسی کے نیچے رسسوس MT Evaluation Campaign کے لئے پیش کیا ہے. باسک ایک کم رسسورٹ کی زبان ہے۔ یہ نئورل ماشین ترجمہ موڈل کے لئے ایک چال ڈالتا ہے جسے معمولاً بہترین عملکرد حاصل کرتا ہے جب بڑے ڈاکٹوں کے ساتھ تربیت کی جاتی ہے۔ اسی طرح ہم نے سینٹیسی ڈیٹا استعمال کیا ہے کہ ایک موڈل کے ذریعہ پیدا ہوا ترجمہ کیفیت کو بہتر کریں جو صرف حقیقت ڈیٹا کے مطابق بنایا گیا ہے. ہماری پیشنهاد واپس ترجمہ ڈیٹا کو استعمال کرتا ہے: اور (b) عبارت کو ترجمہ کریں جو آزمائش سٹ کے نزدیک ہیں، اس لئے مدل کو ترجمہ کرنا چاہیے۔', 'uz': "Bu hujjatda biz Basque uchun yaratilgan ADAPT tizimini ingliz Resource Low MT Taʼminlovchi Kampaniyaga present qilamiz. Baski juda kichkina murakkab, morfologik hosil tili. Name Shunday qilib, biz faqat haqiqiqiy maʼlumot yordamida tarjima sifatini bajarish uchun foydalanamiz. Бизнинг суҳбатимиз яна таркиб қилинган маълумотларни фойдаланади: (a) yangi so'zlar yaratish, shunday qilib, tizimning ko'proq maʼlumot bilan o'rganishi mumkin; (b) sinov moslamalariga yaqin so'zlarni tarjima qilish mumkin. Bu uchun model hujjatga tarjima qilishi mumkin.", 'vi': 'Trong tờ giấy này chúng tôi giới thiệu hệ thống ADAP được xây dựng cho chiến dịch đánh giá Nguồn Tài nguyên thấp người Basque. Xứ Basque là một ngôn ngữ giàu có có, ít xoay xở. Điều này đặt ra một thách thức cho các mô hình lắp máy thần kinh (thần kinh) Dịch sang thường đạt hiệu suất tốt hơn khi được huấn luyện với các bộ dữ liệu lớn. Do đó, chúng tôi dùng dữ liệu tổng hợp để cải thiện chất lượng dịch sản xuất bởi một mẫu được xây dựng bằng chỉ những dữ liệu chính xác. Đề nghị của chúng tôi sử dụng các dữ liệu dịch ngược để: a) tạo ra các câu mới, để cho hệ thống có thể được đào tạo thêm thông tin; và (b) dịch các câu gần với b ộ thử, để mô hình có thể được chỉnh chính xác theo tài liệu cần dịch.', 'hr': 'U ovom papiru predstavljamo sistem ADAPT izgrađen za baskijsku kampanju za procjenu MT-a za manje resurse na engleskom jeziku. Baskijski je nizak izvor, morfološki bogat jezik. To predstavlja izazov za modele neurološkog prevoda strojeva koji obično postignu bolju učinku kada se obučavaju velikim skupinama podataka. Stoga smo koristili sintetičke podatke kako bi poboljšali kvalitet prevođenja iz model a izgrađenog samo autentičnim podacima. Naš prijedlog koristi natrag prevedeni podaci na: a) stvoriti nove rečenice, kako bi sustav mogao biti obučen s više podataka; i b) prevedite rečenice koje su blizu seta ispitivanja, tako da se model može ispravno uključiti dokumentu za prevedenje.', 'bg': 'В настоящата статия представяме системата АДАПТ, изградена за кампанията за оценка на МТ от баски до английски език с ниски ресурси. Баскът е език с ниски ресурси, морфологично богат. Това представлява предизвикателство за моделите на неврален машинен превод, които обикновено постигат по-добра производителност, когато се обучават с големи набори от данни. Съответно използвахме синтетични данни, за да подобрим качеството на превода, произведено от модел, изграден само с автентични данни. Нашето предложение използва обратно преведени данни за: (а) създаване на нови изречения, така че системата да може да бъде обучена с повече данни; и б) превежда изречения, които са близо до тестовия набор, така че моделът може да бъде фино настроен към документа, който ще бъде преведен.', 'da': 'I denne artikel præsenterer vi ADAPT systemet bygget til baskisk til engelsk lav ressource MT evalueringskampagne. Baskisk er et lavt ressourcebesparende og morfologisk rigt sprog. Dette udgør en udfordring for Neural Machine Translation modeller, som normalt opnår bedre ydeevne, når de trænes med store datasæt. Derfor brugte vi syntetiske data til at forbedre oversættelseskvaliteten produceret af en model, der kun er bygget ud fra autentiske data. Vores forslag bruger back-translated data til at: (a) oprette nye sætninger, så systemet kan trænes med flere data; og (b) oversætte sætninger, der ligger tæt på testsættet, så modellen kan finjusteres til det dokument, der skal oversættes.', 'nl': 'In dit artikel presenteren we het ADAPT systeem gebouwd voor de Baskisch naar Engels Low Resource MT Evaluation Campaign. Baskisch is een taal met weinig middelen en morfologische rijkdom. Dit vormt een uitdaging voor Neural Machine Translation modellen die meestal betere prestaties behalen wanneer ze worden getraind met grote hoeveelheden gegevens. Daarom hebben we synthetische gegevens gebruikt om de vertaalkwaliteit van een model dat uitsluitend gebaseerd is op authentieke gegevens te verbeteren. Ons voorstel maakt gebruik van back-vertaalde data om: (a) nieuwe zinnen te creëren, zodat het systeem getraind kan worden met meer data; en (b) zinnen vertalen die dicht bij de testset liggen, zodat het model kan worden afgestemd op het te vertalen document.', 'id': 'Dalam kertas ini kami memperkenalkan sistem ADAPT yang dibangun untuk Kampanye Evaluasi MT Ressource Rendah Bahasa Baska ke Inggris. Basque is a low-resourced, morphologically-rich language.  Ini merupakan tantangan untuk model Translation Mesin Neural yang biasanya mencapai prestasi yang lebih baik ketika dilatih dengan set besar data. Oleh karena itu, kami menggunakan data sintetis untuk meningkatkan kualitas terjemahan yang diproduksi oleh model yang dibuat hanya menggunakan data autentik. Usaha kami menggunakan data terjemahan kembali untuk: (a) membuat kalimat baru, sehingga sistem dapat dilatih dengan lebih banyak data; dan (b) menerjemahkan kalimat yang dekat dengan set tes, sehingga model dapat disesuaikan dengan dokumen yang akan diterjemahkan.', 'de': 'In diesem Beitrag stellen wir das ADAPT-System vor, das für die baskisch-englisch Low Resource MT Evaluation Campaign entwickelt wurde. Baskisch ist eine Sprache mit geringen Ressourcen, die morphologisch reich ist. Dies stellt eine Herausforderung für Modelle der neuronalen maschinellen Übersetzung dar, die normalerweise bessere Leistung erzielen, wenn sie mit großen Datensätzen trainiert werden. Dementsprechend haben wir synthetische Daten verwendet, um die Übersetzungsqualität eines Modells zu verbessern, das ausschließlich authentische Daten verwendet. Unser Vorschlag verwendet rückübersetzte Daten, um: (a) neue Sätze zu erstellen, damit das System mit mehr Daten trainiert werden kann; und (b) Sätze übersetzen, die nahe am Testsatz liegen, damit das Modell auf das zu übersetzende Dokument abgestimmt werden kann.', 'ko': '본고는 바스크 영어 저자원 기계 번역 평가 활동을 위한 자체 적응 시스템을 소개한다.바스케어는 자원이 부족하고 형태가 풍부한 언어이다.이것은 신경 기계 번역 모델에 도전을 제기했다. 빅데이터 집합을 사용하여 훈련을 할 때 이런 모델은 일반적으로 더욱 좋은 성능을 얻을 수 있다.따라서 우리는 합성 데이터를 사용하여 실제 데이터로만 구축된 모델로 이루어진 번역의 질을 향상시킨다.우리의 건의는 반역 데이터를 사용하는 것이다. (a) 새로운 문장을 만들면 시스템이 더 많은 데이터로 훈련할 수 있다.(b) 테스트 집합에 가까운 문장을 번역하면 모델은 번역할 문서에 따라 미세하게 조정할 수 있다.', 'sw': 'Katika karatasi hii tunaonyesha mfumo wa ADAPT ulioanzishwa kwa ajili ya Basque kwa ajili ya kampeni ya Uchunguzi wa Rasilimali Zisizo ya Kiingereza. Basque ni lugha yenye rasilimali duni, yenye utajiri wa kimaadili. Hii inaleta changamoto kwa mifano ya Tafsiri ya Mashine ya Njerumani ambayo mara nyingi hufanikiwa ufanisi mzuri unapofundishwa na makundi makubwa ya taarifa. Kwa hiyo, tulitumia taarifa za pamoja ili kuboresha ubora wa tafsiri uliotengenezwa na modeli iliyotengenezwa kwa kutumia taarifa za uhalisia tu. pendekezo letu linatumia taarifa zilizotafsiriwa kwa nyuma: (a) kutengeneza sentensi mpya, ili mfumo unaweza kufundishwa kwa takwimu zaidi; na kutafsiri maneno yanayokaribia seti ya jaribio, kwa hiyo mifano inaweza kutumika vizuri kwa waraka kutafsiriwa.', 'fa': 'ما در این کاغذ سیستم ADAPT را برای کمپانی ارزیابی MT منابع کم انگلیسی ساخته می\u200cکنیم. باسک یک زبان کمتری از منابع است که به صورت مورفولوژیک ثروتمند است. این یک چالش برای مدلهای ترجمه ماشین عصبی قرار می دهد که معمولاً هنگامی که با مجموعه های بزرگ داده آموزش داده می شود، عملکرد بهتر را می رساند. به همین دلیل، ما از داده\u200cهای سنتتی استفاده کردیم تا کیفیت ترجمه\u200cای که توسط یک مدل ساخته شده با استفاده از داده\u200cهای حقیقی بهتر شود. پیشنهاد ما از داده\u200cهای عقب ترجمه به: a) جمله\u200cهای جدید ایجاد می\u200cکند، پس سیستم می\u200cتواند با داده\u200cهای بیشتری آموزش داده شود. و (b) جمله\u200cهای نزدیک به مجموعه آزمایش ترجمه می\u200cکند، بنابراین مدل می\u200cتواند به سند ترجمه شود.', 'tr': 'Bu kagyzda biziň ADAPT sistemasyny beýik Ressource MT Taýýarlama kampanýasyna bask üçin guruldyrylýan. Baskça azajyk, morfologik bilen baý dildir. Bu näyral maşynyň terjime nusgasyny üçin kynçylyk bar. Bu nusgasy uly düzüm maglumatlar bilen öňünde has gowy hereket edip bilýär. Şol sebäpli, diňe hakyky maglumatlary ulanan bir nusga tarapyndan üretilen terjime kwalitesini geliştirmek üçin sintetik maglumatlary ulandyk Biziň teklibimiz arka terjime edilen maglumaty şuna ulanýar: we (b) testiň düzümlerine ýakyn sözlerni terjime edip, şonuň üçin modi terjime edilmeli senediň üstine hat edilsin.', 'sq': 'Në këtë letër paraqesim sistemin ADAPT të ndërtuar për kampanjën Baske në Anglisht të vlerësimit të MT me burime të ulta. Basku është një gjuhë e pasur me burime të ulta dhe morfologjike. Kjo paraqet një sfidë për modelet e Translacionit të Makinës Neurale që zakonisht arrijnë performancë më të mirë kur trajnohen me grupe të mëdha të dhënash. Sipas kësaj, përdorëm të dhëna sintetike për të përmirësuar cilësinë e përkthimit prodhuar nga një model i ndërtuar duke përdorur vetëm të dhëna autentike. Propozimi ynë përdor të dhëna të përkthyera prapa për: (a) të krijojë fjalime të reja, kështu që sistemi mund të trajnohet me më shumë të dhëna; and (b) translate sentences that are close to the test set, so the model can be fine-tuned to the document to be translated.', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք ADAPT համակարգը, որը կառուցվել է Բասկի և Անգլերենի ցածր ռեսուրսների MT գնահատման քարոզարշավի համար: Բասկը ցածր ռեսուրսների, մորֆոլոգիապես հարուստ լեզու է: Սա մարտահրավեր է առաջացնում նյարդային մեքենայի թարգմանման մոդելների համար, որոնք սովորաբար ավելի լավ արդյունք են ստանում, երբ ուսուցանվում են մեծ տվյալների համակարգերով: Հետևաբար, մենք օգտագործեցինք սինթետիկ տվյալներ թարգմանության որակի բարելավման համար, որը ստեղծվել է մի մոդելի միջոցով, որը ստեղծվել է միայն իրական տվյալներ օգտագործելով: Մեր առաջարկությունը օգտագործում է վերադարձ թարգմանված տվյալներ՝ a) ստեղծելու նոր նախադասություններ, որպեսզի համակարգը կարողանա սովորել ավելի շատ տվյալներով: և (b) թարգմանել նախադասությունները, որոնք մոտ են փորձարկումների սահմանին, այնպես որ մոդելը կարելի է լավ համապատասխանել թարգմանելու փաստաթղթին:', 'am': 'በዚህ ገጾች ውስጥ ለባስክ የደረገውን ADAPT ስርዓት ወደ ኢንግሊዝኛ ታናሽ የኢንጂልኛ ዕቃ MT አረጋጋጭ ዘመቻ እናቀርባለን፡፡ ባስክ የጎደለው፣ የሞሮፎሎጂ ባለጠጋ ቋንቋ ነው፡፡ ይህ የናውሬል መኪን ትርጉም ሞዴላዎችን የሚያሳውቅ ጥቃት ነው፡፡ ስለዚህም በአስረንጋዊ ዳታ ብቻ በመጠቀም በሞዴል የተዘጋጀውን ትርጉም ጥሩ ለማድረግ ተጠቃሚ ነበር፡፡ አዲስ ቃላት መፍጠር ይችላል፣ የስርዓት ዳታዎችን ለመጠቀም ይችላል፡፡ እና (b) ፈተናው ማዘጋጀት የሚቀርቡትን ቃላት ትርጉም፤ ሞዴል ለሰነዱ ለመትረጉም ይችላል፡፡', 'af': "In hierdie papier vertoon ons die ADAPT stelsel gebou vir die Baske na Engels Lae Hulpbron MT Evaluering Kampanie. Baske is 'n lae hulpbron, morfologiese ryk taal. Hierdie stel 'n uitdrukking vir Neural Masjien Vertaling Modelle wat gewoonlik beter uitdrukking bereik wanneer opgelei word met groot stelle data. Ons het dus sintetiese data gebruik om die vertalingskwaliteit te verbeter wat deur 'n model gebou word deur slegs outentiese data te gebruik. Ons voorstel gebruik terugvertaalde data na: (a) skep nuwe teikens, sodat die stelsel kan onderwerp word met meer data; en (b) vertaling setinge wat naby die toets stel is, sodat die model kan fyn-tuned wees na die dokument om vertaling te word.", 'bn': 'এই কাগজটিতে আমরা বাস্কের জন্য বাস্কে নির্মিত এডিএপিটি সিস্টেম উপস্থাপন করছি ইংরেজি থেকে নিম্ন রিসোর্স এমটি ইন বাস্ক একটি কম সম্পদ, মর্ফোলজিক-সমৃদ্ধ ভাষা। এটি নিউরাল মেশিন অনুবাদ মডেলের জন্য একটি চ্যালেঞ্জ যা সাধারণত বিশাল তথ্যের প্রশিক্ষণ দিয়ে ভালো প্রদর্শন করে। তাই, আমরা সিন্টেটিক ডাটা ব্যবহার করেছি অনুবাদের মান উন্নত করার জন্য, যা একটি মডেল তৈরি করেছে তা শুধুমাত্র সত্যিকারী  আমাদের প্রস্তাব পুনরাবৃত্তির তথ্য ব্যবহার করে: (a) নতুন বাক্য তৈরি করুন, যাতে সিস্টেম আরো তথ্য দিয়ে প্রশিক্ষণ প এবং (b) টেস্ট সেটের কাছাকাছি কাছাকাছি বাক্য অনুবাদ করুন, যাতে এই নথিটি অনুবাদ করতে পারে।', 'az': 'Bu kağıtda baskı üçün İngilizə Aşağı Kaynağı MT Evaluasyon Kampağına inşa edilmiş ADAPT sistemini göstəririk. Basque düşük-düşük, morfolojik-zengin dildir. Bu, böyük məlumatlar ilə təhsil edildiyi zaman daha yaxşı performans edəcək Neural Machine Translation modellərinin çətinliklərini göstərir. Beləliklə, sadəcə həqiqi məlumatlar vasitəsilə inşa edilmiş modellərdən ürəklənmiş çeviri kalitetini yaxşılaşdırmaq üçün sintetik məlumatları kullandıq. Bizim teklifimiz geri çevirilmiş məlumatları istifadə edir: a) yeni cümlələr yarat, böylece sistemi daha çox məlumatla təhsil edilə bilər; və b) sınama quruluğuna yaxın olan cümlələri tərcümə edir, b öylece modeli tərcümə ediləcək dökümə tərcümə edilə bilər.', 'ca': "En aquest article presentem el sistema ADAPT construït per a la Campania d'Evaluació de MT de baix recursos vasc a anglès. Basque is a low-resourced, morphologically-rich language.  Això representa un repte per als models de traducció de màquines neuronals que normalment aconsegueixen millor rendiment quan s'entrenen amb grans conjunts de dades. Per tant, vam utilitzar dades sintètiques per millorar la qualitat de traducció produïda per un model construït només fent servir dades autèntiques. La nostra proposta utilitza dades retrotraduïdes per a: a) crear frases noves, per tal que el sistema pugui ser entrenat amb més dades; i b) traduir frases que són properes del conjunt de proves, per tal que el model es pugui ajustar fins al document a traduir.", 'cs': 'V tomto článku představujeme systém ADAPT vytvořený pro baskicko-anglickou Low Resource MT Evaluation Campaign. Baskičtina je nízké zdroje, morfologicky bohatý jazyk. To představuje výzvu pro modely neuronového strojového překladu, které obvykle dosahují lepšího výkonu při tréninku s velkými množinami dat. Proto jsme použili syntetická data ke zlepšení kvality překladu vytvořeného modelem sestaveným pouze z autentických dat. Náš návrh využívá zpětně přeložená data k: (a) vytvoření nových vět, aby systém mohl být trénován s více dat; a b) překládat věty, které jsou blízko testovací sady, takže model může být jemně naladěn na dokument, který má být přeložen.', 'bs': 'U ovom papiru predstavljamo sistem ADAPT izgrađen za baskijsku kampanju za procjenu MT-a za manje resurse. Bask je nisko sredstvo, morfološki bogat jezik. To predstavlja izazov za modele neurološkog prevoda strojeva koji obično postignu bolju učinku kada su obučeni velikim skupinama podataka. Stoga smo koristili sintetičke podatke kako bi poboljšali kvalitet prevođenja iz model a izgrađenog samo autentičnim podacima. Naš prijedlog koristi ponovno prevedeni podaci na: a) stvoriti nove rečenice, tako da sistem može biti obučen sa više podataka; i b) prevedite rečenice koje su blizu seta testa, tako da se model može dobro uključiti dokumentu prevedeno.', 'et': 'Käesolevas töös tutvustame ADAPT süsteemi, mis on ehitatud baski-inglise madala ressursiga MT hindamise kampaania jaoks. Baski keel on madala ressursiga ja morfoloogiliselt rikas keel. See kujutab endast väljakutset neuromasintõlke mudelitele, mis tavaliselt saavutavad suuremate andmekogumitega koolitamisel parema jõudluse. Sellest tulenevalt kasutasime sünteetilisi andmeid tõlkekvaliteedi parandamiseks, mis on toodetud ainult autentsete andmete abil. Meie ettepanekus kasutatakse tagasitõlgitud andmeid, et: a) luua uusi lauseid, et süsteemi saaks koolitada rohkem andmeid; ja (b) tõlkida lauseid, mis on lähedal testikomplekti, nii et mudelit saab täpselt häälestada tõlgitava dokumendiga.', 'fi': 'T채ss채 artikkelissa esittelemme ADAPT-j채rjestelm채n, joka rakennettiin Baskimaan ja Englantiin Low Resource MT Evaluation Campaign -kampanjalle. Baski on v채h채resurssinen ja morfologisesti rikas kieli. T채m채 on haaste neurokonek채채nn철smalleille, jotka yleens채 saavuttavat paremman suorituskyvyn, kun niit채 koulutetaan suurilla tietojoukoilla. N채in ollen hy철dynsimme synteettist채 dataa parantaaksemme vain aitoa dataa hy철dynt채v채n mallin tuottamaa k채채nn철slaatua. Ehdotuksessamme k채ytet채채n taaksep채in k채채nnettyj채 tietoja: (a) luodaan uusia lauseita, jotta j채rjestelm채채 voidaan kouluttaa enemm채n tietoja; ja (b) k채채nt채채 lauseita, jotka ovat l채hell채 testijoukkoa, jotta malli voidaan hienos채채t채채 k채채nnett채v채채n asiakirjaan.', 'he': 'בעיתון הזה אנו מציגים את מערכת ADAPT שנבנתה עבור קמפיין הערכה באנגלית למקורים נמוכים MT. בסקית היא שפה עשירה במקורים נמוכים ומורפולוגיים. זה יוצר אתגר עבור דוגמני התרגום של מכונות נוירות שבדרך כלל משיגים ביצועים טובים יותר כאשר מאומנים עם קבוצות גדולות של נתונים. לכן השתמשנו במידע סינטטי כדי לשפר את איכות התרגום שנוצרה על ידי דוגמא שנבנה בשימוש רק נתונים אמיתיים. הצעה שלנו משתמשת בנתונים מתרגמים אחורה כדי: a) ליצור משפטים חדשים, כך שהמערכת יכולה להיות מאומנת עם יותר נתונים; (b) לתרגם משפטים קרובים לסט הבדיקות, כך שהדוגמן יכול להתאים למסמך שיתרגום.', 'ha': "Ga wannan takardan da Muke iya gabatar da AADATT na'urar da aka gina wa Basque zuwa Ingiriya Low Resource MT Bayan Aiki. Basque is a low-resourced, morphologically-rich language.  Wannan yana da wata ƙudura wa misãlai masu Translate na Kijeri na Neural, wanda ko da ya ƙunsa da mafiya kyau a lokacin da aka sanar da shi da tsari masu yawa. Wancan, mun yi amfani da data na haɗi dõmin mu kyautata tsarin fassarar da wani motel wanda aka samar da shi, ana yi amfani da data masu inganci kawai. Dakatanmu yana amfani da data masu fassarwa da aka sake-fassarwa zuwa: (a) ka sami tsarin da za'a sanar da shi na ƙaranci; Kuma ka sarrafa kalmõmi waɗanda ke mafi kusantar da tsarin jarraba, dõmin an iya iya daidaita misalin kowandan takardar da za'a fassara.", 'sk': 'V prispevku predstavljamo sistem ADAPT, zgrajen za akcijo ocenjevanja MT nizkih virov baskovsko-angleško. Baskovščina je jezik z nizkimi viri, morfološko bogat. To predstavlja izziv za modele nevralnega strojnega prevajanja, ki običajno dosegajo boljšo zmogljivost pri usposabljanju z velikimi nabori podatkov. V skladu s tem smo uporabili sintetične podatke za izboljšanje kakovosti prevodov, ki ga je izdelal model, zgrajen samo z avtentičnimi podatki. Naš predlog uporablja nazaj prevedene podatke za: (a) ustvarjanje novih stavkov, da se sistem lahko usposablja z več podatki; in (b) prevajajo stavke, ki so blizu preskusnega nabora, tako da je model mogoče natančno prilagoditi dokumentu, ki ga je treba prevesti.', 'jv': 'Nang pepulan iki kita nggawe sistem DEPAT sing nggawe kanggo Kemerdekaan Basque kanggo Kemerdekaan MT Kemerdekaan Pasir Basque kuwi basa sing paling kelas, kuwi mangka-alah banget. Iki sampeyan akeh perbudhakan kanggo model penting Neral Masine Tulung dhéwé iso nggawe barang sing luwih dumadhi karo data sing gawe kudu ditulak bantuan. slot Isoporungu punika menehi kelas-terjamahan kanggo: :a) gawe barang-terjamahan karo data anyar, dadi sistem iso disenyong karo data yang terus-terjamahan; Tanggal', 'bo': 'འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་རྒྱ་ནག་ཡིག་གི་ཚད་ལུས་པ་ཇུས་མཐུན་གྱི་རྒྱུ་མཚན་ལ་བཟོ་བཀོད་པ་ཡིན། བྷ་སིཀ་ནི་གཟུགས་རིས་འདི་ལྕགས་ཅན་མེད་པ་ཞིག་རེད། འདིས་Neural Machine་ཡིག་སྒྲུབ་ཀྱི་མ་དབྱིབས་ལ་གདོང་ལེན་དགོས་པ་ཞིག་ཡིན་པས་རྒྱུན་ལྡན་སྔར་སྒྲིག་ཡིག་ཆ་གསལ་གྲ འུ་ཅག་གིས་དབྱིབས་བདེ་རིགས་གནས་ཚུལ་གསལ་བཤད་བྱས་པ ང་ཚོའི་བསམ (b) བརྟག་ཞིབ་ཀྱི་སྒྲིག་འཛུགས་ཀྱི་སྒོ་རྒྱག་ཡོད་པའི་ཚིག་རྐང་འདིའི་ནང་ལྟ་བུ་འཇུག་བྱེད་དགོས།'}
{'en': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task M e MAD  Submission to the  IWSLT  2018 Speech Translation Task', 'es': 'La presentación de MeMAD a la tarea de traducción de voz de IWSLT 2018', 'fr': 'La soumission MeMad à la tâche de traduction vocale IWSLT 2018', 'ar': 'تقديم MeMAD إلى مهمة ترجمة الكلام IWSLT 2018', 'pt': 'O envio do MeMAD para a tarefa de tradução de fala do IWSLT 2018', 'ja': 'IWSLT 2018スピーチ翻訳タスクへのMeMAD提出', 'zh': 'MeMAD 向 IWSLT 2018 音译', 'hi': 'IWSLT 2018 वाक् अनुवाद कार्य के लिए MeMAD सबमिशन', 'ru': 'Заявка MeMAD на выполнение задачи по переводу речи IWSLT 2018', 'ga': 'Aighneacht MeMAD chuig Tasc Aistriúcháin Cainte IWSLT 2018', 'ka': 'MeMAD-ს IWSLT 2018 წერილის გადაწყვეტა საქმე', 'hu': 'A MeMAD benyújtása az IWSLT 2018 beszédfordítási feladatra', 'el': 'Η υποβολή του MeMAD στο έργο μετάφρασης ομιλίας του IWSLT 2018', 'kk': 'MeMAD IWSLT 2018 сөзді аудару тапсырмасына жіберу', 'mk': 'Предавањето на MeMAD на IWSLT 2018 задачата за преведување на говорот', 'it': 'La presentazione MeMAD al compito di traduzione vocale IWSLT 2018', 'ml': 'IWSLT 2018 സംസാരിക്കുന്നതിനുള്ള മെമാഡി സബ്മിഷന്\u200d', 'ms': 'Penghantaran MeMAD ke Tugas Terjemahan Cahaya IWSLT 2018', 'mt': 'Is-sottomissjoni tal-MeMAD lill-IWSLT 2018 Speech Translation Task', 'lt': 'MeMAD pristatymas 2018 m. IWSLT kalbos vertimo uždaviniui', 'ro': 'Transmiterea MeMAD la sarcina de traducere a discursului IWSLT 2018', 'no': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task', 'mn': 'MeMAD-ын IWSLT 2018-н ярианы хөгжлийн даалгавар', 'pl': 'Zgłoszenie MeMAD do zadania tłumaczenia mowy IWSLT 2018', 'so': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task', 'sr': 'MeMAD podmission na IWSLT 2018 prevod govora', 'sv': 'MeMAD-inlämningen till IWSLT 2018 Talöversättning Uppgift', 'si': 'The MeMAD Sub-Mision to the IWSLT 2018 Talk translation Job', 'ur': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task', 'ta': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task', 'uz': 'Name', 'vi': 'Sự đệ trình của Memad cho the IWSLT 208 cú dịch Ngôn ngữ', 'bg': 'Представянето на МеМАД в задачата за превод на реч', 'hr': 'MeMAD podmission na IWSLT 2018 govorni prevodni zadatak', 'da': "MeMAD's indsendelse til IWSLT 2018 Taleoversættelsesopgave", 'nl': 'De MeMAD inzending aan de IWSLT 2018 Speech Translation Task', 'id': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task', 'de': 'Die MeMAD-Einreichung bei der IWSLT 2018 Speech Translation Task', 'ko': 'Memad가 2018년 국제언어문자번역대회에 제출한 강연 번역 임무', 'tr': 'MeMAD Submission to the IWSLT 2018 Speech Translation Task', 'fa': 'مأموریت MeMAD برای ترجمه سخنرانی IWSLT ۲۰۱۸', 'sw': 'Ujumbe wa MeMAD kwa IWSLT 2018 Kazi ya Tafsiri ya Utafiti', 'af': 'Die MeMAD Submission na die IWSLT 2018 Speech Translation Task', 'sq': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task', 'am': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task', 'hy': 'MeMAD-ի հանձնարարությունը IwPLT 2018 թվականի խոսքի թարգմանման առաջադրանքին', 'az': 'MeMAD 캻WSLT 2018 S칬z 칂eviri G칬z톛li', 'bn': 'IWSLT ২০১৮ ভাষার অনুবাদ কাজে মেমাড সাবিমিশন', 'ca': 'La MeMAD Submission a la IWSLT 2018 Speech Translation Task', 'cs': 'Předložení MeMAD k úkolu překladu řeči IWSLT 2018', 'et': 'MeMAD esitamine IWSLT 2018 kõne tõlke ülesandele', 'fi': 'MeMAD-aineisto IWSLT 2018 PuhekĂ¤Ă¤nnĂ¶stehtĂ¤vĂ¤Ă¤n', 'bs': 'MeMAD podmission na IWSLT 2018 govorni prevodni zadatak', 'jv': 'Submis MeMAD kanggo IWSLT 2008 Terjamahan kanggo Terjamahan', 'ha': 'The MeMAD Submit to the IWSLT 2018 Spelling translation job', 'sk': 'Predložitev MeMAD za nalogo prevajanja govora IWSLT 2018', 'he': 'ההעברה של MeMAD למשימה של IWSLT 2018', 'bo': 'The MeMAD Submission to the IWSLT 2018 Speech Translation Task'}
{'en': 'This paper describes the MeMAD project entry to the IWSLT Speech Translation Shared Task, addressing the translation of English audio into German text. Between the  pipeline  and end-to-end model tracks, we participated only in the former, with three contrastive systems. We tried also the latter, but were not able to finish our end-to-end model in time. All of our systems start by transcribing the audio into text through an automatic speech recognition (ASR) model trained on the TED-LIUM English Speech Recognition Corpus (TED-LIUM). Afterwards, we feed the transcripts into English-German text-based neural machine translation (NMT) models. Our systems employ three different translation models trained on separate training sets compiled from the English-German part of the TED Speech Translation Corpus (TED-TRANS) and the OPENSUBTITLES2018 section of the OPUS collection. In this paper, we also describe the experiments leading up to our final  systems . Our experiments indicate that using OPENSUBTITLES2018 in training significantly improves  translation  performance. We also experimented with various preand postprocessing routines for the NMT module, but we did not have much success with these. Our best-scoring system attains a BLEU score of 16.45 on the test set for this year’s task.', 'ar': 'تصف هذه الورقة إدخال مشروع MeMAD إلى المهمة المشتركة لترجمة الكلام IWSLT ، وتتناول ترجمة الصوت الإنجليزي إلى نص ألماني. بين خطوط الأنابيب ومسارات النموذج من طرف إلى طرف ، شاركنا فقط في الأول ، مع ثلاثة أنظمة متباينة. لقد جربنا أيضًا الخيار الأخير ، لكننا لم نتمكن من إنهاء نموذجنا الشامل في الوقت المناسب. تبدأ جميع أنظمتنا بنسخ الصوت إلى نص من خلال نموذج التعرف التلقائي على الكلام (ASR) المدرب على مجموعة TED-LIUM English Speech Recognition Corpus (TED-LIUM). بعد ذلك ، نقوم بتغذية النصوص في نماذج الترجمة الآلية العصبية (NMT) القائمة على النصوص الإنجليزية-الألمانية. تستخدم أنظمتنا ثلاثة نماذج ترجمة مختلفة مدربة على مجموعات تدريب منفصلة تم تجميعها من الجزء الإنجليزي-الألماني من مجموعة TED Speech Translation Corpus (TED-TRANS) وقسم OPENSUBTITLES2018 من مجموعة OPUS. في هذه الورقة ، نصف أيضًا التجارب التي أدت إلى أنظمتنا النهائية. تشير تجاربنا إلى أن استخدام OPENSUBTITLES2018 في التدريب يحسن أداء الترجمة بشكل كبير. لقد جربنا أيضًا العديد من الإجراءات الروتينية السابقة والمعالجة اللاحقة لوحدة NMT ، لكن لم نحقق نجاحًا كبيرًا في هذه الإجراءات. حصل نظامنا الأفضل على الدرجات على درجة BLEU البالغة 16.45 في مجموعة الاختبار لمهمة هذا العام.', 'pt': 'Este artigo descreve a entrada do projeto MeMAD para a Tarefa Compartilhada de Tradução de Fala do IWSLT, abordando a tradução de áudio em inglês para texto em alemão. Entre as trilhas de pipeline e modelo de ponta a ponta, participamos apenas da primeira, com três sistemas contrastantes. Tentamos também o último, mas não conseguimos terminar nosso modelo de ponta a ponta a tempo. Todos os nossos sistemas começam transcrevendo o áudio em texto por meio de um modelo de reconhecimento automático de fala (ASR) treinado no TED-LIUM English Speech Recognition Corpus (TED-LIUM). Depois, alimentamos as transcrições em modelos de tradução automática neural (NMT) baseada em texto inglês-alemão. Nossos sistemas empregam três modelos de tradução diferentes treinados em conjuntos de treinamento separados compilados da parte inglês-alemão do TED Speech Translation Corpus (TED-TRANS) e da seção OPENSUBTITLES2018 da coleção OPUS. Neste artigo, também descrevemos os experimentos que levaram aos nossos sistemas finais. Nossos experimentos indicam que o uso de OPENSUBTITLES2018 no treinamento melhora significativamente o desempenho da tradução. Também experimentamos várias rotinas de pré e pós-processamento para o módulo NMT, mas não tivemos muito sucesso com elas. Nosso sistema de melhor pontuação atinge uma pontuação BLEU de 16,45 no teste definido para a tarefa deste ano.', 'es': 'Este documento describe la entrada del proyecto MeMad a la tarea compartida de traducción de voz de IWSLT, que aborda la traducción de audio en inglés a texto alemán. Entre el oleoducto y el modelo de principio a fin, participamos solo en el primero, con tres sistemas contrastivos. También probamos lo último, pero no pudimos terminar nuestro modelo de principio a fin a tiempo. Todos nuestros sistemas comienzan por transcribir el audio en texto a través de un modelo de reconocimiento automático de voz (ASR) entrenado en el Corpus de reconocimiento de voz en inglés TED-LIUM (TED-LIUM). Después, incorporamos las transcripciones a modelos de traducción automática neuronal (NMT) basada en texto inglés-alemán. Nuestros sistemas emplean tres modelos de traducción diferentes entrenados en conjuntos de capacitación separados compilados a partir de la parte inglés-alemán del Corpus de traducción de voz de TED (TED-TRANS) y la sección OPENSUBTITLES2018 de la colección OPUS. En este artículo, también describimos los experimentos que condujeron a nuestros sistemas finales. Nuestros experimentos indican que el uso de OPENSUBTITLES2018 en la formación mejora significativamente el rendimiento de la traducción. También experimentamos con varias rutinas de preprocesamiento y postprocesamiento para el módulo NMT, pero no tuvimos mucho éxito con ellas. Nuestro sistema de mejor puntuación obtiene una puntuación BLEU de 16,45 en el conjunto de pruebas para la tarea de este año.', 'fr': "Cet article décrit l'entrée du projet MeMad pour la tâche partagée de traduction vocale IWSLT, qui traite de la traduction de l'audio anglais en texte allemand. Entre le pipeline et les pistes de modèles de bout en bout, nous n'avons participé qu'au premier, avec trois systèmes contrastifs. Nous avons également essayé ce dernier, mais nous n'avons pas pu terminer notre modèle de bout en bout à temps. Tous nos systèmes commencent par transcrire l'audio en texte grâce à un modèle de reconnaissance vocale automatique (ASR) formé sur le TED-LIUM English Speech Recognition Corpus (TED-LIUM). Ensuite, nous introduisons les transcriptions dans des modèles de traduction automatique neuronale (NMT) basés sur du texte anglais-allemand. Nos systèmes utilisent trois modèles de traduction différents formés sur des ensembles de formation distincts compilés à partir de la partie anglais-allemand du TED Speech Translation Corpus (TED-TRANS) et de la section OPENSUBTITLES2018 de la collection OPUS. Dans cet article, nous décrivons également les expériences qui ont mené à nos systèmes finaux. Nos expériences indiquent que l'utilisation d'OPENSUBTITLES2018 dans le cadre de la formation améliore considérablement les performances de traduction. Nous avons également expérimenté diverses routines de prétraitement et de post-traitement pour le module NMT, mais nous n'avons pas eu beaucoup de succès avec celles-ci. Notre meilleur système de notation obtient un score BLEU de 16,45 sur l'ensemble de tests pour la tâche de cette année.", 'ja': '本稿では、IWSLT音声翻訳共有タスクへのMeMADプロジェクトエントリについて説明し、英語音声のドイツ語テキストへの翻訳に取り組む。 パイプラインとエンドツーエンドのモデルトラックの間には、前者のみに参加し、3つの対照的なシステムを備えていました。 後者も試しましたが、エンドツーエンドのモデルを間に合わせることができませんでした。 私たちのシステムのすべては、TED - LIUM英語音声認識コーパス（ TED - LIUM ）でトレーニングされた自動音声認識（ ASR ）モデルを通じて音声をテキストに転記することから始まります。 その後、英語とドイツ語のテキストベースのニューラル機械翻訳（ NMT ）モデルにトランスクリプトをフィードします。 当社のシステムは、TED音声翻訳コーパス（ TED - TRANS ）の英語-ドイツ語部分と、OPUSコレクションのOPENSUBTITLES 2018セクションから編纂された個別のトレーニングセットでトレーニングされた3つの異なる翻訳モデルを採用しています。 本稿では、最終システムに至るまでの実験についても述べる。 当社の実験によると、OPENSUBTITLES 2018をトレーニングで使用すると、翻訳パフォーマンスが大幅に向上します。 また、NMTモジュールのさまざまな前後処理ルーチンを実験しましたが、あまり成功していませんでした。 当社のベストスコアリングシステムは、今年のタスクのテストセットで16.45のBLEUスコアを達成します。', 'hi': 'यह पेपर IWSLT वाक् अनुवाद साझा कार्य के लिए MeMAD प्रोजेक्ट प्रविष्टि का वर्णन करता है, जर्मन पाठ में अंग्रेजी ऑडियो के अनुवाद को संबोधित करता है। पाइपलाइन और एंड-टू-एंड मॉडल ट्रैक के बीच, हमने केवल तीन कंट्रास्टिव सिस्टम के साथ पूर्व में भाग लिया। हमने उत्तरार्द्ध की भी कोशिश की, लेकिन समय पर हमारे एंड-टू-एंड मॉडल को खत्म करने में सक्षम नहीं थे। हमारे सभी सिस्टम एक स्वचालित भाषण मान्यता (एएसआर) मॉडल के माध्यम से ऑडियो को पाठ में ट्रांसक्राइब करके शुरू होते हैं, जो TED-LIUM अंग्रेजी भाषण पहचान कॉर्पस (TED-LIUM) पर प्रशिक्षित होता है। इसके बाद, हम अंग्रेजी-जर्मन पाठ-आधारित तंत्रिका मशीन अनुवाद (एनएमटी) मॉडल में टेपों को खिलाते हैं। हमारी प्रणालियां टेड स्पीच ट्रांसलेशन कॉर्पस (टेड-ट्रांस) के अंग्रेजी-जर्मन भाग और OPUS संग्रह के OPENSUBTITLES2018 अनुभाग से संकलित अलग-अलग प्रशिक्षण सेटों पर प्रशिक्षित तीन अलग-अलग अनुवाद मॉडलों को नियोजित करती हैं। इस पेपर में, हम अपने अंतिम प्रणालियों तक पहुंचने वाले प्रयोगों का भी वर्णन करते हैं। हमारे प्रयोगों से संकेत मिलता है कि प्रशिक्षण में OPENSUBTITLES2018 का उपयोग करने से अनुवाद प्रदर्शन में काफी सुधार होता है। हमने एनएमटी मॉड्यूल के लिए विभिन्न प्री और पोस्टप्रोसेसिंग रूटीन के साथ भी प्रयोग किया, लेकिन हमें इनके साथ बहुत सफलता नहीं मिली। हमारी सर्वश्रेष्ठ स्कोरिंग प्रणाली इस वर्ष के कार्य के लिए निर्धारित परीक्षण पर 16.45 का BLEU स्कोर प्राप्त करती है।', 'zh': '本文引 IWSLT 语音译共事者 MeMAD 项目条目,决英语音频翻译成德语文本。 在管道和端到端模样轨道之间,我们只参加了前者,有三个对比系统。 我亦尝后者,未及成端的到端。 凡诸系统,皆先于TED-LIUM英语语音识语料库(TED-LIUM)上自语音识(ASR)将音频转录成文本。 已,输成绩单于英语-德语文本神经机器翻译 (NMT) 中。 吾统用三译,异集上而教之,从 TED 音译语料库 (TED-TRANS) 之英语-德语,与 OPUS 合 OPENSUBTITLES2018 编译来也。 本文之中,犹言致实验。 臣等实验明, OPENSUBTITLES2018 著译性。 又试 NMT 模块诸预处理、后处理例,然未有成功者。 最佳评分系今年试集上得16.45BLEU分。', 'ru': 'В этой статье описывается запись проекта MeMAD в общую задачу по переводу речи IWSLT, касающуюся перевода английского аудио на немецкий текст. Между трассами трубопровода и сквозной модели мы участвовали только в первой, с тремя контрастными системами. Мы также попробовали последнее, но не смогли закончить нашу сквозную модель вовремя. Все наши системы начинаются с транскрипции аудио в текст с помощью модели автоматического распознавания речи (ASR), обученной на TED-LIUM English Speech Recognition Corpus (TED-LIUM). Затем мы вводим расшифровки в англо-немецкие текстовые модели нейронного машинного перевода (НМП). Наши системы используют три различные модели перевода, обученные на отдельных обучающих наборах, составленных из англо-немецкой части TED Speech Translation Corpus (TED-TRANS) и раздела OPENSUBTITLES2018 коллекции OPUS. В этой статье мы также описываем эксперименты, ведущие к нашим конечным системам. Наши эксперименты показывают, что использование OPENSUBTITLES2018 в обучении значительно улучшает показатели перевода. Мы также экспериментировали с различными процедурами предварительной и последующей обработки для модуля NMT, но у нас не было большого успеха с ними. Наша система лучших баллов набрала 16,45 балла BLEU на тестовом наборе для задачи этого года.', 'ga': 'Déanann an páipéar seo cur síos ar iontráil thionscadal MeMAD chuig Tasc Comhroinnte Aistriú Cainte IWSLT, ag tabhairt aghaidh ar aistriú fuaime Béarla go téacs Gearmáinise. Idir an phíblíne agus rianta múnla deireadh go deireadh, ní raibh muid rannpháirteach ach sa chéad cheann, le trí chóras codarsnachta. Rinneamar iarracht ar an dara ceann freisin, ach ní raibh muid in ann ár múnla ceann go ceann a chríochnú in am. Tosaíonn ár gcórais go léir tríd an fhuaim a thras-scríobh go téacs trí mhúnla uathoibríoch aitheantais cainte (ASR) atá oilte ar an TED-LIUM English Speech Recognition Corpus (TED-LIUM). Ina dhiaidh sin, cuirimid na tras-scríbhinní i múnlaí aistriúchán meaisín néareolaíoch téacsbhunaithe Béarla-Gearmáinis (NMT). Úsáideann ár gcórais trí mhúnla aistriúcháin éagsúla atá oilte ar thacair oiliúna ar leith a tiomsaíodh ón gcuid Béarla-Gearmáinis den TED Speech Translation Corpus (TED-TRANS) agus an chuid OPENSUBTITLES2018 de bhailiúchán OPUS. Sa pháipéar seo, déanaimid cur síos freisin ar na turgnaimh roimh ár gcórais deiridh. Léiríonn ár dturgnaimh go bhfeabhsaítear feidhmíocht aistriúcháin go suntasach trí OPENSUBTITLES2018 a úsáid in oiliúint. Rinneamar trialacha freisin le gnáthaimh réamhphróiseála éagsúla agus iarphróiseála don mhodúl NMT, ach níor éirigh go maith linn leo seo. Tá scór BLEU 16.45 bainte amach ag ár gcóras scórála is fearr ar an triail a bhí leagtha síos do thasc na bliana seo.', 'el': 'Η παρούσα εργασία περιγράφει την είσοδο του έργου MeMAD στην κοινή εργασία μετάφρασης ομιλίας του IWSLT, που αφορά τη μετάφραση του αγγλικού ήχου σε γερμανικό κείμενο. Μεταξύ του αγωγού και των τροχών μοντέλων, συμμετείχαμε μόνο στο πρώτο, με τρία αντίθετα συστήματα. Προσπαθήσαμε και το τελευταίο, αλλά δεν μπορέσαμε να τελειώσουμε εγκαίρως το μοντέλο μας. Όλα τα συστήματά μας ξεκινούν με τη μεταγραφή του ήχου σε κείμενο μέσω ενός μοντέλου αυτόματης αναγνώρισης ομιλίας (ASR) εκπαιδευμένου στο Σώμα αναγνώρισης Αγγλικής ομιλίας TED-LIUM (TED-LIUM). Στη συνέχεια, τροφοδοτούμε τα μεταγραφικά σε μοντέλα νευρωνικής μηχανικής μετάφρασης (NMT) που βασίζονται στην αγγλική-γερμανική γλώσσα. Τα συστήματά μας χρησιμοποιούν τρία διαφορετικά μοντέλα μετάφρασης εκπαιδευμένα σε ξεχωριστά εκπαιδευτικά σύνολα που καταρτίζονται από το αγγλο-γερμανικό τμήμα του Σώματος Μεταφρασής Λόγου TED (TED-TRANS) και το τμήμα OPENSUBTITLES2018 της συλλογής OPUS. Στην παρούσα εργασία περιγράφουμε επίσης τα πειράματα που οδηγούν στα τελικά μας συστήματα. Τα πειράματά μας δείχνουν ότι η χρήση στην εκπαίδευση βελτιώνει σημαντικά τις μεταφραστικές επιδόσεις. Πειραματιστήκαμε επίσης με διάφορες ρουτίνες προ και μετά επεξεργασίας για την ενότητα αλλά δεν είχαμε μεγάλη επιτυχία με αυτές. Το σύστημα καλύτερης βαθμολογίας μας επιτυγχάνει βαθμολογία 16.45 στο σετ δοκιμών για το φετινό έργο.', 'ka': 'ამ წიგნის შეტყობინება MeMAD პროექტის შეტყობინება IWSLT წიგნის გასაგულისხმების გასაგულისხმების გასაგულისხმების გასაგულისხმებისთვის, რომელიც ინგლისური ауდი ჩვენ მხოლოდ მხოლოდ მხოლოდ პირველი, სამი კონტრასტური სისტემებით დავწყებდით. ჩვენ ასევე შემდეგ დავცდილოთ, მაგრამ არ შეგვიძლია გადასრულოთ ჩვენი დასრულებული მოდელი დროში. ყველა ჩვენი სისტემი დავიწყება ტექსტში ავტომატური სიტყვების განაცნობის (ASR) მოდელზე, რომელიც TED-LIUM ინგლისური სიტყვების განაცნობის კოპუსზე განაცნობა (TED-LIUM). შემდეგ ჩვენ ინგლისური-გერმანური ტექსტიური ტექსტიური მაქანის გადაწყვეტილება (NMT) მოდელში გადატანა. ჩვენი სისტემები სამი განსხვავებული განგორმაციის მოდელი, რომელიც განსხვავებული განგორმაციების სტრიქციის სტრიქციაში შექმნა, რომელიც TED-დომიანი განგორმაციის კოპოსს (TED-TRANS) და OPENSUBTITLES2018-ის კოლექცი ჩვენ ასევე ვფიქრობთ ექსპერიმენტები, რომლებიც ჩვენი ბოლო სისტემისთვის გადატანა. ჩვენი ექსპერიმენტები აჩვენებს, რომ OPENSUBTITLES2018-ის გამოყენება განსწავლებაში მნიშვნელოვანად უფრო მეტადებს განსწავლება. ჩვენ ასევე ექსპერიმენტებით განსხვავებული პროცემენტებით და დავაპროცესებით NMT მოდულისთვის პროცემენტებით, მაგრამ ჩვენ არ გვაქვს ძალიან წარ ნაქარა ნაი-ეჲბპა ჟთჟრვმა ოჲლსფაგა ბლძჟ 16,45 ოჲლსფაი ნა რვჟრა ჱა რაჱთ დჲეთნა.', 'kk': 'Бұл қағаз IWSLT сөз аудармасының ортақтастырылған тапсырмасының MeMAD жобасының жазуын, ағылшын аудармасының ағылшын аудармасын неміс мәтініне хабарлап береді. Қызық жолы мен аяқтау үлгі жолдардың арасында біз тек бұрынғыларда үш контрастық жүйелерімен қатынасыз. Біз соңғыларды де көрдік, бірақ соңғылардың үлгісін уақытта аяқтай алмадық. Бүкіл жүйелеріміз TED-LIUM ағылшын сөздерді таңдау корпус (TED-LIUM) арқылы автоматты сөздерді анықтау үлгісін мәтінде аударып бастады. Содан кейін ағылшын- неміс мәтін негіздеген неврал машинаның аудару (NMT) үлгілеріне аударып береміз. Біздің жүйелеріміз TED Speech Translation Corpus (TED-TRANS) және OPENSUBTITLES2018 жинақтарының бөлімінен ағылшын- неміс тілдерінің бөлігінен бөліктелген үш түрлі аудару моделдерін қолданады. Бұл қағазда соңғы жүйелерімізге көмектесетін тәжірибелерді таңдаймыз. Біздің тәжірибеміз OPENSUBTITLES2018 қолдану үшін аудармалардың әдістерін өте жақсарту дегенді көрсетеді. Біз сондай-ақ NMT модулі үшін әртүрлі өзгерту және өзгерту әдістерін тәжірибедік, бірақ бұлармен көп сәтті жоқ. Біздің ең жақсы сұрақтар жүйесіміз осы жылдың тапсырманың сынақтарында 16,45 BLEU нәтижесін жеткізеді.', 'hu': 'Ez a tanulmány bemutatja az IWSLT Speech Translation Shared Task MeMAD projekt bejegyzését, amely az angol hang német szövegre történő fordításával foglalkozik. A csővezeték és az end-to-end modellpályák között csak az előbbiben vettünk részt, három kontrasztos rendszerrel. Az utóbbit is kipróbáltuk, de nem tudtuk időben befejezni a teljes modellünket. Minden rendszerünk a TED-LIUM angol beszédfelismerő testületén (TED-LIUM) képzett automatikus beszédfelismerő (ASR) modell segítségével kezdődik. Ezt követően az átiratokat angol-német szövegalapú neurális gépi fordítási (NMT) modellekbe töltjük be. Rendszereink három különböző fordítási modellt alkalmaznak, amelyeket a TED Speech Translation Corpus (TED-TRANS) angol-német részéből és az OPUS gyűjtemény OPENSUBTITLES2018 részéből állítottunk össze. Ebben a tanulmányban bemutatjuk a végső rendszereinkhez vezető kísérleteket is. Kísérleteink azt mutatják, hogy az OPENSUBTITLES2018 képzésben való használata jelentősen javítja a fordítási teljesítményt. Kísérleteztünk különböző elő- és utófeldolgozási rutinokkal az NMT modulhoz, de ezekkel nem volt sok sikerünk. A legjobb pontszámot érő rendszerünk az idei feladatra szolgáló tesztkészleten 16,45 BLEU pontszámot ér el.', 'lt': 'Šiame dokumente apibūdinamas MeMAD projekto įrašas į IWSLT kalbos vertimo bendrą užduotį, skirtas anglų garso vertimui į vokiečių tekstą. Tarp vamzdyno ir modelio kelių nuo pabaigos dalyvavome tik pirmosiose, su trimis kontrastinėmis sistemomis. Mes taip pat bandėme pastarąjį, bet negalėjome laiku užbaigti savo modelio pabaigoje. Visos mūsų sistemos pradedamos transkribuoti garsą į tekstą naudojant automatinio kalbos atpažinimo (ASR) model į, parengtą TED-LIUM anglų kalbos atpažinimo korpuse (TED-LIUM). Vėliau transkriptai įtraukiami į anglų ir vokiečių tekstu pagrįstus nervinių mašinų vertimo (NMT) modelius. Mūsų sistemose naudojami trys skirtingi vertimo modeliai, parengti atskiruose mokymo rinkiniuose, sudarytuose iš anglų ir vokiečių TED kalbos vertimo korpuso (TED-TRANS) ir OPENSUBTITLES2018 skyriaus. Šiame dokumente taip pat apibūdiname eksperimentus, kurie veda prie mūsų galutinių sistemų. Our experiments indicate that using OPENSUBTITLES2018 in training significantly improves translation performance.  We also experimented with various preand postprocessing routines for the NMT module, but we did not have much success with these.  Mūs ų geriausia vertinimo sistema pasiekia BLEU 16.45 tašką, nustatytą šių metų užduoties bandymų rinkinyje.', 'ms': 'Kertas ini menggambarkan masukan projek MeMAD ke Tugas Berkongsi Terjemahan Cahaya IWSLT, mengarahkan terjemahan audio Inggeris ke teks Jerman. Antara saluran paip dan trek model akhir-akhir, kami hanya berpartisipasi dalam sistem pertama, dengan tiga sistem bertentangan. Kami juga mencuba yang terakhir, tetapi tidak dapat menyelesaikan model akhir-akhir kami pada masa. Semua sistem kita bermula dengan menyalin audio ke dalam teks melalui model pengenalan pidato automatik (ASR) dilatih pada korpus pengenalan pidato Inggeris TED-LIUM (TED-LIUM). Kemudian, kami mengisi transkrip ke dalam model mesin saraf terjemahan berbasis teks bahasa Inggeris-Jerman (NMT). Sistem kami menggunakan tiga model terjemahan yang berbeza dilatih pada set latihan yang berbeza dikumpulkan dari bahagian Inggeris-Jerman dari TED Speech Translation Corpus (TED-TRANS) dan seksyen OPENSUBTITLES2018 koleksi OPUS. Dalam kertas ini, kita juga menggambarkan eksperimen yang membawa ke sistem terakhir kita. Eksperimen kami menunjukkan bahawa menggunakan OPENSUBTITLES2018 dalam latihan meningkatkan prestasi terjemahan yang signifikan. Kami juga eksperimen dengan berbeza rutin postproses preand untuk modul NMT, tetapi kami tidak berjaya dengan ini. Sistem penilaian terbaik kita mencapai skor BLEU 16.45 pada set ujian untuk tugas tahun ini.', 'mk': 'This paper describes the MeMAD project entry to the IWSLT Speech Translation Shared Task, addressing the translation of English audio into German text.  Меѓу гасоводот и моделот од крај до крај, учествувавме само во првите, со три контрастивни системи. Се обидовме и со последните, но не можевме да го завршиме нашиот модел крај до крај на време. Сите наши системи почнуваат со препишување на аудиото во текст преку автоматско препознавање на говорот (АСР) модел обучен на ТЕД-ЛИУМ Англискиот Корпус за препознавање на говорот (ТЕД-ЛИУМ). Потоа ги внесуваме транскриптите во англиско-германски текст-базирани нервни машински преводи (НМТ). Нашите системи употребуваат три различни модели на превод обучени на одделни опреми на обука комплицирани од англиско-германскиот дел од TED Speech Translation Corpus (TED-TRANS) и OPENSUBTITLES2018 делот од колекцијата ОПУС. Во овој весник, ние исто така ги опишуваме експериментите кои водат до нашите конечни системи. Нашите експерименти покажуваат дека употребата на OPENSUBTITLES2018 во обуката значително го подобрува преводот. Исто така, експериментиравме со различни рутини за превезување и постобработување за модулот НМТ, но немавме многу успех со овие. Нашиот најдобар систем постигнува БЛЕУ резултат од 16:45 на тестот за оваа година.', 'it': "Questo articolo descrive la voce del progetto MeMAD al compito condiviso di traduzione vocale IWSLT, affrontando la traduzione dell'audio inglese in testo tedesco. Tra la pipeline e le piste di modello end-to-end, abbiamo partecipato solo alla prima, con tre sistemi contrastanti. Abbiamo provato anche quest'ultimo, ma non siamo riusciti a finire il nostro modello end-to-end in tempo. Tutti i nostri sistemi iniziano trascrivendo l'audio in testo attraverso un modello di riconoscimento vocale automatico (ASR) addestrato sul TED-LIUM English Speech Recognition Corpus (TED-LIUM). Successivamente, inseriamo le trascrizioni in modelli di traduzione automatica neurale (NMT) basati sul testo inglese-tedesco. I nostri sistemi utilizzano tre diversi modelli di traduzione formati su set di formazione separati compilati dalla parte inglese-tedesca del TED Speech Translation Corpus (TED-TRANS) e dalla sezione OPENSUBTITLES2018 della collezione OPUS. In questo articolo, descriviamo anche gli esperimenti che hanno portato ai nostri sistemi finali. I nostri esperimenti indicano che l'utilizzo di OPENSUBTITLES2018 nella formazione migliora significativamente le prestazioni di traduzione. Abbiamo anche sperimentato varie routine di pre e post-elaborazione per il modulo NMT, ma non abbiamo avuto molto successo con queste. Il nostro sistema di punteggio migliore raggiunge un punteggio BLEU di 16,45 sul set di test per il compito di quest'anno.", 'mn': 'Энэ цаас IWSLT хэлний хөгжлийн хөгжлийн хөгжлийн хөгжлийг Германы текст руу илэрхийлж, Англи үндлийн хөгжлийн хөгжлийг дэмжиж байна. Хөдөлгөөн шугам болон төгсгөл загварын хооронд бид зөвхөн өмнөх нь 3 эсрэг системтэй холбоотой. Бид хамгийн сүүлийн загварыг ч оролдсон ч цаг хугацаанд дуусгаж чадахгүй. Бидний бүх системүүд TED-LIUM Англи хэлний танилцуулах Корпус (TED-LIUM) дээр сургалтын автоматжуулан илтгэл танилцуулах загварын аргаар бичлэгийг текст руу шилжүүлж эхэлсэн. Дараа нь бид англи-Германы текст суурилсан мэдрэлийн машин хөгжүүлэлтийг (NMT) загвар руу хангадаг. Бидний систем TED-TRANS болон OPENSUBTITLES2018 цуглуулалтын англи-Германы хэсэгт бүтээгдэхүүний 3 өөр өөр өөр хөгжлийн загварыг ашигладаг. Энэ цаасан дээр бид мөн сүүлийн системд хүргэсэн туршилтуудыг тайлбарлаж байна. Бидний туршилтууд OPENSUBTITLES2018-г сургалтын тулд хөгжлийн үйл ажиллагааг үнэхээр сайжруулдаг гэдгийг харуулдаг. Мөн бид NMT модульд олон төрлийн өмнөх болон дараах үйл ажиллагааг туршиж үзсэн. Гэхдээ эдгээрийн тухай маш их амжилттай байхгүй. Бидний хамгийн шилдэг судалгааны систем энэ жилийн ажлын туршилтын тулд БЛЕС 16.45 оноо хүртэл байна.', 'no': 'Denne papiret beskriver oppføringa for MeMAD- prosjektet til den delte oppgåva for taleomsetjinga IWSLT, som adresserer omsetjinga av engelsk lyd til tysk tekst. Mellom røyebrytaren og sluttmodellen delte vi berre i dei tidlegare, med tre kontrastsystemer. Vi prøvde også dei siste, men klarte ikkje avslutta vår sluttmodell i tid. Alle systema våre startar ved å overskriva lyden til tekst gjennom ein automatisk tale-gjenkjenning (ASR) modell som treng på TED-LIUM-engelsk tale-gjenkjenning Corpus (TED-LIUM). Etter denne fører vi transkriptene inn i engelsk- tysk tekstbasert neuralmaskinsomsetjingsmodular (NMT). Sistemet våre bruker tre ulike omsetjingsmodular som trengte på separate opplæringar kompilert frå den engelske-tyske delen av TED-taleomsetjingskorpen (TED-TRANS) og OPENSUBTITLES2018-delen av OPUS-samlinga. I denne papiren beskriver vi også eksperimentene som fører til siste systemet våre. Eksperimentane våre tyder på at bruken av OPENSUBTITLES2018 i opplæring forbetrar utviklinga av omsetjing betydelig. Vi har også eksperimentert med forskjellige postprosesseringar for NMT-modulen, men vi har ikkje mye suksess med desse. Det beste oppløysingssystemet vårt finn ein BLEU-score av 16,45 på testet sett for oppgåva i året.', 'ml': 'ഈ പത്രത്തില്\u200d മെഎംഎഡ് പ്രോജക്റ്റ് എന്\u200dട്രിയിലേക്ക് വിശദീകരിക്കുന്നു. IWSLT സ്പീസ് വിഭാഷ പങ്കാളികള്\u200d പങ്കുചേര്\u200dത്ത പൈപ്പെലൈനും അവസാന മോഡല്\u200d ട്രാക്കുകളും തമ്മില്\u200d, മുന്\u200dപ് മാത്രമേ ഞങ്ങള്\u200d പങ്കുചേര്\u200dന്നുള്ളൂ, മൂന്നു വിരോധമായ സിസ് അവസാനത്തെ ഞങ്ങളും ശ്രമിച്ചു, പക്ഷെ സമയത്ത് നമ്മുടെ അവസാന മോഡല്\u200d പൂര്\u200dത്തിയാക്കാന്\u200d കഴിഞ്ഞില്ല. നമ്മുടെ എല്ലാ സിസ്റ്റത്തിലും ശബ്ദം ടെക്സ്റ്റിങ്ങിലേക്ക് ടെഡി- ലിയുമില്\u200d പഠിപ്പിക്കുന്ന ഒരു സ്വയമായി സംസാരിക്കുന്നതിലൂടെ ടെഡി- ലിയ അതിനുശേഷം, ഞങ്ങള്\u200d ട്രാന്\u200dസ്ക്രിപ്റ്റുകള്\u200d ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d ടെക്സ്റ്റ് അടിസ്ഥാനമായി ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ ഞങ്ങളുടെ സിസ്റ്റത്തില്\u200d വ്യത്യസ്ത പരിശീലനത്തിന്റെ മോഡലുകള്\u200d മൂന്നു വ്യത്യസ്ത പരിശീലനത്തില്\u200d പരിശീലിക്കുന്നു ഈ പത്രത്തില്\u200d, നമ്മുടെ അവസാനത്തെ സിസ്റ്റത്തിലേക്ക് പോകുന്ന പരീക്ഷണങ്ങള്\u200d ഞങ്ങള്\u200d വിശദീകരിക്കുന്നു. ഞങ്ങളുടെ പരീക്ഷണങ്ങള്\u200d വ്യക്തമാക്കുന്നു ഓപെന്\u200dസുബ്ടിറ്റിലെസ്2018 ഉപയോഗിച്ച് പരിശീലനത്തില്\u200d പരിശീലനത്തിന്\u200dറെ  നമ്മള്\u200d വ്യത്യസ്ത പോസ്റ്റ് പ്രോസ്ക്രെയിസ്സിന്റെ രൂട്ടിനുമായി പരീക്ഷിച്ചിരുന്നു. പക്ഷെ നമുക്ക് ഇതില്\u200d വളരെ വി നമ്മുടെ ഏറ്റവും മികച്ച സിസ്റ്റം ഈ വര്\u200dഷത്തിന്റെ ജോലിക്കുള്ള പരീക്ഷണത്തിന്റെ സെറ്റിറ്റ് 16.45 ന്റെ ഒരു ബില', 'mt': "Dan id-dokument jiddeskrivi l-annotazzjoni tal-proġett MeMAD għall-Kompitu Konġunt tat-Traduzzjoni tal-Kellem IWSLT, li jindirizza t-traduzzjoni tal-awdjo Ingliż fit-test Ġermaniż. Bejn il-pajpijiet u l-binarji tal-mudell minn tarf sa tarf, ipparteċipajna biss f’dawk ta’ qabel, bi tliet sistemi kontrastivi. Ippruvajna wkoll dan tal-aħħar, iżda ma setgħux intemmu l-mudell tagħna minn tarf sa tarf fil-ħin. Is-sistemi kollha tagħna jibdew bit-traskrizzjoni tal-awdjo fit-test permezz ta’ mudell ta’ rikonoxximent awtomatiku tad-diskors (ASR) imħarreġ fuq il-Korp tar-rikonoxximent tal-kelma Ingliż TED-LIUM (TED-LIUM). Wara dan, aħna nagħtu t-traskrizzjonijiet fil-mudelli tat-traduzzjoni tal-magni newrali (NMT) ibbażati fuq it-test Ingliż-Ġermaniż. Is-sistemi tagħna jimpjegaw tliet mudelli differenti ta’ traduzzjoni mħarrġa fuq settijiet separati ta’ taħriġ ikkumpilati mill-parti Ingliż-Ġermaniża tal-Korp tat-Traduzzjoni ta’ Speech TED (TED-TRANS) u t-taqsima OPENSUBTITLES2018 tal-ġbir OPUS. In this paper, we also describe the experiments leading up to our final systems.  L-esperimenti tagħna jindikaw li l-użu ta’ OPENSUBTITLES2018 fit-taħriġ itejjeb b’mod sinifikanti l-prestazzjoni tat-traduzzjoni. Esperimentajna wkoll b’diversi rutini ta’ preand postprocessing għall-modulu NMT, iżda ma kellhomx ħafna suċċess b’dawn. Our best-scoring system attains a BLEU score of 16.45 on the test set for this year's task.", 'ro': 'Această lucrare descrie intrarea proiectului MeMAD la IWSLT Speech Translation Shared Task, abordând traducerea audio engleză în text german. Între conductă și piesele de model end-to-end, am participat doar la prima, cu trei sisteme contrastante. Am încercat și pe acesta din urmă, dar nu am reușit să terminăm modelul end-to-end la timp. Toate sistemele noastre încep prin transcrierea audio în text printr-un model de recunoaștere automată a vorbirii (ASR) instruit pe TED-LIUM English Speech Recognition Corpus (TED-LIUM). Ulterior, introducem transcrierile în modele de traducere automată neurală (NMT) bazate pe text engleză-germană. Sistemele noastre utilizează trei modele diferite de traducere instruite pe seturi separate de instruire compilate din partea engleză-germană a corpului TED Speech Translation Corpus (TED-TRANS) și secțiunea OPENSUBTITLES2018 a colecției OPUS. În această lucrare, descriem, de asemenea, experimentele care au condus la sistemele noastre finale. Experimentele noastre indică faptul că utilizarea OPENSUBTITLES2018 în formare îmbunătățește semnificativ performanța traducerii. De asemenea, am experimentat diverse rutine de pre și postprocesare pentru modulul NMT, dar nu am avut prea mult succes cu acestea. Sistemul nostru cel mai bun scor obține un scor BLEU de 16.45 pe setul de test pentru sarcina din acest an.', 'sr': 'Ovaj papir opisuje ulaz MeMAD projekta u IWSLT prevod razgovora zajednički zadatak, obraćajući prevod engleskog zvuka na njemački tekst. Između kanalizacije i tragova modela do kraja, sudjelovali smo samo u bivšim, sa tri kontrastivnih sistema. Pokušali smo i poslednji, ali nismo uspeli da završimo naš model kraja do kraja na vreme. Svi naši sistemi počinju prepisanjem zvuka na tekst kroz automatski model priznanja govora (ASR) obučen na korpusu priznanja TED-LIUM engleskog govora (TED-LIUM). Nakon toga, prevodimo transkripte na engleski-njemaèki tekst-bazirani neuromašinski prevod (NMT) modeli. Naši sistemi koriste tri različite modele prevoda obučene na odvojenim setima obuke, sastavljenim iz Engleskog-Njemačkog dijela TED-govornog prevodnog korpusa (TED-TRANS) i dio OPENSUBTITLES2018 kolekcije OPUS-a. U ovom papiru opisujemo i eksperimente koji vode do naših poslednjih sistema. Naši eksperimenti ukazuju na to da korištenje OPENSUBTITLES2018 u obuci značajno poboljšava učinkovitost prevođenja. Također smo eksperimentirali sa različitim rutinama prei postprocessiranja za modul NMT-a, ali nismo imali mnogo uspeha s tim. Naš najbolji sistem izvlačenja postiže BLEU rezultat od 16,45 na testu određenom za ovaj godišnji zadatak.', 'pl': 'Niniejszy artykuł opisuje wpis projektu MeMAD do zadania IWSLT Speech Translation Shared Task, zajmujący się tłumaczeniem angielskiego dźwięku na tekst niemiecki. Między rurociągiem a torami modelowymi typu end-to-end uczestniczyliśmy tylko w pierwszym, z trzema kontrastywnymi systemami. Próbowaliśmy również tego ostatniego, ale nie byliśmy w stanie zakończyć naszego kompleksowego modelu na czas. Wszystkie nasze systemy zaczynają od transkrypcji dźwięku na tekst poprzez model automatycznego rozpoznawania mowy (ASR) przeszkolony na TED-LIUM English Speech Recognition Corpus (TED-LIUM). Następnie wprowadzamy transkrypcje do angielsko-niemieckich modeli tłumaczenia neuronowego maszynowego (NMT). Nasze systemy wykorzystują trzy różne modele tłumaczeń przeszkolone na oddzielnych zestawach szkoleniowych skompilowanych z angielsko-niemieckiej części Korpusu Tłumaczeń Mowy TED (TED-TRANS) oraz sekcji OPENSUBTITLES2018 kolekcji OPUS. W niniejszym artykule opisujemy również eksperymenty prowadzące do powstania naszych ostatecznych systemów. Nasze eksperymenty wskazują, że stosowanie OPENSUBTITLES2018 w szkoleniu znacznie poprawia wydajność tłumaczenia. Eksperymentowaliśmy również z różnymi procedurami przed i postprocessing modułu NMT, ale nie odniosłyśmy dużego sukcesu. Nasz system najlepszych punktów osiąga wynik BLEU 16,45 na zestawie testowym do tegorocznego zadania.', 'so': 'Kanu warqaddan waxaa ku qoran qoraalka qoraalka MeMAD ee IWSLT Speech Shared Task, addressing tarjumaadda afka Ingiriiska oo qoraalka Jarmalka. Between the pipeline and end-to-end model tracks, we participated only in the former, with three contrastive systems.  Sidoo kale waxaynu isku daynay kuwii dambeeyey, laakiin ma aan dhammayn karin modeligayaga ugu dhammaadka dhammaadka waqtiga. Isticmaalkayga oo dhan waxay ku bilaabayaan qoraalka codka oo ku qoraya qoraal ahaan aqoonsashada hadalka (ASR) modelka lagu baray aqoonsashada afka Ingiriiska ee TED-LIUM (TED-LIUM). Markaas kadib waxaynu warqadaha qoraalka u daajinaynaa qoraalka Ingiriis-German-based neural machine-neural (NMT) models. Systemkanagu waxay shaqeeyaan saddex model oo turjumaan oo kala duduwan oo lagu baray koorasyada waxbarashada gooni ah oo laga soo ururiyey qeybta afka Ingiriiska-Jarmalka (TED-TRANS) iyo qeybta ururka OPUS (OPENSUBTITLES2018). Qoraalkan waxaynu ku qornaa imtixaanka ugu horeeya nidaamka ugu dambeeya. Imtixaanadayada ayaa muuqanaya in isticmaalka OPENSUBTITLES2018 waxbarashada uu si weyn u hagaajiyo muuqashada turjumaadda. Sidoo kale waxaynu ku jirrabnay wadooyin kala duduwan oo ka baaraandegista wadamada AMT, laakiin waxan aad nooma liibaanin. Istixaankayada ugu wanaagsan wuxuu gaadhaa qiimeynta BLEU 16.45 oo ku qoran imtixaanka shaqada sanadkan.', 'si': 'මේ පැත්තේ MeMAD ව්\u200dයාපෘතියට IWSLT වාර්තාව භාවිතය සමාගත වැඩකට ප්\u200dරවේශ කරනවා, ජර්මන් පාළුවට ඉංග්\u200dරීසි ශ්\u200dරී පායිප්ලයින් සහ අවසානය සඳහා අවසානයට අවසානය වෙනුවෙන්, අපි පළවෙනි පද්ධතියේ විතරයි, ප්\u200dරතික්\u200dරමාත්ම අපි අන්තිමට උත්සාහ කළා, ඒත් අපේ අන්තිමට අවසානය කරන්න පුළුවන් නෑ. අපේ සියලුම පද්ධතිය පටන් ගන්නේ ස්වයංක්\u200dරියාත්මක කතාවක් අඳුරගන්න (ASR) මොඩේලය TED-LIUM ඉංග්\u200dරීසි භාෂාවක් අඳුරගන්න කොර්පු ඊට පස්සේ, අපි ඉංග්\u200dරීස්-ජර්මාන් පාළුවේ පාළුවක් අධාරිත න්\u200dයුරල් මැෂින් වාර්තාව (NMT) මොඩේල්  අපේ පද්ධතිය භාවිතා කරන්නේ වෙනස් භාවිතා මොඩල් තුනක් ප්\u200dරශ්නය කරලා ඉංග්\u200dරීසිය-ජර්මාන් භාවිතාන කොර්පුස් (TED-TRANS) සහ OPENSUBTITLES2018 භාවි මේ පත්තරේ අපි පරීක්ෂණයක් තේරුම් කරනවා අපේ අන්තිම පද්ධතියට යනවා. අපේ පරීක්ෂණය පෙන්වන්නේ OPENSUBTITLES2018 විශ්වාස කරන්න පුළුවන් විශේෂයෙන් පරීක්ෂණය වැඩ කරන්න. අපි පරීක්ෂණය කරලා තියෙන්නේ NMT මොඩියුල් එක්ක විවිධ ප්\u200dරීසෙස් සඳහා විවිධ ප්\u200dරශ්නයක් තියෙන්නේ, ඒත් අප අපේ හොඳම ස්කෝරින්ග් පද්ධතියක් මේ අවුරුද්දේ වැඩේ පරීක්ෂණාව සඳහා බ්ලූයුස් ප්\u200dරමාණයක් 16.45 ක් ලැබෙ', 'sv': 'Denna uppsats beskriver MeMAD-projektposten till IWSLT Speech Translation Shared Task, som behandlar översättning av engelskt ljud till tysk text. Mellan pipeline och end-to-end modellspår deltog vi bara i det förra, med tre kontrasterande system. Vi provade också den senare, men kunde inte avsluta vår end-to-end-modell i tid. Alla våra system börjar med att transkribera ljudet till text genom en automatisk taligenkänningsmodell (ASR) utbildad på TED-LIUM English Speech Recognition Corpus (TED-LIUM). Därefter matar vi in transkriptionerna i engelsk-tyska textbaserade neurala maskinöversättningsmodeller (NMT). Våra system använder tre olika översättningsmodeller utbildade på separata utbildningsset som sammanställts från den engelsk-tyska delen av TED Speech Translation Corpus (TED-TRANS) och OPENSUBTITLES2018 sektionen i OPUS-samlingen. I denna uppsats beskriver vi även de experiment som ledde fram till våra slutliga system. Våra experiment tyder på att användningen av OPENSUBTITLES2018 i utbildning avsevärt förbättrar översättningens prestanda. Vi experimenterade också med olika pre- och efterbehandlingsrutiner för NMT-modulen, men vi hade inte så mycket framgång med dessa. Vårt bästa poängsystem uppnår en BLEU-poäng på 16,45 på testset för årets uppgift.', 'ta': 'இந்த தாள் IWSLT பேச்சு மொழிபெயர்ப்பு பகிர்ந்த பணிக்கு MeMAD திட்டத்தை குறிப்பிடுகிறது, ஜெர்மன் உரைக்கு மொழிபெயர்ப்பின்  பைப்லைன் மற்றும் இறுதி முடிவு மாதிரி தடங்களுக்கிடையில், முன்னால் மட்டும் மூன்று எதிர்ப்பு அமைப்புகளுடன் பங்க We tried also the latter, but were not able to finish our end-to-end model in time.  எங்கள் அனைத்து அமைப்புகளும் ஒலியை உரையில் எழுதும் மூலம் துவங்குகிறது ஒரு தானியங்கி பேச்சு அடையாளம் (ASR) மாதிரி TED- LIUM ஆங்கிலத்தின் பேச்சு கார்ப பின்னர், நாம் இந்த எழுத்துருக்களை ஆங்கிலம்- ஜெர்மன் உரையில் அடிப்படையான நெருக்கல் இயந்திரம் மொழிபெயர்ப்பு (NMT) மா எங்கள் அமைப்புகள் வேறு மொழிபெயர்ப்பு மாதிரிகளை பயன்படுத்துகிறது தனிப்பட்ட பயிற்சி அமைப்புகளில் TED பேச்சு மொழிபெயர்ப்பு கார்புஸ் (TED- TRANS) மற்றும் OPUS தொகுப இந்த காகிதத்தில், நாம் எங்கள் இறுதி அமைப்புகளுக்கு முன்னேறிய சோதனைகளை விவரிக்கிறோம். எங்கள் சோதனைகள் OPENSUBTITLES2018 பயன்படுத்தும் பயிற்சி மொழிபெயர்ப்பு செயல்பாட்டை மிகப்பெரியதாக மாற்றுகிறது என நாங்கள் NMT கூற்றுக்கான பல்வேறு முன்னோட்டு பின்செயல்படுத்தல் வழிகளைக் கொண்டு பரிசோதித்தோம், ஆனால் இதைக் கொண்ட எங்கள் சிறந்த மதிப்பெண் அமைப்பு இந்த வருடத்தின் சோதனையின் அமைப்பில் 16.45 மதிப்பு பெறுகிறது.', 'ur': 'This paper describes the MeMAD project entry to the IWSLT Speech Translation Shared Task, addressing the translation of English audio into German text. پائپ لین اور آخر و آخر مدل ٹریک کے درمیان ہم صرف پہلے کے ساتھ تین کنٹرسیٹ سیستموں کے ساتھ شریک ہوئے۔ ہم نے اگلوں کی کوشش کی، لیکن ہمارے آخری مدل کو وقت میں پورا نہیں کر سکتے۔ ہمارے سارے سیسٹم آئڈیو کو ٹیکسٹ میں ٹیکسٹ کرنا شروع کر رہے ہیں TED-LIUM انگلیسی بات پڑھنے کی کورپوس (TED-LIUM) کے ذریعہ سے استعمال کیا گیا ہے۔ اس کے بعد ہم انگلیسی-جرمن کی متن بنیادی نورول ماشین ترجمہ (NMT) موڈل میں ترجمہ کریں گے۔ ہماری سیستم تین مختلف ترجمہ موڈل استعمال کرتا ہے جو مختلف ترکینس سٹوں پر آموزش کی جاتی ہے جو TED Speech Translation Corpus (TED-TRANS) اور OPENSUBTITLES2018 کے مختلف ترکینس کے حصہ سے کامپیل کیے گئے ہیں. اس کاغذ میں، ہم نے بھی اپنی آخری سیسٹموں پر چلنے والی آزمائش کی توصیف کر دی ہے۔ ہمارے آزمائش نشان دیتے ہیں کہ OPENSUBTITLES2018 کے استعمال میں ترکینس کے کامیابی کو بہت اچھی طرح بہتر کر دیتا ہے. ہم نے بھی NMT موڈل کے لئے مختلف پیش اور پوسٹ پرسس روٹینز کے ساتھ آزمائش کی، لیکن ہم نے ان کے ساتھ بہت کامیابی نہیں کی۔ ہماری بہترین اسکورینگ سیسٹم نے اس سال کے کام کے لئے آزمائش سٹم پر 16.45 بلیوس کا اسکور پایا ہے.', 'uz': "Name Pipeline va oxirigi modellar tarkibida faqat birinchi birinchi narsa bilan uchta kontrast tizimga murojaat qildik. Biz keyingizni ko'rib turdik, lekin oxirimiz modelimizni davomida tugata olmadi. Hech narsa tizimmiz TED-LIUM Ingliz tilini Tasdiqlash Korpusi (TED-LIUM) bilan o'rganish modeli bilan tovushni matnni tahrirlash orqali boshlanadi. Keyin biz tarjimalarni ingliz- Olmoncha matn asosida neyrol maskin tarjima qilamiz. Bizning tizimimiz AQSUBTITLES2018 bir xil tarjima qiladigan ingliz- nemis tarjima Korpus (TED-TRANS) va OPUS toʻplamdagi OPENSUBTITLES2018 qismidan bir xil tilni o'rganadi. Bu qogʻozda biz oxirgi tizimga erishilgan jarayonlarni anglatamiz. Bizning tajribalarimiz, OPENSUBTITLES2018 ishlatish uchun tarjima muvaffaqiyatlarini juda ko'paytirish mumkin. Biz NMT moduli uchun boshqa bir necha pre-va postprocessing rutinlari bilan tizimiz, lekin biz bunga ko'p muvaffaqiyatli yo'q. Bizning eng yaxshi qiymatlar tizimmiz shu yil vazifani o'rnatilgan 16.45 pochta BLEU scorini topadi.", 'vi': 'Tờ giấy này mô tả mục nhập dự án MeMAD vào Công việc chia sẻ giọng nói ICWSLT, nhằm mục đích dịch âm thanh tiếng Anh vào văn bản Đức. Giữa đường ống và đường dẫn đường, chúng tôi chỉ tham gia vào các đường ống trước, với ba hệ thống tương phản. Chúng tôi cũng đã thử qua lần sau, nhưng không thể hoàn thành hết theo thời gian. Tất cả hệ thống bắt đầu bằng việc chép âm thanh vào văn bản bằng cách nhận dạng ngôn ngữ tự động (ASR) được đào tạo trên tập đoàn Phát ngôn ngữ được Ted-LIum tiếng Anh (TET-LIum) đã được đào tạo. Sau đó, chúng tôi chuyển các bản sao sang các mô hình dịch từ máy thần kinh bằng văn bản Anh-Đức (NMB). Hệ thống của chúng tôi sử dụng ba mô hình dịch khác nhau được đào tạo trên các tập hợp tập luyện khác nhau được biên tập từ phần tiếng Anh-Đức của tập đoàn Phát Minh Ted (ROT-Trans) và phần khai thác OPUS. Trong tờ giấy này, chúng tôi cũng mô tả các thí nghiệm dẫn đến hệ thống cuối cùng. Các thí nghiệm của chúng tôi cho thấy rằng nhờ OpenHSINGTvekđôi trong huấn luyện cải thiện hiệu quả dịch thuật. Chúng tôi cũng đã thử nghiệm nhiều chương trình trước và sau đó cho môđun NMT, nhưng chúng tôi không có nhiều thành công với chúng. Hệ thống ghi điểm tốt nhất của chúng ta đạt được s ố lượng đứng của hợp lệ 16.45 trên mẫu thử cho nhiệm vụ năm nay.', 'bg': 'Настоящата статия описва влизането на проекта в Споделената задача за превод на реч на английски език в немски текст. Между тръбопровода и модел от край до край, участвахме само в първата, с три контрастни системи. Опитахме и последния, но не успяхме да завършим нашия модел от край до край навреме. Всички наши системи започват с транскрибиране на аудиото в текст чрез модел за автоматично разпознаване на речта (АСР), обучен по Корпуса за разпознаване на реч на английски език (TED-LIUM). След това въвеждаме транскрипциите в английски-немски текстово-базирани модели на невронен машинен превод (НМТ). Нашите системи използват три различни модела на превод, обучени по отделни обучителни комплекти, съставени от англо-немската част на Корпуса за превод на реч на ТЕД (ТЕД-ТРАНС) и раздела ОТВОРЕНИ ДЪРЖАНИЯ от колекцията ОПУС. В тази статия описваме и експериментите, водещи до нашите крайни системи. Нашите експерименти показват, че използването на ОПЕНСУБТИЛС2018 в обучението значително подобрява ефективността на превода. Експериментирахме и с различни рутини за предварителна и следобработка на модула, но с тях нямахме голям успех. Нашата система за най-добра оценка постига резултат от 16.45 на теста за тазгодишната задача.', 'nl': 'Dit document beschrijft de MeMAD project entry in de IWSLT Speech Translation Shared Task, gericht op de vertaling van Engelse audio naar Duitse tekst. Tussen de pijpleiding en end-to-end modelbanen namen we alleen deel aan de eerste, met drie contrasterende systemen. We probeerden ook dat laatste, maar konden ons end-to-end model niet op tijd afmaken. Al onze systemen beginnen met het transcriberen van de audio naar tekst via een automatisch spraakherkenningsmodel (ASR) getraind op het TED-LIUM English Speech Recognition Corpus (TED-LIUM). Daarna voeren we de transcripten in Engels-Duitse tekst-based neural machine translation (NMT) modellen. Onze systemen maken gebruik van drie verschillende vertaalmodellen die zijn getraind op afzonderlijke trainingssets die zijn samengesteld uit het Engels-Duitse deel van het TED Speech Translation Corpus (TED-TRANS) en de OPENSUBTITLES2018 sectie van de OPUS collectie. In dit artikel beschrijven we ook de experimenten die leidden tot onze uiteindelijke systemen. Uit onze experimenten blijkt dat het gebruik van OPENSUBTITLES2018 in training de vertaalprestaties aanzienlijk verbetert. We hebben ook geëxperimenteerd met verschillende pre- en postprocessing routines voor de NMT module, maar daar hebben we weinig succes mee gehad. Ons best-scoresysteem behaalt een BLEU score van 16,45 op de testset voor de taak van dit jaar.', 'de': 'Dieser Beitrag beschreibt den MeMAD-Projekteintrag zum IWSLT Speech Translation Shared Task, der sich mit der Übersetzung von englischem Audio in deutschen Text befasst. Zwischen der Pipeline und den End-to-End-Modellbahnen nahmen wir nur an ersterem teil, mit drei kontrastiven Systemen. Letzteres haben wir auch ausprobiert, konnten aber unser End-to-End-Modell nicht rechtzeitig fertigstellen. Alle unsere Systeme beginnen mit der Transkription des Audios in Text durch ein automatisches Spracherkennungsmodell (ASR), das auf dem TED-LIUM English Speech Recognition Corpus (TED-LIUM) trainiert wurde. Anschließend speisen wir die Transkripte in englisch-deutsche textbasierte NMT-Modelle ein. Unsere Systeme verwenden drei verschiedene Übersetzungsmodelle, die auf separaten Trainingssätzen trainiert werden, die aus dem englisch-deutschen Teil des TED Speech Translation Corpus (TED-TRANS) und dem OPENSUBTITLES2018 Teil der OPUS-Sammlung zusammengestellt wurden. In diesem Beitrag beschreiben wir auch die Experimente, die zu unseren endgültigen Systemen führten. Unsere Experimente zeigen, dass der Einsatz von OPENSUBTITLES2018 im Training die Übersetzungsleistung signifikant verbessert. Wir haben auch mit verschiedenen Pre- und Postprocessing-Routinen für das NMT-Modul experimentiert, aber wir hatten mit diesen nicht viel Erfolg. Unser Best-Scoring-System erreicht eine BLEU-Punktzahl von 16,45 auf dem Testset für die diesjährige Aufgabe.', 'hr': 'Ovaj papir opisuje ulaz projekta MeMAD u dio IWSLT prevoda govora, obraćajući prevod engleskog zvuka na njemački tekst. Između cijevina i tragova modela do kraja, učestvovali smo samo u bivšim, s tri kontrastivnih sustava. Pokušali smo i posljednju, ali nismo uspjeli završiti naš model na kraju. Svi naši sustavi počinju prepisanjem zvuka na tekst putem automatskog priznanja govora (ASR) modela obučenog na korpusu priznanja TED-LIUM engleskog govora (TED-LIUM). Nakon toga, prevodimo transkripte u modele prevoda neuralnih strojeva na engleskom i njemačkom tekstu (NMT). Naši sustavi koriste tri različite modele prevoda obučene na odvojenim setima obuke, sastavljenim iz Engleskog-Njemačkog dijela TED-govornog prevodnog korpusa (TED-TRANS) i dijela OPENSUBTITLES2018 kolekcije OPUS-a. U ovom papiru opisujemo i eksperimente koji vode do naših konačnih sustava. Naši eksperimenti ukazuju na to da korištenje OPENSUBTITLES2018 u obuci značajno poboljšava učinkovitost prevođenja. Također smo eksperimentirali sa različitim rutinama prei postprocessiranja za modul NMT-a, ali nismo imali puno uspjeha s tim. Naš najbolji sustav izvlačenja postiže BLEU rezultat od 16,45 na testu određenom za ovaj godišnji zadatak.', 'da': 'Denne artikel beskriver MeMAD-projektposten til IWSLT Speech Translation Shared Task, der omhandler oversættelsen af engelsk lyd til tysk tekst. Mellem pipeline og end-to-end modelspor deltog vi kun i førstnævnte med tre kontrastsystemer. Vi prøvede også sidstnævnte, men var ikke i stand til at færdiggøre vores end-to-end model i tide. Alle vores systemer starter med at transkribe lyden til tekst gennem en automatisk talegenkendelsesmodel (ASR), der er uddannet på TED-LIUM English Speech Recognition Corpus (TED-LIUM). Derefter indsætter vi udskrifterne i engelsk-tysk tekstbaserede neurale maskinoversættelsesmodeller (NMT). Vores systemer anvender tre forskellige oversættelsesmodeller uddannet på separate træningssæt, der er udarbejdet fra den engelsk-tyske del af TED Speech Translation Corpus (TED-TRANS) og OPENSUBTITLES2018 sektionen i OPUS-samlingen. I denne artikel beskriver vi også de eksperimenter, der fører frem til vores endelige systemer. Vores eksperimenter tyder på, at brugen af OPENSUBTITLES2018 i træning forbedrer oversættelseseffektiviteten markant. Vi eksperimenterede også med forskellige pre- og postprocessing rutiner for NMT modulet, men vi havde ikke så stor succes med disse. Vores bedste scoresystem opnår en BLEU score på 16,45 på testsættet til dette års opgave.', 'id': "Kertas ini menggambarkan masukan proyek MeMAD ke Tugas Berkongsi Penerjemahan Bicara IWSLT, mengarahkan terjemahan audio Inggris ke teks Jerman. Antara saluran pipa dan jalur model akhir-akhir, kami hanya berpartisipasi di awal, dengan tiga sistem kontras. Kami juga mencoba yang terakhir, tapi tidak bisa menyelesaikan model akhir-akhir kami pada waktu. Semua sistem kita dimulai dengan transkrip audio ke teks melalui model pengakuan pidato otomatis (ASR) yang dilatih di TED-LIUM English Speech Recognition Corpus (TED-LIUM). Kemudian, kami mengisi transkrip ke model mesin saraf berbasis teks Inggris-Jerman (NMT). Sistem kami menggunakan tiga model terjemahan yang berbeda dilatih dalam set pelatihan terpisah dikompilasi dari bagian Inggris-Jerman dari TED Speech Translation Corpus (TED-TRANS) dan bagian OPENSUBTITLES2018 dari koleksi OPUS. Dalam kertas ini, kami juga menggambarkan eksperimen yang mengarah ke sistem terakhir kami. Eksperimen kami menunjukkan bahwa menggunakan OPENSUBTITLES2018 dalam latihan meningkatkan prestasi terjemahan yang signifikan. Kami juga eksperimen dengan berbagai rutin postproses preand untuk modul NMT, tapi kami tidak banyak sukses dengan ini. Our best-scoring system attains a BLEU score of 16.45 on the test set for this year's task.", 'sw': 'Gazeti hili linaelezea kuingia kwa mradi wa MeMAD kwenye Tafsiri ya Utafsiri wa Lugha IWSLT, akielezea tafsiri ya sauti ya Kiingereza katika maandishi ya Kijerumani. Katika mifumo ya mabomu na mifumo ya mwisho, tulishiriki tu katika mifumo mitatu tofauti. Tulijaribu pia, lakini hatukuweza kumaliza mtindo wetu wa mwisho wa mwisho kwa muda. Mfumo wetu wote unaanza kwa kuandika sauti kwa kutumia ujumbe wa kutambua hotuba ya kujitegemea (ASR) kupitia mfumo wa kufundishwa kwenye Shirika la Hotuba ya Kiingereza la TED-LIUM (TED-LIUM). Baada ya hayo, tunalisha maandiko katika tafsiri ya mashine ya neura yenye makala ya Kiingereza na Kijerumani (NMT). Mfumo wetu unatumia mifano mitatu tofauti ya tafsiri inayofundishwa katika seti za mafunzo tofauti zilizokusanyika kutoka sehemu ya Uingereza-Ujerumani ya Utafiti wa Tafsiri wa TED (TED-TRANS) na sehemu ya mkusanyiko wa OPENSUBTITLES2018 wa OPUS. Katika karatasi hii, pia tunaelezea majaribio yanayosababisha mifumo yetu ya mwisho. Majaribio yetu yanaonyesha kuwa kwa kutumia OPENSUBTITLES2018 katika mafunzo yanaboresha ufanisi wa tafsiri. Tulijaribu pia kwa njia mbalimbali za upasuaji wa vifaa vya NMT, lakini hatukuwa na mafanikio mengi kwa haya. Mfumo wetu mzuri unafikia vipimo vya BLEU 16.45 vya jaribio la mwaka huu.', 'fa': 'این کاغذ وارد پروژه MeMAD را توصیف می\u200cکند که در مورد ترجمه\u200cهای سخنرانی IWSLT به متن آلمانی تبدیل می\u200cشود. بین خط لوله و نقشه\u200cهای مدل پایان، ما تنها در سیستم\u200cهای سابق با سه سیستم متفاوتی شرکت کردیم. ما همچنین آخرین را امتحان کردیم، ولی نتوانستیم مدل آخرین ما را در زمان تموم کنیم. تمام سیستم\u200cهای ما شروع می\u200cکنند با ترجمه صدا را به متن با یک مدل شناسایی سخنرانی خودکار (ASR) آموزش داده شده در Corpus شناسایی سخنرانی انگلیسی TED-LIUM (TED-LIUM). سپس ما ترجمه\u200cها را به مدل\u200cهای ترجمه\u200cی ماشین\u200cهای عصبی (NMT) بر اساس متن انگلیسی-آلمانی تغذیه می\u200cکنیم. سیستم\u200cهای ما سه مدل ترجمه متفاوت را استفاده می\u200cکنند که در مجموعه آموزش متفاوت آموزش یافته شده از بخشی انگلیسی-آلمانی از مجموعه\u200cی ترجمه\u200cهای سخنرانی TED (TED-TRANS) و بخشی OPENSUBTITLES2018 از جمع\u200cآوری OPUS. در این کاغذ، ما همچنین آزمایشات را به سیستم نهایی ما توصیف می کنیم. آزمایش\u200cهای ما نشان می\u200cدهند که استفاده از OPENSUBTITLES2018 در آموزش عملکرد ترجمه بسیار بهتر می\u200cشود. ما همچنین با روش های مختلف پیش و بعد پردازش برای مدول NMT آزمایش کردیم، ولی ما موفقیت زیادی با این موفقیت نداشتیم. بهترین سیستم آزمایش ما به عنوان امتحان این سال ۱۶.۵۵ امتحان می رسد.', 'sq': 'Ky dokument përshkruan hyrjen e projektit MeMAD në Detyrën e Përkthimit të Fjalës IWSLT, duke adresuar përkthimin e audio anglez në tekstin gjerman. Midis tubacionit dhe gjurmëve të modelit nga fundi në fund, ne morëm pjesë vetëm në të mëparshmen, me tre sisteme kontraste. U përpoqëm edhe të fundit, por nuk arritëm të përfundojmë model in tonë në kohë. All of our systems start by transcribing the audio into text through an automatic speech recognition (ASR) model trained on the TED-LIUM English Speech Recognition Corpus (TED-LIUM).  Pas kësaj, ne i ushqejmë transkriptet në modele të përkthimit të makinave nervore (NMT) të bazuar në tekst anglisht-gjerman. Sistemet tona përdorin tre modele të ndryshme përkthimi të trajnuar në grupe të veçanta trajnimi të mbledhur nga pjesa anglisht-gjermane e korpusit të përkthimit të fjalëve TED (TED-TRANS) dhe pjesa OPENSUBTITLES2018 e koleksionit OPUS. In this paper, we also describe the experiments leading up to our final systems.  Eksperimentet tona tregojnë se përdorimi i OPENSUBTITLES2018 në stërvitje përmirëson ndjeshëm paraqitjen e përkthimit. Kemi eksperimentuar gjithashtu me rutina të ndryshme të predikimit dhe postprocesimit për modulin NMT, por nuk kemi pasur shumë sukses me këto. Sistemi ynë më i mirë shënon një rezultat BLEU prej 16.45 në testin e përcaktuar për detyrën e këtij viti.', 'tr': "Bu kagyz IWSLT söz terjime edilen Taýýasçylyga MeMAD projesiniň girişini Almança metine baglaýar. pipeline we ahyry nusgalaryň arasynda diňe öňki sistemlerde üç kontrast sistemlerde chikanchasydyk. Biz soňky hatda synanyşdyk, ýöne soňky hatlarymyzy wagtynda gutarmadyk. Hemme sistemamyz TED-LIUM Iňlisçe söz tanyşyk Corpus (TED-LIUM) bilen awtomatik çykyş tanyşyk bilen tekst bilen terjime etmek üçin başlaýarlar. Sonradan, olaryň terjimelerini iňlisçe-nemesçe metin tabanly neural maşynyň terjimesine (NMT) nusgalaryna berýäris. Biziň sistemamyz TED Speech Çaltylyşyň Corpus (TED-TRANS) we OPENSUBTITLES2018 jemgynyň böleginden gurlan üç dürli terjime modellerinde gurlýar. Bu kagyzda hem biziň soňky sistemamyza ulalan deneyleri tassykladyrys. Biziň deneylerimiz OPENSUBTITLES2018'i ulanmagynyň terjime etmäniň täsirini gowurap ýöretýändigini görkeýär. Biz hem NMT moduly üçin birnäçe öň-bellenen we bellenen işlemler bilen synanyşdyrdyk, ýöne bunlaryň üstüne kän başarylyk ýok. Biziň iň gowy gözlemek sistemamyz bu ýylyň işi üçin test edilýän günlerde BLEU-yň 16,45 sany barýar.", 'hy': 'Այս հոդվածը նկարագրում է MeMAD նախագծի գրառումը IwSlaT խոսքի թարգմանման ընդհանուր հանձնարարության համար, որն ուղղված է անգլերեն ձայնի թարգմանմանմանը գերմաներեն տեքստի: Կոռուցվածքի և վերջ-վերջ մոդելի հետքերի միջև մենք մասնակցեցինք միայն նախկինում, երեք հակադրական համակարգերով: Մենք նաև փորձեցինք վերջինը, բայց չենք կարողացել ավարտել մեր վերջնական մոդելը ժամանակի ընթացքում: Մեր բոլոր համակարգերը սկսում են հաղորդակցվելով ձայնի տեքստի մեջ ավտոմատիկ խոսքի ճանաչման (ASR) մոդելի միջոցով, որը վարժեցվել է TED-Լիումի անգլերենի խոսքի ճանաչման կորպուսի (TED-Լիումի) վրա: Հետո մենք տեղադրում ենք վերագրությունները անգլերեն-գերմանացի տեքստով հիմնված նյարդային մեքենայի (NMT) թարգմանման մոդելների մեջ: Մեր համակարգերը օգտագործում են երեք տարբեր թարգմանման մոդել, որոնք պատրաստված են առանձին ուսուցման համակարգերի վրա, որոնք կազմված են TED-խոսքի թարգմանման կորպոսի անգլերեն-գերմաներեն մասից (TED-Trans) և ՕՊՊԱՍ հավաքածու 2018 թվականի Օպե Այս աշխատանքում մենք նաև նկարագրում ենք փորձերը, որոնք հանգեցնում են մեր վերջին համակարգերին: Our experiments indicate that using OPENSUBTITLES2018 in training significantly improves translation performance.  Մենք նաև փորձարկում էինք NMT-ի մոդուլների բազմաթիվ նախաձեռնման և հետվերաշարժման սովորույթներով, բայց դրանց հետ շատ հաջողություն չկար: Մեր լավագույն գնահատման համակարգը ստանում է այս տարվա խնդիրների թեստերի համար 16.45 գնահատականը:', 'am': 'ይህ ፕሮግራም የMeMAD ፕሮጀክት ፕሮጀክት የIWSLT ንግግር ትርጓሜ የተShared ስራ ይዘረዝራል፤ የኢንጂልኛ ድምፅ ትርጉም ወደ ጀርመን ጽሑፍ ይናገራል። በጥምቀት እና መጨረሻ መጨረሻ የሞዴል መድረክ መካከል ሦስት ተቃዋሚ ስርዓቶች ብቻ ተጋራን፡፡ የኋለኞቹን ደግሞ ሞከርን ግን የፍጻሜውን መጨረሻ ሞዴል በጊዜው መጨመር አልቻልንም፡፡ All of our systems start by transcribing the audio into text through an automatic speech recognition (ASR) model trained on the TED-LIUM English Speech Recognition Corpus (TED-LIUM).  ከዚህም በኋላ የጽሑፎችን ንግግሊዝና-ጀርመን የጽሑፍ የነዌብ ማተርጓም (NMT) ሞዴላዎችን እናበላታለን፡፡ የቴድ ንግግር ትርጉም ኮርፓስ (TED-TRANS) እና የOPENSUBTITLES2018 ክፍል የቴድ ንግግር ትርጉም ክፍል (TED-TRANS) የቴድ-ጀርመን ትርጉም ክፍል የተለየ ሦስት የተለየ ትርጉም ዓይነቶች ያስተማራሉ። በዚህ ገጾች ውስጥ የመጨረሻ ስርዓታችንን ፈተና እናሳውቃለን፡፡ ፈተናዎቻችን የOPENSUBTITLES2018 በማስተማርት ትርጓሜዎችን በመጠቀም በኩል ያሳድጋል፡፡ እናም ለNMT module በተለየ የፊደል አካባቢ መንገዶች ፈተናል፤ ነገር ግን ከዚህ ጋር ብዙ ስኬተት አላገኘንም፡፡ የዚህ ዓመቱ ስራ ለፈተናው የተደረገውን የBLEU score 16.45 ደረጃ ያገኛል፡፡', 'ko': '본고는 영어 오디오를 독일어 텍스트로 번역하는 데 주력하는 국제음성번역협회(IWSLT) 음성번역 공유 임무의 Memad 프로젝트를 소개한다.파이프와 끝에서 끝 모델 궤도 사이에 우리는 전자만 참여했고 세 가지 비교 시스템이 있다.우리도 후자를 시험해 보았지만, 제때에 끝에서 끝까지 모형을 완성하지 못했다.우리의 모든 시스템은 TED-LIUM 영어 음성인식 자료 라이브러리(TED-LIUM)에서 훈련된 자동 음성인식(ASR) 모델을 통해 오디오를 텍스트로 녹음하기 시작한다.그리고 우리는 텍스트를 영어-독일어 텍스트 기반의 신경기계번역(NMT) 모델에 입력한다.우리 시스템은 세 가지 다른 번역 모델을 채택하여 각각 TED 음성 번역 어료 라이브러리(TED-TRANS)의 영덕 부분과 OPUS 문집의 OPENSUBTITLES 2018 부분을 컴파일한 훈련집에서 훈련한다.본문에서 우리는 최종 체계의 실험도 묘사하였다.우리의 실험은 훈련 중에 OPENSUBTITLES 2018을 사용하면 번역 성능을 현저하게 향상시킬 수 있음을 나타냈다.NMT 모듈의 다양한 전후 처리 루틴에 대한 실험도 수행했지만 큰 성공을 거두지 못했습니다.올해 시험에서 우리의 가장 좋은 평점 시스템은 16.45점에 달했다.', 'bn': 'এই পত্রিকাটি IWSLT ভাষার ভাষার অনুবাদ শেয়ার করা কাজের কাছে মেমাড প্রকল্পের এন্ট্রি বর্ণনা করেছে, যা জার্মান লেখায় ইংরেজি অ পাইপেলাইন এবং শেষ পর্যন্ত মডেল ট্র্যাকের মধ্যে, আমরা শুধুমাত্র প্রাক্তন সিস্টেমে অংশগ্রহণ করেছি, তিনটি বিরোধী সিস্টে আমরা শেষ পর্যন্ত চেষ্টা করেছিলাম, কিন্তু সময়ে আমাদের শেষ পর্যন্ত মডেল শেষ করতে পারলাম না। আমাদের সকল সিস্টেম স্বয়ংক্রিয় ভাষণ স্বীকৃতির মাধ্যমে অডিও টেক্সটে লেখার মাধ্যমে টেডি-লিউম ইংরেজি ভাষা স্বীকৃতি কোর্পাস (টেড-লিউম) প্ এরপর আমরা ইংরেজি-জার্মান-ভিত্তিক টেক্সট ভিত্তিক নিউরেল মেশিন অনুবাদ (এনএমটি) মডেলে ট্রান্সক্রিপ্টগুলোক আমাদের সিস্টেম তিনটি ভিন্ন ভিন্ন ভিন্ন অনুবাদ মডেল চালিয়ে যাচ্ছে প্রশিক্ষণ বিভিন্ন প্রশিক্ষণের প্রশিক্ষণের মাধ্যমে যা টেডি ভাষা অনুবাদ কর্পুস (টেড-ট্রান্ এই কাগজটিতে আমরা আমাদের শেষ ব্যবস্থায় যে পরীক্ষাগুলোতে যাচ্ছে তা বর্ণনা করি। আমাদের পরীক্ষাগুলো নির্দেশ করছে যে প্রশিক্ষণের মাধ্যমে ওপেন্সুবিটিটিলিএস২০১৮ ব্যবহার করে অনুবাদের অনুষ্ঠান এনএমটি মডিউলের জন্য বিভিন্ন পোস্ট প্রক্রিয়ার রুটিন দ্বারা আমরা পরীক্ষা করেছি, কিন্তু এগুলোর সাথে আমরা অনেক সফল হয়নি। আমাদের সর্বোচ্চ স্কোরিং সিস্টেম এই বছরের কাজের পরীক্ষায় ১৬.৪৫ স্কোর পৌঁছায়।', 'az': 'Bu kağıt, IWSLT Sözlük Çeviri paylaşılan işin MeMAD layihəsini Alman metinə çevirir. Pipçil və son-to-end modeli parçaları arasında, biz ancaq əvvəlkilərə, üç müxtəlif sistemlərlə birlikdə iştirak etdik. Sonrakıları da sınağa çəkdik, amma sonrakı modeliyimizi zamanda bitirmək bacarılmadıq. Tüm sistemlərimiz TED-LIUM İngilizə dilləri tanıması Corpus (TED-LIUM) ilə təhsil edilən səsini mətnə təkrarlayıb başlayırlar. Sonra, transkriptləri İngilizce-Almanca metin-tabanlı nöral makinatın çevirimi (NMT) modellərə təmin edirik. Bizim sistemlərimiz TED Speech Translation Corpus (TED-TRANS) və OPENSUBTITLES2018 koleksiyonun ayrı təhsil qurmaqlarında təhsil edilmiş üç cür çeviri modellərini istifadə edir. Bu kağızda, həmçinin son sistemlərimizə yol göstərən eksperimentləri də təsdiq edirik. Bizim təcrübələrimiz OPENSUBTITLES2018 təcrübəsində təcrübə etmək üçün təcrübələrini çox yaxşılaşdırır. Biz də NMT modulu üçün müxtəlif preand post-processing metodlarla təcrübə etdik, amma bunlardan çox başarılı olmadıq. Bizim ən yaxşı scoring sistemimiz bu il işinin s ınamasında 16,45 BLEU müqayisəsinə yetirir.', 'ca': "Aquest article descriu l'entrada del projecte MeMAD a la tasca compartida de traducció de vosaltres IWSLT, dirigint la traducció d'àudio anglès al text alemany. Entre el conductor i les pistes del model de final a final, vam participar només en els primers, amb tres sistemes contrastius. També vam intentar aquest últim, però no vam poder acabar el nostre model de final a final a temps. Tots els nostres sistemes comencen transcrit l'àudio en text a través d'un model de reconeixement automàtic de la voz (ASR) entrenat en el TED-LIUM English Speech Recognition Corpus (TED-LIUM). Després, alimentam les transcripcions en models de traducció neural (NMT) basats en text anglès-alemany. Els nostres sistemes emplenen tres models de traducció diferents entrenats en conjunts de formació separats compilats de la part anglo-alemana del TED Speech Translation Corpus (TED-TRANS) i la secció OPENSUBTITLES2018 de la col·lecció OPUS. In this paper, we also describe the experiments leading up to our final systems.  Els nostres experiments indican que utilitzar OPENSUBTITLES2018 en capacitació millora significativament el rendiment de la traducció. També vam experimentar amb diverses rutines de predicació i postprocessament del módul NMT, però no vam tenir gaire èxit amb aquests. El nostre sistema de millor puntuació obté un puntuatge BLEU de 16,45 en el conjunt de proves de la tasca d'aquest any.", 'cs': 'Tento článek popisuje vstup projektu MeMAD do sdíleného úkolu IWSLT Speech Translation Shared Task, který se zabývá překladem anglického zvuku do německého textu. Mezi potrubím a komplexními modelovými kolejemi jsme se podíleli pouze na prvním, se třemi kontrastními systémy. Zkoušeli jsme i to druhé, ale nebyli jsme schopni dokončit náš end-to-end model včas. Všechny naše systémy začínají přepisem zvuku do textu prostřednictvím modelu automatického rozpoznávání řeči (ASR) vyškoleného na TED-LIUM English Speech Recognition Corpus (TED-LIUM). Následně vkládáme přepisy do anglicko-německých textových modelů neuronového strojového překladu (NMT). Naše systémy využívají tři různé překladové modely trénované na samostatných výcvikových sadách sestavených z anglicko-německé části TED Speech Translation Corpus (TED-TRANS) a OPENSUBTITLES2018 sekce OPUS. V tomto článku také popisujeme experimenty vedoucí k našim konečným systémům. Naše experimenty ukazují, že použití OPENSUBTITLES2018 ve výcviku výrazně zlepšuje výkon překladu. Experimentovali jsme také s různými předzpracovávacími rutinami pro NMT modul, ale s nimi jsme neměli moc úspěchů. Náš nejlepší bodovací systém dosahuje BLEU skóre 16,45 na testovací sadě pro letošní úkol.', 'bs': 'Ovaj papir opisuje ulaz projekta MeMAD u IWSLT razgovor zajednički zadatak, koji se obraća prevodu engleskog zvuka na njemački tekst. Između cijevina i tragova modela do kraja, učestvovali smo samo u bivšim, sa tri kontrastivnih sustava. Pokušali smo i posljednju, ali nismo uspjeli završiti naš model kraja do kraja na vrijeme. Svi naši sustavi počinju prepisanjem zvuka na tekst putem automatskog priznanja govora (ASR) modela obučenog na korpusu priznanja TED-LIUM engleskog govora (TED-LIUM). Nakon toga, prevodimo transkripte u modele prevoda na engleskom i njemačkom tekstu neuromašine (NMT). Naši sustavi koriste tri različite modele prevoda obučene na odvojenim setima obuke, sastavljenim iz Engleskog-Njemačkog dijela TED-govornog prevodnog korpusa (TED-TRANS) i dio OPENSUBTITLES2018 kolekcije OPUS-a. U ovom papiru opisujemo i eksperimente koji vode do naših konačnih sustava. Naši eksperimenti ukazuju na to da korištenje OPENSUBTITLES2018 u obuci značajno poboljšava učinkovitost prevođenja. Također smo eksperimentirali sa različitim rutinama prei postprocessiranja za modul NMT-a, ali nismo imali mnogo uspjeha s tim. Naš najbolji sistem izvlačenja postiže BLEU rezultat od 16,45 na testu određenom za ovaj godišnji zadatak.', 'et': 'Käesolevas artiklis kirjeldatakse MeMAD projekti kirjet IWSLT kõnetõlke jagatud ülesandesse, mis käsitleb inglise heli tõlkimist saksa keelde. Torujuhtme ja otsast otsani mudelirajate vahel osalesime ainult esimesel, kolme kontrastse süsteemiga. Proovisime ka viimast, kuid ei suutnud oma otsast otsani mudelit õigeaegselt lõpetada. Kõik meie süsteemid alustavad heli transkribeerimisega tekstiks automaatse kõnetuvastuse (ASR) mudeli kaudu, mis on koolitatud TED-LIUM English Speech Recognition Corpus (TED-LIUM). Seejärel toimetame transkriptsioonid inglise-saksa tekstipõhistesse neuromasintõlke (NMT) mudelitesse. Meie süsteemid kasutavad kolme erinevat tõlkemudelit, mis on koolitatud eraldi koolituskomplektide alusel, mis on koostatud TED-TRANS (TED-TRANS) inglise-saksa osast ja OPUS kollektsiooni OPENSUBTITLES2018 jaotisest. Käesolevas töös kirjeldame ka katseid, mis viivad meie lõplike süsteemide. Meie eksperimendid näitavad, et OPENSUBTITLES2018 kasutamine koolitusel parandab oluliselt tõlketõhusust. Samuti katsetasime NMT mooduli erinevaid eel- ja järeltöötlusruume, kuid nendega ei olnud meil palju edu. Meie parima tulemuse süsteem saavutab BLEU skoori 16,45 selle aasta ülesande testikomplektis.', 'af': "Hierdie papier beskryf die MeMAD projek inskrywing na die IWSLT Spraak Vertaling Gedeelde Taak, om die vertaling van Engelse oudio in Duitse teks te adres. Tussen die pyplyn en die einde-tot-einde model snitte, het ons slegs gedeel in die vorige, met drie kontrastiewe stelsels. Ons het ook die laaste probeer, maar was nie in staat om ons end-to-end model in tyd te voltooi nie. Alle ons stelsels begin deur die oudio na teks te oorskryf deur 'n automatiese spreek herken model (ASR) wat op die TED-LIUM Engelske spraak herkening Korpus (TED-LIUM) opgelei is. Daarna voer ons die transkripte in Engels- Duitse teks gebaseerde neurale masjien vertaling (NMT) modele. Ons stelsels gebruik drie verskillende vertalingsmodelles wat onderwerp word op aparte onderwerp stelle wat gemaak is van die Engels-Duitse deel van die TED Spraak Vertaling Korpus (TED-TRANS) en die OPENSUBTITLES2018 seksie van die OPUS versameling. In hierdie papier beskrywe ons ook die eksperimente wat tot ons eindelike stelsels laat loop. Ons eksperimente wys dat die gebruik van OPENSUBTITLES2018 in onderwerp betekeurig verbeter vertaling. Ons het ook eksperimenteer met verskillende voorspoediging en postprosessering routines vir die NMT module, maar ons het nie baie sukses met hierdie nie. Ons beste-skoring stelsel het 'n BLEU-punt van 16,45 op die toets stel vir hierdie jaar se taak.", 'fi': 'Tässä artikkelissa kuvataan MeMAD-projektin kirjausta IWSLT Speech Translation Shared Task -tehtävään, joka käsittelee englanninkielisen äänen kääntämistä saksankieliseksi tekstiksi. Putkiputken ja end-to-end-malliradan välissä osallistuimme vain ensimmäiseen, kolmella kontrastijärjestelmällä. Kokeilimme myös jälkimmäistä, mutta emme onnistuneet viimeistelemään end-to-end mallia ajoissa. Kaikki järjestelmämme alkavat kirjoittamalla äänen tekstiksi automaattisen puheentunnistusmallin (ASR) avulla, joka on koulutettu TED-LIUM English Speech Recognition Corpus (TED-LIUM). Tämän jälkeen syötämme transkriptit englannin-saksan tekstipohjaisiin neurokonekäännösmalleihin (NMT). Järjestelmämme käyttävät kolmea erilaista käännösmallia, jotka on koulutettu erillisillä koulutussarjoilla, jotka on koottu TED Speech Translation Corpuksen englannin-saksan osasta (TED-TRANS) ja OPUS-kokoelman OPENSUBTITLES2018-osasta. Tässä työssä kuvaamme myös kokeita, jotka johtivat lopulliseen järjestelmäämme. Kokeemme osoittavat, että OPENSUBTITLES2018:n käyttö koulutuksessa parantaa merkittävästi käännösten suorituskykyä. Kokeilimme myös erilaisia NMT-moduulin pre- ja jälkikäsittelyrutiineja, mutta emme onnistuneet näissä. Paras pisteytysjärjestelmämme saavuttaa BLEU-pisteen 16,45 tämän vuoden testisarjassa.', 'jv': 'Pesene iki rambarang kelas MeMAD kuwi panggon Perojek IWSLT Kemerdekaan Tarjamahan Akir IWSLT Jejaring Awak dhéwé mulai ngono last, njuk kepengin iso mulai model sing ditambah sisan ngono ngono. Lah sistem awak dhéwé mulai nang nggalakno akeh dumaten kanggo teks sing berarti (ASR) model sing ditambah nggawe barang nggo rerakno sistem sing berarti tarjamahan kanggo nggawe tarjamahan kanggo kelas token (ED-LIUT). Tulung, kita nyimpen manung tarjamahan kanggo modèrn nggambar Text-German, basa Neral Masin Terjamahan (NMT). Sistem-sistem anyun gunakake telu model sing itlanjut sampeyan anyar tentang karo pakem nggawe gerakan ning pitik Inggris-German karo nggawe tarjamahan kanggo kelas telu nggunakake corpus Nang mapun iki, awak dhéwé ngerasakno perbudhakan kanggo ngerasah sistem tuku. Awakdhéwé éntuk nggawe barang-barang nggawe OPENSUBTITITITITITITITITI nang nggawe tarjamahan luwih bantuan ngono nggawe tarjamahan. Awak dhéwé éntuk éntukno ngono nggawe sistem preiane lan ngawe barang-sistem kanggo ngilangno NMT, sane dhewe ora ono akeh lanes ngono iki dadi. Sistem-sistem sing paling nggawe barang kanggo tarjamahan kanggo 16.4 ujian sing paling kanggo ujian kanggo nggawe lanjut sing tau.', 'sk': 'V prispevku je opisan vnos projekta MeMAD v skupno nalogo prevajanja govora IWSLT, ki obravnava prevajanje angleškega zvoka v nemško besedilo. Med cevovodnimi in modelnimi progami od konca do konca smo sodelovali le v prvem, s tremi kontrastnimi sistemi. Poskusili smo tudi slednjega, vendar nismo uspeli pravočasno dokončati modela od konca do konca. Vsi naši sistemi se začnejo s transkripcijo zvoka v besedilo prek modela avtomatskega prepoznavanja govora (ASR), usposobljenega na TED-LIUM English Speech Recognition Corpus (TED-LIUM). Nato jih prenesemo v angleško-nemške besedilne modele nevronskega strojnega prevajanja (NMT). Naši sistemi uporabljajo tri različne prevajalske modele, usposobljene na ločenih naborih usposabljanj, sestavljenih iz angleško-nemškega dela TED Speech Translation Corpus (TED-TRANS) in oddelka OPENSUBTITLES2018 zbirke OPUS. V prispevku opisujemo tudi poskuse, ki so vodili do končnih sistemov. Naši eksperimenti kažejo, da uporaba OPENSUBTITLES2018 pri usposabljanju bistveno izboljša učinkovitost prevajanja. Prav tako smo eksperimentirali z različnimi pred- in popobdelavnimi rutinami za NMT modul, vendar nismo imeli veliko uspeha. Naš sistem najboljših točk doseže BLEU rezultat 16,45 na testnem kompletu za letošnjo nalogo.', 'he': 'This paper describes the MeMAD project entry to the IWSLT Speech Translation Shared Task, addressing the translation of English audio into German text.  בין צינור למסלולים של מודל בסוף לסוף, השתתפנו רק במערכות הקודמות, עם שלושה מערכות נוגדות. ניסינו גם את האחרון, אבל לא הצלחנו לסיים את המודל שלנו סוף-סוף בזמן. כל המערכות שלנו מתחילות על ידי שיתוף את האודיו לטקסט באמצעות מודל זיהוי נאום אוטומטי (ASR) מאומן על הקורפוס של TED-LIUM זיהוי נאום אנגלי (TED-LIUM). לאחר מכן, אנו מאכילים את התסריטים למודלים של מכונות עצביות מבוססות בטקסט אנגלי-גרמנית (NMT). המערכות שלנו משתמשות בשלושה דוגמנים של תרגום שונים מאומנים על קבוצות אימונים נפרדות מארגן החלק האנגלי-גרמני של TED Speech Translation Corpus (TED-TRANS) והחלק OPENSUBTITLES2018 של אוסף OPUS. בעיתון הזה, אנחנו גם מתארים את הניסויים שמובילים למערכות הסופיות שלנו. הניסויים שלנו מצביעים כי השימוש OPENSUBTITLES2018 באימונים משפר משמעותית ביצועי התרגום. ניסונו גם עם שגרות שונות של טיפול ואחרי העבודה למודוד NMT, אבל לא הצלחנו הרבה עם אלה. המערכת הטובה ביותר שלנו משיגה נקודת BLEU של 16.45 על קבוצת הבדיקות למשימה של השנה.', 'ha': "@ item Text character set A tsakanin hanyar misalin da zuwa ƙari-ƙari, ba mu yi rabo ba kawai na farko, da wasu na'ura masu motsi uku. Kuma ba mu jarraba ƙarshe ba, kuma ba za mu iya cika ƙarami ba a lokacin. Dukan system-yiwunmu ke fara ta rubutu sauti zuwa matsayi, kowane misalin akwatin bayani na gane (ATR) da aka yi wa shirin a kan KCharselect unicode na Ingiriya na TeD-LIUM (TeD-LIUM). Ga bayan haka, Munã ciyar da transcripts zuwa misalin ayuka na Ingiriya-Jarman-bakin rubutun neural na zane (NMT). Yauranmu suna aikin misãlai uku masu turjuya ko da aka yi wa shirin su da aka haɗa a matsayin taƙaitãwa guda da aka haɗa shi daga shirin Ingiriya-Jarman da rabon tarjibu na TeD-TRANS (TeD-TRANS) da rabon shirin OPSUBTITLES2018. Ga wannan takardan, Munã bayyana misãlai masu ƙarami zuwa na'asarmu. Kayan jarrabõnmu sun nuna cẽwa, a yi amfani da OPANSUBTITLES2018 cikin shirin da aka gyara fassarar da shi mai girma. Haƙĩƙa, Mun jarraba hanyõyi daban-dabam-dabam ga shirin NMT, kuma ba mu sami babban rabo ba da waɗannan. Tsarin da ke kyakkanci ya sami wata na BLEU mai girma a samun jarrabar aikin wannan shekara.", 'bo': 'ཤོག་བྱང་འདིས་MeMAD་ལས་འགུལ་གྱི་ནང་དུ་IWSLT Speech འདི་ཆ་རུང་བའི་བྱ་འགུལ་དང་མཉམ་སྤྲོད་ཀྱི་ཡིག་སྣོད་ལ་སྤྲོད་ཀྱི་ཡོད་པ Between the pipeline and end-to-end model tracks, we participated only in the former, with three contrastive systems. ང་ཚོས་དུས་མཇུག་གི་མི་མང་པོ་དེ་ལྟ་བྱེད་ཀྱི་ཡོད། ཡིན་ནའང་དུས་ཚོད་མཇུག་མཇུག་བསྡད་མི་ཐུབ། All of our systems start by transcribing the audio into text through an automatic speech recognition (ASR) model trained on the TED-LIUM English Speech Recognition Corpus (TED-LIUM). དེ་རྗེས་སུ། འུ་ཚོས་ཡིག་གི་ཚིག་ཡིག Our systems employ three different translation models trained on separate training sets compiled from the English-German part of the TED Speech Translation Corpus (TED-TRANS) and the OPENSUBTITLES2018 section of the OPUS collection. ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་དུས་ཚོད་བྱ་ཚིག་གི་མཐའ་མ་ལག་གི་ཐུག་སྒྲིལ་འགོད་བཞིན་ཡོད། ང་ཚོའི་ལས་འཚོལ་ཞིབ་ཀྱིས་OPENSUBTITLES2018་ཡོད་བཞིན་པའི་སྐབས་བསྒྱུར་གྱི་ལས་འཚོལ་ལྟར་ཡར་རྒྱས་གཏོང་། ང་ཚོས་NMT འདྲ་མཐུད་ཀྱི་སྔོན་འགྱུར་བའི་ལྟ་བུའི་རྒྱུན་ལམ་མིན་འདུག་ལས་ཀྱང་མཐོང་སྣང་མེད། ང་ཚོའི་འཛམ་གླིང་གི་མ་ལག་གི་ཚད་ལྟར་སྐྱེལ་བཞིན་པའི་ཚད་ལྟར་༡༦.༥ཡིས་རྙེད་ཐུབ་པ་རེད།'}
{'en': 'Samsung and University of Edinburgh’s System for the IWSLT 2018 Low Resource MT Task S amsung and  U niversity of  E dinburgh’s System for the  IWSLT  2018 Low Resource  MT  Task', 'ar': 'نظام سامسونج وجامعة إدنبرة لمهمة IWSLT 2018 منخفضة الموارد MT', 'pt': 'Sistema da Samsung e da Universidade de Edimburgo para a tarefa de MT de baixo recurso do IWSLT 2018', 'fr': "Système de Samsung et de l'Université d'Édimbourg pour la tâche de TA à faible ressource IWSLT 2018", 'es': 'El sistema de Samsung y la Universidad de Edimburgo para la tarea de MT de bajos recursos de IWSLT 2018', 'ja': "Samsung and University of Edinburgh 's System for the IWSLT 2018 Low Resource MT Task", 'zh': '三星、爱丁堡大学以 IWSLT 2018 低资源 MT 事统', 'hi': 'IWSLT 2018 कम संसाधन एमटी टास्क के लिए सैमसंग और एडिनबर्ग विश्वविद्यालय की प्रणाली', 'ru': 'Система Samsung и Эдинбургского университета для задачи IWSLT 2018 «МТ с ограниченными ресурсами»', 'ga': 'Córas Samsung agus Ollscoil Dhún Éideann do Thasc MT Acmhainn Íseal 2018 IWSLT', 'ka': 'სისტემის სისტემი ვებინდონის სუნივერსიტი სამუშაო სისტემი IWSLT 2018', 'hu': 'A Samsung és az Edinburgh-i Egyetem rendszere az IWSLT 2018 Low Resource MT feladathoz', 'kk': 'Эдинбург университетінің Самбург және ИWSLT 2018 төмен ресурс MT тапсырмасы', 'mk': 'Самсунг и Универзитетскиот систем на Единбург за IWSLT 2018 Low Resource MT Task', 'el': 'Το σύστημα της Samsung και του Πανεπιστημίου του Εδιμβούργου για την εργασία με χαμηλούς πόρους', 'ms': "Samsung and University of Edinburgh's System for the IWSLT 2018 Low Resource MT Task", 'ml': 'IWSLT 2018 കുറഞ്ഞ വിഭവങ്ങള്\u200d', 'lt': 'Samsung ir Edinburgo universiteto sistema, skirta 2018 m. IWSLT mažų išteklių MT užduotims', 'mt': "Samsung u s-Sistema tal-Università ta' Edinburgh għall-IWSLT 2018 Low Resource MT Task", 'mn': 'Самбун болон Эдинбургийн Их Сургуулийн систем IWSLT 2018 оны бага нөөц MT ажил', 'pl': 'System Samsung i Uniwersytetu Edynburga dla zadania IWSLT 2018 Low Resource MT', 'ro': 'Sistemul Samsung și Universitatea din Edinburgh pentru IWSLT 2018 Low Resource MT Task', 'sr': 'Samsung i Edinburgov sistem Univerziteta za IWSLT 2018 Low Resource MT Task', 'it': "Samsung e l'Università di Edimburgo per l'IWSLT 2018 Low Resource MT Task", 'si': 'සැම්සන්ග් සහ ඉන්දින්බර්න්ග් විද්\u200dයාපාලයේ පද්ධති', 'so': "Samsung and University of Edinburgh's System for the IWSLT 2018 Low Resource MT Task", 'sv': 'Samsung och University of Edinburgh system för IWSLT 2018 Low Resource MT Task', 'ta': 'IWSLT 2018 குறைந்த மூலம் MT பணி', 'no': "Samsung og University of Edinburgh's System for the IWSLT 2018 Low Resource MT Task", 'ur': 'سامبنگ اور ایڈینبرنگ کے سیسٹم کے سامنڈ اور یونیوریسٹ کا IWSLT 2018 نیچے رسسوس MT ٹاکس کے لئے', 'uz': 'Name', 'vi': 'Hệ thống của Samsung và Đại học Edinburgh cho công việc l.WSLT vượt tài nguyên nhãi MTV', 'da': "Samsung og University of Edinburgh's system til IWSLT 2018 Low Resource MT Task", 'nl': "Samsung en University of Edinburgh's systeem voor de IWSLT 2018 Low Resource MT Task", 'bg': 'Системата на Самсунг и Университета в Единбург за задачата с нисък ресурс', 'hr': 'Samsung i Edinburgov sustav Univerziteta za IWSLT 2018 Low Resource MT zadatak', 'de': 'Samsung und University of Edinburgh System für die IWSLT 2018 Low Resource MT Task', 'id': "Samsung and University of Edinburgh's System for the IWSLT 2018 Low Resource MT Task", 'tr': 'IWSLT 2018 IWSLT üçin Samsung we Edimburgyň Uniwersiteti', 'sw': 'Samsung na Mfumo wa Chuo Kikuu cha Edinburgh kwa kazi ya IWSLT 2018 rasilimali chini MT', 'ko': '삼성과 에든버러대는 IWSLT 2018 저자원 MT 미션을 위한 시스템', 'af': 'Samsung en Universiteit van Edinburger se Stelsel vir die IWSLT 2018 Lae hulpbron MT taak', 'fa': 'سیستم دانشگاه سامانگ و دانشگاه ادینبورگ برای کار MT کم منابع ۲۰۱۸ IWSLT', 'az': 'Samsung və Edinburgon Universiteti IWSLT 2018 Low Resource MT Taski', 'bn': 'IWSLT ২০১৮ নিম্ন রিসোর্স এমটি কাজের জন্য স্যামসাংগ এবং এডিনবার্গ বিশ্ববিদ্যালয়ের সিস্টেম', 'bs': 'Samsung i Edinburgov sustav Univerziteta za IWSLT 2018 Low Resource MT Task', 'ca': "Samsung i el Sistema de la Universitat d'Edimburgo per la tasca de MT de baix recursos IWSLT 2018", 'sq': 'Samsung dhe Sistemi i Universitetit të Edinburgut për IWSLT 2018', 'cs': 'Systém společnosti Samsung a univerzity v Edinburghu pro IWSLT 2018 Nízké zdroje MT Task', 'et': 'Samsungi ja Edinburghi Ülikooli süsteem IWSLT 2018 madala ressursiga MT ülesandeks', 'am': 'ሳምsung እና የኤዲንቡር ዩኒቨርስቲ ስርዓት ለIWSLT 2018 ታናሽ ምህርት MT ስራ', 'fi': 'Samsungin ja Edinburghin yliopiston järjestelmä IWSLT 2018 Low Resource MT -tehtävään', 'hy': 'Սամսունգը և Էդինբուրգի համալսարանի համակարգը 2018 թվականի IW-ն ցածր ռեսուրսների MT-ի հանձնարարության համար', 'jv': "Tambun karo Universite di Ubuntu's System kanggo IWSLT 2008 Mawek Ressource MT task", 'he': "Samsung and University of Edinburgh's System for the IWSLT 2018 Low Resource MT Task", 'sk': 'Samsungov in Univerza v Edinburgu sistem za nalogo MT z nizkimi viri IWSLT 2018', 'ha': "Samsung and University of edinburg's system for the IWSLT 2018 Low Resource MT Tasks", 'bo': "Samsung and University of Edinburgh's System for the IWSLT 2018 Low Resource MT Task"}
{'en': 'This paper describes the joint submission to the IWSLT 2018 Low Resource MT task by Samsung R&D Institute, Poland, and the University of Edinburgh. We focused on supplementing the very limited in-domain Basque-English training data with out-of-domain data, with  synthetic data , and with data for other language pairs. We also experimented with a variety of model architectures and features, which included the development of extensions to the Nematus toolkit. Our submission was ultimately produced by a system combination in which we reranked translations from our strongest individual system using multiple weaker systems.', 'ar': 'تصف هذه الورقة التقديم المشترك لمهمة IWSLT 2018 Low Resource MT بواسطة Samsung R&D Institute ، بولندا ، وجامعة إدنبرة. ركزنا على تكملة بيانات تدريب لغة الباسك الإنجليزية المحدودة للغاية في المجال ببيانات خارج المجال ، وبيانات تركيبية ، وبيانات لأزواج لغوية أخرى. لقد جربنا أيضًا مجموعة متنوعة من هياكل وميزات النماذج ، والتي تضمنت تطوير ملحقات لمجموعة أدوات Nematus. تم إنتاج إرسالنا في النهاية من خلال مجموعة نظام قمنا من خلالها بإعادة ترتيب الترجمات من أقوى نظام فردي لدينا باستخدام أنظمة أضعف متعددة.', 'es': 'Este documento describe la presentación conjunta a la tarea de MT de bajos recursos IWSLT 2018 por parte del Instituto de I+D de Samsung, Polonia, y la Universidad de Edimburgo. Nos centramos en complementar los muy limitados datos de capacitación vasco-inglés dentro del dominio con datos fuera del dominio, con datos sintéticos y con datos de otras combinaciones de idiomas. También experimentamos con una variedad de arquitecturas y características de modelos, que incluían el desarrollo de extensiones del kit de herramientas Nematus. Nuestra presentación se produjo en última instancia mediante una combinación de sistemas en la que cambiamos la clasificación de las traducciones de nuestro sistema individual más sólido utilizando varios sistemas más débiles.', 'fr': "Ce document décrit la soumission conjointe à la tâche IWSLT 2018 Low Resource MT par le Samsung R&D Institute, Pologne, et l'Université d'Édimbourg. Nous nous sommes attachés à compléter les données très limitées de formation basque-anglais dans le domaine par des données hors domaine, des données synthétiques et des données pour d'autres paires de langues. Nous avons également expérimenté diverses architectures et fonctionnalités de modèles, notamment le développement d'extensions de la boîte à outils Nematus. Notre soumission a finalement été produite par une combinaison de systèmes dans laquelle nous avons reclassé les traductions de notre système individuel le plus puissant en utilisant plusieurs systèmes plus faibles.", 'pt': 'Este artigo descreve a submissão conjunta à tarefa IWSLT 2018 Low Resource MT pelo Samsung R&D Institute, Polônia, e pela Universidade de Edimburgo. Nós nos concentramos em complementar os dados de treinamento basco-inglês no domínio muito limitados com dados fora do domínio, com dados sintéticos e com dados para outros pares de idiomas. Também experimentamos uma variedade de arquiteturas e recursos de modelo, que incluíam o desenvolvimento de extensões para o kit de ferramentas do Nematus. Nossa submissão foi produzida por uma combinação de sistemas na qual reclassificamos as traduções de nosso sistema individual mais forte usando vários sistemas mais fracos.', 'ja': '本稿では、ポーランドのSamsung R&amp;D Instituteとエディンバラ大学によるIWSLT 2018 Low Resource MTタスクへの共同提出について述べる。私たちは、非常に限られたドメイン内バスク語-英語トレーニングデータを、ドメイン外データ、合成データ、および他の言語ペアのデータで補完することに焦点を当てました。また、Nematusツールキットの拡張機能の開発を含む、さまざまなモデルアーキテクチャと機能を実験しました。当社の提出物は、最終的に、複数の弱いシステムを使用して最強の個々のシステムから翻訳を再ランク付けするシステムの組み合わせによって作成されました。', 'zh': '本文述波兰三星研发研究所与爱丁堡大学IWSLT 2018低资源MT事合。 专注域外数、合成数、语言对数以补非常之巴斯克语-英语训练。 试诸架构功能,开张Nematus工具包。 我们的提交终于一个系统,在这里用多较弱的系统重排了我们最强的单个系统的译。', 'hi': 'यह पेपर सैमसंग आर एंड डी इंस्टीट्यूट, पोलैंड और एडिनबर्ग विश्वविद्यालय द्वारा IWSLT 2018 कम संसाधन एमटी कार्य के लिए संयुक्त प्रस्तुतीकरण का वर्णन करता है। हमने आउट-ऑफ-डोमेन डेटा के साथ, सिंथेटिक डेटा के साथ और अन्य भाषा जोड़े के लिए डेटा के साथ बहुत सीमित इन-डोमेन बास्क-अंग्रेजी प्रशिक्षण डेटा को पूरक करने पर ध्यान केंद्रित किया। हमने विभिन्न प्रकार के मॉडल आर्किटेक्चर और सुविधाओं के साथ भी प्रयोग किया, जिसमें नेमेटस टूलकिट के एक्सटेंशन का विकास शामिल था। हमारा सबमिशन अंततः एक सिस्टम संयोजन द्वारा उत्पादित किया गया था जिसमें हमने कई कमजोर प्रणालियों का उपयोग करके अपनी सबसे मजबूत व्यक्तिगत प्रणाली से अनुवादों को फिर से तैयार किया था।', 'ru': 'В этой статье описывается совместное представление задачи IWSLT 2018 Low Resource MT Институтом исследований и разработок Samsung, Польша, и Эдинбургским университетом. Мы сосредоточились на дополнении очень ограниченных внутридоменных данных обучения баскскому и английскому языкам внедоменными данными, синтетическими данными и данными для других языковых пар. Мы также экспериментировали с различными архитектурами и функциями модели, которые включали в себя разработку расширений для инструментария Nematus. Наше представление в конечном итоге было произведено комбинацией систем, в которой мы перераспределили переводы из нашей самой сильной индивидуальной системы, используя несколько более слабых систем.', 'ga': 'Déanann an páipéar seo cur síos ar chomh-aighneacht chuig tasc MT Íseal Acmhainne IWSLT 2018 ag Samsung R&D Institute, an Pholainn, agus Ollscoil Dhún Éideann. Dhíríomar ar na sonraí traenála Bascais-Béarla an-teoranta a fhorlíonadh le sonraí lasmuigh den fhearann, le sonraí sintéiseacha, agus le sonraí do phéirí teangacha eile. Rinneamar trialacha freisin le héagsúlacht ailtireachta agus gnéithe samhail, lena n-áirítear forbairt síntí ar fhoireann uirlisí Nematus. I ndeireadh na dála, rinneadh ár n-aighneacht trí chomhcheangal córais inar athrangaíomar aistriúcháin ónár gcóras aonair is láidre ag baint úsáide as córais iolracha níos laige.', 'ka': 'ამ წიგნის აღწერა ერთადერთი წიგნის შესახებ IWSLT 2018-ის სამუშაო რესურსის MT სამუშაო ინსტისტუტი, პოლინდი და ვებინდონის სუნივერტუტიდან. ჩვენ დავყენებდით ძალიან დაზრუქებული ბასკი-ანგლისური განაკლების მონაცემების დამატებით, სინტეტიური მონაცემებით და სხვა ენის ზოგებისთვის მონაცემებით. ჩვენ ასევე ექსპერიმენტირებდით მსხვადასხვა მოდელური არქტიქტურებით და ფუნქციებით, რომლებიც ნემატუსის ხელსაწყოთა კიტის განვითარებას შეგვიყვანეთ ჩვენი შემდეგ საკუთოდ სისტემის კომბინეციაში გამოვიყენება, რომელიც ჩვენ უფრო ძალიან სისტემიდან გამოვიყენებთ მრავალი სისტემის გამოყენებას.', 'el': 'Η παρούσα εργασία περιγράφει την κοινή υποβολή στο έργο του Ινστιτούτου Ε&Α της Πολωνίας και του Πανεπιστημίου του Εδιμβούργου. Επικεντρωθήκαμε στη συμπλήρωση των πολύ περιορισμένων βασκικών-αγγλικών εκπαιδευτικών δεδομένων με δεδομένα εκτός τομέα, με συνθετικά δεδομένα και με δεδομένα για άλλα γλωσσικά ζεύγη. Πειραματιστήκαμε επίσης με μια ποικιλία μοντέλων αρχιτεκτονικών και χαρακτηριστικών, τα οποία περιελάμβαναν την ανάπτυξη επεκτάσεων στο κιτ εργαλείων Νεμάτου. Η υποβολή μας τελικά δημιουργήθηκε από έναν συνδυασμό συστήματος στον οποίο επανακατατάξαμε μεταφράσεις από το ισχυρότερο ατομικό μας σύστημα χρησιμοποιώντας πολλαπλά ασθενέστερα συστήματα.', 'hu': 'Ez a tanulmány bemutatja a Samsung K+F Intézet és az Edinburgh-i Egyetem közös benyújtását az IWSLT 2018 Low Resource MT feladatra. A nagyon korlátozott tartományon belüli baszk-angol képzési adatok kiegészítésére összpontosítottunk domain kívüli adatokkal, szintetikus adatokkal és más nyelvpárokra vonatkozó adatokkal. Különböző modellarchitektúrákkal és funkciókkal is kísérleteztünk, beleértve a Nematus eszközkészlet bővítéseit is. A beadványunkat végül egy rendszerkombináció készítette, amelyben a legerősebb egyéni rendszerünk fordításait több gyengébb rendszer segítségével rangsoroltuk át.', 'it': "Questo articolo descrive la presentazione congiunta al compito IWSLT 2018 Low Resource MT da parte del Samsung R&D Institute, Polonia, e dell'Università di Edimburgo. Ci siamo concentrati sull'integrazione dei dati di formazione basco-inglese molto limitati nel dominio con dati fuori dominio, con dati sintetici e con dati per altre coppie linguistiche. Abbiamo anche sperimentato una varietà di architetture e funzionalità dei modelli, tra cui lo sviluppo di estensioni al toolkit di Nematus. La nostra presentazione è stata infine prodotta da una combinazione di sistemi in cui abbiamo rivalutato le traduzioni dal nostro sistema individuale più forte utilizzando più sistemi più deboli.", 'kk': 'Бұл қағаз Сумсинг R&D институты, Польша және Эдинбург университетінің IWSLT 2018-нің төменгі ресурстар MT тапсырмасына біріктірілген жұмысын таңдайды. Біз домендегі баск-ағылшын оқыту деректерін доменге, синтетикалық деректерді, басқа тілдер қосымша деректерді қосымша көмектесдік. Біз сондай-ақ нематус құралдарының кеңейтулерін жасау үлгілері мен мүмкіндіктерін түрлі тәжірибелерді тәжірибеледік. Біздің көмегіміздің соңында жүйелік комбинациясы жасалған. Біз оның ең күшті жүйеңізден бірнеше күшті жүйеңіздің аудармаларын көмектеседі.', 'lt': 'Šiame dokumente aprašomas bendras Samsungo MT instituto, Lenkijos ir Edinburgo universiteto pateiktas IWSLT 2018 m. mažų išteklių MT užduotis. Mes sutelkėme dėmesį į labai ribotų baskų ir anglų mokymo duomenų papildymą ne srities duomenimis, sintetiniais duomenimis ir kitų kalbų poros duomenimis. Taip pat eksperimentavome su įvairiomis modelių architektūromis ir savybėmis, įskaitant Nematus įrankių rinkinio išplėtimą. Mūsų pareiškimą pagaliau sukūrsistemų derinys, kuriame persvarstėme vertimus iš stipriausios atskiros sistemos naudojant daugelį silpnesnių sistemų.', 'ms': 'Kertas ini menggambarkan penghantaran bersama kepada tugas MT Sumber Terrendah IWSLT 2018 oleh Samsung R&D Institute, Poland, dan Universiti Edinburgh. Kami fokus pada tambahan data latihan dalam domain Bahasa-Inggeris yang sangat terbatas dengan data luar domain, dengan data sintetik, dan dengan data untuk pasangan bahasa lain. We also experimented with a variety of model architectures and features, which included the development of extensions to the Nematus toolkit.  Penghantaran kami pada akhirnya dihasilkan oleh kombinasi sistem di mana kami menyatukan terjemahan semula dari sistem individu terkuat kami menggunakan sistem yang lebih lemah berbilang.', 'mk': 'Овој документ го опишува заедничкото поднесување на IWSLT 2018-та задача на МТ со ниски ресурси од страна на Samsung R&D Институтот, Полска и Универзитетот во Единбург. Се фокусиравме на комплиментирање на многу ограничени податоци за обука во баски-англиски домен со податоци надвор од домен, со синтетички податоци и со податоци за други јазички парови. Исто така експериментиравме со различни моделни архитектури и карактеристики, кои вклучуваа развој на проширувања на алатките на Нематус. Нашето поднесување на крајот беше произведено од системска комбинација во која ги повторивме преводите од нашиот најсилен индивидуален систем користејќи повеќе послаби системи.', 'ml': 'ഈ പേപ്പറിന്റെ കൂട്ടത്തില്\u200d IWSLT 2018 കുറഞ്ഞ വിഭവങ്ങള്\u200d എംടി ജോലിയിലേക്ക് കൊടുക്കുന്നതിനെ വിശദീകരിക്കുന്നു ഡൊമൈന്\u200d ബാസ്ക്-ഇംഗ്ലീഷ് പരിശീലന വിവരങ്ങള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നതിന് ഞങ്ങള്\u200d ശ്രദ്ധിച്ചിരിക്കുന്നു. ഡോംമെയിന്\u200d വിവരങ്ങള്\u200d,  നെമുട്ടുകളുടെ ഉപകരണങ്ങളിലേക്ക് വികസിപ്പിക്കപ്പെടുന്നതിനെക്കുറിച്ചും മാതൃകയുടെ ആര്\u200dക്കിട്ടറുകളെയും പരീക്ഷിച്ചി നമ്മുടെ സമ്മതം അവസാനം ഒരു സിസ്റ്റത്തിന്റെ കൂട്ടത്താല്\u200d ഉണ്ടാക്കിയിരുന്നു. അതില്\u200d നമ്മുടെ ശക്തരായ വ്യക്തിപരമായ വ്യവസ്ഥ', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni konġunta lill-IWSLT 2018 Low Resource MT task minn Samsung R&D Institute, il-Polonja, u l-Università ta’ Edinburgh. Aħna ffukajna fuq is-supplimentazzjoni tad-dejta limitata ħafna tat-taħriġ Bask-Ingliż fid-dominju b’dejta barra d-dominju, b’dejta sintetika, u b’dejta għal pari lingwistiċi oħra. Esperimentajna wkoll b’varjetà ta’ arkitetturi u karatteristiċi mudell, li inkludew l-iżvilupp ta’ estensjonijiet għall-għodda Nematus. Is-sottomissjoni tagħna fl-a ħħar mill-aħħar ġiet prodotta minn kombinazzjoni ta’ sistema li fiha rriankjna t-traduzzjonijiet mis-sistema individwali l-aktar b’saħħitha tagħna bl-użu ta’ sistemi multipli aktar dgħajfa.', 'mn': 'Энэ цаас нь Самбун R&D Институт, Польша, Эдинбургийн Их Сургууль, 2018 оны IWSLT-д бага нөөцийн MT-ын ажлын нийлбэртэй хамтдаа хамтдаа тайлбарладаг. Бид баск-Англи хэлний сургалтын мэдээллийг бүтээгдэхүүнээс, синтетик өгөгдлийг, бусад хэлний хооронд өгөгдлийг нэмэхэд төвлөрсөн. Мөн бид олон загварын архитектурууд болон өөр өөр төрлийн төлөвлөгөөтэй туршилт хийсэн. Энэ нь Ниматусын хэрэгсэл хөгжлийн хөгжлийг оруулсан. Бидний хүлээн зөвшөөрөл нь системийн нэгтгэлээс гарч ирсэн. Бид өөрсдийн хамгийн хүчтэй системээс олон сул системийг ашиглан өөрсдийгөө дахин хөгжүүлсэн.', 'pl': 'Niniejszy artykuł opisuje wspólne zgłoszenie do zadania IWSLT 2018 Low Resource MT przez Samsung R&D Institute, Polska i Uniwersytet w Edynburgu. Skupiliśmy się na uzupełnieniu bardzo ograniczonych w domenie danych szkoleniowych baskijsko-angielskich o dane poza domeną, o dane syntetyczne oraz o dane dla innych par językowych. Eksperymentowaliśmy również z różnymi architekturami modeli i funkcjami, w tym opracowywaniem rozszerzeń do zestawu narzędzi Nematus. Nasze zgłoszenie zostało ostatecznie wyprodukowane przez kombinację systemów, w której zmieniliśmy ranking tłumaczeń z naszego najsilniejszego indywidualnego systemu przy użyciu wielu słabszych systemów.', 'ro': 'Această lucrare descrie depunerea comună la sarcina IWSLT 2018 Low Resource MT de către Institutul de Cercetare și Dezvoltare Samsung, Polonia și Universitatea din Edinburgh. Ne-am concentrat pe completarea datelor foarte limitate de formare bască-engleză în domeniu cu date din afara domeniului, cu date sintetice și cu date pentru alte perechi de limbi. De asemenea, am experimentat cu o varietate de arhitecturi și caracteristici de modele, care au inclus dezvoltarea de extensii pentru setul de instrumente Nematus. Transmiterea noastră a fost realizată în cele din urmă printr-o combinație de sistem în care am relocat traducerile din cel mai puternic sistem individual folosind mai multe sisteme mai slabe.', 'sr': 'Ovaj papir opisuje zajedničku predanost zadatku IWSLT 2018-e "Low Resource MT" institucije Samsung R&D, Poljske i Univerziteta Edinburga. Fokusirali smo se na dodavanje vrlo ograničenih podataka o obuci u domenu bazskog-engleskog podataka sa podacima izvan domena, sa sintetičkim podacima i podacima za druge jezičke pare. Također smo eksperimentirali razne modele arhitekture i karakteristike, koje su uključivali razvoj proširenja u Nematus toolkit. Naša podnošenja je na kraju proizvela kombinacija sistema u kojoj smo preobrazili prevode iz našeg najjaèeg individualnog sistema koristeći više slabijih sustava.', 'si': 'මේ පැත්තේ සම්බන්ග් R&D සංස්ථානය, පෝලෑන්ඩ් සහ එන්බින්ග් විශ්වාසිතාවේ IWSLT 2018 වලට සම්බන්ධ විද්\u200dයාප්\u200dතිකාර අපි ප්\u200dරධානය කරන්නේ බාස්ක්-ඉංග්\u200dරීසි ප්\u200dරධාන දත්ත අයින් ඩෝමේන් දත්ත, සංවේදික දත්ත සමග, අනිත් භාෂා ජෝඩාවට ද අපි පරීක්ෂණය කරලා තියෙන්නේ විවිධ විශාල ස්ථාපනය සහ විශේෂතාවක් සමඟ, ඒකෙන් නැමාතුස් උපකරණ කිට් අපේ පිළිගන්න අන්තිම විදියට පද්ධතිය සම්බන්ධයක් නිර්මාණය කරලා තියෙන්නේ. අපි අපේ ශක්තිමත් පද්ධතියෙන් අ', 'so': 'Kanu warqaddan waxaa ka muuqata joint submission to the IWSLT 2018 Low Resource MT task by Samsung R&D Institute, Poland, and University Edinburgh. Waxaynu ku kalsoonaynay ku daritaanka macluumaadka waxbarashada ee gudaha ee Basque-Ingiriis oo aan aheyn, iyo macluumaad la xiriira labada luuqadood oo kale. Sidoo kale waxaynu ku jirrabnay dhismaha dhismaha modelalka oo kala duduwan, kaas oo ku jira horumarinta koritaanka qalabka barnaamijka ee Nematus. Ugu dambaysta la soo dhiibay waxaa la soo saaray isku xiriir nidaam, kaas oo aynu tarjumno nidaamka ugu xoogga badan ee noogu isticmaalay nidaamka cudurka badan.', 'sv': 'Denna uppsats beskriver den gemensamma inlämningen till IWSLT 2018 Low Resource MT-uppgiften från Samsung R&D Institute, Polen och University of Edinburgh. Vi fokuserade på att komplettera den mycket begränsade baskisk-engelska utbildningsdata inom domänen med data utanför domänen, med syntetiska data och med data för andra språkpar. Vi experimenterade också med en mängd olika modellarkitekturer och funktioner, vilket inkluderade utveckling av tillägg till Nematus verktygslåda. Vårt bidrag producerades slutligen genom en systemkombination där vi rankade översättningar från vårt starkaste individuella system med flera svagare system.', 'ta': 'இந்த காகிதத்தை IWSLT 2018 குறைந்த மூலத்திற்கு இணைய அனுப்ப விவரிக்கிறது சாம்சாங் R&D அமைப்பு, போலாண்டு, எடின்பர்க் கல்லூரியில் உள்ள ச நாங்கள் மிகவும் வரம்பு உள்ள டோமைன் பாஸ்க்- ஆங்கிலம் பயிற்சி தரவை சேர்க்கும் மேலும் கவனம் செலுத்தினோம் வெளியே உள்ள தகவல், கூட் நாம் பல்வேறு மாதிரி உருவாக்கங்களையும் குணங்களையும் சோதித்தோம், அது நெமுட் கருவிப்பொறிக்கு விரிவாக்கத்தையும் சே எங்கள் ஒப்புக்கொடுப்பு இறுதியாக ஒரு அமைப்பு இணைப்பால் உருவாக்கப்பட்டது அதில் நாம் பல பலவிதமான பலவிதமான முறைமைகளை பயன்படுத்', 'ur': 'This paper describes the joint submission to the IWSLT 2018 Low Resource MT task by Samsung R&D Institute, Poland and the University of Edinburgh. ہم نے ڈومین میں بہت محدودیت کی مطالعہ ڈاٹی کے ساتھ بیرون ڈومین ڈاٹی کے ساتھ، سینٹیٹیک ڈاٹی کے ساتھ، اور دوسری زبان جوڑوں کے ساتھ ڈاٹی کے ساتھ مطالعہ کیا۔ ہم نے بھی مختلف موڈل معماری اور فرصت کے ساتھ آزمائش کی، جس میں نیمٹوس کے تولیک کیٹ کے لئے اضافہ کی گھیری شامل ہوئی تھی. ہماری اطاعت بالآخر ایک سیستم کی ترکیب سے پیدا کی گئی ہے جس میں ہم نے بہت کمزور سیستموں کے مطابق اپنی قوت ترکیب سے دوبارہ ترکیب کیا ہے.', 'no': 'Denne papiret beskriver den samanlige oppføringa til IWSLT 2018 Low Resource MT-oppgåva av Samsung R&D Institute, Poland og Edinburgh University. Vi fokuserte på å leggja til dei veldig begrensede undersøkingsdata i domenet Basque-English med ekstra-domenedata, med syntetiske data, og med data for andre språkopar. Vi eksperimenterte også med mange modeller arkitektur og funksjonar, som inkluderte utviklinga av utvidingar til Nematus-verktøykassa. Søknaden vårt er til slutt produsert av eit systemkombinasjon der vi gjenopprette omsetjingar frå våre sterke individuelle systemet med fleire svakere systemer.', 'uz': "Bu qogʻoz Samsung R&D Institute, Poland va Edinburg Universitetdagi IWSLT 2018 yaqin manba MT vazifasini aytadi. Biz domen- Ingliz tilida juda chegara taʼminlovchi maʼlumotni qo'shish uchun foydalanamiz. Dasturdan foydalanuvchi maʼlumotlarni qo'shish va boshqa tillar qo'llangan maʼlumot bilan birga qarang. Biz bir necha model arxituvlari va xususiyatlar bilan bir necha tizimni sinab ko'rsatdik. Nematus asboblar asboblarning kengaytmalarini taʼminlashtirish mumkin. Bizning imzolarimiz oxirida bir tizim birinchi bir qanchalik qo'shimcha tizimdan tarjimalarni qayta tarjima qildik.", 'vi': 'Tờ giấy này mô tả sự đệ trình chung đến Nhiệm vụ IWSLT Buổi tài nguyên thấp MTV của viện Nghiên cứu, Ba Lan, và Đại học Edinburgh. Chúng tôi tập trung vào việc bổ sung dữ liệu giáo dục người Anh Basque vô chủ đề bằng dữ liệu ngoài miền, bằng dữ liệu tổng hợp, và với dữ liệu dành cho các cặp ngôn ngữ khác. Chúng tôi cũng đã thử nghiệm với nhiều kiến trúc mẫu khác nhau, bao gồm việc phát triển các phần mở rộng cho bộ cấu trúc Nemo. Sự cung cấp của chúng tôi được sản xuất bởi một hệ thống kết hợp mà chúng tôi lần lại dịch từ hệ thống cá nhân mạnh nhất sử dụng nhiều hệ thống yếu hơn.', 'bg': 'Настоящата статия описва съвместното представяне на задачата МТ с ниски ресурси от Института за научноизследователска и развойна дейност в Полша и Университета в Единбург. Фокусирахме се върху допълването на много ограничените в областта баско-английски данни за обучение с данни извън областта, със синтетични данни и с данни за други езикови двойки. Експериментирахме и с различни архитектури и функции на модела, които включваха разработването на разширения към инструментариума на Нематус. Нашето представяне в крайна сметка беше произведено от системна комбинация, в която пренаредихме преводите от нашата най-силна индивидуална система, използвайки множество по-слаби системи.', 'nl': 'Dit artikel beschrijft de gezamenlijke inzending aan de IWSLT 2018 Low Resource MT taak door Samsung R&D Institute, Polen, en de Universiteit van Edinburgh. We concentreerden ons op het aanvullen van de zeer beperkte in-domain Baskisch-Engelse trainingsdata met out-of-domain data, met synthetische data en met data voor andere taalparen. We experimenteerden ook met een verscheidenheid aan modelarchitecturen en functies, waaronder de ontwikkeling van uitbreidingen voor de Nematus toolkit. Onze inzending werd uiteindelijk geproduceerd door een systeemcombinatie waarin we vertalingen vanuit ons sterkste individuele systeem opnieuw rangschikten met meerdere zwakkere systemen.', 'de': 'Dieses Papier beschreibt die gemeinsame Einreichung der IWSLT 2018 Low Resource MT Aufgabe durch Samsung R&D Institute, Polen, und die Universität Edinburgh. Wir konzentrierten uns darauf, die sehr begrenzten in-domain baskisch-englischen Trainingsdaten mit out-of-domain Daten, mit synthetischen Daten und mit Daten für andere Sprachpaare zu ergänzen. Wir experimentierten auch mit einer Vielzahl von Modellarchitekturen und Features, einschließlich der Entwicklung von Erweiterungen des Nematus Toolkits. Unsere Einreichung wurde letztendlich durch eine Systemkombination erzeugt, in der wir Übersetzungen aus unserem stärksten Einzelsystem mit mehreren schwächeren Systemen neu rangierten.', 'hr': 'Ovaj papir opisuje zajedničku prijedlogu zadatku IWSLT 2018-a MT za manje resurse od strane Instituta Samsung R&D, Poljskog i Univerziteta Edinburga. Fokusirali smo se na dodavanje vrlo ograničenih podataka o obuci na bazskom-engleskom domenu s podacima izvan domena, sintetičkim podacima i podacima za druge jezičke pare. Također smo eksperimentirali razne modele arhitekture i karakteristike, koji su uključivali razvoj proširenja u Nematus toolkit. Naša podnošenja je na kraju proizvela kombinacija sustava u kojoj smo preobrazili prevode iz našeg najjačeg pojedinačnog sustava koristeći višestruke slabije sustave.', 'id': 'Kertas ini menjelaskan pengiriman bersama ke IWSLT 2018 Low Resource MT tugas oleh Samsung R&D Institute, Polandia, dan Universitas Edinburgh. Kami fokus pada menambahkan data latihan yang sangat terbatas dalam domain Bahasa Baska-Inggris dengan data luar domain, dengan data sintetis, dan dengan data untuk pasangan bahasa lain. Kami juga eksperimen dengan berbagai jenis arsitektur dan fitur model, yang termasuk pengembangan ekstensi ke toolkit Nematus. Pengiriman kami akhirnya diproduksi oleh kombinasi sistem di mana kami mengatur terjemahan dari sistem individu terkuat kami menggunakan sistem yang lebih lemah.', 'sw': 'Makala hii inaelezea ujumbe wa pamoja wa IWSLT 2018 kazi ya rasilimali chini ya MT na Samsung R&D Taasisi, Poland na Chuo Kikuu cha Edinburgh. Tulijikita kuongeza taarifa za mafunzo ya Kiingereza yenye taarifa isiyo na maeneo ya ndani, pamoja na taarifa za pamoja, na data kwa ajili ya wanaume wengine wa lugha nyingine. Tulijaribu pia na majengo mbalimbali ya mifano na vipengele, ambavyo vilijumuisha maendeleo ya vifaa vya Nematus. Ujumbe wetu hatimaye ulitengenezwa na muungano wa mfumo ambao tulitafsiri tena kutoka mfumo wetu wenye nguvu zaidi kwa kutumia mifumo mingi dhaifu.', 'da': 'Denne artikel beskriver den fælles indsendelse til IWSLT 2018 Low Resource MT opgave fra Samsung R&D Institute, Polen, og University of Edinburgh. Vi fokuserede på at supplere de meget begrænsede baskisk-engelske træningsdata med data uden for domænet, med syntetiske data og med data for andre sprogpar. Vi eksperimenterede også med en række modelarkitekturer og funktioner, som omfattede udviklingen af udvidelser til Nematus værktøjssæt. Vores indlæg blev i sidste ende produceret af en systemkombination, hvor vi genvurderede oversættelser fra vores stærkeste individuelle system ved hjælp af flere svagere systemer.', 'af': "Hierdie papier beskrywe die joint submisiëring aan die IWSLT 2018 Lae hulpbron MT-taak deur Samsung R&D Institute, Polen en die Universiteit van Edimburg. Ons fokuseer op die baie beperkte in-domein Basque-Engelske onderwerp data met uit-domein data, met sintetiese data en met data vir ander taal paars. Ons het ook eksperimenteer met 'n verskeie modele arkitektuur en funksies, wat die ontwikkeling van uitbreidings na die Nematus nutsbalkit ingesluit het. Ons ondersteuning was eindelik geproduseer deur 'n stelsel kombinasie waarin ons vertalings herankeer het van ons sterkte individuele stelsel gebruik veelvuldige swakkere stelsels.", 'ko': '본고는 폴란드 삼성연구개발원과 에든버러대학이 공동으로 IWSLT 2018 저자원 MT 임무를 제출한 상황을 묘사한다.우리는 역외 데이터, 합성 데이터, 기타 언어에 대한 데이터로 매우 제한된 역내 바스크 영어 교육 데이터를 보충하는 데 전념한다.Nematus 키트 개발을 비롯한 다양한 모델 아키텍처와 기능을 시험해 보았습니다.우리의 제출은 최종적으로 하나의 시스템 조합으로 이루어진 것이다. 이 시스템 조합에서 우리는 여러 개의 약한 시스템을 사용하여 우리의 가장 강한 단일 시스템의 번역을 다시 배열했다.', 'am': 'ይህ ገጽ በሠምሳങ_R&ዲ ኢንተስቲቲቲ፣ ፖሎንድ እና ኤዲንቡር ዩንቨርስቲ በIWSLT 2018 ታናሽ የክፍለ ዕድል MT አድራጊውን ይናገራል፡፡ በዶሜን-ቢስክ-እንግሊዘኛ ትምህርት ዳታዎችን ከውጭ ከዶሜን ዳታ ጋር እና ለሌሎች ቋንቋዎች ዓይነቶች ዳታዎችን በመጨመር ላይ አቆጣጠርን፡፡ We also experimented with a variety of model architectures and features, which included the development of extensions to the Nematus toolkit.  የፍልስታችን ፍጻሜ በተጨማሪው ብዛት ደካማ ስርዓቶች በተጠቃሚ ከኃይለኞች ብሔራዊ ድጋፍ ተርጓሚዎችን አቀረብን፡፡', 'fa': 'این کاغذ تعیین مشترک ارائه به کار MT کم منابع IWSLT ۲۰۱۸ توسط موسسه سامبینگ R&D، لهستان و دانشگاه ادینبرگ را توصیف می\u200cکند. ما روی اضافه کردن اطلاعات آموزش بسکی-انگلیسی بسکی با داده های خارج از دومین، با داده های سناتیک و اطلاعات برای جفت زبان دیگر تمرکز کردیم. ما همچنین با مختلف معماری و ویژه های مدل آزمایش کردیم که شامل توسعه توسعه وسیله های نیماتوس بود. تسلیم ما بالاخره توسط یک ترکیب سیستم تولید شده است که ما ترکیب های قوی\u200cترین سیستم\u200cمان را با استفاده از سیستم\u200cهای ضعیف\u200cتر از آن بازگرداندیم.', 'tr': "Bu kagyz IWSLT 2018 IWSLT'a Aýik Ressurat MT zadyny Samsung R&D Instituty, Polşa we Edimburgyň Uniwersiteti tarapyndan ylalaýar. Biz Bask-iňlis dilinde baýram hasaplanýan maglumatlary domena daşaryk maglumatlary bilen, syntetik maglumatlary bilen we başga dil çiftleri üçin maglumatlary eklemekde üns berdik. Biz hem bir näçe nusga arhitektura we özellikler bilen synanyşdyrdyk we bu nusga Nematus araçlarynyň ýetişdirişi bilen döredildi. Iň soňunda a ýdyşymyz sistemasy bilen döredildi we bu sistemasy biziň iň güýçli sistemamyzdan täzeden terjimelerimizi çalyşyrdyk.", 'az': "Bu kańüńĪt, Samsung R&D Institute, Polonya v…ô Edinburg √úniversitesi t…ôr…ôfind…ôn IWSLT 2018'nin d√ľŇü√ľk ressurs MT iŇüini t…ôsdiql…ôyir. Biz domeind…ô √ßox sńĪnńĪrlńĪ basq-ńįngilizce t…ôhsil m…ôlumatlarńĪnńĪ dńĪŇü domenin m…ôlumatlarńĪ il…ô, sintetik m…ôlumatlarńĪ il…ô v…ô baŇüqa dil √ßiftl…ôrinin m…ôlumatlarńĪ il…ô birlikd…ô t…ôhsil etdik. Biz d…ô m√ľxt…ôlif modell…ôr v…ô √∂zellikl…ôri il…ô t…ôcr√ľb…ô etdik ki, Nematus ara√ß kitabńĪna uzaqlaŇüdńĪrńĪlmasńĪnńĪ dahil etdik. Bizim t…ôsdiqliyimiz sonunda sistem kombinatsiyasńĪ il…ô yaradńĪlmńĪŇüdńĪr ki, bu sistemd…ô √ßoxlu z…ôif sisteml…ôrl…ô …ôn q√ľvv…ôtli sistemimizd…ôn d…ôyiŇüdirilmiŇüik.", 'sq': 'Ky dokument përshkruan paraqitjen e përbashkët për detyrën e IWSLT 2018 me burime të ulta MT nga Samsung R&D Institute, Polonia dhe Universiteti i Edinburgut. Ne u përqëndruam në shtimin e të dhënave shumë të kufizuara të trajnimit në domeni Bask-Anglisht me të dhëna jashtë domenit, me të dhëna sintetike dhe me të dhëna për çifte gjuhësh të tjera. Ne gjithashtu eksperimentuam me një shumëllojshmëri modelesh arkitekturash dhe karakteristikësh, të cilat përfshijnë zhvillimin e zgjerimeve në paketën e mjeteve të Nematus. Përdorimi ynë përfundimisht u prodhua nga një kombinim i sistemit në të cilin ne rishkruam përkthimet nga sistemi ynë më i fortë individual duke përdorur sisteme të shumta më të dobëta.', 'ca': "Aquest paper descriu la presentació conjunta a la tasca de MT de baix recursos del IWSLT 2018 de Samsung Institute de I&D, Polònia i la Universitat d'Edimburgo. Ens vam centrar en complementar les dades d'entrenament basco-anglès en domini molt limitades amb dades fora de domini, amb dades sintètiques i amb dades per altres parelles de llenguatges. També vam experimentar amb una varietat d'arquitectures i característiques models, que van incloure el desenvolupament d'estensions al conjunt d'eines Nematus. La nostra subministració va ser produïda per una combinació de sistema en la que vam reenvolupar les traduccions del nostre sistema individual més fort fent servir múltiples sistemes més dèbils.", 'hy': 'Այս հոդվածը նկարագրում է 2018 թվականի IW-ՍԼT-ի "Նվագ ռեսուրսների" MT-ի հանձնարարությունը Սամսոնգ Հետազոտության և Հետազոտության ինստիտուտի, Փոլանդիայի և Էդինբուրգի կողմից: Մենք կենտրոնացրեցինք բասկի-անգլերեն ուսումնասիրության շատ սահմանափակ տվյալների լրացումն արտաքին տվյալներով, սինթետիկ տվյալներով և այլ լեզվի զույգերի տվյալներով: Մենք նաև փորձեցինք տարբեր մոդելների ճարտարապետությունների և հատկությունների հետ, որոնք ներառում էին Նեմատոսի գործիքների շարժումների զարգացումը: Մեր ներկայացումը ի վերջո արտադրվել է համակարգի համադրության միջոցով, որտեղ մենք վերականգնել ենք թարգմանությունները մեր ամենամեծ անհատական համակարգից օգտագործելով բազմաթիվ ավելի թույլ համակարգեր:', 'cs': 'Tento článek popisuje společné předložení úkolu IWSLT 2018 Low Resource MT společností Samsung R&D Institute v Polsku a Univerzity v Edinburghu. Zaměřili jsme se na doplnění velmi omezených in-doménových baskicko-anglických tréninkových dat mimo doménu, syntetických dat a dat pro další jazykové páry. Experimentovali jsme také s různými modelovými architekturami a funkcemi, které zahrnovaly vývoj rozšíření sady nástrojů Nematus. Náš příspěvek byl nakonec vytvořen systémovou kombinací, ve které jsme přeřadili překlady z našeho nejsilnějšího individuálního systému pomocí několika slabších systémů.', 'et': 'Käesolevas artiklis kirjeldatakse Poola Samsungi teadus- ja arendustegevuse instituudi ja Edinburghi Ülikooli ühist esitamist IWSLT 2018 madala ressursi MT ülesandele. Keskendusime väga piiratud baski-inglise keele koolitusandmete täiendamisele domeenivälisete andmetega, sünteetiliste andmetega ja teiste keelepaaride andmetega. Katsetasime ka mitmesuguseid mudeliarhitektuure ja funktsioone, mis hõlmasid Nematuse tööriistakomplekti laienduste väljatöötamist. Meie esitus toodeti lõppkokkuvõttes süsteemikombinatsioonis, kus me panustasime tõlkeid oma tugevamast individuaalsest süsteemist, kasutades mitut nõrgemat süsteemi.', 'bn': 'এই পত্রিকাটি ইউডএসএলটি ২০১৮ সালের নিম্ন রিসোর্স এমটি কাজের ব্যাখ্যা করেছে স্যামসংগ আর এন্ড ড ইনস্টিটিউটি, পোল্যান্ড এবং এডিনবা আমরা ডোমেইন-বাস্ক-ইংরেজি প্রশিক্ষণের তথ্য যোগাযোগ করার প্রতি মনোযোগ আকর্ষণ করেছিলাম, যা ডোমেইনের বাইরে নেই, সিন্টেটিক ডাটা এবং অন আমরা বিভিন্ন ধরনের মডেল কাঠামো এবং বৈশিষ্ট্য দিয়ে পরীক্ষা করেছি, যার মধ্যে নেমুটাস টুলবিটের বিস্তারিত বিস্তারিত উন্নয়ন আমাদের আত্মসমর্পণ শেষ পর্যন্ত একটি সিস্টেম সম্মিলনের দ্বারা তৈরি হয়েছিল যেখানে আমরা বেশ কয়েকটি দুর্বল ব্যবস্থা ব্যবহার করে আম', 'bs': 'Ovaj papir opisuje zajedničku predanost zadatku IWSLT-a 2018. za manje resurse MT od strane Instituta Samsung R&D, Poljskog i Univerziteta Edinburga. Fokusirali smo se na dodavanje vrlo ograničenih podataka o obuci u domenu Baska-Engleskog s podacima izvan domena, sa sintetičkim podacima i podacima za druge jezičke pare. Također smo eksperimentirali razne modele arhitekture i karakteristike, koji su uključivali razvoj proširenja do Nematus alata. Naša podnošenja je na kraju proizvela kombinacija sustava u kojoj smo preobrazili prevode iz našeg najjačeg pojedinačnog sistema koristeći više slabijih sustava.', 'fi': 'Tässä artikkelissa kuvataan Puolan Samsungin T&D Instituutin ja Edinburghin yliopiston yhteinen hakemus IWSLT 2018 Low Resource MT -tehtävään. Keskityimme täydentämään hyvin rajallista baski-englantia koskevaa koulutustietoa verkkotunnuksen ulkopuolisilla tiedoilla, synteettisillä tiedoilla ja muilla kielipareilla. Kokeilimme myös erilaisia malliarkkitehtuureja ja ominaisuuksia, joihin kuului Nematuksen työkalupakin laajennusten kehittäminen. Toimituksemme tuotti lopulta järjestelmäyhdistelmän, jossa järjestelimme käännökset vahvimmasta yksittäisestä järjestelmästä uudelleen käyttäen useita heikompia järjestelmiä.', 'he': 'העיתון הזה מתאר את ההעברה המשותפת למשימת MT משאבים נמוכים IWSLT 2018 על ידי ממכון R&D Samsung, פולין, ואוניברסיטת אדינבורג. התמקדנו בתוספת נתונים מאד מוגבלים באנגלית-בסקית בתחום עם נתונים מחוץ לתחום, עם נתונים סינטטיים, ובנתונים לזוגות שפות אחרות. We also experimented with a variety of model architectures and features, which included the development of extensions to the Nematus toolkit.  Our submission was ultimately produced by a system combination in which we reranked translations from our strongest individual system using multiple weaker systems.', 'sk': 'Ta prispevek opisuje skupno predložitev projekta IWSLT 2018 Low Resource MT s strani Samsung R&R Institute na Poljskem in Univerze v Edinburgu. Osredotočili smo se na dopolnitev zelo omejenih podatkov o usposabljanju baskovsko-angleščine z zunajdomenskimi podatki, sintetičnimi podatki in podatki za druge jezikovne pare. Eksperimentirali smo tudi z različnimi modelnimi arhitekturami in funkcijami, ki so vključevale razvoj razširitev orodja Nematus. Naša predložitev je končno nastala s sistemsko kombinacijo, v kateri smo prerazporedili prevode iz našega najmočnejšega posameznega sistema z uporabo več šibkejših sistemov.', 'ha': "Wannan avir describes the Join Submit to the IWSLT 2018 Low Resource MT job by Samsung R`D Installat, Poland, and the University of edinburg. Mun fokus zuwa a ƙara da data masu ƙaranci cikin-Domen Basque-Ingiriya da data masu fitarwa daga-Domen, da data na haɗatiki, da kuma da data ga wasu mutane na harshen. Haƙĩƙa, Mun jarraba wasu masu tsarin misãlai da wasu abũbuwan husũka, wanda ke ƙunsa da kiyayen faɗa ɗaɗu zuwa zanen kwamfyutan Nematus. Musuluncinmu na ƙarama ya zaɓe shi da wata koma na'urar system, inda muka raba fassarar masu ƙaranci daga matsayinmu masu ƙarfin mutum guda, da misãlai masu ƙaranci.", 'jv': 'Perintah iki dadi nggawé nggawé nggawé nggawé urip nggawe IWSLT 2013 IWSLT Open Source MT nggawé bakal nggawé nggawe Universite Saturdayg R&D Institute, Puolen, lan Universite di Edgar. We centered on additional the really limiting in-domain Basque Awak dhéwé éntuk éntuk karo akeh akeh akeh akeh-akeh sing sampeyan ngono nganggo cara-akeh sing paling nggawe lan tambah kebutuhan pengguna anyar iki dhéwé ning alat sing berarti ora oleh tur angel. Awak dhéwé nggunaké sak barêng-barêng nggawe sistem sing nyelarane ning awak dhéwé mulai terjamahan ning sistem sing sabên nggawe sistem sing gawe nguasai sistem sing bisa dianggawe.', 'bo': 'ཤོག་བྱང་འདིས་IWSLT 2018་ཡི་གྲངས་ཀྱི་རྒྱུ་དངོས་པོ་(Low Resource MT)ལ་མཉམ་དུ་འགྲེལ་བཤད་བྱེད་ཀྱི་ཡོད། We focused on supplementing the very limited in-domain Basque-English training data with out-of-domain data, with synthetic data, and with data for other language pairs. ང་ཚོས་ཀྱང་མིའི་རྩལ་གཞུང་སྒྲིག་འགོད་དང་ཁྱད་ཆོས་ཀྱི་རྩ་སྒྲིག་འགོད་མ་འདུག་གི་ནང་དུ་ཡར་རྒྱས་སྤྲོད་ཀྱི་ལག་ཆ ང་ཚོའི་མཐའ་མཇུག་དུ་མ་ལག་གི་སྒྲིག་བསྡུར་ཞིག་གིས་གསར་བསྐྲུན་བྱས་ཡོད། དེ་ནས་ང་ཚོའི་མ་ལག་གི་སྟོབས་ཤུགས་ཤིག་ས'}
{'en': 'The AFRL IWSLT 2018 Systems : What Worked, What Did n’t AFRL   IWSLT  2018 Systems: What Worked, What Didn’t', 'ar': 'أنظمة AFRL IWSLT 2018: ما الذي نجح وما لم ينجح', 'pt': 'Os sistemas AFRL IWSLT 2018: o que funcionou, o que não funcionou', 'es': 'Los sistemas AFRL IWSLT 2018: qué funcionó, qué no', 'fr': "Les systèmes AFRL IWSLT 2018\xa0: ce qui a fonctionné et ce qui n'a pas fonctionné", 'ja': 'AFRL IWSLT 2018システム：何が機能し、何が機能しなかったか', 'zh': 'AFRL IWSLT 2018系统:有效无效', 'hi': 'AFRL IWSLT 2018 सिस्टम: क्या काम किया, क्या नहीं किया', 'ru': 'Системы AFRL IWSLT 2018: что сработало, а что нет', 'ga': 'Córais AFRL IWSLT 2018: Cad a d’oibrigh, cad é nár oibrigh', 'ka': 'AFRL IWSLT 2018 სისტემები: რა მუშაობდა, რაც არ მოხდა', 'hu': 'Az AFRL IWSLT 2018 rendszerek: Mi működött, mi nem', 'el': 'Τα συστήματα του Τι λειτούργησε, Τι δεν λειτούργησε', 'lt': 'AFRL IWSLT 2018 sistemos: kas veikė, kas nepavyko', 'it': 'I sistemi AFRL IWSLT 2018: cosa ha funzionato, cosa non ha funzionato', 'mk': 'АФРЛ IWSLT 2018 системи: Што функционираше, што не функционираше', 'kk': 'AFRL IWSLT 2018 жүйелері: Жұмыс істеген, Жұмыс істеген', 'ml': 'എഫ്രില്\u200d ഐവ്സ്ലെറ്റ് 2018 സിസ്റ്റമുകള്\u200d: എന്ത് ജോലി ചെയ്തു, എന്ത് ചെയ്തില്ല', 'ms': 'Sistem AFRL IWSLT 2018: Apa yang Berhasil, Apa yang Tidak Berhasil', 'mt': "The AFRL IWSLT 2018 Systems: What Worked, What Didn't", 'mn': 'AFRL IWSLT 2018 Systems: Юу ажиллаж, юу хийхгүй байсан бэ?', 'no': 'AFRL IWSLT 2018 Systema: Kva arbeidte, Kva ikkje', 'pl': 'System AFRL IWSLT 2018: Co działało, co nie', 'ro': 'Sistemele AFRL IWSLT 2018: Ce a funcționat, ce nu a funcționat', 'si': 'AFRL IWSLT 2018 පද්ධතිය', 'sr': 'Sistemi AFRL IWSLT 2018: ono što je radio, ono što nije bilo', 'so': 'AFRL IWSLT 2018 Systems: What Worked, What aanan', 'sv': 'AFRL IWSLT 2018 System: Vad fungerade, vad gjorde inte', 'ta': 'AFRL IWSLT 2018 அமைப்புகள்: என்ன வேலை செய்தது, என்ன செய்யவில்லை', 'ur': "The AFRL IWSLT 2018 Systems: What Worked, What Didn't", 'uz': '2018 tizimlar', 'vi': "The AFRL IWSLT TE8: What Cháy, What didn't", 'bg': 'Системите на АФРЛ 2018: какво работи, какво не', 'hr': 'Sistemi AFRL IWSLT 2018: Što je radio, što nije', 'nl': 'De AFRL IWSLT 2018 Systemen: Wat werkte, wat niet', 'da': 'AFRL IWSLT 2018 systemer: Hvad virkede, hvad ikke virkede', 'id': "The AFRL IWSLT 2018 Systems: What Worked, What Didn't", 'de': 'Die AFRL IWSLT 2018 Systeme: Was hat funktioniert, was nicht', 'ko': 'AFRL IWSLT 2018 시스템: 유효하고 유효하지 않은 것', 'fa': 'سیستم\u200cهای AFRL IWSLT ۲۰۱۸: کاری کرد، کاری نکرد', 'sw': 'Mfumo wa AFRL IWSLT 2018: Kitu kilichofanya kazi, Kilichochofanywa', 'sq': "AFRL IWSLT 2018 Systems: What Worked, What Didn't", 'af': 'Die AFRL IWSLT 2018 Systeme: Wat werk, Wat het nie', 'am': 'የAFRL IWSLT 2018 Systems: ምን ነበር, ምን አልሠራም', 'tr': "AFRL IWSLT 2018 Systems: What Worked, What Didn't", 'hy': 'ԱֆՌԼ IW-ՍԼT 2018 համակարգերը՝ Աշխատեց, Աշխատեց,', 'bn': '২০১৮ সিস্টেম: কি কাজ করেছে, কি করেনি কি না।', 'ca': 'AFRL IWSLT 2018 Systems: El que va funcionar, el que no va funcionar', 'az': 'AFRL IWSLT 2018 Sistemləri: Çalışan, Çalışmayan', 'bs': 'Sistemi AFRL IWSLT 2018: ono što je radio, ono što nije bilo', 'cs': 'Systémy AFRL IWSLT 2018: Co fungovalo, co ne', 'et': 'AFRL IWSLT 2018 sĂĽsteemid: mis tĂ¶Ă¶tas, mis ei tĂ¶Ă¶tanud', 'fi': 'AFRL IWSLT 2018 -järjestelmät: mikä toimi, mikä ei', 'jv': 'IWSLT AfRL IWSLT 2008 Sistem: sing uwis nggawe, sing ora nggawe', 'ha': 'AFRL IWSLT 2018 Systems: What Acted, What bai', 'he': 'מערכות AFRL IWSLT 2018: מה שעבד, מה לא', 'sk': 'Sistemi AFRL IWSLT 2018: kaj je delovalo, kaj ni', 'bo': "AFRL IWSLT 2018 Systems: What Worked, What Didn't"}
{'en': 'This report summarizes the Air Force Research Laboratory (AFRL) machine translation (MT) and automatic speech recognition (ASR) systems submitted to the spoken language translation (SLT) and low-resource MT tasks as part of the IWSLT18 evaluation campaign.', 'ar': 'يلخص هذا التقرير الترجمة الآلية (MT) لمختبر أبحاث القوات الجوية (AFRL) وأنظمة التعرف التلقائي على الكلام (ASR) المقدمة إلى ترجمة اللغة المنطوقة (SLT) ومهام الترجمة الآلية منخفضة الموارد كجزء من حملة تقييم IWSLT18.', 'es': 'Este informe resume los sistemas de traducción automática (MT) y reconocimiento automático de voz (ASR) del Laboratorio de Investigación de la Fuerza Aérea (AFRL) enviados a las tareas de traducción del idioma hablado (SLT) y MT de bajos recursos como parte de la campaña de evaluación IWSLT18.', 'pt': 'Este relatório resume os sistemas de tradução automática (MT) e reconhecimento automático de fala (ASR) do Laboratório de Pesquisa da Força Aérea (AFRL) submetidos às tarefas de tradução de linguagem falada (SLT) e MT de poucos recursos como parte da campanha de avaliação do IWSLT18.', 'fr': "Ce rapport résume les systèmes de traduction automatique (MT) et de reconnaissance vocale automatique (ASR) du Laboratoire de recherche de l'armée de l'air (AFRL) soumis aux tâches de traduction en langue parlée (SLT) et de MT à faibles ressources dans le cadre de la campagne d'évaluation IWSLT18.", 'ja': '本報告書は、IWSLT 18評価キャンペーンの一環として、空軍研究室（ AFRL ）の機械翻訳（ MT ）および自動音声認識（ ASR ）システムを、口語翻訳（ SLT ）および低資源MTタスクに提出したものをまとめたものである。', 'zh': '本告总结空军研究实验室 (AFRL) 机器翻译 (MT) 与自语音识 (ASR) 系统,以为 IWSLT18 估动之一,提付口语译 (SLT) 与资源匮乏之 MT 。', 'ru': 'Этот отчет суммирует системы машинного перевода (MT) и автоматического распознавания речи (ASR) Исследовательской лаборатории Военно-воздушных сил (AFRL) представленные к переводам устного языка (SLT) и малоресурсным задачам MT как часть кампании оценки IWSLT18.', 'hi': 'यह रिपोर्ट वायु सेना अनुसंधान प्रयोगशाला (AFRL) मशीन अनुवाद (MT) और स्वचालित भाषण पहचान (ASR) सिस्टम को IWSLT18 मूल्यांकन अभियान के हिस्से के रूप में बोली जाने वाली भाषा अनुवाद (SLT) और कम-संसाधन MT कार्यों के लिए प्रस्तुत किए गए सारांशित करती है।', 'ga': 'Déanann an tuarascáil seo achoimre ar na córais aistriúcháin mheaisín (MT) agus uathaitheantais cainte (ASR) de chuid na Saotharlainne Taighde Aerfhórsa (AFRL) a cuireadh isteach chuig an aistriúchán teanga labhartha (SLT) agus tascanna MT íseal-acmhainne mar chuid d’fheachtas meastóireachta IWSLT18.', 'el': 'Η παρούσα έκθεση συνοψίζει τα συστήματα μηχανικής μετάφρασης (MT) και αυτόματης αναγνώρισης ομιλίας (ASR) που υποβλήθηκαν στις εργασίες μετάφρασης προφορικής γλώσσας (SLT) και χαμηλής περιεκτικότητας σε ΜΤ ως μέρος της εκστρατείας αξιολόγησης IWSLT18.', 'ka': 'ამ შეტყობინებაში გამოყენებულია Air Force Research Laboratory (AFRL) მანქანის გადაწყენება (MT) და ავტომატური სიტყვების აღმოჩენება (ASR) სისტემებში, რომლებიც საუბრალოდ ენის გადაწყენება (SLT) და low-resource MT დავალებები IWSLT18 გადაწყ', 'it': "Questo rapporto riassume i sistemi di traduzione automatica (MT) e di riconoscimento automatico del parlato (ASR) del Laboratorio di Ricerca dell'Aeronautica Militare (AFRL) sottoposti alla traduzione della lingua parlata (SLT) e alle attività MT a basso contenuto di risorse nell'ambito della campagna di valutazione IWSLT18.", 'kk': 'Бұл хабарлама ағылшын күш зерттеу лабораториясы (AFRL) машиналық аудару (MT) және автоматты сөздерді анықтау (ASR) жүйелерін IWSLT18 бағалау кампаниясының бөлігі ретінде жіберілген тіл аудару (SLT) және төмен ресурс MT тапсы', 'hu': 'Ez a jelentés összefoglalja az IWSLT18 értékelési kampány részeként a beszélt nyelvű fordításra (SLT) beküldött gépi fordítási (MT) és az automatikus beszédfelismerő (ASR) rendszereket.', 'ms': 'Laporan ini menyatakan ringkasan sistem penerjemah mesin Laboratory Air Force (AFRL) dan pengenalan pidato automatik (ASR) yang dihantar kepada penerjemah bahasa bercakap (SLT) dan tugas MT sumber rendah sebagai sebahagian daripada kampanye penilaian IWSLT18.', 'mk': 'Овој извештај ги сумира машинските преводи на Лабораторијата за истражување на воздушните сили (АФРЛ) и системите за автоматско препознавање на говорот (АСР) поднесени на преводот на говорниот јазик (СЛТ) и задачите со ниски ресурси на МТ како дел од кампањата за евалуација', 'lt': 'Šiame pranešime apibendrinamos oro pajėgų mokslinių tyrimų laboratorijos (AFRL) mašininio vertimo (MT) ir automatinio kalbos pripažinimo (ASR) sistemos, pateiktos kalbos vertimo (SLT) ir mažo išteklio MT užduotims, kaip IWSLT18 vertinimo kampanijos dalis.', 'mt': 'Dan ir-rapport jagħti sommarju tas-sistemi tat-traduzzjoni bil-magna (MT) u tar-rikonoxximent awtomatiku tad-diskors (ASR) tal-Laboratorju tar-Riċerka tal-Forza tal-Ajru (AFRL) sottomessi għat-traduzzjoni bil-lingwa mitkellma (SLT) u kompiti MT b’riżorsi baxxi bħala parti mill-kampanja ta’ evalwazzjoni tal-IWSLT18.', 'no': 'Denne rapporten samanserer luftforskningslaboratorien (AFRL) for maskinsomsetjing (MT) og automatisk tale-gjenkjenning (ASR) av systemet som er sendt til språk omsetjinga (SLT) og låg-ressurs-MT-oppgåver som del av IWSLT18-evalueringskampanjen.', 'mn': 'Энэ мэдээлэл нь агаарын хүчний судалгааны лабораторийг (AFRL) машины хөрөнгө оруулалт (MT) болон автоматжуулалтын илтгэл таних (ASR) системийг IWSLT18 шалгалтын нэг хэсэг болгон өгсөн хэл хөрөнгө оруулалт (SLT) болон бага-сан MT ажиллагааг ил', 'ml': 'ഈ റിപ്പോര്\u200dട്ട് എയര്\u200d ഫോര്\u200dസ് റിസ്റ്റേര്\u200dച്ച് ലാബ്രറിയിലെ (AFRL) മെഷീന്\u200d പരിഭാഷവും സ്വയം ഭാഷ തിരിച്ചറിയുന്ന സിസ്റ്റമുകളും സംസാരിക്കുന്ന ഭാഷയുടെ പരിഭാഷയിലേക്കും കുറഞ്', 'ro': 'Acest raport sintetizează sistemele de traducere automată (MT) ale Laboratorului de Cercetare a Forțelor Aeriene (AFRL) și de recunoaștere automată a vorbirii (ASR) depuse la traducerea limbii vorbite (SLT) și sarcinile MT cu resurse reduse ca parte a campaniei de evaluare IWSLT18.', 'sr': 'Ovaj izveštaj sažetuje prevod uređaja za istraživanje zračnih snaga (AFRL) i automatski priznanje govora (ASR) koji su predani rečenom prevodu jezika (SLT) i zadacima za manje resurse MT kao deo kampanje za procjenu IWSLT18.', 'pl': 'Niniejszy raport podsumowuje systemy tłumaczenia maszynowego (MT) i automatycznego rozpoznawania mowy (ASR) przesłane do tłumaczenia języka mówionego (SLT) i zadań MT o niskich zasobach w ramach kampanii oceniającej IWSLT18.', 'so': 'Riyadaasu waxay summarisaa qoraalka baaritaanka machine (AFRL) iyo habaarka aqoonsashada hadalka (ASR) ee loo dhiibay turjumista luqada lagu hadlo (SLT) iyo shaqooyinka hoos-resource MT oo kamid ah IWSLT18 qiimeynta campaign.', 'si': 'මේ වාර්තාව සම්පූර්ණය කරනවා Air Force Research Laboratories (AFRL) machine translation (MT) සහ ස්වයංක්\u200dරීය කතාව අඳුරන්න (ASR) පද්ධතිය, කතාවිත භාෂාව භාෂාව (SLT) සහ low-source MT වැඩියෝ', 'sv': 'Denna rapport sammanfattar flygvapnets forskningslaboratorium (AFRL) maskinöversättning (MT) och automatisk taligenkänning (ASR) system som lämnats in för språköversättning (SLT) och arbetsuppgifter med låg resurs MT som en del av utvärderingskampanjen IWSLT18.', 'ta': '@ info', 'ur': 'اس راپورت نے آئر فورس تحقیقات آزمائش آزمائش (AFRL) ماشین ترجمہ (MT) اور آئوٹی بات شناسی (ASR) سیستموں کو زبان ترجمہ (SLT) اور کم-رسورس MT کاموں کو IWSLT18 تحقیقات کمپینٹ کی حصہ کے طور پر پیش کیا ہے.', 'uz': '@ info: status', 'vi': 'Bản báo cáo này tổng hợp nhóm Phòng nghiên cứu Không quân (AFRL) máy dịch dịch chuyển máy (MTV) và hệ thống nhận dạng ngôn ngữ tự động (ASR) được gửi cho dịch ngôn ngữ đã nói (SLT) và các công việc MTV ít tài nguyên trong chiến dịch đánh giá IWSLT18.', 'nl': 'Dit rapport geeft een samenvatting van de systemen van het Air Force Research Laboratory (AFRL) voor machinevertaling (MT) en automatische spraakherkenning (ASR) die zijn ingediend voor gesproken taalvertaling (SLT) en MT-taken met weinig resources als onderdeel van de IWSLT18 evaluatiecampagne.', 'bg': 'Този доклад обобщава системите за машинен превод (МТ) и автоматично разпознаване на речта (АСР), представени на задачите за превод на говорен език (СЛТ) и МТ с нисък ресурс като част от кампанията за оценка.', 'hr': 'U ovom izvještaju se sažeta laboratorija istraživanja zračnih snaga (AFRL) prevoda strojeva (MT) i sustava priznanja automatskog govora (ASR) podanih govornom prevodu jezika (SLT) i zadaćima MT s niskim resursima kao dio kampanje za procjenu IWSLT18.', 'da': 'Denne rapport opsummerer luftvåbens forskningslaboratorium (AFRL) maskinoversættelse (MT) og automatisk talegenkendelse (ASR) systemer, der er indsendt til oversættelse af talesprog (SLT) og MT-opgaver med lav ressource som en del af IWSLT18 evalueringskampagnen.', 'de': 'Dieser Bericht fasst die Systeme des Air Force Research Laboratory (AFRL) für maschinelle Übersetzung (MT) und automatische Spracherkennung (ASR) zusammen, die im Rahmen der IWSLT18-Evaluierungskampagne für die Sprachübersetzung (SLT) und ressourcenarme MT-Aufgaben eingereicht wurden.', 'id': 'Laporan ini mempersingkatkan sistem mesin terjemahan Laboratori Penelitian Angkatan Udara (AFRL) dan pengakuan pidato otomatis (ASR) yang dihantar ke terjemahan bahasa berbicara (SLT) dan tugas MT sumber daya rendah sebagai bagian dari kampanye evaluasi IWSLT18.', 'ko': '이 보고서는 공군연구실(AFRL) 기계번역(MT)과 자동음성인식(ASR) 시스템이 IWSLT18 평가 활동의 일부로 구어번역(SLT)과 저자원기계번역 임무에 제출한 것을 총괄했다.', 'fa': 'این گزارش آزمایشگاه تحقیقات نیروی هوا (AFRL) ترجمه ماشین (MT) و سیستم شناسایی سخنرانی خودکار (ASR) را به ترجمه زبان صحبت می\u200cکند (SLT) و کار MT کم منابع به عنوان بخشی از کمپین ارزیابی IWSLT18 ارزیابی می\u200cکند.', 'sw': 'Ripoti hii ina muhtasari wa tafsiri ya mashine ya Utafiti wa Jeshi la Ndege (AFRL) na mfumo wa kutambua hotuba binafsi (ASR) uliotolewa kwa tafsiri ya lugha inayozungumzwa (SLT) na kazi za MT za chini za rasilimali kama sehemu ya kampeni ya uchunguzi wa IWSLT18.', 'tr': 'Bu rapor Air Force Research Laboratoriýasyny (AFRL) maşynyň terjimesini (MT) we awtomatik çykyş tanamagyny (ASR) sistemlerini IWSLT18 deňleme kampanyasynyň bir parçasynda süýtgedi.', 'af': 'Hierdie raporteer versamel die Air Force Research Laboratorie (AFRL) masjien vertaling (MT) en outomatiese praat herken (ASR) stelsels wat aan die praat taal vertaling (SLT) en lae-hulpbron MT taak as deel van die IWSLT18 evalueringskampanja voorgeskryf word.', 'sq': 'Ky raport përmbledh sistemet e përkthimit të makinave të Laboratorit të Kërkimit të Forcave Ajrore (AFRL) dhe njohjes automatike të fjalës (ASR) të paraqitura në përkthimin e gjuhës së folur (SLT) dhe detyrat me burime të ulëta të MT si pjesë e fushatës së vlerësimit të IWSLT18.', 'am': 'ይህ ሪፖርት የአየር ኃይል ምርምርመራ laboratory (AFRL) machine ትርጉም (MT) እና የንግግር ማስታወቂያ (ASR) ስርዓቶች ለቋንቋ ትርጉም (SLT) እና የዝቅተኛ resource MT ስራዎችን እንደ IWSLT18 ማስታወቂያ ዘመቻ ክፍል ያሳያል።', 'hy': 'Այս զեկույցը համառոտագրում է օդային ուժերի հետազոտության լաբորատորիան (ԱՖՌL) մեքենային թարգմանությունը (ՄԹ) և ավտոմատիկ խոսքի ճանաչելը (ԱՍՌ) համակարգերը, որոնք ներկայացվել են խոսված լեզվի թարգմանության (ՍԼԹ) և ցածր ռեսուրսների միջոցով Մ', 'az': 'Bu x…ôb…ôr Air Force Research LaboratoriyanńĪn (AFRL) maŇüńĪn √ßevirisini (MT) v…ô istifad…ô edil…ôn dil √ßevirisin…ô (SLT) v…ô IWSLT18 deńüerlendirm…ô kampanyasńĪnńĪn bir par√ßas ńĪ olaraq t…ôblińü edilmiŇü avtomatik s√∂z tanńĪmasńĪ sisteml…ôrini yazńĪr.', 'bn': 'এই রিপোর্টটি বিমান বাহিনীর গবেষণা ল্যাবার্টরি (এএফআরএল) এবং স্বয়ংক্রিয় ভাষার অনুবাদ স্বীকৃতি সংক্ষিপ্ত ব্যবস্থা (এসএসএলটি) এবং IWSLT18 মুল্যায়ন প্রচারণার অংশ হিসেবে প্', 'ca': "Aquest informe resumeix els sistemes de traducció màquina (MT) i reconeixement automàtic de la paraula (ASR) del Laboratori de Investigació de la Força Aérea (AFRL) submetits a la traducció de llenguatge parlada (SLT) i tasques de MT de baix recursos com part de la campanya d'evaluació IWSLT18.", 'bs': 'Ovaj izvještaj sažetuje laboratoriju istraživanja zračnih snaga (AFRL) za prevod strojeva (MT) i sisteme prepoznavanja automatskog govora (ASR) predate govornom prevodu jezika (SLT) i zadatku MT sa niskim resursima kao dio kampanje za procjenu IWSLT18.', 'cs': 'Tato zpráva shrnuje systémy strojového překladu (MT) a automatického rozpoznávání řeči (ASR) předložené v rámci hodnotící kampaně IWSLT18.', 'et': 'Käesolevas aruandes esitatakse kokkuvõte õhujõudude uuringute laboratooriumi (AFRL) masintõlke (MT) ja automaatse kõnetuvastuse (ASR) süsteemidest, mis on esitatud IWSLT18 hindamiskampaania raames suulise keele tõlke (SLT) ja madala ressursiga MT ülesannetele.', 'fi': 'Tässä raportissa esitetään yhteenveto ilmavoimien tutkimuslaboratorion (AFRL) konekäännös (MT) ja automaattinen puheentunnistus (ASR) järjestelmistä, jotka on toimitettu puhutun kielen käännöksen (SLT) ja vähäisten resurssien MT-tehtäviin osana IWSLT18-arviointikampanjaa.', 'jv': 'Punika ingkang resumen ning perintah (MT) sak oleh nggunakake tresnaning (ASR) lan sistem sing berarti kanggo tarjamahan langkung (SLT) lan lan basa sing wis kelas nêmên MT sampeyan kanggo ngerasah kampanya IWSLT18.', 'sk': 'To poročilo povzema sisteme strojnega prevajanja (MT) in samodejnega prepoznavanja govora (ASR), ki so bili predloženi prevajanju govornega jezika (SLT) in nalogam strojnega prevajanja z nizkimi viri kot del ocenjevalne kampanje IWSLT18.', 'he': 'הדו"ח הזה מסכם את מערכות התרגום המכונית של מעבדת מחקר חיל האוויר (AFRL - Air Force Research Laboratory) והזיהוי הנאום האוטומטי (ASR - Automatic Speech Recognition) שנשלחו לתרגום השפה המפורסמת (SLT - spoken language translation) והמשימות MT עם משאבים נמוכים כחלק מהקמפיין הערכה IWSL', 'ha': 'This report summarizes the Air Force Research Laboratory (AFRL) machine translation (MT) and automatic speech recognition (ASR) systems submitted to the spoken language translation (SLT) and low-resource MT tasks as part of the IWSLT18 evaluation campaign.', 'bo': 'This report summarizes the Air Force Research Laboratory (AFRL) machine translation (MT) and automatic speech recognition (ASR) systems submitted to the spoken language translation (SLT) and low-resource MT tasks as part of the IWSLT18 evaluation campaign.'}
{'en': 'CUNI Basque-to-English Submission in IWSLT18 CUNI   B asque-to- E nglish Submission in  IWSLT 18', 'ar': 'تقديم CUNI من الباسك إلى الإنجليزية في IWSLT18', 'pt': 'Submissão CUNI Basco para Inglês no IWSLT18', 'fr': 'Soumission CUNI du basque-anglais dans IWSLT18', 'es': 'Envío de euskera a inglés de CUNI en IWSLT18', 'ja': 'IWSLT 18でのCuNiバスク語から英語への提出', 'zh': 'CUNI 巴斯克语至英语 IWSLT18 中', 'hi': 'IWSLT18 में CUNI बास्क-टू-इंग्लिश सबमिशन', 'ru': 'Представление CUNI с баскского на английский в IWSLT18', 'ga': 'Aighneacht Bascais-go-Béarla CUNI in IWSLT18', 'el': 'CUNI Βασκικά προς Αγγλικά Υποβολή στο IWSLT18', 'ka': 'CUNI ბასკური-ანგლისკური სამუშაო IWSLT18', 'hu': 'CUNI baszk-angol nyelvű benyújtás IWSLT18 nyelven', 'it': 'CUNI Contributo basco-inglese in IWSLT18', 'kk': 'IWSLT18 дегенде CUNI баск- мен ағылшынша жіберу', 'lt': 'CUNI Baskų–anglų kalbos pristatymas IWSLT18 kalba', 'mk': 'КУНИ Баски-англиска презентација во IWSLT18', 'ms': 'Submission CUNI Basque-to-English dalam IWSLT18', 'ml': 'CUNI Basque-to-English Submission in IWSLT18', 'mt': 'CUNI Sottomissjoni Baska għall-Ingliż fl-IWSLT18', 'no': 'CUNI Basque-to-English Submission in IWSLT18', 'pl': 'CUNI Zgłoszenie języka baskijsko-angielskiego w IWSLT18', 'sr': 'CUNI Bask-to-English Submission u IWSLT18', 'mn': 'IWSLT18-д CUNI Баск-ээс Англи хэлний дамжуулалт', 'so': 'CUNI Basque-to-Ingiriis Submission in IWSLT18', 'sv': 'CUNI Baskisk-till-engelska inlämning i IWSLT18', 'ro': 'CUNI Limba bască în limba engleză în IWSLT18', 'si': 'CUNI බාස්ක් වල ඉංග්\u200dරීසි වල IWSLT18', 'ta': 'IWSLT18 ல் CUNI பாஸ்க்- ல் இருந்து ஆங்கிலத்திற்கு உப பரிமாற்றம்', 'ur': 'CUNI Basque-to-English Submission in IWSLT18', 'uz': 'IWSLT18 da CUNI Basque- to- Inglizchaga submission', 'vi': 'Biểu tượng quốc bản:', 'bg': 'Подаване от баски до английски език в IWSLT18', 'da': 'CUNI Baskisk-til-engelsk indsendelse i IWSLT18', 'nl': 'CUNI Baskisch-naar-Engels inzending in IWSLT18', 'hr': 'CUNI Bask-to-English Submission u IWSLT18', 'de': 'CUNI Baskisch-to-English Einreichung in IWSLT18', 'id': 'CUNI Basque-to-English Submission in IWSLT18', 'fa': 'CUNI Basque-to-English Submission in IWSLT18', 'ko': '뉴욕시티 대학교 바스크 캠퍼스가 IWSLT18에서 제출한 영문 버전', 'sw': 'Ujumbe wa CUNI-Basque-to-English katika IWSLT18', 'af': 'CUNI Basque- to- English Submission in IWSLT18', 'tr': "CUNI IWSLT18'da baskça-we iňlisçe Submission", 'sq': 'CUNI Basque-to-English Submission in IWSLT18', 'am': 'CUNI Basque-to-English Submission in IWSLT18', 'hy': 'Կունի Բասկի-Անգլերեն ներկայացում18-ում', 'az': 'IWSLT18 içində CUNI Basque-to-English Submission', 'bn': 'IWSLT18-এ CUNI বাস্ক- থেকে ইংরেজী সাবমিশন', 'bs': 'CUNI Bask-to-English Submission u IWSLT18', 'ca': 'CUNI Basque-to-English Submission a IWSLT18', 'cs': 'CUNI Baskicko-anglický příspěvek v IWSLT18', 'et': 'CUNI baski-inglise keele esitamine IWSLT18', 'fi': 'CUNI Baskin ja Englannin kielitaito IWSLT18', 'jv': 'CUNI Basque-to-Inggris Submisi kanggo IWSLT18', 'he': 'CUNI Basque-to-English Submission in IWSLT18', 'ha': 'SubMission in IWSLT18', 'sk': 'CUNI baskovsko-angleški prispevek v IWSLT18', 'bo': 'CUNI Basque-to-English Submission in IWSLT18'}
{'en': 'We present our submission to the IWSLT18 Low Resource task focused on the translation from Basque-to-English. Our submission is based on the current state-of-the-art self-attentive neural network architecture, Transformer. We further improve this strong  baseline  by exploiting available  monolingual data  using the back-translation technique. We also present further improvements gained by a  transfer learning , a technique that trains a  model  using a high-resource language pair (Czech-English) and then fine-tunes the  model  using the target low-resource language pair (Basque-English).', 'ar': 'نقدم تقديمنا إلى مهمة IWSLT18 منخفضة الموارد التي تركز على الترجمة من لغة الباسك إلى الإنجليزية. يعتمد تقديمنا على أحدث هندسة الشبكات العصبية الحالية ، المحولات. لقد قمنا بتحسين خط الأساس القوي هذا من خلال استغلال البيانات المتاحة بلغة واحدة باستخدام تقنية الترجمة العكسية. نقدم أيضًا مزيدًا من التحسينات المكتسبة من خلال التعلم الانتقالي ، وهي تقنية تدرب نموذجًا باستخدام زوج لغوي عالي الموارد (التشيكية-الإنجليزية) ثم ضبط النموذج باستخدام الزوج اللغوي المستهدف منخفض الموارد (لغة الباسك-الإنجليزية).', 'fr': "Nous présentons notre soumission à la tâche IWSLT18 Low Resource axée sur la traduction du basque vers l'anglais. Notre soumission est basée sur l'architecture de réseau neuronal auto-attentive à la pointe de la technologie, Transformer. Nous améliorons encore cette base solide en exploitant les données monolingues disponibles à l'aide de la technique de rétro-traduction. Nous présentons également d'autres améliorations apportées par l'apprentissage par transfert, une technique qui entraîne un modèle à l'aide d'une paire de langues à ressources élevées (tchèque-anglais), puis affine le modèle à l'aide de la paire de langues à faible ressource cible (basque-anglais).", 'es': 'Presentamos nuestra presentación a la tarea IWSLT18 Low Resource centrada en la traducción del euskera al inglés. Nuestra presentación se basa en la arquitectura actual de redes neuronales autoatentas de última generación, Transformer. Mejoramos aún más esta sólida base aprovechando los datos monolingües disponibles mediante la técnica de retrotraducción. También presentamos mejoras adicionales obtenidas con un aprendizaje por transferencia, una técnica que entrena un modelo utilizando un par de idiomas de alto nivel de recursos (checo-inglés) y luego ajusta el modelo utilizando el par de idiomas objetivo de bajos recursos (vasco-inglés).', 'pt': 'Apresentamos nossa submissão à tarefa IWSLT18 Low Resource focada na tradução do basco para o inglês. Nossa submissão é baseada na atual arquitetura de rede neural autoatentiva de última geração, Transformer. Melhoramos ainda mais essa linha de base forte explorando dados monolíngues disponíveis usando a técnica de tradução reversa. Também apresentamos outras melhorias obtidas por um aprendizado de transferência, uma técnica que treina um modelo usando um par de idiomas de alto recurso (tcheco-inglês) e, em seguida, ajusta o modelo usando o par de idioma de baixo recurso de destino (basco-inglês).', 'ja': '私たちは、バスク語から英語への翻訳に焦点を当てたIWSLT 18低資源タスクに提出します。当社の提出物は、現在の最先端の自己注意型ニューラルネットワークアーキテクチャであるトランスフォーマーに基づいています。私たちは、バック翻訳技術を使用して利用可能なモノリンガルデータを利用することによって、この強力なベースラインをさらに改善します。また、高リソース言語ペア（チェコ語-英語）を使用してモデルをトレーニングし、ターゲットとなる低リソース言語ペア（バスク語-英語）を使用してモデルを微調整する、転送学習によって得られたさらなる改善を提示します。', 'zh': 'IWSLT18低资源任提交,重自巴斯克语英语译。 提交基于先进之神经网络架构Transformer。 吾因反译用单语数,更进此强基线。 又言迁学益进,高资言语(捷克语 - 英语)习模形,然后用卑资言语(巴斯克语 - 英语)微调模形。', 'hi': 'हम बास्क-टू-इंग्लिश से अनुवाद पर केंद्रित IWSLT18 कम संसाधन कार्य के लिए अपना सबमिशन प्रस्तुत करते हैं। हमारा सबमिशन वर्तमान राज्य के अत्याधुनिक आत्म-चौकस तंत्रिका नेटवर्क आर्किटेक्चर, ट्रांसफॉर्मर पर आधारित है। हम बैक-ट्रांसलेशन तकनीक का उपयोग करके उपलब्ध मोनोलिंगुअल डेटा का शोषण करके इस मजबूत बेसलाइन को और बेहतर बनाते हैं। हम एक स्थानांतरण सीखने द्वारा प्राप्त आगे के सुधारों को भी प्रस्तुत करते हैं, एक तकनीक जो एक उच्च-संसाधन भाषा जोड़ी (चेक-अंग्रेजी) का उपयोग करके एक मॉडल को प्रशिक्षित करती है और फिर लक्ष्य कम-संसाधन भाषा जोड़ी (बास्क-अंग्रेजी) का उपयोग करके मॉडल को ठीक करती है।', 'ru': 'Мы представляем нашу заявку на выполнение задачи IWSLT18 с ограниченными ресурсами, сосредоточенной на переводе с баскского на английский язык. Наша заявка основана на современной самовнимательной архитектуре нейронной сети Transformer. Мы дополнительно улучшаем эту сильную базовую линию, используя доступные одноязычные данные, используя технику обратного перевода. Мы также представляем дальнейшие улучшения, полученные при трансферном обучении, технике, которая обучает модель с использованием высокоресурсной языковой пары (чешско-английский язык), а затем тонко настраивает модель с использованием целевой низкоресурсной языковой пары (баскско-английский язык).', 'ga': 'Cuirimid ár n-aighneacht faoi thasc Acmhainn Íseal IWSLT18 dírithe ar an aistriúchán ó Bhascais go Béarla. Tá ár n-aighneacht bunaithe ar an ailtireacht úrscothach líonra néarchóras féin-aireach, Transformer. Déanaimid tuilleadh feabhais ar an mbonnlíne láidir seo trí leas a bhaint as sonraí aonteangacha atá ar fáil ag baint úsáide as teicníc an ais-aistriúcháin. Cuirimid i láthair freisin feabhsuithe breise a gnóthaíodh trí fhoghlaim aistrithe, teicníocht a thraenáil samhail trí úsáid a bhaint as péire teanga ard-acmhainne (Seice-Béarla) agus ansin mionchoinnte a dhéanamh ar an tsamhail ag baint úsáide as an sprioc-phéire teanga íseal-acmhainne (Bascais-Béarla).', 'ka': 'ჩვენ ჩვენი წარმოდგენებას IWSLT18 მინუს რესურსის რაოდენობაში, რომელიც ბასკურ-ანგლისგან გადაწყვეტა. ჩვენი დამუშაობა მიმდინარე სურათის თავისუფლებელი ნეიროლური ქსელის აქტიქტიქტურაციაზე დაბაზია. ჩვენ უფრო უფრო უფრო უფრო მეტად ამ ძალიან ფესტური ფესტურის გამოყენებით მონოლენგური მონაცემების გამოყენებით. ჩვენ ასევე უფრო მეტად გავაკეთებთ მონაცემები, რომელსაც მოდელის გამოყენებას გამოყენებს მარტივი რესურსური ენის ზოგი (ფექი-ანგლისური) და შემდეგ მოდელის შესაძლებლობად მარტივი რესურსური ენის ზო', 'hu': 'Bemutatjuk benyújtásunkat az IWSLT18 Low Resource feladatra, amely a baszk-angol fordításra összpontosít. A beadványunk a jelenlegi korszerű, önfigyelmes neurális hálózati architektúrán alapul, a Transformeren. A rendelkezésre álló egynyelvű adatok visszafordítási technika segítségével tovább javítjuk ezt az erős alapképet. További fejlesztéseket mutatunk be a transzfer tanulás során, amely egy olyan technika, amely egy modellt egy nagy erőforrású nyelvpárral (cseh-angol), majd finomhangolja a modellt a cél alacsony erőforrású nyelvpárral (baszk-angol).', 'el': 'Παρουσιάζουμε την υποβολή μας στο έργο Χαμηλών Πόρων που επικεντρώνεται στη μετάφραση από τα Βασκικά στα Αγγλικά. Η υποβολή μας βασίζεται στην τρέχουσα υπερσύγχρονη αρχιτεκτονική νευρικών δικτύων, Transformer. Βελτιώνουμε περαιτέρω αυτή την ισχυρή βάση δεδομένων αξιοποιώντας τα διαθέσιμα μονογλωσσικά δεδομένα χρησιμοποιώντας την τεχνική αντίστροφης μετάφρασης. Παρουσιάζουμε επίσης περαιτέρω βελτιώσεις που επιτεύχθηκαν από τη μάθηση μεταφοράς, μια τεχνική που εκπαιδεύει ένα μοντέλο χρησιμοποιώντας ένα γλωσσικό ζεύγος υψηλών πόρων (τσεχικά-αγγλικά) και στη συνέχεια συντονίζει το μοντέλο χρησιμοποιώντας το γλωσσικό ζεύγος χαμηλού πόρων (βασκικά-αγγλικά).', 'kk': 'Біз IWSLT18 баск-ағылшын тілінен аударылғанда төмен ресурс тапсырмасына жібереміз. Біздің келтіріміз қазіргі өзіміздің күйіне негізделген неврал желінің архитектурасы, Трансформациясы. Біз бұл күшті негізгі сызықты артқа аудару техникасын қолдануға арналған монолингі деректерді қолдануға арналған. Сонымен қатар, трансферт үйреніміз арқылы жақсы жақсартуларды көрсетеді, ресурс тілдерін қолдану үшін үлгісін көмектесетін техникалық (Чех-ағылшын) және оның кейін мақсатты төмен ресурс тілдерін қолдану үшін үлгі', 'it': "Presentiamo la nostra presentazione al compito IWSLT18 Low Resource incentrato sulla traduzione dal basco all'inglese. La nostra presentazione si basa sull'attuale architettura di rete neurale auto-attenta, Transformer. Miglioriamo ulteriormente questa solida base di riferimento sfruttando i dati monolingue disponibili utilizzando la tecnica di back-translation. Presentiamo anche ulteriori miglioramenti ottenuti da un transfer learning, una tecnica che allena un modello utilizzando una coppia di lingue ad alto contenuto di risorse (ceco-inglese) e poi affina il modello utilizzando la coppia di lingue a basso contenuto di risorse target (basco-inglese).", 'mk': 'Го претставуваме нашето поднесување на IWSLT18 задачата со ниски ресурси фокусирана на преводот од баски на англиски. Нашето поднесување е базирано на сегашната најсовремена архитектура на нервната мрежа, Трансформер. Понатаму ја подобруваме оваа силна основа со искористување на достапните монојазични податоци користејќи ја техниката на превод. Ние, исто така, претставуваме понатамошни подобрувања постигнати од префрлање на учењето, техника која обучува модел користејќи пар јазик со високи ресурси (чешко-англиски) и потоа го финетизира моделот користејќи пар јазик со ниски ресурси (баск-англиски', 'lt': 'We present our submission to the IWSLT18 Low Resource task focused on the translation from Basque-to-English.  Our submission is based on the current state-of-the-art self-attentive neural network architecture, Transformer.  Toliau geriname šią tvirtą bazę naudojant turimus monokalbinius duomenis taikant grįžtamojo vertimo metodą. Mes taip pat pristatome tolesnius patobulinimus, gautus naudojant mokymąsi perkėlimu, metodą, pagal kurį mokomas modelis naudojant didelės apimties kalbų porą (čekų–anglų kalba), o vėliau tobulinamas modelis naudojant tikslinę mažos apimties kalbų porą (baskų–anglų kalba).', 'ms': 'Kami memperkenalkan penghantaran kami kepada tugas Sumber Terrendah IWSLT18 fokus pada terjemahan dari Basque-ke-Inggeris. Penghantaran kita berdasarkan arkitektur rangkaian saraf yang sedap kini, Transformer. Kami lebih meningkatkan asas kuat ini dengan mengeksploitasi data monobahasa yang tersedia menggunakan teknik terjemahan belakang. Kami juga memperlihatkan peningkatan lanjut yang diperoleh oleh pembelajaran pemindahan, teknik yang melatih model menggunakan pasangan bahasa sumber tinggi (Czech-English) dan kemudian memperbaiki model menggunakan pasangan bahasa sumber rendah sasaran (Basque-English).', 'ml': 'ബാസ്ക്- മുതല്\u200d ഇംഗ്ലീഷില്\u200d നിന്നുള്ള പരിഭാഷണത്തിന്\u200dറെ മേല്\u200d ഞങ്ങള്\u200d ഞങ്ങളുടെ കീഴ്പെടുത്തിയിരിക്കുന്നു. നമ്മുടെ സമ്മതം ഇപ്പോഴത്തെ സ്വയം ആത്മശ്രദ്ധിക്കുന്ന ന്യൂറല്\u200d നെറ്റൂറല്\u200d നെറ്റാള്\u200d ആര്\u200dക്കിട്ടേര്\u200dക്ക് അടിസ്ഥ ബാക്ക്-ട്രെന്\u200dഷന്\u200d ടെക്നിക്ക് ഉപയോഗിച്ച് ലഭ്യമായ മോണോളില്\u200dഗുള്\u200d ഡേറ്റാ ഉപയോഗിച്ച് ഈ ശക്തിയുള്ള ഒരു മാറ്റം പഠിപ്പിക്കുന്നതില്\u200d നിന്നും കൂടുതല്\u200d മെച്ചപ്പെടുത്തുന്ന മുന്നേറ്റങ്ങള്\u200d ഞങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു. അത് ഒരു മോഡല്\u200d ഉപയോഗിക്കുന്നു. ഒരു', 'mt': 'Aħna nippreżentaw is-sottomissjoni tagħna lill-IWSLT18 Low Resource task iffukata fuq it-traduzzjoni mill-Bask għall-Ingliż. Is-sottomissjoni tagħna hija bbażata fuq l-arkitettura attwali tan-netwerk newrali awto-attent, Transformer. We further improve this strong baseline by exploiting available monolingual data using the back-translation technique.  Aħna nippreżentaw ukoll aktar titjib miksub permezz ta’ tagħlim ta’ trasferiment, teknika li tħarreġ mudell bl-użu ta’ par lingwistiku b’riżorsi għoljin (Ċek-Ingliż) u mbagħad nirranġaw il-mudell bl-użu tal-par lingwistiku b’riżorsi baxxi fil-mira (Bask-Ingliż).', 'mn': 'Бид IWSLT18 Баск-ээс Англи хэлэхэд бага боловсролын ажлын төлөө төвлөрсөн. Бидний хүлээн зөвшөөрөл нь орчин үеийн урлагийн өөртөө анхаарлын мэдрэлийн сүлжээний архитектур, Трансформфер дээр суурилсан. Бид энэхүү хүчтэй суурь шугам дээр буцаад орчуулах технологийг ашиглаж, нэг хэл өгөгдлийг ашиглаж байна. Мөн бид шилжүүлэх сургалтын дасгал сайжруулалтыг илүү сайжруулж, өндөр ресурсов хэл хоёр (Чех-Англи) ашиглан загварын дасгал хөгжүүлэх техник, дараа нь зориулагдсан бага ресурсов хэл хоёрыг ашиглан загварын төл', 'pl': 'Przedstawiamy naszą zgłoszenie do zadania IWSLT18 Low Resource skupiającego się na tłumaczeniu z języka baskijskiego na angielski. Nasze zgłoszenie opiera się na aktualnej, najnowocześniejszej architekturze sieci neuronowej Transformer. Dalej poprawiamy tę silną bazę podstawową poprzez wykorzystanie dostępnych danych jednojęzycznych przy użyciu techniki tłumaczenia wstecznego. Przedstawiamy również dalsze ulepszenia uzyskane dzięki uczeniu się transferowemu, technice, która szkoli model z wykorzystaniem pary językowej o wysokich zasobach (czesko-angielski), a następnie dostosowuje model przy użyciu docelowej pary językowej o niskich zasobach (baskijsko-angielski).', 'ro': 'Prezentăm depunerea noastră la sarcina IWSLT18 Low Resource axată pe traducerea din bască în engleză. Sublinierea noastră se bazează pe arhitectura actuală de rețea neurală auto-atentă, Transformer. Îmbunătățim în continuare această bază de referință puternică prin exploatarea datelor monolingve disponibile folosind tehnica back-translation. De asemenea, prezentăm îmbunătățiri suplimentare obținute de o învățare de transfer, o tehnică care antrenează un model folosind o pereche de limbi cu resurse ridicate (cehă-engleză) și apoi reglează modelul folosind perechea de limbi cu resurse reduse țintă (bască-engleză).', 'no': 'Vi presenterer vårt oppføring til IWSLT18 låg ressursoppgåva fokusert på omsetjinga frå bask-til-engelsk. Vårt oppføring er basert på den gjeldande tilstanden av kunsten selvfølgjande neuralnettverksarkitekturen, Transformer. Vi forbedrar denne sterke baselinja lenger ved å bruka tilgjengelege monospråk-data med teknikken for tilbakeomsetjing. Vi presenterer også fleire forbedringar som får ved å lære overføringar, ein teknikk som treng eit modell med eit høg ressursspråk pair (Tsjekkisk-engelsk) og så finn opp modellen med målsspråk par (bask-engelsk).', 'sr': 'Predstavljamo svoju predanost zadatku IWSLT18 niskog resursa fokusiranom na prevod od baskijskog do engleskog. Naša podnošenja je zasnovana na trenutnom stanju samopouzdanja neuralne mreže, Transformer. Nadalje ćemo poboljšati ovu jaku osnovnu liniju iskorištavajući dostupne monojezičke podatke koristeći tehniku prevoda pozadine. Također predstavljamo i daljnje poboljšanje dobijeno učenjem prijenosa, tehniku koja trenira model korištenjem visokih resursa pair a jezika (češki-engleski) i zatim ispravljamo model korištenjem meta nizakvog jezika paira (baskijski-engleski).', 'si': 'අපි අපේ පිළිගන්න IWSLT18 අඩුම ප්\u200dරධාන ක්\u200dරියාවට බාස්ක් වල ඉංග්\u200dරීසිය වලින් පරිවර්තනය කරනවා. අපේ පිළිගන්නේ ප්\u200dරස්තූතිය තත්වයේ ස්වයංත්\u200dර ස්වයංත්\u200dර සංවිධානය, ප්\u200dරවිච්චාරකය. අපි මේ ශක්තිමත් ප්\u200dරධාන ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරන්න පුළුවන් එක භාෂාවක් දත්ත ප්\u200dරයෝජනය කරන්න ප අපි ප්\u200dරවේශනයක් ඉගෙනගන්න පුළුවන් වැඩි වැඩි ප්\u200dරවේශනයක් ප්\u200dරවේශනයක් ප්\u200dරවේශනයක් ප්\u200dරවේශනය කරනවා, අධ්\u200dයස්ථාන භාෂාවක් ප්\u200dරවේශනය කරනවා', 'ta': 'நாங்கள் IWSLT18 குறைந்த மூலம் பணிக்கு எங்கள் ஒப்பை கொண்டு வருகிறோம் பாஸ்க்- மொழிபெயர்ப்பை மொழிபெயர்ப்பில நம்முடைய சரணங்கள் தற்போதைய நிலையில் உள்ளது - கலை சார்ந்த தன்னுடைய சார்ந்த புதிய வலைப்பின்னல் கட்டுப்பாடு, மா திரும்ப மொழிபெயர்ப்பு தொழில்நுட்பத்தை பயன்படுத்தி இந்த வலிமை அடிப்பகுதியை மேம்படுத்துகிறோம். மாற்று கற்றுக்கொள்ளும் மேலும் முன்னேற்றங்களை நாம் கூடுகிறோம், அது ஒரு மாதிரி உயர்மூலத்தின் ஜோடி (செக்- ஆங்கிலம்) பயன்படுத்தும் மாதிரியை பயிற்சி செய்கி', 'so': 'Waxaynu soo dhiibnaa shaqada hoose ee IWSLT18 ku qornaa turjumaanka Basque-to-Ingiriis. Madaxalkayagu waxay ku saleysan tahay taariikhda shabakadda neurada, Transformer. Sidoo kale waxaynu horumarinnaa qoraalkaas xoogga leh, si aan ugu isticmaalno teknikada tarjumaadka dib-u-isticmaalka macluumaadka afka ah. Waxbarashada bedelka ah waxaa sidoo kale ah horumarinta dheeraadka ah ee loo soo kordhiyey, teknikada ku tababarida noocyada ku isticmaalaya luqada sare ee noocyada luqada (Czech-Ingiriis) kadibna waxaynu sameynaa noocyada ku isticmaalaya labada luqada hoose-resource (Basque-Ingiriis).', 'sv': 'Vi presenterar vårt bidrag till IWSLT18 Low Resource-uppgiften med fokus på översättning från baskiska till engelska. Vårt bidrag är baserat på den nuvarande state-of-the-art självuppmärksam neurala nätverksarkitekturen, Transformer. Vi förbättrar denna starka bas ytterligare genom att utnyttja tillgängliga enspråkiga data med hjälp av backöversättningstekniken. Vi presenterar också ytterligare förbättringar som uppnåtts genom transferinlärning, en teknik som tränar en modell med hjälp av ett högresursspråkpar (tjeckiska-engelska) och sedan finjusterar modellen med hjälp av målspråket lågresurs (baskiska-engelska).', 'ur': 'ہم نے IWSLT18 کم رسسور کے کام پر اپنے تسلیم کو پیش کیا ہے جو Basque-to-English کی ترجمہ پر تمرکز کیا گیا ہے۔ ہماری مسلمانیت موجود ایٹرنیسٹ کی سیدھی موقعیت پر متوجہ ہوئی نئورل نیٹورک معماری، ترنسفور پر ہے. ہم اس مضبوط بنیس لین کو اضافہ کر رہے ہیں کہ اس کے مطابق واپس ترجمہ ٹیکنیک کے مطابق موجود موجود ایک زبان کی ڈاکٹی استعمال کریں۔ ہم نے بھی ایک ترنسیس سیکھنے کے ذریعہ اضافہ کی ترنسیس کی تعلیم کے ذریعہ اضافہ کی ترنسیس کی ایک ٹیکنیک ہے جو ایک ماڈل کی استعمال کرتا ہے اور اس کے بعد موڈل کو نیچے منبع زبان جوڑ کے ذریعہ مطابق مطابق مطابق مطابق مطابق مطابق', 'uz': "Biz IWSLT18 qanchalik Resource vazifani ko'rib chiqqamiz Basque- Inglizdan tarjima qilishga maktab qilamiz. Bizning imkoniyatlarimiz joriy shaxsiy neyrol tarmoqni tahrirlash va tarmoqni tahrirlash asosida asosida. Biz orqali tarjima-tarjima texnologiya yordamida oddiy asboblarni ko'rib chiqaramiz. Va biz o'rganishni o'rganishga koʻproq o'rganishni hozir qilamiz. Bu modelni yuqori resource tillari qo'lingiga (Czech- Ingliz tilidan) yordamida o'rnatadi. Keyin esa bu modelni kichkina manba tilning ikki xil (Basque- Ingliz tili) yordamida yordam beradi.", 'vi': 'Chúng tôi xin giới thiệu đến công việc IWSLT18 nhằm mục tiêu dịch từ Basque-English. Sự cung cấp của chúng tôi dựa trên kiến trúc dây thần kinh siêu việt, Transformer. Chúng ta sẽ cải thiện cơ sở vững chắc này bằng cách khai thác dữ liệu ngôn ngữ bằng cách dịch lại. Chúng tôi cũng giới thiệu cải tiến thêm được cải tiến nhờ một khóa học chuyển nhượng, một kỹ thuật huấn luyện một mô hình bằng một đôi ngôn ngữ chất lượng cao (Séc-Anh) và rồi chỉnh lại mô hình sử dụng một cặp ngôn ngữ ít tài nguyên (Basque-English).', 'da': 'Vi præsenterer vores indsendelse til IWSLT18 Low Resource opgave fokuseret på oversættelse fra baskisk til engelsk. Vores indlæg er baseret på den nuværende state-of-the-art selvopmærksomme neurale netværksarkitektur, Transformer. Vi forbedrer yderligere denne stærke baseline ved at udnytte tilgængelige ensprogede data ved hjælp af back-translation teknik. Vi præsenterer også yderligere forbedringer opnået ved en transfer learning, en teknik, der træner en model ved hjælp af et high-resource sprogpar (tjekkisk-engelsk) og derefter finjusterer modellen ved hjælp af målet low-resource sprogpar (baskisk-engelsk).', 'hr': 'Predstavljamo svoju predanost zadatku IWSLT18 niskog resursa usredotočenom na prevod od baskijskog do engleskog. Naša podnošljenja je temeljena na trenutnom stanju samopouzdane neuralne mreže, Transformer. Nadalje ćemo poboljšati ovu jaku početnu liniju iskorištavajući dostupne monojezičke podatke koristeći tehniku prevoda pozadine. Također predstavljamo i daljnje poboljšanje dobijene učenjem prijenosa, tehniku koja trenira model koristeći visokoresursni jezički par (češki-engleski) i zatim ispravlja model koristeći broj jezika s niskim resursima (baskijski-engleski).', 'bg': 'Представяме нашето представяне на задачата с нисък ресурс, фокусирана върху превода от баски на английски език. Нашето представяне се основава на съвременната архитектура на нервната мрежа "Трансформатор". Ние допълнително подобряваме тази силна база, като използваме наличните едноезични данни, използвайки техниката за обратно превод. Представяме и допълнителни подобрения, придобити от трансферното обучение, техника, която обучава модел с помощта на езикова двойка с висок ресурс (чешки-английски) и след това фино настройва модела с помощта на целевата езикова двойка с нисък ресурс (баски-английски).', 'id': 'Kami mempersembahkan pengiriman kami ke IWSLT18 Low Resource tugas fokus pada terjemahan dari Basque-ke-Inggris. Pengiriman kami berdasarkan arkitektur jaringan saraf yang teratur saat ini, Transformer. Kami meningkatkan garis dasar yang kuat ini dengan mengeksploitasi data monobahasa yang tersedia menggunakan teknik terjemahan belakang. Kami juga mempersembahkan peningkatan lanjut yang diperoleh oleh pembelajaran transfer, teknik yang melatih model menggunakan pasangan bahasa sumber daya tinggi (Czech-English) dan kemudian memperbaiki model menggunakan pasangan bahasa sumber daya rendah sasaran (Basque-English).', 'nl': 'We presenteren onze inzending aan de IWSLT18 Low Resource taak gericht op de vertaling van het Baskisch naar het Engels. Onze inzending is gebaseerd op de huidige state-of-the-art zelfattente neurale netwerkarchitectuur, Transformer. We verbeteren deze sterke baseline verder door gebruik te maken van beschikbare eentalige gegevens met behulp van de back-translation techniek. We presenteren ook verdere verbeteringen verkregen door een transfer learning, een techniek die een model traint met behulp van een high-resource taalpaar (Tsjechisch-Engels) en vervolgens het model verfijnt met behulp van het doellow-resource taalpaar (Baskisch-Engels).', 'de': 'Wir stellen unseren Beitrag zur IWSLT18 Low Resource Aufgabe vor, die sich auf die Übersetzung aus dem Baskischen ins Englische konzentriert. Unsere Einreichung basiert auf dem aktuellen Stand der Technik, der selbstaufmerksamen neuronalen Netzwerkarchitektur Transformer. Wir verbessern diese starke Basis weiter, indem wir verfügbare einsprachige Daten mit der Rückübersetzungstechnik nutzen. Darüber hinaus stellen wir weitere Verbesserungen vor, die durch ein Transferlernen erzielt wurden, eine Technik, die ein Modell mit einem ressourcenreichen Sprachpaar (Tschechisch-Englisch) trainiert und dann das Modell mit dem ressourcenarmen Zielsprachenpaar (Baskisch-Englisch) verfeinert.', 'fa': 'ما تحویل خود را به کار منابع کمی IWSLT18 نشان می دهیم که روی ترجمه از بوسک به انگلیسی تمرکز شده است. تسلیم ما بر اساس معماری شبکه عصبی، تغییر دهنده فعلی است. ما این خط بنیادی قوی را با استفاده از داده های یک زبان موجود با استفاده از تکنیک ترجمه پشت بهتر می کنیم. ما همچنین پیشرفتهای بیشتری را که توسط یادگیری انتقال یافته است، یک تکنیکی است که یک مدل را با استفاده از جفت زبان بالا (چک-انگلیسی) تمرین می\u200cکند، و بعد مدل را با جفت زبان کم منبع (باسک-انگلیسی) تنظیم می\u200cکند.', 'ko': '우리는 바스케어에서 영어까지의 번역에 중점을 두고 IWSLT18 저자원 임무를 제출했다.우리의 제출은 현재 가장 선진적인 자기 관심 신경 네트워크 구조인 Transformer를 바탕으로 한다.우리는 역방향 번역 기술을 사용하여 사용 가능한 단어 데이터를 이용하여 이 강력한 기선을 더욱 개선했다.이동 학습을 통해 얻은 진일보한 개선도 소개했다. 이것은 고자원 언어 대(체코 영어) 훈련 모델을 사용한 다음에 목표 저자원 언어 대(바스크 영어) 마이크로 모델을 사용하는 기술이다.', 'sw': 'Tunawasilisha ujumbe wetu kwenye kazi ya IWSLT18 ya rasilimali chini yenye lengo la kutafsiri kutoka Basque-to-English. Mawasiliano yetu yanahusiana na hali ya sasa yenye sanaa yenyewe na ujenzi wa mtandao wa neura unaoendelea, Transfer. Tunaendelea kuboresha misingi hii yenye nguvu kwa kutumia taarifa zinazopatikana kwa lugha za kiutafsiri. Pia tunaweka maendeleo mengine yanayofanikiwa na elimu ya uhamishaji, teknolojia ambayo inafundisha muundo kwa kutumia mbili za lugha ya juu rasilimali (Kizech-Kiingereza) na baadae tunaonyesha mwelekeo mzuri kwa kutumia mbili za lugha ya chini ya rasilimali (Basque-English).', 'tr': 'Biz IWSLT18-dan iňlisçe terjime etmäge rugsat berýäris. Biziň ilatymyz häzirki möhüm möhüm bolan özüni tanyş neural aýry arhitekteriýasyna daýanýar. Biz şu güýçli esasy hatlary arka terjime teknikini ulanarak, bar monodil maglumatlaryny ulanarak gowlaşdyrys. Biz hem gowy göçüp öwrenmek üçin gazanýan täzelikleri, ýokary kaynakly dil çiňisini ulanan nusga üçin örän gowylaşdyran tekniki görkeýäris we soňra nusgany iň az kaynakly dil çiňisini ulanarak (bask-iňlisçe).', 'am': 'የIWSLT18 ታናሽ የኩነታችንን ጉዳይ ከባስክ-ወደ እንግሊዘኛ ለመትርጓሜ እናቀርባለን፡፡ አዋጅ የአሁኑ የራሳቸውን የራሳቸውን የነጥብ መረብ መሠረት፣ የተዘጋጀ ነው፡፡ በኋላ-ትርጉም-ስህተት በመጠቀም የተገኘውን የሞሎንቋል ዳታዎችን በመጠቀም ይህንን ጽኑ መደገፊያውን እናሳድጋለን፡፡ We also present further improvements gained by a transfer learning, a technique that trains a model using a high-resource language pair (Czech-English) and then fine-tunes the model using the target low-resource language pair (Basque-English).', 'hy': 'Մենք ներկայացնում ենք մեր ներկայացումը IwSlaT18 ցածր ռեսուրսների խնդիրը, որը կենտրոնացված է բասկի-անգլերեն թարգմանման վրա: Our submission is based on the current state-of-the-art self-attentive neural network architecture, Transformer.  Մենք նաև բարելավում ենք այս ուժեղ հիմքը օգտագործելով հասանելի միալեզու տվյալներ՝ օգտագործելով հետադարձ թարգմանման տեխնիկան: Մենք նաև ներկայացնում ենք ավելին բարելավումներ, որոնք ստացվել են փոխանցման ուսումնասիրության միջոցով, մի մեթոդ, որը վարժեցնում է մոդելը օգտագործելով բարձր ռեսուրսների լեզվի զույգ (Չեխ-Անգլերեն) և հետո բարելավում է մոդելը օգտագործելով ցածր', 'af': "Ons stel ons ondersteuning aan die IWSLT18 Lae hulpbron taak gefokus op die vertaling van Bask-na-Engels. Ons ondersteuning is gebaseer op die huidige staat van die kuns self-aandag neuralnetwerk architecture, Transformer. Ons verder verbeter hierdie sterk basislien deur beskikbare monolinglike data te gebruik deur die terugvertalingstekniks te gebruik. Ons stel ook verdere verbeteringe wat deur 'n oordrag leer ontvang word, 'n teknikkie wat 'n model trein met 'n hoë-hulpbronne taal paar (Tsjeek-Engels) en dan fin-tunneer die model deur te gebruik van die teiken lae-hulpbronne taal paar (Bask-Engels).", 'sq': 'Ne paraqesim paraqitjen tonë në IWSLT18 me burime të ulëta të përqëndruara në përkthimin nga bask në anglisht. Subjektimi ynë është bazuar në arkitekturën aktuale të rrjetit nervor, Transformer. Ne përmirësojmë më tej këtë bazë të fortë duke shfrytëzuar të dhënat monogjuhësore të disponueshme duke përdorur teknikën e përkthimit mbrapa. Ne prezantojmë gjithashtu përmirësime të mëtejshme të fituara nga një mësim transferimi, një teknikë që trajnon një model duke përdorur një çift gjuhësh me burime të larta (çek-anglez) dhe pastaj përmirëson modelin duke përdorur çiftin gjuhësh me burime të ulta (bask-anglez).', 'az': "Biz IWSLT18'nin düşük ressurs işinə təklif edirik. Basque-to-İngilizdən təklif edilməsinə odaqlanır. Bizim təklifimiz, həmişəlik sanatın özünü dinləyici nöral ağ arhitektarının, Transformer şəklinə dayanılır. Biz bu qüvvətli sətiri geri çeviriş tekniklərini istifadə edərək mümkün olan monodil məlumatlarını istifadə edərik. Biz həmçinin hərəkət öyrənməsi ilə öyrəndiyimiz daha yaxşılıqları göstəririk, yüksək ressurs dili çift (Çək-İngilizce) ilə modeli təhsil edən, sonra modeli düşük ressurs dili çift (Basq-İngilizce) ilə müəyyən edirik.", 'bn': 'আমরা আইউএসএলটি১৮ নিম্ন রিসোর্স কাজের প্রতি আমাদের প্রতিক্রিয়া উপস্থাপন করছি বাস্ক থেকে ইংরেজি থেকে অনুবাদের উপর আমাদের আত্মসমর্পণ বর্তমান পরিস্থিতির উপর ভিত্তিতে রয়েছে নিউরেল নেটওয়ার্ক কাঠামোর, ট্রান্সফার। পিছন-অনুবাদের প্রযুক্তি ব্যবহার করে আমরা এই শক্তিশালী বেস্ট লাইনে আরো উন্নত করি। এছাড়াও আমরা একটি পরিবর্তন শিক্ষার ফলে আরো উন্নতি উপস্থাপন করি, একটি প্রযুক্তি যা হাই-সম্পদ ভাষার জোড়া (চেক- ইংরেজী) ব্যবহার করে একটি মডেল প্রশিক্ষণ দেয় এবং তারপর মোডেলের সুন্দর ভা', 'cs': 'Představujeme náš příspěvek k úkolu IWSLT18 Low Resource zaměřenému na překlad z baskičtiny do angličtiny. Náš příspěvek je založen na současné nejmodernější architektuře neuronové sítě Transformer. Tento silný základ dále zlepšujeme využitím dostupných jednojjazyčných dat pomocí techniky zpětného překladu. Dále představujeme další zlepšení získaná transferovým učením, technikou, která trénuje model pomocí jazykového páru s vysokými zdroji (česko-angličtina) a následně jej vyladí pomocí cílového jazykového páru s nízkými zdroji (baskičtina-angličtina).', 'bs': 'Predstavljamo svoju predanost zadatku IWSLT18 niskog resursa fokusiranom na prevod od baskijskog do engleskog. Naša podnošenja je temeljena na trenutnom stanju samopouzdane neuralne mreže, Transformer. Nadalje ćemo poboljšati ovu jaku početnu liniju iskorištavajući dostupne monojezičke podatke koristeći tehniku prevoda pozadine. Također predstavljamo i daljnje poboljšanje dobijeno učenjem prijenosa, tehniku koja trenira model koristeći visokoresursni jezički par (češki-engleski) i zatim ispravljamo model koristeći broj jezika s niskim resursima (baskijski-engleski).', 'ca': "Presentam la nostra presentació a la tasca de Low Resource IWSLT18 centrada en la traducció de vesc a anglès. La nostra presentació es basa en l'arquitectura actual de la xarxa neural moderna, Transformer. També millorem aquesta base de referència forta explotant les dades monolingües disponibles utilitzant la tècnica de retrotraducció. També presentem millores més aconseguides amb l'aprenentatge de transfer ència, una tècnica que entrena un model fent servir un parell de llenguatges d'alt recurso (cec-anglès) i després millora el model fent servir el parell de llenguatges de baix recursos (basc-anglès).", 'et': 'Esitleme oma ettepanekut IWSLT18 Low Resource ülesandele, mis keskendub tõlkele baski-inglise keelest. Meie esitamine põhineb praegusel kaasaegsel enesetähelepanelikul neurovõrgu arhitektuuril Transformer. Me täiustame seda tugevat lähtetaset veelgi, kasutades tagasitõlke tehnikat kasutades kättesaadavaid ühekeelseid andmeid. Samuti tutvustame edasisi täiendusi, mis on saadud siirdeõppest, tehnikast, mis treenib mudelit, kasutades kõrge ressursiga keelepaari (tšehhi-inglise) ja seejärel täpsustab mudelit, kasutades madala ressursiga keelepaari (baski-inglise).', 'fi': 'Esittelemme ehdotuksemme IWSLT18 Low Resource -teht채v채채n, joka keskittyy k채채nn철ksiin baskista englanniksi. Ty철nt철mme perustuu nykyiseen huipputekniikkaan itsetarkkaavaiseen neuroverkkoarkkitehtuuriin Transformeriin. Parannamme edelleen t채t채 vahvaa l채ht철kohtaa hy철dynt채m채ll채 saatavilla olevaa yksikielist채 tietoa taaksek채채nn철stekniikalla. Lis채ksi esittelemme siirtooppimisella saatuja parannuksia. Tekniikka, joka kouluttaa mallia k채ytt채en suuriresurssista kieliparia (t큄ekki-englanti) ja hienos채채t채채 mallia k채ytt채m채ll채 kohdekieliparia (baski-englanti).', 'ha': "@ info: status Musuluncinmu ne a kan halin-state-of-the-art-ingancin jerin neural, Transformer. Ko ƙara, Muke ƙarfafa wannan salon mai ƙarfi da amfani da zane-zane-zane-bakin-translation. Kayya, Munã halatar da mafaniko ko ƙari wanda aka samar da shi ana iya amfani da wani zanen motsi da ya yi amfani da nau'in lugha na sarki (Czech-Ingiriya) kuma yana sami-gyare da misalin ya yi amfani da nau'in lugha-nau'in (Basque-Ingiriya).", 'he': "אנחנו מציגים את ההעברה שלנו לתפקיד IWSLT18 משאבים נמוכים מתמקד בתרגום מבסקי לאנגלית. ההצגה שלנו מבוססת על ארכיטקטורת הרשת העצבית העצמית הנוכחית, טרנספורטר. אנו משתפרים יותר את הבסיס החזק הזה על ידי ניצל נתונים מונושפתיים זמינים באמצעות טכניקת התרגום האחורית. אנחנו גם מציגים שיפורים נוספים שנוצאים על ידי לימוד העברה, טכניקה שמאמנת מודל בשימוש זוג שפת משאבים גבוהים (צ'ק-אנגלית) ואז מתאים את המודל בשימוש זוג שפת משאבים נמוכים (בסק-אנגלית).", 'sk': 'Predstavljamo našo predstavitev na nalogo IWSLT18 Low Resource, osredotočeno na prevajanje iz baskovščine v angleščino. Naša predložitev temelji na najsodobnejši arhitekturi nevronskega omrežja Transformer. To močno izhodišče nadalje izboljšujemo z izkoriščanjem razpoložljivih enojezičnih podatkov z uporabo tehnike nazaj prevajanja. Predstavljamo tudi nadaljnje izboljšave, pridobljene s transfernim učenjem, tehniko, ki usposablja model z uporabo jezikovnega pare z visokimi viri (češčina-angleščina), nato pa ga natančno nastavi z uporabo ciljnega jezikovnega pare z nizkimi viri (baskovščina-angleščina).', 'jv': "Awakdhéwé menyang karo ingkang IWSLT18 Mi-ne 'Game Info' Rasané awak dhéwé digawesi sistem sing dibenakake ning laraturan sing sampeyan Jaringan, Transformer. Awak dhéwé luwih bantayakno sing nggawe barang-tangan kuwi nggawe dadi sing berarti pernik ingkang sampeyan ingkang beki. Awak dhéwé éntuk nglanggar bantuan liyane sing luwih nggawe ngubah tarjamahan, teknik sing nggawe modèl kuwi nggawe gerakan ingkang bantuan liyane (Cek-ingles) lan nganggo iso nggawe modèl kuwi padha nganggo perusahaan langa-bantuan.", 'bo': 'ང་ཚོས་IWSLT18 དཔག་མཐུན་རྐྱེན་གྱི་བྱ་འགུལ་ལ་ང་ཚོའི་མཉམ་དུ་གཏོང་བ་ཡོད། ང་ཚོའི་ཆོག་འཆན་འདི་ད་ལྟོའི་གནས་སྟངས་སྔོན་སྒྲིག་རང་ཉིད་དང་བློ་གཏོང་གི་ཡུལ་སྒྲིག་དང་བཟོ་བཅོས་པ། ང་ཚོས་རྒྱ་ནག་གི་ཆ་འཕྲིན་ཡིག་ཆ་ནང་དུ་ཡོད་པའི་རྨས་གཞི་འདི་ལྟར་ཡར་རྒྱས་སྤྲོད་ཀྱི་ཐབས་ལམ་ལ་ལག་ལེན་འཐབ ང་ཚོས་གནས་སྟངས་བསྡུར་ན་གྱི་ཐབས་ལམ་ལ་ཁྱབ་པར་མཐུན་རྐྱེན་ཐབས་ལམ་ཞིག་ཡིན་པ་ལས།'}
{'en': 'Data Selection with Feature Decay Algorithms Using an Approximated Target Side', 'ar': 'تحديد البيانات باستخدام خوارزميات تحلل الميزة باستخدام جانب مستهدف تقريبي', 'pt': 'Seleção de dados com algoritmos de decaimento de recursos usando um lado de destino aproximado', 'fr': "Sélection de données à l'aide d'algorithmes de désintégration de caractéristiques utilisant un côté cible approché", 'es': 'Selección de datos con algoritmos de decaimiento de características utilizando un lado objetivo aproximado', 'ja': '近似ターゲット側を使用した特徴分解アルゴリズムを使用したデータ選択', 'zh': '用近似侧者,减算法以数据选择之', 'hi': 'एक अनुमानित लक्ष्य पक्ष का उपयोग कर सुविधा क्षय एल्गोरिदम के साथ डेटा चयन', 'ru': 'Выбор данных с помощью алгоритмов затухания признаков с использованием приближенной целевой стороны', 'ga': 'Roghnú Sonraí le Gné-Algartam Meath Ag Úsáid Thart Taobh Sprice', 'el': 'Επιλογή δεδομένων με αλγόριθμους αποσύνθεσης χαρακτηριστικών χρησιμοποιώντας μια κατά προσέγγιση πλευρά στόχου', 'ka': 'მონაცემების არჩევა ფუტურის გადასრულებული ალგორიტემის გამოყენება', 'hu': 'Adatok kiválasztása funkcióeltávolítási algoritmusokkal hozzávetőleges céloldalon', 'it': 'Selezione dei dati con algoritmi di decadimento delle caratteristiche utilizzando un lato obiettivo approssimativo', 'lt': 'Duomenų atranka su požymių sumažėjimo algoritmais, naudojant apytikslią tikslinę pusę', 'kk': 'Қасиеттерді шегіндіру алгоритмдерін таңдау', 'mk': 'Избор на податоци со алгоритми за уништување на приближната страна на целта', 'ms': 'Pemilihan Data dengan Algoritma Penghancuran Feature Mengguna Sisi Sasaran Dikira-kira', 'mt': 'Data Selection with Feature Decay Algorithms Using an Approximated Target Side', 'ml': 'പ്രോക്സിമേറ്റ് ലക്ഷ്യം ഭാഗത്ത് ഉപയോഗിക്കുന്ന വ്യത്യസ്ത തെരഞ്ഞെടുക്കുക', 'mn': 'Хэрэглэгдсэн Цагаан талыг ашиглаж өгөгдлийн сонголт', 'no': 'Data- utval med funksjonsløysing- algoritmer ved bruk av ein tilnærmings målside', 'pl': 'Wybór danych z algorytmami rozpadu funkcji przy użyciu przybliżonej strony docelowej', 'ro': 'Selectarea datelor cu algoritmii de decapare a caracteristicilor utilizând o parte țintă aproximativă', 'si': 'විශේෂතාවක් සැකසුම් ඇල්ගෝරිතම් සමග දත්ත තෝරාගන්න', 'so': 'Dalbashada macluumaadka oo ku qoran Algorityada dooliga gaarka ah', 'sv': 'Dataval med algoritmer för funktionsbortfall med hjälp av en ungefärlig målsida', 'sr': 'Izabranje podataka sa algoritmima za odlaganje funkcije koristeći približenu ciljnu stranu', 'ta': 'சுலபமாக்கப்பட்ட இலக்கு பக்கத்தை பயன்படுத்தி தகவல் தேர்வுகள்', 'ur': 'فرصت ڈیسی الگوریتم کے ساتھ ڈاٹ انتخاب کرنا', 'uz': 'Data Selection with Feature Decay Algorithms Using an Approximated Target Side', 'vi': 'Bộ lọc dữ liệu với các đơn vị tham gia xung đột Mục tiêu', 'nl': 'Gegevensselectie met algoritmes voor vervallen van functies met behulp van een geschatte doelzijde', 'hr': 'Izabranje podataka sa algoritmima za propuštanje funkcije koristeći prilagođenu ciljnu stranu', 'da': 'Datavalg med algoritmer for funktionsdekage ved hjælp af en omtrentlig målside', 'bg': 'Избор на данни с алгоритми за отслабване на функцията с използване на приблизителна целева страна', 'de': 'Datenauswahl mit Feature Decay Algorithmen unter Verwendung einer ungefähren Zielseite', 'fa': 'انتخاب داده\u200cها با الگوریتم\u200cهای کاهش ویژه استفاده از طرف هدف نزدیک شده', 'ko': '목표 측과 비슷한 특징 감쇠 알고리즘을 사용하여 데이터 선택을 진행하다', 'id': 'Pemilihan Data dengan Algoritma Penghancuran Feature Menggunakan Sisi Sasaran Dikira-kira', 'tr': 'Möhüm Saýlaw Taýýarlyk Algorizmleri', 'sw': 'Uchaguzi wa data na Algorithi za Tayari kwa kutumia upande wa Target', 'af': 'Data Keuse', 'sq': 'Zgjidhja e të dhënave me algoritmet e shkatërrimit të funksionimit duke përdorur një an ë të afërt të objektivit', 'am': 'የዳታ ምርጫዎች', 'az': 'Q톛rql톛ndiril톛n M톛tn 쿮laq톛sini istifad톛 ed톛n M톛lumat Se칞imi', 'hy': 'Տվյալների ընտրությունը առանձնահատկությունների քայքայման ալգորիթմներով՝ օգտագործելով մոտ նպատակային կողմը', 'bs': 'Izabranje podataka sa algoritmima za deklariranje funkcije koristeći približenu ciljnu stranu', 'ca': "Selecció de dades amb algoritmes de decay de característiques utilitzant un costat d'objectiu aproximat", 'cs': 'Výběr dat s algoritmy úpadku funkcí pomocí přibližené cílové strany', 'et': 'Andmete valimine funktsioonide lagunemise algoritmidega, kasutades ligikaudset sihtkülge', 'fi': 'Tietojen valinta ominaisuuksien rappeutumisalgoritmeilla arvioidun kohdepuolen avulla', 'bn': 'আপ্রাক্সিমেট টার্গেট সাইড ব্যবহার করে বৈশিষ্ট্য ডেসে অ্যালগরিদম ব্যবহার করে তথ্য নির্বাচন', 'jv': 'Algorithm', 'sk': 'Izbira podatkov z algoritmi za propad funkcij z uporabo približene ciljne strani', 'he': 'בוחר נתונים עם אלגוריתמים של פיצוץ משתמשים בצד מטרה מתקרב', 'ha': '@ action', 'bo': 'ངོ་བོའི་ཆེ་ཆུང་ལྡན་སྐྱེལ་གྱི་སྒྲིག་ཆ་སྤྱད་ནས་ཉེར་སྤྱོད་བྱས་པའི་དམིགས་ཡུལ་ཟུར་བ'}
{'en': 'Data selection techniques applied to neural machine translation (NMT) aim to increase the performance of a  model  by retrieving a subset of sentences for use as training data. One of the possible data selection techniques are  transductive learning methods , which select the data based on the test set, i.e. the document to be translated. A limitation of these methods to date is that using the source-side test set does not by itself guarantee that sentences are selected with correct translations, or translations that are suitable given the test-set domain. Some  corpora , such as subtitle corpora, may contain parallel sentences with inaccurate translations caused by  localization  or length restrictions. In order to try to fix this problem, in this paper we propose to use an approximated target-side in addition to the source-side when selecting suitable sentence-pairs for training a model. This approximated target-side is built by pre-translating the source-side. In this work, we explore the performance of this general idea for one specific data selection approach called Feature Decay Algorithms (FDA). We train German-English NMT models on data selected by using the test set (source), the approximated target side, and a mixture of both. Our findings reveal that  models  built using a combination of outputs of  FDA  (using the  test set  and an approximated target side) perform better than those solely using the  test set .', 'ar': 'تهدف تقنيات اختيار البيانات المطبقة على الترجمة الآلية العصبية (NMT) إلى زيادة أداء النموذج عن طريق استرداد مجموعة فرعية من الجمل لاستخدامها كبيانات تدريب. إحدى تقنيات اختيار البيانات الممكنة هي طرق التعلم التحويلية ، والتي تحدد البيانات بناءً على مجموعة الاختبار ، أي المستند المراد ترجمته. يتمثل أحد قيود هذه الأساليب حتى الآن في أن استخدام مجموعة الاختبار من جانب المصدر لا يضمن في حد ذاته أن يتم اختيار الجمل بترجمات صحيحة ، أو ترجمات مناسبة بالنظر إلى مجال مجموعة الاختبار. قد تحتوي بعض المجاميع ، مثل هيئة الترجمة ، على جمل متوازية مع ترجمات غير دقيقة ناتجة عن قيود الترجمة أو الطول. لمحاولة حل هذه المشكلة ، نقترح في هذه الورقة استخدام جانب مستهدف تقريبي بالإضافة إلى جانب المصدر عند اختيار أزواج جمل مناسبة لتدريب نموذج. تم بناء هذا الجانب المستهدف التقريبي عن طريق الترجمة المسبقة للجانب المصدر. في هذا العمل ، نستكشف أداء هذه الفكرة العامة لنهج واحد محدد لاختيار البيانات يسمى خوارزميات تسوس الميزات (FDA). نقوم بتدريب نماذج NMT الألمانية-الإنجليزية على البيانات المحددة باستخدام مجموعة الاختبار (المصدر) والجانب الهدف التقريبي ومزيج من الاثنين. تكشف النتائج التي توصلنا إليها أن النماذج التي تم إنشاؤها باستخدام مجموعة من مخرجات إدارة الغذاء والدواء (باستخدام مجموعة الاختبار والجانب المستهدف التقريبي) تعمل بشكل أفضل من النماذج التي تستخدم مجموعة الاختبار فقط. حصلنا على تحسن معتد به إحصائيًا بأكثر من 1.5\nيشير BLEU إلى نموذج تم تدريبه باستخدام جميع البيانات ، وأكثر من 0.5 نقطة BLEU على خط أساس قوي لـ FDA يستخدم المعلومات من جانب المصدر فقط.', 'ja': '神経機械翻訳（ ＮＭＴ ）に適用されるデータ選択技術は、訓練データとして使用するための文のサブセットを取り出すことによって、モデルのパフォーマンスを向上させることを目的とする。 可能なデータ選択テクニックの1つは、試験セット、すなわち翻訳されるドキュメントに基づいてデータを選択する変換学習方法である。 これらの方法の現在までの制限は、ソース側のテストセットを使用すること自体が、正しい翻訳、またはテストセットドメインが与えられた場合に適切な翻訳で文が選択されることを保証しないことである。 字幕コーポラなど、一部のコーポラには、ローカライズや長さ制限によって生じる不正確な翻訳を伴う並行文が含まれている場合があります。 この問題を解決するために、モデルのトレーニングに適した文のペアを選択する際には、ソースサイドに加えて近似ターゲットサイドを使用することを提案します。 この近似ターゲット側は、ソース側を事前に翻訳することによって構築されます。 この研究では、Feature Decay Algorithms （ FDA ）と呼ばれる特定のデータ選択アプローチに対するこの一般的なアイデアのパフォーマンスを探ります。 ドイツとイギリスのNMTモデルは、試験器（ソース）、近似ターゲット側、および両方の混合物を使用して選択されたデータをトレーニングします。 我々の知見では、FDAの出力（試験器と近似ターゲット側を使用）の組み合わせを使用して構築されたモデルは、試験器のみを使用したモデルよりも優れたパフォーマンスを発揮することが明らかになっています。 1.5を超える統計的に有意な改善を得る\nBLEUは、すべてのデータを使用してトレーニングされたモデルを指し、ソース側の情報のみを使用する強力なFDAベースラインを使用して0.5以上のBLEUポイントを指します。', 'fr': "Les techniques de sélection de données appliquées à la traduction automatique neuronale (NMT) visent à augmenter les performances d'un modèle en récupérant un sous-ensemble de phrases destinées à être utilisées comme données d'entraînement. L'une des techniques de sélection de données possibles est les méthodes d'apprentissage par transducteur, qui sélectionnent les données en fonction de l'ensemble de test, c'est-à-dire du document à traduire. L'une des limites de ces méthodes à ce jour est que l'utilisation de l'ensemble de tests côté source ne garantit pas en soi que les phrases sont sélectionnées avec des traductions correctes ou des traductions adaptées au domaine de l'ensemble de tests. Certains corpus, tels que les corpus de sous-titres, peuvent contenir des phrases parallèles avec des traductions inexactes en raison de restrictions de localisation ou de longueur. Afin de tenter de résoudre ce problème, nous proposons dans cet article d'utiliser un côté cible approximatif en plus du côté source lors de la sélection de paires de phrases appropriées pour la formation d'un modèle. Ce côté cible approximatif est construit en pré-traduisant le côté source. Dans ce travail, nous explorons la performance de cette idée générale pour une approche spécifique de sélection de données appelée Feature Decay Algorithms (FDA). Nous entraînons des modèles NMT allemand-anglais sur des données sélectionnées à l'aide de l'ensemble de tests (source), du côté cible approximatif et d'un mélange des deux. Nos résultats révèlent que les modèles construits à l'aide d'une combinaison de sorties de la FDA (utilisant l'ensemble de test et un côté cible approximatif) sont plus performants que ceux utilisant uniquement le jeu de test. Nous obtenons une amélioration statistiquement significative de plus de 1,5\nL'UEBL pointe un modèle formé avec toutes les données, et plus de 0,5 point BLEU sur une base de référence solide de la FDA qui utilise uniquement des informations côté source.", 'pt': 'As técnicas de seleção de dados aplicadas à tradução automática neural (NMT) visam aumentar o desempenho de um modelo recuperando um subconjunto de sentenças para uso como dados de treinamento. Uma das possíveis técnicas de seleção de dados são os métodos de aprendizado transdutivo, que selecionam os dados com base no conjunto de teste, ou seja, o documento a ser traduzido. Uma limitação desses métodos até o momento é que o uso do conjunto de teste do lado da fonte não garante por si só que as frases sejam selecionadas com traduções corretas ou traduções adequadas para o domínio do conjunto de teste. Alguns corpora, como corpora de legendas, podem conter frases paralelas com traduções imprecisas causadas por restrições de localização ou comprimento. Para tentar corrigir esse problema, neste artigo propomos usar um lado alvo aproximado além do lado fonte ao selecionar pares de sentenças adequados para treinar um modelo. Esse lado de destino aproximado é construído pela pré-tradução do lado de origem. Neste trabalho, exploramos o desempenho desta ideia geral para uma abordagem específica de seleção de dados chamada Feature Decay Algorithms (FDA). Treinamos modelos NMT alemão-inglês em dados selecionados usando o conjunto de teste (fonte), o lado alvo aproximado e uma mistura de ambos. Nossas descobertas revelam que os modelos construídos usando uma combinação de saídas do FDA (usando o conjunto de teste e um lado alvo aproximado) têm um desempenho melhor do que aqueles que usam apenas o conjunto de teste. Obtemos uma melhora estatisticamente significativa de mais de 1,5\nPontos BLEU sobre um modelo treinado com todos os dados e mais de 0,5 pontos BLEU sobre uma linha de base forte da FDA que usa apenas informações do lado da fonte.', 'es': 'Las técnicas de selección de datos aplicadas a la traducción automática neuronal (NMT) tienen como objetivo aumentar el rendimiento de un modelo mediante la recuperación de un subconjunto de frases para su uso como datos de entrenamiento. Una de las posibles técnicas de selección de datos son los métodos de aprendizaje transductivo, que seleccionan los datos en función del conjunto de pruebas, es decir, el documento que se va a traducir. Una limitación de estos métodos hasta la fecha es que el uso del conjunto de pruebas del lado fuente no garantiza por sí solo que las oraciones se seleccionen con traducciones correctas o traducciones que sean adecuadas dado el dominio del conjunto de pruebas. Algunos corpus, como los corpus de subtítulos, pueden contener oraciones paralelas con traducciones inexactas causadas por restricciones de localización o longitud. Para tratar de solucionar este problema, en este artículo proponemos utilizar un lado objetivo aproximado además del lado fuente al seleccionar pares de frases adecuados para entrenar un modelo. Este lado de destino aproximado se crea mediante la traducción previa del lado de origen. En este trabajo, exploramos el rendimiento de esta idea general para un enfoque específico de selección de datos llamado Feature Decay Algorithms (FDA). Entrenamos modelos NMT alemán-inglés con datos seleccionados mediante el uso del conjunto de pruebas (fuente), el lado objetivo aproximado y una combinación de ambos. Nuestros hallazgos revelan que los modelos fabricados con una combinación de resultados de la FDA (que utilizan el conjunto de pruebas y un lado objetivo aproximado) funcionan mejor que los que solo utilizan el conjunto de pruebas. Obtenemos una mejora estadísticamente significativa de más de 1.5\nBLEU señala un modelo entrenado con todos los datos, y más de 0.5 puntos BLEU por encima de una sólida base de referencia de la FDA que solo utiliza información de origen.', 'zh': '应用神经机器翻译(NMT)数据选择术,以检句集用训练数,以崇模形。 其一可数据选择术者,转导学术也,以测试集(译者文档)择数也。 迄今为止此一局限性,用源代码端试集,不能保句选正译,或给定试集域译为宜。 其语料库(如副标题语料库)或平行句,译不正者,本地化长限之所致也。 吾请择其句对以训模形,自源端之外,犹用近端。 此近向端因预转源端所构也。 于此之中,讨论特征衰算法(FDA)特定数择法之常心。 以试集(源)、近侧及两者混合之数以练德语-英语 NMT 模。 臣等考结果表明,用FDA输组(用测试集近方)比仅用测试集。 我获过1.5之计显改善\nBLEU过用诸数,过用源端息者FDA基线过0.5 BLEU分。', 'ru': 'Методы отбора данных, применяемые для нейронного машинного перевода (НМП), направлены на повышение производительности модели путем извлечения подмножества предложений для использования в качестве обучающих данных. Одним из возможных методов выбора данных являются трансдуктивные методы обучения, которые выбирают данные на основе тестового набора, то есть документа, подлежащего переводу. Ограничением этих методов на сегодняшний день является то, что использование исходного тестового набора само по себе не гарантирует, что предложения выбираются с правильными переводами или переводами, которые подходят для данного домена тестового набора. Некоторые корпорации, такие как корпорации субтитров, могут содержать параллельные предложения с неточными переводами, вызванными локализацией или ограничениями по объему. Чтобы попытаться решить эту проблему, в данной работе мы предлагаем использовать приближенную сторону цели в дополнение к стороне источника при выборе подходящих пар предложений для обучения модели. Эта аппроксимированная целевая сторона строится путем предварительного переноса исходной стороны. В этой работе мы исследуем эффективность этой общей идеи для одного конкретного подхода к выбору данных, называемого алгоритмами затухания признаков (FDA). Мы обучаем немецко-английские модели NMT на данных, выбранных с использованием тестового набора (источника), приближенной целевой стороны и смеси обоих. Наши результаты показывают, что модели, построенные с использованием комбинации результатов FDA (с использованием тестового набора и аппроксимированной целевой стороны), работают лучше, чем модели, построенные исключительно с использованием тестового набора. Получаем статистически значимое улучшение более чем на 1,5\nBLEU указывает на модель, обученную всем данным, и более 0,5 BLEU баллов над сильной базовой линией FDA, которая использует только информацию на стороне источника.', 'hi': 'न्यूरल मशीन अनुवाद (एनएमटी) पर लागू डेटा चयन तकनीकों का उद्देश्य प्रशिक्षण डेटा के रूप में उपयोग के लिए वाक्यों के सबसेट को पुनः प्राप्त करके एक मॉडल के प्रदर्शन को बढ़ाना है। संभावित डेटा चयन तकनीकों में से एक ट्रांसडक्टिव लर्निंग विधियां हैं, जो परीक्षण सेट के आधार पर डेटा का चयन करती हैं, यानी अनुवाद किए जाने वाले दस्तावेज़। आज तक इन विधियों की एक सीमा यह है कि स्रोत-साइड परीक्षण सेट का उपयोग करना अपने आप में यह गारंटी नहीं देता है कि वाक्यों को सही अनुवाद, या अनुवाद के साथ चुना गया है जो परीक्षण-सेट डोमेन को देखते हुए उपयुक्त हैं। कुछ कॉर्पोरेट, जैसे कि उपशीर्षक निगम, में स्थानीयकरण या लंबाई प्रतिबंधों के कारण गलत अनुवाद के साथ समानांतर वाक्य हो सकते हैं। इस समस्या को ठीक करने की कोशिश करने के लिए, इस पेपर में हम एक मॉडल के प्रशिक्षण के लिए उपयुक्त वाक्य-जोड़े का चयन करते समय स्रोत-पक्ष के अलावा एक अनुमानित लक्ष्य-पक्ष का उपयोग करने का प्रस्ताव करते हैं। यह अनुमानित लक्ष्य-पक्ष स्रोत-पक्ष का पूर्व-अनुवाद करके बनाया गया है। इस काम में, हम एक विशिष्ट डेटा चयन दृष्टिकोण के लिए इस सामान्य विचार के प्रदर्शन का पता लगाते हैं जिसे फीचर क्षय एल्गोरिदम (एफडीए) कहा जाता है। हम परीक्षण सेट (स्रोत), अनुमानित लक्ष्य पक्ष, और दोनों के मिश्रण का उपयोग करके चयनित डेटा पर जर्मन-अंग्रेजी एनएमटी मॉडल को प्रशिक्षित करते हैं। हमारे निष्कर्षों से पता चलता है कि एफडीए के आउटपुट के संयोजन का उपयोग करके बनाए गए मॉडल (परीक्षण सेट और अनुमानित लक्ष्य पक्ष का उपयोग करके) पूरी तरह से परीक्षण सेट का उपयोग करने वालों की तुलना में बेहतर प्रदर्शन करते हैं। हम 1.5 से अधिक का सांख्यिकीय रूप से महत्वपूर्ण सुधार प्राप्त करते हैं\nBLEU सभी डेटा के साथ प्रशिक्षित एक मॉडल पर इंगित करता है, और एक मजबूत एफडीए बेसलाइन पर 0.5 BLEU से अधिक अंक जो केवल स्रोत-साइड जानकारी का उपयोग करता है।', 'ga': 'Tá sé mar aidhm ag teicníochtaí roghnaithe sonraí a chuirtear i bhfeidhm ar néaraistriúchán meaisín (NMT) feidhmíocht samhla a mhéadú trí fho-thacar abairtí a aisghabháil le húsáid mar shonraí oiliúna. Ceann de na teicníochtaí roghnaithe sonraí a d’fhéadfadh a bheith ann is ea modhanna foghlama tras-seolta, a roghnaíonn na sonraí bunaithe ar an tsraith tástála, i.e. an doiciméad atá le haistriú. Srian leis na modhanna seo go dtí seo is ea nach ráthaítear trí úsáid a bhaint as an tacar tástála ar thaobh na foinse ann féin go roghnófar abairtí le haistriúcháin chearta, nó le haistriúcháin atá oiriúnach i bhfianaise na bhfearann tástála. D’fhéadfadh abairtí comhthreomhara le haistriúcháin mhíchruinne de bharr logánaithe nó srianta faid a bheith i gcorpora áirithe, ar nós corpora fotheideal. Chun iarracht a dhéanamh an fhadhb seo a réiteach, tá sé beartaithe againn sa pháipéar seo neas-sprioc a úsáid chomh maith leis an taobh foinse agus péire abairtí oiriúnacha á roghnú chun samhail a oiliúint. Tógtar an taobh sprice gar seo trí thaobh na foinse a aistriú roimh ré. San obair seo, déanaimid iniúchadh ar fheidhmíocht an smaoineamh ghinearálta seo maidir le cur chuige roghnaithe sonraí ar leith ar a dtugtar Algartam Meath Gnéis (FDA). Cuirimid oiliúint ar mhúnlaí NMT Gearmáinis-Béarla ar shonraí a roghnaítear trí úsáid a bhaint as an tacar tástála (foinse), an taobh sprice gar, agus meascán den dá cheann. Léiríonn ár dtorthaí go n-éiríonn níos fearr le samhlacha a tógadh ag baint úsáide as teaglaim aschuir FDA (ag baint úsáide as an tacar tástála agus as an taobh sprice) níos fearr ná iad siúd a úsáideann an tacar tástála amháin. Faighimid feabhas suntasach go staitistiúil de níos mó ná 1.5\nPointí BLEU thar mhúnla atá oilte leis na sonraí go léir, agus níos mó ná 0.5 pointe BLEU thar bhunlíne láidir FDA a úsáideann faisnéis taobh foinse amháin.', 'el': 'Οι τεχνικές επιλογής δεδομένων που εφαρμόζονται στη νευρωνική μηχανική μετάφραση (NMT) στοχεύουν στην αύξηση της απόδοσης ενός μοντέλου ανακτώντας ένα υποσύνολο προτάσεων για χρήση ως δεδομένα κατάρτισης. Μια από τις πιθανές τεχνικές επιλογής δεδομένων είναι οι μέθοδοι μεταγωγικής μάθησης, οι οποίες επιλέγουν τα δεδομένα με βάση το σύνολο δοκιμών, δηλαδή το έγγραφο που πρόκειται να μεταφραστεί. Ένας περιορισμός αυτών των μεθόδων μέχρι σήμερα είναι ότι η χρήση του συνόλου δοκιμών από την πλευρά της πηγής δεν εγγυάται από μόνη της ότι οι προτάσεις επιλέγονται με σωστές μεταφράσεις, ή μεταφράσεις που είναι κατάλληλες δεδομένης του τομέα του σετ δοκιμών. Ορισμένα σώματα, όπως σώματα υποτίτλων, μπορεί να περιέχουν παράλληλες προτάσεις με ανακριβείς μεταφράσεις που προκαλούνται από περιορισμούς εντοπισμού ή μήκους. Για να προσπαθήσουμε να διορθώσουμε αυτό το πρόβλημα, στην παρούσα εργασία προτείνουμε να χρησιμοποιήσουμε μια κατά προσέγγιση πλευρά στόχου εκτός από την πλευρά προέλευσης κατά την επιλογή κατάλληλων ζευγαριών προτάσεων για την εκπαίδευση ενός μοντέλου. Αυτή η κατά προσέγγιση πλευρά του στόχου δημιουργείται με την προ-μετάφραση της πλευράς προέλευσης. Σε αυτή την εργασία, εξερευνούμε την απόδοση αυτής της γενικής ιδέας για μια συγκεκριμένη προσέγγιση επιλογής δεδομένων που ονομάζεται Αλγόριθμοι Decay Feature (FDA). Εκπαιδεύουμε γερμανικά-αγγλικά μοντέλα σε δεδομένα που επιλέγονται χρησιμοποιώντας το σύνολο δοκιμής (πηγή), την κατά προσέγγιση πλευρά στόχου και ένα μείγμα και των δύο. Τα ευρήματά μας αποκαλύπτουν ότι τα μοντέλα που κατασκευάζονται χρησιμοποιώντας συνδυασμό εξόδων του FDA (χρησιμοποιώντας το σετ δοκιμής και μια κατά προσέγγιση πλευρά στόχου) αποδίδουν καλύτερα από εκείνα που χρησιμοποιούν μόνο το σετ δοκιμής. Λαμβάνουμε μια στατιστικά σημαντική βελτίωση πάνω από 1.5\nΤο BLEU δείχνει πάνω από ένα μοντέλο εκπαιδευμένο με όλα τα δεδομένα και περισσότερα από 0.5 σημεία πάνω από μια ισχυρή βάση FDA που χρησιμοποιεί μόνο πληροφορίες από την πλευρά της πηγής.', 'kk': 'Невралдық компьютердің аудармасына (NMT) қолданылатын деректерді таңдау техникалары үшін үлгісін көтеру үшін мәліметтер үшін қолдану үшін үлгісін көтеру үшін. Мүмкін деректерді таңдау техникаларының бірі - сынақтар жиынына негізделген деректерді таңдау әдістері, мысалы, аударылатын құжатты. Қазіргі әдістердің шегі - көз жағындағы сынақ жиынын қолдану сөздерді дұрыс аудармалармен таңдау немесе сынақтау жиынын доменге келтірілген аудармалармен таңдау мүмкін емес. Кейбір корпора, мысалы субтитр корпора, жергілікті не ұзындығын шектеу үшін дұрыс аударылмаған параллель сөздер болуы мүмкін. Бұл мәселеді түзету үшін, бұл қағазда үлгісін оқыту үшін керек сөйлемелерді таңдау үшін көзінің қосымша мақсатты жағын қолдануға болады. Бұл мақсат бетін алдын- аударып құрылады. Бұл жұмыстың жалпы идеясын таңдау арқылы "Feature Decay Algorithms" (FDA) деп аталатын деректерді таңдау арқылы зерттейміз. Біз неміс- ағылшын NMT үлгілерін сынақтар (көзі), мақсатты жағынан, екеуінің арасында таңдалған деректер үшін оқыдық. Біздің іздегеніміз, FDA- ның (сынақтар және мақсатты жағдайындағы) шығыс сәйкестігін қолдану үлгілері тек сынақтар жиынына қолданып жатқандардан жақсы жұмыс істейді. Біз статистикалық түрде 1,5 ден артық\nБЛЕС барлық деректермен оқылған үлгі арқылы, 0,5 БЛЕС бағытты FDA негізгі мәліметті тек көз мәліметті пайдалану үшін бағытталған.', 'mk': 'Техниките за селекција на податоци применети на невралниот машински превод (НМТ) имаат за цел зголемување на резултатите на моделот со собирање на подгрупа реченици за употреба како податоци за обука. Една од можните техники за селекција на податоци се трансдуктивните методи на учење, кои ги избираат податоците базирани на тестот, т.е. документот кој треба да се преведе. Ограничувањето на овие методи до денес е дека употребата на сетот на тестот од страната на изворот самиот не гарантира дека речениците се избрани со правилни преводи, или преводи кои се соодветни со оглед на доменот на сетот на тестот. Некои корпора, како што е субтитулот корпора, може да содржат паралелни реченици со неправилни преводи предизвикани од локализација или ограничувања на должината. Со цел да се обидеме да го поправиме овој проблем, во оваа хартија предлагаме да се користи приближна метна страна, покрај изворовата страна, кога ќе се изберат соодветни парови реченици за обука на модел. Оваа приближна страна на метата е изградена со преведување на изворот. Во оваа работа, ја истражуваме изведбата на оваа генерална идеја за еден специфичен пристап за селекција на податоци наречен Алгоритми за природно дефинирање (FDA). We train German-English NMT models on data selected by using the test set (source), the approximated target side, and a mixture of both.  Нашите откритија откриваат дека моделите изградени користејќи комбинација на излези од ФДА (користејќи го тестот и приближната целна страна) се подобри од оние кои само го користат тестот. Добиваме статистички значително подобрување од повеќе од 1,5\nБЛЕУ посочува врз моделот обучен со сите податоци, и повеќе од 0,5 БЛЕУ посочува врз силната основа на ФДА која користи само информации од страната на изворот.', 'it': "Le tecniche di selezione dei dati applicate alla traduzione automatica neurale (NMT) mirano ad aumentare le prestazioni di un modello recuperando un sottoinsieme di frasi da utilizzare come dati di allenamento. Una delle possibili tecniche di selezione dei dati sono i metodi di apprendimento trasduttore, che selezionano i dati in base al set di test, cioè il documento da tradurre. Una limitazione di questi metodi fino ad oggi è che l'utilizzo del set di test lato sorgente non garantisce di per sé che le frasi sono selezionate con traduzioni corrette, o traduzioni che sono adatte dato il dominio del set di test. Alcuni corpora, come i corpora dei sottotitoli, possono contenere frasi parallele con traduzioni imprecise causate da restrizioni di localizzazione o lunghezza. Per cercare di risolvere questo problema, in questo articolo proponiamo di utilizzare un lato target approssimativo oltre al lato sorgente quando si seleziona coppie di frasi adatte per formare un modello. Questo lato obiettivo approssimativo è costruito pre-traducendo il lato sorgente. In questo lavoro, esploriamo le prestazioni di questa idea generale per un approccio specifico di selezione dei dati chiamato Feature Decay Algorithms (FDA). Formiamo modelli NMT tedesco-inglese sui dati selezionati utilizzando il set di test (fonte), il lato obiettivo approssimato e una miscela di entrambi. I nostri risultati rivelano che i modelli costruiti utilizzando una combinazione di output della FDA (utilizzando il set di test e un lato obiettivo approssimato) funzionano meglio di quelli che utilizzano esclusivamente il set di test. Otteniamo un miglioramento statisticamente significativo di oltre 1,5\nPunti BLEU su un modello addestrato con tutti i dati e più di 0,5 punti BLEU su una base base FDA forte che utilizza solo le informazioni sul lato sorgente.", 'ka': 'მონაცემების ამორჩევის ტექნოგიები, რომლებიც ნეიროლური მანქანის გაგრძელებისთვის (NMT) მიზეზიან, რომ მოდელის გამოყენებას უფრო მეტივად გავაკეთოთ, რომლებიც გამო ერთი შესაძლებელი მონაცემების მონიშნული ტექნოგიები არის ტრანექტური სწავლების მეტოვები, რომელიც მონიშნეთ მონაცემები ტესტის სეტიდან, მაგალითად, დოკუმენტის ამ მეტოვების დასაზღვრება არის, რომ გამოყენება მხოლოდ მხარეს ტესტის გამოყენება თავიდან არ დარანტირება, რომ სიტყვები მონიშნულია მარტივი თავსწორებით, ან თავსწორები, რომლებიც შესა ზოგიერთი კოპორა, როგორც სტატილის კოპორა, შეიძლება დავყენება პარალელური სიტყვები, რომელიც ლოკალიზაცია ან სიგრძნობის განზომილებები გამოიყენებული ამ პრობლემას შესაძლებელად გამოყენება, ჩვენ მინდომებით მოდელს შესწავლობისთვის შესაძლებელი მსოფლიო მხარეს დამატებით გამოყენება. ეს მისამართლური მხარეს წინ შექმნა მხარეს მისამართლური მხარეს. ამ სამუშაოში, ჩვენ განვიწყებთ ამ საერთო იდეაზე ერთი განსაკუთრებული მონაცემების მონიშვნის გავაკეთებას, რომელიც ფაქტიური გადასვლის ალგორიტემი (FDA). ჩვენ გერმანური-ანგლისური NMT მოდელების მონაცემებით გამოყენებული ტესტის სეტის გამოყენებით, მისაღების მისაღები და ორივეს მისაღები. ჩვენი მონაცემები აღმოჩნდა, რომ მოდელები, რომლებიც FDA-ის გამოყენებული გამოყენებული გამოყენება (ტესტის სეტის გამოყენება და მიზემობული მიზემობის მხარეს) უკეთესი გამოყენებ ჩვენ მივიღეთ სტატისტიკურად მნიშვნელოვანი 1.5-ზე მეტი შექმნა\nBLEU უნდა ყველა მონაცემების მოდელის შესახებ და უფრო 0,5 BLEU უნდა უფრო ძალიან FDA ფესტური ხაზი, რომელიც მხოლოდ გამოყენებს მხოლოდ ფესტური ინფორმაცი', 'hu': 'A neurális gépi fordításra (NMT) alkalmazott adatválasztási technikák célja, hogy növeljék a modell teljesítményét azáltal, hogy a mondatok egy részhalmazát képzési adatként használják. Az egyik lehetséges adatválasztási technika a transzduktív tanulási módszerek, amelyek a tesztkészlet, azaz a fordítandó dokumentum alapján választják ki az adatokat. Ezen módszerek eddigi korlátozása az, hogy a forrás oldali tesztkészlet használata önmagában nem garantálja, hogy a mondatok helyes fordításokkal kerülnek kiválasztásra, illetve a tesztkészlet tartományának megfelelő fordításokkal kerülnek kiválasztásra. Egyes korpuszok, mint például a feliratkorpuszok, tartalmazhatnak párhuzamos mondatokat, pontatlan fordításokkal, amelyeket lokalizációs vagy hosszúsági korlátozások okoznak. A probléma megoldásának érdekében ebben a tanulmányban egy hozzávetőleges céloldal használatát javasoljuk a forrás oldalon kívül, amikor megfelelő mondatpárokat választunk ki egy modell kiképzéséhez. Ezt a hozzávetőleges céloldalt a forrás oldalának előfordításával építették. Ebben a munkában megvizsgáljuk ennek az általános elképzelésnek a teljesítményét egy specifikus adatválasztási megközelítésre vonatkozóan, a Feature Decay Algorithms (FDA). A német-angol NMT modelleket a tesztkészlet (forrás), a hozzávetőleges céloldal és mindkettő keveréke alapján kiválasztott adatokra képezzük. Eredményeink azt mutatják, hogy az FDA kimeneteinek kombinációjával készült modellek (a tesztkészlet és a hozzávetőleges céloldal használatával) jobban teljesítenek, mint azok, amelyek kizárólag a tesztkészletet használják. Statisztikailag szignifikáns javulást érünk el, több mint 1,5\nAz összes adatot tartalmazó BLEU-modell fölé mutat, és több mint 0,5 BLEU-pont egy erős FDA-kiindulási értéknél, amely csak a forrás oldali információkat használja.', 'mn': 'Өгөгдлийн сонголтын техникууд, мэдрэлийн машины хөгжүүлэлт (NMT) дээр хэрэглэгдсэн загварын үйлдлийг нэмэгдүүлэх зорилго нь дасгал өгөгдлийн хэлбэрээр хэрэглэх өгөгдлийг авч ирсэн. Магадгүй өгөгдлийн сонголтын техникуудын нэг нь шинжлэх ухааны арга юм. Энэ нь шинжлэх ухааны багтаах өгөгдлийг сонгох, т.е. Өнөөдөр байгаа энэ аргын хязгаар нь эх үүсвэр талын шалгалтыг ашиглах нь өгүүлбэрүүдийг зөв хэлбэрээр сонгогдохыг баталагдахгүй, эсвэл шалгалтын хэлбэрээр зөв хэлбэрээр сонгогдохыг баталагдахгүй. Зарим корпора, жишээлбэр корпора гэх мэт, орон нутгийн болон урт хязгаарлалтын шаардлагатай зөв хэлбэрээр параллел өгүүлбэртэй байж болно. Энэ асуудлыг шийдэхийн тулд, энэ цаасан дээр бид загварын сургалтын тулд зөв өгүүлбөр хоёрыг сонгоход ойролцоогоор загварын талыг ашиглах гэсэн санал байна. Энэ ойролцоогоор зорилготой тал эх үүсвэрийн талыг урьд орлуулж байдаг. Энэ ажил дээр бид Feature Decay Algorithms (FDA) гэдэг тодорхой өгөгдлийн сонголтын аргын ерөнхий санааны үйл ажиллагааг судалж байна. Бид Герман-Англи хэлний NMT загваруудыг шалгалтын суурь (эх үүсвэр), ойролцоогоор зорилготой тал, хоёуланг хоёуланг ашиглан сонгогдсон өгөгдлийн загваруудыг суралцаж Бидний ололтууд нь FDA-ын холбоотой үр дүнг ашиглан бүтээсэн загварууд нь зөвхөн шалгалтын хэлбэрээс илүү сайн хийдэг. Бид 1.5-аас илүү их статистикийн сайжруулалт гаргаж ирсэн.\nБЛЕС бүх өгөгдлийн сургалтын загвар дээр цэглэж байна. 0.5-аас илүү БЛЕС цэг нь зөвхөн эх үүсвэрийн мэдээллийг ашигладаг FDA-ын суурь шугам дээр ашигладаг.', 'lt': 'Data selection techniques applied to neural machine translation (NMT) aim to increase the performance of a model by retrieving a subset of sentences for use as training data.  Vienas i š galimų duomenų atrankos metodų yra transdukciniai mokymosi metodai, kurie atrenka duomenis, pagrįstus bandymų rinkiniu, t. y. verttiną dokumentą. Šių metodų apribojimas iki šiol yra tas, kad naudojant šaltinio bandymų rinkinį savaime neužtikrinama, kad sakiniai būtų pasirinkti tinkamais vertimais arba vertimais, tinkami atsižvelgiant į bandymų rinkinį. Kai kuriose korporose, pvz., subtitle corpora, gali būti lygiagrečių sakinių su netiksliais vertimais, kuriuos sukelia lokalizacija arba ilgio apribojimai. Siekiant išspręsti šią problem ą, šiame dokumente siūlome pasinaudoti suderinta tiksline puse, be šaltinio pusės, pasirinkdami tinkamas sakinių poras mokymui modeliui. Ši apytiksli tikslinė pusė pagaminta iš anksto vertant šaltinį. Šiame darbe nagrinėjame šios bendros idėjos rezultatus, susijusius su konkrečiu duomenų atrankos metodu, vadinamu „Feature Decay Algorithms“ (FDA). Mokome vokiečių ir anglų NMT modelius remiantis duomenimis, atrinktais naudojant bandymų rinkinį (šaltinį), apytikslią tikslinę pusę ir abiejų rūšių mišinį. Mūsų išvados rodo, kad modeliai, sukurti naudojant FDA rezultatų derinį (naudojant bandymų rinkinį ir apytikslią tikslinę pusę), veikia geriau nei modeliai, sukurti naudojant tik bandymų rinkinį. Statistiškai reikšmingai pagerėjo daugiau kaip 1,5\nBLEU nurodo model į, parengtą naudojant visus duomenis, ir daugiau kaip 0,5 BLEU nurodo, palyginti su stipria FDA baze, kurioje naudojama tik šaltinio informacija.', 'pl': 'Techniki selekcji danych stosowane w neuronowym tłumaczeniu maszynowym (NMT) mają na celu zwiększenie wydajności modelu poprzez pobieranie podzbioru zdań do wykorzystania jako danych treningowych. Jedną z możliwych technik selekcji danych są metody uczenia transduktywnego, które dobierają dane na podstawie zestawu testowego, czyli dokumentu do przetłumaczenia. Ograniczeniem dotychczasowych tych metod jest to, że stosowanie zestawu testowego po stronie źródła samo w sobie nie gwarantuje doboru zdań z poprawnymi tłumaczeniami lub tłumaczeniami, które są odpowiednie dla domeny zestawu testowego. Niektóre korpusy, takie jak korpusy napisów, mogą zawierać zdania równoległe z niedokładnymi tłumaczeniami spowodowanymi ograniczeniami lokalizacji lub długości. Aby spróbować rozwiązać ten problem, w niniejszym artykule proponujemy zastosowanie przybliżonej strony docelowej oprócz strony źródłowej przy wyborze odpowiednich par zdań do treningu modelu. Ta przybliżona strona docelowa jest zbudowana poprzez wstępne tłumaczenie strony źródłowej. W niniejszej pracy badamy wydajność tego ogólnego pomysłu dla jednego konkretnego podejścia do selekcji danych o nazwie Feature Decay Algorithms (FDA). Szkolimy niemiecko-angielskie modele NMT na danych wybranych za pomocą zestawu testowego (źródła), przybliżonej strony docelowej oraz mieszanki obu. Nasze ustalenia pokazują, że modele zbudowane przy użyciu kombinacji wyjść FDA (z wykorzystaniem zestawu testowego i przybliżonej strony docelowej) wydają się lepiej niż te wyłącznie wykorzystujące zestaw testowy. Uzyskujemy statystycznie istotną poprawę o ponad 1,5\nBLEU wskazuje na model przeszkolony ze wszystkimi danymi, a ponad 0,5 punkty BLEU nad silną bazą danych FDA, która wykorzystuje tylko informacje ze strony źródła.', 'ms': 'Data selection techniques applied to neural machine translation (NMT) aim to increase the performance of a model by retrieving a subset of sentences for use as training data.  Salah satu teknik pemilihan data yang mungkin adalah kaedah pembelajaran transduktif, yang memilih data berdasarkan set ujian, iaitu dokumen untuk diterjemahkan. Hadangan kaedah ini hingga kini ialah menggunakan set ujian sisi-sumber tidak secara sendiri menjamin bahawa kalimat dipilih dengan terjemahan yang betul, atau terjemahan yang sesuai diberikan domain set-ujian. Beberapa corpora, seperti corpora subtitle, mungkin mengandungi kalimat selari dengan terjemahan yang tidak tepat disebabkan oleh lokasi atau keterangan panjang. Untuk cuba memperbaiki masalah ini, dalam kertas ini kami cadangkan untuk menggunakan sasaran-sisi kira-kira selain sisi-sumber apabila memilih pasangan kalimat yang sesuai untuk melatih model. This approximated target-side is built by pre-translating the source-side.  Dalam kerja ini, kami mengeksplorasi prestasi idea umum ini untuk satu pendekatan pemilihan data spesifik yang dipanggil Algoritma Penghancuran Feature (FDA). Kami melatih model NMT Jerman-Inggeris pada data yang dipilih dengan menggunakan set ujian (sumber), sisi sasaran kira-kira, dan campuran kedua-dua. Penemuan kami mengungkapkan bahawa model yang dibina menggunakan kombinasi output FDA (menggunakan set ujian dan sisi sasaran kira-kira) berjaya lebih baik daripada yang hanya menggunakan set ujian. Kami mendapat peningkatan statistik yang signifikan lebih dari 1.5\nBLEU menunjukkan pada model yang dilatih dengan semua data, dan lebih dari 0.5 poin BLEU di atas dasar FDA yang kuat yang menggunakan maklumat sisi sumber sahaja.', 'ml': 'ഡേറ്റാ തെരഞ്ഞെടുക്കുന്ന സാങ്കേതികവിദ്യ (NMT) പരിശീലനത്തിനായി ഉപയോഗിക്കുന്നതിനായി ഒരു മോഡലിന്റെ പ്രകടനത്തിനുള്ള വാക്കു @ info: status താമസിക്കാനുള്ള ഈ രീതികളുടെ ഒരു പരിധിയെന്തെന്നാല്\u200d സോര്\u200dസ്- side പരീക്ഷണസെറ്റ് ഉപയോഗിച്ച് വാക്കുകള്\u200d ശരിയായ അനുവാദങ്ങളുമായി തിരഞ്ഞെടുക Some corpora, such as subtitle corpora, may contain parallel sentences with inaccurate translations caused by localization or length restrictions.  ഈ പ്രശ്നം ശരിയാക്കാന്\u200d ശ്രമിക്കുവാന്\u200d വേണ്ടി, ഈ പത്രത്തില്\u200d ഒരു മോഡല്\u200d പരിശീലിക്കുമ്പോള്\u200d സോര്\u200dസ്സ്- ഭാഗത്തുള്ള ഒരു ലക്ഷ്യ-ഭാഗത്തിനു  ഈ അടുത്ത ലക്ഷ്യ-ഭാഗത്തിന്റെ അടുത്ത് നിര്\u200dമ്മിക്കപ്പെട്ടിരിക്കുന്നു ഈ ജോലിയില്\u200d നമ്മള്\u200d ഈ പൊതുവായ ആശയത്തിന്റെ പ്രഭാവം പരിശോധിക്കുന്നു. ഫിയ്റ്റര്\u200d ഡീസ് അല്\u200dഗോരിത്മുകള്\u200d എന്ന പേരുള്ള ഒരു  നമ്മള്\u200d പരീക്ഷണസെറ്റ് (സോര്\u200dസ്സ്), അടുത്ത ലക്ഷ്യം ഭാഗത്തും, രണ്ടുപേരുടെയും ഭാഗവും ഉപയോഗിച്ച് തെരഞ്ഞെടുത്ത ഡേറ്റാ മോഡലുകള നമ്മുടെ കണ്ടുപിടികള്\u200d വെളിപ്പെടുത്തുന്നു FDA-ന്റെ ഒരു കൂട്ടിക്കൂട്ടം പുറത്ത് നിര്\u200dമ്മിച്ച മോഡലുകള്\u200d (പരീക്ഷണസെറ്റും അടുത്ത ലക 1.5 കൂടുതല്\u200d പ്രധാനപ്പെട്ട മെച്ചപ്പെടുത്തുന്നത് നമുക്ക് സ്ഥിതികമായി കിട്ടുന്നു.\nഎല്ലാ വിവരങ്ങളുമായി പരിശീലിക്കപ്പെട്ട മോഡലിന്റെ മേല്\u200d BLEU പോയിന്\u200dറുകള്\u200d കാണിക്കുന്നു. പിന്നെ 0. 5 ബിലിയു പോയിന്\u200dറുകള്\u200dക്', 'ro': 'Tehnicile de selecție a datelor aplicate traducerii automate neurale (NMT) vizează creșterea performanței unui model prin recuperarea unui subset de propoziții pentru utilizarea ca date de formare. Una dintre tehnicile posibile de selectare a datelor este metodele de învățare transductivă, care selectează datele pe baza setului de testare, adică documentul care urmează să fie tradus. O limitare a acestor metode până în prezent este că utilizarea setului de testare sursă nu garantează de la sine că propozițiile sunt selectate cu traduceri corecte sau traduceri care sunt adecvate având în vedere domeniul set de test. Unele corpore, cum ar fi corpora subtitrare, pot conține propoziții paralele cu traduceri inexacte cauzate de restricții de localizare sau lungime. Pentru a încerca să rezolvăm această problemă, în această lucrare vă propunem să utilizați o parte țintă aproximativă în plus față de partea sursă atunci când selectați perechile de propoziții potrivite pentru formarea unui model. Această parte țintă aproximativă este construită prin pre-traducerea partea sursă. În această lucrare, explorăm performanța acestei idei generale pentru o abordare specifică de selecție a datelor numită Feature Decay Algorithms (FDA). Instruim modele NMT german-engleză pe datele selectate folosind setul de testare (sursa), partea țintă aproximativă și un amestec al ambelor. Rezultatele noastre arată că modelele construite utilizând o combinație de rezultate ale FDA (utilizând setul de testare și o parte țintă aproximativă) performează mai bine decât cele care utilizează doar setul de testare. Obținem o îmbunătățire semnificativă statistic de peste 1,5\nBLEU puncte peste un model instruit cu toate datele, și mai mult de 0,5 puncte BLEU peste un nivel de referință puternic FDA care utilizează doar informații sursa.', 'so': 'Teqooyinka doorashada ee macluumaadka waxaa lagu codsadaa turjuma maskinada neurada (NMT) in uu kordhiyo muusikada sameynta si uu u soo celiyo koob ka mid ah hadallada lagu isticmaalo sida macluumaadka waxbarashada. Mid ka mid ah takhasuska doorashada macluumaadka waa qaababka waxbarashada, kaas oo ku dooranaya macluumaadka ku saleysan saxda imtixaanka, tusaale ahaan dukumentiga lagu turjumo. Xiriiridda qaababkan ilaa waqtiga la joogo waa in lagu isticmaalayo kooxda imtixaanka dhinaca yurub uusan gooni ahaantiis ku garanayn in looga dooranayo imtixaanka saxda ah, ama turjumaadda ku habboon marka lagu tijaabiyo. Shirkadaha qaarkood, sida shirkadda hoose-shirkadda, waxay ku jiraan fursad lamid ah oo ay ku jiraan turjumaan aan aan sax ahayn oo ay ka sababtay meel-gaarka ah ama xadidaha dhaadheerka. Si aad u baahan karto in aad dhibaatadan u bogsato, warqadan ayaannu ku talo galaynaa inaad isticmaasho dhinaca ku dhow oo ay ku isticmaasho dhinaca aad ku isticmaasho noocyada haboon marka aad doorato noocyada habboon tusaale. Halkaas oo ku dhow dhinaca goalka waxaa lagu dhisaa turjumidda hore. Markaas waxan, waxaynu baaraynaa sameynta fikradan guud ee hal qaab gaar ah oo macluumaad la doorto ee la yidhaahdo Feature Decay Algorithms (FDA). Waxaannu ku tababarinnaa modellada afka Jarmalka-Ingiriiska NMT oo ku saabsan macluumaadka la doortay marka lagu isticmaalo kooxda imtixaanka (sourceed), dhinaca ugu dhow jiilaalka iyo isku xirka labadooda. Shaqooyinkayada waxay muuqanayaan in modellada lagu dhisay isticmaalka soo saarayaasha FDA (isticmaalaya saxda imtixaanka iyo dhinaca ugu dhow jimicsiga) ay sameeyaan si ka wanaagsan kuwa isticmaalaya saxda imtixaanka oo kaliya. Waxaynu helaynaa horumarinta si qiyaas ah oo ka badan 1.5\nBLEU wuxuu ku hagaa model lagu tababariyey dhammaan macluumaad, waxaana ka badan 0.5 BLEU barta ku qoran qoraal xoog leh oo FDA oo isticmaalaya macluumaad dhinaca ah oo keliya.', 'mt': 'It-tekniki tal-għa żla tad-dejta applikati għat-traduzzjoni tal-magni newrali (NMT) għandhom l-għan li jżidu l-prestazzjoni ta’ mudell billi jiksbu sottosett ta’ sentenzi għall-użu bħala dejta ta’ taħriġ. One of the possible data selection techniques are transductive learning methods, which select the data based on the test set, i.e. the document to be translated.  Limitazzjoni ta’ dawn il-metodi s’issa hija li l-użu tas-sett tat-test min-naħa tas-sors waħdu ma jiggarantixxix li s-sentenzi jintgħażlu bi traduzzjonijiet korretti, jew traduzzjonijiet li huma adattati fid-dominju tas-sett tat-test. Xi korpora, bħal corpora subtitle, jista’ jkun fihom sentenzi paralleli bi traduzzjonijiet mhux eżatti kkawżati minn lokalizzazzjoni jew restrizzjonijiet fuq it-tul. Sabiex nippruvaw isolvu din il-problem a, f’dan id-dokument nipproponu li nużaw naħa fil-mira approssimattiva flimkien mal-parti tas-sors meta ningħa żlu pari xierqa ta’ sentenzi għat-taħriġ ta’ mudell. Din in-naħa fil-mira approssimattiva hija mibnija bit-traduzzjoni minn qabel tan-naħa tas-sors. F’dan ix-xogħol, aħna nesploraw il-prestazzjoni ta’ din l-idea ġenerali għal approċċ speċifiku għall-għażla tad-dejta msejjaħ Algoritmi ta’ Tnaqqis tal-Karatteristiċi (FDA). Aħna nħarrġu mudelli NMT Ġermaniż-Ingliż fuq dejta magħżula bl-użu tas-sett tat-test (sors), in-naħa fil-mira approssimattiva, u taħlita tat-tnejn. Is-sejbiet tagħna juru li mudelli mibnija bl-użu ta’ kombinazzjoni ta’ outputs ta’ FDA (bl-użu tas-sett tat-test u naħa fil-mira approssimattiva) iwettqu a ħjar minn dawk li jużaw is-sett tat-test biss. Ikseb titjib statistikament sinifikanti ta’ aktar minn 1.5\nBLEU points over a model trained with all data, and more than 0.5 BLEU points over a strong FDA baseline that uses source-side information only.', 'si': 'දත්ත තෝරාගන්න ප්\u200dරයෝජනය (NMT) පරිවර්තනයට ප්\u200dරයෝජනය කරලා තියෙන්නේ මොඩේල්ගේ වැඩේ වැඩ කරන්න, ප්\u200dරයෝජනය දත්ත විද පුළුවන් දත්ත තෝරාගන්න ප්\u200dරයෝජනයෙන් එකක් තමයි පරීක්ෂණ සූදානයට ආධාරිත දත්ත තෝරාගන්න ප්\u200dරයෝජනය, ඉත මේ විධාන සීමාවක් තියෙන්නේ මුළු පැත්ත පරීක්ෂණය භාවිත කරන්න පුළුවන් පරීක්ෂණය සඳහා වාක්ෂාවක් හරියට පරීක්ෂණය සඳහා තෝ සමහර කාර්පෝරා, සබ්ටිටල් කාර්පෝරා වලින්, සමාන්\u200dය වාක්ය සමහර වෙන්න පුළුවන් පුළුවන් සමාන්\u200dය වාක්ය සම මේ ප්\u200dරශ්නය හදන්න උත්සාහ කරන්න, මේ පත්තරේ අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරන්න ප්\u200dරශ්නයක මේක ගොඩක් ලක්ෂණ පැත්තේ ඉදිරිපත් පැත්තේ ඉදිරිපත් පැත්තෙන් නිර්මාණය කරනවා. මේ වැඩේ අපි මේ සාමාන්\u200dය අදහසක් ගැන ප්\u200dරවෘත්තිය පරීක්ෂණය කරනවා විශේෂ දත්ත තෝරණය (FDA) කියලා කියලා කියලා  අපි ජර්මාන්ස්-ඉංග්\u200dරීසි NMT මොඩේල් එකේ පරීක්ෂණ සෙට් එක්ක භාවිත කරනවා පරීක්ෂණය සඳහා තෝරාගෙන තියෙන්න අපේ හොයාගන්න පෙන්වන්නේ මොඩේල් හදන්නේ FDA ප්\u200dරතිකාරයක් භාවිත කරන්න (පරීක්ෂණ සැට් එක සහ අක්ෂිත පැත්තෙක් භාවිත කරන්න)  අපිට 1.5 වඩා වැඩි සංඛ්\u200dයාත්මක විශේෂයක් ලැබෙනවා\nසියළු දත්ත තියෙන්න ප්\u200dරශ්නයක් ලැබුණු බ්ලූස් ප්\u200dරශ්නයක් ප්\u200dරධානය කරනවා, සහ 0.5 බ්ලූස් ප්\u200dරශ්නයක් වඩා', 'no': 'Tehnikasjonar for utvals av data som er brukte til omsetjinga av neiralmaskin (NMT) mål å auka utviklinga av eit modell ved å henta ein del setningar for bruk som opplæringsdata. Ein av dei moglege datautvalsteknikka er transduktive læringsmetodane, som veljer databaserte på testsettet, t.d. dokumentet som skal omsetjast. Ein avgrensing av desse metodane til dato er at bruk av kjeldesidetesten er ikkje sikker på at setningane er valde med korrige omsetjingar, eller omsetjingar som er passande gjev domenet for testsett. Noen korpora, som undertekstkorpora, kan innehalda parallelle setningar med ugyldig oversettelsar som følgjer av lokalisering eller lengdsavgrensingar. For å prøva å retta dette problemet, i denne papiret foreslår vi å bruka eit omtrent målside i tillegg til kjeldesiden når du velje passande setningpar for å trenja eit modell. Dette omtrent målside er bygd ved å overføra kjeldesiden før omsetjinga. I dette arbeidet utforskar vi utviklinga av denne generelle ideen for ein spesifikk datautval tilnærming kalla «Feature Decay Algorithms» (FDA). Vi treng tysk- engelsk NMT- modeller på data som er valde ved å bruka testsettet (kjelde), omtrent målside og blandet av begge. Finningane våre viser at modeller bygde med ein kombinasjon av utdata av FDA (med testsettet og eit omtrent målside) utfører bedre enn dei som berre brukar testsettet. Vi får ein statistisk betydelig forbedring av mer enn 1,5\nBLEU-punkt over eit modell trent med alle data, og mer enn 0,5 BLEU-punkt over ein sterk FDA-baseline som berre brukar kjeldesideinformasjon.', 'sr': 'Tehnike selekcije podataka primjenjene na prevod neuralne mašine (NMT) ciljeve su povećati provedbu model a prikupljanjem podgrupe rečenica za upotrebu kao podaci obuke. Jedna od mogućih tehnika selekcije podataka su metode prevoditelja učenja, koje odaberu podatke na temelju testa, tj. dokument koji treba prevoditi. ograničenje ovih metoda do sada je da korištenje testa sa izvorske strane samog sebe ne garantuje da se rečenice izaberu sa ispravnim prevodima ili prevodima koje su odgovarajuće s obzirom na domenu testa. Neka korpora, kao što je podtitelna korpora, može sadržati paralelne rečenice sa nepravednom prevodom uzrokovanom lokalizacijom ili ograničenjem dužine. Da bismo pokušali da riješimo ovaj problem, u ovom papiru predlažemo da koristimo približnu ciljnu stranu osim izvorne strane kada biramo odgovarajuće pare rečenica za obuku model a. Ova približna ciljna strana je izgrađena pred prevodom izvora strane. U ovom poslu istražujemo izvršnost ove generalne ideje za jedan specifičan pristup selekcije podataka nazvan Algoritmi za dekoraciju funkcije (FDA). Vježbamo njemačke-engleske NMT modele na podacima odabranim koristeći test set (izvor), približnu ciljnu stranu i mješavinu oboje. Naši nalazi otkrivaju da su modeli izgrađeni koristeći kombinaciju ishoda FDA (koristeći test setu i približnu ciljnu stranu) bolje od onih koji samo koriste test setu. Dobili smo statistički značajno poboljšanje više od 1,5\nBLEU ukazuje na model obučen sa svim podacima, a više od 0,5 BLEU ukazuje na snažnu početnu liniju FDA-a koja koristi samo informacije na izvorskoj strani.', 'sv': 'Dataurvalstekniker som tillämpas på neural maskinöversättning (NMT) syftar till att öka prestandan hos en modell genom att hämta en delmängd meningar för användning som träningsdata. En av de möjliga dataurvalsteknikerna är transduktiva inlärningsmetoder, som väljer data baserat på testuppsättningen, det vill säga det dokument som ska översättas. En begränsning av dessa metoder hittills är att användningen av källsidan testuppsättningen inte i sig garanterar att meningar väljs med korrekta översättningar, eller översättningar som är lämpliga med tanke på testuppsättningens domän. Vissa korpora, till exempel undertextkorpora, kan innehålla parallella meningar med felaktiga översättningar orsakade av lokaliserings- eller längdbegränsningar. För att försöka lösa detta problem föreslår vi i denna uppsats att man använder en ungefärlig målsida utöver källsidan när man väljer lämpliga meningspar för att träna en modell. Denna ungefärliga målsida byggs genom att förhandsöversätta källsidan. I detta arbete undersöker vi prestandan av denna allmänna idé för ett specifikt dataval tillvägagångssätt som kallas Feature Decay Algorithms (FDA). Vi tränar tysk-engelska NMT-modeller på data som valts genom att använda testuppsättningen (källa), den ungefärliga målsidan och en blandning av båda. Våra resultat visar att modeller byggda med en kombination av resultat från FDA (med hjälp av testset och en ungefärlig målsida) presterar bättre än de som enbart använder testset. Vi får en statistiskt signifikant förbättring på mer än 1,5\nBLEU-poäng över en modell som är utbildad med alla data och mer än 0,5 BLEU-poäng över en stark FDA-baslinje som endast använder källinformation.', 'ta': 'புதிய இயந்திரத்தின் மொழிபெயர்ப்பு (NMT) பயன்படுத்தப்பட்ட தகவல் தேர்ந்தெடுப்பு தொகுதி @ info இந்த முறைகளின் வரம்பு என்னவென்றால் மூலத்தின் பக்கம் சோதனை அமைப்பை பயன்படுத்தி சரியான மொழிபெயர்ப்புகளால் தேர்ந்தெடுக்கப்பட்ட வாக்குகள் அல் சில நிறுவனங்கள், உப தலைப்புக்குறியீட்டு போன்ற, இணைய வாக்குகள் உள்ளமைப்பு அல்லது நீளம் கட்டுப்பாடுகள் காரணமாக மொழிபெயர்ப இந்த பிரச்சனையை சரிபார்க்க முயற்சி செய்ய, இந்த தாளில் நாம் மூலத்திற்கு சேர்க்கும் போது ஒரு மாதிரிக்கு பொருத்தமான வாக்கு- ஜோட இந்த சுற்றியமாக இலக்கு- பக்கம் மூலத்தை மொழிமாற்றி முன் உருவாக்கப்பட்டது. இந்த வேலையில், நாம் இந்த பொது யோசனையின் செயல்பாட்டை பார்க்க வேண்டும் ஒரு குறிப்பிட்ட தரவு தேர்வு செயல்பாட்டிற் தேர்ந்தெடுக்கப்பட்ட தரவுகளில் ஜெர்மன்- ஆங்கிலம் NMT மாதிரிகளை நாம் பயிற்சி செய்கிறோம் சோதனைப் அமைப்பு (மூலம், சுக்கி எங்கள் கண்டுபிடிப்புகள் FDA யின் ஒரு சேர்ப்பு வெளியீடுகளை பயன்படுத்தி உருவாக்கப்பட்ட மாதிரிகளை காண்பிக்கிறது (சோதனை அமைப்பை பயன்படுத் We obtain a statistically significant improvement of more than 1.5\nBLEU குறிப்புகள் அனைத்து தரவுகளுடனும் பயிற்சி மாதிரி குறிப்பிட்டுள்ளது, மற்றும் 0. 5 பிலியு குறிப்புகளுக்கு மேலும் அது வல', 'ur': 'نیورل ماشین ترجمہ (NMT) کے لئے استعمال کیا گیا ہے، یعنی ایک موڈل کے فعالیت کو زیادہ کرنا چاہتا ہے کہ اس کے ذریعہ سے کلمات کے سپسٹ کو استعمال کرنے کے لئے استعمال کرے۔ ڈیٹا انتخاب ٹیکنیک میں سے ایک ایسی ہے جو ٹیٹ سٹ پر بنیاد ڈیٹا انتخاب کرتی ہے، یعنی ٹیٹ سٹ پر ڈیٹا انتخاب کرتی ہے۔ یہاں تک پہنچانے کے لئے ان طریقوں کی محدودیت یہ ہے کہ سورس-سائڈ تست سٹ کے استعمال کرنا اپنے آپ کے ساتھ تضمین نہیں کرتا کہ کلمات ٹھیک ترجمہ کے ساتھ انتخاب کیے جائیں، یا ترجمہ جو تست-سٹ ڈومین کے ساتھ مناسب ہیں۔ کچھ کوپرا، جیسے سوٹیٹیل کوپرا، ممکن ہے موقعیت یا طویل محدودیت کے باعث غلط ترجمہ کے مطابق مطابق مطابق عبارت کے ساتھ مطابق عبارت رکھے. اس مسئلہ کو اصلاح کرنے کے لئے، اس کاغذ میں ہم نے ایک مدل کی آموزش کے لئے مناسب جماعت جوڑوں کو انتخاب کرنے کے لئے تقریباً موقع کی طرف سے استعمال کرنے کی پیشنهاد کرتا ہے. یہ تقریباً تقریباً موقع کی طرف سے سورج کی طرف سے پہلے ترجمہ کیا جاتا ہے۔ اس کام میں، ہم نے اس عمومی ایڈیو کی عمدگی کا تحقیق کر لیا ایک خاص ڈیٹ انتخاب طریقہ کے لئے، جس کا نام "Feature Decay Algorithms" (FDA) ہے۔ ہم جرمن-انگلیسی NMT موڈل کو ٹرین کریں جو ٹیسٹ سٹ (سورست) کے مطابق انتخاب کئے گئے ہیں، تقریباً ٹیلٹ سائڈ، اور دونوں کی ایک میکسٹ. ہمارے نتیجے نشان دیتے ہیں کہ مدل بنائے گئے ہیں FDA کے نتیجے کے مطابق (آزمائش مجموعہ اور تقریباً موقع جانب کے مطابق) ان سے بہتر عمل کرتے ہیں جو صرف امتحان مجموعہ کے مطابق استعمال کرتے ہیں. ہم نے 1.5 سے زیادہ زیادہ مقررہ عمدہ تحقیق حاصل کیا ہے\nبلیوس ایک موڈل پر پوینٹ کرتا ہے جو تمام ڈاکٹوں کے ساتھ تعلیم کی جاتی ہے اور 0.5 بلیوس سے زیادہ مضبوط FDA بنسٹلین پر ہے جو صرف سورج جانب معلومات کا استعمال کرتا ہے.', 'uz': "Name @ info Bu yerda maʼlumot chegarasi, manba- side sinov moslamasi yordamida bir so'zlar to ʻgʻri tarjimalar yoki tarjima qiladigan domen bilan moslangan boʻlishi mumkin. @ info Bu muammoga tizimni tizimlashni istaysizki, bu hujjatda modelni o'rganish uchun qisqarli soʻzning chegarasini oʻzgartirishni istaysizmi. @ info: whatsthis Bu ishda, biz bu bir necha maʼlumot tanlash usuli (FDA) nomli darajasini ko'rib chiqaramiz. Biz tashqi sohasi (manba), qisqacha chegara yonida va ikkita bir qanchalik tartibi bilan tanlangan maʼlumot uchun Olmon- Ingliz tili NMT modellarini o'rganamiz. Bizning natijalarimiz faqat sinov moslamadan foydalanadigan modellar FDA birlashtirilgan tugmalar bilan ishlatiladi. Biz 1.5 dan ortiq yaxshi yaxshi o'zlarimiz\nName", 'vi': 'Kỹ thuật tuyển chọn dữ liệu được áp dụng cho dịch chuyển máy thần kinh (NMB) nhằm tăng hiệu quả của một mô hình bằng cách lấy một nhóm câu để sử dụng làm dữ liệu huấn luyện. Một trong những kỹ thuật chọn dữ liệu có thể là các phương pháp học hành, chọn các dữ liệu dựa trên bộ thử, tức là tài liệu cần dịch. Một hạn chế của những phương pháp này cho đến nay là sử dụng bộ bài kiểm tra mặt gốc không tự bảo đảm rằng các câu được chọn với một bản dịch chính xác, hoặc một bản dịch thích hợp với khu vực thử nghiệm. Một số Hạ sĩ, như phụ đề Hạ sĩ, có thể có những câu song với những bản dịch không chính xác gây ra bởi hạn chế địa vị hay độ dài. Để tìm cách giải quyết vấn đề này, trong tờ giấy này chúng tôi đề nghị sử dụng một mục tiêu tương ứng hơn bên ngoài nguồn khi chọn một cặp câu thích hợp để đào tạo một mô hình. Mục tiêu tương ứng này được xây dựng nhờ dịch trước mặt nguồn. Trong công việc này, chúng tôi khám phá khả năng của ý tưởng chung này cho một phương pháp chọn dữ liệu đặc biệt gọi là Trung tâm Decay Algorehms (FDA). Chúng tôi đào tạo mẫu NMT Đức-Anh về dữ liệu đã được chọn bằng cách sử dụng bộ thử (nguồn) và kích thước của chúng. Những kết quả của chúng tôi cho thấy các mô- đun được xây dựng bằng kết hợp xuất của FDA (dùng bộ thử và một mặt mục tiêu tương ứng) tốt hơn so với các mô- đun chỉ dùng bộ thử. Chúng ta có thể kiểm tra được khác trước tệ hơn 1.5\nDICAPRIO: cả một mô hình được huấn luyện với tất cả dữ liệu, và hơn cả 0.5 tiếng bíp chỉ trỏ vào một đường hầm FDA mạnh mà chỉ sử dụng thông tin mặt nguồn.', 'bg': 'Техниките за подбор на данни, прилагани при невронния машинен превод (НМТ), имат за цел да повишат производителността на даден модел чрез извличане на поднабор от изречения, които да се използват като тренировъчни данни. Една от възможните техники за подбор на данни са трансдуктивните методи на обучение, които избират данните въз основа на тестовия набор, т.е. документа, който ще бъде преведен. Ограничение на тези методи до момента е, че използването на тестовия набор от източника само по себе си не гарантира, че изреченията са избрани с правилни преводи, или преводи, които са подходящи предвид домейна на тестовия набор. Някои корпуси, като например корпуси на субтитри, могат да съдържат паралелни изречения с неточни преводи, причинени от локализация или ограничения на дължината. За да се опитаме да решим този проблем, в настоящата статия предлагаме да се използва приблизителна целева страна в допълнение към източника при избора на подходящи двойки изречения за обучение на модел. Тази приблизителна целева страна е изградена чрез предварително превеждане на източника. В тази работа ние изследваме изпълнението на тази обща идея за един специфичен подход за подбор на данни, наречен алгоритми за разпадане на характеристиките (FDA). Обучаваме немско-английски модели на НМТ на данни, избрани чрез тестовия набор (източник), приблизителната целева страна и смес от двете. Нашите констатации показват, че моделите, създадени с помощта на комбинация от изходни резултати на FDA (използвайки тестовия набор и приблизителна целева страна), се представят по-добре от тези, които използват само тестовия набор. Получаваме статистически значимо подобрение от повече от 1,5\nБлеу посочва модел, обучен с всички данни, и повече от 0,5 Блеу точки над силна база на FDA, която използва само информация от източника.', 'hr': 'Tehnike selekcije podataka primjenjene na prevod neuralnih strojeva (NMT) ciljeve su povećati učinkovitost model a prikupljajući podskup rečenica za uporabu kao podatke obuke. Jedna od mogućih tehnika izbora podataka su metode prevoditelja učenja, koje odaberu podatke na temelju testnog seta, tj. dokument koji treba prevoditi. ograničenje ovih metoda do sada je da korištenje testa na izvornoj strani samog sebe ne garantuje da se rečenice izaberu s ispravnim prevodima ili prevodima koje su odgovarajuće s obzirom na domenu ispitivanja. Neka korpora, kao što je podtitelna korpora, može sadržati paralelne rečenice s nepravednom prevodom uzrokovanom lokalizacijom ili ograničenjem dužine. Da bismo pokušali riješiti ovaj problem, u ovom papiru predlažemo koristiti približnu ciljnu stranu osim izvorne strane kada biramo odgovarajuće pare kazne za obuku model a. Ova približna ciljna strana izgrađena je pred prevodom izvora strane. U ovom poslu istražujemo učinkovitost ove opće ideje za jedan određeni pristup izbora podataka nazvan Algoritmi za dekoraciju funkcija (FDA). Vježbamo njemačke-engleske NMT modele na podacima odabranim koristeći test set (izvor), približnu ciljnu stranu i mješavinu oboje. Naši nalazi otkrivaju da modeli izgrađeni koristeći kombinaciju ishoda FDA (koristeći kompletu test a i približnu ciljnu stranu) čine bolje od onih koji koriste samo test kompletu. Dobili smo statistički značajno poboljšanje više od 1,5\nBLEU ukazuje na model obučen svim podacima, a više od 0,5 BLEU ukazuje na jaku početnu liniju FDA-a koja koristi samo informacije s izvorskim stranama.', 'de': 'Datenauswahltechniken für neuronale maschinelle Übersetzung (NMT) zielen darauf ab, die Leistung eines Modells zu erhöhen, indem eine Teilmenge von Sätzen für die Verwendung als Trainingsdaten abgerufen wird. Eine der möglichen Datenauswahltechniken sind transduktive Lernmethoden, bei denen die Daten anhand des Testsatzes, also des zu übersetzenden Dokuments, ausgewählt werden. Eine Einschränkung dieser Methoden besteht bisher darin, dass die Verwendung des quellenseitigen Testsets allein nicht garantiert, dass Sätze mit korrekten Übersetzungen oder Übersetzungen ausgewählt werden, die für die Testset-Domäne geeignet sind. Einige Korpora, wie zum Beispiel Untertitelkorpora, können parallele Sätze mit ungenauen Übersetzungen enthalten, die durch Lokalisierungs- oder Längenbeschränkungen verursacht werden. Um dieses Problem zu beheben, schlagen wir in diesem Beitrag vor, bei der Auswahl geeigneter Satzpaare zusätzlich zur Quellseite eine approximierte Zielseite zu verwenden. Diese approximierte Zielseite wird durch Vorübersetzung der Quellseite erstellt. In dieser Arbeit untersuchen wir die Leistungsfähigkeit dieser allgemeinen Idee für einen spezifischen Datenauswahlansatz namens Feature Decay Algorithms (FDA). Wir trainieren deutsch-englische NMT-Modelle auf Daten, die anhand des Testsets (Quelle), der angenäherten Zielseite und einer Mischung aus beiden ausgewählt wurden. Unsere Ergebnisse zeigen, dass Modelle, die mit einer Kombination von Outputs der FDA (unter Verwendung des Testsets und einer approximierten Zielseite) erstellt wurden, besser abschneiden als diejenigen, die ausschließlich den Testsatz verwenden. Wir erhalten eine statistisch signifikante Verbesserung von mehr als 1,5\nBLEU zeigt auf ein Modell, das mit allen Daten trainiert wurde, und mehr als 0,5 BLEU zeigt auf eine starke FDA-Basislinie, die nur quellenseitige Informationen verwendet.', 'da': 'Dataudvælgelsesteknikker anvendt til neural maskinoversættelse (NMT) sigter mod at øge en models ydeevne ved at hente en delmængde sætninger til brug som træningsdata. En af de mulige dataudvælgelsesteknikker er transduktive læringsmetoder, som vælger dataene ud fra testsættet, dvs. det dokument, der skal oversættes. En begrænsning af disse metoder til dato er, at brug af kildesidens testsæt ikke i sig selv garanterer, at sætninger er valgt med korrekte oversættelser, eller oversættelser, der er egnede i betragtning af testsættets domæne. Nogle korpora, såsom undertekstkorpora, kan indeholde parallelle sætninger med unøjagtige oversættelser forårsaget af lokaliserings- eller længdebegrænsninger. For at forsøge at løse dette problem foreslår vi i denne artikel at bruge en omtrentlig målside ud over kildesiden, når du vælger egnede sætningspar til træning af en model. Denne omtrentlige målside er bygget ved at forhåndsoversætte kildesiden. I dette arbejde undersøger vi ydeevnen af denne generelle idé til en specifik dataudvælgelsesmetode kaldet Feature Decay Algorithms (FDA). Vi træner tysk-engelske NMT modeller på data udvalgt ved hjælp af testsættet (kilde), den omtrentlige målside og en blanding af begge. Vores resultater viser, at modeller bygget ved hjælp af en kombination af output fra FDA (ved hjælp af testsættet og en omtrentlig målside) fungerer bedre end dem, der udelukkende bruger testsættet. Vi opnår en statistisk signifikant forbedring på mere end 1,5\nBLEU point over en model, der er trænet med alle data, og mere end 0,5 BLEU point over en stærk FDA baseline, der kun bruger kildeoplysninger.', 'nl': "Data selectie technieken toegepast op neurale machine translation (NMT) hebben tot doel de prestaties van een model te verhogen door een subset zinnen op te halen voor gebruik als trainingsdata. Een van de mogelijke technieken voor gegevensselectie zijn transductieve leermethoden, waarbij de gegevens worden geselecteerd op basis van de testset, d.w.z. het te vertalen document. Een beperking van deze methoden tot op heden is dat het gebruik van de bronzijde testset op zichzelf niet garandeert dat zinnen worden geselecteerd met correcte vertalingen, of vertalingen die geschikt zijn voor het testset domein. Sommige corpora's, zoals ondertitelcorpora's, kunnen parallelle zinnen bevatten met onnauwkeurige vertalingen veroorzaakt door lokalisatie of lengtebeperkingen. Om dit probleem op te lossen, stellen we in dit artikel voor om naast de bronzijde ook een geschatte doelzijde te gebruiken bij het selecteren van geschikte zinsparen voor het trainen van een model. Deze geschatte doelzijde wordt gebouwd door de bronzijde vooraf te vertalen. In dit werk onderzoeken we de prestaties van dit algemene idee voor een specifieke gegevensselectie benadering genaamd Feature Decay Algorithms (FDA). We trainen Duits-Engels NMT modellen op basis van data geselecteerd met behulp van de testset (bron), de geschatte doelzijde en een mix van beide. Onze bevindingen tonen aan dat modellen die zijn gebouwd met behulp van een combinatie van outputs van FDA (met behulp van de testset en een geschatte doelzijde) beter presteren dan die welke uitsluitend de testset gebruiken. We verkrijgen een statistisch significante verbetering van meer dan 1.5\nBLEU wijst op een model dat is getraind met alle gegevens en meer dan 0,5 BLEU wijst op een sterke FDA-baseline die alleen broninformatie gebruikt.", 'sw': 'Teknolojia za uchaguzi wa taarifa zilitumika kwa kutafsiri mashine ya kidini (NMT) lengo la kuongeza ufanisi wa muundo kwa kurudisha mfumo wa sentensi kwa kutumia kama data za mafunzo. Moja ya mbinu za uchaguzi wa data zinazowezekana ni njia za kujifunza za upatikanaji, ambazo zinachagua taarifa kwa kutumia set i ya jaribio, yaani nyaraka zinazotafsiriwa. Uzuizi wa njia hizi mpaka sasa ni kwamba kwa kutumia seti ya jaribio la upande wa asili hauwezi kujihakikisha kwamba sentensi zimechaguliwa kwa tafsiri sahihi, au tafsiri zinazofanana na kutolewa kwenye tovuti ya jaribio. Baadhi ya makampuni, kama vile kampuni ya chini ya kichwa, yanaweza kuwa na hukumu mbalimbali na tafsiri zisizo sahihi zinazosababishwa na vikwazo vya ndege. Ili kujaribu kurekebisha tatizo hili, katika karatasi hii tunapendekeza kutumia takribani upande wa lengo zaidi ya upande wa vyanzo pale tunachagua wanandoa wa hukumu sahihi kwa ajili ya mafunzo model. Hii takriban upande wa lengo umejengwa na kutafsiri vyanzo vya awali. In this work, we explore the performance of this general idea for one specific data selection approach called Feature Decay Algorithms (FDA).  Tunawafunza mifano ya NMT ya Kijerumani-Kiingereza kwa kutumia seti ya jaribio (chanzo), upande wa karibu wa lengo, na mchanganyiko wa wote. Matokeo yetu yanaonyesha kuwa mifano iliyotengenezwa kwa kutumia muungano wa matokeo ya FDA (kwa kutumia seti ya mtihani na upande wa karibu wa lengo) wanafanya vizuri kuliko wale tu wanaotumia seti ya jaribio. Tunapata maendeleo makubwa ya takwimu ya zaidi ya 1.5\nBLEU anaonyesha juu ya muundo ulioelekezwa na taarifa zote, na zaidi ya 0.5 BLEU inaonyesha juu ya mstari mkali wa FDA unaotumia taarifa za vyanzo pekee.', 'ko': '신경기계번역(NMT)에 적용되는 데이터 선택 기술은 문장 서브셋을 트레이닝 데이터로 검색해 모델의 성능을 향상시키기 위한 것이다.그 중 가능한 데이터 선택 기술은 학습 방법을 바꾸는 것이다. 테스트 집합 (즉 번역할 문서) 을 바탕으로 데이터를 선택한다.지금까지 이러한 방법의 한계는 원본 테스트 집합 자체를 사용하면 선택한 문장이 정확한 번역을 할 수 없거나 테스트 집합역을 정한 상황에서 번역이 적합하다는 것이다.일부 자료 라이브러리, 예를 들어 자막 자료 라이브러리는 현지화나 길이 제한으로 인해 번역이 부정확한 평행문장을 포함할 수 있다.이 문제를 해결하기 위해 본고에서 우리는 적당한 문장 대조를 선택하여 모델을 훈련할 때 원단을 제외하고 비슷한 목표단을 사용해야 한다고 제안한다.이 근사한 목표단은 사전 번역 원본을 통해 구축된 것이다.이 작업에서 우리는 특징감소 알고리즘(FDA)이라고 불리는 특정한 데이터 선택 방법의 전체적인 사고방식의 성능을 탐색했다.우리는 테스트 세트(원본), 근사 목표단과 이들의 혼합을 이용하여 데이터를 선택하고 덕영 NMT 모델을 훈련한다.FDA 출력 조합(테스트 세트와 근사 목표 측면을 사용)으로 구축된 모델이 별도로 테스트 세트를 사용한 모델보다 더 나은 것으로 나타났다는 연구 결과가 나왔다.우리는 1.5퍼센트가 넘는 통계가 현저하게 개선되었다\nBLEU 점수는 모든 데이터 트레이닝을 사용하는 모델을 능가하고 0.5 이상의 BLEU 점수는 소스 정보만 사용하는 강력한 FDA 기준선을 초과합니다.', 'tr': "NMT'a uygulanan maglumat saýlawy teknikleri, işleýän sözlerniň bir toparyny öwretmek üçin bir nusgasyny bejermek üçin hedeflenýär. Mümkin maglumat saýlaw teknikleri, terjime edilmeli senedi terjime etmek üçin terjime etmek üçin terjime etmek üçin data saýlayan metodlardyr. Häzirki şu döwletleriň hoýdançalygyny çeşme-tarap barlamagyny özüne garaşdyrmaýar. Käbir korpora, altyazylyk korpora ýaly, ýerleşdirilmek ýa-da durmuş çykyşlary bilen parallel sözlemler bolup biler. Bu meseläni çözmek üçin, bu kagyzda nusga üçin gowy sözlem çiftleri saýlamak üçin golaý bir hedef tarapyny golaýlaşdyrmak üçin guruldyrýarys. Bu ýakyn mümkin hedef tarapyny çeşme tarapyny öňünden terjime etmek üçin guruldy. Bu işde, Feature Decay Algorithms (FDA) diýilip atlanan bir hasaplanjak golaýynyň bu umumy ideýanyň başarylygyny keşfetýäris. Biz nemes-iňlisçe NMT nusgalaryny test setirini ulanarak saýlanan hatlaryň üstüne öwredýäris. Biziň tapylyklarymyz FDA netijeleri ulanan nusgalaryň diňe test setirini ulanan nusgalaryň has gowydygyny görkeýär. Biz 1.5-den köp taýýarlanan statistiki uly gowurak aldyk\nBLEU hemme maglumatlar bilen bilinmeli bir nusga üstünde bilinmiş we 0", 'id': 'Teknik pemilihan data yang diterapkan untuk terjemahan mesin saraf (NMT) bertujuan untuk meningkatkan prestasi sebuah model dengan mengambil subset kalimat untuk digunakan sebagai data latihan. Salah satu teknik pemilihan data yang mungkin adalah metode belajar transduktif, yang memilih data berdasarkan set tes, yaitu dokumen yang akan diterjemahkan. Sebuah batasan dari metode ini hingga hari ini adalah bahwa menggunakan set tes sisi sumber tidak secara sendiri menjamin bahwa kalimat dipilih dengan terjemahan yang benar, atau terjemahan yang sesuai dengan domain set tes. Beberapa corpora, seperti corpora subtitle, mungkin mengandung kalimat paralel dengan terjemahan yang tidak tepat disebabkan oleh lokasi atau batasan panjang. Untuk mencoba memperbaiki masalah ini, di kertas ini kami mengusulkan untuk menggunakan sisi target yang terdekat selain sisi sumber ketika memilih pasangan kalimat yang cocok untuk melatih model. Ini disekitar sasaran dibangun dengan preterjemahkan sisi sumber. Dalam pekerjaan ini, kami mengeksplorasi prestasi ide umum ini untuk satu pendekatan seleksi data spesifik yang disebut Algoritma Feature Decay (FDA). Kami melatih model NMT Jerman-Inggris pada data yang dipilih dengan menggunakan set tes (sumber), sisi target yang terdekat, dan campuran keduanya. Our findings reveal that models built using a combination of outputs of FDA (using the test set and an approximated target side) perform better than those solely using the test set.  Kami mendapatkan peningkatan statistik yang signifikan dari lebih dari 1,5\nBLEU menunjukkan pada model yang dilatih dengan semua data, dan lebih dari 0,5 BLEU menunjukkan pada dasar FDA yang kuat yang hanya menggunakan informasi sisi sumber.', 'fa': 'تکنیک انتخاب داده\u200cها به ترجمه\u200cهای ماشین عصبی (NMT) هدف می\u200cگیرند تا عملکرد یک مدل را افزایش دهد، با استفاده از زیر جمله جمله\u200cهای جمله برای استفاده به عنوان داده\u200cهای آموزش. یکی از تکنیک انتخاب داده\u200cهای ممکن روش یادگیری ترجمه\u200cکننده است که داده\u200cها را بر پایه مجموعه آزمایش انتخاب می\u200cکند، یعنی سند را ترجمه می\u200cکند. محدودیت این روش\u200cها تا تازگی این است که استفاده از مجموعه آزمایش منبع جانب خودش تضمین نمی\u200cکند که جمله\u200cها با ترجمه\u200cهای درست انتخاب می\u200cشوند، یا ترجمه\u200cهای مناسب به مجموعه\u200cی تنظیم آزمایش داده می\u200cشوند. بعضی شرکت، مثل شرکت زیر عنوان زیر عنوان، ممکن است جمله\u200cهای متفاوتی با ترجمه\u200cهای غیرقابل توسط محلی یا محدودیت طول باشد. برای اینکه سعی کنیم این مشکل را حل کنیم، در این کاغذ پیشنهاد می کنیم که در اضافه به طرف هدف نزدیک شده استفاده کنیم، در حالی که جفت جمله مناسب برای آموزش یک مدل انتخاب کنیم. این قسمت هدف تقریباً توسط قبل از ترجمه کردن جانب منبع ساخته می شود. در این کار، ما فعالیت این ایده عمومی را برای یک طریق انتخاب داده خاص به نام الگوریتم\u200cهای تخمین ویژه (FDA) تحقیق می\u200cکنیم. ما مدل\u200cهای آلمانی-انگلیسی NMT را روی داده\u200cها انتخاب می\u200cکنیم که با استفاده از مجموعه آزمایش (منبع) استفاده می\u200cکنیم، نزدیک به سمت هدف و یک ترکیب از هر دو. نتیجه\u200cهای ما نشان می\u200cدهند که مدل\u200cهای ساخته شده با استفاده از ترکیب نتیجه\u200cهای FDA (با استفاده از مجموعه آزمایش و یک طرف هدف نزدیک) بهتر از آن\u200cها انجام می\u200cدهند که تنها از مجموعه آزمایش استفاده می\u200cکنند. ما به طور آماری بهتر شدن بیش از ۱.۵ دریافت می\u200cکنیم\nBLEU بر روی یک مدل آموزش داده شده با تمام داده ها، و بیشتر از 0.5 BLEU بر روی یک خط بنیادی قوی FDA که فقط از اطلاعات منبع استفاده می کند.', 'sq': 'Teknikët e zgjedhjes së të dhënave të aplikuara në përkthimin nervor të makinave (NMT) synojnë të rritin performancën e një modeli duke marrë një nëngrup fjalësh për përdorim si të dhëna treinimi. Një nga teknikat e mundshme të zgjedhjes së të dhënave janë metodat transduktive të mësimit, të cilat zgjedhin të dhënat bazuar në grupin e provave, pra dokumenti që do të përkthehet. Një kufizim i këtyre metodave deri tani është se përdorimi i grupit të testit nga ana e burimit nuk garanton vetë se fjalët janë zgjedhur me përkthime të sakta apo përkthime të përshtatshme duke marrë parasysh domenin e grupit të testit. Disa corpora, të tilla si corpora subtitle, mund të përmbajnë fjalë paralele me përkthime të pakurata të shkaktuara nga lokalizimi apo kufizimet e gjatësisë. Me qëllim që të përpiqemi të rregullojmë këtë problem, në këtë letër ne propozojmë të përdorim një an ë objektive të afërt përveç anës burimi kur zgjedhim çifte fjalësh të përshtatshme për trajnimin e një modeli. Kjo anë e objektivit është ndërtuar duke përkthyer përpara anës burimi. Në këtë punë, ne eksplorojmë performancën e kësaj ide të përgjithshme për një metodë specifike të zgjedhjes së të dhënave të quajtur Algoritme të Shkatërrimit të Features (FDA). Ne trajnojmë modelet gjermano-angleze NMT në të dhënat e zgjedhura duke përdorur grupin e testit (burim), anën e objektivit të afërt, dhe një përzierje të të dyve. Gjetjet tona zbulojnë se modelet e ndërtuara duke përdorur një kombinim të daljeve të FDA (duke përdorur grupin e testit dhe një an ë objektive të afërt) bëjnë më mirë se ato që përdorin vetëm grupin e testit. We obtain a statistically significant improvement of more than 1.5\nBLEU vë në dukje një model të trajnuar me të gjitha të dhënat dhe më shumë se 0.5 pikë BLEU mbi një bazë të fortë të FDA që përdor vetëm informacionin nga ana e burimit.', 'hy': 'Նյարդային մեքենայի թարգմանման (NMT) համար օգտագործվող տվյալների ընտրության մեթոդները նպատակում են մեծացնել մոդելի արդյունավետությունը՝ վերցնելով որպես ուսուցման տվյալներ օգտագործվող նախադասությունների մի ենթախումբ: Հնարավոր տվյալների ընտրության մեթոդներից մեկը տրանսուկտիվ ուսուցման մեթոդներ են, որոնք ընտրում են տվյալները, հիմնված փորձարկման համակարգի վրա, այսինքն՝ թարգմանվող փաստաթղթի վրա: Այս մեթոդների սահմանափակումն այսօր այն է, որ աղբյուր կողմի փորձարկումների սահմանափակումն ինքն իրեն չի երաշխավորում, որ նախադասությունները ընտրվում են ճիշտ թարգմանություններով կամ թարգմանություններով, որոնք համապատասխանում են փորձարկումների սա Որոշ մարմներ, ինչպիսիք են ենթագլխավոր մարմները, կարող են պարունակել զուգահեռ նախադասություններ, որոնք անճշգրիտ թարգմանություններ են առաջացել գտնվելու կամ երկարության սահմանափակումների պատճառով: Այս խնդիրը լուծելու համար, այս թղթի մեջ մենք առաջարկում ենք օգտագործել մոտավորապես նպատակային կողմը նաև աղբյուրի կողմը, երբ ընտրում ենք մոդելի ուսուցման համար համապատասխան նախադասությունների զույգեր: Այս մոտավորված նպատակային կողմը կառուցվում է նախթարգմանելով աղբյուրի կողմը: Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք այս ընդհանուր գաղափարի արտադրողությունը տվյալների ընտրության մի կոնկրետ մոտեցում, որը կոչվում է Ալգորիթմներ, որոնք կոչվում են Ալգորիթմներ: Մենք սովորեցնում ենք գերմաներեն-անգլերեն NMT մոդելներ տվյալների վրա, որոնք ընտրվել են օգտագործելով փորձարկման համակարգը (աղբյուր), մոտավորված նպատակային կողմը և երկուսի խառնուրդ: Մեր հայտնաբերությունները ցույց են տալիս, որ մոդելները, որոնք կառուցվել են FDA-ի արտադրողների համադրման օգնությամբ (օգտագործելով փորձարկման համակարգը և մոտավորապես նպատակային կողմը), ավելի լավ են աշխատում, քան նրանք, որոնք միայն Մենք ստանում ենք վիճակագրական նշանակալի զարգացում ավելի քան 1.5\nԲԼԵՎ-ը ցույց է տալիս բոլոր տվյալներով սովորեցված մոդելի վրա, և ավելի քան 0.5 ԲԼԵՎ-ը ցույց է տալիս FDA-ի ուժեղ հիմքի վրա, որը միայն օգտագործում է աղբյուրի կողմից տեղեկատվություն:', 'af': "Data keuse teknike wat op neurale masjien vertaling (NMT) aangepas het, doel om die prestasie van 'n model te vermeerder deur 'n subartikel van setinge te ontvang vir gebruik as onderwerp data. Een van die moontlike data keuse tekens is transduktiewe leer metodes, wat kies die data gebaseer op die toets stel, bv. die dokument om te vertaal. 'n Begrens van hierdie metodes tot datum is dat gebruik van die bron- kant toets stel nie deur homself garantieer dat setinge gekose word met korrekte vertalings, of vertalings wat geskikte is gegee het die toets- stel domein. Sommige korpora, soos subtitle corpora, kan parallele setings bevat met onregte vertalings veroorsaak deur lokalisering of lengte beperking. Om hierdie probeer te herstel, in hierdie papier voorstel ons om 'n aangewonde doel-kant te gebruik bygevoeg na die bron-kant wanneer ons geskikte sentence-pairs kies om 'n model te oefen. Hierdie omtrent doel- kant is gebou deur voor- vertaling van die bron- kant. In hierdie werk, ondersoek ons die prestasie van hierdie algemene idee vir een spesifieke data-keuse toegang genoem Feature Decay Algorithms (FDA). Ons trein Duitse-Engels NMT modele op data gekose deur die toets stel (bron), die omtrent doelskant en 'n gemink van beide te gebruik. Ons gevinde vertoon dat modele gebou het met gebruik van 'n kombinasie van uitvoerdes van FDA (gebruik die toets stel en 'n omtrent doel kant) beter uitvoer as die slegs gebruik die toets stel. Ons kry 'n statistiese betaling verbetering van meer as 1.5\nBLES punte oor 'n model wat met alle data opgelei is, en meer as 0,5 BLEU punte oor 'n sterk FDA basislien wat slegs bron-kant inligting gebruik.", 'bn': 'প্রশিক্ষণ তথ্য হিসেবে ব্যবহার করার জন্য একটি মডেলের প্রভাব বৃদ্ধি করার উদ্দেশ্যে ডাটা নিউরুল মেশিন অনুবাদের (এনএমটি) প্রয়োগ করা হয়েছে। সম্ভাব্য তথ্য নির্বাচন প্রযুক্তিগুলোর মধ্যে একটি ট্রান্ডনাক্টিভ শিক্ষা পদ্ধতি, যা পরীক্ষা সেটের ভিত্তিক তথ্য নির্বাচন সোর্স- পার্শ্ব পরীক্ষা ব্যবহার করার জন্য এই পদ্ধতির সীমাবদ্ধ হলো নিশ্চিত নিশ্চিত না যে সঠিক অনুবাদ দিয়ে বাক্য নির্বাচিত হয়েছে অথবা অনুবাদে কিছু কোর্পোরা, যেমন সাবশিরোনাম কর্পোরা, স্থানীয় অবস্থান বা দীর্ঘ সীমাবদ্ধতার কারণে অকার্যকর অনুবাদের সাথে সামান্য ব এই সমস্যাটি ঠিক করার চেষ্টা করার জন্য, এই পত্রিকায় আমরা প্রস্তাব করছি যে সোর্স-পাশের পরিবর্তে মোডেল প্রশিক্ষণের জন্য যথাযথ বাক্য-জোড়া নির্বা এই প্রায় লক্ষ্য-পাশে উৎস-পাশের পূর্বে অনুবাদ করে নির্মাণ করা হয়েছে। এই কাজে আমরা এই সাধারণ চিন্তার প্রকৃতি খুঁজে বের করি ফিয়েটার ডিসে অ্যালগরিদম (এফডিএ) নামে একটি নির্দিষ্ট তথ্য নির্বাচনে আমরা জার্মান-ইংরেজী এনএমটি মডেল নির্বাচিত তথ্য নিয়ে প্রশিক্ষণ প্রশিক্ষণ করি পরীক্ষা সেট (সোর্স), প্রায় লক্ষ্য পাশ এবং উভয় Our findings reveal that models built using a combination of outputs of FDA (using the test set and an approximated target side) perform better than those solely using the test set.  আমরা পরিসংখ্যানের পরিসংখ্যানে এক.\nবিলু একটি মডেলের নির্দেশ দিয়েছে যা সকল তথ্য দিয়ে প্রশিক্ষণ করা হয়েছে, এবং ০. ৫ বিলিউ বিন্দুকে একটি শক্তিশালী FDA বেস্লাইনের উপর প্র', 'am': 'የዳታ ምርጫዎች ምረጡ በናውሬል ማሻሻል ትርጉም (NMT) የተጠቃሚ የሞዴል ማስታወቂያውን ለመጨመር በተቃውሞ የsentence ክፍል አቅራቢያ ለመስጠት ዳታዎችን ለማስጠጋት ነው፡፡ የዳታ ምርጫዎች ምረጡ ተቃውሞ ተማሪዎችን ማረጃ ማድረግ ነው፤ የዳታ መረጃዎችን በሞክሩ ማሰናጃ ላይ የሚመረጠውን አዲስ ሰነድ ለመትረጉም ነው፡፡ የእነዚህ ሰርዓቶች ግንኙነት ነው፤ የኩነቶች-side ፈተና ማድረግ በተጠቃሚ የተመረጡ ቃላት በመክፈት ወይም በመተርጓም በሚያስፈልጉ ዶሜን በመስጠት የተመረጡ መግለጫ በራሱ አይደለም። አንዳንዶች ኮርፖርት፣ እንደ አቅራቢያ ኮርፖር፣ ብሔራዊ ግንኙነት ወይም ረጅም ግንኙነት የተደረገ የግንኙነት ግንኙነት በማይችል ተርጓሚዎች ይችላል፡፡ ይህንን ጉዳይ ለመፈለግ ለመፈለግ፣ በዚህ ገጽ ውስጥ ለአካባቢው ጉዳይ-side በተጨማሪው የፊደል ጉዳይ-ዓይነቶች ለሞዴል ማስተማር ሲመርጥ እናስቸጋጅላለን፡፡ ይህ የአካባቢው እቅድ-side በመግለጫው በፊት የተሠራ ነው፡፡ በዚህ ስራ፣ የዚህን አዳላዊ አእምሮውን ለማድረግ እናደርጋለን፡፡ የጀርመን-እንግሊዘኛ NMT ዓይነቶችን በመረጠው የዳታ ዘዴዎችን እናስተምራለን፡፡ ፍላጎታችን የFDA ውጤቶች በተለየ ቁጥጥር (የፈተናው መስመር እና የአካባቢው ክፍል) የተደረገውን ምሳሌዎች ከፈተናው ማሰናከል በተጠቀም የሚሻል ነው፡፡ 1.5 የሚበልጠውን የstatistically significant ማሻሻሻል እናገኛለን\nBLEU በማድረግ ሁሉ በተማረ ሞዴል ላይ ይነክራል፣ ከ0.5 ቢLEU በላይ የኩነቶች መረጃ ብቻ የሚጠቅመውን ብርቱ FDA የመስመር መስመር ላይ ይነክራል፡፡', 'ca': "Les tècniques de selecció de dades aplicades a la traducció neural de màquines (NMT) tenen l'objectiu d'augmentar el rendiment d'un model obtenint un subconjunt de frases per a utilitzar-se com a dades d'entrenament. One of the possible data selection techniques are transductive learning methods, which select the data based on the test set, i.e. the document to be translated.  Una limitació d'aquests mètodes fins ara és que utilitzar el conjunt de proves de costat font no garanteix per si mateix que les frases es seleccionen amb traduccions correctes, o traduccions adequades dada el domini del conjunt de proves. Alguns corpores, com els subtitles corpores, poden contenir frases paralleles amb traduccions inaccurates causades per la localització o restriccions de llargada. Per tractar de solucionar aquest problem a, en aquest paper proposem que utilitzem una banda d'objectiu aproximada a més de la banda d'origen quan seleccionem parelles de frases adequades per a formar un model. Aquest punt d'objectiu aproximat està construït traducent-se previament el punt d'origen. En aquesta feina, explorem el desempeny d'aquesta idea general per a un enfocament específic de selecció de dades anomenat Algoritmes de Descapacitat de Característiques (FDA). Ensenyem models de NMT alemanès-anglès en dades seleccionates utilitzant el conjunt de prova (font), el costat d'objectiu aproximat i una mistura de ambdós. Els nostres descobriments revelen que els models construïts utilitzant una combinació de productes de FDA (utilitzant el conjunt de prova i un costat d'objectiu aproximat) actuen millor que els que només utilitzen el conjunt de prova. Obtenim una millora estadísticament significativa de més de 1,5\nBLEU apunta sobre un model entrenat amb totes les dades, i més de 0,5 punts BLEU sobre una base forta de FDA que només utilitza informació de la font.", 'az': 'NMT-ə uyğunlanan məlumat seçmə teknikləri modelinin performansını artırmaq məqsədilə təhsil məlumatları olaraq istifadə etmək üçün cümlələrin subgruplarını alır. Mümkün məlumat seçmə tekniklərindən biri təkrar öyrənmə metodlarındır, həmçinin sınama qutusuna dayanan məlumatları seçir, yoxsa təkrar ediləcək döküməni seçir. Bu metodların günə qədər sınırlanması, mənbə tərəflərinin sınaması tərəfindən istifadə etmək cümlələrin doğru tercümə ilə seçilməsini və ya sınama tərəflərinin dəyişdirilməsini təsdiqlənməsini təsdiqlənməsini təmin etməkdir. Bazı korpora, altyazı korpora kimi, yerləşdirilməsi və uzunluğu müəyyənləşdirilməsi üzündən təqrib tərcümlə paralel cümlələr içərir. Bu problemi çəkmək üçün, bu kağızda modeli təhsil etmək üçün uyğun cümlələr çiftlərini seçərkən mənbə tərəfindən istifadə etməyi təklif edirik. Bu yaxınlaşdırılmış hedef tərəfindən mənbə tərəfindən əvvəl çevirib inşa edilir. Bu işdə, Feature Decay Algorithms (FDA) adlı məlumatların seçimləri üçün bu general ideyanın performansını keşfetirik. Biz alman-İngilizce NMT modellərini test setini, yaxınlaşdırılmış məqsəd tərəfindən və ikisinin qarışıqlığı ilə seçilmiş məlumatlarda təhsil edirik. Bizim tapındıqlarımız göstərir ki modellər FDA-nın birləşdirilməsi ilə inşa edilmişdir (test seti və yaxınlaşdırılmış məsafə tərəfindən istifadə edilən məsafə tərəfindən daha yaxşıdır). Biz statistik olaraq 1.5-dən çox mövcuddur bir improvisası alırıq.\nBütün məlumatlarla təhsil edilmiş modellərin üstündə BLEU nöqtələri və 0,5 BLEU nöqtələri yalnız mənbə tərəfindən istifadə edən FDA tərəfindən çox qüvvətli tərəfindən yüksək.', 'et': 'Neuraalse masintõlke (NMT) andmete valimise meetodite eesmärk on suurendada mudeli jõudlust, tuues välja lausete alamhulga, mida kasutatakse treeningandmetena. Üks võimalikest andmete valimise meetoditest on transduktiivsed õppemeetodid, mis valivad andmed testikomplekti alusel, st tõlkitava dokumendi alusel. Nende meetodite siiani piiranguks on see, et allikakülgse testikomplekti kasutamine iseenesest ei taga lausete valimist õigete tõlketega või testikomplekti domeenile sobivate tõlketega. Mõned korpused, näiteks subtiitrite korpused, võivad sisaldada paralleelseid lauseid ebatäpsete tõlketega, mis on põhjustatud lokaliseerimise või pikkuse piirangutest. Selleks et probleemi lahendada, pakume selles töös välja kasutada ligikaudset sihtkülge lisaks allikaküljele sobivate lausepaaride valimisel mudeli treenimiseks. See ligikaudne sihtkülg on ehitatud lähtekülje eeltõlkimise teel. Selles töös uurime selle üldise idee tulemuslikkust ühe konkreetse andmevaliku lähenemisviisi jaoks, mida nimetatakse Feature Decay Algorithms (FDA). Me treenime saksa-inglise NMT mudeleid andmetel, mis on valitud katsekomplekti (allika), ligikaudse sihtkülje ja mõlema segu abil. Meie tulemused näitavad, et FDA väljundite kombinatsiooni kasutades ehitatud mudelid (kasutades katsekomplekti ja ligikaudset sihtkülge) toimivad paremini kui ainult katsekomplekti kasutavad mudelid. Saame statistiliselt olulise paranemise rohkem kui 1,5\nBLEU osutab kõigi andmetega koolitatud mudelile ja rohkem kui 0,5 BLEU-punkti FDA tugevale lähtetasemele, mis kasutab ainult allikapoolset teavet.', 'cs': 'Techniky výběru dat aplikované na neuronový strojový překlad (NMT) mají za cíl zvýšit výkon modelu načtením podmnožiny vět pro použití jako tréninková data. Jednou z možných technik výběru dat jsou metody transduktivního učení, které vybírají data na základě testovací sady, tedy dokumentu, který má být přeložen. Dosavadní omezení těchto metod spočívá v tom, že použití testovací sady na straně zdroje samo o sobě nezaručuje výběr vět se správnými překlady nebo překlady, které jsou vhodné vzhledem k doméně testovací sady. Některé korpusy, například korpusy titulků, mohou obsahovat paralelní věty s nepřesnými překlady způsobenými lokalizací nebo omezeními délky. Abychom tento problém vyřešili, navrhujeme v tomto článku použít při výběru vhodných větových párů pro trénink modelu přibližnou cílovou stranu vedle zdrojové strany. Tato přibližná cílová strana je vytvořena předpřekladem zdrojové strany. V této práci zkoumáme výkonnost této obecné myšlenky pro jednu specifickou metodu výběru dat nazvanou Feature Decay Algorithms (FDA). Trénujeme německo-anglické NMT modely na základě dat vybraných pomocí testovací sady (zdroj), aproximované cílové strany a směsi obou. Naše zjištění ukazují, že modely vytvořené kombinací výstupů FDA (s využitím testovací sady a přibližné cílové strany) fungují lépe než ty, které používají pouze testovací sadu. Dosahujeme statisticky významného zlepšení o více než 1,5\nBLEU ukazuje na model trénovaný se všemi daty a více než 0,5 BLEU ukazuje na silnou základnu FDA, která používá pouze informace na straně zdroje.', 'bs': 'Tehnike selekcije podataka primjenjene na prevod neuralne mašine (NMT) ciljeve su povećati učinkovitost model a prikupljanjem podgrupe rečenica za uporabu kao podaci obuke. Jedna od mogućih tehnika selekcije podataka su metode prevoditelja učenja, koje odaberu podatke na temelju seta testa, tj. dokument koji treba prevoditi. ograničenje ovih metoda do sada je da korištenje testa na izvornoj strani samog sebe ne garantuje da se rečenice izaberu sa ispravnim prevodima ili prevodima koje su odgovarajuće s obzirom na domenu testa. Neka korpora, kao što je podtitelna korpora, može sadržati paralelne rečenice sa nepravednom prevodom uzrokovanom lokalizacijom ili ograničenjem dužine. Da bismo pokušali riješiti ovaj problem, u ovom papiru predlažemo da koristimo približnu ciljnu stranu osim izvorne strane kada biramo odgovarajuće pare kazne za obuku model a. Ova približna ciljna strana je izgrađena pred prevodom izvora strane. U ovom poslu istražujemo provedbu ove generalne ideje za jedan određeni pristup selekcije podataka nazvan Algoritmi za dekoraciju funkcija (FDA). Vježbamo njemačke-engleske NMT modele na podacima odabranim koristeći test set (izvor), približnu ciljnu stranu i mješavinu oboje. Naši nalazi otkrivaju da modeli izgrađeni koristeći kombinaciju ishoda FDA (koristeći kompletu test a i približnu ciljnu stranu) čine bolje od onih koji koriste samo test kompletu. Dobili smo statistički značajno poboljšanje više od 1,5\nBLEU ukazuje na model obučen sa svim podacima, a više od 0,5 BLEU ukazuje na jaku početnu liniju FDA-a koja koristi samo informacije na izvorskoj strani.', 'fi': 'Neuraalisen konekäännöksen (NMT) tiedonvalintatekniikoilla pyritään parantamaan mallin suorituskykyä noutamalla lauseiden osajoukko harjoitusdataksi. Yksi mahdollisista tiedonvalintatekniikoista ovat transduktiiviset oppimismenetelmät, jotka valitsevat tiedot testisarjan eli käännettävän asiakirjan perusteella. Näiden menetelmien rajoituksena tähän mennessä on se, että lähdepuolen testisarjan käyttäminen ei sinänsä takaa, että lauseet valitaan oikeilla käännöksillä, tai käännökset, jotka soveltuvat testijoukon verkkotunnukseen. Jotkin korpuset, kuten tekstityskorporat, voivat sisältää rinnakkaisia lauseita, joissa on epätarkkoja käännöksiä lokalisaation tai pituusrajoitusten vuoksi. Tämän ongelman ratkaisemiseksi tässä työssä ehdotamme lähdepuolen lisäksi likimääräistä kohdepuolta valittaessa sopivia lausepareja mallin harjoitteluun. Tämä likimääräinen kohdepuoli rakennetaan kääntämällä lähdepuoli etukäteen. Tässä työssä tutkimme tämän yleisen idean suorituskykyä tietylle tiedonvalintamenetelmälle nimeltä Feature Decay Algorithms (FDA). Koulutamme saksa-englantilaisia NMT-malleja käyttäen testisarjaa (lähde), likimääräistä kohdepuolta ja molempien sekoitusta. Tuloksemme osoittavat, että FDA:n tuotosten yhdistelmällä rakennetut mallit (käyttäen testisarjaa ja arvioitua kohdepuolta) toimivat paremmin kuin pelkästään testisarjaa käyttävät mallit. Saamme tilastollisesti merkitsevän parannuksen yli 1,5\nBLEU osoittaa mallia, joka on koulutettu kaikilla tiedoilla, ja yli 0,5 BLEU-pistettä FDA:n vahvaan lähtötilanteeseen, jossa käytetään vain lähdepuolen tietoja.', 'sk': 'Tehnike izbire podatkov, ki se uporabljajo za nevronsko strojno prevajanje (NMT), želijo povečati učinkovitost modela s pridobivanjem podmnožice stavkov za uporabo kot podatki o usposabljanju. Ena od možnih tehnik izbire podatkov so transduktivne metode učenja, ki izberejo podatke na podlagi testnega niza, tj. dokumenta, ki ga je treba prevesti. Omejitev teh metod do danes je, da uporaba preskusnega nabora na strani vira sama po sebi ne zagotavlja, da so stavki izbrani s pravilnimi prevodi ali prevodi, ki so primerni glede na domeno preskusnega nabora. Nekateri korpusi, kot so korpusi podnapisov, lahko vsebujejo vzporedne stavke z netočnimi prevodi zaradi lokalizacije ali omejitev dolžine. Da bi poskušali rešiti to težavo, v tem prispevku predlagamo uporabo približne ciljne strani poleg strani vira pri izbiri primernih stavkov za usposabljanje modela. Ta približna stran cilja je zgrajena s predprevajanjem strani vira. V tem delu raziskujemo uspešnost te splošne ideje za en specifičen pristop izbire podatkov, imenovan Feature Decay Algorithms (FDA). Treniramo nemško-angleške modele NMT na podatkih, izbranih z uporabo testnega niza (vira), približne ciljne strani in mešanice obeh. Naše ugotovitve kažejo, da so modeli, izdelani s kombinacijo rezultatov FDA (z uporabo testnega nabora in približne ciljne strani), boljši od tistih, ki uporabljajo samo testni nabor. Dobimo statistično značilno izboljšanje za več kot 1,5\nBLEU kaže na model, usposobljen z vsemi podatki, in več kot 0,5 točke BLEU na močno osnovno točko FDA, ki uporablja samo informacije na strani vira.', 'he': 'טכניקות הבחירה של נתונים שמשתמשות לתרגום מכונות עצביות (NMT) מכוונות להעלות את ההפעלה של מודל על ידי השיגת תחתונה של משפטים לשימוש בתור נתונים אימונים. אחת הטכניקות האפשריות לבחור נתונים הן שיטות לימוד טרנסודקטיביות, שבחרו את הנתונים המבוססים על קבוצת הבדיקות, כלומר המסמך שיתרשמו. הגבלה של השיטות הללו עד היום היא ששימוש בסט מבחן צד מקור לא מבטיח בעצמו שהמשפטים נבחרים עם תרגומות נכונות, או תרגומות שהתאימות בהתחשב בתחום הסט מבחן. איזה גופורה, כמו גופורה תורגם ע"י תורגם וסונכרן ע"י כדי לנסות לתקן את הבעיה הזאת, בעיתון הזה אנו מציעים להשתמש בצד המטרה מתקרב בנוסף לצד המקור כשבוחרים זוגות משפטים מתאימים לאימון מודל. צד המטרה המפורסם הזה נבנה על ידי התרגום קודם לצד המקור. In this work, we explore the performance of this general idea for one specific data selection approach called Feature Decay Algorithms (FDA).  אנחנו מאמן דוגמנים של NMT גרמני-אנגלי על נתונים שנבחרו על ידי השימוש בסט הבדיקה (מקור), בצד המטרה המפורסם, וערבוב של שניהם. הממצאים שלנו מראים שדוגמנים שנבנו בשימוש שילוב של יצורים של FDA אנחנו מקבלים שיפור סטטיסטי משמעותי של יותר מ-1.5\nBLEU מצביע על מודל מאומן עם כל הנתונים, ויותר מ-0.5 נקודות BLEU מעל רמז חזק FDA אשר משתמש רק במידע מצד מקור.', 'ha': "@ info: tooltip Bayani cikin shirin zaɓen data masu iya yiwuwa, yana shiryoyin lõkaci na farata, wanda za'a zãɓi data a kan tsarin jararin, misali, takardan za'a fassara. Tsarin wannan shiryoyin a yanzu shine cewa, a yi amfani da jarrabar-side-source ba zai yi amfani da shi ba zai tabbatar da cewa, ba za'a zãɓi saurãre da fassarar masu inganci ba, ko kuma fassarar da ke daidai da a sami'a-set Domen. Ko da wani firma, kamar makampuni na ƙarƙashin ajiya, za'a ƙunsa da sigar masu daidaita da fassarori masu inganci wanda ya shagaltar da lokalori ko kanana tsawo. Dõmin ka yi jarraba cewa masu daidaita wannan muammãni, cikin wannan takarda, Munã buƙata wa ka yi amfani da wani taki makusanci na taga, da kuma a ƙara-side idan ka zãɓi nau'in-nau'i masu daidai wa tsarin wani misali. @ info: whatsthis In this work, we explore the performance of this general idea for one specific data selection approach called Feature Decay Algorithms (FDA).  Tuna kõre misãlai na Jaman-Ingiriya na NMT kan data wanda aka zãɓe su da amfani da tsarin jarraba (source), taki gaba ga tagan gaba ɗaya, da kuma haɗi. FayiyinMu na bayyana cewa misãlai da aka gina ta da komai na FDA (da za'a yi amfani da tsarin jarrabãwa da cire-gaba) su yi mafiya alhẽri daga waɗanda ke amfani da tsarin jarrabãwa kawai. Tuna sami kyakkyawan kyauta akan 1.5\n@ item: inmenu", 'jv': 'Genjer-Genjer data diuwisi teknik sing aplikasi kanggo tarjamahan de sistem Neral (NMT) kang nggawe barang nggawe modèl kuwi tindakan ngerasai kapan-kapan kanggo nggawe sistem dadi nyong. Jejaring limitation of this method to date is that use the source-side test set Baling kanggo ngilangno nggunakake perkoro iki, ning alih iki dhéwé ngerti nggunakake tarjamahan kanggo gabung, dadi kebutuhan seneng dolanan sing apik nggo ngerasakno Puno Nang negori iki, kita sampeyan nggawe barang nggawe akeh operasi iki banget kanggo nganggo perusahaan dadi sing nyimpen podho sing sembarang "Attribute Desay Algorithms (FD). Awak dhéwé ngewat model alaman-Inggris NMT kuwi alaman sing wis diulok ngono nggawe ujian (penonton), dadi kanggo ngwala saiki, lan ngawehi gedung Ndoleh-Ndoleh sing bukane mungkin ngerasai model sing gawe nguteranku ngerasai FDa Awak dhéwé luwih akeh dadi nggawe luwih operasi 1.5\n"Bli" punika dipunangé kapan sistem sing ditambahak karo akeh dadi, lan luwih-luwih sing katya 0.5', 'bo': 'neural machine translation (NMT)ལ་འཇུག་སྤྱོད་པའི་ཐབས་ལམ་གནད་དོན་ཡོད་པའི་མིག་ཆས་བཀོལ་སྤྱོད་ཀྱི་ཚོགས འབྱུང་སྲིད་པའི་ཆ་འཕྲིན་གདམ་ཀྱི་ཐབས་ལམ་ཞིག A limitation of these methods to date is that using the source-side test set does not by itself guarantee that sentences are selected with correct translations, or translations that are suitable given the test-set domain. Some corpora, such as subtitle corpora, may contain parallel sentences with inaccurate translations caused by localization or length restrictions. དཀའ་ངལ་འདི་བདེ་ཞིབ་བཟོ་བྱེད་དགོས་ན། ཤོག་བྱང་འདིའི་ནང་གི་ནང་དུ་ང་ཚོས་མིག་སྔར་སྒྲིག་གི་དམིགས་ཡུལ་ཕྱོགས་སུ་མཐུན་སྒྲིག འདི་གཟུགས་ཐལ་ཡོད་པའི་དམིགས་ཡུལ་ཕྱོགས་འདི་འདྲ་ཞིག་གི་སྔོན་ལ་བསྒྱུར་ནས་ཡོད་པ འོན་ཀྱང་། ང་ཚོས་རང་ཉིད་སྐྱེས་ཆེན་གྱི་ཐབས་ལམ་དེ་ལ་སྤྱིར་བཏང་བ་འདིའི་གྲངས་སྤྱོད་ཀྱི་ལས་འགན ང་ཚོས་བརྟག་ཞིབ ང་ཚོའི་མཐོང་སྣང་དག་གིས་དཔེ་གཞི་རྩལ་བ་སྤྱོད་མཁན་གྱི་ཕྱིར་ཚོགས་ཀྱི་བསྡུར་བ་གཅིག་ལས་མཐུན་རྐྱེན་བྱས་པ་ཡིན་པས། ང་ཚོས་1.5ལས་བརྩིས་རྩིས་འབྲེལ་གྱིས་ཚད་རྩིས་གཏོང་བའི་ཡར་རྒྱས་འགྲོ་བ་ཞིག་ཐོབ་ཡོད།\nBLEU ་སྔོན་འཛུགས་ཀྱི་ཐབས་ལམ་ཞིག་བརྟན་པར་སྒྲིག'}
{'en': 'Multi-paraphrase Augmentation to Leverage Neural Caption Translation', 'ar': 'التعزيز المتعدد المعاد صياغته للاستفادة من ترجمة التسمية التوضيحية العصبية', 'fr': 'Augmentation des paraphrases multiples pour tirer parti de la traduction neuronale des sous-titres', 'es': 'Aumento de múltiples paráfrasis para aprovechar la traducción de subtítulos neuronales', 'pt': 'Aumento de várias paráfrases para alavancar a tradução de legendas neurais', 'ja': 'ニューラルキャプション翻訳を活用するためのマルチパラフレーズ拡張', 'zh': '多释义增用神经字幕译', 'ru': 'Многопарафразовое расширение для использования перевода нейронных заголовков', 'hi': 'बहु-व्याख्या संवर्धन तंत्रिका कैप्शन अनुवाद का लाभ उठाने के लिए', 'ga': 'Méadú Il-athfhorsa chun Aistriú Fotheideal Néaracha a Ghiaráil', 'el': 'Ενίσχυση πολλαπλών παραφράσεων για να αξιοποιήσει τη μετάφραση νευρωνικών λεζάντων', 'kk': 'Көп парафразы Нейралық айдарының аудармасына көбейту', 'ka': 'Multi paraphrase Augmentation to Leverage Neural Caption Translation', 'hu': 'Több parafrázisú bővítés az idegi felirat fordításának kihasználására', 'lt': 'Daugiaparafrazės Augmentavimas, siekiant išreikšti neurologinio frazės vertimą', 'it': 'Aumento multi-parafrasi per sfruttare la traduzione della didascalia neurale', 'mk': 'Multi-paraphrase Augmentation to Leverage Neural Caption Translation', 'ms': 'Penjemahan Capsi Neural Berbilang-parafrasa', 'ml': 'ലെവരേജ് ന്യൂറല്\u200d തലക്കെട്ടിന്റെ വിവരങ്ങള്\u200d', 'mn': 'Олон хэлбэрээр хэлбэрээр сэтгэл санааны сэтгэл хөрөнгө хөрөнгө оруулах', 'no': 'Multiparafrase- augmentation to Leverage Neural Caption Translation', 'sr': 'Višeparafraza povećanje neuronskog prevoda', 'mt': 'Multi-parafrażi Żieda fil-Livell tat-Traduzzjoni tal-Kaptazzjoni Newrali', 'pl': 'Rozszerzenie wielu parafraz w celu wykorzystania tłumaczenia napisów neuronowych', 'ro': 'Augmentarea cu mai multe parafraze pentru a stimula traducerea textului neural', 'so': 'Turjumidda qoraalka Neural Caption Neural', 'sv': 'Förstärkning med flera parafraser för att utnyttja översättning av neural bildtext', 'ta': 'எழுத்துரு நெருக்கல் தலைப்பு மொழிபெயர்ப்பு மொழிபெயர்ப்பு', 'ur': 'Multi paraphrase Augmentation to Leverage Neural Caption Translation', 'si': 'MultiparaPhrase', 'uz': 'Name', 'vi': 'Tăng tốc độ bắt cóc thần kinh', 'bg': 'Многопарафразово увеличение за използване на превода на неврални надписи', 'nl': 'Multi-parafrase Augmentatie om gebruik te maken van neurale ondertiteling vertaling', 'hr': 'Višeparafraza Povećavanje Neuralnog prevoda', 'da': 'Forstærkning med flere parafraser til at udnytte oversættelse af neural billedtekst', 'id': 'Multi-parafrasa Augmentation to Leverage Neural Caption Translation', 'fa': 'افزایش چند عبارت به ترجمه عنوان عصبی', 'de': 'Multi-Paraphrasen-Erweiterung zur Nutzung der Übersetzung neuronaler Bildunterschriften', 'ko': '신경 자막 번역의 다중 해석을 이용하여 확장하다', 'sw': 'Multi-paraphrase Augmentation to Leverage Neural Caption Translation', 'tr': 'Çoklu-paraphraz Jemi Taýýarlama', 'sq': 'Shumë parafraza rritje në nivelin e përkthimit të titullit neuronal', 'af': 'Multi paraphrase Augmentation to Leverage Neural Caption Translation', 'am': 'ምርጫዎች', 'hy': 'Բազմաարտահայտություն', 'az': 'Multi paraphrase Augmentation to Leverage Neural Caption Translation', 'bn': 'লেভারেজ নিউরেল শিরোনাম অনুবাদ', 'bs': 'Višeparafraza povećanje neuronskog prevoda', 'ca': 'Multi-parafrases Augmentation to Leverage Neural Caption Translation', 'cs': 'Víceparafrázové rozšíření k využití překladu neuronových titulků', 'et': 'Mitme parafraasi suurendamine neuropealkirja tõlkimise võimendamiseks', 'fi': 'Usean parafraasin lisäys neurokuvatekstin kääntämiseen', 'jv': 'structural navigation', 'ha': 'Multi-paraphrase Augmentation to Leverage Neural Caption Translation', 'he': 'תורגם וסונכרן ע"י Qsubs מצוות', 'sk': 'Večparafrazna povečanje za spodbujanje prevoda nevronskih napisov', 'bo': 'Leverage Neural Caption Translation'}
{'en': 'Paraphrasing has been proven to improve translation quality in  machine translation (MT)  and has been widely studied alongside with the development of  statistical MT (SMT) . In this paper, we investigate and utilize neural paraphrasing to improve  translation quality  in neural MT (NMT), which has not yet been much explored. Our first contribution is to propose a new way of creating a multi-paraphrase corpus through visual description. After that, we also proposed to construct neural paraphrase models which initiate expert models and utilize them to leverage NMT. Here, we diffuse the image information by using image-based paraphrasing without using the image itself. Our proposed image-based multi-paraphrase augmentation strategies showed improvement against a vanilla NMT baseline.', 'ar': 'لقد ثبت أن إعادة الصياغة تعمل على تحسين جودة الترجمة في الترجمة الآلية (MT) وتمت دراستها على نطاق واسع جنبًا إلى جنب مع تطوير الترجمة الآلية (SMT). في هذه الورقة ، نقوم بالتحري عن إعادة الصياغة العصبية واستخدامها لتحسين جودة الترجمة في الترجمة الآلية العصبية (NMT) ، والتي لم يتم استكشافها كثيرًا بعد. تتمثل مساهمتنا الأولى في اقتراح طريقة جديدة لإنشاء مجموعة إعادة صياغة متعددة من خلال الوصف المرئي. بعد ذلك ، اقترحنا أيضًا إنشاء نماذج إعادة الصياغة العصبية التي تبدأ نماذج الخبراء واستخدامها للاستفادة من NMT. هنا ، ننشر معلومات الصورة باستخدام إعادة الصياغة القائمة على الصورة دون استخدام الصورة نفسها. أظهرت إستراتيجياتنا المقترحة لتقوية الصيغة المتعددة المعاد صياغتها والقائمة على الصور تحسنًا مقابل خط الأساس لـ NMT الفانيليا.', 'fr': "Il a été prouvé que la paraphrase améliore la qualité de la traduction en traduction automatique (TA) et a fait l'objet de nombreuses études parallèlement au développement de la TA statistique (SMT). Dans cet article, nous étudions et utilisons la paraphrase neuronale pour améliorer la qualité de la traduction dans la MT neuronale (NMT), qui n'a pas encore été beaucoup explorée. Notre première contribution est de proposer une nouvelle façon de créer un corpus multi-paraphrase par description visuelle. Ensuite, nous avons également proposé de construire des modèles de paraphrase neurale qui initient des modèles experts et les utilisent pour tirer parti de la NMT. Ici, nous diffusons les informations de l'image en utilisant une paraphrase basée sur l'image sans utiliser l'image elle-même. Nos stratégies d'augmentation multi-paraphrase basées sur l'image proposées ont montré une amélioration par rapport à une base de référence NMT standard.", 'pt': 'Foi comprovado que a paráfrase melhora a qualidade da tradução na tradução automática (TA) e tem sido amplamente estudada juntamente com o desenvolvimento da TA estatística (SMT). Neste artigo, investigamos e utilizamos a paráfrase neural para melhorar a qualidade da tradução em MT neural (NMT), que ainda não foi muito explorada. Nossa primeira contribuição é propor uma nova maneira de criar um corpus multiparáfrase por meio da descrição visual. Depois disso, também propusemos construir modelos de paráfrase neural que iniciam modelos especialistas e os utilizam para alavancar a NMT. Aqui, difundimos as informações da imagem usando paráfrases baseadas em imagens sem usar a própria imagem. Nossas estratégias de aumento de múltiplas paráfrases baseadas em imagens mostraram melhorias em relação a uma linha de base NMT de baunilha.', 'es': 'Se ha demostrado que la paráfrasis mejora la calidad de la traducción en la traducción automática (MT) y se ha estudiado ampliamente junto con el desarrollo de la MT estadística (SMT). En este artículo, investigamos y utilizamos la paráfrasis neuronal para mejorar la calidad de la traducción en la MT neuronal (NMT), que aún no se ha explorado mucho. Nuestra primera contribución es proponer una nueva forma de crear un corpus de múltiples paráfrasis a través de la descripción visual. Después de eso, también propusimos construir modelos de paráfrasis neuronal que iniciaran modelos expertos y los utilizaran para aprovechar la NMT. Aquí, difundimos la información de la imagen mediante la paráfrasis basada en imágenes sin usar la propia imagen. Nuestras estrategias de aumento multiparáfrasis basadas en imágenes propuestas mostraron una mejora con respecto a una base de referencia básica de NMT.', 'ja': 'パラフレーズは、機械翻訳（ MT ）における翻訳品質を向上させることが証明されており、統計的MT （ SMT ）の開発とともに広く研究されています。本論文では、神経MT （ NMT ）における翻訳品質を向上させるために、神経パラフレーズを調査し、利用しているが、これはまだあまり研究されていない。私たちの最初の貢献は、視覚的な説明を通じて多言語コーパスを作成する新しい方法を提案することです。その後、専門家モデルを開始し、NMTを活用するニューラルパラフレーズモデルを構築することも提案しました。ここでは、画像自体を用いず、画像ベースのパラフレーズを用いて画像情報を拡散する。提案された画像ベースのマルチパラフレーズ拡張戦略は、バニラNMTベースラインに対して改善を示しました。', 'zh': '释义已证增机器翻译(MT)译,随计机器翻译(SMT)广究。 本文之中,研用神经释义以崇神经机器翻译(NMT)译,未得太多。 首献以视创多释义语料库之新法。 既而议为神经释义模,宜启而用之NMT。 于此,吾以释义散之,不以其身。 所陈多图像释义增强策略见NMT基线改。', 'ru': 'Было доказано, что перефразирование улучшает качество перевода в машинном переводе (MT) и широко изучалось наряду с разработкой статистического MT (SMT). В этой статье мы исследуем и используем нейронное перефразирование для улучшения качества перевода в нейронном MT (NMT), которое еще не было изучено. Наш первый вклад заключается в том, чтобы предложить новый способ создания многопарафразового корпуса посредством визуального описания. После этого мы также предложили построить модели нейронного перефразирования, которые инициируют экспертные модели и используют их для использования NMT. Здесь мы распространяем информацию об изображении, используя перефразирование на основе изображения без использования самого изображения. Наши предлагаемые стратегии мультипарафразного увеличения на основе изображений показали улучшение по сравнению с базовым уровнем ванили NMT.', 'hi': 'मशीन अनुवाद (एमटी) में अनुवाद की गुणवत्ता में सुधार करने के लिए पैराफ्रेसिंग साबित हुआ है और सांख्यिकीय एमटी (एसएमटी) के विकास के साथ-साथ व्यापक रूप से अध्ययन किया गया है। इस पेपर में, हम तंत्रिका एमटी (एनएमटी) में अनुवाद की गुणवत्ता में सुधार करने के लिए तंत्रिका व्याख्या की जांच और उपयोग करते हैं, जिसे अभी तक बहुत अधिक पता नहीं लगाया गया है। हमारा पहला योगदान दृश्य विवरण के माध्यम से एक बहु-व्याख्या कॉर्पस बनाने का एक नया तरीका प्रस्तावित करना है। उसके बाद, हमने तंत्रिका व्याख्या मॉडल का निर्माण करने का भी प्रस्ताव दिया जो विशेषज्ञ मॉडल शुरू करते हैं और एनएमटी का लाभ उठाने के लिए उनका उपयोग करते हैं। यहां, हम छवि का उपयोग किए बिना छवि-आधारित पैराफ्रेसिंग का उपयोग करके छवि जानकारी को फैलाते हैं। हमारी प्रस्तावित छवि-आधारित बहु-व्याख्यात्मक वृद्धि रणनीतियों ने एक वेनिला एनएमटी बेसलाइन के खिलाफ सुधार दिखाया।', 'ga': 'Tá sé cruthaithe go bhfeabhsaítear cáilíocht an aistriúcháin san aistriúchán meaisín (MT) ag athinsint agus rinneadh staidéar forleathan air in éineacht le forbairt MT staidrimh (SMT). Sa pháipéar seo, déanaimid imscrúdú agus úsáid as athinsint néarach chun cáilíocht an aistriúcháin i MT néarúil (NMT) a fheabhsú, rud nach bhfuil mórán fiosraithe déanta fós. Is é an chéad rannchuidiú atá againn ná bealach nua a mholadh chun corpas ilfhoclach a chruthú trí chur síos amhairc. Ina dhiaidh sin, mholamar freisin samhlacha néaracha athfhrása a thógáil a thionscnaíonn múnlaí saineolaithe agus a úsáidfidh iad chun NMT a ghiaráil. Anseo, déanaimid an fhaisnéis íomhá a idirleathadh trí athinsint bunaithe ar íomhá a úsáid gan an íomhá féin a úsáid. Thaispeáin ár straitéisí méadaithe ilfhorleathana íomhá-bhunaithe feabhsaithe i gcomparáid le bunlíne fanaile NMT.', 'ka': 'პარაფრაზაცია მოწმებულია, რომ მანქანის გაგრძელებით (MT) განახლებაში უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო მე ამ დომენტში ჩვენ ინტერსტირებით და გამოყენებით ნეიროლური პარაფრაზაციას, რომელიც ნეიროლური MT (NMT) წარმოქმედებით, რომელიც კი უფრო არ აღმოქმედება. ჩვენი პირველი დამატება არის ახალი საზოგადომის შექმნა მრავალ პარაფეზის კორპუსს ვიზუალური გამოსახულებით. შემდეგ ჩვენ შეგვეძლო ნეიროლური პარაფრეზის მოდელების შექმნა, რომლებიც ექსპერტის მოდელების დავიწყება და გამოყენება, რომ NMT-ს გამოყენება. აქ, ჩვენ გამოსახულების ინფორმაციას გამოყენებთ გამოსახულებული პარაფრაზაციის გამოყენებით გამოყენებული გამოსახულება. ჩვენი საზოგადოებული მრავალ პარაფიზაციის სტრატიგიები გამოსახულებულია, რომლებიც განილია NMT ბაზილური სტრატიზაციის შესაძლებლობად გაუქმნა.', 'hu': 'A parafrázás bizonyítottan javítja a fordítási minőséget a gépi fordításban (MT), és széles körben tanulmányozták a statisztikai MT (SMT) fejlesztésével párhuzamosan. Ebben a tanulmányban a neurális parafrázást vizsgáljuk és használjuk fel a neurális MT (NMT) fordítási minőségének javítására, ami még nem sokat vizsgált. Az első hozzájárulásunk az, hogy új módszert javasoljunk egy többparafrázisú korpusz létrehozására vizuális leírással. Ezt követően azt is javasoltuk, hogy olyan neurális parafrázismodelleket építsünk, amelyek szakértői modelleket kezdeményeznek és felhasználják őket az NMT kihasználására. Itt a kép információit kép alapú parafrázással terjesztjük el anélkül, hogy magát a képet használnánk. A javasolt kép alapú multi-parafrázis augmentációs stratégiáink javulást mutattak a vanília NMT kiindulási értékhez képest.', 'el': 'Η παράφραση έχει αποδειχθεί ότι βελτιώνει την ποιότητα της μετάφρασης στη μηχανική μετάφραση (ΜΤ) και έχει μελετηθεί ευρέως παράλληλα με την ανάπτυξη της στατιστικής ΜΤ (SMT). Στην παρούσα εργασία, ερευνούμε και χρησιμοποιούμε τη νευρωνική παράφραση για τη βελτίωση της ποιότητας μετάφρασης στο νευρωνικό ΜΤ (NMT), το οποίο δεν έχει ακόμη διερευνηθεί πολύ. Η πρώτη μας συνεισφορά είναι να προτείνουμε έναν νέο τρόπο δημιουργίας ενός σώματος πολλαπλών παραφράσεων μέσω οπτικής περιγραφής. Μετά από αυτό, προτείναμε επίσης να κατασκευάσουμε μοντέλα νευρωνικής παραφράσης τα οποία ξεκινούν μοντέλα εμπειρογνωμόνων και τα χρησιμοποιούν για να αξιοποιήσουν την NMT. Εδώ, διαχέουμε τις πληροφορίες της εικόνας χρησιμοποιώντας παράφραση βασισμένη στην εικόνα χωρίς να χρησιμοποιούμε την ίδια την εικόνα. Οι προτεινόμενες στρατηγικές αύξησης πολλαπλών παραφράσεων με βάση την εικόνα έδειξαν βελτίωση έναντι μιας βάσης NMT βανίλιας.', 'lt': 'Įrodyta, kad parafrazė pagerino vertimo raštu kokybę mašin ų vertimo raštu (MT) ir buvo plačiai tiriama kartu su statistinio MT (SMT) kūrimu. In this paper, we investigate and utilize neural paraphrasing to improve translation quality in neural MT (NMT), which has not yet been much explored.  Pirmasis mūsų indėlis - pasiūlyti naują kelių parafrazių korpuso kūrimo būdą per vizualinį aprašymą. Po to taip pat pasiūlėme sukurti nervų parafrazės modelius, kurie inicijuotų ekspertų modelius ir juos panaudotų NMT svertui. Čia mes skleidžiame vaizdo informaciją naudojant vaizdo parafrazę, nenaudodami paties vaizdo. Mūsų pasiūlytos įvaizdžiu pagrįstos daugialypės parafrazės didinimo strategijos parodė pagerėjimą, palyginti su vanilinės NMT pradine verte.', 'mk': 'Парафразирањето се докажа дека го подобрува квалитетот на преводот во машинскиот превод (МТ) и беше широко проучено заедно со развојот на статистички МТ (СМТ). Во овој весник, ние истражуваме и користиме нервна парафразирање за подобрување на квалитетот на преводот во нервниот МТ (НМТ), кој сé уште не е многу истражен. Нашиот прв придонес е да предложиме нов начин за создавање мултипарафразен тело преку визуелен опис. После тоа, ние, исто така, предложивме конструкција на модели за нервна парафраза кои иницираат експертски модели и ги искористуваат за да се искористат НМТ. Овде, ги разнесуваме информациите за сликата користејќи парафразирање базирано на слика без користење на самата слика. Нашите предложени стратегии за зголемување на мултипарафрази базирани на слики покажаа подобрување во однос на базата на ванила НМТ.', 'kk': 'Парафразация машинаның аудармасының (MT) сапасында аудармасының сапасын жақсарту үшін тексерілді, және статистикалық MT (SMT) жасауымен бірге көп оқылған. Бұл қағазда невралдық парафразын зерттеу және қолдану үшін невралдық MT (NMT) сапасында аудару сапатын жақсарту үшін қолдануға болады. Бұл қағазда әлі білмеген. Біздің бірінші қатынасыз - визуалдық сипаттамасы арқылы көп парафраз корпус құру жаңа жолын ұсыну. Содан кейін біз невралдық парафраз үлгілерін құру және оны NMT үшін қолдану үшін қолданатын невралдық парафраз үлгілерін құру үшін ұсындық. Мұнда, кескіндің мәліметін кескіндің негіздеген парафразын қолдану арқылы түрлендіреміз. Кескіннің негіздеген көп парафраз көптегенциялық стратегияларымыз vanilla NMT негіздегі жолына қарсы жақсарту көрсетілді.', 'it': "La parafrasazione ha dimostrato di migliorare la qualità della traduzione nella traduzione automatica (MT) ed è stata ampiamente studiata insieme allo sviluppo della MT statistica (SMT). In questo articolo, esaminiamo e utilizziamo la parafrasi neurale per migliorare la qualità della traduzione nella MT neurale (NMT), che non è ancora stata molto esplorata. Il nostro primo contributo è quello di proporre un nuovo modo di creare un corpus multiparafrasico attraverso la descrizione visiva. Dopo di che, abbiamo anche proposto di costruire modelli di parafrasi neurali che avviano modelli esperti e li utilizzano per sfruttare NMT. Qui diffondiamo le informazioni dell'immagine utilizzando la parafrasi basata sull'immagine senza utilizzare l'immagine stessa. Le nostre strategie di aumento multi-parafrasi proposte hanno mostrato un miglioramento rispetto a un basale NMT vanilla.", 'mn': 'Paraphrasing нь машины хөгжүүлэлт (MT) дээр хөгжүүлэх чадварыг сайжруулж, статистикийн MT (SMT) хөгжүүлэлтийн хамтдаа шинэ судалгаа хийгдсэн. Энэ цаасан дээр бид мэдрэлийн парафразыг судалж, ашиглаж, мэдрэлийн MT (NMT) дээр хөгжүүлэх чадварыг сайжруулахын тулд олон судалгаагүй. Бидний анхны зорилго бол харааны тодорхойлолтоор олон хэлбэрийн корпус бүтээх шинэ арга замыг санал болгох юм. Үүнээс дараа нь бид нарийн мэдрэлийн парафрейз загваруудыг бүтээж, NMT-г ашиглан ашигладаг мэдрэлийн парафрейз загваруудыг бүтээхийг санал болгосон. Энд бид зургийн мэдээллийг зураг дээр суурилсан парафразыг өөрийгөө ашиглахгүй ашиглаж хувааж байна. Бидний санал өгсөн зураг дээр суурилсан олон хэлбэрүүдийн нэмэлт стратеги нь vanilla NMT суурь шугамын эсрэг сайжруулалтыг харуулсан.', 'ms': 'Parafrasasi telah dibuktikan untuk meningkatkan kualiti terjemahan dalam terjemahan mesin (MT) dan telah dipelajari secara luas bersama dengan pembangunan MT statistik (SMT). Dalam kertas ini, kami menyelidiki dan menggunakan parafrasa saraf untuk meningkatkan kualiti terjemahan dalam MT saraf (NMT), yang belum banyak diteliti. Kontribusi pertama kita adalah untuk melamar cara baru untuk mencipta mayat multi-parafrasa melalui keterangan visual. Selepas itu, kami juga melamar untuk membina model parafrasa saraf yang memulakan model pakar dan menggunakannya untuk menggunakan NMT. Di sini, kita menyebarkan maklumat imej dengan menggunakan parafrasa berasaskan imej tanpa menggunakan imej sendiri. Our proposed image-based multi-paraphrase augmentation strategies showed improvement against a vanilla NMT baseline.', 'ml': 'മെഷിന്\u200d പരിഭാഷത്തിന്റെ (എംടി) പരിഭാഷത്തിന്റെ ഗുണവും മെച്ചപ്പെടുത്തുവാന്\u200d പാരാപ്പ്രസിദ്ധീകരിച്ചിരിക്കുന്നു. എസ്എ ഈ പത്രത്തില്\u200d നമ്മള്\u200d അന്വേഷിക്കുകയും ഉപയോഗിക്കുകയും ചെയ്യുന്നു. ന്യൂറല്\u200d എംഎംടി (NMT) ന്യൂറലിലെ പരിഭാഷണത്തിന്റെ ഗുണവും മെ നമ്മുടെ ആദ്യത്തെ ഭാഗമെന്തെന്നാല്\u200d അതിനു ശേഷം നമ്മളും ന്യൂറല്\u200d പാരാഫ്രേസ് മോഡലുകള്\u200d നിര്\u200dമ്മിക്കാന്\u200d പ്രൊദ്ദേശിച്ചു. അത് വിശേഷിപ്പുകാരുടെ മോഡലുകള്\u200d തു ഇമേജ് സ്വയം ഉപയോഗിക്കാതെ ചിത്ര വിവരങ്ങള്\u200d ഉപയോഗിച്ച് ചിത്ര വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നു. നമ്മുടെ പ്രൊദ്ദേശിച്ച ചിത്രത്തിന്റെ അടിസ്ഥാനത്തുള്ള പല-പാരാഫ്രേഷന്\u200d കൂടുതല്\u200d കൂടുതല്\u200d പദ്ധതികള്\u200d വാനില്ലാത', 'mt': 'Il-parafrażizzazzjoni ntweriet li ttejjeb il-kwalità tat-traduzzjoni fit-traduzzjoni bil-magna (MT) u ġiet studjata b’mod wiesa’ flimkien mal-iżvilupp ta’ MT statistiku (SMT). F’dan id-dokument, ninvestigaw u nużaw parafrażizzazzjoni newrali biex itejbu l-kwalità tat-traduzzjoni f’MT newrali (NMT), li għadu ma ġiex esplorat ħafna. L-ewwel kontribut tagħna huwa li nipproponu mod ġdid kif jinħoloq korpus b’parafrażi multipla permezz ta’ deskrizzjoni viżwali. After that, we also proposed to construct neural paraphrase models which initiate expert models and utilize them to leverage NMT.  Hawnhekk, aħna nxerrdu l-informazzjoni dwar l-immaġni billi nużaw parafrażizzazzjoni bbażata fuq l-immaġni mingħajr ma nużaw l-immaġni nnifisha. L-istrateġiji ta’ żieda ta’ multi-parafrażi bbażati fuq l-immaġni proposti tagħna wrew titjib meta mqabbla mal-linja bażi tal-vanilla NMT.', 'pl': 'Udowodniono, że parafrazowanie poprawia jakość tłumaczeń w tłumaczeniu maszynowym (MT) i było szeroko badane wraz z rozwojem statystycznego MT (SMT). W niniejszym artykule badamy i wykorzystujemy parafrazowanie neuronowe w celu poprawy jakości tłumaczenia w neuronowej MT (NMT), która jeszcze nie została zbyt zbadana. Naszym pierwszym wkładem jest zaproponowanie nowego sposobu tworzenia wieloparafrazowego korpusu poprzez opis wizualny. Następnie zaproponowaliśmy również skonstruowanie neuronowych modeli parafrazy, które inicjują eksperckie modele i wykorzystują je do wykorzystania NMT. Tutaj rozproszamy informacje o obrazie poprzez parafrazowanie oparte na obrazie bez używania samego obrazu. Nasze proponowane strategie powiększania obrazów oparte na wielu parafrazach wykazały poprawę w stosunku do bazy bazowej NMT waniliowej.', 'ro': 'S-a dovedit că parafrazarea îmbunătățește calitatea traducerii în traducerea automată (MT) și a fost studiată pe scară largă alături de dezvoltarea MT statistică (SMT). În această lucrare, investigăm și utilizăm parafrazarea neurală pentru a îmbunătăți calitatea traducerii în MT neurală (NMT), care nu a fost încă explorată mult. Prima noastră contribuție este să propunem un nou mod de a crea un corpus multi-parafrază prin descrierea vizuală. După aceea, am propus, de asemenea, construirea de modele de parafrază neurală care inițiază modele de experți și le utilizează pentru a valorifica NMT. Aici, difuzăm informațiile de imagine folosind parafrazarea bazată pe imagine, fără a utiliza imaginea în sine. Strategiile noastre de augmentare multi-parafrază propuse au arătat îmbunătăţiri faţă de valoarea iniţială a NMT vanilie.', 'no': 'Parafrasing er prøvd å forbetra omsetjingskvalitet i maskinsomsetjinga (MT), og er veldig studiert saman med utviklinga av statistiske MT (SMT). I denne papiret er vi undersøk og bruk neuralparafrasing for å forbetra omsetjingskvalitet i neural MT (NMT), som enno ikkje er noko mykje utforska. Første bidrag vårt er å foreslå ein ny måte å laga eit multiparafrase korpus gjennom visuell skildring. Etter det, har vi også foreslått å konstruere neuralparafrase-modeller som startar ekspertmodeller og brukar dei for å levera NMT. Her diffuserer vi biletformasjonen ved å bruka biletbasert parafrasing utan å bruka biletet sjølv. Våre foreslått fleire-parafrase-økingsstrategiar viste forbedringar mot ein vanillisk NMT-baseline.', 'so': "Paraphrasing waxaa loo caddeeyey in loo kordhiyo qiimaha turjumista machine turjumista (MT) iyo in loo baray widely along with the development of statistical MT (SMT). Qoraalkan waxaynu baaritaan oo isticmaalnaa baaritaanka neurada si aan u kordhinno qiimaha turjumista (NMT) ee neural MT (NMT), kaas oo aan weli wax badan la baarayn. Kharashadanada ugu horeysa waa in loo soo jeedo qaab cusub oo ku sameynta koob kala duduwan oo muuqasho ah. Markaas kadib waxaynu soo jeednay in aan dhisno modelal naxaad ah, taasoo bilowda modelal khabiir ah oo u isticmaalaya in loo soo diro NMT. Halkan, waxaynu isticmaalnaa macluumaadka sawirka si aan isticmaalin sawirka. Qorshooyinkeena kordhiska ee sawirkayada la soo jeeday oo ku qoran qoraal kala duduwan ayaa ka muuqatay horumarin ka hor jeeda sameynta qoraalka NMT ee baabba'a ah.", 'si': 'පැරැෆ්\u200dරේසින්ග් සාක්ෂිත විශේෂයක් පද්ධතිය පද්ධතිය (MT) වලින් වාර්ථාවක් විශේෂය කරන්න සාක්ෂිත විදියට පරි මේ පත්තරේ අපි පරීක්ෂණය කරන්න සහ ප්\u200dරයෝජනය කරන්නේ න්\u200dයූරාල් පැරැෆ්\u200dරේසින් විශේෂය සඳහා න්\u200dයූරාල් MT (NMT) වලින් ව අපේ පළමු ප්\u200dරධාන ප්\u200dරශ්නයක් තමයි විස්තර විස්තරයෙන් අලුත් ප්\u200dරශ්නයක් නිර්මාණය කරන්න. ඊට පස්සේ, අපි න්\u200dයූරාල් පැරැෆේස් මොඩේල් නිර්මාණය කරන්න පුළුවන් වුණා, ඒ වගේම විශ්වාසිත විදියට පටන් ගන් මෙන්න, අපි පින්තූර තොරතුරු පින්තූර පින්තූරය සඳහා පින්තූර පරාෆ්\u200dරේසින් භාවිත කරන්න. අපේ පින්තූරය අධාරිත විශේෂ විශේෂ විශේෂ විශේෂ ප්\u200dරදේශය පෙන්වන්න පුළුවන් වැනිලා NMT පස', 'sv': 'Parafrasering har visat sig förbättra översättningskvaliteten inom maskinöversättning (MT) och har studerats brett tillsammans med utvecklingen av statistisk MT (SMT). I denna uppsats undersöker och använder vi neural parafrasering för att förbättra översättningskvaliteten i neural MT (NMT), vilket ännu inte har utforskats särskilt mycket. Vårt första bidrag är att föreslå ett nytt sätt att skapa en multiparafraskorpus genom visuell beskrivning. Efter det föreslog vi också att bygga neurala parafrasmodeller som initierar expertmodeller och använder dem för att utnyttja NMT. Här sprider vi bildinformationen genom att använda bildbaserad parafrasering utan att använda själva bilden. Våra föreslagna bildbaserade multi-parafrase augmentation strategier visade förbättring jämfört med en vanilj NMT baslinje.', 'sr': 'Parafrazacija je dokazana kako bi poboljšala kvalitet prevoda u prevodu mašine (MT) i široko je proučena zajedno s razvojom statističkog MT (SMT). U ovom papiru istražujemo i iskoristavamo neuralnu parafrazaciju kako bi poboljšali kvalitet prevoda u neuralnom MT-u (NMT), koja još nije mnogo istražena. Naš prvi doprinos je da predložimo novi način stvaranja multiparafraze korpusa kroz vizuelni opis. Nakon toga smo takođe predložili da izgradimo modele neuralne parafraze koji pokreću ekspertne modele i iskoristimo ih za primjenu NMT-a. Ovde širimo informacije o slikama koristeći parafrazaciju na osnovu slike bez samog korištenja slike. Naša predložena strategija povećanja multiparafraze na osnovu slike pokazala je poboljšanje protiv početne linije vanile NMT-a.', 'ta': 'கணினி மொழிபெயர்ப்பில் மொழிபெயர்ப்பு தரம் (MT) மேம்படுத்த தெளிவாக்கப்பட்டுள்ளது மற்றும் புள்ளிவிவரமான MT (SMT) உருவாக்கத்து இந்த காகிதத்தில், நாம் புதிய மொழிபெயர்ப்பினை உபயோகிக்க மற்றும் பயன்படுத்துகிறோம் மொழிபெயர்ப்பு தரம் மேம்படுத்துவதற்கு, அது  எங்கள் முதல் பங்கு பார்வை விவரிப்பு மூலம் ஒரு புதிய வழியை உருவாக்குவதற்கு தான். இதன் பின்னர், நாம் புதிய புதிய கூற்று மாதிரிகளை உருவாக்க வேண்டும், அது சிறப்பான மாதிரிகளை ஆரம்பிக்கிறது மற்றும் NMT கொடு பிம்பம் தன்னைப் பயன்படுத்தாமல் பிம்பத்தின் தகவலை பயன்படுத்தி பிம்பத்தை பயன்படுத்தி வேறுபடுத்துகிறோம். Our proposed image-based multi-paraphrase augmentation strategies showed improvement against a vanilla NMT baseline.', 'ur': 'پارافریزنگ مشین ترجمہ (MT) میں ترجمہ کی کیفیت کو بہتر کرنے کے لئے ثابت کی گئی ہے اور ایسٹیسٹی MT (SMT) کی توسعہ کے ساتھ بہت وسیع تحقیق کی گئی ہے۔ اس کاغذ میں ہم نے نئورل پارافریزنگ کی تحقیق اور استعمال کی کہ نئورل مٹی (NMT) میں ترجمہ کیفیت کو زیادہ زیادہ تحقیق کرنے کے لئے، جو اب بھی زیادہ تحقیق نہیں کی گئی۔ ہمارا پہلا حصہ یہ ہے کہ ایک نئی طریقہ پیشنهاد کرنا ہے کہ ایک بہت سی فریز کورپوس بنانے کے ذریعہ تصویر کے ذریعہ۔ اس کے بعد ہم نے نئورل پارافریز موڈل بنانے کی پیشنهاد کی ہے جو مطابق موڈل آغاز کرتا ہے اور ان کو NMT کے ذریعے استعمال کرتا ہے یہاں، ہم تصویر کی اطلاعات کو پھیلاتے ہیں تصویر کے بغیر پھیر پھیر پھیر پھیر کر۔ ہماری پیشنهاد کی تصویر کی بنیاد پر متعدد فریز اضافہ استراتژی نے vanilla NMT بنیاس لین کے مقابلے میں اضافہ کی۔', 'uz': "Name Bu qogʻozda biz bir necha ko'p qidirilmagan neural paraphraslardan foydalanamiz. Bizning birinchi qandaydir ko'proq taʼrif bilan bir necha paraphras corpusni yaratish uchun yangi yo'l qilish. Keyin biz yana yaxshiroq modellarni ishga tushirish va ularni NMT yozib qo'llash uchun foydalanishni istaysiz. Bu yerda rasm maʼlumotini rasm asosida paraphrasing yordamida boʻlishimiz mumkin. Tahrirlangan rasm asosida bir necha paraphras qo'shish strategiyasi vanillar NMT asosiy satrlariga yaxshi ko'paydi.", 'vi': 'Siêu dàn đã được chứng minh là cải thiện chất dịch trong dịch vụ máy (MTV) và đã được nghiên cứu rộng cùng với việc phát triển thống kê MTV (SMT). Trong tờ giấy này, chúng tôi nghiên cứu và sử dụng các hình ảnh thần kinh để cải thiện chất dịch của kênh gan thần kinh (NMB) mà chưa được khám phá nhiều. Đầu tiên chúng tôi góp phần đề xuất một cách mới để tạo ra một tập thể hình ảnh đầy đủ. Sau đó, chúng tôi cũng đề xuất xây dựng các mô hình ảnh thần kinh, cung cấp các mô hình chuyên gia và sử dụng chúng để sử dụng NMT. Ở đây, chúng tôi khuếch tán thông tin ảnh bằng cách sử dụng sự diễn giải ảnh mà không dùng ảnh. Các chiến lược gia tăng đột biến hình ảnh của chúng tôi cho thấy cải tiến so với đường cơ bản NMB vani.', 'bg': 'Доказано е, че парафразирането подобрява качеството на превода в машинния превод (МТ) и е широко проучено заедно с развитието на статистическия МТ (МТ). В тази статия ние изследваме и използваме неврално парафразиране за подобряване качеството на превода в невралното МТ (НМТ), което все още не е много проучено. Първият ни принос е да предложим нов начин за създаване на многопарафразен корпус чрез визуално описание. След това предложихме и изграждането на невронни парафразни модели, които инициират експертни модели и ги използват за използване на НМТ. Тук разпространяваме информацията за изображението чрез парафразиране, базирано на изображение, без да използваме самото изображение. Нашите предложения, базирани на изображения мулти-парафразни стратегии за увеличаване показаха подобрение спрямо базовата база на ваниловата НМТ.', 'da': 'Parafrasering har vist sig at forbedre oversættelseskvaliteten i maskinoversættelse (MT) og er blevet omfattende undersøgt sideløbende med udviklingen af statistisk MT (SMT). I denne artikel undersøger og bruger vi neural parafrasering til at forbedre oversættelseskvaliteten i neural MT (NMT), som endnu ikke er blevet meget udforsket. Vores første bidrag er at foreslå en ny måde at skabe et multiparaphrasekorpus på gennem visuel beskrivelse. Derefter foreslog vi også at konstruere neurale parafrasemodeller, der starter ekspertmodeller og bruger dem til at udnytte NMT. Her spreder vi billedets information ved hjælp af billedbaseret parafrasering uden at bruge selve billedet. Vores foreslåede billedbaserede multi-parafrase augmentation strategier viste forbedring i forhold til en vanilje NMT baseline.', 'nl': 'Parafraseren is bewezen om de vertaalkwaliteit in machinevertaling (MT) te verbeteren en is uitgebreid bestudeerd samen met de ontwikkeling van statistische MT (SMT). In dit artikel onderzoeken en gebruiken we neurale parafrasering om de vertaalkwaliteit in neurale MT (NMT) te verbeteren, wat nog niet veel onderzocht is. Onze eerste bijdrage is om een nieuwe manier voor te stellen om een multi-parafrase corpus te creëren door middel van visuele beschrijving. Daarna hebben we ook voorgesteld neurale parafrasemmodellen te bouwen die expertmodellen initiëren en deze gebruiken om NMT te gebruiken. Hier verspreiden we de beeldinformatie door beeldgebaseerde parafrasering te gebruiken zonder het beeld zelf te gebruiken. Onze voorgestelde image-based multi-parafrase augmentatie strategieën toonden verbetering ten opzichte van een vanille NMT baseline.', 'hr': 'Parafrazacija je dokazana kako bi poboljšala kvalitet prevoda u prevodu strojeva (MT) i široko je proučena zajedno s razvojom statističkog MT-a (SMT). U ovom papiru istražujemo i iskoristavamo neuralnu parafrazaciju kako bi poboljšali kvalitet prevoda u neuralnom MT-u (NMT), koja još nije bila mnogo istražena. Naš prvi doprinos je da predložimo novi način stvaranja multiparafraze korpusa kroz vizuelni opis. Nakon toga smo također predložili izgradnju modela neuroparafraze koji pokreću stručne modele i iskoristiti ih za primjenu NMT-a. Ovdje širimo informacije o slikama koristeći parafrazaciju na osnovu slike bez samog korištenja slike. Naše predložene strategije povećanja multiparafraze na osnovu slike pokazale su poboljšanje protiv početne linije vanile NMT-a.', 'de': 'Paraphrasierung verbessert nachweislich die Übersetzungsqualität in der maschinellen Übersetzung (MT) und wurde zusammen mit der Entwicklung der statistischen MT (SMT) umfassend untersucht. In diesem Beitrag untersuchen und nutzen wir neuronale Paraphrasierungen, um die Übersetzungsqualität in neuronaler MT (NMT) zu verbessern, die bisher nicht viel erforscht wurde. Unser erster Beitrag ist es, eine neue Art und Weise vorzuschlagen, einen multi-paraphrasischen Korpus durch visuelle Beschreibung zu schaffen. Danach schlugen wir auch vor, neuronale Paraphrasenmodelle zu konstruieren, die Expertenmodelle initiieren und diese nutzen, um NMT zu nutzen. Hier diffundieren wir die Bildinformationen durch bildbasierte Paraphrasierungen, ohne das Bild selbst zu verwenden. Unsere vorgeschlagenen bildbasierten Multi-Paraphrasen Augmentationsstrategien zeigten Verbesserungen gegenüber einer Vanille NMT Baseline.', 'id': 'Parafrasasi telah terbukti untuk meningkatkan kualitas terjemahan dalam terjemahan mesin (MT) dan telah dipelajari secara luas bersama dengan pengembangan MT statistik (SMT). Dalam kertas ini, kami menyelidiki dan menggunakan parafrasa saraf untuk meningkatkan kualitas terjemahan dalam MT saraf (NMT), yang belum banyak diteliti. Kontribusi pertama kita adalah mengusulkan cara baru untuk menciptakan mayat multi-parafrasa melalui deskripsi visual. Setelah itu, kami juga mengusulkan untuk membangun model parafrasa saraf yang memulai model ahli dan menggunakannya untuk menggunakan NMT. Di sini, kita menyebarkan informasi gambar dengan menggunakan parafrasa berdasarkan gambar tanpa menggunakan gambar sendiri. Strategi peningkatan multi-parafrasa berbasis gambar kami menunjukkan peningkatan terhadap dasar NMT vanilla.', 'ko': '기계번역(MT)에서 해석이 번역의 질을 높일 수 있다는 것이 입증됐고, 통계기계번역(SMT)이 발전하면서 해석도 폭넓게 연구됐다.본고에서 우리는 신경 해석을 연구하고 이용하여 신경기계번역(NMT)의 번역 질을 향상시키는 데 이 방면의 연구가 많지 않다.우리의 첫 번째 공헌은 시각적 묘사를 통해 다석의 어료 라이브러리를 만드는 새로운 방법을 제시한 것이다.이후 신경 해석 모델을 구축해 전문가 모델을 가동하고 이를 활용해 NMT를 활용하자는 제안도 했다.여기서 우리는 이미지 자체를 사용하지 않고 이미지의 해석을 바탕으로 이미지 정보를 확산시킨다.우리가 제시한 이미지 기반의 다중 해석 강화 전략은 일반적인 NMT 기선에 비해 개선되었다.', 'fa': 'پارافریزنگ ثابت شد که کیفیت ترجمه در ترجمه ماشین (MT) بهتر شود و با توسعه MT (SMT) آموزش داده شده است. در این کاغذ، ما تحقیق و استفاده از پارافریز عصبی برای بهتر کیفیت ترجمه در MT عصبی (NMT) استفاده می کنیم که هنوز زیاد تحقیق نشده است. اولین شرکت ما این است که یک راه جدید برای ایجاد یک کورپوس چندین عبارت از طریق توضیح دیده پیشنهاد کنیم. بعد از آن، ما همچنین پیشنهاد دادیم که مدل\u200cهای پارافریز عصبی بسازیم که مدل\u200cهای متخصص را آغاز می\u200cکنند و آنها را برای تأثیر NMT استفاده می\u200cکنند. در اینجا، ما اطلاعات تصویر را با استفاده از پارافریزهای بنیاد تصویر بدون استفاده از تصویر خود تغییر می دهیم. استراتژی\u200cهای افزایش چندین عبارت بر اساس تصویر پیشنهاد ما در برابر یک خط بنیادی NMT وانیلا بهتر شد.', 'tr': "Çaltylyk maşynyň terjime edilýän (MT) aýratynyň kalitesini geliştirmek üçin barlanyldy we statistik MT (SMT) gelişmegi bilen bölegi ýaly öwrenildi. Bu kagyzda, biz neural parafrazlerini neural MT (NMT) täsirinde terjime etmek üçin barlap we ulanýarys. Biziň ilkinji gezek, görsel taslamak bilen multi-parafraz korpusy döretmäge täze bir nusga teklip etmekdir. Mundan soňra, biz neural parafraz nusgalaryny gurmagy teklip etdik we bu nusgalary NMT'y etmäge ulanýardyk. Bu ýerde resim maglumaty suratdan daşarylan parafrazleri özüni ulanarak çykarýarys. Biziň suratlarymyzda daşary örän-parafraz üýtgetmek stratejiýalarymyz vanilla NMT baseliniň garşynda gelişmeleri görkezildi.", 'sq': 'Parafrazimi është provuar të përmirësojë cilësinë e përkthimit në përkthimin e makinave (MT) dhe është studiuar gjerësisht së bashku me zhvillimin e MT statistike (SMT). Në këtë letër, ne hetojmë dhe përdorim parafrazimin neuronal për të përmirësuar cilësinë e përkthimit në MT neuronal (NMT), që ende nuk është eksploruar shumë. Kontributi ynë i parë është të propozojmë një mënyrë të re për të krijuar një trup me shumë parafraza nëpërmjet përshkrimit vizual. Pas kësaj, ne propozuam gjithashtu të ndërtojmë modele parafraze neurale që nisin modele eksperte dhe i përdorin për të përdorur NMT. Këtu, ne përhapim informacionin e imazhit duke përdorur parafrazimin bazuar në imazh pa përdorur vetë imazhin. Strategjitë tona të propozuara për rritjen e shumë parafrazave bazuar në imazh treguan përmirësim ndaj një baze të NMT vanille.', 'sw': 'Uchapishaji umethibitishwa kuboresha ubora wa tafsiri katika tafsiri ya mashine (MT) na umesomwa kwa kiasi kikubwa pamoja na maendeleo ya takwimu ya MT (SMT). Katika gazeti hili, tunachunguza na kutumia maneno ya neurali ili kuboresha kiwango cha tafsiri katika MT (NMT), ambayo bado haijagunduliwa sana. Mchango wetu wa kwanza ni kupendekeza njia mpya ya kutengeneza viungo vingi vingi kwa kupitia maelezo ya kuona. Baada ya hayo, tulipendekeza pia kujenga mifano ya upinzani wa neura ambazo zinaanzisha mifano ya wataalam na kutumia ili kuitumia NMT. Here, we diffuse the image information by using image-based paraphrasing without using the image itself.  Mipango yetu ya kuongeza kwa misingi mbalimbali ya picha zilizopendekezwa ilionyesha maendeleo dhidi ya msingi wa NMT.', 'af': "Parafrasing is bevestig om vertalingskwaliteit in masjien vertaling (MT) te verbeter en is vaste ondersoek saam met die ontwikkeling van statistiese MT (SMT). In hierdie papier, ons ondersoek en gebruik neurale parafrase om oorsetting kwaliteit in neurale MT (NMT) te verbeter, wat nog nie baie ondersoek is nie. Ons eerste bydraai is om 'n nuwe manier te voorstel om 'n multiparafrase korpus te skep deur visuele beskrywing. Daarna het ons ook voorgestel om neurale parafrase modele te konstrukteer wat eksperte modele begin en hulle gebruik om NMT te verwyder. Hier, ons versprei die beeldinformasie deur beeldgebaseerde parafrase te gebruik sonder die beeld self te gebruik. Ons voorgestelde beeldgebaseerde multiparafrase vergroot strategies het verbetering teen 'n vanilla NMT basisline vertoon.", 'am': 'ማሻሻል ትርጉም ጥሩ ማሻሻል ተርጓሚዎች (MT) እና በተስፋው ተማርቷል፡፡ በዚህ ፕሮግራም ውስጥ በብዙ ሳይመረምር የናውሬል MT (NMT) ጥያቄን ለማድረግ እና የናቡራዊ ግንኙነትን እናጠይቃለን፡፡ የመጀመሪያው አካሄዳችን አዲስ መንገድን ለመፍጠር ነው፤ በዓይነት ግንኙነት የብዙ የፋራፊ ኮፓስ መፍጠር ነው፡፡ ከዚህም በኋላ ደግሞ የናቡር የፓራፊር ሞዴላዎችን ለመሥራት እና የሞክራዊ ሞዴላዎችን ለመጠቀም እና በNMT ለማስጠጋት ለመጠቀም አሻገርን፡፡ የምስል መረጃዎችን በመጠቀም የምስል መረጃዎችን በመጠቀም እናስፋለን፡፡ የተዘጋጀው የምስል ብዙዎችን የባሕላዊ አካባቢ አካባቢ ስርዓት በዋና የኤምቴል መደገፊያ ላይ አሻራጅ አሳየን፡፡', 'hy': 'Պարզվել է, որ պարաֆրազիան բարելավում է մեքենայի թարգմանման (MT) թարգմանման որակը և լայնորեն ուսումնասիրել է միասին վիճակագրական MT (SMT) զարգացման հետ: In this paper, we investigate and utilize neural paraphrasing to improve translation quality in neural MT (NMT), which has not yet been much explored.  Մեր առաջին ներդրումն այն է, որ առաջարկենք նոր միջոց ստեղծելու բազմաբառիկ մարմին տեսողական նկարագրության միջոցով: Դրանից հետո մենք նաև առաջարկեցինք կառուցել նյարդային պարաֆրազիայի մոդելներ, որոնք սկսում են մասնագետ մոդելներ և օգտագործում են դրանք NMT-ի օգնությամբ: Այստեղ մենք տարածում ենք պատկերի ինֆորմացիան օգտագործելով պատկերի հիմնված պարաֆրեզիա առանց պատկերի ինքնուրույն օգտագործելու: Մեր արտադրված պատկերի վրա հիմնված բազմա պարաֆրեզների աճի ռազմավարությունները ցույց տվեցին զարգացում, համեմատած Վանիլիայի ՆՄԹ հիմքի վրա:', 'bn': 'মেশিন অনুবাদের (এমটি) অনুবাদের মান উন্নত করার জন্য প্যারাফ্রাজিং প্রমাণ করা হয়েছে এবং পরিসংখ্যান এমটি(এসএমটি) উন্নয়নের সাথে ব্যা এই কাগজটিতে আমরা নিউরাল এমটি (এনএমটি) অনুবাদের মান উন্নত করার জন্য নিউরুল প্যারাফারেশন ব্যবহার করি এবং ব্যবহার করি, যা এখনো অনেক বেশি তদন্ত আমাদের প্রথম অংশগ্রহণ হচ্ছে দৃষ্টিভঙ্গির মাধ্যমে একটি বহুবাক্তির কোর্পাস তৈরি করার একটি নতুন উপায় প্রস্তাব করা। এরপর আমরা নিউরাল প্যারাফ্রেস মডেল নির্মাণ করার প্রস্তাব দিয়েছিলাম যা বিশেষজ্ঞ মডেল শুরু করে এবং এনএমটি ব্যবহার করার জন্য। এখানে আমরা ছবির তথ্য ব্যবহার করি ছবিটি নিজেই ব্যবহার করে ছবির ভিত্তিক প্যারাফ্রেজিং ব্যবহার করে। আমাদের প্রস্তাবিত ছবির ভিত্তিক মাল্টি প্যারাফ্রেজ বাড়ানোর কৌশল ভানিয়েলা এনএমটি বেসাইনের বিরুদ্ধে উন্নতি প্', 'bs': 'Parafrazacija je dokazana kako bi poboljšala kvalitet prevoda u prevodu strojeva (MT), a široko je proučena zajedno s razvojom statističkog MT-a (SMT). U ovom papiru istražujemo i iskoristavamo neuralnu parafrazaciju kako bi poboljšali kvalitet prevoda u neuralnom MT-u (NMT), koji još nije mnogo istražen. Naš prvi doprinos je da predložimo novi način stvaranja multiparafraze korpusa kroz vizuelni opis. Nakon toga smo također predložili da izgradimo modele neuralne parafraze koji pokreću stručne modele i iskoriste ih za primjenu NMT-a. Ovdje širimo informacije o slikama koristeći parafrazaciju na osnovu slike bez samog korištenja slike. Naše predložene strategije povećanja multiparafraze na osnovu slike pokazale su poboljšanje protiv početne linije vanile NMT-a.', 'ca': "La parafrasió ha demostrat millorar la qualitat de la traducció en traducció màquina (MT) i ha estat ampliament estudiata juntament amb el desenvolupament de MT estadística (SMT). En aquest article investigam i utilitzem parafrases neuronals per millorar la qualitat de traducció en MT neuronal (NMT), que encara no ha estat molt explorat. La nostra primera contribució és proposar una nova manera de crear un cos multiparafrases a través de descripció visual. Després d'això, també vam proposar construir models de parafrases neurals que inicien models experts i els utilitzen per aprofitar la NMT. Aquí difusem la informació de la imatge utilitzant parafrases basades en la imatge sense utilitzar la imatge mateixa. Les nostres estratègies proposades per augmentar les multiparafrases basades en imatges van mostrar millor en comparació amb una línia basal de NMT de vanilla.", 'az': "Paraphrasing maşın çevirilməsi (MT) içində çevirilmə keyfiyyətini yaxşılaşdırmaq üçün təsdiqlənir və statistik MT (SMT) təhsil edilməsi ilə geniş təhsil edildi. Bu kağızda, hələ də çox keşfedilməmişdir ki, neuron parafrasing şəkilində çevirilən MT (NMT) kalitetini daha yaxşılaşdırmaq üçün təhsil edirik və istifadə edirik. Bizim ilk qismətimiz, görsel tasvir vasitəsilə çoxlu parafraz korpusu yaratmaq üçün yeni bir yol təklif etməkdir. Bundan sonra biz də nöral parafraz modellərini inşa etmək və NMT'i istifadə etmək üçün istifadə etdik. Burada, görüntü məlumatını görüntü tabanlı parafrazanı özünü istifadə etmədən istifadə edirik. Bizim təbliğ etdiyimiz görüntü tabanlı çox-parafraz artırma stratejilərimiz vanilla NMT səviyyəsinə qarşı yaxşılıq göstərdi.", 'cs': 'Parafrázování bylo prokázáno, že zlepšuje kvalitu překladu v strojovém překladu (MT) a bylo široce studováno spolu s vývojem statistického MT (SMT). V tomto článku zkoumáme a využíváme neuronovou parafrázu ke zlepšení kvality překladu v neuronové MT (NMT), která dosud nebyla příliš zkoumána. Naším prvním příspěvkem je navrhnout nový způsob vytvoření multi-parafrázového korpusu prostřednictvím vizuálního popisu. Následně jsme navrhli sestavit neuronové parafrázové modely, které iniciují expertní modely a využívají je k využití NMT. Zde rozptýlíme obrazové informace pomocí parafrázy založené na obrazu bez použití samotného obrazu. Naše navržené strategie rozšíření obrazu založené na multiparafrázích ukázaly zlepšení oproti vanilkové NMT základně.', 'et': 'Parafraseerimine parandab tõestatud tõlkekvaliteeti masintõlkes (MT) ja seda on laialdaselt uuritud koos statistilise MT (SMT) arendamisega. Käesolevas töös uurime ja kasutame neuroparafraseerimist, et parandada tõlkekvaliteeti neuraalses MT-s (NMT), mida pole veel palju uuritud. Meie esimene panus on pakkuda välja uus viis luua multiparafraasiline korpus visuaalse kirjelduse kaudu. Seejärel tegime ettepaneku luua ka neuroparafraasimudelid, mis algatavad ekspertmudelid ja kasutavad neid NMT võimendamiseks. Siin hajutame pilditeavet pildipõhise parafraseerimise abil ilma pilti enda kasutamata. Meie pakutud pildipõhised multiparafraasilised suurendusstrateegiad näitasid paranemist võrreldes vanilje NMT algtasemega.', 'fi': 'Parafrasoinnin on osoitettu parantavan käännösten laatua konekäännöksessä (MT), ja sitä on tutkittu laajasti tilastollisen MT:n (SMT) kehittämisen yhteydessä. Tässä työssä tutkimme ja hyödynnämme neuroparafrasointia parantaaksemme neuron MT:n (NMT) käännöslaatua, jota ei ole vielä tutkittu paljon. Ensimmäinen panos on ehdottaa uutta tapaa luoda monimuotoinen korpus visuaalisen kuvauksen avulla. Tämän jälkeen ehdotimme myös neuroparafraasimallien rakentamista, jotka käynnistävät asiantuntijamallit ja hyödyntävät niitä NMT:n hyödyntämiseen. Tässä levitämme kuvainformaatiota käyttämällä kuvapohjaista parafrasointia käyttämättä itse kuvaa. Ehdotetut kuvapohjaiset moniparafraasien augmentaatiostrategiamme osoittivat parannusta vaniljan NMT-lähtötasoon verrattuna.', 'he': 'הוכחה שפראפרזיזציה משפר את איכות התרגום בתרגום מכונות (MT) ונלמדה באופן רחב יחד עם הפיתוח של MT סטטיסטי (SMT). In this paper, we investigate and utilize neural paraphrasing to improve translation quality in neural MT (NMT), which has not yet been much explored.  התרומה הראשונה שלנו היא להציע דרך חדשה ליצור גופה ממספר פראפרזיות דרך תיאור ויזואלי. לאחר מכן הצענו גם לבנות מודלים של פראפרזיה עצבית שמתחילים מודלים מומחים ומשתמשים בהם כדי להשתמש בני-אם-טי. Here, we diffuse the image information by using image-based paraphrasing without using the image itself.  אסטרטגיות גידול במבוססת התמונות שלנו הראו שיפור בניגוד לבסיס של NMT וונילה.', 'ha': "An jarraba fassarar-rayin dõmin ya improve tsarin translation in mashine (MT) kuma an karanta widely along with the developed statistical MT (SMT). Ga wannan takardan, Munã tambaya kuma Muke yi amfani da fassarar neural dõmin a improve tsarin translation in neural MT (NMT), wanda ba a iya ƙara da yawa ba. Bayanmu na farkon aikin da za'a goyya wata hani na ƙiƙiro wata nau'i-multi-parameter a bayani. Sa'an nan kuma, Mun buɗa in samun misãlai na neurar da za'a fara misãlai masu masu fitarwa kuma mu yi amfani da su zuwa ga iyar da NMT. Wannan, muna yin amfani da zane da zane-zane idan ba mu yi amfani da zanen kansa ba. Tsarin ƙaramako da aka buƙata masu bakin zane-zane-bakin multi-parafrasa, sun nuna mafiya kyau a kan basalin NMT.", 'sk': 'Parafraziranje izboljšuje kakovost prevajanja v strojnem prevajanju (MT) in je bilo široko raziskano skupaj z razvojem statističnega MT (SMT). V tem prispevku raziskujemo in uporabljamo nevralno parafraziranje za izboljšanje kakovosti prevajanja v nevralni MT (NMT), ki še ni bila veliko raziskana. Naš prvi prispevek je predlagati nov način ustvarjanja večparafraznega korpusa skozi vizualni opis. Po tem smo predlagali tudi gradnjo nevronskih parafraznih modelov, ki sprožijo strokovne modele in jih uporabljajo za vzvod NMT. Tukaj razpršujemo slikovne informacije s parafraziranjem na podlagi slike brez uporabe same slike. Naše predlagane strategije večparafraznega povečanja na podlagi slike so pokazale izboljšanje glede na izhodišče vanilijevega NMT.', 'jv': 'structural navigation Nang pewiir iki, kita ujaran karo ngono nggunakake paraFrarasan nêr kanggo nglanggar kalite tarjamahan ning MT (NMT), sing ora bisa diandelak durung. Awak dhéwé perusahaan tanggal nggawe sistem anyar tentang nggawe barang multi-paragraf Awak dhéwé éntuk pisan ngéwangi, sampek iso nggawe model paraFrasisa Neral sing dadi nggawe model sing paling nggambar ngono ngéwangi ngéwangi NMT. string" in "context_BAR_stringLink Awak dhéwé nggawe sistem-sistem sing dikarepaké karo perusahaan-perusahaan gambar apa-perusahaan', 'bo': 'དབྱེ་ཚིག་ནང་དུ་ཡིག་གཟུགས་ཀྱི་སྒྲིག་འགོད་ཀྱི་གནས་ཚུལ་འདི་ཡར་རྒྱས་གཏོང་བ་ཞིབ་ཏེ། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་འོང་ཚོས་བརྟན་དཔྱད་ཞིབ་དང་སྤྱད་ནས་དུས་མཐུན་བཟོ་བར་གཏོང་ཚིགས་ཀྱི་གནས་ཚུལ་ཉེན་སྐྱེན་ཆེ ང་ཚོའི་གོ་སྤྲོད་དང་པོ་ནི་མཐོང་བའི་འགྲེལ་བཤད་ཀྱི་རྩིས་བ་སྣ་ཚོགས་ཅན་ཞིག་གསར་གཏོང་བའི་ཐབས་ལམ་གསར་བ་ཞིག་བ དེ་ལས་འོན་ཀྱང་། ང་ཚོས་དབུས་ཀྱི་དཔེ་དབྱིབས་དཔེ་དབྱིབས་བཟོ་བྱེད་པའི་མིག་སྔར་སྒྲིག འདིར་ང་ཚོས་བརྙན་རིས་སྐོར་གྱི་གཟུགས་རིས་གཞི་བརྟེན་པའི་ཚིག་རྟགས་ཀྱི་མ་ལག་ལེན་བྱེད་པ་ལས་ཚོར་བ་ ང་ཚོའི་གྲོས་འཆར་བཀོད་པའི་གཟུགས་བརྙན་རིས་གཞི་བརྟེན་པའི་སྣ་ཚོགས་ཆེ་མཐོང་གི་ཐབས་ལམ་དེ་ནི་vanilla NMT གཞི་རྟེན་གནས་ས'}
