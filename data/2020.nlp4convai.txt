{'en': 'How to Tame Your Data : Data Augmentation for Dialog State Tracking', 'ar': 'كيفية ترويض بياناتك: زيادة البيانات لتتبع حالة الحوار', 'fr': "Comment dompter vos données\xa0: augmentation des données pour le suivi de l'état des boîtes de dialogue", 'ja': 'データを活用する方法：ダイアログの状態トラッキングのためのデータ拡張', 'es': 'Cómo controlar sus datos: aumento de datos para el seguimiento del estado de los diálogos', 'hi': 'अपने डेटा को कैसे वश में करें: संवाद स्थिति ट्रैकिंग के लिए डेटा वृद्धि', 'zh': '何以驯数:以对话框数广之', 'pt': 'Como domar seus dados: aumento de dados para rastreamento de estado de diálogo', 'ru': 'Как приручить ваши данные: увеличение данных для отслеживания состояния диалога', 'ga': 'Conas Do Shonraí a Chumhnú: Méadú Sonraí le haghaidh Rianú Stáit Dialóige', 'hu': 'Hogyan szelídítsd meg az adataidat: Adatbővítés a párbeszédállapot nyomon követéséhez', 'el': 'Πώς να δαμάσετε τα δεδομένα σας: Αύξηση δεδομένων για παρακολούθηση κατάστασης διαλόγου', 'kk': 'Деректеріңізді қалай тазалау: Диалог күйін қадағалау', 'it': 'Come addomesticare i tuoi dati: Aumento dei dati per il monitoraggio dello stato di dialogo', 'lt': 'Kaip sumažinti Jūsų duomenis: duomenų didinimas dialogo būklės sekimui', 'mk': 'Како да ги намалите вашите податоци: Агментација на податоците за следење на состојбата на дијалогот', 'ml': 'നിങ്ങളുടെ വിവരങ്ങള്\u200d എങ്ങനെയാണു് നിര്\u200dമ്മിക്കുക: ഡയലോഗ് സ്റ്റേറ്റ് ട്രാക്കിങ്ങിനുള്ള ഡേറ', 'ms': 'Bagaimana untuk Tame Data Anda: Pembesaran Data untuk Pengejaran Keadaan Dialog', 'ka': 'თქვენი მონაცემები: დიალოგის სტატის მონაცემებისთვის მონაცემები', 'mn': 'Өгөгдлийг хэрхэн тайлбарлах вэ?', 'mt': 'Kif tnaqqas id-Dejta tiegħek: Żieda fid-Dejta għat-Traċċar tal-Istat tad-Djalogu', 'no': 'Korleis data skal gjerast: Data- augmentasjon for dialogtilstand- sporing', 'pl': 'Jak oswoić swoje dane: Rozszerzenie danych w celu śledzenia stanu dialogu', 'ro': 'Cum să vă îmblânziți datele: Augmentarea datelor pentru urmărirea stării dialogului', 'so': 'Sidee macluumaadkaada cashuurta: Tilmaamaha macluumaadka ee baaraandegista dowladda', 'sr': 'Kako da završite vaše podatke: povećanje podataka za praćenje države dijaloga', 'si': 'කොහොමද ඔයාගේ දත්ත තියාගන්නේ: සංවාදය ස්ථානය පරික්ෂණය සඳහා දත්ත වැඩි කරන්න', 'sv': 'Så här tämjer du dina data: Dataförstärkning för spårning av dialogtillstånd', 'ta': 'உங்கள் தரவு: உரையாடல் நாட்டு பின்பற்றிக்கான தகவல் கூறுதல்', 'ur': 'کیسے اپنا ڈاٹا ٹیمیٹ کرنا ہے: ڈاٹا اگنٹ ڈاٹ ایٹ ترکینگ کے لئے', 'uz': 'Maò¥lumotlar bazasini qanday qilish: Maò¥lumot bajarish', 'vi': 'Làm sao giải mã dữ liệu: gia tăng dữ liệu cho việc theo dõi bang hộp thoại', 'bg': 'Как да опитомите данните си: увеличаване на данните за проследяване на състоянието на диалоговия прозорец', 'da': 'Sådan tæmmer du dine data: Dataudvidelse til sporing af dialogtilstand', 'nl': 'Hoe u uw gegevens temt: Data Augmentation voor het bijhouden van dialoogstatus', 'id': 'Bagaimana untuk Tame Data Anda: Data Augmentation untuk Dialog State Tracking', 'de': 'So zähmen Sie Ihre Daten: Datenerweiterung für Dialogzustandsverfolgung', 'ko': '데이터 길들이기: 대화상자 상태 추적 데이터 확장', 'sw': 'Namna ya Kufuatilia Taarifa yako: Uunganishaji wa Data kwa ajili ya Kufuatilia Taifa ya Dialog', 'hr': 'Kako završiti vaše podatke: povećanje podataka za praćenje države dijaloga', 'tr': 'Siziň Maglumatyňyzy Nähili Ewez Et: Data Augmentation for Dialog State Tracking', 'fa': 'چگونه پاک کردن داده\u200cهایتان: افزایش داده\u200cها برای ردیابی وضعیت دیalog', 'af': 'Hoe na Tame Jou Data: Data Augmentation for Dialog State Tracking', 'am': 'ዳታ', 'bn': 'আপনার তথ্য কিভাবে তাম করা হবে: ডায়ালগ রাষ্ট্রীয় অনুসন্ধানের জন্য তথ্য অংশগ্রহণ', 'hy': 'Ինչպե՞ս նվազեցնել ձեր տվյալները: Տվյալների աճը դասախոսության վիճակի հետևման համար', 'sq': 'Si të përmirësoni të dhënat tuaja: rritja e të dhënave për ndjekjen e gjendjes së dialogut', 'ca': "Com ajustar les vostres dades: augmentació de dades per a seguir l'estat del diàleg", 'cs': 'Jak zkrotit data: Rozšíření dat pro sledování stavu dialogů', 'et': 'Kuidas oma andmeid taltsutada: andmete suurendamine dialoogi oleku jälgimiseks', 'fi': 'Kuinka kesyttää tietosi: tietojen lisääminen dialogin tilan seurantaan', 'az': 'Sizin m톛lumatlar캼n캼z캼 nec톛 tamamlay캼n: Dialoog Eyaleti 캻zl톛m톛si 칲칞칲n Data Augmentation', 'bs': 'Kako završiti vaše podatke: povećanje podataka za praćenje države dijaloga', 'jv': 'File', 'sk': 'Kako ukrotiti svoje podatke: povečanje podatkov za sledenje stanju pogovornega okna', 'ha': 'Yãya Kayan Tayina Kwamfyuta: Ƙarandin Dane na Kwamfyuta wa Taimar Dialog', 'he': 'How to Tame Your Data: Data Augmentation for Dialog State Tracking', 'bo': 'How to Tame Your Data: Data Augmentation for Dialog State Tracking'}
{'en': 'Dialog State Tracking (DST) is a problem space in which the effective vocabulary is practically limitless. For example, the domain of possible movie titles or restaurant names is bound only by the limits of language. As such, DST systems often encounter out-of-vocabulary words at inference time that were never encountered during training. To combat this issue, we present a targeted data augmentation process, by which a practitioner observes the types of errors made on held-out evaluation data, and then modifies the training data with additional corpora to increase the vocabulary size at training time. Using this with a RoBERTa-based Transformer architecture, we achieve state-of-the-art results in comparison to systems that only mask trouble slots with special tokens. Additionally, we present a data-representation scheme for seamlessly retargeting DST architectures to new domains.', 'ar': 'تتبع حالة الحوار (DST) هو مساحة مشكلة تكون فيها المفردات الفعالة عمليا غير محدودة. على سبيل المثال ، يقتصر نطاق عناوين الأفلام أو أسماء المطاعم المحتملة فقط على حدود اللغة. على هذا النحو ، غالبًا ما تواجه أنظمة التوقيت الصيفي كلمات خارجة عن المفردات في وقت الاستدلال والتي لم تتم مواجهتها مطلقًا أثناء التدريب. لمكافحة هذه المشكلة ، نقدم عملية زيادة البيانات المستهدفة ، والتي من خلالها يلاحظ الممارس أنواع الأخطاء التي حدثت في بيانات التقييم المعلقة ، ثم يعدل بيانات التدريب مع مجموعات إضافية لزيادة حجم المفردات في وقت التدريب. باستخدام هذا مع بنية Transformer المستندة إلى RoBERTa ، نحقق نتائج متطورة مقارنة بالأنظمة التي تخفي فقط فتحات المشاكل بعلامات مميزة. بالإضافة إلى ذلك ، نقدم مخطط تمثيل البيانات لإعادة توجيه هياكل التوقيت الصيفي بسلاسة إلى مجالات جديدة.', 'fr': "Le Dialog State Tracking (DST) est un espace de problèmes dans lequel le vocabulaire effectif est pratiquement illimité. Par exemple, le domaine des titres de films ou des noms de restaurants possibles n'est limité que par les limites de la langue. Ainsi, les systèmes DST rencontrent souvent des mots hors vocabulaire au moment de l'inférence qui n'ont jamais été rencontrés pendant la formation. Pour lutter contre ce problème, nous présentons un processus d'augmentation ciblée des données, par lequel un praticien observe les types d'erreurs commises sur les données d'évaluation conservées, puis modifie les données d'entraînement avec des corpus supplémentaires afin d'augmenter la taille du vocabulaire au moment de la formation. En utilisant cela avec une architecture Transformer basée sur Roberta, nous obtenons des résultats de pointe par rapport aux systèmes qui masquent uniquement les emplacements de panne avec des jetons spéciaux. De plus, nous présentons un schéma de représentation des données pour le reciblage transparent des architectures DST vers de nouveaux domaines.", 'es': 'El seguimiento del estado del diálogo (DST) es un espacio problemático en el que el vocabulario efectivo es prácticamente ilimitado. Por ejemplo, el dominio de los posibles títulos de películas o nombres de restaurantes está limitado únicamente por los límites del idioma. Como tal, los sistemas DST a menudo encuentran palabras fuera del vocabulario en el momento de la inferencia que nunca se encontraron durante el entrenamiento. Para combatir este problema, presentamos un proceso de aumento de datos específico, mediante el cual un profesional observa los tipos de errores cometidos en los datos de evaluación mantenidos y, a continuación, modifica los datos de entrenamiento con cuerpos adicionales para aumentar el tamaño del vocabulario en el momento del entrenamiento. Al usar esto con una arquitectura Transformer basada en Roberta, logramos resultados de vanguardia en comparación con los sistemas que solo enmascaran las ranuras de problemas con tokens especiales. Además, presentamos un esquema de representación de datos para reorientar sin problemas las arquitecturas DST a nuevos dominios.', 'pt': 'O Dialog State Tracking (DST) é um espaço de problemas no qual o vocabulário efetivo é praticamente ilimitado. Por exemplo, o domínio de possíveis títulos de filmes ou nomes de restaurantes é limitado apenas pelos limites da linguagem. Como tal, os sistemas DST geralmente encontram palavras fora do vocabulário no momento da inferência que nunca foram encontradas durante o treinamento. Para combater esse problema, apresentamos um processo de aumento de dados direcionado, pelo qual um praticante observa os tipos de erros cometidos nos dados de avaliação retidos e, em seguida, modifica os dados de treinamento com corpora adicionais para aumentar o tamanho do vocabulário no momento do treinamento. Usando isso com uma arquitetura Transformer baseada em RoBERTa, alcançamos resultados de última geração em comparação com sistemas que apenas mascaram slots de problemas com tokens especiais. Além disso, apresentamos um esquema de representação de dados para redirecionar perfeitamente as arquiteturas DST para novos domínios.', 'ja': 'Dialog State Tracking （ DST ）は、効果的な語彙が実質的に無限である問題空間である。たとえば、映画のタイトルやレストラン名のドメインは、言語の制限にのみ拘束されます。したがって、DSTシステムは、トレーニング中に遭遇したことのない推論時間に語彙外の単語に遭遇することが多い。この問題に対処するために、実践者が保持された評価データ上のエラーの種類を観察し、トレーニング時に語彙サイズを増やすためにトレーニングデータを追加のコーパスで修正する、ターゲットを絞ったデータ拡張プロセスを提示する。これをRoBERTaベースのトランスフォーマーアーキテクチャで使用すると、特別なトークンでトラブルスロットのみをマスクするシステムと比較して、最先端の結果を達成できます。さらに、DSTアーキテクチャを新しいドメインにシームレスにリターゲティングするためのデータ表現スキームを提示します。', 'hi': 'संवाद स्थिति ट्रैकिंग (DST) एक समस्या स्थान है जिसमें प्रभावी शब्दावली व्यावहारिक रूप से असीम है। उदाहरण के लिए, संभावित चलचित्र शीर्षकों या रेस्तरां नामों का डोमेन केवल भाषा की सीमाओं से बाउंड है. इस प्रकार, डीएसटी सिस्टम अक्सर अनुमान समय पर आउट-ऑफ-शब्दावली शब्दों का सामना करते हैं जो प्रशिक्षण के दौरान कभी सामना नहीं किए गए थे। इस मुद्दे का मुकाबला करने के लिए, हम एक लक्षित डेटा संवर्धन प्रक्रिया प्रस्तुत करते हैं, जिसके द्वारा एक व्यवसायी आयोजित-आउट मूल्यांकन डेटा पर की गई त्रुटियों के प्रकारों का निरीक्षण करता है, और फिर प्रशिक्षण के समय शब्दावली के आकार को बढ़ाने के लिए अतिरिक्त कॉर्पोरेट के साथ प्रशिक्षण डेटा को संशोधित करता है। RoBERTa-आधारित ट्रांसफॉर्मर आर्किटेक्चर के साथ इसका उपयोग करते हुए, हम उन प्रणालियों की तुलना में अत्याधुनिक परिणाम प्राप्त करते हैं जो केवल विशेष टोकन के साथ परेशानी स्लॉट को मुखौटा करते हैं। इसके अतिरिक्त, हम नए डोमेन के लिए डीएसटी आर्किटेक्चर को मूल रूप से पुन: लक्षित करने के लिए एक डेटा-प्रतिनिधित्व योजना प्रस्तुत करते हैं।', 'zh': '言与 (DST) 间,其效词汇无穷也。 或电影题餐厅名域仅受言语约束。 故DST 统常于推理遇训练之间未尝遇词汇量不足之单词。 凡此诸针对性,从业者观存评上犯谬,然后用额外语料库改练数,以增训练之词汇量。 比之 RoBERTa Transformer 架构,比于特用令牌屏蔽故障槽之统,先进之效也。 供数据表示方,以 DST 体系结构无隙重定向新域。', 'ru': 'Отслеживание состояния диалога (DST) - это проблемное пространство, в котором эффективный словарь практически безграничен. Например, домен возможных названий фильмов или названий ресторанов привязан только к языковым ограничениям. Таким образом, DST-системы часто сталкиваются с внесловными словами во время вывода, которые никогда не встречались во время обучения. Для решения этой проблемы мы представляем целенаправленный процесс расширения данных, с помощью которого практикующий врач наблюдает за типами ошибок, допущенных в отношении задержанных оценочных данных, а затем изменяет учебные данные с помощью дополнительных корпусов, чтобы увеличить размер словарного запаса во время обучения. Используя это с архитектурой трансформатора на базе RoBERTa, мы достигаем самых современных результатов по сравнению с системами, которые только маскируют слоты неисправностей с помощью специальных токенов. Кроме того, мы представляем схему представления данных для плавного ретаргетинга архитектур DST на новые домены.', 'ga': 'Is spás fadhbanna é Rianú Stáit Dialóige (DST) ina bhfuil an stór focal éifeachtach beagnach gan teorainn. Mar shampla, níl fearann teideal scannán féideartha nó ainmneacha bialainne faoi cheangal ach ag teorainneacha teanga. Mar sin, is minic a thagann córais DST ar fhocail as stór focal ag am tátail nár thángthas orthu riamh le linn na hoiliúna. Chun an tsaincheist seo a chomhrac, cuirimid i láthair próiseas méadaithe sonraí spriocdhírithe, trína mbreathnaíonn cleachtóir ar na cineálacha earráidí a rinneadh ar shonraí meastóireachta a coinníodh amach, agus ansin modhnaítear na sonraí oiliúna le corpora breise chun méid an stór focal a mhéadú ag am oiliúna. Agus é seo á úsáid le hailtireacht Trasfhoirmeoir atá bunaithe ar RoBERTa, bainimid torthaí den scoth amach i gcomparáid le córais nach gceileann ach sliotáin trioblóide le comharthaí speisialta. Ina theannta sin, cuirimid scéim ionadaíochta sonraí i láthair chun ailtireachtaí DST a ath-spriocdhíriú chuig fearainn nua gan uaim.', 'el': 'Η παρακολούθηση κατάστασης διαλόγου είναι ένας προβληματικός χώρος στον οποίο το αποτελεσματικό λεξιλόγιο είναι πρακτικά απεριόριστο. Για παράδειγμα, ο τομέας των πιθανών τίτλων ταινιών ή των ονομάτων εστιατορίων δεσμεύεται μόνο από τα όρια της γλώσσας. Ως εκ τούτου, τα συστήματα συχνά συναντούν λέξεις εκτός λεξιλογίου κατά τη στιγμή συμπερασμάτων που δεν συναντήθηκαν ποτέ κατά τη διάρκεια της εκπαίδευσης. Για την αντιμετώπιση αυτού του ζητήματος, παρουσιάζουμε μια στοχευμένη διαδικασία αύξησης δεδομένων, με την οποία ένας επαγγελματίας παρατηρεί τους τύπους σφαλμάτων που γίνονται σε καθυστερημένα δεδομένα αξιολόγησης και στη συνέχεια τροποποιεί τα δεδομένα κατάρτισης με πρόσθετα σώματα για να αυξήσει το μέγεθος του λεξιλογίου κατά την προπόνηση. Χρησιμοποιώντας αυτό με μια αρχιτεκτονική μετασχηματιστή βασισμένη στο επιτυγχάνουμε αποτελέσματα τελευταίας τεχνολογίας σε σύγκριση με συστήματα που καλύπτουν μόνο αυλακώσεις προβλημάτων με ειδικά διακριτικά. Επιπλέον, παρουσιάζουμε ένα σχέδιο αναπαράστασης δεδομένων για την απρόσκοπτη επαναπροσανατολισμή αρχιτεκτονικών σε νέους τομείς.', 'ka': 'დიალოგის სტატიური მონახვა (DST) არის პრობლემების სამყარო, რომელიც ეფექტიური სიტყვებულია პრაქტიკურად უდრიმები. მაგალითად, შესაძლებელი ფილმის სახელი ან რესტოპანტის სახელებების დემომინი მხოლოდ ენის ზომილებით დაკავშირდება. როგორც ასე, DST სისტემები ძალიან გარეშე სიტყვებულების სიტყვებით, რომლებიც ინფრენციის დროში არასდროს შეხვედნენ, რომლებიც არასდროს განსწავლების დრო ამ პრობლემას გაბრუნდეთ, ჩვენ მოგვეყვანეთ მინიშვნელოვანი მონაცემების აგგენტირების პროცესი, რომელიც პრაქტიკონიერი მონაცემების ტიპების შეცდომის შეცდომის მონაცემებზე, და შემდეგ შეცდომა მო ეს გამოყენება რობერტაზე დაფარდებული ტრანფორმეტრის აქტიქტურაციაზე, ჩვენ მივიღეთ სისტემის შესაბამისად, რომელიც მხოლოდ პრობლემეტრის სპეციალური სისტემის შესაბამისად მხ დამატებით, ჩვენ მონაცემების გამოსახულების სქემის გადავიტანოთ DST არქიტექტიკების ახალი დიომენზე.', 'it': "Dialog State Tracking (DST) è uno spazio problematico in cui il vocabolario efficace è praticamente illimitato. Ad esempio, il dominio di possibili titoli cinematografici o nomi di ristoranti è vincolato solo dai limiti della lingua. Come tale, i sistemi DST spesso incontrano parole fuori vocabolario al momento dell'inferenza che non sono mai state incontrate durante l'allenamento. Per combattere questo problema, presentiamo un processo mirato di aumento dei dati, attraverso il quale un professionista osserva i tipi di errori commessi sui dati di valutazione trattenuti, e quindi modifica i dati di allenamento con corpi aggiuntivi per aumentare le dimensioni del vocabolario al momento dell'allenamento. Utilizzando questo con un'architettura Transformer basata su RoBERTa, otteniamo risultati all'avanguardia rispetto ai sistemi che mascherano solo gli slot di problemi con token speciali. Inoltre, presentiamo uno schema di rappresentazione dei dati per il retargeting senza soluzione di continuità delle architetture DST a nuovi domini.", 'kk': 'Диалог күй- жайын қадағалау (DST) деген сөздер әрекетті шектелмеген мәселе орын. Мысалы, мүмкін фильм атауларының не ресторантың атауларының домені тек тілдің шектерінен байланысты. Бұл үшін DST жүйелері көпшілікті сөздерінің сөздері өзгертілмеген уақытта келмейді. Бұл мәселеге көмектесу үшін біз мәліметтің мақсатты деректерді көбектеу процесін таңдаймыз. Бұл үшін тәжірибелі бақылау деректерінде қате түрлерін көреді, сондықтан кейін сөздердің өлшемін оқыту уақытында көбе Бұны RoBERTa негіздеген Трансформалер архитектурасынан қолдануға арнаулы белгілерден тек қалған слоттарды қалқайтын жүйелерімен қалыптастырып жеткіземіз. Қосымша, біз DST архитектураларын жаңа доменге қайталау үшін деректерді көрсету сұлбасын таңдаймыз.', 'hu': 'A párbeszédállapot nyomon követése (DST) egy olyan probléma tér, amelyben a hatékony szókincs gyakorlatilag korlátlan. Például a lehetséges filmcímek vagy éttermek nevei tartományát csak a nyelv korlátai kötik. Ilyen módon a DST rendszerek gyakran találkoznak szókincsen kívüli szavakkal a következtetések időpontjában, amelyek soha nem találkoztak az edzés során. A probléma leküzdése érdekében bemutatunk egy célzott adatbővítési folyamatot, amelynek segítségével a gyakorló megfigyeli a tartott értékelési adatok hibáinak típusát, majd további corporákkal módosítja az edzési adatokat, hogy növelje a szókincs méretét az edzés időpontjában. Ezt a RoBERTa alapú Transformer architektúrával használva a legkorszerűbb eredményeket érünk el olyan rendszerekhez képest, amelyek csak speciális tokenekkel maszkolják el a hibahelyeket. Ezenkívül bemutatunk egy adatábrázolási sémát a DST architektúrák zökkenőmentes újratelepítéséhez új tartományokba.', 'lt': 'Dialog State Tracking (DST) is a problem space in which the effective vocabulary is practically limitless.  Pavyzdžiui, galimų filmų pavadinimų arba restoranų pavadinimų sritis yra ribojama tik kalbos ribomis. Taigi DST sistemos dažnai susiduria su ne žodžių žodžiais, kurie nebuvo susiduriami mokymo metu. Siekiant kovoti su šiuo klausimu, pristatome tikslinį duomenų didinimo procesą, pagal kurį praktikuojantis gydytojas stebi klaidų, padarytų naudojantis saugomais vertinimo duomenimis, tipus, ir tada keičia mokymo duomenis su papildoma korpora, kad mokymo metu didintų žodyno dydį. Naudojant šį metodą su RoBERTa grindžiama Transformer architektūra, mes pasiekiame pažangiausius rezultatus palyginti su sistemomis, kurios slepia tik probleminius laiko tarpsnius su specialiais ženklais. Be to, mes pristatome duomenų perdavimo sistemą, skirtą nuolat atsiliekančiai DST architektūrai naujose srityse.', 'mk': 'Дијалогот за следење на состојбата (DST) е проблемски простор во кој ефективниот речник е практично безграничен. For example, the domain of possible movie titles or restaurant names is bound only by the limits of language.  As such, DST systems often encounter out-of-vocabulary words at inference time that were never encountered during training.  За да се бориме против ова прашање, претставуваме целосен процес на зголемување на податоците, со кој практикот ги набљудува видовите на грешки направени на податоците за одржана евалуација, а потоа ги модификува податоците за обука со дополнителни корпора за зголемување на големината на речникот Користејќи го ова со трансформна архитектура со седиште на Роберта, постигнуваме најдобри резултати во споредба со системите кои маскираат само проблеми со специјални знаци. Покрај тоа, претставуваме схема за претставување на податоци за непријатно ретардирање на архитектурите на ДСТ во новите домени.', 'ms': 'Dialog State Tracking (DST) is a problem space in which the effective vocabulary is practically limitless.  Contohnya, domain tajuk filem yang mungkin atau nama restoran hanya terikat oleh had bahasa. Sebagai demikian, sistem DST sering bertemu perkataan luar-dari-vocabulari pada masa kesimpulan yang tidak pernah ditemui semasa latihan. To combat this issue, we present a targeted data augmentation process, by which a practitioner observes the types of errors made on held-out evaluation data, and then modifies the training data with additional corpora to increase the vocabulary size at training time.  Dengan menggunakan ini dengan arkitektur Transformer berasaskan RoBERTa, kita mencapai hasil terbaik dalam perbandingan dengan sistem yang hanya menutup slot masalah dengan token istimewa. Lagipun, kami memperkenalkan skema perwakilan-data untuk mendedahkan arkitektur DST secara terus-menerus ke domain baru.', 'mt': 'It-Traċċar mill-Istat tad-Djalogu (DST) huwa spazju problematiku fejn il-vokabulari effettiv huwa prattikament mingħajr limitu. Pereżempju, id-dominju tat-titoli possibbli tal-films jew l-ismijiet tar-ristoranti huwa marbut biss mil-limiti tal-lingwa. Bħala tali, is-sistemi DST spiss jiltaqgħu ma’ kliem barra mill-vokabulari fi żmien ta’ inferenza li qatt ma nstabu waqt it-taħriġ. Biex niġġieldu kontra din il-kwistjoni, nippreżentaw proċess immirat ta’ żieda fid-dejta, li permezz tiegħu prattikant josserva t-tipi ta’ żbalji magħmula fuq dejta ta’ evalwazzjoni miżmuma, u mbagħad nimmodifikaw id-dejta ta’ taħriġ ma’ korpora addizzjonali biex iżid id-daqs tal-vokabulari fiż-żmien tat-taħriġ. Bl-użu ta’ dan ma’ arkitettura Transformer ibbażata fuq RoBERTa, inkisbu riżultati l-aktar avvanzati meta mqabbla ma’ sistemi li jaħbu biss slots ta’ problemi b’tokens speċjali. Barra minn hekk, qed nippreżentaw skema ta’ rappreżentazzjoni tad-dejta biex l-arkitetturi tad-DST jiġu ritardati mingħajr xkiel għal oqsma ġodda.', 'ml': 'ഡയലോഗ് സ്റ്റേറ്റ് സ്റ്റേറ്റ് ട്രാക്കിംഗ് (DST) ഒരു പ്രശ്നമായ സ്ഥലം ആണു് അതില്\u200d പ്രാകൃതികമായ വാക്കോലിഷന ഉദാഹരണത്തിന്, സാധ്യതയുള്ള സിനിമ തലക്കെട്ടുകളുടെയോ റെസ്റ്റോറന്റിന്റെ പേരുകള്\u200d മാത്രമേ ഭാഷയുടെ അതിരു As such, DST systems often encounter out-of-vocabulary words at inference time that were never encountered during training.  ഈ പ്രശ്നത്തോട് പോരാടാന്\u200d ഞങ്ങള്\u200d ലക്ഷ്യമായ വിവരങ്ങള്\u200d കൂട്ടുന്ന പ്രക്രിയയില്\u200d കൊണ്ടുവരുന്നു. അതിലൂടെ ഒരു പരിശീലിക്കാരന്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്ന പിശകുകള്\u200d പുറത്തു റോബെര്\u200dട്ടാ അടിസ്ഥാനത്തുള്ള ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആര്\u200dക്ടിക്കേറ്റര്\u200d ഉപയോഗിച്ച്, പ്രത്യേക ചിഹ്നങ്ങള്\u200d കൊണ്ട് മുഖം പ്രയാസങ്ങള്\u200d മുഖം മ കൂടുതല്\u200d ഡിഎസ്റ്റിന്റെ ആര്\u200dക്കിട്ടുകള്\u200d പുതിയ ഡോമെന്\u200dസിലേക്ക് സ്ഥാപിക്കുന്നതിനായി നമ്മള്\u200d ഒരു ഡേറ്റാ പ്രതിനി', 'pl': 'Dialog State Tracking (DST) to przestrzeń problemowa, w której efektywne słownictwo jest praktycznie nieograniczone. Na przykład domena możliwych tytułów filmów lub nazw restauracji jest związana tylko ograniczeniami języka. W związku z tym systemy DST często napotykają słowa poza słownictwem w czasie wnioskowania, które nigdy nie były spotykane podczas treningu. Aby przeciwdziałać temu problemowi, przedstawiamy ukierunkowany proces powiększania danych, dzięki któremu praktyk obserwuje rodzaje błędów popełnianych na zatrzymanych danych oceniających, a następnie modyfikuje dane treningowe dodatkowymi korpusami, aby zwiększyć rozmiar słownictwa w czasie treningu. Korzystając z tego z architekturą Transformera opartą na RoBERTa, osiągamy najnowocześniejsze wyniki w porównaniu z systemami, które maskują tylko gniazda problemów specjalnymi tokenami. Ponadto przedstawiamy schemat reprezentacji danych umożliwiający płynne retargingowanie architektur DST do nowych domen.', 'ro': 'Urmărirea stării dialogului (DST) este un spațiu problematic în care vocabularul eficient este practic nelimitat. De exemplu, domeniul posibilelor titluri de film sau nume de restaurante este legat doar de limitele limbajului. Ca atare, sistemele DST întâlnesc adesea cuvinte din vocabular la momentul inferenței care nu au fost întâlnite niciodată în timpul antrenamentului. Pentru a combate această problemă, vă prezentăm un proces specific de mărire a datelor, prin care un practician observă tipurile de erori făcute pe datele de evaluare reținute și apoi modifică datele de formare cu corpore suplimentare pentru a crește dimensiunea vocabularului la momentul antrenamentului. Folosind acest lucru cu o arhitectură Transformer bazată pe RoBERTa, obținem rezultate de ultimă oră în comparație cu sistemele care maschează doar sloturile de probleme cu jetoane speciale. În plus, prezentăm o schemă de reprezentare a datelor pentru retargerea perfectă a arhitecturilor DST în domenii noi.', 'sr': 'Državni praćenje dijaloga (DST) je problem prostor u kojem je efikasna reč praktično besgranična. Na primer, domena mogućih filmskih naslova ili restoranskih imena povezana je samo granicama jezika. Kao što je tako, DST-ovi sistemi često se susreću sa nečim riječima u vrijeme infekcije koje nikada nisu susreli tokom treninga. Da bi se borili protiv ovog pitanja, predstavljamo ciljni proces povećanja podataka, s kojim praktičar posmatra vrste grešaka izvedenih na određenim podacima o procjeni, a zatim modifikuje podatke o obuci sa dodatnim korporama kako bi povećala veličinu rečenika u treningu. Koristeći ovo sa arhitekturom transformera na RoBERTi, postižemo rezultate umetnosti u usporedbi sa sistemima koji maskiraju samo probleme sa posebnim znakovima. Osim toga, predstavljamo shemu predstavljanja podataka za bezobrazno retardiranje DST arhitekture u nove domene.', 'si': 'සංවාදය ස්ථානය පරීක්ෂණය (DST) ප්\u200dරශ්නයක් තියෙන්නේ ප්\u200dරශ්නයක් තියෙන ප්\u200dරශ්නයක් තියෙන්නේ ඒ උදාහරණය විතරයි, පුළුවන් චිත්\u200dරපටික ශිර්මාලය නැතුවක් නැතුවක් විතරයි භාෂාවේ සීමාවක් වි ඒ වගේම, DST පද්ධතිය සාමාන්\u200dයයෙන් ප්\u200dරශ්නයක් වෙලාවක් නැති වචනයක් හම්බවෙනවා කියලා. මේ ප්\u200dරශ්නය සටන් කරන්න, අපි ලක්ෂණ දත්ත විශාලනයක් ප්\u200dරශ්නය කරනවා, ඒ වගේම ප්\u200dරශ්නකයෙක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් පරීක්ෂණය කරලා තියෙන්නේ වැ මේක RoBERTa-ආධාරිත ප්\u200dරවර්තනයක් සඳහා භාවිත කරන්න, අපි විශේෂ ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් තියෙන ප්\u200dරශ්නයක් තියෙන ප්\u200dර තවත්, අපි අලුත් ඩෝමේන් වලට DST ස්තූතිපත්තිපත්තිපත්තිපත්තිපත්තියක් පෙනුම් කරනවා.', 'so': 'Waxbarashada dowladda (DST) waa meel dhibaato ah, kaas oo ku saabsan hadalka faa’iidada leh uu si gaar ah u xadgudbo. Tusaale ahaan deegaanka filimada ee suurtagal ah waxaa lagu xidhan karaa xuduudaha luuqada oo kaliya. Sida oo kale nidaamka DST wuxuu marar badan la kulmaa hadal aan hadal ahayn oo aan la arag waqtiga cayiman waqtiga waxbarashada. Si aan u dagaallanto arrintan, waxaan keenaynaa kooras kordhinta macluumaadka, kaas oo ku qoran tababar tababarida uu arko noocyada khaladda lagu sameeyay ee lagu qiimeeyo, kadibna beddelinayaa macluumaadka waxbarashada iyo shirkadda kale si uu u kordhiyo tirada hadalka xilliga waxbarashada. Isku isticmaalidda dhismaha turjumista ee RoBERTA, waxaynu gaadhnaa xaaladda farshaxanta, taas oo isbarbardhig nidaamka dhibaatada oo kaliya ay leeyihiin calaamado gaar ah. Sidoo kale waxaynu u keennaa qorshaha macluumaad-u-代表si aan u badnayno dhismaha DST oo cusub.', 'sv': 'Dialogtillståndsspårning (DST) är ett problemområde där det effektiva ordförrådet är praktiskt taget obegränsat. Till exempel är domänen för möjliga filmtitlar eller restaurangnamn endast bunden av språkgränserna. Som sådana stöter DST-system ofta på ord utanför ordförrådet vid slutgiltighetstiden som aldrig förekom under träning. För att bekämpa detta problem presenterar vi en riktad dataökning process, genom vilken en utövare observerar de typer av fel som görs på utdragna utvärderingsdata, och sedan ändrar träningsdata med ytterligare corpora för att öka vokabulärets storlek vid träningstid. Med hjälp av detta med en RoBERTa-baserad Transformer-arkitektur uppnår vi toppmoderna resultat jämfört med system som bara maskerar problemplatser med speciella tokens. Dessutom presenterar vi ett datarepresentationsschema för sömlöst återföring av DST-arkitekturer till nya domäner.', 'ta': 'Dialog State Tracking (DST) is a problem space in which the effective vocabulary is limitless. உதாரணத்திற்கு, சாத்தியமான படம் தலைப்புகள் அல்லது restaurant பெயர்கள் மொழியின் வரம்புகள் மட்டும் கட்டப்பட்டுள்ளது. இது போன்று, DST அமைப்புகள் பெரும்பாலாக பயிற்சியில் எதிர்பாராத நேரத்தில் வெளியே சொல்லாத வார்த்தைகளை சந்திக இந்த விஷயத்தை எதிர்பார்க்க, நாம் இலக்கிய தரவு மேலும் செயல்பாட்டை கொண்டுள்ளோம், அதைக் கொண்டு ஒரு பயிற்சியாளர் பார்க்கிறான் வெளியேற்றப்பட்ட மதிப்பின் வகைய ரோபெர்டா அடிப்படையிலான மாற்று உருவாக்கியமைப்புடன் இதை பயன்படுத்தி, சிறப்பு குறியீடுகளுடன் மட்டும் பிரச்சினைகளை மூடும் அமைப்புகளை ஒப கூடுதலாக, நாம் புதிய களங்களுக்கு ஒரு தரவு குறிப்பிடும் திட்டத்தை கொண்டு வருகிறோம்.', 'ur': 'Dialog State Tracking مثال، امکان فیلم کے تایٹل یا رستورانٹ کے نام کے دامنی صرف زبان کی محدودیت کے ذریعہ باندھے جاتے ہیں. اس طرح، ڈیس ٹی سیسٹم اکثر ایسے لفظوں میں بیرون لفظ لفظوں سے ملتے ہیں جن کی تعلیم میں کبھی نہیں ملی تھی. اس مسئلہ سے جنگ کرنے کے لئے، ہم نے ایک موجود ڈیٹا افزایش پروسس کو پیش کیا ہے، جس کے ذریعہ ایک پڑھنے والے نے اٹھایا ہوا ارزیابی ڈیٹے پر گناہوں کی طرح دیکھ لیا ہے، پھر اس کے بعد اضافہ کورپورا کے ساتھ تطالب ڈیٹا بدل دیتا ہے کہ آواز کی سازی تربی اسے روبرٹا بنیادی ترنسفور معماری کے ساتھ استعمال کرتے ہیں، ہم نے اسٹیٹ کی آرتی کا نتیجہ پہنچایا ہے سیستموں کے مقابلہ میں جو صرف مشکل کے سٹوٹوں کو مخصوص ٹوکنوں کے ساتھ ماسک کر رہے ہیں. اور اضافہ، ہم نے ایک ڈیٹی معماری تصویر کو نئی ڈیمین میں سیدھی طرح پھیرنے کے لئے پیش کیا ہے۔', 'mn': 'Диалог Улс Холбоо (DST) гэдэг асуудлын орон зай юм. Эффектив үг нь яг л хязгааргүй байдаг. Жишээлбэл, магадгүй кино нэр, ресторант нэр нь зөвхөн хэл хязгаарлаар холбогдсон. Иймээс ДНХ-ын системүүд дасгал хөдөлгөөн үед хэзээ ч харилцаагүй үг биш үг байдаг. Энэ асуудлыг эсэргүүцэхийн тулд бид зориулсан өгөгдлийн нэмэгдүүлэлтийн процессийг үзүүлнэ. Үүнээс мэргэжлийн ажиллагч нь хэдэн алдаа гарсан талаар ажиглаж, дараа нь сургалтын өгөгдлийг нэмэлт корпораттай өөрчилж өгөгдлийг сургалтын ца Үүнийг RoBERTa-д суурилсан Трансформатор архитектуртай ашиглан бид урлагийн байр сууриллагын үр дүнг онцгой тодорхойлолтуудыг зөвхөн асуудлыг дүрслэх системтэй харьцуулахад хүргэж байна. Мөн бид DST архитектуруудыг шинэ газрын дотор шинэ хэсгүүд рүү шилжүүлэх боломжтой мэдээллийн төлөвлөгөө төлөвлөгдөж байна.', 'no': 'Dialogtilstand- sporing (DST) er eit problem- plass der den effektive ordboka er praktisk grensa. For eksempel, domenet med moglege filmtittel eller restaurantnamn er berre bound by the limits of language. Som slik må DST-systemet ofte oppfylle ut-ordbokstavar ved infeksjonstid som aldri oppstod under opplæring. For å kjempe med dette problemet, presenterer vi ein målteg data-augmentasjonsprosess, med at ein praktisering observerer typane feil gjennomførte ved høgde evalueringsdata, og så endrar opplæringsdata med fleire korpora for å auka ordbokstørrelsen ved opplæringstid. Bruk dette med eit RoBERTa-basert transformeringsarkitektur, oppnår vi tilstanden av kunsten i sammenligning med systemar som bare maskerer problemplassar med spesielle teikn. I tillegg presenterer vi eit data-representasjonsskjema for å trykke DST-arkitekturar på nye domene.', 'uz': "Name Masalan, muvaffaqiyatli filamu sarlavhasi yoki restaurant nomi faqat tilning chegarasi bilan bogʻliq. Shunday qilib, DST tizimlari taʼminlovchi vaqtda hech qachon hech qachon murojaat qilmagan soʻzlardan foydalanish mumkin. Bu muammo bilan boshqarish uchun bir qanday maʼlumot qoʻshish jarayoni hozir qilamiz. Bu muammolar bilan ishlatadigan qiymatning turlarini ko'rib chiqaradi va keyin taʼminlovchi vaqtda qoʻshimcha ma'lumot maʼlumotni o'zgartiradi. Biz buni RoBERTA asosida Transformer architektorlar bilan ishlatish mumkin, biz faqat muammolar bilan boshqaruvchi muammolarni qo'yish tizimlarga o'xshash natijalarini bajaramiz. Ko'pchilik, biz oddiy oddiy DST strukturelarini yangi dometlarga saqlash uchun maʼlumot represent qolipini koʻrsatimiz.", 'vi': 'Việc theo dõi bang Dialogo (DST) là một khoảng vấn đề trong đó ngôn ngữ hiệu quả hầu như vô hạn. Ví dụ, lĩnh vực của các tựa phim hay tên nhà hàng có thể được ràng buộc bởi giới hạn ngôn ngữ. Do đó, hệ thống DSS thường phải đối mặt với những từ ngoài từ vựng trong thời gian ngụ ý mà chưa bao giờ xảy ra trong khi luyện tập. Để chống lại vấn đề này, chúng tôi giới thiệu một tiến trình gia tăng dữ liệu đích, nhờ đó một bác sĩ quan sát các dạng lỗi trong dữ liệu đánh giá bị bỏ lại, và sau đó sửa đổi dữ liệu đào tạo với thêm cơ thể để tăng tỷ lệ từ vựng vào thời điểm huấn luyện. Sử dụng điều này với một kiến trúc transformer dựa trên RolTa, chúng ta đạt được kết quả tuyệt vời hơn so với hệ thống chỉ che giấu những khe hở với những thẻ đặc biệt. Thêm nữa, chúng tôi giới thiệu một kế hoạch phân tích dữ liệu để tái hoàn chỉnh các kiến trúc DST cho miền mới.', 'da': 'Dialog State Tracking (DST) er et problemområde, hvor det effektive ordforråd praktisk talt er ubegrænset. For eksempel er domænet for mulige filmtitler eller restaurantnavne kun bundet af sproggrænserne. Som sådan støder DST-systemer ofte ord uden for ordforråd på konklusionstidspunktet, som aldrig blev stødt på under træning. For at bekæmpe dette problem præsenterer vi en målrettet dataforøgelsesproces, hvorved en praktiserende læge observerer de typer fejl, der er begået på udholdte evalueringsdata, og derefter ændrer træningsdataene med yderligere corpora for at øge ordforrådsstørrelsen på træningstidspunktet. Ved hjælp af dette med en RoBERTa-baseret Transformer-arkitektur opnår vi state-of-the-art resultater sammenlignet med systemer, der kun maskerer problemslots med specielle tokens. Derudover præsenterer vi en datarepræsentationsordning til problemfrit retargeting af DST-arkitekturer til nye domæner.', 'nl': 'Dialoog State Tracking (DST) is een probleemruimte waarin de effectieve woordenschat praktisch onbeperkt is. Zo is het domein van mogelijke filmtitels of restaurantnamen alleen gebonden aan de taalgrenzen. Als zodanig komen DST-systemen vaak woorden tegen die buiten de woordenschat liggen tijdens de inferentie die nooit tijdens de training zijn tegengekomen. Om dit probleem aan te pakken, presenteren we een gericht data augmentation proces, waarbij een beoefenaar de soorten fouten observeert die gemaakt zijn op uitgestelde evaluatiegegevens, en vervolgens de trainingsgegevens aanpast met extra corpora om de woordenschat te vergroten tijdens de training. Door dit te gebruiken met een op RoBERTa gebaseerde Transformer architectuur, bereiken we state-of-the-art resultaten in vergelijking met systemen die alleen probleemslots maskeren met speciale tokens. Daarnaast presenteren we een data-representatie schema voor naadloze retargeting van DST architecturen naar nieuwe domeinen.', 'bg': 'Проследяването на състоянието на диалоговия прозорец е проблемно пространство, в което ефективният речник е практически неограничен. Например домейнът на възможните заглавия на филми или имена на ресторанти е обвързан само от ограниченията на езика. Като такива, системите често срещат думи извън речника по време на заключение, които никога не са били срещани по време на обучение. За да се справим с този проблем, представяме целенасочен процес на увеличаване на данните, чрез който практикуващият наблюдава видовете грешки, направени върху проведените данни за оценка, и след това модифицира данните за обучение с допълнителни корпуси, за да увеличи размера на речника по време на обучение. Използвайки това с базирана трансформаторна архитектура, ние постигаме най-съвременни резултати в сравнение със системите, които само маскират слотове за проблеми със специални токени. Освен това представяме схема за представяне на данни за безпроблемно пренасочване на архитектурите към нови домейни.', 'de': 'Dialog State Tracking (DST) ist ein Problemraum, in dem der effektive Wortschatz praktisch grenzenlos ist. Beispielsweise ist die Domain möglicher Filmtitel oder Restaurantnamen nur an die Grenzen der Sprache gebunden. Daher stoßen DST-Systeme oft auf Wörter, die nicht im Wortschatz enthalten sind, während des Trainings. Um diesem Problem entgegenzuwirken, stellen wir einen gezielten Prozess der Datenerweiterung vor, bei dem ein Praktiker die Fehlerarten an ausgeblendeten Auswertungsdaten beobachtet und dann die Trainingsdaten mit zusätzlichen Korpora modifiziert, um den Wortschatz zur Trainingszeit zu vergrößern. Mit einer RoBERTa-basierten Transformer-Architektur erzielen wir State-of-the-Art-Ergebnisse im Vergleich zu Systemen, die nur Fehlerslots mit speziellen Token maskieren. Darüber hinaus präsentieren wir ein Datenrepräsentationsschema zur nahtlosen Retargeting von DST-Architekturen auf neue Domänen.', 'ko': '대화 상태 추적(DST)은 문제 공간으로 유효 어휘가 거의 무한하다.예를 들어 가능한 영화 제목이나 식당 이름은 언어로만 제한된다.따라서 DST 시스템은 추리할 때 어휘표 밖의 단어를 자주 만나는데 이런 단어들은 훈련 중에 만난 적이 없다.이 문제를 해결하기 위해 우리는 맞춤형 데이터 확충 과정을 제시했다. 이 과정을 통해 종사자들은 제공된 평가 데이터에서 범한 오류 유형을 관찰한 다음에 추가 자료 라이브러리를 사용하여 교육 데이터를 수정하여 교육 시 어휘량을 증가시킬 수 있다.특수 영패 차단 고장 슬롯만 사용하는 시스템에 비해 RoBERTA 기반의 Transformer 구조를 사용하여 우리는 가장 선진적인 결과를 실현했다.또한 DST 아키텍처를 새로운 영역으로 원활하게 재정립하기 위한 데이터 표현 시나리오도 제시했습니다.', 'hr': 'Državni praćenje dijaloga (DST) je problem prostor u kojem je učinkovit riječ praktično besgraničan. Na primjer, domena mogućih filmskih naslova ili restoranskih imena povezana je samo granicama jezika. Kao što je tako, DST-ovi sustavi često se susrećuju s izjavnim riječima u vrijeme infekcije koje nikada nisu susreli tijekom treninga. Za borbu protiv ovog pitanja predstavljamo ciljni proces povećanja podataka, kojim praktičar posmatra vrste grešaka izvedenih na određenim podacima o procjeni, a zatim modifikuje podatke o obuci s dodatnim tijelom kako bi povećao veličinu riječi na vrijeme obuke. Koristeći to s arhitekturom transformera na RoBERTi, postigli smo rezultate umjetnosti u usporedbi sa sustavima koji maskiraju samo probleme s posebnim znakovima. Osim toga, predstavljamo shemu predstavljanja podataka za beznačajno retardiranje arhitekture DST-a u nove domene.', 'sw': 'Ufuatiliaji wa Serikali ya Dialog (DST) ni sehemu tatizo ambapo lugha yenye ufanisi ni isiyo na ukomo. Kwa mfano, maeneo ya vichwa vya filamu au majina ya mgahawa yanafungiwa tu kwa mipaka ya lugha. Kwa mfano, mfumo wa DST mara nyingi hukutana na maneno yasiyo na lugha katika wakati ambao hayakuwahi kukutana wakati wa mafunzo. Ili kupambana na suala hili, tunaleta mchakato wa kuongeza taarifa zinazolengwa, ambapo mfanyakazi anatazama aina ya makosa yaliyofanywa kwenye taarifa za uchunguzi, na kisha hubadilisha taarifa za mafunzo kwa kampuni ya ziada ili kuongeza ukubwa wa lugha wakati wa mafunzo. Kwa kutumia hii kwa ujenzi wa Transfer anayeishi RoBERTa, tunafanikiwa matokeo ya hali ya sanaa yanayolinganisha na mifumo ambayo tu hutoa vifaa vya matatizo kwa alama maalum. Zaidi ya hayo, tunaweka mpango wa uwakilizaji wa data kwa ajili ya kuweka majengo ya DST kwa ajili ya maeneo mapya.', 'id': 'Dialog State Tracking (DST) is a problem space in which the effective vocabulary is practically limitless.  For example, the domain of possible movie titles or restaurant names is bound only by the limits of language.  Sebagai seperti itu, sistem DST sering menghadapi kata-kata luar-dari-vocabulari pada waktu kesimpulan yang tidak pernah ditemui selama latihan. Untuk melawan masalah ini, kami mempersembahkan proses penambahan data yang ditujukan, yang mana seorang dokter mengamati jenis kesalahan yang dilakukan pada data evaluasi yang tersimpan, dan kemudian mengubah data pelatihan dengan corpora tambahan untuk meningkatkan ukuran vokal pada waktu pelatihan. Menggunakan ini dengan arsitektur Transformer berdasarkan RoBERTa, kita mencapai hasil terbaik dalam perbandingan dengan sistem yang hanya menutupi slot masalah dengan token khusus. Selain itu, kami mempersembahkan skema perwakilan data untuk melambatkan arsitektur DST secara terus menerus ke domain baru.', 'sq': 'Dialogu State Tracking (DST) është një hapësirë problematike në të cilën fjalorin efektiv është praktikisht i pakufizuar. Për shembull, domenia e titujve të mundshëm të filmit apo emrave të restauranteve është e lidhur vetëm nga kufijtë e gjuhës. Si e tillë, sistemet DST shpesh takojnë fjalë jashtë fjalëkalimit në kohën e përfundimit që nuk u takuan kurrë gjatë trajnimit. Për të luftuar këtë çështje, ne paraqesim një proces shtimi të të dhënave të synuara, me të cilin një praktikant vëzhgon llojet e gabimeve të bërë në të dhënat e vlerësimit të mbajtur, dhe pastaj modifikon të dhënat e trajnimit me korpra shtesë për të rritur madhësinë e fjalorëve në kohën e trajnimit. Duke përdorur këtë me arkitekturën e Transformer me bazë në RoBERTa, ne arrijmë rezultate më të larta në krahasim me sistemet që maskojnë vetëm vende problemesh me shenja të posaçme. Përveç kësaj, ne paraqesim një skemë përfaqësimi të të dhënave për shtyrjen e vazhdueshme të arkitekturave DST në fusha të reja.', 'am': 'የDialog State Tracking (DST) is a problem space where the effective vocabulary is limitless. ለምሳሌ፣ የሚቻለው የፊል አርእስቶች ወይም የሬስቶሮንት ስም በቋንቋ ግንኙነት ብቻ የታሰረ ነው፡፡ As such, DST systems often encounter out-of-vocabulary words at inference time that were never encountered during training.  ይህንን ጉዳይ ለመከላከል በተቃወሙ የዳታ አካባቢ ፕሮጀክት እናቀርባለን፣ ባስተማሪ የስህተት ማሳየት ዳታ የሚደረጉትን የስህተት ዓይነት ያያል፣ ከዚያም በኋላ የግንኙነቱን ዳታ በተጨማሪው ኮርፖርተራ ላይ የባለፉትን መጠን በሚያበዛበት ጊዜ ይለውጣል፡፡ በRoBERTa-based Transformer መሠረት የተደረገውን እናደርጋለን፣ የ-art ፍሬዎችን በተስተካከል እናደርጋለን፡፡ በተጨማሪም የDST መሠረት አካባቢዎችን በአዲስ አካባቢዎች እናስቀምጣለን፡፡', 'af': "Dialoog Staat Volg (DST) is 'n probleem spasie waarin die effektief woordeboek prakties beperk is. Byvoorbeeld, die domein van moontlike filmtitels of restaurantnaams is slegs gebind deur die grense van taal. Soos so, DST-stelsels het dikwels van uitwoordeboek woorde by die uitbreidingstyd ontmoet wat nooit ontmoet word tydens onderwerp nie. Om hierdie probleem te veg, laat ons 'n doelgemaakte data vergroot proses voorsien, deur waarmee 'n praktiseerder die tipes van foute wat op gehou-uitgevoerde evaluering data gemaak het, en dan verander die onderwerp data met addisionele korpora om die woordeboekgrootte op onderwerp tyd te vergroot. Die gebruik van hierdie met 'n RoBERTa-gebaseerde Transformer-arkitektuur, word ons die staat-van-die-kunsten resultate in vergelyking met stelsels wat slegs moeilikheidspasies met spesiale tekens masker. In addition, we present a data-representation scheme for seamlessly retargering DST architectures to new domains.", 'hy': 'Առաջին դասախոսության հետևումը (DST) խնդիր է, որտեղ արդյունավետ բառարանը գրեթե անսահմանափակ է: Օրինակ, ֆիլմի հնարավոր անվանումների կամ ռեստորանների անունների ոլորտը կապված է միայն լեզվի սահմաններով: As such, DST systems often encounter out-of-vocabulary words at inference time that were never encountered during training.  Այս խնդրի դեմ պայքարելու համար մենք ներկայացնում ենք նպատակային տվյալների աճի գործընթաց, որի միջոցով փորձագետը դիտարկում է պահպանված գնահատման տվյալների վրա կատարված սխալների տեսակները, և հետո փոխում է կրթության տվյալները ավելացյալ մարմնով, որպեսզի աճի բառա Օգտագործելով սա ՌոԲԵՌԹԱ-ի հիմնված տրանսֆերմերների ճարտարապետության հետ, մենք հասնում ենք ամենաբարձր արդյունքներ համեմատելով համակարգերի հետ, որոնք միայն ծածկում են խնդիրների անկյուններ հատուկ նշաններով: Ավելին, մենք ներկայացնում ենք տվյալների ներկայացման ծրագիր, որպեսզի նոր բնագավառներում DST ճարտարապետությունները անընդհատ դադարեցնեն:', 'bn': 'ডায়ালগ স্টেট ট্র্যাক্টিং (DST) একটি সমস্যা স্থান যেখানে কার্যকর শব্দভাণ্ডারের কার্যকর সীমাবদ্ধ। উদাহরণস্বরূপ, সম্ভাব্য চলচ্চিত্রের শিরোনাম অথবা রেস্টোরেন্টের নামের ডোমেইন শুধুমাত্র ভাষার সীমা যেমন, DST সিস্টেম প্রায়শই বাইরে শব্দভাণ্ডারের কথার সাথে সাক্ষাৎ করে যায়, যা প্রশিক্ষণের সময় কখনোই সাক্ষাৎ হয়নি। এই বিষয়ের বিরুদ্ধে যুদ্ধের জন্য আমরা একটি লক্ষ্য করা তথ্য যোগাযোগ প্রক্রিয়া উপস্থাপন করি, যার মাধ্যমে একজন প্রশিক্ষক দেখেছেন আটকে যাওয়া তথ্যের ভুল পর্যবেক্ষণ করেছেন, এবং তারপর রোবের্তার ভিত্তিক ট্রান্সফারেন্স কাঠামোর মাধ্যমে এটা ব্যবহার করে আমরা সিস্টেমের সাথে তুলনায় পৌঁছাই যা কেবল বিশেষ প্রমাণ দিয়ে সমস্যার এছাড়াও আমরা নতুন ডোমেইনে ডাটা প্রতিনিধিত্বের একটি পরিকল্পনা উপস্থাপন করি সীমারণভাবে ডিএসটি আর্কিটেক্টারের জন্য।', 'bs': 'Državni praćenje dijaloga (DST) je problem prostor u kojem je efikasna reč praktično besgranična. Na primjer, domena mogućih filmskih naslova ili restoranskih imena povezana je samo granicama jezika. Kao što je tako, DST-ovi sustavi često se susreću s izjavnim riječima u vrijeme infekcije koje nikada nisu susreli tijekom treninga. Da bi se borili protiv ovog pitanja, predstavljamo ciljni proces povećanja podataka, kojim praktičar posmatra vrste grešaka izvedenih na određenim podacima o procjeni, a zatim modifikuje podatke o obuci sa dodatnim tijelom kako bi povećao veličinu riječi na trening. Koristeći to sa arhitekturom transformera na RoBERTi, postigli smo rezultate umjetnosti u usporedbi sa sistemima koji maskiraju samo probleme sa posebnim znakovima. Osim toga, predstavljamo shemu predstavljanja podataka za beznačajno retardiranje arhitektura DST-a u nove domene.', 'fa': 'ردیابی وضعیت دیalog (DST) یک فضای مشکلی است که کلمات فعالی در آن تقریباً بی محدود است. برای مثال، دامین عنوان فیلم ممکن یا نام رستوران فقط با محدودیت زبان بسته می شود. به عنوان این، سیستم\u200cهای DST اغلب کلمات بیرون کلمات در زمان بیماری که در طول تمرین هرگز با هم ملاقات نکرده بودند، ملاقات می\u200cکنند. برای مبارزه با این مسئله، ما یک فرایند افزایش داده های هدف را پیشنهاد می کنیم، که به وسیله آن یک تمرین کننده از نوع اشتباهی که در داده های ارزیابی پایین انجام شده را مشاهده می کند، و سپس داده های آموزش را با شرکت اضافی تغییر می دهد تا اندازه vocabulaری در زمان آموزش اف با استفاده از این با یک معماری تبدیل کننده بر روبرتا، نتیجه\u200cهای موقعیت هنر را در مقایسه با سیستم\u200cهایی که فقط با نشانه\u200cهای ویژه مشکلات را ماسک می\u200cکنیم. به اضافه، ما یک نقشه نمایش داده برای تأخیر ساختاری DST به دامنهای جدید نشان می دهیم.', 'tr': 'диалог Durum İzleme (DST) faýly sözleri çykarmak üçin bir mesele seleňdir. Mesela, filmiň başlyklary ýa-da restoran adlarynyň domeny diňe diliň muglaryna baglanýar. Şonuň ýaly DST sistemalary köplenç okuwçy wagtynda hiç wagt garşy ýok sözleri bilen galyp barýarlar. Bu meselede garşy etmek üçin, biz hedefimiz maglumaty üýtgetmek prosesini görkeýäris. Bir praktikçi tarapyndan çykyp durmuş çykyş berüvlerinde hatalaryň türlerini görkeýär we soňra bu okuw maglumatyny bozmak üçin esasy korpora bilen üýtgedi. Muny RoBERTa tabanly bir Transformer arhitektegi bilen ullanýarys. Biz sungatyň durumyny ýöne özel möhümler bilen kynçylyk sistemlerle karşılaşyp başarýarys. Hemişe, DST arhitekterilerini täze sahypa gaýtalamak üçin bir maglumat temsilcisi taslaýyny görkeýäris.', 'ca': "Dialog State Tracking (DST) és un espai de problem a en el qual el vocabulari efectiu és pràcticament indefinit. Per exemple, el domini dels possible títols de pel·lícules o noms de restaurants només està lligat pels límits del llenguatge. As such, DST systems often encounter out-of-vocabulary words at inference time that were never encountered during training.  Per combatre aquesta qüestió, presentem un procés de augmentació de dades mirat, en el qual un metge observe els tipus d'errors comets en dades d'evaluació mantenida, i després modifica les dades d'entrenament amb corpora adicional per augmentar la mida del vocabulari en temps d'entrenament. Utilitzant això amb una arquitectura de Transformer basada en RoBERTa, aconseguem resultats més avançats en comparació amb sistemes que només masquen espais de problemes amb fitxes especials. Additionally, we present a data-representation scheme for seamlessly retargeting DST architectures to new domains.", 'cs': 'Sledování stavu dialogu (DST) je problémový prostor, ve kterém je efektivní slovní zásoba prakticky neomezená. Například doména možných filmových titulů nebo názvů restaurací je vázána pouze omezením jazyka. Jako takový, DST systémy často narážejí na slova mimo slovní zásobu v době závěru, která se nikdy během tréninku nesetkala. Pro boj s tímto problémem představujeme cílený proces rozšíření dat, kterým praktikující sleduje typy chyb udělaných na vyčerpávaných hodnotících datech a následně upravuje tréninková data o další korpusy pro zvýšení velikosti slovní zásoby v době tréninku. Pomocí architektury Transformer založené na RoBERTa dosahujeme nejmodernějších výsledků ve srovnání se systémy, které maskují pouze problémové sloty speciálními tokeny. Navíc představujeme schéma reprezentace dat pro bezproblémové retargetování architektur DST do nových domén.', 'et': 'Dialoogi oleku jälgimine (DST) on probleemne ruum, kus efektiivne sõnavara on praktiliselt piiramatu. Näiteks võimalike filmide pealkirjade või restoranide nimede domeen on seotud ainult keelepiirangutega. Seetõttu kohtavad DST süsteemid sageli sõnavara väljaspool järeldusaega sõnu, mida treeningu ajal ei esinenud. Selle probleemi vastu võitlemiseks esitame sihipärase andmete suurendamise protsessi, mille käigus praktik jälgib läbiviidud hindamisandmetel tehtud vigu ja seejärel muudab treeninguandmeid täiendavate korpustega, et suurendada sõnavara suurust treeningu ajal. Kasutades seda koos RoBERTa-põhise transformaatori arhitektuuriga, saavutame tipptasemel tulemusi võrreldes süsteemidega, mis varjavad probleeme ainult spetsiaalsete tokenitega. Lisaks esitame andmete esitamise skeemi DST arhitektuuride sujuvaks ümbersuunamiseks uutele domeenidele.', 'fi': 'Dialog State Tracking (DST) on ongelmatila, jossa tehokas sanasto on käytännössä rajaton. Esimerkiksi mahdollisten elokuvien tai ravintoloiden nimien verkkotunnusta sitovat vain kielirajat. Näin ollen DST-järjestelmät kohtaavat usein sanaston ulkopuolisia sanoja päättelyhetkellä, joita ei koskaan havaittu harjoittelun aikana. Tämän ongelman torjumiseksi esittelemme kohdennetun datan lisäämisprosessin, jossa harjoittelija tarkkailee suoritettaviin arviointitietoihin tehtyjen virheiden tyyppejä ja muokkaa harjoitustietoja lisäkorpusilla sanaston koon lisäämiseksi harjoitushetkellä. Käyttämällä tätä RoBERTa-pohjaisen Transformer-arkkitehtuurin kanssa saavutamme huippuluokan tuloksia verrattuna järjestelmiin, jotka peittävät ongelmapaikat vain erityisillä poleteilla. Lisäksi esittelemme dataesitysjärjestelmän DST-arkkitehtuurien saumattomaan uudelleensuuntaamiseen uusille toimialueille.', 'az': 'Dialoog Eyalet İzləməsi (DST) efektiv sözləri əslində sınırsız bir məsafədir. Məsələn, mümkün film başlıqlarının və restoran adlarının domeini yalnız dilin sınırları ilə bağlıdır. Bəlkə, DST sistemləri təhsil sırasında heç vaxt qarşılaşmamış sözlərdə çox fərqli sözlərlə qarşılaşırlar. Bu məsələyə qarşı müharibə etmək üçün biz məqsədilə məlumatları artırmaq prosesini göstəririk, bu olaraq təhsil edən təhsil verilən xətaların türünü görür, sonra təhsil verilən məlumatları başqa korpora ilə dəyişdirir ki, sözlərin böyüklüyünü təhsil vaxtında artırsın. Bunu RoBERTa tabanlı Transformer arhitektüsü ilə istifadə edirik, sanatın vəziyyəti müxtəlif möcüzələrlə yalnız sıxıntılar üzərində gizlənən sistemlərlə qarşılaşdırılır. Üstəlik, DST arhitektarını yeni domenalara arhitektarlıqlıq etmək üçün məlumatları təsdiqləmə taslağı göstəririk.', 'jv': 'Dialog state tracing (SST) is a question space in the effectual word Sampeyan, domain sing dibenalke film titles apa restoran iki dipunangé perusahaan bangsa. Sistem-SST sing ditambah kuwi, nik kuwi ora ono wektu-uwis kuwi padha kelas-kelas nang titimbang kuwi, ora sapa temèh dumateng neng njuk. Ngawe ngubah perusahaan iki, kita ngomong sampeyan perusahaan data nyang gawe perusahaan data nyang apik sing perusahaan winih dhéwé Ngawe ngubah iki karo akeh Transformer architecture, kita dumadhi state-of-the-arts maneh dumadhiné karo sistem sing bisa Layer Mask pakan karo token sing apik dhéwé. Mungkin maneh, kita ngubah data-representation scheme kanggo ngilanggar maringgawe architectures', 'sk': 'Sledenje stanja pogovornega okna (DST) je problematični prostor, v katerem je učinkovito besedišče praktično neomejeno. Domeno možnih naslovov filmov ali imena restavracij na primer zavezujejo le omejitve jezika. Tako se sistemi DST pogosto srečujejo z besedami iz besedišča izven besedišča v času sklepanja, ki jih med treningom nikoli niso srečali. Za boj proti tej težavi predstavljamo ciljno usmerjen proces povečanja podatkov, s katerim izvajalec opazuje vrste napak na izvedenih ocenjevalnih podatkih, nato pa spremeni podatke o usposabljanju z dodatnimi korpusi, da poveča velikost besedišča v času treninga. Z uporabo te arhitekture s transformatorjem, ki temelji na RoBERTa, dosegamo najsodobnejše rezultate v primerjavi s sistemi, ki prikrivajo reže za težave le s posebnimi žetoni. Poleg tega predstavljamo shemo predstavitve podatkov za nemoteno preusmerjanje arhitektur DST v nove domene.', 'ha': "@ action: button Misali, aka ɗauki duk sunan filamu masu iya yiwuwa ko sunan restaurant kawai da tsarin harshen. Kamar misãlin, na'urar DSS ko da yawa sunã haɗi maganar-out-dictionary at an kasa haɗa wa lokaci da ba ya haɗu ba a lokacin da ya yi amfani da shi. To, dõmin ka yi yãƙi ga wannan masu zartar, Munã gabatar da wani jarrabi na ƙara data wanda aka yi goani, da shi wani mai gyare yana gani wa typi makorari waɗand a aka aikata a kan evaluation-raye, kuma yana gyara data na shirin da ke ƙara koronata dõmin ya ƙara girma wa tsarin maganar a lokacin da za'a yi amfani da shi. Yi amfani da wannan da aka baka wani matsayin Transformer na RoBERTA, za'a sami al'amarin-the-art zuwa a sami'anar da system waɗanda ke rufe matsayin matalauta kawai da alama masu hushi. Additionally, we present a data-representation scheme for seamlessly retargeting DST architectures to new domains.", 'he': 'מעקב המדינה של הדיולוג (DST) הוא מרחב בעיה שבה המילון היעיל הוא כמעט ללא גבול. For example, the domain of possible movie titles or restaurant names is bound only by the limits of language.  ככה, מערכות DST לעתים קרובות פוגשות מילים מחוץ למילים בזמן המסקנה שמעולם לא נפגשו במהלך האימונים. כדי להילחם בנושא הזה, אנו מציגים תהליך גידול נתונים ממוקד, שבה רופא צופה בסוגים של שגיאות שעשו על נתוני הערכה החזקת, ואז משנה את נתוני האימונים עם גופרה נוספת כדי לגדל את גודל המילים בזמן האימונים. בשימוש בזה עם ארכיטקטורה טרנספורטרית מבוססת ברוברטה, אנו משיגים תוצאות מוקדמות בהשוואה למערכות שמסתירות רק קומות צרות עם סימנים מיוחדים. בנוסף, אנחנו מציגים תכנית מייצג נתונים לארכיטקטורות DST מפגרות ללא הפרעה לתחומים חדשים.', 'bo': 'Dialog State Tracking (DST) is a problem space in which the effective vocabulary is practically limitless. དཔེར་ན། བྱུང་སྲིད་པའི་དགའ་ཆས་ཀྱི་མགོ་མིང་དང་གསུམ་སྟོང་གསུམ་ཅིག་མིང་ཚོ་ནི་སྐད་ཡིག་གི་ཚད་གཞི་ཁོ་ན དེར་བརྟེན། DST་མ་ལག་གིས་རྒྱུན་ལྡན་ནས་བརྡ་སྤྲོད་ཀྱི་ཚིག་དང་དུས་གཏོང་མཚམས་ལ་མཐུན་པ་ལས། To combat this issue, we present a targeted data augmentation process, by which a practitioner observes the types of errors made on held-out evaluation data, and then modifies the training data with additional corpora to increase the vocabulary size at training time. འདི་ལ་RoBERTa་གཞི་བརྟེན་ནས་བཟོ་བཅོས་མཁན་གྱི་བཟོ་བརྩོན་བཟོ་བ་ཅིག་བེད་སྤྱོད་བཞིན་པའི་གནས་སྟངས་གཙོ་རིམ་དང་མཐུན་སྒྲིག ད་དུང་། ང་ཚོས་དུང་ཚང་གསར་བ་ལ་སྐྱུར་བརྗོད་བྱེད་པའི་ཆ་འཕྲིན་གྱི་ཐབས་ལམ་ཞིག་འཇུག་བྱེད།'}
{'en': 'Efficient Intent Detection with Dual Sentence Encoders', 'ar': 'الكشف الفعال عن النوايا باستخدام تشفير الجمل المزدوجة', 'pt': 'Detecção de intenção eficiente com codificadores de sentença dupla', 'fr': "Détection d'intention efficace grâce aux codeurs de phrases doubles", 'es': 'Detección eficiente de intenciones con codificadores de doble frase', 'ja': 'デュアル文章エンコーダによる効率的なインテント検出', 'zh': '用双句编码器高效意向检测', 'ru': 'Эффективное обнаружение намерений с помощью кодеров с двойным предложением', 'hi': 'दोहरी वाक्य Encoders के साथ कुशल इरादा का पता लगाने', 'ga': 'Brath Éifeachtach Rúin le Ionchódóirí Dé-Abairte', 'ka': 'Comment', 'hu': 'Hatékony szándék felismerése kettős mondatkódolókkal', 'el': 'Αποτελεσματική ανίχνευση προθέσεων με διπλούς κωδικοποιητές φράσεων', 'it': 'Rilevamento efficiente delle intenzioni con codificatori a doppia frase', 'lt': 'Veiksmingas ketinimų nustatymas naudojant dvigubo sakinio kodus', 'kk': 'Екінші сөз кодерлерімен жұмыс жеткілікті анықтау', 'ms': 'Pengesanan Intent Efisien dengan Pengekod Dua Putusan', 'ml': 'രണ്ടാമത്തെ ശിക്ഷ കുറിപ്പുകളുമായി ഉള്ളിലുള്ള തിരിച്ചറിയുക', 'mk': 'Efficient Intent Detection with Dual Sentence Encoders', 'mt': 'Sejbien Effiċjenti bl-Intenzjoni b’Kodifikaturi ta’ Sentenza Doppja', 'pl': 'Wydajne wykrywanie intencji za pomocą podwójnych koderów zdań', 'no': 'Effektivt intent oppdaging med dobbelte teiknkoder', 'ro': 'Detectare eficientă a intențiilor cu codoare duble de sentință', 'so': 'Aqoonshaha faa’iido ah ee la xiriira Heeganka labaad', 'si': 'දුවල් වාක්ය සංකේතකය සමඟ හොයාගන්න හොයාගන්න', 'ta': 'இருமுறை வாக்குறியீடுகளுடன் தேவையான உள்ளீட்டு கண்டுபிடிப்பு', 'mn': 'Хоёрдугаар өгүүлбэр кодчуудтай эзэмшигтэй ухаантай олох', 'ur': 'دوئل سنٹنس کوڈر کے ساتھ عمدہ تلاش', 'sr': 'Učinjena intenzivna otkrića sa dvostrukim koderima kazne', 'sv': 'Effektiv avsiktsdetektering med dubbla meningskoder', 'vi': 'Phát hiện ý thức hiệu quả với mã số phát âm kép', 'uz': 'Ikki marta sertifikatlarni aniqlash muvaffaqiyatsiz tugadi', 'bg': 'Ефективно откриване на намерения с двойни кодери за изречения', 'hr': 'Učinjena intenzivna otkrića s dvostrukim koderima kazne', 'da': 'Effektiv hensigtsetektering med dobbelte sætningskodere', 'nl': 'Efficiënte intentiedetectie met dubbele zinnencoders', 'de': 'Effiziente Intent Detection mit Dual Satzence Encoder', 'id': 'Deteksi Intent Efisien dengan Koder Dua Sentensi', 'ko': '이중 언어 인코더를 사용하는 효율적인 의도 검출', 'fa': 'شناسایی موثری با رمزگران دومین کلمه', 'sw': 'Kugundua Kifaa kinachofanikiwa na Kufunguliwa kwa adhabu mbili', 'af': 'Effektiewe Intent Opdekking met Duele Sentence Encoders', 'tr': 'Fatal Sened Ködlemeleri bilen ýeterlik ýere tap', 'sq': 'Detektimi Efektiv i Intentionit me koduesit e dyfishtë', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'az': 'İki Sözü Kodlayıcıları ilə Yetişkin İşləmə', 'hy': 'Եֆեկտիվ մտադրական հայտնաբերում երկու նախադասությունների կոդերներով', 'bn': 'দুই শাস্তি এনকোডারের সাথে প্রয়োজনীয় ইন্টেন্ট সনাক্ত', 'bs': 'Učinjena intenzivna otkrića sa dvostrukim koderima kazne', 'ca': "Detecció d'intenció eficient amb codificadors de doble frase", 'cs': 'Efektivní detekce záměrů pomocí dvojitých snímačů vět', 'et': 'Tõhus kavatsuste tuvastamine kahesuunaliste kodeerijatega', 'fi': 'Tehokas aikeiden tunnistus kaksoislausekoodereilla', 'sk': 'Učinkovito zaznavanje namena z dvojnimi kodirniki stavkov', 'jv': 'cage-mode', 'ha': '@ action', 'he': 'זיהוי כוונה יעיל עם קודים משפטיים כפולים', 'bo': 'འཇམ་ཅན་གྱི་ཚིག་རྟགས་སྟོན་པ་དང་མཉམ་དུ་རྟོགས་པ'}
{'en': 'Building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes (i.e., in few-shot setups). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT. We demonstrate the usefulness and wide applicability of the proposed intent detectors, showing that : 1) they outperform intent detectors based on fine-tuning the full BERT-Large model or using BERT as a fixed black-box encoder on three diverse intent detection data sets ; 2) the gains are especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated examples per intent) ; 3) our intent detectors can be trained in a matter of minutes on a single CPU ; and 4) they are stable across different hyperparameter settings. In hope of facilitating and democratizing research focused on intention detection, we release our code, as well as a new challenging single-domain intent detection dataset comprising 13,083 annotated examples over 77 intents.', 'ar': 'يتطلب بناء أنظمة محادثة في مجالات جديدة وبوظائف إضافية نماذج ذات كفاءة في استخدام الموارد تعمل في ظل أنظمة منخفضة البيانات (على سبيل المثال ، في إعدادات قليلة اللقطات). بدافع من هذه المتطلبات ، نقدم طرق اكتشاف النية مدعومة بمشفرات الجملة المزدوجة التي تم اختبارها مسبقًا مثل USE و ConveRT. نبرهن على الفائدة والتطبيق الواسع لأجهزة الكشف عن النوايا المقترحة ، موضحين ما يلي: 1) أنها تتفوق على أجهزة الكشف عن النوايا بناءً على الضبط الدقيق لنموذج BERT-Large الكامل أو استخدام BERT كمشفِّر للصندوق الأسود الثابت على ثلاث مجموعات متنوعة من بيانات الكشف عن النية ؛ 2) تظهر المكاسب بشكل خاص في إعدادات قليلة اللقطات (على سبيل المثال ، مع 10 أو 30 مثالاً مشروحًا فقط لكل نية) ؛ 3) يمكن تدريب أجهزة الكشف عن النوايا الخاصة بنا في غضون دقائق على وحدة معالجة مركزية واحدة ؛ و 4) تكون مستقرة عبر إعدادات مختلفة للمعلمات الفائقة. على أمل تسهيل وإضفاء الطابع الديمقراطي على البحث الذي يركز على اكتشاف النية ، قمنا بإصدار الكود الخاص بنا ، بالإضافة إلى مجموعة بيانات جديدة صعبة للكشف عن النية في مجال واحد تضم 13083 مثالاً مشروحًا عبر 77 نية.', 'es': 'La creación de sistemas conversacionales en nuevos dominios y con funcionalidad adicional requiere modelos eficientes en cuanto a recursos que funcionen bajo regímenes de datos bajos (es decir, en configuraciones de pocas tomas). Motivados por estos requisitos, introducimos métodos de detección de intenciones respaldados por codificadores de doble oración preentrenados, como USE y CONVERt. Demostramos la utilidad y amplia aplicabilidad de los detectores de intención propuestos, demostrando que: 1) superan a los detectores de intención en función del ajuste fino del modelo BERT-Large completo o el uso de BERT como codificador fijo de caja negra en tres conjuntos de datos de detección de intención diversos; 2) las ganancias son especialmente pronunciadas en configuraciones de pocos disparos (es decir, con solo 10 o 30 ejemplos anotados por intento); 3) nuestros detectores de intención se pueden entrenar en cuestión de minutos en una sola CPU; y 4) son estables en diferentes configuraciones de hiperparámetros. Con la esperanza de facilitar y democratizar la investigación centrada en la detección de intenciones, publicamos nuestro código, así como un nuevo y desafiante conjunto de datos de detección de intenciones de un solo dominio que comprende 13 083 ejemplos anotados en 77 intentos.', 'fr': "La création de systèmes conversationnels dans de nouveaux domaines et avec des fonctionnalités supplémentaires nécessite des modèles économes en ressources qui fonctionnent dans des régimes de faible volume de données (c'est-à-dire dans des configurations peu nombreuses). Motivés par ces exigences, nous introduisons des méthodes de détection d'intention soutenues par des encodeurs de phrases doubles préentraînés tels que USE et Convert. Nous démontrons l'utilité et la large applicabilité des détecteurs d'intention proposés, montrant que\xa0: 1) ils surpassent les détecteurs d'intention en ajustant le modèle BERT-large complet ou en utilisant BERT comme encodeur de boîte noire fixe sur trois ensembles de données de détection d'intention différents\xa0; 2) les gains sont particulièrement prononcés dans quelques configurations (c'est-à-dire avec seulement 10 ou 30 exemples annotés par intention)\xa0; 3) nos détecteurs d'intention peuvent être entraînés en quelques minutes sur un seul processeur\xa0; et 4) ils sont stables dans différents paramètres d'hyperparamètres. Dans l'espoir de faciliter et de démocratiser la recherche axée sur la détection d'intention, nous publions notre code, ainsi qu'un nouveau jeu de données stimulant de détection d'intention à domaine unique comprenant 13 083 exemples annotés sur 77 intentions.", 'pt': 'Construir sistemas de conversação em novos domínios e com funcionalidade adicional requer modelos com eficiência de recursos que funcionem sob regimes de poucos dados (ou seja, em configurações de poucos disparos). Motivados por esses requisitos, apresentamos métodos de detecção de intenção apoiados por codificadores de sentença dupla pré-treinados, como USE e ConveRT. Demonstramos a utilidade e ampla aplicabilidade dos detectores de intenção propostos, mostrando que: 1) eles superam os detectores de intenção com base no ajuste fino do modelo BERT-Large completo ou usando o BERT como um codificador fixo de caixa preta em três conjuntos de dados de detecção de intenção diferentes ; 2) os ganhos são especialmente pronunciados em configurações de poucos tiros (ou seja, com apenas 10 ou 30 exemplos anotados por intenção); 3) nossos detectores de intenção podem ser treinados em questão de minutos em uma única CPU; e 4) eles são estáveis em diferentes configurações de hiperparâmetros. Na esperança de facilitar e democratizar a pesquisa focada na detecção de intenção, lançamos nosso código, bem como um novo conjunto de dados desafiador de detecção de intenção de domínio único, composto por 13.083 exemplos anotados em 77 intenções.', 'hi': 'नए डोमेन में और अतिरिक्त कार्यक्षमता के साथ संवादात्मक प्रणालियों के निर्माण के लिए संसाधन-कुशल मॉडल की आवश्यकता होती है जो कम-डेटा शासन (यानी, कुछ-शॉट सेटअप में) के तहत काम करते हैं। इन आवश्यकताओं से प्रेरित होकर, हम पहले से प्रशिक्षित दोहरे वाक्य एनकोडर जैसे USE और ConveRT द्वारा समर्थित इरादे का पता लगाने के तरीकों को पेश करते हैं। हम प्रस्तावित इरादे डिटेक्टरों की उपयोगिता और व्यापक प्रयोज्यता का प्रदर्शन करते हैं, यह दिखाते हुए कि: 1) वे पूर्ण BERT-Large मॉडल को ठीक-ट्यूनिंग के आधार पर या तीन विविध इरादे का पता लगाने वाले डेटा सेट पर एक निश्चित ब्लैक-बॉक्स एन्कोडर के रूप में BERT का उपयोग करने के आधार पर इरादे डिटेक्टरों को मात देते हैं; 2) लाभ विशेष रूप से कुछ-शॉट सेटअप में स्पष्ट होते हैं (यानी, प्रति इरादे केवल 10 या 30 एनोटेटेड उदाहरणों के साथ); 3) हमारे इरादे डिटेक्टरों को एक ही सीपीयू पर मिनटों के मामले में प्रशिक्षित किया जा सकता है; और 4) वे विभिन्न हाइपरपैरामीटर सेटिंग्स में स्थिर हैं। इरादे का पता लगाने पर केंद्रित अनुसंधान को सुविधाजनक बनाने और लोकतांत्रिक बनाने की उम्मीद में, हम अपने कोड को जारी करते हैं, साथ ही साथ एक नया चुनौतीपूर्ण एकल-डोमेन इरादा पता लगाने वाला डेटासेट जिसमें 77 इरादों से अधिक 13,083 एनोटेटेड उदाहरण शामिल हैं।', 'ja': '新しいドメインで会話システムを構築し、機能を追加するには、低データレジームで動作するリソース効率の良いモデルが必要です（すなわち、ほとんどのショットのセットアップで）。 これらの要件に基づいて、使用やConveRTなどの事前に訓練された二重文エンコーダに裏打ちされたインテント検出方法を導入します。 私たちは、提案されたインテント検出器の有用性と幅広い適用性を実証し、次のことを示します。1 ）完全なBERT - Largeモデルを微調整すること、または3つの多様なインテント検出データセットでBERTを固定ブラックボックスエンコーダとして使用することに基づいてインテント検出器を上回る性能を発揮すること、2 ）ゲインは、数ショットの設定で特に顕著であること（つまり、インテントごとに10または30の注釈付きの例のみ）、3 ）インテント検出器は、単一のCPUで数分で訓練することができること、および4 ）異なるハイパーパラメータ設定にわたって安定していること。 意図の検出に焦点を当てた研究を促進し、民主化することを期待して、私たちはコードと、77の意図にわたる13,083の注釈付きの例を含む新しい挑戦的な単一ドメイン意図検出データセットをリリースします。', 'zh': '凡新域有附能之语,统须资源节约型模,(于下数,于少置中)下。 凡此诸推,引入预练双句编码器(如USE与ConveRT)扶持之意。 余证其意检测器有用性广适用性,明:1)其优于调全BERT-Large或用BERT为定黑盒编码器于三异之意检数集上之意探测器。 2)增益于小镜头置中尤明(即,每意惟10或30带注示例)。 3)吾意检测器可于几分钟内练于单CPU。 与4)异参数设置而定。 进民主化注意,发吾代码,与一新挑战性之单域意检数集,其中含77意之13,083注示例。', 'ru': 'Построение разговорных систем в новых доменах и с дополнительными функциями требует ресурсоэффективных моделей, которые работают в режимах с малым объемом данных (т.е. в настройках с несколькими выстрелами). Основываясь на этих требованиях, мы вводим методы обнаружения намерений, поддерживаемые предварительно обученными двойными кодерами предложений, такими как USE и ConveRT. Мы демонстрируем полезность и широкую применимость предложенных детекторов намерений, показывая, что: 1) они превосходят детекторы намерений, основанные на тонкой настройке полной модели BERT-Large или использовании BERT в качестве фиксированного кодировщика черного ящика на трех различных наборах данных обнаружения намерений; 2) усиления особенно выражены в настройках с несколькими выстрелами (т.е., только с 10 или 30 аннотированными примерами на намерение); 3) наши детекторы намерений могут быть обучены в течение нескольких минут на одном ЦП; и 4) они стабильны при различных настройках гиперпараметров. В надежде облегчить и демократизировать исследования, сосредоточенные на обнаружении намерений, мы выпускаем наш код, а также новый сложный однодоменный набор данных об обнаружении намерений, включающий 13 083 аннотированных примера за 77 намерений.', 'ga': 'Chun córais chomhrá a thógáil i bhfearainn nua agus le feidhmiúlacht bhreise, teastaíonn samhlacha atá tíosach ar acmhainní a oibríonn faoi réimeanna sonraí íseal (i.e. i socruithe cúpla seat). Arna spreagadh ag na ceanglais seo, tugaimid isteach modhanna braite rún le tacaíocht ó ionchódóirí dé-abairte réamhoilte ar nós USE and ConverT. Léirímid úsáideacht agus infheidhmeacht leathan na mbrathadóirí rún beartaithe, ag taispeáint: 1) go sáraíonn siad na brathadóirí intinne bunaithe ar mhionchoigeartú a dhéanamh ar mhúnla iomlán BERT-Large nó ag baint úsáide as BERT mar ionchódóir bosca dubh seasta ar thrí thacar sonraí braite rún éagsúla. ; 2) tá na gnóthachain le sonrú go háirithe i socruithe cúpla lámhaigh (i.e., gan ach 10 nó 30 sampla anótáilte in aghaidh na hintinne); 3) is féidir ár brathadóirí intinne a oiliúint i gceann cúpla nóiméad ar LAP amháin; agus 4) go bhfuil siad cobhsaí ar fud socruithe hipearpharaiméadair éagsúla. Agus muid ag súil le taighde dírithe ar bhrath intinne a éascú agus a dhaonlathú, scaoilimid ár gcód, chomh maith le tacar sonraí braite aon-raoin dúshlánach nua a chuimsíonn 13,083 sampla anótáilte thar 77 rún.', 'el': 'Η οικοδόμηση συστημάτων συνομιλίας σε νέους τομείς και με προστιθέμενη λειτουργικότητα απαιτεί μοντέλα αποδοτικά με πόρους που λειτουργούν κάτω από καθεστώτα χαμηλών δεδομένων (δηλ. σε ρυθμίσεις λίγων πλάνων). Με κίνητρο από αυτές τις απαιτήσεις, εισάγουμε μεθόδους ανίχνευσης προθέσεων που υποστηρίζονται από προκαθορισμένους κωδικοποιητές διπλών προτάσεων όπως ΧΡΗΣΗ και ConveRT. Αποδεικνύουμε τη χρησιμότητα και την ευρεία δυνατότητα εφαρμογής των προτεινόμενων ανιχνευτών προθέσεων, δείχνοντας ότι: 1) υπερτερούν των ανιχνευτών προθέσεων με βάση την τελειοποίηση του πλήρους μοντέλου ή τη χρήση του ως σταθερού κωδικοποιητή μαύρου κουτιού σε τρία διαφορετικά σύνολα δεδομένων ανίχνευσης προθέσεων. 2) τα κέρδη είναι ιδιαίτερα έντονα σε ρυθμίσεις λίγων πυροβολισμών (δηλ., με μόνο 10 ή 30 σχολιασμένα παραδείγματα ανά πρόθεση)· 3) οι ανιχνευτές προθέσεών μας μπορούν να εκπαιδευτούν μέσα σε λίγα λεπτά σε έναν ενιαίο επεξεργαστή. και 4) είναι σταθεροί σε διαφορετικές ρυθμίσεις υπερπαραμέτρων. Ελπίζοντας να διευκολύνουμε και να εκδημοκρατίσουμε την έρευνα που επικεντρώνεται στην ανίχνευση προθέσεων, κυκλοφορούμε τον κώδικα μας, καθώς και ένα νέο προκλητικό σύνολο δεδομένων ανίχνευσης προθέσεων ενός τομέα που περιλαμβάνει 13.083 σχολιασμένα παραδείγματα πάνω από 77 προθέσεις.', 'ka': 'ახალი დიომენში და დამატებული ფუნქციალურობით კონტუნქციალური სისტემების შექმნა უნდა რესურსის ეფექციალური მოდელები, რომლებიც მუშაობენ ცოტა მონაცემების რეზიმი (მა მოტივირული ამ შესაძლებლობით, ჩვენ ჩვენ შევცვალოთ საზოგადომის განვიხოვრების მეტი, რომლებიც USE და ConveRT-ის კოდერებით მხარდაჭირებული ორივე სიტყვებით. ჩვენ გამოჩვენებთ საზოგადომის მონაცემების გამოყენებელობას და უფრო საზოგადოებელობას, რომელიც გამოჩვენებენ, რომ: 1) ისინი გამოყენებენ საზოგადომის detectorები, რომელიც უფრო უფრო მეტი BERT- დიდი მოდელზე დააკეთებული, ან 2) შეიძლება განსაკუთრებულად გამოსახულებულია რამდენიმე სტატის კონფიგურაციაში (მაგალითად, მხოლოდ 10 ან 30 ანოტატირებული მაგალითებით მინდა); 3) ჩვენი საზოგადოებო დიტექტორი შეიძლება ერთი პროცესის შემთხვევაში შეიძლება განაკეთება; და 4) ისინი განსხვავებული ჰიპეროპარამეტრის პარამეტრების შესახებ სტაბილურია. დამეხოვრებით, რომ დახმარება და დემოკრატიზაცია სწორედ გავაკეთებთ საზოგადოება, ჩვენ გავაკეთებთ ჩვენი კოდის, და ახალი საზოგადოებელი საზოგადოება მონაცემების სექტი, რომელიც 13 083 მონაცემები', 'hu': 'A beszélgetési rendszerek új területeken történő kiépítése és kiegészítő funkcionalitásokkal rendelkező erőforrás-hatékony modelleket igényel, amelyek alacsony adatszintű rendszerek mellett működnek (például néhány felvétel esetén). Ezeknek a követelményeknek megfelelően bevezetjük az előkészített kettős mondatkódolókkal, például az USE és a ConveRT által támogatott szándék-felismerési módszereket. Bemutatjuk a javasolt szándék-érzékelők hasznosságát és széles körű alkalmazhatóságát, bemutatva, hogy: 1) a teljes BERT-Large modell finomhangolása vagy a BERT fix fekete dobozos kódolóként három különböző szándék-érzékelési adatkészleten felülmúlják a szándék-érzékelőket; 2) a nyereség különösen kifejezetten néhány lövéses beállításokban jelentkezik (azaz szándékunként csak 10 vagy 30 jegyzetelt példával); 3) szándék érzékelőink percek alatt képezhetők egyetlen CPU-n; és 4) stabil a különböző hiperparaméter beállítások között. A szándék felismerésére összpontosító kutatások megkönnyítésének és demokratizálásának reményében kiadjuk kódunkat, valamint egy új, kihívást jelentő, egydományos szándék felismerésére vonatkozó adatkészletet, amely 13 083 megjegyzett példát tartalmaz 77 szándéknál.', 'kk': 'Жаңа доменлерде және қосылған функциялық түрлендіру жүйелерді құру керек деректер режимдерінің астында жұмыс істейтін ресурс эффективті үлгілері (мысалы, бірнеше шарт баптауларында). Бұл қажеттерді қолдану үшін біз USE және ConveRT секілді екі сөз кодерлері қолданылатын нақты анықтау әдістерін келтіреміз. Біз келтірілген мақсатты анықтаушылардың пайдаланушылығын және көпшілігін көрсетедік: 1) олар толық BERT- Үлкен үлгі моделін баптауға негізделген мақсатты анықтаушыларды, немесе BERT- ді үш түрлі мақсатты анықтау керек деректерінің кодтамасы 2) жетістіктерді өзгеше бірнеше сүрлер баптауларында (мысалы, тек 10 немесе 30 жазылған мысалдар бар); 3) біздің мақсатымызды анықтаушыларымыз бір процессордың бірнеше мәселеде оқылмай алады; 4) олар басқа гиперпараметрлер параметрлерінде дұрыс болады. Біз зерттеулерді көмектесу және демократизациялауға көмектесу үшін көмектесіміздің кодымызды, сондай-ақ 77 мақсаттарынан артық 13 083 мәселелерді жаңа бір доменге көмектесетін жаңа мәселелерді анықтау үші', 'it': "Costruire sistemi di conversazione in nuovi domini e con funzionalità aggiuntive richiede modelli efficienti sotto il profilo delle risorse che funzionano con regimi a basso contenuto di dati (ad esempio, con configurazioni a pochi scatti). Motivati da questi requisiti, introduciamo metodi di rilevamento degli intenti supportati da encoder dual sentence pre-addestrati come USE e ConveRT. Dimostriamo l'utilità e l'ampia applicabilità dei rivelatori di intenti proposti, dimostrando che: 1) superano i rivelatori di intenti basati sulla messa a punto del modello BERT-Large completo o utilizzando BERT come codificatore fisso a scatola nera su tre diversi set di dati di rilevamento degli intenti; 2) i guadagni sono particolarmente pronunciati nelle configurazioni a pochi colpi (cioè, con solo 10 o 30 esempi annotati per intento); 3) i nostri rilevatori di intenti possono essere addestrati in pochi minuti su una singola CPU; e 4) sono stabili attraverso diverse impostazioni di iperparametri. Nella speranza di facilitare e democratizzare la ricerca focalizzata sul rilevamento delle intenzioni, rilasciamo il nostro codice, così come un nuovo impegnativo set di dati di rilevamento delle intenzioni monodominio comprendente 13.083 esempi annotati su 77 intenti.", 'mk': 'Изградбата на конверзационални системи во нови домени и со додадена функционалност бара модели ефикасни во ресурсите кои работат во режими со ниски податоци (т.е. во неколку поставувања). Мотивирани од овие барања, воведуваме методи за детекција на намери поддржани од претренирани кодери на две реченици како што се УСЕ и ConveRT. Ние ја демонстрираме корисноста и широката апликабилност на предложените детектори на намери, покажувајќи дека: 1) тие ги надминуваат детекторите на намери базирани на финетизирање на целиот BERT-Голем модел или користејќи BERT како фиксен кодер со црна кутија на три различни набори податоци за детектирање намери; 2) добивките се особено изразени во неколку поставувања (т.е., со само 10 или 30 примери наведени по намера); 3) our intent detectors can be trained in a matter of minutes on a single CPU;  and 4) they are stable across different hyperparameter settings.  Во надеж дека ќе го олесниме и демократизираме истражувањето фокусирано на детекција на намерите, го ослободиме нашиот код, како и нов предизвикувачки набор на податоци за детекција на намерите на еден домен, кој вклучува 13.083 примери од 77 намери.', 'lt': 'Building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes (i.e., in few-shot setups).  Motyvuojami šiais reikalavimais, įvedame sąmoningumo nustatymo metodus, remiamus iš anksto parengtais dviejų sakinių kodatoriais, pvz., USE ir ConveRT. We demonstrate the usefulness and wide applicability of the proposed intent detectors, showing that: 1) they outperform intent detectors based on fine-tuning the full BERT-Large model or using BERT as a fixed black-box encoder on three diverse intent detection data sets;  2) pelnas yra ypač didelis nedideliu mastu (t. y. tik 10 arba 30 užrašytų pavyzdži ų vienam ketinimui); 3) mūsų ketinimų detektorius galima apmokyti per kelias minutes vienoje CPU; ir 4) jos yra stabilios įvairiose hiperparatorių aplinkybėse. Tikimės palengvinti ir demokratizuoti mokslinius tyrimus, kuriais daugiausia dėmesio skiriama ketinimų nustatymui, išleisime savo kodeksą, taip pat naują sudėtingą vienos srities ketinimų nustatymo duomenų rinkinį, apimantį 13 083 užrašytus pavyzdžius iš 77 ketinimų.', 'ml': "പുതിയ ഡോമെനുകളില്\u200d സംസാരിക്കുന്ന സിസ്റ്റമുകള്\u200d പണിയുകയും ചേര്\u200dക്കുന്ന ഫങ്ഷനിയോടൊപ്പം ചേര്\u200dക്കുകയും ചെയ്യുന്ന വിഭവങ്ങള്\u200d കുറഞ്ഞ ഡ ഈ ആവശ്യങ്ങള്\u200d പ്രാവര്\u200dത്തികമാക്കിയിരിക്കുന്നു, യുസൈയും കോണ്\u200dവെര്\u200dവെര്\u200dട്ടിയും പോലുള്ള രണ്ടു വാക്കുകളുടെ കോഡോര്\u200dഡുകള്\u200d പി പ്രൊദ്ദേശിക്കപ്പെട്ട intent detectors' ഉപയോഗവും വിശാലമായ പ്രയോഗവും നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നു. അത് കാണിച്ചുകൊണ്ടിരിക്കുന്നു: 1) മുഴുവന്\u200d ബെര്\u200dട്ടി- വലിയ മോഡലിനെ സൂക 2) പ്രത്യേകിച്ച് വെടിവെക്കപ്പെടുന്ന കുറച്ച് വെടിവെക്കപ്പെട്ട കുറ്റങ്ങളില്\u200d നിന്ന് സമ്മാനം പ്രസ്താവിക് 3) നമ്മുടെ ലക്ഷ്യം ഡിക്റ്ററുകള്\u200dക്ക് ഒരു സിപിയുവില്\u200d ഒരു മിനിട്ടിനുള്ളില്\u200d പരിശീലിക്കാന്\u200d കഴിയും. 4) വ്യത്യസ്ത ഹൈപ്പര്\u200dപാരാമീറ്റര്\u200d സജ്ജീകരണങ്ങളില്\u200d അവര്\u200d സ്ഥിരമായിരിക്കുന്നു. നിരീക്ഷിക്കുന്നതിനെയും ജനാധിപത്യത്തെയും ശ്രദ്ധിക്കുന്നതിനെയും പ്രതീക്ഷിക്കുന്നതിനായി, ഞങ്ങള്\u200d നമ്മുടെ കോഡിനെയും പുതിയ വ്യാല്\u200dവെച്ച് ഡേറ്റ", 'mt': "Building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes (i.e., in few-shot setups).  Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT.  Jiġu murija l-utilità u l-applikabbiltà wiesgħa tad-detetturi tal-intenzjoni proposti, li juru li: 1) huma jaqbżu d-detetturi tal-intenzjoni bbażati fuq l-irfinar tal-mudell sħiħ BERT-Kbar jew l-użu tal-BERT bħala kodifikatur fiss tal-kaxxa sewda fuq tliet settijiet ta’ dejta ta’ detezzjoni tal-intenzjoni differenti; 2) il-qligħ huwa speċjalment evidenti f’settijiet bi ftit skopijiet (jiġifieri, b’10 jew 30 e żempju annotati biss għal kull intenzjoni); 3) id-detetturi tal-intenzjoni tagħna jistgħu jitħarrġu fi kwistjoni ta’ minuti fuq CPU waħda; u 4) huma stabbli f’setturi differenti ta’ iperparaturi. Fit-tama li tiġi ffaċilitata u demokratizzata r-riċerka ffukata fuq l-iskoperta tal-intenzjonijiet, nirrilaxxaw il-kodiċi tagħna, kif ukoll sett ġdid ta' dejta ġdid ta' skoperta tal-intenzjonijiet f'dominju uniku li jinkludi 13,083 eżempju annotat fuq 77 intenzjoni.", 'mn': 'Шинэ хэсэгт харилцааны системийг бүтээх болон нэмэгдсэн функцийн чадвар бага өгөгдлийн режим доор ажилладаг ресурс бүтээмжтэй загварууд хэрэгтэй. Эдгээр шаардлагатай шаардлагатай нь бид зорилгоор олох арга замыг харуулж байна. Яг USE болон ConveRT зэрэг хоёр давхар өгүүлбэрийн коддогчид дэмжигдсэн. Бид санал өгсөн зорилго тогтоогчдын хэрэглээ болон өргөн хэрэглээ гэдгийг харуулж байна. 1) тэд бүрэн BERT-том загварыг тодорхойлох эсвэл BERT-г гурван төрлийн зорилго тогтоох өгөгдлийн санааны шинжлэх ухааны шинжлэх ухааны шинжлэх ухааны шинжлэх ухааны 2) Ялангуяа хэд хэдэн зурагт авсан зардал (яг л зөвхөн 10 эсвэл 30 зөвхөн анзаарагдсан жишээ) гэдэг. 3) Бидний зорилго тогтоогчид нэг процессорын тухай хэдэн минутын дараа сургалт хийж чадна. 4) тэд өөр гиперпараметр дээр тогтмол байдаг. Судалгааны тусламжтайгаар, ардчилсан судалгааны тусламжтайгаар төвлөрсөн гэдэгт итгэл найдаж, бид бидний кодыг, мөн 77 зорилго дээр 13 083 анзаарсан жишээ авч ирсэн шинэ шаардлагатай нэг зорилготой өгөгдлийн санааг олох гэсэн найдвар юм.', 'ro': 'Construirea sistemelor de conversație în domenii noi și cu funcționalitate adăugată necesită modele eficiente din punct de vedere al resurselor, care funcționează în regimuri cu date scăzute (de exemplu, în setări cu puține fotografii). Motivați de aceste cerințe, introducem metode de detectare a intenției susținute de codificatoare cu două propoziții precum USE și ConveRT. Demonstrăm utilitatea și aplicabilitatea largă a detectoarelor de intenție propuse, arătând că: 1) acestea depășesc detectoarele de intenție pe baza reglării fine a modelului complet BERT-Large sau utilizând BERT ca codificator fix cu cutie neagră pe trei seturi de date diverse de detectare a intențiilor; 2) câștigurile sunt pronunțate în special în setările cu puține lovituri (adică, cu doar 10 sau 30 de exemple adnotate pe intenție); 3) detectoarele noastre de intenție pot fi instruite în câteva minute pe un singur procesor; și 4) sunt stabile în diferite setări de hiperparametru. În speranța de a facilita și democratiza cercetarea axată pe detectarea intențiilor, lansăm codul nostru, precum și un nou set de date provocator de detectare a intențiilor unice, cuprinzând 13.083 exemple adnotate peste 77 de intenții.', 'ms': 'Bina sistem perbualan dalam domain baru dan dengan fungsi tambahan memerlukan model efisien sumber yang berfungsi di bawah režim data rendah (i.e., dalam beberapa tetapan tembakan). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT. Kami menunjukkan kebaikan dan kemudahan luas penemui niat yang diusulkan, menunjukkan bahawa: 1) mereka melampaui pengesan niat yang berdasarkan penyesuaian baik model BERT-Besar penuh atau menggunakan BERT sebagai pengekod kotak hitam tetap pada tiga set data pengesan niat berbeza; 2) keuntungan terutama diungkapkan dalam setup beberapa tembakan (iaitu hanya dengan 10 atau 30 contoh yang dicatat setiap niat); 3) pengesan tujuan kita boleh dilatih dalam beberapa minit pada satu CPU; and 4) they are stable across different hyperparameter settings.  Dalam harapan untuk memudahkan dan demokratisasikan kajian yang fokus pada pengesan tujuan, kami melepaskan kod kami, serta set data pengesan tujuan domain tunggal yang mencabar yang mengandungi 13,083 contoh yang dicatat lebih dari 77 tujuan.', 'sr': 'Izgradavanje razgovornih sistema u novim domenama i sa dodanom funkcionalnošću zahteva efikasne modele resursa koji rade pod nizim podacima (tj. u nekoliko snimanja). Motivirani ovim zahtevima, predstavljamo metode otkrivanja namjera podržavane koderima dvostruke rečenice poput USE i ConveRT. Mi pokazujemo korisnost i široku primjenu predloženih detektora namjera, pokazujući da: 1) oni izvršavaju namjerne detektore na osnovu finalnog prilagodbe kompletnog model a BERT-Velikog modela ili koriste BERT kao fiksni koder crne kutije na tri seta podataka o otkrivanju različitih namjera; 2) dobitke su posebno izjavljene u nekoliko snimanja (tj. sa samo 10 ili 30 primjera po namjeru); i 3) naši detektori namjere mogu biti obučeni u nekoliko minuta na jednom procesoru; i 4) stabilni su preko različitih hiperparametara. Nadajući se da će olakšati i demokratizirati istraživanje usredotočeno na otkrivanje namjera, oslobodimo naš kodeks, kao i novi izazovni set podataka za otkrivanje jedinstvenog domena koji sastoji od 13.083 annotiranih primjera preko 77 namjera.', 'pl': 'Budowanie systemów konwersacyjnych w nowych domenach i z dodatkową funkcjonalnością wymaga modeli efektywnych zasobami, które działają w reżimech niskiej ilości danych (tj. w konfiguracjach kilku ujęć). Motywowani tymi wymaganiami wprowadzamy metody detekcji intencji wspierane wstępnie przeszkolonymi koderami podwójnych zdań, takimi jak USE i ConveRT. Wykazujemy przydatność i szerokie zastosowanie proponowanych detektorów intencji, pokazując, że: 1) wydają one wyniki detektorów intencji opartych na dostosowaniu pełnego modelu BERT-Large lub wykorzystując BERT jako stały koder czarnej skrzynki na trzech różnych zbiorach danych detekcji intencji; 2) zyski są szczególnie wyraźne w konfiguracjach kilku strzałów (tj. z tylko 10 lub 30 adnotacji przykładów na intencję); 3) nasze detektory intencji mogą być przeszkolone w ciągu kilku minut na jednym procesorze; i 4) są stabilne w różnych ustawieniach hiperparametrów. W nadziei na ułatwienie i demokratyzację badań koncentrujących się na wykrywaniu intencji, publikujemy nasz kod, a także nowy wymagający zestaw danych wykrywania intencji pojedynczej domeny zawierający 13,083 adnotacje przykładów ponad 77 intencji.', 'so': "Degmooyinka cusub ku dhisashada nidaamka iskala hadlitaanka iyo waxyaabaha lagu daro waxay u baahan yihiin noocyo faa’iido leh oo ka shaqeeya xeerarka hoose-data (tusaale ahaan kooxaha wax yar oo lagu dhuftay). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT.  Waxaynu muujinnaa faa'iidada iyo ballaadhan ee qofka la soo jeeday, waxayna muujiyaan in ay sameeyaan qalabka inteniga ah oo ku saleysan hagaajinta modelka buuxda BERT-Large ama ku isticmaalaan BERT sida koox madow-box oo madow ah oo ku qoran saddex koox oo macluumaad ah oo kala duduwan; 2) Waxyaabaha la soo qaatay waxaa si gaar ah looga sheegaa dhibaatooyin yar oo lagu dhuftay (tusaale ahaan 10 ama 30 tusaale ahaan oo kaliya). 3) xisaabiyayaasheena waxqabadka ah waxaa la tababari karaa muddo daqiiqo ah oo kaliya CPU; 4) waxay ku adag yihiin xarumaha heerarka kala duwan. Waxaan rajaynayaa in waxbarashada la fududeeyo oo lagu beddelo, waxaynu u sii daynaa aqoonsigayaga, sidoo kale sawir cusub oo la soo ogaanayo macluumaadka kooxaha halka gudaha ah oo ku qoran 13,083 tusaalooyin ka badan 77 noocyo.", 'si': 'අළුත් ඩෝමේන් වල වාර්තාවක් පද්ධතිය නිර්මාණය කරන්න සහ සම්බන්ධ වැඩක් සඳහා සම්බන්ධ වැඩක් අවශ්\u200dයය සඳහා පරීක්ෂාත්මක අපි මේ අවශ්\u200dයයෙන් හොයාගන්න හැකියුම් විදියට පරීක්ෂණය කරලා තියෙන්නේ, USE සහ ConveRT විදියට පරීක්ෂණය කරන දෙවල් වාක්ය අපි ප්\u200dරදර්ශනය කරනවා ප්\u200dරවේශනය සහ විශේෂ ප්\u200dරවේශකයේ ප්\u200dරවේශකය සහ ප්\u200dරවේශකය, ප්\u200dරවේශකයෙන්: 1) ඔවුන් පුරුණු BERT- ලොකු මොඩේල් එක සඳහා ප්\u200dරවේශකය සඳහා ප්\u200dරවේ 2) විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂය කරලා තියෙන්නේ (ඉතින් විශේෂයෙන් වි 3) අපේ අදහස් පරීක්ෂකයන්ට පුළුවන් විනාඩියක් පරීක්ෂණය කරන්න පුළුවන් CPU එක්කෙන් විනාඩියකට; 4) ඔවුන් වෙනස් හායිපර් ප්\u200dරමාණය සැකසුම් වලට ස්ථිර වෙනවා. අපි අපේ කෝඩ් හොයාගන්න හැටියට පරීක්ෂණය සහ ප්\u200dරධානය කරන්න හැටියට අවශ්\u200dයයෙන්, අපි අපේ කෝඩ් හොයාගන්න හැටියට අළුත් ප්\u200dරශ්නයක් සහ අළුත් එක්', 'sv': 'Att bygga konversationssystem i nya domäner och med extra funktionalitet kräver resurseffektiva modeller som fungerar under lågdataregimer (dvs. i enstaka inställningar). Motiverade av dessa krav introducerar vi avsiktsdetekteringsmetoder som stöds av förkränade dubbla meningskoder som USE och ConveRT. Vi visar nyttan och den breda tillämpningen av de föreslagna avsiktsdetektorer och visar att: 1) de presterar bättre än avsiktsdetektorer baserat på finjustering av hela BERT-Large-modellen eller använder BERT som en fast svartboxkodare på tre olika uppsättningar avsiktsdetekteringsdata. 2) Vinsterna är särskilt uttalade i några skott konfigurationer (dvs. med endast 10 eller 30 kommenterade exempel per avsikt); 3) våra avsiktsdetektorer kan utbildas på några minuter på en enda CPU; och 4) de är stabila över olika hyperparameter inställningar. I hopp om att underlätta och demokratisera forskning inriktad på avsiktsdetektering släpper vi vår kod, samt ett nytt utmanande dataset för avsiktsdetektering med en domän bestående av 13 083 kommenterade exempel över 77 intentioner.', 'ta': '@ info இந்த விருப்பங்களால் இயக்கப்பட்டது, USE மற்றும் ConveRT போன்ற இருமுறை வாக்கியின் குறியீடு நாம் பரிந்துரைக்கப்பட்டுள்ள விருப்பத்தின் பயன்பாடு மற்றும் அகலமான பயன்பாடு 2) சில துடைக்கப்பட்ட அமைப்புகளில் வெளிப்படுத்தப்பட்டுள்ளது (அதாவது, நிலைக்கு மட்டும் 10 அல்லது 30 துக்கப்பட்ட உதாரணங்கள 3) our intent detectors can be trained in a matter of minutes on a single CPU;  4) மேலும் அவர்கள் வேறு மின்னெழுத்து அளபுரு அமைப்புகளில் உறுதியாக இருக்கின்றன. நாம் கண்டுபிடிப்பதற்கு கவனமாக ஆராய்ச்சி மற்றும் வடிவமைக்கும் ஆராய்ச்சி எதிர்பார்ப்பிற்கு, நாம் எங்கள் குறியீட்டை வெளியிடுவோம், மற்றும் ஒரு ப', 'no': 'Bygging av konvertasjonssystemet i nye domene og med tillegg av funksjonalitet krev ressurseffektiv modeller som arbeidar under låg dataregime (t.d. i få fotografiske oppsett). Av desse kreveta, introduserer vi metoder for oppdaging som er støtta av trekkkodarar med trekking av dobbelt setningar, slik som USE og ConveRT. Vi viser at det er nyttig og breidde tilgjengeligheten til dei foreslåtte inntekningsmaterne, viser at: 1) dei utfører inntekningsmaterne basert på finnstilling av den fulle BERT- store modellen eller brukar BERT som ein fast svartbokskoder på tre ulike målsettingar for oppdaging av data. 2) gjennomsnittet er spesielt uttalet i få fotooppsett (t.d. berre med 10 eller 30 uttale eksemplar per intensjon); 3) målsettingsdetektatorane våre kan trenjast i ein del minutt på ein enkelt prosessor; og 4) dei er stabile over ulike hyperparameter-innstillingar. I håp for å gjera forskning som er tilgjengeleg og demokratisert fokusert på oppdaging av vilkåra, så løyser vi koden vårt, og eit nytt utfordrende datasett for oppdaging av enkeldomene som inneheld 13 083 markerte eksemplar over 77 vilkåra.', 'ur': 'نو ڈومین میں مکانٹ سیسٹم بنانے اور زیادہ فعالیت کے ساتھ مکانٹ سیسٹم کی ضرورت ہے کہ کم ڈاٹ ریجیمز کے نیچے کام کریں یہ ضرورت کے ذریعے چلنے والے ہیں، ہم نے مطلب پیدا کرنے کے طریقے پیش کیے ہیں جن کی پشتیبانی دئیویل جماعت کوڈر جیسے USE اور ConveRT کے ذریعے ہیں. ہم نشان دیتے ہیں کہ پیشنهاد ارادہ ڈیٹونٹروں کے فائدہ اور وسیع کاربری کا استعمال کرتا ہے، یہ کہ: 1) وہ تمام BERT-بزرگ موڈل کو پاکیزہ تنظیم کرنے پر بنیاد رکھتے ہیں یا BERT کو تین مختلف انتظام ڈیٹ سٹوں پر ثابت سیاہ باکس کا انکوڈر بناتے ہیں۔ 2) غنیمتیں مخصوص تھوڑے شٹ کے سامان میں پڑھی جاتی ہیں (یعنی صرف ۱۰ یا ۳۰ مثالیں لکھی جاتی ہیں) 3) ہمارے ارادہ ڈاکٹر ایک سی پی یو کے بارے میں ایک منٹ کے بارے میں آموزش کی جاتی ہیں۔ اور 4) وہ مختلف ہیپر پارامیٹوں کے اندر ثابت ہیں۔ اس کی امید ہے کہ تحقیقات کی آسانی اور دموکراتیزی کے ذریعہ مطالبہ آزمائش پر تمرکز کیا گیا ہے، ہم نے اپنے کوڈ کو چھوڑ دیا ہے، اور ایک ڈومین کا ایک مشکل ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈ', 'uz': "Name Bu takliflar bilan ishga tushirilgan, biz USE va ConveRT kabi ikki maxfiy soʻzning kodlari bilan qoʻllanilgan intent aniqlash usullarini ishlatimiz. Biz talab qilingan qatlam detektorlarining foydalanishini va kengaytirish qobiliyatini koʻrsatimiz. Ko'rsatish mumkin: 1) ular butun BERT- katta modelini ajratish asosida ko'rsatadi yoki uchta xil maʼlumot tizimini qidirish uchun BERT'ni boshqarish imkoniyatini ko'rsatadi; 2) Mavzular faqat bir necha saqlangan tizimlarda (balki faqat qanday 10 yoki 30 misollar bilan keladi). 3) Bizning qanday detektorlarimiz bir necha daqiqa daqiqa o'rganishi mumkin. va 4) ular boshqa hyperparametr moslamalariga stabil. Tafitini aniqlash uchun foydalanish va demokrasiy qilish uchun, biz qoidamizni chiqaramiz, va biz 77 ta'minga bir qanday qanday qiziqarish uchun yangi qiziqarli maʼlumotlar tarkibini aniqlashimiz mumkin.", 'vi': 'Xây dựng hệ thống đối thoại trong những miền mới và có tính năng thêm đòi hỏi các mô hình hiệu quả nguồn tài nguyên có tác dụng trong chế độ ít dữ liệu (tức là cài đặt ít). Động cơ bởi những yêu cầu này, chúng tôi giới thiệu phương pháp phát hiện ý đồ được hỗ trợ bởi mã hóa hai bản án chuẩn như chuẩn bị sử dụng và thuyết phục. Chúng tôi cho thấy sự hữu dụng và rộng rãi của các máy dò ý định đề xuất, cho thấy: 1) chúng vượt trội các bộ máy dò có mục đích dựa trên độ chỉnh sửa toàn bộ mô hình BERT-Large hoặc sử dụng BERT như một bộ mã hóa hộp đen cố định trên ba bộ dữ liệu trinh thám khác nhau; 2) lợi nhuận được phát triển đặc biệt trong cài đặt ít phát triển (v.d. chỉ có mười hay ba mươi đi ển ghi chú cho mục đích) Ba) Máy phát hiện mục đích có thể được huấn luyện chỉ trong vài phút. và 4) chúng ổn định trên các thiết lập siêu tham số khác nhau. Với hy vọng giúp đỡ và dân chủ nghiên cứu tập trung vào dự án khám phá mục đích, chúng tôi giải phóng mã của chúng tôi, cũng như một tập tin dữ liệu trinh sát chủ nhiệm mới đầy thử thách gồm bộ 1,03 và ghi chú trên bộ định 77.', 'bg': 'Изграждането на разговорни системи в нови области и с добавена функционалност изисква ефективно използване на ресурсите модели, които работят при режими с ниско съдържание на данни (т.е. при няколко настройки). Мотивирани от тези изисквания, ние въвеждаме методи за откриване на намерения, подкрепени от предварително тренирани кодери с двойни изречения, като например УЕЗ и КонвеRT. Ние демонстрираме полезността и широката приложимост на предложените детектори за намерение, показвайки, че: 1) те превъзхождат детекторите за намерение въз основа на фина настройка на пълния модел или използване на фиксиран кодер за черна кутия върху три различни набора данни за откриване на намерения; 2) печалбите са особено изразени при няколко снимки (т.е. само с 10 или 30 анотирани примера за намерение); 3) нашите детектори за намерение могат да бъдат обучени за минути на един процесор; и 4) те са стабилни в различни настройки на хиперпараметъра. С надеждата да улесним и демократизираме изследванията, фокусирани върху откриването на намерения, ние публикуваме нашия код, както и нов предизвикателен набор от данни за откриване на намерения с един домейн, включващ 13 083 анотирани примера над 77 намерения.', 'nl': 'Voor het bouwen van conversatiesystemen in nieuwe domeinen en met toegevoegde functionaliteit zijn resource-efficiënte modellen nodig die werken onder low-data regimes (d.w.z. in enkele-shot setups). Gemotiveerd door deze vereisten introduceren we intentiedetectiemethoden ondersteund door vooraf getrainde dubbele zinnencoders zoals USE en ConveRT. We demonstreren het nut en de brede toepasbaarheid van de voorgestelde intentiedetectoren, waaruit blijkt dat: 1) ze beter presteren dan intentiedetectoren op basis van finetuning van het volledige BERT-Large model of het gebruik van BERT als vaste black-box encoder op drie verschillende intentiedetectie datasets; 2) de winsten zijn vooral uitgesproken in weinige-shot opstellingen (d.w.z. met slechts 10 of 30 geannoteerde voorbeelden per intentie); 3) onze intentiedetectoren kunnen worden getraind in een kwestie van minuten op een enkele CPU; en 4) ze zijn stabiel over verschillende hyperparameter instellingen. In de hoop om onderzoek gericht op intentiedetectie te faciliteren en te democratiseren, brengen we onze code uit, evenals een nieuwe uitdagende dataset voor intentiedetectie met 13.083 geannoteerde voorbeelden boven 77 intenties.', 'da': 'Opbygning af samtalesystemer i nye domæner og med ekstra funktionalitet kræver ressourceeffektive modeller, der arbejder under low-data regimer (dvs. i få skud opsætninger). Motiveret af disse krav, introducerer vi hensigtsdetekteringsmetoder understøttet af forudtrænede dobbeltsætningskodere som USE og ConveRT. Vi demonstrerer nytten og den brede anvendelighed af de foreslåede intentionsdetektorer og viser, at: 1) de overgår intentionsdetektorer baseret på finjustering af hele BERT-Large-modellen eller bruger BERT som en fast sort bokskoder på tre forskellige intentionsdetektionsdatasæt; 2) gevinsterne er især udtalt i nogle-skud opsætninger (dvs. med kun 10 eller 30 annoterede eksempler pr. hensigt); 3) vores intent detektorer kan trænes i løbet af få minutter på en enkelt CPU; og 4) de er stabile på tværs af forskellige hyperparameter indstillinger. I håb om at lette og demokratisere forskning, der fokuserer på intention detektion, frigiver vi vores kode, samt et nyt udfordrende single-domæne intention detection datasæt bestående af 13.083 kommenterede eksempler over 77 intentions.', 'hr': 'Izgradavanje razgovornih sustava u novim domenama i s dodanom funkcionalnošću zahtijeva efikasne modele resursa koji rade pod nizim podacima (tj. u nekoliko snimanja). Pod motivacijom ovih zahtjeva, predstavljamo metode otkrivanja namjera podržane koderima dvostruke rečenice poput USE i ConveRT. Mi pokazujemo korisnost i široku primjenu predloženih detektora namjera, pokazujući da: 1) oni izvršavaju namjerne detektore na temelju finalnog prilagođenja punog model a BERT-Velikog ili koristeći BERT kao fiksni koder crne kutije na tri različite namjere otkrivanja podataka; 2) dobitke su posebno izjavljene u nekoliko snimanja (tj. s samo 10 ili 30 primjera za namjeru primjera). 3) naši detektori namjere mogu biti obučeni u nekoliko minuta na jednom procesoru; i 4) stabilni su preko različitih hiperparametara. Nadajući se da će olakšati i demokratizirati istraživanje usredotočeno na otkrivanje namjera, osloboditi ćemo naš kodeks, kao i novi izazovni set podataka za otkrivanje jedinstvenog domena koji sadrže 13.083 primjera iznosi preko 77 namjera.', 'de': 'Der Aufbau von Gesprächssystemen in neuen Domänen und mit zusätzlicher Funktionalität erfordert ressourceneffiziente Modelle, die unter Low-Data-Regimes (d.h. in wenigen Aufnahmen) funktionieren. Motiviert durch diese Anforderungen führen wir Intent Detection Methoden ein, die durch vortrainierte Doppelsatz Encoder wie USE und ConveRT unterstützt werden. Wir demonstrieren die Nützlichkeit und breite Anwendbarkeit der vorgeschlagenen Absichtsdetektoren und zeigen, dass: 1) sie übertreffen Absichtsdetektoren, die auf der Feinabstimmung des vollständigen BERT-Large-Modells basieren oder BERT als fester Black-Box-Encoder auf drei verschiedenen Intent-Detection-Datensätzen verwenden; 2) die Gewinne sind besonders ausgeprägt in wenigen Aufnahmen (d.h. mit nur 10 oder 30 kommentierten Beispielen pro Intent); 3) Unsere Intent Detektoren können in wenigen Minuten auf einer einzigen CPU trainiert werden; und 4) sie sind über verschiedene Hyperparameter-Einstellungen stabil. In der Hoffnung, Forschung mit Schwerpunkt auf Intention Detection zu erleichtern und zu demokratisieren, veröffentlichen wir unseren Code sowie einen neuen herausfordernden Single-Domain Intent Detection Datensatz, der 13.083 kommentierte Beispiele über 77 Intents enthält.', 'id': 'Membangun sistem konversasi dalam domain baru dan dengan fungsi tambahan membutuhkan model efisien sumber daya yang bekerja di bawah resim data rendah (i.e., dalam beberapa setup tembakan). Dimotifkan oleh keperluan ini, kami memperkenalkan metode deteksi sengaja yang didukung oleh koder kalimat dua yang dilatih sebelum dilatih seperti USE dan ConveRT. Kami menunjukkan kebaikan dan aplikabilitas luas detektor tujuan yang diusulkan, menunjukkan bahwa: 1) mereka melampaui detektor tujuan berdasarkan penyesuaian model BERT-Besar lengkap atau menggunakan BERT sebagai koder kotak hitam tetap pada tiga set data deteksi tujuan berbeda; 2) the gains are especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated examples per intent);  3) detektor tujuan kita dapat dilatih dalam beberapa menit pada satu CPU; dan 4) mereka stabil melalui pengaturan hyperparameter yang berbeda. Dalam harapan untuk memfasilitasi dan demokratisasikan penelitian fokus pada deteksi niat, kami melepaskan kode kami, serta sebuah set data penelitian niat satu-domain menantang baru yang mengandung 13.083 contoh yang dicatat lebih dari 77 niat.', 'fa': 'ساختن سیستم\u200cهای مکالمانی در دامنهای جدید و با عملکرد اضافه کردن نیاز به مدل\u200cهای قابل فعالیت منابع است که زیر رژیم\u200cهای داده\u200cهای پایین کار می\u200cکنند (یعنی در تنظیم\u200cهای چند تصویر). توسط این نیازهای حرکت شده، ما روش شناسایی هدف را معرفی می کنیم که توسط رمز\u200cکننده\u200cهای دوباره\u200cی مجازات مانند USE و ConveRT پشتیبانی شده است. ما کاربردی و کاربردی وسیع از بازرسان هدف پیشنهاد را نشان می دهیم که: ۱) آنها بازرسان هدف را بر پایه سازی مدل BERT-بزرگ کامل یا استفاده از BERT به عنوان یک کودهر سیاه بوکس ثابت بر سه مجموعه داده\u200cهای شناسایی هدف مختلف انجام می\u200cدهند. 2) پیروزی مخصوصا در تنظیمات کمی (یعنی با فقط ۱۰ یا ۳۰ مثال مطلوب به عنوان هدف) تعریف می\u200cشود. 3) کارآگاه\u200cکنندگان هدف ما می\u200cتوانند در چند دقیقه در یک CPU آموزش داده شوند; و ۴) آنها در تنظیمات های هیپر پارامتر متفاوت ثابت هستند. امیدوارم تحقیقات را آسان و دموکراتیک کنترل کنیم که روی کشف قصد تمرکز شده است، ما کد خود را آزاد کنیم، و یک مجموعه اطلاعات شناسایی هدف یک دامنی جدید که شامل 13.083 مثالهایی که بیش از 77 هدف نشان داده شده است.', 'sw': 'Kujenga mifumo ya mazungumzo katika maeneo mapya na kuongeza kazi inahitaji mifano yenye ufanisi wa rasilimali inayofanya kazi chini ya utawala wa data (yaani katika seti chache zilizopigwa risasi). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT.  Tunaonyesha matumizi na matumizi mengi ya watambuzi wa nia ya pendekezo, wakionyesha kwamba: 1) wanafanya wachunguzi wenye lengo linalotumia vizuri kwa kutumia muundo mkubwa wa BERT au kutumia BERT kama kodi maalumu ya boksi nyeusi kwenye seti tatu za taarifa za kutambua; 2) Matokeo hayo yanatangazwa hasa katika matatizo machache yanayopigwa risasi (yaani, kwa mfano 10 au 30 tu kwa lengo hili); 3) wachambuzi wetu wanaweza kufundishwa katika dakika chache kwenye CPU moja; na 4) ni imara katika mazingira mbalimbali ya kipeperupa. Kwa matumaini ya kusaidia na kutetea utafiti ulijikita kwenye kutambua lengo, tunatoa sheria yetu, pamoja na seti mpya ya kutambua taarifa za ndani yenye lengo la pekee linalojumuisha mifano 13,083 yenye lengo la 77.', 'ko': '새로운 분야에서 세션 시스템을 구축하고 기능을 늘리려면 낮은 데이터 모델(즉 소량의 스냅샷 설정에서)에서 작업하는 자원 고효율 모델이 필요하다.이러한 수요를 바탕으로 우리는 미리 훈련된 이중 언어 인코더(예를 들어 USE와 ConveRT)가 지원하는 의도 검출 방법을 도입했다.우리는 제시된 의도 검출기의 실용성과 광범위한 적용성을 증명했다. 1) 이들은 마이크로스피커를 기반으로 한 버트 모델의 의도 검출기보다 낫거나 세 개의 다른 의도 검출 데이터 집합에서 버트를 고정 블랙박스 인코더로 사용하는 의도 검출기보다 낫다.2) 소수의 방포 설정(즉 각 의도는 주석 있는 예시 10개 또는 30개만 있음)에서 수익이 특히 현저하다.3) 우리의 목표 탐지기는 몇 분 내에 단일 CPU에서 훈련을 진행할 수 있다.4) 서로 다른 하이퍼매개변수 설정에서 안정적입니다.의도적 검측에 대한 연구를 추진하고 민주화하기 위해 우리는 우리의 코드와 도전적인 단일 의도적 검측 데이터 집합을 발표했다. 77개 이상의 의도를 가진 13083개의 주석 예시를 포함한다.', 'tr': 'Täze sahypalarda soňlaşma sistemalary gurlýan we eklendik funksiýaly resurslar etkinleşen nusgalarynyň astynda i şlenýän (meselâ, kiçi-resim düzümlerinde). Bu şartlar tarafından önlenmiş, USE ve ConveRT gibi arkalanmış iki sözle kodlayıcılar tarafından niyetli keşfetme yöntemlerini tanıtıyoruz. Biz teklip eden niýet detektoriň ullanlygyny we ullanlygyny görkezip otyrýarys. Şuny görkezýäris: 1) olar bütin BERT-Ullakan nusgasyny bejermek üçin dürli maksady detektoriň üstünde çykarýarlar ýada BERT-iň üstini bejermek üçin dürli maksady detektoriň kodegi ýaly ullanýarlar; 2) gazançlar özellikle birnäçe atly düzümlerinde takylýar (diňe 10 ýa 30 ýa-da niýe bilen ýazylýan mysal bardyr); 2 3) biziň maksadymyz bir CPU-da minutlarda bilim alyp biler; we 4) farklı hiperparameter ayarlarynda stabil. Araştyrymyzy bejermek we demokratik etmek üçin amaçlarymyzy tanamak üçin ünsüni çykarýarys, we 77 niýetinde 13,083 hasaplanýan ýaly täze bir domeny bejermek maksady çykarýarys.', 'sq': 'Ndërtimi i sistemeve bisedimore në fusha të reja dhe me funksionalitet të shtuar kërkon modele efikase në burime që punojnë nën regjime me të dhëna të ulëta (pra, në disa konfigurime). Motivuar nga këto kërkesa, ne futim metoda të zbulimit të qëllimeve të mbështetura nga koduesit e parastërvitur të dy dënimeve të tilla si USE dhe ConveRT. Ne demonstrojmë përdorueshmërinë dhe aplikabilitetin e gjerë të detektorëve të propozuar të qëllimeve, duke treguar se: 1) ata kryejnë detektorët e qëllimeve bazuar në rregullimin e modelit të plotë BERT-Large ose duke përdorur BERT si një kodues fiks të kutisë së zezë në tre grupe të dhënash të zbulimit të qëllimeve të ndryshme; 2) fitimet janë veçanërisht të shprehura në disa konfigurime (pra, me vetëm 10 apo 30 shembuj të shënuar për qëllim); 3) detektorët tonë të qëllimeve mund të trajnohen për një çështje minutash në një CPU të vetme; dhe 4) janë të qëndrueshme nëpërmjet rregullimeve të ndryshme të hiperparametrave. Në shpresë për lehtësimin dhe demokratizimin e kërkimit të përqëndruar në zbulimin e qëllimeve, ne lëshojmë kodin tonë si dhe një grup të ri sfidues për zbulimin e qëllimeve me një domeni të vetëm që përfshin 13,083 shembuj të anotuar mbi 77 qëllime.', 'am': 'በአዲስ ውይይት ውስጥ የሚካሄድ ስርዓቶች በመሠረት እና በተጨማሪው ሥርዓቶች ውስጥ የሚሠራ የክፍተኛ-ፍቃድ ሞዴላዎችን ያስፈልጋል (አዎን በጥቂት-shot setup) እንደዚህ ፈቃድ የተመሳሳይ፣ የአሜሪካ እና ConveRT እንደተደረገው የሁለት የፍርድ ክፍተቶችን በተመሳሳይ የመግለጫ ሥርዓቶችን እናሳውቃለን፡፡ 1) በሙሉ BERT-ትልቁ ሞዴል በመጠቀም ወይም በሦስት ልዩ ልዩ ልዩ ልዩ አካባቢ የጥቁር-box ኮድ በመጠቀም የጥቁር አካባቢ የሆኑን አካባቢ እናሳየዋለን፡፡ 2) ሀብት በተለየ በጥቂት በተወረዱት ድርጊቶች (ምናልባት 10 ወይም 30 ምሳሌዎች ብቻ ነው፡፡ 3) የስልጣን አዳራጮቻችን በጥቂት ደቂቃ ውስጥ አንድ CPU ማስተማር ይችላል፤ 4) በተለየ የhyperparameter አካባቢዎች ላይ ጥላቻዎች ናቸው ። ምርመራን ለማግኘት እና ዲሞክራሲ ለማግኘት ተስፋ እናደርጋለን፡፡ ኮዱን እና በ77 ዓይነት ላይ የሚቆጠሩ አዲስ የፍላጎት ዳታዎችን እናስፈታለን፡፡', 'af': "Opbou konversasiesstelsels in nuwe domeine en met byvoeg funksionaliteit benodig hulpbron-effektief modele wat werk onder lae-data rejimes (bv. in paar-skoot opstelling). Gebeweging deur hierdie benodighede, introduseer ons doel opdekking metodes wat agtergrond word deur voorreine tweede setkoders soos USE en ConveRT. Ons wys die gebruikerheid en wyde toepassing van die voorgestelde doel-detekteerders, wat vertoon dat: 1) hulle uitvoer doel-detekteerders gebaseer op fyn-tuning van die volle BERT-Groot model of gebruik BERT as 'n vaste swart-boks enkoder op drie verskeie doel-detekteerde data stelle; 2) die oorwinning is spesiaal uitgevoer in paar skoot opstelling (bv. met slegs 10 of 30 aangetekende voorbeelde per doel); 3) ons doel-detektors kan in â\x80\x99n saak van minute op â\x80\x99n enkele CPU onderwerp word; en 4) hulle is stabil oor verskillende hiperparameter instellings. In hoop om forskings te eenvoudig en demokrasiering te fokus op intensie opmekaar, laat ons ons kode verlos, en 'n nuwe aandagende enkel-domein-doel opmekaar datastel wat 13,083 opgemaak voorbeelde oor 77 doel.", 'az': "Yeni domeylərdə müzakirə sistemləri in şa etmək və əlavə edilmiş funksiyalıqla çox düşük məlumat rejimlərinin altında çalışan ressurs-effektiv modelleri lazım edir. Bu şartların tərəfindən hərəkət edildiyi, USE və ConveRT kimi iki cümləlik kodlayıcıların dəstəklənməsi üçün niyyətli keşif metodlarını təşkil edirik. Biz təbliğ edilmiş niyyət detektörlərinin faydalanılığını və geniş uyğunluğunu göstərdik, ki: 1) onlar bütün BERT-Büyük modelini düzəltməyə dayanan niyyət detektörlərini və ya BERT'i üç müxtəlif niyyət keçmə məqsədilə sabit siyah qutusu kodlayıcısı kimi istifadə edirlər. 2) Qazanlar xüsusilə az vuruş ayarları i çində müəyyən edilir (ya da yalnız 10 ya da 30 məsəllərlə müəyyən edilir); 3) Bizim niyyətimiz detektörlərimiz təkcə bir CPU-də bir dəqiqə içində təhsil edilə bilər; və 4) onlar müxtəlif hiperparameter ayarlarında sabitlidir. İstədiyimiz keşfini təşkil etmək və demokratik təşkil etmək üçün kodumuzu yayındırırıq, həmçinin 77 niyyətində 13.083 məsəllər çəkilən tək domena niyyətində olan yeni çətin təşkil edilən təşkil verilər qurulması üçün.", 'hy': 'Նոր բնագավառներում և ավելացված ֆունկցիոնալ համակարգերի կառուցվածքը պահանջում է ռեսուրսներով արդյունավետ մոդելներ, որոնք աշխատում են ցածր տվյալների համակարգերի (այսինքն՝ մի քանի նկարների կառուցվածքների ժամանակ): Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT.  Մենք ցույց ենք տալիս առաջարկած մտադրության դետեկտորների օգտակարությունը և լայն կիրառելիությունը, ցույց տալով, որ 1) նրանք արտադրում են մտադրության դետեկտորներ, որոնք հիմնված են BER-Large ամբողջ մոդելի բարձրացման վրա կամ BER-ի օգտագործման որպես ֆիքսավոր սև արկղի կոդեր երեք տարբեր մտադր 2) շահույթը հատկապես արտահայտվում է մի քանի նկարների կառուցվածքներում (այսինքն, միայն 10 կամ 30 նկարագրված օրինակ ունենալով յուրաքանչյուր նպատակի համար): 3) մեր մտադրությունների դետեկտորները կարող են մի քանի րոպեում սովորեցնել մեկ պրոցեսորի վրա: և 4) դրանք կայուն են տարբեր հիպերպարամետրերի միջև: Հույս ունենալով նպատակների հայտնաբերման վրա կենտրոնացված հետազոտությունների խրախուսելու և ժողովրդավարացման համար, մենք հրապարակում ենք մեր կոդը, ինչպես նաև նոր մարտահրավերներ մեկ բնագավառի նպատակների հայտնաբերման տվյալների համակարգ, որը ներառում է 13,083 նշո', 'bn': 'নতুন ডোমেইনে আলোচনা সিস্টেম নির্মাণ করা এবং এর সাথে যোগ করা কার্যকলাপের সাথে সম্পদ-কার্যকর মডেলের প্রয়োজন যা কম ডাটা শাসকদের নিচে কাজ করে (যেমন কয়ে এই প্রয়োজনের দ্বিতীয় বাণী এনকোডার, যেমন ইউএস আর কনভের্ট ট। আমরা প্রস্তাবিত গন্তব্য ডিটেক্টরের প্রয়োজন এবং ব্যাপারটি প্রদর্শন করি যেখানে দেখা যাচ্ছে: ১) তারা পূর্ণ বিবের্ট-ব্যাপক মডেলের ভিত্তিতে গুরুত্বপূর্ণ গুরুত্বপূর 2) the gains are especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated examples per intent);  ৩) আমাদের উদ্দেশ্য ডিটেক্টর একটি সিপিইউ-এ এক মিনিটের মধ্যে প্রশিক্ষণ প্রদান করা যাবে; এবং ৪) তারা বিভিন্ন হাইপার্পারামিটার বৈশিষ্ট্যের মধ্যে স্থির। গবেষণা সহায়তা এবং গণতান্ত্রিক করার আশায়, আমরা আমাদের কোড মুক্তি দেই, এবং একই সাথে একটি নতুন চ্যালেঞ্জালেঞ্জ ডেটার সনাক্তির উদাহরণের মাধ্যমে ১৩,০৮৩ জন', 'bs': 'Izgradnja razgovornih sustava u novim domenama i sa dodanom funkcionalnošću zahtijeva efikasne modele resursa koji rade pod nizim podacima (tj. u nekoliko snimanja). Pokrenuti ovim zahtjevima, predstavljamo metode otkrivanja namjera podržane pretkišenim koderima dvostruke rečenice poput USE i ConveRT. Mi pokazujemo korisnost i široku primjenu predloženih detektora namjere, pokazujući da: 1) oni izvršavaju namjerne detektore na temelju finalnog prilagođenja punog model a BERT-Velikog ili koristeći BERT kao fiksni koder crne kutije na tri različita namjera otkrivanja podataka; 2) dobitke su posebno izjavljene u nekoliko snimanja (tj. sa samo 10 ili 30 primjera na namjeru). 3) naši detektori namjere mogu biti obučeni u nekoliko minuta na jednom procesoru; i 4) stabilni su preko različitih hiperparametara. Nadajući se da će olakšati i demokratizirati istraživanje usredotočeno na otkrivanje namjera, oslobodimo naš kodeks, kao i novi izazovni set podataka za otkrivanje jedinstvenog domena koji sadrže 13.083 primjera iznosih 77 namjera.', 'cs': 'Budování konverzačních systémů v nových doménách a s přidanou funkcí vyžaduje efektivní modely, které fungují v režimech s nízkým množstvím dat (tj. v nastaveních s několika záběry). Motivováni těmito požadavky představujeme metody detekce záměru podporované předem trénovanými dvojitými větovými kodéry, jako jsou USE a ConveRT. Prokážeme užitečnost a širokou aplikaci navržených detektorů záměru a ukazujeme, že: 1) překonávají detektory záměru založené na jemném ladění plného modelu BERT-Large nebo používají BERT jako pevný snímač černé skříňky na třech různých datových sadách detekce záměru; 2) zisky jsou zvláště výrazné v několika sestavách (tj. s pouze deseti nebo 30 anotovanými příklady na záměr); 3) naše detektory záměru mohou být trénovány během několika minut na jednom procesoru; a 4) jsou stabilní napříč různými nastaveními hyperparametrů. V naději, že usnadníme a demokratizujeme výzkum zaměřený na detekci záměrů, vydáváme náš kód, stejně jako nový náročný datový soubor detekce záměrů pro jednu doménu obsahující 13,083 anotované příklady nad 77 záměry.', 'ca': "La construcció de sistemes de conversació en nous dominys i amb funcionalitat adicionada requereix models eficients en recursos que funcionen sota règims de baixos nivells de dades (és a dir, en configuracions poc fetes). Motivats per aquests requisits, introduïm mètodes de detecció d'intencions sostenits per codificadors de frases dobles pré-entrenats com USE i ConveRT. Demonstrem l'utilitat i l'ampla aplicabilitat dels detectors de intenció proposats, mostrant que: 1) superen els detectors de intenció basats en ajustar el model BERT-Large complet o utilitzen BERT com un codificador de caixa negra fixa en tres conjunts de dades de detecció de intencions diversos; 2) els guanys són especialment pronunciats en poques configuracions (és a dir, amb només 10 o 30 exemples anotats per intenció); 3) our intent detectors can be trained in a matter of minutes on a single CPU;  i 4) són estables a través de diferents configuracions hiperparamètriques. In hope of facilitating and democratizing research focused on intention detection, we release our code, as well as a new challenging single-domain intent detection dataset comprising 13,083 annotated examples over 77 intents.", 'et': 'Vestlussüsteemide loomine uutes valdkondades ja lisafunktsionaalsusega nõuab ressursitõhusaid mudeleid, mis töötavad madala andmepuudusega režiimides (st vähese võttega seadistustes). Nende nõuete alusel tutvustame kavatsuste tuvastamise meetodeid, mida toetavad eeltreenitud kahekordsed lausekodeerijad, nagu USE ja ConveRT. Näitame väljapakutud kavatsuste detektorite kasulikkust ja laialdast rakendatavust, näidates, et: 1) nad ületavad kavatsuste detektorid, mis põhinevad täielikul BERT-Large mudelil või kasutavad BERT-i fikseeritud musta kasti kodeerijana kolmel erineval kavatsuste tuvastamise andmekogumil; 2) kasu on eriti väljendatud vähese võtte seadistustes (st ainult 10 või 30 märgitud näidet kavatsuse kohta); 3) meie kavatsuste detektoreid saab treenida mõne minutiga ühel protsessoril; ja 4) nad on stabiilsed erinevate hüperparameetrite seadete puhul. Lootuses hõlbustada ja demokratiseerida kavatsuste tuvastamisele keskendunud uuringuid, avaldame oma koodi ja uue keerulise ühe domeeni kavatsuste tuvastamise andmekogumi, mis sisaldab 13 083 märgitud näidet 77 kavatsusest.', 'fi': 'Keskustelujärjestelmien rakentaminen uusille toimialoille ja lisätoiminnoilla edellyttää resurssitehokkaita malleja, jotka toimivat mataladataisissa järjestelmissä (eli muutamassa vaiheessa). Näiden vaatimusten pohjalta esittelemme intent detection -menetelmiä, joita tukevat ennalta koulutetut kaksoislausekooderit, kuten USE ja ConveRT. Osoitamme ehdotettujen intent-ilmaisimien hyödyllisyyden ja laajan sovellettavuuden osoittaen, että: 1) ne toimivat paremmin kuin intent-ilmaisimet, jotka perustuvat koko BERT-Large-mallin hienosäätöön tai BERT:n käyttämiseen kiinteänä mustana laatikkokoodarina kolmella erilaisella intent-tunnistustiedostolla; 2) voitot ovat erityisen voimakkaita muutaman laukauksen kokoonpanoissa (eli vain 10 tai 30 merkittyä esimerkkiä tarkoitusta kohti); 3) aikeenilmaisimet voidaan kouluttaa muutamassa minuutissa yhdellä suorittimella; ja 4) ne ovat stabiileja eri hyperparametrien asetuksissa. Pyrimme helpottamaan ja demokratisoimaan aikomusten havaitsemiseen keskittyvää tutkimusta julkaisemme koodimme sekä uuden haastavan yhden toimialueen aikomusten havaitsemiseen liittyvän aineiston, joka sisältää 13 083 huomaututettua esimerkkiä 77 aikomuksesta.', 'jv': 'Ngawe Daerah sistem conversation kanggo saben dumateng anyar karo sistem sing nambah operasi sing butuh model sing di nggawe barang-pakan nggunakake sistem sing wis ana (t.e.g. iso dianggawe operasi layang-pakan). Awak dhéwé wis rampung dibutuhke iki, kita nggawe layang-layang sistem kebuturan cara nggawe dinor duwelan sing dikarolan USE lan conveRT. Awak dhéwé éntukno kabèh lan aplikasi kanggo Ketokanan aturan sing beraksi 2) Digambut sing dibutungano uwong apa-apa ning titik-apa (dadi, saboh barang 10 atawa 30 sing apik dadi bisa balikat). 3) Perintah-perintah sing dibutuhke ditambah podho kelas nang sampeyan ingkang sampeyan; akeh and 4) it is stable against the same parameter settings. Nambah sing beraksi karo perusahaan lan démocrasyone resampungan dipunangguna nggawe barang nggawe winih, kita kebebasan kode dhéwé, lak ngono nggawe waé sing beraksi podho nggawe dataset ingkang 13,583 sing apik dhéwé, wigatining sedhaya sing berarti.', 'sk': 'Za gradnjo pogovornih sistemov na novih področjih in z dodatno funkcionalnostjo so potrebni modeli, ki učinkovito učinkoviti z viri, ki delujejo v režimih z nizko količino podatkov (tj. pri nekaj posnetkih). Na podlagi teh zahtev uvajamo metode zaznavanja namena, ki jih podpirajo predhodno uvedeni kodirniki dvojnih stavkov, kot sta USE in ConveRT. Prikazujemo uporabnost in široko uporabnost predlaganih detektorjev namena, pri čemer pokažemo, da: 1) presegajo detektorje namena, ki temeljijo na natančnem nastavitvi celotnega modela BERT-Large ali uporabi BERT kot fiksnega kodirja črnega polja na treh različnih naborih podatkov o zaznavanju namena; 2) dobički so še posebej izraziti pri nekaj posnetkih (tj. z le 10 ali 30 označenimi primeri na namen); 3) naše detektorje namena lahko usposabljamo v nekaj minutah na enem procesorju; in 4) so stabilni v različnih nastavitvah hiperparametrov. V upanju, da bomo olajšali in demokratizirali raziskave, osredotočene na odkrivanje namenov, objavljamo našo kodo in nov zahteven nabor podatkov o odkrivanju namenov z eno domeno, ki vsebuje 13.083 označenih primerov nad 77 nameni.', 'he': 'בניית מערכות שיחה בתחומים חדשים ובתוספת פונקציונליות דורשות דוגמנים יעילים משאבים שעובדים תחת מערכות נתונים נמוכות (כלומר, במערכות קטנות). מוטיבציה על ידי הדרישות האלה, אנו מכירים שיטות גילוי כוונות תומכות על ידי קודים משפטים כפולים מתאמנים מראש, כמו USE ובConveRT. אנחנו מראים את השימוש והאפשרות הרחבה של גלאי הכוונות המוצעים, מראים כי: 1) הם יוצאים מעל גלאי הכוונות המבוססים על התדרגות המלאה של המודל BERT-גדול או בשימוש BERT כקודד קופסה שחורה קבוע על שלושה קבוצות נתונים של זיהוי הכוונות מגוונים; 2) הרווחים מבטחים במיוחד במערכות קטנות (כלומר, עם רק 10 או 30 דוגמאות מצוינות לכוונה); 3) גלאי הכוונה שלנו יכולים להיות מאומנים בעוד כמה דקות על CPU אחד; ו-4) הם יציבים במערכות היפרפרמטרים שונות. בתקווה להקל ולדמוקרטיזם מחקר ממוקד על זיהוי כוונות, אנחנו משחררים את הקוד שלנו, כמו גם קבוצת נתונים חדשה מאתגרת לזהות כוונות במשטרה אחת שמכילה 13,083 דוגמאות מוצבעות מעל 77 כוונות.', 'ha': "Yi samun shiryoyin ayuka da aka haɗa cikin wurãre-daban, da kuma an ƙara wani aiki, yana ƙayyade misãlai masu da amfani da resource da su yi aiki a ƙarƙashin-data (misali, cikin tsari masu ƙaranci). Aka fara da wannan umarni, Munã ƙara hanyoyin bayani masu iya ƙaranci da aka baka ko-kodi biyu kamar shirin YUK da ConvRT. Tuna nuna amfani da amfani da mai shimfiɗawa wa masu shirya matsayin shiryarwa da aka yi niyyar da shi, suna nuna: 1) suna tafiya zaɓani a kan gyarata masu amfani da matsayin mai cikakken BERT-Babbar ko kuma suna yin amfani da BERT kamar kodi mai daidaita matsayin-boxen mai baƙi a kan daidaita danne-zane-zane taki uku daban-daban; 2) Ana ƙayyade matsayin da aka ƙayyade shi a cikin masu tsari kaɗan (misali, da misãlai 10 ko 30 wanda aka yi zartar da shi a gaba ɗaya). 3) za'a iya kõre masu so cikin guda dakika guda a kan CPU; kuma 4) suna madaidaici a kan kowane zaɓallin giperparameteri dabam. In a tsammãni ga sauƙi da kuma a Democratizi research, yana fassara kowanmu da ke so, da sami wani zane-zane-zane-zane-zane-danne da ke cikin kashi-guda, wanda ke samun misãlai 13,083 da aka sanar da shi a kan kashfa 77.", 'bo': 'དྲ་ཁོངས་གསར་པའི་ནང་དུ་གཏམ་གླེང་སྒྲུབ་གྱི་མ་ལག་གསར་པ་དང་ཁ་སྐོང་རྩིས་མཐུན་བྱས་པའི་རྒྱུ་དངོས་ཡིག་སྟོན་ནུས་ཡོད་པའི་མ་ལག་ལེན་དགོས Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT. ང་ཚོས་འཆར་བཀོད་པའི་དམིགས་བསལ་བྱ་རིམ་གྱི་སྤྱོད་སྤྱོད་དང་ཆེ་བའི་འཇུག་སྤྱོད་མཁན་ལ་མངོན་འཆར་བྱེད་ཀྱི་ཡོད། 2) རྒྱལ་སྤྱིར་བཏང་བ་ཡིན་པའི་སྒྲིག་འཛིན་ཉུང་ཅིག་གི་ནང་དུ་གཏོང་ཡོད། 3) ང་ཚོའི་དམིགས་བསལ་རྟོགས་པ་ཚོ་སྐར་ཆ་གཅིག་པུ་ཞིག་གི་ནང་སློབ་འཛུགས་བྱེད་སྲིད། and 4) they are stable across different hyperparameter settings. In hope of facilitating and democratizing research focused on intention detection, we release our code, as well as a new challenging single-domain intent detection dataset comprising 13,083 annotated examples over 77 intents.'}
{'en': 'Accelerating Natural Language Understanding in Task-Oriented Dialog', 'ar': 'تسريع فهم اللغة الطبيعية في الحوار الموجه نحو المهام', 'pt': 'Acelerando a compreensão da linguagem natural na caixa de diálogo orientada a tarefas', 'es': 'Acelerar la comprensión del lenguaje natural en el diálogo orientado a tareas', 'fr': 'Accélérer la compréhension du langage naturel dans les dialogues orientés tâches', 'hi': 'कार्य-उन्मुख संवाद में प्राकृतिक भाषा की समझ में तेजी लाना', 'ja': 'タスク指向のダイアログで自然言語の理解を加速する', 'zh': '速自然语言解于对面之对话框', 'ru': 'Ускорение понимания естественного языка в диалоге, ориентированном на задачу', 'ga': 'Ag Luathú Tuiscint Teanga Nádúrtha in Dialóg atá Dírithe ar Thasc', 'ka': 'დავალებების ორიენტირებული დიალოგიში ჩვენი თავისუფალური ენის გაგრძელება', 'el': 'Επιτάχυνση της κατανόησης της φυσικής γλώσσας σε διάλογο προσανατολισμένο στην εργασία', 'hu': 'A természetes nyelv megértésének felgyorsítása feladatorientált párbeszédpanelen', 'it': 'Accelerare la comprensione del linguaggio naturale nella finestra di dialogo orientata alle attività', 'kk': 'Тапсырма- бағытталған диалогында табиғи тілді түсініктерді жылдамдылау', 'lt': 'Skatinti gamtos kalbos supratimą į užduotis orientuoto dialogo metu', 'mk': 'Го забрзува разбирањето на природниот јазик во дијалогот насочен кон задачите', 'ms': 'Memecut Pemahaman Bahasa Biasa dalam Dialog Berarah Tugas', 'ml': 'ജോലി- സ്ഥാപിക്കപ്പെട്ട ഡയലോഗില്\u200d സ്വാഭാവികമായ ഭാഷ വിശേഷമാക്കുന്നു', 'mt': 'L-aċċellerazzjoni tal-fehim tal-lingwi naturali fid-Djalogu orjentat lejn ix-Xogħol', 'mn': 'Байгалийн хэл ойлголтын хурдацтай ажлын эхлэл диалогт', 'no': 'Snøggtast for naturleg språk i oppgåveorientert dialogvindauge', 'sr': 'Ubrzavanje razumevanja prirodnog jezika u dijalogu orijentiranog zadatka', 'pl': 'Przyspieszenie zrozumienia języka naturalnego w dialogu zorientowanym na zadania', 'ro': 'Accelerarea înțelegerii limbajului natural în dialogul orientat spre activități', 'so': 'Fasaxidda luqada asalka ah Understanding in dialogue shaqo-oriented', 'si': 'කාර්ය- ප්\u200dරමාණය සංවාදයේ ස්වාභාවික භාෂාව තේරුම්ගන්න', 'sv': 'Påskynda förståelsen av naturligt språk i uppgiftsorienterad dialogruta', 'ta': 'பணியில் தேர்ந்தெடுக்கப்பட்ட உரையாடலில் புரிந்து கொள்ளும் இயல்பான மொழி', 'ur': 'Task-Oriented Dialog میں طبیعی زبان سمجھنے کی تیزی دی جاتی ہے', 'uz': 'Name', 'vi': 'Gia tốc hiểu biết ngôn ngữ tự nhiên trong Hộp thoại chuyên', 'bg': 'Ускоряване на разбирането на естествения език в диалоговия прозорец, ориентиран към задачите', 'hr': 'Ubrzavanje razumijevanja prirodnog jezika u dijalogu orijentiranog na zadatke', 'da': 'Fremskyndelse af forståelse af natursprog i opgaveorienteret dialog', 'nl': 'Versterking van natuurlijke taal in taakgerichte dialoog versnellen', 'de': 'Beschleunigung des Verständnisses natürlicher Sprache im aufgabenorientierten Dialog', 'id': 'Memakselerasi Bahasa Alami Memahami Dalam Dialog Berorientasi Tugas', 'ko': '임무를 향한 대화에서 자연 언어의 이해를 가속화하다', 'fa': 'سرعت درک زبان طبیعی در محاورۀ تاریخی', 'sw': 'Kwa haraka lugha ya asili inayoelewa katika blogu ya kazi-oriented', 'af': 'Versnelling van Natuurlike Taal Verstaan in Opdrag- Orienteerde Dialoog', 'tr': 'Taýýal-Gyzalan Diller Düşünmesini Häzirleýin', 'sq': 'Shpejtimi i kuptimit të gjuhës natyrore në dialogun e orientuar në detyra', 'az': 'T…ôbi…ôtli dil anlama tezl…ôŇüdirilm…ôsi', 'hy': 'Նույնիսկ արագացնել բնական լեզուների հասկացությունը', 'am': 'አድራሻ', 'bn': 'কাজ- অরিন্তিত ডায়ালগে প্রাকৃতিক ভাষা বুঝতে পারে', 'ca': 'Accelerar la comprensió del llenguatge natural en el diàleg orientat a les tasques', 'bs': 'Ubrzavanje razumijevanja prirodnog jezika u dijalogu orijentiranog zadatka', 'fi': 'Luonnollisen kielen ymmärtämisen nopeuttaminen tehtäväkeskeisessä dialogissa', 'cs': 'Zrychlení porozumění přirozenému jazyku v dialogu orientovaném na úkoly', 'et': 'Loomuliku keele mõistmise kiirendamine ülesannetele orienteeritud dialoogis', 'jv': 'Tulungi Perangkat langkung sapa-pernganggo ning task-Oriented Dialog', 'sk': 'Pospeševanje razumevanja naravnega jezika v oknu, usmerjenem v opravila', 'he': 'להאיץ את ההבנה של שפת טבעית בדיולוג ממוקד משימה', 'ha': 'KCharselect unicode block name', 'bo': 'བྱ་འགུལ་ལྡོག་མཐོང་སྒྲོམ་ནང་གི་སྤྱིར་བཏང་ནུས་ཀྱི་སྐད་རིགས་འདྲ་བཤུ་གཏོང་བ'}
{'en': 'Task-oriented dialog models typically leverage complex neural architectures and large-scale, pre-trained Transformers to achieve state-of-the-art performance on popular natural language understanding benchmarks. However, these models frequently have in excess of tens of millions of parameters, making them impossible to deploy on-device where resource-efficiency is a major concern. In this work, we show that a simple convolutional model compressed with structured pruning achieves largely comparable results to BERT on ATIS and Snips, with under 100 K parameters. Moreover, we perform acceleration experiments on CPUs, where we observe our multi-task model predicts intents and slots nearly 63x faster than even DistilBERT.', 'es': 'Los modelos de diálogo orientados a tareas suelen aprovechar arquitecturas neuronales complejas y Transformers preentrenados a gran escala para lograr un rendimiento de vanguardia en los puntos de referencia populares de comprensión del lenguaje natural. Sin embargo, estos modelos con frecuencia tienen más de decenas de millones de parámetros, lo que hace que sea imposible implementarlos en el dispositivo donde la eficiencia de los recursos es una preocupación importante. En este trabajo, mostramos que un modelo convolucional simple comprimido con poda estructurada logra resultados en gran medida comparables a BERT en ATIS y Snips, con parámetros inferiores a 100K. Además, realizamos experimentos de aceleración en CPU, donde observamos que nuestro modelo multitarea predice intenciones y ranuras casi 63 veces más rápido que incluso Distilbert.', 'ar': 'تستفيد نماذج الحوار الموجه نحو المهام عادةً من البنى العصبية المعقدة والمحولات واسعة النطاق المدربة مسبقًا لتحقيق أداء متطور على معايير فهم اللغة الطبيعية الشائعة. ومع ذلك ، غالبًا ما تحتوي هذه النماذج على ما يزيد عن عشرات الملايين من المعلمات ، مما يجعل من المستحيل نشرها على الجهاز حيث تكون كفاءة الموارد مصدر قلق كبير. في هذا العمل ، أظهرنا أن نموذجًا تلافيفيًا بسيطًا مضغوطًا بتقليم منظم يحقق نتائج قابلة للمقارنة إلى حد كبير مع BERT على ATIS و Snips ، مع معلمات أقل من 100 كيلو بايت. علاوة على ذلك ، نجري تجارب تسريع على وحدات المعالجة المركزية (CPU) ، حيث نلاحظ أن نموذجنا متعدد المهام يتنبأ بالنوايا والفتحات أسرع بنحو 63 مرة من DistilBERT.', 'pt': 'Os modelos de diálogo orientados a tarefas normalmente aproveitam arquiteturas neurais complexas e Transformers pré-treinados em larga escala para obter desempenho de última geração em benchmarks populares de compreensão de linguagem natural. No entanto, esses modelos frequentemente têm mais de dezenas de milhões de parâmetros, tornando-os impossíveis de implantar no dispositivo onde a eficiência de recursos é uma grande preocupação. Neste trabalho, mostramos que um modelo convolucional simples compactado com poda estruturada alcança resultados amplamente comparáveis ao BERT em ATIS e Snips, com parâmetros abaixo de 100K. Além disso, realizamos experimentos de aceleração em CPUs, onde observamos que nosso modelo multitarefa prevê intents e slots quase 63x mais rápido que o DistilBERT.', 'fr': "Les modèles de dialogue orientés tâches exploitent généralement des architectures neuronales complexes et des transformateurs préformés à grande échelle pour atteindre des performances de pointe sur les tests de compréhension du langage naturel les plus courants. Cependant, ces modèles ont souvent plus de dizaines de millions de paramètres, ce qui les rend impossibles à déployer sur des appareils où l'efficacité des ressources est une préoccupation majeure. Dans ce travail, nous montrons qu'un modèle convolutif simple compressé avec un élagage structuré permet d'obtenir des résultats largement comparables à ceux du BERT sur ATIS et Snips, avec moins de 100 000 paramètres. De plus, nous effectuons des expériences d'accélération sur les processeurs, où nous observons que notre modèle multitâche prédit les intentions et les créneaux près de 63 fois plus vite que Distilbert.", 'hi': 'कार्य-उन्मुख संवाद मॉडल आमतौर पर लोकप्रिय प्राकृतिक भाषा समझ बेंचमार्क पर अत्याधुनिक प्रदर्शन प्राप्त करने के लिए जटिल तंत्रिका आर्किटेक्चर और बड़े पैमाने पर, पूर्व-प्रशिक्षित ट्रांसफॉर्मर का लाभ उठाते हैं। हालांकि, इन मॉडलों में अक्सर लाखों पैरामीटर से अधिक होते हैं, जिससे उन्हें ऑन-डिवाइस को तैनात करना असंभव हो जाता है जहां संसाधन-दक्षता एक प्रमुख चिंता का विषय है। इस काम में, हम दिखाते हैं कि संरचित छंटाई के साथ संकुचित एक साधारण कनवल्शनल मॉडल 100K मापदंडों के तहत ATIS और Snips पर BERT के लिए काफी हद तक तुलनीय परिणाम प्राप्त करता है। इसके अलावा, हम सीपीयू पर त्वरण प्रयोग करते हैं, जहां हम अपने बहु-कार्य मॉडल का निरीक्षण करते हैं, यहां तक कि डिस्टिलबर्ट की तुलना में लगभग 63x तेजी से इरादे और स्लॉट की भविष्यवाणी करते हैं।', 'ja': 'タスク指向のダイアログモデルは、通常、複雑なニューラルアーキテクチャと大規模で事前にトレーニングされたトランスフォーマーを活用して、人気のある自然言語理解ベンチマークで最先端のパフォーマンスを達成します。しかし、これらのモデルは頻繁に数千万を超えるパラメータを持つため、リソース効率が大きな懸念事項であるデバイス上での展開は不可能です。この研究では、構造化された枝刈りで圧縮された単純な畳み込みモデルは、ATISとSnipsでBERTとほぼ同等の結果を達成し、100 K未満のパラメータを持つことを示しています。さらに、私たちはCPUで加速実験を行い、マルチタスクモデルを観察して、DistilBERTよりもほぼ63倍速くインテントとスロットを予測します。', 'zh': '向之对者,常以杂神经架构、大、豫练之变形金刚,流行之自然语言,略得先进之性。 然常有过数千万个参数,不可以资源效率为设备也。 以此明之,用结构化剪压缩之简卷积形于ATISSnips,略相当BERT,参数下于100K。 CPU行速实验,观我多任务测插槽,倍于DistilBERT快近63。', 'ru': 'Ориентированные на задачи диалоговые модели, как правило, используют сложные нейронные архитектуры и крупномасштабные предварительно обученные трансформаторы для достижения самой современной производительности на популярных эталонах понимания естественного языка. Однако эти модели часто имеют более десятков миллионов параметров, что делает невозможным их развертывание на устройстве, где ресурсоэффективность является серьезной проблемой. В этой работе мы показываем, что простая сверточная модель, сжатая со структурированной обрезкой, достигает в значительной степени сопоставимых результатов с BERT на ATIS и Snips с параметрами ниже 100K. Кроме того, мы проводим эксперименты по ускорению на процессорах, где мы наблюдаем, как наша многозадачная модель предсказывает намерения и слоты почти в 63 раза быстрее, чем даже DistilBERT.', 'ga': 'Is gnách go n-eascraíonn samhlacha dialóige atá dírithe ar thascanna ailtireachtaí néaracha casta agus Claochladáin réamhoilte ar mhórscála chun feidhmíocht úrscothach a bhaint amach ar thagarmharcanna móréilimh tuiscint teanga nádúrtha. Mar sin féin, is minic a bhíonn níos mó ná na mílte paraiméadair ag na samhlacha seo, rud a fhágann nach féidir iad a imscaradh ar an ngléas nuair is mór an imní é an éifeachtúlacht acmhainní. San obair seo, léirímid go n-éiríonn le samhail shimplí réchúiseach atá comhbhrúite le bearradh struchtúrtha torthaí atá inchomparáide den chuid is mó le BERT ar ATIS agus Snips, agus níos lú ná 100K paraiméadair. Ina theannta sin, déanaimid turgnaimh luasghéaraithe ar LAPanna, áit a bhfeicimid ár samhail il-tasc a thuar rún agus sliotáin beagnach 63x níos tapúla ná fiú DistilBERT.', 'el': 'Τα μοντέλα διαλόγου προσανατολισμένα σε εργασίες χρησιμοποιούν συνήθως πολύπλοκες νευρωνικές αρχιτεκτονικές και μεγάλης κλίμακας, προ-εκπαιδευμένους μετασχηματιστές για να επιτύχουν επιδόσεις τελευταίας τεχνολογίας σε δημοφιλή σημεία αναφοράς κατανόησης φυσικής γλώσσας. Ωστόσο, αυτά τα μοντέλα συχνά έχουν πάνω από δεκάδες εκατομμύρια παραμέτρους, καθιστώντας τα αδύνατα να αναπτυχθούν στη συσκευή όπου η αποδοτικότητα των πόρων αποτελεί σημαντικό πρόβλημα. Σε αυτή την εργασία, καταδεικνύουμε ότι ένα απλό μοντέλο συστολής συμπιεσμένο με δομημένο κλάδεμα επιτυγχάνει σε μεγάλο βαθμό συγκρίσιμα αποτελέσματα με το BERT σε ATIS και Snips, με παραμέτρους κάτω από 100Κ. Επιπλέον, διεξάγουμε πειράματα επιτάχυνσης σε επεξεργαστές, όπου παρατηρούμε ότι το μοντέλο πολλαπλών εργασιών προβλέπει προθέσεις και αυλακώσεις σχεδόν 63x γρηγορότερα από ό, τι ακόμη και το DistilBERT.', 'ka': 'პარამეტრების განსაზღვრებული დიალოგის მოდელები ტიპულად კომპლექსი ნეიროლური არქტიქტურები და დიდ განსაზღვრებული ტრანფორმეტრები, რომლებიც პოლიოლური ნაიროლური ენერგიის განსაზღვრების მაგრამ, ეს მოდელები ხშირად აქვს ათი მილიონი პარამეტრების გარეშე, რომელიც ისინი შეუძლებელია გარეშე მოწყობილობა სადაც რესურსის ეფექტიურობა მნიშვნელოვანია. ამ სამუშაოში ჩვენ გამოჩვენებთ, რომ სტრუქტურაციული კონფორციალური მოდელი, რომელიც კონფორციული კონფორციალური მოდელს, უფრო დიდი შემდგომარებელი წარმოდგენა BERT-ზე ATIS და დამატებით, ჩვენ გავაკეთებთ სწრაფილური ექსპერიმენტები CPUs-ზე, სადაც ჩვენი მრავალური მოდელის მონაცემები უნდა დავიწყებთ საზოგადოება და სტაციები დამატებით 63x', 'hu': 'A feladatorientált párbeszédmodellek jellemzően komplex neurális architektúrákat és nagyszabású, előre képzett transzformátorokat használnak fel annak érdekében, hogy a legkorszerűbb teljesítményt érjenek el a népszerű természetes nyelvértési referenciaértékeken. Ezeknek a modelleknek azonban gyakran több tízmillió paramétere van, ami lehetetlenné teszi azokat az eszközökön történő telepítésére, ahol az erőforrás-hatékonyság komoly aggodalomra ad okot. Ebben a munkában megmutatjuk, hogy egy egyszerű, strukturált metszéssel tömörített konvolúciós modell nagyrészt összehasonlítható eredményeket ér el az ATIS és Snips BERT esetében, alig 100K paraméterekkel. Továbbá processzorokon végzünk gyorsítási kísérleteket, ahol megfigyeljük, hogy a többfeladatos modellünk közel 63-szor gyorsabb, mint a DistilBERT.', 'it': "I modelli di dialogo orientati alle attività sfruttano in genere architetture neurali complesse e Transformer pre-addestrati su larga scala per ottenere prestazioni all'avanguardia sui benchmark popolari di comprensione del linguaggio naturale. Tuttavia, questi modelli hanno spesso più di decine di milioni di parametri, rendendo impossibile l'implementazione sul dispositivo dove l'efficienza delle risorse è una preoccupazione importante. In questo lavoro, mostriamo che un semplice modello convoluzionale compresso con potatura strutturata raggiunge risultati ampiamente comparabili a BERT su ATIS e Snips, con parametri inferiori a 100K. Inoltre, eseguiamo esperimenti di accelerazione su CPU, dove osserviamo il nostro modello multi-task predice intenti e slot quasi 63 volte più veloci di DistilBERT.", 'lt': 'Į užduotis orientuoti dialogo modeliai paprastai skatina sudėtingas neurologines architektūras ir didelio masto, iš anksto apmokytus transformatorius, kad būtų pasiekti pažangiausi rezultatai pagal populiarius gamtos kalbų supratimo lyginamuosius rodiklius. Tačiau šie modeliai dažnai turi daugiau kaip dešimtis milijonų parametrų, todėl jų neįmanoma diegti įrenginiuose, kuriuose išteklių naudojimo efektyvumas kelia didelį susirūpinimą. Šiame darbe parodomi, kad paprastas konvoliucinis modelis, suspaustas struktūriniu šluostymu, gauna iš esmės panašius rezultatus kaip BERT ATIS ir Snips, kurių parametrai mažesni kaip 100K. Be to, atliekame paspartinimo eksperimentus su CPU, kur stebime savo daugiafunkcinį model į, numatantį ketinimus ir laiko tarpsnius beveik 63x greičiau nei net DistilBERT.', 'kk': 'Тапсырмалар бағытталған диалог үлгілері әдетте комплекс невралдық архитектураларды және үлкен масштабтағы, алдыңғы оқылған түрлендірушілерді табиғи тілдерді түсініктіру кезінде күй- жайымды орын Бірақ бұл үлгілер көбінде 10 миллион параметрлерден артық болады, оларды ресурс эффективдігінің маңызды маңызды құрылғысын орындауға мүмкін болады. Бұл жұмыс ішінде құрылған құрылғылармен сығылған қарапайым құрылғы үлгісі, ATIS және Snips параметрлерінің 100K астындағы BERT- мен салыстырылатын нәтижелерін көрсетеді. Көп тапсырмалар үлгісіміздің көп тапсырмалар үлгісіміздің мақсаттарымыз мен слоттарымызды DistilBERT дегеннен жақын 63x жылдам тез көрсетеді.', 'mk': 'Моделите на дијалог ориентирани на задачите обично користат комплексни нервни архитектури и големи предобучени трансформирачи за постигнување на најсовремени резултати за популарното разбирање на природниот јазик. Сепак, овие модели често имаат повеќе од десетици милиони параметри, што ги прави невозможни да се распоредуваат на уредот каде ресурсната ефикасност е главна загриженост. Во оваа работа, покажуваме дека едноставен конволуционален модел компресиран со структурирано прскање постигнува во голема мера споредливи резултати со BERT на ATIS и Snips, со помалку од 100K параметри. Moreover, we perform acceleration experiments on CPUs, where we observe our multi-task model predicts intents and slots nearly 63x faster than even DistilBERT.', 'ms': 'Model dialog bertujuan tugas biasanya menggunakan arkitektur saraf kompleks dan Penukar skala besar, dilatih-dilatih untuk mencapai prestasi state-of-the-art pada tanda pandangan pemahaman bahasa alam populer. Namun, model-model ini sering mempunyai lebih daripada puluhan juta parameter, membuat mereka mustahil untuk menggunakan pada peranti di mana efisiensi sumber merupakan masalah utama. Dalam kerja ini, kami menunjukkan bahawa model konvolusi sederhana yang dipampat dengan pemotong struktur mencapai keputusan yang sama dengan BERT pada ATIS dan Snips, dengan bawah parameter 100K. Selain itu, kami melakukan eksperimen pemecut pada CPU, di mana kami mengamati model multi-tugas kami meramalkan niat dan slot hampir 63x lebih cepat daripada DistilBERT.', 'mt': 'Il-mudelli ta’ djalogu orjentati lejn ix-xogħol tipikament jinfurzaw arkitetturi newrali kumplessi u Transformaturi fuq skala kbira u mħarrġa minn qabel biex jiksbu prestazzjoni avvanzata fuq punti ta’ riferiment tal-fehim tal-lingwa naturali popolari. Madankollu, dawn il-mudelli ta’ spiss għandhom aktar minn għexieren ta’ miljuni ta’ parametri, li jagħmluhom impossibbli li jintużaw fuq l-apparat fejn l-effiċjenza tar-riżorsi hija ta’ tħassib kbir. F’dan ix-xogħol, naraw li mudell konvoluzzjonali sempliċi kompressat bi pruning strutturat jikseb riżultati fil-biċċa l-kbira komparabbli mal-BERT fuq ATIS u Snips, b’parametri taħt 100K. Moreover, we perform acceleration experiments on CPUs, where we observe our multi-task model predicts intents and slots nearly 63x faster than even DistilBERT.', 'mn': 'Тапсын ориентиролт диалог загварууд нь ерөнхийдөө комплекс мэдрэлийн архитектурууд, том хэмжээний, урлагийн түвшинд сургалтын түвшигчид хүмүүсийг илүү олон байгалийн хэлний ойлголтын салбаруудыг хүргэх боломжтой. Гэвч эдгээр загварууд ихэвчлэн арван сая параметр илүү их байдаг. Байгаль бүтээмжтэй байдал нь маш их асуудал юм. Энэ ажлын хувьд бид энгийн хэмжээний загвар бүтээгдэхүүнтэй хамтдаа жижиг хэмжээний үр дүнг ATIS болон Snips-тэй харьцуулах боломжтой болж 100K параметртэй бага байдаг. Мөн бид CPUудын хурдацтай туршилтыг хийдэг. Бид олон ажлын загварын загварыг ажиглаж байгаа нь зорилго, слотуудыг DistilBERT-ээс бараг 63x хурдан таамагладаг.', 'ml': 'ജോലി തിരഞ്ഞെടുക്കുന്ന ഡയലോഗിന്റെ മോഡലുകള്\u200d സാധാരണ ലെയരേജ് കൂടുതല്\u200d പ്രധാനപ്പെട്ട നെയുറല്\u200d ആര്\u200dക്കിട്ടുകളും വലിയ സ്ഥാനവും പ്രധാനപ്പെട്ട ട ട്രാന എന്നാലും ഈ മോഡലുകള്\u200d പത്തുലക്ഷത്തിന് മാത്രമേയുള്ള പരാമീറ്ററുകള്\u200dക്ക് കൂടുതല്\u200d ഉള്ളതാണ്, വിഭവപൂര്\u200dണ്ണമായ വിഭവങ്ങള്\u200dക്കുള്ള സാധ്യതയില ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത് ഒരു സാധാരണ മോഡല്\u200d കൂട്ടിയിരിക്കുന്ന ഒരു സാധാരണക്കാരന്\u200d മാതൃകയാണെന്നാണ്, കൂടുതല്\u200d ചിട അതുകൊണ്ടും, നമ്മള്\u200d സിപിയുസില്\u200d വേഗത്തിലേക്ക് പരീക്ഷണങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. അവിടെ നമ്മുടെ പല ജോലികളുടെ മോഡല്\u200d നോക്കുന്നു.', 'no': 'Dialogmodeller med oppgåveorientert oppgåver gjer vanlegvis komplekse neuralarkitektur og stor skala, først trengte transformatorar for å oppnå tilstanden av kunsten på populære naturspråk forståande benchmarker. Desse modelane har ofte over tiere millioner av parametra, slik at dei er ikkje mogleg å utføra på eininga der ressurseffektivitet er ein stor bekymring. I denne arbeida viser vi at ein enkel konvolusjonsmodell komprimert med strukturerte prøving når det gjer stort sammenlignbare resultat med BERT på ATIS og Snips, med under 100K-parametrar. I tillegg utfører vi akselereringseksperimenter på prosessarar, der vi observerer vår multioppgåvemodell foregår vilkåra og plasser nesten 63x raskare enn selv DistilBERT.', 'pl': 'Modele dialogowe zorientowane na zadania zazwyczaj wykorzystują złożone architektury neuronowe i duże, wstępnie przeszkolone transformatory, aby osiągnąć najnowocześniejszą wydajność w popularnych standardach zrozumienia języka naturalnego. Jednak modele te często mają ponad dziesiątki milionów parametrów, co uniemożliwia ich wdrożenie na urządzeniu, gdzie efektywność zasobów jest głównym problemem. W niniejszej pracy pokazujemy, że prosty model konwolucyjny skompresowany strukturalnym przycinaniem osiąga w dużej mierze porównywalne wyniki do BERT na ATIS i Snips, z parametrami poniżej 100K. Ponadto przeprowadzamy eksperymenty akceleracyjne na procesorach, gdzie obserwujemy nasz wielozadaniowy model przewidujący intencje i sloty niemal 63x szybciej niż nawet DistilBERT.', 'sr': 'Modeli dijaloga koji su orijentirani na zadatke obično utiču na kompleksne neuralne arhitekture i veliku skalu, predobučene transformere kako bi postigli stanje umjetnosti na popularnim standardima prirodnog razumevanja jezika. Međutim, ovi modeli često imaju preko desetine miliona parametara, čineći ih nemogućim da se rasporede na uređaju gdje je velika briga za efikasnost resursa. U ovom poslu pokazujemo da jednostavan konvolucioni model komprimiran sa strukturovanim prunjem postiže većinom usporedljiv rezultat sa BERT na ATIS i Snips, sa manjim od 100K parametara. Osim toga, obavljamo eksperimente ubrzanja na procesorima, gde posmatramo naš multi task model predviđaju namjere i mjesta skoro 63x brže nego čak i DistilBERT.', 'ro': 'Modelele de dialog orientate spre sarcini utilizează, de obicei, arhitecturi neuronale complexe și Transformers la scară largă, pre-instruite pentru a obține performanțe de ultimă oră pe criteriile populare de înțelegere a limbajului natural. Cu toate acestea, aceste modele au adesea peste zeci de milioane de parametri, ceea ce le face imposibil de implementat pe dispozitiv unde eficiența resurselor reprezintă o preocupare majoră. În această lucrare, arătăm că un model simplu convoluțional comprimat cu tăiere structurată obține rezultate în mare măsură comparabile cu BERT pe ATIS și Snips, cu parametri sub 100K. Mai mult decât atât, efectuăm experimente de accelerare pe procesoare, unde observăm modelul nostru multi-task prezice intenții și sloturi aproape 63 de ori mai rapide decât chiar DistilBERT.', 'si': 'සාමාන්\u200dයයෙන්ම සංවාදය සංවාදය සංවාදය සහ ලොකු විශාල ස්ථාපනය සඳහා විශාල ස්ථාපනය සඳහා ප්\u200dරධානය කරපු ප්\u200dරධානය කරපු විශ නමුත්, මේ මෝඩේල් සාමාන්\u200dයයෙන් ප්\u200dරමාණයක් මිලියන දහයක් ගොඩක් වැඩියි, ඔවුන්ට ප්\u200dරමාණයක් නිර්මාණය කරන්න බැරි වෙන්න පුළ මේ වැඩේ අපි පෙන්වන්නේ සාමාන්\u200dය සම්පූර්ණ ප්\u200dරමාණයක් සංක්\u200dරියාත්මක වෙනුවෙන් සම්පූර්ණ ප්\u200dරමාණයක් සංක්\u200dරියාත්මක වෙන ඒවගේම, අපි CPUවල ඉක්මනය කරන්න ප්\u200dරයෝජනය කරන්නේ, අපේ ගොඩක් වැඩි වැඩි වැඩි වැඩි වැඩි වැඩි වැඩි වැඩි වැඩි අරමුණු සහ ස්ථානය', 'so': 'Tusaalada diyaarinta shaqo-ku hagistay sida caadiga ah leverage complex dhismaha neurada iyo ballaadhan, baaritaanka horay loo tababaray si ay u gaadhaan bandhigyada farshaxanka oo ku saabsan waxgarashada afka caadiga ah. Si kastaba ha ahaatee tusaalahan inta badan waxay leeyihiin toban kun oo milyan oo parameter, waxayna ka dhigaan suurtagal in ay ku ridaan qalabka, taasoo ay ku jirto khatar weyn oo ay ku saabsan waxyaabaha nololeedka. Shaqadan, waxaynu tusnaynaa in qaab fudud oo hoos u dhigay qoraal ka mid ah, oo aad u eg, waxay ka helaan resultiyada BERT ee ku saabsan ATIS iyo Snips, waxayna ka yar tahay 100K parameters. Sidoo kale waxaynu sameynaa imtixaanka dheeraadka oo ku saabsan CPUs, meesha aynu ilaalinaynaa qaababka shaqada oo badan, waxaynu sheegaynaa in dhowr 63x oo dhaqso ah oo ka sii dhaqso DistilBERT.', 'sv': 'Uppgiftsinriktade dialogmodeller utnyttjar vanligtvis komplexa neurala arkitekturer och storskaliga, förklädda Transformers för att uppnå toppmoderna prestanda på populära riktmärken för förståelse av naturligt språk. Dessa modeller har dock ofta över tiotals miljoner parametrar, vilket gör dem omöjliga att distribuera på enheten där resurseffektivitet är ett stort problem. I detta arbete visar vi att en enkel konvulutionsmodell komprimerad med strukturerad beskärning uppnår i stort sett jämförbara resultat med BERT på ATIS och Snips, med under 100K parametrar. Dessutom utför vi accelerationsexperiment på processorer, där vi observerar vår multi-task modell förutspår intentioner och slots nästan 63x snabbare än ens DistilBERT.', 'ta': 'Task-oriented dialog models typically leverage complex neural architectures and large-scale, pre-trained Transformers to achieve state-of-the-art performance on popular natural language understanding benchmarks.  ஆனால், இந்த மாதிரிகள் பெரும்பாலாக பத்து மில்லியன் அளபுருக்களுக்கு மேல் இருக்கிறது, மூலத்தின் விளைவு முக்கியமான கவலையாக இருக்கிறது. இந்த வேலையில், நாம் காண்பிக்கிறோம் ஒரு சுலபமான சாதாரண மாதிரி அமைப்புடன் சுருக்கப்பட்டுள்ளது, ATIS மற்றும் ஸ்னிப்ஸ் மீது பிரெட் முடிவு மற்றும், நாம் சிபிஎஸ் மீது வேக சோதனைகளை செய்கிறோம், அதில் நாம் எங்கள் பல பணி மாதிரி முறைமை பார்க்கிறோம் எங்கள் செயல் முறைமை மற்றும்', 'ur': 'ٹاکس کی طرف متوجہ ہوئی ڈالیلوگر موڈل معمولاً پیچیدہ نئورل معمار اور بڑی اسکیل، پیش آموزش کی تغییرات کرنے والوں کو پہنچانے کے لئے محبوب طبیعی زبان سمجھنے کے بارے میں فعالیت کا موقع پہنچا سکتا ہے. However, these models often have over 10 million parameters, making them impossible to deploy on-device where resource-efficiency is a major concern. ہم اس کام میں دکھاتے ہیں کہ ایک ساده کنویلوشن موڈل جو ساختہ پرینگ کے ساتھ کمپیٹ کی گئی ہے بہت زیادہ اتصال کا نتیجہ ATIS اور Snips پر BERT کے ساتھ ہوتا ہے، 100K پارامیٹروں کے نیچے۔ اور اس کے علاوہ، ہم CPUs پر تیزی آزمائش کرتے ہیں، جہاں ہم اپنے بہت سے کام کے نمونے کو دیکھتے ہیں، مقصد اور اسلوٹ تقریباً 63x سے زیادہ تیز تر ہے.', 'uz': "Task-oriented dialog models typically leverage complex neural architectures and large-scale, pre-trained Transformers to achieve state-of-the-art performance on popular natural language understanding benchmarks.  Lekin, bu modellar ko'p minglab milliondan ortiq parametrlar bor, ularni Resource- effekti muhim eng muhim eng muhimligi asosida ishlab chiqarishi mumkin. Bu ishda biz bunday ko'rayapmiz, tuzilishi bilan bir oddiy muammolar modeli ATIS va Snips bilan bir qisqa natijalariga bajaradi va 100,000 parametrlardan juda kamaytirish natijalariga bajaradi. Ko'p, biz CPU uchun tezlashtirish imtiyozlarini bajaramiz, bu yerda biz ko'plab vazifa modelimizni ko'rib turamiz, DistilBERT'dan ko'proq 63xdan tez keladi.", 'vi': 'Các mô hình thoại hướng dẫn nhiệm vụ thường sử dụng các kiến trúc thần kinh phức tạp và các biến hình lớn được rèn luyện trước để đạt trình độ công nghệ dựa trên các tiêu chuẩn hiểu ngôn ngữ. Tuy nhiên, những mô hình này thường vượt qua hàng chục triệu thông số, khiến chúng không thể phát triển trên thiết bị nơi mà khả năng tiêu hủy tài nguyên là mối quan tâm lớn. Trong công trình này, chúng tôi cho thấy một mô hình xoắn ốc đơn giản được nén với tỉa cấu trúc đạt kết quả hoàn to àn tương tự với BERT trên ATS và Snips, với các thông số theo 100K. Hơn nữa, chúng tôi thực hiện thí nghiệm gia tốc trên CPU, nơi chúng tôi quan sát mô hình đa nhiệm của chúng ta dự đoán được độ cao và thời gian gần 63x nhanh hơn thậm chí xuất sắc.', 'da': "Opgaveorienterede dialogmodeller udnytter typisk komplekse neurale arkitekturer og omfattende, forududdannede Transformers til at opnå state-of-the-art ydeevne på populære benchmarks for forståelse af naturligt sprog. Disse modeller har dog ofte over titusinder af millioner parametre, hvilket gør dem umulige at implementere på enheden, hvor ressourceeffektivitet er et stort problem. I dette arbejde viser vi, at en simpel konvulutionsmodel komprimeret med struktureret beskæring opnår stort set sammenlignelige resultater med BERT på ATIS og Snips, med under 100K parametre. Desuden udfører vi accelerationseksperimenter på CPU'er, hvor vi observerer vores multi-task model forudsiger intentioner og slots næsten 63x hurtigere end endda DistilBERT.", 'bg': 'Моделите на диалогов диалог, ориентирани към задачите, обикновено използват сложни невронни архитектури и широкомащабни, предварително обучени трансформатори, за да постигнат най-съвременни резултати при популярните показатели за разбиране на естествения език. Въпреки това, тези модели често имат над десетки милиони параметри, което ги прави невъзможни за разполагане на устройство, където ефективността на ресурсите е основен проблем. В тази работа показахме, че един прост конволюционален модел, компресиран със структурирано подрязване, постига до голяма степен сравними резултати с BERT при АТИС и Снипс, с параметри под 100К. Освен това, ние извършваме експерименти с ускорение на процесори, където наблюдаваме нашия многофункционален модел прогнозира намеренията и слотовете почти 63 пъти по-бързо от дори ДистилBERT.', 'nl': "Taakgerichte dialoogmodellen maken meestal gebruik van complexe neurale architecturen en grootschalige, vooraf getrainde Transformers om state-of-the-art prestaties te bereiken op populaire benchmarks voor het begrijpen van natuurlijke taal. Deze modellen hebben echter vaak meer dan tientallen miljoenen parameters, waardoor ze onmogelijk op het apparaat te implementeren zijn waar resource-efficiency een grote zorg is. In dit werk laten we zien dat een eenvoudig convolutioneel model gecomprimeerd met gestructureerd snoeien grotendeels vergelijkbare resultaten oplevert als BERT op ATIS en Snips, met onder 100K parameters. Bovendien voeren we versnellingsexperimenten uit op CPU's, waarbij we observeren dat ons multitask model intenties voorspelt en slots bijna 63x sneller zijn dan zelfs DistilBERT.", 'de': 'Aufgabenorientierte Dialogmodelle nutzen typischerweise komplexe neuronale Architekturen und großformatige, vortrainierte Transformatoren, um eine State-of-the-Art-Leistung bei gängigen Benchmarks für das Verständnis natürlicher Sprache zu erreichen. Diese Modelle verfügen jedoch häufig über mehr als zehn Millionen Parameter, sodass sie nicht auf dem Gerät bereitgestellt werden können, wo Ressourceneffizienz ein wichtiges Anliegen ist. In dieser Arbeit zeigen wir, dass ein einfaches Faltmodell, komprimiert mit strukturiertem Beschneiden, weitgehend vergleichbare Ergebnisse mit BERT auf ATIS und Snips erzielt, mit unter 100K Parametern. Darüber hinaus führen wir Beschleunigungsexperimente an CPUs durch, bei denen wir beobachten, dass unser Multi-Task-Modell Intents und Slots fast 63x schneller vorhersagt als DistilBERT.', 'hr': 'Modeli dijaloga orijentirani na zadatke obično utjecaju na kompleksne neuralne arhitekture i veliku skalu, predobučene transformere kako bi postigli postupak stanja umjetnosti na popularnim kriterijama razumijevanja prirodnog jezika. Međutim, ovi modeli često imaju preko desetine milijuna parametara, čineći ih nemogućim rasporediti na uređaju gdje je velika zabrinutost učinkovitosti resursa. U ovom poslu pokazujemo da jednostavan konvolucioni model komprimiran sa strukturovanim pružanjem postiže u velikoj mjeri usporedbljivi rezultati BERT na ATIS i Snips, s manjim od 100K parametara. Osim toga, obavljamo eksperimente ubrzanja na procesorima, gdje posmatramo naš multizadatačni model predviđa namjere i mjesta skoro 63x brže nego čak i DistilBERT.', 'ko': '임무를 위한 대화 모델은 복잡한 신경 체계 구조와 대규모, 사전 훈련 변환기를 이용하여 유행하는 자연 언어 이해 기준에서 가장 선진적인 성능을 실현한다.그러나 이런 모델의 매개 변수는 항상 수천만 개를 초과하기 때문에 자원 효율이 주요한 문제인 설비에 배치할 수 없다.이 작업에서 우리는 간단한 권적 모형을 보여 주었는데 구조화된 가지치기 압축을 통해 ATIS와 스나이프에서 100K 매개 변수에서 BERT와 비슷한 결과를 얻었다.또한 CPU에서 가속 실험을 수행하여 DistilBERT보다 63배 빠른 멀티태스킹 모델 예측 의도와 시간 간격을 관찰했습니다.', 'fa': 'مدل\u200cهای محاورۀ مکالمه\u200cی تابع معماری\u200cهای عصبی پیچیده و مقیاس بزرگ، تغییردهنده\u200cهای پیش آموزش\u200cشده برای رسیدن اجرای موقعیت هنری بر برنامه\u200cهای تعلیم زبان طبیعی مشهور تحقیق می\u200cکنند. ولی این مدلها اغلب بیشتر از ده میلیون میلیون پارامتر دارند که آنها را غیر ممکن است در حالی که فعالیت منابع یک نگرانی بزرگ است. در این کار، ما نشان می دهیم که یک مدل راحتی که با پارامتر ساخته شده با پارامتر ساخته شده، بسیار قابل مقایسه با BERT در ATIS و Snips، با کمتر از ۱۰۰ کیلومتر می رسد. علاوه بر این، ما آزمایش\u200cهای سرعت در سی\u200cپوس انجام می\u200cدهیم، جایی که مدل چندین کار ما را پیش\u200cبینی می\u200cکند که هدف\u200cها و نقطه\u200cها تقریباً 63x سریع\u200cتر از حتی DistilBERT را پیش\u200cبینی می\u200cکند.', 'sw': 'Mfano wa mazungumzo yenye malengo ya kazi kwa kawaida, majengo magumu ya neura na kwa kiwango kikubwa, Watafsiri wa zamani walio na mafunzo ili kupata utendaji wa hali ya sanaa juu ya misingi maarufu ya kuelewa lugha ya asili. Hata hivyo, mifano hii mara nyingi huwa na zaidi ya mamilioni kumi ya parameter, na kuwafanya wasiweze kutumia vifaa ambapo ufanisi wa rasilimali ni hofu kubwa. Katika kazi hii, tunaonyesha kuwa mwelekeo rahisi wa kimataifa uliohusishwa na madini yanafanikiwa matokeo makubwa yanayofanana na BERT kwenye ATIS na Snips, na chini ya parameter 100,000. Zaidi ya hayo, tunafanya majaribio ya upesi kwenye CPU, ambapo tunaangalia mtindo wetu wa kazi nyingi unatabiri nia na mistari ya karibu 63x haraka kuliko hata DistilBERT.', 'tr': "Görevlerden berilen dialoog modelleri adatça karmaşık näyral arhitektarlaryň we uly ölçekli, öň-bilinmeli terjimelerinde tebigy diller düşünýän benchmarklaryň durumyny ýetmek üçin ýüze çykarýarlar. Ýöne bu nusgalar köplenç 10 milliýon parameterlerden ýokary bar, olaryň janlaşdyrylygyny janlaşdyrmak mümkin däldir. Bu işde, strukturly pruning ile sıkıştırılan basit bir şekilde ATIS we Snips ile BERT'nin 100K parametrelerinin a şağıyla hoylaştırılabilir netijeleri ulaştığını gösteriyoruz. Munuň üçin, CPUlaryň üstünde hızlandyrylşygy barýarys. Birnäçe-täblik nusgalarymyzy we mektuplarymyzy DistilBERT-den has ýakyn 63x ýokary çalt öwrülýär.", 'id': 'Model dialog orientasi tugas biasanya menggunakan arsitektur saraf kompleks dan skala besar, Transformers terlatih untuk mencapai prestasi terbaik pada benchmark pemahaman bahasa alam populer. Namun, model-model ini sering memiliki lebih dari puluhan juta parameter, membuat mereka mustahil untuk menggunakan pada perangkat di mana efisiensi sumber daya adalah masalah utama. Dalam pekerjaan ini, kami menunjukkan bahwa model konvolusi sederhana yang dikompresi dengan pemotong struktur mencapai hasil yang sebagian besar yang dapat dibandingkan dengan BERT pada ATIS dan Snips, dengan bawah 100K parameter. Selain itu, kami melakukan eksperimen akselerasi pada CPU, di mana kami mengamati model multi-tugas kami memprediksi niat dan slot hampir 63x lebih cepat dari bahkan DistilBERT.', 'af': "Opdrag-orienteerde dialoog modele tipies verwyder komplekse neurale arkitektuure en groot-skaal, voorafgevorderde Transformeerders om state-of-the-art-prestasie te bereik op populêre natuurlike taal verstaan benchmarke. Hierdie modele het egter dikwels in oorsaak van tien miljoene van parameters, maak hulle onmoontlik om op-toestel te verwend waar hulpbron-effektiviteit 'n groot bekommering is. In hierdie werk, wys ons dat 'n eenvoudige konvolusiele model met struktureerde pruning in groot vergelykbare resultate bereik word met BERT op ATIS en Snips, met onder 100K parameters. Ook, ons uitvoer versnelling eksperimente op CPUs, waar ons onderhou ons multi-taak-model voorskou doels en slots byna 63x vinniger as selfs DistilBERT.", 'az': "Görev-oriented dialog modelləri genellikle kompleks nöral arhitektarları və böyük ölçüdə, əvvəlcə təhsil edilmiş transformatörlər məşhur təbiətli dil anlama benchmarklərinin vəziyyətini başa düşəcək. Ancaq bu modellər çox çox minlərdən fazla parametr var, bu modelləri çox böyük bir məxluqat olaraq on avadanlığı istifadə etməyə imkansız edir. Bu işdə, bizim göstərirdiyimiz ki, strukturlu pruning ilə sıkıştırılmış basit konvolucional modellərin, ATIS və Snips-də BERT ilə 100 K parametrinin altındakı neçə-neçə müəyyən sonuçlarını başa düşür. Daha sonra, CPUlar barəsində hızlandırma təcrübələrini gerçəkləşdiririk, çoxlu işlər modelini gözləyirik, niyyətlərimizi və yerlərini DistilBERT'dən az 63x daha hızlı təcrübə edir.", 'sq': 'Modelet e dialogut të orientuar ndaj detyrave zakonisht përdorin arkitektura të ndërlikuara neuronale dhe Transformuesit në shkallë të madhe të paratrajnuar për të arritur shfaqjen më të lartë në pikat e kuptimit të gjuhës natyrore popullore. Megjithatë, këto modele shpesh kanë më tepër se dhjetra milionë parametra, duke i bërë të pamundur vendosja në pajisje ku efektshmëria e burimeve është një shqetësim i madh. Në këtë punë, ne tregojmë se një model i thjeshtë konvolutiv i kompresionuar me pruning të strukturuar arrin rezultate të krahasueshme me BERT në ATIS dhe Snips, me nën 100K parametra. Përveç kësaj, ne bëjmë eksperimente përshpejtimi në CPU, ku vëzhgojmë modelin tonë shumëdetyror parashikon qëllimet dhe slots gati 63x më shpejt se edhe DistilBERT.', 'bn': 'কাজের প্রাকৃতিক ভাষা বুঝতে পারে প্রাকৃতিক ভাষার ব্যাঙ্কের ব্যাপারে প্রশিক্ষিত ট্রান্সফার্সারের পূর্ব পর্যন্ত প্রশিক্ষিত ট্রান্সফার্স তবে এই মডেলগুলো প্রায়শই দশ লক্ষ লক্ষ পরামিতির বেশী বেশি প্রায়শই রয়েছে, যেখানে সম্পদ-কার্যকর বিষয়টি একটি গুরুত্বপূর্ণ উদ্বেগ। এই কাজের মধ্যে আমরা দেখাচ্ছি যে একটি সাধারণ বিশ্বাসী মডেল যা কাঠামোর মাধ্যমে ধারণ করা হয়েছে বিবেরেটের সাথে তুলনামূলক ফলাফল অর্জন করেছে, যার মধ্যে ১০ এছাড়াও, আমরা সিপিউসের উপর তাড়াতাড়ি পরীক্ষা করি, যেখানে আমরা আমাদের বহুক্ষেত্র মডেল দেখতে পাচ্ছি আমাদের উদ্দেশ্য এবং স্লোট প্রায় ৬৩x দ', 'am': 'አድራሻ ምንም እንኳን እነዚህ ምሳሌዎች በሺሕ ሚሊዮን ሚሊዮን parameters የሚጨምሩ ናቸው፤ ምህርት-ፍቃድዋ ዋነኛ ጉዳይ ሆኖ በመጠቀም አይችሉም፡፡ በዚህ ስራ፣ አካባቢ አካባቢ እና ታናሽ በ100K parameter ላይ BERT በሚያሳየው ቀላል ጉዳይ ሞዴል እናሳየዋለን፡፡ ደግሞም በCPU ላይ የፍጥረት ፈተና እናደርጋለን፤ የብዙዎችን ሥርዓት ሞዴል ከዲስቲብሬት ይልቅ 63x ፈጥኖ የሚቆጠርን እናደርጋለን፡፡', 'hy': 'Գործի վրա ուղղություն ունեցող երկխոսային մոդելները սովորաբար օգտագործում են բարդ նյարդային ճարտարապետություններ և մեծ մասշտաբ, նախապատրաստված տրանֆորմերներ, որպեսզի հասնեն լավագույն արդյունքները բնական լեզուների հասկանալու հարաբերականների Այնուամենայնիվ, այս մոդելները հաճախ ունեն ավելի քան տասնյակ միլիոնավոր պարամետրեր, որոնք անհնար են դարձնում օգտագործել սարքի մեջ, որտեղ ռեսուրսների արդյունավետությունը մեծ խնդիր է: Այս աշխատանքի ընթացքում մենք ցույց ենք տալիս, որ կառուցվածքային կտրականությամբ ընկճված մի պարզ հակադրական մոդել ունի հիմնականում համեմատուկ արդյունքներ ATIS-ի և Սնիպսի BER-ի հետ, որի արտահայտությունը 100,000 պարամետրով է պակաս Ավելին, մենք կատարում ենք արագացման փորձարկումներ CPU-ների վրա, որտեղ մենք հետևում ենք մեր բազմախնդիրների մոդելը կանխատեսում է նպատակներ և վայրընթացներ մոտ 63x ավելի արագ, քան նույնիսկ Դիստիլբերթը:', 'ca': "Els models de diàleg orientats a les tasques normalment aprofiten arquitectures neurals complexes i transformadors a gran escala, pré-entrenats, per aconseguir un rendiment d'última generació en punts de referència populars d'enteniment del llenguatge natural. No obstant això, aquests models sovint tenen més de desenes de milions de paràmetres, fent impossible desplegar-los a l'aparell on l'eficiència dels recursos és una gran preocupació. En aquest treball, demostram que un simple model convolucional comprimat amb pruning estructurat aconsegueix resultats en gran part comparables a BERT en ATIS i Snips, amb menys de 100K paràmetres. A més, fem experiments d'acceleració en CPU, on observem el nostre model multitasca prediu intencions i slots gairebé 63x més ràpid que fins i tot DistilBERT.", 'bs': 'Modeli dijaloga orijentirani na zadatke obično utiču na kompleksne neuralne arhitekture i veliku skalu, predobučene transformere kako bi postigli postupak stanja umjetnosti o popularnim kriterijama prirodnog razumijevanja jezika. Međutim, ovi modeli često imaju preko desetine miliona parametara, čineći ih nemogućim da se rasporede na uređaju gdje je velika briga za učinkovitost resursa. U ovom poslu pokazujemo da jednostavan konvolucioni model komprimiran sa strukturovanim pružanjem postiže uglavnom usporedbljivi rezultati BERT na ATIS i Snips, s manjim od 100K parametara. Osim toga, obavljamo eksperimente ubrzanja na CPU, gdje posmatramo naš multi task model predviđa namjere i mjesta skoro 63x brže nego čak i DistilBERT.', 'et': "Ülesannetele orienteeritud dialoogimudelid kasutavad tavaliselt keerukaid neuraalarhitektuure ja suuremahulisi eelkoolitud transformaatoreid, et saavutada tipptasemel jõudlus populaarsete looduskeelte mõistmise võrdlusnäitajate puhul. Nendel mudelitel on sageli üle kümnete miljonite parameetrite, mistõttu on neid võimatu kasutada seadmes, kus ressursitõhusus on suur probleem. Käesolevas töös näitame, et lihtne konvolutsiooniline mudel, mis on kokku surutud struktureeritud pügamisega, saavutab suures osas võrreldavad tulemused BERT-ga ATIS ja Snips'i puhul, mille parameetrid on alla 100K. Lisaks teostame protsessoritega kiirenduskatseid, kus jälgime, et meie mitme ülesandega mudel ennustab kavatsusi ja pesasid peaaegu 63 korda kiiremini kui isegi DistilBERT.", 'fi': 'Tehtävälähtöiset dialogimallit hyödyntävät tyypillisesti monimutkaisia neuroarkkitehtuuria ja laajamittaisia esikoulutettuja muuntajia saavuttaakseen huipputason suorituskyvyn suosituissa luonnonkielen ymmärtämisen vertailuarvoissa. Näillä malleilla on kuitenkin usein yli kymmeniä miljoonia parametreja, minkä vuoksi niitä on mahdotonta ottaa käyttöön laitteissa, joissa resurssitehokkuus on suuri huolenaihe. Tässä työssä osoitetaan, että yksinkertainen konvolutionaalinen malli, joka on puristettu strukturoidulla karsinnalla, saavuttaa pitkälti vertailukelpoisia tuloksia kuin BERT ATIS- ja Snips-malleissa, joiden parametrit ovat alle 100K. Lisäksi suoritamme kiihtyvyyskokeita suorittimilla, joissa havainnoimme monitehtävämallimme ennustaa aikomukset ja lähtöpaikat lähes 63 kertaa nopeammin kuin DistilBERT.', 'cs': 'Dialogové modely orientované na úlohy obvykle využívají složité neuronové architektury a rozsáhlé, předškolené transformátory k dosažení nejmodernějšího výkonu v oblíbených referenčních hodnotách porozumění přirozenému jazyku. Tyto modely však často mají překračující desítky milionů parametrů, což znemožňuje nasazení na zařízení tam, kde je účinnost zdrojů hlavním problémem. V této práci ukazujeme, že jednoduchý konvoluční model komprimovaný strukturovaným řezáním dosahuje do značné míry srovnatelných výsledků s BERT na ATIS a Snips, s parametry pod 100K. Kromě toho provádíme akcelerační experimenty na procesorech, kde sledujeme, že náš multiúlohový model předpovídá záměry a sloty téměř 63x rychleji než dokonce DistilBERT.', 'sk': 'Modeli dialogov, usmerjeni v opravila, običajno uporabljajo kompleksne nevralne arhitekture in obsežne, predhodno usposobljene transformatorje, da dosežejo najsodobnejše zmogljivosti pri popularnih merilih razumevanja naravnega jezika. Vendar pa imajo ti modeli pogosto več kot deset milijonov parametrov, zaradi česar jih ni mogoče uvesti na napravi, kjer je učinkovita raba virov glavna skrb. V tem delu smo pokazali, da preprost konvolucijski model, stisnjen s strukturiranim obrezovanjem, doseže večinoma primerljive rezultate kot BERT na ATIS in Snips s parametri pod 100K. Poleg tega izvajamo pospeševalne poskuse na CPU-jih, kjer opazujemo, da naš večopravilni model napoveduje namene in reže skoraj 63-krat hitreje kot celo DistilBERT.', 'ha': "@ action: button A lokacin da haka, waɗannan misãlai ko da yawa suna cikin millionyan parameteri kumar, kuma yana kasancẽwa a kan su saka kan shirin da ke da muhimmin muhimmin sha'awa. Daga wannan aikin, Muke nuna cewa, wata misãlin da aka samu da zane-zane da zane-zane-zane, za'a sami matsalar da matsalar BERT a kan ATIS da Nafãfyuta, da bakin parameteri 100000. Kayya, Munã cika jarrabo masu haraka a kan CPU, a inda Muke dũbi misalinmu masu aikin da yawa, yana gabatar da kashi taki 63x kashi ko kuma don DistilBERT.", 'jv': 'task-Orientation dialog modeles politenessoffpolite, "), and when there is a change ("assertive Workspace 1 Laptop" and "Desktop', 'he': 'דוגמנים דיאלוגים ממוקדים למשימות בדרך כלל משתמשים בארכיטקטורות עצביות מורכבות ומעברים גדולים ומאמנים מראש כדי להשיג ביצועים מוקדמים על נקודות הבנה של שפת טבעית פופולריות. עם זאת, לדוגמנים אלה לעתים קרובות יש מעל עשרות מיליוני פרמטרים, מה שמאפשר להפעיל אותם במתקן שבו יעילות המשאבים היא דאגה גדולה. בעבודה הזו, אנו מראים שמודל משתנה פשוט ללחוץ עם שיקוי מבנה משיג תוצאות שוויות לרוב לברט על ATIS וסניפס, עם פחות מ-100 אלף פרמטרים. חוץ מזה, אנו מבצעים ניסויים מאיץ על CPUs, שבו אנו צופים בדוגמא המולט-משימות שלנו חושפים כוונות ומקומות כמעט 63x מהר יותר מאפילו DistilBERT.', 'bo': 'Task-oriented dialog models typically leverage complex neural architectures and large-scale, pre-trained Transformers to achieve state-of-the-art performance on popular natural language understanding benchmarks. However, these models frequently have in excess of tens of millions of parameters, making them impossible to deploy on-device where resource-efficiency is a major concern. In this work, we show that a simple convolutional model compressed with structured pruning achieves largely comparable results to BERT on ATIS and Snips, with under 100K parameters. འོན་ཀྱང་། ང་ཚོས་CPUs ཐོག་ཏུ་མགྱོགས་འགྱུར་བའི་བརྟག་ཞིག་ལས་མཐོང་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Automating Template Creation for Ranking-Based Dialogue Models', 'ar': 'أتمتة إنشاء النماذج لنماذج الحوار القائمة على الترتيب', 'fr': 'Automatisation de la création de modèles pour les modèles de dialogue basés sur le classement', 'es': 'Automatización de la creación de plantillas para modelos de diálogo basados en la clasificación', 'pt': 'Automatizando a criação de modelos para modelos de diálogo com base em classificação', 'ja': 'ランキングベースのダイアログモデルのテンプレート作成の自動化', 'hi': 'रैंकिंग-आधारित संवाद मॉडल के लिए टेम्पलेट निर्माण को स्वचालित करना', 'zh': '自创于排名之模板', 'ru': 'Автоматизация создания шаблонов для моделей диалогов на основе ранжирования', 'ga': 'Cruthú Teimpléad a Uathoibriú le haghaidh Múnlaí Idirphlé Rangbhunaithe', 'ka': 'შაბლონის შექმნა დიალოგის მოდელებისთვის ავტომატურად', 'el': 'Αυτοματοποίηση δημιουργίας προτύπων για μοντέλα διαλόγου βάσει κατάταξης', 'hu': 'Sablonlétrehozás automatizálása rangsorolási párbeszédmodellekhez', 'it': 'Creazione automatica di modelli per modelli di dialogo basati su classificazione', 'kk': 'Диалог үлгілерінің үлгісін автоматты түрде құру', 'lt': 'Automatizuojamas šablonų kūrimas pagal intervalus grindžiamiems dialogo modeliams', 'mk': 'Автоматизирање на креирање на шаблони за модели на дијалог базирани на рангирање', 'ms': 'Automatikan Cipta Templat untuk Model Dialog Berasas-Rangkaian', 'ml': 'റാങ്ങിംഗ് അടിസ്ഥാനമായ ഡയലോഗ് മോഡലുകള്\u200dക്കുള്ള മാമ്പേള്\u200d സ്വയം സൃഷ്ടിക്കുന്നു', 'mn': 'Дөрвөлжингийн үндсэн диалог загварын шалгалтыг автоматжуулах', 'mt': 'L-awtomatizzazzjoni tal-ħolqien ta’ mudelli għal mudelli ta’ djalogu bbażati fuq il-klassifikazzjoni', 'pl': 'Automatyzacja tworzenia szablonów dla modeli dialogowych opartych na rankingu', 'no': 'Automatisk oppretting av malen for dialogmodeller', 'ro': 'Automatizarea creării șabloanelor pentru modelele de dialog bazate pe clasament', 'sr': 'Automatisanje stvaranja šablona za modele dijaloga na osnovu rasporeda', 'si': 'රේන්ග් අධාරිත සංවාදය නිර්මාණය සඳහා ස්වයංක්\u200dරියාත්මක නිර්මාණය කරන්න', 'sv': 'Automatisera skapandet av mallar för rankningsbaserade dialogmodeller', 'so': 'Automatic-abuuridda macluumaadka', 'ta': 'வரிசைப்படுத்தப்பட்ட உரையாடல் மாதிரிகளுக்கான வார்ப்புருவை தானாகவே உருவாக்குகிறது', 'ur': 'Ranking-Based Dialog Models کے لئے ٹیپلٹ پیدا کرنے کا اتوماٹ کیا جاتا ہے', 'uz': 'Dialog modellari uchun namunani avtomatik yaratish', 'vi': 'Tự động tạo mẫu biểu mẫu cho mô hình duyệt', 'bg': 'Автоматизиране на създаването на шаблон за модели на диалогови диалози въз основа на класиране', 'hr': 'Automatiziranje kreiranja šablona za modele dijaloga na osnovu rasporeda', 'da': 'Automatisering skabelon oprettelse af placeringsbaserede dialogmodeller', 'nl': 'Het maken van sjablonen automatiseren voor op rangschikking gebaseerde dialoogmodellen', 'de': 'Automatisierung der Templateerstellung für rankingbasierte Dialogmodelle', 'ko': '랭킹 기반 대화 모델을 위한 템플릿 자동 생성', 'id': 'Memotomatis Penciptaan Templat untuk Model Dialog Berdasarkan Ranking', 'fa': 'ساختن نمونه برای نمونه\u200cهای محاورۀ پایه\u200cبندی', 'sw': 'Ujengenezaji wa Template kwa ajili ya Modeli za Dialog', 'af': 'Name', 'tr': 'Ýardam kadalýa nusgala üçin modler bejerilýär', 'sq': 'Automatizimi i krijimit të modelit për modelet e dialogut të bazuar në renditje', 'az': '䓉饲柉餠쎜獴쎼湤즙歩⁄楡汯潧⁍潤敬泉饲椠쎼쎧쎼渠얞慢汯渠奡牡瓄녬浡珄넊', 'am': 'templates-action', 'hy': 'Հաշվի առնելով դասակարգում հիմնված հաղորդագրությունների մոդելների ավտոմատիկ կառուցվածքը', 'bn': 'স্বয়ংক্রিয়ভিত্তিক ডায়ালগ মোডেলের জন্য প্রেম তৈরি করা হচ্ছে', 'ca': 'Automatitzar la creació de models de diàleg basat en rangs', 'bs': 'Automatiziranje kreiranja šablona za modele dijaloga na osnovu snimanja', 'cs': 'Automatizace tvorby šablon pro modely dialogů založené na hodnocení', 'et': 'Mallide loomise automatiseerimine järjestuspõhiste dialoogimudelite jaoks', 'fi': 'Mallien luomisen automatisointi sijoituspohjaisille dialogimalleille', 'jv': 'Automating template Creation for ranking-bazed Dialog model', 'sk': 'Samodejno ustvarjanje predlog za modele pogovornih pogovorov na podlagi razvrščanja', 'he': 'Automating Template Creation for Ranking-Based Dialogue Models', 'bo': 'Ranking-Based ཌའི་ལོག་གླེང་སྒྲོམ་དབྱིབས་རང་འགུལ་གྱིས་དཔེ་དབྱིབས་བཟོ་བྱེད་བཞིན་པ', 'ha': '@ action'}
{'en': 'Dialogue response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages. However, manually creating templates is time-consuming and requires domain expertise. To alleviate this problem, we explore automating the process of creating dialogue templates by using unsupervised methods to cluster historical utterances and selecting representative utterances from each cluster. Specifically, we propose an end-to-end model called Deep Sentence Encoder Clustering (DSEC) that uses an auto-encoder structure to jointly learn the utterance representation and construct template clusters. We compare this method to a random baseline that randomly assigns templates to clusters as well as a strong baseline that performs the sentence encoding and the utterance clustering sequentially. To evaluate the performance of the proposed method, we perform an automatic evaluation with two annotated customer service datasets to assess clustering effectiveness, and a human-in-the-loop experiment using a live customer service application to measure the acceptance rate of the generated templates. DSEC performs best in the automatic evaluation, beats both the sequential and random baselines on most metrics in the human-in-the-loop experiment, and shows promising results when compared to gold / manually created templates.', 'ar': 'نماذج إنشاء استجابة الحوار التي تستخدم تصنيف القالب بدلاً من إنشاء التسلسل المباشر تسمح لمطوري النماذج بالحد من الاستجابات التي تم إنشاؤها للرسائل المعتمدة مسبقًا. ومع ذلك ، فإن إنشاء النماذج يدويًا يستغرق وقتًا طويلاً ويتطلب خبرة في المجال. للتخفيف من هذه المشكلة ، نستكشف أتمتة عملية إنشاء قوالب الحوار باستخدام طرق غير خاضعة للإشراف لتجميع الأقوال التاريخية واختيار أقوال تمثيلية من كل مجموعة. على وجه التحديد ، نقترح نموذجًا شاملاً يسمى مجموعة تشفير الجمل العميقة (DSEC) الذي يستخدم بنية تشفير تلقائي للتعرف بشكل مشترك على تمثيل الكلام وبناء مجموعات القوالب. قارنا هذه الطريقة بخط أساس عشوائي يعين قوالب بشكل عشوائي للمجموعات بالإضافة إلى خط أساس قوي ينفذ ترميز الجملة وتجميع الكلام بالتتابع. لتقييم أداء الطريقة المقترحة ، نجري تقييمًا تلقائيًا بمجموعتي بيانات مشروحتين لخدمة العملاء لتقييم فعالية التجميع ، وتجربة بشرية في الحلقة باستخدام تطبيق خدمة عملاء مباشر لقياس معدل قبول القوالب التي تم إنشاؤها . يؤدي DSEC أفضل أداء في التقييم التلقائي ، ويتفوق على كل من خطوط الأساس التسلسلية والعشوائية في معظم المقاييس في تجربة الإنسان في الحلقة ، ويظهر نتائج واعدة عند مقارنتها بالقوالب الذهبية / التي تم إنشاؤها يدويًا.', 'es': 'Los modelos de generación de respuestas de diálogo que utilizan la clasificación de plantillas en lugar de la generación de secuencias directas permiten a los desarrolladores de modelos limitar las respuestas generadas a los mensajes aprobados Sin embargo, la creación manual de plantillas lleva mucho tiempo y requiere experiencia en el dominio. Para aliviar este problema, exploramos la automatización del proceso de creación de plantillas de diálogo mediante el uso de métodos no supervisados para agrupar las declaraciones históricas y seleccionar las declaraciones representativas de cada grupo. Específicamente, proponemos un modelo integral llamado Deep Sentence Encoder Clustering (DSEC) que utiliza una estructura de autocodificador para aprender conjuntamente la representación de enunciados y construir clústeres de plantillas. Comparamos este método con una línea base aleatoria que asigna plantillas de forma aleatoria a los grupos, así como con una línea base sólida que realiza la codificación de oraciones y el agrupamiento de enunciados secuencialmente. Para evaluar el rendimiento del método propuesto, realizamos una evaluación automática con dos conjuntos de datos de servicio al cliente anotados para evaluar la eficacia de la agrupación en clústeres, y un experimento humano en el bucle utilizando una aplicación de servicio al cliente en vivo para medir la tasa de aceptación de las plantillas generadas. La DSEC se desempeña mejor en la evaluación automática, supera las líneas de base secuenciales y aleatorias en la mayoría de las métricas del experimento human-in-the-loop y muestra resultados prometedores en comparación con las plantillas creadas manualmente o de oro.', 'fr': "Les modèles de génération de réponses au dialogue qui utilisent le classement des modèles plutôt que la génération de séquences directes permettent aux développeurs de modèles de limiter les réponses générées aux messages pré-approuvés. Cependant, la création manuelle de modèles prend beaucoup de temps et nécessite une expertise dans le domaine. Pour pallier ce problème, nous explorons l'automatisation du processus de création de modèles de dialogue en utilisant des méthodes non supervisées pour regrouper les énoncés historiques et en sélectionnant des énoncés représentatifs dans chaque groupe. Plus précisément, nous proposons un modèle de bout en bout appelé Deep Sentence Encoder Clustering (DSEC) qui utilise une structure d'encodeur automatique pour apprendre conjointement la représentation de l'énoncé et construire des clusters de modèles. Nous comparons cette méthode à une base aléatoire qui attribue aléatoirement des modèles aux clusters ainsi qu'à une base forte qui effectue le codage des phrases et le regroupement des énoncés de manière séquentielle. Pour évaluer les performances de la méthode proposée, nous effectuons une évaluation automatique à l'aide de deux ensembles de données de service client annotés afin d'évaluer l'efficacité du clustering, et une expérience humaine dans la boucle à l'aide d'une application de service client en direct pour mesurer le taux d'acceptation des modèles générés. DSEC est le plus performant dans l'évaluation automatique, surpasse les lignes de base séquentielles et aléatoires pour la plupart des métriques dans l'expérience de l'humain dans la boucle et affiche des résultats prometteurs par rapport aux modèles or/créés manuellement.", 'pt': 'Os modelos de geração de resposta de diálogo que usam classificação de modelo em vez de geração de sequência direta permitem que os desenvolvedores de modelo limitem as respostas geradas a mensagens pré-aprovadas. No entanto, criar modelos manualmente é demorado e requer experiência no domínio. Para aliviar esse problema, exploramos a automatização do processo de criação de modelos de diálogo usando métodos não supervisionados para agrupar enunciados históricos e selecionar enunciados representativos de cada agrupamento. Especificamente, propomos um modelo de ponta a ponta chamado Deep Sentence Encoder Clustering (DSEC) que usa uma estrutura de auto-codificador para aprender conjuntamente a representação do enunciado e construir clusters de modelo. Comparamos esse método com uma linha de base aleatória que atribui aleatoriamente modelos a clusters, bem como uma linha de base forte que realiza a codificação de sentenças e o agrupamento de enunciados sequencialmente. Para avaliar o desempenho do método proposto, realizamos uma avaliação automática com dois conjuntos de dados de atendimento ao cliente anotados para avaliar a eficácia do agrupamento e um experimento humano no circuito usando um aplicativo de atendimento ao cliente ao vivo para medir a taxa de aceitação dos modelos gerados . O DSEC tem o melhor desempenho na avaliação automática, supera as linhas de base sequenciais e aleatórias na maioria das métricas no experimento human-in-the-loop e mostra resultados promissores quando comparado aos modelos ouro/criados manualmente.', 'ja': '直接シーケンス生成ではなくテンプレートランキングを使用するダイアログ応答生成モデルは、モデル開発者が生成された応答を事前承認されたメッセージに制限することを可能にする。 ただし、手動でテンプレートを作成するには時間がかかり、ドメインの専門知識が必要です。 この問題を緩和するために、監督されていない方法を使用して過去の発話をクラスター化し、各クラスターから代表的な発話を選択することにより、対話テンプレートを作成するプロセスを自動化することを模索します。 具体的には、オートエンコーダ構造を使用して発話表現を共同で学習し、テンプレートクラスタを構築するDSEC （ Deep Sentence Encoder Clustering ）と呼ばれるエンドツーエンドのモデルを提案します。 この方法は、テンプレートをランダムにクラスタに割り当てるランダムなベースラインと、文章のエンコードと発話のクラスタリングを順次実行する強いベースラインとを比較します。 提案された方法のパフォーマンスを評価するために、クラスタリングの有効性を評価するための2つの注釈付きカスタマーサービスデータセットを使用した自動評価と、生成されたテンプレートの受け入れ率を測定するためのライブカスタマーサービスアプリケーションを使用したヒューマンインザループの実験を行います。 DSECは、自動評価で最も優れたパフォーマンスを発揮し、ヒューマン・イン・ザ・ループ実験のほとんどの指標で順次ベースラインとランダムベースラインの両方に勝ち、ゴールド/手動で作成されたテンプレートと比較した場合に有望な結果を示します。', 'ru': 'Диалоговые модели генерации ответов, которые используют ранжирование шаблонов, а не генерацию прямой последовательности, позволяют разработчикам моделей ограничивать сгенерированные ответы предварительно утвержденными сообщениями. Тем не менее, создание шаблонов вручную занимает много времени и требует экспертизы домена. Чтобы облегчить эту проблему, мы исследуем автоматизацию процесса создания шаблонов диалога путем использования неконтролируемых методов для кластеризации исторических высказываний и отбора репрезентативных высказываний из каждого кластера. В частности, мы предлагаем сквозную модель под названием Deep Sentence Encoder Clustering (DSEC), которая использует структуру автокодера для совместного изучения представления высказываний и построения кластеров шаблонов. Мы сравниваем этот метод со случайной базой, которая случайным образом назначает шаблоны кластерам, а также с сильной базой, которая последовательно выполняет кодирование предложений и кластеризацию высказываний. Чтобы оценить эффективность предлагаемого метода, мы выполняем автоматическую оценку с двумя аннотированными наборами данных службы поддержки клиентов для оценки эффективности кластеризации и эксперимент «человек в петле» с использованием живого приложения службы поддержки клиентов для измерения скорости принятия сгенерированных шаблонов. DSEC наилучшим образом выполняет автоматическую оценку, превосходит как последовательные, так и случайные базовые линии по большинству показателей в эксперименте «человек в петле» и показывает многообещающие результаты по сравнению с золотом/вручную созданными шаблонами.', 'zh': '用模板排名,非直序生成之对也开发人员限以生成之应为豫可也。 然手动创模板甚耗时,且须领域专业知识。 以缓之,求无监之法聚类择有代表性之言以自模板也。 深句编码器聚类 (DSEC) 端,自编码器共学语而造模板聚类。 以此法与随机分模板与聚类之随机基线及以次行句编码与语聚类之强基线较之。 以两带注客户服务数集自料,以质聚类之有效性,并用实时客户服务应用程序人机环实验,以测生成之模板受率。 DSEC于自料最佳,于人机循环实验中者多指标皆逾次序随机基线,且比黄金/手动创造之模板,以见有望。', 'hi': 'संवाद प्रतिक्रिया जनरेशन मॉडल जो प्रत्यक्ष अनुक्रम पीढ़ी के बजाय टेम्पलेट रैंकिंग का उपयोग करते हैं, मॉडल डेवलपर्स को पूर्व-अनुमोदित संदेशों के लिए उत्पन्न प्रतिक्रियाओं को सीमित करने की अनुमति देते हैं। हालांकि, मैन्युअल रूप से टेम्पलेट्स बनाना समय लेने वाला है और इसके लिए डोमेन विशेषज्ञता की आवश्यकता होती है। इस समस्या को कम करने के लिए, हम ऐतिहासिक कथनों को क्लस्टर करने और प्रत्येक क्लस्टर से प्रतिनिधि कथनों का चयन करने के लिए असुरक्षित तरीकों का उपयोग करके संवाद टेम्पलेट्स बनाने की प्रक्रिया को स्वचालित करने का पता लगाते हैं। विशेष रूप से, हम डीप वाक्य एनकोडर क्लस्टरिंग (DSEC) नामक एक एंड-टू-एंड मॉडल का प्रस्ताव करते हैं जो संयुक्त रूप से उच्चारण प्रतिनिधित्व सीखने और टेम्पलेट क्लस्टर का निर्माण करने के लिए एक ऑटो-एनकोडर संरचना का उपयोग करता है। हम इस विधि की तुलना एक यादृच्छिक आधार रेखा से करते हैं जो यादृच्छिक रूप से टेम्पलेट्स को क्लस्टर के साथ-साथ एक मजबूत आधार रेखा को असाइन करता है जो वाक्य एन्कोडिंग और उच्चारण क्लस्टरिंग को क्रमिक रूप से निष्पादित करता है। प्रस्तावित विधि के प्रदर्शन का मूल्यांकन करने के लिए, हम क्लस्टरिंग प्रभावशीलता का आकलन करने के लिए दो एनोटेट किए गए ग्राहक सेवा डेटासेट के साथ एक स्वचालित मूल्यांकन करते हैं, और जेनरेट किए गए टेम्पलेट्स की स्वीकृति दर को मापने के लिए लाइव ग्राहक सेवा एप्लिकेशन का उपयोग करके एक मानव-इन-द-लूप प्रयोग करते हैं। DSEC स्वचालित मूल्यांकन में सबसे अच्छा प्रदर्शन करता है, मानव-इन-द-लूप प्रयोग में अधिकांश मीट्रिक पर अनुक्रमिक और यादृच्छिक आधार रेखादोनों को धड़कता है, और सोने / मैन्युअल रूप से बनाए गए टेम्पलेट्स की तुलना में आशाजनक परिणाम दिखाता है।', 'ga': 'Ligeann samhlacha giniúna freagartha idirphlé a úsáideann rangú teimpléad seachas giniúint seicheamh díreach d’fhorbróirí samhlacha teorainn a chur le freagraí ginte ar theachtaireachtaí réamhcheadaithe. Mar sin féin, tógann sé go leor ama teimpléid a chruthú de láimh agus teastaíonn saineolas fearainn. Chun an fhadhb seo a mhaolú, déanaimid iniúchadh ar an bpróiseas a bhaineann le teimpléid dialóige a chruthú go huathoibríoch trí úsáid a bhaint as modhanna gan mhaoirseacht chun cainteanna stairiúla a bhraisliú agus cainteanna ionadaíocha a roghnú ó gach braisle. Go sonrach, molaimid múnla deireadh le deireadh ar a dtugtar Cnuasach Ionchódóra Pianbhreithe Deep (DSEC) a úsáideann struchtúr uath-ionchódóra chun an léiriú cainte a fhoghlaim i gcomhpháirt agus chun cnuasaigh teimpléid a thógáil. Déanaimid an modh seo a chur i gcomparáid le bunlíne randamach a sannann teimpléid go randamach do bhraislí chomh maith le bunlíne láidir a fheidhmíonn an t-ionchódú abairtí agus an braisliú cainte go seicheamhach. Chun feidhmíocht an mhodha atá beartaithe a mheas, déanaimid meastóireacht uathoibríoch le dhá thacar sonraí seirbhíse custaiméara anótáilte chun éifeachtacht cnuasaithe a mheas, agus turgnamh daonna-i-an-lúb ag baint úsáide as feidhmchlár beo seirbhíse do chustaiméirí chun ráta glactha na dteimpléad ginte a thomhas. . Is fearr a fheidhmíonn DSEC sa mheastóireacht uathoibríoch, buaileann sé na bunlínte seicheamhacha agus randamacha ar fhormhór na méadrachta sa turgnamh daonna-i-an-lúb, agus taispeánann sé torthaí gealltanais i gcomparáid le teimpléid óir/láimhe.', 'ka': 'დიალოგის რეგენციის მოდელები, რომლებიც შაბლონის რენექტირებას გამოყენებენ, არა დირექტური რენექტირების რეგენციის რეგისტირების რეგისტირების რეგისტირების რე მაგრამ მანძილურად შაბლონის შექმნის შექმნია დროის გამოყენება და მოჭირდება დიომინის ექსპერტიზაცია. ამ პრობლემას გახსნა, ჩვენ ავტომატიურად განვიხსნა დიალოგის შაბლონების შექმნა პროცესის შექმნის გამოყენებით, არაფერიზებული მეტოვების გამოყენებით ისტორიული სიტყვების და ყველა განსაკუთრებულია, ჩვენ მინდომებით დასრულებული მოდელს, რომელიც საერთოდ გამოყენებს სტრუქტურაცია და კონტრუქტურაცია შაბლონის კლასტერის გამოყენება ავტოკოდერის სტრუქტურაცია. ჩვენ ამ პროცემის შემდგომარებით შემდგომარებით გამოსაწყებული ფესტრის, რომელიც შემდგომარებით კლასტრისთვის შაბლონებს დააყენებს, რომელიც ძალიან ფესტრის ფესტრის,  საკუთარი პროგრამის გამოყენება, ჩვენ ავტომატური გამოყენება ორი მონიტურებული კლიენტერის სერვისტის მონაცემების დანაცემებისთვის კლასტერის ეფექტიურობის შესახებ, და ადამიანის მონაცემების პროგრამის გამოყენება კლიენტერი DSEC ავტომატიკური განსაზღვრებაში უფრო მნიშვნელოვანია, შემდეგ და გამოსაწყვებელოვანი ფემპერიმეტრიკის უფრო მეტრიკური ექსპერიმენტიკში, და გამოჩვენებს გასაზღვრებელი წარმოდგენები, როდესაც მომწ', 'el': 'Τα μοντέλα δημιουργίας απόκρισης διαλόγου που χρησιμοποιούν ταξινόμηση προτύπων αντί της άμεσης δημιουργίας αλληλουχιών επιτρέπουν στους προγραμματιστές μοντέλων να περιορίζουν τις παραγόμενες απαντήσεις σε προκαθορισμένα μηνύματα. Ωστόσο, η χειροκίνητη δημιουργία προτύπων είναι χρονοβόρα και απαιτεί εμπειρογνωμοσύνη στον τομέα. Για την ανακούφιση αυτού του προβλήματος, διερευνούμε την αυτοματοποίηση της διαδικασίας δημιουργίας προτύπων διαλόγου χρησιμοποιώντας μεθόδους χωρίς επίβλεψη για να ομαδοποιήσουμε ιστορικές εκφράσεις και επιλέγοντας αντιπροσωπευτικές εκφράσεις από κάθε σύμπλεγμα. Συγκεκριμένα, προτείνουμε ένα ολοκληρωμένο μοντέλο που ονομάζεται ομαδοποίηση κωδικοποιητή βαθιάς φράσης (που χρησιμοποιεί μια δομή αυτόματου κωδικοποιητή για να μάθει από κοινού την αναπαράσταση εκφρασμού και να κατασκευάσει ομάδες προτύπων. Συγκρίνουμε αυτή τη μέθοδο με μια τυχαία γραμμή βάσης που εκχωρεί τυχαία πρότυπα σε ομάδες καθώς και μια ισχυρή γραμμή βάσης που εκτελεί την κωδικοποίηση προτάσεων και την ομαδοποίηση εκφρασμού διαδοχικά. Για να αξιολογηθεί η απόδοση της προτεινόμενης μεθόδου, διενεργούμε μια αυτόματη αξιολόγηση με δύο σχολιασμένα σύνολα δεδομένων εξυπηρέτησης πελατών για την αξιολόγηση της αποτελεσματικότητας της ομαδοποίησης, και ένα πείραμα με χρήση μιας ζωντανής εφαρμογής εξυπηρέτησης πελατών για τη μέτρηση του ποσοστού αποδοχής των παραγόμενων προτύπων. Η DSEC αποδίδει καλύτερα στην αυτόματη αξιολόγηση, νικά τόσο τις διαδοχικές όσο και τις τυχαίες γραμμές βάσης στις περισσότερες μετρήσεις στο πείραμα ανθρώπου-στον-βρόχο και παρουσιάζει πολλά υποσχόμενα αποτελέσματα σε σύγκριση με τα χρυσά/χειροκίνητα δημιουργημένα πρότυπα.', 'hu': 'A sablonrangsorolást használó párbeszédválasz-generálási modellek lehetővé teszik a modellfejlesztők számára, hogy korlátozzák a generált válaszokat az előzetesen jóváhagyott üzenetekre. A sablonok manuális létrehozása azonban időigényes és tartományi szakértelmet igényel. A probléma enyhítése érdekében a párbeszédsablonok létrehozásának automatizálását vizsgáljuk felügyelet nélküli módszerekkel a történelmi kimondások összekapcsolására és az egyes klaszterekből reprezentatív kimondások kiválasztására. Konkrétan egy olyan végpontos modellt javasolunk, amelynek neve Deep Sentence Encoder Clustering (DSEC), amely egy automatikus kódoló struktúrát használ a kimondás reprezentációjának közös megismerésére és sablonfürtök létrehozására. Ezt a módszert egy véletlenszerű alapvonallal hasonlítjuk össze, amely véletlenszerűen hozzárendeli a sablonokat a klaszterekhez, valamint egy erős alapvonallal, amely sorozatban végrehajtja a mondatkódolást és a kimondási klaszterezést. A javasolt módszer teljesítményének értékeléséhez automatikus értékelést végzünk két jegyzetelt ügyfélszolgálati adatkészlettel a klaszterezés hatékonyságának értékelésére, valamint egy élő ügyfélszolgálati alkalmazás segítségével a létrehozott sablonok elfogadási arányának mérésére. A DSEC teljesít a legjobban az automatikus értékelésben, mind a szekvenciális, mind a véletlenszerű alapértékeket a legtöbb mutatónál a humán-in-the-loop kísérletben, és ígéretes eredményeket mutat az arany/manuálisan létrehozott sablonokhoz képest.', 'it': "I modelli di generazione di risposte di dialogo che utilizzano il posizionamento dei modelli piuttosto che la generazione di sequenze dirette consentono agli sviluppatori di modelli di limitare le risposte generate ai messaggi pre-approvati. Tuttavia, la creazione manuale di modelli richiede tempo e richiede competenze nel dominio. Per ovviare a questo problema, esploriamo l'automatizzazione del processo di creazione di modelli di dialogo utilizzando metodi non supervisionati per raggruppare le espressioni storiche e selezionare le espressioni rappresentative da ogni cluster. Nello specifico, proponiamo un modello end-to-end chiamato Deep Sentence Encoder Clustering (DSEC) che utilizza una struttura auto-encoder per imparare congiuntamente la rappresentazione dell'espressione e costruire cluster di template. Confrontiamo questo metodo con una linea di base casuale che assegna casualmente modelli ai cluster, così come una linea di base forte che esegue la codifica delle frasi e il clustering delle parole in modo sequenziale. Per valutare le prestazioni del metodo proposto, eseguiamo una valutazione automatica con due set di dati del servizio clienti annotati per valutare l'efficacia del clustering e un esperimento human-in-the-loop utilizzando un'applicazione di servizio clienti live per misurare il tasso di accettazione dei modelli generati. DSEC si comporta meglio nella valutazione automatica, batte sia le linee di base sequenziali che casuali sulla maggior parte delle metriche nell'esperimento umano-in-the-loop e mostra risultati promettenti se confrontati con modelli gold/creati manualmente.", 'lt': 'Dialogo atsako generavimo modeliai, naudojantys šablonų klasifikavimą, o ne tiesioginę sekos generavimą, leidžia modelio kūrėjams apriboti iš anksto patvirtintų pranešimų gautus atsakus. Tačiau rankiniu būdu sukurti šablonus reikia laiko ir reikalinga srities patirtis. Siekiant sušvelninti šią problem ą, mes tiriame dialogo šablonų kūrimo proceso automatizavimą naudojant nepastebimus metodus istoriniams išraiškams suvienodinti ir kiekvienos grupės atstovaujamiems išraiškams pasirinkti. Konkrečiai siūlome model į „giliųjų sakinių kodavimo klasterizacija“ (angl. Deep Sense Encoder Clustering, DSEC), kuriame naudojama automatinio kodavimo struktūra bendrai mokytis žodžio atstovavimo ir sukurti šablonų klasterius. Palyginame šį metodą su atsitiktine pradine verte, kuri atsitiktinai priskiria šablonus klasteriams, taip pat stiprią pradinę vertę, kuri atlieka sakinio kodavimą ir žodžių klasteriavimą iš eilės. Siekiant įvertinti siūlomo metodo veiksmingumą, atliekame automatinį vertinimą su dviem anotuotais klientų paslaugų duomenų rinkiniais, kad įvertintume klasterizavimo veiksmingumą, ir žmogaus eksperimentą su gyva klientų paslaugų programa, kad įvertintume sukurtų šablonų priėmimo lygį. DSEC atlieka geriausius rezultatus atliekant automatinį vertinimą, dažniausiai atliekant žmogaus bandymą su ciklu grindžiamas sekacines ir atsitiktines bazines linijas ir rodo pažangius rezultatus, palyginti su auksiniais ir (arba) rankiniu būdu sukurtais šablonais.', 'kk': 'Диалогтың жауап беру үлгілерін құру үлгілері, тәсілді реттеу үлгілерін құру үлгілері, жасаушылардың үлгілерін алдын- ала құпталған хаттардың жауаптарын ше Бірақ, үлгілерді қолмен құру - уақыт пайдалану және доменнің білімі керек. Бұл мәселеді көшірмелеу үшін, біз диалог үлгілерін құру процесін автоматты түрде зерттеп, тарихлық сөздерді кластерлеу және әрбір кластерден келтірілген сөздерді таңдау үшін қолданбаған ә Ескерту үшін, біз "Deep Sentence Encoder Clustering" (DSEC) деп аталатын аяқтау үлгісін қолданатын автокодер құрылғысын біріктіру және үлгі кластерін құру үшін қолданатын аяқтау үлгісін таңдаймыз. Бұл әдісті кездейсоқ негізгі сызыққа салыстырып, үлгілерді кластерге, сөздер кодтамасын және сөздерді кездейсоқ кластерге салыстырады. Бұл таңдалған әдістерді бағалау үшін, біз клиенттердің қабылдау жылдамдығын анықтау үшін екі жарияланған клиенттер қызметінің деректер қорларынан автоматты түрде оқиға істейміз. DSEC автоматты түрде бағалау үшін ең жақсы жұмыс істейді, адамдардың ішіндегі теспериментінің көпшілігі метрикалық және кездейсоқ негізгі сызықтарын да бұғаттайды, ол алтын/қолмен құрылған үлгілерімен салыстырылғанда', 'mk': 'Моделите на генерација на одговори од дијалогот кои користат рангирање на шаблони наместо директна генерација на секвенца им овозможуваат на развивачите на моделите да ги ограничат генерираните одговори на преодобрени пораки. Сепак, рачно создавање на шаблони потребно е време и бара експертиза во доменот. За да го олесниме овој проблем, го истражуваме автоматизирањето на процесот на создавање шаблони за дијалог со употреба на ненадгледувани методи за групирање историски изрази и избирање на претставни изрази од секој груп. Специфично, предложуваме модел од крај до крај наречен Клустеринг на кодери на длабоки реченици (ДСЕК) кој користи структура на автоматски кодери за заеднички да го научи претставувањето на изразот и да изгради клустери на шаблони. Го споредуваме овој метод со случајна основа која случајно ги додава шаблоните на групи, како и силна основа која ја извршува кодирањето на речениците и групирањето на изразите секвенцијално. To evaluate the performance of the proposed method, we perform an automatic evaluation with two annotated customer service datasets to assess clustering effectiveness, and a human-in-the-loop experiment using a live customer service application to measure the acceptance rate of the generated templates.  ДСЕК е најдобар во автоматската проценка, ги победува секвенцијалните и случајните основни линии на повеќето метрики во експериментот во врска со човекот и покажува ветувачки резултати во споредба со златните/рачно создадени шаблони.', 'ms': 'Model generasi balas dialog yang menggunakan rangkaian templat daripada generasi urutan langsung membenarkan pembangun model untuk hadapi balas yang dijana kepada mesej yang telah disetujui. Namun, mencipta templat secara manual memakan masa dan memerlukan keterampilan domain. To alleviate this problem, we explore automating the process of creating dialogue templates by using unsupervised methods to cluster historical utterances and selecting representative utterances from each cluster.  Secara khusus, kami cadangkan model akhir-akhir yang dipanggil Pemkumpulan Pengekod Perhatian Dalam (DSEC) yang menggunakan struktur pengekod-sendiri untuk belajar bersama-sama perwakilan ungkapan dan membina kumpulan templat. Kita membandingkan kaedah ini dengan dasar rawak yang secara rawak menukarkan templat kepada kumpulan serta dasar kuat yang melakukan pengekodan kalimat dan kumpulan utterance secara berturut-turut. Untuk menilai prestasi kaedah yang direncanakan, kami melakukan penilaian automatik dengan dua set data perkhidmatan pelanggan yang dicatat untuk menilai keefektivitas kelompok, dan eksperimen manusia-dalam-loop menggunakan aplikasi perkhidmatan pelanggan langsung untuk mengukur kadar penerimaan templat yang dijana. DSEC melakukan yang terbaik dalam penilaian automatik, memukul kedua-dua garis dasar secara jujukan dan rawak pada kebanyakan metrik dalam eksperimen manusia-dalam-loop, dan menunjukkan keputusan yang berjanji bila dibandingkan dengan templat emas/dicipta secara manual.', 'no': 'Modellar for oppretting av svar på dialogvindauget som brukar mal- ranking i staden for direkte sekvensgenerasjon tillèt utviklarane for modellen å avgrensa oppretta svar til føregodkjende meldingar. Men å laga malar manuelt er tidspunkt og krev domeneekspertisering. For å redusera dette problemet, utforskar vi automatisk prosessen for å laga dialogmaler ved å bruka ulike metodar for å klassera historiske uttrykk og velja reprezentativ uttrykk frå kvar grupper. Vi foreslår eit sluttmodul kalla Deep Sentence Encoder Clustering Vi samanliknar denne metoden med ein tilfeldig grunnlinje som tilfeldig tilbyr malen til grupper og ein sterk grunnlinje som utfører setningskodinga og utgangskodinga etterfølgjande. For å evaluera utviklinga av den foreslåtte metoden, utfører vi ein automatisk evaluering med to oppmerkte klientteneste- datasett for å vurdere klosteringseffektivitet, og ein eksperiment med menneske- i- loop- eksperiment med ein leve klientteneste- program for å måle aksepteringsrate på dei genererte malene. DSEC utfører best i den automatiske evalueringa, slår både sekvensielle og tilfeldige baselinjene på dei fleste metrikane i den menneskelige eksperimentet i loopen, og viser promiserende resultater når det sammenlignet med gull/manuelt laga malar.', 'mn': 'Диалогдын хариу үйлдвэрлэлийн загварууд нь шууд дарааллын бүтээгдэхүүний оронд шалгалтын дарааллыг ашигладаг загваруудын хөгжүүлэгчдийн загваруудыг аль нь зөвшөөрөгдсөн загварууды Гэвч, хугацааны хэрэглээнд гараар шагналыг бий болгох нь цаг хугацаа хэрэглэдэг ба холбооны мэргэжлийн талаар хэрэгтэй. Энэ асуудлыг багасгахын тулд бид диалог шалгалтыг бий болгох үйл явцыг автоматжуулан судалж, түүхийн хэлэлцээг, бүр бүрийн захирагчийн хэлэлцээг сонгох арга хэрэглэдэг. Ялангуяа бид "Deep Sentence Encoder Clustering" (DSEC) нэртэй төгсгөл үеийн загварыг санал болгож автокодчуудын бүтэц ашигладаг. Бид энэ аргыг санамсаргүй үндсэн шулуунтай харьцуулж байна. Энэ аргыг бүлэгтэй, мөн хүчирхэг үндсэн шулуунтай харьцуулж байна. Өөрчлөгдсөн арга хэмжээний ажиллагааг үнэлэхэд бид хоёр анзаарсан хэрэглэгчийн үйл ажиллагааны өгөгдлийн сангуудыг автоматжуулан үнэлэх хэрэглэгчийн үйл ажиллагааны үр дүнг шалгахын тулд, мөн хүн дотор нь хэрэглэгчийн үйл ажиллагааны хэрэглэгчийн ам DSEC автоматжуулалтын үнэлгээнд хамгийн сайн хийдэг, хүн төрөлхтний туршилтын ихэнх метриктик болон санамсаргүй суурь шугам хоёулаа хоёулаа хоёулаа хоёулаа хоёулаа хоёулаа хоёулаа хоёулаа хоёулаа хоёулаа хоё', 'ml': 'Dialogue response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages.  എന്നാലും കൈയ്യില്\u200d മാതൃകങ്ങള്\u200d ഉണ്ടാക്കുന്നത് സമയം ഉപയോഗിക്കുന്നതാണ്. ഡൊമെയിന്\u200d വിശേഷം ആവശ്യമുണ്ട്. ഈ പ്രശ്നത്തെ ലളിപ്പിക്കാന്\u200d, നമ്മള്\u200d സംസാരിക്കുന്ന ഡയലോഗ് മാതൃകങ്ങള്\u200d സൃഷ്ടിക്കുന്നതിന്\u200dറെ പ്രക്രിയയെ സ്വയം പരിശോധിക്കുന്നു. നിര്\u200dജ് പ്രത്യേകിച്ച്, ആഴത്തെ ശിക്ഷ ക്ലോസ്റ്റര്\u200d ക്ലോസ്റ്റര്\u200d (DSEC) എന്ന പേരുള്ള അവസാനത്തേക്കുള്ള ഒരു മോഡല്\u200d നാം പ്രായശ്ചിത്തം ചെയ്യുന്നു. വാക്കുകളുടെ പ നമ്മള്\u200d ഈ രീതിയെ താല്\u200dക്കാലികമായ ഒരു ബെസ്ലൈനിലേക്ക് താല്\u200dക്കാലികമായി ക്ലാസ്റ്റര്\u200dക്ക് അയച്ചുകൊടുക്കുന്ന ഒരു ശക്തിയുള്ള ബെസ്ലൈ പ്രൊദ്ദേശിക്കപ്പെട്ട രീതിയുടെ പ്രഭാവം വിലാസപ്പെടുത്താന്\u200d, സൃഷ്ടിച്ചിരിക്കുന്ന മാതൃകങ്ങളുടെ സേവനത്തിന്റെ സ്വാതന്ത്ര്യം അളക്കാന്\u200d രണ്ട് കസ്റ്റര്\u200d സേവനത ഡിസിസി സ്വയമായ വിലാസങ്ങളില്\u200d ഏറ്റവും നല്ലത് പ്രവര്\u200dത്തിപ്പിക്കുന്നു, മനുഷ്യരുടെ മെറ്റിക്കങ്ങളില്\u200d മെട്രിക്കുകളില്\u200d സ്വർണ്ണ/കൈമാന്റ് ഉണ്ടാക്കുമ്പോള്\u200d', 'mt': 'Il-mudelli tal-ġenerazzjoni tar-rispons tad-djalogu li jużaw klassifikazzjoni tal-mudelli minflok ġenerazzjoni diretta tas-sekwenza jippermettu lill-iżviluppaturi tal-mudelli jillimitaw ir-risponsi ġġenerati għal messaġġi approvati minn qabel. Madankollu, il-ħolqien manwali ta’ mudelli jieħu ħafna ħin u jeħtieġ għarfien espert fid-dominju. Biex itaffu din il-problema, nesploraw l-awtomatizzazzjoni tal-proċess tal-ħolqien ta’ mudelli ta’ djalogu billi nużaw metodi mhux sorveljati biex jingħaqdu dikjarazzjonijiet storiċi u nagħżlu dikjarazzjonijiet rappreżentattivi minn kull grupp. B’mod speċifiku, qed nipproponu mudell minn tarf sa tarf imsejjaħ Klassifikazzjoni tal-Kodifikatur tas-Sentenzi Profondi (Deep Sentence Encoder Clustering - DSEC) li juża struttura tal-awto-kodifikatur biex jitgħallem b’mod konġunt ir-rappreżentazzjoni tal-espressjoni u jinbnew klassifikazzjonijiet tal-mudelli. Aħna nqabblu dan il-metodu ma’ linja bażi każwali li b’mod każwali tassenja mudelli lil raggruppamenti kif ukoll linja bażi b’saħħitha li twettaq l-ikkodifikar tas-sentenza u l-raggruppament tal-espressjonijiet b’mod sekwenzjali. Biex tivvaluta l-prestazzjoni tal-metodu propost, nagħmlu evalwazzjoni awtomatika b’żewġ settijiet ta’ dejta annotati dwar is-servizz tal-klijent biex tivvaluta l-effettività tal-clustering, u esperiment uman fil-loop bl-użu ta’ applikazzjoni live tas-servizz tal-klijent biex tkejjel ir-rata ta’ a ċċettazzjoni tal-mudelli ġġenerati. DSEC tagħmel l-aħjar fl-evalwazzjoni awtomatika, taqbeż kemm il-linji bażi sekwenzjali kif ukoll dawk każwali fuq il-biċċa l-kbira tal-metriċi fl-esperiment tal-bniedem fil-loop, u turi riżultati promettenti meta mqabbla ma’ mudelli tad-deheb/maħluqa manwalment.', 'pl': 'Modele generowania odpowiedzi dialogowych, które używają rankingu szablonów zamiast bezpośredniego generowania sekwencji, pozwalają twórcom modeli ograniczyć generowane odpowiedzi na wstępnie zatwierdzone wiadomości. Ręczne tworzenie szablonów jest jednak czasochłonne i wymaga wiedzy specjalistycznej w dziedzinie. Aby złagodzić ten problem, badamy automatyzację procesu tworzenia szablonów dialogów poprzez wykorzystanie metod nienadzorowanych do klastrowania historycznych wypowiedzi i wyboru reprezentatywnych wypowiedzi z każdego klastra. W szczególności proponujemy kompleksowy model o nazwie Deep Sentence Encoder Clustering (DSEC), który wykorzystuje strukturę autokodera do wspólnego uczenia się reprezentacji wypowiedzi i konstruowania klastrów szablonów. Porównujemy tę metodę z losową linią bazową, która losowo przypisuje szablony do klastrów, a także silną linią bazową, która wykonuje kodowanie zdań i grupowanie wypowiedzi kolejno. Aby ocenić wydajność proponowanej metody, wykonujemy automatyczną ocenę z dwoma adnotacyjnymi zestawami danych obsługi klienta w celu oceny skuteczności klastrowania oraz eksperyment człowieka w pętli za pomocą aplikacji obsługi klienta na żywo w celu pomiaru współczynnika akceptacji generowanych szablonów. DSEC sprawdza się najlepiej w automatycznej ocenie, pokonuje zarówno sekwencyjne, jak i losowe linie bazowe w większości wskaźników eksperymentu człowieka w pętli i pokazuje obiecujące wyniki w porównaniu ze złotymi/ręcznie tworzonymi szablonami.', 'ro': 'Modelele de generare a răspunsurilor de dialog care utilizează clasificarea șabloanelor mai degrabă decât generarea directă de secvențe permit dezvoltatorilor de modele să limiteze răspunsurile generate la mesajele pre-aprobate. Cu toate acestea, crearea manuală a șabloanelor necesită timp și necesită expertiză în domeniu. Pentru a atenua această problemă, explorăm automatizarea procesului de creare a șabloanelor de dialog utilizând metode nesupravegheate pentru a grupa cuvintele istorice și selectarea cuvintelor reprezentative din fiecare cluster. Mai exact, propunem un model end-to-end numit Deep Sentence Encoder Clustering (DSEC), care utilizează o structură auto-encoder pentru a învăța împreună reprezentarea rostirii și a construi clustere de șabloane. Comparăm această metodă cu o linie de referință aleatorie care atribuie aleatoriu șabloane grupurilor, precum și cu o linie de referință puternică care efectuează codificarea propozițiilor și gruparea cuvintelor secvențial. Pentru a evalua performanța metodei propuse, efectuăm o evaluare automată cu două seturi de date adnotate de serviciu pentru clienți pentru a evalua eficiența clusterizării și un experiment uman-in-the-loop utilizând o aplicație live de serviciu pentru clienți pentru a măsura rata de acceptare a șabloanelor generate. DSEC performează cel mai bine în evaluarea automată, bate atât liniile de referință secvențiale, cât și aleatorii pe majoritatea măsurătorilor din experimentul uman-in-the-loop și arată rezultate promițătoare în comparație cu șabloanele aurii / create manual.', 'sr': 'Modeli generacije odgovora na dijalog koji koriste ranking šablona umjesto izravne generacije sekvence omogućavaju modelu razvijača da ograniče generirane odgovore na pre odobrene poruke. Međutim, ručno stvaranje šablona je potrošenje vremena i zahteva stručnost domena. Da bismo olakšali ovaj problem, istražujemo automatski proces stvaranja šablona dijaloga koristeći neodređene metode za skupljanje istorijskih izraza i izabranje reprezentativnih izraza iz svakog skupa. Posebno, predlažemo model kraja do kraja nazvan klustering dubokog kaznog kodera (DSEC) koji koristi strukturu automatskog kodera kako bi zajedno naučili predstavljanje izraza i konstrukciju klupova šablona. Uspoređujemo ovu metodu sa nasumičnom početnom linijom koja slučajno određuje hrame skupinama, kao i snažnom početnom linijom koja izvršava kodiranje rečenica i izraz skupljanja slično. Da bismo procenili provedbu predložene metode, izvršili smo automatsku procjenu sa dve oznake podatke o usluzi klijenata kako bi procenili učinkovitost skusteringa i eksperiment koji koristi aplikaciju za uslugu živog klijenta kako bi izmjerili stopu prihvatanja proizvedenih šablona. DSEC izvršava najbolje u automatskoj procjeni, pobeđuje i sekvencijalne i nasumične osnovne linije na većini metrika u eksperimentu u ljudskom krugu, i pokazuje obećavajuće rezultate u usporedbi sa zlatom/ručno stvorenim hramom.', 'so': "Tusaale'aalaha ku jawaabista diyaarinta ee isticmaalaya jardiinada ay ku raadiyaan meelaha ay ku qoran lahaayeen meelaha dhaqdhaqaaqa oo toos ah, waxay u fasaxaan kuwa sameynaya qaababka sameynta si ay u xadgudbaan jawaabo ay u soo jeedaan wargeeyayaasha horay loo ogolaaday. Si kastaba ha ahaatee sameynta macluumaadku waa cuntada waqtiga ah, waxaadna u baahan tahay aqoonta deegaanka. To alleviate this problem, we explore automating the process of creating dialogue templates by using unsupervised methods to cluster historical utterances and selecting representative utterances from each cluster.  Si gaar ah, waxaynu soo jeedaynaa model dhammaadka ugu dambaysta ah oo la yidhaahdo Deep Encoder Xukunka (DSEC) oo isticmaalaya dhismo auto-encoder-structure si aad ugu wada barto muuqashada hadalka oo aad u sameynayso qalabka template. Waxaynu isbarbardhignaa noocyada hoose-hoose oo si fudud u dhiga qoraal ay u dhigaan dhaqdhaqaale iyo sidoo kale qoraal xoog leh oo sameynaya qoraalka codsiga iyo hadalka dabadeed. Si a an u qiimeyno sameynta qaababka la soo jeeday, waxaynu sameynaa qiimeynta dhaqdhaqaalaha labada kooban ee adeegga macaamiisha si aan u qiimeyno faa’iidada hore iyo imtixaanka qofka ah oo ku qoran codsiga adeegga nolosha ee macaamiisha si aan u qiyaasto qiimeynta qaabilaada macaamiisha laga sameeyo. DSEC wuxuu si wanaagsan u sameeyaa qiimeynta bilowga ah, wuxuu ku garaacaa qoraalka hoose-hoose iyo hoos-dhexe oo ku yaala imtixaanka dadka oo dhan, wuxuuna tusaa resultooyin ballan ah marka la barbardhigo qoraalo dahab/gacmo lagu sameeyo.", 'sv': 'Modeller för dialogsvarsgenerering som använder mallrankning snarare än direkt sekvensgenerering gör det möjligt för modellutvecklare att begränsa genererade svar till förhandsgodkända meddelanden. Att skapa mallar manuellt är dock tidskrävande och kräver domänexpertis. För att lindra detta problem utforskar vi att automatisera processen att skapa dialogmallar genom att använda oövervakade metoder för att klustra historiska uttalanden och välja representativa yttranden från varje kluster. Specifikt föreslår vi en end-to-end-modell som kallas Deep Sentence Encoder Clustering (DSEC) som använder en automatisk kodningsstruktur för att gemensamt lära sig yttranderepresentationen och konstruera mallkluster. Vi jämför den här metoden med en slumpmässig baslinje som slumpmässigt tilldelar mallar till kluster samt en stark baslinje som utför meningskodning och yttrandeklustring sekventiellt. För att utvärdera resultatet av den föreslagna metoden utför vi en automatisk utvärdering med två kommenterade kundservicedataset för att bedöma klustereffektivitet, och ett human-in-the-loop experiment med hjälp av en live kundserviceapplikation för att mäta acceptansfrekvensen för de genererade mallarna. DSEC presterar bäst i den automatiska utvärderingen, slår både sekventiella och slumpmässiga baselines på de flesta mätvärden i human-in-the-loop experimentet, och visar lovande resultat jämfört med guld/manuellt skapade mallar.', 'si': '@ info: whatsthis නමුත්, වෙලාවක් නිර්මාණය කරන්නේ වෙලාව භාවිත කරන්න සහ ඩොමේන් විශේෂය අවශ්\u200dයයි. මෙම ප්\u200dරශ්නයක් අඩංගුවන්න, අපි ස්වයංගයෙන් සංවාදයේ ටෙම්ප්ලේටල් සිර්මාණය කරන්න ස්වයංගයක් පරීක්ෂණය කරනවා සහ සංවාද විශේෂයෙන්ම, අපි අවසානයෙන් අවසානයෙන් අවසානය කරනවා Deep Sentence Encoder Cluster (DSECE) කියලා, ඒක ස්වයංකේතකයෙන් සංවිධානයක් භාවිත කරනවා කියලා කි අපි මේ විධානය සම්බන්ධ කරන්නේ ක්\u200dරියාත්මක ප්\u200dරමාණය සහ ක්\u200dරියාත්මක විදිහට ට ටෙම්ප්ලේට්ස්ටර් එක්ක සම්බන්ධ ප්\u200dරමාණය සහ ක්\u200dරියා ප්\u200dරශ්න විධානයේ ක්\u200dරියාත්මක විශ්වාස කරන්න, අපි ස්වයංක්\u200dරියාත්මක විශ්වාස කරන්න, ස්වයංක්\u200dරියාත්මක විශ්වාස දෙකක් සඳහා ප්\u200dරශ්න විශ්වාස කරන්න, ස DSEක් ස්වයංක්\u200dරීය විශ්ලේෂණයෙන් හොඳම විශ්ලේෂණය කරනවා, මිනිස්සුන්ගේ මෙට්\u200dරික්ස් වලින් සියළුම සහ අවසාන විශ්ලේෂණයෙන් පරීක්ෂණයෙ', 'ta': 'Dialogue response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages.  ஆயினும், கைமுறையாக வார்ப்புருவை உருவாக்குதல் நேரம் பயன்படுத்தல் மற்றும் domain expertise தேவைப்படுகிறது. இந்த பிரச்சினையை நீக்க, ஒவ்வொரு குழுவிலிருந்தும் இருந்தும் பிரதிநிதிய மொழிகளை தேர்ந்தெடுக்க உரையாடல் வார்த்தைகளை உருவாக்கும் மு குறிப்பிட்டு, நாம் ஆழமான வாக்குறியீட்டு குறியீடு (DSEC) என்ற ஒரு முடிவு மாதிரி முறைமையை பரிந்துரைக்கிறோம். இது தானியங்கி குறியீட்டு உருவமைப்பை  நாம் இந்த முறையை ஒப்பிடுக்க வேண்டும் ஒரு குறிப்பில்லாத அடிப்பகுதிக்காட்டில் வார்ப்புருக்களை குறியீட்டுக்கு ஒப்பிடுகிறோம்  பரிந்துரைக்கப்பட்ட முறைமையின் செயல்பாட்டை மதிப்பிட, நாம் தன்னியக்கமாக ஒரு மதிப்பிடுதலை செய்கிறோம் இரண்டு குறிப்பிட்ட பயனர் சேவை தரவுத்தளங்களை மதிப்பிடுவதற்கு, மேலும DSEC தன்னியக்கமாக மதிப்பீட்டில் சிறந்த செயல்படுத்துகிறது, பின்வரும் குறிப்பிடப்பட்ட மெட்ரிக்களில் இருந்தும் அடிப்படையான அடிப்படைகளையும் தோல்விக்கிறது, மன', 'ur': 'Dialog response generation models that use template ranking instead of direct sequence generation model developers to limit generated responses to pre-approved messages. لیکن، ٹیپلٹ بنانے کے ذریعے وقت مصرف کرنا ہے اور ڈومین کی تعلیم کی ضرورت ہے. اس مسئلہ کو آسان کرنے کے لئے، ہم ڈالیٹ ٹیپلٹ بنانے کی پروسس کو اٹوکیٹ کررہے ہیں، اور ہر کلسٹر سے نمایشن باتوں کا انتخاب کررہے ہیں۔ خاص طور پر، ہم ایک آخر-آخر موڈل کو پیشنهاد کرتے ہیں جو Deep Sentence Encoder Clustering (DSEC) کا نام ہے جس نے ایک استعمال کوڈر کی ساختار استعمال کرتا ہے کہ ایک ساتھ بات کی نمایش اور ٹمپلٹ کلسٹر کو سکھائے۔ ہم نے اس طریقہ کو ایک ناقص بنسٹ لین کے مطابق مقایسہ کرتا ہے جو کلسٹر کے لئے ٹیپلٹ اور ایک قوی بنسٹ لین کے مطابق ٹیپلٹ کا مقایسہ کرتا ہے جو کلسٹر کا اکنوڈ کرتا ہے اور کلسٹر کے مطابق کلسٹر کرتا ہے۔ پیشنهاد طریقے کے عملکرد کا ارزش کرنے کے لئے، ہم نے دو مشهور کائن سرویس ڈیٹ سٹ کے ساتھ ایک آٹوٹی ارزش کرلیا ہے کہ کلسٹرینگ عملکرد کا ارزش کریں، اور ایک انسان-in-loop آزمائش کے مطابق ایک زندہ کائن سرویس کاروبار کے مطابق پیدا کئے ہوئے ٹیپلٹوں کے قبول کے ڈیس اس کی آٹوٹی ارزیابی میں بہترین عمل کرتا ہے، انسان کی آزمائش میں بہترین میٹریک کے بارے میں سکنڈی اور نافذی بنسٹلین کو ضرب دیتا ہے، اور سونے/ہاتھ سے پیدا ہوئے ٹیپلٹوں کے مقابلہ میں وعدہ کا نتیجہ دکھاتا ہے.', 'uz': "Dialogue response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages.  Lekin, namunani qoʻlbola yaratish vaqt ishlatish va domen ekspertisi kerak. Bu muammolani kamaytirish uchun, biz muloqat namunasini avtomatik yaratish jarayonlarini o'rganamiz va tarixiy so'zlarni kichiklashtirish va har bir cluster bilan bir xil gapirishni tanlash uchun xabar qilamiz. Koʻrsatilgan, biz soʻzni tahrirlash va namunani yaratish uchun avtomatik kodlash tuzusini foydalanishi mumkin. Biz bu usulni Tasodifiy asboblar bilan kamaytamiz. Namunalar davom etiladi, va maxfiy soʻzni kodlash va soʻzni keyin keladi. Taʼminlovchi usulning natijasini qiymatish uchun biz taʼminlovchi ikkita taʼminlovchi xizmatlar maʼlumotlari bilan avtomatik bajaramiz, va tuzuvlagan namunalarning qiymatini qidirish uchun davom etish uchun oddiy foydalanuvchi xizmatni foydalanish uchun qo'shimcha muvaffaqiyatli imtiyozni bajaramiz. Name", 'vi': 'Những mẫu tạo phản ứng đối thoại dùng kiểu xếp hạng mẫu thay vì chế tạo chuỗi trực tiếp cho phép mô- đun phát triển giới hạn phản ứng với các thông điệp được phê chuẩn. Tuy nhiên, việc tạo mẫu bằng tay đòi hỏi thời gian và cần chuyên môn miền. Để giải quyết vấn đề này, chúng ta sẽ khám phá việc tự động quá trình tạo mẫu thoại bằng cách dùng phương pháp không giám sát để thống kê những từ lịch sử và chọn những từ đại diện từ mỗi cụm mục. Cụ thể, chúng tôi đề xuất một kiểu mẫu kết thúc-tới-cuối gọi là DẬY Encoder Thấy Thấy Thấy (DSEC) dùng một cấu trúc tự mã hóa để cùng nhau học đại diện người phát âm và xây dựng các tập mẫu. Chúng tôi so sánh phương pháp này với một cơ sở cơ bản ngẫu nhiên phân bố mẫu cho cụm cụm số, cũng như một cơ sở cơ bản mạnh mẽ thực hiện mã số câu và kết hợp cụm từ. Để đánh giá hiệu quả của phương pháp được đề xuất, chúng tôi thực hiện một đánh giá tự động với hai bộ dữ liệu phục vụ khách hàng được ghi chú để đánh giá hiệu quả tụ tập, và một thử nghiệm trên mạng sử dụng dịch vụ khách hàng trực tiếp để đo tốc độ chấp nhận của các mẫu đã tạo ra. phần lớn các bản mẫu ngẫu nhiên so với các mẫu được tạo bằng vàng (các mẫu tự tạo ra) đều có kết quả tốt nhất.', 'hr': 'Modeli generacije odgovora na dijalog koji koriste redakciju šablona umjesto izravne generacije sekvencije omogućavaju razvijačima modela ograničiti generirane odgovore na predodobrene poruke. Međutim, ručno stvaranje šablona je potrošenje vremena i zahtijeva stručnost domena. Da bismo ublažili ovaj problem, istražujemo automatski proces stvaranja šablona dijaloga koristeći neodređene metode za skupljanje povijesnih izraza i izabrati predstavne izraze iz svakog skupa. Posebno, predlažemo model kraja do kraja nazvan klustering dubokog kaznog kodera (DSEC) koji koristi strukturu automatskog kodera kako bi zajedno naučili predstavljanje izraza i konstrukciju skupina šablona. Uspoređujemo ovu metodu sa nasumičnom početnom linijom koja slučajno dodaje šablone skupinama, kao i snažnom početnom linijom koja izvršava kodiranje rečenica i izraz skupine. Da bismo procijenili učinkovitost predložene metode, izvršili smo automatsku procjenu s dvije označene podatke o usluzi klijenata kako bi procijenili učinkovitost skusteringa i eksperiment koji koristi aplikaciju o usluzi živog klijenta kako bi mjerili stopu prihvaćenja proizvedenih šablona. DSEC najbolje provodi u automatskoj procjeni, pobjeđuje i sekvencijalne i nasumične osnovne linije na većini metrika u eksperimentu u ljudskom krugu i pokazuje obećavajuće rezultate u usporedbi s zlatom/ručno stvorenim šablovima.', 'bg': 'Моделите за генериране на отговор на диалоговия прозорец, които използват класиране на шаблони вместо директно генериране на последователност, позволяват на разработчиците на модели да ограничат генерираните отговори до предварително одобрени съобщения. Въпреки това ръчното създаване на шаблони отнема време и изисква експертен опит в областта. За да облекчим този проблем, изследваме автоматизирането на процеса на създаване на шаблони за диалог чрез използване на ненадзорни методи за групиране на исторически изказвания и подбор на представителни изказвания от всеки клъстер. По-конкретно, ние предлагаме модел от край до край, наречен клъстер за кодиране на дълбоки изречения (ДСЕК), който използва структура за автоматично кодиране, за да научи съвместно представянето на изказванията и да изгради клъстери шаблони. Сравняваме този метод с случайна базова линия, която произволно възлага шаблони на клъстери, както и със силна базова линия, която извършва кодирането на изреченията и клъстерирането на изреченията последователно. За да оценим ефективността на предлагания метод, извършваме автоматична оценка с два анотирани набора от данни за обслужване на клиенти, за да оценим ефективността на клъстерите, и експеримент с използване на приложение за обслужване на клиенти на живо, за да измерим степента на приемане на генерираните шаблони. ДСЕК се представя най-добре в автоматичната оценка, бие както последователните, така и случайните базови линии на повечето показатели в експеримента с човек в цикъла и показва обещаващи резултати в сравнение със златни / ръчно създадени шаблони.', 'da': 'Dialogsvarsgenereringsmodeller, der bruger skabelonplacering i stedet for direkte sekvensgenerering, giver modeludviklere mulighed for at begrænse genererede svar på forhåndsgodkendte meddelelser. Det er dog tidskrævende at oprette skabeloner manuelt og kræver domænekompetence. For at afhjælpe dette problem undersøger vi at automatisere processen med at oprette dialogskabeloner ved at bruge uautoriserede metoder til at klynge historiske udtalelser og vælge repræsentative udtalelser fra hver klynge. Specielt foreslår vi en end-to-end model kaldet Deep Sentence Encoder Clustering (DSEC), der bruger en autokodningsstruktur til i fællesskab at lære ytringsrepræsentationen og konstruere skabelonklynger. Vi sammenligner denne metode med en tilfældig basislinje, der tilfældigt tildeler skabeloner til klynger samt en stærk basislinje, der udfører sætningskodning og ytringsklyngning sekventielt. For at evaluere ydeevnen af den foreslåede metode udfører vi en automatisk evaluering med to annoterede kundeservicedatasæt for at vurdere klyngeeffektiviteten, og et human-in-the-loop eksperiment ved hjælp af en levende kundeserviceapplikation til at måle acceptraten af de genererede skabeloner. DSEC klarer sig bedst i den automatiske evaluering, slår både sekventielle og tilfældige baselines på de fleste målinger i human-in-the-loop-eksperimentet og viser lovende resultater sammenlignet med guld/manuelt oprettede skabeloner.', 'nl': 'Dialogresponsgeneratiemodellen die gebruik maken van template ranking in plaats van directe sequentie generatie, stellen modelontwikkelaars in staat om gegenereerde reacties op vooraf goedgekeurde berichten te beperken. Het handmatig maken van sjablonen is echter tijdrovend en vereist domeinexpertise. Om dit probleem op te lossen, onderzoeken we het automatiseren van het proces van het maken van dialoogsjablonen door gebruik te maken van onbeheerde methoden om historische uitingen te clusteren en representatieve uitingen uit elk cluster te selecteren. Specifiek stellen we een end-to-end model voor genaamd Deep Sentence Encoder Clustering (DSEC) dat een auto-encoder structuur gebruikt om gezamenlijk de expressie representatie te leren en template clusters te bouwen. We vergelijken deze methode met een willekeurige basislijn die willekeurig sjablonen toewijst aan clusters, evenals een sterke basislijn die de zinscodering en de uitsprekingsclustering opeenvolgend uitvoert. Om de prestaties van de voorgestelde methode te evalueren, voeren we een automatische evaluatie uit met twee geannoteerde customer service datasets om de effectiviteit van clustering te beoordelen, en een human-in-the-loop experiment met behulp van een live customer service applicatie om de acceptatiesnelheid van de gegenereerde sjablonen te meten. DSEC presteert het beste in de automatische evaluatie, verslaat zowel de sequentiële als willekeurige baselines op de meeste statistieken in het human-in-the-loop experiment en toont veelbelovende resultaten in vergelijking met goud/handmatig gemaakte sjablonen.', 'de': 'Modelle zur Generierung von Dialogantworten, die das Vorlagenranking anstelle der direkten Sequenzgeneration verwenden, ermöglichen es Modellentwicklern, generierte Antworten auf vorab genehmigte Nachrichten zu beschränken. Das manuelle Erstellen von Vorlagen ist jedoch zeitaufwendig und erfordert Domänenwissen. Um dieses Problem zu beheben, untersuchen wir die Automatisierung des Prozesses der Erstellung von Dialogvorlagen, indem wir unbeaufsichtigte Methoden verwenden, um historische Äußerungen zu clustern und repräsentative Äußerungen aus jedem Cluster auszuwählen. Insbesondere schlagen wir ein End-to-End-Modell namens Deep Satence Encoder Clustering (DSEC) vor, das eine Auto-Encoder-Struktur verwendet, um gemeinsam die Äußerungsdarstellung zu erlernen und Vorlagencluster zu konstruieren. Wir vergleichen diese Methode mit einer zufälligen Baseline, die zufällig Vorlagen zu Clustern zuordnet, sowie mit einer starken Baseline, die die Satzkodierung und die Äußerungsclustering sequenziell durchführt. Um die Leistung der vorgeschlagenen Methode zu bewerten, führen wir eine automatische Auswertung mit zwei kommentierten Kundenservicedatensätzen durch, um die Clustering-Effektivität zu bewerten, und ein Human-in-the-Loop-Experiment mit einer Live-Kundendienstanwendung, um die Akzeptanzrate der generierten Vorlagen zu messen. DSEC schneidet am besten in der automatischen Auswertung ab, übertrifft sowohl die sequentiellen als auch zufälligen Baselines der meisten Metriken im Human-in-the-Loop-Experiment und zeigt vielversprechende Ergebnisse im Vergleich zu Gold/manuell erstellten Vorlagen.', 'id': 'Model generasi respon dialog yang menggunakan rangkaian templat daripada generasi urutan langsung memungkinkan pengembang model untuk membatasi respon yang dihasilkan ke pesan yang disetujui sebelumnya. However, manually creating templates is time-consuming and requires domain expertise.  Untuk mengurangi masalah ini, kami mengeksplorasi proses untuk menciptakan templat dialog dengan menggunakan metode tidak diawasi untuk mengumpulkan ucapan sejarah dan memilih ucapan mewakili dari setiap kluster. Secara spesifik, kami mengusulkan model akhir-akhir yang disebut Deep Sentence Encoder Clustering (DSEC) yang menggunakan struktur auto-encoder untuk bersama-sama belajar representation utterance dan membangun template clusters. Kita membandingkan metode ini dengan dasar acak yang secara acak mengatur templat ke kumpulan serta dasar yang kuat yang melakukan pengekodan kalimat dan kumpulan utterance secara urutan. Untuk mengevaluasi prestasi dari metode yang diusulkan, kami melakukan evaluasi otomatis dengan dua set data pelayanan pelanggan yang dicatat untuk mengevaluasi efektivitas clustering, dan eksperimen manusia-in-the-loop menggunakan aplikasi layanan pelanggan langsung untuk mengukur kadar penerimaan dari templat yang dihasilkan. DSEC melakukan yang terbaik dalam evaluasi otomatis, mengalahkan garis dasar sekuensial dan acak pada kebanyakan metrik dalam eksperimen manusia-dalam-loop, dan menunjukkan hasil yang berjanji ketika dibandingkan dengan emas/templat yang dibuat secara manual.', 'ko': '직접 시퀀스 대신 템플릿 정렬을 사용하는 대화 응답 생성 모델은 모델 개발자가 생성된 응답을 미리 승인된 메시지로 제한할 수 있도록 합니다.그러나 수동으로 템플릿을 만드는 데는 시간이 많이 걸리고 분야의 전문 지식이 필요하다.이 문제를 완화시키기 위해 우리는 대화 템플릿을 자동으로 만드는 과정을 탐색했다. 방법은 감독이 없는 방법으로 역사적 언어를 분류하고 각 분류에서 대표적인 언어를 선택하는 것이다.구체적으로 말하자면, 우리는 언어 표시를 연합하여 학습하고 템플릿 집합을 구성하는 자동 인코딩 구조를 사용하는 심층문장 인코딩 집합(DSEC)이라는 끝에서 끝까지의 모델을 제시했다.우리는 이 방법을 무작위 기선(무작위 분배 템플릿에서 묶음까지)과 문장 인코딩과 언어 집합을 순서대로 실행하는 강한 기선과 비교할 것이다.이 방법의 성능을 평가하기 위해 우리는 주석이 달린 두 개의 고객 서비스 데이터 집합을 사용하여 자동 평가를 실시하여 집합 효과를 평가하고 실시간 고객 서비스 응용 프로그램을 이용하여 회로 실험을 실시하여 생성 템플릿의 수용률을 측정했다.DSEC은 자동 평가에서 가장 좋았고 회로 실험에서 대부분의 지표에서 순서와 무작위 기준선보다 우수했으며 황금/수동으로 만든 템플릿에 비해 유망한 결과를 보였다.', 'fa': 'مدلهای نسخه پاسخ دادن محاورۀ محاورۀ محاورۀ نسخه\u200cهای قالب استفاده می\u200cکنند به جای نسخه رشته\u200cهای مستقیم اجازه می\u200cدهد که توسعه\u200cکنندگان مدل اجازه دهند تا پاسخ\u200cهای تولید با این حال، ساختن قالب\u200cهای دستی زمان\u200cconsumption است و نیاز به دانش\u200cشناسی دامنی است. برای آسان کردن این مشکل، ما از طریق استفاده از روش\u200cهای غیرقابل استفاده برای کلاس سخنرانی تاریخی و انتخاب سخنرانی نماینده\u200cای از هر کلاس استفاده می\u200cکنیم. به طور خاص، ما یک مدل آخر و پایان را پیشنهاد می\u200cکنیم به نام کلاسترینگ رمزگذاری عمیق (DSEC) که از یک ساختار رمزگذاری خودکار استفاده می\u200cکند تا با هم نمایش گفتن و کلاسترهای رمزگذاری را یاد بگیریم. ما این روش را با یک خط بنیادی تصادفی مقایسه می کنیم که به طور تصادفی کلاس ها را به کلاس ها و یک خط بنیادی قوی تهیه می کند که قانون رمز کردن جمله و کلاس\u200cها را به طور بعدی انجام می دهد. برای ارزیابی عملکرد روش پیشنهاد، ما یک ارزیابی اتوماتیک را با دو مجموعه داده\u200cهای خدمات مشتری آشکار می\u200cکنیم تا ارزیابی فعالیت کلاسترین را بررسی کنیم، و یک آزمایش انسان در داخل چرخه با استفاده از یک کاربرد خدمت موکلی زنده برای اندازه\u200cگیری میزان پذیرش قالب تولی DSEC بهترین تحقیقات خودکار را انجام می دهد، هر دو خط طبقه\u200cهای پایگاه\u200cهای سفارشی و تصادفی را بر بیشتر متریک در آزمایش انسان در چرخه\u200cی چرخه شکست می\u200cدهد، و نتیجه\u200cهای قول\u200cدهنده را در مقایسه با templه\u200cهای طلا/دستی ساخته می\u200cکند.', 'af': "Dialoog geantwoord generasie modele wat gebruik sjabloon ranking eerder as direkte volgorde generasie toelaat model ontwikkelaars na beperk genereerde reaksies na voorsoekte boodskappe. Maar, die skep van die werkvoorbeeld is tyd- gebruik en benodig domein ekspertiseer. Om hierdie probleem te verminder, ondersoek ons outomaties die proses van skep dialoog sjabloane deur die gebruik van onondersoekte metodes na cluster historiese uitdrukkings en kies reprezentante uitdrukkings van elke cluster. Spesifieke, ons voorstel 'n end- to- end model genoem Deep Sentence Encoder Clustering (DSEC) wat gebruik 'n outo- encoder struktuur om joint die uitdrukking voorstelling te leer en te konstrukteer template clusters. Ons vergelyk hierdie metode met 'n willekeurige basislien wat willekeurig toewys templates na clusters as ook 'n sterk basislien wat die setkodering en die uitdrukking clustering sekwensies uitvoer. Om die prestasie van die voorgestelde metode te evalueer, doen ons 'n outomatiese evaluering met twee annotateerde kliënt diens datastelle om clustering effektiviteit te evalueer, en 'n mens- in- the- loop eksperiment te gebruik met 'n lewende kliënt diens toepassing om die aanvaardingstempo van die genereerde sjablole te maak. DSEC uitvoer die beste in die outomatiese evaluering, slaan beide die sekwensiele en willekeurige basisline op die meeste metries in die mens-in-die-loop-eksperiment, en wys beloftende resultate wanneer vergelyk word met goud/hand geskepe temple.", 'tr': 'Däpli sanlary janlaşdyrma modelleri düzgün hatlary bejermek üçin ön bellenen mesajlara jogaplary çykarmaga rugsat berýär. "%s" faýly açylyp başarmady çünki nusgalary elimden bejermek üçin zaman ahmal we domena ukyplaryny gerek. Bu meseläni azaltmak üçin, biz dialogy nusgalary bejermek üçin janlaşmayan yöntemlerden geçmişi sözlerini çaplamak üçin we her klusterden reprezentan sözlerni saýlamak üçin awtomatik olaryny keşfetýäris Adatça, biz "derin sözleşme kodeçi klustering" (DSEC) adly ahyrlamak üçin bir nusga teklip edip, sözleşme suratyny öwrenmek üçin awtomatik kodeçi yapısını ulanýarys. Biz bu yöntemi görkezilýän rastgelen bir baseçin bilen kelläp görýäris. Bu yöntemi görkezilýän modlere cluster we güýçli bir baseçin derejesine tertibleyär. Önerleven yönteminiň etkinleşigini deňleşdirmek üçin, biz 2 nusgalan müşteriler häsiýeti bilen awtomatik deňlenmek üçin clusterlik etkinleşigini deňleşdirmek üçin, we loop-içinde bir adam testimi ýa şaýan müşteriler häsiýeti ulanyp nusgala hasaplamalaryny ölçürmek üçin etdik. DSEC otomatik deňleşmede gowy bir çykyş edýär, adamlaryň içindeki metrikleriň iň köp bölegi ýagdaýynda täsir edip, we altyn/el döredilýän çykyşlaryň üstüne müsaade eden netijesini görkez.', 'sw': 'Mradi wa uzalishaji wa majibu ya dialogue unaotumia namba yenye rangi ya utaratibu badala ya kizazi cha moja kwa moja unaruhusu watengenezaji wa modeli kupunguza majibu yaliyozaliwa kwa ujumbe uliopitishwa. Hata hivyo, kutengeneza misitu kwa mikononi ni matumizi ya muda na inahitaji utaalam wa ndani. Ili kupunguza tatizo hili, tunachunguza mchakato wa kutengeneza mijadala kwa kutumia mbinu zisizo sahihi kuendeleza hotuba za kihistoria na kuchagua hotuba za uwakilishi kutoka kwa kila mstari. Kwa ujumla, tunapendekeza mtindo wa mwisho unaoitwa Kikundi cha Kufungua Hukumu (DSEC) ambacho kinatumia muundo wa kuweka kwa ajili ya kujifunza kwa pamoja uwakilishi wa hotuba na kujenga viungo vya namba. Tunawalinganisha mbinu hii na mstari wa msingi wa asili ambao kwa kawaida huweka misingi kwa ajili ya viungo na mstari mkali wa msingi unaoendesha ujumbe wa hukumu na hotuba inayohitimisha baadae. Ili kutathmini utendaji wa mbinu zilizopendekezwa, tunafanya uchunguzi wa moja kwa moja kwa moja na seti mbili za huduma za wateja zinazoelezwa ili kutathmini ufanisi mkubwa, na jaribio la wanadamu lililopangwa kwa kutumia tumizi la moja kwa moja la wateja wa huduma za wateja ili kupima kiwango cha kukubaliana kwa namba zilizotengenezwa. DSEC inafanya vizuri zaidi katika uchunguzi wa kujitegemea, anapiga misingi ya msingi wa mfululizo na usio wa kawaida katika mtihani wa mazungumzo ya binadamu, na inaonyesha matokeo yanayoahidi wakati ukilinganishwa na nyumba za dhahabu/zilizotengenezwa kwa mikononi.', 'sq': 'Dialogue response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages.  Megjithatë, krijimi manual i modeleve është i nevojshëm për kohë dhe kërkon ekspertizë në domeni. Për të lehtësuar këtë problem, ne eksplorojmë automatizimin e procesit të krijimit të modeleve të dialogut duke përdorur metoda të pazgjidhura për të grupuar shprehjet historike dhe zgjedhjen e shprehjeve përfaqësuese nga çdo grup. Veçan ërisht, ne propozojmë një model nga fundi në fund të quajtur Deep Sentence Encoder Clustering (DSEC) që përdor një strukturë autokoduese për të mësuar së bashku përfaqësimin e shprehjes dhe për të ndërtuar grupe modelesh. Ne e krahasojmë këtë metodë me një bazë të rastësishme që rastësisht i cakton modelet grupeve si dhe një bazë të fortë që kryen kodimin e fjalëve dhe grupimin e shprehjes sekuencuese. Për të vlerësuar performancën e metodës së propozuar, ne kryejmë një vlerësim automatik me dy grupe të dhënash të shërbimit të klientëve të anotuar për të vlerësuar efektshmërinë e grupimit dhe një eksperiment njerëzor-në-loop duke përdorur një aplikacion të shërbimit të klientëve të gjatë për të matur normën e pranimit të modeleve të gjeneruar. DSEC performs best in the automatic evaluation, beats both the sequential and random baselines on most metrics in the human-in-the-loop experiment, and shows promising results when compared to gold/manually created templates.', 'az': 'Şablon sıralamasını istifadə edən dəstək sıralamasının əvəzini dəstək sıralamasına istifadə edən dəstək cavab verən modellərin əvvəlcə təsdiqlənmiş ismarışlara cavab verməyə imkan verir. Ancaq hüquqları əlində yaratmaq vaxtı istifadə edir və domena təhsil istəyir. Bu problemi yüngülləşdirmək üçün, hər cluster tərəfindən dəstəkli sözləri seçmək üçün müəyyən edilməmiş məsələlər yaratmaq üçün dəyişdirilmiş məsələləri avtomatik olaraq keşif edirik. Özellikle, biz "Deep Sentence Encoder Clustering" (DSEC) adlı sonun-sonun modelini təklif edirik ki, sözlərin göstəricisini öyrənmək və şablon clustersini inşa edər. Biz bu metodları müəyyən vaxtlı səhifələrə və cümlənin kodlamasını və sözlərini seçən qüvvətli səhifələrə götürür. Önülləşdirilmiş metodun təqdirisini değerləşdirmək üçün, biz iki nəzər verilmiş müştəçi servisi veri seti ilə, clustering effektivitətini değerləşdirmək üçün, və canlı müştəçi servisi uyğulamasını istifadə etmək üçün insan-in-loop eksperimenti yaratdığı templlərin qəbul sürətini ölçür. DSEC avtomatik değerlendirmədə ən yaxşı işlər edir, insanların içində-loop eksperimentindəki metriklərin əksəriyyəti ilə hər ikisini və təkrar təkrar təkrar təkrar edir və altın/əl yaratdığı templlərə qarşılaşdığında vəd verən sonuçları göstərir.', 'hy': "Պատասխանների պատասխանների ստեղծման մոդելները, որոնք օգտագործում են մոդելների դասակարգման փոխարեն, քան ուղղակի հաջորդականության ստեղծման, թույլ են տալիս մոդելների զարգացողներին սահմանափակել նախկինում ընդու However, manually creating templates is time-consuming and requires domain expertise.  Այս խնդիրը լուծելու համար մենք ուսումնասիրում ենք, թե ինչպես է ստեղծվում երկխոսային մոդելներ' օգտագործելով անվերահսկված մեթոդներ պատմական արտահայտությունների խմբագրելու և յուրաքանչյուր խմբագրության ներկայացուցիչ արտահայտությունների ընտրության միջոցով: Հատկապես, մենք առաջարկում ենք մի վերջ-վերջ մոդել, որը կոչվում է Deep Sense Encder Cluster (DSCC), որը օգտագործում է ինքնակոդավորման կառուցվածք, որպեսզի միասին սովորի արտահայտությունների ներկայացումը և կառուցվի մոդելներ: Մենք համեմատում ենք այս մեթոդը պատահական հիմքի հետ, որը պատահական ձևեր է տալիս խմբերի վրա, ինչպես նաև ուժեղ հիմքի վրա, որը կատարում է նախադասությունների կոդավորումը և արտահայտությունների խմբավորումը հաջորդաբար: To evaluate the performance of the proposed method, we perform an automatic evaluation with two annotated customer service datasets to assess clustering effectiveness, and a human-in-the-loop experiment using a live customer service application to measure the acceptance rate of the generated templates.  DSCC-ը լավագույնը կատարում է ավտոմատիկ գնահատման մեջ, հաղթահարում է մարդկային փորձի մեծ մասի մետրիկային և պատահական հիմքերը և ցույց է տալիս խոստացնող արդյունքներ՝ համեմատելով ոսկու և ձեռքով ստեղծված մոդելների հետ:", 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s ምንም እንኳን የዶሜን ውይይት ያስፈልጋል፡፡ ይህንን ጉዳይ ለማቅረብ፣ የጦማሪያን መክፈት ማድረጊያውን በመፍጠር እና የታሪካዊ ቃላትን በመጠቀም እና ከሁሉም ጉዳይ የተለየ ቃላትን በመምረጥ የማስተካከል ሥርዓት እናደርጋለን፡፡ በተለየ ጊዜ የጥልቅ የስርዓት ኮድ ኮድ ማቀናጃ (DSEC) የሚባል የፊደል ማቀናጃ ማቀናጃ እና የቃላትን መልዕክት ለመማር እና የጉዳዩ ጉዳይ ጉዳይ መሠረትን ለመግጠም እና ለመግጠም ጥናት እናደርጋለን፡፡ ይህንን ሥርዓት በጭራሽ ክፍተቶችን ለመቆጣጠር እና የጽሑፉን ክፍተት እና ቃላትን ለመፈጸም ኃይለኛ መደገፊያ እና መግለጫን እናስተያየዋለን፡፡ የተዘጋጀውን የሥርዓት ሥርዓት ለማስተዋል፣ የተፈጠረውን የአካባቢ ስብሰባዎችን ለመቀበል በሁለት የአገልግሎት አገልግሎት ዳታዎችን ማረጋገጫ እና በቁጥጥር እና የአካባቢ ግንኙነት ለመጠቀም የሚችሉትን የአካባቢ አገልግሎት ፕሮግራም ለመጠቀም የሚችሉትን የአካባቢ ስርዓት ማድረግ እናደርጋለን፡፡ DSEC በአውሮፓዊ ማውጣት የበለጠ ነው፣ የሰው ማህበረሰብ በሚያስተካክሉ እና በሥርዓት መሠረት ላይ የሚደግፉትን እና የተደላደለውን መሠረት ይደክማል፡፡", 'bn': 'ডায়ালগের প্রতিক্রিয়া প্রজন্মের মডেল যারা সরাসরি সেকেন্স প্রজন্মের পরিবর্তে ট্যাম্পেল রেঙ্কিং ব্যবহার করে মডেল ডেভেলপারে তবে নিজস্ব মন্দির তৈরি করা হচ্ছে সময়-ভক্ষণ এবং ডোমেইনের বিশেষজ্ঞ দরকার। এই সমস্যা কমিয়ে দেওয়ার জন্য, আমরা স্বয়ংক্রিয়ভাবে আলোচনা মন্দির তৈরি করার প্রক্রিয়া খুঁজে বের করি যাতে ঐতিহাসিক ভাষণ উৎপাদন করা এবং প্রতিটি ক্লাস্টা বিশেষ করে আমরা একটি শেষ পর্যন্ত মডেল প্রস্তাব করি যার নাম ডিপ সেন্স এনকোডার ক্লাস্টারিং (ডিসিসি) ব্যবহার করে একটি স্বয়ংক্রিয় এনকোডার কাঠামো ব্যবহার করে যাতে বাক্ আমরা এই পদ্ধতির তুলনা করি একটি অদ্ভুত বেসালাইনের সাথে যা ক্লাস্টারের ক্ষেত্রে মন্দিরগুলোর ক্ষেত্রে নির্ধারণ করে এবং একটি শক্তিশালী বেস্টারেন প্রস্তাবিত পদ্ধতির প্রভাব মূল্য করার জন্য আমরা স্বয়ংক্রিয়ভাবে মূল্য চালিয়ে দিচ্ছি দুটি ব্যবহারকারী ক্যাস্টার সার্ভিসের ডাটাসেটের মাধ্যমে দুটি পরিমাণের মূল্য চাল ডিসিসি স্বয়ংক্রিয়ভাবে মূল্যবোধের মধ্যে সবচেয়ে ভালো কাজ করে, মানুষ-ইন-লুপ-এর পরীক্ষায় বেশীরভাগ মেট্রিক এবং অক্ষরের মেট্রিকে হারিয়ে দেয় এবং তারা প্রতিশ', 'bs': 'Modeli generacije odgovora na dijalogu koji koriste ranking šablona umjesto izravne generacije sekvence omogućavaju razvijačima modela da ograniče generirane odgovore na predodobrene poruke. Međutim, ručno stvaranje šablona je potrošenje vremena i zahtijeva stručnost domena. Da bismo ublažili ovaj problem, istražujemo automatski proces stvaranja hramena dijaloga koristeći neodređene metode za skupljanje povijesnih izraza i izabrati predstavne izraze iz svakog skupa. Posebno, predlažemo model kraja do kraja nazvan klustering dubokog kaznog kodera (DSEC) koji koristi strukturu automatskog kodera kako bi zajedno naučili predstavljanje izraza i konstrukciju klupova šablona. Uspoređujemo ovu metodu sa nasumičnom početnom linijom koja slučajno dodaje šablone skupinama, kao i snažnom početnom linijom koja izvršava kodiranje rečenica i izraz skupine. Da bismo procijenili učinkovitost predložene metode, obavljali smo automatsku procjenu sa dvije oznake podatke o usluzi klijenata kako bi procijenili učinkovitost skusteringa, i eksperiment koji koristi aplikaciju o usluzi živog klijenta za mjerenje stope prihvatanja proizvedenih šablona. DSEC najbolje izvršava u automatskoj procjeni, pobjeđuje i sekvencijalne i nasumične osnovne linije na većini metrika u eksperimentu u ljudskom krugu i pokazuje obećavajuće rezultate u usporedbi sa zlatom/ručno stvorenim šablovima.', 'ca': "Els models de generació de resposta del diàleg que utilitzen la classificació de models en lloc de generació de seqüències directes permeten als desenvolupadors de models limitar les respostes generades als missatges previament aprovads. Però la creació manual de models costa temps i requereix experiència en dominis. Per aliviar aquest problema, explorem l'automatització del procés de creació de models de diàleg utilitzant mètodes no supervisats per agrupar expressions històriques i seleccionant expressions representatives de cada agrupament. Concretament, proposem un model final a final anomenat Deep Sentence Encoder Clustering (DSEC) que utilitza una estructura de codificador automàtic per aprendre conjuntament la representació d'expressions i construir clusters de models. Comparem aquest mètode amb una línia de referència aleatòria que assenya models aleatòriament a grups i una línia de referència forta que fa la codificació de frases i l'agrupament de frases seqüencialment. Per avaluar el rendiment del mètode proposat, fem una avaluació automàtica amb dos conjunts de dades anotats de servei de client per avaluar l'eficacia de la agrupació, i un experiment humà en circuit utilitzant una aplicació de servei de client en directe per mesurar la tasa d'acceptació dels models generats. El DSEC fa el millor en l'evaluació automàtica, bate tant les línies de base seqüencials com aleatòries en la majoria de les mètriques de l'experiment humane en el cicle, i mostra resultats prometedors comparats amb models d'or/creats manualment.", 'cs': 'Modely generování odpovědí dialogu, které používají pořadí šablon namísto přímého generování sekvencí, umožňují vývojářům modelů omezit generované odpovědi na předem schválené zprávy. Ruční vytváření šablon je však časově náročné a vyžaduje odborné znalosti v oblasti domény. Abychom tento problém zmírnili, zkoumáme automatizaci procesu vytváření šablon dialogů pomocí metod bez dohledu shlukování historických výroků a výběr reprezentativních výroků z každého clusteru. Konkrétně navrhujeme komplexní model s názvem Deep Sentence Encoder Clustering (DSEC), který používá strukturu automatického kódování k společnému učení reprezentace výroku a sestavení clusterů šablon. Porovnáme tuto metodu s náhodnou směrnou linií, která náhodně přiřazuje šablony do clusterů, stejně jako se silnou směrnou směrnou linií, která provádí kódování vět a shlukování výroků postupně. Pro vyhodnocení výkonnosti navrhované metody provádíme automatické vyhodnocení se dvěma anotovanými datovými sadami služeb zákazníkům pro posouzení efektivity clusterování a experiment human-in-the-loop pomocí živé aplikace zákaznického servisu pro měření akceptace generovaných šablon. DSEC je nejlepší v automatickém vyhodnocování, porazí sekvenční i náhodné základní linie na většině metrik v experimentu human-in-the-loop a ukazuje slibné výsledky ve srovnání se zlatými/ručně vytvořenými šablonami.', 'et': 'Dialoogivastuste genereerimise mudelid, mis kasutavad mallide järjestust otsese järjestuse genereerimise asemel, võimaldavad mudelite arendajatel piirata loodud vastuseid eelnevalt kinnitatud sõnumitele. Mallide käsitsi loomine on aga aeganõudev ja nõuab domeeniteadmisi. Selle probleemi leevendamiseks uurime dialoogimallide loomise protsessi automatiseerimist, kasutades järelevalveta meetodeid ajalooliste väljendite kogumiseks ja valides igast klastrist esinduslikke väljendeid. Täpsemalt pakume välja lõpp-lõpuni mudeli nimega Deep Sentence Encoder Clustering (DSEC), mis kasutab automaatse kodeerija struktuuri, et ühiselt õppida väljenduse esitust ja luua malliklastrid. Me võrdleme seda meetodit juhusliku lähtejoonega, mis määrab juhuslikult mallid klastritele, samuti tugeva lähtejoonega, mis teeb lause kodeerimist ja väljendite klastrit järjestikuselt. Kavandatud meetodi tulemuslikkuse hindamiseks teostame klastrite efektiivsuse hindamiseks automaatse hindamise kahe märgitud klienditeeninduse andmekogumiga ning loodud mallide aktsepteeritavuse määra mõõtmiseks reaalajas klienditeeninduse rakenduse abil. DSEC toimib automaatses hindamises kõige paremini, ületab enamiku inimese-silmuses eksperimendi mõõdikute järjestikused ja juhuslikud lähtejooned ning näitab paljulubavaid tulemusi võrreldes kuldsete/käsitsi loodud mallidega.', 'fi': 'Dialoogin vastausten luontimallit, joissa käytetään mallien luokittelua suoran sekvenssin luomisen sijaan, sallivat mallikehittäjien rajoittaa luotuja vastauksia ennalta hyväksyttyihin viesteihin. Mallien manuaalinen luominen on kuitenkin aikaa vievää ja vaatii toimialueen asiantuntemusta. Ongelman lievittämiseksi tutkimme dialogimallien luomisen automatisointia käyttämällä valvomattomia menetelmiä historiallisten sanontojen ryhmittämiseen ja valitsemalla edustavia sanontoja kustakin klusterista. Erityisesti ehdotamme päästä päähän -mallia nimeltä Deep Sentence Encoder Clustering (DSEC), joka käyttää automaattista koodausrakennetta oppiakseen yhdessä lauseiden esittämisen ja rakentaakseen malliklustereita. Vertaamme tätä menetelmää satunnaiseen perusaikatauluun, joka satunnaisesti määrittää mallit klustereille, sekä vahvaan perusaikatauluun, joka suorittaa lausekoodauksen ja lauseklusteroinnin järjestyksessä. Ehdotetun menetelmän suorituskyvyn arvioimiseksi suoritamme automaattisen arvioinnin kahdella merkinnällä varustetulla asiakaspalvelutietoaineistolla klusteroinnin tehokkuuden arvioimiseksi ja human-in-the-loop -kokeilun reaaliaikaisella asiakaspalvelusovelluksella luotujen mallien hyväksymisasteen mittaamiseksi. DSEC suoriutuu parhaiten automaattisessa arvioinnissa, päihittää sekä sekvenssiaaliset että satunnaiset perusviivat useimmissa ihmisen silmukassa -kokeessa ja näyttää lupaavia tuloksia verrattuna kultaisiin/käsin luotuihin malleihin.', 'ha': "Salon zaɓen ajiya na zauren zauren akwatin bayanin zauren akwatin bayani da za'a yi amfani da buƙata mai salon da mazaɓa mai sauya ko kuma don ya yarda masu motsi da za'a ƙayyade masu motsi da suka ƙãga tsari wa sunan-gode. A lokacin da za'a ƙiƙira kayan aiki da hannun, yana da amfani da lokaci kuma yana buƙata masu tsari ga Domen. Domin yin sauƙi ga wannan muammãni, Munã yin ƙidãya farat-ɗabi'ar ka samun zauren akwatin zauren akwatin bayani da za'a yi amfani da shiryoyin da ba'a tsare su ba dõmin ya ƙara magana na kihistorian kuma mu zãɓi hotuna na masu bakan bayani daga kõwane clust. A ƙayyade, Munã goyyade wani motsi na ƙari zuwa ƙari wanda ke kiran Kwamfyuta Encodir Cincin (DSC) wanda ke amfani da wani matsayin kode farat ɗaya dõmin ya sanar da shiryarwa na magana da kuma za'a sami komai na salon wata salo. Munã daidaita wannan hanyon zuwa wani layin da ba da ransa ba, wanda ke ƙayyade shi ga masu ƙarfafa da kuma wani salon mai ƙarfi wanda ke cika kodi da maganar ta ƙara bayan. To, idan an ƙaddara cikakken shirin da aka buƙata, za mu iya tafiyar an ƙaddara farat ɗaya da data na tsari biyu na wajen aikin na ɗabi'a, dõmin ka ƙaddara masu amfani da shiryarwa mai ƙaranci, kuma wata jarrabi na mutum cikin-loop don a yi amfani da shirin shiryarwa mai gabatar da shi don ya cika karin sauri na salon da aka ƙãga. DCEC yana aiki mafi kyaun ƙidãyar ta ƙayyade farat ɗaya, yana beati biyu masu bashi na daban da randa, a cikin jarrabin mutum-in-loop, kuma yana nũna fassarar da mai yiwuwa da ke yi wa'adi idan an sammeni da kayan da aka gina shi da hannunsa.", 'jv': 'dialogs-action Name Digawe nggawe bot iki, kita ngubah nambah layang kanggo ngilanggar sampeyan dialog templates sing berarti CURRENTCURRENT Anyone Jejaring "', 'sk': 'Modeli ustvarjanja odzivov v pogovornem oknu, ki uporabljajo razvrščanje predlog namesto neposredne ustvarjanje zaporedja, omogočajo razvijalcem modelov, da omejijo ustvarjene odzive na vnaprej odobrena sporočila. Vendar pa je ročno ustvarjanje predlog zamudno in zahteva strokovno znanje z domeno. Za lajšanje te težave raziskujemo avtomatizacijo procesa ustvarjanja predlog za dialog z uporabo nenadzorovanih metod za združevanje zgodovinskih izgovorov in izbiro reprezentativnih izgovorov iz vsakega grozda. Natančneje predlagamo model od konca do konca imenovan Deep Stance Encoder Clustering (DSEC), ki uporablja strukturo samokodirnika za skupno učenje predstavitve izraza in oblikovanje grozdov predlog. To metodo primerjamo z naključnim osnovnim načrtom, ki naključno dodeljuje predloge skupinam, ter z močnim osnovnim načrtom, ki izvaja kodiranje stavkov in grudiranje izgovorov zaporedno. Za oceno učinkovitosti predlagane metode izvajamo avtomatsko ocenjevanje z dvema označenima naboroma podatkov o storitvi strankam za oceno učinkovitosti grozdov in eksperiment človek-v-zanki z uporabo aplikacije za storitev strankam v živo za merjenje stopnje sprejemljivosti ustvarjenih predlog. DSEC je najboljši pri avtomatičnem ocenjevanju, premaga tako zaporedne kot naključne osnovne črte pri večini meritev v poskusu človeka v zanki in kaže obetavne rezultate v primerjavi z zlatimi/ročno ustvarjenimi predlogami.', 'he': 'דוגמנים של דוגמני גיבוי דיאלוג שמשתמשים בדרגה של דוגמנים במקום בדרגה ישירה מאפשרים לפיתוחים של דוגמנים להגביל את התגובות שנוצרות למסרים מאושרים מראש. עם זאת, יצירת דוגמנים ידנית לוקחת זמן ומדורשת מומחיות בתחום. כדי להקל על הבעיה הזאת, אנו חוקרים את התהליך של יצירת דוגמני דיאלוג על ידי השימוש בשיטות ללא השגחה כדי לקבוע ביטויים היסטוריים ולבחר ביטויים מייצגים מכל קבוצה. Specifically, we propose an end-to-end model called Deep Sentence Encoder Clustering (DSEC) that uses an auto-encoder structure to jointly learn the utterance representation and construct template clusters.  אנחנו משוותים את השיטה הזאת לבסיס אקראי שמסיים באופן אקראי דגמנים לקלאסטרים, כמו גם מבסיס חזק שמבצע את הקוד המשפטים ואת הקוד המאומרים ברציפות. כדי להעריך את ההפעלה של השיטה המוצעת, אנו מבצעים עריכה אוטומטית עם שני קבוצות נתונים שירות לקוחות מוכתבים כדי להעריך יעילות קבוצה, וניסוי אנושי בתוך הלובע בשימוש שירות לקוחות חי כדי למדוד את קצב הקבלה של המדפסים המיוצרים. DSEC מבצע את הערכה האוטומטית הטובה ביותר, מכה את קווי הבסיס הרצועיים והאקראיים ברוב המטריקות בניסיון האנושי-בתוך הלגל, ומראה תוצאות מבטיחות בהשוואה לזהב/דפוסים שנוצרים ידנית.', 'bo': 'Dialog response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages. ཡིན་ནའང་། ལག་བཟོ་ནས་དཔེ་དབྱིབས་གསར་འཛུགས་ནི་དུས་ཚོད་ལས་ཕལ་ཆེན་བྱེད་དགོས་པ To alleviate this problem, we explore the process of creating dialog templates by using unsupervised methods to cluster historical utterances and selecting representative utterances from each cluster. Specifically, we propose an end-to-end model called Deep Sentence Encoder Clustering (DSEC) that uses an auto-encoder structure to jointly learn the utterance representation and construct template clusters. ངེད་ཚོས་ཐབས་ལམ་འདི་ལྟར་མཐའ་མྱུར་བའི་རྨང་གཞིའི་རྩིས་བ་དང་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད། To evaluate the performance of the proposed method, we perform an automatic evaluation with two annotated customer service datasets to assess clustering effectiveness, and a human-in-the-loop experiment using a live customer service application to measure the acceptance rate of the generated templates. DSEC performs best in the automatic evaluation, beats both the sequential and random baselines on most metrics in the human-in-the-loop experiment, and shows promising results when compared to gold/manually created templates.'}
{'en': 'MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines', 'ar': 'MultiWOZ 2.2: مجموعة بيانات حوار مع تصحيحات إضافية للتعليقات التوضيحية وخطوط أساسية لتتبع الحالة', 'es': 'MultiWoz 2.2: Un conjunto de datos de diálogo con correcciones de anotaciones adicionales y líneas de base de seguimiento de estados', 'fr': "MultiWOZ 2.2\xa0: Un jeu de données de dialogue avec des corrections d'annotations supplémentaires et des lignes de base de suivi d'état", 'pt': 'MultiWOZ 2.2: um conjunto de dados de diálogo com correções de anotação adicionais e linhas de base de rastreamento de estado', 'ja': 'MultiWOZ 2.2 ：追加の注釈修正と状態追跡ベースラインを備えたダイアログデータセット', 'zh': 'MultiWOZ 2.2:附注校正与基线对数集', 'hi': 'MultiWOZ 2.2: अतिरिक्त एनोटेशन सुधार और राज्य ट्रैकिंग बेसलाइन के साथ एक संवाद डेटासेट', 'ru': 'MultiWOZ 2.2 : Диалоговый набор данных с дополнительными исправлениями аннотаций и базовыми линиями отслеживания состояния', 'ga': 'MultiWOZ 2.2 : Tacar Sonraí Comhphlé le Ceartúcháin Anótála Breise agus Bunlínte Rianaithe Stáit', 'ka': 'MultiWOZ 2.2 : დიალოგის მონაცემები დამატებითი კონტაქციის რექსირებით და სტატური მონაცემების ბაზი ხაზებით', 'hu': 'MultiWOZ 2.2: Párbeszédadatkészlet kiegészítő jegyzetkövetési javításokkal és állapotkövetési alapokkal', 'el': 'Ένα σύνολο δεδομένων διαλόγου με πρόσθετες διορθώσεις σχολίων και βάσεις παρακολούθησης κατάστασης', 'it': 'MultiWOZ 2.2: un set di dati di dialogo con correzioni aggiuntive di annotazioni e linee di base per il monitoraggio dello stato', 'kk': 'MultiWOZ 2.2 : Қосымша жазбаларды түзету мен күй- жай қадағалау негізгі жолдары бар диалог деректер қоры', 'lt': 'MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines', 'mk': 'МултиВОЗ 2.2 : Папка податоци за дијалог со дополнителни корекции на анотации и бази на државното следење', 'ml': 'MultiWOZ 2. 2 : കൂടുതല്\u200d അറിയിപ്പ് തിരിച്ചറിയുന്നതും രാജ്യത്തെ ട്രാക്കിങ്ങ് ബേസിലിനുകളുമായ ഒരു ഡയലോഗ് ഡേറ്റാസ', 'mt': "MultiWOZ 2.2 : Sett ta' Dejta ta' Djalogu b'Korrezzjonijiet ta' Annotazzjoni Addizzjonali u Linji Bażi ta' Traċċar mill-Istat", 'ms': 'MultiWOZ 2.2 : Satu Set Data Dialog dengan Pembetulan Annotasi Tambahan dan Garis Asas Pengjejak Negara', 'mn': 'MultiWOZ 2.2 : Диалог өгөгдлийн санг нэмэлт нэмэлт нэмэлт загвар болон улс орнуудын дагуулах суурь шугам', 'pl': 'MultiWOZ 2.2: Zestaw danych dialogowych z dodatkowymi korektami adnotacji i bazami śledzenia stanu', 'no': 'MultiWOZ 2.2 : Ein dialogbasert med tilleggskorreksjonar og tilstandskorreksjonar', 'sr': 'MultiWOZ 2.2 : Datata dijaloga sa dodatnim korekcijama Annotacije i osnovnim linijama državnog praćenja', 'ro': 'MultiWOZ 2.2: Un set de date de dialog cu corecții suplimentare de adnotare și linii de referință pentru urmărirea stării', 'si': 'MultiWOZ 2.2 : තවත් කිරීම සහ තත්වය පරීක්ෂණ ප්\u200dරමාණය සඳහා සංවාද දත්ත සංවාද', 'so': 'MultiWOZ 2.2 : A Dialog Dataset with Additional Annotation Corrections and State Tracking Baselines', 'sv': 'MultiWOZ 2.2: Ett dialogdataset med ytterligare noteringskorrigeringar och baslinjer för tillståndsspårning', 'ta': 'MultiWOZ 2. 2 : கூடுதல் அறிவிப்பு திருத்தம் மற்றும் நாடு பின்பற்றி அடிப்படைகளுடன் ஒரு உரையாடல் தகவல் அமைப்பு', 'ur': 'MultiWOZ 2', 'uz': 'MultiWOZ 2. 2 : Qo\xa0Ľshimcha ta\xa0ľrif to\xa0Ľg\xa0Ľriligi va davlat qidirish bazalari bilan muloqat ma\xa0ľlumoti', 'vi': 'Truyền trình đa WOZ 2.2', 'da': 'MultiWOZ 2.2: Et dialogdatasæt med yderligere noteringsrettelser og baselines for tilstandssporing', 'bg': 'Набор от данни на диалоговия диалог с допълнителни корекции на анотацията и базови линии за проследяване на състоянието', 'nl': 'MultiWOZ 2.2: Een dialoogdataset met aanvullende annotatiecorrecties en baselines voor state tracking', 'hr': 'MultiWOZ 2.2 : Datacija dijaloga s dodatnim korekcijama Annotacije i osnovnim linijama državnog praćenja', 'de': 'MultiWOZ 2.2: Ein Dialogdatensatz mit zusätzlichen Anmerkungskorrekturen und Zustandsverfolgungsbasisen', 'id': 'MultiWOZ 2.2 : Satu Set Data Dialog dengan Koreksi Annotasi Tambahan dan garis dasar pelacakan negara', 'ko': 'MultiWOZ 2.2: 추가 주석 수정 및 상태 추적 베이스라인이 있는 대화 데이터 세트', 'fa': 'MultiWOZ 2', 'sw': 'MultiWOZ 2.2 : Taarifa za Dialogue yenye Mabadiliko ya Tamko na Mifumo ya Ufuatiliaji wa Taifa', 'tr': 'MultiWOZ 2.2 : Ekstra duyarlama Düzeltmeleri we Durum Tracking Baselines bilen bir Dialog Maglumaty', 'af': "MultiWOZ 2. 2 :  ' n Dialoog DatabaseComment", 'sq': 'MultiWOZ 2.2 : Një bazë të dhënash dialogu me korreksione shtesë të anotacioneve dhe linjat bazë të ndjekjes shtetërore', 'am': '2', 'hy': 'Բազմազանգվածը 2.2. Առաջական նամակների ուղղությամբ և պետական հետևման հիմքերով', 'az': 'MultiWOZ 2.2 : Əlavə Annotation Corrections və Eyalet Tracking Baselines', 'bn': '২: অতিরিক্ত বিজ্ঞাপন সংশোধন এবং রাষ্ট্রীয় ট্র্যাকিং বৈশিষ্ট্য', 'cs': 'MultiWOZ 2.2: Dialogová sada dat s dalšími korekcemi anotací a základními liniemi sledování stavu', 'bs': 'MultiWOZ 2.2 : Datata dialoga s dodatnim korekcijama Annotacije i osnovnim linijama državnog praćenja', 'et': 'MultiWOZ 2.2: dialoogi andmekogum, mis sisaldab täiendavaid annotatsiooniparandusi ja oleku jälgimise aluseid', 'fi': 'MultiWOZ 2.2: Dialogue Dataset, jossa on lisähuomautuskorjauksia ja tilan seurannan perusaikatauluja', 'ca': "MultiWOZ 2.2: Un conjunt de dades de diàleg amb correccions adicionals d'anotació i línies de base de seguiment estatal", 'sk': 'MultiWOZ 2.2: nabor podatkov v pogovornem oknu z dodatnimi popravki opomb in osnovnimi načrti za sledenje stanju', 'ha': 'KCharselect unicode block name', 'he': 'MultiWOZ', 'jv': 'MultiWOZ 2.2', 'bo': 'MultiWOZ 2.2 : A Dialog Dataset with Additional Annotation Corrections and State Tracking Baselines'}
{'en': 'MultiWOZ is a well-known task-oriented dialogue dataset containing over 10,000 annotated dialogues spanning 8 domains. It is extensively used as a benchmark for dialogue state tracking. However, recent works have reported presence of substantial noise in the dialogue state annotations. MultiWOZ 2.1 identified and fixed many of these erroneous annotations and user utterances, resulting in an improved version of this dataset. This work introduces MultiWOZ 2.2, which is a yet another improved version of this dataset. Firstly, we identify and fix dialogue state annotation errors across 17.3 % of the utterances on top of MultiWOZ 2.1. Secondly, we redefine the ontology by disallowing vocabularies of slots with a large number of possible values (e.g., restaurant name, time of booking). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them. We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work. In the end, we discuss best practices for dialogue data collection that can help avoid annotation errors.', 'ar': 'تعد MultiWOZ مجموعة بيانات حوار موجهة نحو المهام معروفة وتحتوي على أكثر من 10000 حوار مشروح تغطي 8 مجالات. يتم استخدامه على نطاق واسع كمعيار لتتبع حالة الحوار. ومع ذلك ، فقد أبلغت الأعمال الأخيرة عن وجود ضوضاء كبيرة في شروح حالة الحوار. حدد MultiWOZ 2.1 وأصلح العديد من هذه التعليقات التوضيحية الخاطئة وأقوال المستخدم ، مما أدى إلى نسخة محسنة من مجموعة البيانات هذه. يقدم هذا العمل MultiWOZ 2.2 ، وهو نسخة محسنة أخرى من مجموعة البيانات هذه. أولاً ، نحدد أخطاء التعليقات التوضيحية لحالة الحوار ونصلحها عبر 17.3٪ من الكلمات المنطوقة أعلى الإصدار 2.1 من MultiWOZ. ثانيًا ، نعيد تعريف الأنطولوجيا من خلال عدم السماح بمفردات الخانات الزمنية التي تحتوي على عدد كبير من القيم الممكنة (على سبيل المثال ، اسم المطعم ، ووقت الحجز). بالإضافة إلى ذلك ، نقدم التعليقات التوضيحية لمدى الفتحات لهذه الفتحات لتوحيدها عبر النماذج الحديثة ، والتي استخدمت سابقًا أساليب الاستدلال في مطابقة السلسلة المخصصة لإنشاءها. نقوم أيضًا بقياس عدد قليل من نماذج تتبع حالة الحوار الحديثة على مجموعة البيانات المصححة لتسهيل المقارنة للعمل المستقبلي. في النهاية ، نناقش أفضل الممارسات لجمع بيانات الحوار التي يمكن أن تساعد في تجنب أخطاء التعليقات التوضيحية.', 'pt': 'O MultiWOZ é um conhecido conjunto de dados de diálogo orientado a tarefas que contém mais de 10.000 diálogos anotados abrangendo 8 domínios. É amplamente usado como referência para rastreamento de estado de diálogo. No entanto, trabalhos recentes relataram presença de ruído substancial nas anotações do estado de diálogo. O MultiWOZ 2.1 identificou e corrigiu muitas dessas anotações errôneas e declarações do usuário, resultando em uma versão aprimorada desse conjunto de dados. Este trabalho apresenta o MultiWOZ 2.2, que é mais uma versão aprimorada deste conjunto de dados. Em primeiro lugar, identificamos e corrigimos erros de anotação de estado de diálogo em 17,3% dos enunciados no MultiWOZ 2.1. Em segundo lugar, redefinimos a ontologia desautorizando vocabulários de slots com um grande número de valores possíveis (por exemplo, nome do restaurante, horário da reserva). Além disso, introduzimos anotações de intervalo de slot para esses slots para padronizá-los em modelos recentes, que anteriormente usavam heurísticas de correspondência de string personalizadas para gerá-los. Também comparamos alguns modelos de rastreamento de estado de diálogo de última geração no conjunto de dados corrigido para facilitar a comparação para trabalhos futuros. No final, discutimos as melhores práticas para coleta de dados de diálogo que podem ajudar a evitar erros de anotação.', 'es': 'MultiWoz es un conocido conjunto de datos de diálogos orientados a tareas que contiene más de 10 000 diálogos anotados que abarcan 8 dominios. Se utiliza ampliamente como punto de referencia para el seguimiento del estado del diálogo. Sin embargo, trabajos recientes han reportado la presencia de ruido sustancial en las anotaciones de estado de diálogo. MultiWoz 2.1 identificó y corrigió muchas de estas anotaciones y enunciados de usuario erróneos, lo que dio como resultado una versión mejorada de este conjunto de datos. Este trabajo presenta MultiWoz 2.2, que es otra versión mejorada de este conjunto de datos. En primer lugar, identificamos y arreglamos errores de anotación de estado de diálogo en el 17,3% de los enunciados además de MultiWoz 2.1. En segundo lugar, redefinimos la ontología al no permitir vocabularios de espacios con un gran número de valores posibles (por ejemplo, nombre del restaurante, hora de reserva). Además, introducimos anotaciones de intervalo de ranuras para estas ranuras para estandarizarlas en los modelos recientes, que anteriormente utilizaban heurística de coincidencia de cadenas personalizada para generarlas. También comparamos algunos modelos de seguimiento del estado del diálogo de última generación en el conjunto de datos corregido para facilitar la comparación para el trabajo futuro. Al final, discutimos las mejores prácticas para la recopilación de datos de diálogo que pueden ayudar a evitar errores de anotación.', 'fr': "MultiWOZ est un jeu de données de dialogue orienté tâches bien connu contenant plus de 10 000 dialogues annotés couvrant 8 domaines. Il est largement utilisé comme référence pour le suivi de l'état du dialogue. Cependant, des travaux récents ont signalé la présence d'un bruit important dans les annotations d'état de dialogue. MultiWOZ 2.1 a identifié et corrigé bon nombre de ces annotations et énoncés utilisateur erronés, ce qui a permis d'améliorer la version de ce jeu de données. Ce travail présente MultiWoz 2.2, qui est une autre version améliorée de ce jeu de données. Tout d'abord, nous identifions et corrigeons les erreurs d'annotation d'état de dialogue dans 17,3\xa0% des énoncés en plus de MultiWOZ 2.1. Deuxièmement, nous redéfinissons l'ontologie en interdisant les vocabulaires des créneaux comportant un grand nombre de valeurs possibles (par exemple, le nom du restaurant, l'heure de la réservation). En outre, nous introduisons des annotations de plage d'emplacements pour ces emplacements afin de les standardiser dans les modèles récents, qui utilisaient auparavant des heuristiques de correspondance de chaînes personnalisées pour les générer. Nous comparons également quelques modèles de suivi d'état de dialogue de pointe sur l'ensemble de données corrigé afin de faciliter la comparaison pour les travaux futurs. À la fin, nous discutons des meilleures pratiques pour la collecte de données de dialogue qui peuvent aider à éviter les erreurs d'annotation.", 'ja': 'MultiWOZは、8つのドメインにわたる10,000以上の注釈付きダイアログを含む、よく知られたタスク指向のダイアログデータセットです。 対話状態追跡のベンチマークとして広く使用されている。 しかしながら、近年の著作では対話状態の注釈に実質的なノイズが存在することが報告されている。 MultiWOZ 2.1は、これらの誤った注釈やユーザーの発言の多くを特定し、修正し、このデータセットの改良版をもたらしました。 この作品では、このデータセットのもう一つの改良版であるMultiWOZ 2.2を紹介しています。 まず、MultiWOZ 2.1の上にある発話の17.3%にわたるダイアログの状態の注釈エラーを特定して修正します。 第二に、多数の可能な値（レストラン名、予約時刻など）を持つスロットのボキャブラリを許可しないことで、オントロジーを再定義します。 さらに、これらのスロットのスパン注釈を導入して、最近のモデル間で標準化しています。これらのモデルでは、以前にカスタム文字列マッチングヒューリスティックを使用してそれらを生成していました。 また、修正されたデータセット上のいくつかの最先端の対話状態追跡モデルをベンチマークして、将来の作業の比較を容易にします。 最後に、注釈エラーを回避するのに役立つ対話データ収集のベストプラクティスについて説明します。', 'zh': 'MultiWOZ 者,众所周知对数集,包越 8 个域之 10,000 多所注释。 博以为言。 然近作告说,多所噪音注。 MultiWOZ 2.1 多所识修,多所阙用户,改入此集本。 引入MultiWOZ 2.2,此别改本也。 先识MultiWOZ 2.1而修17.3%语。 其次禁有大可直(,餐厅名,预订时)之插槽词汇以复其体。 又为引入槽跨度注,以近模标准化之,前用自定义字符串匹配启发式法以成之。 校正后数集上面试最先进之语,以较未来之事。 最后,我将对话数据收集的最佳,可以助助免注误。', 'ru': 'MultiWOZ - это хорошо известный набор данных для диалога, ориентированного на решение конкретных задач, содержащий более 10 000 аннотированных диалогов, охватывающих 8 доменов. Он широко используется в качестве эталона для отслеживания состояния диалога. Тем не менее, недавние работы сообщили о наличии существенного шума в аннотациях состояния диалога. MultiWOZ 2.1 выявил и исправил многие из этих ошибочных аннотаций и высказываний пользователей, что привело к улучшению версии этого набора данных. Эта работа представляет MultiWOZ 2.2, который является еще одной улучшенной версией этого набора данных. Во-первых, мы выявляем и исправляем ошибки аннотации состояния диалога в 17,3% высказываний поверх MultiWOZ 2.1. Во-вторых, мы переопределяем онтологию, запрещая использование словарей слотов с большим количеством возможных значений (например, название ресторана, время бронирования). Кроме того, мы вводим аннотации интервала слотов для этих слотов, чтобы стандартизировать их среди последних моделей, которые ранее использовали пользовательскую эвристику сопоставления строк для их генерации. Мы также сравниваем несколько современных диалоговых моделей отслеживания состояния с исправленным набором данных, чтобы облегчить сравнение для будущей работы. В итоге мы обсуждаем передовые методы сбора данных для диалога, которые помогут избежать ошибок в аннотациях.', 'hi': 'MultiWOZ एक प्रसिद्ध कार्य-उन्मुख संवाद डेटासेट है जिसमें 8 डोमेन में फैले 10,000 से अधिक एनोटेट संवाद शामिल हैं। यह बड़े पैमाने पर संवाद राज्य ट्रैकिंग के लिए एक बेंचमार्क के रूप में उपयोग किया जाता है। हालांकि, हाल के कार्यों ने संवाद राज्य एनोटेशन में पर्याप्त शोर की उपस्थिति की सूचना दी है। MultiWOZ 2.1 ने इन गलत एनोटेशन और उपयोगकर्ता कथनों में से कई की पहचान की और तय किया, जिसके परिणामस्वरूप इस डेटासेट का एक बेहतर संस्करण हुआ। यह काम MultiWOZ 2.2 का परिचय देता है, जो इस डेटासेट का एक और बेहतर संस्करण है। सबसे पहले, हम पहचान करते हैं और MultiWOZ 2.1 के शीर्ष पर कथन के 17.3% भर में संवाद राज्य एनोटेशन त्रुटियों को ठीक. दूसरे, हम बड़ी संख्या में संभावित मूल्यों (जैसे, रेस्तरां का नाम, बुकिंग का समय) के साथ स्लॉट की शब्दावली को अस्वीकार करके आंटोलॉजी को फिर से परिभाषित करते हैं। इसके अलावा, हम हाल के मॉडलों में उन्हें मानकीकृत करने के लिए इन स्लॉट के लिए स्लॉट स्पैन एनोटेशन पेश करते हैं, जो पहले उन्हें उत्पन्न करने के लिए कस्टम स्ट्रिंग मिलान ह्यूरिस्टिक्स का उपयोग करते थे। हम भविष्य के काम के लिए तुलना की सुविधा के लिए सही डेटासेट पर कला संवाद राज्य ट्रैकिंग मॉडल के कुछ राज्य को भी बेंचमार्क करते हैं। अंत में, हम संवाद डेटा संग्रह के लिए सर्वोत्तम प्रथाओं पर चर्चा करते हैं जो एनोटेशन त्रुटियों से बचने में मदद कर सकते हैं।', 'ga': "Is tacar sonraí comhphlé tasc-dhírithe aitheanta é MultiWOZ ina bhfuil níos mó ná 10,000 dialóg anótáilte thar 8 bhfearann. Úsáidtear go forleathan é mar thagarmharc do rianú stáit idirphlé. Mar sin féin, thuairiscigh saothair a rinneadh le déanaí go raibh torann suntasach i nótaí stáit an chomhphlé. D’aithin agus shocraigh MultiWOZ 2.1 go leor de na nótaí earráideacha seo agus nathanna cainte úsáideoirí, rud a d’fhág gur cuireadh leagan feabhsaithe den tacar sonraí seo ar fáil. Tugann an obair seo isteach MultiWOZ 2.2, atá ina leagan feabhsaithe eile den tacar sonraí seo. Ar an gcéad dul síos, déanaimid earráidí anótála stáit idirphlé a shainaithint agus a shocrú thar 17.3% de na cainteanna ar bharr MultiWOZ 2.1. Ar an dara dul síos, déanaimid an ontology a ath-shainmhíniú trí stór focal sliotán a bhfuil líon mór luachanna féideartha acu a dhícheadú (m.sh., ainm bialainne, am áirithinte). Ina theannta sin, tugaimid isteach nótaí réise sliotán do na sliotáin seo chun iad a chaighdeánú trasna samhlacha le déanaí, a d'úsáid heuristicí meaitseála teaghrán saincheaptha chun iad a ghiniúint. Déanaimid tagarmharcáil freisin ar roinnt samhlacha rianaithe staid an chomhphlé den scoth ar an tacar sonraí ceartaithe chun comparáid a éascú le haghaidh oibre amach anseo. Sa deireadh, pléifimid na cleachtais is fearr maidir le bailiú sonraí idirphlé ar féidir leo cabhrú le hearráidí nótaí a sheachaint.", 'ka': 'MultiWOZ არის უცნობიერი დავალების მონაცემები დიალოგის მონაცემები, რომელიც უფრო 10 000 მონაცემებული დიალოგიების დიალოგია, რომელიც 8 დომენის გადატანა. ეს დიალოგის სტატის შენახვედისთვის გამოყენება. მაგრამ, ახალი სამუშაო სამუშაო სამუშაო სიტყვების შესახებ დიალოგის სამუშაო ნიოტაციებში. MultiWOZ 2.1 იდენტიფიკაცია და განსაზღვრება ამ შეცდომა ანოტაციების და მომხმარებელი სიტყვების მრავალი, რომელიც შემდეგ ამ მონაცემების გაუკეთებული ვერსია. ეს სამუშაო multiWOZ 2. 2 იყენებს, რომელიც ამ მონაცემების სხვა უფრო მეტი გაუქმებული ვერსია. პირველი, ჩვენ განვიცნობით და დავაკეთებთ დიალოგის სტატუსის შეცდომები 17.3% მრავალური 2.1- ზე. მეორე, ჩვენ განვიცნობით ანტოლოგია პროგრამის სიტყვებულების შესაძლებელი რაოდენიმე მნიშვნელობით (მაგალითად, რესტორანტის სახელი, ბუკერების დრო). დამატებით, ჩვენ შევცვალოთ სტროტის სპენტიკური ანოტაციები ამ სტროტებისთვის, რომ ისინი სტანდარტიკურებთ ახალი მოდელში, რომელიც წინ გამოიყენეთ სტრიქტური სტრიქტიკის ჩვენ ასევე კონფიგურაცით სურათის დიალოგის სტატის მოდელეების შენახვა მოდელეების შესაძლებლობად მომხმარებული მონაცემების კონფიგურაციას. საბოლოოდ, ჩვენ განსაკუთრებით უკეთესი პრაქტიკები დიალოგის მონაცემების კოლექციისთვის, რომელიც შეგვიძლია დახმარება შეცდომილებები', 'el': 'Το MultiWOZ είναι ένα γνωστό σύνολο δεδομένων διαλόγου προσανατολισμένο στην εργασία που περιέχει πάνω από 10.000 σχολιασμένους διαλόγους που καλύπτουν οκτώ τομείς. Χρησιμοποιείται εκτενώς ως σημείο αναφοράς για την παρακολούθηση κατάστασης διαλόγου. Ωστόσο, πρόσφατα έργα έχουν αναφέρει την παρουσία σημαντικού θορύβου στις σημειώσεις κατάστασης διαλόγου. Το MultiWOZ 2.1 αναγνώρισε και διόρθωσε πολλές από αυτές τις λανθασμένες σχολιάσεις και δηλώσεις χρηστών, με αποτέλεσμα μια βελτιωμένη έκδοση αυτού του συνόλου δεδομένων. Αυτή η εργασία εισάγει το MultiWOZ 2.2, το οποίο είναι μια ακόμη βελτιωμένη έκδοση αυτού του συνόλου δεδομένων. Πρώτον, εντοπίζουμε και διορθώνουμε σφάλματα σχολιασμού κατάστασης διαλόγου σε 17.3% από τις δηλώσεις πάνω από το MultiWOZ 2.1. Δεύτερον, επαναπροσδιορίζουμε την οντολογία με την απαγόρευση λεξιλογίων κουλοχέρηδων με μεγάλο αριθμό πιθανών τιμών (π.χ. όνομα εστιατορίου, ώρα κράτησης). Επιπλέον, εισάγουμε σχολιασμούς εύρους αυλακώσεων για αυτές τις αυλακώσεις για να τις τυποποιήσουμε σε πρόσφατα μοντέλα, τα οποία προηγουμένως χρησιμοποιούσαν προσαρμοσμένες συμβολοσειρές αντιστοίχισης heuristics για να τις παραγάγουν. Επίσης, αξιολογούμε ορισμένα μοντέλα παρακολούθησης κατάστασης διαλόγου τελευταίας τεχνολογίας στο διορθωμένο σύνολο δεδομένων για να διευκολύνουμε τη σύγκριση για μελλοντικές εργασίες. Στο τέλος, συζητάμε τις βέλτιστες πρακτικές για τη συλλογή δεδομένων διαλόγου που μπορούν να βοηθήσουν στην αποφυγή σφαλμάτων σχολιασμού.', 'hu': 'A MultiWOZ egy jól ismert feladatorientált párbeszédadatkészlet, amely több mint 10.000 jegyzetelt párbeszédet tartalmaz 8 tartományban. Széles körben használják referenciaértékként a párbeszéd állapotának nyomon követéséhez. A legutóbbi munkák azonban jelentős zaj jelenlétéről számoltak be a párbeszédállapot jegyzeteiben. A MultiWOZ 2.1 azonosította és javította ezeket a hibás megjegyzéseket és felhasználói kimondásokat, ami az adatkészlet jobb verzióját eredményezte. Ez a munka bemutatja a MultiWOZ 2.2-t, amely ennek az adatkészletnek a további továbbfejlesztett verziója. Először is azonosítjuk és javítjuk a párbeszédállapot jegyzékeinek hibáit a MultiWOZ 2.1-en felül a kijelentések 17,3%-ában. Másodszor újrafogalmazzuk az ontológiát azáltal, hogy nem engedélyezzük a nagyszámú lehetséges értékkel (pl. étterem neve, foglalás időpontja). Ezenkívül bemutatjuk ezekhez a résekhez a résekhez a résekhez tartozó tartomány-megjegyzéseket, hogy szabványosítsuk őket a legutóbbi modellekhez, amelyek korábban egyéni karakterlánc-megfelelő heurisztikát használtak. Továbbá összehasonlítunk néhány korszerű párbeszéd állapotkövető modellt a korrigált adatkészleten, hogy megkönnyítsük az összehasonlítást a jövőbeli munkákhoz. Végül megvitatjuk a párbeszédadatgyűjtésre vonatkozó bevált gyakorlatokat, amelyek segítenek elkerülni a jegyzetelési hibákat.', 'lt': 'MultiWOZ is a well-known task-oriented dialogue dataset containing over 10,000 annotated dialogues spanning 8 domains.  Jis plačiai naudojamas kaip dialogo būklės stebėjimo lyginamasis taškas. Vis dėlto neseniai atliktuose darbuose buvo pranešta, kad dialogo būsenos anotacijose buvo didelis triukšmas. MultiWOZ 2.1 nustatė ir nustatė daugelį šių klaidingų anotacijų ir naudotojo išraiškų, todėl pagerėjo šio duomenų rinkinio versija. Šiame darbe įvedamas MultiWOZ 2.2, kuris yra dar viena patobulinta šio duomenų rinkinio versija. Pirma, identifikuojame ir ištaisome dialogo valstybės anotacijų klaidas 17,3 proc. išreiškimų virš MultiWOZ 2.1. Antra, iš naujo apibrėžiame ontologiją uždraudžiant laiko tarpsnių žodynus, turinčius daug galimų vertybių (pvz., restorano pavadinimas, užsakymo laikas). Be to, mes įvedame laiko tarpsnių intervalo anotacijas šiems laiko tarpsniams standartizuoti pagal naujausius modelius, kurie anksčiau juos gamino naudojo pritaikytas juostas atitinkančias heuristikas. Taip pat vertiname keletą pažangiausių dialogo valstybių stebėjimo modelių, susijusių su pataisytais duomenų rinkiniais, kad būtų lengviau palyginti būsimus darbus. Galiausiai diskutuojame apie geriausią dialogo duomenų rinkimo praktiką, kuri gali padėti išvengti anotacijos klaidų.', 'it': "MultiWOZ è un noto set di dati di dialogo orientato alle attività contenente oltre 10.000 dialoghi annotati che coprono 8 domini. È ampiamente usato come punto di riferimento per il monitoraggio dello stato di dialogo. Tuttavia, lavori recenti hanno segnalato la presenza di notevole rumore nelle annotazioni dello stato di dialogo. MultiWOZ 2.1 ha identificato e corretto molte di queste annotazioni errate e dichiarazioni degli utenti, con conseguente miglioramento della versione di questo set di dati. Questo lavoro introduce MultiWOZ 2.2, che è un'altra versione migliorata di questo set di dati. In primo luogo, identifichiamo e risolviamo gli errori di annotazione dello stato di dialogo sul 17,3% delle dichiarazioni in cima a MultiWOZ 2.1. In secondo luogo, ridefiniamo l'ontologia rifiutando vocabolari di slot con un gran numero di valori possibili (ad esempio, nome del ristorante, ora della prenotazione). Inoltre, introduciamo annotazioni di span slot per questi slot per standardizzarli su modelli recenti, che in precedenza utilizzavano euristiche personalizzate di corrispondenza delle stringhe per generarli. Confrontiamo anche alcuni modelli di monitoraggio dello stato di dialogo all'avanguardia sul set di dati corretti per facilitare il confronto per il lavoro futuro. Alla fine, discutiamo le migliori pratiche per la raccolta dei dati di dialogo che possono aiutare a evitare errori di annotazione.", 'mk': 'МултиWOZ е познат дијалог ориентиран кон задачите со податоци кој содржи повеќе од 10.000 анотирани дијалози кои опфатуваат 8 домени. Истата е екстремно употребена како референтна точка за следење на состојбата на дијалогот. Сепак, неодамнешните дела објавија присуство на значителна бучава во анотациите во состојбата на дијалогот. МултиWOZ 2.1 идентификуваше и фиксираше многу од овие грешни анотации и изрази на корисникот, што резултираше со подобрена верзија на овој датотек. Оваа работа претставува МултиВОЗ 2. 2, која е уште една подобрена верзија на овој датотек. Прво, идентификуваме и поправиме грешки во анатацијата на состојбата на дијалогот во 17,3 отсто од изразите врз МултиВОЗ 2.1. Второ, ја редефинираме онтологијата со одбивање на речниците со голем број можни вредности (на пример, името на ресторанот, време на резервирање). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them.  We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work.  На крајот, разговараме за најдобрите практики за собирање на дијалог податоци кои може да помогнат да се избегнат грешки во анотацијата.', 'kk': 'Көптеген WOZ - 8 доменге ауыстырылған 10 000 артық белгіленген диалог диалогының білетін диалог жиыны. Диалог күйін қадағалау үшін қолданылады. Бірақ соңғы жұмыстар диалог күйінің белгілерінде маңызды дыбыс болуын хабарлады. Көп WOZ 2. 1 бұл қате жазбаларды және пайдаланушылардың сөзін анықталды және анықталды. Бұл деректер жиының жақсы нұсқасы болады. Бұл жұмыс бірнеше жақсы деректер жиынының көптеген нұсқасын көрсетеді. Біріншіден, біз көпшілікті 2. 1- нің үстіндегі сөздердің 17. 3% деген диалог жазбаларының қатесін анықтап, түземіз. Екіншіден, слоттардың сөздерін көп санды (мысалы, ресторантың атауы, бетбелгінің уақыты) арқылы онтологияны қайта анықтаймыз. Қосымша, бұл слоттар үшін слоттардың жаңа үлгілерді стандарттау үшін слоттардың кеңістіктерін келтіреміз. Бұларды құру үшін өзінің геуристикасына сәйкес келетін жолдарды қолданған. Сонымен қатар, келесі жұмыс үшін салыстыру үшін, өзгертілген деректер жиынының күйін қадағалау моделдерінің бірнеше күйін белгілеп тастаймыз. Соңғы соңында бұл диалог деректерді жинақтау үшін ең жақсы әрекеттерді талқылаймыз. Бұл жазбалардың қатесінен шығу мүмкін.', 'ml': 'MultiWOZ ഒരു നല്ല ജോലി- തിരിച്ചറിയപ്പെട്ട ഡയലോഗ് ഡാറ്റാസെറ്റാണ്. അതില്\u200d 10,000 കൂടുതല്\u200d അപരിചിതമായ ഡയലോഗുകളുണ്ട്. 8 ഡൊമെനെന്\u200d ഡയലോഗ് സ്റ്റേറ്റ് ട്രാക്ക് ചെയ്യുന്നതിനുള്ള ബെന്\u200dച്മാര്\u200dക്ക് വിശാലമായി അത് ഉപയോഗിക്കു എന്നാലും അടുത്ത പ്രവര്\u200dത്തനങ്ങള്\u200d സംസാരിക്കുന്ന സംസാരത്തില്\u200d വലിയ ശബ്ദം ഉണ്ടെന്ന് റിപ്പോര്\u200dട്ട് ചെയ ഇത്തരം തെറ്റായ വാക്കുകളും ഉപയോക്താവിന്റെ വാക്കുകളും തിരിച്ചറിയുകയും ചെയ്തു. ഈ ഡാറ്റാസറ്റിന്റെ മെച്ചപ്പെട്ട പതിപ്പ്  ഈ പ്രവര്\u200dത്തിക്കുന്നത് MultiWOZ 2. 2 എന്ന് പരിചയപ്പെടുത്തുന്നു. അത് ഇപ്പോഴും ഈ ഡാറ്റാസറ്റിന്റെ മറ്റൊരു മെച്ച Firstly, we identify and fix dialogue state annotation errors across 17.3% of the utterances on top of MultiWOZ 2.1.  രണ്ടാമതായി, സ്ലോട്ടുകളുടെ വാക്കുകള്\u200d നിഷിദ്ധമാക്കുന്നതിനാല്\u200d നമ്മള്\u200d നിര്\u200dണ്ണയിക്കുന്നത് വീണ്ടും വിവരിക്കുന്നു. ഒരുപാട് സാധ് കൂടാതെ, ഈ സ്ലോട്ടുകള്\u200dക്ക് വേണ്ടി സ്പാന്\u200d അഭിപ്രായങ്ങള്\u200d പരിചയപ്പെടുത്തുന്നു. അവയെ അടുത്ത മോഡലുകളിലൂടെ സ്ഥാപിക്കുന്നതിനായി  ഭാവിയുടെ ജോലിക്ക് തുല്യമാക്കുന്നതിന് ഞങ്ങള്\u200d തുല്യമാക്കുവാന്\u200d സാധ്യതയുള്ള ഡാറ്റാസറ്റ് ട്രാക്കിങ്ങ് മോഡല അവസാനം നമ്മള്\u200d സംസാരിക്കുന്നത് ഡയലോഗ് ഡേറ്റാ സംഘത്തിനായി ഏറ്റവും നല്ല പ്രവര്\u200dത്തനങ്ങള്\u200d സംസാരിക്കുന്നു.', 'ms': 'MultiWOZ adalah set data dialog orientasi tugas yang diketahui yang mengandungi lebih dari 10,000 dialog annotasi yang meliputi 8 domain. Ia digunakan secara luas sebagai tanda referensi untuk pengesan keadaan dialog. Namun, kerja-kerja baru-baru ini telah melaporkan kehadiran bunyi yang besar dalam anotasi keadaan dialog. MultiWOZ 2.1 mengenalpasti dan menetapkan banyak anotasi dan ucapan pengguna yang salah ini, yang menghasilkan versi yang lebih baik bagi set data ini. Kerja ini memperkenalkan MultiWOZ 2.2, yang merupakan versi yang lebih baik bagi set data ini. Pertama, kita mengenalpasti dan memperbaiki ralat anotasi keadaan dialog melalui 17.3% ucapan di atas MultiWOZ 2.1. Kedua, kita menentukan semula ontologi dengan menolak vocabulari slot dengan bilangan besar nilai yang mungkin (contohnya nama restoran, masa untuk memesan). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them.  Kami juga benchmark beberapa model pengesan keadaan dialog seni pada set data yang betul untuk memudahkan perbandingan untuk kerja masa depan. Pada akhirnya, kita membincangkan praktek terbaik untuk koleksi data dialog yang boleh membantu menghindari ralat anotasi.', 'mt': "MultiWOZ is a well-known task-oriented dialogue dataset containing over 10,000 annotated dialogues spanning 8 domains.  Jintuża b’mod estensiv bħala punt ta’ riferiment għat-traċċar tal-istat tad-djalogu. Madankollu, xogħlijiet reċenti rrappurtaw preżenza ta’ storbju sostanzjali fl-annotazzjonijiet tal-istat tad-djalogu. MultiWOZ 2.1 identifika u ffissat ħafna minn dawn l-annotazzjonijiet żbaljati u dikjarazzjonijiet tal-utent, li rriżultaw f’verżjoni mtejba ta’ dan is-sett ta’ dejta. Dan ix-xogħol jintroduċi MultiWOZ 2.2, verżjoni mtejba oħra ta’ dan is-sett ta’ dejta. L-ewwel nett, nidentifikaw u nilqgħu l-iżbalji fl-annotazzjoni tal-istat fid-djalogu fuq 17.3% tal-espressjonijiet fuq MultiWOZ 2.1. It-tieni nett, niddefinixxu mill-ġdid l-ontoloġija billi niċħdu l-vokabulariji tas-slots b’g ħadd kbir ta’ valuri possibbli (pereżempju l-isem tar-ristorant, il-ħin tal-prenotazzjoni). Barra minn hekk, aħna nintroduċu annotazzjonijiet tal-firxa tas-slots għal dawn is-slots biex jiġu standardizzati fil-mudelli reċenti, li qabel użaw ġewristiċi personalizzati li jaqblu mal-istrejn biex jiġġenerawhom. Nirreferu wkoll ftit mudelli ta' segwitu tal-istat tal-a ħħar djalogu dwar is-sett ta' dejta kkoreġut biex jiġi ffaċilitat it-tqabbil għal xogħol futur. Fl-aħħar nett, niddiskutu l-aħjar prattiki għall-ġbir tad-dejta tad-djalogu li jistgħu jgħinu jevitaw żbalji fl-annotazzjoni.", 'mn': 'Олон WOZ гэдэг нь 8 салбарын түвшинд 10,000 гаруй анзаарсан диалог өгөгдлийн сан юм. Энэ нь диалог байр суурь дагах үед банкмарк болгон ашиглагддаг. Гэвч саяхан ажиллагаанууд диалогийн байр суурь чимээгүй байдлыг харуулсан. MultiWOZ 2.1 нь эдгээр алдаа буруу анзааралтуудыг, хэрэглэгчийн илтгэлийг тодорхойлдог. Тэгээд энэ өгөгдлийн сангийн сайжруулсан хувилбар болсон. Энэ ажил MultiWOZ 2.2-г танилцуулдаг. Энэ нь өгөгдлийн сангийн өөр сайжруулсан хувилбар юм. Эхлээд бид диалогын байр сууриллагын алдааны 17.3% нь MultiWOZ 2.1-ийн дээд байгаа хэлэлцээний талаар тодорхойлдог. Хоёрдугаарт, слотын үг хэлэхэд олон тоо боломжтой (жишээлбэл, рестораны нэр, номын цаг) болон онтологийг дахин тодорхойлдог. Түүнчлэн, бид энэ слотуудын сүүлийн загварууд дээр стандартизацийг ашиглаж байгаа слотын хэмжээний загваруудыг танилцуулж байна. Энэ нь өмнө нь хюристик боловсруулахын тулд хувийн стринг ашиглаж байсан. Мөн бид ирээдүйн ажлын харьцуулалтын тулд зөв өгөгдлийн хэмжээ дээр урлагийн диалогын хэд хэдэн байр суурь загварын дагуулах загварыг багтана. Эцэст нь бид мэдээллийн цуглуулалтын сайн дасгал дасгал дээр талаар ярилцдаг.', 'no': 'MultiWOZ er eit kjent oppgåveorientert dialogoppsett som inneheld over 10 000 oppmerkingsdialogar med 8 domene. Det vert utvida brukt som ein benchmark for dialogtilstand. I dialogtilstand-notasjonane har det siste arbeidet meldt at det er støy. MultiWOZ 2. 1 identifisert og fiks mange av desse feil notasjonane og brukarstalene, som fører til eit forbetra versjon av denne dataset. Dette arbeidet introduserer fleire WOZ 2. 2, som er enno eit anna forbetra versjon av denne datasettet. Først identifiserer vi og retter opp dialogoppmerkingsfeilar over 17,3% av uttalene øvre på MultiWOZ 2.1. Sekundært definerer vi ontologien på nytt ved å slå av ordlister på plasser med stor mange moglege verdiar (f.eks. restaurantnamn, tid for bokering). I tillegg introduserer vi plasseringsnotasjonar for disse plassene for å standardisere dei over nyleg modeller, som tidlegare bruka sjølvvald streng som passar med heuristikk for å laga dei. Vi benchmarkerer også ein par tilstandar i verktøydialogvindauget for sporingsmodeller på den korrigerte datasettet for å letta samanlikning for framtidige arbeid. I slutten diskuterer vi best praksis for samlinga av dialogvindauget som kan hjelpa til å unngå oppmerkingsfeilar.', 'pl': 'MultiWOZ to znany zestaw danych dialogowych zorientowanych na zadania zawierający ponad 10.000 adnotacje dialogowe obejmujące 8-domeny. Jest on szeroko stosowany jako punkt odniesienia do śledzenia stanu dialogu. Jednakże w ostatnich pracach odnotowano obecność znacznego hałasu w adnotacjach stanu dialogu. MultiWOZ 2.1 zidentyfikował i naprawił wiele z tych błędnych adnotacji i wypowiedzi użytkowników, co skutkowało ulepszoną wersją tego zbioru danych. W niniejszej pracy wprowadzono MultiWOZ 2.2, który jest kolejną ulepszoną wersją tego zbioru danych. Po pierwsze, identyfikujemy i naprawiamy błędy adnotacji stanu dialogu w 17,3% wypowiedzi na górze MultiWOZ 2.1. Po drugie, ponownie definiujemy ontologię poprzez uniemożliwienie słowników slotów o dużej liczbie możliwych wartości (np. nazwa restauracji, czas rezerwacji). Ponadto wprowadzamy adnotacje rozpiętości slotów dla tych slotów, aby ujednolicić je w najnowszych modelach, które wcześniej używały niestandardowych heurystyk dopasowywania ciągów do ich generowania. Porównujemy również kilka najnowocześniejszych modeli śledzenia stanu dialogu na skorygowanym zbiorze danych, aby ułatwić porównanie dla przyszłych prac. W końcu omówimy najlepsze praktyki gromadzenia danych dialogowych, które mogą pomóc uniknąć błędów adnotacji.', 'ro': 'MultiWOZ este un set de date bine cunoscut de dialog orientat spre sarcini, care conține peste 10.000 de dialoguri adnotate, cuprinzând 8 domenii. Este utilizat pe scară largă ca reper pentru urmărirea stării dialogului. Cu toate acestea, lucrările recente au raportat prezența unui zgomot substanțial în adnotările de stat de dialog. MultiWOZ 2.1 a identificat și a reparat multe dintre aceste adnotări eronate și pronunțări ale utilizatorilor, rezultând o versiune îmbunătățită a acestui set de date. Această lucrare introduce MultiWOZ 2.2, care este o altă versiune îmbunătățită a acestui set de date. În primul rând, identificăm și remediem erorile de adnotare a stării dialogului pe 17,3% din cuvintele de deasupra MultiWOZ 2.1. În al doilea rând, redefinim ontologia prin interzicerea vocabularelor sloturilor cu un număr mare de valori posibile (de exemplu, numele restaurantului, ora rezervării). În plus, introducem adnotări pentru intervalul sloturilor pentru aceste sloturi pentru a le standardiza în modelele recente, care au folosit anterior euristice personalizate pentru a le genera. De asemenea, analizăm câteva modele de urmărire a stărilor de dialog de ultimă oră pe setul de date corectat pentru a facilita compararea pentru lucrările viitoare. În cele din urmă, discutăm cele mai bune practici pentru colectarea datelor de dialog care pot ajuta la evitarea erorilor de adnotare.', 'sr': 'MultiWOZ je poznat dizajn podataka sa orijentacijom na zadatke koji sadrži preko 10.000 annotiranih dijaloga koje šire 8 domena. To se široko koristi kao kongres za praćenje stanja dijaloga. Međutim, nedavni radovi su prijavili prisustvo značajne buke u navodima države dijaloga. MultiWOZ 2.1 je identifikovao i popravio mnoge pogrešne annotacije i izraze korisnika, što je rezultiralo poboljšanoj verziji ovog seta podataka. Ovaj rad predstavlja MultiWOZ 2.2, što je još jedna poboljšana verzija ovog seta podataka. Prvo, identifikujemo i popravimo greške državne annotacije dijaloga preko 17,3% reči na vrhu MultiWOZ 2.1. Drugo, predefinišemo ontologiju odbacivanjem rečnika slota sa velikim brojem mogućih vrijednosti (npr. ime restorana, vrijeme rezervacije). Osim toga, predstavljamo annotacije za slot spajanje za te slote kako bi ih standardizovali u skorijim modelima, koje su prethodno koristile obične žice odgovarajuće heurističkim metodama kako bi ih stvorili. Takoðe smo povezali nekoliko stanja umetničkog dijaloga modela praćenja država za umetnički dijalog na ispravnom setu podataka kako bi olakšali usporedbu za budući rad. Na kraju, razgovaramo o najboljoj praksi za kolekciju dijalogskih podataka koja može pomoæi da izbegne greške annotacije.', 'so': 'MultiWOZ waa qoraal ku qoran shaqo oo ku qoran 10,000 oo ka badan dialogues oo ku qoran 8 domain. Waxaa si ballan ah loogu isticmaalaa sida bangiga booqashada dowladda. However, recent works have reported presence of substantial noise in the dialogue state annotations.  WOZ 2.1 ayaa aqoonsaday oo hagaajiyey hadalladaas oo badan oo khalad ah iyo hadalladan isticmaalayaasha, waxaana sababtay warqad kordhisan sawiradan. Shaqadan wuxuu soo bandhigayaa MultiWOZ 2.2, kaas oo weli ah warqad kale oo la hagaajiyey sawiradan. Marka ugu horeysa, waxaynu aqoonsanaynaa oo hagaynaa dhibaatooyin ku saabsan dowladda wax dhibaatada ah oo ka soo baxaya 17.3% hadalka dusha ah ee MultiWOZ 2.1. Second, waxaynu dib u sawirannaa nidaamka si aan u diidno waxyaabaha ay leeyihiin qiimaha badan oo suurtagal ah (tusaale ahaan magaca restaurantu, xilliga booking). Intaas waxaa dheer oo aan u soo bandhignaynaa qalabkan si aan ugu soo bandhignayno tusaalooyin dhowaad, taasoo horay u isticmaalay xadhig caadi ah oo u eg heuristis. Sidoo kale waxaynu soo bandhignaynaa noocyada qoraalka farshaxanka ee dowladda ah oo ku qoran samooyinka saxda macluumaadka si loo fududeeyo isbarbardhigga shaqada mustaqbalka. Ugu dambaysta, waxaynu ka sheekeynaynaa habab ugu wanaagsan ee la soo ururiyo macluumaad, kaas oo kaa caawinaya in uu ka fogaado qaladyada dhibaatada.', 'sv': 'MultiWOZ är ett välkänt uppgiftsorienterat dialogdataset som innehåller över 10 000 kommenterade dialoger över 8 domäner. Den används i stor utsträckning som riktmärke för spårning av dialogtillstånd. De senaste verken har dock rapporterat förekomst av betydande buller i kommentarerna i dialogtillståndet. MultiWOZ 2.1 identifierade och rättade många av dessa felaktiga kommentarer och användaruttalanden, vilket resulterade i en förbättrad version av denna datauppsättning. Detta arbete introducerar MultiWOZ 2.2, som är ännu en förbättrad version av denna dataset. För det första identifierar och åtgärdar vi kommenteringsfel i dialogtillstånd över 17,3% av yttrandena ovanpå MultiWOZ 2.1. För det andra omdefinierar vi ontologin genom att inte tillåta ordlistor för slots med ett stort antal möjliga värden (t.ex. restaurangens namn, bokningstid). Dessutom introducerar vi spår span annotationer för dessa slots för att standardisera dem över de senaste modellerna, som tidigare använde anpassade sträng matchande heuristik för att generera dem. Vi jämför även några toppmoderna dialogstatusspårningsmodeller på den korrigerade datauppsättningen för att underlätta jämförelser för framtida arbete. I slutändan diskuterar vi bästa praxis för insamling av dialogdata som kan hjälpa till att undvika anteckningsfel.', 'si': 'MultiWOZ හොඳටම දන්නේ වැඩක් ප්\u200dරමාණය සංවාදය දත්ත සංවාදයක් 10,000 වඩා ප්\u200dරමාණය කළ සංවාදය 8 වැඩියි. ඒක සංවාද ස්ථානය පරීක්ෂණය සඳහා බෙන්චමාර්ක් විදිහට භාවිත වෙනවා. නමුත්, අලුත් වැඩක් සංවාදයේ ස්ථානයේ සංවාදයේ විශාල ශබ්දයක් තියෙනවා. MultiWOZ 2.1 මේ වැරදි කිරීම සහ ප්\u200dරයෝජක කිරීමේ වැරදි කිරීම සඳහා මේ දත්ත සංවිධානයේ වැඩි සංවිධානයක් තියෙනවා සහ මේ වැඩේ MultiWOZ 2. 2 වෙනුවෙන්, ඒක තවත් මේ දත්ත සෙට්ටුවේ වැඩි වැඩි වැඩි සංවිධානයක්. මුලින්ම, අපි සංවාද දැනගන්න සහ සංවාද දැනගන්න පුළුවන් 17.3% විතරයි MultiWOZ 2.1 වලින් කියලා දෙවෙනි විදියට, අපි පුළුවන් විශාල විශාලාවක් සමඟ ප්\u200dරතිශ්න විශාලාවක් නැති කරලා පුළුවන් විශාල විශාලාවක් අ ඒ වගේම, අපි මේ ස්ලෝට්ස්ට් ස්පැන් නිර්දේශනය කරනවා මේ ස්ලෝට්ස්ටාන් එක්ක මොඩේල්ස් එක්ක ස්ටැන්ඩාන්ඩායිස් කරන්න, මුලි අපි සමහරවිට විද්\u200dයාත්මක සංවාදයේ කිසිම ස්ථිතියක් බෙන්ච්මාර්ක් කරනවා අනාගතය වැඩේ සඳහා සුරකුණු දත්ත අවසානයෙන්, අපි සංවාද දත්ත සංගීතයට හොඳ ප්\u200dරයෝජනය කතා කරන්න පුළුවන් සංවාද දත්ත සංගීතයෙන්', 'ta': 'பல்WOZ ஒரு நன்றாக அறியப்பட்ட பணி திசைக்கப்பட்ட உரையாடல் தகவல் அமைப்பு 10,000 க்கு மேற்பட்ட அறிவிக்கப்பட்ட உரையாடல் 8 டொமைன்கள் உள்ளத உரையாடல் நிலையை பின்பற்றுவதற்கு இது விரிவாக உபயோகிக்கப்படுகிறது. ஆனால், சமீபத்தில் செயல்கள் உரையாடல் நிலையில் பெரிய சப்தங்கள் இருப்பதை அறிவித்துள்ளார்கள். MultiWOZ 2. 1 இந்த பிழையான குறிப்புகள் மற்றும் பயனர் வார்த்தைகளை கண்டுபிடிக்கப்பட்டு சரிபார்த்தது, இந்த தரவுத்தளத்தின் மேம்பட This work introduces MultiWOZ 2. 2, which is yet another improved version of this dataset. முதலில், நாம் உரையாடல் நிலை அறிவிப்பு பிழைகளை கண்டுபிடிக்க மற்றும் சரிசெய்கிறோம் மேல் பல்WOZ 2. 1 வார்த்தைகளில் 17. 3%  இரண்டாம், நாம் சாத்தியமான மதிப்புகளை தடை செய்த சொல்லகங்களை மீண்டும் வரையறுக்கிறோம் (உதாரணமாக, நீராட்டு பெயர், புத்தக நேரம்) மேலும், நாம் இந்த செருகுவாய்ப்பு ஸ்பான் குறிப்புகளை அறிவிக்கிறோம் அண்மையில் தற்போதைய மாதிரிகளில் நிலைபெறுவதற்கு, இது முன We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work.  முடிவில், நாம் பேச்சு தகவல் தொகுப்பிற்கான சிறந்த செயல்களை விவாதம் செய்கிறோம். அது அறிவிப்பு பிழைகளை தவ', 'ur': 'MultiWOZ ایک معلوم کام-oriented ڈائیلوسٹ ہے جو 10,000 سے زیادہ اظہار کئے ہوئے ڈائیلوسٹ ہیں۔ یہ ڈالیٹ استٹراک کے لئے بینچم مارک کے طور پر استعمال کیا جاتا ہے. لیکن اچھے کاموں نے ڈالیٹ ایٹیٹ نوٹیزوں میں بہت بڑی آواز کی موجودگی بتائی ہے۔ MultiWOZ 2.1 یہ بہت سی غلطی یادہانی اور کارساز کلمات کو پہچان لیا اور ثابت کردیا، اور اس ڈیٹ سٹ کے بہترین نسخہ میں ثابت ہوا۔ یہ کام MultiWOZ 2.2 کو معلوم کرتا ہے، جو اس ڈیٹ سٹ کی ایک دوسری بہترین نسخہ ہے۔ پہلی بار، ہم تعریف کریں اور تعریف کریں گے کہ مثالی WOZ 2.1 کے اوپر کلمات کی 17.3% کے درمیان ڈیلوٹ ایٹیٹ انٹیٹ کی خطائیں ہیں. دوسرا، ہم اسلوٹ کے کلمات کو بہت سے ممکن ارزش کے ساتھ منع کرنے کے ذریعہ اس آنٹلوژی کو دوبارہ تفصیل دیتے ہیں۔ اس کے علاوہ، ہم نے ان سلوٹوں کے لئے اسلٹ اسپانیٹ اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا معلوم کیا ہے کہ ان کو اچھے موڈل کے ساتھ استاندارڈ کریں، جو پہلے ان کے پیدا کرنے کے لئے مطابق سٹرینگ ہم نے اچھے کام کے لئے مقایسہ کرنے کے لئے آرام کرنے کے لئے اچھے کام کے لئے مقایسہ کرنے کے لئے آسانی کرنے کے لئے آسانی کے لئے آسانی کرنے کے لئے آرتی ڈیٹ ڈیٹ سٹ کے ٹراکینگ موڈل کے چند موقعیت کو بھی بنچ آخر میں، ہم ڈالیٹ کالکٹ کے لئے بہترین عملیات کی بحث کرتے ہیں جو انٹیٹ خطاوں سے بچنے کی مدد کرسکتے ہیں.', 'uz': "MultiWOZ - 8 domen boʻyicha muloqat muloqat muloqat muloqat maʼlumoti maʼlumotlar tarkibi. It is extensively used as a benchmark for dialogue state tracking.  Lekin, yaqinda ishlar dialog davlatda juda katta yozuvlar mavjudligini hisoblash mumkin. @ info: status Bu ishni MultiWOZ 2. 2 ishlatiladi. Bu maʼlumot setning boshqa yaxshi versiyasi. Birinchisi, biz muloqat taʼminlovchi holatni aniqlash va taʼminlovchi xatolarni ko'rsamiz MultiWOZ 2.1 yuqoridagi so'zlarning 17.3% ko'pchiligi. Ikkinchi so'zda, biz sonlarning vositalarni qanchalik qiymatlar bilan qo'shish uchun ontologiyani qayta qayta yaratimiz (masalan, restaurant nomi, kitob soati). Ko'pchilik, bu slot span taʼminlovlarini ishlatib chiqaramiz. Yaqinda ishlab chiqarish uchun ularni andozalash uchun boshqa shakllar bilan ishlatiladi. Biz bir necha holat haqida muloqat muloqat oynasi taʼminlovchi modellarini saqlash uchun kelajak ishga tenglashni foydalanishimiz mumkin. Tugashida, muloqat maʼlumot toʻplami uchun eng yaxshi narsalarni javob beramiz. Bu taʼminlovchi xatolarni olib tashlash mumkin.", 'vi': "Đa WOZ là một tập tin được biết về một nhiệm vụ được biết có chứa hơn mười,000 được ghi chú các ca-bin nằm trong khu vực 8. Nó được sử dụng rộng rãi như tiêu chuẩn để theo dõi tình trạng đối thoại. Những tác phẩm gần đây cho thấy có tiếng ồn lớn trong biên bản ghi chú trạng thái đối thoại. Nhiều ghi chú sai lầm và giọng người dùng đã được xác định. Kết quả là phiên bản của bộ dữ liệu này đã được cải tiến. Việc này giới thiệu MulWOZ 2.2, còn là một phiên bản cải tiến khác của bộ dữ liệu này. Đầu tiên, chúng tôi xác định và sửa lỗi ghi chú trong ghi chú đối thoại trong phạm vi 17.3='của những phát âm trên Đỉnh của multiWOZ 2.1. Thứ hai, chúng tôi định nghĩa lại ngành khảo cổ bằng cách không cho sắp xếp các tập quán thời gian với nhiều giá trị có thể (v.d. tên nhà hàng, giờ đặt phòng). Thêm vào đó, chúng tôi giới thiệu chú thích thời gian cho những khe cửa này để tiêu chuẩn chúng qua những mẫu mới, mà trước đây đã dùng dây tương ứng thần kinh để tạo ra chúng. Chúng tôi cũng tiêu điểm một số mẫu thời đại của cuộc đối thoại nghệ thuật trên bộ dữ liệu đã sửa chữa để dễ so sánh cho công việc tương lai. Cuối cùng, chúng ta thảo luận về cách thức tốt nhất để thu thập dữ liệu đối thoại có thể giúp tránh lỗi ghi chú.", 'nl': 'MultiWOZ is een bekende taakgerichte dialoogdataset met meer dan 10.000 geannoteerde dialoogvensters over acht domeinen. Het wordt veel gebruikt als benchmark voor het bijhouden van dialoogstatus. Recente werken hebben echter gemeld dat er sprake is van aanzienlijke ruis in de annotaties van de dialoogtoestand. MultiWOZ 2.1 identificeerde en herstelde veel van deze foutieve annotaties en gebruikersuitingen, wat resulteerde in een verbeterde versie van deze dataset. Dit werk introduceert MultiWOZ 2.2, een nieuwe verbeterde versie van deze dataset. Ten eerste identificeren en verhelpen we annotatiefouten in dialoogstaten over 17,3% van de uitspraken bovenop MultiWOZ 2.1. Ten tweede herdefiniëren we de ontologie door woordenboeken van slots met een groot aantal mogelijke waarden (bijvoorbeeld restaurantnaam, tijdstip van boeking) uit te sluiten. Daarnaast introduceren we slotspan annotaties voor deze slots om ze te standaardiseren in recente modellen, die eerder aangepaste string matching heuristics gebruikten om ze te genereren. We benchmarken ook enkele state of the art dialogstate tracking modellen op de gecorrigeerde dataset om vergelijking voor toekomstig werk te vergemakkelijken. Uiteindelijk bespreken we best practices voor het verzamelen van dialooggegevens die kunnen helpen annotatiefouten te voorkomen.', 'da': 'MultiWOZ er et velkendt opgaveorienteret dialogdatasæt, der indeholder over 10.000 kommenterede dialoger, der spænder over 8 domæner. Det bruges i vid udstrækning som benchmark for dialog stat tracking. De seneste værker har imidlertid rapporteret om tilstedeværelse af betydelig støj i dialogstatens annotationer. MultiWOZ 2.1 identificerede og rettede mange af disse fejlagtige annotationer og brugerudtalelser, hvilket resulterede i en forbedret version af dette datasæt. Dette arbejde introducerer MultiWOZ 2.2, som er endnu en forbedret version af dette datasæt. For det første identificerer og retter vi fejl i dialogtilstanden på tværs af 17,3% af udtalelserne oven på MultiWOZ 2.1. For det andet omdefinerer vi ontologien ved at afvise ordforråd for slots med et stort antal mulige værdier (f.eks. restaurantens navn, reservationstidspunkt). Derudover introducerer vi slots span annotationer for disse slots for at standardisere dem på tværs af nyere modeller, som tidligere brugte brugerdefinerede strengmatchende heuristik til at generere dem. Vi sammenligner også et par state-of-the-art dialog state tracking modeller på det korrigerede datasæt for at lette sammenligning til fremtidige arbejde. I sidste ende diskuterer vi bedste praksis for indsamling af dialogdata, der kan hjælpe med at undgå annoteringsfejl.', 'bg': 'MultiWOZ е добре известен набор от данни от диалогови диалози, ориентирани към задачите, съдържащ над 10 000 анотирани диалогови диалога, обхващащи 8 домейна. Той се използва широко като еталон за проследяване на състоянието на диалога. Въпреки това, последните произведения съобщават за наличие на значителен шум в анотациите на състоянието на диалога. МултиWOZ 2.1 идентифицира и коригира много от тези погрешни анотации и потребителски изказвания, което води до подобрена версия на този набор от данни. Тази работа представя МултиWOZ 2.2, която е още една подобрена версия на този набор от данни. Първо, идентифицираме и коригираме грешки в анотацията на състоянието на диалога в 17,3% от изказванията отгоре на МултиWOZ 2.1. На второ място, предефинираме онтологията, като забраняваме речниците на слотове с голям брой възможни стойности (напр. име на ресторант, време на резервация). В допълнение, въвеждаме анотации за интервала на слотове за тези слотове, за да ги стандартизираме в последните модели, които преди това използваха персонализирани хевристики за съвпадение на низове, за да ги генерират. Също така сравняваме няколко модела за проследяване на състоянието на диалога върху коригирания набор от данни, за да улесним сравняването за бъдеща работа. В крайна сметка обсъждаме най-добрите практики за събиране на данни в диалога, които могат да помогнат за избягване на грешки в анотацията.', 'hr': 'MultiWOZ je poznat sastav podataka o dijalogu s orijentacijom na zadatke koji sadrži preko 10.000 annotiranih dijaloga koje šire 8 domena. To se široko koristi kao kongres za praćenje stanja dijaloga. Međutim, nedavni radovi prijavili su prisustvo značajne buke u državnim navodima dijaloga. MultiWOZ 2.1 je identificirao i popravio mnoge od tih pogrešnih annotacija i proglaska korisnika, što je rezultiralo poboljšanoj verziji ovog seta podataka. Ovaj rad predstavlja MultiWOZ 2.2, što je još jedna poboljšana verzija ovog seta podataka. Prvo, identificiramo i popravimo greške u javnoj annotaciji dijaloga preko 17,3% izraza na vrhu MultiWOZ 2.1. Drugo, predefiniramo ontologiju odbacivanjem rečnika slota velikim brojem mogućih vrijednosti (npr. ime restorana, vrijeme rezervacije). Osim toga, predstavljamo annotacije za vrijeme slota za te mjesta kako bi ih standardizirali u nedavnim modelima, koje su prethodno koristile obične žice odgovarajuće heurističkim mjerama kako bi ih stvorili. Također smo navodili i nekoliko stanja umjetničkog dijaloga modela praćenja država za praćenje ispravnih podataka kako bi olakšali usporedbu za budući rad. Na kraju, razgovaramo o najboljoj praksi za kolekciju dijalogskih podataka koja može pomoći izbjegavati greške annotacije.', 'de': 'MultiWOZ ist ein bekannter aufgabenorientierter Dialogdatensatz, der über 10.000 annotierte Dialoge über acht Domänen enthält. Es wird häufig als Benchmark für die Verfolgung von Dialogzuständen verwendet. Neuere Arbeiten berichten jedoch von erheblichem Rauschen in den Anmerkungen zum Dialogzustand. MultiWOZ 2.1 identifizierte und korrigierte viele dieser fehlerhaften Anmerkungen und Benutzeräußerungen, was zu einer verbesserten Version dieses Datensatzes führte. Diese Arbeit stellt MultiWOZ 2.2 vor, eine weitere verbesserte Version dieses Datensatzes. Zunächst identifizieren und beheben wir Annotationsfehler im Dialog über 17,3% der Äußerungen auf MultiWOZ 2.1. Zweitens definieren wir die Ontologie neu, indem wir Vokabulare von Slots mit einer großen Anzahl möglicher Werte (z.B. Restaurantname, Buchungszeit) ablehnen. Darüber hinaus führen wir Slot-Spann-Anmerkungen für diese Slots ein, um sie in aktuellen Modellen zu standardisieren, die zuvor benutzerdefinierte String-Matching-Heuristiken verwendet haben, um sie zu generieren. Wir benchmarken auch einige State-of-the-Art Dialogstatus-Tracking-Modelle auf dem korrigierten Datensatz, um den Vergleich für zukünftige Arbeiten zu erleichtern. Am Ende diskutieren wir Best Practices für die Erfassung von Dialogdaten, die helfen können, Annotationsfehler zu vermeiden.', 'id': 'MultiWOZ adalah set data dialog orientasi tugas yang terkenal yang mengandung lebih dari 10.000 dialog annotasi yang meliputi 8 domain. Ini digunakan secara ekstensif sebagai benchmark untuk pelacakan keadaan dialog. Namun, pekerjaan-pekerjaan baru-baru ini telah melaporkan kehadiran suara besar dalam annotasi negara dialog. MultiWOZ 2.1 mengidentifikasikan dan memperbaiki banyak anotasi yang salah dan ucapan pengguna ini, yang menyebabkan versi yang lebih baik dari set data ini. Pekerjaan ini memperkenalkan MultiWOZ 2.2, yang merupakan versi yang lebih baik dari set data ini. Pertama, kita mengidentifikasi dan memperbaiki kesalahan anotasi negara dialog melalui 17,3% dari ucapan di atas MultiWOZ 2.1. Kedua, kita mendefinisikan ulang ontologi dengan menolak vocabulari slots dengan jumlah besar nilai yang mungkin (contohnya nama restoran, waktu memesan). Selain itu, kami memperkenalkan anotasi slot span untuk slots ini untuk standardisasi mereka melalui model baru-baru ini, yang sebelumnya menggunakan string suai yang cocok heuristik untuk menghasilkannya. Kami juga benchmark beberapa model state-of-the-art dialog state tracking model pada set data yang diperbaiki untuk memudahkan perbandingan untuk pekerjaan masa depan. Akhirnya, kita mendiskusikan praktek terbaik untuk koleksi data dialog yang dapat membantu menghindari kesalahan anotasi.', 'ko': 'MultiWOZ는 임무를 위한 유명한 대화 데이터 집합으로 8개 구역에 10000개가 넘는 주석이 달린 대화를 포함한다.그것은 대화 상태 추적의 기준으로 광범위하게 사용된다.그러나 최근 연구에 따르면 대화 상태 주석에는 대량의 소음이 존재한다.MultiWOZ 2.1은 많은 잘못된 주석과 사용자 언어를 식별하고 수정하여 이 데이터 집합의 버전을 개선시켰다.이 작업은 MultiWOZ 2.2를 도입하여 데이터 세트의 또 다른 개선 버전입니다.먼저, MultiWOZ 2.1을 토대로 17.3%의 대화 상태 주석 오류를 식별하고 수정했습니다.그 다음에 우리는 본체를 새롭게 정의했고 가능한 값(예를 들어 식당 이름, 예약 시간)이 많은 플러그인 어휘를 허용하지 않았다.또한 최근 모델에서 이를 표준화하기 위해 이 플러그인들을 위한 플러그인 경계 주석을 도입했습니다. 이 모델들은 이전에 사용자 정의 문자열 일치 탐색법을 사용하여 그것들을 생성했습니다.우리는 또한 수정된 데이터 집합의 일부 가장 선진적인 대화 상태 추적 모델에 대해 기준 테스트를 실시하여 장래의 업무를 비교하기 편리하도록 했다.마지막으로 우리는 대화 데이터 수집의 가장 좋은 실천에 대해 토론했는데 이것은 주석 오류를 피하는 데 도움이 된다.', 'fa': 'MultiWOZ یک مجموعه داده\u200cهای محاورۀ مشخص\u200cشده\u200cای است که بیش از ۱۰۰۰۰ محاورۀ مشخص شده\u200cاند که ۸ دامنه\u200cها را طول می\u200cکشد. آن به طور وسیع به عنوان نشانه\u200cای برای ردیابی وضعیت محاورش استفاده می\u200cشود. ولی کارهای اخیر گزارش داده\u200cاند که در توضیح\u200cهای ایالت گفتگو در حضور صدای زیادی باشد. MultiWOZ 2.1 بسیاری از این نوشته\u200cهای اشتباهی و گفته\u200cهای کاربر را شناسایی کردند و تعمیر کردند، به نتیجه نسخه\u200cای از این مجموعه داده\u200cها بهتر شد. این کار MultiWOZ 2.2 را معرفی می\u200cکند که هنوز نسخه\u200cی این مجموعه\u200cی داده\u200cها بهتر شده است. اول، ما خطاهای اظهار ایالت دیalog را در ۱۷.۳ درصد سخنرانی بر بالای MultiWOZ 2.1 شناسایی می کنیم و درست می کنیم. دوم، ما توسط اجازه دادن واژه\u200cهای صفحه\u200cها با تعداد زیادی از ارزش\u200cهای ممکن (مثال اسم رستوران، زمان ذخیره\u200cسازی) آن\u200cتونلوژی را دوباره تعریف می\u200cکنیم. علاوه بر این، ما توضیح\u200cهای منطقه\u200cای برای این نقطه\u200cها را معرفی می\u200cکنیم تا آنها را در مدل\u200cهای اخیر استاندارد کنیم، که قبلاً از این استفاده از نقطه\u200cهای منطقه\u200cای که مسابقه\u200cای با هوریستیک برای ایجاد آنها می\u200cکنند ما همچنین یک مقدار از مدل ردیابی ایالت دیalog هنری را در مجموعه داده\u200cهای درست برای آسانی مقایسه برای کار آینده نشان می\u200cدهیم. در نهایت، ما در مورد عملیات بهترین برای مجموعه داده\u200cهای محاورش صحبت می\u200cکنیم که می\u200cتواند کمک کند از اشتباه\u200cهای یادآوری فرار کند.', 'sw': 'MultiWOZ ni seti ya takwimu za mazungumzo yenye maarufu ya majadiliano yenye zaidi ya mazungumzo 10,000 yanayozungumzia maeneo 8. Inatumiwa kwa kiasi kikubwa kama benchmark for tracking state of dialogue. Hata hivyo, kazi za hivi karibuni zimewashiria kuwepo kwa kelele kubwa katika matatizo ya hali ya mjadala. MultiWOZ 2.1 ilitambuliwa na kurekebisha matamko mengi haya yanayokosea na hotuba za watumiaji, na kusababisha toleo lililobadilika la seti hii ya taarifa. Kazi hii inaonyesha MultiWOZ 2.2, ambayo ni toleo jingine lililoboreshwa na seti hii ya taarifa. Kwanza, tunagundua na kurekebisha makosa ya matangazo ya mazungumzo ya nchi kwa asilimia 17.3 ya maneno juu ya MultiWOZ 2.1. Pili, tunaelezea upya utafiti huo kwa kuzuia maneno ya mistari yenye thamani kubwa inayowezekana (kwa mfano, jina la mgahawa, wakati wa kuandika). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them.  Pia tunaweka hatua chache za mazungumzo ya sanaa ya ufuatiliaji wa mifano ya ufuatiliaji wa taarifa sahihi ili kuwezesha kulinganisha kwa kazi za baadaye. Mwisho, tunajadili mazingira bora kwa ajili ya kukusanya taarifa za mazungumzo ambayo inaweza kusaidia kuepuka makosa ya uchunguzi.', 'tr': "Çoklu WOZ 8 rakam zolaky içinde bilinen täblisaň görnöşikli dýaloglardyr Bu dýalog durum izlemek üçin elipbi pozylýar Ýöne soňky eserler durum duýgularynda gaty gürrüň bardygyny aýdylar. MultiWOZ 2 Bu işe MultiWOZ 2.2'i tanyşdyrýar. Bu data düzümleriniň entäk gelişmiş bir wersiýasy. Ilkinji gezek, MultiWOZ 2.1 üstündeki sözleriniň 17.3% üstündeki durum ýazgytlaryny tanap we çözeriz. Ikinjisi, ýerlerde bolan sözlerini birnäçe möhüm mykdarlar bilen ýene-de taýýarlap, ontologiýany (meselâ, restoran ady, rezervasyň wagty). Biz bu ýerler üçin slot kalamlary tanyşdyrýarys, oňki nusgalar bilen tanyşdyrmak üçin bu ýerler üçin slot kalamlary tanyşdyrýarys. Biz hem sanat dialogynyň birnäçe durumyny düzeldi veri setirinde gözlemek nusgalaryny gelejek işiň karşılaşygyny a ňsat etmek üçin gurlaýarys. Soňunda, sözleşme hatalaryndan çykyp biljek dijalog ýygnamasynyň iň gowy praktika we gürrüň edýäris.", 'af': "MultiWOZ is 'n goed bekende taak- orienteerde dialoog datastel bevat meer 10 000 annotateerde dialoog wat 8 domeine spandeer. Dit is uitbreidig gebruik as 'n benchmark vir dialoog staat agtervolg. Maar onlangse werke het die aangesig van groot ruis in die dialoog staatsnotasies verkondig. MultiWOZ 2. 1 geïdentifiseer en vasgestel baie van hierdie foute notasies en gebruikeruitdrukkings, wat resultaat in 'n verbeterde weergawe van hierdie datastel. Hierdie werk introduseer MultiWOZ 2. 2, wat is 'n nog 'n verbeterde weergawe van hierdie datastel. Eerste, ons identifiseer en herstel dialoog staat annotasie foute oor 17. 3% van die uitspraak bo van MultiWOZ 2. 1. Tweede, ons redefineer die ontologie deur die toegelaat van woordeboeke van slots met 'n groot aantal moontlike waardes (bv. restaurantnaam, tyd van boek). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them. Ons het ook 'n paar staat van die kuns dialoog staat agtervolg modele op die korrigeerde datastel om vergelyking vir toekomstige werk te maak. In die einde, ons bespreek die beste praksies vir dialoog data versameling wat kan help om annotasie foute te voorkom.", 'am': 'ብዙኃን ፋይል sን መክፈት አልቻለም፦ %s፦ %s However, recent works have reported presence of substantial noise in the dialogue state annotations.  ብዙአዊ WOZ 2.1 የተሳሳተ እና የተጠቃሚ ንግግር አግኝቷል፡፡ ይሄ ሥራ ብዙWOZ 2.2 ያስታያል፤ ይህም ደግሞ የዚህ ዳታ-setን ሌላ ክፍል ነው፡፡ በመጀመሪያው፣ የብዙኃን 2.1 በሚያነካው በአስማትነቱ ላይ 17.3 በመቶ ስህተቶችን እናሳውቃለን እናሳውቃለን፡፡ በሁለተኛውም፣ የስልክ አካባቢዎችን በመግለጽ በተቻለ ቁጥር (ምሳሌ የመረጃ ስም፣ የመስኮት ሰዓት) እናስተካክላለን፡፡ በተጨማሪም፣ እንደዚህ አዲስ አካባቢዎች በሙሉ አካባቢዎች ላይ እናሳውቃቸዋለን፡፡ እና ለፊት ለሥራው ትክክል ለማግኘት በጥሩ ዳታ ማሳየት አካባቢ የጥያቄ አካባቢ ሥርዓት እናሳርጋለን፡፡ በመጨረሻውም የመስመር ጠንካራ ስህተቶችን ለመራቀቅ የሚችሉትን የዳታ ማኅበረሰብ ጥያቄዎችን እናሳውቃለን፡፡', 'bn': 'MultiWOZ হচ্ছে একটি ভালো পরিচিত কাজ-আদর্শিত ডায়ালগ ডাটাসেট যার মধ্যে আছে ১০,০০০ বেশী বিখ্যাত ডায়ালগের মধ্যে ৮ ডোমেনের স্প ডায়ালগ রাষ্ট্রের ট্র্যাকিং এর জন্য এটি ব্যাপকভাবে ব্যবহৃত। তবে সাম্প্রতিক কাজ এই ডায়ালগ রাষ্ট্রের বিরক্তিকর শব্দের উপস্থিতি সংবাদ প্রদান করেছে। মাল্টিউডোজ ২. ১ এই সমস্ত ভুল বিভ্রান্ত বিষয়গুলো পরিচিত এবং ব্যবহারকারী ভাষাগুলো ঠিক করেছে, যার ফলে এই ডাটাসেটের উন্নত সংস্করণ এই কাজ মাল্টিউডওজ ২. ২ পরিচিত, যা এখনো এই ডাটাসেটের আরেকটি উন্নত সংস্করণ। প্রথমত, আমরা ডায়ালগ রাষ্ট্রের বিরুদ্ধে পরিচিতি এবং সংশোধন করি মাল্টিউডওজ ২. দ্বিতীয়, আমরা স্লোটগুলোর শব্দভাণ্ডার নিষিদ্ধ করে পুনরায় বিস্তারিত বর্ণনা করি সম্ভাব্য মান (যেমন রেস্টুরেন্ট নাম, বুকের সময়)। এছাড়াও, সাম্প্রতিক মডেলের মধ্যে স্লোট স্প্যানের বিষয়গুলোর জন্য আমরা স্প্যানের বিষয়গুলোকে পরিচয় করিয়ে দিয়েছি যারা সাম্প্রতি আমরা আর্ট ডায়ালগের কয়েকটি অবস্থা বেনম্যার্ক করি ভবিষ্যতের কাজের তুলনায় সুসংশোধন করা ডাটাসেটের ট্র্যাকিং মডেলের উপর। In the end, we discuss best practices for dialogue data collection that can help avoid annotation errors.', 'hy': 'Բազմազանգվածը հայտնի գործողությունների ուղղությամբ խոսակցային տվյալների համակարգ է, որը պարունակում է ավելի քան 10,000 annoտացված խոսակցային համակարգ, որը ընդհանուր է 8 տիեզերք: Այն մեծամասնությամբ օգտագործվում է որպես համեմատային արտահայտություն վիճակի հետևման համար: However, recent works have reported presence of substantial noise in the dialogue state annotations.  Բազմազանգվածը 2.1 բացահայտեց և կատարեց այս սխալ annoտացիաներից շատերը և օգտագործողների արտահայտությունները, ինչը հանգեցնում է տվյալների լավագույն տարբերակին: Այս աշխատանքը ներկայացնում է «Միջին աշխատանք» 2.2-ը, որը այս տվյալների համակարգի ևս մեկ բարելավված տարբերակն է: Առաջինը, մենք հայտնաբերում ենք և լուծում ենք բաղադրամի վիճակի annoտացիայի սխալները, որոնք բառերի 17.3 տոկոսի մեջ են, բառերի 2.1 վերևում: Երկրորդ, մենք վերաձևավորում ենք գոնտոլոգիան, թույլ տալով բառերի բառերը, որոնք ունեն հնարավոր շատ արժեքներ (օրինակ ռեստորանի անունը, պահելու ժամանակը): Ավելին, մենք ներկայացնում ենք վայրերի ընթացքում նշումներ այս վայրերի համար, որպեսզի ստանդարտիզացնենք դրանք վերջին մոդելների միջոցով, որոնք նախկինում օգտագործում էին հատուկ լարեր, որոնք համապատասխանում են հորիստիկային դրանք ստեղծելու Մենք նաև համեմատում ենք մի քանի նորաձևագույն երկրախոսակցություն նախատեսված տվյալների համակարգի վերաբերյալ, որպեսզի հեշտացնենք համեմատությունը ապագա աշխատանքի համար: Վերջ ի վերջո, մենք քննարկում ենք տվյալների հավաքածու համար լավագույն գործողությունները, որոնք կարող են օգնել խուսափել նշումների սխալներից:', 'az': "MultiWOZ, 8 domena geniŇüliyi 10.000 il…ô bildirilmiŇü m…ôlumatlar bar…ôsind…ô tanńĪnmńĪŇü m…ôlumatlar danńĪŇümaq m…ôlumatńĪ qurduńüu m…ôlumatdńĪr. Bu m√ľ…ôyy…ôn edilmiŇü dijalog durumu izl…ôm…ôsi √ľ√ß√ľn benchmark olaraq istifad…ô edilir. Halbuki, yeni iŇül…ôr el√ßi m…ôlumatlarńĪnda b√∂y√ľk s…ôs olduńüunu bildirdi. MultiWOZ 2.1 bu x…ôta bildirilm…ôl…ôrin v…ô istifad…ô√ßil…ôrin √ßoxunu tanńĪdńĪ v…ô t…ôyin etdi, bu veri qutusunun yaxŇüńĪlaŇüdńĪrńĪlmńĪŇü versiyonu olaraq. Bu iŇül…ôr MultiWOZ 2.2 il…ô tanńĪŇüńĪr, bu veril…ôn qutusunun baŇüqa daha yaxŇüńĪlaŇüdńĪrńĪlmńĪŇü versiyonu. ∆Źvv…ôlc…ô, √ßoxlu WOZ 2.1'nin √ľst√ľnd…ôki s√∂zl…ôrin 17.3% il…ô d…ôyiŇüdirilmiŇü durum x…ôtalarńĪnńĪ tanńĪyńĪrńĪq v…ô d√ľz…ôldirik. ńįkinci olaraq, √ßox m√ľmk√ľn qiym…ôtl…ôrl…ô slot s√∂zl…ôrinin istifad…ôsi etm…ôkl…ô ontoloji yenid…ôn t…ôyin edirik. Buna g√∂r…ô d…ô, biz bu slotlar √ľ√ß√ľn slot span annotatiyonlarńĪnńĪ yeni modell…ôrl…ô standardizl…ôm…ôk √ľ√ß√ľn tanńĪyńĪrńĪq ki, …ôvv…ôll…ôr heuristik il…ô uyńüunlaŇüan Ňü…ôkild…ô istifad…ô edilmiŇüdir. Biz d…ô m√ľ…ôyy…ôn edilmiŇü veril…ônl…ôr qutusunda sanat dialogńĪnńĪn bir ne√ß…ô durumunu t…ôr…ôf √ß…ôkirik ki, g…ôl…ôc…ôk iŇüin qarŇüńĪlaŇüdńĪrmasńĪnńĪ asanlaŇüdńĪrsńĪn. Sonunda, el√ßi m…ôlumatńĪ koleksiyonu √ľ√ß√ľn …ôn yaxŇüńĪ praksil…ôrl…ô m√ľbahis…ô edirik ki, m…ôlumatńĪ x…ôtalarńĪndan √ß…ôkinm…ôy…ô k√∂m…ôk ed…ô bil…ôr.", 'bs': 'MultiWOZ je poznat sastav podataka o dijalogu s orijentacijom na zadatke koji sadrži preko 10.000 annotiranih dijaloga koje šire 8 domena. To se široko koristi kao referent za praćenje stanja dijaloga. Međutim, nedavni radovi su prijavili prisustvo značajne buke u navodima države dijaloga. MultiWOZ 2.1 je identifikovao i popravio mnoge od tih pogrešnih annotacija i izraza korisnika, što je rezultiralo u poboljšanoj verziji ovog seta podataka. Ovaj rad predstavlja MultiWOZ 2.2, što je još jedna poboljšana verzija ovog seta podataka. Prvo, identificiramo i popravimo greške u javnoj annotaciji dijaloga preko 17,3% izraza na vrhu MultiWOZ 2.1. Drugo, predefinišemo ontologiju odbacivanjem rečnika slota sa velikim brojem mogućih vrijednosti (npr. ime restorana, vrijeme rezervacije). Osim toga, predstavljamo annotacije za vrijeme slota za te slote kako bi ih standardizirali preko nedavnih modela, koje su prethodno koristile obične žice odgovarajuće heurističkim metodama kako bi ih stvorili. Također se nalazimo i nekoliko stanja umjetničkog dijaloga modela praćenja država za umjetničkim dijalogom na ispravnom setu podataka kako bi olakšali usporedbu za budući rad. Na kraju, razgovaramo o najboljoj praksi za kolekciju dijalogskih podataka koja može pomoći izbjegavati greške annotacije.', 'ca': "MultiWOZ és un conegut conjunt de dades de diàleg orientat a les tasques que conté més de 10.000 diàlegs anotats abans de 8 dominis. Es utilitza ampliament com a punt de referència per a seguir l'estat del diàleg. Tot i així, treballs recents han dit que hi ha soroll substancial a les anotacions de l'estat del diàleg. MultiWOZ 2.1 va identificar i arreglar moltes d'aquestes anotacions errònies i expressions d'usuari, resultant en una versió millorada d'aquest conjunt de dades. This work introduces MultiWOZ 2.2, which is a yet another improved version of this dataset.  En primer lloc, identificem i arreglam els errors d'anotació de l'estat del diàleg en un 17,3% de les expressions a sobre de MultiWOZ 2.1. Secondly, we redefine the ontology by disallowing vocabularies of slots with a large number of possible values (e.g., restaurant name, time of booking).  A més, introduïm anotacions d'interval de slots per a estandaritzar-los en models recents, que abans utilitzaven cadenes personalitzades que coincidien amb heurística per generar-los. També comparem alguns models de seguiment de l'estat de diàleg més avançat en el conjunt de dades corregides per facilitar la comparació de la feina futura. Al final, parlem de les millors pràctiques per a la col·lecció de dades de diàleg que poden ajudar a evitar errors d'anotació.", 'cs': 'MultiWOZ je známá databáze dialogů orientovaných na úlohy obsahující více než 10.000 anotovaných dialogů napříč osmi doménami. Je široce používán jako měřítko pro sledování stavu dialogu. Nicméně nedávné práce uváděly přítomnost značného hluku v anotacích stavu dialogu. MultiWOZ 2.1 identifikoval a opravil mnoho těchto chybných anotací a uživatelských výroků, což vedlo k vylepšení verze této datové sady. Tato práce představuje MultiWOZ 2.2, což je další vylepšená verze této datové sady. Nejprve identifikujeme a opravujeme chyby anotace stavu dialogu nad 17,3% výroků nad MultiWOZ 2.1. Za druhé předefinujeme ontologii zakázáním slovníků slotů s velkým počtem možných hodnot (např. název restaurace, čas rezervace). Kromě toho představujeme anotace rozpětí slotů pro tyto sloty, abychom je standardizovali napříč nedávnými modely, které dříve používaly vlastní heuristiku odpovídající řetězcům k jejich generování. Také porovnáváme několik nejmodernějších modelů sledování stavu dialogů na opraveném datovém souboru, abychom usnadnili srovnání pro budoucí práci. Na závěr diskutujeme osvědčené postupy pro sběr dialogových dat, které mohou pomoci předejít chybám anotace.', 'et': 'MultiWOZ on tuntud ülesannetele orienteeritud dialoogi andmekogum, mis sisaldab üle 10 000 märgitud dialoogi, mis hõlmavad 8 domeeni. Seda kasutatakse laialdaselt dialoogi seisundi jälgimise võrdlusalusena. Hiljutised tööd on aga teatanud märkimisväärsest mürast dialoogi oleku märgistustes. MultiWOZ 2.1 tuvastas ja parandas paljud neist valedest märkustest ja kasutajate väljenditest, mille tulemuseks oli andmekogumi täiustatud versioon. Selles töös tutvustatakse MultiWOZ 2.2, mis on veel üks täiustatud versioon sellest andmekogumist. Esiteks tuvastame ja parandame dialoogi oleku annotatsioonivead 17,3% väljenditest MultiWOZ 2.1 peal. Teiseks määratleme ontoloogia uuesti, keelates teenindusaegade sõnastikud, millel on suur hulk võimalikke väärtusi (nt restorani nimi, broneerimise aeg). Lisaks tutvustame nende pesade jaoks pesade ulatuse annotatsioone, et standardida neid hiljutistes mudelites, mis varem kasutasid nende genereerimiseks kohandatud stringide sobivuse heuristikat. Samuti võrdleme parandatud andmekogumi mõningaid kaasaegseid dialoogi riigi jälgimismudeleid, et hõlbustada võrdlemist tulevaste tööde jaoks. Lõpuks arutame dialoogiandmete kogumise parimaid tavasid, mis aitavad vältida märgistusvigu.', 'fi': 'MultiWOZ on tunnettu tehtävälähtöinen dialogitiedosto, joka sisältää yli 10 000 huomaututettua dialogia 8 toimialueella. Sitä käytetään laajasti vertailukohtana vuoropuhelun tilan seurannassa. Viimeaikaiset teokset ovat kuitenkin ilmoittaneet, että dialogin tilamerkinnät ovat aiheuttaneet huomattavaa melua. MultiWOZ 2.1 tunnisti ja korjasi monet näistä virheellisistä huomautuksista ja käyttäjien lausumista, mikä johti tämän aineiston parempaan versioon. Tässä työssä esitellään MultiWOZ 2.2, joka on jälleen yksi parannettu versio tästä aineistosta. Ensinnäkin tunnistamme ja korjaamme dialogitilan merkitsemisvirheet 17,3 prosentissa MultiWOZ 2.1:n yläpuolella olevista lauseista. Toiseksi määrittelemme ontologian uudelleen kieltämällä lähtö- ja saapumisaikojen sanastot, joilla on suuri määrä mahdollisia arvoja (esim. ravintolan nimi, varauksen aika). Lisäksi esittelemme slot span -merkinnät näille sloteille standardisoidaksemme ne uusimmissa malleissa, joissa aiemmin käytettiin mukautettuja merkkijonojen täsmäytysheuristioita niiden luomiseen. Vertailemme myös muutamia viimeisimpiä dialogin tilan seurantamalleja korjattuun aineistoon, jotta vertailu tulevaa työtä varten olisi helpompaa. Lopuksi keskustelemme dialogitietojen keräämisen parhaista käytännöistä, joiden avulla voidaan välttää huomautusvirheet.', 'sq': 'MultiWOZ është një grup i njohur i të dhënave të dialogut të orientuar në detyra që përmban mbi 10,000 dialoge të anotuara që përfshijnë 8 domene. Ajo përdoret në mënyrë të gjerë si një pikë referimi për gjurmimin e gjendjes së dialogut. Megjithatë, punët e fundit kanë raportuar praninë e zhurmës thelbësore në anotacionet e shtetit të dialogut. MultiWOZ 2.1 identifikoi dhe rregulloi shumë nga këto anotacione të gabuara dhe shprehje të përdoruesve, duke rezultuar në një version të përmirësuar të këtij grupi të dhënash. Ky punë paraqet MultiWOZ 2.2, i cili është një version tjetër i përmirësuar i këtij grupi të dhënash. Së pari, identifikojmë dhe rregullojmë gabimet e anotacionit të shtetit të dialogut në 17.3% të shprehjeve mbi MultiWOZ 2.1. Së dyti, ne e ridefiniojmë ontologjinë duke ndaluar fjalorët e slots me një numër të madh vlerash të mundshme (për shembull emri i restaurantit, koha e rezervimit). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them.  We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work.  Në fund, diskutojmë praktikat më të mira për mbledhjen e të dhënave të dialogut që mund të ndihmojnë të shmangen gabimet e anotacionit.', 'jv': 'MultiWOZ iku task-Oriented dialog dataset It is extremely used as a bench for dialog state tracking. politenessoffpolite, "), and when there is a change ("assertivepoliteness MultiWOZ 2.1 kang dipeneksi lan basa sing akeh perusahaan karo nambah Ngomongke iki nambah MultiWOZ 2.2, sampeyan kuwi wis nambah versi sing lunak nggawe dataset iki. Node Siji-wis, kita mulai kotak nggawe ontlogi dipunangé awak dhéwé karo nganggo sistem sing gak adhil (sae. jeneng restoran, aku ndelok). slot type @bench_BAR_ Fine', 'sk': 'MultiWOZ je znan nabor podatkov o opravilu usmerjenih dialogih, ki vsebuje več kot 10.000 označenih dialogov, ki obsegajo 8 domen. Obsežno se uporablja kot merilo za spremljanje stanja dialoga. Nedavna dela pa poročajo o prisotnosti znatnega hrupa v opombah stanja dialoga. MultiWOZ 2.1 je odkril in popravil številne napačne opombe in uporabniške izjave, kar je posledica izboljšane različice tega nabora podatkov. To delo predstavlja MultiWOZ 2.2, ki je še ena izboljšana različica tega nabora podatkov. Prvič, prepoznamo in popravimo napake pri opombah stanja dialoga v 17,3% izjav na vrhu MultiWOZ 2.1. Drugič, ontologijo ponovno opredelimo tako, da ne dovolimo besednikov rež z velikim številom možnih vrednosti (npr. ime restavracije, čas rezervacije). Poleg tega smo za te reže uvedli opombe razpona rež, da bi jih standardizirali v novejših modelih, ki so prej uporabljali heuristiko ujemanja nizov po meri za njihovo ustvarjanje. Primerjamo tudi nekaj najsodobnejših modelov sledenja stanju dialoga na popravljenem naboru podatkov, da bi olajšali primerjavo za prihodnje delo. Na koncu razpravljamo o najboljših praksah za zbiranje podatkov v dialogu, ki lahko pomagajo preprečiti napake pri pripombah.', 'ha': "Multan WOZ yana da tsarin zauren akwatin bayani mai da aka sani game da shi, mai ƙunsa da zauren akwatin zauren akwatin bayanin akwatin bayani 10,000 da aka nuna 8-sauni. An yi amfani da hakki kamar bangon bangon wa jerin bayani na zauren akwatin bayani. Haƙĩƙa, aikin nan da suka sani an sami sauti mai girma a cikin zanen zauren akwatin bayanin. @ info: status Wannan aikin na ƙunsa da multi-WOZ 2.2, wannan yana da wani tsohon da aka fizge wannan tsarin da aka samu. Na farko, za'a gane kuma mu daidaita makorari ga halin taƙaita na zauren akwatin bayanin akwatin bayani na 17.3% na maganar da ke saman multi-WOZ 2.1. Dukkan na, za'a buƙata fikarin ontoli da za'a kanana wasu misãlai masu yiwuwa (misali sunan restaurant, lokacin booki). Kuma da waɗancan, muna ƙara wa taƙaita slot span wa wannan slot dõmin ya daidaita su a kowace misãlai na farko, wanda ya yi amfani da string na ɗabi'a da heuristics don ya ƙara su. Kayya, Muke bangẽwa masu kaɗan na halin mazaɓa na zauren zauren akwatin bayani na sanata masu shirya kan tsarin da aka yi amfani da shi ga fasalin aiki na gaba. Ga ƙarshen, Munã jãyayya masu kyakkyawan hanyoyin zauren akwatin bayani da za'a iya amfani da su kange ɓata masu cũtarwa.", 'bo': 'MultiWOZ འདི་སྤྱོད་མཁན་ལྡན་གྱིས་རྒྱུད་ལྡན་བྱས་པའི་བྱ་འགུལ་གྱིས་ཡིག་སྒྲོམ་ནང་གི་སྒྲུམ་སྐད་ཡོངས་སྟོང་བཅུ་༡༠༠༠་ འདི་སྒྲ་ཚུལ་གྱི་གནས་ཚད་རྗེས་ལྟ་བུའི་ལྟ་བུའི་བརྒྱུད་རིམ་པ་ཞིག་གིས་ལག་ལེན་འཐབ་སྟེ། ཡིན་ནའང་། ཉེ་ཆར་བྱ་བ་དག་གི་སྒྲ་སྐད་བརྡ་སྟོན་པ་མང་པོ་ཡོད་པ་ཚོས་མཐོང་ནུས་མཐོང་བ་ཡིན། MultiWOZ 2.1 identified and fixed many of these erroneous annotations and user utterances, resulting in an improved version of this dataset. འདི་ལས་ཀ་སྒྲུབ་ཀྱིས་བཏོན་གཏོང་བྱེད་ཀྱི་MultiWOZ 2.2་ཡིན། དེ་ནི་འཕྲིན་སྒྲིག་ཆ་འཕྲིན་ཀྱི་པར་རིས་གཞན་ཞིག་ཏུ་ དང་པོ་མཉམ་དུ། ང་ཚོས་ཡུལ་སྒྲོམ་ནང་གི་གསལ་བཤད་ཀྱི་ནོར་འཁྲུལ་བ་མང་ཆེ་བོའི་ཐོག་ལས་17.3% Secondly, we redefine the ontology by disallowing vocabularies of slots with a large number of possible values (e.g. restaurant name, time of booking). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them. ང་ཚོས་ཀྱང་སྒྱུ་རྩལ་གླེང་སྒྲོམ་གྱི་གནས་སྟངས་ལ་རང་ཉིད་ཀྱི་རྣམ་པ་ལྟ་ཀློག་བྱེད་པའི་མིག་སྒྲིག་ཡིག་ཆ མཇུག་གི་རྗེས་མ་དུ། འུ་ཅག་གིས་སྒྲུབ་གླེང་སྒྲུབ་ནང་གི་བྱ་སྟངས་ཕལ་ཆེན་བྱེད་དགོས།', 'he': 'MultiWOZ הוא קבוצת נתונים ידועה במיוחד למשימות שמכילה מעל 10,000 דיאלוגים מועטפים במרחק 8 שדות. הוא משתמש באופן רחב כנקודת רמז עבור מעקב מדיום דיאלוג. However, recent works have reported presence of substantial noise in the dialogue state annotations.  MultiWOZ This work introduces MultiWOZ 2.2, which is a yet another improved version of this dataset.  ראשית, אנו מזהה ולתקן שגיאות ציוני מדינה בדיולוג ברחבי 17.3% מהמבטות מעל MultiWOZ 2.1. שנית, אנו מגדירים מחדש את האונטולוגיה על ידי לאסור את המילים של קופסאות עם מספר גדול של ערכים אפשריים (למשל, שם המסעדה, זמן ההזמנה). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them.  We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work.  בסופו של דבר, אנחנו מדברים על הפרקטיקות הטובות ביותר לאספת נתונים בדיולוגים שיכולים לעזור למנוע שגיאות הערות.'}
{'en': 'Probing Neural Dialog Models for Conversational Understanding', 'ar': 'استقصاء نماذج الحوار العصبي لفهم المحادثة', 'fr': 'Analyse des modèles de dialogue neuronal pour une compréhension conversationnelle', 'pt': 'Provando Modelos de Diálogo Neural para Entendimento Conversacional', 'es': 'Sondeo de modelos de diálogo neuronal para la comprensión conversacional', 'ja': '会話理解のためのニューラルダイアログモデルの探索', 'zh': '测曰:神经言模也', 'ru': 'Зондирование моделей нейронных диалогов для разговорного понимания', 'hi': 'संवादी समझ के लिए तंत्रिका संवाद मॉडल की जांच', 'ga': 'Samhlacha Dialóige Néaracha a Scrúdú le haghaidh Tuiscint Chomhrá', 'ka': 'ნეიროლური დიალოგის მოდელების შეცდომა კონტაქციოლური პასუხისთვის', 'el': 'Δοκιμή μοντέλων νευρωνικού διαλόγου για κατανόηση συνομιλίας', 'hu': 'Neurális párbeszédablak modellek vizsgálata a beszélgetési megértéshez', 'it': 'Analisi dei modelli di dialogo neurale per la comprensione delle conversazioni', 'lt': 'Neuralinio dialogo modelių bandymas konversacijos supratimui', 'kk': 'Динамикалық түсінбеу үшін нейрондық диалог үлгілерін тексеру', 'mk': 'Пробување на модели на нервен дијалог за конверзационално разбирање', 'ms': 'Memuji Model Dialog Neural untuk Pemahaman Perbualan', 'ml': 'സംസാരിക്കുന്നതിനായി നെയുറല്\u200d ഡയലോഗ് മോഡലുകള്\u200d പരിശോധിക്കുന്നു', 'mt': 'Probing Neural Dialog Models for Conversational Understanding', 'mn': 'Хариулт ойлголтын сэтгэл зүй диалогын загваруудыг судалж', 'no': 'Testar neuraldialogmodeller for samtaleforståking', 'ro': 'Proiectarea modelelor de dialog neural pentru înțelegerea conversațională', 'pl': 'Badanie neuronowych modeli dialogu dla zrozumienia konwersacji', 'sr': 'Probanje modela neurološkog dijaloga za razumevanje', 'si': 'සංවාදය තේරුම්ගන්න සඳහා න්\u200dයූරල් සංවාදය නිර්මාණය', 'so': 'Isticmaalka diyaarinta neurada', 'sv': 'Söka Neural Dialog Modeller för konversationsförståelse', 'ta': 'உரையாடல் புரிந்து கொள்ளும் பொருளுக்கான புதிய உரையாடல் மாதிரிகளை சோதிக்கிறது', 'ur': 'مکالمانی سمجھنے کے لئے نئورل ڈیلوگ موڈل کا امتحان کیا جاتا ہے', 'uz': 'Name', 'vi': 'Chế độ ngắt thần kinh cho hiểu biết đối thoại', 'bg': 'Проучване на модели на неврални диалози за разбиране на разговора', 'hr': 'Proba modela neurološkog dijaloga za razumijevanje razgovora', 'da': 'Undersøgelse af Neurale Dialogmodeller til samtaleforståelse', 'nl': 'Neuronale dialoogmodellen testen voor conversatievermogen', 'de': 'Untersuchung neuronaler Dialogmodelle zum Verständnis von Gesprächen', 'id': 'Memuji Model Dialog Neural untuk Pemahaman Berbicara', 'ko': '대화 이해의 신경 대화 모델을 탐구하다', 'fa': 'امتحان نمونه\u200cهای گفتگوی عصبی برای درک مکالمه', 'sw': 'Mradi wa Dialogu ya Neural kwa ajili ya Maelezo ya mazungumzo', 'tr': 'Qonuşma düşünmek üçin näyral dialogy nusgala', 'sq': 'Duke provuar modelet e dialogut neuronal për kuptimin konversacional', 'af': 'Probeer Neurale Dialoog Models vir Gespraak Verstaan', 'am': 'dialogs-action', 'hy': 'Խոսախոսական հասկանալու նյարդային պատկերների մոդելների փորձում', 'bn': 'কথোপকথন বুঝার জন্য নিউরাল ডায়ালগ মডেলস প্রস্তুত করা হচ্ছে', 'az': 'Qonuşma anlaşılması üçün nöral Dialoog Modellərini sınamaq', 'bs': 'Proba modela neurološkog dijaloga za razumijevanje', 'cs': 'Testování modelů neuronového dialogu pro konverzační porozumění', 'et': 'Neuraalsete dialoogide mudelite uurimine vestluse mõistmiseks', 'ca': 'Probar models de diàleg neuronal per a entendre conversacionalment', 'fi': 'Neuraaliset dialogimallit keskustelun ymmärtämiseksi', 'jv': 'Jejaring', 'ha': '@ action', 'bo': 'གཏམ་གླེང་གི་རྟོགས་པའི་སྣང་བ་གླེང་སྒྲོམ་གླེང་སྒྲོམ་གྱི་རྣམ་པ་ཚོད་ལྟ་བྱེད་པ', 'he': 'ניסוי דוגמני דיאלוג נוירואלים להבינה שיחה', 'sk': 'Prodiranje modelov živčnih pogovorov za razumevanje pogovorov'}
{'en': 'The predominant approach to open-domain dialog generation relies on end-to-end training of neural models on chat datasets. However, this approach provides little insight as to what these models learn (or do not learn) about engaging in dialog. In this study, we analyze the internal representations learned by neural open-domain dialog systems and evaluate the quality of these representations for learning basic conversational skills. Our results suggest that standard open-domain dialog systems struggle with answering questions, inferring contradiction, and determining the topic of conversation, among other tasks. We also find that the dyadic, turn-taking nature of dialog is not fully leveraged by these models. By exploring these limitations, we highlight the need for additional research into architectures and training methods that can better capture high-level information about dialog.', 'fr': "L'approche prédominante de la génération de dialogues de domaine ouvert repose sur l'entraînement de bout en bout de modèles neuronaux sur des ensembles de données de chat. Cependant, cette approche fournit peu d'informations sur ce que ces modèles apprennent (ou n'apprennent pas) sur l'engagement dans le dialogue. Dans cette étude, nous analysons les représentations internes apprises par les systèmes de dialogue neuronaux à domaine ouvert et évaluons la qualité de ces représentations pour l'apprentissage des compétences conversationnelles de base. Nos résultats suggèrent que les systèmes de dialogue ouverts standard ont du mal à répondre aux questions, à déduire des contradictions et à déterminer le sujet de la conversation, entre autres tâches. Nous constatons également que la nature dyadique et tournante du dialogue n'est pas pleinement exploitée par ces modèles. En explorant ces limites, nous soulignons la nécessité de mener des recherches supplémentaires sur les architectures et les méthodes de formation qui peuvent mieux saisir des informations de haut niveau sur le dialogue.", 'es': 'El enfoque predominante para la generación de diálogos de dominio abierto se basa en el entrenamiento integral de modelos neuronales en conjuntos de datos de chat. Sin embargo, este enfoque proporciona poca información sobre lo que estos modelos aprenden (o no aprenden) sobre el diálogo. En este estudio, analizamos las representaciones internas aprendidas por los sistemas de diálogo neuronales de dominio abierto y evaluamos la calidad de estas representaciones para aprender habilidades conversacionales básicas. Nuestros resultados sugieren que los sistemas de diálogo de dominio abierto estándar tienen dificultades para responder preguntas, inferir contradicciones y determinar el tema de conversación, entre otras tareas. También encontramos que estos modelos no aprovechan completamente la naturaleza diádica y decisiva del diálogo. Al explorar estas limitaciones, destacamos la necesidad de realizar investigaciones adicionales sobre arquitecturas y métodos de capacitación que puedan captar mejor información de alto nivel sobre el diálogo.', 'ar': 'يعتمد النهج السائد لإنشاء حوار المجال المفتوح على التدريب الشامل للنماذج العصبية على مجموعات بيانات الدردشة. ومع ذلك ، فإن هذا النهج يوفر القليل من التبصر فيما تتعلمه هذه النماذج (أو لا تتعلمه) حول الانخراط في الحوار. في هذه الدراسة ، نقوم بتحليل التمثيلات الداخلية التي تعلمتها أنظمة حوار المجال المفتوح العصبية وتقييم جودة هذه التمثيلات لتعلم مهارات المحادثة الأساسية. تشير نتائجنا إلى أن أنظمة حوار المجال المفتوح المعيارية تكافح مع الإجابة على الأسئلة ، واستنتاج التناقض ، وتحديد موضوع المحادثة ، من بين مهام أخرى. نجد أيضًا أن الطبيعة الثنائية المتباعدة للحوار لا تستفيد بشكل كامل من هذه النماذج. من خلال استكشاف هذه القيود ، نسلط الضوء على الحاجة إلى إجراء بحث إضافي في البنى وطرق التدريب التي يمكنها التقاط معلومات عالية المستوى حول الحوار بشكل أفضل.', 'pt': 'A abordagem predominante para a geração de diálogo de domínio aberto depende do treinamento de ponta a ponta de modelos neurais em conjuntos de dados de bate-papo. No entanto, essa abordagem fornece poucas informações sobre o que esses modelos aprendem (ou não aprendem) sobre o engajamento no diálogo. Neste estudo, analisamos as representações internas aprendidas por sistemas neurais de diálogo de domínio aberto e avaliamos a qualidade dessas representações para o aprendizado de habilidades básicas de conversação. Nossos resultados sugerem que os sistemas de diálogo de domínio aberto padrão lutam para responder perguntas, inferir contradições e determinar o tópico da conversa, entre outras tarefas. Também descobrimos que a natureza diádica e de troca de turnos do diálogo não é totalmente aproveitada por esses modelos. Ao explorar essas limitações, destacamos a necessidade de pesquisas adicionais sobre arquiteturas e métodos de treinamento que possam capturar melhor as informações de alto nível sobre o diálogo.', 'zh': '开域之大要,依于聊天数集上神经规模之端。 然其法殆不给于言(与不学于)。 于此论之,吾论神经开放域之所学,而质其质,以学其本。 臣等考结果表明,准的开放域对话系统难以答应,推断矛盾,定对话主题等事。 我们还发现,这些模样没有充用对话的二元性、轮番性质。 探其局限性,须考架构训练方法,以善获对语之高。', 'hi': 'ओपन-डोमेन संवाद पीढ़ी के लिए प्रमुख दृष्टिकोण चैट डेटासेट पर तंत्रिका मॉडल के अंत-से-अंत प्रशिक्षण पर निर्भर करता है। हालांकि, यह दृष्टिकोण संवाद में संलग्न होने के बारे में ये मॉडल क्या सीखते हैं (या सीखते नहीं हैं) के रूप में बहुत कम अंतर्दृष्टि प्रदान करता है। इस अध्ययन में, हम तंत्रिका ओपन-डोमेन संवाद प्रणालियों द्वारा सीखे गए आंतरिक अभ्यावेदनों का विश्लेषण करते हैं और बुनियादी संवादात्मक कौशल सीखने के लिए इन अभ्यावेदनों की गुणवत्ता का मूल्यांकन करते हैं। हमारे परिणाम बताते हैं कि मानक ओपन-डोमेन संवाद प्रणाली प्रश्नों के उत्तर देने, विरोधाभास का अनुमान लगाने और अन्य कार्यों के बीच बातचीत के विषय को निर्धारित करने के साथ संघर्ष करती है। हम यह भी पाते हैं कि संवाद की युग्मक, बारी लेने की प्रकृति इन मॉडलों द्वारा पूरी तरह से लीवरेज नहीं की जाती है। इन सीमाओं की खोज करके, हम आर्किटेक्चर और प्रशिक्षण विधियों में अतिरिक्त शोध की आवश्यकता को उजागर करते हैं जो संवाद के बारे में उच्च-स्तरीय जानकारी को बेहतर ढंग से कैप्चर कर सकते हैं।', 'ja': 'オープンドメインのダイアログ生成の主なアプローチは、チャットデータセット上のニューラルモデルのエンドツーエンドのトレーニングに依存しています。しかし、このアプローチは、これらのモデルがダイアログに参加することについて何を学ぶ（または学ばない）かについての洞察をほとんど提供しない。この研究では、神経オープンドメインのダイアログシステムによって学習された内部表現を分析し、基本的な会話スキルを学習するためのこれらの表現の質を評価します。私たちの結果は、標準的なオープンドメインのダイアログシステムが、質問に答えたり、矛盾を推論したり、会話のトピックを決定したりすることに苦労していることを示唆しています。また、ダイアログのダイアディックでターンテイキングな性質は、これらのモデルによって完全に活用されていないこともわかります。これらの限界を探ることで、ダイアログに関する高レベルの情報をよりよく把握できるアーキテクチャとトレーニング方法についての追加の研究の必要性を強調します。', 'ru': 'Преобладающий подход к формированию диалога с открытым доменом основан на сквозном обучении нейронных моделей на наборах данных чата. Тем не менее, этот подход дает мало информации о том, что эти модели узнают (или не узнают) об участии в диалоге. В этом исследовании мы анализируем внутренние представления, изученные нейронными диалоговыми системами с открытым доменом, и оцениваем качество этих представлений для обучения базовым разговорным навыкам. Наши результаты показывают, что стандартные диалоговые системы открытого домена борются с ответами на вопросы, выводя противоречия и определяя тему разговора, среди прочих задач. Мы также обнаружили, что эти модели не в полной мере используют диадический характер диалога. Изучая эти ограничения, мы подчеркиваем необходимость дополнительных исследований архитектур и методов обучения, которые могут лучше фиксировать информацию высокого уровня о диалоге.', 'ga': "Tá an cur chuige is mó maidir le giniúint dialóige fearainn oscailte ag brath ar oiliúint ó cheann go ceann ar shamhlacha néaracha ar thacair sonraí comhrá. Mar sin féin, is beag léargas a thugann an cur chuige seo ar cad a fhoghlaimíonn (nó nach bhfoghlaimíonn) na samhlacha seo faoi dhul i mbun dialóige. Sa staidéar seo, déanaimid anailís ar na huiríll inmheánacha a d'fhoghlaim na córais néaracha dialóige oscailte fearainn agus déanaimid meastóireacht ar cháilíocht na n-uiríll sin chun bunscileanna comhrá a fhoghlaim. Tugann ár dtorthaí le fios go mbíonn deacrachtaí ag córais chaighdeánacha dialóige fearainn oscailte le ceisteanna a fhreagairt, contrárthacht a bhaint amach, agus ábhar an chomhrá a chinneadh, i measc tascanna eile. Faighimid freisin nach bhfuil nádúr lándaite, sealaíochta na dialóige á ghiaráil go hiomlán ag na samhlacha seo. Trí na teorainneacha seo a fhiosrú, leagaimid béim ar an ngá atá le taighde breise ar ailtireachtaí agus modhanna oiliúna ar féidir leo faisnéis ardleibhéil faoin dialóg a ghabháil níos fearr.", 'ka': 'დიალოგის გახსნა დიალოგის განვითარებას უფრო მეტად გახსნა ნეიროლური მოდელების განვითარებაზე დარწმუნება. მაგრამ, ეს პროგრამა უფრო ცოტა შეცდომა, როგორც ეს მოდელები ვისწავლენ (ან არ ვისწავლენ) დიალოგიში შემდეგ. ამ კვლევაში ჩვენ ანალიზებთ ინტერესტრაციები, რომლებიც ნეიროლური გახსნილი დიალოგის სისტემებით ვისწავლილი და გამოუყენებთ ამ გამოსახულებების საფუძველი კონტრაციოლ ჩვენი წარმოდგენები გვაქვს, რომ სტანდარტური დიალოგის დიალოგის სისტემი გახსნა კითხვებისთვის გასაღებისთვის, დაკავშირებას და განსაზღვრებას საზოგადომის თემა, სხვა ჩვენ ასევე აღმოჩნეთ, რომ დიალოგის დიადიკური, გამოყენებული სახელი არ არის ამ მოდელეების ყველაფერი გამოყენება. ამ ზომილებების განსხვავებით, ჩვენ განსხვავებთ უნდა დამატებული სწავლობა არქტიქტურების და განსწავლების მეტოვებისთვის, რომელიც უფრო უფრო დიალოგის შესახებ ინფ', 'el': 'Η κυρίαρχη προσέγγιση για τη δημιουργία διαλόγου ανοικτού τομέα βασίζεται στην ολοκληρωμένη εκπαίδευση νευρωνικών μοντέλων σε σύνολα δεδομένων συνομιλίας. Ωστόσο, αυτή η προσέγγιση παρέχει λίγες πληροφορίες σχετικά με το τι μαθαίνουν (ή δεν μαθαίνουν) αυτά τα μοντέλα σχετικά με τη συμμετοχή σε διάλογο. Στην παρούσα μελέτη αναλύουμε τις εσωτερικές αναπαραστάσεις που μαθαίνονται από νευρικά συστήματα διαλόγου ανοιχτού τομέα και αξιολογούμε την ποιότητα αυτών των αναπαραστάσεων για την εκμάθηση βασικών δεξιοτήτων συνομιλίας. Τα αποτελέσματά μας δείχνουν ότι τα τυπικά συστήματα διαλόγου ανοικτού τομέα αγωνίζονται με την απάντηση σε ερωτήσεις, την εξαγωγή αντίφασης και τον προσδιορισμό του θέματος της συνομιλίας, μεταξύ άλλων. Διαπιστώνουμε επίσης ότι η δυαδική, ανατρεπτική φύση του διαλόγου δεν αξιοποιείται πλήρως από αυτά τα μοντέλα. Εξετάζοντας αυτούς τους περιορισμούς, υπογραμμίζουμε την ανάγκη για πρόσθετη έρευνα σε αρχιτεκτονικές και μεθόδους κατάρτισης που μπορούν να συλλάβουν καλύτερα πληροφορίες υψηλού επιπέδου σχετικά με τον διάλογο.', 'hu': 'A nyílt tartományú párbeszédek generálásának elsődleges megközelítése a neurális modellek csevegési adatkészleteken történő végpontos képzésén alapul. Ez a megközelítés azonban kevés betekintést nyújt arra vonatkozóan, hogy ezek a modellek mit tanulnak (vagy nem tanulnak) a párbeszédben való részvételről. Ebben a tanulmányban elemezzük a neurális nyílt domain párbeszédrendszerek által tanult belső reprezentációkat és értékeljük ezen reprezentációk minőségét az alapvető beszélgetési készségek elsajátítására. Eredményeink arra utalnak, hogy a szokásos nyílt tartományú párbeszédrendszerek többek között küzdenek a kérdések megválaszolásával, ellentmondások következtetésével és a beszélgetés témájának meghatározásával. Azt is találjuk, hogy a párbeszéd diadikus, fordulós jellegét ezek a modellek nem használják ki teljes mértékben. Ezeknek a korlátozásoknak a feltárásával kiemeljük, hogy további kutatásokra van szükség az architektúrákkal és képzési módszerekkel kapcsolatban, amelyek jobban meg tudják gyűjteni a párbeszédről szóló magas szintű információkat.', 'kk': 'Доменді ашу диалогын құру үшін бастапқы тәсілі ньюралдық моделдердің аяқтау- аяқтау бағдарламасына тәуелді. Бұл жағдай, бұл үлгілер диалогында қатынау (немесе оқылмайтын) үлгілерді оқыту (немесе оқылмайтын) туралы кішкентай түсінікті береді. Бұл зерттеулерде, невралдық ашылған домендық диалог жүйелерінде үйренген ішкі көріністерді анализ және олардың негізгі қатынасын оқыту үшін сапаттарының сапаттамасын бағалаймыз. Біздің нәтижелеріміз стандартты ашылған домен диалог жүйелері сұрақтарды жауап беру, қарсы қарсы жасау және сұрақтардың нақышын басқа тапсырмалар арасында анықтау үшін көмектеседі. Біз сондай-ақ бұл үлгілер үлгілерінде диалогтың диадикалық, аудару қасиеті толық түрде қолданылмайды. Бұл шектеулерді зерттеп, диалог туралы жоғары деңгейіндегі мәліметті алу үшін архитектуралар мен оқыту әдістерін қосымша зерттеу қажеттігін таңдаймыз.', 'lt': 'Pagrindinis požiūris į atviro domeno dialogo generaciją grindžiamas mokymu nuo vienos iki kitos neuralinių modelių pokalbių duomenų rinkiniuose. However, this approach provides little insight as to what these models learn (or do not learn) about engaging in dialog.  Šiame tyrime analizuojame vidaus atstovavimus, įgytus naudojant neuralines atviros srities dialogo sistemas, ir vertiname šių atstovavimų kokybę mokymosi pagrindiniais pokalbio įgūdžiais srityje. Mūsų rezultatai rodo, kad standartinės atviros srities dialogo sistemos, be kitų užduočių, kovoja su atsakymais į klausimus, prieštarauja prieštaravimui ir sprendžia pokalbio temą. Taip pat manome, kad šie modeliai ne visapusiškai naudoja dinaminį ir apsisukantį dialogo pobūdį. Nagrinėdami šiuos apribojimus pabrėžiame būtinybę atlikti papildomus architektūros ir mokymo metodų mokslinius tyrimus, kurie galėtų geriau surinkti aukšto lygio informaciją apie dialog ą.', 'it': "L'approccio predominante alla generazione di dialoghi open-domain si basa sulla formazione end-to-end di modelli neurali su set di dati chat. Tuttavia, questo approccio fornisce poche informazioni su ciò che questi modelli imparano (o non imparano) sul coinvolgimento nel dialogo. In questo studio analizziamo le rappresentazioni interne apprese dai sistemi neurali di dialogo a dominio aperto e valutiamo la qualità di queste rappresentazioni per l'apprendimento delle abilità conversazionali di base. I nostri risultati suggeriscono che i sistemi standard di dialogo a dominio aperto faticano a rispondere alle domande, a dedurre contraddizione e a determinare l'argomento della conversazione, tra gli altri compiti. Troviamo anche che la natura diadica e mutevole del dialogo non è pienamente sfruttata da questi modelli. Esplorando queste limitazioni, sottolineiamo la necessità di ulteriori ricerche su architetture e metodi di formazione in grado di acquisire meglio informazioni di alto livello sul dialogo.", 'mk': 'Председателниот пристап до генерацијата на дијалози со отворен домен се зависи од обуката од крај до крај на нервните модели на компјутерите на податоци за разговори. Сепак, овој пристап обезбедува мало разбирање за тоа што овие модели научија (или не научија) за ангажирањето во дијалогот. Во оваа студија, ги анализираме внатрешните претставувања научени од неуралните системи на дијалог со отворен домен и го проценуваме квалитетот на овие претставувања за учење на основните разговорни вештини. Нашите резултати покажуваат дека стандардните системи на дијалог со отворен домен се борат со одговорите на прашањата, заклучувајќи контрадиција и одредувајќи ја темата на разговорот, меѓу другите задачи. Исто така, откриваме дека дијадичката, свртувачката природа на дијалогот не е целосно употребена од овие модели. Со истражувањето на овие ограничувања, ја истакнуваме потребата од дополнително истражување на архитектурите и методите на обука кои подобро можат да заземат информации на високо ниво за дијалогот.', 'ms': 'pendekatan utama untuk generasi dialog domain terbuka bergantung pada latihan akhir-akhir model saraf pada set data sembang. Namun, pendekatan ini memberikan sedikit pengetahuan mengenai apa yang model ini belajar (atau tidak belajar) mengenai terlibat dalam dialog. Dalam kajian ini, kami menganalisis perwakilan dalaman yang dipelajari oleh sistem dialog-domain terbuka saraf dan menilai kualiti perwakilan ini untuk belajar keterampilan percakapan asas. Our results suggest that standard open-domain dialog systems struggle with answering questions, inferring contradiction, and determining the topic of conversation, among other tasks.  Kami juga mendapati bahawa sifat dialog yang dididik, mengambil balik tidak sepenuhnya digunakan oleh model ini. Dengan mengeksplorasi keterangan-keterangan ini, kami menyatakan keperluan penelitian tambahan dalam arkitektur dan kaedah latihan yang lebih baik dapat menangkap maklumat tahap tinggi tentang dialog.', 'mt': 'L-approċċ predominanti għall-ġenerazzjoni ta’ djalogu open-domain jiddependi fuq taħriġ minn tarf sa tarf ta’ mudelli newrali fuq settijiet ta’ dejta chat. Madankollu, dan l-approċċ jipprovdi ftit għarfien dwar dak li dawn il-mudelli jitgħallmu (jew ma jitgħallmux) dwar l-involviment fid-djalogu. F’dan l-istudju, nagħmlu analiżi tar-rappreżentazzjonijiet interni magħrufa mis-sistemi ta’ djalogu newrali b’dominju miftuħ u nagħmlu evalwazzjoni tal-kwalità ta’ dawn ir-rappreżentazzjonijiet għat-tagħlim tal-ħiliet bażiċi ta’ konverżjoni. Ir-riżultati tagħna jissuġġerixxu li s-sistemi standard ta’ djalogu open-domain iħabbtu wiċċhom ma’ mistoqsijiet li jwieġbu, li jfissru kontradizzjoni, u li jiddeterminaw is-suġġett tal-konverżjoni, fost kompiti oħra. Issibu wkoll li n-natura dijodika u li tiddawwar tad-djalogu mhijiex ingranata bis-sħiħ minn dawn il-mudelli. By exploring these limitations, we highlight the need for additional research into architectures and training methods that can better capture high-level information about dialog.', 'mn': 'Дэлхийн нээлттэй диалог бүтээлтийн гол арга нь ярианы өгөгдлийн санд тархины загварын төгсгөлд суралцах боломжтой. Гэхдээ энэ арга нь эдгээр загварууд диалогт оролцохын тухай юу сурах (сурахгүй) талаар бага ойлголт өгдөг. Энэ судалгаанд бид мэдрэлийн нээлттэй диалог системээр сурсан дотоод харилцааны чадварыг шинжилгээ хийдэг. Бидний үр дүн нь стандарт нээлттэй диалог системүүд асуултуудад хариулт өгөх, эсрэг байдлын тухай тэмцэх, ярилцлагын тухай бусад ажил дээр тодорхойлж байгааг сануулдаг. Мөн бид энэ загварууд бүрэн ашиглаж чадахгүй. Эдгээр хязгаарыг судалж, бид диалогын талаар илүү өндөр түвшинд мэдээллийг авах боломжтой архитектурууд болон сургалтын архитектурууд нэмэлт судалгаа хэрэгтэй гэдгийг тодорхойлж байна.', 'pl': 'Dominujące podejście do generowania dialogów otwartych w domenie opiera się na kompleksowym szkoleniu modeli neuronowych na zbiorach danych czatu. Takie podejście zapewnia jednak niewiele wglądu na to, czego modele uczą się (lub czego nie uczą) o angażowaniu się w dialog. W niniejszym opracowaniu analizujemy wewnętrzne reprezentacje nauczane przez neuronowe systemy dialogowe otwartej domeny i oceniamy jakość tych reprezentacji dla nauki podstawowych umiejętności konwersacyjnych. Nasze wyniki sugerują, że standardowe systemy dialogowe otwarte domeny zmagają się m.in. z odpowiedzią na pytania, wnioskowaniem sprzeczności, określeniem tematu rozmowy. Stwierdzamy również, że dyadyczny, przewracający charakter dialogu nie jest w pełni wykorzystywany przez te modele. Badając te ograniczenia, podkreślamy potrzebę dodatkowych badań nad architekturą i metodami szkoleniowymi, które mogą lepiej przechwytywać informacje na temat dialogu na wysokim poziomie.', 'ro': 'Abordarea predominantă a generarii dialogurilor cu domeniu deschis se bazează pe instruirea end-to-end a modelelor neurale pe seturi de date chat. Cu toate acestea, această abordare oferă puține perspective cu privire la ceea ce aceste modele învață (sau nu învață) despre angajarea în dialog. În acest studiu, analizăm reprezentările interne învățate de sistemele neurale de dialog cu domeniu deschis și evaluăm calitatea acestor reprezentări pentru învățarea abilităților conversaționale de bază. Rezultatele noastre sugerează că sistemele standard de dialog cu domeniu deschis se luptă cu răspunsul la întrebări, deducerea contradicțiilor și determinarea subiectului conversației, printre alte sarcini. De asemenea, constatăm că natura diadică și orientală a dialogului nu este pe deplin valorificată de aceste modele. Explorând aceste limitări, evidențiem necesitatea unor cercetări suplimentare privind arhitecturile și metodele de instruire care să poată capta mai bine informații la nivel înalt despre dialog.', 'sr': 'Predsjedni pristup generaciji dijaloga otvorenog domena oslanja se na obuku neuralnih modela na sete datoteka. Međutim, ovaj pristup pruža malo uvida o tome šta ovi modeli nauče (ili ne nauče) o učenju u dijalogu. U ovoj studiji analiziramo unutrašnje predstave koje su naučili sistemi dijaloga neuronskog otvorenog domena i procjenjivali kvalitet tih predstavljanja za učenje osnovnih razgovornih vještina. Naši rezultati sugeriraju da se standardni dijalogski sistemi otvorenog domena bore sa odgovornim pitanjima, uvećavajući kontradikciju i određivanjem teme razgovora, među drugim zadacima. Takoðe pronaðemo da taj model ne utièe na dijadièku prirodu dijaloga. Istražujući te ograničenja, naglašavamo potrebu za dodatnim istraživanjem arhitekture i metoda obuke koje mogu bolje da uhvati informacije o visokom nivou o dijalogu.', 'si': 'විවෘත සංවාදය නිර්මාණය සඳහා ප්\u200dරධාන විදියට ප්\u200dරධාන විදියට ප්\u200dරධාන විදියට සංවාදය දත්ත සැට් වල සං නමුත්, මේ ප්\u200dරවේශනය ප්\u200dරවේශනයක් ප්\u200dරවේශනය කරනවා මේ මොඩල් ඉගෙන ගන්න (නැත්තම් ඉගෙන ගන්න) සංවාදයේ ඇත මේ පරීක්ෂණයේදී, අපි අන්තිම ප්\u200dරතිචාරයක් විශ්ලේෂ කරනවා න්\u200dයුරාල් අර්විශ්ලේෂණ සංවාදය පද්ධතියෙන් ඉගෙන ගත අපේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්නය සමඟ ස්ථානිත විවෘත සංවාද පද්ධතිය ප්\u200dරශ්නය කරනව අපිට හොයාගන්න පුළුවන් විදියට, සංවාදයේ ස්වභාවිතය සම්පූර්ණයෙන්ම මොඩේල් වලින් ප්\u200dරයෝජනය කරන මේ සීමාව පරීක්ෂා කරන්න, අපි අවශ්\u200dය විද්\u200dයාපාර සහ ප්\u200dරශ්නය විද්\u200dයාපනය සඳහා අවශ්\u200dය විද්\u200dයාපනය සඳහා අවශ්\u200dය වි', 'so': "Dhaqaalaha ugu horeeya ee u furan dhaqanka dialogue-domain waxay ku xiran tahay waxbarashada ugu dhammaadka ugu dambeeya tusaalaha neurada ee ku qoran danbiyada chat. Si kastaba ha ahaatee qaabkaasu waxey leedahay waxyaabo yar oo ku saabsan samooyinka ay ku bartaan (ama aan baran) oo ku saabsan wadashada. Waxbarashadan waxaynu ku baaraynaa kooxaha hoose ee lagu baray nidaamka dialogka ee naadiga ah oo furan, waxaana qiimeynaynaa qiimaha noocyadan ee barashada aqoonta aasaasiga ah. Abaalkayaga waxay ka jeedaan in nidaamka dialogka ee furan ee standardka ah ay la dagaalamayaan jawaabta su'aalaha, ka dhibaataysa islamarkaasna go’aanka arrimaha hadalka, shaqada kale dhexdooda. Sidoo kale waxaynu ognahay in dabiicadda dialog-ku-bedelka aan sameyn samooyinkaas oo dhan. Markaas baaraandegista xaduudahan, waxaynu tusnaynaa baahida waxbarasho dheeraad ah oo ku qoran dhismaha iyo qaababka waxbarashada, taasoo si wanaagsan u qabsan karta macluumaadka labada heer oo ku saabsan dialog.", 'ml': 'ഡൊമെയിന്\u200d ഡയലോഗ് തലമുറയ്ക്കുള്ള പ്രധാനപ്പെട്ട രീതിയില്\u200d ചാറ്റ് ഡാറ്റാസറ്റുകളില്\u200d ന്യൂറല്\u200d മോഡലുകളുടെ അവസ എന്നാലും ഈ സാധ്യതയില്\u200d ഈ മോഡലുകള്\u200d പഠിക്കുന്നതിനെപ്പറ്റി (അല്ലെങ്കില്\u200d പഠിക്കാതിരിക്കുന്നതിനെപ്പറ് ഈ പഠനത്തില്\u200d, ന്യൂറല്\u200d തുറന്ന ഡൊമെയിന്\u200d ഡയലോഗ് സിസ്റ്റം പഠിച്ച ആന്തരീക പ്രതിനിധികള്\u200d പരിശോധിക്കുകയും, അടിസ്ഥാനമായ സംസാരിക്കുന്ന നമ്മുടെ ഫലങ്ങള്\u200d ഉദ്ദേശിക്കുന്നത് സാധാരണ തുറന്ന ഡൊമെയിന്\u200d ഡയലോഗ് സിസ്റ്റം ചോദ്യങ്ങളുടെ ഉത്തരം ചോദിക്കുന്നതിന് ഉത്തരം നല്\u200dകുന് സംസാരത്തിന്റെ സ്വഭാവം പൂര്\u200dണ്ണമായും മാറ്റിയിട്ടില്ല എന്നും ഞങ്ങള്\u200d കണ്ടെത്തുന്നു. ഈ പരിധികള്\u200d പരിശോധിക്കുന്നതിനാല്\u200d, സാഹചര്യത്തെക്കുറിച്ച് ഉയര്\u200dന്ന നില വിവരങ്ങള്\u200d പിടികൂടുതല്\u200d പരിശീലിക്കുന്നതിന്റെയും', 'sv': 'Det dominerande tillvägagångssättet för dialog med öppen domän bygger på heltäckande utbildning av neurala modeller på chattdataset. Detta tillvägagångssätt ger dock lite insikt om vad dessa modeller lär sig (eller inte lär sig) om att engagera sig i dialog. I denna studie analyserar vi de interna representationer som lärts av neurala öppna domändialogsystem och utvärderar kvaliteten på dessa representationer för lärande av grundläggande konversationsförmåga. Våra resultat tyder på att standarddialogsystem med öppen domän har svårt att besvara frågor, härleda motsägelser och bestämma samtalsämnet, bland annat. Vi finner också att dialogens dyadiska, omväxlande karaktär inte utnyttjas fullt ut av dessa modeller. Genom att utforska dessa begränsningar lyfter vi fram behovet av ytterligare forskning om arkitekturer och utbildningsmetoder som bättre kan fånga in högnivåinformation om dialog.', 'no': 'Den viktigste tilnærminga til oppretting av dialogvindauget for open-domain er avhengig av uttrykking av neuralmodeller på pratedatasett. Denne tilnærminga gjev imidlertid liten innsyning om kva desse modelane lærer (eller ikkje lærer) om å engasjera i dialogen. I denne studien analyserer vi interne representasjonane lærte av dialogvindauget for neuralt opna domene og evaluerer kvaliteten på desse representasjonane for å lære grunnleggjande samtaleskillar. Resultatet våre tyder på at standard open-domain-dialog-systemet strømmer med svarande spørsmål, gjer kontradiksjon og bestemmer emnet på samtale, blant andre oppgåver. Vi finn også at denne modellen ikkje har fullstendig bruk av dialogvindauget dyadisk, omvendt-naturen. Ved å utforske desse grensene, må vi markere nødvendigheten for ekstra forskning i arkitektur og opplæringsmetodar som kan bedre henta informasjon om høg nivå om dialogen.', 'ur': 'کھولنے والی ڈومین ڈیٹ سٹ پر نئورل موڈل کی تعلیم کے انتہائی انتہائی انتہائی انتہائی طریقے پر اعتماد ہے. لیکن یہ تقریبا بہت کم بصیرت دیتا ہے کہ یہ مدلز جو کچھ سیکھتے ہیں (یا نہ سیکھتے ہیں) ان کے بارے میں مشغول ہونے کے بارے میں۔ اس مطالعہ میں، ہم نے نیورل اوپن ڈومین ڈیلوگر سیستم سے سیکھا ہوا داخلی نمونات کو تحقیق کرلیا اور ان نمونات کی کیفیت کا ارزش کرلیا بنیادی بات کی طاقتوں کے لئے۔ ہمارے نتیجے اس بات کی تفصیل دیتے ہیں کہ استاندارد اوپن ڈومین ڈائیلوگ سیسٹم سوال کے جواب دینے کے ساتھ مشکل کرتی ہیں، مخالفت کے ذریعے اور بحث کے موضوع کا فیصلہ کرتی ہیں، اور دوسرے کاموں کے درمیان. ہم نے بھی دیکھا ہے کہ ان نمڈلوں کے ذریعہ سے دھیادیک، پھیر لینے کی طبیعت پوری طور پر نہیں ہے۔ یہ محدودیتوں کی تحقیق کے ذریعہ، ہم نے معماری اور تربیت روش کے مطابق اضافہ تحقیق کے لئے ضرورت کی ہدایت کی ہے جو اس کے بارے میں اچھی سطح کی معلومات کو اچھی طرح پکڑ سکتی ہے.', 'ta': 'The predominant approach to open-domain dialog generation relies on end-to-end training of neural models on chat datasets.  ஆனால், இந்த முறைமை உரையாடலில் சேர்ந்து கொள்வது பற்றி இந்த மாதிரிகள் கற்றுக்கொள்வதைப் பற்றி குறைவான பார்வை இந்த ஆராய்ச்சியில், நாம் புதிய திறந்த டொமைன் உரையாடல் முறைமைகளால் கற்றுக் கொண்ட உள்ளார்ந்த பிரதிநிதிகளை ஆராய்ந்து கொள்கிறோம எங்கள் முடிவுகள் நிலையான திறந்த டொமைன் உரையாடல் அமைப்புகள் கேள்விகளுக்கு பதில் போராடுகிறார் இந்த மாதிரிகளால் முழுவதும் கொடுக்கப்படவில்லை என்பதை நாம் கண்டுபிடிக்கிறோம். இந்த எல்லைகளை கண்டுபிடித்தால், நாம் அட்டவணைகள் மற்றும் பயிற்சி முறைகளில் கூடுதலான ஆராய்ச்சி தேவை', 'uz': "Name Lekin, bu usul muloqat bilan o'rganish (yoki o'rganish) haqida juda ko'rinishi mumkin. Bu tadqida, biz neyrolik ochiq domen dialogi tizimi tomonidan o'rganilgan internal representarini analyzeriz, va bu tashkilotlar asosiy muloqat taʼminotlarini o'rganishga o'rganish uchun o'xshasiz. Bizning natijalarimiz esa, standard ochiq domen dialogi tizimi savollariga javob beradi, murakkab harakat qiladi va boshqa vazifalarga mavzuni aniqlashni anglatadi. Biz shunday o'ylaymiz, muloqat tarkibi muloqat natijasi bu modellar butunlay yordam emas. Bu chegaralarni aniqlash orqali biz arxituvlar va taʼminlov usullarda qoʻshimcha taʼminot kerak va muloqat haqida yaxshi darajada maʼlumotni olish mumkin.", 'vi': 'Cách tiếp cận phổ biến của hộp thoại mở miền phụ thuộc vào việc huấn luyện tận cùng các mô hình thần kinh trên các bộ dữ liệu chat. Tuy nhiên, phương pháp này cung cấp ít thông tin về những gì các mô hình này học (hoặc không học) về hoạt động trong hộp thoại. Trong nghiên cứu này, chúng tôi phân tích các biểu tượng nội bộ học được từ hệ thống hộp thoại thần kinh mở miền và đánh giá chất lượng của các biểu tượng này để học kỹ năng đối thoại cơ bản. Kết quả của chúng tôi cho thấy hệ thống thoại tiêu chuẩn mở miền đấu tranh với câu trả lời câu hỏi, nhận ra sự mâu thuẫn, và quyết định vấn đề đối thoại, trong những nhiệm vụ khác. Chúng tôi cũng thấy rằng bản chất hấp dẫn, hấp dẫn của hộp thoại không hoàn toàn tác động bởi các mô hình này. Bằng cách khám phá những giới hạn này, chúng tôi nhấn mạnh nhu cầu nghiên cứu thêm về kiến trúc và các phương pháp đào tạo có thể nắm bắt thông tin cấp cao về hộp thoại.', 'bg': 'Преобладаващият подход за генериране на диалогов диалог с отворен домейн разчита на цялостно обучение на невронни модели върху набори от данни за чат. Този подход обаче дава малко представа за това какво тези модели научават (или не научават) за участие в диалог. В настоящото изследване анализираме вътрешните представи, научени от невронните диалогови системи с отворен домейн, и оценяваме качеството на тези представи за изучаване на основни разговорни умения. Нашите резултати показват, че стандартните отворени диалогови системи се борят с отговорите на въпроси, извеждането на противоречия и определянето на темата на разговора, наред с други задачи. Също така откриваме, че диалогът не се използва изцяло от тези модели. Изследвайки тези ограничения, ние подчертаваме необходимостта от допълнителни изследвания на архитектурите и методите за обучение, които могат по-добре да улавят информация на високо ниво за диалога.', 'da': 'Den fremherskende tilgang til åbent domæne dialog generation afhænger af end-to-end træning af neurale modeller på chat datasæt. Denne tilgang giver dog kun lidt indsigt i, hvad disse modeller lærer (eller ikke lærer) om at engagere sig i dialog. I dette studie analyserer vi de interne repræsentationer lært af neurale åbne domæne dialogsystemer og evaluerer kvaliteten af disse repræsentationer for at lære grundlæggende samtalefærdigheder. Vores resultater tyder på, at standard åbent domæne dialogsystemer kæmper med at besvare spørgsmål, udlede modsigelse og bestemme emnet samtale, blandt andre opgaver. Vi finder også, at dialogens dyadiske, skiftende natur ikke fuldt ud udnyttes af disse modeller. Ved at undersøge disse begrænsninger fremhæver vi behovet for yderligere forskning i arkitekturer og træningsmetoder, der bedre kan fange information på højt niveau om dialog.', 'nl': 'De overheersende benadering van het genereren van open-domein dialoog is gebaseerd op end-to-end training van neurale modellen op chat datasets. Deze aanpak geeft echter weinig inzicht in wat deze modellen leren (of niet leren) over het aangaan van dialoog. In deze studie analyseren we de interne representaties die worden geleerd door neurale open-domein dialoogsystemen en evalueren we de kwaliteit van deze representaties voor het leren van basis conversatievermogen. Onze resultaten suggereren dat standaard open-domein dialoogsystemen worstelen met het beantwoorden van vragen, het afleiden van tegenstrijdigheden en het bepalen van het onderwerp van gesprek, onder andere taken. We merken ook dat de dyadische, turn-takeng aard van dialoog niet volledig wordt benut door deze modellen. Door deze beperkingen te onderzoeken, benadrukken we de noodzaak van aanvullend onderzoek naar architecturen en trainingsmethoden die informatie op hoog niveau over dialoog beter kunnen vastleggen.', 'hr': 'Predsjedni pristup generaciji dijaloga otvorenog domena oslanja se na obuku neuralnih modela na razgovornim setima podataka. Međutim, ovaj pristup pruža malo uvida o tome što ovi modeli uče (ili ne uče) o učenju u dijalogu. U ovom ispitivanju analiziramo unutrašnje predstave koje su naučili sustavi dijaloga neuronskog otvorenog domena i procjenjivali kvalitetu tih predstavljanja za učenje osnovnih razgovornih vještina. Naši rezultati sugeriraju da se standardni dijalogski sustavi otvorenog domena bore s odgovornim pitanjima, donose kontradikciju i određivanjem teme razgovora, među drugim zadacima. Također smatramo da dijadična priroda, priroda okretanja dijaloga ne potpuno utječe na te modele. Istražujući te ograničenja, naglašavamo potrebu za dodatnim istraživanjem arhitekture i metoda obuke koje mogu bolje uhvatiti informacije o dijalogu na visokoj razini.', 'de': 'Der vorherrschende Ansatz zur Generierung von Open-Domain-Dialogen beruht auf dem durchgängigen Training neuronaler Modelle auf Chat-Datensätzen. Dieser Ansatz gibt jedoch wenig Einblick in das, was diese Modelle über den Dialog lernen (oder nicht lernen). In dieser Studie analysieren wir die internen Repräsentationen, die neuronale Open-Domain-Dialogsysteme erlernen und bewerten die Qualität dieser Repräsentationen für das Erlernen grundlegender Konversationsfähigkeiten. Unsere Ergebnisse deuten darauf hin, dass Standard-Open-Domain-Dialogsysteme unter anderem mit der Beantwortung von Fragen, dem Ableiten von Widersprüchen und der Bestimmung des Gesprächsthema zu kämpfen haben. Wir stellen auch fest, dass die dyadische, bahnbrechende Natur des Dialogs von diesen Modellen nicht voll genutzt wird. Indem wir diese Einschränkungen untersuchen, unterstreichen wir die Notwendigkeit zusätzlicher Forschung zu Architekturen und Trainingsmethoden, die hochrangige Informationen über Dialog besser erfassen können.', 'id': 'pendekatan dominan untuk generasi dialog-domain terbuka bergantung pada latihan akhir-akhir dari model saraf pada set data chat. Namun, pendekatan ini memberikan sedikit pengetahuan tentang apa yang model ini belajar (atau tidak belajar) tentang terlibat dalam dialog. Dalam penelitian ini, kami menganalisis representation internal yang dipelajari oleh sistem dialog saraf domain terbuka dan mengevaluasi kualitas representation ini untuk belajar keterampilan percakapan dasar. Our results suggest that standard open-domain dialog systems struggle with answering questions, inferring contradiction, and determining the topic of conversation, among other tasks.  Kami juga menemukan bahwa alami dialog yang didiadikan, memutar tidak sepenuhnya diperoleh oleh model-model ini. Dengan mengeksplorasi batasan-batasan ini, kami memperhatikan kebutuhan penelitian tambahan dalam arsitektur dan metode pelatihan yang dapat lebih baik menangkap informasi tingkat tinggi tentang dialog.', 'fa': 'دستور بزرگی برای نسل محاورۀ محاورۀ دامنی باز به پایان پایان از مدل\u200cهای عصبی بر مجموعه\u200cهای داده\u200cهای صحبت بستگی دارد. ولی این دستور کمی در مورد آنچه این مدل یاد می\u200cگیرند (یا یاد نمی\u200cگیرند) در مورد مشارکت در محاورش می\u200cدهد. در این مطالعه، ما نمایش\u200cهای داخلی را تحلیل می\u200cکنیم که توسط سیستم\u200cهای محاورۀ محاورۀ دیومین\u200cهای غیر عصبی یاد گرفته\u200cاند و کیفیت این نمایش\u200cها را برای یاد آموزش مهارت\u200cهای بنیادی گفتگوی ارزی نتیجه\u200cهای ما پیشنهاد می\u200cدهند که سیستم\u200cهای محاوره\u200cای استاندارد با جواب سوال\u200cها مبارزه می\u200cکنند، مخالفت\u200cها را تحریک می\u200cکنند، و موضوع گفتگو را در بین دیگر وظیفه\u200cها تعیین می\u200cکنند. ما همچنین پیدا کردیم که طبیعت تغییر پذیرش دیاژدها توسط این مدلها کاملاً تحت تاثیر قرار نیست. با تحقیق این محدودیت، نیازی برای تحقیقات اضافه به معماری و روش آموزش که می\u200cتواند بهتر اطلاعات سطح بالا در مورد محاورش بگیرد را تشکیل دهیم.', 'sw': 'Mtakatifu mkubwa wa uzalishaji wa mazungumzo ya ndani unategemea mafunzo ya mwisho ya mifano ya ubongo katika seti za mazungumzo. Hata hivyo, mbinu hii inatoa uelewa mdogo kuhusu kile ambacho mifano hii hujifunza (au sio kujifunza) kuhusu kushiriki katika mazungumzo. Katika utafiti huu, tunachambua maoni ya ndani yaliyojifunzwa na mfumo wa mazungumzo ya kijamii ulio wazi wa ndani na kutathmini kiwango cha uwakilishi huu kwa ajili ya kujifunza ujuzi wa msingi wa mazungumzo. Matokeo yetu yanapendekeza kwamba mifumo ya mazungumzo ya wazi ya ndani yanapigana na kujibu maswali, kuharibu tofauti, na kuamua mada ya mazungumzo, miongoni mwa kazi nyingine. Pia tunagundua kuwa asili ya mazungumzo ya mabadiliko yanayotokana na mifano hii haijapatikana kabisa. Kwa kutafuta vizuizi hivi, tunaonyesha hitaji la utafiti wa ziada katika majengo na mbinu za mafunzo ambazo zinaweza kupata taarifa za juu kuhusu mazungumzo.', 'ko': '개방역 대화상자 생성의 주요 방법은 채팅 데이터 집합의 신경 모형의 끝에서 끝까지의 훈련에 의존한다.그러나 이러한 모델 학습(또는 학습하지 않음)과 관련된 대화에 참여하는 내용에 대해 이런 방법은 제공하는 견해가 매우 적다.이 연구에서 우리는 신경 개방역 대화 시스템에서 배운 내부 표징을 분석하고 이러한 표징이 기본 회화 기능 학습에 대한 질을 평가했다.우리의 연구 결과에 따르면 표준적인 개방역 대화 시스템은 질문에 대답하고 모순을 추론하며 대화 주제를 확정하는 등 임무에서 매우 어렵다고 한다.우리는 또 이런 모델들이 대화의 이원, 교대 성질을 충분히 이용하지 못했다는 것을 발견했다.이러한 한계를 탐색함으로써 우리는 다이어로그와 관련된 고급 정보를 더욱 잘 포착하기 위해 체계 구조와 교육 방법에 대해 더 많은 연구를 해야 한다고 강조한다.', 'tr': 'Açmak üçin ön bellenen yaklaşyk neural modelleriniň soňky-soňky hatlarynda paýlaşmak üzere ynanýar. Ýöne bu ýagdaý, bu nusgalaryň ne öwrenip (öwrenip bilmeýän) dialogda gatnaşmak hakynda örän az pikir täsir edýär. Bu çalışmada, nöral açık domuz sistemlerinde öğrenmiş iç temsilleri analiz edip, bu temel konuşma becerilerinin kalitesini değerlendiriyoruz. Biziň netijelerimiz standart aç-domeny dijalog sistemalary soraglary jogap bermek, garşy çykmak we sohbet meýdanyny beýleki zadyň arasynda çözmek üçin mücadele edip bilýärler. Biz hem bu nusgalar tarapyndan dyadik, çykarmak dogrusynyň doly çykarmady. Bu çäreleri keşfederek, arhitektura we eğitim ýokary derejesi barada gowy dereje informasiýany çykyp biljek ilatyny ýagtylaşdyrýarys.', 'af': 'Name Maar hierdie toegang verskaf klein insig oor wat hierdie modele leer (of nie leer nie) oor aanteken in dialoog. In hierdie studie, ons analyseer die interne voorstellings wat deur neurale oop-domein dialoog stelsels geleer het en evalueer die kwaliteit van hierdie voorstellings vir die leer van basiese gesprekslyk kunstenaars. Ons resultate stel voorstel dat standaard open-domain dialoog stelsels struikel met antwoord vrae, teenwoordigheid en die onderwerp van gesprek onder ander werke. Ons vind ook dat die dyadiese, draai-neem natuur van dialoog nie volledig deur hierdie modele gebruik word nie. Deur hierdie beperking te ondersoek, verlig ons die behoefte vir addisionele ondersoek binne arkitektuur en onderwerp metodes wat beter hoë vlak inligting oor dialoog kan opneem.', 'sq': 'Përqasja e mbizotërueshme për gjenerimin e dialogut të dominiu të hapur mbështetet në trajnimin nga fundi në fund të modeleve nervore në grupet e të dhënave chat. Megjithatë, kjo qasje ofron pak kuptim për atë që këto modele mësojnë (apo nuk mësojnë) rreth përfshirjes në dialog. Në këtë studim, ne analizojmë përfaqësimet e brendshme të mësuara nga sistemet e dialogut neuronal të dominit të hapur dhe vlerësojmë cilësinë e këtyre përfaqësimeve për mësimin e aftësive bazë të bisedës. Rezultatet tona sugjerojnë se sistemet standard të dialogut të dominiu të hapur luftojnë me përgjigjen e pyetjeve, duke përfshirë kontradiktësinë dhe përcaktimin e temës së bisedës, midis detyrave të tjera. Gjithashtu zbulojmë se natyra dyadike e dialogut nuk është e përdorur plotësisht nga këto modele. Duke eksploruar këto kufizime, ne theksojmë nevojën për kërkime shtesë në arkitektura dhe metoda stërvitjeje që mund të kapin më mirë informacione të nivelit të lartë rreth dialogut.', 'am': 'የዶሜን ትውልድ መክፈት የሚችል ደረጃ በአካባቢው ዳታተሮች ላይ የናውሬል ሞዴላዎችን ለመጨረሻ ይታሰራል፡፡ ነገር ግን ይህች ሥርዓት እነዚህ ምሳሌዎች (ወይም አይማሩም) በማስተካከል የሚማሩትን ነገር ጥቂት አሳብ ያሳየዋል፡፡ በዚህ ትምህርት ውስጥ የናውሬት ክፍት ዲሜን ዳይማር ሲስተማርነው የውይይት ብልሃቶችን እናስተምር፡፡ ፍሬቶቻችን የተከፈቱት ዶሜን ዳይሞክራዊ ጦማሪያዎች ጥያቄዎችን በመመልስ፣ ተቃውሞውን በመግለጽ እና በሌላ ስራ መካከል የንግግርን ጉዳይ መቆጣጠርን እንዲያረጋግጡ ያስባል፡፡ እናም ዲዲዳዲ እና የመስመር አካባቢ እና እነዚህን ምሳሌዎች በሙሉ እንደተደገፈ እናገኛለን፡፡ By exploring these limitations, we highlight the need for additional research into architectures and training methods that can better capture high-level information about dialog.', 'hy': 'Հիմնական մոտեցումը բաց տիեզերքի պատկերների ստեղծման վրա կախված է նյարդային մոդելների վերջ-վերջ ուսումնասիրության վրա խոսակցության տվյալների համակարգերի վրա: Այնուամենայնիվ, այս մոտեցումը շատ քիչ հասկացություն է տալիս այն մասին, թե ինչ են այս մոդելները սովորում (կամ չեն սովորում) խոսակցության մեջ ներգրավվելու մասին: Այս ուսումնասիրության ընթացքում մենք վերլուծում ենք ներքին ներկայացումները, որոնք սովորել են նեյրոնային բաց բնագավառի հաղորդակցման համակարգերի միջոցով, և գնահատում ենք այս ներկայացումների որակը սովորելու հիմնական հաղորդակցման հմտ Մեր արդյունքները ցույց են տալիս, որ ստանդարտ բաց բնագավառի հաղորդակցման համակարգերը պայքարում են պատասխանելու հարցերին, հանգեցնելով հակառակը և որոշելով խոսակցության թեման, այլ խնդիրների միջև: Մենք նաև հայտնաբերում ենք, որ այս մոդելները չեն ամբողջությամբ օգտագործում բախումների դիադիկ բնույթը: By exploring these limitations, we highlight the need for additional research into architectures and training methods that can better capture high-level information about dialog.', 'az': 'Açıq-domena dialogu nəzəriyyəti üçün ən böyük tərzim sohbet verilən qurğularında nöral modellərin təhsil edilməsinə təvəkkül edir. Ancaq bu metod, bu modellərin öyrəndiyi (öyrənmədiyi) məlumatları barəsində çox az fikirləşdirir. Bu təhsil içində, nöral açıq domenin dayalı sistemlərindən öyrənmiş içəri təsirlərini analiz edirik və bu təsirlərin təhsilinin təhsilini təhsil edirik. Bizim sonuçlarımız standart açıq-domen dialoğu sistemləri suallarına cavab vermək, mübahisə etmək və digər işlər arasında danışmaq məsəlinə müvafiq etmək istəyirlər. Biz də elçilərin dyadik, dönüşünün təbiətinin bu modellərdən tamamlanmadığını görürük. Bu limitlərin keşfetməsi ilə, arhitektura və təhsil metodlarına daha yaxşı dərəcəli məlumatları haqqında daha yüksək səviyyə məlumatlarını almaq üçün ehtiyacı yoxdur.', 'bn': 'ডোমেইন ডায়ালগ প্রজন্মের প্রধান প্রশিক্ষণের উপর নির্ভর করে চ্যাট ডাটাসেটে নিউরেল মডেলের শেষ পর্যন্ত প্রশিক্ষণের উপর। তবে এই পদক্ষেপ আলোচনায় অংশগ্রহণের ব্যাপারে এই মডেলগুলো কি শিখেছে (অথবা শিখেন না) সম্পর্কে সামান্য দৃষ্টিভঙ্ এই গবেষণায় আমরা নিউরেল খোলা ডোমেইন ডায়ালগ সিস্টেমের দ্বারা শিক্ষিত ইন্টারনেট প্রতিনিধিদের বিশ্লেষণ করি এবং মৌলিক কথোপকথনের দক্ষতা শ আমাদের ফলাফল পরামর্শ দিয়েছে যে স্বাভাবিক মুক্ত ডোমেইন ডায়ালগ সিস্টেম প্রশ্নের উত্তর দিয়ে লড়াই করে, বিরোধীতা আক্রান্ত করে এবং অন্যান্ আমরা আবিষ্কার করি যে ডায়ালগের প্রকৃতি পুরোপুরি মোডেল দ্বারা প্রতিষ্ঠিত নয়। এই সীমাবদ্ধতা ব্যবহার করে আমরা আর্কিটেক্টার এবং প্রশিক্ষণ পদ্ধতিতে আরও গবেষণার প্রয়োজন উল্লেখ করি যা ডায়ালগ সম্পর্কে উচ্চ স্তরের তথ', 'bs': 'Predsjednik pristupa generaciji dijaloga otvorenog domena oslanja se na obuku neuralnih modela na sete podataka za razgovor. Međutim, ovaj pristup pruža malo uvida o tome šta ovi modeli nauče (ili ne nauče) o učenju u dijalogu. U ovom studiju analiziramo unutrašnje predstave koje su naučili sistemi dijaloga neuronskog otvorenog domena i procjenjivali kvalitetu tih predstavljanja za učenje osnovnih razgovornih vještina. Naši rezultati sugeriraju da se standardni dijalogski sistemi otvorenog domena bore sa odgovornim pitanjima, donose kontradikciju i određuju temu razgovora, među drugim zadacima. Također smatramo da te modele nisu potpuno uticali na dijadičnu prirodu dijaloga. Istražujući te ograničenja, naglašavamo potrebu za dodatnim istraživanjem arhitekture i metoda obuke koje mogu bolje uhvatiti informacije o visokom nivou o dijalogu.', 'cs': 'Převládající přístup k generování dialogů otevřené domény spočívá na komplexním tréninku neuronových modelů na chatových datových sadách. Tento přístup však poskytuje malý přehled o tom, co se tyto modely naučí (nebo ne) o zapojení do dialogu. V této práci analyzujeme vnitřní reprezentace, které se naučí neuronovými otevřenými doménovými dialogovými systémy a hodnotíme kvalitu těchto reprezentací pro učení základních konverzačních dovedností. Naše výsledky naznačují, že standardní otevřené dialogové systémy se kromě jiných úkolů potýkají s odpovědí na otázky, odvozováním rozporů a určováním tématu konverzace. Zjišťujeme také, že dyadická, zvratná povaha dialogu není plně využívána těmito modely. Zkoumáním těchto omezení zdůrazňujeme potřebu dalšího výzkumu architektur a metod školení, které mohou lépe zachytit informace na vysoké úrovni o dialogu.', 'et': 'Valdav lähenemisviis avatud domeeni dialoogi genereerimisele tugineb neuromudelite täielikule koolitusele vestlusandmekogumitel. Selline lähenemisviis annab siiski vähe ülevaadet sellest, mida need mudelid dialoogis osalemise kohta õpivad (või ei õpi). Käesolevas uuringus analüüsime avatud neuraalsete dialoogisüsteemide sisemist esindust ja hindame nende esinduste kvaliteeti põhiliste vestlusoskuste õppimisel. Meie tulemused näitavad, et standardsed avatud domeenilised dialoogisüsteemid võitlevad muu hulgas küsimustele vastamise, vastuolude järeldamise ja vestlusteema määramisega. Samuti leiame, et need mudelid ei võimenda dialoogi düaadilist ja pöördeid tegevat olemust täielikult. Nende piirangute uurimisega rõhutame vajadust täiendavate arhitektuuride ja koolitusmeetodite uurimise järele, mis suudavad paremini koguda kõrgetasemelist teavet dialoogi kohta.', 'fi': 'Pääasiallinen lähestymistapa avoimen verkkotunnuksen dialogin luomiseen perustuu neuromallien kokonaisvaltaiseen koulutukseen chat-dataaineistojen avulla. Tämä lähestymistapa antaa kuitenkin vähän tietoa siitä, mitä nämä mallit oppivat (tai eivät opi) vuoropuheluun osallistumisesta. Tässä tutkimuksessa analysoimme avoimien neurodialogijärjestelmien sisäisiä representaatioita ja arvioimme näiden representaatioiden laatua keskustelun perustaitojen oppimisessa. Tuloksemme viittaavat siihen, että tavalliset avoimen verkkotunnuksen dialogijärjestelmät kamppailevat muun muassa kysymyksiin vastaamisen, ristiriitojen päättelyn ja keskustelun aiheen määrittämisen kanssa. Huomaamme myös, että nämä mallit eivät täysin hyödynnä dialogin dyadista ja käänteentekevää luonnetta. Tutkimalla näitä rajoituksia korostamme tarvetta tehdä lisätutkimuksia arkkitehtuureista ja koulutusmenetelmistä, joilla voidaan paremmin tallentaa korkean tason tietoa dialogista.', 'ca': "L'enfocament predominant a la generació de diàlegs de domini obert es basa en l'entrenament de finals a finals de models neuronals en conjunts de dades de conversa. No obstant això, aquest enfocament proporciona poca comprensió sobre el que aquests models aprenen (o no aprenen) sobre participar en el diàleg. En aquest estudi, analitzem les representacions internes aprengutes pels sistemes de diàleg neural de domini obert i evaluem la qualitat d'aquestes representacions per aprendre habilitats bàsiques de conversació. Our results suggest that standard open-domain dialog systems struggle with answering questions, inferring contradiction, and determining the topic of conversation, among other tasks.  També descobrim que aquests models no utilitzen plenament la naturalesa diàdica i giradora del diàleg. Explorant aquestes limitacions, destaquem la necessitat de recerca adicional sobre arquitectures i mètodes de formació que puguin captar millor informació d'alt nivell sobre el diàleg.", 'jv': 'The prekomiant method to open-domain dialog Generation rests on end-to-end Learning of Neral modes on conversation dataset. Mangkin, dadi iki bakal nesaturan kelas nang sampek kanggo sampek model iki (atawa isih njaluk) babagan ngangge dialog. Nang barêng-barêng iki, kéné ranjelisar kuwi sampeyan sisal karo hal-open-domain sistem kuwi nggawe barang nggawe barang nggawe barang nggawe barang urip kuwi karo hal basa conversatiyonal karo kuwi. Kita pejalongan suggersul sistem sistem Open-domain nggawe barang ngganti responsar question, informang contrast, lan nggunakake tema ngresampsi, sak cara-cara sing wis ana. Awak dhéwé bukané karo diaadik, njuk-ijolan dialog kuwi nggawe barang maneh iki. Nanging kebugakake limiting iki, kita ngubanjur nggawe kanggo ngilanggar aturan tambah karo perusahaan maneh sing bisa ngelambang kelas informasi sing luwih akeh bantuan banjur dialog', 'sk': 'Prevladujoč pristop k ustvarjanju odprtega domena dialoga temelji na celovitem usposabljanju nevronskih modelov na naborih podatkov klepeta. Vendar pa ta pristop omogoča malo vpogleda, kaj se ti modeli naučijo (ali se ne naučijo) o vključevanju v dialog. V tej študiji analiziramo notranje reprezentacije, ki se jih naučijo nevronski dialogni sistemi odprte domene, in ocenimo kakovost teh reprezentacij za učenje osnovnih pogovornih veščin. Naši rezultati kažejo, da se standardni dialogni sistemi odprte domene med drugim borijo z odgovori na vprašanja, sklepanjem protislovja in določanjem teme pogovora. Ugotavljamo tudi, da ti modeli v celoti ne izkoriščajo diadske narave dialoga. Z raziskovanjem teh omejitev poudarjamo potrebo po dodatnih raziskavah arhitektur in metod usposabljanja, ki lahko bolje zajemajo visoko raven informacij o dialogu.', 'ha': "Tsarin da ya ƙaranta zuwa shirin zauren akwatin bayanin akwatin bayani na buɗe-Domen, yana dõgara ga tsarin misãlai na ƙarami zuwa ƙarami kan zane-zane. However, this approach provides little insight as to what these models learn (or do not learn) about engaging in dialog.  A cikin wannan lõkaci, Munã anayya masu akin guda da aka sanar da shi na tsarin zauren akwatin bayanin akwatin da ke buɗe guda kuma munã ƙaddara, sifar sifar waɗannan masu shiryuwa da aka sanar da zane-zane masu basara. MatamayinMu na gaya cewa, tsarin zauren akwatin bayani na daban-bayanin da aka buɗe ta yana ƙara da su karɓa wa masu tambayar, sunã yin kiyaya da sãɓãni, kuma yana yanke muhimman mazaɓa, da wasu aikin dabam. Ana gane cewa zauren zauren akwatin bayani bai zama mai cikakken su ba. Ina ƙiƙira waɗannan tsaro, sai Mu ƙayyade muhimmada a canza tafiti masu ƙaranci zuwa matsayin ayuka da shiryoyin ayuka da za'a iya amfani da masu tsari ga zauren akwatin bayani.", 'he': "הגישה העיקרית לדור דיאלוגים בתחום פתוח תלויה באימון סוף-סוף של דוגמנים עצביים על קבוצות נתונים של צ'אט. עם זאת, הגישה הזאת מספקת מעט הבנה לגבי מה הדוגמנים האלה לומדים (או לא לומדים) על התערבות בדיולוג. במחקר הזה, אנו מנתחים את היציגות הפנימיות שנלמדו על ידי מערכות דיאלוגים עצביים פתוחות ומעריכים את איכות היציגות הללו ללמוד כישורי שיחה בסיסיים. התוצאות שלנו מציעות כי מערכות דיאלוג סטנדרטיות של שטח פתוח מתאבקות עם עניין על שאלות, להוציא התנגדות, ולקבע את נושא השיחה, בין משימות אחרות. אנחנו גם מוצאים שהטבע הדיאדיק, המפוך של הדיולוג לא מוצלח לחלוטין על ידי הדוגמנים האלה. על ידי לחקור את הגבלות האלה, אנו מזכירים את הצורך למחקר נוסף בארכיטקטורות ושיטות אימונים שיכולות יותר לתפוס מידע ברמה גבוהה על דיאלוג.", 'bo': 'The predominant approach to open-domain dialog generation relies on end-to-end training of neural models on chat datasets. ཡིན་ནའང་། ཐབས་ལམ་འདིས་དཔེ་གཞི་འདི་དག་གི་སྐོར་ལས་གླེང་སྒྲུང་ནང་དུ་འཇུག་པའི་མི་འདྲ་བ་སྐོར་དང་མི་ཤེས་ཀྱི་ཡོད། In this study, we analyze the internal representations learned by neural open-domain dialog systems and evaluate the quality of these representations for learning basic conversational skills. ང་ཚོའི་འབྲས་བུ ང་ཚོས་ཀྱང་མཐོང་ནི་བློ་གཏོང་བ་དང་སྤྱིར་བའི་རང་བཞིན་ཡུལ་རྣམས་མེད་འདུག་གིས་མི་འདུག By exploring these limitations, we highlight the need for additional research into architectures and training methods that can better capture high-level information about dialog.'}
