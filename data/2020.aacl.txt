{'en': 'Touch Editing : A Flexible One-Time Interaction Approach for  Translation', 'ar': 'التحرير باللمس: نهج تفاعل لمرة واحدة مرن للترجمة', 'pt': 'Edição de toque: uma abordagem flexível de interação única para tradução', 'es': 'Edición táctil: un enfoque flexible de interacción única para la traducción', 'fr': "Édition tactile\xa0: une approche d'interaction unique flexible pour la traduction", 'ja': 'タッチ編集：翻訳のための柔軟なワンタイムインタラクションアプローチ', 'zh': '摩挲编辑:一次性译交法', 'hi': 'संपादन स्पर्श करें: अनुवाद के लिए एक लचीला एक-बार इंटरैक्शन दृष्टिकोण', 'ru': 'Сенсорное редактирование: гибкий подход к одноразовому взаимодействию для перевода', 'ga': 'Eagarthóireacht Tadhaill: Cur Chuige Solúbtha Aonuaire Idirghníomhaíochta don Aistriúchán', 'ka': 'Name', 'el': 'Επεξεργασία αφής: Μια ευέλικτη προσέγγιση εφάπαξ αλληλεπίδρασης για τη μετάφραση', 'hu': 'Érintőszerkesztés: Rugalmas egyszeri interakciós megközelítés a fordításhoz', 'it': 'Touch Editing: un approccio flessibile di interazione una tantum per la traduzione', 'kk': 'Өңдеу: Аудару үшін бір- бірінші бір- бірінші интерактивтік қатынасы', 'lt': 'Touch Editing: A flexible one-time interaction approach for translation', 'mk': 'Уредување на допир: Флексибилен пристап на едновремена интеракција за превод', 'ms': 'Penyunting Sentuhan: Pendekatan Interaksi Satu-Kali Fleksibel untuk Terjemahan', 'ml': 'തൊടുക്കുന്ന ചിട്ടപ്പെടുത്തുന്നത്: ഒരു സമയത്തിനുള്ള വിവരങ്ങള്\u200d', 'mn': 'Touch Editing: A Flexible One-Time Interaction Approach for Translation', 'no': 'Trykk- redigering: Ein fleksibel enkelt interaksjon- tilgang for omsetjing', 'pl': 'Edycja dotykowa: elastyczne jednorazowe podejście do interakcji w tłumaczeniu', 'ro': 'Editare tactilă: o abordare flexibilă de interacțiune unică pentru traducere', 'sr': 'Pristup za prevod', 'si': 'Name', 'so': 'Touch Editing: A Flexible One-time Interaction Approach for Translation', 'sv': 'Pekredigering: En flexibel engångsstrategi för översättning', 'ta': 'தொடுக்கும் தொகுப்பு: ஒரு நேரத்தில் வெளியேறும் ஒரு இடைவெளி செயல் மொழிபெயர்ப்புக்கு அருகில்', 'ur': 'ٹوچ ایڈیٹینگ: ترجمہ کے لئے ایک دفعہ اضافہ کی تقرب', 'mt': 'Editar tal-Touch: Approċċ flessibbli ta’ Interazzjoni ta’ darba għat-Traduzzjoni', 'uz': 'Comment', 'vi': 'Chạm Sửa: Một phương pháp tương tác thời gian ngắn cho dịch', 'da': 'Touch redigering: En fleksibel engangsinteraktionstilgang til oversættelse', 'nl': 'Touch Editing: een flexibele eenmalige interactie aanpak voor vertaling', 'bg': 'Редактиране на докосване: гъвкав подход за еднократно взаимодействие за превод', 'hr': 'Pristup za prevod', 'de': 'Touch Editing: Ein flexibler, einmaliger Interaktionsansatz für Übersetzungen', 'id': 'Penyunting Sentuhan: Pendekatan Interaksi Sekali Fleksibel untuk Terjemahan', 'fa': 'تغییر تغییر: یک نزدیک تغییر فعالیت یک زمانی برای ترجمه', 'sw': 'Matukio ya Mhariri: Mtandao wa Mitandao ya Mara moja kwa mara kwa ajili ya Tafsiri', 'sq': 'Modifikimi i prekjes: Një metodë fleksible ndërveprimi një-herë për përkthimin', 'ko': '터치 편집: 유연한 일회용 상호작용 번역 방법', 'hy': 'Խոսքի խմբագրում. մեկ անգամ բարդ ինտերակցիոն մոտեցում թարգմանելու համար', 'af': "Touk Redigering: ' n Fleksibel Een- Tyd Interaksie toegang vir Vertaling", 'az': 'T톛rc칲m톛 칲칞칲n Flexible One-Time Interaction Approach', 'tr': 'Touch Editing: A Flexible One-Time Interaction Approach for Translation', 'bn': 'স্পর্শ সম্পাদনা: অনুবাদের জন্য একটি ফ্ল্যামেবল এক-সময় ইন্টারনেশন', 'am': 'ክሊፕቦርዱን ለጥፍ', 'ca': "Editar contactes: Un enfocament flexible d'interacció d'una vegada per a la traducció", 'bs': 'Pristup interakcije za prevod', 'cs': 'Dotykové úpravy: Flexibilní jednorázová interakce při překladu', 'fi': 'Kosketusmuokkaus: Joustava kertaluonteinen lähestymistapa kääntämiseen', 'et': 'Puudutusega redigeerimine: paindlik ühekordne suhtlemisviis tõlkimiseks', 'jv': 'New', 'sk': 'Urejanje na dotik: prilagodljiv pristop za enkratno interakcijo za prevajanje', 'ha': 'KCharselect unicode block name', 'he': 'עורך נגיעה: גישה חד פעולה נוקשה לתרגום', 'bo': 'Touch Editing: A Flexible One-Time Interaction Approach for Translation'}
{'en': 'We propose a touch-based editing method for  translation , which is more flexible than traditional keyboard-mouse-based translation postediting. This approach relies on  touch actions  that users perform to indicate translation errors. We present a dual-encoder model to handle the actions and generate refined translations. To mimic the user feedback, we adopt the TER algorithm comparing between draft translations and references to automatically extract the simulated actions for training data construction. Experiments on translation datasets with simulated editing actions show that our  method  significantly improves original translation of Transformer (up to 25.31 BLEU) and outperforms existing interactive translation methods (up to 16.64 BLEU). We also conduct experiments on post-editing dataset to further prove the robustness and effectiveness of our  method .', 'ar': 'نقترح طريقة تحرير للترجمة تعتمد على اللمس ، وهي أكثر مرونة من الترجمة التقليدية التي تعتمد على الماوس. يعتمد هذا الأسلوب على إجراءات اللمس التي يقوم بها المستخدمون للإشارة إلى أخطاء الترجمة. نقدم نموذجًا مزدوج التشفير للتعامل مع الإجراءات وإنشاء ترجمات محسّنة. لتقليد ملاحظات المستخدم ، نعتمد خوارزمية TER للمقارنة بين ترجمات المسودة والمراجع لاستخراج الإجراءات المحاكية تلقائيًا لبناء بيانات التدريب. تُظهر التجارب على مجموعات بيانات الترجمة مع إجراءات التحرير المحاكاة أن طريقتنا تحسن بشكل كبير الترجمة الأصلية لـ Transformer (حتى 25.31 BLEU) وتتفوق على طرق الترجمة التفاعلية الحالية (حتى 16.64 BLEU). نجري أيضًا تجارب على مجموعة بيانات ما بعد التحرير لإثبات متانة طريقتنا وفعاليتها بشكل أكبر.', 'pt': 'Propomos um método de edição baseado em toque para tradução, que é mais flexível do que a publicação de tradução tradicional baseada em mouse e teclado. Essa abordagem se baseia em ações de toque que os usuários realizam para indicar erros de tradução. Apresentamos um modelo de codificador duplo para lidar com as ações e gerar traduções refinadas. Para imitar o feedback do usuário, adotamos o algoritmo TER comparando entre rascunhos de traduções e referências para extrair automaticamente as ações simuladas para construção de dados de treinamento. Experimentos em conjuntos de dados de tradução com ações de edição simuladas mostram que nosso método melhora significativamente a tradução original do Transformer (até 25,31 BLEU) e supera os métodos de tradução interativa existentes (até 16,64 BLEU). Também realizamos experimentos no conjunto de dados pós-edição para provar ainda mais a robustez e a eficácia do nosso método.', 'es': 'Proponemos un método de edición táctil para la traducción, que es más flexible que la posedición tradicional basada en teclado-ratón. Este enfoque se basa en las acciones táctiles que realizan los usuarios para indicar errores de traducción. Presentamos un modelo de doble codificador para gestionar las acciones y generar traducciones refinadas. Para imitar los comentarios de los usuarios, adoptamos el algoritmo TER que compara entre borradores de traducciones y referencias para extraer automáticamente las acciones simuladas para la construcción de datos de entrenamiento. Los experimentos en conjuntos de datos de traducción con acciones de edición simuladas muestran que nuestro método mejora significativamente la traducción original de Transformer (hasta 25,31 BLEU) y supera a los métodos de traducción interactivos existentes (hasta 16,64 BLEU). También realizamos experimentos sobre la postedición de datos para demostrar aún más la solidez y eficacia de nuestro método.', 'fr': "Nous proposons une méthode d'édition tactile pour la traduction, qui est plus flexible que la post-édition de traduction traditionnelle basée sur le clavier et la souris. Cette approche repose sur les actions tactiles effectuées par les utilisateurs pour signaler les erreurs de traduction. Nous présentons un modèle à double encodeur pour gérer les actions et générer des traductions affinées. Pour imiter les commentaires des utilisateurs, nous adoptons l'algorithme TER qui compare les traductions des brouillons et les références afin d'extraire automatiquement les actions simulées pour la construction des données d'entraînement. Des expériences sur des ensembles de données de traduction avec des actions d'édition simulées montrent que notre méthode améliore considérablement la traduction originale de Transformer (jusqu'à 25,31 BLEU) et surpasse les méthodes de traduction interactives existantes (jusqu'à 16,64 BLEU). Nous menons également des expériences sur la post-édition de jeux de données afin de prouver davantage la robustesse et l'efficacité de notre méthode.", 'ja': '従来のキーボード・マウスによる翻訳後編集よりも柔軟な、タッチベースの翻訳編集方法を提案します。このアプローチは、ユーザーが翻訳エラーを示すために実行するタッチ操作に依存します。私たちは、アクションを処理し、洗練された翻訳を生成するためのデュアルエンコーダモデルを提示します。ユーザーのフィードバックを模倣するために、トレーニングデータ構築のためのシミュレートされたアクションを自動的に抽出するために、草稿翻訳と参照の間で比較するTERアルゴリズムを採用します。模擬編集アクションを使用した翻訳データセットの実験は、当社の方法がTransformerのオリジナル翻訳を大幅に改善し（最大25.31 BLEU ）、既存のインタラクティブ翻訳方法（最大16.64 BLEU ）を上回ることを示しています。また、ポストエディットデータセットの実験を行い、メソッドの堅牢性と有効性をさらに証明しています。', 'zh': '建一本于触摩之法,其变于键盘鼠标者也。 其法赖于用户行者,指授译误。 设一双编码器模样,操作精微译。 拟用户反馈, TER 算校稿译引用,自取模拟操作以练数事。 模拟编辑操实验,吾法著入 Transformer 始(高达 253.1 BLEU),优于见交互式(达 16.64 BLEU)。 又于译后编辑数据集行实验,以证吾法之鲁棒性有效性。', 'hi': 'हम अनुवाद के लिए एक स्पर्श-आधारित संपादन विधि का प्रस्ताव करते हैं, जो पारंपरिक कीबोर्ड-माउस-आधारित अनुवाद पोस्टिटिंग की तुलना में अधिक लचीला है। यह दृष्टिकोण उन स्पर्श क्रियाओं पर निर्भर करता है जो उपयोगकर्ता अनुवाद त्रुटियों को इंगित करने के लिए करते हैं. हम क्रियाओं को संभालने और परिष्कृत अनुवाद उत्पन्न करने के लिए एक दोहरी-एन्कोडर मॉडल प्रस्तुत करते हैं। उपयोगकर्ता प्रतिक्रिया की नकल करने के लिए, हम टीईआर एल्गोरिथ्म को प्रारूप अनुवाद और संदर्भों के बीच तुलना करते हुए स्वचालित रूप से प्रशिक्षण डेटा निर्माण के लिए नकली कार्यों को निकालने के लिए अपनाते हैं। सिम्युलेटेड संपादन कार्यों के साथ अनुवाद डेटासेट पर प्रयोगों से पता चलता है कि हमारी विधि ट्रांसफॉर्मर के मूल अनुवाद (25.31 BLEU तक) में काफी सुधार करती है और मौजूदा इंटरैक्टिव अनुवाद विधियों (16.64 BLEU तक) को मात देती है। हम अपनी विधि की मजबूती और प्रभावशीलता को और साबित करने के लिए पोस्ट-एडिटिंग डेटासेट पर प्रयोग भी करते हैं।', 'ru': 'Мы предлагаем метод сенсорного редактирования для перевода, который является более гибким, чем традиционное размещение перевода с клавиатуры на мышь. Этот подход основан на действиях касания, которые пользователи выполняют, чтобы указать на ошибки перевода. Мы представляем модель двойного кодировщика для обработки действий и создания уточненных переводов. Чтобы имитировать обратную связь с пользователем, мы принимаем алгоритм ТЭР, сравнивающий черновики переводов и ссылки, чтобы автоматически извлечь смоделированные действия для построения обучающих данных. Эксперименты на наборах данных перевода с смоделированными действиями по редактированию показывают, что наш метод значительно улучшает исходный перевод Трансформатора (до 25,31 BLEU) и превосходит существующие интерактивные методы перевода (до 16,64 BLEU). Мы также проводим эксперименты с набором данных после редактирования, чтобы дополнительно доказать надежность и эффективность нашего метода.', 'ga': 'Molaimid modh eagarthóireachta atá bunaithe ar theagmháil don aistriúchán, atá níos solúbtha ná posteagarthóireacht aistriúcháin thraidisiúnta méarchlár-luch-bhunaithe. Braitheann an cur chuige seo ar ghníomhartha tadhaill a dhéanann úsáideoirí chun earráidí aistriúcháin a léiriú. Cuirimid múnla dé-ionchódóra i láthair chun na gníomhartha a láimhseáil agus chun aistriúcháin scagtha a ghiniúint. Chun aithris a dhéanamh ar aiseolas na n-úsáideoirí, glacaimid leis an algartam TER i gcomparáid idir dréacht-aistriúcháin agus tagairtí chun na gníomhartha ionsamhlaithe chun sonraí oiliúna a thógáil a bhaint go huathoibríoch. Léiríonn turgnaimh ar thacair sonraí aistriúcháin le gníomhartha eagarthóireachta ionsamhailte go gcuireann ár modh feabhas suntasach ar bhunaistriúchán Transformer (suas go dtí 25.31 BLEU) agus go sáraíonn sé na modhanna aistriúcháin idirghníomhacha atá ann cheana (suas go dtí 16.64 BLEU). Déanaimid turgnaimh freisin ar thacar sonraí iar-eagarthóireachta chun láidreacht agus éifeachtacht ár modh a chruthú.', 'hu': 'A fordításhoz egy érintő alapú szerkesztési módszert javasolunk, amely rugalmasabb, mint a hagyományos billentyűzetes egér alapú fordítás utószerkesztés. Ez a megközelítés a felhasználók által a fordítási hibák jelzésére végrehajtott érintési műveletekre támaszkodik. Kettős kódoló modellt mutatunk be a műveletek kezelésére és finomított fordítások létrehozására. A felhasználói visszajelzések utánzása érdekében a TER algoritmust alkalmazzuk, amely összehasonlítja a vázlatok fordításait és a hivatkozásokat, hogy automatikusan kivonja a szimulált műveleteket az edzési adatok építéséhez. A szimulált szerkesztési műveletekkel végzett fordítási adatkészletekkel végzett kísérletek azt mutatják, hogy módszerünk jelentősen javítja a Transformer eredeti fordítását (legfeljebb 25,31 BLEU) és felülmúlja a meglévő interaktív fordítási módszereket (legfeljebb 16,64 BLEU). Kísérleteket végzünk utólagos adatkészletekkel is, hogy tovább bizonyítsuk módszerünk robusztusságát és hatékonyságát.', 'el': 'Προτείνουμε μια μέθοδο επεξεργασίας που βασίζεται στην αφή για τη μετάφραση, η οποία είναι πιο ευέλικτη από την παραδοσιακή μεταγραφή με πληκτρολόγιο-ποντίκι. Αυτή η προσέγγιση βασίζεται σε ενέργειες αφής που εκτελούν οι χρήστες για να υποδείξουν λάθη μετάφρασης. Παρουσιάζουμε ένα μοντέλο διπλού κωδικοποιητή για να χειριστεί τις ενέργειες και να δημιουργήσει εκλεπτυσμένες μεταφράσεις. Για να μιμηθούμε την ανατροφοδότηση των χρηστών, υιοθετούμε τον αλγόριθμο που συγκρίνει μεταξύ σχεδίων μεταφράσεων και αναφορών για να εξαγάγουμε αυτόματα τις προσομοιωμένες ενέργειες για την κατασκευή δεδομένων κατάρτισης. Τα πειράματα σε σύνολα δεδομένων μετάφρασης με προσομοιωμένες ενέργειες επεξεργασίας δείχνουν ότι η μέθοδος μας βελτιώνει σημαντικά την αρχική μετάφραση του μετασχηματιστή (έως 25.31 BLEU) και ξεπερνά τις υπάρχουσες διαδραστικές μεθόδους μετάφρασης (έως 16.64 BLEU). Πραγματοποιούμε επίσης πειράματα σε σύνολα δεδομένων μετά την επεξεργασία για να αποδείξουμε περαιτέρω την ανθεκτικότητα και την αποτελεσματικότητα της μεθόδου μας.', 'ka': 'ჩვენ შეგიძლიათ შეცვლის რედაქტირების მეთოდი, რომელიც უფრო გრძნობელია, ვიდრე რედაქტირებული კლავიატურატურატურატურატურატურატურატურატურ ეს პროგრამა დახმარებულია, რომ მომხმარებელი შეცდომის შეცდომის შეცდომის გამოყენება. ჩვენ მხოლოდ ეუ-კოდერის მოდელის გამოყენება, რომელიც მოქმედება და შექმნა განსხვავებული თავსუფლებების შექმნა. მომხმარებელი გახსნა მიმიზემისთვის, ჩვენ TER ალგორიტიმას გავაკეთებთ, რომელიც პროგრამეტს გადაწყვეტილების და რეფენციების შორის შემდეგ ავტომატურად გამოვაკეთება სიმულაციული მო ჩვენი რედაქტირებული მონაცემების გამოცდილება გამოცდილობული მონაცემების გამოცდილობაში, რომელიც ჩვენი მეტი ძალიან უფრო უფრო მეტრინსტრუქტირების ორიგინალური გადაწყვეტილება (25,31 BLEU) და გადა ჩვენ ასევე ექსპერიმენტები გავაკეთებთ მონაცემების მონაცემების შესახებ, რომ ჩვენი მეთოდის ძალიან ძალიან და ეფექტიურობის შესახებ.', 'it': "Proponiamo un metodo di editing touch-based per la traduzione, che è più flessibile rispetto al tradizionale post-editing basato su tastiera. Questo approccio si basa su azioni touch eseguite dagli utenti per indicare errori di traduzione. Presentiamo un modello dual-encoder per gestire le azioni e generare traduzioni raffinate. Per imitare il feedback degli utenti, adottiamo l'algoritmo TER di confronto tra traduzioni di bozze e riferimenti per estrarre automaticamente le azioni simulate per la costruzione dei dati di allenamento. Esperimenti su set di dati di traduzione con azioni di editing simulate dimostrano che il nostro metodo migliora significativamente la traduzione originale di Transformer (fino a 25,31 BLEU) e supera i metodi di traduzione interattiva esistenti (fino a 16,64 BLEU). Conduciamo anche esperimenti su set di dati post-editing per dimostrare ulteriormente la robustezza e l'efficacia del nostro metodo.", 'kk': 'Біз аудармалардың touch- негіздеген өзгерту әдісін ұсынамыз. Бұл әдімгі пернетақта- тышқанның негіздеген аудармалардың орналасуынан артық. Бұл жағдай пайдаланушылардың аудармалардың қатесін көрсету үшін әрекеттеріне тәуелді. Біз әрекеттерді басқару және түзетілген аудармаларды құру үшін екі кодер үлгісін келтіреміз. Пайдаланушының қайталануын түсіндіру үшін, мәліметтерді құру үшін өзгертілген әрекеттерді автоматты түрде тарқату үшін TER алгоритмін қолданамыз. Орындалған өңдеу әрекеттері туралы аудару деректер жиындарының тәжірибесі Трансформацияның бастапқы аударымызды (25, 31 BLEU дегенге дейін) және интерактивті аудару әдістерінің (16, 64 BLEU дегенге дейін) жо Сонымен қатар, өзгерту деректер жиынынан кейін өзгерту тәжірибелерін өзгертіп тәжірибелеріміздің әдісіміздің құндылығын және ең әсер етіктер', 'ml': 'We propose a touch-based editing method for translation, which is more flexible than traditional keyboard-mouse-based translation postediting.  @ info: whatsthis പ്രവര്\u200dത്തനങ്ങളെ കൈകാര്യം ചെയ്യാനും വിശദീകരിച്ച വിവരങ്ങള്\u200d ഉണ്ടാക്കാനും നമ്മള്\u200d രണ്ട് കോഡെര്\u200d മോഡല്\u200d ക ഉപയോക്താവിന്റെ ഫിഡിബ്ബാക്കിനെ മൈക്ക് ചെയ്യാന്\u200d വേണ്ടി ടെആര്\u200d ആല്\u200dഗോരിത്മ് ഉപയോഗിക്കുന്നു. പരിശീലനത്തിനുള്ള പരിശീലനത്തിനുള് ട്രാന്\u200dസ്ഫോര്\u200dഫിന്\u200dറെ അടിസ്ഥാനത്തില്\u200d നിന്നും നിലവിലുള്ള interactive translation methods (16. 64 BLEU വരെ ഉള്ള) പരിശോധന നടത്തുന്നതില്\u200d പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു. പിന്നീട് ചിട്ടപ്പെടുത്തുന്ന ഡാറ്റാസെറ്റില്\u200d ഞങ്ങള്\u200d പരീക്ഷണങ്ങള്\u200d പ്രവര്\u200dത്തിക്കുന്നു. നമ്മുടെ രീതിയി', 'lt': 'Siūlome, kad vertimo raštu redakcijos metodas būtų grindžiamas kontaktiniu būdu, kuris būtų lankstesnis nei tradicinis vertimo raštu, grindžiamu klaviatūra pele, redakcija. Šis metodas grindžiamas kontaktiniais veiksmais, kuriuos naudotojai atlieka rodydami vertimo klaidas. We present a dual-encoder model to handle the actions and generate refined translations.  Siekiant imituoti naudotojo grįžtamąją informaciją, mes priimame TER algoritmą, palyginantį vertimų projektus ir nuorodas, kad automatiškai ištrauktų modeliuojamus veiksmus rengiant duomenis. Eksperimentai dėl vertimo duomenų rinkinių su modeliuojamais redagavimo veiksmais rodo, kad mūsų metodas gerokai pagerina pradinį Transformer vertimą (iki 25,31 BLEU) ir atitinka esamus interaktyvius vertimo metodus (iki 16,64 BLEU). Taip pat atliekame eksperimentus dėl duomenų rinkinio po redakcijos, kad toliau įrodytume mūsų metodo patikimumą ir veiksmingumą.', 'ms': 'Kami cadangkan kaedah penyuntingan berdasarkan sentuhan untuk terjemahan, yang lebih fleksibel daripada terjemahan tradisional berdasarkan papan kekunci tetikus. pendekatan ini bergantung pada tindakan sentuhan yang pengguna lakukan untuk menunjukkan ralat terjemahan. Kami perkenalkan model pengekod-dua untuk mengendalikan tindakan dan menghasilkan terjemahan terjemahan. Untuk meniru balas balik pengguna, kami menerima algoritma TER yang membandingkan antara terjemahan drpd dan rujukan untuk secara automatik mengekstrak tindakan simulasi untuk pembangunan data latihan. Experiments on translation datasets with simulated editing actions show that our method significantly improves original translation of Transformer (up to 25.31 BLEU) and outperforms existing interactive translation methods (up to 16.64 BLEU).  Kami juga melakukan eksperimen pada set data pos-edisi untuk membuktikan lebih lanjut kepekatan dan kegunaan kaedah kami.', 'mk': 'We propose a touch-based editing method for translation, which is more flexible than traditional keyboard-mouse-based translation postediting.  Овој пристап се потпира на активностите кои корисниците ги извршуваат за да индицираат грешки во преводот. Презентираме модел со двојен кодер за да се справи со акциите и да се генерира рафиниран превод. За да ја имитираме реакцијата на корисникот, го усвоивме тер алгоритмот во споредба помеѓу нацрт-преводи и референции за автоматски да ги извадиме симулираните акции за обука на изградба на податоци. Експериментите на датотеките за превод со симулирани акции за уредување покажуваат дека нашиот метод значително го подобрува оригиналниот превод на Трансформерот (до 25,31 БЛЕ) и ги надминува постојните интерактивни методи за превод (до 16,64 БЛЕ). Ние, исто така, спроведуваме експерименти на постуредувачкиот податок за понатамошно да ја докажеме силноста и ефикасноста на нашиот метод.', 'no': 'Vi foreslår ein tekstmetode for omsetjing som er fleksibel enn tradisjonell posting av omsetjing med tastaturbasert muse. Denne tilnærminga er avhengig av kontakthandlingar som brukarar utfører for å visa omsetjingsfeilar. Vi presenterer ein dobbelkodingsmodell for å handtera handlingane og laga refinerte omsetjingar. For å mimisera brukaren tilbakemeldinga, kan vi bruka TER-algoritmen som sammenlignar mellom prosjektet av omsetjingar og referanser til å automatisk pakka ut simulerte handlingane for opplæring av datakonstruksjon. Eksperimentar på omsetjingsdata med simulerte redigeringshandlingar viser at metoden vårt betydelig forbedrar originalt omsetjing av Transformer (opp til 25,31 BLEU) og utfører eksisterande interaktive omsetjingsmetoder (opp til 16,64 BLEU). Vi gjer også eksperimenter på datasettet etter redigering for å bevise støtte og effektiviteten av metoden vårt.', 'pl': 'Proponujemy metodę edycji dotykowej do tłumaczeń, która jest bardziej elastyczna niż tradycyjna postedycja tłumaczeń oparta na klawiaturze myszy. To podejście opiera się na działaniach dotykowych wykonywanych przez użytkowników w celu wskazania błędów tłumaczenia. Prezentujemy model dwukodera do obsługi działań i generowania dopracowanych tłumaczeń. Aby naśladować opinie użytkowników, przyjmujemy algorytm TER porównujący projekty tłumaczeń i odniesień, aby automatycznie wyodrębnić symulowane działania do budowy danych treningowych. Eksperymenty na zbiorach danych tłumaczeniowych z symulowanymi działaniami edycyjnymi pokazują, że nasza metoda znacznie poprawia oryginalne tłumaczenie Transformera (do 25.31 BLEU) i przewyższa istniejące interaktywne metody tłumaczenia (do 16.64 BLEU). Przeprowadzamy również eksperymenty na postedycji zbioru danych, aby jeszcze bardziej udowodnić solidność i skuteczność naszej metody.', 'mn': 'Бид өөрсдийгөө хөрөнгө оруулахын тулд суурилсан өөрчлөлтийн аргыг санал дэвшүүлнэ. Энэ нь уламжлалтын клавиатур-хулганаас суурилсан хөрөнгө оруулах арга юм. Энэ арга баримт хэрэглэгчид орчуулах алдаа гаргахад хийдэг хүчний үйл ажиллагаанд хамаарна. Бид эдгээр үйл ажиллагааг удирдаж, шинэчлэгдсэн орнуудыг бий болгох хоёр кодлогч загварыг тайлбарлаж байна. Хэрэглэгчдийн хариултыг дүрслэхийн тулд бид TER алгоритмыг өгөгдлийн барилгын сургалтын зохион байгуулалтыг автоматжуулахын тулд харьцуулахын тулд автоматжуулсан үйл ажиллагааг ашигладаг. Төгсгөл өгөгдлийн сангийн шинжлэх ухааны туршилтууд нь бидний арга нь Төгсгөлдөгч (25.31 БЛЕУ хүртэл) эхний орнуудын орнуудын орнуудын орнуудын орнуудын орнуудын хөгжүүлэлтийг илүү сайн сайжруулж, интерактив орну Мөн бид өөрсдийн арга замын хүчтэй, үр дүнтэй байдлыг баталахын тулд дараагийн өгөгдлийн сангийн дараах туршилтыг хийдэг.', 'ro': 'Propunem o metodă de editare tactilă pentru traducere, care este mai flexibilă decât posteditarea tradițională a traducerii bazată pe tastatură-mouse. Această abordare se bazează pe acțiuni tactile efectuate de utilizatori pentru a indica erorile de traducere. Vă prezentăm un model dual-encoder pentru a gestiona acțiunile și a genera traduceri rafinate. Pentru a imita feedback-ul utilizatorului, adoptăm algoritmul TER care compară între traducerile proiectelor și referințele pentru a extrage automat acțiunile simulate pentru construirea datelor de formare. Experimentele pe seturi de date de traducere cu acțiuni de editare simulate arată că metoda noastră îmbunătățește semnificativ traducerea originală a Transformer (până la 25,31 BLEU) și depășește metodele de traducere interactivă existente (până la 16,64 BLEU). De asemenea, efectuăm experimente pe seturi de date post-editare pentru a dovedi în continuare robustețea și eficiența metodei noastre.', 'sr': 'Predlažemo metodu editiranja na dodiru za prevod, koja je fleksibilnija od tradicionalnog postizanja prevoda na tastaturi na mišu. Ovaj pristup se oslanja na dodirne akcije koje korisnici izvode kako bi pokazali greške prevođenja. Predstavljamo dvokoderski model kako bi se bavili akcijama i stvorili refinansirane prevode. Da bi imitirali povratku korisnika, usvojili smo algoritam TER u usporedbi između projekta prevoda i referencija da bi automatski izvukli simulirane akcije za izgradnju podataka. Eksperimenti o setima prevođenja podataka sa simulisanim redakcijama pokazuju da naša metoda značajno poboljšava originalni prevoz transformera (do 25,31 BLEU) i iznosi postojeće interaktivne metode prevođenja (do 16,64 BLEU). Takoðe provodimo eksperimente o setu podataka za posteditanje kako bi dalje dokazali robustnost i efikasnost našeg metoda.', 'so': 'Waxaan soo jeedaynaa qoraal tahriri oo ku saleysan taabasho, taasoo ka sii flexin badan turjumaadda caadiga ah oo ku qoran qoraalka qoraalka muse-based. Markaas qaababkan waxay ku xiran tahay falimaha xiriirka, kuwaas oo isticmaalayaasha sameeya si ay u muujiyaan qalbiyada turjumidda. We present a dual-encoder model to handle the actions and generate refined translations.  Si aan u gaarno feedbacyada isticmaalaha, waxaynu u qaadannaa Algorithm TER oo u barbareysanaya qoraalka turjumaadda iyo soo jeedidda, si aan automatic uga soo bixino falimaha la similanayo oo loo sameynayo dhismaha danbiyada. Imtixaan ku saabsan macluumaadka turjumaadda oo simulated editing actions shows that methodeennu significantly improves the original translation of Transformer (up to 25.31 BLEU) and outperforms existing interactive translation methods (up to 16.64 BLEU). Sidoo kale waxaynu sameynaa imtixaamo ku saabsan sawirida macluumaadka ka dib si aan ugu caddeyno waxyaabaha dhaqdhaqaalaha iyo waxqabashada qaababkayaga.', 'si': 'අපි පරිවර්තනය වෙනුවෙන් අතුරුද්ධ සංවේදනය විධානයක් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා, ඒක පාරමාන්\u200dය කීබ Name අපි ක්\u200dරියාව පාලනය කරන්න සහ ප්\u200dරතික්\u200dරියාත්මක කරන්න දුවල් කෝඩාර් මොඩේල් එකක් පෙන්වන්න. භාවිතා ප්\u200dරතිචාරකය ප්\u200dරතිචාරයක් මයිමික් කරන්න, අපි TER ඇල්ගෝරිතම් එක ප්\u200dරතිචාර කරනවා ක්\u200dරියාක්\u200dෂණය සහ ප්\u200dරතිචාරකය පරිවර්තන දත්ත සෙට්ටුවේ පරීක්ෂණය පෙන්වන්න පුළුවන් අපේ විධානය විශේෂයෙන් පරිවර්තන කරන්න පුළුවන් පරිවර්තන කරන්න (25.31 BLUE වලට) ස අපි පස්සේ සංපාදනය කරන්න දත්ත සූදානයට පරීක්ෂණය කරන්න ප්\u200dරයෝජනය කරනවා අපේ විධානයේ ශක්තිමතාවය සහ හැකිම', 'sv': 'Vi föreslår en touch-baserad redigeringsmetod för översättning, som är mer flexibel än traditionell keyboard-musbaserad översättning postredigering. Detta tillvägagångssätt bygger på pekåtgärder som användare utför för att indikera översättningsfel. Vi presenterar en dual-encoder modell för att hantera åtgärderna och generera förfinade översättningar. För att efterlikna användarfeedback använder vi TER-algoritmen som jämför mellan utkastöversättningar och referenser för att automatiskt extrahera simulerade åtgärder för konstruktion av träningsdata. Experiment på översättningsdata med simulerade redigeringsåtgärder visar att vår metod avsevärt förbättrar originalöversättning av Transformer (upp till 25,31 BLEU) och överträffar befintliga interaktiva översättningsmetoder (upp till 16,64 BLEU). Vi genomför även experiment på efterredigeringsdata för att ytterligare bevisa robustheten och effektiviteten i vår metod.', 'ur': 'ہم ترجمہ کے لئے ایک ٹونچ بنیادی ایڈینگ طریقہ پیشنهاد کرتے ہیں، جو سنتی کیبوریڈ-ماوس بنیادی ترجمہ پوسٹینگ سے زیادہ مہربانی ہے. This approach relies on touch actions that users perform to indicate translation errors. ہم ایک دوئل کوڈر موڈل کو پیش کریں گے کہ عمل کو ادارہ کریں اور پاکیزہ ترجمہ پیدا کریں۔ استعمال فیڈبک کے مطابق، ہم نے ڈرافوٹ ترجمن اور ارتباطات کے درمیان تفریق کی TER الگوریتم کو استعمال کیا ہے کہ ڈیٹا بنانے کے لئے سیمولیٹ کیے ہوئے عمل کو اٹھا سکیں۔ ترجمہ ڈیٹ سٹ کی تجربیات سیمالیٹ ایڈیٹ کیٹ کیٹ کے ساتھ دکھائی جاتی ہے کہ ہمارا طریقہ معمولی طور پر ترجمہ ترجمہ کرتا ہے (25.31 BLEU تک) اور موجود مختلف ترجمہ طریقے (16.64 BLEU تک) سے زیادہ اضافہ کرتا ہے۔ ہم اس طرح اپنے طریقے کی مضبوطی اور فعالیت کی ثابت کرنے کے لئے پوسٹ ویڈیٹ ڈیٹ سٹ کے بارے میں بھی آزمائش کرتے ہیں.', 'ta': 'மொழிபெயர்ப்பிற்கான தொடர்பு அடிப்படையிலான தொகுப்பு முறைமையை நாம் பரிந்துரைக்கிறோம், அது மரபார்ந்த விசைப்பல @ info நாம் செயல்களை கையாளும் மற்றும் பிரதிபலிக்கப்பட்ட மொழிபெயர்ப்புகளை உருவாக்க ஒரு இரு குறியீட்டு மாத பயன்படுத்துபவர் செலுத்துவதற்கு, வரைவு மொழிபெயர்ப்புகள் மற்றும் குறிப்புகளுக்கு இடையே ஒப்பிடும் TER முறைமையை நாம் எடுத்து தானாகவே பாவன Name பின்தொகுப்பு தகவல் அமைப்பில் நாம் சோதனைகளை செய்கிறோம் மேலும் எங்கள் முறைமையின் தொகுப்பு மற்றும் விள', 'mt': 'Aħna nipproponu metodu ta’ editjar ibbażat fuq il-kuntatt għat-traduzzjoni, li huwa aktar flessibbli mit-traduzzjoni tradizzjonali bbażata fuq il-keyboard-mouse postediting. Dan l-approċċ jiddependi fuq azzjonijiet ta’ kuntatt li l-utenti jwettqu biex jindikaw żbalji fit-traduzzjoni. We present a dual-encoder model to handle the actions and generate refined translations.  To mimic the user feedback, we adopt the TER algorithm comparing between draft translations and references to automatically extract the simulated actions for training data construction.  Experiments on translation datasets with simulated editing actions show that our method significantly improves original translation of Transformer (up to 25.31 BLEU) and outperforms existing interactive translation methods (up to 16.64 BLEU).  Inwettqu wkoll esperimenti dwar sett ta’ dejta ta’ wara l-edizzjoni biex nipprovaw aktar ir-robustezza u l-effettività tal-metodu tagħna.', 'uz': "We propose a touch-based editing method for translation, which is more flexible than traditional keyboard-mouse-based translation postediting.  @ info: whatsthis @ info: whatsthis Name @ info Biz o'zgarishdan keyingi maʼlumotlar tarkibini bajaramiz va usulidagi o'zgarishni va ishlatishni davom etish uchun.", 'vi': 'Chúng tôi đề xuất một phương pháp sửa chữa gấp đôi để dịch chuyển, nó còn linh hoạt hơn cả cách dịch chuyển con chuột bàn phím truyền thống. Phương pháp này dựa trên những hành động liên quan mà người dùng thực hiện để chỉ ra lỗi dịch. Chúng tôi có một mô hình mã hóa kép để xử lý các hành động và tạo ra dịch thuật phức tạp. Để bắt chước phản hồi của người dùng, chúng tôi sử dụng thuật to án TER so sánh giữa bản dịch nháp và các chỉ dẫn để tự động trích các hành động mô phỏng để đào tạo dữ liệu. Thí nghiệm trên các tập tin dịch với các thao tác soạn thảo mô phỏng cho thấy rằng phương pháp của chúng ta cải thiện bản dịch phiên bản gốc của Transformer (tới 25.31 bleU) và hoàn thành các phương pháp dịch chuyển tương tác tồn tại (tới 16.64 bleU). Chúng tôi cũng tiến hành thí nghiệm trên tập tin sau khi sửa xong để chứng minh tính bền vững và hiệu quả của phương pháp.', 'bg': 'Предлагаме метод за редактиране, базиран на сензор, който е по-гъвкав от традиционния постредакционен превод, базиран на клавиатура и мишка. Този подход разчита на действия с докосване, които потребителите извършват, за да показват грешки в превода. Представяме модел с двоен кодер за справяне с действията и генериране на рафинирани преводи. За да имитираме обратната връзка на потребителите, ние възприемаме алгоритъма сравняващ между чернови преводи и препратки, за да извлечем автоматично симулираните действия за изграждане на данни за обучение. Експерименти с набори от данни за преводи със симулирани действия за редактиране показват, че методът ни значително подобрява оригиналния превод на трансформатора (до 25.31) и превъзхожда съществуващите интерактивни методи за превод (до 16.64). Също така провеждаме експерименти с набор от данни след редактиране, за да докажем допълнително здравината и ефективността на нашия метод.', 'hr': 'Predlažemo metodu editiranja na dodiru za prevod, koja je fleksibilnija od tradicionalnog prevoda na klavijaturi na mišu. Ovaj pristup se oslanja na dodirne akcije koje korisnici čine kako bi pokazali greške prevođenja. Predstavljamo dvokoderski model kako bi se riješili akcije i stvorili rafinirane prevode. Da bi imitirali povratku korisnika, usvojili smo algoritam TER-a u usporedbi između nacrta prevoda i referencija na automatsku izvlačenje simuliranih akcija za izgradnju podataka o obuci. Eksperimenti o setima podataka prevođenja sa simuliranim redakcijama pokazuju da naša metoda značajno poboljšava originalni prevoz transformera (do 25,31 BLEU) i iznosi postojeće interaktivne metode prevođenja (do 16,64 BLEU). Također provodimo eksperimente o postavljanju podataka kako bi dalje dokazali robustnost i učinkovitost našeg metoda.', 'nl': 'We stellen een touch-based bewerkingsmethode voor vertaling voor, die flexibeler is dan traditionele toetsenbord-muis-gebaseerde vertaling postediting. Deze aanpak is gebaseerd op aanraakacties die gebruikers uitvoeren om vertaalfouten aan te geven. We presenteren een dual-encoder model om de acties af te handelen en verfijnde vertalingen te genereren. Om de feedback van de gebruiker na te bootsen, gebruiken we het TER-algoritme dat vergelijkt tussen conceptvertalingen en referenties om automatisch de gesimuleerde acties voor de constructie van trainingsgegevens te extraheren. Experimenten met vertaaldatasets met gesimuleerde bewerkingsacties tonen aan dat onze methode de originele vertaling van Transformer aanzienlijk verbetert (tot 25.31 BLEU) en bestaande interactieve vertaalmethoden (tot 16.64 BLEU) overtreft. We voeren ook experimenten uit op post-editing dataset om de robuustheid en effectiviteit van onze methode verder te bewijzen.', 'da': 'Vi foreslår en berøringsbaseret redigeringsmetode til oversættelse, som er mere fleksibel end traditionel tastatur-musebaseret oversættelse postredigering. Denne tilgang er baseret på berøringshandlinger, som brugerne udfører for at angive oversættelsesfejl. Vi præsenterer en dual-encoder model til at håndtere handlingerne og generere raffinerede oversættelser. For at efterligne brugerens feedback anvender vi TER algoritmen, der sammenligner mellem udkastsoversættelser og referencer for automatisk at udtrække de simulerede handlinger til opbygning af træningsdata. Eksperimenter med oversættelsesdatasæt med simulerede redigeringsaktioner viser, at vores metode forbedrer original oversættelse af Transformer betydeligt (op til 25,31 BLEU) og overgår eksisterende interaktive oversættelsesmetoder (op til 16,64 BLEU). Vi gennemfører også eksperimenter med post-redigering datasæt for yderligere at bevise robustheden og effektiviteten af vores metode.', 'de': 'Wir schlagen eine Touch-basierte Bearbeitungsmethode für Übersetzungen vor, die flexibler ist als herkömmliche tastaturmausbasierte Übersetzungs-Nachbearbeitung. Dieser Ansatz basiert auf Touch-Aktionen, die Benutzer ausführen, um Übersetzungsfehler anzuzeigen. Wir präsentieren ein Dual-Encoder-Modell, um die Aktionen zu handhaben und verfeinerte Übersetzungen zu generieren. Um das Benutzerfeedback nachzuahmen, verwenden wir den TER-Algorithmus, der zwischen Entwurfsübersetzungen und Referenzen vergleicht, um die simulierten Aktionen für die Konstruktion von Trainingsdaten automatisch zu extrahieren. Experimente an Übersetzungsdatensätzen mit simulierten Bearbeitungsaktionen zeigen, dass unsere Methode die Originalübersetzung von Transformer signifikant verbessert (bis 25.31 BLEU) und bestehende interaktive Übersetzungsmethoden (bis 16.64 BLEU) übertrifft. Wir führen auch Experimente an Post-Editing-Datensätzen durch, um die Robustheit und Effektivität unserer Methode weiter zu belegen.', 'id': 'Kami mengusulkan metode penyuntingan berdasarkan sentuhan untuk terjemahan, yang lebih fleksibel dari tradisional penyuntingan keyboard-mouse. pendekatan ini bergantung pada tindakan sentuhan yang dilakukan pengguna untuk menunjukkan kesalahan terjemahan. Kami mempersembahkan model dua pengekode untuk menangani tindakan dan menghasilkan terjemahan yang sempurna. Untuk meniru feedback pengguna, kami mengadopsi algoritma TER yang membandingkan antara draft terjemahan dan referensi untuk secara otomatis mengekstraksi tindakan simulasi untuk latihan konstruksi data. Eksperimen pada set data terjemahan dengan tindakan penyuntingan simulasi menunjukkan bahwa metode kami meningkatkan terjemahan asli Transformer (sampai 25,31 BLEU) dan melebihi metode terjemahan interaktif yang ada (sampai 16,64 BLEU). We also conduct experiments on post-editing dataset to further prove the robustness and effectiveness of our method.', 'fa': 'ما پیشنهاد می\u200cکنیم روش ویرایش\u200cسازی بر پایه\u200cی لمس برای ترجمه، که بیشتر از ترجمه\u200cسازی بر پایه\u200cی کلید-موش\u200cهای سنتی است. این روش بر روی کارهای لمس که کاربران برای نشان دادن خطاهای ترجمه انجام می دهند بستگی دارد. ما یک مدل دوگانه رمزگر را برای کنترل عمل و تولید ترجمه\u200cهای پاکیزه پیشنهاد می\u200cکنیم. برای تصویر بازگشت کاربر، الگوریتم TER را در مقایسه بین پروژه ترجمه\u200cها و ارتباطات برای استفاده از کارهای شبیه\u200cسازی برای ساختن داده\u200cهای آموزش می\u200cکنیم. تجربه\u200cها در مجموعه داده\u200cهای ترجمه با کارهای ویرایش شبیه\u200cسازی نشان می\u200cدهند که روش ما به طور معنی ترجمه اصلی ترجمه\u200cکننده\u200cی ترجمه\u200cکننده (تا ۲۵.۳۱ BLEU) را بهتر می\u200cکند و روش\u200cهای ترجمه\u200cکننده\u200cی متفاوتی موجود (تا ۱ ما همچنین آزمایش\u200cها را در مجموعه\u200cی داده\u200cهای بعد از ویرایش انجام می\u200cدهیم تا بیشتر ثابت کنند استعداد و فعالیت روش ما.', 'sw': 'Tunazipendekeza mbinu ya kuhariri inayotokana na msingi wa taarifa kwa kutafsiri, ambayo ni yenye ubunifu zaidi ya tafsiri ya kitamaduni yenye msingi wa mifusi. Hatua hii inategemea vitendo vya taabu ambavyo watumiaji wanafanya kazi ili kuonyesha makosa ya kutafsiri. Tunaweza kutengeneza muundo wa kodi mbili ili kukabiliana na matendo na kutengeneza tafsiri zilizotafsiriwa. Kwa kutumia maoni ya mtumiaji, tunatumia utambulisho wa TER ukilinganisha kati ya rasimu za tafsiri na maoni yanayohusu kutengeneza hatua zilizofanana kwa ajili ya ujenzi wa data. Majaribio kuhusu taarifa za kutafsiri kwa kutumia hatua za kuhariri zinaonyesha kuwa njia yetu inaboresha tafsiri ya asili ya Tafsiri (hadi 25.31 BLEU) na inafanya mbinu za tafsiri zinazohusiana na moja kwa moja (hadi 16.64 BLEU). Pia tunafanya majaribio katika seti ya taarifa za baada ya kuhariri ili kuonesha zaidi ubakaji na ufanisi wa njia yetu.', 'tr': 'Biz özümize touch tabanly bir taryşma yöntemi teklip edip bilýäris. Bu däpli-täsirden, syçan tabanly terjime taýýarlamak üçin fleksibdir. Bu approach ullançylar terjime hatalaryny görkezmek üçin edip duran elleşmelere ynanýar. Biz bu işleri başarmak üçin iki ködleme modelini saýlaýrys we taýýarlanan terjimeleri döretýäris Ullançylaryň Feedbackyny mimoňlaşdyrmak üçin, biz TER algoritmini, faýllary terjime etmek üçin süýtgetmek üçin öz-özüne golaýlanýan emelleri çykarmak üçin gurlap kabul edip kabul edip görýäris. Simüle edilen edirmek emelleri bilen terjime eden veri setirlerinde örän çykyşlar görkezilýän çykyşlarymyz terjime edip görkezilýän çykyşlarymyz (25.31 BLEU we olara çevrilýän terjime metodlarymyz üstine çykarýar (16.64 BLEU çevrine çevril Mundan soňra veri setirini edip bilmek üçin synaglarymyzy çykarýarys.', 'sq': 'Ne propozojmë një metodë modifikimi për përkthimin bazuar në prekje, e cila është më fleksible se përkthimi tradicional bazuar në tastierë miu. Ky qasje mbështetet në veprimet e prekjes që përdoruesit kryejnë për të treguar gabimet e përkthimit. Ne paraqesim një model me dy kodues për të trajtuar veprimet dhe për të gjeneruar përkthime të rafinuara. Për të imituar reagimin e përdoruesit, ne miratojmë algoritmin TER që krahason midis projektit të përkthimeve dhe referencave për të nxjerrë automatikisht veprimet e simuluara për trajnimin e ndërtimit të të dhënave. Eksperimentet në grupet e të dhënave të përkthimit me veprime të simuliuara të ndryshimit tregojnë se metoda jonë përmirëson ndjeshëm përkthimin origjinal të Transformer (deri në 25.31 BLEU) dhe përmirëson metodat ekzistuese interaktive të përkthimit (deri në 16.64 BLEU). Ne gjithashtu kryejmë eksperimente në grupin e të dhënave të posteditimit për të provuar më tej fuqinë dhe efektshmërinë e metodës sonë.', 'am': 'ለትርጓሜ የተደረገውን የዳስስ ማቀናጃ ማቀናጃ ማድረግ እናዘጋጀዋለን፡፡ ይህ ሥርዓት በተርጉም ስህተት ለማሳየት የሚጠቀሙት ተጠቃሚዎች በሚያደርጉት ላይ በሚያስተካክሉ ሥራ ላይ ነው። ሁለተኛ የሆሄደውን ተርጓሚዎች እና ትርጓሜዎችን ለመቀበል እናደርጋለን፡፡ በተጠቃሚ መልዕክት ለመቀላቀል፣ በጽሑፉ ትርጉም እና በተለየ ትርጉም እና በተለየ ትምህርት መሠረት ላይ የተመሳሳይ ድርጊቶችን በራስነት ለማውጣት እናስቀሳቅሳለን፡፡ የትርጉም ዳታዎችን በመስመር ማቀናጃ ማቀናጃ ማድረግ ማድረግ እና ማድረግ ማድረግ ማድረግ ማድረግ ማድረግ ነው (እስከ 25.31 BLEU) እና outperforms existing interactive translation methods (up to 16.64 BLEU). እናም የሥርዓታችንን ጥብቅ እና ጥብቃዊውን ለመግለጽ በኋላ ማቀናጃ ዳታዎችን እናደርጋለን፡፡', 'hy': 'Մենք առաջարկում ենք թարգմանման համար հպման հիմնված խմբագրման մեթոդ, որը ավելի ճկուն է, քան ավանդական մկնիկի վրա հիմնված թարգմանումը: This approach relies on touch actions that users perform to indicate translation errors.  Մենք ներկայացնում ենք երկու կոդերի մոդել, որպեսզի կառավարենք գործողությունները և ստեղծենք բարելավված թարգմանություններ: Որպեսզի կրկնօրինակենք օգտագործողի արձագանքը, մենք ընդունում ենք TER ալգորիթմը, որը համեմատում է թարգմանությունների նախագծերի և հղումների միջև, որպեսզի ինքնաբերաբար վերցնենք տվյալների կառուցման կրկն Սիմուլյացված խմբագրման գործողություններով թարգմանման տվյալների համակարգերի փորձարկումները ցույց են տալիս, որ մեր մեթոդը նշանակալիորեն բարելավում է Թանֆորմերի սկզբնական թարգմանությունը (մինչև 25.31 ԲԼԵՎ) և արտադրում է գոյություն ունեցող ինտե Մենք նաև փորձեր ենք կատարում տեղեկատվական համակարգի վերաբերյալ, որպեսզի ապացուցենք մեր մեթոդի կայունությունը և արդյունավետությունը:', 'af': "Ons voorstel 'n raak-gebaseerde redigeringsmetode vir vertaling, wat is meer fleksibel as tradisionele sleutelbord-muis-gebaseerde vertaling. Hierdie toegang verlig op aanraak aksies wat gebruikers uitvoer om vertaling foute te wys. Ons stel 'n tweede-enkoder model om die aksies te hanteer en te genereer verrafinge vertalings. Om die gebruiker terugmelding te mimiseer, aanvaar ons die TER algoritme wat vergelyk tussen draft vertalings en verwysing tot outomaties uitpak die simuleerde aksies vir onderwerp van data konstruksie. Eksperimente op vertaling datastelle met simuleerde redigeer aksies vertoon dat ons metode betekenlik die oorspronklike vertaling van Transformer (tot 25. 31 BLEU) verbeter en uitvoer bestaande interaktiewe vertaling metodes (tot 16. 64 BLEU). Ons doen ook eksperimente op post-redigeering datastel om verder die kragtigheid en effektiviteit van ons metode te bevestig.", 'ko': '우리는 터치 기반의 번역 후 편집 방법을 제시했는데 전통적인 키보드 마우스 기반의 번역 후 편집보다 더욱 유연하다.이런 방법은 사용자가 실행하는 터치 동작에 의존해서 번역 오류를 표시한다.우리는 동작을 처리하고 정확한 번역을 만드는 이중 인코더 모델을 제시했다.사용자 피드백을 시뮬레이션하기 위해 우리는 TER 알고리즘을 적용하여 초고 번역과 참고 사이를 비교하고 시뮬레이션 동작을 자동으로 추출하여 훈련 데이터를 구축한다.아날로그 편집 조작을 가진 번역 데이터 집합에서의 실험에 의하면 우리의 방법은 Transformer의 원시 번역(BLEU 최고 25.31)을 현저하게 개선했고 기존의 상호작용 번역 방법(BLEU 최고 16.64)보다 우수하다는 것을 알 수 있다.우리는 또한 편집된 데이터 집합에 대해 실험을 진행하여 이 방법의 노봉성과 유효성을 한층 더 증명하였다.', 'bs': 'Predlažemo metodu editiranja na dodiru za prevod, koja je fleksibilnija od tradicionalnog postizanja prevoda na tastaturi na mišu. Ovaj pristup se oslanja na dodirne akcije koje korisnici izvode kako bi pokazali greške prevođenja. Predstavljamo dvokoderski model kako bi se bavili akcijama i stvorili refinansirane prevode. Da bi imitirali reakciju korisnika, usvojili smo algoritam TER-a u usporedbi između projekta prevoda i referencija da bi automatski izvukli simulirane akcije za izgradnju podataka o obuci. Eksperimenti o setima podataka prevođenja sa simuliranim redakcijama pokazuju da naša metoda značajno poboljšava originalni prevoz transformera (do 25,31 BLEU) i iznosi postojeće interaktivne metode prevođenja (do 16,64 BLEU). Također provodimo eksperimente o setu podataka nakon editiranja kako bismo dalje dokazali robustnost i učinkovitost našeg metoda.', 'cs': 'Navrhujeme dotykovou metodu editace pro překlad, která je flexibilnější než tradiční posteditace překladu pomocí klávesnice myší. Tento přístup spoléhá na dotykové akce, které uživatelé provádějí k označení chyb překladu. Představujeme model duálního kodéru pro zvládnutí akcí a generování rafinovaných překladů. Abychom napodobili zpětnou vazbu uživatelů, přijali jsme algoritmus TER porovnávání návrhů překladů a referencí, abychom automaticky extrahovali simulované akce pro tvorbu tréninkových dat. Experimenty na překladových datových sadách se simulovanými editačními akcemi ukazují, že naše metoda výrazně zlepšuje původní překlad Transformeru (až 25.31 BLEU) a překonává stávající interaktivní překladové metody (až 16.64 BLEU). Dále provádíme experimenty na post-editaci datových sad, abychom dále prokázali robustnost a efektivitu naší metody.', 'az': 'Biz təkrarlama üçün toxunma tabanlı düzenleme metodlarını təklif edirik. Bu, əvvəlki klavyə-sıçan təkrarlamasından daha fleksibildir. Bu tərzim istifadəçilərin qurğulama xətalarını göstərmək üçün etdikləri toxunmaq işlərinə təvəkkül edir. Biz işləri idarə etmək və təmizlənmiş tercümələri yaratmaq üçün iki kodlayıcı modeli göstəririk. İstifadəçilərin reaksiyonu mimiyalaşdırmaq üçün, məlumat inşaması üçün simulasyon eylemlərini avtomatik təhsil etmək üçün TER algoritmini alırıq. Simülatlı düzenleme eylemləri ilə çevirilən verilən verilənlər təcrübələrinin təcrübələrinin əsl tərcübəsini (25,31 BLEU-ə qədər ) daha yaxşı dəyişdirir və mevcut interaktif tercümə metodlarını (16,64 BLEU-ə qədər artırır). Biz həmçinin metodumuzun güclülüyünü və etkinliğini daha çox təsdiqləmək üçün verilən verilənlər qutusunda də imtahana çəkirik.', 'bn': 'আমরা অনুবাদের জন্য একটি স্পর্শ ভিত্তিক সম্পাদক পদ্ধতি প্রস্তাব করি, যা ঐতিহ্যবাহী কীবোর্ড- মাউস ভিত্তিক অনুবাদ পোস্টিং এই পদ্ধতি অনুবাদের ত্রুটি নির্দেশ করার জন্য ব্যবহারকারীদের স্পর্শ করার উপর নির্ভর করে। আমরা একটি দুই এনকোডার মডেল উপস্থাপন করি কাজের মাধ্যমে কাজ করা এবং সংস্কার করা অনুবাদ তৈরি করার জন্য। ব্যবহারকারীর ফিডব্যাককে মাইক করার জন্য আমরা টেআর অ্যালগরিদম মেনে নিয়েছি মানচিত্র অনুবাদ এবং উল্লেখ করার মধ্যে তুলনা করেছি স্বয়ংক্রিয়ভাব অনুবাদের তথ্য সংক্রান্ত সম্পাদনার সাথে অনুবাদের পরীক্ষার পরীক্ষা দেখা যাচ্ছে যে আমাদের পদ্ধতি অনুবাদের মূল অনুবাদের গুরুত্বপূর্ণ করে দেয় (২৫. ৩১ এছাড়াও আমরা পরীক্ষা করি আমাদের পদ্ধতির রাস্তা ও কার্যকর প্রমাণের জন্য পোস্ট সম্পাদনার পরিকল্পনায়।', 'ca': "Proposem un mètode d'edició basat en contacte per a la traducció, que és més flexible que la traducció tradicional basada en el ratolí. Aquest enfocament es basa en accions de contacte que els usuaris fan per indicar errors de traducció. Presentam un model de doble codificador per gestionar les accions i generar traduccions refines. Per imitar el feedback dels usuaris, adoptem l'algoritme TER comparant entre projectes de traducció i referències per extrair automàticament les accions simulades per a formar la construcció de dades. Els experiments en conjunts de dades de traducció amb accions d'edició simulades mostran que el nostre mètode millora significativament la traducció original del Transformer (fins a 25,31 BLEU) i supera els mètodes de traducció interactiu existents (fins a 16,64 BLEU). També fem experiments en un conjunt de dades post-edicionats per demostrar més la robustet i l'eficacia del nostre mètode.", 'et': 'Tõlkimiseks pakume välja puutepõhise redigeerimismeetodi, mis on paindlikum kui traditsiooniline klaviatuuri-hiirepõhine tõlke järeltredigeerimine. See lähenemine tugineb puutetoimingutele, mida kasutajad teevad tõlkevigade märkimiseks. Esitame topeltkodeerija mudeli toimingute käsitlemiseks ja rafineeritud tõlkete genereerimiseks. Kasutaja tagasiside jäljendamiseks võtame kasutusele TER algoritmi, mis võrdleb projekti tõlkeid ja viiteid, et automaatselt välja simuleeritud toimingud koolitusandmete ehitamiseks. Simuleeritud redigeerimistoimingutega seotud tõlkeandmekogumite eksperimendid näitavad, et meie meetod parandab oluliselt Transformeri originaaltõlget (kuni 25.31 BLEU) ja ületab olemasolevaid interaktiivseid tõlkemeetodeid (kuni 16.64 BLEU). Samuti teeme katseid järeltöötluse andmekogumiga, et veelgi tõestada meie meetodi tugevust ja efektiivsust.', 'fi': 'Ehdotamme kosketuspohjaista k채채nn철smenetelm채채, joka on joustavampi kuin perinteinen n채pp채imist철hiiripohjainen k채채nn철ksen j채lkieditointi. T채m채 l채hestymistapa perustuu kosketustoimintoihin, joita k채ytt채j채t suorittavat k채채nn철svirheiden osoittamiseksi. Esittelemme kaksoiskooderimallin, joka k채sittelee toimintoja ja tuottaa hienostuneita k채채nn철ksi채. K채ytt채jien palautteen j채ljittelemiseksi otamme k채ytt철철n TER-algoritmin, joka vertailee luonnoksen k채채nn철ksi채 ja viittauksia, jotta simuloidut toimet voidaan automaattisesti poimia harjoitusdatan rakentamiseen. Simuloiduilla editointitoimilla tehdyt k채채nn철stietokokeet osoittavat, ett채 menetelm채mme parantaa merkitt채v채sti Transformerin alkuper채isk채채nn철st채 (jopa 25.31 BLEU) ja ylitt채채 olemassa olevat interaktiiviset k채채nn철smenetelm채t (jopa 16.64 BLEU). Teemme my철s kokeiluja j채lkimuokkausaineistosta todistaaksemme menetelm채mme luotettavuuden ja tehokkuuden.', 'sk': 'Predlagamo metodo urejanja na dotik za prevajanje, ki je fleksibilnejša od tradicionalnega postdediranja prevajanja na tipkovnici in miški. Ta pristop temelji na dejanjih na dotik, ki jih uporabniki izvajajo za označevanje napak pri prevodu. Predstavljamo model z dvojnim kodirnikom za upravljanje dejanj in ustvarjanje prefinjenih prevodov. Za posnemanje povratnih informacij uporabnikov uporabimo algoritem TER, ki primerja osnutke prevodov in sklicevanja, da samodejno izvlečemo simulirane akcije za gradnjo podatkov o usposabljanju. Eksperimenti na naborih podatkov o prevajanju s simuliranimi ukrepi urejanja kažejo, da naša metoda bistveno izboljša originalni prevod Transformerja (do 25.31 BLEU) in presega obstoječe interaktivne prevajalske metode (do 16.64 BLEU). Izvajamo tudi poskuse na naboru podatkov po urejanju, da bi dodatno dokazali robustnost in učinkovitost naše metode.', 'ha': "Tuna goyyar da shirin taƙaitar da aka binge ta kan birarin, wanda ke fi fleksible ko kuma da fassarar fassarar da aka danne shi na zaman ayuka-mouse. Wannan durowa yana dõgara ga aikin da za'a yi amfani da shi, wanda suke aikin su nuna errors ga fassarar. Tuna gabatar da wani misali na kode-dubu dõmin su yi aiki na aikin ƙwarai kuma mu ƙiƙiro fassarar da aka fassara. To, in ƙayyade feedback na mai amfani da shi, mu zãɓi algoritm na Tsariya da ke daidaita tsakanin fassarar-fassarar da Reference zuwa ya nuna aikin da aka kamata ɗabi'a wa tsarin data. KCharselect unicode block name Kayya, Munã samun jarrabo a kan danne-haƙin bayan-editi, dõmin ka ƙara bayani ga manunufi da tayari na hanyarmu.", 'jv': 'Awak dhéwé ngerwih akeh basa nang dodo-basa sing tarjamahan kanggo tarjamahan, sing langgar bantuan karo perusahaan-musik sing basa tarjamahan. Name Awak dhéwé éntuk model sing duwat-koder kanggo ngebagian aksi lan nggawe tarjamahan Jejaring Name Awak dhéwé éntuk éntuk éntuk mulai perusahaan dengané dadi nggawe dadi nggawe barang nggawe barang nggawe barang nggawe sistem sing beraksi dadi.', 'he': 'אנו מציעים שיטת עורך מבוססת מגע לתרגום, שהיא יותר גמישה מאשר התרגום מסורתי מבוסס על עכבר. This approach relies on touch actions that users perform to indicate translation errors.  אנחנו מציגים מודל קודם כפול כדי לטפל בפעולות ולייצר תרגומות מעודפות. כדי לחקות את ההחזרה של המשתמשים, אנו מאמצים את האלגוריתם TER שיווה בין התרגשות סגנון וההתייחסות כדי לחלץ באופן אוטומטי את הפעולות הסימולציות לבניית נתונים. ניסויים על קבוצות נתונים התרגום עם פעולות עורכת סמיולציות מראים ששיטתנו משפר באופן משמעותי את התרגום המקורי של טרנספורטר (עד 25.31 BLEU) ומעביר את שיטות התרגום אינטראקטיבית קיימות (עד 16.64 BLEU). אנחנו גם מבצעים ניסויים על קבוצת נתונים לאחר העורה כדי להוכיח עוד את החזקה והיעילות של השיטה שלנו.', 'bo': 'We propose a touch-based editing method for translation, which is more flexible than traditional keyboard-mouse-based translation postediting. གཟུགས་སྐོར་འདིས་སྤྱོད་མཁན་གྱི་སྤྲོད་ཀྱི་བྱ་འགུལ་ལ་རྟེན་འདུག We present a dual-encoder model to handle the actions and generate refined translations. སྤྱོད་མཁན དབྱིབས་སྒྱུར་བཅོས་གནད་སྡུད་གཞུང་ཚབ་དང་མཉམ་དུ་བསྡུར་བའི་བྱ་འགུལ ང་ཚོས་ཞིབ་ཕྱིར་བསྒྱུར་བཅོས་ཐབས་ལམ་གྱི་སྒྲིག་འགོད་གནད་དོན་དག་གི་ལྟ་ཞིབ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Can Monolingual Pretrained Models Help Cross-Lingual Classification?', 'ar': 'هل يمكن للنماذج أحادية اللغة أن تساعد في التصنيف متعدد اللغات؟', 'es': '¿Pueden los modelos monolingües preentrenados ayudar a la clasificación multilingüe', 'pt': 'Modelos pré-treinados monolíngues podem ajudar na classificação entre idiomas?', 'fr': 'Les modèles préentraînés monolingues peuvent-ils aider à la classification interlinguistique\xa0?', 'ja': 'モノリンガル事前トレーニングモデルは、クロスリンガル分類を助けることができますか？', 'zh': '单语预练模形可以助言语分类乎?', 'hi': 'क्या मोनोलिंगुअल प्रीट्रेन्ड मॉडल क्रॉस-लिंगुअल वर्गीकरण में मदद कर सकते हैं?', 'ru': 'Могут ли одноязычные предварительно обученные модели помочь в перекрестной классификации?', 'ga': 'An féidir le Múnlaí Réamhthraenáilte Aonteangacha Cuidiú le hAicmiú Trastheangach?', 'ka': 'მჲზვ ლთ მჲნჲლთნდსჟკთ ოპვკპაჟვნთ მჲევლთ ეა ოჲმჲდნარ ოპვკპაჟლთგნარა კლაჟთტთკაუთწ?', 'hu': 'Segíthetnek-e az egynyelvű előkészített modellek a nyelvek közötti osztályozásban?', 'it': 'I modelli monolingue pretensionati possono aiutare la classificazione interlinguistica?', 'lt': 'Can Monolingual Pretrained Models Help Cross-Lingual Classification?', 'kk': 'Біртіл тілінен қарсы үлгілерді көмектесе аласыз ба?', 'mk': 'Може ли монолингуалните предобучени модели да помогнат во крстојалната класификација?', 'ml': 'മോണോളില്\u200d പരിശീലിക്കപ്പെട്ട മോഡലുകള്\u200d', 'ms': 'Boleh Model Terlatih Monolingual membantu Klasifikasi Selasa-Bahasa?', 'no': 'Kan monolinguiske modeller hjelpa krysslingsklassifikasjon?', 'mn': 'Монолин хэлний давхар загварууд хэлбэрийн давхар хэлний классификацийг тусалж чадах уу?', 'mt': 'Il-Mudelli Monolingwali mħarrġa minn qabel jistgħu jgħinu fil-Klassifikazzjoni Cross-Lingwali?', 'pl': 'Czy jednojęzyczne modele pretreningowe mogą pomóc w klasyfikacji między językami?', 'ro': 'Modelele monolingve pretrainate pot ajuta la clasificarea interlingvistică?', 'el': 'Μπορούν τα μονογλωσσικά προσχεδιασμένα μοντέλα να βοηθήσουν στη διαγλωσσική ταξινόμηση;', 'sr': 'Може ли монолингуални модели прекирани да помогне преко-лингуалној класификацији?', 'si': 'මොනෝලින්ගුල් ප්\u200dරීතිරීම් මොඩල් උදව් කරන්න පුළුවන්ද?', 'so': 'Isticmaalka afka Monoliku ma caawini karaa fasaxa luuqada?', 'sv': 'Kan enspråkiga företränade modeller hjälpa till att klassificera flera språk?', 'ta': 'Can Monolingual Pretrained Models Help Cross-Lingual Classification?', 'ur': 'Can Monolingual Pretrained Models Cross-Lingual Classification Help?', 'uz': '@ info: whatsthis', 'vi': 'Phụ mẫu giả đơn ngôn ngữ có thể giải mã được không?', 'bg': 'Могат ли моноезичните предтренирани модели да помогнат за междулингвистичната класификация?', 'da': 'Kan ensprogede prætrænede modeller hjælpe tværsproget klassificering?', 'hr': 'Može li Monolijezički modeli pomoći preko jezika klasifikaciji?', 'nl': 'Kunnen eentalige voorgetrainde modellen helpen cross-lingual classificatie?', 'de': 'Können einsprachige vortrainierte Modelle der sprachübergreifenden Klassifizierung helfen?', 'id': 'Bisakah Monolingual Pretrained Models membantu Cross-Language Classification?', 'fa': 'ميتونه مدل هاي زير زبان مونوليژي به کلاسي عبور زبان کمک کنه؟', 'ko': '단어 예훈련 모델은 다중 언어의 분류를 도울 수 있습니까?', 'sw': 'Je, Modeli wenye mafunzo ya lugha za KiMonolinguzi wanaweza kusaidia Kutokana na Msalama wa lugha?', 'tr': 'Monoli Dilli Yapışkan Modeller Çapraz Dilli Sınıflandırma Yardımcı olabilir mi?', 'af': 'Kan Monolingueel Pretrained Models Help Cross-Lingual Classification?', 'sq': 'Mund modelet monolinguale të parastërvitura të ndihmojnë klasifikimin ndërgjuhësor?', 'hy': 'Կարո՞ղ են Մոնոլինգուլ նախապատրաստված մոդելները օգնել միջլեզվային դասակարգումը:', 'am': 'ቋንቋ', 'az': 'Monoli Dili 칐l칞칲l칲 Modell톛r 칂톛rz Dili Klasifikasyonuna Yard캼m ed톛 bil톛rmi?', 'bn': 'মনোলিভাল প্রশিক্ষিত মডেল কি সাহায্য করতে পারে?', 'ca': 'Els models monolingües pré-entrenats poden ajudar a la classificació translingüe?', 'bs': 'Može li Monolingški modeli da pomognu klasifikaciji preko jezika?', 'cs': 'Mohou jednojjazyčné předtrénované modely pomoci mezijazyčné klasifikaci?', 'et': 'Kas ühekeelsed eelkreenitud mudelid aitavad keeleülest klassifitseerimist?', 'fi': 'Voiko yksikieliset esikoulutetut mallit auttaa kielienvälistä luokitusta?', 'jv': "Jane Smith (that's been a long time)", 'ha': '@ item Text character set', 'sk': 'Ali lahko enojezični predtrenirani modeli pomagajo pri medjezikovni klasifikaciji?', 'he': 'האם מודלים מונולינגוליים מתאמנים יכולים לעזור להקליфікаציה לצלב לינגולי?', 'bo': 'Monolingual Pretrained Models Help Cross-Lingual Classification ཡིན་ནམ།'}
{'en': 'Multilingual pretrained language models (such as multilingual BERT) have achieved impressive results for cross-lingual transfer. However, due to the constant model capacity, multilingual pre-training usually lags behind the monolingual competitors. In this work, we present two approaches to improve zero-shot cross-lingual classification, by transferring the knowledge from monolingual pretrained models to multilingual ones. Experimental results on two cross-lingual classification benchmarks show that our methods outperform vanilla multilingual fine-tuning.', 'ar': 'حققت نماذج اللغات سابقة التدريب متعددة اللغات (مثل BERT متعدد اللغات) نتائج رائعة في النقل عبر اللغات. ومع ذلك ، نظرًا لقدرة النموذج الثابتة ، فإن التدريب المسبق متعدد اللغات عادة ما يتخلف عن المنافسين أحاديي اللغة. في هذا العمل ، نقدم طريقتين لتحسين تصنيف متعدد اللغات ، من خلال نقل المعرفة من النماذج أحادية اللغة المحددة مسبقًا إلى النماذج متعددة اللغات. تظهر النتائج التجريبية على اثنين من معايير التصنيف عبر اللغات أن أساليبنا تتفوق في الأداء على الضبط الدقيق متعدد اللغات للفانيليا.', 'pt': 'Modelos de idiomas pré-treinados multilíngues (como o BERT multilíngue) alcançaram resultados impressionantes para a transferência entre idiomas. No entanto, devido à capacidade constante do modelo, o pré-treinamento multilíngue geralmente fica atrás dos concorrentes monolíngues. Neste trabalho, apresentamos duas abordagens para melhorar a classificação multilíngue de tiro zero, transferindo o conhecimento de modelos pré-treinados monolíngues para multilíngues. Resultados experimentais em dois benchmarks de classificação multilíngue mostram que nossos métodos superam o ajuste fino multilíngue vanilla.', 'es': 'Los modelos lingüísticos multilingües preentrenados (como BERT multilingüe) han logrado resultados impresionantes en la transferencia multilingüe. Sin embargo, debido a la capacidad constante del modelo, la preformación multilingüe suele ir a la zaga de los competidores monolingües. En este trabajo, presentamos dos enfoques para mejorar la clasificación interlingüística de tiro cero, mediante la transferencia del conocimiento de modelos monolingües preentrenados a modelos multilingües. Los resultados experimentales en dos puntos de referencia de clasificación interlingües muestran que nuestros métodos superan al ajuste fino multilingüe básico.', 'fr': 'Les modèles linguistiques préformés multilingues (tels que le BERT multilingue) ont obtenu des résultats impressionnants en matière de transfert multilingue. Cependant, en raison de la capacité constante du modèle, la pré-formation multilingue est généralement en retard par rapport aux concurrents monolingues. Dans ce travail, nous présentons deux approches pour améliorer la classification interlinguistique à zéro coup, en transférant les connaissances des modèles préentraînés monolingues vers des modèles multilingues. Les résultats expérimentaux sur deux points de référence de classification interlinguale montrent que nos méthodes surpassent le réglage fin multilingue vanille.', 'zh': '多言预训(如多语BERT)跨语得深成。 然以模形容恒定,多言预练常后于单语竞争对手。 于此二者,立二法以零次言语之类,法移单语预练模形于多言。 两跨语类实验结果表明,吾道优于众。', 'ja': '多言語の事前訓練された言語モデル（多言語BERTなど）は、クロスリンガル転送のために印象的な結果を達成しました。しかし、モデルの容量が一定であるため、多言語の事前トレーニングは通常、単一言語の競合他社よりも遅れています。この研究では、ゼロショットのクロスリンガル分類を改善するための2つのアプローチを提示します。これは、単一言語の事前訓練されたモデルから多言語のモデルに知識を移すことによって行われます。2つのクロスリンガル分類ベンチマークの実験結果は、当社の方法がバニラ多言語微調整よりも優れていることを示しています。', 'ru': 'Многоязычные заранее подготовленные языковые модели (такие как многоязычный BERT) достигли впечатляющих результатов для межязыкового перевода. Однако из-за постоянной емкости модели многоязычное предварительное обучение обычно отстает от одноязычных конкурентов. В этой работе мы представляем два подхода к совершенствованию кросс-лингвистической классификации с нулевым выстрелом, путем переноса знаний с одноязычных предварительно подготовленных моделей на многоязычные. Экспериментальные результаты по двум межязыковым критериям классификации показывают, что наши методы превосходят многоязычную тонкую настройку ванили.', 'hi': 'बहुभाषी पूर्व प्रशिक्षित भाषा मॉडल (जैसे बहुभाषी BERT) ने क्रॉस-भाषी हस्तांतरण के लिए प्रभावशाली परिणाम प्राप्त किए हैं। हालांकि, निरंतर मॉडल क्षमता के कारण, बहुभाषी पूर्व-प्रशिक्षण आमतौर पर मोनोलिंगुअल प्रतियोगियों के पीछे रहता है। इस काम में, हम शून्य-शॉट क्रॉस-लिंगुअल वर्गीकरण में सुधार करने के लिए दो दृष्टिकोण प्रस्तुत करते हैं, मोनोलिंगुअल प्रीट्रेन्ड मॉडल से ज्ञान को बहुभाषी लोगों में स्थानांतरित करके। दो क्रॉस-लिंगुअल वर्गीकरण बेंचमार्क पर प्रयोगात्मक परिणाम बताते हैं कि हमारे तरीके वेनिला बहुभाषी फाइन-ट्यूनिंग से बेहतर प्रदर्शन करते हैं।', 'ga': 'Tá torthaí iontacha bainte amach ag samhlacha ilteangacha teanga réamhoilte (amhail BERT ilteangach) maidir le haistriú tras-teanga. Mar gheall ar thoilleadh seasta na samhla, áfach, is gnách go mbíonn réamhoiliúint ilteangach taobh thiar de na hiomaitheoirí aonteangacha. Sa saothar seo, cuirimid i láthair dhá chur chuige chun rangú tras-teangacha gan urchar a fheabhsú, tríd an eolas a aistriú ó mhúnlaí réamhoilte aonteangacha go samhlacha ilteangacha. Léiríonn torthaí turgnamhacha ar dhá thagarmharcáil tras-teangacha aicmithe go sáraíonn ár modhanna mionchoigeartú ilteangach fanaile.', 'ka': 'მრავალენგური წარმოდგენებული ენის მოდელები (როგორც მრავალენგური BERT) მიიღეთ მრავალენგური წარმოდგენების შესაძლებელი გადატანისთვის. მაგრამ, კონსტანტიური მოდელური შესაძლებლობად, მრავალენგური წინასწარმატებით მონოლენგური კონპექტირების შემდეგ გადარჩენა. ამ სამუშაოში, ჩვენ ჩვენ ჩვენ აჩვენებთ ორი დახმარება, რომელიც ნულ სტრიქტური კლასიფიკაციაში უფრო უფრო მეტი ენგური კლასიფიკაციაში, მონოლენგური მოდელებიდან მრავა ვკჟოვპთმვნრთფნთ პვჱსლრართ ნა ეგვ კლაჟთტთკაუთჲნალნთ ბვნქმაპკთ ოჲკაჱგარ, ფვ ნაქთრვ მვრჲეთ თჱოპაგწრ განთლთწ მნჲდთლთნჟკთ ტთნრ', 'hu': 'A többnyelvű előképzett nyelvi modellek (mint például a többnyelvű BERT) lenyűgöző eredményeket értek el a többnyelvű transzfer terén. Az állandó modellkapacitás miatt azonban a többnyelvű előképzés általában lemarad az egynyelvű versenyzőktől. Ebben a munkában két megközelítést mutatunk be a zéró nyelvű keresztnyelvű osztályozás javítására, a tudás átadásával az egynyelvű előképzett modellekről a többnyelvűekre. Két keresztnyelvű osztályozási referenciaérték kísérleti eredményei azt mutatják, hogy módszereink felülmúlják a vanília többnyelvű finomhangolást.', 'el': 'Τα πολύγλωσσα προ-εκπαιδευμένα γλωσσικά μοντέλα (όπως το πολύγλωσσο BERT) έχουν επιτύχει εντυπωσιακά αποτελέσματα για τη διασυνοριακή μεταφορά. Ωστόσο, λόγω της σταθερής ικανότητας μοντέλου, η πολύγλωσση προεκπαίδευση συνήθως υστερεί από τους μονογλωσσικούς ανταγωνιστές. Στην παρούσα εργασία, παρουσιάζουμε δύο προσεγγίσεις για τη βελτίωση της μηδενικής γλωσσικής ταξινόμησης, μεταφέροντας τη γνώση από μονογλωσσικά προ-εκπαιδευμένα μοντέλα σε πολυγλωσσικά. Τα πειραματικά αποτελέσματα σε δύο διαγώνια γλωσσικά κριτήρια ταξινόμησης δείχνουν ότι οι μέθοδοι μας ξεπερνούν τον πολυγλωσσικό συντονισμό βανίλιας.', 'it': 'I modelli linguistici multilingue pre-addestrati (come il BERT multilingue) hanno ottenuto risultati impressionanti per il trasferimento multilingue. Tuttavia, a causa della costante capacità di modello, la pre-formazione multilingue di solito è in ritardo rispetto ai concorrenti monolingue. In questo lavoro, presentiamo due approcci per migliorare la classificazione cross-lingual zero shot, trasferendo le conoscenze da modelli monolingue pre-addestrati a modelli multilingue. I risultati sperimentali su due parametri di classificazione cross-lingual mostrano che i nostri metodi superano il fine tuning multilingue vanilla.', 'lt': 'Daugiakalbiai išankstinio mokymo kalbų modeliai (pvz., daugiakalbiai BERT) pasiekė įspūdingų rezultatų tarpkalbiniam perdavimui. Tačiau dėl nuolatinių modelių pajėgumų daugiakalbis išankstinis mokymas paprastai atsilieka nuo vienakalbių konkurentų. Šiame darbe pristatome du metodus, kaip pagerinti nulinę tarpkalbinę klasifikaciją, perduodami žinias iš monokalbinių ikimokomų modelių į daugiakalbius. Eksperimentiniai dviejų tarpkalbinio klasifikavimo lyginamųjų rodiklių rezultatai rodo, kad mūsų metodai viršija vanilės daugiakalbį patobulinimą.', 'kk': 'Көптеген тілдер үлгілері (көптеген BERT секілді) көптеген тілдерді аудару үшін көптеген нәтижелер жеткізді. Бірақ тұрақты үлгі көмегімен бірнеше тілдерді алдын- ала оқыту көмегімен бірнеше тілдердің конкурстарының артында қалды. Бұл жұмыс ішінде, біз нөл тілдердің көпшілікті классификациясын жасау үшін, білімдерді бір тілдерден көп тілдерге аударып, білімдерді бірнеше тілдердің моделдерінен аударып Екі тілдерді көптеген классификациялық банкшаларының эксперименталдық нәтижелері біздің әдістеріміздің көптеген тілдерді баптауға арналған.', 'mk': 'Мултијазичните предобучени јазички модели (како што се мултијазичните БЕРТ) постигнаа импресивни резултати за прекујазичен трансфер. However, due to the constant model capacity, multilingual pre-training usually lags behind the monolingual competitors.  In this work, we present two approaches to improve zero-shot cross-lingual classification, by transferring the knowledge from monolingual pretrained models to multilingual ones.  Експерименталните резултати на двата меѓујазични резултати за класификација покажуваат дека нашите методи го надминуваат мултијазичното подобрување на ванилата.', 'ml': 'പല ഭാഷകളിലുള്ള ഭാഷ മോഡലുകള്\u200d (multilingual BERT പോലെ) ക്രിസ്ലിങ്ഗല്\u200d മാറ്റുന്നതിനുള്ള ഉത്തമമായ ഫലങ്ങള്\u200d സമ്പാദിച്ചു. എന്നാലും, നിലനില്\u200dക്കുന്ന മോഡലിന്\u200dറെ കഴിവിന്\u200dറെ കാരണം, പല ഭാഷക്കാര്\u200dക്കും മുമ്പ് പരിശീലനത്തിന്\u200dറെ പിന്നില്\u200d സാധാ ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d പൂര്\u200dണ്ണമായ വെടിവെക്കപ്പെടുത്താന്\u200d രണ്ട് വഴികള്\u200d കാണിക്കുന്നു. മോണോളില്\u200d നിന്നും മാന്ത്രിമാതൃകകളില്\u200d നി രണ്ട് ക്രിസ്ലാങ്കില്\u200d ക്ലാസ്ഫിക്ഷന്\u200d ബെന്\u200dമാര്\u200dക്കിന്\u200dറെ പരീക്ഷണ ഫലങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ രീതികള്\u200d വാനില്ലാത', 'mn': 'Ихэнх хэлний хувьсан хэл загварууд (олон хэл BERT шиг) хэлний шилжүүлэхэд гайхалтай үр дүнг гаргасан. Гэвч тогтмол загварын чадвараас олон хэлний өмнө сургалтын тулд нэг хэлний өрсөлдөгчдийн ард байдаг. Энэ ажлын тулд бид хоёр арга зам гаргаж, тэгш хэл давхар хэлний хуваалтыг сайжруулахын тулд, нэг хэл давхар загвараас олон хэл загвараар мэдлэгийг шилжүүлж байна. Хоёр хэлний хэлбэрийн хуваарилалтын тооны туршилтын үр дүнд бидний арга нь хэлний олон хэлний хуваарилалтын тусламжтайгаас илүүтэй гэдгийг харуулдаг.', 'ms': 'Model bahasa berbilang yang dilatih dahulu (seperti BERT berbilang bahasa) telah mencapai keputusan yang mengesankan untuk pemindahan saling bahasa. Namun, disebabkan kapasitas model konstan, pralatihan berbilang bahasa biasanya tertinggal di belakang kompetitor monobahasa. Dalam kerja ini, kami memperkenalkan dua pendekatan untuk meningkatkan klasifikasi saling bahasa 0-shot, dengan memindahkan pengetahuan dari model monobahasa yang dilatih ke model berbilang bahasa. Keputusan percubaan pada dua tanda benchmark klasifikasi saling bahasa menunjukkan bahawa kaedah kita melebihi penyesuaian berbilang bahasa vanilla.', 'mt': 'Mudelli multilingwi ta’ lingwa mħarrġa minn qabel (bħal BERT multilingwi) kisbu riżultati impressjonanti għal trasferiment translingwi. Madankollu, minħabba l-kapaċità kostanti tal-mudell, it-taħriġ minn qabel multilingwi normalment jonqos lura mill-kompetituri monolingwi. F’dan ix-xogħol, qed nippreżentaw żewġ approċċi biex tittejjeb il-klassifikazzjoni translingwistika b’sensiela żero, billi nittrasferixxu l-għarfien minn mudelli monolingwi mħarrġa minn qabel għal dawk multilingwi. Riżultati esperimentali fuq żewġ punti ta’ riferiment tal-klassifikazzjoni bejn il-lingwi juru li l-metodi tagħna jaqbżu l-aġġustament tal-vanilla multilingwi.', 'no': 'Fleirspråksprøvne språk- modeller (som fleirspråk BERT) har oppnådd uttrykkelige resultat for krysspråk- overføring. Men på grunn av konstant modelskapasitet, vil fleire språksprøving vanlegvis gå bak dei monospråkskonkurrentane. I denne arbeiden presenterer vi to tilnærmingar for å forbedra krysspråksklassifikasjon med null-shot, ved å overføra kunnskapen frå monospråksmønsteret til fleirspråksmønsteret. Eksperimentale resultat på to krysspråk klassifikasjonsbanker viser at våre metoder utfører vanylige fleirspråk fine-tuning.', 'sr': 'Većina jezičkih modela (kao što su multijezički BERT) postigli su impresivne rezultate za prebacivanje preko jezika. Međutim, zbog konstantnog modelnog kapaciteta, multijezička predobuka obično ostaje iza monojezičkih konkurenta. U ovom poslu predstavljamo dva pristupa da poboljšamo klasifikaciju nula-pucnjave preko jezika, prebacivanjem znanja iz monojezičkih pretkišenih modela na višejezičke. Eksperimentalni rezultati na dva međujezička klasifikacija pokazuju da naši metodi nadmađuju vanilnu multijezičku finalizaciju.', 'pl': 'Wielojęzyczne modele językowe (takie jak wielojęzyczny BERT) osiągnęły imponujące rezultaty w transporcie między językami. Jednak ze względu na stałą zdolność modelu wielojęzyczne szkolenia przedszkoleniowe zwykle pozostaje w tyle za konkurentami jednojęzycznymi. W niniejszej pracy przedstawiamy dwa podejścia do poprawy klasyfikacji między językami zerowymi poprzez przeniesienie wiedzy z modeli jednojęzycznych wstępnie trenowanych na modele wielojęzyczne. Wyniki eksperymentalne na dwóch wskaźnikach klasyfikacji między językami pokazują, że nasze metody przewyższają wielojęzyczne dostrajanie wanilii.', 'ro': 'Modelele lingvistice multilingve pre-instruite (cum ar fi BERT multilingv) au obținut rezultate impresionante în ceea ce privește transferul interlingv. Cu toate acestea, datorită capacității constante de model, pregătirea multilingvă rămâne, de obicei, în urma concurenților monolingvi. În cadrul acestei lucrări, prezentăm două abordări pentru îmbunătățirea clasificării interlingve zero-shot, prin transferul cunoștințelor de la modele monolingve pre-instruite la cele multilingve. Rezultatele experimentale pe două criterii de clasificare încrucișate indică faptul că metodele noastre depășesc reglarea fină multilingvă a vaniliei.', 'so': "Tusaale luuqado badan oo af kala duwan ah (tusaale ahaan BERT) waxay helaan resulto faa'iido leh oo la wareejiyo luuqadaha kala duwan. Si kastaba ha ahaatee awoodda modelada joogtada ah darteed waxbarasho-horaadka luuqadaha kala duduwan waxay inta badan dib ugu dhacdaa competitoraha luqada ah. Shaqadan, waxaan keenaynaa laba qaabab ah si aan u kordhinno fasalka nooca ah, si aan aqoonta looga wareejinno noocyo af badan. Imtixaanka waxaa laga helaa laba kooxaha fasaxa luuqadaha oo kala duduwan waxay muujiyaan in qaababkayagu ay ka samaystaan baabuur luuqad kala duduwan.", 'si': 'ගොඩක් භාෂාවක් ප්\u200dරීට්\u200dරීන් භාෂාවක් මොඩේල්ස් (බොහොම භාෂාවක් BERT වගේ) ප්\u200dරශ්ණිත ප්\u200dරතිචාරයක්  නමුත්, ස්ථායිත මොඩල් ක්\u200dරියාත්මක විසින්, බොහොම භාෂාවක් ප්\u200dරීක්ෂණයක් සාමාන්\u200dයයෙන්ම තරඟින මේ වැඩේ අපි ප්\u200dරවේශ දෙකක් තියෙන්නේ ශූන්ය විශේෂ භාෂාවක් විශේෂ කරන්න, එක භාෂාවක් ප්\u200dරවේශ විද්\u200dයාපයක් වලින්  විශ්වාසික විශේෂ බෙන්ච්මාර්ක් දෙන්නේ පරීක්ෂණ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති', 'sv': 'Flerspråkiga förkränade språkmodeller (t.ex. flerspråkiga BERT) har uppnått imponerande resultat för transspråkig överföring. På grund av den ständiga modellkapaciteten ligger dock flerspråkig fortbildning vanligtvis efter de enspråkiga konkurrenterna. I detta arbete presenterar vi två tillvägagångssätt för att förbättra noll-shot tvärspråklig klassificering, genom att överföra kunskap från enspråkiga förkränade modeller till flerspråkiga modeller. Experimentella resultat på två korspråkiga klassificeringsriktmärken visar att våra metoder överträffar vanilj flerspråkig finjustering.', 'ur': 'Multilingual pretrained language models (such as multilingual BERT) have achieved impressive results for cross-language transfer. However, due to the constant model capacity, multilingual pre-training usually leaves the monolingual competitors behind. ہم اس کام میں دو طریقے پیش کرتے ہیں کہ صفر-شٹ کرسی زبان کلاسیفوں کو بہترین کریں، ایک زبان کی پرٹرین مدل سے علم کو بہت سی زبان کی طرف منتقل کر دیں۔ دو مختلف زبان کلاسپیٹ بنچم پر تجربہ کا نتیجہ دکھاتا ہے کہ ہمارے طریقے vanilla multilingual fine-tuning سے کام لیتے ہیں.', 'ta': 'Multilingual pretrained language models (such as multilingual BERT) have achieved impressive results for cross-lingual transfer.  ஆனால், நிலையான மாதிரி இயல்பின் காரணத்தால், பல மொழி முன் பயிற்சி வழக்கமாக மாதிரியாளர்களுக்கு பின்னால் விடும். இந்த வேலையில், நாம் பூஜ்ஜியமான மொழி வகுப்பை மேம்படுத்த இரண்டு வழிகளை காண்பிக்கிறோம், மோனோலிமொழி மாதிரி மாதிரிகளிலிருந்து பல மொழ இரண்டு மொழி வகுப்பு பிரிப்பு குறிப்புகளின் முடிவுகள் காண்பிக்கிறது எங்கள் முறைமைகள் வெற்றில்லா பல மொழிக்கு நன்றாக ம', 'uz': "Bir necha tillar o'zgarishga tayyorlangan tilning modellari (huddi bir tillar BERT kabi tilda) juda ajoyib natijalari topildi. Lekin, davomida model qobiliyati sababda, ko'plab tildan oldin o'rganish odatda monolingan rivojlanuvchilarga keladi. Bu vazifanda biz ikkita tilni o'zgartirish uchun nuqta tilni o'zgartirish uchun qo'l tilni o'zgartirish uchun qo'llanmani o'zgartirish mumkin. Ko'pchilik tillardan ikkita ta'lim darajalashtirish imkoniyatini ko'rsatish mumkin, bizning usullamiz vanillar bir tillarda yaxshi suhbatni bajarishimiz mumkin.", 'vi': 'Các mô hình ngôn ngữ ngữ lưỡng điệu (như vang trắng) đã đạt được kết quả ấn tượng cho việc chuyển giao ngôn ngữ khác nhau. Tuy nhiên, dựa trên khả năng mô hình liên tục, việc chế tạo tiền đào tạo đa dạng thường chậm hơn so với các đối thủ độc ngôn. Trong công việc này, chúng tôi giới thiệu hai phương pháp để cải thiện việc phân loại chữ không phát, bằng cách chuyển tri thức từ các mô- đun trước ngữ học sang chế độ đa dạng. Kết quả thí nghiệm trên hai tiêu chuẩn phân loại ngôn ngữ khác nhau cho thấy phương pháp của chúng ta vượt trội vani-1-độ-thời-2.', 'bg': 'Многоезичните предварително обучени езикови модели (като многоезичните BERT) са постигнали впечатляващи резултати за междуезичен трансфер. Въпреки това, поради постоянния капацитет на модела, многоезичното предобучение обикновено изостава от едноезичните конкуренти. В тази работа представяме два подхода за подобряване на нулевата междуезична класификация чрез прехвърляне на знанията от едноезични предварително обучени модели към многоезични. Експерименталните резултати на две междуезични критерии за класификация показват, че нашите методи превъзхождат фината настройка на ваниловите многоезици.', 'nl': 'Meertalige voorgetrainde taalmodellen (zoals meertalige BERT) hebben indrukwekkende resultaten behaald voor cross-lingual transfer. Door de constante modelcapaciteit blijft meertalige pretraining echter meestal achter op de eentalige concurrenten. In dit werk presenteren we twee benaderingen om zero-shot cross-lingual classificatie te verbeteren, door de kennis over te dragen van eentalige voorgetrainde modellen naar meertalige modellen. Experimentele resultaten op twee cross-lingual classificatiebenchmarks tonen aan dat onze methoden beter presteren dan vanille meertalige finetuning.', 'da': 'Flersprogede prætrænede sprogmodeller (såsom flersproget BERT) har opnået imponerende resultater for overførsel på tværs af sprog. På grund af den konstante modelkapacitet halter flersprogede foruddannelser imidlertid normalt bagud for de ensprogede konkurrenter. I dette arbejde præsenterer vi to tilgange til at forbedre nul-shot tværsproget klassificering ved at overføre viden fra ensprogede prætrænede modeller til flersprogede modeller. Eksperimentelle resultater på to tværsprogede klassificeringsbenchmarks viser, at vores metoder overgår vanilje flersproget finjustering.', 'hr': 'Većina jezičkih modela preliječenih jezika (poput višejezičkih BERT) postigli su impresivni rezultati prijenosa međujezika. Međutim, zbog konstantnog modelnog kapaciteta, multijezička predobuka obično ostaje iza monojezičkih konkurenta. U ovom poslu predstavljamo dva pristupa za poboljšanje krstojezičke klasifikacije nulog snimanja, prenošenjem znanja iz monojezičkih pretkišenih modela na višejezičke. Eksperimentalni rezultati na dva krstojezička klasifikacija pokazuju da naše metode nadmađuju vanilnu multijezičku finalizaciju.', 'de': 'Mehrsprachige vortrainierte Sprachmodelle (z.B. mehrsprachiges BERT) haben beeindruckende Ergebnisse für den sprachübergreifenden Transfer erzielt. Aufgrund der konstanten Modellkapazität hinkt das mehrsprachige Vortraining jedoch meist hinter den einsprachigen Konkurrenten zurück. In dieser Arbeit stellen wir zwei Ansätze vor, um die zero-shot crosslinguale Klassifizierung zu verbessern, indem wir das Wissen von einsprachigen Modellen auf mehrsprachige Modelle übertragen. Experimentelle Ergebnisse an zwei sprachübergreifenden Klassifikations-Benchmarks zeigen, dass unsere Methoden die mehrsprachige Feinabstimmung von Vanille übertreffen.', 'fa': 'مدلهای زبان زیادی (مثل BERT multilingual) نتیجه\u200cهای تاثیر\u200cپذیر برای انتقال زبان\u200cهای زیادی رسیده\u200cاند. با این حال، به دلیل توانایی مدل پایدار، پیش آموزش های زیادی زبان معمولاً پشت مسابقه های یک زبان می ماند. در این کار، ما دو دستیابی را برای بهبود کردن کلیسازی صفر با تغییر دادن علم از مدل های تک زبانی به متعدد زبان نشان می دهیم. نتیجه\u200cهای تجربه روی دو تنظیم گروه\u200cهای مختلف زبان نشان می\u200cدهد که روش\u200cهایمان بیشتر از تنظیم\u200cهای زیادی زبان\u200cهای vanilla را انجام می\u200cدهد.', 'ko': '다중 언어 사전 훈련 언어 모델(예를 들어 다중 언어 BERT)은 다중 언어 이동에 있어 인상적인 성과를 거두었다.그러나 모델의 용량이 일정하기 때문에 다국어 예비 교육은 통상적으로 단어 경쟁 업체보다 뒤떨어진다.이 작업에서 우리는 제로 렌즈의 크로스 언어 분류를 개선하는 두 가지 방법을 제시하여 지식을 단어 예훈련 모델에서 다국어 모델로 옮겼다.두 개의 다중 언어 분류 기준에서의 실험 결과에 의하면 우리의 방법은 일반적인 다중 언어 조정 방법보다 우수하다는 것을 알 수 있다.', 'id': 'Model bahasa berbagai bahasa yang dilatih sebelumnya (seperti BERT berbagai bahasa) telah mencapai hasil yang mengesankan untuk transfer saling bahasa. Namun, karena kapasitas model konstan, prapelatihan multibahasa biasanya tertinggal di belakang kompetitor monobahasa. Dalam pekerjaan ini, kami mempersembahkan dua pendekatan untuk meningkatkan klasifikasi saling bahasa tanpa tembakan, dengan memindahkan pengetahuan dari model monobahasa yang dilatih ke model multibahasa. Hasil percobaan pada dua benchmark klasifikasi saling bahasa menunjukkan bahwa metode kita melebihi penyesuaian vanilla multibahasa.', 'sw': 'Multilingual pretrained language models (such as multilingual BERT) have achieved impressive results for cross-lingual transfer.  Hata hivyo, kwa sababu ya uwezo wa mtindo wa kawaida, mafunzo ya awali ya lugha nyingi mara nyingi hubaki nyuma ya washindi wa lugha. Katika kazi hii, tunaweka mbinu mbili ili kuboresha usambazaji wa lugha sifuri, kwa kuhamisha maarifa kutoka kwenye mifano ya lugha za kimonolinguli kwa lugha mbalimbali. Matokeo ya majaribio yaliyotokana na misingi mawili ya kutangaza lugha mbalimbali yanaonyesha kuwa njia zetu zinaonyesha vizuri vya lugha mbalimbali.', 'tr': 'Çoklu diller öňünde durmuş dil nusgalary (çoklu diller BERT ýaly) çapda diller transferi üçin täsirli netijesi başarmady. Ýöne, adalat nusga ukyplarynyň sebäbi, köp dilli öňünden öňünden okuwçylary adatça monolingt döwzişgerleriniň arkasynda galýar. Bu işde, 0-atlı çarpaklı dil klasifikasyny geliştirmek üçin iki goll çykardyk, bilimi monodil öňündeki örneklerden çoxlu dillere göndererek. Iki çerçe dilli klasifikasyon taýýarlarynyň netijesi biziň metodlarymyzyň vanilla köp dilli taýýarlanmagynyň üstünden çykarýandygyny görkezýär.', 'sq': 'Modelet shumëgjuhësore të gjuhës së stërvitur (të tilla si BERT shumëgjuhës) kanë arritur rezultate mbresëlënëse për transferimin ndërgjuhësor. Megjithatë, për shkak të kapacitetit konstant të modelit, paratrajnimi shumëgjuhës zakonisht mbetet pas konkurentëve monogjuhës. Në këtë punë, ne paraqesim dy qasje për të përmirësuar klasifikimin zero-shot ndërgjuhësor, duke transferuar njohuritë nga modelet monogjuhësore të paramësuara në ato shumëgjuhësore. Rezultatet eksperimentale në dy nivele klasifikimi ndër-gjuhës tregojnë se metodat tona tejkalojnë rregullimin e vanilës me shumëgjuhë.', 'am': 'የቋንቋ ቋንቋዎች ምሳሌዎች (እንደ ብልቋ ቋንቋ BERT) ለcross-ቋንቋ መዘዋወር የበለጠ ውጤቶች አግኝተዋል፡፡ ነገር ግን በዘወትር ሞዴል ስልጣን ምክንያት የቋንቋ ቋንቋዎች የፊደል ትምህርት በተቃዋሚዎቹ ውስጥ ይቆማል፡፡ በዚህ ሥራ፣ የክፍለ ቋንቋ-ቋንቋን ክፍል ለማድረግ ሁለት ደረጃዎችን እናሳውቃለን፡፡ የሁለት የቋንቋ ግንኙነት ክፍተቶችን በማሳየት ውጤቶች የሳንቋ በቋንቋ ደንቋዊ ጥሩ ማድረጊያውን እንዲያሳየው ነው፡፡', 'az': 'Çoxlu dil öyrənmiş dil modelləri (çoxlu dil BERT kimi) çoxlu dil transfer üçün təsirli sonuçlar gəlmişdir. Ancaq, daimi modellərin qabiliyyətinə görə, çoxlu dil əvvəl təhsil edilməsi genellikle monodil müəllifələrinin arxasında qalar. Bu işdə, sıfır dillərin çoxlu dil klasifikasiyasını yaxşılaşdırmaq üçün iki yol göstəririk. İki dildən çox klasifikasyon benchmarklərinin təcrübə sonuçları vanilla çoxlu dildən çoxlu təcrübə edilməsini göstərir.', 'hy': 'Բազլեզու նախադասական լեզվի մոդելները (ինչպիսիք են բազլեզու BER-ը) բազլեզու լեզվի փոխանցման համար զարմանահրաշ արդյունքներ են ստացել: Այնուամենայնիվ, մշտապես մոդելի ունակության շնորհիվ, բազմալեզու նախապատրաստվածությունը սովորաբար մնում է միալեզու մրցակիցների ետևում: Այս աշխատանքի ընթացքում մենք ներկայացնում ենք երկու մոտեցում, որպեսզի բարելավենք զրո-նկարների միջլեզվային դասակարգումը, փոխանցելով գիտելիքները միալեզվային նախադասակարգված մոդելներից բազլեզվային մոդելներին: Experimental results on two cross-lingual classification benchmarks show that our methods outperform vanilla multilingual fine-tuning.', 'ca': 'Els models multilingües de llenguatges pré-entrenats (com el BERT multilingüe) han aconseguit resultats impressionants per a la transfer ència translingüística. Però, a causa de la capacitat constantde model, la pré-formació multilingüe normalment queda darrere dels competidors monolingües. In this work, we present two approaches to improve zero-shot cross-lingual classification, by transferring the knowledge from monolingual pretrained models to multilingual ones.  Els resultats experimentals de dos punts de referència de classificació translingüística mostren que els nostres mètodes superen la perfeccionació multilingüística de la vànilla.', 'bn': 'মাল্টিভাষার ভাষার প্রেমিক ভাষার মডেল (যেমন বহুভাষায় বিআরটি) ক্রাশ-ভাষাভাষী পরিবর্তনের জন্য আকর্ষণীয় ফলাফল অর্জন করেছে। তবে স্থায়ী মডেলের ক্ষমতার কারণে অনেক ভাষার প্রশিক্ষণ সাধারণত সাধারণত অনুভাষী প্রতিযোগীদের পিছনে থাকে। এই কাজের মধ্যে আমরা দুটি পদক্ষেপ উপস্থাপন করি শূন্য-শুট ক্রাশ-ভাষার বিভাগের উন্নতি করার জন্য, মোনোলিভাল ভাষা থেকে প্রেমিক মডেল থেকে  দুই শ্রেণীভাষাভাষী ব্যাঙ্কেমের পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের পদ্ধতি ভ্যানিলা মালিভাষায় ভালো ভালো ভাষায় ভাল', 'bs': 'Većina jezičkih modela preliječenih jezika (poput multilingual BERT) postigli su impresivne rezultate za prelaz preko jezika. Međutim, zbog konstantnog modelnog kapaciteta, multijezička predobuka obično ostaje iza monojezičkih konkurenta. U ovom poslu predstavljamo dva pristupa za poboljšanje krstojezičke klasifikacije nula snimanja, prenošenjem znanja iz monojezičkih pretkišenih modela na multijezičke. Eksperimentalni rezultati na dva krstojezička kritika klasifikacije pokazuju da naši metodi nadmađuju vanilnu multijezičku finalizaciju.', 'af': 'Veelvuldige praatspraak taal modele (soos multilingual BERT) het inpresief resultate bereik vir kruistale oordrag. Maar, vanweë die konstante model kapasiteit, maal tale voor-oefening is gewoonlik agter die monotale mededingsters. In hierdie werk het ons twee toegang voorgestel om nul-skoot kruistale klasifikasie te verbeter deur die kennis van monolinglike pretreënde modele te oordra na veelvuldige tale. Eksperimentale resultate op twee kruistale klasifikasie benchmarke vertoon dat ons metodes van vanilla multilinglike fintuning uitvoer.', 'et': 'Mitmekeelsed eelõpetatud keelemudelid (nt mitmekeelsed BERT) on saavutanud muljetavaldavaid tulemusi keeleülese ülekande osas. Pideva mudelivõime tõttu jääb mitmekeelne koolitus tavaliselt ühekeelsetest konkurentidest maha. Käesolevas töös tutvustame kahte lähenemisviisi keeleülese klassifikatsiooni parandamiseks, kandes teadmised ühekeelsetelt eelõpetatud mudelitelt mitmekeelsetele mudelitele. Eksperimentaalsed tulemused kahe keeleülese klassifikatsiooni võrdlusaluse kohta näitavad, et meie meetodid ületavad vanilje mitmekeelset peenhäälestust.', 'cs': 'Vícejazyčné předtrénované jazykové modely (například vícejazyčné BERT) dosáhly působivých výsledků pro přenos mezi jazyky. Vzhledem k konstantní kapacitě modelu však vícejazyčné předškolení obvykle zaostává za jednojjazyčnými konkurenty. V této práci představujeme dva přístupy ke zlepšení zero-shot cross-jazyčné klasifikace přenosem znalostí z jednojzyčných předtrénovaných modelů na vícejazyčné. Experimentální výsledky na dvou mezijazyčných klasifikačních referencích ukazují, že naše metody překonávají vícejazyčné doladění vanilky.', 'fi': 'Monikieliset esikoulutetut kielimallit (kuten monikielinen BERT) ovat saaneet aikaan vaikuttavia tuloksia monikielisessä tiedonsiirrossa. Monikielinen esikoulutus on kuitenkin jatkuvan mallikapasiteetin vuoksi yleensä jäljessä yksikielisistä kilpailijoista. Tässä työssä esitellään kaksi lähestymistapaa nollakuvan monikielisen luokittelun parantamiseen siirtämällä tietoa monikielisistä esikoulutetuista malleista monikielisiin malleihin. Kokeelliset tulokset kahdesta monikielisestä luokittelusta osoittavat, että menetelmämme ovat parempia kuin vaniljan monikielinen hienosäätö.', 'jv': 'Mulalawat model sing paling ngatur lenggane (koyo BERT multilenguang) kang dumateng kapan langkung bantuan. Nanging, ngenggo akeh dumateng model kuwi, suku akeh-suku layang bantuan ingkang sapa-suku. Nang gunggo iki, kita sampeyan mrograh sing apik kanggo luwih-luwih bantuan ingkang, lan ingkang nggawe ngerasara awak dhéwé suku model lan ingkang sampeyan ingkang bantuan. Ndoleh sing paling-kaling langgar kuwi nggambar kelalen gambar kuwi tindah banter', 'ha': "@ info: status A lokacin da ya samu'in misalin mutane, ko da kawai yana baka marubori na mulki-littafi. Daga wannan aikin, Munã sami hanyoyin biyu dõmin ya kyautata fassarar-sifarin sifiri na'ura, kuma za mu motsar ilmi daga misãlai na monoliki zuwa misalin mulki-lingui. Tajararin matsala ta kan fasalin biyu na tsofanin lugha ta nuna cewa hanyoyinmu za'a samar da jarrabi masu bakin multilingun na ƙarya.", 'sk': 'Večjezični predtrenirani jezikovni modeli (kot je večjezični BERT) so dosegli impresivne rezultate pri medjezičnem prenosu. Vendar pa zaradi stalne zmogljivosti modela večjezično predusposabljanje običajno zaostaja za enojezičnimi konkurenti. V tem delu predstavljamo dva pristopa za izboljšanje ničelne medjezične klasifikacije s prenosom znanja iz enojezičnih predtreniranih modelov na večjezične modele. Eksperimentalni rezultati dveh medjezičnih referenčnih vrednosti klasifikacije kažejo, da so naše metode boljše od vanilijevega večjezičnega finega nastavitve.', 'bo': 'སྐད་རིགས་སྔོན་ལྟའི་སྐད་ཡིག་ཆ་ཀྱི་མིང་དཔེ་དབྱེ་བ(དཔེར་ན་ BERT སྐད་ཡིག་ཆ་ཀྱི་འགྱུར་བརྗོད་ཀྱི་རྐྱེན་སྐད་བསྒྱུར ཡིན་ནའང་། རྒྱུན་ལྡན་གྱི་མ་དབྱིབས་ཆེ་ཤོས་ལས་སླེབས་པའི་སྔོན་གྲངས་སྒྲིག འོན་ཀྱང་། ང་ཚོའི་ནང་དུ་ཅུང་ལྡན་སྔོན་གྱི་ཐབས་ལམ་གཉིས་ཀྱི་གཟུགས་རིས་མང་ཙམ་བཟོ་བྱེད་ཀྱི་ཡོད། སྐད་རིགས་འདིའི་ནང་འཁོད་གྱི་ཐབས་ལམ་གཉིས་ཀྱི་དབྱེ་སྟངས་འཛིན་གྱི་གནད་དོན་དག་བརྟན་ན།', 'he': 'דוגמני שפות רבות (כמו BERT רבות שפות) השיגו תוצאות מרשים עבור העברה דרך שפות. בכל אופן, בשל יכולת המודל המתמודדת, האימונים הקדמיים רבים לשונות בדרך כלל מאחורי המתחרים המונולשונים. In this work, we present two approaches to improve zero-shot cross-lingual classification, by transferring the knowledge from monolingual pretrained models to multilingual ones.  תוצאות ניסיוניות על שני נקודות מסווג שפות-שפתיים מראות ששיטותינו עולים על התאמה רבת-שפתית של וונילה.'}
{'en': 'FERNet : Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues FERN et: Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues', 'ar': 'FERNet: شبكة استخراج وتفكير دقيقة للتعرف على المشاعر في الحوارات', 'es': 'FERnet: red de extracción y razonamiento de grano fino para el reconocimiento de emociones en los diálogos', 'fr': "FerNet\xa0: réseau d'extraction et de raisonnement précis pour la reconnaissance des émotions dans les dialogues", 'pt': 'FERNet: Rede Refinada de Extração e Raciocínio para Reconhecimento de Emoções em Diálogos', 'ja': 'FERNet ：対話における感情認識のための細かい抽出と推論ネットワーク', 'zh': 'FERNet曰:言情识者细粒度取与理网络', 'hi': 'FERNet: संवादों में भावना मान्यता के लिए ठीक-ठाक निष्कर्षण और तर्क नेटवर्क', 'ru': 'FERNet: Мелкозернистая сеть извлечения и рассуждений для распознавания эмоций в диалоге', 'ga': 'FERnet: Gréasán Eastósctha agus Réasúnaithe Míndeartha le hAithint Mothúchán in Agallaimh', 'ka': 'FERNet: დიალოგში ემოციონის განახლებისთვის საქაღალდე', 'el': 'Δίκτυο Εκχύλισης και Λογιστικής για την Αναγνώριση Συναισθημάτων σε Διάλογους', 'hu': 'FERNet: Finomszemű extrakciós és érvelési hálózat az érzelmi felismeréshez a párbeszédekben', 'it': 'FERNet: Rete di estrazione e ragionamento a grana fine per il riconoscimento emotivo nei dialoghi', 'kk': 'FERNet: Диалогтарда көңіл түсініктерді табу және түсініктер желі', 'lt': 'FERNet: Skaidriųjų ekstrahavimo ir pagrįstumo tinklas, skirtas emocijų pripažinimui dialoguose', 'mk': 'ФЕРНЕТ: Мрежа за екстракција и размислување за препознавање на емоции во дијалозите', 'ms': 'FERNet: Rangkaian Ekstraksi dan Memakai Bentuk untuk Pengenalan Emosi dalam Dialog', 'ml': 'ഫെര്\u200dനെറ്റ്: ഡയലോഗിലെ ഇമോട്ടോഷന്\u200d തിരിച്ചറിയുന്നതിനുള്ള ശേഖരം', 'mt': 'FERNet: Netwerk ta’ Estrazzjoni u Raġunar ta’ Ħruġ Fin għar-Rikonoxximent tal-Emożjonijiet fid-Djalogi', 'mn': 'ФЕРНЕТ: Диалогдууд дээрх сайн тарианы тараах болон шалтгаан зориулах сүлжээ', 'no': 'FERNet: Ekstraksjon og årsakende nettverk for kjenning av emosjonar i dialogvindauge', 'pl': 'FERNet: drobnoziarnista sieć ekstrakcji i uzasadniania rozpoznawania emocji w dialogach', 'ro': 'FERNet: Rețeaua de extracție și raționare fină pentru recunoașterea emoțiilor în dialoguri', 'si': 'FERNet: සංවාදයේදී ප්\u200dරතිචාරය සහ හැකියුම් ජාලය', 'sr': 'FERNet: Fino-grained Extraction and Reasoning Network for Emotion Recognition in Dialogs', 'so': 'FERNet: Shabakadda Fine-grained Extraction and Readsashada Istixgelinta Dialog', 'sv': 'FERNet: Finkornigt extraktions- och förnuftsnätverk för känsloigenkänning i dialoger', 'ta': 'FERnetComment', 'ur': 'فیرونٹ: صحبت میں احساسات شناخت کے لئے نیک دانے اخراج اور راس ونٹر', 'uz': 'Comment', 'vi': 'FRNet: mạng chiết xuất và Tìm hiểu cảm xúc trong hộp thoại', 'bg': 'Финозърнеста мрежа за извличане и разсъждаване за разпознаване на емоциите в диалозите', 'da': 'FERNet: Finkornet ekstraktions- og fornuftsnetværk til følelsesgenkendelse i dialoger', 'nl': 'FERNet: fijnkorrelig extractie- en redeneringsnetwerk voor emotionele herkenning in dialoog', 'hr': 'FERNet: Fino-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues', 'de': 'FERNet: Feingranulares Extraktions- und Reasoning-Netzwerk zur Emotionserkennung im Dialog', 'id': 'FERNet: Rangkaian Ekstraksi dan Reasoning untuk Pengenalan Emosi dalam Dialog', 'ko': 'FERnet: 대화 중 감정 식별의 세립도 추출과 추리 네트워크', 'sw': 'FERNet: Mtandao mzuri wa Kutengeneza na Kujifunza Kutambua Uhisia katika Dialoga', 'fa': 'FERNet: اخراج و واکنش شبکه برای شناسایی احساسات در محاورها', 'af': 'FERNet: Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues', 'tr': 'FERNet: Emotik tanımlamak üçin Taýram we Reaksyonal Açmak Dialoglarda', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'bn': 'FERNet: ডায়ালগে ইমোটেশন স্বীকার করার জন্য ভালো গ্রেফতার এবং পুনরায় নেটওয়ার্ক', 'az': 'FERNet: Dialoglarda Emotion Recognition Network for Fine grain Extraction and Reasoning Network', 'bs': 'FERNet: Fino-grained Extraction and Reasoning Network for Emotion Recognition in Dialogs', 'ca': 'FERNet: Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues', 'cs': 'FERNet: Jemnozrnná extrakční a rozumná síť pro rozpoznávání emocí v dialogu', 'et': 'FERNet: peenrahaline ekstraheerimis- ja mõistmisvõrgustik emotsioonide äratundmiseks dialoogides', 'fi': 'FERNet: Hienorakeinen uuttamis- ja järkeilyverkosto tunteiden tunnistamiseksi vuoropuheluissa', 'sq': 'FERNet: Rrjeti i nxjerrjes dhe arsyetimit me drithëra të holla për njohjen e emocioneve në dialoge', 'hy': 'ՖԵՌՆԹ. Պարտահայտված զգացմունքների ճանաչման ցանցը պատմություններում', 'jv': 'MERERET: Fine-graned extration lan REASINging Network kanggo EMOtion REGNIVE Nang Dialog', 'he': 'FERNet: רשת יציאה ומסבירה מעולה לזהות רגשות בדיולוגים', 'sk': 'FERNet: Finozrnata mreža za pridobivanje in razumevanje čustev v dialogih', 'ha': 'FERNet: Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogues', 'bo': 'FERNet: Fine-grained Extraction and Reasoning Network for Emotion Recognition in Dialogs'}
{'en': 'Unlike non-conversation scenes,  emotion recognition  in dialogues (ERD) poses more complicated challenges due to its interactive nature and intricate  contextual information . All present methods model historical utterances without considering the content of the target utterance. However, different parts of a historical utterance may contribute differently to emotion inference of different target utterances. Therefore we propose Fine-grained Extraction and Reasoning Network (FERNet) to generate target-specific historical utterance representations. The reasoning module effectively handles both local and global sequential dependencies to reason over context, and updates target utterance representations to more informed vectors. Experiments on two  benchmarks  show that our  method  achieves competitive performance compared with previous  methods .', 'ar': 'على عكس المشاهد غير المتعلقة بالمحادثة ، فإن التعرف على المشاعر في الحوارات (ERD) يشكل تحديات أكثر تعقيدًا بسبب طبيعته التفاعلية والمعلومات السياقية المعقدة. جميع الطرق الحالية نموذج للألفاظ التاريخية دون النظر إلى محتوى الكلام الهدف. ومع ذلك ، قد تساهم أجزاء مختلفة من الكلام التاريخي بشكل مختلف في الاستدلال العاطفي لأقوال الهدف المختلفة. لذلك نقترح شبكة استخراج واستدلال دقيقة (FERNet) لإنشاء تمثيلات النطق التاريخي المحددة للهدف. تتعامل وحدة التفكير بشكل فعال مع التبعيات المتسلسلة المحلية والعالمية للتفكير على السياق ، وتقوم بتحديث تمثيلات الكلام المستهدف إلى نواقل أكثر استنارة. تظهر التجارب على مقياسين أن طريقتنا تحقق أداءً تنافسيًا مقارنة بالطرق السابقة.', 'es': 'A diferencia de las escenas que no son de conversación, el reconocimiento de emociones en los diálogos (ERD) plantea desafíos más complicados debido a su naturaleza interactiva y a su compleja información contextual. Todos los métodos actuales modelan enunciados históricos sin considerar el contenido del enunciado objetivo. Sin embargo, diferentes partes de un enunciado histórico pueden contribuir de manera diferente a la inferencia de emociones de diferentes enunciados objetivo. Por lo tanto, proponemos la Red de Extracción y Razonamiento de Grano Fino (FERNet) para generar representaciones históricas de enunciados específicos del objetivo. El módulo de razonamiento maneja eficazmente las dependencias secuenciales locales y globales para razonar sobre el contexto, y actualiza las representaciones de enunciados objetivo a vectores más informados. Los experimentos en dos puntos de referencia muestran que nuestro método logra un rendimiento competitivo en comparación con los métodos anteriores.', 'fr': "Contrairement aux scènes sans conversation, la reconnaissance des émotions dans les dialogues (ERD) pose des défis plus complexes en raison de sa nature interactive et de ses informations contextuelles complexes. Toutes les méthodes actuelles modélisent des énoncés historiques sans tenir compte du contenu de l'énoncé cible. Cependant, différentes parties d'un énoncé historique peuvent contribuer différemment à l'inférence émotionnelle de différents énoncés cibles. C'est pourquoi nous proposons un réseau d'extraction et de raisonnement à grain fin (FerNet) pour générer des représentations d'énoncés historiques spécifiques à la cible. Le module de raisonnement gère efficacement les dépendances séquentielles locales et globales de raisonnement par rapport au contexte, et met à jour les représentations d'énoncés cibles vers des vecteurs mieux informés. Des expériences sur deux points de référence montrent que notre méthode atteint des performances compétitives par rapport aux méthodes précédentes.", 'pt': 'Ao contrário das cenas de não-conversação, o reconhecimento de emoções em diálogos (ERD) apresenta desafios mais complicados devido à sua natureza interativa e informações contextuais intrincadas. Todos os métodos atuais modelam enunciados históricos sem considerar o conteúdo do enunciado alvo. No entanto, diferentes partes de um enunciado histórico podem contribuir de forma diferente para a inferência de emoções de diferentes enunciados alvo. Portanto, propomos a Rede de Extração e Raciocínio Refinado (FERNet) para gerar representações históricas de enunciados específicos do alvo. O módulo de raciocínio lida efetivamente com dependências sequenciais locais e globais para raciocinar sobre o contexto e atualiza as representações de enunciado de destino para vetores mais informados. Experimentos em dois benchmarks mostram que nosso método atinge um desempenho competitivo em comparação com os métodos anteriores.', 'zh': '与非对语不同,言情相别(ERD)因其交互性错上下文信而挑战。 凡诸时法,皆建模于史语,而不虑其语也。 然史语之异者,或以异情推之。 是以建议细粒度取推理网络(FERNet)以成特定史之语。 推理模块有效于本地全局顺序,以理上下文,而以向语示新为明向量。 二准之实验,比之前法,吾道有竞争力矣。', 'ru': 'В отличие от сцен, не связанных с разговором, распознавание эмоций в диалоге (ERD) создает более сложные проблемы из-за его интерактивного характера и сложной контекстной информации. Все существующие методы моделируют исторические высказывания без учета содержания целевого высказывания. Однако различные части исторического высказывания могут по-разному влиять на эмоциональный вывод различных целевых высказываний. Поэтому мы предлагаем сеть мелкозернистой экстракции и логического мышления (FERNet) для создания репрезентаций ретроспективных высказываний, специфичных для конкретной мишени. Модуль рассуждений эффективно обрабатывает как локальные, так и глобальные последовательные зависимости для обоснования контекста и обновляет представления целевых высказываний до более информированных векторов. Эксперименты по двум эталонам показывают, что наш метод достигает конкурентных показателей по сравнению с предыдущими методами.', 'ja': '非会話シーンとは異なり、対話における感情認識（ ERD ）は、そのインタラクティブな性質と複雑な文脈情報により、より複雑な課題をもたらす。すべての現在の方法は、ターゲット発話の内容を考慮せずに歴史的発話をモデル化する。しかしながら、歴史的発話の異なる部分は、異なるターゲット発話の感情推論に異なる寄与し得る。したがって、ターゲット固有の歴史的発話表現を生成するために、Fine - grained Extraction and Reasoning Network （ FERNet ）を提案します。推論モジュールは、文脈を超えて推論するローカルおよびグローバルのシーケンシャル依存関係の両方を効果的に処理し、ターゲット発話表現をより情報に基づいたベクトルに更新する。2つのベンチマークの実験では、当社の方法が以前の方法と比較して競争力のあるパフォーマンスを達成していることが示されています。', 'hi': 'गैर-वार्तालाप दृश्यों के विपरीत, संवादों (ईआरडी) में भावना मान्यता इसकी इंटरैक्टिव प्रकृति और जटिल प्रासंगिक जानकारी के कारण अधिक जटिल चुनौतियां पैदा करती है। सभी वर्तमान तरीके लक्ष्य उच्चारण की सामग्री पर विचार किए बिना ऐतिहासिक कथनों को मॉडल करते हैं। हालांकि, एक ऐतिहासिक उच्चारण के विभिन्न हिस्से विभिन्न लक्ष्य कथनों की भावनाओं के अनुमान में अलग-अलग योगदान कर सकते हैं। इसलिए हम लक्ष्य-विशिष्ट ऐतिहासिक उच्चारण अभ्यावेदन उत्पन्न करने के लिए फाइन-ग्रेन्ड एक्सट्रैक्शन एंड रीजनिंग नेटवर्क (FERNet) का प्रस्ताव करते हैं। तर्क मॉड्यूल प्रभावी रूप से संदर्भ पर तर्क करने के लिए स्थानीय और वैश्विक अनुक्रमिक निर्भरताओं दोनों को संभालता है, और अधिक सूचित वैक्टर के लिए लक्ष्य उच्चारण अभ्यावेदन को अपडेट करता है। दो बेंचमार्क पर प्रयोगों से पता चलता है कि हमारी विधि पिछले तरीकों की तुलना में प्रतिस्पर्धी प्रदर्शन प्राप्त करती है।', 'ga': 'Murab ionann agus radhairc neamhchomhrá, cruthaíonn aithint mhothúcháin in idirphlé (ERD) dúshláin níos casta mar gheall ar a nádúr idirghníomhach agus faisnéis chomhthéacsúil casta. Múnlaíonn gach modh atá ann faoi láthair nathanna stairiúla gan ábhar na sprice a chur san áireamh. Mar sin féin, féadfaidh codanna éagsúla de chaint stairiúil cur go héagsúil le tátail mhothúcháin ar spriocfhocail dhifriúla. Dá bhrí sin molaimid Líonra Astarraingthe agus Réasúnaithe Mhínnithe (FERNet) chun léiriúcháin stairiúla sprioc-shonracha a ghiniúint. Láimhseálann an modúl réasúnaíochta go héifeachtach spleáchais sheicheamhacha áitiúla agus dhomhanda araon chun réasúnaíocht a dhéanamh ar chomhthéacs, agus nuashonraítear uiríll cainte sprice chuig veicteoirí níos eolasaí. Léiríonn turgnaimh ar dhá thagarmharc go mbaineann ár modh feidhmíocht iomaíoch amach i gcomparáid le modhanna roimhe seo.', 'hu': 'A nem beszélgetési jelenetekkel ellentétben az érzelmek felismerése a párbeszédekben (ERD) sokkal bonyolultabb kihívásokat jelent interaktív természetének és bonyolult kontextuális információinak köszönhetően. Minden jelen módszer modellezi a történelmi kifejezéseket anélkül, hogy figyelembe venné a célkifejezés tartalmát. Egy történelmi kijelentés különböző részei azonban eltérően járulhatnak hozzá a különböző célkijelzések érzelmi következtetéséhez. Ezért javasoljuk a finomszemű extrakciós és érvelési hálózatot (FERNet) a célspecifikus történelmi kimondási reprezentációk létrehozásához. Az érvelési modul hatékonyan kezeli mind a helyi, mind a globális szekvenciális függőségeket a kontextus fölött, és frissíti a célkitűzési reprezentációkat a tájékozottabb vektorokra. Két referenciaértéken végzett kísérletek azt mutatják, hogy módszerünk versenyképes teljesítményt ér el a korábbi módszerekhez képest.', 'el': 'Σε αντίθεση με τις σκηνές μη συζήτησης, η αναγνώριση συναισθημάτων σε διαλόγους θέτει πιο περίπλοκες προκλήσεις λόγω της διαδραστικής φύσης της και της περίπλοκης περιεκτικής πληροφόρησης. Όλες οι σύγχρονες μέθοδοι μοντελοποιούν ιστορικές εκφράσεις χωρίς να λαμβάνουν υπόψη το περιεχόμενο της στοχευόμενης έκφρασης. Ωστόσο, διαφορετικά μέρη μιας ιστορικής έκφρασης μπορεί να συμβάλουν διαφορετικά στην συναίσθηση συμπερασμάτων διαφορετικών στοχοθετημένων εκφράσεων. Ως εκ τούτου, προτείνουμε το Δίκτυο Εκχύλισης και Λογιστικής (για την παραγωγή ιστορικών αναπαραστάσεων εκφρασμού συγκεκριμένων στόχων). Η ενότητα συλλογισμού διαχειρίζεται αποτελεσματικά τόσο τις τοπικές όσο και τις παγκόσμιες διαδοχικές εξαρτήσεις στη λογική πάνω από το πλαίσιο και ενημερώνει τις αναπαραστάσεις εκφρασμού στόχων σε πιο ενημερωμένα διανύσματα. Τα πειράματα σε δύο σημεία αναφοράς δείχνουν ότι η μέθοδος μας επιτυγχάνει ανταγωνιστικές επιδόσεις σε σύγκριση με τις προηγούμενες μεθόδους.', 'ka': 'პარამეტრების გარეშე, ემოციონის განახლება დიალოგში (ERD) უფრო კომპლექტირებული გამოცდილებები მისი ინტერაქტიური ნათობით და ინტერკექსტური ინფორმაციისთვის შემდეგ ყველა მიმდინარე მეტოვები ისტორიური სიტყვების მოდელური შესახებ, მიზედული სიტყვების შემდგომარების შემდგომარებით არ აღმო მაგრამ ისტორიური სიტყვების განსხვავებული ნაწილები შეიძლება განსხვავებული ემოციონის განსხვავებულ მიზეზი სიტყვებისთვის დაახლოებით. ამიტომ ჩვენ გვეძლევა საკუთარი ისტორიული გამოსახულების გამოსახულების შექმნა (FERNet). პარამენტის მოდულია ეფექტიურად ლოკალური და გლობალური სკენექციალური დასაწყვებულებების შესაძლებლობად კონტექსტის მიზეზი და მიზეზების უფრო ინფორმაციული გვე ორი ბანქმარკის ექსპერიმენტები ჩვენი მედიოდი მიიღება კონკენტებური გამოყენებას, როგორც წინა მედიოდით.', 'it': "A differenza delle scene non di conversazione, il riconoscimento delle emozioni nei dialoghi (ERD) pone sfide più complicate a causa della sua natura interattiva e delle intricate informazioni contestuali. Tutti i metodi presenti modellano le espressioni storiche senza considerare il contenuto dell'espressione target. Tuttavia, diverse parti di un'espressione storica possono contribuire in modo diverso all'inferenza emotiva di diverse espressioni target. Pertanto, proponiamo la Rete di Estrazione e Ragionamento Fine-Grained (FERNet) per generare rappresentazioni storiche di espressione specifiche per target. Il modulo di ragionamento gestisce efficacemente le dipendenze sequenziali locali e globali per ragionare sul contesto e aggiorna le rappresentazioni di pronuncia target a vettori più informati. Esperimenti su due parametri di riferimento dimostrano che il nostro metodo raggiunge prestazioni competitive rispetto ai metodi precedenti.", 'mk': 'За разлика од неразговарачките сцени, емоционалното препознавање во дијалозите (ЕРД) претставува покомплицирани предизвици поради нејзината интерактивна природа и сложени контекстни информации. Сите сегашни методи моделираат историски изрази без да се разгледува содржината на целниот израз. Сепак, различни делови од историското изразување може да придонесат различно во емоционалната инференција на различни целни изрази. Затоа предложуваме Фино-зелена мрежа за екстракција и разум (ФЕРНЕТ) за генерирање на историски репрезентации специфични за цел. Модулот за размислување ефикасно се справува со локалните и глобалните секвенцијални зависности од размислување во врска со контекстот, и ги ажурира претставувањата на изразот на целта на поинформирани вектори. Експериментите на две референтни оценки покажуваат дека нашиот метод постигнува конкурентна перформанса во споредба со претходните методи.', 'kk': 'Диалогтардың (ERD) эмоциялық түсініктемесінің түсініктемесінің түсініктемесінің түсініктемесінің себебі, оның интерактивті табиғат мен интерактивті контексті мәліметінің себебі Барлық қазіргі әдістер мақсатты сөздердің мазмұнын қарастырып, тарихлық сөздердің үлгісін үлгілейді. Бірақ тарихлық сөздердің әртүрлі бөлігі әртүрлі мақсатты сөздердің емоцияларына көмектесе алады. Сондықтан біз таңдау жүйесі (FERNet) таңдау және түзету желі (Fine-grained Extraction and Reasoning Network) таңдау үшін таңдаймыз. Арақтау модулі жергілікті және әлемді тәуелсіздіктерді контексті бойынша тәуелсіздіктерге әсер етеді және мақсатты сөздерді келтірілген векторларға жаңарту. Екі бағдарламалардың тәжірибелері біздің әдіміміздің алдыңғы тәжірибелерімен салыстырып тәжірибесін жеткізеді.', 'lt': 'Priešingai nei ne pokalbių scenos, emocijų pripažinimas dialoguose (ERD) kelia sudėtingesnius iššūkius dėl interaktyvaus pobūdžio ir sudėtingos kontekstinės informacijos. Visi dabartiniai metodai modeliuoja istorines išraiškas neatsižvelgiant į tikslinio išraiško turinį. Tačiau skirtingos istorinės išraiškos dalys gali skirtingai prisidėti prie skirtingų tikslinių išraiškų emocinių išvadų. Todėl siūlome Fine-grained Extraction and Reasoning Network (FERNet), kad būtų sukurti konkretūs tiksliniai istoriniai žodžiai. Motyvavimo modulis veiksmingai tvarko vietos ir pasaulines nuoseklias priklausomybes atsižvelgiant į aplinkybes ir atnaujina tikslinį išraišką labiau informuotiems vektoriams. Dviejų lyginamųjų rodiklių eksperimentai rodo, kad mūsų metodas, palyginti su ankstesniais metodais, yra konkurencingas.', 'ms': 'Tidak seperti adegan bukan perbualan, pengenalan emosi dalam dialog (ERD) menghasilkan cabaran yang lebih rumit disebabkan sifat interaktif dan maklumat kontekstual yang rumit. Semua kaedah kini model ungkapan sejarah tanpa mempertimbangkan kandungan ungkapan sasaran. Bagaimanapun, bahagian-bahagian yang berbeza dari ucapan sejarah mungkin menyumbangkan secara berbeza kepada kesimpulan emosi dari ucapan sasaran yang berbeza. Oleh itu, kami cadangkan Rangkaian Ekstraksi dan Rasionasi (FERNet) untuk menghasilkan persembahan keterangan sejarah khusus sasaran. Modul alasan mengendalikan dependensi sekuensi setempat dan global secara efektif untuk alasan atas konteks, dan kemaskini perwakilan ungkapan sasaran kepada vektor yang lebih maklumat. Eksperimen pada dua tanda referensi menunjukkan bahawa kaedah kita mencapai prestasi kompetitif dibandingkan dengan kaedah terdahulu.', 'ml': 'സംസാരിക്കാത്ത സ്ഥലങ്ങള്\u200dക്ക് വ്യത്യസ്തമാണ്, ഡയലോഗുകളിലെ വികാരങ്ങള്\u200d തിരിച്ചറിയുന്നതിനാല്\u200d അതിന്റെ interactive സ്വഭാവം കാരണം കൂടുതല്\u200d  നിലവിലുള്ള എല്ലാ രീതികളും ചരിത്ര വാക്കുകള്\u200d നിരീക്ഷിക്കുക എന്നാലും ചരിത്രത്തിലെ വാക്കുകളുടെ വ്യത്യസ്ത ഭാഗങ്ങള്\u200d വ്യത്യസ്തമായ വാക്കുകളുടെ വാക്കുകളില്\u200d വ്യത്യസ്ത വി അതുകൊണ്ട് നമ്മുടെ ലക്ഷ്യം പ്രത്യേകിച്ച ചരിത്ര വാക്കുകളുടെ പ്രതിനിധികള്\u200d ഉണ്ടാക്കാന്\u200d നല്ല പ്രാദേശിക്കുന്നു. ഈ കാരണങ്ങളുടെ ഘടകം പ്രാവര്\u200dത്ഥികമായി സ്ഥാനമായി കൈകാര്യം ചെയ്യുന്നു, കൂടുതല്\u200d അറിവുള്ള വെക്റ്ററുകള്\u200dക്ക് വേണ്ടി കാര്യങ്ങളുടെ  രണ്ട് ബെന്\u200dമാര്\u200dക്കിന്\u200dറെ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ രീതിയില്\u200d മത്സരത്തിലുള്ള പ്രകടനം എതിര്\u200dക്കു', 'mt': 'Għall-kuntrarju tax-xeni mhux ta’ konverżjoni, ir-rikonoxximent tal-emozzjonijiet fid-djalogi (ERD) joħloq sfidi aktar ikkumplikati minħabba n-natura interattiva tiegħu u informazzjoni kuntestwali kumplikata. Il-metodi preżenti kollha jimmudellaw dikjarazzjonijiet storiċi mingħajr ma jikkunsidraw il-kontenut tat-dikjarazzjoni fil-mira. Madankollu, partijiet differenti ta’ dikjarazzjoni storika jistgħu jikkontribwixxu b’mod differenti għall-inferenza emozzjonali ta’ dikjarazzjonijiet fil-mira differenti. Therefore we propose Fine-grained Extraction and Reasoning Network (FERNet) to generate target-specific historical utterance representations.  Il-modulu tar-raġunament jimmaniġġja b’mod effettiv kemm id-dipendenzi sekwenzjali lokali kif ukoll globali għar-raġuni fuq il-kuntest, u jaġġorna r-rappreżentazzjonijiet tal-espressjoni fil-mira għal vetturi aktar infurmati. L-esperimenti fuq żewġ punti ta’ riferiment juru li l-metodu tagħna jikseb prestazzjoni kompetittiva meta mqabbel ma’ metodi preċedenti.', 'pl': 'W przeciwieństwie do scen niekonwersacyjnych, rozpoznawanie emocji w dialogach (ERD) stanowi bardziej skomplikowane wyzwania ze względu na interaktywny charakter i skomplikowane informacje kontekstowe. Wszystkie obecne metody modelują historyczne wypowiedzi bez uwzględnienia treści wypowiedzi docelowej. Jednak różne części wypowiedzi historycznej mogą różnie przyczyniać się do wnioskowania emocji różnych wypowiedzi docelowych. W związku z tym proponujemy drobnoziarnistą sieć ekstrakcji i rozumowania (FERNet) w celu generowania specyficznych dla celów reprezentacji historycznych wypowiedzi. Moduł rozumowania skutecznie obsługuje zarówno lokalne, jak i globalne zależności sekwencyjne od rozumowania kontekstu i aktualizuje reprezentacje wypowiedzi docelowych do bardziej świadomych wektorów. Eksperymenty na dwóch wskaźnikach pokazują, że nasza metoda osiąga konkurencyjność w porównaniu z poprzednimi metodami.', 'mn': 'Дэлхийн биш байдлаас ялгаатай, диалог дээр сэтгэл хөдлөл ойлгох сэтгэл хөдлөл ойлгох нь илүү төвөгтэй сорилтуудыг үүсгэдэг. Бүх орчин үеийн арга нь зорилготой хэлбэрийн бүтээгдэхүүнийг ойлгохгүй түүхийн хэл загварын загвар юм. Гэхдээ түүхийн хэлэлцээний өөр хэсэг нь өөр өөр өөр зорилготой хэлэлцээний сэтгэл хөдлөлд нөлөөлөх боломжтой. Тиймээс бид финан тарианы тарианы тархины хэлбэрүүдийг бүтээх боломжийг санал болгож байна. Учир шалтгаан модуль нь орон нутгийн болон дэлхийн дараагийн холбоотой холбоотой холбоотой хамааралтай байдлыг шалтгааныг харуулж, зорилготой хэлбэрийг илүү мэдээлэлтэй векторууд руу шинэчлэх Хоёр салбарын туршилтууд бидний арга нь өмнөх арга замыг харьцуулахдаа өрсөлдөг үйл ажиллагааг гаргадаг.', 'no': 'I motsetjing av ikkje-samtalescenar kan følelseskjenning i dialogvindauge (ERD) plassera meir kompliserte utfordringar på grunn av sine interaktive natur og intrikative kontekstinformasjon. Alle gjeldande metodane modeller historiske uttrykk utan å forstå innhaldet i målet. Men forskjellige deler av eit historisk uttale kan bidra til følelsesinfeksjon av ulike målstaler. Det er derfor vi fører til å laga historiske uttrykk og grunnleggingsnettverk (FERNet). Reaksjonsmodulet handterar både lokale og globale sekvensiale avhengighet til grunn over kontekst, og oppdaterer målsettingsrepresentasjonar til meir informerte vektorar. Eksperiment på to benchmarker viser at metoden vårt når det gjer sammenlignet med førre metoder.', 'ro': 'Spre deosebire de scenele non-conversație, recunoașterea emoțiilor în dialoguri (ERD) reprezintă provocări mai complicate datorită naturii sale interactive și a informațiilor contextuale complicate. Toate metodele prezente modelează cuvintele istorice fără a lua în considerare conținutul cuvântului țintă. Cu toate acestea, diferite părți ale unei cuvinte istorice pot contribui diferit la deducerea emoțională a diferitelor cuvinte țintă. Prin urmare, propunem Rețeaua de extracție și raționare fină (FERNet) pentru a genera reprezentări istorice specifice țintei. Modulul de raționament gestionează în mod eficient atât dependențele secvențiale locale, cât și globale pentru a raționa peste context și actualizează reprezentările de rostire țintă pentru vectori mai informați. Experimentele pe două criterii de referință arată că metoda noastră atinge performanțe competitive comparativ cu metodele anterioare.', 'sr': 'Za razliku od scena bez razgovora, priznanje emocija u dijalogima (ERD) predstavlja komplikovanije izazove zbog interaktivne prirode i intriksnih kontekstualnih informacija. Svi sadašnji metodi modele istorijske reči bez razmišljanja o sadržaju ciljnog reči. Međutim, različiti dijelovi istorijskog govora mogu drugačije doprinijeti emocijama infekciji različitih ciljnih govora. Stoga predlažemo izvlačenu i razumnu mrežu (FERNet) za stvaranje predstavljanja istorijskog izražavanja ciljeva. Razumni modul efikasno obrađuje lokalne i globalne sekvenčne zavisnosti razuma u kontekstu, i aktualizuje predstave ciljnog rečenja informativnijim vektorima. Eksperimenti na dva kritika pokazuju da naša metoda postigne konkurentne funkcije u usporedbi sa prethodnim metodama.', 'sv': 'Till skillnad från icke-konversationsscener innebär känsloigenkänning i dialoger (ERD) mer komplicerade utmaningar på grund av dess interaktiva natur och intrikata kontextuella information. Alla nuvarande metoder modellerar historiska yttranden utan att beakta innehållet i måluttrycket. Olika delar av ett historiskt yttrande kan dock bidra annorlunda till känslomässiga slutsatser av olika målyttranden. Därför föreslår vi Finkornig Extraction and Reasoning Network (FERNet) för att generera målspecifika historiska yttringsrepresentationer. Motiveringsmodulen hanterar effektivt både lokala och globala sekventiella beroenden till resonemang över kontext, och uppdaterar målyttringsrepresentationer till mer informerade vektorer. Experiment på två riktmärken visar att vår metod uppnår konkurrenskraftig prestanda jämfört med tidigare metoder.', 'so': 'Meelaha aan la hadlin oo kala duwan, aqoonsashada dhakhtarka (ERD) waxay leedahay dhibaatooyin aad u adag, sababtoo ah dabiicadiisa interactive ah iyo macluumaad ku saabsan. Dhammaan qaababka la soo jeedo oo dhan qaababka ku saabsan hadal taariikhda ah oo aan ka fiirsanayn waxyaabaha ku qoran hadalka goalka. Si kastaba ha ahaatee qeybo kala duduwan oo hadalka taariikhda ah waxay si kala duwan uga faa’iidi karaan cudurka dareemaha iyo hadallada waxqabadka la jeedo oo kala duduwan. Sidaa darteed waxaynu soo jeedaynaa shabakadda Fine-grained Extraction and Reading (FERNet) si aan u soo saarno noocyo gaar ah oo ku qoran hadal historical ah. Noocyada sababta ah waxey si faa’iido leh u qabanqaabisaa ku xiran degmada iyo caalamiga ah, taas oo ku saabsan waxyaabaha ku saabsan, wuxuuna cusboonaysiiyaa noocyada hadalka waxqabadka ee la jeedo waddooyinka ogeysiinta ah. Imtixaanka labada bangiyadu waxay muuqataa in qaababkayagu uu gaadho sameynta iskutallaabta, iyadoo la barbardhigta qaababka hore.', 'si': 'සංවාද (ERD) වලින් සම්බන්ධ වෙන්න බැරි සම්බන්ධ ස්ථානයක් වගේ, සංවාද (සම්බන්ධ සංවාද) වලින් භාවිත අඳුරණය සියළුම මාර්ගයේ ඉතිහාසික වාර්තාව ප්\u200dරමාණයක් ඉලක්කම් කිරීමට හිතන්න බැරිවුනා. නමුත්, ඉතිහාසික වචනයක් වගේ වෙනස් කොටසක් වෙනස් විදිහට වෙනස් විදිහට සම්බන්ධ කරන්න පුළුවන්. ඉතින් අපි ප්\u200dරශ්නය කරන්නේ Fine-Graned Extraction and Reasoning NetworkName ප්\u200dරශ්නය මොඩ්යුල් ප්\u200dරශ්නයෙන් ස්ථානික සහ ජාතික ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය සඳහා සම්බන්ධතාවට හේතුව සඳහා හේ බෙන්ච්මාර්ක් දෙකක් ගැන පරීක්ෂණය පෙන්වන්නේ අපේ විදියට ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනවා කියලා', 'ta': 'பேசாத காட்சிகளுக்கு மாறுபட்டால், உரையாடலில் உணர்வு அடையாளம் (ERD) அதிக சிக்கலான சவால்கள் கொடுக்கிறது, அதன் நடுவில் செயல்படும் இயல்பா அனைத்து தற்போதைய முறைமைகளும் வரலாற்று வார்த்தைகளை பார்க்கவில்லை ஆனால், வரலாற்று வார்த்தையின் வித்தியாசமான பகுதிகள் வேறு வித்தியாசமாக உணர்வு பிரச்சனைகளின் வார்த்தைகளி ஆகையால் நாம் நன்றாக பிடிக்கப்பட்ட பிரித்தல் மற்றும் பிணையத்தின் பிணையத்தை உருவாக்க பரிந்துரைக்கிறோம். காரணங்களின் கூறு உள்ளூர் மற்றும் உலக பின்வரும் சார்ந்த சார்புகளையும் தேர்ந்தெடு இரண்டு பெங்குருக்களில் சோதனைகள் முந்தைய முறைமைகளுடன் ஒப்பிடும் போராட்டியின் செயல்பாட்டை பெறுகிறது என', 'ur': 'غیر بحث صحیفوں کے مطابق، ایرڈ کے درمیان احساسات کی پہچان سے زیادہ پیچیدہ چلنے کی وجہ سے اس کی پیچیدہ طبیعت اور پیچیدہ موضوع کی معلومات کی وجہ سے زیادہ پیچیدہ چلنے والی ہے. تمام موجود طریقے تاریخی کلمات کی مدل کرتے ہیں اور موجود کلمات کی منصوبت کو بغیر سمجھتے ہیں. اگرچہ، ایک تاریخی کلام کی مختلف قسموں میں مختلف طریقے سے مختلف طریقے کے کلمات کی احساسات کے ذریعے اضافہ کر سکتے ہیں. اسی وجہ سے ہم نیک دانے اٹھانے والی نیٹورک (FERNet) کو پیشنهاد کرتے ہیں تاریخی کہانیاں پیشنهاد کرنے کے لئے۔ منظورت موڈیل موجود موجود کے طور پر محلی اور گلوبی سکنٹیل اعتبارت کو منظورت کے ذریعہ سمجھانے کے لئے سمجھانے کے لئے سمجھانے کے لئے ہاتھ لگاتا ہے اور موجود بات کی تعریف کو زیادہ معلوم ویکتوروں کے دو بنچم مارک کے تجربے دکھاتے ہیں کہ ہمارا طریقہ پہلے طریقوں کے مقابلہ میں مقابلہ کرنے والی کامیابی پہنچتا ہے.', 'vi': 'Không giống những cảnh không nói chuyện, sự nhận dạng cảm xúc trong các ca thoại (ERD) tạo ra những thử thách phức tạp hơn vì bản chất tương tác và những thông tin phức tạp. Tất cả các phương pháp hiện thời đều mô phỏng lời nói lịch sử mà không xem xét nội dung của lời nhắn. Tuy nhiên, những phần khác nhau của một phát ngôn lịch sử có thể đóng góp khác nhau trong nhận biết cảm xúc của những phát biểu khác nhau. Do đó chúng tôi đề nghị tái cấu trúc tháo gỡ và Hợp lý (FERNet) để tạo ra các biểu tượng lịch sử cụ thể. Các mô- đun lập trình quản lý các quan hệ phụ thuộc theo kiểu địa phương và to àn cầu dựa vào lẽ phải trên ngữ cảnh, và cập nhật các diễn biến phát biểu đích đến với các môi trường thông tin hơn. Thí nghiệm trên hai tiêu chuẩn cho thấy phương pháp của chúng ta đạt được hiệu suất cạnh tranh so với các phương pháp trước.', 'uz': "@ info Hamma hozir usullar tarixi so'zlarni tasavvur qilmaydi. Lekin tarixiy so'zlarining boshqa qismlari boshqa so'zlarning o'zgarishni o'zgartirish mumkin. Shunday qilib, biz juda yaxshi ajratish va qidirish tarmoq (FERNet) bilan foydalanish uchun shaxsiy tarixi gaplarni yaratishni talab qilamiz. Name Ikki obʼektlarni tajriba qilish imtiyozlarimiz oldingi usullar bilan rivojlanishga ishlatiladi.", 'bg': 'За разлика от сцените без разговор, разпознаването на емоции в диалозите (ЕРД) поставя по-сложни предизвикателства поради интерактивния си характер и сложната контекстуална информация. Всички настоящи методи моделират историческите изказвания, без да се отчита съдържанието на целевата изказване. Въпреки това, различни части от историческото изказване могат да допринесат различно за емоционалното заключение на различни целеви изказвания. Ето защо предлагаме фина мрежа за извличане и разсъждаване (ФЕРнет) за генериране на специфични за целта исторически представяния на изказванията. Модулът за разсъждения ефективно обработва както локалните, така и глобалните последователни зависимости към разсъжденията над контекста и актуализира целевите представи на изказванията до по-информирани вектори. Експериментите по две показатели показват, че нашият метод постига конкурентни резултати в сравнение с предишните методи.', 'nl': 'In tegenstelling tot niet-conversatiescènes vormt emotie herkenning in dialogen (ERD) ingewikkeldere uitdagingen vanwege zijn interactieve aard en ingewikkelde contextuele informatie. Alle huidige methoden modelleren historische uitingen zonder rekening te houden met de inhoud van de doeluiting. Echter, verschillende delen van een historische uiting kunnen verschillend bijdragen aan de emotionele conclusie van verschillende doeluitingen. Daarom stellen we Fine-graned Extraction and Reasoning Network (FERNet) voor om doelgerichte historische uitingen te genereren. De redeneringsmodule behandelt effectief zowel lokale als globale sequentiële afhankelijkheden om te redeneren over context, en werkt target expression representaties bij naar meer geïnformeerde vectoren. Experimenten op twee benchmarks tonen aan dat onze methode concurrerende prestaties behaalt ten opzichte van eerdere methoden.', 'da': 'I modsætning til ikke-samtale scener udgør følelsesgenkendelse i dialoger (ERD) mere komplicerede udfordringer på grund af dens interaktive karakter og indviklede kontekstuelle information. Alle nuværende metoder modellerer historiske udtalelser uden at tage hensyn til indholdet af måludtalelsen. Forskellige dele af en historisk udtalelse kan dog bidrage forskelligt til følelsesudledelse af forskellige måludtalelser. Derfor foreslår vi Finkornet Extraction and Reasoning Network (FERNet) for at generere målspecifikke historiske ytringsrepræsentationer. Ræsonnementsmodulet håndterer effektivt både lokale og globale sekventielle afhængigheder til ræsonnering over kontekst, og opdaterer måludtalelsesrepræsentationer til mere informerede vektorer. Eksperimenter på to benchmarks viser, at vores metode opnår konkurrencedygtige resultater sammenlignet med tidligere metoder.', 'de': 'Im Gegensatz zu Nicht-Gesprächsszenen stellt die Emotionserkennung in Dialogen (ERD) aufgrund ihrer interaktiven Natur und komplexen Kontextinformationen kompliziertere Herausforderungen dar. Alle bisherigen Methoden modellieren historische Äußerungen, ohne den Inhalt der Zieläußerung zu berücksichtigen. Allerdings können verschiedene Teile einer historischen Äußerung unterschiedlich zur Emotionsfolgerung verschiedener Zieläußerungen beitragen. Daher schlagen wir Feingranulares Extraction and Reasoning Network (FERNet) vor, um zielspezifische historische Äußerungsrepräsentationen zu generieren. Das Argumentationsmodul behandelt effektiv sowohl lokale als auch globale sequentielle Abhängigkeiten zur Vernunft über Kontext und aktualisiert Target-Äußerungsdarstellungen auf besser informierte Vektoren. Experimente an zwei Benchmarks zeigen, dass unsere Methode im Vergleich zu bisherigen Methoden wettbewerbsfähig ist.', 'hr': 'Za razliku od scena bez razgovora, priznanje emocija u dijalogima (ERD) predstavlja kompliciranije izazove zbog interaktivne prirode i intriktirane kontekstske informacije. Svi sadašnji metodi modeliraju povijesni izraz bez razmatranja sadržaja ciljnog izraza. Međutim, različiti dijelovi povijesnog govora mogu doprinijeti drugačije emocijama infekciji različitih ciljnih izraza. Stoga predlažemo izvlačenu i razumnu mrežu (FERNet) za stvaranje predstavljanja istorijskog izražavanja ciljevima. Modul razmatranja djelotvorno obrađuje lokalnu i globalnu sekvencijsku zavisnost razuma u kontekstu i aktualizira predstavljanje ciljnih izraza na više informiranih vektorima. Eksperimenti na dva mjera pokazuju da naša metoda postigne konkurentne učinke u usporedbi s prethodnim metodama.', 'id': 'Tidak seperti adegan bukan percakapan, pengakuan emosi dalam dialog (ERD) menghasilkan tantangan yang lebih rumit karena alami interaktif dan informasi kontekstual yang rumit. Semua metode saat ini model ucapan sejarah tanpa mempertimbangkan isi ucapan sasaran. Bagaimanapun, bagian-bagian yang berbeda dari ucapan sejarah mungkin berkontribusi berbeda ke inferensi emosi dari ucapan target yang berbeda. Oleh karena itu kami mengusulkan Extraksi dan Reasoning Network (FERNet) untuk menghasilkan persembahan ekspresi sejarah spesifik target. Modul reasoning secara efektif menangani kedua dependensi sekwensial lokal dan global untuk alasan atas konteks, dan memperbaharui representation target utterance ke vektor yang lebih terinformasi. Eksperimen pada dua tanda referensi menunjukkan bahwa metode kita mencapai prestasi kompetitif dibandingkan dengan metode sebelumnya.', 'sw': 'Tofauti na maeneo yasiyo ya mazungumzo, kutambua hisia katika mazungumzo (ERD) yanaleta changamoto kubwa zaidi kutokana na asili yake ya kati na taarifa za kimataifa. All present methods model historical utterances without considering the content of the target utterance.  Hata hivyo, sehemu mbalimbali za hotuba ya kihistoria inaweza kusaidia tofauti ya kuongezeka kwa hisia kwa maneno tofauti ya malengo. Kwa hiyo tunapendekeza kutengeneza maongezi ya kihistoria yenye lengo hilo. Kifaa kinachosababishwa kinahusika kwa ufanisi na kutegemea kwa ajili ya kuelewa kwa muktadha, na habari mpya za hotuba zinazowakilishwa kwa vectori zenye taarifa zaidi. Majaribio kwenye misingi mawili yanaonyesha kuwa mbinu yetu inafanikiwa utendaji wa ushindani ukilinganishwa na njia zilizopita.', 'fa': 'بخلاف صحنه\u200cهای غیر گفتگو، شناختن احساسات در گفتگوها (ERD) چالش\u200cهای پیچیده\u200cتر به دلیل طبیعت\u200cهای متفاوتی و اطلاعات متفاوتی آن قرار می\u200cدهد. تمام روش\u200cهای موجود کلمات تاریخی را بدون توجه به محتوای کلمات هدف مدل می\u200cدهد. ولی بخشی های مختلف از یک سخن تاریخی ممکن است به طور متفاوتی به آلودگی احساسات از کلمات هدف مختلف کمک کند. بنابراین ما پیشنهاد می\u200cکنیم که شبکه\u200cی اخراج و دلیل\u200cسازی (FERNet) برای تولید نمایش\u200cدهندگان تاریخی\u200cهای هدف خاص باشد. مولد دلیل\u200cگیری به طور موثرت بستگی\u200cهای محلی و جهانی به دلیل\u200cهای مختلف، و نمایش\u200cهای گفتگوی هدف را به ویکتورهای اطلاعات بیشتری روبرو می\u200cکند. تجربه\u200cهایی روی دو برچسب نشان می\u200cدهند که روش ما با روش\u200cهای قبلی به رقابت رسیده است.', 'tr': 'Söhbet etmek sahypalary ýaly, duýgular tanamak dialoglarda özüniň täsirli tebigatyna we çevrili senediň maglumatyna sebäbi köp kynçylyklar döreýär. Hemme häzirki metodlar maksadyň sözlerini düşünmeden geçmiş sözleri nusgala. Yöne, taryhy sözleriniň beýleki bölegi üýtgeşik sözleriniň duýgularyň düşmegine üýtgeşik edip biler. Şol sebäpli biz Fine-grain Açmak we Reasoning Network (FERNet) maksadyň häzirki taryh sözlerini bejermek üçin teklip edip görýäris. Mantıklılık modüli hem lokal hem dünýädçe sonraki bağlantılardan hem kontekst üstünde düşünmek üçin ullanýar, hem maksady sözlerini daha bilgili vektörlere üýtgeder. Iki benchmarklarda örän experimentalar öňki döwürler bilen ýakynlaşykly etkinlik ukyplarymyzy ýetmegini görkezýär.', 'af': "Ongelyks van nie-gesprekslykskandes, bepaal emosie herkening in dialoog (ERD) meer kompliseerde uitdagings vanweë sy interaktiewe natuur en intrikaat contextual inligting. Alle huidige metodes model historiese uitdrukkings sonder om die inhoud van die doel uitdrukking te onderwerp. Maar verskillende dele van 'n historiese uitspraak kan anders bydra aan emosie inferensie van verskillende doel uitspraak. Daarom voorstel ons Fine-grained Extraction and Reasoning Network (FERNet) om die doel-spesifieke historiese uitdrukking voorstellings te genereer. Die redeming module effektief handteer beide plaaslike en globaal sekwensiele afhanklikhede tot rede oor konteks en opdateer die doel uitdrukking voorstellings tot meer inligtige vektore. Eksperimente op twee benchmarke wys dat ons metode gemeenskap doen met vorige metodes.", 'sq': 'Ndryshe nga skenat e jo-bisedës, njohja e emocioneve në dialoge (ERD) paraqet sfida më të komplikuara për shkak të natyrës së saj interaktive dhe informacionit kontekstual të komplikuar. Të gjitha metodat e tanishme modelojnë shprehjet historike pa konsideruar përmbajtjen e shprehjes objektive. Megjithatë, pjesë të ndryshme të shprehjes historike mund të kontribuojnë ndryshe në përfundimin emocional të shprehjeve të ndryshme objektive. Prandaj ne propozojmë rrjetin e ekstraksionit dhe arsyetimit të hollë (FERNet) për të gjeneruar përfaqësime të shprehjes historike specifike objektiv. Modulli arsyetimi trajton efektivisht si varësitë lokale ashtu dhe globale sekuencuese për arsyetimin lidhur me kontekstin dhe përditëson përfaqësimet e shprehjes objektive në vektorë më të informuar. Eksperimentet në dy pika referuese tregojnë se metoda jonë arrin performancë konkurruese krahasuar me metodat e mëparshme.', 'am': 'በተለየ እና ማነጋገር አይደሉም፣ የስህተት ማወቃት በመስኮቶች (ERD) በተጨማሪው ሥርዓት እና የአካባቢው መረጃ በመጠቀም ምክንያት የተጨማሪውን ጥቃት ያቆማል፡፡ የአሁኑን ዓይነቶች ሁሉ የአስረቢያ ቃላት አካባቢ ቃላት ሳይመለከት ነው፡፡ ነገር ግን የተለየ ታሪካዊ ንግግር የተለየ የአካባቢ ንግግር የልዩ አካላቢ ቋንቋ የሚታወቅ ክፍሎች በተለየ ልዩ ልዩ ልዩ ልዩ ልዩ አካላት እንዲያሳርፍ ይችላል፡፡ ስለዚህም የተለየ ታሪክ ንግግር መልዕክቶችን ለመፍጠር እና የመስጠት መረብ (FERNet) እናስጀጋለን፡፡ አዋቂው ሞዴል በጥያቄ እና በዓለምአቀፍ የሚታመቁትን በአካባቢ እና በሙሉ ማስታወቂያውን በመጠቀም እና የጉዳዩን ንግግር ማሳየት ለሚታወቁ vectors ማሻሻሻል፡፡ በሁለቱ benchmark ላይ ፈተናዎች ከቀድሞው ሥርዓት ጋር ተቃውሞ የሚደረገውን ሥርዓት እንዲያገኝ ያሳያል፡፡', 'bn': 'আলোচনার দৃশ্যের বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন কথোপকথনে ডায়ালগ (এরডি) এ আবেগ স সকল বর্তমান পদ্ধতি তার ঐতিহাসিক ভাষার মডেল করে টার্গেট বাক্যের বিষয়বস্তু বিবেচনা করা ছাড়া। However, different parts of a historical utterance may contribute differently to emotion inference of different target utterances.  কাজেই আমরা ভালো ক্রেতৃত্ব এবং প্রতিক্রিয়া নেটওয়ার্ক (FERNet) প্রস্তাব করছি যাতে লক্ষ্য-নির্দিষ্ট ঐতিহাসিক বক্তৃতার প্ যুক্তির মোডুল কার্যকর করে স্থানীয় এবং বিশ্বের পরবর্তীতে নির্ভর করে স্থানীয় এবং প্রেক্ষাপটের ব্যাপারে নির্ভর করার জন্য এবং আরো জ দুই বেনমার্কের পরীক্ষা দেখাচ্ছে যে আমাদের পদ্ধতি পূর্ববর্তী পদ্ধতির তুলনায় প্রতিযোগিতায় প্রতিযোগিতা প', 'ko': '비대화 장면과 달리 대화 중의 감정인식(ERD)은 상호작용성과 복잡한 언어 환경 정보 때문에 더욱 복잡한 도전을 가져왔다.기존의 방법은 모두 역사적 언어를 모델링하는 것이지 목표 언어의 내용을 고려하지 않는다.그러나 역사적 언어의 다른 부분은 서로 다른 목표 언어의 감정 추리에 서로 다른 영향을 미칠 수 있다.따라서 목표에 특정된 역사적 담론 표시를 생성하기 위해 세립도 추출과 추리망(FERnet)을 제시했다.추리 모듈은 상하문에서 추리를 할 수 있도록 국부와 전역 서열 의존을 효과적으로 처리하고 목표 언어를 더욱 정보적인 벡터로 업데이트한다.두 가지 기준 테스트에서의 실험은 이전의 방법에 비해 우리의 방법이 경쟁력 있는 성능을 얻었다는 것을 나타냈다.', 'az': 'Söhbət olmayan sahələrə bənzər, elçilər (ERD) içində emosyon tanıması interaktif təbiəti və müxtəlif məlumatlarına görə daha komplikat çətinliklərə bənzəyir. Bütün həmin metodlar məqsəd sözlərinin məlumatını baxmayaraq tarix sözlərini modelləyir. Lakin, tarixəli sözlərin müxtəlif parçaları müxtəlif məqsəd sözlərinin hisslərinin dəyişməsinə müxtəlif səbəb olar. Beləliklə, biz həqiqəti təsdiqləyən tarihi sözləri yaratmaq üçün Fine-grained Extraction and Reasoning Network (FERNet) təklif edirik. Röqsanlıq modulu hər ikisini yerli və küresel sonrakı bağlılıqlarını kontekst üzərində dəyişiklik etmək və məqsəd sözlərini daha çox bilgili vektörlərə yeniləndirir. Əvvəlki metodlar ilə qarşılaşdığımız təcrübələrimizin müqayisədə müqayisədi performansını göstərir.', 'ca': "A diferència de les escenes no de conversa, el reconeixement emocional en els diàlegs (ERD) pose reptes més complicats a causa de la seva naturalesa interactiva i la seva informació contextual complicada. Tots els mètodes actuals modelen expressions històriques sense considerar el contingut de l'expressió alvo. Però diferents parts d'una expressió històrica poden contribuir de manera diferent a la inferència emocional de diferents expressions d'objectiu. Així que proposem una Red d'Extracció i Reasoning Fine-grained (FERNet) per generar representacions històriques d'expressions específices per als objectius. El módul de raonament gestiona efectivament les dependencies seqüencials locals i globals per raonar sobre el context, i actualitza les representacions d'expressió destinada a vectors més informats. Els experiments de dos punts de referència demostren que el nostre mètode aconsegueix un rendiment competitiu comparat amb els mètodes anteriors.", 'cs': 'Na rozdíl od scén bez konverzace představuje rozpoznávání emocí v dialogu (ERD) komplikovanější výzvy kvůli interaktivní povaze a složitým kontextovým informacím. Všechny současné metody modelují historické výroky bez ohledu na obsah cílové výroky. Různé části historického výroku však mohou odlišně přispívat k emočnímu odvozu různých cílových výroků. Proto navrhujeme jemnou extrakční a odůvodnění síť (FERNet) pro generování cílově specifických historických reprezentací výroku. Modul uvažování efektivně zpracovává lokální i globální sekvenční závislosti na rozumu nad kontextem a aktualizuje reprezentace cílových výroků na informovanější vektory. Experimenty na dvou benchmarkech ukazují, že naše metoda dosahuje konkurenčního výkonu oproti předchozím metodám.', 'bs': 'Za razliku od scena bez razgovora, priznanje emocija u dijalogima (ERD) predstavlja komplikovanije izazove zbog interaktivne prirode i intriktirane kontekstske informacije. Svi sadašnji metodi modeliraju istorijske izreke bez razmišljanja o sadržaju ciljne izreke. Međutim, različiti dijelovi istorijskog govora mogu doprinijeti drugačije emocijama infekciji različitih ciljnih govora. Stoga predlažemo Fine-grained Extraction and Reasoning Network (FERNet) da bi stvorili predstave o istorijskoj izjavi cilja. Razumni modul efikasno obrađuje lokalnu i globalnu sekvencijsku zavisnost o razumijevanju u kontekstu, i aktualizuje predstave ciljnog izraza za više informiranih vektora. Eksperimenti na dva kritika pokazuju da naša metoda postigne konkurentne funkcije u usporedbi sa prethodnim metodama.', 'fi': 'Toisin kuin keskusteluttomat kohtaukset, tunteiden tunnistus dialogeissa (ERD) asettaa monimutkaisempia haasteita interaktiivisen luonteensa ja monimutkaisen kontekstitietonsa vuoksi. Kaikki nykyiset menetelmät mallintavat historiallisia ilmaisuja ottamatta huomioon kohdeilmaisun sisältöä. Historiallisen ilmaisun eri osat voivat kuitenkin vaikuttaa eri tavoin eri kohdeilmaisujen tunteiden päättelyyn. Siksi ehdotamme Fine-grained Extraction and Reasoning Network (FERNet), joka tuottaa kohdekohtaisia historiallisia ilmaisuesityksiä. Ratkaisumoduuli käsittelee tehokkaasti sekä paikalliset että globaalit peräkkäiset riippuvuudet järkeilyyn kontekstin yli ja päivittää kohdelauseiden esitykset tietoisempiin vektoreihin. Kahdella vertailuarvolla tehdyt kokeet osoittavat, että menetelmämme saavuttaa kilpailukykyisen suorituskyvyn edellisiin menetelmiin verrattuna.', 'hy': 'Ի տարբերություն ոչ խոսակցության բնագավառներից, զգացմունքների ճանաչելը դասախոսություններում ավելի բարդ մարտահրավերներ է առաջացնում իր ինտերակտիվ բնույթի և բարդ կոնտեքստալ ինֆորմացիայի պատճառով: Բոլոր ներկա մեթոդները մոդելավորում են պատմական արտահայտությունները առանց հաշվի առնելու նպատակային արտահայտության պարունակությունը: Այնուամենայնիվ, պատմական արտահայտության տարբեր մասերը կարող են այլ կերպ ներդրում ունենալ տարբեր նպատակային արտահայտությունների զգացմունքային հետևանքների վրա: Այդ պատճառով մենք առաջարկում ենք գեղեցիկ ցորենի արտադրման և մտածողության ցանց (ՖԵՌՆԹ) ստեղծելու համար նպատակի հատուկ պատմական արտահայտություններ: Պատկերացման մոդուլը արդյունավետ վերահսկում է տեղական և գլոբալ հաջորդականների կախվածությունը կոնտեքստի վերաբերյալ, և վերականգնում է նպատակային արտահայտությունների արտահայտությունը ավելի տեղեկացված վեկտորների համար: Երկու համեմատական նպատակների վրա կատարվող փորձարկումները ցույց են տալիս, որ մեր մեթոդը հասնում է մրցակցության արդյունք համեմատած նախորդ մեթոդների հետ:', 'et': 'Erinevalt vestluseta stseenidest tekitab emotsioonide tuvastamine dialoogides keerulisemaid väljakutseid oma interaktiivsuse ja keerulise kontekstiteabe tõttu. Kõik praegused meetodid modelleerivad ajaloolisi väljendeid ilma sihtväljendi sisu arvestamata. Ajaloolise väljendi erinevad osad võivad aga erinevate sihtväljendite emotsionaalsele järeldusele erinevalt kaasa aidata. Seetõttu pakume välja peenrahalise ekstraheerimise ja mõistmise võrgustiku (FERNet), et luua sihtspetsiifilisi ajaloolisi väljendusi. Mõtlemismoodul käsitleb tõhusalt nii kohalikke kui ka globaalseid järjestikuseid sõltuvusi konteksti üle mõtlemise ning värskendab sihtlause esitusi teadlikumateks vektoriteks. Kahe võrdlusnäitaja katsed näitavad, et meie meetod saavutab võrreldes varasemate meetoditega konkurentsivõimelise tulemuse.', 'jv': 'Gak Cocok-Colok diagram sing ora nggawe conversasi, akeh nesalamat karo dialog (ESD) sing berarti perbudhakan sing komplikasi sing ngengatining priwatara interactive lan informasi sing dikarepaké contextual. politenessoffpolite"), and when there is a change ("assertive Nanging, cah-cah sing sampeyan sing paling awak dadi iki bangsane mengko karo perusahaan langgar sampeyan karo kuwi kesempatan sing mengko nggawe tarjamahan Ero tambah, kita supoyo Fine-graned extration lan REASUN Network nggawe tarjamahan kelas kelelah The rationg module effectly handle the locale and global sequitorial packages to rationale about context, and Updates Tarject words representations to additional information vectors. 2', 'sk': 'Za razliko od prizorov brez pogovorov prepoznavanje čustev v dialogih (ERD) predstavlja bolj zapletene izzive zaradi interaktivne narave in zapletenih kontekstnih informacij. Vse prisotne metode modelirajo zgodovinske izjave brez upoštevanja vsebine ciljne izjave. Vendar pa lahko različni deli zgodovinskega izgovora drugače prispevajo k sklepanju čustev različnih ciljnih izgovorov. Zato predlagamo finozrnato mrežo ekstrakcije in razumevanja (FERNet) za ustvarjanje specifičnih ciljnih predstavitev zgodovinskih izgovorov. Modul razmišljanja učinkovito obravnava lokalne in globalne zaporedne odvisnosti od razuma nad kontekstom in posodablja ciljne predstavitve izgovorov v bolj informirane vektorje. Eksperimenti na dveh merilih kažejo, da naša metoda dosega konkurenčno uspešnost v primerjavi s prejšnjimi metodami.', 'bo': 'གླེང་སྒྲུང་མེད་པའི་གནས་སྟངས་དང་མི་འདྲ་བར་ན། སྒྲུང་ཚོགས་ནང་གི་སེམས་ཚོར་རྟོགས་ནི་ཧ་གོ་བསྐྱེད་པའི་གནད་དོན་དག་རེད། དམིགས་ཡུལ་ཐུབ་ཀྱི་ནང་དོན་འདི་ལྟ་བུ་རྣམ་གྲངས་ཀྱི་ལོ་རྒྱུས་ཀྱི་གནད་དོན་རྟོགས་པ་ཡིན། ཡིན་ནའང་། ལོ་རྒྱུས་ཀྱི་གནད་དོན་གང་འདྲ་ཞིག་གིས་སྤྲོད་ཀྱི་དམིགས་ཡུལ་ཁྱད་པར་མཐུན་རྐྱེན་ཏེ། དེར་བརྟེན། ང་ཚོས་Fine-grain Extraction and Reasoning Network (FERNet)ལ་དམིགས་ཡུལ་དམིགས The reasoning module effectively handles both local and global sequential dependencies to reason over context, and updates target utterance representations to more informed vectors. ངལ་རྟགས་ཟིན་བྲིས་གཉིས་བརྟན་ན། འུ་ཅག་གི་ཐབས་ལམ་ནི་ཕྱོགས་སྔོན་གྱི་ཐབས་ལམ་དང་མཉམ་དུ་མཐུན་གྱི་གོང་འཕེ', 'ha': "Di motsi da filayen yin magana, ganin hisãbi cikin zauren akwatin zauren akwatin bayani (ERD) na ƙayyade masu kalma masu tsananin husũma sabõda kanan da ke cikin shirin tarayya da kuma yana shiga bayani na guda. Dukan shiryoyin ayuka da ke yanzu, misalin ayuka na historical, bã da kula da kayan faɗin maganar da aka yi amfani da ba. A lokacin da, rabo dabam-dabam na faɗi na kihistoriki yana iya ƙara wa sauri na dabar-dabar-sauri. Saboda haka, Munã buɗar da Shirin Ayuka na Fine-graffed Extraction da Akwainuwa (FERNet) dõmin ya zata masu gabatar da baka-bayan magana masu ƙayyade. @ info: whatsthis Tajararin a kan bangon biyu na nuna cewa metodenmu za'a sami tsari da metodin zaman.", 'he': 'בניגוד לסצנות לא לשיחה, זיהוי רגשות בדיולוגים (ERD) יוצר אתגרים מסובכים יותר בגלל הטבע האינטראקטיבי שלה ומידע קונטוקטואלי מסובך. כל השיטות הנוכחיות דוגמניות ביטויים היסטוריים בלי לשקול את תוכן ביטוי המטרה. עם זאת, חלקים שונים של ביטוי היסטורי יכולים לתרום בצורה שונה למסקנה רגשית של ביטויים מטרה שונים. לכן אנו מציעים רשת חידוש ומסביר (FERNet) על מנת ליצור מייצגים היסטוריים מסויימים למטרה. מודול ההיגיון מטפל באופן יעיל גם תלויות רצפיות מקומיות וגלובליות כדי להסביר על הקשר, ומעדכן מייצגים מידע מטרה לווקטורים מודיעים יותר. ניסויים על שני נקודות רמז מראים שהשיטה שלנו משיגה ביצועים תחרותיים בהשוואה לשיטות קודמות.'}
{'en': 'Investigating Learning Dynamics of BERT Fine-Tuning BERT  Fine-Tuning', 'ar': 'التحقيق في ديناميكيات التعلم لضبط BERT الدقيق', 'es': 'Investigación de la dinámica de aprendizaje del ajuste de BERT', 'fr': "Étude de la dynamique d'apprentissage du réglage fin du BERT", 'pt': 'Investigando a Dinâmica de Aprendizagem do Ajuste Fino do BERT', 'ja': 'BERT微調整の学習ダイナミクスの調査', 'zh': '旒쥭ERT籃쉯졞駱뷘궏', 'hi': 'BERT ठीक ट्यूनिंग के सीखने की गतिशीलता की जांच', 'ru': 'Изучение динамики обучения BERT FINE-TUNING', 'ga': 'Ag Iniúchadh ar Dhinimic Foghlama Mhínithe BERT', 'el': 'Διερεύνηση της μαθησιακής δυναμικής του λεπτού συντονισμού BERT', 'ka': 'BERT სწავლის დინამიკის ინსტექტირება', 'hu': 'A BERT finomhangolásának tanulási dinamikájának vizsgálata', 'it': 'Indagine sulle dinamiche di apprendimento di BERT Fine-Tuning', 'mk': 'Истражување на динамиката на учењето на BERT финотизирање', 'lt': 'BERT tobulinimo mokymosi dinamikos tyrimas', 'mt': 'Investigazzjoni tad-Dinamika tat-Tagħlim tal-Aġġustament Irfinat BERT', 'kk': 'BERT жақсы баптау динамикасының оқыту динамикасы', 'ms': 'Menyelidiki Dinamika Pelajaran BERT Penyesuaian Terbaik', 'ml': 'ബെര്\u200dട്ടിയുടെ വിശിഷ്ടമായ ജീവിതത്തെ അന്വേഷിക്കുന്നു', 'pl': 'Badanie dynamiki uczenia się drobnego dostrojenia BERT', 'no': 'Investigating Learning Dynamics of BERT Fine-Tuning', 'mn': 'BERT Fine-Tuning-ын суралцах динамикийн судалгаа', 'si': 'BERT Fine-Tuning ගැන ඉගෙනගන්න සාධාරණය', 'ro': 'Investigarea dinamicilor de învăţare ale BERT Fine-Tuning', 'sv': 'Undersökning av inlärningsdynamiken hos BERT Finjustering', 'sr': 'Istraživanje dinamike učenja BERT-a', 'so': 'Baaritaanka barashada Dynamics of BERT Fine-Tuning', 'ta': 'Name', 'ur': 'BERT Fine-Tuning کی تعلیم دینامیک کی تحقیق', 'uz': 'Name', 'vi': 'Nghiên cứu về sự học động của BERT Fine-tuning', 'bg': 'Изследване на динамиката на ученето на фината настройка на BERT', 'hr': 'Istraživanje dinamike učenja BERT-a', 'da': "Undersøgelse af BERT's læringsdynamik", 'nl': 'Onderzoek naar de leerdynamiek van BERT Fine-Tuning', 'de': 'Untersuchung der Lerndynamik von BERT Fine-Tuning', 'fa': 'تحقیق دینامیک یادگیری از تنظیم نیک BERT', 'id': 'Menyelidiki Dinamika Belajar BERT Fine-Tuning', 'sw': 'Utafiti wa Kufundisha Dynamics wa Utamaduni wa BERT', 'ko': '버트 마이크로스피커 학습 동력학 연구', 'tr': 'BERT Fine-Tuning öwrenmek Dinamikleri', 'af': 'Inligting van leer dinamike van BERT Fine-Tuning', 'sq': 'Hetimi i dinamikës së mësimit të rregullimit të mirë të BERT', 'am': 'image-action', 'hy': 'BER Fine Tuning ուսումնասիրությունը', 'az': 'BERT Fine-Tuning √∂yr…ônm…ô dinamikl…ôrini inc…ôstat edir', 'bn': 'বেরেট ফিন-টিউনিং এর শিক্ষা শিক্ষা দৈত্য অনুসন্ধান করা হচ্ছে', 'bs': 'Istraživanje dinamike učenja BERT-a', 'ca': "Investigar la dinàmica d'aprenentatge de la BERT Fine Tuning", 'cs': 'Vyšetřování dynamiky učení jemného ladění BERT', 'et': 'BERT Fine-Tuning õppedünaamika uurimine', 'fi': 'BERT Fine-Tuningin oppimisdynamiikan tutkiminen', 'jv': 'igating Learning dynamics of BERT Fine-Tuning', 'he': 'חוקר דינמיקה ללמוד של התרגיל הטוב של BERT', 'ha': 'Ana Underestimation Ana Learn Dũnami of BERT Fine-Tuning', 'sk': 'Raziskovanje dinamike učenja BERT Fine-Tuning', 'bo': 'BERT Fine-Tuning ཡི་སྒྲ་ཚུལ་གྱི་སྣ་ཚོགས་ལ་བརྟག་ཞིབ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'The recently introduced pre-trained language model BERT advances the state-of-the-art on many NLP tasks through the fine-tuning approach, but few studies investigate how the fine-tuning process improves the  model  performance on downstream tasks. In this paper, we inspect the learning dynamics of BERT fine-tuning with two indicators. We use JS divergence to detect the change of the attention mode and use SVCCA distance to examine the change to the feature extraction mode during BERT fine-tuning. We conclude that BERT fine-tuning mainly changes the attention mode of the last layers and modifies the feature extraction mode of the intermediate and last layers. Moreover, we analyze the consistency of BERT fine-tuning between different  random seeds  and different datasets. In summary, we provide a distinctive understanding of the learning dynamics of BERT fine-tuning, which sheds some light on improving the  fine-tuning  results.', 'es': 'El modelo de lenguaje BERT previamente entrenado recientemente introducido mejora el estado de la técnica en muchas tareas de PNL a través del enfoque de ajuste fino, pero pocos estudios investigan cómo el proceso de ajuste mejora el rendimiento del modelo en las tareas posteriores. En este artículo, inspeccionamos la dinámica de aprendizaje de la puesta a punto de BERT con dos indicadores. Utilizamos la divergencia JS para detectar el cambio del modo de atención y utilizamos la distancia SVCCA para examinar el cambio al modo de extracción de características durante el ajuste fino de BERT. Concluimos que el ajuste fino de BERT cambia principalmente el modo de atención de las últimas capas y modifica el modo de extracción de características de las capas intermedia y última. Además, analizamos la consistencia del ajuste fino de BERT entre diferentes semillas aleatorias y diferentes conjuntos de datos. En resumen, proporcionamos una comprensión distintiva de la dinámica de aprendizaje del ajuste fino de BERT, que arroja algo de luz sobre la mejora de los resultados del ajuste fino.', 'ar': 'يعمل نموذج اللغة BERT الذي تم تقديمه مؤخرًا على تطوير أحدث التقنيات في العديد من مهام البرمجة اللغوية العصبية من خلال نهج الضبط الدقيق ، لكن القليل من الدراسات تبحث في كيفية تحسين عملية الضبط الدقيق لأداء النموذج في المهام النهائية. في هذه الورقة ، نفحص ديناميكيات التعلم لضبط BERT باستخدام مؤشرين. نحن نستخدم اختلاف JS لاكتشاف تغيير وضع الانتباه واستخدام مسافة SVCCA لفحص التغيير في وضع استخراج الميزات أثناء ضبط BERT. نستنتج أن الضبط الدقيق لـ BERT يغير بشكل أساسي وضع الانتباه للطبقات الأخيرة ويعدل وضع استخراج الميزة للطبقتين الوسيطة والأخيرة. علاوة على ذلك ، نقوم بتحليل اتساق الضبط الدقيق لـ BERT بين البذور العشوائية المختلفة ومجموعات البيانات المختلفة. باختصار ، نحن نقدم فهمًا مميزًا لديناميات التعلم لضبط BERT ، مما يلقي بعض الضوء على تحسين نتائج الضبط الدقيق.', 'fr': "Le modèle de langage pré-entraîné BERT, récemment introduit, fait progresser l'état de la technique sur de nombreuses tâches de PNL grâce à l'approche de réglage fin, mais peu d'études étudient comment le processus de réglage fin améliore les performances du modèle sur les tâches en aval. Dans cet article, nous examinons la dynamique d'apprentissage du réglage fin du BERT à l'aide de deux indicateurs. Nous utilisons la divergence JS pour détecter le changement du mode d'attention et nous utilisons la distance SVCCA pour examiner le changement du mode d'extraction de caractéristiques pendant le réglage fin du BERT. Nous concluons que le réglage fin BERT modifie principalement le mode d'attention des dernières couches et modifie le mode d'extraction des caractéristiques des couches intermédiaire et dernière. De plus, nous analysons la cohérence du réglage fin du BERT entre différentes graines aléatoires et différents ensembles de données. En résumé, nous apportons une compréhension particulière de la dynamique d'apprentissage du réglage fin du BERT, ce qui jette un peu de lumière sur l'amélioration des résultats de réglage fin.", 'pt': 'O modelo de linguagem pré-treinado BERT, introduzido recentemente, avança o estado da arte em muitas tarefas de PNL através da abordagem de ajuste fino, mas poucos estudos investigam como o processo de ajuste fino melhora o desempenho do modelo em tarefas downstream. Neste artigo, inspecionamos a dinâmica de aprendizado do ajuste fino do BERT com dois indicadores. Usamos a divergência JS para detectar a mudança do modo de atenção e usamos a distância SVCCA para examinar a mudança no modo de extração de recursos durante o ajuste fino do BERT. Concluímos que o ajuste fino do BERT altera principalmente o modo de atenção das últimas camadas e modifica o modo de extração de recursos das camadas intermediária e final. Além disso, analisamos a consistência do ajuste fino do BERT entre diferentes sementes aleatórias e diferentes conjuntos de dados. Em resumo, fornecemos uma compreensão distinta da dinâmica de aprendizado do ajuste fino do BERT, o que lança alguma luz sobre como melhorar os resultados do ajuste fino.', 'zh': '近者预训言语BERT微调之法,NLP进最先进之术,而罕究其高下之能。 本文以两指标验BERT微学动。 用JS散以检式,用SVCCA以检BERT微调以取式。 臣等所论,BERT微主变其末式,而改中间层最后之特征取式。 此外分别随机种子,不同数集BERT微调之一致性。 赞曰∶BERT微之学,资之以特解,这为之以微调。', 'ja': '最近導入された事前訓練された言語モデルBERTは、微調整アプローチを通じて多くのNLPタスクの最先端を進歩させているが、微調整プロセスが下流タスクのモデルパフォーマンスをどのように改善するかを調査する研究はほとんどない。本稿では， 2つの指標を用いてBERT微調整の学習動態を検討する． JS発散を使用して注目モードの変化を検出し、SVCCA距離を使用してBERT微調整中のフィーチャー抽出モードへの変化を調べます。BERTの微調整は、主に最後のレイヤーの注意モードを変更し、中間レイヤーと最後のレイヤーのフィーチャー抽出モードを変更すると結論付けます。さらに、異なるランダムシードと異なるデータセットとの間のBERT微調整の一貫性を分析する。要約すると、私たちはBERT微調整の学習ダイナミクスを独自に理解しており、微調整結果の改善にいくつかの光を当てています。', 'ru': 'Недавно введенная предварительно обученная языковая модель BERT продвигает современные технологии по многим задачам NLP с помощью подхода точной настройки, но лишь немногие исследования исследуют, как процесс точной настройки улучшает производительность модели по задачам ниже по потоку. В данной работе мы рассмотрим динамику обучения БЕРТ тонкой настройке с двумя показателями. Мы используем дивергенцию JS для обнаружения изменения режима внимания и расстояние SVCCA для изучения изменения режима извлечения признаков во время тонкой настройки BERT. Мы приходим к выводу, что точная настройка BERT в основном изменяет режим внимания последних слоев и изменяет режим выделения признаков промежуточного и последнего слоев. Кроме того, мы анализируем согласованность точной настройки BERT между различными случайными семенами и различными наборами данных. Подводя итог, мы обеспечиваем отличительное понимание динамики обучения тонкой настройке BERT, что проливает некоторый свет на улучшение результатов тонкой настройки.', 'hi': 'हाल ही में पेश किया गया पूर्व-प्रशिक्षित भाषा मॉडल BERT फाइन-ट्यूनिंग दृष्टिकोण के माध्यम से कई एनएलपी कार्यों पर अत्याधुनिक को आगे बढ़ाता है, लेकिन कुछ अध्ययन जांच करते हैं कि ठीक-ट्यूनिंग प्रक्रिया डाउनस्ट्रीम कार्यों पर मॉडल प्रदर्शन में कैसे सुधार करती है। इस पेपर में, हम दो संकेतकों के साथ BERT ठीक ट्यूनिंग की सीखने की गतिशीलता का निरीक्षण करते हैं। हम ध्यान मोड के परिवर्तन का पता लगाने के लिए जेएस विचलन का उपयोग करते हैं और BERT ठीक ट्यूनिंग के दौरान सुविधा निष्कर्षण मोड में परिवर्तन की जांच करने के लिए SVCCA दूरी का उपयोग करते हैं। हम निष्कर्ष निकालते हैं कि BERT ठीक ट्यूनिंग मुख्य रूप से अंतिम परतों के ध्यान मोड को बदलता है और मध्यवर्ती और अंतिम परतों के सुविधा निष्कर्षण मोड को संशोधित करता है। इसके अलावा, हम विभिन्न यादृच्छिक बीजों और विभिन्न डेटासेट के बीच BERT ठीक ट्यूनिंग की स्थिरता का विश्लेषण करते हैं। संक्षेप में, हम BERT ठीक ट्यूनिंग की सीखने की गतिशीलता की एक विशिष्ट समझ प्रदान करते हैं, जो ठीक-ट्यूनिंग परिणामों में सुधार पर कुछ प्रकाश डालता है।', 'ga': 'Leis an tsamhail teanga réamhoilte a tugadh isteach le déanaí cuireann BERT an úrscothacht ar go leor tascanna NLP chun cinn tríd an gcur chuige mionchoigeartaithe, ach is beag staidéar a dhéanann imscrúdú ar conas a fheabhsaíonn an próiseas mionchoigeartaithe an fheidhmíocht mhúnla ar thascanna iartheachtacha. Sa pháipéar seo, déanaimid iniúchadh ar dhinimic foghlama mhionchoigeartaithe CRET le dhá tháscaire. Bainimid úsáid as éagsúlacht JS chun athrú ar an modh aird a bhrath agus úsáidimid fad SVCCA chun an t-athrú ar an modh eastósctha gné a scrúdú le linn mionchoigeartú BERT. Bainimid de thátal as go n-athraíonn mionchoigeartú BERT modh aird na sraitheanna deiridh go príomha agus go modhnaítear modh eastósctha gné na sraitheanna idirmheánacha agus deiridh. Ina theannta sin, déanaimid anailís ar chomhsheasmhacht mhionchoigeartaithe BERT idir síolta randamacha éagsúla agus tacair shonraí éagsúla. Mar achoimre, soláthraímid tuiscint shainiúil ar dhinimic foghlama mhionchoigeartaithe CRET, rud a thugann léargas ar fheabhsú na dtorthaí mionchoigeartaithe.', 'el': 'Το πρόσφατα εισαγόμενο προ-εκπαιδευμένο γλωσσικό μοντέλο προωθεί την κατάσταση της τεχνολογίας σε πολλές εργασίες μέσω της προσέγγισης λεπτού συντονισμού, αλλά λίγες μελέτες διερευνούν πώς η διαδικασία λεπτού συντονισμού βελτιώνει την απόδοση του μοντέλου σε μεταγενέστερες εργασίες. Στην παρούσα εργασία, εξετάζουμε τη μαθησιακή δυναμική του συντονισμού με δύο δείκτες. Χρησιμοποιούμε την απόκλιση για να ανιχνεύσουμε την αλλαγή του τρόπου προσοχής και χρησιμοποιούμε την απόσταση για να εξετάσουμε την αλλαγή στη λειτουργία εξαγωγής χαρακτηριστικών κατά τη διάρκεια του συντονισμού. Συμπεραίνουμε ότι ο συντονισμός αλλάζει κυρίως τον τρόπο προσοχής των τελευταίων στρωμάτων και τροποποιεί τον τρόπο εξαγωγής χαρακτηριστικών του ενδιάμεσου και του τελευταίου στρώματος. Επιπλέον, αναλύουμε τη συνέπεια του συντονισμού μεταξύ διαφορετικών τυχαίων σπόρων και διαφορετικών συνόλων δεδομένων. Συνοπτικά, παρέχουμε μια ξεχωριστή κατανόηση της μαθησιακής δυναμικής της τελειοποίησης που ρίχνει κάποιο φως στη βελτίωση των αποτελεσμάτων της τελειοποίησης.', 'hu': 'A nemrégiben bevezetett, előzetesen képzett nyelvi modell, a BERT a finomhangolási megközelítés révén számos NLP feladat legkorszerűbb fejlesztését fejleszti elő, de kevés tanulmány vizsgálja, hogy a finomhangolási folyamat hogyan javítja a modell teljesítményét a downstream feladatok esetében. Ebben a tanulmányban két mutatóval vizsgáljuk meg a BERT finomhangolásának tanulási dinamikáját. JS divergenciát használunk a figyelemmód változásának észlelésére, és SVCCA távolságot használunk a funkciókivonási mód változásának vizsgálatára BERT finomhangolás során. Arra a következtetésre jutunk, hogy a BERT finomhangolása elsősorban az utolsó rétegek figyelemmódját változtatja meg, és módosítja a középső és utolsó rétegek funkciókivonási módját. Továbbá elemezzük a BERT finomhangolásának konzisztenciáját a különböző véletlenszerű vetőmag és a különböző adatkészletek között. Összefoglalva, megkülönböztető megértést nyújtunk a BERT finomhangolás tanulási dinamikájáról, ami rávilágít a finomhangolási eredmények javítására.', 'ka': 'მხოლოდ განვითარებული ენის მოდელი BERT-ს მუშაობა NLP რამდენიმე სამუშაო დამუშაობების შესახებ, მაგრამ რამდენიმე სამუშაო შესწავლობა თუ როგორ მოდელის კონფიგურაცია მოდელის კონფიგურაციას ამ დომენტში, ჩვენ შევხედავთ BERT-ის სწავლების დინამიკის ორი ინდექტორით. ჩვენ JS განსხვავებას გამოყენებთ დაახლოების რეჟიმის ცვლილებას და SVCCA განსხვავებას გამოყენებთ განსხვავებას განსხვავებას ფუნქციების ექსტრექციის რეჟიმის შემდეგ BERT დაა ჩვენ გავაკეთებთ, რომ BERT-ს კონფიგურაცია ძირითად შეცვლა ბოლო ჩანაწერის რეჟიმი და შეცვლა შორის და ბოლო ჩანაწერის ფუნქტურაციის გამოყენება რეჟიმი. დამატებით, ჩვენ განსხვავებული მონაცემების და განსხვავებული მონაცემების განსხვავებულობის BERT-ის კონსტენსტის ანალიზაცია. ჩვენ განსხვავებთ BERT-ის სწავლების დინამიკის განსხვავება, რომელიც განსხვავებული სინამდვილეების შესაძლებლობისათვის გაუკეთება.', 'kk': 'Жуырда келтірілген тіл үлгісі BERT бағдарламасы NLP тапсырмаларының көпшілігін жақсы баптау арқылы өзгертеді, бірақ бірнеше зерттеулердің баптау процесінің қалай баптау үлгісін төмендету тапсырмаларының істеу ар Бұл қағазда, біз BERT оқыту динамикасын екі индикаторымен қарап тұрамыз. Біз JS дивергенциясын қолданып, беRT жақсы баптау кезінде өзгерістерін тексеру үшін SVCCA қашықтығын анықтау үшін қолданып, BERT қатынау режімінің өзгерістерін тексеру үшін қолданамыз. Біз BERT баптауының негізінде соңғы қабаттардың назарын өзгертіп, орташа мен соңғы қабаттардың тарқату режімін өзгертіп, өзгертіп тұрады. Қосымша, біз BERT бағдарламасының әртүрлі кездейсоқ тарық мен әртүрлі деректер жиындарының тәуелсіздігін анализ. Тұжырымдамызда, біз BERT баптау динамикасының бірнеше түсініктерін береміз. Бұл жақсы баптау нәтижелерін жақсарту үшін бірнеше жарықты түсіндіреді.', 'it': "Il modello linguistico pre-addestrato BERT, recentemente introdotto, avanza lo stato dell'arte su molte attività NLP attraverso l'approccio di fine-tuning, ma pochi studi indagano in che modo il processo di fine-tuning migliora le prestazioni del modello sulle attività a valle. In questo articolo esaminiamo le dinamiche di apprendimento della messa a punto di BERT con due indicatori. Usiamo la divergenza JS per rilevare il cambiamento della modalità di attenzione e usiamo la distanza SVCCA per esaminare la modifica alla modalità di estrazione delle funzionalità durante la messa a punto di BERT. Concludiamo che la messa a punto di BERT cambia principalmente la modalità di attenzione degli ultimi strati e modifica la modalità di estrazione delle caratteristiche degli strati intermedi e degli ultimi. Inoltre, analizziamo la coerenza della messa a punto di BERT tra diversi semi casuali e diversi set di dati. In sintesi, forniamo una comprensione distintiva delle dinamiche di apprendimento del fine-tuning BERT, che fa luce sul miglioramento dei risultati di fine-tuning.", 'lt': 'Neseniai įdiegtas iš anksto parengtas kalbų modelis BERT gerina pažangą daugelio NLP užduočių srityje tobulinant metodą, tačiau nedaugelis tyrimų tiria, kaip tobulinimo procesas gerina modelio rezultatus tolesnių užduočių srityje. Šiame dokumente tikriname BERT mokymosi dinamiką, suderintą su dviem rodikliais. JS skirtumas nustatomas dėmesio režimo pasikeitimui ir SVCCA atstumui tikrinti savybių ištraukimo režimo pasikeitimą BERT tikslumo metu. Galime daryti išvadą, kad BERT patobulinimas iš esmės keičia pastarųjų sluoksnių dėmesio režimą ir keičia tarpinių ir paskutinių sluoksnių savybių ištraukimo režimą. Be to, analizuojame BERT patikslinimo tarp skirtingų atsitiktinių sėklų ir skirtingų duomenų rinkinių nuoseklumą. Apibendrinant, mes aiškiai suprantame BERT patobulinimo mokymosi dinamiką, kuri leidžia šiek tiek šviesos tobulinti patobulinimo rezultatus.', 'ms': 'Model bahasa yang baru-baru ini diperkenalkan BERT melanjutkan kemajuan-kemajuan dalam banyak tugas NLP melalui pendekatan penyesuaian, tetapi beberapa kajian menyelidiki bagaimana proses penyesuaian memperbaiki prestasi model pada tugas turun. Dalam kertas ini, kita periksa dinamik pembelajaran BERT penyesuaian dengan dua indikator. Kami menggunakan divergensi JS untuk mengesan perubahan mod perhatian dan menggunakan jarak SVCCA untuk memeriksa perubahan ke mod ekstraksi ciri semasa penyesuaian BERT. Kami menyimpulkan bahawa penyesuaian BERT terutamanya mengubah mod perhatian lapisan terakhir dan mengubah mod ekstraksi ciri lapisan tengah dan terakhir. Selain itu, kami menganalisis konsistensi penyesuaian BERT antara benih rawak berbeza dan set data berbeza. Secara ringkasan, kami menyediakan pemahaman yang berbeza tentang dinamik pembelajaran penyesuaian BERT, yang memberikan beberapa cahaya untuk meningkatkan hasil penyesuaian.', 'mk': 'Неодамна воведениот предобучен јазички модел БЕРТ го унапредува најновиот модел на многуте задачи на НЛП преку пристапот на финетизирање, но неколку студии истражуваат како процесот на финетизирање ја подобрува резултатот на моделот на понатамошните задачи. Во овој весник, ја проверуваме динамиката на учењето на BERT финетизирање со два индикатори. Ние ја користиме дивергенцијата на JS за да ја детектираме промената на режимот на внимание и да ја користиме дистанцата на SVCCA за да ја испитаме промената на режимот на екстракција на функциите за време на BERT финетирање. Завршуваме дека подобрувањето на BERT главно го менува режимот на внимание на последните слоеви и го модификува режимот на екстракција на карактеристиките на средните и последните слоеви. Покрај тоа, ја анализираме константноста на BERT финетизирање помеѓу различни случајни семиња и различни податоци. Во кратко, обезбедуваме различен разбирање на динамиката на учењето на подобрувањето на БЕРТ, што дава малку светлина за подобрувањето на резултатите на подобрувањето на подобрувањето.', 'mt': 'Il-mudell lingwistiku mħarreġ minn qabel li ġie introdott reċentement BERT javvanza l-aktar avvanzat fuq ħafna kompiti NLP permezz tal-approċċ ta’ rfinar, iżda ftit studji jinvestigaw kif il-proċess ta’ rfinar itejjeb il-prestazzjoni tal-mudell fuq kompiti downstream. F’dan id-dokument, aħna ninspezzjonaw id-dinamika tat-tagħlim tal-aġġustament tal-BERT b’żewġ indikaturi. Aħna nużaw id-diverġenza JS biex niżvelaw il-bidla fil-modalità tal-attenzjoni u nużaw id-distanza SVCCA biex nieżaminaw il-bidla fil-modalità tal-estrazzjoni tal-karatteristiċi waqt l-irfinar BERT. Aħna kkonkludew li l-irfinar BERT jibdel prinċipalment il-mod ta’ attenzjoni tal-aħħar saffi u jimmodifika l-mod ta’ estrazzjoni tal-karatteristiċi tas-saffi intermedji u l-aħħar. Barra minn hekk, nagħmlu analiżi tal-konsistenza tal-aġġustament bir-reqqa tal-BERT bejn żrieragħ każwali differenti u settijiet ta’ dejta differenti. In summary, we provide a distinctive understanding of the learning dynamics of BERT fine-tuning, which sheds some light on improving the fine-tuning results.', 'no': 'Den nyleg introduserte språk- modellen BERT forbetrar kunstået på mange NLP- oppgåver gjennom finnstillingstilnærming, men få studier undersøker korleis finnstillingsprosessen forbetrar modellen på nedtrekkoppgåver. I denne papiret kontrollerer vi læringsdynamikken av BERT med to indikatorer. Vi brukar JS-divergens for å finna endringane av oppmerksmodus og bruka SVCCA-avstanden for å undersøke endringane til funksjonsekstraksjonsmodus under BERT-finnstilling. Vi avsluttar at BERT-innstillinga endrar hovudsakelig oppmerksmodus for dei siste lagene og endrar funksjonen for utpakkingsmodus av mediane og siste lag. I tillegg analyserer vi konsistensitet av BERT-finnstilling mellom ulike tilfeldige deler og ulike datasett. I sammendrag gir vi ein spesifikk forståelse av læringsdynamikken av BERT-fin-tuning, som gjer litt lys på å forbetra fin-tuning-resultatene.', 'pl': 'Niedawno wprowadzony wstępnie przeszkolony model językowy BERT rozwija najnowocześniejszy stan techniki w wielu zadaniach NLP poprzez podejście do dostrajania, ale niewiele badań bada, w jaki sposób proces dostrajania poprawia wydajność modelu w dalszych zadaniach. W niniejszym artykule analizujemy dynamikę uczenia się dostrajania BERT za pomocą dwóch wskaźników. Używamy dywergencji JS, aby wykryć zmianę trybu uwagi i używamy odległości SVCCA, aby zbadać zmianę w trybie ekstrakcji cech podczas dostrajania BERT. Wnioskujemy, że dostosowanie BERT zmienia głównie tryb uwagi ostatnich warstw oraz modyfikuje tryb ekstrakcji cech warstwy pośredniej i ostatniej. Ponadto analizujemy spójność dostrajania BERT między różnymi losowymi nasionami i różnymi zbiorami danych. Podsumowując, zapewniamy wyraźne zrozumienie dynamiki uczenia się dostrajania BERT, co rzuca trochę światła na poprawę wyników dostrajania.', 'ro': 'Modelul lingvistic pre-instruit recent introdus, BERT, avansează avantajele de ultimă oră în multe sarcini PNL prin abordarea de reglare fină, dar puține studii analizează modul în care procesul de reglare fină îmbunătățește performanța modelului în sarcinile din aval. În această lucrare, inspectăm dinamica de învățare a reglajului fin BERT cu doi indicatori. Utilizăm divergența JS pentru a detecta schimbarea modului de atenție și utilizăm distanța SVCCA pentru a examina schimbarea modului de extragere a caracteristicilor în timpul reglării fine BERT. Concluzionăm că reglarea fină BERT modifică în principal modul de atenție al ultimelor straturi și modifică modul de extragere a caracteristicilor straturilor intermediare și ultimelor straturi. Mai mult decât atât, analizăm consistența reglării fine a BERT între diferite semințe aleatorii și seturi de date diferite. Pe scurt, oferim o înțelegere distinctivă a dinamicii de învățare a reglării fine a BERT, ceea ce pune o lumină asupra îmbunătățirii rezultatelor reglării fine.', 'ml': 'അടുത്തുതന്നെ പരിശീലിക്കപ്പെട്ട ഭാഷ മോഡല്\u200d ബെര്\u200dട്ടി മുന്\u200dകൂട്ടിയിട്ടുണ്ടായിരുന്നു. ഒരുപാട് NLP ജോലികളുടെ രാജ്യത്തെ മുന്\u200dകൂട്ടുന്നു. പക്ഷെ കുറച്ചു പഠനങ ഈ പത്രത്തില്\u200d, നമ്മള്\u200d ബെര്\u200dട്ടിയുടെ പഠനാവുന്നതിന്\u200dറെ ഡൈനാമിക്സ് പരിശോധിക്കുന്നു. രണ്ട് അടയാളങ്ങള്\u200d കൊണ് നമ്മള്\u200d ജെസ്സിന്റെ വ്യത്യാസങ്ങള്\u200d ഉപയോഗിക്കുന്നു ശ്രദ്ധ മോഡിന്റെ മാറ്റങ്ങള്\u200d കണ്ടുപിടിക്കുവാനും ബെര്\u200dട്ടിന്റെ മുന്\u200dകൂട്ടി ബെര്\u200dട്ടിന്റെ സുന്ദരിയുടെ പ്രധാനപ്പെട്ട ടാളുകളുടെ ശ്രദ്ധ മാറ്റുന്നു അവസാനത്തെ തടുത്തുകളുടെ ശ്രദ്ധ മാറ്റുന്നതും ഇടത് അതുകൊണ്ടും, നമ്മള്\u200d വ്യത്യസ്തമായ വിത്രങ്ങള്\u200dക്കും വ്യത്യസ്ത ഡാറ്റാസറ്റുകള്\u200dക്കും തമ്മിലുള്ള ബെര്\u200dട്ടിന്\u200dറെ സ ഉച്ചത്തില്\u200d, ബെര്\u200dട്ടിന്\u200dറെ സുന്ദരിയുടെ പഠനത്തിന്\u200dറെ വ്യത്യസ്തമായ ഒരു മനസ്സിലാക്കിയിരിക്കുന്നു. അത് നല്ല വിവരങ്ങള്\u200d മുന്\u200dകൂട്ട', 'mn': 'Саяхан сургалтын өмнө сургалтын хэл загварын загвар BERT нь NLP даалгаврын олон ажил дээрх урлагийн төвшин хөгжүүлдэг. Гэхдээ хэд хэдэн судалгаанууд бага даалгаврын даалгаврын загварын үйлдвэрлэлийг хэрхэн сайжруулдаг талаар судалж Энэ цаасан дээр бид БЕРТ-ийн суралцах динамикийг хоёр загвартай сайжруулах хэрэгтэй. Бид JS диверензийг анхаарал төвлөрүүлэх горимын өөрчлөлтийг мэдэхэд ашиглаж, БЕРТ сайн тохирох үед өөрчлөлтийг шийдэхэд SVCCA зай ашиглаж байна. Бид БЕРТ-г тодорхойлох нь ихэвчлэн сүүлийн давхарын анхаарлын загварыг өөрчилж, дундаж болон сүүлийн давхарын ялгаруулах загварыг өөрчилж байна. Мөн бид өөр санамсаргүй үр болон өөр өгөгдлийн сангийн хоорондох BERT-ын тохиромжтой байдлыг шинжилгээ хийдэг. Түүнчлэн бид БЕРТ-ын суралцах динамикийг тодорхой ойлгох боломжтой болгож байна. Энэ нь сайн тодорхойлолтын үр дүнг сайжруулахад зарим гэрлийг ашигладаг.', 'sr': 'Nedavno uvedeni predobučeni jezički model BERT napreduje stanje umjetnosti na mnogim zadacima NLP-a kroz dobar pristup, ali nekoliko studija istražuju kako proces finaliziranja poboljšava modelnu funkciju na sledećim zadacima. U ovom papiru, provjeravamo dinamiku učenja BERT-a sa dva indikatora. Koristimo JS razliku da otkrijemo promjenu pažnje režima i koristimo daljinu SVCCA da pregledamo promjenu režima izvlačenja funkcija tijekom dobre prilike BERT. Zaključili smo da BERT finaliziranje uglavnom mijenja pažnju režima poslednjih slojeva i modifikuje režim izvlačenja funkcija prosječnih i poslednjih slojeva. Osim toga, analiziramo konsekvenciju BERT-a između različitih nasumičnih semena i različitih seta podataka. U sažetku, pružamo određeno razumijevanje dinamike učenja BERT-a, koja proizvodi malo svjetla na poboljšanju rezultata dobre prilagodbe.', 'si': 'අවස්ථානයෙන් ප්\u200dරධාන භාෂාව ප්\u200dරධානය කරලා තියෙන්නේ BERT නිර්මාණය සඳහා NLP ක්\u200dරියාවක් ගොඩක් වැඩේ වැඩ කරන්න, ඒත් පරීක්ෂණය ටිකක් පරීක්ෂණය මේ පත්තරේ අපි පරීක්ෂා කරනවා BERT ගේ ඉගෙනගන්න සාධාර්ථක විද්\u200dයාපනය දෙකක් තියෙන්නේ. අපි JS විවිධානය භාවිතා කරනවා අවධානය විධානය පරීක්ෂණය කරන්න සහ SVCCA දුරය භාවිතා කරනවා BERT විවිධානය සඳහා විවිධානය ප අපි පිළිබඳු වෙනවා BERT හොඳ සංවිධානය විශේෂයෙන් අන්තිම ස්ථානයේ අවධානය සහ අන්තිම ස්ථානයේ අවධානය සහ අවධ තවත්, අපි BERT විවිදිහට විවිදිහට පරීක්ෂණය කරනවා වෙනස් විදිහට පරීක්ෂණය සහ වෙනස් දත්ත සේට් අතර. සම්පූර්ණයෙන්, අපි BERT සුදුසුම් සුදුසුම් සුදුසුම් ගැන ඉගෙන ගන්න පුළුවන් තේරුම් ගන්නවා, ඒකෙන් සුදුසුම් සුදුස', 'so': 'Muddii ugu dhowayd waxaa lagu soo bandhigay tusaale ahaan afka hore oo lagu tababaray BERT ayaa horumarinaya xaalada farshaxanta ee shaqada badan ee NLP, laakiin waxaa laga baaraandegay wax yar oo baaritaanka ku saabsan sameynta sameynta sameynta sameynta sameynta sameynta hawlaha hoose. Warqadan waxaynu ka fiirinaynaa cilmiga barashada ee BERT si fiican loola jeedo labo indicator. Waxaynu u isticmaalnaa JS bedelka si aan u ogaano isbedelka hababka islamarkaasna aan u isticmaalnaa SVCCA durdurka si aan u baaritaanno bedelka bedelka qaabka loo soo bixiyo xiliga BERT fine-tuning. Waxaynu dhamaystiraynaa in BERT qurxinta ugu horeyn beddeli qaabka booqashada ee ugu dambeeya, wuxuuna beddeli qaabka soo saarista xiliga dhexe iyo ugu dambeeya. Sidoo kale waxaynu wax u baaraynaa dabiicadda BERT oo kala duduwan abuurka kala duduwan iyo sawirada kala duduwan. Xigaalka ugu dhaw, waxaynu soo bandhignaynaa waxyaabo kala duwan oo ku saabsan barashada farsamada BERT, kaasoo iftiin ka muuqata horumarinta midhihiisa wanaagsan.', 'sv': 'Den nyligen introducerade färdigutbildade språkmodellen BERT lyfter fram det senaste inom många NLP-uppgifter genom finjusteringsmetoden, men få studier undersöker hur finjusteringsprocessen förbättrar modellprestandan för nedströmsuppgifter. I denna uppsats undersöker vi inlärningsdynamiken för BERT-finjustering med två indikatorer. Vi använder JS-avvikelse för att upptäcka förändringen av uppmärksamhetsläget och använder SVCCA-avstånd för att undersöka förändringen av funktionsextraktionsläget under BERT-finjustering. Vi drar slutsatsen att BERT-finjustering huvudsakligen ändrar uppmärksamhetsläget för de sista lagren och ändrar funktionsextraktionsläget för de mellanliggande och sista lagren. Dessutom analyserar vi konsistensen i BERT finjustering mellan olika slumpmässiga frön och olika datauppsättningar. Sammanfattningsvis ger vi en tydlig förståelse för inlärningsdynamiken i BERT finjustering, vilket kastar lite ljus på förbättringen av finjusteringsresultaten.', 'ta': 'சமீபத்தில் பயிற்சி முன்பயிற்சி மொழி மாதிரி பிரெட் நிலையை மேம்படுத்தி பல NLP பணிகளில் முன்னேற்றுகிறது, ஆனால் சில ஆராய்ச்சிகள் எப்படி நன்றாக முன்னேற்றும் ச In this paper, we inspect the learning dynamics of BERT fine-tuning with two indicators.  நாம் JS வேறுபாட்டை பயன்படுத்தி கவனத்தின் முறைமையை கண்டுபிடிக்க மற்றும் SVCCA தூரத்தை பயன்படுத்தி தனிப்பயன் பிரெட்டு முறையில் செ நாம் முடிவு செய்கிறோம் BERT சரியான தூண்டுதல் முக்கியமாக கடைசி அடுக்குகளின் கவனத்தை மாற்றுகிறது மற்றும் நடுத்த மற்றும் கடைச மேலும், நாம் வேறு குறிப்பில்லாத வித்திகள் மற்றும் வேறு தரவு அமைப்புகளுக்கும் இடையே BERT சரியான தொடர்பை ஆர சுருக்கத்தில், நாம் ஒரு வித்தியாசமான பிரெட் நன்மையான தூண்டுதல் கற்றுக்கொள்ளும் இயற்கையை கொடுக்கிறோம், அது நன்மை முடிவுகள', 'ur': 'اچھے سے پہلے تحصیل کی زبان موڈل BERT نے بہت سی NLP تاسکیوں پر بہت سی مطابق اضافہ کی ہے، لیکن بہت سی مطابق تحقیق کرتی ہیں کہ نیک ٹونگ پروسس کس طرح ڈونسٹریم تاسکیوں پر موڈل کی عمدگی اضافہ کرتی ہے. اس کاغذ میں، ہم نے BERT کی سیکھنے کی ڈینامیک کو دو نشانیوں کے ساتھ تحقیق کیا۔ ہم JS اختلاف کو استعمال کرتے ہیں کہ توجه موڈ کے بدلنے کو پہچان سکیں اور SVCCA فاصلہ کو استعمال کریں کہ BERT فائدہ تنظیم کے وقت فعالیت اضافہ موڈ کے بدلنے کے لئے بدلنے کے لئے استعمال کریں. ہم تصمیم لیتے ہیں کہ BERT نیٹ تنظیم کی عمدہ طور پر اخرین لائٹوں کی توجه موڈ کو بدل دیتا ہے اور اخرین لائٹوں اور فائدہ اخراج موڈ کو بدل دیتا ہے. اور ہم نے BERT کے مطابق مختلف طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح ہم نے BERT نیٹ ٹونگ کی سیکھنے والی ڈینامیک کی ایک متفاوت سمجھ دی ہے، جو نیٹ ٹونگ نتائج کو بہتر کرنے پر کچھ نور ڈالتا ہے.', 'vi': 'Dự án ngôn ngữ được tuyển dụng gần đây qua phương pháp chỉnh sửa, nhưng ít nghiên cứu về cách cải tiến tiến tiến tiến tiến tiến tiến tiến trình phục vụ mẫu trên các công việc xuôi dòng. Trong tờ giấy này, chúng tôi kiểm tra các động lực học tập của Berlin. Chúng tôi dùng divergence JS để phát hiện sự thay đổi chế độ chú ý và dùng khoảng cách SVCCA để kiểm tra sự thay đổi chế độ trích biến sang chế độ lõi năng lượng khi giao thức được giao phó. Chúng tôi kết luận rằng giao độ cẩn thận của BERT chủ yếu thay đổi chế độ chú ý của các lớp cuối cùng và thay đổi chế độ đặc trưng của các lớp trung gian và cuối cùng. Hơn nữa, chúng tôi phân tích sự đồng nhất giữa các hạt giống ngẫu nhiên và các bộ dữ liệu khác nhau. Tóm lại, chúng tôi cung cấp một sự hiểu biết đặc biệt về các động lực học tập của sự cải tạo sang trái sót sót sót sót sót sót sót. Điều đó làm sáng tỏ việc cải thiện kết quả.', 'uz': "Yaqinda o'rgangan tildan oldin o'rganish modeli BERT ko'pchilik NLP vazifalarining holatini o'zgartiradi, lekin bir nechta o'rganish jarayonni rivojlanish muvaffaqiyatlaridan foydalanishini o'rganadi. Bu qogʻozda biz ikki indikatlar bilan BERT'ning o'rganish dynamikasini o'rganamiz. @ info: whatsthis Biz murakkab qilamiz, BERT yaxshi tuzilishi aslida eng oxirgi qatlamning fikrlarini o'zgartiradi va o'rtacha qatlamning xossasini o'zgartiradi. Ko'rib, biz har xil sonlar va har xil maʼlumotlar tarkibidagi BERT yaxshi tuzilishini aniqlamiz. Qisqacha paytda biz BERT yaxshi suhbat o'rganishni o'rganishni o'rganamiz. Bu yaxshi suhbat natijalarini o'zgartirish uchun bir necha nuru ko'rsatadi.", 'bg': 'Наскоро въведеният предварително обучен езиков модел подобрява съвременните технологии при много задачи на НЛП чрез подхода за фино настройване, но малко проучвания изследват как процесът на фино настройване подобрява ефективността на модела при задачи надолу по веригата. В настоящата статия ние инспектираме учебната динамика на фината настройка с два индикатора. Използваме дивергенцията за откриване на промяната в режима на внимание и използваме разстоянието за изследване на промяната в режима на екстракция на функции по време на фината настройка. Заключваме, че фината настройка променя основно режима на внимание на последните слоеве и модифицира режима на екстракция на характеристиките на междинния и последния слой. Освен това анализираме консистенцията на фината настройка между различни произволни семена и различни набори от данни. В обобщение, ние предоставяме отличително разбиране на учебната динамика на фината настройка, което хвърля известна светлина върху подобряването на резултатите от фината настройка.', 'da': 'Den nyligt indførte prætrænede sprogmodel BERT fremmer den nyeste teknologi på mange NLP-opgaver gennem finjusterende tilgang, men få undersøgelser undersøger, hvordan finjusterende proces forbedrer modellens ydeevne på downstream-opgaver. I denne artikel inspicerer vi læringsdynamikken ved BERT finjustering med to indikatorer. Vi bruger JS divergens til at registrere ændringen i opmærksomhedstilstanden og bruger SVCCA afstand til at undersøge ændringen i funktionsudtrækningstilstanden under BERT finjustering. Vi konkluderer, at BERT finjustering hovedsageligt ændrer opmærksomhedstilstanden for de sidste lag og ændrer funktionsudtrækningstilstanden for de mellemliggende og sidste lag. Desuden analyserer vi konsistensen i BERT finjustering mellem forskellige tilfældige frø og forskellige datasæt. Sammenfattende giver vi en markant forståelse af læringsdynamikken i BERT finjustering, hvilket kaster lys over forbedringen af finjusteringsresultaterne.', 'nl': 'Het onlangs geïntroduceerde voorgetrainde taalmodel BERT verbetert de state-of-the-art op veel NLP-taken door middel van de fine-tuning-aanpak, maar weinig studies onderzoeken hoe het fine-tuning proces de modelprestaties op downstream taken verbetert. In dit artikel inspecteren we de leerdynamiek van BERT finetuning met twee indicatoren. We gebruiken JS-divergentie om de verandering van de aandachtsmodus te detecteren en gebruiken SVCCA-afstand om de verandering van de kenmerkextractiemodus tijdens BERT finetuning te onderzoeken. We concluderen dat BERT fine-tuning voornamelijk de aandachtsmodus van de laatste lagen verandert en de feature extraction mode van de tussenlagen en laatste lagen wijzigt. Bovendien analyseren we de consistentie van BERT fine-tuning tussen verschillende willekeurige zaden en verschillende datasets. Samengevat bieden we een onderscheidend inzicht in de leerdynamiek van BERT fine-tuning, wat licht werpt op het verbeteren van de fine-tuning resultaten.', 'hr': 'Nedavno uvedeni predobučeni jezički model BERT napreduje stanje umjetnosti na mnogim zadacima NLP-a kroz dobar pristup prilagođenja, ali nekoliko ispitivanja istražuju kako proces finaliziranja poboljšava učinkovitost modela na nizovim zadacima. U ovom papiru, provjeravamo dinamiku učenja BERT-a sa dva indikatora. Koristimo JS razliku za otkrivanje promjene pažnje režima i koristimo daljinu SVCCA-a kako bi pregledali promjenu režima izvlačenja funkcija tijekom dobre prilagodbe BERT-a. Zaključili smo da BERT-ova finalna prilagodba uglavnom promijeni pažnju moda posljednjih slojeva i modifikuje način izvlačenja karakteristika prosječnih i posljednjih slojeva. Osim toga, analiziramo konsekvenciju dobre prilagodbe BERT između različitih nasumičnih sjemena i različitih seta podataka. U sažetku, pružamo određeno razumijevanje dinamike učenja BERT-a, koja proizvodi malo svjetla na poboljšanju rezultata isprave.', 'id': 'Model bahasa yang baru-baru ini diperkenalkan pre-terlatih BERT mengembangkan state-of-the-art dalam banyak tugas NLP melalui pendekatan penyesuaian, tetapi beberapa studi menyelidiki bagaimana proses penyesuaian meningkatkan prestasi model pada tugas downstream. Dalam kertas ini, kami memeriksa dinamika belajar BERT fine-tuning dengan dua indikator. We use JS divergence to detect the change of the attention mode and use SVCCA distance to examine the change to the feature extraction mode during BERT fine-tuning.  Kami menyimpulkan bahwa penyesuaian BERT terutama mengubah mode perhatian lapisan terakhir dan mengubah mode ekstraksi fitur lapisan intermediate dan terakhir. Selain itu, kami menganalisa konsistensi dari BERT fine-tuning antara benih acak berbeda dan set data berbeda. Secara ringkasan, kami menyediakan pemahaman yang berbeda tentang dinamika belajar dari penyesuaian BERT, yang memberikan beberapa cahaya pada meningkatkan hasil penyesuaian.', 'de': 'Das kürzlich eingeführte vortrainierte Sprachmodell BERT bringt den Stand der Technik bei vielen NLP-Aufgaben durch den Fine-Tuning-Ansatz voran, aber nur wenige Studien untersuchen, wie der Fine-Tuning-Prozess die Modellleistung bei nachgelagerten Aufgaben verbessert. In diesem Beitrag untersuchen wir die Lerndynamik der BERT-Feinabstimmung mit zwei Indikatoren. Wir verwenden JS-Divergenz, um die Änderung des Aufmerksamkeitsmodus zu erkennen und verwenden SVCCA-Distanz, um die Änderung des Merkmalsextraktionsmodus während der BERT-Feinabstimmung zu untersuchen. Wir schließen daraus, dass die BERT-Feinabstimmung hauptsächlich den Aufmerksamkeitsmodus der letzten Ebenen ändert und den Feature-Extraktionsmodus der Zwischen- und letzten Ebenen modifiziert. Darüber hinaus analysieren wir die Konsistenz der BERT-Feinabstimmung zwischen verschiedenen zufälligen Seeds und verschiedenen Datensätzen. Zusammenfassend vermitteln wir ein ausgeprägtes Verständnis der Lerndynamik von BERT Feinabstimmung, das ein wenig Licht auf die Verbesserung der Feinabstimmungsergebnisse wirft.', 'ko': '최근 도입된 예비훈련 언어모델인 BERT는 미세조정 방법을 통해 많은 NLP 임무의 최신 수준을 향상시켰지만, 미세조정 과정이 하위 임무의 모델 성능을 어떻게 개선하는지에 대한 연구는 드물다.본문에서 우리는 두 가지 지표로 버트의 미조 학습 동태를 고찰했다.Google은 JS 산도를 사용하여 주의 모드의 변화를 측정하고, SVCCA 거리를 사용하여 BERT에서 미세하게 조정하는 동안 특징 추출 모드의 변화를 검사합니다.우리는 버트미조는 주로 마지막 층의 주의 모델을 바꾸고 중간 층과 마지막 층의 특징 추출 모델을 수정한다는 결론을 얻었다.그 밖에 우리는 서로 다른 랜덤 피드와 서로 다른 데이터 집합 사이의 버트 마이크로스피드 일치성을 분석했다.한 마디로 하면 우리는 베르토 마이크로스피커의 학습 동력학에 대해 독특한 이해를 가지게 되었고 이것은 마이크로스피커 결과를 개선하는 데 어느 정도 도움이 되었다.', 'fa': 'مدل پیش آموزش زبانی BERT به اخیرا معرفی شده است که موقعیت هنری بر بسیاری از کارهای NLP با طریق تنظیم\u200cکننده\u200cای پیشرفت می\u200cکند، ولی چند مطالعه تحقیق می\u200cکند که چگونه فرایند تنظیم\u200cکننده\u200cی نیکویی عملکرد مدل را بر کارهای پایین\u200cترین تغییر در این کاغذ، ما دینامیک یادگیری BERT را با دو نشان\u200cدهنده تحقیق می\u200cکنیم. ما از تغییرات JS استفاده می کنیم تا تغییرات حالت توجه را شناسایی کنیم و از فاصله SVCCA استفاده کنیم تا تغییرات را در حالت استخراج ویژه در حالت تنظیم BERT تحقیق کنیم. ما تصمیم می\u200cگیریم که نیکوترین تنظیمات BERT اصلاً حالت توجه آخرین لایه\u200cها را تغییر می\u200cدهد و حالت خارج کردن ویژه\u200cها را تغییر می\u200cدهد. به علاوه، ما هماهنگی BERT را بین دانه\u200cهای تصادفی و مجموعه\u200cهای داده\u200cهای مختلف تحلیل می\u200cکنیم. در summary, we provide a distinctive understanding of the learning dynamics of BERT fine tuning, which puts some light on improving the fine tuning results.', 'sq': 'Modeli i gjuhës së parastërvitur i parastërvitur i kohëve të fundit BERT përparon gjendjen më të lartë në shumë detyra NLP nëpërmjet qasjes së përshtatjes, por pak studime hetojnë se si procesi i përshtatjes përmirëson performancën e modelit në detyrat e poshtme. Në këtë letër, ne inspektojmë dinamikën e mësimit të BERT-it në rregullim me dy tregues. Ne përdorim divergjencën JS për të zbuluar ndryshimin e modalitetit të vëmendjes dhe përdorim distancën SVCCA për të shqyrtuar ndryshimin në modalitetin e nxjerrjes së funksioneve gjatë rregullimit të BERT. Ne përfundojmë se rregullimi i BERT ndryshon kryesisht modalitetin e vëmendjes së niveleve të fundit dhe modifikon modalitetin e nxjerrjes së funksioneve të niveleve të mesme dhe të fundit. Përveç kësaj, ne analizojmë konsistencën e rregullimit të BERT midis farave të ndryshme të rastësishme dhe të dhënave të ndryshme. Për të përmbledhur, ne ofrojmë një kuptim të veçantë të dinamikës mësuese të përshtatjes së BERT, e cila hedh pak dritë në përmirësimin e rezultateve të përshtatjes së përshtatjes.', 'am': 'በቅርብ ጊዜ የፊተኛውን ተማሪ የቋንቋ ሞዴል BERT ብዙዎች የNLP ስራዎችን በመጠቀም የሚጠቅምበት የልዩ አርእስት ሁኔታ ያሳድጋል፤ ነገር ግን ጥቂቶች ትምህርት ተማርተዋል፡፡ በዚህ ፕሮግራም የBERT ጥያቄን በሁለት ማሳየት ጥያቄን እናስመርዋለን፡፡ በBERT ጥያቄ ጊዜ የፊደል ምርጫውን ለመመርመር የJS ልዩነት እናስቀምጣለን፡፡ የመጨረሻይቱን ደረጃዎች ያስተካክሉ ዘንድ BERT ጥያቄን እንዲለውጥ እና በመካከለኛና በመጨረሻው ደረጃዎች ላይ የጥያቄውን አካሄድ እንዲለውጥ እና ያስተካክሉታል፡፡ ከዚህም በላይ የBERT አካባቢ እና በተለየ ዘር እና በተለየ የዳታ አካሄድ መፍጠርን እናስተዋልታለን፡፡ በተጠቃሚ ጊዜ የBERT ፍሬዎችን በማድረግ የሚታወቀውን ትምህርት እናስታውቃለን፡፡', 'hy': 'Վերջերս ներկայացված նախապատրաստված լեզվի մոդելը ԲԵՌԹ-ը բարձրացնում է նորաձևությունը շատ ՆԼՊ-ի առաջադրանքների վրա բարձրացման միջոցով, սակայն մի քանի ուսումնասիրություններ են ուսումնասիրում, թե ինչպես է բարձրացման գործընթացը բարելավում մոդելների արտադրող Այս թղթի մեջ մենք ստուգում ենք BER-ի ուսումնասիրության դինամիկայը կապված երկու ցուցանիշների հետ: We use JS divergence to detect the change of the attention mode and use SVCCA distance to examine the change to the feature extraction mode during BERT fine-tuning.  Մենք եզրակացնում ենք, որ BERT-ի բարելավումը հիմնականում փոխում է վերջին շերտերի ուշադրության ռեժը և փոխում է միջին և վերջին շերտերի հատկանիշների վերացման ռեժը: Ավելին, մենք վերլուծում ենք BER-ի կատարելագործման համապատասխանությունը տարբեր պատահական սերմերի և տարբեր տվյալների համակարգերի միջև: Կարճ ասած, մենք տրամադրում ենք BER-ի բարձրացման ուսումնական դինամիկայի առանձնահատուկ հասկացություն, որը որոշ լույս է տալիս բարձրացման արդյունքների վրա:', 'sw': 'Hivi karibuni, modeli ya lugha iliyoendelea kabla ya mafunzo, BERT inaboresha hali ya sanaa ya kazi nyingi za NLP kupitia mbinu za mafunzo, lakini tafiti chache zinachunguza jinsi mchakato wa mafunzo huo unavyobadilisha utendaji wa mifano katika kazi za mito ya chini. Katika gazeti hili, tunachunguza mbinu za kujifunza za vizuri vya BERT kwa ishara mbili. Tunatumia tofauti ya JS ili kutambua mabadiliko ya namna ya kutangaza na kutumia umbali wa SVCCA ili kuchunguza mabadiliko ya namna ya utoaji wa vifaa wakati wa mafunzo ya BERT. We conclude that BERT fine-tuning mainly changes the attention mode of the last layers and modifies the feature extraction mode of the intermediate and last layers.  Zaidi ya hayo, tunachambua umuhimu wa usambazaji wa BERT kati ya mbegu tofauti na seti tofauti za data. Katika muhtasari, tunatoa uelewa wa kina wa kujifunza dynami za mafunzo ya BERT, ambayo inaonyesha mwanga kuhusu kuboresha matokeo mazuri.', 'tr': "횦akynda 철흫-bilim ta첵첵arlanan dil nusgasyny BERT g철rkezil첵채n nusgasyny NLP ta첵첵arlama 첵agda첵ynda 철r채n m철h체m ta첵첵arlama ta첵첵arlamasyny 철흫체nd체r첵채r, 첵철ne k채n 철흫체nde durum ta첵첵arlamany흫 nusgasyny a힊aky g철renlerde t채zele힊tirip bar첵andygyny Bu kagyzda, BERT 철wrenmeni흫 dinamikyny iki g철rkez bilen gowy d체z체mlenmegi bar첵arys. Biz JS 챌arpy힊yny 체ns modini흫 체첵tgewini detek etmek 체챌in we SVCCA aralygyny BERT gabdaly tenzim etmek 체챌in 체첵tgewleri barlamak 체챌in ullan첵arys. BERT'y흫 dym d체z체mlenmesini흫 aslynda so흫ky katlary흫 체ns체ni 체첵tgedir we olary흫 s철흫ki katlary흫 챌ykarma moduny 체첵tgedir. Munu흫 체챌in, biz BERT'y흫 farkl캇 tassyklan 철s체mlikleri흫 we farkl캇 veri setirlerini흫 arasynda gabdalygyny 챌철z체mle첵채ris Topla첵y힊larda, BERT dogry d체zeltmegini흫 철wrenmek dinamikyny 체첵tged첵채ris. Bu 힊ekilde gowy d체zeltmek 체챌in biraz 첵agtylygy gowurar.", 'az': "Son təhsil edilmiş dil modeli BERT çox NLP işləri ilə təhsil edilən təhsil modeli təhsil etdi, amma az təhsil təhsil işləri düşürülmüş işlərin modeli performansını necə yaxşılaşdırır. Bu kağızda, BERT öyrənməsi dinamikini iki indikator ilə təsdiqləyirik. Biz JS dəyişikliyini gözləmə modunun dəyişikliyini keşfetmək üçün istifadə edirik və SVCCA uzaqlaşığını BERT fərqli təmizləmə sırasında fərqli təmizləmə modunun dəyişikliyini təsdiqləmək üçün istifadə edirik. Beləliklə, BERT təmizlənməsi ən çox son sütunların dikkatini dəyişdirir və son sütunların təmizlənməsi modunu dəyişdirir. Daha sonra, BERT'nin müxtəlif təsirli bitkilərin və müxtəlif verilənlərin arasında müəyyən müəyyən müddətini analiz edirik. Qısqa gəlməsində, BERT təmizlənməsinin öyrənmə dinamiklərini təmizləyirik. Bu, yaxşı təmizlənmə sonuçlarını yaxşılaşdırmaq üçün bir az işıq yaratır.", 'bn': 'সম্প্রতি প্রশিক্ষিত ভাষার মডেল বিরেটি অনেক এনএলপি কাজের মাধ্যমে সুন্দর ভাষার মাধ্যমে পূর্বে প্রশিক্ষণ প্রদান করা হয়েছে, কিন্তু কয়েকটি গবেষণা অনুসন্ধান করেছে যে ভাল এই কাগজটিতে আমরা দুই নিদর্শন দিয়ে বের্টের শিক্ষার ধারণা পরীক্ষা করি। আমরা জেএস-এর পার্থক্য ব্যবহার করি মনোযোগ মোডের পরিবর্তন সনাক্ত করার জন্য এবং বেরেটি সুন্দর সংক্রান্ত বৈশিষ্ট্যের বিনিময়ের পরিবর্তন পরীক্ষ আমরা উপসংহার প্রদান করেছি যে বেরেট ভালো টানিং মূলধারণত শেষ পর্যায়ের মনোযোগ মোড পরিবর্তন করে এবং মাঝামাঝি এবং শেষ স্তরের বৈশিষ্ট্ এছাড়াও, আমরা বিবের্টের সাথে বিভিন্ন ক্ষেত্র এবং বিভিন্ন ডাটাসেটের মধ্যে সুন্দর সংস্করণ বিশ্লেষণ করি। সারসংক্ষেপে আমরা বিবের্টের সুন্দর শিক্ষার্থীর ক্ষেত্রে বিভিন্ন ব্যাপারে বিস্তারিত বুঝি দিয়েছি, যা ভালো টিউনিং ফলাফল উন্নত', 'ca': "El model de llenguatge pre-entrenat recentment introduït BERT avança l'última en moltes tasques de NLP a través de l'enfocament d'ajustament, però pocs estudis investigan com el procés d'ajustament millora el rendiment del model en tasques avall. In this paper, we inspect the learning dynamics of BERT fine-tuning with two indicators.  Utilitzem la divergència JS per detectar el canvi del món d'atenció i utilitzem la distància SVCCA per examinar el canvi en el món d'extracció de característiques durant l'ajustament BERT. Conclouem que el millorament de BERT canvia principalment el món d'atenció de les últimes capes i modifica el món d'extracció de característiques de les capes intermedies i últimes. A més, analitzem la consistencia de l'ajustament BERT entre les seves varietats aleatòries i els conjunts de dades diferents. En resum, proporcionem una comprensió distinta de la dinàmica d'aprenentatge de l'ajustament BERT, que emet alguna llum a la millora dels resultats d'ajustament.", 'cs': 'Nedávno zavedený předškolený jazykový model BERT posiluje nejmodernější úlohy na mnoha úlohách NLP prostřednictvím přístupu k jemnému ladění, ale jen málo studií zkoumá, jak proces jemného ladění zlepšuje výkon modelu u následných úloh. V tomto článku zkoumáme dynamiku učení jemného ladění BERT pomocí dvou ukazatelů. K detekci změny režimu pozornosti používáme JS divergenci a k prozkoumání změny režimu extrakce funkcí při jemném ladění BERT používáme SVCCA vzdálenost. Dospěli jsme k závěru, že jemné ladění BERT mění hlavně režim pozornosti posledních vrstev a modifikuje režim extrakce prvků mezipřední a poslední vrstvy. Kromě toho analyzujeme konzistenci jemného ladění BERT mezi různými náhodnými semeny a různými datovými sadami. Shrnutím poskytujeme výrazné pochopení dynamiky učení jemného ladění BERT, které vrhá světlo na zlepšení výsledků jemného ladění.', 'et': 'Hiljuti kasutusele võetud eelõpetatud keelemudel BERT arendab paljude uue õppekava ülesannete tehnoloogia taset peenhäälestuse abil, kuid vähesed uuringud uurivad, kuidas peenhäälestusprotsess parandab mudeli tulemuslikkust järgnevate ülesannete puhul. Käesolevas töös uurime BERT peenhäälestuse õppedünaamikat kahe näitaja abil. Kasutame tähelepanurežiimi muutuse tuvastamiseks JS divergentsi ja BERT peenhäälestuse ajal funktsiooni ekstraheerimisrežiimi muutuse uurimiseks SVCCA kaugust. Järeldame, et BERT peenhäälestus muudab peamiselt viimaste kihtide tähelepanu režiimi ning muudab vahe- ja viimaste kihtide funktsioonide ekstraheerimise režiimi. Lisaks analüüsime BERT peenhäälestuse järjepidevust erinevate juhuslike seemnete ja erinevate andmekogumite vahel. Kokkuvõttes anname eristuva arusaamise BERT peenhäälestuse õppedünaamikast, mis annab mõningast valgust peenhäälestuse tulemuste parandamisele.', 'fi': 'Hiljattain esitelty esikoulutettu kielimalli BERT edistää monien NLP-tehtävien huipputasoa hienosäätömenetelmän avulla, mutta harvoissa tutkimuksissa selvitetään, miten hienosäätöprosessi parantaa mallin suorituskykyä loppupään tehtävissä. Tässä artikkelissa tarkastelemme BERT-hienosäätön oppimisdynamiikkaa kahdella indikaattorilla. Havaitsemme huomiotilan muutoksen JS-divergenssin avulla ja tarkastelemme ominaisuuden poistotilan muutosta BERT-hienosäätön aikana SVCCA-etäisyyden avulla. Päätämme, että BERT-hienosäätö muuttaa pääasiassa viimeisten kerrosten huomiotilaa ja muuttaa väli- ja viimeisten kerrosten ominaisuusuuttoa. Lisäksi analysoimme BERT-hienosäätön johdonmukaisuutta eri satunnaissiementen ja eri aineistojen välillä. Tiivistelmä annamme selkeän käsityksen BERT-hienosäätön oppimisdynamiikasta, mikä valaisee hienosäätötulosten parantamista.', 'af': "Die onlangs ingevoerde taal model BERT het die state-of-the-art op baie NLP-opdragte verbeter deur die fyn-tuning toegang, maar sommige studie ondersoek hoe die fyn-tuning proses die model-prestasie op onderstreem opdragte verbeter. In hierdie papier, ons inspekteer die leer dinamike van BERT fyn-tuning met twee indikators. Ons gebruik JS divergensie om die verandering van die aandagmodus te beskik en SVCCA afstand te gebruik om die verandering na die funksie uittrek modus te ondersoek tydens BERT fyn- tuning. Ons sluit dat BERT fyn-tuning hoofsaaklik die aandagmodus van die laaste laag verander en die funksie-uittrekking modus van die middelste en laaste laag verander. Ook, ons analyseer die konsistensie van BERT-fintuning tussen verskillende willekeurige seede en verskillende datastelle. In die opsomming, verskaf ons 'n spesifieke verstanding van die leer dinamike van BERT fyn-tuning, wat 'n paar lig skei op die verbetering van die fyn-tuning resultate.", 'bs': 'Nedavno uvedeni predobučeni jezički model BERT napreduje stanje umjetnosti na mnogim zadacima NLP-a kroz dobar pristup prilagođenja, ali nekoliko studija istražuju kako proces finaliziranja poboljšava izvođenje modela na nizovim zadacima. U ovom papiru, provjeravamo dinamiku učenja BERT-a sa dva indikatora. Koristimo JS razliku kako bi otkrili promjenu moda pažnje i koristili udaljenost SVCCA-a da bi pregledali promjenu režima izvlačenja funkcija tijekom dobre prilagodbe BERT-a. Zaključili smo da BERT finaliziranje uglavnom mijenja mod pažnje posljednjih slojeva i modifikuje mod izvlačenja karakteristika prosječnih i posljednjih slojeva. Osim toga, analiziramo konsekvenciju dobre prilagodbe BERT između različitih nasumičnih sjemena i različitih seta podataka. U sažetku, pružamo određeno razumijevanje dinamike učenja BERT-a, koja proizvodi malo svjetla na poboljšanju rezultata isprave.', 'jv': 'Neng dhéwé éntuk nggawe model sing luwih-luwih bantuan karo BERT dumadhi duruh-dumadhi sing gawe NLP ngono nggawe gerasane nggawe layakno, njuk dhéwé ngerasai perusahaan sing paling nggawe gerangkat kuwi nggawe akses dibutuhke tarjamahan nganggep sistêm nggawe barang dumadhi. Nang pemilih iki, kita ngubah weruh uh nggambar sistem sing BERT koyok barang kelas 2. Awak dhéwé nggunakake BERT small Label Digaramusik, kita sumelan sistem sing dibenakake nggawe dynamics sing dibenakake BERT, sing ngawe barang langur ngono nggawe barang langur-uwong.', 'he': 'מודל השפה המוצגת לאחרונה BERT מתקדם את המצב המיוחד במשימות רבות NLP דרך הגישה התאימה, אך מעט מחקרים חוקרים איך תהליך התאימה משפר את ההופעה של המודל במשימות מתקדמות. בעיתון הזה, אנחנו בודקים את דינמיקת הלימודים של התאמה של BERT עם שני אינדיקטורים. אנו משתמשים במחלוקת JS כדי לגלות את שינוי מצב תשומת לב ולהשתמש במרחק SVCCA כדי לבדוק את השינוי למצב החלץ של תכונות במהלך התדרגות BERT. We conclude that BERT fine-tuning mainly changes the attention mode of the last layers and modifies the feature extraction mode of the intermediate and last layers.  חוץ מזה, אנו מנתחים את התקבילות של התאימון של BERT בין זרעים אקראיים שונים וקבוצות נתונים שונים. בסופו של דבר, אנחנו מספקים הבנה מיוחדת של דינמיקה הלימודית של התאים של BERT, אשר משליך קצת אור על שיפור התוצאות התאים.', 'sk': 'Pred kratkim uvedeni vnaprej usposobljeni jezikovni model BERT s pristopom finega uravnavanja pospešuje najsodobnejše pri številnih nalogah NLP, vendar le malo študij raziskuje, kako proces finega uravnavanja izboljša uspešnost modela pri nadaljnjih nalogah. V prispevku pregledujemo učno dinamiko natančnega uravnavanja BERT z dvema kazalnikoma. Uporabljamo JS divergence za zaznavanje spremembe načina pozornosti in uporabljamo SVCCA razdaljo za pregled spremembe načina ekstrakcije funkcij med natančnim nastavitvijo BERT. Zaključimo, da BERT fino nastavitev v glavnem spreminja način pozornosti zadnjih plasti in spreminja način ekstrakcije značilnosti vmesnih in zadnjih plasti. Poleg tega analiziramo konsistentnost BERT finega uravnavanja med različnimi naključnimi semeni in različnimi nabori podatkov. Če povzamemo, zagotavljamo značilno razumevanje učne dinamike BERT finega uravnavanja, kar osvetli izboljšanje rezultatov finega uravnavanja.', 'ha': "Ga na ƙaran da aka introduce misalin harshen zaman-mai-tunkuɗe BERT yana ƙarfafa halin-sanar da masu aiki masu yawa na NLP, a kan hanyarwa mai gyarawa, kuma amma kaɗan na yi ƙidãya a kan aikin muhimmin da aka gyara musamman ko da ya kyautata mazaɓan motel a kan aikin na ƙarami. Ga wannan karatun, za'a jarraba karatun masu karatun na BERT da alama biyu. Tuna yi amfani da JS-gaura dõmin Mu gane canza musanyawa ga shirin muhalli kuma Mu yi amfani da durowa SvCCA dõmin ka yi jarraba canza zuwa shirin nunowa na ƙayyade idan an nuna shi na BERT. We conclude that BERT fine-tuning mainly changes the attention mode of the last layers and modifies the feature extraction mode of the intermediate and last layers.  Za kuma, Munã yin anayya da sami mai baƙo na BERT a tsakanin farũra dabam-dabam da danne-daban. Gani na ƙara, Munã bã ta fahimta mai tsawo wa'anar da aka sani na BERT mai kyãwo, wanda ke nuna wani haske a kan gyaranta fassaran mai kyau.", 'bo': 'The recently introduced pre-trained language model BERT advances the state-of-the-art on many NLP tasks through the fine-tuning approach, but few studies investigate how the fine-tuning process improves the model performance on downstream tasks. འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་BERT་གི་སྒྲུབ་གཏོང་གི་ཐབས་ལམ་ལ་ཞིབ་འཇུག་བྱེད་ཀྱི་ཡོད། We use JS divergence to detect the change of the attention mode and use SVCCA distance to examine the change to the feature extraction mode during BERT fine-tuning. We conclude that BERT fine-tuning mainly changes the attention mode of the last layers and modifies the feature extraction mode of the intermediate and last layers. འོན་ཀྱང་། ང་ཚོས་BERT ཡི་ཆེ་བ་དང་སྐྱེས་པའི་དབྱིབས་ཆ་སྒྲིག་ཀྱི་ཆེ་མཐོང་ཚད་ལྟ་ཞིབ་བྱེད་ཀྱི་ཡོད། འུ་ཅག་གིས་མཛོད་ཁང་ནང་དུ་BERT་ལྟ་ཞིབ་བཟོ་བའི་སྲོལ་རྒྱུན་གྱི་གྲངས་ཚད་གཞན་ཞིག་བྱིན་ཡོད།'}
{'en': 'A Simple Text-based Relevant Location Prediction Method using Knowledge Base', 'ar': 'طريقة بسيطة للتنبؤ بالموقع ذي الصلة تعتمد على النص باستخدام قاعدة المعارف', 'pt': 'Um método simples de previsão de localização relevante baseado em texto usando a base de conhecimento', 'fr': 'Une méthode simple de prédiction de position pertinente basée sur du texte utilisant la base de connaissances', 'es': 'Un método simple de predicción de ubicación relevante basado en texto que utiliza la base de conocimientos', 'ja': 'ナレッジベースを使用したシンプルなテキストベースの関連位置予測メソッド', 'hi': 'नॉलेज बेस का उपयोग करके एक साधारण पाठ-आधारित प्रासंगिक स्थान पूर्वानुमान विधि', 'ru': 'Простой текстовый метод прогнозирования местоположения с использованием базы знаний', 'zh': '盖文本之简知识库相关占候之术也', 'ga': 'Modh Simplí Téacsbhunaithe um Thuar Láithreacha Ábhartha ag úsáid Bonn Eolais', 'ka': 'Name', 'el': 'Μια απλή μέθοδος πρόβλεψης σχετικής θέσης βασισμένη στο κείμενο χρησιμοποιώντας τη Γνωσιακή Βάση', 'hu': 'Egyszerű szövegalapú releváns hely-előrejelzési módszer a Tudásbázis használatával', 'lt': 'Paprastas tekstu pagrįstas atitinkamos vietos prognozavimo metodas naudojant žinių bazę', 'it': 'Un semplice metodo di previsione della posizione rilevante basato su testo utilizzando la Knowledge Base', 'mk': 'Name', 'kk': 'Мәтін негіздеген қарапайым мәтіндік мәліметтің мәліметті таңдау әдісіName', 'ms': 'Name', 'ml': 'അറിവുകളുടെ അടിസ്ഥാനം ഉപയോഗിച്ചു് എളുപ്പമുള്ള പദാവലിയിലുള്ള ബന്ധപ്പെട്ട സ്ഥാനം മുന്\u200dഗണന മാര്\u200dഗ', 'mt': 'Metodu sempliċi ta’ Tbassir tal-Post Relevanti bbażat fuq it-Test bl-użu tal-Bażi tal-Għarfien', 'mn': 'Мэдлэг суурь ашиглан энгийн Текст суурилсан Relevant Location Prediction Method', 'ro': 'O metodă simplă de predicție a locației relevante bazată pe text utilizând baza de cunoștințe', 'pl': 'Prosta metoda prognozowania odpowiedniej lokalizacji oparta na tekstie przy użyciu bazy wiedzy', 'no': 'Name', 'sr': 'Jednostavni metod predviđanja lokacije na tekstu koristeći bazu znanja', 'so': 'A Simple Text-based Relevant Location Prediction Method using Knowledge Base', 'si': 'Name', 'sv': 'En enkel textbaserad relevant platsförutsägelsemetod med hjälp av Knowledge Base', 'ur': 'Name', 'ta': 'Name', 'uz': 'Name', 'vi': 'Một phương pháp tiên đoán vị trí liên quan bằng đơn giản', 'bg': 'Прост метод за прогнозиране на релевантно местоположение, базиран на текст, с помощта на база знания', 'hr': 'Jednostavni metod predviđanja mjesta na temelju teksta koristeći bazu znanja', 'da': 'En enkel tekstbaseret relevant placeringsforudsigelsesmetode ved hjælp af Knowledge Base', 'nl': 'Een eenvoudige op tekst gebaseerde relevante locatievoorspellingsmethode met behulp van Knowledge Base', 'ko': '지식 라이브러리 기반의 간단한 텍스트 관련 위치 예측 방법', 'de': 'Eine einfache textbasierte Methode zur Vorhersage relevanter Standorte mithilfe der Knowledge Base', 'fa': 'Name', 'id': 'Metode Prediksi Lokasi Berdasarkan Teks Sederhana menggunakan Baza Pengetahuan', 'sw': 'Utawala wa Udhibiti wa Mahakama yenye msingi wa Matambo', 'tr': 'Bilgi Basesini ullan basit metin tabanly Relevant Location Prediction Method', 'af': 'Name', 'sq': 'Një metodë e thjeshtë e parashikimit të vendit të duhur bazuar në tekst duke përdorur bazën e njohurive', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'hy': 'Comment', 'az': 'Bilim 칖st칲nd톛n istifad톛 edil톛n Basit Metin-tabanl캼 Relevant Location Prediction Methodi', 'bn': 'জ্ঞান বেস ব্যবহার করে সাধারণ টেক্সট ভিত্তিক সম্পর্কিত অবস্থানের পছন্দের মাধ্যম', 'bs': 'Jednostavni metod predviđanja lokacije na tekstu koristeći bazu znanja', 'ca': "Un mètode de predicció d'un lloc pertinent basat en text utilitzant una base de coneixements", 'et': 'Lihtne tekstipõhine asjakohase asukoha prognoosimise meetod teabebaasi abil', 'cs': 'Jednoduchá metoda predikce relevantního umístění založená na textu pomocí znalostní báze', 'fi': 'Yksinkertainen tekstipohjainen merkityksellisen sijainnin ennustusmenetelmä käyttäen Knowledge Base -tietokantaa', 'jv': 'Sampeyan Teks basa Relative Location', 'sk': 'Preprosta metoda napovedovanja ustrezne lokacije na podlagi besedila z uporabo zbirke znanja', 'ha': 'A Simple Text-based Relevant Location Prediction Method using Knowledge Base', 'he': 'Name', 'bo': 'ཤེས་རིག་གཞི་བེད་སྤྱོད་བཞིན་པའི་སྔོན་སྒྲིག་གནས་ཡུལ་ལ་འཛུགས་ཀྱི་ཐབས་ལམ་ཞིག་པ'}
{'en': 'In this paper, we propose a simple method to predict salient locations from  news article text  using a knowledge base (KB). The proposed method uses a dictionary of locations created from the  KB  to identify occurrences of locations in the text and uses the hierarchical information between entities in the  KB  for assigning appropriate saliency scores to regions. It allows prediction at arbitrary region units and has only a few hyperparameters that need to be tuned. We show using manually annotated news articles that the proposed method improves the  f-measure  by   0.12 compared to multiple baselines.', 'ar': 'في هذه الورقة ، نقترح طريقة بسيطة للتنبؤ بالمواقع البارزة من نص المقالة الإخبارية باستخدام قاعدة المعرفة (KB). تستخدم الطريقة المقترحة قاموسًا للمواقع التي تم إنشاؤها من قاعدة المعارف لتحديد تكرارات المواقع في النص وتستخدم المعلومات الهرمية بين الكيانات في قاعدة المعارف لتعيين درجات الملاءمة المناسبة للمناطق. يسمح بالتنبؤ بوحدات المنطقة العشوائية ولديه فقط عدد قليل من المعلمات الفائقة التي تحتاج إلى ضبط. نوضح باستخدام المقالات الإخبارية المشروحة يدويًا أن الطريقة المقترحة تعمل على تحسين مقياس f بمقدار 0.12 مقارنة بخطوط الأساس المتعددة.', 'pt': 'Neste artigo, propomos um método simples para prever locais de destaque a partir do texto de uma notícia usando uma base de conhecimento (KB). O método proposto utiliza um dicionário de localizações criado a partir da KB para identificar ocorrências de localizações no texto e utiliza as informações hierárquicas entre as entidades da KB para atribuir pontuações de saliência adequadas às regiões. Ele permite a previsão em unidades de região arbitrárias e possui apenas alguns hiperparâmetros que precisam ser ajustados. Mostramos usando artigos de notícias anotados manualmente que o método proposto melhora a f-measure em 0,12 em comparação com várias linhas de base.', 'es': 'En este artículo, proponemos un método simple para predecir ubicaciones destacadas a partir del texto de artículos de noticias utilizando una base de conocimientos (KB). El método propuesto utiliza un diccionario de ubicaciones creado a partir de la base de conocimientos para identificar las apariciones de ubicaciones en el texto y utiliza la información jerárquica entre las entidades de la base de conocimientos para asignar puntuaciones de prominencia adecuadas a las regiones. Permite la predicción en unidades de región arbitrarias y solo tiene unos pocos hiperparámetros que deben ajustarse. Demostramos mediante artículos de noticias anotados manualmente que el método propuesto mejora la medida f en 0,12 en comparación con múltiples líneas de base.', 'fr': "Dans cet article, nous proposons une méthode simple pour prédire les lieux saillants à partir du texte d'un article de presse à l'aide d'une base de connaissances (KB). Le procédé proposé utilise un dictionnaire d'emplacements créé à partir de la base de connaissances pour identifier les occurrences d'emplacements dans le texte et utilise les informations hiérarchiques entre les entités de la base de connaissances pour attribuer des scores de prépondérance appropriés aux régions. Il permet la prédiction à des unités de région arbitraires et ne possède que quelques hyperparamètres qui doivent être ajustés. Nous montrons à l'aide d'articles de presse annotés manuellement que la méthode proposée améliore la mesure f de 0,12 par rapport à plusieurs niveaux de référence.", 'ja': '本稿では，知識ベース（ KB ）を用いて，ニュース記事テキストから顕著な位置を予測する簡単な手法を提案する．提案された方法は、テキスト内の場所の発生を識別するためにKBから作成された場所の辞書を使用し、適切なSaliencyスコアを地域に割り当てるためにKB内のエンティティ間の階層情報を使用します。任意の領域単位での予測を可能にし、調整する必要があるハイパーパラメータはわずかです。手動で注釈を付けたニュース記事を用いて、提案された方法は、複数のベースラインと比較してf -メジャーを0.12向上させることを示した。', 'zh': '于本文中,发一用知识库(KB)于新闻文本中测突出位置之简法。 议曰:用知识库创位字典以识文本,以知识库实之间,分为区域显著性分。 许以任情单位,并须调整参数。 臣等用手动注新闻文,比于数基线,所上之法,将f测重0.12。', 'ru': 'В этой статье мы предлагаем простой метод прогнозирования основных местоположений из текста новостной статьи с использованием базы знаний (КБ). Предложенный способ использует словарь местоположений, созданный из KB, для идентификации вхождений местоположений в тексте и использует иерархическую информацию между объектами в KB для присвоения соответствующих баллов различимости регионам. Он позволяет прогнозировать в произвольных единицах региона и имеет только несколько гиперпараметров, которые необходимо настроить. Мы показываем с помощью ручных аннотированных новостных статей, что предлагаемый метод улучшает измерение f на 0,12 по сравнению с несколькими базовыми линиями.', 'hi': 'इस पेपर में, हम नॉलेज बेस (KB) का उपयोग करके समाचार लेख पाठ से मुख्य स्थानों की भविष्यवाणी करने के लिए एक सरल विधि का प्रस्ताव करते हैं। प्रस्तावित विधि पाठ में स्थानों की आवृत्तियों की पहचान करने के लिए KB से बनाए गए स्थानों के शब्दकोश का उपयोग करती है और क्षेत्रों को उपयुक्त saliency स्कोर असाइन करने के लिए KB में निकायों के बीच पदानुक्रमित जानकारी का उपयोग करती है. यह मनमाने ढंग से क्षेत्र इकाइयों में भविष्यवाणी की अनुमति देता है और केवल कुछ हाइपरपैरामीटर है जिन्हें ट्यून करने की आवश्यकता है। हम मैन्युअल रूप से एनोटेट किए गए समाचार लेखों का उपयोग करके दिखाते हैं कि प्रस्तावित विधि कई बेसलाइन की तुलना में 0.12 द्वारा एफ-माप में सुधार करती है।', 'ga': 'Sa pháipéar seo, molaimid modh simplí chun láithreacha suntasacha a thuar ó théacs an ailt nuachta ag baint úsáide as bonn eolais (KB). Úsáideann an modh molta foclóir de shuíomhanna a cruthaíodh ón KB chun teagmhais suíomhanna sa téacs a aithint agus úsáidtear an t-eolas ordlathach idir eintitis sa KB chun scóir oiriúnacha sásúla a shannadh do réigiúin. Ceadaíonn sé réamh-mheastachán ag aonaid réigiún treallach agus níl ach cúpla hipearpharaiméadair ann ar gá iad a thiúnadh. Léirímid trí úsáid a bhaint as ailt nuachta le nótaí láimhe go bhfeabhsaíonn an modh atá beartaithe an f-bheart faoi 0.12 i gcomparáid le bonnlínte iolracha.', 'hu': 'Ebben a tanulmányban egy egyszerű módszert javasolunk arra, hogy megjósoljuk a kiemelkedő helyeket a hírek szövegéből egy tudásbázis (KB) segítségével. A javasolt módszer a KB-ból létrehozott helyek szótárát használja a szövegben lévő helyek előfordulásának azonosítására, és a KB-ban lévő entitások közötti hierarchikus információkat használja a megfelelő kiemelkedő pontszámok régiókhoz történő hozzárendelésére. Lehetővé teszi az előrejelzést tetszőleges régióegységeknél, és csak néhány hiperparaméterrel rendelkezik, amelyeket hangolni kell. Manuálisan jegyzetelt hírekkel mutatjuk meg, hogy a javasolt módszer 0,12-vel javítja az f-mérést a több alapvonalhoz képest.', 'el': 'Στην παρούσα εργασία, προτείνουμε μια απλή μέθοδο για την πρόβλεψη σημαντικών τοποθεσιών από κείμενο άρθρων ειδήσεων χρησιμοποιώντας μια βάση γνώσεων (ΚΒ). Η προτεινόμενη μέθοδος χρησιμοποιεί ένα λεξικό τοποθεσιών που δημιουργείται από την ΚΒ για τον προσδιορισμό των περιπτώσεων τοποθεσιών στο κείμενο και χρησιμοποιεί τις ιεραρχικές πληροφορίες μεταξύ οντοτήτων στην ΚΒ για την εκχώρηση κατάλληλων βαθμολογιών σημαντικότητας σε περιοχές. Επιτρέπει την πρόβλεψη σε αυθαίρετες μονάδες περιοχής και έχει μόνο λίγες υπερπαραμέτρους που πρέπει να συντονιστούν. Δείχνουμε χρησιμοποιώντας χειροκίνητα σχολιασμένα άρθρα ειδήσεων ότι η προτεινόμενη μέθοδος βελτιώνει το μέτρο κατά 0.12 σε σύγκριση με πολλαπλές γραμμές βάσης.', 'ka': 'ჩვენ ამ წიგნაში უფრო მარტივი პროგრამის გამოყენება, რომელიც ახალგაზომის ტექსტიდან წარმოიდგინოთ სიახლეების ადგილზე. პროგრამეტრები KB-დან შექმნილი ადგილების სიტყვანის გამოყენება ტექსტის ადგილების მოხდებების განსაზღვრებისთვის და იერაქტიკური ინფორმაციის გამოყენება KB-ის ელექტრების შორის ელექტრების განსაზ ეს შესაძლებელია არბრიტური რეგიონის ერთეულებში წარმოდგენა და აქვს მხოლოდ რამდენიმე ჰიპერ პარამეტრები, რომლებიც უნდა დააკეთება. ჩვენ ჩვენ გამოყენებთ ხელსახურად მონიშნული ინფორმაციების მისამართლად, რომ მისამართლად მინდა f-მართლა 0.12-ით გაუკეთება მრავალ ფესტური ხაზებით.', 'it': 'In questo articolo, proponiamo un metodo semplice per prevedere posizioni salienti dal testo degli articoli di notizie utilizzando una knowledge base (KB). Il metodo proposto utilizza un dizionario di posizioni creato dalla KB per identificare le occorrenze di posizioni nel testo e utilizza le informazioni gerarchiche tra entità nella KB per assegnare punteggi salienti appropriati alle regioni. Permette la previsione a unità regionali arbitrarie e ha solo pochi iperparametri che devono essere sintonizzati. Mostriamo utilizzando articoli di notizie annotati manualmente che il metodo proposto migliora la misura f di 0,12 rispetto a più linee di base.', 'kk': 'Бұл қағазда білім негізін (КБ) қолдану арқылы жаңалық мақаланың мәтінінен жаңалық орналасуын таңдау үшін қарапайым әдісін таңдаймыз. Мәтіндегі орналасуын анықтау үшін КБ- дан құрылған орналасуының сөздігін қолданады және КБ- дағы орналасуының арасындағы иерархиялық мәліметін келтіру үшін орналасуын келтіру үшін. Бұл тәуелсіз аумақтың бірліктерінде таңдауға мүмкіндік береді және тек бірнеше гиперпараметрлерді баптауға керек болады. Біз қолмен жаңалық мақалаларды қолданып көрсетедік, бұл таңдалған әдіс f- өлшемін бірнеше негізгі жолдармен салыстырып 0, 12 деп жақсартады.', 'lt': 'Šiame dokumente siūlome paprastą metodą, pagal kurį būtų galima nuspėti svarbias žinių straipsnių teksto vietas naudojant žinių bazę (KB). Siūlomame metode naudojamas KB sukurtų vietų žodynas, siekiant nustatyti tekste esančių vietų pasikartojimą, ir KB subjektų hierarchinę informaciją naudojama tam, kad regionams būtų priskiriami atitinkami druskos taškai. Ji leidžia prognozuoti savavališkuose regiono vienetuose ir turi tik keletą hiperparametrų, kuriuos reikia pritaikyti. Naudojant rankinius annotuotus naujienų straipsnius parodoma, kad siūlomas metodas pagerina f-priemonę 0,12, palyginti su keliomis bazinėmis linijomis.', 'mk': 'Во овој весник, предложуваме едноставен метод за предвидување на локациите од текстот на новинските статии користејќи база на знаење (КБ). Предложениот метод користи речник на локации создадени од КБ за идентификување на појавувањата на локациите во текстот и ги користи хиерархичките информации меѓу ентитетите во КБ за доделување на соодветни оценки на ослободување на регионите. Тоа овозможува предвидување на арбитралните регионални единици и има само неколку хиперпараметри кои треба да се прилагодат. Користејќи рачно анотирани вести, покажуваме дека предложениот метод ја подобрува мерката f за 0,12 во споредба со повеќе бази линии.', 'ms': 'Dalam kertas ini, kami cadangkan kaedah sederhana untuk meramalkan lokasi yang penting dari teks artikel berita menggunakan pangkalan pengetahuan (KB). Kaedah yang diusulkan menggunakan kamus lokasi yang dicipta dari KB untuk mengenalpasti kejadian lokasi dalam teks dan menggunakan maklumat hierarkis diantara entiti dalam KB untuk menyerahkan skor salinsi yang sesuai ke kawasan. Ia membenarkan ramalan pada unit kawasan arbitrari dan hanya mempunyai beberapa hyperparameter yang perlu disesuaikan. Kami menunjukkan menggunakan artikel berita yang dicatat secara manual bahawa kaedah yang diusulkan meningkatkan ukuran f dengan 0.12 dibandingkan dengan garis dasar berbilang.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഒരു എളുപ്പമായ രീതിയില്\u200d നിന്നും അറിവ് ബേസ് ഉപയോഗിക്കുന്ന വാര്\u200dത്ത ലേഖനത്തില്\u200d നിന്നും സ്ഥലങ പ്രൊദ്ദേശിക്കപ്പെട്ട രീതിയില്\u200d പദാവലിയിലെ സ്ഥാനങ്ങള്\u200d തിരിച്ചറിയാന്\u200d കെബിയില്\u200d നിന്ന് സൃഷ്ടിച്ച സ്ഥലങ്ങളുടെ നിഘണ്ടി ഉപയോഗിക്കുന്നു. പ അത് ആർബിറ്ററി പ്രദേശത്തിന്റെ യൂണിറ്റിൽ പ്രവചിക്കാൻ അനുവദിക്കുന്നു. കുറച്ച് ഹൈപ്പര്\u200dപാരാമീറ്ററുകള്\u200d മ സംസാരിക്കപ്പെട്ട രീതിയില്\u200d നിന്ന് നിര്\u200dദ്ദേശിക്കപ്പെട്ട സംവാര്\u200dത്തകള്\u200d കൈകാര്യമായി കാണിക്കുന്നു', 'mn': 'Энэ цаасан дээр бид мэдээллийн суурь (КБ) ашиглаж мэдээллийн текстээс сайхан байрлал таамаглахын тулд энгийн арга зам өгдөг. Өөрчлөлтийн арга нь КБ-ээс бүтээгдэхүүний орнуудын тодорхойлолтуудыг тайлбарлахад, КБ-ын байгууллагуудын хоорондын шинжлэх ухаан хэрэглэдэг. Энэ нь зөвхөн хэмжээний бүс нутагт таамаглах боломжтой ба зөвхөн хэдэн гиперпараметрлүүд байдаг. Бид хэрэглэж байгаа мэдээллийн баримтуудыг хэрэглэж харуулж байна. Энэ арга нь f-хэмжээг 0.12-д олон суурь шулуунтай харьцуулж байна.', 'mt': 'F’dan id-dokument, qed nipproponu metodu sempliċi biex nipprevedi postijiet salienti mit-test tal-artikolu tal-a ħbarijiet bl-użu ta’ bażi tal-għarfien (KB). The proposed method uses a dictionary of locations created from the KB to identify occurrences of locations in the text and uses the hierarchical information between entities in the KB for assigning appropriate saliency scores to regions.  Hija tippermetti tbassir f’unitajiet ta’ reġjun arbitrarju u għandha biss ftit parametri iperparattivi li jeħtieġu jiġu a ġġustati. Aħna nuru bl-użu ta’ artikoli tal-aħbarijiet annotati manwalment li l-metodu propost itejjeb il-miżura f b’ = 0.12 meta mqabbel ma’ linji bażi multipli.', 'pl': 'W niniejszym artykule proponujemy prostą metodę przewidywania istotnych lokalizacji z tekstu artykułu wiadomościowego z wykorzystaniem bazy wiedzy (KB). Proponowana metoda wykorzystuje słownik lokalizacji utworzony z KB do identyfikacji występowań lokalizacji w tekście i wykorzystuje hierarchiczne informacje między podmiotami w KB do przypisywania odpowiednich punktów występowania regionom. Umożliwia przewidywanie dowolnych jednostek regionu i ma tylko kilka hiperparametrów, które muszą być dostrojone. Używając ręcznie adnotacji artykułów informacyjnych pokazujemy, że proponowana metoda poprawia miarę f o 0,12 w porównaniu z wieloma liniami bazowymi.', 'no': 'I denne papiret foreslår vi ein enkel metode for å foreslå salient plasseringar frå nyhetsteksten med ein kunnskapsbasen (KB). Den foreslåde metoden brukar eit ordbok på plasseringar laga frå KB for å identifisera oppstod av plasseringar i teksten og bruka hierarkisk informasjon mellom einingar i KB for å tilordna tilgjengelege saliseringspoeng til område. Dette tillèt foregåve ved tilfeldige område- einingar og har berre nokre hyperparametrar som må setjast opp. Vi viser ved hjelp av manuelt oppmerkte nye artiklar at den foreslåde metoden forbedrar f-målet med 0,12 sammenlignet med fleire baselinjer.', 'ro': 'În această lucrare, propunem o metodă simplă de a prezice locații importante din textul articolului de știri folosind o bază de cunoștințe (KB). Metoda propusă utilizează un dicționar de locații create din KB pentru a identifica aparițiile locațiilor din text și utilizează informațiile ierarhice dintre entitățile din KB pentru a atribui scoruri de saliență corespunzătoare regiunilor. Permite predicția la unități de regiune arbitrare și are doar câțiva hiperparametri care trebuie reglați. Vă arătăm folosind articole de știri adnotate manual că metoda propusă îmbunătățește măsura f cu 0,12 comparativ cu mai multe linii de referință.', 'sr': 'U ovom papiru predlažemo jednostavnu metodu da predvidimo saliène lokacije iz teksta novinskog članaka koristeći bazu znanja (KB). Predložena metoda koristi rečnik lokacija koje su stvorene iz KB-a da identifikuju pojave lokacija u tekstu i koristi hijerarhičku informaciju između entitata u KB-u za dodavanje odgovarajućih rezultata salijencije regijama. To omogućava predviđanje u proizvodnjim jedinicama region a i ima samo nekoliko hiperparametara koji moraju biti prilagođeni. Mi pokazujemo korištenje manualno annotiranih novinskih članaka da je predložena metoda poboljšava f-mjeru za 0,12 u usporedbi sa višestrukim osnovnim linijama.', 'so': 'Qoraalkan waxaynu ka soo jeedaynaa qaab fudud oo aan ka hor dhigno meelaha laga helo meel laga soo qoro warqadda warqadda warqada ah ee warqadda warqadda ku qoran oo lagu isticmaalo saldhig aqoonta (KB). Midabka la soo jeeday wuxuu isticmaalaa luqada meelaha laga abuuray KB si uu u caddeeyo meelaha ay ku dhacaan qoraalka, wuxuuna isticmaalaa macluumaadka hierarchiga ee u dhexeeya waxyaabaha ku qoran KB, si ay u qaybsadaan kooxda cibaadada ee habboon. Waxey sii sheegi kartaa goobaha caadiga ah oo ay leedahay heerar aad u baahan tahay. Waxaannu muujinnaa warqadaha warqadaha si qof ah loo isticmaalay in qaabkii la soo jeeday uu kordhiyo kooxda f-qiyaasta /0.12 oo isbarbarbardhiga qoraal badan.', 'si': 'මේ පත්තරේ අපි සාමාන්\u200dය විධානයක් ප්\u200dරයෝජනය කරනවා වාර්තාව පැත්තක් පිළිබඳ ස්ථානයක් පරීක්ෂණය කරන්න,  @ info ඒකෙන් සාමාන්\u200dය ප්\u200dරදේශ යුනිත් වලින් ප්\u200dරශ්නයක් තියෙන්න පුළුවන් විතරයි සහ හ හායිපර් ප්\u200dරමාණයක අපි පෙන්වන්නේ වාර්තාව ප්\u200dරයෝජන විදිහට ප්\u200dරයෝජනය කරන්න පුළුවන් විදිහට, කියලා ප්\u200dරයෝජනය විදිහට f-මාර්ග', 'sv': 'I denna uppsats föreslår vi en enkel metod för att förutsäga framträdande platser från nyhetsartikeltext med hjälp av en kunskapsbas (KB). Den föreslagna metoden använder en ordlista med platser som skapats från KB för att identifiera förekomster av platser i texten och använder den hierarkiska informationen mellan entiteter i KB för att tilldela lämpliga nyckelpoäng till regioner. Den tillåter förutsägelse vid godtyckliga regionenheter och har bara ett fåtal hyperparametrar som behöver justeras. Vi visar med hjälp av manuellt kommenterade nyhetsartiklar att den föreslagna metoden förbättrar f-måttet med 0,12 jämfört med flera baslinjer.', 'ur': 'اس کاغذ میں، ہم ایک ساده طریقہ پیش کریں گے کہ ایک علم بنسس (KB) کے مطابق اخبار لکھ کے متن سے سیلی جگہ کی پیش بینی کریں۔ پیشنهاد کی طریقہ ٹیکس میں موقعیت کی موقعیت کو پہچان کرنے کے لئے کیب سے پیدا کیا ہوا موقعیت کا ایک لکھنے والی جگہ استعمال کرتا ہے اور کیب میں موقعیت کے درمیان موقعیت کے درمیان پوشیدہ معلومات کا استعمال کرتا ہے۔ اس کے لئے تقدیر کی اجازت دیتا ہے کہ منطقہ یونیٹوں میں اور صرف تھوڑے ہیپر پارامیٹر ہیں جن کو تنظیم کرنے کی ضرورت ہے. ہم مطلب اخبار کے مطابق مطلب کے مطابق دکھاتے ہیں کہ پیغمبر کی طریقہ فی اندازہ 0.12 کے مطابق بہت سی بنسلین کے مقابلہ میں بہتر کرتا ہے.', 'ta': "இந்த காகிதத்தில், நாம் ஒரு சுலபமான முறைமையை அறிவு அடிப்படையை பயன்படுத்தி செய்தி கட்டுரையிலிருந்து விற்பனை இடங் பரிந்துரைக்கப்பட்ட முறைமை உரையில் இருந்து உரையில் உள்ள இடங்களை கேபியிலிருந்து உருவாக்கப்பட்ட இடங்களின் அகராதியை பயன்படுத்தி பொருத்தமான வாய்ப்பு  இது ஆர்பிரிட்டர் பகுதி அலகுகளில் முன்வார்வை அனுமதிக்கிறது மற்றும் சில ஹைப்பர்அளபுருக்கள் மட்டும் உள்ளது தேவை நாம் கைமுறையாக வெளிப்படுத்தப்பட்ட செய்தி கட்டுரைகளை பயன்படுத்தி காட்டுகிறோம் பரிந்துரைக்கப்பட்ட முறையில் '0. 12' ம", 'uz': "Bu hujjatda, biz ilmiy bazasini (KB) yordamida qo'shish manzilini koʻrsatish uchun oddiy usulni tahrirlash. The proposed method uses a dictionary of locations created from the KB to identify occurrences of locations in the text and uses the hierarchical information between entities in the KB for assigning appropriate saliency scores to regions.  Bu arbitral maydonning bir necha parametrlarda ishlatish imkoniyatini ruxsat beradi. Biz qo'lbola yordamida yangilangan maqolalar yordamida ko'proq asboblar bilan bir necha xil asboblarga o'zgartiradi.", 'vi': 'Trong tờ giấy này, chúng tôi đề xuất một phương pháp đơn giản để dự đoán vị trí nổi bật từ văn bản bài báo, sử dụng một căn cứ kiến thức (KB). Phương pháp đề nghị sử dụng từ điển các địa điểm được tạo ra từ KB để xác định các lần xuất hiện các địa điểm trong văn bản và sử dụng các thông tin cấp bậc giữa các thực thể trong KB để chỉ định các điểm nổi tiếng thích hợp cho các vùng. Nó cho phép dự đoán tại các đơn vị khu vực ngẫu nhiên và chỉ có vài siêu tham số cần chỉnh lại. Chúng tôi cho thấy bằng các bài báo được ghi chú bằng tay rằng phương pháp đã đề nghị cải thiện thước đo bằng 0.12 so với nhiều đường hầm.', 'bg': 'В настоящата статия предлагаме прост метод за предсказване на видни локации от текст на новинарска статия, използвайки база от знания (КБ). Предложеният метод използва речник от местоположения, създаден от КБ, за да идентифицира появата на местоположения в текста и използва йерархичната информация между субектите в КБ за определяне на подходящи оценки за видимост на регионите. Тя позволява прогнозиране при произволни регионални единици и има само няколко хиперпараметри, които трябва да бъдат настроени. С помощта на ръчно анотирани новинарски статии показваме, че предложеният метод подобрява мярката с 0,12 в сравнение с множество базови линии.', 'da': "I denne artikel foreslår vi en simpel metode til at forudsige fremtrædende placeringer fra nyhedsartikletekst ved hjælp af en vidensbase (KB). Den foreslåede metode bruger en ordbog over steder, der er oprettet ud fra KB'en, til at identificere forekomster af steder i teksten og bruger de hierarkiske oplysninger mellem enheder i KB'en til at tildele passende pointtal til regioner. Det tillader forudsigelse ved vilkårlige regionenheder og har kun få hyperparametre, der skal indstilles. Vi viser ved hjælp af manuelt kommenterede nyhedsartikler, at den foreslåede metode forbedrer f-målingen med 0,12 sammenlignet med flere basislinjer.", 'nl': "In dit artikel stellen we een eenvoudige methode voor om opvallende locaties te voorspellen vanuit de tekst van nieuwsberichten met behulp van een kennisbank (KB). De voorgestelde methode maakt gebruik van een woordenboek van locaties gemaakt van de KB om het voorkomen van locaties in de tekst te identificeren en gebruikt de hiërarchische informatie tussen entiteiten in de KB voor het toewijzen van geschikte saliciteitsscores aan regio's. Het maakt voorspelling mogelijk bij willekeurige regio-eenheden en heeft slechts een paar hyperparameters die moeten worden afgestemd. Aan de hand van handmatig geannoteerde nieuwsberichten laten we zien dat de voorgestelde methode de f-maat met 0.12 verbetert in vergelijking met meerdere baselines.", 'hr': 'U ovom papiru predlažemo jednostavnu metodu predviđanja saličnih lokacija iz teksta novinskog članaka koristeći bazu znanja (KB). Predložena metoda koristi rečnik lokacija stvorenih iz KB-a kako bi identificirali pojave lokacija u tekstu i koristili hijerarhičku informaciju između entitata u KB-u za dodavanje odgovarajućih rezultata salicije regijama. To omogućava predviđanje u proizvodnjim jedinicama region a i ima samo nekoliko hiperparametara koji trebaju biti prilagođeni. Pokazujemo koristeći manuelno annotirane novinske članake da je predložena metoda poboljšala mjeru f-0,12 u usporedbi s višestrukim početnim linijama.', 'de': 'In diesem Beitrag schlagen wir eine einfache Methode vor, um prominente Standorte aus Nachrichtenartikeltexten anhand einer Wissensdatenbank (KB) vorherzusagen. Die vorgeschlagene Methode verwendet ein von der KB erstelltes Standortwörterbuch, um Vorkommen von Standorten im Text zu identifizieren und verwendet die hierarchischen Informationen zwischen Entitäten in der KB, um Regionen geeignete Salienzwerte zuzuweisen. Es ermöglicht Vorhersagen an beliebigen Regionseinheiten und hat nur wenige Hyperparameter, die abgestimmt werden müssen. Anhand von manuell kommentierten Nachrichtenartikeln zeigen wir, dass die vorgeschlagene Methode das f-Maß um 0,12 im Vergleich zu mehreren Baselines verbessert.', 'ko': '본고에서 우리는 지식 라이브러리(KB)를 이용하여 뉴스 문장 텍스트에서 현저한 위치를 예측하는 간단한 방법을 제시했다.제시된 방법은 지식 라이브러리에서 만들어진 위치 사전을 이용하여 텍스트의 위치의 출현을 식별하고 지식 라이브러리에서 실체 간의 차원 정보를 이용하여 지역에 적당한 현저성 점수를 분배한다.그것은 임의의 지역 단위로 예측할 수 있고 조정해야 할 몇 개의 초파라미터만 있다.우리는 수동으로 주석한 뉴스 기사를 사용하여 여러 기선에 비해 제시한 방법이 f도량을 0.12 높였다는 것을 나타냈다.', 'id': 'Dalam kertas ini, kami mengusulkan metode sederhana untuk memprediksi lokasi yang penting dari teks artikel berita menggunakan dasar pengetahuan (KB). Metode yang diusulkan menggunakan kamus lokasi yang diciptakan dari KB untuk mengidentifikasi kejadian lokasi dalam teks dan menggunakan informasi hierarkis antara entitas di KB untuk mengatur skor salinsi yang sesuai ke daerah. Ini memungkinkan prediksi di unit wilayah arbitrari dan hanya memiliki beberapa hyperparameter yang perlu disesuaikan. Kami menunjukkan menggunakan artikel berita annotasi secara manual bahwa metode yang diusulkan memperbaiki f-ukuran dengan 0,12 dibandingkan dengan garis dasar berbilang.', 'fa': 'در این کاغذ، ما یک روش ساده پیشنهاد می\u200cکنیم تا جایگاهی استفاده از متن اخبار با استفاده از پایگاه علم (ک ب) پیش بینی کنیم. روش پیشنهاد از یک لغت\u200cنامه از مکان\u200cهای ایجاد شده از کیب استفاده می\u200cکند تا اتفاقات مکان\u200cهای متن را شناسایی کند و از اطلاعات قانونی بین عناصر\u200cها در کیب استفاده می\u200cکند برای تعیین نمونه\u200cهای قابل استفاده به منطقه\u200cها. این اجازه می\u200cدهد پیش\u200cبینی در واحدهای منطقه\u200cای تصادفی باشد و فقط چند پارامتر hyperparameters دارد که باید تنظیم شود. ما با استفاده از مقاله\u200cهای خبری\u200cهای دستگیر نشان می\u200cدهیم که روش پیشنهاد f-اندازه را با 0.12 در مقایسه با بسیاری از خط\u200cهای بنیادی بهتر می\u200cکند.', 'tr': 'Bu kagyzda, bilim üssünden (KB) ulanan täzelikli ýerleri önlemek üçin basit bir yöntem teklip edýäris. Önerleven metin ýerleri belli etmek üçin KB-den oluşan ýerler sözlügini ulanýar we ýerlerde ýerleri ýerleşdirmek üçin KB-de ýerleşdirilen ýerler arasyndaky iýerarhiýa maglumaty ullanyr. unit-format Biz bu täzelikler ullanyp görkezilýän täzelikler ullanyp görkezip görkezip görkezip ýän nusgasyny f ölçüsi “ 0.12” diýip çarpylýar, birnäçe basit hatlary bilen karşılaşýar.', 'sw': 'Katika karatasi hii, tunapendekeza njia rahisi ya kutabiri maeneo yanayotumiwa na makala ya habari kwa kutumia msingi wa maarifa (KB). Utawala huu unapendekezwa hutumia dictionary of locations created from KB to identify locations in text and use the hierarchical information between entities in KB for assigning scores suitable to the region. Inaruhusu kutabiri katika vifaa vya eneo la kiholela na ina parameter chache tu ambazo zinahitaji kuchangwa. Tunaonyesha kwa kutumia makala za habari zenye kuchanganyikiwa kwa mkono kwamba mbinu hiyo ya pendekezo inaboresha upatikanaji wa nafasi kwa £0.12 ukilinganisha na mistari mbalimbali.', 'af': "In hierdie papier, voorstel ons 'n eenvoudige metode om salient ligging te voorskou van nuus artikel teks te gebruik met 'n kennis basis (Kb). Die voorgestelde metode gebruik 'n woordeboek van liggings geskep van die Kb om voorkoms van liggings in die teks te identifiseer en gebruik die hierarkies inligting tussen entiteite in die Kb vir toewying van geskikte salienstelling telling na regione. Dit laat toe voorskou by arbitrêre regionale eenhede en het slegs 'n paar hiperparameters wat nodig moet wees aangepas. Ons wys deur die gebruik van hand aangetelde nuus artikels dat die voorgestelde metode die f-maat verbeter deur 0.12 vergelyk met veelvuldige basis lyne.", 'sq': 'Në këtë letër, propozojmë një metodë të thjeshtë për të parashikuar vendet e rëndësishme nga teksti i artikullit të lajmeve duke përdorur një bazë njohurie (KB). Metoda e propozuar përdor një fjalor të vendeve të krijuara nga KB për të identifikuar ndodhjet e vendeve në tekst dhe përdor informacionin hierarkik midis njësive në KB për të caktuar rezultate të përshtatshme të shënuara në rajone. Ajo lejon parashikimin në njësitë arbitrare të rajonit dhe ka vetëm disa hyperparametra që duhet të rregullohen. Ne tregojmë duke përdorur artikujt e lajmeve të anotuar manualisht se metoda e propozuar përmirëson masën f me 0.12 krahasuar me linjat bazë të shumta.', 'am': 'በዚህ ካላት ውስጥ እውቀት መቀመጫን (KB) በመጠቀም የዜና አርእስት ጽሑፍ ቦታዎችን ለማሳየት ቀላል ልማድ እናሳልቃለን፡፡ The proposed method uses a dictionary of locations created from the KB to identify occurrences of locations in the text and uses the hierarchical information between entities in the KB for assigning appropriate saliency scores to regions.  በአርቢስቲካዊ ክልል ውስጥ ትንቢት እንዲፈቅድ እና በጥቂት hyperparameters ብቻ ያስፈልጋል፡፡ በጥያቄ የዜና ጽሑፎችን በመጠቀም እናሳያቸዋለን፡፡ የተዘጋጀው ሥርዓት በ0.12 በተለየ ብዙዎች መሠረት ይሻላል፡፡', 'hy': 'Այս թղթի մեջ մենք առաջարկում ենք պարզ մեթոդ նորությունների հոդվածի տեքստի հիմնական տեղադրությունների կանխատեսելու համար՝ օգտագործելով գիտելիքի հիմքը (ԿԲ). Պատրաստված մեթոդը օգտագործում է ԿԲ-ից ստեղծված վայրերի բառարան տեքստում տեղադրված վայրերի հայտնաբերման համար և օգտագործում է ԿԲ-ի կազմակերպությունների միջև հիերարխիկ տեղեկատվությունը, որպեսզի հատուկ արտահայտության գնահատականներ տեղադրվի տար Այն թույլ է տալիս կանխատեսել կամավոր տարածաշրջանի միավորներում և ունի միայն մի քանի հիպերպարամետրեր, որոնք պետք է կարգավորվեն: Մենք ցույց ենք տալիս, օգտագործելով ձեռքով նկարագրված նորությունների հոդվածներ, որ առաջարկած մեթոդը բարելավում է f-չափումը 0.12-ով, համեմատած բազմաթիվ հիմնական գծերի հետ:', 'az': 'Bu kağızda, bilgi üssünü (KB) vasitəsilə haqq mətnindən çətin yerləri təmin etmək üçün basit bir yol təklif edirik. Önülləşdirilmiş metod, metin içindəki yerlərin rastlıqlarını tanıtmaq üçün KB-dən yaratdığı yerlərin sözlüyünü istifadə edir və bölgelere uyğun salik nöqtələrini verir. Bu hərəkətli bölgedə tədbir tədbir edər və yalnız bir neçə hiperparametr var ki, tədbir edilməsi lazımdır. Biz özümüzə bildirilmiş xəbər məktublarını göstərdik ki, təklif metodların f ölçüsünü çoxlu sətir ilə 0.12 ilə yaxşılaşdırır.', 'bn': 'এই কাগজটিতে আমরা একটি সাধারণ পদ্ধতি প্রস্তাব করি একটি জ্ঞানের বেস ব্যবহার করে সংবাদ প্রবন্ধের সংবাদ প্রবন্ধের সংবাদ প্ প্রস্তাবিত পদ্ধতি টেক্সটে অবস্থান সনাক্ত করার জন্য কেবিবি থেকে তৈরি করা অবস্থানের একটি অভিধান ব্যবহার করে এবং কেবির মধ্যে প্রযুক্ত বৈশিষ্ট্যের স্কোর দি এটি বিচ্ছিন্ন অঞ্চলের ইউনিটে ভবিষ্যদ্বাণী প্রদান করে এবং শুধুমাত্র কয়েকটি হাইপারার প্যারামিটার আছে যাদের স আমরা সংবাদ প্রবন্ধ ব্যবহার করে দেখাচ্ছি যে প্রস্তাবিত পদ্ধতি বেশ কয়েকটি বেসার লাইনের তুলনায় ০.', 'et': 'Käesolevas töös pakume välja lihtsa meetodi oluliste asukohtade prognoosimiseks uudisartikli tekstist, kasutades teadmistebaasi (KB). Kavandatud meetod kasutab tekstis asukohtade esinemise tuvastamiseks KB-st loodud asukohtade sõnastikku ja piirkondadele sobivate silmapaistvuskooride määramiseks kasutab KB-i olemite vahelist hierarhilist teavet. See võimaldab ennustada suvalise piirkonna ühikuid ja on ainult mõned hüperparameetrid, mida tuleb häälestada. Näitame käsitsi annoteeritud uudisteartiklite abil, et kavandatud meetod parandab f-mõõdet 0,12 võrra võrreldes mitme lähtejoonega.', 'bs': 'U ovom papiru predlažemo jednostavnu metodu predviđanja saličnih lokacija iz teksta novinskog članaka koristeći bazu znanja (KB). Predložena metoda koristi rečnik lokacija stvorenih iz KB-a kako bi identifikovao pojave lokacija u tekstu i koristio hijerarhičku informaciju između entitata u KB-u za dodavanje odgovarajućih rezultata salicije regijama. To omogućava predviđanje u proizvodnim jedinicama region a i ima samo nekoliko hiperparametara koji trebaju biti prilagođeni. Mi pokazujemo korištenjem manuelno annotiranih novinskih članaka da je predložena metoda poboljšava f-mjeru za 0,12 u usporedbi s višestrukim osnovnim linijama.', 'ca': "En aquest article, proposem un mètode senzill per predir llocs salients del text d'un article de notícies utilitzant una base de coneixement (KB). El mètode proposat utilitza un diccionari de llocs creats a partir del KB per identificar ocurrències de llocs en el text i utilitza la informació jeràrquica entre entitats del KB per assenyar puntuacions adequats de saliència a les regions. Permet predir unes unitats arbitràries de regió i només té uns quants hiperpàmetres que cal ajustar. We show using manually annotated news articles that the proposed method improves the f-measure by  0.12 compared to multiple baselines.", 'cs': 'V tomto článku navrhujeme jednoduchou metodu predikce významných lokalit z textu zpravodajského článku pomocí znalostní báze (KB). Navržená metoda využívá slovník lokalit vytvořený z KB k identifikaci výskytu lokalit v textu a využívá hierarchické informace mezi entitami v KB pro přiřazení příslušných výsledků výsledků salencity regionům. Umožňuje predikci na libovolných jednotkách oblasti a má pouze několik hyperparametrů, které je třeba naladit. Pomocí ručně anotovaných zpravodajských článků ukazujeme, že navrhovaná metoda zlepšuje f-měření o 0,12 ve srovnání s více základními liniemi.', 'fi': 'Tässä artikkelissa ehdotamme yksinkertaista menetelmää merkittävien sijaintien ennustamiseen uutisartikkelin tekstistä käyttäen tietopohjaa (KB). Ehdotetussa menetelmässä käytetään KB:stä luotua sijaintisanakirjaa paikannusten tunnistamiseen tekstissä ja KB:n entiteettien välistä hierarkkista tietoa sopivien näkyvyyspisteiden määrittämiseen alueille. Se mahdollistaa ennusteen mielivaltaisilla alueyksiköillä ja on vain muutamia hyperparametreja, jotka täytyy virittää. Osoitamme manuaalisesti annotoiduilla uutisartikkeleilla, että ehdotettu menetelmä parantaa f-mittaria 0,12:lla verrattuna moniin perusviivoihin.', 'jv': 'Nang pebuk iki, kita supoyo sistem sampeyan kanggo ngerti luwih apa-apa kanggo ingkang artik batir barang nggawe basa matang (K). Ndoleh sing dipolehasno ning diketeksi sing gawe ngubah akeh saben nang K unit-format Awak dhéwé éntuk sistem sing manut kanggo ngerewakno dadi Manual', 'sk': 'V prispevku predlagamo enostavno metodo napovedovanja pomembnih lokacij iz besedila novic z uporabo baze znanja (KB). Predlagana metoda uporablja slovar lokacij, ustvarjen iz KB, za prepoznavanje pojavov lokacij v besedilu in uporablja hierarhične informacije med entitetami v KB za dodeljevanje ustreznih ocen opaznosti regijam. Omogoča napovedovanje pri poljubnih regijskih enotah in ima le nekaj hiperparametrov, ki jih je treba nastaviti. S pomočjo ročno označenih člankov prikazujemo, da predlagana metoda izboljša merilo f za 0,12 v primerjavi z več osnovnimi črtami.', 'ha': 'Daga wannan takardar, muna buƙata wani metode mai sauƙi zuwa ka ƙayyade wurin masu buƙata daga matsayin makala na lãbãri da amfani da wani bane na ilmi (KB). @ info: whatsthis Yana yarda ka yi bayani a cikin sunayen region masu arbita kuma yana da ƙayyade guda masu buƙata kawai. Tuna nũna wa makala da aka faɗa da hannayen da aka faɗa cewa, hanyon da aka faɗaɗa f-metode da 0.12 sammenliki da misalin masu yawa.', 'he': 'בעיתון הזה, אנו מציעים שיטה פשוטה לחזות מיקומות מפורסמים מטקסט מאמר חדשות באמצעות בסיס ידע (KB). השיטה המוצעת משתמשת במילון של מיקומות שנוצרים מהKB כדי לזהות התרחשות של מיקומות בטקסט ולהשתמש במידע הייררכי בין יחידות בקי.בי. זה מאפשר לחזות ביחידות אזוריות עצומות ויש לו רק כמה היפרפרמטרים שצריכים להתאים. אנו מראים באמצעות מאמרים חדשות מוכתבים ידנית שהשיטה המוצעת משפר את המידה ב-0.12 בהשוואה למספר קווים בסיסיים.', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཆ་འཕྲིན་ཡིག་གི་གནས་ཡུལ་རྣམས་སྔོན་སྟངས་ཐབས་ལམ་སྟབས་བདེ་བོའི་སྔོན་སྒྲིག The proposed method uses a dictionary of locations created from the KB to identify occurrences of locations in the text and uses the hierarchical information between entities in the KB for assigning appropriate saliency scores to regions. It allows prediction at arbitrary region units and has only a few hyperparameters that need to be tuned. ང་ཚོས་f-ཚད་ལྟར་ཡར་རྒྱས་གཏོང་ཡོད་པའི་བརྡ་ཞིག་སྟངས་ལག་སྟར་བཀོད་བྱས་པ་ནི།'}
{'en': 'An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks K orean  NLP  Tasks', 'ar': 'دراسة تجريبية لاستراتيجيات الترميز للعديد من مهام البرمجة اللغوية العصبية الكورية', 'fr': 'Une étude empirique des stratégies de tokenisation pour diverses tâches de PNL coréennes', 'pt': 'Um estudo empírico de estratégias de tokenização para várias tarefas coreanas de PNL', 'es': 'Un estudio empírico de las estrategias de tokenización para varias tareas de la PNL coreana', 'zh': '韩诸NLP务者,实也', 'ja': '様々な韓国NLPタスクのトークン化戦略の実証的研究', 'ru': 'Эмпирическое исследование стратегий токенизации для различных корейских задач NLP', 'hi': 'विभिन्न कोरियाई एनएलपी कार्यों के लिए टोकनीकरण रणनीतियों का एक अनुभवजन्य अध्ययन', 'ga': 'Staidéar Eimpíreach ar Straitéisí Comharthaíochta le haghaidh Tascanna Éagsúla NLP na Cóiré', 'el': 'Εμπειριακή Μελέτη Στρατηγικών Τοκενοποίησης για Διάφορα Κορεατικά καθήκοντα NLP', 'ka': 'Tokenization Strategies for Various Korean NLP Tasks An Empirical Study of Tokenization Strategies', 'hu': 'A tokenizációs stratégiák empirikus tanulmánya különböző koreai NLP feladatokhoz', 'it': 'Uno studio empirico delle strategie di tokenizzazione per vari compiti del PNL coreano', 'mk': 'Империска студија на стратегиите за токенизација за различни корески НЛП задачи', 'ml': 'An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks', 'ms': 'Name', 'mt': 'Studju Empiriku ta’ Strateġiji ta’ Tokenizzazzjoni għal Ħidmiet Diversi tal-NLP Koreani', 'kk': 'Түрлі корея NLP тапсырмаларының токенизациялау стратегиясының империялық зерттеу', 'mn': 'Олон Солонгосын NLP ажлын Токенизацийн стратегийг эзэмшигийн судалгаа', 'no': 'Name', 'ro': 'Un studiu empiric al strategiilor de tokenizare pentru diferite sarcini ale PNL coreene', 'lt': 'Įvairių Korėjos NLP užduočių toksinio poveikio strategijų empirinis tyrimas', 'pl': 'Empiryczne badanie strategii tokenizacji dla różnych koreańskich zadań NLP', 'sr': 'Impiričko istraživanje Tokenizacije strategije za razne korejske NLP zadatke', 'si': 'Name', 'sv': 'En empirisk studie av tokeniseringsstrategier för olika koreanska NLP-uppgifter', 'ta': 'பல்வேறு கொரியா NLP பணிகளுக்கான முன்னிருப்பு முறைமையான முயற்சி', 'ur': 'مختلف کوریایی NLP تاسکیوں کے لئے ٹوکینیزان استراتژی کی مطالعہ', 'so': 'A Empirical Study of Tokenization Strategies for various Korean NLP shaqooyinka', 'uz': 'Name', 'vi': 'Một cuộc nghiệp chấm thuật chậm học cho nhiều điều nhạc của Hàn quốc', 'bg': 'Емпирично проучване на стратегиите за токенизация за различни задачи на корейския НПО', 'nl': 'Een empirische studie van tokeniseringsstrategie√´n voor verschillende Koreaanse NLP-taken', 'hr': 'Empiričko ispitivanje Tokenizacijske strategije za razne korejske NLP zadatke', 'da': 'En empirisk undersøgelse af tokeniseringsstrategier for forskellige koreanske NLP-opgaver', 'de': 'Eine empirische Studie von Tokenisierungsstrategien für verschiedene koreanische NLP-Aufgaben', 'ko': '한국어 자연 언어 처리 임무 중 표기화 전략에 대한 실증 연구', 'id': 'Sebuah Studi Empirical of Tokenization Strategies for Various Korean NLP Tasks', 'fa': 'یک مطالعه امپراتیک از استراتژی های توکینیزی برای کارهای NLP مختلف کره', 'sw': 'Utafiti wa Uwezeshaji wa Mipango ya Kutengeneza kwa Mipango mbalimbali ya Kazi za NLP nchini Korea', 'tr': 'Köreçe NLP Görevleri üçin Tokenizaň Strateýgisi', 'af': "'n Empirical Study of Tokenization Strategies for Various Korean NLP Tasks", 'sq': 'Një studim perandor i strategjive të Tokenizimit për detyra të ndryshme të NLP Koreane', 'az': 'Çeşitli Koreyanın NLP işləri üçün Tokenizasyon Stratexyolarının İmparikiya Öyrənməsi', 'am': 'የተለያዩ የቆሬያ NLP ስራዎችን ለማድረግ የተማሪ ትምህርት', 'hy': 'Տոքսենիզացիայի ռազմավարության տարբեր կորեացի ՆԼՊ-ի առաջադրանքների կայսրական ուսումնասիրությունը', 'bs': 'Empiričko ispitivanje Tokenizacijske strategije za razne korejske NLP zadatke', 'cs': 'Empirická studie tokenizačních strategií pro různé korejské NLP úkoly', 'bn': 'বিভিন্ন কোরিয়ার এনএলপি কাজের জন্য টোকেনিজেশন স্ট্রেটেজির একটি সামার্কিক গবেষণা', 'fi': 'Empiirinen tutkimus eri korealaisten NLP-tehtävien Tokenisaatiostrategioista', 'et': 'Empiiriline uuring erinevate Korea NLP ülesannete Tokeniseerimisstrateegiate kohta', 'ca': "Un estudi empíric d'estratègies de toxinització per a diverses tasques del NLP coreans", 'he': 'מחקר אימפריקלי של אסטרטגיות טוקניזציה למשימות NLP קוריאות שונות', 'sk': 'Empirična študija strategij tokenizacije za različne naloge korejskega NLP', 'jv': 'Ombudhakan Ketokenisaan Seneng Daerah Karo NLP Taaksi Korea', 'ha': 'An Empirical Research of Tokenization Traitors for variables Korea NLP tasks', 'bo': 'ཊོ་ཀོ་རི་ཡཱན་གྱི་NLP བྱ་འགུལ་སྤེལ་བའི་གྲ་སྐོར་གྱི་དཔྱད་ལས་སྦྱོར་བརྩོན་བྱས་པ་ཞིག་'}
{'en': 'Typically,  tokenization  is the very first step in most  text processing  works. As a token serves as an atomic unit that embeds the contextual information of text, how to define a token plays a decisive role in the performance of a model. Even though Byte Pair Encoding (BPE) has been considered the de facto standard tokenization method due to its simplicity and universality, it still remains unclear whether BPE works best across all languages and tasks. In this paper, we test several tokenization strategies in order to answer our primary research question, that is, What is the best tokenization strategy for Korean NLP tasks? Experimental results demonstrate that a hybrid approach of morphological segmentation followed by BPE works best in  Korean  to / from English machine translation and natural language understanding tasks such as KorNLI, KorSTS, NSMC, and PAWS-X. As an exception, for KorQuAD, the Korean extension of SQuAD, BPE segmentation turns out to be the most effective. Our code and pre-trained models are publicly available at https://github.com/kakaobrain/kortok.', 'ar': 'عادةً ما يكون الترميز هو الخطوة الأولى في معظم أعمال معالجة النصوص. نظرًا لأن الرمز المميز يعمل كوحدة ذرية تدمج المعلومات السياقية للنص ، فإن كيفية تعريف الرمز المميز يلعب دورًا حاسمًا في أداء النموذج. على الرغم من أن تشفير زوج البايت (BPE) قد تم اعتباره أسلوب الترميز القياسي الواقعي نظرًا لبساطته وشموليته ، إلا أنه لا يزال من غير الواضح ما إذا كان BPE يعمل بشكل أفضل عبر جميع اللغات والمهام. في هذه الورقة ، نختبر العديد من استراتيجيات الترميز للإجابة على سؤال البحث الأساسي لدينا ، وهو "ما هي أفضل استراتيجية رمزية لمهام البرمجة اللغوية العصبية الكورية؟" توضح النتائج التجريبية أن النهج الهجين للتجزئة المورفولوجية متبوعًا بـ BPE يعمل بشكل أفضل في اللغة الكورية من / إلى الترجمة الآلية الإنجليزية ومهام فهم اللغة الطبيعية مثل KorNLI و KorSTS و NSMC و PAWS-X. كاستثناء ، بالنسبة لـ KorQuAD ، الامتداد الكوري لـ SQuAD ، تبين أن تجزئة BPE هي الأكثر فعالية. الكود الخاص بنا والنماذج المدربة مسبقًا متاحة للجمهور على https://github.com/kakaobrain/kortok.', 'fr': "Généralement, la segmentation en jetons est la toute première étape de la plupart des travaux de traitement de texte. Comme un jeton sert d'unité atomique intégrant les informations contextuelles du texte, la définition d'un jeton joue un rôle décisif dans la performance d'un modèle. Même si l'encodage par paires d'octets (BPE) a été considéré comme la méthode de segmentation standard de facto en raison de sa simplicité et de son universalité, on ne sait toujours pas si BPE fonctionne le mieux dans tous les langages et toutes les tâches. Dans cet article, nous testons plusieurs stratégies de tokenisation afin de répondre à notre principale question de recherche, à savoir «\xa0Quelle est la meilleure stratégie de tokenisation pour les tâches de PNL coréennes\xa0?\xa0» Les résultats expérimentaux démontrent qu'une approche hybride de segmentation morphologique suivie de BPE fonctionne mieux pour les tâches de traduction automatique en coréen vers/depuis l'anglais et de compréhension du langage naturel telles que KornLi, KORSTs, NSMC et PAWS-X. Exceptionnellement, pour KorQuad, l'extension coréenne de SQuad, la segmentation BPE s'avère la plus efficace. Notre code et nos modèles pré-entraînés sont accessibles au public à l'adresse https://github.com/kakaobrain/kortok.", 'pt': 'Normalmente, a tokenização é o primeiro passo na maioria dos trabalhos de processamento de texto. Como um token serve como uma unidade atômica que incorpora as informações contextuais do texto, como definir um token desempenha um papel decisivo no desempenho de um modelo. Embora o Byte Pair Encoding (BPE) tenha sido considerado o método de tokenização padrão de fato devido à sua simplicidade e universalidade, ainda não está claro se o BPE funciona melhor em todos os idiomas e tarefas. Neste artigo, testamos várias estratégias de tokenização para responder à nossa principal questão de pesquisa, ou seja, “Qual é a melhor estratégia de tokenização para tarefas coreanas de PNL?” Os resultados experimentais demonstram que uma abordagem híbrida de segmentação morfológica seguida de BPE funciona melhor na tradução automática de coreano para/do inglês e tarefas de compreensão de linguagem natural, como KorNLI, KorSTS, NSMC e PAWS-X. Como exceção, para KorQuAD, a extensão coreana do SQuAD, a segmentação BPE acaba sendo a mais eficaz. Nosso código e modelos pré-treinados estão disponíveis publicamente em https://github.com/kakaobrain/kortok.', 'es': 'Por lo general, la tokenización es el primer paso en la mayoría de los trabajos de procesamiento de texto. Como un token sirve como una unidad atómica que incorpora la información contextual del texto, la forma de definir un token juega un papel decisivo en el desempeño de un modelo. A pesar de que la codificación de par de bytes (BPE) se ha considerado el método de tokenización estándar de facto debido a su simplicidad y universalidad, aún no está claro si la BPE funciona mejor en todos los idiomas y tareas. En este artículo, probamos varias estrategias de tokenización para responder a nuestra pregunta principal de investigación, es decir, «¿Cuál es la mejor estrategia de tokenización para las tareas de PNL coreana?» Los resultados experimentales demuestran que un enfoque híbrido de segmentación morfológica seguido de BPE funciona mejor en tareas de traducción automática del coreano a/desde el inglés y la comprensión del lenguaje natural como KorNli, KorSTs, NSMC y PAWS-X. Como excepción, para KorQuad, la extensión coreana de sQuad, la segmentación de BPE resulta ser la más eficaz. Nuestro código y modelos preentrenados están disponibles al público en https://github.com/kakaobrain/kortok.', 'ja': '通常、トークン化はほとんどのテキスト処理作業の最初のステップです。 トークンは、テキストのコンテキスト情報を埋め込む原子単位として機能するため、トークンを定義する方法は、モデルのパフォーマンスにおいて決定的な役割を果たします。 バイトペアエンコーディング（ BPE ）は、そのシンプルさと普遍性のために事実上の標準トークン化方法と見なされてきましたが、BPEがすべての言語とタスクで最適に機能するかどうかはまだ不明です。 この論文では、主要な研究課題である「韓国のNLPタスクに最適なトークン化戦略は何ですか？」に答えるために、いくつかのトークン化戦略をテストします。」実験結果は、形態的セグメンテーションに続くBPEのハイブリッドアプローチが、KorNLI、KorSTS、NSMC、PAWS - Xなどの韓国語と英語の機械翻訳および自然言語理解タスクで最も効果的であることを示しています。例外として、SQuADの韓国の拡張であるKorQuADでは、BPEセグメンテーションが最も効果的であることがわかりました。 コードと事前トレーニング済みモデルは、https://github.com/kakaobrain/kortokで公開されています。', 'zh': '凡标记化是多文本处事之首。 以令牌充嵌文本上下文信息之原子单元,故定义令牌于模形之性中起著决定性之用。 虽字节于编码(BPE),以简性通用性为实,而BPE于言任之效未可知也。 试之化策,以应大体,曰:"韩NLP之至策何如?" 实验结果表明形分之混合,然后为BPE,于韩语与英语机器翻译、自然语言解事(如KorNLI、KorSTS、NSMC、PAWS-X)之效为上。 其于SQuAD韩语广KorQuAD,BPE分之效也。 吾代码与豫教者,明于 https://github.com/kakaobrain/kortok 也。', 'ru': 'Как правило, токенизация является самым первым шагом в большинстве работ по обработке текста. Поскольку токен служит в качестве атомной единицы, которая встраивает контекстную информацию текста, то как определить токен играет решающую роль в эффективности модели. Несмотря на то, что кодирование пары байтов (BPE) считается де-факто стандартным методом токенизации из-за его простоты и универсальности, все еще остается неясным, работает ли BPE лучше всех языков и задач. В этой статье мы тестируем несколько стратегий токенизации, чтобы ответить на наш основной исследовательский вопрос: «Какова лучшая стратегия токенизации для корейских задач NLP?« Экспериментальные результаты показывают, что гибридный подход морфологической сегментации, за которым следует BPE, лучше всего работает в задачах перевода с корейского на английский и понимания естественного языка, таких как KorNLI, KorSTS, NSMC и PAWS-X. Исключением является KorQuAD, корейское расширение сегментации SQuAD, BPE. Наш код и предварительно обученные модели доступны в открытом доступе по адресу https://github.com/kakaobrain/kortok.', 'hi': 'आमतौर पर, टोकनाइजेशन अधिकांश पाठ प्रसंस्करण कार्यों में पहला कदम है। जैसा कि एक टोकन एक परमाणु इकाई के रूप में कार्य करता है जो पाठ की प्रासंगिक जानकारी को एम्बेड करता है, टोकन को कैसे परिभाषित किया जाए, एक मॉडल के प्रदर्शन में एक निर्णायक भूमिका निभाता है। भले ही बाइट पेयर एन्कोडिंग (बीपीई) को इसकी सादगी और सार्वभौमिकता के कारण वास्तविक मानक टोकनीकरण विधि माना जाता है, फिर भी यह स्पष्ट नहीं है कि बीपीई सभी भाषाओं और कार्यों में सबसे अच्छा काम करता है या नहीं। इस पेपर में, हम अपने प्राथमिक शोध प्रश्न का उत्तर देने के लिए कई टोकनीकरण रणनीतियों का परीक्षण करते हैं, अर्थात, "कोरियाई एनएलपी कार्यों के लिए सबसे अच्छी टोकनाइजेशन रणनीति क्या है? प्रयोगात्मक परिणामों से पता चलता है कि बीपीई के बाद रूपात्मक विभाजन का एक हाइब्रिड दृष्टिकोण कोरियाई से / अंग्रेजी मशीन अनुवाद और KorNLI, KorSTS, NSMC और PAWS-X जैसे प्राकृतिक भाषा समझने वाले कार्यों में सबसे अच्छा काम करता है। एक अपवाद के रूप में, KorQuAD के लिए, SQuAD का कोरियाई विस्तार, BPE विभाजन सबसे प्रभावी साबित होता है। हमारे कोड और पूर्व प्रशिक्षित मॉडल सार्वजनिक रूप से https://github.com/kakaobrain/kortok पर उपलब्ध हैं।', 'ga': 'Go tipiciúil, is é tokenization an chéad chéim i bhformhór na n-oibreacha próiseála téacs. Toisc gur aonad adamhach é comhartha a neadaíonn faisnéis chomhthéacsúil an téacs, tá ról cinntitheach ag conas comhartha a shainiú i bhfeidhmiú samhail. Cé gur measadh gurb é Ionchódú Beart Péire (BPE) an modh caighdeánach comharthaíochta de facto mar gheall ar a simplíocht agus a uilíocht, ní léir fós an n-oibríonn BPE is fearr i ngach teanga agus tasc. Sa pháipéar seo, déanaimid tástáil ar roinnt straitéisí comharthaíochta chun ár bpríomhcheist taighde a fhreagairt, is é sin, "Cad é an straitéis comharthaíochta is fearr le haghaidh tascanna NLP na Cóiré?" Léiríonn torthaí turgnamhacha go n-oibríonn cur chuige hibrideach de dheighilt moirfeolaíoch agus BPE ina dhiaidh sin ag obair ar an mbealach is fearr sa Chóiréis go/ó aistriúchán meaisín Béarla agus tascanna tuiscint teanga nádúrtha ar nós KorNLI, KorSTS, NSMC, agus PAWS-X. Mar eisceacht, i gcás KorQuAD, is é an síneadh Cóiréach ar dheighilt SQuAD, BPE an ceann is éifeachtaí. Tá ár gcód agus ár múnlaí réamhoilte ar fáil go poiblí ag https://github.com/kakaobrain/kortok.', 'el': 'Συνήθως, η επισήμανση είναι το πρώτο βήμα στις περισσότερες εργασίες επεξεργασίας κειμένου. Ως σύμβολο χρησιμεύει ως ατομική μονάδα που ενσωματώνει τις πληροφορίες περιβάλλοντος του κειμένου, ο ορισμός ενός σήματος παίζει καθοριστικό ρόλο στην απόδοση ενός μοντέλου. Παρόλο που η κωδικοποίηση ζευγαριού Byte (έχει θεωρηθεί η εκ των πραγμάτων τυποποιημένη μέθοδος επισήμανσης λόγω της απλότητας και της καθολικότητάς της, εξακολουθεί να παραμένει ασαφές αν λειτουργεί καλύτερα σε όλες τις γλώσσες και εργασίες. Σε αυτή την εργασία, εξετάζουμε διάφορες στρατηγικές επισήμανσης προκειμένου να απαντήσουμε στην κύρια ερευνητική μας ερώτηση, δηλαδή, "Ποια είναι η καλύτερη στρατηγική επισήμανσης για τα καθήκοντα της Κορέας;" Τα πειραματικά αποτελέσματα καταδεικνύουν ότι μια υβριδική προσέγγιση μορφολογικής κατακερματισμού ακολουθούμενη από BPE λειτουργεί καλύτερα στην κορεάτικη προς/από αγγλική μηχανική μετάφραση και εργασίες κατανόησης φυσικής γλώσσας όπως και ως εξαίρεση, για το KorQuAD, η κορεάτικη επέκταση του SQuAD, η τμηματοποίηση BPE αποδεικνύεται η πιο αποτελεσματική. Ο κώδικας και τα προ-εκπαιδευμένα μοντέλα μας είναι δημόσια διαθέσιμα στο https://github.com/kakaobrain/kortok.', 'hu': 'Jellemzően a tokenizáció az első lépés a legtöbb szövegfeldolgozási munkában. A tokenként olyan atomegységként szolgál, amely beágyazza a szöveg kontextuális információit, a tokenek definiálása döntő szerepet játszik egy modell teljesítményében. Annak ellenére, hogy a bájtpáros kódolás (BPE) egyszerűsége és egyetemessége miatt a de facto standard tokenizációs módszernek számít, még mindig nem világos, hogy a BPE működik-e a legjobban minden nyelven és feladaton. Ebben a tanulmányban több tokenizációs stratégiát tesztelünk annak érdekében, hogy megválaszoljuk elsődleges kutatási kérdésünket, azaz: "Mi a legjobb tokenizációs stratégia a koreai NLP feladatokhoz?" Kísérleti eredmények azt mutatják, hogy a morfológiai szegmentáció hibrid megközelítése, amelyet a BPE követ, a koreai gépi fordítás és a természetes nyelv megértési feladatok, mint a KorNLI, KorsTS, NSMC és PAWS-X. Kivételként a KorQuAD esetében, az SQUAD koreai kiterjesztése, a BPE szegmentáció a leghatékonyabbnak bizonyul. Kódunk és előre képzett modelleink nyilvánosan elérhetők a következő oldalon: https://github.com/kakaobrain/kortok.', 'ka': 'ტიპულად, ტექსტის პროცესის პირველი ნაწილია. როგორც ატომიური ერთეულია, რომელიც ტექსტის კონტექსტური ინფორმაციას ჩაყენებს, როგორ განსაზღვრება მოდელის მუშაობაში განსაზღვრებელი პროლია. მაგრამ ბაიტის პოდერის კოდინოდირება (BPE) იყო de facto სტანდარტული ტოკენიზაციის პროცემის გამოსახულება და სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა, რომ BPE მუშაობს ყველა ენაში და დავალებ ამ დომენტში, ჩვენ შევცვალოთ რამდენიმე ტოკენიზაციის სტრატიგიები, რომ გაუკეთოთ ჩვენი პირველ კითხვაში, ეს არის: "რა არის ყველაზე საუკეთესო ტოკენიზაციის სტრატიგია კორე ექსპერიმენტიური წარმოდგენები აჩვენებენ, რომ BPE შემდეგ მოპროლოგიური სეგმენტაციის ჰიბრიტური წარმოდგენები მუშაობს კორეული მაქსინური გაგრძელებაში/ანგლისური მაქსინური გაგრძელებაში და ნახვა ენის გაგრძელებაში, როგორც KorNLI, KorSTS, NSMC და PA ჩვენი კოდი და წინაშემდეგ მოდელები ადამიანის შესაძლებელია https://github.com/kakaobrain/kortok.', 'it': "In genere, la tokenizzazione è il primo passo nella maggior parte dei lavori di elaborazione del testo. Come token serve come unità atomica che incorpora le informazioni contestuali del testo, come definire un token gioca un ruolo decisivo nelle prestazioni di un modello. Anche se la codifica Byte Pair (BPE) è stata considerata il metodo di tokenizzazione standard de facto per la sua semplicità e universalità, non è ancora chiaro se BPE funziona meglio in tutte le lingue e attività. In questo articolo, testiamo diverse strategie di tokenizzazione al fine di rispondere alla nostra domanda di ricerca primaria, che è 'Qual è la migliore strategia di tokenizzazione per le attività NLP coreane?' I risultati sperimentali dimostrano che un approccio ibrido di segmentazione morfologica seguito da BPE funziona meglio nella traduzione automatica coreana a/dall'inglese e nelle attività di comprensione della lingua naturale come KorNLI, KorsTS, NSMC e PAWS-X. Come eccezione, per KorQuAD, l'estensione coreana di SQUAD, la segmentazione BPE risulta essere la più efficace. Il nostro codice e i modelli pre-addestrati sono disponibili pubblicamente a https://github.com/kakaobrain/kortok.", 'lt': 'Paprastai tokenizacija yra pirmasis žingsnis daugumoje teksto apdorojimo darbų. Kaip ženklas naudojamas kaip atominis vienetas, kuris įtraukia kontekstinę teksto informaciją, kaip apibrėžti ženklą atlieka lemiamą vaidmenį atliekant model į. Even though Byte Pair Encoding (BPE) has been considered the de facto standard tokenization method due to its simplicity and universality, it still remains unclear whether BPE works best across all languages and tasks.  Šiame dokumente bandome keletą tokenizacijos strategijų, kad atsakytume į mūsų pirminį mokslinių tyrimų klausimą, t. y. "Kokia yra geriausia tokenizacijos strategija Korėjos NLP užduotims?" Eksperimentiniai rezultatai rodo, kad mišrus morfologinės segmentacijos metodas, po kurio seka BPE, geriausiai veikia koreanų kalba ir (arba) anglų mašin ų vertimo ir natūralios kalbos supratimo užduotis, pvz., KorNLI, KorSTS, NSMC ir PAWS-X. Išimties tvarka KorQuAD atveju Korėjos SQuAD išplėtimas, BPE segmentacija pasirodo veiksmingiausia. Mūsų kodas ir iš anksto parengti modeliai yra viešai prieinami https://github.com/kakaobrain/kortok.', 'mk': 'Обично, токенизацијата е првиот чекор во повеќето текстови процеси. Како знак служи како атомска единица која ги вклучува контекстните информации за текстот, како да се дефинира знак игра одлучна улога во изведувањето на моделот. Иако кодирањето на пари бајти (BPE) се смета за дефактичен стандарден метод на токенизација поради неговата едноставност и универзалност, сé уште не е јасно дали BPE работи најдобро на сите јазици и задачи. Во овој документ, тестираме неколку стратегии за токенизација со цел да одговориме на нашето првично истражувачко прашање, тоа е: „Која е најдобрата стратегија за токенизација за задачите на корејската НЛП?“ Експерименталните резултати покажуваат дека хибридниот пристап на морфолошката сегментација, по кој следи БPE, работи најдобро на корејски до/од англиски машински превод и природен јазик разбирање задачи како што се KorNLI, KorSTS, NSMC и PAWS-X. Како исклучок, за KorQuAD, корејското продолжување на SQuAD, сегментацијата BPE се покажува дека е најефективна. Нашиот код и предобучените модели се јавно достапни на https://github.com/kakaobrain/kortok.', 'kk': 'Жалпы түрде, токенизация мәтін өңдеу жұмысының ең бірінші қадамы. Белгісі мәтіннің контексті мәліметін ендіру атомдық бірлігі ретінде, белгісін анықтау үлгісінде шешімді рольді орындайды. Байт пар кодтамасы (BPE) де фактически стандартты токенизациялау әдісі өзінің қарапайым және универсалдығының себебі болса да, BPE әлі тілдер мен тапсырмалардың ең жақсы жұмыс істейтінін білмейді. Бұл қағазда бірнеше токенизациялау стратегиясын тексеріп, негізгі зерттеу сұрағымызды жауап беру үшін, "Корея NLP тапсырмаларының ең жақсы токенизациялау стратегиясы не?" деген сөз. Эксперименталдық нәтижелері, BPE- ден келесі морфологикалық сегментацияның гибридті тәсілдері корейске жұмыс істейді, ағылшын тілінің аудармасынан/ағылшын тілінен жұмыс істейтін жұмыс істейтін жұмыс істейді, мысалы KorNLI, KorSTS, NSMC және PAWS- X. KorQuAD-  Біздің кодымыз және алдыңғы оқылған моделдеріміз көпшілікті https://github.com/kakaobrain/kortok.', 'mt': 'Typically, tokenization is the very first step in most text processing works. Bħala token iservi bħala unit à atomika li tinkorpora l-informazzjoni kuntestwali tat-test, kif wieħed jiddefinixxi token għandu rwol deċiżiv fil-prestazzjoni ta’ mudell. Minkejja li l-Kodifikazzjoni tal-Paġni Byte (BPE) ġiet ikkunsidrata bħala l-metodu de facto standard ta’ tokenization minħabba s-sempliċit à u l-universalità tiegħu, għadu mhux ċar jekk il-BPE taħdimx bl-aħjar mod fil-lingwi u l-kompiti kollha. F\'dan id-dokument, nistestjaw diversi strateġiji ta\' tokenizzazzjoni sabiex twieġeb il-mistoqsija tar-riċerka primarja tagħna, jiġifieri, "X\'inhi l-aħjar strateġija ta\' tokenizzazzjoni għall-kompiti Koreani tal-NLP?" Riżultati esperimentali juru li approċċ ibridu tas-segmentazzjoni morfoloġika segwit mill-BPE jaħdem bl-a ħjar mod bil-Korean sa/minn kompiti ta’ traduzzjoni tal-magni bl-Ingliż u fehim tal-lingwa naturali bħall-KorNLI, KorSTS, NSMC, u PAWS-X. Bħala eċċezzjoni, għall-KorQuAD, l-estensjoni Korean a ta’ SQuAD, is-segmentazzjoni tal-BPE tidher li hija l-aktar effettiva. Our code and pre-trained models are publicly available at  https://github.com/kakaobrain/kortok.', 'ms': "Biasanya, tokenization adalah langkah pertama dalam kebanyakan proses teks berfungsi. Sebagai token berkhidmat sebagai unit atom yang memasukkan maklumat kontekstual teks, bagaimana menentukan token bermain peran yang menentukan dalam prestasi model. Walaupun Pengekodan Pasangan Byte (BPE) telah dianggap kaedah tokenisasi piawai de facto disebabkan kemudahan dan universaliti, ia masih tidak jelas sama ada BPE berfungsi terbaik dalam semua bahasa dan tugas. Dalam kertas ini, kami menguji beberapa strategi tokenization untuk menjawab soalan penyelidikan utama kami, iaitu, 'Apakah strategi tokenization terbaik untuk tugas NLP Korea?' Hasil percubaan menunjukkan bahawa pendekatan hibrid segmen morfologik diikuti oleh BPE berfungsi terbaik dalam bahasa Korea ke/dari mesin terjemahan bahasa Inggeris dan tugas pemahaman bahasa semulajadi seperti KorNLI, KorSTS, NSMC, dan PAWS-X. Sebagai pengecualian, untuk KorQuAD, sambungan Korea SQuAD, segmen BPE ternyata menjadi yang paling berkesan. Kod kami dan model terlatih terdapat di https://github.com/kakaobrain/kortok.", 'mn': 'Хэдийгээр тодорхойлолт бол ихэнх текст үйлдвэрлэлийн хамгийн анхны алхам юм. Тодорхойлолтой нь текстийн орчин үеийн мэдээллийг хэрхэн тодорхойлох нь загварын үйлдвэрлэлд шийдвэрлэх үүрэг юм. Byte Pair Encoding (BPE) нь энгийн болон универсал байдлын шалтгаан de facto стандарт тодорхойлолтын арга гэж үздэг ч, BPE нь бүх хэл болон үйл ажиллагаанд хамгийн сайн ажилладаг эсэхийг ойлгохгүй байна. Энэ цаасан дээр бид өөрсдийн анхны судалгааны асуултаас хариулт өгөхийн тулд олон тодорхойлолтын стратегийг шалгаж, "Солонгосын НLP ажлын хамгийн сайн тодорхойлолтын стратеги юу вэ?" Үүний туршилтын үр дүнд BPE-ын дараагийн морфологик загварын гибрид арга нь Солонгос болон Англи хэлний хөрөнгө болон байгалийн хэл ойлгох үйл ажиллагааны сайн ажилладаг. KorNLI, KorSTS, NSMC, PAWS-X зэрэг KorQuAD-ын хувьд Солонгос, BPE загварын нэмэлт нь хамгийн үр дүнтэй болно. Бидний код болон урьд сургалтын загварууд олон нийтэд https://github.com/kakaobrain/kortok.', 'pl': 'Zazwyczaj tokenizacja jest pierwszym krokiem w większości prac przetwarzania tekstu. Jako token służy jako jednostka atomowa osadzająca informacje kontekstowe tekstu, jak zdefiniować token odgrywa decydującą rolę w wydajności modelu. Chociaż kodowanie pary bytów (BPE) zostało uważane za de facto standardową metodę tokenizacji ze względu na swoją prostotę i uniwersalność, nadal nie jest jasne, czy BPE działa najlepiej we wszystkich językach i zadaniach. W niniejszym artykule testujemy kilka strategii tokenizacji, aby odpowiedzieć na nasze podstawowe pytanie badawcze, tj. "Jaka jest najlepsza strategia tokenizacji dla koreańskich zadań NLP?". Wyniki eksperymentalne pokazują, że hybrydowe podejście segmentacji morfologicznej, po którym następuje BPE, sprawdza się najlepiej w koreańskim do/z angielskiego tłumaczeniu maszynowym i rozumieniu języka naturalnego, takich jak KornLI, KorSTS, NSMC i PAWS-X. Jako wyjątek dla KorQuAD, koreańskie rozszerzenie SQuAD, segmentacja BPE okazuje się najbardziej skuteczna. Nasz kod i wstępnie przeszkolone modele są publicznie dostępne pod adresem: https://github.com/kakaobrain/kortok.', 'no': 'Normalt er tokenisering den første stegen i dei fleste tekstbehandlingane. Som eit teikn tjener som eit atomeining som innebærar kontekstinformasjonen om tekst, korleis å definera eit teikn spelar eit avgjørende rolle i utføringa av eit modell. Selv om byte-par-koding (BPE) er betre som de facto-standard tokenisasjonsmetoden på grunn av enkeltet og universalitet, er det fortsatt uventa om BPE fungerer best over alle språk og oppgåver. I denne papiret tester vi fleire tokenisasjonsstrategiar for å svara på vår primærforskningsspørsmål, som er: Kva er den beste tokenisasjonsstrategien for Koreanske NLP-oppgåver? Eksperimentale resultat viser at ein hybrid tilnærming av morfologiske segmentasjon etter BPE verkar best i Koreansk til/frå engelsk maskinsomsetjing og naturspråk forståking av oppgåver som KorNLI, KorSTS, NSMC og PAWS-X. Som unntak, for KorQuAD, vert koreansk utviding av SQuAD, BPE-segmentasjonen vist til å vera det mest effektive. Våre kode og avanserte modeller er offentlig tilgjengeleg på https://github.com/kakaobrain/kortok.', 'ro': 'De obicei, tokenizarea este primul pas în majoritatea lucrărilor de procesare a textului. Ca un token servește ca o unitate atomică care încorporează informațiile contextuale ale textului, modul de definire a unui token joacă un rol decisiv în performanța unui model. Chiar dacă Byte Pair Encoding (BPE) a fost considerată metoda standard de facto de tokenizare datorită simplității și universalității sale, rămâne neclar dacă BPE funcționează cel mai bine în toate limbile și sarcinile. În această lucrare, testăm mai multe strategii de tokenizare pentru a răspunde la întrebarea noastră primară de cercetare, și anume, "Care este cea mai bună strategie de tokenizare pentru sarcinile PNL coreene?" Rezultatele experimentale demonstrează că o abordare hibridă a segmentării morfologice urmată de BPE funcționează cel mai bine în traducerea automată coreeană în / din engleză și sarcini de înțelegere a limbii naturale, cum ar fi KorNLI, KorsTS, NSMC și PAWS-X. Ca o excepție, pentru KorQuAD, extensia coreeană a SQUAD, segmentarea BPE se dovedește a fi cea mai eficientă. Codul nostru și modelele pre-instruite sunt disponibile public la https://github.com/kakaobrain/kortok.', 'sr': 'Tipično, tokenizacija je prvi korak u većini tekstualnih radova. Kao znak služi kao atomska jedinica koja uključuje kontekstualne informacije o tekstu, kako definirati znak igra odluènu ulogu u provedbi model a. Iako je kodiranje Byte Pair (BPE) smatralo de facto standardnim metodom tokenizacije zbog jednostavnosti i univerzalnosti, još uvijek je neprihvatljivo da li BPE najbolje radi na svim jezicima i zadacima. U ovom papiru testiramo nekoliko tokenizacionih strategija kako bi odgovorili na naše prvo istraživanje pitanje, to je: "Koja je najbolja tokenizaciona strategija za korejske NLP zadatke?" Eksperimentalni rezultati pokazuju da hibridni pristup morfološkog segmentacije nakon toga BPE najbolje radi na Korejskom i/od prevoda engleskog mašine i prirodnog razumevanja zadataka poput KorNLI, KorSTS, NSMC i PAWS-X. Kao izuzetak, za KorQuAD, korejska produženja SQuAD, segmentacija BPE je najefikasnija. Naši kod i predobučeni modeli su javno dostupni u https://github.com/kakaobrain/kortok.', 'si': 'සාමාන්\u200dය විදියටම, ටොකෙනිසේෂණය තමයි වැඩි පාළුවේ ප්\u200dරධාන වැඩේ පළමු පැත්තේ. ටෝකෙන් විදිහට අටෝමික යුනිටියක් විදිහට සේවා කරන්නේ පාළුවන් සම්බන්ධ තොරතුරු සම්බන්ධ වෙන්න, ටෝකෙන් කොහොමද ප්\u200d බායිට් සම්පූර්ණ සංකේතනය (BPE) ක්\u200dරියාත්මක විදිහට හිතලා තියෙනවා නමුත් එයාගේ සාමාන්\u200dය සහ සාමාන්\u200dය භාෂාව සහ කාර්යාත්මක විදිහට, B මේ පත්තරේ අපි පරීක්ෂා කරනවා අපේ ප්\u200dරධාන පරීක්ෂණ ප්\u200dරශ්නයක් උත්තර දෙන්න, ඒක තමයි, "කෝරියානු NLP වැඩ කරන්න හොඳම තොක්න පරීක්ෂණාත්මක ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200dරතික්\u200dරියාත්මක විදිහට BPE වෙනුවෙන් කෝරියානුවෙන් ඉංග්\u200dරියානුවෙන් ඉංග්\u200dරියානුවෙන් ඉංග්\u200dරියාන අපේ කෝඩ් සහ ප්\u200dරධානය කරලා තියෙන ප්\u200dරමාණය සාමාන්\u200dයයෙන්ම ප්\u200dරවේශ කරන්න පුළුවන් https://github.com/kakaobrain/kortok.', 'so': "Sida caadiga ah caddeynta waa koowaad ee ugu horeeya shaqada baaraandegista qoraalka badan. Sida calaamad looga adeego sida qayb atomi ah oo ku qoran macluumaadka joogtada ah ee qoraalka, siduu calaamada u sawiraa qayb gaar ah oo ku saabsan sameynta model. Xataa in kastoo koowaad BPE (BPE) looga xisaabiyay qaababka calaamadda ee bandhigga ah sababtoo ah fududnimadiisa iyo jaamacadeeda, weli ma oga in BPE si fiican ugu shaqeeyo luuqadaha iyo shaqada oo dhan. Qoraalkan waxaan ku tijaabinaynaa qoraalo badan oo calaamad ah si aan ugu jawaabno su'aalkeenna asalka ah, waa maxay qoraalka ugu wanaagsan ee muujinta shaqada NLP ee Korea? Imtixaanka waxaa ka muuqda in xebrid approach of morphological segmentation followed by BPE wuxuu ka shaqeeyaa si wanaagsan Korean to/from Ingiriis machine translation and garashada afka naturada, tusaale ahaan KorNLI, KorSTS, NSMC, and PAWS-X. Sida kale, QuAD, koreanka sii-socoshada SQuAD, BPE segmentation waxay u muuqataa inay tahay mid ugu caqli badan. Qoidaheenna iyo modelalka horay loo tababaray waxay si bayaan ah u helaan https://github.com/kakaobrain/kortok.", 'sv': 'Typiskt är tokenisering det allra första steget i de flesta textbearbetningsarbeten. Som en token fungerar som en atomenhet som inbäddar textens kontextuella information, hur man definierar en token spelar en avgörande roll för prestandan av en modell. Även om Byte Pair Encoding (BPE) har ansetts vara de facto standardtokeniseringsmetoden på grund av dess enkelhet och universalitet, är det fortfarande oklart om BPE fungerar bäst på alla språk och uppgifter. I denna uppsats testar vi flera tokeniseringsstrategier för att besvara vår primära forskningsfråga, det vill säga "Vilken är den bästa tokeniseringsstrategin för koreanska NLP-uppgifter?" Experimentella resultat visar att en hybrid ansats av morfologisk segmentering följt av BPE fungerar bäst i koreanska till/från engelska maskinöversättning och naturliga språkförståelse uppgifter som KorNLI, KorsTS, NSMC och PAWS-X. Som ett undantag, för KorQuAD, den koreanska förlängningen av SQUAD, BPE segmentering visar sig vara den mest effektiva. Våra kod och förkunskaperade modeller är tillgängliga för allmänheten på https://github.com/kakaobrain/kortok.', 'ur': 'طبق طور پر، ٹوکنیزی اکثر ٹیکسٹ پرسس کے کاموں میں سب سے پہلی قدم ہے۔ ایک ٹوکین کے طور پر اتم یونیٹ کی طرح موجود ہوتا ہے جو متن کے متوسط معلومات کو پیدا کرتا ہے، ایک ٹوکین کی تعریف کس طرح ایک موڈل کی عملکرد میں ایک فیصلہ کرنے والا رول پڑتا ہے. اگرچہ بائیٹ جوڑ کی کوڈینگ (BPE) کو اس کی سادگی اور universality کے باعث دفعہ استاندارڈ ٹوکینیز طریقہ سے سمجھ لیا گیا ہے، یہ بھی نہیں جانتا کہ BPE ہر زبان اور دنیا میں بہترین عمل کرتا ہے. اس کاغذ میں ہم بہت سی ٹوکنیزی استراتژی کی آزمائش کرتے ہیں کہ ہمارے اولین تحقیق سوال کی جواب دیں، یعنی "کوریا کے NLP کاموں کے لئے بہترین ٹوکنیزی استراتژی کون ہے؟" Experimental results demonstrate that a hybrid approach of morphological segmentation followed by BPE works best in Korean to/from English machine translation and natural language understanding tasks such as KorNLI, KorSTS, NSMC, and PAWS-X. As an exception, for KorQuAD, the Korean extension of SQuAD, BPE segmentation turns out to be the most effective. ہمارے کڈ اور پہلے تربین کی مدل ظاہر طور پر موجود ہیں https://github.com/kakaobrain/kortok.', 'ta': 'பெரும்பாலான உரை செயல்படுத்தலில் குறிப்பிடுதல் முதல் படியாகும். ஒரு குறியீடு ஒரு அணு அலகாக சேவைக்கும் போது உரையின் தற்காலிக தகவலை உள்ளடக்கும், எப்படி ஒரு குறியீடு மாதிரியின் செயல்பாட்டில் decisive பங் பைட்டு பேர் குறியீடு (BPE) அதன் எளிதாக்கத்தின் மற்றும் உலகத்திற்கு காரணத்தாலும் காரணமாக நிலையான குறியீடு முறையாக கருதப்பட்டுள்ளதாலும், BPE அன இந்த காகிதத்தில், நாம் பல குறியீட்டு திட்டங்களை சோதிக்கிறோம், நமது முதல் ஆராய்ச்சி கேள்விக்கு பதில் கொடுக்க, அது "கொரிய NLP பண பரிசோதனை முடிவு எங்கள் குறியீடு மற்றும் முன் பயிற்சி மாதிரிகள் பொதுவாக கிடைக்கும் https://github.com/kakaobrain/kortok.', 'ml': 'സാധാരണ, ടെക്സ്റ്റ് പ്രവര്\u200dത്തിപ്പിക്കുന്നതില്\u200d ഏറ്റവും ആദ്യത്തെ പടിയാണ് പ്രവര്\u200dത്തിക്കുന്നത്. ടെക്സ്റ്റിന്റെ നിലവിലുള്ള വിവരങ്ങള്\u200d ഉള്\u200dപ്പെടുത്തുന്ന ആറ്റോമിക് യൂണിറ്റിയായി ഒരു അടയാളം ആയി സേവിക്കുന്നു ബൈറ്റ് പേയിര്\u200d എന്\u200dകോഡിങ്ങ് (ബിപെയി) അതിന്\u200dറെ സാധാരണ സ്ഥാനികമായ സ്ഥിതിയുടെയും പ്രവർത്തകത്തിന്\u200dറെയും കാരണം വിചാരിക്കപ്പെട്ടിരിക്കുന്നുവ ഈ പത്രത്തില്\u200d, നമ്മുടെ പ്രധാന പദ്ധതികള്\u200dക്ക് ഉത്തരം നല്\u200dകാന്\u200d വേണ്ടി നമ്മള്\u200d പല പ്രധാനപ്പെടുത്തിക്കൊണ്ടിരിക്കുന്ന പ്രധാനപരി പരീക്ഷിക്കുന്ന ഫലങ്ങള്\u200d കൊറിയയിലേക്ക്/ഇംഗ്ലീഷ് മെഷീന്\u200d പരിഭാഷകളിലേക്ക് മോര്\u200dഫോളജിക്കുന്നതിന്റെ പിന്നാലെ ബെപിയിലേക്ക് മെച്ചപ്പെട്ട ഒരു ഹൈബ്രിഡ് പ്രവര്\u200dത്തനം ചെയ്യുന്നു. കൊര്\u200dനില്\u200d, കോര്\u200dസ്റ്റ്\u200cസ്,  നമ്മുടെ കോഡും പരിശീലിക്കപ്പെട്ട മോഡലുകളും പ്രസിദ്ധമായി ലഭ്യമാണ് https://github.com/kakaobrain/kortok.', 'uz': 'Oddiy, tasdiqlash, ko\'pchilik matn boshqaruvchidagi birinchi qadam. Belgilar matnning daqiqa maʼlumotni qoʻyish uchun nuqta birikmasi sifatida ishlatiladi. Agar Byte Pair kodlash (BPE) oddiylik va universitetsiya sababchi asosabatlarning andoza to ʻgʻri toʻplami deb hisoblanadi, balki BPE hamma tillar va vazifalar bilan eng yaxshi ishlayapti deb o\'ylamaydi. Bu hujjatda biz bir necha tashkilotlar tashkilotlarimizga javob berish uchun ko\'plab tashkilotni sinash imkoniyatlarimiz. Bu: "Koriya NLP vazifalari uchun eng yaxshi ko\'paytirish strategiya nima?" Tajriba natijalari hozirgi ko\'rsatadi, BPE\'ning keyingi fofologik tarjima qilingan foydalanishini Koreya va ingliz tilidagi eng yaxshi narsa va aslida tilni o\'rganish vazifalari KorNLI, KorSTS, NSMC va PAWS-X kabi ishlarni ko\'rsatadi. Масалан, QuAD uchun Koreya kengaytmasi SQuAD uchun BPE параметри eng ishlaydi. Kodlash va o\'rganishdan oldin modellar https://github.com/kakaobrain/kortok.', 'vi': 'Như thường, tokeniation là bước đầu tiên trong phần lớn các công trình xử lý văn bản. Như một vật thể phục vụ như một đơn vị nguyên tử chứa các thông tin ngữ cảnh của văn bản, cách xác định biểu tượng là một vai trò quyết định trong việc phục vụ của mô hình. Mặc dù Bảng phân tích đường Byte đôi (BPE) đã được coi là phương pháp chuyển hóa tiêu chuẩn thực nhờ vào sự đơn giản và tính phổ thông, nó vẫn chưa rõ liệu BPE hoạt động tốt nhất trong mọi ngôn ngữ và nhiệm vụ. Trong bài báo này, chúng ta thử vài phương pháp trù tính để trả lời câu hỏi nghiên cứu chính của chúng ta, có nghĩa là "Chiến lược đồ vật tốt nhất cho việc lập quốc gia NLP là gì?" Kết quả thử nghiệm cho thấy một cách tiếp cận sinh lý theo sau của BPE hoạt động tốt nhất ở Hàn Quốc với dịch vụ máy tính và các công việc hiểu biết ngôn ngữ tự nhiên như KorLII, KorSTS, NSMC, và PAWS-X. Như một cách ngoại lệ, với KorQurAD, sự gia tăng Hàn Quốc của SCOAD, BPE phân chia cắt thành công hiệu quả nhất. The code và the pre-trained models are công khai at https://github.com/kakaobrain/kortok.', 'bg': 'Обикновено токенизацията е първата стъпка в повечето текстови обработки. Като символ служи като атомна единица, която вгражда контекстната информация на текста, как да се определи символ играе решаваща роля в изпълнението на даден модел. Въпреки че кодирането на байтови двойки (БПЕ) се счита за де факто стандартен метод за токенизация поради неговата простота и универсалност, все още не е ясно дали работи най-добре във всички езици и задачи. В тази статия тестваме няколко стратегии за токенизация, за да отговорим на основния ни изследователски въпрос, а именно: "Каква е най-добрата стратегия за токенизация за задачите на корейския НЛП?" Експерименталните резултати показват, че хибридният подход на морфологичната сегментация, следван от БПЕ, работи най-добре в корейски към/от английски машинен превод и задачи за разбиране на естествения език като Изключение за KorQuAD корейското разширение на СQuAD сегментацията се оказва най-ефективна. Нашият код и предварително обучени модели са публично достъпни на адрес: https://github.com/kakaobrain/kortok.', 'da': "Typisk er tokenisering det allerførste skridt i de fleste tekstbehandlingsarbejder. Som en token tjener som en atomenhed, der integrerer kontekstuelle oplysninger i tekst, spiller hvordan man definerer en token en afgørende rolle i udførelsen af en model. Selvom Byte Pair Encoding (BPE) er blevet betragtet som de facto standard tokenisering metode på grund af sin enkelhed og universalitet, er det stadig uklart, om BPE fungerer bedst på tværs af alle sprog og opgaver. I denne artikel tester vi flere tokeniseringsstrategier for at besvare vores primære forskningsspørgsmål, det vil sige, 'Hvad er den bedste tokeniseringsstrategi for koreanske NLP-opgaver?' Eksperimentelle resultater viser, at en hybrid tilgang til morfologisk segmentering efterfulgt af BPE fungerer bedst i koreansk til/fra engelsk maskinoversættelse og natursprogforståelse opgaver som KorNLI, KorsTS, NSMC og PAWS-X. Som en undtagelse, for KorQuAD, den koreanske udvidelse af SQUAD, BPE segmentering viser sig at være den mest effektive. Vores kode og prætrænede modeller er offentligt tilgængelige på https://github.com/kakaobrain/kortok.", 'nl': "Typisch is tokenisering de allereerste stap in de meeste tekstverwerkingswerken. Omdat een token dient als een atomaire eenheid die de contextuele informatie van tekst insluit, speelt hoe een token te definiëren een beslissende rol in de prestaties van een model. Hoewel Byte Pair Encoding (BPE) gezien de eenvoud en universaliteit de facto standaard tokenization methode is, blijft het nog onduidelijk of BPE het beste werkt in alle talen en taken. In dit artikel testen we verschillende tokeniseringsstrategieën om onze primaire onderzoeksvraag te beantwoorden, namelijk: 'Wat is de beste tokeniseringsstrategie voor Koreaanse NLP-taken?' Experimentele resultaten tonen aan dat een hybride benadering van morfologische segmentatie gevolgd door BPE het beste werkt in Koreaans naar/van Engelse machinevertaling en natuurlijke taal begrijpen taken zoals KornLI, KorSTS, NSMC en PAWS-X. Als uitzondering blijkt voor KorQuAD, de Koreaanse uitbreiding van SQuAD, BPE segmentatie de meest effectieve. Onze code en voorgetrainde modellen zijn openbaar beschikbaar op: https://github.com/kakaobrain/kortok.", 'hr': 'Tipično, tokenizacija je prvi korak u većini proizvodnje teksta. Kao znak služi kao atomska jedinica koja uključuje kontekstualne informacije o tekstu, kako definirati znak igra odlučnu ulogu u provedbi model a. Iako je Byte Pair Encoding (BPE) smatrao de facto standardnim metodom tokenizacije zbog jednostavnosti i univerzalnosti, još uvijek nije jasno da li BPE najbolje radi na svim jezicima i zadacima. U ovom papiru testiramo nekoliko tokenizacijskih strategija kako bi odgovorili na naše osnovno istraživanje, to je: "Koja je najbolja tokenizacijska strategija za korejske zadatke NLP?" Eksperimentalni rezultati pokazuju da hibridni pristup morfološkog segmentacije nakon toga BPE najbolje radi na Korejskom i/od prevoda engleskog strojeva i prirodnog razumijevanja zadataka poput KorNLI, KorSTS, NSMC i PAWS-X. Kao izuzetak, za KorQuAD, korejska produženja SQuAD, BPE segmentacija je najučinkovitija. Naši kod i predobučeni modeli su javno dostupni na https://github.com/kakaobrain/kortok.', 'de': 'Typischerweise ist die Tokenisierung der allererste Schritt in den meisten Textverarbeitungsarbeiten. Da ein Token als atomare Einheit dient, die die kontextuellen Informationen des Textes einbettet, spielt die Definition eines Tokens eine entscheidende Rolle für die Performance eines Modells. Obwohl Byte Pair Encoding (BPE) aufgrund ihrer Einfachheit und Universalität als de facto Standard-Tokenisierungsmethode angesehen wurde, bleibt unklar, ob BPE in allen Sprachen und Aufgaben am besten funktioniert. In diesem Beitrag testen wir verschiedene Tokenisierungsstrategien, um unsere primäre Forschungsfrage zu beantworten, nämlich: "Was ist die beste Tokenisierungsstrategie für koreanische NLP-Aufgaben?" Experimentelle Ergebnisse zeigen, dass ein hybrider Ansatz der morphologischen Segmentierung gefolgt von BPE am besten für maschinelle Übersetzungen in/von Englisch und natürliche Sprachverständnisaufgaben wie KornLI, KorSTS, NSMC und PAWS-X funktioniert. Unser Code und vortrainierte Modelle sind öffentlich verfügbar unter https://github.com/kakaobrain/kortok.', 'ko': '일반적으로 태그화는 대부분의 텍스트 처리 작업의 첫걸음이다.텍스트 상하문 정보를 삽입하는 원자 단원으로서 영패의 정의는 모델의 성능에 결정적인 역할을 한다.바이트 인코딩 (BPE) 은 단순성과 유니버설성 때문에 사실상 표준 표기화 방법으로 여겨지지만, 모든 언어와 작업에서 BPE가 가장 잘 작동하는지 알 수 없다."이 논문에서 우리가 테스트해야 할 주요 표기화 전략은 무엇입니까?"실험 결과 한국어부터/영어 기계 번역과 자연 언어 이해 임무(예를 들어 KorNLI, KorSTS, NSMC와 PAWS-X) 중 형태학적 분할과 BPE가 결합된 혼합 방법이 가장 효과가 좋다. 예외적으로 KorQuad, 즉 한국반의 확장에 BPE 분할이 가장 효과적이다.우리의 코드와 사전 교육 모델은https://github.com/kakaobrain/kortok.', 'sw': "Typically, tokenization is the very first step in most text processing works.  Kama alama inayotumika kama kituo cha atomu kinachoingiza taarifa za maandishi, jinsi ya kuelezea alama inavyofanya jukumu la muhimu katika utendaji wa modeli. Hata kama Ujumbe wa Ujumbe wa BPE (BPE) umechukuliwa kama mbinu ya kuonyesha ukweli kwa sababu ya urahisi na ulimwengu wake, bado haijajulikana kama BPE inafanya kazi bora zaidi katika lugha na kazi zote. In this paper, we test several tokenization strategies in order to answer our primary research question, that is, 'What is the best tokenization strategy for Korean NLP tasks?'  Matokeo ya majaribio yanaonyesha kuwa mbinu za usambazaji wa kimaadili zinazofuatiwa na BPE zinafanya kazi nzuri zaidi nchini Korea hadi/kutoka katika tafsiri ya mashine ya Kiingereza na ufahamu wa lugha asili kama vile KorNLI, KorSTS, NSMC, na PAWS-X. Kama tofauti, Uongezeko wa SQuAD wa Korea, kutangazwa kwa chama cha BPE kinaonekana kuwa na ufanisi mkubwa zaidi. Kodi zetu na mifano ya zamani yanapatikana kwa umma https://github.com/kakaobrain/kortok.", 'fa': 'معمولاً شناسایی اولین قدم در بیشتر کارهای پرداخت متن است. به عنوان یک علامت به عنوان یک واحد اتمی که اطلاعات موضوع متن را وارد می\u200cکند، چگونه تعریف یک علامت نقش تصمیم\u200cگیری در انجام یک مدل بازی می\u200cکند. با وجود اینکه رمزبندی بایت pair (BPE) روش استاندارد توکین (de facto standard tokenization) به دلیل ساده و جهانی اش به نظر گرفته می\u200cشود، هنوز معلوم نیست که آیا BPE در تمام زبانها و وظیفه\u200cها بهتر کار می\u200cکند. در این کاغذ، ما چندین استراتژی توکینیک را برای پاسخ دادن سوال تحقیقات اصلی ما آزمایش می کنیم، یعنی: بهترین استراتژی توکینیک برای کارهای NLP کره چیست؟ نتیجه\u200cهای تجربه نشان می\u200cدهد که یک روش hybrid از بخش\u200cهای مورفیک پیروی از BPE بهتر در ترجمه\u200cهای ماشین\u200cهای انگلیسی به/از زبان\u200cهای طبیعی مانند KorNLI، KorSTS, NSMC و PAWS-X کار می\u200cکند. به عنوان استثنایی، برای KorQuAD، تقسیم کوریه\u200cای SQuAD، بخش\u200cهای BPE به طور موثرترین می\u200cشود. کد و مدل های پیش آموزش ما به طور عمومی در https://github.com/kakaobrain/kortok.', 'tr': 'Adatça, metin işlemekde ilkinji adım. Bir token bolsa, metin senediň maglumatyny içine sokan atom bir vienaty hökmünde, bir token nähili takyklamak üçin modyň başarylygynda çözümli roli çalýar. BPE Bu kagyzda, biz esasy araşdyrma soragymyza jogap bermek üçin birnäçe tokenizat stratejiýalaryny barýarys. Şu ýagdaýda "Koreýa NLP zady üçin iň gowy tokenizat stratejiýasy näme? Experimental netijesi bPE tarapyndan gelen morfolojik segmentasiýanyň hibrid ýazşynyň koreýan a/iňlisçe maşynyň terjimesinden gowy işleýändigini görkez. KorNLI, KorSTS, NSMC, we PAWS Biziň ködlerimiz we öňünden öňünden gelen nusgalarymyz publika içinde bar. https://github.com/kakaobrain/kortok.', 'af': "Tipe, tokenisasie is die eerste stap in die meeste teks verwerk. As 'n teken dien as 'n atomiese eenheid wat die kontekslike inligting van teks inbêer, hoe om 'n teken te definieer speel 'n besluitbare rol in die prestasie van 'n model. Alhoewel Byte Pair Enkodering (BPE) is beskou as die de facto standaard tokenisasie metode vanweë sy eenvoudigheid en universealiteit, bly dit nog onbekende of BPE beste werk oor alle tale en taak. In hierdie papier, is ons verskeie tokenisasie strategies toets om ons primêre ondersoek vraag te antwoord, dit is: Wat is die beste tokenisasie strategie vir Koreaanse NLP-opdragte? Eksperimentele resultate wys dat 'n hibride toegang van morfologiese segmentasie volg deur BPE die beste werk in Koreaanse na/van Engelse masjien vertaling en natuurlike taal verstaan opdragte soos KorNLI, KorSTS, NSMC, en PAWS-X. As 'n uitsondering, vir KorQuAD, die Koreaanse uitbreiding van SQuAD, BPE segmentasie draai uit om die mees effektief te wees. Ons kode en voorafgeleerde modele is openlik beskikbaar by https://github.com/kakaobrain/kortok.", 'id': "Biasanya, tokenisasi adalah langkah pertama dalam kebanyakan proses teks bekerja. As a token serves as an atomic unit that embeds the contextual information of text, how to define a token plays a decisive role in the performance of a model.  Even though Byte Pair Encoding (BPE) has been considered the de facto standard tokenization method due to its simplicity and universality, it still remains unclear whether BPE works best across all languages and tasks.  In this paper, we test several tokenization strategies in order to answer our primary research question, that is, 'What is the best tokenization strategy for Korean NLP tasks?'  Hasil eksperimen menunjukkan bahwa pendekatan hibrid dari segmentasi morfologi diikuti oleh BPE bekerja terbaik dalam bahasa Korea ke/dari tradukasi mesin Inggris dan tugas pemahaman bahasa alami seperti KorNLI, KorSTS, NSMC, dan PAWS-X. Sebagai pengecualian, untuk KorQuAD, ekstensi Korea SQuAD, segmentasi BPE ternyata paling efektif. Our code and pre-trained models are publicly available at  https://github.com/kakaobrain/kortok.", 'am': 'በተለመደው፣ ማስታወቂያው በብዙ ጽሑፍ ማቀናቀል የመጀመሪያ ደረጃ ነው፡፡ ምልክቱ የጽሑፉን መረጃ እንደሚያሳየው አካባቢ ክፍል እንደሚገልጽ፣ ምልክት በሞዴል ማሳየት እንዴት እንደሚያሳውቅ የፍርድ ክፍል ይጫወታል፡፡ ቢይት ፓይር የፊርድ ኮድ (BPE) ምንም እንኳ የውጤቱ አካባቢነት እና የባሕላዊነት አካባቢነት የተደረገው የአካባቢው ማቀናቀል ቢሆን እንኳ BPE በቋንቋ እና ስራዎችን ሁሉ በላጭ ቢሠራ ምንም አይታወቅም፡፡ በዚህ ፕሮግራም፣ የመጀመሪያውን ምርመራ ጥያቄን ለመመልስ ብዙዎችን ማስታወቂያ strategy እንሞክራለን፡፡ ፈተና ፍጻሜዎች የቆሬኒያ፣ ኮርስቴስ፣ NSMC እና PAWS-X፣ ለቆሬና የSquaAD ስፋት፣ BPE መግለጫ የበለጠ እና የኢንግሊዝኛ ቋንቋ ትርጓሜ እና የፍጥረተ ቋንቋ ማስተዋል ስራዎችን እንደሚሠራ ያሳያል፡፡ ቀድሞቻችን የፊተማሩ ሞዴሎቻችን በህዝብ የተገኙ ናቸው፡፡ https://github.com/kakaobrain/kortok.', 'az': "Tipik olaraq, tokenizasyon mətn işləməsinin ən çox ilk adımdır. Bir möcüzə kimi mətn məlumatının müxtəlif məlumatını daxil edən atom birimi olaraq, bir möcüzə növbəsini tanımlamaq model in in təqdirdə kararlı rol oynayır. Byte Pair Encoding (BPE) sadiqliyinə və universalətinə görə de facto standart tokenizasyon metodlarına baxmayaraq, BPE bütün dillərdə və işlərdə ən yaxşı işlədiyini bilmir. Bu kağızda, biz bir neçə tokenizasyon stratejisini sınayırıq, ilk araştırma sualarımıza cavab vermək üçün: Koreya NLP işlərinin ən yaxşı tokenizasyon stratejisi nədir? Experimental sonuçları, BPE'nin ardınca gələn morfolojik segmentasiyasının hibrid yolu Koreyadan/İngilizə maşın çevirilməsindən və doğal dillərin anlama işlərinin KorNLI, KorSTS, NSMC və PAWS-X kimi daha yaxşı işləyir. Bizim kodumuz və əvvəl təhsil edilmiş modellərimiz açıq-aşkar mövcuddur. https://github.com/kakaobrain/kortok.", 'bn': 'সাধারণত, টেক্সট প্রক্রিয়ার প্রথম পদক্ষেপ। একটি চিহ্ন হিসেবে একটি পারমাণবিক ইউনিট হিসেবে সার্ভিস করা হয় যা টেক্সটের স্থানীয় তথ্য প্রবেশ করে, কিভাবে একটি চিহ্ন নির্ধারণ করা হবে একটি মড যদিও বাইটপেয়ার এনকোডিং (বিপেকে) বিভিন্ন বিষয়ে বিবেচনা করা হয়েছে যে তথ্য স্বাভাবিক এবং বিশ্ববিদ্যালয়ের কারণে স্বাভাবিকতা এবং প্রতিষ্ঠানের কারণ এই প্রধান গবেষণার প্রশ্নের উত্তর দেয়ার জন্য আমরা বেশ কিছু চিহ্নিত কৌশল পরীক্ষা করি যাতে আমরা আমাদের প্রাথমিক গবেষণা প্রশ্নের উত্তর দেই, য পরীক্ষার ফলাফল দেখাচ্ছে যে বিপের পরে মোরফোলিক্যাল বৈচিত্র্যের একটি প্রযুক্তি কাজ করে কোরিয়া থেকে /থেকে ইংরেজি মেশিন অনুবাদ এবং প্রাকৃতিক ভাষা বুঝতে পারে যেমন কোরিয়ার বিস্তারিত কোরিয়ার বিস্তারিত বিপের ব আমাদের কোড এবং পূর্ব প্রশিক্ষিত মডেল প্রকাশ্যে পাওয়া যাচ্ছে https://github.com/kakaobrain/kortok.', 'bs': 'Tipično, tokenizacija je prvi korak u većini tekstualnih radova. Kao znak služi kao atomska jedinica koja uključuje kontekstualne informacije o tekstu, kako definirati znak igra odlučnu ulogu u provedbi model a. Iako je Byte Pair Encoding (BPE) smatrao de facto standardnim metodom tokenizacije zbog njegove jednostavnosti i univerzalnosti, još uvijek nije jasno da li BPE najbolje radi na svim jezicima i zadacima. U ovom papiru testiramo nekoliko tokenizacijskih strategija kako bi odgovorili na naše prvo istraživanje pitanje, to je: "Koja je najbolja tokenizacijska strategija za korejske NLP zadatke?" Eksperimentalni rezultati pokazuju da hibridni pristup morfološkog segmentacije nakon toga BPE najbolje radi na korejskom i/od prevoda engleskog mašine i prirodnog razumijevanja zadataka poput KorNLI, KorSTS, NSMC i PAWS-X. Kao izuzetak, za KorQuAD, korejska produženja SQuAD, segmentacija BPE je najefikasnija. Naši kod i predobučeni modeli su javno dostupni u https://github.com/kakaobrain/kortok.', 'ca': 'Normalment, la fitogenització és el primer pas en la majoria de treballs de processament de text. Com a fitxa serveix com una unitat atòmica que incorpora la informació contextual del text, com definir una fitxa juga un paper decisiu en el desempeny d\'un model. Encara que la codificació de parell de bytes (BPE) ha estat considerada el mètode de tecenització standard de fet per la seva simplicitat i universalitat, encara no és clar si la BPE funciona millor en totes les llengües i tasques. En aquest paper, testem diverses estratègies de tecnicització per respondre a la nostra pregunta primària de recerca, és a dir, "Quina és la millor estratègia de tecnicització per a les tasques de NLP coreanes?" Els resultats experimentals demostren que un enfocament híbrid de segmentació morfològica seguit de BPE funciona millor en coreana fins a/des de la traducció de màquina anglesa i de tasques de comprensió natural de llenguatge com KorNLI, KorSTS, NSMC i PAWS-X. Com a excepció, per KorQuAD, la extensió coreana de SQuAD, la segmentació BPE resulta ser la més efectiva. El nostre codi i els models pré-entrenats estan a disposició pública en https://github.com/kakaobrain/kortok.', 'cs': 'Obvykle je tokenizace úplně prvním krokem ve většině práce na zpracování textu. Jako token slouží jako atomová jednotka, která vloží kontextové informace textu, jak definovat token hraje rozhodující roli ve výkonu modelu. I když byte Pair Encoding (BPE) bylo kvůli své jednoduchosti a univerzálnosti považováno za de facto standardní tokenizační metodu, stále není jasné, zda BPE funguje nejlépe ve všech jazycích a úkolech. V tomto článku testujeme několik tokenizačních strategií, abychom odpověděli na naši primární výzkumnou otázku, "Jaká je nejlepší tokenizační strategie pro korejské NLP úkoly?" Experimentální výsledky ukazují, že hybridní přístup morfologické segmentace následující BPE funguje nejlépe v korejštině do/z angličtiny strojového překladu a porozumění přirozeným jazykům, jako jsou KornLI, KorSTS, NSMC a PAWS-X. Náš kód a předškolené modely jsou veřejně dostupné na adrese: https://github.com/kakaobrain/kortok.', 'et': 'Tavaliselt on tokeniseerimine kõige esimene samm enamikus tekstitöötluses. Kui märk toimib aatomüksusena, mis sisaldab teksti kontekstiteavet, mängib märgi defineerimine otsustavat rolli mudeli jõudluses. Kuigi baidipaari kodeerimist (BPE) peetakse de facto standardseks tokeniseerimismeetodiks selle lihtsuse ja universaalsuse tõttu, on endiselt ebaselge, kas BPE töötab kõigis keeltes ja ülesannetes kõige paremini. Selles töös testime mitmeid tokeniseerimisstrateegiaid, et vastata meie peamisele uurimisküsimusele, milleks on "Milline on Korea NLP ülesannete jaoks parim tokeniseerimisstrateegia?" Eksperimentaalsed tulemused näitavad, et hübriidne lähenemisviis morfoloogilisele segmenteerimisele, millele järgneb BPE, toimib kõige paremini korea keele masintõlke ja inglise keele mõistmise ülesannetes nagu KorNLI, KorSTS, NSMC ja PAWS-X. Erandina osutub KorQuAD korea laiendus BPE segmenteerimine kõige tõhusamaks. Meie kood ja eelkoolitud mudelid on avalikult kättesaadavad aadressil https://github.com/kakaobrain/kortok.', 'fi': 'Tyypillisesti tokenisointi on ensimmäinen askel useimmissa tekstinkäsittelytöissä. Merkkinä toimii atomiyksikkönä, joka upottaa tekstin kontekstitiedon, ja sen määrittelyllä on ratkaiseva rooli mallin suorituskyvyssä. Vaikka Byte Pair Encoding (BPE) on pidetty de facto standardina tokenisaatiomenetelmänä sen yksinkertaisuuden ja yleismaailmallisuuden vuoksi, on edelleen epäselvää, toimiiko BPE parhaiten kaikilla kielillä ja tehtävissä. Tässä artikkelissa testaamme useita tokenisaatiostrategioita vastataksemme ensisijaiseen tutkimuskysymykseemme, "Mikä on paras tokenisaatiostrategia Korean NLP-tehtäviin?" Kokeelliset tulokset osoittavat, että morfologisen segmentoinnin hybridiajattelu, jota seuraa BPE, toimii parhaiten koreasta englannin konekäännökseen ja luonnollisen kielen ymmärtämiseen liittyvissä tehtävissä, kuten KorNLI, KorSTS, NSMC ja PAWS-X. KorQuAD:n korealainen laajennus, BPE-segmentointi osoittautuu tehokkaimmaksi. Koodimme ja esikoulutetut mallit ovat julkisesti saatavilla osoitteessa https://github.com/kakaobrain/kortok.', 'hy': "Typically, tokenization is the very first step in most text processing works.  As a token serves as an atomic unit that embeds the contextual information of text, how to define a token plays a decisive role in the performance of a model.  Even though Byte Pair Encoding (BPE) has been considered the de facto standard tokenization method due to its simplicity and universality, it still remains unclear whether BPE works best across all languages and tasks.  In this paper, we test several tokenization strategies in order to answer our primary research question, that is, 'What is the best tokenization strategy for Korean NLP tasks?'  Experimental results demonstrate that a hybrid approach of morphological segmentation followed by BPE works best in Korean to/from English machine translation and natural language understanding tasks such as KorNLI, KorSTS, NSMC, and PAWS-X. As an exception, for KorQuAD, the Korean extension of SQuAD, BPE segmentation turns out to be the most effective.  Our code and pre-trained models are publicly available at  https://github.com/kakaobrain/kortok.", 'sq': "Typically, tokenization is the very first step in most text processing works.  As a token serves as an atomic unit that embeds the contextual information of text, how to define a token plays a decisive role in the performance of a model.  Even though Byte Pair Encoding (BPE) has been considered the de facto standard tokenization method due to its simplicity and universality, it still remains unclear whether BPE works best across all languages and tasks.  In this paper, we test several tokenization strategies in order to answer our primary research question, that is, 'What is the best tokenization strategy for Korean NLP tasks?'  Rezultatet eksperimentale demonstrojnë se një qasje hibride e segmentimit morfologjik pasuar nga BPE punon më mirë në korean për/nga përkthimi i makinave angleze dhe detyrat e kuptimit natyror të gjuhës si KorNLI, KorSTS, NSMC dhe PAWS-X. Si përjashtim, për KorQuAD, zgjerimi korean i SQuAD, segmentimi BPE duket të jetë më efektiv. Our code and pre-trained models are publicly available at  https://github.com/kakaobrain/kortok.", 'jv': 'Tokenizer Tulung sampeyan ing kotak Atomik sing ngetoken dumaten informasi contextual de teks, piye cara nggawe token kuwi wis kelompok barang nggawe model politenessoffpolite"), and when there is a change ("assertivepoliteness Nang paper iki, awak dhéwé éntuk sistem sing gak tokenisé sampeyan kanggo ngomong sapa perusahaan ingkang sampeyan, sing uwis \'Sing sampeyan tokenisé sing luwih apik kanggo nggawe operasi NLP Korea?\' Refirming Punika dipoleh lan model sing dibutuhke ditambah akeh Publik https://github.com/kakaobrain/kortok.', 'sk': 'Običajno je žetonizacija prvi korak v večini del obdelave besedila. Kot žeton služi kot atomska enota, ki vključuje kontekstualne informacije besedila, ima kako definirati žeton odločilno vlogo pri izvedbi modela. Čeprav se BPE zaradi svoje enostavnosti in univerzalnosti šteje za dejansko standardno metodo žetonizacije, še vedno ni jasno, ali BPE deluje najbolje v vseh jezikih in nalogah. V tem prispevku preizkusimo več strategij žetonizacije, da bi odgovorili na naše primarno raziskovalno vprašanje, to je: "Katera je najboljša strategija žetonizacije za naloge korejskega NLP?" Eksperimentalni rezultati kažejo, da hibridni pristop morfološke segmentacije, ki mu sledi BPE, deluje najbolje pri korejskem strojnem prevajanju v angleščino in razumevanju naravnega jezika, kot so KorNLI, KorSTS, NSMC in PAWS-X. Izjemoma se za KorQuAD izkaže, da je korejska razširitev SQuAD segmentacija BPE najučinkovitejša. Naša koda in vnaprej usposobljeni modeli so javno dostopni na spletni strani https://github.com/kakaobrain/kortok.', 'bo': 'རྒྱུན་ལྡན་གྱིས་བྱ་རིམ་དེ་ཚིག་ཡིག་གི་ལས་སྦྱོར་རྩོམ་མཁན་ཆེ་ཤོས་ཐོག་མའི་གྲལ་རིམ As a token serves as an atomic unit that embeds the contextual information of text, how to define a token plays a decisive role in the performance of a model. Byte Pair Encoding ཤོག་བྱང་འདིའི་ནང་གི་ལྟ་བུའི་ནང་དུ་ང་ཚོས་རྩ་བའི་འཚོལ་ཞིབ་ཀྱི་ཐབས་ལམ་མང་པོ་ཞིག་ལ་བརྟག་ཞིབ་བྱེད་ཀྱི་ཡོད། Experimental results demonstrate that a hybrid approach of morphological segmentation followed by BPE works best in Korean to/from English machine translation and natural language understanding tasks such as KorNLI, KorSTS, NSMC, and PAWS-X. As an exception, for KorQuAD, the Korean extension of SQuAD, BPE segmentation turns out to be the most effective. ང་ཚོའི་སྔོན་གྲངས་ཀྱི་ཨང་དང་སྔོན་གྲངས་བསྒྲིག་པའི་མིག་དཔེ་གཟུགས་རིས་མང་ཆོས་ཡོད་པ་ནི་ https://github.com/kakaobrain/kortok.', 'ha': 'A ɗabi\'a, alama ta zama na farkon kwanza cikin masu aiki na matsayi. As a cikin wata alama, za\'a yi amfani da kamar wani atomic unit wanda ke ƙunsa da maɓallin yanzu na matsayin, yadda a bayyana wata alama zai nuna wani roli mai damu a cikin aikin wani misali. Haƙĩƙa, kuma kõ da an ƙaddara kodi na Bayte Pair (BPA) ko kuma an ƙayyade metoden bangon ayuka na daidaita ko kuma universaliti, sai ba ta kasa ba idan BPA ke aiki mafi kyaun duk harshe da aikin aiki. Ga wannan takarda, Munã jarraba ko da takwai masu haske ko dõmin su karɓa wa tambayar mu na farko, "Mẽne ne mafi kyaun taskõki ga aikin NLP na Korea?" Mataimakin jarrabãwa sun nuna cewa a Hybri way of morfological segment followed by BLE works best in Korea to/from English mashine translation and natural hankalin harshen hankalin su kamar KorNLI, KorstanS, NSMC, da PAWS-X. As an buga, ko QuAD, faɗin SQuAD, an ƙara BLE segmentation ya kasa mafi fasahan aiki. Kodĩniyarmu da misalin da aka riga-wa\'anar da https://github.com/kakaobrain/kortok.', 'he': "Typically, tokenization is the very first step in most text processing works.  As a token serves as an atomic unit that embeds the contextual information of text, how to define a token plays a decisive role in the performance of a model.  Even though Byte Pair Encoding (BPE) has been considered the de facto standard tokenization method due to its simplicity and universality, it still remains unclear whether BPE works best across all languages and tasks.  In this paper, we test several tokenization strategies in order to answer our primary research question, that is, 'What is the best tokenization strategy for Korean NLP tasks?'  תוצאות ניסיוניות מראות שגישה היברידית של התחלוקת מורפולוגית, בעקבות BPE, עובדת הכי טוב בקוריאנית לאנגלית לתרגום מכונות ומשימות הבנה של שפת טבעית כמו KorNLI, KorSTS, NSMC, ופאוס-X. כמיוחד, עבור KorQuAD, ההארכה הקוריאנית של SQuAD, התחלוקת BPE מתברר להיות הכי יעילה. Our code and pre-trained models are publicly available at  https://github.com/kakaobrain/kortok."}
{'en': 'Named Entity Recognition in Multi-level Contexts', 'ar': 'التعرف على الكيانات المسماة في سياقات متعددة المستويات', 'pt': 'Reconhecimento de entidade nomeada em contextos multinível', 'fr': "Reconnaissance d'entités nommées dans des contextes multiniveaux", 'es': 'Reconocimiento de entidades con nombre en contextos de varios niveles', 'ja': 'マルチレベルコンテキストでの名前付きエンティティ認識', 'ru': 'Распознавание именованных сущностей в многоуровневых контекстах', 'hi': 'बहु-स्तरीय प्रसंगों में नामित निकाय पहचान', 'zh': '多上下文中名实体识', 'ga': 'Aitheantas Aonán Ainmnithe i gComhthéacsanna Il-leibhéil', 'hu': 'Megnevezett szervezetek elismerése többszintű kontextusokban', 'ka': 'მრავალური კონტექსტებში სახელი ინტერტის მიღება', 'el': 'Αναγνώριση ονομαστικής οντότητας σε πολυεπίπεδα πλαίσια', 'mk': 'Признавање на именуван ентитет во контекст на повеќе нивоа', 'kk': 'Көп деңгейіндегі контекстерде аталған нысанды анықтау', 'it': 'Riconoscimento delle entità denominate in contesti multilivello', 'lt': 'Pavadintojo subjekto pripažinimas daugiapakopiais kontekstais', 'ms': 'Pengenalan Entiti bernama dalam Konteks Berberapa Aras', 'ml': 'Multi- level Contexts', 'mt': 'Rikonoxximent ta’ Entità Ismija f’Kuntest Multi-Livelli', 'ro': 'Recunoașterea entității denumite în contexte pe mai multe niveluri', 'mn': 'Олон түвшинд нэрлэгдсэн Entity Recognition', 'sr': 'Prepoznavanje imenovanih podataka u kontekstima višerazina', 'no': 'Namnet element- gjenkjenning i fleirnivåkontekstar', 'pl': 'Rozpoznawanie nazwanych podmiotów w kontekstach wielopoziomowych', 'sv': 'Namngivn enhetsredovisning i flernivåsammanhang', 'si': 'ගොඩක් ස්තූතිය සම්බන්ධතාවයේ නම් තියෙන අන්තිම අඳුරණය', 'so': 'Aqoonsashada ganacsiga ee lagu magacaabay waxyaabaha aad leedahay', 'ta': 'பல- மட்டத்தில் உள்ளடக்கங்களில் பெயரிடப்பட்ட பொருள் அடையாளம்', 'ur': 'Multi-level Contexts میں نام دار اینٹی پکارنے', 'uz': 'Taò¥rifi', 'vi': 'Tênd Entity recognition in multicấp tương ứng', 'hr': 'Prepoznavanje imenovanih podataka u kontekstima višerazina', 'da': 'Anerkendelse af navngivne enheder i flere niveauer', 'bg': 'Разпознаване на наименовани субекти в контексти на няколко нива', 'nl': 'Erkenning van naamloze entiteiten in context op meerdere niveaus', 'de': 'Erkennung benannter Entitäten in mehrstufigen Kontexten', 'id': 'Pengenalan Entitas bernama dalam Konteks Multi-Level', 'ko': '다중 상하문에서의 명명 실체 식별', 'fa': 'شناسایی واحد نامیده در محیط\u200cهای متعدد سطح', 'tr': '_Mazmunlar', 'sw': 'Tambulisho la Ujumbe la Jina katika Mitandao ya Kiwango', 'sq': 'Njohja e njësisë së emëruar në kontekste shumë niveli', 'af': 'Genaamde Eenheidherkening in veelvuldige vlak Konteks', 'am': 'የአሁኑን ፋይል አስቀምጥ', 'bn': 'বহুস্তরের বিষয়বস্তুতে নামের প্রতিনিধি পরিচিতি', 'hy': 'Մարդկանց անվանված ճանաչելը բազմամամակարդակի կոնտեքստներում', 'az': '√áoxlu s…ôviyy…ô m…ôlumatlarda Adlƒ± Entity Recognition', 'bs': 'Prepoznavanje imenovanih podataka u kontekstima višerazina', 'ca': "Recognició d'Entitats Nomada en Contexts Multinivells", 'cs': 'Rozpoznávání pojmenovaných entit ve víceúrovňových kontextech', 'et': 'Nimetatud olemi tunnustamine mitmetasandilistes kontekstides', 'fi': 'Nimettyjen yhteisöjen tunnistaminen monitasoisissa yhteyksissä', 'ha': 'KCharselect unicode block name', 'jv': 'Jenengan Entire Atengan', 'he': 'זיהוי איכות בשם בתקשרים רבים רמה', 'sk': 'Prepoznavanje imenovanega subjekta v večstopenjskih kontekstih', 'bo': 'མིང་བསྐྱར་ཡོད་པའི་རྣམ་གྲངས་ཀྱི་སྣང་བ་རྟོགས་ཤེས་པ'}
{'en': 'Named entity recognition is a critical task in the  natural language processing field . Most existing  methods  for this  task  can only exploit  contextual information  within a sentence. However, their performance on recognizing entities in limited or ambiguous sentence-level contexts is usually unsatisfactory. Fortunately, other sentences in the same document can provide supplementary document-level contexts to help recognize these entities. In addition, words themselves contain word-level contextual information since they usually have different preferences of entity type and relative position from named entities. In this paper, we propose a unified framework to incorporate  multi-level contexts  for  named entity recognition . We use TagLM as our basic  model  to capture sentence-level contexts. To incorporate document-level contexts, we propose to capture interactions between sentences via a multi-head self attention network. To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference. We jointly train our model in entity recognition and the auxiliary classification task via  multi-task learning . The experimental results on several  benchmark datasets  validate the effectiveness of our  method .', 'ar': 'يعد التعرف على الكيان المحدد مهمة حاسمة في مجال معالجة اللغة الطبيعية. معظم الأساليب الموجودة لهذه المهمة يمكنها فقط استغلال المعلومات السياقية داخل الجملة. ومع ذلك ، فإن أداؤهم في التعرف على الكيانات في سياقات محدودة أو غامضة على مستوى الجملة عادة ما يكون غير مرضٍ. لحسن الحظ ، يمكن أن توفر الجمل الأخرى في نفس المستند سياقات تكميلية على مستوى المستند للمساعدة في التعرف على هذه الكيانات. بالإضافة إلى ذلك ، تحتوي الكلمات نفسها على معلومات سياقية على مستوى الكلمات نظرًا لأنها عادةً ما تحتوي على تفضيلات مختلفة لنوع الكيان والموقع النسبي من الكيانات المسماة. في هذه الورقة ، نقترح إطارًا موحدًا لدمج سياقات متعددة المستويات للتعرف على الكيانات المسماة. نحن نستخدم TagLM كنموذج أساسي لدينا لالتقاط سياقات على مستوى الجملة. لدمج السياقات على مستوى المستند ، نقترح التقاط التفاعلات بين الجمل عبر شبكة الاهتمام الذاتي متعددة الرؤوس. لتعدين سياقات مستوى الكلمة ، نقترح مهمة مساعدة للتنبؤ بنوع كل كلمة لالتقاط تفضيل النوع الخاص بها. نقوم بشكل مشترك بتدريب نموذجنا في التعرف على الكيانات ومهمة التصنيف المساعدة عبر التعلم متعدد المهام. تؤكد النتائج التجريبية على العديد من مجموعات البيانات المعيارية فعالية طريقتنا.', 'es': 'El reconocimiento de entidades nombradas es una tarea fundamental en el campo del procesamiento del lenguaje natural. La mayoría de los métodos existentes para esta tarea solo pueden aprovechar la información contextual dentro de una oración. Sin embargo, su desempeño en el reconocimiento de entidades en contextos limitados o ambiguos a nivel de oración suele ser insatisfactorio. Afortunadamente, otras oraciones del mismo documento pueden proporcionar contextos complementarios a nivel de documento para ayudar a reconocer estas entidades. Además, las propias palabras contienen información contextual a nivel de palabra, ya que normalmente tienen preferencias diferentes de tipo de entidad y posición relativa de las entidades nombradas. En este artículo, proponemos un marco unificado para incorporar contextos multinivel para el reconocimiento de entidades nombradas. Utilizamos TagLM como nuestro modelo básico para capturar contextos a nivel de oración. Para incorporar contextos a nivel de documento, proponemos capturar las interacciones entre oraciones a través de una red de autoatención de múltiples cabezas. Para extraer contextos a nivel de palabras, proponemos una tarea auxiliar para predecir el tipo de cada palabra para capturar su preferencia de tipo. Entrenamos conjuntamente nuestro modelo en el reconocimiento de entidades y la tarea de clasificación auxiliar mediante el aprendizaje multitarea. Los resultados experimentales de varios conjuntos de datos de referencia validan la eficacia de nuestro método.', 'pt': 'O reconhecimento de entidades nomeadas é uma tarefa crítica no campo de processamento de linguagem natural. A maioria dos métodos existentes para esta tarefa só pode explorar informações contextuais dentro de uma frase. No entanto, seu desempenho no reconhecimento de entidades em contextos limitados ou ambíguos em nível de sentença geralmente é insatisfatório. Felizmente, outras frases no mesmo documento podem fornecer contextos suplementares no nível do documento para ajudar a reconhecer essas entidades. Além disso, as próprias palavras contêm informações contextuais em nível de palavra, pois geralmente têm preferências diferentes de tipo de entidade e posição relativa das entidades nomeadas. Neste artigo, propomos uma estrutura unificada para incorporar contextos multiníveis para reconhecimento de entidades nomeadas. Usamos o TagLM como nosso modelo básico para capturar contextos em nível de sentença. Para incorporar contextos em nível de documento, propomos capturar interações entre sentenças por meio de uma rede de autoatenção multi-cabeças. Para explorar contextos em nível de palavra, propomos uma tarefa auxiliar para prever o tipo de cada palavra para capturar sua preferência de tipo. Treinamos nosso modelo em conjunto em reconhecimento de entidade e na tarefa de classificação auxiliar por meio de aprendizado multitarefa. Os resultados experimentais em vários conjuntos de dados de referência validam a eficácia do nosso método.', 'fr': "La reconnaissance d'entités nommées est une tâche essentielle dans le domaine du traitement du langage naturel. La plupart des méthodes existantes pour cette tâche ne peuvent exploiter que les informations contextuelles contenues dans une phrase. Cependant, leur performance en matière de reconnaissance d'entités dans des contextes de peine limités ou ambigus est généralement insatisfaisante. Heureusement, d'autres phrases du même document peuvent fournir des contextes supplémentaires au niveau du document pour aider à reconnaître ces entités. En outre, les mots eux-mêmes contiennent des informations contextuelles au niveau du mot, car ils ont généralement des préférences différentes en matière de type d'entité et de position relative par rapport aux entités nommées. Dans cet article, nous proposons un cadre unifié pour intégrer des contextes multi-niveaux pour la reconnaissance d'entités nommées. Nous utilisons TagLM comme modèle de base pour capturer les contextes au niveau de la phrase. Pour intégrer des contextes au niveau du document, nous proposons de capturer les interactions entre les phrases via un réseau d'attention personnelle à plusieurs têtes. Pour explorer les contextes au niveau des mots, nous proposons une tâche auxiliaire pour prédire le type de chaque mot afin de saisir sa préférence de type. Nous formons conjointement notre modèle à la reconnaissance d'entités et à la tâche de classification auxiliaire via l'apprentissage multitâche. Les résultats expérimentaux de plusieurs ensembles de données de référence valident l'efficacité de notre méthode.", 'ja': '名前付きエンティティ認識は、自然言語処理分野における重要なタスクです。 このタスクの既存のメソッドのほとんどは、文内のコンテキスト情報のみを利用することができます。 しかし、限られたまたは曖昧な文レベルの文脈でエンティティを認識する際のパフォーマンスは、通常満足のいくものではありません。 幸いなことに、同じドキュメント内の他の文は、これらのエンティティを認識するのに役立つ補足的なドキュメントレベルのコンテキストを提供することができます。 さらに、単語自体は、通常、名前付きエンティティとは異なるエンティティタイプと相対的な位置の好みを有するため、単語レベルのコンテキスト情報を含んでいます。 本稿では、命名されたエンティティ認識のためのマルチレベルのコンテキストを組み込むための統一されたフレームワークを提案する。 文レベルのコンテキストをキャプチャするために、TagLMを基本モデルとして使用します。 ドキュメントレベルの文脈を組み込むために、複数のヘッドの自己注目ネットワークを介して文章間の相互作用をキャプチャすることを提案します。 ワードレベルコンテキストをマイニングするために、各ワードの種類を予測してその種類の好みをキャプチャする補助タスクを提案します。 私たちは、マルチタスク学習を通じて、エンティティ認識と補助分類タスクのモデルを共同でトレーニングします。 いくつかのベンチマークデータセットの実験結果は、当社の方法の有効性を検証します。', 'zh': '名实体识者,自然语言治域之要务也。 多用句中上下文信息。 然其于有限、模棱上下文中识实体者,常不能满意。 幸同文档他句文档级上下文补,以助识其实。 单词身单词上下文信,以其有名实首选项。 于本文中,立一统之框架,以合名实识者众上下文。 以TagLM为得句上下文之大经。 合文档级上下文,请因多头自关网络得句之交。 掘单词上下文,举一佐以卜单词,以得其善。 吾以多任务学,合体而教之。 数准集实验验其有效性。', 'ru': 'Распознавание именованных сущностей является критически важной задачей в области обработки естественного языка. Большинство существующих методов для этой задачи могут использовать только контекстную информацию в предложении. Однако их эффективность при распознавании сущностей в ограниченных или неоднозначных контекстах на уровне предложений обычно неудовлетворительна. К счастью, другие предложения в том же документе могут обеспечить дополнительные контексты на уровне документов, чтобы помочь распознать эти сущности. Кроме того, сами слова содержат контекстную информацию на уровне слов, поскольку они обычно имеют различные предпочтения типа сущности и относительного положения от именованных сущностей. В этой статье мы предлагаем унифицированную структуру для включения многоуровневых контекстов для распознавания именованных сущностей. Мы используем TagLM в качестве нашей базовой модели для захвата контекстов на уровне предложений. Чтобы включить контексты на уровне документа, мы предлагаем захватывать взаимодействия между предложениями через многоглавую сеть самовнимания. Чтобы определить контексты на уровне слов, мы предлагаем вспомогательную задачу для прогнозирования типа каждого слова, чтобы охватить его предпочтения типа. Мы совместно обучаем нашу модель распознаванию сущностей и вспомогательной задаче классификации с помощью многозадачного обучения. Экспериментальные результаты по нескольким эталонным наборам данных подтверждают эффективность нашего метода.', 'hi': 'नामित एंटिटी पहचान प्राकृतिक भाषा प्रसंस्करण क्षेत्र में एक महत्वपूर्ण कार्य है। इस कार्य के लिए अधिकांश मौजूदा तरीके केवल एक वाक्य के भीतर प्रासंगिक जानकारी का शोषण कर सकते हैं। हालांकि, सीमित या अस्पष्ट वाक्य-स्तर के संदर्भों में संस्थाओं को पहचानने पर उनका प्रदर्शन आमतौर पर असंतोषजनक होता है। सौभाग्य से, एक ही दस्तावेज़ में अन्य वाक्य इन संस्थाओं को पहचानने में मदद करने के लिए पूरक दस्तावेज़-स्तर के संदर्भ प्रदान कर सकते हैं। इसके अलावा, शब्दों में स्वयं शब्द-स्तर की प्रासंगिक जानकारी होती है क्योंकि उनके पास आमतौर पर नामित संस्थाओं से इकाई प्रकार और सापेक्ष स्थिति की अलग-अलग प्राथमिकताएं होती हैं। इस पेपर में, हम नामित इकाई मान्यता के लिए बहु-स्तरीय संदर्भों को शामिल करने के लिए एक एकीकृत ढांचे का प्रस्ताव करते हैं। हम वाक्य-स्तर के संदर्भों को कैप्चर करने के लिए अपने मूल मॉडल के रूप में TagLM का उपयोग करते हैं। दस्तावेज़-स्तर के संदर्भों को शामिल करने के लिए, हम एक बहु-सिर स्व-ध्यान नेटवर्क के माध्यम से वाक्यों के बीच बातचीत को कैप्चर करने का प्रस्ताव करते हैं। शब्द-स्तर के संदर्भों का खनन करने के लिए, हम अपने प्रकार की वरीयता को कैप्चर करने के लिए प्रत्येक शब्द के प्रकार की भविष्यवाणी करने के लिए एक सहायक कार्य का प्रस्ताव करते हैं। हम संयुक्त रूप से इकाई मान्यता और बहु-कार्य सीखने के माध्यम से सहायक वर्गीकरण कार्य में अपने मॉडल को प्रशिक्षित करते हैं। कई बेंचमार्क डेटासेट पर प्रयोगात्मक परिणाम हमारी विधि की प्रभावशीलता को मान्य करते हैं।', 'ga': 'Is tasc ríthábhachtach é aitheantas aonáin ainmnithe i réimse na próiseála teanga nádúrtha. Ní féidir leis an gcuid is mó de na modhanna atá ann don tasc seo ach leas a bhaint as faisnéis chomhthéacsúil laistigh d’abairt. Mar sin féin, is gnách go mbíonn a bhfeidhmíocht maidir le heintitis a aithint i gcomhthéacsanna teoranta nó débhríoch ar leibhéal na habairte míshásúil. Ar ámharaí an tsaoil, is féidir le habairtí eile sa doiciméad céanna comhthéacsanna forlíontacha ar leibhéal doiciméad a sholáthar chun cabhrú leis na haonáin seo a aithint. Ina theannta sin, bíonn faisnéis chomhthéacsúil ar leibhéal na bhfocal sna focail féin toisc go mbíonn roghanna difriúla acu de ghnáth maidir le cineál eintitis agus suíomh coibhneasta agus na haonáin ainmnithe. Sa pháipéar seo, molaimid creat aontaithe chun comhthéacsanna il-leibhéil a ionchorprú le haghaidh aitheantais aonáin ainmnithe. Bainimid úsáid as TagLM mar ár múnla bunúsach chun comhthéacsanna ar leibhéal na habairte a ghabháil. Chun comhthéacsanna ar leibhéal na ndoiciméad a ionchorprú, tá sé beartaithe againn idirghníomhaíochtaí idir abairtí a ghabháil trí ghréasán féinairdithe ilcheann. Chun comhthéacsanna leibhéal na bhfocal a mhianlú, molaimid tasc cúnta chun cineál gach focal a thuar chun a rogha cineáil a ghabháil. Déanaimid comhthraenáil ar ár múnla maidir le haitheantas aonáin agus an tasc cúnta aicmithe trí fhoghlaim ilthasc. Déanann na torthaí turgnamhacha ar roinnt tacar sonraí tagarmharcála éifeachtacht ár modha a bhailíochtú.', 'ka': 'სახელი ინტერტის განაცნობა არის კრიტიკური რაოდენობა სახელის პროცესის პანელში. ამ დავალებისთვის უფრო მეტი არსებობს შესაძლებელია მხოლოდ კონტექსტური ინფორმაციის გამოყენება. მაგრამ, მათი განსაზღვრება განსაზღვრებით ან განსაზღვრებულ სიტყვების განსაზღვრებით განსაზღვრებით უფრო განსაზღვრებულია. ბედნიერად, ერთი დოკუმენტში სხვა სიტყვები შეუძლია დამატება კონტექსტური დოკუმენტის დოკუმენტის კონტექსტურები, რომელიც დამატება ამ დამატებით, სიტყვები თავიდან სიტყვების კონტექსტური ინფორმაცია, რადგან ისინი საერთოდ აქვს განსხვავებული ინტერტიკური ტიპის პროგრამების და პროგრამეტურ ამ დოკუნტში ჩვენ მინდა ერთადერთი ფრამეტრი, რომელიც მრავალდომის კონტექსტების შეყვარება სახელსახელ ინტერტიკის განაცნობისთვის. ჩვენ TagLM-ს გამოყენებთ ჩვენი ფესტური მოდელის შესახებ სიტყვების კონტექსტში. კოკუმენტის დოკუმენტის კონტექსტების შეყვარება, ჩვენ მინდომარებით მრავალთან თავისუფლიო ქსელის გამოყენება სიტყვების შესახებ ინტექსტა ჩემი სიტყვების კონტექსტუსებისთვის, ჩვენ მინდა დახმარებელი საქმე, რომელიც ყოველ სიტყვების ტიპის წინასწორება, რომელიც მისი ტიპის მონიშვნელობის შესახე ჩვენ ერთადერთად ჩვენი მოდელს ინტერტიკის განაცნობაში და დახმარებელი კლასიფიკაციის რაოდენობაში მრავალ რაოდენობების სწავლების გამოყენება. ექსპერიმენტიური შედეგები რამდენიმე ბენქმარკის მონაცემების შესაძლებლობად ჩვენი მეთოდის ეფექტიურობას გადაწყენება.', 'hu': 'A nevezett entitás felismerése kritikus feladat a természetes nyelvfeldolgozás területén. A tevékenység legtöbb meglévő módszere csak egy mondaton belüli kontextuális információkat használhat ki. Azonban a korlátozott vagy kétértelmű mondatszintű kontextusokban lévő entitások felismerésével kapcsolatos teljesítményük általában nem kielégítő. Szerencsére ugyanabban a dokumentumban található más mondatok kiegészítő dokumentumszintű kontextusokat biztosíthatnak az entitások felismeréséhez. Ezenkívül maguk a szavak szószintű kontextuális információkat tartalmaznak, mivel általában az entitás típusát és relatív pozícióját különböző preferenciákkal rendelkeznek a megnevezett entitásoktól. Ebben a tanulmányban egy egységes keretrendszert javasolunk a nevezett entitások felismeréséhez szükséges többszintű kontextusok beépítésére. A TagLM-et használjuk alapvető modellként mondatszintű kontextusok rögzítésére. A dokumentum szintű kontextusok beépítése érdekében javasoljuk, hogy a mondatok közötti interakciókat egy többfejű önfigyelmi hálózaton keresztül rögzítsük. A szószintű kontextusok bányászatához egy kiegészítő feladatot javaslunk, amely megjósolja az egyes szavak típusát, hogy megragadja a típuspreferenciát. Modellünket közösen képezzük az entitások felismerésére és a kiegészítő osztályozási feladatokra többfeladatos tanulással. Több benchmark adathalmaz kísérleti eredményei igazolják módszerünk hatékonyságát.', 'el': 'Η αναγνώριση ονομαστικής οντότητας είναι μια κρίσιμη εργασία στο πεδίο επεξεργασίας φυσικής γλώσσας. Οι περισσότερες υπάρχουσες μέθοδοι για αυτήν την εργασία μπορούν να εκμεταλλευτούν μόνο πληροφορίες περιβάλλοντος μέσα σε μια πρόταση. Ωστόσο, η απόδοσή τους στην αναγνώριση οντοτήτων σε περιορισμένα ή διφορούμενα πλαίσια σε επίπεδο πρότασης είναι συνήθως μη ικανοποιητική. Ευτυχώς, άλλες προτάσεις στο ίδιο έγγραφο μπορούν να παρέχουν συμπληρωματικά πλαίσια σε επίπεδο εγγράφου για να βοηθήσουν στην αναγνώριση αυτών των οντοτήτων. Επιπλέον, οι ίδιες οι λέξεις περιέχουν πληροφορίες περιβάλλοντος σε επίπεδο λέξης, δεδομένου ότι συνήθως έχουν διαφορετικές προτιμήσεις για τον τύπο οντότητας και τη σχετική θέση από τις ονομαστικές οντότητες. Στην παρούσα εργασία, προτείνουμε ένα ενοποιημένο πλαίσιο για την ενσωμάτωση πολυεπίπεδων πλαισίων για την αναγνώριση ονομαστικής οντότητας. Χρησιμοποιούμε το ως βασικό μοντέλο για να συλλάβουμε τα πλαίσια σε επίπεδο πρότασης. Για να ενσωματώσουμε τα πλαίσια σε επίπεδο εγγράφων, προτείνουμε να καταγράψουμε τις αλληλεπιδράσεις μεταξύ των προτάσεων μέσω ενός δικτύου αυτοπροσοχής πολλαπλών κεφαλιών. Για να εξορύξουμε τα πλαίσια σε επίπεδο λέξεων, προτείνουμε μια βοηθητική εργασία για να προβλέψουμε τον τύπο κάθε λέξης για να συλλάβουμε την προτίμησή της τύπου. Εκπαιδεύουμε από κοινού το μοντέλο μας στην αναγνώριση οντοτήτων και την βοηθητική εργασία ταξινόμησης μέσω της εκμάθησης πολλαπλών εργασιών. Τα πειραματικά αποτελέσματα σε διάφορα σύνολα δεδομένων αναφοράς επιβεβαιώνουν την αποτελεσματικότητα της μεθόδου μας.', 'lt': 'Pavadintojo subjekto pripažinimas yra esminė užduotis natūralios kalbos apdorojimo srityje. Dauguma esamų šios užduoties metodų gali naudoti tik kontekstinę informaciją sakinyje. However, their performance on recognizing entities in limited or ambiguous sentence-level contexts is usually unsatisfactory.  Laimei, kiti to paties dokumento sakiniai gali suteikti papildomų dokumentų lygmens kontekstų, padedančių atpažinti šiuos subjektus. Be to, pačiuose žodžiuose pateikiama žodžių lygio kontekstinė informacija, nes jie paprastai turi skirtingas subjekto tipo ir santykinės padėties preferencijas nei pavadinti subjektai. Šiame dokumente siūlome vieningą sistemą, kurioje būtų įtraukti daugiapakopiai subjektų pripažinimo kontekstai. Mes naudojame TagLM kaip pagrindinį model į, kad sugalvotume sakinių lygį. To incorporate document-level contexts, we propose to capture interactions between sentences via a multi-head self attention network.  Kalbant apie žodžių lygmens kontekstus, siūlome papildomą užduotį numatyti kiekvieno žodžio tipą, kad būtų gautas jo tipo pasirinkimas. Bendrai mokome savo model į subjektų pripažinimo ir papildomos klasifikacijos užduoties srityje, pasitelkdami daugiafunkcinį mokymąsi. Eksperimentiniai kelių lyginamųjų duomenų rinkinių rezultatai patvirtina mūsų metodo veiksmingumą.', 'kk': 'Аталған нысандарды анықтау - табиғи тілді өңдеу өрісінде маңызды тапсырма. Бұл тапсырманың көбірек әдістері тек мәліметті сөйлеменің ішінде қолдануға болады. Бірақ олардың шектелген немесе шектелген сөйлем деңгейіндегі жағдайларды анықтау әдеттегісі әдетте қарапайды. Бұл құжаттың басқа сөздері осы нысандарды анықтау үшін қосымша құжаттың деңгейіндегі контексті бере алады. Қосымша, сөздер өзінде сөздер деңгейіндегі контексті мәліметі бар, өйткені олардың кәдімгі нысандардың түріне және аталған нысандардан сәйкес орналасатын бапт Бұл қағазда біріктірілген бағдарламаларды бірнеше деңгейіндегі тәртіптерді біріктіру үшін біріктіріп тастаймыз. Біз TagLM дегенді сөйлемелер деңгейіндегі контексттерді алу үшін негізгі үлгілеріміз ретінде қолданамыз. Құжат деңгейіндегі контексттерді қосу үшін, біз сөйлемелер арасындағы бірнеше басқа себептердің өзінің қатынасын түсіргенін ұсынамыз. Менің сөз деңгейіндегі контексттерімізге, әрбір сөздің түрін таңдау үшін көмекші тапсырманы таңдаймыз. Біз өзіміздің үлгімізді бірнеше тапсырманы анықтау және көмектесу тапсырмасын көмектесу арқылы көмектесетін. Бірнеше банкмарк деректер қорларының тәжірибесінің тәжірибесін тексеру.', 'mk': 'Признавањето на именуваниот ентитет е критична задача во полето за процес на природен јазик. Повеќето постоечки методи за оваа задача можат само да искористат контекстни информации во рамките на реченица. Сепак, нивната изведба во врска со препознавањето на ентитетите во ограничени или двогледни контексти на ниво на реченици обично е незадоволна. За среќа, другите реченици во истиот документ можат да обезбедат дополнителни контексти на ниво на документи за да помогнат во препознавањето на овие ентитети. Покрај тоа, самите зборови содржат контекстуални информации на ниво на зборови бидејќи тие обично имаат различни преференции на типот на ентитет и релативна позиција од именуваните ентитети. Во овој документ, предлагаме унифицирана рамка за вклучување на повеќето нивоа контексти за препознавање на именуваните ентитети. We use TagLM as our basic model to capture sentence-level contexts.  За да ги вклучиме контекстите на ниво на документи, предлагаме да се зафатат интеракциите помеѓу речениците преку мрежа со повеќе глави за себе внимание. За да ги пронајдеме контекстите на зборово ниво, предлагаме помошна задача за предвидување на типот на секој збор за да го фати својот тип преференција. Заедно го обучуваме нашиот модел во препознавањето на ентитетите и помошната класификација задача преку мултизадачно учење. Експерименталните резултати на неколку бази на податоци ја потврдуваат ефикасноста на нашиот метод.', 'ms': 'Pengenalan entiti bernama adalah tugas kritik dalam medan pemprosesan bahasa alami. Most existing methods for this task can only exploit contextual information within a sentence.  Namun, prestasi mereka mengenali entiti dalam konteks aras kalimat yang terbatas atau ambiguh biasanya tidak puas. Untungnya, kalimat lain dalam dokumen yang sama boleh menyediakan konteks aras dokumen tambahan untuk membantu mengenali entiti ini. Selain itu, kata-kata sendiri mengandungi maklumat kontekstual aras perkataan kerana mereka biasanya mempunyai keutamaan yang berbeza jenis entiti dan kedudukan relatif dari entiti bernama. Dalam kertas ini, kami melamar kerangka bersatu untuk memasukkan konteks multi-tahap untuk pengenalan entiti bernama. Kami menggunakan TagLM sebagai model as as kami untuk menangkap konteks tahap kalimat. Untuk memasukkan konteks aras dokumen, kami melamar untuk menangkap interaksi antara kalimat melalui rangkaian perhatian diri berbilang-kepala. To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference.  Kami bersama-sama melatih model kami dalam pengenalan entiti dan tugas klasifikasi bantuan melalui pembelajaran multi-tugas. Hasil percubaan pada beberapa set data benchmark sahkan kegunaan kaedah kita.', 'ml': 'സ്വാഭാവികമായ ഭാഷയുടെ പ്രക്രിയഭാഷയുടെ പ്രക്രിയഭാഷയില്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനുള്ള പേരി ഈ ജോലിക്കുള്ള ഏറ്റവും നിലവിലുള്ള രീതികള്\u200d എന്നാലും അവയുടെ പ്രവര്\u200dത്തനങ്ങള്\u200d നിരീക്ഷിക്കുന്നതിനോ ശിക്ഷയുടെ നില വാക്കുകള്\u200d നിലനില്\u200dക്കുന്നതിനോ സാധാരണ അസാധാ ഭാഗ്യവശാലം, ഒരേ രേഖയിലെ മറ്റു വാക്കുകള്\u200d ഈ വസ്തുക്കളെ തിരിച്ചറിയാന്\u200d സഹായിക്കുന്നതിനായി കൂടുതല്\u200d രേഖയുടെ ന കൂടാതെ, വാക്കുകള്\u200dക്ക് വാക്കുകള്\u200d വാക്ക്- നിലവിലുള്ള വിവരങ്ങള്\u200d സ്വയം ലഭ്യമാകുന്നു. അവയുടെ സാധാരണ വസ്തുക്കളുടെ തരത് ഈ പത്രത്തില്\u200d, നമ്മള്\u200d ഒരു യൂണിക്കൂട്ടിയ ഫ്രെയിമെക്ക്രെയിമെന്\u200dറ് ചെയ്യുന്നു, പേരിട്ട വസ്തുക്കള്\u200d തിരിച്ചറ നമ്മുടെ അടിസ്ഥാന മോഡലായി ടാഗ്ലിഎം ഉപയോഗിക്കുന്നു വാക്ക് നില പരിഹാരം പിടിക്കാന്\u200d. രേഖയുടെ നില പരിഗണനങ്ങള്\u200d ചേര്\u200dക്കാന്\u200d ഞങ്ങള്\u200d പ്രാര്\u200dത്ഥിക്കുന്നു. ഒരു പലതലയിലെ സ്വയം ശ്രദ്ധ പ്രവർത്തിക്കുന്ന ശേഖര എന്\u200dറെ വാക്ക്- നില പരിപാടികള്\u200dക്ക്, അതിന്\u200dറെ തരം മുന്\u200dഗണന പിടിക്കാന്\u200d ഓരോ വാക്കിന്\u200dറെയും തരം പ്രവചിക്കാന്\u200d ഞങ്ങള്\u200d ഒരു കൂട We jointly train our model in entity recognition and the auxiliary classification task via multi-task learning.  നമ്മുടെ രീതിയിലെ പ്രവർത്തനവും പരീക്ഷിക്കുന്ന പരീക്ഷണ ഫലങ്ങളിലുള്ള പരീക്ഷണ ഫലങ്ങളാണ്.', 'it': "Il riconoscimento delle entità denominate è un compito critico nel campo dell'elaborazione del linguaggio naturale. La maggior parte dei metodi esistenti per questa attività può sfruttare solo le informazioni contestuali all'interno di una frase. Tuttavia, le loro prestazioni nel riconoscere entità in contesti limitati o ambigui a livello di frase sono solitamente insoddisfacenti. Fortunatamente, altre frasi nello stesso documento possono fornire contesti supplementari a livello di documento per aiutare a riconoscere queste entità. Inoltre, le parole stesse contengono informazioni contestuali a livello di parola poiché di solito hanno preferenze diverse di tipo di entità e posizione relativa rispetto alle entità nominate. In questo articolo, proponiamo un framework unificato per incorporare contesti multi-livello per il riconoscimento di entità nominative. Usiamo TagLM come modello base per catturare contesti a livello di frase. Per incorporare contesti a livello di documento, proponiamo di catturare le interazioni tra frasi attraverso una rete di auto-attenzione multi-testa. Per estrarre contesti a livello di parola, proponiamo un'attività ausiliaria per prevedere il tipo di ogni parola per catturare la sua preferenza di tipo. Formiamo congiuntamente il nostro modello nel riconoscimento delle entità e nell'attività di classificazione ausiliaria attraverso l'apprendimento multi-task. I risultati sperimentali su diversi set di dati di benchmark confermano l'efficacia del nostro metodo.", 'mt': 'Ir-rikonoxximent tal-entità msemmija huwa kompitu kritiku fil-qasam tal-ipproċessar tal-lingwi naturali. Il-biċċa l-kbira tal-metodi eżistenti għal dan il-kompitu jistgħu jisfruttaw biss l-informazzjoni kuntestwali fi ħdan sentenza. Madankollu, il-prestazzjoni tagħhom fuq entitajiet rikonoxxuti f’kuntesti limitati jew ambigwi fil-livell tas-sentenza normalment mhijiex sodisfaċenti. Fortunatament, sentenzi oħra fl-istess dokument jistgħu jipprovdu kuntesti supplimentari fil-livell tad-dokument biex jgħinu jirrikonoxxu dawn l-entitajiet. Barra minn hekk, il-kliem innifsu fihom informazzjoni kuntestwali fil-livell tal-kliem peress li normalment ikollhom preferenzi differenti tat-tip ta’ entità u pożizzjoni relattiva minn entitajiet imsemmija. F’dan id-dokument, qed nipproponu qafas unifikat biex jinkorpora kuntesti f’diversi livelli għar-rikonoxximent ta’ entitajiet imsemmija. Aħna nużaw TagLM bħala mudell bażiku tagħna biex inqabdu l-kuntesti fil-livell tas-sentenza. Biex jiġu inkorporati kuntesti fil-livell tad-dokumenti, nipproponu li jinqabdu interazzjonijiet bejn is-sentenzi permezz ta’ netwerk ta’ awtonomija b’diversi kapijiet. Għall-kuntesti fil-livell tal-kliem fil-minjieri, qed nipproponu kompitu awżiljarju li jipprevedi t-tip ta’ kull kelma biex tinqabad il-preferenza tat-tip tagħha. Aħna nħarrġu b’mod konġunt il-mudell tagħna fir-rikonoxximent tal-entitajiet u l-kompitu awżiljarju ta’ klassifikazzjoni permezz ta’ tagħlim b’diversi kompiti. Ir-riżultati sperimentali fuq diversi settijiet ta’ dejta ta’ referenza jivvalidaw l-effettività tal-metodu tagħna.', 'ro': 'Recunoașterea entităților denumite este o sarcină critică în domeniul procesării limbajului natural. Majoritatea metodelor existente pentru această activitate pot exploata doar informațiile contextuale dintr-o propoziție. Cu toate acestea, performanța lor privind recunoașterea entităților în contexte limitate sau ambigue la nivel de propoziții este de obicei nesatisfăcătoare. Din fericire, alte propoziții din același document pot oferi contexte suplimentare la nivel de document pentru a ajuta la recunoașterea acestor entități. În plus, cuvintele însele conțin informații contextuale la nivel de cuvânt, deoarece au, de obicei, preferințe diferite de tip de entitate și poziție relativă față de entitățile numite. În această lucrare, propunem un cadru unificat pentru a include contexte pe mai multe niveluri pentru recunoașterea entităților denumite. Folosim TagLM ca model de bază pentru a capta contexte la nivel de propoziție. Pentru a încorpora contexte la nivel de document, propunem să capturăm interacțiunile dintre propoziții printr-o rețea de auto-atenție multi-cap. Pentru a extrage contexte la nivel de cuvinte, propunem o sarcină auxiliară pentru a prezice tipul fiecărui cuvânt pentru a capta preferința de tip. Pregătim împreună modelul nostru în recunoașterea entităților și sarcina auxiliară de clasificare prin învățare multi-task. Rezultatele experimentale ale mai multor seturi de date de referință validează eficiența metodei noastre.', 'no': 'Tilgjenkjenning av namnet entitet er ein kritisk oppgåve i den naturlege språkkhandteringsfeltet. Dei fleste eksisterande metodane for denne oppgåva kan berre bruka kontekstinformasjon i eit setning. Dette gjeld imidlertid å gjenkjenne einingar i begrensede eller avgjengelege setningsnivå, vanlegvis er uverkjende. For godt kan andre setningar i det same dokumentet gjeve ekstra dokumentnivåkontekstar for å hjelpa å gjenkjenna desse einingane. I tillegg inneheld ord sjølv kontekstinformasjon om ordnivået sidan dei vanlegvis har ulike innstillingar av entitetstype og relativt plassering frå namnet entiteter. I denne papiret foreslår vi eit vienot ramme for å inkludere fleire nivåkontekstar for gjenkjenning av namnet entitet. Vi bruker TagLM som vår grunnleggjande modell for å henta setningsnivåkontekstar. For å inkludere dokumentnivåkontekstar, foreslår vi å henta saman mellom setningar via eit fleire hovudnettverk for selvmerking. For ordnivåkontekstane mine, foreslår vi ei hjelpeoppgåve for å foreslå kvar type ord for å ta inn innstillingane for typen. Vi treng sammen modellen vårt i gjenkjenning av einingar og hjelpeklassifikasjonen ved å lære fleire oppgåver. Eksperimentale resultatene på fleire benchmarkdatasett bestemmer effektiviteten av metoden vår.', 'mn': 'Байгалийн хэл үйлдвэрлэлийн талбарт нэрлэгдсэн бүтээлүүдийг хүлээн зөвшөөрөх нь чухал ажил юм. Энэ үйлдлийн ихэнх арга нь зөвхөн үгийн дотор орчин үгийн мэдээллийг ашиглаж чадна. Гэхдээ тэдний үйл ажиллагаа нь хязгаарлагдмал эсвэл хамаагүй өгүүлбэрийн нөхцөлд хүлээн зөвшөөрөх үйл ажиллагаа ихэвчлэн хэцүү байдаг. Харамсалтай нь, нэг баримтын бусад өгүүлбэрүүд эдгээр бүтээгдэхүүнийг танихын тулд нэмэлт баримт түвшинд нөхцөл байдлаар хангаж болно. Үүнээс гадна үг өөрсдийгөө үг-түвшинд орчин үг-түвшинд орчин үг-түвшинд мэдээллийг агуулдаг. Учир нь ихэвчлэн биетийн төрлийн өөр сонирхолтой, нэрлэгдсэн биетүүдийн хар Энэ цаасан дээр бид нэгтгэл хөрөнгө оруулж, нэрлэгдсэн биетийн танихын тулд олон төвшин нөхцөл байдлыг нэгтгэх боломжтой. Бид TagLM-г өгүүлбэрийн түвшинд авч үзэхэд үндсэн загвар болгон ашиглаж байна. Документын түвшинд орчин тухай нэгтгэхэд бид өгүүлбэрийн хоорондоо олон толгой анхаарлын сүлжээгээр харилцаа авахыг санал болно. Миний үгийн түвшинд тусламжтайгаар бид хэлбэрийн сонголтыг авахын тулд тусламжтайгаар ажиллаж байна. Бид загварыг олон ажлын сургалтын аргаар хүлээн зөвшөөрөх, тусламжтайгаар хуваалцах ажил дээр нийлүүлж суралцаж байна. Бидний арга замын үр дүнтэй байдлыг шалгаж үзэх хэдэн банк өгөгдлийн сангийн туршилтын үр дүнг.', 'sr': 'Prepoznavanje imenovanih entiteta je kritičan zadatak u oblasti obrade prirodnog jezika. Većina postojećih metoda za ovaj zadatak može iskoristiti samo kontekstne informacije unutar rečenice. Međutim, njihov učinkovit priznanja entitata u ograničenim ili dvosmislenim kontekstima na nivou rečenica obično je nezadovoljno. Srećom, druge rečenice u istom dokumentu mogu pružiti dodatne kontekste na nivou dokumenta kako bi pomogla prepoznati te entitate. Osim toga, sami reči sadrže kontekstske informacije na nivou riječi jer obično imaju različite preferencije tipa entiteta i relativne pozicije od imenovanih entitata. U ovom papiru predlažemo jedinstveni okvir da uključimo višeniverske kontekste za priznanje entiteta. Koristimo TagLM kao osnovni model da uhvatimo kontekste na nivou rečenica. Da bi uključili kontekste na nivou dokumenta, predlažemo da uhvatimo interakciju između rečenica putem višeglavne samopouzdanje mreže. U mojim kontekstima na nivou riječi predlažemo pomoćni zadatak da predvidimo vrstu svake reči da uhvati svoju preferenciju tipa. Zajedno treniramo naš model u priznanju entiteta i pomoænom klasifikacijskom zadatku putem multi task učenja. Eksperimentalni rezultati na nekoliko standardnih podataka potvrđuju učinkovitost našeg metoda.', 'so': 'Aqoonsashada qofka la magacaabay waa shaqo muhiim ah oo ku jira beerta baaritaanka afka asalka ah. Inta badan qaababka joogtada ah ee shaqadan waxay ku isticmaali karaan macluumaad joogta ah oo kaliya garsoorida. Si kastaba ha ahaatee sameyntooda aqoonsashada waxyaabaha la xiriira ama la xiriira heerka maxkamadda sida caadiga ah waa mid aan la suurtoonayn. Si nasiib leh waxaa laga heli karaa erayo kale oo ku jira dukumentigaas, si ay ugu caawiyaan aqoonsigan waxyaabahaas. Intaas waxaa dheer in erayo ay isku qoran yihiin macluumaad ku saabsan heerka hadalka, sababtoo ah sida caadiga ah waxay leeyihiin doorashooyin kala duduwan oo ay leeyihiin noocyada jidhka ah iyo booska qoyska ah oo ay leeyihiin macluumaadka la magacaabay. Qoraalkan waxaynu soo jeedaynaa shirkad isku darsameyn si aan u soo galno qoraal heer kala duduwan oo lagu magacaabay aqoonsashada entity. Waxaynu TagLM u isticmaalnaa qaababka asalka ah si aan u qabsanno dhibaatooyinka heerka. Si aan u qorno qoraalka heerka ee dokumenta, waxaynu soo jeedinaynaa in lagu qabsado xiriir kala duduwan bogagga shabakadda iskuulka. Waxaan u soo jeedaynaa shaqo la xiriira hadalkayga, si aan u sii sheegno nooca kasta oo eray ah si aan u qabno nooca loo doorto. Tusaaleheenna si wadajir ah ayaannu ku tababarinnaa aqoonsiga bogga shaqada iyo shaqada fasaxda aqoonsiga sharciga ah via waxbarashada shaqo badan. Imtixaanka waxaa ku qoran macluumaadyo badan oo ku saabsan bangiga, waxayna xaqiijiyaan awooddayada.', 'sv': 'Identifiering av namngivna entiteter är en viktig uppgift i fältet för behandling av naturligt språk. De flesta befintliga metoder för den här uppgiften kan bara utnyttja kontextuell information i en mening. Men deras prestation på att känna igen entiteter i begränsade eller tvetydiga meningsnivåsammanhang är vanligtvis otillfredsställande. Lyckligtvis kan andra meningar i samma dokument ge kompletterande dokument-nivå sammanhang för att hjälpa till att känna igen dessa entiteter. Dessutom innehåller orden själva kontextuell information på ordnivå eftersom de vanligtvis har olika preferenser för entitetstyp och relativ position från namngivna entiteter. I denna uppsats föreslår vi ett enhetligt ramverk för att införliva flernivåsammanhang för namngiven entitetsigenkänning. Vi använder TagLM som vår grundläggande modell för att fånga meningsnivåsammanhang. För att införliva dokument-nivå kontexter föreslår vi att fånga interaktioner mellan meningar via ett multi-head self-attention nätverk. För att gruva ordnivåkontexter föreslår vi en hjälpuppgift för att förutsäga typen av varje ord för att fånga dess typpreferens. Vi utbildar tillsammans vår modell i entitetsigenkänning och den extra klassificeringsuppgiften via multi-task learning. De experimentella resultaten på flera benchmarkdatauppsättningar bekräftar effektiviteten av vår metod.', 'pl': 'Rozpoznawanie nazwanych jednostek jest kluczowym zadaniem w dziedzinie przetwarzania języka naturalnego. Większość istniejących metod tego zadania może wykorzystać tylko informacje kontekstowe w ramach zdania. Jednak ich wyniki w rozpoznawaniu podmiotów w ograniczonych lub niejednoznacznych kontekstach na poziomie zdań są zwykle niesatysfakcjonujące. Na szczęście inne zdania w tym samym dokumencie mogą zapewnić dodatkowe konteksty na poziomie dokumentu, aby pomóc rozpoznać te podmioty. Ponadto same słowa zawierają informacje kontekstowe na poziomie słowa, ponieważ zazwyczaj mają różne preferencje typu jednostki i względnej pozycji niż nazwane jednostki. W niniejszym artykule proponujemy ujednolicone ramy uwzględniające konteksty wielopoziomowe do rozpoznawania nazwanych podmiotów. Używamy TagLM jako naszego podstawowego modelu do uchwycenia kontekstów na poziomie zdań. Aby uwzględnić konteksty na poziomie dokumentów, proponujemy uchwycenie interakcji między zdaniami za pośrednictwem wieloosobowej sieci uwagi na siebie. Aby wydobyć konteksty na poziomie słów, proponujemy zadanie pomocnicze, aby przewidzieć typ każdego słowa, aby uchwycić jego preferencje typowe. Wspólnie szkolimy nasz model w zakresie rozpoznawania podmiotów i pomocniczego zadania klasyfikacji poprzez wielozadaniowe uczenie się. Wyniki eksperymentalne na kilku zestawach danych referencyjnych potwierdzają skuteczność naszej metody.', 'si': 'නම් කිරීමට තියෙන ප්\u200dරතිභාව පරීක්ෂණ ක්\u200dෂේත්රයේ ස්වභාවික භාෂාව ප්\u200dරතිභාවිත වැඩ මේ වැඩේ ගොඩක් විදියට තියෙන්න පුළුවන් වාර්තාවක් තොරතුරු විතරයි. නමුත්, ඔවුන්ගේ ප්\u200dරමාණය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය සම්පූර්ණය ස සතුටුයි, එකම වාර්තාවේ අනිත් වචනය පුළුවන් විශේෂයෙන් සම්පූර්ණ වාර්තාව සම්පූර්ණය සම්පූර්ණය ස ඒ වගේම, වචන් ඔවුන්ගේ වචන සම්බන්ධතා තොරතුරු තියෙන්නේ, මොකද ඔවුන්ට සාමාන්\u200dයයෙන්ම වෙනස් අයිතිය වර්ගය මේ පැත්තට, අපි එක්ක සංවිධානයක් ප්\u200dරයෝජනය කරනවා නම් අයිතිකරණය සඳහා ගොඩක් ස්තූතිය සංවිධානය සම් අපි ටැග්ල්ම් වාර්තාව සම්බන්ධතාව අල්ලන්න අපේ මූලික මොඩල් විදියට භාවිතා කරනවා. ලිපින්ත ස්ථානයක් සම්බන්ධ කරන්න, අපි ප්\u200dරශ්නයක් වාර්තාවක් අතර සම්බන්ධයක් ගන්න පුළුවන් විතරයි. මගේ වචන ස්ථානයකට, අපි ප්\u200dරශ්නයක් අල්ලගන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක අපි එකට අපේ මොඩේල් එක්ක සංවිධානය අඳුරගන්න සහ ගොඩක් වැඩක් ඉගෙන ගන්න පුළුවන් විශාල විශාල වැඩක්  බෙන්ච්මාර්ක් දත්ත සෙට් වල පරීක්ෂණ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d', 'ta': 'பெயரிடப்பட்ட பொருள் அறிவிப்பு இயல்பான மொழி செயல் புலத்தில் ஒரு முக்கியமான செயல். இந்த செயலுக்கு பெரும்பாலான இருக்கும் முறைகள் ஒரு வாக்கியத்திற்குள் உள்ள தற்போதைய தகவலை மட்டும் பயன However, their performance on recognizing entities on limited or ambiguous sentence- level contexts is usually unsatisfactory. அதிர்ஷ்டவசமாக, அதே ஆவணத்தில் உள்ள மற்ற வாக்கியங்கள் கூடுதலான ஆவண- நிலையின் பொருள்களை அறிந்து கொள்வதற்கு உதவும். சேர்க்கவும், வார்த்தைகள் சொல்ல- மட்டத்தில் தற்காலிக தகவல் உள்ளது ஏனெனில் அவர்கள் வழக்கமாக பொருள் வகையின் வித்தியாசமான இந்த காகிதத்தில், நாம் ஒரு ஒன்றிணைக்கப்பட்ட சட்டத்தை பரிந்துரைக்கிறோம் பெயரிடப்பட்ட பொருள் அடையாளத்திற்கான பல நாங்கள் அடிப்படை மாதிரியாக எங்கள் அடிப்படை ஒட்டுக்களை பயன்படுத்தி வாக்கு-மட்டத்தை பிடிக்க. ஆவண- மட்டத்தை சேர்க்க நாம் பரிந்துரைக்கிறோம் பல தலைப்பு தன்னுடைய கவனம் வலைப்பின்னல் மூலம் வாக்கியங்களுக்கிடையே இட என் வார்த்தை - மட்டத்தின் முன்னுரிமைகளுக்கு, ஒவ்வொரு வார்த்தையும் தன்னுடைய வகையை பிடிக்க முன்னுரிமை பொருள் அடையாளம் மற்றும் அதிக வகுப்பு பணியை பல பணி கற்றுக்கொண்டு நாம் எங்கள் மாதிரியை ஒன்றாக பயிற்சி செய்வோம். சோதனையின் முடிவுகள் பல பென்க்மார்க் தகவல்களின் முறைமையின் விளைவை சரிபார்க்கிறது.', 'ur': 'نام لیا گیٹی کی شناسایی طبیعی زبان پرسس فیلڈ میں ایک ضروری کام ہے. اس کام کے لئے بہت سے موجود طریقے صرف ایک جماعت میں متوسط معلومات استعمال کر سکتے ہیں. لیکن ان کی عملکرد محدود یا مختلف فیصلہ سطح کی موضوع کی پہچان کرنے کے لئے معمولاً غیر قابل ہے. خوش شانس، ایک ہی دکھانے میں دوسری جماعت یہ واحدوں کو پہچان کرنے کے لئے اضافہ دکھانے والی سطح کی کنٹکسٹس کی مدد کرسکتی ہیں. اس کے علاوہ، کلمات خود ہی لکھ رہے ہیں، کیونکہ ان کے لئے ایک ٹیٹی کی طرح اور نسبتی موقعیت کے مختلف ترجیح ہیں۔ اس کاغذ میں، ہم ایک متحدہ فرمیک پیشنهاد کرتے ہیں کہ نام داری پہچان کے لئے multi-level contexts شامل کریں. ہم ٹاگلم کو ہمارے بنیادی موڈل کے طور پر استعمال کرتے ہیں جماعت-سطح کی کنٹکسٹس کو پکڑنے کے لئے۔ سند-سطح کی کنٹکسٹس میں شامل ہونے کے لئے، ہم ایک multi-head self-attention نیٹ ورک کے ذریعہ کلمات کے درمیان اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپن میرے لفظ سطح کے متعلق، ہم ایک مددگار کام پیش کریں گے کہ ہر لفظ کی طرح کی پیش بینی کریں کہ اس کی طرح ترجیح حاصل کریں۔ ہم ایک دوسرے کے ساتھ اپنے مدل کو ایک ٹیٹی کی شناخت اور مددگاری کلاسیفوں کے کام کی تعلیم دیتے ہیں بہت سے کام کی تعلیم کے ذریعہ۔ بہت سی بنچم مارک ڈیٹ سٹ پر آزمائش کا نتیجہ ہمارے طریقے کے مطابق ثابت کرتا ہے.', 'uz': "Name Ushbu vazifa uchun koʻp mavjud usullar faqat bir terminalda matn maʼlumotni foydalanishi mumkin. Lekin ularning cheksiz yoki cheksiz so'zlar darajadagi obʼektlarni aniqlash imkoniyatini o'zgartirish oddiy emas. @ info Qoʻshimcha, so'zlar quyidagi matn maʼlumoti mavjud boʻladi, chunki u odatda quyidagi narsa turi va bogʻ'liq maʼlumotidan boshqa parametrlar mavjud. Bu qogʻozda, biz quyidagi tashkilotni tasdiqlash uchun bir nechta darajaga murakkab qilamiz. Biz tagLM asosiy modelimizdan foydalanamiz, so'zning darajaga murakkab qilish uchun. Hujjatning darajasi taʼminlarini qoʻyish uchun biz bir necha boshqaruv shaxsiy tarmoq orqali so'zlarning orasidagi interfeyslarini qabul qilish talab qilamiz. Mening so'zning darajasi taʼminlariga, biz bir so'zning turini oldinga bir so'zning turini oldin qilish uchun ishlatiladimiz. Biz bir necha vazifa o'rganish orqali tizimni tashqi qilamiz. Bir nechta benchmark maʼlumotidagi jarayon natijalari metodimizning effektligini toʻgʻri beradi.", 'vi': 'Nhận diện một thực thể có tên là một nhiệm vụ quan trọng trong lĩnh vực xử lý ngôn ngữ tự nhiên. Hầu hết các phương pháp tồn tại cho nhiệm vụ này chỉ có thể khai thác các thông tin ngữ cảnh trong một câu. Tuy nhiên, khả năng nhận diện thực thể trong ngữ cảnh hạn chế hoặc mơ hồ của trường hợp trường chữ là không hài lòng. May mắn thay, những câu khác trong cùng một tài liệu có thể cung cấp các ngữ cảnh văn bản bổ sung để giúp nhận diện những thực thể này. Thêm vào đó, các từ bản thân chứa các thông tin ngữ cảnh, vì chúng thường có những sở thích khác nhau về kiểu thực thể và vị trí tương đối với các thực thể tên. Trong tờ giấy này, chúng tôi đề nghị một cơ sở thống nhất để bao gồm các mặt ngữ cảnh đa cấp cho việc nhận diện thực thể. Chúng tôi dùng TagLM để chụp ảnh nền tảng của chúng tôi để chụp ảnh địa chỉ phí bản án. Để kết nối các tài liệu cấp, chúng tôi đề nghị thu thập các tương tác giữa các câu truyện qua một mạng lưới chăm sóc tự chủ đa đầu. Để khai thác các mặt từ cấp các tiếp xúc, chúng tôi đề nghị một nhiệm vụ phụ trợ dự đoán các kiểu của mỗi từ để nắm bắt kiểu đầu tiên của nó. Chúng tôi cùng nhau huấn luyện mô hình về nhận dạng thực thể và các nhiệm vụ phân bổ phụ thông qua nhiều nhiệm vụ học tập. Các kết quả thử nghiệm trên nhiều tập tin tiêu chuẩn xác nhận hiệu quả phương pháp này.', 'bg': 'Разпознаването на наименовани субекти е критична задача в областта на обработка на естествения език. Повечето съществуващи методи за тази задача могат да използват само контекстуална информация в рамките на изречение. Въпреки това, тяхното представяне при разпознаване на субекти в ограничен или двусмислен контекст на ниво изречение обикновено е незадоволително. За щастие, други изречения в същия документ могат да предоставят допълнителни контексти на ниво документ, за да помогнат за разпознаването на тези субекти. Освен това самите думи съдържат контекстуална информация на ниво дума, тъй като те обикновено имат различни предпочитания за тип на субекта и относителна позиция от имената. В настоящата статия предлагаме единна рамка за включване на контексти на многостепенно ниво за признаване на наименовани субекти. Използваме като основен модел за улавяне на контексти на ниво изречение. За да включим контексти на ниво документ, предлагаме да се улавят взаимодействията между изреченията чрез мрежа за самовнимание с няколко глави. За да минем контекстите на ниво дума, предлагаме допълнителна задача за предсказване на типа на всяка дума, за да уловим предпочитанията й за тип. Съвместно обучаваме модела си по разпознаване на обекти и спомагателна класификационна задача чрез многофункционално обучение. Експерименталните резултати на няколко сравнителни набора данни потвърждават ефективността на нашия метод.', 'da': 'Genkendelse af navngivne enheder er en kritisk opgave i feltet behandling af natursprog. De fleste eksisterende metoder til denne opgave kan kun udnytte kontekstuelle oplysninger i en sætning. Men deres præstation med at anerkende enheder i begrænsede eller tvetydige sætningsniveau sammenhænge er normalt utilfredsstillende. Heldigvis kan andre sætninger i samme dokument give supplerende dokumentniveau sammenhænge for at hjælpe med at genkende disse enheder. Derudover indeholder ordene selv kontekstuelle oplysninger på ordniveau, da de normalt har forskellige præferencer for entitetstype og relative position fra navngivne entiteter. I denne artikel foreslår vi en samlet ramme til at indarbejde flere niveauer sammenhænge for navngivet enhedsanerkendelse. Vi bruger TagLM som vores grundlæggende model til at fange sætningsniveau sammenhænge. For at indarbejde sammenhænge på dokumentniveau foreslår vi at indfange interaktioner mellem sætninger via et multi-head selvopmærksomhedsnetværk. For at mine ordniveau kontekster foreslår vi en hjælpeopgave til at forudsige typen af hvert ord for at fange dens typepræference. Vi træner i fællesskab vores model i enhedsgenkendelse og hjælpeklassifikationsopgave via multi-task learning. De eksperimentelle resultater på flere benchmark datasæt validerer effektiviteten af vores metode.', 'hr': 'Prepoznavanje imenovanih entiteta je kritičan zadatak u polju obrade prirodnog jezika. Većina postojećih metoda za ovaj zadatak može iskoristiti samo contextualne informacije unutar rečenice. Međutim, njihov učinkovit priznanja subjekta u ograničenim ili dvosmislenim kontekstima razine kazne obično je nezadovoljno. Srećom, druge rečenice u istom dokumentu mogu pružiti dodatne kontekste na razini dokumenta kako bi pomogla prepoznati te entitate. Osim toga, sami riječi sadrže kontekstske informacije na razini riječi jer obično imaju različite preferencije tipa entiteta i relativne pozicije od imenovanih entitata. U ovom papiru predlažemo jedinstveni okvir za uključivanje multiniverskih konteksta za priznanje imena entiteta. Koristimo TagLM kao osnovni model da uhvatimo kontekste na razini rečenica. Da bi uključili kontekste na nivou dokumenta, predlažemo da uhvatimo interakcije između rečenica kroz višeglavnu samopouzdanju mrežu. U mojim kontekstima na razini riječi predlažemo pomoćni zadatak za predviđanje vrsta svake riječi da uhvati svoju preferenciju tipa. Zajednički treniramo naš model u priznanju entiteta i pomoćnom klasifikacijskom zadatku putem multizadatačnog učenja. Eksperimentalni rezultati na nekoliko standardnih podataka potvrđuju učinkovitost našeg metoda.', 'nl': 'De herkenning van naamloze entiteiten is een cruciale taak in het verwerkingsveld van natuurlijke taal. De meeste bestaande methoden voor deze taak kunnen alleen contextuele informatie binnen een zin exploiteren. Hun prestaties bij het herkennen van entiteiten in beperkte of dubbelzinnige zinnenniveaus zijn echter meestal onbevredigend. Gelukkig kunnen andere zinnen in hetzelfde document aanvullende context op documentniveau bieden om deze entiteiten te herkennen. Bovendien bevatten woorden zelf contextuele informatie op woordniveau omdat ze meestal andere voorkeuren hebben voor entiteitstype en relatieve positie dan benoemde entiteiten. In dit document stellen we een uniform raamwerk voor om multi-level contexten voor benoemde entiteiten te integreren. We gebruiken TagLM als ons basismodel om contexten op zinsniveau vast te leggen. Om contexten op documentniveau te integreren, stellen we voor om interacties tussen zinnen vast te leggen via een multi-head self attention netwerk. Om contexten op woordniveau te analyseren, stellen we een hulptaak voor om het type van elk woord te voorspellen om de typevoorkeur vast te leggen. We trainen gezamenlijk ons model in entiteitsherkenning en de hulpclassificatietaak via multitask learning. De experimentele resultaten op verschillende benchmark datasets valideren de effectiviteit van onze methode.', 'de': 'Die Erkennung benannter Entitäten ist eine kritische Aufgabe im Bereich der Verarbeitung natürlicher Sprache. Die meisten vorhandenen Methoden für diese Aufgabe können nur Kontextinformationen innerhalb eines Satzes ausnutzen. Ihre Leistung bei der Erkennung von Entitäten in begrenzten oder mehrdeutigen Kontexten auf Satzebene ist jedoch in der Regel unbefriedigend. Glücklicherweise können andere Sätze im selben Dokument zusätzliche Kontexte auf Dokumentenebene bieten, um diese Entitäten zu erkennen. Darüber hinaus enthalten Wörter selbst kontextbezogene Informationen auf Wortebene, da sie normalerweise andere Präferenzen für Entitätstyp und relative Position als benannte Entitäten haben. In diesem Beitrag schlagen wir ein einheitliches Framework vor, um mehrstufige Kontexte für die Erkennung benannter Entitäten zu integrieren. Wir verwenden TagLM als unser grundlegendes Modell, um Zusammenhänge auf Satzebene zu erfassen. Um Kontexte auf Dokumentenebene zu integrieren, schlagen wir vor, Interaktionen zwischen Sätzen über ein mehrköpfiges Selbstaufmerksamkeitsnetzwerk zu erfassen. Um Kontexte auf Wortebene zu analysieren, schlagen wir eine Hilfsaufgabe vor, um den Typ jedes Wortes vorherzusagen, um seine Typpräferenz zu erfassen. Gemeinsam trainieren wir unser Modell in der Entitätenerkennung und der Hilfsklassifikationsaufgabe durch Multi-Task Learning. Die experimentellen Ergebnisse mehrerer Benchmark-Datensätze bestätigen die Wirksamkeit unserer Methode.', 'id': 'Pengenalan entitas bernama adalah tugas kritis dalam bidang proses bahasa alami. Kebanyakan metode yang ada untuk tugas ini hanya dapat mengeksploitasi informasi kontekstual dalam kalimat. Namun, pertunjukan mereka pada pengenal entitas dalam konteks tingkat kalimat terbatas atau ambigu biasanya tidak memuaskan. Untungnya, kalimat lain dalam dokumen yang sama dapat menyediakan konteks tambahan tingkat dokumen untuk membantu mengenali entitas ini. Selain itu, kata-kata sendiri mengandung informasi kontekstual tingkat kata karena mereka biasanya memiliki keutamaan yang berbeda dari tipe entitas dan posisi relatif dari entitas bernama. Dalam kertas ini, kami mengusulkan cadangan bersatu untuk memasukkan konteks multi-level untuk pengenalan entitas bernama. Kami menggunakan TagLM sebagai model dasar kami untuk menangkap konteks tingkat kalimat. Untuk mengikorporasi konteks tingkat dokumen, kami mengusulkan untuk menangkap interaksi antara kalimat melalui jaringan perhatian diri multi-kepala. To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference.  Kami bersama-sama melatih model kami dalam pengenalan entitas dan tugas klasifikasi bantuan melalui belajar multi-tugas. Hasil percobaan dari beberapa set data benchmark mengkvalifikasi efektif metode kita.', 'ko': '명명 실체 식별은 자연 언어 처리 분야의 관건적인 임무이다.대다수의 기존 방법은 문장 속의 상하문 정보만 이용할 수 있다.그러나 그들이 유한하거나 모호한 문장 차원에서 실체를 식별하는 표현은 보통 만족스럽지 않다.다행히도 같은 문서의 다른 문장은 이러한 실체를 식별하는 데 도움을 줄 수 있는 보충 문서 수준의 상하문을 제공할 수 있다.그 밖에 단어 자체는 단어급 상하문 정보를 포함한다. 왜냐하면 그들은 일반적으로 실체 유형과 상대적인 위치에 대한 선호가 명명된 실체와 다르기 때문이다.본고에서 우리는 통일된 구조를 제시하여 다단계 상하문을 결합시켜 명명 실체 식별을 한다.우리는 문장 차원의 상하문을 포착하기 위해 TagLM을 기본 모델로 사용했다.문서급 상하문을 통합시키기 위해서, 우리는 여러 개의 자기주의 네트워크를 통해 문장 간의 상호작용을 포착할 것을 건의합니다.단어급 상하문을 발굴하기 위해 우리는 모든 단어의 유형을 예측하여 그 유형의 선호도를 얻는 보조 임무를 제시했다.우리는 다중 임무 학습을 통해 우리의 실체 식별 모델과 보조 분류 임무를 연합하여 훈련한다.여러 개의 기준 데이터 집합에서의 실험 결과는 이 방법의 유효성을 검증했다.', 'fa': 'شناسایی عنوان نامیده یک کار مهمی در زمینه پرداخت زبان طبیعی است. بیشتر روش\u200cهای موجود برای این کار می\u200cتواند فقط اطلاعات موجود در یک جمله استفاده کند. ولی عملکرد آنها در مورد شناختن شرایط محدودیت یا محدودیت سطح مجازات معمولا غیر قابل توجه است. خوشبختانه، جمله\u200cهای دیگر در یک سند می\u200cتوانند شرایط سطح سند اضافه\u200cای را برای کمک به شناسایی این شرایط ارائه دهند. علاوه بر این، کلمات خودشان اطلاعات متوسط سطح کلمات را دارند، زیرا معمولاً ترجیح\u200cهای متفاوتی از نوع واحد و موقعیت نسبتی از واحدهای نامیده دارند. در این کاغذ، ما یک چهارچوب متحد را پیشنهاد می\u200cکنیم تا شرایط متحد برای شناسایی نامیده شده\u200cاند. ما از TagLM به عنوان مدل بنیادی ما استفاده می کنیم تا موضوع سطح جمله را بگیریم. برای شامل موضوع سطح سند، پیشنهاد می\u200cکنیم که تعاملات بین جمله\u200cها از طریق شبکه توجه خودش را از طریق یک شبکه متعدد سر خودش بگیریم. برای محیط\u200cهای سطح کلمه من، ما یک کار کمک پیشنهاد می\u200cکنیم تا نوع هر کلمه را پیش\u200cبینی کنیم تا ترجیح\u200cهای نوع آن را بگیریم. ما با همدیگر مدل خود را در تعلیم شناسایی اجتماعی و وظیفه\u200cای از طریق یادگیری چندین کار آموزش می\u200cدهیم. نتیجه آزمایشی روی چندین مجموعه\u200cهای داده\u200cهای نقشه\u200cبندی\u200cها فعالیت روش ما را تأیید می\u200cکنند.', 'sw': 'Kutambua entity jina ni kazi muhimu katika eneo la utaratibu wa lugha asilia. Njia nyingi zilizopo kwa kazi hii zinaweza kutumia taarifa za kawaida ndani ya hukumu. Hata hivyo, utendaji wao wa kutambua vifaa vinavyotokana na kiwango kikubwa cha hukumu kwa mara nyingi hauna uhakika. Kwa bahati nzuri, hukumu nyingine katika nyaraka hiyo inaweza kutoa mikutano ya kiangazi cha dokumentari ili kusaidia kutambua vitu hivi. Zaidi ya hayo, maneno yenyewe yanajumuisha taarifa za kiwango cha maneno kwa sababu mara nyingi huwa zina upendeleo tofauti wa aina ya entity na nafasi inayohusiana na vitu vinavyoitwa. Katika karatasi hii, tunapendekeza mfumo wa muungano wa kuingiza mikutano ya ngazi mbalimbali kwa jina la kutambua entity. Tunatumia TagLM kama mtindo wetu wa msingi wa kushika matatizo ya kiwango cha hukumu. Ili kuunganisha makubaliano ya kiwango cha dokumentari, tunapendekeza kukata mahusiano kati ya sentensi kupitia mtandao wa mitandao yenye mwangalizi. To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference.  Tunafundisha muundo wetu kwa pamoja katika kutambua taasisi na kazi ya usambazaji kwa njia ya kujifunza kwa kazi nyingi. Matokeo ya majaribio kwenye takwimu kadhaa za bendera yanathibitisha ufanisi wa njia yetu.', 'tr': 'Taýigry dil işleýän sahypalarda ady tanamak wajyplyg zady. Bu täblisaň iň kop bar yöntemleri diňe sözlem içinde moda maglumaty ulanyp biler. Ýöne, sözlem derejesinde yada ýok sözlem derejesinde tanamak üçin eserleşmeleri adatça çykarmaz. Gynansakda, bir senediň başga sözleriň bu soraglary tanamak üçin täze bir sened derejesini saýlap biler. Üstünde sözler özlerinde söz derejesi Kontrol maglumaty bar, sebäbi adatça bir faýlyň hili we gollaýyşyk möhümlikleriniň seçenekleri bar. Bu kagyzda, birnäçe dereje bir üns tanamak üçin birden bir çerçew teklip edip görýäris Tägleriň sözleriň derejesini ýazmak üçin esasy nusgasymyz hökmünde ullanýarys. Sened derejesi meňzeşdirmek üçin sözleriň arasynda bir multi-kelläp özüne üns berilýän netijesi görkezmegi teklip edýäris. Maňa söz derejesi meýdançalaryma, her sözüň seçeneklerini taýýarlamak üçin bir kömek täbligini önerdik. Biz nusgamyzy birnäçe-täbli tanamak we kömek taýýarlama täbligini birnäçe-täbli öwrenmek bilen birleşdirdik. Çeşitli benchmark veri setirlerinde synanyş netijesi biziň metodamyzyň etkinlik barlygyny barlaýar.', 'sq': 'Njohja e emëruar e njësisë është një detyrë kritike në fushën e procesimit natyror të gjuhës. Shumica e metodave ekzistuese për këtë detyrë mund të shfrytëzojnë vetëm informacionin kontekstual brenda një fjalimi. Megjithatë, shfaqja e tyre në njohjen e njësive në kontekste të kufizuara apo të ambiguara të nivelit të dënimeve është zakonisht e pakënaqur. Fatmirësisht, fjalë të tjera në të njëjtin dokument mund të ofrojnë kontekste shtesë në nivelin e dokumentit për të ndihmuar njohjen e këtyre njësive. Përveç kësaj, fjalët vetë përmbajnë informacion kontekstual të nivelit të fjalëve pasi ato zakonisht kanë preferenca të ndryshme të llojit të njësisë dhe pozitës relative nga njësitë e emëruara. Në këtë letër, propozojmë një kuadër të unifikuar për të përfshirë kontekste shumënivele për njohjen e emëruar të njësisë. Ne përdorim TagLM si modelin tonë bazë për të kapur kontekstet e nivelit të fjalëve. Për të përfshirë kontekstet e nivelit të dokumentit, ne propozojmë të kapim ndërveprimet midis fjalëve nëpërmjet një rrjeti shumë-kokësh vetëvëmendjeje. To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference.  Ne trajnojmë së bashku model in tonë në njohjen e njësisë dhe detyrën e klasifikimit ndihmës nëpërmjet mësimit me shumë detyra. Rezultatet eksperimentale në disa baza të dhënash vlerësojnë efektshmërinë e metodës sonë.', 'am': 'ቦታ ለዚህ ስራ የሚደረገውን አብዛኛዎቹ የሥርዓት መረጃዎችን በክፍል ውስጥ ብቻ ሊጠቀም ይችላል። ነገር ግን የሥርዓት ደረጃ ግንኙነታቸው በተቃራኒ ወይም በተጨማሪው የቁጥጥር ግንኙነት በመጠቀም የተሳሳተ ነው፡፡ በተሰፋ፣ በአንድ ሰነድ ውስጥ ያሉ ሌሎች ቃላት የጨዋታ ሰነድ-ደረጃ ግንኙነቶችን እንዲያስታውቁ ይችላል፡፡ በተጨማሪም፣ ቃላት ራሳቸው የቃላት-ደረጃ የአሁኑን መረጃ ይኖራል፡፡ በዚህ ፕሮግራም አካባቢ አካል ማውቀትን ለመቀበል የብዙ ደረጃዎች ጥቅምቶችን ለመቀበል እናሳስባታለን፡፡ የቁጥጥር ደረጃ ግንኙነቶችን ለመያዝ እናስጠጋለን፡፡ ሰነድ-ደረጃ ግንኙነቶችን ለማግባት፣ በብዙ ራስ-ራስ የራሱን ትኩረት መረብ በመካከል የፍርድ መካከል ግንኙነትን ለመያዝ እናዘጋጅታለን፡፡ ለቃላት-ደረጃ ግንኙነት፣ የዓይነት ምርጫውን ለመቀበል የቃላትን ዓይነት ለማንበብ እናስታውቃለን፡፡ ሞዴሌዎቻችንን በብዙ-ስራ ትምህርት በማድረግ እና የአግባር ትርፍን ስራ እናስተማራለን፡፡ የሞከሩ ውጤቶች በብዙ benchmark ዳታዎች የሥርዓታችንን ውጤት የሚያረጋግጥ ነው፡፡', 'af': "Genaamde entiteit herken is 'n kritiese taak in die natuurlike taal verwerking veld. Mees bestaande metodes vir hierdie taak kan slegs kontekslike inligting in 'n seting uitbrei. Maar hulle prestasie op herken van entiteite in beperkte of onbeperkte setvlak-konteks is gewoonlik onbevestig. Gelukkig, ander setings in dieselfde dokument kan supplementeerde dokumentvlak-konteks verskaf om hierdie entiteite te herken. In addition, words themselves contain word- level contextual information since they usually have different preferences of entity type and relative position from named entities. In hierdie papier voorstel ons 'n eenvoudige raamwerk om multivlak konteks te inkorpreer vir genoem entiteiterkenning. Ons gebruik TagLM as ons basiese model om sentence- level contexts te vang. Om dokumentvlak konteks te inkorporeer, voorstel ons om interaksies tussen setings deur 'n multikop self-aandagnetwerk te vang. Na myne woord-vlak kontekste, voorstel ons 'n hulpbruk taak om die tipe van elke woord te voorskou om sy tipe voorkeure te vang. Ons tref ons model saamgevoer in einditeiterkenning en die helplike klassifikasie taak deur multi-taak leer. Die eksperimentale resultate op verskeie benchmark datastelle waardig die effektiviteit van ons metode is.", 'hy': 'Նվանված էության ճանաչման կարևոր խնդիր է բնական լեզվի վերամշակման ոլորտում: Այս խնդրի համար գոյություն ունեցող մեթոդների մեծ մասը կարող է օգտագործել միայն կոնտեքստային տեղեկատվությունը նախադասության մեջ: Այնուամենայնիվ, նրանց արտադրողությունը սահմանափակ կամ երկիմաստ նախադասությունների մակարդակի կոնտեքստներում ճանաչող միավորների նկատմամբ սովորաբար բավարար չէ: Բարեբախտաբար, նույն փաստաթղթի այլ նախադասությունները կարող են ապահովել ավելացրական փաստաթղթի մակարդակի կոնտեքստներ, որոնք օգնում են ճանաչել այս առանձնահատկությունները: Ավելին, բառերը իրենք պարունակում են բառի մակարդակի կոնտեքստոնալ ինֆորմացիա, քանի որ նրանք սովորաբար ունեն անհատականության տեսակի և հարաբերական դիրքի տարբեր նախընտրություններ անվանված անհատականություններ In this paper, we propose a unified framework to incorporate multi-level contexts for named entity recognition.  Մենք օգտագործում ենք ՏագԼՄ-ը որպես հիմնական մոդել նախադասության մակարդակի կոնտեքստների նկարահանելու համար: Որպեսզի ներառենք փաստաթղթի մակարդակի կոնտեքստերը, մենք առաջարկում ենք վերցնել նախադասությունների միջև փոխազդեցությունը բազմագլխավոր եսաուշադրության ցանցի միջոցով: Իմ բառի մակարդակի կոնտեքստների համար մենք առաջարկում ենք օգնական խնդիր, որպեսզի կանխատեսենք յուրաքանչյուր բառի տեսակը, որպեսզի վերցնենք իր տիպի նախընտրությունը: Մենք միասին ուսուցանում ենք մեր մոդելը առանձնահատկությունների ճանաչելու և դասակարգման օգտակար խնդիրների միջոցով: Բազմաթիվ համեմատային տվյալների համակարգերի փորձարկման արդյունքները ստուգում են մեր մեթոդի արդյունավետությունը:', 'az': "Adlı entitə tanıması təbiətli dil işləmə sahəsində kritik bir işdir. Bu işin ən çox mevcut metodları ancaq cümlənin içində müxtəlif məlumatları istifadə edə bilər. Lakin, həmin cümlələr səviyyəsində və ya müəyyən təsirlərində tanıdıqları məhsullarda onların performansı genellikle dəyişiklikdir. Necə ki, aynı belədəki başqa cümlələr bu növlərin tanımasına kömək edə bilər. Üstəlik, sözlər özlərində söz-seviyyəti müxtəlif məlumatlar barəsindədir, çünki onlar genellikle ünvanların növü və növ növlərindən müxtəlif məlumatları vardır. Bu kağızda, bizə çoxlu səviyyə müxtəlif məlumatları təyin etmək üçün birləşdirilmiş bir framework təklif edirik. Biz TagLM'i cümlələr səviyyəsi müxtəliflərini almaq üçün əsas modellərimiz olaraq istifadə edirik. Dökümət səviyyəsi müxtəlif məlumatları birləşdirmək üçün, cümlələr arasında çoxlu başlıq təhlükəsizlik şəbəkəsi vasitəsilə təşkil etmək üçün təklif edirik. Mənim söz-seviyyətim müxtəliflərə, hər sözün növünün seçimlərini almaq üçün yardımcı bir iş təklif edirik. Biz modellərimizi bir çox iş öyrənməsi vasitəsilə təhsil edirik. Bir neçə benchmark veri qurularında eksperimentli sonuçlar metodumuzun etkinliğini təsdiqləyir.", 'bn': 'প্রাকৃতিক ভাষা প্রক্রিয়ার ক্ষেত্রে নামের বস্তুর স্বীকৃতি একটি গুরুত্বপূর্ণ কাজ। এই কাজের বেশীরভাগ বিদ্যমান পদ্ধতি শুধুমাত্র একটি বাক্যের মধ্যে প্রাক্তন তথ্য ব্যবহার করতে পারে। তবে সীমিত বা বিচ্ছিন্ন স্তরের বিভিন্ন প্রতিযোগিতায় স্বীকৃতি প্রদর্শনের প্রভাব সাধারণত ব্যবস্থার ব্যাপারে অস সৌভাগ্যবান, একই নথিতে অন্যান্য বাক্য এই বস্তুগুলোকে চিনতে সাহায্য করার জন্য সাহায্য করতে পারে। এছাড়াও, শব্দের নিজেদের মধ্যে শব্দ-স্তরের প্রতিক্রিয়া তথ্য রয়েছে যেহেতু সাধারণত ত তাদের বস্তুর ধরনের বিভিন্ন প এই কাগজটিতে আমরা একটি একত্রিত ফ্রেম প্রস্তাব করছি যাতে নামের বস্তুর স্বীকৃতির জন্য বহ-স্তরের প্রতিযোগিতায় অন্তর্ভু আমরা ট্যাগ এলএমকে আমাদের মৌলিক মডেল হিসেবে ব্যবহার করি শাস্তি স্তরের প্রতিযোগিতা গ্রহণের জন্য। ডকুমেন্ট-স্তরের প্রতিযোগিতা অন্তর্ভুক্ত করার জন্য আমরা প্রস্তাব করছি বহুমাধ্যমের আত্মমনোযোগ নেটওয়ার্কের মাধ্যমে এই ব আমার শব্দ-স্তরের প্রতিযোগিতার জন্য আমরা প্রস্তাব করছি যে প্রত্যেক শব্দের ধরনের পছন্দ গ্রহণ করার জন্য। আমরা একসাথে আমাদের মডেল প্রশিক্ষণ করি প্রতিষ্ঠানের স্বীকৃতি এবং অনেক কাজের শিক্ষার মাধ্যমে অনুগ্রহের ক্লাসাফিকে কয়েকটি বেনকম্যার্ক ডাটাসেটের পরীক্ষার ফলাফল আমাদের পদ্ধতির কার্যক্রম বৈধ করে।', 'ca': "El reconeixement d'una entitat anomenada és una tasca crítica en el camp del processament natural de llenguatges. La majoria dels mètodes existents per a aquesta tasca només poden explotar la informació contextual dins una frase. No obstant això, la seva actuació en reconèixer entitats en contextes limitats o ambiguos de nivell de frases normalment no és satisfactòria. Afortunadament, altres frases del mateix document poden proporcionar contextes complementars a nivell de documents per ajudar a reconèixer aquestes entitats. A més, les paraules mateixes contenen informació contextual a nivell de paraules, ja que normalment tenen diferents preferències del tipus d'entitat i la posició relativa dels nombrats. En aquest paper, proposem un marc unificat per incorporar contextos a molts nivells per al reconeixement d'entitats anomenades. Utilitzem TagLM com el nostre model bàsicper capturar contextes de nivell de frases. Per incorporar contextes a nivell documental, proposem capturar interaccions entre frases a través d'una xarxa d'autoatenció multicapa. Al meu contexte de nivell de paraules, proposem una tasca auxiliar de predir el tipus de cada paraula per capturar la seva preferència. Ens entrenem junts en el reconeixement d'entitats i la tasca de classificació auxiliar mitjançant aprenentatge multitascat. Els resultats experimentals de diversos conjunts de dades de referència validen l'eficacia del nostre mètode.", 'cs': 'Rozpoznávání pojmenovaných entit je kritickým úkolem v poli zpracování přirozeného jazyka. Většina existujících metod pro tento úkol může využít pouze kontextové informace v rámci věty. Nicméně jejich výkon při rozpoznávání entit v omezených nebo nejednoznačných kontextech na úrovni vět je obvykle neuspokojivý. Naštěstí jiné věty ve stejném dokumentu mohou poskytnout doplňkové kontexty na úrovni dokumentu, které pomohou rozpoznat tyto entity. Kromě toho samotná slova obsahují kontextové informace na úrovni slova, protože obvykle mají odlišné preference typu entity a relativní pozice od pojmenovaných entit. V tomto článku navrhujeme jednotný rámec pro začlenění víceúrovňových kontextů pro rozpoznávání pojmenovaných entit. Používáme TagLM jako náš základní model pro zachycení kontextů na úrovni věty. Pro začlenění kontextů na úrovni dokumentů navrhujeme zachytit interakce mezi větami prostřednictvím vícehlavé sítě sebepozornosti. Pro dolování kontextů na úrovni slov navrhujeme pomocný úkol, který předpovídá typ každého slova, aby zachytil jeho preferenci typu. Společně trénujeme náš model v oblasti rozpoznávání entit a pomocné klasifikační úlohy prostřednictvím víceúlohového učení. Experimentální výsledky na několika referenčních datových sadách potvrzují efektivitu naší metody.', 'bs': 'Prepoznavanje imenovanih entiteta je kritičan zadatak u oblasti obrade prirodnog jezika. Većina postojećih metoda za ovaj zadatak može iskoristiti samo contextualne informacije unutar rečenice. Međutim, njihov učinkovit priznanja subjekta u ograničenim ili dvosmislenim kontekstima razine kazne obično je nepristojljiv. Srećom, druge rečenice u istom dokumentu mogu pružiti dodatne kontekste na nivou dokumenta kako bi pomogla prepoznati te entitate. Osim toga, sami riječi sadrže kontekstske informacije na razini riječi jer obično imaju različite preferencije tipa entiteta i relativne pozicije od imenovanih entitata. U ovom papiru predlažemo jedinstveni okvir za uključenje multiniverskih konteksta priznanja entiteta. Koristimo TagLM kao osnovni model da uhvatimo kontekste na nivou kazne. Da bi uključili kontekste na nivou dokumenta, predlažemo da uhvatimo interakcije između rečenica preko višeglavne samopouzdane mreže. U mojim kontekstima na nivou riječi predlažemo pomoćni zadatak da predvidimo vrstu svake riječi da uhvati svoju preferenciju tipa. Zajednički treniramo naš model u priznanju entiteta i pomoćnom klasifikacijskom zadatku putem multi task učenja. Eksperimentalni rezultati na nekoliko standardnih podataka potvrđuju učinkovitost našeg metoda.', 'et': 'Nimetatud olemi tuvastamine on looduskeele töötlemise valdkonnas kriitiline ülesanne. Enamik olemasolevaid meetodeid selle ülesande jaoks saab kasutada ainult lause kontekstiteavet. Kuid nende tulemused üksuste tunnustamisel piiratud või ebaselges lausetasemel kontekstis on tavaliselt ebarahuldavad. Õnneks võivad teised laused samas dokumendis pakkuda täiendavaid dokumenditasemel kontekste, mis aitavad neid üksusi ära tunda. Lisaks sisaldavad sõnad ise sõnatasemel kontekstiteavet, kuna neil on tavaliselt erinevad olemitüübi ja suhtelise positsiooni eelistused nimetatud olemitest. Käesolevas dokumendis pakume välja ühtse raamistiku, mis hõlmab mitmetasandilisi kontekste nimetatud üksuste tunnustamiseks. Me kasutame TagLM-i oma põhimudelina lausetaseme kontekstide jäädvustamiseks. Dokumenditasemel kontekstide kaasamiseks teeme ettepaneku jäädvustada lausete vahelisi interaktsioone mitmepealise enesetähelepanuvõrgu kaudu. Sõnatasemel kontekstide kaevandamiseks pakume välja abiülesande iga sõna tüübi prognoosimiseks, et jäädvustada selle tüübi eelistus. Koolitame ühiselt oma mudelit üksuste tunnustamise ja lisaklassifitseerimise ülesande kaudu mitme ülesandega õppimise kaudu. Mitme võrdlusandmekogumi katsetulemused kinnitavad meie meetodi efektiivsust.', 'fi': 'Nimetty entiteetti tunnistus on kriittinen tehtävä luonnollisen kielen käsittelykentällä. Useimmat olemassa olevat menetelmät tähän tehtävään voivat hyödyntää vain kontekstitietoa lauseessa. Niiden suorituskyky entiteettien tunnistamisessa rajoitetuissa tai epäselvissä lausetason yhteyksissä on kuitenkin yleensä epätyydyttävä. Onneksi saman asiakirjan muut lauseet voivat tarjota täydentäviä dokumenttitason konteksteja näiden kokonaisuuksien tunnistamiseksi. Lisäksi sanat itsessään sisältävät sanatason kontekstitietoa, koska niillä on yleensä eri mieltymykset entiteetin tyypistä ja suhteellisesta sijainnista kuin nimetyillä entiteeteillä. Tässä artikkelissa ehdotamme yhtenäistä kehystä, jolla yhdistetään monitasoiset kontekstit nimettyjen yhteisöjen tunnistamiseen. Käytämme TagLM:tä perusmallina lausetason kontekstien kuvaamiseen. Asiakirjatason kontekstien sisällyttämiseksi ehdotamme lauseiden välistä vuorovaikutusta monipäisen itsepalveluverkoston kautta. Sanatason kontekstien kaivamiseksi ehdotamme aputehtävää, jonka avulla voidaan ennustaa kunkin sanan tyyppi sen tyyppimieltymyksen tallentamiseksi. Koulutamme yhdessä malliamme kokonaisuuksien tunnistamisessa ja apuluokittelutehtävässä monitehtäväoppimisen kautta. Useiden vertailuaineistojen kokeelliset tulokset vahvistavat menetelmämme tehokkuuden.', 'he': "זיהוי ישות בשם הוא משימה קריטית בשדה עיבוד שפה טבעי. רוב השיטות הקיומות למשימה הזאת יכולות לנצל רק מידע קונטקסטי בתוך משפט. בכל אופן, ההופעה שלהם על זיהוי יחידות בתוך קשרים גבוהים או סבירים ברמת המשפטים בדרך כלל לא מספקת. Fortunately, other sentences in the same document can provide supplementary document-level contexts to help recognize these entities.  בנוסף, המילים עצמן מכילות מידע קונטקסטי רמה מילים מאחר שיש להם בדרך כלל עדיפות שונות של סוג יחידה ומיקום יחסי מאנשים בשם. בעיתון הזה, אנו מציעים מסגרת מאוחדת לכלול קשרים רבים רמה לזיהוי ישויות בשם. אנחנו משתמשים בטאג'ל-אם כמודל בסיסי שלנו כדי לתפוס קשרים רמת המשפט. כדי להכיל קשרים ברמה המסמכים, אנחנו מציעים לתפוס אינטראקציות בין משפטים דרך רשת תשומת לב עצמית רבה ראשים. כדי לקונקסטים ברמה מילים שלי, אנחנו מציעים משימה עזרית לחזות את סוג כל מילה כדי לתפוס את העדיפות הטיפוס שלה. אנחנו מאמן יחד את המודל שלנו בזיהוי היחידות ומשימת ההקלטה העוזרת באמצעות לימוד ממשימים רבים. התוצאות הניסיוניים על מספר קבוצות נתונים רמזים מאשרים את היעילות של השיטה שלנו.", 'sk': 'Prepoznavanje imenovanih entitet je ključna naloga na področju obdelave naravnega jezika. Večina obstoječih metod za to opravilo lahko izkoristi le kontekstne informacije v stavku. Vendar pa je njihova uspešnost pri prepoznavanju subjektov v omejenih ali dvoumnih kontekstih na ravni stavka običajno nezadovoljiva. Na srečo lahko drugi stavki v istem dokumentu zagotovijo dodatne kontekste na ravni dokumenta, ki pomagajo prepoznati te entitete. Poleg tega besede same vsebujejo kontekstualne informacije na ravni besede, saj imajo običajno različne preference glede vrste entitete in relativnega položaja od imenovanih entitet. V tem prispevku predlagamo enoten okvir za vključitev večstopenjskih kontekstov za priznavanje imenovanih subjektov. TagLM uporabljamo kot osnovni model za zajemanje kontekstov na ravni stavka. Za vključitev kontekstov na ravni dokumenta predlagamo zajemanje interakcij med stavki prek mreže samopozornosti z več glavami. Za iskanje kontekstov na ravni besed predlagamo pomožno nalogo za predvidevanje vrste vsake besede, da zajamemo njeno tipsko preferenco. Naš model skupaj usposabljamo na področju prepoznavanja entitet in pomožne klasifikacijske naloge preko večopravilnega učenja. Eksperimentalni rezultati na več referenčnih naborih podatkov potrjujejo učinkovitost naše metode.', 'ha': "Sunan sunan shaidar abun shine wani aikin mai muhimmi a cikin filin aiki na fassarar harshen. Babu ƙayyade shiryoyin da ke jira wa wannan aikin, za'a iya amfani da amfani da macalli ɗin da ke cikin wata azãba kawai. A lokacin da, gyaransu a kan ganin abubuwa masu cikin matsayin-daraja da ba'a ƙunci ba, ko kuma ba da saurãre ba, ɗammãnin bã ya kasancẽwa. Babu rabo, wasu kalmõmi da ke cikin dukkan takarda guda, za'a iya ƙara matsayin takardar-daraja da za'a taimakon su gane wannan abun. Da wannan, magana za'a ƙunsa da maɓallin tsari da ke cikin zane-daraja da ke cikin kwanan da a ƙulla su da wasu zaɓani na nau'in abun da matsayi masu danganta daga abun da aka sune. Ga wannan takardan, Munã buɗa wata firam mai haɗa ko da za'a haɗa matsayin-daraja masu cikin sunan sunan abun. Tuna amfani da TagLM kamar misalinmu na ƙari dõmin mu kãma matsayin-daraja. Dõmin ka shigar da takardar-daraja cikin takardar-daraja, muna buƙatan mu kãma interaction a tsakanin saurãren zuwa wani jerin masu nau'in-nau'i mai yawa. To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference.  Tuna sanar da misalinmu sami cikin kunyar gaskiyar abun da aikin lissafi masu inganci, a bayan karanta aiki masu yawa. Matarin jarrabai ne a kan data na bangon ayuka masu inganci da tsarin hanyarmu.", 'jv': 'Sampeyang Entire Gak bener Piye pernik-pernik sing isih sabanjuré kanggo nggawe task iki iso kelompok informasi contextual nang sabanjuré. politenessoffpolite"), and when there is a change ("assertivepoliteness Sampeyan, kabeh luwih-luwih sing wis ana ing dokumen sing berarti iso nggawe kontinut-kalih dokumen sing nyelehake kanggo nggarap entekake iki. politenessoffpolite"), and when there is a change ("assertivepoliteness Nanging mapang iki, kita supoyo nggawe sistem sing beraksi kanggo ngilanggar contextu multi-evel kanggo nambah layang Entire. We use tagLM as the basic model to Capture Jejaring text-tool-action Awakdhéwé nggawe modèl nang ngerasakno karo akeh pengguna-pengguna ngono nggawe layakno multi-task seneng pisan. Report translation bugs to <\\.\\.\\.>', 'bo': 'མིང་བཏགས་པའི་དབང་ཆ་རྟོགས་ནི་རང་བཞིན་གྱི་སྐད་རིགས་ལས་སྦྱོར་གསོའི་དོན་ལྟར་གལ་ཆེན་ཤིག་རེད། བྱ་འགུལ་འདིའི་ལྟ་བུའི་ལམ་ལུགས་ཆེ་ཤོས་ཀྱིས་ཚིག་ཡུན་གྱི་གནས་ཚུལ་གསལ་བཤད་གཅིག་ལས་སྤྱོད་ཐུབ། ཡིན་ནའང་། ཁོང་ཚོའི་ལས་འགན་སྡུད་དམ་འཛུགས་ཀྱི་ཚིག་རྟགས་གང་ཡང་ན་ཕན་ཚུན་གྱིས་རྟོགས་པ་སྣང་མེད། ཡིན་ནའང་སྤྲོ་བ་དེ་ལ་ཡིག་གེའི་ནང་གི་ཚིག་རྐང་གཞན་ཞིག་ནི་ཡིག་ཚན་འདི་རྟོགས་རྒྱུ་དང་ཁ་ཤས་བྱིན་ཐུབ་པ In addition, words themselves contain word-level contextual information since they usually have different preferences of entity type and relative position from named entities. ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་དབང་ཆ་རྟོགས་དང་མིང ང་ཚོས་དེ་གིས་ང་ཚོའི་རྨན་གཞི་མ་གཟུགས་རིས་ལ་ཚིག་རྟགས་གནས་ཚུལ་མངོན་འཆར་བྱེད་ཀྱི་ཡོད། ཡིག་གེའི་གནས་ཚུལ་འདུག་དང་མཉམ་དུ་ཡོད་པའི་སྣ་ཚོགས་རང་ཉིད་ཀྱི་དྲ་རྒྱ་སྟངས་ལ་འབྲེལ་བ་ཞིག་ཡོད་པ་དང་། ངའི་ཡི་གེའི་གནས་སྟངས་དང་ཁྱད་པར་དུ་འོང་ཚོས་རེ་བཞིན་པའི་རང་མོས་སྒྲིག་འགོད་རྗེས་སུ་གྲོགས་རམ་གྱི་ལས་འགན་ཞིག ང་ཚོས་མཐུན་གྱིས་དབུགས་ཤེས་ཀྱི་དཔེ་དབུགས་དང་རྒྱས་ཁབ་དབྱེ་སྟངས་ལ་བསྡད་ན་མང་ལས་སྦྱོར་བྱེད་ཀྱི་ཡོད། ངག་ཚོའི་ཐབས་ལམ་ལུགས་བྱ་འགུལ་གྱི་བརྟག་འགྲུལ་གྱི་གནད་སྡུད་ནང་གི་གྲངས་འབྱོར་མང་ཙམ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Generating Commonsense Explanation by Extracting Bridge Concepts from Reasoning Paths', 'pt': 'Gerando explicação de bom senso extraindo conceitos de ponte de caminhos de raciocínio', 'ar': 'توليد تفسير العموم عن طريق استخراج مفاهيم الجسر من مسارات التفكير', 'es': 'Generar una explicación de sentido común extrayendo conceptos puente de las rutas de razonamiento', 'fr': 'Générer une explication de bon sens en extrayant des concepts de pont à partir de trajectoires', 'ja': '推論パスから橋の概念を抽出して常識的な説明を生成する', 'zh': '取桥于理径以成常识性说', 'hi': 'तर्क पथ से ब्रिज अवधारणाओं को निकालकर कॉमनसेंस स्पष्टीकरण उत्पन्न करना', 'ru': 'Генерирование объяснения здравого смысла путем извлечения концепций мостов из путей мышления', 'ga': 'Míniú Commonsense a Ghiniúint trí Choincheapa Droichead a Bhaint as Cosáin Réasúnúcháin', 'el': 'Δημιουργία εξήγησης κοινής λογικής με την εξαγωγή εννοιών γεφυρών από μονοπάτια λογικής', 'ka': 'Name', 'hu': 'Általános magyarázat generálása hídkoncepciók kivonásával az észlelési útvonalakból', 'kk': 'Көпір концепцияларын сезім жолдарынан тарқату арқылы Commonsense түсініктемесін құру', 'mk': 'Генерирање на заедничко објаснување со извлекување на концептите на мостот од размислувачките патишта', 'it': 'Generare spiegazioni di commonsense estraendo concetti di ponte dai percorsi di ragionamento', 'ms': 'Generating Commonsense Explanation by Extracting Bridge Concepts from Reasoning Paths', 'lt': 'Bendro paaiškinimo sukūrimas ištraukiant tilto koncepcijas iš pagrįstų kelių', 'mn': 'Компаннесийн тодорхойлолт нь Хүүгийн Концепциудыг Reasoning Paths-аас гаргаж ирсэн', 'mt': 'Il-Ġenerazzjoni ta’ Spjegazzjoni Komuni bl-Estrazzjoni tal-Kunċetti tal-Pont minn Toroq ta’ Raġunar', 'pl': 'Generowanie wyjaśnień powszechnego sensu poprzez wyodrębnienie koncepcji mostu ze ścieżek rozumowania', 'ml': 'പാതകങ്ങളില്\u200d നിന്നും പുറത്തുകടക്കുന്ന പാലില്\u200d നിന്നും കോണ്\u200dസെന്\u200dസ് എക്സ്ലാനേഷന്\u200d സൃഷ്ടിക്കുന്നു', 'no': 'Lagar kommunisenske utklaring ved å pakka ut brig-konseptar frå årsakende baner', 'sr': 'Napravljanje objašnjenja Komunikacija izvlačenjem koncepta mosta iz različitih puteva', 'ro': 'Generarea explicațiilor de bun simț prin extragerea conceptelor de pod din căi de raționare', 'si': 'සම්බන්ධතාව ප්\u200dරකාශනය නිර්මාණය කරනවා බ්\u200dරිජ් සැකසුම් ප්\u200dරකාශනය', 'so': 'Generating Commonsence Explanation by Extracting Bridge Concepts from Reading Path', 'ur': 'کمنسنس واضح کی توضیح بنا رہی ہے کہ براڈ کنٹسپٹ کو رائسونینگ مسیروں سے نکالنے کے ذریعہ', 'sv': 'Generera Commonsense Förklaring genom att extrahera Bridge Concepts från förnuftsvägar', 'ta': 'பாதைகளிலிருந்து வெளியேறுதல் பாதைகளை வெளியேற்றுதலால் உருவாக்குகிறது', 'uz': 'Generating Commonsense Explanation by Extracting Bridge Concepts from Reasoning Paths', 'vi': 'Phát ngôn ngữ chung bằng cách tháo bỏ ý tưởng cầu từ các lối ra.', 'bg': 'Генериране на общоприето обяснение чрез извличане на мостови концепции от разумни пътища', 'hr': 'Generiranje objašnjenja Commonsense izvlačenjem koncepta mosta iz različitih puteva', 'da': 'Generere Commonsense forklaring ved at udtrække brobegreber fra fornuftsveje', 'nl': 'Het genereren van Commonsense Verklaring door brugconcepten uit redenerende paden te extraheren', 'de': 'Generierung von Commonsense Erklärungen durch Extrahieren von Brückenkonzepten aus Denkpfaden', 'id': 'Menjana Penjelasan Komunis dengan Ekstraksi Koncept Jembatan dari Jalan Menyebabkan', 'ko': '추리 경로에서 교량 개념을 추출하여 상식적인 해석을 만들다', 'fa': 'ایجاد توضیح کمونس توسط اخراج مفهوم پل از مسیرهای منطقی', 'sw': 'Kutengeneza Tamko la Mawasiliano na Kutengeneza Mipaka ya Kutoa Sauti Kutokea', 'tr': 'Köp Maýdançalary Çykarak bilen Commonsenes Explanation Bejer', 'af': 'Name', 'sq': 'Duke krijuar shpjegim të përbashkët duke nxjerrë konceptet e urës nga rruga e arsyetimit', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': "Հաճախ բացատրություն ստեղծելով' հանելով կամուրջի գաղափարները", 'bn': 'পাথ থ থেকে বের করা ব্রিজ কনসেপ্টের মাধ্যমে কমিনসেন্স এক্সপ্ল্যানেশন তৈরি করা হচ্ছে', 'az': 'Köprü Koncepsiyalarını Reasoning Yollarından Çıqaraq Commonsense Explanation yaradılır', 'bs': 'Generiranje objašnjenja Commonsense izvlačenjem koncepta mosta iz različitih puteva', 'ca': 'generant una explicació comú extraint conceptes de pont dels camí de raonament', 'cs': 'Generování vysvětlení obecného rozumu extrahováním mostových konceptů z cest rozumu', 'et': 'Üldmõistliku selgituse genereerimine sildade kontseptsioonide ekstraheerimise teedest', 'fi': 'Yleinen selitys poimimalla siltakonseptejä järkeilypoluista', 'jv': 'Daerah Keterahak Komunis', 'ha': 'KCharselect unicode block name', 'sk': 'Ustvarjanje splošne razlage s črpanjem konceptov mostov iz razumnih poti', 'he': 'יצירת הסבר משותף על ידי מחלץ מושג גשר ממסלולי הגיון', 'bo': 'Generating Commonsense Explanation by Extracting Bridge Concepts from Reasoning Paths'}
{'en': 'Commonsense explanation generation aims to empower the machine’s sense-making capability by generating plausible explanations to statements against commonsense. While this  task  is easy to human, the machine still struggles to generate reasonable and informative explanations. In this work, we propose a  method  that first extracts the underlying concepts which are served as bridges in the reasoning chain and then integrates these  concepts  to generate the final explanation. To facilitate the reasoning process, we utilize external commonsense knowledge to build the connection between a statement and the bridge concepts by extracting and pruning multi-hop paths to build a subgraph. We design a bridge concept extraction model that first scores the triples, routes the paths in the subgraph, and further selects bridge concepts with weak supervision at both the triple level and the concept level. We conduct experiments on the commonsense explanation generation task and our model outperforms the state-of-the-art baselines in both automatic and human evaluation.', 'ar': 'يهدف إنشاء تفسير المشاع إلى تمكين قدرة الآلة على صنع المعنى من خلال إنشاء تفسيرات معقولة للعبارات ضد المنطق. في حين أن هذه المهمة سهلة على الإنسان ، إلا أن الآلة ما زالت تكافح لتوليد تفسيرات معقولة وغنية بالمعلومات. في هذا العمل ، نقترح طريقة تقوم أولاً باستخراج المفاهيم الأساسية التي تعمل كجسور في سلسلة التفكير ثم تدمج هذه المفاهيم لتوليد التفسير النهائي. لتسهيل عملية التفكير ، نستخدم المعرفة الخارجية المنطقية لبناء اتصال بين العبارة ومفاهيم الجسر عن طريق استخراج وتقليم مسارات متعددة القفزات لبناء رسم بياني فرعي. نصمم نموذجًا لاستخراج مفهوم الجسر يقوم أولاً بتسجيل النقاط الثلاثية ، ويوجه المسارات في الرسم البياني الفرعي ، ويختار أيضًا مفاهيم الجسر بإشراف ضعيف على كل من المستوى الثلاثي ومستوى المفهوم. نجري تجارب على مهمة إنشاء التفسير المنطقي ويتفوق نموذجنا على أحدث خطوط الأساس في كل من التقييم التلقائي والبشري.', 'pt': 'A geração de explicação do senso comum visa fortalecer a capacidade de criação de sentido da máquina, gerando explicações plausíveis para declarações contra o senso comum. Embora essa tarefa seja fácil para humanos, a máquina ainda luta para gerar explicações razoáveis e informativas. Neste trabalho, propomos um método que primeiro extrai os conceitos subjacentes que servem como pontes na cadeia de raciocínio e depois integra esses conceitos para gerar a explicação final. Para facilitar o processo de raciocínio, utilizamos o conhecimento externo do senso comum para construir a conexão entre uma declaração e os conceitos de ponte, extraindo e podando caminhos de vários saltos para construir um subgrafo. Projetamos um modelo de extração de conceito de ponte que primeiro pontua as triplas, roteia os caminhos no subgrafo e seleciona conceitos de ponte com supervisão fraca tanto no nível triplo quanto no nível de conceito. Conduzimos experimentos na tarefa de geração de explicação de senso comum e nosso modelo supera as linhas de base de última geração em avaliação automática e humana.', 'es': 'La generación de explicaciones de sentido común tiene como objetivo potenciar la capacidad de la máquina de crear sentido mediante la generación de explicaciones plausibles para declaraciones en contra del sentido común. Si bien esta tarea es fácil de realizar, la máquina todavía tiene dificultades para generar explicaciones razonables e informativas. En este trabajo, proponemos un método que primero extrae los conceptos subyacentes que sirven como puentes en la cadena de razonamiento y luego integra estos conceptos para generar la explicación final. Para facilitar el proceso de razonamiento, utilizamos conocimiento de sentido común externo para construir la conexión entre una declaración y los conceptos puente extrayendo y podando rutas de múltiples saltos para construir un subgrafo. Diseñamos un modelo de extracción de conceptos de puente que primero califica los triples, recorre los caminos en el subgráfico y selecciona aún más los conceptos de puente con una supervisión débil tanto en el nivel triple como en el nivel de concepto. Llevamos a cabo experimentos sobre la tarea de generación de explicaciones de sentido común y nuestro modelo supera las líneas de base de última generación tanto en la evaluación automática como en la humana.', 'fr': "La génération d'explications de bon sens vise à renforcer la capacité de création de sens de la machine en générant des explications plausibles à des déclarations contraires au bon sens. Bien que cette tâche soit facile pour l'homme, la machine a encore du mal à générer des explications raisonnables et informatives. Dans ce travail, nous proposons une méthode qui extrait d'abord les concepts sous-jacents qui servent de ponts dans la chaîne de raisonnement, puis intègre ces concepts pour générer l'explication finale. Pour faciliter le processus de raisonnement, nous utilisons des connaissances externes de bon sens pour établir la connexion entre une instruction et les concepts de pont en extrayant et en supprimant les chemins multi-sauts pour créer un sous-graphe. Nous concevons un modèle d'extraction de concept de pont qui marque d'abord les triplets, achemine les chemins dans le sous-graphe, puis sélectionne les concepts de pont avec une faible supervision à la fois au niveau triple et au niveau du concept. Nous menons des expériences sur la tâche de génération d'explications de bon sens et notre modèle surpasse les niveaux de référence de pointe en matière d'évaluation automatique et humaine.", 'ja': 'コモンセンスの説明生成は、コモンセンスに対するステートメントに対して妥当な説明を生成することにより、マシンのセンスメイキング能力を強化することを目的としています。 このタスクは人間にとっては簡単ですが、機械は合理的で情報に富んだ説明を生み出すのに苦労しています。 この研究では、まず推論チェーンのブリッジとして機能する基礎となる概念を抽出し、それらの概念を統合して最終的な説明を生成する方法を提案します。 推論プロセスを容易にするために、外部の常識的な知識を利用して、サブグラフを構築するためにマルチホップパスを抽出および剪定することによって、ステートメントとブリッジコンセプトの間の接続を構築します。 まずトリプルスコアを作成し、サブグラフでパスをルーティングし、さらにトリプルレベルとコンセプトレベルの両方で監督が弱いブリッジコンセプトを選択するブリッジコンセプト抽出モデルを設計します。 私たちは、常識的な説明生成タスクの実験を行い、自動評価と人間評価の両方で、私たちのモデルは最先端のベースラインを上回っています。', 'zh': '常识性说生於生逆常之说以益机器知能。 虽易于人,机器难生理翔实之说。 先取推理链中为桥梁之基本概念,然后整合其概以成其说。 以便推理,外用常识,提取多跳径以构子图,而系于语桥接之间。 设一桥之概,先评分三元组,次于子图中路,次于三元组级次于弱桥。 常识性说生成实验,工评最先进基线。', 'ru': 'Генерация объяснений здравого смысла направлена на расширение возможностей машины по созданию смысла, генерируя правдоподобные объяснения утверждений против здравого смысла. Хотя эта задача легко для человека, машина все еще изо всех сил пытается генерировать разумные и информативные объяснения. В этой работе мы предлагаем метод, который сначала извлекает основополагающие концепции, которые служат мостами в цепочке рассуждений, а затем интегрирует эти концепции для получения окончательного объяснения. Чтобы облегчить процесс рассуждения, мы используем внешние знания здравого смысла для построения связи между утверждением и концепциями моста путем извлечения и обрезки многохоповых путей для построения подграфа. Мы разрабатываем модель извлечения концепции моста, которая сначала оценивает тройки, маршрутизирует пути в подграф, а затем выбирает концепции моста со слабым контролем как на тройном уровне, так и на уровне концепции. Мы проводим эксперименты по задаче генерации объяснений здравого смысла, и наша модель превосходит современные базовые линии как в автоматической, так и в человеческой оценке.', 'hi': 'Commonsense स्पष्टीकरण पीढ़ी का उद्देश्य CommonSense के खिलाफ बयानों के लिए प्रशंसनीय स्पष्टीकरण उत्पन्न करके मशीन की भावना बनाने की क्षमता को सशक्त बनाना है। जबकि यह कार्य मानव के लिए आसान है, मशीन अभी भी उचित और जानकारीपूर्ण स्पष्टीकरण उत्पन्न करने के लिए संघर्ष करती है। इस काम में, हम एक ऐसी विधि का प्रस्ताव करते हैं जो पहले अंतर्निहित अवधारणाओं को निकालती है जो तर्क श्रृंखला में पुलों के रूप में कार्य करती हैं और फिर अंतिम स्पष्टीकरण उत्पन्न करने के लिए इन अवधारणाओं को एकीकृत करती हैं। तर्क प्रक्रिया को सुविधाजनक बनाने के लिए, हम एक सबग्राफ बनाने के लिए मल्टी-हॉप पथों को निकालने और छंटाई करके एक बयान और पुल अवधारणाओं के बीच संबंध बनाने के लिए बाहरी कॉमनसेंस ज्ञान का उपयोग करते हैं। हम एक पुल अवधारणा निष्कर्षण मॉडल डिजाइन करते हैं जो पहले ट्रिपल स्कोर करता है, सबग्राफ में पथों को रूट करता है, और आगे ट्रिपल स्तर और अवधारणा स्तर दोनों पर कमजोर पर्यवेक्षण के साथ पुल अवधारणाओं का चयन करता है। हम कॉमनसेंस स्पष्टीकरण पीढ़ी कार्य पर प्रयोग करते हैं और हमारा मॉडल स्वचालित और मानव मूल्यांकन दोनों में अत्याधुनिक आधार रेखाओं को मात देता है।', 'ga': 'Tá sé mar aidhm ag giniúint mínithe Commonsense cumas ciallaithe an mheaisín a chumhachtú trí mhínithe sochreidte a ghiniúint ar ráitis in aghaidh tuiscint coiteann. Cé go bhfuil an tasc seo éasca don duine, tá an meaisín fós ag streachailt le mínithe réasúnta agus faisnéiseach a ghiniúint. Sa saothar seo, molaimid modh a bhainfidh amach ar dtús na bunchoincheapa a ndéantar freastal orthu mar dhroichid sa slabhra réasúnaíochta agus a chomhtháthaíonn na coincheapa sin ansin chun an míniú deiridh a ghiniúint. Chun an próiseas réasúnaíochta a éascú, bainimid úsáid as eolas ciallmhar seachtrach chun an nasc idir ráiteas agus na coincheapa droichead a thógáil trí chosáin il-hop a bhaint agus a bhearradh chun foghraf a thógáil. Dearaímid samhail eastósctha coincheap droichead a scórálann na triples ar dtús, a stiúrann na cosáin san fhoghraf, agus a roghnaíonn níos mó coincheapa droichead le maoirseacht lag ag an leibhéal triple agus ag an leibhéal coincheap araon. Déanaimid turgnaimh ar an tasc ginte míniú ciallmhar agus sáraíonn ár samhail na bunlínte úrscothacha i measúnú uathoibríoch agus daonna araon.', 'hu': 'A Commonsense magyarázat generálása célja, hogy erősítse a gép érzékelő képességét azáltal, hogy valószínű magyarázatokat generál a Commonsense kijelentésekre. Bár ez a feladat könnyű emberi számára, a gép még mindig igyekszik ésszerű és informatív magyarázatokat generálni. Ebben a munkában egy olyan módszert javasolunk, amely először kivonja a mögöttes fogalmakat, amelyek hidaként szolgálnak az érvelési láncban, majd integrálja ezeket a fogalmakat a végső magyarázat létrehozásához. Az érvelési folyamat megkönnyítése érdekében külső közérzeti ismereteket használunk arra, hogy kapcsolatot építsünk egy állítás és a hídkoncepciók között azáltal, hogy kiterjesszük és metszjük a multi-hop utakat egy algráf építéséhez. Olyan hídkoncepciós extrakciós modellt tervezünk, amely először a háromszorokat pontozza, irányítja az algráfiában lévő ösvényeket, továbbá gyenge felügyelettel választja ki a hídkoncepciókat mind a háromszoros, mind a koncepciószinten. Kísérleteket végzünk a józan értelmű magyarázat generálási feladatra és modellünk mind automatikus, mind emberi értékelésben felülmúlja a legkorszerűbb alapvető értékeket.', 'it': "La generazione di spiegazioni commonsense mira a potenziare la capacità di fare senso della macchina generando spiegazioni plausibili alle dichiarazioni contro il commonsense. Mentre questo compito è facile per l'uomo, la macchina fatica ancora a generare spiegazioni ragionevoli e informative. In questo lavoro, proponiamo un metodo che prima estrae i concetti sottostanti che sono serviti da ponti nella catena del ragionamento e poi integra questi concetti per generare la spiegazione finale. Per facilitare il processo di ragionamento, utilizziamo conoscenze esterne di senso comune per costruire la connessione tra una dichiarazione e i concetti di ponte estraendo e potando percorsi multi-hop per costruire un sottografo. Progettiamo un modello di estrazione del concetto di ponte che prima segna i tripli, instrada i percorsi nel sottografico e seleziona ulteriormente concetti di ponte con scarsa supervisione sia a livello triplo che a livello concettuale. Conduciamo esperimenti sul compito di generazione di spiegazioni di senso comune e il nostro modello supera le linee di base state-of-the-art sia nella valutazione automatica che umana.", 'lt': 'Bendros paaiškinimų sukūrimo tikslas – padidinti mašinos jutimo gebėjimą sukuriant patikimus paaiškinimus pareiškimams prieš bendrą supratimą. While this task is easy to human, the machine still struggles to generate reasonable and informative explanations.  Šiame darbe siūlome metodą, kuris pirmiausia ištrauks pagrindines sąvokas, kurios naudojamos kaip tiltai motyvavimo grandinėje, ir tuomet integruoja šias sąvokas, kad būtų pateiktas galutinis paaiškinimas. Siekdami palengvinti motyvavimo procesą, mes naudojame išorines bendrąsias žinias, kad sukurtume sąsają tarp pareiškimo ir tilto sąvokų ekstrahuodami ir susmulkindami daugiapakopius kelius, kad sukurtume paragramą. Mes sukuriame tilto koncepcijos ekstrahavimo model į, kuris pirmą kartą įvertina trigubus taškus, maršrutuoja kelius papunktyje ir toliau atrenka tilto koncepcijas su silpna priežiūra tiek trigubo lygio, tiek koncepcijos lygio. Atliekame eksperimentus dėl bendros suprantamos paaiškinimų kūrimo užduoties, o mūsų modelis, atlikdamas automatinį ir žmogaus vertinimą, viršija naujausias bazines linijas.', 'ka': 'საზოგადოებო განახსნა მიზეზია, რომ მაქსინის შესაძლებლობას გავაკეთოთ საზოგადოებო განახსნალებების შესაძლებლობა, რომელიც შექმნა შესაძლებლობელი განახსნალებების შე თუმცა ეს საქმე ადამიანისთვის ადამიანისთვის ადამიანისთვის ადამიანისთვის ადამიანი, მაქსინი უკვე ძალიან ძალიან ძალიან გავაკეთებს პარამეტურ ამ სამუშაოში, ჩვენ მინდომებით მეტი, რომელიც პირველად ექსტრუქტურებს ბაზეც კონფექტები, რომელიც ახალგაზრულებული წერტილის მოძლევებით და შემდეგ ეს კონფექტები ინტე რომელიც განსაზღვრებას პროცესის შესაძლებლობად, ჩვენ გამოყენებთ გარეშე საზოგადოებო ცნობიერებს, რომელიც გამოყენება განსაზღვრება და მოსტის კონფექტების შორის დაკავშირება, მრა ჩვენ მოვიყენებთ ბრიჯის კონცექტურის მოდელი, რომელიც პირველად სამჯერ წერდება, სამჯერ წერდება, სამჯერ წერდება სამჯერ და კონცექტურის კონცექტური კონცექტურების შესაძ ჩვენ ექსპერიმენტები გავაკეთებთ ჩვენი მოდელის დავაკეთებას და ჩვენი მოდელის გავაკეთებას არ გავაკეთებთ სამყარო სამყარო და ადამიანის გავაკეთებას.', 'el': 'Η παραγωγή εξηγήσεων κοινής λογικής στοχεύει στην ενδυνάμωση της ικανότητας δημιουργίας αισθήσεων της μηχανής δημιουργώντας αξιόπιστες εξηγήσεις σε δηλώσεις κατά της κοινής λογικής. Ενώ αυτό το έργο είναι εύκολο για τον άνθρωπο, η μηχανή εξακολουθεί να αγωνίζεται να δημιουργήσει λογικές και ενημερωτικές εξηγήσεις. Στην παρούσα εργασία, προτείνουμε μια μέθοδο που πρώτα εξάγει τις υποκείμενες έννοιες που χρησιμεύουν ως γέφυρες στην αλυσίδα συλλογισμού και στη συνέχεια ενσωματώνει αυτές τις έννοιες για να δημιουργήσει την τελική εξήγηση. Για να διευκολύνουμε τη διαδικασία συλλογισμού, χρησιμοποιούμε εξωτερική γνώση κοινής λογικής για να χτίσουμε τη σύνδεση μεταξύ μιας δήλωσης και των εννοιών γέφυρας με την εξαγωγή και το κλάδεμα μονοπατιών πολλαπλών λυκίδων για να χτίσουμε ένα υπογράφημα. Σχεδιάζουμε ένα μοντέλο εξαγωγής έννοιας γέφυρας που πρώτα βαθμολογεί τα τριπλάσια, δρομολογεί τις διαδρομές στο υπογράφημα και επιλέγει περαιτέρω έννοιες γέφυρας με αδύναμη εποπτεία τόσο στο τριπλό επίπεδο όσο και στο επίπεδο της έννοιας. Διεξάγουμε πειράματα σχετικά με την εργασία δημιουργίας εξηγήσεων κοινής λογικής και το μοντέλο μας ξεπερνά τις τελευταίες γραμμές βάσης τόσο στην αυτόματη όσο και στην ανθρώπινη αξιολόγηση.', 'mk': 'Генерацијата на заеднички објаснувања има за цел да ја зајакне смислената способност на машината со генерирање веројатни објаснувања за изјавите против заедничкиот согласност. Иако оваа задача е лесна за човек, машината сé уште се бори да создаде разумни и информативни објаснувања. Во оваа работа, предложуваме метод кој прво ги извадува основните концепти кои се служат како мостови во ланецот на размислување и потоа ги интегрира овие концепти за да го генерира конечното објаснување. За да го олесниме процесот на размислување, користиме надворешно заедничко знаење за да ја изградиме поврзаноста помеѓу изјавата и концептите на мостот преку извлекување и исцепување на патиштата со мултископ за изградба на субграф. Ние дизајнираме мост концепт на екстракција модел кој прво ги оценува тројните, ги патува патиштата во подграфот, и понатаму ги избира мостовите концепти со слаб надзор на тројното и концептното ниво. Ние спроведуваме експерименти на заедничката задача за генерација објаснувања и нашиот модел ги надминува најсовремените бази во автоматска и човечка проценка.', 'ms': 'Generasi penjelasan umum bertujuan untuk memungkinkan kemampuan pembuatan sens mesin dengan menghasilkan penjelasan yang dapat diterima kepada pernyataan terhadap commonsense. Sementara tugas ini mudah bagi manusia, mesin masih berjuang untuk menghasilkan penjelasan yang masuk akal dan maklumat. Dalam kerja ini, kami cadangkan kaedah yang pertama-tama mengekstrak konsep yang didasarkan yang dilayani sebagai jembatan dalam rantai alasan dan kemudian mengintegrasikan konsep-konsep ini untuk menghasilkan penjelasan akhir. Untuk memudahkan proses alasan, kami menggunakan pengetahuan luaran yang sama untuk membina sambungan antara pernyataan dan konsep jambatan dengan mengekstrak dan mencurahkan laluan multi-hop untuk membina subgraf. Kami merancang model ekstraksi konsep jambatan yang pertama mencetak tiga kali, melalui laluan dalam subgraf, dan lebih lanjut memilih konsep jambatan dengan pengawasan lemah pada kedua-dua tahap tiga dan tahap konsep. Kami melakukan eksperimen pada tugas generasi penjelasan umum dan model kami melampaui garis dasar state-of-the-art dalam penilaian automatik dan manusia.', 'kk': 'Компансиялық түсініктемелерді құру мақсатты машинаның сезімдік мүмкіндігін көпшілікті түсініктемелерді жасап, көпшілікті түсініктемелерді жасау үшін. Бұл тапсырма адамға оңай болғанда, машина оңай және мәліметтік түсініктерді құру үшін әлі күреседі. Бұл жұмыс ішінде, біріншіден негізгі концепцияларды көпірлеу тізімінде көпірлеу ретінде шығару және соңғы түсініктемелерді жасау үшін бұл концепцияларды біріктіру әдісін таңда Арақтыру процесін көмектесу үшін, біз бөлшекті құру үшін көп-хоп жолдарын тарту және көп-хоп жолдарын құру үшін сыртқы көпшілік мәліметтерді қолдану үшін қосылымды құру үші Біз көпшілік концепциясын шығару үлгісін құрамыз. Бірінші көпшілікті есептеп, субграфикадағы жолдарды жолдау және көпшілікті көпшілікті көпшілік концепцияларының Біз көпшілікті түсініктер тапсырмасын жасау және моделіміз автоматты және адамдардың оқиғаларының негізгі сызықтарын жасаймыз.', 'ml': 'കമോണ്\u200dസണ്\u200dസെന്\u200dസ് വിശദീകരിക്കുന്ന തലമുറയാണ് യന്ത്രത്തിന്\u200dറെ മനസ്സിലാക്കുന്നതിന്\u200dറെ ശക്തിയെ പ്രാപ്തിപ്പിക്കുന് ഈ ജോലി മനുഷ്യര്\u200dക്ക് എളുപ്പമാണെങ്കില്\u200d, യന്ത്രം ഇപ്പോഴും വിവരങ്ങളും വിശദീകരിക്കുന്ന വിശദീകരണങ്ങള്\u200d ഉണ്ടാ ഈ പ്രവര്\u200dത്തനത്തില്\u200d, ആദ്യം നമ്മള്\u200d ഒരു രീതിയില്\u200d നിര്\u200dദ്ദേശിക്കുന്നു. ആദ്യം അടിസ്ഥാനത്തെ ആശയങ്ങള്\u200d പുറത്തെടുക്കുന്നു. അതിന്റെ കാര്യം കാ കാര്യങ്ങളുടെ പ്രക്രിയയെ സുരക്ഷിതമാക്കാന്\u200d ഞങ്ങള്\u200d പുറത്തുള്ള കമ്മോണ്\u200dസണ്\u200dസിന്\u200dറെ അറിവ് ഉപയോഗിക്കുന്നു. ഒരു പ്രസ്താവിക്കും പാലിന്\u200dറെ ആശയങ്ങളും  നമ്മള്\u200d ഒരു പാലത്തിന്റെ ആദ്യം പുറത്തുവരുത്തുന്ന മാതൃകയെ നിര്\u200dമ്മിക്കുന്നു. അത് മൂന്ന് നിലയില്\u200d മാറ്റുന്നു, സബ്ഗ്രാഫിലെ വഴികളിലേക്ക് നയിക്കുന നമ്മള്\u200d കമോണ്\u200dസണ്\u200dസ് വിശദീകരിക്കുന്ന ജോലിയില്\u200d പരീക്ഷണങ്ങള്\u200d നടത്തുന്നു. നമ്മുടെ മോഡല്\u200d സ്വയമായിക്കൊണ്ടും മനുഷ്യന്\u200d വിശദീകരണത്', 'mt': 'Il-ġenerazzjoni ta’ spjegazzjonijiet komuni għandha l-għan li tagħti s-setgħa lill-kapaċità tat-tfassil tas-sensi tal-magna billi tiġġenera spjegazzjonijiet plawżibbli għad-dikjarazzjonijiet kontra l-kunsens komuni. Filwaqt li dan il-kompitu huwa faċli għall-bniedem, il-magna xorta tiġġieled biex tiġġenera spjegazzjonijiet raġonevoli u informativi. F’dan ix-xogħol, qed nipproponu metodu li l-ewwel jastrezzjona l-kunċetti sottostanti li huma serviti bħala pontijiet fil-katina tar-raġunament u mbagħad jintegra dawn il-kunċetti biex tiġġenera l-ispjegazzjoni finali. Biex jiġi ffaċilitat il-proċess ta’ raġunament, a ħna nużaw għarfien komuni estern biex nibnu l-konnessjoni bejn dikjarazzjoni u l-kunċetti tal-pont billi nistraħħu u niprunaw mogħdijiet b’ħafna ħops biex nibnu sottografu. Aħna niddisinjaw mudell ta’ estrazzjoni tal-kunċett tal-pont li l-ewwel jikklassifika t-tripli, nirregolaw il-mogħdijiet fis-sottografu, u nagħżlu aktar kunċetti tal-pont b’superviżjoni dgħajfa kemm fil-livell tat-tripli kif ukoll fil-livell tal-kunċett. Aħna nagħmlu esperimenti dwar il-kompitu komuni ta’ ġenerazzjoni ta’ spjegazzjonijiet u l-mudell tagħna jwettaq il-linji bażi l-aktar avvanzati kemm f’evalwazzjoni awtomatika kif ukoll umana.', 'pl': 'Generowanie wyjaśnień zdrowego sensu ma na celu wzmocnienie zdolności maszyny do tworzenia zmysłów poprzez generowanie wiarygodnych wyjaśnień do stwierdzeń przeciwko zdrowemu rozsądkowi. Chociaż to zadanie jest łatwe dla człowieka, maszyna wciąż zmaga się z generowaniem rozsądnych i informacyjnych wyjaśnień. W niniejszej pracy proponujemy metodę, która najpierw ekstraktuje podstawowe pojęcia, które służą jako mosty w łańcuchu rozumowania, a następnie integruje te pojęcia w celu wygenerowania końcowego wyjaśnienia. Aby ułatwić proces rozumowania, wykorzystujemy zewnętrzną wiedzę zdrowego rozsądku do zbudowania połączenia między oświadczeniem a koncepcjami mostu poprzez ekstrakcję i przycinanie ścieżek multi-hop w celu zbudowania podgrafu. Projektujemy model ekstrakcji koncepcji mostu, który najpierw ocenia potrójniki, kieruje ścieżki w podgrafie, a następnie wybiera koncepcje mostu o słabym nadzorze zarówno na poziomie potrójnym, jak i koncepcyjnym. Przeprowadzamy eksperymenty nad zadaniem generowania wyjaśnień zdrowego rozsądku, a nasz model przewyższa najnowocześniejsze linie podstawowe zarówno w automatycznej, jak i ludzkiej ocenie.', 'ro': 'Generarea explicațiilor Commonsense își propune să îmbunătățească capacitatea de a face simțuri a mașinii prin generarea de explicații plauzibile pentru declarațiile împotriva bunului sens. Deși această sarcină este ușoară pentru om, mașina încă se luptă să genereze explicații rezonabile și informative. În această lucrare, propunem o metodă care extrage mai întâi conceptele de bază care sunt servite ca punți în lanțul de raționament și apoi integrează aceste concepte pentru a genera explicația finală. Pentru a facilita procesul de raționament, utilizăm cunoștințe externe de bun simț pentru a construi conexiunea dintre o declarație și conceptele de pod prin extragerea și tăierea căilor multi-hop pentru a construi un subgraf. Proiectăm un model de extracție a conceptului de pod care punctează mai întâi triplele, trasează traseele din subgraf și selectează în continuare conceptele de pod cu supraveghere slabă atât la nivelul triplu, cât și la nivelul conceptului. Realizăm experimente cu privire la sarcina de generare a explicațiilor de bun sens și modelul nostru depășește liniile de bază de ultimă oră atât în evaluarea automată, cât și în cea umană.', 'sr': 'Generacija objašnjenja zajednica cilja je da omogućava sposobnost izrade smisla mašine stvaranjem uvjerljivih objašnjenja izjavama protiv zajedničkog smisla. Iako je ovaj zadatak lak za ljude, mašina se i dalje bori za stvaranje razumnih i informativnih objašnjenja. U ovom poslu predlažemo metodu koja prvo izvlači temeljne koncepte koje su služene kao mostove u lancu razumevanja i onda integriše te koncepte kako bi stvorili konačno objašnjenje. Da bismo olakšali razumni proces, iskoristili smo spoljne znanje zajedničkog smisla da izgradimo vezu između izjave i koncepta mosta izvlačimo i pružimo multihopske puteve da izgradimo podgraf. Mi dizajniramo model izvlačenja mosta koji prvi put rezultira tri puta, putuje puteve u podgrafu, i dalje odabere koncept mosta sa slabim nadzorom na trostrukom nivou i nivou koncepta. Mi provodimo eksperimente o zadatku generacije objašnjenja zajedničkog smisla i naš model iznosi stanje umjetničkih osnovnih linija u automatskoj i ljudskoj procjeni.', 'mn': 'Нийгмийн тодорхойлолтын төгсгөл нь машины мэдрэмжлэх чадварыг ихэвчлэн ойлголтын эсрэг тодорхойлолтыг бий болгоход хүргэж байна. Энэ ажил хүн төрөлхтний хувьд амархан хэдий ч машин ойлгомжтой, мэдээллийн тодорхойлолтуудыг бий болгохын тулд хичээдэг. Энэ ажил дээр бид эхлээд суурь ойлголтыг шилжүүлэх арга зам гаргаж, дараа нь эдгээр ойлголтыг сүүлийн тодорхойлолт үүсгэхийн тулд нэгтгэдэг. Учир шалтгааны үйл явцыг амжилттай болгохын тулд бид илтгэл болон хөлөг ойлголтын хоорондын холбоотой байдлыг ашиглаж, олон холбоотой замыг суурь график бүтээхээр хэрэглэдэг. Бид түрүүнд гурван дахь тоонуудыг тооцоолж, гурван дахь замыг загвар руу шилжүүлж, гурван дахь хэмжээст, ойлголтын түвшинд сул хязгаарлагдсан хөлөг ойлголтыг сонгож байна. Бид ерөнхийдөө ойлголттой тодорхойлолтын даалгаварын тухай туршилт хийдэг. Бидний загвар нь автоматик болон хүн төрөлхтний оюутнуудын төвшин суурь шугамнуудыг автоматжуулах боломжтой.', 'so': "Qorshaha furashada heshiiska waxaa loola jeedaa in uu xoogeeyo awoodda sameynta maskinenta, marka uu soo saaro fasax faa'iido ah oo ka gees ah shirkadda. Inta ay shaqadaas dadka u fudud tahay, mashiinku weli wuxuu u dagaalamaa inuu soo saaro fasax caqli ah oo macluumaad leh. Markaas waxan, waxaynu soo jeedinnaa qaab ay marka hore ka soo saaraan fikrada hoose ee lagu isticmaalo silsiladda sababta ah, kadibna waxaynu isku daynaa fikradan si uu u sameeyo fasirka ugu dambeeya. Si aynu u fududayno baaritaanka sababta ah, waxaynu isticmaalnaa aqoonta dibadda ah si aan u dhisno xiriirka u dhexeeya hadal iyo fikrada darafka, si aan u soo bixino wadooyin badan oo aad u baahan karno dhisid submarin. Waxaynu sawirannaa model qalabka ka soo bixinta, kaasoo marka ugu horeysa isku qiimeeya saddexda, waddooyinkana koobsiga ku socota, kadibna waxaan kaloo dooranaynaa fikrada darafka darafka iyo darafka saxda. Waxaannu sameynaa imtixaan ku saabsan shaqada farshaxanka, qaababkayagana wuxuu ka muujiyaa qoraalka farshaxanka, si gaar ah iyo qiimeynta dadka.", 'no': 'Generasjonen av kommunikasjonskildringar måtar å styra maskinen sin følelseskapasitet ved å laga tilgjengelege forklaringar til uttaler mot fellesskap. Mens denne oppgåva er lett for menneske, kjem maskina framleis til å laga raskt og informativt forklaringar. I denne arbeiden foreslår vi ein metode som først ekstraherer dei underliggende konseptane som vert kalla som brøg i sambandkjeden og så integrerer desse konseptane for å laga den siste forklaringa. For å gjera det lett å forstå rasjonsprosessen, bruker vi eksterne vanskeleg kunnskap for å bygge tilkoplinga mellom eit uttrykk og brøkkonsept ved å ekstrahera og trekke fleire hoppsruter for å bygge ein undergraf. Vi design ein modul for ekstraksjon av brig-konsept som først skal rekna ut trekantane, ruter banene i undergrafen, og vel fleire brig-konseptar med slag oversikt på både trekantnivået og konseptnivået. Vi gjer eksperimenter på den vanlege utklaringsoppgåva og modellen vårt utfører baselinjene i både automatisk og menneskelig evaluering.', 'ta': 'பொருள் விளக்கம் தலைமுறை இயந்திரத்தின் உணர்வு உருவாக்கும் சக்தியை உருவாக்குவதற்கு தெரியும். இந்த செயல் மனிதனுக்கு எளிதாக இருக்கும் போது, இயந்திரம் இன்னும் விளக்கங்களை உருவாக்க முயற்சிக்கிறது. இந்த வேலையில், நாம் முதலில் அடிப்படையான கருத்துக்களை வெளியேற்றும் முறையை முறைமையாக நினைவிக்கிறோம். பின்னர் குறிப்பிடும் சங்க நாம் வெளிப்புற அறிவை பயன்படுத்தி ஒரு கூற்று மற்றும் பால் கருத்துக்களுக்கும் இடையே இணைப்பை உருவாக்க பயன்படுத்துகிறோம் மற்றும் பல- hop பாதைகளை வ நாம் பால் கண்டுபிடிப்பு மாதிரி வடிவமைக்கிறோம் அது முதலில் முன்னோட்டங்களை மதிப்பெடுக்கும், துணை வரைபடத்தில் பாதைகளை செலுத்தும், மற்றும் மூன் நாங்கள் தொடர்பு விளக்கம் உருவாக்கும் பணியின் மீது சோதனைகளை செய்கிறோம் மற்றும் எங்கள் மாதிரி தானாகவே மற்றும் மனித மதிப்பிடும', 'ur': 'کمپنس کی توضیح کی نسل کا ارادہ یہ ہے کہ ماشین کی حس سازی قابلیت کو مضبوط بنانے کے ذریعہ سزاوار توضیح دینے کے ذریعہ حالانکہ یہ کام انسان کے لئے آسان ہے، ماشین اب بھی منطقی اور معلوم توضیح پیدا کرنے کے لئے کوشش کرتا ہے۔ ہم اس کام میں ایک طریقہ پیشنهاد کرتے ہیں جو پہلی بار بنیاد نظریں اٹھاتے ہیں جن کو دلیل زنجیر میں پول کے طور پر استعمال کیا جاتا ہے اور پھر یہ نظریں اٹھاتے ہیں کہ آخری توضیح پیدا کریں۔ اس طرح مفصل پرسس کو آسان کرنے کے لئے، ہم ایک واضح اور پل کی نظریں کے درمیان اتصال کا استعمال کریں گے اور ایک سوگراف بنانے کے لئے multi-hop راستے اٹھانے اور کاٹنے کے ذریعے استعمال کریں گے. ہم ایک برڈ کا منظور اضافہ موڈل طراحی کرتے ہیں جو پہلی بار تین سی سی سی کور کرتا ہے، سپس گراف میں راستوں کو روٹ کرتا ہے، اور اس سے زیادہ کمزور نظر کے ساتھ برڈ کا منظور انتخاب کرتا ہے تین سی سطح اور منظور سطح پر۔ ہم عام سمجھ کی توضیح کی نسل کے کام پر آزمائش کرتے ہیں اور ہماری مدل آزمائش کی حالت کی بنسٹ لینوں کو آٹوٹی اور انسان کی ارزش میں کام نہیں کرتا۔', 'si': 'සම්බන්ධ විස්තරය පිළිගන්න අදහස් කරනවා මැෂින්ගේ අදහස් කරන්න ක්\u200dරියාත්මක ක්\u200dරියාත්මක විස්තර කරන්න, සාමාන්\u200dය විර මේ වැඩේ මිනිස්සුන්ට ලේසි වෙලා තියෙනවා නමුත් මේෂින් තාමත් ප්\u200dරශ්නයක් සහ තොරතුරු විස්තර කරන්න ප්\u200dර මේ වැඩේ අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරනවා මුලින්ම ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ අන්තිම ප්\u200dරශ්නයක් නිර්මා අපි ප්\u200dරශ්නයක් සහ ප්\u200dරශ්නයක් සාධාරණය කරන්න, අපි ප්\u200dරශ්නයක් සහ ප්\u200dරශ්නයක් අතර සම්බන්ධයක් නිර්මාණය කරන්න සහ ප්\u200dරශ්නයක් සඳහ අපි බ්\u200dරිජ් සංඥානයක් සිද්ධානය කරන්න ප්\u200dරමාණයක් සිද්ධානය කරනවා, මුලින්ම තුනක් ප්\u200dරමාණයක් සිද්ධා කරනවා, සබ්රාග්\u200dරාෆ් වල අපි සාමාන්\u200dය විශ්වාස කරන්න ප්\u200dරයෝජනය කරනවා සහ අපේ මොඩේල් ස්වයංක්\u200dරියාත්මක විශ්වාස කරනවා ස්වයංක්\u200dරියාව සහ මිනිස්', 'sv': 'Generation av allmännyttiga förklaringar syftar till att stärka maskinens sinnesskapande förmåga genom att generera rimliga förklaringar till uttalanden mot allmännyttiga. Även om denna uppgift är lätt för människa, kämpar maskinen fortfarande för att generera rimliga och informativa förklaringar. I detta arbete föreslår vi en metod som först extraherar de underliggande begreppen som tjänar som broar i resonemanget kedjan och sedan integrerar dessa begrepp för att generera den slutliga förklaringen. För att underlätta resonemanget använder vi extern allmännyttig kunskap för att bygga kopplingen mellan ett statement och brokoncepten genom att extrahera och beskära multi-hop banor för att bygga en undergraf. Vi designar en brokonceptextraktionsmodell som först får poäng på trippelen, leder stigarna i undergrafen och vidare väljer brokoncept med svag övervakning på både trippelnivå och konceptnivå. Vi utför experiment på den allmänsliga förklaringsgenereringsuppgiften och vår modell överträffar de senaste baslinjerna i både automatisk och mänsklig utvärdering.', 'uz': "Komponentsiya foydalanuvchi birinchi foydalanishi, mashinaning g'oyalari qobiliyatini qo'shishga ega bo'ladi. Bu vazifa inson uchun oddiy narsa bo'lsa, mashina haqiqiqiy va maʼlumot tafsilotlarini yaratishga harakat qiladi. In this work, we propose a method that first extracts the underlying concepts which are served as bridges in the reasoning chain and then integrates these concepts to generate the final explanation.  Biz tashkilotni foydalanishimiz uchun tashqi xabarnomalardan foydalanamiz, bir tashqi va bir darajadagi g'oyalarga bog'lash uchun bir necha yoʻllarni chiqarish va bir necha qo'shish orqali yaratish uchun. Biz bir bir darajani ajratish modelini yaratishimiz, birinchi marta uchta darajada, tub grafikdagi yoʻllarni ko'rsatadi, va keyin bir necha darajada bir xil va concept darajada yordamni tanlashmiz. Biz tashkilotni tajriba qilamiz va modelimizni avtomatik va inson qiymatlarida asosiy holatni bajaramiz.", 'vi': 'Sản phẩm giải thích phổ biến nhằm tăng cường khả năng làm cho cỗ máy bằng cách tạo ra lý do hợp lý cho những phát biểu chống lại lẽ thường. Trong khi nhiệm vụ này dễ dàng với con người, cỗ máy vẫn cố gắng tạo ra những giải thích hợp lý và thông tin. Trong công trình này, chúng tôi đề xuất một phương pháp khai thác đầu tiên các khái niệm cơ bản được phục vụ như những cầu nối trong chuỗi lập luận và sau đó hợp nhất các khái niệm này để giải thích cuối cùng. Để làm dễ việc quá trình lập luận, chúng tôi sử dụng kiến thức tỉnh lẻ bên ngoài để xây dựng sự kết nối giữa một tuyên bố và các khái niệm cây cầu bằng cách khai thác và cắt tỉa các đường dẫn đa nhà thờ để xây dựng tiểu thư. Chúng tôi thiết kế một mô hình vẽ khái niệm cầu, để ghi điểm đầu tiên cho các tế bào, đường mòn các đường dẫn trong tiểu đồ, và thêm chọn các khái niệm cây cầu với sự giám sát yếu ở mức ba và mức khái niệm. Chúng tôi thực hiện thí nghiệm về nhiệm vụ sản xuất giải thích hợp lý và mẫu của chúng tôi hoàn thành các bản nền tảng nghệ thuật trong cả đánh giá tự động lẫn con người.', 'bg': 'Генерирането на разумни обяснения има за цел да даде възможност на машината да създава смисъл чрез генериране на правдоподобни обяснения на твърдения срещу разума. Въпреки че тази задача е лесна за човека, машината все още се бори да генерира разумни и информативни обяснения. В тази работа предлагаме метод, който първо извлича основните понятия, които служат като мостове във веригата на разсъжденията и след това интегрира тези понятия, за да генерира окончателното обяснение. За да улесним процеса на разсъждение, ние използваме външни познания, за да изградим връзката между изявлението и концепциите за моста чрез извличане и подрязване на мулти-хоп пътеки за изграждане на подграф. Проектираме модел за екстракция на концепцията за мост, който първо оценява тройките, маршрутизира пътищата в подграфата и допълнително избира концепции за мостове с слаб надзор както на тройното ниво, така и на концепцията. Провеждаме експерименти по задачата за генериране на разумно обяснение и нашият модел превъзхожда най-съвременните базови линии както при автоматична, така и при човешка оценка.', 'nl': 'Het genereren van commonsense verklaringen is bedoeld om de zintuigmakende capaciteit van de machine te versterken door plausibele verklaringen te genereren voor uitspraken tegen gezond verstand. Hoewel deze taak gemakkelijk voor de mens is, worstelt de machine nog steeds met het genereren van redelijke en informatieve verklaringen. In dit werk stellen we een methode voor die eerst de onderliggende concepten extraheert die dienen als bruggen in de redeneringsketen en vervolgens integreert om de definitieve uitleg te genereren. Om het redeneringsproces te vergemakkelijken, gebruiken we externe gezonde kennis om de verbinding tussen een statement en de brugconcepten op te bouwen door multi-hop paden te extraheren en te snoeien om een subgraaf te bouwen. We ontwerpen een brugconcept extractiemodel dat eerst de triples scoort, de paden in de subgraaf routet en verder brugconcepten selecteert met zwakke supervisie op zowel het triple niveau als het conceptniveau. We voeren experimenten uit op het genereren van gezonde verklaringen en ons model presteert beter dan de state-of-the-art basislijnen in zowel automatische als menselijke evaluatie.', 'hr': 'Generacija objašnjenja zajedničkih smisla cilja je omogućiti sposobnost izrade smisla stroja stvaranjem uvjerljivih objašnjenja izjavama protiv zajedničkog smisla. Iako je ovaj zadatak lak za ljude, mašina se i dalje bori za stvaranje razumnih i informativnih objašnjenja. U ovom poslu predlažemo metodu koja prvo izvlači temeljne koncepte koje su služene kao mostove u razumnom lancu, a zatim integriraju te koncepte kako bi stvorili konačno objašnjenje. Da bismo olakšali razumni proces, iskoristili smo vanjske znanje zajedničkog smisla kako bi izgradili vezu između izjave i koncepta mosta izvlačili i pružili multihopske puteve kako bi izgradili podgraf. Mi dizajniramo model izvlačenja koncepta mosta koji prvi put rezultira tri puta, putuje puteve u podgrafu, i dalje odabere koncept mosta sa slabim nadzorom na trostrukoj razini i razini koncepta. Mi provodimo eksperimente o zadatku generacije objašnjenja zajedničkog smisla i naš model iznosi početne linije stanja umjetnosti i u automatskoj i ljudskoj procjeni.', 'da': 'Generation af almindelige forklaringer har til formål at styrke maskinens sansevne ved at generere plausible forklaringer til udsagn mod almindelige fornuft. Mens denne opgave er let for mennesker, kæmper maskinen stadig med at generere rimelige og informative forklaringer. I dette arbejde foreslår vi en metode, der først udtrækker de underliggende begreber, der tjener som broer i ræsonnementskæden, og derefter integrerer disse begreber for at generere den endelige forklaring. For at lette ræsonnementsprocessen bruger vi ekstern almindelig viden til at opbygge forbindelsen mellem et statement og brokoncepterne ved at udtrække og beskære multi-hop stier for at opbygge en undergraf. Vi designer en brokonceptudtrækningsmodel, der først scorer tredoblerne, ruter stierne i undergrafen og yderligere udvælger brokoncepter med svag overvågning på både tredobbelt niveau og konceptniveau. Vi udfører eksperimenter med genereringen af almindelige forklaringer, og vores model overgår de avancerede basislinjer i både automatisk og menneskelig evaluering.', 'de': 'Die Generierung von Commonsense-Erklärungen zielt darauf ab, die Sinnesfähigkeit der Maschine zu stärken, indem plausible Erklärungen zu Aussagen gegen gesunden Menschenverstand generiert werden. Obwohl diese Aufgabe einfach für den Menschen ist, kämpft die Maschine immer noch darum, vernünftige und informative Erklärungen zu generieren. In dieser Arbeit schlagen wir eine Methode vor, die zunächst die zugrunde liegenden Konzepte extrahiert, die als Brücken in der Argumentationskette dienen und diese dann integriert, um die endgültige Erklärung zu generieren. Um den Argumentationsprozess zu erleichtern, nutzen wir externes gesundes Wissen, um die Verbindung zwischen einer Aussage und den Brückenkonzepten herzustellen, indem wir Multi-Hop-Pfade extrahieren und beschneiden, um ein Subgraph zu erstellen. Wir entwerfen ein Brückenkonzept Extraktionsmodell, das zuerst die Triple bewertet, die Pfade im Subgraph routet und darüber hinaus Brückenkonzepte mit schwacher Überwachung sowohl auf der Triple-Ebene als auch auf der Konzeptebene auswählt. Wir führen Experimente zur Generierung gesunder Erklärungen durch und unser Modell übertrifft sowohl die modernen Grundlagen in der automatischen als auch in der menschlichen Bewertung.', 'id': 'Generasi penjelasan umum bertujuan untuk memungkinkan kemampuan pembuat sensasi mesin dengan menghasilkan penjelasan yang dapat dipercaya untuk pernyataan melawan kesehatan umum. Sementara tugas ini mudah bagi manusia, mesin masih berjuang untuk menghasilkan penjelasan yang masuk akal dan informatif. Dalam pekerjaan ini, kami mengusulkan metode yang pertama mengekstrak konsep yang didasarkan yang dilayani sebagai jembatan dalam rantai pemikiran dan kemudian mengintegrasi konsep-konsep ini untuk menghasilkan penjelasan akhir. Untuk memudahkan proses pemikiran, kita menggunakan pengetahuan luar biasa untuk membangun koneksi antara pernyataan dan konsep jembatan dengan mengekstraksi dan menggosok jalur multi-hop untuk membangun subgraf. Kami merancang model ekstraksi konsep jembatan yang pertama mencetak tiga kali, jalur jalur di subgraf, dan lebih lanjut memilih konsep jembatan dengan pengawasan yang lemah di tingkat tiga dan tingkat konsep. Kami melakukan eksperimen pada tugas generasi penjelasan umum dan model kami melampaui batas dasar state-of-the-art dalam evaluasi otomatis dan manusia.', 'ko': '상식 해석 생성은 상식에 어긋나는 진술에 대한 합리적인 해석을 통해 기계의 감지 능력을 강화하는 데 목적을 두고 있다.비록 이 임무는 인류에게 매우 쉽지만 기계는 여전히 합리적이고 정보가 풍부한 해석을 만들기 어렵다.이 작업에서 우리는 추리 체인 중의 교량의 기초 개념으로 먼저 추출한 다음에 이러한 개념을 통합시켜 최종 해석을 생성하는 방법을 제시했다.추리 과정을 간소화하기 위해 우리는 외부 상식 지식을 이용하여 다중 점프 경로를 추출하고 편집함으로써 서브맵을 구축하여 문장과 브리지 개념 사이에 연결을 구축한다.우리는 교량 개념 추출 모델을 설계했다. 이 모델은 먼저 삼원조에 대해 평가를 하고 서브맵에서 경로를 정한 다음에 삼원조와 개념급에서 감독이 비교적 약한 교량 개념을 선택한다.우리는 상식 해석 생성 임무에 대해 실험을 실시했는데 우리의 모델은 자동과 인공 평가 방면에서 가장 선진적인 기선보다 우수하다.', 'sw': "Commonsense explanation generation aims to empower the machine's sense-making capability by generating plausible explanations to statements against commonsense.  Wakati juhudi hili ni rahisi kwa binadamu, mashine bado inajitahidi kuleta maelezo yenye ufanisi na taarifa. Katika kazi hii, tunapendekeza njia ambayo kwanza hutoa dhana za msingi ambazo zinatumiwa kama daraja katika mfumo wa kisiasa na kisha kuunganisha dhana hizi ili kutengeneza maelezo ya mwisho. Ili kusaidia mchakato wa kutangaza, tunatumia maarifa ya nje ya umma ili kujenga uhusiano kati ya tamko na dhana za daraja kwa kutengeneza na kuendeleza njia nyingi za jumuiya ili kujenga vifaa. Tunaweza kutengeneza modeli ya kutengeneza dhana ya daraja ambayo kwa mara ya kwanza inaonyesha majaribio hayo, inaongoza njia katika eneo hilo, na pia tunachagua dhana za daraja yenye ufuatiliaji dhaifu katika ngazi ya tatu na kiwango cha dhana. Tunafanya majaribio kuhusu kazi ya uzalishaji wa umma na mtindo wetu unaonyesha msingi wa hali ya sanaa katika utafiti wa kibinafsi na binadamu.", 'fa': 'نسل توضیح کمانس هدف دارد که توانایی ساختن حس ماشین را با تولید توضیح قابل توضیح\u200cهای قابل توضیح بر خلاف تعریف عمومی تواند کرد. در حالی که این کار برای انسان آسان است، ماشین هنوز برای ایجاد توضیح منطقی و اطلاعاتی تلاش می کند. در این کار، ما یک روش پیشنهاد می\u200cکنیم که اول مفهوم\u200cهای بنیادی را خارج می\u200cکند که به عنوان پل در زنجیر منطقی خدمت می\u200cشوند و سپس این مفهوم\u200cها را برای توضیح نهایی تولید می\u200cکند. برای آسان کردن فرایند منطقی، ما از دانش معمولی بیرون استفاده می کنیم تا ارتباط بین یک واژه و مفهوم پل را با استخراج و پاک کردن مسیر چندین هوپ برای ساختن یک زیر گراف بسازیم. ما یک مدل استخراج مفهوم پل را طراحی می کنیم که اولین امتیاز سه برابر می کند، مسیر را در زیر گراف می کند، و بیشتر مفهوم پل را با نیروی ضعیف در سطح سه برابر و سطح مفهوم انتخاب می کند. ما آزمایش\u200cها را روی کار توضیح نسل معمولی انجام می\u200cدهیم و مدل ما در ارزیابی خودکار و انسان\u200cها از شرایط پایگاه\u200cهای هنر استفاده می\u200cکند.', 'af': "Die gemeenskapsverklaring generasie is doel om die masjien se sens-maak-kapasiteit te verower deur verligbare uitduidelings te genereer aan uitduidelike teen gemeenskapssins. Terwyl hierdie taak maklik is vir die mens, struikel die masjien nog steeds om redelike en informatiewe uitduidelings te genereer. In hierdie werk voorstel ons 'n metode wat eerste uittrek die onderstelde konsepte wat as bruides in die redekende ketting gedien word en dan integreer hierdie konsepte om die eindelike uitduidelikheid te genereer. Om die redeningsproses te eenvoudig, gebruik ons eksterne gemeenskap kennis om die verbinding tussen 'n uitdrukking en die brig konsepte te bou deur multihoppaaie uittrek en uitdruk om 'n subgraaf te bou. Ons ontwerp 'n brig konsepte uittrekking model wat eerste tel die drieples, reis die paaie in die subgraaf, en verder kies brig konsepte met swak supervisie op beide die drieplike vlak en die konseptvlak. Ons doen eksperimente op die gemeenskaplike verklaring generasie taak en ons model uitvoer die state-of-the-art basisline in beide automatiese en menslike evaluering.", 'tr': 'Kommunusy흫 d체힊체ndiri힊i jena첵aty ma힊yny흫 du첵gulanmagy ukyp etmek 체챌in c채reler du첵gulanmagy m체mkin du첵gularyna d체힊체ndirip d체힊체ndiril첵채r. Bu zady ynsan 체챌in a흫sat bolsa, ma힊yn henizem d체힊체njeli we informaty첵an d체힊체ndirimleri d철retmek 체챌in m체cadele ed첵채r. Bu i힊de biz ilkinji gezek d체힊체len d체힊체njeleri 철z체ne k철p 힊eklinde 챌ykarmak 체챌in bu d체힊체njeleri teklip edip, so흫ra so흫ky d체힊체njeleri d철retmek 체챌in bu d체힊체njeleri 챌ykarmak 체챌in 체첵tged첵채ris. Mant캇klyk prosesini 첵e흫le힊tirmek 체챌in, bir deklarasyon we k철p d체힊체nceleri arasynda bir bagla첵y힊y 챌ykarmak we k철p 첵oluny s체첵힊irmek 체챌in da힊aryk du첵umlulyk bilgilerini ulan첵arys. Biz k철p d체힊체nj채ni 챌ykarmak nusgasyny ilkinji gezek 체챌체ni gola첵la첵ar, subgrafdaky 첵olaryny 첵철re첵채ris we k철p d체힊체nj채ni i흫 체챌체nji derejede we d체힊체nj채ni흫 derejesinde k철p d체힊체nj채ni sa첵l첵arys. Biz umumy d체힊체n첵채n d체힊체njeleri d철redijilik t채sirinde d체힊체ndirip bar첵arys we nusgymyz hem awtomatik hem adamlary흫 de휓erlendirmelerinde durumyny 챌ykar첵ar.', 'sq': 'Gjenerimi i shpjegimeve të përbashkëta synon të forcojë aftësinë e krijimit të ndjenjave të makinës duke krijuar shpjegime të besueshme ndaj deklaratave kundër të përbashkëtës. Ndërsa kjo detyrë është e lehtë për njerëzit, makina ende lufton për të gjeneruar shpjegime të arsyeshme dhe informative. Në këtë punë, ne propozojmë një metodë që së pari nxjerr konceptet themelore që shërbehen si ura në zinxhirin e arsyetimit dhe pastaj integron këto koncepte për të gjeneruar shpjegimin përfundimtar. Për të lehtësuar procesin e arsyetimit, ne përdorim njohuritë e jashtme të përbashkëta për të ndërtuar lidhjen midis një deklarate dhe koncepteve të urës duke nxjerrë dhe prerë rrugët multi-hop për të ndërtuar një subgraf. Ne dizajnojmë një model të nxjerrjes së konceptit të urës që së pari shënon trefishin, udhëton rrugët në nëngrafin dhe zgjedh më tej konceptet e urës me mbikqyrje të dobët si në nivelin e trefishtë ashtu dhe në nivelin e konceptit. Ne kryejmë eksperimente në detyrën e përgjithshme të gjenerimit të shpjegimeve dhe modeli ynë mbivlerëson linjat bazë më të larta si në vlerësimin automatik ashtu dhe njerëzor.', 'am': 'የመስመር ትውልድ የሞክራዊውን አካሄድ ማድረግ ማድረግ ይችላል፡፡ ይህም ስራ ለሰው ቀላል ሲሆን መሳሪያው ገና አስተዋይ እና የመረጃ ትርጓሜዎችን ለመፍጠር ይጋደላል፡፡ በዚህ ሥራ፣ አስቀድሞ የመጀመሪያውን ጥያቄዎች እንደ ድረ ሰንሰለት የሚደረጉትን እናወጣለን፡፡ To facilitate the reasoning process, we utilize external commonsense knowledge to build the connection between a statement and the bridge concepts by extracting and pruning multi-hop paths to build a subgraph.  የመድረክ አካባቢ ምሳሌ መፍጠርን እናደርጋለን፡፡ የግንኙነት ትውልድ አድራሻ ላይ ፈተናዎችን እናደርጋለን፡፡', 'hy': 'Հիմնական բացատրությունների սերունդը նպատակն է հզորացնել մեքենայի զգացմունքներ ստեղծելով հավատալի բացատրություններ ընդհանուր զգացմունքների դեմ: Մինչդեռ այս խնդիրը մարդկային համար հեշտ է, մեքենան դեռևս պայքարում է խելամիտ և ինֆորմատիվ բացատրություններ ստեղծելու համար: Այս աշխատանքի մեջ մենք առաջարկում ենք մեթոդ, որը նախ հանում է հիմնական գաղափարները, որոնք օգտագործվում են որպես կամուրջներ մտածողական շղթաում և հետո ինտեգրում է այս գաղափարները վերջնական բացատրությունը ստեղծելու համար: Որպեսզի հեշտացնենք մտածողականության գործընթացը, մենք օգտագործում ենք արտաքին ընդհանուր գիտելիքները, որպեսզի կառուցենք կապը հայտարարության և կամուրջի գաղափարների միջև՝ բազմահույսերի ճանապարհներ դուրս բերելով և կտրելով Մենք նախագծում ենք կամուրջի գաղափարի վերացման մոդել, որը առաջին անգամ գնահատում է երեք անգամ, ուղղություններ է կատարում ենթագրաֆիկի ուղղություններում, և ապա ընտրում է կամուրջի գաղափարներ՝ թույլ վերահսկողությամբ և երեք անգա Մենք փորձարկումներ ենք կատարում ընդհանուր բացատրությունների սերնդի առաջադրանքի վրա, և մեր մոդելը գերազանցում է ամենակարևոր հիմնական գծերը, ինչպես ավտոմատիկ, ինչպես նաև մարդկային գնահատման մեջ:', 'bn': 'কমিনসেন্সের প্রজন্মের ব্যাখ্যা হচ্ছে মেশিনের বুদ্ধিমান ব্যাখ্যা ব্যাখ্যা তৈরি করার মাধ্যমে মেশিনের বুদ্ধিমান যদিও এই কাজ মানুষের জন্য সহজ, তবে মেশিন এখনো যুক্ত এবং তথ্যের ব্যাখ্যা তৈরি করার জন্য সংগ্রাম করছে। এই কাজে আমরা একটি পদ্ধতি প্রস্তাব করি যা প্রথমে ভূমিকা ধারণা বের করে যায় যা কোন কারণের চেইন হিসেবে ব্রিজ হিসেবে ব্যবহার করা হয় এবং তারপর এই ধারণাগুলো একত যুক্তি প্রক্রিয়াকে সুবিধা দেয়ার জন্য আমরা বাইরের কমিউনিসেন্সের জ্ঞান ব্যবহার করি একটি বিবৃতি এবং ব্রিজ ধারণার মধ্যে যোগাযোগ তৈরি করার জন্য এবং সাবগ আমরা একটি ব্রিজ ধারণা বিনিময়ের মডেল ডিজাইন করি যা প্রথম ত্রিগ্রাফের দ্বারা স্কোর করে, সাবগ্রাফের রাস্তা পরিচালিত করে, আর ব্রিজের ধারণা দুর্বল পর্যায়ে  আমরা কমন্সেন্সের ব্যাখ্যা প্রজন্মের কাজের উপর পরীক্ষা করি এবং আমাদের মডেল স্বয়ংক্রিয়ভাবে এবং মানুষের মূল্যের মূল্যের মধ্যে দ', 'az': 'Kommunikas təfsilatı nəsli maşının hiss etmə qabiliyyətini təşkil etmək istəyir, müxtəlif ifadələrə qarşı təfsilatlar yaratmaq istəyir. Bu işin insana asan olduğu halda, maşın hələ də razıllıq və informativ açıqlama yaratmaq üçün mübahisə edir. Bu işdə, biz ilk dəfə düşüncə zəncirlərin köprüsü kimi köprüyü yaratmaq üçün bu düşüncələri birləşdirir. Araştırma prosesini asanlaşdırmaq üçün, bir ifadəsi və köprü fikirlərin arasındakı bağlantı yaratmaq üçün çoxlu-Hop yollarını çəkmək və süpürmək üçün istifadə edirik. Biz köprüsü təkrarlama modelini tasarlayırıq ki, ilk üçlüyü müəyyən edir, subgrafının yollarını yola yönəldir, və daha sonra köprüsü müəyyən etdiklərini zəif gözləyir, həm üçlü seviyyətdə də, həm də müəyyən səviyyədə seçir. Biz müxtəlif təfsilatının nəsil işini və modellərimiz hər ikisinin automatik və insan değerlendirməsində müəyyən olunmuş təcrübələrini təşkil edirik.', 'bs': 'Generacija objašnjenja zajednica cilja je da omogućava sposobnost izrade smisla mašine stvaranjem uvjerljivih objašnjenja izjavama protiv zajedničkog smisla. Iako je ovaj zadatak lak za ljude, mašina se i dalje bori za stvaranje razumnih i informativnih objašnjenja. U ovom poslu predlažemo metodu koja prvi put izvlači temeljne koncepte koje su služene kao mostove u razumnom lancu i onda integrira te koncepte kako bi stvorila konačno objašnjenje. Da bismo olakšali razumni proces, iskoristili smo vanjske znanje zajedničkog znanja kako bi izgradili vezu između izjave i koncepta mosta izvlačili i pružili multihopske ceste kako bi izgradili podgraf. Mi dizajniramo model izvlačenja mosta koji prvi put rezultira tri puta, putuje puteve u podgrafu, i dalje odabere koncept mosta sa slabim nadzorom na trostrukom nivou i nivou koncepta. Mi provodimo eksperimente o zadatku generacije objašnjenja zajedničkog smisla i naš model iznosi početne linije države umjetnosti i u automatskoj i ljudskoj procjeni.', 'ca': "La generació d'explicacions comunes mira a empoderar la capacitat de creació de sentits de la màquina generant explicacions plausible s a declaracions contra el comú. Mentre aquesta tasca és fàcil per a l'humà, la màquina encara lluita per generar explicacions raonables i informatives. En aquesta feina, proposem un mètode que primer extreu els conceptes subjacents que serveixen com ponts a la cadena de raonament i després integra aquests conceptes per generar l'explicació final. Per facilitar el procés de raonament, utilitzem coneixements comuns externs per construir la connexió entre una declaració i els conceptes de pont extraint i recollint camins multi-hop per construir un subgràfic. Desenyem un model d'extracció de concepte de pont que primer puntueix els triples, ruta els camis del subgràfic i selecciona més endavant conceptes de pont amb una supervisió dèbil tant a nivell triple com a nivell conceptual. Fem experiments sobre la tasca comú de generació d'explicacions i el nostre model supera les línies de base més avançades tant en l'evaluació automàtica com en la humana.", 'cs': 'Generace vysvětlení zdravého rozumu si klade za cíl posílit schopnost stroje vytvářet smysl tím, že generuje věrohodná vysvětlení proti zdravému rozumu. Zatímco tento úkol je pro člověka snadný, stroj stále bojuje s vytvářením rozumných a informativních vysvětlení. V této práci navrhujeme metodu, která nejprve extrahuje základní pojmy sloužící jako mosty v řetězci uvažování a následně tyto pojmy integruje k generování konečného vysvětlení. Abychom usnadnili proces uvažování, využíváme externí znalosti zdravého rozumu k vytvoření spojení mezi výrokem a konceptem mostu extrakcí a prořezáním multi-hop cest k vytvoření podgrafu. Navrhujeme extrakční model mostového konceptu, který nejprve skóruje trojice, směřuje cesty v podgrafu a dále vybírá mostové koncepty se slabým dohledem jak na trojité úrovni, tak na konceptní úrovni. Provádíme experimenty na úkolu generování zdravého rozumu vysvětlení a náš model překonává nejmodernější základní linie v automatickém i lidském hodnocení.', 'et': 'Üldmõistlike selgituste genereerimise eesmärk on suurendada masina mõistlikkust, luues usutavaid selgitusi ühismõistuse vastastele avaldustele. Kuigi see ülesanne on inimesele lihtne, siis masin püüab endiselt luua mõistlikke ja informatiivseid selgitusi. Käesolevas töös pakume välja meetodi, mis kõigepealt ekstraheerib aluskontseptsioonid, mida teenitakse sildadena arutlusahelas ja seejärel integreerib need kontseptsioonid lõpliku selgituse saamiseks. Mõtlemisprotsessi hõlbustamiseks kasutame väliseid mõistlikke teadmisi, et luua seos avalduse ja silla kontseptsioonide vahel, kaevandades ja lõikades multi-hop teed, et ehitada alamgraafi. Töötame välja silla kontseptsiooni ekstraheerimise mudeli, mis esmakordselt hindab kolmekordseid punkte, suunab teed alamgraafis ja valib edaspidi nõrga järelevalvega sillakontseptsioone nii kolmekordsel kui ka kontseptsioonitasandil. Me teeme eksperimente mõistliku selgituse genereerimise ülesandega ning meie mudel ületab nii automaatse kui ka inimese hindamise tipptasemel lähtejooni.', 'fi': 'Yleisen järjen selityksen generoinnin tavoitteena on vahvistaa koneen järkeenkäymiskykyä tuottamalla uskottavia selityksiä terveen järjen vastaisille lausunnoille. Vaikka tämä tehtävä on helppo ihmiselle, kone yrittää silti tuottaa järkeviä ja informatiivisia selityksiä. Tässä työssä ehdotamme menetelmää, joka ensin poimii taustalla olevat käsitteet, jotka toimivat siltoina päättelyketjussa, ja sitten integroi nämä käsitteet lopullisen selityksen tuottamiseksi. Perusteluprosessin helpottamiseksi hyödynnämme ulkoista maalaisjärjestystietoa lauseen ja siltakonseptien välisen yhteyden rakentamiseen kaivamalla ja karsimalla monihyppyreittejä pohjakaavion rakentamiseksi. Suunnittelemme siltakonseptin uuttamismallin, joka ensin pisteyttää kolminkertaiset pisteet, reitittää reitit alareunassa ja valitsee siltakonseptit heikolla valvonnalla sekä kolminkertaistasolla että konseptitasolla. Teemme kokeiluja järkevän selityksen generointitehtävässä ja mallimme suoriutuu sekä automaattisessa että inhimillisessä arvioinnissa.', 'jv': 'buddy Nanging kelas iki dadi gampang sampeyan kanggo wong, macin kuwi isih njaluk-njaluk kanggo nggawe barang beraksi lan basa informasi. Awak dhéwé éntuk aturan karo hal-hal iki dadi aturan tanggal nggawe nguasai perusahaan winih lan nganggo dolanan sing beraksi iki dadi bisa nguasai perusahaan tanggal nggawe Ngawe kang perusahaan akeh sampeyang nggawe, kita ngubah akeh barang langgar-wong liyane nggawe barang nggawe aturan tapi kejahatan lan nggawe barang langgar-wong liyané perusahaan multi-top kanggo nggawe barang. Awak dhéwé ngênêmên ngerasakno sistem sing wis ngerasakno dadi sing perusahaan karo ngono ngênêmên, kuwi ngênêmên kuwi tindakan sistem sing gawe nêmên ngerasakno karo ngono ngênêmên kuwi tindakan Triangkat lan wong kuwi tindakan. Awak dhéwé éntuk éntuk perbudhakan kanggo ngerasakno nggawe barang-barang nggawe barang nggawe barang-barang nggawe barang sistem ora bisa perusahaan karo perusahaan karo hal-karang.', 'sk': 'Cilj generacije splošnega smisla je povečati sposobnost ustvarjanja smisla stroja z ustvarjanjem verjetnih pojasnil za izjave proti splošnemu smislu. Čeprav je ta naloga človeku enostavna, se stroj še vedno trudi ustvariti razumne in informativne razlage. V tem delu predlagamo metodo, ki najprej izvleče osnovne koncepte, ki služijo kot mostovi v verigi razmišljanja in nato integrira te koncepte, da ustvari končno razlago. Da bi olajšali proces razmišljanja, uporabljamo zunanje splošno znanje za gradnjo povezave med izjavo in koncepti mostov z ekstrakcijo in obrezovanjem multi-hop poti za gradnjo podgrafije. Zasnovamo model ekstrakcije koncepta mostu, ki najprej oceni trojnice, usmeri poti v podgrafu in nadalje izbere koncepte mostov s šibkim nadzorom tako na trojni kot konceptni ravni. Izvajamo poskuse na nalogi generiranja razlage, naš model pa presega najsodobnejše osnovne linije tako pri avtomatičnem kot pri človeku.', 'he': 'דור ההסברים המפורסמים מתכוון להחזיק את יכולת ההתחשבות של המכונה על ידי ליצור הסברים אמינים להצהרות נגד ההתחשבות המפורסמות. בעוד המשימה הזאת קלה לאדם, המכונה עדיין נאבקת ליצור הסבר הגיוני ומידע. In this work, we propose a method that first extracts the underlying concepts which are served as bridges in the reasoning chain and then integrates these concepts to generate the final explanation.  כדי להקל את תהליך ההיגיון, אנו משתמשים בידע משותף חיצוני כדי לבנות את הקשר בין הצהרה לבין הרעיונות הגשר על ידי החולץ ולחטיף דרכים רבים-הופפים לבניין תת-גרף. אנחנו מעצבים מודל חולץ מושג גשר שמקבל קודם את השלישיים, מסלולים את המסלולים בתא הגרף, ובנוסף בוחרים מושג גשר עם פיקוח חלש ברמה השלישית וברמת המושג. אנו מבצעים ניסויים על משימה של דור ההסבר המפורסם והמודל שלנו מוביל את קווי הבסיס המיוחדים באוטומטיים ובעריכה אנושית.', 'ha': "Babu fassarar da Commonce yana nufin ya ƙara awon mai sanyi wa mashine da za'a sami shi da ya ƙãga fassarar da bakwai masu fassarar da bakwai. While this task is easy to human, the machine still struggles to generate reasonable and informative explanations.  Daga wannan aikin, Munã buɗa wata hanyoyi ta farkon ta fitar idãnun bakwai da ake amfani da su kamar biryutan a cikin marubucin da ke fahimta, sa'an nan kuma Muke haɗa zato da su sami fassarar ta ƙarshen. Ina amfani da aikin zartar da ke fahimta, sai mu yi amfani da ilmi na bakin bayani dõmin mu ƙiƙiri haɗi tsakanin da bayani da mawaƙo na birgo da za'a fito da hanyõyi masu multi-juma don ka gina wani subgraf. Kana ƙayyade wata misalin kofi na biryuta wanda ke iya amfani da shi na farko, yana shiryi hanyõyi cikin shawacan, kuma yana zãɓi zaɓen biryuta idan yana da manyan tsari masu rauni kan daraja uku da daraja uku. Munã samun jarrabãwa a kan aikin farin farin da za'a bayyana shi, kuma misalinmu yana samar da halin-sanannin ta farat ɗaya da kuma yana iya ƙaranci ga mutane.", 'bo': 'སྤྱི་ཚོགས་ཀྱི་མི་རབས་གསལ་བཤད་ནི་དམིགས་ཡུལ་ན་མིན་པས་རྩིས་འཁོར་གྱི་ཐབས་ཤེས་དེ་རང་ཉིད་ཀྱི་ཐབས་ཤེས་ཡོད་པ་དང་། དེ་ལྟ་བུའི་ལས་ཀ་འདི་ནུས་མེད་ལ་སླ་མོ་རེད་ནའང་མ་ལག་གིས་དུས་ཡོད་དུ་རྟོགས་བསམ་བློ་གཏོང་དང་གསལ་བཤད In this work, we propose a method that first extracts the underlying concepts that are served as bridges in the reasoning chain and then integrates these concepts to generate the final explanation. To facilitate the reasoning process, we use external commonsense knowledge to build the connection between a statement and the bridge concepts by extracting and pruning multi-hop paths to build a subgraph. We design a bridge concept extraction model that first scores the triples, routes the paths in the subgraph, and further selects bridge concepts with weak supervision at both the triple level and the concept level. ང་ཚོས་རྒྱལ་ཁབ་ཀྱི་ལས་འགན་འགྲེལ་བཤད་ཀྱི་སྐོར་ལས་བརྟན་དཔྱད་བྱེད་ཀྱིས་རང་འགུལ་གྱིས་དང་མི་རིག'}
{'en': 'All-in-One : A Deep Attentive Multi-task Learning Framework for  Humour ,  Sarcasm , Offensive,  Motivation , and Sentiment on Memes', 'ar': 'الكل في واحد: إطار عمل تعليمي متعدد المهام شديد الانتباه للفكاهة والسخرية والهجوم والتحفيز والمشاعر تجاه المذكرات', 'es': 'Todo en uno: un marco de aprendizaje multitarea profundo y atento para el humor, el sarcasmo, la ofensiva, la motivación y el sentimiento en los memes', 'fr': "Tout-en-un\xa0: un cadre d'apprentissage multitâche profond et attentif pour l'humour, le sarcasme, l'offensive, la motivation et le sentiment sur les mèmes", 'pt': 'All-in-One: uma estrutura de aprendizado multitarefa profunda e atenta para humor, sarcasmo, ofensivo, motivação e sentimento em memes', 'ja': 'オールインワン：ユーモア、皮肉、攻撃的、動機づけ、そしてミームへの感情のための深いこだわりのマルチタスク学習フレームワーク', 'zh': '多合一:深注多任务学框架,幽默刺刺,动机模因情', 'hi': 'ऑल-इन-वन: हास्य, व्यंग्य, आक्रामक, प्रेरणा और मेम्स पर भावना के लिए एक गहरी चौकस मल्टी-टास्क लर्निंग फ्रेमवर्क', 'ru': 'Все-в-одном: основа глубокого внимательного многозадачного обучения юмору, сарказму, оскорбительным действиям, мотивации и настроениям на мемах', 'ga': 'Uile-i-amháin: Creat Foghlama Ilthasc domhain Aireach le haghaidh Greann, Sarcasm, Ionsaitheach, Inspreagadh agus Meon ar Memes', 'ka': 'ყველაფერი-ერთი: ძალიან დარწმუნებელი მრავალური დასწავლების ფრამეტრები სამუშაო, საპკაზმი, ძალიან დაკავშირებელი, მოტოვიცია და მემების შესახებ', 'el': 'Όλα σε ένα: Ένα Βαθύ Προσεκτικό Πλαίσιο εκμάθησης πολλαπλών εργασιών για το χιούμορ, τον σαρκασμό, την προσβολή, το κίνητρο και το συναίσθημα στις μνήμες', 'hu': 'All-in-One: Egy mély figyelmes, többfeladatos tanulási keretrendszer a humor, szarkazmus, támadás, motiváció és érzelem emlékeken', 'it': 'All-in-One: un quadro di apprendimento multi-task attento profondo per umorismo, sarcasmo, offensivo, motivazione e sentimento sui meme', 'kk': 'Барлық бірінде: Хумор, Саркассм, Жылдамдық, Жылдамдық және Жазбалардың көптеген көптеген тапсырмаларды оқыту фреймі', 'lt': 'Visi iš vieno: giliai aktyvi daugiafunkcinio mokymosi sistema, skirta humorui, sarkazmui, nusikalstamumui, motyvacijai ir jausmui dėl atminties', 'mk': 'All-in-One: A Deep Attentive Multi-task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Memes', 'ms': 'All-in-One: A Deep Attentive Multi-Task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Memes', 'ml': 'എല്ലാവരും ഒന്ന്: മെമ്മുകളിലെ ആഴത്തിലെ ആഴത്തിലുള്ള ഒരു അധികം ജോലി പഠിപ്പിക്കുന്ന ഫ്രെയിമോര്\u200dക്ക്, സര്\u200dക്കാസം, ഓഫെന്\u200dഷന്\u200dവിഫ', 'mt': 'All-in-One: A Deep Attentive Multi-task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Memes', 'mn': 'Бүгд-нэг: Гүн гүнзгий олон ажлын суралцах үйл ажиллагаа хөдөлгөөн, сэтгэл хөдөлгөөн, сэтгэл санааны тухай', 'no': 'All-in-One: Eit dyp merkelig fleire oppgåver-læringsrammeverk for Humor, Sarkasm, Offensive, Motivation og Sentiment for Memer', 'sr': 'Sve u prvom: Duboko pažljivo višezadatašnje naučenje okvira za Humor, Sarkasm, Offensive, Motivacije i Sentiment o Memima', 'pl': 'Wszystko w jednym: Głębokie uważne wielozadaniowe ramy uczenia się humoru, sarkazmu, ofensywy, motywacji i sentymentu na pamiętach', 'ro': 'All-in-One: Un cadru de învățare multi-sarcini atent profund pentru umor, sarcasm, ofensiv, motivație și sentiment pe memes', 'si': 'හැම දෙයක්ම එක: ගොඩක් අවධානයක් ගොඩක් වැඩක් ඉගෙන ඉගෙන ගන්න ප්\u200dරමාණයක්, සාර්කාස්ම්, ප්\u200dරමාණයක්, චිත්\u200dරීය, මතකයෝ වල', 'sv': 'Allt-i-ett: En djup uppmﾃ､rksam flerfunktionsinlﾃ､rningsram fﾃｶr humor, sarkasm, offensiv, motivation och kﾃ､nsla pﾃ･ memes', 'so': 'Dhammaan: A Deep Attentive Multi-task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Mems', 'ta': 'அனைத்தும் ஒன்று: நினைவுகளில் உள்ள ஆழமான பெருக்கல் செயல் படிப்பின் சட்டத்தை கற்றுக்கொள்ளும் ஆழமான செயல்பாடு', 'ur': 'سب-in-One: ایک عمیق متوجہ multi-task Learning Framework for Humor, Sarcasm, Offensive, Motivation, and Sentiment on Memes', 'vi': 'All-in-one: A Deep Attentive đa-Task Learning Modern for Humour, Sarcasm, Offensive, lư ention, and l... on Memes', 'uz': "Hammasini bir necha vazifa o'rganish freymi", 'nl': 'Alles-in-één: Een diep attent multi-task leerkader voor humor, sarcasme, offensief, motivatie en sentiment op mems', 'bg': 'Всичко в едно: Дълбоко внимателна многозадача учебна рамка за хумор, сарказъм, офанзива, мотивация и сентимент върху мемите', 'hr': 'Sve u prvom: Duboko pažljivo višezadatačno učenje okvira za Humor, Sarkasm, Offensive, Motivative i Sentiment o Memesima', 'da': 'Alt-i-en: En dyb opmærksom multi-opgave læringsramme for humor, sarkasme, offensiv, motivation og følelse på memes', 'de': 'All-in-One: Ein Deep Attentive Multi-Task Learning Framework für Humor, Sarkasmus, Offensive, Motivation und Sentiment on Memes', 'fa': 'همه در-اول: یک فرم یادگیری زیادی مهارت عمیق برای خشونت، سارکاسم، فعالیت، حرکت و احساسات در ذهن', 'ko': '유머, 풍자, 공격성, 동기와 모인에 대한 깨달음에 사용되는 깊이 있는 멀티태스킹 학습 프레임워크', 'sw': 'Wote kwa moja: Mfumo wa Kujifunza Mipango ya Kazi nyingi kwa ajili ya Binadamu, Sarcasm, Huduma, Hatua na Wakati wa Kumbukumbu', 'af': "Alle-in-een: 'n Deep aandagbaar veelvuldige taak leer raamwerk vir Humor, Sarkasm, Offensive, Motivation en Sentiment op Meme", 'tr': 'Bir-içinde-Bir: Humor, Sarcasm, Offensive, Motivation ve Meme Sentiment için derin bir çoklu-task öwrenmek Sistemi', 'am': 'ሁሉንም በአንድ ላይ: የጥልቅ ተማሪ ብዙ ስራ መማር ፍሬም ለHumour, Sarcasm, Offensive, Motivation and Sentiment', 'hy': 'All-in-One: A Deep Attentive Multi-task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Memes', 'az': 'Birinci: Humor, Sarcasm, Offensive, Motivation və Meme-lər üçün çoxlu işin öyrənməsi Framework for Deep Attentive Multi task Learning Framework for Humor, Sarcasm, Offensive, Motivation and Sentiment on Memes', 'id': 'All-in-One: A Deep Attentive Multi-Task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Memes', 'bn': 'সবাইকে: হিউমার, সার্কাস্ম, অফিসেন্টিভ, মোটেভেশন এবং মেমের ব্যাপারে সেন্টাইমেন্ট', 'bs': 'Sve u prvom: Duboko pažljivo višezadatačno učenje okvira za Humor, Sarkasm, Offensive, Motivacije i Sentiment o Memesima', 'sq': 'All-in-One: A Deep Attentive Multi-task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Memes', 'cs': 'Vše v jednom: Hluboký pozorný víceúkolový učební rámec pro humor, sarkasmus, útok, motivaci a sentiment na paměti', 'et': 'Kõik-ühes: sügav tähelepanuväärne mitme ülesandega õppimise raamistik huumorile, sarkasmile, ründavale, motiveerimisele ja tunnetele Memes', 'fi': 'All-in-One: Deep Attentive Multi-Task Learning Framework huumorille, sarkasmille, hyökkäykselle, motivoinnille ja tunteille Memes', 'ca': "Un marc d'aprenentatge multitasca d'atenció profunda per humor, sarcasme, ofensiu, motivació i sentiment en les memòries", 'jv': 'All-in-One: A deep Attentive Multi-task Learning frame for Smith, Sarkasm, offensive, Moation, and Sentiment on memes', 'he': '"כולם באחד: מסגר ללמוד במשימות רבות"', 'bo': 'All-in-One: Deep Attentive Multi-task Learning Framework for Humour, Sarcasm, Offensive, Motivation and Sentiment on Memes', 'ha': '@ action: button', 'sk': 'Vse-v-enem: Globoko pozoren večopravilni okvir za učenje humorja, sarkazma, ofenzive, motivacije in čustva na memesih'}
{'en': 'In this paper, we aim at learning the relationships and similarities of a variety of tasks, such as humour detection, sarcasm detection, offensive content detection, motivational content detection and  sentiment analysis  on a somewhat complicated form of information, i.e.,  memes . We propose a multi-task, multi-modal deep learning framework to solve multiple tasks simultaneously. For  multi-tasking , we propose two attention-like mechanisms viz., Inter-task Relationship Module (iTRM) and Inter-class Relationship Module (iCRM). The main motivation of iTRM is to learn the relationship between the tasks to realize how they help each other. In contrast,  iCRM  develops relations between the different classes of tasks. Finally,  representations  from both the attentions are concatenated and shared across the five  tasks  (i.e.,  humour ,  sarcasm , offensive, motivational, and sentiment) for  multi-tasking . We use the recently released dataset in the Memotion Analysis task @ SemEval 2020, which consists of  memes  annotated for the classes as mentioned above. Empirical results on Memotion dataset show the efficacy of our proposed approach over the existing state-of-the-art systems (Baseline and SemEval 2020 winner). The evaluation also indicates that the proposed multi-task framework yields better performance over the single-task learning.', 'ar': 'في هذه الورقة ، نهدف إلى تعلم العلاقات وأوجه التشابه بين مجموعة متنوعة من المهام ، مثل اكتشاف الفكاهة ، واكتشاف السخرية ، واكتشاف المحتوى المسيء ، واكتشاف المحتوى التحفيزي ، وتحليل المشاعر على شكل معقد إلى حد ما من المعلومات ، مثل الميمات. نقترح إطار عمل للتعلم العميق متعدد المهام والوسائط لحل مهام متعددة في وقت واحد. لتعدد المهام ، نقترح آليتين تشبهان الانتباه ، وحدة العلاقة بين المهام (iTRM) ووحدة العلاقات بين الطبقات (iCRM). الدافع الرئيسي لـ iTRM هو معرفة العلاقة بين المهام لإدراك كيف تساعد بعضها البعض. في المقابل ، يطور iCRM العلاقات بين فئات المهام المختلفة. أخيرًا ، يتم تجميع التمثيلات من كلتا الانتباه ومشاركتها عبر المهام الخمس (أي ، الفكاهة ، السخرية ، الهجومية ، التحفيزية ، والمشاعر) لتعدد المهام. نستخدم مجموعة البيانات التي تم إصدارها مؤخرًا في مهمة Memotion Analysis @ SemEval 2020 ، والتي تتكون من الميمات التي تم شرحها للفئات كما هو مذكور أعلاه. تظهر النتائج التجريبية على مجموعة بيانات Memotion فعالية نهجنا المقترح على أحدث الأنظمة الحالية (Baseline و SemEval 2020 الفائز). يشير التقييم أيضًا إلى أن إطار العمل متعدد المهام المقترح ينتج عنه أداء أفضل على التعلم بمهمة واحدة.', 'es': 'En este artículo, nuestro objetivo es aprender las relaciones y similitudes de una variedad de tareas, como la detección de humor, la detección de sarcasmo, la detección de contenido ofensivo, la detección de contenido motivacional y el análisis de sentimientos en una forma de información un tanto complicada, es decir, los memes. Proponemos un marco de aprendizaje profundo multimodal y multitarea para resolver múltiples tareas simultáneamente. Para la multitarea, proponemos dos mecanismos similares a la atención, a saber, el módulo de relaciones entre tareas (iTRM) y el módulo de relaciones entre clases (iCRM). La principal motivación de iTRM es aprender la relación entre las tareas para darse cuenta de cómo se ayudan entre sí. Por el contrario, iCRM desarrolla relaciones entre las diferentes clases de tareas. Finalmente, las representaciones de ambas atenciones se concatenan y se comparten en las cinco tareas (es decir, humor, sarcasmo, ofensiva, motivacional y sentimiento) para la multitarea. Utilizamos el conjunto de datos publicado recientemente en la tarea Análisis de Memotion @ SemEval 2020, que consiste en memes anotados para las clases como se mencionó anteriormente. Los resultados empíricos en el conjunto de datos de Memotion muestran la eficacia de nuestro enfoque propuesto sobre los sistemas de vanguardia existentes (ganador de Baseline y SemEval 2020). La evaluación también indica que el marco multitarea propuesto produce un mejor rendimiento en comparación con el aprendizaje de una sola tarea.', 'fr': "Dans cet article, nous visons à apprendre les relations et les similitudes entre diverses tâches, telles que la détection de l'humour, la détection du sarcasme, la détection de contenu offensant, la détection de contenu motivant et l'analyse des sentiments sur une forme d'information un peu complexe, c'est-à-dire les mèmes. Nous proposons un cadre de deep learning multitâche et multimodal pour résoudre plusieurs tâches simultanément. Pour le multitâche, nous proposons deux mécanismes similaires à l'attention, à savoir le module de relation inter-tâches (iTRM) et le module de relations interclasses (iCRM). La principale motivation d'iTRM est d'apprendre la relation entre les tâches afin de comprendre comment elles s'entraident. En revanche, iCRM développe des relations entre les différentes catégories de tâches. Enfin, les représentations des deux attentions sont concaténées et partagées entre les cinq tâches (humour, sarcasme, offensive, motivation et sentiment) pour le multitâche. Nous utilisons le jeu de données récemment publié dans la tâche Memotion Analysis @ SemeVal 2020, qui consiste en des mèmes annotés pour les classes comme mentionné ci-dessus. Les résultats empiriques sur l'ensemble de données Memotion montrent l'efficacité de l'approche que nous proposons par rapport aux systèmes de pointe existants (prix Baseline et SemEval 2020). L'évaluation indique également que le cadre multitâche proposé offre de meilleures performances par rapport à l'apprentissage à tâche unique.", 'pt': 'Neste artigo, pretendemos aprender as relações e semelhanças de uma variedade de tarefas, como detecção de humor, detecção de sarcasmo, detecção de conteúdo ofensivo, detecção de conteúdo motivacional e análise de sentimentos em uma forma de informação um tanto complicada, ou seja, memes. Propomos uma estrutura de aprendizado profundo multitarefa e multimodal para resolver várias tarefas simultaneamente. Para multitarefas, propomos dois mecanismos de atenção, a saber, Módulo de Relacionamento entre Tarefas (iTRM) e Módulo de Relacionamento entre Classes (iCRM). A principal motivação do iTRM é aprender a relação entre as tarefas para perceber como elas se ajudam. Em contraste, o iCRM desenvolve relações entre as diferentes classes de tarefas. Finalmente, as representações de ambas as atenções são concatenadas e compartilhadas nas cinco tarefas (ou seja, humor, sarcasmo, ofensiva, motivacional e sentimento) para multitarefa. Usamos o conjunto de dados lançado recentemente na tarefa de Análise de Memória @ SemEval 2020, que consiste em memes anotados para as classes mencionadas acima. Os resultados empíricos no conjunto de dados do Memotion mostram a eficácia da nossa abordagem proposta sobre os sistemas de última geração existentes (vencedor do Baseline e SemEval 2020). A avaliação também indica que a estrutura multitarefa proposta produz melhor desempenho em relação ao aprendizado de tarefa única.', 'ja': '本稿では、ユーモアの検出、皮肉の検出、不快なコンテンツの検出、動機づけコンテンツの検出、感情の分析など、さまざまなタスクの関係性と類似点を、やや複雑な形の情報、すなわちミームについて学ぶことを目的とする。 複数のタスクを同時に解決するためのマルチタスク、マルチモーダルディープラーニングフレームワークを提案します。 マルチタスクについては、2つの注意のようなメカニズム、すなわちを提案している。、タスク間関係モジュール（ iTRM ）およびクラス間関係モジュール（ iCRM ）。 ITRMの主な動機は、タスク間の関係を学び、それらが互いにどのように役立つかを実現することです。 対照的に、iCRMは異なるクラスのタスク間の関係を発展させます。 最後に、両方の注意からの表現が連結され、マルチタスクのための5つのタスク（すなわち、ユーモア、皮肉、攻撃的、動機づけ、感情）にわたって共有されます。 最近リリースされたデータセットをMemotion Analysisタスク@ SemEval 2020で使用します。このタスクは、上記のようにクラスに注釈を付けたミームで構成されています。 Memotionデータセットの実証結果は、既存の最先端システム（ベースラインおよびSemEval 2020受賞者）に対する提案されたアプローチの有効性を示しています。 この評価はまた、提案されたマルチタスクフレームワークが、シングルタスクラーニングよりも優れたパフォーマンスをもたらすことを示している。', 'zh': '夫文者,学之与相似性,幽检刺检,犯性检,动机检,杂文之信(即模因)情析。 吾举一多任务,多模态深学框架,可兼决也。 其于多任务处理也,举二者,模块(iTRM)、类间模块(iCRM)也。 iTRM之机,学务之际,以成其助。 比之,iCRM异务也。 终于两意者,多任务处理之五务(幽默刺刺,动情接)者也。 臣等于 Memotion Analysis @ SemEval 2020 中用近出数集,当数集由上所引类注模因成。 Memotion数集之实结果表明,优于先进之统(Baseline与SemEval 2020获奖者)。 论犹明,比于单任务学,议者多任务框架有善绩效。', 'ru': 'В этой статье мы стремимся изучить взаимосвязи и сходства различных задач, таких как обнаружение юмора, обнаружение сарказма, обнаружение оскорбительного контента, обнаружение мотивационного контента и анализ настроений на несколько сложной форме информации, т.е. мемах. Мы предлагаем многозадачный, мультимодальный фреймворк глубокого обучения для одновременного решения нескольких задач. Для многозадачности мы предлагаем два механизма, похожих на внимание, а именно:, модуль межзадачных отношений (iTRM) и модуль межклассовых отношений (iCRM). Основной мотивацией iTRM является изучение взаимосвязи между задачами, чтобы понять, как они помогают друг другу. Напротив, iCRM развивает отношения между различными классами задач. Наконец, представления от обоих вниманий объединяются и делятся по пяти задачам (т.е. юмор, сарказм, оскорбительные, мотивационные и настроения) для многозадачности. Мы используем недавно выпущенный набор данных в задаче Memotion Analysis @ SemEval 2020, которая состоит из мемов, аннотированных для вышеупомянутых классов. Эмпирические результаты по набору данных Memotion показывают эффективность нашего предлагаемого подхода по сравнению с существующими современными системами (победитель Baseline и SemEval 2020). Оценка также показывает, что предлагаемая многозадачная структура дает лучшие результаты по сравнению с однозадачным обучением.', 'hi': 'इस पेपर में, हम विभिन्न प्रकार के कार्यों के संबंधों और समानताओं को सीखने का लक्ष्य रखते हैं, जैसे कि हास्य का पता लगाना, व्यंग्य का पता लगाना, आक्रामक सामग्री का पता लगाना, प्रेरक सामग्री का पता लगाना और जानकारी के कुछ हद तक जटिल रूप पर भावना विश्लेषण, यानी, मेम्स। हम एक साथ कई कार्यों को हल करने के लिए एक बहु-कार्य, बहु-मोडल डीप लर्निंग फ्रेमवर्क का प्रस्ताव करते हैं। मल्टी-टास्किंग के लिए, हम दो ध्यान-जैसे तंत्र ों का प्रस्ताव करते हैं जैसे, इंटर-टास्क रिलेशनशिप मॉड्यूल (आईटीआरएम) और इंटर-क्लास रिलेशनशिप मॉड्यूल (आईसीआरएम)। आईटीआरएम की मुख्य प्रेरणा यह महसूस करने के लिए कार्यों के बीच संबंधों को सीखना है कि वे एक-दूसरे की मदद कैसे करते हैं। इसके विपरीत, आईसीआरएम कार्यों के विभिन्न वर्गों के बीच संबंध विकसित करता है। अंत में, दोनों ध्यानों से अभ्यावेदन को पांच कार्यों (यानी, हास्य, व्यंग्य, आक्रामक, प्रेरक और भावना) में बहु-टास्किंग के लिए संयोजित और साझा किया जाता है। हम Memotion Analysis Task @ SemEval 2020 में हाल ही में जारी किए गए डेटासेट का उपयोग करते हैं, जिसमें ऊपर उल्लिखित कक्षाओं के लिए एनोटेट किए गए मेम्स होते हैं। Memotion डेटासेट पर अनुभवजन्य परिणाम मौजूदा अत्याधुनिक प्रणालियों (बेसलाइन और SemEval 2020 विजेता) पर हमारे प्रस्तावित दृष्टिकोण की प्रभावकारिता दिखाते हैं। मूल्यांकन यह भी इंगित करता है कि प्रस्तावित बहु-कार्य ढांचे से एकल-कार्य सीखने पर बेहतर प्रदर्शन होता है।', 'ga': 'Sa pháipéar seo, tá sé mar aidhm againn na caidrimh agus na cosúlachtaí a bhaineann le tascanna éagsúla a fhoghlaim, mar shampla greann a bhrath, an searbhas a bhrath, ábhar maslach a bhrath, ábhar spreagtha a bhrath agus anailís meoin ar fhoirm beagán casta faisnéise, i.e., memes. Molaimid creat foghlama domhain ilthasc, ilmhódúil chun tascanna iolracha a réiteach go comhuaineach. Le haghaidh ilthascanna, molaimid dhá mheicníocht aird-chosúil, eadhon, Modúl Caidrimh Idirthasc (iTRM) agus Modúl Caidrimh Idir-ranga (iCRM). Is é príomh-spreagadh iTRM ná an gaol idir na tascanna a fhoghlaim chun tuiscint a fháil ar an gcaoi a gcuidíonn siad lena chéile. I gcodarsnacht leis sin, forbraíonn iCRM caidreamh idir na haicmí éagsúla tascanna. Mar fhocal scoir, déantar uiríll ón dá aird a chomhfhogasú agus a roinnt ar fud na gcúig thasc (i.e. greann, searbhas, maslach, inspreagtha, agus meon) le haghaidh ilthascanna. Bainimid úsáid as an tacar sonraí a eisíodh le déanaí sa tasc Anailís Memotion @ SemEval 2020, atá comhdhéanta de memes anótáilte do na ranganna mar a luadh thuas. Léiríonn torthaí eimpíreacha ar thacar sonraí Memotion éifeachtúlacht ár gcur chuige molta thar na córais úrscothacha atá ann cheana féin (Buaiteoir Bunlíne agus SemEval 2020). Léirítear sa mheastóireacht freisin go bhfuil feidhmíocht níos fearr ag baint leis an gcreat ilthascanna atá beartaithe thar an bhfoghlaim aon tasc.', 'ka': 'ამ დომენტში ჩვენ უნდა ვისწავლოთ განსხვავებული რაოდენობების და განსხვავებების შესახებ, როგორც ჰუმური განსხვავება, საპკასმის განსხვავება, განსხვავება ინფორმაციის განსხვავება, მოტივიციონალური შესახებ განსხვავება და სენტიმენტის ანალ ჩვენ მრავალური დავალება, მრავალური მოდიალური სწავლების ფრამეტრი, რომელიც მრავალური დავალება ერთად. მრავალური დავალებისთვის, ჩვენ გვეძლევა ორი დაახლოების მექანემისთვის. Inter- task Relationship Module (iTRM) და Inter- class Relationship Module (iCRM). iTRM-ის მნიშვნელოვანი მოტივაცია არის გავისწავლა საქმედების განმავლობა, როგორ ერთმანეთს დახმარებენ. კონტრასტში, iCRM განვითარებს პარამეტრების განსხვავებული კლასების შესახებ. საბოლოოდ, ორივე მონაცემების გამოსახულებები მრავალური საქმებისთვის გაყოფილი და გაყოფილი ხუთი საქმებისთვის (მაგალითად, ჰუმური, საპკასმი, სატუნციური, მოტივიციური და სენტიმენტი) მომრა ჩვენ გამოყენებთ მხოლოდ განახლებული მონაცემების ანალიზიციის რაოდენობაში @@SemEval 2020, რომელიც შექმნა მემების შესახებ, რომელიც საუკეთესებისთვის განახლებულია. მემოციონის მონაცემების შესახებ მონაცემების შესახებ ჩვენი წარმოიდგინეთ პროგრამის ეფექტიურობას ჩვენი წარმოიდგინეთ სისტემების მუშაობაზე (ბაზილინი და semiEval 2020 ამოცანაში ასევე აღწერს, რომ მრავალრამეტრი დავალების კონფიგურაცია უფრო მეტი დავალება ერთადერთი დავალების სწავლებაზე.', 'el': 'Στην παρούσα εργασία, στοχεύουμε στην εκμάθηση των σχέσεων και των ομοιοτήτων μιας ποικιλίας εργασιών, όπως η ανίχνευση χιούμορ, η ανίχνευση σαρκασμού, η ανίχνευση προσβλητικού περιεχομένου, η ανίχνευση κινήτρων και η ανάλυση συναισθημάτων σε μια κάπως περίπλοκη μορφή πληροφοριών, δηλαδή μιμίδια. Προτείνουμε ένα πλαίσιο βαθιάς μάθησης πολλαπλών εργασιών, πολλαπλών τρόπων για την επίλυση πολλαπλών εργασιών ταυτόχρονα. Για την πολλαπλή εργασία, προτείνουμε δύο μηχανισμούς προσοχής: Ενότητα σχέσης μεταξύ εργασιών (iTRM) και Ενότητα σχέσης μεταξύ κλάσης (iCRM). Το κύριο κίνητρο του είναι να μάθει τη σχέση μεταξύ των εργασιών για να συνειδητοποιήσει πώς βοηθούν ο ένας τον άλλον. Αντίθετα, αναπτύσσει σχέσεις μεταξύ των διαφόρων κατηγοριών εργασιών. Τέλος, οι αναπαραστάσεις και από τις δύο προσοχές αλληλοσυνδέονται και μοιράζονται μεταξύ των πέντε καθηκόντων (δηλαδή χιούμορ, σαρκασμός, προσβλητικό, κίνητρο και συναίσθημα) για την πολλαπλή εργασία. Χρησιμοποιούμε το πρόσφατα δημοσιευμένο σύνολο δεδομένων στην εργασία Ανάλυση μνημονίων στο το οποίο αποτελείται από μιμητικά σχολιασμένα για τις τάξεις όπως προαναφέρθηκε. Τα εμπειρικά αποτελέσματα του συνόλου δεδομένων δείχνουν την αποτελεσματικότητα της προτεινόμενης προσέγγισής μας σε σχέση με τα υπάρχοντα συστήματα τελευταίας τεχνολογίας (νικητής της γραμμής βάσης και της σειράς 2020). Η αξιολόγηση δείχνει επίσης ότι το προτεινόμενο πλαίσιο πολλαπλών εργασιών αποδίδει καλύτερες επιδόσεις έναντι της μάθησης μιας εργασίας.', 'hu': 'Jelen tanulmányban különböző feladatok, mint például humorfelismerés, szarkazmus felismerés, sértő tartalom felismerés, motivációs tartalom felismerés és érzelmek elemzése egy kissé bonyolult információformán, azaz mémeken. Egy multifeladatos, multimodális mélytanulási keretrendszert javasolunk több feladat egyidejű megoldására. A többfunkciós feladatokhoz két figyelemszerű mechanizmust javasolunk, azaz: Tevékenységközi kapcsolati modul (iTRM) és osztályközi kapcsolati modul (iCRM). Az iTRM fő motivációja, hogy megismerje a feladatok közötti kapcsolatot, hogy megvalósítsa, hogyan segítik egymást. Ezzel szemben az iCRM kapcsolatokat fejleszt ki a különböző feladatosztályok között. Végül mindkét figyelem reprezentációja összefügg és megosztja az öt feladat (humor, szarkazmus, sértő, motiváció és érzelem) között a multi-feladat. A nemrég kiadott adatkészletet használjuk a Memotion Analysis feladatban @ SemEval 2020, amely a fent említett osztályokhoz jegyzetelt mémekből áll. A Memotion adatkészlet empirikus eredményei azt mutatják, hogy javasolt megközelítésünk hatékonysága a meglévő korszerű rendszerekkel szemben (Baseline és SemEval 2020 győztes). Az értékelés azt is jelzi, hogy a javasolt többfeladatos keretrendszer jobb teljesítményt nyújt az egyfeladatos tanuláshoz képest.', 'it': "In questo articolo, ci proponiamo di apprendere le relazioni e le somiglianze di una varietà di compiti, come il rilevamento dell'umorismo, il rilevamento del sarcasmo, il rilevamento offensivo dei contenuti, il rilevamento motivazionale dei contenuti e l'analisi del sentiment su una forma piuttosto complicata di informazione, cioè i meme. Proponiamo un framework multi-task e multimodale di deep learning per risolvere più compiti contemporaneamente. Per il multi-tasking, proponiamo due meccanismi di attenzione, vale a dire., Intertask Relationship Module (iTRM) e Interclass Relationship Module (iCRM). La motivazione principale di iTRM è quella di imparare la relazione tra i compiti per realizzare come si aiutano a vicenda. Al contrario, iCRM sviluppa relazioni tra le diverse classi di attività. Infine, le rappresentazioni di entrambe le attenzioni sono concatenate e condivise tra i cinque compiti (cioè umorismo, sarcasmo, offensivo, motivazionale e sentimentale) per il multitasking. Usiamo il set di dati recentemente rilasciato nell'attività Memotion Analysis @ SemEval 2020, che consiste di meme annotati per le classi come sopra menzionato. I risultati empirici sul set di dati Memotion mostrano l'efficacia del nostro approccio proposto rispetto ai sistemi esistenti all'avanguardia (Baseline e SemEval 2020 vincitore). La valutazione indica inoltre che il quadro multi-task proposto offre prestazioni migliori rispetto all'apprendimento monotask.", 'kk': 'Бұл қағазда біз бірнеше тапсырмалардың қатынасын және ұқсастығын оқытуға мақсат береміз, мысалы "хумор" анықтау, сарказм анықтау, қарсы мазмұнын анықтау, мотивациялық мазмұнын анықтау және сезімдік анализ, мәліметтердің бірнеш Біз бірнеше тапсырмаларды бірден шешу үшін көптеген тапсырмалар, көптеген көптеген түсті оқыту бағдарламасын ұсынамыз. Көптеген тапсырмалар үшін, біз екі қызықтық сияқты механизмдерді ұсынамыз. Тапсырмалар арасындағы қатынас модулі (iTRM) және класс арасындағы қатынас модулі (iCRM). iTRM бағдарламасының негізгі мотивациясы - тапсырмалар арасындағы қатынасын бір-біріне қалай көмектесетінін түсіну. Контрастырса, iCRM тапсырмалардың түрлі классының қатынасын жасайды. Соңғы сәтте, екеуінің қатынасы бірнеше тапсырма үшін бес тапсырмалардың (мәселен, хумор, сарказм, қарсы, мотивациялық және көп тапсырмалардың көп тапсырмалардың түрінде бөлікті және б Жуырдағы шығарылған деректер жиынын Memotion Analysis тапсырмасында @ SemEval 2020 қолданамыз. Бұл жоғардағы мәліметтер үшін келтірілген класстардың мемоттарынан тұрады. Мемоцияның деректер қорларының империялық нәтижелері біздің ұсынылған тәсіліміздің эффективнігін көрсетеді (негізгі жол мен semiEval 2020 жетілдірушісі). Бұл оқиға қолданылатын көп тапсырмалар қоршауының бір тапсырманың оқиғаларының артықшылығын жақсы жұмыс істейтінін көрсетеді.', 'lt': 'Šiame dokumente siekiame i šsiaiškinti įvairių užduočių santykius ir panašumus, pvz., humoro aptikimą, sarkazmo aptikimą, užpuolamąjį turinį aptikimą, motyvacinį turinio aptikimą ir jausmų analizę šiek tiek sudėtingoje informacijos formoje, t. y. memes. Siūlome įvairių užduočių daugiarūšio giliavandenio mokymosi sistemą, kad būtų išspręstos kelios užduotys vienu metu. Daugiaužduočių srityje siūlome du į dėmesį panašius mechanizmus, t. y. Tarpužduočių ryšių modulis (iTRM) ir tarpklasių ryšių modulis (iCRM). Pagrindinė iTRM motyvacija yra sužinoti užduočių santykius, kad suprastų, kaip jos viena kitai padeda. Priešingai, iCRM plėtoja įvairių užduočių klasių santykius. Galiausiai abiejų dėmesio atstovai sutrumpinti ir dalijami penkiose užduotyse (t. y. humoras, sarkazmas, užpuolimas, motyvacija ir jausmas), kuriose atliekamos įvairios užduotys. Naudojame neseniai paskelbtą duomenų rinkinį Memotion Analysis task @SemEval 2020, kurį sudaro pirmiau minėtoms klasėms priskiriami memei. Empiriniai Memorial duomenų rinkinio rezultatai rodo, kad mūsų siūlomas požiūris veiksmingas esamoms moderniausioms sistemoms (pradinis ir „SemEval 2020“ laimėtojas). Vertinimas taip pat rodo, kad siūloma daugiafunkcinė sistema užtikrina geresnius vienos užduoties mokymosi rezultatus.', 'mk': 'Во овој весник, ние имаме за цел да ги научиме односите и сличностите на различни задачи, како што се детекција на хумор, детекција на сарказам, детекција на навредлива содржина, детекција на мотивационална содржина и анализа на чувствата на некако комплицирана форма на информации, т.е. меми. We propose a multi-task, multi-modal deep learning framework to solve multiple tasks simultaneously.  For multi-tasking, we propose two attention-like mechanisms viz.,  Модул за врска меѓузадачи (iTRM) и модул за врска меѓукласа (iCRM). The main motivation of iTRM is to learn the relationship between the tasks to realize how they help each other.  За разлика од тоа, iCRM развива односи помеѓу различните класи на задачи. Конечно, претставувањата од двете вниманија се концентрирани и споделени низ петте задачи (т.е., хумор, сарказам, навредливи, мотивационални и чувства) за мултизадачи. Ние ја користиме неодамна објавената датотека во задачата за анализа на мемотијата @SemEval 2020, која се состои од меми анотирани за класите како што се спомнува горе. Империските резултати на сетот на податоци за мемоција ја покажуваат ефикасноста на нашиот предложен пристап во однос на постојните најсовремени системи (победник на Базилната линија и Семевал 2020). The evaluation also indicates that the proposed multi-task framework yields better performance over the single-task learning.', 'ms': 'Dalam kertas ini, kami bertujuan untuk mempelajari hubungan dan persamaan dari berbagai tugas, seperti pengesan humor, pengesan sarkasm, pengesan kandungan serangan, pengesan kandungan motivasi dan analisis perasaan pada bentuk maklumat yang agak rumit, iaitu memes. Kami melamar kerangka pembelajaran dalam berbilang-tugas, berbilang-modal untuk menyelesaikan beberapa tugas secara bersamaan. Untuk multi-tasking, kami cadangkan dua mekanisme seperti perhatian viz. Modul Hubungan Antara-Tugas (iTRM) dan Modul Hubungan Antara-Kelas (iCRM). Motif utama iTRM adalah untuk belajar hubungan antara tugas untuk sedar bagaimana mereka membantu satu sama lain. In contrast, iCRM develops relations between the different classes of tasks.  Akhirnya, perwakilan dari kedua-dua perhatian dikongsi dan dikongsi melalui lima tugas (iaitu humor, sarkasme, serangan, motivasi, dan perasaan) untuk multi-tugas. Kami menggunakan set data yang baru-baru ini dibebaskan dalam tugas Analisi Memotion @ SemEval 2020, yang terdiri dari meme yang dicatat untuk kelas seperti yang disebut di atas. Keputusan empirik pada set data Memotion menunjukkan kegunaan pendekatan kami yang diusulkan terhadap sistem-state-of-the-art yang ada (Baseline dan SemEval 2020 pemenang). The evaluation also indicates that the proposed multi-task framework yields better performance over the single-task learning.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d വ്യത്യസ്തമായ ജോലികളുടെ ബന്ധങ്ങളും സംബന്ധങ്ങളും പഠിപ്പിക്കാന്\u200d ഉദ്ദേശിക്കുന്നു. തമാശയുടെ കണ്ടുപിടിക്കാന്\u200d, സറക്കാസം കണ്ടുപിടിക്കുന്നത്, പ്രാര്\u200dത ഞങ്ങള്\u200d ഒരു പല ജോലിയുടെയും അധികമായ മോഡില്\u200d ആഴത്തില്\u200d പഠിക്കുന്ന ഫ്രെയിമെക്ക് പ്രൊദ്ദേശിക്കുന്നു. ഒരേ സമയത് പല്ലാത്ത ജോലിക്ക് വേണ്ടി, രണ്ട് ശ്രദ്ധിക്കുന്ന മെക്കാനിസ് വിസ് നാം പ്രൊദാനം ചെയ്യുന്നു. Inter-task Relationship Module (iTRM) and Inter-class Relationship Module (iCRM). ഐTRM-ന്റെ പ്രധാനപ്പെട്ട പ്രധാനപ്പെട്ടത് ജോലികള്\u200dക്കിടയിലെ ബന്ധം പഠിപ്പിക്കാനാണ്. അവര്\u200d പരസ്പരം സഹായി വ്യത്യസ്തമായി ഐസിഎം ജോലികളുടെ വ്യത്യസ്ത ക്ലാസുകള്\u200dക്കിടയിലുള്ള ബന്ധങ്ങള്\u200d പരിഗണിക്കുന്നു. അവസാനം, രണ്ടു ശ്രദ്ധയില്\u200d നിന്നും പ്രതിനിധികള്\u200d അഞ്ച് ജോലികള്\u200dക്ക് മുകളില്\u200d പങ്കുചേര്\u200dക്കുകയും ചെയ്തിരിക്കുന്നു. (അതായത് തമാശ, ചര്\u200dക്കസം, ആക്രമണ മെമ്മറിഷന്\u200d അന്യായമായ ജോലിയില്\u200d നമ്മള്\u200d അടുത്തുള്ള വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നു @SemEval 2020, മേലോട്ടുള്ള ക്ലാസുകള്\u200dക്ക് വേണ്ടി  മെമ്മറിഷന്\u200d ഡാറ്റാസറ്റിലെ സാമ്രിക്കല്\u200d ഫലങ്ങള്\u200d നിലവിലുള്ള സ്ഥിതിയുടെ നിലവിലുള്ള സ്ഥിതിയില്\u200d നമ്മുടെ പ്രോദ്ദേശിക്കപ്പെട് പ്രൊദ്ദേശിക്കപ്പെട്ട പല-ജോലിയുടെ ഫ്രെയിമ്പ് ഒരേ ജോലി പഠിക്കുന്നതിനെക്കുറിച്ച് കൂടുതല്\u200d പ്രവര്\u200dത്ത', 'mn': 'Энэ цаасан дээр бид өөр олон зүйлийн харилцаа, төстэй зүйлсийг сурах зорилготой. Хуморын ололт, саркассмын ололт, хүчирхийллийн агуулалт, сэтгэл хөдлөл өгөгдлийн мэдээллийн тухай сэтгэл хөдлөл, сэтгэл хөдлөл, сэтгэл хөдлөл шинжилгээ, мэд Бид олон ажил, олон моделийн гүн гүнзгий суралцах хэлбэрээр олон ажил шийдвэрлэх боломжтой санал өгдөг. Бид олон ажлын төлөө хоёр анхаарлын төлөвлөгөөтэй механизмийг санал болгож байна. Интерфейсийн харилцааны модуль (iTRM) болон интерфейсийн харилцааны модуль (iCRM). iTRM-ын гол урам зорилго нь ажлын хоорондын харилцаа хэрхэн тусалдаг талаар ойлгох юм. Харамсалтай нь, iCRM ажлын өөр ангийнхарилцааныг хөгжүүлдэг. Эцэст нь, сонирхолтой байдлаас хоёр дахь даалгавар нь олон даалгаварын төлөө (яг л "хумор, саркассм, зорилготой, урам зориг, сэтгэл хөдлөл") таван даалгавар дээр хуваалцдаг. Бид саяхан хэвлэгдсэн өгөгдлийн санааны шинжилгээний ажил @ SemEval 2020 дээр ашиглаж байна. Энэ нь дээр хэвлэгдсэн хичээлийн санаануудын санаанууд юм. Шинэ санааны өгөгдлийн сангийн эзэмшигийн үр дүнд бидний санал дэвшүүлсэн арга хэмжээний тогтолцооны үр дүнг харуулдаг. Шалгалт нь мөн олон ажлын үйлдвэрлэл нь нэг ажлын суралцах дээр илүү сайн үйлдвэрлэл гаргадаг гэдгийг харуулдаг.', 'no': 'I denne papiret må vi lære forholdet og liknande oppgåver, som humor-oppdaging, sarkasm-oppdaging, offensiv innhald-oppdaging, motivasjonalt innhald-oppdaging og sentimentanalyse om ein litt komplisert form av informasjon, t.d. memer. Vi foreslår eit fleire oppgåver, fleire modal dyp læringsrammeverk for å løysa fleire oppgåver samtidig. For fleire oppgåver, foreslår vi to oppmerksomhet-liknande mekanisme, f.eks. Inter- oppgåve relasjonsmodul (iTRM) og Inter- klasse relasjonsmodul (iCRM). Høvudsmotivasjonen av iTRM er å lære forholdet mellom oppgåva for å forstå korleis dei hjelper kvarandre. I contrast, iCRM utviklar forholdet mellom dei ulike oppgåver klassene. Til slutt er representasjonane frå begge opplysningar samsvart og delt over fem oppgåver (t.d. humor, sarkasm, offensiv, motivasjon og sentiment) for fleire oppgåver. Vi bruker den siste utgjevne datasettet i Memotion Analysis oppgåva @ SemEval 2020, som inneheld av memer som er notata for klassene som oppgjevne over. Empirical results on Memotion dataset show the efficacy of our proposed approach over the existing state of the art systems (Baseline and semiEval 2020 winner). Evalueringa viser også at den foreslåde fleire oppgåver-rammeverket gjer betre utviklinga over den enkelte oppgåva-læringa.', 'pl': 'Celem niniejszego artykułu jest poznanie związków i podobieństw różnych zadań, takich jak wykrywanie humoru, wykrywanie sarkazmu, wykrywanie obraźliwych treści, wykrywanie treści motywacyjnych i analiza sentymentów na nieco skomplikowanej formie informacji, tj. memach. Proponujemy wielozadaniowe, multimodalne ramy głębokiego uczenia, aby rozwiązywać wiele zadań jednocześnie. W przypadku wielozadaniowości proponujemy dwa mechanizmy podobne do uwagi: Moduł relacji międzyklasowych (iTRM) i moduł relacji międzyklasowych (iCRM). Główną motywacją iTRM jest poznanie relacji między zadaniami, aby uświadomić sobie, jak sobie nawzajem pomagają. Natomiast iCRM rozwija relacje między różnymi klasami zadań. Wreszcie, reprezentacje obu uwag są łączone i dzielone w pięciu zadaniach (tj. humor, sarkazm, obraźliwy, motywacyjny i sentyment) dla wielozadaniowości. Wykorzystujemy niedawno wydany zestaw danych w zadaniu Analiza memowania SemEval 2020, który składa się z memów adnotacyjnych dla klas, jak wspomniano powyżej. Wyniki empiryczne dotyczące zbioru danych Memotion pokazują skuteczność proponowanego podejścia w stosunku do istniejących najnowocześniejszych systemów (laureat Baseline i SemEval 2020). Ocena wskazuje również, że proponowane ramy wielozadaniowe przynoszą lepsze wyniki w porównaniu z uczeniem się jednozadaniowym.', 'ro': 'În această lucrare, ne propunem să învățăm relațiile și similaritățile unei varietăți de sarcini, cum ar fi detectarea umorului, detectarea sarcasmului, detectarea conținutului ofensator, detectarea conținutului motivațional și analiza sentimentului pe o formă oarecum complicată de informație, și anume meme. Propunem un cadru multimodal de învățare profundă multimodală pentru a rezolva simultan mai multe sarcini. Pentru multi-tasking, propunem două mecanisme asemănătoare atenției și anume: Modulul de relație între sarcini (iTRM) și Modulul de relație între clase (iCRM). Motivația principală a iTRM este de a învăța relația dintre sarcini pentru a realiza modul în care acestea se ajută reciproc. În schimb, iCRM dezvoltă relații între diferitele clase de sarcini. În cele din urmă, reprezentările ambelor atenții sunt concatenate și împărtășite în cele cinci sarcini (adică umor, sarcasm, ofensiv, motivațional și sentiment) pentru multitasking. Folosim setul de date recent lansat în sarcina Analiza Memoției @ SemEval 2020, care constă în meme adnotate pentru clasele menționate mai sus. Rezultatele empirice privind setul de date Memotion arată eficacitatea abordării propuse față de sistemele de ultimă generație existente (Baseline și SemEval 2020 câștigător). Evaluarea arată, de asemenea, că cadrul propus pentru mai multe sarcini oferă performanțe mai bune față de învățarea cu o singură sarcină.', 'sr': 'U ovom papiru ciljamo je naučiti veze i sličnosti raznih zadataka, poput otkrivanja humora, detekcije sarkazma, detekcije ofanzivnog sadržaja, detekcije motivacije sadržaja i analize osjećanja o nekom komplikovanom obliku informacija, tj. meme. Predlažemo višestruki zadatak, multimodalni duboko učenje okvir da istovremeno reši više zadataka. Za višestruke zadatke predlažemo dva mehanizma poput pažnje. Modul odnosa međuzadataka (iTRM) i modul odnosa međuklase (iCRM). Glavna motivacija iTRM je naučiti vezu između zadataka da bi shvatili kako pomažu jedno drugom. Usrotno, iCRM razvija odnose između različitih klasa zadataka. Konačno, predstave iz obje pažnje su potvrđene i dijeljene preko pet zadataka (tj. humor, sarkazam, ofanzivnim, motivacionalnim i osjećajima) za višestruke zadatke. Koristimo nedavno oslobođenu kompletu podataka u zadatku za analizu Memotion @ SemEval 2020, koja se sastoji od meme koji su navodili za klase kao što je spomenulo iznad. Impirički rezultati na setu podataka o Memotiju pokazuju efikasnost našeg predloženog pristupa na postojećim sistemima stanja umjetnosti (osnovna linija i dobitnik polEvala 2020). Novinarenje takođe ukazuje na to da predloženi višezadatačni okvir pruža bolju provedbu nad učenjem jednozadataka.', 'si': 'මේ පත්තරේ අපි ඉලක්කුවේ වෙනස් වැඩක් සම්බන්ධතාවක් සහ සම්බන්ධතාවක් ඉගෙන ගන්න, හමුරු පරීක්ෂණය, සර්කාස් පරීක්ෂණය, අපරාධික සාමාන්ත්\u200dරිය පරීක්ෂණය, ප්\u200dර අපි ගොඩක් වැඩක්, ගොඩක් මෝඩාල් ගොඩක් ගොඩක් ඉගෙන ගොඩක් වැඩක් විසඳන්න සැලසුම් කරනවා. ගොඩක් වැඩක් වෙනුවෙන්, අපි අවධානයක් වගේ පරික්ෂාවක් දෙකක් ප්\u200dරයෝජනය කරන්නේ. සම්බන්ධ වැඩසම්බන්ධතා මොඩියුල් (iTRM) සහ අන්තර්ගක්ෂාව සම්බන්ධතා මොඩියුල් (iCRM). iTRM ගේ ප්\u200dරධාන ප්\u200dරශ්නයක් තමයි වැඩේ අතර සම්බන්ධය ඉගෙන ගන්න, ඔවුන් එක්කෙනෙක්ට උදව් කරන්න කොහොමද කි වෙනස් වෙනුවෙන්, iCRM වෙනස් විදිහට වැඩක් වර්ගයේ සම්බන්ධතාවක් නිර්මාණය කරනවා. අන්තිමේදී, දෙන්නම අවධානයෙන් ප්\u200dරතිනිධානය සම්බන්ධ වෙලා තියෙනවා වගේම වැඩ පහක් වෙනුවෙන් සම්බන්ධ වෙලා තියෙනවා. අපි මේමෝටියෝ විශ්ලේෂණ විශ්ලේෂණ වැඩේ අවස්ථාවක් පාවිච්චි කරලා තියෙන දත්ත සෙට්ටුව භාවිතා කරනවා @ semeval මෙමෝටියෝ දත්ත සූදානයේ අධ්\u200dයාත්මක ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d ඒ විශ්වාසයෙන් පෙන්වන්නේ විශ්වාස කරන්නේ වැඩි වැඩි වැඩි වැඩි ක්\u200dරියාවක් එක්ක වැඩේ ඉගෙනීමේ හොඳ', 'so': 'Qoraalkan waxaynu ku qornaa inaannu barno xiriirka iyo shuqullada kala duduwan, tusaale ahaan baaritaanka jimicsiga, garashada sarkaamka, garshada waxyaabaha dhimirka ah, baaritaanka waxyaabaha dhaqdhaqaaqa iyo baaritaanka fikrada, tusaale ahaan macluumaad adag. Waxaannu soo jeedaynaa koorso waxbarasho badan oo kala duduwan, si loo xalliyo shaqooyin kala duduwan. Shaqooyin badan darteed, waxaan soo jeedaynaa laba mechanisyo oo u eg taqsiir, Isku xiriirka shaqada (iTRM) iyo module xiriirka fasalka Inter-fasalka (iCRM). Ujeedada ugu weyn ee iTRM waa in la barto xiriirka shaqaalaha dhexdooda si ay u ogaato sida ay isu caawinayaan. In contrast, iCRM develops relations between the different classes of tasks.  Ugu dambaysta waxaa lagu qeybiyaa qeyb ka mid ah shantii shaqadood (tusaale ahaan xijooyin, sarcasm, waxyeello, waxqabasho iyo fikrad badan). Waxaynu isticmaalnaa macluumaadkii la soo daayay ee ugu dambeysay shaqada xasuusta @SemEval 2020, kaas oo ka mid ah memeys dhibaataysan fasalka ku qoran. Xirfaha ku saabsan macluumaadka xusuusta ayaa tusaya saameyn ku saabsan qaabilaada la soo jeeday oo ku saabsan xaaladda-qoraalka (Baseline iyo SemEval 2020 guuleysan). Qiimeynta waxaa sidoo kale loola jeedaa in qasnada la soo jeeday shaqo badan ay ka muuqataa mid ka wanaagsan waxbarashada hal shaqo oo kaliya.', 'sv': 'I denna uppsats syftar vi till att lära oss relationerna och likheterna mellan en mängd olika uppgifter, såsom humor detektering, sarkasm detektering, stötande innehållsdetektering, motivationsinnehållsdetektering och sentimental analys på en något komplicerad form av information, dvs memes. Vi föreslår en multi-task, multimodal djupinlärningsram för att lösa flera uppgifter samtidigt. För multi-tasking föreslår vi två uppmärksamhetsliknande mekanismer dvs., Intertask Relationship Module (iTRM) och Interclass Relationship Module (iCRM). Den huvudsakliga motivationen för iTRM är att lära sig relationen mellan uppgifterna för att inse hur de hjälper varandra. Däremot utvecklar iCRM relationer mellan de olika klasserna av uppgifter. Slutligen sammanfogas representationer från båda uppmärksamheten och delas över de fem uppgifterna (dvs humor, sarkasm, stötande, motiverande och sentiment) för multitasking. Vi använder den nyligen släppta datauppsättningen i Memotion Analysis uppgiften @ SemEval 2020, som består av memes kommenterade för klasserna som nämnts ovan. Empiriska resultat på Memotion dataset visar effektiviteten av vårt föreslagna tillvägagångssätt jämfört med befintliga state-of-the-art system (Baseline och SemEval 2020 vinnare). Utvärderingen visar också att det föreslagna ramverket för flera uppgifter ger bättre resultat än lärandet med en enda uppgift.', 'ta': 'இந்த காகிதத்தில், நாம் பல்வேறு பணிகளின் உறவுகள் மற்றும் ஒத்திசைகளையும் கற்றுக் கொள்ள நோக்குகிறோம், அதாவது சூடான கண்டுபிடிப்பு, சூழ்நிலையான உள்ளடக்கங்கள் கண்டுபிடிப்பத பல-பணிகள், பல-மாற்று ஆழமான கற்றுக்கொள்ளும் சட்டத்தை நாம் பரிந்துரைக்கிறோம் அதே போல் பல பணிகளை தீர்வு செய்ய. பல பணிகளுக்கு, நாம் இரண்டு கவனத்தைப் போன்ற முறைமைகளை விஸ் பரிந்துரைக்கிறோம். செயல் தொடர்பு கூறு (iTRM) மற்றும் இட வகுப்பு தொடர்பு கூறு (iCRM). The main motivation of iTRM is to learn the relationship between the tasks to realize how they help each other.  மாறாக, iCRM பணிகளின் வேறு வகுப்புகளுக்கிடையே தொடர்புகளை உருவாக்குகிறது. கடைசியாக, இரு பார்வைகளில் இருந்தும் பிரதிநிதிகளும் ஒருங்கிணைக்கப்பட்டுள்ளன மற்றும் பல பணிகளுக்கு முழுமையாக பங்கிடப்பட்டுள்ளன (அதாவது, சூடு, சூ நாங்கள் சமீபத்தில் வெளியிடப்பட்ட தகவல் அமைப்பை பயன்படுத்தி நினைவு Analysis பணியில் @SemEval 2020, அது மேலே குறிப்பிட்ட வகுப்புகளுக்கு க நினைவு தரவுத்தளத்தின் விளைவுகள் தற்போதைய நிலையில் இருக்கும் கலை அமைப்புகளின் விளைவுகளைக் காட்டும் இந்த மதிப்பீடு மேலும் குறிப்பிடுகிறது பரிந்துரைக்கப்பட்ட பல பணி சட்டத்தில் ஒரு செயல் கற்றுக்கொள்ளும் மேலான', 'ur': 'اس کاغذ میں ہم ایک طرح طرح کے کاموں کی رابطہ اور شباهت کی تعلیم کرنا چاہتے ہیں، جیسے ہمور کا اظہار، سارکاسم کا اظہار، فساد منصفات کا اظہار، انگیز منصفات کا اظہار اور احساسات کا تحلیل ایک کم پیچیدہ طرح کی اطلاعات پر، یعنی میموں پر۔ ہم ایک multi-task, multi-modal deep learning framework propose to solve multiple tasks simultaneously. بہت سے کام کے لئے ہم دو مکانیزوں کی طرح توجه کریں گے۔ Inter-task Relationship Module (iTRM) and Inter-Class Relationship Module (iCRM). iTRM کی اصلی دلیل یہ ہے کہ اپنے کاموں کے درمیان رابطہ کو سمجھ سکیں کہ وہ ایک دوسرے کی مدد کیسے کرتے ہیں۔ بغیر اس کے، iCRM نے کاموں کے مختلف کلاس کے درمیان رابطہ اختیار کیا ہے. بالآخر، دونوں غور سے نشانیاں مختلف طریقے کے لئے پانچ کاموں میں (یعنی ہنسی, sarcasm, offensive, motivational, and sentimental) مشترک ہیں۔ ہم نے اچھی طرح سے ڈیٹ سٹ کو مموٹیون تحقیقات کے تابع میں استعمال کیا ہے @ SemEval 2020، جو کلاس کے لئے یادہانی کیا گیا ہے۔ مموٹیون ڈیٹ سٹ کے امپراتیک نتائج ہمارے پیشنهاد کی تقریبا کے موجود موجود state-of-the-art systems (Baseline and SemEval 2020 winner) کے ذریعہ موجود ہیں۔ اس کا ارزیابی بھی دکھاتا ہے کہ پیشنهاد ملتی-ٹاکس فرمیک ایک ٹاکس کی تعلیم پر بہترین عملکرد پیدا کرتا ہے.', 'mt': 'In this paper, we aim at learning the relationships and similarities of a variety of tasks, such as humour detection, sarcasm detection, offensive content detection, motivational content detection and sentiment analysis on a somewhat complicated form of information, i.e., memes.  We propose a multi-task, multi-modal deep learning framework to solve multiple tasks simultaneously.  For multi-tasking, we propose two attention-like mechanisms viz.,  Inter-task Relationship Module (iTRM) and Inter-class Relationship Module (iCRM).  The main motivation of iTRM is to learn the relationship between the tasks to realize how they help each other.  In contrast, iCRM develops relations between the different classes of tasks.  Fl-aħħar nett, ir-rappreżentazzjonijiet miż-żewġ attenzjonijiet huma konġunti u kondiviżi matul il-ħames kompiti (jiġifieri l-umor, is-sarkazmu, l-ofensiv, il-motivazzjoni, u s-sentiment) għal multi-kompiti. We use the recently released dataset in the Memotion Analysis task @ SemEval 2020, which consists of memes annotated for the classes as mentioned above.  Empirical results on Memotion dataset show the efficacy of our proposed approach over the existing state-of-the-art systems (Baseline and SemEval 2020 winner).  L-evalwazzjoni tindika wkoll li l-qafas multikompitu propost jagħti prestazzjoni aħjar fuq it-tagħlim ta’ kompitu wieħed.', 'uz': "Bu hujjatda, biz bir necha xil vazifalar bilan aloqalarni o'rganishga qaramamiz, sarkasm aniqlashni, harakat mavzuni aniqlashni, motivatsiyot tarkibini aniqlashni va hisobni aniqlashni bir qanchalik murakkab maʼlumot turini o'rganamiz, balki meslik. Biz bir necha vazifalarni bir necha xil vazifalarni ko'paytirish uchun bir necha vazifalar o'ylab ko'proq o'rganish qanday qilamiz. Ko'pchilik vazifalar uchun biz ikkita taqdimlik mekanizni o'ylaymiz. Vazifaning interfeys aloqa moduli (iTRM) va sinf boshqa aloqa moduli (iCRM). The main motivation of iTRM is to learn the relationship between the tasks to realize how they help each other.  ICRM vazifalar boshqa sinfning orasidagi aloqalarni taʼminlaydi. Oxiri, ikkita tashkilotlardan tashkilotlar bir necha vazifalar bilan bir necha vazifalar bilan bir xil vazifalar bilan bog'langan. @ SemEval 2020, yuqoridagi sinfning taʼminotlari uchun qisqarli narsalar bo'lgan. Name Ko'rib chiqish esa, quyidagi bir necha vazifa freymi bir vazifa o'rganishda yaxshi bajarish natijasida bajaradi.", 'vi': "Trong bài báo này, chúng tôi hướng tới việc học các mối quan hệ và đi ểm tương đồng của nhiều công việc khác nhau, như việc khám phá âm tính, phát hiện nội dung tấn công, phát hiện nội dung động lực, và phân tích cảm xúc về một dạng thông tin phức tạp, ví dụ, các ký ức. Chúng tôi đề xuất một cơ sở tập luyện đa năng nhiều phương thần để giải quyết nhiều việc cùng lúc. Với nhiều nhiệm vụ, chúng tôi đề xuất hai cơ quan chú ý: Mô- đun mối quan hệ giữa các nhiệm vụ (iTM) và Mô- đun mối quan hệ xuyên đẳng cấp (iCRM). Tạo động cơ chính của iTRM là tìm hiểu mối quan hệ giữa các nhiệm vụ để nhận ra cách chúng giúp đỡ nhau. Ngược lại, iTCRM phát triển mối quan hệ giữa các hạng nhiệm vụ khác nhau. Và cuối cùng, các biểu tượng từ cả hai sự chú ý được gắn kết và chia sẻ trong năm nhiệm vụ (tức cười, mỉa mai, tấn công, động lực, và tình cảm) cho nhiều nhiệm vụ. Chúng tôi sử dụng bộ dữ liệu được công bố gần đây trong nhiệm vụ phân tích thư mục'Semal 2020, gồm các ký ức được ghi lại cho các lớp như đã đề cập trên. Các kết quả từ dữ liệu Memotion cho thấy hiệu quả của phương pháp chúng ta đề nghị với hệ thống hiện đại (Baseline và SemEvol 2020). Bài đánh giá này cũng cho thấy trong phạm vi đa nhiệm vụ đề nghị đạt hiệu quả tốt hơn trong việc học đơn vị.", 'bg': 'В настоящата статия се стремим да научим взаимоотношенията и приликите на различни задачи, като откриване на хумор, откриване на сарказъм, откриване на обидно съдържание, откриване на мотивационно съдържание и анализ на сантименталността върху една донякъде сложна форма на информация, т.е. меми. Предлагаме мулти-задача, мулти-модална рамка за дълбоко обучение за решаване на множество задачи едновременно. За многофункционалното изпълнение предлагаме два механизма, подобни на вниманието: Модул за взаимоотношения между задачите (iTRM) и модул за взаимоотношения между класовете (iCRM). Основната мотивация на е да научи връзката между задачите, за да осъзнае как те си помагат взаимно. За разлика от това развива взаимоотношения между различните класове задачи. И накрая, представянията и от двете внимания се конкатенират и споделят в петте задачи (хумор, сарказъм, обидни, мотивационни и сантиментални) за многозадачно изпълнение. Използваме наскоро публикувания набор от данни в задачата Анализ на мемоциите @ който се състои от меми анотирани за класовете, както е споменато по-горе. Емпиричните резултати от набора от данни показват ефикасността на предлагания от нас подход спрямо съществуващите най-съвременни системи (победител в базовата линия и SemEval 2020). Оценката показва също, че предложената рамка за многозадачи дава по-добри резултати в сравнение с обучението с една задача.', 'da': 'I denne artikel har vi til formål at lære forholdene og lighederne mellem en række opgaver, såsom humor detektion, sarkasme detektion, stødende indholdsdetektion, motivationsindholdsdetektion og sentimental analyse på en noget kompliceret form for information, dvs. memes. Vi foreslår en multi-opgave, multimodal dyb læring ramme til at løse flere opgaver samtidigt. Til multi-tasking foreslår vi to opmærksomheds-lignende mekanismer, dvs., Inter-task Relationship Module (iTRM) og Inter-class Relationship Module (iCRM). Hovedmotivationen for iTRM er at lære forholdet mellem opgaverne for at realisere, hvordan de hjælper hinanden. I modsætning hertil udvikler iCRM relationer mellem de forskellige klasser af opgaver. Endelig er repræsentationer fra begge opmærksomheder sammenkoblet og delt på tværs af de fem opgaver (dvs. humor, sarkasme, offensiv, motiverende og følelse) for multitasking. Vi bruger det nyligt udgivne datasæt i Memotion Analysis opgaven @ SemEval 2020, som består af memes kommenteret for klasserne som nævnt ovenfor. Empiriske resultater på Memotion datasæt viser effektiviteten af vores foreslåede tilgang i forhold til de eksisterende state-of-the-art systemer (Baseline og SemEval 2020 vinder). Evalueringen viser også, at den foreslåede ramme for flere opgaver giver bedre resultater i forhold til læring med én opgave.', 'hr': 'U ovom papiru ciljamo naučiti odnose i sličnosti raznih zadataka, poput otkrivanja humora, otkrivanja sarkazma, otkrivanja ofanzivnog sadržaja, otkrivanja motivacijskog sadržaja i analiza osjećanja o malo komplikovanom obliku informacija, tj. meme. Predlažemo višestruki zadatak, multimodalni duboko učenje okvir da istovremeno riješimo višestruke zadatke. Za višestruke zadatke predlažemo dva mehanizma slična pažnjom. Modul odnosa međuzadataka (iTRM) i modul odnosa međuklase (iCRM). Glavna motivacija iTRM je naučiti odnos između zadataka kako bi shvatili kako pomažu jedno drugom. Usrotno, iCRM razvija odnose između različitih razreda zadataka. Na kraju, predstavljanja obje pažnje su potvrđene i dijeljene u pet zadataka (tj. humor, sarkazam, ofanzivnim, motivacionalnim i osjećajima) za višestruke zadatke. Koristimo nedavno oslobođenu kompletu podataka u zadatku za analizu Memotion @ SemEval 2020, koja se sastoji od meme navedenih za klase kao što je navedeno iznad. Empirički rezultati na setu podataka o Memotiju pokazuju učinkovitost našeg predloženog pristupa na postojećim sustavima stanja umjetnosti (osnovna linija i dobitnik polEval 2020). Procjenjivanje također ukazuje na to da predloženi višezadatačni okvir pruža bolju provedbu nad učenjem jednozadataka.', 'nl': 'In dit artikel willen we de relaties en overeenkomsten leren kennen van een verscheidenheid aan taken, zoals humor detectie, sarcasme detectie, aanstootgevende content detectie, motivationele content detectie en sentimentanalyse op een enigszins gecompliceerde vorm van informatie, d.w.z. memes. We stellen een multi-task, multi-modaal deep learning framework voor om meerdere taken tegelijkertijd op te lossen. Voor multitasking stellen we twee aandachtsvergelijkende mechanismen voor: Inter-task Relationship Module (iTRM) en Inter-class Relationship Module (iCRM). De belangrijkste motivatie van iTRM is om de relatie tussen de taken te leren om te realiseren hoe ze elkaar helpen. Daarentegen ontwikkelt iCRM relaties tussen de verschillende soorten taken. Tenslotte worden representaties van beide aandachtspunten samengevoegd en gedeeld over de vijf taken (humor, sarcasme, aanstootgevend, motiverend en sentiment) voor multitasking. We gebruiken de recent vrijgegeven dataset in de Memotion Analysis taak van SemEval 2020, die bestaat uit memes die zijn geannoteerd voor de klassen zoals hierboven vermeld. Empirische resultaten op Memotion dataset tonen de effectiviteit van onze voorgestelde aanpak ten opzichte van de bestaande state-of-the-art systemen (Baseline en SemEval 2020 winnaar). Uit de evaluatie blijkt ook dat het voorgestelde multitask-kader betere prestaties oplevert ten opzichte van het leren met één taak.', 'de': 'In diesem Beitrag wollen wir die Zusammenhänge und Ähnlichkeiten einer Vielzahl von Aufgaben, wie Humor Detection, Sarkasmus Detection, offensive Content Detection, motivationale Content Detection und Sentiment Analyse auf einer etwas komplizierten Form von Information, d.h. Memes, lernen. Wir schlagen ein multitasking, multimodales Deep Learning Framework vor, um mehrere Aufgaben gleichzeitig zu lösen. Für Multitasking schlagen wir zwei aufmerksamkeitsähnliche Mechanismen vor: Inter-task Relationship Module (iTRM) und Inter-class Relationship Module (iCRM). Die Hauptmotivation von iTRM ist es, die Beziehung zwischen den Aufgaben zu lernen, um zu erkennen, wie sie einander helfen. Im Gegensatz dazu entwickelt iCRM Beziehungen zwischen den verschiedenen Aufgabenklassen. Schließlich werden Repräsentationen beider Aufmerksamkeiten verkettet und über die fünf Aufgaben (d.h. Humor, Sarkasmus, Offensive, Motivation und Sentiment) für Multitasking geteilt. Wir verwenden den kürzlich veröffentlichten Datensatz in der Memotion Analysis Task SemEval 2020, der aus Memen besteht, die für die oben genannten Klassen kommentiert wurden. Empirische Ergebnisse auf Memotion Datensätzen zeigen die Wirksamkeit unseres vorgeschlagenen Ansatzes gegenüber den bestehenden State-of-the-Art Systemen (Baseline und SemEval 2020 Gewinner). Die Bewertung zeigt auch, dass das vorgeschlagene Mehraufgaben-Framework eine bessere Leistung gegenüber dem Einzelaufgaben-Lernen erbringt.', 'id': 'Dalam kertas ini, kami bertujuan untuk mempelajari hubungan dan persamaan dari berbagai tugas, seperti deteksi humor, deteksi sarkasme, deteksi konten serangan, deteksi konten motivasional dan analisis sentimen pada bentuk informasi yang agak rumit, yaitu memes. Kami mengusulkan rangkaian belajar dalam multi-tugas, multi modal untuk menyelesaikan beberapa tugas secara bersamaan. For multi-tasking, we propose two attention-like mechanisms viz.,  Modul hubungan antara tugas (iTRM) dan Modul hubungan antara kelas (iCRM). Motivasi utama iTRM adalah untuk belajar hubungan antara tugas untuk menyadari bagaimana mereka membantu satu sama lain. Sebaliknya, iCRM mengembangkan hubungan antara kelas tugas yang berbeda. Akhirnya, perwakilan dari kedua perhatian dikoncatenasi dan dibagi melalui lima tugas (i.e., humor, sarkasme, serangan, motivasi, dan perasaan) untuk multi-tugas. Kami menggunakan set data yang baru-baru ini dibebaskan dalam tugas Memotion Analysis @ SemEval 2020, yang terdiri dari meme yang dicatat untuk kelas seperti yang disebutkan di atas. Hasil kerajaan pada set data Memotion menunjukkan efektivitas pendekatan kami yang diusulkan atas sistem terbaik yang ada (Pemenang Baseline dan SemEval 2020). Evaluasi juga menunjukkan bahwa cadangan multi-tugas yang diusulkan memberikan prestasi yang lebih baik daripada belajar tugas tunggal.', 'fa': 'در این کاغذ، ما هدف داریم که رابطه\u200cها و شبیه\u200cهایی از کارهای مختلف یاد بگیریم، مثل شناسایی شوخی، شناسایی سارکاسم، شناسایی محتوای فساد، شناسایی محتوای انگیز و تحلیل احساسات در یک شکل پیچیده از اطلاعات، یعنی میم\u200cها. ما پیشنهاد می\u200cکنیم یک چهارچوب یادگیری عمیق بسیاری از کار بسیاری، بسیاری از مدل\u200cهای عمیق تا همزمان حل کار بسیاری را حل کنیم. برای تعداد زیادی کار، ما دو مکانیسم شبیه توجه پیشنهاد می کنیم، viz. Module Internal Relationship (iTRM) and Inter-Class Relationship Module (iCRM). انگیزه اصلی iTRM اینه که رابطه بین وظیفه ها را یاد بگیریم تا بفهمیم چگونه به یکدیگر کمک می کنند. بر خلاف این، iCRM رابطه بین کلاس\u200cهای مختلف کار را توسعه می\u200cکند. بالاخره، نمایش\u200cهایی از هر دو توجه در پنج وظیفه مشترک و مشترک می\u200cشوند (یعنی خنده، سارکاسم، فساد کننده، انگیزه\u200cکننده و احساسات) برای چندین وظیفه\u200cای. ما از مجموعه داده\u200cهای اخیر آزاد شده در کار تحلیل Memotion @ SemEval 2020 استفاده می\u200cکنیم، که از مجموعه\u200cهایی است که برای کلاس\u200cهایی که از بالا اشاره کرده\u200cاند نوشته شده\u200cاند. نتایج امپراطوری روی مجموعه داده\u200cهای یادداشت نشان می\u200cدهد که تأثیر دستور پیشنهاد ما بر سیستم\u200cهای هنر موجود است. این ارزیابی همچنین نشان می دهد که چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچها', 'sw': 'Katika karatasi hii, tunakusudia kujifunza mahusiano na mazingira yanayofanana na kazi mbalimbali, kama vile uchunguzi wa ucheshi, kutambua maudhui ya uchochezi, uchunguzi wa maudhui yanayohamasisha na uchambuzi wa hisia katika aina fulani ya taarifa tata, yaani ujumbe. Tunazipendekeza mfumo wa kujifunza kwa njia mbalimbali ili kutatua kazi nyingi kwa wakati mmoja. Kwa kufanya kazi mbalimbali, tunapendekeza viza vizuri viwili kama wanavyofanana na ufuatiliaji, Module ya Uhusiano wa Kimataifa (iTRM) na Module ya Mahusiano ya Kimataifa (iCRM). Lengo kuu la iTRM ni kujifunza uhusiano kati ya kazi za kuelewa jinsi wanavyowasaidiana. Tofauti na hilo, iCRM huendelea mahusiano kati ya darasa tofauti za kazi. Mwisho, wawakilishi kutoka kwenye hatua zote hizo zinaunganishwa na kushirikiana katika kazi tano (yaani ucheshi, kejeli, matusi, hamasa na hisia) kwa ajili ya kufanya kazi mbalimbali. Tunatumia taarifa zilizotolewa hivi karibuni katika kazi ya Uchambuzi wa Kumbukumbu @SemEval 2020, ambazo zinajumuisha ujumbe unaotumiwa kwa darasa kama ilivyotajwa hapo juu. Matokeo ya kipekee kwenye taarifa za Kumbukumbu yanaonyesha ufanisi wa mbinu zetu zilizopendekezwa kuhusiana na mifumo ya sanaa (msingi na SemEval 2020). The evaluation also indicates that the proposed multi-task framework yields better performance over the single-task learning.', 'ko': '본고에서 우리는 유머 검측, 풍자 검측, 공격적 내용 검측, 동기적 내용 검측과 특정한 복잡한 형식의 정보(즉 모인)에 대한 정서 분석을 배우는 데 목적을 둔다.우리는 여러 가지 임무, 여러 모델의 심도 있는 학습 틀을 제시하여 여러 가지 임무를 동시에 해결했다.다중 임무에 대해 우리는 두 가지 주의력과 유사한 메커니즘을 제시했다. 즉,작업 간 관계 모듈(iTRM)과 클래스 간 관계 모듈(iCRM).iTRM의 주요 동기는 임무 간의 관계를 배워서 그들이 어떻게 서로 돕는지 이해하는 것이다.이에 비해 iCRM은 서로 다른 임무 유형 간의 관계를 개발했다.마지막으로 이 두 가지 주의력의 표현은 다중 임무의 다섯 가지 임무(즉 유머, 풍자, 공격성, 동기와 정서)에서 연결되고 공유된다.Memotion Analysis task@SemEval 2020에서는 위 클래스 주석의 모인으로 구성된 최근 게시된 데이터 세트를 사용했습니다.Memotion 데이터 세트의 실증 결과에 따르면 우리가 제시한 방법은 기존의 최첨단 시스템(베이스라인과 SemEval 2020 우승자)보다 더 효과적이다.평가에 따르면 단일 임무 학습에 비해 제시된 다중 임무 학습 구조가 더 좋은 성능을 가진 것으로 나타났다.', 'tr': "Bu kagyzda biz özümiz görnüşlerimizi we görnüşlerimizi öwrenmegi amaçlarýarys, humusyň deteksiyony, hassas manysynyň deteksiyony, motivasiýal maksadyň deteksiyony we duýgularyň bir şekli karmaşık şeklinde duýgular analizi bilen meňzeýäris. Birden çok görev, birden çok modal derin öğrenme çerçevesini birden çözmek için teklif ediyoruz. Birnäçe işi üçin, iki üns ýaly meýdançasyny maslahat berýäris Ara-täblisaň Derjesi Moduli (iTRM) we Inter-class Derjesi Moduli (iCRM). iTRM'iň esasy motivasy görenler arasynda bir-birine nähili kömek edip biljeklerini gözlemek. Garşyňda, iCRM farklı täpleriň arasynda baglaýyşy gelişýär. Soňunda, her iki dikkatiň suratlary birnäçe-i ş üçin beş zadyň hemmesine bir şekilde ylalaşýar we bölünýärler. Memotion Analyzasynda edilen soňky sereden veri setirini @ SemEval 2020'da ullanýarys. Şu ýerde agzalan ýaly synplar üçin aýdylan memeler içerilýär. Memoýun veri setindeki imperiýasy netijeleri biziň teklip edilen yaklaýyşymyzyň etkinliýatyny bar öň bar ýagdaýyň durumynda (Baseline we SemEval 2020 ýeňiji). Ýardamçylyk şöyle ýagdaýda görkezilýän köp-täblik framynyň ýeke täblik öwrenmesiniň üstünde gowy etmägi täsir edýändigini aýdýar.", 'sq': 'Në këtë letër, ne synojmë të mësojmë marrëdhëniet dhe ngjashmëritë e një shumicë detyrash të ndryshme, të tilla si zbulimi i humorit, zbulimi i sarkazmit, zbulimi ofensiv i përmbajtjes, zbulimi motivues i përmbajtjes dhe analiza e ndjenjave në një form ë disi të komplikuar informacioni, pra, meme. Ne propozojmë një kuadër mësimi të thellë multi-detyrash, multi-modal për të zgjidhur disa detyra në të njëjtën kohë. Për shumë detyra, propozojmë dy mekanizma të ngjashme me vëmendjen viz. Modul i lidhjes ndër-detyra (iTRM) dhe Modul i lidhjes ndër-klasë (iCRM). Motivi kryesor i iTRM është të mësojmë lidhjen midis detyrave për të kuptuar se si ata ndihmojnë njëri-tjetrin. Në ndryshim, iCRM zhvillon marrëdhënie midis klasave të ndryshme të detyrave. Më në fund, përfaqësimet nga të dy vëmendjet janë të shkurtra dhe të ndara nëpërmjet pesë detyrave (pra, humori, sarkazmi, ofensiv, motivues dhe ndjesi) për shumë detyra. Ne përdorim grupin e të dhënave të lëshuara kohët e fundit në detyrën e Analizës së Kujtimeve @ SemEval 2020, e cila përbëhet nga meme të anotuara për klasat siç përmendet më parë. Rezultatet imperiale mbi grupin e të dhënave të përkujtimit tregojnë efektshmërinë e qasjes sonë të propozuar lidhur me sistemet ekzistuese më të larta (fituesi i linjës bazë dhe gjysmës Eval 2020). Vlerësimi tregon gjithashtu se kuadri i propozuar shumëdetyror jep rezultate më të mira mbi mësimin e një detyre.', 'af': "In hierdie papier doen ons doel om die verwantings en gelykenisse van 'n verskillende taak te leer, soos humor-opdekking, sarkasme-opdekking, offensive inhoud-opdekking, motivasionale inhoud-opdekking en sentimentanalisie op 'n iets kompliseerde vorm van inligting, t.d., memos. Ons voorstel 'n multi-taak, multimodaal diep leer raamwerk om veelvuldige taak simultaan te los. Vir multi-taak, voorstel ons twee aandag-soos mekanisme Inter- task Relasie Module (iTRM) en Inter- klas Relasie Module (iCRM). Die hoofmotivasie van iTRM is om die verwanting tussen die taak te leer om te verstaan hoe hulle mekaar hulp. In contrast, iCRM ontwikkel relasies tussen die verskillende klasse van taak. Eindelik, voorstellings van beide die aandag is saamgestel en gedeel deur die vyf opdragte (i.e. humor, sarkasm, offensiv, motivasie en sentiment) vir meerder opdrag. Ons gebruik die onlangs verligte datastel in die Memotion Analysis taak @ SemEval 2020, wat bestaan van memes wat vir die klasse aangeteken word soos bo aangeteken is. Enige resultate op Memotion datastel vertoon die effektiviteit van ons voorgestelde toegang oor die bestaande staat-van-kunstenstelsels (basisline en semiEval 2020-winner). Die evaluering indiek ook dat die voorgestelde multi-taak raamwerk beter uitvoer oor die enkele-taak leer.", 'am': 'በዚህ ካላት፣ የግንኙነትን እና የተለያዩ ስራዎችን ማምረን እናስፈልጋለን፣ የሳርካሲን ግንኙነት፣ የስቃይ ውጤት ማግኘት፣ የንቅናቄ ውጤት ማግኘት እና አስተያየት ዘንድ እናስፈልጋለን፡፡ በብዙ-ስራ፣ በብዙ-modal የጥልቅ ትምህርት ፍሬም በአንድ ጊዜም ብዙ ስራዎችን ለመፍታት እናስባለን፡፡ ለብዙ ስራ፣ ሁለት ብጤ የሚመስሉትን አካሄኖችን እናሳውቃለን፡፡ አድራሻ የiTRM መጀመሪያ ጉዳይ የስራዎችን መካከል ግንኙነት እንዴት እንደሚረዱ ለመማር ነው፡፡ በተለይም የኢ.CRM በተለያዩ ደረጃዎች መካከል ግንኙነትን ያስተካክላል፡፡ በመጨረሻውም፣ የሁለቱ ማስታወቂያው መልዕክቶች በአምስቱ ስራ (አነስተኛ፣ ሐሳብ፣ ሰርካሲም፣ የሚያስጨንቀው፣ አብዛኛነት እና ስሜት) የተለየፉ ናቸው፡፡ @SemEval 2020፣ ለበላይኛው ክፍሎች የተመሳሰሉ ብልቶች የሚቆጠሩ አናቶች የሚሆነውን የአሁኑን የዳታ ሳጥን እናስቀምጣለን፡፡ በአስታወስ ዳታ ላይ የፍሬት ውጤቶች የአሁኑን የዐርብ ስርዓት (Baseline እና SemEval 2020 winner) በተዘጋጀው የሥርዓት ሥርዓት ጥያቄን ያሳያል፡፡ ማስታወቂያውም ደግሞ የተዘጋጀው ብዙዎች-ስራ ፍሬም በአንድ ስራ ትምህርት ላይ የሚሻለውን ፍሬት እንዲሰጥ ያሳያል፡፡', 'az': "Bu kağızda, biz müxtəlif i şlərin ilişkilerini və bənzərini öyrənməyə niyyət edirik, həmçinin humor keşfini, sarkasm keşfini, həddi a şmaq məlumatı keşfini, motivasiyonlu məlumatı keşfini və hisslərin analizisini bir az sarmaşdırılmış məlumatın form as ı barəsində, məsələlər. Biz çoxlu iş, çoxlu modal derin öyrənmə framework ünü təklif edirik ki, çoxlu işləri birlikdə çəkin. Çoxlu işlər üçün, iki gözləmə bənzər mehānismi təklif edirik. İş İlişkiləri Modülü (iTRM) və Sınıf İlişkiləri Modülü (iCRM). iTRM'in ən böyük motivasyonu işlərin arasındakı ilişkisini öyrənməkdir ki, onların bir-birinə nasıl kömək edirlər. Əksinə, iCRM müxtəlif işlərin səviyyələri arasındakı ilişkiləri təşkil edir. Sonunda, hər ikisinin təsirlərindən təsirlər çoxlu i şlər üçün beş işin içində birlikdə və paylaşırlar. Memotion Analizi işində son günlərdə çıxarılmış verilən qurğunu istifadə edirik @ SemEval 2020, yuxarıda deyilən sınıflar üçün bildirilən memelərdən olur. Memotion verilənlərin müəyyən sonuçları bizim təbliğ edilmiş tərzimizin müvəffəqiyyətini mövcuddur sanat sistemlərində göstərir. Bu değerlendirmə də belə göstərir ki, təklif olunan çoxlu işlər qurğusu təklif öyrənməsindən daha xeyirli işlər yaradır.", 'bn': 'এই কাগজটিতে আমরা বিভিন্ন কাজের সম্পর্ক ও সম্পর্ক শিখতে চাই, যেমন হাস্যরস আবিষ্কার, বিদ্রোহী আবিষ্কার, আক্রমণের বিষয়বস্তু সনাক্তি, উদ্দেশ্যের বিষয়বস্তু সনাক্তি এবং অনুভূতির আমরা একই সাথে বেশ কিছু কাজ সমাধান করার প্রস্তাব করছি বহুমোডাল গভীর শিক্ষা ফ্রেম। For multi-tasking, we propose two attention-like mechanisms viz.,  Inter-task Relation Module (iTRM) এবং Inter-class Relation Module (iCRM). আইTRM এর প্রধান উদ্দেশ্য হচ্ছে কাজের মধ্যে সম্পর্ক শিখতে যাতে তারা একে অপরকে কিভাবে সাহায্য করে। বিপরীতে, আইCRM কাজের বিভিন্ন ক্লাসের মধ্যে সম্পর্ক তৈরি করে। শেষ পর্যন্ত এই দুটির প্রতিনিধিত্ব অনুযায়ী পাঁচটি কাজের মধ্যে একত্রিত এবং শেয়ার করা হয় (যেমন মস্তিষ্ক, বিদ্রোহী, আক্রমণ, উদ্দেশ্য এবং অনুভূতি) অনেক আমরা সাম্প্রতিক মেমরিশন বিশ্লেষণ কর্মসূচীতে মুক্ত তথ্য সেট ব্যবহার করি @সেমইভাল ২০২০, যা উপরের উল্লেখিত ক্লাসের জন্য বিরক্তিকর মে মেমোমেরিশন ডাটাসেটের সমালোচনার ফলাফল দেখাচ্ছে বিদ্যমান রাষ্ট্র-অফ-শিল্প সিস্টেমের উপর আমাদের প্রস্তাবিত পদ্ধতির কার্যক্রমের কার এই মূল্যের মাধ্যমে উল্লেখ করা হয়েছে যে প্রস্তাবিত বহুক্ষেত্রের ফ্রেক্কারের মাধ্যমে এক কাজ শিক্ষার ব্যাপা', 'bs': 'U ovom papiru ciljamo naučiti veze i sličnosti raznih zadataka, poput otkrivanja humora, detekcije sarkazma, detekcije ofanzivnog sadržaja, otkrivanja motivacijskog sadržaja i analize osjećanja o malo komplikovanoj formi informacija, tj. meme. Predlažemo višestruki zadatak, multimodalni duboko učenje okvir da istovremeno riješimo višestruke zadatke. Za višestruke zadatke predlažemo dva mehanizma poput pažnje, viz. Modul odnosa međuzadataka (iTRM) i modul odnosa međuklase (iCRM). Glavna motivacija iTRM je naučiti odnos između zadataka kako bi shvatili kako pomažu jedno drugom. Usrotno, iCRM razvija odnose između različitih razreda zadataka. Na kraju, predstavljanja obje pažnje su potvrđena i podijeljena u pet zadataka (tj. humor, sarkazam, ofanzivnim, motivacionalnim i osjećajima) za višestruke zadatke. Koristimo nedavno objavljenu kompletu podataka u zadatku za analizu Memotion @ SemEval 2020, koja se sastoji od meme koje su navodile za klase kako je navedeno iznad. Empirički rezultati na setu podataka o Memotiju pokazuju učinkovitost našeg predloženog pristupa na postojećim sustavima države umjetnosti (osnovna linija i dobitnik polEval 2020). U procjeni se također ukazuje da predloženi višezadatačni okvir pruža bolju provedbu nad učenjem jednozadataka.', 'cs': 'V tomto článku se zaměřujeme na poznání vztahů a podobností různých úkolů, jako je detekce humoru, detekce sarkasmu, detekce urážlivého obsahu, detekce motivačního obsahu a analýza sentimentů na poněkud složité formě informací, tj. memů. Navrhujeme multi-úkolový, multimodální rámec hlubokého učení pro řešení více úkolů současně. Pro multitasking navrhujeme dva mechanismy podobné pozornosti: Inter-task Relationship Module (iTRM) a Inter-class Relationship Module (iCRM). Hlavní motivací iTRM je naučit se vztah mezi úkoly a uvědomit si, jak si navzájem pomáhají. Naproti tomu iCRM rozvíjí vztahy mezi různými třídami úkolů. Konečně, reprezentace obou pozorností jsou spojeny a sdíleny napříč pěti úkoly (tj. humor, sarkasmus, urážlivý, motivační a sentiment) pro multitasking. Používáme nedávno vydanou datovou sadu v úloze Memotion Analysis v SemEval 2020, která se skládá z memů anotovaných pro třídy, jak je uvedeno výše. Empirické výsledky na datové sadě Memotion ukazují účinnost našeho navrhovaného přístupu oproti stávajícím nejmodernějším systémům (Baseline a SemEval 2020 vítěz). Hodnocení rovněž ukazuje, že navrhovaný rámec pro více úkolů přináší lepší výkon oproti učení s jedním úkolem.', 'et': 'Käesolevas töös püüame õppida erinevate ülesannete, näiteks huumori tuvastamise, sarkasmi tuvastamise, solvava sisu tuvastamise, motivatsioonilise sisu tuvastamise ja sentimentaalüüsi suhteid ja sarnasusi mõnevõrra keerulise informatsiooni vormi ehk meemide puhul. Pakume välja mitme ülesandega, mitmeliigilise sügavõppe raamistiku, et lahendada korraga mitu ülesannet. Mitme ülesande täitmiseks pakume välja kaks tähelepanu sarnast mehhanismi: Ülesannetevaheliste suhete moodul (iTRM) ja klassidevaheliste suhete moodul (iCRM). iTRMi peamine motivatsioon on õppida ülesannete vahelist seost, et mõista, kuidas nad üksteist aitavad. Seevastu iCRM arendab suhteid erinevate ülesannete klasside vahel. Lõpuks on mõlema tähelepanu esindused ühendatud ja jagatud viie ülesande (huumor, sarkasm, solvav, motivatsiooniline ja tunded) vahel multiülesandeks. Kasutame hiljuti avaldatud andmekogumit Memotion Analysis ülesandes @ SemEval 2020, mis koosneb eespool nimetatud klasside jaoks märgitud memidest. Memotioni andmekogumi empiirilised tulemused näitavad meie kavandatud lähenemisviisi tõhusust olemasolevate kaasaegsete süsteemide suhtes (lähtetaseme ja SemEval 2020 võitja). Hindamine näitab ka, et kavandatud mitmeülesandeline raamistik annab parema tulemuse kui ühe ülesandega õppimine.', 'fi': 'Tässä työssä pyrimme oppimaan erilaisten tehtävien, kuten huumorintunnistuksen, sarkasmin havaitsemisen, loukkaavan sisällön havaitsemisen, motivoivan sisällön havaitsemisen ja tunteiden analysoinnin suhteita ja yhtäläisyyksiä jonkin verran monimutkaisessa informaatiomuodossa eli meemeissä. Ehdotamme monitehtävää, multimodaalista syväoppimista koskevaa kehystä useiden tehtävien ratkaisemiseksi samanaikaisesti. Monitehtävään ehdotamme kahta huomiota muistuttavaa mekanismia eli: Tehtävien välinen suhdemoduuli (iTRM) ja luokkien välinen suhdemoduuli (iCRM). iTRM:n tärkein motivaatio on oppia tehtävien välinen suhde ymmärtämään, miten ne auttavat toisiaan. Sen sijaan iCRM kehittää suhteita eri tehtäväluokkien välillä. Lopuksi kummankin huomion esitykset yhdistetään ja jaetaan viiden tehtävän (huumori, sarkasmi, loukkaava, motivoiva ja tunteellinen) kesken monitehtävää varten. Käytämme vastikään julkaistua aineistoa Memotion Analysis -tehtävässä @ SemEval 2020, joka koostuu edellä mainittujen luokkien muistiinpanoista. Memotion-aineiston empiiriset tulokset osoittavat ehdotetun lähestymistapamme tehokkuuden nykyisiin viimeisimpiin järjestelmiin verrattuna (Baseline- ja SemEval 2020 -voittaja). Arviointi osoittaa myös, että ehdotettu monitehtäväkehys tuottaa paremman suorituskyvyn kuin yhden tehtävän oppiminen.', 'ca': "In this paper, we aim at learning the relationships and similarities of a variety of tasks, such as humour detection, sarcasm detection, offensive content detection, motivational content detection and sentiment analysis on a somewhat complicated form of information, i.e., memes.  Proposem un marc d'aprenentatge profund multi modal per resoldre múltiples tasques simultàneament. Per a la multitasca, proposem dos mecanismes d'atenció: Inter-task Relationship Module (iTRM) and Inter-class Relationship Module (iCRM).  La motivació principal d'iTRM és aprendre la relació entre les tasques per adonar-se de com s'ajuden els uns als altres. En canvi, l'iCRM desenvolupa relacions entre les diferents classes de tasques. Finally, representations from both the attentions are concatenated and shared across the five tasks (i.e., humour, sarcasm, offensive, motivational, and sentiment) for multi-tasking.  Utilitzem el conjunt de dades publicat recentment a la tasca d'analís de la memòria @ SemEval 2020, que consisteix en memes anotats per les classes com s'ha dit abans. Els resultats empírics del conjunt de dades Memotion mostren l'eficacia del nostre enfocament proposat sobre els sistemes actuals (guanyador de Baseline i SemEval 2020). L'evaluació també indica que el marc multitascat proposat dóna millor rendiment en relació amb l'aprenentatge unitascat.", 'hy': 'Այս թղթի մեջ մենք նպատակում ենք սովորել տարբեր խնդիրների հարաբերությունները և նմանությունները, ինչպիսիք են հումորի հայտնաբերումը, սարկազմի հայտնաբերումը, գայթակղիչ պարունակության հայտնաբերումը, մոտիվացիոն պարունակության հայտնաբերումը և զգացմունքների վերլուծությունը մի քիչ բարդ տեղեկատվության ձև Մենք առաջարկում ենք բազմախնդիր, բազմամոդալ խորը ուսումնասիրության շրջանակ, որպեսզի միաժամանակ բազմաթիվ խնդիրներ լուծենք: Բազմախնդիրների համար մենք առաջարկում ենք ուշադրության նման երկու մեխանիզմներ. Comment iTMR-ի հիմնական դրդապատճառը նրանում է, որ ուսումնասիրենք առաջադրանքների միջև կապը հասկանալու համար, թե ինչպես են նրանք օգնում միմյանց: Ի հակառակ դրան, iCHM-ը զարգանում է գործողությունների տարբեր դասակարգերի միջև հարաբերություններ: Վերջապես, երկու ուշադրության ներկայացումները համընկնում են և կիսվում են բազմապատասխանատվության հինգ խնդիրների (այսինքն՝ հումորի, սարկազմի, գայթակղիչ, մոտիվացիոն և զգացմունքների) վրա: Մենք օգտագործում ենք Վերջերս հրատարակված տվյալների համակարգը ՝ Մեմոցիոն վերլուծություն ՝ Սեմեվալ 2020, որը կազմված է մեմերից, որոնք գրված են նախկինում նշված դասերի համար: Հիշողության տվյալների համակարգի կայսրիկական արդյունքները ցույց են տալիս մեր առաջարկած մոտեցումների արդյունավետությունը գոյություն ունեցող ամենաբարձր համակարգերի վրա (Հիշողության հիմնական և ՍեմԵվալ 2020 հաղթողը): The evaluation also indicates that the proposed multi-task framework yields better performance over the single-task learning.', 'jv': 'Nang peuter iki, awak dhéwé iso nglanggar wigatahan karo sampeyan karo winih lan ngaweh sampeyan karo perkaraan sing kalah-winih, koyok itolah dhéwé, informasi layar, titik-titik ngêftêr, informasi layar We proposal a multi-task, multi-modal deep Learning frame to find out multi tasks at the same time. kanggo multi-task, kita supoyo sistem sing dikarepakke durung, dadi. Name Mobil iTRM sing dipunangé kanggo ngerasakno babagan nggawe gerakan kanggo ngerasakno piye cara ngéwangi. CalImp Lha wih-wih, repréntasi sing gawe sawetara sampeyan ngono langgar sampeyan 5 task (i.e.g. hukum, sarkasm, warni-warni, warni-warni, dotakyo sampeyan lan saiki) ngono multi-task. Awak dhéwé ngéwé éntuk dataset sing gak nggawe dataset ing nggawe memosion Test . Rejalaké empirhik karo dataset memoton mungkane efekan ning awak dhéwé nggunakake sistem sing gak nggawe barang-sistem sing dibenakno (Ngawe barang sistem sing basa lan semebal 2020 duwé). Wanggang ngentambah mengko ajeng-ajeng barang multi-task kuwi nggawe akeh luwih apik sing luwih apik lan sampek singgu task.', 'sk': 'V prispevku želimo spoznati odnose in podobnosti različnih nalog, kot so odkrivanje humorja, odkrivanje sarkazma, odkrivanje žaljivih vsebin, odkrivanje motivacijske vsebine in analiza čustva na nekoliko zapleteni obliki informacij, tj. memov. Predlagamo večopravilni, multimodalni okvir globokega učenja za reševanje več nalog hkrati. Za večopravilo predlagamo dva pozornosti podobna mehanizma: Modul medopravil odnosov (iTRM) in modul medrazredov odnosov (iCRM). Glavna motivacija iTRM je, da se naučimo razmerja med nalogami, da ugotovimo, kako si medsebojno pomagajo. Nasprotno pa iCRM razvija odnose med različnimi razredi nalog. Končno, predstavitve obeh pozornosti so povezane in delite med petimi nalogami (npr. humor, sarkazem, ofenzivnost, motivacija in čustva) za večopravilno opravljanje. Nedavno objavljen nabor podatkov uporabljamo v opravilu Memotion Analysis @ SemEval 2020, ki je sestavljen iz memov z oznakami za razrede, kot je navedeno zgoraj. Empirični rezultati zbirke podatkov Memotion kažejo učinkovitost našega predlaganega pristopa v primerjavi z obstoječimi najsodobnejšimi sistemi (zmagovalec izhodišča in SemEval 2020). Ocena kaže tudi, da predlagani okvir za več nalog zagotavlja boljšo učinkovitost kot učenje z eno nalogo.', 'he': 'בעיתון הזה, אנו מכוונים ללמוד את מערכות היחסים והדומות של מגוון משימות, כמו זיהוי הומור, זיהוי סרקזם, זיהוי תוכן מעליב, זיהוי תוכן מוטיבציוני וניתוח רגשות על צורה קצת מסובכת של מידע, כלומר ממים. אנו מציעים מסגרת למידה עמוקה רבה משימות ולפתור משימות רבות באותו זמן. למשימות רבות, אנו מציעים שני מנגנונים דומים לתשומת לב. מודול יחסים בין משימות (iTRM) ומודול יחסים בין שיעורים (iCRM). המוטיבציה העיקרית של iTRM היא ללמוד את מערכת היחסים בין המשימות כדי להבין איך הם עוזרים אחד לשני. בניגוד לזה, iCRM מפתח יחסים בין השיעורים השונים של משימות. Finally, representations from both the attentions are concatenated and shared across the five tasks (i.e., humour, sarcasm, offensive, motivational, and sentiment) for multi-tasking.  אנחנו משתמשים בסט הנתונים שנוצא לאחרונה בתפקיד ניתוח הזיכרון @SemEval 2020, אשר מורכב ממים שנעטפו לכיתות כפי שנזכר קודם. התוצאות האימפריות על קבוצת נתונים של זיכרון מראות את היעילות של הגישה המוצעת שלנו על מערכות המצב המיוחד הקיומות הקיומות (Baseline ומנצח חצי Eval 2020). הערכה מצביעה גם על כך שמסגרת המשימה המוצעת נותנת ביצועים טובים יותר על הלימוד המשימה היחידה.', 'ha': "Daga wannan takardan, Munã aimar mu karanta mazaɓa da masu misãlin aikin dabam, kamar gani na humori, zane gane sarki, zane gane abubuwa, zane ganin maɓallin muhimmada da aka yi amfani da akan hisani, misali, meme. Munã goyyar da firam masu aikin mulki-multi, masu motsi da masu yawa dõmin su sola aiki masu yawa sami ɗaya. Ga masu amfani da mulki, za'a bubuƙata misalin matsayi biyu masu kamid da sauri, @ action: button Bayyan aikin iTRM shine a sanar da mazaunin a tsakanin aikin da za'a gane yadda suke taimakon jũna. In da tsohon, iCRM na tsãge haɗi tsakanin nau'i-nau'in aikin daban. Haƙĩƙa, masu gayi daga dukansu ana haɗa kuma ana share su a cikin aikin shan (misali, humu, sarcasm, masu kashẽwa, masu kashfa da fara da sauran da sauri). @ SemEal 2020, wanda ke samun maimmar da aka cũtar wa kurs kamar an faɗa. Empirical Result on data set Ana nuna cewa, firam-aiki mai bukatawa na ƙara mafiya kyau a kan karanta aiki guda.", 'bo': 'འུ་ཅག་གི་ཤོག་བུ་འདིའི་ནང་དུ་བློ་གཏོང་དང་། བློ་གཏོང་རུང་ནང་མི་འདྲ་བའི་མཐུན་སྣང་དང་། གནད་དོན་རྟོགས་བསམ་བློ་གཏོང་དང་། ནང་དོན་རྟོགས་བསམ་བློ་གཏོང་དང་། སེལ་ཚོའི་དབྱིབས་ We propose a multi-task, multi-modal deep learning framework to solve multiple tasks simultaneously. ང་ཚོས་བྱ་བ་མང་པོ་ཞིག་ལ་བསམ་བློ་གཏོང་ཐབས་ལམ་གཉིས་དང་། Inter-task Relationship Module (iTRM) and Inter-class Relationship Module (iCRM). iTRM་གི་རྩ་བའི་རྒུལ་སྐྱེན་དེ་ནི་བྱ་འགུལ་གྱི་འབྲེལ་བ་དང་མཐུན་རྟོགས་པ་དེ་རེད། གདོང་ཚུལ་དང་འགྱུར་བ། iCRM་ནི་བྱ་འགུལ་གྱི་དབྱེ་བ་མི་འདྲ་བར་གྱི་འབྲེལ་བ་ཞིག་ཡར་རྒྱས་གཏོང་། མཐའ་མ་དེ། བྱ་ཚུལ་གཉིས་ལས་གཟུགས་བ་གཉིས་ལས་བྱ་ཚིག་ནང་གི་སྦྲེལ་མཐུན་གཅིག་སྟོན་པ་ཡིན། དཔེར་ན། དགོད་པ། བློ་གཏོང་བུའི་སྐོར་དང་རང་ཉིད་ ང་ཚོས་ཉེ་ཆར་རང་ཉིད་དུ་བཏོན་ཡོད་པའི་ཆ་འཕྲིན་ཡིག་ཆ་འཕྲིན་གྱི་ལས་ཀ་ལྟར་ཞིབ་སྤྱོད་ཀྱི་ཡོད། གནས་སྡུད་གནས་སྡུད་ནང་གི་གནད་སྤེལ་བ་དག་གི་ཐབས་ལམ་ལ་ང་ཚོའི་སྔོན་སྒྲིག་གི་ཐབས་ལམ་དེ་་གནས་སྟངས་དང་འཛམ་གླིང་གི་ཐབས་ལམ་ལ་ཡར ཞིབ་དཔྱད་ནི་ཀྱང་སྔོན་འཆར་བཀོད་ཡོད་པའི་ལྟ་བུའི་རྒྱུ་དངོས་ཡིག་ཆའི་ནང་དུ་ལས་ཉེན་ཁ་ཤས་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Identifying Implicit Quotes for Unsupervised Extractive Summarization of Conversations', 'ar': 'تحديد الاقتباسات الضمنية للتلخيص الاستخراجي غير الخاضع للرقابة للمحادثات', 'fr': 'Identification des citations implicites pour la synthèse extractive non supervisée des conversations', 'es': 'Identificación de cotizaciones implícitas para la sumarización extractiva no supervisada de las conversaciones', 'pt': 'Identificando citações implícitas para sumarização extrativa não supervisionada de conversas', 'ja': '会話の監督されていない抽出の要約の暗黙の相場を特定する', 'hi': 'वार्तालापों के असुरक्षित निष्कर्षण सारांशीकरण के लिए अंतर्निहित उद्धरणों की पहचान करना', 'ga': 'Sleachta Intuigthe a Aithint maidir le hAchoimriú Sliocht Neamh-Mhaoirsithe ar Chomhráite', 'zh': '无监取摘要之隐式引号', 'ru': 'Выявление неявных котировок для неконтролируемого экстрагирующего обобщения бесед', 'ka': 'პარამეტრების გამოყენება', 'el': 'Προσδιορισμός έμμεσων προσφορών για μη εποπτευόμενη αποσπαστική περίληψη συνομιλιών', 'hu': 'Implicit árajánlatok azonosítása a beszélgetések felügyeletlen extraktív összefoglalásához', 'kk': 'Динамикалық тіркелгілер тіркелгісін таңдау', 'it': 'Identificazione di preventivi impliciti per la sintesi estrattiva non sorvegliata delle conversazioni', 'mk': 'Идентификување на имплицитни цитати за ненадгледувана екстрактивна резултата на разговорите', 'lt': 'Nustatyti netiesiogines kvotas, skirtas nekontroliuojamai ekstraktyviai konversacijų santraukai', 'mt': 'L-identifikazzjoni ta’ kwoti impliċiti għas-Sommarju Estrattiv tal-Konversjonijiet Mhux Sorveljat', 'ms': 'Mengenalpasti Petikan Implicit untuk Penapisan Ekstraktif Tidak Dikawal', 'ml': 'നിരീക്ഷിക്കപ്പെടാത്ത വിവരങ്ങള്\u200d സംസാരിക്കുന്നതിനുള്ള അസാധാരണയ്ക്ക് തിരിച്ചറിയുക', 'no': 'Identifiserer implisitte sitatar for usikkerte ekstraktiv samandrag av samtaler', 'pl': 'Identyfikacja dorozumianych cytatów dla nienadzorowanej ekstrakcyjnej streszczenia rozmów', 'ro': 'Identificarea cotațiilor implicite pentru rezumarea extractivă nesupravegheată a conversațiilor', 'si': 'සම්බන්ධ නැති වික්\u200dරියාත්මක සම්බන්ධයක් සඳහා ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරන්න', 'mn': 'Холбоонуудын нэмэлт хэвлэлүүдийг тодорхойлох', 'so': 'Identification Implicit Quotes for Unsupervised Extractive Summary of Conversations', 'sv': 'Identifiera implicita citat för icke övervakad extraktiv sammanfattning av konversationer', 'sr': 'Identifikacija Implicitnih citata za neodređenu ekstraktivnu sažetku razgovora', 'ta': 'பார்க்கப்படாத பேச்சு சுருக்கம்', 'ur': 'بغیر محفوظت کے اضافہ مثبت کی تعریف کے لئے مثبت اثبات شناسایی کی جاتی ہے', 'uz': 'Name', 'vi': 'Xác định hàm của chưa được giám sát Chỉ âm rút', 'bg': 'Идентифициране на имплицитни цитати за необуздано екстрактивно обобщаване на разговорите', 'da': 'Identificering af implicitte citater til ukontrolleret ekstraktiv opsummering af samtaler', 'nl': 'Identificeren van impliciete citaten voor niet-begeleide extractieve samenvatting van gesprekken', 'hr': 'Identifikacija Implicitnih citata za neodržavane ekstraktivne sažetke razgovora', 'de': 'Identifizierung impliziter Zitate für die nicht überwachte extraktive Zusammenfassung von Gesprächen', 'fa': 'شناسایی اشاره\u200cهای مثبتی برای جمع\u200cآوری خارجی غیرقابل حفاظت', 'id': 'Identifying Implicit Quotes for Unsupervised Extractive Summarization of Conversations', 'sw': 'Kutambua Nukuu za Implicit kwa Ujumbe wa Mazungumzo yasiyopangwa na Utetezi', 'ko': '대화 무감독 요약 중의 은밀한 인용어를 식별하다', 'tr': 'Gaýd edilmedik Çikgi Nişanlar üçin Sözgütler Dämeleri tanyşdyrylýar', 'af': 'Identifikasie Implicite Quotes vir Ononderwerpende Extractive Summarization of Conversations', 'am': 'ReplyForward', 'hy': 'Խոսակցությունների առանց վերահսկվող արտադրողական համառոտագրության աննշանակալի մեջբերումներ հայտնաբերելը', 'az': '兯湵얟浡污爠쎼쎧쎼渠楳瑩晡擉餠敤楬淉饹즙渠䓉饲条桬쒱⁄즙牧慨污狄넠瓉饳摩煬즙湩爊', 'bn': 'Identifying Implicit Quotes for Unsupervised Extractive Summarization of Conversations', 'bs': 'Identifikacija Implicitnih citata za neodređenu ekstraktivnu sažetku razgovora', 'cs': 'Identifikace implicitních citátů pro nekontrolovanou extraktivní shrnutí konverzací', 'ca': 'Identificar quotes implicites for Unsupervised Extractive Summary of Conversations', 'et': 'Kaudsete tsitaatide kindlakstegemine vestluste järelevalveta ekstraktiivse kokkuvõtte jaoks', 'fi': 'Implisiittisten lainausten tunnistaminen valvomattoman ekstraktiivisen yhteenvedon keskusteluista', 'sq': 'Identifikimi i citimeve të përfshira për përmbledhjen ekstraktive të bisedimeve të pa mbikqyrur', 'ha': 'KCharselect unicode block name', 'jv': 'Job', 'sk': 'Identifikacija implicitnih citatov za nenadzorovano ekstraktivno povzetek pogovorov', 'bo': 'གཏམ་གླེང་ཚོགས་ལ་སྲུང་མེད་པའི་ཁྱད་དུ་འཕགས་རིས་ཀྱི་བཅུད་སྡུད་དྲན་འབྲེལ་ལ་ངོས་འཛིན་བྱེད་པ', 'he': 'מזהה ציטוטים משמעותיים לסומריזציה מחדשת של שיחות ללא השגחה'}
{'en': 'We propose Implicit Quote Extractor, an end-to-end unsupervised extractive neural summarization model for conversational texts. When we reply to posts,  quotes  are used to highlight important part of texts. We aim to extract quoted sentences as summaries. Most replies do not explicitly include  quotes , so it is difficult to use  quotes  as  supervision . However, even if it is not explicitly shown, replies always refer to certain parts of texts ; we call them implicit quotes. Implicit Quote Extractor aims to extract implicit quotes as summaries. The training task of the  model  is to predict whether a reply candidate is a true reply to a post. For  prediction , the  model  has to choose a few sentences from the post. To predict accurately, the  model  learns to extract sentences that replies frequently refer to. We evaluate our  model  on two email datasets and one social media dataset, and confirm that our  model  is useful for extractive summarization. We further discuss two topics ; one is whether quote extraction is an important factor for summarization, and the other is whether our model can capture salient sentences that conventional methods can not.', 'pt': 'Propomos o Implicit Quote Extractor, um modelo de sumarização neural extrativa não supervisionada de ponta a ponta para textos conversacionais. Quando respondemos às postagens, as aspas são usadas para destacar parte importante dos textos. Nosso objetivo é extrair frases citadas como resumos. A maioria das respostas não inclui citações explicitamente, por isso é difícil usar aspas como supervisão. No entanto, mesmo que não seja explicitamente indicado, as respostas referem-se sempre a determinadas partes dos textos; nós os chamamos de aspas implícitas. O Implicit Quote Extractor visa extrair citações implícitas como resumos. A tarefa de treinamento do modelo é prever se um candidato a resposta é uma resposta verdadeira a uma postagem. Para previsão, o modelo deve escolher algumas frases do post. Para prever com precisão, o modelo aprende a extrair frases às quais as respostas se referem com frequência. Avaliamos nosso modelo em dois conjuntos de dados de e-mail e um conjunto de dados de mídia social e confirmamos que nosso modelo é útil para sumarização extrativa. Discutimos ainda dois tópicos; uma é se a extração de citações é um fator importante para a sumarização, e a outra é se nosso modelo pode capturar sentenças salientes que os métodos convencionais não podem.', 'fr': "Nous proposons Implicit Quote Extractor, un modèle de résumé neuronal extractif non supervisé de bout en bout pour les textes conversationnels. Lorsque nous répondons à des publications, des citations sont utilisées pour mettre en évidence des parties importantes des textes. Notre objectif est d'extraire les phrases citées sous forme de résumés. La plupart des réponses n'incluent pas explicitement de guillemets, il est donc difficile d'utiliser des guillemets à titre de supervision. Cependant, même si cela n'apparaît pas explicitement, les réponses font toujours référence à certaines parties du texte\xa0; nous les appelons des citations implicites. Implicit Quote Extractor vise à extraire des citations implicites sous forme de résumés. La tâche de formation du modèle est de prédire si un candidat de réponse est une vraie réponse à un message. Pour la prédiction, le modèle doit choisir quelques phrases dans le post. Pour prédire avec précision, le modèle apprend à extraire les phrases auxquelles les réponses se réfèrent fréquemment. Nous évaluons notre modèle sur deux ensembles de données de courrier électronique et un jeu de données de réseaux sociaux, et nous confirmons que notre modèle est utile pour la synthèse extractive. Nous discutons également de deux sujets\xa0; l'un est de savoir si l'extraction des citations est un facteur important pour la synthèse, et l'autre est de savoir si notre modèle peut capturer des phrases saillantes que les méthodes conventionnelles ne peuvent pas saisir.", 'zh': '臣等发隐式引提取器,此一会话文本之端,端无监取神经摘要模。 当吾报帖时,引号以显文本之要。 我的是提取引用的句子为摘要。 多报未明引号,故难用引号为监督。 然虽未明示,报亦辄及文本。 吾谓之隐式引号。 隐式引提取器旨取隐式引号为摘要。 模形之训练任务,占答者为帖之实否。 其于测候,必于帖中择数句。 为准的,模样会学提取常常引用的句子。 两电子邮件之集,一社交媒体之数集上料吾形,而信吾之于提取性摘要也。 更论两主题。 一则引取是非总结之要,一则吾辈之能得古之法不可得之奇句也。', 'ja': '私たちは、会話テキストのためのエンドツーエンドの無監督抽出ニューラルサマリゼーションモデルである、暗黙の引用抽出器を提案します。 投稿に返信する際、引用符はテキストの重要な部分を強調表示するために使用されます。 引用文を要約として抽出することを目指している。 ほとんどの返信には引用が明示されていないため、監督として引用を使用することは困難です。 しかし、明示的に示されていなくても、返信は常にテキストの特定の部分を参照します。私たちはそれらを暗黙の引用符と呼びます。 暗黙の引用抜粋は、要約として暗黙の引用を抽出することを目的としています。 モデルのトレーニングタスクは、返信候補が投稿に対する真の返信であるかどうかを予測することです。 予測のために、モデルは投稿からいくつかの文章を選択する必要があります。 正確に予測するために、モデルは、返信が頻繁に参照する文章を抽出することを学びます。 2つの電子メールデータセットと1つのソーシャルメディアデータセットでモデルを評価し、モデルが抽出の要約に有用であることを確認します。 さらに2つのトピックについて説明します。1つは、引用抽出が要約の重要な要素であるかどうかであり、もう1つは、従来の方法では不可能な顕著な文をモデルがキャプチャできるかどうかです。', 'ar': 'نقترح مستخرج الاقتباس الضمني ، وهو نموذج تلخيص عصبي استخلاصي غير خاضع للرقابة من طرف إلى طرف لنصوص المحادثة. عند الرد على المنشورات ، يتم استخدام الاقتباسات لإبراز جزء مهم من النصوص. نحن نهدف إلى استخراج الجمل المقتبسة كملخصات. لا تتضمن معظم الردود صراحة اقتباسات ، لذلك من الصعب استخدام علامات الاقتباس للإشراف. ومع ذلك ، حتى لو لم يتم عرضها بشكل صريح ، فإن الردود تشير دائمًا إلى أجزاء معينة من النصوص ؛ نسميها اقتباسات ضمنية. يهدف مستخرج الاقتباس الضمني إلى استخراج الاقتباسات الضمنية كملخصات. تتمثل مهمة التدريب الخاصة بالنموذج في توقع ما إذا كان مرشح الرد يمثل ردًا حقيقيًا على إحدى المشاركات. للتنبؤ ، يجب أن يختار النموذج بضع جمل من المنشور. للتنبؤ بدقة ، يتعلم النموذج استخراج الجمل التي تشير إليها الردود بشكل متكرر. نقوم بتقييم نموذجنا على مجموعتي بيانات بريد إلكتروني ومجموعة بيانات وسائط اجتماعية واحدة ، ونؤكد أن نموذجنا مفيد للتلخيص الاستخراجي. نناقش كذلك موضوعين ؛ الأول هو ما إذا كان استخلاص الاقتباس عاملًا مهمًا للتلخيص ، والآخر هو ما إذا كان نموذجنا يمكنه التقاط جمل بارزة لا تستطيع الأساليب التقليدية ذلك.', 'hi': 'हम अंतर्निहित उद्धरण चिमटा, संवादी ग्रंथों के लिए एक एंड-टू-एंड अप्रशिक्षित निष्कर्षण तंत्रिका सारांश मॉडल का प्रस्ताव करते हैं। जब हम पोस्ट का जवाब देते हैं, तो उद्धरणों का उपयोग ग्रंथों के महत्वपूर्ण हिस्से को उजागर करने के लिए किया जाता है। हम सारांश के रूप में उद्धृत वाक्यों को निकालने का लक्ष्य रखते हैं। अधिकांश उत्तरों में स्पष्ट रूप से उद्धरण शामिल नहीं हैं, इसलिए पर्यवेक्षण के रूप में उद्धरणों का उपयोग करना मुश्किल है। हालांकि, भले ही यह स्पष्ट रूप से नहीं दिखाया गया है, जवाब हमेशा ग्रंथों के कुछ हिस्सों को संदर्भित करते हैं; हम उन्हें अंतर्निहित उद्धरण कहते हैं। अंतर्निहित उद्धरण चिमटा सारांश के रूप में निहित उद्धरण निकालने के लिए है। मॉडल का प्रशिक्षण कार्य यह अनुमान लगाना है कि क्या एक उत्तर उम्मीदवार एक पोस्ट का सही जवाब है। भविष्यवाणी के लिए, मॉडल को पोस्ट से कुछ वाक्यों का चयन करना होगा। सटीक भविष्यवाणी करने के लिए, मॉडल उन वाक्यों को निकालना सीखता है जो अक्सर संदर्भित करते हैं। हम दो ईमेल डेटासेट और एक सोशल मीडिया डेटासेट पर अपने मॉडल का मूल्यांकन करते हैं, और पुष्टि करते हैं कि हमारा मॉडल निष्कर्षण सारांश के लिए उपयोगी है। हम आगे दो विषयों पर चर्चा करते हैं; एक यह है कि क्या उद्धरण निष्कर्षण सारांशीकरण के लिए एक महत्वपूर्ण कारक है, और दूसरा यह है कि क्या हमारा मॉडल मुख्य वाक्यों पर कब्जा कर सकता है जो पारंपरिक तरीके नहीं कर सकते हैं।', 'ru': 'Мы предлагаем неявный экстрактор цитат, сквозную неконтролируемую модель экстрактивного нейросуммирования для разговорных текстов. Когда мы отвечаем на сообщения, цитаты используются для выделения важной части текстов. Мы стремимся извлечь цитируемые предложения в виде резюме. Большинство ответов не содержат явных цитат, поэтому трудно использовать цитаты в качестве надзора. Однако, даже если это прямо не показано, ответы всегда относятся к определенным частям текстов; мы называем их неявными цитатами. Экстрактор неявных кавычек предназначен для извлечения неявных кавычек в виде сводок. Тренировочная задача модели заключается в том, чтобы предсказать, является ли кандидат на ответ истинным ответом на пост. Для предсказания модель должна выбрать несколько предложений из поста. Чтобы точно предсказать, модель учится извлекать предложения, на которые часто ссылаются в ответах. Мы оцениваем нашу модель на двух наборах данных электронной почты и одном наборе данных социальных сетей и подтверждаем, что наша модель полезна для экстрактивного обобщения. Мы далее обсуждаем две темы; одна из них заключается в том, является ли извлечение цитат важным фактором для обобщения, а другая - в том, может ли наша модель охватить важные предложения, которые традиционные методы не могут.', 'ga': 'Molaimid Inplicit Quote Extractor, samhail achomair eastóscach néarúil gan mhaoirseacht ó cheann go ceann le haghaidh téacsanna comhrá. Nuair a thugaimid freagra ar phoist, úsáidtear comharthaí athfhriotail chun cuid thábhachtach de théacsanna a aibhsiú. Tá sé mar aidhm againn abairtí luaite a bhaint as mar achoimrí. Ní chuimsíonn formhór na bhfreagraí comharthaí athfhriotail, mar sin tá sé deacair comharthaí athfhriotail a úsáid mar mhaoirseacht. Mar sin féin, fiú mura dtaispeántar go sainráite é, tagraíonn freagraí i gcónaí do chodanna áirithe de théacsanna; tugaimid Sleachta intuigthe orthu. Tá sé mar aidhm ag Inplicit Quote Extractor sleachta intuigthe a bhaint as mar achoimrí. Is é tasc oiliúna na samhla ná a thuar cé acu an fíorfhreagra ar phost é iarrthóir freagartha. Le tuar, caithfidh an tsamhail cúpla abairt a roghnú as an bpostáil. Chun tuar cruinn a dhéanamh, foghlaimíonn an tsamhail conas abairtí a bhaintear amach as a dtagraíonn freagraí go minic. Déanaimid measúnú ar ár múnla ar dhá thacar sonraí ríomhphoist agus tacar sonraí meán sóisialta amháin, agus deimhnímid go bhfuil ár múnla úsáideach le haghaidh achoimre eastóscach. Déanaimid plé breise ar dhá ábhar; is é ceann amháin an bhfuil eastóscadh athfhriotail ina fhachtóir tábhachtach le haghaidh achoimre, agus is é an ceann eile an féidir lenár múnla abairtí suntasacha a ghabháil nach féidir le modhanna traidisiúnta.', 'es': 'Proponemos Implicit Quote Extractor, un modelo de resumen neuronal extractivo no supervisado de extremo a extremo para textos conversacionales. Cuando respondemos a publicaciones, las citas se utilizan para resaltar una parte importante de los textos. Nuestro objetivo es extraer las frases citadas como resúmenes. La mayoría de las respuestas no incluyen citas explícitamente, por lo que es difícil usarlas como supervisión. Sin embargo, aunque no se muestre explícitamente, las respuestas siempre se refieren a ciertas partes de los textos; las llamamos citas implícitas. Implicit Quote Extractor tiene como objetivo extraer cotizaciones implícitas como resúmenes. La tarea de capacitación del modelo es predecir si un candidato de respuesta es una respuesta verdadera a una publicación. Para la predicción, el modelo tiene que elegir algunas frases de la publicación. Para predecir con precisión, el modelo aprende a extraer frases a las que se hace referencia con frecuencia en las respuestas. Evaluamos nuestro modelo en dos conjuntos de datos de correo electrónico y un conjunto de datos de redes sociales, y confirmamos que nuestro modelo es útil para el resumen extractivo. Además, discutimos dos temas; uno es si la extracción de cotizaciones es un factor importante para el resumen, y el otro es si nuestro modelo puede capturar oraciones sobresalientes que los métodos convencionales no pueden.', 'ka': 'ჩვენ მუშაობთ იმპლექტიური სიტყვეტის ექსტრაკტორი, საბოლოოდ დასრულებული ექსტრაქტიური ნეირალური სიმუშატების მოდელის შემდეგ. როდესაც ჩვენ პასუხით, სტატის მნიშვნელოვანი ნაწილს გამოყენება. ჩვენ მინდომით კიტატირებული სიტყვების გამოყენება. უფრო მეტი საუპასუხი არ გამოიყენებს კუტაციები, ასე რომ ძალიან რთულია გამოყენება კუტაციები როგორც ნახვა. მაგრამ, თუმცა ეს არ ჩვენებულია განსაკუთრებულად, განსხვავებები ყოველთვის ტექსტის განსაკუთრებული ნაწილზე იყოს; ჩვენ ისინი ინომპლიციტიური სიტყვები გვაქვს. Implicit Quote Extractor უნდა იქნება იმპლიციტური სიტყვების გამოყენება როგორც სიტყვები. მოდელის განვითარების დავალება არის განვითარება, თუ არა განსხვავებული კანდიდეტი მართლად განსხვავება პოსტზე. პროგრამებისთვის, მოდელი უნდა მოიყენოთ რამდენიმე სიტყვები პოსტიდან. მართლად წარმოდგენისთვის, მოდელი ისწავლის გამოყენებას, რომელიც წარმოდგენებს ბევრად. ჩვენ ჩვენი მოდელს ორი ელფოსტური მონაცემების და ერთი სოციალური მედია მონაცემების კონფიგურაციაში გავამუშავებთ, რომ ჩვენი მოდელი ექსტრაქტიური კონ ჩვენ შემდეგ ორი ტემენტის განსაზღვრება; ერთი არის თუ კიტრაციის ექსტრექცია გასანიშვნელოვანი ფაქტორია, და მეორე არის თუ ჩვენი მოდელი შეუძლიათ წარმოდგენოთ წარმოდგენელი წარმოდგენები, რომელიც კონტრაცი', 'hu': 'Javasoljuk az Implicit Quote Extractort, egy end-to-end felügyelet nélküli extraktív neurális összefoglaló modellt a beszélgetési szövegekhez. Amikor a bejegyzésekre válaszolunk, az idézetekkel kiemeljük a szövegek fontos részét. Célunk az idézett mondatok összefoglalóként történő kivonása. A legtöbb válasz nem tartalmaz kifejezetten idézéseket, ezért nehéz felügyeletként használni az idézéseket. A válaszok mindig a szövegek bizonyos részeire utalnak, még ha nem is kifejezetten feltüntetik is; implicit idézeteknek hívjuk őket. Implicit Quote Extractor célja, hogy kivonja az implicit idézeteket összefoglalóként. A modell képzési feladata annak előrejelzése, hogy a válaszjelölt valódi válasz-e egy bejegyzésre. Az előrejelzéshez a modellnek ki kell választania néhány mondatot a posztból. A pontos előrejelzés érdekében a modell megtanulja kivonni azokat a mondatokat, amelyekre a válaszok gyakran hivatkoznak. Modellünket két e-mail adatkészleten és egy közösségi média adatkészleten értékeljük, és megerősítjük, hogy modellünk hasznos az extraktív összefoglaláshoz. Továbbá két témát vitatunk meg: Az egyik az, hogy az idézetek kivonása fontos tényező-e az összefoglaláshoz, a másik, hogy a modellünk képes-e olyan kiemelkedő mondatokat rögzíteni, amelyeket a hagyományos módszerek nem.', 'el': 'Προτείνουμε ένα ολοκληρωμένο χωρίς επίβλεψη εξορυκτικό μοντέλο νευρωνικής σύνοψης για κείμενα συνομιλίας. Όταν απαντάμε σε δημοσιεύσεις, τα αποσπάσματα χρησιμοποιούνται για να επισημάνουμε σημαντικό μέρος των κειμένων. Στόχος μας είναι να εξάγουμε αποσπασμένες προτάσεις ως περιλήψεις. Οι περισσότερες απαντήσεις δεν περιλαμβάνουν ρητά εισαγωγές, οπότε είναι δύσκολο να χρησιμοποιήσετε εισαγωγές ως εποπτεία. Ωστόσο, ακόμη και αν δεν εμφανίζεται ρητά, οι απαντήσεις αναφέρονται πάντοτε σε ορισμένα μέρη κειμένων· Τα λέμε σιωπηρά αποσπάσματα. Στόχος του είναι η εξαγωγή σιωπηρών εισαγωγών ως περιλήψεις. Το εκπαιδευτικό καθήκον του μοντέλου είναι να προβλέψει εάν ένας υποψήφιος απάντησης είναι μια πραγματική απάντηση σε μια δημοσίευση. Για πρόβλεψη, το μοντέλο πρέπει να επιλέξει μερικές προτάσεις από τη δημοσίευση. Για να προβλέψει με ακρίβεια, το μοντέλο μαθαίνει να εξάγει προτάσεις στις οποίες αναφέρονται συχνά οι απαντήσεις. Αξιολογούμε το μοντέλο μας σε δύο σύνολα δεδομένων ηλεκτρονικού ταχυδρομείου και ένα σύνολο δεδομένων κοινωνικών μέσων και επιβεβαιώνουμε ότι το μοντέλο μας είναι χρήσιμο για την εξαγωγή συνοψίας. Συζητούμε περαιτέρω δύο θέματα: Το ένα είναι αν η εξαγωγή αποσπασμάτων είναι ένας σημαντικός παράγοντας για την περίληψη, και το άλλο είναι αν το μοντέλο μας μπορεί να συλλάβει σημαντικές προτάσεις που οι συμβατικές μέθοδοι δεν μπορούν.', 'it': "Proponiamo Implicit Quote Extractor, un modello di sintesi neurale estrattivo end-to-end non supervisionato per testi conversazionali. Quando rispondiamo ai post, le citazioni vengono utilizzate per evidenziare parti importanti dei testi. Il nostro obiettivo è estrarre frasi citate come riassunti. La maggior parte delle risposte non include esplicitamente citazioni, quindi è difficile utilizzare citazioni come supervisione. Tuttavia, anche se non è esplicitamente indicato, le risposte si riferiscono sempre a determinate parti dei testi; Le chiamiamo citazioni implicite. Implicit Quote Extractor mira a estrarre citazioni implicite come riassunti. Il compito formativo del modello è quello di prevedere se un candidato di risposta è una vera risposta a un post. Per la previsione, il modello deve scegliere alcune frasi dal post. Per prevedere con precisione, il modello impara ad estrarre frasi a cui le risposte si riferiscono frequentemente. Valutiamo il nostro modello su due set di dati email e un set di dati sui social media e confermiamo che il nostro modello è utile per la sintesi estrattiva. Discutiamo inoltre due temi: Uno è se l'estrazione delle citazioni è un fattore importante per la sintesi, e l'altro è se il nostro modello può catturare frasi salienti che i metodi convenzionali non possono.", 'ms': 'Kami cadangkan Pengekstrak Quot Implicit, model pengringkasan saraf ekstraktif tidak diawasi akhir-akhir untuk teks perbualan. Apabila kita menjawab kepada pos, kutipan digunakan untuk menyatakan bahagian penting teks. Kami bertujuan untuk mengekstrak kalimat petikan sebagai ringkasan. Kebanyakan jawapan tidak termasuk petikan secara eksplicit, jadi sukar menggunakan petikan sebagai pengawasan. Namun, walaupun ia tidak dipaparkan secara jelas, jawapan sentiasa rujuk kepada bahagian tertentu teks; kita panggil mereka kutipan yang tidak jelas. Pengekstrak Quot Implicit bermaksud untuk ekstrak kutipan implicit sebagai ringkasan. Tugas latihan bagi model adalah meramalkan sama ada calon jawapan adalah jawapan sebenar kepada pos. Untuk ramalan, model perlu memilih beberapa kalimat dari pos. Untuk meramalkan dengan tepat, model belajar untuk mengekstrak kalimat yang menjawab sering merujuk. Kami menilai model kami pada dua set data e-mel dan satu set data media sosial, dan mengesahkan bahawa model kami berguna untuk ringkasan ekstraktif. Kami lebih lanjut membincangkan dua topik; satu ialah sama ada ekstraksi kutipan adalah faktor penting untuk ringkasan, dan yang lain ialah sama ada model kita boleh menangkap kalimat yang penting yang kaedah konvensional tidak boleh.', 'kk': 'Қарастырмалы мәтіндер үшін имплитті тіркелген тіркелген тіркелген тіркелген тіркелген тіркелгі, соңында соңында соңында қолданылмаған экстрактивті невралдық тіркелгі үлгісін Жіберілгендерге жауап бергенде, мәтіннің маңызды бөлігін бояулау үшін қолданылады. Біз тіркелген сөйлемелерді тіркелгілер ретінде тарқату керек. Жауаптардың көпшілігі таңбашаларды таңбашалар болмайды, сондықтан таңбашаларды қарау үшін қолдану қиын. Бірақ бұл көрсетілмеген болса да, жауаптар әрқашан кейбір мәтіннің бөлігіне сәйкес келеді. Біз оларды таңбашалар деп атаймыз. Шығыс тіркелген тіркелген тіркелген тіркелген тіркелген тіркелген тіркелген тіркелген тіркелген тіркелгілерді тіркелгілер ретінде тарқату мақса Үлгінің оқыту тапсырмасы - жауап кандидаты жіберу үшін жауап беру үшін. Алдын- ала қарау үшін, үлгі жолдан бірнеше сөзді таңдау керек. Бұл үлгі дұрыс таңдау үшін үлгі жауап беретін сөздерді көбірек тарқатуды үйренеді. Біз үлгімізді екі эл. пошта деректер және бір социалдық медиа деректер жиынына тең етіп, өзіміздің үлгіміз экстрактивті тұжырымдама үшін пайдалы дегенді тексер Екі тақырыпты қолданып тұрмыз; Біріншісі - цитаттарды тарқату үшін маңызды күнделікті факторы. Біріншісі - үлгіміздің кәдімгі әдістерді алмайтын сұлбаларды тарқатып алуы мүмкін емес.', 'mk': 'Предложуваме имплицитен извадувач на цитати, ненадгледуван нервен модел за резултат на разговорите. Кога одговараме на постови, цитатите се користат за истакнување на важниот дел од текстите. Ние имаме за цел да ги извадиме цитираните реченици како резултати. Повеќето одговори не вклучуваат експлицитно цитати, па тешко е да се користат цитати како надзор. Сепак, дури и ако не е експлицитно прикажано, одговорите секогаш се однесуваат на одредени делови од текстот; ги нарекуваме имплицитни цитати. Implicit Quote Extractor aims to extract implicit quotes as summaries.  Задачата за обука на моделот е да се предвиди дали кандидатот за одговор е вистински одговор на пост. За предвидување, моделот мора да избере неколку реченици од постот. За претпоставување точно, моделот научи да извлече реченици кои често се однесуваат на одговорите. Го проценуваме нашиот модел на два податоци за електронска пошта и еден податок за социјалните медиуми, и потврдиме дека нашиот модел е корисен за екстрактивна резултатација. We further discuss two topics;  Еден е дали извлекувањето на цитатите е важен фактор за резултатирање, а другиот е дали нашиот модел може да фати основни реченици кои конвенционалните методи не можат.', 'ml': 'സംസാരിക്കുന്ന ടെക്സ്റ്റുകള്\u200dക്കുള്ള ഒരു അവസാനത്തേക്കുള്ള അവസാനത്തേക്കുള്ള അവസാനത്തേക്കുള്ള അവസാനത്തേക്കുള്ള സംസാരി പോസ്റ്റുകള്\u200dക്ക് ഉത്തരം നല്\u200dകുമ്പോള്\u200d, പ്രധാനപ്പെട്ട ട ടെക്സ്റ്റുകളുടെ ഭാഗങ്ങള്\u200d പ്രധാനപ്പെ വാക്കുകള്\u200d വേര്\u200dപെടുത്തുവാന്\u200d ഞങ്ങള്\u200d ഉദ്ദേശിക്കുന്നു. പ്രധാനപ്പെട്ട ഉത്തരങ്ങള്\u200d വ്യക്തമായി ചേര്\u200dക്കുന്നില്ല, അതുകൊണ്ട് വാക്കുകള്\u200d നിരീക്ഷിക്കാന്\u200d പ്രയാസമ എന്നാലും പ്രത്യക്ഷമായി കാണിച്ചിട്ടില്ലെങ്കിലും ഉത്തരം എപ്പോഴും പദാവലികളുടെ ചില ഭാഗങ്ങള്\u200d പറയുന്നു; നമ്മള്\u200d അവരെ പ്രത്യക്ഷമായ വാക്കുകള്\u200d എന്ന് വിളിക്കുന്നു. എക്സ്റ്റ്രാക്ട്രാക്ടറിന്റെ ഉദ്ദേശങ്ങള്\u200d വ്യക്തമായി പുറത്തെടുക്കുവാന്\u200d ഉദ്ദേശിക്കുന്നു. മോഡലിന്റെ ട്രെയിനിങ്ങള്\u200d പ്രവചിക്കുന്നത് ഒരു പോസ്റ്റിന്റെ ശരിയായ മറുപടി ആണോ എന്നാണ്. പ്രതീക്ഷിക്കാന്\u200d, പോസ്റ്റില്\u200d നിന്ന് കുറച്ച് വാക്കുകള്\u200d തെരഞ്ഞെടുക്കണം. ശരിയായി പ്രവചിക്കാന്\u200d മോഡല്\u200d പഠിക്കുന്നത് ആവശ്യമായി ഉത്തരം പറയുന്ന വാക്കുകള്\u200d പുറത്തെടുക്കാന്\u200d പഠിക്ക We evaluate our model on two email datasets and one social media dataset, and confirm that our model is useful for extractive summarization.  നമ്മള്\u200d രണ്ടു വിഷയങ്ങളെക്കുറിച്ച് കൂടി സംസാരിക്കുന്നു; സാധാരണ മാര്\u200dഗ്ഗങ്ങള്\u200d പിടികൂടാന്\u200d കഴിയാത്ത വാക്കുകള്\u200d നമ്മുടെ മോഡല്\u200d പിടികൂടാന്\u200d സാധിക്കുമോ എന്നാണ് ഉദ്ദേശിക്കുന്നത്.', 'lt': 'Mes siūlome implicitų kvotų ekstraktorių, iš vienos iki kitos neprižiūrėto ekstraktyvinio nervų santraukų modelio pokalbių tekstams. Atsakydami į postus, citacijos naudojamos svarbiai tekstų daliai pabrėžti. Mes siekiame išbraukti cituotus sakinius kaip santraukas. Daugumoje atsakymų aiškiai nenurodytos citacijos, todėl sudėtinga naudoti citacijas kaip priežiūrą. Tačiau net jei tai nėra aiškiai parodyta, atsakymai visada susiję su tam tikromis tekstų dalimis; mes juos vadiname netiesioginėmis citacijomis. Netiesioginis kvotų išrašytojas siekia išbraukti netiesioginius kvotų santraukas. Modelio mokymo užduotis – numatyti, ar atsakymo kandidatas yra tikras atsakymas į pareigas. For prediction, the model has to choose a few sentences from the post.  Siekiant tiksliai nuspėti, modelis išmoko išimti atsakymuose dažnai nurodytus sakinius. Vertiname savo model į dviem elektroninio pašto duomenų rinkiniais ir vienu socialinių žiniasklaidos duomenų rinkiniu ir patvirtiname, kad mūsų model is naudingas ekstraktyviai apibendrinant. Toliau aptariame du klausimus: viena, ar citatų išgavimas yra svarbus apibendrinimo veiksnys, kita, ar mūsų model is gali apimti svarbius sakinius, kurių tradiciniai metodai negali.', 'mt': 'Aħna nipproponu Estrattur Impliċitu tal-Kwoti, mudell ta’ sommarju newrali estrattiv mhux sorveljat minn tarf sa tarf għal test ta’ konverżjoni. Meta nwieġbu għall-postijiet, il-kwotazzjonijiet jintużaw biex jenfasizzaw parti importanti mit-testi. Għandna l-għan li neħħew sentenzi kkwotati bħala sommarji. Il-biċċa l-kbira tat-tweġibiet ma jinkludux b’mod espliċitu kwotazzjonijiet, għalhekk huwa diffiċli li jintużaw kwotazzjonijiet bħala superviżjoni. Madankollu, anke jekk ma jintweriex espliċitament, it-tweġibiet dejjem jirreferu għal ċerti partijiet tat-testi; jissejjaħhom kwotazzjonijiet impliċiti. L-Estrattur impliċitu tal-Kwoti għandu l-għan li jestrezzjona kwoti impliċiti bħala sommarji. Il-kompitu tat-taħriġ tal-mudell huwa li jipprevedi jekk kandidat għat-tweġiba huwiex tweġiba vera għal kariga. Għall-previżjoni, il-mudell għandu jagħżel ftit sentenzi mill-kariga. Biex jipprevedi b’mod preċiż, il-mudell jitgħallem jestrezzjona sentenzi li t-tweġibiet ta’ spiss jirreferu għalihom. Aħna jevalwaw il-mudell tagħna fuq żewġ settijiet tad-dejta tal-email u sett wieħed tad-dejta tal-midja soċjali, u kkonfermaw li l-mudell tagħna huwa utli għas-sommarju estrattiv. We further discuss two topics;  wieħed huwa jekk l-estrazzjoni tal-kwotazzjonijiet hijiex fattur importanti għas-sommarju, u l-ieħor huwa jekk il-mudell tagħna jistax jaqbad sentenzi salienti li l-metodi konvenzjonali ma jistgħux.', 'mn': 'Бид харилцааны текстүүдэд эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь хадгалагдаггүй мэдрэлийн тодруулах загварыг санал болгож байна. Захимдаа хариулт өгөх үед дуудлага бичсэн чухал хэсэг тодорхойлох хэрэгтэй. Бид тэмдэглэгдсэн үгийг жинхэнэ хэлбэрээр гаргахаар зориулсан. Ихэнх хариултууд тодорхой хэлбэрээр дүгнэлт биш, тэгэхээр дүгнэлт хэрэглэх нь хэцүү. Гэвч энэ тодорхой харагдахгүй ч, хариулт үргэлж хэд хэсгийг нь харуулдаг. бид тэднийг нэрлэдэг нэр тохиолдол гэж нэрлэдэг. Үнэндээ нэвтрэгчийн зорилго нь нэвтрэгчийн зорилго юм. Загварын сургалтын ажил бол хариултын захирагчийн захирагчийн хувьд үнэн хариулт байх эсэхийг тодорхойлох юм. Таамаглах үед загвар нь хэдэн өгүүлбэрийг тайлбарлах хэрэгтэй. Үнэндээ тодорхой таамаглахын тулд загвар нь ихэвчлэн хариулах өгүүлбэрийг гаргахад суралцдаг. Бид загварыг хоёр эл. пошта өгөгдлийн санд, нэг нийгмийн медиа өгөгдлийн санд үнэлдэг. Бидний загвар нь нэмэгдүүлэхэд хэрэгтэй гэдгийг тодорхойлдог. Бид хоёр сэдэв илүү ярилцдаг. Нэг нь дахин дахин дахин дахин дахин дахин нэмэгдүүлэх чухал хүчин зүйл эсвэл, нөгөө нь бидний загвар нь ердийн аргаар дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин', 'pl': 'Proponujemy Implicit Quote Extractor, kompleksowy, bez nadzoru ekstrakcyjny model streszczenia neuronowego dla tekstów konwersacyjnych. Kiedy odpowiadamy na posty, cytaty są używane do podkreślenia ważnej części tekstów. Naszym celem jest wydobycie cytowanych zdań jako podsumowań. Większość odpowiedzi nie zawiera wyraźnie cytatów, więc trudno jest używać cytatów jako nadzoru. Jednakże, nawet jeśli nie jest ono wyraźnie pokazane, odpowiedzi zawsze odnoszą się do pewnych części tekstów; Nazywamy je cytatami ukrytymi. Implicit Quote Extractor ma na celu wyodrębnienie domyślnych cytatów jako podsumowań. Zadaniem szkoleniowym modelu jest przewidywanie, czy kandydat na odpowiedź jest prawdziwą odpowiedzią na post. Dla przewidywania model musi wybrać kilka zdań z postu. Aby dokładnie przewidzieć, model uczy się wyodrębniać zdania, do których odpowiedzi często odnoszą się. Oceniamy nasz model na dwóch zbiorach danych e-mail i jednym zbiorze danych mediów społecznościowych i potwierdzamy, że nasz model jest przydatny do ekstrakcyjnego podsumowania. Omówimy dwa tematy: Jednym z nich jest to, czy ekstrakcja cytatów jest ważnym czynnikiem podsumowania, a drugim, czy nasz model potrafi uchwycić istotne zdania, których konwencjonalne metody nie potrafią.', 'ro': 'Propunem Implicit Quote Extractor, un model de sintetizare neurală extractivă fără supraveghere end-to-end pentru textele conversaționale. Când răspundem la mesaje, citatele sunt folosite pentru a evidenția o parte importantă a textelor. Scopul nostru este să extragem propoziții citate ca rezumate. Majoritatea răspunsurilor nu includ în mod explicit citate, deci este dificil să folosiți citate ca supraveghere. Cu toate acestea, chiar dacă nu este prezentat în mod explicit, răspunsurile se referă întotdeauna la anumite părți ale textelor; Le numim citate implicite. Implicit Quote Extractor își propune să extragă citatele implicite ca rezumate. Sarcina de instruire a modelului este de a prezice dacă un candidat de răspuns este un răspuns adevărat la un post. Pentru predicție, modelul trebuie să aleagă câteva propoziții din post. Pentru a prezice cu precizie, modelul învață să extragă propoziții la care răspunsurile se referă frecvent. Evaluăm modelul nostru pe două seturi de date prin e-mail și un set de date social media și confirmăm că modelul nostru este util pentru rezumarea extractivă. Mai discutăm două subiecte: unul este dacă extragerea citatului este un factor important pentru rezumare, iar celălalt este dacă modelul nostru poate capta propoziții importante pe care metodele convenționale nu le pot face.', 'no': 'Vi foreslår implisitt siteringsekstraktor, eit ekstraktivt neuralsamanseringsmodul for konverterande tekstar utan slutt til slutt. Når vi svarar på e- post, vert sitata brukt til å markera viktig del av tekstar. Vi må henta ut siterte setningar som samandrag. Dei fleste svara inkluderer ikkje forklart sitata, så det er vanskeleg å bruka sitata som oversikt. Men selv om det ikkje er eksplisert vist, vil svara alltid referera til enkelte tekstdeler. vi kallar dei implisitte sitat. Implicit Quote Extractor mål å pakka ut implisitt sitat som samandrag. Øvingsoppgåva i modellen er å foregå om ein svarkandidat er ein sann svar på ei post. For forhåndsvising må modellen velja noen setningar frå post. For å foregå nøyaktig, lærer modellen å pakka ut setningar som svarar ofte refererer til. Vi evaluerer modellen vårt på to e-postadatasett og ein sosiale media-dataset, og bekrefter at modellen vårt er nyttig for ekstraktivt samansering. Vi diskuterer to emne lenger; Ein er om sitattekstrahering er ein viktig faktor for sammendraging, og den andre er om modellen vår kan henta salient setningar som ikkje kan henta konvensjonale metodar.', 'sr': 'Predlažemo Implicitni ekstraktor citata, neodređeni ekstraktivni neuralni rezimetrirani model za razgovorne tekste. Kada odgovorimo na postove, citati se koriste kako bi naglasili važan deo teksta. Ciljem smo da izvučemo citatne rečenice kao sažetke. Većina odgovora ne uključuju jasno citate, pa je teško koristiti citate kao nadzor. Međutim, čak i ako se ne pokazuje jasno, odgovori uvek odnose na određene dijelove teksta; nazivamo ih implicitnim citatama. Implicitni quote Extractor je cilj da izvuče implicitne citate kao sažetke. Odvjetnica model a je predviđati da li je kandidat odgovora istinski odgovor na poštu. Za predviđanje, model mora izabrati nekoliko rečenica iz postaje. Da bi precizno predvidjela, model nauèi da izvuèe rečenice na koje često odgovara. Procjenjujemo naš model na dva seta podataka e-maila i jedan set podataka socijalnih medija i potvrđujemo da je naš model korisan za ekstraktivnu sažetku. Dalje razgovaramo o dva tema; jedan je da li je ekstrakcija citata važan faktor za sažetak, a drugi je da li naš model može uhvatiti saliène rečenice koje konvencionalne metode ne mogu.', 'so': "We propose Implicit Quote Extractor, an end-to-end unsupervised extractive neural summarization model for conversational texts.  Markii aan ka jawaabno boostada, waxaa loo isticmaalaa in loo caddeeyo qeyb muhiim ah qoraalka. Waxaynu isku daynaa in aan soo saarno erayo la qoray oo uu soo jeedo. Jawaabta badankoodu si cad uma ahan mid quraan, sidaas darteed waa ku adag tahay in la isticmaalo quraanka sida ilaaliyo. Si kastaba ha ahaatee hadduusan si cad u muuqaneyn, jawaabaha waxaa mar walba loola jeedaa qeybo qoraal ah; waxaynu ugu magacaabnaa waxyaabo la'aan ah. Implicit quote Extractor wuxuu aimaa in uu soo saaro quotes implicit as summaris. Shaqada waxbarashada modellka waa in la sii sheegaa in mushaarku uu yahay jawaab run ah. Tusaale ahaan waa in uu booska ka doortaa dhawr erayo. Si loo sii sheegayo si saxda ah, modelku wuxuu baraa in uu soo bixiyo hadallada uu marar badan ku jawaabo. Tusaalkayaga waxaynu ku qiimeynaynaa labada macluumaad ee e-mailka iyo mid kamid ah macluumaadka bulshada, waxaynu xaqiijinnaa in modellkayagu uu faa’iido u yahay mid la soo saaro. Waxaynu ka sheekeysanaynaa labada mada; Mid waa in la soo saaro uu yahay xaalad muhiim ah oo la soo jarayo, tan kalena waa in modellkayagu uu qabsan karo fursado saliidda oo aan awoodin qaababka caadiga ah.", 'sv': 'Vi föreslår Implicit Quote Extractor, en end-to-end oövervakad extraktiv neural sammanfattningsmodell för konversationstexter. När vi svarar på inlägg används citat för att lyfta fram viktiga delar av texter. Vi strävar efter att extrahera citerade meningar som sammanfattningar. De flesta svar innehåller inte uttryckligen citat, så det är svårt att använda citat som övervakning. Även om svaren inte uttryckligen anges hänvisar de dock alltid till vissa delar av texten. Vi kallar dem underförstådda citat. Implicit Quote Extractor syftar till att extrahera implicita citat som sammanfattningar. Modellens utbildningsuppgift är att förutsäga om en svarskandidat är ett verkligt svar på ett inlägg. För förutsägelse måste modellen välja några meningar från inlägget. För att förutsäga exakt lär modellen sig att extrahera meningar som svar ofta hänvisar till. Vi utvärderar vår modell på två e-postdataset och ett dataset för sociala medier, och bekräftar att vår modell är användbar för extraktiv sammanfattning. Vi diskuterar vidare två frågor: Den ena är om citat extraktion är en viktig faktor för sammanfattning, och den andra är om vår modell kan fånga viktiga meningar som konventionella metoder inte kan.', 'ta': 'பேச்சு உரைகளுக்கான முடிவிலிருந்து முடிவிலிருந்து பாதுகாப்பாக்கப்படாத பெண் சுருக்கல் மாதிரியை செயல்படுத்துக நாம் அஞ்சலுக்கு பதில் அளிக்கும் போது, மேற்கோள்கள் உரைகளின் முக்கியமான பகுதி தனிப்படுத்தப்படுகிறது. நாம் சுருக்கமாக சொல்லப்பட்ட வாக்கியங்களை வெளியேற்ற வேண்டும். பெரும்பாலான பதில் வெளிப்படையாக சேர்க்கப்படவில்லை, அதனால் குறிப்புகளை கண்காணிப்பாக பயன்படுத்த கடினமானது. அது வெளிப்படையாக காட்டப்படாமல் இருந்தாலும், பதில் எப்போதும் சில உரைகளின் சில பகுதிகளை குறிக்கும். நாம் அவர்களை குறிப்பிட்ட குறிப்புகள் என்று அழைக்கிறோம். Implicit Quote Extractor aims to extract implicit quotes as summaries.  மாதிரியின் பயிற்சி செயல் ஒரு பதில் தேர்ந்தெடுக்கப்பட்ட விருப்பத்திற்கு உண்மையான பதில் இருக்கிறதா என் முன்வாக்கியத்திற்கு, மாதிரி ஒரு சில வாக்கியங்களை தேர்ந்தெடுக்க வேண்டும். சரியாக முன்வாக்குவதற்கு, மாதிரி வாக்கியங்களை வெளியேற்றுவதற்கு கற்றுக் கொள்கிறது அது வெளியேற்றும் வாக் இரண்டு மின்னஞ்சல் தரவுத்தளங்கள் மற்றும் ஒரு சமூக ஊடக தரவுத்தளத்தில் எங்கள் மாதிரியை மதிப்பிடுகிறோம். நம் மாதிரி வெளியேற்ற நாம் இன்னும் இரண்டு தலைப்புகளை விவாதம் செய்கிறோம். சுருக்கத்திற்கான முக்கியமான வெளியீடு என்பதாகும் மற்றொரு மாதிரி வழக்கமான முறைகளை பிடிக்க முடியாத வாக்கியங்களை பிடிக', 'si': 'අපි ප්\u200dරයෝජනය කරන්නේ ප්\u200dරයෝජනය ප්\u200dරයෝජනයක්, අවසානයෙන් අවසානයක් නැති ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය වෙනුවෙන් ප්\u200dරය අපි පොස්ට් වලට උත්තර දෙන්නම්, පැත්තට වැදගත් කොටසක් පැහැදිලි කරන්න පාවිච්චි කරනවා. අපි අදහස් කරනවා කියලා කියලා කියලා කියලා කියලා කියන්න. ගොඩක් ප්\u200dරතිච්චිත ප්\u200dරතිචාරයක් පැහැදිලිවෙන්නේ නැහැ, ඉතින් ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක නමුත්, ඒක පැහැදිලි විදිහට පෙන්වන්නේ නැත්නම්, ප්\u200dරතිචාරය හැමවෙලේම පාළුවන් කිසිම කොටස් වල අපි ඔවුන්ට ප්\u200dරශ්නයක් කියනවා. විශේෂ ක්\u200dරියාත්මක ක්\u200dරියාත්මක ක්\u200dරියාත්මක විශේෂ විශේෂ කරන්න. මොඩල් එකේ ප්\u200dරශ්නය වැඩය තමයි ප්\u200dරතිච්චාරයක් පොස්ටල් එකට ඇත්ත උත්තර ප්\u200dරතිච්චාරයක් කියලා ප පොස්ට් එකෙන් වාක්ය කිහිපයක් තෝරගන්න ඕන. හරියටම ප්\u200dරශ්නය කරන්න, මොඩේල් ඉගෙන ගන්නවා වචන අතිරික්ෂා කරන්න. අපි අපේ මෝඩේල් දෙකට සහ සාමාජික මධ්\u200dයමාධ්\u200dයම දත්ත සූදානයට අවශ්\u200dය කරන්න, අපේ මෝඩේල් ප්\u200dරයෝජනය ප්\u200dරයෝජ අපි තව ප්\u200dරශ්නයක් දෙකක් කතා කරනවා; එක තමයි ක්\u200dරියාත්මක නිර්මාණය සම්පූර්ණය සඳහා වැදගත් ක්\u200dරියාත්මක වෙන්නේ නැත්නම්, අනිත් ක්\u200dරියාත්මක විදියට', 'ur': 'ہم اثبات اثبات اثبات کرنے والے کو پیشنهاد کرتے ہیں، ایک پایان-پایان کے لئے غیرقابل اثبات نیورال سامنے کے نمونڈل ہے. جب ہم پوسٹوں کو جواب دیتے ہیں، اثرات لکھنے کے لئے استعمال کیے جاتے ہیں. ہم اس بات کا ارادہ کرنا چاہتے ہیں کہ جمع کریں۔ اکثر جواب صریح طور پر اثرات کے ساتھ نہیں لگتے، سو اثرات کو نظر کے طور پر استعمال کرنے کا مشکل ہے. لیکن اگر یہ واضح طور پر نہیں دکھائی جاتی تو جواب ہمیشہ ایک قسم کے متعلق ہے ہم ان کو معلوم کررہے ہیں۔ اثبات اثبات اثبات کا ارادہ کرتا ہے کہ اثبات اثبات اثبات کریں مدل کی تعلیم کا کام یہ ہے کہ پیش بینی کریں کہ ایک جواب کاندینٹ ایک پوسٹ پر سچا جواب ہے. پیش بینی کے لئے، موڈل کو پوسٹ سے چند جماعتیں انتخاب کرنے کی ضرورت ہے. مطمئن طور پر پیش بینی کرنے کے لئے، موڈل سیکھ رہا ہے کہ کلمات اٹھانے کی جگہ بہت زیادہ اٹھاتے ہیں۔ ہم نے اپنے مدل کو دو ایمیل ڈیٹ سٹ اور ایک سوسیل میڈیا ڈیٹ سٹ پر مطابق کریں اور تصدیق کریں کہ ہمارا مدل اضافہ کرنے کے لئے فائدہ ہے. ہم دوسرے موضوع میں بھی بحث کرتے ہیں۔ ایک یہ ہے کہ اٹھانے کے لئے اٹھانے کا ایک اہم فکتور ہے اور دوسرا یہ ہے کہ کیا ہماری مدل اٹھانے والی جماعتیں پکڑ سکتی ہیں جن کی معمولی طریقے نہیں کر سکتے۔', 'uz': "Biz suhbat matnlari uchun muvaffaqiyatli muvaffaqiyatli muvaffaqiyatli koʻchirilmagan neyron hisoblash modelini tahrirlash talab qilamiz. Xabarga javob berilganda quyidagi matnlarning muhim qismni koʻrsatish uchun ishlatiladi. Biz quyidagi so'zlarni kichkina qilish uchun tuzilamiz. Koʻpchilik javoblar notoʻgʻri imkoniyatlarni koʻchirish mumkin, shunday qilib quyidagi so ʻzlarni boshqarish juda qiyin. Lekin, agar tashqi koʻrsatilmasa, javoblar har doim matnlarning bir necha qismlariga ega bo'ladi; biz ularni muvaffaqiyatli misol deb ataymiz. @ info: whatsthis Name Koʻrib chiqish uchun model postdan bir necha so'zlarni tanlashi kerak. Koʻrsatish uchun model oddiy narsalarni chiqarishni o'rganadi. Biz ikki elektron pochta maʼlumotlar tarkibida modelimizni qiymatimiz va bir shaxsiy medya maʼlumotlar tarkibida ishlatamiz va modelmizni tashkilotni ajratish uchun foydalanishimizni bekor qilamiz. Biz ikkita mavzuni boshqaramiz; birinchi so'zni ajratish muhim darajasi, boshqa modelmiz qo'shilgan usullarni qabul qilishi mumkin.", 'vi': 'Chúng tôi đề xuất ra máy trích dẫn ngầm, một mô hình phòng độc lập thần kinh khai thác không giám sát cho văn bản đối thoại. Khi chúng tôi trả lời các bài viết, trích dẫn được dùng để nhấn mạnh một phần quan trọng trong văn bản. Mục tiêu của chúng tôi là trích dẫn các câu trích dẫn. Hầu hết các câu trả lời không hiển thị trích dẫn, nên khó dùng trích dẫn làm giám sát. Tuy nhiên, ngay cả khi nó không được hiển thị rõ ràng, câu trả lời luôn liên quan đến một số phần văn bản; Chúng tôi gọi đó là ngầm trích dẫn. Bộ trích dẫn ngầm nhằm trích dẫn ngầm như các bản tóm tắt. Nhiệm vụ huấn luyện của mô hình là dự đoán ứng viên trả lời có phải là câu trả lời thực sự cho một bài viết. Để dự đoán, người mẫu phải chọn vài câu từ bài viết. Để dự đoán chính xác, mẫu học cách trích ra câu trả lời mà thường xuyên liên quan. Chúng tôi đánh giá mẫu của chúng tôi trên hai bộ dữ liệu email và một bộ dữ liệu mạng xã hội, và xác nhận rằng mô hình này có ích cho việc lấy đầy đủ. Chúng ta còn thảo luận hai vấn đề; Một là việc trích dẫn là một yếu tố quan trọng cho việc tổng kết luận, còn một là liệu mô hình của chúng ta có thể chụp những câu hỏi nổi bật mà các phương pháp truyền thống không thể.', 'bg': 'Предлагаме имплицитно извличане на цитати, модел от край до край без надзор за извличане на невронни обобщения за разговорни текстове. Когато отговаряме на публикации, цитати се използват за подчертаване на важна част от текстовете. Целта ни е да извлечем цитираните изречения като обобщения. Повечето отговори не включват изрично цитати, така че е трудно да се използват цитати като надзор. Въпреки това, дори и да не е изрично посочено, отговорите винаги се отнасят до определени части от текстовете; Наричаме ги имплицитни цитати. Екстрактор на имплицитни цитати има за цел да извлече имплицитни цитати като резюмета. Задачата на обучението на модела е да предвиди дали кандидатът за отговор е верен отговор на дадена публикация. За прогнозиране моделът трябва да избере няколко изречения от публикацията. За да предскаже точно, моделът се научава да извлича изречения, които отговорите често се отнасят. Ние оценяваме нашия модел на два набора от данни по имейл и един набор от данни в социалните медии и потвърждаваме, че нашият модел е полезен за извличане на обобщение. По-нататък обсъждаме две теми: Единият е дали извличането на цитати е важен фактор за обобщаване, а другият е дали нашият модел може да улови важни изречения, които конвенционалните методи не могат.', 'da': 'Vi foreslår Implicit Quote Extractor, en end-to-end uden opsyn ekstraktiv neural opsummering model til samtaletekster. Når vi besvarer indlæg, bruges citater til at fremhæve vigtige dele af teksterne. Vi tilstræber at udtrække citerede sætninger som resuméer. De fleste svar indeholder ikke eksplicit citater, så det er svært at bruge citater som tilsyn. Selv om svarene ikke udtrykkeligt fremgår, henviser de imidlertid altid til visse dele af teksten. Vi kalder dem implicitte citater. Implicit Quote Extractor har til formål at udtrække implicitte citater som resuméer. Modellens uddannelsesopgave er at forudsige, om en svarkandidat er et sandt svar på et indlæg. Til forudsigelse skal modellen vælge et par sætninger fra indlægget. For at forudsige nøjagtigt lærer modellen at udtrække sætninger, som svar ofte refererer til. Vi evaluerer vores model på to e-maildatasæt og et datasæt på sociale medier, og bekræfter, at vores model er nyttig til ekstraktiv opsummering. Vi drøfter yderligere to emner: Den ene er, om citat ekstraktion er en vigtig faktor for opsummering, og den anden er, om vores model kan fange vigtige sætninger, som konventionelle metoder ikke kan.', 'hr': 'Predlažemo Implicitni ekstraktor citata, neodređen ekstraktivni neuralni rezimetrirani model za razgovorne tekste. Kada odgovorimo na postove, citati se koriste kako bi naglasili važan dio teksta. Ciljem smo izvući citatne rečenice kao sažetke. Većina odgovora ne uključuju jasno citate, pa je teško koristiti citate kao nadzor. Međutim, čak i ako se ne pokazuje jasno, odgovori se uvijek odnose na određene dijelove teksta; nazivamo ih implicitnim citatama. Implicitno quote extractor cilja je izvući implicitne citate kao sažetke. Odvjetnički zadatak model a je predviđati je li kandidat odgovora istinski odgovor na postaju. Za predviđanje, model mora izabrati nekoliko rečenica iz postaje. Da bi precizno predvidjeli, model uči izvlačiti rečenice na koje često odgovara. Procjenjujemo naš model na dva seta podataka e-maila i jedan set podataka društvenih medija i potvrđujemo da je naš model korisan za ekstraktivnu sažetku. Dalje razgovaramo o dvije teme; jedan je da li je izvlačenje citata važan faktor za sažetak, a drugi je da li naš model može uhvatiti salične rečenice koje konvencionalne metode ne mogu.', 'nl': 'We stellen Implicit Quote Extractor voor, een end-to-end, niet-begeleid extractief neurale samenvattingsmodel voor conversationele teksten. Wanneer we reageren op berichten, worden citaten gebruikt om belangrijke delen van teksten te markeren. We proberen geciteerde zinnen als samenvattingen te extraheren. De meeste antwoorden bevatten geen expliciete citaten, dus het is moeilijk om citaten als toezicht te gebruiken. De antwoorden hebben echter altijd betrekking op bepaalde delen van teksten, ook al wordt deze niet expliciet vermeld; We noemen ze impliciete citaten. Implicit Quote Extractor heeft als doel impliciete citaten te extraheren als samenvattingen. De trainingstaak van het model is om te voorspellen of een antwoordkandidaat een echt antwoord op een bericht is. Voor voorspelling moet het model een paar zinnen uit de post kiezen. Om nauwkeurig te voorspellen, leert het model zinnen te extraheren waar antwoorden vaak naar verwijzen. We evalueren ons model op twee e-mail datasets en één social media dataset, en bevestigen dat ons model nuttig is voor extractieve samenvatting. We bespreken verder twee onderwerpen: De ene is of citaatextractie een belangrijke factor is voor samenvatting, en de andere is of ons model opvallende zinnen kan vastleggen die conventionele methoden niet kunnen.', 'de': 'Wir schlagen Implicit Quote Extractor vor, ein End-to-End unüberwachtes extraktives neuronales Zusammenfassungsmodell für Konversationstexte. Wenn wir auf Beiträge antworten, werden Zitate verwendet, um wichtige Teile von Texten hervorzuheben. Unser Ziel ist es, zitierte Sätze als Zusammenfassungen zu extrahieren. Die meisten Antworten enthalten keine Zitate explizit, daher ist es schwierig, Zitate als Aufsicht zu verwenden. Auch wenn sie nicht ausdrücklich angegeben ist, beziehen sich die Antworten immer auf bestimmte Textteile; Wir nennen sie implizite Zitate. Implicit Quote Extractor zielt darauf ab, implizite Zitate als Zusammenfassungen zu extrahieren. Die Trainingsaufgabe des Modells besteht darin, vorherzusagen, ob ein Antwortkandidat eine echte Antwort auf einen Beitrag ist. Zur Vorhersage muss das Modell einige Sätze aus dem Beitrag auswählen. Um genau vorherzusagen, lernt das Modell Sätze zu extrahieren, auf die sich Antworten häufig beziehen. Wir bewerten unser Modell anhand von zwei E-Mail-Datensätzen und einem Social Media-Datensatz und bestätigen, dass unser Modell für extraktive Zusammenfassungen nützlich ist. Wir diskutieren weiter zwei Themen: Zum einen ist die Frage, ob Zitatenextraktion ein wichtiger Faktor für die Zusammenfassung ist, zum anderen, ob unser Modell aussagekräftige Sätze erfassen kann, die herkömmliche Methoden nicht erfassen können.', 'fa': 'ما پیشنهاد می\u200cکنیم که اخراج\u200cکننده\u200cی استفاده\u200cی استفاده\u200cی استفاده\u200cی استفاده\u200cی استفاده\u200cی استفاده\u200cی استفاده\u200cهای عصبی برای متن\u200cهای مکالمه\u200cای است. وقتی به پست جواب می دهیم، نقل\u200cهای مهم از متن\u200cها استفاده می\u200cشود. ما قصد داریم جمله\u200cهای ذخیره\u200cشده را به عنوان جمله\u200cها خارج کنیم. بسیاری از پاسخ\u200cها به طور واضحی از جمله\u200cهای عبارت نمی\u200cباشند، بنابراین برای استفاده از عبارت به عنوان نظارت سخت است. با این حال، حتی اگر به طور واضح نمایش نشده باشد، پاسخها همیشه به بخشی از متن\u200cها refer می\u200cشوند. ما به آنها می\u200cگوییم که نقل\u200cهای معمولی است. استخراج\u200cکننده\u200cی استخراج مثبت هدف می\u200cدهد که استخراج مثبت مثبت را به عنوان جمع\u200cآوری خارج کند. وظیفه آموزش مدل این است که پیش بینی کنیم که آیا یک کاندیدای جواب یک جواب حقیقی برای یک پست است. برای پیش بینی، مدل باید چند جمله از پست انتخاب کند. برای پیش\u200cبینی دقیقا، مدل یاد می\u200cگیرد که جمله\u200cهایی که معمولاً به آن جواب می\u200cدهند، اخراج کنند. ما مدل خود را در دو مجموعه داده\u200cهای ایمیل و یک مجموعه داده\u200cهای اجتماعی ارزیابی می\u200cکنیم و تایید می\u200cکنیم که مدل ما برای جمع\u200cآوری خارجی مفید است. ما دوتا موضوع را بحث می کنیم، یکی اینه که آیا استخراج نقل یک منبع مهم برای جمع کردن است، و دیگر این است که آیا مدل ما می تواند جمله\u200cهای طبیعی را بگیرد که روش\u200cهای معمولی نمی\u200cتواند.', 'id': 'Kami mengusulkan Pengekstraktor Quot Implicit, model ekstraksi saraf ekstraksi yang tidak diawasi akhir-akhir untuk teks konversasi. Ketika kita menjawab pada pos, kutipan digunakan untuk menyatakan bagian penting dari teks. Kami bertujuan untuk mengekstrak kalimat kutipan sebagai ringkasan. Kebanyakan jawaban tidak secara eksplicit termasuk kutipan, jadi sulit menggunakan kutipan sebagai pengawasan. Namun, meskipun tidak secara eksplisit ditunjukkan, jawaban selalu merujuk ke bagian tertentu dari teks; we call them implicit quotes.  Implicit Quote Extractor aims to extract implicit quotes as summaries.  Tugas latihan dari model adalah untuk memprediksi apakah kandidat jawaban adalah jawaban yang benar pada pos. Untuk prediksi, model harus memilih beberapa kalimat dari pos. Untuk memprediksi dengan akurat, model belajar untuk mengekstrak kalimat yang menjawab sering merujuk. We evaluate our model on two email datasets and one social media dataset, and confirm that our model is useful for extractive summarization.  We further discuss two topics;  salah satunya adalah apakah ekstraksi kutipan adalah faktor penting untuk ringkasan, dan yang lainnya adalah apakah model kita dapat menangkap kalimat yang penting bahwa metode konvensional tidak dapat.', 'sw': 'Tunapendekeza Mradi wa Utetezi wa Kumbukumbu, Mradi wa muhtasari wa ubongo usioendeleweka mwishoni wa mwishoni kwa ajili ya maandishi ya mazungumzo. Tunapojibu makala, nukuu zinatumiwa kuonyesha sehemu muhimu ya maandishi. Tuna lengo la kuondoa hukumu zilizonukuliwa kama muhtasari. Miitikio mengi hayakuwa wazi ni pamoja na nukuu, kwa hiyo ni vigumu kutumia nukuu kama ufuatiliaji. Hata hivyo, hata kama haionekani wazi, majibu mara zote yanamaanisha baadhi ya maandishi; tunawaita nukuu zenye maana. Mfumo Mkuu wa Utengenezaji unalenga kuondoa nukuu zenye maana kama muhtasari. The training task of the model is to predict whether a reply candidate is a true reply to a post.  Kwa kutabiri, muundo unapaswa kuchagua hukumu chache kutoka makala hiyo. Ili kutabiri kwa sahihi, modeli inajifunza kutengeneza sentensi ambazo hujibu mara nyingi inamaanisha. Tunatathmini mtindo wetu kwenye seti za barua pepe mbili na seti moja ya taarifa za mitandao ya kijamii, na kuthibitisha kuwa mtindo wetu una ufanisi wa muhtasari wa kutosha. Tunajadili mada mbili zaidi; moja ni kama utekelezaji wa nukuu ni sababu muhimu kwa ajili ya uchaguzi wa muhtasari, na mwingine ni kama mfano wetu unaweza kukuta hukumu za mauzi ambazo njia za kawaida haziwezi.', 'ko': '우리는 은식 인용문 추출기를 제기했는데 이것은 세션 텍스트의 끝에서 끝까지 무감독 추출 신경 요약 모델이다.우리가 댓글에 답장을 할 때, 인용어는 텍스트의 중요한 부분을 돋보이게 하는 데 쓰인다.우리의 목표는 인용된 문장을 추출하여 총결하는 것이다.대부분의 답장에는 인용부호가 명확하게 포함되어 있지 않기 때문에 인용부호를 감독으로 사용하기 어렵다.그러나 명확하게 드러나지 않아도 답변은 항상 사건의 일부분을 언급한다.우리는 숨은 인용이라고 부른다.스텔스 인용 추출기는 스텔스 인용을 요약으로 추출하는 데 목적을 둔다.이 모델의 훈련 임무는 댓글 답변 후보가 댓글에 대한 진실한 답변인지 아닌지를 예측하는 것이다.예측에 있어서 모델은 반드시 댓글에서 몇 개의 문장을 선택해야 한다.이 모델은 정확한 예측을 위해 답장자가 자주 언급하는 문장을 추출한다.우리는 두 개의 전자 우편 데이터 집합과 한 소셜 미디어 데이터 집합에서 우리의 모델을 평가하고 우리의 모델이 요약 추출에 유용하다는 것을 확인했다.우리는 두 가지 주제를 진일보 토론한다.하나는 인용문 추출이 요약의 중요한 요소인지, 다른 하나는 우리의 모델이 전통적인 방법으로는 포획할 수 없는 현저한 문장을 포획할 수 있는지이다.', 'sq': 'Ne propozojmë Extraktorin e Quotave Implicit, një model përfundim-përfundim të jashtëzakonshëm rrëfimi nervor për tekstet bisedimore. Kur i përgjigjemi postimeve, citatet përdoren për të theksuar pjesën e rëndësishme të teksteve. We aim to extract quoted sentences as summaries.  Shumica e përgjigjeve nuk përfshijnë shprehësisht citimet, kështu që është e vështirë të përdoren citimet si mbikqyrje. Megjithatë, edhe nëse nuk shfaqet shprehësisht, përgjigjet gjithmonë referohen në disa pjesë të teksteve; i quajmë citate implicite. Ekstraktori implicit i citimeve synon të nxjerrë citimet implicite si përmbledhje. The training task of the model is to predict whether a reply candidate is a true reply to a post.  Për parashikim, modeli duhet të zgjedhë disa fjalë nga posti. Për të parashikuar saktësisht, modeli mëson të nxjerrë fraza që përgjigjet i referohen shpesh. We evaluate our model on two email datasets and one social media dataset, and confirm that our model is useful for extractive summarization.  Ne diskutojmë më tej dy temë; one is whether quote extraction is an important factor for summarization, and the other is whether our model can capture salient sentences that conventional methods cannot.', 'af': "Ons voorstel Implicite Quote Extractor, 'n end- to- end ongeonderwerp ekstraktiewe neurale opsomming model vir gesprekslyn teks. Wanneer ons antwoord na pos, word citasies gebruik om belangrik deel van teks te verlig. Ons doen doel om aangetelde setnings as opsommings uit te trek. Die meeste antwoordes insluit nie uitsondelik citasies nie, sodat dit is moeilik om citasies as supervisie te gebruik. Maar selfs as dit nie uitduidelik vertoon is nie, antwoordes altyd verwys na sekere dele van teks; ons noem hulle implisite siteite. Implicite Quote Extractor doel om implicit quotes as opsommings te uitpak. Die onderwerp van die model is om te voorskou of 'n antwoord kandidate 'n waar antwoord op 'n pos is. Vir voorskou moet die model 'n paar setings van die pos kies. Om presies te voorskou, leer die model om te uitpak setnings wat antwoord dikwels verwys na. Ons evalueer ons model op twee e-pos datastelle en een sosiale media datastel en bevestig dat ons model nuttig is vir ekstraktiewe opsomming. Ons bespreek nog twee onderwerpe; een is of quote extraction 'n belangrike faktor is vir opsomming, en die ander is of ons model salient setnings kan opneem wat konvensionale metodes kan nie.", 'am': 'የውጤት ምርጫዎች፣ ወደ መጨረሻ ያልጠበቀው የነጥብ አቀማመጥ ሞዴል ለመስጠት እናስፈልጋለን፡፡ When we reply to posts, quotes are used to highlight important part of texts.  We aim to extract quoted sentences as summaries.  ብዙዎቹም መልዕክቶች በተለየ የተጠቃሚ ነጥቦች አያስቀምጡም፣ የተጠቃሚ ነጥቦችን እንደ መጠበቅ ለመጠቀም በጣም ችግር ነው፡፡ ነገር ግን ግልፅ ባይታይ እንኳ መልስ ሁልጊዜ ወደ አንዳንድ ጽሑፎች ይጠራል፤ ጥሩ ቃላት እንጠራቸዋለን ። ReplyForward የሞዴል ትምህርት ማድረግ መልስ እውነተኛ መሆኑን ለማወቅ ነው፡፡ ለትንቢት፣ ሞዴል ከፖስቲካው ጥቂት ቃላት መምረጥ ያስፈልጋል፡፡ በሙሉ ለመፍጠር ሞዴል ብዙ ጊዜ የሚመልሱትን ቃላት ለመውጣት ይማራል፡፡ የኢሜይል ዳታዎችን እና አንድ ማኅበራዊ ሚዲያ ዳታሰርን እናረጋግጣለን እና ሞዴልናችን ለውጭ ማቀናቀል ይጠቅማል ብለን እናረጋግጣለን፡፡ ሁለትን ጉዳዮች እንጨምር:: አንዱ ነጥብ ማሳየት የግል ጉዳይ ነው፣ ሁለተኛውም ሞዴሌያችን የዘላለም ሥርዓት መያዛቸውን መያዝ አይችልም ማለት ነው፡፡', 'tr': 'Biz Implicit Quote Extractor\'y teklip edip görkezilýän çykyş metinler üçin janlaşdyrmady. Zirnatlara jogap berdikde, sözleriň wajyp bölegini ýagtylamak üçin ullanylýar. Biz sözleri sumrak diýip açmagy amaçlarys. Iň köp jogabat tapylmady, beýleki hatlary bejermek kyn däl. Ýagna görkezilmedik bolsa-da, jogaplar hemişe metin bölegine söz berýär; olara görnüş gabat diýip atlandyrýarys. Geditiň sened Aňlaýyşy sumatlar ýaly açmak amasynda. Modeliň taýýarlanmasy meýdançasynyň jogaby bir post üçin dogry jogaby diýip çaklamak. Taýýarlama üçin, nusga ýerden birnäçe sözleri saýlamak gerek. Dyggat öňden geçirmek üçin, nusga köplenç diňe jogaplary açmak öwrenýär. Biz nusgamyzyň iki e-maili veri setirinde we bir sosyal medýä veri setirinde deňleýäris we nusgamyzyň ekstra jemgyýet üçin faydalydygyny tassyklaýarys. Biz iki tema diňe gürrüň berýäris; Birinji "sözleşme" diýip sözlerimiz sumatlandyrmak üçin wajyp faktördür, we beýlekisi, nusgamyzyň modimiziň diňe-eşikli sözlerimizi tapyp bilmeýän däldir.', 'hy': 'Մենք առաջարկում ենք ներկայացված մեջբերումների արտադրողը, հաղորդակցման տեքստերի վերջ-վերջ անվերահսկված նյարդային արտադրողական համառոտագրման մոդել: Երբ մենք պատասխանում ենք հարցերին, մեջբերումները օգտագործվում են մեջբերումների կարևոր մասը նշելու համար: Մենք նպատակում ենք մեջբերված նախադասությունները հանել որպես համառոտագրություն: Պատասխանների մեծ մասը բացահայտորեն չի ներառում մեջբերումներ, այնպես որ դժվար է մեջբերումներ օգտագործել որպես վերահսկողություն: Այնուամենայնիվ, նույնիսկ եթե դրանք բացատրական չեն ցույց տալիս, պատասխանները միշտ վերաբերվում են տեքստների որոշ մասերին: we call them implicit quotes.  Անպայման մեջբերման արտադրողը նպատակն է հանել անպայման մեջբերումները որպես համառոտագրություններ: Մոդելի ուսուցման խնդիրն այն է, որ կանխատեսենք, թե արդյոք պատասխանի թեկնածուն իրական պատասխան է աշխատանքին: Նախատեսելու համար մոդելը պետք է ընտրի մի քանի նախադասություններ հրապարակից: Ճշմարիտ կանխատեսելու համար մոդելը սովորում է հանել նախադասություններ, որոնց պատասխանները հաճախ անվանում են: Մենք գնահատում ենք մեր մոդելը երկու էլեկտրոնային տվյալների համակարգի և մի սոցիալական լրատվյալների համակարգի վրա, և հաստատում ենք, որ մեր մոդելը օգտակար է արտադրողական համառոտագրման համար: Մենք նաև քննարկում ենք երկու թեման` Առաջինը՝ արդյոք մեջբերումը համառոտագրության կարևոր գործոն է, իսկ մյուսը՝ արդյոք մեր մոդելը կարող է վերցնել հիմնական նախադասություններ, որոնք ավանդական մեթոդները չեն կարող:', 'az': 'Biz müzakirə metinlər üçün istifadə edilməmiş ekstraktif nöral təmizləmə modeli olan Implicit Quote Extractor təklif edirik. Postlara cavab verdiyimiz zaman, mətnlərin möhkəm parçasını işıqlandırmaq üçün sitatlar alınır. Biz sözləri təmizləmək istəyirik. Çox cavab açıq-aydın sitatları içərisində deyil, bu yüzden sitatları gözətçi kimi istifadə etmək çətin. Lakin, əgər açıq-aydın göstərilməsə də, cavablar həmişə bəzi mətnlərin parçalarına danışır. Biz onları implicit quotes adlandırırıq. Qısqa Qısqa Çıqtıcısı qeyd olaraq qeyd edilməyə niyyət edir. Modelin təhsil işləri, cavab kandidatının postaya doğru cavab olduğunu təmin etməkdir. Önümüzdə modellərin bir neçə cümlələri postadan seçməsi lazımdır. Düzgün tədbir etmək üçün, model çox dəfə cavab verən cümlələri çıxartmaq öyrənir. Biz modelimizi iki e-poçt veri seti və bir sosyal media veri seti ilə değerləşdiririk və modelimizin ekstraktif summarizasyon üçün faydalı olduğunu təsdiqləyirik. Biz daha sonra iki məsələni danışırıq. Digəri is ə modellərimizin sıxıntılı cümlələri alıb apara bilmədiyimiz mühüm faktördür.', 'bn': 'আমরা এক্সপ্লিকিট উদ্ধৃতি এক্সট্র্যাক্ট্র্যাক্টের প্রস্তাব করছি, যা শেষ পর্যন্ত সংরক্ষিত নিউরেল সংক্রান্ত সংক্রান্ত মডেল। যখন আমরা পোস্টের প্রতি উত্তর দেই, তার উদ্ধৃতি লেখার গুরুত্বপূর্ণ অংশ তুলে ধরার জন্য ব্যবহার করা হয়। আমরা উদ্দেশ্যের উদ্দেশ্যে সামারিক সংক্ষেপ হিসেবে উদ্ধৃতি প্রদান করি। বেশীর ভাগ উত্তর স্পষ্টভাবে উদ্ধৃতি আছে না, কাজেই উদ্ধৃতি পর্যবেক্ষণ হিসেবে ব্যবহার করা কঠিন। However, even if it is not explicitly shown, replies always refer to certain parts of texts;  we call them implicit quotes.  উদ্ধৃতি এক্সট্র্যাক্র্যাক্টরের লক্ষ্য হচ্ছে সারসংক্ষেপ হিসেবে ইম্পিকেট উদ্ধৃতি বের করার জন্য। মডেলের প্রশিক্ষণ কাজ হচ্ছে একটি পোস্টের প্রার্থী সত্যিকার কিনা ভবিষ্যদ্বাণী করা যায়। ভবিষ্যৎবাণীর জন্য, এই মডেলের পোস্ট থেকে কয়েকটি বাক্য নির্বাচন করতে হবে। যথাযথভাবে ভবিষ্যদ্বাণী করার জন্য মডেল শিখতে পারে যে বাক্য প্রতিক্রিয়া প্রায়শই উল্লেখ করে। আমরা দুই ই ই-মেইল ডাটাসেট এবং একটি সামাজিক মিডিয়া ডাটাসেটে আমাদের মডেল মূল্যায়ন করি, এবং নিশ্চিত করি যে আমাদের মডেল বের করে আনা সং আমরা আরো দুই বিষয় নিয়ে আলোচনা করি; একজন হচ্ছে উদ্ধৃতি সংক্ষেপের জন্য গুরুত্বপূর্ণ কারণ, আর অন্যটি হচ্ছে আমাদের মডেল বিক্রেতার শাস্তি গ্রহণ করতে পারে কিনা যা সাধারণ ম', 'cs': 'Navrhujeme Implicit Quote Extractor, komplexní nervový souhrnný model pro konverzační texty. Když odpovídáme na příspěvky, citace se používají k zvýraznění důležité části textů. Naším cílem je extrahovat citované věty jako shrnutí. Většina odpovědí výslovně neobsahuje citace, takže je obtížné použít citace jako dohled. Avšak i když není výslovně uvedena, odpovědi se vždy vztahují na určité části textů; Říkáme jim implicitní citace. Implicit Quote Extractor si klade za cíl extrahovat implicitní citace jako souhrny. Tréninkovým úkolem modelu je předpovědět, zda kandidát na odpověď je skutečnou odpověď na příspěvek. Pro predikci musí model vybrat několik vět z příspěvku. Pro přesné předpovědi se model naučí extrahovat věty, na které odpovědi často odkazují. Vyhodnocujeme náš model na dvou e-mailových datových sadách a jedné sadě sociálních médií a potvrzujeme, že náš model je užitečný pro extraktivní shrnutí. Dále diskutujeme o dvou tématech: Jedním z nich je, zda je extrakce citací důležitým faktorem pro shrnutí, a druhým je, zda náš model dokáže zachytit významné věty, které konvenční metody nemohou.', 'bs': 'Predlažemo Implicitni ekstraktor citata, neodređeni ekstraktivni neuralni rezimetrirani model za razgovorne tekste. Kada odgovorimo na postove, citati se koriste kako bi naglasili važan dio teksta. Ciljem smo izvući citatne rečenice kao sažetke. Većina odgovora ne uključuju jasno citate, pa je teško koristiti citate kao nadzor. Međutim, čak i ako se ne pokazuje jasno, odgovori se uvijek odnose na određene dijelove teksta; nazivamo ih implicitnim citatama. Implicitno quote Extractor cilja je izvući implicitne citate kao sažetke. Odvjetnički zadatak model a je predvidjeti da li je kandidat odgovora istinski odgovor na postaju. Za predviđanje, model mora izabrati nekoliko rečenica iz postaje. Da bi precizno predvidjela, model se naučio izvući rečenice na koje često odgovara. Procjenjujemo naš model na dva seta podataka e-maila i jedan set podataka socijalnih medija i potvrđujemo da je naš model korisan za ekstraktivnu sažetku. Dalje razgovaramo o dva tema; jedan je da li je izvlačenje citata važan faktor za sažetak, a drugi je da li naš model može uhvatiti salične rečenice koje konvencionalne metode ne mogu.', 'ca': "Proposem Extractor Implicit de Quote, un model de resum neural extractiu no supervisat de final a final per als textos conversacionals. Quan responem a publicacions, les citacions s'utilitzen per destacar una part important dels textos. Tenim l'objectiu d'extrair les frases citades com a resums. La majoria de les respostes no inclouen expressament citacions, així que és difícil utilitzar citacions com supervisió. No obstant això, fins i tot si no es mostra explícitament, les respostes sempre es refereixen a certes parts de textos; els anomenem citacions implícites. Implicit Quote Extractor té l'objectiu d'extrair citacions implícites com a resums. La tasca d'entrenament del model és predir si un candidat a resposta és una resposta veritable a un post. Per a predir, el model ha de triar unes quantes frases del post. Per predir amb precisió, el model aprene a extrair frases a les que les respostes es refereixen sovint. Evaluam el nostre model en dos conjunts de dades de correus electrònics i un conjunt de dades de mitjans socials, i confirmam que el nostre model és útil per a una resumida extractiva. Discutem més sobre dos temes: una és si l'extracció de cita és un factor important per a resumir, i l'altra és si el nostre model pot capturar frases salients que els mètodes convencionals no poden.", 'et': 'Pakume välja Implicit Quote Extractor, täieliku järelevalveta ekstraktiivse neuraalse kokkuvõtte mudeli vestlustekstraktide jaoks. Postitustele vastamisel kasutatakse tsitaate, et esile tuua oluline osa tekstist. Meie eesmärk on välja võtta tsiteeritud laused kokkuvõtetena. Enamik vastustest ei sisalda selgesõnaliselt tsitaate, mistõttu on keeruline kasutada tsitaate järelevalvena. Isegi kui seda ei ole selgesõnaliselt näidatud, viitavad vastused alati teatud tekstiosadele; Me nimetame neid kaudseteks tsitaatideks. Implicit Quote Extractor eesmärk on ekstraheerida kaudsed tsitaatid kokkuvõtetena. Mudeli koolituse ülesanne on ennustada, kas vastusekandidaat on tõeline vastus ametikohale. Ennustamiseks peab mudel valima postitusest mõned laused. Täpseks prognoosimiseks õpib mudel ekstraheerima lauseid, millele vastused sageli viitavad. Hindame oma mudelit kahe e-posti andmekogumi ja ühe sotsiaalmeedia andmekogumi põhjal ning kinnitame, et meie mudel on kasulik ekstraheerimiseks. Arutame veel kahte teemat: Üks on, kas tsitaatide ekstraheerimine on oluline tegur kokkuvõtlikuks tegemiseks ja teine on, kas meie mudel suudab jäädvustada silmapaistvaid lauseid, mida tavameetodid ei suuda.', 'fi': 'Ehdotamme Implicit Quote Extractor, päästä päähän valvomatonta ekstraktivointimallia keskusteluteksteille. Kun vastaamme viesteihin, lainausmerkkejä käytetään korostamaan tärkeää osaa teksteistä. Pyrimme erottamaan siteeratut lauseet tiivistelmiksi. Useimmat vastaukset eivät sisällä lainauksia, joten lainauksia on vaikea käyttää valvontana. Vastauksissa viitataan kuitenkin aina tiettyihin tekstien osiin, vaikkei sitä nimenomaisesti esitetä. Kutsumme niitä implisiittisiksi lainauksiksi. Implicit Quote Extractor pyrkii poimimaan implisiittiset lainaukset tiivistelminä. Mallin koulutustehtävänä on ennustaa, onko vastausehdokas oikea vastaus viestiin. Ennustetta varten mallin on valittava muutama lause postauksesta. Ennustaakseen tarkasti malli oppii poimimaan lauseita, joihin vastaukset usein viittaavat. Arvioimme malliamme kahden sähköpostiaineiston ja yhden sosiaalisen median aineiston perusteella ja vahvistamme, että mallimme on hyödyllinen tiivistelmässä. Keskustelemme myös kahdesta aiheesta: Toinen on se, onko lainauksen purkaminen tärkeä tekijä tiivistelmässä, ja toinen on se, pystyykö mallimme vangitsemaan merkittäviä lauseita, joita perinteiset menetelmät eivät pysty.', 'jv': 'We proposal paragraph-styletextattr Awak dhéwé kabèh nggolaké pêrbudhakan kanggo resmi echoH e l l o space w o r l d periodHelloworldHello world Nanging, meh iso ngomong nik apa-apa ora bisa ngomong, mbubati mesthi luwih mengko perkarang-perkarang textattr; akeh online ReplyForward Ombudhakan nggawe modèl kuwi tau ngerti apa ora dadi kapan pangan kuwi mesthi sing arep mbubati sing apik. Durangkang dipurangan, model kudu milih kebebasan kelas nang pisan Laptop" and "Desktop Awak dhéwé éntuk model nambah iki dadi e-mail lan saben dataset media sothik, lan nganggo nggawe barak dhéwé model sing barang nggo resampungasi wis diagram Awak dhéwé seneng pisan kelas telu; tema iki Wurung iku kelompok nggambar kelompok nggambar obah-obahan kanggo sumulasi, lan mbuh sing wis nong, iso disebarke winih dhéwé iso nggambar barang kelompok sing bisa pasar awak dhéwé.', 'ha': "Tuna goyyar da Complicit Quoter Extracti, wata motel na ƙarami wanda ba'a tsare shi ba na ƙarami masu tsari na bakin rubural wa littafan mazaɓa. Idan za mu karɓa wa mailman, za'a yi amfani da quoten a nuna rabon matsayin muhimu. Munã nufin mu sami maganar da aka rubũta shi kamar ƙari. Babu mayarwa ba su zama mai bayyana na ƙunsa da quoten, don haka, ya yi ƙunci a yi amfani da quoten kamar tsarin. Amma, kuma kõ da ba a nuna shi da bayyane ba, jawabun sune-daidai zuwa wani abu na littãfi; Munã kiran su misa. @ action: button Yi gabani kawai aikin mai amfani da shirin ayuka ko kuma yana da mayarwa gaskiyar zuwa wani mailli. Ko kuma ya kamata misalin ya zãɓi cire kaɗan daga bayan. Ga ka ƙayyade tsari, motel yana sanar da su zartar da tsaro wanda ke karɓa mai maras a kansa. Kana ƙaddara misalinmu a kan tsarin bayanin email biyu da tsari guda na mitandai na jamii, kuma muna gaskata cewa misalinmu yana da amfani ga ƙararin kashi. Tuna yi furuci biyu masu jayayya; ɗabi ne idan shirin nufi ya zama wani matsayi mai muhimu wa kurarin, kuma gudan yana kasa idan misalinmu ya iya kãma maganar salsalon da hanyon da ba za'a iya amfani da shi ba.", 'sk': 'Predlagamo Implicit Quote Extractor, nenadzorovan ekstraktivni nevronski model za povzetek besedil iz konca do konca. Ko odgovarjamo na objave, se uporabljajo citati za poudarjanje pomembnega dela besedil. Cilj je izvleči citirane stavke kot povzetke. Večina odgovorov ne vključuje izrecno navedb, zato je kot nadzor težko uporabiti navedbe. Vendar se odgovori vedno nanašajo na določene dele besedil, tudi če niso izrecno navedeni; Imenujemo jim implicitne citate. Implicit Quote Extractor želi izvleči implicitne citate kot povzetke. Naloga usposabljanja modela je napovedati, ali je kandidat za odgovor resničen odgovor na delovno mesto. Za napoved mora model izbrati nekaj stavkov iz objave. Če želite natančno napovedati, se model nauči izvleči stavke, na katere se odgovori pogosto nanašajo. Naš model ocenjujemo na dveh naborih podatkov o elektronski pošti in enem naboru podatkov o družbenih omrežjih ter potrjujemo, da je naš model uporaben za ekstraktivno povzetek. Nadalje razpravljamo o dveh temah: Ena je, ali je ekstrakcija citatov pomemben dejavnik za povzetek, druga pa, ali lahko naš model zajame pomembne stavke, ki jih običajne metode ne morejo.', 'he': 'אנו מציעים מחלץ ציטוטים משמעותיים, מודל מסופר לסופו של סוף אל סוף מסופר של סדרה נוירואלית חולץ לא מושגת לטקסטים שיחה. כאשר אנו מגיבים לפרסומות, ציטוטים משתמשים כדי להדגיש חלק חשוב של טקסטים. אנחנו מתכוונים להוציא משפטים ציטוטים כסכם. רוב התשובות לא כוללות באופן ברור ציטוטים, אז קשה להשתמש ציטוטים כפיקוח. עם זאת, גם אם זה לא מוצג באופן ברור, התשובות תמיד מתייחסות לחלקים מסוימים של טקסטים; אנחנו קוראים להם ציטוטים מרושעים. מחלץ ציטוטים משמעותיים מתכוון להוציא ציטוטים משמעותיים כסדרות. המשימה של המודל היא לחזות אם מועמד לתשובה הוא תשובה אמיתית לתפקיד. כדי לחזות, המודל צריך לבחור כמה משפטים מהפוסט. כדי לחזות בדיוק, המודל לומד להוציא משפטים שהתשובות מתייחסות לעתים קרובות. אנו מעריכים את הדוגמא שלנו בשני קבוצות מידע דואר אלקטרוני ומקבוצת מידע אחת של התקשורת החברתית, ואושרים שהדוגמא שלנו שימושית לסיוריזציה חיצונית. אנחנו מדברים על שני נושאים נוספים; אחת היא האם חיטוף ציטוטים הוא גורם חשוב לסיוריזציה, והאחרת היא האם הדוגמאל שלנו יכול לתפוס משפטים מרשימים ששיטות קונבנסיונציונליות לא יכולות.', 'bo': 'ང་ཚོས་འཇུག་སྣོད་ཀྱི་གསལ་བཤད་ཀྱི་དབྱིབས་བཟོས་བྱེད་མཁན ང་ཚོས་གནས་ཡུལ་ལ་ལན་པའི་སྐབས་སུ། ཆ་འཕྲིན་ཡིག་གི་གལ་ཆེ་ཆུང་ལ་དམིགས་འཛུགས་བྱེད་སྐབས། ང་ཚོས་ཚིག་ཕྲན་ཡིག་པའི་ཚིག་རྟགས་ལ་བསྡུས་བྱེད་པར་དམིགས་ཡུལ། ཡིན་ཡང་གནད་སྡུད་ཚན་གཅིག་གསལ་བཤད་ཀྱིས་དྲན་གཏོང་བྱེད་མི་ཐུབ། དེ་ལས་ཀྱང་དཀའ་ངལ་བསྒྲགས་ཚོགས ཡིན་ནའང་། གསལ་བཤད་མི་མངོན་པ་ཞིག་ལ་ལན་པར་ཐིག་ཁྲམ་གྱི་ཆ་ཤས་ཤས་གཅིག་མཚུངས་ཡིན་པ་མིན། ང་ཚོས་དེ་དག་ལ་གསལ་བཤད་ཀྱི་དབྱིབས་གཏོང་ཐུབ་པ་ཞིག་བྱེད། Implicit Quote Extractor aims to extract implicit quotes as summaries. མ་དབྱིབས་གཟུགས་རིས་གྱི་ལས་སྦྱོར་བ་ནི་ཁྲིད་རོགས་གནང་བ་ཞིག་ལ་བདེན་པའི་ལན་སྐོར་ཞིག་རེད། གཟུགས་རིས་འདི་ལྟ་བུའི་རྣམ་གྲངས་ཀ་དེ་ཐོག་མའི་ཚིག་རྐང་ཉུང་ཅིག་འདེམས་དགོས། གཟུགས་རིས་བདེན་པར་སྔོན་འཆར་བྱེད་དགོས་ན། མ་དབྱིབས་དཔེ་གཏོང་ཡོད་པའི་ཚིག ང་ཚོའི་མིག ང་ཚོས་དོན་བརྗོད་དོན་གཉིས་ཀྱི་གཏམ་གླེང་བ་དང་ གཞན་ཞིག་ནི་ཚིག་ཕྱིར་འདྲེན་ནི་བཅུད་སྡུད་པར་གལ་ཆེན་རེད་ཅིག་ཡིན་མིན།'}
{'en': 'Chinese Content Scoring : Open-Access Datasets and Features on Different Segmentation Levels C hinese Content Scoring: Open-Access Datasets and Features on Different Segmentation Levels', 'es': 'Calificación de contenido chino: conjuntos de datos y funciones de acceso abierto en diferentes niveles de segmentación', 'pt': 'Pontuação de conteúdo chinês: conjuntos de dados e recursos de acesso aberto em diferentes níveis de segmentação', 'ja': '中国語コンテンツスコアリング：さまざまなセグメンテーションレベルのオープンアクセスデータセットと機能', 'ar': 'تسجيل المحتوى الصيني: مجموعات بيانات مفتوحة الوصول وميزات على مستويات تجزئة مختلفة', 'zh': '中文评分:细分级开获取数据集功能', 'fr': 'Chinese Content Scoring\xa0: ensembles de données en libre accès et fonctionnalités à différents niveaux de segmentation', 'hi': 'चीनी सामग्री स्कोरिंग: ओपन-एक्सेस डेटासेट और विभिन्न विभाजन स्तरों पर सुविधाएँ', 'ga': 'Scóráil Ábhar Síneach: Tacair Sonraí Rochtana Oscailte agus Gnéithe ar Leibhéil Éagsúla Deighleacháin', 'ru': 'Оценка китайского контента: наборы данных открытого доступа и функции на разных уровнях сегментации', 'el': 'Αξιολόγηση κινεζικού περιεχομένου: σύνολα δεδομένων και χαρακτηριστικά ανοικτής πρόσβασης σε διαφορετικά επίπεδα τμηματοποίησης', 'hu': 'Kínai tartalom pontszámozás: nyílt hozzáférésű adatkészletek és funkciók különböző szegmentációs szinteken', 'ka': 'Name', 'it': 'Punteggio dei contenuti cinesi: set di dati open-access e funzionalità su diversi livelli di segmentazione', 'lt': 'Kinijos turinio vertinimas: atviros prieigos duomenų rinkiniai ir įvairių segmentacijos lygių požymiai', 'kk': 'Қытай мазмұны нүктесі: Open- Access деректер мен мүмкіндіктері түрлі сегментациялық деңгейінде', 'mk': 'Оценка на кинеската содржина: датотеки со отворен пристап и објекти на различни нивоа на сегментација', 'ms': 'Skor Kandungan Cina: Set Data Akses Buka dan Ciri-ciri pada Aras Segmentasi berbeza', 'ml': 'ചൈനീസിന്റെ ഉള്ളടക്കത്തിന്റെ സ്കോര്\u200dണി: വ്യത്യസ്തമായ വിഭാഗങ്ങളുടെ നിലകളില്\u200d തുറക്കുക', 'mt': 'Punteġġ tal-Kontenut Ċiniż: Settijiet ta’ Dejta b’Aċċess Miftuħ u Karatteristiċi fuq Livelli ta’ Segmentazzjoni Differenti', 'mn': 'Хятад Content Scoring: Open-Access өгөгдлийн сан болон өөр өөр хэлбэрийн хэмжээний боломж', 'no': 'Kinesisk innhaldspoeng: Opna-tilgang databaser og funksjonar på ulike segmenteringsnivå', 'pl': 'Chińska ocena treści: zbiory danych i funkcje otwartego dostępu na różnych poziomach segmentacji', 'ro': 'Scorarea conținutului chinezesc: seturi de date și caracteristici cu acces liber la diferite niveluri de segmentare', 'sr': 'Оценка китајских содержања: данате за открити приступ и фактуре на различним уровима сегментације', 'so': 'Sawirada waxyaabaha ku jira ee Shiino: Saacadaha kala duwan ee furan iyo imtixaanka kala duduwan', 'si': 'Name', 'sv': 'Kinesiskt innehållspoäng: Open Access datauppsättningar och funktioner på olika segmenteringsnivåer', 'ta': 'சீனா உள்ளடக்க மதிப்பெண்கள்: வேறு பிரிவு மட்டங்களில் திறந்துவிடும் தகவல் அமைப்புகள் மற்றும் பண்புகள்', 'ur': 'Name', 'uz': 'Name', 'vi': 'Đánh giá nội dung Trung Quốc: Bộ dữ liệu mở truy cập và các yếu tố khác nhau', 'bg': 'Китайска оценка на съдържанието: набор от данни и функции с отворен достъп на различни нива на сегментация', 'da': 'Kinesisk indhold scoring: Open Access datasæt og funktioner på forskellige segmenteringsniveauer', 'nl': 'Chinese content scoren: Open-access datasets en functies op verschillende segmentatieniveaus', 'hr': 'Kineski rezultat sadržaja: Datati otvorenog pristupa i karakteristike na različitim razinama segmentacije', 'ko': '중국어 콘텐츠 평점: 다양한 수준의 오픈 액세스 데이터 세트 및 기능', 'de': 'Chinesisches Content Scoring: Open-Access-Datensätze und Features auf verschiedenen Segmentierungsebenen', 'id': 'Puncakan Konten Cina: Dataset Akses Buka dan Feature pada Tingkat Segmentasi Berbeda', 'fa': 'Ш§Щ…ШӘЫҢШ§ШІ Щ…ШӯШӘЩҲШ§ЫҢ ЪҶЫҢЩҶЫҢ: ШҜШ§ШҜЩҮвҖҢЩҮШ§ЫҢ ШЁШ§ШІ-ШҜШіШӘШұШіЫҢ ЩҲ ЩҲЫҢЪҳЩҮвҖҢЩҮШ§ ШҜШұ ШіШ·Шӯ Ш¬ШҜШ§ЫҢЫҢ Щ…ШӘЩҒШ§ЩҲШӘ', 'sw': 'Uchunguzi wa Maudhui wa China: Mitandao ya Uhuru na Tamko kuhusu Viwango tofauti vya Ugaji', 'tr': 'Mazmunlar Çinçe', 'af': 'Name', 'sq': 'Zgjidhja e përmbajtjes kineze: Të dhënat me akses të hapur dhe funksionet në nivelet e ndryshme të segmentimit', 'am': 'የቻይንኛ ደረጃዎች', 'hy': 'Չինաստանի պարունակության գնահատականներ. բաց հասանելիության տվյալներ և հատկություններ տարբեր սեգրմացիայի մակարդակներում', 'az': 'Çincə Məzmun Qərcləyici: Açıq-Erişim Məlumatı və Müxtəlif Segmentasyon Səviyyələri', 'bn': 'চীনা বিষয়বস্তু স্কোরিং: বিভিন্ন বিভিন্ন বিভিন্ন সংক্রান্ত তথ্যের স্থানে খোলা ও বৈশিষ্ট্য', 'bs': 'Kineski rezultat sadržaja: Datati otvorenog pristupa i karakteristike na različitim nivoima segmentacije', 'ca': 'Chinese Content Scoring: Open-Access Datasets and Features on Different Segmentation Levels', 'cs': 'Čínské hodnocení obsahu: Datové sady a funkce s otevřeným přístupem na různých úrovních segmentace', 'et': 'Hiina sisu hindamine: avatud juurdepääsuga andmekogumid ja funktsioonid erinevatel segmenteerimistasanditel', 'fi': 'Kiinan sisällönpisteytys: Open Access datasetit ja ominaisuudet eri segmentointitasoilla', 'jv': 'string" in "context_BAR_stringLink', 'ha': 'KCharselect unicode block name', 'sk': 'Kitajsko ocenjevanje vsebin: nabori podatkov in funkcije odprtega dostopa na različnih ravneh segmentacije', 'bo': 'ནང་དོན་རྒྱ་ནག་གི་ནང་དོན་སྟངས་སྟངས: Open-Access Datasets and Features on Different Segmentation Levels', 'he': 'תוצאות התוכן הסיני: קבוצות נתונים ובתכונות גישה פתוחה ברמות Segmentation שונות'}
{'en': 'In this paper, we analyse the challenges of Chinese content scoring in comparison to  English . As a review of prior work for  Chinese content scoring  shows a lack of  open-access data  in the field, we present two short-answer data sets for  Chinese . The Chinese Educational Short Answers data set (CESA) contains 1800 student answers for five science-related questions. As a second  data set , we collected ASAP-ZH with 942 answers by re-using three existing prompts from the ASAP data set. We adapt a state-of-the-art content scoring system for  Chinese  and evaluate it in several settings on these  data sets . Results show that  features  on lower segmentation levels such as character n-grams tend to have better performance than  features  on token level.', 'ar': 'في هذه الورقة ، نقوم بتحليل تحديات تسجيل المحتوى الصيني مقارنة باللغة الإنجليزية. نظرًا لأن مراجعة العمل السابق لتسجيل درجات المحتوى الصيني يُظهر نقصًا في بيانات الوصول المفتوح في هذا المجال ، فإننا نقدم مجموعتين من بيانات الإجابات القصيرة للغة الصينية. تحتوي مجموعة بيانات الإجابات القصيرة التعليمية الصينية (CESA) على 1800 إجابة للطلاب لخمسة أسئلة متعلقة بالعلوم. كمجموعة بيانات ثانية ، قمنا بجمع ASAP-ZH مع 942 إجابة عن طريق إعادة استخدام ثلاث مطالبات حالية من مجموعة بيانات ASAP. نقوم بتكييف نظام تسجيل محتوى حديث للغة الصينية وتقييمه في العديد من الإعدادات على مجموعات البيانات هذه. تظهر النتائج أن الميزات الموجودة على مستويات التجزئة المنخفضة مثل الأحرف n-grams تميل إلى الحصول على أداء أفضل من الميزات الموجودة على مستوى الرمز المميز.', 'es': 'En este artículo, analizamos los desafíos de la puntuación de contenido chino en comparación con el inglés. Como una revisión del trabajo anterior para la puntuación de contenido chino muestra una falta de datos de acceso abierto sobre el terreno, presentamos dos conjuntos de datos de respuestas cortas para chino. El conjunto de datos Chinese Educational Short Answers (CESA) contiene 1800 respuestas de los estudiantes para cinco preguntas relacionadas con la ciencia. Como segundo conjunto de datos, recopilamos ASAP-ZH con 942 respuestas reutilizando tres solicitudes existentes del conjunto de datos ASAP. Adaptamos un sistema de puntuación de contenido de última generación para chino y lo evaluamos en varios entornos en estos conjuntos de datos. Los resultados muestran que las funciones en niveles de segmentación más bajos, como los n-gramas de caracteres, tienden a tener un mejor rendimiento que las funciones a nivel de token.', 'fr': "Dans cet article, nous analysons les défis de la notation du contenu chinois par rapport à l'anglais. Comme un examen des travaux antérieurs pour la notation du contenu chinois révèle un manque de données en libre accès sur le terrain, nous présentons deux ensembles de données à réponse courte pour le chinois. L'ensemble de données Chinese Educational Short Answers (CESA) contient 1800 réponses d'étudiants pour cinq questions liées à la science. Comme deuxième ensemble de données, nous avons collecté ASAP-ZH avec 942 réponses en réutilisant trois invites existantes de l'ensemble de données ASAP. Nous adaptons un système de notation de contenu de pointe pour le chinois et l'évaluons dans plusieurs paramètres sur ces ensembles de données. Les résultats montrent que les entités à des niveaux de segmentation inférieurs, telles que les n-grammes de caractères, ont tendance à avoir de meilleures performances que les entités au niveau des jetons.", 'pt': 'Neste artigo, analisamos os desafios da pontuação do conteúdo chinês em comparação com o inglês. Como uma revisão de trabalhos anteriores para pontuação de conteúdo em chinês mostra a falta de dados de acesso aberto em campo, apresentamos dois conjuntos de dados de resposta curta para chinês. O conjunto de dados Chinese Educational Short Answers (CESA) contém 1.800 respostas de alunos para cinco perguntas relacionadas à ciência. Como um segundo conjunto de dados, coletamos ASAP-ZH com 942 respostas reutilizando três prompts existentes do conjunto de dados ASAP. Adaptamos um sistema de pontuação de conteúdo de última geração para chinês e o avaliamos em várias configurações nesses conjuntos de dados. Os resultados mostram que recursos em níveis de segmentação mais baixos, como n-grams de caracteres, tendem a ter melhor desempenho do que recursos em nível de token.', 'ja': '本稿では，英語と比較した中国語コンテンツスコアリングの課題を分析する．中国のコンテンツスコアリングの先行研究のレビューでは、現場でのオープンアクセスデータの欠如が示されているため、中国人向けの2つの短い回答データセットを提示します。中国教育短答データセット（ CESA ）には、5つの科学関連の質問に対する1800人の学生の回答が含まれています。第２のデータセットとして、ＡＳＡＰデータセットからの既存の３つのプロンプトを再利用して、９ ４ ２の回答を有するＡＳＡＰ － Ｚ Ｈを収集した。私たちは、中国人のための最先端のコンテンツスコアリングシステムを適応させ、これらのデータセットのいくつかの設定でそれを評価します。結果は、文字nグラムなどの低いセグメンテーションレベルの機能は、トークンレベルの機能よりも優れたパフォーマンスを有する傾向があることを示しています。', 'zh': '于本文中,析比英语,中文评分挑战。 顾前中文评分事,见领地乏开获取数据,发二中文简答数集。 中文教简答题数据集(CESA)含1800名学生对五科学。 第二数集,因ASAP数集三见提示,收ASAP-ZH942答案。 凡刺中文最先进者评分系统,并于集数多置中评估。 结果表明下分级(如字符 n-gram)上比令牌往往有善性。', 'hi': 'इस पेपर में, हम अंग्रेजी की तुलना में चीनी सामग्री स्कोरिंग की चुनौतियों का विश्लेषण करते हैं। चीनी सामग्री स्कोरिंग के लिए पूर्व कार्य की समीक्षा के रूप में क्षेत्र में ओपन-एक्सेस डेटा की कमी दिखाती है, हम चीनी के लिए दो लघु-उत्तर डेटा सेट प्रस्तुत करते हैं। चीनी शैक्षिक लघु उत्तर डेटा सेट (सीईएसए) में विज्ञान से संबंधित पांच प्रश्नों के लिए 1800 छात्र उत्तर शामिल हैं। एक दूसरे डेटा सेट के रूप में, हमने ASAP डेटा सेट से तीन मौजूदा संकेतों का पुन: उपयोग करके 942 उत्तरों के साथ ASAP-ZH एकत्र किया। हम चीनी के लिए एक अत्याधुनिक सामग्री स्कोरिंग सिस्टम को अनुकूलित करते हैं और इन डेटा सेटों पर कई सेटिंग्स में इसका मूल्यांकन करते हैं। परिणाम बताते हैं कि चरित्र एन-ग्राम जैसे कम विभाजन स्तरों पर सुविधाओं में टोकन स्तर पर सुविधाओं की तुलना में बेहतर प्रदर्शन होता है।', 'ga': 'Sa pháipéar seo, déanaimid anailís ar na dúshláin a bhaineann le scóráil ábhar na Síne i gcomparáid leis an mBéarla. Ós rud é go léiríonn athbhreithniú ar obair roimh ré maidir le scóráil ábhar Síneach go bhfuil easpa sonraí rochtana oscailte sa réimse, cuirimid i láthair dhá thacar sonraí gearrfhreagartha do na Síne. Tá 1800 freagra daltaí ar chúig cheist a bhaineann leis an eolaíocht i dtacar sonraí Freagraí Gearra Oideachais na Síne (CESA). Mar dhara tacar sonraí, bhailigh muid ASAP-ZH le 942 freagra trí thrí leid reatha ó thacar sonraí ASAP a athúsáid. Déanaimid córas scórála ábhar den scoth a oiriúnú do na Síne agus déanaimid é a mheas i roinnt suíomhanna ar na tacair sonraí seo. Léiríonn torthaí gur gnách go mbíonn feidhmíocht níos fearr ag gnéithe ar leibhéil deighilte níos ísle cosúil le carachtar n-gram ná mar a bhíonn ag gnéithe ar an leibhéal comhartha.', 'ru': 'В данной работе мы анализируем проблемы оценки китайского контента в сравнении с английским. Поскольку обзор предыдущей работы по оценке китайского контента показывает отсутствие данных открытого доступа в этой области, мы представляем два набора данных с короткими ответами для китайского языка. Китайский набор коротких образовательных ответов (CESA) содержит 1800 ответов студентов на пять вопросов, связанных с наукой. В качестве второго набора данных мы собрали ASAP-ZH с 942 ответами путем повторного использования трех существующих подсказок из набора данных ASAP. Мы адаптируем современную систему оценки контента для китайцев и оцениваем ее в нескольких настройках на этих наборах данных. Результаты показывают, что функции на более низких уровнях сегментации, такие как символьные n-граммы, как правило, имеют лучшую производительность, чем функции на уровне токенов.', 'hu': 'Ebben a tanulmányban elemezzük a kínai tartalom pontozásának kihívásait az angol nyelvhez képest. Mivel a kínai tartalom pontszámozásával kapcsolatos korábbi munkák áttekintése azt mutatja, hogy a terepen nincsenek nyílt hozzáférésű adatok, két rövid választ mutatunk be a kínai adatokra. A Kínai Oktatási Rövid Válaszok Adatkészlet (CESA) 1800 hallgatói választ tartalmaz öt tudományos kérdésre. Második adatkészletként 942 választ gyűjtöttünk össze az ASAP-ZH adatkészletből származó három meglévő utasítás újrafelhasználásával. Kiigazítjuk a kínai tartalom korszerű pontszámítási rendszerét, és ezeken az adatkészleteken több beállításban értékeljük. Az eredmények azt mutatják, hogy az alacsonyabb szegmentációs szinteken lévő funkciók, mint például a karakter n-grammok, általában jobb teljesítményt nyújtanak, mint a token szintű funkciók.', 'el': 'Στην παρούσα εργασία αναλύουμε τις προκλήσεις της βαθμολογίας κινεζικού περιεχομένου σε σύγκριση με τα αγγλικά. Καθώς μια ανασκόπηση προηγούμενων εργασιών για την αξιολόγηση κινεζικού περιεχομένου δείχνει έλλειψη δεδομένων ανοικτής πρόσβασης στον τομέα, παρουσιάζουμε δύο σύνολα δεδομένων σύντομης απάντησης για τα κινεζικά. Το σύνολο δεδομένων για τις κινεζικές εκπαιδευτικές σύντομες απαντήσεις (CESA) περιέχει 1800-απαντήσεις φοιτητών για πέντε επιστημονικές ερωτήσεις. Ως δεύτερο σύνολο δεδομένων, συλλέξαμε τις απαντήσεις 942 επαναχρησιμοποίησης τριών υπαρχόντων προτάσεων από το σύνολο δεδομένων. Προσαρμόζει ένα υπερσύγχρονο σύστημα βαθμολογίας περιεχομένου για τα κινέζικα και το αξιολογεί σε διάφορες ρυθμίσεις σε αυτά τα σύνολα δεδομένων. Τα αποτελέσματα δείχνουν ότι χαρακτηριστικά σε χαμηλότερα επίπεδα τμηματοποίησης, όπως τα γραμμάτια χαρακτήρων τείνουν να έχουν καλύτερη απόδοση από τα χαρακτηριστικά σε επίπεδο συμβολαίων.', 'ka': 'ჩვენ ამ დოკუნეში ჩინეთი შემდგომარების გამოცდილებების ანალიზება, რომლებიც ინგლისური შემდგომარებით. როგორც წინა სამუშაო სამუშაო შესახებ ჩინეთების შესახებ მონაცემების არსებობა სამუშაოში, ჩვენ ჩინეთებისთვის ორი ნაკლები სამუშაო მონაცემების შე ჩინეთი განსწავლებელი კიდევ პარამეტრების მონაცემები (CESA) მონაცემების შესახებ 1800 სტუდენტის პასუხი ხუთი მეცნიერებელი კითხვებისთვის. როგორც მეორე მონაცემების კონფიგურაცია, ჩვენ ASAP-ZH-ს 942 პასუხით შევყენეთ, რომ ASAP მონაცემების კონფიგურაციის სამი მხოლოდ გამოყენება. ჩვენ ჩინეთებისთვის სურათის მდგომარეობის სურათის სისტემის აეპორტირებით და გავამუშავოთ ამ მონაცემების სურათში რამდენიმე პარამეტრებში. შედეგი გამოჩვენება, რომ ფუნქციები ცოტა სექმენტის დრამში, როგორც n- დრამში სიმბოლოების უფრო მუშაობა, ვიდრე სიმბოლოების დრამში.', 'kk': 'Бұл қағазда, Қытай мазмұнын ағылшын тіліне салыстыру үшін талдап көреміз. Қытай мазмұның алдыңғы жұмысын қарау үшін өрісте ашық қатынау деректері жоқ дегенді көрсетеді. Біз қытайша екі қысқа жауап деректер жиынын көрсетедік. Қытай білім беру қысқа жауаптарды (CESA) баптауында 1800 студенттің бес ғылым сұрақтарының жауаптары бар. Екінші деректер жинағында ASAP- ZH жауаптарын 942 жауап беріп ASAP деректер жинағынан үш сұрақ қайта қолданып алдық. Біз қытайша мазмұның күйін қолданып, оны бұл деректер жиындарындағы бірнеше параметрлерде оқиға аламыз. Нәтижелер n- граммдар сипаттамасының төменгі сегментациялық деңгейіндегі мүмкіндіктері белгілер деңгейіндегі мүмкіндіктерден артық болып тұрады.', 'it': "In questo articolo analizziamo le sfide del punteggio dei contenuti cinesi rispetto all'inglese. Poiché una revisione del precedente lavoro per il punteggio dei contenuti cinesi mostra una mancanza di dati ad accesso aperto sul campo, presentiamo due set di dati a risposta breve per il cinese. Il set di dati Chinese Educational Short Answers (CESA) contiene 1800 risposte agli studenti per cinque domande scientifiche. Come secondo set di dati, abbiamo raccolto ASAP-ZH con 942 risposte riutilizzando tre prompt esistenti dal set di dati ASAP. Adattiamo un sistema di punteggio dei contenuti all'avanguardia per il cinese e lo valutiamo in diverse impostazioni su questi set di dati. I risultati mostrano che le funzionalità a livelli di segmentazione più bassi come i caratteri n-grammi tendono ad avere prestazioni migliori rispetto alle funzionalità a livello di token.", 'lt': 'Šiame dokumente analizuojame Kinijos turinio vertinimo iššūkius, palyginti su anglų kalba. Kadangi išankstinio Kinijos turinio vertinimo darbo apžvalga rodo, kad šioje srityje trūksta atviros prieigos duomenų, pateiksime du trumpalaikius Kinijos duomenų rinkinius. Kinijos švietimo trumpųjų atsakymų duomenų rinkinyje (CESA) yra 1800 student ų atsakymų į penkis su mokslu susijusius klausimus. Kaip antrasis duomenų rinkinys surinkėme ASAP-ZH su 942 atsakymais pakartotinai naudojant tris esamus ASAP duomenų rinkinį. Mes pritaikome naujausią Kinijos turinio vertinimo sistemą ir vertiname ją keliose šių duomenų rinkinių settings. Rezultatai rodo, kad mažesnio segmentacijos lygio požymiai, pvz., n gramai, paprastai turi geresnių rezultatų nei požymių lygio požymiai.', 'mk': 'Во овој весник ги анализираме предизвиците на оценувањето на кинеската содржина во споредба со англискиот. Како преглед на претходната работа за оценка на кинеската содржина покажува недостаток на податоци за отворен пристап во полето, претставуваме два набори на податоци за кратки одговори за кинеските. Кинескиот набор на податоци за кратки одговори на образованието (ЦЕСА) содржи 1800 одговори на студентите за пет прашања поврзани со науката. Како втор набор на податоци, собравме ASAP-ZH со 942 одговори со повторно употреба на три постоечки барања од наборот на податоци ASAP. We adapt a state-of-the-art content scoring system for Chinese and evaluate it in several settings on these data sets.  Резултатите покажуваат дека карактеристиките на пониските нивоа на сегментација, како што е знакот n-грам, имаат подобра резултатност од карактеристиките на нивото на симболи.', 'ms': 'Dalam kertas ini, kami menganalisis cabaran nilai Cina dalam perbandingan dengan bahasa Inggeris. Sebagai ulasan kerja terdahulu untuk skor kandungan Cina menunjukkan kekurangan data akses terbuka dalam medan, kami memperkenalkan dua set data jawapan pendek untuk Cina. Set data Jawapan pendek Pendidikan Cina (CESA) mengandungi 1800 jawapan pelajar untuk lima soalan berkaitan sains. Sebagai set data kedua, kami mengumpulkan ASAP-ZH dengan 942 jawapan dengan menggunakan semula tiga maklum yang wujud dari set data ASAP. Kami menyesuaikan sistem skor kandungan state-of-the-art untuk Cina dan menilainya dalam beberapa tetapan pada set data ini. Hasil menunjukkan bahawa ciri-ciri pada aras segmentasi lebih rendah seperti n-gram aksara cenderung mempunyai prestasi yang lebih baik daripada ciri-ciri pada aras token.', 'mt': 'F’dan id-dokument, nagħmlu analiżi tal-isfidi tal-punteġġ tal-kontenut Ċiniż meta mqabbel mal-Ingliż. As a review of prior work for Chinese content scoring shows a lack of open-access data in the field, we present two short-answer data sets for Chinese.  Is-sett tad-dejta Ċiniż dwar Tweġibiet Edukattivi Qasira (CESA) fih 1800 tweġiba għall-istudenti għal ħames mistoqsijiet relatati max-xjenza. Bħala t-tieni sett ta’ dejta, inġabru ASAP-ZH b’942 tweġiba billi ntużaw mill-ġdid tliet sinjali eżistenti mis-sett ta’ dejta ASAP. Aġġustaw sistema ta’ punteġġ tal-kontenut l-aktar avvanzata għa ċ-Ċiniżi u jevalwawha f’diversi settijiet fuq dawn is-settijiet ta’ dejta. Ir-riżultati juru li karatteristiċi fuq livelli aktar baxxi ta’ segmentazzjoni bħall-karattru n-grammi għandhom it-tendenza li jkollhom prestazzjoni aħjar mill-karatteristiċi fuq livell ta’ token.', 'ml': 'ഈ പത്രത്തില്\u200d, ഇംഗ്ലീഷിലേക്ക് തുല്യമായി ചൈനീസ് ഉള്ളടക്കം ചോദ്യങ്ങളുടെ വിലപാടുകള്\u200d നമ്മള്\u200d അന്വേഷി ചൈനീസ് ഉള്ളടക്കം സ്കോരിങ്ങിന് മുമ്പുള്ള ജോലിയുടെ ഒരു പരിശോധന പ്രദര്\u200dശിപ്പിക്കുന്നതിനാല്\u200d പ്രദേശത്തില്\u200d തുറന്ന വിവ ചൈനീസ് വിദ്യാഭ്യാസ വിദ്യാഭ്യാസത്തിന്റെ ചെറുതായ വിവരങ്ങളുടെ സജ്ജീകരണം (CESA) അഞ്ചു ശാസ്ത്ര വിദ്യാര്\u200dത് രണ്ടാമത്തെ ഡേറ്റാ സെറ്റ് ആയി ഞങ്ങള്\u200d ASAP-ZH ഉത്തരങ്ങള്\u200d 942 ഉത്തരം കൊണ്ട് ശേഖരിച്ചു. ASAP ഡേറ്റാ സജ്ജീകരണത്തില്\u200d നിന്നും മ ചൈനീസിന്റെ സ്കോര്\u200dട്ട് സംവിധാനത്തിനുള്ള സ്റ്റേറ്റ് സ്റ്റേറ്റ് സംവിധാനം ഞങ്ങള്\u200d ചേര്\u200dക്കുന്നു. ഈ ഡേറ്റ ഫലങ്ങള്\u200d കാണിക്കുന്നുണ്ടെങ്കില്\u200d ടോങ്ക് നിലയില്\u200d നിന്നും കൂടുതല്\u200d ചിഹ്നങ്ങള്\u200d കൂടുതല്\u200d നല്ല പ്രവര്\u200dത്തനവുമുണ്ടെന്ന്.', 'mn': 'Энэ цаасан дээр бид Хятадын тодорхойлолтын асуудлыг Англи хэлнээс харьцуулахад шинжилгээ хийдэг. Хятадын агууллагуудын хувьд өмнөх ажлын шинжлэх ухааны хувьд бид хоёр богино хариултын өгөгдлийг Хятадын хувьд харуулж байна. Хятад боловсролын богино хариулт өгөгдлийн сангууд (CESA) нь 1800 оюутнуудын таван шинжлэх ухааны асуултуудад хариулт өгдөг. Хоёр дахь өгөгдлийн хэмжээний хувьд бид ASAP-ZH өгөгдлийн хэмжээгээс гурван хурдан ашиглаж 942 хариулттай цуглуулсан. Бид Хятадын хувьд урлагийн бүтээгдэхүүний тохиолдлын системийг загварчлаад эдгээр өгөгдлийн хэмжээсүүд дээр олон тохиолддог. Үүний үр дүнд n-грамм гэх мэт загварын бага хэмжээнд харагдаж байгаа нь тэмдэгтийн хэмжээгээс илүү сайн үйл ажиллагаатай байдаг.', 'no': 'I denne papiret analyserer vi utfordringane til kinesisk innhald som skal gå sammenlignet med engelsk. Som ei gjennomgang av førre arbeid for kinesisk innhaldsskoring viser at det ikkje er tilgang til opna data i feltet, viser vi to kort svardatasett for kinesisk. Den kinesiske opplæringskorte svara (CESA) inneheld 1800 studentsvar for fem vitenskapelige spørsmål. Som eit andre datasett samla vi ASAP-ZH med 942 svar ved å gjenoppretta tre eksisterande prompt frå ASAP-datasettet. Vi tilpassar eit innhaldsscoring av kunsten for kinesisk og evaluerer det i fleire innstillingar på desse datasettene. Resultater viser at funksjonar på lågare segmenteringsnivå, som teikn n- gramer, har bedre funksjonar enn funksjonar på teiknenivå.', 'pl': 'W niniejszym artykule analizujemy wyzwania związane z oceną treści chińskich w porównaniu z językiem angielskim. Ponieważ przegląd wcześniejszych prac dotyczących oceny treści chińskich pokazuje brak danych otwartego dostępu w terenie, przedstawiamy dwa zestawy danych krótkich odpowiedzi dla chińskich. Chiński zestaw danych dotyczących krótkich odpowiedzi edukacyjnych (CESA) zawiera 1800-odpowiedzi studentów na pięć pytań związanych z nauką. Jako drugi zestaw danych zebraliśmy ASAP-ZH z odpowiedziami 942, ponownie wykorzystując trzy istniejące pytania z zestawu danych ASAP. Dostosowujemy najnowocześniejszy system oceny treści dla chińskich i oceniamy go w kilku ustawieniach na tych zbiorach danych. Wyniki pokazują, że funkcje na niższych poziomach segmentacji, takie jak n-gramy znaków, mają tendencję do lepszej wydajności niż funkcje na poziomie tokenów.', 'ro': 'În această lucrare, analizăm provocările scorului conținutului chinez în comparație cu limba engleză. Deoarece o revizuire a activităților anterioare pentru scorarea conținutului chinez arată o lipsă de date cu acces liber în domeniu, prezentăm două seturi de date cu răspunsuri scurte pentru chineză. Setul de date pentru răspunsuri scurte educaționale chinezești (CESA) conține 1800 de răspunsuri studențești pentru cinci întrebări legate de știință. Ca al doilea set de date, am colectat ASAP-ZH cu 942 de răspunsuri prin reutilizarea a trei solicitări existente din setul de date ASAP. Adaptăm un sistem de scorare a conținutului de ultimă generație pentru chineză și îl evaluăm în mai multe setări pe aceste seturi de date. Rezultatele arată că caracteristicile la niveluri mai mici de segmentare, cum ar fi caracterele n-grame tind să aibă performanțe mai bune decât caracteristicile la nivel de token.', 'sr': 'U ovom papiru analiziramo izazove kineskog sadržaja u usporedbi sa engleskim. Kao pregled prethodnog rada za kineski izvlačenje sadržaja pokazuje nedostatak podataka otvorenog pristupa na terenu, predstavljamo dva seta podataka za kineske kratkoodgovore. Kineski skup podataka za kratke odgovore (CESA) sadrži 1800 studentskih odgovora na pet pitanja vezanih za nauku. Kao druga set a podataka, sakupljali smo ASAP-ZH sa 942 odgovora ponovno korištenjem tri postojeća brzina iz seta podataka ASAP-a. Mi prilagodimo sistem izviđanja stanja umjetnosti za kineske i procjenjujemo ga u nekoliko postavljanja na ovim setima podataka. Rezultati pokazuju da karakteristike na nižim nivoima segmentacije poput n-grama imaju bolju funkciju nego karakteristike na nivou tokena.', 'sv': 'I den här uppsatsen analyserar vi utmaningarna med kinesiskt content scoring jämfört med engelska. Eftersom en genomgång av tidigare arbete med kinesisk innehållsvärdering visar att det saknas open access data på fältet presenterar vi två kortvariga datauppsättningar för kinesiskt innehåll. CESA innehåller 1800 studentsvar för fem vetenskapliga frågor. Som en andra datauppsättning samlade vi in ASAP-ZH med 942 svar genom att återanvända tre befintliga uppmaningar från ASAP-datauppsättningen. Vi anpassar ett toppmodernt innehållspoängsystem för kinesiska och utvärderar det i flera inställningar på dessa datauppsättningar. Resultaten visar att funktioner på lägre segmenteringsnivåer som tecken n-gram tenderar att ha bättre prestanda än funktioner på token-nivå.', 'so': 'Warqadan waxaynu ku baaraynaa dhibaatooyinka waxyaabaha ku jira Shiino ee isbarbardhigga Ingiriiska. Ka baaraandegista shaqada hore ee koontarooyinka kooxaha Shiino waxey ka muuqataa baahida macluumaadka furan ee duurka, waxaynu u keenaynaa laba kooban macluumaad oo jawaabta gaaban ee Shiino. The Chinese Educational Short Answers data set (CESA) contains 1800 student answers for five science-related questions.  Sida saxda labaad ee macluumaadka, waxaynu soo urursanay ASAP-ZH oo 942 jawaabayaal ugu soo celinay saddex degdeg oo ka soo baxsan saxda data ee ASAP. Waxaynu ku habboonaynaa nidaamka kooxaha farshaxanka ee Shiino, waxaana ku qiimeynaynaa xarumo badan oo ku qoran sawiradan. Xiriimaha waxaa laga muujiyaa in heerarka ka hooseeya, sida xarafka n-gram waa mid ka fiican tababaro heerka calaamada.', 'si': 'මේ පත්තරේ අපි චීනි සාමාන්ත්\u200dරයේ අවශ්\u200dය විශ්ලේෂණය කරනවා ඉංග්\u200dරීසිය සමඟ විස්තර කරන්න. චීනි සාමාන්\u200dය ස්කෝරින්ගේ ප්\u200dරධාන වැඩක් පරීක්ෂණය විදිහට පෙන්වන්න පුළුවන් විදිහට පරීක්ෂණයෙන් පෙන්වන චීනි ශිෂ්\u200dය ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණ පහත් විද්\u200dයාණ ප්\u200dරශ්ණ ප දෙවෙනි දත්ත සැට් විදියට, අපි ASAP-ZH එක්ක 942 ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරයෙන් ආයෙත් භාවිත කරන්න ASAP-ZH දත්ත සැටිය අපි චීනියාව ස්කෝරින් පද්ධතියක් ස්ථානයක් සමාවිත කරනවා ඒ වගේම මේ දත්ත සැට් වලින් සැකසුම් වලින් ඒක ප්\u200dරතිචාරය පෙන්වන්න පුළුවන් විශේෂතා පහළ සැකසුම් ස්ථානයේ අක්ෂර n- ග්\u200dරෑම් වලින් ප්\u200dරතිචාරය ට', 'ta': 'இந்த காகிதத்தில், நாம் சீனம் உள்ளடக்கத்தின் சவால்பங்களை பார்ப்போம் ஆங்கிலத்திற்கு ஒப்பிடுவதாக சீனா உள்ளடக்கத்திற்கான முன்னோட்ட வேலைக்கான முன்னோட்டம் பரிசோதிக்கும் புலத்தில் திறந்த துவிடும் தகவல் குறைவாக இருக The Chinese Educational Short Answers data set (CESA) contains 1800 student answers for five science-related questions.  இரண்டாவது தரவு அமைப்பாக, நாங்கள் ASAP-ZH 942 விடைகளைக் கொண்டு 942 விடைகளை மீண்டும் பயன்படுத்தி மூன்று இருக்கும் விதிகளை ம நாம் சீனாவிற்கு ஒரு நிலையில் கலை உள்ளடக்கத்தின் மதிப்பெண் அமைப்பை ஒப்பிடுகிறோம் மற்றும் இந்த தகவல் அமைப்புகளில முடிவு', 'ur': 'اس کاغذ میں ہم چینی منصوبات کی چالوں کو انگلیسی کے مقابلہ میں تحقیق کرتے ہیں۔ چین کے منصوبات اسکورینگ کے لئے پہلے کے کام کی روشنی کے طور پر فیلڈ میں کھولنے والی دسترسی ڈیٹے کی ناکامی دکھاتی ہے، ہم چین کے لئے دو چھٹی جواب دینے والی ڈیٹ سٹ پیش کرتے ہیں. چین کی تحصیل کوٹی پارچ پارچ سؤال کے لئے 1800 طالب جواب ملتی ہے۔ دوسری ڈیٹا سٹ کے طور پر ہم نے ASAP-ZH کو 942 جواب دے کر تین موجود پارپوٹ کو ASAP ڈیٹا سٹ سے دوبارہ استعمال کیا۔ ہم نے چین کے لئے ایک ایست-of-the-art content scoring سیستم کو اڈیٹ کر رکھا ہے اور اس کو ان ڈیٹ سٹوں پر بہت سی تنظیمات میں مطابق کریں۔ نتیجے دکھاتے ہیں کہ نیچے سقمیٹ سطح پر ویژگی ہیں جیسے کریٹر n-گرم ٹوکنے سطح پر ویژگی سے بہتر فعالیت رکھتے ہیں.', 'uz': 'Bu qogʻozda, biz ingliz tilida qiymati qiladigan Xitoycha tarkiblarining qiziqarishlarini aniqlamiz. @ info: whatsthis Name Ikkinchi maʼlumot tizimi sifatida, biz ASAP-ZH 942 javoblari bilan uchta mavjud soʻzni qayta ishlatish mumkin. Biz Xitoycha tarkibi holatini tahrirlash tizimini moslash va bu maʼlumot turlarida bir nechta moslamalarda qiymatmiz. @ info: whatsthis', 'vi': 'Trong tờ giấy này, chúng tôi phân tích thử thách về ghi chép nội dung Trung Quốc so với tiếng Anh. Để xem xét việc đánh giá nội dung của Trung Quốc cho thấy thiếu dữ liệu truy cập mở trong lĩnh vực, chúng tôi giới thiệu hai nhóm dữ liệu trả lời ngắn cho Trung Quốc. Bộ dữ liệu ngắn về Giáo dục Trung Quốc (ESA) chứa 1800 câu trả lời sinh viên cho năm câu hỏi liên quan đến khoa học. Chúng tôi thu thập ASAP-ZH với 92 trả lời bằng cách sử dụng lại ba lời nhắc từ bộ dữ liệu ASAP. Chúng tôi thích ứng một hệ thống đánh giá nội dung hiện đại cho Trung Quốc và đánh giá nó trong nhiều thiết lập trên các bộ dữ liệu này. Kết quả cho thấy các chức n ăng về phân chia thấp như ký tự n-gam thường có hiệu suất tốt hơn tính năng biểu tượng.', 'bg': 'В настоящата статия анализираме предизвикателствата на китайското съдържание в сравнение с английския език. Тъй като преглед на предишната работа за оценка на китайското съдържание показва липса на данни с отворен достъп в областта, ние представяме два набора данни с кратки отговори за китайски. Китайският набор от данни за кратки образователни отговори (ЦЕСА) съдържа 1800 отговора на студентите на пет въпроса, свързани с науката. Като втори набор от данни събрахме с 942 отговора чрез повторно използване на три съществуващи подкани от набора от данни. Ние адаптираме съвременна система за оценка на съдържанието за китайски език и я оценяваме в няколко настройки на тези набори от данни. Резултатите показват, че функциите на по-ниски нива на сегментация, като знак n-грама, са склонни да имат по-добра производителност от функциите на ниво символ.', 'nl': 'In dit artikel analyseren we de uitdagingen van Chinese content scoren in vergelijking met Engels. Omdat een overzicht van eerdere werkzaamheden voor Chinese contentscoren een gebrek aan open-access data in het veld aantoont, presenteren we twee short-respons datasets voor Chinees. De Chinese Educational Short Answers dataset (CESA) bevat 1800-antwoorden van studenten voor vijf wetenschapsgerelateerde vragen. Als tweede dataset verzamelden we ASAP-ZH met 942 antwoorden door drie bestaande prompts uit de ASAP dataset opnieuw te gebruiken. We passen een state-of-the-art content scoresysteem aan voor Chinees en evalueren dit in verschillende instellingen op deze datasets. De resultaten tonen aan dat functies op lagere segmentatieniveaus, zoals teken n-grammen, doorgaans betere prestaties hebben dan functies op tokenniveau.', 'da': 'I denne artikel analyserer vi udfordringerne ved at score kinesisk indhold i forhold til engelsk. Da en gennemgang af tidligere arbejde med kinesisk indhold scoring viser mangel på open access data i feltet, præsenterer vi to korte svar datasæt for kinesisk. Den kinesiske Educational Short Answers datasæt (CESA) indeholder 1800 studerende svar på fem videnskabelige spørgsmål. Som et andet datasæt indsamlede vi ASAP-ZH med 942 svar ved at genbruge tre eksisterende prompts fra ASAP datasættet. Vi tilpasser et avanceret indholdsstatiseringssystem til kinesisk og evaluerer det i flere indstillinger på disse datasæt. Resultaterne viser, at funktioner på lavere segmenteringsniveauer såsom tegn n-grams har en tendens til at have bedre ydeevne end funktioner på token niveau.', 'hr': 'U ovom papiru analiziramo izazove kineskog sadržaja u usporedbi s engleskim. Kao pregled prethodnog rada za kineski izvlačenje sadržaja pokazuje nedostatak podataka otvorenog pristupa na terenu, predstavljamo dva skupa podataka za kineske kratkoodgovore. Kineska skupina podataka za kratke odgovore na obrazovanje (CESA) sadrži 1800 studentskih odgovora na pet pitanja vezanih za nauku. Kao druga set a podataka, skupili smo ASAP-ZH s 942 odgovora ponovno koristeći tri postojeća brzina iz seta podataka ASAP-a. Prilagodili smo sistem izvještaja sadržaja umjetnosti za kineske i procjenjivali ga u nekoliko postavljanja na ovim podacima. Rezultati pokazuju da karakteristike na nižim nivoima segmentacije poput n-grama imaju bolju funkciju nego karakteristike na nivou tokena.', 'de': 'In diesem Beitrag analysieren wir die Herausforderungen des chinesischen Content Scoring im Vergleich zu Englisch. Da eine Überprüfung früherer Arbeiten zum chinesischen Content Scoring einen Mangel an Open-Access-Daten im Feld zeigt, stellen wir zwei Kurzantwortdatensätze für Chinesisch vor. Der Chinese Educational Short Answers Datensatz (CESA) enthält 1800-Schülerantworten für fünf wissenschaftsbezogene Fragen. Als zweiten Datensatz haben wir ASAP-ZH mit 942 Antworten gesammelt, indem wir drei vorhandene Eingabeaufforderungen aus dem ASAP Datensatz wiederverwenden. Wir passen ein hochmodernes Content Scoring System für Chinesisch an und werten es in mehreren Einstellungen auf diesen Datensätzen aus. Die Ergebnisse zeigen, dass Features auf niedrigeren Segmentierungsebenen, wie z. B. Zeichen-n-Gramm, tendenziell eine bessere Leistung aufweisen als Features auf Tokenebene.', 'id': 'In this paper, we analyse the challenges of Chinese content scoring in comparison to English.  Sebagai penelitian dari pekerjaan sebelumnya untuk skor konten Cina menunjukkan kekurangan data akses terbuka di lapangan, kami mempersembahkan dua set data jawaban pendek untuk Cina. Set data Jawaban pendek Pendidikan Cina (CESA) mengandung 1800 jawaban murid untuk lima pertanyaan berkaitan dengan ilmu pengetahuan. Sebagai set data kedua, kami mengumpulkan ASAP-ZH dengan 942 jawaban dengan menggunakan ulang tiga prompt yang ada dari set data ASAP. Kami mengadaptasi sistem skor konten terbaik untuk Cina dan mengevaluasinya dalam beberapa pengaturan pada set data ini. Hasil menunjukkan bahwa fitur pada tingkat segmentasi lebih rendah seperti karakter n-gram cenderung memiliki prestasi yang lebih baik daripada fitur pada tingkat token.', 'ko': '본고에서 우리는 중국어 내용 평점과 영문 내용 평점에 비해 직면한 도전을 분석했다.이전의 중국어 내용 평가 업무에 대한 회고에 의하면 이 분야는 개방적인 데이터 획득이 부족하기 때문에 우리는 두 개의 중국어 간단한 답안 데이터 집합을 제공했다.중국 교육단답 데이터세트(CESA)에는 과학 관련 5개의 질문에 대한 1천800개의 학생 답안이 담겼다.두 번째 데이터 세트인 ASAP 데이터 세트의 기존 프롬프트 3개를 재사용해 942개의 답을 모은 ASAP-ZH입니다.우리는 가장 선진적인 중국어 내용 평가 시스템을 채택했고 이 데이터 집합의 여러 설정에서 이를 평가했다.그 결과 낮은 분할 단계의 특징(예를 들어 문자 n-gram)은 표기 단계의 특징보다 성능이 좋은 것으로 나타났다.', 'fa': 'در این کاغذ، ما چالش های محتوای چینی را در مقایسه با انگلیسی تحلیل می کنیم. به عنوان تحقیقات کارهای قبلی برای تحقیقات محتوای چینی نشان می دهد که کمبود داده های دسترسی باز در میدان، ما دو مجموعه داده کوتاه برای چینی را پیشنهاد می کنیم. مجموعه داده های کوتاه پاسخ های آموزشی چینی (CESA) ۱۸۰۰ پاسخ دانش آموزشی برای پنج سوال با علم وجود دارد. به عنوان یک مجموعه داده دوم، ما ASAP-ZH را با پاسخ 942 با استفاده از سه پیشنهاد موجود از مجموعه داده های ASAP جمع کردیم. ما یک سیستم تحقیقات محتوای هنری را برای چینی adapt می کنیم و در چند تنظیمات در این مجموعه داده ها ارزیابش می کنیم. نتیجه\u200cها نشان می\u200cدهند که ویژگی\u200cها در سطح جدایی پایین مانند شخصیت n گرم\u200cها عملکرد بهتر از ویژگی\u200cهای سطح علامت دارند.', 'sw': 'Katika karatasi hii, tunachambua changamoto za maudhui ya Kichina yanayochezea kulinganisha na Kiingereza. Kama tathmini ya kazi za awali kwa ajili ya kuchukuliwa kwa maudhui ya China inaonyesha ukosefu wa taarifa za wazi za upatikanaji katika uwanja, tunaweka seti mbili za majibu kwa Wachina. Mpango wa data fupi wa Elimu nchini China (CESA) una majibu 1800 ya wanafunzi kwa maswali matano yanayohusiana na sayansi. Kama seti ya takwimu ya pili, tulikusanya ASAP-ZH kwa majibu 942 kwa kutumia tena mara tatu zilizopo kutoka kwenye seti ya data ya ASAP. Tunaweza kubadilisha mfumo wa maudhui ya sanaa kwa Wachina na kutathmini katika mazingira kadhaa katika seti hizi za takwimu. Matokeo yanaonyesha kuwa vipande vya chini vya upigaji kura kama vile tabia n-gram huwa na utendaji bora kuliko vipengele vya alama.', 'tr': 'Bu kagyzda biz Çin çe mazmunlaryň iňlisçe karşılaşykda görä kynçylyklaryny çözýäris. Öňki Çin çe maglumaty üçin öňki işiň barlamasynda sahyda a çyk-jaýyn maglumatyň ýok bolmagyny görkezýär. Biz Çinçe üçin iki kiçiräk jogabat setirini görkezýäris. Çinçe Beýik Bilim maglumaty üçin 1800 okuwçy jogaplary bar. Ikinji maglumat seti bolup, ASAP maglumat setinden üç bolan prompt üçin 942 jogabyla ASAP-ZH bilen ýygnadyk Biz bir sanat sistemini Çin çe üçin taýýarlapdyr we muny şu data düzümlerinde bir näçe düzümlerde çykýarys. Netijeler, karakter n-gramlar ýaly segment derejesinde hatlaryň token derejesinden has gowy performansy bolmalydygyny görkezýär.', 'af': "In hierdie papier, ons analyseer die uitdagings van Sjinese inhoud wat in vergelyking met Engels vergelyk word. As 'n hersiening van voorheen werk vir Sjinese inhoud skoring vertoon 'n mislukking van oop-toegang data in die veld, vertoon ons twee kort-antwoord data stel vir Sjinees. Die Sjinese Edukasiese Kort Antwoordes data stel (CESA) bevat 1800 studente antwoordes vir vyf wetenskapelike vrae. As 'n tweede data stel, het ons ASAP- ZH versamel met 942 antwoorde deur drie bestaande prompte hergebruik van die ASAP data stel. Ons adapteer 'n staat-van-die-kuns inhoud skoring stelsel vir Sjinees en evalueer dit in verskeie instellings op hierdie data stelle. Resultate wys dat funksies op minder segmentasie vlakke soos karakter n- grams tendeer na het beter prestasie as funksies op token vlak.", 'sq': 'Në këtë letër, ne analizojmë sfidat e përmbajtjes kineze në krahasim me anglishtin. Si një përmbledhje e punës së mëparshme për shënimin e përmbajtjes kineze tregon një mungesë të të dhënave me akses të hapur në fushë, ne paraqesim dy grupe të të dhënave me përgjigje të shkurtër për kinezët. Grupi i të dhënave për përgjigjet e shkurtra arsimore kineze (CESA) përmban 1800 përgjigje student ësh për pesë pyetje lidhur me shkencën. Si një grup i dytë të dhënash, ne mbledhëm ASAP-ZH me 942 përgjigje duke përdorur përsëri tre kërkesa ekzistuese nga grupi i të dhënave ASAP. Ne përshtatemi një sistem të rendit të përmbajtjes për kinezët dhe e vlerësojmë në disa rregullime në këto grupe të dhënash. Rezultatet tregojnë se karakteristikat n ë nivelet më të ulta të segmentimit të tillë si karakteri n-gram kanë tendencë të kenë performancë më të mirë se karakteristikat në nivelin e token.', 'am': 'በዚህ ገጽ የቻይና የውይይት ነጥቦችን ከንግግሊዝኛ ጋር እናስተምር፡፡ የቀድሞው የቻይና ተቃውሞ ማድረግ ማሰናከል የቻይና ጥያቄ መክፈት የክፍት መረጃዎችን እንደሚያሳየው፣ ለቻይና ሁለት ትንሽ የመልስ ዳታ ማዘጋጀት እናቀርባለን፡፡ ቻይናውያን ትምህርት አጭራሽ ድምፅ (CESA) ለአምስት ሳይንቨር ጥያቄዎች የ1800 ተማሪዎችን መልስ አላቸው። ሁለተኛ ዳታ መስመር፣ ASAP-ZH በ942 መልስ ሰብሰብን ከASAP ዳታ ዘይት የተገኘውን ሦስት ደብዳቤዎችን በመለስ አቀረብን፡፡ የቻይናውያንን የ-የ-የ-የ-አርእስት አካባቢ ቁጥጥር እናስገድዳለን፡፡ Results show that features on lower segmentation levels such as character n-grams tend to have better performance than features on token level.', 'hy': 'Այս աշխատանքում մենք վերլուծում ենք չինական պարունակության մարտահրավերները՝ համեմատելով անգլերենը: Քանի որ չինական պարունակության գնահատման նախորդ աշխատանքի վերլուծումը ցույց է տալիս, որ այս ոլորտում բաց հասանելիության տվյալների բացակայությունը, մենք ներկայացնում ենք երկու կարճ պատասխաններ չինական համար: Չինաստանի կրթության կարճ պատասխանների տվյալների համակարգը (ESCA) պարունակում է 1800 ուսանողի պատասխաններ հինգ գիտության հարցերին: Երկրորդ տվյալների համակարգը մենք հավաքեցինք ASAP-ZH 942 պատասխաններով, վերամշակվելով երեք գոյություն ունեցող հարցեր ASAP տվյալների համակարգից: Մենք հարմարեցնում ենք Չինաստանի համար նորագույն պարունակության գնահատման համակարգը և գնահատում ենք այն այս տվյալների համակարգերի որոշ միջոցներում: Արդյունքները ցույց են տալիս, որ նվազեգրամման ցածր մակարդակների հատկությունները, ինչպիսիք են n-գրամը, հակված են ավելի լավ արդյունք ունենալ, քան նշանների մակարդակի հատկությունները:', 'bn': 'এই পত্রিকায় আমরা চীনা বিষয়বস্তুর চ্যালেঞ্জ বিশ্লেষণ করি ইংরেজীর তুলনায়। চীনা বিষয়বস্তু স্কোরের পূর্ববর্তী কাজের প্রতিবেদন হিসেবে আমরা চীনাদের জন্য দুটি সংক্ষিপ্ত তথ্যের অভাব উপস্থাপন করি। চীনা শিক্ষা সংক্ষিপ্ত তথ্য সেট (সিএসএ) আছে পাঁচ বিজ্ঞান সম্পর্কিত প্রশ্নের জন্য ১৮০০ ছাত্রের উত্তর। As a second data set, we collected ASAP-ZH with 942 answers by re-using three existing prompts from the ASAP data set.  আমরা চীনাদের জন্য একটি রাষ্ট্র-অফ-শিল্পের বিষয়বস্তু স্কোরিং সিস্টেম পরিবর্তন করি এবং এই তথ্য সেটে বেশ কয়েকটি বিশেষ ফলাফল দেখা যাচ্ছে যে নিম্নলিখিত স্তরের বৈশিষ্ট্যাবলীর বৈশিষ্ট্য, যেমন অক্ষর n-gram টোকার স্তরের বৈশিষ্ট্যের চেয়ে ভাল', 'az': 'Bu kağızda, İngilizce ilə qarşılaşdığı Çin məlumatının çətinliklərini analiz edirik. Çincə məlumatı müəyyən edilməsi üçün əvvəlki işlərin müəyyən edilməsi kimi sahədə a çıq əlaqəsi verilən məlumatı yoxdur, biz Çincə üçün iki qısa cavab verilən məlumatı qurğuları göstəririk. Çincə Eğitimli Qısa Cevaplar verilən məlumatlar qutusu (CESA) beş bilim haqqındakı sualları üçün 1800 öğrenci cavab verir. İkinci məlumat quruluğu kimi, ASAP veri quruluğundan üç məlumatı yenidən istifadə edərək 942 cavabı ilə ASAP-ZH topladıq. Biz Çincə məlumatı müəyyən etdiyimiz və bu məlumat qurğularının çoxlu qurğularında değerləşdiririk. Sonuçlar, n-gramlar kimi n-qramların düşük segmentasyon seviyyələrində fəaliyyətlərin token seviyyətindən daha yaxşı performans olmasın ı göstərir.', 'bs': 'U ovom papiru analiziramo izazove kineskog sadržaja u usporedbi s engleskim. Kao pregled prethodnog rada za kineski izvlačenje sadržaja pokazuje nedostatak podataka otvorenog pristupa na terenu, predstavljamo dva seta podataka za kineske kratkoodgovore. Kineski skup podataka za kratke odgovore na obrazovanje (CESA) sadrži 1800 studentskih odgovora na pet pitanja vezanih za nauku. Kao drugi set podataka, sakupljali smo ASAP-ZH sa 942 odgovora ponovno korištenjem tri postojeća brzina iz seta podataka ASAP-a. Mi prilagodimo sistem izvlačenja sadržaja umjetnosti za kineske i procjenjujemo ga u nekoliko postavljanja na ovim setima podataka. Rezultati pokazuju da karakteristike na nižim nivoima segmentacije poput n-grama imaju bolju funkciju nego karakteristike na nivou znakova.', 'ca': "En aquest article, analitzem els reptes de la puntuació del contingut xinès en comparació amb l'anglès. Com una revisió del treball anterior de puntuació de contingut xinès mostra la falta de dades d'accés obert en el camp, presentem dos conjunts de dades de resposta curta per a xinès. El conjunt de dades de respostes curtes d'educació xinesa (CESA) conté 1800 respostes d'estudiants per cinc preguntes relacionades amb la ciència. Com a segon conjunt de dades, vam recollir ASAP-ZH amb 942 respostes reutilitzant tres indicacions existents del conjunt de dades ASAP. Adaptem un sistema de puntuació de continguts més avançat per a xinès i l'evaluem en diverses configuracions d'aquests conjunts de dades. Els resultats mostren que les característiques en nivells de segmentació més baixos com el caràcter n-grams tendeixen a tenir millor rendiment que les característiques en nivell de fitxes.", 'cs': 'V tomto článku analyzujeme výzvy čínského obsahu skórování ve srovnání s angličtinou. Jelikož přehled předchozích prací pro skórování čínského obsahu ukazuje na nedostatek dat otevřeného přístupu v terénu, představujeme dva datové sady krátkých odpovědí pro čínštinu. Datová sada čínských krátkých vzdělávacích odpovědí (CESA) obsahuje 1800 odpovědi studentů na pět otázek souvisejících s vědou. Jako druhý datový soubor jsme shromáždili ASAP-ZH s odpověďmi 942 opětovným použitím tří existujících výzv z datové sady ASAP. Přizpůsobujeme nejmodernější systém skórování obsahu pro Čínštinu a vyhodnocujeme ho v několika nastaveních na těchto datových sadách. Výsledky ukazují, že funkce na nižších úrovních segmentace, jako jsou n-gramy znaků, mají tendenci lepší výkon než funkce na úrovni tokenů.', 'et': 'Käesolevas töös analüüsime hiina sisu hindamise väljakutseid võrreldes inglise keelega. Kuna Hiina sisu hindamise varasema töö ülevaade näitab, et valdkonnas puuduvad avatud juurdepääsuga andmed, esitame hiina keele kohta kaks lühiandmekogumit. Hiina hariduslike lühikeste vastuste andmekogum (CESA) sisaldab 1800 õpilase vastust viiele teadusega seotud küsimusele. Teise andmekogumina kogusime ASAP-ZH 942 vastusega, kasutades uuesti ASAP andmekogumi kolme olemasolevat viipi. Kohandame hiina keele jaoks kaasaegset sisuhindamissüsteemi ja hindame seda nende andmekogumite erinevates seadetes. Tulemused näitavad, et madalama segmenteerimistaseme funktsioonid, näiteks märgi n-grammid, kipuvad olema paremad kui märgi tasemel funktsioonid.', 'fi': 'Tässä artikkelissa analysoimme kiinalaisen sisällön pisteytyksen haasteita verrattuna englantiin. Kiinalaisen sisällön pisteytystä koskevan aikaisemman työn tarkastelu osoittaa, että kentällä ei ole avointa dataa, joten esittelemme kaksi lyhytvastausdataa kiinalaiselle. Kiinalainen Educational Short Answers -tietokokonaisuus (CESA) sisältää 1800 opiskelijan vastausta viiteen tieteeseen liittyvään kysymykseen. Toisena tietokokonaisuutena keräsimme ASAP-ZH:n 942 vastauksella käyttämällä uudelleen kolmea olemassa olevaa ASAP-tietokokonaisuutta. Mukautamme kiinalaiselle sisällönpisteytysjärjestelmää ja arvioimme sitä useissa asetuksissa näissä tietosarjoissa. Tulokset osoittavat, että alempien segmentoitustasojen ominaisuuksilla, kuten merkin n-grammilla, on yleensä parempi suorituskyky kuin tunnuksen tasolla.', 'jv': 'Nanging mapan iki, kéné tahlilas piye cara-cara sing nganggo barang-cara sing nganggo Inggris barang. Sampeyan ngembukak perusahaan kanggo nggawe barang dhéwé nggawe barang-perusahaan data sing mbukak kanggo ngilangno, kéné sampeyan data sing mbutuhak dhéwé iki dadi mbutuhak kanggo barang dhéwé. Tenggang Panjenengan langkung urip Perkaran Akrato Perkaran (SES) sak mulai 18 marang pisan sing dumadhi kanggo lima sawang kering. Sampeyan data sing wis digawe, kita cokot ASHR-Z H barêng mapuluh ênggap kanggo nambah telu mbutuyo sing perusahaan karo data yang ASHP Awak dhéwé ngewigat sistem sing ditambang-sistem ning cara-karcis kanggo Kemerdekaan lan nggawe barang dhéwé ning halaman sing dadi iki. textattr', 'ha': "Ga wannan takardan, Munã yin anayya ga masu kansalar da maɓallin China da tsofalin Ingiriya. Kama kure ya gabãni ga aikin wanda aka score na tsarin tsari na China, yana nũna wa'ana da data na buɗe-daki cikin birnin, kuma munã nuna matsayin bayani biyu masu basu'in-jibo wa China. QFontDatabase Kama daidaita na ɗabi'a, mun sami majibu na ANAN-ZH da 942, da mu sake sake yin amfani da sauri uku masu jira daga tsarin data na SAPA. Tuna daidaita halin-tsari na-sanar na tsarin mai tsari wa China kuma Muke ƙaddara shi a cikin wasu daidaita masu kanana. Mataimakin ya nuna cewa masu tsari cikin daraja masu ƙas ƙanci kamar misali n-gram, yana da mafiya kyau ga gyãra daga fassarar cikin daraja na ayuka.", 'sk': 'V prispevku analiziramo izzive kitajskega ocenjevanja vsebin v primerjavi z angleščino. Ker pregled predhodnega dela za ocenjevanje kitajskih vsebin kaže pomanjkanje odprtega dostopa podatkov na terenu, predstavljamo dva nabora podatkov o kratkih odgovorih za kitajsko. Kitajski nabor podatkov o kratkih izobraževalnih odgovorih (CESA) vsebuje 1800 odgovorov študentov na pet znanstvenih vprašanj. Kot drugi nabor podatkov smo zbrali ASAP-ZH z 942 odgovori s ponovno uporabo treh obstoječih pozivov iz nabora podatkov ASAP. Prilagodimo najsodobnejši sistem ocenjevanja vsebin za kitajščino in ga ocenimo v več nastavitvah na teh naborih podatkov. Rezultati kažejo, da imajo funkcije na nižjih ravneh segmentacije, kot so n-grami znakov, običajno boljšo zmogljivost kot funkcije na ravni žetonov.', 'bo': 'ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་རྒྱ་ནག་ནང་དོན་ཡོད་པའི་དཀའ་འགོད་བྱེད་ཀྱི་གནད་དོན་ལ་དབྱིན་ཡིག་དང་མཐུ རྒྱ་ནག རྒྱ་ནག་གི་ཤེས་ཡོན་ཚད་ཆེན་མཚམས་ཆུ་མཐུན་སྒྲིག་ཆ་སྒྲིག་འཛུགས་ཀྱི་ཚད་ལྡན་བྱས་པ་ཡིན་ནའང་། སྤྱི་ཚོགས དབྱེ་སྟངས་གཉིས་པ་ཞིག་གིས་སྒྲིག ང་ཚོས་རྒྱ་ནག གྲུབ་འབྲས་འབྲས་བ་དེའི་ཆེ་ཆུང་ཉུང་བའི་གནས་རིམ་དང་དཔེར་ན། ཡིག་འབྲུ་n(grams)ནང་གི་ཁྱད་ཆོས་ཉེས', 'he': 'בעיתון הזה, אנו מנתחים את האתגרים של תוכן סיני בהשוואה לאנגלית. בתור מבחן של עבודה קודמת לנקודת תוכן סיני מראה חוסר נתונים של גישה פתוחה בשטח, אנחנו מציגים שני קבוצות נתונים של תשובות קצרות לסינים. The Chinese Educational Short Answers data set (CESA) contains 1800 student answers for five science-related questions.  בתור קבוצת נתונים שנייה, אספנו ASAP-ZH עם 942 תשובות על ידי השתמש מחדש בשלושה נקודות קיימות מהקבוצת נתונים ASAP. אנחנו מתאימים מערכת ציונים של תוכן חדשה לסינים ולעריך אותו במספר סדרות על קבוצות נתונים אלה. התוצאות מראות כי תכונות ברמות סגמנציה נמוכות כמו n-גרם אופי נוטים להיות ביצועים טובים יותר מאשר תכונות ברמה של סימנים.'}
{'en': 'An Exploratory Study on Multilingual Quality Estimation', 'ar': 'دراسة استكشافية حول تقدير الجودة متعدد اللغات', 'pt': 'Um estudo exploratório sobre estimativa de qualidade multilíngue', 'fr': "Une étude exploratoire sur l'estimation de la qualité multilingue", 'es': 'Un estudio exploratorio sobre la estimación de la calidad multilingüe', 'ja': '多言語品質推定に関する探究的研究', 'zh': '多言质料之探索性', 'hi': 'बहुभाषी गुणवत्ता आकलन पर एक अन्वेषक अध्ययन', 'ru': 'Поисковое исследование по оценке качества многоязычия', 'ga': 'Staidéar Taiscéalach ar Mheastachán Cáilíochta Ilteangach', 'el': 'Μια διερευνητική μελέτη για την εκτίμηση της πολυγλωσσικής ποιότητας', 'hu': 'Feltáró tanulmány a többnyelvű minőségbecslésről', 'kk': 'Көптілік сапатты оқу туралы зерттеу', 'ka': '醿涐儬醿愥儠醿愥儦醿斸儨醿掅儯醿犪儤 醿欋儛alit醿斸儮醿樶儭 醿掅儛醿溼儭醿愥儢醿︶儠醿犪償醿戓儛', 'lt': 'Daugiakalbio kokybės vertinimo tiriamasis tyrimas', 'mk': 'Експераториска студија за проценка на повеќејазичната квалитет', 'it': 'Uno studio esplorativo sulla valutazione della qualità multilingue', 'ms': 'Name', 'ml': 'Multilingual Quality എസ്റ്റിമേഷനില്\u200d ഒരു എക്സപ്ലോററിയി പഠനം', 'mn': 'Олон хэл хэлний чадварын оюуны судалгааны судалгаа', 'no': 'Name', 'pl': 'Badanie rozpoznawcze dotyczące wielojęzycznej oceny jakości', 'mt': 'Studju esploratorju dwar l-istima tal-kwalità multilingwi', 'si': 'ගොඩක් භාෂාවික කුළුවත් අනුමාණය සඳහා ප්\u200dරශ්නයක් පරීක්ෂණය', 'ro': 'Un studiu exploratoriu privind estimarea calității multilingve', 'so': 'Waxbarashada imtixaanka ah ee ku saabsan qiimaynta luuqadaha badan', 'sr': 'Istraživačka studija o procjeni kvalitete mnogih jezika', 'sv': 'En förberedande studie om flerspråkig kvalitetsbedömning', 'ta': 'பல மொழிகளின் தரம் கணக்கீட்டில் ஒரு ஏற்றுமதி ஆராய்ச்சி', 'ur': 'Multilingual Quality Estimation کے بارے میں ایک تحقیق پڑھنا', 'uz': 'An Exploratory Study on Multilingual Quality Estimation', 'vi': 'Một nghiên cứu về Chất lượng đa ngôn ngữ', 'bg': 'Изследователно проучване на многоезичната оценка на качеството', 'da': 'En undersøgelse af flersproget kvalitetsvurdering', 'hr': 'Istraživačka ispitivanja o procjeni višejezičke kvalitete', 'nl': 'Een verkennend onderzoek naar meertalige kwaliteitsschatting', 'de': 'Eine explorative Studie zur mehrsprachigen Qualitätsschätzung', 'ko': '다언어 품질 평가의 탐색적 연구', 'id': 'Sebuah studi eksplorasi tentang penilaian kualitas berbilang bahasa', 'fa': 'یک مطالعه تحقیق در مورد ارزیابی کیفیت زیادی زبان', 'sw': 'Utafiti wa Utafiti wa Utafiti wa Utawala wa lugha', 'tr': 'Birnäçe diller kalitesi Taýýarlama', 'af': "'n Exploratory Study on Multilingual Quality Estimation", 'sq': 'Një studim eksplorues mbi vlerësimin e cilësisë shumëgjuhëse', 'am': 'ምርጫዎች', 'hy': 'Բազլեզու որակի գնահատման ուսումնասիրությունը', 'az': 'Multilingual Quality Assessment', 'bn': 'বহুভাষার মান গণনায় এক এক্সপ্লোরোরেটরি গবেষণা', 'cs': 'Průzkumná studie vícejazyčného odhadu kvality', 'bs': 'Istraživačka ispitivanja o procjeni mnogih jezičkih kvaliteta', 'ca': "Un estudi exploratori sobre l'estimació de qualitat multilingüe", 'et': 'Mitmekeelse kvaliteedi hindamise uuring', 'fi': 'Monikielistä laadunarviointia koskeva tutkimus', 'jv': 'Works on Multilanguage Quality', 'sk': 'Raziskovalna študija o večjezični oceni kakovosti', 'ha': 'An Exploration Reset on Taking Quality', 'bo': 'སྐད་རིགས་དབྱེ་བ་ལུགས་དང་བསྐྱེད་ཚད་ལ་བརྗོད་བྱེད་པའི་བརྗོད་ཞིབ་བྱས་པ་ཞིག་', 'he': 'מחקר חקירה על הערכת איכות רבות שפות'}
{'en': 'Predicting the quality of  machine translation  has traditionally been addressed with language-specific models, under the assumption that the quality label distribution or  linguistic features  exhibit traits that are not shared across languages. An obvious disadvantage of this approach is the need for  labelled data  for each given language pair. We challenge this assumption by exploring different approaches to multilingual Quality Estimation (QE), including using scores from translation models. We show that these outperform single-language models, particularly in less balanced quality label distributions and low-resource settings. In the extreme case of zero-shot QE, we show that it is possible to accurately predict  quality  for any given new language from  models  trained on other languages. Our findings indicate that state-of-the-art neural QE models based on powerful pre-trained representations generalise well across languages, making them more applicable in real-world settings.', 'es': 'La predicción de la calidad de la traducción automática se ha abordado tradicionalmente con modelos específicos del idioma, bajo el supuesto de que la distribución de la etiqueta de calidad o las características lingüísticas exhiben rasgos que no se comparten entre idiomas. Una desventaja obvia de este enfoque es la necesidad de datos etiquetados para cada par de idiomas dado. Desafiamos esta suposición explorando diferentes enfoques para la estimación de la calidad (QE) multilingüe, incluido el uso de puntuaciones de modelos de traducción. Demostramos que estos modelos superan a los modelos de un solo idioma, especialmente en distribuciones de etiquetas de calidad menos equilibradas y entornos de bajos recursos. En el caso extremo de la QE cero, demostramos que es posible predecir con precisión la calidad de cualquier idioma nuevo dado a partir de modelos entrenados en otros idiomas. Nuestros hallazgos indican que los modelos de QE neuronal de última generación basados en potentes representaciones preentrenadas se generalizan bien en todos los idiomas, lo que los hace más aplicables en entornos del mundo real.', 'ar': 'لقد جرت العادة على معالجة التنبؤ بجودة الترجمة الآلية من خلال نماذج خاصة بلغة معينة ، على افتراض أن توزيع ملصقات الجودة أو السمات اللغوية تُظهر سمات لا يتم مشاركتها عبر اللغات. من العيوب الواضحة في هذا الأسلوب الحاجة إلى البيانات المصنفة لكل زوج لغوي معين. نحن نتحدى هذا الافتراض من خلال استكشاف طرق مختلفة لتقدير الجودة متعدد اللغات (QE) ، بما في ذلك استخدام الدرجات من نماذج الترجمة. نوضح أن هذه النماذج تتفوق في الأداء على النماذج أحادية اللغة ، لا سيما في توزيعات ملصقات الجودة الأقل توازناً وإعدادات الموارد المنخفضة. في الحالة القصوى للتيسير الكمي بدون طلقة ، نظهر أنه من الممكن التنبؤ بدقة بالجودة لأي لغة جديدة معينة من النماذج المدربة على لغات أخرى. تشير النتائج التي توصلنا إليها إلى أن أحدث نماذج التيسير الكمي العصبية القائمة على التمثيلات القوية المدربة مسبقًا تُعمم جيدًا عبر اللغات ، مما يجعلها أكثر قابلية للتطبيق في بيئات العالم الحقيقي.', 'fr': "La prédiction de la qualité de la traduction automatique est traditionnellement abordée à l'aide de modèles spécifiques à une langue, en partant du principe que la distribution des labels de qualité ou les caractéristiques linguistiques présentent des caractéristiques qui ne sont pas partagées entre les langues. Un inconvénient évident de cette approche est la nécessité de disposer de données étiquetées pour chaque paire de langues donnée. Nous remettons en question cette hypothèse en explorant différentes approches de l'estimation de la qualité (QE) multilingue, notamment en utilisant les scores des modèles de traduction. Nous montrons que ces modèles surpassent les modèles unilingues, en particulier dans les distributions d'étiquettes de qualité moins équilibrées et dans les environnements à faibles Dans le cas extrême du QE zero-shot, nous montrons qu'il est possible de prédire avec précision la qualité d'une nouvelle langue donnée à partir de modèles formés sur d'autres langues. Nos résultats indiquent que les modèles QE neuronaux de pointe basés sur de puissantes représentations pré-entraînées se généralisent bien entre les langues, ce qui les rend plus applicables dans des environnements réels.", 'pt': 'A previsão da qualidade da tradução automática tem sido tradicionalmente abordada com modelos específicos de idioma, sob a suposição de que a distribuição do rótulo de qualidade ou os recursos linguísticos exibem características que não são compartilhadas entre os idiomas. Uma desvantagem óbvia dessa abordagem é a necessidade de dados rotulados para cada par de idiomas. Desafiamos essa suposição explorando diferentes abordagens para estimativa de qualidade multilíngue (QE), incluindo o uso de pontuações de modelos de tradução. Mostramos que esses modelos superam os modelos de idioma único, principalmente em distribuições de rótulos de qualidade menos equilibradas e configurações de poucos recursos. No caso extremo de QE zero-shot, mostramos que é possível prever com precisão a qualidade de qualquer nova linguagem a partir de modelos treinados em outras linguagens. Nossas descobertas indicam que os modelos QE neurais de última geração baseados em poderosas representações pré-treinadas generalizam bem entre os idiomas, tornando-os mais aplicáveis em configurações do mundo real.', 'ja': '機械翻訳の品質を予測することは、品質ラベルの分布または言語的特徴が言語間で共有されていない特性を示すという仮定の下で、言語固有のモデルで伝統的に対処されてきた。このアプローチの明らかな欠点は、所与の言語ペアごとにラベル付けされたデータが必要であることである。翻訳モデルからのスコアを使用するなど、多言語品質推定（ QE ）に対するさまざまなアプローチを探ることで、この仮定に挑戦します。特にバランスの取れていない品質ラベルの分布やリソースの少ない設定では、これらのモデルが単一言語のモデルよりも優れていることを示しています。ゼロショットQEの極端なケースでは、他の言語で訓練されたモデルから任意の新しい言語の品質を正確に予測することが可能であることを示しています。私たちの調査結果は、強力な事前訓練された表現に基づいた最先端のニューラルQEモデルが、言語全体でよく一般化し、現実の環境でより適用可能になっていることを示しています。', 'hi': 'मशीन अनुवाद की गुणवत्ता की भविष्यवाणी पारंपरिक रूप से भाषा-विशिष्ट मॉडल के साथ संबोधित की गई है, इस धारणा के तहत कि गुणवत्ता लेबल वितरण या भाषाई विशेषताएं उन लक्षणों को प्रदर्शित करती हैं जो भाषाओं में साझा नहीं की जाती हैं। इस दृष्टिकोण का एक स्पष्ट नुकसान प्रत्येक दिए गए भाषा जोड़ी के लिए लेबल किए गए डेटा की आवश्यकता है। हम बहुभाषी गुणवत्ता अनुमान (क्यूई) के लिए विभिन्न दृष्टिकोणों की खोज करके इस धारणा को चुनौती देते हैं, जिसमें अनुवाद मॉडल से स्कोर का उपयोग करना शामिल है। हम दिखाते हैं कि ये एकल-भाषा मॉडल से बेहतर प्रदर्शन करते हैं, विशेष रूप से कम संतुलित गुणवत्ता वाले लेबल वितरण और कम-संसाधन सेटिंग्स में। शून्य-शॉट क्यूई के चरम मामले में, हम दिखाते हैं कि अन्य भाषाओं पर प्रशिक्षित मॉडल से किसी भी नई भाषा के लिए गुणवत्ता की सटीक भविष्यवाणी करना संभव है। हमारे निष्कर्षों से संकेत मिलता है कि शक्तिशाली पूर्व-प्रशिक्षित अभ्यावेदनों के आधार पर अत्याधुनिक तंत्रिका क्यूई मॉडल भाषाओं में अच्छी तरह से सामान्यीकृत होते हैं, जिससे उन्हें वास्तविक दुनिया की सेटिंग्स में अधिक लागू किया जाता है।', 'zh': '古者,机器翻译之质用特定言语之形以决之,假令标布言语不共之征。 此一法明病,须为每给定语言对用标记数。 探多言质评 (QE) 之异术(兼译模之分数)以挑其伪设。 我们表明,这些模形优于单言语模样,特别在质量不太均的标签分布和低资源境内。 零次QE之极,以他语为准给定新语。 臣等考结果表明,基于强大之先进神经QE形于众言,皆可推广,使宜于世。', 'ru': 'Прогнозирование качества машинного перевода традиционно рассматривалось с помощью языковых моделей, исходя из предположения, что распределение этикеток качества или лингвистические особенности проявляют черты, которые не являются общими для всех языков. Очевидным недостатком этого подхода является потребность в маркированных данных для каждой данной языковой пары. Мы оспариваем это предположение, исследуя различные подходы к многоязычной оценке качества (QE), в том числе с использованием баллов из моделей перевода. Мы показываем, что эти модели превосходят одноязычные, особенно в менее сбалансированных качественных распределениях этикеток и малоресурсных настройках. В крайнем случае QE с нулевым выстрелом мы показываем, что можно точно предсказать качество для любого данного нового языка из моделей, обученных на других языках. Наши результаты показывают, что современные нейронные модели QE, основанные на мощных предварительно обученных представлениях, хорошо обобщают языки, что делает их более применимыми в реальных условиях.', 'ga': 'Tugadh aghaidh go traidisiúnta ar cháilíocht an aistriúcháin mheaisín a thuar le múnlaí a bhaineann go sonrach le teanga, ag glacadh leis go léiríonn dáileadh lipéad cáilíochta nó gnéithe teangeolaíocha tréithe nach bhfuil roinnte trasna teangacha. Míbhuntáiste soiléir a bhaineann leis an gcur chuige seo is ea an gá atá le sonraí lipéadaithe do gach péire teanga ar leith. Déanaimid dúshlán don toimhde seo trí fhiosrú a dhéanamh ar chuir chuige éagsúla maidir le Meastachán Cáilíochta ilteangach (QE), lena n-áirítear úsáid a bhaint as scóir ó mhúnlaí aistriúcháin. Léirímid go n-éiríonn leo seo níos fearr ná múnlaí aonteangacha, go háirithe i ndáileadh lipéid cháilíochta nach bhfuil chomh cothrom céanna agus i suíomhanna íseal-acmhainne. I gcás an-mhór QE gan urchar, léirímid gur féidir cáilíocht a thuar go cruinn d’aon teanga nua ar leith ó mhúnlaí oilte ar theangacha eile. Tugann ár dtorthaí le fios go bhfuil samhlacha néarúla QE den scoth atá bunaithe ar léirithe cumhachtacha réamhoilte ag ginearálú go maith thar theangacha, rud a fhágann go bhfuil siad níos infheidhme i suímh dhomhanda.', 'el': 'Η πρόβλεψη της ποιότητας της μηχανικής μετάφρασης έχει παραδοσιακά αντιμετωπιστεί με ειδικά γλωσσικά μοντέλα, με την υπόθεση ότι η διανομή της ετικέτας ποιότητας ή τα γλωσσικά χαρακτηριστικά παρουσιάζουν χαρακτηριστικά που δεν μοιράζονται μεταξύ των γλωσσών. Ένα προφανές μειονέκτημα αυτής της προσέγγισης είναι η ανάγκη για επισημασμένα δεδομένα για κάθε δεδομένο γλωσσικό ζεύγος. Προκαλούμε αυτή την υπόθεση εξερευνώντας διαφορετικές προσεγγίσεις για την πολυγλωσσική εκτίμηση ποιότητας (QE), συμπεριλαμβανομένης της χρήσης βαθμολογιών από μεταφραστικά μοντέλα. Αποδεικνύουμε ότι αυτά τα μοντέλα ξεπερνούν τις επιδόσεις των μονογλωσσικών μοντέλων, ιδίως σε λιγότερο ισορροπημένες διανομές ετικετών ποιότητας και ρυθμίσεις χαμηλής περιεκτικότητας σε πόρους. Στην ακραία περίπτωση της μηδενικής QE, αποδεικνύουμε ότι είναι δυνατόν να προβλεφθεί με ακρίβεια η ποιότητα για κάθε δεδομένη νέα γλώσσα από μοντέλα εκπαιδευμένα σε άλλες γλώσσες. Τα ευρήματά μας δείχνουν ότι τα σύγχρονα μοντέλα νευρικής QE που βασίζονται σε ισχυρές προ-εκπαιδευμένες αναπαραστάσεις γενικεύονται καλά σε όλες τις γλώσσες, καθιστώντας τα πιο εφαρμόσιμα σε πραγματικές συνθήκες.', 'hu': 'A gépi fordítás minőségének előrejelzését hagyományosan nyelvspecifikus modellekkel kezelték, azzal a feltételezéssel, hogy a minőségi címke elosztása vagy nyelvi jellemzői olyan jellemzőket mutatnak, amelyek nem osztoznak nyelveken. Ennek a megközelítésnek nyilvánvaló hátránya az, hogy minden egyes nyelvpárhoz címkézett adatokra van szükség. Ezt a feltételezést a többnyelvű minőségbecslés (QE) különböző megközelítéseinek feltárásával vitatjuk meg, beleértve a fordítási modellek pontszámait is. Megmutatjuk, hogy ezek az egynyelvű modellek teljesítményét felülmúlják, különösen a kevésbé kiegyensúlyozott minőségű címkelosztások és az alacsony erőforrásokat igénylő beállítások esetében. A zéró minőségű minőségbiztosítás extrém esetében megmutatjuk, hogy bármely új nyelv minőségét pontosan lehet előrejelezni más nyelveken képzett modellekből. Eredményeink azt mutatják, hogy a legkorszerűbb neurális QE modellek, amelyek erőteljes, előre képzett reprezentációkon alapulnak, jól általánosítják a nyelveket, így jobban alkalmazhatók a valós környezetben.', 'ka': 'მაქსინის გარგულისხმების კაalitეტის დაწყვეტილება ტრადიციურად იყო ენის სპექტიფიკური მოდელებით, რომლებიც წარმოიდგინეთ, რომ კაalitეტის ნიშანების გარგულისხმები ან ენგულისტიკური ფუნ ამ პროგრამის გამოსახულებელი არაფერი არის ყველა განახულებული ენის ზოგრამისთვის მინიშვნელოვანი მონაცემები. ჩვენ ამ წარმოდგენისთვის განსხვავებული წარმოდგენების განსაზღვრება მრავალური კვალეტის განსაზღვრებას (QE) გამოყენებით, რომელიც განსაზღვრების მოდელების გამოყენებას ჩვენ გამოჩვენებთ, რომ ეს ერთადერთი ენის მოდელები, განსაკუთრებით უფრო ბალანსური კაalitეტის ნიშანების განყოფილებაში და უფრო ბალანსური რესურსის პარამეტრებში QE-ის კექტრემეტური შემთხვევაში ჩვენ აჩვენებთ, რომ შესაძლებელია წარმოდგინოთ კოლეტური წარმოდგინოთ ყველა ახალი ენაზე, რომელიც სხვა ენაზე განსწავლებული მოდელებიდან ჩვენი შესაძლებლობები გვეჩვენება, რომ სამყარო მნიშვნელოვანი ნეიროლური QE მოდელები, რომლებიც ძალიან სამყარო სამყარო რედაქტირებულებზე დაბაზიან ძალიან სამყარო რედაქტირებ', 'it': "La previsione della qualità della traduzione automatica è stata tradizionalmente affrontata con modelli specifici per la lingua, partendo dal presupposto che la distribuzione dell'etichetta di qualità o le caratteristiche linguistiche presentino tratti che non sono condivisi tra le lingue. Uno svantaggio evidente di questo approccio è la necessità di dati etichettati per ogni coppia di lingue. Sfidiamo questa ipotesi esplorando diversi approcci alla valutazione della qualità multilingue (QE), incluso l'utilizzo di punteggi da modelli di traduzione. Dimostriamo che queste prestazioni superano i modelli monolingua, in particolare nelle distribuzioni di etichette di qualità meno equilibrate e nelle impostazioni a basso contenuto di risorse. Nel caso estremo del QE zero-shot, mostriamo che è possibile prevedere con precisione la qualità di qualsiasi nuova lingua da modelli formati su altre lingue. I nostri risultati indicano che i modelli QE neurali all'avanguardia basati su potenti rappresentazioni pre-addestrate generalizzano bene in tutte le lingue, rendendoli più applicabili nelle impostazioni del mondo reale.", 'lt': 'Mašininio vertimo kokybės prognozavimas tradiciškai buvo sprendžiamas naudojant konkrečiai kalbai būdingus modelius, darant prielaidą, kad kokybės etiketės platinimas arba kalbinės savybės turi savybes, kurios nėra pasidalijamos kalbomis. Akivaizdus šio požiūrio trūkumas yra tai, kad kiekvienai konkrečiai kalbų porai reikia pažymėtų duomenų. Mes iššūkiame šią prielaidą ištirdami skirtingus daugiakalbio kokybės vertinimo metodus, įskaitant vertimo modelių rezultatus. Mes rodome, kad šie vienos kalbos modeliai yra didesni, ypač mažiau subalansuotų kokybės ženklų paskirstymo ir mažai išteklių turinčių aplinkybių atveju. Ektremaliu nulinio QE atveju mes parodome, kad galima tiksliai nuspėti bet kurios naujos kalbos kokybę iš modelių, mokomų kitomis kalbomis. Our findings indicate that state-of-the-art neural QE models based on powerful pre-trained representations generalise well across languages, making them more applicable in real-world settings.', 'mk': 'Предвидувањето на квалитетот на машинскиот превод традиционално е решено со модели специфични на јазикот, под претпоставка дека дистрибуцијата на квалитетната етикета или јазичните карактеристики покажуваат знаци кои не се споделени меѓу јазиците. Очигледно недостаток на овој пристап е потребата од означени податоци за секој даден пар јазици. Ние ја предизвикуваме оваа претпоставка со истражување на различни пристапи до мултијазичката проценка на квалитетот (QE), вклучувајќи го и користењето на резултатите од преводните модели. Покажуваме дека овие модели се поголеми од моделите на еднојазик, особено во помалку балансирани квалитетни дистрибуции на етикетите и поставувања со ниски ресурси. Во екстремниот случај на нула QE, покажуваме дека е можно претпоставување на квалитетот за секој даден нов јазик од модели обучени на други јазици. Нашите откритија покажуваат дека најсовремените нервни модели на QE базирани на моќни предобучени претставувања се генерализираат добро низ јазиците, правејќи ги поприменливи во реалните услови.', 'kk': 'Компьютердің аудармасының сапасы дәстүрлі тілдердің ерекше үлгілерімен адрес етілген, сапатты жарлық үлестірімі не лингвистикалық мүмкіндіктердің тілдерде ортақтастырылмаған қасиеттерін көрсетеді. Бұл жағдайдың көрінісі - барлық тіл екі үшін жарлық деректер қажет. Бұл тапсырманы көптеген тілдердің қасиеттерін (QE) бағалау арқылы, аудару үлгілерінен сәйкестіктерді қолдану арқылы түрлі жағдайларды зерттейміз. Біз бұл жалғыз тіл үлгілерін көрсетедік, әсіресе балансияланған сапатты белгілер үлестірімізде және ресурстардың төмен баптауларында. QE- нөл сүру үшін, біз басқа тілдер үлгілерінен келген жаңа тіл үлгілерінен дұрыс таңдау мүмкіндігін көрсетедік. Біздің тапсырмаларымыздың күй- жай QE үлгілеріне негізделген күшті алдын- оқыту үлгілеріне негізделген тілдерді жалғастырып, оларды шын әлемдік параметрлерінде қолдануға болады.', 'ms': 'Menunjukkan kualiti terjemahan mesin telah tradisional ditujukan dengan model khusus bahasa, di bawah asumsi bahawa distribusi label kualiti atau ciri-ciri bahasa menunjukkan ciri-ciri yang tidak dikongsi di seluruh bahasa. Kegagalan yang jelas bagi pendekatan ini adalah perlukan data yang ditabel bagi setiap pasangan bahasa yang diberi. Kami cabar asumsi ini dengan mengeksplorasi pendekatan yang berbeza kepada penilaian Kualiti berbilang bahasa (QE), termasuk menggunakan skor dari model terjemahan. Kami menunjukkan bahawa model-bahasa tunggal ini lebih berharga, terutama dalam distribusi label kualiti yang kurang seimbang dan tetapan sumber rendah. Dalam kes ekstrim QE 0-shot, kita menunjukkan bahawa ia adalah mungkin untuk meramalkan kualiti dengan tepat untuk mana-mana bahasa baru yang diberikan dari model yang dilatih dalam bahasa lain. Penemuan kami menunjukkan bahawa model QE saraf terbaik berdasarkan perwakilan praterlatih yang berkuasa menyeluruh bahasa, menjadikannya lebih berguna dalam tetapan dunia nyata.', 'ml': 'മെഷീന്\u200d പരിഭാഷക്കുറിച്ചുള്ള മാതൃകങ്ങളുടെ സ്വാധീനം പ്രാധാന്യം ഭാഷ- പ്രത്യേകിച്ച മോഡലുകളുമായി വിലാസപ്പെടുത്തിയിരിക്കുന്നു. ലൈബ ഈ നടപടിയിലെ വ്യക്തമായ അസാധ്യതയാണ് എല്ലാ ഭാഷ ജോലികള്\u200dക്കും ലേബിള്\u200dഡ് ഡേറ്റായിട്ടുള്ള ആവശ്യം. ട്രെന്\u200dഷന്\u200d മോഡലില്\u200d നിന്നും സ്കോര്\u200d ഉപയോഗിച്ചുകൊണ്ട് പല ഭാഷകങ്ങളുടെ വ്യത്യസ്ത സാധ്യതകള്\u200d പരിശോധിക്കുന്നതിനാല്\u200d  നമ്മള്\u200d കാണിച്ചു കൊടുക്കുന്നത് ഈ ഏക ഭാഷയിലെ മോഡലുകള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു, പ്രത്യേകിച്ച് താല്\u200dക്കാലികമായ ക്യൂയിയുടെ പൂര്\u200dണ്ണമായ വെടിവെക്കപ്പെട്ട കാര്യത്തില്\u200d നമ്മള്\u200d കാണിക്കുന്നു, മറ്റു ഭാഷകളില്\u200d പരിശീലിക്കപ്പെട്ട മോഡലുകളി നമ്മുടെ കണ്ടുപിടികള്\u200d കാണിക്കുന്നുണ്ടെങ്കില്\u200d പ്രധാനപ്പെട്ട പ്രതിനിധികള്\u200dക്ക് അടിസ്ഥാനത്ത് ന്യൂറല്\u200d ക്യൂയിയുടെ രാജ്യത്തിന്', 'mt': 'It-tbassir tal-kwalità tat-traduzzjoni bil-magna tradizzjonalment ġie indirizzat ma’ mudelli speċifiċi għall-lingwa, bil-preżunzjoni li d-distribuzzjoni tat-tikketta tal-kwalità jew il-karatteristiċi lingwistiċi juru karatteristiċi li mhumiex kondiviżi bejn il-lingwi. Żvantaġġ ovvju ta’ dan l-approċċ huwa l-ħtieġa għal dejta ttikkettata għal kull par ta’ lingwi partikolari. Aħna ninsfidaw din is-suppożizzjoni billi nesploraw approċċi differenti għall-istima multilingwi tal-kwalità (QE), inkluż l-użu ta’ punteġġi minn mudelli ta’ traduzzjoni. Aħna nuru li dawn il-mudelli b’lingwa waħda huma aktar effettivi, b’mod partikolari f’distribuzzjonijiet ta’ tikketta ta’ kwalità inqas ibbilanċjati u f’ambjenti b’riżorsi baxxi. Fil-każ estrem ta’ QE żero-shot, nuru li huwa possibbli li tiġi mbassra b’mod preċiż il-kwalità għal kwalunkwe lingwa ġdida partikolari minn mudelli mħarrġa f’lingwi oħra. Is-sejbiet tagħna jindikaw li l-mudelli tal-QE newrali l-aktar avvanzati bbażati fuq rappreżentazzjonijiet qawwija mħarrġa minn qabel jiġġeneralizzaw sew fil-lingwi kollha, u jagħmluhom aktar applikabbli f’ambjenti reali.', 'no': 'Forhåndsvising av kvaliteten på maskinsomsetjinga er tradisjonell adressert med språkspesifiserte modeller, under assumpsjonen at kvalitetmerkelappen eller språksfunksjonane viser eigenskapar som ikkje er delt på språk. Dette er nødvendighet for merkelige data for kvar oppgitt språk par. Vi utfordrer denne assumpsjonen ved å utforska ulike tilnærmingar til fleirspråk kvalitetevaluering (QE), inkludert med å bruka poeng frå omsetjingsmodular. Vi viser at desse utfører enkelspråk-modeller, spesielt i mindre balanserte kvalitetskildringar og låg ressursinnstillingar. I ekstremt tilfelle med null-shot QE viser vi at det er mogleg å spesifisera kvaliteten for alle oppgjevne nye språk frå modeller trengte på andre språk. Finningane våre tyder på at kunsten-neurale QE-modeller basert på kraftige føretrainerte representasjonar generelliserer bra på språk, og gjer dei meir tilgjengelege i verdensinnstillingar.', 'mn': 'Машины хөрөнгө оруулалтын чанарыг хэл тодорхойлолтой загваруудын хувьд илэрхийлэгддэг гэдгийг ойлгож байна. Энэ ойлголтын тухай ойлголтын тухай ойлголт нь өгөгдлийн хоёр бүрт нэрлэгдсэн өгөгдлийн хэрэгтэй. Бид энэ тодорхойлолтыг олон хэл хэлний чадварын оюун ухаан (QE) руу олон аргыг судалж, үүнийг орчуулах загварын тоо ашиглах боломжтой. Бид эдгээр нэг хэл загваруудыг дамжуулж, ялангуяа баланслагдсан сайн жижиг хэлбэрийн загваруудын хуваарилалт болон бага нөөц тохиолдолд гаргадаг. QE-н хамгийн тохиромжтой тохиолдолд бид өөр хэл дээр сургалтын загвараас өгөгдсөн ямар ч шинэ хэл болохыг тодорхойлох боломжтой гэдгийг харуулж байна. Бидний олж мэдсэн зүйлс нь урлагийн мэдрэлийн QE загваруудын тухай хүчирхэг сургалтын илэрхийлэл дээр илэрхийлэгддэг хэл олон төрлийн төрлийн загваруудыг илүү ашиглаж байна.', 'ro': 'Prevederea calității traducerii automate a fost abordată în mod tradițional prin modele specifice limbilor, presupunând că distribuția etichetelor de calitate sau caracteristicile lingvistice prezintă trăsături care nu sunt împărtășite între limbi. Un dezavantaj evident al acestei abordări este nevoia de date etichetate pentru fiecare pereche de limbi. Provocăm această ipoteză explorând diferite abordări ale estimării calității multilingve (QE), inclusiv utilizând scoruri din modele de traducere. Noi arătăm că aceste modele depășesc performanța modelelor unilingvistice, în special în distribuțiile de etichete de calitate mai puțin echilibrate și setările cu resurse reduse. În cazul extrem al QE zero-shot, arătăm că este posibil să prezicem cu precizie calitatea pentru orice limbă nouă dată din modele instruite pe alte limbi. Descoperirile noastre indică faptul că modelele QE neurale de ultimă oră bazate pe reprezentări puternice pre-instruite generalizează bine în toate limbile, făcându-le mai aplicabile în setările din lumea reală.', 'pl': 'Przewidywanie jakości tłumaczenia maszynowego było tradycyjnie uwzględniane za pomocą modeli specyficznych dla języka, przy założeniu, że rozkład etykiety jakości lub cechy językowe wykazują cechy, które nie są wspólne między językami. Oczywistą wadą tego podejścia jest potrzeba znakowanych danych dla każdej pary językowej. Podważamy to założenie, badając różne podejścia do wielojęzycznej oceny jakości (QE), w tym wykorzystując wyniki z modeli tłumaczeniowych. Pokazujemy, że te modele przewyższają modele jednojęzyczne, zwłaszcza w mniej zrównoważonych dystrybucjach etykiet jakości i ustawieniach o niskich zasobach. W skrajnym przypadku zero-shot QE pokazujemy, że możliwe jest dokładne przewidywanie jakości dla danego nowego języka na podstawie modeli trenowanych na innych językach. Nasze ustalenia wskazują, że najnowocześniejsze neuronowe modele QE oparte na potężnych, wstępnie przeszkolonych reprezentacjach dobrze uogólniają się w różnych językach, dzięki czemu są bardziej stosowane w świecie rzeczywistym.', 'sr': 'Predviđanje kvalitete prevoda mašine tradicionalno je rešeno sa specifičnim jezikom modelima, pod pretpostavkom da distribucija kvalitetne etikete ili jezičke funkcije pokazuju osobine koje nisu dijeljene na jezicima. Očigledno nedostatak ovog pristupa je potreba za označenim podacima za svaki određeni jezički par. Izazivamo ovu pretpostavku istražujući različite pristupe multijezičkoj procjeni kvalitete (QE), uključujući korištenje rezultata iz modela prevoda. Pokazujemo da su ovi jedinstveni modeli izvršene, posebno u manjoj balanciranoj distribuciji etikete kvalitete i podešavanju niskih resursa. U ekstremnom slučaju 0-shot QE pokazujemo da je moguće precizno predvidjeti kvalitet svakog novog jezika iz modela obučenih na drugim jezicima. Naši nalazi ukazuju na to da state-of-the-art neural QE modeli bazirani na moćnim predobučenim predstavljanjima generalizuju dobro širom jezika, čineći ih primjenjivijima u stvarnom svijetu.', 'si': 'යන්ත්\u200dරය භාෂාවිතයේ ක්\u200dරියාත්මක විශේෂතාවට භාෂාව විශේෂය සමග භාෂාවිත විශේෂය සහ භාෂාවිතයේ භාෂාවිතයෙන් සමාන්\u200d මේ විදියට පැහැදිලි අවස්ථාවක් තමයි හැම භාෂා ජෝඩාවට ලබේල් කරලා තියෙන දත්ත අවශ්\u200dය. අපි මේක අවශ්\u200dයය කරන්නේ වෙනස් අවශ්\u200dයය අවශ්\u200dයය අවශ්\u200dයය (QE) වලින් වෙනස් අවශ්\u200dයය අවශ්\u200dයය අවශ්\u200dයය (අවශ්\u200dයය) සමග අපි පෙන්වන්නේ මේ එක භාෂාවක් මෝඩේල් වලින්, විශේෂයෙන්ම සම්බන්ධ විශේෂ ලේබෙල් විතරය සහ අඩුම්  QE ශූන්ය ශූන්ය විශේෂ විදියට, අපි පෙන්වන්න පුළුවන් කියලා අනිත් භාෂාවට පුළුවන් අලුත් භාෂාවට ප්\u200dරශ අපේ හොයාගන්න පුළුවන් විදිහට පෙන්වන්නේ කියලා කියලා කියලා කියලා කියලා, ශක්තිමත් ප්\u200dරධානය කරලා තියෙන ප්\u200dරධානයක් භාෂ', 'so': 'Waxbarashada u diyaarinta turjumaadda machine waxaa si caadiga ah lagula macaamilooday tusaalooyin cayiman oo afka lagu qoray, sida loo malaynayo, qaybinta takhasuska ama farsamada luqada lagu qorayo waxay muujiyaan baaritaanka aan lagu qeybinayn luuqadaha oo dhan. Qof kasta oo luqada la siiyey waa in loo baahan yahay macluumaad la qoray. Waxaynu dhibaateynaa malayntan si aan u baahan qaababka kala duduwan ee qiyaamadda qiimaha luuqadaha kala duduwan (QE), kuwaas oo ku jira isticmaalka tusaalaha turjumidda. Waxaynu muujinnaa in muuqashadan qaababka afka oo kaliya, khusuusan ku kala qaybinta qoraalka qiimaha ah oo ka yar iyo sawirada hoose-resource. In the extreme case of zero-shot QE, we show that it is possible to accurately predict quality for any given new language from models trained on other languages.  Shaqooyinkayada ayaa tusaale ka dhiga qaababka neurada ee QE-da oo ku saleysan qaab xoog leh oo horay loo tababariyey waxay si fiican ugu dhaqdhaqaajiyaan luuqadaha oo dhan, waxayna ka dhigaan kuwo ka faa’iido badan xarumaha caalamiga ah.', 'sv': 'Att förutsäga kvaliteten på maskinöversättning har traditionellt behandlats med språkspecifika modeller, under antagandet att kvalitetsmärkningen eller språkliga egenskaper uppvisar egenskaper som inte delas mellan olika språk. En uppenbar nackdel med detta tillvägagångssätt är behovet av märkta data för varje givet språkpar. Vi utmanar detta antagande genom att utforska olika tillvägagångssätt för flerspråkig kvalitetsbedömning (QE), inklusive att använda poäng från översättningsmodeller. Vi visar att dessa presterar bättre än enspråksmodeller, särskilt i mindre balanserade kvalitetsmärkningar och lågresursinställningar. I det extrema fallet med noll-skott QE visar vi att det är möjligt att exakt förutsäga kvalitet för ett givet nytt språk från modeller utbildade på andra språk. Våra resultat tyder på att state-of-the-art neurala QE-modeller baserade på kraftfulla pre-utbildade representationer generaliserar väl över språk, vilket gör dem mer tillämpliga i verkliga miljöer.', 'ta': 'இயந்திரத்தின் மொழிமாற்றியின் தரம் மொழிக்குறிப்பிட்ட மாதிரிகளால் முன்னோக்கம் செய்யப்பட்டுள்ளது, தரம் விளக்கம் அல்லது மொழிக்குறிப்பு கு கொடுக்கப்பட்ட ஒவ்வொரு மொழி ஜோடிக்கும் குறிப்பிட்ட தரவு மொழிபெயர்ப்பு மாதிரிகளில் இருந்து மதிப்புகளை பயன்படுத்தி பல மொழிகளின் தரம் கணக்கீடு (QE) வேறு முறையான வழிகாட்டிகளை தேட We show that these outperform single-language models, particularly in less balanced quality label distributions and low-resource settings.  பூஜ்ஜியமாக சுட்டு கியூயியின் மிகவும் முக்கியமாக, மற்ற மொழிகளில் பயிற்சி செய்யப்பட்ட புதிய மொழிகளுக்கு சரியாக புதிய ம எங்கள் கண்டுபிடிப்புகள் குறிப்பிடுகிறது உண்மையான உலக அமைப்புகளில் மேலும் பயன்படுத்தும் முன் பயிற்சிக்கப்பட்ட முன் குறிப்புகளை அடிப', 'ur': 'ماشین کی ترجمہ کی کیفیت کی پیش بینی کی جاتی ہے کہ زبانوں میں مشترک موڈل کے ساتھ پڑھی جاتی ہے، یہ گمان ہے کہ کیفیت لیبل تقسیم یا زبان ویٹنی ویٹیوں کی ویٹیوں کو دکھاتے ہیں جو زبانوں میں مشترک نہیں ہیں. اس طریقے کی صریح مخالفت یہ ہے کہ ہر ایک دیئے زبان جوڑے کے لئے لابل کیا جاتا ہے. ہم اس فرضی کو مشکل دیتے ہیں کہ بہت سی زبان کی کیفیت کی ارزیابی (QE) کے لئے مختلف طریقے کا تحقیق کریں۔ ہم دکھاتے ہیں کہ یہ ایک زبان کی مدلکوں سے کام لیتے ہیں، مخصوصاً کم برالیس کیلوٹ لیبل کے تقسیم اور کم سراسر کے تنظیم میں۔ صفر-شٹ QE کے مطابق قسم میں، ہم نشان دیتے ہیں کہ ہر نوی زبان کے لئے ایک دوسری زبانوں پر آموزش کی مدلکوں سے سیدھی طرح کی کیفیت کی پیش کرنا ممکن ہے. ہمارے نتیجے نشان دیتے ہیں کہ انٹر کی ایٹر کی نیورال کیئ موڈل قوی پیش آموزش کی تعلیم پر بنیاد رکھتے ہیں، زبانوں میں بہت زیادہ آسانی کرتے ہیں، اور ان کو حقیقی دنیا کے تنظیم میں زیادہ لازم بناتے ہیں.', 'uz': "Name @ info Biz bu fikrlarni tarjima modeldan foydalanish bilan bir necha tilning Quality Estimatsiya (QE) uchun boshqa usullarni aniqlash orqali rivojlanamiz. Biz shu bir tildan foydalanuvchi modellarni ko'rsatishimiz mumkin, ammo o o'xshash balandlik yorliqni qaytarish va kam manbaning moslamalarida. Biz yolg'oncha QE'ni ko'rsatumiz, biz boshqa tillardan o'rganilgan modellardan foydalanilgan yangi tilning sifatini aniqlash mumkin. Bizning murojaatlarimiz shunday namoyishlarimizni anglatadi, maktab o'rganilgan tashkilotlar o'z tildagi ko'plab o'zgarishga ega bo'ladi va ularni halik dunyo moslamalarida qo'llashda qo'llash mumkin.", 'vi': 'Dự đoán chất lượng của dịch vụ máy đã được đề cập theo truyền thống với các mô hình ngôn ngữ cụ thể, với giả thuyết là hiệu ứng nhãn hay các tính năng ngôn ngữ đều có những đặc điểm không chia sẻ các ngôn ngữ. Một điều bất lợi rõ ràng của phương pháp này là cần phải có dữ liệu được dán nhãn cho mỗi cặp ngôn ngữ. Chúng tôi thách thức giả thuyết này bằng cách thăm dò các phương pháp khác nhau về định giá chất lượng đa dạng (QE) bao gồm việc sử dụng điểm từ các mô hình dịch. Chúng tôi cho thấy những mô hình ngôn ngữ riêng, đặc biệt trong việc phân phối nhãn chất lượng kém cân bằng và thiết lập nguồn ít. Trong trường hợp nhạy bén với QE bằng không, chúng tôi cho thấy khả năng dự đoán chính xác chất lượng cho bất kỳ ngôn ngữ mới nào được cung cấp từ các mô hình được đào tạo ở các ngôn ngữ khác. Những phát hiện của ta cho thấy các mô hình thần kinh QE thần kinh cao nhất dựa trên các biểu tượng được huấn luyện mạnh thường xuyên xuyên qua các ngôn ngữ, làm chúng dễ áp dụng hơn trong thế giới thực.', 'nl': 'Het voorspellen van de kwaliteit van machinevertaling is traditioneel aangepakt met taalspecifieke modellen, onder de veronderstelling dat de distributie van kwaliteitslabels of taalkundige kenmerken kenmerken vertonen die niet over talen worden gedeeld. Een duidelijk nadeel van deze aanpak is de behoefte aan gelabelde gegevens voor elk gegeven taalpaar. We dagen deze veronderstelling uit door verschillende benaderingen van meertalige kwaliteitsschatting (QE) te onderzoeken, waaronder scores uit vertaalmodellen. We laten zien dat deze modellen beter presteren dan enkeltalige modellen, met name in minder evenwichtige kwaliteitslabeldistributies en instellingen met weinig resources. In het extreme geval van zero-shot QE laten we zien dat het mogelijk is om de kwaliteit van elke nieuwe taal nauwkeurig te voorspellen op basis van modellen die zijn getraind op andere talen. Onze bevindingen wijzen erop dat state-of-the-art neurale QE-modellen gebaseerd op krachtige vooraf getrainde representaties goed generaliseren in alle talen, waardoor ze toepasbaar zijn in echte omgevingen.', 'da': 'Forudsigelse af kvaliteten af maskinoversættelse er traditionelt blevet behandlet med sprogspecifikke modeller, idet distributionen af kvalitetsmærker eller sproglige træk udviser træk, der ikke deles på tværs af sprog. En åbenlys ulempe ved denne tilgang er behovet for mærkede data for hvert givet sprogpar. Vi udfordrer denne antagelse ved at undersøge forskellige tilgange til flersproget kvalitetsestimering (QE), herunder ved at bruge scores fra oversættelsesmodeller. Vi viser, at disse yder bedre end ensprogede modeller, især i mindre afbalancerede kvalitetsmærkedistributioner og lav ressource-indstillinger. I det ekstreme tilfælde af zero-shot QE viser vi, at det er muligt præcist at forudsige kvalitet for et givet nyt sprog fra modeller, der er trænet på andre sprog. Vores resultater indikerer, at state-of-the-art neurale QE modeller baseret på kraftfulde prætrænede repræsentationer generaliserer godt på tværs af sprog, hvilket gør dem mere anvendelige i den virkelige verden.', 'hr': 'Predviđanje kvalitete prevoda strojeva tradicionalno je riješeno s određenim jezičkim modelima, pod pretpostavkom da distribucija kvalitetne etikete ili jezičke funkcije pokazuju osobine koje nisu dijeljene na jezicima. Očito nedostatak ovog pristupa je potreba za označenim podacima za svaki određeni jezički par. Izazivamo ovu pretpostavku istraživanjem različitih pristupa procjenama multijezičkih kvaliteta (QE), uključujući korištenje rezultata iz prevodnih modela. Pokazujemo da su ovi jednojezički modeli izvršene, posebno u manjoj balanciranoj raspodjeli etikete kvalitete i nastave niskih resursa. U ekstremnom slučaju 0-shot QE pokazujemo da je moguće precizno predvidjeti kvalitet svakog novog jezika iz modela obučenih na drugim jezicima. Naši nalazi ukazuju na to da state-of-the-art neural QE modeli bazirani na moćnim predobučenim predstavljanjima generaliziraju dobro na jezicima, čineći ih primjenjivijima u stvarnom svijetu.', 'bg': 'Прогнозирането на качеството на машинния превод традиционно се разглежда чрез специфични за езика модели, като се приема, че разпределението на етикета за качество или езиковите характеристики показват черти, които не се споделят между езиците. Очевиден недостатък на този подход е необходимостта от етикетирани данни за всяка дадена езикова двойка. Ние оспорваме това предположение, като изследваме различни подходи към многоезичната оценка на качеството, включително чрез използване на оценки от модели на превод. Показваме, че тези модели превъзхождат едноезичните модели, особено при по-малко балансирани разпределения на етикети за качество и настройки с ниски ресурси. В екстремния случай на нулев кадър показваме, че е възможно точно да се предвиди качеството на даден нов език от модели, обучени на други езици. Нашите открития показват, че най-съвременните невронни модели на QE, базирани на мощни предварително обучени представи, генерализират добре различните езици, което ги прави по-приложими в реални условия.', 'de': 'Die Vorhersage der Qualität maschineller Übersetzung wurde traditionell mit sprachspezifischen Modellen angegangen, wobei davon ausgegangen wird, dass die Verteilung von Gütesiegeln oder linguistische Merkmale Merkmale aufweisen, die nicht sprachübergreifend geteilt werden. Ein offensichtlicher Nachteil dieses Ansatzes ist die Notwendigkeit von markierten Daten für jedes gegebene Sprachpaar. Wir hinterfragen diese Annahme, indem wir verschiedene Ansätze zur mehrsprachigen Qualitätsschätzung (QE) erforschen, einschließlich Scores aus Übersetzungsmodellen. Wir zeigen, dass diese Modelle einfachsprachige Modelle übertreffen, insbesondere bei weniger ausgewogenen Qualitätslabelverteilungen und ressourcenarmen Einstellungen. Im Extremfall von Zero-Shot QE zeigen wir, dass es möglich ist, die Qualität für jede neue Sprache anhand von Modellen, die auf anderen Sprachen trainiert wurden, genau vorherzusagen. Unsere Ergebnisse deuten darauf hin, dass hochmoderne neurale QE-Modelle, die auf leistungsstarken vortrainierten Repräsentationen basieren, sich gut über Sprachen hinweg verallgemeinern und somit in realen Umgebungen anwendbar machen.', 'id': 'Menunjukkan kualitas terjemahan mesin tradisional telah didirikan dengan model spesifik bahasa, di bawah asumsi bahwa distribusi label kualitas atau ciri-ciri bahasa menunjukkan ciri-ciri yang tidak dibagi di seluruh bahasa. Sebuah kelemahan jelas dari pendekatan ini adalah kebutuhan untuk data yang ditabel untuk setiap pasangan bahasa yang diberikan. Kami menantang asumsi ini dengan mengeksplorasi pendekatan yang berbeda untuk penilaian kualitas multibahasa (QE), termasuk menggunakan skor dari model terjemahan. Kami menunjukkan bahwa model bahasa tunggal ini lebih berharga, terutama dalam distribusi label kualitas yang kurang seimbang dan pengaturan sumber daya rendah. Dalam kasus ekstrim QE 0-shot, kami menunjukkan bahwa mungkin untuk memprediksi akurat kualitas untuk setiap bahasa baru yang diberikan dari model yang dilatih dalam bahasa lain. Penemuan kami menunjukkan bahwa model QE saraf terbaik berdasarkan representation prapelatih yang kuat menyebar dengan baik di berbagai bahasa, membuat mereka lebih dapat diterapkan dalam pengaturan dunia nyata.', 'fa': 'پیش\u200cبینی کیفیت ترجمه\u200cهای ماشین به طور سنتی با مدل\u200cهای ویژه\u200cی زبان، تحت فرض که توزیع برچسب\u200cهای کیفیت یا ویژگی\u200cهای زبان\u200cشناسی ویژگی\u200cهایی را نشان می\u200cدهند که در زبانها مشترک نمی\u200cشوند. ناتوانی مشخص این دستور نیاز برای داده\u200cهای برچسب برای هر جفت زبان داده شده است. ما این فرضیه را با تحقیق طریق های مختلف برای تحقیق کیفیت زیادی زبان (QE) چالش می\u200cکنیم، شامل استفاده از امتیاز از مدل ترجمه\u200cها. ما نشان می دهیم که این مدل\u200cهای یک زبان بیشتر انجام می\u200cدهند، مخصوصا در توزیع برچسب\u200cهای کیفیت کمتری و تنظیمات منابع کمتری. در مورد نهایت صفر شلیک QE نشان می دهیم که ممکن است دقیقا برای هر زبان جدید از مدل های آموزش به زبان دیگر پیش بینی کنیم. نتیجه\u200cهایمان نشان می\u200cدهند که مدل\u200cهای عصبی\u200cهای هنری که بر اساس نمایش\u200cهای پیش آموزش\u200cشده\u200cای قدرتمند در زبان\u200cها به صورت عمومی تغییر می\u200cدهند و آنها را در تنظیمات دنیای واقعی به کاربردی بیشتر می\u200cدهند.', 'ko': '전통적으로 기계 번역의 질을 예측하는 것은 특정 언어의 모델을 통해 해결되는데 전제는 품질 라벨의 분포나 언어 특징이 크로스 언어가 공유하지 않는 특징을 나타내는 것이다.이런 방법의 뚜렷한 단점은 주어진 언어마다 표기 데이터를 제공해야 한다는 것이다.우리는 번역 모델을 사용하는 점수를 포함한 다양한 언어 품질 평가(QE)의 다양한 방법을 모색함으로써 이 가설에 도전한다.우리는 이러한 모델이 단일 언어 모델보다 우수하다는 것을 발견했다. 특히 품질 라벨의 분포 불균형과 자원 설정이 비교적 낮은 상황에서.제로포QE의 극단적인 상황에서 우리는 다른 언어에서 훈련된 모델에서 새로운 언어의 질을 정확하게 예측하는 것이 가능하다는 것을 증명했다.우리의 연구 결과에 따르면 강력한 예훈련 표징을 바탕으로 하는 가장 선진적인 신경QE모델은 언어를 뛰어넘어 이를 현실 세계에 더욱 잘 적용할 수 있다.', 'tr': 'Makin terjimesiniň kalitesini öň bellenen adatça diller takyk nusgalar bilen çykylýar, sözleriň içinde paýlaşmaýan hasaplanyň ýa-da lingwistiki özellikleri belli edip bilýär. Bu ýazşyň belli mümkinçiligi her berilen dil çiftleri üçin etilen maglumatlar gereklidir. Biz bu tahmini çoklu dil kalitesi Taýýarlama (QE), terjime modellerinden notlary ulanarak çözerek çözeriz. Biz bu ýeke dil nusgalarynyň üstüne çykarýandygyny görkezýäris, ýöne taýýarlykly kalit etitleri taýýarlandyrylygyny we resurs düşürmeklerinde. QE-iň ahmal ýagdaýynda, başga dillerde bilinen örän täze diller üçin dykkatly tahmin etmek mümkin däldir. Biziň tapylyklarymyz sungat näural QE modelleriniň güýçli öň-bilim edilen täze köp dillerde üýtgeşirilýär we olaryň hakyky dünýä düzümlerinde has gowy uygulandyrýandygyny görkeýär.', 'sq': 'Parashikimi i cilësisë së përkthimit të makinave është trajtuar tradicionalisht me modele specifike gjuhës, nën supozimin se shpërndarja e etiketës së cilësisë apo karakteristikat gjuhësore tregojnë karakteristika që nuk janë të ndara nëpërmjet gjuhëve. Një pakënaqësi e qartë e kësaj qasje është nevoja për të dhëna të etiketuara për çdo çift gjuhësh të caktuar. Ne e sfidojmë këtë supozim duke eksploruar metoda të ndryshme për vlerësimin e cilësisë shumëgjuhëse (QE), duke përfshirë përdorimin e rezultateve nga modelet e përkthimit. Ne tregojmë se këto modele janë më të larta se modelet e gjuhës së vetme, veçanërisht në shpërndarjet më të ekuilibruara të etiketave të cilësisë dhe rregullimet me burime të ulëta. Në rastin ekstrem të QE zero-shot, ne tregojmë se është e mundur të parashikohet saktësisht cilësia për çdo gjuhë të dhënë të re nga modelet e trajnuar në gjuhë të tjera. Gjetjet tona tregojnë se modelet e QE neuronale të moderne bazuar në përfaqësime të fuqishme të paratrajnuara gjeneralizohen mirë nëpër gjuhë, duke i bërë ato më të aplikueshme në ambientet e botës reale.', 'sw': 'Kuandaa ubora wa tafsiri ya mashine kwa kawaida umejadiliwa na mifano maalum ya lugha, chini ya dhana kwamba usambazaji wa viwango vya habari au lugha huonyesha vibaya ambavyo haujasambazwa katika lugha mbalimbali. Hali ya wazi ya mbinu hii ni haja ya takwimu zilizotajwa kwa kila jingine aliyepewa lugha. Tunashindana na dhana hii kwa kutafuta mbinu tofauti za Uhitimu wa lugha mbalimbali (QE), ikiwa ni pamoja na kutumia score kutoka kwa mifano ya tafsiri. Tunaonyesha kuwa hii inafanya mifano ya lugha moja, hususani katika usambazaji wa ubora wa usawa wa usawa na mazingira ya rasilimali duni. Katika kesi ya QE isiyo na sifa, tunaonyesha kwamba inawezekana kutabiri viwango kwa uhakika kwa lugha yoyote inayopewa kipya kutoka kwa mifano inayofundishwa kwa lugha nyingine. Matokeo yetu yanaonyesha kuwa mifano ya kiserikali ya kiserikali inayohusiana na uwakilishi wenye nguvu wa zamani hujumuisha vizuri katika lugha mbalimbali, na kuwafanya kuwa na matumizi zaidi katika mazingira ya dunia halisi.', 'af': "Die kwaliteit van masjien vertaling is tradisioneel met taal-spesifieke modele gespreek, onder die aanvaar dat die kwaliteit etiket verspreiding of lingwisiese funksies uitbied eienskappe wat nie deur taal gedeel word nie. 'n Oorskynlike onderwerp van hierdie toegang is die benodig vir etiketeerde data vir elke gegewe taal paar. Ons probeer hierdie aanvaar deur verskillende toegange te exploreer na veelvuldige tale Kwaliteit Estimatie (QE), insluitend die gebruik van aantal van vertalingsmodelle. Ons wys dat hierdie enkele taal-modelles uitvoer, veral in minder balanse kwaliteit-etiket-verspreidings en lae-hulpbron-instellings. In die ekstrem geval van nul-skoot QE, wys ons dat dit moontlik is om te presies voorskou kwaliteit vir enige gegewe nuwe taal van modele wat op ander taal opgelei is. Ons bevestings wys dat state-of-the-art neural QE modele gebaseer op kragtige voorafgeleerde voorafgeleerde voorafgeleerde voorafgeleerde voorafgeleerde voorafgeleerde voorafgeleerde voorafgeleerde tale genereer, maak hulle meer toewenbaar in regte wêreld instellings.", 'am': 'በቋንቋዎች ውስጥ ያልተካፈሉ ብልሃት ወይም የቋንቋ ትርጉም ጥሩ በቋንቋ-specific ዓይነቶች በተጨማሪው ግንኙነት እና በቋንቋዎች ላይ ያልተካፈሉ ባስመሳሰብ ይታያል፡፡ An obvious disadvantage of this approach is the need for labelled data for each given language pair.  የቋንቋዎች ጥያቄ (QE) በመፍጠር የልዩ ልዩ ልዩ ደረጃዎችን በመፍጠር እናቃጥላለን፡፡ እነዚህን በአንድ ቋንቋ ምሳሌዎች እናሳየዋለን፣ ይልቁንም በትክክል እና ትንሽ የክፍለ ክፍል ማካላት እና በ ጽሑፍ በተደረገው የ/የ/የ/የ/የ/የ/የ/አዲስ ቋንቋ በተሰጠው አዲስ ቋንቋ ለማንኛውም እናስታውቃለን፡፡ ፍለጋዎቻችን የፀሐይ አካባቢ የኩነቶች የኩነቶች የኩነቶች የQE modelዎች በቋንቋዎች ሁሉ ላይ በመጠቀም እንዲያሳየቁ ያሳያል፡፡', 'hy': 'Predicting the quality of machine translation has traditionally been addressed with language-specific models, under the assumption that the quality label distribution or linguistic features exhibit traits that are not shared across languages.  Այս մոտեցումների ակնհայտ թերությունն այն է, որ յուրաքանչյուր լեզվի զույգի համար պիտակուցված տվյալներ պետք է: Մենք մարտահրավերում ենք այս ենթադրությունը բազմալեզու որակի գնահատման տարբեր մոտեցումների ուսումնասիրելով, ներառյալ թարգմանման մոդելների գնահատականները: Մենք ցույց ենք տալիս, որ այս մեկլեզու մոդելները ավելի լավ են աշխատում, հատկապես ավելի քիչ հավասարակշռություն ունեցող որակային պիտակների տարածումներում և ցածր ռեսուրսների միջոցներում: Զերոյական QE-ի ծայրահեղ դեպքում մենք ցույց ենք տալիս, որ հնարավոր է ճշգրիտ կանխատեսել ցանկացած նոր լեզու որակը այլ լեզուներով սովորեցված մոդելներից: Մեր հայտնաբերությունները ցույց են տալիս, որ ամենահետագա նյարդային QE մոդելները, հիմնված հզոր նախապատրաստված ներկայացումների վրա, լավ են ընդհանուր տարբեր լեզուներում, դարձնելով դրանք ավելի օգտագործելի իրական աշխարհի միջավայրում:', 'az': "Makinelərin çevirisinin keyfiyyətini təsdiqləyən təqdirdə dillər arasında paylaşılmayan özellikləri təsdiqləyən kimi dili təsdiqli modellərlə çəkilmişdir. Bu tərzimin açıq-aydın müsibəti hər dil çift üçün etiketli verilən məlumatlar lazımdır. Biz bu varlığı, çevirim modellerindən nöqtələri istifadə etmək üçün çoxlu dil kaliteli hesablama (QE) tərzlərinə müxtəlif tərzlərini keşf edirik. Biz bu tək dil modellərinin üstünlüyünü göstəririk, özlərinə də az balançılıq kaliteli etiketlərin dağıtılması və düşük resursu ayarları. Sıfır-vuruş QE'nin aşırı vaxtında, başqa dillərdə təhsil edilmiş modellərdən verilən hər hansı bir dil üçün təhsil edilmiş yeni dil üçün mümkün olduğunu göstəririk. Bizim tapındıqlarımız belə göstərir ki, sanat nöral QE modellərinin güclü əvvəlcə təhsil edilmiş göstəricilərə dayanan dillərdən çox yaxşı təhsil edir, onları həqiqət dünya ayarlarında daha uyğunlaşdırır.", 'bn': 'মেশিন অনুবাদের মান নির্ধারণের প্রেক্ষিতে সাধারণত ভাষা-নির্দিষ্ট মডেল দিয়ে ভাষায় ঠিকানা হয়েছে, অনুমানের অধীনে যে মান লেবেল বিতরণ অথবা ভাষাগত প্রত্যেক নির্দিষ্ট ভাষার জোড়ার জন্য লেবেল ডাটার প্রয়োজন। অনুবাদের মডেল থেকে স্কোর ব্যবহার করে আমরা এই ধারণাটিকে বিভিন্ন ধরনের উপায় ব্যবহার করতে চ্যালেঞ্জ করছি। আমরা দেখাচ্ছি যে এই একক ভাষার মডেলগুলো প্রকাশ করে, বিশেষ করে কম মানের মান বিতরণ এবং কম সম্পদের বৈশিষ্ট্যে। যে কোনো নতুন ভাষায় প্রশিক্ষণ প্রদান করা হয়েছে তার মান সঠিকভাবে ভবিষ্যদ্বাণী করা সম্ভব। আমাদের খুঁজে পাওয়া যাচ্ছে যে পূর্ব প্রশিক্ষিত প্রতিনিধিদের ভিত্তিতে ক্ষমতাশালী প্রতিনিধিদের ভিত্তিতে নিউরাল কিউই-এর রাষ্ট্র', 'ca': "La predicció de la qualitat de la traducció màquina ha estat tradicionalment abordada amb models específics de llenguatge, sota la suposició que la distribució de l'etiqueta de qualitat o les característiques lingüístices mostren trets que no es comparteixen entre llenguatges. Un desvantatge evident d'aquest enfocament és la necessitat de dades etiquetades per cada parell de llenguatges. Desafiam aquesta suposició explorant diferents enfocaments a l'Estimat de Qualitat Multilingüe (QE), inclosament fent servir puntuacions dels models de traducció. Ens demostram que aquests models de llenguatge únic superen, especialment en distribucions menys equilibrades d'etiquetes de qualitat i configuracions de baix recursos. En el cas extrem de QE de zero, demostram que és possible predir exactament la qualitat de qualsevol llenguatge dada a partir de models entrenats en altres llengües. Els nostres descobriments indiquen que els models de QE neural més avançats basats en representacions poderoses pré-entrenades s'generalitzen ben a través de les llengües, fent-los més aplicables en entorns del món real.", 'bs': 'Predviđanje kvalitete prevoda mašine tradicionalno je riješeno sa specijalnim jezikom modelima, pod pretpostavkom da distribucija kvalitetne etikete ili jezičke funkcije pokazuju osobine koje nisu dijeljene na jezicima. Očigledno nedostatak ovog pristupa je potreba za označenim podacima za svaki određeni jezički par. Mi izazivamo ovu pretpostavku istraživanjem različitih pristupa procjenama multijezičkih kvaliteta (QE), uključujući korištenje rezultata iz modela prevoda. Pokazujemo da su ovi jedinstveni modeli izvršene, posebno u manjoj balanciranoj distribuciji etikete kvalitete i nastavi niskih resursa. U ekstremnom slučaju 0-shot QE pokazujemo da je moguće precizno predvidjeti kvalitet svakog novog jezika iz modela obučenih na drugim jezicima. Naši nalazi ukazuju na to da state-of-the-art neural QE modeli bazirani na moćnim predobučenim predstavljanjima generalizuju dobro na jezicima, čineći ih primjenjivijima u stvarnom svijetu.', 'cs': 'Předpověď kvality strojového překladu byla tradičně řešena pomocí jazykově specifických modelů za předpokladu, že distribuce štítků kvality nebo jazykové rysy vykazují rysy, které nejsou sdíleny mezi jazyky. Zjevnou nevýhodou tohoto přístupu je potřeba označených dat pro každý jazykový pár. Tento předpoklad zpochybňujeme zkoumáním různých přístupů k vícejazyčnému odhadu kvality (QE), včetně použití skóre z překladových modelů. Ukazujeme, že tyto modely překonávají jednotlivé jazyky, zejména v méně vyvážených distribucích štítků kvality a nastaveních s nízkými zdroji. V extrémním případě nulové QE ukazujeme, že je možné přesně předpovídat kvalitu pro daný nový jazyk z modelů trénovaných na jiných jazycích. Naše zjištění naznačují, že nejmodernější neuronové modely QE založené na silných předškolených reprezentacích se dobře zobecňují napříč jazyky, což je činí více aplikovatelnými v reálném světě.', 'et': 'Masintõlke kvaliteedi prognoosimist on traditsiooniliselt käsitletud keelespetsiifiliste mudelitega eeldusel, et kvaliteedimärgise levikul või keelelistel omadustel on omadusi, mida keeltes ei jagata. Selle lähenemisviisi ilmselge puudus on vajadus iga keelepaari kohta märgistatud andmete järele. Me vaidlustame selle eelduse, uurides erinevaid lähenemisviise mitmekeelsele kvaliteedihindamisele, sealhulgas kasutades tõlkemudelite tulemusi. Näitame, et need on ühekeelsetest mudelitest paremad, eriti vähem tasakaalustatud kvaliteedimärgiste jaotamise ja vähese ressursiga seadete puhul. Äärmuslikul juhul näitame, et iga uue keele kvaliteeti on võimalik täpselt prognoosida teistes keeltes treenitud mudelitest. Meie tulemused näitavad, et võimsatel eelnevalt koolitatud esitustel põhinevad tipptasemel neurokvaliteedi kvaliteedi kvaliteedi kvaliteedi mudelid üldistavad hästi kõiki keeli, muutes need reaalses maailmas rakendatavamaks.', 'fi': 'Konekäännöksen laadun ennustamista on perinteisesti käsitelty kielikohtaisilla malleilla olettaen, että laatumerkin jakelussa tai kielellisissä ominaisuuksissa on piirteitä, joita ei ole jaettu eri kielillä. Tämän lähestymistavan ilmeinen haitta on se, että kutakin kieliparia varten tarvitaan merkittyjä tietoja. Haastamme tämän olettamuksen tutkimalla erilaisia lähestymistapoja monikieliseen laatuarviointiin (QE), mukaan lukien käännösmallien pisteytys. Osoitamme, että nämä ovat parempia kuin yksikieliset mallit, erityisesti vähemmän tasapainoisissa laatumerkkien jakeluissa ja vähävaraisissa asetuksissa. Nollashot QE:n äärimmäisessä tapauksessa osoitamme, että on mahdollista ennustaa tarkasti minkä tahansa uuden kielen laatua muilla kielillä koulutetuilla malleilla. Tuloksemme osoittavat, että tehokkaisiin esikoulutettuihin esityksiin perustuvat huipputekniset neurotason QE-mallit yleistyvät hyvin eri kielillä, tehden niistä käyttökelpoisempia reaalimaailmassa.', 'ha': "Idan ana gabatar da sifar fassarar maɓalli, an ƙidãya an yi addu'a da misãlai-masu ƙayyade cikin harshen, ana ƙara da zato, idan an yi zato da shirin rabon nau'in label ko kuma tsarin linguistic, sai ya nuna taƙaita waɗanda ba su yi raba shi ba a tsakanin lugha. Babu dalĩli da bayyane na wannan hanyarwa yana da amfani da data wanda aka rubũta wa kowace harshe biyu. Munã tsãge wannan zato da za'a sami hanyoyin daban-daban zuwa tsari na'awa na mulki-lingui (QEK), kamar da Muke yi amfani da misãlai masu fassari. Tuna nũna cewa waɗannan masu samun misãlai da ke cikin harshen ayuka guda, hususan cikin rabo masu da inganci da kuma kayan daidaita manyan resource. Yana nuna cewa ana iya ƙayyade tsarin tsari wa kowane harshen da aka bai wa zaɓani daga misãlai wanda aka sanar da cikin wasu harshe. FantayinMu na nuna cewa misalin-muhimmin neura na QEke, a kan karatun masu ƙarfin shiryuwa da ke gaba-wa-zaman wahalar da masu amfani da su a cikin lugha, kuma ya sanya su mafi masu amfani da a cikin daidaita-duniya halinsa.", 'sk': 'Predvidevanje kakovosti strojnega prevajanja je bilo tradicionalno obravnavano z modeli, specifičnimi za jezik, pod predpostavko, da distribucija oznake kakovosti ali jezikovne značilnosti kažejo lastnosti, ki se ne delijo med jeziki. Očitna pomanjkljivost tega pristopa je potreba po označenih podatkih za vsak jezikovni par. To predpostavko izpodbijamo z raziskovanjem različnih pristopov k večjezični oceni kakovosti (QE), vključno z uporabo rezultatov iz prevajalskih modelov. Pokazali smo, da ti modeli presegajo učinkovitost enojezikovnih modelov, zlasti pri manj uravnoteženih distribucijah oznak kakovosti in nastavitvah z nizkimi viri. V skrajnem primeru ničelnega QE pokažemo, da je mogoče natančno napovedati kakovost katerega koli novega jezika iz modelov, usposobljenih za druge jezike. Naše ugotovitve kažejo, da se najsodobnejši nevronski QE modeli, ki temeljijo na zmogljivih predhodno usposobljenih reprezentacijah, dobro posplošijo v vseh jezikih, zaradi česar so bolj uporabni v realnih okoljih.', 'jv': 'Ngubah ingkang kalitas karo terjamahan ing sampeyan anyar tentang karo model sing apik bangsane, nang supoyo kuwi nggawe bahsa etiket karo akeh alam sing paling dhéwé ngerasakno cara-teka sing ora kepulangan luwih. Open...Open dot dot dot Awak dhéwé éntuk luwih nggawe barang-luwih akeh sampeyan kanggo nggawe barang nggawe kalite-sampeyan kanggo multi-lenguangkat (qE), gambar nggawe Puntuan kanggo model terjamahan. Awak dhéwé ngerasakno ngono model sing wis ana luwih, ngomong nik nggawe daftar tentang karo nggawe kalite sing beraksi lan aturan sing wis ana-nesaturan. Ing cah sing wis nul-shot, kéné ngomong nik akeh iso nggantihan kowé ning ngerasahan luwih apik sing ngebrakno model sing ngebrakno banget wis ana. Ndheke awakdhéwé ngeranyirno ngomong nik model state-of-the-are-the-arts Neral Njuk supoyo supoyo-cara-ne susahe supoyo barang kelas kotak dhéwé, mengko iso dianggap liyane sing luwih apik dhéwé.', 'he': 'ניתן לנחש את איכות התרגום של מכונות התייחסו במסורתית עם דוגמנים ספציפיים לשפה, בהנחה שהפיצוץ של תווית איכות או תכונות שפתיים מציגים תכונות שלא משותפים בין שפות. בעיה ברורה של הגישה הזאת היא הצורך למידע מסוים לכל זוג שפה מסוים. We challenge this assumption by exploring different approaches to multilingual Quality Estimation (QE), including using scores from translation models.  אנו מראים שהדוגמנים האלה יוצאים יותר ממופעים בשפה אחת, במיוחד בהפיצות תוויות איכות פחות מאוזנות ומוסדות משאבים נמוכים. במקרה הקיצוני של QE אפס-ירי, אנחנו מראים שאפשר לחזות בדיוק איכות לכל שפה חדשה מסוימת ממודלים מאומנים בשפות אחרות. הממצאים שלנו מצביעים על דוגמני QE עצביים מוקדמים מבוססים על מייצגים חזקים מאומנים מראש מגנרלים היטב בכל שפות, הופכים אותם יותר אפשריים במסגרות בעולם האמיתי.', 'bo': 'སྐད་ཡིག་དམིགས་བསལ འདིའི་གཟུགས་སྐོར་གྱི་མི་གསལ་པོ་ཞིག་ནི་པར་རྟགས་བཀོད་པའི་ཆ་འཕྲིན་དང་། We challenge this assumption by exploring different approaches to multilingual Quality Estimation (QE), including using scores from translation models. ང་ཚོས་སྐད་ཡིག་ཆ་གཅིག་གི་མིག ངལ་བཤེར་གྱི་མིག་ཐག་ཅིག་གི་གནད་དོན་ཐག་ཏུ་འུ་ཅག་གིས་སྐད་ཡིག་གཞན་ཞིག་གིས་ཕན་རིགས་སྔོན་སྒྲིག་བྱེད་པའི་སྐད་རིགས ང་ཚོའི་མཐོང་སྣང་གིས་སྣང་གནས་སྟངས་དང་སྒྱུ་རྩལ་གནས་སྟངས་ཀྱི་དཔེ་གཞི་རྩ་བ་ནས་སྔོན་སྒྲིག'}
{'en': 'English-to-Chinese Transliteration with Phonetic Auxiliary Task E nglish-to- C hinese Transliteration with Phonetic Auxiliary Task', 'ar': 'تحويل صوتي من الإنجليزية إلى الصينية مع مهمة مساعدة صوتية', 'fr': "Translittération de l'anglais vers le chinois avec tâche phonétique auxiliaire", 'pt': 'Transliteração de inglês para chinês com tarefa auxiliar fonética', 'es': 'Transliteración del inglés al chino con tarea auxiliar fonética', 'ja': '音声補助タスク付き英語から中国語への翻訳', 'zh': '带语佐命者英译至中文音译', 'ru': 'Англо-китайская транслитерация с дополнительным фонетическим заданием', 'hi': 'ध्वन्यात्मक सहायक कार्य के साथ अंग्रेजी-से-चीनी लिप्यंतरण', 'ga': 'Traslitriú Béarla go Sínis le Tasc Cúnta Foghraíochta', 'hu': 'Angol-kínai átvitel fonetikus kiegészítő feladattal', 'ka': 'ფონეტიკური დახმარებელი პარამეტრებით ინგლისური- ჩინეთის ტრანსლიტაცია', 'el': 'Αγγλικά-κινέζικη μεταγραφή με φωνητική βοηθητική εργασία', 'kk': 'Фонетикалық көмекші тапсырманың ағылшын- қытайша транслитерациясы', 'mk': 'Name', 'ms': 'Name', 'mt': 'English-to-Chinese Transliteration with Phonetic Auxiliary Task', 'lt': 'English-to-Chinese Transliteration with Phonetic Auxiliary Task', 'it': 'Translitterazione inglese-cinese con compito ausiliario fonetico', 'pl': 'Transliteracja angielsko-chińska z zadaniem pomocniczym fonetycznym', 'ml': 'ഫോണെറ്റിക് ഓക്സിലിയറി ടാസ്കുമായി ഇംഗ്ലീഷില്\u200d നിന്നും ചൈനീസിലേക്കുള്ള പരിഭാഷ', 'sr': 'English-to-Chinese Transliteration with Phonetic Assistant Task', 'mn': 'Хятадаас Англи хэл болон Хятадаас Фонетикийн тусламжтай транслитераци', 'no': 'Engelsk- til kinesisk transliterasjon med fonetisk hjelpeoppgåve', 'so': 'Turjumista afka Finnishka iyo Shiino', 'ro': 'Transliterare engleză-chineză cu sarcină auxiliară fonetică', 'sv': 'Engelska-till-kinesiska translitering med fonetisk hjälpuppgift', 'ta': 'Name', 'si': 'ඉංග්\u200dරීසිය- ටි- චීනියාවට ප්\u200dරතික්\u200dරියාත්මක ක්\u200dරියාත්මක සමග ඉංග්\u200dරීසියාව', 'ur': 'انگلیسی سے چینی ٹرانس لیٹریشن فونیک اپنا کام کے ساتھ', 'uz': 'Name', 'vi': 'Dịch qua chữ tiếng Anh với Phonetic Auxiliary.', 'da': 'Engelsk-til-kinesisk translitering med fonetisk hjælpeopgave', 'bg': 'Английско- китайска транслитерация с фонетична помощна задача', 'nl': 'Engels-naar-Chinees transliteratie met fonetische hulptaak', 'hr': 'English-to-Chinese Transliteration with Phonetic Assistant Task', 'ko': '음성 보조 임무를 띤 영한 음역', 'fa': 'تغییر\u200cنویسی انگلیسی به چینی با کار کمک فونیک', 'sw': 'Tafsiri ya Kiingereza na Kichina kwa kazi ya Picha', 'af': 'Engels- na- Sjinese Transliterasie met Fonetiese Assistent Taak', 'tr': 'Iňlisçe-we Çinçe Haýyş Görevi bilen terjime etmek', 'de': 'Englisch-Chinesische Transliteration mit phonetischer Hilfsaufgabe', 'sq': 'English-to-Chinese Transliteration with Phonetic Auxiliary Task', 'am': 'እንግሊዝኛ-ወደ ቻይና ትርጓሜ ከፎኔቲክ Auxiliary Task', 'id': 'Transliterasi Bahasa Inggris ke Cina dengan Tugas Bantuan Phonetik', 'hy': 'Անգլերեն-չինական տրանսգրականություն ֆոնետիկ օգնական առաջադրանքով', 'az': 'Fonetik Yardımcıl Görevi ilə İngiliz-Çincə Transliterasyonu', 'cs': 'Přepis z angličtiny do čínštiny s fonetickou pomocnou úlohou', 'bs': 'English-to-Chinese Transliteration with Phonetic Assistant Task', 'bn': 'ফোনেটিক অ্যাক্সিলিয়ারি কাজের সাথে ইংরেজি থেকে চীনা অনুবাদ', 'ca': 'Transliteració anglesa-xinesa amb tasca fonètica auxiliar', 'et': 'Inglise - hiina transliteratsioon foneetilise abiülesandega', 'fi': 'Englanti - kiina Transliteration with Phonetic Auxiliary Tehtävä', 'sk': 'Angleško-kitajsko prevajanje s fonetičnim pomožnim opravilom', 'ha': '@ item Spelling dictionary', 'he': 'Name', 'bo': 'དབྱིན་ཡིག་ལས་རྒྱ་ནག་ལ་ཡིག་སྒྲུབ་གཏོང་བྱེད་ཀྱི་ལས་འགུལ་སྤྲོད་ཀྱི་ཡོད་པ', 'jv': 'Pernak-Perusahaan Inggris-Tarjamahan kanggo Kemerdekaan apakno'}
{'en': 'Approaching named entities transliteration as a Neural Machine Translation (NMT) problem is common practice. While many have applied various NMT techniques to enhance machine transliteration models, few focus on the linguistic features particular to the relevant languages. In this paper, we investigate the effect of incorporating phonetic features for English-to-Chinese transliteration under the multi-task learning (MTL) settingwhere we define a phonetic auxiliary task aimed to improve the generalization performance of the main transliteration task. In addition to our system, we also release a new English-to-Chinese dataset and propose a novel evaluation metric which considers multiple possible  transliterations  given a source name. Our results show that the multi-task model achieves similar performance as the previous state of the art with a  model  of a much smaller size.', 'ar': 'يعتبر الاقتراب من تحويل الأحرف للكيانات المسماة كمشكلة ترجمة آلية عصبية (NMT) ممارسة شائعة. في حين أن الكثيرين قد طبقوا تقنيات NMT المختلفة لتحسين نماذج الترجمة الآلية ، إلا أن القليل منهم يركز على السمات اللغوية الخاصة باللغات ذات الصلة. في هذه الورقة ، نحقق في تأثير دمج الميزات الصوتية للترجمة الصوتية من الإنجليزية إلى الصينية ضمن إعداد التعلم متعدد المهام (MTL) - حيث نحدد مهمة مساعدة صوتية تهدف إلى تحسين أداء التعميم لمهمة الترجمة الصوتية الرئيسية. بالإضافة إلى نظامنا ، قمنا أيضًا بإصدار مجموعة بيانات جديدة من الإنجليزية إلى الصينية ونقترح مقياس تقييم جديدًا يأخذ في الاعتبار الترجمات الصوتية المتعددة الممكنة مع ذكر اسم المصدر. تظهر نتائجنا أن نموذج المهام المتعددة يحقق أداءً مشابهًا للحالة الفنية السابقة مع نموذج بحجم أصغر بكثير.', 'fr': "L'approche de la translittération d'entités nommées comme un problème de traduction automatique neuronale (NMT) est une pratique courante. Alors que beaucoup ont appliqué diverses techniques de NMT pour améliorer les modèles de translittération automatique, peu se concentrent sur les caractéristiques linguistiques propres aux langues concernées. Dans cet article, nous étudions l'effet de l'intégration de caractéristiques phonétiques pour la translittération de l'anglais vers le chinois dans le cadre de l'apprentissage multitâche (MTL), où nous définissons une tâche auxiliaire phonétique visant à améliorer les performances de généralisation de la tâche de translittération principale. En plus de notre système, nous publions également un nouveau jeu de données de l'anglais vers le chinois et proposons une nouvelle métrique d'évaluation qui prend en compte plusieurs translittérations possibles en fonction d'un nom de source. Nos résultats montrent que le modèle multitâche atteint des performances similaires à celles de l'état de l'art antérieur avec un modèle de taille beaucoup plus petite.", 'es': 'Abordar la transliteración de entidades nombradas como un problema de traducción automática neuronal (NMT) es una práctica común. Si bien muchos han aplicado varias técnicas de NMT para mejorar los modelos de transliteración automática, pocos se centran en las características lingüísticas propias de los idiomas pertinentes. En este artículo, investigamos el efecto de incorporar características fonéticas para la transliteración del inglés al chino en el entorno de aprendizaje multitarea (MTL), donde definimos una tarea auxiliar fonética destinada a mejorar el rendimiento de generalización de la tarea de transliteración principal. Además de nuestro sistema, también publicamos un nuevo conjunto de datos de inglés a chino y proponemos una métrica de evaluación novedosa que considera múltiples transliteraciones posibles con un nombre de fuente. Nuestros resultados muestran que el modelo multitarea logra un rendimiento similar al del estado de la técnica anterior con un modelo de un tamaño mucho más pequeño.', 'pt': 'Abordar a transliteração de entidades nomeadas como um problema de tradução automática neural (NMT) é uma prática comum. Embora muitos tenham aplicado várias técnicas de NMT para aprimorar os modelos de transliteração de máquina, poucos se concentram nos recursos linguísticos específicos dos idiomas relevantes. Neste artigo, investigamos o efeito da incorporação de recursos fonéticos para transliteração de inglês para chinês sob a configuração de aprendizado multitarefa (MTL) - onde definimos uma tarefa auxiliar fonética destinada a melhorar o desempenho de generalização da tarefa principal de transliteração. Além de nosso sistema, também lançamos um novo conjunto de dados de inglês para chinês e propomos uma nova métrica de avaliação que considera várias transliterações possíveis a partir de um nome de origem. Nossos resultados mostram que o modelo multitarefa alcança desempenho semelhante ao estado da arte anterior com um modelo de tamanho muito menor.', 'ja': 'ニューラル・マシン・トランスレーション（ NMT ）問題として名前付き音訳の実体にアプローチすることは一般的な慣習である。多くの人は、機械音訳モデルを強化するために様々なNMT技術を適用してきたが、関連する言語に特有の言語学的特徴に焦点を当てる人はほとんどいない。本稿では，マルチタスク学習（ MTL ）設定の下で英語から中国語への音声変換に音声特徴を取り入れることの効果を検討し，音声補助タスクを定義して主な音声変換タスクの一般化性能の向上を目指した．当社のシステムに加えて、新しい英語から中国語へのデータセットをリリースし、ソース名が与えられた複数の可能な翻訳を考慮した新しい評価指標を提案します。私たちの結果は、マルチタスクモデルが、より小さなサイズのモデルで、以前の最先端と同様のパフォーマンスを達成することを示しています。', 'zh': '名实体音译为神经机器翻译 (NMT) 常见之道也。 虽众用NMT术以增机器音译模形,而罕有关言者。 本文之中,研多任务学(MTL)设下合语英汉音译之效,定义一语,以崇主音译之泛化。 自系统之外,发一新英译中文数据集,并立新评指标,当指标思定源名者数音译。 吾之的结果表明,多任务与先进相似者,尺寸小得多。', 'hi': 'एक तंत्रिका मशीन अनुवाद (NMT) समस्या के रूप में नामित संस्थाओं लिप्यंतरण के पास पहुंचना आम बात है। जबकि कई लोगों ने मशीन लिप्यंतरण मॉडल को बढ़ाने के लिए विभिन्न एनएमटी तकनीकों को लागू किया है, कुछ प्रासंगिक भाषाओं के लिए विशेष रूप से भाषाई विशेषताओं पर ध्यान केंद्रित करते हैं। इस पेपर में, हम मल्टी-टास्क लर्निंग (एमटीएल) सेटिंग के तहत अंग्रेजी-से-चीनी लिप्यंतरण के लिए ध्वन्यात्मक सुविधाओं को शामिल करने के प्रभाव की जांच करते हैं- जहां हम मुख्य लिप्यंतरण कार्य के सामान्यीकरण प्रदर्शन में सुधार करने के उद्देश्य से एक ध्वन्यात्मक सहायक कार्य को परिभाषित करते हैं। हमारे सिस्टम के अलावा, हम एक नया अंग्रेजी-से-चीनी डेटासेट भी जारी करते हैं और एक उपन्यास मूल्यांकन मीट्रिक का प्रस्ताव करते हैं जो स्रोत नाम दिए गए कई संभावित लिप्यंतरणों पर विचार करता है। हमारे परिणामों से पता चलता है कि बहु-कार्य मॉडल बहुत छोटे आकार के मॉडल के साथ कला की पिछली स्थिति के समान प्रदर्शन प्राप्त करता है।', 'ru': 'Подход к транслитерации именованных сущностей как к задаче нейронного машинного перевода (НМП) является обычной практикой. Хотя многие применяли различные методы НМТ для улучшения моделей машинной транслитерации, немногие сосредоточены на лингвистических особенностях, характерных для соответствующих языков. В данной работе мы исследуем эффект включения фонетических признаков для английско-китайской транслитерации в условиях многозадачного обучения (MTL), где мы определяем фонетическую вспомогательную задачу, направленную на улучшение обобщения выполнения основной задачи транслитерации. В дополнение к нашей системе, мы также выпускаем новый английско-китайский набор данных и предлагаем новую оценочную метрику, которая учитывает несколько возможных транслитераций с заданным именем источника. Наши результаты показывают, что многозадачная модель достигает такой же производительности, как и предыдущее состояние техники с моделью гораздо меньшего размера.', 'ga': 'Is cleachtas coitianta é dul i ngleic le traslitriú aonáin ainmnithe mar fhadhb Néar-Aistriúcháin Meaisín (NMT). Cé gur chuir go leor teicníochtaí éagsúla NMT i bhfeidhm chun samhlacha traslitrithe meaisín a fheabhsú, is beag duine a dhíríonn ar na gnéithe teangeolaíochta a bhaineann go háirithe leis na teangacha ábhartha. Sa pháipéar seo, déanaimid imscrúdú ar an éifeacht a bhaineann le gnéithe foghraíochta a ionchorprú le haghaidh traslitrithe Béarla go Sínis faoin socrú foghlama il-tasc (MTL) - áit a ndéanaimid sainmhíniú ar thasc cúnta foghraíochta a bhfuil sé mar aidhm aige feabhas a chur ar fheidhmíocht ginearálaithe an phríomhthasc traslitrithe. Chomh maith lenár gcóras, eiseoimid tacar sonraí nua Béarla-go-Sínis freisin agus molaimid méadrach meastóireachta nua a bhreithníonn iliomad traslitrithe féideartha nuair a thugtar ainm foinse dóibh. Léiríonn ár dtorthaí go mbaineann an tsamhail il-tasc feidhmíocht cosúil leis an úrscothacht roimhe seo le múnla de mhéid i bhfad níos lú.', 'it': "Approcciare la traslitterazione di entità denominate come un problema NMT (Neural Machine Translation) è pratica comune. Mentre molti hanno applicato varie tecniche NMT per migliorare i modelli di traslitterazione automatica, pochi si concentrano sulle caratteristiche linguistiche particolari delle lingue pertinenti. In questo articolo, esaminiamo l'effetto di incorporare caratteristiche fonetiche per la traslitterazione inglese-cinese sotto l'impostazione multi-task learning (MTL), dove definiamo un'attività fonetica ausiliaria finalizzata a migliorare le prestazioni di generalizzazione del compito principale di traslitterazione. Oltre al nostro sistema, pubblichiamo anche un nuovo dataset inglese-cinese e proponiamo una nuova metrica di valutazione che considera molteplici traslitterazioni possibili con un nome sorgente. I nostri risultati mostrano che il modello multi-task raggiunge prestazioni simili al precedente stato dell'arte con un modello di dimensioni molto più ridotte.", 'el': 'Η προσέγγιση της μεταγραφής ονομάτων οντοτήτων ως πρόβλημα Νευρικής Μηχανικής Μετάφρασης (NMT) είναι κοινή πρακτική. Ενώ πολλοί έχουν εφαρμόσει διάφορες τεχνικές για την ενίσχυση των μοντέλων μηχανικής μεταγραφής, λίγοι επικεντρώνονται στα γλωσσικά χαρακτηριστικά των σχετικών γλωσσών. Σε αυτή την εργασία, διερευνούμε την επίδραση της ενσωμάτωσης φωνητικών χαρακτηριστικών για την αγγλική-κινεζική μεταγραφή κάτω από τη ρύθμιση εκμάθησης πολλαπλών εργασιών (όπου καθορίζουμε μια φωνητική βοηθητική εργασία με στόχο τη βελτίωση της απόδοσης γενικοποίησης της κύριας εργασίας μεταγραφής. Εκτός από το σύστημά μας, κυκλοφορούμε επίσης ένα νέο σύνολο δεδομένων από Αγγλικά προς Κινέζικα και προτείνουμε μια νέα μετρική αξιολόγηση που εξετάζει πολλαπλές πιθανές μεταγραφές που δίνονται ένα όνομα πηγής. Τα αποτελέσματα μας δείχνουν ότι το μοντέλο πολλαπλών εργασιών επιτυγχάνει παρόμοια απόδοση με την προηγούμενη κατάσταση της τεχνολογίας με ένα μοντέλο πολύ μικρότερου μεγέθους.', 'hu': 'A nevezett entitások transzliterációjának megközelítése Neural Machine Translation (NMT) problémaként általános gyakorlat. Bár sokan különböző NMT technikákat alkalmaztak a gépi transzliterációs modellek javítására, kevesen összpontosítanak az érintett nyelvek nyelvi jellemzőire. Jelen tanulmányban az angol-kínai transzliteráció fonetikai funkcióinak beépítésének hatását vizsgáljuk a multifeladatos tanulás (MTL) beállítás alatt, ahol egy fonetikai segédfeladatot definiálunk, amely a fő transzliterációs feladat általánosítási teljesítményének javítására irányul. Rendszerünk mellett új angol-kínai adatkészletet is kiadunk, és egy új értékelési metrikát javasolunk, amely több lehetséges transzliterációt vesz figyelembe forrásnévvel. Eredményeink azt mutatják, hogy a többfeladatos modell hasonló teljesítményt ér el, mint a korábbi korszerű, sokkal kisebb méretű modell.', 'lt': 'Dažna praktika – kalbėti apie pavadintų subjektų transliteraciją kaip apie neuronų mašinų vertimo (NMT) problem ą. Nors daugelis naudojo įvairius NMT metodus mašinų transliteracijos modeliams tobulinti, nedaug dėmesio skiria kalbinėms savybėms, ypač atitinkamoms kalboms. Šiame dokumente tiriame fonetinių charakteristikų anglų ir kinų transliteracijos įtraukimo į daugiafunkcinį mokymąsi (MTL) nustatymą, kuriame apibrėžiama fonetinė pagalbinė užduotis, kuria siekiama pagerinti pagrindinės transliteracijos užduoties generalizaciją. Be mūsų sistemos, mes taip pat paskelbiame naują anglų ir Kinijos duomenų rinkinį ir siūlome naują vertinimo metriką, kurioje atsižvelgiama į daugelį galimų transliteracijų, nurodant šaltinio pavadinimą. Mūsų rezultatai rodo, kad daugelio užduočių modelis pasiekia panašius rezultatus kaip ankstesnė pažanga, o modelis yra daug mažesnis.', 'ka': 'სახელი ინტერნეტიების ტრანსლიტაცია როგორც ნეიროლური მაქინის ტრანსლიტაცია (NMT) პრობლემა არის საერთო პრობლემა. თუმცა ბევრი განსხვავებული NMT ტექნექციები მაქსინის ტრანსლიტაციის მოდელების გასაკეთებლად დააყენებენ, რამდენიმე ინგურისტიკური ფუნქციების განსაკუთრებულ ამ დომენტში ჩვენ განსხვავებთ ფონეტიკური ფუნეტიკური ფუნეტიკური განსხვავება ინგლისურად-ჩინეთის ტრანსლიტაციაზე (MTL) მრავალური მოსწავლების შემდეგ, სადაც ჩვენ განსაზღვრებთ ფონეტიკური დახმარებელი დავალება,  ჩვენი სისტემის დამატებით, ჩვენ ასევე ახალი ინგლისური-ჩინეთის მონაცემების სექტის გახსნა და ჩვენ ახალი მონაცემების მეტრიკის გადაწყვება, რომელიც მრავალ შესაძლებელი ტ ჩვენი წარმოდგენება ჩვენი მრავალ დავალების მოდელი მიიღება მსგავსი გამოყენება, როგორც წინა ხელოვნების მოდელი მცირე ზომის მოდელი.', 'ml': 'നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിനായി പേരുള്ള വസ്തുക്കള്\u200d ട്രാന്\u200dസ്ലേഷന്\u200d ചെയ്യുന്നത് പ്രശ്നം സ മെഷിന്\u200d ട്രാന്\u200dസ്ലിറ്റരേഷന്\u200d മോഡലുകള്\u200d വളര്\u200dത്താന്\u200d പലരും NMT ടെക്നിക്കേഷനുകള്\u200d പ്രയോഗിച്ചിട്ടുണ്ടെങ്കില്\u200d, ഈ പത്രത്തില്\u200d, ഇംഗ്ലീഷ്-ലേക്ക്-ചൈനീസ് ട്രാന്\u200dസ്ലേഷനിലേക്ക് ചേര്\u200dക്കുന്ന ഫോണെറ്റിക് ഗുണഗണങ്ങളുടെ പ്രഭാവം ഞങ്ങള്\u200d അന്വേഷിക്കുന്നു. പല ജോലി പഠിക്കുന്നതിന്\u200dറെ നമ്മുടെ സിസ്റ്റത്തിനു കൂടാതെ, ഞങ്ങള്\u200d ഒരു പുതിയ ഇംഗ്ലീഷില്\u200d നിന്നും ചൈനീസില്\u200d നിന്നും ഡാറ്റാസസെറ്റ് വിടുകയും, ഒരു നോവല്\u200d വിന്യാസവ നമ്മുടെ ഫലങ്ങള്\u200d കാണിക്കുന്നത് പലിപ്പണികളുടെ മാതൃകയാണെന്നാണ്, മുമ്പുള്ള കലാകാര്യത്തിന്റെ അവസ്ഥ പോലെ പ്രവര്\u200dത്തനങ', 'mt': 'L-approċċ tat-traslitterazzjoni ta’ entitajiet imsemmija bħala problem a tat-Traduzzjoni ta’ Magni Newrali (NMT) huwa prattika komuni. Filwaqt li ħafna applikaw diversi tekniki NMT biex itejbu l-mudelli tat-traslitterazzjoni tal-magni, ftit jiffokaw fuq il-karatteristiċi lingwistiċi partikolarment għall-lingwi rilevanti. In this paper, we investigate the effect of incorporating phonetic features for English-to-Chinese transliteration under the multi-task learning (MTL) setting-where we define a phonetic auxiliary task aimed to improve the generalization performance of the main transliteration task.  In addition to our system, we also release a new English-to-Chinese dataset and propose a novel evaluation metric which considers multiple possible transliterations given a source name.  Ir-riżultati tagħna juru li l-mudell multikompitu jikseb prestazzjoni simili għall-a ħħar avvanz b’mudell ta’ daqs ferm iżgħar.', 'ms': 'Approaching named entities transliteration as a Neural Machine Translation (NMT) problem is common practice.  Walaupun ramai telah melaksanakan teknik NMT berbeza untuk meningkatkan model transliterasi mesin, sedikit fokus pada ciri-ciri bahasa tertentu kepada bahasa yang berkaitan. Dalam kertas ini, kami menyelidiki kesan memasukkan fitur fonetik untuk transliterasi Inggeris-Cina di bawah tetapan pembelajaran-tugas berbilang (MTL) di mana kami takrifkan tugas fonetik bantuan yang bertujuan untuk meningkatkan prestasi generalisasi tugas transliterasi utama. Selain sistem kita, kita juga melepaskan set data bahasa Inggeris ke Cina baru dan melamar metrik penilaian baru yang menganggap pelbagai transliterasi yang mungkin diberikan nama sumber. Hasil kami menunjukkan bahawa model berbilang-tugas mencapai prestasi yang sama dengan keadaan seni terdahulu dengan model saiz jauh lebih kecil.', 'mk': 'Приближувањето на транслитерацијата на именуваните ентитети како проблем со преведувањето на невралните машини (НМТ) е обична практика. Иако многумина применија различни техники на НМТ за подобрување на машинските транслитерациски модели, малку се фокусираат на јазичните карактеристики посебни на релевантните јазици. In this paper, we investigate the effect of incorporating phonetic features for English-to-Chinese transliteration under the multi-task learning (MTL) setting-where we define a phonetic auxiliary task aimed to improve the generalization performance of the main transliteration task.  Покрај нашиот систем, исто така, објавуваме нов набор на англиски-кинески податоци и предложуваме нова метрика за евалуација која ги смета за многуте можни транслитерации со име на извор. Нашите резултати покажуваат дека мултизадачниот модел постигнува слична перформанса како претходната техничка состојба со модел од многу помала големина.', 'pl': 'Podejście do transliteracji nazwanych jednostek jako problemu neuronowego tłumaczenia maszynowego (NMT) jest powszechną praktyką. Chociaż wielu z nich zastosowało różne techniki NMT w celu ulepszenia modeli transliteracji maszynowej, niewielu skupia się na cechach językowych szczególnych dla odpowiednich języków. W niniejszym artykule badamy efekt włączenia funkcji fonetycznych dla transliteracji angielsko-chińskiej w ustawieniu wielozadaniowego uczenia się (MTL), gdzie definiujemy fonetyczne zadanie pomocnicze mające na celu poprawę wydajności uogólnienia głównego zadania transliteracyjnego. Oprócz naszego systemu udostępniamy również nowy zestaw danych angielsko-chiński oraz proponujemy nową metrykę oceny, która uwzględnia wiele możliwych transliteracji podanych nazwą źródła. Nasze wyniki pokazują, że model wielozadaniowy osiąga podobną wydajność jak poprzedni stan techniki z modelem o znacznie mniejszych rozmiarach.', 'ro': 'Abordarea transliterației entităților numite ca o problemă Neural Machine Translation (NMT) este o practică comună. Deși mulți au aplicat diferite tehnici NMT pentru a îmbunătăți modelele de transliterare automată, puțini se concentrează pe caracteristicile lingvistice specifice limbilor relevante. În această lucrare, investigăm efectul încorporării caracteristicilor fonetice pentru transliterația engleză-chineză în cadrul setării de învățare multi-task (MTL), unde definim o sarcină fonetică auxiliară menită să îmbunătățească performanța de generalizare a sarcinii principale de transliterație. În plus față de sistemul nostru, lansăm, de asemenea, un nou set de date engleză-chineză și propunem o nouă metrică de evaluare care ia în considerare mai multe transliterații posibile având un nume sursă. Rezultatele noastre arată că modelul multi-task obține performanțe similare cu cele de ultimă generație cu un model de dimensiuni mult mai mici.', 'sr': 'Približavanje transliteracije imenih entitata kao problem neuronskog prevoda mašine (NMT) je zajednička praksa. Iako su mnogi primjenjivali različite tehnike NMT za unapređenje modela transliteracije mašine, malo se fokusiralo na jezičke funkcije posebne na odgovarajućim jezicima. U ovom papiru istražujemo učinak uključenja fonetičkih karakteristika za transliteraciju engleskog i kineskog jezika u okviru multi task učenja (MTL), gde definišemo fonetički pomoćni zadatak koji je cilj poboljšavanja generalizacije glavnog transliteracije zadataka. Uz naš sistem, takođe oslobodimo novi set podataka engleskog na kinesko i predlažemo novu metriku za procjenu koja smatra više mogućih transliteracija pod izvornim imenom. Naši rezultati pokazuju da multi task model postigne slične izvedbe kao prethodno stanje umjetnosti sa modelom mnogo manje veličine.', 'si': 'Name ගොඩක් අනුවෙන් අනුවෙන් NMT තාක්ෂණය අනුවෙන් පද්ධතිය සඳහා පද්ධතිය පද්ධතිය විශ්වාස කරන්න, භාෂාවික විශේ මේ පත්තරේ අපි පරීක්ෂණය කරන්නේ ඉංග්\u200dරීසියෙන් චීනියාවට ප්\u200dරශ්නයක් සම්පූර්ණය කරලා ඉංග්\u200dරීසියාව සහ චීනියාවට ප්\u200dරශ්නයක් සම්පූර්ණය කරනවා මුළු  අපේ පද්ධතිය සමග, අපි අළුත් ඉංග්\u200dරීසියාව චීනියාවට තොරතුරු සෙට් එකක් නිර්මාණය කරනවා ඒ වගේම පුළුවන් විශ්වාස කරන්න අපේ ප්\u200dරතිචාරය පෙන්වන්නේ වැඩි වැඩි වැඩි වැඩි වැඩි වැඩේ ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක් වෙනුවෙන් වැඩි වැ', 'mn': 'Нүүрстөрөгчийн нэрлэгдсэн биетүүдийг мэдрэлийн машин хөгжүүлэх (NMT) асуудал гэж ойртох нь ерөнхий дасгал юм. Ихэнх нь машин орчуулах загваруудыг нэмэгдүүлэхэд өөр өөр NMT технологийг ашигласан ч хэд хэд хэд хэд хэд хэд хэд хэд хэдэн анхаарлаа хандуулдаг. Энэ цаасан дээр бид Англи-аас Хятадад олон ажлын суралцах сургалтын доорх (MTL) боловсруулахын тулд фонетик тусламжтай ажиллагааг тодорхойлдог. Гэхдээ бид англи-аас Хятадад ихэнх ажиллагааны ерөнхийлөгчийн үйл ажиллагааг сайжруулахын тулд зо Бид бас Англи-т Хятадаас шинэ өгөгдлийн санг ашиглаж, эх үүсвэрийн нэр өгсөн олон боломжтой илтгэлийг ойлгох шинэ дүгнэлтийн метрик санал болгож байна. Бидний үр дүнд олон ажлын загвар нь урлагийн өмнөх байдалтай адилхан үйл ажиллагааг бага хэмжээний загвартай гаргадаг.', 'so': 'Waxyaabaha la magacaabay u soo turjumista sida tarjumaadda Masiinka Neural (NMT) waa wax caadi ah. Inta lagu jiro qaar badan waxay codsadeen qaabab kala duduwan oo ay u kordhisaan qaababka qaabilaadda maskaxda, waxaa ka mid ah kuwo yar oo ku kalsoonaada luuqadaha ku qoran. Qoraalkan waxaynu ka baaraynaa saamaynta ku saabsan qoraalka afka finnishka ee Ingiriiska-iyo-Shiino, taasoo lagu qorayo waxbarashada shaqada badan (MTL) oo lagu qorayo shaqo la xiriira telefonetka ah oo loogu talagalay inuu horumariyo sameynta sameynta shaqada hoosta u dhexeeya. Sidoo kale nidaamka aan ka sokeyno, waxaynu bixinaynaa koob cusub ee warqada ingiriisiga iyo Shiino, waxaana soo jeedinaynaa qiimeynta warqadda oo ka fiirsan karta qoraal badan oo suurtagal ah oo magac ku qoran. Abaalkayaga waxay muuqataa in qaababka shaqada badan uu helo wax la mid ah oo la mid ah xaaladdii hore ee farshaxanku uu ku sameynayo tusaale aad u yar.', 'no': 'Nærming av transliterasjon med namn på einingar som eit problem med Neuralmaskinsomsetjing (NMT) er vanleg praksis. Selv om mange har brukt forskjellige NMT-teknikk for å forbetra maskinetransliterasjonsmodeller, få fokus på språk-funksjonane spesielt for dei relevante språka. I denne papiret undersøker vi effekten på å inkludere fonetiske funksjonar for engelsk-til-kinesisk transliterasjon under innstillinga av fleire oppgåver (MTL), der vi definerer ein fonetisk hjelpeoppgåve som er målt å forbedra generelliseringen av hovudtransliterasjonsoppgåva. I tillegg til systemet vårt, så lager vi også ein ny dataset for engelsk til kinesisk og foreslår eit nytt evalueringsmetrisk som ser på fleire mulige transliterasjonar gjeve eit kjeldenamn. Resultatet våre viser at multioppgåvemodellen gjer liknande utviklingar som den førre tilstanden av kunsten med eit modell med mykje mindre storleik.', 'kk': 'Нейрондық машинаны аудару (NMT) мәселесі ретінде аталған нысандарды аудару - жалпы практика. Көпшілігі машинаның транслитерациялық үлгілерін көтеру үшін әртүрлі NMT техникаларын қолдануға болады, бірақ тілдерге арнайы лингвистикалық қасиеттеріне көп назар Бұл қағазда біз ағылшын және қытайша аудару үшін фонетикалық мүмкіндіктерді бірнеше тапсырма оқыту (MTL) бағдарламасында фонетикалық көмекші тапсырманы анықтап, негізгі транслитерациялық тапсырманың жалпы жұмысын жасау үшін,  Біздің жүйемізге қосымша, жаңа ағылшын тілінен қытайша деректер жинағын шығару және көзінің атауы берілген бірнеше мүмкін транслитерацияларды қалайтын жаңа оқиға метрикалық мә Біздің нәтижелеріміз көп тапсырмалар үлгісінің алдыңғы өзінің көп өлшемінің үлгісі мен ұқсас істеу үлгісін көрсетеді.', 'sv': 'Att närma sig namngivna entiteters transliteration som ett NMT-problem är vanligt förekommande. Många har tillämpat olika NMT-tekniker för att förbättra maskintransliterationsmodeller, men få fokuserar på de språkliga egenskaper som är specifika för de relevanta språken. I denna uppsats undersöker vi effekten av att införliva fonetiska funktioner för engelsk-kinesisk transliteration under inställningen multi-task learning (MTL), där vi definierar en fonetisk hjälpuppgift som syftar till att förbättra generaliseringen av huvudtransliterationsuppgiften. Utöver vårt system släpper vi också en ny engelsk-kinesisk datauppsättning och föreslår en ny utvärderingsmetod som beaktar flera möjliga transliterationer med ett källnamn. Våra resultat visar att multi-task modellen uppnår liknande prestanda som tidigare state of the art med en modell av mycket mindre storlek.', 'ta': 'Name While many have applied various NMT techniques to enhance machine transliteration models, few focus on the linguistic features particular to the relevant languages.  இந்த காக்கியத்தில், நாம் ஆங்கிலத்தில் இருந்து சீனா மாற்றியமைப்பிற்கான போன்டிக் குணங்களை சேர்க்க வேண்டும் விளைவுகளை தேர்வு செய்கிறோம் பல பணிகள் கற்றுக்கொள்ளும்  எங்கள் கணினியை தவிர, நாம் ஒரு புதிய ஆங்கிலத்தில் இருந்து சீனா தரவுத்தளத்தை வெளியிடுகிறோம் மற்றும் ஒரு புதிய பரிசோதனை மெட்ரிக்கை  முடிவு', 'ur': 'نائرل ماشین ترجمہ (NMT) کے طور پر ذریعہ انٹیٹیوں کے نام کی ترجمہ کے قریب حاصل کرنے کا مشکل معمول ہے. اگرچہ بہت سے NMT ٹیکنالوٹی موڈل کو زیادہ کرنے کے لئے مختلف ٹیکنالوٹی استعمال کر رہے ہیں، بہت سے زبان شناسی موجودات پر مشترک زبانوں کے ذریعہ تدبیر کررہے ہیں۔ ہم اس کاغذ میں تحقیق کرتے ہیں کہ انگلیسی سے چینی ٹرانسلیٹریشن کے لئے فونیٹیکی ویژگی کا اثر جمع کرنا (MTL) کے مطابق جہاں ہم ایک فونیٹیکی مددگاری تابع کا مطابق مقرر کرتے ہیں جو اصلی ٹرانسلیٹریشن تابع کی عمومی فعالیت کو بہتر کرنا چاہتا ہے۔ ہمارے سیستم کے علاوہ، ہم نے بھی ایک نئی انگلیسی سے چینی ڈاٹ سٹ آزاد کر دی اور ایک نئی ارزیابی متریک کی پیشنهاد کرتی ہے جو بہت سی ممکن ترنسلیٹریشن کو سورج نام دیا گیا ہے۔ ہمارے نتیجے دکھاتے ہیں کہ بہت سے دنیا کی موڈل ایسی طرح کامیابی حاصل کرتا ہے جیسے پہلے هنر کی حالت کے ساتھ بہت چھوٹی اندازہ کی مدل سے۔', 'uz': "Name Ko'pchilik bir xil NMT teknikalarni mashina tarjima modellarini oshirish uchun qo'llangan edi, bir nechta lingvistik xususiyatlariga muhit tilga foydalanish mumkin. Bu hujjatda biz bir necha vazifa o'rganishda ingliz-Xitoycha tarjimalarning fonetik xossalarini o'rganish natijasida o'rganish natijasida foydalanuvchi vazifani aniqlashimiz mumkin. Biz tizimimizning tillaridan ham yangi ingliz tilida Xitoycha maʼlumotlar tarkibini chiqaramiz va novel qiymatini o'ylab, bir nechta tarjima qilish muvaffaqiyatlarini o'ylab turadi. Our results show that the multi-task model achieves similar performance as the previous state of the art with a model of a much smaller size.", 'vi': 'Tiếp cận các thực thể có tên là dịch chuyển dạng thần kinh (NMB) là vấn đề thông thường. Trong khi nhiều kỹ thuật NMB đã áp dụng nhiều kỹ thuật để cải thiện các mô hình xuyên tạc cỗ máy, rất ít tập trung vào các đặc điểm ngôn ngữ liên quan. Trong tờ giấy này, chúng tôi nghiên cứu kết quả của việc nhập các tính năng ngữ âm cho việc chuyển chữ Anh-Trung Quốc dưới thiết lập các tập tin đa nhiệm vụ (MTV) nơi chúng tôi xác định một nhiệm vụ hỗ trợ ngữ âm nhằm cải thiện khả năng tổng hợp của nhiệm vụ chuyển dạng chính. Ngoài hệ thống của chúng ta, chúng ta cũng phát hành một tập tin mới giữa Anh và Trung Quốc và đề xuất một hệ thống đánh giá mới, xem xét nhiều khả năng chuyển dạng với một tên nguồn. Kết quả của chúng tôi cho thấy mô hình đa nhiệm vụ đạt được hiệu quả tương tự như trạng thái nghệ thuật trước đây với mô hình kích thước nhỏ hơn nhiều.', 'bg': 'Приближаването на транслитерацията на имената като проблем с невралния машинен превод (НМТ) е често срещана практика. Въпреки че мнозина са приложили различни техники за подобряване на моделите за машинна транслитерация, малцина се фокусират върху езиковите особености, специфични за съответните езици. В настоящата статия изследваме ефекта от включването на фонетични характеристики за английско-китайската транслитерация при настройката за многозадачно обучение (МТЛ), където дефинираме фонетична помощна задача, насочена към подобряване на генерализацията на основната транслитерационна задача. В допълнение към нашата система, ние също така пускаме нов английско-китайски набор от данни и предлагаме нов измервателен показател, който отчита множество възможни транслитерации, дадено име на източника. Нашите резултати показват, че мултизадачният модел постига сходни резултати като предишното състояние на изкуството с модел с много по-малък размер.', 'nl': 'Het benaderen van benoemde entiteiten transliteratie als een Neural Machine Translation (NMT) probleem is gebruikelijk. Hoewel velen verschillende NMT-technieken hebben toegepast om machine transliteration modellen te verbeteren, richten weinigen zich op de linguïstische kenmerken die specifiek zijn voor de relevante talen. In dit artikel onderzoeken we het effect van het opnemen van fonetische functies voor Engels-naar-Chinees transliteratie onder de multi-task learning (MTL) instelling, waarbij we een fonetische hulptaak definiëren gericht op het verbeteren van de generalisatieprestaties van de hoofdtransliteratietaak. Naast ons systeem brengen we ook een nieuwe Engels-Chinees dataset uit en stellen we een nieuwe evaluatie metric voor die rekening houdt met meerdere mogelijke transliteraties met een bronnaam. Onze resultaten tonen aan dat het multitask model vergelijkbare prestaties behaalt als de vorige state of the art met een model van een veel kleiner formaat.', 'da': 'At nærme sig navngivne entiteter transliteration som et NMT-problem (Neural Machine Translation) er almindelig praksis. Mens mange har anvendt forskellige NMT teknikker til at forbedre maskintransliterationsmodeller, fokuserer få på de sproglige træk, der er særlige for de relevante sprog. I denne artikel undersøger vi effekten af at indarbejde fonetiske funktioner til engelsk-kinesisk transliteration under multi-task learning (MTL)-indstillingen – hvor vi definerer en fonetisk hjælpeopgave, der har til formål at forbedre generaliseringen af den vigtigste transliterationsopgave. Ud over vores system udgiver vi også et nyt engelsk-kinesisk datasæt og foreslår en ny evalueringsmetric, der tager højde for flere mulige translitterationer givet et kildenavn. Vores resultater viser, at multi-task modellen opnår samme ydeevne som den tidligere state of te art med en model af en meget mindre størrelse.', 'de': 'Die Transliteration benannter Entitäten als neuronale maschinelle Übersetzung (NMT) ist gängige Praxis. Während viele verschiedene NMT-Techniken angewendet haben, um maschinelle Transliterationsmodelle zu verbessern, konzentrieren sich nur wenige auf die sprachlichen Besonderheiten der jeweiligen Sprachen. In diesem Beitrag untersuchen wir den Effekt der Integration phonetischer Merkmale für die Englisch-Chinesische Transliteration unter der Multi-Task Learning (MTL)-Einstellung, wobei wir eine phonetische Hilfsaufgabe definieren, die die Generalisierungsleistung der Haupttransliterationsaufgabe verbessern soll. Zusätzlich zu unserem System veröffentlichen wir auch einen neuen englisch-chinesischen Datensatz und schlagen eine neuartige Auswertungsmetrik vor, die mehrere mögliche Transliterationen mit Quellnamen berücksichtigt. Unsere Ergebnisse zeigen, dass das Multitask-Modell mit einem wesentlich kleineren Modell ähnliche Leistungen erzielt wie der bisherige Stand der Technik.', 'ko': '명명된 솔리드 음역을 신경 기계 번역(NMT) 문제로 처리하는 것은 흔히 볼 수 있는 방법이다.많은 사람들이 이미 각종 NMT 기술을 응용하여 기계의 음역 모델을 강화했지만 관련 언어 특유의 언어 특징에 주목하는 사람은 드물다.본고에서 우리는 다중 임무 학습(MTL) 환경에서 음성 특징을 영한 음역에 융합시키는 효과에 대해 연구했다. MTL 환경에서 우리는 음성 보조 임무를 정의하여 주요 음역 임무의 범용 성능을 향상시키는 데 목적을 둔다.우리 시스템을 제외하고 우리는 새로운 영한 데이터 집합을 발표했고 새로운 평가 지표를 제시했다. 이 지표는 소스 이름에 대한 여러 가지 가능한 음역을 고려했다.우리의 결과에 따르면 다중 임무 모델의 성능은 이전의 기술 수준과 비슷하고 모델의 크기가 훨씬 작다는 것을 알 수 있다.', 'fa': 'به عنوان یک مشکل ترجمه ماشین عصبی (NMT) نزدیک شدن به عنوان تغییر نامیده\u200cها تمرین معمولی است. در حالی که بسیاری از تکنیک های NMT مختلف را برای افزایش مدلهای ترجمه ماشین استفاده کردند، کمی روی ویژگی های زبان\u200cشناسی خاص برای زبان\u200cهای مربوط به تمرکز کردند. در این کاغذ، ما تحقیق می کنیم که تاثیر فنی برای تغییرات انگلیسی به چینی در زیر تعلیم یادگیری چندین کار (MTL) تعریف می کنیم که ما یک کار کمک تلفنی را تعریف می کنیم که هدف دارد تا عملکرد ژنرالیزی عمومی از کار تغییرات اصلی را بهتر کند. علاوه بر سیستم ما، یک مجموعه داده\u200cهای انگلیسی به چینی جدید را آزاد می\u200cکنیم و یک متریک ارزیابی تازه را پیشنهاد می\u200cکنیم که چندین ترجمه\u200cهای ممکن را به نام منبع می\u200cرساند. نتیجه\u200cهای ما نشان می\u200cدهند که مدل چندین کاری به عنوان وضعیت قبلی هنر با مدل اندازه\u200cی بسیار کوچکتر رسیده است.', 'sw': 'Approaching named entities transliteration as a Neural Machine Translation (NMT) problem is common practice.  Wakati wengi wametumia mbinu mbalimbali za NMT kuongeza mifano ya usambazaji wa mashine, wachache wakijikita kwenye lugha hususani kwa lugha zinazohusika. Katika karatasi hii, tunachunguza madhara ya kuingiza vipengenezo vya simu kwa ajili ya tafsiri za Kiingereza na Kichina chini ya mafunzo ya kazi nyingi (MTL) ambapo tunaelezea kazi ya ushirikiano wa simu kwa lengo la kuboresha utengenezaji wa kazi kuu ya tafsiri. In addition to our system, we also release a new English-to-Chinese dataset and propose a novel evaluation metric which considers multiple possible transliterations given a source name.  Matokeo yetu yanaonyesha kuwa mtindo wa kazi nyingi unafanikiwa utendaji huo kama hali ya zamani ya sanaa yenye mfano wa ukubwa mdogo sana.', 'af': "Toegang aan genoem entiteite transliterasie as 'n Neurale Masjien Vertaling (NMT) probleem is gemeenskap praksie. Alhoewel baie verskillende NMT-teknike toewend het om masjien transliterasie-modele te verbeter, sommige fokus op die lingwisiese funksies spesifieke aan die relevante tale. In hierdie papier, ons ondersoek die effek van die inkorporering van fonetiese funksies vir Engels-na-Sjinese transliterasie onder die multi-taak leer (MTL) instelling-waar ons 'n fonetiese hulpbruk definieer wat die generellisering effekte van die hoof transliterasie taak is om te verbeter. In addition to our system, we also release a new English-to-Chinese data set and propose a novel evaluation metric which considers multiple possible transliterations given a source name. Ons resultate wys dat die multi-taak model soos die vorige staat van die kuns met 'n model van 'n baie kleiner grootte bereik.", 'tr': 'Adynyň terjime edilmegi näral Maşynyň terjime edilmegi (NMT) kynçylykdyr. Birnäçe NMT tehnikalary maşynyň terjime etmek üçin üýtgetmek üçin ullanýarlar, birnäçe dillerde nähili möhüm dillere üns berilýär. Bu kagyzda, biz İngilizçe-Çinçe terjime etmekleriň (MTL) köp işi öwrenmesiniň astynda fonetik kömek täbliklerini bejermek üçin fonetik üýtgewlerini barlaýarys. Biziň sistemimize daşary, biz hem täze bir iňlisçe-Çinçe veri setirini çykaryp, birnäçe çeşme adynda mümkin terjime edip biljek täze bir metrik maslahat berýäris. Biziň netijelerimiz köp-täblik nusgasynyň öňki ýagdaýynyň öňki ýagdaýynda birnäçe kiçi ululyk nusgasy bilen meňzeşlik ukyplaryny çykarýandygyny görkez.', 'id': 'Approaching named entities transliteration as a Neural Machine Translation (NMT) problem is common practice.  Sementara banyak telah menerapkan berbagai teknik NMT untuk meningkatkan model transliterasi mesin, sedikit fokus pada fitur bahasa khusus untuk bahasa yang relevan. Dalam kertas ini, kami menyelidiki efek dari memasukkan fitur fonetik untuk transliterasi Inggris-Cina di bawah pengaturan belajar multi-tugas (MTL) di mana kami mendefinisikan tugas fonetik bantuan yang bertujuan untuk meningkatkan prestasi generalisasi tugas transliterasi utama. Selain sistem kita, kita juga melepaskan set data bahasa Inggris ke Cina baru dan mengusulkan metrik evaluasi baru yang mempertimbangkan banyak transliterasi yang mungkin diberikan nama sumber. Hasil kami menunjukkan bahwa model multi-tugas mencapai prestasi yang sama dengan keadaan seni sebelumnya dengan model yang jauh lebih kecil.', 'hy': 'Ներոլ մեքենայի թարգմանման (NMT) խնդիրը սովորական գործընթաց է: While many have applied various NMT techniques to enhance machine transliteration models, few focus on the linguistic features particular to the relevant languages.  Այս թղթի մեջ մենք ուսումնասիրում ենք անգլերեն-չինական տրանսգրականության ֆոնետիկ հատկանիշների ներառման ազդեցությունը բազմախնդիր սովորելու (MTL) միջոցով, որտեղ մենք սահմանում ենք ֆոնետիկ օգնական խնդիր, որի նպատակն է բարելավել գլխավոր տրանսգրականության խնդիրը: Բացի մեր համակարգից, մենք նաև հրապարակում ենք նոր անգլերեն-չինական տվյալների համակարգ և առաջարկում ենք նոր գնահատման մետրիկ, որը հաշվի առնում է բազմաթիվ հնարավոր տրանսգրականություններ աղբյուրի անունով: Մեր արդյունքները ցույց են տալիս, որ բազմախնդիրների մոդելը հասնում է նմանատիպ արտադրողությունների, ինչպիսին նախկին արվեստի վիճակը, շատ ավելի փոքր մոդելի միջոցով:', 'am': 'የኔural machine ትርጉም (NMT) መከራ የተለየ ነው፡፡ ብዙዎቹ የNMT ቴክክኖችን በመሣሪያው መተካካት ሞዴላዎችን ለመጨመር ሲጠይቁ፣ ለቋንቋው በተለየ ቋንቋዎች ላይ ጥቂቶች ማጠቃለያቸውን ያስተካክሉ፡፡ በዚህ ፕሮግራም፣ የፌንቲካዊ ምርጫዎችን ለመቀበል የንግግሊዝና-ወደ ቻይና ትርጓሜዎችን ለመቀበል እናሳውቃለን፡፡ ከስውተታችን በቀር አዲስ እንግሊዝኛ-ወደ ቻይና ዳታዎችን እናስፈቅዳለን፡፡ ፍሬዎቻችን ብዙዎች-ስራ ዓይነት እንደ ቀድሞው የዐርብ ሁኔታ ብጤ በጣም ትንሽ መጠን የሚመስል ነው፡፡', 'bn': 'নিউরাল মেশিন অনুবাদ হিসেবে নামের বস্তুগুলোর ট্রান্সলিপারেশন (এনএমটি) সমস্যা সাধারণ প্রশিক্ষণ। এদিকে অনেকেই মেশিন ট্রান্সলিটারেশন মডেল বৃদ্ধি করতে এনএমটি বিভিন্ন কৌশল প্রয়োগ করেছে, কিন্তু সামান্য ভাষার বিশেষ ভাষার এই কাগজটিতে আমরা অনেক কাজ শিক্ষার অধীনে ইংরেজী থেকে চীনা ট্রান্সলিকেশনের (এমটিএল) ফোনেটিক বৈশিষ্ট্যাবলিক বিষয়গুলোর মধ্যে যোগাযোগ করার প্রভাব তদন্ত করি যেখানে আমরা একটি ফোন In addition to our system, we also release a new English-to-Chinese dataset and propose a novel evaluation metric which considers multiple possible transliterations given a source name.  আমাদের ফলাফল দেখা যাচ্ছে যে মাল্টিক কাজের মডেলটি পূর্ববর্তী শিল্পের পরিস্থিতির মতো কার্যক্রম অর্জন করেছে যার মাধ্যমে', 'bs': 'Približavanje transliteracije imenih entitata kao problem neurološkog prevoda stroja (NMT) je uobičajena prakse. Iako su mnogi primjenjivali različite tehnike NMT-a za unapređenje modela transliteracije strojeva, malo se fokusiralo na jezičke funkcije posebne na odgovarajućim jezicima. U ovom papiru istražujemo učinak uključenja fonetičkih karakteristika za transliteraciju engleskog i kineskog jezika u okviru multi task učenja (MTL), gdje definiramo fonetički pomoćni zadatak koji cilja poboljšati generalizaciju glavnog transliteracije zadataka. Uz naš sistem, također oslobodimo novi set podataka engleskog na kinesko i predlažemo novu metriku za procjenu koja smatra više mogućih transliteracija pod izvornim imenom. Naši rezultati pokazuju da multi task model postigne slične izvedbe kao prethodno stanje umjetnosti sa modelom mnogo manje veličine.', 'sq': 'Përqafimi i transliteracionit të njësive të quajtura si një problem i përkthimit të makinave nervore (NMT) është praktika e zakonshme. Ndërsa shumë kanë aplikuar teknika të ndryshme NMT për të përmirësuar modelet e transliteracionit të makinave, pak përqëndrohen në karakteristikat gjuhësore të veçanta në gjuhët e duhura. Në këtë letër, ne hetojmë efektin e përfshirjes së karakteristikave fonetike për transliteracionin anglez-kinez nën përcaktimin e mësimit me shumë detyra (MTL) ku ne përcaktojmë një detyrë fonetike ndihmëse që synon të përmirësojë performancën e gjeneralizimit të detyrës kryesore transliteracioni. Përveç sistemit tonë, ne gjithashtu lëshojmë një set të ri të dhënash angleze-kineze dhe propozojmë një metrik të ri vlerësimi që konsideron transliteracione të shumta të mundshme duke dhënë një emër burimi. Rezultatet tona tregojnë se modeli me shumë detyra arrin performancë të ngjashme me gjendjen e mëparshme të artit me një model me një madhësi shumë më të vogël.', 'az': 'Nöral Makin Çevirməsi (NMT) problemi olaraq adlı entitələrin transliterasyona yaxınlaşması ortaq praksidir. Çoxların makinelərin transliterasyon modellərini artırmaq üçün müxtəlif NMT tehniklərini uyguladıqları halda, çoxların məxluqat dillərinə müəyyən edilən dillərə məxsus dillərin dillərinə məxsusdur. Bu kağızda, İngilizə-Çinlə transliterasyon üçün çoxlu-iş öyrənməsi (MTL) təyin edilməsində fonetik kömək işlərini təyin edirik ki, böyük transliterasyon işlərinin generalizasiyasını yaxşılaşdırmaq niyyətində olan bir fonetik kömək işlərini təyin edirik. Bizim sistemimizə həmçinin yeni İngilizce-Çinlə verilən verilən qurbanı yayındırırıq və bir yeni değerlendirmə metrik təklif edirik ki, çoxlu mümkün mənbə adı verilən transliterasyonları düşünür. Bizim sonuçlarımız çoxlu iş modeli, sanatın əvvəlki durumu kimi çoxlu kiçik ölçüdə modellə eyni olaraq başa düşər.', 'hr': 'Približavanje transliteracije imenih entitata kao problem neurološkog prevoda stroja (NMT) je uobičajena prakse. Iako su mnogi primjenjivali različite tehnike NMT-a za poboljšanje modela transliteracije strojeva, malo se fokusiralo na jezičke funkcije posebne na odgovarajućim jezicima. U ovom papiru istražujemo učinak uključenja fonetičkih karakteristika za transliteraciju engleskog i kineskog jezika u okviru višestrukog učenja (MTL), gdje definiramo fonetički pomoćni zadatak koji cilja poboljšati generalizaciju učinka glavnog transliteracije. Osim našeg sustava, također oslobodimo novi set podataka engleskog na kinesko i predlažemo novu metriku za procjenu koja smatra više mogućih transliteracija s obzirom na izvorno ime. Naši rezultati pokazuju da multizadatačni model postigne slične funkcije kao prethodno stanje umjetnosti s modelom mnogo manje veličine.', 'cs': 'Přistupování k transliteraci pojmenovaných entit jako k problému neuronového strojového překladu (NMT) je běžnou praxí. Zatímco mnozí aplikovali různé NMT techniky ke zlepšení strojových transliteračních modelů, jen málokdo se zaměřuje na jazykové vlastnosti specifické pro příslušné jazyky. V tomto článku zkoumáme vliv začlenění fonetických vlastností pro transliteraci z angličtiny do čínštiny v nastavení multi-tasking learning (MTL), kde definujeme fonetický pomocný úkol zaměřený na zlepšení zobecnění hlavního transliteračního úkolu. Kromě našeho systému vydáváme také nový datový soubor anglicko-čínsko-čínských dat a navrhujeme novou hodnotící metriku, která bere v úvahu více možných transliterací s názvem zdroje. Naše výsledky ukazují, že víceúlohový model dosahuje podobného výkonu jako předchozí stav techniky u modelu mnohem menší velikosti.', 'et': 'Nimetatud üksuste transliteratsiooni käsitlemine neuromasintõlke (NMT) probleemina on tavaline tava. Kuigi paljud on masintransliteratsioonimudelite täiustamiseks rakendanud mitmesuguseid NMT-meetodeid, keskenduvad vähesed asjaomaste keelte keelelistele omadustele. Käesolevas töös uurime foneetiliste funktsioonide lisamise mõju inglise-hiina transliteratsioonile mitme ülesandega õppimise (MTL) seadetes, kus määratleme foneetilise abiülesande, mille eesmärk on parandada põhilise transliteratsiooniülesande üldistamisjõudlust. Lisaks oma süsteemile anname välja ka uue inglise-hiina andmekogumi ja pakume välja uue hindamismeetodi, mis arvestab mitut võimalikku transliteratsiooni allika nime andmisel. Meie tulemused näitavad, et mitme ülesandega mudel saavutab palju väiksema suurusega mudeliga sarnase jõudluse kui eelmine tehnika tasemel.', 'fi': 'Nimettyjen entiteettien transliteraation lﾃ､hestyminen neurokonekﾃ､ﾃ､nnﾃｶsongelmana (NMT) on yleinen kﾃ､ytﾃ､ntﾃｶ. Vaikka monet ovat soveltaneet erilaisia NMT-tekniikoita konetransliteraatiomallien parantamiseksi, harvat keskittyvﾃ､t kieliominaisuuksiin, jotka ovat ominaisia asianomaisille kielille. Tﾃ､ssﾃ､ tyﾃｶssﾃ､ tutkitaan foneettisten ominaisuuksien sisﾃ､llyttﾃ､misen vaikutusta englannin-kiinan transliteraatioon monitehtﾃ､vﾃ､oppimisen (MTL) puitteissa, jossa mﾃ､ﾃ､ritellﾃ､ﾃ､n foneettinen aputehtﾃ､vﾃ､, jonka tarkoituksena on parantaa pﾃ､ﾃ､asiallisen transliteraatiotehtﾃ､vﾃ､n yleistymistﾃ､. Jﾃ､rjestelmﾃ､mme lisﾃ､ksi julkaisemme uuden englannin-kiinan aineiston ja ehdotamme uutta arviointimittaria, joka huomioi useita mahdollisia transliteraatioita lﾃ､hteen nimen perusteella. Tuloksemme osoittavat, ettﾃ､ monitehtﾃ､vﾃ､malli saavuttaa saman suorituskyvyn kuin edellinen huipputekninen malli paljon pienemmﾃ､llﾃ､ mallilla.', 'ca': "Aproximar la transliteració d'entitats anomenades com un problem a de traducció de màquines neuronales (NMT) és pràctica comú. Tot i que moltes han aplicat diverses tècniques NMT per millorar els models de transliteració màquina, pocs s es centren en les característiques lingüístices particulars a les llengües pertinents. En aquest article investigam l'efecte de l'incorporació de característiques fonètiques per la transliteració anglès-xinesa sota l'entorn d'aprenentatge multitasca (MTL) on definim una tasca fonètica auxiliar mirada a millorar el rendiment de generalització de la tasca principal de transliteració. A més del nostre sistema, també alliberam un nou conjunt de dades anglès-xinès i proposem una nova mesura d'evaluació que considera múltiples transliteracions possibles donant un nom de font. Els nostres resultats demostren que el model multitasca aconsegueix un rendiment similar a l'estat d'art anterior amb un model de mida molt més petita.", 'sk': 'Pristopanje do transliteracije imenovanih entitet kot težave z nevralnim strojnim prevajanjem (NMT) je običajna praksa. Medtem ko so mnogi uporabili različne NMT tehnike za izboljšanje modelov strojne transliteracije, se malo osredotoča na jezikovne značilnosti, ki so posebne za ustrezne jezike. V prispevku smo raziskali učinek vključevanja fonetičnih funkcij za angleško-kitajsko transliteracijo pod nastavitvijo večopravilnega učenja (MTL), kjer smo opredelili fonetično pomožno nalogo, namenjeno izboljšanju uspešnosti generalizacije glavne transliteracijske naloge. Poleg našega sistema izdajamo tudi nov angleško-kitajski nabor podatkov in predlagamo novo meritev ocenjevanja, ki upošteva več možnih transliteracij, ki jih daje ime vira. Naši rezultati kažejo, da večopravilni model dosega podobno zmogljivost kot prejšnji najsodobnejši model z veliko manjšo velikostjo.', 'ha': "Approaching named entities transliteration as a Neural Machine Translation (NMT) problem is common practice.  Wakati da mãsu yawa sun yi amfani da wasu masu motsi na NMT dõmin ƙarani da misãlai mai transliteratori na mashine, sai kaɗan sun yi zura kan fassarar-harshen masu husũma. Daga wannan takardan, Munã jãyayya muhimmin ka shigar da wasu sifafai na fomat wa littafin Ingiriya-zuwa-China a ƙarƙashin da aka sanar da shi masu multi-aikin (MTL) a wurin da Muke bayyana wani aikin mataimaki na fonet don ya yi amfani da wajen ƙari ga aikin na muhimmin transliteratori. Ga baka na'asarmu, za'a saka wani danne na Ingiriya-zuwa-China kuma munã buƙata wani littãfi da aka ƙayyade littãfin nan da ke ƙayyade misalin wasu masu yiwuwa da aka bãyar da sunan source. MatamayinMu na nũna cewa misalin mulki ya sami mai kama da halin na farko na sanar da wani misali mai ƙaranci.", 'he': 'התקרבות לטרנסליטציה של ישויות בשם כבעיה של מכונת נוירולית (NMT) היא מעשה נפוץ. בעוד רבים השתמשו בטכניקות NMT שונות כדי לשפר דוגמנים טרנסליטציה מכונות, מעט מתמקדים במיוחדים הלשוניים לשפות הרלוונטיות. בעיתון הזה, אנו חוקרים את ההשפעה של הכילוי של תכונות פונטיות לטרנסליטציה אנגלית-לסינית תחת ההגדרה של הלימוד המון משימות (MTL) שבו אנו מגדירים משימה עוזרת פונטית שמתכוונת לשפר את ביצועי הגנרליזציה של המשימה העיקרית של הטרנסליטציה. In addition to our system, we also release a new English-to-Chinese dataset and propose a novel evaluation metric which considers multiple possible transliterations given a source name.  התוצאות שלנו מראות שהמודל המולט משימה משיג ביצועים דומים למצב האמנות הקודם עם מודל בגודל הרבה יותר קטן.', 'bo': 'མིང་ཡོད་པའི་དབྱིབས་ཚུལ་སྒྱུར་གྱི་རྩིས་འཁོར་ལ་སྤྲོད་ཀྱི་དཀའ་ངལ་བ་ཞིག་དང་མཐུན་སྣུམ་རེད། སྐད་རིགས་མང་པོ་ཞིག་གིས་མིང་ཚོའི་འགྱུར་བ་སྤྱོད་ཀྱི་ཐབས་ལམ་འདྲ་མིན་མང་པོ་ཞིག་ཡིན་ནའང་། སྐད་རིགས ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཡིག In addition to our system, we also release a new English-to-Chinese dataset and propose a novel evaluation metric which considers multiple possible transliterations given a source name. ང་ཚོའི་འབྲུག', 'jv': 'Ngubah kang dipunangé karo nganggo penting nggambar kelas telas urip Nyural Majin Terjamahan (NMT) kuwi perintah sing dibenaké. Eror akèh sing sampeyan aplikasi sistem NMT sampeyan kanggo ngubah model karo perusahaan alêr, durung nggawe perspek kanggo langgar-ingkang kesèhku kanggo langgar. Nang pepulan iki, kita yatênggunaké efek kanggo nggawe peringatan pangan saiki nggo nyebuturan pangan lan basa sing nyebutaké Multi-task Learning (MTL) kang ndherengé awak dhéwé nyong nggunaké petani sing berarti sing nyebutaké nggawe nguasai perusahaan langgar sampek kang nggawe nguasai nggawe nguasai perusahaan nggo kuwi nggawe Nambah ning sistem sing, kita mulai nggambar dataset sing bagian Inggris-kanggo Kemerdekaan karo barang nggawe sistem sing beraksi basa sing nyebutke sing isih perusahaan pangan bangrungan. Kita ngomong nik akeh multi-task model kuwi nggawe akeh operasi layan karo status layan karo model sing apik akeh basa sing apik.'}
{'en': 'Predicting and Using Target Length in  Neural Machine Translation', 'ar': 'توقع واستخدام طول الهدف في الترجمة الآلية العصبية', 'es': 'Predicción y uso de la longitud objetivo en la traducción automática neuronal', 'pt': 'Prevendo e usando o comprimento de destino na tradução automática neural', 'fr': 'Prédiction et utilisation de la longueur cible dans la traduction automatique neuronale', 'ja': '神経機械翻訳における目標長の予測と使用', 'zh': '在神经机器翻译中占用长短', 'ru': 'Прогнозирование и использование целевой длины в нейронном машинном переводе', 'hi': 'भविष्यवाणी और तंत्रिका मशीन अनुवाद में लक्ष्य लंबाई का उपयोग करना', 'ga': 'Fad Sprioc a Thuar agus a Úsáid san Aistriú Meaisín Néarthach', 'hu': 'A célhossz előrejelzése és használata a neurális gépi fordításban', 'it': "Prevedere e utilizzare la lunghezza dell'obiettivo nella traduzione automatica neurale", 'kk': 'Нейрондық машинаның аудармасында мақсатты ұзындығын таңдау және қолдану', 'lt': 'Predicting and Using Target Length in Neural Machine Translation', 'mk': 'Предвидување и употреба на должина на целта во превод на неврални машини', 'ka': 'მისამართი სიგრძე ნეიროლური მაქინის გადაწყვეტაში და გამოყენება', 'el': 'Προβλέποντας και χρησιμοποιώντας το μήκος στόχου στην Νευρική Μηχανική Μετάφραση', 'ml': 'നെയുറല്\u200d മെഷീനിലെ ലക്ഷ്യം ഉപയോഗിക്കുന്നതിന്റെ നീളം', 'mt': 'Il-Previżjoni u l-Użu tat-Tul tal-Għan fit-Traduzzjoni tal-Magna Newrali', 'mn': 'Цахилгаан машины хөрөнгө дамжуулалт болон хэрэглэх', 'no': 'Forhåndsvising og bruk mållengde i neuralmaskineomsetjing', 'ms': 'Mengimbas dan menggunakan Panjang Sasaran dalam Terjemahan Mesin Neural', 'ro': 'Predicția și utilizarea lungimii țintă în traducerea automată neurală', 'pl': 'Przewidywanie i używanie długości docelowej w neuronowym tłumaczeniu maszynowym', 'sr': 'Predviđanje i korištenje ciljne dužine u neurološkom prevodu mašine', 'si': 'න්\u200dයුරාල් මැෂින් පරිවර්තනයේ ලක්ෂණ ලාමාව භාවිත කරන්න හා ප්\u200dරශ්නය කරන්න', 'sv': 'Förutsäge och användning av mållängd i neural maskinöversättning', 'so': 'Horumarinta iyo isticmaalka gaadiidka dhererka ee Maamulka Neural', 'ur': 'نئورل ماشین ترجمہ میں موقع لانگ کی پیش بینی اور استعمال کرنا', 'ta': 'நெயுரால் இயந்திரத்தில் இலக்கு நீளம் மொழிபெயர்ப்பில் முன்னேற்றம் மற்றும் பயன்படுத்துகிறது', 'uz': 'Tarjima', 'vi': 'Định trước và sử dụng địa điểm trong phiên dịch máy thần kinh', 'da': 'Forudsigelse og brug af mållængde i neural maskinoversættelse', 'hr': 'Predviđanje i korištenje ciljne dužine u neurološkom prevodu strojeva', 'bg': 'Прогнозиране и използване на целевата дължина в невралния машинен превод', 'nl': 'Voorspelling en gebruik van doellengte in neuronale machinevertaling', 'id': 'Prediksi dan Menggunakan Panjang Target dalam Translation Mesin Neural', 'de': 'Vorhersage und Verwendung der Ziellänge in der neuronalen maschinellen Übersetzung', 'ko': '신경기계 번역 중 목표 길이의 예측 및 사용', 'fa': 'پیش\u200cبینی و استفاده از طول هدف در ترجمه ماشین عصبی', 'sw': 'Utengenezaji na kutumia lengo katika Tafsiri ya Mashine ya Neural', 'af': 'Voorskou en gebruik Teël Lengte in Nural Masjien Vertaling', 'tr': 'Neural Mazmunlar terjimesinde Mazmunlar Uňluky Taýýan we ullanýa', 'am': 'ትርጉም', 'hy': 'Նյարդային մեքենայի թարգմանման համար նպատակի երկարությունը կանխատեսելը և օգտագործելը', 'sq': 'Parashikimi dhe përdorimi i gjatësisë së objektivit në përkthimin e makinës nervore', 'bn': 'নিউরাল মেশিন অনুবাদে টার্গেটের দৈর্ঘ্য ও ব্যবহার করা হচ্ছে', 'az': 'Nöral Makin Tərcümündə Məqsəd Uzunluğunu Və İstifadə Et', 'ca': "Predictir i utilitzar la llargada de l'objectiu en la traducció de la màquina neuronal", 'bs': 'Predviđanje i korištenje ciljne dužine u neurološkom prevodu mašine', 'cs': 'Předpověď a použití cílové délky v neuronovém strojovém překladu', 'et': 'Sihtmärkpikkuse prognoosimine ja kasutamine neuroaalses masintõlkes', 'fi': 'Tavoitteen pituuden ennustaminen ja käyttö hermojen konekäännöksessä', 'jv': 'Layihke lan Ngawe Perintah tanggal kang angka dibutuhke', 'sk': 'Predvidevanje in uporaba ciljne dolžine v nevralnem strojnem prevajanju', 'he': 'צפוי ושימוש באורך המטרה בתרגום מכונת נוירואלית', 'ha': 'Predicting and Using Target Length in Neural Machine Translation', 'bo': 'Neural Machine Translation ནང་དུ་དམིགས་འབེན་གྱི་རིང་ཚད་སྔོན་སྒྲིག་དང་སྤྱོད་པ'}
{'en': 'Attention-based encoder-decoder models have achieved great success in neural machine translation tasks. However, the lengths of the target sequences are not explicitly predicted in these  models . This work proposes length prediction as an auxiliary task and set up a  sub-network  to obtain the length information from the  encoder . Experimental results show that the length prediction sub-network brings improvements over the strong baseline system and that the predicted length can be used as an alternative to length normalization during decoding.', 'ar': 'حققت نماذج وحدة فك التشفير والتشفير القائمة على الانتباه نجاحًا كبيرًا في مهام الترجمة الآلية العصبية. ومع ذلك ، لا يتم توقع أطوال التسلسلات المستهدفة بشكل صريح في هذه النماذج. يقترح هذا العمل التنبؤ بالطول كمهمة مساعدة وإنشاء شبكة فرعية للحصول على معلومات الطول من المشفر. تظهر النتائج التجريبية أن الشبكة الفرعية للتنبؤ بالطول تجلب تحسينات على نظام خط الأساس القوي وأنه يمكن استخدام الطول المتوقع كبديل لتطبيع الطول أثناء فك التشفير.', 'pt': 'Modelos de codificador-decodificador baseados em atenção obtiveram grande sucesso em tarefas de tradução automática neural. No entanto, os comprimentos das sequências alvo não são previstos explicitamente nesses modelos. Este trabalho propõe a previsão de comprimento como tarefa auxiliar e configura uma sub-rede para obter as informações de comprimento do codificador. Resultados experimentais mostram que a sub-rede de previsão de comprimento traz melhorias em relação ao sistema de linha de base forte e que o comprimento previsto pode ser usado como uma alternativa à normalização de comprimento durante a decodificação.', 'fr': "Les modèles encodeur-décodeur basés sur l'attention ont connu un grand succès dans les tâches de traduction automatique neuronale. Cependant, les longueurs des séquences cibles ne sont pas explicitement prévues dans ces modèles. Ce travail propose la prédiction de longueur comme tâche auxiliaire et met en place un sous-réseau pour obtenir les informations de longueur du codeur. Les résultats expérimentaux montrent que le sous-réseau de prédiction de longueur apporte des améliorations par rapport au système de base solide et que la longueur prévue peut être utilisée comme alternative à la normalisation de longueur pendant le décodage.", 'es': 'Los modelos de codificador-decodificador basados en la atención han logrado un gran éxito en las tareas de traducción automática neuronal. Sin embargo, las longitudes de las secuencias diana no se predicen explícitamente en estos modelos. Este trabajo propone la predicción de longitud como una tarea auxiliar y establece una subred para obtener la información de longitud del codificador. Los resultados experimentales muestran que la subred de predicción de longitud aporta mejoras con respecto al sistema de base fuerte y que la longitud predicha puede usarse como una alternativa a la normalización de longitud durante la decodificación.', 'ja': '注意に基づくエンコーダデコーダモデルは、ニューラル機械翻訳タスクで大きな成功を収めました。しかしながら、標的配列の長さは、これらのモデルにおいて明示的に予測されない。本作業では、補助的な作業として長さ予測を提案し、エンコーダから長さ情報を取得するためのサブネットワークを設定する。実験結果は、長さ予測サブネットワークが強力なベースラインシステムに対して改善をもたらし、予測された長さをデコード中の長さ正規化の代替として使用することができることを示している。', 'zh': '基于意力之编码器-解码器,形于神经机器翻译务, 大有成功。 然中未显式占序之长也。 立一子网,取息于编码器。 实验结果表明,子网络比强基线统有所改,可以为解码归一化代方。', 'hi': 'ध्यान-आधारित एन्कोडर-डिकोडर मॉडल ने तंत्रिका मशीन अनुवाद कार्यों में बड़ी सफलता हासिल की है। हालांकि, इन मॉडलों में लक्ष्य अनुक्रमों की लंबाई की स्पष्ट रूप से भविष्यवाणी नहीं की गई है। यह कार्य एक सहायक कार्य के रूप में लंबाई की भविष्यवाणी का प्रस्ताव करता है और एन्कोडर से लंबाई की जानकारी प्राप्त करने के लिए एक उप-नेटवर्क सेट करता है। प्रयोगात्मक परिणामों से पता चलता है कि लंबाई की भविष्यवाणी उप-नेटवर्क मजबूत बेसलाइन सिस्टम पर सुधार लाता है और यह कि अनुमानित लंबाई को डिकोडिंग के दौरान लंबाई सामान्यीकरण के विकल्प के रूप में इस्तेमाल किया जा सकता है।', 'ru': 'Модели кодер-декодер, основанные на внимании, достигли больших успехов в задачах нейронного машинного перевода. Однако длины целевых последовательностей в этих моделях явно не предсказаны. Эта работа предлагает прогнозирование длины в качестве вспомогательной задачи и настройку подсети для получения информации о длине от кодера. Экспериментальные результаты показывают, что подсеть прогнозирования длины приносит улучшения по сравнению с сильной базовой системой и что прогнозируемая длина может быть использована в качестве альтернативы нормализации длины во время декодирования.', 'ga': "D'éirigh thar barr le samhlacha ionchódóra-díchódóra atá bunaithe ar aird i dtascanna néaraistriúcháin meaisín. Mar sin féin, ní dhéantar faid na seicheamh sprice a thuar go sainráite sna samhlacha seo. Molann an obair seo réamh-mheastachán faid mar thasc cúnta agus bunaítear fo-líonra chun an t-eolas faid a fháil ón ionchódóir. Léiríonn torthaí turgnamhacha go dtugann an fo-líonra réamhaisnéise faid feabhsuithe ar an gcóras bonnlíne láidir agus gur féidir an fad tuartha a úsáid mar mhalairt ar normalú faid le linn díchódaithe.", 'hu': 'A figyelem alapú útmérő-dekódoló modellek nagy sikert értek el az idegi gépi fordítási feladatokban. A célszekvenciák hosszát azonban ezekben a modellekben nem jósolják meg kifejezetten. Ez a munka kiegészítő feladatként javasolja a hosszúság előrejelzését, és hozzon létre egy alhálózatot, hogy megszerezze a hosszúsági információkat a kódolótól. Kísérleti eredmények azt mutatják, hogy a hosszúság-előrejelző alhálózat javulást hoz az erős alaprendszerhez képest, és hogy a várható hossz a dekódolás során használható a hosszúság normalizálásának alternatívájaként.', 'ka': 'დაახლოებით კოდერის რეკოდერების მოდელები უფრო წარმატებულია ნეიროლური მაქინის გაგრძელების მოქმედებში. მაგრამ, მისაღების სიგრძე ამ მოდელში არ არის განსაზღვრებული. ეს სამუშაო მუშაობა განმავლობა როგორც დახმარებელი სამუშაო დააყენება და სამუშაო ქსელის დაყენება, როგორც კოდერიდან სიგრძე ინფორმაცია მიიღებ ექსპერიმენტიური წარმოდგენები აჩვენებს, რომ სისტემის სისტემის ძალიან სისტემის შესაძლებლობა და რომ წარმოდგენილი სიგრძე შეიძლება გამოიყენება ალტენტიფიკაცია სიგრძე ნორმა', 'it': "I modelli encoder-decoder basati sull'attenzione hanno raggiunto un grande successo nelle attività di traduzione automatica neurale. Tuttavia, le lunghezze delle sequenze target non sono esplicitamente previste in questi modelli. Questo lavoro propone la previsione della lunghezza come attività ausiliaria e imposta una sottorete per ottenere le informazioni sulla lunghezza dall'encoder. I risultati sperimentali mostrano che la sottorete di previsione della lunghezza apporta miglioramenti rispetto al sistema di base forte e che la lunghezza prevista può essere utilizzata come alternativa alla normalizzazione della lunghezza durante la decodifica.", 'el': 'Τα μοντέλα κωδικοποιητών-αποκωδικοποιητών με βάση την προσοχή έχουν επιτύχει μεγάλη επιτυχία σε εργασίες νευρολογικής μηχανικής μετάφρασης. Ωστόσο, τα μήκη των ακολουθιών στόχων δεν προβλέπονται ρητά σε αυτά τα μοντέλα. Η παρούσα εργασία προτείνει την πρόβλεψη μήκους ως βοηθητικό έργο και τη δημιουργία ενός υποδικτύου για την απόκτηση των πληροφοριών μήκους από τον κωδικοποιητή. Τα πειραματικά αποτελέσματα δείχνουν ότι το υποδίκτυο πρόβλεψης μήκους φέρνει βελτιώσεις σε σχέση με το ισχυρό σύστημα βάσης και ότι το προβλεπόμενο μήκος μπορεί να χρησιμοποιηθεί ως εναλλακτική λύση στην ομαλοποίηση μήκους κατά την αποκωδικοποίηση.', 'kk': 'Назардағы кодер- декодер үлгілері неврал машинаның аудару тапсырмаларында үлкен сәтті жетті. Бірақ, мақсатты реттеулердің ұзындығы бұл үлгілерде тұрақты көрсетілмейді. Бұл жұмыс көмекші тапсырма ретінде ұзындығын бақылау және кодерден ұзындық мәліметін алу үшін ішкі желіні орнату. Эксперименталдық нәтижелер ұзындығын бақылау желінің күшті негізгі жүйесіне жақсарту және бақылаған ұзындығын декодтау кезінде ұзындығын нормализациялау альтернативі ретінде қолданыла', 'mk': 'Моделите на кодер-декодер базирани на внимание постигнаа голем успех во задачите за превод на невровните машини. However, the lengths of the target sequences are not explicitly predicted in these models.  Оваа работа предлага предвидување на должината како помошна задача и поставува подмрежа за да се добие информација за должината од кодерот. Експерименталните резултати покажуваат дека подмрежата за предвидување на должината носи подобрувања во однос на силниот основен систем и дека предвидената должина може да се користи како алтернатива на нормализацијата на должината за време на декодирањето.', 'lt': 'Atidžiai pagrįsti kodavimo kodavimo modeliai pasiekė didelę sėkmę atliekant nervinių mašin ų vertimo užduotis. Tačiau šiuose modeliuose tikslinių sekų ilgis aiškiai nenumatytas. Šiame darbe siūloma kaip pagalbinė užduotis numatyti ilgius ir sukurti posistemį, kad būtų gauta informacijos apie ilgius iš koduotojo. Eksperimentiniai rezultatai rodo, kad ilgumo prognozavimo posistemis pagerina stiprią bazinę sistemą ir kad prognozuojamas ilgis gali būti naudojamas kaip alternatyva ilgio normalizavimui dekoduojant.', 'ms': 'Model pengekod-dekoder berdasarkan perhatian telah mencapai sukses besar dalam tugas terjemahan mesin saraf. Namun, panjang urutan sasaran tidak dijangka secara eksplicit dalam model ini. Kerja ini melamar ramalan panjang sebagai tugas bantuan dan tetapkan subrangkaian untuk mendapatkan maklumat panjang dari pengekod. Hasil eksperimental menunjukkan bahawa subrangkaian ramalan panjang membawa peningkatan atas sistem as as kuat dan bahawa panjang ramalan boleh digunakan sebagai alternatif kepada normalisasi panjang semasa penyahkodan.', 'ml': 'ശ്രദ്ധിക്കുന്നത്- അടിസ്ഥാനമായ കോഡെര്\u200d- ഡെക്കോഡെര്\u200d മോഡലുകള്\u200d ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷണത്തിന്റെ ജോലികളില എന്നാലും, ഈ മോഡലില്\u200d ലക്ഷ്യങ്ങളുടെ നീളം വ്യക്തമായി പ്രവചിക്കപ്പെടുന്നില്ല. ഈ ജോലി ഒരു കൂടുതല്\u200d ജോലിയായി നീളം പ്രവചിപ്പിക്കുന്നതാണ് പ്രായശ്ചിത്തമാക്കുന്നത് എന്നിട്ട് കോഡെരില്\u200d നീളം വ പരീക്ഷിക്കുന്ന ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നുവെങ്കില്\u200d ശക്തിയുള്ള ബെസ്ലൈന്\u200d സിസ്റ്റത്തില്\u200d നീളം പ്രവചിക്കുന്നതിന്റെ ന', 'mt': 'Il-mudelli tad-dekodifikatur ibbażati fuq l-attenzjoni kisbu suċċess kbir fil-kompiti tat-traduzzjoni tal-magni newrali. Madankollu, it-tul tas-sekwenzi fil-mira mhuwiex previst b’mod espliċitu f’dawn il-mudelli. Dan ix-xogħol jipproponi tbassir tat-tul bħala kompitu awżiljarju u jistabbilixxi sottonetwerk biex jikseb l-informazzjoni dwar it-tul mill-kodifikatur. Ir-riżultati esperimentali juru li s-sottonetwerk tat-tbassir tat-tul iġib titjib fuq is-sistema bażi qawwija u li t-tul imbassar jista’ jintuża bħala alternattiva għan-normalizzazzjoni tat-tul waqt id-dekodifikazzjoni.', 'mn': 'Хэрвээ анхаарлын үндсэн коддогч загвар нь мэдрэлийн машин орчуулах үйл ажиллагаанд гайхалтай амжилттай болсон. Гэхдээ зорилготой дарааллын урт нь эдгээр загваруудад тодорхой таамаглагдаггүй. Энэ ажлын хугацааны таамаглал нь тусламжтай ажиллагаа болгон урт хугацааны таамаглал болон кодчуудаас урт мэдээллийг авах суб-сүлжээг зохион байгуулдаг. Эмчилгээний үр дүнд урт хугацааны суб-сүлжээ нь хүчтэй суурь шулууны системээс сайжруулах боломжтой байдал нь хугацааны урт хугацааны шинэчлэл болгох боломжтой гэдгийг харуулж байна.', 'no': 'Merknadsbaserte koderingsmodeller har oppnådd stor suksess i omsetjingsprogrammer for neuralmaskin. Lengda av målskjevensane er imidlertid ikkje eksplisisert i desse modelane. Denne arbeidet foreslår lengda som ei hjelpeoppgåve og setje opp ein undernettverk for å få lengda- informasjon frå koderen. Eksperimentale resultat viser at undernettverket for lengd-forhåndsvising inneheld forbedringar over den sterke baselinjesystemet og at forhåndsvising kan brukast som alternativ for lengd-normalisering ved dekodering.', 'pl': 'Modele koderów-dekoderów oparte na uwadze osiągnęły ogromny sukces w zadaniach neuronowego tłumaczenia maszynowego. Jednak długość sekwencji docelowych nie jest wyraźnie przewidywana w tych modelach. W niniejszej pracy proponowano predykcję długości jako zadanie pomocnicze oraz utworzenie podsieci w celu uzyskania informacji o długości z kodera. Wyniki eksperymentalne pokazują, że podsieć predykcyjna długości przynosi ulepszenia nad silnym systemem bazowym i że przewidywana długość może być stosowana jako alternatywa dla normalizacji długości podczas dekodowania.', 'ro': 'Modelele encoder-decoder bazate pe atenție au obținut un mare succes în sarcinile de traducere automată neurală. Cu toate acestea, lungimea secvențelor țintă nu este prevăzută în mod explicit în aceste modele. Această lucrare propune predicția lungimii ca o sarcină auxiliară și configurarea unei subrețele pentru a obține informațiile de lungime de la encoder. Rezultatele experimentale arată că subrețeaua de predicție a lungimii aduce îmbunătățiri față de sistemul de bază puternic și că lungimea anticipată poate fi utilizată ca alternativă la normalizarea lungimii în timpul decodificării.', 'si': 'බලාපොරොත්තු අධිරූපයෙන් ඇන්කෝඩර් ඩිකෝඩර් මොඩේල්ස් එක්ක ප්\u200dරශ්නයක් ලැබුණා න්\u200dයුරල් මැ නමුත්, මේ මොඩේල් වලින් ඉලක්කම් පරීක්ෂණයේ වැඩේ ප්\u200dරතිකෘත විශ්වාස කරන්නේ නැහැ. මේ වැඩේ විශාල ප්\u200dරශ්නයක් වෙනුවෙන් විශාල ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් සබ- ජාලය සැකසුම පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ ලොකු ප්\u200dරතිචාරයක් සබ- ජාලයේ ශක්තිමත් පද්ධතියේ ප්\u200dරතිචාරයක් වලට ප්\u200dරවේ', 'so': "Tusaalada codcoder-coder-based ayaa ku liibaanay faa'iido weyn oo ku gaadhay shaqooyinka turjumaadda maskaxda neurada. However, the lengths of the target sequences are not explicitly predicted in these models.  Shaqadaasu wuxuu soo bandhigaa wax sii sheegidda dheeraadka ah oo shaqo la xiriira ah, wuxuuna sameynayaa shabakadda shabakadda, si uu macluumaadka dheeriga ah uga helo codsiga. Imtixaanka waxaa ka muuqda in shabakadda ku dhegta la sii sheego uu kordhinayo nidaamka hoose ee xoogga leh iyo in dhererka la sii sheegay looga isticmaali karo mid bedel ah bedelka sii-normaliska waqtiga deynta.", 'sr': 'Modeli kodera-dekodera na osnovu pažnje postigli su veliki uspeh u zadatkima za prevod neuralne mašine. Međutim, dužina ciljnih sekvencija nije jasno predviđena u ovim modelima. Ovaj rad predlaže predviđanje dužine kao pomoćni zadatak i postavlja podmrežu da bi dobila informacije o dužini od kodera. Eksperimentalni rezultati pokazuju da podmreža predviđanja dužine donosi poboljšanje nad jakim početnim sistemom i da predviđena dužina može biti korištena kao alternativa normalizacije dužine tokom dekodiranja.', 'sv': 'Uppm채rksamhet-baserade encoder-dekoder modeller har uppn책tt stor framg책ng i neurala maskin철vers채ttningsuppgifter. M책lsekvensernas l채ngd f철rutses dock inte uttryckligen i dessa modeller. Detta arbete f철resl책r l채ngdf철ruts채gelse som en hj채lpuppgift och uppr채tta ett deln채tverk f철r att f책 l채ngdinformation fr책n kodaren. Experimentella resultat visar att l채ngdprognosens deln채tverk ger f철rb채ttringar j채mf철rt med det starka baslinjesystemet och att den f철rutsp책dda l채ngden kan anv채ndas som ett alternativ till l채ngdnormalisering vid avkodning.', 'ta': 'கவனம்- அடிப்படையிலான குறியீட்டு மாதிரிகள் புதிய கணினி மொழிபெயர்ப்பு பணிகளில் பெரிய வெற்றியடைந்தது. ஆயினும், இலக்கு வரிசைகளின் நீளம் இந்த மாதிரிகளில் வெளிப்படையாக எதிர்பார்க்கப்படவில்லை. இந்த வேலை குறியீட்டிலிருந்து நீண்ட தகவலை பெற உப- வலைப்பின்னலை அமைக்கும். முயற்சி முடிவுகள் காண்பிக்கப்படுகிறது துணை பிணையத்தின் நீளம் முன்னேற்றத்தை மேலும் மேம்படுத்துகிறது மற்றும் குறிப்பிடும் போது ம', 'ur': 'نائرل ماشین ترجمہ کے کاموں میں بہت بڑی موفقیت پہنچ چکی ہے۔ However, the length of the target sequences is not explicitly predicted in these models. یہ کام ایک مددگار کام کے طور پر طویل پیش بینی کی پیش بینی کرتا ہے اور ایک سوب- نیٹورک کو اس کے لئے کوڈر سے لامٹی معلومات حاصل کرنے کے لئے تنظیم کرتا ہے. Experimental results show that the length prediction sub-network brings improvements over the strong baseline system and that the predicted length can be used as a alternative to length normalization during decoding.', 'uz': "Name Lekin, jadvalning chegarasining uzunligi bu modellarda koʻrsatilmaydi. Name Tekshirish natijalari koʻrsatiladi, uzunlik sub-tarmoqning uzunligi asboblar tizimida o'zgarishni bajaradi va kutilgan uzunligi soʻzni kodlash paytidagi tartib boʻlishi mumkin.", 'vi': 'Các mẫu mã hóa chú ý đã đạt được thành công lớn trong các nhiệm vụ dịch chuyển máy thần kinh. Tuy nhiên, độ dài của dãy mục tiêu không được dự đoán rõ ràng trong các mô- đun này. Việc này đề xuất dự đoán chiều dài như một nhiệm vụ phụ trợ và thiết lập một mạng phụ để lấy thông tin về chiều dài từ bộ mã hóa. Kết quả thí nghiệm cho thấy mạng lưới dự đoán dài mang lại cải tiến trên hệ thống cơ sở cơ bản mạnh mẽ và rằng độ dài dự đoán có thể được sử dụng như một sự thay đổi thường lệ về độ dài trong thời gian giải mã.', 'da': 'Opmærksomhedsbaserede encoder-dekoder modeller har opnået stor succes i neurale maskinoversættelsesopgaver. Målsekvensernes længde forudsiges imidlertid ikke udtrykkeligt i disse modeller. Dette arbejde foreslår forudsigelse af længde som en hjælpeopgave og opretter et undernetværk for at få længdeinformation fra encoderen. Eksperimentelle resultater viser, at længde forudsigelse undernetværket bringer forbedringer i forhold til det stærke baseline system, og at den forudsigede længde kan bruges som et alternativ til længde normalisering under afkodning.', 'bg': 'Моделите, базирани на вниманието кодер-декодер, постигнаха голям успех в задачите за невронен машинен превод. Въпреки това, дължините на целевите последователности не са изрично прогнозирани в тези модели. Тази работа предлага прогнозиране на дължината като допълнителна задача и създаване на подмрежа за получаване на информация за дължината от кодера. Експерименталните резултати показват, че подмрежата за прогнозиране на дължината носи подобрения спрямо силната базова система и че прогнозираната дължина може да се използва като алтернатива на нормализирането на дължината по време на декодиране.', 'hr': 'Modeli kodera-dekodera na temelju pažnje postigli su veliki uspjeh u zadatkima prevoda neuronskih strojeva. Međutim, dužina ciljnih sekvencija nije jasno predviđena u ovim modelima. Ovaj rad predlaže predviđenje dužine kao pomoćni zadatak i uspostavi podmrežu kako bi dobili dužine informacije iz kodera. Eksperimentalni rezultati pokazuju da podmreža predviđanja dužine donosi poboljšanje nad jakim početnim sustavom i da se predviđena dužina može koristiti kao alternativa normalizacije dužine tijekom dekodiranja.', 'nl': 'Attentie-based encoder-decoder modellen hebben groot succes geboekt in neurale machinevertaaltaken. De lengtes van de doelsequenties worden echter niet expliciet voorspeld in deze modellen. Dit werk stelt lengteprognitie voor als hulptaak en het opzetten van een subnetwerk om de lengterinformatie van de encoder te verkrijgen. Experimentele resultaten tonen aan dat het subnetwerk voor lengteprognitie verbeteringen brengt ten opzichte van het sterke baseline systeem en dat de voorspelde lengte kan worden gebruikt als alternatief voor lengtennormalisatie tijdens decodering.', 'de': 'Aufmerksamkeitsbasierte Encoder-Decoder-Modelle haben große Erfolge bei neuronalen maschinellen Übersetzungsaufgaben erzielt. Die Längen der Zielsequenzen werden in diesen Modellen jedoch nicht explizit vorhergesagt. Diese Arbeit schlägt die Längenprädiktion als Hilfsaufgabe vor und richtet ein Subnetz ein, um die Längeninformation vom Encoder zu erhalten. Experimentelle Ergebnisse zeigen, dass das Längenprädiktionsunternetz Verbesserungen gegenüber dem starken Baseline-System bringt und dass die vorhergesagte Länge als Alternative zur Längennormalisierung während der Dekodierung verwendet werden kann.', 'id': 'Model decoder-decoder berdasarkan perhatian telah mencapai sukses besar dalam tugas terjemahan mesin saraf. Namun, panjang urutan target tidak secara eksplicit diprediksi dalam model ini. Pekerjaan ini mengusulkan prediksi panjang sebagai tugas bantuan dan mengatur subjaringan untuk mendapatkan informasi panjang dari pengekode. Hasil eksperimen menunjukkan bahwa prediksi panjang subjaringan membawa peningkatan atas sistem dasar yang kuat dan bahwa panjang prediksi dapat digunakan sebagai alternatif untuk normalisasi panjang selama dekoding.', 'ko': '주의를 바탕으로 한 디코더 모형은 신경기계 번역 임무에서 큰 성공을 거두었다.그러나 이들 모델은 목표 서열의 길이를 명확하게 예측하지 못했다.본고는 길이 예측을 보조 임무로 하고 서브네트워크를 구축하여 인코더로부터 길이 정보를 얻도록 한다.실험 결과에 따르면 강기선 시스템에 비해 길이 예측 서브네트워크가 개선되었고 예측 길이는 디코딩 과정에서 길이를 귀일화하는 대체 방안으로 삼을 수 있다.', 'sw': 'Mfano wa kodi-decodi wenye msimamo mkali wa kusikiliza umefanikiwa mafanikio makubwa katika kazi za kutafsiri mashine ya kijamii. Hata hivyo, muda mrefu wa mfululizo wa lengo hautabiriwi wazi katika mifano hii. This work proposes length prediction as an auxiliary task and set up a sub-network to obtain the length information from the encoder.  Matokeo ya majaribio yanaonyesha kuwa muda mrefu wa utabiri wa mtandao wa intaneti unaleta maendeleo zaidi ya mfumo wa msingi wa msingi na kwamba ongezeko la kutabiriwa linaweza kutumika kama mbadala wa utaratibu wa muda mrefu wakati wa kupungua.', 'fa': 'مدل\u200cهای رمزبندی\u200cکننده\u200cی رمزبندی بر پایه توجه موفقیت بزرگی در کار\u200cهای ترجمه\u200cی ماشین\u200cهای عصبی به دست آورده\u200cاند. با این حال، طول ترکیب هدف در این مدلها مشخص پیش بینی نمی\u200cشود. این کار پیش\u200cبینی طولانی را به عنوان یک کار کمک پیشنهاد می\u200cکند و یک شبکه زیر را برای گرفتن اطلاعات طولانی از رمزگار تنظیم می\u200cکند. نتیجه\u200cهای تجربه نشان می\u200cدهد که زیر شبکه\u200cهای طولانی پیش\u200cبینی بر سیستم پایین\u200cخط قوی بهتری می\u200cکند و طول پیش\u200cبینی می\u200cتواند به عنوان جایگزینه\u200cای برای نورمیزی طولانی در طول\u200cکشی در زمان دکوندن استفاده', 'tr': 'Unsurly ködleme-ködleme nusgalary neural maşynyň terjime täbliklerinde beter başarnyga ýetdi. Ýöne, bu nusgalaryň uzunlygy bu nusgalarda takyk öňünde berilmeýär. Bu işe uzakdygy öngörümlerini kömek täblisasi hökmünde döredir we ködlerden uzakdygy maglumatlary almak üçin sub-nete düzümler. Aramanyň netijeleri ukyrlaşyk önümleriniň altyndaky şebekedeniň güýçli baz sistemasynda gelişmeleri getirip bilýär we önümlenen uzalyklary kodlemekde ululyk normalizasyonyň başga bir üýtgetmesi üçin ullanýar.', 'af': "Aansig-gebaseerde enkoder-dekoder modele het groot sukses in neurale masjien vertaling opdragte bereik. Maar die lengte van die doel sekwensies is nie uitgespreek in hierdie modele nie. Hierdie werk voorstel die lengte voorskou as 'n helper taak en stel 'n sub- netwerk op om die lengte inligting van die enkoder te kry. Eksperimentale resultate wys dat die lengte voorskou sub-netwerk verbeteringe oor die sterk basisline stelsel en dat die voorskoude lengte kan gebruik word as 'n alternatief vir lengte normalisering tydens dekodering.", 'sq': 'Modelet e kodifikuesve të bazuar në vëmendje kanë arritur sukses të madh në detyrat e përkthimit të makinave nervore. Megjithatë, gjatësia e sekuencave të objektivit nuk parashikohet në mënyrë eksplicite në këto modele. Ky punë propozon parashikimin e gjatësisë si një detyrë ndihmëse dhe ngre një nënrrjet për të marrë informacionin e gjatësisë nga koduesi. Rezultatet eksperimentale tregojnë se nënrrjeti i parashikimit të gjatësisë sjell përmirësime mbi sistemin e fortë bazë dhe se gjatësia e parashikuar mund të përdoret si një alternativë për normalizimin e gjatësisë gjatë dekodimit.', 'am': 'የኢትዮጵያ አካባቢ የሆኑት የሆኑት የኮድዶር-አዳራጅ ሞዴላዎች በናውራዊ መሣሪያን ትርጉም ስራዎችን አግኝተዋል፡፡ ነገር ግን የአካባቢው ርዝመት የእርግዝነት ቁጥር በዚህ ዓይነቶች የተለየ አይደሉም፡፡ ይሄ ስራ የረጅም ትንቢት ማቀናጃ እንዲሆን ያስጀምራል፡፡ ፈተና ውጤቶች የረጅም ጥምቀት የመዝገብ መረብ ጥምቀት በኃይለኛው መደገፊያ እንዲያሳየው እና የተቀጠቀጠው ርዝመት የረጅም ጥምቀት ለመቀናቀል ለመለወጥ ይችላል፡፡', 'az': 'Attention-based encoder-decoder modelləri nöral maşın çeviri işlərində böyük başarılı oldular. Lakin, məqsəd sequencelərin uzunluğu bu modellərdə açıq-aşkar tədbir edilməz. Bu işlər uzunluğu tədbir üçün köməkçi iş olaraq təklif edir və kodçdan uzunluğu məlumatları almaq üçün sub-a ğı təyin edir. Experimental sonuçları göstərir ki, uzunluğun öngörünüş altı ağı güclü baseline sistemi üzərində yaxşılıqlar gətirir və tədbir edilmiş uzunluğu kodlama sırasında uzunluğun normalizasyonun alternatifi olaraq istifadə edilə bilər.', 'bn': 'মনোযোগের ভিত্তিক এনকোডার-ডেকোডার মডেল নিউরুল মেশিন অনুবাদের কাজে বেশ সফল হয়েছে। তবে এই মডেলে লক্ষ্যবস্তুর দীর্ঘ দীর্ঘদিন পরিস্কার করা হয়নি। এই কাজের দীর্ঘ ভবিষ্যদ্বাণী প্রস্তাব করে একটি অনুগ্রহশীল কাজ হিসেবে এবং এনকোডার থেকে দীর্ঘ তথ্য পাওয়ার জন্য সাব- নেট পরীক্ষার ফলাফল দেখা যাচ্ছে যে দীর্ঘ ভবিষ্যদ্বাণী সাব-নেটওয়ার্কের দীর্ঘদিনের সাব-নেটওয়ার্ক শক্তিশালী বেসাইন সিস্টেমের উপর উন্নতি পা', 'hy': 'Attention-based encoder-decoder models have achieved great success in neural machine translation tasks.  Այնուամենայնիվ, նպատակային հաջորդականությունների երկարությունը այս մոդելներում բացահայտորեն չեն կանխատեսվում: Այս աշխատանքը առաջարկում է երկարության կանխատեսումը որպես օգնական խնդիր և հիմնում է ենթացանց, որպեսզի ստանանք երկարության տեղեկությունը կոդերից: Փորձարկվող արդյունքները ցույց են տալիս, որ երկարության կանխատեսման ենթացանցը բարելավում է հիմնական համակարգը և որ կանխատեսված երկարությունը կարող է օգտագործվել որպես երկարության նորմալիզացիայի այլընտրանք կոդավորման ընթացքում:', 'ca': "Els models de codificador basats en l'atenció han aconseguit un gran èxit en les tasques de traducció neuromàtica. No obstant això, en aquests models no es predeixen explícitament les llargues de les seqüències d'objectiu. Aquesta feina propon predir la llargada com a tasca auxiliar i crear una subxarxa per obtenir la informació sobre la llargada del codificador. Els resultats experimentals mostren que la subxarxa de predicció de la longitud porta millors sobre el sistema de base fort i que la longitud predicuta pot ser utilitzada com una alternativa a la normalització de la longitud durant la decodificació.", 'bs': 'Modeli kodera-dekodera na temelju pažnje postigli su veliki uspjeh u zadatkima za prevod neuroloških strojeva. Međutim, dužina ciljnih sekvencija nije jasno predviđena u ovim modelima. Ovaj rad predlaže predviđanje dužine kao pomoćni zadatak i uspostavi podmrežu kako bi dobili dužine informacije iz kodera. Eksperimentalni rezultati pokazuju da podmreža predviđanja dužine donosi poboljšanje nad jakim početnim sistemom i da se predviđena dužina može koristiti kao alternativa normalizacije dužine tijekom dekodiranja.', 'cs': 'Modely kodérů a dekodérů založené na pozornosti dosáhly velkého úspěchu v úlohách neuronového strojového překladu. Délky cílových sekvencí však v těchto modelech nejsou explicitně předpovídány. Tato práce navrhuje predikci délky jako pomocný úkol a nastavení subsítě pro získání informací o délce z snímače. Experimentální výsledky ukazují, že subsíť predikce délky přináší zlepšení oproti silnému základnímu systému a že předpokládaná délka může být použita jako alternativa k normalizaci délky během dekódování.', 'fi': 'Huomioon perustuvat kooderi-dekooderimallit ovat saavuttaneet suurta menestystä neurokonekäännöstöissä. Näissä malleissa kohdesekvenssien pituutta ei kuitenkaan nimenomaisesti ennusteta. Tässä työssä ehdotetaan pituuden ennustamista aputehtäväksi ja luodaan aliverkko pituustietojen saamiseksi kooderista. Kokeelliset tulokset osoittavat, että pituuden ennustamisen aliverkko tuo parannuksia vahvaan peruskantajärjestelmään verrattuna ja että ennustettua pituutta voidaan käyttää vaihtoehtona pituuden normalisoinnille dekoodauksen aikana.', 'et': 'Tähelepanu põhinevad kodeerija-dekooderi mudelid on saavutanud suure edu neuromasintõlke ülesannetes. Siiski ei ole nendes mudelites sihtjärjestuste pikkusi selgesõnaliselt prognoositud. Käesolevas töös pakutakse välja pikkuse prognoosimine abiülesandena ja luuakse alamvõrk kodeerijalt pikkuse info saamiseks. Eksperimentaalsed tulemused näitavad, et pikkuse prognoosimise alamvõrk parandab tugevat baassüsteemi ning prognoositud pikkust saab kasutada alternatiivina pikkuse normaliseerimisele dekodeerimisel.', 'sk': 'Modeli kodirnikov-dekoderjev, ki temeljijo na pozornosti, so dosegli velik uspeh pri nalogah nevronskega strojnega prevajanja. Vendar pa dolžine ciljnih zaporedij v teh modelih niso izrecno predvidene. To delo predlaga napoved dolžine kot pomožno nalogo in vzpostavitev podomrežja za pridobivanje informacij o dolžini iz kodirnika. Eksperimentalni rezultati kažejo, da podomrežje napovedovanja dolžine prinaša izboljšave v primerjavi z močnim osnovnim sistemom in da se predvidena dolžina lahko uporabi kot alternativa normalizaciji dolžine med dekodiranjem.', 'jv': 'Attribute politenessoffpolite"), and when there is a change ("assertive Workspace Names Perintah sing dipunsersal dipontrolan kanggo ngerasai tanggal apa-tambah kuwi bisa dianggawe sistem sing bisa dianggawe lan padha winih sing bisa dianggawe nguasai Alternate kanggo ngerasai tanggal nggawe nguasai winih.', 'he': 'דוגמני קודד-קידור מבוססים על תשומת לב השיגו הצלחה גדולה במשימות התרגום של מכונות עצביות. עם זאת, האורך של רצפי המטרה לא נצפה באופן ברור בדוגמנים אלה. העבודה הזו מציעה חיזוי אורך בתור משימה עזרית ותקים תת-רשת כדי להשיג מידע אורך מהקודד. תוצאות ניסויים מראות שהתחת-רשת צפוי הארוך מביאה שיפורים מעל מערכת הבסיס החזקה ושאורך צפוי יכול להשתמש בתור אלטרנטיבה לנורמליזציה הארוך במהלך הפענוח.', 'ha': "@ action: button Haƙĩƙa, tsawo na sakan da aka yi goani ba'a ƙayyade bayani ba cikin wannan misalin. Wannan aikin yana ƙarfafa bayani na tsawo kamar wani aikin mai inganci kuma ya daidaita wani shiri na ƙarƙashin-tarayya dõmin ya samu maɓalli tsawo daga koden. Experimental results show that the length prediction sub-network brings improvements over the strong baseline system and that the predicted length can be used as an alternative to length normalization during decoding.", 'bo': 'Attention-based encoder-decoder models have achieved great success in neural machine translation tasks. ཡིན་ནའང་དམིགས་ཡུལ་གྱི་དབྱེ་རིམ་གྱི་རིང་ཚད་མ་གསལ་པོ་སྔོན་འཛུགས་བྱས་མེད། This work proposes length prediction as an auxiliary task and set up a sub-network to get the length information from the encoder. Experimental results show that the length of the prediction sub-network brings improvements over the strong baseline system and that the predicted length can be used as an alternative to length normalization during decoding.'}
{'en': 'Heads-up ! Unsupervised Constituency Parsing via Self-Attention Heads', 'ar': 'انتباه! تحليل دائرة انتخابية غير خاضعة للإشراف عبر رؤساء الاهتمام الذاتي', 'fr': "Head-up\xa0! Analyse de circonscription non supervisée via des têtes d'auto-attention", 'pt': 'Atenção! Análise não supervisionada de grupos constituintes por meio de chefes de autoatenção', 'es': '¡Heads-up! Análisis de circunscripciones no supervisadas a través de los jefes de autoatención', 'ja': '気をつけろ！監督されていない選挙区は、自己注意喚起ヘッドを介して解析している', 'zh': '举头! 无监选以自关解析', 'hi': 'सिर! स्वयं-ध्यान प्रमुखों के माध्यम से असुरक्षित निर्वाचन क्षेत्र पार्सिंग', 'ru': 'Неконтролируемый анализ избирательных округов через головы самовлияния', 'ga': 'Cinnirí suas! Parsáil Toghlach Gan Maoirseacht trí Chinn Féinaird', 'hu': 'Figyelmeztetés! Felügyelet nélküli választókerületi elemzés önfigyelő vezetőkön keresztül', 'ka': 'დლაგთრვ დჲპვ! არაფერიზებული კონსტისტუტესტის პანელიზაცია თავისუფალი თავისუფალი თავისუფალი', 'el': 'Πρόσεχε! Ανεπίβλεπτη ανάλυση πολιτείας μέσω αρχηγών αυτοπροσοχής', 'mk': 'Внимавајте! Unsupervised Constituency Parsing via Self-Attention Heads', 'ms': 'Awas! Penghuraian Keadaan Tidak Dipengawasi Melalui Kepala Perhatian-Sendiri', 'it': 'Attenzione! Analisi delle circoscrizioni non sorvegliate tramite capi di auto-attenzione', 'kk': 'Айдар жоғары! Өзіңізге қарау айдары арқылы сақталмаған конституттық талдау', 'lt': 'Atsargiai! Neprižiūrimas sudedamųjų dalių analizavimas per savarankiško dėmesio vadovus', 'ml': 'മുകളിലേക്ക്! സ്വയം ശ്രദ്ധിക്കുന്ന തലക്കെട്ടുകളിലൂടെ നിരീക്ഷിക്കപ്പെടാത്ത ആധിപത്യ പാര്\u200dസിങ്ങ്', 'no': 'Topp opp! Uødvendig tolking av konstitusjonar via selvmerkingshovud', 'mn': 'толгой дээш! Өөрсдийгөө анхаарлаа хандуулахгүй байгууллагын талаар', 'mt': 'Heads-up!  Analiżi tal-Kostituzzjoni Mhux Sorveljata permezz ta’ Kapijiet ta’ Awtoattenzjoni', 'pl': 'Głowa do góry! Niekontrolowana analiza wyborcza za pośrednictwem szefów uwagi na siebie', 'ro': 'Heads-up! Analizarea circumstanțelor electorale nesupravegheate prin intermediul șefilor auto-atenție', 'sr': 'Glave gore! Neobezbeđeno razmatranje konstitucija putem glava samopouzdanja', 'so': 'Heads-up!  Jardiinooyinka ka ilaalinaysan madaxda iskaa-Attention', 'si': 'ඔළුව උඩට! ස්වයංග- බලාපොරොත්තුවක් මධ්\u200dයමයෙන් නැති ස්ථානය විශාලනය', 'sv': 'Varning! Oservade valkretsar tolkar via sjĂ¤lvuppmĂ¤rksamhetschefer', 'ta': 'தலைப்பு-மேல்! சார்ந்து கவனம் தலைப்புகள் வழியாக கண்காணிக்கப்படாத பாடல்', 'ur': 'سر اوپر! بے حفاظت پارچینگ', 'uz': 'Sarlavha! Unsupervised Constituency Parsing via Self-Attention Heads', 'vi': 'Cẩn thận! Chế độ bầu cử không tuân lệnh', 'bg': 'Горе главата! Неконтролирано анализиране на избирателите чрез ръководители на самовниманието', 'hr': 'Glave gore! Neodređeno razmatranje konstitucija kroz glave samopouzdanja', 'nl': 'Opgelet! Onbegeleide constitutionele analyse via zelfattentiehoofden', 'da': 'Advarsel! Ikke-overvåget valgkreds fortolkning via selvopmærksomhedschefer', 'de': 'Achtung! Unservised Constituency Parsing über Self-Attention Heads', 'ko': '조심하다자기 주의 헤드의 무감독 선택 영역 분석을 통해', 'fa': 'سر بالا! تولید محیط غیرقابل حفاظت', 'id': 'Awas! Penganalis Konstitusi Belum Disupervisi Melalui Kepala Perhatian Sendiri', 'sw': 'Wako juu! Uchapishaji wa Kikatiba kwa kupitia Viongozi vya kujitegemea', 'af': 'Op koppe! Ononderwerpende Konstituciteit Verwerking deur Self- Attention Koppe', 'tr': 'Başlyg üste Üýtgedik Ululyk', 'am': 'ራስ CategoryName', 'sq': 'Heads-up!  Duke analizuar kushtetutën e pazgjidhur nëpërmjet kokave të vetëvëzhgimit', 'hy': 'Զգուշացեք: Comment', 'az': 'Başlıqlar yuxarı! Özünün gözləmə başlıqları vasitəsilə mühafizə edilməmiş', 'bn': 'মাথা! স্বয়ংক্রিয়ভাবে মনোযোগ দেওয়া শীর্ষচরণের মাধ্যমে অনলাইন সংবিধান পার্সিং', 'bs': 'Glave gore! Neobezbeđeno razmatranje konstitucija putem glava samopouzdanja', 'ca': "Cuidado! Analització de la Constituència sense supervisió mitjançant cap d'auto-atenció", 'cs': 'Hlavu nahoru! Nehlídaná analýza občanství prostřednictvím hlav sebepozornosti', 'et': 'Pead püsti! Järelevalveta valijate parsimine enesetähelepanu juhtide kaudu', 'fi': 'Varokaa! Tarkkailematon vaalipiirien jäsentely itsepalvelupäälliköiden kautta', 'jv': 'structural navigation Speaking of indentation and justification', 'ha': 'Madaidaici! KCharselect unicode block name', 'he': 'ראש למעלה! פרסום בתחום ללא השגחה באמצעות ראשי תשומת לב עצמית', 'sk': 'Glave gor! Nenadzorovano razvrščanje volilnih enot prek vodij samopozornosti', 'bo': 'མགོ་ཡིག་བཀོག རང་ཉིད་ལྟ་རྟོགས་པའི་མགོ་ཡིག་དང་བསྟུན་ནས་སྒྲིག་མེད་པའི་རྩ་བའི་དབྱིབས་མཐུན་བཟོ་བྱེད་པ'}
{'en': 'Transformer-based pre-trained language models (PLMs) have dramatically improved the state of the art in  NLP  across many tasks. This has led to substantial interest in analyzing the syntactic knowledge PLMs learn. Previous approaches to this question have been limited, mostly using test suites or probes. Here, we propose a novel fully unsupervised parsing approach that extracts constituency trees from PLM attention heads. We rank transformer attention heads based on their inherent properties, and create an ensemble of high-ranking heads to produce the final  tree . Our  method  is adaptable to low-resource languages, as it does not rely on development sets, which can be expensive to annotate. Our experiments show that the proposed  method  often outperform existing approaches if there is no development set present. Our unsupervised parser can also be used as a tool to analyze the grammars PLMs learn implicitly. For this, we use the parse trees induced by our method to train a neural PCFG and compare it to a  grammar  derived from a human-annotated treebank.', 'ar': 'لقد حسنت نماذج اللغة المدربة مسبقًا (PLMs) المستندة إلى المحولات بشكل كبير من حالة الفن في البرمجة اللغوية العصبية عبر العديد من المهام. وقد أدى ذلك إلى اهتمام كبير بتحليل المعرفة النحوية التي تتعلمها PLM. كانت المناهج السابقة لهذا السؤال محدودة ، ومعظمها باستخدام مجموعات الاختبار أو المسابير. هنا ، نقترح أسلوب تحليل جديد غير خاضع للإشراف بالكامل يستخلص أشجار الدوائر من رؤوس انتباه PLM. نصنف رؤوس انتباه المحولات بناءً على خصائصها المتأصلة ، وننشئ مجموعة من الرؤوس عالية المستوى لإنتاج الشجرة النهائية. طريقتنا قابلة للتكيف مع اللغات منخفضة الموارد ، لأنها لا تعتمد على مجموعات التطوير ، والتي قد تكون مكلفة للتعليق عليها. تظهر تجاربنا أن الطريقة المقترحة غالبًا ما تتفوق في الأداء على الأساليب الحالية إذا لم تكن هناك مجموعة تطوير موجودة. يمكن أيضًا استخدام المحلل اللغوي غير الخاضع للرقابة كأداة لتحليل القواعد النحوية التي تتعلمها بشكل ضمني. لهذا ، نستخدم أشجار التحليل الناتجة عن طريقتنا لتدريب PCFG العصبي ومقارنته بقواعد مستمدة من بنك شجرة بشرح.', 'es': 'Los modelos de lenguaje preentrenados (PLM) basados en transformadores han mejorado drásticamente el estado del arte de la PNL en muchas tareas. Esto ha generado un interés sustancial en analizar el conocimiento sintáctico que aprenden los PLM. Los enfoques anteriores a esta pregunta han sido limitados, en su mayoría utilizando conjuntos de pruebas o sondas. Aquí, proponemos un novedoso enfoque de análisis totalmente sin supervisión que extrae los árboles de las unidades constitutivas de los cabezales de atención de PLM. Clasificamos las cabezas de atención de los transformadores en función de sus propiedades inherentes y creamos un conjunto de cabezas de alto rango para producir el árbol final. Nuestro método es adaptable a lenguajes de bajos recursos, ya que no se basa en conjuntos de desarrollo, que pueden resultar costosos de anotar. Nuestros experimentos muestran que el método propuesto a menudo supera a los enfoques existentes si no hay un conjunto de desarrollo presente. Nuestro analizador no supervisado también se puede utilizar como una herramienta para analizar las gramáticas que los PLM aprenden implícitamente. Para ello, utilizamos los árboles de análisis inducidos por nuestro método para entrenar un PCFG neuronal y compararlo con una gramática derivada de un banco de árboles anotado por humanos.', 'pt': 'Modelos de linguagem pré-treinados (PLMs) baseados em transformador melhoraram drasticamente o estado da arte em PNL em muitas tarefas. Isso levou a um interesse substancial em analisar o conhecimento sintático que os PLMs aprendem. As abordagens anteriores para essa questão foram limitadas, principalmente usando conjuntos de testes ou sondas. Aqui, propomos uma nova abordagem de análise totalmente não supervisionada que extrai árvores constituintes das cabeças de atenção do PLM. Classificamos as cabeças de atenção do transformador com base em suas propriedades inerentes e criamos um conjunto de cabeças de alto nível para produzir a árvore final. Nosso método é adaptável a linguagens de poucos recursos, pois não depende de conjuntos de desenvolvimento, que podem ser caros para anotar. Nossos experimentos mostram que o método proposto geralmente supera as abordagens existentes se não houver um conjunto de desenvolvimento presente. Nosso analisador não supervisionado também pode ser usado como uma ferramenta para analisar as gramáticas que os PLMs aprendem implicitamente. Para isso, usamos as árvores de análise sintática induzidas pelo nosso método para treinar um PCFG neural e compará-lo com uma gramática derivada de um banco de árvores anotado por humanos.', 'fr': "Les modèles de langage préformés (PLM) basés sur des transformateurs ont considérablement amélioré l'état de l'art en matière de PNL dans de nombreuses tâches. Cela a suscité un intérêt considérable pour l'analyse des connaissances syntaxiques apprises par les PLM. Les approches précédentes de cette question étaient limitées, utilisant principalement des suites de tests ou des sondes. Nous proposons ici une nouvelle approche d'analyse entièrement non supervisée qui extrait les arbres de constituants des têtes d'attention PLM. Nous classons les têtes d'attention des transformateurs en fonction de leurs propriétés inhérentes et créons un ensemble de têtes de haut rang pour produire l'arbre final. Notre méthode est adaptable aux langages à faibles ressources, car elle ne repose pas sur des ensembles de développement, ce qui peut être coûteux à annoter. Nos expériences montrent que la méthode proposée surpasse souvent les approches existantes en l'absence d'ensemble de développement. Notre analyseur non supervisé peut également être utilisé comme outil pour analyser les grammaires apprises implicitement par les PLM. Pour cela, nous utilisons les arbres d'analyse induits par notre méthode pour entraîner un PCFG neuronal et le comparer à une grammaire dérivée d'une banque d'arbres annotée par l'homme.", 'ja': 'トランスフォーマーベースの事前訓練された言語モデル（ PLM ）は、多くのタスクにわたってNLPの最先端を劇的に改善してきた。 これにより、PLMが学習する構文知識の分析に大きな関心が寄せられている。 この質問に対する以前のアプローチは限られており、主にテストスイートまたはプローブを使用しています。 ここでは、PLMの注意喚起ヘッドから選挙区ツリーを抽出する、完全に監督されていない新規の構文解析アプローチを提案します。 変圧器ヘッドの固有の特性に基づいてランク付けを行い、高位のヘッドのアンサンブルを作成して最終ツリーを作成します。 私たちのメソッドは、アノテーションするのに高価な開発セットに依存しないため、低リソース言語に適応できます。 我々の実験では、開発セットが存在しない場合、提案された方法が既存のアプローチをしばしば上回ることが示されている。 私たちの監視されていない構文解析器は、PLMが暗黙的に学習する文法を分析するためのツールとしても使用できます。 このため、神経PCFGを訓練し、人間が注釈したツリーバンクから導き出された文法と比較するために、私たちの方法で誘導された構文解析ツリーを使用します。', 'zh': '盖转换器之预训言语模样(PLM)大改NLP之最新技术水平。 此所以PLM学之句法浓厚兴趣也。 前此之道有限,主用测试套件探测器。 此处全无监解析法,可从PLM意取区头。 因变压器之性而名变压器注意,合高级而成树。 吾道宜低资源言语,以其不依开发集,而注释固可高也。 臣等实验明,若不开集,所上常优于今。 吾无监解析器亦可以为析PLM隐式学语法之具。 是以诱吾解析树来以训神经PCFG,比之人注树库生语法。', 'hi': 'ट्रांसफॉर्मर-आधारित पूर्व-प्रशिक्षित भाषा मॉडल (पीएलएम) ने कई कार्यों में एनएलपी में कला की स्थिति में नाटकीय रूप से सुधार किया है। इसने वाक्यात्मक ज्ञान का विश्लेषण करने में पर्याप्त रुचि पैदा की है पीएलएम सीखते हैं। इस प्रश्न के लिए पिछले दृष्टिकोण सीमित हैं, ज्यादातर परीक्षण सुइट्स या जांच का उपयोग करके। यहां, हम एक उपन्यास पूरी तरह से असुरक्षित पार्सिंग दृष्टिकोण का प्रस्ताव करते हैं जो पीएलएम ध्यान प्रमुखों से निर्वाचन क्षेत्र के पेड़ों को निकालता है। हम उनके अंतर्निहित गुणों के आधार पर ट्रांसफॉर्मर ध्यान सिर को रैंक करते हैं, और अंतिम पेड़ का उत्पादन करने के लिए उच्च रैंकिंग वाले सिरों की एक टुकड़ी बनाते हैं। हमारी विधि कम-संसाधन भाषाओं के अनुकूल है, क्योंकि यह विकास सेट पर भरोसा नहीं करती है, जो एनोटेट करने के लिए महंगा हो सकता है। हमारे प्रयोगों से पता चलता है कि प्रस्तावित विधि अक्सर मौजूदा दृष्टिकोणों को मात देती है यदि कोई विकास सेट मौजूद नहीं है। हमारे असुरक्षित पार्सर का उपयोग एक उपकरण के रूप में भी किया जा सकता है ताकि पीएलएम द्वारा स्पष्ट रूप से सीखे जाने वाले व्याकरणों का विश्लेषण किया जा सके। इसके लिए, हम एक तंत्रिका PCFG को प्रशिक्षित करने के लिए हमारी विधि से प्रेरित पार्स पेड़ों का उपयोग करते हैं और इसकी तुलना मानव-एनोटेट ट्रीबैंक से व्युत्पन्न व्याकरण से करते हैं।', 'ru': 'Трансформаторные предварительно обученные языковые модели (PLM) значительно улучшили современное состояние в NLP во многих задачах. Это привело к существенному интересу к анализу синтаксических знаний, которые изучают PLMS. Предыдущие подходы к этому вопросу были ограничены, в основном с использованием тестовых наборов или зондов. Здесь мы предлагаем новый полностью неконтролируемый подход к синтаксическому анализу, который извлекает деревья избирательных округов из глав внимания PLM. Мы ранжируем головки внимания трансформатора по их присущим свойствам и создаем ансамбль голов высокого ранга для создания финального дерева. Наш метод адаптируется к языкам с низким объемом ресурсов, так как он не опирается на наборы разработок, которые могут быть дорогостоящими для аннотирования. Наши эксперименты показывают, что предлагаемый метод часто превосходит существующие подходы, если отсутствует набор разработок. Наш неконтролируемый синтаксический анализатор также может быть использован в качестве инструмента для анализа грамматики, которую PLM изучают неявно. Для этого мы используем синтаксический анализ деревьев, индуцированный нашим методом, чтобы обучить нейронный PCFG и сравнить его с грамматикой, полученной из аннотированного человеком берега деревьев.', 'ga': 'Chuir múnlaí teanga réamhoilte atá bunaithe ar chlaochladán (PLManna) feabhas mór ar an úrscothacht in NLP thar go leor tascanna. Mar thoradh air seo tá suim mhór in anailís a dhéanamh ar an eolas comhréire a fhoghlaimíonn PLM. Ní raibh mórán cur chuige maidir leis an gceist seo roimhe seo, ag baint úsáide as seomraí tástála nó taiscéalaithe den chuid is mó. Anseo, molaimid cur chuige úr parsála gan mhaoirseacht a bhainfidh crainn dáilcheantair ó chinn aird PLM. Déanaimid rangú ar chinn aird na gclaochladán bunaithe ar a n-airíonna dúchasacha, agus cruthaímid ensemble de chinn ardchéime chun an crann deiridh a tháirgeadh. Tá ár modh inoiriúnaithe do theangacha íseal-acmhainne, toisc nach bhfuil sé ag brath ar thacair forbartha, ar féidir leo a bheith costasach le nótaí a dhéanamh. Léiríonn ár dturgnaimh gur minic a sháraíonn an modh atá molta na cineálacha cur chuige atá ann cheana féin mura bhfuil tacar forbartha ann. Is féidir ár parsálaí gan mhaoirseacht a úsáid freisin mar uirlis chun anailís a dhéanamh ar na gramadaí a fhoghlaimíonn PLManna go hintuigthe. Chuige seo, bainimid úsáid as na crainn pharsála a chothaítear lenár modh chun PCFG néarúil a oiliúint agus é a chur i gcomparáid le gramadach a dhíorthaítear ó bhruach crann daonna-anótáilte.', 'el': 'Τα προ-εκπαιδευμένα μοντέλα γλωσσών με βάση τον μετασχηματιστή έχουν βελτιώσει δραματικά την κατάσταση της τεχνολογίας σε πολλές εργασίες. Αυτό έχει οδηγήσει σε ουσιαστικό ενδιαφέρον για την ανάλυση της συντακτικής γνώσης που μαθαίνουν οι PLM. Οι προηγούμενες προσεγγίσεις σε αυτό το ερώτημα ήταν περιορισμένες, κυρίως χρησιμοποιώντας σουίτες δοκιμών ή ανιχνευτές. Εδώ, προτείνουμε μια νέα, πλήρως χωρίς επίβλεψη προσέγγιση ανάλυσης που εξάγει δέντρα εκλογικών περιφερειών από κεφάλαια προσοχής PLM. Ταξιδεύουμε τις κεφαλές προσοχής μετασχηματιστών με βάση τις εγγενείς ιδιότητές τους, και δημιουργούμε ένα σύνολο κορυφαίων κεφαλών για να παραγάγουμε το τελικό δέντρο. Η μέθοδος μας είναι προσαρμόσιμη σε γλώσσες χαμηλής περιεκτικότητας, καθώς δεν βασίζεται σε σύνολα ανάπτυξης, τα οποία μπορεί να είναι ακριβά να σχολιάσουν. Τα πειράματά μας δείχνουν ότι η προτεινόμενη μέθοδος συχνά ξεπερνά τις υπάρχουσες προσεγγίσεις αν δεν υπάρχει αναπτυξιακό σύνολο. Ο αναλυτής χωρίς επίβλεψη μπορεί επίσης να χρησιμοποιηθεί ως εργαλείο για την ανάλυση των γραμματικών που μαθαίνουν έμμεσα. Για αυτό, χρησιμοποιούμε τα δένδρα που προκαλούνται από τη μέθοδο μας για να εκπαιδεύσουμε ένα νευρικό PCFG και να το συγκρίνουμε με μια γραμματική που προέρχεται από μια ανθρώπινη σχολιασμένη δένδρα.', 'ka': 'ტრანფორმეტრის დაბათი წინასწარმოადგენული ენის მოდელები (PLMs) დირამატიკურად NLP წინასწარმოადგენის სტატუსის სტატუსაციას მრავალში გაუქმნა. ეს გავაგრძნეთ ძალიან ინტერესტი სინტაქტიური ცნობილების ანალიზაციაში, რომელიც PLMs სწავლის. ამ კითხვაზე წინა დაეხმარება უფრო დარჩენა, ძალიან გამოყენებული ტესტის სუტი ან პრობეტების გამოყენება. აქ, ჩვენ პრომენტის პრომენტი, რომელსაც პრომენტის განსხვავებული არსხვავებული პრომენტის პრომენტი, რომელსაც პრომენტის განსხვავება პრომენტის სახელიდა ჩვენ რენსტრუმენტერის აღმოჩენებელი თავის შესახებ მისი შესახებ, და შევქმნით უფრო დიდი ნაწილის ნაწილის შესახებ. ჩვენი მეთოდი ცოტა რესურსისების ენაზებისთვის ადაპტირებულია, რადგან ის არ განვითარების კონტაქტისთვის, რომელიც შეიძლება იყოს ძალიან ძალიან ძალ ჩვენი ექსპერიმენტები გამოჩვენება, რომ პროგრამები ძალიან უფრო მეტად გავაკეთება, თუ არ არ არის განვითარება. ჩვენი არაფერიზებული პანსერიზი შეიძლება გამოყენება როგორც ხელსაწყო, როგორც გრამიმარები PLMs-ს ანალიზაციისთვის შესწავლად. ამისთვის, ჩვენ გამოყენებთ ჩვენი მეთოდიდან განვიყენებული პანუს ეხეები, რომლებიც ნეიროლური PCFG და დამყენებთ ის გრამიკაზე, რომლებიც ადამიანის ანოტირებულ საბონდან გამოიყენ', 'hu': 'A transzformátorok alapú, előre képzett nyelvi modellek (PLM) jelentősen javították az NLP technológia állapotát számos feladatban. Ez jelentős érdeklődéshez vezetett a PLM-k tanulásának szintaktikus ismereteinek elemzése iránt. Korábbi megközelítések korlátozottak voltak erre a kérdésre, leginkább tesztcsomagokat vagy szondákat használva. Itt egy új, teljesen felügyelet nélküli elemzési megközelítést javasolunk, amely kivonja a választókerületi fákat a PLM figyelemfejeiből. A transzformátorok figyelemfelkeltő fejeit a benne rejlő tulajdonságok alapján rangsoroljuk, és magas rangú fejekből álló együtteset hozunk létre a végső fa előállításához. Módszerünk alkalmazkodik az alacsony erőforrású nyelvekhez, mivel nem támaszkodik a fejlesztési készletekre, amelyek költségesek lehetnek a megjegyzések. Kísérleteink azt mutatják, hogy a javasolt módszer gyakran felülmúlja a meglévő megközelítéseket, ha nincs jelen fejlesztési halmaz. Felügyelet nélküli elemzőnk eszközként is használható a nyelvtanfolyamok implicit tanulásának elemzésére. Ehhez a módszerünk által indukált parse fákat használjuk egy neurális PCFG kiképzésére, és összehasonlítjuk egy emberi jegyzetelésű fából származó nyelvtant.', 'it': "I modelli linguistici pre-formati basati su trasformatori (PLM) hanno notevolmente migliorato lo stato dell'arte nel PNL in molte attività. Ciò ha portato ad un notevole interesse nell'analizzare le conoscenze sintattiche apprese dai PLM. Gli approcci precedenti a questa domanda sono stati limitati, principalmente utilizzando suite di test o sonde. Qui, proponiamo un nuovo approccio di analisi completamente non supervisionato che estrae gli alberi delle circoscrizioni elettorali dai capi di attenzione del PLM. Classificamo le teste di attenzione dei trasformatori in base alle loro proprietà intrinseche e creiamo un insieme di teste di alto rango per produrre l'albero finale. Il nostro metodo è adattabile ai linguaggi a basso contenuto di risorse, in quanto non si basa su set di sviluppo, che possono essere costosi da annotare. I nostri esperimenti dimostrano che il metodo proposto spesso supera gli approcci esistenti se non c'è un insieme di sviluppo presente. Il nostro parser non supervisionato può anche essere utilizzato come strumento per analizzare le grammaticali che i PLM imparano implicitamente. Per questo, utilizziamo gli alberi di parse indotti dal nostro metodo per addestrare un PCFG neurale e confrontarlo con una grammatica derivata da un albero annotato dall'uomo.", 'kk': 'Трансформация негіздеген алдын- оқылған тіл үлгілері (PLMs) NLP- дағы суреттердің көпшілігін көп тапсырмалардың ішінде жақсы жасады. Бұл синтактикалық білім PLMs оқытуға көп қызықты болды. Бұл сұрақтың алдыңғы арқылы шектелген, көпшілігі сынақтар немесе проботтарды қолданады. Мұнда, біз Романы толық қамтамасыз емес талдау тәсіліне ұсынамыз. Бұл жерде PLM тәртіпсіздік ағаштарды түсіріп алып тастайды. Біз олардың қасиеттеріне негізделген түрлендірушілердің басына қарап, соңғы ағаш жасау үшін жоғары жоғары жоғары басының белгісін құрамыз. Біздің әдіміміз көп ресурстар тілдеріне адаптауға мүмкін, өйткені ол жасау баптарына сенбейді, бұл мәліметтердің бағасы болуы мүмкін. Біздің тәжірибеміздің таңдалған тәжірибесі барлық тәжірибелерді көбірек жасауға көбірек болады. Біздің бағытталмаған талдаушысымыз, граммалар PLMs граммаларын талдау үшін қолданылады. Бұл үшін біз өзіміздің әдімімізге көмектесетін талдау ағаштарын пайдалану үшін невралдық PCFG оқыту үшін және оны адамдардың белгілеген ағаш бағыттан салыстырып, грамматтар', 'mk': 'Трансформските предобучени јазички модели (ПЛМ) драматично ја подобрија техничката состојба во НЛП во текот на многу задачи. Ова доведе до значителен интерес за анализа на синтактичкото знаење што ПЛМ учат. Претходните пристапи кон ова прашање се ограничени, претежно користејќи тестови костуми или сонди. Овде, предложуваме нов, целосно ненадгледуван пристап на анализирање кој ги извадува дрвјата на изборните околини од главите на вниманието на ПЛМ. Ние ги рангираме главите на внимание на трансформаторите базирани на нивните природни имоти, и создаваме ансембл на високи глави за да го произведеме последното дрво. Нашиот метод е адаптабилен на јазиците со ниски ресурси, бидејќи не се зависи од наборите за развој, кои може да бидат скапи за анотирање. Нашите експерименти покажуваат дека предложениот метод честопати ги надминува постојните пристапи ако не постои постоечки развој. Нашиот ненадгледуван анализатор исто така може да се користи како алат за анализирање на граматките што ПЛМ ги научи имплицитно. За ова, ги користиме дрвјата на анализирање индустрирани од нашиот метод за да обучуваме невропски ПЦФГ и да ја споредиме со граматика која се изведува од дрвена лента која е анотирана од човек.', 'lt': 'Įgyvendinant daugelį užduočių, iš anksto parengtų kalbų modeliai (PLM) iš esmės pagerino NLP pažangą. Tai sukėlė didelį susidomėjimą analizuojant sintetines žinias, kurias įgyja PLM. Ankstesni požiūriai į šį klausimą buvo riboti, daugiausia naudojant bandymų kostiumus ar sondus. Čia mes siūlome naują visiškai nepastebimą analizavimo metodą, kuris ištraukia rinkimų apygardos medžius iš PLM dėmesio galvutų. Mes klasifikuojame transformatorių dėmesio galvas, grindžiamas jų savybėmis, ir sukuriame aukšto rango galvų rinkinį galutiniam medžiui gaminti. Mūsų metodas gali būti pritaikytas prie mažai išteklių turinčių kalbų, nes jis nesiremia vystymosi rinkiniais, kurie gali būti brangu užrašyti. Mūsų eksperimentai rodo, kad siūlomas metodas dažnai viršija esamus metodus, jei nėra jokio vystymosi. Mūsų nepastebimas analizatorius taip pat gali būti naudojamas kaip įrankis netiesiogiai mokytiems PLM gramatikams analizuoti. Šiam tikslui mes naudojame savo metodu indukuotus analizinius medžius, kad apmokytume nervinį PCFG ir palygintume jį su gramatika, gauta iš žmogaus anotuoto medžio.', 'ms': 'Model bahasa pra-dilatih berasaskan-Transformer (PLMs) telah meningkatkan keadaan seni dalam NLP secara dramatis melalui banyak tugas. Ini telah membawa kepada kepentingan yang besar dalam menganalisis pengetahuan sintaktik PLMs belajar. pendekatan terdahulu kepada soalan ini telah terbatas, kebanyakan menggunakan sut ujian atau sond. Di sini, kami melamar novel pendekatan penghuraian yang tidak diawasi sepenuhnya yang mengekstrak pokok konstitusi dari kepala perhatian PLM. Kami peringkatkan kepala perhatian pengubah berdasarkan ciri-ciri mereka, dan mencipta kumpulan kepala yang tinggi untuk menghasilkan pokok akhir. Kaedah kami boleh disesuaikan dengan bahasa sumber rendah, kerana ia tidak bergantung pada set pembangunan, yang boleh mahal untuk dicatat. Eksperimen kami menunjukkan bahawa kaedah yang diusulkan sering melebihi pendekatan yang wujud jika tiada set pembangunan yang ada. Penghurai kami tidak diawasi juga boleh digunakan sebagai alat untuk menganalisis grammar PLMs belajar secara implicit. Untuk ini, kita gunakan pepohonan penghuraian yang disebabkan oleh kaedah kita untuk melatih PCFG saraf dan membandingkannya dengan grammar yang berasal dari pokok yang dicatat oleh manusia.', 'mn': 'Трансформацийн сургалтын өмнө сургалтын хэл загварууд (PLMs) нь NLP-ын урлагийн байдлыг олон ажил дээр сайжруулсан. Энэ нь синтактикийн мэдлэг ПЛМ суралцахын тулд маш их сонирхолтой болсон. Энэ асуултын өмнөх ойлголт хязгаарлагдсан, ихэнхдээ шалгалтын суурь эсвэл судалгааг ашигладаг. Энд бид PLM анхаарлын толгойд байгууллагын моднуудыг нэмэгдүүлэх шинэ шинэ хуваалцааны арга зам санал болгож байна. Бид анхаарлыг өөрчилж чадварыг өөрчилж, төгсгөл модыг бүтээхэд өндөр хэмжээний толгой бүтээж байна. Бидний арга нь бага боловсролын хэл дээр зохицох боломжтой. Яагаад гэвэл хөгжлийн багш хэл дээр итгэлтэй байдаггүй. Бидний туршилтууд санал өгсөн аргыг ихэвчлэн хөгжлийн төлөө байхгүй бол оршиж буй арга замыг дамжуулдаг гэдгийг харуулдаг. Бидний хүлээн зөвшөөрөгдсөн хуваагч мөн ПЛМ-г грамм шинжилгээнд суралцах хэрэгсэл болгож ашиглаж болно. Үүний тулд бид мэдрэлийн PCFG-г суралцаж, хүн төрөлхтний замбараас гарсан грамматтай харьцуулахын тулд өөрсдийн арга замыг ашиглаж байна.', 'mt': 'Il-mudelli tal-lingwi mħarrġa minn qabel ibbażati fuq it-trasformaturi (PLMs) tejbu b’mod drammatiku l-aktar avvanzati fil-NLP f’bosta kompiti. Dan wassal għal interess sostanzjali fl-analiżi tal-għarfien sintattiku tat-tagħlim tal-PLMs. L-approċċi preċedenti għal din il-kwistjoni kienu limitati, l-aktar bl-użu ta’ suites jew sondi tat-test. Hawnhekk, qed nipproponu approċċ ġdid għall-analiżi kompletament mhux sorveljat li jastrezzjona s-siġar tal-kostitwenza minn kapijiet tal-attenzjoni tal-PLM. We rank transformer attention heads based on their inherent properties, and create an ensemble of high-ranking heads to produce the final tree.  Our method is adaptable to low-resource languages, as it does not rely on development sets, which can be expensive to annotate.  L-esperimenti tagħna juru li l-metodu propost spiss jaqbeż l-approċċi eżistenti jekk ma jkunx hemm sett ta’ żvilupp preżenti. Il-analizzatur mhux sorveljat tagħna jista’ jintuża wkoll bħala għodda biex janalizza l-grammi PLMs jitgħallmu impliċitament. Għal dan, a ħna nużaw is-siġar tal-analiżi indotti mill-metodu tagħna biex inħarrġu PCFG newrali u nqabblu ma’ gramma derivata minn tarf tas-siġar annotat mill-bniedem.', 'ml': 'Transformer-based pre-trained language models (PLMs) have dramatically improved the state of the art in NLP across many tasks.  ഇത് പിഎല്\u200dഎസ് പഠിക്കുന്ന സിന്റാക്റ്റിക്ക് അറിവ് വിശദീകരിക്കുന്നതിന് വളരെ താല്പര്യമുണ്ടാക്കി ഈ ചോദ്യത്തിന്റെ മുമ്പുള്ള സമ്മാനങ്ങള്\u200d പരീക്ഷ സ്യൂട്ടുകളോ പരീക്ഷണങ്ങളോ ഉപയോഗിച്ചിരിക്കുന്നു. ഇവിടെ, നമ്മള്\u200d ഒരു നോവല്\u200d പൂര്\u200dണ്ണമായും സംരക്ഷിക്കപ്പെടാത്ത പാര്\u200dജിങ്ങിന്\u200dറെ അടുത്ത് നിര്\u200dദേശിക്കുന്നു. പിഎല്\u200dഎമി അവയുടെ ഉള്ളിലുള്ള സ്വത്തുക്കള്\u200dക്ക് അടിസ്ഥാനത്തില്\u200d നാം ശ്രദ്ധ മാറ്റുന്ന തലകള്\u200d മാറ്റുന്നു. അവസാന വൃക്ഷത്തെ ഉണ്ട നമ്മുടെ രീതിയില്\u200d കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകള്\u200dക്ക് സമര്\u200dപ്പിക്കാന്\u200d സാധിക്കുന്നു. അത് വികസിപ്പിക്കാന്\u200d വിലയേറ്റ നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു പ്രൊദ്ദേശിക്കപ്പെട്ട രീതിയില്\u200d നിലവിലുള്ള വഴി നമ്മുടെ സംരക്ഷിക്കപ്പെടാത്ത പരാജയപ്രകാരം പിഎല്\u200dഎസ് പഠിക്കുന്നതിനെ പരിശോധിക്കാന്\u200d ഒരു ഉപകരണമായി ഉപയോഗിക്കാം. ഇതിന് വേണ്ടി, നമ്മുടെ രീതിയിലൂടെ ന്യൂറല്\u200d പിസിഎഫിജിയെ പരിശീലിപ്പിക്കുന്ന പാര്\u200dസ് വൃക്ഷങ്ങള്\u200d ഉപയോഗിക്കുന്നു. മനുഷ്യന്\u200d പ്രശ്നമു', 'no': 'Transformeringsbasert først- trengde språk- modeller (PLMs) har dramatisk forbedra kunstået i NLP over mange oppgåver. Dette har ført til å analysere syntaksiske kunnskap PLMs lære stor interesse. Førre tilnærmingar til denne spørsmålet er begrenset, hovudsakelig brukar testsuite eller prober. Her foreslår vi ein novel fullstendig usikkert tolkingslinjen som ekstraherer konstitusjonstrær frå PLM-oppmerkshoder. Vi rankerer transformeringshoder basert på sine eigenskapar, og lagar ein ensembel av høg rankeringshoder for å produsera den siste treen. Metoden vårt er tilpassabil til låg ressursspråk, sidan den ikkje er tilhøyrande på utviklingssett, som kan vera dyp for å merke merknaden. Eksperimentane våre viser at den foreslåde metoden ofte utfører eksisterande tilnærmingar viss det ikkje finst utviklinga. Vårt ikkje-oppretta tolkar kan også brukast som verktøy for å analysera grammar PLMs lære implisitt. For dette bruker vi tolkingstemmene som er indusert av metoden vårt for å trene ein neural PCFG og sammenligne det med eit grammar som er avhengig frå ein menneskelig markert treebank.', 'ro': 'Modelele lingvistice pre-instruite bazate pe transformatori (PLM) au îmbunătățit dramatic starea de ultimă oră în PNL în multe sarcini. Acest lucru a condus la un interes substanțial în analiza cunoștințelor sintactice pe care PLM le învață. Abordările anterioare la această întrebare au fost limitate, în principal folosind suite de testare sau sonde. Aici, propunem o abordare nouă de analiză complet nesupravegheată, care extrage copacii din circumscripții electorale din capetele de atenție PLM. Clasificăm capetele de atenție ale transformatorului în funcție de proprietățile inerente și creăm un ansamblu de capete de rang înalt pentru a produce copacul final. Metoda noastră este adaptabilă la limbaje cu resurse reduse, deoarece nu se bazează pe seturi de dezvoltare, care pot fi scumpe de adnotat. Experimentele noastre arată că metoda propusă depășește adesea abordările existente dacă nu există un set de dezvoltare prezent. Parserul nostru nesupravegheat poate fi, de asemenea, folosit ca instrument pentru a analiza gramaticale PLM învață implicit. Pentru aceasta, folosim arborii de pătrundere induși de metoda noastră pentru a antrena un PCFG neural și compara-l cu o gramatică derivată dintr-un copac adnotat de om.', 'pl': 'Wstępnie przeszkolone modele językowe oparte na transformatorach (PLM) znacznie poprawiły stan techniki w NLP w wielu zadaniach. Doprowadziło to do dużego zainteresowania analizą wiedzy składniowej, którą PLM uczą. Dotychczasowe podejście do tego pytania było ograniczone, głównie przy użyciu zestawów testowych lub sond. Proponujemy tutaj nowe, w pełni bez nadzoru podejście parsowania, które wydobywa drzewa okręgów wyborczych z głów uwagi PLM. Rankingujemy głowy uwagi transformatorów na podstawie ich nieodłącznych właściwości i tworzymy zespół głów wysokiej rangi, aby wyprodukować ostateczne drzewo. Nasza metoda może być dostosowana do języków o niskich zasobach, ponieważ nie opiera się na zestawach programistycznych, których adnotacja może być kosztowna. Nasze eksperymenty pokazują, że proponowana metoda często przewyższa istniejące podejścia, jeśli nie ma obecnego zestawu rozwojowego. Nasz nienadzorowany parser może być również używany jako narzędzie do analizy gramatyki PLM uczą się domyślnie. W tym celu używamy drzew parse indukowanych naszą metodą do treningu neuronowego PCFG i porównywamy go z gramatyką pochodzącą z adnotacji drzewa przez człowieka.', 'sr': 'Preobučeni jezički modeli na transformaciji (PLMs) dramatično su poboljšali stanje umjetnosti u NLP u mnogim zadacima. To je dovelo do značajnog interesa u analizu sintaktičkog znanja koje su PLMs naučili. Prethodni pristupi ovom pitanju su ograničeni, uglavnom koristeći testne odijele ili sonde. Ovde predlažemo roman potpuno neodređen pristup analizacije koji izvlači drveće iz glave pozornosti PLM-a. Počinjemo preobraćajuću pažnju glave na temelju njihovih inherentnih vlasništva i stvoriti ensemble visokog reda glava da proizvedemo konačno drvo. Naša metoda je prilagodljiva jezicima niskih resursa, jer se ne oslanja na setove razvoja, koje mogu biti skupe za annotaciju. Naši eksperimenti pokazuju da predložena metoda često iznosi postojeće pristupe ako nema prisutnog razvoja. Naš nepotrebni analitičar se takođe može koristiti kao alat za analiziranje gramara PLMs-a implicitno naučiti. Za to koristimo prazničke drveće koje su izazvane našim metodom da treniramo neuralnu PCFG i usporedimo ga sa gramatikom iz ljudskog annotiranog drveta.', 'si': 'වෙනස්ථාපකය සඳහා ප්\u200dරධානය කරපු භාෂා මොඩේල්ස් (PlMs) නිර්මාණය කරන්නේ NLP වල ඉන්න කිරීමේ ස්ථිතිය ගොඩක් වැඩ මේක ප්\u200dරශ්නයක් විශ්ලේෂණය කරන්න පුළුවන් විශ්ලේෂණයෙන් ප්\u200dරශ්නයක් තියෙන්නේ. මේ ප්\u200dරශ්නයට කලින් ප්\u200dරශ්නයක් සීමාවිත් වෙලා තියෙන්නේ, ප්\u200dරශ්නයක් පරීක්ෂණ සුටිට් නැ මෙන්න, අපි ප්\u200dරතිචාරයක් පුළුවන් නොපුරුද්ධ විශ්ලේෂණයක් ප්\u200dරවේශනය කරන්න පුළුවන් විදිහට ප්\u200dරවේශන අපි ඔවුන්ගේ විශේෂ විශේෂ ප්\u200dරතිපත්තිය අධාරිත්වයෙන් ප්\u200dරමාණය කරනවා, ඔවුන්ගේ අන්තිම වස්තුවක් නිර්මා අපේ විධානය අඩුම සම්බන්ධ භාෂාවට සම්බන්ධ වෙන්න පුළුවන්, ඒක විකාශ සෙට්ටුවට විශ්වාස කරන්නේ නැහැ අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට ප්\u200dරවේශ විදිහට සාමාන්\u200dය විදිහට ප්\u200dරවේශනය කරන්න පුළුවන අපේ නැවතිරීක්ෂණ විශාලකය ප්\u200dරයෝජනය කරන්න පුළුවන් තියෙන්නේ ප්\u200dරයෝජනයක් විශ්ලේෂනය කරන්න. මේකට, අපි අපේ විධානයෙන් පාර්ස් ගස් පාවිච්චි කරනවා න්\u200dයූරාල් PCFG ක්\u200dරියාන්ත කරන්න, ඒක මිනිස්සුන්ගේ ප්\u200dරතිකාරයෙන් පිළ', 'so': "Tusaalada afka hore oo lagu tababaray (PLMs) waxay si aad ah u kordhisay xaaladda farshaxanka ee NLP shaqooyin badan. Tan waxaa sababtay in aad u xiisayso baaritaanka aqoonta la xiriira ay bartaan asalka PLMs. Dhaqdooyinkii hore ee su'aalahan waa la xaday, inta badan isticmaalaya dharka imtixaanka ama imtixaanka. Halkan, waxaynu soo jeedaynaa warqad baaritaanka oo dhan aan la ilaalinayn, taasoo ka soo saara geedo ka mid ah madaxa PLM. Waxaannu kor u bedelaa madaxa digtoonaanta, iyadoo ku saleysan hantida ay leeyihiin, waxaana sameynaa tusaale madaxa sare si ay u soo bixiso geedka ugu dambeeya. Our method is adaptable to low-resource languages, as it does not rely on development sets, which can be expensive to annotate.  Imtixaankayada waxay muuqataa in qaababka la soo jeeday ay ay marar badan sameeyaan qaabab joogta ah haddii aysan jirin meel horumarinta ah. Parameerkeenna aan ilaalinayn waxaa sidoo kale looga isticmaali karaa qalabka lagu baarito maareynta PLMs inay si cadaan u baraan. Taas darteed waxaynu isticmaalnaa geedaha baaritaanka oo noogu soo bandhigayo qaab aan ku tababarinno PCFG neurada ah, waxaynu isbarbareynaa qof ka soo baxay geed baabuur ah oo dadku dhibaataysan.", 'sv': 'Transformarbaserade pre-trained language models (PLM) har dramatiskt förbättrat det senaste inom NLP för många uppgifter. Detta har lett till ett stort intresse för att analysera den syntaktiska kunskap PLM lär sig. Tidigare tillvägagångssätt på denna fråga har varit begränsade, främst med hjälp av testsviter eller sonder. Här föreslår vi en ny helt obevakad tolkningsmetod som extraherar valkretsträd från PLM:s uppmärksamhet huvuden. Vi rangordnar transformatorns uppmärksamhetshuvud baserat på deras inneboende egenskaper och skapar en ensemble av högt rankade huvuden för att producera det slutliga trädet. Vår metod är anpassningsbar till lågresursspråk, eftersom den inte förlitar sig på utvecklingsuppsättningar, vilket kan vara dyrt att kommentera. Våra experiment visar att den föreslagna metoden ofta överträffar befintliga metoder om det inte finns någon utvecklingsuppsättning närvarande. Vår oövervakade parser kan också användas som ett verktyg för att analysera grammatiken PLMs lär sig implicit. För detta använder vi parseträden som induceras av vår metod för att träna en neural PCFG och jämföra den med en grammatik som härrör från en mänsklig-kommenterad trädbank.', 'ta': 'மாற்றியமைப்பு முன் பயிற்சி மொழி மாதிரிகள் (PLMs) பல பணிகளில் உள்ள கலைஞர் நிலையை மேம்படுத்தியுள்ளது. இது பிஎல்எம்ஸ் கற்றுக்கொள்ளும் ஒத்திசைவு அறிவை ஆராய்ச்சியில் மிகப்பெரிய வட்டி @ info இங்கு, நாம் ஒரு புதையத்தை முழும் பாதுகாப்பாக்கப்படாத பாடல் நெருக்கம் என்று பரிந்துரைக்கிறோம். பிஎல்எம் தலைவர்களி நாம் அவர்களுடைய உள்ளூர்ந்த பண்புகளை அடிப்படையில் கவனத்தை மாற்றுகிறோம், மற்றும் கடைசி மரத்தை உருவாக்க ஒரு உயர்ந்த தலைவர் எங்கள் முறைமையில் குறைந்த மூலத்தின் மொழிகளுக்கு ஒப்புக்கொள்ள முடியும், ஏனெனில் அது வளர்ச்சி அமைப்புகளை நம்புவதி எங்கள் சோதனைகள் முன்னோக்கப்பட்ட முறைமையில் பெரும்பாலாக இருக்கும் வழிகளை வெளியேற்றுகிறது என்று காட் எங்கள் பாதுகாப்பாக்கப்படாத பகுதியை பிஎல்எம்ஸ் பிரச்சனைகளை சரிபார்க்க ஒரு கருவியாக பயன்படுத்த முடியும். இதுக்கு, நாம் எங்கள் முறைமையால் தொடங்கப்பட்ட பிசிஎஃப்ஜி பயிற்சியை பயன்படுத்தி ஒரு மனிதன் அறிவிக்கப்பட்ட மரத்திற்கு அதை ஒப்பிடுகிறோம்.', 'ur': 'ٹرانسفور بنیاد پر پیش ترسین کی زبان موڈل (PLMs) نے NLP میں بہت سی کاموں میں هنر کی حالت بہت اچھی کر دی ہے. یہ سینٹکتیک علم PLMs کی تعلیم کے بارے میں بہت زیادہ علاقمند ہوا ہے. اس سوال کے پہلے طریقے محدود ہوئے ہیں، زیادہ سے تست سوئٹ یا پرڈز کے استعمال کرتے ہیں. یہاں، ہم ایک نوم کی پیشنهاد کرتے ہیں جو کامل غیر قابل تحقیق کی تقریبا ہے جو PLM کے سروں سے محیط درختوں کو نکالتا ہے. اور ہم ان کے اموال پر سر تغییر دینے والے ہیں اور ان کے سروں میں ایک مضبوط سر بناتے ہیں تاکہ آخر درخت پیدا کریں ہمارا طریقہ کم سروسیز زبانوں پر اضافہ کرنے والا ہے، کیونکہ یہ توسعہ سٹوں پر اعتماد نہیں کرتا، جو اضافہ کرنے کے لئے بہت گران ہے. ہمارے آزمائش دکھاتے ہیں کہ پیشنهاد کی طریقہ بہت زیادہ موجود آزمائش کے مطابق انجام دیتی ہے اگر موجود کوئی توسعہ مقرر نہیں ہوتی۔ ہمارے غیرقابل پارچر کو بھی ایک ابزار کے طور پر استعمال کر سکتا ہے کہ گرامر PLMs کو غیرقابل تحقیق کرنے کے لئے استعمال کر سکتے ہیں. اس کے لئے ہم اپنے طریقے سے پیوست کے درختوں کو استعمال کرتے ہیں کہ ایک نئورل PCFG کی تعلیم کریں اور اسے ایک نئورل ٹریبنک سے پیدا ہوا گراماری سے مقایسہ کریں۔', 'uz': "Name Name @ info: whatsthis Bu yerda, biz muvaffaqiyatli muvaffaqiyatli xabar qilmagan darajani PLM boshqaruvchilaridan olib tashlash mumkin. Biz ma'lumotni o'zgartirib o'zgartirib turamiz. Biz o'zgarishni o'zgartirib, o'zgarishni o'zgartirishimiz mumkin. Бизнинг усулимиз кам манбалар тилларга мойил бўлиши мумкин, chunki у тарзда ишонч таркиб этиш мумкин эмас, бу қизиқ тафаккур учун қизиқ бўлиши мумкин. Bizning tajribalarimizni ko'rsatishimiz, taʼminlovchi usul mavjud usullarni ko'pincha bajarishi mumkin, agar taʼminlovchi mavjud emas. Bizning saqlanmagan параметрларимиз PLMs grammatika muvaffaqiyatli o'rganish uchun asboblar sifatida ishlatiladi. Bu uchun biz neyural PCFG'ni o'rganish usuli bilan bir parcha daraxtlardan foydalanamiz va biz odamning taxminan darajadagi grammatika o'rganamiz.", 'vi': 'Chế độ biến hình đã được đào tạo từ các mô hình ngôn ngữ nguyên bản (PLM) đã cải thiện hoàn toàn trạng thái nghệ thuật tại Njala trong nhiều nhiệm vụ. Điều này đã dẫn đến sự quan tâm lớn trong việc phân tích kiến thức cú pháp mà PLM đã học. Các phương pháp trước đã được giới hạn, chủ yếu sử dụng các phòng thí nghiệm hoặc các vòi thăm dò. Ở đây, chúng tôi đề nghị một phương pháp phân tích hoàn toàn mới mà không được giám sát, tách các cây bầu của các vị trí chú ý PLM. Chúng tôi xếp hạng các đầu mũi tập trung chuyển hóa dựa trên tính chất của chúng, và tạo ra một kết hợp những cái đầu cao cấp để sản xuất cái cây cuối cùng. Phương pháp của chúng ta có thể thích nghi với ngôn ngữ có ít tài nguyên, vì nó không dựa vào các bộ phát triển, mà có thể tốn tiền ghi chú. Những thí nghiệm của chúng tôi cho thấy phương pháp được đề nghị thường vượt trội các phương pháp tồn tại nếu không có trường hợp phát triển. Tên cha xứ không giám sát của chúng ta cũng có thể dùng làm công cụ để phân tích các tạp chí ảo. Chúng tôi dùng các cây cha xứ được tạo ra theo phương pháp để đào tạo PCFG và so sánh nó với loại ngữ pháp bắt nguồn từ một cây ba-đông được ghi chú người.', 'bg': 'Предварително обучените езикови модели, базирани на трансформатори, драстично подобриха състоянието на новите технологии в НЛП при много задачи. Това доведе до значителен интерес към анализирането на синтактичните знания, които се научават. Предишните подходи към този въпрос са ограничени, най-вече използвайки тестови комплекти или сонди. Тук предлагаме нов напълно ненадзорен подход за анализ, който извлича дърветата от избирателните райони от вниманието на ПЛМ. Ние подреждаме главите на вниманието на трансформаторите въз основа на присъщите им свойства и създаваме ансамбъл от високопоставени глави за производство на окончателното дърво. Нашият метод е адаптивен към езици с ниски ресурси, тъй като не разчита на набор от разработки, които могат да бъдат скъпи за анотиране. Нашите експерименти показват, че предложеният метод често превъзхожда съществуващите подходи, ако не присъства набор от разработки. Нашият ненадзорен анализатор може да се използва и като инструмент за анализ на граматиките, които изучават имплицитно. За тази цел използваме анализиращите дървета, индуцирани от нашия метод, за да обучим неврален ПЦФГ и да го сравним с граматика, получена от човешко анотирана дървесна банка.', 'da': "Transformer-baserede prætrænede sprogmodeller (PLM'er) har dramatisk forbedret den nyeste teknologi inden for NLP på tværs af mange opgaver. Dette har ført til betydelig interesse i at analysere den syntaktiske viden PLM'er lærer. Tidligere tilgange til dette spørgsmål har været begrænset, hovedsagelig ved hjælp af testsuiter eller sonder. Her foreslår vi en ny fuldt overvåget analysemetode, der udtrækker valgkredsstræer fra PLM's opmærksomhedshoveder. Vi rangerer transformatoropmærksomhedshoveder baseret på deres iboende egenskaber, og skaber et ensemble af højtstående hoveder til at producere det endelige træ. Vores metode kan tilpasses sprog med lav ressource, da den ikke er afhængig af udviklingssæt, som kan være dyrt at kommentere. Vores eksperimenter viser, at den foreslåede metode ofte overgår eksisterende metoder, hvis der ikke er nogen udviklingssæt til stede. Vores uautoriserede fortolker kan også bruges som et værktøj til at analysere grammatikken PLM'er lærer implicit. Til dette bruger vi parsetræerne induceret af vores metode til at træne en neural PCFG og sammenligne det med en grammatik afledt af en menneskelig-kommenteret træbank.", 'nl': "Op transformatorgebaseerde vooraf getrainde taalmodellen (PLM's) hebben de stand van de techniek in NLP voor veel taken drastisch verbeterd. Dit heeft geleid tot een aanzienlijke interesse in het analyseren van de syntactische kennis die PLM's leren. Eerdere benaderingen van deze vraag waren beperkt, meestal met behulp van testsuites of sondes. Hier stellen we een nieuwe volledig onbeheerde parsing-aanpak voor die kiesdistrictbomen uit PLM-aandachtskoppen haalt. We rangschikken de aandacht van transformatoren op basis van hun inherente eigenschappen en creëren een ensemble van hooggeplaatste hoofden om de uiteindelijke boom te produceren. Onze methode is aanpasbaar aan low-resource talen, omdat het niet afhankelijk is van ontwikkelingssets, die duur kunnen zijn om te annoteren. Uit onze experimenten blijkt dat de voorgestelde methode vaak beter presteert dan bestaande benaderingen als er geen ontwikkelingsset aanwezig is. Onze onbeheerde parser kan ook worden gebruikt als een hulpmiddel om de grammatica's die PLM's impliciet leren te analyseren. Hiervoor gebruiken we de parse trees geïnduceerd door onze methode om een neurale PCFG te trainen en te vergelijken met een grammatica afgeleid van een door mensen geannoteerde boombank.", 'hr': 'Preobučeni jezički modeli na transformaciji (PLMs) dramatično su poboljšali stanje umjetnosti u NLP u mnogim zadatkima. To je dovelo do značajnog interesa analiziranja sintaktičkih znanja koje su PLMs naučili. Prethodni pristupi ovom pitanju su ograničeni, uglavnom koristeći testne odijele ili sonde. Ovdje predlažemo nov potpuno neodređen pristup razmatranja koji izvlači drveće iz pozornosti PLM-a. Počinjemo preobraćajuću pažnju glave na temelju njihovih inherentnih vlasništva i stvoriti ensemble visokog reda glava kako bi proizveli konačno drvo. Naša metoda je prilagodljiva jezicima niskih resursa, jer se ne oslanja na setove razvoja, koje mogu biti skupe za annotaciju. Naši eksperimenti pokazuju da predložena metoda često iznosi postojeće pristupe ako nema prisutnog razvoja. Naš neodređeni analitičar može se također koristiti kao alat za analiziranje gramara PLMs-a implicitno naučiti. Za to koristimo prazničke drveće koje su izazvane našim metodom da obučimo neuralnu PCFG i usporedimo ga s gramatikom iz ljudskog annotiranog drveta.', 'de': 'Transformatorbasierte vortrainierte Sprachmodelle (PLMs) haben den Stand der Technik in NLP für viele Aufgaben drastisch verbessert. Dies hat zu einem erheblichen Interesse an der Analyse des syntaktischen Wissens geführt, das PLMs erlernen. Bisherige Ansätze zu dieser Frage waren begrenzt, zumeist mit Testsuiten oder Sonden. Hier schlagen wir einen neuartigen völlig unbeaufsichtigten Parsing-Ansatz vor, der aus PLM-Aufmerksamkeitsköpfen Wahlkreisbäume extrahiert. Wir ordnen Transformatoraufmerksamkeitsköpfe basierend auf ihren inhärenten Eigenschaften ein und erstellen ein Ensemble hochrangiger Köpfe, um den endgültigen Baum zu produzieren. Unsere Methode ist an ressourcenarme Sprachen anpassbar, da sie nicht auf Entwicklungssets angewiesen ist, die teuer zu kommentieren sein können. Unsere Experimente zeigen, dass die vorgeschlagene Methode oft bestehende Ansätze übertrifft, wenn kein Entwicklungsset vorhanden ist. Unser unüberwachter Parser kann auch als Werkzeug verwendet werden, um die Grammatiken zu analysieren, die PLMs implizit lernen. Dazu verwenden wir die Parse-Bäume, die durch unsere Methode induziert werden, um ein neuronales PCFG zu trainieren und es mit einer Grammatik zu vergleichen, die von einer vom Menschen kommentierten Baumbank abgeleitet wird.', 'id': 'Model bahasa pra-dilatih (PLM) berasasi transformer telah meningkatkan keadaan seni dalam NLP secara dramatis melalui banyak tugas. Ini telah menyebabkan kepentingan besar dalam menganalisis pengetahuan sintaksi PLMs belajar. Pendekatan sebelumnya untuk pertanyaan ini telah terbatas, kebanyakan menggunakan pakaian tes atau sonda. Di sini, kami mengusulkan novel pendekatan analisis yang tidak diawasi sepenuhnya yang mengekstrak pohon konstitusi dari kepala perhatian PLM. Kami mengatur kepala perhatian transformer berdasarkan properti mereka, dan menciptakan sebuah kumpulan kepala tinggi untuk menghasilkan pohon akhir. Metode kita dapat diadaptasi dengan bahasa sumber daya rendah, karena tidak bergantung pada set pengembangan, yang bisa mahal untuk mengatakannya. Eksperimen kami menunjukkan bahwa metode yang diusulkan sering melebihi pendekatan yang ada jika tidak ada set perkembangan yang ada. Analisa kami tidak diawasi juga dapat digunakan sebagai alat untuk menganalisa grammar PLMs belajar secara implicit. Untuk ini, kami menggunakan pohon analisis yang didorong oleh metode kami untuk melatih PCFG saraf dan membandingkannya dengan gramatika yang didorong dari batang pohon yang dicatat oleh manusia.', 'ko': 'Transformer를 바탕으로 하는 예비 훈련 언어 모델(PLM)은 NLP가 많은 임무에서 선진성을 크게 향상시켰다.이 때문에 PLMs에서 배운 문법 지식을 분석하는 데 많은 관심을 가지게 되었다.이전에 이 문제를 해결하는 방법은 유한했고 주로 테스트 세트나 탐지기를 사용했다.여기서 우리는 PLM 주의 헤드에서 선택 트리를 추출하는 새로운 완전 무감독 해석 방법을 제시했다.우리는 변압기 주의 헤드의 고유 속성에 따라 정렬하고, 고급 헤드 집합을 만들어서 최종 트리를 생성합니다.우리의 방법은 저자원 언어에 적용된다. 왜냐하면 개발집에 의존하지 않기 때문에 개발집의 주석 원가가 매우 높을 수 있기 때문이다.우리의 실험은 개발집이 없는 상황에서 이 방법의 성능은 왕왕 기존의 방법보다 우수하다는 것을 보여 주었다.우리의 무감독 해석기는 PLMs 스텔스 학습 문법을 분석하는 도구로도 사용할 수 있다.이를 위해 우리는 우리의 방법으로 생성된 해석 트리를 사용하여 신경 PCFG를 훈련시키고 이를 인류 주석 트리 라이브러리에서 나온 문법과 비교한다.', 'sw': 'Mfano wa lugha za zamani uliofanyika na zamani (PLMs) umeboresha hali ya sanaa ya NLP katika kazi nyingi. Hii imesababisha maslahi makubwa ya kuchambua maarifa ya pamoja ya maarifa ya PLMs yanayojifunza. Matokeo yaliyopita kwa swali hili yamekuwa vizuizi, zaidi kwa kutumia mavazi ya jaribio au majaribio. Hapa, tunapendekeza riwaya isiyo na usalama wa wimbo ambao unatoa miti ya ubunge kutoka vichwa vya PLM. Tunawabadilisha vichwa vya habari kwa kutumia utajiri wao, na kutengeneza mifano ya vichwa vya juu ili kutengeneza mti wa mwisho. Utawala wetu unaweza kubalika kwa lugha za chini za rasilimali, kwa sababu haitegemea seti za maendeleo, ambazo zinaweza kuwa ghali kwa kutangaza. Our experiments show that the proposed method often outperform existing approaches if there is no development set present.  Anachambua wetu wasio na usalama anaweza pia kutumika kama nyenzo ya kuchambua maarufu wa PLMs wanajifunza kwa ufanisi. Kwa hili, tunatumia mti wa bunge uliotengenezwa na njia yetu ya kufundisha PCFG ya neura na kulinganisha na mchoro uliotolewa kutoka kwenye benki ya miti iliyochangazwa na binadamu.', 'sq': 'Modelet e gjuhës paratrajnuara me bazë në transformime (PLM) kanë përmirësuar dramatikisht gjendjen e artit në NLP nëpërmjet shumë detyrave. Kjo ka shpjerë në interes thelbësor në analizën e njohurive sintaktike që mësojnë PLMs. Përqasjet e mëparshme ndaj kësaj pyetjeje janë të kufizuara, kryesisht duke përdorur kostume testimi apo sonda. Këtu, ne propozojmë një metodë të re analizuese plotësisht të pazgjidhur që nxjerr pemët e qarkut zgjedhor nga kokat e vëmendjes PLM. Ne rendisim kokat e vëmendjes së transformuesve bazuar në pronat e tyre të përbashkëta, dhe krijojmë një grup kokash të larta për të prodhuar pemën finale. Metoda jonë është e përshtatshme ndaj gjuhëve me burime të ulëta, pasi nuk mbështetet në grupe zhvillimi, që mund të jetë e shtrenjtë për të shënuar. Eksperimentet tona tregojnë se metoda e propozuar shpesh kalon qasjet ekzistuese në qoftë se nuk ka asnjë zhvillim të pranishëm. Analizatori ynë i pazgjidhur mund të përdoret gjithashtu si një mjet për të analizuar gramatikat që PLMs mësojnë implicitisht. Për këtë, ne përdorim pemët e analizimit të induktuara nga metoda jonë për të trajnuar një PCFG nervore dhe për ta krahasuar me një gramatikë të prodhuar nga një bazë pemësh të anotuar nga njeriu.', 'am': 'የተለየው የፊተኛውን የቋንቋ ሞዴላዎች (PLMs) በብዙ ስራ በNLP የዐርላዊውን ሁኔታ በጥያቄ አሻርቷል፡፡ ይህም የPLMs እውቀትን በማስተማርና የሚያሳውቀው የውጤት ጉዳይ ነው፡፡ Previous approaches to this question have been limited, mostly using test suites or probes.  ወደዚህ፣ የፓርቲው ዛፎችን ከPLM ራስ ውጤት እንዲያወጣ የመዘርጊያውን አቀናቅላታል፡፡ የፍጻሜውን ዛፍ ለመፍጠር የረጅም ራስ ምሳሌ እናደርጋለን፡፡ እና ልማዳችን የዝቅተኛ ዕቃ ቋንቋዎች ማሰናከል ይችላል፣ ምክንያቱም በመፍጠር ላይ አይታመንም፡፡ ፈተናዎቻችን ብዙ ጊዜ የአሁኑን ሥርዓት ማድረግ ባይኖር እንደተፈጸመ ነው፡፡ ያልጠበቀው ተፈላጊያችን PLMs በጥያቄ ለማስተማር እንደሚችል መጠቀም ይችላል፡፡ ለዚህ ምክንያት የፖስቲካ ፕዩኤፍG የደረሰውን የፓርላማ ዛፎችን እናስቀራለን እና ከሰው ተቃውሞ ከሚገኘው መዝገብ ጋር እናስተያየዋለን፡፡', 'hy': 'Transformer-based pre-trained language models (PLMs) have dramatically improved the state of the art in NLP across many tasks.  Սա մեծ հետաքրքրություն է հանգեցրել Սինտակտիկ գիտելիքների ուսումնասիրության մեջ: Այս հարցին նախորդ մոտեցումները սահմանափակված են, հիմնականում օգտագործելով փորձարկման հագուստներ կամ Sondes: Այստեղ մենք առաջարկում ենք նոր, ամբողջովին անվերահսկված վերլուծության մոտեցում, որը հանում է ընտրական շրջանի ծառերը PLM ուշադրության գլխավորներից: Մենք դասակարգում ենք վերափոխող ուշադրության գլխավորները հիմնված իրենց բնորոշ հատկությունների վրա, և ստեղծում ենք բարձր դասակարգված գլխավորների համակարգ վերջնական ծառի արտադրելու համար: Մեր մեթոդը հարմարվում է ցածր ռեսուրսների լեզուներին, քանի որ այն չի հիմնված զարգացման համակարգերի վրա, որոնք կարող են թանկ նշումներ անել: Մեր փորձարկումները ցույց են տալիս, որ առաջարկված մեթոդը հաճախ գերազանցում է գոյություն ունեցող մոտեցումները, եթե գոյություն չունի զարգացում: Մեր անվերահսկված վերլուծողը կարող է նաև օգտագործվել որպես գործիք, որպեսզի վերլուծենք գրամագրությունները, որոնք PLM-ները անմիջապես սովորում են: Այս դեպքում մենք օգտագործում ենք մեր մեթոդով արտադրված վերլուծության ծառերը նյարդային պոֆԳ-ի վարժեցնելու համար և համեմատում ենք այն մարդկային գրամագրության հետ, որը ստեղծվել է ծառի վրա:', 'az': 'Transformer-based öyrənmiş dil modelləri (PLMs) NLP sanatının durumunu çox işlərdə dəhşətli təhsil etdi. Bu, sintaktik bilgi PLMs öyrənməsini analizə etmək üçün çox maraqlıdır. Bu sualın əvvəlki yaxınlıqları müəyyən edilmişdir, çox sınaq sütüklərini və sondu istifadə edir. Burada, biz tamamilə müəyyən edilməmiş bir yeni ayırma approach təklif edirik ki, PLM gözləmə a ğaclarını çıxarır. Biz onların özlərinin mallarının üstündə dəyişdirir və sonuncu ağacı ürəkləmək üçün yüksək dəyişdirilmiş başlıqların körpüsünü yararıq. Bizim metodumuz düşük ressurs dillərinə uyğunlaşdırılabilir, çünki bu təhsil qurğularına təvəkkül etmirdi, bu təhsil edilmək üçün mal olar. Bizim təcrübələrimiz göstərir ki, əgər təcrübə edilən metodların orada heç bir təcrübə edilməsə, həmişəlik mövcuddur yaxınlıqlarından daha çox üstün olur. Bizim qeyri-müdafiə edilməmiş paylayıcımız də Grammar PLMs öyrənmək üçün istifadə edilə bilər. Buna görə, biz neural PCFG təhsil etmək üçün yaratdığımız təhsil a ğaclarını və insan təhsil edilmiş çubuğundan qazanmış bir gramatika karşılaşdırırıq.', 'bn': 'ভিত্তিক ভিত্তিক ভিত্তিক ভাষার পূর্ব প্রশিক্ষিত ভাষার মডেল (পিএলএমএস) অনেক কাজের মধ্যে এনএলপির শিল্পের অবস্থা ন্য এটি পিএলএমএস শিক্ষার বিশ্লেষণের জন্য গুরুত্বপূর্ণ আগ্রহের সৃষ্টি করেছে। এই প্রশ্নের পূর্ববর্তী প্রতিক্রিয়া সীমিত, বেশীরভাগ পরীক্ষা স্যুট ব্যবহার করা হয়েছে। এখানে, আমরা পুরোপুরি সংরক্ষিত পার্সিং প্রস্তাব করি যে পিএলএম মের মাথার প্রতিনিধির গাছগুলো বের করে আনে। আমরা তাদের বিভিন্ন সম্পত্তি ভিত্তিতে মনোযোগ প্রদান করি এবং চূড়ান্ত গাছ উৎপন্ন করার জন্য একটি উদাহরণ তৈরি করি। Our method is adaptable to low-resource languages, as it does not rely on development sets, which can be expensive to annotate.  আমাদের পরীক্ষাগুলো দেখাচ্ছে যে প্রস্তাবিত পদ্ধতি প্রায়শই বিদ্যমান পদ্ধতি প্রকাশ করে যদি কোন উন্নয়ন সং আমাদের অরক্ষিত বিশ্লেষণের জন্য গ্রামার পিএলএমএস গ্রামার বিশ্লেষণের একটি টুল হিসেবে ব্যবহার করা যাবে। এর জন্য আমরা পার্স গাছ ব্যবহার করি নিউরেল পিসিএফজিকে প্রশিক্ষণ দিতে আমাদের পদ্ধতি দ্বারা উৎপাদন করা হয়েছে এবং এটি মানুষ-বিরক্তিকর ট্রিব্যাংক থ', 'bs': 'Preobučeni jezički modeli na transformaciji (PLMs) dramatično su poboljšali stanje umjetnosti u NLP u mnogim zadatkima. To je dovelo do značajnog interesa u analizu sintaktičkog znanja koje su PLMs naučili. Prethodni pristupi ovom pitanju su ograničeni, uglavnom koristeći testne odijele ili sonde. Ovdje predlažemo roman potpuno neodređen pristup razmatranju koji izvlači drveće iz glave pozornosti PLM-a. Mi postavljamo glave preobraćajuće pažnje na temelju njihovih nasljednih vlasništva, i stvorimo kompleks visokog reda glava kako bi proizveli konačno drvo. Naša metoda je prilagodljiva jezicima niskih resursa, jer se ne oslanja na setove razvoja, koje mogu biti skupe za annotaciju. Naši eksperimenti pokazuju da predložena metoda često iznosi postojeće pristupe ako nema prisutnog razvoja. Naš nepotrebni analitičar se također može koristiti kao alat za analiziranje gramara PLMs-a implicitno naučiti. Za to koristimo prazničke drveće koje su izazvane našim metodom da obučimo neuralnu PCFG i usporedimo ga sa gramatikom iz ljudskog noteiranog drveta.', 'tr': "NLP'da sungatyň durumyny köp işiň içinde görkezilip, terjime edilen öňünde bilim nusgalary (PLMs). Bu syntaktik bilim PLMsiniň öwrenmesini çözmek üçin örän gyzyklandyrdy. Bu soragyň öňki golaýlary çykardy. Köplenç synaglama süýtleri ýa-da sanallary ulanýar. Bu ýerde, PLM bilen meýdany agaçlary kellesinden daşary gaýşartmaklygyny doly tassyklanmadyk bir roman teklip edýäris. Biz öz hasaplaryna daýan ýar kellelerini üýtgederis we soňky agajyny üretmek üçin ýokary dereje kellelerini üýtgederis. Biziň ýüregimiz iň az resurslar dili bilen üýtgedip bilýär, sebäbi gelişme düzümlerine ynanmaýar, bu ýagdaýyň täsir edilen baýram bolup biler. Biziň deneylerimiz teklip eden yöntemiň köplenç bolan ýagdaýlaryň bardygyny görkezýär. Biziň tassyklanmadyk çözümleriň grammarlary PLM'yň ifade öwrenmesini çözmek üçin ullanýar. Bu üçin biz neural PCFG öwrenmek üçin ýüzümizden gelen pars agaçlaryny ulanýarys we muny adam bilen nasilsiz çörek bagyndan döredilen gramatika karşılaştyrýarys.", 'ca': "Els models de llenguatges pré-entrenats basats en transformadors han millorat dramàticament l'estat d'avançat de la NLP en moltes tasques. Això ha portat a un interès substancial en analitzar el coneixement sinàctic que aprenen els PLM. Els enfocaments anteriors a aquesta pregunta han estat limitats, principalment utilitzant suites o sondes de prova. Aquí proposem un nou enfocament d'analització completament sense supervisió que extreu arbres de districtes electorals dels cabells d'atenció de PLM. Estem classificant els cabells d'atenció dels transformadors basats en les seves propietats inherents, i creem un conjunt de cabells d'alta classe per produir l'arbre final. Our method is adaptable to low-resource languages, as it does not rely on development sets, which can be expensive to annotate.  Els nostres experiments mostren que el mètode proposat sovint supera els enfocaments existents si no hi ha un conjunt de desenvolupament present. El nostre analitzador no supervisat també pot ser utilitzat com una eina per analitzar les gramàtiques que els PLM aprenen implícitament. Per això, utilitzem els arbres d'analització induïts pel nostre mètode per formar un PCFG neural i comparar-lo amb una gramàtica derivada d'un banc d'arbres anotat per humans.", 'fa': 'مدلهای زبان پیش آموزش یافته (PLMs) بر اساس تغییر\u200cپذیر، وضعیت هنری در NLP در طول بسیاری از کار\u200cهای زیادی بهبود داده\u200cاند. این باعث شد علاقه\u200cای بزرگی در تحلیل دانش\u200cهای سنتاکتیک PLMs یاد گیرند. نزدیک قبلی به این سوال محدودیت شده است، بیشتر از استفاده از سویتهای آزمایش یا امتحان\u200cها. در اینجا، ما یک روانی را پیشنهاد می\u200cکنیم که به طور کامل از طریق تجزیه کردن غیرقابل تحریک شده است که درختان محیط را از سر توجه PLM خارج می\u200cکند. ما سرهای تغییر توجه\u200cکننده\u200cای را بر پایه اموال\u200cهایشان قرار می\u200cدهیم، و برای تولید درخت پایان یک سری بالا می\u200cآوریم. روش ما به زبانهای کم منابع adaptable است، زیرا بر مجموعه\u200cهای توسعه اعتماد ندارد که می\u200cتواند برای اخطار گران باشد. آزمایش\u200cهای ما نشان می\u200cدهند که روش پیشنهاد اغلب بیشتر از نزدیک\u200cهای موجود را انجام می\u200cدهد اگر هیچ تنظیم توسعه\u200cای وجود ندارد. ویژه\u200cکننده\u200cی غیرقابل استفاده از ما می\u200cتواند همچنین به عنوان ابزار برای تحلیل گرم\u200cها PLMs به طور غیرقابل یاد بگیرند. برای این، ما از درخت\u200cهای پردازی که توسط روش\u200cهایمان تولید شده\u200cاند استفاده می\u200cکنیم تا یک PCFG عصبی را آموزش دهیم و آن را با یک گرامی که تولید شده\u200cاست از یک درخت\u200cهای درخت\u200cهایی که تولید شده\u200cاند به انسان مقایسه کنیم.', 'cs': 'Předškolené jazykové modely založené na transformátoru dramaticky zlepšily stav techniky NLP v mnoha úkolech. To vedlo k podstatnému zájmu o analýzu syntaktických znalostí, které PLM učí. Předchozí přístupy k této otázce byly omezeny, většinou pomocí testovacích sad nebo sond. Zde navrhujeme nový zcela bez dohledu přístup k analýze, který extrahuje stromy volebních obvodů z hlav pozornosti PLM. Řadíme hlavy pozornosti transformátorů na základě jejich vlastností a vytvoříme soubor vysoce postavených hlav, které vytvoří finální strom. Naše metoda je přizpůsobitelná jazykům s nízkými zdroji, protože se nespoléhá na vývojové sady, které může být drahé anotovat. Naše experimenty ukazují, že navrhovaná metoda často překoná stávající přístupy, pokud neexistuje žádná vývojová sada. Náš bez dozoru parser může být také použit jako nástroj pro analýzu gramatik PLM učení implicitně. K tomu používáme parse stromy indukované naší metodou k tréninku nervového PCFG a porovnáváme ho s gramatikou odvozenou z člověkem anotovaného stromu.', 'af': "Transformer-gebaseerde voor-opgelei taal modele (PLMs) het dramatiese die staat van die kuns in NLP verbeter oor baie taak. Hierdie het gelei na betekende belang in die analyseer van die sintaktieke kennis PLMs leer. Vorige toegang tot hierdie vraag is beperk, meeste gebruik toets suites of probes. Hier, ons voorstel 'n roman volledig ongeondersteunde verwerking toegang wat konstituency bome uit PLM aandagkoppe uittrek. Ons rank transformeerder aandag koppe gebaseer op hul inherende eienskappe en skep 'n ensemble van hoë-ranking koppe om die eindelike boom te produseer. Ons metode is aanpasbaar na lae hulpbron tale, omdat dit nie op ontwikkelingsstelle vertrou nie, wat koste kan wees om te annoteer nie. Ons eksperimente wys dat die voorgestelde metode dikwels voortvoer bestaande toegange as daar geen ontwikkelingsstel voorsien is nie. Ons onverondersteunde ontwerker kan ook gebruik word as 'n hulpmiddel om die gramme PLMs inplisite te analyseer. Vir hierdie gebruik ons die verwerking bome wat deur ons metode aangedoen is om 'n neurale PCFG te oefen en dit te vergelyk met 'n grammatiek wat van 'n mens-annotateerde treebank afgelei is.", 'et': 'Transformeritel põhinevad eelkoolitud keelemudelid (PLM) on oluliselt parandanud NLP tehnikat paljude ülesannete puhul. See on toonud kaasa märkimisväärse huvi süntaktiliste teadmiste analüüsimise vastu, mida PLM õpib. Varasemad lähenemisviisid sellele küsimusele on olnud piiratud, enamasti kasutades testikomplekte või sonde. Siinkohal pakume välja uudse täielikult järelevalveta parsimisviisi, mis eraldab valimisringkonna puud PLMi tähelepanu peadest. Me järjestame trafo tähelepanu pead vastavalt nende omadustele ja loome lõpliku puu tootmiseks kõrgetasemeliste peade ansambli. Meie meetod on kohandatav vähese ressursiga keeltele, kuna see ei toetu arenduskomplektidele, mille märkimine võib olla kallis. Meie eksperimendid näitavad, et kavandatud meetod ületab sageli olemasolevaid lähenemisviise, kui ei ole arenduskomplekti olemas. Meie järelevalveta parserit saab kasutada ka vahendina, et analüüsida grammatikat, mida PLMs kaudselt õpivad. Selleks kasutame meie meetodiga indutseeritud puude parsimiseks neuraalse PCFG-i treenimiseks ja võrdlemiseks grammatikaga, mis tuleneb inimese-annoteeritud puupangast.', 'fi': 'Muuntajapohjaiset esikoulutetut kielimallit (PLM) ovat parantaneet merkittävästi NLP:n nykytilaa monissa tehtävissä. Tämä on johtanut huomattavaan kiinnostukseen analysoida PLM:n oppimaa syntaktista tietoa. Aiemmat lähestymistavat tähän kysymykseen ovat olleet rajallisia, lähinnä käyttämällä testisarjoja tai luotaimia. Tässä ehdotamme uutta täysin valvomatonta analyysimenetelmää, joka poistaa vaalipiiripuut PLM:n huomiopäistä. Sijoitamme muuntajan huomiopäät niiden luontaisten ominaisuuksien perusteella ja luomme joukon korkealuokkaisia päitä lopullisen puun tuottamiseksi. Menetelmämme mukautuu vähäresurssisiin kieliin, koska se ei perustu kehityssarjoihin, joiden merkitseminen voi olla kallista. Kokeet osoittavat, että ehdotettu menetelmä usein ylittää olemassa olevat lähestymistavat, jos ei ole olemassa kehitysjoukkoa. Valvontatonta jäsentäjäämme voidaan käyttää myös työkaluna analysoida PLM:n implisiittisesti oppimia kieliopioita. Tätä varten käytämme menetelmämme indusoimia jäsennyspuita neuraalisen PCFG:n kouluttamiseen ja vertaamme sitä ihmisen merkitsemästä puusta johdettuun kielioppiin.', 'jv': 'templates-action Digawe nggo ngerasakno sistem sing paling nggo nyelarakno liyane PLM kuwi ngerasakno. yes Punika, kita hukung donge kuwi nggawe barang nggawe aturan urip nggawe perusahaan kowe nguasai winih kanggo kowe nggawe PLM kuwi mau. Awak dhéwé mengko perusahaan langgar-wong liyane dadi bisa perusahaan sing nguasai nggawe lan kedhah basa sing nguasai nggolok barang apik dhéwé. Ndéwé wis nguasai gedung winih dhéwé kuwi nggawe Awakdhéwé punika dipoleh kanggo langgambar akeh-nesaturan, dadi iki ora bisa nguasai nggawe ngubah akeh pengguna, sing bisa jejaraké awak dhéwé. Awak dhéwé éntuk sing ngerasakno ana, akeh sabanjuré nggawe gerakan kelas nang ora ono nggawe nguasai nggawe. Open Failed Digawe iki, kita uwis menehi kelompok nggawe layanan karo pernik, iso nggawe wajih dumaten karo nggawe barang kelompok nggawe barang kelompok uwis.', 'he': 'מודלים שפות מאומנים מראש (PLMs) השתפרו באופן דרמטי את מצב האמנות של NLP ברחבי משימות רבות. זה הוביל לאינטרס משמעותי בניתוח הידע הסינטקטי PLMs ללמוד. גישות קודמות לשאלה הזאת הוגבלו, בעיקר בשימוש בחליפות מבחן או חוקים. כאן, אנו מציעים ניתוח חיפוש בלתי משומר לחלוטין שמוציא עצי מחוז הבחירות מראשי תשומת לב PLM. אנו מעצבים ראשי תשומת לב משתנה מבוססים על תכונותיהם הנכונות, ויוצרים אסמבל ראשי מעמד גבוה כדי לייצר את העץ האחרון. השיטה שלנו מסוגלת להתאים לשפות משאבים נמוכות, כיוון שהיא לא תלויה על קבוצות פיתוח, שאפשר להיות יקר להציין. הניסויים שלנו מראים שהשיטה המוצעת לעתים קרובות מעלית גישות קיימות אם אין קבוצת פיתוח נוכחת. המחקר הלא מושגת שלנו גם יכול להשתמש ככלי לנתח את התרמטיקות PLMs ללמוד באופן לא ישיר. בשביל זה, אנו משתמשים בעצי המחקר שנגרמו על ידי השיטה שלנו כדי לאמן PCFG עצבי ולהשוות אותו לגרמטיקה שנוצרה מבנק עץ שמכתב אנושי.', 'ha': "@ info: status Wannan ta ƙara wa interesse mai girma a yi analyza kan sanar da ma'anar PLM na syntactic. @ action: button A nan, Munã goyyar da wani matsayi wanda ba'a tsare shi ba cikakken hanyoyi mai tsaro da ta samu ta fita itãcen wanda ke cikin tsari daga kicuɓan PLM. We rank transformer attention heads based on their inherent properties, and create an ensemble of high-ranking heads to produce the final tree.  Tsarakanmu na adadi zuwa harshen-wuri, kamar yadda bã ya dõgara a kan daidaita mafaɗari, wanda za ta kasance mai amfani ga zartar da shi. Kayan jarrabõyinmu na nũna cewa metoden da aka buƙata, ko da yawa za'a samar da wasu hanyõyin da ke da idan ba wani tsari ba ta zo ba. Ana iya amfani da Paramermarmu wanda ba'a tsare ba, kamar zance ya yi amfani da shi dõmin a sanar da grammar PLM masu buƙata. Daga wannan, Munã amfani da it ãcen parse wanda aka ƙara shi na hanyõyinmu dõmin mu yi wa yin wa'anar wani PCFG na neura kuma mu samfane shi da grammar wanda aka samu daga wani bakin mutum-da aka sanar ta.", 'sk': 'Predhodno usposobljeni jezikovni modeli (PLM), ki temeljijo na transformatorjih, so dramatično izboljšali stanje tehnike NLP pri številnih nalogah. To je privedlo do precejšnjega zanimanja za analizo sintaktičnega znanja, ki ga PLM učijo. Prejšnji pristopi k temu vprašanju so bili omejeni, večinoma z uporabo testnih kompletov ali sond. Tukaj predlagamo nov, popolnoma nenadzorovan pristop razčlenjanja, ki izvleče drevesa volilnih okrožij iz pozornih glav PLM. Glave pozornosti transformatorjev razvrščamo glede na njihove neločljive lastnosti in ustvarimo ansambel visokih glav za proizvodnjo končnega drevesa. Naša metoda je prilagodljiva jezikom z nizkimi viri, saj se ne zanaša na razvojne nabore, ki jih je lahko drago navesti. Naši poskusi kažejo, da predlagana metoda pogosto presega obstoječe pristope, če ni prisotnega nabora razvoja. Naš nenadzorovan razčlenjevalnik se lahko uporablja tudi kot orodje za analizo slovničničnih slovnic, ki se jih PLM implicitno učijo. Za to uporabljamo razčlenjevalna drevesa, ki jih povzroča naša metoda, za usposabljanje živčnega PCFG in ga primerjamo s slovnico, pridobljeno iz človeške oznake dreves.', 'bo': 'འགྱུར་བརྒྱུད་པ་ལ་སྔོན་གྲངས་སྒྲིག་གི་སྐད་རིགས་དཔེ་དབྱེ་བ(PLMs)ནི་NLP ནང་གི་སྒྱུ་རྩལ་གནས་སྟངས་དེ་གནད་དོན་ཏུ་ཡར་བསྐྱེད་ འདིས་དབྱིབས་བྱ་ཚིག་གི་དབྱེ་རིགས་ལ་ཆ་སྐྱེས་པའི་དགའ་ཚོགས་སྐྱེས་ཆེན་ཚོར་བསམ་བློ་གཏོང་བ འདྲི་ཚིག་འདིའི་སྔོན་གྱི་གཟུགས་སྐོར་ལ་ཚད་འཛིན་བྱས་ཡོད། རྩ་བ་ནས་བརྟག འདིར་ངེད་ཚོས་PLM་ཡི་གནད་དོན་ཁང་གི་སྒྲིག་ཐང་ཡོད་མེད་པའི་བཟོ་ཚོགས་གསར་བ་ཞིག་སྤྲོད་ཡོད། ང་ཚོས་རང་ཉིད་ཀྱི་ངོ་བོའི་རྒྱུ་དངོས་གཞི་ཡོད་པའི་ལྟ་བུའི་དབུགས་གཙོ་རིམ་བཟོ་བྱེད་ཀྱི་ཡོད་པ་ཞིག་གསར་བསྐྲུན་འབད་ཡོད། ང་ཚོའི་ལམ་ལུགས་འདིས་རྐྱེན་འབྱུང་བའི་སྐད་རིགས་ལ་ཉུང་བའི་བཟོ་བཅོས་བྱེད་པར་མཐུན་པས། ང་ཚོའི་བརྟག་ཞིག་གིས་དམིགས་འཛུགས་ཀྱི་ཐབས་ལམ་ནི་རྒྱུན་ལྡན་ནས་གནས་ཡུལ་གྱི་གནད་དོན་མི་འདུག ང་ཚོའི་རྩིས་མེད་བཟོ་བྱས་མེད་པའི་དབྱེ་སྟངས་དེ་ལས་བྱ་རིམ་གྱི་ལག་ཆ་ཞིབ་ནང་དུ་ལག་ལེན་འཐབ་ཐུབ། འོན་ཀྱང་། ང་ཚོས་ང་ཚོའི་ཐབས་ལམ་གྱིས་ལག་ལེན་པའི་དབྱེ་སྟངས་ཀྱི་རྩིས་པ་ཞིག་གིས་དཔྱད་བྱེད་རྒྱུ་དང་། འདི་ལྟ་བུའི་རྣམ་པས་མིན་ན་ཤེ'}
{'en': 'Self-Supervised Learning for Pairwise Data Refinement', 'ar': 'التعلم الخاضع للإشراف الذاتي لتنقيح البيانات المزدوجة', 'pt': 'Aprendizado autossupervisionado para refinamento de dados em pares', 'fr': 'Apprentissage auto-supervisé pour le raffinement des données deux à deux', 'es': 'Aprendizaje autosupervisado para el refinamiento de datos en pareja', 'ja': 'ペアワイズデータリファインのための自主的な学習', 'zh': '用于成对数优化者自督学', 'ru': 'Самостоятельное обучение для парного уточнения данных', 'hi': 'Pairwise डेटा शोधन के लिए स्व-पर्यवेक्षित सीखना', 'ga': 'Foghlaim Féinmhaoirsithe le haghaidh Scagadh Sonraí Pairwise', 'ka': 'თავიდან დანახვა მონაცემების გასწავლება', 'hu': 'Önfelügyeleti tanulás páros adatfrissítéshez', 'el': 'Αυτοεποπτευόμενη μάθηση για τον διυλισμό δεδομένων σε σχέση με ζευγάρια', 'lt': 'Savarankiškai prižiūrimas mokymasis paruošti poros duomenis', 'it': 'Apprendimento auto-supervisionato per la raffinazione dei dati a coppie', 'kk': 'Өзінің бақылау мәліметін өзінің бақылау оқытуы', 'mk': 'Самонадгледувано учење за финансирање на податоци за парови', 'ms': 'Pembelajaran Dipengawasi Sendiri untuk Penapisan Data Pasangan', 'ml': 'പൈര്\u200dവിസ് ഡേറ്റാ പുതുക്കുന്നതിനുള്ള സ്വയം സൂക്ഷ്മമായ പഠനം', 'mt': 'Tagħlim Awto-Sorveljat għar-Rifinar tad-Dejta dwar iż-Żewġ', 'mn': 'Өөрийгөө удирдах суралцах', 'no': 'Sjølvovervåka læring for å refinera data', 'pl': 'Nauka samodzielnie nadzorowana dla udoskonalenia danych parowych', 'ro': 'Învățare auto-supravegheată pentru rafinarea datelor pereche', 'sr': 'Самонадзорено учење за поправку дана пара', 'so': 'Waxbarashada iskuulka ah ee qasabka macluumaadka Pairwise', 'si': 'සම්බන්ධ දත්ත ප්\u200dරවර්තනය සඳහා ස්වයංක්\u200dරීය විදියට ඉගෙනගන්න', 'sv': 'Självövervakat lärande för parvis dataraffinering', 'ta': 'Name', 'ur': 'پارچز ڈاٹ پابندی کے لئے خود-Supervised Learning for Pairwise Data Refinement', 'uz': 'Name', 'vi': 'Tự giám sát học phí', 'bg': 'Самоуправляемо обучение за усъвършенстване на данните по двойки', 'hr': 'Sam-nadzirano učenje za osnovu podataka o parnici', 'nl': 'Zelfbegeleid leren voor pairwise data verfijning', 'da': 'Selvtilsynet læring til parvis dataforbedring', 'de': 'Self-Supervised Learning für Pairwise Data Refinement', 'id': 'Self-Supervised Learning for Pairwise Data Refinement', 'ko': '두 개의 데이터 세분화에 사용되는 자체 감독 학습', 'fa': 'یادگیری که خود مراقبت شده برای بازسازی داده\u200cهای جفت', 'tr': 'Paýlaş Maglumaty Gaýtalamak üçin Öz Gözlemli Öwrenmek', 'sw': 'Kujifunza kujitegemea kwa ajili ya Uchambuzi wa Taarifa za Pairwise', 'af': 'Selfbeheerde leer vir Paruis Data Verwydering', 'sq': 'Mësimi i mbikqyrur vetë për përmirësimin e të dhënave të palëve', 'hy': 'Ինքնավերահսկված սովորելը զույգչային տվյալների վերլուծության համար', 'am': 'ምርጫዎች', 'az': '칐z칲n칲n 칐z칲n칲n 칐z칲n칲n 칐z칲n칲n 칐z칲n칲n 칐z칲n칲 칐z칲n칲n 칐z칲n칲n 칐z칲n칲n Veri S톛fl톛m톛si', 'bn': 'পাইরওয়াইজ ডাটা সংস্কারের জন্য স্বয়ংক্রিয়ভাবে শিক্ষা শিক্ষা', 'ca': "L'aprenentatge autosupervisada per a perfeccionar les dades de parell", 'bs': 'Sam-nadzorno učenje za oslobađanje podataka o parnici', 'cs': 'Samozřejmé učení pro párové vylepšování dat', 'et': 'Isejärelevalvega õppimine paari andmete täpsustamiseks', 'fi': 'Itseohjattu oppiminen paritietojen tarkentamiseen', 'ha': 'KCharselect unicode block name', 'he': 'ללמוד משגיח על עצמו עבור מידע של זוגות', 'sk': 'Samodejno učenje za paresko izboljšanje podatkov', 'bo': 'Self-Supervised Learning for Pairwise Data Refinement', 'jv': 'Learn Mode'}
{'en': 'Pairwise data automatically constructed from weakly supervised signals has been widely used for training  deep learning models . Pairwise datasets such as parallel texts can have uneven quality levels overall, but usually contain data subsets that are more useful as learning examples. We present two methods to refine data that are aimed to obtain that kind of subsets in a self-supervised way. Our methods are based on iteratively training dual-encoder models to compute  similarity scores . We evaluate our methods on de-noising  parallel texts  and training neural machine translation models. We find that : (i) The self-supervised refinement achieves most machine translation gains in the first iteration, but following iterations further improve its intrinsic evaluation. (ii)  Machine translations  can improve the de-noising performance when combined with selection steps. (iii) Our  methods  are able to reach the performance of a supervised method. Being entirely self-supervised, our  methods  are well-suited to handle pairwise data without the need of prior knowledge or human annotations.', 'ar': 'تم استخدام البيانات الزوجية التي تم إنشاؤها تلقائيًا من إشارات ضعيفة الإشراف على نطاق واسع لتدريب نماذج التعلم العميق. يمكن أن تحتوي مجموعات البيانات الزوجية مثل النصوص المتوازية على مستويات جودة غير متساوية بشكل عام ، ولكنها تحتوي عادةً على مجموعات فرعية من البيانات تكون أكثر فائدة كأمثلة تعليمية. نقدم طريقتين لتحسين البيانات التي تهدف إلى الحصول على هذا النوع من المجموعات الفرعية بطريقة تخضع للإشراف الذاتي. تعتمد أساليبنا على التدريب المتكرر لنماذج التشفير المزدوج لحساب درجات التشابه. نقوم بتقييم أساليبنا في إزالة الضوضاء عن النصوص المتوازية وتدريب نماذج الترجمة الآلية العصبية. نجد أن: (1) الصقل الذي يتم الإشراف عليه ذاتيًا يحقق معظم مكاسب الترجمة الآلية في التكرار الأول ، ولكن اتباع التكرارات يزيد من تحسين التقييم الجوهري. (2) يمكن للترجمات الآلية تحسين أداء إزالة الضوضاء عند دمجها مع خطوات الاختيار. (3) أساليبنا قادرة على الوصول إلى أداء طريقة خاضعة للإشراف. نظرًا لكوننا خاضعة للإشراف الذاتي تمامًا ، فإن أساليبنا مناسبة تمامًا للتعامل مع البيانات المزدوجة دون الحاجة إلى معرفة مسبقة أو تعليقات بشرية.', 'pt': 'Dados em pares construídos automaticamente a partir de sinais fracamente supervisionados têm sido amplamente utilizados para treinar modelos de aprendizado profundo. Conjuntos de dados em pares, como textos paralelos, podem ter níveis de qualidade desiguais em geral, mas geralmente contêm subconjuntos de dados que são mais úteis como exemplos de aprendizado. Apresentamos dois métodos para refinar dados que visam obter esse tipo de subconjuntos de forma autossupervisionada. Nossos métodos são baseados no treinamento iterativo de modelos de codificador duplo para calcular pontuações de similaridade. Avaliamos nossos métodos para eliminar ruídos de textos paralelos e treinar modelos de tradução automática neural. Descobrimos que: (i) O refinamento autossupervisionado alcança a maioria dos ganhos de tradução automática na primeira iteração, mas as iterações seguintes melhoram ainda mais sua avaliação intrínseca. (ii) As traduções automáticas podem melhorar o desempenho de redução de ruído quando combinadas com etapas de seleção. (iii) Nossos métodos são capazes de atingir o desempenho de um método supervisionado. Sendo totalmente autossupervisionados, nossos métodos são adequados para lidar com dados em pares sem a necessidade de conhecimento prévio ou anotações humanas.', 'fr': "Les données deux à deux générées automatiquement à partir de signaux faiblement supervisés ont été largement utilisées pour l'entraînement de modèles de deep learning. Les ensembles de données deux à deux tels que les textes parallèles peuvent présenter des niveaux de qualité inégaux dans l'ensemble, mais contiennent généralement des sous-ensembles de données qui sont plus utiles comme exemples d'apprentissage. Nous présentons deux méthodes pour affiner les données qui visent à obtenir ce type de sous-ensembles de manière auto-supervisée. Nos méthodes sont basées sur l'entraînement itératif de modèles à double encodeur pour calculer des scores de similarité. Nous évaluons nos méthodes de débruitage de textes parallèles et de formation de modèles de traduction automatique neuronale. Nous constatons que\xa0: (i) le raffinement auto-supervisé permet d'obtenir la plupart des gains de traduction automatique lors de la première itération, mais les itérations suivantes améliorent encore son évaluation intrinsèque. (ii) Les traductions automatiques peuvent améliorer les performances de débruitage lorsqu'elles sont combinées avec des étapes de sélection. (iii) Nos méthodes sont capables d'atteindre les performances d'une méthode supervisée. Entièrement auto-supervisées, nos méthodes sont parfaitement adaptées pour traiter des données par paires sans avoir besoin de connaissances préalables ou d'annotations humaines.", 'es': 'Los datos en pares construidos automáticamente a partir de señales débilmente supervisadas se han utilizado ampliamente para entrenar modelos de aprendizaje profundo. Los conjuntos de datos por pares, como los textos paralelos, pueden tener niveles de calidad desiguales en general, pero por lo general contienen subconjuntos de datos que son más útiles como ejemplos de aprendizaje. Presentamos dos métodos para refinar los datos que tienen como objetivo obtener ese tipo de subconjuntos de forma autosupervisada. Nuestros métodos se basan en el entrenamiento iterativo de modelos de doble codificador para calcular las puntuaciones de similitud. Evaluamos nuestros métodos para eliminar el ruido de textos paralelos y entrenar modelos de traducción automática neuronal. Encontramos que: (i) El refinamiento autosupervisado logra la mayoría de los beneficios de la traducción automática en la primera iteración, pero las iteraciones posteriores mejoran aún más su evaluación intrínseca. (ii) Las traducciones automáticas pueden mejorar el rendimiento de eliminación de ruido cuando se combinan con los pasos de selección. (iii) Nuestros métodos son capaces de alcanzar el rendimiento de un método supervisado. Al estar totalmente autosupervisados, nuestros métodos son adecuados para manejar datos por pares sin necesidad de conocimientos previos o anotaciones humanas.', 'ja': '弱く監視された信号から自動的に構築されたペアワイズデータは、ディープラーニングモデルのトレーニングに広く使用されています。 並列テキストなどのペアワイズデータセットは、全体的に不均一な品質レベルを有する可能性がありますが、通常、学習例としてより有用なデータサブセットを含みます。 そのようなサブセットを自主監視的に取得することを目的としたデータを絞り込むための2つの方法を提示します。 私たちの方法は、類似性スコアを計算するためのデュアルエンコーダモデルを反復的にトレーニングすることに基づいています。 私たちは、平行テキストのノイズ除去とニューラル機械翻訳モデルのトレーニングの方法を評価します。 私たちは、次のことを発見しました。（ i ）自主監督による微細化は、最初の反復でほとんどの機械翻訳の利得を達成しますが、反復を繰り返すことで、その本質的な評価がさらに向上します。（ ii ）機械翻訳は、選択ステップと組み合わせると、ノイズ除去のパフォーマンスを向上させることができます。（ iii ）私たちの方法は、監督された方法のパフォーマンスに到達することができます。 完全に自主的に監督されているため、当社の方法は、事前の知識や人間による注釈を必要とせずに、ペアワイズデータを扱うのに適しています。', 'zh': '从弱督信自构成对数已博练深习。 成对数据集(如并行文本)全体质量水平或参差不齐,但常包以为学示例更有用数子集。 二术优化数,以自督取集。 吾法基于迭代练双编码器以算相似性分。 评估去噪并行文本及训练神经机器翻译模之法。 曰:(i)自督者细化于初迭代多机器翻译益,既而迭代益善其内。 (ii) 机器翻译与步骤合,可以益噪性。 (iii)吾道之能致督也。 以全自督,吾法非常适合为对数,而无先验知识人工注释。', 'hi': 'कमजोर पर्यवेक्षित संकेतों से स्वचालित रूप से निर्मित पेयरवाइज डेटा का व्यापक रूप से गहरे सीखने के मॉडल के प्रशिक्षण के लिए उपयोग किया जाता है। समानांतर ग्रंथों जैसे पेयरवाइज डेटासेट में समग्र रूप से असमान गुणवत्ता स्तर हो सकते हैं, लेकिन आमतौर पर डेटा सबसेट होते हैं जो सीखने के उदाहरणों के रूप में अधिक उपयोगी होते हैं। हम डेटा को परिष्कृत करने के लिए दो तरीके प्रस्तुत करते हैं जिनका उद्देश्य उस तरह के सबसेट को स्व-पर्यवेक्षित तरीके से प्राप्त करना है। हमारे तरीके समानता स्कोर की गणना करने के लिए पुनरावर्ती प्रशिक्षण दोहरे-एनकोडर मॉडल पर आधारित हैं। हम समानांतर ग्रंथों और प्रशिक्षण तंत्रिका मशीन अनुवाद मॉडल पर de-noising पर हमारे तरीकों का मूल्यांकन करते हैं। हम पाते हैं कि: (i) स्व-पर्यवेक्षित शोधन पहले पुनरावृत्ति में अधिकांश मशीन अनुवाद लाभ प्राप्त करता है, लेकिन पुनरावृत्तियों के बाद इसके आंतरिक मूल्यांकन में और सुधार होता है। (ii) चयन चरणों के साथ संयुक्त होने पर मशीन अनुवाद डी-नॉइज़िंग निष्पादन में सुधार कर सकते हैं। (iii) हमारे तरीके एक पर्यवेक्षित विधि के निष्पादन तक पहुंचने में सक्षम हैं। पूरी तरह से आत्म-पर्यवेक्षित होने के नाते, हमारे तरीके पूर्व ज्ञान या मानव एनोटेशन की आवश्यकता के बिना युग्मवार डेटा को संभालने के लिए अच्छी तरह से अनुकूल हैं।', 'ru': 'Параметрические данные, автоматически созданные на основе слабо контролируемых сигналов, широко используются для обучения моделям глубокого обучения. Парные наборы данных, такие как параллельные тексты, могут иметь неравномерные уровни качества в целом, но обычно содержат подмножества данных, которые более полезны в качестве примеров обучения. Мы предлагаем два метода уточнения данных, которые направлены на получение такого рода подмножеств самостоятельно. Наши методы основаны на итеративном обучении моделей двойного кодирования для вычисления показателей сходства. Мы оцениваем наши методы по устранению шумов параллельных текстов и обучаем модели нейронного машинного перевода. Мы находим, что: (i) самоконтролируемое уточнение достигает большинства преимуществ машинного перевода в первой итерации, но следующие итерации еще больше улучшают его внутреннюю оценку. (ii) Машинный перевод может улучшить производительность удаления шума в сочетании с этапами отбора. (iii) Наши методы способны достичь производительности контролируемого метода. Будучи полностью самоконтролируемыми, наши методы хорошо подходят для обработки попарных данных без необходимости предварительного знания или человеческих аннотаций.', 'ga': 'Baineadh úsáid go forleathan as sonraí Pairwise a tógadh go huathoibríoch ó chomharthaí lag-mhaoirsithe chun samhlacha domhainfhoghlama a oiliúint. D’fhéadfadh leibhéil cháilíochta éagothroma a bheith ag tacair sonraí Pairwise ar nós téacsanna comhthreomhara ar an iomlán, ach de ghnáth bíonn fo-thacair sonraí iontu atá níos úsáidí mar shamplaí foghlama. Cuirimid dhá mhodh i láthair chun sonraí a bheachtú atá dírithe ar an gcineál sin fo-thacair a fháil ar bhealach féin-mhaoirsithe. Tá ár modhanna bunaithe ar mhúnlaí dé-ionchódóra a thraenáil go atriallach chun scóir chosúlachta a ríomh. Déanaimid measúnú ar ár gcuid modhanna chun téacsanna comhthreomhara a dhí- fhuaimniú agus chun samhlacha néar-aistriúcháin meaisín a thraenáil. Faighimid amach: (i) Is é an mionchoigeartú féin-mhaoirsithe a ghnóthaíonn an chuid is mó de ghnóthachain aistriúcháin mheaisín sa chéad atriall, ach tar éis atriallta feabhsaítear a luacháil intreach tuilleadh. (ii) Is féidir le haistriúcháin meaisín feabhas a chur ar an bhfeidhmíocht dí-torainn nuair a chomhcheanglaítear é leis na céimeanna roghnaithe. (iii) Tá ár modhanna in ann feidhmíocht modh maoirsithe a bhaint amach. Ós rud é go bhfuilimid féin-mhaoirsithe go hiomlán, tá ár modhanna feiliúnach chun sonraí péirewise a láimhseáil gan gá le réamheolas ná le nótaí daonna.', 'hu': 'A gyengén felügyelt jelekből automatikusan készült páros adatokat széles körben használják a mélytanulási modellek képzésére. A párhuzamos adatkészletek, például a párhuzamos szövegek összességében eltérő minőségi szintekkel rendelkeznek, de általában olyan adatkészleteket tartalmaznak, amelyek hasznosabbak tanulási példaként. Két olyan módszert mutatunk be az adatok finomítására, amelyek célja az ilyen részhalmazok önfelügyeleti módon történő beszerzése. Módszereink a hasonlósági pontszámok kiszámítására hasonlósági pontszámok iteratív képzésén alapulnak. Módszereinket a párhuzamos szövegek zajtalanítására és neurális gépi fordítási modellek képzésére értékeljük. Megállapítjuk, hogy: (i) Az önfelügyelt finomítás az első iterációban a legtöbb gépi fordítási nyereséget éri el, de az iterációkat követően tovább javítja a belső értékelését. (ii) A gépi fordítások a kiválasztási lépésekkel kombinálva javíthatják a zajtalanítás teljesítményét. (iii) Módszereink képesek elérni a felügyelt módszer teljesítését. Teljes mértékben önfelügyeletű módszereink alkalmasak arra, hogy páros adatokat kezeljenek előzetes ismeretek vagy emberi megjegyzések nélkül.', 'el': 'Τα δεδομένα ζεύγους που κατασκευάζονται αυτόματα από αδύναμα εποπτευόμενα σήματα έχουν χρησιμοποιηθεί ευρέως για την κατάρτιση μοντέλων βαθιάς μάθησης. Τα ζεύγη σύνολα δεδομένων, όπως τα παράλληλα κείμενα, μπορούν να έχουν άνισα επίπεδα ποιότητας συνολικά, αλλά συνήθως περιέχουν υποσύνολα δεδομένων που είναι πιο χρήσιμα ως παραδείγματα μάθησης. Παρουσιάζουμε δύο μεθόδους για τη βελτίωση των δεδομένων που στοχεύουν στην απόκτηση αυτού του είδους υποσύνολων με τρόπο αυτοεπίβλεψης. Οι μέθοδοι μας βασίζονται σε επαναλαμβανόμενα μοντέλα διπλών κωδικοποιητών για τον υπολογισμό των αποτελεσμάτων ομοιότητας. Αξιολογούμε τις μεθόδους μας για την απομάκρυνση του θορύβου παράλληλων κειμένων και την εκπαίδευση μοντέλων νευρωνικής μηχανικής μετάφρασης. Διαπιστώνουμε ότι: (η αυτοεποπτευόμενη βελτίωση επιτυγχάνει τα περισσότερα κέρδη μηχανικής μετάφρασης κατά την πρώτη επανάληψη, αλλά οι επόμενες επαναλήψεις βελτιώνουν περαιτέρω την εγγενή αξιολόγησή της. (Οι μηχανικές μεταφράσεις μπορούν να βελτιώσουν την απόδοση απομάκρυνσης θορύβου όταν συνδυάζονται με βήματα επιλογής. (Οι μέθοδοι μας είναι σε θέση να επιτύχουν την απόδοση μιας εποπτευόμενης μεθόδου. Έχοντας πλήρη αυτοεπίβλεψη, οι μέθοδοι μας είναι κατάλληλες για να χειριστούν δεδομένα ζεύγους χωρίς την ανάγκη προηγούμενων γνώσεων ή ανθρώπινων σχολίων.', 'ka': 'მარტივი მონაცემები ავტომატურად შექმნილი სიგნალებიდან, რომლებიც ძალიან დანარწმუნებული სიგნალებიდან აკეთებულია, ძალიან გამოყენებული იყო ძალ პარალელი ტექსტის მაგალითად განსაზღვრებული მონაცემები შესაძლებელია ყველაფერი განსაზღვრებული კაalitეტის დონეები, მაგრამ განსაზღვრებულია მონაცემების სესესეს ჩვენ ჩვენ აჩვენებთ ორი მეტი მონაცემების გარეფიქტირება, რომელიც უნდა მიიღება ამ სახელ სესესეტის გარეფიქტირება სესესეტის გარეფიქტირება სა ჩვენი მეტოვები იქნება იტერატიურად განაკეთებული ეუკოდერის მოდელების განაკეთებაზე, რომლებიც სხვადასხვა მოდელების გამოყენება. ჩვენ ვამუშაობთ ჩვენი მეტოვები პარალელი ტექსტის განმავლობაში და განაკეთებაში ნეიროლური მაქინის განმავლობაში. ჩვენ აღმოჩნეთ, რომ: i) თავიდან დავარწმუნეთ რეფინეცია უფრო მეტი მანქანის გაგრძელება პირველი იტერეციაში, მაგრამ შემდეგ იტერეციების შემდეგ უფრო მეტი მისი ინტერენ ii) მაქსინური გაგრძელება შეიძლება უფრო უფრო მეტად გაგრძელება, როდესაც შეიძლება მონიშნულების კონფიგურაცია. iii) ჩვენი მეტირები შეუძლებელია გადავადგინოთ მონაცემებული მეტის გამოყენება. აკჲ ჟმვ ნაოყლნჲ ჟვბვჱნარვლნთ, ნაქთრვ მვრჲეთ ჟა ეჲბპვ ჟოჲჟჲბვნთ ჱა ეა ოპაგთმ ეანარა ბვჱ ნსზეა ჲრ ოპვეგთ ჱნანთწ თ ფჲგვფვჟკთ ანჲრაუთთ.', 'it': "I dati a coppie costruiti automaticamente da segnali debolmente supervisionati sono stati ampiamente utilizzati per la formazione di modelli di deep learning. I set di dati a coppie come i testi paralleli possono avere livelli di qualità non uniformi nel complesso, ma di solito contengono sottoinsiemi di dati più utili come esempi di apprendimento. Presentiamo due metodi per affinare i dati che mirano a ottenere quel tipo di sottoinsiemi in modo auto-supervisionato. I nostri metodi si basano sulla formazione iterativa di modelli dual-encoder per calcolare i punteggi di somiglianza. Valutiamo i nostri metodi sulla rimozione del rumore di testi paralleli e sulla formazione di modelli di traduzione automatica neurale. Troviamo che: (i) il perfezionamento auto-supervisionato raggiunge la maggior parte dei guadagni di traduzione automatica nella prima iterazione, ma dopo iterazioni migliora ulteriormente la sua valutazione intrinseca. (ii) Le traduzioni automatiche possono migliorare le prestazioni di disintossicazione se combinate con le fasi di selezione. (iii) I nostri metodi sono in grado di raggiungere l'esecuzione di un metodo supervisionato. Essendo completamente auto-supervisionati, i nostri metodi sono adatti a gestire dati a coppie senza la necessità di conoscenze preliminari o annotazioni umane.", 'lt': 'Pairwise data automatically constructed from weakly supervised signals has been widely used for training deep learning models.  Porų duomenų rinkiniai, pavyzdžiui, lygiagretūs tekstai, gali turėti nevienodą kokybę, bet paprastai apima duomenų pogrupius, kurie yra naudingi kaip mokymosi pavyzdžiai. Pateikiame du būdus duomenų, skirtų tokio pobūdžio pogrupiams gauti savarankiškai prižiūrint, tobulinimui. Mūsų metodai grindžiami pakartotiniu mokymu dvigubo kodavimo modeliais panašumui apskaičiuoti. Vertiname savo lygiagrečių tekstų triukšmo mažinimo metodus ir mokome nervinių mašinų vertimo modelius. Mes manome, kad: i) savarankiškai priži ūrimas rafinavimas pirmojo kartojimo metu pasiekia didžiausią vertimo mašinomis naudą, bet po kartojimo toliau gerina jo vidinį vertinimą. ii) Mašinų vertimai gali pagerinti triukšmo mažinimo charakteristikas kartu su atrankos etapais. iii) Mūsų metodai gali pasiekti prižiūrimo metodo veiksmingumą. Būdami visiškai savarankiškai prižiūrimi, mūsų metodai gerai tinka tvarkyti poros duomenis be išankstinių žinių ar žmogaus pastabų.', 'kk': 'Тіпті оқыту үлгілерінде автоматты түрде бақылау сигналдардан құрылған парақты деректерді автоматты түрде қолданылады. Параллельді мәтіндер секілді жалпы сапалық деңгейлері болуы мүмкін, бірақ кәдімгі оқыту үшін қолдайтын деректердің субөлігі болады. Біз деректерді түзету үшін екі әдістерді таңдаймыз. Бұл әдістерді өзімізге қарау үшін көмектесетін баптау үшін. Біздің әдістеріміз ұқсас нәтижелерін есептеу үшін екі кодер үлгілеріне негізделген. Біз өзіміздің әдістерімізді параллелді мәтіндерді дешуге және невралдық машинаны аудару үлгілерінде оқыту үшін бағалаймыз. Біз бірінші реттеу үшін: i) өзімізді бақылайтын рефининг машинаның көпшілігін бірінші реттеу үшін орындалады, бірақ қайталанулардың келесі қайталануларының ішкі дәрежесін жақсарт ii) Компьютердің аудармалары таңдау қадамдарымен біріктіргенде дыбыс- дыбыс істеуін жақсартуға болады. iii) Біздің әдістеріміз бақылау әдісінің әрекетін жеткізе алады. Өзімізді бақылау үшін, әдістеріміз өткен білім не адамдардың жазбалары қажет болмаса, екі деректерді басқару үшін дұрыс керек.', 'mk': 'Податоците за парови кои се автоматски изградени од слабо надгледувани сигнали се широко употребени за обука на модели за длабоко учење. Собори на податоци за парови како паралелни тексти може да имаат нееднакви квалитетни нивоа вкупно, но обично содржат подгрупи на податоци кои се покорисни како примери за учење. Презентираме два методи за рафинирање на податоците кои имаат за цел да добијат такви подгрупи на самоупотребен начин. Нашите методи се базирани на итеративна обука на модели со двојен кодер за пресметка на оценки на сличност. Ги проценуваме нашите методи на дешумирање паралелни тексти и обука на модели за превод на невропските машини. Најдовме дека: (i) Самонадгледуваното рафинансирање постигнува повеќето машински промени во првата итерација, но по итерациите понатаму ја подобрува својата внатрешна оценка. (ii) Машинските преводи можат да ја подобрат извршноста на дешумирање кога се комбинираат со чекорите на избор. (iii) Нашите методи можат да го постигнат изведувањето на надгледуван метод. Бидејќи сме целосно себеси надгледувани, нашите методи се соодветни за да се справат со парови податоци без потреба од претходно знаење или човечки анотации.', 'mt': 'Id-dejta dwar il-pari mibnija awtomatikament minn sinjali b’superviżjoni dgħajfa ntużat b’mod wiesa’ għat-taħriġ ta’ mudelli ta’ tagħlim profond. Settijiet ta’ dejta dwar il-pari bħal testi paralleli jista’ jkollhom livelli ta’ kwalità mhux ugwali b’mod ġenerali, iżda normalment ikun fihom settijiet ta’ dejta li huma aktar utli bħala eżempji ta’ tagħlim. Aħna nippreżentaw żewġ metodi biex nirraffinaw id-dejta li għandha l-għan li tikseb dan it-tip ta’ sottosettijiet b’mod awtosorveljat. Our methods are based on iteratively training dual-encoder models to compute similarity scores.  Aħna jevalwaw il-metodi tagħna dwar it-tneħħija tal-istorbju tat-testi paralleli u t-taħriġ tal-mudelli tat-traduzzjoni tal-magni newrali. Issibu li: (i) Ir-raffinar awtosorveljat jikseb il-biċċa l-kbira tal-kisbiet fit-traduzzjoni bil-magna fl-ewwel iterazzjoni, i żda wara iterazzjonijiet itejjeb aktar l-evalwazzjoni intrinsika tiegħu. (ii) It-traduzzjonijiet tal-magni jistgħu jtejbu l-prestazzjoni tat-tneħħija tal-istorbju meta kkombinati mal-passi tal-għażla. (iii) Il-metodi tagħna jistgħu jilħqu l-prestazzjoni ta’ metodu sorveljat. Billi nkunu kompletament awtosorveljati, il-metodi tagħna huma adattati tajjeb għall-immaniġġjar tad-dejta bejn il-pari mingħajr il-ħtieġa ta’ għarfien minn qabel jew annotazzjonijiet umani.', 'ms': 'Data pasangan yang dibina secara automatik dari isyarat yang mengawasi lemah telah digunakan secara luas untuk melatih model belajar dalam. Pairwise datasets such as parallel texts can have uneven quality levels overall, but usually contain data subsets that are more useful as learning examples.  Kami memperkenalkan dua kaedah untuk menaikkan data yang bertujuan untuk mendapatkan jenis subkumpulan tersebut dengan cara yang diawasi oleh diri sendiri. Kaedah kita berdasarkan latihan secara iteratif model pengekod dua untuk menghitung skor persamaan. Kami menilai kaedah kami pada teks selari yang menggoyang dan melatih model terjemahan mesin saraf. Kami mendapati bahawa: (i) Penyesuaian yang mengawasi diri mencapai kebanyakan peningkatan terjemahan mesin dalam iterasi pertama, tetapi mengikut iterasi lebih meningkatkan penilaian dalamnya. (ii) Terjemahan mesin boleh meningkatkan prestasi nyahbunyi bila digabungkan dengan langkah pemilihan. (iii) Kaedah kami mampu mencapai prestasi kaedah yang diawasi. Menjadi benar-benar mengawasi diri, kaedah kita sesuai untuk mengendalikan data pasangan tanpa perlukan pengetahuan sebelumnya atau anotasi manusia.', 'ml': 'ദുര്\u200dബലമായ നിരീക്ഷിക്കപ്പെട്ട സിഗ്നലുകളില്\u200d നിന്നും സ്വയം നിര്\u200dമ്മിക്കപ്പെട്ട പൈര്\u200dവിസ് ഡേറ്റാ ആഴത്തെ പ പാര്\u200dലെല്\u200d ടെക്സ്റ്റുകള്\u200d പോലുള്ള പെയിര്\u200dവിസ് ഡാറ്റാസറ്റുകള്\u200dക്ക് മൊത്തം കാര്യമില്ലാത്ത മാന്യമായ നിലങ്ങള്\u200d കിട്ടാം അത്തരം വിഭവങ്ങള്\u200d സ്വയം നിരീക്ഷിക്കുന്നതിനുള്ള രീതിയില്\u200d നമ്മള്\u200d രണ്ട് രീതികള്\u200d കൊണ്ടുവരുന്നു. Our methods are based on iteratively training dual-encoder models to compute similarity scores.  ഞങ്ങള്\u200d നമ്മുടെ രീതികള്\u200d വിലാസപ്പെടുത്തുന്നത് പാരാളല്\u200d ടെക്സ്റ്റുകളിലും ന്യൂറല്\u200d മെഷീന്\u200d പരിശീലന മോഡലുകള നമ്മള്\u200d കണ്ടെത്തുന്നത്: (i) സ്വയം നിരീക്ഷിക്കപ്പെട്ട മെഷിന്\u200d പരിശോധനത്തില്\u200d ഏറ്റവും മികച്ച വിഭാഗങ്ങള്\u200d ആദ്യത്തെ വിവരങ്ങളില്\u200d നിന് (ii) തെരഞ്ഞെടുക്കുന്ന പടികള്\u200d കൂട്ടിച്ചേര്\u200dക്കുമ്പോള്\u200d മെഷീന്\u200d പരിഭാഷകള്\u200d മെച്ചപ്പെടുത്തുവാന്\u200d സാധ (i) നിരീക്ഷിക്കപ്പെട്ട ഒരു രീതിയുടെ പ്രകടനത്തിലേക്ക് എത്താന്\u200d നമ്മുടെ രീതികള്\u200dക്ക് കഴിയും. പൂര്\u200dണ്ണമായും സ്വയം നിരീക്ഷിക്കപ്പെടുന്നതായിരുന്നു നമ്മുടെ രീതികള്\u200d ജോലിയുള്ള വിവരങ്ങള്\u200d കൈകാര്യം ചെയ്യാന്\u200d നല്ലത', 'mn': 'Хоёр хоёр мэдээллийг автоматаар байгуулсан суралцах загваруудыг суралцахын тулд автоматаар хэрэглэгдсэн. Парлелел текст шиг хоёр дахь өгөгдлийн сангууд ихэвчлэн төвөгтэй байж болно. Гэхдээ ихэвчлэн суралцах жишээ шиг илүү ашигтай өгөгдлийн сангууд байдаг. Бид өөрийгөө удирдлагатай байдлаар өгөгдлийг цэвэрлэх зорилготой хоёр арга зам өгдөг. Бидний арга нь ижил тооны тоонуудыг тооцохын тулд дахин дахин суралцах хоёр коддогч загвар дээр суурилсан. Бид өөрсдийнхөө арга замыг дуу-чимээгүй параллел текст болон мэдрэлийн машины хөгжлийн загварын талаар үнэлдэг. Бид үүнийг олж мэднэ: i) өөрийгөө удирдаж байгаа сэтгэл хангамж нь анхны давтамжтайгаар машины орчуулалтын ихэнх хувьд гарч ирнэ. Гэхдээ давтамжтайгаар давтах нь өөрийн дотоод дүгнэлтийг ил (ii) Машин хөгжлийн хөгжлийн хөгжлийн хөгжлийг сонголтын алхам хоорондоо холбогдож чадна. iii) Бидний арга зам нь удирдлагатай арга замыг хүргэж чадна. Өөрийгөө бүрэн удирдаж байхдаа бидний арга нь өмнө мэдлэг, хүн төрөлхтний сэтгэл хандлага хэрэггүй хоёр мэдээллийг удирдах хэрэгтэй.', 'no': 'Pairwise-data automatisk konstruert frå viktige oversikte signalar har blitt brukt for å trenja dype læringsmodeller. Paresett datasett som parallelle tekstar kan ha ulike kvalitetsnivå overalt, men vanlegvis inneheld dataundersett som er meir nyttige som læringseksemplar. Vi presenterer to metodar for å refinera data som er målet å få slike undergrupper på ein sjølvovervakt måte. Metodane våre er basert på gjentaktivt opplæring av dual-koderingsmodeller for å rekna ut liknande poeng. Vi evaluerer metodane våre på parallelle tekstar og uttrykk av neuralmaskinovertalingsmodeller. Vi finn at: i) Den sjølvoversikte refineringa oppnår dei fleste maskineoversettelsene i den første gjentakinga, men følgjande gjentakingar forbedrar det innenfor evalueringa. ii) maskineoversettelsar kan forbetra de-støyringsfunksjonen når det kombinerer med utvalsteg. iii) Metodane våre er i stand til å nå utføringa av ein oversikt metode. Ved å være fullstendig sjølvovervåka, er metodane våre godt passa for å handtera parvis data utan treng for førre kunnskap eller menneske annotasjonar.', 'pl': 'Dane parowe automatycznie zbudowane z słabo nadzorowanych sygnałów są szeroko stosowane do szkolenia modeli głębokiego uczenia. Parowe zbiory danych, takie jak teksty równoległe, mogą mieć ogólnie nierówny poziom jakości, ale zwykle zawierają podzbiory danych, które są bardziej przydatne jako przykłady nauki. Przedstawiamy dwie metody udoskonalania danych, które mają na celu uzyskanie tego rodzaju podzbiorów w sposób samodzielny. Nasze metody opierają się na iteracyjnym szkoleniu modeli dwóch koderów do obliczania wyników podobieństwa. Oceniamy nasze metody w zakresie usuwania równoległych tekstów oraz szkolenia neuronowych modeli tłumaczenia maszynowego. Ustalamy, że: (i) Udoskonalenie samodzielnie nadzorowane osiąga większość zysków tłumaczenia maszynowego w pierwszej iteracji, ale kolejne iteracje dodatkowo poprawiają jego wewnętrzną ocenę. (ii) Tłumaczenia maszynowe mogą poprawić wydajność usuwania szumów w połączeniu z etapami selekcji. (iii) Nasze metody są w stanie osiągnąć wydajność metody nadzorowanej. Będąc całkowicie samodzielnie nadzorowane, nasze metody doskonale nadają się do obsługi danych parowych bez potrzeby wcześniejszej wiedzy lub adnotacji ludzkich.', 'ro': 'Datele pereche construite automat din semnale slab supravegheate au fost utilizate pe scară largă pentru formarea modelelor de învățare profundă. Seturile de date pereche, cum ar fi textele paralele, pot avea niveluri de calitate inegale în general, dar de obicei conțin subseturi de date care sunt mai utile ca exemple de învățare. Prezentăm două metode de rafinare a datelor care vizează obținerea acestui tip de subseturi într-un mod auto-supravegheat. Metodele noastre se bazează pe instruirea iterativă a modelelor dual-encoder pentru a calcula scorurile de similitudine. Evaluăm metodele noastre privind dezzgomotul textelor paralele și instruirea modelelor neuronale de traducere automată. Descoperim că: (i) rafinamentul auto-supravegheat obține majoritatea câștigurilor de traducere automată în prima iterație, dar următoarele iterații îmbunătățesc și mai mult evaluarea intrinsecă a acestuia. (ii) Traducerile automate pot îmbunătăți performanța de eliminare a zgomotului atunci când sunt combinate cu etapele de selecție. (iii) Metodele noastre sunt capabile să atingă performanța unei metode supravegheate. Fiind complet auto-supravegheate, metodele noastre sunt potrivite pentru a gestiona datele pereche fără a fi nevoie de cunoștințe prealabile sau adnotări umane.', 'sr': 'Podaci o paru koji su automatski izgrađeni iz slabe nadzorne signale su široko korišteni za obuku modela dubokog učenja. Podaci podataka za pare poput paralelnih tekstova mogu imati ukupno jednake nivoe kvaliteta, ali obično sadrže podatke podataka koji su korisniji kao primjeri učenja. Predstavljamo dve metode za refinansiranje podataka koje su ciljane da dobiju takve podskupine na samopouzdani način. Naše metode su temeljene na iterativnom treningu modela dvokodera kako bi računalo rezultate sličnosti. Procjenjujemo naše metode o paralelnim tekstima i obuci modele prevođenja neuralnih mašina. Pronašli smo da: i) samopouzdanje rafiniranja postiže većinu dobitnika prevoda mašine u prvoj iteraciji, ali nakon iteracija bolje poboljšava svoju unutrašnju procjenu. ii) mehanički prevod može poboljšati debukiranje kada se kombinira sa koracima izbora. iii) Naše metode su u stanju da postignu izvršnost nadzornog metoda. Budući potpuno samopouzdani, naši metodi su dobro odgovarajući za podatke o parovima bez potrebe za prethodnim znanjem ili ljudskim annotacijom.', 'si': 'දුර්වලින් බලන්න සංඥාවන් වලින් ස්වයංක්\u200dරමයෙන් ස්වයංක්\u200dරමයෙන් නිර්මාණය කරලා තියෙන්නේ ගොඩ සමාන්\u200dය පාළුවන් වගේ දත්ත සෙට්ටුව සමහර විශේෂ ස්තූතියෙන්න පුළුවන්, ඒත් සාමාන්\u200dය විශේෂ ස්තූතියෙන් අපි ප්\u200dරවේශනය දෙකක් තියෙන්නේ ඒ වගේ සම්බන්ධ ප්\u200dරවේශනයක් ස්වාම්බන්ධ විදියට පරීක්ෂණය කරන්න. අපේ විධානය ආයෙත් ප්\u200dරශ්නයක් නිර්මාණය කරන්නේ දුවල් කෝඩර් මොඩේල්ස් වලින් සමාන ප්\u200dරශ්නයක් ගණන්න අපි අපේ විධානය විශ්වාස කරන්නේ සාමාන්\u200dය පණිවිඩය සහ න්\u200dයූරාල් මැෂින් වාර්තාවක් විශ්වාස කරන්න අපිට හොයාගන්න පුළුවන් විදියට: (i) ස්වාමින් බලන්න පුළුවන් විදියට පළමුවෙනි මැෂින් වාර්ථාවේ ගොඩක් අවශ්\u200dය විදිය (i) මැෂින් පරිවර්තනය කරන්න පුළුවන් විශ්වාස කරන්න පුළුවන් තෝරාගන්න පැත්තක් සමග සංවි (Ii) අපේ විදියට පුළුවන් විදියට පරීක්ෂා විදියට පුළුවන්. සම්පූර්ණයෙන්ම ස්වයංග බලන්න, අපේ පද්ධතිය හොඳයි, මිනිස්සුන්ගේ දැනගන්න අවශ්\u200dයය නැතුව මුලින් දැනගන්න ඕන', 'so': 'Macluumaadka Pairwise ee si automatic ah looga dhisay calaamadaha itaaldaran la ilaaliyey waxaa loo isticmaalay si loo barto modellada waxbarashada mool dheer. Isticmaalayaasha macluumaadka ah, sida qoraalka isbardhiga ah waxay heli karaan heerarka qiimo la’aanta, laakiin sida caadiga ah waxaa ku jira kooxo macluumaadka oo ka faa’iido badan sida tusaale ahaan waxbarashada. Waxaynu keennaa laba qaab oo ay ku sawiraan macluumaad, kaas oo loogu talagalay in lagu helo kooxo caynkaas ah si loo ilaaliyo. Shaqooyinkayagu waxay ku saleysan yihiin waxbarashada qaababka labada kooban si ay u xisaabiyaan scoro isku mid ah. Waxaynu qiimeynaynaa qaababkayaga ku saabsan qoraalka lambarka ah iyo tababarinta turjumidda maskaxda neurada. We find that: (i) The self-supervised refinement achieves most machine translation gains in the first iteration, but following iterations further improve its intrinsic evaluation.  (ii) Turjumaadda mashiinka ayaa beddeli kara bandhigyada codsiga marka lagu isku daro tallaabooyinka doorashada. (iii) qaababkayaga waxay gaadhi karaan sameynta qaab ilaaliya. Marka aan si kamid ah u ilaalinayno, qaababkayagu waa suuraan yihiin in ay xambaaraan labada macluumaad xigmad leh, iyadoon u baahnayn aqoonta hore ama dhibaatooyinka dadka.', 'sv': 'Parvis data som automatiskt konstruerats från svagt övervakade signaler har använts i stor utsträckning för att träna djupinlärningsmodeller. Parvis datauppsättningar som parallella texter kan ha ojämna kvalitetsnivåer generellt, men innehåller vanligtvis datauppsättningar som är mer användbara som inlärningsexempel. Vi presenterar två metoder för att förfina data som syftar till att erhålla den typen av delmängder på ett självövervakat sätt. Våra metoder bygger på iterativt träning av dual-encoder modeller för att beräkna likhetspoäng. Vi utvärderar våra metoder för att avljuda parallella texter och träna neurala maskinöversättningsmodeller. Vi finner att: (i) Den självövervakade förfiningen uppnår de flesta maskinöversättningsvinsterna i den första iterationen, men efter iterationer förbättrar dess inneboende utvärdering ytterligare. (ii) Maskinöversättningar kan förbättra ljudavläsningen i kombination med urvalssteg. (iii) Våra metoder kan uppnå utförandet av en övervakad metod. Våra metoder är helt självövervakade och lämpar sig väl för att hantera parvis data utan behov av förkunskaper eller mänskliga anteckningar.', 'ta': 'பலஹீனமாக கண்காணிக்கப்பட்ட சிக்கல் இணைப்பு உரைகள் போன்ற பேர்வைஸ் தரவு அமைப்புகள் மொத்தமாக தேவையான தரவு நிலைகள் இருக்க முடியும், ஆனால் பொதுவாக தரவு துணைகள் உள்ளன இந்த வகையான துணை பெறுவதற்கு தானே கண்காணிக்கப்படும் வழியில் இரண்டு முறைகளை நாம் கொண்டுள்ளோம். நமது முறைகள் பொருத்தமாக இருமுறை குறியீட்டு மாதிரிகளை கணக்கிடுவதற்கு அடிப்படையில் உள்ளது. We evaluate our methods on de-noising parallel texts and training neural machine translation models.  நாங்கள் கண்டுபிடிக்கிறோம்: (i) தானே கண்காணிக்கப்பட்ட புதுபாக்கியம் முதல் உருவாக்கத்தில் பெரும்பாலான இயந்திர மொழிமாற்றி ப (ii) இயந்திரம் மொழிபெயர்ப்புகள் தேர்ந்தெடுப்பு படிகளுடன் ஒன்றிணைக்கப்படும்போது தேர்ந்தெடுக்கப்பட்ட ம (i) கண்காணிக்கப்பட்ட முறையின் செயல்பாட்டை அடைய முடியும். முழுமையாக தானே பாதுகாப்பாக்கப்பட்டது, எங்கள் முறைமைகள் நன்றாக இருக்கும் ஜோடி விளக்கமான தகவல்களை கையாளும் முன்னோர்', 'ur': 'کمزور نظارت کی سیگنالوں سے جوڑی ہوئی جگہ ڈیٹا اپنے ساتھ استعمال کیا گیا ہے جگہ سیکھنے کی موڈل کی تعلیم کے لئے وسیع طور پر استعمال کیا گیا ہے. جیسے پارالٹ ٹکسٹ کے سامنے برابر کیلوٹ سٹ مل سکتے ہیں، لیکن معمولاً ڈیٹ سٹ کے سامنے لکھتے ہیں جو مثال سکھانے کے لئے زیادہ فائدہ ہیں. ہم دو طریقے پیش کرتے ہیں کہ دکھائے جاتے ہیں جو اس طریقے کے مطابق اپنے اوپر نظر آتے ہیں۔ ہمارے طریقے دوئل اکڈر نمڈلوں کی تعلیم پر بنیاد ہیں جو برابری اسکوروں کا شمار کریں۔ ہم نے اپنے طریقے ڈ-غږ کے مطابق پارالی ٹیکسٹ اور نیورل ماشین ترجمہ موڈل کی تطابق کرتے ہیں. ہم دیکھتے ہیں کہ: (i) خود نظارت کی پابندی پہلی بار میں بہت سی ماشین کی ترجمہ کا فائدہ پہنچاتا ہے، لیکن دوبارہ تکرار کے پیچھے اس کی داخلی ارزش کو اضافہ کرتا ہے۔ (ii) مشین ترجمہ گزاری قدموں کے ساتھ ڈی-غږ کی فعالیت کو بہتر کر سکتا ہے۔ (iii) ہمارے طریقے ایک تحقیق طریقے کے کام پہنچ سکتے ہیں۔ پوری طرح اپنے اوپر نظر کیا گیا ہے، ہمارے طریقے اگلے علم یا انسان کی اظہار کے بغیر جسم کی اطلاعات کے لئے بہتر مناسب ہیں.', 'vi': 'Dữ liệu được tự động tạo ra từ tín hiệu bị giám sát thiếu sót đã được sử dụng rộng rãi để huấn luyện các mô hình học sâu. Các tập tin cộng đồng như các văn bản song song có thể có mức độ chất lượng không ổn, nhưng thường có những nhóm dữ liệu có ích hơn là ví dụ về học tập. Chúng tôi giới thiệu hai phương pháp tinh chỉnh dữ liệu nhằm đạt mục đích tạo ra loại nhóm dưới đó theo cách tự giám sát. Phương pháp của chúng tôi dựa trên các mô hình kép được đào tạo để tính to án điểm tương đồng. Chúng tôi đánh giá phương pháp của chúng tôi trên các văn bản đồng loạt giảm âm và huấn luyện các mô hình dịch cỗ máy thần kinh. Chúng tôi thấy rằng: i) Sự tinh chế tự giám sát đạt được hầu hết các lợi nhuận của phiên bản dịch máy trong lần lặp đi đầu tiên, nhưng theo phiên bản nâng cao sự đánh giá của nó. Dịch cỗ máy có thể cải thiện hiệu suất giảm tiếng khi kết hợp với các bước chọn. (III, các phương pháp của chúng tôi có khả năng đạt được quy trình giám sát. Do hoàn to àn tự giám sát, phương pháp của chúng tôi rất phù hợp để xử lý các dữ liệu ghép mà không cần ghi chú hay thông tin con người.', 'uz': "Name Name Biz buni o'zimni o'zimni o'zgartirish uchun ikkita usulni o'zgartirish uchun qo'llanmiz. Biz usullamiz bir xil qiymatni hisoblash uchun ikkita kodlash modellari asosida. Biz o'ylaymiz, parallel matnlar va neyrol maskin tarjima modellarini qiymatmiz. Biz o'ylaymiz: (i) o'zimni boshqa narsalarga ko'pchilik tarjima qilishga erishiladi, lekin narsalarni qo'shishga qo'shish mumkin. (ii) Tarjima qilish (ii) Biz usullamiz taʼminlovchi usulni bajarish mumkin. Biz o'zimiz o'zimni boshqarish mumkin, bizning usullamiz bir xil maʼlumotni boshqarish uchun juda yaxshi ko'p ilmiy ko'rinishimiz kerak emas.", 'bg': 'Двойни данни, автоматично изградени от слабо контролирани сигнали, са широко използвани за обучение на модели за дълбоко обучение. Двойни набори от данни като паралелни текстове могат да имат неравномерни нива на качество като цяло, но обикновено съдържат поднабори от данни, които са по-полезни като примери за обучение. Представяме два метода за рафиниране на данните, които са насочени към получаване на този вид подмножество по самоконтролиран начин. Нашите методи се основават на итеративно обучение на модели с двоен кодер за изчисляване на сходни резултати. Ние оценяваме нашите методи за обезшумяване на паралелни текстове и обучение на модели на невронен машинен превод. Установяваме, че: (i) самоконтролираното усъвършенстване постига най-много печалби от машинния превод в първата итерация, но след итерации допълнително подобрява вътрешната си оценка. Машинните преводи могат да подобрят ефективността на обезшумяване, когато се комбинират със стъпки за подбор. (Нашите методи са в състояние да достигнат изпълнението на надзорен метод. Тъй като са изцяло самостоятелно контролирани, нашите методи са подходящи за обработка на двойки данни без необходимост от предварителни знания или човешки анотации.', 'nl': 'Pairwise data automatisch opgebouwd uit zwak begeleide signalen is veel gebruikt voor het trainen van deep learning modellen. Paarsgewijze datasets zoals parallelle teksten kunnen over het algemeen ongelijke kwaliteitsniveaus hebben, maar bevatten meestal gegevenssubsets die nuttiger zijn als leervoorbeelden. We presenteren twee methoden om data te verfijnen die gericht zijn op het verkrijgen van dit soort subsets op een zelfbegeleide manier. Onze methoden zijn gebaseerd op iteratieve training van dual-encoder modellen om gelijkenisscores te berekenen. We evalueren onze methoden op het verwijderen van parallelle teksten en trainen neurale machinevertaalmodellen. We vinden dat: (i) De zelfbegeleide verfijning de meeste winst in de eerste iteratie behaalt, maar volgende iteraties verbeteren de intrinsieke evaluatie verder. (ii) Machine vertalingen kunnen de de-noise prestaties verbeteren wanneer gecombineerd met selectiestappen. (iii) Onze methoden zijn in staat om de prestaties van een begeleide methode te bereiken. Omdat onze methodes volledig zelfbegeleid zijn, zijn ze zeer geschikt om pairwise data te verwerken zonder voorafgaande kennis of menselijke annotaties.', 'da': 'Parvise data, der automatisk er konstrueret ud fra svagt overvågede signaler, er blevet anvendt i vid udstrækning til træning af deep learning modeller. Parvise datasæt som parallelle tekster kan generelt have ujævne kvalitetsniveauer, men indeholder normalt datasæt, der er mere nyttige som læringseksempler. Vi præsenterer to metoder til at finpudse data, der har til formål at opnå den slags delmængder på en selvovervåget måde. Vores metoder er baseret på iterativ træning af dual-encoder modeller til beregning af lighedsscorer. Vi evaluerer vores metoder til afstøjning af parallelle tekster og træning af neurale maskinoversættelsesmodeller. Vi finder ud af, at: (i) Den selvovervågede raffinering opnår de fleste gevinster i maskinoversættelse i den første iteration, men efter iterationer forbedrer den iboende evaluering yderligere. (ii) Maskinoversættelser kan forbedre støjefjernelsesevnen, når de kombineres med udvælgelsestrin. (iii) Vores metoder er i stand til at nå udførelsen af en overvåget metode. Vores metoder er fuldstændig selvovervågede og egner sig godt til at håndtere parvise data uden behov for forudgående viden eller menneskelige annotationer.', 'ko': '약한 감독 신호로 자동으로 구성된 쌍의 데이터는 이미 심도 있는 학습 모델의 훈련에 광범위하게 사용되고 있다.평행 텍스트 등 데이터 집합의 전체적인 품질 수준은 불균형할 수 있지만, 일반적으로 더욱 유용한 데이터 서브집합을 포함하여 학습 예로 삼는다.우리는 이러한 서브집합을 자기 감독의 방식으로 얻기 위해 두 가지 방법을 제시했다.우리의 방법은 반복 훈련 더블 인코더 모델을 바탕으로 유사성 점수를 계산한다.우리는 평행 텍스트의 소음을 없애고 신경기계 번역 모델을 훈련시키는 방법을 평가했다.우리는 (i) 자체 감독의 정화는 첫 번째 교체에서 대부분의 기계 번역 수익을 얻었지만 후속 교체는 그 내재적인 평가를 더욱 개선시켰다.(ii)기계번역과 선택 절차를 결합하면 소음 제거 성능을 높일 수 있다.(iii) 우리의 방법은 감독 방법의 성능에 도달할 수 있다.완전한 자기 감독으로 인해 우리의 방법은 선험지식이나 인공주석이 필요 없이 데이터 쌍으로 처리하기에 매우 적합하다.', 'hr': 'Podaci o paru koji su automatski izgrađeni iz slabe nadzorne signale široko se koriste za obuku modela dubokog učenja. Podaci podataka o paru poput paralelnih tekstova mogu imati ukupno jednake razine kvalitete, ali obično sadrže podatke podataka koji su korisniji kao primjeri učenja. Predstavljamo dvije metode za refinansiranje podataka koje su ciljane da dobiju takve podatake na samopouzdani način. Naše metode su temeljene na iterativnoj obuci modela dvokodera kako bi računali rezultate sličnosti. Procjenjujemo naše metode o paralelnim tekstima i obuci modela prevoda neuralnih strojeva. Pronašli smo da: i) samopouzdanje rafiniranja postiže većinu dobića prevoda strojeva u prvoj iteraciji, ali nakon iteracija dalje poboljšava svoju unutrašnju procjenu. ii) prevodi strojeva mogu poboljšati djelujuće učinke u kombinaciji s koracima izbora. iii) Naše metode mogu postići provedbu nadzornog metoda. Budući potpuno samopouzdani, naši metodi su dobro odgovarajući za rješavanje parovnih podataka bez potrebe za prethodnim znanjem ili ljudskim annotacijom.', 'de': 'Pairwise Daten, die automatisch aus schwach überwachten Signalen erstellt werden, wurden häufig für das Training von Deep Learning Modellen verwendet. Paarweise Datensätze wie parallele Texte können insgesamt ein ungleichmäßiges Qualitätsniveau aufweisen, enthalten aber in der Regel Datenuntergruppen, die als Lernbeispiele nützlicher sind. Wir stellen zwei Methoden vor, um Daten zu verfeinern, die darauf abzielen, diese Art von Teilmengen selbstüberwacht zu erhalten. Unsere Methoden basieren auf iterativem Training von Dual-Encoder-Modellen zur Berechnung von Ähnlichkeitswerten. Wir evaluieren unsere Methoden zur Entrauschung paralleler Texte und trainieren neuronale maschinelle Übersetzungsmodelle. Wir stellen fest, dass: (i) Die selbstüberwachte Verfeinerung die meisten Gewinne in der maschinellen Übersetzung in der ersten Iteration erzielt, aber folgende Iterationen verbessern ihre intrinsische Bewertung weiter. (ii) Maschinenübersetzungen können die Rauschunterdrückung verbessern, wenn sie mit Auswahlschritten kombiniert werden. (iii) Unsere Methoden sind in der Lage, die Leistung einer überwachten Methode zu erreichen. Da unsere Methoden vollständig selbst beaufsichtigt sind, sind sie gut geeignet, paarweise Daten ohne Vorwissen oder menschliche Anmerkungen zu verarbeiten.', 'id': 'Data pasangan yang dibuat secara otomatis dari sinyal yang terlihat lemah telah digunakan secara luas untuk melatih model belajar dalam. Pairwise datasets such as parallel texts can have uneven quality levels overall, but usually contain data subsets that are more useful as learning examples.  Kami mempersembahkan dua metode untuk memperbaiki data yang ditujukan untuk mendapatkan jenis subkelompok tersebut dengan cara yang diawasi oleh diri sendiri. Metode kami berdasarkan latihan iteratif model double-encoder untuk menghitung skor persamaan. Kami mengevaluasi metode kami dalam mengeluarkan teks paralel dan melatih model terjemahan mesin saraf. Kami menemukan bahwa: (i) Penyesuaian yang diawasi sendiri mencapai kebanyakan peningkatan terjemahan mesin dalam iterasi pertama, tetapi mengikuti iterasi lebih memperbaiki evaluasi dalamnya. (ii) Terjemahan mesin dapat meningkatkan prestasi mengeluarkan suara ketika dikombinasikan dengan langkah pemilihan. (iii) Metode kami mampu mencapai prestasi dari metode yang diawasi. Menjadi benar-benar mengawasi diri sendiri, metode kita cocok untuk menangani data pasangan tanpa membutuhkan pengetahuan sebelumnya atau anotasi manusia.', 'sw': 'Pairwise data automatically constructed from weakly supervised signals has been widely used for training deep learning models.  Mitandao ya taarifa kama vile maandishi yanayofanana yanaweza kuwa na kiwango cha kiwango cha usawa kwa ujumla, lakini mara nyingi hujumuisha viungo vya taarifa ambavyo vina manufaa zaidi kama mifano ya kujifunza. Tunaweza kuweka mbinu mbili za kuboresha taarifa zinazolenga kupata viungo hivyo kwa njia ya kujichunguza. Mindo yetu inatokana na mafunzo ya mfumo wa kodi mbili ili kuhesabu vipimo vya usawa. Tunatathmini mbinu zetu za maandishi yanayofanana na mafunzo ya utafsiri wa mashine ya neurali. Tunapata kwamba: (i) Mabadiliko ya kujitazama yanafanikiwa kupata mafanikio mengi ya kutafsiri mashine katika viwanja vya kwanza, lakini kufuatia vitu vinavyoendelea kuboresha tafiti yake ya ndani. (ii) Tafsiri za mashine zinaweza kuboresha utendaji wa sauti unapoungana na hatua za uchaguzi. (iii) njia zetu zinaweza kufikia utendaji wa njia inayochunguzwa. Kufuatiliwa kwa ujumla, mbinu zetu zina vyema kukabiliana na takwimu mbili zenye akili bila haja ya maarifa ya zamani au matatizo ya binadamu.', 'fa': 'اطلاعات جفتی که از سیگنال های ضعیف تحت نظر قرار گرفته شده به طور وسیع برای آموزش مدل یادگیری عمیق استفاده می\u200cشود. مجموعه\u200cهای داده\u200cهای جفت مانند متن\u200cهای متفاوتی می\u200cتوانند در کل سطح کیفیت نابرابر داشته باشند، اما معمولاً مجموعه\u200cهای داده\u200cها را دارند که به عنوان نمونه\u200cهای یادگیری مفید\u200cتر هستند. ما دو روش برای پاکسازی داده\u200cها را پیشنهاد می\u200cکنیم که هدف می\u200cگیرند تا این نوع زیر\u200cبخش\u200cها را به طریق خود تحت نظر بگیریم. روش\u200cهای ما بر روی مدل\u200cهای دوگانه\u200cای آموزش دوگانه\u200cای برای محاسبات امتیاز\u200cهای شبیه هستند. ما روش\u200cهایمان را در مورد متن\u200cهای پارالل و ترجمه\u200cهای ماشین\u200cهای عصبی ارزیابی می\u200cکنیم. ما این را پیدا می\u200cکنیم: (i) تغییرات خود را بررسی می\u200cکند که بیشتر ترجمه\u200cهای ماشین را در اولین بار بررسی می\u200cکند، ولی بعد از تغییرات بیشتر ارزیابی داخلی خود را بهتر می\u200cکند. (ii) ترجمه\u200cهای ماشین می\u200cتوانند هنگامی که با قدم\u200cهای انتخاب ترجمه می\u200cشوند عملکرد غیر صدا را بهتر کنند. (iii) روش\u200cهای ما می\u200cتوانند به انجام یک روش تحت نظر رسیده باشند. به طور کامل تحت نظر خودمون، روش\u200cهامون به خوبی مناسب هستند تا اطلاعات جفت\u200cها را بدون نیازی به دانش\u200cهای قبلی یا آگاهی\u200cهای انسان تحت نظر بگیریم.', 'sq': 'Të dhënat e çifteve të ndërtuara automatikisht nga sinjalet e mbikqyrur dobësisht janë përdorur gjerësisht për trajnimin e modeleve të mësimit të thellë. Të dhënat e çifteve të tilla si tekstet paralele mund të kenë nivele të pabarazishëm kualiteti përgjithësisht, por zakonisht përmbajnë nëngrupe të dhënash që janë më të dobishme si shembuj mësimi. Ne paraqesim dy metoda për të rafinuar të dhënat që synojnë të marrin këtë lloj nëngrupesh në një mënyrë vetëmbikqyrure. Metodat tona janë bazuar në trajnimin e përsëritur të modeleve me dy kodues për të llogaritur rezultatet e ngjashmërisë. Ne vlerësojmë metodat tona për të hequr zhurmën e teksteve paralele dhe për të trajnuar modelet e përkthimit të makinave nervore. Ne gjejmë se: (i) rafinimi i vetëmbikqyrur arrin shumicën e fitimeve të përkthimit automatik në përsëritjen e parë, por pas përsëritjeve përmirëson më tej vlerësimin e saj të brendshëm. (ii) Machine translations can improve the de-noising performance when combined with selection steps.  (iii) Metodat tona janë në gjendje të arrijnë performancën e një metode të mbikqyrur. Being entirely self-supervised, our methods are well-suited to handle pairwise data without the need of prior knowledge or human annotations.', 'af': "Pairwise data outomaties gebruik van swak ondersoekte signale is vaste gebruik vir onderwerp diep leer modele. Pairwise datastel soos parallele teks kan ongelyk kwaliteit vlakke heeltemal hê, maar gewoonlik bevat data substelle wat meer bruikbaar is as leervoudige voorbeelde. Ons stel twee metodes om data te refineer wat doel is om daardie soort subartikels te kry op 'n selfbesig manier. Ons metodes is gebaseer op iteratiewe onderwerp twee-enkoder modele om gelykheidstelling te bereken. Ons evalueer ons metodes op de- noising parallele tekste en onderwerp neurale masjien vertaling modele. Ons vind dat: i) Die self-ondersoekte herstelling van die meeste masjien vertaling verkry in die eerste iterasie, maar volg iterasies verder sy intrinsiese evaluering verbeter. (ii) Masjien vertalings kan die de- noising prestasie verbeter wanneer gekombineer word met keuse stappe. (iii) Ons metodes kan die prestasie van 'n ondersoekte metode bereik. As ons heeltemal self-superviseer is, is ons metodes goed geskik om paar wyse data te hanteer sonder die behoefte van vorige kennis of menslike annotasies.", 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s እንደተፈላጊ ጽሑፎች የጥያቄ ጥያቄ ደረጃዎች በሙሉ ይችላል፤ ነገር ግን እንደምታስተምር ምሳሌ የሚጠቅሙ የዳታ ጥያቄዎች ይኖራሉ። እንደዚህ ዓይነት አካባቢዎችን ለራሱ በመጠበቅ መንገድ ለማግኘት የሚችሉትን ዳታዎችን ለማድረግ ሁለት መንገዶች እናቀርባለን፡፡ የሥርዓታችን ሥርዓት ሁለተኛ የድምፅ አካባቢዎችን ለመቆጠር በመሠረት ነው፡፡ የባሕላዊ ጽሑፎችን እና የነዌብ መሣሪያን ትርጉም ሞዴላዎችን እናስተምራለን፡፡ እንዲህ እናገኘዋለን:(i) ራሱ የተጠበቀው ማስታወቂያው በመጀመሪያው መፍጠር ብዙዎቹን የመረጃ ትርጉም አግኝቷል፤ ነገር ግን በጥያቄው ውይይት ማሻሻል፡፡ (ii) የመኪን ትርጉም በመረጃ ደረጃዎች በተጠቃሚ ጊዜ የድምፅ ድምፅ ድምፅ ማድረግ ይችላል። (iii) መንገዳችን የተጠበቀውን ልማድ ለመደርስ ይችላል፡፡ ራሳችንን በመጠበቅ፣ የሁለትን ጥበበኞች ዳታዎችን ለመቀበል እና የሰው ማሰቃየት ባስፈልጋቸው ልማድ መልካም ነው፡፡", 'tr': 'Aýahatça gözleýän signallerden inşa edilen çiftleýik maglumatlar derin öwrenmek nusgalaryny öwrenmek üçin köplenç ulanylýar. Parallel metin ýaly çiftleşdirim maglumaty düzümleri çykaryp biler. Emma adatça öwrenmek ýaly has üçin ullanyş maglumaty düzümleri bar. Biz öz-özüne gözlemäge amaçly maglumatlary taýýarlamak üçin iki yöntemi görkeýäris. Biziň yönlerimiz, beýleki noktalary hasaplamak üçin ikinji ködleme sistemasyna daýanýar. Biz öz metodlarymyzy parallel tekstlerden çykyp, nural maşynyň terjime modellerinde çykyp çykýarys. Öz gözlemän taýýarlanma ilkinji gezek maşynyň terjime edeniň köp ýerini birinji gezek ýerine ýetirýär, ýöne tekrarlaryň yzyndan soňra daşary çözümlerini gowdurýar. (ii) Maşynyň terjimeleri saýlaw adımlary bilen birleşince sesli eserini gowurap biler. (iii) Biziň yöntemlerimiz gözlemäge taýýarlanan yöntemimize ulap biler. Öňki bilgi ýa-da ynsan duýdurmasy gerek bolmadykdan çykyp biljek maglumatlarymyz gowy gözleýän.', 'hy': 'Pairwise data automatically constructed from weakly supervised signals has been widely used for training deep learning models.  Երկու համակարգեր, ինչպիսիք են զուգահեռ տեքստերը, կարող են ունենալ անհավասար որակային մակարդակներ ընդհանուր առմամբ, բայց սովորաբար պարունակում են տվյալների ենթահամակարգեր, որոնք ավելի օգտակար են որպես ուս Մենք ներկայացնում ենք երկու մեթոդ, որպեսզի վերլուծենք տվյալները, որոնք նպատակով են ստանալ այդ տեսակի ենթախմբեր ինքնավերահսկվող կերպով: Մեր մեթոդները հիմնված են կրկնօրինակ կրկնօրինակող երկու կոդավորման մոդելների վրա նմանությունների հաշվարկելու համար: Մենք գնահատում ենք մեր մեթոդները զուգահեռ հաղորդագրությունների ձայնաչափման և նյարդային մեքենայի թարգմանման մոդելների ուսուցման համար: Մենք հայտնաբերում ենք, որ: (i) Ինքնավերահսկվող վերականգնումը հասնում է մեքենային թարգմանման ամենաշատը առաջին կրկնման ընթացքում, բայց կրկնման ընթացքում շարունակում է բարելավել իր ներքին գնահատականը: (ii) Machine translations can improve the de-noising performance when combined with selection steps.  Մեր մեթոդները կարողանում են հասնել վերահսկված մեթոդի կատարման: Որպես ամբողջովին ինքնավերահսկողություն, մեր մեթոդները լավ համապատասխանում են զույգչափ տվյալների վերաբերյալ առանց նախկին գիտելիքների կամ մարդկային նկարագրությունների կարիքի:', 'bn': 'দুর্বল পর্যবেক্ষণ করা সিগন্যাল থেকে স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয়ভাবে নির্মাণ করা তথ্য গভীর শিক্ষা মডেল প্রশ প্যারাইভাইস ডাটাসেট, যেমন প্যারালেল লেখাগুলো সাধারণত অজানা মানের স্তর থাকতে পারে, কিন্তু সাধারণত তথ্য সাবস্টেটের আমরা দুই পদ্ধতি উপস্থাপন করি যাতে তথ্য পুনরুদ্ধার করতে পারি যার উদ্দেশ্য হচ্ছে এই ধরনের সাবটগুলো নিজেদের নিজেদের আমাদের পদ্ধতি একই স্কোর গণনা করার জন্য প্রশিক্ষণ দুই-এনকোডার মডেলের উপর ভিত্তিক। আমরা প্যারালেল লেখা এবং নিউরেল মেশিন অনুবাদ মডেলে আমাদের মূল্যের মূল্যায়ন করি। আমরা খুঁজে পাচ্ছি: (i) আত্মপরায়ণতার সংস্কার প্রথম বিষয়বস্তুতে বেশীরভাগ মেশিন অনুবাদ অর্জন পেয়েছে, কিন্তু বিষয়বস্তুর অনুসরণের পরে  (ii) মেশিন অনুবাদের সাথে নির্বাচন পদক্ষেপের সাথে সংযুক্ত হওয়ার পর ডি-আওয়াজের প্রদর্শনের কার্যক্রম উন্নত করতে প (ই) আমাদের পদ্ধতি একটি পর্যবেক্ষক পদ্ধতি পৌঁছাতে পারে। পুরোপুরি নিজেকে পর্যবেক্ষণ করা হচ্ছে, আমাদের পদ্ধতি ভালোভাবে মানুষের পূর্বের জ্ঞান অথবা মানুষের বিরক্তির প্রয়োজন ছাড়া', 'az': 'Çiftli təhsil edilmiş sinyallərdən automatsk inşa edilmiş payı verilər derin öyrənmə modellərini təhsil etmək üçün genişliyi istifadə edilmişdir. Parallel metinlər kimi çift verilən qurğular böyük bir kalitel seviyeli olar, amma genellikle öyrənmək məsəlləri kimi daha faydalı verilən verilən qurğular içərir. Biz bu məlumatları özünün gözləmə yolunda almaq məqsədilə təmizlənmək üçün iki yol göstəririk. Bizim metodlarımız, bənzər nöqtələri hesablamaq üçün ikili kodlayıcı modellərə təhsil edilir. Bizim metodlarımızı çətinliklə paralel metinlər və nöral maşın çeviri modellərində təhsil edirik. Özümüzün gözlədiyi rafinçək ilk dəfə maşın çevirilməsi qəbul edər, amma tekrarların ardınca daxilində ölçülərini daha yaxşılaşdırır. (ii) Seçim adımları ilə birlikdə maşın tercümələri səslənmə performansını yaxşılaşdıra bilər. ( iii) Bizim metodlarımız gözləmə metodun təqdirinə yetişə bilər. Özümüzdən tamamilə gözləyirik, metodlarımız əvvəlki bilgi və insan məlumatlarına ehtiyacı olmadan çift məlumatları idarə etmək üçün yaxşı uyğundur.', 'bs': 'Podaci o paru koji su automatski izgrađeni iz slabe nadzorne signale široko se koriste za obuku modela dubokog učenja. Podaci o paru poput paralelnih tekstova mogu imati ukupno jednake nivoe kvaliteta, ali obično sadrže podaci podataka koji su korisniji kao primjeri učenja. Predstavljamo dvije metode za refinansiranje podataka koje su ciljane da dobiju takve podatake na samoopraćen način. Naše metode su temeljene na iterativnoj obuci modela dvokodera kako bi računali rezultate sličnosti. Procjenjujemo naše metode o paralelnim tekstima i obuci modele prevođenja neuralnih strojeva. Pronašli smo da: i) samopouzdanje refinerije postiže većinu dobitnika prevoda strojeva u prvoj iteraciji, ali nakon iteracija bolje poboljšava svoju unutrašnju procjenu. ii) prevodi mašine mogu poboljšati djelovanje buke u kombinaciji s koracima izbora. iii) Naši metodi su u mogućnosti da postignu izvršnost nadzornog metoda. Budući potpuno samopouzdani, naši metodi su dobro odgovarajući za rješavanje parovičnih podataka bez potrebe za prethodnim znanjem ili ljudskim annotacijom.', 'cs': 'Párová data automaticky sestavená ze slabě sledovaných signálů byla široce používána pro trénink modelů hlubokého učení. Párové datové sady, jako jsou paralelní texty, mohou mít celkově nerovnoměrnou úroveň kvality, ale obvykle obsahují datové podmnožiny, které jsou užitečnější jako příklady učení. Představujeme dvě metody pro upřesnění dat, které mají za cíl získat tento druh podmnožin vlastním dohledem. Naše metody jsou založeny na iterativním tréninku modelů dvou kodérů pro výpočet bodů podobnosti. Naše metody hodnotíme na odstraňování šumu paralelních textů a tréninku neuronových strojových modelů překladu. Zjišťujeme, že: (i) Samozřejmé vylepšení dosahuje největších zisků strojového překladu v první iteraci, ale následující iterace dále zlepšují jeho vnitřní hodnocení. (ii) Strojové překlady mohou zlepšit výkon odstraňování šumu v kombinaci s kroky výběru. (iii) Naše metody jsou schopny dosáhnout výkonu dohledované metody. Naše metody jsou zcela pod vlastním dohledem vhodné pro zpracování párových dat bez nutnosti předchozích znalostí nebo lidských anotací.', 'et': 'Sügavõppe mudelite koolitamiseks on laialdaselt kasutatud automaatselt nõrgalt järelevalve all olevatest signaalidest moodustatud paariandmeid. Paari andmekogumitel, näiteks paralleelsetel tekstidel, võib olla üldiselt ebaühtlane kvaliteet, kuid tavaliselt sisaldavad andmekogumeid, mis on õppimise näidetena kasulikumad. Esitame kaks meetodit andmete täpsustamiseks, mille eesmärk on saada selliseid alamhulke ise järelevalve all. Meie meetodid põhinevad iteratiivsel koolitusel kahekodeerijate mudelitel sarnasuse skoori arvutamiseks. Hindame paralleelsete tekstide müra eemaldamise meetodeid ja neuromasintõlke mudelite koolitamist. Leiame, et: (i) Isejärelevalve täiustamine saavutab enamiku masintõlke kasu esimesel iteratsioonil, kuid pärast iteratsioone parandab veelgi selle sisemist hindamist. ii) masintõlked võivad parandada müra eemaldamise jõudlust, kui need on kombineeritud valikutoimingutega. (iii) Meie meetodid suudavad saavutada järelevalvemeetodi tulemuslikkuse. Olles täielikult ise järelevalve all, sobivad meie meetodid hästi paari andmete käsitlemiseks ilma eelnevate teadmiste või inimese märkusteta.', 'ca': "Les dades de parell construïdes automàticament a partir de senyals debidament supervisats s'han utilitzat ampliament per formar models d'aprenentatge profund. Els conjunts de dades parelles com els textos paralèls poden tenir nivells de qualitat desiguals en general, però normalment contenen subconjunts de dades que són més útils com exemples d'aprenentatge. Presentam dos mètodes per refinar les dades destinades a obtenir aquest tipus de subgrups d'una manera autosupervisada. Our methods are based on iteratively training dual-encoder models to compute similarity scores.  Evaluam els nostres mètodes de dessorollar els textos parallels i entrenar models de traducció neuronal. Trobem que: (i) El refinament auto-supervisat aconsegueix la majoria dels guanys de traducció màquina en la primera iteració, però segons les iteracions millora encara més la seva evaluació intrínseca. ii) Les traduccions de màquines poden millorar el rendiment de dessoroll combinat amb etapes de selecció. iii) Els nostres mètodes són capaços d'aconseguir la performance d'un mètode supervisat. Estant totalment autosupervisos, els nostres mètodes són adequats per manejar dades parelles sense la necessitat de coneixement previ o anotacions humanes.", 'fi': 'Heikosti valvotuista signaaleista automaattisesti muodostettua parikohtaista dataa on käytetty laajasti syväoppimismallien harjoittelussa. Parikohtaiset aineistot, kuten rinnakkaistekstit, voivat olla yleisesti ottaen epätasaisia laatutasoja, mutta ne sisältävät yleensä tietoryhmiä, jotka ovat hyödyllisempiä oppimisesimerkkeinä. Esitämme kaksi menetelmää tiedon tarkentamiseen, joiden tarkoituksena on saada tällaisia osajoukkoja itsevalvotulla tavalla. Menetelmämme perustuvat kaksoiskoodausmallien iteratiiviseen harjoitteluun samankaltaisuuspisteiden laskemiseksi. Arvioimme menetelmiämme rinnakkaistekstien melunpoistossa ja neurokonekäännösmallien harjoittelussa. Havaitsemme, että: (i) Itsevalvottu jalostus saavuttaa suurimman osan konekäännöksen voitoista ensimmäisessä iteraatiossa, mutta seuraavat iteraatiot parantavat edelleen sen sisäistä arviointia. (ii) Konekäännökset voivat parantaa melunpoistokykyä yhdistettynä valintavaiheisiin. (iii) Menetelmillämme voidaan saavuttaa valvotun menetelmän suorituskyky. Koska menetelmämme ovat täysin itseohjautuvia, ne soveltuvat hyvin paritietojen käsittelyyn ilman ennakkotietoa tai inhimillisiä huomautuksia.', 'jv': 'Genjer Paragraf Awak dhéwé éntuk sistem sing duwé kanggo nggawe dadi iki dadi iki dadi iki dadi nggawe barang-sistem iki dadi bisa nguasakno. Awakdhéwé éntuk sistemané karo nggawe sistem item-tanggal, model-koder kuwi nggawe barang sambaran. Awakdhéwé éntuk dhéwé kuwi nggambar luwih-luwih basa gambar nggawe tarjamahan karo model itolet kuwi perintal maneh. Awak dhéwé éné: i) iso nglanggar sampeyan nguasai perbudhakan iso nggawe tarjamah karo ingkang sampeyan, mengko iso nggawe Iturasi sing luwih apik dhéwé, ngono nggawe tarjamahan sing luwih apik nyebute sing apik nyebute. (ii) Perintah sing dibutuhke maneh iso nggawe gerakan kanggo ngilangno gerakan sing dibutuhke gambaran. iii) Ndolem sing iso nggawe dadi nggawe barang pengguna suproti. Isi-isih lanjut sampeyan nguasai, awak dhéwé iki dadi luwih-luwih apik kanggo ngilangno awak dhéwé kuwi kesempatan kanggo ngerasai awak dhéwé.', 'ha': "@ info: whatsthis QScriptBreakpointsModel Kuma Munã zo da hanyõyi biyu dõmin ka tsare data da ake yi nufin su sami wannan nau'a cikin hanya mai tsaro. Tsarakanmu ne a kan yin amfani da misãlai na koda dubu-dubu dõmin ya lissafa score masu daidaita. Tuna ƙaddara hanyoyinmu a kan misãlai masu yin sauri da misalin fassarori na aikin neural. We find that: (i) The self-supervised refinement achieves most machine translation gains in the first iteration, but following iterations further improve its intrinsic evaluation.  (ii) Tsarin Fassarori na Kana iya ƙarar da performance na-sauna idan an haɗa da hanyõyin zaɓen. Zuwa-hanyõyinMu, za'a iya cika wani metode mai tsaro. Kuma a kan tsare kansa, hanyoyinmu na da amfani ga su yi aiki da data biyu ko kuma bã da haji ba ga a gaba ga wani ilmi ko taɓa ga mutane.", 'sk': 'Parni podatki, ki so samodejno zgrajeni iz slabo nadzorovanih signalov, se pogosto uporabljajo za usposabljanje modelov globokega učenja. Zbirke podatkov po pareh, kot so vzporedna besedila, imajo lahko na splošno neenakomerne ravni kakovosti, vendar običajno vsebujejo podnabore podatkov, ki so bolj uporabni kot učni primeri. Predstavljamo dve metodi za izboljšanje podatkov, katerih cilj je pridobitev tovrstnih podmnožic na samonadzorovan način. Naše metode temeljijo na iterativnem usposabljanju modelov z dvojnim kodirnikom za izračun podobnih rezultatov. Naše metode ocenjujemo na področju odstranjevanja hrupa vzporednih besedil in usposabljanja modelov nevronskega strojnega prevajanja. Ugotavljamo, da: (i) samonadzorovana izpopolnitev doseže največ dobičkov strojnega prevajanja v prvi iteraciji, vendar po iteracijah dodatno izboljša njeno notranjo oceno. (ii) Strojni prevodi lahko izboljšajo učinkovitost odstranjevanja hrupa v kombinaciji s koraki izbire. (iii) Naše metode lahko dosežejo izvedbo nadzorovane metode. Ker so naše metode popolnoma samonadzorovane, so primerne za obdelavo pare podatkov brez potrebe po predhodnem znanju ali človeških opombah.', 'he': 'נתוני זוג שנבנו באופן אוטומטי מאותם אותים ששולטים בחולשה השתמשו באופן רחב לאימון דוגמני למידה עמוקה. קבוצות מידע זוגות כמו טקסטים מקבילים יכולות להיות רמות איכות לא שונות באופן כללי, אך בדרך כלל מכילות קבוצות נתונים שימושיות יותר כדוגמאות למידה. We present two methods to refine data that are aimed to obtain that kind of subsets in a self-supervised way.  השיטות שלנו מבוססות על אימון חוזר מודלים של קודד כפול כדי לחשב נקודות דומה. אנו מעריכים את השיטות שלנו על טקסטים מקבילים מוסריים ומאמנים מודלים התרגום של מכונות עצביות. אנו מוצאים את זה: (i) השיפוץ השופט בעצמו משיג את רוב הרווחים של התרגום המכונית בשיפוץ הראשון, אבל לאחר השיפורים משפר את הערכה הפנימית שלה. (ii) תרגומות מכונות יכולות לשפר את ההפעלה המסרת הרעש כשהן משולבות עם צעדים בחירה. (iii) השיטות שלנו מסוגלות להגיע לביצוע של שיטה מבוקרת. כשאנחנו שומרים על עצמנו לחלוטין, השיטות שלנו מתאימות היטב להתמודד עם נתונים זוגות ללא צורך של ידע קודם או הערות אנושיות.', 'bo': 'Pairwise data automatically constructed from weakly supervised signals has been widely used for training deep learning models. Pairwise datasets such as parallel texts can have uneven quality levels overall, but usually contain data subsets that are more useful as learning examples. ང་ཚོས་རང་ཉིད་ལྟ་བུའི་ཐབས་ལམ་གཉིས་མཉམ་དུ་འཇོག་ཡོད་པའི་ཐབས་ལམ་གཉིས་མཉམ་དུ་བཞག་ཡོད། Our methods are based on iteratively training dual-encoder models to compute similarity scores. ང་ཚོས་རང་གི་ཐབས་ལམ་ལ་བསྟེན་ནས་དབུས་མཐུན་གྱི་ཡིག་གཟུགས་དང་། སྒྲ་བརྙན་གྱི་མ་ལག་གི་དབུས་མཐུན་དཔེ་དབུས ང་ཚོས་དུས་མཐོང: (i) རང་ཉིད་ལྟ་རྟོག (ii) མིག (iii) ང་ཚོའི་ལམ་ལུགས་འདི་ལྟ་རྟོག་བྱེད་མི་ལམ་ལུགས་ཀྱི་སྒྲུབ་ཕྱོགས་ཡོད། Being entirely self-supervised, our methods are well-suited to handle pairwise data without the need of prior knowledge or human annotations.'}
{'en': 'A Survey of the State of Explainable AI for  Natural Language Processing AI  for Natural Language Processing', 'ar': 'مسح لحالة الذكاء الاصطناعي القابل للتفسير لمعالجة اللغة الطبيعية', 'es': 'Una encuesta sobre el estado de la IA explicable para el procesamiento del lenguaje natural', 'pt': 'Uma pesquisa sobre o estado da IA explicável para processamento de linguagem natural', 'fr': "Une enquête sur l'état de l'IA explicable pour le traitement du langage naturel", 'hi': 'प्राकृतिक भाषा प्रसंस्करण के लिए व्याख्यायोग्य एआई की स्थिति का एक सर्वेक्षण', 'zh': '自然语言处可解AI见状勘问', 'ja': '自然言語処理のための説明可能なAIの現状調査', 'ru': 'Обзор состояния объяснимого ИИ для обработки естественного языка', 'ga': 'Suirbhé ar Staid an AI Inmhínithe maidir le Próiseáil Teanga Nádúrtha', 'el': 'Μια έρευνα για την κατάσταση της επεξηγημένης τεχνητής νοημοσύνης για την επεξεργασία φυσικής γλώσσας', 'hu': 'A magyarázható mesterséges intelligencia állapotának felmérése a természetes nyelvfeldolgozáshoz', 'ka': 'სახელსაწყოთა ენის პროცესისთვის სახელსაწყოთა AI სტატის შესახებ', 'it': "Un'indagine sullo stato dell'intelligenza artificiale spiegabile per l'elaborazione del linguaggio naturale", 'kk': 'Табиғи тіл процессері үшін түсінікті AI күйін зерттеу', 'lt': 'Paaiškinamojo AI dėl natūralios kalbos apdorojimo valstybės tyrimas', 'mk': 'Истражување на состојбата на објаснливата ВИ за природното обработување јазик', 'ms': 'Survey of the State of Explainable AI for Natural Language Processing', 'ml': 'സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയയ്ക്കുവേണ്ടി വ്യക്തമാക്കാവുന്ന സ്റ്റേറ്റ് എ- എ- ലെ ഒരു പരിശോധന', 'mn': 'Байгалийн хэл үйлдвэрлэхийн тулд тодорхойлж болох AI-ын орнуудын судалгаа', 'no': 'Name', 'pl': 'Badanie stanu wytłumaczalnej AI dla przetwarzania języka naturalnego', 'ro': 'Un studiu privind starea AI explicabilă pentru prelucrarea limbajului natural', 'sr': 'Istraživanje države objašnjivih AI za proces prirodnog jezika', 'mt': 'Stħarriġ tal-Istat tal-AI Spjegabbli għall-Ipproċessar tal-Lingwi Naturali', 'si': 'Name', 'so': 'A Survey of the State of Explaiable AI for Processing Natural language', 'ta': 'இயல்பான மொழி செயல்பாடுக்கான விளக்கக்கூடிய AI நாட்டின் ஒரு பரிசோதனை', 'ur': 'طبیعی زبان پردازی کے لئے واضح AI کی حالت کا تحقیق', 'sv': 'En kartläggning av tillståndet för förklarande AI för behandling av naturligt språk', 'uz': 'Name', 'vi': 'A Survey of the State of Giải thích AI for Natural language treatment', 'bg': 'Проучване на състоянието на обяснимия изкуствен интелект при обработката на естествения език', 'da': 'En undersøgelse af tilstanden for forklarelig AI til behandling af natursprog', 'hr': 'Istraživanje države objašnjivih AI za proces prirodnog jezika', 'nl': 'Een overzicht van de staat van uitlegbare AI voor de verwerking van natuurlijke taal', 'de': 'Ein Überblick über den Stand erklärbarer KI für die Verarbeitung natürlicher Sprache', 'id': 'Survey of the State of Explainable AI for Natural Language Processing', 'fa': 'یک تحقیق ایالت AI توضیح برای پرداخت زبان طبیعی', 'tr': 'Dobiýal dil işlemek üçin A ňlap AI durumynyň barlag', 'ko': '자연 언어 처리에서 인공지능의 현황을 설명할 수 있는 종합 서술', 'af': 'Name', 'sw': 'Tafiti la Taifa la AI inayoeleweka kwa ajili ya Utafiti wa lugha ya asili', 'sq': 'Një sondazh i gjendjes së AI të shpjegueshme për procesimin e gjuhës natyrore', 'am': 'A Survey of the State of Explainable AI for Natural Language Processing', 'hy': 'Բնական լեզվի վերաբերյալ բացատրելի ԱԲ-ի վիճակի հետազոտությունը', 'bs': 'Istraživanje države objašnjivih AI za proces prirodnog jezika', 'az': 'Təbiətli Dil İşləməsi üçün aydınlaşdırılabilir AI eyaletinin', 'bn': 'স্বাভাবিক ভাষার প্রক্রিয়ার জন্য ব্যাখ্যা আই-রাষ্ট্রের একটি পর্যবেক্ষণ', 'et': 'Looduskeele töötlemise selgitatava tehisintellekti olukorra uuring', 'ca': 'A Survey of the State of Explainable AI for Natural Language Processing', 'cs': 'Průzkum stavu vysvětlitelné AI pro zpracování přirozeného jazyka', 'fi': 'Selittävän tekoälyn tila luonnollisen kielen prosessoinnissa', 'jv': 'Asmaci perusahaan AI sing paling-perusahaan kanggo Periksus Language Daftar', 'sk': 'Raziskava stanja pojasnljive umetne inteligence za predelavo naravnega jezika', 'he': 'חקירה של מצב התמונה המסבירה על התהליך השפה הטבעית', 'ha': 'KCharselect unicode block name', 'bo': 'སྤྱིར་བཏང་བའི་སྐད་རིགས་ལས་སྦྱོར་ཀྱི་གནས་སྟངས་ལ་བལྟ་སྟངས་ཞིབ'}
{'en': 'Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of  models  becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of  Natural Language Processing (NLP) . We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area.', 'es': 'En los últimos años se han producido importantes avances en la calidad de los modelos de última generación, pero esto se ha producido a costa de que los modelos se vuelvan menos interpretables. Esta encuesta presenta una visión general del estado actual de la IA Explicable (XAI), considerada dentro del dominio del procesamiento del lenguaje natural (NLP). Discutimos la principal categorización de las explicaciones, así como las diversas formas en que se pueden llegar a las explicaciones y visualizarlas. Detallamos las técnicas de operaciones y explicabilidad disponibles actualmente para generar explicaciones para las predicciones de los modelos de PNL, a fin de que sirvan como un recurso para los desarrolladores de modelos en la comunidad. Finalmente, señalamos las brechas actuales y alentamos las direcciones para el trabajo futuro en esta importante área de investigación.', 'pt': 'Nos últimos anos, houve avanços importantes na qualidade dos modelos de última geração, mas isso ocorreu às custas de os modelos se tornarem menos interpretáveis. Esta pesquisa apresenta uma visão geral do estado atual da IA Explicável (XAI), considerada dentro do domínio do Processamento de Linguagem Natural (PLN). Discutimos a principal categorização das explicações, bem como as várias maneiras pelas quais as explicações podem ser alcançadas e visualizadas. Detalhamos as operações e técnicas de explicabilidade atualmente disponíveis para gerar explicações para previsões de modelos de PNL, para servir como um recurso para desenvolvedores de modelos na comunidade. Por fim, apontamos as lacunas atuais e encorajamos direções para trabalhos futuros nesta importante área de pesquisa.', 'ar': 'شهدت السنوات الأخيرة تطورات مهمة في جودة أحدث النماذج ، ولكن هذا جاء على حساب النماذج التي أصبحت أقل قابلية للتفسير. يقدم هذا الاستطلاع نظرة عامة على الحالة الحالية للذكاء الاصطناعي القابل للتفسير (XAI) ، الذي يعتبر ضمن مجال معالجة اللغة الطبيعية (NLP). نناقش التصنيف الرئيسي للتفسيرات ، بالإضافة إلى الطرق المختلفة التي يمكن من خلالها الوصول إلى التفسيرات وتصورها. نقوم بتفصيل تقنيات العمليات والشرح المتاحة حاليًا لتوليد تفسيرات لتنبؤات نموذج البرمجة اللغوية العصبية ، لتكون بمثابة مصدر لمطوري النماذج في المجتمع. أخيرًا ، نشير إلى الفجوات الحالية ونشجع الاتجاهات للعمل المستقبلي في هذا المجال البحثي المهم.', 'fr': "Ces dernières années, des progrès importants ont été réalisés dans la qualité des modèles de pointe, mais cela s'est fait au détriment de la diminution de l'interprétation des modèles. Cette enquête présente un aperçu de l'état actuel de l'IA explicable (XAI), considérée dans le domaine du traitement du langage naturel (NLP). Nous discutons de la catégorisation principale des explications, ainsi que des différentes manières dont les explications peuvent être obtenues et visualisées. Nous détaillons les opérations et les techniques d'explicabilité actuellement disponibles pour générer des explications pour les prévisions de modèles NLP, afin de servir de ressource aux développeurs de modèles de la communauté. Enfin, nous soulignons les lacunes actuelles et nous encourageons les orientations pour les travaux futurs dans cet important domaine de recherche.", 'zh': '近年以来,最先进的模形的质量取重进展,但是以模形变成不然则可以解释为代价的。 按概述自然语言治(NLP)域内可解AI(XAI)。 论说之大要,及说之可得可视化也。 备言目前可用于生成NLP测说之操可解释性,以为社区开发人员之资。 最后指目前差,并劝为未来指明方向。', 'ja': '近年、最先端モデルの品質は重要な進歩を見せていますが、これはモデルが解釈可能でなくなることを犠牲にしています。この調査では、自然言語処理（ NLP ）の領域内で検討されている説明可能なAI （ XAI ）の現状の概要を紹介します。説明の主な分類と、説明が到達し、可視化される様々な方法について説明します。NLPモデル予測の説明を生成するために現在利用可能な操作と説明可能性テクニックを詳細に説明し、コミュニティのモデル開発者のためのリソースとして機能します。最後に、現在のギャップを指摘し、この重要な研究分野における今後の作業の方向性を奨励します。', 'ru': 'В последние годы наблюдается значительный прогресс в качестве современных моделей, однако это происходит в ущерб тому, что модели становятся менее интерпретируемыми. В этом опросе представлен обзор текущего состояния объяснимого ИИ (XAI), рассматриваемого в области обработки естественного языка (NLP). Мы обсуждаем основную категоризацию объяснений, а также различные способы получения и визуализации объяснений. Мы детализируем операции и методы объяснимости, доступные в настоящее время для создания объяснений для прогнозов модели NLP, чтобы служить ресурсом для разработчиков моделей в сообществе. Наконец, мы отмечаем существующие пробелы и рекомендуем направления будущей работы в этой важной области исследований.', 'hi': 'हाल के वर्षों में अत्याधुनिक मॉडल की गुणवत्ता में महत्वपूर्ण प्रगति देखी गई है, लेकिन यह मॉडल के कम व्याख्या योग्य होने की कीमत पर आया है। यह सर्वेक्षण प्राकृतिक भाषा प्रसंस्करण (एनएलपी) के डोमेन के भीतर माना जाने वाला समझाने योग्य एआई (XAI) की वर्तमान स्थिति का अवलोकन प्रस्तुत करता है। हम स्पष्टीकरण के मुख्य वर्गीकरण पर चर्चा करते हैं, साथ ही साथ विभिन्न तरीकों से स्पष्टीकरण पर पहुंचा जा सकता है और कल्पना की जा सकती है। हम समुदाय में मॉडल डेवलपर्स के लिए एक संसाधन के रूप में सेवा करने के लिए एनएलपी मॉडल भविष्यवाणियों के लिए स्पष्टीकरण उत्पन्न करने के लिए वर्तमान में उपलब्ध संचालन और व्याख्या तकनीकों का विस्तार करते हैं। अंत में, हम वर्तमान अंतराल को इंगित करते हैं और इस महत्वपूर्ण शोध क्षेत्र में भविष्य के काम के लिए दिशाओं को प्रोत्साहित करते हैं।', 'ga': "Le blianta beaga anuas tá dul chun cinn tábhachtach tagtha ar cháilíocht na múnlaí úrscothacha, ach tá sé seo tar éis dul i gcion ar na samhlacha a bheith níos lú inmhínithe. Tugann an suirbhé seo forbhreathnú ar staid reatha AI Inmhínithe (XAI), arna bhreithniú laistigh den réimse Próiseáil Teanga Nádúrtha (NLP). Déanaimid plé ar phríomhchatagóiriú na mínithe, chomh maith leis na bealaí éagsúla inar féidir teacht ar mhínithe agus iad a léirshamhlú. Sonraímid na hoibríochtaí agus na teicníochtaí inmhínithe atá ar fáil faoi láthair chun mínithe a ghiniúint ar thuar samhail NLP, chun fónamh mar acmhainn d'fhorbróirí samhlacha sa phobal. Ar deireadh, dírímid ar na bearnaí atá ann faoi láthair agus spreagaimid treoracha le haghaidh oibre sa todhchaí sa réimse tábhachtach taighde seo.", 'hu': 'Az elmúlt években jelentős előrelépéseket tapasztaltak a korszerű modellek minőségében, de ez a modellek kevésbé értelmezhetővé váltak. Ez a felmérés áttekintést nyújt a Magyarázható AI (XAI) jelenlegi állapotáról, amelyet a Natural Language Processing (NLP) területén vizsgálnak. Beszéljük a magyarázatok fő kategorizálását, valamint a magyarázatok megérkezésének és vizualizálásának különböző módjait. Részletesen részletezzük a jelenleg rendelkezésre álló műveleteket és magyarázhatósági technikákat az NLP modell előrejelzéseinek magyarázataihoz, hogy erőforrásként szolgáljanak a közösség modellfejlesztői számára. Végezetül rámutatunk a jelenlegi hiányosságokra, és ösztönözzük az e fontos kutatási területen végzett jövőbeli munka irányait.', 'ka': 'ახლა წლის შემდეგ მნიშვნელოვანი წარმოდგენა მნიშვნელოვანი წარმოდგენების წარმოდგენებით, მაგრამ ეს მოდელების გამოყენებაში უფრო ცოტაციელია. ამ შემოწმებაში მიმდინარე განსხვავებელი AI (XAI) განსხვავებელი განსხვავებელი განსხვავებელი განსხვავებელი განსხვავებელი განსხვავებელი განსხვავებელი განსხვავებელი დომინის დემო ჩვენ განსხვავებების მნიშვნელოვანი კატეგორიზაციას და განსხვავებების განსხვავებას შეგვიძლია მიიღოთ და ვიზუალურება. ჩვენ ახლა ხელმისაწარმოდგენებული პერაციების და განახსნა ტექნოგიების განახსნა NLP მოდელის წარმოდგენების განახსნა, რომელიც მოდელის განვითარებისთვის რესურსი. საბოლოოდ, ჩვენ აღმოჩნეთ მიმდინარე განსხვავებები და მოდინარებისთვის მომავალეთ სამუშაო სამუშაო სამუშაო განსხვავებაში.', 'el': 'Τα τελευταία χρόνια έχουν σημειώσει σημαντικές προόδους στην ποιότητα των μοντέλων τελευταίας τεχνολογίας, αλλά αυτό έχει συμβεί σε βάρος των μοντέλων να γίνουν λιγότερο ερμηνευτά. Η παρούσα έρευνα παρουσιάζει μια επισκόπηση της τρέχουσας κατάστασης της Εξηγήσιμης Τεχνολογικής Τεχνολογίας (XAI), που εξετάζεται στον τομέα της Επεξεργασίας Φυσικής Γλώσσας (NLP). Συζητούμε την κύρια κατηγοριοποίηση των εξηγήσεων, καθώς και τους διάφορους τρόπους με τους οποίους οι εξηγήσεις μπορούν να βρεθούν και να οπτικοποιηθούν. Αναλυτικά αναλύουμε τις λειτουργίες και τις τεχνικές επεξήγησης που είναι διαθέσιμες σήμερα για τη δημιουργία επεξηγήσεων για τις προβλέψεις μοντέλων ώστε να χρησιμεύσουν ως πόρος για τους προγραμματιστές μοντέλων στην κοινότητα. Τέλος, επισημαίνουμε τα σημερινά κενά και ενθαρρύνουμε κατευθύνσεις για μελλοντικές εργασίες σε αυτόν τον σημαντικό ερευνητικό τομέα.', 'it': "Negli ultimi anni si sono registrati importanti progressi nella qualità dei modelli all'avanguardia, ma ciò è avvenuto a scapito di modelli meno interpretabili. Questo sondaggio presenta una panoramica dello stato attuale dell'IA spiegabile (XAI), considerato all'interno del dominio del Natural Language Processing (NLP). Discutiamo la principale categorizzazione delle spiegazioni, così come i vari modi in cui le spiegazioni possono essere raggiunte e visualizzate. Descriviamo le operazioni e le tecniche di spiegabilità attualmente disponibili per generare spiegazioni per le previsioni dei modelli NLP, per servire come risorsa per gli sviluppatori di modelli nella comunità. Infine, segnaliamo le attuali lacune e incoraggiamo le indicazioni per il futuro lavoro in questo importante settore di ricerca.", 'kk': 'Жуырдағы жылдар күй-жай моделдерінің сапасында маңызды өзгертулерді көрген, бірақ бұл моделдердің маңызды аударып тұрады. Бұл сұхбат Түзіндік тіл процессорының (NLP) доменінде қазіргі түсінікті AI (XAI) күйін көрсетеді. Біз түсініктердің негізгі санаттарын, түсініктердің түсініктері және түсініктердің әртүрлі түсініктерін көрсетуге болады. Қолданыстағы NLP үлгілерінің түсініктемелерін жасау үшін қолданылатын әрекеттерді және түсініктемелер техникаларын егжей- тегжей- тегжей береміз, қоғамдық жасаушыларының ү Соңында, біз осы маңызды зерттеу аумағындағы келесі жұмыс істеудің бағыттарын көрсетеді.', 'mk': 'Во последните години се видени важни напредоци во квалитетот на најновите модели, но ова дојде на трошок на моделите што стануваат помалку интерпретабилни. Овој истражување претставува преглед на сегашната состојба на објаснливата AI (XAI), разгледувана во доменот на природното обработување јазик (NLP). Разговараме за главната категоризација на објаснувањата, како и за различните начини на кои може да се постигнат и визуализираат објаснувањата. Ние ги деталираме операциите и техниките за објаснување кои моментно се достапни за генерирање објаснувања за предвидувањата на моделот на НЛП, за да служат како ресурс за моделните развивачи во заедницата. Конечно, ги истакнуваме сегашните празнини и ги охрабруваме насоките за идната работа во оваа важна истражувачка област.', 'lt': 'Pastaraisiais metais pastebėta svarbių pažangų modernių modelių kokybėje, tačiau tai atsirado dėl to, kad modeliai tampa mažiau aiškinami. Šiame tyrime apžvelgiama dabartinė aiškinamųjų AI (XAI) būklė, nagrinėjama gamtos kalbų apdorojimo (NLP) srityje. Mes aptariame pagrindinį paaiškinimų klasifikavimą, taip pat įvairius paaiškinimų pateikimo ir apžvelgimo būdus. Išsamiai apibūdiname šiuo metu turimas operacijas ir paaiškinimo metodus, kad būtų galima paaiškinti NLP modelių prognozes, kad jie būtų naudojami kaip modelių kūrėjų ištekliai bendruomenėje. Finally, we point out the current gaps and encourage directions for future work in this important research area.', 'ms': 'Tahun-tahun terakhir telah melihat kemajuan penting dalam kualiti model-state-of-the-art, tetapi ini telah datang pada biaya model menjadi kurang boleh diterangkan. Survey ini memperlihatkan paparan ringkasan keadaan semasa AI yang boleh dijelaskan (XAI), dianggap dalam domain Pemprosesan Bahasa Alami (NLP). Kami membincangkan kategorisasi utama penjelasan, serta cara-cara penjelasan yang berbeza boleh tiba di dan ditampilkan. Kami perincian operasi dan teknik penjelasan yang sekarang tersedia untuk menghasilkan penjelasan untuk ramalan model NLP, untuk berkhidmat sebagai sumber untuk pembangun model di komuniti. Akhirnya, kita tunjukkan kekurangan semasa dan mendorong arah kerja masa depan di kawasan kajian penting ini.', 'mt': 'Dawn l-aħħar snin raw avvanzi importanti fil-kwalità tal-mudelli l-aktar avvanzati, iżda dan sar bi spiża li l-mudelli jsiru inqas interpretabbli. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP).  Aħna niddiskutu l-kategorizzazzjoni ewlenija tal-ispjegazzjonijiet, kif ukoll id-diversi modi kif jistgħu jinkisbu u jiġu viżwalizzati l-ispjegazzjonijiet. Aħna niddettaljaw l-operazzjonijiet u t-tekniki ta’ spjegabbiltà disponibbli bħalissa għall-ġenerazzjoni ta’ spjegazzjonijiet għat-tbassir tal-mudelli NLP, biex iservu bħala riżorsa għall-iżviluppaturi tal-mudelli fil-komunità. Finally, we point out the current gaps and encourage directions for future work in this important research area.', 'ml': 'അടുത്ത വര്\u200dഷങ്ങള്\u200d രാജ്യത്തിന്റെ മാതൃകയുടെ ഗുരുതരമായ മുന്\u200dഗണങ്ങള്\u200d കണ്ടിരിക്കുന്നു. പക്ഷെ ഇത് മോഡലുകളുടെ വില കുറച്ച് വ്യാ ഈ അന്വേഷണം ഇപ്പോഴത്തെ സ്വാഭാവ ഭാഷ പ്രക്രിയയുടെ (NLP) ഡൊമെയിനില്\u200d വിശദീകരിക്കുന്ന സ്ഥിതിയുടെ (XAI) നിലവിലുള്ള സ്ഥാ വിശദീകരണങ്ങളുടെ പ്രധാന വിഭാഗങ്ങളെക്കുറിച്ചും വ്യക്തമായ വിശദീകരണങ്ങളെക്കുറിച്ചും ഞങ്ങള്\u200d സംസാരിക്കുന്നു. നിലവിലുള്ള പ്രവര്\u200dത്തനങ്ങളും വിശദീകരിക്കുന്ന സാങ്കേതികവിദ്യകളും നമ്മള്\u200d വിശദീകരിക്കുന്നു. NLP മോഡല്\u200d പ്രവചനങ്ങള്\u200dക്ക് വിശദീകരിക അവസാനം, ഈ പ്രധാനപ്പെട്ട പഠനത്തിന്റെ ഭാവിയിലെ ജോലിക്കുള്ള നേര്\u200dവഴികളില്\u200d നാം ഇപ്പോഴത്തെ തമ്മില്\u200d കാ', 'mn': 'Сүүлийн жилүүд улсын урлагийн загварын чанарын чухал хөгжлийг харсан. Гэхдээ энэ загварын үнэ цэнэтэй болсон. Энэ судалгаа нь Байгалийн хэл Процессорын (NLP) дотор ойлгомжтой тодорхойлдог AI (XAI) орчин үеийн тухай ойлголтыг харуулдаг. Бид тодорхойлолтын гол хэлбэрээр ярилцаж, тайлбарлалтын олон талаар ярилцдаг. Одоо бид NLP загварын тодорхойлолтыг гаргаж, нийгмийн хөгжүүлэгчдийн загварын хөгжүүлэгчдийн боловсруулах боломжтой үйл ажиллагааны болон тайлбарлах боломжтой техникуудыг нарийвчлан тайлбарла Эцэст нь бид одоогийн ялгааг тайлбарлаж ирээдүйн ажиллагааны замайг энэ чухал судалгааны талаар дэмжиж байна.', 'no': 'Siste år har sett viktige framgangar i kvaliteten av kunstmodeller, men dette har kommet på utvidinga av modeller som blir mindre tolkbare. Denne undersøkinga viser ei oversikt over gjeldande tilstanden til utforskar AI (XAI), som er betre i domenet for naturspråk-handsaming (NLP). Vi diskuterer hovudkategoriseringa av forklaringar, og forskjellige måtar forklaringar kan komme til og visualiserast. Vi detaljerer operasjonane og forklaringsteknikane som er tilgjengelege for å laga forklaringar for NLP-modelleforegåver, for å tjera som ressurs for modelleutviklarar i samfunnet. I slutt viser vi gjeldande mellomrom og oppfordrer retningar for framtidige arbeid i denne viktige forskningsområdet.', 'ro': 'În ultimii ani s-au înregistrat progrese importante în ceea ce privește calitatea modelelor de ultimă generație, dar acest lucru a avut loc în detrimentul modelelor care devin mai puțin interpretabile. Acest studiu prezintă o prezentare generală a stării actuale a IA explicabilă (XAI), luată în considerare în domeniul Natural Language Processing (PNL). Discutăm principala categorizare a explicațiilor, precum și diferitele modalități în care explicațiile pot fi ajunse și vizualizate. Detalizăm operațiunile și tehnicile de explicabilitate disponibile în prezent pentru generarea explicațiilor pentru predicțiile modelului PNL, pentru a servi ca resursă pentru dezvoltatorii de modele din comunitate. În cele din urmă, subliniem lacunele actuale și încurajăm direcții pentru activitatea viitoare în acest domeniu important de cercetare.', 'pl': 'W ostatnich latach odnotowano istotne postępy w jakości najnowocześniejszych modeli, jednak kosztem tego, że modele stają się mniej interpretowalne. Niniejsze badanie przedstawia przegląd aktualnego stanu wyjaśniającej sztucznej inteligencji (XAI), rozważanej w dziedzinie przetwarzania języka naturalnego (NLP). Omówimy główną kategoryzację wyjaśnień, a także różne sposoby uzyskania i wizualizacji wyjaśnień. Szczegółowo opisujemy operacje i techniki wyjaśnialności dostępne obecnie do generowania wyjaśnień dla prognoz modeli NLP, aby służyć jako zasób dla deweloperów modeli w społeczności. Na koniec wskazujemy obecne luki i zachęcamy do dalszych prac w tym ważnym obszarze badań.', 'sr': 'Poslednje godine su videli važan napredak u kvaliteti modela države umjetnosti, ali to je došlo na troškove modela koji postaju manje interpretabilni. Ova istraživanja predstavlja pregled trenutnog stanja objašnjivog AI (XAI), koji se razmatra u domenu procesa prirodnog jezika (NLP). Razgovaramo o glavnoj kategoriji objašnjenja, kao i različitim naèinima na koji se mogu približiti i vizualizirati objašnjenja. Detaljno objašnjavamo tehnike operacije i objašnjavanja koje trenutno dostupne za stvaranje objašnjenja za predviđanje NLP model a, da služimo kao resurs za modele razvijača u zajednici. Konačno, pokazujemo trenutne praznine i ohrabrujemo upute za budući rad u ovom važnom istraživačkom području.', 'si': 'අන්තිම අවුරුද්දු දැක්කා වැදගත් විශේෂ ප්\u200dරමාණයක් විශේෂයේ විශේෂය, ඒත් මේක ප්\u200dරමාණයේ විශේෂ විශේෂය අඩු ව මේ පරීක්ෂණය ප්\u200dරවේශනය කරන්න පුළුවන් AI (XAI) ගැන ප්\u200dරවේශනය සඳහා ප්\u200dරාකෘතික භාෂාව පරීක්ෂණය (NLP) වලින් ප්\u200dරව අපි ප්\u200dරශ්නයක් ගැන ප්\u200dරධාන වර්ගයක් කතා කරනවා, වර්ගයක් වර්ගයක් වගේම ප්\u200dරශ්නයක් ලැබෙන්න පුළුවන් වි අපි පරීක්ෂණය සහ විස්තර කරන්න පුළුවන් පරීක්ෂණය සඳහා අවස්ථාවක් ප්\u200dරවේශනය සඳහා NLP මොඩේල් ප්\u200dරවේශනය සඳහා ප්\u200dරවේශන අන්තිමට, අපි දැන් ප්\u200dරතිච්චිත වැඩක් පෙන්වනවා සහ අනාගතයේ වැඩක් වෙනුවෙන් මේ වැදගත් පරීක්ෂණ ප', 'so': "Sannadihii la soo dhowaaday waxay arkeen horumarinta muhiimka ah oo ku saabsan noocyada farshaxanka, laakiin taasi waxay ku dhacday kharashka modelalka oo ay turjumi karto. Baaritaanku wuxuu soo bandhigaa xaaladda joogta ah ee AA (XAI), oo lagu fiiriyey gudaha gaaritaanka afka asalka ah (NLP). Waxaannu kala sheekeynaynaa qeybta ugu horeeya fasirada, sidoo kale waxaa la soo bandhigi karaa turjubaan kala duduwan. Waxaynu u qornaynaa qalabka waxqabadka iyo habka faa'iidada ah ee haatan la isticmaalayo, si loo sameeyo wax u caddeyn tusaale-beddelyada NLP, in loo adeego sida resource u noqdo dadka sameynta modellka. Ugu dambaysta, waxaynu tusaynaa burburka joogta ah, waxaynu ku dhiirranaynaa hagitaan shaqada mustaqbalka ah ee arimahan baaritaanka muhiimka ah.", 'sv': 'De senaste åren har det skett betydande framsteg när det gäller kvaliteten på de senaste modellerna, men detta har skett på bekostnad av att modellerna blir mindre tolkningsbara. Denna undersökning presenterar en översikt över det aktuella tillståndet för förklarad AI (XAI), som betraktas inom området Natural Language Processing (NLP). Vi diskuterar huvudkategoriseringen av förklaringar, samt de olika sätt förklaringar kan komma fram till och visualiseras. Vi beskriver de operationer och förklaringstekniker som för närvarande finns tillgängliga för att generera förklaringar till NLP-modellprognoser, för att fungera som en resurs för modellutvecklare i samhället. Slutligen pekar vi på de nuvarande luckorna och uppmuntrar riktlinjer för framtida arbete inom detta viktiga forskningsområde.', 'ta': 'அண்மைய ஆண்டுகள் முக்கியமான முன்னேற்றங்களை பார்த்துள்ளார்கள், ஆனால் இது மாதிரிகளின் செலவில் குறைந்து விளக்கமாக வரும். இந்த பரிசோதனை தற்போதைய விளக்கக்கூடிய AI (XAI) நிலையை காட்டுகிறது, இயல்பான மொழி செயல்பாட்டின் களத்தில் பார்க்கப்பட்டது. நாம் விளக்கங்களின் முக்கிய வகுப்பை விவாதம் செய்கிறோம், மற்றும் பல விளக்கங்கள் வந்து பார்க்க முடியும். நாம் இப்போது செயல்பாடுகளை விளக்குகிறோம் மற்றும் விளக்கமுடியாத த தொழில்நுட்பங்களை NLP மாதிரி முன்வாக்கியங்களை உருவாக்குவதற இறுதியில், நாம் தற்போதைய இடைவெளியை குறிப்பிடுகிறோம் மற்றும் இந்த முக்கிய ஆய்வு பகுதியில் எதிர்க', 'ur': 'اگلوں سالوں نے اہم پیشرفت کو نظر آئی ہے، لیکن یہ مدل کے خرچ میں کم تعبیر کرنے والا ہو گیا ہے. This survey presents an overview of the current state of Explainable AI (XAI), considered in the domain of Natural Language Processing (NLP). ہم توضیح کی اصلی قسم کی بحث کرتے ہیں، اور مختلف طریقے کی توضیح پہنچ سکتے ہیں اور بحث کر سکتے ہیں. ہم عملیات اور توضیح فناکیلوں کو مفصل کر رہے ہیں جن میں NLP موڈل پیش بینی کے لئے مفصل پیدا کرنے کے لئے موجود ڈولونٹر کے لئے موڈل کے لئے استعمال کریں۔ بالآخر، ہم نے اس اہم تحقیق منطقه میں موجود فاصلے کو دکھایا اور مستقبل کام کے لئے مستقبل طریقے کی تشویق دیں.', 'uz': "Yaqinda yillar davlat modeli sifatida muhim darajalarni ko'rsatadi, lekin bu modellarning qiymatida qisqa tarjima bo'ladi. Name Biz faqatlarning asosiy kategori turlarini bilamiz, va har xil tafsilotlar keladigan va ko'rsatish mumkin. Biz hozir mavjud amallar va foydalanuvchilarni NLP model oldini yaratish uchun faqatlarni bajaramiz, jamiyatning model tuzuvchilari uchun manbalar sifatida ishlatamiz. Endi biz joriy gap bilan tushunamiz va kelajakdagi qidirish maydonda ishni ishlashga yordam beramiz.", 'vi': 'Những năm gần đây đã có những tiến bộ quan trọng trong chất lượng của những mô hình hiện đại, nhưng nó đến với cái giá của việc biến các mô hình trở nên khó hiểu hơn. Cuộc khảo sát này cung cấp một thông tin tổng quát về tình trạng của AI Giải thích (biểu dương) được cân nhắc trong lĩnh vực Bản Quản lý Ngôn ngữ tự nhiên (NLP). Chúng tôi thảo luận về loại giải thích chính, cũng như các cách giải thích khác nhau có thể đến và hình dung ra. Chúng tôi mô tả các hoạt động và kỹ thuật giải thích về khả năng cung cấp giải thích cho dự đoán kiểu mẫu của Njala, để phục vụ như một nguồn tài nguyên cho những nhà phát triển mô hình trong cộng đồng. Cuối cùng, chúng ta sẽ chỉ ra những khoảng trống hiện tại và thúc đẩy hướng dẫn cho công việc tương lai trong khu nghiên cứu quan trọng này.', 'hr': 'Posljednje godine su vidjeli važan napredak u kvaliteti modela države umjetnosti, ali to je došlo na troškove modela koji su postali manje interpretabilni. Ovo istraživanje predstavlja pregled trenutnog stanja razumljivog AI (XAI), koji se razmatra u domenu procesa prirodnog jezika (NLP). Razgovarali smo o glavnoj kategoriji objašnjenja, kao i različitim načinama na koji se može doći i vizualizirati objašnjenja. Mi detaljno objašnjavamo tehnike operacije i objašnjavanja koje su trenutno dostupne za stvaranje objašnjenja za predviđanje model a NLP-a, kako bi služili kao resurs za razvijače modela u zajednici. Konačno ukazujemo na trenutne praznine i poticamo upute za budući rad u ovom važnom istraživačkom području.', 'nl': 'De laatste jaren zijn belangrijke vooruitgang geboekt in de kwaliteit van state-of-the-art modellen, maar dit gaat ten koste van de minder interpreteerbare modellen. Deze enquête geeft een overzicht van de huidige stand van Uitleg AI (XAI), gezien binnen het domein van Natural Language Processing (NLP). We bespreken de belangrijkste categorisering van verklaringen, evenals de verschillende manieren waarop verklaringen kunnen worden verkregen en gevisualiseerd. We beschrijven de bewerkingen en uitlegbaarheidstechnieken die momenteel beschikbaar zijn voor het genereren van verklaringen voor NLP-modellvoorspellingen, om te dienen als een bron voor modelontwikkelaars in de gemeenschap. Tot slot wijzen we op de huidige lacunes en moedigen we richting aan voor toekomstige werkzaamheden op dit belangrijke onderzoeksgebied.', 'da': 'De seneste år har der været betydelige fremskridt i kvaliteten af de nyeste modeller, men dette er sket på bekostning af, at modellerne bliver mindre fortolkende. Denne undersøgelse præsenterer et overblik over den aktuelle tilstand for forklarelig AI (XAI), betragtet inden for domænet Natural Language Processing (NLP). Vi diskuterer hovedkategoriseringen af forklaringer, samt de forskellige måder, forklaringer kan komme frem til og visualiseres på. Vi detaljerer de operationer og forklaringsteknikker, der i øjeblikket er tilgængelige for at generere forklaringer til NLP-modelforudsigelser, for at tjene som en ressource for modeludviklere i fællesskabet. Endelig påpeger vi de nuværende huller og fremmer retningslinjer for det fremtidige arbejde på dette vigtige forskningsområde.', 'de': 'In den letzten Jahren wurden wichtige Fortschritte bei der Qualität modernster Modelle erzielt, was jedoch zu Lasten der weniger interpretierbaren Modelle ging. Die vorliegende Umfrage gibt einen Überblick über den aktuellen Stand der Erklärbaren KI (XAI) im Bereich der Natural Language Processing (NLP). Wir diskutieren die Hauptkategorisierung von Erklärungen sowie die verschiedenen Möglichkeiten, Erklärungen zu finden und visualisiert werden können. Wir beschreiben die Operationen und Erklärungstechniken, die derzeit verfügbar sind, um Erklärungen für NLP-Modellvorhersagen zu generieren, um als Ressource für Modellentwickler in der Community zu dienen. Abschließend weisen wir auf die aktuellen Lücken hin und geben Anregungen für künftige Arbeiten in diesem wichtigen Forschungsgebiet.', 'bg': 'През последните години се наблюдава важен напредък в качеството на най-съвременните модели, но това е за сметка на моделите, които стават по-малко тълкуваеми. Това проучване представя преглед на текущото състояние на обяснимия изкуствен интелект, разглеждан в областта на обработката на естествения език (НЛП). Обсъждаме основната категоризация на обясненията, както и различните начини, по които обясненията могат да бъдат достигнати и визуализирани. Ние подробно описваме операциите и техниките за обяснимост, които понастоящем са налични за генериране на обяснения за прогнозите на моделите, които служат като ресурс за разработчиците на модели в общността. Накрая, посочваме настоящите пропуски и насърчаваме насоките за бъдеща работа в тази важна научноизследователска област.', 'id': 'Tahun-tahun terakhir telah melihat kemajuan penting dalam kualitas model-state-of-the-art, tetapi hal ini telah datang pada biaya model menjadi kurang terinterpretasi. Survei ini memperlihatkan panjang keadaan saat ini AI yang dapat dijelaskan (XAI), dianggap dalam domain Proses Bahasa Alami (NLP). Kami mendiskusikan kategorisasi utama penjelasan, serta berbagai cara penjelasan dapat tiba di dan ditampilkan. Kami mendetail operasi dan teknik penjelasan yang sekarang tersedia untuk menghasilkan penjelasan untuk prediksi model NLP, untuk melayani sebagai sumber daya untuk pengembang model di komunitas. Akhirnya, kami menunjukkan kekurangan saat ini dan mendorong arah kerja di masa depan di daerah penelitian penting ini.', 'ko': '최근 몇 년 동안 가장 선진적인 모델의 질은 중대한 발전을 이루었지만 이것은 모델이 해석하기 어려워진 대가이다.이 조사는 인공지능(XAI)의 자연언어처리(NLP) 분야 현황을 설명한다.우리는 해석의 주요 분류와 해석의 각종 실현과 가시화 방식을 토론했다.우리는 현재 NLP 모델의 예측 해석을 생성하는 데 사용할 수 있는 조작과 해석 가능한 기술을 상세하게 소개하여 지역사회에서 모델 개발자의 자원으로 삼았다.마지막으로 우리는 현재의 격차를 지적하고 이 중요한 연구 분야의 미래 업무 방향을 격려했다.', 'tr': 'Ýakyndaky ýyllar möhüm ösümlikleri möhüm ukyplaryň ybaratynda görýärler, ýöne bu nusgalaryň buýrukynda ýakyn bir terjime edilýändir. Bu araşdyrma, dogal dil işleýän (NLP) domaýynda düşünülen Häzirki Araşdyrylmaz AI (XAI) durumynyň (gaýd edilen ýagdaýynyň halyny) görkezýär. Biz esasy taýýarlaryň esasy kategoriýasyny we düşündirişimiz ýaly-da düşündirişim başarmaýar we görselleştirilebilir. NLP nusgasy üçin düşündirilmek üçin häzirki wagtda mejbur operasiýalary we düşündirilmek teknikelerini soňlaşdyrýarys, toplumyň nusgasy ösütçilikleriniň nusgasy diýmek üçin häzirki ýerleşdirilmek üçin häzirki teknik Soňunda, häzirki boşluklary we gelejekki işi üçin bu wajyp ylmy meýdançasynda tassyklaýarys.', 'fa': 'سالهای اخیر پیشرفت های مهم در کیفیت مدل های هنر دیده اند، اما این به هزینه های مدل کمتر تفسیر قابل تفسیر شده است. این تحقیقات پیش\u200cبینی از وضعیت فعلی AI Explainable (XAI) که در حوزه\u200cهای پرداخت زبان طبیعی (NLP) توضیح داده می\u200cشود. ما در مورد گروهی اصلی توضیح\u200cها صحبت می\u200cکنیم، و همچنین روش\u200cهای مختلف توضیح\u200cها می\u200cتوانند به رسیدن و تصویر دهند. ما فناوری های عملیات و توضیح قابلیت در حال حاضر برای ایجاد توضیح برای پیش بینی های مدل NLP را توضیح می دهیم تا به عنوان یک منبع برای توسعه کنندگان مدل در جامعه خدمت کنیم. بالاخره، ما فاصله\u200cهای فعلی را نشان می\u200cدهیم و مسیر\u200cهایی را برای کار آینده در این منطقه تحقیقات مهم تشویق می\u200cدهیم.', 'af': "Onlangse jaar het belangrike vorderings gesien in die kwaliteit van state-of-the-art modele, maar dit het gekom op die koste van modele wat minder vertaling word. Hierdie ondersoek stel 'n oorskou van die huidige staat van Verduidelike AI (XAI), aangesien binne die domein van Natuurlike Taal Verwerking (NLP). Ons bespreek die hooftkategoriseering van uitduidelings, asook die verskeie maniere uitduidelings kan aankom en visualiseer word. Ons detaljeer die operasies en verduidelikheidteknologies wat huidiglik beskikbaar is om uitduidelings vir NLP model voorskoue te genereer, om as 'n hulpbron te dien vir model ontwikkelaars in die gemeenskap. Eindelik, ons wys die huidige gaps en bevestig rigtings vir toekomstige werk in hierdie belangrike ondersoek area.", 'sw': 'Miaka ya hivi karibuni imeshuhudia maendeleo muhimu katika kiwango cha mifano ya sanaa, lakini hii imekuja kwa gharama ya mifano inayokuwa na tafsiri isiyo na ufafanuzi. Utafiti huu unaonyesha mtazamo wa hali ya sasa ya UKI (XAI) inayoelezea, uliofanywa ndani ya mchakato wa lugha ya asili (NLP). Tunajadili makundi makuu ya ufafanuzi, pamoja na namna mbalimbali za maelezo yanaweza kufikia na kuonyesha. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community.  Mwisho, tunaonyesha mapambano ya sasa na kuhamasisha maelekezo ya kazi za baadaye katika eneo hili muhimu la utafiti.', 'sq': 'Vitet e fundit kanë parë përparime të rëndësishme në cilësinë e modeleve më të larta, por kjo ka ardhur në dëm të modeleve që bëhen më pak të interpretueshëm. Ky sondazh paraqet një përmbledhje të gjendjes së tanishme të AI të shpjeguar (XAI), konsideruar brenda fushës së Procesimit të Gjuhave Natyrore (NLP). Ne diskutojmë kategorizimin kryesor të shpjegimeve si dhe mënyrat e ndryshme të shpjegimeve mund të arrihen dhe të vizualizohen. Ne detalizojmë operacionet dhe teknikat e shpjegimisë aktualisht në dispozicion për gjenerimin e shpjegimeve për parashikimet e modelit NLP, për të shërbyer si një burim për zhvilluesit e modeleve në komunitet. Finally, we point out the current gaps and encourage directions for future work in this important research area.', 'am': 'የቀድሞው ዓመታት የሀገር አካባቢ-አርእስት ዓይነት ብዛት የሚያስፈልገውን ጠቃሚ ቅድሚያ አይተዋል፤ ግን ይህ በሞዴል ዋጋ ትንሽ የሚተረጉም ሆኖአል፡፡ ይህ ምርጫው የአሁኑን ሁኔታ አካል (XAI) በሚያስተካክለው የአፍሪካዊ ቋንቋ ፕሮጀክት (NLP) ውስጥ የተመሳሳይ ነው፡፡ ትርጉም መሆኑን የዋነኛው ክፍል እናሳውቃለን፣ እናም ልዩ ልዩ ልዩ ልዩ ልዩን ሊደርስና እንዲያረጋግጥ እናውቃለን፡፡ በኮምፒዩተር አካባቢዎች የሞዴል አካባቢዎች መሆኑን ለማፍጠር የሚችሉትን እናስታውቃለን፡፡ በመጨረሻም፣ የአሁኑን ደረጃ እናሳየዋለን እና በዚህ አስቸጋሪ ትምህርት ክልል ውስጥ ለመሥራት የመግለጫ መንገድ እናሳብቃለን፡፡', 'hy': 'Վերջին տարիների ընթացքում կարևոր առաջընթաց է կատարվել նորագույն մոդելների որակի մեջ, բայց սա եկավ մոդելների ավելի քիչ մեկնաբանելի ծախսերի վրա: Այս հետազոտությունը ներկայացնում է ԱԲ (XAI) ներկայիս վիճակի ընկալումը, որը համարվում է Բնական լեզվի վերլուծության ոլորտում: Մենք քննարկում ենք բացատրությունների հիմնական խմբագրությունը, ինչպես նաև բացատրությունների տարբեր ձևերը, որոնց վրա կարող ենք հասնել և տեսնել: Մենք մանրամասնում ենք գործողությունները և բացատրելիության տեխնիկաները, որոնք ներկայումս հասանելի են ՆԼՊ մոդելի կանխատեսումների բացատրություններ ստեղծելու համար, որպեսզի օգտագործենք որպես ռեսուրս համայնքի մոդել զարգացողների համար: Վերջապես, մենք նշում ենք ներկայիս բացառությունները և խրախուսում ենք ապագա աշխատանքի ուղղություններ այս կարևոր ուսումնասիրության ոլորտում:', 'bn': 'সাম্প্রতিক বছরগুলো রাষ্ট্র-শিল্পের মডেলের মানে গুরুত্বপূর্ণ উন্নয়ন দেখেছে, কিন্তু মডেলের খরচ কম ব্যাখ্যা হচ্ছে। এই জরিপের বর্তমান অবস্থার ব্যাখ্যা ব্যাখ্যা AI (XAI), প্রাকৃতিক ভাষা প্রক্রিয়ার (NLP) ডোমেইনে বিবেচনা করা হয়েছে। আমরা ব্যাখ্যার প্রধান বিভাগ নিয়ে আলোচনা করি, আর বিভিন্ন ভাবে ব্যাখ্যা পৌঁছাতে পারে এবং দেখতে পারি। আমরা বর্তমানে এনএলপি মডেলের ভবিষ্যতের জন্য ব্যাখ্যা তৈরি করার জন্য অপারেশন এবং ব্যাখ্যা প্রযুক্তি ব্যাখ্যা করি সম্প্রদায়ের মডেল ডে শেষ পর্যন্ত আমরা বর্তমান বিভ্রান্ত বিভ্রান্তির কথা উল্লেখ করি এবং ভবিষ্যতের এই গুরুত্বপূর্ণ গবেষণা এলাকা', 'az': 'Son illərdə möhüm tədbir modellərin keyfiyyətində görünür, amma bu modellərin xərclənməsinə düşür. Bu araştırma təbiətli Dil İşləməsi (NLP) domeinində düşünülən Açıqlanabilir AI (XAI) halındakı halda bir nəzər göstərir. Biz təfsilatların ən böyük kategoriyasını, müxtəlif təfsilatların gəlməsi və vizualizasyonu ilə mübahisə edirik. Biz NLP modeli tədbirlərini yaratmaq üçün hazırda mümkün olan işləri və a çıq-aydınlıq tekniklərini ətraflı izah edirik, toplumda modeli tədbirləçilər üçün istifadə etmək üçün. Sonunda, bu möhüm araştırma bölgesində gələcək işin yollarını göstəririk.', 'ca': "Els últims anys han vist avanços importants en la qualitat dels models d'última generació, però això ha arribat a costa que els models es tornin menys interpretables. Aquesta encuesta presenta un panorama general de l'estat actual de l'AI explicable (XAI), considerada en el domini del processament de llenguatges naturals (NLP). Discutem sobre la categorització principal de les explicacions, i sobre les diverses maneres en què es poden arribar a explicacions i visualitzar-se. Detallem les tècniques operatives i d'explicabilitat actualment disponibles per generar explicacions per a les prediccions del model NLP, per servir com a recurso per als desenvolupadors de models de la comunitat. Finalment, recordem les diferències actuals i encorajem direccions per a la feina futura en aquesta àrea important de recerca.", 'cs': 'V posledních letech došlo k významnému pokroku v kvalitě nejmodernějších modelů, což však přišlo na úkor toho, že se modely stávají méně interpretovatelnými. Tento průzkum představuje přehled současného stavu vysvětlitelné AI (XAI), který je zohledněn v oblasti zpracování přirozeného jazyka (NLP). Diskutujeme hlavní kategorizaci vysvětlení, stejně jako různé způsoby, jakými lze vysvětlení dosáhnout a vizualizovat. Podrobně popisujeme operace a techniky vysvětlitelnosti, které jsou v současné době k dispozici pro generování vysvětlení pro předpovědi NLP modelů, které slouží jako zdroj pro vývojáře modelů v komunitě. Nakonec upozorňujeme na současné mezery a podporujeme směry pro budoucí práci v této důležité oblasti výzkumu.', 'fi': 'Viime vuosina huippumallien laadussa on edistytty merkittävästi, mutta tämä on tapahtunut mallien tulkinnan heikkenemisen kustannuksella. Tämä kysely esittelee yleiskatsauksen selittävän tekoälyn (XAI) nykytilasta, jota tarkastellaan luonnollisen kielen prosessoinnin (NLP) alalla. Keskustelemme selitysten pääkategorisoinnista sekä siitä, miten selitykset voidaan saavuttaa ja visualisoida. Esittelemme yksityiskohtaisesti käytössä olevat toiminnot ja selitettävyystekniikat NLP-malliennusteiden selittämiseen, jotta ne toimisivat resurssina yhteisön mallikehittäjille. Lopuksi korostamme nykyisiä puutteita ja kannustamme suuntaamaan tulevaa työtä tällä tärkeällä tutkimusalueella.', 'bs': 'Posljednje godine su vidjeli važan napredak u kvaliteti modela države umjetnosti, ali to je došlo na troškove modela koji postaju manje interpretabilni. Ovo istraživanje predstavlja pregled trenutnog stanja objašnjivog AI (XAI), koji se razmatra u domenu procesa prirodnog jezika (NLP). Razgovaramo o glavnoj kategoriji objašnjenja, kao i o različitim načinama na koji se može doći i vizualizirati objašnjenja. Mi detaljno objašnjavamo tehnike operacije i objašnjavanja koje trenutno dostupne za stvaranje objašnjenja za predviđanje NLP model a, da služimo kao resurs za modele razvijača u zajednici. Konačno, pokazujemo trenutne praznine i ohrabrujemo upute za budući rad u ovom važnom istraživačkom području.', 'et': 'Viimastel aastatel on kaasaegsete mudelite kvaliteet oluliselt arenenud, kuid see on toimunud mudelite arvelt, mis on muutunud vähem tõlgendatavaks. Käesolev uuring annab ülevaate looduskeele töötlemise valdkonnas kaalutud seletatava tehisintellekti (XAI) hetkeseisust. Arutleme selgituste peamist kategooriat ning erinevaid võimalusi selgitusteni jõuda ja visualiseerida. Üksikasjalikult kirjeldame operatsioone ja selgitatavuse tehnikaid, mis on praegu kättesaadavad NLP mudelite prognooside selgitamiseks, et olla ressurss kogukonna mudelite arendajatele. Lõpetuseks juhime tähelepanu praegustele lünkadele ja julgustame suuniseid edasiseks tööks selles olulises uurimisvaldkonnas.', 'jv': 'Rasané sing klompok tau ngomong nik kuwi nggolok dianggap banjur kuwi model sing larang, karo hal-hal kuwi dianggap kuwi tindakan model sing bisa pasang manut. Aplikasi iki ngewehhita karo hal-hal sing gawe perusahaan AI (XAI), kang dipune sak tanggal ning Daftar Manus (NLP). Awak dhéwé pisan karo kategori sing nyealaman aparané, lan kabèh basa luwih panelusuran iso dianggawe lan ijol-ijolan. Awak dhéwé ngerti perusahaan lan tambah-teknik kapan anyar nggawé kanggo ngilanggar kapan kanggo ngerasahan model NLP Lha wih-wih, kita mudhaya tanggal gak lan bodhakan perusahaan kanggo nggawe barang langkung iki luwih basa sing dikarepaké.', 'sk': 'V zadnjih letih je prišlo do pomembnega napredka v kakovosti najsodobnejših modelov, vendar je to prišlo na račun, da so modeli postali manj razložljivi. Ta raziskava predstavlja pregled trenutnega stanja pojasnljive umetne inteligence (XAI), ki se upošteva na področju obdelave naravnega jezika (NLP). Razpravljamo o glavni kategorizaciji razlag ter različnih načinih, na katere je mogoče priti do razlag in jih vizualizirati. Podrobno opisujemo operacije in tehnike pojasnljivosti, ki so trenutno na voljo za ustvarjanje pojasnil za napovedi modela NLP, ki služijo kot vir za razvijalce modelov v skupnosti. Nazadnje opozarjamo na sedanje vrzeli in spodbujamo usmeritve za prihodnje delo na tem pomembnem raziskovalnem področju.', 'ha': "Yẽkaru da suka sami mafariko masu muhimu cikin tsarin-halin-mai-sanawa, kuma amma, wannan ya zo a kan matuƙar misalin misãlai sun kasance bã da fassarawa ba. Wannan shirin ya bãyar da wani surfati na halin da ke kai yanzu na Explaiable AI (XAI), wanda aka yi bincike a cikin tafiyar da aiki na Lugha na Natural (NLP). Munã jãyayya masu muhimmin fassarar fassarar da kuma da wasu fassarar dabam-dabam da za'a iya kai zuwa da a gani. Tuna bayyana masu aikin aiki da takwizarin bayani yanzu za'a iya samar da fassarai wa misãlai na NLP, dõmin ya yi aiki kamar wata resource wa masu motsi da ke cikin jamii. Gani, Munã nuna gaura masu kai yanzu kuma Muke kwaɗaitar shiryarwa ga aikin ijãra a cikin wannan filin nan muhimmi.", 'he': 'בשנים האחרונות ראו התקדמות חשובות באיכות הדוגמנים המאוחרים, אך זה הגיע על חשבון הדוגמנים הופכים פחות אפשריים לפרש. הסקר הזה מציג את המצב הנוכחי של AI הסביר (XAI), שנחשב בתחום התהליך השפה הטבעית (NLP). אנחנו מדברים על הקטגוריזציה העיקרית של ההסברים, כמו גם על דרכים שונות ההסברים יכולים להגיע ולדמיין. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community.  סוף סוף, אנחנו מצביעים על הפערים הנוכחים ולעודדים כיוונים לעבודה עתידית באזור המחקר החשוב הזה.', 'bo': 'དབུས་གཞུང་གི་ལོ་ངོ་དག་གིས་མཐོང་ནི་རྒྱལ་ཁབ་གལ་འཕར་རིས་མཐོང་བ་ཡིན་ནའང་། འདི་དག་གི་མིག་རྣམས་ཀྱི་སྐྱེས་ཚད་དང་འགྱུར་བའི་ཐབ This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP). ང་ཚོས་རང་གི་དབྱེ་རིམ་དེ་གསལ་བཤད་ཀྱི་རྩ་བའི་དབྱེ་རིམ་དང་། འགྲེལ་བཤད་འདི་དག་འབྲས་ཐུབ་ཀྱི་ཡོད་པ་དང་མཐོང་སྣང་ ང་ཚོས་ད་ལྟ་བུའི་བཀོལ་སྤྱོད་དང་འགྲེལ་བཤད་ནུས་པའི་ལག་ལེན་གྱི་ཐབས་ལམ་གསལ་བཤད་དང་ལག་ལེན་བྱེད་པའི་NLP་རྣམ་གྲངས་སྔོན་ཚུ མཐའ་མར་དུ། འུ་ཚོས་ཀྱིས་ད་ལྟོའི་བར་སྟོང་དང་སྤྱད་ནས་ང་ཚོས་མ་འོངས་ཀྱི་ལས་འཚོལ་ཞིབ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Beyond Fine-tuning : Few-Sample Sentence Embedding Transfer', 'ar': 'ما بعد الضبط الدقيق: نقل تضمين جملة عينة قليلة', 'fr': "Au-delà du peaufinage\xa0: transfert d'intégration de phrases à quelques échantillons", 'es': 'Más allá del ajuste fino: transferencia de incrustación de oraciones de pocas muestras', 'pt': 'Além do ajuste fino: transferência de incorporação de sentenças com poucas amostras', 'ja': '微調整を超えて:サンプル文の埋め込み転送はほとんどありません', 'zh': '越微调:小样本句嵌移', 'ru': 'Beyond Fine-tuning: Перенос Вложения Приговора Немного - Образца', 'hi': 'ठीक ट्यूनिंग से परे: कुछ नमूना वाक्य एम्बेडिंग स्थानांतरण', 'ga': 'Seachas Mionchoigeartú: Aistriú Leabú Pianbhreithe Mionshamplaí', 'ka': 'ძალიან შესაბამის გარეშე: მარტივი მაგალითი სიტყვების გარეშე', 'el': 'Πέρα από την τελειοποίηση: μεταφορά πρότασης ελάχιστων δειγμάτων', 'hu': 'A finomhangoláson túl: néhány minta mondat beágyazása átvitel', 'it': 'Oltre la messa a punto: trasferimento di embedding di frasi a pochi esempi', 'kk': 'Қайталау үшін: сөз ендірілген тасымалдау', 'lt': 'Beyond fine tuning: Few-Sample Sentence Embedding Transfer', 'ms': 'Selain Penyesuaian Terbaik: Pengalihan Penyesuaian Beberapa Sampel', 'mt': 'Lil hinn mill-irfinar: Trasferiment ta’ Sentenza b’Ħafna Kampjuni', 'ml': 'സുന്ദരിയുടെ പുറത്തു്: കുറച്ചു് മാതൃകയുടെ ശിക്ഷ എംബെഡിങ് മാറ്റുന്നതിനു്', 'mk': 'Покрај финетизирањето: Пренесување на неколку реченици со примерок', 'mn': 'Шинэ товчлолын гадна: Хэдэн жижиг өгүүлбэрийн товчлол', 'no': 'Utan finnstilling: Få eksempel teikn innebygd overføring', 'ro': 'Dincolo de reglare fină: transfer de sentință cu câteva exemple', 'pl': 'Poza precyzyjnym dostrajaniem: Transfer osadzania kilku przykładów zdań', 'si': 'හොඳ සංවිධානය පිටිපස්සේ: සංවිධානය ටිකක් සංවිධානය සංවිධානය', 'sr': 'Izvan dobre naprave: prijenos sa malo uzoraka', 'so': 'Hore-horumarinta: Few-Sample Sentence', 'sv': 'Bortom finjustering: överföring av meningar med några exempel', 'ta': 'குறைந்த மாதிரி வாக்கியம் உட்பொதிந்த மாற்றுதல்', 'ur': 'فائن ٹونگ کے علاوہ: کم نمبر سنٹنس ایمبڈینگ ٹرنسفر', 'uz': '@ info: whatsthis', 'vi': 'Vượt xa giao thoa chính thức:', 'da': 'Udover finjustering: Overførsel af sætninger med få prøver', 'nl': 'Meer dan fine-tuning: Transfer met weinig voorbeelden van zinnen', 'hr': 'Iznad dobre naprave: prijenos prijenosnih izraza za manje uzoraka', 'bg': 'Отвъд фината настройка: Прехвърляне на вграждане на няколко примерни изречения', 'de': 'Jenseits der Feinabstimmung: Few-Sample Satze Embedding Transfer', 'fa': 'کنار تنظیمات پاکیزه: تنظیمات جمله\u200cهای کمی', 'tr': 'İlerlemeden fazla: Few-Sample Sözi İçeri Giriş Transferi', 'id': 'Beyond Fine-tuning: Few-Sample Sentence Embedding Transfer', 'sw': 'Beyond Fine-tuning: Few-Sample Sentence Embedding Transfer', 'ko': '미세 조정 제외: 소량의 예시 문장 삽입 이동', 'af': 'Buitend Fine- tuning: Klein- voorbeeld Sense Inbêer Oordrag', 'sq': 'Beyond Fine-tuning: Few-Sample Sentence Embedding Transfer', 'bn': 'সুন্দর টুইনিং এর পাশে: কয়েকটি সামাইল শাস্তি এমবেডিং স্থানান্তর', 'bs': 'Iznad dobre pjesme: prijenos sa malo uzoraka izraza', 'ca': "Més enllà de l'ajustament: Transfer ència d'incorporació de frases amb poques mostres", 'am': 'ምርጫዎች', 'hy': 'Few-օրինակ Sense Embed Transfer', 'az': '캻yi-t톛mizl톛m톛 칬yr톛nm톛sind톛n: Daha az n칲mun톛 S칬z칲 캻칞ind톛 D톛rg톛ndirm톛si', 'et': 'Lisaks peenhäälestusele: mõne näidislause põimimise ülekanne', 'cs': 'Kromě jemného ladění: Přenos vložení několika vzorků věty', 'fi': 'Hienosäädön lisäksi: muutaman esimerkin lauseen upotussiirto', 'he': 'מעבר לתרגיל: מעברת גזרות מעט דוגמאות', 'jv': 'Fine-tuning', 'ha': '@ action', 'sk': 'Poleg finega nastavitve: prenos vključevanja stavkov z nekaj vzorčnimi stavki', 'bo': 'ཕྱིར་ལོག་མཐའ་དབྱེ་སྟངས་མིན་པ། ཆེ་བའི་ཚིག་རྣམ་པ་ནང་དུ་སྤར་སྐྱེལ་འདྲེན་'}
{'en': 'Fine-tuning (FT) pre-trained sentence embedding models on small datasets has been shown to have limitations. In this paper we show that concatenating the embeddings from the pre-trained model with those from a simple sentence embedding model trained only on the target data, can improve over the performance of FT for few-sample tasks. To this end, a linear classifier is trained on the combined embeddings, either by freezing the embedding model weights or training the  classifier  and embedding models end-to-end. We perform evaluation on seven small datasets from NLP tasks and show that our approach with end-to-end training outperforms FT with negligible  computational overhead . Further, we also show that sophisticated combination techniques like  CCA  and  KCCA  do not work as well in practice as  concatenation . We provide  theoretical analysis  to explain this empirical observation.', 'ar': 'تم إثبات وجود قيود على نماذج التوليف الدقيق لتضمين الجملة المدربة مسبقًا على مجموعات البيانات الصغيرة. نوضح في هذه الورقة أن ربط الحفلات من النموذج المدرَّب مسبقًا مع تلك الموجودة في نموذج تضمين جملة بسيط تم تدريبه فقط على البيانات الهدف ، يمكن أن يحسن أداء FT لمهام قليلة العينات. تحقيقا لهذه الغاية ، يتم تدريب المصنف الخطي على حفلات الزفاف المدمجة ، إما عن طريق تجميد أوزان نموذج التضمين أو تدريب المصنف ودمج النماذج من طرف إلى طرف. نقوم بإجراء تقييم على سبع مجموعات بيانات صغيرة من مهام البرمجة اللغوية العصبية (NLP) ونبين أن نهجنا في التدريب الشامل يتفوق على FT مع تكاليف حسابية لا تذكر. علاوة على ذلك ، نظهر أيضًا أن تقنيات الدمج المعقدة مثل CCA و KCCA لا تعمل بشكل جيد في الممارسة مثل التسلسل. نقدم التحليل النظري لشرح هذه الملاحظة التجريبية.', 'pt': 'O ajuste fino (FT) de modelos de incorporação de sentenças pré-treinadas em pequenos conjuntos de dados mostrou ter limitações. Neste artigo mostramos que concatenar os embeddings do modelo pré-treinado com aqueles de um modelo de embedding de sentença simples treinado apenas nos dados de destino pode melhorar o desempenho do FT para tarefas de poucas amostras. Para isso, um classificador linear é treinado nos embeddings combinados, seja congelando os pesos do modelo de embedding ou treinando o classificador e os modelos de embedding de ponta a ponta. Realizamos avaliação em sete pequenos conjuntos de dados de tarefas de PNL e mostramos que nossa abordagem com treinamento de ponta a ponta supera FT com sobrecarga computacional insignificante. Além disso, também mostramos que técnicas de combinação sofisticadas como CCA e KCCA não funcionam tão bem na prática quanto a concatenação. Fornecemos análises teóricas para explicar essa observação empírica.', 'fr': "Il a été démontré que les modèles d'intégration de phrases pré-entraînés de réglage fin (FT) sur de petits ensembles de données présentent des limites. Dans cet article, nous montrons que la concaténation des intégrations du modèle pré-entraîné avec celles d'un modèle d'intégration de phrases simple formé uniquement sur les données cibles peut améliorer les performances de FT pour quelques tâches d'échantillon. À cette fin, un classificateur linéaire est entraîné sur les intégrations combinées, soit en gelant les poids du modèle d'intégration, soit en entraînant le classificateur et les modèles d'intégration de bout en bout. Nous effectuons une évaluation sur sept petits ensembles de données provenant de tâches de PNL et montrons que notre approche de la formation de bout en bout surpasse la FT avec une surcharge de calcul négligeable. De plus, nous montrons également que les techniques de combinaison sophistiquées telles que le CCA et le KCCA ne fonctionnent pas aussi bien dans la pratique que la concaténation. Nous fournissons une analyse théorique pour expliquer cette observation empirique.", 'es': 'Se ha demostrado que el ajuste fino (FT) de los modelos de incrustación de oraciones preentrenados en conjuntos de datos pequeños tiene limitaciones. En este artículo mostramos que la concatenación de las incorporaciones del modelo previamente entrenado con las de un modelo de incrustación de oraciones simple entrenado solo en los datos de destino, puede mejorar el rendimiento de FT para tareas de pocas muestras. Con este fin, se entrena a un clasificador lineal en las incrustaciones combinadas, ya sea congelando los pesos del modelo de incrustación o entrenando el clasificador e incorporando modelos de extremo a extremo. Realizamos evaluaciones en siete pequeños conjuntos de datos de tareas de PNL y demostramos que nuestro enfoque con la capacitación integral supera a FT con una sobrecarga computacional insignificante. Además, también mostramos que técnicas de combinación sofisticadas como CCA y KCCA no funcionan tan bien en la práctica como la concatenación. Proporcionamos análisis teóricos para explicar esta observación empírica.', 'ja': '微調整（ Ｆ Ｔ ）の事前トレーニングされた文埋め込みモデルは、小さなデータセットに制限があることが示されている。本稿では、事前に訓練されたモデルからの埋め込みを、ターゲットデータのみで訓練された単純な文章埋め込みモデルからの埋め込みと連結することで、少数のサンプルタスクに対するFTのパフォーマンスよりも改善できることを示した。このために、線形分類子は、埋め込みモデルの重みを凍結するか、分類子と埋め込みモデルをエンドツーエンドで訓練することによって、組み合わせられた埋め込みについて訓練されます。私たちは、NLPタスクからの7つの小さなデータセットについて評価を行い、エンドツーエンドのトレーニングを使用した私たちのアプローチが、無視できる計算オーバーヘッドでFTを上回ることを示します。さらに、CCAとKCCAのような洗練された組み合わせ技術は、連結ほど実際にはうまく機能しないことも示されています。この実証的な観察を説明するための理論的な分析を提供します。', 'zh': '于小集上微调(FT)预练之句,已验有局限性。 其在本文,则将自预练模形者嵌之,与向数之约句嵌之,可以崇FT于少数样本务之性也。 是以冻结而重或端练其器与其器,合而线性之。 七小NLP集,明端到端训练方法优于FT,计销可忽略不计。 又明CCA、KCCA之术在实践中非联类也。 吾等以理解之。', 'hi': 'छोटे डेटासेट पर फाइन-ट्यूनिंग (एफटी) पूर्व-प्रशिक्षित वाक्य एम्बेडिंग मॉडल को सीमाओं के लिए दिखाया गया है। इस पेपर में हम दिखाते हैं कि केवल लक्ष्य डेटा पर प्रशिक्षित एक साधारण वाक्य एम्बेडिंग मॉडल से उन लोगों के साथ पूर्व-प्रशिक्षित मॉडल से एम्बेडिंग को संयोजित करना, कुछ-नमूना कार्यों के लिए एफटी के प्रदर्शन में सुधार कर सकता है। इस अंत के लिए, एक रैखिक क्लासिफायर को संयुक्त एम्बेडिंग पर प्रशिक्षित किया जाता है, या तो एम्बेडिंग मॉडल वजन को ठंडा करके या क्लासिफायर को प्रशिक्षित करके और एम्बेडिंग मॉडल को एंड-टू-एंड करके। हम एनएलपी कार्यों से सात छोटे डेटासेट पर मूल्यांकन करते हैं और दिखाते हैं कि एंड-टू-एंड प्रशिक्षण के साथ हमारा दृष्टिकोण नगण्य कम्प्यूटेशनल ओवरहेड के साथ एफटी को मात देता है। इसके अलावा, हम यह भी दिखाते हैं कि सीसीए और केसीसीए जैसी परिष्कृत संयोजन तकनीकें संयोजन के रूप में अभ्यास में अच्छी तरह से काम नहीं करती हैं। हम इस अनुभवजन्य अवलोकन की व्याख्या करने के लिए सैद्धांतिक विश्लेषण प्रदान करते हैं।', 'ru': 'Было показано, что предварительно обученные модели встраивания предложений в небольшие наборы данных имеют ограничения. В этой статье мы показываем, что объединение вложений из предварительно обученной модели с вложениями из простой модели вложения предложений, обученной только целевым данным, может улучшить производительность FT для небольшого числа выборочных задач. С этой целью на комбинированных вложениях обучается линейный классификатор, либо замораживая веса модели вложений, либо обучая сквозные модели классификаторов и вложений. Мы проводим оценку семи небольших наборов данных из задач NLP и показываем, что наш подход с сквозным обучением превосходит FT с незначительными вычислительными накладными расходами. Кроме того, мы также показываем, что сложные методы комбинирования, такие как CCA и KCCA, не работают так хорошо на практике, как конкатенация. Мы проводим теоретический анализ для объяснения этого эмпирического наблюдения.', 'ga': 'Tá sé léirithe go bhfuil teorainneacha ag baint le mionchoigeartú (FT) a dhéanann leabú abairtí réamh-oilte ar thacair sonraí beaga. Sa pháipéar seo léirímid gur féidir feabhas a chur ar fheidhmíocht FT do thascanna cúplasampla trí na leabuithe ón múnla réamhoilte a chomhdhlúthú leo siúd ó shamhail leabaithe abairtí simplí atá oilte ar na sonraí sprice amháin. Chuige sin, cuirtear oiliúint ar aicmitheoir líneach ar na leabú comhcheangailte, trí mheáchain an mhúnla leabaithe a reo nó trí oiliúint a chur ar an aicmitheoir agus ar mhúnlaí leabú ceann go ceann. Déanaimid meastóireacht ar sheacht tacar sonraí beaga ó thascanna NLP agus léirímid go n-éiríonn lenár gcur chuige maidir le hoiliúint ceann go ceann ná FT le forchostas ríomhaireachtúil diomaibhseach. Ina theannta sin, léirímid freisin nach n-oibríonn teicníochtaí teaglaim sofaisticiúla cosúil le CCA agus KCCA chomh maith go praiticiúil le comhghatánú. Cuirimid anailís theoiriciúil ar fáil chun an bhreathnóireacht eimpíreach seo a mhíniú.', 'el': 'Έχει αποδειχθεί ότι τα προ-εκπαιδευμένα μοντέλα ενσωμάτωσης προτάσεων σε μικρά σύνολα δεδομένων έχουν περιορισμούς. Σε αυτή την εργασία δείχνουμε ότι η συσχέτιση των ενσωματώσεων από το προ-εκπαιδευμένο μοντέλο με εκείνες από ένα απλό μοντέλο ενσωμάτωσης προτάσεων εκπαιδευμένο μόνο στα δεδομένα στόχων, μπορεί να βελτιώσει την απόδοση του για εργασίες ελάχιστων δειγμάτων. Για το σκοπό αυτό, εκπαιδεύεται ένας γραμμικός ταξινομητής στις συνδυασμένες ενσωματώσεις, είτε παγώνοντας τα βάρη του μοντέλου ενσωμάτωσης είτε εκπαιδεύοντας τον ταξινομητή και ενσωματώνοντας μοντέλα από το τέλος σε το τέλος. Πραγματοποιούμε αξιολόγηση σε επτά μικρά σύνολα δεδομένων από εργασίες και αποδεικνύουμε ότι η προσέγγισή μας με εκπαίδευση από τέλος σε τέλος ξεπερνά την FT με αμελητέο υπολογιστικό κόστος. Επιπλέον, καταδεικνύουμε επίσης ότι οι εξελιγμένες τεχνικές συνδυασμού όπως η CCA και η KCCA δεν λειτουργούν τόσο καλά στην πράξη όσο η αλληλουχία. Παρέχουμε θεωρητική ανάλυση για να εξηγήσουμε αυτή την εμπειρική παρατήρηση.', 'hu': 'A finomhangoló (FT) előre képzett mondatbeágyazási modellek kis adatkészletekre korlátozottak. Ebben a tanulmányban megmutatjuk, hogy az előkészített modellből származó beágyazások összekapcsolása egy egyszerű mondat beágyazási modellből származó beágyazásokkal, amelyeket csak a céladatokra képzett, javíthatja az FT teljesítményét néhány mintás feladat esetén. Ebből a célból lineáris osztályozót képeznek a kombinált beágyazásokra, vagy a beágyazási modell súlyának befagyasztásával, vagy az osztályozó és a modellek beágyazásával végtől-végig. NLP feladatokból hét kisméretű adatkészleten végzünk értékelést, és megmutatjuk, hogy a végpontos képzéssel végzett megközelítésünk elhanyagolható számítási költséggel felülmúlja az FT-t. Továbbá azt is megmutatjuk, hogy az olyan kifinomult kombinációs technikák, mint a CCA és a KCCA, nem működnek olyan jól a gyakorlatban, mint az összefüggés. Elméleti elemzést nyújtunk ennek az empirikus megfigyelésnek a magyarázatára.', 'ka': 'პატარა მონაცემების კონფიგურაცია (FT) წინატარებული წინატარებული წინატარება მარტივი მოდელეების შემდეგ გამოჩვენებულია. ამ დოკუნში ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ მოვაჩვენებთ, რომ წინ მოგზავნილი მოდელიდან შემდეგ მარტივი სიტყვების მოდელიდან, რომელიც მხოლოდ მისაღების მონაცემებ ამ კონფიგურისთვის, ლინიერი კლასიფიგური კონფიგურაცია კონფიგურაციაში იქნება, ან შემდეგ მოდელური გაზების გაზების შემდეგ, ან კლასიფიგურაციაში და შემდეგ მოდელების გადასრულება ჩვენ NLP დავამუშავებთ შვიდი პატარა მონაცემების შესახებ და გამოჩვენებთ, რომ ჩვენი დავამუშავება ბოლოდან დასრულებული მონაცემების შესახებ FT-ს უფრო გავამუშავებს, რო დამატებით ჩვენ ასევე ჩვენ ჩვენ აჩვენებთ, რომ სოფისტიკური კომბინეციის ტექნოგიები, როგორც CCA და KCCA, არ მუშაობენ როგორც კომბინეციაში. ჩვენ თეორეტიკალური ანალიზია, რომელიც ამ ემპერიკალური დაახსნათ.', 'lt': 'Nustatyta, kad iš anksto parengti tikslesnio koregavimo (FT) sakinių įtraukimo į mažus duomenų rinkinius modeliai turi apribojimų. Šiame dokumente parodomi, kad suderinti iš anksto parengto modelio įterptus įterptus įterptus įterptus įterptus įterptus įterptus įterptus įterptus įterptus įterptus įterptus įterptus modelius, parengtus tik tiksliniais duomenimis, gali pagerinti FT veiklos rezultatus kelioms atrinktoms užduotims. Šiuo tikslu linijinis klasifikatorius mokomas su kombinuotais įdėjimais, įšaldant įdėjimo modelio svorius arba mokant klasifikatorių ir įdėjimo modelius nuo galo iki galo. Vertiname septynis nedidelius NLP užduočių duomenų rinkinius ir parodome, kad mūsų požiūris į mokymo baigties rezultatus sudaro FT su nereikšmingomis bendrosiomis skaičiavimo išlaidomis. Further, we also show that sophisticated combination techniques like CCA and KCCA do not work as well in practice as concatenation.  Pateikiame teorinę analizę, kad paaiškintume šią empirinę pastabą.', 'it': 'È stato dimostrato che i modelli pre-addestrati per incorporare frasi su piccoli set di dati hanno delle limitazioni. In questo articolo mostriamo che concatenare gli embedding dal modello pre-addestrato con quelli da un semplice modello di embedding di frase addestrato solo sui dati di destinazione, può migliorare le prestazioni di FT per attività di pochi campioni. A tal fine, un classificatore lineare viene addestrato sulle incorporazioni combinate, congelando i pesi del modello incorporato o allenando il classificatore e incorporando modelli end-to-end. Eseguiamo valutazioni su sette piccoli set di dati provenienti da attività NLP e mostriamo che il nostro approccio con la formazione end-to-end supera FT con costi computazionali trascurabili. Inoltre, mostriamo anche che sofisticate tecniche di combinazione come CCA e KCCA non funzionano bene nella pratica come la concatenazione. Forniamo analisi teoriche per spiegare questa osservazione empirica.', 'mk': 'Се покажа дека моделите за вклопување на реченици во мали податоци имаат ограничувања. In this paper we show that concatenating the embeddings from the pre-trained model with those from a simple sentence embedding model trained only on the target data, can improve over the performance of FT for few-sample tasks.  За ова, линијарен класификатор е обучен на комбинираните вградувања, или преку замрзнување на вградувачките тегови на моделот или обука на класификаторот и вградувачките модели од крај до крај. Правиме проценка на седум мали податоци од задачите на НЛП и покажуваме дека нашиот пристап со крајна обука го надминува ФТ со незначителни пресметки. Покрај тоа, ние исто така покажуваме дека софистицираните техники на комбинација како што се ЦЦА и КЦЦА не функционираат толку добро во практиката како концетанација. Ние обезбедуваме теоретска анализа за да ја објасниме оваа емпириска набљудување.', 'kk': 'Шағын деректер қорларында таңдау үлгілері (FT) алдын- талап етілген сөз ендіру үлгілері шектелген деп көрсетілді. Бұл қағазда біз алдын- оқылған үлгіден ендіру үлгісін тек мақсатты деректерге қарапайым мәліметті ендіру үлгісінен бірнеше үлгілер үшін FT жұмысын жақсартуға болады. Бұл үшін сызық классификаторы біріктірілген ендіру үшін, немесе ендіру үлгілерін мұздырып, немесе классификаторын және ендіру үлгілерін аяқтау үлгілеріне оқытуға болады. Біз NLP тапсырмаларының yedi кішкентай деректер жиындарын оқу және соңындағы оқу бақылауымыз FT-нің көмегімен жұмыс істейді. Сонымен қатар, CCA және KCCA секілді жұмыс істейтін жұмыс істемейді. Бұл империялық байқау үшін теориялық анализ береміз.', 'no': 'Det er vist å ha begrensningar med finnstillingar (FT) før- trenga setningsmodular som innebyr inn i små datasett. I denne papiret viser vi at samanlikninga av innbyggingane frå den først trengte modellen med dei frå ein enkel setningsmodul som berre treng på måldatane, kan forbetra utviklinga av FT for få prøveprøver. I denne slutten vert ein lineær klassifiserer trent på dei kombinerte innbygginga anten ved å frysera innbyggingsvekta eller opplæra klassifiseringen og innbyggingsmodeller slutttil slutt. Vi utfører evalueringa på sju små datasett frå NLP- oppgåver og viser at tilnærminga vårt med ende- til- sluttøving utfører FT med små datamaskin overhode. I tillegg viser vi også at sofistikerte kombinasjonssteknikk som CCA og KCCA ikkje fungerer også i praksis som samsvar. Vi gjev teoretisk analyse for å forklare denne empiriske observasjonen.', 'ms': 'Penyesuaian-baik (FT) model penyembedding kalimat pra-dilatih pada set data kecil telah dipaparkan mempunyai had. Dalam kertas ini kami menunjukkan bahawa menyatukan penyembedding dari model yang dilatih-dilatih dengan yang dari satu kalimat sederhana penyembedding model yang dilatih hanya pada data sasaran, boleh meningkatkan prestasi FT untuk beberapa tugas sampel. Untuk tujuan ini, pengklasifikasi linear dilatih pada penyembedding kombinasi, sama ada dengan membekukan berat model penyembedding atau melatih pengklasifikasi dan penyembedding model akhir-akhir. Kami melakukan penilaian pada tujuh set data kecil dari tugas NLP dan menunjukkan bahawa pendekatan kita dengan latihan akhir-akhir melalui FT dengan overhead perhitungan yang tidak terlihat. Lagipun, kita juga menunjukkan bahawa teknik kombinasi yang canggih seperti CCA dan KCCA tidak berfungsi dengan baik dalam praktek sebagai concatenation. Kami memberikan analisis teori untuk menjelaskan pengamatan empirik ini.', 'mt': 'Intwera li mudelli ta’ inkorporazzjoni ta’ sentenzi mħarrġa minn qabel ta’ aġġustament finat (FT) fuq settijiet żgħar ta’ dejta għandhom limitazzjonijiet. F’dan id-dokument naraw li l-konċidenza tal-inkorporazzjonijiet mill-mudell imħarreġ minn qabel ma’ dawk minn mudell sempliċi ta’ inkorporazzjoni ta’ sentenza mħarreġ biss fuq id-dejta fil-mira, tista’ ttejjeb fuq il-prestazzjoni ta’ FT għal ftit kompiti ta’ kampjuni. Għal dan il-għan, klassifikatur lineari huwa mħarreġ fuq l-inkorporazzjonijiet ikkombinati, jew billi jiffriża l-piżijiet tal-mudell inkorporat jew billi jħares il-klassifikatur u l-mudelli inkorporati minn tarf għal tarf. We perform evaluation on seven small datasets from NLP tasks and show that our approach with end-to-end training outperforms FT with negligible computational overhead.  Barra minn hekk, naraw ukoll li tekniki sofistikati ta’ kombinazzjoni bħas-CCA u l-KCCA ma jaħdmux tajjeb fil-prattika daqs il-konċentrazzjoni. Aħna nipprovdu analiżi teoretika biex nispjegaw din l-osservazzjoni empirika.', 'ml': 'ചെറിയ ഡാറ്റാസറ്റുകളിലുള്ള വാക്കിനുള്ള മോഡലുകളില്\u200d മുമ്പ് പരിശീലിക്കപ്പെട്ട വാക്കുകള്\u200d മുന്\u200dപ് ട്രെയിനി ഈ പേപ്പറില്\u200d നമ്മള്\u200d കാണിച്ചു കൊടുക്കുന്നത് മുന്\u200dപരിശീലന മോഡലില്\u200d നിന്നുള്ള അകത്തുനിന്നുള്ള മാതൃകങ്ങള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നത് മോഡലില്\u200d നിന്നും  ഈ അവസാനത്തിനുള്ളില്\u200d ഒരു ലൈയിര്\u200d ക്ലാസ്ഫിക്കര്\u200d കൂട്ടിചേര്\u200dത്തിരിക്കുന്നതില്\u200d പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു, ഒന്നുകില്\u200d മോഡല്\u200d തൂക് NLP ജോലികളില്\u200d നിന്നുള്ള ഏഴു ചെറിയ ഡാറ്റാസറ്റുകളില്\u200d ഞങ്ങള്\u200d വിലാസപ്പെടുത്തുകയും, അവസാന പരിശീലനത്തില്\u200d നമ്മുടെ നടപടിയില്\u200d നിന് അതിനുശേഷം, നമ്മള്\u200d കാണിക്കുന്നത് സികിയെയും കെസിഎയെയും പോലുള്ള സോഫിക്സിക്കേഷന്\u200d സാങ്കേതികവിദ്യകള്\u200dക്കും പ്രവർ ഈ ശ്രദ്ധ വിശദീകരിക്കാന്\u200d നമുക്ക് തിയറ്ററിക്കല്\u200d അന്വേഷണം നല്\u200dകുന്നു.', 'mn': 'Жижиг өгөгдлийн санг дамжуулах (FT) урд дамжуулагдсан өгүүлбэрүүдийн загвар нь хязгаарлагддаг. Энэ цаасан дээр бид өмнө сургалтын загвараас хамтдаа сургалтын загварыг зөвхөн зорилготой өгөгдлийн загвар дээр сургалтын загварын загвараас илүү сайжруулж чадна гэдгийг харуулж байна. Энэ төгсгөлд шулуун хэлбэрийг холбогдож, холбогдох загварын жингийг мөсөж, эсвэл классификаторыг дасгалжуулж, загварын төгсгөлд хүргэж чадна. Бид NLP ажлын 7 жижиг өгөгдлийн санг үнэлгээ хийж, төгсгөл болон төгсгөл дасгал хөгжүүлэх үйлдлийн үр дүнтэй FT-г багасгадаг гэдгийг харуулж байна. Мөн бид CCA болон KCCA шиг нарийн нэгтгэл технологиуд бага зэрэг дасгал хөдөлгөөнд ажиллахгүй гэдгийг харуулж байна. Бид теоретикийн шинжилгээг тайлбарлахын тулд энэ эмператикийн ажиглагааг өгдөг.', 'pl': 'Wykazano, że wstępnie przeszkolone modele osadzania zdań na małych zbiorach danych mają ograniczenia. W niniejszym artykule pokazujemy, że łączenie osadzeń z modelu wstępnie przeszkolonego z modelem osadzania prostego zdania przeszkolonym tylko na danych docelowych, może poprawić wydajność FT dla zadań kilku próbek. W tym celu klasyfikator liniowy jest trenowany na połączonych osadzeniach, albo poprzez zamrożenie wag modelu osadzenia lub szkolenie klasyfikatora i osadzenie modeli od końca do końca. Przeprowadzamy ocenę siedmiu małych zbiorów danych z zadań NLP i pokazujemy, że nasze podejście z kompleksowym szkoleniem przewyższa FT przy nieznacznym nakładzie obliczeniowym. Ponadto pokazujemy, że zaawansowane techniki kombinacji, takie jak CCA i KCCA, nie działają tak dobrze w praktyce jak łączenie. Przedstawiamy analizę teoretyczną w celu wyjaśnienia tej empirycznej obserwacji.', 'so': "Sida loo muujiyey samooyin ku habboon sawir gaar ah oo ku qoran qoraalka sawirada yaryar (FT) waxaa looga muujiyey inay haystaan xad. Qoraalkan waxan ka muujinaynaa in lagu sameynayo sameynta qaababka hore ee lagu baray tusaale fudud oo keliya lagu tababariyey macluumaadka goalka ah, wuxuu horumarin karaa sameynta FT ee shaqooyinka samooyinka yar. To this end, a linear classifier is trained on the combined embeddings, either by freezing the embedding model weights or training the classifier and embedding models end-to-end.  Waxaannu qiimeynaynaa todobada macluumaad yar oo ka mid ah shaqada NLP, waxaana tusaynaa in qaabkeenkeenna ugu dambaysta waxbarashada FT uu ku sameeyo xisaab la'aan. Sidoo kale waxaynu tusnaynaa in qalabka iskuulka ah, sida CCA iyo KCCA aysan sidoo kale shaqeyneyn karno si ay u shaqeeyaan. Anaalbaarinta theoretical si aan u caddayno aragtidan cajiibka ah.", 'si': 'පුංචි දත්ත සෙට්ටුවට සීමාවක් තියෙන්න පෙන්වන්න පුළුවන් ප්\u200dරධානය සඳහා ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය සඳ මේ පත්තරේ අපි පෙන්වන්නේ ප්\u200dරධානය කළ ප්\u200dරධානය කරලා තියෙන ප්\u200dරධානය කරලා තියෙන ප්\u200dරධානය කරලා තියෙන ප්\u200dරධානය කරලා තියෙන ප්\u200dරධානය මේ අවසානයෙන්, ලේනියාර් ක්\u200dරිසිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්සිපර්ස අපි NLP වැඩේ පුංචි දත්ත සේට් 7ක් ගැන අවශ්\u200dයය කරනවා ඒ වගේම පෙන්වනවා අපේ අවශ්\u200dයය අවශ්\u200dයයෙන් අවශ්\u200dයයෙන් ප්\u200dරධානය FT එක තවත්, අපි පෙන්වන්නේ CCA සහ KCCA වගේ සම්බන්ධ විද්\u200dයාවක් සම්බන්ධ විද්\u200dයාවක් වැඩ කරන්නේ නැහැ කියලා. අපි සාධාරණික විශ්ලේෂණය දෙන්නේ මේ සාධාරණික බලන්න පැහැදිලි කරන්න.', 'ro': 'S-a demonstrat că modelele pre-instruite de încorporare a frazelor pe seturi de date mici au limitări. În această lucrare arătăm că concatenarea încorporărilor din modelul pre-instruit cu cele dintr-un model simplu de încorporare a frazelor instruit numai pe datele țintă, poate îmbunătăți performanța FT pentru sarcini de câteva eșantioane. În acest scop, un clasificator liniar este instruit pe încorporările combinate, fie prin înghețarea greutăților modelului de încorporare, fie prin instruirea clasificatorului și încorporarea modelelor end-to-end. Efectuăm evaluarea a șapte seturi de date mici din sarcinile PNL și arătăm că abordarea noastră cu instruirea end-to-end depășește FT cu costuri de calcul neglijabile. Mai mult, demonstrăm, de asemenea, că tehnicile sofisticate de combinație precum CCA și KCCA nu funcționează la fel de bine în practică ca concatenarea. Oferim analize teoretice pentru a explica această observație empirică.', 'sr': 'Pokazano je da su modeli uključenih predobučenih rečenica na male datasete ograničeni. U ovom papiru pokazujemo da potvrđivanje integracija iz predobučenog model a sa onima iz jednostavnog modela integracije rečenice obučenog samo na ciljnim podacima može poboljšati provedbu FT-a za nekoliko uzoraka. Za taj cilj, linijski klasifikator je obučen na kombiniranim integracijama, ili smrzavanjem integracijske težine model a ili obučavanjem klasifikatora i integracijskih modela do kraja. Izvodimo procjenu na sedam malih seta podataka iz zadataka NLP-a i pokazujemo da naš pristup treninga kraja do kraja nadmašuje FT sa negličnim računalnim iznad glave. Nadalje, takođe pokazujemo da sofisticirane kombinacijske tehnike poput CCA i KCCA ne rade baš u praksi kao i u concatenaciji. Mi pružamo teorijsku analizu da objasnimo ovu empirièku promatranje.', 'sv': 'Finjusterande (FT) förklädda meningsmodeller på små datauppsättningar har visat sig ha begränsningar. I den här uppsatsen visar vi att sammanfoga inbäddningarna från den förintränade modellen med dem från en enkel meningsinbäddningsmodell som endast tränas på måldata, kan förbättra FT:s prestanda för några exempel uppgifter. För detta ändamål tränas en linjär klassificerare på de kombinerade inbäddningarna, antingen genom att frysa inbäddningsmodellvikterna eller genom att träna klassificeraren och inbäddningsmodellerna från början till slut. Vi utvärderar sju små datauppsättningar från NLP-uppgifter och visar att vårt tillvägagångssätt med end-to-end-träning överträffar FT med försumbar beräkningskostnad. Vidare visar vi att sofistikerade kombinationstekniker som CCA och KCCA inte fungerar lika bra i praktiken som sammanläggning. Vi tillhandahåller teoretisk analys för att förklara denna empiriska observation.', 'ta': 'சிறிய தரவுத் தளங்களில் உள்ள மாதிரியான முன் பயிற்சியான வாக்கியத்தில் உள்ள முன்னோட்டம் செய்யும் (FT) எல்லைகள்  இந்த காகிதத்தில் நாம் காட்டுகிறோம் முன் பயிற்சி மாதிரியில் இருந்து உள்ளிடப்பட்ட மாதிரியில் இருந்து சேர்க்கப்பட்டுள்ள பொருள்களை சேர்த்து கொள் இந்த முடிவிற்கு, ஒரு வரிசை வகுப்பாளர் ஒன்றிணைக்கப்பட்ட உள்ளடக்கங்களில் பயிற்சி செய்யப்படுகிறது, அல்லது உள்ளிடும் மாதிரி எடைகளை மழுப்பு அல்லது வகு NLP பணிகளில் இருந்து ஏழு சிறிய தகவல் அமைப்புகளில் நாம் செய்ய விளக்கம் செய்கிறோம் மற்றும் எங்கள் முடிவு இறுதி பயிற்சியில் நாம மேலும், நாம் காட்டுகிறோம் CCA மற்றும் கேசியா போன்ற தொழில்நுட்ப தொழில்நுட்பத்தையும் செயல்படுத்த முடியாது. நாம் இந்த முக்கியமான பார்வையை விளக்குவதற்கு தியூரியல் ஆய்வு வழங்குகிறோம்.', 'ur': 'چھوٹے ڈاٹ سٹ پر پاکیزہ ترینینگ (FT) پیش ترینس کیے ہوئے sentence embedding models دکھائے گئے ہیں۔ ہم اس کاغذ میں دکھاتے ہیں کہ پہلے ترسین کی موڈل سے انبوڈینگ کو ان کے ساتھ ایک سادہ جماعت مہینڈ موڈل کے ذریعہ سے متصل کرتا ہے جو صرف موجود ڈاٹ پر آموزش کی گئی ہے، بہت کم نمونڈ کے کاموں کے لئے FT کی عملکرد پر بہتر کر سکتا ہے اس کے لئے ایک لینر کلاسیر کی تعلیم کی جاتی ہے جو جمع کئے جاتے ہیں، یا انڈیڈنگ موڈل وزت کو ٹھنڈا دیتے ہیں یا کلاسیر اور انڈیڈنگ موڈل کو انتہا-انتہا کی تعلیم دیتے ہیں. ہم NLP تاسکیوں سے سات چھوٹے ڈیٹ سٹ پر ارزیابی کر رہے ہیں اور دکھاتے ہیں کہ آخر تک تمرین کے ساتھ ہمارا طریقہ FT کو ناپسند کامپیوتر اورہڈ کے ساتھ اضافہ کرتا ہے۔ اور ہم بھی دکھاتے ہیں کہ CCA اور KCCA جیسے پیچیدہ پیچیدہ پیچیدہ تکنیک بھی کام نہیں کرتے۔ ہم نے نظریہ تحقیقات کو اس امپریٹی نظریہ کی توضیح کے لئے پیش کیا ہے۔', 'uz': "Name Bu hujjatda biz birinchi taʼminlovchi modeldan foydalanuvchilarni birlashtirish mumkin, faqat qanday maʼlumot bilan o'rganilgan modellardan foydalanish mumkin, bir necha sampul vazifalar uchun FT bajarishni oshirish mumkin. Bu hozirda, liner klassifisi birlashtirilgan emblemlarda o'rganadi, yoki chegara modelning balandligini yopish yoki klassifiser va tuzuvchi modellarning oxiriga o'rganish mumkin. We perform evaluation on seven small datasets from NLP tasks and show that our approach with end-to-end training outperforms FT with negligible computational overhead.  Ko'rsatganda, biz CCA va KCCA kabi sofistika teknikalarni ko'rsatishimiz mumkin va birlashtirishga ishlamaydi. Biz bu tasavvur ko'rinishni o'rganish uchun teoretik analytikni anglatamiz.", 'vi': 'Việc chỉnh sửa bản án tốt (FT) đã được đào tạo trước những mẫu vẽ trên các bộ dữ liệu nhỏ đã có giới hạn. Trong tờ giấy này chúng tôi cho thấy khả năng kết hợp sự nhúng vào từ mô hình được huấn luyện trước với mẫu được tạo ra từ một mô hình đơn giản chỉ dựa trên dữ liệu đích, có thể cải thiện khả năng thực hiện của TD cho các nhiệm vụ mẫu. Để đạt được mục đích, người phân loại đường thẳng được đào tạo về sự nhúng tay kết hợp, bằng cách đóng băng các tạ kiểu hoặc huấn luyện người phân loại và ghép các mô hình từ cuối đến cuối. Chúng tôi thực hiện đánh giá bảy bộ dữ liệu nhỏ từ nhiệm vụ NLP và cho thấy phương pháp của chúng tôi với kết thúc đào tạo hậu quả của FT với mức tính không đáng kể. Chúng tôi cũng cho thấy các kỹ thuật tổ hợp phức tạp như CCA và KCCA không hoạt động tốt như trong thực tế Chúng tôi cung cấp phân tích lý thuyết để giải thích quan sát này.', 'nl': 'Vooropgeleide modellen voor het inbedden van zinnen op kleine datasets hebben beperkingen. In dit artikel laten we zien dat het samenvoegen van de inbeddingen uit het vooraf getrainde model met die uit een eenvoudig zinsinbeddingsmodel dat alleen is getraind op de doelgegevens, de prestaties van FT voor taken met weinig voorbeelden kan verbeteren. Daartoe wordt een lineaire classificator getraind op de gecombineerde embeddings, hetzij door de inbeddingsmodelgewichten te bevriezen of door de classificator te trainen en modellen end-to-end in te sluiten. We voeren evaluaties uit op zeven kleine datasets uit NLP-taken en laten zien dat onze aanpak met end-to-end training FT overtreft met verwaarloosbare rekenkosten. Verder laten we ook zien dat geavanceerde combinatietechnieken zoals CCA en KCCA in de praktijk niet zo goed werken als aaneenschakeling. We geven theoretische analyse om deze empirische observatie te verklaren.', 'bg': 'Доказано е, че предварително обучените модели за вграждане на изречения с фина настройка (FT) върху малки набори от данни имат ограничения. В тази статия показваме, че конкатенирането на вгражданията от предварително обучен модел с тези от прост модел за вграждане на изречения, обучен само върху целевите данни, може да се подобри в сравнение с изпълнението на ФТ за няколко примерни задачи. За тази цел се обучава линеен класификатор върху комбинираните вграждания, или чрез замразяване на теглата на вградения модел, или чрез обучение на класификатора и вграждането на модели от край до край. Извършваме оценка на седем малки набора от данни от задачи по НЛП и показваме, че нашият подход с обучение от край до край превъзхожда ФТ с незначителни изчислителни разходи. Освен това, ние също така показваме, че сложни комбинирани техники като КТСА и ККТСА не работят толкова добре на практика, колкото конкатенацията. Предоставяме теоретичен анализ, за да обясним това емпирично наблюдение.', 'da': "Finjusterende (FT) prætrænede sætningsindlejringsmodeller på små datasæt har vist sig at have begrænsninger. I denne artikel viser vi, at sammenkædning af indlejringer fra den præ-trænede model med dem fra en simpel sætning indlejring model trænet udelukkende på måldata, kan forbedre FT's ydeevne for få-prøveopgaver. Til dette formål trænes en lineær klassificering i de kombinerede indlejringer, enten ved at fryse indlejringsmodelvægtene eller træne klassificeringen og indlejre modeller end-to-end. Vi udfører evaluering på syv små datasæt fra NLP-opgaver og viser, at vores tilgang med end-to-end træning overgår FT med ubetydelige beregningsomkostninger. Desuden viser vi også, at sofistikerede kombinationsteknikker som CCA og KCCA ikke fungerer så godt i praksis som sammenkobling. Vi leverer teoretisk analyse for at forklare denne empiriske observation.", 'de': 'Bei der Feinabstimmung (FT) von vortrainierten Satzbedingungsmodellen auf kleinen Datensätzen wurde gezeigt, dass sie Einschränkungen aufweisen. In diesem Beitrag zeigen wir, dass die Verkettung der Einbettungen aus dem vortrainierten Modell mit denen aus einem einfachen Satzbedding-Modell, das nur auf den Zieldaten trainiert wurde, die Leistung von FT für wenige Beispielaufgaben gegenüber verbessern kann. Dazu wird ein linearer Klassifikator auf die kombinierten Einbettungen trainiert, entweder durch Einfrieren der Einbettungsmodellgewichte oder durch Training des Klassifikators und der Einbettungsmodelle end-to-end. Wir führen Auswertungen an sieben kleinen Datensätzen aus NLP-Aufgaben durch und zeigen, dass unser Ansatz mit End-to-End-Training FT mit vernachlässigbarem Rechenobergang übertrifft. Weiterhin zeigen wir, dass anspruchsvolle Kombinationstechniken wie CCA und KCCA in der Praxis nicht so gut funktionieren wie Verkettung. Wir liefern theoretische Analysen, um diese empirische Beobachtung zu erklären.', 'hr': 'Pokazano je da su modeli uključenih predobučenih rečenica na malim podacima ograničeni. U ovom papiru pokazujemo da potvrđivanje integracija iz predobučenog model a s onima iz jednostavnog modela uvođenog rečenica obučenog samo na ciljnim podacima može poboljšati učinkovitost FT-a za nekoliko uzoraka. Za taj cilj, linearni klasifikator se obučava na kombiniranim integracijama, ili smrzavanjem ugrađenih model težina ili obučavanjem klasifikatora i ugrađenih model a do kraja. Izvodimo procjenu na sedam malih podataka iz zadataka NLP-a i pokazujemo da naš pristup treninga na kraju do kraja nadmašuje FT sa negličnim računalnim iznad glave. Nadalje, također pokazujemo da sofisticirane kombinacijske tehnike poput CCA i KCCA ne funkcioniraju kao i u praksi. Mi pružamo teorijsku analizu kako bi objasnili ovu empiričku promatranje.', 'ko': '작은 데이터 세트에서 미세조정(FT) 사전 훈련된 문장 삽입 모델은 한계가 있음을 증명했다.본고에서 우리는 예비 훈련 모델의 삽입과 목표 데이터에서만 훈련하는 간단한 문장 삽입 모델의 삽입을 연결하면 소량의 견본 작업에서 FT의 성능을 향상시킬 수 있음을 증명하였다.이를 위해 삽입모형의 무게를 동결하거나 끝에서 끝까지 분류기와 삽입모형을 훈련시켜 조합에 삽입하여 선형분류기를 훈련시킨다.NLP 작업에서 나온 7개의 작은 데이터 세트를 평가한 결과, FT 방법보다 엔드 투 엔드 트레이닝 방법이 우수하며, 계산 비용은 무시할 수 있습니다.또한 복잡한 조합 기술(예를 들어 CCA와 KCCA)은 실천에서 직렬 연결 기술만큼 효과적이지 않다는 것을 보여준다.우리는 이론 분석을 제공하여 이 실증 관찰 결과를 해석했다.', 'id': 'Penyesuaian baik (FT) praselatih kalimat memasukkan model pada set data kecil telah menunjukkan memiliki batasan. In this paper we show that concatenating the embeddings from the pre-trained model with those from a simple sentence embedding model trained only on the target data, can improve over the performance of FT for few-sample tasks.  Untuk tujuan ini, klasifikasi linear dilatih pada embedding kombinasi, baik dengan membeku berat model embedding atau melatih klasifikasi dan embedding model akhir-akhir. Kami melakukan evaluasi pada tujuh set data kecil dari tugas NLP dan menunjukkan bahwa pendekatan kita dengan latihan akhir-akhir melanjutkan FT dengan overhead perhitungan yang tidak terlihat. Selain itu, kami juga menunjukkan bahwa teknik kombinasi yang sophistik seperti CCA dan KCCA tidak bekerja dengan baik dalam praktek sebagai konatenasi. Kami menyediakan analisis teori untuk menjelaskan pengamatan empiris ini.', 'fa': 'نمونه\u200cهایی که در مجموعه\u200cهای داده\u200cهای کوچک محدودیت دارند، پیش آموزش داده شده\u200cاند، تنظیم\u200cکننده (FT) را نشان داده می\u200cشود. در این کاغذ نشان می\u200cدهیم که هماهنگ\u200cکننده\u200cها از مدل پیش آموزش شده با کسانی که از یک جمله ساده\u200cای که فقط روی داده\u200cهای هدف آموزش داده شده\u200cاند، می\u200cتوانند بر عملکرد FT برای کار چند نمونه\u200cای بهتر کنند. برای این قسمت، یک کلینگر خطی روی جمع کردن آموزش داده می شود، یا با سرد کردن وزن مدل وارد کردن یا تمرین کردن کلینگر و وارد کردن مدل آخر به پایان. ما روی هفت مجموعه داده کوچک از کارهای NLP ارزیابی انجام می دهیم و نشان می دهیم که روش ما با آموزش های پایان و پایان به FT با سر کامپیوتری ناپذیر است. ما همچنین نشان می دهیم که تکنیک های ترکیب پیچیدگی مانند CCA و KCCA همچنین در تمرین هماهنگی کار نمی کنند. ما تحلیل نظریه را برای توضیح این مشاهده امپراتیک می دهیم.', 'tr': "Kiçi datahiller üzerinde ön eğlenen sözler girişdirmeler (FT). Bu kagyzda biz öňünden eğlenen nusgadan daňlanan nusgadan diňe maksady maglumatlarda eğlenen bir sözlem bilen birleştirilip FT taýýarlandygyny görkezip bileris. Bu üçin, çizgi klassifikatçi kombinat ködlemelerde eğlenýär NLP zadynyň ýedi kiçi sany çykyşynda çykyşymyz çykýar we soňra-soňra görünýän işlerimiz FT'i çykyş hasaplamak üstünde çykýar. Mundan hem biz CCA we KCCA ýaly soňlaýyn birleşme teknikleriniň praktika hem birleşme ýaly işlemeýändigini görkeýäris. Biz bu empirik gözleri düşündirmek üçin teoriýa analýşiny temin edýäris.", 'af': "Fine- tuning (FT) vooraf- onderwerp seting inbetering modele op klein datastelle is vertoon om beperkings te hê. In hierdie papier wys ons dat die inbêdings van die voorafgevorderde model met die wat vanaf 'n eenvoudige seting inbêring model wat slegs op die doel data opgelei is, kan verbeter oor die prestasie van FT vir 'n paar- voorbeeld opdragte. Na hierdie einde is 'n lineêre klassifiseerder onderwerp op die gekombineerde inbêdings, of deur die inbêring model gewigte of die klassifiseerder en inbêer modele end- to- end te frees. Ons uitvoer evaluasie op sewe klein datastelle van NLP-opdragte en wys dat ons toegang met einde-tot-einde onderriging uitvoer FT met negligbare rekenaar oordeel. Verder, ons wys ook dat sofistike kombinasie teknike soos CCA en KCCA nie so goed werk in praksie as samelewing nie. Ons verskaf teorieese analisie om hierdie empiriese observasie te verduidelik.", 'sq': 'Modelet e përcaktimit të mirë (FT) të paratrajnuara për të përfshirë fjalë në grupe të vogla të dhënash janë treguar të kenë kufizime. Në këtë letër ne tregojmë se bashkimi i përfshirjeve nga modeli i paratrajnuar me ato nga një fjalim i thjeshtë përfshirje modeli i trajnuar vetëm në të dhënat objektive, mund të përmirësohet në lidhje me performancën e FT për disa detyra me mostra. Për këtë qëllim, një klasifikues linear është trajnuar në përfshirjet e kombinuara, ose duke ngrirë peshat e modelit të përfshirjes ose duke trajnuar klasifikuesin dhe përfshirjen e modeleve nga fundi në fund. Ne bëjmë vlerësim në shtatë grupe të dhënash të vogla nga detyrat e NLP dhe tregojmë se qasja jonë me trajnimin përfundimtar përfundon me FT me kosto të pakujdesshme llogaritare. Për më tepër, ne tregojmë gjithashtu se teknikat e sofistikuara të kombinimit si CCA dhe KCCA nuk funksionojnë aq mirë në praktikë sa bashkëkalimi. Ne japim analizë teorike për të shpjeguar këtë vëzhgim empirik.', 'am': 'አዲስ ዶሴ ፍጠር በዚህ ፕሮግራም፣ የፊተኛውን ተማሪ ሞዴል ከሚያስተማሩት እና በተቃራኒው ዳታዎች ብቻ የተማሩ ሞዴል ከሆነው እናሳየዋለን፡፡ ወደዚህ ምክንያት የመስመር ክፍል የሚያስተምር፣ ወይም በሙሉ ሞዴል ሚዛን በመዝነዝ ወይም በክፍለ መጨረሻ እና በሙሉ መተላለፊያውን በማስተማር ነው፡፡ ከNLP ስራ ሰባት ትንሽ ዳታዎችን ማረጋገጫ እናሳያቸዋለን፡፡ በተጨማሪም፣ እንደCCA እና ካክCA እና እንደተግባር ስልጣናዎችን እናሳያቸዋለን፡፡ We provide theoretical analysis to explain this empirical observation.', 'hy': 'Fine-tuning (FT) pre-trained sentence embedding models on small datasets has been shown to have limitations.  Այս թղթի մեջ մենք ցույց ենք տալիս, որ համեմատելը նախապատրաստված մոդելի ներդրումների հետ պարզ նախադասությունից ներդրող մոդելի հետ, որը պատրաստված է միայն նպատակային տվյալների վրա, կարող է բարելավել ՖԹ-ի արտադրողությունը մի քանի նմուշների համար: Այս նպատակով գծային դասակարգիչը սովորեցվում է համադրված ներդրումների վրա, կամ սառեցնելով ներդրման մոդելի կշիռը, կամ սովորեցնելով դասակարգիչը և ներդրման մոդելները վերջ-վերջ: Մենք գնահատում ենք 7 փոքրիկ տվյալներ ՆԼՊ-ի առաջադրանքներից և ցույց ենք տալիս, որ մեր մոտեցումը վերջ-վերջ ուսուցման միջոցով է արտադրում ՖԹ-ը, որն ունի աննշանակալի հաշվարկների ընդհանուր ծախսեր: Ավելին, մենք նաև ցույց ենք տալիս, որ բարդ համադրման տեխնիկաները, ինչպիսիք են ԿԿԱ և ԿԿԱԿԱ, չեն աշխատում այնքան լավ իրականության մեջ, որքան կոնկրետացիան: Մենք տրամադրում ենք տեսական վերլուծություն, որպեսզի բացատրենք այս էմպրիկական հետազոտությունը:', 'az': "Kiçik verilən qurğularda gözəl düzəltmə (FT) ön təhsil edilmiş cümlələr içərisində gizlənmək modelləri limitlərinin olması göstərildi. Bu kağıtda biz göstəririk ki, əvvəlcə təhsil edilmiş modelindən istifadə edilən bir cümlədən sadəcə məlumat verilənlərə təhsil edilmiş modellərlə birlikdə istifadə edilən inbingləri, bir neçə nümunə işləri üçün FT performansını daha yaxşılaşdıra bilər. Bütün bunlara görə, birləşdirilmiş birləşdirilmələr üzərində linear klasifikatçı təhsil edilir, ya da modellərin a ğırlığını dondurub, ya da klasifikatçısını təhsil edir, ya da modellərin sonu-sonu təhsil edir. NLP işindən yeddi kiçik veri qurğuları təyin edirik və sona qədər təhsil edilən təhsil bizim FT'nin zəiflik hesablama üstündə istifadə edilməsini göstəririk. Daha sonra, biz də göstəririk ki CCA və KCCA kimi sofistikli kombinatsiyalı tekniklərlə birlikdə də çalışmır. Biz bu empirik gözləməyi açıqlamaq üçün teorik analizi təmin edirik.", 'sw': 'Ufunzi mzuri (FT) uliofanywa na mifano ya kufundisha hukumu ya awali katika seti ndogo ya data imeonyesha kuwa na vizuizi. Katika gazeti hili tunaonyesha kuwa, kukusanyika na mabango hayo kutoka kwa mtindo wa zamani wa mafunzo na wale kutoka kwenye neno rahisi lililofunzwa tu kwa taarifa za malengo, inaweza kuboresha utendaji wa FT kwa kazi chache za sampuli. To this end, a linear classifier is trained on the combined embeddings, either by freezing the embedding model weights or training the classifier and embedding models end-to-end.  Tunafanya uchunguzi wa taarifa saba ndogo kutoka kazi za NLP na kuonyesha kwamba hatua yetu kwa mafunzo ya mwisho yanaendesha FT yenye hisabati zisizo na maana. Zaidi ya hayo, tunaonyesha pia mbinu za kuunganisha kama vile CCA na KCCA hazifanyi kazi pia katika mazoea kama vile kuunganisha. Tunatoa uchambuzi wa kimaadili wa kuelezea mtazamo huu wa msisitizo.', 'cs': 'Bylo prokázáno, že předem trénované modely vkládání vět na malé datové sady mají omezení. V tomto článku ukazujeme, že řetězení vkládání z předtrénovaného modelu s těmi z jednoduchého modelu vkládání vět trénovaného pouze na cílových datech může zlepšit výkon FT pro úlohy s několika vzorky. Za tímto účelem je lineární klasifikátor trénován na kombinovaných vloženích, buď zmrazením hmotnosti vložení modelu nebo tréninkem klasifikátoru a vkládáním modelů end-to-end. Provádíme vyhodnocení sedmi malých datových sad z NLP úloh a ukazujeme, že náš přístup s end-to-end školením překonává FT s zanedbatelným výpočetním režimem. Dále ukazujeme, že sofistikované kombinační techniky jako CCA a KCCA v praxi nefungují tak dobře jako řetězce. Poskytujeme teoretickou analýzu k vysvětlení tohoto empirického pozorování.', 'bs': 'Pokazano je da su modeli uključenih predobučenih rečenica na male datasete ograničeni. U ovom papiru pokazujemo da potvrđivanje integracija iz predobučenog model a sa onima iz jednostavnog modela uključenog rečenice, obučenog samo na ciljnim podacima, može poboljšati učinkovitost FT-a za nekoliko uzorka. Za taj cilj, linearni klasifikator je obučen na kombiniranim integracijama, ili zamrzavanjem težine uključujuće modele ili obučavanjem klasifikatora i uključujuće modele do kraja. Izvodimo procjenu na sedam malih podataka iz zadataka NLP-a i pokazujemo da naš pristup treninga kraja do kraja nadmašuje FT sa negličnim računalnim iznad glave. Nadalje, također pokazujemo da sofisticirane kombinacijske tehnike poput CCA i KCCA ne funkcioniraju ni u praksi kao u concatenaciji. Mi pružamo teorijsku analizu da objasnimo ovu empiričku promatranje.', 'et': 'Väikestele andmekogumitele on näidatud piiranguid peenhäälestuse (FT) eelõpetatud lause manustamise mudelitel. Käesolevas töös näitame, et eelkoolitud mudeli manustamiste sidumine lihtsa lause manustamise mudeliga, mis on koolitatud ainult sihtandmetel, võib parandada FT tulemuslikkust vähese näidisega ülesannete puhul. Sel eesmärgil koolitatakse lineaarset klassifitseerijat kombineeritud manustamise kohta, kas külmutades manustamismudeli kaalud või treenides klassifitseerijat ja manustamismudeleid otsast otsani. Hindame seitset väikest andmekogumit NLP ülesannetest ning näitame, et meie lähenemine lõpuni koolitusega ületab FT väikese arvutuskuluga. Lisaks näitame, et keerukad kombinatsioonitehnikad, nagu CCA ja KCCA, ei toimi praktikas nii hästi kui seostamine. Pakume teoreetilist analüüsi, et selgitada seda empiirilist vaatlust.', 'bn': 'সামান্য তথ্য সীমাবদ্ধতা আছে বলে প্রশিক্ষিত পূর্ব প্রশিক্ষিত বাক্যের প্রাক্তন মডেলের মধ্যে উৎকৃষ্ট ট টুনিং (F এই কাগজটিতে আমরা দেখাচ্ছি যে প্রাক্তন প্রশিক্ষিত মডেল থেকে বিভিন্ন প্রতিষ্ঠানগুলোকে একত্রিত করা যাচ্ছে যারা শুধুমাত্র টার্গেট ডাটায় প্রশিক্ষণ প্রদ এই পর্যন্ত একটি লাইনিয়ার শ্রেণীবিদের প্রশিক্ষণ প্রদান করা হচ্ছে একত্রিত বিভিন্ন বিভিন্ন বিভিন্ন বিভিন্ন বিভিন্ন প্রতিষ্ঠানের মোডেলের ওজন আমরা এনএলপি কাজ থেকে সাত ছোট্ট ডাটাসেটের উপর মূল্য প্রদান করি এবং দেখাই যে শেষ পর্যন্ত প্রশিক্ষণের মাধ্যমে আমাদের প্রতিযোগিতা এফটি এছাড়াও আমরা দেখাচ্ছি যে সিসিএ এবং কিসিএ এর মতো সাফিক্সিক যোগাযোগ প্রযুক্তিগুলো কাজ করে না। We provide theoretical analysis to explain this empirical observation.', 'fi': 'Fine-tuning (FT) esikoulutetuilla lauseiden upotusmalleilla pieniin aineistoihin on osoitettu olevan rajoituksia. Tässä artikkelissa osoitetaan, että esikoulutetun mallin upotusten yhdistäminen yksinkertaiseen lauseen upotusmalliin, joka on koulutettu vain kohdedataan, voi parantaa FT:n suorituskykyä muutaman näytteen tehtävissä. Tätä varten lineaarinen luokittelija koulutetaan yhdistettyihin upotuksiin joko jäädyttämällä upotusmallipainot tai kouluttamalla luokittelijaa ja upotusmalleja päästä päähän. Arvioimme seitsemää pientä tietojoukkoa NLP-tehtävistä ja osoitamme, että lähestymistapamme end-to-end-koulutuksen avulla on FT:tä parempi kuin laskennallinen yleiskustannus. Lisäksi osoitamme, että kehittyneet yhdistelmätekniikat, kuten CCA ja KCCA, eivät toimi käytännössä yhtä hyvin kuin konkatenointi. Esitämme teoreettisen analyysin tämän empiirisen havainnon selittämiseksi.', 'ca': 'Fine-tuning (FT) pre-trained sentence embedding models on small datasets has been shown to have limitations.  In this paper we show that concatenating the embeddings from the pre-trained model with those from a simple sentence embedding model trained only on the target data, can improve over the performance of FT for few-sample tasks.  To this end, a linear classifier is trained on the combined embeddings, either by freezing the embedding model weights or training the classifier and embedding models end-to-end.  We perform evaluation on seven small datasets from NLP tasks and show that our approach with end-to-end training outperforms FT with negligible computational overhead.  També demostram que tècniques sofisticades de combinació com la CCA i la KCCA no funcionen tant bé en la pràctica com la concatenació. We provide theoretical analysis to explain this empirical observation.', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness In this paper we show that concatenate the embedding of the embedding model from the ultraspect with all the words from a Simple politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé ngerti cara-cara sing beraksi saben pitik dataset nggawe NLP dadi iki dadi ono dianggawe barang nggawe geranggap ilet-arang eft kanggo ngwala macem gawe dataset sing paling dumateng. Mungkin, kita nguasakno ngono teknik sing wis dipun sojit karo nggambar, lagi, iso nggawe barang kelas telu operasi lan tambah. Awakdhéwé nyebuté pancening theoretik kanggo ngerasakno perspekntar empirhik iki.', 'sk': 'Izkazalo se je, da imajo vnaprej usposobljeni modeli vdelave stavkov na majhne nabore podatkov omejitve. V tem prispevku smo pokazali, da se lahko povezovanje vdelav iz vnaprej usposobljenega modela s tistimi iz preprostega modela vdelave stavkov, usposobljenega samo na ciljne podatke, izboljša v primerjavi z uspešnostjo FT pri nekaj vzorčnih nalogah. V ta namen se linearni klasifikator usposablja za kombinirane vgradnje, bodisi z zamrznitvijo uteži vgradnje modela bodisi z usposabljanjem klasifikatorja in vgradnje modelov od konca do konca. Izvajamo vrednotenje sedmih majhnih podatkovnih nizov iz nalog NLP in pokažemo, da naš pristop z usposabljanjem od konca do konca presega FT z zanemarljivimi računalniškimi stroški. Poleg tega pokažemo tudi, da prefinjene kombinirane tehnike, kot sta CCA in KCCA, v praksi ne delujejo tako dobro kot konkatenacija. Zagotavljamo teoretično analizo za pojasnitev tega empiričnega opazovanja.', 'ha': "Fine-tuning (FT) pre-trained sentence embedding models on small datasets has been shown to have limitations.  Daga wannan takardan, Munã nũna musu, yin sammakon filin da aka yi wa shirin ayuka na zaman shirin da waɗanda ke cikin wani salon mai sauƙi da aka sanar da su kawai kan data na goan, yana iya ƙaranci game da aikin FT wa misalin misali kaɗan. To, zuwa wannan, an sanar da wani mai fassarar linje da aka haɗa cikin filinaiki, ko kuma a kulle mai nau'i na motel mai cikin shirin ayuka ko kuma a yi wa shirin mai fasasar da motsi na ƙari zuwa ƙarami. Munã tafiyar evaluation kan bakwai masu ƙarami database daga aikin NLP kuma ke nũna cewa hanyarmu da aikin na ƙarami zuwa ƙarami na samar FT da kawaici na lissafi. Furan haka, za mu nũna masu sofi masu komai kamar CCA da KCCA ba su yi aiki da kuma suna sami da sami. Munã samar da anayyar da littafiki dõmin mu bayyana wannan gani na tamko.", 'he': 'הוכח שיש לו גבלות. In this paper we show that concatenating the embeddings from the pre-trained model with those from a simple sentence embedding model trained only on the target data, can improve over the performance of FT for few-sample tasks.  למטרה זו, מסגר לינרי מאומן על התקפות המשולבות, או על ידי הקפיאה במשקלי המודל של התקפות או על ידי אימון את המסגר ומקפוץ מודלים סוף-סוף. אנו מבצעים עריכה על שבעה קבוצות מידע קטנות ממשימות NLP ולהראות שהגישה שלנו עם אימון מסוף-לסוף תוצאות FT עם מחשב גבוה בלתי משמעותי. חוץ מזה, אנחנו גם מראים שטכניקות שילוב מתוחכמות כמו CCA וקי. אנחנו מספקים ניתוח תיאורטי כדי להסביר את ההצגה האמפרית הזו.', 'bo': 'Fine-tuning (FT) pre-trained sentence embedding models on small datasets have been shown to have limitations. ང་ཚོའི་ཤོག་བྱང་འདིའི་ནང་དུ་སྔོན་གྲངས་སྒྲིག To this end, a linear classifier is trained on the combined embeddings, either by freezing the embedding model weights or training the classifier and embedding models end-to-end. We perform evaluation on seven small datasets from NLP tasks and show that our approach with end-to-end training outperforms FT with negligible computational overhead. ད་དུང་། ང་ཚོས་CCA དང་KCCA ལྟ་བུའི་སྡོད་རིམ་གྱི་ལག་ལེན་གྱིས་མཉམ་དུ་ལས་ཀྱང་མེད་པར་ཨིན་པ་ཡིན། ང་ཚོས་གཞུང་ལུགས་ཀྱི་དཔོན་རྟགས་འདི་གསལ་བཤད་བྱེད་པར་མཁན་གྱི་དབྱེ་ཞིབ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Multimodal Pretraining for Dense Video Captioning', 'ar': 'التدريب المسبق متعدد الوسائط للتسميات التوضيحية الكثيفة للفيديو', 'pt': 'Pré-treinamento multimodal para legendas de vídeo densas', 'es': 'Preentrenamiento multimodal para subtítulos de vídeo densos', 'fr': 'Pré-entraînement multimodal pour le sous-titrage vidéo dense', 'ja': '密度の高いビデオキャプションのためのマルチモーダルプレトレーニング', 'zh': '用密集视频字幕多模式预训练', 'hi': 'घने वीडियो कैप्शनिंग के लिए मल्टीमॉडल प्रीट्रेनिंग', 'ru': 'Мультимодальное предварительное обучение для плотной видеоподписи', 'ga': 'Réamhoiliúint Ilmhódach le haghaidh Físfhotheidealú Dlúth', 'hu': 'Multimodális előkészítés sűrű videofeliratozáshoz', 'el': 'Πολυmodale προεπιλογή για πυκνή τιτλοποίηση βίντεο', 'ka': 'Name', 'it': 'Pretraining multimodale per sottotitoli video densi', 'lt': 'Daugiarūšis išankstinis mokymas tankiam vaizdo įrašui', 'mk': 'Multimodal Pretraining for Dense Video Captioning', 'kk': 'Dense Video Captioning үшін көп модельді бақылау', 'ms': 'Pralatihan Multimodal untuk Capsyen Video Dense', 'ml': 'ഡെന്\u200dസ് വീഡിയോ ക്യാപ്റ്റനിങ്ങിനുള്ള മള്\u200dമൊഡോള്\u200d പരിശീലി', 'mn': 'Хүмүүсийн бичлэгийн зурагт олон загвар хөгжүүлэх', 'mt': 'It-taħriġ minn qabel multimodali għall-Captioning Dense Video', 'no': 'Name', 'pl': 'Multimodalne wstępne szkolenie dla gęstych napisów wideo', 'ro': 'Pretraining multimodal pentru subtitrare video densă', 'sr': 'Multimodalna pretvaranja za snimanje Dense Video', 'si': 'Name', 'so': 'Multimodal Pretraining for Dense Video Captioning', 'sv': 'Multimodal pretraining för tät videotextning', 'ta': 'Name', 'ur': 'ڈینس ویڈیو کاپیٹینگ کے لئے بہت سی موڈال پرٹرین', 'uz': 'Name', 'vi': 'Định dạng đa phương cho ảnh nhận dạng Dense', 'hr': 'Multimodalna pretvaranja za snimanje Denske snimke', 'nl': 'Multimodale pretraining voor dichte videoondertiteling', 'bg': 'Мултимодално претрениране за плътно видео заснемане', 'da': 'Multimodal forudsætning for tæt videobilledtekst', 'id': 'Multimodal Pretraining untuk Dense Video Captioning', 'de': 'Multimodales Vortraining für dichte Videobeschriftungen', 'ko': '영상 자막이 밀집된 다중모드 예습 훈련', 'fa': 'Name', 'tr': 'Dens Video Captioning için Çoklumodal Renkli', 'sw': 'Tayarisho la Video ya Dense kwa Kupiga Video', 'sq': 'Parastërvitje multimodale për thellimin e videove', 'af': 'Name', 'hy': 'Մոտ-մոդելային պատրաստում խիստ տեսագրության համար', 'az': 'Dens Video Captioning üçün çoxlu modal Pretraining', 'am': 'የድምፅ ቪዲዮ አቀማመጥ', 'bn': 'ডেন্স ভিডিও ক্যাপ্টেনিং এর জন্য বহুমোডাল প্রশিক্ষণ', 'ca': 'Predictoria multimodal per a captar vídeos densos', 'bs': 'Multimodalna pretvaranja za snimanje Denske snimke', 'cs': 'Multimodální předškolení pro husté video titulky', 'et': 'Multimodaalne eeltreening tiheda videopealdise jaoks', 'fi': 'Multimodaalinen esikoulutus tiheään videokuvaukseen', 'he': 'Multimodal Pretraining for Dense Video Captioning', 'jv': 'Multimodal Tatanan kanggo Dense Video Caption', 'sk': 'Multimodalno predvajanje za goste videoposnetke', 'ha': 'KCharselect unicode block name', 'bo': 'Dense Video Captioning པར་ཆས་སྣུམ་མཐུད་སྣུམ་རྣམ་པ'}
{'en': 'Learning specific hands-on skills such as  cooking ,  car maintenance , and  home repairs  increasingly happens via instructional videos. The user experience with such videos is known to be improved by meta-information such as time-stamped annotations for the main steps involved. Generating such  annotations  automatically is challenging, and we describe here two relevant contributions. First, we construct and release a new dense video captioning dataset, Video Timeline Tags (ViTT), featuring a variety of instructional videos together with time-stamped annotations. Second, we explore several multimodal sequence-to-sequence pretraining strategies that leverage large unsupervised datasets of videos and caption-like texts. We pretrain and subsequently finetune dense video captioning models using both YouCook2 and ViTT. We show that such  models  generalize well and are robust over a wide variety of instructional videos.', 'ar': 'يحدث تعلم مهارات عملية محددة مثل الطهي وصيانة السيارات وإصلاحات المنزل بشكل متزايد عبر مقاطع الفيديو التعليمية. من المعروف أن تجربة المستخدم مع مقاطع الفيديو هذه قد تحسنت من خلال المعلومات الوصفية مثل التعليقات التوضيحية ذات الطابع الزمني للخطوات الرئيسية المعنية. يعد إنشاء مثل هذه التعليقات التوضيحية تلقائيًا أمرًا صعبًا ، ونحن نصف هنا مساهمتين ذات صلة. أولاً ، نقوم بإنشاء وإصدار مجموعة بيانات تسميات توضيحية للفيديو كثيفة جديدة ، علامات الخط الزمني للفيديو (ViTT) ، والتي تضم مجموعة متنوعة من مقاطع الفيديو التعليمية جنبًا إلى جنب مع التعليقات التوضيحية ذات الطابع الزمني. ثانيًا ، نستكشف العديد من استراتيجيات التدريب المسبق متعددة الوسائط من التسلسل إلى التسلسل التي تستفيد من مجموعات البيانات الكبيرة غير الخاضعة للإشراف لمقاطع الفيديو والنصوص الشبيهة بالتعليقات. نقوم بالتدقيق المسبق ثم تحسين نماذج التسميات التوضيحية للفيديو الكثيفة باستخدام YouCook2 و ViTT. نظهر أن مثل هذه النماذج تُعمم جيدًا وأنها قوية عبر مجموعة متنوعة من مقاطع الفيديو التعليمية.', 'pt': 'Aprender habilidades práticas específicas, como cozinhar, manutenção de carros e reparos domésticos, acontece cada vez mais por meio de vídeos instrutivos. A experiência do usuário com esses vídeos é conhecida por ser aprimorada por meta-informações, como anotações com carimbo de data/hora para as principais etapas envolvidas. Gerar tais anotações automaticamente é um desafio, e descrevemos aqui duas contribuições relevantes. Primeiro, construímos e lançamos um novo conjunto de dados de legendagem de vídeo denso, as Tags de linha de tempo de vídeo (ViTT), apresentando uma variedade de vídeos instrutivos junto com anotações com carimbo de data/hora. Em segundo lugar, exploramos várias estratégias multimodais de pré-treinamento de sequência a sequência que aproveitam grandes conjuntos de dados não supervisionados de vídeos e textos semelhantes a legendas. Nós pré-treinamos e posteriormente ajustamos modelos de legendas de vídeo densos usando YouCook2 e ViTT. Mostramos que tais modelos generalizam bem e são robustos em uma ampla variedade de vídeos instrucionais.', 'fr': "L'apprentissage de compétences pratiques spécifiques telles que la cuisine, l'entretien de la voiture et les réparations à domicile se fait de plus en plus via des vidéos pédagogiques. L'expérience utilisateur avec de telles vidéos est connue pour être améliorée par des méta-informations telles que des annotations horodatées pour les principales étapes impliquées. La génération automatique de telles annotations est un défi, et nous décrivons ici deux contributions pertinentes. Tout d'abord, nous créons et publions un nouveau jeu de données de sous-titrage vidéo dense, Video Timeline Tags (ViTT), qui comprend une variété de vidéos pédagogiques ainsi que des annotations horodatées. Ensuite, nous explorons plusieurs stratégies de pré-apprentissage multimodales séquence à séquence qui exploitent de grands ensembles de données non supervisés de vidéos et de textes similaires à des sous-titres. Nous préformons puis affinons les modèles de sous-titrage vidéo denses en utilisant YouCook2 et ViTT. Nous montrons que de tels modèles se généralisent bien et sont robustes sur une grande variété de vidéos pédagogiques.", 'es': 'El aprendizaje de habilidades prácticas específicas, como cocinar, el mantenimiento del automóvil y las reparaciones del hogar, se realiza cada vez más a través de videos instructivos. Se sabe que la experiencia del usuario con tales vídeos se mejora con metainformación, como anotaciones con marca de tiempo para los pasos principales involucrados. Generar este tipo de anotaciones automáticamente es un desafío, y describimos aquí dos contribuciones relevantes. Primero, creamos y publicamos un nuevo conjunto de datos de subtítulos de vídeo denso, Video Timeline Tags (ViTT), que incluye una variedad de videos instructivos junto con anotaciones con marca de tiempo. En segundo lugar, exploramos varias estrategias multimodales de preentrenamiento de secuencia a secuencia que aprovechan grandes conjuntos de datos no supervisados de vídeos y textos similares a subtítulos. Entrenamos previamente y, posteriormente, ajustamos modelos de subtítulos de video densos con YouCook2 y ViTT. Demostramos que estos modelos se generalizan bien y son sólidos en una amplia variedad de videos instructivos.', 'ja': '料理、車のメンテナンス、家の修理など、特定の実践的なスキルを学ぶことは、インストラクショナルビデオを通じてますます行われます。このようなビデオのユーザーエクスペリエンスは、関連する主要なステップのタイムスタンプ付きアノテーションなどのメタ情報によって改善されることが知られています。このような注釈を自動的に生成することは困難であり、ここでは2つの関連する貢献について説明します。まず、さまざまなインストラクショナルビデオとタイムスタンプ付きアノテーションを備えた新しい高密度のビデオキャプションデータセット、ビデオタイムラインタグ（ ViTT ）を構築してリリースします。第二に、ビデオとキャプションのようなテキストの大規模な監視されていないデータセットを活用する、いくつかのマルチモーダルシーケンスからシーケンスへの事前トレーニング戦略を探ります。YouCook 2とViTTの両方を使用して、事前にトレーニングを行い、その後に高密度のビデオキャプション作成モデルを作成します。このようなモデルはよく一般化され、多種多様なインストラクショナルビデオにわたって堅牢であることを示しています。', 'ru': 'Обучение конкретным практическим навыкам, таким как приготовление пищи, техническое обслуживание автомобилей и ремонт домов, все чаще происходит с помощью обучающих видеороликов. Известно, что пользовательский опыт использования таких видеоматериалов улучшается за счет метаинформации, такой как аннотации с метками времени для основных этапов. Автоматическое создание таких аннотаций является сложной задачей, и мы описываем здесь два соответствующих вклада. Во-первых, мы создаем и выпускаем новый плотный набор данных с субтитрами видео, Video Timeline Tags (ViTT), включающий различные обучающие видеоролики вместе с аннотациями с метками времени. Во-вторых, мы изучаем несколько мультимодальных стратегий последовательного предварительного обучения, которые используют большие неконтролируемые наборы данных видео и текстов, похожих на субтитры. Мы предварительно анализируем и затем тонко настраиваем плотные модели субтитров видео, используя YouCook2 и ViTT. Мы показываем, что такие модели хорошо обобщают и надежны над широким разнообразием обучающих видеороликов.', 'zh': '教视频益多特定技,烹饪汽车修。 诸所周知,此类视频者用户体验可以元信息(如所涉大要,注)改善。 自生此注有挑战性,于此两相关。 先构而发一新密集视频字幕数据集,即视频时间轴标签 (ViTT),其中包含诸教学视频及带有时数之注。 其次,探诸模样序列到序列预训练之策,用视频类字幕文本大无督数集。 用 YouCook2 、 ViTT 视频字幕,随而微之。 吾示有良通用性,而强于诸学视频。', 'hi': 'खाना पकाने, कार रखरखाव, और घर की मरम्मत जैसे विशिष्ट हाथों पर कौशल सीखना तेजी से अनुदेशात्मक वीडियो के माध्यम से होता है। इस तरह के वीडियो के साथ उपयोगकर्ता अनुभव को मेटा-जानकारी जैसे कि शामिल मुख्य चरणों के लिए समय-मुद्रांकित एनोटेशन द्वारा बेहतर बनाने के लिए जाना जाता है। स्वचालित रूप से इस तरह के एनोटेशन उत्पन्न करना चुनौतीपूर्ण है, और हम यहां दो प्रासंगिक योगदानों का वर्णन करते हैं। सबसे पहले, हम एक नया घने वीडियो कैप्शनिंग डेटासेट, वीडियो टाइमलाइन टैग (ViTT) का निर्माण और रिलीज करते हैं, जिसमें समय-मुद्रांकित एनोटेशन के साथ विभिन्न प्रकार के अनुदेशात्मक वीडियो शामिल हैं। दूसरा, हम कई बहुआयामी अनुक्रम-से-अनुक्रम प्रीट्रेनिंग रणनीतियों का पता लगाते हैं जो वीडियो और कैप्शन जैसे ग्रंथों के बड़े असुरक्षित डेटासेट का लाभ उठाते हैं। हम Pretrain और बाद में दोनों YouCook2 और ViTT का उपयोग कर घने वीडियो कैप्शनिंग मॉडल finetune. हम दिखाते हैं कि इस तरह के मॉडल अच्छी तरह से सामान्यीकृत होते हैं और विभिन्न प्रकार के अनुदेशात्मक वीडियो पर मजबूत होते हैं।', 'ga': "Tarlaíonn sé níos mó agus níos mó scileanna praiticiúla a fhoghlaim mar chócaireacht, cothabháil carranna agus deisiúcháin tí trí fhíseáin teagaisc. Is eol go bhfeabhsaítear eispéireas an úsáideora le físeáin dá leithéid trí mheitifhaisnéis ar nós nótaí a bhfuil stampa ama orthu do na príomhchéimeanna atá i gceist. Tá sé dúshlánach nótaí den sórt sin a ghiniúint go huathoibríoch, agus déanaimid cur síos anseo ar dhá ionchur ábhartha. Ar an gcéad dul síos, déanaimid agus scaoilimid tacar sonraí dlúth fotheidealaithe físe nua, Clibeanna Amlíne Físe (ViTT), ina mbeidh éagsúlacht d’fhíseáin teagaisc mar aon le nótaí le stampa ama orthu. Ar an dara dul síos, déanaimid iniúchadh ar roinnt straitéisí réamhoiliúna ilmhódacha seicheamh-go-seicheamh a ghiaráil tacair shonraí móra gan mhaoirseacht d'fhíseáin agus de théacsanna cosúil le fotheideal. Déanaimid réamhthraenáil agus mionchoigeartú ar mhúnlaí dlúthfhotheidealaithe fístéipeanna ag baint úsáide as YouCook2 agus ViTT araon. Léirímid go ginearáltaíonn samhlacha den sórt sin go maith agus go bhfuil siad láidir thar raon leathan d’fhíseáin teagaisc.", 'el': 'Η εκμάθηση συγκεκριμένων πρακτικών δεξιοτήτων όπως μαγείρεμα, συντήρηση αυτοκινήτων και επισκευές στο σπίτι γίνεται όλο και περισσότερο μέσω εκπαιδευτικών βίντεο. Η εμπειρία χρήστη με τέτοια βίντεο είναι γνωστό ότι βελτιώνεται με μετα-πληροφορίες, όπως σχόλια με χρονοσφραγίδα για τα κύρια βήματα που εμπλέκονται. Η αυτόματη δημιουργία τέτοιων σχολίων αποτελεί πρόκληση και περιγράφουμε εδώ δύο σχετικές συνεισφορές. Αρχικά, κατασκευάζουμε και κυκλοφορούμε ένα νέο πυκνό σύνολο δεδομένων λεζάντας βίντεο, που περιλαμβάνει μια ποικιλία εκπαιδευτικών βίντεο μαζί με σχόλια με χρονοσφραγίδα. Δεύτερον, εξερευνούμε διάφορες πολυπροπικές στρατηγικές προετοιμασίας ακολουθίας σε ακολουθία που αξιοποιούν μεγάλα, χωρίς επίβλεψη σύνολα δεδομένων βίντεο και κειμένων που μοιάζουν με λεζάντες. Προετοιμάζουμε και στη συνέχεια συντονίζουμε πυκνά μοντέλα λεζάντας βίντεο χρησιμοποιώντας τόσο το YouCook2 όσο και το ViTT. Δείχνουμε ότι τέτοια μοντέλα γενικεύονται καλά και είναι ανθεκτικά σε μια μεγάλη ποικιλία εκπαιδευτικών βίντεο.', 'hu': 'Az olyan speciális gyakorlati készségek elsajátítása, mint a főzés, az autókarbantartás és az otthoni javítás egyre inkább oktatási videók segítségével történik. Az ilyen videókkal kapcsolatos felhasználói élményt ismert metainformációkkal javítják, mint például az időbélyegzős megjegyzések az érintett fő lépésekhez. Az ilyen megjegyzések automatikus generálása kihívást jelent, és itt két releváns hozzájárulást írunk le. Először is létrehozunk és kiadunk egy új, sűrű videofeliratozó adatkészletet, a Video Timeline Tags (ViTT), amely különböző oktatási videókat és időbélyegzős jegyzeteket tartalmaz. Másodszor számos multimodális szekvencia-sorrend előkészítési stratégiát vizsgálunk fel, amelyek nagy, felügyelet nélküli, videókból és feliratszerű szövegekből álló adatkészleteket használnak. A YouCook2 és a ViTT segítségével előkészítjük és finomhangoljuk a sűrű videofeliratozási modelleket. Megmutatjuk, hogy az ilyen modellek jól általánosítanak és robusztusak a különböző oktatási videók széles választékában.', 'ka': 'სწავლება განსაკუთრებული ხელსაწყოთა მეცნიერებები, როგორც საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი ვიდეოებით. მომხმარებელი გამოცდილობა ამ ვიდეოებით უცნობიან, რომ მეტა- ინფორმაციის გამოსახულება, როგორც დროს- სტანტირებულია ანოტაციები მნიშვნელოვანი ნაწილეში. ასეთი ნიოტაციების შექმნა ავტომატურად შესაძლებელია, და ჩვენ აქ აღწერეთ ორი მნიშვნელოვანი დამატება. პირველი, ჩვენ კონტრუქტურაცით და გაუშვებთ ახალი სამყარო ვიდეო შესახებ თარიღები, ვიდეო სამყარო ტეგიები (ViTT), რომელიც განსხვავებული ინსტრუქტურაციული ვიდეოები ერთად, რომე მეორე, ჩვენ ვიყვანეთ რამდენიმე მულტიმოდიალური სერექცია-დან სერექცია სტრატიგიები, რომლებიც დიდი არსერექტირებულ მონაცემები ვიდეოების და სერექციის ტექსტის შესახებ ჩვენ შემდეგ გავაკეთებთ და შემდეგ გავაკეთებთ ძალიან ძალიან კოკ2 და ViTT-ის გამოყენებული ვიდეო კაპუციაციის მოდელები. ჩვენ ჩვენ აჩვენებთ, რომ ასეთი მოდელები წარმოადგენიან და უფრო ძალიან განსხვავებული ინსტრუქციალური ვიდეოებით.', 'it': "Imparare specifiche abilità pratiche come cucinare, manutenzione auto e riparazioni domestiche avviene sempre più attraverso video didattici. L'esperienza utente con tali video è nota per essere migliorata da meta-informazioni come annotazioni con timestamp per i passaggi principali coinvolti. Generare automaticamente tali annotazioni è difficile, e qui descriviamo due contributi rilevanti. In primo luogo, costruiamo e rilasciamo un nuovo denso set di dati per la didascalia video, Video Timeline Tags (ViTT), che include una varietà di video didattici insieme a annotazioni cronometrate. In secondo luogo, esploriamo diverse strategie multimodali di pretraining sequenza-sequenza che sfruttano grandi set di dati non supervisionati di video e testi simili a didascalie. Prepariamo e successivamente finiamo modelli di didascalie video densi utilizzando sia YouCook2 che ViTT. Mostriamo che tali modelli generalizzano bene e sono robusti su un'ampia varietà di video didattici.", 'kk': 'Мысалы, мекен сақтау және мекен түзетулері мәліметті видео арқылы көптеген көптеген көптеген құрылғыларды үйрену. Бұл видеолордың пайдаланушылардың тәжірибесі негізгі қадамдар үшін уақыт белгілеген мәліметтермен жақсартылады. Бұл мәліметтерді автоматты түрде жасау көмекшілікті болады. Біз осында екі қатынасыз көмекшілігін таңдаймыз. Біріншіден, біз жаңа тұрақты видео айдарындағы деректер жиынын құру және шығару, видео уақыт сызығының тегтері (ViTT), уақыт белгілерімен бірге бірнеше мәлімет бейнелерін көрсетеді. Екіншіден, біз бірнеше көп модельді реттеу-реттеу стратегияларын зерттеп, бұл үлкен видео және айдарлар секілді мәтіндердің деректер жиындарын көмектеседі. Біз YouCook2 және ViTT қолданатын тең видео айдарының үлгілерін өзгертеміз. Бұл моделдер жалпы түрде жақсы болып, көптеген бірнеше мәлімет бейнелерін көптеген.', 'ms': 'Belajar keterampilan tangan-pada khusus seperti memasak, penyelenggaran kereta, dan perbaikan rumah semakin berlaku melalui video arahan. Pengalaman pengguna dengan video tersebut diketahui untuk diperbaiki oleh maklumat meta seperti anotasi stempel masa untuk langkah utama yang terlibat. Menjana anotasi seperti ini secara automatik adalah menantang, dan kami menggambarkan di sini dua kontribusi yang berkaitan. Pertama, kita membina dan melepaskan set data captioning video tebal baru, Tag Timeline Video (ViTT), yang mengandungi pelbagai video arahan bersama dengan anotasi-stempel masa. Kedua, kami mengeksplorasi beberapa strategi pencegahan rangkaian-ke-rangkaian multimodal yang mempengaruhi set data besar tidak diawasi video dan teks seperti tajuk. Kami berlatih dan kemudian menyesuaikan model captioning video yang padat menggunakan YouCook2 dan ViTT. We show that such models generalize well and are robust over a wide variety of instructional videos.', 'ml': 'പാചകം, കാറിന്റെ മേല്\u200dനോട്ടത്തിനും വീട്ടിലേക്കുള്ള തിരിച്ചറിവുകള്\u200d കൂടുതല്\u200d സംഭവിക്കുന്നു. ഇതുപോലുള്ള വീഡിയോകളിലുള്ള ഉപയോക്താവിന്റെ അനുഭവങ്ങള്\u200d മെറ്റി- വിവരങ്ങള്\u200d മുന്\u200dകൂട്ടുന്നതാണു് എന്നു് അറിയുന്നു ഇങ്ങനെയുള്ള അഭിപ്രായം സൃഷ്ടിക്കുന്നത് സ്വയം വിലപാടാണ്. നമ്മളിവിടെ രണ്ട് പ്രധാനപ്പെട്ട വിവരങ്ങള ആദ്യം, ഞങ്ങള്\u200d ഒരു പുതിയ വീഡിയോ പിടികൂടുന്ന ഡാറ്റാസെറ്റ്, വിഡിയോ ടൈമെലിന്\u200d ടാഗുകള്\u200d (വിടിടിഐ), ഒരു പുതിയ വീഡിയോ നിര്\u200dമ്മിക്കുകയും, സമയത്തിന രണ്ടാമതായി, നമ്മള്\u200d പല മുള്\u200dട്ടിമോഡല്\u200d സെക്കന്\u200dസിന്\u200dറ് മുമ്പ് വീണ്ടെടുക്കുന്ന യുദ്ധങ്ങള്\u200d പരിശോധിക്കുന്നു. അത് വലിയ സംരക്ഷിതമായ വീഡി നമ്മള്\u200d മഴ പെയ്യുന്നു, പിന്നീട് വീഡിയോ പിടിക്കുന്ന മോഡലുകള്\u200d യൂകുക്ക് 2 വിടിറ്റി ഉപയോഗിക്കുന്നു. നമ്മള്\u200d കാണിക്കുന്നത് ഇത്തരം മോഡലുകള്\u200d നല്ലത് സൃഷ്ടിക്കുന്നു എന്നും വ്യത്യസ്ത വീഡിയോകളില്\u200d കൊണ്ട് കൊണ്', 'lt': 'Mokymasis konkrečiais praktiniais įgūdžiais, pavyzdžiui, virtuva, automobilių techninė priežiūra ir namų remontas vis dažniau vyksta per mokymo vaizdo įrašus. Žinoma, kad tokių vaizdo įrašų naudojimo patirtis pagerėja metainformacija, pavyzdžiui, svarbiausių susijusių žingsnių užrašai su laiko antspaudu. Tokių anotacijų sukūrimas automatiškai yra sudėtingas, ir čia apibūdinami du svarbūs įnašai. First, we construct and release a new dense video captioning dataset, Video Timeline Tags (ViTT), featuring a variety of instructional videos together with time-stamped annotations.  Second, we explore several multimodal sequence-to-sequence pretraining strategies that leverage large unsupervised datasets of videos and caption-like texts.  Mes pradedame mokyti ir vėliau tobuliname tankius vaizdo įrašų modelius naudojant YouCook2 ir ViTT. Mes rodome, kad tokie modeliai gerai paplitę ir yra tvirti įvairiuose mokymo vaizdo įrašuose.', 'mk': 'Учењето на специфични вештини како што се готвењето, одржувањето на автомобилите и домашните поправки се сé повеќе се случува преку инструкционални видеа. Познато е дека искуството на корисникот со ваквите видеа е подобрено со метаинформации како што се анотациите со временски печати за главните чекори кои се вклучени. Генерирањето на вакви анотации автоматски е предизвикувачки, а ние овде опишуваме два релевантни придонеси. Прво, конструираме и објавуваме нов груб видео нацртеж на податоци, Video Timeline Tags (ViTT), со различни инструкционални видео заедно со временски означувања. Второ, истражуваме неколку мултимодилни стратегии за претренирање од секвенца до секвенца кои влијаат на големи ненадгледувани податоци на видеа и тексти слични на наслов. Предоаѓаме и потоа ги финираме густите видео-насловни модели користејќи и YouCook2 и ViTT. Ние покажуваме дека ваквите модели се генерализираат добро и се силни во врска со широка разлика на инструкционални видеа.', 'mt': "Learning specific hands-on skills such as cooking, car maintenance, and home repairs increasingly happens via instructional videos.  L-esperjenza tal-utent b’vidjows bħal dawn hija magħrufa li tittejjeb permezz ta’ meta-informazzjoni bħal annotazzjonijiet bit-timbru tal-ħin għall-passi ewlenin involuti. Il-ġenerazzjoni ta’ annotazzjonijiet bħal dawn awtomatikament hija sfida, u hawnhekk niddeskrivu żewġ kontribuzzjonijiet rilevanti. L-ewwel nett, a ħna nibnu u nirrilaxxaw sett ta’ dejta ġdid dens tal-intestaturi tal-vidjo, Tags tal-Linja taż-Żmien tal-Vidjo (ViTT), b’varjetà ta’ vidjo ta’ tagħlim flimkien ma’ annotazzjonijiet bit-timbru tal-ħin. It-tieni nett, qed nesploraw diversi strateġiji multimodali ta’ taħriġ minn sekwenza għal sekwenza li jagħtu spinta lil settijiet kbar ta’ dejta mhux sorveljati ta’ vidjows u testi simili għall-intestaturi. Aħna nħarrġu minn qabel u sussegwentement nidfinaw mudelli densi ta' video captioning bl-użu kemm ta' YouCook2 kif ukoll ta' ViTT. Aħna nuru li mudelli bħal dawn jiġġeneralizzaw tajjeb u huma robusti fuq varjetà wiesgħa ta’ vidjows ta’ tagħlim.", 'pl': 'Nauka konkretnych umiejętności praktycznych, takich jak gotowanie, konserwacja samochodu i naprawa domu coraz częściej odbywa się za pośrednictwem filmów instrukcyjnych. Doświadczenie użytkownika z takimi filmami jest wiadomo, że poprawiają metainformacje, takie jak adnotacje z znacznikiem czasu dla głównych kroków. Automatyczne generowanie takich adnotacji jest wyzwaniem i opisujemy tutaj dwa istotne wkłady. Najpierw budujemy i wydajemy nowy gęsty zestaw danych dotyczących napisów wideo, Video Timeline Tags (ViTT), zawierający różnorodne filmy instrukcyjne wraz z adnotacjami z znacznikiem czasu. Po drugie, badamy kilka multimodalnych strategii wstępnego treningu sekwencji do sekwencji, które wykorzystują duże zbiory danych wideo i tekstów podobnych do napisów. Wstępnie trenujemy, a następnie dopracowujemy gęste modele podpisów wideo za pomocą zarówno YouCook2, jak i ViTT. Pokazujemy, że takie modele dobrze uogólniają i są solidne w szerokiej gamie filmów instrukcyjnych.', 'no': 'Læring av spesifikke handlingar, slik som kobling, bilretningar og heimsrettingar, skjer større med instruksjonsvideoar. Brukaropplevelsen med slike videoar er kjent til å vera forbetra av metainformasjon, som tidsstrykk notasjonar for dei viktigste stegane som er involvert. Oppretting av slike notasjonar er vanskeleg automatisk, og vi beskriver her to relevante bidragar. Først konstruerer vi og slepp ein ny tett video-tittelsett, videotidslinjemerker (ViTT), som inneheld mange instruksjonsvideoar saman med tidstamperte notasjonar. Andre, vi undersøker fleire fleire fleire sekvens-til-sekvens-trekkingsstrategier som leverer store ikkje-oppretta datasett av videoar og tekst som liknar tittel. Vi prøver og følgjande finetune tette videotittelmodeller med både YouCook2 og ViTT. Vi viser at slike modeller generelliserer godt og er kraftig over ein stor forskjellig instruksjonsvideoar.', 'mn': 'Холбоо хийх, машины хамгаалах, гэр бүлийн засах чадваруудыг сурах нь багшлах бичлэгээр нэмэгдүүлдэг. Ийм бичлэгүүдийн хэрэглэгчдийн туршлага нь цаг хугацааны хамгийн чухал алхам дээр нээлттэй мэдээллээр сайжруулагддаг. Ийм санаануудыг автоматаар бий болгох нь хэцүү. Бид энд хоёр хамааралтай нөлөөлөлийг тайлбарлаж байна. Эхлээд бид шинэ жинхэнэ бичлэгийн хэвлэлийн өгөгдлийн санг, Видео цаг хугацааны тегт (ViTT) бүтээж, цаг хугацааны хэвлэлтэй олон багшийн бичлэгүүдийг харуулж байна. Хоёрдугаар, бид олон моделийн дарааллаас дарааллаар дамжуулах стратегийг судалж байна. Энэ нь бичлэг болон зураг шиг бичлэгүүдийг дэмжиж чаддаггүй өгөгдлийн сангуудыг ашигладаг. Ингээд бид YouCook2 болон ViTT хоёуланг ашиглан жигхэн бичлэгийн загваруудыг сайжруулдаг. Бид ийм загваруудыг ерөнхийлөгч, олон төрлийн багш нарын бичлэгээр хүчтэй харуулж байна.', 'ro': 'Învățarea abilităților practice specifice, cum ar fi gătitul, întreținerea mașinilor și reparațiile la domiciliu se întâmplă din ce în ce mai mult prin intermediul videoclipurilor instrucționale. Experiența utilizatorului cu astfel de videoclipuri este cunoscută pentru a fi îmbunătățită prin meta-informații, cum ar fi adnotările cu timp pentru pașii principali implicați. Generarea automată a unor astfel de adnotări este o provocare și descriem aici două contribuții relevante. În primul rând, construim și lansăm un nou set de date dense de subtitrare video, Video Timeline Tags (ViTT), prezentând o varietate de videoclipuri instrucționale împreună cu adnotări cu timp. În al doilea rând, explorăm mai multe strategii multimodale de pregătire secvență-secvență, care utilizează seturi mari de date nesupravegheate de videoclipuri și texte asemănătoare cu titlurile. Pregătim și ulterior finuționăm modele dense de subtitrare video folosind atât YouCook2, cât și ViTT. Noi arătăm că astfel de modele generalizează bine și sunt robuste pe o gamă largă de videoclipuri instrucționale.', 'sr': 'Učenje specifičnih vještina na rukama poput kuhanja, održavanja automobila i popravka kuće se sve više dešava putem instrukcijskih snimaka. Korisničko iskustvo sa takvim video je poznato da se poboljšava metainformacijama kao što su navođene na vrijeme oznake za glavne korake uključene. Ovde opisujemo dva relevantna doprinosa. Prvo, izgradimo i oslobodimo nove guste video snimke podataka, Video Timeline Tags (ViTT), koja uključuje razne instruktivne snimke zajedno sa time-markiranim annotacijom. Drugo, istražujemo nekoliko multimodalnih strategija pretvaranja sekvence do sekvence koje utiču na velike neodređene podatke video i tekstove slične na kapciju. Pripremamo se i nakon toga finetune guste video snimke koji koriste i YouCook2 i ViTT. Pokazujemo da se takvi modeli dobro generalizuju i jači nad širom raznim instrukcijskim video.', 'so': 'Waxbarashada aqoonta gacmaha gaarka ah sida cuntada cuntada, masruufka baabuurka iyo hagitaanka guryaha waxaa ku socda fiidiyowyada hagitaanka. Aqoonshaha isticmaalayaasha fiidiyowyadaas waxaa loo yaqaan in la kordhinayo macluumaadka meta-meta, tusaale ahaan baaraandegista waqtiga lagu isticmaalayo tallaabooyinka aasaasiga ah. Horay u imaanshaha dhibaatooyinka caynkaas ah waa dhibaatooyin, halkan waxaynu ku qoraynaa laba qayb oo muhiim ah. Marka ugu horeysa waxaynu dhisaynaa oo u dirnaa fiidiyowga hoose oo cusub oo lagu barto taariikhda, Video Timeline tags (ViTT), waxaana sameynaynaa fiidiyooyin kala duduwan oo la hagaajiyey iyo waraaqaha waqtiga la soconayo. Second, waxaynu baaraynaa qalabka roobka oo badan oo kala midab ah, kaasoo soo saara qoraal aad u badan oo aan la ilaalinayn fiidiyowyo iyo qoraal la mid ah. Waxaynu iska daabacnaa fiidiyowga hoose ee ugu dambeeya sameynta sameynta YouCook2 iyo ViTT. We show that such models generalize well and are robust over a wide variety of instructional videos.', 'sv': 'Att lära sig specifika praktiska färdigheter som matlagning, bilunderhåll och hemreparationer sker allt oftare via instruktionsvideor. Användarupplevelsen med sådana videor är känd för att förbättras genom metainformation som tidsstämplade anteckningar för de viktigaste stegen. Att skapa sådana anteckningar automatiskt är utmanande, och vi beskriver här två relevanta bidrag. Först konstruerar och släpper vi ett nytt tätt dataset för bildtexter, Video Timeline Tags (ViTT), med en mängd olika instruktionsvideor tillsammans med tidsstämplade anteckningar. För det andra utforskar vi flera multimodala sekvens-till-sekvens-förberedande strategier som utnyttjar stora oövervakade datauppsättningar av videor och bildtexter. Vi förbereder och finjusterar sedan täta bildtextningsmodeller med både YouCook2 och ViTT. Vi visar att sådana modeller generaliserar väl och är robusta över en mängd olika instruktionsvideor.', 'si': 'විශේෂ විශේෂ විද්\u200dයාවක් අත් අත් අත් අත් අත් අත් අත් අත්තර ඉගෙන ගන්න, කාර් ආරක්ෂාව, හා ගෙදර සුදුසුම මෙතන වීඩියෝ එක්ක ප්\u200dරයෝජකය අභ්\u200dයාපකය අභ්\u200dයාගයක් දන්නවා මෙටා- තොරතුරු වලින් වැඩි කරනවා වගේම වෙලාව ස්ටැම අනිවාර්යයෙන් ස්වයංක්\u200dරියාවිතයෙන් සැකසුම් කරන්න ප්\u200dරශ්නයක් තියෙනවා, අපි මෙතන සම්බන්ධ සම්බ මුලින්ම, අපි නිර්මාණය සහ අළුත් වීඩියෝ කැප්සයින් දත්ත සැට, වීඩියෝ කාලයේ ටැග් (ViTT), විවිධිපත් වීඩියෝ සමග විවිධිපත් ව දෙවෙනි විදියට, අපි වීඩියෝ සහ කැප්ටන් වගේ විදියෝ සඳහා විදියෝ සහ පැත්තක් වගේ ලොකු නැති දත්ත සෙට් ප්\u200dරශ්නය කරනවා. අපි පස්සේ ප්\u200dරතිස්ථානය කරනවා ඒ වගේම ප්\u200dරතිස්ථානය වීඩියෝ කැප්සියෝ මොඩේල්ස් එක්ක ප්\u200dරයෝජනය කරනවා  අපි පෙන්වන්නේ ඒ වගේ මෝඩේල් සාමාන්\u200dයයෙන් හොඳයි කියලා, ඒ වගේම ප්\u200dරශ්නයක් විශේෂ වීඩියෝ වලට', 'ta': 'குறிப்பிட்ட கைகள் பற்றி கற்றுக் கொள்வது, கார் பராமரிப்பு, மற்றும் வீட்டின் மீட்டு மீட்டுகள் இன்னும் கட்டளைப்படுத்த முக்கிய அடிப்படைகளுக்கான நேரத்தில் மாற்றப்பட்ட குறிப்புகள் போன்ற வீடியோக்களுடன் பயனர் அனுபவம் மேம்படுத்தப்படும் என அறி இத்தகைய அறிவிப்புகளை உருவாக்குதல் தானாகவே சவால் செய்கிறது, நாம் இங்கே இரண்டு தொடர்பு பங்களை விவரிக்கிறோம முதலில், நாம் ஒரு புதிய குழுவான வீடியோ பிடிப்பு தகவல் அமைப்பை உருவாக்கி வெளியிடுகிறோம், வீடியோ டேமில்லைன் ஒட்டுகள் (விடிடிடி), பல்வேறு  இரண்டாவது, நாம் பல்வேறு தொடர்ச்சி-அடுக்கு வரிசையில் முன்னோக்கி வெளியேறும் திட்டங்களை தேடுகிறோம். அது பெரிய பாதுகாப்பாக்கப்படாத தக YouCook2 மற்றும் ViTT பயன்படுத்தி நாம் மழை மற்றும் பின்னர் துளைவான காணொளி பிடிப்பு மாதிரிகளை மாற்றுகிறோம். இத்தகைய மாதிரிகள் நன்றாக உருவாக்குகின்றன மற்றும் பல்வேறு கட்டளைப்படுத்தப்பட்ட காட்சியோவின் மீது கற்று', 'ur': 'ویڈیو کے ذریعے مضبوط ہاتھوں کی تعلیمات کی تعلیم کی جاتی ہے جیسے cooking, car maintenance, اور گھر کی اصلاح کی جاتی ہے۔ ایسے ویڈیوں کے ساتھ کارساز کا تجربہ معلوم ہوتا ہے کہ مٹا-معلومات کے ذریعہ برابری کی جاتی ہے جیسے وقت-stamped انٹیٹیوں کے ذریعہ مشترک قدم کے لئے۔ اور ہم یہاں دو معاملہ اضافہ کریں گے۔ پہلے ہم نے ایک نئی گہری ویڈیو کاپٹینگ ڈیٹ سٹ، ویڈیو تایمیلین ٹاگ (ViTT) بنایا اور آزاد کردیا، ایک طرح طرح طرح طرح طرح طرح طرح طرح طرح کی ویڈیوں کے ساتھ تایمپ ڈیٹ سٹ، ویڈیو تایمیلین ٹ دوسرا، ہم بہت سی مثالی مثالی سفارش کریں گے جو ویڈیوں اور کپٹن جیسی ٹیکسٹوں کے بڑے غیر محفوظ ڈاٹ سٹوں کو اثر دیتے ہیں۔ ہم یو کوک 2 اور ویٹ کے مطابق ایک گہرے ویڈیو کیپٹیونٹ موڈل کو آراستہ کرتے ہیں۔ ہم دکھاتے ہیں کہ ایسے موڈل اچھے طریقے سے اچھے طریقے سے اچھے طریقے سے اچھے طریقے سے کامل ہیں', 'uz': "Kok'k, mashinani davom etish va uy taʼminlovchilari yordamida foydalanadi. Name Bu tajribalarni avtomatik yaratish avtomatik murakkab qiladi, va biz bu yerda ikkita muhim qandaydir qaramamiz. Birinchisi, biz maʼlumot bazasini olib tashlash va yangi qiyin video yozuvchini chiqaramiz va video taymaviy teglarini (ViTT) bilan bir nechta taʼminlovchi video yozuvlar bilan bir xil taʼminlovchi taʼminlovchilar bilan boshlanamiz. Ikkinchi so'zda, biz bir necha ko'pchilik seksiyatlarni o'rganamiz va o'xshash textlarni ko'rib chiqarish strategiyalarini o'rganamiz. We pretrain and subsequently finetune dense video captioning models using both YouCook2 and ViTT.  Biz shu modellar yaxshi narsa yaratishni ko'rsamiz va ko'pchilik taʼminlovchi video'larni ko'payapmiz.", 'vi': 'Học những kỹ năng cụ thể như nấu ăn, bảo dưỡng xe hơi và sửa nhà ngày càng phát triển qua các đoạn phim hướng dẫn. Người dùng có kinh nghiệm với những video này được biết đến có thể cải thiện bằng các meta-thông tin như ghi chú thời gian cho các bước chính liên quan. Tự động tạo chú thích như vậy là khó khăn, và ở đây chúng tôi mô tả hai sự đóng góp liên quan. Đầu tiên, chúng ta xây dựng và phát hành một tập tin video dày đặc mới, Thẻ Thiết bị Thời Gian (Chơi video Timeline) với một loạt các chú thích được in thời gian. Thứ hai, chúng ta sẽ tìm hiểu các chiến lược trước mưa đa chiều nhiều cách sắp xếp để tạo lợi thế cho các tập tin dữ liệu lớn không giám sát. Chúng ta sẽ sử dụng sản phẩm video dày đặc dùng cả YouCook2 và Vimter. Chúng tôi cho thấy những mô hình này rộng rãi và mạnh mẽ hơn rất nhiều ảnh hướng dẫn.', 'bg': 'Научаването на специфични практически умения като готвене, поддръжка на автомобили и домашни ремонти все повече се случва чрез видеоклипове с инструкции. Известно е, че потребителското преживяване с такива видеоклипове се подобрява чрез мета-информация, като например анотации с времеви печати за основните стъпки. Генерирането на такива анотации автоматично е предизвикателство и тук описваме два съответни приноса. Първо, ние конструираме и пускаме нов плътен набор от данни за надписи на видео, включващ разнообразие от инструкционни видеоклипове заедно с бележки по време. Второ, изследваме няколко мултимодални стратегии за предварително обучение от последователност към последователност, които използват големи ненадзорни набори от данни от видеоклипове и текстове, подобни на надписи. Предварително тренираме и впоследствие финализираме модели за плътно видео надписване, използвайки както YouCook2, така и ViTT. Показваме, че такива модели се обобщават добре и са здрави върху голямо разнообразие от инструкционни видеоклипове.', 'hr': 'Učenje specifičnih vještina na rukama poput kuhanja, održavanja automobila i popravka kuće se sve više događa putem instrukcijskih snimaka. Iskustvo korisnika s takvim snimkama poznato je da se poboljšava metainformacijama kao što su vrijeme oznake za glavne korake uključene. Proizvedenje takvih annotacija automatski je izazovno, a ovdje opisujemo dva relevantna doprinosa. Prvo, izgradimo i oslobodimo novu gustu video snimku podataka, Video Timeline Tags (ViTT), koja prikazuje razne instruktivne snimke zajedno s time-markiranim annotacijom. Drugo, istražujemo nekoliko multimodalnih strategija pretvaranja sekvence do sekvence koje utječu na velike neodređene podatke snimaka i teksta sličnih na kapciju. Pripremamo se i nakon toga finetune guste video snimke koji koriste i YouCook2 i ViTT. Pokazujemo da se takvi modeli dobro generaliziraju i jači nad širom raznim instrukcijskim snimkama.', 'da': 'At lære specifikke praktiske færdigheder som madlavning, bilvedligeholdelse og reparationer i hjemmet sker i stigende grad via instruktionsvideoer. Brugeroplevelsen med sådanne videoer er kendt for at blive forbedret af meta-oplysninger såsom tidsstemplede annotationer til de vigtigste trin, der er involveret. Det er udfordrende at generere sådanne noteringer automatisk, og vi beskriver her to relevante bidrag. For det første konstruerer og frigiver vi et nyt tæt datasæt til videobilledtekster, Video Timeline Tags (ViTT), der indeholder en række instruktionsvideoer sammen med tidsstemplede noter. For det andet undersøger vi flere multimodale sekvens-til-sekvens forudtræningsstrategier, der udnytter store datasæt af videoer og billedtekstlignende tekster uden opsyn. Vi forbereder og finjusterer efterfølgende tætte videobilledtekstmodeller ved hjælp af både YouCook2 og ViTT. Vi viser, at sådanne modeller generaliserer godt og er robuste over en bred vifte af instruktionsvideoer.', 'nl': "Het leren van specifieke hands-on vaardigheden zoals koken, autoonderhoud en thuisreparaties gebeurt steeds vaker via instructievideo's. Het is bekend dat de gebruikerservaring met dergelijke video's wordt verbeterd door meta-informatie zoals tijdstempel annotaties voor de belangrijkste stappen. Het automatisch genereren van dergelijke annotaties is een uitdaging en we beschrijven hier twee relevante bijdragen. Eerst bouwen en publiceren we een nieuwe dichte dataset voor video-ondertiteling, Video Timeline Tags (ViTT), met een verscheidenheid aan instructievideo's samen met tijdmarkeringen. Ten tweede onderzoeken we verschillende multimodale sequence-to-sequence pretraining strategieën die gebruik maken van grote onbeheerde datasets van video's en bijschriftachtige teksten. We trainen en finetunen dichte video ondertitelingsmodellen met zowel YouCook2 als ViTT. We laten zien dat dergelijke modellen goed generaliseren en robuust zijn over een breed scala aan instructievideo's.", 'de': 'Das Erlernen spezifischer praktischer Fähigkeiten wie Kochen, Autowartung und Hausreparaturen erfolgt zunehmend über Schulungsvideos. Die Benutzererfahrung mit solchen Videos wird bekanntlich durch Metainformationen wie Zeitstempel-Anmerkungen für die wichtigsten Schritte verbessert. Solche Anmerkungen automatisch zu generieren ist eine Herausforderung, und wir beschreiben hier zwei relevante Beiträge. Zunächst erstellen und veröffentlichen wir einen neuen, dichten Videobeschriftungsdatensatz, Video Timeline Tags (ViTT), der eine Vielzahl von Schulungsvideos zusammen mit Zeitstempel-Anmerkungen enthält. Zweitens untersuchen wir mehrere multimodale Sequenz-zu-Sequenz-Vortrainingsstrategien, die große, unbeaufsichtigte Datensätze von Videos und beschriftungsartigen Texten nutzen. Mit YouCook2 und ViTT bereiten wir dichte Untertitelmodelle vor und optimieren sie anschließend. Wir zeigen, dass solche Modelle gut verallgemeinern und robust sind über eine Vielzahl von Lehrvideos.', 'id': 'Belajar keterampilan tangan-pada spesifik seperti memasak, pemeliharaan mobil, dan perbaikan rumah semakin terjadi melalui video instruksional. Pengalaman pengguna dengan video tersebut dikenal untuk diperbaiki oleh meta-informasi seperti anotasi time-stamped untuk langkah utama yang terlibat. Membuat anotasi seperti itu secara otomatis adalah tantangan, dan kami menjelaskan di sini dua kontribusi relevan. Pertama, kami membangun dan melepaskan set data captioning video yang tebal, Tag Timeline Video (ViTT), yang mengandung berbagai video instruksional bersama dengan anotasi time-stamped. Kedua, kita mengeksplorasi beberapa strategi multimodal dari urutan ke urutan yang mengakibatkan set data besar yang tidak diawasi dari video dan teks seperti caption. Kami menggunakan YouCook2 dan ViTT. Kami menunjukkan bahwa model-model tersebut menggeneralisasi dengan baik dan kuat atas berbagai jenis video instruksional.', 'ko': '수업 영상을 통해 요리, 자동차 정비, 주택 수리 등 구체적인 실천 기술을 배우는 경우가 늘고 있다.모두가 알다시피 이런 영상의 사용자 체험은 메타데이터를 통해 개선될 수 있다. 예를 들어 관련된 주요 절차의 시간 스탬프 주석이다.이러한 주석을 자동으로 생성하는 것은 도전이다. 우리는 여기서 두 가지 관련 공헌을 묘사했다.우선, 우리는 각종 교학 영상과 시간 스탬프 주석을 특색으로 하는 새로운 밀집 영상 자막 데이터 세트 비디오 타임라인 태그를 구축하고 발표했다.그 다음에 우리는 몇 가지 다중모드 서열부터 서열 예훈련 전략을 연구했다. 이런 전략은 대량의 감독이 없는 영상 데이터 집합과 자막과 유사한 텍스트를 이용했다.우리는 YouCook2와 ViTT를 이용하여 밀집 영상 자막 모형을 예습한 후 미세하게 조정한다.우리는 이러한 모델이 매우 좋은 범위성을 가지고 있으며 각양각색의 교육 영상에서 매우 강한 노봉성을 가지고 있음을 증명했다.', 'sw': 'Kujifunza ujuzi maalum wa mikono kama vile chakula, usafiri wa gari, na mageuzi ya nyumbani yanaendelea kwa kiasi kikubwa kupitia video zinazoonyesha. Mtumiaji wa mtandao wa intaneti wenye video kama hizo wanafahamika kuboreshwa na taarifa za meta kama vile taarifa za muda zilizopangwa kwa hatua kuu zinazohusika. Kutengeneza matatizo haya kwa mara moja ni changamoto, na tunaelezea hapa michango mawili yanayohusiana. Kwanza, tunajenga na kuachia video mpya yenye uchunguzi wa taarifa, Video Tags za Timeline (ViTT), zinazoonyesha video mbalimbali za maelekezo pamoja na matangazo ya muda. Pili, tunatafuta mipango kadhaa ya mfululizo wa mfululizo wa mfululizo kwa mara nyingi za kutengeneza mipango ya mvua ambayo inatengeneza seti kubwa za video ambazo hazijaswi na maandishi yanayofanana. Tunafanya mvua na baadae vizuri vyenye picha za video kwa kutumia YouCook2 na ViTT. Tunaonyesha kuwa mifano hiyo inatengeneza vizuri na inavamiwa kwenye video mbalimbali za maelekezo.', 'fa': 'یاد گرفتن مهارت\u200cهای ویژه\u200cای مثل آشپزی، نگهبانی ماشین و تعمیر خانه\u200cها بیشتر با ویدئو\u200cهای آموزشی اتفاق می\u200cافتد. تجربه کاربر با چنین ویدئو شناخته می\u200cشود که توسط اطلاعات meta-information مثل اظهار زمان\u200cگذاری برای قدم\u200cهای اصلی درگیر می\u200cشوند. تولید این نوشته\u200cها به طور خودکار سخت\u200cکننده است، و ما اینجا دو دسترسی مربوط به توصیف می\u200cکنیم. اول، ما یک مجموعه داده\u200cهای عنوان ویدئو تند جدید را ساختیم و آزاد می\u200cکنیم، نقاشی\u200cهای زمان ویدئو (ViTT) که با توضیح\u200cهای زمان\u200cگذاری\u200cشده\u200cاند، گونه\u200cای از ویدئو\u200cهای آموزشی را مشخص می\u200cکنیم. دوم، ما تعدادی از استراتژی\u200cهای پیش\u200cگیری\u200cکننده\u200cهای مختلف مدل\u200cها را تحقیق می\u200cکنیم که مجموعه\u200cهای داده\u200cهای بزرگی از ویدئو\u200cها و متن\u200cهای شبیه به عنوان عنوان عنوان استراتژی\u200cهای پیش\u200cگیری می\u200cکنند. ما با استفاده از YouCook2 و ViTT مدل\u200cهای عنوان ویدئویی\u200cهای تند را پیش\u200cفرض می\u200cکنیم و بعدش نیکویی می\u200cکنیم. ما نشان می دهیم که این مدلها به طور کامل تولید می کنند و بر روی ویدئو های آموزشی مختلف قوی هستند.', 'tr': "Gowup, ulag taýýarlamagy ýaly ellerde takyk ukyplary öwrenmek we öý bejermeleri bilim wideoýlaryla köpräk boldy. Ullançy görkezilýän videolar bilen tejribeler meta-informasiýa görä gelişmelidir, nähili möhüm adılar üçin wagt stampeldyrylýan ýaly terjimeler bilen gelişmelidir. Bu ýaly täzelikleri otomatik mümkinçidir we biz bu ýerde iki möhüm täzelikleri tasvir edip görýäris. Ilkinji gezek, biz täze yoğun wideo kapsamçylygy taýýarlap, wideo zamanlygy tägleri (ViTT), zaman-stampeli duýdurmalar bilen birnäçe görkezilýän eğitim videolary taýýarlapdyk. Ikinjisi, biz birnäçe modal sequence-to-sequence pretraining strategiýalaryny keşif edýäris ki bu wideo we kelläp ýaly metinleri üçin önüne getirilmez Biz YouCook2 we ViTT'i kullanarak yoğun wideo çekişim modellerini ýazdyrýarys. Biz bu nusgalar gowy döredilýäni we birnäçe görnüş videolaryň üstünde kynçylykdygyny görkeýäris.", 'af': "Onderleer spesifieke hande-op kunstenaars soos koeking, car onderhouering en tuis herstellings wat vergroot gebeur word deur instruksieflike videos. Die gebruiker erfaring met sodanige videos is bekend om te verbeter deur meta-inligting soos tyd-stampeerde notasies vir die hoofstappe wat betrokke is. Skep sodanige notasies outomaties is aanvaardig, en ons beskrywe hier twee relevante bydraaghings. Eerste, ons konstrukteer en verlos 'n nuwe dens video titelsette datastel, Video Tydslyn etikette (ViTT), met 'n verskeie instruksieflike videos saam met tydsdrukke notasies. Tweede, ons ondersoek verskeie multimodale volgorde-na-sekwensierekwensiestrategies wat groot onondersoekte datastelle van videos en opskriftelyke teks verwyder. Ons trek en daarna finetune dens video-kapsiemodules met gebruik van beide YouCook2 en ViTT. Ons wys dat sulke modele goed genereer en is sterk oor 'n wyde verskillende instruksievideos.", 'sq': 'Mësimi i aftësive të caktuara të dorës, të tilla si kuzhinieri, mirëmbajtja e makinave dhe riparimi i shtëpisë ndodh gjithnjë e më shumë nëpërmjet videove mësuese. Përvoja e përdoruesit me videot e tilla është e njohur se përmirësohet nga meta-informacioni të tillë si anotacionet me timon kohor për hapat kryesorë të përfshira. Generating such annotations automatically is challenging, and we describe here two relevant contributions.  Së pari, ne ndërtojmë dhe lëshojmë një set të ri të dendur video titullimi të të dhënave, Video Timeline Tags (ViTT), duke paraqitur një shumëllojshmëri të videove mësuese së bashku me anotacionet me kohë. Së dyti, ne eksplorojmë disa strategji multimodale sekuencë-në-sekuencë të parastërvitjes që përdorin grupe të mëdha të dhënash të pazgjidhura të videove dhe teksteve të ngjashme me titujt. Ne paraqesim dhe më pas përmirësojmë modele të dendura video duke përdorur si YouCook2 ashtu edhe ViTT. Ne tregojmë se modelet e tilla gjeneralizohen mirë dhe janë të forta mbi një varietet të gjerë të videove mësuese.', 'am': 'እንደማጠፊያ፣ የመርከብ ማደሪያ እና የቤት ፍጥረት በተለያዩ ቪዲዮዎች በጥምቀት ይደረጋል፡፡ እንደዚህ ያሉ ቪዲዮዎች ያሉት ተጠቃሚው እውቀት ለመጠቀም የጠቅላላ ደረጃዎች እንደተጨማሪው ጊዜ-stamped annotations እንዲታወቅ ታወቃለች፡፡ እንደዚህ ያሉ ማስታወቂያውን በመፍጠር በራሱ አዋቂ ነው እናም በዚህ ሁለት ተቃውሞ አዋጅ እናሳውቃለን፡፡ መጀመሪያ፣ አዲስ ጥልቅ የቪዲዮ ድምፅ ማነሳት እና አዲስ ጥልቅ ድምፅ፣ የቪዲዮ ትምህርት መስኮቶች (ViTT)፣ በተጨማሪም በተጨማሪው የቪዲዮዎች እና በተጨማሪው ዘመን እና አሰናክሎችን እናደርጋለን፡፡ በሁለተኛው፣ ብዙ ብልሃት የውጤት ምርጫዎችን ለመፍጠር እናደርጋለን፡፡ በዩCook2 እና ቪቲ እና ጥልቅ የቪዲዮ አካባቢዎችን እናፍቃለን፡፡ እንደነዚህ ዓይነቶች መልካም እንዲያሳየቁ እናሳያቸዋለን እና በተለያዩ ልዩ ተግሳጽን ቪዲዮችን እንደተለብጠዋል፡፡', 'hy': 'Հասկացած հմտություններ սովորելը, ինչպիսիք են խոհարարությունը, մեքենայի պահպանությունը և տնային վերականգնումը, ավելի ու ավելի տեղի է ունենում դասավանդման տեսանյութերի միջոցով: Այսպիսի տեսահոլովակների հետ կապված օգտագործողների փորձը հայտնի է, որ բարելավվում է մետատեղեկատվության միջոցով, ինչպիսիք են օրինակ ժամանակի նշումները, որոնք ներառված են հիմնական քայլերի համար: Այսպիսի նկարագրություններ ավտոմատ ստեղծելը դժվար է, և մենք այստեղ նկարագրում ենք երկու կարևոր ներդրումներ: Առաջինը, մենք կառուցում ենք և հրապարակում ենք նոր խիստ վիդեո վերնագրման տվյալների համակարգ, Վիդեո Ժամանակի գծերի տախտակներ (ViT), որոնք ներկայացնում են տարբեր դասավանդման տեսահոլովակներ միասին ժամանակի վրա նշումների հետ: Երկրորդ, մենք ուսումնասիրում ենք մի քանի բազմամոդալ հաջորդականություններ հաջորդականությամբ նախապատրաստվող ռազմավարություններ, որոնք օգտագործում են հսկայական անվերահսկված տվյալների համակարգեր տեսանյութերի և վերնագրի նման տեքստների: We pretrain and subsequently finetune dense video captioning models using both YouCook2 and ViTT.  Մենք ցույց ենք տալիս, որ նման մոդելները լավ են ընդհանրացվում և ուժեղ են տարբեր դասավանդման տեսանյութերի ընթացքում:', 'az': 'Yeşiklik, maşın təmizlənməsi və evi təmizlənməsi kimi əl-üstü yeteneklikləri öyrənmək öyrənmək isə öyrənmək videoları vasitəsilə daha çox olar. Bütün videolar ilə istifadəçilər təcrübəsi, mövcud adımlar üçün vaxt-stamped notlara bənzər meta-məlumatları ilə yaxşılaşdırılır. Bu məlumatları avtomatik olaraq yaratmaq çətindir və biz burada iki məlumatlı qisməti tanımlıyıq. Birincisi, biz yeni yox video kapsiyası verilən qutusu, Video Timeline Tags (ViTT) inşa edir və yayındırırıq, zaman-stamped notları ilə birlikdə müxtəlif təhsil videoları göstərir. İkincisi, biz birkaç çox modal sequence-to-sequence pretraining stratejilərini keşfetirik ki, böyük müəyyən edilməmiş veri quruları videoya və başlıqlarına bənzər metinləri istifadə edir. Biz YouCook2 və ViTT ilə istifadə edən yox video captioning modellərini təmizləyirik. Biz bu modellərin çox yaxşı olduğunu göstəririk və çox müxtəlif öyrənim videoların üstündə qüvvətli olduğunu göstəririk.', 'ca': "Aprendre habilitats manuals específices com cuina, manutenció de cotxes i reparacions domèstiques passa cada cop més a través de vídeos instructius. És conegut que la experiència dels usuaris amb aquests vídeos es millora amb meta-informació com anotacions marcades amb temps per als pas principals involucrats. Generar aquestes anotacions automàticament és difícil, i aquí descrivim dues contribucions pertinents. En primer lloc, construïm i alliberam un nou conjunt de dades denses de captionització de vídeo, Etiquetes de Llinia del temps del vídeo (ViTT), amb una varietat de vídeos instructius juntament amb anotacions marcades amb temps. En segon lloc, explorem diverses estratègies multimodals de pràctica seqüència a seqüència que utilitzen grans conjunts de dades no supervisades de vídeos i textos similars a títulos. We pretrain and subsequently finetune dense video captioning models using both YouCook2 and ViTT.  Mostrem que aquests models s'generalitzen bé i són robustos en una gran varietat de vídeos instructius.", 'bs': 'Učenje specifičnih vještina na rukama poput kuhanja, održavanja automobila i popravka kuće se sve više dešava putem instrukcijskih snimaka. Korisničko iskustvo sa takvim snimkama se poznaje da se poboljšava metainformacijama kao što su navodi na vrijeme oznake za glavne korake uključene. Proizvedenje takvih annotacija automatski je izazovno, a ovdje opisujemo dva relevantna doprinosa. Prvo, izgradimo i oslobodimo nove guste video snimke podataka, Video Timeline Tags (ViTT), koja uključuje razne instruktivne snimke zajedno sa time-markiranim annotacijom. Drugo, istražujemo nekoliko multimodalnih strategija pretvaranja sekvence do sekvence koje utiču na velike neodređene podatke snimka i teksta sličnih na kapciju. Pripremamo se i nakon toga finetune guste video snimke koji koriste i YouCook2 i ViTT. Pokazujemo da se takvi modeli dobro generalizuju i jači nad širom raznim instrukcijskim snimkama.', 'cs': 'Učení se konkrétních praktických dovedností, jako je vaření, údržba automobilů a opravy domácnosti, stále častěji probíhá prostřednictvím instrukčních videí. Je známo, že uživatelský zážitek s takovými videa je zlepšen metainformacemi, jako jsou časové známky pro hlavní kroky. Automatické generování takových anotací je náročné a zde popisujeme dva relevantní příspěvky. Nejprve vytvoříme a uvolňujeme novou hustou datovou sadu titulků videa, Video Timeline Tags (ViTT), která obsahuje celou řadu instrukčních videí spolu s časovými poznámkami. Za druhé zkoumáme několik multimodálních strategií předškolení sekvence k sekvenci, které využívají velké datové sady videí a textů podobných titulkům. Předtřídíme a následně jemně ladíme husté video titulky pomocí YouCook2 i ViTT. Ukazujeme, že tyto modely se dobře zobecňují a jsou robustní v široké škále instrukčních videí.', 'fi': 'Erityisten käytännön taitojen oppiminen, kuten ruoanlaitto, auton huolto ja kodinkorjaus, tapahtuu yhä useammin opetusvideoilla. Tällaisten videoiden käyttökokemuksen tiedetään parantuvan metatiedoilla, kuten aikaleimaisilla huomautuksilla tärkeimmissä vaiheissa. Tällaisten huomautusten luominen automaattisesti on haastavaa, ja kuvaamme tässä kaksi olennaista vastausta. Ensin rakennamme ja julkaisemme uuden tiheän videokuvatekstitystiedoston, Video Timeline Tags (ViTT), joka sisältää erilaisia opetusvideoita ja aikaleimattuja merkintöjä. Toiseksi tutkimme useita multimodaalisia sekvenssistä sekvenssiin esikoulutusstrategioita, jotka hyödyntävät suuria valvomattomia videosarjoja ja tekstityksen kaltaisia tekstejä. Esivalmennamme ja sen jälkeen hienosäädämme tiheitä videokuvausmalleja sekä YouCook2:lla että ViTT:llä. Osoitamme, että tällaiset mallit yleistyvät hyvin ja ovat vankkoja monenlaisissa opetusvideoissa.', 'et': 'Spetsiifiliste praktiliste oskuste õppimine, nagu toiduvalmistamine, auto hooldus ja koduremont, toimub üha enam juhendavate videote kaudu. Teadaolevalt parandatakse selliste videote kasutajakogemust metateabega, näiteks ajatempliga märkmetega seotud peamiste sammude kohta. Selliste märkuste automaatne genereerimine on keeruline ja me kirjeldame siin kahte asjakohast panust. Esiteks ehitame ja avaldame uue tiheda video pealdiste andmekogumi, Video Timeline Sildid (ViTT), mis sisaldab erinevaid õppevideoid koos ajatempliga märgistustega. Teiseks uurime mitmeid multimodaalseid järjestusest järjestuseni eeltreeningu strateegiaid, mis kasutavad suuri järelevalveta andmekogumeid videotest ja pealdiste tekstidest. Me eeltreenime ja seejärel peenestame tihedate videopiltide mudeleid, kasutades nii YouCook2 kui ViTT-i. Me näitame, et sellised mudelid üldistavad hästi ja on tugevad paljude õppevideote puhul.', 'bn': 'নির্দেশিত ভিডিও মাধ্যমে বিশেষ প্রতিষ্ঠান, গাড়ি প্রতিষ্ঠান এবং বাড়ির প্রতিষ্ঠান বাড়ছে। এই ধরনের ভিডিও দিয়ে ব্যবহারকারীর অভিজ্ঞতাকে মেটা-তথ্যের মাধ্যমে উন্নত করে দেখা যায়, যেমন সময়-স্ট্যাম্পেডের প্রধান পদক্ স্বয়ংক্রিয়ভাবে এই ধরনের বিবৃতি তৈরি করা চ্যালেঞ্জ, এবং আমরা এখানে দুটি প্রসঙ্গ অবদান বর্ণনা করি। প্রথমত, আমরা একটি নতুন গভীর ভিডিও নির্মাণ এবং মুক্তি দিয়ে ভিডিও টাইমেলিন ট্যাগ (ভিটিটি) ডাটাসেট, ভিডিও টাইমেলিন ট্যাগ (ভিটিটি) নির্দে দ্বিতীয়, আমরা বেশ কয়েকটি মাল্টিমোডাল সেকেন্স-দ্বিতীয় বৃষ্টি কৌশল খুঁজে বের করি যা বিশাল অরক্ষিত তথ্য সংরক্ষিত ভিডিও এবং শিরোনাম আমরা ইউকুক২ এবং ভিটিটি উভয়ে ব্যবহার করে ভিডিও ক্যাপ্টেশনের মডেল দেখাচ্ছি। আমরা দেখাচ্ছি যে এই ধরনের মডেলগুলো ভালোভাবে জেনারেল করে এবং তারা বিভিন্ন নির্দেশাবলী ভিডিওের উপর রোবট কর', 'sk': 'Učenje specifičnih praktičnih veščin, kot so kuhanje, vzdrževanje avtomobila in popravila doma, se vedno bolj dogaja prek videoposnetkov z navodili. Znano je, da se uporabniška izkušnja s takimi videoposnetki izboljša z metainformacijami, kot so časovno označene opombe za glavne korake. Avtomatsko ustvarjanje takšnih opomb je zahtevno, tukaj pa opisujemo dva ustrezna prispevka. Najprej zgradimo in objavimo nov gost nabor podatkov o video napisovanju, Video Timeline Tags (ViTT), ki vsebuje različne videoposnetke z navodili skupaj s časovnimi oznakami. Drugič, raziskujemo več multimodalnih strategij predtreninga med zaporedjem, ki izkoriščajo velike nenadzorovane nabore podatkov videoposnetkov in besedil, podobnih napisu. Modele gostih video napisov predvajamo in nato natančno nastavimo z uporabo YouCook2 in ViTT. Pokazali smo, da se takšni modeli dobro posplošujejo in so robustni v široki paleti poučnih videoposnetkov.', 'jv': 'Learning Perintah pengguna sing karo video sing dipunangé kaya meta-informasi luwih nggawe tarjamahan kanggo nggawe barang-tarjamahan kanggo kuwi nggawe gerakan. Gjer-ngobro sing ditambah sing automatically cara-cara iki dadi iki dadi sekondirno Awak dhéwé nggawe lan mbukakipun video captioning dataset, Video timeline tag 2D Awak dhéwé mulairan ngono sakjane sampek video captioning model sing gampang ngono YouTube Kuk2 lan VisTT. Awak dhéwé ngerasakno ngono kuwi model sing gak ngomong nik kabèh karo video sing apik batar institusi.', 'he': 'ללמוד כישורי ידיים ספציפיים כמו בישול, תחזוקה במכונית, ותיקונים בבית קורים יותר ויותר דרך וידאו הוראה. ניסיון המשתמש עם וידאו כזה ידוע שיפור על ידי מטה-מידע כמו הערות עם סימני זמן לצעד הראשי מעורב. ליצור ציונים כאלה באופן אוטומטי זה מאתגר, ואנחנו מתארים כאן שתי תרומות רלוונטיות. ראשית, אנו בונים ושחררו קבוצת מידע חדשה צפופה, תווידים של קו הזמנים של וידאו (ViTT), המכילים מגוון של וידאו מדריכים יחד עם ציונים עם סימנים זמנים. שנית, אנו חוקרים מספר אסטרטגיות מלפני אימון רצף לרצף שגורמות לסרטים גדולים של וידאו ולטקסטים דומים לכותבות. אנחנו מתחילים להתגשם ולאחר מכן מתאימים מודלים צפופים של ציור וידאו בשימוש גם YouCook2 וגם ViTT. אנחנו מראים שדוגמנים כאלה מגנרלים היטב והם חזקים על מגוון רחב של וידאו מדריך.', 'ha': "Ana karatun zane-zane-hannuwan su ƙayyade kamar kokin, da tsarin gari, da masu gyarawa na gida, yana ƙara kodi da video na shiryarwa. Ana san abincin mai amfani da waɗancan video da za'a improve shi da information na meta-meta kamar sunayen da aka yi wa lokaci-stamping wa hanyõyin muhimmin da aka haɗa shi. An ƙididdige kunyari wannan farat ɗaya, kuma munã bayyana a nan rabo biyu masu husũma. Kayyan, za'a samar da kuma mu saka wani video mai sauni na haɗi da tsari na danne-danne, tagogi na video na Timeline (Witt), wanda ke samu da zane-zane masu shirya da lokaci-stamping. Dukkan, Muke jarraba ko da miski-sauri masu yawa na sauri-sauri da bakwai-bakin juyin ruwa wanda ke samar da matsayin mutane masu da ba'a tsare shi ba. Tuna baka, kuma a bayan haka, misãlai masu tsari na video masu ƙaranci da ke amfani da YouCook2 da Kitt. Muna nũna misãlai masu samun su da alhẽri kuma an kife su a kan wasu video masu shiryarwa.", 'bo': 'སྒྲ་བརྙན་ནང་གི་ཐབས་ལམ་གསལ་པོ་ཞིག་མིན་པར་སྟོན་ན། མེ་འགུལ་གྱི་བདུན་སྒྲིག་འགོད་པ་དང་། མིང་གི་བདུན་སྒྲིག་གི་བརྙན སྤྱོད་མཁན་གྱི་བརྙན་གཟུགས་རིས་འདི་དང་མཉམ་དུ་འཇུག་པའི་བརྙན་གཟུགས་རིས་འགྲེལ་བཤད་ཀྱི་རྒྱུ་དངོས་ལ། རང་འགུལ་གྱིས་འདི་ལྟ་བུའི་བསྐུལ་ལ་རང་འགུལ་གྱིས་དཀའ་ངལ First, we construct and release a new dense video captioning dataset, Video Timeline Tags (ViTT), featuring a variety of instructional videos together with time-stamped annotations. གཉིས་པ། ང་ཚོས་ཀྱིས་བརྙན་གཟུགས་རིས་འདི་དག་གི་སྣ་ཚོགས་གྱི་གོ་རིམ་ལ་གྲངས་སུ་མཐོང་ཐབས་ལམ ང་ཚོས་YouCook2 དང་ViTT གཉིས་པོ་སྤྱད་ནས་མཐའ་མིན་ཐག་གི་བརྙན་རིས་བཀོད་སྤྱོད་པའི་མིག་རྣམས། འུ་ཅག་གིས་མིག'}
{'en': 'Point-of-Interest Oriented Question Answering with Joint Inference of Semantic Matching and Distance Correlation', 'ar': 'الإجابة على الأسئلة الموجهة نحو نقطة الاهتمام مع الاستدلال المشترك للمطابقة الدلالية والارتباط عن بعد', 'pt': 'Resposta a perguntas orientadas a pontos de interesse com inferência conjunta de correspondência semântica e correlação de distância', 'fr': "Réponse aux questions orientée point d'intérêt avec inférence conjointe de correspondance sémantique et de corrélation de distance", 'ja': 'セマンティックマッチングと距離相関の共同推論を伴う関心のあるポイント指向の質問の回答', 'es': 'Respuesta a preguntas orientadas a puntos de interés con inferencia conjunta de correspondencia semántica y correlación de distancia', 'zh': '向兴点语义匹配距相关推理问答', 'ru': 'Ответ на вопрос, ориентированный на точку интереса, с совместным выводом семантического соответствия и корреляции расстояний', 'hi': 'प्वाइंट-ऑफ-इंटरेस्ट ओरिएंटेड प्रश्न शब्दार्थ मिलान और दूरी सहसंबंध के संयुक्त अनुमान के साथ उत्तर देना', 'ga': 'Ceist a Dhírítear ar Phointe Suim ag Freagairt le Comhthátal maidir le Meaitseáil Shéimeantach agus Cianchoibhneas', 'ka': 'საინტერესო კითხვა, რომელიც საერთო სემონტიკური დაკავშირება და განსხვავება', 'el': 'Επίκεντρη απάντηση ερωτήσεων με κοινό συμπέρασμα σημασιολογικής αντιστοίχισης και συσχέτισης εξ αποστάσεως', 'hu': 'Érdeklődési pont-orientált kérdések megválaszolása a szemantikus egyezés és a távolsági korreláció közös fertőzésével', 'it': 'Risposta alle domande orientate ai punti di interesse con inferenza congiunta di corrispondenza semantica e correlazione tra distanza', 'lt': 'Į interesus orientuotas atsakymas į klausimus, susijusius su bendra semeninio derinimo ir nuotolinės koreliacijos pažeidimu', 'mk': 'Одговорите на прашањата ориентирани на точката на интерес со заедничка инференција на семантичко совпаѓање и корелација на далечина', 'kk': 'Ертепнұсқа сұрақ көлемі және қашықтығын түзету сұрағының жауап беру', 'ml': 'സെമാന്റിക് പൊരുത്തിപ്പെടുത്തുന്നതിന്റെയും ദൂരെയുള്ള കോര്\u200dബന്ധത്തിന്റെയും യൂണ്ടെന്\u200dറ് ഇന്\u200dഫെരെന്\u200dസിന്റെ', 'no': 'Punkt av Interest orientert spørsmål svarar med samanlikn av semiantisk samanlikning og avstandkorreksjon', 'ms': 'Jawapan soalan yang ditujukan ke titik-kepentingan dengan Perrujukan Berkongsi Perpadanan Semantik dan Korelasi Jarak', 'mt': 'Tweġiba għall-mistoqsijiet orjentati lejn il-Punt ta’ Interess b’Inferenza Konġunta ta’ Qbil Semantiku u Korelazzjoni tad-Distanza', 'pl': 'Odpowiedź na pytania zorientowane na punkt zainteresowania ze wspólnym wnioskiem dopasowania semantycznego i korelacji na odległość', 'ro': 'Răspunsul la întrebări orientate spre puncte de interes cu inferența comună a potrivirii semantice și corelației distanțelor', 'sr': 'Poenta od interesa orijentirana pitanja odgovarajući na zajedničku nedostatku semantičkog odgovaranja i korištenja udaljenosti', 'mn': 'Хамгийн сонирхолтой эхлэл асуултын хариулт Semantic Matching and Distance Correlation-ын хооронд', 'sv': 'Intresseorienterat frågesvar med gemensam inferens av semantisk matchning och distanskorrelation', 'ur': 'سفارشی مطابق اور دور کی اصلاح کے ساتھ جواب دینے والی سؤال کی پوینٹ-of-Interest Oriented Question', 'so': 'Point-of-Interest oriented Question answering with Joint Inference of Semantic Matching and Distance Correlation', 'ta': 'செமாண்டிக் பொருத்தல் மற்றும் தூரத்தின் இணைய புகுதிய புள்ளி', 'si': 'ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණ ප්\u200dරශ්ණය සමග සෙමාන්ටික් සහ දුරස්ථානය සඳහ', 'uz': 'Name', 'vi': 'Câu hỏi hướng về điểm quan tâm Trả lời với Liên quan kết giữa kết cục và kết cấu khoảng cách giữa hai kỳ.', 'bg': 'Отговаряне на въпроси, ориентирани към точка на интерес, със съвместно заключение на семантично съвпадение и дистанционна корелация', 'hr': 'Odgovor na odgovor s zajedničkim teškošću semantičkog odgovaranja i korištenja udaljenosti', 'da': 'Point-of-interesse orienteret spørgsmål besvarelse med fælles inferens af semantisk matching og distancekorrelation', 'de': 'Point-of-Interest-orientierte Fragebeantworterung mit gemeinsamer Schlussfolgerung von semantischem Matching und Distanzkorrelation', 'nl': 'Punt-of-Interest gerichte vragen beantwoorden met gezamenlijke conclusie van semantische matching en afstandscorrelatie', 'id': 'Jawaban Pertanyaan Berorientasi ke Titik Interes dengan Inferensi Bersama Persamaan Semantik dan Korelasi Jarak', 'sw': 'Swali linaloongozwa na maswali yanayojibu pamoja na Kuzungumza na Kuhusiana na Makosa ya Kijinsia', 'ko': '의미 일치와 거리 관련 연합 추리에 기초한 취미점 문답', 'fa': 'پاسخ پرسش اولیه\u200cی نقطه\u200cی علاقه\u200cای که با تفاوت همدیگر مربوط به هماهنگ و اصلاح دور', 'sq': 'Përgjigja e pyetjeve të orientuara në pikën e interesit me Inferencën e Përbashkët të Korelacionit Semantik dhe të Distancës', 'hy': 'Հետաքրքիր կետի հարցերի պատասխանը սեմանտիկ հարաբերությունների և հեռավորության հաղորդակցման ընդհանուր ինֆերենսիայի հետ', 'am': 'ነጥብ', 'az': 'Semantik eŇüitm…ôsi v…ô uzaq d√ľz…ôltm…ôsi bar…ôsind…ô birl…ôŇüdirilmiŇü soruŇü', 'bn': 'সেম্যান্টিক মিল এবং দূরত্বের সম্পর্কের সাথে যুক্ত প্রশ্নের উত্তর দিয়েছে', 'af': 'Punt van Interest Orienteerde Vrag antwoord met saamgevoeg ondergang van Semantiese Ooreenstemming en Afstand Korrektuuring', 'ca': 'Point-of-Interest Oriented Question Answering with Joint Inference of Semantic Matching and Distance Correlation', 'cs': 'Odpověď na otázky orientované na bod zájmu se společným závěrem sémantického shodování a vzdálenostní korelace', 'et': 'Huvipunktile orienteeritud küsimustele vastamine koos semantilise sobivuse ja kaugkorrelatsiooni ühise järeldusega', 'tr': 'Semantik Eşleşmeler we Uzak Düzeltmesinin Kop Tersine jogap', 'bs': 'Poenta interesa orijentirana pitanja koja odgovara na zajedničku nedostatku semantičkog odgovaranja i korištenja udaljenosti', 'fi': 'Kiinnostuksen kohteisiin suuntautunut kyselyvastaus, jossa on yhteinen päätelmä semanttisesta vastaamisesta ja etäisyyskorrelaatiosta', 'ha': 'KCharselect unicode block name', 'jv': 'Point-of-interst Oriented question responsing with Joint Info of semianti Match and Distance', 'he': 'תשובה לשאלה ממוקמת לנקודת עניין עם מעבר משותף של התאמה סמנטית', 'bo': 'Point-of-Interest Oriented Question Answering with Joint Inference of Semantic Matching and Distance Correlation', 'sk': 'Odgovor na vprašanja na točke interesa s skupno ugotovitvijo semantičnega ujemanja in korelacije na razdaljo'}
{'en': 'Point-of-Interest (POI) oriented question answering (QA) aims to return a list of POIs given a question issued by a user. Recent advances in intelligent virtual assistants have opened the possibility of engaging the client software more actively in the provision of location-based services, thereby showing great promise for automatic POI retrieval. Some existing  QA methods  can be adopted on this task such as  QA similarity calculation  and  semantic parsing  using pre-defined rules. The returned results, however, are subject to inherent limitations due to the lack of the ability for handling some important POI related information, including  tags , location entities, and proximity-related terms (e.g. nearby, close). In this paper, we present a novel deep learning framework integrated with joint inference to capture both tag semantic and geographic correlation between question and POIs. One characteristic of our model is to propose a special cross attention question embedding neural network structure to obtain question-to-POI and POI-to-question information. Besides, we utilize a  skewed distribution  to simulate the spatial relationship between questions and POIs. By measuring the results offered by the  model  against existing methods, we demonstrate its robustness and practicability, and supplement our conclusions with empirical evidence.', 'ar': 'تهدف الإجابة عن الأسئلة الموجهة (QA) إلى نقاط الاهتمام (POI) إلى إرجاع قائمة النقاط المهمة في ضوء سؤال صادر عن المستخدم. لقد فتحت التطورات الأخيرة في المساعدين الافتراضيين الأذكياء إمكانية إشراك برنامج العميل بشكل أكثر نشاطًا في توفير الخدمات المستندة إلى الموقع ، مما يُظهر وعودًا كبيرة لاسترداد النقاط المهمة تلقائيًا. يمكن اعتماد بعض أساليب ضمان الجودة الحالية في هذه المهمة مثل حساب تشابه ضمان الجودة والتحليل الدلالي باستخدام قواعد محددة مسبقًا. ومع ذلك ، فإن النتائج التي تم إرجاعها تخضع لقيود متأصلة بسبب عدم القدرة على التعامل مع بعض المعلومات المهمة المتعلقة بالنقاط المهمة ، بما في ذلك العلامات وكيانات الموقع والمصطلحات المتعلقة بالتقارب (على سبيل المثال "قريب" ، "قريب"). في هذه الورقة ، نقدم إطارًا جديدًا للتعلم العميق مدمجًا مع الاستدلال المشترك لالتقاط الارتباط الدلالي والجغرافي بين السؤال ونقاط الاهتمام. تتمثل إحدى سمات نموذجنا في اقتراح سؤال خاص حول الاهتمام المتقاطع يتضمن بنية الشبكة العصبية للحصول على معلومات من الأسئلة إلى POI و POI إلى سؤال. إلى جانب ذلك ، نستخدم التوزيع المنحرف لمحاكاة العلاقة المكانية بين الأسئلة ونقاط الاهتمام. من خلال قياس النتائج التي يقدمها النموذج مقابل الأساليب الحالية ، نظهر متانته وقابليته للتطبيق ، ونكمل استنتاجاتنا بالأدلة التجريبية.', 'fr': "La réponse aux questions (QA) orientée point d'intérêt (POI) vise à renvoyer une liste de points d'intérêt correspondant à une question émise par un utilisateur. Les récents progrès réalisés dans le domaine des assistants virtuels intelligents ont ouvert la possibilité d'impliquer plus activement le logiciel client dans la fourniture de services basés sur la localisation, ce qui est très prometteur pour la récupération automatique des points d'intérêt. Certaines méthodes d'assurance qualité existantes peuvent être adoptées pour cette tâche, telles que le calcul de similarité d'assurance qualité et l'analyse sémantique à l'aide de règles prédéfinies. Les résultats renvoyés, cependant, sont soumis à des limitations inhérentes en raison du manque de capacité à gérer certaines informations importantes liées aux points d'intérêt, y compris les balises, les entités de localisation et les termes liés à la proximité (par exemple «\xa0à proximité\xa0», «\xa0proche\xa0»). Dans cet article, nous présentons un nouveau cadre d'apprentissage profond intégré à l'inférence conjointe pour capturer à la fois la corrélation sémantique des balises et la corrélation géographique entre la question et les points d'intérêt. L'une des caractéristiques de notre modèle est de proposer une question d'attention croisée spéciale intégrant la structure du réseau de neurones pour obtenir des informations de question à point d'intérêt et de point d'intérêt à question. En outre, nous utilisons une distribution asymétrique pour simuler la relation spatiale entre les questions et les points d'intérêt. En mesurant les résultats offerts par le modèle par rapport aux méthodes existantes, nous démontrons sa robustesse et sa praticabilité, et complétons nos conclusions par des preuves empiriques.", 'pt': 'A resposta a perguntas (QA) orientada a Pontos de Interesse (POI) visa retornar uma lista de POIs dada uma pergunta emitida por um usuário. Os avanços recentes em assistentes virtuais inteligentes abriram a possibilidade de envolver o software cliente de forma mais ativa na prestação de serviços baseados em localização, mostrando assim uma grande promessa de recuperação automática de POI. Alguns métodos de QA existentes podem ser adotados nesta tarefa, como cálculo de similaridade de QA e análise semântica usando regras pré-definidas. Os resultados retornados, no entanto, estão sujeitos a limitações inerentes devido à falta de capacidade de lidar com algumas informações importantes relacionadas a POI, incluindo tags, entidades de localização e termos relacionados à proximidade (por exemplo, “próximo”, “próximo”). Neste artigo, apresentamos uma nova estrutura de aprendizado profundo integrada com inferência conjunta para capturar a semântica de tags e a correlação geográfica entre pergunta e POIs. Uma característica do nosso modelo é propor uma questão especial de atenção cruzada incorporando a estrutura da rede neural para obter informações de pergunta a POI e POI a pergunta. Além disso, utilizamos uma distribuição assimétrica para simular a relação espacial entre perguntas e POIs. Ao medir os resultados oferecidos pelo modelo em relação aos métodos existentes, demonstramos sua robustez e praticidade e complementamos nossas conclusões com evidências empíricas.', 'es': 'La respuesta a preguntas (QA) orientada a puntos de interés (POI) tiene como objetivo devolver una lista de POI dada una pregunta emitida por un usuario. Los avances recientes en los asistentes virtuales inteligentes han abierto la posibilidad de involucrar más activamente el software del cliente en la prestación de servicios basados en la ubicación, lo que resulta muy prometedor para la recuperación automática de puntos de interés. Se pueden adoptar algunos métodos de control de calidad existentes en esta tarea, como el cálculo de similitud de control de calidad y el análisis semántico mediante reglas predefinidas. Sin embargo, los resultados devueltos están sujetos a limitaciones inherentes debido a la falta de capacidad para manejar cierta información importante relacionada con los puntos de interés, incluidas las etiquetas, las entidades de ubicación y los términos relacionados con la proximidad (por ejemplo, «cerca», «cerca»). En este artículo, presentamos un nuevo marco de aprendizaje profundo integrado con inferencia conjunta para capturar la correlación semántica y geográfica de las etiquetas entre la pregunta y los POI. Una característica de nuestro modelo es proponer una pregunta especial de atención cruzada que incorpore una estructura de red neuronal para obtener información de pregunta a POI y POI a pregunta. Además, utilizamos una distribución sesgada para simular la relación espacial entre las preguntas y los POI. Al medir los resultados que ofrece el modelo en comparación con los métodos existentes, demostramos su robustez y viabilidad, y complementamos nuestras conclusiones con evidencia empírica.', 'ja': 'POI （ Point of Interest ）指向の質問応答（ QA ）は、ユーザーが発行した質問に指定されたPOIのリストを返すことを目的としています。 最近のインテリジェント仮想アシスタントの進歩により、ロケーションベースのサービスの提供にクライアントソフトウェアをより積極的に関与させる可能性が開かれ、自動POI取得の大きな可能性が示されています。 既存のQA方法のいくつかは、QA類似性計算やあらかじめ定義されたルールを使用したセマンティック解析など、このタスクで採用することができます。 ただし、返された結果は、タグ、ロケーションエンティティ、および近接性関連用語（「近く」、「閉じる」など）を含むいくつかの重要なPOI関連情報を処理する能力が欠如しているため、固有の制限の対象となります。 この論文では、質問とPOIの間のタグの意味的および地理的相関の両方を取り込むために、共同推論と統合された新規の深層学習フレームワークを提示する。 私たちのモデルの特徴の1つは、POIへの質問とPOIへの質問の情報を得るために、ニューラルネットワーク構造を埋め込む特別なクロス注意質問を提案することです。 さらに、質問とPOIの空間的関係をシミュレートするために、偏った分布を利用します。 モデルが提供する結果を既存の手法と比較して測定することで、その堅牢性と実用性を示し、実証的な証拠で結論を補完する。', 'hi': 'Point-of-Interest (POI) उन्मुख प्रश्न उत्तर (QA) का उद्देश्य उपयोगकर्ता द्वारा जारी किए गए प्रश्न को दिए गए POIs की एक सूची वापस करना है। बुद्धिमान आभासी सहायकों में हाल की प्रगति ने ग्राहक सॉफ़्टवेयर को स्थान-आधारित सेवाओं के प्रावधान में अधिक सक्रिय रूप से संलग्न करने की संभावना खोली है, जिससे स्वचालित पीओआई पुनर्प्राप्ति के लिए बहुत अच्छा वादा दिखाया गया है। कुछ मौजूदा QA विधियों को इस कार्य पर अपनाया जा सकता है जैसे कि QA समानता गणना और पूर्व-परिभाषित नियमों का उपयोग करके शब्दार्थ पार्सिंग। हालांकि, लौटाए गए परिणाम कुछ महत्वपूर्ण पीओआई से संबंधित जानकारी को संभालने की क्षमता की कमी के कारण अंतर्निहित सीमाओं के अधीन हैं, जिसमें टैग, स्थान संस्थाएं और निकटता से संबंधित शब्द (जैसे "आस-पास", "बंद")। इस पेपर में, हम प्रश्न और पीओआई के बीच टैग शब्दार्थ और भौगोलिक सहसंबंध दोनों को पकड़ने के लिए संयुक्त अनुमान के साथ एकीकृत एक उपन्यास गहरी सीखने की रूपरेखा प्रस्तुत करते हैं। हमारे मॉडल की एक विशेषता प्रश्न-से-पीओआई और पीओआई-टू-प्रश्न जानकारी प्राप्त करने के लिए तंत्रिका नेटवर्क संरचना को एम्बेड करने के लिए एक विशेष क्रॉस ध्यान प्रश्न का प्रस्ताव करना है। इसके अलावा, हम प्रश्नों और पीओआई के बीच स्थानिक संबंधों का अनुकरण करने के लिए एक विषम वितरण का उपयोग करते हैं। मौजूदा तरीकों के खिलाफ मॉडल द्वारा पेश किए गए परिणामों को मापने से, हम इसकी मजबूती और व्यावहारिकता का प्रदर्शन करते हैं, और अनुभवजन्य साक्ष्य के साथ हमारे निष्कर्षों को पूरक करते हैं।', 'zh': '向兴点 (POI) 问答 (QA) 旨还给定用户 POI 列表。 智能虚拟助者最新进展为之极用客户端软件资其位而辟其能,以见自POI之巨端。 此可用见QA之法,如QA相似性算用预定义之语义解析。 然乏要 POI(标签位实,与邻近相关术语(如近闭))之能,还为固限。 本文中,发新型深学框架,以获问POI之间,表语义地理相关性。 凡我模样,特立殊交,以问神经网络结构,以得POIPOI之信。 以偏斜布拟之,与POI之间。 以今度之,吾验其稳健性实用性,以验补之。', 'ru': 'Ответы на вопросы, ориентированные на точки интереса (POI), направлены на возврат списка POI, заданных пользователем. Недавние достижения в области интеллектуальных виртуальных помощников открыли возможность для более активного привлечения клиентского программного обеспечения к предоставлению услуг на основе определения местоположения, что открывает большие перспективы для автоматического поиска объектов инфраструктуры. Некоторые существующие методы QA могут быть приняты для этой задачи, такие как вычисление сходства QA и семантический синтаксический анализ с использованием предопределенных правил. Однако возвращенные результаты подвержены ограничениям из-за отсутствия возможности обработки некоторой важной информации, связанной с POI, включая теги, объекты местоположения и термины, связанные с близостью (например, «поблизости», «рядом»). В этой статье мы представляем новую структуру глубокого обучения, интегрированную с совместным выводом, чтобы охватить как семантическую, так и географическую корреляцию между вопросом и POI. Одной из особенностей нашей модели является предложение специального вопроса с перекрестным вниманием, встраивающего структуру нейронной сети для получения информации от вопроса к объекту интереса и от объекта интереса к объекту интереса. Кроме того, мы используем асимметричное распределение для моделирования пространственной взаимосвязи между вопросами и POI. Измеряя результаты, предлагаемые моделью, с существующими методами, мы демонстрируем ее надежность и практичность и дополняем наши выводы эмпирическими данными.', 'ga': 'Tá sé mar aidhm ag freagairt ceisteanna atá dírithe ar Phointe Suim (POI) (QA) liosta de na POIs a chuir úsáideoir ar fáil dóibh. De bharr an dul chun cinn a rinneadh le déanaí i gcúntóirí fíorúla éirimiúla, tá an fhéidearthacht ann go bhféadfaí na bogearraí cliant a chur i ngleic ar bhealach níos gníomhaí i soláthar seirbhísí atá bunaithe ar shuíomh, rud a léiríonn gealltanas iontach maidir le haisghabháil uathoibríoch POI. Is féidir roinnt modhanna QA atá ann cheana a ghlacadh ar an tasc seo ar nós ríomh cosúlachta QA agus parsáil shéimeantach ag baint úsáide as rialacha réamhshainithe. Tá na torthaí a thugtar ar ais, áfach, faoi réir teorainneacha bunúsacha mar gheall ar an easpa cumais chun roinnt faisnéise tábhachtach a bhaineann le POI a láimhseáil, lena n-áirítear clibeanna, aonáin suímh, agus téarmaí a bhaineann le gaireacht (m.sh. “in aice láimhe”, “gar”). Sa pháipéar seo, cuirimid i láthair creat foghlama domhain nua atá comhtháite le comhthátal chun comhghaolú séimeantach agus geografach a ghabháil idir ceist agus POI. Tréith amháin dár múnla is ea ceist chrosaire ar leith a mholadh lena neadófar struchtúr an líonra néaraigh chun faisnéis ceist-go-POI agus POI-go-ceist a fháil. Ina theannta sin, bainimid úsáid as dáileadh sceabhach chun an gaol spásúlachta idir ceisteanna agus POIs a insamhail. Trí na torthaí a thairgeann an tsamhail a thomhas i gcoinne modhanna atá ann cheana féin, léirímid a stóinseacht agus a praiticiúlacht, agus cuirimid lenár gconclúidí le fianaise eimpíreach.', 'ka': 'საინტერესტის (POI) კითხვის გადასვლა (QA) მიზეზიან POI-ის სია, რომელიც მომხმარებელი გადასვლა კითხვა. მიმდინარე ინტელექტური ვირტუალური asistenტებში გახსნა კლიენტის პროგრამის შესაძლებლობა უფრო აკეთექტურად დაკავშირება პროგრამის სერვისებში, რომელსაც აკეთექტურად დაკავშ QA პროცემები იქნება ამ დავალებაში, როგორც QA სხვადასხვა გამოწვება და semantic გამოწვება პროცემის გამოყენებით. მაგრამ გადასვლა შედეგი წარმოდგენები შეუძლებელია შესაძლებლობა POI-ის გასაკეთებელი ინფორმაციის გასაკეთებელი გასაკეთებელი შესაძლებლობა, მაგრამ ტეგიები, ადგილების ინტერტივიები და დასაკეთებელი წარმოდგენები (მა ამ დომენტში ჩვენ ახალგაზრდებით პრომენტიური ძალიან სწავლების ფრამეტრი, რომელიც ერთადერთი ინფრენციაზე ინტერგურაციულია, რომელიც კითხვის და POI-ის შორის შიგრამეტური ჩვენი მოდელის ერთი პერატიფიკაცია არის სპეციალური კონტაქტის კითხვა, რომელიც ნეიროლური ქსტრუქტურის სტრუქტურაციას მიიღებთ კითხვის POI და POI-კითხვის ინფორმაცი დამატებით, ჩვენ გამოყენებთ სკენ გაყოფილების სიმუალური შესახებ კითხვების და POI-ის შორის. მარტირებით მოდელის შედეგები, რომლებიც მოდელის მიღებულიან მეტისებზე, ჩვენ მისი ძალიან ძალიან და პრაქტიკურად გამოყენებთ და ჩვენი გადაწყვეტილებები ემპერიკურად გამო', 'el': 'Η απάντηση σε ερωτήσεις προσανατολισμένες στο σημείο ενδιαφέροντος (ΠΟI) έχει ως στόχο να επιστρέψει μια λίστα με σημεία ενδιαφέροντος που έχουν δοθεί σε μια ερώτηση που έχει εκδοθεί από έναν χρήστη. Οι πρόσφατες εξελίξεις στους έξυπνους εικονικούς βοηθούς έχουν ανοίξει τη δυνατότητα να εμπλακεί το λογισμικό πελατών πιο ενεργά στην παροχή υπηρεσιών βάσει τοποθεσίας, δείχνοντας έτσι μεγάλη υπόσχεση για αυτόματη ανάκτηση σημείων. Ορισμένες υπάρχουσες μέθοδοι QS μπορούν να υιοθετηθούν σε αυτήν την εργασία, όπως ο υπολογισμός ομοιότητας QS και η σημασιολογική ανάλυση χρησιμοποιώντας προκαθορισμένους κανόνες. Τα επιστρεφόμενα αποτελέσματα, ωστόσο, υπόκεινται σε εγγενείς περιορισμούς λόγω της έλλειψης της δυνατότητας χειρισμού ορισμένων σημαντικών πληροφοριών σχετικά με σημεία ενδιαφέροντος, συμπεριλαμβανομένων ετικετών, οντοτήτων τοποθεσίας και όρων που σχετίζονται με την εγγύτητα (π.χ. "κοντά", "κοντά"). Σε αυτή την εργασία, παρουσιάζουμε ένα νέο πλαίσιο βαθιάς μάθησης ενσωματωμένο με κοινή συμπέρασμα για την καταγραφή τόσο σημασιολογικής όσο και γεωγραφικής συσχέτισης ετικετών μεταξύ ερώτησης και σημείων ενδιαφέροντος. Ένα χαρακτηριστικό του μοντέλου μας είναι να προτείνουμε μια ειδική ερώτηση διασταυρούμενης προσοχής που ενσωματώνει τη δομή νευρωνικών δικτύων για την απόκτηση πληροφοριών από ερώτηση προς σημείο και σημείο προς ερώτηση. Εκτός αυτού, χρησιμοποιούμε μια διαστρεβλωμένη κατανομή για να προσομοιώσουμε τη χωρική σχέση μεταξύ ερωτήσεων και σημείων ενδιαφέροντος. Μετρώντας τα αποτελέσματα που προσφέρει το μοντέλο σε σχέση με τις υπάρχουσες μεθόδους, αποδεικνύουμε την αξιοπιστία και την πρακτικότητά του και συμπληρώνουμε τα συμπεράσματά μας με εμπειρικά στοιχεία.', 'it': 'La risposta alle domande orientate al punto di interesse (POI) mira a restituire un elenco di POI fornito da una domanda rilasciata da un utente. I recenti progressi negli assistenti virtuali intelligenti hanno aperto la possibilità di coinvolgere il software client più attivamente nella fornitura di servizi basati sulla posizione, mostrando così grandi promesse per il recupero automatico dei POI. Alcuni metodi QA esistenti possono essere adottati in questo compito, come il calcolo della somiglianza QA e l\'analisi semantica utilizzando regole predefinite. I risultati restituiti, tuttavia, sono soggetti a limitazioni intrinseche dovute alla mancanza di capacità di gestire alcune importanti informazioni relative ai POI, tra cui tag, entità di localizzazione e termini relativi alla prossimità (ad esempio "vicino", "vicino"). In questo articolo, presentiamo un nuovo framework di deep learning integrato con inferenza congiunta per catturare sia la correlazione semantica che geografica dei tag tra domanda e POI. Una caratteristica del nostro modello è quella di proporre una speciale domanda di attenzione incrociata che incorpora la struttura della rete neurale per ottenere informazioni question-to-POI e POI-to-question. Inoltre, utilizziamo una distribuzione distorta per simulare la relazione spaziale tra domande e POI. Misurando i risultati offerti dal modello rispetto ai metodi esistenti, dimostriamo la sua robustezza e praticità e completiamo le nostre conclusioni con prove empiriche.', 'hu': 'Az érdeklődési pont (POI) orientált kérdésre adott válasz (QA) célja, hogy visszaküldje a felhasználó által kibocsátott kérdésekre adott POI-k listáját. Az intelligens virtuális asszisztensek közelmúltbeli fejlődése megnyitotta annak lehetőségét, hogy az ügyfélszoftvert aktívabban bevonják a helyszínalapú szolgáltatások nyújtásába, így nagy ígéretet mutat az automatikus POI-visszahívás tekintetében. Néhány meglévő minősítési módszer alkalmazható erre a feladatra, mint például a minősítési hasonlóság kiszámítása és a szemantikai elemzés előre meghatározott szabályokkal. A visszaküldött eredményekre azonban belső korlátozások vonatkoznak, mivel nem lehet kezelni néhány fontos POI-val kapcsolatos információt, beleértve a címkéket, a helymeghatározó entitásokat és a közelséggel kapcsolatos kifejezéseket (pl. "közeli", "bezárás"). Ebben a tanulmányban egy új, közös következtetéssel integrált mélytanulási keretrendszert mutatunk be a kérdés és a POI közötti címkék szemantikai és földrajzi korreláció rögzítésére. Modellünk egyik jellemzője, hogy egy speciális keresztfigyelemmel kísérő kérdést javasolunk, amely beágyazza a neurális hálózati struktúrát, hogy kérdés-POI és POI-to-question információkat kapjon. Emellett ferde eloszlást használunk a kérdések és POI közötti térbeli kapcsolat szimulálására. A modell által kínált eredmények mérésével a meglévő módszerekkel összehasonlítva bizonyítjuk annak robusztusságát és kivitelezhetőségét, valamint empirikus bizonyítékokkal egészítjük ki következtetéseinket.', 'kk': 'Интерфейстің (POI) бағытталған сұрақ жауап (QA) тізімін пайдаланушының берілген сұрақ тізімін қайтару мақсаты. Жуырдағы виртуалды көмекшілердің бағдарламасын жерге негізделген қызметтерді жеткізу мүмкіндігін ашып, ол автоматты түрде POI алу үшін үлкен әлемі көрсетеді. QA тең есептеу және semantic талдау әдістері бұл тапсырманың көбірек QA әдістерін алдын- ала анықталған ережелерден қолдануға болады. Бірақ қайтарылған нәтижелер, кейбір маңызды POI мәліметті қамтамасыз ету мүмкіндігі жоқ болып, тегтерді, орналасу нысандарын және жақындағы тегтерді (мысалы, "жақындағы", "жақындау" деген шарттарын қамтамасыз етеді). Бұл қағазда, біз сұрақ мен POI арасындағы семантикалық және географикалық корреляциялық тегтерді түсінуге болатын жалпы оқыту бағдарламасын көрсету үшін. Біздің үлгіміздің бір қасиеті - Сұрақ-POI және POI-ден сұрақ мәліметін алу үшін невралдық желінің құрылымының арнайы бірнеше қарапайым сұрағын ұсыну. Сұрақтар мен POI арасындағы жергілікті қатынасын симуляциялау үшін кеңістік үлестірімізді қолданамыз. Өзгертілген тәсілдерге қарсы үлгі нәтижелерін өлшеп, оның құндылығын және әрекеттігін көрсету және соңызды импирикалық құндылығымен қосып жатырмыз.', 'lt': 'Į interesų tašką orientuoto atsakymo į klausimus tikslas – grąžinti naudotojo pateiktą POI sąrašą. Pastaruoju metu pažanga pažangiųjų virtualių padėjėjų srityje suteikė galimybę aktyviau įtraukti kliento programinę įrangą į vietoje grindžiamų paslaugų teikimą ir taip parodė didelį pažadą automatiškai gauti POI. Šioje užduotyje gali būti patvirtinti kai kurie esami QA metodai, pavyzdžiui, QA panašumo skaičiavimas ir semantinis analizavimas taikant iš anksto nustatytas taisykles. Vis dėlto grąžintiems rezultatams taikomi būdingi apribojimai dėl to, kad trūksta gebėjimų tvarkyti tam tikrą svarbią su POI susijusią informaciją, įskaitant ženklus, vietos subjektus ir su artimumu susijusias sąvokas (pvz. „artimas“, „artimas“). Šiame dokumente pristatome naują gilaus mokymosi sistemą, integruotą į bendrą išvadą, kad būtų galima nustatyti semantinę ir geografinę klausimų ir POI koreliaciją. One characteristic of our model is to propose a special cross attention question embedding neural network structure to obtain question-to-POI and POI-to-question information.  Be to, mes naudojame nubrėžtą paskirstymą, kad simuliuotume erdvinius klausimų ir POI ryšius. Matuodami modelio siūlomus rezultatus pagal esamus metodus, įrodome jo patikimumą ir praktiškumą ir papildome savo išvadas empiriniais įrodymais.', 'ms': 'Jawapan soalan yang oriented Point-of-Interest (POI) bertujuan untuk mengembalikan senarai POI yang diberikan soalan dikeluarkan oleh pengguna. Kemajuan baru-baru ini dalam pembantu maya bijak telah membuka kemungkinan untuk melibatkan perisian klien lebih aktif dalam penyediaan perkhidmatan berdasarkan lokasi, dengan demikian menunjukkan janji besar untuk pemulihan POI secara automatik. Beberapa kaedah QA yang wujud boleh diterima pada tugas ini, seperti pengiraan persamaan QA dan penghuraian semantik menggunakan peraturan terdefinisi. Keputusan yang dikembalikan, bagaimanapun, mengalami keterangan yang terkandung kerana kekurangan kemampuan untuk mengendalikan beberapa maklumat berkaitan POI yang penting, termasuk tag, entiti lokasi, dan terma berkaitan dengan kedekatan (cth. "dekat", "tutup"). Dalam kertas ini, kami memperkenalkan kerangka belajar dalam novel yang terintegrasi dengan kesimpulan bersama untuk menangkap kedua-dua tag sambungan semantik dan geografik antara soalan dan POI. One characteristic of our model is to propose a special cross attention question embedding neural network structure to obtain question-to-POI and POI-to-question information.  Besides, we utilize a skewed distribution to simulate the spatial relationship between questions and POIs.  Dengan mengukur keputusan yang ditawarkan oleh model terhadap kaedah yang ada, kami menunjukkan kekuatannya dan kemudahan latihan, dan menambahkan kesimpulan kami dengan bukti empirik.', 'mk': 'Ориентираното одговорување на прашањата на точката на интерес (POI) (QA) има за цел враќање на листата на POI со прашање издадено од корисник. Неодамнешните напредоци во интелигентните виртуелни асистенти ја отворија можноста за активно вклучување на клиентскиот софтвер во обезбедувањето на локациски услуги, покажувајќи со тоа големи ветувања за автоматско преземање на POI. Некои постоечки методи за QA можат да бидат усвоени за оваа задача, како што се пресметувањето на сличноста на QA и семантичното анализирање користејќи предефинирани правила. Сепак, враќаните резултати се предмет на природни ограничувања поради недостатокот на способноста за управување со некои важни информации поврзани со POI, вклучувајќи ги и ознаките, ентитетите на локацијата и термините поврзани со близината (на пример „близу“, „близу“, „ In this paper, we present a novel deep learning framework integrated with joint inference to capture both tag semantic and geographic correlation between question and POIs.  One characteristic of our model is to propose a special cross attention question embedding neural network structure to obtain question-to-POI and POI-to-question information.  Освен тоа, користиме скриена дистрибуција за да ја симулираме просторната врска помеѓу прашањата и полицијата. Со мерење на резултатите понудени од моделот со постојните методи, ние ја демонстрираме неговата силност и практичност, и ги дополниме нашите заклучоци со емпирички докази.', 'ml': 'Point-of-Interest (POI) oriented question answering (QA) aims to return a list of POIs given a question issued by a user.  ബുദ്ധിമാന്യനായ വെര്\u200dച്ചുവലിയ സഹായികളുടെ അടുത്തുള്ള മുന്\u200dഗണങ്ങള്\u200d സ്ഥാനത്തിലെ സേവനങ്ങള്\u200dക്ക് വേണ്ടി കൂടുതല്\u200d സജ്ജീവമായ സംവിധാനങ്ങള്\u200d ചേര്\u200dക് ഈ ജോലിയില്\u200d നിലവിലുള്ള ക്യൂഎ രീതികള്\u200d പൂര്\u200dണ്ണമായ നിയമങ്ങള്\u200d ഉപയോഗിച്ച് ക്യൂഎ സമമായ കണക്കെട്ടിനും semantic പാര്\u200dസിങ എന്നാലും തിരിച്ചുവരുന്ന ഫലങ്ങള്\u200d നിലനില്\u200dക്കുന്ന പരിധികള്\u200dക്ക് കാരണം പ്രധാനപ്പെട്ട പോഐ വിവരങ്ങള്\u200d കൈകാര്യം ചെയ്യുന്നതിന്റെ കഴിവിന്റെ കാരണമാണ്. ടാഗ ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഒരു നോവല്\u200d ആഴത്തെ പഠിക്കുന്ന ഫ്രെയിമെക്ക് കൊണ്ടുവരുന്നു. ചോദ്യത്തിനും പോയിസിനും തമ്മിലുള്ള സെമാന്റിക് നമ്മുടെ മോഡലിന്റെ ഒരു പ്രത്യേക ശ്രദ്ധ പ്രധാനപ്പെട്ട ചോദ്യം ചോദിക്കുന്നത് ന്യൂറല്\u200d നെറ്റോറല്\u200d നെറ്റോവര്\u200dക്ക് സ്റ്റോക്ക പിന്നെ ചോദ്യങ്ങള്\u200dക്കും പോയികള്\u200dക്കും തമ്മിലുള്ള സ്പെയില്\u200d ബന്ധങ്ങള്\u200d സിമില്\u200d ചെയ്യാന്\u200d ഞങ്ങള്\u200d ഒരു വിതരണം ഉപയോഗ നിലവിലുള്ള രീതികള്\u200dക്കെതിരായി മാതൃകയുടെ ഫലങ്ങള്\u200d അളന്നു തരുന്നതിനാല്\u200d, നാം അതിന്റെ വസ്ത്രവും പ്രവർത്തകവും കാണിച്ചുകൊടുക്കുന്', 'mt': "It-tweġiba għall-mistoqsijiet orjentati lejn il-Punt ta’ Interess (POI) għandha l-għan li tirritorna list a ta’ POIs mogħtija mistoqsija maħruġa minn utent. L-avvanzi reċenti fl-assistenti virtwali intelliġenti fetħu l-possibbiltà li s-softwer tal-klijent jiġi involut b’mod aktar attiv fil-forniment ta’ servizzi bbażati fuq il-post, u b’hekk urew wegħda kbira għall-irkupru awtomatiku tal-POI. Xi metodi QA eżistenti jistgħu jiġu adottati fuq dan il-kompitu bħall-kalkolu tas-similarità QA u l-analiżi semantika bl-użu ta’ regoli definiti minn qabel. Ir-riżultati ritornati, madankollu, huma soġġetti g ħal limitazzjonijiet inerenti minħabba n-nuqqas ta’ kapaċità għall-immaniġġjar ta’ xi informazzjoni importanti relatata mal-POI, inklużi t-tikketti, l-entitajiet tal-post, u termini relatati mal-viċinanza (pereżempju “qrib”, “qrib”). F’dan id-dokument, qed nippreżentaw qafas ġdid ta’ tag ħlim profond integrat ma’ inferenza konġunta biex tinqabad kemm korrelazzjoni semantika kif ukoll ġeografika bejn mistoqsijiet u POIs. Karatteristika waħda tal-mudell tagħna hija li tipproponi kwistjoni speċjali ta’ attenzjoni inkroċjata li tinkorpora struttura tan-netwerk newrali biex tinkiseb informazzjoni mistoqsija-għal-POI u POI-għal-mistoqsija. Barra minn hekk, a ħna nużaw distribuzzjoni skewed biex ninsimulaw ir-relazzjoni ġeografika bejn mistoqsijiet u POIs. Billi nqisu r-riżultati offruti mill-mudell kontra l-metodi eżistenti, nagħmlu xhieda tar-robustezza u l-prattikabbiltà tiegħu, u ssupplimentaw il-konklużjonijiet tagħna b'evidenza empirika.", 'ro': 'Răspunsul la întrebări orientat spre puncte de interes (POI) vizează returnarea unei liste a POI-urilor acordate unei întrebări emise de un utilizator. Progresele recente în domeniul asistenților virtuali inteligenți au deschis posibilitatea de a angaja software-ul client mai activ în furnizarea de servicii bazate pe locație, arătând astfel o mare promisiune pentru recuperarea automată a POI. Unele metode de QA existente pot fi adoptate pentru această sarcină, cum ar fi calculul similitudinii QA și analizarea semantică folosind reguli predefinite. Cu toate acestea, rezultatele returnate sunt supuse unor limitări inerente datorită lipsei capacității de a gestiona unele informații importante legate de POI, inclusiv etichete, entități de localizare și termeni legate de proximitate (de exemplu, "apropiere", "închide"). În această lucrare, prezentăm un nou cadru de învățare profundă integrat cu inferență comună pentru a capta atât corelația semantică a etichetelor, cât și cea geografică dintre întrebare și POI. O caracteristică a modelului nostru este aceea de a propune o întrebare specială de atenție încrucișată care încorporează structura rețelei neurale pentru a obține informații întrebare-la-POI și POI-la-întrebare. În plus, utilizăm o distribuție distorsionată pentru a simula relația spațială dintre întrebări și POI. Prin măsurarea rezultatelor oferite de model în raport cu metodele existente, demonstrăm robustețea și caracterul practic al acestuia și completăm concluziile noastre cu dovezi empirice.', 'sr': 'Odgovor na odgovor na pitanje (QA) na to čku interesa (POI) je cilj vratiti listu POI-a koje je dao pitanje koje je izdao korisnik. Nedavno napredak u inteligentnim virtualnim asistentima otvorio je mogućnost aktivnijeg uključivanja softvera klijenta u pružanju usluga na lokaciji, tako pokazujući veliko obećanje za automatsko preuzimanje POI-a. Neke postojeće metode QA mogu biti usvojene na ovaj zadatak kao što su računa sličnosti QA i semantična analiza koristeći predodređena pravila. Međutim, povratni rezultati su podloženi inherentnim ograničenjima zbog nedostatka sposobnosti za rješavanje nekih važnih informacija povezanih sa POI-om, uključujući etikete, lokacione entitate i uslove povezanih sa blizinom (npr. “blizu”, “blizu”). U ovom papiru predstavljamo novi okvir dubokog učenja integrisan sa zajedničkom infekcijom kako bi uhvatili semantičku i geografsku korelaciju između pitanja i POI-a. Jedna karakteristika našeg model a je da predložimo posebno prekršno pitanje pažnje, uključujući strukturu neuralne mreže, kako bi dobili informacije o pitanju na POI i POI na pitanje. Osim toga, iskoristili smo raskidnu distribuciju da simuliramo prostornu vezu između pitanja i POI-a. Izmjerenjem rezultata koji je model ponudio protiv postojećih metoda, pokazujemo njegovu robustnost i praktičnost, i dodajemo naše zaključke empiričkim dokazima.', 'no': 'Punkt av Interest (POI) orientert spørsmål som svarar (QA) er målet å returnera ei liste over POI- oppgjeven eit spørsmål som utgjeven av ein brukar. Nyleg har avanserte i intelligente virtuelle assistentar opna muligheten for å engasjera klientprogramvaren meir aktivt i tillegget av lokasjonsbaserte tenester, slik at det viser stor promet for automatisk POI-henting. Noen eksisterande QA-metodar kan brukast på denne oppgåva, som QA-kalkulasjon og semantisk tolking med føredefinerte reglar. Den returnerte resultatene er imidlertid subject to inherent limitations due to the lack of ability for handling some important POI related information, including tags, location entities and proximity-related terms (e.g. "near", "close"). I denne papiret presenterer vi eit nytt dyp læringsrammeverk integrert med kopla infeksjon for å henta både tagg semantisk og geografisk korrelasjon mellom spørsmål og POI. Eit karakteristikk av modellen vårt er å foreslå eit spesielt kryss oppmerksomslag som innebyr neuralnettverksstrukturen for å få spørsmål-til-POI og POI-til-spørsmål-informasjon. I tillegg bruker vi ein skilte distribusjon for å simulere mellomromforholdet mellom spørsmål og POI. Med å måle resultatet tilbygde av modellen mot eksisterande metodar, viser vi kraftighet og praktisk, og legger sammen konklusjonane våre med empiriske beviser.', 'mn': 'Хэрэглэгчийн гаргасан асуулт (QA) цэг-интерест (POI) асуулт хариулт (QA) нь хэрэглэгчийн гаргасан асуулт өгөгдсөн POI-ын жагсаалтыг буцаах зорилго юм. Саяхан ухаантай виртуал тусламжийн хөгжлийн тусламжтайгаар клиент програм хангамжийг илүү актив оролцох боломжтой болсон бөгөөд байр суурилсан үйлчилгээний тусламжтайгаар автоматжуулах POI-г автоматжуул QA тэнцүү тооны тооцоолол болон semantic хуваалцах нь өмнө тодорхойлогдсон дүрмийг ашиглаж болох зарим QA арга замыг ашиглаж болно. Гэхдээ буцаагдсан үр дүн нь зарим чухал POI-тэй хамааралтай мэдээллийг удирдах боломжгүй болохоор хамааралтай хэмжээсүүдтэй холбоотой байдаг. Энэ цаасан дээр бид асуулт болон POI-ын хоорондын семантик болон географик холбоотой холбоотой холбоотой шинэ гүн гүнзгий суралцах үйл ажиллагааны системийг бий болгодог. Бидний загварын нэг тодорхойлолт нь сэтгэл зүйн сүлжээний бүтцийг асуулт POI болон POI-т асуулт өгөгдлийн тулд нэмэгдүүлэх төвөгтэй анхаарлын асуултыг санал болгох юм. Үүнээс гадна бид асуулт болон POI хоорондын орон зай холбоотой холбоотой хуваарилалтыг ашиглаж байна. Үүний үр дүнг хэмжээгээр оршиж буй арга загварын эсрэг хэмжээгээр бид түүний хүчтэй, бодит байдлыг харуулж, эзэмшигтэй баталгаатай нэмэгдүүлж байна.', 'pl': 'Odpowiedzi na pytania zorientowane na punkt zainteresowania (QA) mają na celu zwrócenie listy punktów POI podanych pytaniu wydanemu przez użytkownika. Ostatnie postępy w zakresie inteligentnych wirtualnych asystentów otworzyły możliwość aktywniejszego zaangażowania oprogramowania klienta w świadczenie usług lokalizacyjnych, co pokazuje ogromną obietnicę automatycznego pobierania POI. Niektóre istniejące metody QA mogą być przyjęte do tego zadania, takie jak obliczanie podobieństwa QA i parsowanie semantyczne przy użyciu wstępnie zdefiniowanych reguł. Zwracane wyniki podlegają jednak nieodłącznym ograniczeniom ze względu na brak możliwości obsługi niektórych ważnych informacji związanych z punktem POI, w tym znaczników, jednostek lokalizacji i terminów związanych z bliskością (np. "blisko", "blisko"). W niniejszym artykule przedstawiamy nowe ramy głębokiego uczenia zintegrowane ze wspólnymi wnioskami, aby uchwycić zarówno semantyczną, jak i geograficzną korelację między pytaniem a POI. Jedną z cech naszego modelu jest zaproponowanie specjalnego pytania o uwagę krzyżową osadzającego strukturę sieci neuronowej w celu uzyskania informacji o pytaniu-do-POI i POI-to-pytanie. Poza tym, wykorzystujemy skrzywiony rozkład do symulacji przestrzennej relacji między pytaniami a POI. Pomierzając wyniki oferowane przez model na tle istniejących metod, demonstrujemy jego solidność i praktyczność, a nasze wnioski uzupełniamy dowodami empirycznymi.', 'si': 'ප්\u200dරශ්න ප්\u200dරශ්න (POI) ප්\u200dරශ්න ප්\u200dරශ්නයක් (QA) ලක්ෂණයෙන් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප ඉතින් විශ්වාසික අවස්ථාවක් සහායකයෙන් ප්\u200dරධානය කරනවා ස්ථානයේ ආධාරිත සේවාවය සඳහා ස්වයංක්\u200dරියාත්මක සම්බන්ධ වෙන්න QA විදිහට තියෙන්න පුළුවන් විදිහට මේ කාර්යයේදි QA වගේ ගණනය සහ semantic පරීක්ෂණය යුද්ධ කරන්න පුළුවන්. නමුත්, ආපහු ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d මේ පැත්තට, අපි ප්\u200dරශ්නය සහ POIs අතර සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් සැමැන්ටික් සහ භූතික සම්බන්ධ වෙනුවෙන අපේ මොඩල් එක්ක ප්\u200dරශ්නයක් තමයි විශේෂ අවධානයක් ප්\u200dරශ්නයක් සම්බන්ධ කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් POI සහ POI-සම් ඒ වගේම, අපි ප්\u200dරශ්නය සහ POI අතර අතර අතර සම්බන්ධ සම්බන්ධයක් ප්\u200dරයෝජනය කරනවා. ඉතින් විදියට විරුද්ධ විරුද්ධ විරුද්ධ විරුද්ධ විදියට ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d', 'sv': 'Point-of-Interest (POI) orienterat frågesvar (QA) syftar till att returnera en lista över POI som ges en fråga utfärdad av en användare. De senaste framstegen inom intelligenta virtuella assistenter har öppnat möjligheten att engagera klientprogramvaran mer aktivt i tillhandahållandet av platsbaserade tjänster, vilket visar stora löften för automatisk hämtning av POI. Vissa befintliga kvalitetssäkringsmetoder kan användas för den här uppgiften, till exempel beräkning av kvalitetssäkring och semantisk tolkning med fördefinierade regler. De returnerade resultaten är dock föremål för inneboende begränsningar på grund av bristen på möjlighet att hantera viss viktig information relaterad till POI, inklusive taggar, platsenheter och närhetsrelaterade termer (t.ex. "nära", "stäng"). I denna uppsats presenterar vi ett nytt ramverk för djupinlärning integrerat med gemensam inferens för att fånga både taggsemantisk och geografisk korrelation mellan fråga och POI. En egenskap hos vår modell är att föreslå en speciell korsuppmärksamhetsfråga som inbäddar neurala nätverksstruktur för att erhålla fråga-till-POI och POI-till-fråga information. Dessutom använder vi en sned fördelning för att simulera den rumsliga relationen mellan frågor och POI. Genom att mäta modellens resultat mot befintliga metoder demonstrerar vi dess robusthet och genomförbarhet och kompletterar våra slutsatser med empirisk evidens.', 'ur': 'پوئنٹ-of-interest (POI) منظور سوال جواب (QA) کا ارادہ ہے کہ ایک کارساز کے ذریعہ ایک سوال دی گئی POI کے ایک لکھی لوٹائے۔ اس کے ذریعہ سے بہت اچھا وعدہ ہے کہ موقعیت پر بنیاد رکھی ہوئی خدمات کے سفارشی کے ذریعہ کالائٹ سوفٹوفر کو زیادہ فعال کرنے کی امید ہے۔ کچھ موجود QA طریقے اس کام پر قبول کر سکتے ہیں جیسے QA برابری کا شمار اور سیمانٹی پارسینگ پیش فرض کی قوانین کے مطابق۔ However, the returned results are subject to inherent limitations due to the lack of ability for handling some important POI related information, including tags, location entities, and nearby-related terms (e.g. “nearby”, “close”). اس کاغذ میں ہم ایک نوم عمیق سیکھنے کا فرمود پیش کرتے ہیں جو سوال اور پوئس کے درمیان سیمنٹی اور جغرافیک تعلق کو پکڑنے کے لئے ایک جوڑی سیکھنے کا فرمود ہے۔ ہمارے مدل کا ایک شخصیت یہ ہے کہ ایک مخصوص مخصوص مشورہ سوال کی پیشنهاد کرنا ہے جو نئورل نیٹورک ساختاری کے لئے سوال-POI اور POI-سوال کی اطلاعات حاصل کرنا ہے۔ اور ہم نے سوال اور پوئیس کے درمیان فضائی رابطہ کو سیمولیٹ کرنے کے لئے ایک سیمولیٹ تقسیم کا استعمال کیا ہے. موجود طریقوں کے مقابلہ میں موجود نتیجے کا اندازہ کرکے ہم اس کی طاقت اور قابلیت کو دکھاتے ہیں اور ہمارے نتیجے مضبوط دلیل کے ساتھ اضافہ کرتے ہیں.', 'so': "Point-of-Interest (POI) oriented question answering (QA) aims to return a list of POIs given a question issued by a user.  Horumarinta ugu dambeysa ee caawiyayaasha virus-ka ah ayaa fursaday suurtagalka in dhakhtarka dhaqaalaha laga soo wadayo adeegyada degmada, taasoo lagu tusiyo ballan weyn oo ay horumar u leeyihiin dib u soo qaadashada POI. Shaqadan waxaa lagu qaadan karaa qaabab QA ah oo ay jiraan, tusaale ahaan QA xisaab u eg xisaabta islamarkaasna baaritaanka semantika ah oo lagu isticmaali karo sharciyada horay loo qoray. Si kastaba ha ahaatee resultiyada dib u soo celinta waxaa laga heli karaa xadooyin joogto ah, sababtoo ah baahida aan awood u yeelan karin macluumaad muhiim ah oo la xiriira POI, tusaale ahaan tagsiga, meelaha la dego iyo xiriirka xigaanka (tusaale, “dhow”, “close”). Qoraalkan waxaynu ku qornaa qoraal aad u dheer oo waxbarasho ah oo la qabsaday iskuul ka mid ah, si aan u qabno xiriir u dhexeeya su’aalaha iyo POIs. Tusaale ahaan mid ka mid ah waa in uu soo jeedo su'aal gaar ah oo iskuul ah oo ku jirta dhismaha shabakadda neurada si uu u helo macluumaad su'aal-su'aal-POI iyo POI-su'aal-su'aalaha. Sidoo kale waxaynu isticmaalnaa qaybinta sawirida si aan u simno xiriirka cimilka ee u dhexeeya su'aalaha iyo POIs. Si aan u qiyaasayno resultiyada modelka ka gees ah qaababka joogta, waxaynu muujinnaa dharkiisa iyo tababaridiisa, waxaana ku dareynaa dhamaanshaheenna si caddayn ah.", 'ta': 'தேர்ந்தெடுக்கப்பட்ட கேள்வி பதில் (QA) ஒரு பயனர் வழங்கப்பட்ட கேள்வி கொடுக்கப்பட்ட POIs பட்டியலை திருப்ப வேண்டும். புதிய மெய்நிகர் உதவியாளர்களின் சமீபத்தில் முன்னேற்றம் திறந்து வாங்கிய மென்பொருள் மென்பொருளை மேலும் செயல்படுத்த வேண்டியிருக்கிறது, இடத்த முன் வரையறுக்கப்பட்ட விதிகளை பயன்படுத்தி சில QA முறைமைகள் இந்த செயல்பாட்டில் பயன்படுத்தலாம் QA போன்ற கணக்கீடு மற்றும் பாதி ஆனால் திரும்பி முடிவுகள் உள்ள வரம்புகள் கையாளும் சில முக்கியமான POI தகவல்களைக் கையாளும் காரணத்தால் உள்ள வரம்புகளுக்கு கட்டுப்படுகிறது, சில ஒட்டுகள், இடம் ப இந்த காகிதத்தில், நாம் ஒரு புதிய ஆழமான கற்றுக்கொள்ளும் சட்டத்தை காண்பிக்கிறோம் கேள்வி மற்றும் POIs இடையே இருப்பிலும் குறியீ எங்கள் மாதிரியின் ஒரு சிறப்பு குறிப்பு கவனம் கேள்வியை முன்நோக்குகிறது புதிய பிணையத்தின் வலைப்பின்னல் அமைப்பு உள்ளது கேள்வி  அதற்கும் மேலும், நாம் ஒரு வரையப்பட்ட பங்கீட்டை பயன்படுத்தி கேள்விகள் மற்றும் POIs இடையே இடையேயுள்ள வெளியீட்டு  மாதிரி வழங்கப்பட்ட முடிவுகளை அளக்கினால், நாம் ஏற்கெனவே இருக்கும் முறைகளுக்கு எதிராக க காட்டுகிறோம், அதன் ஆட்சியையும் இயக்கு', 'uz': "Name Yaqinda, virtual yordamchilar davomida taʼminlovchi darajalar davomida dasturni ishga tushirish imkoniyatini ochib, manzil asosidagi xizmatlarni saqlash imkoniyatini ishga tushirish imkoniyatini ko'rsatadi. @ info: whatsthis @ info: status Bu qogʻozda, biz savol va POIs orasidagi semantik va geografi bog'liqni qabul qilish uchun eng yaxshi o'rganish qatlamni o'rganamiz. Modemizning bir hususiyati esa, neyrol tarmoq tizimini qo'shish uchun maxsus foydalanuvchi soʻzni tahlil qilish uchun savol va POI va savol haqida maʼlumotni olish uchun. Ko'rsatilgan, biz soʻrovlar va POIs orasidagi spatial munosabasini kamaytirish uchun chizish tarkibini foydalanamiz. Model modelining natijalarini o'zgartirish orqali o'zgartirish bilan, biz uni o'zgarishni va ishlatishni ko'rsatamiz va ishimizni qo'shish mumkin.", 'vi': 'Mục đích của câu hỏi nhạy bén (POI) là trả lời câu hỏi theo mục đích trả lời (QA) để trở lại danh sách dữ liệu được đưa ra bởi người dùng câu hỏi. Những tiến bộ gần đây của các trợ lý ảo thông minh đã mở rộng khả năng sử dụng phần mềm khách hàng một cách tích cực hơn trong việc cung cấp dịch vụ dựa trên địa điểm, cho thấy một hứa hẹn lớn cho việc phục hồi POI tự động. Một số phương pháp QA đã có thể được áp dụng trong nhiệm vụ này, như tính chung quanh QA và phân tích theo quy định đã được xác định. Tuy nhiên, kết quả được cung cấp đều bị hạn chế bởi sự thiếu khả năng xử lý một số thông tin quan trọng liên quan tới POI, bao g ồm thẻ, địa điểm, và các điều khoản liên quan đến gần nhau (v. d. 822;gần 892; Trong bài báo này, chúng tôi giới thiệu một cơ sở học sâu mới có kết hợp với việc đồng kết luận về khái niệm chữ nghĩa và địa điểm tương quan giữa câu hỏi và ngóng. Một đặc trưng của mô hình là đề xuất một vấn đề quan tâm đặc biệt gắn kết cấu trúc mạng thần kinh để có được thông tin giữa câu hỏi và câu hỏi. Bên cạnh đó, chúng tôi sử dụng phân phối lệch để mô phỏng mối quan hệ không gian giữa các câu hỏi và POI. Bằng cách đo kết quả của mô hình dựa trên các phương pháp tồn tại, chúng tôi thể hiện sự vững chắc và thực tế của nó, và kết luận của chúng tôi được cải thiện bằng chứng cứ.', 'nl': "Point-of-Interest (POI) oriented question responsing (QA) heeft als doel een lijst van POI's te retourneren die een vraag van een gebruiker hebben gekregen. Recente vooruitgang op het gebied van intelligente virtuele assistenten heeft de mogelijkheid geopend om de clientsoftware actiever te betrekken bij het leveren van locatiegebaseerde diensten, wat een grote belofte toont voor automatische POI-opvraging. Sommige bestaande QA-methoden kunnen voor deze taak worden overgenomen, zoals QA-gelijkenisberekening en semantische parsing met behulp van vooraf gedefinieerde regels. De geretourneerde resultaten zijn echter onderhevig aan inherente beperkingen vanwege het ontbreken van de mogelijkheid om bepaalde belangrijke POI-gerelateerde informatie te verwerken, waaronder tags, locatie-entiteiten en nabijheidsgerelateerde termen (bijvoorbeeld 'dichtbij', 'dicht'). In dit artikel presenteren we een nieuw deep learning framework geïntegreerd met gezamenlijke inferentie om zowel tag semantische als geografische correlatie tussen vraag en POI's vast te leggen. Een kenmerk van ons model is om een speciale kruisaandachtsvraag voor te stellen die neurale netwerkstructuur insluit om vraag-naar-POI en POI-naar-vraag informatie te verkrijgen. Daarnaast gebruiken we een scheeve verdeling om de ruimtelijke relatie tussen vragen en POI's te simuleren. Door de resultaten van het model te meten aan bestaande methoden, tonen we de robuustheid en uitvoerbaarheid ervan aan en vullen we onze conclusies aan met empirisch bewijs.", 'bg': 'Целта на отговора на въпроси, ориентирани към точка на интерес (ПОИ), е да върне списък на ПОИ, зададен от потребител въпрос. Последният напредък в интелигентните виртуални асистенти отвори възможността за ангажиране на софтуера на клиента по-активно в предоставянето на услуги, базирани на местоположението, като по този начин показва голямо обещание за автоматично извличане на ПОИ. Някои съществуващи методи за контрол на качеството могат да бъдат приети за тази задача, като например изчисляване на сходството и семантичен анализ с помощта на предварително определени правила. Върнатите резултати обаче са обект на присъщи ограничения поради липсата на възможност за обработка на някои важни данни, свързани с ПО, включително маркери, обекти за местоположение и термини, свързани с близостта (напр. "наблизо", "затворено"). В настоящата статия представяме нова рамка за дълбоко учене, интегрирана със съвместни изводи, за да се улови както семантична, така и географска корелация между въпросите и пощенските обекти. Една от характеристиките на нашия модел е да предложим специален въпрос за кръстосано внимание, включващ структурата на невронната мрежа, за да се получи информация от въпрос към точка и точка към въпрос. Освен това използваме изкривено разпределение, за да симулираме пространствената връзка между въпросите и POIs. Чрез измерване на резултатите, предлагани от модела спрямо съществуващите методи, ние демонстрираме неговата стабилност и практичност и допълваме заключенията си с емпирични доказателства.', 'da': 'Point-of-Interest (POI) orienteret spørgsmål besvarelse (QA) har til formål at returnere en liste over POI\'er givet et spørgsmål udstedt af en bruger. De seneste fremskridt inden for intelligente virtuelle assistenter har åbnet mulighed for at engagere klientsoftwaren mere aktivt i leveringen af lokationsbaserede tjenester, hvilket viser store løfter for automatisk POI hentning. Nogle eksisterende QA-metoder kan anvendes på denne opgave, f.eks. beregning af QA-lighed og semantisk fortolkning ved hjælp af foruddefinerede regler. De returnerede resultater er dog underlagt iboende begrænsninger på grund af manglende evne til at håndtere nogle vigtige oplysninger relateret til seværdigheder, herunder tags, placeringsenheder og nærhedsrelaterede udtryk (f.eks. "nær", "luk"). I denne artikel præsenterer vi en ny dyb læringsramme integreret med fælles inference for at fange både tagsemantisk og geografisk korrelation mellem spørgsmål og POI\'er. Et kendetegn ved vores model er at foreslå et særligt krydsopmærksomhedsspørgsmål, der integrerer neurale netværksstruktur for at opnå spørgsmål-til-POI og POI-til-spørgsmål information. Desuden bruger vi en skæv fordeling til at simulere det rumlige forhold mellem spørgsmål og POI\'er. Ved at måle modellens resultater i forhold til eksisterende metoder demonstrerer vi dens robusthed og gennemførlighed og supplerer vores konklusioner med empirisk evidens.', 'hr': 'Odgovor na odgovor na pitanje (QA) na to čku interesa (POI) ima cilj vratiti popis POI-a koji je dao pitanje koje je izdao korisnik. Nedavno napredak inteligentnih virtualnih pomoćnika otvorio je mogućnost aktivnijeg uključivanja softvera klijenta u pružanju usluga na lokaciji, te pokazujući veliko obećanje za automatsko preuzimanje POI-a. Na ovom zadatku se mogu usvojiti neke postojeće metode QA-a poput računa sličnosti QA-a i semantičke analize koristeći predodređene pravila. Međutim, povratni rezultati su podloženi inherentnim ograničenjima zbog nedostatka sposobnosti za rješavanje nekih važnih podataka povezanih s POI-om, uključujući etikete, lokalne subjekte i uslove povezanih s blizinom (npr. „blizu“, „blizu“, „blizu“). U ovom papiru predstavljamo novi okvir dubokog učenja integriran s zajedničkom infekcijom kako bi uhvatili semantičku i geografsku korelaciju između pitanja i POI-a. Jedna karakteristika našeg model a je predložiti posebno prekršno pitanje pažnje, uključujući strukturu neuralne mreže kako bi dobili informacije o pitanju na POI-u i POI-u-pitanju. Osim toga, koristimo raspored za simulaciju prostornog odnosa između pitanja i POI-a. Izmjerenjem rezultata koji je model ponudio protiv postojećih metoda, pokazujemo njegovu robustnost i praktičnost i dodajemo naše zaključke empiričkim dokazima.', 'id': "Point-of-Interest (POI) oriented question answering (QA) aims to return a list of POIs given a question issued by a user.  Recent advances in intelligent virtual assistants have opened the possibility of engaging the client software more actively in the provision of location-based services, thereby showing great promise for automatic POI retrieval.  Beberapa metode QA yang ada dapat diadopsi pada tugas ini seperti kalkulasi kesamaan QA dan penghuraian semantis menggunakan peraturan terdefinisi. Hasil yang dikembalikan, bagaimanapun, mengalami batasan inherent karena kekurangan kemampuan untuk menangani beberapa informasi penting berkaitan dengan POI, termasuk tag, entitas lokasi, dan istilah berkaitan dengan proximity (contohnya 'dekat', 'close'). Dalam kertas ini, kami mempersembahkan cadangan belajar dalam novel yang terintegrasi dengan kesimpulan bersama untuk menangkap kedua tag semantis dan korelasi geografik antara pertanyaan dan POI. Salah satu karakteristik dari model kita adalah untuk mengusulkan pertanyaan perhatian salib khusus yang memasukkan struktur jaringan saraf untuk mendapatkan informasi pertanyaan-ke-POI dan POI-ke-pertanyaan. Besides, we utilize a skewed distribution to simulate the spatial relationship between questions and POIs.  Dengan mengukur hasil yang ditawarkan oleh model melawan metode yang ada, kami menunjukkan kekuatan dan praktikasinya, dan menambahkan kesimpulan kami dengan bukti empiris.", 'de': 'Point-of-Interest (POI) orientierte Fragebeantwortung (QA) zielt darauf ab, eine Liste von POIs zurückzugeben, die einer Frage eines Benutzers gegeben wurden. Die jüngsten Fortschritte bei intelligenten virtuellen Assistenten haben die Möglichkeit eröffnet, die Client-Software aktiver in die Bereitstellung standortbasierter Dienste einzubinden und damit ein großes Potenzial für den automatischen POI-Abruf zu bieten. Einige bestehende QA-Methoden können für diese Aufgabe übernommen werden, wie QA-Ähnlichkeitsberechnung und semantisches Parsen mit vordefinierten Regeln. Die zurückgegebenen Ergebnisse unterliegen jedoch inhärenten Einschränkungen, da einige wichtige POI-bezogene Informationen nicht verarbeitet werden können, einschließlich Tags, Standortentitäten und nähere Begriffe (z. B. "in der Nähe", "in der Nähe"). In diesem Beitrag stellen wir ein neuartiges Deep Learning Framework vor, das mit gemeinsamer Inferenz integriert ist, um sowohl die semantische als auch die geographische Korrelation zwischen Frage und POIs zu erfassen. Ein Merkmal unseres Modells ist es, eine spezielle Queraufmerksamkeitsfrage vorzuschlagen, die neuronale Netzwerkstruktur einbettet, um Frage-zu-POI und POI-zu-Frage Informationen zu erhalten. Außerdem verwenden wir eine schiefe Verteilung, um die räumliche Beziehung zwischen Fragen und POIs zu simulieren. Durch die Messung der Ergebnisse des Modells mit bestehenden Methoden demonstrieren wir seine Robustheit und Praktikabilität und ergänzen unsere Schlussfolgerungen durch empirische Evidenz.', 'sw': "Point of Interest (POI) originally answering questions (QA) lengo la kurudisha orodha ya POI iliyotolewa na mtumiaji. Maendeleo ya hivi karibuni katika wasaidizi wa mtandao wa intaneti wamefungua uwezekano wa kuwashirikisha programu za kijinsia kwa haraka zaidi katika kutoa huduma za maeneo, na hivyo kuonyesha ahadi nzuri kwa ajili ya kurudishwa kwa POI binafsi. Baadhi ya mbinu zilizopo na QA zinaweza kuchukuliwa katika kazi hii kama vile hisabu za simu za QA na kuchimba kwa kutumia kanuni zilizoelezwa kabla. Matokeo yaliyorudishwa, hata hivyo, yanakabiliwa na vizuizi vya kudumu kwa sababu ya ukosefu wa uwezo wa kukabiliana na taarifa muhimu zinazohusiana na POI, ikiwa ni pamoja na tags, vifaa vya mahali na vipindi vya karibu (kwa mfano ‘karibu’, 'karibu’). Katika karatasi hii, tunaweka mfumo wa riwaya wa kujifunza yenye msingi wa kina unaohamasishwa na maambukizi ya pamoja ili kushika mahusiano ya kijiografia kati ya swali na POIs. Mtendaji mmoja wa mifano yetu ni kupendekeza swali maalum la kutangaza mfumo wa mitandao ya kijamii ili kupata taarifa za maswali na POI kwa maswali. Zaidi ya hayo, tunatumia usambazaji wa simulizi wa uhusiano wa angani kati ya maswali na POIs. Kwa kupima matokeo yaliyotolewa na modeli dhidi ya mbinu zilizopo, tunaonyesha nguo zake na uhalisia, na kuongeza hitimisho letu kwa ushahidi wa msisitizo.", 'fa': 'پاسخ پرسش\u200cهای مستقیم (POI) به نقطه\u200cی Interest (QA) هدف می\u200cدهد که یک فهرست POI را به یک سوال که توسط یک کاربر اخراج شده برگرداند. پیشرفت اخیرا در دستیاران مجازی هوشمند احتمال اینکه نرم افزار مشتری را بیشتر فعال\u200cتر در تحویل خدمات بنیاد محل باز کنند، با این نشان دادن قول بزرگی برای بازیابی POI خود. بعضی روش\u200cهای QA موجود در این کار می\u200cتوانند با استفاده از قوانین پیش\u200cتعریف استفاده کنند، تقسیم شبیه QA و تقسیم semantic. ولی نتیجه\u200cهای برگشته\u200cشده، به دلیل کمبود توانایی برای کنترل اطلاعات مربوط به POI مهم، شامل برچسب\u200cها، متحده\u200cهای موقعیت و شرایط مربوط به نزدیکترین (مثال «نزدیکترین», «نزدیک»). در این کاغذ، ما یک چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچها یک ویژگی از مدل ما این است که یک سوال مشخص توجه خاصی را پیشنهاد کنیم که ساختار شبکه عصبی را برای دریافت اطلاعات سوال به POI و POI به سوال دریافت کند. علاوه بر این، ما یک توزیع اسکال را برای شبیه سازی رابطه فضایی بین سوال و POI استفاده می کنیم. با اندازه\u200cگیری نتیجه\u200cهایی که توسط مدل پیشنهاد می\u200cشود بر خلاف روش\u200cهای موجود، ما استعداد و قابلیت آن را نشان می\u200cدهیم، و نتیجه\u200cهایمان را با مدرک امپراتیک اضافه می\u200cکنیم.', 'ko': "관심사(POI)를 위한 퀴즈(QA)는 주어진 사용자 문제의 POI 목록을 되돌려주는 데 목적을 둔다.스마트 가상 보조원의 최신 진전은 클라이언트 소프트웨어를 더욱 적극적으로 사용하여 위치 기반 서비스를 제공하는 데 가능성을 열어 자동 POI 검색의 커다란 전망을 보여 주었다.일부 기존의 QA 방법은 이 작업에 사용할 수 있습니다. 예를 들어 QA 싱크로율 계산과 미리 정의된 규칙의 의미 해석을 사용합니다.그러나 일부 중요한 POI 관련 정보를 처리하는 능력이 부족하기 때문에 되돌아오는 결과는 라벨, 위치 실체와 인접성 관련 용어(예를 들어'부근','닫기'등)를 포함하여 고유의 제한을 받는다.본고에서 우리는 새로운 깊이 있는 학습 구조를 제시하고 연합 추리를 결합시켜 문제와 POI 간의 표기 의미와 지리적 관련성을 포착했다.이 모델의 특징 중 하나는 특수한 교차 주의 문제를 신경 네트워크 구조에 삽입하여 문제에 대한 문제와 문제에 대한 정보를 얻는 것이다.그 밖에 우리는 편향 분포를 이용하여 문제와 파송 간의 공간 관계를 모의한다.기존의 방법과 비교를 통해 우리는 이 모델의 안정성과 실용성을 증명했고 경험적인 증거로 우리의 결론을 보충했다.", 'sq': "Point-of-Interest (POI) oriented question answering (QA) aims to return a list of POIs given a question issued by a user.  Përparimet e fundit në asistentët inteligjentë virtual ë kanë hapur mundësinë e përfshirjes së programit të klientëve më aktivisht në furnizimin e shërbimeve bazuar në vendndodhje, duke treguar kështu premtimin e madh për marrjen automatike të POI. Disa metoda ekzistuese QA mund të miratohen në këtë detyrë të tilla si llogaritja e ngjashmërisë QA dhe analiza semantike duke përdorur rregulla të parapërcaktuara. Rezultatet e kthyera megjithatë janë subjekte të kufizimeve inerente për shkak të mungesës së aftësisë për trajtimin e disa informacioneve të rëndësishme të lidhura me POI, duke përfshirë etiketat, njësitë e vendosjes dhe termat e lidhura me afërsinë (për shembull 'afër', 'afër'). Në këtë letër, ne paraqesim një kuadër të ri të mësimit të thellë të integruar me përfundim të përbashkët për të kapur si korrelacionin semantik ashtu edhe gjeografik midis pyetjes dhe POIs. Një karakteristikë e modelit tonë është të propozojmë një çështje të veçantë vëmendjeje kryqësore që përfshin strukturën e rrjetit nervor për të marrë informacion pyetje-në-POI dhe POI-në-pyetje. Përveç kësaj, ne përdorim një shpërndarje të dobët për të simuluar marrëdhëniet hapësirore midis pyetjeve dhe POI. By measuring the results offered by the model against existing methods, we demonstrate its robustness and practicability, and supplement our conclusions with empirical evidence.", 'hy': 'Point-of-Interest (POI) oriented question answering (QA) aims to return a list of POIs given a question issued by a user.  Recent advances in intelligent virtual assistants have opened the possibility of engaging the client software more actively in the provision of location-based services, thereby showing great promise for automatic POI retrieval.  Գոյություն ունեցող QA մեթոդներ կարող են օգտագործվել այս խնդրի վրա, ինչպիսիք են QA նմանության հաշվարկումները և սեմանտիկ վերլուծությունը, օգտագործելով նախասահմանված կանոնները: Այնուամենայնիվ, վերադարձված արդյունքները ենթարկվում են բնորոշ սահմանափակումներին, որովհետև կարևոր POI-ի հետ կապված տեղեկատվության վերաբերյալ, ներառյալ թեգերը, տեղադրության միավորները և մոտավորության հետ կապված տերմինները (օրինակ «մոտակայքում», «մոտակայքում», In this paper, we present a novel deep learning framework integrated with joint inference to capture both tag semantic and geographic correlation between question and POIs.  Մեր մոդելի առանձնահատկությունն այն է, որ առաջարկենք հատուկ խաչը ուշադրության հարց, որը ներառում է նյարդային ցանցի կառուցվածքը, որպեսզի ստանանք հարց-առ-POI և POI-առ-հարց տեղեկատվություն: Ավելին, մենք օգտագործում ենք շեղված տարածումը հարցերի և POI միջև տարածական հարաբերությունների սիմուլյացիայի համար: Մոդելի առաջարկված արդյունքները գոյություն ունեցող մեթոդների հետ համեմատած չափելով, մենք ցույց ենք տալիս դրա կայունությունը և իրականացման կարողությունը, և մեր եզրակացությունները լրացնում ենք էմպրիկական ապացույցներով:', 'am': 'የPOI ጥያቄ መልስ የአሁኑ የውሃት ደረጃዎች የፖሊስ መመለስ ታላቅ ተስፋ ማሳየት ሲያሳየቱ የኮሌተር ሶፍትዌርን በመጠቀም በቦታ አገልግሎት ላይ እንዲያሳየፉ የሚችሉትን ግንኙነት ከፈቱ፡፡ የአሁኑ የQA ሥርዓት ነገር ግን የተመለሱት ውጤቶች፣ የፖሊስ የግንኙነት መረጃዎችን በመቀበል ስልጣን፣ መክፈቻ፣ ቦታ አካባቢዎች እና ቅርብ ግንኙነት (ምሳሌ ‘ቅርብ’ ‘ቅርብ’) በመስጠት ነው፡፡ በዚህ ገጽ፣ የጠልቅ ትምህርት ፍሬምበር እና የፖሊስ እና የመጠያቂያውን እና የግዮግራፊውን ግንኙነት ለመያዝ እና በተጠያየቅ ጥልቅ ትምህርት ፍሬም እናቀርባለን፡፡ One characteristic of our model is to propose a special cross attention question embedding neural network structure to obtain question-to-POI and POI-to-question information.  ከዚህም በቀር በጥያቄ እና በፖሊስ መካከል የስፋዊ ግንኙነትን ለመቀላቀል እናስጠይቃለን፡፡ ምሳሌ በተደረገው ሥርዓት ላይ የተደረገውን ፍሬዎችን በማስተካከል፣ የልብስነትን እና ልግስናውን እናሳየዋለን፣ ፍርዓታችንንም በማስማማት ማስረጃ እናደጋግማለን፡፡', 'bn': 'ব্যবহারকারীর দ্বারা প্রশ্ন প্রকাশিত প্রশ্নের উত্তর প্রশ্নের উদ্দেশ্য হচ্ছে পোআইসের তালিকা ফিরিয়ে দেওয়ার জন্য। বুদ্ধিমান ভার্চুয়াল সাহায্যকারীদের সাম্প্রতিক অগ্রগতি ক্লায়েন্ট সফটওয়্যার আরো সক্রিয় করে স্থানীয় ভিত্তিক সেবা প্রদান করার সম্ভাবনা খুলে  পূর্ব নির্ধারিত নিয়ম ব্যবহার করে কিছু বিদ্যমান QA পদ্ধতি এই কাজে গ্রহণ করতে পারে যেমন QA সমতামূলক গণনা এবং সেম্যান্টিক পার্স তবে ফিরে আসা ফলাফল বিভিন্ন সীমাবদ্ধতার কারণে কিছু গুরুত্বপূর্ণ পোআই সংক্রান্ত তথ্য নিয়ন্ত্রণের অভাব, যার মধ্যে ট্যাগ, অবস্থান এবং ক্ষেত্রের সংশ্লিষ্ এই কাগজটিতে আমরা একটি গভীর শিক্ষা ফ্রেম কাঠামো উপস্থাপন করছি যার মধ্যে যৌথ অসংক্রান্ত হয়ে যাচ্ছে প্রশ্ন ও পোআইসের মধ্যে দুটো ট্যাগের সে আমাদের মডেলের একটি চরিত্র হলো নিউরেল নেটওয়ার্ক কাঠামোর মধ্যে একটি বিশেষ প্রশ্নের প্রস্তাব করার জন্য প্রশ্ন-পোআই-থেকে প্রশ্নের তথ এছাড়াও, আমরা একটি আঁকা বিতরণ ব্যবহার করি প্রশ্ন ও পোআইসের মধ্যে স্পেশিয়াল সম্পর্ক সিমিল করার জন্য। বিদ্যমান পদ্ধতির বিরুদ্ধে মডেলের ফলাফল পরিমাপের মাধ্যমে আমরা তাদের রাস্তা এবং বৈশিষ্ট্যের বিরুদ্ধে প্রদর্শন করি এবং আমাদের পরিণতি স', 'az': "İstifadəçi tarafından çıxarılan bir sual verilən POI listesini qaytarmaq məqsədilə. Akıllı virtual yardımçıların son öyüd-nəsihətləri klient proqramını daha aktif olaraq yerə tabanlı servislər təyin etmək üçün açar və bu olaraq POI almaq üçün böyük vədə göstərər. QA similarity hesablaması və semantik analizi, əvvəlcə tanımlanmış qaydalar vasitəsilə, bu işdə QA metodları qəbul edilə bilər. Ancaq qaytarılmış sonuçlar, bəzi möhüm POI haqqında olan məlumatları, etiketlər, məlumatlar və yaxınlıq əlaqəsi ilə bağlı şartları (məsələn 'yaxınlıq', 'yaxınlıq', 'yaxınlıq') ilə istifadə etmək bacarılmasına g örə müəyyən ölçülərə layiqdirlər. Bu kağıtda, sual və POI arasındakı semantik və ģeogrāfiski bağlantıları tutmaq üçün birlikdə birlikdə olan yeni öyrənmə qurğunu göstəririk. Modelimizin bir xüsusiyyəti, sual-to-POI və POI-to-question məlumatlarını almaq üçün nöral şəbəkə strukturları içərisində xüsusiyyətli bir məlumat təklif etməkdir. Əksinə, suallar və POI arasındakı uzay ilişkisini simülə etmək üçün müxtəlif bir dağıtımı istifadə edirik. Modelin qurduğu sonuçlarını müəyyən etməklə, biz onun güclülüyünü və praktikanlığını göstərdik və sonuçlarımızı empirik kanıtlarına əlavə edirik.", 'af': "Punt- of- Interest (POI) orienteerde vraag antwoord (QA) doel om 'n lys van POI gegee 'n vraag deur' n gebruiker uitgevoer te terug. Onlangse vorderings in inteligente virtuele assistente het die moontlikheid van die kliënt sagteware meer aktief in die verskaffing van ligging-gebaseerde dienste oopgemaak, sodat groot belofte vir outomatiese POI-ontvanging vertoon word. Sommige bestaande QA metodes kan aangeneem word op hierdie taak soos QA gelykenis berekening en semantiese verwerking gebruik voor- gedefinieerde reëls. Die teruggekeerde resultate is egter onderwerp na inherende beperkinge vanweë die ontbreek van die moontlikheid vir behandeling van sommige belangrike POI verwante inligting, insluitend etikette, ligging entiteite en proximity-verwante terme (bv. 'naby', 'close'). In hierdie papier, voorsien ons 'n roman diep leer raamwerk wat integreer is met joint inferensie om beide etiket semantiese en geografiese korrelasie tussen vraag en POIs te vang. Een karakteristiek van ons model is om 'n spesiaal kruis aandag vraag te voorstel wat neuralnetwerk struktuur ingesluit om vraag-na-POI en POI-na-vraag inligting te kry. Ons gebruik ook 'n geskeide verspreiding om die spasiele verhouding tussen vrae en POIs te simuleer. Deur die resultate wat deur die model verskaf is teen bestaande metodes te maak, wys ons sy kragtigheid en praktiese toepassing en ons conclusies met empiriese getuienis bygevoeg.", 'tr': "Ullançy tarapyndan berilen POI-lariň (POI) jogabaty berilen soragy (QA) kabul etmek üçin maksady. Ýakynda intellek wirtual kömekçileriniň gelişmeleri klient softwaryny ýerleşdirilýän häsiýetleri üçin has gatnaşmak mümkinçiligini açdylar we şonuň üçin otomatik POI gaýd etmek üçin örän uly söz berdi. QA benzeri hasaplamak we semantik analyz edilen öň tanyş kurallary ullanýan öň bar kiçi bir QA metodlary bu işde ullanabilir. Ýeri geldikleri netijeler bolsa, birnäçe möhüm POI-bilen baglanylan maglumatlary ýok etmek üçin esasy çykyşlara meýdança çykyşlar we golaýlaşyk terjimelere (meselm. 'ýakyn', 'ýakyn'). Bu kagyzda, biz hem semantik hem POI-laryň arasyndaky hem çykyş öwrenmek üçin bir roman çykyşlygyny görkeýäris. Biziň nusgamyzyň bir karakteristiki näyral şebeke sistemasynda sorag-POI we POI-dan sorag maglumaty almak üçin has çarpak üns soragyny teklip etmekdir. Ayrıca, sorular ve POI arasındaki uzay ilişkilerini simüle etmek için bozulmuş bir dağıtım kullanırız. Öň bar yönlere garşy nusgalary örän nusgalary ölçüp, biz onuň ýigrenlişligini we praktikantlygyny görkez we näme netijesimizi empirik kanunlar bilen ekleýäris.", 'bs': 'Odgovor na odgovor na pitanje (QA) na to čku interesa (POI) je cilj vratiti listu POI-a koje je dao pitanje koje je izdao korisnik. Nedavno napredak inteligentnih virtualnih asistenata otvorio je mogućnost aktivnijeg uključivanja softvera klijenta u pružanju usluga na lokaciji, tako pokazujući veliko obećanje za automatsko preuzimanje POI-a. Neke postojeće metode QA mogu biti usvojene na ovaj zadatak kao što su računa sličnosti QA i semantička analiza koristeći predodređena pravila. Međutim, povratni rezultati su podloženi inherentnim ograničenjima zbog nedostatka sposobnosti za rješavanje nekih važnih informacija povezanih sa POI-om, uključujući etikete, lokacione entitate i uslove povezanih sa blizinom (npr. „blizu“, „blizu“, „blizu“). U ovom papiru predstavljamo novi okvir dubokog učenja integrisan sa zajedničkom infekcijom kako bi uhvatili semantičku i geografsku korelaciju između pitanja i POI-a. Jedna karakteristika našeg model a je da predložimo posebno prekršno pitanje pažnje, uključujući strukturu neuralne mreže kako bi dobili informacije o pitanju na POI i POI na pitanje. Osim toga, iskoristili smo skewed distribuciju kako bi simulirali prostornu vezu između pitanja i POI-a. Izmjerenjem rezultata koji je model ponudio protiv postojećih metoda, pokazujemo njegovu robustnost i praktičnost, i dodajemo naše zaključke empiričkim dokazima.', 'cs': 'Odpověď na otázky orientované na bod zájmu (QA) má za cíl vrátit seznam bodů orientovaných na otázku vydanou uživatelem. Nedávné pokroky v oblasti inteligentních virtuálních asistentů otevřely možnost aktivněji zapojit klientský software do poskytování služeb založených na poloze, čímž ukazují velký slib pro automatické vyhledávání POI. K tomuto úkolu lze přijmout některé stávající metody QA, jako je výpočet podobnosti QA a sémantická analýza pomocí předem definovaných pravidel. Vrácené výsledky však podléhají inherentním omezením z důvodu nedostatku schopnosti zpracovávat některé důležité informace související s POI, včetně značek, entit umístění a termínů souvisejících s blízkostí (např. "blízko", "blízko"). V tomto článku představujeme nový framework hlubokého učení integrovaný se společnými inferencemi, který zachycuje sémantickou i geografickou korelaci tagů mezi otázkou a POI. Jednou z charakteristik našeho modelu je navržení speciální křížové pozornosti otázky zahrnující strukturu neuronové sítě pro získání informací o otázkách na POI a POI na otázku. Kromě toho využíváme šikmou distribuci k simulaci prostorového vztahu mezi otázkami a POI. Měřením výsledků nabízených modelem proti existujícím metodám demonstrujeme jeho robustnost a praktičnost a doplníme naše závěry o empirické důkazy.', 'et': 'Huvipunktile orienteeritud küsimustele vastamise eesmärk on tagastada kasutaja poolt esitatud küsimusele esitatud huvipunktide nimekiri. Hiljutised edusammud intelligentsete virtuaalsete assistentide valdkonnas on avanud võimaluse klienditarkvara aktiivsemaks kaasamiseks asukohapõhiste teenuste osutamisse, näidates seeläbi suurt lubadust huvipunktide automaatseks otsimiseks. Selles ülesandes saab kasutusele võtta mõned olemasolevad kvaliteedi tagamise meetodid, näiteks kvaliteedi tagamise sarnasuse arvutamine ja semantiline parsimine, kasutades eelnevalt määratletud reegleid. Tagastatud tulemuste suhtes kehtivad siiski omapärased piirangud, kuna puudub võimalus käsitleda mõningat olulist huvipunktidega seotud teavet, sealhulgas sildid, asukohaüksused ja lähedusega seotud terminid (nt "läheduses", "sulgemas"). Käesolevas töös tutvustame uudset sügavõppe raamistikku, mis on integreeritud ühise järeldusega, et hõlmata nii sildi semantilist kui ka geograafilist korrelatsiooni küsimuste ja huvipunktide vahel. Üks meie mudeli omadus on pakkuda välja spetsiaalne risttähelepanu küsimus, mis sisaldab neurovõrgu struktuuri, et saada küsimus-huvipunktile ja huvipunktile-küsimusele teavet. Lisaks kasutame küsimuste ja huvipunktide ruumilise seose simuleerimiseks väänatud jaotust. Mõõtes mudeli pakutavaid tulemusi olemasolevate meetoditega, demonstreerime mudeli tugevust ja praktilisust ning täiendame oma järeldusi empiiriliste tõenditega.', 'fi': 'Point-of-Interest (POI) oriented quest answer (QA) pyrkii palauttamaan luettelon POI:ista, jotka ovat antaneet käyttäjän esittämän kysymyksen. Älykkäiden virtuaaliassistenttien viimeaikainen kehitys on avannut mahdollisuuden ottaa asiakasohjelmisto aktiivisemmin mukaan sijaintipohjaisten palvelujen tarjoamiseen, mikä on erittäin lupaavaa automaattiselle POI-hakulle. Tähän tehtävään voidaan soveltaa joitakin olemassa olevia laadunvarmistusmenetelmiä, kuten laadunvarmistuksen samankaltaisuuden laskentaa ja semanttista jäsentämistä ennalta määriteltyjen sääntöjen avulla. Palautetuihin tuloksiin kohdistuu kuitenkin luontaisia rajoituksia, jotka johtuvat siitä, ettei voida käsitellä joitakin tärkeitä kiinnostavia kohteita koskevia tietoja, kuten tunnisteita, sijaintiyksiköitä ja läheisyyteen liittyviä termejä (esim. "lähellä", "lähellä"). Tässä artikkelissa esitellään uusi syväoppimisen viitekehys, joka on integroitu yhteiseen päättelyyn, jotta voidaan tallentaa sekä tag semanttinen että maantieteellinen korrelaatio kysymyksen ja POI:n välillä. Yksi mallimme ominaisuus on ehdottaa erityistä ristikkäishuomiota sisältävää kysymystä, joka sulauttaa neuroverkkorakenteen kysymys-to-point ja POI-to-question informaation saamiseksi. Lisäksi käytämme vinoutunutta jakaumaa simuloimaan kysymysten ja kohteiden välistä spatiaalista suhdetta. Mittaamalla mallin tarjoamia tuloksia olemassa oleviin menetelmiin osoitamme sen kestävyyden ja käytännöllisyyden sekä täydennämme johtopäätöksiämme empiirisillä todisteilla.', 'ca': 'Point-of-Interest (POI) oriented question answering (QA) aims to return a list of POIs given a question issued by a user.  Recent advances in intelligent virtual assistants have opened the possibility of engaging the client software more actively in the provision of location-based services, thereby showing great promise for automatic POI retrieval.  Some existing QA methods can be adopted on this task such as QA similarity calculation and semantic parsing using pre-defined rules.  Però els resultats retornats estan sujets a limitacions inherents degut a la falta d\'habilitat de manipular alguna informació important relacionada amb la POI, incloent etiquetes, entitats de localització i termes relacionats amb la proximitat (per exemple "a prop", "a prop"). En aquest paper, presentem un nou marc d\'aprenentatge profund integrat amb una inferència conjunta per capturar la correlació semàntica i geogràfica entre preguntes i institucions POI. Una característica del nostre model és proposar una qüestió especial d\'atenció cruzada que incorpore l\'estructura de la xarxa neuronal per obtenir informació d\'una pregunta a una POI i d\'una POI a una pregunta. Besides, we utilize a skewed distribution to simulate the spatial relationship between questions and POIs.  Medint els resultats oferits pel model en comparació amb els mètodes existents, demostram la seva robustetat i practicabilitat i complementam les nostres conclusions amb evidències empíriques.', 'jv': 'Point-of Algorithm Algorithm Nanging, dadi, ono langkung saé mbutuhake nggawe limitiné sing gak bakal terus nggawe kapan kanggo nggawe informasi sing nggawe IGIO kang dipatengan, gambaran tags, entis lokasi, lan terêmêr terêmêr sing arep terêmêr (mm. "asêrbêng", "kapan"). Nang paper iki, kita mudhaya un ngupakan anyar nggambar luwih apik lan ijol-ijolan sing dibenalke nggawe tarjamahan semanti karo kelangan seneng dipun-ijolan sak cara nggawe Iki karcis ning model sing dumadhi kanggo nyebah akeh bantuan ingkang layang kanggo nguasai tanggal alam sing titimbang maneh dumadhi tanggal nggawe kesempatan-to-potI lan potI-to-question information. politenessoffpolite"), and when there is a change ("assertivepoliteness Nerimo kuwi nggawe sistem sing nyimpen ning model kuwi tindakan wis ana, awak dhéwé iso nggambar nggawe barang nggawe lan ijol-ijolan, lan unyangno dhéwé sampeyan geulakno karo awak dhéwé.', 'he': 'תשובת שאלה ממוקמת על נקודת עניין (POI) מטרה להחזיר רשימה של POIs שנתנה שאלה שנוצאה על ידי משתמש. התקדמות האחרונות בעוזרים וירטואליים אינטליגנטיים פתחו את האפשרות לערב את תוכנת הלקוח באופן פעיל יותר בספק שירותים מבוססים במיקום, ולכן הראו הבטחה גדולה לשיגור אוטומטי POI. כמה שיטות QA קיימות יכולות לאמץ על המשימה הזאת, כמו חישוב דומות QA ומחקר סמנטי באמצעות חוקים מוגדרים מראש. The returned results, however, are subject to inherent limitations due to the lack of the ability for handling some important POI related information, including tags, location entities, and proximity-related terms (e.g. “nearby”, “close”).  בעיתון הזה, אנו מציגים מסגרת למידה עמוקה רומנית שמתוקפת עם תוצאה משותפת כדי לתפוס את הקשר סמנטי וגיאוגרפי בין שאלה לבין POIs. אופיינת אחת של המודל שלנו היא להציע שאלה של תשומת לב צלב מיוחדת שמכילה מבנה רשת עצבית כדי להשיג מידע שאלה-אל-POI ו-POI-אל-שאלה. חוץ מזה, אנו משתמשים בהפצה סגורה כדי להדמיל את מערכת היחסים החלל בין שאלות לבין POIs. על ידי למדוד את התוצאות המוציאות על ידי המודל בהתאם לשיטות קיימות, אנחנו מראים את החזקה והאפשרות שלה, ומוספים את המסקנות שלנו עם ראיות אמפיריות.', 'sk': 'Namen odgovarjanja na vprašanja, usmerjenih v točke interesa (POI), je vrniti seznam zanimivih zanimivih točk, ki jih je izdal uporabnik. Nedavni napredek na področju inteligentnih virtualnih pomočnikov je odprl možnost aktivnejšega vključevanja odjemalske programske opreme v zagotavljanje storitev na podlagi lokacije, s čimer kaže veliko obetov za samodejno pridobivanje zanimivih točk. Za to opravilo je mogoče sprejeti nekatere obstoječe metode kakovosti, kot so izračun podobnosti kakovosti in semantično razčlenjevanje z uporabo vnaprej določenih pravil. Vendar so vrnjeni rezultati predmet neločljivih omejitev zaradi pomanjkanja zmožnosti ravnanja z nekaterimi pomembnimi informacijami, povezanimi z zanimivimi točkami, vključno z oznakami, lokacijskimi entitetami in izrazom, povezanimi z bližino (npr. "blizu", "zaprto"). V prispevku predstavljamo nov okvir globokega učenja, integriran s skupnimi sklepi, da bi zajeli tako semantično kot geografsko korelacijo oznak med vprašanjem in zanimivimi točkami. Ena od značilnosti našega modela je predlagati posebno vprašanje navzkrižne pozornosti, ki vključuje strukturo nevronskega omrežja za pridobivanje informacij vprašanja-do-zanimive točke in točke-do-vprašanja. Poleg tega uporabljamo nagnjeno porazdelitev za simuliranje prostorske povezave med vprašanji in zanimivimi točkami. Z merjenjem rezultatov modela glede na obstoječe metode dokazujemo njegovo robustnost in praktičnost ter dopolnjujemo svoje zaključke z empiričnimi dokazi.', 'ha': '@ action: button Bayani da aka buɗe masu taimakon masu aikin aiki da ke da shi, masu yiwuwa ya iya haɗa ma\'anar kwamfyuta kafyuta ta farat ɗaya a cikin abincin da aka samar da shi a wuri-wuri, kuma ya nuna wa\'adin mai girma wa motsi na farat-farat. QA Ana sami matsala da aka mayar da su, ko da kuma, ana sami tsari da ba\'a da ikon ya yi tafiyar da wasu information masu muhimu na shirin PoI, kamar tagogi, abubuwa da da masu danganta (misali, "wuri"). In this paper, we present a novel deep learning framework integrated with joint inference to capture both tag semantic and geographic correlation between question and POIs.  Babu wani mai ƙayyade daga misalinmu yana bukãta wani tambayi mai special fassarar aikinsa wanda ke ƙunsa da tsarin jerin neural zuwa-PoI da kuma don-tambayi. Bayan haka, za mu yi amfani da rabon yin taƙaita dõmin mu sami dangancin spashi a tsakanin tambayar da PSI. Ina iya ƙaddara fassarar da misãlin da aka bãyar da shi a kan hanyõyin da ke da, za mu nuna tufãfinsa da abin da yake a gaba, kuma mu ƙarfafa fassararmu da bayani na ƙaranci.', 'bo': 'Point-of-Interest (POI) oriented question answering (QA)aims to return a list of POIs given a question by a user. Recent advances in intelligent virtual assistant have opened the possibility of engaging the client software more actively in the provision of location-based services, thereby showing great promise for automatic POI retrieval. བྱ་འགུལ་འདིའི་ནང་དུ་གནས་ཡོད་པའི་QA རྒྱུན་ལྡན་གཞན་ཞིག་འཛིན་ཐུབ་པ། དཔེར་ན། QA similarity calculation and semantic parsing using pre-defined rules. ཡིན་ནའང་། དཔག འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་དུས་ཚོད་ཀྱི་སྐྱོན་རིམ་གྱི་གཞུང་ཚབ་ཞིག་སྟོན་དུ་ཡོད། ང་ཚོའི་མ་དབྱིབས དེ་ལས་ཀྱང་། ང་ཚོས་དྲི་ཚིག་དང་POIs་དབར་གྱི་བར་སྟོང་པའི་འབྲེལ་བ་ཞིག་གི་དབར་གྱི་གྲངས་རིམ་གྱི་བགོ་སྤྱད་ནས་ལག་ དབྱེ་བ་འདི་དག་གི་ལམ་ལུགས་དང་འཐབ་རྩོལ་བ་གཉིས་ཀྱིས་མཐུན་པ་ཡིན་པས། ང་ཚོས་རང་ཉིད་ཀྱི་སྟོབས་ཤུགས་དང་སྤྱིར་བཏང་བ་ཡོད་པ་'}
{'en': 'Leveraging Structured Metadata for Improving  Question Answering  on the Web', 'ar': 'الاستفادة من البيانات الوصفية المهيكلة لتحسين الإجابة على الأسئلة على الويب', 'es': 'Aprovechamiento de metadatos estructurados para mejorar la respuesta a preguntas en la web', 'fr': 'Exploiter les métadonnées structurées pour améliorer les réponses aux questions sur le Web', 'pt': 'Aproveitando Metadados Estruturados para Melhorar a Resposta a Perguntas na Web', 'ja': '構造化されたメタデータを活用してウェブ上の質問への回答を改善する', 'zh': '因结构化元数改 Web 对', 'ru': 'Использование структурированных метаданных для улучшения ответов на вопросы в Интернете', 'hi': 'वेब पर प्रश्न उत्तर देने में सुधार के लिए संरचित मेटाडेटा का लाभ उठाना', 'ga': 'Meiteashonraí Struchtúrtha a Ghiaráil chun Freagra Ceist ar an nGréasán a Fheabhsú', 'ka': 'სტრუქტურაციული მეტადატური მონაცემები ვებზე გასაუბრუნოთ კითხვების პასუხი', 'el': 'Αξιοποίηση δομημένων μεταδεδομένων για τη βελτίωση της απάντησης ερωτήσεων στο διαδίκτυο', 'hu': 'Strukturált metaadatok kihasználása a kérdések webes megválaszolásának javításához', 'it': 'Sfruttare i metadati strutturati per migliorare la risposta alle domande sul Web', 'lt': 'Struktūrinių metaduomenų, skirtų geriau atsakyti į klausimus internete, sklaida', 'kk': 'Вебтегі сұрақ жауаптарын жасау үшін құрылған метадеректерді шешу', 'mk': 'Разголемување на структурните метададани за подобрување на одговорите на прашањата на интернет', 'ml': 'വെബിലുള്ള ചോദ്യങ്ങള്\u200d മുന്\u200dകൂട്ടുന്നതിനുള്ള ഉത്തരം ലഭ്യമാക്കുന്നതിനായി മെറ്റാഡാറ്റ', 'ms': 'Leveraging Structured Metadata for Improving Question Answering on the Web', 'mt': 'Inżidu l-Metadejta Strutturata għat-Titjib tat-Tweġibiet għall-Mistoqsijiet fuq l-Internet', 'mn': 'Веб дээр асуулт хариултыг сайжруулахын тулд Structured Metadata', 'pl': 'Wykorzystanie ustrukturyzowanych metadanych do poprawy odpowiedzi na pytania w sieci Web', 'ro': 'Utilizarea metadatelor structurate pentru îmbunătățirea răspunsurilor la întrebări pe Web', 'no': 'Leverar strukturerte metadata for å forbetra spørsmålssvar på nettet', 'sr': 'Uspoređivanje strukturnih metapodataka za poboljšanje odgovora na pitanja na internetu', 'si': 'ජාලයේ ප්\u200dරශ්න ප්\u200dරතිච්චාරයක් වැඩි කරන්න ප්\u200dරශ්නයක් වැඩි කරන්න ස්ථාපනය වැඩි මෙටාඩේටා', 'so': 'Levering structured Metadata for improving queries answers internetka', 'sv': 'Utnyttja strukturerade metadata för att förbättra frågesvaret på webben', 'ta': 'இணையத்தில் கேள்வி முன்னேற்றத்திற்கான விடை', 'ur': 'ویب پر سوال جواب کے ساتھ بہتر کرنے کے لئے ساختاری مٹا ڈیٹا ڈیٹا استعمال کیا جاتا ہے', 'uz': 'Name', 'vi': 'Cung cấp siêu dữ liệu cấu trúc để cải thiện câu hỏi trên mạng', 'nl': 'Gebruiken van gestructureerde metadata voor het verbeteren van het beantwoorden van vragen op het web', 'bg': 'Използване на структурирани метаданни за подобряване на отговора на въпроси в интернет', 'hr': 'Usporavanje strukturnih metapodataka za poboljšanje odgovora na pitanja na internetu', 'da': 'Udnyttelse af strukturerede metadata til forbedring af spørgsmål besvarelse på internettet', 'de': 'Nutzung strukturierter Metadaten zur Verbesserung der Beantwortung von Fragen im Web', 'id': 'Menangkap Metadata Struktur untuk Menembak Jawaban Pertanyaan di Web', 'fa': 'تحت تأثیر داده\u200cهای Metadata ساخته شده برای بهترین پاسخ سوال در وب', 'ko': '구조화된 메타데이터를 이용하여 네트워크 문답을 개선하다', 'sw': 'Leveraging Structured Metadata for Improving Question Answering on the Web', 'tr': 'Sorag jogabyny bejermek üçin Structured Metadata Taýýarlanýar', 'af': 'Name', 'am': 'ጥያቄን ለመቀበል በመስጠት ላይ አቀማመጥ', 'sq': 'Shkatërrimi i metatë strukturuar për përmirësimin e përgjigjeve të pyetjeve në internet', 'az': 'İnternettə sual cavabını yaxşılaşdırmaq üçün Structured Metadata', 'hy': 'Վեբ-ի հարցերի պատասխանների բարելավման համար կառուցված մետատվյալներ բարելավելը', 'bs': 'Usporavanje strukturnih metapodataka za poboljšanje odgovora na pitanja na internetu', 'bn': 'ওয়েবে প্রশ্নের উত্তর প্রদানের জন্য লেভারেজিং নির্মাণ মেটাডাতা', 'cs': 'Využití strukturovaných metadat pro zlepšení odpovědi na otázky na webu', 'ca': 'Ampliar metadades estructuradas per millorar les respostes a preguntes a la Web', 'et': 'Struktureeritud metaandmete kasutamine küsimustele vastamise parandamiseks veebis', 'fi': 'Strukturoitujen metatietojen hyödyntäminen kysymyksiin vastaamisen parantamiseksi verkossa', 'jv': 'politenessoffpolite"), and when there is a change ("assertive', 'he': 'מעלה מיטנתונים מבוססים לשיפור תשובות לשאלות באינטרנט', 'bo': 'འཛམ་གླིང་གི་དྲ་ཐོག་ཏུ་མཐོ་གཏོང་བའི་དབུས་བཟོས་ཟིན་བྲིས་གནས་སྡུད་བཙལ་བཟོ་བཞིན་པ', 'sk': 'Izkoriščanje strukturiranih metapodatkov za izboljšanje odgovarjanja na vprašanja na spletu', 'ha': 'KCharselect unicode block name'}
{'en': 'We show that leveraging  metadata information  from  web pages  can improve the performance of  models  for answer passage selection / reranking. We propose a neural passage selection model that leverages  metadata information  with a fine-grained encoding strategy, which learns the representation for  metadata predicates  in a hierarchical way. The  models  are evaluated on the MS MARCO (Nguyen et al., 2016) and Recipe-MARCO datasets. Results show that our  models  significantly outperform baseline models, which do not incorporate  metadata . We also show that the fine-grained encoding’s advantage over other strategies for encoding the  metadata .', 'pt': 'Mostramos que alavancar informações de metadados de páginas da web pode melhorar o desempenho de modelos para seleção/reclassificação de passagem de resposta. Propomos um modelo de seleção de passagem neural que alavanca informações de metadados com uma estratégia de codificação refinada, que aprende a representação de predicados de metadados de forma hierárquica. Os modelos são avaliados nos conjuntos de dados MS MARCO (Nguyen et al., 2016) e Recipe-MARCO. Os resultados mostram que nossos modelos superam significativamente os modelos de linha de base, que não incorporam metadados. Mostramos também a vantagem da codificação refinada sobre outras estratégias de codificação dos metadados.', 'ar': 'نظهر أن الاستفادة من معلومات البيانات الوصفية من صفحات الويب يمكن أن يحسن أداء النماذج لاختيار / إعادة ترتيب الإجابة. نقترح نموذج اختيار الممر العصبي الذي يستفيد من معلومات البيانات الوصفية باستراتيجية تشفير دقيقة الحبيبات ، والتي تتعلم تمثيل مسندات البيانات الوصفية بطريقة هرمية. تم تقييم النماذج على مجموعات بيانات MS MARCO (Nguyen et al. ، 2016) و Recipe-MARCO. تُظهر النتائج أن نماذجنا تتفوق بشكل كبير على النماذج الأساسية ، التي لا تتضمن بيانات وصفية. نظهر أيضًا أن ميزة التشفير الدقيق تتفوق على الاستراتيجيات الأخرى لتشفير البيانات الوصفية.', 'es': 'Demostramos que aprovechar la información de metadatos de las páginas web puede mejorar el rendimiento de los modelos para la selección/reclasificación de pasajes de respuestas. Proponemos un modelo de selección de pasajes neuronales que aprovecha la información de metadatos con una estrategia de codificación detallada, que aprende la representación de los predicados de metadatos de forma jerárquica. Los modelos se evalúan en los conjuntos de datos MS MARCO (Nguyen et al., 2016) y RECIPE-MARCO. Los resultados muestran que nuestros modelos superan significativamente a los modelos de referencia, que no incorporan metadatos. También mostramos la ventaja de la codificación detallada sobre otras estrategias para codificar los metadatos.', 'fr': "Nous montrons que l'exploitation des informations de métadonnées provenant de pages Web peut améliorer les performances des modèles de sélection/reclassement des passages de réponses. Nous proposons un modèle de sélection de passage neuronal qui exploite les informations de métadonnées avec une stratégie de codage fine, qui apprend la représentation des prédicats de métadonnées de manière hiérarchique. Les modèles sont évalués sur les ensembles de données MS MARCO (Nguyen et al., 2016) et Recipe-Marco. Les résultats montrent que nos modèles surpassent de manière significative les modèles de base, qui n'intègrent pas de métadonnées. Nous montrons également que l'avantage de l'encodage fin par rapport aux autres stratégies d'encodage des métadonnées.", 'ja': 'ウェブページのメタデータ情報を活用することで、回答パスの選択/再ランク化のためのモデルのパフォーマンスを向上させることができることを示しています。メタデータ情報を細かい符号化戦略で活用し、メタデータ述語の表現を階層的に学習するニューラルパサージュ選択モデルを提案する。モデルは、ＭＳ Ｍａｒｃｏ （ Ｎｕｇｙｅｎ ｅ ｔ ａ ｌ ． ， ２ ０ １ ６ ）及びＲｅｃｉｐｅ － ＭＡＲＣＯデータセット上で評価される。結果は、当社のモデルがメタデータを組み込まないベースラインモデルを大幅に上回っていることを示しています。また、メタデータをエンコードするための他の戦略よりも、細かいエンコーディングの利点があることも示しています。', 'zh': '吾明利用网页元数以重对案段落择/更次之性也。 吾为神经道择模形,当用元数细粒度编码策,以分学元数谓词之。 其在MS MARCO(Nguyen等,2016)与Recipe-MARCO数集上评之。 结果表明,吾形明优于不包元数之基线。 又验细粒度编码对他元数编码策之胜。', 'hi': 'हम दिखाते हैं कि वेब पेजों से मेटाडेटा जानकारी का लाभ उठाने से उत्तर मार्ग चयन / पुनर्रैंकिंग के लिए मॉडल के प्रदर्शन में सुधार हो सकता है। हम एक तंत्रिका मार्ग चयन मॉडल का प्रस्ताव करते हैं जो मेटाडेटा जानकारी को एक ठीक-ठाक एन्कोडिंग रणनीति के साथ लाभ उठाता है, जो पदानुक्रमित तरीके से मेटाडेटा विधेय के लिए प्रतिनिधित्व सीखता है। मॉडल का मूल्यांकन एमएस मार्को (गुयेन एट अल. 2016) और रेसिपी-मार्को डेटासेट पर किया जाता है। परिणाम बताते हैं कि हमारे मॉडल बेसलाइन मॉडल को काफी बेहतर बनाते हैं, जिसमें मेटाडेटा शामिल नहीं है। हम यह भी दिखाते हैं कि मेटाडेटा को एन्कोडिंग करने के लिए अन्य रणनीतियों पर ठीक-ठाक एन्कोडिंग का लाभ।', 'ru': 'Мы показываем, что использование информации о метаданных с веб-страниц может улучшить производительность моделей для выбора/повторного ранжирования пассажей с ответами. Мы предлагаем модель выбора нейронных пассажей, которая использует информацию метаданных с мелкозернистой стратегией кодирования, которая изучает представление для предикатов метаданных иерархическим образом. Модели оцениваются на наборах данных MS MARCO (Nguyen et al., 2016) и Recipe-MARCO. Результаты показывают, что наши модели значительно превосходят базовые модели, которые не включают метаданные. Мы также показываем, что преимущество мелкозернистого кодирования по сравнению с другими стратегиями кодирования метаданных.', 'ga': 'Léirímid gur féidir le giaráil faisnéise meiteashonraí ó leathanaigh ghréasáin feabhas a chur ar fheidhmíocht na múnlaí do roghnú/athrangú sliocht freagraí. Molaimid múnla roghnúcháin sliocht néaraigh a ghiaráil faisnéis meiteashonraí le straitéis ionchódaithe mhíne, a fhoghlaimíonn ionadaíocht do thuartha meiteashonraí ar bhealach ordlathach. Déantar na samhlacha a mheas ar thacair sonraí MS MARCO (Nguyen et al., 2016) agus Oideas-MARCO. Léiríonn torthaí go sáraíonn ár samhlacha samhlacha bonnlíne go suntasach, nach n-ionchorpraíonn meiteashonraí. Léirímid freisin go bhfuil buntáiste ag an ionchódú míne thar straitéisí eile chun na meiteashonraí a ionchódú.', 'ka': 'ჩვენ ჩვენ აჩვენებთ, რომ მეტადატური ინფორმაცია ვებ გვერდიდან შეიძლება მოდელების გამოსახულებას გადავიწყება/გადავიწყება. ჩვენ მინდა ნეიროლური მონიშნული მოდელი, რომელიც მეტადატურების ინფორმაციას, რომელიც ძირითადი კოდირება სტრატიგიაზე გამოყენებს, რომელიც მეტადატურების პრედაქტირებას იერაქტიკურად მოდელები MS MARCO (Nguyen et al., 2016) და Recipe-MARCO მონაცემების კონფიგურაციაში გაუმუშავებულია. შემდეგ ჩვენი მოდელები მნიშვნელოვანია, რომლებიც მეტადატატატა არ შეიყვარს მნიშვნელოვანია. ჩვენ ასევე აჩვენებთ, რომ სხვა სტრატეგიაზე მეტარეტატატიკის კოდირების გამოსახულება სხვა კოდირების გამოსახულება.', 'hu': 'Megmutatjuk, hogy a weboldalakról származó metaadatok felhasználása javíthatja a modellek teljesítményét a válaszadások kiválasztására/átrendezésére. Javasolunk egy neurális átjáró kiválasztási modellt, amely finom szemű kódolási stratégiával használja a metaadatok információit, amely hierarchikus módon tanulja meg a metaadatok predikátumainak reprezentációját. A modellek értékelése MS MARCO (Nguyen et al., 2016) és Recipe-MARCO adatkészletek alapján történik. Az eredmények azt mutatják, hogy modelleink jelentősen felülmúlják az alapvető modelleket, amelyek nem tartalmaznak metaadatokat. Azt is megmutatjuk, hogy a finomszemű kódolás előnye a metaadatok kódolására vonatkozó más stratégiákkal szemben.', 'el': 'Δείχνουμε ότι η αξιοποίηση πληροφοριών μεταδεδομένων από ιστοσελίδες μπορεί να βελτιώσει την απόδοση των μοντέλων για την επιλογή/επανακατάταξη περάσματος απαντήσεων. Προτείνουμε ένα μοντέλο επιλογής νευρικού περάσματος που χρησιμοποιεί πληροφορίες μεταδεδομένων με μια λεπτή στρατηγική κωδικοποίησης, η οποία μαθαίνει την αναπαράσταση των προϋπολογισμών μεταδεδομένων με ιεραρχικό τρόπο. Τα μοντέλα αξιολογούνται στα σύνολα δεδομένων MS MARCO (Nguyen et al., 2016) και Recipe-MARCO. Τα αποτελέσματα δείχνουν ότι τα μοντέλα μας ξεπερνούν σημαντικά τα μοντέλα βάσης, τα οποία δεν ενσωματώνουν μεταδεδομένα. Δείχνουμε επίσης ότι το πλεονέκτημα της λεπτόκοκκης κωδικοποίησης έναντι άλλων στρατηγικών κωδικοποίησης των μεταδεδομένων.', 'it': "Dimostriamo che l'utilizzo delle informazioni sui metadati provenienti dalle pagine web può migliorare le prestazioni dei modelli per la selezione/riorientamento dei passaggi delle risposte. Proponiamo un modello di selezione del passaggio neurale che sfrutta le informazioni sui metadati con una strategia di codifica a grana fine, che impara la rappresentazione dei predicati dei metadati in modo gerarchico. I modelli sono valutati sui dataset MS MARCO (Nguyen et al., 2016) e Recipe-MARCO. I risultati mostrano che i nostri modelli superano significativamente i modelli di base, che non incorporano metadati. Mostriamo anche che la codifica a grana fine ha un vantaggio rispetto ad altre strategie per la codifica dei metadati.", 'kk': 'Біз веб- парақтардың мета- деректер мәліметін жауап таңдау/қайта таңдау үшін үлгілерін жақсартуға болады дегенді көрсетедік. Біз метадеректер мәліметін дұрыс кодтамасыз стратегиясы арқылы көмектесетін невралдық пассажасын таңдау үлгісін ұсынамыз. Бұл метадеректердің предикацияларын иерархиялық түрде үйренеді. Үлгілер MS MARCO (Nguyen et al., 2016) және Recipe- MARCO деректер қорларында бағалады. Нәтижелері біздің үлгілеріміздің метадеректері қосылмаған негізгі жол үлгілерінен артық болады. Метадеректерді кодтамасыз үшін басқа стратегиялардың артықшылығын көрсетеді.', 'lt': 'Mes rodome, kad naudojant interneto puslapių metaduomenų informaciją galima pagerinti atsakymų atrankos ir (arba) perskaičiavimo modelių veiksmingumą. Siūlome atrankos model į, pagal kurį metaduomenų informacija sutelkiama į svertą taikant tikslią kodavimo strategiją, kuri hierarchiškai supranta metaduomenų aprašymą. Modeliai vertinami pagal valstybių narių MARCO (Nguyen et al., 2016) ir MARCO recepto duomenų rinkinius. Rezultatai rodo, kad mūsų modeliai gerokai viršija pradinius modelius, kuriuose nėra metaduomenų. Mes taip pat parodome, kad smulkiojo kodavimo pranašumas, palyginti su kitomis metaduomenų kodavimo strategijomis.', 'mk': 'Ние покажуваме дека користењето на метададаните информации од веб страниците може да ја подобри перформансата на моделите за селекција/повторно поврзување на одговорите. We propose a neural passage selection model that leverages metadata information with a fine-grained encoding strategy, which learns the representation for metadata predicates in a hierarchical way.  Моделите се проценуваат на податоците на MS MARCO (Nguyen и ал., 2016) и Recipe-MARCO. Резултатите покажуваат дека нашите модели значително ги надминуваат основните модели, кои не вклучуваат метадатоци. Исто така, покажуваме дека предноста на финото кодирање во однос на другите стратегии за кодирање на метададаните.', 'ms': 'Kami menunjukkan bahawa penggunaan maklumat metadata dari halaman web boleh meningkatkan prestasi model untuk pemilihan/pemilihan semula laluan jawapan. Kami cadangkan model pemilihan laluan saraf yang menggunakan maklumat metadata dengan strategi pengekodan yang sempurna, yang mempelajari perwakilan bagi data metadata didikat dengan cara hierarkis. Model diteliti pada set data MS MARCO (Nguyen et al., 2016) dan Recipe-MARCO. Hasil menunjukkan bahawa model kita secara signifikan melebihi model asas, yang tidak mengandungi metadata. Kami juga menunjukkan keuntungan pengekodan yang baik daripada strategi lain untuk pengekodan metadata.', 'ml': 'വെബ് താളുകളില്\u200d നിന്നും മെറ്റേഡാറ്റ വിവരങ്ങള്\u200d ലഭ്യമാക്കുന്നത് മോഡലുകളുടെ പ്രഭാവം മുന്\u200dകൂട്ടിക്കൊടുക്കുന് ന്യൂറല്\u200d പാസ്സേജ് തെരഞ്ഞെടുക്കുന്ന ഒരു മോഡല്\u200d ഞങ്ങള്\u200d പ്രാദോഷിപ്പിക്കുന്നു. അത് മെറ്റാഡാറ്റ വിവരങ്ങള്\u200d നല്ല കോഡിങ്ങിന്റെ കൊണ്ട്  MS MARCO (Nguyen et al., 2016) എന്നിട്ടും MARCO ഡാറ്റാസറ്റുകളിലും മോഡലുകള്\u200d വിലാസപ്പെടുത്തുന്നു. Results show that our models significantly outperform baseline models, which do not incorporate metadata.  നമ്മളും കാണിക്കുന്നത് മെറ്റാഡാറ്റ എന്\u200dകോഡ് ചെയ്യുന്നതിനെക്കാള്\u200d നല്ല കോഡിങ്ങിന്\u200dറെ ഉപയോഗങ്ങളാണെന്ന', 'mt': 'Aħna nuru li l-ingranaġġ tal-informazzjoni dwar il-metadejta mill-paġni tal-internet jista’ jtejjeb il-prestazzjoni tal-mudelli għall-għażla tal-passaġġ tar-risposti/l-ikkunsidrar mill-ġdid. Aħna nipproponu mudell tal-għa żla tal-passaġġ newrali li jiġġenera l-informazzjoni dwar il-metadejta bi strateġija ta’ kodifikazzjoni bir-reqqa, li titgħallem ir-rappreżentazzjoni għall-predikati tal-metadejta b’mod ġerarkiku. Il-mudelli huma evalwati fuq is-settijiet tad-dejta tal-MS MARCO (Nguyen et al., 2016) u Recipe-MARCO. Ir-riżultati juru li l-mudelli tagħna jaqbżu b’mod sinifikanti l-mudelli tal-linja bażi, li ma jinkorporawx metadejta. Aħna nuru wkoll li l-vantaġġ tal-kodifikazzjoni bir-reqqa fuq strateġiji oħra għall-kodifikazzjoni tal-metadejta.', 'mn': 'Бид веб хуудас дээр мета өгөгдлийн мэдээллийг ашиглах нь хариултын сонголт/дахин ажиллах загварын үйлдлийг сайжруулж чадна. Бид мэдрэлийн дагуулын сонголтын загварыг санал болгож, мета-өгөгдлийн мэдээллийг бага зэрэг шийдвэрлэх стратегийнхээ тулд ашигладаг. Энэ нь мета-өгөгдлийн хэмжээсүүдийн илэрхийлэл ойлгомжтой. Моделууд MS MARCO (Nguyen et al., 2016) болон Recipe-MARCO өгөгдлийн санд үнэлгээгддэг. Үүний үр дүнд бидний загварууд мета өгөгдлийг бүрдүүлэхгүй суурь шугам загваруудыг маш их ашигладаг. Мөн бид мета өгөгдлийг кодлох боломжтой бусад стратеги дээр сайхан кодлогын үнэ цэнийг харуулж байна.', 'no': 'Vi viser at å leverara metadata-informasjon frå nettsider kan forbetra utviklinga av modeller for å svara på passordutval/gjenoppretting. Vi foreslår eit modell for utval av neuralpassasjon som leverer metadata- informasjon med ein fyrke kodingsstrategi, som lærer representasjonen for metadata predikar på ein hierarkisk måte. Modellene er evaluert på MS MARCO (Nguyen et al., 2016) og Recipe-MARCO-datasettet. Resultat viser at modellen våre utfører betydelig grunnlinjesmodeller, som ikkje inkluderer metadata. Vi viser også at fordel av teiknkodinga over andre strategier for koding av metadata.', 'ro': 'Noi arătăm că utilizarea informațiilor despre metadate de pe paginile web poate îmbunătăți performanța modelelor pentru selectarea pasajelor de răspuns / re-ranking. Propunem un model de selecție a pasajelor neurale care valorifică informațiile metadatelor cu o strategie de codificare fină, care învață reprezentarea predicilor metadatelor într-un mod ierarhic. Modelele sunt evaluate pe seturile de date MS MARCO (Nguyen et al., 2016) și Recipe-MARCO. Rezultatele arată că modelele noastre depășesc semnificativ modelele de bază, care nu includ metadate. De asemenea, arătăm că codificarea cu granule fine are avantajul față de alte strategii de codificare a metadatelor.', 'sr': 'Pokazujemo da uključivanje metapodataka sa web stranica može poboljšati učinkovitost modela za odabire/preokretanje odgovora. Predlažemo model selekcije neurološkog prolaza koji utiče na metapodatke sa strategijom finog zrnca kodiranja, koja nauči zastupanje metapodataka predikata na hijerarhički naèin. Modeli se procjenjuju na podacima MS MARCO (Nguyen et al., 2016) i Recipe-MARCO. Rezultati pokazuju da naši modeli značajno iznose početne modele, koje ne uključuju metapodatke. Takoðe pokazujemo da prednost kodiranja finog zrnca nad drugim strategijama za kodiranje metapodataka.', 'pl': 'Pokazujemy, że wykorzystanie informacji metadanych ze stron internetowych może poprawić wydajność modeli do wyboru/ponownego rankingu odpowiedzi. Proponujemy model selekcji przejścia neuronowego, który wykorzystuje informacje metadanych z drobnoziarnistą strategią kodowania, która uczy się reprezentacji predykatów metadanych w sposób hierarchiczny. Modele są oceniane na zbiorach danych MS MARCO (Nguyen et al., 2016) i Recipe-MARCO. Wyniki pokazują, że nasze modele znacznie przewyższają modele bazowe, które nie zawierają metadanych. Pokazujemy również, że drobnoziarniste kodowanie jest przewagą nad innymi strategiami kodowania metadanych.', 'si': 'අපි පෙන්වන්නේ වෙබ් පිටුවලින් මෙටාඩේටා තොරතුරු ප්\u200dරවේශනය කරන්න පුළුවන් වෙන්න පුළුවන් ප්\u200dරවේශනය විස අපි ප්\u200dරශ්නයක් කරනවා න්\u200dයූරාල් පාස් එක තෝරණයේ මෙටාඩේටා තොරතුරු ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් තියෙනවා, මෙටාඩාටා ප්\u200dරශ්නයක මොඩේලන් විශ්වාස කරන්නේ MS MARCO (nguyen et al., 2016) සහ රිසිප්-MARCO දත්ත සේට් වල. ප්\u200dරතිචාරය පෙන්වන්නේ අපේ මොඩල් විශේෂයෙන් ප්\u200dරමාණය විශේෂයෙන් ප්\u200dරමාණය කරන්න, මෙටාඩේටා එක්කරල අපිට පෙන්වන්න පුළුවන් විදිහට මෙටාඩේටාව සංකේතනය කරන්න අනිත් ප්\u200dරයෝජනය වලට හොඳ සංකේතනය ප්\u200dරයෝ', 'sv': 'Vi visar att utnyttjande av metadatainformation från webbsidor kan förbättra prestandan hos modeller för val av svarsvägar/omräkning. Vi föreslår en modell för urval av neurala passager som utnyttjar metadata information med en finkornig kodningsstrategi, som lär sig representationen för metadata predikater på ett hierarkiskt sätt. Modellerna utvärderas på MS MARCO (Nguyen et al., 2016) och Recipe-MARCO datauppsättningar. Resultaten visar att våra modeller presterar betydligt bättre än basmodeller, som inte innehåller metadata. Vi visar också att den finkorniga kodningen är en fördel jämfört med andra strategier för kodning av metadata.', 'so': "Waxaynu tusnaynaa in macluumaadka metadata laga soo diro bogagga internetka ah uu beddeli karo sameynta sameynta sameynta doorashada baasabka/dib-u-dhigidda. Tusaale doorashada neurada ah oo ku qoran macluumaadka metadata, kaas oo ku barta qaab u eg qorshaha kooxda, kaasoo ku qoran qaab hierarchical ah. Tusaaladaha waxaa lagu qiimeynayaa MS MARCO (Nguyen et al., 2016) iyo sawirada macluumaadka Recipe-MARCO. Resultadu waxay muuqataa in modelladayagu ay si muhiim ah u sameeyaan modelalka baseline, taasoo aan ku kooban metadata. Sidoo kale waxaynu muujinnaa in faa'iidada koodeynta wanaagsanayd ay ka badan yihiin qalabka kale ee kooban taariikhda metaada.", 'ta': 'இணைய பக்கங்களிலிருந்து metadata தகவல் வழங்குவதை நாம் காட்டுகிறோம் என்றால் பதில் கடவுச்செலுத்தல்/மீண்டும் தேர்வு செய நாம் ஒரு புதிய கடவுச்செல்லும் தேர்வு மாதிரியை பரிந்துரைக்கிறோம். அது மெட்டாடாவின் குறியீட்டு விவரங்களுடன் மெட்டாடா தகவல் தகவல்களை  MS MARCO (Nguyen et al., 2016) மற்றும் MARCO தரவு அமைப்புகளில் மாதிரிகள் மதிப்பிடப்படுகிறது. @ info மேலும் நாம் மெட்டேடா குறியீட்டை குறியீட்டும் வேறு திட்டங்களை விட நல்ல கிராப்பப்பட்ட குறியீட்டு', 'ur': 'ہم دکھاتے ہیں کہ ویب پائز سے مٹا ڈیٹا معلومات لیورڈ کرنا پھیر کے انتخاب/دوبارہ لینک کے لئے موڈل کے کامل کو بہتر کر سکتا ہے. ہم ایک نئورل پاسج انتخاب موڈل کو پیشنهاد کرتے ہیں جو مٹا ڈیٹا معلومات کو ایک پاکیزہ دانہ اکڈینگ استراتژی کے ساتھ لائر کرتا ہے، جو metadata predicates کے ذریعہ سیکھاتا ہے ایک ہیرارک طریقے سے. مڈیلڈ مہ مارکو (Nguyen et al., 2016) اور ریسپی-مارکو ڈیٹسٹ پر ارزش کیا جاتا ہے. نتیجے دکھاتے ہیں کہ ہمارے نمڈلوں نے بنیاس لین نمڈلوں سے زیادہ اضافہ کیا ہے، جو مٹا ڈاٹائے شامل نہیں ہوتے۔ ہم نے بھی دکھایا ہے کہ مٹا ڈاٹائے کے لئے دوسرے استراتژی پر بہترین دانے کا انکوڈینگ فائدہ ہے.', 'uz': "Veb sahifadagi metadata maʼlumotini yozib olish modellarni bajarishi mumkin. Biz bir neyrolik parametrlarini tanlash modelini tahlil qilamiz. Bu bir necha kodlash strategiya bilan metadata maʼlumot yordamida qo'shiladi. Name Natijalar ko'rsatadi, bizning modellarimiz baseline modellaridan juda muhim bajarish mumkin, bu metadata'ga murojaat emas. Biz metadata kodlash usulida boshqa strategiya uchun yaxshi kodlash imkoniyatini ko'rsatumiz.", 'vi': 'Chúng tôi cho thấy việc kích hoạt dữ liệu siêu dữ liệu từ trang web có thể cải thiện hiệu suất của các mô hình để chọn đoạn/kiểm tra lại câu trả lời. Chúng tôi đề xuất một mô hình chọn đường dây thần kinh dùng để kích hoạt thông tin siêu dữ liệu bằng một chiến lược mã hóa đặc biệt, chuyên môn học cách phân biệt siêu dữ liệu. Các mẫu được đánh giá qua các tập tin mẫu M MACO (Nguyen et al., 2006) và Recpe-MACO. Kết quả cho thấy các mẫu hoàn thiện đáng kể các mô hình cơ sở cơ sở, không chứa siêu dữ liệu. Chúng tôi cũng cho thấy rằng lợi thế của màn mã hóa phức tạp hơn những chiến lược để mã hóa siêu dữ liệu.', 'bg': 'Показваме, че използването на информация за метаданни от уеб страници може да подобри ефективността на моделите за избор на пасажи на отговори/пренареждане. Предлагаме модел за избор на невронни пасажи, който използва информацията за метаданни с фина кодираща стратегия, която изучава представянето на предикатите за метаданни по йерархичен начин. Моделите са оценени на базата на данни МС МАРКО (Нгуен и др., 2016) и Рецепта-МАРКО. Резултатите показват, че нашите модели значително превъзхождат базовите модели, които не включват метаданни. Показваме също, че финото кодиране е предимство пред другите стратегии за кодиране на метаданните.', 'nl': "We laten zien dat het gebruik van metadata informatie van webpagina's de prestaties van modellen voor het selecteren/opnieuw rangschikken van antwoordpassages kan verbeteren. We stellen een neurale passage selectiemodel voor dat metadata informatie gebruikt met een fijnkorrelige coderingsstrategie, die de representatie van metadata predicaten leert op een hiërarchische manier. De modellen worden geëvalueerd op de MS MARCO (Nguyen et al., 2016) en Recipe-MARCO datasets. De resultaten tonen aan dat onze modellen aanzienlijk beter presteren dan baseline modellen, die geen metadata bevatten. We laten ook zien dat de fijnkorrelige codering het voordeel heeft ten opzichte van andere strategieën voor het coderen van de metadata.", 'hr': 'Pokazujemo da uključivanje metapodataka sa web stranica može poboljšati učinkovitost modela za odabire/preokretanje odgovora. Predlažemo model izbora neuroloških prolaza koji utiče na metapodatke sa strategijom finog zrnca kodiranja, koja nauči zastupanje metapodataka predikata na hijerarhički način. Modeli se procjenjuju na podacima MS MARCO (Nguyen et al., 2016) i Recipe-MARCO. Rezultati pokazuju da naši modeli značajno iznose početne modele, koje ne uključuju metapodatke. Također pokazujemo da prednost lijepog kodiranja nad drugim strategijama za kodiranje metapodataka.', 'da': 'Vi viser, at udnyttelse af metadataoplysninger fra websider kan forbedre ydeevnen af modeller til valg af svarpassage/omlankering. Vi foreslår en neural passage valgmodel, der udnytter metadata information med en finkornet kodningsstrategi, der lærer repræsentationen for metadata prædikater på en hierarkisk måde. Modellerne er evalueret på MS MARCO (Nguyen et al., 2016) og Recipe-MARCO datasæt. Resultaterne viser, at vores modeller yder betydeligt bedre end basismodeller, som ikke indeholder metadata. Vi viser også, at den finkornede kodning er fordel i forhold til andre strategier for kodning af metadata.', 'de': 'Wir zeigen, dass die Nutzung von Metadateninformationen von Webseiten die Leistung von Modellen für die Auswahl/Neurangierung von Antwortpassagen verbessern kann. Wir schlagen ein neuronales Durchgangsselektionsmodell vor, das Metadateninformationen mit einer feingranularen Kodierungsstrategie nutzt, die die Repräsentation von Metadatenprädikaten auf hierarchische Weise erlernt. Die Modelle werden auf den MS MARCO (Nguyen et al., 2016) und Recipe-MARCO Datensätzen ausgewertet. Die Ergebnisse zeigen, dass unsere Modelle die Basismodelle deutlich übertreffen, die keine Metadaten enthalten. Wir zeigen auch, dass die feinkörnige Codierung einen Vorteil gegenüber anderen Strategien zur Codierung der Metadaten hat.', 'id': 'Kami menunjukkan bahwa penggunaan informasi metadata dari halaman web dapat meningkatkan prestasi model untuk seleksi/reranking pasar jawaban. Kami mengusulkan model pemilihan pasar saraf yang menggunakan informasi metadata dengan strategi pengekodan yang sempurna, yang mempelajari rappresentasi metadata predikasi dengan cara hierarkis. Model-model diteliti pada dataset MS MARCO (Nguyen et al., 2016) dan Recipe-MARCO. Hasil menunjukkan bahwa model kita jauh lebih dari model dasar, yang tidak mengandung metadata. Kami juga menunjukkan bahwa keuntungan pengekodan yang baik daripada strategi lain untuk mengekodikan metadata.', 'fa': 'ما نشان می دهیم که استفاده از اطلاعات metadata از صفحه های وب می تواند عملکرد مدلها را برای انتخاب/بازگرداندن پاسخ بهتر کند. ما یک مدل انتخاب مسیر عصبی را پیشنهاد می\u200cکنیم که اطلاعات متداده را با استراتژی رمزبندی\u200cکننده\u200cی خوشمزه\u200cای تحت تاثیر قرار می\u200cدهد، که نمایش داده\u200cهای متداده\u200cها را به طریق طبیعی یاد می\u200cگیرد. Models are evaluated on the MS MARCO (Nguyen et al., 2016) and Recipe-MARCO data sets. نتیجه\u200cها نشان می\u200cدهند که مدل\u200cهای ما خیلی بیشتر از مدل\u200cهای پایه\u200cخط انجام می\u200cدهند که متداده\u200cها را شامل نمی\u200cکنند. ما همچنین نشان می دهیم که فایده\u200cهای کودکان\u200cدهنده\u200cی دانه\u200cهای نیکو بر خلاف استراتژی\u200cهای دیگر برای کودکان داده\u200cهای متداد است.', 'sw': 'Tunaonyesha kuwa upatikanaji wa taarifa za meta kutoka kurasa za mtandaoni unaweza kuboresha ufanisi wa mifano kwa ajili ya kujibu uchaguzi wa upatikanaji/upya. Tunazipendekeza muundo wa uchaguzi wa upatikanaji wa neura unaotumia taarifa za metadata kwa mkakati mzuri wa kodi, ambao unajifunza uwakilizaji wa taarifa za meta kwa njia ya upepo. Mradi huo unapitiwa kwenye ujumbe wa MS MARCO (Nguyen et al., 2016) na seti za taarifa za kupokea MARCO. Matokeo yanaonyesha kuwa mifano yetu kwa kiasi kikubwa inafanya mifano ya msingi, ambazo hazina taarifa za meta. Tunaonyesha pia kuwa faida ya kodi zilizotolewa vizuri zaidi ya mikakati mengine ya kuzuia taarifa za meta.', 'ko': '우리는 웹 페이지의 메타데이터 정보를 이용하여 답안 단락 선택/재배열 모델의 성능을 향상시킬 수 있음을 나타낸다.우리는 신경 채널 선택 모델을 제시했다. 이 모델은 메타데이터 정보와 세립도 인코딩 전략을 이용하여 메타데이터 술어의 표시를 층별로 학습한다.모델은 MS MARCO(Nguyen 등, 2016)와 Recipe MARCO 데이터 세트에서 평가한다.그 결과 우리의 모델은 원 데이터가 포함되지 않은 기선 모델보다 현저히 낫다는 것을 알 수 있다.우리는 또한 세립도 인코딩이 다른 메타데이터 인코딩 전략에 비해 장점을 보여 주었다.', 'tr': 'Web sahypalardan metadata maglumatyny taýýarlamak üçin jaýyn saýlamak/täzeden çykarmak üçin nusgalaryň eserini gowylaşdyryp biljekdigini görkez. Biz neural geçişi saýlamak nusgasyny teklip edýäris ki metadata maglumaty ýüze taýýarlyk ködleme stratejiýasy bilen etmäge yarayan, bu da metadata predikatlaryň täsirini hijerarşik ýoly bilen öwrenýär. Modeller MS MARCO (Nguyen et al., 2016) we Recipe-MARCO veri setirlerinde deňlenýär Netijenler biziň modellerimiz metadata içerilmeýän basit modellerden çykyp çykýandygyny görkezýär. Mundan hem metadata ködlemek üçin gowy kodlemek üçin başga strategiýalaryň üstünde ökdedigini görkezýäris.', 'am': 'የመድረክ ገጾች የመድረክ መረጃዎችን ማሻሻል እናሳያቸዋለን፡፡ የናቡር ምርጫ ሞዴል በመፍጠር ላይ የተመሳሳይ የዳታ መረጃዎችን በተመሳሳይ የሆኑት የኮድ መስኮት ተቃውሞ ሲሰጥ እናሳውቃለን፡፡ ሞዴሎቹ በ (Nguyen et al., 2016) እና የMARCO ዳታዎችን በመቀበል ይሞክራሉ። ፍጥረቶቹ መተላለፊያዎቻችን በመስመር ሳጥን የሚያሳየው ማተዳራዎችን የማያሳዩ ናቸው፡፡ እናም መሆኑን መክፈት የሚደረገውን የጽሑፉ የኮድ ጥቅምት ከሌሎቹ ተቃውሞ ላይ እናሳያቸዋለን፡፡', 'hy': 'Մենք ցույց ենք տալիս, որ մետատվյալների ինֆորմացիայի օգտագործումը վեբ էջերից կարող է բարելավել պատասխանների ընտրության և վերամշակման մոդելների արդյունքը: We propose a neural passage selection model that leverages metadata information with a fine-grained encoding strategy, which learns the representation for metadata predicates in a hierarchical way.  Մոդելները գնահատվում են M.S. Արդյունքները ցույց են տալիս, որ մեր մոդելները նշանակալիորեն գերազանցում են հիմնական մոդելները, որոնք չեն ներառում մետատվյալներ: Մենք նաև ցույց ենք տալիս, որ գեղեցիկ կոդավորման առավելությունը մետատվյալների կոդավորման այլ ռազմավարությունների փոխարեն:', 'az': 'İnternet səhifələrindən metadata məlumatlarını təmizləndirmək səhifələrinin yanıt seçməsi/yenilənməsi üçün modellərin performansını daha yaxşılaşdırabilir. Biz bir nöral keçmə modelini təbliğ edirik ki, metadata predikatlarını hiyerarşik yolundan öyrənir. Modellər MS MARCO (Nguyen et al., 2016) və Recipe-MARCO veri qurularında değerlendirilir. Sonuçlarımız modellərimizin metadata içərisində olmayan baseline modelləri çox yüksək göstərir. Biz də göstəririk ki, metadata kodlamaq üçün digər stratejilərdən üstün s ünbül kodlamanın faydası.', 'bn': 'আমরা দেখাচ্ছি যে ওয়েব পাতায় মেটেডাটা তথ্য প্রদান করা যাচ্ছে তারা প্যাসেজ নির্বাচন/পুনরায় নির্বাচনের জন্য মডেলের আমরা একটি নিউরেল প্যাসেজ নির্বাচন মডেল প্রস্তাব করছি যা মেটাডা তথ্য প্রদান করে একটি ভালো কোডিং কৌশলের মাধ্যমে, যা হিয়েরার্কিক ভাবে মেটাডা প এমএস ম্যার্কো (Nguye et al., ২০১৬) এবং রিসিপি-MARCO ডাটাসেটগুলোতে মডেলগুলো মূল্যায়ন করা হয়েছে। ফলাফল দেখাচ্ছে যে আমাদের মডেলগুলো বেসাইলাইন মডেলগুলোকে গুরুত্বপূর্ণ করে দেখাচ্ছে, যা মেটাডাটার মধ্যে অন এছাড়াও আমরা দেখাচ্ছি যে মেটেডাটা এনকোড করার জন্য অন্যান্য কৌশলের চেয়ে ভালো কোডিং এর সুবিধা।', 'bs': 'Pokazujemo da uključivanje metapodataka sa web stranica može poboljšati učinkovitost modela za odgovor na izbor prolaza/preokretanje. Predlažemo model selekcije neurološkog prolaza koji utiče na metapodatke sa strategijom finog zrnca kodiranja, koja nauči zastupanje metapodataka predikata na hijerarhički način. Modeli se procjenjuju na podacima MS MARCO (Nguyen et al., 2016) i Recipe-MARCO. Rezultati pokazuju da naši modeli značajno iznose početne modele, koje ne uključuju metapodatke. Također pokazujemo da prednost kodiranja finog zrnca nad drugim strategijama za kodiranje metapodataka.', 'ca': "Mostrem que aprofitar la informació sobre les metadades de les pàgines web pot millorar el rendiment dels models de selecció/revisió del passatge de resposta. Proposem un model de selecció de passatges neurals que aprofita la informació de metadades amb una estratègia de codificació fina, que aprenen la representació de metadades predicades d'una manera jeràrquica. Els models es valoren en els conjunts de dades MS MARCO (Nguyen et al., 2016) i Recipe-MARCO. Els resultats mostran que els nostres models superen significativament els models de base, que no incorporan metadades. També demostram que l'avantatge de la codificació fina sobre altres estratègies per codificar les metadades.", 'cs': 'Ukazujeme, že využití metadatových informací z webových stránek může zlepšit výkon modelů pro výběr/změnu řazení pasáží odpovědí. Navrhujeme model výběru neuronových pasáží, který využívá metadatové informace s jemnou kódovací strategií, která se naučí reprezentovat metadatové predikáty hierarchickým způsobem. Modely jsou hodnoceny na datových sadách MS MARCO (Nguyen et al., 2016) a Recipe-MARCO. Výsledky ukazují, že naše modely výrazně převyšují základní modely, které neobsahují metadata. Také ukazujeme, že jemnozrnné kódování má výhodu oproti ostatním strategiím kódování metadat.', 'af': "Ons wys dat die verskaffing van metadata inligting van webbladsye kan die prestasie van modele verbeter vir antwoord van wagkeuse/herankering. Ons voorstel 'n neurale verbygegangskeuse model wat metadata inligting verwyder met 'n fyn- graan enkodering strategie, wat leer die voorstelling vir metadata vooraflikbaar op 'n hierarkies manier. Die modele word uitgewerk op die MS MARCO (Nguyen et al., 2016) en Recipe- MARCO datastelle. @ info Ons wys ook dat die fine-grained enkodering se voordeel oor ander strategies vir enkodering van die metadata.", 'et': 'Näitame, et metaandmete kasutamine veebilehtedelt võib parandada vastuste läbipääsu valimise/ümberpankimise mudelite jõudlust. Pakume välja neuraalse läbipääsu valiku mudeli, mis kasutab metaandmete infot peenete kodeerimisstrateegiaga, mis õpib metaandmete predikaatide esitamist hierarhiliselt. Mudeleid hinnatakse MS MARCO (Nguyen et al., 2016) ja Recipe-MARCO andmekogumite alusel. Tulemused näitavad, et meie mudelid ületavad oluliselt baasmudeleid, mis ei sisalda metaandmeid. Samuti näitame, et peenrahaline kodeerimine on eelis teiste metaandmete kodeerimise strateegiate ees.', 'sq': "Ne tregojmë se përdorimi i informacionit të metatë nga faqet e internetit mund të përmirësojë performancën e modeleve për zgjedhjen e pasazhit të përgjigjeve. Ne propozojmë një model zgjedhjeje të kalimit nervor që nxjerr informacionin e metatë me një strategji kodimi të hollësishme, e cila mëson përfaqësimin për metatë predikohet në një mënyrë hierarkike. Modelet vlerësohen në sistemet e të dhënave MS MARCO (Nguyen et al., 2016) dhe Recipe-MARCO. Rezultatet tregojnë se modelet tona tejkalojnë ndjeshëm modelet bazë, që nuk përfshijnë metatë. We also show that the fine-grained encoding's advantage over other strategies for encoding the metadata.", 'fi': 'Osoitamme, että verkkosivujen metatietojen hyödyntäminen voi parantaa vastausten valintaa/uudelleenjärjestelyä koskevien mallien suorituskykyä. Ehdotamme neuroväylän valintamallia, joka hyödyntää metatietoja hienojakoisella koodausstrategialla, joka oppii metatiedon predikaattien edustuksen hierarkkisesti. Mallit on arvioitu MS MARCO (Nguyen et al., 2016) ja Recipe-MARCO -aineistojen perusteella. Tulokset osoittavat, että mallimme suoriutuvat merkittävästi paremmin kuin perusmallit, jotka eivät sisällä metatietoja. Osoitamme myös, että hienojakoinen koodaus on eduksi muihin koodausstrategioihin verrattuna.', 'sk': 'Pokazali smo, da lahko z izkoriščanjem metapodatkovnih informacij s spletnih strani izboljšamo učinkovitost modelov za izbiro/prerazporejanje odgovorov. Predlagamo model izbire nevronskih prehodov, ki izkorišča metapodatkovne informacije z natančno strategijo kodiranja, ki se na hierarhičen način nauči reprezentacije metapodatkovnih predikatov. Modeli so ocenjeni na podlagi podatkovnih nizov MS MARCO (Nguyen et al., 2016) in Recipe-MARCO. Rezultati kažejo, da so naši modeli bistveno boljši od osnovnih modelov, ki ne vključujejo metapodatkov. Pokažemo tudi, da ima natančno kodiranje prednost pred drugimi strategijami kodiranja metapodatkov.', 'jv': "Awak dhéwé menehi metungan informasi nang pagjine web iso nggawe gerakan dadi model kanggo ngubah mulasar seneng pisan Manual Awak dhéwé ngerasai model penting nggambar uwis Nari model sing dikandari dadi nggo data sing mas MARO (Nguyen et al, 2011) karo Recipe-MARO Punika diputaakeh lan model sing dumadhi nggawe model sing bisa diantel sing dumadhi, sing ora dadi metadata sing bisa diantel. Awak dhéwé énong ngomong nik 'decode' sing dibutuhi bener kanggo ngerasakno metadata sing kok dadi.", 'ha': "Tuna nũna cewa, da za'a samar da data na metadata daga kuran web pages, zai iya ƙara gyarawa ga shirin motel wa zaɓen shirin hanya/re-ana. We propose a neural passage selection model that leverages metadata information with a fine-grained encoding strategy, which learns the representation for metadata predicates in a hierarchical way.  Ana ƙaddara motsalan a kan MARCO (Nguyen et al., 2016) da samun motsi-MARCO. Matunan ya nuna cewa misãlananmu masu ƙaranci mai girma, wanda ba su shiga metadata ba. Kayya, Muke nũna kode mafiya kyauta ga kodi ko da wasu takwai na kodi da metadata.", 'he': 'אנו מראים ששימוש מידע מטה נתונים מדפי האינטרנט יכול לשפר את ההפעה של דוגמנים לבחירת מעבר תשובה אנו מציעים מודל לבחירה של מעבר עצבי שממשיך מידע מטה-נתונים עם אסטרטגיה של קידוד מעולה, שלמדה את מייצג מטה-נתונים מתייחס בדרך היררכית. הדוגמנים מוערכים על מסמכי הנתונים של MS MARCO (Nguyen et al., 2016) ו Recipe-MARCO. התוצאות מראות שהדוגמנים שלנו יוצאים משמעותית מעל דוגמנים בסיסיים, שלא מכילים מטה-נתונים. אנחנו גם מראים את יתרון של הקוד המפורסם על אסטרטגיות אחרות לקוד המטאדאטה.', 'bo': 'ང་ཚོས་དྲ་ཤོག་བྱང་ནས་མ་ཆ་གནས་ཚུལ་མངོན་འཆར་བྱེད་པར་མཐུན་རྐྱེན་བྱེད་པའི་མིག་སྟོན་ཡོད་པ We propose a neural passage selection model that leverages metadata information with a fine-grained encoding strategy, which learns the representation for metadata predicates in a hierarchical way. Models are evaluated on the MS MARCO (Nguyen et al., 2016) and Recipe-MARCO datasets. རྐྱེན་འབྲས་བ་མངོན་གསལ་བ་ནི་ང་ཚོའི་མིག་གཟུགས་རིས་གཞི་དཔེ་གཞི་བྱས་ཉེས་མེད་པའི་ནང་དུ་བཏོན་ཡོད་པ འུ་ཚོས་ཀྱང་གསལ་བ་ཞིབ་བཤེར་བྱེད་སྐབས་འཇལ་རྩིས་བ་སྤྱོད་མེད་པ་གཞན་ཞིག་ཏུ་མངོན་གསལ་བཀལ་བ་ཡིན།'}
{'en': 'Cue Me In : Content-Inducing Approaches to Interactive Story Generation', 'ar': 'Cue Me In: مناهج تحفيز المحتوى لإنشاء قصة تفاعلية', 'pt': 'Cue Me In: Abordagens Indutoras de Conteúdo para a Geração de Histórias Interativas', 'es': 'Cue Me In: enfoques que inducen el contenido para la generación de historias interactivas', 'fr': "Cue Me In\xa0: Approches induisant du contenu pour la génération d'histoires interactives", 'hi': 'क्यू मुझे में: इंटरैक्टिव स्टोरी जनरेशन के लिए सामग्री-उत्प्रेरण दृष्टिकोण', 'ja': 'Cue Me In ：インタラクティブなストーリー生成へのコンテンツ誘導アプローチ', 'zh': '提示我:交互式故事生成之道', 'ru': 'Cue Me In: Контент-индуцирующие подходы к формированию интерактивных историй', 'ga': 'Cue Me In: Cur Chuige a Spreagann Ábhar maidir le Giniúint Scéal Idirghníomhach', 'hu': 'Cue Me In: Tartalom-indukáló megközelítések az interaktív történetek generálásához', 'el': 'Προσεγγίσεις που προκαλούν περιεχόμενο στη δημιουργία διαδραστικών ιστοριών', 'ka': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'it': 'Cue Me In: Approcci che inducono contenuti alla generazione interattiva di storie', 'kk': 'Мені таңдау: Content- Inducing Approaches to Interactive Story Generation', 'lt': 'Įtraukti į: turinį skatinantys požiūriai į sąveikų istorijų generaciją', 'mk': 'Cue Me In: Приблизи за индукција на содржина до генерација на интерактивни приказни', 'ml': 'ക്യൂ എന്നെ ഉള്\u200dപ്പെടുത്തുക: ഉള്ളടക്കത്തിലുള്ള സ്റ്റോറി ജനിപ്പിക്കാന്\u200d സമീപിക്കുന്നു', 'ms': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'mt': 'Cue Me In: Approċċi li jinduċu l- Kontenut għall- Ġenerazzjoni Interattiva ta ’ Story', 'mn': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'no': 'Cue me In: Content-Inducing Approaches to Interactive Story Generation', 'pl': 'Cue Me In: Zawartościowe podejścia do interaktywnego generowania opowieści', 'ro': 'Cue Me In: Abordări care induc conținut pentru generarea interactivă de povești', 'sr': 'Cue me In: Content-Inducing Approaches to Interactive Story Generation', 'si': 'Cue me In: සම්බන්ධතාවක් ඉන්දිරීම් කතාවක් නිර්මාණය', 'so': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'sv': 'Cue Me In: innehållsframkallande förhållningssätt till interaktiv berättelsegenerering', 'ta': 'Cue Me in: Content- Inducing Approaches to Interactive Story Generation', 'ur': 'Cue me in: Content-Inducing Approaches to Interactive Story Generation', 'uz': 'Comment', 'vi': 'Điều khiển nội dung của tạo truyện tương tác', 'da': 'Cue Me In: Indholdsindskydende tilgange til interaktiv historiegenerering', 'nl': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'bg': 'Включете ме: Подходи за създаване на интерактивни истории', 'de': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'id': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'ko': '제시: 인터랙티브 스토리 생성의 내용 유도 방법', 'sw': 'Cue Me In: Maudhui yanayoingia kwenye Generation of Stories Interactive', 'hr': 'Cue me In: Content-Inducing Approaches to Interactive Story Generation', 'sq': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'am': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'af': 'Cue My In: Inhoud- Indusierende toegang na Interaktiewe Historie Genereer', 'fa': 'Cue me In: Content-Inducing Approaches to Interactive Story Generation', 'tr': 'Durum:Content-Inducing Approaches to Interactive Story Generation', 'az': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'bn': 'কি আমাকে ইন: বিষয়বস্তু ইন্টারেক্টিভ স্টোরি প্রজন্মের কাছে যাচ্ছে', 'hy': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'cs': 'Cue Me In: Obsah-inducing přístupy k interaktivnímu generování příběhů', 'ca': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'et': 'Sisu tekitavad lähenemisviisid interaktiivsele looloole', 'fi': 'Cue Me In: Sisältöä luovat lähestymistavat interaktiiviseen tarinankehitykseen', 'bs': 'Cue me In: Content-Inducing Approaches to Interactive Story Generation', 'ha': 'KCharselect unicode block name', 'he': 'Cue Me In: Content-Inducing Approaches to Interactive Story Generation', 'sk': 'Pristopi k ustvarjanju interaktivnih zgodb, ki spodbujajo vsebino', 'jv': 'Cumulate', 'bo': 'Content-Inducing Approaches to Interactive Story Generation'}
{'en': 'Automatically generating stories is a challenging problem that requires producing causally related and logical sequences of events about a topic. Previous approaches in this domain have focused largely on one-shot generation, where a  language model  outputs a complete story based on limited initial input from a user. Here, we instead focus on the task of interactive story generation, where the user provides the model mid-level sentence abstractions in the form of cue phrases during the generation process. This provides an interface for human users to guide the  story generation . We present two content-inducing approaches to effectively incorporate this additional information. Experimental results from both automatic and human evaluations show that these  methods  produce more topically coherent and personalized stories compared to baseline methods.', 'ar': 'يعد إنشاء القصص تلقائيًا مشكلة صعبة تتطلب إنتاج تسلسلات منطقية وذات صلة سببية للأحداث حول موضوع ما. ركزت المناهج السابقة في هذا المجال بشكل كبير على التوليد دفعة واحدة ، حيث يُخرج نموذج اللغة قصة كاملة بناءً على مدخلات أولية محدودة من المستخدم. هنا ، نركز بدلاً من ذلك على مهمة إنشاء القصة التفاعلية ، حيث يقدم المستخدم تجريدات الجملة متوسطة المستوى في شكل عبارات تلميح أثناء عملية التوليد. يوفر هذا واجهة للمستخدمين البشريين لتوجيه إنشاء القصة. نقدم نهجين يشجعان المحتوى لدمج هذه المعلومات الإضافية بشكل فعال. تظهر النتائج التجريبية من التقييمات التلقائية والبشرية أن هذه الأساليب تنتج قصصًا أكثر تناسقًا وشخصية من الناحية الموضوعية مقارنة بأساليب خط الأساس.', 'fr': "La génération automatique d'histoires est un problème difficile qui nécessite de produire des séquences d'événements logiques et causales sur un sujet. Les approches précédentes dans ce domaine se sont largement concentrées sur la génération ponctuelle, où un modèle de langage produit une histoire complète basée sur une entrée initiale limitée d'un utilisateur. Ici, nous nous concentrons plutôt sur la tâche de génération d'histoires interactives, où l'utilisateur fournit les abstractions de phrases de niveau intermédiaire du modèle sous forme de phrases repères pendant le processus de génération. Cela fournit une interface permettant aux utilisateurs humains de guider la génération d'histoires. Nous présentons deux approches induisant du contenu pour intégrer efficacement ces informations supplémentaires. Les résultats expérimentaux des évaluations automatiques et humaines montrent que ces méthodes produisent des histoires plus cohérentes et personnalisées d'un point de vue thématique par rapport aux méthodes de base.", 'pt': 'A geração automática de histórias é um problema desafiador que requer a produção de sequências de eventos lógicos e causalmente relacionados sobre um tópico. As abordagens anteriores neste domínio se concentraram principalmente na geração one-shot, onde um modelo de linguagem gera uma história completa com base na entrada inicial limitada de um usuário. Aqui, em vez disso, focamos na tarefa de geração de história interativa, onde o usuário fornece o modelo de abstrações de sentenças de nível médio na forma de frases de sinalização durante o processo de geração. Isso fornece uma interface para usuários humanos orientarem a geração da história. Apresentamos duas abordagens indutoras de conteúdo para incorporar efetivamente essas informações adicionais. Resultados experimentais de avaliações automáticas e humanas mostram que esses métodos produzem histórias mais coerentes e personalizadas em relação aos métodos de linha de base.', 'es': 'La generación automática de historias es un problema desafiante que requiere producir secuencias lógicas y relacionadas con la causa de los eventos sobre un tema. Los enfoques anteriores en este campo se han centrado en gran medida en la generación única, en la que un modelo de lenguaje produce una historia completa basada en la información inicial limitada de un usuario. Aquí, en cambio, nos centramos en la tarea de generación de historias interactivas, donde el usuario proporciona el modelo de abstracciones de frases de nivel medio en forma de frases guía durante el proceso de generación. Esto proporciona una interfaz para que los usuarios humanos guíen la generación de historias. Presentamos dos enfoques que inducen contenido para incorporar eficazmente esta información adicional. Los resultados experimentales de las evaluaciones automáticas y humanas muestran que estos métodos producen historias más coherentes y personalizadas desde el punto de vista tópico en comparación con los métodos de referencia.', 'ja': 'ストーリーを自動的に生成することは、トピックに関する因果関係のある論理的な一連のイベントを生成する必要がある困難な問題です。この分野における以前のアプローチは、言語モデルがユーザーからの限られた初期入力に基づいて完全なストーリーを出力する、ワンショット生成に主に焦点を当てています。ここでは、代わりにインタラクティブなストーリー生成のタスクに焦点を当てます。ここでは、ユーザーは生成プロセス中にキューフレーズの形式でモデルの中間レベルの文章抽象化を提供します。これは、人間のユーザーがストーリー生成を導くためのインターフェースを提供する。この追加情報を効果的に取り入れるための2つのコンテンツ誘導アプローチを提示します。自動評価と人間評価の両方の実験結果は、これらの方法がベースライン方法と比較して、より局所的に一貫性のある、個別化されたストーリーを生み出すことを示している。', 'zh': '自生故事,一挑战性之问也;自生事者,一逻辑序也。 凡领域以前,要在一次性生成上,其言语依用户有限初始输入输出全者。 注意于交互式,用户示短语中级句。 这为人用户一界面以成其事。 二者诱之以效整合附以信息。 自与人工评实验结果表明,比于基线法,更生贯个性化。', 'hi': 'स्वचालित रूप से कहानियों को उत्पन्न करना एक चुनौतीपूर्ण समस्या है जिसके लिए किसी विषय के बारे में घटनाओं के कारण से संबंधित और तार्किक अनुक्रमों का उत्पादन करने की आवश्यकता होती है। इस डोमेन में पिछले दृष्टिकोणों ने काफी हद तक एक-शॉट पीढ़ी पर ध्यान केंद्रित किया है, जहां एक भाषा मॉडल उपयोगकर्ता से सीमित प्रारंभिक इनपुट के आधार पर एक पूरी कहानी आउटपुट करता है। यहां, हम इसके बजाय इंटरैक्टिव स्टोरी जेनरेशन के कार्य पर ध्यान केंद्रित करते हैं, जहां उपयोगकर्ता पीढ़ी की प्रक्रिया के दौरान क्यू वाक्यांशों के रूप में मॉडल मध्य-स्तरीय वाक्य अमूर्तता प्रदान करता है। यह कहानी पीढ़ी का मार्गदर्शन करने के लिए मानव उपयोगकर्ताओं के लिए एक इंटरफ़ेस प्रदान करता है। हम इस अतिरिक्त जानकारी को प्रभावी ढंग से शामिल करने के लिए दो सामग्री-उत्प्रेरण दृष्टिकोण प्रस्तुत करते हैं। स्वचालित और मानव मूल्यांकन दोनों के प्रयोगात्मक परिणामों से पता चलता है कि ये विधियां बेसलाइन विधियों की तुलना में अधिक शीर्ष रूप से सुसंगत और व्यक्तिगत कहानियों का उत्पादन करती हैं।', 'ru': 'Автоматическое создание историй является сложной проблемой, которая требует создания причинно-следственных и логических последовательностей событий вокруг темы. Предыдущие подходы в этой области были сосредоточены в основном на одноразовом поколении, где языковая модель выводит полную историю, основанную на ограниченном первоначальном вкладе пользователя. Здесь мы вместо этого фокусируемся на задаче интерактивной генерации историй, где пользователь предоставляет модель абстракции предложений среднего уровня в виде реплик в процессе генерации. Это обеспечивает интерфейс для пользователей, чтобы направлять создание истории. Мы представляем два подхода, побуждающих к содержанию, для эффективного включения этой дополнительной информации. Экспериментальные результаты как автоматических, так и человеческих оценок показывают, что эти методы дают более топически последовательные и персонализированные истории по сравнению с базовыми методами.', 'ga': "Is fadhb dhúshlánach í scéalta a ghiniúint go huathoibríoch a éilíonn seichimh imeachtaí a bhaineann le hábhar agus a bhaineann le hábhar a tháirgeadh. Dhírigh cuir chuige roimhe seo sa réimse seo go mór ar ghlúin aon-ghlúin, áit a n-aschuireann samhail teanga scéal iomlán bunaithe ar ionchur tosaigh teoranta ó úsáideoir. Anseo, dírímid ina ionad sin ar an tasc a bhaineann le giniúint scéalta idirghníomhach, áit a soláthraíonn an t-úsáideoir astarraingtí abairtí meánleibhéil múnla i bhfoirm frásaí leid le linn an phróisis ghiniúna. Soláthraíonn sé seo comhéadan d'úsáideoirí daonna chun giniúint an scéil a threorú. Cuirimid dhá chur chuige a spreagann ábhar i láthair chun an fhaisnéis bhreise seo a ionchorprú go héifeachtach. Léiríonn torthaí turgnamhacha ó mheastóireachtaí uathoibríocha agus daonna araon go dtáirgeann na modhanna seo scéalta níos comhleanúnaí ó thaobh topaicí agus pearsantaithe i gcomparáid le modhanna bunlíne.", 'ka': 'ავტომატიკურად ისტორიების შექმნა არის შესაძლებელი პრობლემა, რომელიც საჭირო გამოიყენება მიზეზი და ლოგიკური მოვლენების შესაძლებლობა. ამ დიომინში წინა მოწყობილობა უფრო ერთი სურათის განვითარებაზე დაფუნსებულია, სადაც ენის მოდელეც გამოყენება სრულ ისტორია, რომელიც გამოყენებელიდან დაფარდებული დასაწ აქ, ჩვენ შემდეგ ინტერაქტიური ისტორიის განვითარების დავაყენებთ, სადაც მომხმარებელი მოდელს საშუალო დონეში წესების აბსტრაქციების ფორმაში სიტყვის პროცესის დროში. ეს ადამიანის მომხმარებისთვის ინტერფექტის შესახებ ისტორიების შესახებ. ჩვენ ჩვენ აჩვენებთ ორი შემდგომარების მიღება, რომელიც ეფექტურად ამ დამატებული ინფორმაციას ჩვენებს. ექსპერიმენტიური შედეგი ორივე ავტომატური და ადამიანის განსაზღვრებისგან გამოიყენება, რომ ეს მეტოვები უფრო ტემიკურად კონექციურად და პოციალურად განსაზ', 'hu': 'A történetek automatikus generálása egy kihívást jelentő probléma, amely okozati összefüggésben és logikai eseménysorozatokat igényel egy témával kapcsolatban. A korábbi megközelítések ezen a területen nagyrészt az egyszeri generációra összpontosítottak, ahol a nyelvi modell egy teljes történetet ad ki a felhasználó korlátozott kezdeti bevitele alapján. Itt inkább az interaktív történetgenerálás feladatára összpontosítunk, ahol a felhasználó a középszintű mondatok absztrakcióját a generációs folyamat során cue frakciók formájában biztosítja. Ez egy interfészt biztosít az emberi felhasználók számára, hogy irányítsák a történet generálását. Ezen kiegészítő információk hatékony beépítéséhez két tartalom-indukáló megközelítést mutatunk be. Mind az automatikus, mind az emberi értékelések kísérleti eredményei azt mutatják, hogy ezek a módszerek aktuálisan koherensebb és személyre szabottabb történeteket eredményeznek az alapvető módszerekhez képest.', 'el': "Η αυτόματη δημιουργία ιστοριών είναι ένα προκλητικό πρόβλημα που απαιτεί την παραγωγή αιτιώδους και λογικών ακολουθιών γεγονότων σχετικά με ένα θέμα. Οι προηγούμενες προσεγγίσεις σε αυτόν τον τομέα έχουν επικεντρωθεί σε μεγάλο βαθμό στην παραγωγή μίας βολής, όπου ένα γλωσσικό μοντέλο παράγει μια πλήρη ιστορία βασισμένη σε περιορισμένη αρχική εισαγωγή από έναν χρήστη. Εδώ, αντ' αυτού, εστιάζουμε στο έργο της διαδραστικής δημιουργίας ιστοριών, όπου ο χρήστης παρέχει το μοντέλο αφαίρεσης προτάσεων μεσαίου επιπέδου με τη μορφή φράσεων σύνθεσης κατά τη διάρκεια της διαδικασίας δημιουργίας. Αυτό παρέχει μια διεπαφή για τους ανθρώπινους χρήστες για να καθοδηγήσει τη δημιουργία ιστοριών. Παρουσιάζουμε δύο προσεγγίσεις που προκαλούν περιεχόμενο για την αποτελεσματική ενσωμάτωση αυτών των πρόσθετων πληροφοριών. Πειραματικά αποτελέσματα τόσο από αυτόματες όσο και από ανθρώπινες αξιολογήσεις δείχνουν ότι αυτές οι μέθοδοι παράγουν πιο επίκαιρα συνεκτικές και εξατομικευμένες ιστορίες σε σύγκριση με τις μεθόδους βάσης.", 'it': "Generare automaticamente storie è un problema impegnativo che richiede la produzione di sequenze causalmente correlate e logiche di eventi su un argomento. Gli approcci precedenti in questo settore si sono concentrati in gran parte sulla generazione one-shot, dove un modello linguistico produce una storia completa basata su input iniziali limitati da un utente. Qui, invece, ci concentriamo sul compito della generazione interattiva di storie, dove l'utente fornisce il modello di astrazioni di frase di medio livello sotto forma di frasi cue durante il processo di generazione. Questo fornisce un'interfaccia per gli utenti umani per guidare la generazione della storia. Presentiamo due approcci che inducono contenuti per incorporare efficacemente queste informazioni aggiuntive. I risultati sperimentali di valutazioni automatiche e umane mostrano che questi metodi producono storie più coerenti e personalizzate rispetto ai metodi di base.", 'kk': 'Автоматты түрде оқиғаларды құру - нақышта туралы оқиғаларды жасау және логикалық реттеу керек мәселе. Бұл домендегі алдыңғы жағдайлардың көпшілігі бір сәтті құрылғанда, тіл үлгісі пайдаланушының бастапқы енгізуіне негізделген толық оқиғаны жасайды. Мұнда, біз оның орнына интерактивті оқиғаны құру тапсырмасына көздейміз, пайдаланушының орташа деңгейіндегі мәтінді абстрактациялау үлгісін жасау процесінде белгілі сөздер тү Бұл адамдар пайдаланушылардың оқиғаны құру үшін интерфейсін көрсетеді. Біз осы қосымша мәліметті қосу үшін екі мазмұнды индукциялау арқылы таңдаймыз. Автоматты және адамның оқиғаларының эксперименталдық нәтижелері бұл әдістер негізгі әдістерімен салыстырып, нақышты және өзгертілген оқиғаларды жасайды.', 'mk': 'Автоматски генерирање приказни е предизвикувачки проблем кој бара производство на причински поврзани и логични секвенци на настани во врска со тема. Претходните пристапи во овој домен се фокусираа главно на една генерација, каде јазичкиот модел излегува од целосна приказна базирана на ограничен иницијален внес од корисник. Тука, наместо тоа, се фокусираме на задачата на интерактивната генерација на приказни, каде корисникот го обезбедува моделот на апстракции на речениците на средно ниво во форма на знаци за време на генерацискиот процес. Ова обезбедува интерфејс за човечките корисници за водење на генерацијата на приказни. Презентираме два пристапи за индукција на содржина за ефикасно вклучување на оваа дополнителна информација. Експерименталните резултати од автоматските и човечките проценки покажуваат дека овие методи произведуваат поточки кохерентни и персонализирани приказни во споредба со основните методи.', 'ms': 'Menjana cerita secara automatik adalah masalah yang mencabar yang memerlukan menghasilkan urutan yang berkaitan dengan penyebab dan logik peristiwa mengenai topik. Previous approaches in this domain have focused largely on one-shot generation, where a language model outputs a complete story based on limited initial input from a user.  Di sini, kita fokus pada tugas generasi cerita interaktif, di mana pengguna menyediakan model abstraksi kalimat tahap tengah dalam bentuk frasa isyarat semasa proses generasi. Ini menyediakan antaramuka bagi pengguna manusia untuk memimpin generasi cerita. Kami memperkenalkan dua pendekatan yang mengakibatkan kandungan untuk memasukkan maklumat tambahan ini secara efektif. Hasil eksperimen dari penilaian automatik dan manusia menunjukkan bahawa kaedah ini menghasilkan cerita yang lebih konsisten secara topik dan pribadi dibandingkan dengan kaedah asas.', 'ml': 'സ്വയമായി കഥകള്\u200d ഉണ്ടാക്കുന്നത് വിലപിടിക്കുന്ന പ്രശ്നമാണ്. അതിന്റെ കാരണമായി ബന്ധപ്പെട്ടിരിക്കുന്ന സംഭവങ് ഈ ഡൊമെയിനിലെ മുമ്പുള്ള നേര്\u200dവഴികള്\u200d ഒരു ഷോട്ട് തലമുറതലമുറയില്\u200d ശ്രദ്ധിച്ചിരിക്കുന്നു. ഒരു ഭാഷ മോഡല്\u200d ഒരു ഉപയോക്താവില്\u200d നി Here, we instead focus on the task of interactive story generation, where the user provides the model mid-level sentence abstractions in the form of cue phrases during the generation process.  ഈ കഥ തലമുറയിലേക്ക് നേര്\u200dവഴി കാണിക്കാന്\u200d മനുഷ്യര്\u200dക്ക് ഒരു ഇന്റര്\u200dഫെസ് നല്\u200dകുന്നു. ഈ കൂടുതല്\u200d വിവരങ്ങള്\u200d കൂടുതല്\u200d ചേര്\u200dക്കാന്\u200d നമ്മള്\u200d രണ്ട് ഉള്\u200dക്കൊള്ളുന്നുണ്ട്. സ്വയമായിട്ടും മനുഷ്യരുടെയും വിലാസങ്ങളില്\u200d നിന്നും പരീക്ഷണ ഫലങ്ങള്\u200d കാണിക്കുന്നു ഈ രീതികള്\u200d അടിസ്ഥാനത്തില്\u200d കൂടുതല്\u200d സ്വകാര്യമ', 'mt': 'Il-ġenerazzjoni awtomatika ta’ storji hija problem a ta’ sfida li teħtieġ il-produzzjoni ta’ sekwenzi ta’ avvenimenti relatati mal-kawża u loġiċi dwar suġġett. L-approċċi preċedenti f’dan id-dominju ffukaw l-aktar fuq ġenerazzjoni ta’ darba, fejn mudell lingwistiku joħroġ storja kompluta bbażata fuq input inizjali limitat minn utent. Hawnhekk, minflok niffokaw fuq il-kompitu tal-ġenerazzjoni interattiva ta’ storji, fejn l-utent jipprovdi l-mudell astrazzjonijiet tas-sentenzi ta’ nofs il-livell fil-forma ta’ frażijiet ta’ sinjal matul il-proċess ta’ ġenerazzjoni. Dan jipprovdi interface għall-utenti umani biex jiggwidaw il-ġenerazzjoni tal-istorja. Aħna nippreżentaw żewġ approċċi li jinduċu l-kontenut biex b’mod effettiv inkorporaw din l-informazzjoni addizzjonali. Experimental results from both automatic and human evaluations show that these methods produce more topically coherent and personalized stories compared to baseline methods.', 'no': 'Automatisk oppretting av historiar er eit vanskeleg problem som krev å produsera først relaterte og logiske sekvensar av hendingar om eit emne. Førre tilnærmingar i denne domenet har fokuserte stort på eitt skjulte generering, der eit språk-modell utfører ein fullstendig historie basert på begrenset inndata frå ein brukar. Her, vi fokuserer i staden på oppgåva for interaktive historieformasjon, der brukaren tilbyr abstraksjonen av modellen midtsnivå i form av teiknefrassar under genereringsprosessen. Name Vi presenterer to tilnærmingar med innhaldet for å inkludere denne ekstra informasjonen effektivt. Eksperimentale resultat frå både automatiske og menneskelige evalueringar viser at desse metodane produserer meir temaelt samanlig og personaliserte historiar samanlikna med baseline metodar.', 'mn': 'Автоматик түүх бий болгох нь сэдвийн тухай холбоотой болон логикийн дарааллыг бүтээх шаардлагатай асуудал юм. Энэ холбооны өмнөх арга барилгууд нэг зураг үеийнх дээр ихэвчлэн төвлөрсөн. Холбооны загвар нь хэрэглэгчдийн анхны орлуулалт дээр бүрэн түүхийг гаргадаг. Энд бид интерактив түүх үеийн ажил дээр анхаарлаа төвлөрүүлнэ. Хэрэглэгчид үеийн дундаж хэмжээний үеийн загварыг хүлээн зөвшөөрүүлэх үеийн хэлбэрээр илтгэл үеийн хэлбэрээр гаргадаг. Энэ нь хүмүүсийн хэрэглэгчид түүх үеийнхөө руу зөвлөх интерфейсийг хангадаг. Бид эдгээр нэмэлт мэдээллийг бүрдүүлэхэд хоёр content-induced арга зам өгдөг. Автоматик болон хүн төрөлхтний оюутнуудын туршилтын үр дүнг нь эдгээр арга нь суурь шугам аргаас харьцуулахад илүү холбоотой болон хувийн түүхийг бий болгодог.', 'lt': 'Automatinis istorijų kūrimas yra sunki problem a, dėl kurios reikia sukurti priežastiniu ir logiškas įvykių sekas temai. Ankstesni požiūriai šioje srityje daugiausia buvo susiję su vienkartine karta, kur kalbos modelis pateikia visą istoriją, pagrįstą ribotu vartotojo pradiniu įnašu. Here, we instead focus on the task of interactive story generation, where the user provides the model mid-level sentence abstractions in the form of cue phrases during the generation process.  Tai suteikia žmonių naudotojams sąsają, kuria vadovaujama istorijų kūrimui. Pateikiame du turinį skatinančius metodus, kaip veiksmingai įtraukti šią papildomą informaciją. Automatinių ir žmogaus vertinimų eksperimentiniai rezultatai rodo, kad šie metodai sudaro nuoseklesnes ir individualesnes istorijas, palyginti su pradiniais metodais.', 'pl': 'Automatyczne generowanie opowieści jest problemem wymagającym wytworzenia powiązanych przyczynowo i logicznych sekwencji zdarzeń dotyczących danego tematu. Poprzednie podejścia w tej dziedzinie koncentrowały się w dużej mierze na generowaniu jednego ujęcia, w którym model językowy wydaje kompletną historię opartą na ograniczonym wstępnym wkładzie od użytkownika. Tutaj skupiamy się zamiast tego na zadaniu interaktywnego generowania opowieści, gdzie użytkownik dostarcza modelowe abstrakcje zdań średniego poziomu w postaci fraz cue podczas procesu generowania. Zapewnia to interfejs dla użytkowników ludzkich, aby kierować generowaniem historii. Przedstawiamy dwa podejścia wywołujące treść, aby skutecznie uwzględnić te dodatkowe informacje. Wyniki eksperymentalne zarówno z automatycznych, jak i ludzkich ocen pokazują, że metody te tworzą bardziej aktualnie spójne i spersonalizowane historie w porównaniu z metodami bazowymi.', 'ro': 'Generarea automată a poveștilor este o problemă provocatoare care necesită producerea de secvențe cauzale legate și logice de evenimente despre un subiect. Abordările anterioare în acest domeniu s-au concentrat în mare măsură asupra generației one-shot, în cazul în care un model lingvistic emite o poveste completă bazată pe input inițial limitat de la un utilizator. Aici ne concentrăm în schimb asupra sarcinii generarii interactive a poveștilor, unde utilizatorul furnizează modelul de abstracții de fraze de nivel mediu sub formă de fraze cu tac în timpul procesului de generare. Aceasta oferă o interfață pentru utilizatorii umani pentru a ghida generarea poveștii. Prezentăm două abordări care induc conținutul pentru a integra în mod eficient aceste informații suplimentare. Rezultatele experimentale ale evaluărilor automate și umane arată că aceste metode produc povești mai coerente și personalizate din punct de vedere topic comparativ cu metodele de bază.', 'sr': 'Automatski proizvedenje priče je izazovni problem koji zahteva proizvedenje uzrokovanih i logičkih sekvencija događaja o temi. Prethodni pristupi u ovom domenu su se uglavnom fokusirali na generaciju jedne snimke, gde jezički model iznosi kompletnu priču na osnovu ograničenog početnog ulaska od korisnika. Ovde, umjesto toga, fokusiramo se na zadatak generacije interaktivne priče, gde korisnik pruža model abstrakcije rečenice srednje nivoe u obliku znakova rečenica tokom procesa generacije. Ovo pruža interfejs ljudskim korisnicima da vode generaciju priče. Predstavljamo dva pristupa induciranja sadržaja kako bi učinkovito uključili ove dodatne informacije. Eksperimentalni rezultati automatske i ljudske procjene pokazuju da te metode proizvode temeljnije saskaņotne i personalizirane priče u usporedbi sa početnim metodama.', 'ta': 'தானாகவே கதைகளை உருவாக்குதல் ஒரு சவாலிக்கையான பிரச்சினை @ info இங்கே நாம் செயல்படுத்தும் கதை உருவாக்குவதற்கு பதிலாக கவனம் செலுத்துகிறோம், பயனர் உருவாக்கும் செயல்பாட்டில் உள்ள நடுநிலை வாக்கிய இது மனித பயனர்களுக்கு ஒரு இடைமுகப்பு வழங்குகிறது கதை உருவாக்குவதற்கு. இந்த கூடுதல் தகவலை சேர்க்க இரண்டு உள்ளடக்கங்கள் முதலீடுகளை கொண்டு வருகிறோம். தன்னியக்கமாக மற்றும் மனித மதிப்புகளிலிருந்தும் சோதனை முடிவு', 'so': 'Sida caadiga ah abuuridda sheekooyinku waa dhibaato adag oo u baahan yahay inuu soo saaro dhacdooyinka arrimaha la xiriira iyo cilmiga la xiriira. Dhaqdooyinkii hore ee gudaha ku yaalay waxay aad ugu horaysiiyeen hal qarni, kaas oo qaabka afka lagu qoray uu ka soo bixiyo warqad buuxa oo ku saleysan input-horaadka oo saxda ah ee isticmaalaha. Halkan, waxaynu ku kalsoonaan nahay xafiiska qarniga sheekooyinka dhexe, kaas oo isticmaaluhu uu sameynayo tusaale ahaan xafiiska saxda dhexe ah oo u eg hadalka muuqashada xiliga qarniga. Taasi waxay dadka isticmaalaya u fidisaa Interfac si ay u hagaan qarniga sheekadda. Waxaynu keennaa laba qaab oo wax ku qoraya waxyaabo faa’iido ah oo macluumaadkan dheeraad ah. Imtixaanka waxaa ka soo baxa qiimeynta bilowga ah iyo waxyaabaha biniaadaba waxay muujiyaan in qaababkan ay ku soo kordhaan sheekooyin si ka caadi ah oo loo barbaranayo qaababka aasaasiga ah.', 'sv': 'Att automatiskt generera berättelser är ett utmanande problem som kräver att producera kausalt relaterade och logiska sekvenser av händelser om ett ämne. Tidigare tillvägagångssätt inom detta område har främst fokuserat på one-shot generation, där en språkmodell ger en fullständig berättelse baserad på begränsad initial input från en användare. Här fokuserar vi istället på uppgiften med interaktiv berättelsegenerering, där användaren ger modellen medelnivåfraser i form av cuefraser under genereringsprocessen. Detta ger ett gränssnitt för mänskliga användare för att vägleda berättelsens generation. Vi presenterar två innehållsframkallande metoder för att effektivt införliva denna ytterligare information. Experimentella resultat från både automatiska och mänskliga utvärderingar visar att dessa metoder producerar mer aktuellt sammanhängande och personliga berättelser jämfört med baslinjemetoder.', 'si': 'ස්වයංක්\u200dරමයෙන් කතාවක් නිර්මාණය කරන්න ප්\u200dරශ්නයක් තමයි ප්\u200dරශ්නයක් නිර්මාණය කරන්න අවශ්\u200dය වෙන්නේ ප්\u200dරශ මේ ඩොමේනියේන් වලින් පිළිබඳ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා, භාෂා මොඩේලයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ මෙතන, අපි ප්\u200dරවේශකය කතාව පරීක්ෂණයේ වැඩේ බලන්න, පරීක්ෂකයෙන් ප්\u200dරවේශකයෙන් මධ්\u200dය ස්ථානය සම්බන්ධ වාක්ය ප්\u200dරවේශකයේ  මේක මිනිස්සු ප්\u200dරයෝජකයන්ට කතාව ප්\u200dරමාණය කරන්න ප්\u200dරයෝජනයක් දෙනවා. අපි මේ තවත් තොරතුරු සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණය කරනවා. ස්වයංක්\u200dරියාත්මක සහ මිනිස්සු විශ්ලේෂණයෙන් පරීක්ෂණ ප්\u200dරතිචාරයක් පෙන්වන්නේ මේ විධානය වඩා විදිය', 'ur': 'اپنا کہانیاں پیدا کرنا ایک مشکل ہے جو ایک موضوع کے بارے میں باعث اتصال اور منطقی اتصال کرنے کی ضرورت ہے. اس ڈومین میں پہلے طریقے سے ایک شاٹ کی نسل پر مہربانی کی گئی ہے جہاں ایک زبان مدل ایک کارساز سے محدودہ پہلی ایمپ پر بنیاد رکھتا ہے. یہاں، ہم اس کے بدلے بیٹراکتیوں کہانیاں کی نسل کے کام پر تمرکز کرتے ہیں، جہاں استعمال نے مدل میڈ سطح کے مطابق جماعت کے مطابق کوئ فریزوں کی شکل میں پیدا کیا ہے. یہ انسان کارساز کے لئے ایک انٹرنیٹ پیدا کرتا ہے تاریخ کی نسل کی راہ دکھانے کے لئے۔ ہم اس اضافہ معلومات کے ساتھ شامل کرنے کے لئے دو منزل کے پیدا کرنے والے طریقے پیش کرتے ہیں. آزمائش کے نتائج دونوں آٹوٹی اور انسان کی ارزیابی سے دکھاتے ہیں کہ یہ طریقے اس سے زیادہ موجود اور شخصی کہانیاں پیدا کرتے ہیں جو بنیادی لین طریقوں کے مقابلہ میں ہیں.', 'uz': "Automatically generating stories is a challenging problem that requires producing causally related and logical sequences of events about a topic.  @ info Bu yerda, biz interactive tarixi generalida vazifani foydalanamiz, bu yerda foydalanuvchi foydalanuvchi foydalanuvchi tugmalar bir darajadagi matnning oʻrtadagi gaplarni aytadi. Name Biz bu qo'shimcha maʼlumot qo'shilga oshirish uchun ikkita maʼlumot ichiga qaror qilamiz. Tekshirish natijalari avtomatik va inson qiymatlaridan ham ko'rsatadi bu usullar asosiy usullar bilan bir xil bir xil va shaxsiy hikoyalarni yaratadi.", 'vi': 'Tự động tạo ra các câu chuyện là một vấn đề thách thức cần thiết sản xuất các chuỗi liên quan đến nguyên nhân và logic của các sự kiện về một chủ đề. Các phương pháp trước trong lĩnh vực này đã tập trung rất nhiều vào một phát, nơi mô hình ngôn ngữ cung cấp một câu chuyện hoàn chỉnh dựa trên nội dung ban đầu của người dùng. Ở đây, chúng ta tập trung vào nhiệm vụ sản xuất câu chuyện tương tác, nơi người dùng cung cấp các đoạn phân đoạn hình mẫu ở giữa cấp dưới dạng các cụm từ điển trong quá trình sản xuất. Nó cung cấp một giao diện cho người dùng để hướng dẫn thế hệ câu chuyện. Chúng tôi đưa ra hai phương pháp kích thích nội dung để cung cấp thông tin thêm này. Kết quả thí nghiệm từ cả đánh giá tự động lẫn con người cho thấy các phương pháp này tạo ra các câu chuyện hoàn hảo hơn so với các phương pháp cơ bản.', 'bg': 'Автоматичното генериране на истории е предизвикателен проблем, който изисква създаването на причинно-свързани и логически последователности от събития по дадена тема. Предишните подходи в тази област са се фокусирали предимно върху генерирането на един изстрел, където езиков модел извежда пълна история въз основа на ограничен първоначално вход от потребителя. Тук вместо това се фокусираме върху задачата за интерактивно генериране на истории, където потребителят предоставя модела на абстракции на изречения от средно ниво под формата на реплики по време на процеса на генериране. Това осигурява интерфейс за човешки потребители, който да ръководи генерирането на история. Представяме два подхода за ефективно включване на тази допълнителна информация. Експерименталните резултати от автоматични и човешки оценки показват, че тези методи произвеждат по-актуално съгласувани и персонализирани истории в сравнение с базовите методи.', 'nl': 'Het automatisch genereren van verhalen is een uitdagend probleem dat het produceren van causaal gerelateerde en logische reeksen van gebeurtenissen over een onderwerp vereist. Eerdere benaderingen in dit domein zijn grotendeels gericht op one-shot generatie, waarbij een taalmodel een volledig verhaal uitvoert op basis van beperkte initiële input van een gebruiker. Hier richten we ons in plaats daarvan op de taak van interactieve verhaaltgeneratie, waarbij de gebruiker tijdens het genereerproces het model van zinsabstracties op middelhoog niveau verstrekt in de vorm van cue-zinnen. Dit biedt een interface voor menselijke gebruikers om het genereren van verhalen te begeleiden. We presenteren twee inhoudelijke benaderingen om deze aanvullende informatie effectief op te nemen. Experimentele resultaten van zowel automatische als menselijke evaluaties tonen aan dat deze methoden meer actueel samenhangende en gepersonaliseerde verhalen produceren in vergelijking met basismethoden.', 'da': 'Automatisk generering af historier er et udfordrende problem, der kræver at producere kausalt relaterede og logiske sekvenser af begivenheder om et emne. Tidligere tilgange på dette område har hovedsageligt fokuseret på one-shot generation, hvor en sprogmodel udgiver en komplet historie baseret på begrænset indledende input fra en bruger. Her fokuserer vi i stedet på opgaven med interaktiv historiegenerering, hvor brugeren giver modellen mid-level sætningsafdragter i form af cue sætninger under genereringsprocessen. Dette giver en grænseflade for menneskelige brugere til at guide historien generering. Vi præsenterer to indholdsinducerende tilgange til effektivt at indarbejde disse yderligere oplysninger. Eksperimentelle resultater fra både automatiske og menneskelige evalueringer viser, at disse metoder producerer mere aktuelt sammenhængende og personlige historier sammenlignet med baseline metoder.', 'de': 'Das automatische Generieren von Geschichten ist ein herausforderndes Problem, das es erfordert, kausale und logische Sequenzen von Ereignissen zu einem Thema zu produzieren. Bisherige Ansätze in diesem Bereich konzentrierten sich größtenteils auf die One-Shot-Generierung, bei der ein Sprachmodell eine komplette Geschichte auf der Grundlage begrenzter anfänglicher Eingaben eines Benutzers ausgibt. Stattdessen konzentrieren wir uns hier auf die Aufgabe der interaktiven Story-Generierung, bei der der Benutzer während des Generierungsprozesses die mittleren Satzantraktionen in Form von Cue-Phrasen modelliert. Dies bietet eine Schnittstelle für menschliche Benutzer, um die Story-Generierung zu steuern. Wir stellen zwei inhaltliche Ansätze vor, um diese zusätzlichen Informationen effektiv zu integrieren. Experimentelle Ergebnisse aus automatischen und menschlichen Auswertungen zeigen, dass diese Methoden im Vergleich zu Basismethoden topisch kohärentere und personalisiertere Geschichten produzieren.', 'id': 'Membuat cerita secara otomatis adalah masalah yang menantang yang membutuhkan menghasilkan urutan yang berhubungan dengan penyebab dan logis peristiwa tentang topik. Previous approaches in this domain have focused largely on one-shot generation, where a language model outputs a complete story based on limited initial input from a user.  Di sini, kita berbaliknya fokus pada tugas generasi cerita interaktif, di mana pengguna menyediakan model abstraksi kalimat tengah tingkat dalam bentuk frasa cue selama proses generasi. Ini menyediakan antarmuka bagi pengguna manusia untuk memimpin generasi cerita. We present two content-inducing approaches to effectively incorporate this additional information.  Hasil eksperimen dari evaluasi otomatis dan manusia menunjukkan bahwa metode ini menghasilkan cerita yang lebih konsisten secara topik dan pribadi dibandingkan dengan metode dasar.', 'ko': '자동 생성 이야기는 도전적인 문제로 주제와 관련된 인과 관계와 논리적 사건 서열을 생성해야 한다.이 분야의 이전 방법은 주로 일회성 생성, 즉 언어 모델이 사용자의 유한한 초기 입력과 출력을 바탕으로 완전한 이야기를 만드는 데 집중되었다.여기서 우리는 상호작용 이야기 생성의 임무에 중점을 두고 사용자가 생성 과정에서 제시단어의 형식으로 모델 중급 문장을 추상적으로 제공할 것이다.이것은 인류 사용자에게 하나의 인터페이스를 제공하여 이야기의 생성을 지도한다.우리는 이러한 부가 정보를 효과적으로 통합시키기 위해 두 가지 내용 유도 방법을 제시했다.자동과 인공 평가의 실험 결과에 따르면 기선 방법에 비해 이런 방법은 더욱 주제의 일관성과 개성화된 이야기를 만들어 낼 수 있다.', 'sw': 'Kutengeneza hadithi binafsi ni tatizo la changamoto ambalo linahitaji kutengeneza mfululizo wa matukio yanayohusiana na kimaadili kuhusu mada. Matokeo yaliyopita katika eneo hili yamekuwa yakinikiza zaidi kwenye kizazi kimoja kinachopigwa risasi, ambapo mtindo wa lugha unatoa simulizi kamili kwa kutumia input mdogo wa mwanzo kutoka kwa mtumiaji. Hapa, badala yake tunajikita kwenye jukumu la kizazi cha habari kinachohusiana, ambapo mtumiaji huyo anatoa mifano ya sentensi ya kati ya ngazi ya hukumu hiyo kwa namna ya maneno ya kiungo wakati wa mchakato wa kizazi. Hii inatoa sura kwa watumiaji wa binadamu kuongoza kizazi hiki. Tunaweza kutoa mbinu mbili za kuwekeza maudhui ili kuwasilisha taarifa hii kwa ufanisi. Experimental results from both automatic and human evaluations show that these methods produce more topically coherent and personalized stories compared to baseline methods.', 'hr': 'Automatski stvaranje priče je izazovni problem koji zahtijeva proizvodnju uzrokovanih i logičkih sekvencija događaja o temi. Prethodni pristupi u ovom domenu su se uglavnom fokusirali na generaciju jedne snimke, gdje jezički model iznosi kompletnu priču na temelju ograničenog početnog ulaska od korisnika. Ovdje, umjesto toga, fokusiramo se na zadatak generacije interaktivne priče, gdje korisnik pruža model apstrakcije rečenica srednje razine u obliku znakova fraza tijekom procesa generacije. To pruža interfejs ljudskim korisnicima da vode generaciju priče. Predstavljamo dva pristupa induciranja sadržaja kako bi učinkovito uključili ove dodatne informacije. Eksperimentalni rezultati automatskih i ljudskih procjena pokazuju da te metode proizvode temeljnije saskaņotne i personalizirane priče u usporedbi s početnim metodama.', 'fa': 'تولید داستان\u200cها به طور خودکار یک مشکل سخت\u200cکننده است که نیاز به تولید دسته\u200cهای باعث اتفاقات و منطقی در مورد یک موضوع است. نزدیک های قبلی در این دامنه بسیار روی نسل یک شلیک تمرکز می کنند، جایی که یک مدل زبان یک داستان کامل را بر اساس ورودهای اولیه محدود از یک کاربر بیرون می دهد. اینجا، ما به جای اینکه روی کار نسل داستان متفاوتی تمرکز کنیم، جایی که کاربر مدل جمله\u200cهای متوسط سطح را در شکل جمله\u200cهای نشانی در طول فرایند نسل می\u200cدهد. این یک مشترک برای کاربران انسان برای هدایت نسل داستان را می\u200cدهد. ما دو دستیابی که باعث می\u200cشود از محتویات تحریک کند را برای فعالیت این اطلاعات اضافه تشکیل دهیم. نتیجه\u200cهای تجربه\u200cای از ارزیابی\u200cهای خودکار و انسان نشان می\u200cدهد که این روش\u200cها داستان\u200cهای موجود و شخصی\u200cتری را در مقایسه با روش\u200cهای پایین\u200cتری تولید می\u200cکنند.', 'tr': 'Öňki ýasalan hekaýalar meýilleşdirmek meňzeşli mesele. Bu mesele hakynda sebäbi baglanýan we logik gabdalyklaryň netijesi bar. Bu domeniň öňki golaýlary ullançylaryň başlangıç girişi barada üns berilýär. Bu ýerde, biz bu ýerde etkileşimli hekaýa döwletlerine üns berýäris. Ulaşçylaryň orta dereje sözleriň habarlamagyny janlaşdyrylyp durmuşy ýagdaýda hasaplamagyny saýlaýarlar. Bu adamlaryň hekaýa döwletlerini görkezmek üçin bir interfeje temin edýär. Biz bu ýene bir maglumat dahyl etmek üçin iki maksadyň täsirli golaýy görkeýäris. Durmanyň netijeleri hem awtomatik, hem adamlaryň deňleşmelerinden bu yönleriň üýtgeşik we şahsy hekaýalary baseline yönlere görä daşyrýandygyny görkezýär.', 'hy': 'Անշուշտ պատմություններ ստեղծելը բարդ խնդիր է, որը պահանջում է թեմայի մասին պատճառային և տրամաբանական իրադարձությունների ստեղծման: Այս ոլորտում նախորդ մոտեցումները հիմնականում կենտրոնացել են մեկ սերունդի վրա, որտեղ լեզվի մոդելը հանում է ամբողջական պատմություն, հիմնված օգտագործողի սահմանափակ սկզբնական ներմուծների վրա: Այստեղ, փոխարենը, մենք կենտրոնանում ենք ինտերակտիվ պատմությունների ստեղծման խնդրի վրա, որտեղ օգտագործողը տրամադրում է մոդելը միջին մակարդակի նախադասությունների վերացումների տեսքով սերնդի ընթացքում: Սա մարդկային օգտագործողների համար ինտերֆեյս է տրամադրում պատմության սերնդի ուղղությամբ: We present two content-inducing approaches to effectively incorporate this additional information.  Առաջինս և ավտոմատիկ գնահատումների փորձարկման արդյունքները ցույց են տալիս, որ այս մեթոդները ստեղծում են ավելի թեմատիկապես համապատասխանատու և անձնական պատմություններ, համեմատած հիմնական մեթոդների հետ:', 'am': 'ታሪኮችን በመፍጠር ውጤት የጉዳዩ ጉዳይ እና የግንኙነትን ጉዳይ በመፍጠር ያስፈልጋል፡፡ የቀድሞው የዚህ ዶሜን ደረጃዎች በተለየ በአንድ ትውልድ ላይ ተማክሮአል፤ ቋንቋ ሞዴል ከተጠቃሚ የጥያቄ ጥያቄ የተደረገውን ሙሉ ታሪክ ያወጣል፡፡ ይሄን፣ በተግባር ታሪክ ትውልድ ማድረግ ላይ እናስማታለን፣ በተጠቃሚ የግንኙነት መካከለኛውን የክፍለ ቃላትን በክዌ ፕሮጀክት ውስጥ የሚደረገውን እናስብ፡፡ ይህም ታሪክ ትውልድ ለመመራት ለሰው ተጠቃሚዎች የግንኙነት ማቀናጃ ነው፡፡ ሁለትን የውይይት አካባቢ መረጃዎችን ለመጠቀም እናቀርባለን፡፡ ፈተና ውጤቶች ከህትመት እና ከሰው ውጤቶች ይታያል፤ እነዚህ ሥርዓቶች ከBaseline ሥርዓት ጋር የሚተካክሉ እና የተለየ ታሪኮችን አብልጠዋል፡፡', 'bn': 'Automatically generating stories is a challenging problem that requires producing causally related and logical sequences of events about a topic.  এই ডোমেইনের পূর্ববর্তী পদক্ষেপ বেশীরভাগ একটি গুলি প্রজন্মের উপর মনোযোগ দিয়েছে, যেখানে একটি ভাষা মডেল ব্যবহারকারীর কাছ থেকে সীমিত প এখানে আমরা ব্যবহারকারীরা প্রজন্মের সময় মধ্যস্তরের মাঝামাঝি মাঝামাঝি বাক্যের বিরুদ্ধে মোডেল প্রদান করেছেন। এটি মানব ব্যবহারকারীদের জন্য একটি ইন্টারফেস প্রদান করে গল্প প্রজন্মের পথ দেখানোর জন্য। আমরা এই বিষয়টি কার্যকর তথ্য যোগাযোগ করার জন্য দুটি উপায় উপস্থাপন করি। স্বয়ংক্রিয়ভাবে এবং মানুষের মূল্য উভয়ের পরীক্ষার ফলাফল দেখাচ্ছে যে এই পদ্ধতিগুলো বেসেলাইন পদ্ধতির তুলনায় আরো ব্যক্তিগত গল্প তৈ', 'af': "Outomaties genereer histories is 'n pragtige probleem wat vereis om oorsaaklik verwante en logiese sekwensies van gebeurtenis oor 'n onderwerp te produseer. Vorige toegang in hierdie domein het groot gefokus op een-skoot generasie, waar 'n taal model uitvoer 'n volledige storie gebaseer op beperk aanvanklike invoer van' n gebruiker. Hier, ons in plaas fokus op die taak van interaktiewe storie generasie, waar die gebruiker verskaf die model middel-vlak seën abstraksies in die vorm van cue frase tydens die generasie proses. Name Ons stel twee inhoud-induserende toegang om hierdie addisionele inligting te inkorporeer. Eksperimentale resultate van beide automatiese en menslike evaluasies vertoon dat hierdie metodes meer onderwerp en persoonlike stories vergelyk het met baselyn metodes.", 'sq': 'Gjenerimi automatik i historive është një problem sfidues që kërkon prodhimin e sekuencave të lidhura me shkak dhe logjike të ngjarjeve rreth një temë. Përqasjet e mëparshme në këtë domeni janë përqëndruar kryesisht në një gjeneratë me një gjuhë, ku një model gjuhësh nxjerr një histori të plotë bazuar në hyrje të kufizuar fillestare nga një përdorues. Këtu, ne në vend të kësaj fokusohemi në detyrën e gjenerimit interaktiv të historive, ku përdoruesi ofron model in abstrakcione të fjalëve të nivelit të mesëm në form ën e frazave të sinjalit gjatë procesit të gjenerimit. Kjo ofron një interfaqe për përdoruesit njerëzor për të udhëzuar gjeneratën e historive. Ne paraqesim dy qasje nxitëse përmbajtjesh për të përfshirë efektivisht këtë informacion shtesë. Experimental results from both automatic and human evaluations show that these methods produce more topically coherent and personalized stories compared to baseline methods.', 'cs': 'Automatické generování příběhů je náročný problém, který vyžaduje produkci kauzálně souvisejících a logických sekvencí událostí o daném tématu. Předchozí přístupy v této oblasti se zaměřily převážně na jednorázovou generaci, kde jazykový model vydává kompletní příběh založený na omezeném počátečním vstupu od uživatele. Zde se místo toho zaměřujeme na úlohu interaktivního generování příběhu, kde uživatel při generování poskytuje model abstrakce vět střední úrovně ve formě nápovědných frází. To poskytuje rozhraní pro lidské uživatele, které vede generování příběhu. Představujeme dva obsahově vyvolávající přístupy k efektivnímu začlenění těchto doplňkových informací. Experimentální výsledky automatických i lidských hodnocení ukazují, že tyto metody produkují aktuálně koherentnější a personalizovanější příběhy ve srovnání se základními metodami.', 'az': 'Hekay…ôl…ôri avtomatik olaraq yaratmaq m…ôs…ôl…ôsi haqqńĪnda olaraq bańülńĪ v…ô lojik olaraq yaratmaq lazńĪmdńĪr. Bu domandakńĪ …ôvv…ôlki t…ôrzl…ôrin √ßox bir t…ôrzin n…ôsilin…ô odaqlanmńĪŇüdńĪr. Dil modeli istifad…ô√ßisinin qurńüulu ilk giriŇüin …ô dayanan tamam hekay…ôni √ßńĪxarńĪr. Burada, biz interaktif hekay…ô n…ôsill…ôrinin iŇüin …ô odaklanńĪrńĪq, istifad…ô√ßin in n…ôsil prosesi sńĪrasńĪnda orta s…ôviyy…ô c√ľml…ôl…ôrinin orta s…ôviyy…ôd…ô modeli abstraksiyonlarńĪ t…ômin edir. Bu, insan istifad…ô√ßil…ôrinin hekay…ôtin n…ôslini dońüru yola y√∂n…ôltm…ôk √ľ√ß√ľn bir interfejsi t…ômin edir. Biz bu …ôlav…ô m…ôlumatlarńĪnńĪ etkili olaraq birl…ôŇüdirm…ôk √ľ√ß√ľn iki m…ôlumat t…ôŇükil ed…ôn approach g√∂st…ôririk. ńįkisind…ô d…ô avtomatik v…ô insan deńüerlendirm…ôl…ôrind…ôn t…ôcr√ľb…ô sonu√ßlarńĪ t…ôcr√ľb…ô edirl…ôr ki, bu metodlar t…ôcr√ľb…ô metodlarńĪ il…ô m√ľqayis…ôd…ô daha m√ľxt…ôlif v…ô kiŇüiseli hekay…ôl…ôr √ľr…ôkl…ônir.', 'et': 'Lugude automaatne genereerimine on keeruline probleem, mis nõuab põhjuslikult seotud ja loogiliste sündmuste järjestuste koostamist teema kohta. Varasemad lähenemisviisid selles valdkonnas on keskendunud peamiselt ühekordsele generatsioonile, kus keelemudel väljastab täieliku loo, mis põhineb kasutaja piiratud esialgsel sisendil. Siin keskendume selle asemel interaktiivse loo genereerimise ülesandele, kus kasutaja pakub mudeli kesktaseme lauseabstraktsioone vihjefraaside kujul genereerimisprotsessi ajal. See annab inimkasutajatele liidese, et juhtida lugu genereerimist. Esitame kaks sisu tekitavat lähenemisviisi selle lisateabe tõhusaks kaasamiseks. Nii automaatsete kui ka inimeste hindamiste eksperimentaalsed tulemused näitavad, et need meetodid toodavad algmeetoditega võrreldes aktuaalselt sidusamaid ja isikupärastatud lugusid.', 'bs': 'Automatski stvaranje priče je izazovni problem koji zahtijeva proizvodnju uzrokovanih i logičkih sekvencija događaja o temi. Prethodni pristupi u ovom domenu su se uglavnom fokusirali na generaciju jedne snimke, gdje jezički model iznosi kompletnu priču baziranu na ograničenoj početnoj ulazi od korisnika. Ovdje, umjesto toga, fokusiramo se na zadatak generacije interaktivnih priča, gdje korisnik pruža model apstrakcije rečenica srednje nivoe u obliku znakova fraza tijekom procesa generacije. To pruža interfejs ljudskim korisnicima da vode generaciju priče. Predstavljamo dva pristupa induciranja sadržaja kako bi učinkovito uključili ove dodatne informacije. Eksperimentalni rezultati automatske i ljudske procjene pokazuju da te metode proizvode temeljnije saskaņotne i personalizirane priče u usporedbi s početnim metodama.', 'fi': 'Tarinoiden automaattinen generointi on haastava ongelma, joka edellyttää kausaalisesti liittyvien ja loogisten tapahtumien tuottamista aiheesta. Aiemmat lähestymistavat tällä alalla ovat keskittyneet pitkälti yhden laukauksen generointiin, jossa kielimalli tuottaa täydellisen tarinan, joka perustuu käyttäjän rajalliseen alkusyötteeseen. Tässä keskitytään vuorovaikutteiseen tarinankehittämiseen, jossa käyttäjä tarjoaa mallin keskitason lauseabstraktioita merkkilauseiden muodossa generointiprosessin aikana. Tämä tarjoaa käyttöliittymän ihmisille ohjaamaan tarinan syntymistä. Esittelemme kaksi sisältöä luovaa lähestymistapaa, joilla nämä lisätiedot voidaan tehokkaasti sisällyttää. Kokeelliset tulokset sekä automaattisista että inhimillisistä arvioinneista osoittavat, että nämä menetelmät tuottavat ajankohtaisesti johdonmukaisempia ja yksilöllisempiä tarinoita verrattuna perusmenetelmiin.', 'ca': "generar històries automàticament és un problem a desafiant que requereix produir seqüències lògiques i causals d'esdeveniments sobre un tema. Els enfocaments anteriors en aquest domini s'han centrat principalment en una generació d'una sola foto, on un model de llenguatge produeix una història completa basada en una entrada inicial limitada d'un usuari. Aquí ens centrem en la tasca de la generació interactiva de històries, on l'usuari proporciona el model d'abstraccions de frases de nivell mitjà en forma de frases de segons durant el procés de generació. Això proporciona una interfície per als usuaris humans per guiar la generació de històries. Presentam dos enfocaments que indueixen continguts per incorporar efectivament aquesta informació adicional. Els resultats experimentals de les evaluacions automàtiques i humanes mostren que aquests mètodes produeixen històries més coherents topicalment i personalitzades en comparació amb els mètodes de base.", 'he': 'ליצור סיפורים באוטומטית היא בעיה מאתגרת שדורשת ליצור רצפי אירועים שקשורים לסיבה ולגיונים על נושא. גישות קודמות בתחום הזה התמקדו בעיקר בדור אחד, שבו מודל שפה יוציא סיפור מושלם מבוסס על כניסה קודמית מוגבלת משתמש. כאן, במקום זה, אנחנו מתמקדים במשימה של דור סיפורים אינטראקטיביים, שבו המשתמש מספק את הדוגמא משפטים ברמה האמצעית בצורה של ביטויים סימן במהלך תהליך הדור. זה מספק ממשק למשתמשים אנושיים כדי להדריך את דור הסיפורים. אנחנו מציגים שתי גישות מעוררות תוכן כדי להשתלב באופן יעיל את המידע הנוסף הזה. תוצאות ניסויים מהערכות אוטומטיות וגם האנושיות מראות שהשיטות האלה יוצרות סיפורים יותר תואמים ומתאימים באופן נושאי בהשוואה לשיטות הבסיסית.', 'ha': "@ action: button Tsarin da ya gabãta cikin wannan Domen sun fokus kikubwa a kan kije guda, inda wata misalin harshe na fitar da wani lãbãri cikakki, a kan da aka ƙayyade tsarin da ke ƙara daga mai amfani da shi. Hala, munã fokusar wa aikin shaidar na kiyayen aiki, a inda mai amfani da shi yana bãyar da shirin motel da cire-cewa tsakanin-daraja cikin tsarin maganar cue a lokacin mazaɓa. Wannan yana da wani interfekt wa masu amfani da mazan mutane da ke shiryarwa kiyayen. Tuna gabatar da hanyõyi biyu masu ƙaranci, dõmin su sami wannan information na ƙara. Matarin jarrabai daga ƙaddarawa farat ɗaya da kuma yana nuna cewa, waɗannan hanyõyin su zata ƙaranci da bakwai masu haɗi da hadiyado masu da ɗabi'a da sami'a da metoden-layin.", 'sk': 'Samodejno ustvarjanje zgodb je zahteven problem, ki zahteva ustvarjanje vzročno povezanih in logičnih zaporedij dogodkov o temi. Prejšnji pristopi na tem področju so se v veliki meri osredotočili na enotno generacijo, kjer jezikovni model izda celotno zgodbo, ki temelji na omejenem začetnem vnosu uporabnika. Tukaj se namesto tega osredotočamo na nalogo interaktivnega ustvarjanja zgodb, kjer uporabnik med procesom generacije zagotavlja vzorčne abstrakcije stavkov srednje ravni v obliki smernic. To zagotavlja vmesnik za človeške uporabnike, ki vodi ustvarjanje zgodbe. Predstavljamo dva vsebinska pristopa za učinkovito vključitev teh dodatnih informacij. Eksperimentalni rezultati avtomatičnih in človeških ocen kažejo, da te metode ustvarjajo bolj aktualno skladne in prilagojene zgodbe v primerjavi z osnovnimi metodami.', 'jv': 'Layout Go online Punika, kita dipontrol kanggo nggawe Perintah ingkang interactive Ngomongke iki banget kanggo usul dumadhi kanggo ngubah winih Awak dhéwé éntuk sistem sing dibutuhke tarjamahan kanggo nggawe informasi tambah iki. Rasalih sing perbudhakan karo sistem sing otomatik karo hal-hal kuwi nggawe nguasai perbudhakan karo hal-hal sing menehi nggawe nguasai perbudhakan yak sampek karo perbudhakan liyane karo perbudhakan liyane', 'bo': 'རང་འགུལ་གྱིས་སྒྲུང་ཐོག་བཟོ་བྱེད་དགོས་པའི་གནད་དོན་དཀའ་ངལ་ཆེ་བ་རེད། Previous approaches in this domain have focused largely on one-shot generation, where a language model outputs a complete story based on limited initial input from a user. འདིར་ན། ང་ཚོས་བློ་གཏད་འཚོལ་བ་ལྟ་བུའི་དོན་ལ་དམིགས་བསལ་འདོད་པ་དེ་ནི་སྤྱོད་མཁན་གྱི་རྣམ་པ་གྲངས་མཚམས་མཐོང་སྣང་གི་ཚིག་ར འདིས་མི་ལག་ལེན་པ་ལ་སྒྲུང་གཏམ་གླེང་ལ་འདིའི་མཐུད་སྣེ་འདྲ་ཞིག་བྱེད་ཀྱི་ཡོད། ང་ཚོས་ནང་དོན་གྱི་ཐབས་ལམ་གཉིས་ཀྱིས་གནད་དོན་ཐད་ཀར་འགྲེལ་བཤད་ཐབས་ལམ་གཉིས་ངོས་འཛིན་ཡོད། རང་འགུལ་གྱིས་མི་རིགས་དང་མི་རིགས་ཀྱི་དཔྱད་སྐོར་ལས་བརྟན་ན། ཐབས་ལམ་འདི་དག་གིས་གནད་དོན་ཡོད་པའི་དང་མི་རིགས་སྐྱེས་པའི་'}
{'en': 'Liputan6 : A Large-scale Indonesian Dataset for Text Summarization I ndonesian Dataset for Text Summarization', 'pt': 'Liputan6: um conjunto de dados indonésio em grande escala para sumarização de texto', 'es': 'Liputan6: Un conjunto de datos indonesio a gran escala para el resumen de textos', 'ar': 'Liputan6: مجموعة بيانات إندونيسية واسعة النطاق لتلخيص النص', 'fr': 'Liputan6\xa0: un jeu de données indonésien à grande échelle pour la synthèse de texte', 'ja': 'Liputan 6:テキストの要約のための大規模なインドネシアのデータセット', 'zh': 'Liputan6:文本大印度尼西亚集', 'hi': 'Liputan6: पाठ Summarization के लिए एक बड़े पैमाने पर इंडोनेशियाई डेटासेट', 'ru': 'Liputan6: Крупномасштабный индонезийский набор данных для обобщения текста', 'ga': 'Liputan6: Tacar Sonraí Indinéisis ar Mhórscála le haghaidh Achoimre Téacs', 'el': 'Λιπουταν6: Ένα ευρείας κλίμακας σύνολο δεδομένων για την Ινδονησία για την περίληψη κειμένου', 'hu': 'Liputan6: Egy nagyméretű indonéz adatkészlet a szövegösszefoglaláshoz', 'ka': 'Name', 'kk': 'Liputan6: Мәтін тұжырымдамасы үшін Индонезия үлкен масштабы деректер бағдарламасы', 'it': 'Liputan6: un dataset indonesiano su larga scala per la sintesi del testo', 'ms': 'Liputan6: Satu Set Data Indonesia Skala Besar untuk Ringkasan Teks', 'lt': 'Liputan6: Didelio masto Indonezijos duomenų rinkinys tekstui apibendrinti', 'ml': 'ലിപൂട്ടാന്\u200d6: വാചകത്തിനുള്ള വിവരങ്ങള്\u200d', 'mt': 'Liputan6: Sett ta’ Dejta Indoneżjan fuq skala kbira għas-Sommarju tat-Test', 'mn': 'Liputan6: Том хэмжээний Индонезийн өгөгдлийн сан', 'pl': 'Liputan6: duży zestaw danych indonezyjskich na potrzeby podsumowania tekstu', 'ro': 'Liputan6: Un set de date indonezian pe scară largă pentru rezumarea textelor', 'mk': 'Липутан6: Голем индонезиски податок за резултат на текстот', 'so': 'Liputan6: A Large scale Indonesian Dataset for summarization text', 'sv': 'Liputan6: En storskalig indonesisk dataset för textsammanfattning', 'si': 'Name', 'no': 'Liputan6: Ein stor indonesisk databaser for sammendraging av tekst', 'sr': 'Liputan6: Velika skala Indonezijskih podataka za sažetanje teksta', 'ta': 'லிபுடான்6: உரை சுருக்கம்', 'ur': 'لیپوٹن 6: ایک بزرگ اسکیل اینڈونزی ڈاٹ سٹ لیکس جماریزی کے لئے', 'uz': 'Liputan6: Matn hisoboti uchun katta IndoneziyaName', 'vi': 'Lipstan6: Một bộ nhớ dữ liệu Indonesia trên diện rộng về tổng hợp văn bản', 'hr': 'Liputan6: Velika skala Indonezijskih podataka za sažetak teksta', 'bg': 'Липутан6: Голям индонезийски набор от данни за обобщаване на текста', 'da': 'Liputan6: Et stort indonesisk datasæt til tekst summering', 'id': 'Liputan6: Satu set data Indonesia skala besar untuk Penapisan Teks', 'ko': 'Liputan6: 텍스트 요약을 위한 대규모 인도네시아 데이터 세트', 'nl': 'Liputan6: Een grootschalige Indonesische dataset voor tekstsamenvatting', 'fa': 'Name', 'de': 'Liputan6: Ein großer indonesischer Datensatz zur Textzusammenfassung', 'sw': 'Liputan6: Mpaka wa data kwa kiwango kikubwa wa Indonesia kwa ajili ya Ujumbe wa Maandishi', 'tr': 'Liputan6: Metin Toplaýyşy üçin Ullakan Mazmunlar', 'af': 'Name', 'hy': '6. Տեքստի համառոտագրման մեծ ինդոնեզիայի տվյալներ', 'am': 'ሊputan6: ማጠቃለያ ትልቅ የኢንዶኒያዊ ዳታ ማጠቃለያ የጽሑፍ ማጠቃለያ', 'sq': 'Liputan6: Një bazë të dhënash në shkallë të madhe indoneziane për përmbledhjen e tekstit', 'ca': 'Liputan6: A Large-scale Indonesian Dataset for Text Summarization', 'cs': 'Lipútán6: Rozsáhlý indonéský datový soubor pro shrnutí textů', 'bs': 'Liputan6: Velika skala Indonezijskih podataka za sažetak teksta', 'az': 'Liputan6: Metin Toplaşdırması üçün böyük ölçüdə Indoneziya verilən verilən', 'fi': 'Liputan6: Laajamittainen indonesialainen tietojoukko tekstin yhteenvetoa varten', 'et': 'Liputan6: Suuremahuline Indoneesia andmekogum teksti kokkuvõtmiseks', 'bn': 'লিপুটান৬: লেখা সামার্জারের জন্য ইন্দোনেশিয়ান ডাটা সেট', 'sk': 'Liputan6: obsežen indonezijski nabor podatkov za povzetek besedila', 'he': 'Liputan6: קבוצת נתונים אינדונזית ברמה גדולה לסומריזציה טקסטית', 'ha': '6: KCharselect unicode block name', 'bo': 'Liputan6:ཆེ་ཆུང་བའི་ནང་དུ་ནུས་ཡིག་ཆ་བསྡུས་ཀྱི་གནས་སྡུད་རིམ་ཞིག', 'jv': 'Liputan6'}
{'en': 'In this paper, we introduce a large-scale Indonesian summarization dataset. We harvest articles from Liputan6.com, an online news portal, and obtain 215,827 documentsummary pairs. We leverage pre-trained language models to develop benchmark extractive and abstractive summarization methods over the dataset with multilingual and monolingual BERT-based models. We include a thorough error analysis by examining machine-generated summaries that have low ROUGE scores, and expose both issues with ROUGE itself, as well as with extractive and abstractive summarization models.', 'ar': 'في هذه الورقة ، نقدم مجموعة بيانات تلخيص إندونيسية واسعة النطاق. نحصد المقالات من Liputan6.com ، وهي بوابة إخبارية على الإنترنت ، ونحصل على 215827 زوجًا من ملخصات المستندات. نحن نستفيد من نماذج اللغة المدربة مسبقًا لتطوير طرق تلخيص معيارية استخلاصية وتجريدية عبر مجموعة البيانات باستخدام نماذج متعددة اللغات وأحادية اللغة قائمة على BERT. نقوم بتضمين تحليل شامل للخطأ من خلال فحص الملخصات المُنشأة آليًا والتي لها درجات منخفضة من ROUGE ، وكشف كلتا المشكلتين مع ROUGE نفسها ، وكذلك مع نماذج التلخيص الاستخراجية والتجريدية.', 'es': 'En este artículo, presentamos un conjunto de datos de resumen de Indonesia a gran escala. Recogemos artículos de Liputan6.com, un portal de noticias en línea, y obtenemos 215.827 pares de documentos y resúmenes. Aprovechamos modelos lingüísticos previamente entrenados para desarrollar métodos de resumen extractivos y abstractivos de referencia sobre el conjunto de datos con modelos basados en BERT multilingües y monolingües. Incluimos un análisis exhaustivo de errores mediante el examen de los resúmenes generados por máquinas que tienen puntuaciones ROUGE bajas, y exponemos ambos problemas con ROUGE en sí, así como con los modelos de resumen extractivos y abstractivos.', 'fr': "Dans cet article, nous présentons un ensemble de données de synthèse indonésien à grande échelle. Nous recueillons des articles sur Liputan6.com, un portail d'actualités en ligne, et obtenons 215 827 paires documents-résumés. Nous tirons parti de modèles linguistiques préformés pour développer des méthodes de synthèse extractives et abstraites de référence sur l'ensemble de données avec des modèles multilingues et monolingues basés sur BERT. Nous incluons une analyse approfondie des erreurs en examinant les résumés générés par machine qui ont de faibles scores ROUGE, et nous exposons à la fois les problèmes avec ROUGE lui-même, ainsi que les modèles de synthèse extractifs et abstraits.", 'pt': 'Neste artigo, apresentamos um conjunto de dados de sumarização indonésio em grande escala. Colhemos artigos do Liputan6.com, um portal de notícias online, e obtemos 215.827 pares documento-resumo. Aproveitamos modelos de linguagem pré-treinados para desenvolver métodos de sumarização extrativos e abstrativos de referência sobre o conjunto de dados com modelos baseados em BERT multilíngues e monolíngues. Incluímos uma análise de erro completa examinando resumos gerados por máquina que têm pontuações baixas do ROUGE e expomos ambos os problemas com o próprio ROUGE, bem como com modelos de sumarização extrativos e abstrativos.', 'ja': '本稿では、インドネシアの大規模な要約データセットを紹介する。オンラインニュースポータルであるLiputan6.comから記事を収集し、215,827のドキュメントサマリーペアを入手します。事前にトレーニングを受けた言語モデルを活用して、多言語および単一言語のBERTベースのモデルを使用して、データセット上でベンチマーク抽出および抽象的な要約方法を開発します。当社では、Rougeのスコアが低い機械で生成された要約を調べ、ROUGE自体と抽象的および抽象的な要約モデルの両方の問題を明らかにすることで、徹底的なエラー分析を含めています。', 'zh': '本文中,大印度尼西亚摘要数集。 在线新闻门户网站 Liputan6.com)集文章,并获215,827文档摘要是也。 吾因豫教之语,以多言单语BERT,以数集上取象摘要法。 参之机器生,下ROUGE分数之摘要,以尽过失,以明ROUGE身及抽象摘要法。', 'hi': 'इस पेपर में, हम एक बड़े पैमाने पर इंडोनेशियाई सारांश डेटासेट पेश करते हैं। हम Liputan6.com, एक ऑनलाइन समाचार पोर्टल से लेख काटते हैं, और 215,827 दस्तावेज़-सारांश जोड़े प्राप्त करते हैं। हम बहुभाषी और मोनोलिंगुअल BERT-आधारित मॉडल के साथ डेटासेट पर बेंचमार्क निष्कर्षण और अमूर्त summarization विधियों को विकसित करने के लिए पूर्व-प्रशिक्षित भाषा मॉडल का लाभ उठाते हैं। हम मशीन-जनित सारांशों की जांच करके एक पूरी तरह से त्रुटि विश्लेषण शामिल करते हैं जिनमें कम रूज स्कोर होते हैं, और रूज के साथ-साथ निष्कर्षण और अमूर्त सारांश मॉडल के साथ दोनों मुद्दों को उजागर करते हैं।', 'ru': 'В настоящем документе мы представляем крупномасштабный индонезийский сводный набор данных. Мы собираем статьи онлайн-портала новостей Liputan6.com и получаем 215 827 пар документов. Мы используем предварительно обученные языковые модели для разработки эталонных методов извлечения и абстрактного обобщения по сравнению с набором данных с многоязычными и одноязычными моделями на основе BERT. Мы включаем тщательный анализ ошибок, изучая сгенерированные машиной сводки, которые имеют низкие оценки ROUGE, и раскрываем обе проблемы с самой ROUGE, а также с извлекающими и абстрактными моделями обобщения.', 'ga': 'Sa pháipéar seo, tugaimid isteach tacar sonraí achoimrithe Indinéisis ar scála mór. Bainimid ailt ó Liputan6.com, tairseach nuachta ar líne, agus faighimid 215,827 péirí doiciméad-achoimre. Déanaimid giaráil ar shamhlacha teanga réamhoilte chun modhanna achomair eastóscacha agus teibí tagarmharcála a fhorbairt thar an tacar sonraí le samhlacha ilteangacha agus aonteangacha bunaithe ar BERT. Áirímid anailís earráide críochnúil trí scrúdú a dhéanamh ar achoimrí meaisínghinte a bhfuil scóir ROUGE íseal acu, agus a nochtar an dá shaincheist le ROUGE féin, chomh maith le samhlacha achoimre eastóscacha agus teibí.', 'ka': 'ამ დოკუნეში ჩვენ ინდონეციური საზოგადოება მონაცემების საზოგადოება ჩვენ ჩვენ გავაჩვენოთ. ჩვენ ლიპუტანის არქილების წყებით.6. Name ჩვენ ვიყენებთ წინ შესწავლობული ენის მოდელები, რომლებიც ბენქმარკური ექსტრაქტიური და აბსტრაქტიური რეზიუმიზაციის მეტოვების განვითარებას მონაცემების მრავალენგური და მონო ჩვენ დავყენებთ ძალიან შეცდომა ანალიზაცია, რომელიც მანქანის შექმნილი საზოგადოებები აქვს ცოტა ROUGE, და რომელიც ორივე პროგრამები თავს ROUGE, და ექსტრაქტიური და აბსტრაქტიური', 'el': 'Σε αυτή την εργασία, εισάγουμε ένα ευρείας κλίμακας σύνολο δεδομένων σύνοψης της Ινδονησίας. Μαζεύουμε αντικείμενα από το Λιπουταν6. και να αποκτήσετε 215,827 ζεύγη εγγράφων-σύνοψης. Χρησιμοποιούμε προ-εκπαιδευμένα γλωσσικά μοντέλα για την ανάπτυξη μεθόδων εξαγωγικής και αφηρημένης σύνοψης συγκριτικής αναφοράς σε όλο το σύνολο δεδομένων με πολυγλωσσικά και μονογλωσσικά μοντέλα βασισμένα στο BERT. Συμπεριλαμβανόμαστε μια εμπεριστατωμένη ανάλυση σφαλμάτων εξετάζοντας περιλήψεις που δημιουργούνται από μηχανές που έχουν χαμηλές βαθμολογίες και εκθέτουμε τόσο τα ζητήματα με το ίδιο το καθώς και με τα εξορυκτικά και αφηρημένα μοντέλα συνοψίας.', 'it': "In questo articolo, presentiamo un set di dati di sintesi indonesiano su larga scala. Raccogliamo articoli da Liputan6. com, un portale di notizie online, e ottenere 215.827 coppie di documenti-sintesi. Sfruttamo modelli linguistici pre-formati per sviluppare metodi di sintesi estrattivi e astratti di riferimento sul set di dati con modelli multilingue e monolingue basati su BERT. Includiamo un'analisi approfondita degli errori esaminando riassunti generati da macchine che hanno bassi punteggi ROUGE e esponiamo entrambi i problemi con ROUGE stesso, così come con modelli di sintesi estrattivi e astratti.", 'kk': 'Бұл қағазда, біз Индонезия үлкен масштабының тұжырымдамасының деректерін келтіреміз. Біз Липутандың мақалаларын жинаймыз.6 com, онлайн жаңалық порталы және 215 827 құжат тұжырымдамасын алу үшін. Біз бірнеше тіл үлгілерін бірнеше тілді және бірнеше тілді BERT негіздеген үлгілер үшін деректер қорларының көп тілді және бірнеше тілді үлгілерін жасау үшін қолданамыз. Біз компьютер құрылған тұжырымдамаларды тексеріп, ROUGE нәтижесінің төменгі мәселелерін және экстрактивті және абстрактивті тұжырымдамаларды тексеріп, тұтас қатенің анализациясы бар.', 'hu': 'Ebben a tanulmányban egy nagyszabású indonéz összefoglaló adatkészletet mutatunk be. Liputánból gyűjtünk cikkeket. Egy online hírportál, amely 215 827 dokumentum-összefoglaló párt szerez. Az előzetesen képzett nyelvi modelleket használjuk, hogy többnyelvű és egynyelvű BERT-alapú modellekkel alakítsuk ki az adatkészleten felüli extraktív és absztraktív összefoglalási módszereket. Alapos hibaelemzést végzünk a gép által generált összefoglalók vizsgálatával, amelyek alacsony ROUGE pontszámmal rendelkeznek, és mindkét problémát magával a ROUGE-val, valamint extraktív és absztraktív összefoglaló modellekkel fedjük fel.', 'lt': 'Šiame dokumente pristatome didelės apimties Indonezijos suvestinių duomenų rinkinį. Mes renkame daiktus iš Liputan6. com, internetinis naujienų portalas ir gauti 215 827 dokumentų santraukos poros. Naudojame iš anksto parengtus kalbų modelius, kad parengtume lyginamuosius ekstraktyvius ir abstraktyvius santraukų metodus duomenų rinkinyje naudojant daugiakalbius ir vienakalbius BERT pagrįstus modelius. Įtraukiame išsamią klaidų analizę išnagrinėjant mašinų sukeltas santraukas, kurių ROUGE rezultatai yra maži, ir aptariame abu klausimus su pačiu ROUGE, taip pat su ekstraktyviais ir abstrakciniais santraukų modeliais.', 'ml': 'ഈ പത്രത്തില്\u200d, നമ്മള്\u200d ഒരു വലിയ സാധാരണ ഇന്തോനേഷ്യയുടെ വിവരങ്ങള്\u200d പരിചയപ്പെടുത്തുന്നു. ലിപുതാന്\u200d 6 ല്\u200d നിന്നും ഞങ്ങള്\u200d ലേഖനങ്ങള്\u200d കൊയ്യുന്നു. ഒരു ഓണ്\u200dലൈന്\u200d വാര്\u200dത്ത പോര്\u200dട്ടല്\u200d, 215,827 രേഖയുടെ ചുരുക്കത്തില്\u200d ജോട്ടികള്\u200d കിട്ടുന്നു. ബെന്\u200dച്മാര്\u200dക്ക് പുറമെ പരിശീലന ഭാഷ മോഡലുകള്\u200dക്ക് മുന്\u200dപ് പരിശീലിക്കപ്പെടുന്നതിനായി നമ്മള്\u200d പ്രാവര്\u200dത്തികമാക്കുന്നു. ബെര്\u200dട്ടിന്\u200dറെ അടി മെഷിന്\u200d നിര്\u200dമ്മിക്കപ്പെട്ട സംഖ്യകള്\u200d പരിശോധിക്കുന്നതിനാല്\u200d നമുക്കൊരു പൂര്\u200dണ്ണമായ തെറ്റുകള്\u200d പരിശോധിക്കുന്നു. റൂജിന്റെ സ്വന്തം പ്രശ്നങ്ങളും പുറത്', 'mk': 'Во овој весник, воведуваме голема индонезиска група податоци за резултати. We harvest articles from Liputan6. com, an online news portal, and obtain 215,827 document-summary pairs.  Ние ги искористуваме предобучените јазички модели за да развиеме методи на екстрактивна и апстрактивна резултативна резултатација во врска со податоците со мултијазични и монојазични модели базирани на БЕРТ. Ние вклучуваме темелна анализа на грешки со испитување на резултати генерирани од машина кои имаат ниски ROUGE резултати, и ги изложуваме двете прашања со самиот ROUGE, како и со екстрактивни и апстрактивни модели на резултати.', 'no': 'I denne papiret introduserer vi ein stor oppsummeringsdataset for Indonesisk. Vi bygger artiklar frå Liputan6. com, en online news portal, and obtain 215,827 document-summary pairs. Vi leverer først trengte språk-modeller for å utvikle benchmarkekstraktiv og abstraktive samanseringsmetoder over datasettet med fleirspråk og monospråk-baserte BERT-modeller. Vi inkluderer ein grunnleggjande feilanalyse ved å undersøke samandrasjonar som har låg ROUGE- poeng, og eksponere begge problemar med ROUGE sjølv, og med ekstraktiv og abstraktive samandrasjonsmodular.', 'mn': 'Энэ цаасан дээр бид Индонезийн жинхэнэ өгөгдлийн санг илтгэнэ. Бид Липутаны6 баримтуудыг агуулдаг. com, онлайн мэдээллийн захирал, 215,827 баримт хураагдах хоёр гарч ирсэн. Бид өмнө сургалтын хэл загваруудыг олон хэл болон ганц хэлний BERT суурилсан загвартай өгөгдлийн суурилуулалтын арга загваруудыг хөгжүүлэх зорилготой. Бид ROUGE оноо бага байдаг машин бүтээгдэхүүний цуглуулалтыг шалгаж, ROUGE-тэй хоёр асуудлыг хоёуланг нэмэгдүүлж, нэмэгдүүлэх, abstractive жинхэнэ загваруудыг тодорхойлдог.', 'pl': 'W niniejszym artykule przedstawiamy duży zestaw danych podsumowujących indonezyjski. Zbieramy artykuły z Liputan6. Komunikacja, portal informacyjny online, i uzyskać 215,827 para dokumentów-podsumowania. Wykorzystujemy wstępnie przeszkolone modele językowe, aby opracować metody ekstrakcyjne i abstrakcyjne podsumowywania w zbiorze danych za pomocą wielojęzycznych i jednojęzycznych modeli opartych na BERT. Zawieramy dokładną analizę błędów, badając podsumowania generowane maszynowo, które mają niskie wyniki ROUGE, i ujawniamy zarówno problemy z samym ROUGE, jak i z ekstrakcyjnymi i abstrakcyjnymi modelami podsumowania.', 'sr': 'U ovom papiru predstavljamo veliku indijsku sažetku podataka. Skupljamo članak iz Liputan6. com, online novinski portal, i dobiti 215.827 sažetnih par dokumenta. Primjeravamo predobučene jezičke modele kako bi razvili ekstraktivne i abstraktivne metode sažetanja benchmarka nad setom podataka sa multijezičkim i monojezičkim modelima na BERT-u. Uključujemo temeljnu analizu greške ispitivajući sažetke proizvedene strojevima koji imaju niske rezultate ROUGE-a, i izložavamo oba problema sa samim ROUGE-om, kao i sa ekstraktivnim i abstraktivnim modelima sažetke.', 'ro': 'În această lucrare, introducem un set de date de sinteză indoneziană la scară largă. Recoltam articole din Liputan6. com, un portal de știri online, și obține 215.827 perechi de documente-rezumat. Utilizăm modele lingvistice pre-instruite pentru a dezvolta metode de sinteză extractive și abstractive de referință peste setul de date cu modele multilingve și monolingve bazate pe BERT. Includem o analiză amănunțită a erorilor prin examinarea rezumatelor generate de mașini care au scoruri reduse de ROUGE și expunem ambele probleme cu ROUGE în sine, precum și cu modele de rezumare extractive și abstractive.', 'si': 'මේ පත්තරේ අපි ලොකු ප්\u200dරමාණයක් ඉන්ඩෝනේසියානු සාමාණික දත්ත සෙට් එකක් පෙනුම් කරනවා. අපි ලිපුටන් 6 වලින් පිළිපත් ගන්නවා. Name අපි ප්\u200dරධානය කරපු භාෂාව මොඩල් කරනවා බෙන්ච්මාර්ක් ප්\u200dරධානය සහ ප්\u200dරධානය සම්ප්\u200dරධානය විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාප අපි පරීක්ෂණය කරන්න පුළුවන් විශ්ලේෂණයක් සම්පූර්ණ විශ්ලේෂණයක් සම්පූර්ණ විශ්ලේෂණය කරනවා පරීක්ෂණය කරලා පරීක්ෂණය කරනවා ROUGE', 'sv': 'I denna uppsats introducerar vi en storskalig indonesisk sammanfattningsdataupps瓣ttning. Vi sk繹rdar artiklar fr疇n Liputan6. com, en nyhetsportal online, och f疇 215 827 dokument-sammanfattningar par. Vi utnyttjar redan utbildade spr疇kmodeller f繹r att utveckla benchmark extraktiva och abstrakta sammanfattningsmetoder 繹ver dataupps瓣ttningen med flerspr疇kiga och enspr疇kiga BERT-baserade modeller. Vi inkluderar en grundlig felanalys genom att unders繹ka maskingenererade sammanfattningar som har l疇ga ROUGE po瓣ng, och exponerar b疇da problemen med ROUGE sj瓣lv, liksom med extraktiva och abstrakta sammanfattningsmodeller.', 'so': 'Warqadan waxan ku soo bandhignaa sawir macluumaad ku qoran Indonesian. Waxaannu ka soo ururinnaa warqadaha Liputan6. com, jardiinada warbixinta ee internetka, waxaad heleysaa 215,827 qof oo xagaaga ah. Waxaynu soo bandhignaa qaabab afka hore oo lagu tababaray si aan u korinno qaababka soo saarista iyo cayilnaanta ah oo lagu qoro macluumaadka oo ku qoran qaabab luuqad kala duduwan iyo muulooyinka BERT. Anaalbaarinta qaladka waxaa ku jira baaritaanka baaritaanka koorsooyinka machine-generay oo ay leeyihiin koorsooyin hoos u ah ROUGE, waxaana muujinaynaa labada dhibaatooyin oo la xiriira ROUGE naftiisa, sidoo kale sameynta qaababka soo saarista iyo waxyaabaha la’aan ah.', 'mt': 'F’dan id-dokument, a ħna nintroduċu sett ta’ dejta ta’ sommarju Indoneżjan fuq skala kbira. Aħna nħasdu oġġetti minn Liputan6. com, portal tal-aħbarijiet onlajn, u jikseb 215 827 par ta’ dokumenti-sommarju. Aħna ninfurzaw mudelli lingwistiċi mħarrġa minn qabel biex niżviluppaw metodi ta’ sinteżi ta’ referenza estrattivi u astrattivi fuq is-sett tad-dejta b’mudelli multilingwi u monolingwi bbażati fuq BERT. Aħna inkludew analiżi bir-reqqa tal-iżbalji billi jeżaminaw sommarji ġġenerati mill-magna li għandhom punteġġi ROUGE baxxi, u jesponu ż-żewġ kwistjonijiet mar-ROUGE innifsu, kif ukoll mal-mudelli ta’ sommarju estrattiv u astrattiv.', 'ur': 'اس کاغذ میں ہم ایک بڑی اسکیل اندونزی ڈیٹ سٹ کو معرفی کرتے ہیں۔ ہم لیپوٹن سے لکھ لیتے ہیں 6. کم، ایک اولنٹ نیویٹ پورٹ، اور 215,827 دفتر-جمع جوڑے حاصل کریں۔ ہم پہلے تدریس کی زبان نمڈلوں کو بتانے کے لئے بینچم مارک اخلاقی اور اخلاقی ذخیره طریقے بنانے کے لئے بہت سی زبان اور ایک زبان کی BERT-based نمڈلوں کے ذریعے ڈاٹ سٹ پر استعمال کرتے ہیں. ہم نے ماشین کے پیدا کئے ہوئے مثالیں کی تحقیق کے ذریعہ ایک عمدہ خطا تحلیل میں شامل کر رکھا ہے جو کم روGE اسکور رکھتے ہیں اور روGE کے ساتھ دونوں مسائل کو کھول دیتے ہیں اور اضافہ اور اضافہ مثالیں کے ذریعہ سے بھی۔', 'ta': 'இந்த காகிதத்தில், நாம் ஒரு பெரிய அளவு இந்தோனேசிய சுருக்க தகவல் அமைப்பை அறிவிக்கிறோம். நாங்கள் லிபுதான் 6 லிருந்து கட்டுரைகளை கொடுக்க. ஒரு இணைய செய்தி முனையம், மற்றும் 215,827 ஆவண சுருக்கம் ஜோடி பெறுகிறது. நாங்கள் முன் பயிற்சி மொழி மாதிரிகளை வெளியேற்ற மற்றும் செயல்படுத்தும் மற்றும் செயல்படுத்தும் சுருக்க முறைமைகளை உருவாக்குவதற்கான முன் இயந்திரம் உருவாக்கப்பட்ட சுருக்கங்களை பரிசோதிக்கும் மூலம் நாம் ஒரு முழு பிழை ஆய்வு சேர்ப்பை சேர்க்கவும் சேர்க்கவும், மற்றும் ROUGE தன்னையே இரு பிரச்', 'ms': 'In this paper, we introduce a large-scale Indonesian summarization dataset.  We harvest articles from Liputan6. com, portal berita online, dan mendapatkan 215,827 pasangan ringkasan dokumen. Kami menggunakan model bahasa yang dilatih-dilatih untuk mengembangkan kaedah penghasilan ekstraktif dan abstraktif tanda referensi melalui set data dengan model berasaskan BERT berbilang bahasa dan monobahasa. Kami termasuk analisis ralat yang teliti dengan memeriksa ringkasan yang dijana oleh mesin yang mempunyai skor ROUGE rendah, dan mengekspos kedua-dua isu dengan ROUGE sendiri, serta dengan model ringkasan ekstraktif dan abstraktif.', 'uz': "Bu qogʻozda, biz Indoneziyaga katta tajriba maʼlumot tarkibini anglatamiz. Biz Liputan6dan maqolalarni ishlaymiz. Name We leverage pre-trained language models to develop benchmark extractive and abstractive summarization methods over the dataset with multilingual and monolingual BERT-based models.  Biz kompyuterning qiymatlarini qidirish uchun juda katta xato analyzeri mavjud. Bu ikkita muammolarni ROUGE'ning o'zi bilan ko'rsatish va kichkina muhit modellari bilan ajratish mumkin.", 'vi': 'Trong tờ báo này, chúng ta sẽ giới thiệu một tập tin đầy đủ của Indonesia. Chúng tôi thu hoạch đồ từ Liphutan6. com, một cánh cổng tin tức trực tuyến, và đoạt cặp tài liệu đầy đủ 95,87. Chúng tôi sử dụng các mô hình ngôn ngữ được đào tạo trước để phát triển các phương pháp tổng quát thu thập tiêu chuẩn trên bộ dữ liệu với các mô- đun trường thiếu ngôn ngữ và ngôn ngữ. Chúng tôi bao gồm cả một phân tích lỗi kỹ lưỡng bằng cách kiểm tra các bản tóm tắt máy tạo ra mà có điểm thấp của ROCE, và phơi bày cả hai vấn đề với bản thân ROCE, cũng như với các mô hình thu nhỏ và trích dẫn.', 'bg': 'В тази статия представяме мащабен индонезийски обобщаващ набор от данни. Събираме артикули от Липутан6. Ком, онлайн новинарски портал, и да получите 215 827 двойки документи-резюме. Ние използваме предварително обучени езикови модели, за да разработим референтни методи за извличане и абстрактно обобщаване върху набора от данни с многоезични и едноезични модели базирани на БРТ. Ние включваме задълбочен анализ на грешките чрез изследване на машинно генерирани резюмета, които имат ниски оценки и излагаме както проблемите със самия Роуг, така и с екстрактивни и абстрактни модели за обобщаване.', 'nl': 'In dit artikel introduceren we een grootschalige Indonesische samenvattingsdataset. We oogsten artikelen uit Liputan6. Kom, een online nieuwsportaal, en verkrijg 215.827 document-summary paren. We maken gebruik van vooraf getrainde taalmodellen om benchmark extractieve en abstracte samenvattingsmethoden over de dataset te ontwikkelen met meertalige en eentalige BERT-gebaseerde modellen. We omvatten een grondige foutanalyse door machinegegenereerde samenvattingen te onderzoeken die lage ROUGE scores hebben, en brengen zowel problemen met ROUGE zelf als met extractieve en abstractieve samenvattingsmodellen bloot.', 'da': 'I denne artikel introducerer vi et omfattende indonesisk sammenfattende datasæt. Vi høster artikler fra Liputan6. com, en online nyhedsportal, og få 215.827 dokument-resumépar. Vi udnytter prætrænede sprogmodeller til at udvikle benchmark ekstraktive og abstraktive sammenfatningsmetoder over datasættet med flersprogede og ensprogede BERT-baserede modeller. Vi inkluderer en grundig fejlanalyse ved at undersøge maskingenererede resuméer, der har lave ROUGE scores, og afsløre begge problemer med ROUGE selv, såvel som med ekstraktive og abstraktive resumémodeller.', 'de': 'In diesem Beitrag stellen wir einen großen indonesischen Zusammenfassungsdatensatz vor. Wir ernten Artikel aus Liputan6. Sie erhalten 215.827 Dokument-Zusammenfassung Paare. Wir nutzen vortrainierte Sprachmodelle, um benchmarkextraktive und abstraktive Zusammenfassungsmethoden über den Datensatz mit mehrsprachigen und einsprachigen BERT-basierten Modellen zu entwickeln. Wir schließen eine gründliche Fehleranalyse ein, indem wir maschinell generierte Zusammenfassungen mit niedrigen ROUGE-Scores untersuchen und sowohl Probleme mit ROUGE selbst als auch mit extraktiven und abstraktiven Zusammenfassungsmodellen aufdecken.', 'ko': '본고는 대형 인도네시아 요약 데이터 집합을 소개했다.우리는 Liputan6에서 글을 수집한다.그리고 215827개의 문서 요약 쌍을 얻었다.우리는 미리 훈련된 언어 모델을 이용하여 다중 언어와 단어를 바탕으로 하는 BERT 모델의 데이터 집합에서 기준 추출과 추상적 요약 방법을 개발한다.우리는 기계가 생성한 비교적 낮은 ROUGE 점수를 가진 요약을 검사함으로써 철저한 오류 분석을 하고 ROUGE 자체와 추출과 추상적인 요약 모델의 두 가지 문제를 제시한다.', 'hr': 'U ovom papiru predstavljamo veliku skupinu podataka o sažetku Indonezije. Skupljamo članak iz Liputan6. com, online vijesti portal, i dobiti 215.827 sažetnih par dokumenta. Primjenjujemo predobučene jezičke modele kako bi razvili metode ekstraktivne i abstraktivne sažetke kriterije nad setom podataka s multijezičkim i monojezičkim modelima na BERT-u. Uključujemo temeljnu analizu greške ispitivajući sažetke proizvedene strojevima koji imaju niske rezultate ROUGE-a i izložavajući obje probleme sa samim ROUGE-om, kao i sa ekstraktivnim i abstraktivnim modelima sažetke.', 'tr': 'Bu kagyzda, Indoneziýanyň uly düzümlenme maglumatlaryny tanyşdyrýarys Biz Liputan6 makalasyny hasaplýarys. com, an online news portal, and get 215,827 document-summary pairs. Biz öňünden eğitilen dil nusgalaryny benchmark ekstraktiv we abstraktiv toparlama yöntemlerini multidil we monodil BERT tabanly modelleri bilen geliştirmek üçin süýtgedýäris ROUGE अंदर düşük we ROUGE bilen iki meseleni hem ekstraktif we abstraktiv toparlama modelleri barlap derin hata analýusiny bar.', 'sw': 'Katika karatasi hii, tunaonyesha seti kubwa ya taarifa za muhtasari wa Indonesia. Tunachoma makala kutoka Liputan6. com, kituo cha habari cha mtandaoni, na kupata dola za nyaraka 215,827. Tunaweza kutumia mifano ya lugha iliyoendeshwa kabla ya kuendeleza njia za ufumbuzi wa bendera na kutoa taarifa za upatikanaji na mifano yenye lugha mbalimbali na moja kwa moja ya lugha ya BERT. Tunajumuisha uchambuzi wa makosa makubwa kwa kuchunguza muhtasari wa kompyuta uliotengenezwa na mashine yenye vipimo vya chini vya ROUGE, na kuonyesha masuala yote yanayohusiana na ROUGE wenyewe, pamoja na mifano ya muhtasari wa kutolewa na kutolewa.', 'id': 'Dalam kertas ini, kami memperkenalkan sebuah set data ringkasan Indonesia. Kami mengambil artikel dari Liputan6. com, portal berita online, dan mendapatkan 215.827 pasangan dokumen-ringkasan. Kami memanfaatkan model bahasa yang dilatih-dilatih untuk mengembangkan metode ekstraksi benchmark dan abstraktif perhitungan melalui set data dengan model berbagai bahasa dan berdasarkan BERT monobahasa. Kami termasuk analisis kesalahan yang teliti dengan memeriksa ringkasan yang dibuat oleh mesin yang memiliki skor ROUGE rendah, dan mengekspos kedua isu dengan ROUGE sendiri, serta dengan model ekstraktif dan abstraktif ringkasan.', 'af': "In hierdie papier, introduseer ons 'n groot-skaal Indonesiese opsomming dataset. Ons maak artikels uit Liputan6. â\x80\x99n online nuusportaal, en kry 215,827 dokument-opsomming paar. Ons verwyder voor-opgelei taal modele om benchmark ekstraktiewe en abstraktiewe opsomming metodes te ontwikkel oor die datastel met multitaal en monotaal BERT-gebaseerde modele. Ons insluit 'n groot fout analiseer deur masjien genereerde opsommings te ondersoek wat lae ROUGE aantal het, en beide probleem met ROUGE self uitgevoer en met ekstraktiewe en abstraktiewe opsommingsmodele.", 'fa': 'در این کاغذ، ما یک مجموعه اطلاعات جمع اندونزی بزرگ را معرفی می کنیم. ما مقاله های لیپوتان 6 را میگیریم. com، یک دروازه اخبار آنلاین، و جفت جمع سند 215,827 را دریافت کنید. ما مدل های پیش آموزش زبانی را برای توسعه کردن روش\u200cهای جمع\u200cآوری استثناء و استثناء صفحه\u200cای بر روی مجموعه\u200cهای داده\u200cها با مدل\u200cهای متعدد زبان و متعدد زبان BERT استثناء می\u200cکنیم. ما توسط تحقیق جمع\u200cآوری\u200cهای تولید شده از دستگاه\u200cها را تحقیق می\u200cکنیم که نمونه\u200cهای ROUGE کم دارند، و هر دو مشکل را با خودش ROUGE نشان می\u200cدهیم، و همچنین با مدل\u200cهای جمع\u200cآوری خارجی و بی\u200cاثر نشان می\u200cدهیم.', 'sq': 'Në këtë letër, ne paraqesim një sërë të dhënash në shkallë të madhe të përmbledhjes indoneziane. Ne mbledhim artikuj nga Liputan6. com, një portal lajmesh online, dhe të marrë 215,827 çifte dokumenti-përmbledhje. Ne përdorim modele gjuhësh të stërvitura para-të për të zhvilluar metodat e përmbledhjes së paraqitjeve ekstraktive dhe abstraktive mbi grupin e të dhënave me modele shumëgjuhëse dhe monogjuhëse bazuar në BERT. We include a thorough error analysis by examining machine-generated summaries that have low ROUGE scores, and expose both issues with ROUGE itself, as well as with extractive and abstractive summarization models.', 'bn': 'এই কাগজটিতে আমরা একটি বিশাল সংক্ষেপ ইন্দোনেশিয়ার সংক্ষেপের ডাটাসেট পরিচয় করিয়ে দেই। আমরা লিপুটান ৬ থেকে প্রবন্ধ কাজ করি। কম, একটি অনলাইন সংবাদ পোর্টাল এবং ২১৫,৮২৭ নথি সংক্ষেপের জোড়া পেয়েছে। আমরা পূর্ব প্রশিক্ষিত ভাষার মডেল লেভ করি বেনকম্যাক্টর্ক নির্বাচন এবং আত্মসংক্রান্ত সংক্রান্ত সংক্রান্ত পদ্ধতি উন্নয়নের জন্য যা বহুভাষা  মেশিন উৎপাদনিত সংক্ষেপ পরীক্ষা করার মাধ্যমে আমরা গুরুত্বপূর্ণ ভুল বিশ্লেষণ অন্তর্ভুক্ত রয়েছি, যার মধ্যে রয়েছে কম রুজের সংক্ষেপ এবং রুজের নিজের সাথে উভয় ব', 'hy': 'In this paper, we introduce a large-scale Indonesian summarization dataset.  Մենք հոդվածներ ենք հավաքում Լիպուտանից 6: համակարգ, ինտերնետ նորությունների պորտալ, և ստանալ 215,817 փաստաթղթի-համառոտագրական զույգ: Մենք օգտագործում ենք նախապատրաստված լեզվի մոդելներ, որպեսզի զարգացնենք համեմատական արտադրողական և վերացրատիվ համառոտագրական մեթոդներ տվյալների համակարգում բազլեզվով և միալեզվով BER-ի հիմնված մոդելներով: Մենք ներառում ենք հիմնական սխալների վերլուծություն, ուսումնասիրելով մեքենայի կողմից ստեղծված համառոտագրությունները, որոնք ունեն ցածր ROUGe-ի գնահատականներ, և բացահայտում ենք երկու խնդիրները ROUGe-ի հետ, ինչպես նաև վերացական և վերացրատիվ համառոտագրական մոդե', 'am': 'በዚህ ካላት ትልቁ የኢንዶኒያዊ አዋራጅ ዳታዎችን እናሳውቃለን፡፡ ከሊputan6 ጽሑፎችን እናጭራለን። com፣ የኢንተርኔት ዜና ፖርቲካ፣ 215,827 ሰነድ አሁኑን አግኝቷል፡፡ በብዙ ቋንቋ እና ብሬተር ምሳሌዎችን ለመፍጠር በፊት ተማሪ የቋንቋ ሞዴላዎችን አቀናልለን፡፡ We include a thorough error analysis by examining machine-generated summaries that have low ROUGE scores, and expose both issues with ROUGE itself, as well as with extractive and abstractive summarization models.', 'ca': "In this paper, we introduce a large-scale Indonesian summarization dataset.  Recollem articles de Liputan6. com, un portal de notícies en línia, i obtenir 215.827 parells de resum de documents. Utilitzem models de llenguatge pré-entrenats per desenvolupar mètodes de resume extractiu i abstractiu en el conjunt de dades amb models multilingües i monolingües basats en BERT. Inclouem una anàlisi detallada d'errors examinant resumes generats per màquina que tenen baixos puntuacions ROUGE, i exposem ambdós problemes amb ROUGE mateix, com amb models de resume extractiu i abstract.", 'bs': 'U ovom papiru predstavljamo veliku Indonezijsku rezimentaciju podataka. Skupljamo članak iz Liputan6. com, online novinski portal, i dobiti 215,827 sažetnih par dokumenta. Primjeravamo predobučene jezičke modele kako bi razvili metode ekstraktivne i abstraktivne sažetke kritike nad setom podataka sa multijezičkim i monojezičkim modelima na BERT-u. Uključujemo temeljnu analizu greške ispitivajući sažetke proizvedene strojevima koji imaju niske rezultate ROUGE-a, i izložavamo obje probleme sa samim ROUGE-om, kao i sa ekstraktivnim i abstraktivnim modelima sažetke.', 'cs': 'V tomto článku představujeme rozsáhlý indonéský soubor souhrnných dat. Sklízíme zboží z Lipútánu.6 com, on-line zpravodajský portál, a získejte 215,827 dokument-souhrn páry. Využíváme předškolené jazykové modely k vývoji benchmarkových extrakčních a abstraktivních metod shrnutí v datové sadě s vícejazyčnými a monojazyčnými modely založenými na BERT. Zahrnujeme důkladnou analýzu chyb zkoumáním strojově generovaných souhrnů, které mají nízké ROUGE skóre, a odhalujeme oba problémy s ROUGE samotným, stejně jako s extraktivními a abstraktivními souhrnnými modely.', 'et': 'Käesolevas dokumendis tutvustame ulatuslikku Indoneesia kokkuvõtte andmekogumit. Korjame Liputanist tooteid.6 com, online uudisteportaal, ja saada 215 827 dokumendi-kokkuvõtte paari. Me kasutame eelnevalt koolitatud keelemudeleid, et töötada välja võrdlusalused ekstraktiivsed ja abstraktsed kokkuvõtlusmeetodid mitmekeelsete ja ühekeelsete BERT-põhiste mudelite abil. Lisame põhjaliku veaanalüüsi, uurides masinagenereeritud kokkuvõtteid, millel on madal ROUGE skoor, ning paljastame nii ROUGE enda kui ka ekstraktivsete ja abstraktsete kokkuvõtete mudelite probleemid.', 'fi': 'Tässä artikkelissa esittelemme laajamittaisen Indonesian yhteenvetoaineiston. Keräämme Liputanista artikkeleita.6 com, online-uutisportaali, ja saada 215 827 asiakirja-tiivistelmä paria. Hyödynnämme ennalta koulutettuja kielimalleja kehittääksemme vertailukelpoisia ekstraktiivisia ja abstraktiivisia yhteenvetomenetelmiä aineiston yli monikielisten ja yksikielisten BERT-mallien avulla. Sisällytämme perusteellisen virheanalyysin tutkimalla konepohjaisia yhteenvetoja, joilla on alhaiset ROUGE-pisteet, ja paljastamme sekä itse ROUGE-ongelmia että ekstraktiivisia ja abstraktiivisia yhteenvetomalleja.', 'az': "Bu kağızda böyük ölçüdə Indoneziya toplama verilənləri tanıdırıq. Biz Liputan6'dan məktubları yığırıq. com, online news portal, və 215,827 document-summary pairs alır. Biz, çoxlu dil və monodil BERT tabanlı modelləri ilə verilən verilənlər üçün benchmark ekstraktiv və abstraktiv toplama metodlarını təhsil etdik. Bizim maşın yaratdığı qeyri-cərgələri yoxlayaraq tamamilə xəta analizi daxil edirik ki, ROUGE ilə hər ikisini də a şkar və abstraktiv qeyri-cərgələr modelləri ilə açılır.", 'ha': "In this paper, we introduce a large-scale Indonesian summarization dataset.  Munã samun makala daga Liputan6. com, an samu wata hoton news, kuma ka samu 215,827 takardar-ƙarshen. Tuna samar da misãlai na zaman-haƙƙin harshen zuwa a buɗe hanyoyin bonkimar ta haramtar da kuma ta kandamta masu tsari a kan dataset da misãlai masu multi-lingui da sauri'in BERT. Mu ƙunsa da rabon ɓata mai cikakken bayani game da jarraba ƙarami wanda aka ƙididdige na mashine da suka samu masu nau'i masu rauni na RUGE, kuma Mu sami duk masu saka da RuUGE kanana, da sami da misãlai masu buɗe da kuma masu kanana da kurarin.", 'sk': 'V tem prispevku predstavljamo obsežen indonezijski nabor podatkov o povzetku. Zbiramo izdelke iz Liputan6. com, spletni novičarski portal, in pridobite 215.827 parov dokumentov-povzetkov. Izkoriščamo vnaprej usposobljene jezikovne modele za razvoj referenčnih metod ekstraktivnega in abstraktivnega povzetka prek nabora podatkov z večjezičnimi in enojezičnimi modeli BERT. Vključimo temeljito analizo napak s pregledom strojno generiranih povzetkov, ki imajo nizke ROUGE ocene, in razkrivamo obe problemi z ROUGE samim, kot tudi z ekstraktivnimi in abstraktivnimi modeli povzetka.', 'jv': 'Nang pemilih iki, kita sembah akeh sistem dadi nyong padah-takas Awak dhéwé ngewat barang Liputan6. com, online media website, og rampunga 2,587 dokumen-sumpunga Awak dhéwé ngéwé mulasar-cara-cara Language model kanggo nggawe bench-cara extract lan absolute sumulasi nggawe dataset karo multi-language lan Monlanguage BERT-basa model. Awak dhéwé éntukno karo perusahaan dumadhi sing beraksi dadi nggawe barang kelas', 'he': 'In this paper, we introduce a large-scale Indonesian summarization dataset.  אנחנו קוצרים מאמרים מליפוטאן 6. קום, שער חדשות באינטרנט, ולקבל 215,827 זוגות מסמכים-סכם. אנו משתמשים בדוגמנים לשפה מאומנים מראש כדי לפתח שיטות צילום צילומי ומאסטרקטיביים במערכת המידע עם דוגמנים מבוססים על BERT רבות ושפתיים. אנחנו כוללים ניתוח שגיאות יסודי על ידי לבדוק סדרות יוצרות מכונות שיש להם נקודות ROUGE נמוכות, ולחשוף את שני הבעיות עם ROUGE עצמו, כמו גם עם מודלים של סדרות אסטרקטיביות ומוציאות.', 'bo': 'འོག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་རྒྱ་ནག་གི་ཆོས་ཉིད་དུས་རབས་ཆེན་སྒྲིག་ཆ་འཕྲིན་ཡིག ང་ཚོས་Liputan6 ཡི་བརྗོད་ཐོག་འབྲི་རྩིས་ཐོག་གི་ཡིག་གཟུགས་དང་། com, an online news portal, and get 215,827 document-summary pairs. We leverage pre-trained language models to develop benchmark extractive and abstractive summarization methods over the dataset with multilingual and monolingual BERT-based models. We include a thorough error analysis by examining machine-generated summaries that have low ROUGE scores, and expose both issues with ROUGE itself, as well as with extractive and abstractive summarization models.'}
{'en': 'Generating Sports News from Live Commentary : A Chinese Dataset for Sports Game Summarization C hinese Dataset for Sports Game Summarization', 'ar': 'توليد أخبار رياضية من التعليق المباشر: مجموعة بيانات صينية لتلخيص الألعاب الرياضية', 'fr': 'Générer des actualités sportives à partir de commentaires en direct\xa0: un ensemble de données chinois pour la synthèse des jeux sportifs', 'es': 'Generar noticias deportivas a partir de comentarios en vivo: un conjunto de datos chino para el resumen de juegos deportivos', 'pt': 'Gerando notícias esportivas a partir de comentários ao vivo: um conjunto de dados chinês para resumo de jogos esportivos', 'ja': 'ライブ解説からスポーツニュースを生み出す：スポーツゲームの要約のための中国のデータセット', 'zh': '因今论成体育新闻:用体育比赛摘要中文数据集', 'hi': 'लाइव कमेंट्री से खेल समाचार उत्पन्न करना: खेल खेल सारांशके लिए एक चीनी डेटासेट', 'ru': 'Создание спортивных новостей из живого комментария: китайский набор данных для суммирования спортивных игр', 'ga': 'Nuacht Spóirt a Ghiniúint ó Tráchtaireacht Bheo: Tacar Sonraí Síneach le haghaidh Achoimre ar Chluiche Spóirt', 'el': 'Δημιουργία αθλητικών ειδήσεων από ζωντανά σχόλια: Ένα κινεζικό σύνολο δεδομένων για την περίληψη αθλητικών παιχνιδιών', 'ka': 'Name', 'hu': 'Sporthírek generálása élő kommentárból: Kínai adatkészlet a sportjátékok összefoglalásához', 'it': 'Generare notizie sportive dal vivo Commento: Un dataset cinese per la sintesi dei giochi sportivi', 'kk': 'Name', 'lt': 'Sportinių naujienų kūrimas iš tiesioginių komentarų: Kinijos sporto žaidimų duomenų rinkinys', 'mk': 'Генерирање на спортски вести од жив коментар: Кинески податок за резултат на спортската игра', 'ms': 'Menjana Berita Isport dari Komentar Langsung: Satu Set Data Cina untuk Penapisan Permainan Isport', 'mt': 'Generating Sports News from Live Commentary: A Chinese Dataset for Sports Game Summarization', 'mn': 'Sports News from Live Commentary: A Chinese Dataset for Sports Game Summary', 'ml': 'ലൈവ് കമെന്ററിയില്\u200d നിന്നുള്ള സ്പോര്\u200dട്ട് വാര്\u200dത്തകള്\u200d സൃഷ്ടിക്കുന്നുName', 'no': 'Name', 'pl': 'Generowanie wiadomości sportowych z komentarza na żywo: chiński zestaw danych podsumowujący gry sportowe', 'sr': 'Napravljanje sportskih vesti iz live komentara: Kineski podaci za sažetak sportskih igra', 'ro': 'Generarea de știri sportive din comentariu live: Un set de date chinezesc pentru rezumarea jocurilor sportive', 'si': 'Name', 'so': 'Generation News of Sports from Live Commentary: A Dataset for Jimicsiga', 'sv': 'Generera sportnyheter från Live Kommentarer: En kinesisk dataset för sportspel summering', 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': 'Truyền tin thể thao từ Ghi chép trực tiếp: Bộ dữ liệu Trung Quốc cho giải thể thao.', 'bg': 'Генериране на спортни новини от коментар на живо: Китайски набор от данни за обобщаване на спортни игри', 'nl': 'Sportnieuws genereren vanuit live commentaar: een Chinese dataset voor samenvatting van sportspellen', 'hr': 'Generiranje sportskih vijesti iz live komentara: Kineski podaci za sažetak sportskih igra', 'da': 'Generere sportsnyheder fra Live Kommentarer: Et kinesisk datasæt til sportsspil summering', 'de': 'Generierung von Sportnachrichten aus Live-Kommentaren: Ein chinesischer Datensatz zur Zusammenfassung von Sportspielen', 'id': 'Menjana berita olahraga dari Komentar langsung: Sebuah Set Data Cina untuk Penapisan Permainan olahraga', 'ko': '현장 평론에서 스포츠 뉴스 생성: 스포츠 경기 요약에 사용되는 중국어 데이터 집합', 'sw': 'Kutengeneza Habari za Sports from Live Comments: Taarifa za Kichina kwa ajili ya Makusanyiko ya michezo', 'fa': 'ایجاد اخبار ورزشی از توضیح زنده: یک داده\u200cهای چینی برای جمع\u200cآوری بازی ورزشی', 'af': 'Name', 'tr': 'Duruz terjime eden Sport Haýtalary döredilýär: A Chinese Dataset for Sports Game Summarization', 'sq': 'Gjenerimi i Lajmeve Sportive nga Komentari Live: Një bazë të dhënash kineze për përmbledhjen e Lojës Sportive', 'am': 'አዲስ ዶሴ ፍጠር', 'az': "Canlı Komentar'dan Sports Haqqaları Olur: A Chinese Dataset for Sports Game Summarization", 'hy': 'Generating Sports News from Live Commentary: A Chinese Dataset for Sports Game Summarization', 'ca': 'Generating Sports News from Live Commentary: A Chinese Dataset for Sports Game Summarization', 'bn': 'লাইভ কমেন্টারি থেকে স্পোর্ট সংবাদ তৈরি করা হচ্ছে: খেলার সামার্মিজেশনের জন্য চীনা ডাটাসেট', 'bs': 'Generiranje sportskih vijesti iz live komentara: Kineski podaci za sažetak sportskih igra', 'cs': 'Generování sportovních zpráv z živého komentáře: Čínská data pro shrnutí sportovních her', 'et': 'Spordiuudiste genereerimine live kommentaarist: Hiina andmekogum spordimängude kokkuvõtmiseks', 'fi': 'Luodaan urheiluuutisia live-kommentista: Kiinalainen datajoukko urheilupelien yhteenvetoa varten', 'sk': 'Ustvarjanje športnih novic iz komentarja v živo: Kitajski nabor podatkov za povzetek športnih iger', 'jv': 'Gjer-Ngerawat Minggos Jabun Mulai Komentar: A Chinese data asat kanggo Kemerdekaan Minggos', 'ha': 'KCharselect unicode block name', 'he': 'Generating Sports News from Live Commentary: A Chinese Dataset for Sports Game Summarization', 'bo': 'གསར་བསྐྲུན་འབད་བའི་དབྱིབས་སྡུད་བརྡ་ཞིག་ལ་བསྐྱེད་བཞིན་ཡོད། རྒྱ་ནག་གི་གནས་སྡུད་གཞི་ཚོགས་སྡུད'}
{'en': 'Sports game summarization focuses on generating news articles from  live commentaries . Unlike traditional summarization tasks, the source documents and the target summaries for sports game summarization tasks are written in quite different writing styles. In addition, live commentaries usually contain many  named entities , which makes summarizing sports games precisely very challenging. To deeply study this task, we present SportsSum, a Chinese sports game summarization dataset which contains 5,428 soccer games of live commentaries and the corresponding  news articles . Additionally, we propose a two-step summarization model consisting of a selector and a rewriter for SportsSum. To evaluate the correctness of generated sports summaries, we design two novel score metrics : name matching score and event matching score. Experimental results show that our  model  performs better than other summarization baselines on ROUGE scores as well as the two designed scores.', 'pt': 'A sumarização de jogos esportivos se concentra na geração de artigos de notícias a partir de comentários ao vivo. Ao contrário das tarefas de sumarização tradicionais, os documentos de origem e os resumos de destino para tarefas de sumarização de jogos esportivos são escritos em estilos de escrita bastante diferentes. Além disso, os comentários ao vivo geralmente contêm muitas entidades nomeadas, o que torna o resumo de jogos esportivos muito desafiador. Para estudar profundamente essa tarefa, apresentamos o SportsSum, um conjunto de dados de resumo de jogos esportivos chineses que contém 5.428 jogos de futebol de comentários ao vivo e as notícias correspondentes. Além disso, propomos um modelo de sumarização em duas etapas que consiste em um seletor e um reescritor para SportsSum. Para avaliar a exatidão dos resumos esportivos gerados, projetamos duas novas métricas de pontuação: pontuação de correspondência de nomes e pontuação de correspondência de eventos. Os resultados experimentais mostram que nosso modelo tem um desempenho melhor do que outras linhas de base de sumarização nas pontuações do ROUGE, bem como nas duas pontuações projetadas.', 'ar': 'يركز تلخيص الألعاب الرياضية على إنشاء مقالات إخبارية من التعليقات الحية. بخلاف مهام التلخيص التقليدية ، تتم كتابة المستندات المصدر والملخصات المستهدفة لمهام تلخيص الألعاب الرياضية بأساليب كتابة مختلفة تمامًا. بالإضافة إلى ذلك ، تحتوي التعليقات المباشرة عادةً على العديد من الكيانات المسماة ، مما يجعل تلخيص الألعاب الرياضية تحديًا شديد الصعوبة. لدراسة هذه المهمة بعمق ، نقدم SportsSum ، وهي مجموعة بيانات لتلخيص الألعاب الرياضية الصينية تحتوي على 5428 لعبة كرة قدم من التعليقات الحية والمقالات الإخبارية المقابلة. بالإضافة إلى ذلك ، نقترح نموذج تلخيص من خطوتين يتكون من محدد ومعيد كتابة لـ SportsSum. لتقييم صحة الملخصات الرياضية التي تم إنشاؤها ، قمنا بتصميم مقياسين مبتدئين للنتائج: نتيجة مطابقة الاسم ودرجة مطابقة الحدث. تظهر النتائج التجريبية أن نموذجنا يؤدي أداءً أفضل من خطوط أساس التلخيص الأخرى على درجات ROUGE بالإضافة إلى الدرجتين المصممتين.', 'es': 'El resumen de juegos deportivos se centra en generar artículos de noticias a partir de comentarios en vivo. A diferencia de las tareas de resumen tradicionales, los documentos fuente y los resúmenes de destino para las tareas de resumen de juegos deportivos se escriben con estilos de escritura bastante diferentes. Además, los comentarios en vivo suelen contener muchas entidades nombradas, lo que hace que resumir los juegos deportivos sea muy difícil. Para estudiar en profundidad esta tarea, presentamos SportsSum, un conjunto de datos de resumen de juegos deportivos chinos que contiene 5.428 partidos de fútbol con comentarios en vivo y los artículos de noticias correspondientes. Además, proponemos un modelo de resumen de dos pasos que consiste en un selector y un regrabador para SportsSum. Para evaluar la exactitud de los resúmenes deportivos generados, diseñamos dos métricas de puntuación novedosas: la puntuación de coincidencia de nombres y la puntuación de coincidencia de eventos. Los resultados experimentales muestran que nuestro modelo funciona mejor que otras líneas de base de resumen en las puntuaciones ROUGE, así como las dos puntuaciones diseñadas.', 'fr': "La synthèse des jeux sportifs se concentre sur la génération d'articles d'actualité à partir de commentaires en direct. Contrairement aux tâches de synthèse traditionnelles, les documents source et les résumés cibles pour les tâches de résumé de jeux sportifs sont écrits dans des styles d'écriture très différents. De plus, les commentaires en direct contiennent généralement de nombreuses entités nommées, ce qui rend la synthèse des jeux sportifs très difficile. Pour étudier en profondeur cette tâche, nous présentons SportsSum, un ensemble de données résumant les jeux de sport chinois qui contient 5 428 matchs de football avec des commentaires en direct et les articles de presse correspondants. De plus, nous proposons un modèle de synthèse en deux étapes composé d'un sélecteur et d'une réécriture pour SportsSum. Pour évaluer l'exactitude des résumés sportifs générés, nous concevons deux nouvelles mesures de score\xa0: le score de correspondance de nom et le score de correspondance d'événement. Les résultats expérimentaux montrent que notre modèle fonctionne mieux que les autres bases de synthèse sur les scores ROUGE ainsi que les deux scores conçus.", 'zh': '体育戏摘要侧重于于今论成新闻文。 与古异务,体育比赛总其源文档与向摘要以殊体为之。 此外,今论常含名实体,使总结体育比赛甚有挑战性。 深究斯务,介于SportsSum,此中国体育比赛摘要数集,其中包5,428场足球比赛论相应新闻文也。 二步而结模,SportsSum选择器重写器而成。 为评体育摘要之正确性,设二新之分指标:名配分数,事配分数。 实验结果表明,ROUGE分及两计之分,优于总基线。', 'ja': 'スポーツゲームのまとめは、実況解説からニュース記事を生み出すことに主眼が置かれている。従来の要約タスクとは異なり、スポーツゲームの要約タスクのソースドキュメントとターゲット要約は、かなり異なる書き方で書かれています。さらに、ライブ解説には通常、名前のあるエンティティが多く含まれているため、スポーツの試合をまとめることは非常に困難です。この課題を深く研究するために、ライブ解説と対応するニュース記事のサッカーゲームを5,428本収録した中国のスポーツゲームの要約データセットであるSportsSumをご紹介します。さらに、SportsSumのセレクタとリライタからなる2段階の要約モデルを提案します。生成されたスポーツサマリーの正確性を評価するために、名前マッチングスコアとイベントマッチングスコアの2つの新しいスコア指標を設計します。実験結果は、当社のモデルが、ROUGEスコアと2つの設計されたスコアの他の要約ベースラインよりも優れたパフォーマンスを発揮することを示しています。', 'hi': 'खेल खेल summarization लाइव टिप्पणियों से समाचार लेख उत्पन्न करने पर केंद्रित है. पारंपरिक सारांशीकरण कार्यों के विपरीत, स्रोत दस्तावेज़ और खेल खेल सारांशीकरण कार्यों के लिए लक्ष्य सारांश काफी अलग लेखन शैलियों में लिखे गए हैं। इसके अलावा, लाइव टिप्पणियों में आमतौर पर कई नामित संस्थाएं होती हैं, जो खेल के खेल को सारांशित करती हैं, जो खेल को बहुत चुनौतीपूर्ण बनाती हैं। इस कार्य का गहराई से अध्ययन करने के लिए, हम SportsSum, एक चीनी खेल खेल सारांश डेटासेट प्रस्तुत करते हैं जिसमें लाइव टिप्पणियों के 5,428 फुटबॉल गेम और संबंधित समाचार लेख शामिल हैं। इसके अतिरिक्त, हम एक दो-चरणीय सारांश मॉडल का प्रस्ताव करते हैं जिसमें एक चयनकर्ता और स्पोर्ट्ससम के लिए एक रीराइटर शामिल है। उत्पन्न खेल सारांश की शुद्धता का मूल्यांकन करने के लिए, हम दो उपन्यास स्कोर मीट्रिक डिजाइन करते हैं: नाम मिलान स्कोर और ईवेंट मिलान स्कोर। प्रयोगात्मक परिणामों से पता चलता है कि हमारा मॉडल रूज स्कोर के साथ-साथ दो डिज़ाइन किए गए स्कोर पर अन्य सारांश आधार रेखाओं की तुलना में बेहतर प्रदर्शन करता है।', 'ru': 'Подведение итогов спортивных игр фокусируется на создании новостных статей из живых комментариев. В отличие от традиционных задач суммирования, исходные документы и целевые сводки для задач суммирования спортивных игр написаны в совершенно разных стилях письма. Кроме того, живые комментарии обычно содержат много названных сущностей, что делает обобщение спортивных игр именно очень сложной задачей. Для глубокого изучения этой задачи мы представляем SportsSum, китайский набор сводных данных о спортивных играх, который содержит 5428 футбольных игр с живыми комментариями и соответствующие новостные статьи. Кроме того, мы предлагаем двухэтапную модель суммирования, состоящую из селектора и переписчика для SportsSum. Чтобы оценить правильность сгенерированных спортивных сводок, мы разрабатываем две новые метрики оценки: совпадающую оценку имени и совпадающую оценку события. Экспериментальные результаты показывают, что наша модель демонстрирует лучшие результаты, чем другие исходные данные для суммирования по баллам РУЖА, а также по двум расчетным баллам.', 'ga': 'Díríonn achoimre ar chluichí spóirt ar ailt nuachta a ghiniúint ó thráchtairí beo. Murab ionann agus tascanna achoimrithe traidisiúnta, tá na bundoiciméid agus na hachoimrí sprice do thascanna achoimrithe cluichí spóirt scríofa i stíleanna scríbhneoireachta an-difriúla. Ina theannta sin, is iondúil go mbíonn go leor eintiteas ainmnithe i dtráchtaireacht bheo, rud a fhágann go bhfuil sé fíordhúshlánach achoimre a dhéanamh ar chluichí spóirt. Chun staidéar domhain a dhéanamh ar an tasc seo, cuirimid i láthair SportsSum, tacar sonraí achoimrithe cluichí spóirt na Síne ina bhfuil 5,428 cluiche sacair de thráchtaireacht beo agus na hailt nuachta comhfhreagracha. Ina theannta sin, molaimid múnla achoimrithe dhá chéim ina mbeidh roghnóir agus athscríbhneoir do SportsSum. Chun cruinneas na n-achoimrí spóirt a ghintear a mheas, déanaimid dhá mhéadracht scór úrscéal a dhearadh: scór meaitseála ainmneacha agus scór meaitseála imeachtaí. Léiríonn torthaí turgnamhacha go bhfeidhmíonn ár múnla níos fearr ná bonnlínte achoimre eile ar scóir ROUGE chomh maith leis an dá scór deartha.', 'hu': 'A sportjátékok összefoglalása az élő kommentárokból származó hírek készítésére összpontosít. A hagyományos összefoglalási feladatoktól eltérően a sportjátékok összefoglalási feladatainak forrásdokumentációi és célösszefoglalói teljesen eltérő írási stílusban vannak írva. Ezenkívül az élő kommentárok általában sok elnevezett entitást tartalmaznak, ami a sportjátékok összefoglalását pontosan nagyon kihívást jelent. A feladat mélyreható tanulmányozásához bemutatjuk a SportsSum, egy kínai sportjáték összefoglaló adatkészletet, amely 5 428 focimeccset tartalmaz élő kommentárokból és a megfelelő hírekből. Továbbá javaslatunk egy kétlépéses összefoglaló modellt, amely egy választóból és egy újraíróból áll a SportsSum számára. A létrehozott sportösszefoglalók helyességének értékelése érdekében két új pontszámmérőt tervezünk: névpontszám és eseménypontszám. Kísérleti eredmények azt mutatják, hogy modellünk jobb teljesítményt nyújt a ROUGE pontszámok és a két tervezett pontszám tekintetében.', 'el': 'Η σύνοψη αθλητικών παιχνιδιών επικεντρώνεται στη δημιουργία άρθρων ειδήσεων από ζωντανά σχόλια. Σε αντίθεση με τις παραδοσιακές εργασίες σύνοψης, τα έγγραφα προέλευσης και οι περιλήψεις στόχων για τις εργασίες σύνοψης αθλητικών παιχνιδιών γράφονται σε αρκετά διαφορετικά στυλ γραφής. Επιπλέον, τα ζωντανά σχόλια περιέχουν συνήθως πολλές ονομαστικές οντότητες, γεγονός που καθιστά την περίληψη των αθλητικών παιχνιδιών ακριβώς πολύ δύσκολη. Για να μελετήσουμε βαθύτατα αυτό το έργο, παρουσιάζουμε το ένα σύνολο δεδομένων σύνοψης κινεζικών αθλητικών παιχνιδιών που περιέχει 5,428 ποδοσφαιρικά παιχνίδια ζωντανών σχολίων και τα αντίστοιχα άρθρα ειδήσεων. Επιπλέον, προτείνουμε ένα μοντέλο σύνοψης δύο βημάτων που αποτελείται από έναν επιλογέα και έναν αναδημιουργό για το SportsSum. Για να αξιολογηθεί η ορθότητα των παραγόμενων αθλητικών περιλήψεων, σχεδιάζουμε δύο νέες μετρήσεις βαθμολογίας: βαθμολογία αντιστοίχισης ονόματος και βαθμολογία αντιστοίχισης γεγονότων. Τα πειραματικά αποτελέσματα δείχνουν ότι το μοντέλο μας αποδίδει καλύτερα από άλλες γραμμές βάσης συνοψίας στις βαθμολογίες καθώς και στις δύο σχεδιασμένες βαθμολογίες.', 'ka': 'Name ტრადიციონალური კოსტუმენტის დავალების განმავლობაში, სპორტის თამაში კოსტუმენტის კოსტუმენტის კოსტუმენტის კოსტუმენტის კოსტუმენტის კოსტ დამატებით, ცხოვრებული კომენტერიები საერთოდ აქვს ბევრი სახელ ინტერტიკები, რომელიც სპორტის თამაშვების საკითხებით ძალიან შესაძლებელია. ამ დავალების ძალიან გასწავლისთვის, ჩვენ ჩინეთი სპორტის თამაშების კომპორტიზაციის მონაცემების კომპორტიზაცია, რომელიც 5 428 ფუბური თამაშების ცხოვრებული კომპორტირების და დამატებით, ჩვენ გვეძლევა ორ-კვადრატური სუბუზაციის მოდელი, რომელიც არჩეველი და სოპორტისსუმის გარეშექმნა. შექმნილი სპორტის რეზიუმენტის მარტივის შესაბამისთვის, ჩვენ ორი პრომენტის მონაცემების მეტრიკის შესაბამისთვის: სახელი შესაბამისთვის მონაცემების და მონაცემე ექსპერიმენტიური შედეგები ჩვენი მოდელი უკეთესი გავაკეთება, ვიდრე სხვა სიმბოლო ხაზების ROUGE შედეგების შედეგების შედეგების შედეგების შედეგების შედეგები', 'kk': 'Спорт ойының тұжырымдамасы жаңалық мақалаларын өмір түсініктемелерден құру үшін көздейді. Дәстүрлі тұжырымдама тапсырмаларының мазмұнына, спорттың тұжырымдама тапсырмаларының көздегі құжаттар мен нақты тұжырымдамасы әртүрлі жазу стилінде жазылады. Қосымша, өмір комментарияларда көпшілік аталған нысандар бар, бұл спорт ойындарын тұжырымдастыру үшін дұрыс әсер етеді. Бұл тапсырманы түсіндіру үшін біз SportsSum- ды, 5 428 футболдық комментариялар мен жаңалық мақалалар бар қытайша спорт ойының тұжырымдамасын көрсетедік. Сонымен қатар, біз SportsSum- тың таңдаушысы мен қайта жазушысы үшін екі қадам жинақтау үлгісін ұсынамыз. Жасалған спорт тұжырымдарының дұрыстығын бағалау үшін біз екі романдық нөмірлер метрикалығын құрамыз: нөмірлер мен оқиға сәйкес келетін нөмірлер атауы. Эксперименталдық нәтижелері ROUGE нәтижелерінде және екі құрылған нәтижелерде басқа тұжырымдамасынан жақсы жұмыс істейді.', 'it': 'La sintesi dei giochi sportivi si concentra sulla generazione di articoli di notizie da commenti dal vivo. A differenza dei compiti di riepilogo tradizionali, i documenti di origine e i riassunti di destinazione per i compiti di riepilogo dei giochi sportivi sono scritti in stili di scrittura molto diversi. Inoltre, i commenti dal vivo di solito contengono molte entità nominate, il che rende la sintesi dei giochi sportivi esattamente molto impegnativa. Per approfondire questo compito, presentiamo SportsSum, un set di dati di sintesi dei giochi sportivi cinesi che contiene 5.428 partite di calcio di commenti dal vivo e i corrispondenti articoli di notizie. Inoltre, proponiamo un modello di riepilogo in due fasi composto da un selettore e un riscrittore per SportsSum. Per valutare la correttezza dei riassunti sportivi generati, progettiamo due nuove metriche di punteggio: punteggio di corrispondenza del nome e punteggio di corrispondenza degli eventi. I risultati sperimentali mostrano che il nostro modello ha prestazioni migliori rispetto ad altre linee di base di sintesi sui punteggi ROUGE e sui due punteggi progettati.', 'mk': 'Сумеризацијата на спортските игри се фокусира на генерирање новински статии од живи коментари. За разлика од традиционалните задачи за резоризација, изворните документи и целните резоризации за резоризација на спортските игри се напишани во сосема различни стили на пишување. Покрај тоа, живите коментари обично содржат многу именувани ентитети, што прави резултатот на спортските игри прецизно многу тешко. За длабоко да ја проучуваме оваа задача, го претставуваме SportsSum, компјутер на податоци за резултат на кинеските спортски игри кој содржи 5.428 фудбалски игри со живи коментарии и соодветни вести. Покрај тоа, предложуваме двочекорен модел за резултат кој се состои од избор и репис за Спортсум. За да ја процениме коректноста на генерираните спортски резултати, дизајнираме две метрики на романски резултати: резултат за одговарање на името и резултат за одговарање на настаните. Experimental results show that our model performs better than other summarization baselines on ROUGE scores as well as the two designed scores.', 'ms': 'Penapisan permainan sukan fokus pada menghasilkan artikel berita dari komentar langsung. Unlike traditional summarization tasks, the source documents and the target summaries for sports game summarization tasks are written in quite different writing styles.  Selain itu, komentar langsung biasanya mengandungi banyak entiti bernama, yang membuat ringkasan permainan sukan tepat sangat mencabar. Untuk mempelajari tugas ini secara mendalam, kami memperkenalkan SportsSum, sebuah set data ringkasan permainan sukan Cina yang mengandungi 5,428 permainan sepak bola komentari langsung dan artikel berita yang sesuai. Selain itu, kami cadangkan model ringkasan dua langkah yang terdiri dari pemilih dan penulis semula untuk Sum Sports. Untuk menilai kebijaksanaan ringkasan sukan yang dijana, kami merancang dua metrik skor novel: skor yang sepadan nama dan skor yang sepadan peristiwa. Hasil percubaan menunjukkan bahawa model kita berjaya lebih baik daripada garis dasar penghuraian lain pada skor ROUGE serta dua skor yang direka.', 'mt': 'Is-sommarju tal-logħob sportiv jiffoka fuq il-ġenerazzjoni ta’ artikoli tal-aħbarijiet minn kummenti diretti. Għall-kuntrarju tal-kompiti tradizzjonali ta’ sommarju, id-dokumenti tas-sors u s-sommarji fil-mira għall-kompiti ta’ sommarju tal-logħob sportiv huma miktuba fi stili ta’ kitba pjuttost differenti. Barra minn hekk, il-kummenti live normalment fihom ħafna entitajiet imsemmija, li jagħmlu s-sommarju tal-logħob sportiv preċiżament diffiċli ħafna. Biex nistudjaw dan il-kompitu fil-fond, nippreżentaw SportsSum, sett ta’ dejta dwar is-sommarju tal-logħob sportiv Ċiniż li fih 5,428 logħob tal-futbol ta’ kummentarji live u l-artikoli korrispondenti tal-a ħbarijiet. Barra minn hekk, qed nipproponu mudell ta’ sommarju f’żewġ stadji li jikkonsisti f’selettur u kitba mill-ġdid għall-Isport Sum. To evaluate the correctness of generated sports summaries, we design two novel score metrics: name matching score and event matching score.  Ir-riżultati esperimentali juru li l-mudell tagħna jwettaq prestazzjoni aħjar minn linji bażi oħra ta’ sommarju fuq il-punteġġi ROUGE kif ukoll iż-żewġ punteġġi ddisinjati.', 'ml': 'സ്പോര്\u200dട്ട് കളിയുടെ ചുരുക്കം കാണിക്കുന്നത് ജീവിതമായ വാര്\u200dത്താക്കുകളില്\u200d നിന്നും നിര്\u200dമ്മിക് പാരമ്പര്യത്തിലെ ചുരുക്കം ചെയ്യുന്ന ജോലികള്\u200dക്ക് വ്യത്യസ്തമായി സോര്\u200dസ്സ് രേഖകളും കളിയുടെ ചുരുക്കത്തിനുള്ള ലക്ഷ്യങ്ങളുമായ കൂടാതെ, ജീവിതത്തിലെ കണക്കുകള്\u200d സാധാരണയായി പേരുള്ള പല വസ്തുക്കളുടെ കൂട്ടത്തിലുണ്ട്. അത് സംസാരിക്കുന്ന കളികള്\u200d  ഈ ജോലിയെ ആഴത്തോടെ പഠിപ്പിക്കാന്\u200d ഞങ്ങള്\u200d സ്പോര്\u200dട്ട്സുമിനെ കാണിക്കുന്നു, ചൈനീസ് കളികളുടെ കുറിച്ചുള്ള ഡാറ്റാസറേറ്റ് കൊണ്ടുവരുന കൂടുതല്\u200d സ്പോര്\u200dട്ട്സ് സംസ്കാരത്തിനുള്ള ഒരു തെരഞ്ഞെടുക്കുന്ന രണ്ട് പടിയുടെ സംഖ്യകളുടെ മോഡലിനെയും കൂടിയാണ് ഞങ്ങള്\u200d  സൃഷ്ടിക്കപ്പെട്ട സ്ക്രീസിന്റെ ശരിയാണെന്ന് നിരീക്ഷിക്കുവാന്\u200d, രണ്ട് നോവല്\u200d സ്കോര്\u200d മെറ്റിക്സ് നാം ഡിസൈനിക്കുന്നു പരീക്ഷിക്കുന്ന ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ മോഡല്\u200d മറ്റു ചുരുക്കത്തിന്റെ അടിസ്ഥാനത്തേക്കാള്\u200d നല്ലത് പ', 'lt': 'Sportinių žaidimų santraukoje daugiausia dėmesio skiriama naujienų straipsnių kūrimui iš tiesioginių komentarų. Skirtingai nuo tradicinių apibendrinimo užduočių, šaltiniai dokumentai ir tikslinės sporto žaidimų apibendrinimo užduočių apibendrinimo santraukos yra rašomos visiškai skirtingais rašymo stilais. Be to, tiesioginiuose komentaruose paprastai yra daug pavadintų subjektų, todėl sporto žaidimų santrauka yra labai sudėtinga. Siekdami išsamiai išnagrinėti šią užduotį, pristatysime SportsSum, Kinijos sporto žaidimų santraukos duomenų rinkinį, kuriame yra 5 428 futbolo žaidimai su tiesioginiais komentarais ir atitinkami naujienų straipsniai. Be to, siūlome dviejų etapų apibendrinimo model į, kurį sudaro atrankos rinkėjas ir sporto sumai skirtas perskaičiavimas. Siekiant įvertinti sukauptų sporto santraukų teisingumą, sukuriame du naujus rezultatų rodiklius: vardų ir renginių atitikties rodiklius. Eksperimentiniai rezultatai rodo, kad mūsų modelis veikia geriau nei kitos ROUGE rezultatų suvestinės bazės, taip pat du sukurti rezultatai.', 'mn': 'Спорт тоглоомын жинхэнэ тодорхойлолт нь амьдралын сэтгүүлчдийн мэдээллийг бий болгодог. Олон уламжлалтын жинхэнэ даалгавруудын ялгаа, спортын тоглоомын жинхэнэ даалгавруудын эх баримт болон зорилготой жинхэнэ жинхэнэ хэлбэрээр бичигддэг. Түүнчлэн амьдралын сэтгэл санаанууд ихэвчлэн нэрлэгдсэн бизнесүүдийг агуулдаг. Энэ нь спортын тоглоомуудыг тодорхойлох нь маш хэцүү. Энэ ажлыг гүн гүнзгий судлах үед бид Хятад спортын тоглоомын жинхэнэ өгөгдлийн санг тайлбарлаж байна. Энэ нь 5 428 хөмбөг тоглоомын амьдралын сэтгэл хөдлөл болон харьцангуй мэдээллийн баримт. Мөн бид хоёр дахь дахь жинхэнэ загварыг сонгогч болон спорт суммын дахин бичигч болгон санал болгож байна. Бүтээгдсэн спортын цуглуулалтын зөв хэмжээг үнэлэхээр бид хоёр шинэ оноо метрик загвар зохиож байна: нэр тоо болон үйл явдлын цуглуулалтын тоо. Эмчилгээний үр дүнд бидний загвар ROUGE оноо болон хоёр бүтээгдэхүүнээс илүү дээр ажилладаг.', 'pl': 'Podsumowanie gier sportowych skupia się na generowaniu artykułów wiadomościowych z komentarzy na żywo. W przeciwieństwie do tradycyjnych zadań podsumowywania, dokumenty źródłowe i docelowe podsumowania dla zadań podsumowywania gier sportowych są napisane w zupełnie różnych stylach pisania. Ponadto komentarze na żywo zawierają zwykle wiele nazwanych podmiotów, co sprawia, że podsumowanie gier sportowych jest bardzo wymagające. Aby głęboko zbadać to zadanie, przedstawiamy SportsSum, chiński zestaw danych podsumowujący gry sportowe zawierający 5,428 mecze piłki nożnej z komentarzami na żywo oraz odpowiednie artykuły wiadomościowe. Dodatkowo proponujemy dwuetapowy model podsumowania składający się z selektora i rewritera dla SportsSum. Aby ocenić poprawność wygenerowanych streszczeń sportowych, projektujemy dwie nowe wskaźniki wyników: wynik dopasowania nazw i wynik dopasowania wydarzeń. Wyniki eksperymentalne pokazują, że nasz model sprawdza się lepiej niż inne podstawowe podsumowania wyników ROUGE oraz dwóch zaprojektowanych wyników.', 'no': 'Samandringa av sportspel fokuserer på å laga nytt- artiklar frå live kommentarar. I motsetjing av tradisjonelle samandringsoppgåver, kjeldedokumenta og målsamningane for samandringsoppgåver for sportspel er skriven i ganske ulike skrivingsstilar. I tillegg inneheld leve kommentarar vanlegvis mange namnet entiteter, som gjer samansering av sportspel nøyaktig veldig vanskeleg. For å dypt studera denne oppgåva, presenterer vi SportsSum, eit kinesisk sportspel-dataset som inneheld 5,428 fotball-spel med leve kommentarar og tilsvarande nyhetseiningar. I tillegg foreslår vi eit to-steg samanseringsmodul som inneheld eit veljar og ein omskriver for SportsSum. For å evaluera korrektet av oppretta sportsamandrag, designerer vi to rommerke: namn som passar med poeng og hendingar som passar med poeng. Eksperimentale resultat viser at modellen vårt utfører bedre enn andre sammendragsbaselinjer på ROUGE- poeng og dei to designerte poeng.', 'sr': 'Sažetanje sportskih utakmica fokusira se na stvaranje novih članaka iz živih komentara. Za razliku od tradicionalnih zadataka za sažetanje, izvorni dokumenti i ciljni sažetak zadataka za sažetanje sportskih igra napisani su u prilično različitim stilima pisanja. Osim toga, živi komentari obično sadrže mnoge imenovane entitate, što čini sažetak sportskih igra tačno veoma izazovnim. Da bismo duboko proučavali ovaj zadatak, predstavljamo SportsSum, sažetak podataka o kineskoj sportskoj igri koja sadrži 5.428 fudbalskih utakmica živih komentara i odgovarajućih novinskih članaka. Osim toga, predlažemo model za sažetak dva koraka koji se sastoji od selektora i prepisača za SportsSum. Da bi procenili ispravnost proizvedenih sportskih sažetaka, dizajnirali smo dve metrike novog rezultata: mjeno odgovarajuće rezultate i rezultate odgovarajućih događaja. Eksperimentalni rezultati pokazuju da naš model izvršava bolje od drugih osnovnih linija za rezultate ROUGE-a, kao i dva dizajnirana rezultata.', 'so': 'Sports game summarization focuses on generating news articles from live commentaries.  Shaqooyinka koorsiga ah oo kala duduwan, dukumentiyada asalka ah iyo jardiinada jimicsiga waxaa lagu qoraa noocyo kala duduwan oo qoraal ah. Intaas waxaa dheer in laga helaa macluumaadyo badan oo la magacaabay, kaas oo ka dhigaya ciyaar jimicsi si si gaar ah oo ay u adag yihiin. Si aad u deegaan ayaannu shuqulkaas u baranaynaa kooxda jimicsiga ee Shiino, taas oo ku qoran 5,428 ciyaaro oo nool, iyo warqadaha warbixinta ee ku saabsan. Sidoo kale waxaynu soo jeedaynaa tusaale u soo jeedista labaad oo koob ah oo ka mid ah dooraha iyo qoraalka jimicsiga. Si aan ugu qiimeyno saxda jimicsiga oo la soo dhashay, waxaynu u qoraynaa laba kooras oo sawir ah: magac u eg score iyo dhacdooyinka isku mid ah. Imtixaanka waxaa muuqda in modellkayagu uu sameeyo wax ka wanaagsan qoraal kale oo lagu qoray kooxo ROUGE iyo labada kooxood oo lagu qoray.', 'ro': 'Rezumatul jocurilor sportive se concentrează pe generarea de articole de știri din comentarii live. Spre deosebire de sarcinile tradiționale de rezumare, documentele sursă și rezumatele țintă pentru sarcinile de rezumare a jocurilor sportive sunt scrise în stiluri de scriere destul de diferite. În plus, comentariile live conțin de obicei multe entități numite, ceea ce face ca rezumatul jocurilor sportive să fie foarte dificil. Pentru a studia profund această sarcină, vă prezentăm SportsSum, un set de date de rezumare a jocurilor sportive chinezești care conține 5.428 de jocuri de fotbal cu comentarii live și articole de știri corespunzătoare. În plus, vă propunem un model de rezumare în doi pași format dintr-un selector și un rescriere pentru SportsSum. Pentru a evalua corectitudinea rezumatelor sportive generate, proiectăm două valori noi ale scorului: scorul potrivit numelui și scorul potrivit evenimentelor. Rezultatele experimentale arată că modelul nostru performează mai bine decât alte linii de referință de rezumare pe scorurile ROUGE, precum și pe cele două scoruri proiectate.', 'sv': 'Sammanfattning av sportspel fokuserar på att generera nyhetsartiklar från livekommentarer. Till skillnad från traditionella sammanfattningsuppgifter är källdokumenten och målsammanfattningarna för sammanfattningsuppgifter skrivna i helt olika skrivstilar. Dessutom innehåller livekommentarer vanligtvis många namngivna entiteter, vilket gör sammanfattning av sportspel exakt mycket utmanande. För att fördjupa denna uppgift presenterar vi SportsSum, ett kinesiskt sportspelssammanfattningsdataset som innehåller 5 428 fotbollsmatcher med livekommentarer och motsvarande nyhetsartiklar. Dessutom föreslår vi en tvåstegs sammanfattningsmodell bestående av en väljare och en omskrivare för SportsSum. För att utvärdera korrektheten hos genererade sportsammanfattningar utformar vi två nya poängmått: namnmatchningspoäng och evenemangsmatchningspoäng. Experimentella resultat visar att vår modell presterar bättre än andra sammanfattande baslinjer på ROUGE-poäng samt de två designade poängen.', 'si': 'ස්පෝර්ම් සෙල්ලම් සංවිධානයක් ජීවිත කිරීමක් වලින් වාර්තාව නිර්මාණය කරනවා. සාමාන්\u200dය සුරකුණු වැඩක් වෙනුවෙන්, ප්\u200dරභාව විවිධ ලිපින් විවිධ විදිහට ලිපින් විදිහට ලියනවා ක්\u200dරීඩාව සු ඒ වගේම, ජීවිත කිරීමක් සාමාන්\u200dයයෙන්ම නම් කියලා තියෙන්නේ ගොඩක් අයිතියක් තියෙනවා, ඒකෙන් ස්පර්ශනය ස් මේ වැඩේ ගොඩක් අධ්\u200dයානය කරන්න, අපි ස්පෝර්ට් සුම්, චීනි ස්පෝර්ට් සුම්පූර්ණ සුම්පූර්ණ දත්ත සුම්පූර්ණ සුම්පූ තවත්, අපි පැත්තක් දෙකක් සංවිධානයක් සම්පූර්ණය කරනවා කියලා තෝරණකයෙක් සහ ස්පෝර්ට් සුම් වෙනුවෙන් පු නිර්මාණය කරපු ක්\u200dරියාත්මක සංශ්\u200dයාවක් නිර්මාණය කරන්න, අපි ක්\u200dරියාත්මක ප්\u200dරමාණ දෙකක් සංශ්\u200dයාපනය කරන්න: නම් ස පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ මොඩල් හොඳයි ROUGE ප්\u200dරතිචාරයක් වලින් අනිත් සංවිධානය ප්\u200dර', 'ur': 'اسپارٹ کھیل کے سامنے نویس لکھائی کے پیدا کرنے پر تمرکز کیا جاتا ہے۔ اسپارٹی جمع کرنے کے کاموں کے مطابق، سورس دکھانے اور موجود جمع کرنے کے لئے کھیل جمع کرنے کے کاموں کے مطابق مختلف طریقوں میں لکھے جاتے ہیں. اور اس کے علاوہ، زندگی مطلوبات معمولاً بہت سی نام داری ہیں، جو اسپارٹ کھیلیوں کو بہت مشکل کر رہا ہے۔ یہ کام عمیق سے پڑھنے کے لئے، ہم اسپورٹ سوم، ایک چینی اسپورٹ کے کھیل جمع کرنا ڈیٹ سٹ کو پیش کرتے ہیں جس میں 5,428 فوٹ بول کھیل ہیں جن کی زندگی کمٹرنیٹر اور مطابق نیویس لکھائی ہیں. اور اضافہ، ہم ایک دوگاؤں کے سامنے موڈل کی پیشنهاد کرتے ہیں جو ایک انتخاب کرنے والا اور اسپارٹ سوم کے لئے دوبارہ ریائٹر ہے. ہم نے دوسرے نومین اسکور میٹریک ڈیزائن کیا ہے: اسکور اور ایڈیونٹ میٹریک کے مطابق مطابق نام. Experimental results show that our model performs better than other summarization baselines on ROUGE scores as well as the two designed scores.', 'ta': 'விளையாட்டு விளையாட்டு சுருக்கம் விளையாட்டு விளையாட்டு விளையாட்டு விளையாட்டு குறிப்ப பாரம்பரிய சுருக்கும் செயல்களுக்கு மூல ஆவணங்கள் மற்றும் விளையாட்டு விளையாட்டு சுருக்கும் சேர்க்கைகள் மிகவும் வேறு வித கூடுதலாக, வாழ்வு குறிப்புரைகள் வழக்கமாக பெயர்க்கப்பட்ட பல பொருள்களைக் கொண்டிருக்கிறது, அது விளையாட்டுகளை சு இந்த பணியை ஆழமாக படிக்க, நாம் விளையாட்டு சீனா விளையாட்டு சுருக்கம் தகவல்களை காண்பிக்கிறோம், அதில் 5,428 கால் விளையாட்டு விளையாட்டுகள கூடுதலாக, நாம் ஒரு தேர்ந்தெடுப்பவர் மற்றும் விளையாட்டு சேர்ப்பு முறைமையை மீண்டும் எழுதுபவரை பரிந்துரைக்கிறோம். உருவாக்கப்பட்ட விளையாட்டு சுருக்கத்தின் சரியை மதிப்பிட, நாம் இரண்டு புதிய புள்ளி மதிப்பை வடிவமைக்கிறோம்: பெயர் பொருந் முயற்சி முடிவுகள் என்று காட்டுகிறது எங்கள் மாதிரி மற்ற சுருக்கல் அடிப்படைகளை விட சிறந்த செயல்படுத்துகிறது ROUGE மதிப்புகள் மற', 'vi': 'Bản tóm tắt trò chơi thể thao tập trung vào việc phát ra tin tức từ tường thuật trực tiếp. Không giống như các công việc tổng hợp truyền thống, các tài liệu gốc và các bản tóm tắt tiêu điểm cho các công việc thể thao được viết trong các kiểu hoàn toàn khác nhau. Thêm vào đó, những lời bình luận trực tiếp thường chứa nhiều thực thể có tên, điều đó làm cho việc tổng hợp các trò chơi thể thao rất khó. Để nghiên cứu sâu về nhiệm vụ này, chúng tôi có thể hiện bản tin và bản tin về các trò chơi thể thao Trung Quốc. Thêm nữa, chúng tôi đề xuất một mô hình tổng hợp hai bước có một bộ chọn và một sửa soạn bản thể thao cho bản thể thao. Để đánh giá sự sửa chữa các bản tóm tắt thể thao đã tạo ra, chúng tôi thiết kế hai thước đo số mới: số lượng số điểm khớp tên và số các sự kiện khớp. Kết quả thí nghiệm cho thấy mô hình của chúng ta hiệu quả tốt hơn so với các bản tóm tắt trên các điểm của ROCE cũng như hai điểm được thiết kế.', 'uz': "Sports game summarization focuses on generating news articles from live commentaries.  Name Ko'pchilik, hayoti izohlari odatda ko'pchilik nomli narsalar mavjud. Bu sport oʻyinlarini juda qisqarli qisqartmalar qiladi. Bu vazifani eng yaxshi o'rganish uchun Sports Sum, Xitoycha sport o'yincha muhitiyat maʼlumotlarini hozirganamiz. Uning 5,428 soccer o'yinlari va corresponding xabar maqolalari bor. Ko'pchilik, biz tanlagicha va SportsSum uchun qayta yozuvchi bir ikki qadam muhitiyat modelini talab qilamiz. Name Tekshirish natijalari koʻrsatiladi, modelmiz ROUGE scorlarida boshqa qisqaruv asosidagi asosidan yaxshi bajaradi va ikkita dizayning qiymatlarini bajaradi.", 'bg': 'Обобщението на спортните игри се фокусира върху генерирането на новинарски статии от коментари на живо. За разлика от традиционните задачи за обобщаване, изходните документи и целевите резюмета за задачите за обобщаване на спортни игри са написани в доста различни стилове на писане. В допълнение, коментарите на живо обикновено съдържат много имена, което прави обобщаването на спортните игри точно много предизвикателно. За да проучим задълбочено тази задача, представяме набор от данни за обобщаване на китайски спортни игри, който съдържа 5428 футболни мача с коментари на живо и съответните новини. Освен това предлагаме двустепенен модел за обобщаване, състоящ се от селектор и пренаписване на СпортсСум. За да оценим коректността на генерираните спортни резюмета, проектираме две нови показатели за резултат: резултат за съвпадение на имената и резултат за съвпадение на събития. Експерименталните резултати показват, че нашият модел се представя по-добре от другите базови линии за обобщаване на резултатите както и на двете проектирани резултати.', 'da': 'Sports spil resuméering fokuserer på at generere nyhedsartikler fra live kommentarer. I modsætning til traditionelle opsummeringsopgaver er kildedokumenterne og målopsummeringerne for sportsspil opsummeringsopgaver skrevet i helt forskellige skrivestilarter. Derudover indeholder live kommentarer normalt mange navngivne enheder, hvilket gør opsummering af sportsspil præcist meget udfordrende. For at undersøge denne opgave dybt præsenterer vi SportsSum, et kinesisk sportsspil opsummering datasæt, der indeholder 5.428 fodboldspil med live kommentarer og de tilsvarende nyhedsartikler. Derudover foreslår vi en to-trins opsummeringsmodel bestående af en vælger og en omskriver til SportsSum. For at vurdere rigtigheden af genererede sportsresuméer designer vi to nye resultatmålinger: navn matching score og event matching score. Eksperimentelle resultater viser, at vores model præsterer bedre end andre sammenfattende baselines på ROUGE scores samt de to designede scores.', 'nl': 'Samenvatting van sportspellen richt zich op het genereren van nieuwsberichten uit live commentaren. In tegenstelling tot traditionele samenvattingstaken worden de brondocumenten en de doelsamenvattingen voor samenvattingstaken van sportwedstrijden in heel verschillende schrijfstijlen geschreven. Bovendien bevatten live commentaren meestal veel benoemde entiteiten, wat het samenvatten van sportwedstrijden juist erg uitdagend maakt. Om deze taak grondig te bestuderen, presenteren we SportsSum, een Chinese sportgame samenvatting dataset die 5.428 voetbalwedstrijden van live commentaren en de bijbehorende nieuwsberichten bevat. Daarnaast stellen we een tweestaps samenvattingsmodel voor bestaande uit een selector en een herschrijver voor SportsSum. Om de juistheid van gegenereerde sportsamenvattingen te evalueren, ontwerpen we twee nieuwe score metrics: naam matching score en event matching score. Experimentele resultaten tonen aan dat ons model beter presteert dan andere samenvattingsbaselines op ROUGE scores en de twee ontworpen scores.', 'hr': 'Sažetanje sportskih utakmica fokusira se na stvaranje novih članaka iz živih komentara. Za razliku od tradicionalnih zadataka za sažetak, izvorni dokumenti i ciljni sažetak zadataka za sažetak sportskih igra napisani su u prilično različitim stilima pisanja. Osim toga, živi komentari obično sadrže mnoge imenovane entitate, što čini sažetak sportskih utakmica točno vrlo izazovnim. Da bismo duboko proučavali ovaj zadatak, predstavljamo SportsSum, sažetak podataka o kineskoj sportskoj igri koja sadrži 5 428 fudbalskih utakmica živih komentara i odgovarajućih novinskih članaka. Osim toga, predlažemo model za sažetak dva koraka koji se sastoji od selektora i prepisača za SportsSum. Da bi procijenili ispravnost proizvedenih sportskih sažetaka, dizajnirali smo dvije metrike novog rezultata: rezultat odgovarajućeg imena i rezultat odgovarajućeg događaja. Eksperimentalni rezultati pokazuju da naš model izvršava bolje od drugih osnovnih linija rezultata ROUGE-a, kao i dva dizajnirana rezultata.', 'de': 'Die Zusammenfassung von Sportspielen konzentriert sich auf die Generierung von Nachrichtenartikeln aus Live-Kommentaren. Anders als herkömmliche Zusammenfassungsaufgaben werden die Quelldokumente und die Zielzusammenfassungen für Sportspiel-Zusammenfassungsaufgaben in ganz unterschiedlichen Schreibstilen geschrieben. Darüber hinaus enthalten Live-Kommentare in der Regel viele benannte Entitäten, was die präzise Zusammenfassung von Sportspielen sehr herausfordernd macht. Um diese Aufgabe eingehend zu untersuchen, stellen wir SportsSum vor, einen chinesischen Datensatz zur Zusammenfassung von Sportspielen, der 5.428 Fußballspiele mit Live-Kommentaren und den entsprechenden Nachrichtenartikeln enthält. Zusätzlich schlagen wir ein zweistufiges Zusammenfassungsmodell vor, das aus einem Selektor und einem Rewriter für SportsSum besteht. Um die Richtigkeit der generierten Sportzusammenfassungen zu bewerten, entwerfen wir zwei neuartige Score-Metriken: Name Matching Score und Event Matching Score. Experimentelle Ergebnisse zeigen, dass unser Modell sowohl bei ROUGE Scores als auch bei den beiden designten Scores besser abschneidet als bei anderen Zusammenfassungsbasisen.', 'id': 'Persingkatan permainan olahraga fokus pada menghasilkan artikel berita dari komentar langsung. Tidak seperti tugas ringkasan tradisional, dokumen sumber dan ringkasan sasaran untuk tugas ringkasan game olahraga ditulis dalam gaya tulisan yang cukup berbeda. Selain itu, komentar langsung biasanya mengandung banyak entitas bernama, yang membuat mempersingkatkan permainan olahraga tepat sangat menantang. Untuk mempelajari tugas ini secara mendalam, kami mempersembahkan SportsSum, sebuah set data perhitungan permainan olahraga Cina yang mengandung 5.428 permainan sepak bola komentar langsung dan artikel berita yang sesuai. Selain itu, kami mengusulkan model penglihatan dua langkah yang terdiri dari pemilih dan penulis ulang untuk SportsSum. To evaluate the correctness of generated sports summaries, we design two novel score metrics: name matching score and event matching score.  Hasil eksperimen menunjukkan bahwa model kita berhasil lebih baik dari garis dasar penghasilan lainnya pada skor ROUGE serta dua skor yang dirancang.', 'fa': 'جمع کردن بازی ورزشی روی تولید مجموعه\u200cهای خبری از توضیح\u200cهای زنده تمرکز می\u200cکند. برخلاف وظیفه\u200cهای جمع\u200cآوری سنتی، مدارک منبع و جمع\u200cآوری هدف برای وظیفه\u200cهای جمع\u200cآوری بازی ورزش در استیلهای نوشتن کاملا متفاوت نوشته می\u200cشوند. در addition, live commentaries usually contain many entities named, which makes summarizing sports games precisely very challenging. برای عمیق تحقیق این وظیفه، ما یک مجموعه داده\u200cهای جمع کردن بازی ورزشی چینی را پیشنهاد می\u200cکنیم که 5.428 بازی فوتبال از توضیح\u200cهای زنده و مجموعه\u200cهای خبرهای متفاوت دارد. به اضافه، ما یک مدل جمع کردن دو قدم را پیشنهاد می کنیم که از یک انتخاب کننده و یک نویسنده برای ورزش سوم است. برای ارزیابی درستی از جمع\u200cآوری\u200cهای ورزشی تولید، دو امتیاز رمانی را طراحی می\u200cکنیم: نام با امتیاز و امتیاز هماهنگ رویداد. نتیجه\u200cهای تجربه نشان می\u200cدهد که مدل ما بهتر از خطوط\u200cهای پایگاه\u200cهای جمع\u200cآوری در امتیاز ROUGE و دو امتیاز طراحی انجام می\u200cدهد.', 'sw': 'Uhitaji wa michezo ya michezo unajikita katika kutengeneza makala za habari kutoka kwa maoni ya moja kwa moja. Tofauti na kazi za muhtasari wa kitamaduni, nyaraka za vyanzo vya habari na muhtasari wa muhtasari wa michezo zimeandikwa katika mitindo tofauti ya kuandika michezo. Zaidi ya hayo, maoni ya moja kwa moja mara nyingi hujumuisha vifaa vingi vinavyoitwa, ambavyo vinafanya michezo ya muhtasari kwa hakika ni changamoto sana. Kusoma kazi hii kwa kina, tunaweka kipindi cha Sports Suu, taarifa ya muhtasari wa michezo ya michezo ya China yenye michezo 5,428 ya maoni ya moja kwa moja na makala yanayohusiana na habari. Kwa nyongeza, tunapendekeza muundo wa muhtasari wa hatua mbili wa muhtasari unaohusika na mpiga kura na mwandishi mwingine wa Suala la Sports. To evaluate the correctness of generated sports summaries, we design two novel score metrics: name matching score and event matching score.  Matokeo ya majaribio yanaonyesha kuwa mifano yetu inafanya vizuri zaidi ya misingi ya muhtasari mwingine kwenye vituo vya ROUGE pamoja na vipindi viwili vilivyoundwa.', 'af': "Speletjie opsomming fokus op die genereer van nuus artikels van lewende kommentaar. Ongelyks van tradisionele opsommingstaak, die bron dokumente en die doel opsommingstaak vir sportspeletjie opsommingstaak word in heeltemal verskillende skryfstyle geskryf. In addition, live commentaries usually contain many named entities, which makes summarizing sports games precisely very challenging. Om diep hierdie taak te leer, laat ons SportsSum voorsien, 'n Sjinese sportspeletjie opsomming dataset wat 5,428 fotball speletjies van lewende kommentaar en die ooreenstemmende nuus artikels bevat. In addition, we propose a two-step summarization model consisting of a selector and a rewriter for SportsSum. Om die regverdigheid van genereerde sport opsommings te evalueer, ontwerp ons twee novel telling metries: naam ooreenstemmende telling en gebeurtenis ooreenstemmende telling. Eksperimentele resultate wys dat ons model beter uitvoer as ander opsomming basisline op ROUGE telling en ook die twee ontwerp punte.", 'tr': "Sport oýunlary gyzyklaşdyrmak täzelikler ýaşaýyş terjimelerden döretmäge üns berir. Däpli juaýat täzelikleri ýara-da, çeşme senedi we sport oýunlaryň juaýat täzelikleri üçin maksady toparlaryň has beýleki ýazma stillerde ýazylýar. Munuň üstine ýaşaýan töwziňler adatça adly zatlary bar. Bu sport oýunlaryny düýbünden kynçylyk edip bilýär. Bu zady derinlikle öwrenmek üçin biz SportsSum'y, 5,428 futbol futbol oýunlaryň ýa şamly terjimelerinde we nähili täzelikler bar. Hemişe, biz sport suwusy üçin bir saýlawçy we täzeden ýazma nusgasyny iki adım süýtgetme nusgasyny teklip edýäris. Ýüklenen spor toparlaryň dogrylygyny deňlemek üçin, iki roman अंश metriklerini düzenlemek üçin, at we bellenen notlaryň adyna eşleşen noktalary düzenlemek üçin. Durmançylyk netijelerimiz ROUGE notlarynda we 2 düzenli notlaryň beýleki topar hatlaryndan gowy etýändigini görkezýär.", 'sq': 'Përmbledhja e lojrave sportive përqëndrohet në krijimin e artikujve të lajmeve nga komentet e drejtpërdrejta. Ndryshe nga detyrat tradicionale të përmbledhjes, dokumentet e burimit dhe përmbledhjet objektive për detyrat e përmbledhjes së lojrave sportive janë shkruar në stile shkrimi mjaft të ndryshme. In addition, live commentaries usually contain many named entities, which makes summarizing sports games precisely very challenging.  Për të studiuar thellësisht këtë detyrë, ne paraqesim SportsSum, një grup të dhënash për përmbledhjen e lojrave sportive kineze që përmban 5,428 lojra futbolli me komentare të drejtpërdrejta dhe artikujt e lajmeve korrespondentë. Përveç kësaj, ne propozojmë një model përmbledhjeje dy hapash që përbëhet nga një zgjedhës dhe një rishkrimtar për SportsSum. To evaluate the correctness of generated sports summaries, we design two novel score metrics: name matching score and event matching score.  Rezultatet eksperimentale tregojnë se modeli ynë performon më mirë se linjat bazë të tjera të përmbledhjes në rezultatet ROUGE si dhe dy rezultatet e projektuara.', 'hy': 'Սպորտային խաղերի համառոտագրությունը կենտրոնանում է լրատվական հոդվածների ստեղծման վրա կենդանի մեկնաբանություններից: Ի տարբերություն ավանդական համառոտագրման խնդիրներին, սպորտային խաղերի համառոտագրման խնդիրների աղբյուր փաստաթղթերը և նպատակային համառոտագրությունները գրվում են բավականին տարբեր գրողական ոճերով: Ավելին, կենդանի մեկնաբանությունները սովորաբար պարունակում են բազմաթիվ անվանված էակներ, ինչը ստիպում է սպորտային խաղերի համառոտագրությունը ճշգրիտ շատ դժվար դառնալ: Այս խնդիրը խորապես ուսումնասիրելու համար մենք ներկայացնում ենք SportsSum-ը, Չինաստանի սպորտային խաղերի համառոտագրման տվյալների համակարգը, որը պարունակում է 5.428 ֆուտբոլային խաղեր կենդանի մեկնաբանությունների և համապատասխան նորությունների հոդվածներ Ավելին, մենք առաջարկում ենք երկու քայլ համառոտագրման մոդել, որը կազմված է ընտրողից և SportsSum-ի վերագրողից: Որպեսզի գնահատենք ստեղծված սպորտային համառոտագրությունների ճշմարտությունը, մենք ստեղծում ենք երկու նորարար գնահատականների մետրիկներ՝ անունների համապատասխանման գնահատականներ և իրադարձությունների համապատասխանման գնահատականներ: Փորձարկվող արդյունքները ցույց են տալիս, որ մեր մոդելը ավելի լավ է աշխատում, քան այլ համառոտագրման հիմնական գծերը ROUGe գնահատականների վրա, ինչպես նաև երկու նախագծված գնահատականների վրա:', 'am': 'የፖርት ጨዋታ አቀማመጥ የዜና ጽሑፎችን ከሕይወት አስተያየት በመፍጠር ላይ ያስተካክላል፡፡ በተለየ ባሕላዊው አቀማመጥ አድራጊዎች፣ ምንጭ ሰነዱን እና የጨዋታውን ጨዋታ አድራሻ በተለየ ልዩ ጽሑፍ ዓይነት ተጽፎአል። በተጨማሪም፣ የሕይወት አስተያየት ብዙዎችን በተጠራጠሩ አካባቢዎች ይኖራሉ፤ የጨዋታውን የጨዋታ ጨዋታዎች በትክክል አዋጅ ያሳስታል፡፡ ይህንን ሥርዓት አጥብቀው ለማስተምር፣ የቻይና የጨዋታ ጨዋታ አቁማርነት ዳታዎችን እና 5,428 የእግር እግር አዋራጅ እና የሚታያየው የዜና ጽሑፎች እና አቅርብ እናደርጋለን፡፡ በተጨማሪም፣ የመረጠኛ እና ለSports Sum የሚተካክል የሁለት ደረጃዎች አቀማመጥ ማተሚያ ሞዴል እናሳውቃለን፡፡ የጨዋታ ደረጃ ፈተና ውጤቶች ሞዴላዎቻችን በሌላ አዋራጅ የሮዩጂ scores እና ሁለቱ የተፈጠሩ ደረጃዎች የሚሻል መሠረት ያሳያል፡፡', 'az': "Sports oyunu qeyd edilməsi haqq məktullarını canlı komentarlardan yaratmağa odaqlanır. Dəstəliyi təmizləmə işləri ilə, sport oyunu təmizləmə işləri üçün mənbə belələri və məqsədi təmizləmə işləri çox müxtəlif yazma stillərində yazılır. Əvvəlcə, yaşlı komentarlar genellikle bir çox adlı növlər barəsində, bu da sport oyunlarını çox çətin göstərir. Bu işi derin təhsil etmək üçün, biz SportsSum'u, 5.428 futbol oyunları və müqayisədə haqqı məlumatları olan bir Çin sport oyunu toplama verilənlərini göstəririk. Daha çox, biz SportsSum üçün bir seçici və yenidən yazıcı olan iki adım toplama modeli təklif edirik. Məxluqatlı spor toplamlarının doğruluğunu değerləşdirmək üçün, iki roman nöqtəsi metrik tasarlayırıq: nöqtəsi ilə uyuşan nöqtəsi və nöqtəsi ilə uyuşan nöqtəsi. Experimental sonuçlarımız modellərimiz ROUGE nöqtələrində və iki nöqtələrindən daha yaxşı işlədiyini göstərir.", 'bn': 'সংক্ষিপ্ত খেলার সারসংক্ষিপ্ত সংক্রান্ত খবর তৈরি করার দিকে মনোযোগ প্রদান করে। ঐতিহ্যবাহী সংক্ষেপের কাজের বিভিন্ন ভিন্ন ভিন্ন ভিন্ন লেখায় লেখা হয়েছে। এছাড়াও, সরাসরি মন্তব্য সাধারণত অনেক নামের প্রতিষ্ঠান রয়েছে, যা খেলার খেলার সারামিক খেলায় খেলায় খুব চ্যালেঞ্জ এই কাজের গভীরভাবে গবেষণার জন্য আমরা চীনা খেলার সংক্ষেপের তথ্য উপস্থাপন করি স্পোর্টস সাম যার মধ্যে আছে ৫,৪২৮ ফুটবল খেলা এবং সংশ্লিষ্ট সংবাদ প এছাড়াও, আমরা একটি দুই পদক্ষেপের সারসংক্ষেপ মডেল প্রস্তাব করি যেখানে একজন নির্বাচনী এবং স্পোর্টস সামের পুনরায় লেখক। তৈরি করা খেলার সংক্রান্ত সংক্রান্ত সংক্রান্ত সঠিক মূল্যায়নের জন্য আমরা দুই নভেল স্কোর মেট্রিক ডিজাইন করি: নাম ম মিলিয়ে  পরীক্ষার ফলাফল দেখা যাচ্ছে যে আমাদের মডেল অন্যান্য সার্মিজেশনের বেসারেশনের চেয়ে ভালো কাজ করে যাচ্ছে এবং এই দুটি ডিজাইনার স', 'ko': '스포츠 경기 요약은 현장 평론에서 뉴스 기사를 만드는 데 중심을 두었다.전통적인 요약 임무와 달리 스포츠 경기 요약 임무의 원본 문서와 목표 요약은 완전히 다른 창작 스타일을 채택한다.그 밖에 생방송 평론은 보통 많은 명칭 실체를 포함하기 때문에 스포츠 경기를 정확하게 정리하는 것은 매우 도전적이다.이 임무를 깊이 있게 연구하기 위해 우리는 중국 스포츠 경기 요약 데이터집인 스포츠섬을 제공했는데 그 중에서 5428경기의 축구 경기 실황 평론과 상응하는 뉴스 기사를 포함한다.그 밖에 우리는 선택기와 리코더로 구성된 두 가지 요약 모델을 제시했다.생성된 운동 요약의 정확성을 평가하기 위해 우리는 두 가지 새로운 점수 지표를 설계했다. 그것이 바로 명칭 일치 점수와 이벤트 일치 점수이다.실험 결과에 의하면 우리의 모델은 연지 점수와 두 디자인 점수에서 다른 요약 기선보다 우수하다는 것을 알 수 있다.', 'ca': "El resum del joc deportiu es centra en generar articles de notícies a partir de comentaris en directe. A diferència de les tasques tradicionals de resum, els documents de font i els resums de mira de les tasques de resum dels jocs esportius estan escrits en estils d'escriptura bastant diferents. A més, els comentaris en directe normalment contenen moltes entitats anomenades, cosa que fa que resumir els jocs esportius sigui precisament molt difícil. Per estudiar profundament aquesta tasca, presentem SportsSum, un conjunt de dades de resum dels jocs esportius xinesos que conté 5.428 jocs de fútbol de comentaris en directe i els articles de notícia correspondents. A més, proposem un model de resum de dos passos compost d'un selector i un reescriptor per SportsSum. Per avaluar la correctesa dels resums sportifs generats, dissenyem dues noves puntuacions: puntuacions de nom i puntuacions d'eventos. Experimental results show that our model performs better than other summarization baselines on ROUGE scores as well as the two designed scores.", 'cs': 'Shrnutí sportovních her se zaměřuje na generování zpravodajských článků z živých komentářů. Na rozdíl od tradičních souhrnných úloh jsou zdrojové dokumenty a cílové souhrnné úlohy pro souhrnné úlohy sportovních her napsány zcela odlišnými styly psaní. Kromě toho živé komentáře obvykle obsahují mnoho jmenovaných entit, což činí shrnutí sportovních her přesně velmi náročné. Pro hluboké studium tohoto úkolu představujeme SportsSum, čínský soubor souhrnu sportovních her, který obsahuje 5,428 fotbalové hry živých komentářů a odpovídající zpravodajské články. Navíc navrhujeme dvoustupňový souhrnný model sestávající z selektoru a přepisovače pro SportsSum. Pro vyhodnocení správnosti generovaných sportovních souhrnů navrhujeme dvě nové metriky skóre: skóre shodování jmen a skóre shodování událostí. Experimentální výsledky ukazují, že náš model vede lépe než ostatní souhrnné základní linie na ROUGE skóre a dvou navržených skóre.', 'bs': 'Sažetanje sportskih utakmica fokusira se na stvaranje novih članaka iz živih komentara. Za razliku od tradicionalnih zadataka za sažetak, izvorni dokumenti i ciljni sažetak zadataka za sažetak sportskih igra napisani su u prilično različitim stilima pisanja. Osim toga, živi komentari obično sadrže mnoge imenovane entitate, što čini sažetak sportskih igra tačno veoma izazovnim. Da bismo duboko proučili ovaj zadatak, predstavljamo SportsSum, sažetak podataka o kineskoj sportskoj igri koji sadrži 5.428 fudbalskih utakmica živih komentara i odgovarajućih novinskih članaka. Osim toga, predlažemo model za sažetak dva koraka koji se sastoji od selektora i prepisača za SportsSum. Da bi procijenili ispravnost proizvedenih sportskih sažetaka, dizajnirali smo dvije metrike novog rezultata: mjeno odgovarajuće rezultate i rezultate odgovarajućih događaja. Eksperimentalni rezultati pokazuju da naš model izvršava bolje od drugih osnovnih linija za rezultate ROUGE-a, kao i dva dizajnirana rezultata.', 'fi': 'Urheilupelien yhteenveto keskittyy uutisartikkeleiden tuottamiseen livekommenteista. Perinteisistä yhteenvetotehtävistä poiketen urheilupelien yhteenvetotehtävien lähdeasiakirjat ja kohdeyhteenvedot on kirjoitettu melko erilaisilla kirjoitustyyleillä. Lisäksi live-kommentaarit sisältävät yleensä monia nimettyjä kokonaisuuksia, mikä tekee urheilupelien tiivistämisestä erittäin haastavaa. Tutkiaksemme tätä tehtävää syvällisesti esittelemme SportsSumin, kiinalaisen urheilupelien yhteenvetoaineiston, joka sisältää 5 428 jalkapallopeliä live-kommentteja ja vastaavia uutisartikkeleita. Lisäksi ehdotamme kaksivaiheista yhteenvetomallia, joka koostuu valitsimesta ja uudelleenkirjoittajasta SportsSumille. Luodun urheiluyhteenvedon oikeellisuuden arvioimiseksi suunnittelemme kaksi uutta pistemittaria: nimipistemäärä ja tapahtumapistemäärä. Kokeelliset tulokset osoittavat, että mallimme suoriutuu paremmin kuin muut ROUGE-pisteet ja kaksi suunniteltua pisteytystä.', 'et': 'Spordimängude kokkuvõte keskendub uudisteartiklite genereerimisele live kommentaaridest. Erinevalt traditsioonilistest kokkuvõtlusülesannetest kirjutatakse spordimängude kokkuvõtlusülesannete lähtedokumendid ja sihtkokkuvõtted üsna erinevates kirjutamisstiilides. Lisaks sisaldavad live kommentaarid tavaliselt palju nimetatud üksusi, mis muudab spordimängude kokkuvõtmise täpselt väga keeruliseks. Selle ülesande põhjalikuks uurimiseks tutvustame Hiina spordimängude kokkuvõtte andmekogumit SportsSum, mis sisaldab 5428 jalgpallimängu live kommentaare ja vastavaid uudisartikleid. Lisaks pakume välja kaheastmelise kokkuvõtlusmudeli, mis koosneb SportsSumi valijast ja ümberkirjutajast. Loodud spordikokkuvõtete õigsuse hindamiseks töötame välja kaks uut tulemusmeetrit: nime sobivuse skoor ja sündmuse sobivuse skoor. Eksperimentaalsed tulemused näitavad, et meie mudel toimib paremini kui teised kokkuvõtlikud lähtejooned nii ROUGE skooride kui ka kahe kavandatud skooride kohta.', 'jv': 'Cumulatement Ngawe Perintah sing dibenalke perusahaan dadi, dokumen bukal lan saiki nggawe dolanan sing dibenalke denis Nambah, ndhek komentar kang dipun ngomong nik akeh sampeyan nganggo sampeyan sing luwih apik, iki dadi nggawe dolanan liyane kelas sing apik tenan apik. Ngawe nggambar nggo langgar-langgar task iki, kita gawe Poker Sum, dataset pernganggo dolanan sing dibenakno Chinese sing nduwe 5,48 dolanan ping komentar liyane lan nganggo pernganggo dolanan sing berarti Mungkin, kita nggunakake model sing duwe-pas mungkin bakal terusahaan ning sektor lan ngubah nambah kanggo strip-Sum . Peringatan nggawe barang nggawe dolang-dolang sing dibenakno Perintah sing paling maneh kuwi model sing gawe nggawe luwih apik dadi sing perusahaan banget nggawe roti sing dumadhi iki dadi sing dibenakno', 'sk': 'Povzetek športnih iger se osredotoča na ustvarjanje novic iz komentarjev v živo. Za razliko od tradicionalnih nalog povzetka so izvorni dokumenti in ciljni povzetki za naloge povzetka športnih iger napisani v precej različnih slogih pisanja. Poleg tega komentarji v živo običajno vsebujejo veliko imenovanih entitet, zaradi česar je povzemanje športnih iger zelo zahtevno. Za temeljito preučevanje te naloge predstavljamo SportsSum, kitajski nabor podatkov o povzetku športnih iger, ki vsebuje 5.428 nogometnih tekem komentarjev v živo in ustrezne novice. Poleg tega predlagamo dvostopenjski model povzetka, sestavljen iz selektorja in prenovitelja za SportsSum. Za oceno pravilnosti ustvarjenih športnih povzetkov oblikujemo dve novi meritvi rezultatov: rezultat ujemanja imen in rezultat ujemanja dogodkov. Eksperimentalni rezultati kažejo, da je naš model boljši od drugih izhodiščnih vrstic za povzetek rezultatov ROUGE in obeh oblikovanih rezultatov.', 'ha': "Samansa na gami na firam masu fokus na samun makala na lãbãri daga mai bayani na live. @ info: whatsthis Da wannan, faranta masu live ana ƙunsa da wasu abubuwa masu sune, wanda ke samu game da jimci na ƙayyade. Ko iya karatun wannan aikin da ake iya ƙaranci, Muna halatar da shirin gamuwa na idãnun firam na China, wanda na ƙunsa da gamuwa 5,428 na salon soccer mai bayani da kuma da takardar lãbãri masu inganci. Ina ƙaranci, za'a buƙata wata misalin ƙararin takis biyu wanda ke ƙunsa da wani mai zaɓa da wani mai rubutu wa SjotsSum. To, don ka ƙayyade gaskiyar gamawa da aka ƙãga, za'a ƙayyade metric biyu na noveli: sunan da ke daidaita score da shiryi mai daidai. Mataimakin jarrabawa na nuna cewa misalinmu yana sami mafi alhẽri daga matsali masu ƙararinsa a kan score na RUGE da sauri biyu wanda aka designe.", 'he': 'הספורטיזציה של משחקי ספורט מתמקדת על יוצרת מאמרים חדשות ממסכמות חיות. בניגוד למשימות סכם מסורתיות, מסמכי המקור והסכם המטרה למשימות סכם משחקי ספורט נכתבים בסגנונים כתיבה שונים לגמרי. בנוסף, הערות חיות בדרך כלל מכילות יחידות רבות בשמות, מה שעושה את המסכם של משחקי ספורט מאד מאתגר בדיוק. כדי ללמוד עמוק את המשימה הזאת, אנחנו מציגים SportsSum, קבוצת מידע של משחקי ספורט סיני שמכילה 5,428 משחקי כדורגל של תגובות חיות ומאמרי החדשות המתאימים. בנוסף, אנו מציעים מודל סדרה בשתי צעדים שמכיל מבחר ומכתב מחדש לספורט סאם. כדי להעריך את התאמה של סדרות ספורט יוצרות, אנחנו מעצבים שתי מטריות נקודות רומניות: נקודת תואמת שם וקודת תואמת אירועים. תוצאות ניסויים מראות שהמודל שלנו מופע טוב יותר מאשר קווי בסיס של סאמריזציה אחרים על נקודות ROUGE כמו גם שני נקודות המתכננות.', 'bo': 'Sports game summarization focuses on creating news articles from live comments. སྔོན་སྲོལ་རྒྱུན་ལྡན་གསར་བསྐྲུན་བྱེད་ཀྱི་བྱ་འགུལ་དང་ཐོག་མའི་ཡིག བསྡུར་ན། མི་ཚོགས་པའི་མཆན་བཤད་ཀྱི་ནང་དུ་མིང་ཡོད་པའི་དབུགས་ཆ་མང་པོ་ཡིན། འདི་ལྟ་བུའི་རྩོལ་བ་སྐྱོང་བའི་ནང་དུ་ང་ཚོར་རྩོལ་བ་མང་པོ་ཞིག་གི་སྡེབ་སྔོན་སྒྲིག་ཡོད། འོན་ཀྱང་། ང་ཚོས་འདེམས་པ་ཞིག་དང་རྩོམ་འབྲི་བརྗོད་པའི་གྲངས་སྒྲིག་ཆ་གཉིས་ཀྱི་མཇུག་བསྡུས་ཐབས་ལམ་ཞིག་བཤད་ནི་ To evaluate the correctness of generated sports summaries, we design two novel score metrics: name matching score and event matching score. Experimental results show that our model performs better than other summarization baselines on ROUGE scores as well as the two designed scores.'}
{'en': 'Improving  Context Modeling  in Neural Topic Segmentation', 'ar': 'تحسين نمذجة السياق في تجزئة الموضوع العصبي', 'pt': 'Aprimorando a modelagem de contexto na segmentação de tópicos neurais', 'fr': 'Amélioration de la modélisation contextuelle dans la segmentation neuronale', 'es': 'Mejorando el modelado de contexto en la segmentación de temas', 'hi': 'तंत्रिका विषय विभाजन में संदर्भ मॉडलिंग में सुधार', 'ja': 'ニューラルトピックセグメンテーションにおけるコンテキストモデリングの改善', 'ru': 'Совершенствование контекстного моделирования в сегментации нейронных тем', 'zh': '改进神经主题分中上下文建模', 'ga': 'Samhaltú Comhthéacs a Fheabhsú sa Deighilt ar Thopaicí Néaracha', 'ka': 'კონტექსტის მოდელირება ნეიროლური ტემიკური სეგენტიკაციაში', 'el': 'Βελτίωση της μοντελοποίησης περιβάλλοντος σε νευρωνική τμηματοποίηση θεμάτων', 'hu': 'A kontextusmodellezés javítása a neurális témaszegmentációban', 'it': 'Migliorare la modellazione del contesto nella segmentazione degli argomenti neurali', 'kk': 'Нейрондық нақышты сегментациясындағы контексттің үлгісін жақсарту', 'lt': 'Neural in ės teminės segmentacijos konteksto modeliavimo gerinimas', 'mk': 'Подобрување на моделирањето на контекст во сегментацијата на невралната тема', 'ms': 'Improving Context Modeling in Neural Topic Segmentation', 'ml': 'നെയുറല്\u200d വിഭാഗത്തിന്റെ വിഭാഗത്തിലുള്ള ഉള്ളിലുള്ള മോഡലിങ് മുന്\u200dകൂട്ടുന്നു', 'mt': 'Titjib fil-Mudellar tal-Kuntest fis-Segmentazzjoni Topika Newrali', 'mn': 'Сэтгэл сэдвийн загварын тухай Context Modeling сайжруулах', 'no': 'Forbetra kontekstmodellering i nøyralt temasegmentasjon', 'pl': 'Poprawa modelowania kontekstu w segmentacji tematów neuronowych', 'ro': 'Îmbunătățirea modelării contextului în segmentarea subiectelor neurale', 'sr': 'Poboljšanje modela konteksta u neuralnoj segmentaciji tema', 'si': 'සාමාන්\u200dය විශේෂ සෙග්ටිමන්ත්\u200dරයෙන් සංවේදනය වැඩි කරනවා', 'so': 'Horumarinta Modeling of Content in Neural Topic Segment', 'ta': 'புதிய தலைப்பு பிரிவில் உள்ளடக்கம் மாதிரியும்', 'sv': 'Förbättra kontextmodellering i neural ämnessegmentering', 'ur': 'Neural Topic Segmentation', 'uz': 'Name', 'vi': 'Cách tạo ngữ cảnh trong phân đoạn tiếp cận thần kinh', 'bg': 'Подобряване на контекстното моделиране в сегментацията на невралните теми', 'hr': 'Poboljšanje modela konteksta u segmentaciji neurone teme', 'da': 'Forbedring af kontekstmodellering i neural emnesegmentering', 'nl': 'Verbetering van contextmodellering in neurale topic segmentatie', 'id': 'Menembak Modeling Konteks dalam Segmentasi Topik Neural', 'de': 'Verbesserung der Kontextmodellierung in der Segmentierung neuronaler Themen', 'fa': 'بهتر کردن مدل محیط در بخش موضوع عصبی', 'ko': '신경 테마 분할 중 상하문 모델링 개선', 'sw': 'Kuboresha Utawala wa Mazingira katika Kugawanywa Mada ya Kiuraia', 'tr': 'Neural Meýdançasynda Mazmunlar Biýdalanýar', 'af': 'Verbeter Konteks Modelering in Nurale Tema Segmentasie', 'sq': 'Përmirësimi i modelimit të kontekstit në segmentimin e temave neuronale', 'am': 'ቦታ፦', 'hy': 'Նյարդային թեմային սեգմենտացիայի կոնտեքստի մոդելավորման բարելավումը', 'bn': 'নিউরাল বিষয়বস্তু বিভাগের মধ্যে বিষয়বস্তুর মোডেল উন্নতি করা হচ্ছে', 'az': 'Nöral Mevzu Segmentasiyasında Kontext Modelinə İcat Et', 'bs': 'Poboljšanje modela konteksta u neuralnoj segmentaciji tema', 'ca': 'millorar la modelació del context en la segmentació del tema neuronal', 'et': 'Kontekstimodelleerimise parandamine neuroteemade segmentatsioonis', 'cs': 'Zlepšení modelování kontextu v segmentaci neuronových témat', 'fi': 'Kontekstimallinnuksen parantaminen hermoaiheiden segmentoinnissa', 'jv': 'Gworongno Kontext model nang segmentasii Tema Nutral', 'sk': 'Izboljšanje modeliranja konteksta v segmentaciji nevralnih tem', 'ha': '@ action', 'he': 'שיפור מודל קונטקסט בסגמנטציה נושאית נוירואלית', 'bo': 'Neural Theme Segmentation ཐོག་གི་ཁོར་ཡུག་རྣམ་གྲངས་མ་དབྱིབས་ཡར་རྒྱས་གཏོང་བ'}
{'en': 'Topic segmentation is critical in key NLP tasks and recent works favor highly effective neural supervised approaches. However, current neural solutions are arguably limited in how they model context. In this paper, we enhance a segmenter based on a hierarchical attention BiLSTM network to better model context, by adding a coherence-related auxiliary task and restricted self-attention. Our optimized segmenter outperforms SOTA approaches when trained and tested on three datasets. We also the robustness of our proposed  model  in domain transfer setting by training a  model  on a large-scale dataset and testing it on four challenging real-world benchmarks. Furthermore, we apply our proposed  strategy  to two other languages (German and Chinese), and show its effectiveness in multilingual scenarios.', 'ar': 'يعد تجزئة الموضوع أمرًا بالغ الأهمية في مهام البرمجة اللغوية العصبية الرئيسية ، وتفضل الأعمال الحديثة مناهج عصبية عالية الفعالية تحت الإشراف. ومع ذلك ، يمكن القول إن الحلول العصبية الحالية محدودة في كيفية نمذجة السياق. في هذه الورقة ، قمنا بتحسين أداة التجزئة بناءً على شبكة BiLSTM ذات الاهتمام الهرمي لتحسين سياق النموذج ، عن طريق إضافة مهمة مساعدة مرتبطة بالتماسك والاهتمام الذاتي المقيد. يتفوق جهاز التجزئة المُحسَّن لدينا في الأداء على نهج SOTA عند تدريبه واختباره على ثلاث مجموعات بيانات. نحن أيضًا متانة نموذجنا المقترح في إعداد نقل المجال من خلال تدريب نموذج على مجموعة بيانات واسعة النطاق واختباره على أربعة معايير واقعية للتحدي. علاوة على ذلك ، نطبق استراتيجيتنا المقترحة على لغتين أخريين (الألمانية والصينية) ، ونظهر فعاليتها في سيناريوهات متعددة اللغات.', 'es': 'La segmentación de temas es fundamental en las tareas clave de la PNL y los trabajos recientes favorecen los enfoques supervisados neuronales altamente efectivos. Sin embargo, las soluciones neuronales actuales son posiblemente limitadas en la forma en que modelan el contexto. En este artículo, mejoramos un segmentador basado en una red BilsTM de atención jerárquica para modelar mejor el contexto, agregando una tarea auxiliar relacionada con la coherencia y una autoatención restringida. Nuestro segmentador optimizado supera los enfoques de SOTA cuando se capacita y se prueba en tres conjuntos de datos. También comprobamos la solidez de nuestro modelo propuesto en la configuración de transferencia de dominio al entrenar un modelo en un conjunto de datos a gran escala y probarlo en cuatro desafiantes puntos de referencia del mundo real. Además, aplicamos nuestra estrategia propuesta a otros dos idiomas (alemán y chino) y demostramos su eficacia en escenarios multilingües.', 'fr': "La segmentation des sujets est essentielle dans les tâches clés de la PNL et des travaux récents favorisent des approches supervisées neuronales hautement efficaces. Cependant, les solutions neuronales actuelles sont sans doute limitées dans la façon dont elles modélisent le contexte. Dans cet article, nous améliorons un segmenteur basé sur un réseau BilsTM d'attention hiérarchique afin de mieux modéliser le contexte, en ajoutant une tâche auxiliaire liée à la cohérence et une attention personnelle limitée. Notre segmenteur optimisé surpasse les approches SOTA lorsqu'il est formé et testé sur trois ensembles de données. Nous avons également apprécié la robustesse de notre modèle proposé dans le cadre du transfert de domaine en entraînant un modèle sur un ensemble de données à grande échelle et en le testant sur quatre points de référence difficiles du monde réel. En outre, nous appliquons la stratégie que nous proposons à deux autres langues (allemand et chinois) et montrons son efficacité dans des scénarios multilingues.", 'pt': 'A segmentação de tópicos é crítica em tarefas-chave de PNL e trabalhos recentes favorecem abordagens neurais supervisionadas altamente eficazes. No entanto, as soluções neurais atuais são indiscutivelmente limitadas em como modelam o contexto. Neste artigo, aprimoramos um segmentador baseado em uma rede BiLSTM de atenção hierárquica para melhorar o contexto do modelo, adicionando uma tarefa auxiliar relacionada à coerência e autoatenção restrita. Nosso segmentador otimizado supera as abordagens SOTA quando treinado e testado em três conjuntos de dados. Também avaliamos a robustez de nosso modelo proposto na configuração de transferência de domínio treinando um modelo em um conjunto de dados de grande escala e testando-o em quatro benchmarks desafiadores do mundo real. Além disso, aplicamos nossa estratégia proposta a outros dois idiomas (alemão e chinês) e mostramos sua eficácia em cenários multilíngues.', 'hi': 'विषय विभाजन प्रमुख एनएलपी कार्यों में महत्वपूर्ण है और हाल के काम अत्यधिक प्रभावी तंत्रिका पर्यवेक्षित दृष्टिकोणों के पक्ष में हैं। हालांकि, वर्तमान तंत्रिका समाधान यकीनन सीमित हैं कि वे संदर्भ को कैसे मॉडल करते हैं। इस पेपर में, हम एक पदानुक्रमित ध्यान BiLSTM नेटवर्क के आधार पर एक सेगमेंटर को बेहतर मॉडल संदर्भ में बढ़ाते हैं, एक सुसंगतता से संबंधित सहायक कार्य और प्रतिबंधित आत्म-ध्यान जोड़कर। हमारे अनुकूलित सेगमेंटर तीन डेटासेट पर प्रशिक्षित और परीक्षण किए जाने पर SOTA दृष्टिकोणों को मात देता है। हम बड़े पैमाने पर डेटासेट पर एक मॉडल को प्रशिक्षित करके और चार चुनौतीपूर्ण वास्तविक दुनिया के बेंचमार्क पर इसका परीक्षण करके डोमेन ट्रांसफर सेटिंग में हमारे प्रस्तावित मॉडल की मजबूती भी रखते हैं। इसके अलावा, हम अपनी प्रस्तावित रणनीति को दो अन्य भाषाओं (जर्मन और चीनी) पर लागू करते हैं, और बहुभाषी परिदृश्यों में इसकी प्रभावशीलता दिखाते हैं।', 'ja': 'トピックセグメンテーションは、主要なNLPタスクにおいて重要であり、最近の研究では、非常に効果的な神経監視アプローチが好まれている。しかしながら、現在のニューラルソリューションは、コンテキストをモデル化する方法において限定的であると言える。本稿では，コヒーレンス関連の補助タスクと制限された自己注意を追加することにより，階層的注意力BiLSTMネットワークに基づくセグメンタを強化してコンテキストをより良いモデル化する．当社の最適化されたセグメンテーターは、3つのデータセットでトレーニングとテストを行うと、SOTAアプローチを上回ります。また、大規模なデータセット上のモデルをトレーニングし、4つの現実の挑戦的なベンチマークでテストすることで、ドメイン転送設定における提案されたモデルの堅牢性を向上させます。さらに、提案された戦略を他の2つの言語（ドイツ語と中国語）に適用し、多言語シナリオでの有効性を示します。', 'zh': '太题分NLP至重,近事利高效神经督。 然则今之神经解决方案拟上下文可谓有限矣。 夫本文者,所以佐一致性受限自强,基于分BiLSTM网络之分割器,以善建模上下文也。 吾优化之分段器在三数集上练习优于SOTA法。 又以大集上练模形,试于四挑战性之实,域移置以为鲁棒性。 此外宜用二语(德语与中文),并展其多言之有效性。', 'ru': 'Сегментация по темам имеет решающее значение в ключевых задачах NLP, и недавние работы отдают предпочтение высокоэффективным нейронным контролируемым подходам. Тем не менее, текущие нейронные решения, возможно, ограничены в том, как они моделируют контекст. В этой статье мы улучшаем сегментатор, основанный на иерархическом внимании к сети BiLSTM, чтобы лучше моделировать контекст, добавляя связанную с когерентностью вспомогательную задачу и ограниченное самовнимание. Наш оптимизированный сегментатор превосходит подходы SOTA при обучении и тестировании на трех наборах данных. Мы также оцениваем надежность нашей предлагаемой модели в области настройки переноса доменов, обучая модель на крупномасштабном наборе данных и тестируя ее на четырех сложных контрольных показателях реального мира. Кроме того, мы применяем предлагаемую нами стратегию к двум другим языкам (немецкому и китайскому) и демонстрируем ее эффективность в многоязычных сценариях.', 'ga': 'Tá deighilt topaicí ríthábhachtach i bpríomhthascanna an NLP agus tá saothair le déanaí i bhfabhar cuir chuige néar-mhaoirsithe an-éifeachtach. Mar sin féin, d’fhéadfaí a mhaíomh go bhfuil réitigh néarúla reatha teoranta ó thaobh conas a mhúnlaíonn siad comhthéacs. Sa pháipéar seo, feabhsaítear deighleoir atá bunaithe ar ghréasán ordlathach aird BiLSTM chun comhthéacs múnla níos fearr, trí thasc cúnta a bhaineann le comhleanúnachas agus féin-aird srianta a chur leis. Is fearr lenár ndeighleogóir optamaithe cur chuige SOTA nuair a dhéantar oiliúint agus tástáil a dhéanamh ar thrí thacair sonraí. Déanaimid stóinseacht ár múnla molta maidir le socrú aistrithe fearainn trí mhúnla a oiliúint ar thacar sonraí mórscála agus é a thástáil ar cheithre thagarmharc fíordhomhanda dúshlánach. Ina theannta sin, cuirimid ár straitéis bheartaithe i bhfeidhm ar dhá theanga eile (Gearmáinis agus Sínis), agus léirímid a héifeachtúlacht i gcásanna ilteangacha.', 'ka': 'ტემიკური სეგმენტაცია კრიტიკურია NLP დავალებში და ახალი სამუშაო სამუშაო სამუშაო ნეიროლური დანარწმუნებული დახმარებაში. მაგრამ მიმდინარე ნეიროლური გარეშე არგებულია, როგორ მოდელურია კონტექსტი. ამ დომენტში ჩვენ სექმენტები იერაქტიკალური დაახლოებით BiLSTM ქსელის უკეთესი მოდელური კონტექსტის დამატებით, დამატებით კონტექსტების დამატებით დამატებით დამატებით დამა ჩვენი ოპტიმიზებული სეგმენტერი სამი მონაცემების შესახებ SOTA-ს შესახებ. ჩვენ ასევე გვაქვს ჩვენი მოდელის ძალიან ძალიან ძალიან ძალიან ძალიან დიომინური ტრანსტრინქციის შესაძლებლობაში მოდელის შესაბამისათვის დიდი დონტაქტის მონაცემების სექტის და გა დამატებით, ჩვენ ჩვენი საზოგადომის სტრატიგიას დავაყენებთ ორი სხვა ენაში (გერმანეთი და ჩინეთი) და მრავალური სინარიოში ჩვენ ჩვენ ჩვენი ეფექტიურობას', 'el': 'Η κατακερματισμός θεμάτων είναι κρίσιμη σε βασικές εργασίες και πρόσφατα έργα ευνοούν ιδιαίτερα αποτελεσματικές προσεγγίσεις με νευρική εποπτεία. Ωστόσο, οι τρέχουσες νευρωνικές λύσεις είναι αναμφισβήτητα περιορισμένες στον τρόπο που μοντελούν το πλαίσιο. Σε αυτή την εργασία, ενισχύουμε ένα τμήμα βασισμένο σε ένα ιεραρχικό δίκτυο προσοχής για καλύτερο πλαίσιο μοντέλου, προσθέτοντας μια βοηθητική εργασία που σχετίζεται με τη συνοχή και περιορισμένη αυτοπροσοχή. Το βελτιστοποιημένο τμήμα μας ξεπερνά τις προσεγγίσεις όταν εκπαιδεύεται και δοκιμάζεται σε τρία σύνολα δεδομένων. Επίσης, εξετάζουμε την ανθεκτικότητα του προτεινόμενου μοντέλου στη ρύθμιση μεταφοράς τομέων εκπαιδεύοντας ένα μοντέλο σε ένα σύνολο δεδομένων μεγάλης κλίμακας και δοκιμάζοντας το σε τέσσερις απαιτητικούς πραγματικούς δείκτες αναφοράς. Επιπλέον, εφαρμόζουμε την προτεινόμενη στρατηγική μας σε δύο άλλες γλώσσες (γερμανικά και κινέζικα), και αποδεικνύουμε την αποτελεσματικότητά της σε πολυγλωσσικά σενάρια.', 'hu': 'A témaszegmentáció kritikus fontosságú a kulcsfontosságú NLP feladatokban, és a legutóbbi munkák a rendkívül hatékony neurális felügyelt megközelítéseket támogatják. Azonban a jelenlegi neurális megoldások vitathatóan korlátozottak a kontextus modellezésében. Ebben a tanulmányban egy hierarchikus figyelemre épülő BiLSTM hálózaton alapuló szegmentálót javítunk a környezet jobb modellezésére, koherenciával kapcsolatos kiegészítő feladat és korlátozott önfigyelem hozzáadásával. Optimalizált szegmentőnk három adatkészleten képzett és tesztelt SOTA megközelítéseket felülmúlja. Továbbá a tervezett modellünk robusztusságát a domain transzfer beállításában azáltal is, hogy egy modellt képzünk egy nagyszabású adatkészletre és teszteljük azt négy kihívást jelentő valós referenciaértéken. Továbbá javasolt stratégiánkat két másik nyelvre (német és kínai) alkalmazzuk, és többnyelvű forgatókönyvekben mutatjuk be hatékonyságát.', 'it': "La segmentazione degli argomenti è fondamentale nei compiti chiave del PNL e lavori recenti favoriscono approcci neurosupervisionati altamente efficaci. Tuttavia, le attuali soluzioni neurali sono probabilmente limitate nel modo in cui modellano il contesto. In questo articolo, valorizziamo un segmenter basato su un'attenzione gerarchica BiLSTM network per modellare meglio il contesto, aggiungendo un compito ausiliario legato alla coerenza e limitata auto-attenzione. Il nostro segmenter ottimizzato supera gli approcci SOTA se addestrato e testato su tre set di dati. Abbiamo anche la robustezza del nostro modello proposto nell'impostazione del trasferimento di domini, formando un modello su un set di dati su larga scala e testandolo su quattro impegnativi benchmark del mondo reale. Inoltre, applichiamo la nostra strategia proposta ad altre due lingue (tedesco e cinese) e dimostriamo la sua efficacia in scenari multilingui.", 'lt': 'Teminis segmentavimas yra labai svarbus atliekant pagrindines NLP užduotis, o neseniai atlikti darbai skatina labai veiksmingus nervų priežiūros metodus. Tačiau dabartiniai neurologiniai sprendimai tikriausiai yra riboti modeliuojant kontekstą. Šiame dokumente didiname segmentą, pagrįstą hierarchiniu BiLSTM tinklo dėmesiu geresniam modelio kontekstui, pridėdami su nuoseklumu susijusią pagalbinę užduotį ir ribotą savarankišką dėmesį. Mūsų optimizuotas segmentatorius atlieka SOTA metodus, kai jis mokomas ir išbandomas trimis duomenų rinkiniais. Mes taip pat pasiūlyto modelio tvirtumą nustatant srities perdavimą, parengdami model į didelio masto duomenų rinkinyje ir išbandydami jį keturiais sunkiais realiojo pasaulio lyginamaisiais rodikliais. Furthermore, we apply our proposed strategy to two other languages (German and Chinese), and show its effectiveness in multilingual scenarios.', 'mk': 'Тематска сегментација е критична во клучните задачи на НЛП и неодамнешните дела се за многу ефикасни пристапи надгледувани од нервите. Сепак, сегашните нервни решенија се веројатно ограничени во тоа како тие моделираат контекст. Во овој документ, го зголемуваме сегментарот базиран на хиерархиско внимание на мрежата BiLSTM на подобар моделен контекст, додавајќи помошна задача поврзана со кохеренцијата и ограничено себеси внимание. Нашиот оптимизиран сегментер го надминува пристапот на SOTA кога е трениран и тестиран на три податоци. Ние, исто така, ја одржуваме и силноста на нашиот предложен модел во поставувањето на трансфер на домени преку обука на модел на голем компјутер на податоци и тестирање на четири предизвикувачки реални центри. Покрај тоа, ја применуваме нашата предложена стратегија на два други јазици (германски и кинески) и ја покажуваме нејзината ефикасност во повеќекратни сценарија.', 'kk': 'Нақыштың сегментациясы NLP тапсырмаларында қиын. Соңғы жұмыстар көп эффективті невралды бақылау арқылы көмектеседі. Бірақ назардағы невралдық шешімдері қалай контексті үлгілеу үшін шектелген. Бұл қағазда біз иерархиялық назарды BiLSTM желіне негізделген сегменттерді жақсы үлгі контекстіне көмектесу және өзіңізді шектелген көмектесу тапсырманы қосу арқылы біз шектеп береміз. Біздің оптимизацияланған сегментеріміз үш деректер жинақтарында оқылған және сынап алғанда SOTA жағдайларын шектеп береді. Сонымен қатар, біз доменге аудару параметрлерінің үлкен масштаб деректер жиынының үлгілігін оқыту арқылы, оны төрт әлемдегі қиын бағдарламаларда сынап көреміз. Қосымша, біз қолданатын стратегиямызды басқа екі тілде (неміс және қытайша) қолданатын және оның көптеген тілдер сценариясында әсерікті көрсетеді.', 'ms': 'Segmentasi topik adalah kritikal dalam tugas NLP kunci dan kerja baru-baru ini mendukung pendekatan yang diawasi saraf yang sangat berkesan. Namun, penyelesaian saraf semasa mungkin terbatas dalam bagaimana mereka model konteks. Dalam kertas ini, kami meningkatkan segmen berdasarkan perhatian hierarkis rangkaian BiLSTM kepada konteks model yang lebih baik, dengan menambah tugas bantuan berkaitan kesehatan dan perhatian diri yang terbatas. Segmen optimizasi kita melebihi pendekatan SOTA bila dilatih dan diuji pada tiga set data. Kami juga kekuatan model kami yang diusulkan dalam tetapan pemindahan domain dengan melatih model pada set data skala besar dan mengujinya pada empat tanda benchmark dunia nyata yang menantang. Selain itu, kami melaksanakan strategi kami yang direncanakan untuk dua bahasa lain (Jerman dan Cina), dan menunjukkan kegunaannya dalam skenario berbilang bahasa.', 'ml': 'പ്രധാനപ്പെട്ട വിഭാഗങ്ങള്\u200d NLP ജോലികളില്\u200d പ്രധാനപ്പെട്ടിരിക്കുന്നു. അടുത്ത പ്രവര്\u200dത്തിക്കുന്ന പ്രധാനപ്പെട എന്നാലും ഇപ്പോഴത്തെ ന്യൂറല്\u200d പരിഹരണങ്ങള്\u200d എങ്ങനെയാണ് മാതൃകയില്\u200d നിര്\u200dബന്ധമാക്കുന്നത്. ഈ പത്രത്തില്\u200d, നമ്മള്\u200d ഒരു ഹിയെരാര്\u200dക്കിക്കല്\u200d ശ്രദ്ധയില്\u200d അടിസ്ഥാനമായി ഒരു സെഗ്മെന്\u200dറര്\u200d കൂട്ടുന്നു. ബില്\u200dസ്റ്റമിലെ ശ്രദ്ധ ബില്\u200dസ്റ്റം നെറ് മൂന്നു ഡാറ്റാസറ്റുകളില്\u200d പരീക്ഷിക്കപ്പെടുകയും ചെയ്തപ്പോള്\u200d നമ്മുടെ ആഗ്രഹിക്കപ്പെട്ട സെഗ്മെന്\u200dറര്\u200d സ നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡലിന്റെ ആശ്വാസവും നമ്മള്\u200d ഒരു വലിയ വിവരങ്ങളുടെ ഡാറ്റാസെറ്റില്\u200d പരിശീലിക്കുന്നതും നാല് ലോകത്തെ വ അതിനുശേഷം, നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട യുദ്ധത്തിന് രണ്ടു ഭാഷകള്\u200dക്കും (ജര്\u200dമ്മന്\u200d ചൈനീസ്) പ്രയോഗിക്കുന്നു. അതിന്', 'mt': 'Is-segmentazzjoni tematika hija kritika f’kompiti ewlenin tal-NLP u xogħlijiet reċenti jiffavorixxu approċċi sorveljati newrali effettivi ħafna. Madankollu, is-soluzzjonijiet newrali attwali huma argwabbilment limitati f’kif jimmudellaw il-kuntest. In this paper, we enhance a segmenter based on a hierarchical attention BiLSTM network to better model context, by adding a coherence-related auxiliary task and restricted self-attention.  Is-segmentatur ottimizzat tagħna jwettaq approċċi SOTA meta jkun imħarreġ u ttestjat fuq tliet settijiet ta’ dejta. Aħna wkoll il-qawwa tal-mudell propost tagħna fl-istabbiliment tat-trasferiment ta’ dominji billi nħarrġu mudell fuq sett ta’ dejta fuq skala kbira u ntestjawh fuq erba’ punti ta’ riferiment ta’ sfida fid-dinja reali. Furthermore, we apply our proposed strategy to two other languages (German and Chinese), and show its effectiveness in multilingual scenarios.', 'mn': 'Сүүлийн үеийн сэдэв загвар нь NLP-ийн чухал ажил дээр чухал. Саяхан ажилладаг нь сэтгэл хөдлөлийн удирдлагатай ойлголтыг ашигладаг. Гэвч одоогийн мэдрэлийн шийдэл нь хэрхэн загвар загвараар хязгаарлагддаг. Энэ цаасан дээр бид биLSTM сүлжээ дээр сайн загварын тусламжтай тусламжтай ажил нэмж, өөртөө анхаарлыг хязгаарлаж, сайн загварын тусламжтай загвар дээр суурилуулдаг. Гурван өгөгдлийн сангийн туршилтаар сургалт болон шалгалт хийх үед бидний сайн сайн сайжруулагч SOTA арга барилгыг дамжуулдаг. Мөн бид холбооны шилжүүлэх хэмжээний загварын хүчтэй загварыг том хэмжээний өгөгдлийн сангийн загварыг суралцаж, үүнийг дөрвөн шаардлагатай жинхэнэ ертөнцийн багц дээр шалгаж үзүүлж байна. Мөн бид өөрсдийн санал өгсөн стратегийг өөр хоёр хэл (Герман болон Хятад) руу ашиглаж, олон хэл хувилбарт үр дүнтэй байдлыг харуулдаг.', 'no': 'Tema-segmentasjon er kritisk i nøkkeloppgåver NLP og nyleg fungerer for veldig effektive nøyraloversikte tilnærmingar. Det gjeldande neuralløysing er likevel begrenset i korleis dei modeller kontekst. I denne papiret forbedrar vi eit segmenter basert på eit hierarkisk oppmerksomhet på BiLSTM-nettverk til betre modellekontekst ved å leggja til ei koherens-relatert hjelpeoppgåve og avgrensa selvmerksomhet. Det optimaliserte segmenteret vår utfører SOTA-tilnærmingar når det trengte og testa på tre datasett. Vi har også kraftighet av vårt foreslått modell i domeneoverføring ved å trenga eit modell på ein stor skala datasett og testa det på fire vanskelege verdensbenchmarker. I tillegg kan vi bruke vårt foreslått strategi til to andre språk (tysk og kinesisk), og vise effektiviteten i fleirspråk scenarioar.', 'pl': 'Segmentacja tematyczna ma kluczowe znaczenie w kluczowych zadaniach NLP, a ostatnie prace sprzyjają wysoce skutecznym podejściom nadzorowanym neuronem. Jednak obecne rozwiązania neuronowe są prawdopodobnie ograniczone pod względem modelowania kontekstu. W niniejszym artykule udoskonaliliśmy segmenter oparty na hierarchicznej sieci uwagi BiLSTM do lepszego kontekstu modelu, dodając zadanie pomocnicze związane ze spójnością i ograniczoną uwagą na siebie. Nasz zoptymalizowany segmenter przewyższa podejścia SOTA, gdy jest przeszkolony i testowany na trzech zbiorach danych. Również solidność proponowanego modelu w ustawieniu transferu domen poprzez szkolenie modelu na dużej skali zbiorze danych i testowanie go na czterech wymagających rzeczywistych standardach odniesienia. Ponadto stosujemy proponowaną strategię do dwóch innych języków (niemieckiego i chińskiego) i pokazujemy jej skuteczność w wielojęzycznych scenariuszach.', 'ro': 'Segmentarea subiectelor este critică în sarcinile cheie ale PNL, iar lucrările recente favorizează abordările supravegheate neuronal extrem de eficiente. Cu toate acestea, soluțiile neurale actuale sunt, probabil, limitate în modul în care modelează contextul. În această lucrare, îmbunătățim un segmenter bazat pe o atenție ierarhică a rețelei BiLSTM pentru a modela mai bine contextul, prin adăugarea unei sarcini auxiliare legate de coerență și auto-atenție restrânsă. Sistemul nostru de segmentare optimizat depășește abordările SOTA atunci când este instruit și testat pe trei seturi de date. De asemenea, robustețea modelului propus în stabilirea transferului de domenii prin instruirea unui model pe un set de date la scară largă și testarea acestuia pe patru criterii de referință provocatoare din lumea reală. În plus, aplicăm strategia propusă în alte două limbi (germană și chineză) și demonstrăm eficacitatea acesteia în scenarii multilingve.', 'sr': 'Temska segmentacija je kritična u ključnim zadacima NLP-a, a nedavni radovi koriste veoma efikasne neuronske nadzorne pristupe. Međutim, trenutne neurološke rješenja su navodno ograničene u modelu konteksta. U ovom papiru, poboljšavamo segmenter a na temelju hijerarhijske pažnje BiLSTM mreže na bolji model kontekst, dodajući pomoæni zadatak povezan sa koherencijom i ograničeni samopouzdanje. Naš optimizirani segmenter iznosi SOTA pristupe kada je obučen i testiran na tri seta podataka. Takoðe smo i snažnost našeg predloženog model a u postavljanju prijenosa domena trenirajuæi model na velikoj skali podataka i testirati ga na četiri izazovne kriterije stvarnog sveta. Osim toga, mi primjenjujemo svoju predloženu strategiju na dva druga jezika (njemačka i kineska), i pokažemo svoju efikasnost u multijezičkim scenarijama.', 'si': 'ප්\u200dරශ්ණ විශේෂ විශේෂය NLP වැඩේ විශේෂ විශේෂ විශේෂයෙන් විශේෂ වෙනවා සහ අලුත් වැඩේ විශේෂ නමුත්, ප්\u200dරස්තූත න්\u200dයූරාල් විසරණය සීමාවිත් වෙනවා ඔවුන් කොහොමද සංවේදනය කරන්නේ කියලා. මේ පත්තරේ අපි සෙගෙම්ටර් එකක් විශේෂ කරනවා බිල්ස්ටිම් ජාලයේ හොඳ මොඩල් සම්බන්ධයකට, සම්බන්ධතාවය සම්බන්ධතාවක් සහ ස්වයංග්\u200dර අපේ විශ්වාසිත සෙගෙම්ටර් ඉදිරියට SOTA ප්\u200dරවේශනය කරන්න පුළුවන් සහ දත්ත සෙට් තුනක් පරීක්ෂණය කරන්න. අපි තමයි අපේ ප්\u200dරශ්නයක් විදිහට ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් ලොකු ප්\u200dරශ්නයක් තියෙන්නේ ප්\u200dරශ තවත්, අපි අනිත් භාෂාවක් දෙකට අපේ ප්\u200dරයෝජනය කරනවා (ජර්මන් සහ චීනියාවක්), ඒ වගේම ඒක ගොඩක් භාෂාවක් සි', 'so': 'Xiriirka shaqada NLP waa muhiim, shaqaalaha ugu dambeeyana waa raalli aad iyo aad u shaqeeya qaababka neural la ilaaliyo. Si kastaba ha ahaatee, xalalka neurada ee haatan ah waxaa si qiimo ah ugu xadgudbay sida ay u sameynayaan daboolka. Qoraalkan, waxaynu ku kordhinaynaa qof xil ah oo ku saleysan hierarchical attention BiLSTM shabakad si aan u beddelno daboolka ka fiican, waxaana ku daraynaa shaqo la xiriira sharciga islamarkaasna aan iska xadgudbayno. Xigmentheenna aad u optimisan waxay SOTA u soo bandhigtaa marka lagu tababaray oo lagu tijaabiyey saddexda databaset. Sidoo kale waxaynu ku tijaabnaa muusikadeenna la soo jeeday wareejinta guriga, tusaale baaraandegista danbiyada oo aad u weyn, waxaana ku tijaabinaynaa afar qiimayaasha caalamka ah. Sidoo kale, waxaynu qorshaha la soo jeeday u soo bandhignaynaa laba luqadood oo kale (Jarmal iyo Shiino), waxaana tusnaa waxyaabaheeda ku saabsan aragtida luuqadaha kala duduwan.', 'sv': 'Ämnessegmentering är avgörande i viktiga NLP-uppgifter och senaste arbeten gynnar mycket effektiva neurala övervakade metoder. Nuvarande neurala lösningar är dock utan tvekan begränsade i hur de modellerar kontext. I denna uppsats förstärker vi en segmenter baserad på en hierarkisk uppmärksamhet BiLSTM-nätverk för att bättre modellera sammanhang, genom att lägga till en sammanhållningsrelaterad hjälpuppgift och begränsad självuppmärksamhet. Vår optimerade segmentering överträffar SOTA-metoder när den tränas och testas på tre datauppsättningar. Vi har också robustheten hos vår föreslagna modell inom domänöverföring genom att utbilda en modell på en storskalig datauppsättning och testa den på fyra utmanande riktmärken i verkligheten. Dessutom tillämpar vi vår föreslagna strategi på två andra språk (tyska och kinesiska) och visar dess effektivitet i flerspråkiga scenarier.', 'ta': 'தலைப்பு பிரிவு NLP பணிகளில் முக்கியமானது மற்றும் சமீபத்தில் வேலை செய்கிறது மிகவும் வெளிப்படையான புதிய புதிய நெரு ஆனால், தற்போதைய புதிய தீர்வுகள் எவ்வாறு மாதிரிப்பு முறைமையில் வரையறுக்கப்பட்டுள்ளது. இந்த காகிதத்தில், நாம் ஒரு துண்டாக்கி பில்எஸ்டிஎம் பிணையத்தை அடிப்படையில் அதிகப்படுத்துகிறோம் மாதிரியின் சிறந்த மாதிரி சூழல் சேர்த மூன்று தகவல் அமைப்புகளில் பயிற்சிக்கப்பட்டு சோதிக்கப்பட்ட பின்னர் SOTA வெளியேறுகிறது. நாங்கள் ஒரு பெரிய அளவு தரவு அமைப்பில் ஒரு மாதிரியை பயிற்சி செய்து நான்கு சவாலிக்கும் உண்மையான உலக பென்கார்க்குகளில் சோதிக்கிற அதற்கும், நாம் எங்கள் முன்னோக்கப்பட்ட திட்டத்தை இரண்டு மொழிகளுக்கு (ஜெர்மன் மற்றும் சீனா) பயன்படுத்தி பல மொழிகள் காட்சியில', 'ur': 'موضوع سگرمیٹ NLP کے کاموں میں ضروری ہے اور اچھے کاموں میں بہت اثر اثر نائرول نظارت کی طریقے کے مطابق ہیں. حالانکہ موجود نیورل حل کی مدل کی طرح محدود ہوتی ہیں۔ اس کاغذ میں ہم ایک سیگنٹر کو زیادہ مہربانی دیتے ہیں جو BiLSTM نیٹ ورک پر بنیاد رکھتا ہے بہترین موڈل کے متصل میں، ایک مشترک مشترک تابع اور اپنی توجه محدود کرتی ہے۔ ہماری optimized segmenter SOTA approaches when trained and tested on three datasets. ہم نے بھی ڈومین ترنس سٹینٹ میں اپنی پیشنهاد کی مدل کی طاقت رکھی تھی، ایک بڑی اسکیل ڈاٹ سٹ پر ایک مدل کی آموزش کے ذریعہ اور چار چار مشکل دنیا کی بنچمٹ پر آزمائش کی تھی. اور ہم نے اپنے پیغمبر کی استراتژی کو دوسری زبانوں (جرمن اور چینی) پر لازم کیا ہے اور اس کی عمدگی مختلف زبانوں میں دکھاتے ہیں۔', 'uz': "Name Lekin, ҳозирги neyrol solutions o'zgarishlarni qanday model qilishda qisqarli. Bu qogʻozda biz bir xizmatni bir xizmatni biLSTM tarmoqda yaxshi model tarkibini qoʻshish va bir xizmatga bog'langan vazifani qoʻshish va o'zimni o'zimga qoʻshish mumkin. Bizning optimizdagi segmenter SOTA uchta maʼlumotlar satrda o'rganishda SOTA ishlab chiqaradi. Biz domen transfer modelimizning o'zgarishlarimizni ko'paytirish uchun katta maʼlumotlar satrini o'rganish modelini o'rganamiz va uni to'rtta dunyo haqiqiqiy parametrlarida sinab ko'raymiz. Ko'rib, biz yaxshi tashkilotlarimizni boshqa ikkita tilga (Olmon va Xitoycha) qo'llanmiz, va biz ko'plab tildagi xitoblar tilida ishlatishni ko'rsamiz.", 'vi': 'Phân loại chuột là vấn đề quan trọng trong các công việc chính của NMB, và các công việc gần đây ủng hộ các tiếp cận dây thần kinh giám sát hiệu quả. Tuy nhiên, các giải pháp thần kinh hiện tại được cho là hạn chế trong cách chúng mô hình ngữ cảnh. Trong tờ giấy này, chúng ta tăng cường một bộ chế dựa trên một mạng tập trung cấp cao BiLSTM để làm khung cảnh mô hình tốt hơn, bằng cách thêm một nhiệm vụ trợ giúp liên quan đến sự đồng bộ và tự chú ý hạn chế. Hệ thống gián điệp được tối đa hoàn thiện các phương pháp SOTA khi được huấn luyện và thử nghiệm trên ba tập tin. Chúng tôi cũng kiên trì trong việc thiết lập chuyển nhượng miền đề nghị bằng cách đào tạo một mô hình trên một bộ dữ liệu quy mô lớn và thử nghiệm nó trên bốn điểm hẹn thế giới thực đầy thử thách. Chúng tôi áp dụng chiến lược đề xuất vào hai ngôn ngữ khác (Đức và Trung Quốc) và cho thấy nó có hiệu quả trong các kịch bản đa dạng.', 'da': 'Emnesegmentering er kritisk i vigtige NLP-opgaver, og nylige arbejder favoriserer meget effektive neurale overvågede tilgange. Men nuværende neurale løsninger er sandsynligvis begrænset i, hvordan de modellerer kontekst. I denne artikel forbedrer vi en segmenter baseret på en hierarkisk opmærksomhed BiLSTM netværk til bedre modellering af kontekst, ved at tilføje en kohærens-relateret hjælpeopgave og begrænset selvopmærksomhed. Vores optimerede segmenter overgår SOTA-tilgange, når de trænes og testes på tre datasæt. Vi har også robustheden af vores foreslåede model inden for domæneoverførsel indstilling ved at træne en model på et stort datasæt og teste den på fire udfordrende virkelige benchmarks. Desuden anvender vi vores foreslåede strategi på to andre sprog (tysk og kinesisk) og viser dens effektivitet i flersprogede scenarier.', 'bg': 'Тематичната сегментация е от решаващо значение при ключовите задачи на НЛП и последните работи благоприятстват високо ефективни невронни надзорни подходи. Въпреки това, настоящите невронни решения са несъмнено ограничени в начина, по който моделират контекста. В тази статия ние подобряваме сегментатора, базиран на йерархична мрежа за по-добро моделиране на контекста, чрез добавяне на свързана с съгласуваност спомагателна задача и ограничено самовнимание. Нашият оптимизиран сегментатор превъзхожда подходите при обучение и тестване на три набора от данни. Ние също така осигуряваме здравината на нашия предложен модел в настройката за трансфер на домейни чрез обучение на модел върху мащабен набор от данни и тестване на него на четири предизвикателни показатели от реалния свят. Освен това, ние прилагаме предложената стратегия на два други езика (немски и китайски) и показваме нейната ефективност в многоезични сценарии.', 'hr': 'Temska segmentacija je kritična u ključnim zadatkima NLP-a i nedavni radovi koriste vrlo učinkovite neuronske nadzorne pristupe. Međutim, trenutne neurološke rješenje su argumentno ograničene u načinu modela konteksta. U ovom papiru, poboljšavamo segmenter a na temelju hijerarhičke pažnje BiLSTM mreže na bolji kontekst modela, dodajući pomoćni zadatak povezan s koherencijom i ograničeni samopouzdanje. Naš optimizirani segmenter iznosi SOTA pristupe kada je obučen i testiran na tri dataseta. Također smo snažni naš predloženi model u postavljanju prijenosa domena vježbamo model na velikoj skali podataka i testiramo ga na četiri izazovne kriterije stvarnog svijeta. Nadalje, primjenjujemo svoju predloženu strategiju na dva druga jezika (Njemačka i Kineska), i pokazujemo svoju učinkovitost u multijezičkim scenarijama.', 'nl': "Topic segmentatie is cruciaal in belangrijke NLP-taken en recente werken bevorderen zeer effectieve neurale begeleide benaderingen. De huidige neurale oplossingen zijn echter waarschijnlijk beperkt in hoe ze context modelleren. In dit artikel verbeteren we een segmenter gebaseerd op een hiërarchisch aandachts BiLSTM netwerk om een betere modelcontext toe te voegen, door een coherentie-gerelateerde hulptaak en beperkte zelfaandacht toe te voegen. Onze geoptimaliseerde segmenter presteert beter dan SOTA-benaderingen wanneer getraind en getest op drie datasets. We hebben ook de robuustheid van ons voorgestelde model in domeintransfer setting door een model te trainen op een grootschalige dataset en het te testen op vier uitdagende real-world benchmarks. Daarnaast passen we onze voorgestelde strategie toe op twee andere talen (Duits en Chinees), en tonen we de effectiviteit ervan in meertalige scenario's.", 'id': 'Topic segmentation is critical in key NLP tasks and recent works favor highly effective neural supervised approaches.  Namun, solusi saraf saat ini mungkin terbatas dalam bagaimana mereka model konteks. Dalam kertas ini, kami meningkatkan segmen berdasarkan perhatian hierarkis jaringan BiLSTM untuk konteks model yang lebih baik, dengan menambahkan tugas bantuan berkaitan dengan koerensi dan perhatian diri yang terbatas. Segmenter optimisasi kita melebihi pendekatan SOTA ketika dilatih dan diuji pada tiga set data. Kami juga kekuatan model kami yang diusulkan dalam pengaturan transfer domain dengan melatih model pada set data skala besar dan mengujinya pada empat tanda benchmark dunia nyata yang menantang. Selain itu, kami menerapkan strategi kami yang diusulkan untuk dua bahasa lainnya (Jerman dan Cina), dan menunjukkan efektifnya dalam skenario berbilang bahasa.', 'ko': '주제 분할은 관건적인 자연 언어 처리 임무에서 매우 중요하기 때문에 최근의 연구는 효율적인 신경 감독 방법을 지원한다.그러나 현재의 신경 해결 방안은 모델링 환경에서 제한을 받고 있다.본고에서 우리는 관련 보조 임무와 제한적인 자기주의를 추가함으로써 층별 주의를 바탕으로 하는 BilSTM 네트워크의 절분기를 강화하여 상하문을 더욱 잘 모의하고자 한다.세 개의 데이터 세트에서 훈련과 테스트를 진행할 때 우리가 최적화한 세그먼트의 성능은 SOTA 방법보다 우수하다.우리는 또한 대규모 데이터 집합에서 훈련 모델을 훈련하고 네 가지 도전적인 현실 기준에서 테스트를 실시하여 우리가 제시한 모델이 역 이동 설정에서의 노봉성을 검증했다.그 밖에 우리는 우리가 제시한 전략을 다른 두 가지 언어(독일어와 중국어)에 응용하고 다중 언어 장면에서 그 유효성을 보여 주었다.', 'de': 'Themensegmentierung ist bei wichtigen NLP-Aufgaben von entscheidender Bedeutung, und jüngste Arbeiten begünstigen hocheffektive neuronale überwachte Ansätze. Allerdings sind aktuelle neuronale Lösungen wohl begrenzt in der Art und Weise, wie sie Kontext modellieren. In diesem Beitrag erweitern wir einen Segmenter, der auf einem hierarchischen Aufmerksamkeits-BiLSTM-Netzwerk basiert, um einen besseren Modellkontext zu erzielen, indem wir eine kohärenzbezogene Hilfsaufgabe und eingeschränkte Selbstaufmerksamkeit hinzufügen. Unser optimierter Segmenter übertrifft SOTA-Ansätze, wenn er auf drei Datensätzen trainiert und getestet wird. Wir zeigen auch die Robustheit unseres vorgeschlagenen Modells in der Domänentransfereinstellung, indem wir ein Modell auf einem großen Datensatz trainieren und es an vier herausfordernden realen Benchmarks testen. Darüber hinaus wenden wir unsere vorgeschlagene Strategie auf zwei weitere Sprachen (Deutsch und Chinesisch) an und zeigen deren Wirksamkeit in mehrsprachigen Szenarien.', 'fa': 'بخش موضوع در وظیفه\u200cهای NLP کلید مهم است و کارهای اخیرا به سود دسترسی\u200cهای کنترل عصبی بسیار موثر است. با این حال، راه حل های عصبی فعلی در مورد مدل موجود محدود هستند. در این کاغذ، ما یک بخش\u200cکننده را بر اساس یک شبکه توجه\u200cی دایره\u200cآرایشی BiLSTM به موقعیت\u200cهای بهتر مدل\u200cهای بیشتری افزایش می\u200cدهیم، با اضافه کردن یک کار کمک\u200cکننده\u200cای با هماهنگی و توجه خود محدود می\u200cشود. گروهبان optimized ما در زمان آموزش و آزمایش در سه مجموعه داده\u200cها به SOTA نزدیک می\u200cشود. ما همچنین استعداد مدل پیشنهاد ما در انتقال دومین با آموزش یک مدل روی یک مجموعه داده های مقیاس بزرگ و آزمایش آن را روی چهار مقیاس جهان واقعی مشکل می کنیم. ما استراتژی پیشنهاد خود را به دو زبان دیگر (آلمان و چینی) استفاده می\u200cکنیم و فعالیت آن را در صحنه\u200cهای زیادی زبان نشان می\u200cدهیم.', 'sw': 'Kugawanywa kwa mada ni muhimu katika kazi muhimu za NLP na hivi karibuni inafanya kazi zinazopendekezwa sana na mbinu zinazofuatiliwa na neura. Hata hivyo, suluhisho la kisasa kwa kiasi kikubwa ni mipaka katika jinsi wanavyoelezea muktadha. Katika karatasi hii, tunaongeza mtangazaji kwa kutumia mtandao wa ufuatiliaji wa ubunifu wa BiLSTM kwa muktadha mzuri, kwa kuongeza jukumu la ushirikiano na kujizuia. Mgaidi wetu wenye matumaini zaidi hufanya kazi ya SOTA inapopata mafunzo na kujaribu kwenye seti tatu za data. We also the robustness of our proposed model in domain transfer setting by training a model on a large-scale dataset and testing it on four challenging real-world benchmarks.  Zaidi ya hayo, tunatumia mkakati wetu wa lugha mbili (Ujerumani na Kichina), na kuonyesha ufanisi wake katika mitazamo ya lugha mbalimbali.', 'tr': 'Tema segmentasiýasy NLP täbliklerinde wajyp möhüm. Ýakyndaky işleri näyral gözetleýän ýakynlary üçin örän täsirli näyral gözetleýän ýakynlary üçin ullanýarlar. Ýöne, häzirki näyral çözümler nähili görkezilýän çözümleri şartly çarpdy. Bu kagyzda, biz iýerarhiýa ünsli BiLSTM şebekesine gowy nusga daýanýarlar, kohereket bilen baglanýan kömek täbligini ekläp, özüne üns çykaryp barýarys. Biziň optimiz segmenterimiz üç datasetlerde test edilýän we test edilýän wagtynda SOTA yaklaýyşlaryny etýär. Biz hem biziň teklip eden nusgamyzyň güýçli şol domenyň üstünde örän ölçekli veri setirinde bir nusga öwrenip, muny dört güýçli dünýä benchmarklarynda testiň edip otyrdyk. Mundan soňra teklip eden strategiýamyzy başga iki dile uygulapdyr (Alman we Çin çe), we munyň etkinliýetini birnäçe dil senaryolarynda görkez.', 'af': "Tema-segmentasie is kritiese in sleutel NLP-taak en onlangse werk genader baie effektief neurale ondersoekte toegang. Maar, huidige neurale oplossing is argumenteel beperk in hoe hulle model konteks. In hierdie papier, verbeter ons 'n segmenter gebaseer op 'n hierarkiese aandag van BiLSTM netwerk na beter model konteks, deur 'n koherens-verwante hulpbruk en self-aandag te byvoeg. Ons optimaliseerde segmenter uitvoer SOTA toegang wanneer onderwerp en toets op drie datastel. Ons het ook die kragtigheid van ons voorgestelde model in domein oordrag instelling deur 'n model op 'n groot skaal datastel te onderwerp en dit te testeer op vier uitgelykende regte wêreld benchmarke. Ons het ook ons voorgestelde strategie aan twee ander tale (Duits en Sjinees) aanwend en sy effektiviteit in multitaalske scenarios vertoon.", 'hy': 'Թեմային սեգմետրացիան կարևոր է ՆԼՊ-ի հիմնական խնդիրներում, և վերջին աշխատանքները օգնում են շատ արդյունավետ նյարդային վերահսկվող մոտեցումներ: Այնուամենայնիվ, ներկայիս նյարդային լուծումները, հավանաբար, սահմանափակված են այն բանի մեջ, թե ինչպես են նրանք մոդելավորում կոնտեքստը: Այս թղթի մեջ մենք բարելավում ենք բիLSԹՄ ցանցի հիերարխիկ ուշադրության վրա հիմնված սեգմետրը ավելի լավ մոդելային կոնտեքստի համար, ավելացնելով կոնցենցիայի հետ կապված օգնական խնդիր և սահմանափակված ինքնաուշադրություն: Our optimized segmenter outperforms SOTA approaches when trained and tested on three datasets.  Մենք նաև մեր առաջարկված մոդելի ուժեղությունը բնագավառների փոխանցման միջոցով մեծ մասշտաբով տվյալների համակարգի մոդելի վարժեցնելով և ստուգելով այն չորս մարտահրավեր իրական աշխարհի համեմատական նպատակների վրա: Ավելին, մենք կիրառում ենք մեր առաջարկած ռազմավարությունը երկու այլ լեզուների (գերմաներեն և չինարեն) և ցույց ենք տալիս դրա արդյունավետությունը բազլեզու սցենարներում:', 'az': 'NLP vəzifələrində məsələlər segmentasiyası kritikdir və son işlər çox etkili nöral gözləyirləndirilən təsirlərə faydalanır. Halbuki, ağımdaki nöral çətinləri necə modellərində müəyyən edilmişdir. Bu kağıtda, hiyerarşik ünsü BiLSTM a ğına dayanan bir segmentçi daha yaxşı modellər məlumatına artırırıq, birləşdirilmiş köməkçi işləri və özünü müəyyən edərək. Bizim optimizləndirilmiş segmentçimiz üç verilən qutularda təhsil edilən və imtahana edilən SOTA yaxınlıqlarını daha üstün edər. Biz həmçin in domain transfer quruluşunda qurulduğumuz modellərin güclülüyünü böyük ölçüdə veri quruluğu təhsil edib dörd çətin dünya benchmarklarında imtahana çəkirik. Daha sonra, təklif etdiyimiz stratejimizi başqa iki dilə (Alman və Çin) uygulayıb çoxlu dil sahələrində etkinlik göstəririk.', 'sq': 'Segmentacioni tematik është kritik në detyrat kryesore të NLP dhe punët e fundit favorizojnë qasje shumë efektive të mbikqyrura nervore. Megjithatë, zgjidhjet aktuale nervore janë me siguri të kufizuara në mënyrën se si ato modelojnë kontekstin. Në këtë letër, ne përmirësojmë një segmenter bazuar në një rrjet hierarkik vëmendje BiLSTM në një kontekst më të mirë modeli, duke shtuar një detyrë ndihmëse lidhur me koherencën dhe vetëvëmendje të kufizuar. Segmenteri ynë optimizuar bën më tepër se SOTA-ja kur është trajnuar dhe testuar në tre grupe të dhënash. Ne gjithashtu fuqinë e model it tonë të propozuar në vendosjen e transferimit të fushës duke trajnuar një model në një grup të dhënash në shkallë të madhe dhe duke e testuar atë në katër pika të sfidave të botës reale. Përveç kësaj, ne zbatojmë strategjinë tonë të propozuar në dy gjuhë të tjera (gjermane dhe kineze) dhe tregojmë efektshmërinë e saj në skenarë shumëgjuhëse.', 'am': 'የጉዳዩ ግንኙነት በNLP ስራ ውስጥ አግባባዊ ነው እና በቅርብ ጊዜ የነዌብ ተሟጋቾች የጠቅላላ ግንኙነት በጣም የበለጠ ነው፡፡ ነገር ግን የአሁኑ የኔትራዊ መፍትሄ እንዴት እንደምታደርጉ ይደረጋሉ፡፡ በዚህ ፕሮግራም፣ የቢልSTM መረብ በመጠቀም የሚሻለውን የሞዴል ክፍል እናበዛለን፡፡ የተመረጠው አካባቢነታችን SOTA በሦስት ዳታተሮች ላይ በተፈተናና በተፈተና ጊዜ ይደረጋል፡፡ በተዘጋጀው የዶሜን መተላለፊያ ሞዴል የሞላፊነታችንን የ ትልቅ ዳታር ማሳየት እና በአራቱ የዓለምን አዋቂዎች ማሰናከል እናሞክረዋለን፡፡ በተጨማሪም፣ በተዘጋጀው strategieችንን ለሁለት ቋንቋዎች (የጀርመን እና ቻይና) እናሳየዋለን፡፡', 'bn': 'প্রধান এনএলপি কাজে বিষয়টির বিভিন্ন অংশগ্রহণ গুরুত্বপূর্ণ এবং সাম্প্রতিক কাজে নিউরেল পর্যবেক্ষণের প্রেক্ষাপগ তবে বর্তমান নিউরেল সমাধান কিভাবে তারা মডেল করেছে তাতে সীমিত। এই কাগজটিতে আমরা একটি প্রতিষ্ঠাতা বিএলস্টিএম নেটওয়ার্কের উপর ভিত্তিক মনোযোগ বৃদ্ধি প্রদান করি, যার মাধ্যমে সাথে সম্পর্কিত প্রতিযোগিতার কাজ আর নি আমাদের অপ্রাসঙ্গিক বিভিন্ন সংখ্যাকারীরা তিন তথ্য সেটে প্রশিক্ষণ ও পরীক্ষা করার সময় SOTA প্রতিযোগিতায় প্ আমাদের প্রস্তাবিত ডোমেইন পরিবর্তনের মডেলের রাস্তায় আমরা একটি বিশাল স্কেল ডাটাসেটে প্রশিক্ষণ দিয়েছি এবং চারটি চ্যালেঞ্জ বিশ্বের বেন এছাড়াও আমরা আমাদের প্রস্তাবিত কৌশল অন্য দুই ভাষায় (জার্মান এবং চীনা) প্রয়োগ করি এবং বহুভাষাভাষী দৃশ্যে তার কার্যকর্ষত', 'bs': 'Temska segmentacija je kritična u ključnim zadacima NLP-a, a nedavni radovi koriste veoma efikasne neuronske nadzorne pristupe. Međutim, trenutne neurološke rješenje su navodno ograničene u modelu konteksta. U ovom papiru, poboljšavamo segmenter a na temelju hijerarhičke pažnje BiLSTM mreže na bolji model kontekst, dodajući pomoćni zadatak povezan sa saslušanjem i ograničeni samopouzdanje. Naš optimizirani segmenter iznosi SOTA pristupe kada je obučen i testiran na tri dataseta. Također smo snažni naš predloženi model u postavljanju prijenosa domena vježbamo model na velikoj skali podataka i testiramo ga na četiri izazovne kriterije stvarnog svijeta. Osim toga, primjenjujemo našu predloženu strategiju na dva druga jezika (Njemačka i Kineska), i pokazujemo svoju učinkovitost u multijezičkim scenarijama.', 'et': 'Teema segmenteerimine on olulise tähtsusega NLP ülesannetes ja hiljutised tööd soodustavad väga tõhusaid närvijärelevalvega lähenemisviise. Praegused närvilahendused on siiski väidetavalt piiratud, kuidas need konteksti modelleerivad. Käesolevas töös tõhustame hierarhilisel tähelepanu BiLSTM võrgul põhinevat segmenteerijat paremaks mudelikontekstiks, lisades sidususega seotud abiülesande ja piiratud enesetähelepanu. Meie optimeeritud segmenteerija ületab SOTA lähenemisviise, kui seda koolitatakse ja testitakse kolme andmekogumiga. Samuti on meie väljapakutud mudeli tugevus domeeniülekande seadmisel, koolitades mudelit laiaulatuslikul andmekogumil ja testides seda nelja väljakutsuva reaalmaailma võrdlusaluse põhjal. Lisaks rakendame oma kavandatud strateegiat kahe teise keele (saksa ja hiina) suhtes ning näitame selle tõhusust mitmekeelsetes stsenaariumides.', 'cs': 'Segmentace témat je kritická v klíčových úkolech NLP a nedávné práce upřednostňují vysoce efektivní neuronově dohledované přístupy. Nicméně současná neuronová řešení jsou pravděpodobně omezená v tom, jak modelují kontext. V tomto článku rozšíříme segmenter založený na hierarchické BiLSTM síti pozornosti k lepšímu modelovému kontextu, přidáním pomocného úkolu souvisejícího s koherencí a omezené sebepozornosti. Náš optimalizovaný segmenter překonává SOTA přístupy, když je trénován a testován na třech datových sadách. Také robustnost našeho navrhovaného modelu v nastavení přenosu domén prostřednictvím školení modelu na rozsáhlém datovém souboru a testování jej na čtyřech náročných reálných referenčních měřítkách. Navrženou strategii aplikujeme i na dva další jazyky (němčinu a čínštinu) a ukazujeme její efektivitu v mnohojazyčných scénářích.', 'fi': 'Aihesegmentointi on kriittistä keskeisissä NLP-tehtävissä ja viimeaikaiset työt suosivat erittäin tehokkaita neurovalvottuja lähestymistapoja. Nykyiset hermoratkaisut ovat kuitenkin kiistatta rajallisia siinä, miten ne mallintavat kontekstia. Tässä artikkelissa parannamme hierarkkiseen BiLSTM-huomioverkostoon perustuvaa segmentointia parempaan mallikontekstiin lisäämällä johdonmukaisuuteen liittyvän aputehtävän ja rajoitetun itsehuomion. Optimoitu segmentointijärjestelmämme päihittää SOTA-lähestymistavat, kun se on koulutettu ja testattu kolmella datajoukolla. Lisäksi ehdotamme toimintamallimme luotettavuutta verkkotunnusten siirtoympäristössä kouluttamalla mallin laajamittaiseen dataan ja testaamalla sitä neljällä haastavalla reaalimaailman vertailuarvolla. Lisäksi sovellamme ehdotettua strategiaa kahteen muuhun kieleen (saksa ja kiina) ja osoitamme sen tehokkuuden monikielisissä skenaarioissa.', 'ca': "La segmentació temàtica és crítica en les tasques clau del NLP i les recents obres favoreixen enfocaments altament efectius supervisats neuronals. However, current neural solutions are arguably limited in how they model context.  En aquest paper, millorem un segmentador basat en una xarxa jeràrquica d'atenció BiLSTM a un context model millor, afegint una tasca auxiliar relacionada amb la coherencia i una autoatenció restringida. El nostre segmentador optimitzat supera els enfocaments SOTA quan està entrenat i provat en tres conjunts de dades. També la robustet del nostre model proposat en la configuració de transfer ències de dominis treinant un model en un conjunt de dades a gran escala i testant-lo en quatre punts de referència desafiants del món real. A més, aplicam la nostra estratègia proposada a dues altres llengües (alemanya i xinesa), i mostram la seva eficacia en escenaris multilingües.", 'sk': 'Segmentacija teme je ključnega pomena pri ključnih nalogah NLP, nedavna dela pa podpirajo visoko učinkovite nevronsko nadzorovane pristope. Vendar pa so sedanje nevronske rešitve verjetno omejene v tem, kako modelirajo kontekst. V tem prispevku smo izboljšali segmenter, ki temelji na hierarhični pozornosti BiLSTM mreži za boljši model konteksta, z dodajanjem koherentne pomožne naloge in omejene samopozornosti. Naš optimiziran segmenter presega pristope SOTA, ko je usposobljen in testiran na treh naborih podatkov. Tudi robustnost našega predlaganega modela pri določanju prenosa domen smo izobraževali model na obsežnem naboru podatkov in ga testirali na štirih zahtevnih merilih realnega sveta. Poleg tega našo predlagano strategijo uporabljamo za dva druga jezika (nemščina in kitajščina) in pokažemo njeno učinkovitost v večjezičnih scenarijih.', 'ha': "QXml Amma, an ƙayyade masu solar neura da ake kai yanzu a cikin yadda misalin su ke motsi. Daga wannan takardan, Munã ƙara wani segment based on an haɗi wa muhalli na hierrrchical aikin BiLSM zuwa mafi alhẽri motel context, da kuma Mu ƙara wani aikin mataimaki na haɗi da kuma ana ƙuntata kansa. @ info: whatsthis Tuna sami makarantar misalinmu da aka buɗe shi a cikin shifo-danne da za'a yi amfani da misalin wani misali a kan danne-danne masu girma kuma za'a jarraba shi a kan matabbata huɗu masu motsi a cikin duniya. Furan haka, muna amfani da aikin tufãtan da aka buƙata zuwa lugha biyu (Jamanci da China), kuma munã nuna masu amfani da fassararsa a cikin misalin mutane na'ura.", 'jv': 'segmentation politenessoffpolite"), and when there is a change ("assertive Nang paper iki, kita mulai segmenter sing basa saben nggo nyengke ditambah karo sistem sing luwih dumateng, BiSLT M kuwi nggawe layanan model sing luwih apik, nganggo nambah layanan sumelan karo koherence nggo ndelok sami nggo ndelok. section We tamben la botus of the proposal model in domain transfer settings by engaging a model on a big-scale dataset and testing it on 4 Ytambah, awak dhéwé ngerasakno kanggo ngerasakno iki luwih saben (German lan Cines), lan ngerasakno pengguna kuwi tindakan anyar neng sampek uga.', 'he': 'סגמנציה נושאית היא קריטית במשימות NLP מפתחות ועבודות לאחרונה מעדיפות גישות עצביות יעילות מאוד. עם זאת, פתרונות עצביים הנוכחיות מוגבלות בטח באיך הם דוגמנים הקשר. בעיתון הזה, אנחנו מגדילים סגמנטר מבוסס על תשומת לב היררכית רשת BiLSTM לקשר מודל טוב יותר, על ידי להוסיף משימה עזרית קשורה לכישוריות ותשומת לב עצמי מוגבלת. הסגמנטר האופטימיזם שלנו מוציא גישות SOTA כאשר מאומנים ובדיקות על שלושה קבוצות נתונים. We also the robustness of our proposed model in domain transfer setting by training a model on a large-scale dataset and testing it on four challenging real-world benchmarks.  בנוסף, אנו משתמשים באסטרטגיה המוצעת שלנו לשני שפות אחרות (גרמנית וסינית), ולהראות את היעילות שלה בתרחישות רבות שפות.', 'bo': 'གནད ཡིན་ནའང་། ད་ལྟའི་གནས་སྟངས་ཀྱི་ཐབས་ཤེས་དེ་གིས་ཇི་ལྟར་དཔེ་འགོད་པའི་སྟངས་འཛིན་ཏེ། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཡིག ང་ཚོའི་ཆེས་ཤུགས་ཀྱི་ཆ་རྐྱེན་གྱིས་སྨན་གཞི་སྒྲིག་ཚང་གསུམ་གྱི་ནང་ལས་བརྟག་དཔྱད་སྐབས་SOTA་གཟུགས་ཐལ We also the robustness of our proposed model in domain transfer setting by training a model on a large-scale dataset and testing it on four challenging real-world benchmarks. འོན་ཀྱང་། ང་ཚོས་སྔོན་སྒྲིག་གི་ཐབས་ལམ་ནི་སྐད་རིགས་གཞན་གཉིས་ལ་སྤྱོད་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Event Coreference Resolution with Non-Local Information', 'ar': 'حل تصديق الأحداث بالمعلومات غير المحلية', 'es': 'Resolución de correferencias de eventos con información no local', 'pt': 'Resolução de Correferência de Eventos com Informações Não Locais', 'fr': "Résolution de coréférence d'événement avec informations non locales", 'ja': '非ローカル情報を使用したイベントコアレファレンス解決', 'ru': 'Разрешение ядра события с помощью нелокальной информации', 'hi': 'गैर-स्थानीय जानकारी के साथ ईवेंट Coreference समाधान', 'zh': '有非地信息之事,协同询解析', 'ga': 'Taifeach Croíthagartha Imeachta le Faisnéis Neamh-Áitiúil', 'ka': 'მოვლენების კონფერენციის რეზიოციონი არა ლოკალური ინფორმაციის შესახებ', 'hu': 'Eseménykorreferencia feloldása nem helyi információkkal', 'el': 'Ψήφισμα συνέργειας συμβάντος με μη τοπικές πληροφορίες', 'kk': 'Оқиғаның қасиеттері жергілікті емес мәліметімен айырымдылығы', 'lt': 'Susitarimo sutikimo sprendimas su ne vietos informacija', 'it': 'Risoluzione della Coreferenza degli eventi con informazioni non locali', 'mk': 'Резолуција на коференцијата на настаните со нелокална информација', 'ms': 'Resolusi Kesempatan Kejadian dengan Maklumat Bukan Setempat', 'mn': 'Орон нутгийн мэдээлэл бус үйл ажиллагааны хамгийн сайн шалгалт', 'ml': 'ലോക്കല്\u200d വിവരങ്ങളുമില്ലാത്ത അവസ്ഥ കോര്\u200dഫെന്\u200dസ് വിശദീകരണം', 'mt': 'Riżoluzzjoni tal-Koreferenza tal-Avvenimenti b’Informazzjoni Mhux Lokali', 'no': 'Oppløysing av hendingshovud med ikkje- lokale informasjon', 'ro': 'Rezolvarea corefenței evenimentelor cu informații non-locale', 'pl': 'Rozwiązanie współpracy zdarzeń z informacjami nielokalnymi', 'sr': 'Резолюција кореферентности случаја са неместним информацијом', 'si': 'ස්ථානික තොරතුරු සමඟ අවස්ථානය ප්\u200dරමාණය', 'so': 'Heshiiska xafiiska dhacda ee macluumaadka aan degmada aheyn', 'sv': 'HĂ¤ndelsekonferenslĂ¶sning med icke-lokal information', 'ta': 'உள்ளமைப்பு தகவலுடன் நிகழ்வு மாற்று திரைத்திறன்', 'ur': 'غیر محلی معلومات کے ساتھ حادثہ قابل رخصت رخصت', 'uz': '@ info: whatsthis', 'vi': 'Thành quả cuối cùng', 'bg': 'Разрешаване на кореференцията на събитието с нелокална информация', 'hr': 'Rezolucija korisnosti događaja s neplokalnim informacijama', 'da': 'Løsning af begivenhedskoreference med ikke-lokale oplysninger', 'de': 'Resolution der Veranstaltung Coreferenz mit nicht-lokalen Informationen', 'id': 'Event Coreference Resolution with Non-Local Information', 'fa': 'راه حل پیشنهاد رویداد با اطلاعات غیر محلی', 'sw': 'Jukumu la Baraza la Event with Non-Local Information', 'nl': 'Resolutie van de Coreference van evenementen met niet-lokale informatie', 'tr': 'Ýeri gabul Maglumat bilen Çaşyrymy Däşerlik', 'af': '@ info: whatsthis', 'ko': '비국부적 정보의 사건은 모두 해소를 가리킨다', 'sq': 'Rezoluta e Koreferencës së Eventit me Informacione jo-lokale', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'az': 'Yerli Malümatı', 'bn': 'স্থানীয় তথ্যের সাথে ইভেন্ট সংক্রান্ত রিপশন', 'hy': 'Comment', 'bs': 'Rezolucija korisnosti događaja sa neplokalnim informacijama', 'ca': "Resolució de la Coreferència d'Events amb Informació No Local", 'et': 'Sündmuste korrektsiooni lahendamine mittekohalise teabega', 'fi': 'Tapahtumien yhteispäätösratkaisu muiden kuin paikallisten tietojen kanssa', 'cs': 'Řešení společné události s nemístními informacemi', 'ha': '@ action', 'sk': 'Reševanje korference dogodkov z nelokalnimi informacijami', 'he': 'פתרון תקופה עם מידע לא מקומי', 'jv': 'iCalImp', 'bo': 'འབྱུང་སྟངས་ལ་རང་ཁུལ་གྱི་མིན་པའི་གནས་ཚུལ་དང་མཉམ་འཛུགས་བྱེད་སྟངས'}
{'en': 'We present two extensions to a state-of-theart joint model for event coreference resolution, which involve incorporating (1) a supervised topic model for improving trigger detection by providing global context, and (2) a preprocessing module that seeks to improve event coreference by discarding unlikely candidate antecedents of an event mention using discourse contexts computed based on salient entities. The resulting  model  yields the best results reported to date on the KBP 2017 English and Chinese datasets.', 'fr': "Nous présentons deux extensions d'un modèle conjoint de pointe pour la résolution de coréférence d'événements, qui consistent à intégrer (1) un modèle de sujet supervisé pour améliorer la détection des déclencheurs en fournissant un contexte global, et (2) un module de prétraitement qui cherche à améliorer la coréférence d'événements en rejetant les candidats improbables les antécédents d'une mention d'événement utilisant des contextes de discours calculés sur la base d'entités saillantes. Le modèle résultant produit les meilleurs résultats rapportés à ce jour sur les ensembles de données anglais et chinois KBP 2017.", 'es': 'Presentamos dos extensiones a un modelo conjunto de última generación para la resolución de correferencias de eventos, que implican la incorporación de (1) un modelo de tema supervisado para mejorar la detección de desencadenantes al proporcionar contexto global, y (2) un módulo de preprocesamiento que busca mejorar la correferencia de eventos descartando candidatos improbables los antecedentes de una mención de un evento utilizando contextos de discurso calculados en función de entidades destacadas. El modelo resultante arroja los mejores resultados informados hasta la fecha en los conjuntos de datos en inglés y chino de KBP 2017.', 'pt': 'Apresentamos duas extensões para um modelo conjunto de última geração para resolução de correferência de eventos, que envolve a incorporação (1) de um modelo de tópico supervisionado para melhorar a detecção de gatilhos fornecendo contexto global e (2) um módulo de pré-processamento que busca melhorar a correferência de eventos descartando antecedentes candidatos improváveis de uma menção de evento usando contextos de discurso computados com base em entidades salientes. O modelo resultante produz os melhores resultados relatados até o momento nos conjuntos de dados KBP 2017 em inglês e chinês.', 'ar': 'نقدم امتدادين لنموذج مشترك حديث لقرار مرجع الحدث ، والذي يتضمن دمج (1) نموذج موضوع خاضع للإشراف لتحسين اكتشاف الزناد من خلال توفير سياق عالمي ، و (2) وحدة معالجة مسبقة تسعى إلى تحسين مرجعية الحدث من خلال نبذ السوابق المرشحة غير المحتملة لحدث يذكر باستخدام سياقات الخطاب المحسوبة على أساس الكيانات البارزة. ينتج عن النموذج الناتج أفضل النتائج التي تم الإبلاغ عنها حتى الآن على مجموعات البيانات الإنجليزية والصينية KBP 2017.', 'zh': '臣等陈先进共配合模二广,其(1)一监主模,以供全局上下文以善触发器检,及(2)一预处理模块,宜模块图弃用基于显实计语上下文事不太可能选前置以改善共配。 由是生KBP 2017英文及中文数据集上生迄今为止告之最也。', 'ja': '我々は、イベントコアレファレンス解決のための最先端の共同モデルに2つの拡張を提示し、これには、（ 1 ）グローバルコンテキストを提供することによってトリガ検出を改善するための監視されたトピックモデル、および（ 2 ）顕著なエンティティに基づいて計算された話題コンテキストを使用して、イベント言及の可能性の低い候補の前段階を破棄することによってイベントコアレフィケーションを改善しようとする前処理モジュールを組み込むことが含まれる。結果として得られたモデルは、KBP 2017の英語と中国語のデータセットで報告された最高の結果をもたらします。', 'hi': 'हम ईवेंट कोरेफेरेंस रिज़ॉल्यूशन के लिए एक स्टेट-ऑफ-द-आर्ट संयुक्त मॉडल के लिए दो एक्सटेंशन प्रस्तुत करते हैं, जिसमें (1) वैश्विक संदर्भ प्रदान करके ट्रिगर डिटेक्शन में सुधार के लिए एक पर्यवेक्षित विषय मॉडल को शामिल करना शामिल है, और (2) एक प्रीप्रोसेसिंग मॉड्यूल जो एक घटना के संभावित उम्मीदवार पूर्ववर्तियों को छोड़कर ईवेंट कोरेफेरेंस में सुधार करना चाहता है, जो मुख्य संस्थाओं के आधार पर गणना किए गए प्रवचन संदर्भों का उपयोग करके घटना के संदर्भों का उल्लेख करता है। परिणामी मॉडल KBP 2017 अंग्रेजी और चीनी डेटासेट पर आज तक रिपोर्ट किए गए सर्वोत्तम परिणाम देता है।', 'ru': 'Мы представляем два расширения к современной совместной модели разрешения ядра события, которые включают в себя (1) контролируемую тематическую модель для улучшения обнаружения триггера путем предоставления глобального контекста и (2) модуль предварительной обработки, который стремится улучшить ядро события путем отбрасывания маловероятных потенциальных предшественников упоминания события с использованием контекстов дискурса, вычисленных на основе явных сущностей. Полученная модель дает лучшие результаты, сообщенные на сегодняшний день в наборах данных KBP 2017 на английском и китайском языках.', 'ga': 'Cuirimid dhá shíneadh i láthair ar chomhshamhail úrscothach le haghaidh réiteach croí-chomhdhála imeachtaí, lena n-áirítear (1) samhail topaice maoirsithe chun braite truicear a fheabhsú trí chomhthéacs domhanda a sholáthar, agus (2) modúl réamhphróiseála a fhéachann le croíchomhdháil imeachtaí a fheabhsú. trí réamhinsint iarrthóirí neamhdhócha ar lua teagmhas a chaitheamh siar trí úsáid a bhaint as comhthéacsanna dioscúrsa arna ríomh bunaithe ar eintitis shuntasacha. Tugann an tsamhail mar thoradh air na torthaí is fearr a tuairiscíodh go dtí seo ar thacair sonraí KBP 2017 Béarla agus Síne.', 'ka': 'ჩვენ ჩვენ მხოლოდ ორი განზომილებების სხვადასხვა მოდელის შესახებ მოდელის შესახებ, რომელიც გოლობალური კონტექსტის განზომილების შესახებ (1) სხვადასხვა მოდელის შესახებ მოდელის შესახებ, და (2) პრეპროცესი მოდულია, რომელიც მოვლენების შესაძლებლობას გაუფლებელება მოვლენების შესაძლებლობა, რომელიც შეუძლებელია, რომ მოვლენების შესაძლებლობად კონდიდენტების ანტერესენტები გადარჩენა, რომელიც შემდეგ მოდელი იქნება ყველაზე საუკეთესო შემდეგ შემდეგ, რომელიც KBP 2017 ინგლისური და ჩინეთის მონაცემების შემდეგ შემდეგ შემდეგ.', 'el': 'Παρουσιάζουμε δύο επεκτάσεις σε ένα σύγχρονο κοινό μοντέλο επίλυσης συναλλακτικών γεγονότων, το οποίο περιλαμβάνει την ενσωμάτωση (1) ενός εποπτευόμενου μοντέλου θέματος για τη βελτίωση της ανίχνευσης σκανδαλών παρέχοντας παγκόσμιο πλαίσιο, και (2) μια ενότητα προεπεξεργασίας που επιδιώκει να βελτιώσει τη συνάφεια γεγονότων απορρίπτοντας απίθανες υποψήφιες προηγούμενες αναφορές ενός γεγονότος χρησιμοποιώντας πλαίσια λόγου που υπολογίζονται βάσει σημαντικών οντοτήτων. Το μοντέλο που προκύπτει αποδίδει τα καλύτερα αποτελέσματα που έχουν αναφερθεί μέχρι σήμερα στα σύνολα δεδομένων KBP 2017 αγγλικά και κινέζικα.', 'hu': 'Két kiegészítést mutatunk be az eseménycoreferencia megoldására vonatkozó korszerű közös modellhez, amelyek magukban foglalják (1) egy felügyelt témamodellt, amely globális kontextus biztosításával javítja a trigger detektálását, és (2) egy előfeldolgozó modul, amely arra törekszik, hogy javítsa az eseménycoreferenciát azáltal, hogy eldobja egy eseményemlítés valószínűtlen jelölt előzményeit a kiemelkedő entitások alapján kiszámított diskurzus kontextusok segítségével. Az így kapott modell a KBP 2017 angol és kínai adatkészleteiben eddig jelentett legjobb eredményeket eredményezi.', 'it': "Presentiamo due estensioni di un modello congiunto allo stato dell'arte per la risoluzione della coreferenza degli eventi, che comporta l'incorporazione (1) di un modello tematico supervisionato per migliorare il rilevamento dei trigger fornendo un contesto globale, e (2) un modulo di pre-elaborazione che cerca di migliorare la coreferenza degli eventi scartando improbabili antecedenti candidati di una menzione di evento utilizzando contesti di discorso calcolati sulla base di entità salienti. Il modello risultante fornisce i migliori risultati finora riportati sui set di dati in inglese e cinese KBP 2017.", 'lt': 'Pateikiame du naujus bendro renginių atitikties rezoliucijos modelio išplėtimus, kuriuose numatoma įtraukti (1) prižiūrėtą teminį model į siekiant pagerinti sprogmenų nustatymą, užtikrinant pasaulines aplinkybes, ir (2) parengiamojo apdorojimo modulis, kuriuo siekiama pagerinti įvykių atitiktį atmetant neįtikėtinus įvykio paminėjimo kandidatų antecedentus naudojant diskurso kontekstus, apskaičiuotus remiantis svarbiais subjektais. The resulting model yields the best results reported to date on the KBP 2017 English and Chinese datasets.', 'mk': 'Презентираме две проширувања на заедничкиот модел на состојба на театарот за резолуција на соодветните настани, кој вклучува вклучување (1) надгледуван модел на тема за подобрување на детекцијата на активаторите со обезбедување глобален контекст, И (2) препроцесиран модул кој се обидува да ја подобри соодветноста на настаните со отфрлање на најверојатните кандидатски претходи од споменување на настанот користејќи дискурсни контексти компјутирани врз основа на основни ентитети. Резултатот на моделот ги дава најдобрите резултати што досега се објавија за наборот на англиски и кинески податоци на КБП 2017.', 'kk': 'Біз оқиғалардың кеңейту үшін екі кеңейтулерін оқиғалардың кеңейту үлгісіне таңдаймыз. Оқиғалардың кеңейту үшін (1) бақылаған нақыштар үлгісін жасау үшін жүйелік контексті жақсарту үшін қо және (2) оқиғалардың қасиеттерін өзгерту үшін оқиғалардың қасиеттерін өзгерту үшін, ол оқиғалардың қасиеттерін өзгерту үшін әрекеттердің қасиеттерін өзгертуге болады. Бұл үлгі KBP 2017 ағылшын және қытайлық деректер жиындарының ең жақсы нәтижелерін береді.', 'ms': 'Kami perkenalkan dua sambungan ke model kongsi keadaan-teater untuk resolusi persamaan peristiwa, yang melibatkan memasukkan (1) model topik yang diawasi untuk meningkatkan pengesan pemicu dengan menyediakan konteks global, Dan (2) modul pemprosesan yang cuba memperbaiki persamaan peristiwa dengan membuang anteceden calon yang tidak mungkin disebut peristiwa menggunakan konteks diskors dikira berdasarkan entiti salient. Model yang menghasilkan memberikan keputusan terbaik yang dilaporkan hingga kini pada set data bahasa Inggeris dan Cina KBP 2017.', 'ml': 'നിര്\u200dണ്ണയിക്കുന്ന കോര്\u200dഫെന്\u200dസ് റിസ്റ്റേഷന്\u200dറെ സ്റ്റേറ്റ് സ്റ്റേറ്റ് സ്റ്റേറ്റ് സ്റ്റേറ്റ് മോഡലിലേക്ക് നമ്മള്\u200d രണ്ട് വികസിപ്പിക്കു (2) സംസാരിക്കുന്ന സംഭാഷണ കോണ്\u200dട്ടെക്സ്റ്റുകള്\u200d ഉപയോഗിച്ച് കണക്ട് ചെയ്യുന്ന സംസാരിക്കുന്നത് ഉപയോഗിച്ചുകൊണ്ട് സംസാരിക്കുന്ന സാര അതിന്റെ ഫലമായ മോഡല്\u200d കെബിപി 2017 ഇംഗ്ലീഷും ചൈനീസ് ഡാറ്റാസറ്റുകളും തീയതിയ്ക്കുള്ള ഏറ്റവും നല്ല ഫലം കൊണ്ടുവര', 'mt': "Aħna nippreżentaw żewġ estensjonijiet għal mudell konġunt ta' l-istat ta' l-art għar-riżoluzzjoni tal-koerenza ta' l-avvenimenti, li jinvolvi l-inkorporazzjoni (1) ta' mudell ta' suġġett sorveljat għat-titjib tad-detezzjoni ta' l-iskattaturi billi jipprovdi kuntest globali, ) u (2) modulu ta’ preproċessar li jfittex li jtejjeb il-koerenza ta’ avvenimenti billi jarmi anteċedenti mhux probabbli ta’ kandidati ta’ referenza ta’ avveniment bl-użu ta’ kuntesti ta’ diskors ikkalkulati abbażi ta’ entitajiet salienti. Il-mudell li jirriżulta jagħti l-aħjar riżultati rrappurtati sal-lum fis-settijiet tad-dejta Ingliż u Ċiniż tal-KBP 2017.", 'no': 'Vi presenterer to utvidingar til ein kopt modell for tilfelle for oppløysing av hendingar, som involverer inkludering av (1) eit oversikt temamodell for å forbetra utløysingar ved å gjera globalt kontekst, og (2) ein modul for forhandtering som forsøk å forbedra hendingsreferansen ved å avslutta sannsynlegvis kandidate anteanteanter av ei hendinga som mener ved å bruka diskurskontekstar rekna ut basert på salient einingar. Det resultatet modellet gjev dei beste resultatene som er rapportert til dato på KBP 2017-datasettet for engelsk og kinesisk.', 'mn': 'Бид үйл явдлын сайхан шийдвэрлэлийн төлөө хоёр давхар загварыг дэлгэцэн дэлхийн агуулалтыг сайжруулахын тулд (1) удирдлагатай сэдэв загварын загварыг нэмэгдүүлэх боломжтой болгодог. 2) үйл явдал дээр тооцоолж байгаа ярианы тухай ярилцлага орчин дээр тооцоолж өгсөн үйл явдал дээр тооцоолж байгаа хүмүүсийн тааламжтай сайжруулах боломжтой модуль. Үүний үр дүнтэй загвар нь 2017 оны KBP-ийн Англи болон Хятад өгөгдлийн сангийн хамгийн сайн үр дүнг гаргадаг.', 'pl': 'Przedstawiamy dwa rozszerzenia aktualnego wspólnego modelu rozwiązywania współdziałań zdarzeń, które obejmują włączenie (1) modelu nadzorowanego tematu w celu poprawy wykrywania wyzwalaczy poprzez zapewnienie globalnego kontekstu, oraz (2) moduł przetwarzania wstępnego, który ma na celu poprawę współdziałania zdarzeń poprzez odrzucenie mało prawdopodobnych kandydatów poprzedzających wzmiankę o zdarzeniu przy użyciu kontekstów dyskursu obliczonych na podstawie istotnych podmiotów. Otrzymany model daje najlepsze dotychczasowe wyniki zgłoszone na zbiorach danych KBP 2017 w języku angielskim i chińskim.', 'ro': 'Prezentăm două extensii ale unui model comun de rezolvare a corefenței evenimentelor, care implică încorporarea (1) unui model supravegheat pentru îmbunătățirea detectării declanșatorului prin furnizarea contextului global, și (2) un modul de pre-procesare care caută să îmbunătățească corefența evenimentelor prin eliminarea antecedentelor improbabile candidate ale unei mențiuni de eveniment folosind contexte de discurs calculate pe baza entităților saliente. Modelul rezultat oferă cele mai bune rezultate raportate până în prezent pe seturile de date din limba engleză și chineză KBP 2017.', 'si': 'අපි විස්තරයක් දෙකක් පෙන්වන්නේ ස්ථානයේ සංවිධානයක් සංවිධානයක් සඳහා සිද්ධ විස්තරයක් සඳහා සිද්ධ විස්තරයක් සඳහා සංවිධ සහ (2) ප්\u200dරතික්\u200dරියාපනය මොඩියෝල් එකක් සඳහා සිලියින් සිද්ධ විදියට පරීක්ෂා කරලා තියෙන්න පුළුවන් සිද්ධ විදියට පරීක්ෂණය කරලා ස ඉංග්\u200dරීසි 2017 වල ඉංග්\u200dරීසි සහ චීනි දත්ත සේට් වලින් තියෙන හොඳම ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති', 'so': "Waxaannu u fidinaynaa laba kororo oo u qoran qaab wadamada farshaxanta ah oo ku saabsan heshiiska qaybta dhacdooyinka, kaas oo ku saabsan soo gelinta (1) model maamul la ilaaliyo oo hagaajiya baaritaanka ganacsiga, si uu u sameyno qalabka caalamiga ah, (2) qalabka ka hor-socoshada oo doonaya inuu hagaajiyo kaararka dhacda marka lagu rido alaabta suurtagalka ah oo ay ku qoran yihiin isticmaalka qoraalka hadalka oo lagu xisaabiyay hay'adaha badbaadada. Tusaalada soo socda waxay soo bixisaa resultiyada ugu wanaagsan ee loo soo sheegay maalinta lagu soo qoray KBP 2017 Ingiriis iyo Shiino.", 'sr': 'Predstavljamo dve proširenje zajedničkom modelu za rezoluciju korisnosti događaja, koji uključuje uključivanje (1) nadzornog model a tema za poboljšanje otkrivanja okidača pružanjem globalnog konteksta, i (2) modul predobrađivanja koji pokušava poboljšati pristojnost događaja odbacivanjem nejverovatnije kandidatnih predsednika događaja koji se spominje korištenjem konteksta diskursa računalog na temelju salijanih entiteta. Rezultatni model daje najbolji rezultati koji su do sada prijavljeni na KBP engleskim i kineskim podacima 2017.', 'sv': 'Vi presenterar två förlängningar av en state-of-art gemensam modell för händelsecoreference lösning, som innebär att (1) en övervakad ämnesmodell för att förbättra trigger detection genom att tillhandahålla global kontext, och (2) en förbehandling modul som syftar till att förbättra händelsekorrefensen genom att kassera osannolika kandidatföreteelser av ett händelseomnämnande med hjälp av diskurskontexter som beräknats utifrån framträdande entiteter. Den resulterande modellen ger de bästa resultaten som hittills rapporterats på KBP 2017 engelska och kinesiska datauppsättningar.', 'ur': 'ہم نے ایک ایڈیونٹ کی شرکت کی ملکیت موڈل کے لئے دو اضافہ پیش کیے ہیں جن میں (1) ایک تحت نظر والی موڈل کے ذریعہ ایک سرپرست موڈل شامل ہوتا ہے جہالت کی کنٹیسٹ کے ذریعہ ترینگر شناسایی کو بہتر کرنے کے لئے، اور (2) ایک پرپرپروسینگ موڈیل جو ایڈینٹ کی مہربانی کو بہتر کرنے کی کوشش کرتا ہے، اس کے ذریعہ سے ایک ایڈینٹ کی مہربانی کا ذریعہ ذخیره کرنے والی ایڈینٹ کی مہربانی کے ذریعہ ایک ایسی ایڈینٹ کی مہربانی کے ذریعہ سے بصیرت کی کن نتیجہ موڈل نے KBP 2017 انگلیسی اور چینی ڈاٹ سٹ میں بہترین نتیجے پیش کئے ہیں۔', 'ta': 'நாம் நிகழ்வு குறிப்பு தீர்வு தெளிவுத்திற்கான நிலையில் இரண்டு விரிவாக்கத்தை கொண்டு வருகிறோம். இது (1) ஒரு பொருளை சேர்க்கும் பொருள் கண்டுபிட (2) விற்பனை பொருள் அடிப்படையில் கணிக்கப்பட்ட பேச்சு பொருட்களை பயன்படுத்தி பேச்சு முறைமையை மேம்படுத்துவதற்கான முன் செயல்படுத்தும் கூறு முடிவு மாதிரி கேபிபி 2017 ஆங்கிலம் மற்றும் சீனா தரவு அமைப்புகளில் அறிக்கப்பட்ட சிறந்த முடிவு', 'uz': "Biz hodisa birinchi darajada bir darajada bir kengaytmalarni hozir qilamiz. Bu hodisa bogʻ'liqning xossalari uchun (1) muhit modelini ajratish mumkin. @ info: whatsthis Name", 'vi': 'Chúng tôi giới thiệu hai phần mở rộng cho mô hình liên bang về cam go sự kiện giải quyết, gồm gồm: 1) một mô hình chủ đề được giám sát để phát hiện kích hoạt bằng cách cung cấp bối cảnh to àn cầu, và (2) một mô- đun xử lý trước nhằm cải thiện khả năng của sự kiện bằng cách loại bỏ những khả năng chưa chắc chắn ứng cử viên của một sự kiện tham gia đề cập sử dụng các ngữ cảnh được tính dựa trên các thực thể nổi tiếng. Kết quả của mẫu cung cấp những kết quả tốt nhất được báo cáo cho đến nay trên bộ dữ liệu kiểu Anh và Trung Quốc KBP 2007.', 'da': 'Vi præsenterer to udvidelser af en state-of-the-art fælles model for hændelsescoreference løsning, som indebærer at indarbejde (1) en overvåget emnemodel til forbedring af trigger detection ved at give global kontekst, og (2) et forbearbejdningsmodul, der søger at forbedre begivenhedskoreference ved at kassere usandsynlige kandidatforudsætninger for en begivenhedsomtale ved hjælp af diskurskontekster beregnet baseret på fremtrædende entiteter. Den resulterende model giver de bedste resultater, der hidtil er rapporteret på KBP 2017 engelske og kinesiske datasæt.', 'nl': 'We presenteren twee uitbreidingen van een state-of-the-art gezamenlijk model voor het oplossen van gebeurtenissen coreferenties, waarbij (1) een supervised topic model wordt opgenomen om triggerdetectie te verbeteren door wereldwijde context te bieden, en (2) een preprocessing module die ernaar streeft de samenhang van gebeurtenissen te verbeteren door onwaarschijnlijke kandidaat-antecedenten van een gebeurtenisvermelding te verwerpen met behulp van discourscontexten berekend op basis van opvallende entiteiten. Het resulterende model levert de beste resultaten op die tot nu toe zijn gerapporteerd op de KBP 2017 Engelse en Chinese datasets.', 'hr': 'Predstavljamo dvije proširenje zajedničkom modelu za rješenje odgovarajućih događaja, koji uključuje uključivanje (1) nadzornog model a tema za poboljšanje otkrivanja okidača pružanjem globalnog konteksta, i (2) modul predobrađivanja koji pokušava poboljšati pristojnost događaja odbacivajući vjerojatno kandidatne predsjednice događaja koji se spominju koristeći kontekste diskursa računali na temelju salijanih entitata. Rezultatni model daje najbolji rezultati koji su do sada prijavljeni na KBP engleskim i kineskim podacima 2017.', 'id': 'Kami mempersembahkan dua ekstensi untuk model kongsi negara-teater untuk resolusi koreferensi peristiwa, yang melibatkan inkorporasi (1) model topik yang diawasi untuk meningkatkan deteksi pemicu dengan menyediakan konteks global, Dan (2) modul pemroses yang berusaha memperbaiki persamaan peristiwa dengan membuang anteceden kandidat yang tidak mungkin disebutkan peristiwa menggunakan konteks diskors yang dihitung berdasarkan entitas salient. Model hasilnya memberikan hasil terbaik yang dilaporkan hingga saat ini pada set data Inggris dan Cina KBP 2017.', 'bg': 'Представяме две разширения на съвместен модел за решаване на съвкупността от събития, които включват включване на (1) надзорен тематичен модел за подобряване на откриването на спусъка чрез осигуряване на глобален контекст, и (2) модул за предварителна обработка, който се стреми да подобри кореференцията на събитията чрез отхвърляне на вероятните кандидатски предшественици на споменаване на събитие, използвайки дискурсни контексти, изчислени въз основа на видни субекти. Полученият модел дава най-добрите резултати, отчетени до момента за наборите от данни на английски и китайски.', 'de': 'Wir stellen zwei Erweiterungen eines aktuellen gemeinsamen Modells für die Lösung von Ereigniskorreferenzen vor, bei denen (1) ein überwachtes Themenmodell zur Verbesserung der Triggererkennung durch Bereitstellung eines globalen Kontexts integriert wird. und (2) ein Vorverarbeitungsmodul, das darauf abzielt, die Event-Coreferenz zu verbessern, indem unwahrscheinliche Kandidaten-Vorgänger einer Ereigniserwähnung verworfen werden, indem Diskurskontexte verwendet werden, die auf Basis von prominenten Entitäten berechnet wurden. Das resultierende Modell liefert die bisher besten Ergebnisse aus den englischen und chinesischen KBP 2017 Datensätzen.', 'fa': 'ما دو تفاوت را به یک مدل مشترک در حالت هنر برای حل\u200cسازی هماهنگی رویدادها پیشنهاد می\u200cکنیم، که شامل تولید (۱) یک مدل موضوع تحت نظر برای بهترین شناسایی ماشه\u200cسازی با تولید محیط جهانی است، و (۲) یک مدول پیش\u200cپردازی که تلاش می\u200cکند برای بهتر رضایت حادثه\u200cها با پاک کردن پیش\u200cبینی\u200cهای شایسته\u200cای از یک حادثه\u200cای که با استفاده از موضوع سخنرانی محاسبه شده بر اساس موضوع\u200cهای استفاده می\u200cشود. مدل نتیجه\u200cای بهترین نتیجه\u200cهای گزارش داده شده تا حالا در مجموعه\u200cهای انگلیسی و چینی KBP ۲۰۱۷ می\u200cدهد.', 'ko': '우리는 이벤트가 모두 해소되는 상태 연합 모델에 대해 두 가지 확장을 진행했다. (1) 전역 상하문을 제공함으로써 촉발 검측의 감독 주제 모델을 개선하고(2) 예처리 모듈은 현저한 실체 계산을 바탕으로 하는 언어 환경을 사용하여 사건에 언급된 불가능한 후보 선행어를 버리고 사건 공지를 개선하고자 한다.이로 인해 발생한 모델은 KBP 2017에서 영문 데이터 세트가 지금까지 보고한 가장 좋은 결과를 얻었다.', 'sw': 'Tunaweza kuonyesha maendeleo mawili katika muundo wa pamoja wa hali ya sanaa kwa ajili ya suluhisho la tukio hilo, ambalo linahusisha kuingiza (1) muundo wa mada uliothibitiwa kwa ajili ya kuboresha uchunguzi wa mwanzo kwa kutoa muktadha wa kimataifa, na (2) kifaa cha upasuaji kinacholenga kuboresha muungano wa tukio kwa kuacha matukio yanayowezekana ya wagombea wa tukio hilo kwa kutumia mazingira ya mazungumzo yanayohesabika kwa kutumia vitu vya uchunguzi. Mradi wa matokeo hayo unaleta matokeo bora yaliyoripotiwa katika taarifa za habari za KBP 2017 za Kiingereza na Kichina.', 'sq': 'Ne paraqesim dy zgjerime në një model të përbashkët shteti-teatër për zgjidhjen e bashkëdrejtimit të ngjarjeve, i cili përfshin përfshirjen (1) e një modeli tematike të mbikqyrur për përmirësimin e zbulimit të shkaktuesve duke ofruar kontekst global, dhe (2) një modul paraprocesues që kërkon të përmirësojë korreferencën e ngjarjeve duke hequr antecedentet e padyshim të kandidatit të një ngjarje përmendur duke përdorur kontekstet diskursore të llogaritura bazuar në njësi të rëndësishme. Modeli që rezulton jep rezultatet më të mira të raportuara deri tani në KBP 2017 të dhënave angleze dhe kineze.', 'af': "Ons stel twee uitbreidings voor 'n staat-van-die-kunsten joint model vir gebeurtenis koreferensieresolusie, wat insluit (1)  'n ondersoekte onderwerp model vir die verbetering van uitbreidings deur globale konteks te verskaf, en (2) â\x80\x99n voorafverwerking module wat soek na verbeter gebeurtenis van voorafverwerking deur onwaarskynlik kandidate antecedente van â\x80\x99n gebeurtenis te verwyder met gebruik van diskursie konteks wat bereken gebaseer op salient entiteite. Die resulteerde model gee die beste resultate wat op die KBP 2017 Engels en Sjinese datastel verspreek is.", 'tr': 'Bir hereket ta첵첵arlanmasy 체챌in 2 gola첵 nusgasyny ta첵첵arlanmasy 체챌in bir nusgasyna ewez ed첵채ris. Bu nusgasy d체n첵채b kontekste 체첵tgetmek 체챌in g철zetli bir tema nusgasyna dahil ed첵채r. 2) Ta첵dan ge챌irmek 체챌in bir fa첵ly n채dogry ta첵첵arlamak isle첵채n bir fa첵ly ta첵첵arlamak 체챌in bir fa첵ly n채dogry ta첵첵arlanan 챌yky힊 durumlaryny ulanmak 체챌in g철zle첵채n bir ta첵첵arlama modi. Netij채n nusgasy KBP 2017-nji I흫lis we 횉in챌e maglumaty흫 체stine g철rkezil첵채n netijeleri ta첵첵arlar.', 'am': 'በዓለምአቀፍ ክፍል በመስጠት የተጠበቀውን (1) የጦር አካባቢ አካባቢ አካባቢ አካባቢ አካባቢ እናደርጋለን፡፡ እና (2) በተገኘው የአካባቢ አካላት በተገኘው የንግግር ግንኙነቶች በተቃውሞ የተካሄደውን የአካባቢውን ክፍል ማሻሻል የሚፈልገውን የፕሮግራም ፕሮግራም ሚዲል ማድረግ ነው፡፡ ይህም ምሳሌ በKBP 2017 እና በቻይናዊ ዳታተርቶች ላይ የተለየውን ውጤቶች ያፈራል፡፡', 'hy': "Մենք ներկայացնում ենք երկու ընդլայնումներ իրադարձությունների համապատասխանատվության լուծման ընդհանուր մոդելի վրա, որը ներառում է (1) վերահսկված թեմային մոդելի ներառումը, որպեսզի բարելավվի խթանիչների հայտնաբերումը, տրամադրելով գլոբալ կոնտե Եվ (2) նախամշակվող մոդուլը, որը փորձում է բարելավել իրադարձությունների համապատասխանությունը' անհավանական թեկնածու նախադեպքերը հեռացնելով իրադարձությունների նշումների մասին, օգտագործելով խոսակցային կոնտեքստներ, որոնք հաշվարկվում են հիմնական էության վրա: Արդյունքում ստացված մոդելը բերում է մինչ օր ամենալավ արդյունքները, որոնք հայտարարվել են 2017-ի անգլերեն և չինական տվյալների համակարգերում:", 'az': 'Biz 2 uzaqlaşdırılır, dünya müxtəlif məlumatlarını təmizləyib təsirlərini yaxşılaşdırmaq üçün (1) gözləyirli məlumat modelini birləşdiririk. ( 2 ) və ( 2 ) olaraq yaxşılaşdırmaq istəyən tədbir modulu təmizləndirmək istəyir ki , bu tədbir mümkün olmayan tədbir tədbirlərini istifadə edərək, söhbət tədbirlərini istifadə edərək istifadə edilən tədbir tədbirlərini tərk edər . Sonuç modeli KBP 2017 İngilizce və Çin veri qurularında bildirilən ən yaxşı nəticələri verir.', 'bs': 'Predstavljamo dvije proširenje zajedničkom modelu za rezoluciju odgovarajućih događaja, koji uključuje uključivanje (1) model a nadzorne teme za poboljšanje otkrivanja okidača pružanjem globalnog konteksta, i (2) modul predobrađivanja koji želi poboljšati pristojnost događaja odbacivanjem nejverovatnije kandidatnih predsjednika događaja spomenunog na upotrebi konteksta diskursa računalog na temelju salijanih entitata. Rezultatni model daje najbolji rezultati koji su do sada prijavljeni na KBP engleskim i kineskim podacima 2017.', 'bn': 'আমরা অনুষ্ঠানের কোরেফারেন্স সিদ্ধান্তের জন্য একটি রাষ্ট্রীয় সংযুক্ত মডেলের দুটি বিস্তারিত বর্তমানে উপস্থাপন করি, যা বিশ্বের পরিসংখ্যা প্রদান করার এবং (২) একটি পূর্ব প্রক্রিয়ার মডিউল যা ব্যবস্থার ভিত্তিতে বিভিন্ন বিষয়বস্তু ব্যবহার করে বিভিন্ন কথোপকথন প্রতিযোগিতা ব্যবহার করে অনুষ্ঠানের কোর The resulting model yields the best results reported to date on the KBP 2017 English and Chinese datasets.', 'cs': 'Představujeme dvě rozšíření aktuálního společného modelu pro řešení koreferencí událostí, které zahrnují začlenění (1) modelu supervisovaného tématu pro zlepšení detekce triggerů poskytnutím globálního kontextu, a (2) předzpracovávací modul, který se snaží zlepšit koreferenci událostí odmítnutím nepravděpodobných kandidátských předchůdců zmínky události pomocí diskurzních kontextů vypočítaných na základě významných entit. Výsledný model přináší nejlepší dosavadní výsledky uvedené v datasetech KBP 2017 v angličtině a čínštině.', 'et': 'Esitleme kaks laiendust sündmuste kaassündmuste lahendamise hetkeolukorra ühismudelile, mis hõlmavad (1) järelevalve all oleva teemamudeli lisamist päästikute tuvastamise parandamiseks globaalse konteksti pakkumise kaudu, ja (2) eeltöötlusmoodul, millega püütakse parandada sündmuste kaasviidet, kõrvaldades sündmuste mainimise ebatõenäolised kandidaadi eelkäijad, kasutades silmapaistvate olemite põhjal arvutatud diskursustekstikke. Saadud mudel annab KBP 2017 inglise ja hiina andmekogumites seni esitatud parimad tulemused.', 'fi': 'Esittelemme kaksi laajennusta tapahtumakorferenssin ratkaisun nykytilaan liittyvään yhteiseen malliin, jotka sisältävät (1) valvotun teemamallin laukaisijan havaitsemisen parantamiseksi tarjoamalla globaalin kontekstin, ja (2) esikäsittelymoduuli, jolla pyritään parantamaan tapahtumakoreferenssiä hylkäämällä tapahtumamaininnan todennäköiset ehdokastaustat käyttämällä näkyviin entiteetteihin perustuvia diskurssikonteksteja. Tuloksena saatu malli tuottaa parhaat tähän mennessä raportoidut tulokset KBP 2017 englannin ja kiinan aineistoissa.', 'ca': "Presentam dues extensions a un model conjunt d'estat del teatre per a resoldre eventos de referència, que impliquen incorporar (1) un model de tema supervisat per millorar la detecció de disparadors proporcionant contexte global, i (2) un módul de preprocessió que busca millorar la coreferença d'esdeveniments eliminant antecedents poc probables de candidats d'una menció d'esdeveniments utilitzant contextes de discurs calculats basats en entitats salients. El model resultant produeix els millors resultats que s'han informat fins ara en els conjunts de dades anglès i xinès KBP 2017.", 'sk': 'Predstavljamo dve razširitvi state of theart skupnega modela za reševanje sredinskih dogodkov, ki vključujeta vključitev (1) nadzorovanega tematskega modela za izboljšanje zaznavanja sprožilca z zagotavljanjem globalnega konteksta, in (2) modul predobdelave, ki skuša izboljšati koreferenco dogodkov z zavržitvijo verjetnih predhodnih kandidatov omenjanja dogodka z uporabo diskurznih kontekstov, izračunanih na podlagi pomembnih entitet. Dobljeni model prinaša najboljše dosedanje rezultate v angleškem in kitajskem naboru podatkov KBP 2017.', 'ha': 'Tuna halatar da gwargwado biyu zuwa wani misali mai haɗi na-halin-kwance wa rabo-rayin aiki, wanda ke haɗa (1) da wani misali wanda aka tsare (1) da ya sami da shi ga gyare-ganin fassarar da ke samar da muhalli na duniya,  and (2) a preprocessing module that seeks to improve event coreference by discarding unlikely candidate antecedents of an event mention using discourse contexts computed based on salient entities.  @ info: status', 'he': 'אנו מציגים שני מחדשים למודל משותף של מדינת התיארט לפתרון אירועים מתאימים, אשר כולל הכילוי (1) מודל נושא מבוקש לשיפור זיהוי ההדקים על ידי סיפק קונטקסט גלובלי,  and (2) a preprocessing module that seeks to improve event coreference by discarding unlikely candidate antecedents of an event mention using discourse contexts computed based on salient entities.  המודל הנוצא מציג את התוצאות הטובות ביותר שנדווחות עד כה על קבוצת נתונים אנגלית וסינית KBP 2017.', 'bo': 'ང་ཚོས་རྒྱལ་ཁབ་འདི་ལྟ་བུའི་མཐུན་སྣེ་ཚོགས་ཀྱི་མ་དཔེ་བཀོད་པ་གཉིས་མཉམ་དུ་འཇུག་གི་ཡོད་ཚད་དང་མཐུན་སྒྲིག་གནད་དོན་རིམ་པ་ཞིག་ནང་དུ་བཙུགས་ཡོད - and (2) a preprocessing module that seeks to improve event coreference by discarding unlikely candidate antecedents of an event mentioned using discourse contexts computed based on salient entities. The following are: དབྱིབས་འབྱུང་བའི་མ་དབྱིབས་དུས་ཚོད་ལྟ་བུའི་མཐོང་སྣང་ཚུལ་གསལ་ཤོས་རྐྱེན་བྱས་མེད།', 'jv': 'Awak dhéwé éntuk sistem duwé esteraning nggawe sistem sistem sing dibenalke nggawe gerakan kanggo nggawe aksi nggawe geraksi (1) kang model sing titiro-titiro cara-titiro kanggo ngerasai winih dhéwé nggawe sistem sing berarti. 1 Model sing wis mbut dadi sing paling dhéwé dadi sing bakal ditambah sabanjuré nang K-bah Inggris lan dataset sing Chebas sabanjuré'}
{'en': 'Asking Crowdworkers to Write Entailment Examples : The Best of Bad Options A sking  C rowdworkers to  W rite  E ntailment  E xamples:  T he  B est of  B ad Options', 'es': 'Pedir a los trabajadores colectivos que escriban ejemplos de implicación: la mejor de las malas opciones', 'fr': "Demander aux travailleurs participatifs d'écrire des exemples d'implication\xa0: le meilleur des mauvaises options", 'ar': 'مطالبة عمال الحشود بكتابة أمثلة على الاستحواذ: أفضل الخيارات السيئة', 'pt': 'Pedindo aos Crowdworkers que escrevam exemplos de comprometimento: a melhor das más opções', 'ja': 'クラウドワーカーにエンターテイメントの例を書いてもらう：最良のオプション', 'hi': 'Crowdworkers से पूछना Entailment उदाहरण लिखने के लिए: बुरे विकल्पों का सबसे अच्छा', 'zh': '请众包工作者编示例:莫大恶择', 'ru': 'Попросить краудработников написать примеры втягивания: лучшие из плохих вариантов', 'ga': 'Ag Iarraidh ar Sluaite Eiseamláirí a Scríobh: Na Roghanna is Fearr', 'ka': 'კუპორდის მუშაობელების დაწერის მაგალითები: ყველაზე საუკეთესო პარამეტრები', 'hu': 'Példák írására a Crowdworkerek kérése: A legjobb a rossz lehetőségekből', 'el': 'Ζητώντας από τους Crowdworkers να γράψουν παραδείγματα: Οι καλύτερες από τις κακές επιλογές', 'it': 'Chiedere a Crowdworker di scrivere esempi di Entailment: il meglio delle opzioni cattive', 'kk': 'Жалпы мәселелерді жазу үшін сұрау: Жарамсыз параметрлердің ең жақсы', 'mk': 'Побарање од групите да пишуваат примери за проблеми: Најдобрите од лошите опции', 'lt': 'Klausimas darbuotojų rašyti ligos pavyzdžius: geriausios iš blogų pasirinkimų', 'ml': 'എന്\u200dടെയിലെന്\u200dറ് ഉദാഹരണങ്ങള്\u200d എഴുതാന്\u200d ക്രൌഡ് പണിക്കാരോട് ചോദിക്കുന്നു', 'mn': 'Бүтээлтийн жишээ бичихийг асууж байна: Сайн муу сонголтууд', 'ms': 'Meminta rakyat untuk menulis contoh penyakit: Opsyen Terbaik', 'mt': 'Li jitolbu lill-ħaddiema taċ-ċittadini biex jiktbu Eżempji ta’ Diżabilità: L-Aħjar Għażliet Mħażina', 'no': 'Spør krøvdarbeidarar om å skriva eksemplar for fullføring: The best of Bad Options', 'pl': 'Poproszenie Crowdworkerów o napisanie przykładów edycji: najlepsze ze złych opcji', 'ro': 'Solicitarea Crowdworkerilor să scrie exemple de implicare: cele mai bune opțiuni proaste', 'sr': 'Pitajući Crowdworkers da napišu primjere: Najbolje od loših opcija', 'sv': 'Be Crowdworkers att skriva Entailment Exempel: Det bästa av dåliga alternativ', 'si': 'ක්\u200dරෝඩ් වැඩකරුවන්ට අන්තිම විදිහට ලියන්න පුළුවන් උදාහරණය: The Better of Bad Options', 'so': 'Codsashada shaqaalaha Crowd in ay qoraan tusaale ahaan: Best Options Bad', 'ta': 'சிறந்த விருப்பங்கள்', 'ur': 'کروڈ کاروں سے پوچھتے ہیں کہ تمام مثالیں لکھیں: سب سے بہترین برے گزینے', 'uz': '@ info: whatsthis', 'vi': 'Yêu cầu Người công dân viết câu hỏi ví dụ: Những lựa chọn tồi tệ nhất', 'hr': 'Pitanje Crowdworkers da napišu primjere kompletnosti: Najbolje od loših opcija', 'bg': 'Помолете хората да напишат примери за справка: най-добрите от лошите опции', 'nl': 'Crowdworkers vragen om voorbeelden te schrijven: de beste van slechte opties', 'da': 'At bede Crowdworkere om at skrive eksempler på optagelse: Det bedste ved dårlige muligheder', 'de': 'Crowdworker bitten, Entailment-Beispiele zu schreiben: Das Beste der schlechten Optionen', 'id': 'Meminta para pekerja keramaian untuk menulis contoh penyakit: Pilihan terbaik yang buruk', 'fa': 'سؤال کردن کارگران برای نوشتن مثالهای کامل: بهترین گزینه های بد', 'ko': 'Crowdworkers에 은밀한 예를 쓰도록 요구합니다: 가장 좋은 나쁜 선택', 'sw': 'Kuwaomba wafanyakazi wa Crowd kuandika Mifano ya Ujumbe: Options bora', 'tr': 'Öňüm mysal ýazmakda işgärleri soraýarlar: iň gowy ýaman Opşenler', 'sq': 'Duke kërkuar nga turma që të shkruajnë shembuj të sëmundjes: opsionet më të mira të keqe', 'af': 'Vra Crowdworkers om volledige voorbeelde te skryf: Die beste van slegte opsies', 'am': 'የመድረክ ምርጫዎች', 'hy': 'Խնդրել ժողովրդի աշխատակիցներին գրել հիվանդության օրինակներ. The Best of վատ տարբերակները', 'bn': 'Asking Crowdworkers to Write Entailment Examples: The Best of Bad Options', 'az': 'Bütün məsəllər yazmağını soruşurlar: ən yaxşı pis seçimlər', 'bs': 'Pitajući Crowdworkers da napišu primjere kompletnosti: Najbolje od loših opcija', 'cs': 'Po탑찼d찼n챠 Crowdworker킁, aby napsali p힂챠klady vylep큄en챠: to nejlep큄챠 ze 큄patn첵ch mo탑nost챠', 'et': 'Palumine rahvatöötajatel kirjutada näiteid: parimad halbadest valikutest', 'fi': 'Joukkotyöntekijöiden pyytäminen kirjoittamaan Entailment Exemples: Parhaat huonot vaihtoehdot', 'ca': 'Asking Crowdworkers to Write Entailment Examples: The Best of Bad Options', 'he': 'מבקש מהעובדים לכתוב דוגמאות מחלה: אפשרויות הטובות ביותר', 'sk': 'Prosimo množične delavce, naj napišejo primere zapisov: najboljše od slabih možnosti', 'ha': 'KCharselect unicode block name', 'jv': 'Jejaring Kemerdekaan kanggo Kemerdekaan Entilment Sampeyan: Pilihan sing apik sing apik', 'bo': 'ཆ་འཕྲིན་གྱི་དཔེར་བརྗོད་ལ་སྤྱོད་མཁན་ཚོས་བརྗོད་དགོས། ཆ་འཕྲིན་ཡོད་པའི་དཔེར་བརྗོད：འདེམས་སྟངས'}
{'en': 'Large-scale natural language inference (NLI) datasets such as SNLI or MNLI have been created by asking crowdworkers to read a premise and write three new hypotheses, one for each possible semantic relationships (entailment, contradiction, and neutral). While this  protocol  has been used to create useful benchmark data, it remains unclear whether the writing-based annotation protocol is optimal for any purpose, since it has not been evaluated directly. Furthermore, there is ample evidence that crowdworker writing can introduce artifacts in the data. We investigate two alternative  protocols  which automatically create candidate (premise, hypothesis) pairs for annotators to label. Using these protocols and a writing-based baseline, we collect several new English NLI datasets of over 3k examples each, each using a fixed amount of annotator time, but a varying number of examples to fit that time budget. Our experiments on NLI and  transfer learning  show negative results : None of the alternative protocols outperforms the baseline in evaluations of  generalization  within NLI or on transfer to outside target tasks. We conclude that crowdworker writing still the best known option for entailment data, highlighting the need for further data collection work to focus on improving writing-based annotation processes.', 'es': 'Se han creado conjuntos de datos de inferencia de lenguaje natural (NLI) a gran escala, como SNLI o MNLI, pidiendo a los trabajadores colectivos que lean una premisa y escriban tres nuevas hipótesis, una para cada posible relación semántica (implicación, contradicción y neutralidad). Si bien este protocolo se ha utilizado para crear datos de referencia útiles, no está claro si el protocolo de anotación basado en escritura es óptimo para cualquier propósito, ya que no se ha evaluado directamente. Además, hay amplia evidencia de que la escritura colaborativa puede introducir artefactos en los datos. Investigamos dos protocolos alternativos que crean automáticamente pares de candidatos (premisa, hipótesis) para que los anotadores los etiqueten. Utilizando estos protocolos y una línea de base basada en la escritura, recopilamos varios conjuntos de datos nuevos de NLI en inglés de más de 3000 ejemplos cada uno, cada uno con una cantidad fija de tiempo de anotador, pero un número variable de ejemplos para ajustarse a ese presupuesto de tiempo. Nuestros experimentos sobre NLI y aprendizaje por transferencia muestran resultados negativos: ninguno de los protocolos alternativos supera la línea de base en las evaluaciones de generalización dentro de NLI o en la transferencia a tareas objetivo externas. Concluimos que la escritura colaborativa sigue siendo la opción más conocida para los datos de implicación, destacando la necesidad de un mayor trabajo de recopilación de datos para centrarse en mejorar los procesos de anotación basados en la escritura.', 'pt': 'Conjuntos de dados de inferência de linguagem natural (NLI) em larga escala, como SNLI ou MNLI, foram criados pedindo a crowdworkers para ler uma premissa e escrever três novas hipóteses, uma para cada possível relação semântica (implicação, contradição e neutra). Embora esse protocolo tenha sido usado para criar dados de referência úteis, ainda não está claro se o protocolo de anotação baseado em gravação é ideal para qualquer finalidade, pois não foi avaliado diretamente. Além disso, há ampla evidência de que a escrita de crowdworker pode introduzir artefatos nos dados. Investigamos dois protocolos alternativos que criam automaticamente pares candidatos (premissas, hipóteses) para os anotadores rotularem. Usando esses protocolos e uma linha de base baseada em escrita, coletamos vários novos conjuntos de dados NLI em inglês com mais de 3 mil exemplos cada, cada um usando uma quantidade fixa de tempo do anotador, mas um número variável de exemplos para se adequar a esse orçamento de tempo. Nossos experimentos em NLI e aprendizado de transferência mostram resultados negativos: nenhum dos protocolos alternativos supera a linha de base nas avaliações de generalização dentro do NLI ou na transferência para tarefas externas. Concluímos que a escrita de crowdworker ainda é a opção mais conhecida para dados de vinculação, destacando a necessidade de mais trabalho de coleta de dados para focar na melhoria dos processos de anotação baseados em escrita.', 'ar': 'تم إنشاء مجموعات بيانات الاستدلال اللغوي الطبيعي (NLI) على نطاق واسع مثل SNLI أو MNLI من خلال مطالبة العاملين في الحشد بقراءة فرضية وكتابة ثلاث فرضيات جديدة ، واحدة لكل علاقات دلالية محتملة (الاستنتاج والتناقض والحيادية). بينما تم استخدام هذا البروتوكول لإنشاء بيانات مرجعية مفيدة ، لا يزال من غير الواضح ما إذا كان بروتوكول التعليقات التوضيحية المستند إلى الكتابة هو الأمثل لأي غرض ، حيث لم يتم تقييمه بشكل مباشر. علاوة على ذلك ، هناك أدلة كثيرة على أن كتابة العامل الجماعي يمكن أن تقدم المصنوعات اليدوية في البيانات. نحن نحقق في بروتوكولين بديلين يقومان تلقائيًا بإنشاء أزواج مرشحة (فرضية وفرضية) للمعلقين لتسميةهم. باستخدام هذه البروتوكولات وخط الأساس القائم على الكتابة ، نقوم بجمع العديد من مجموعات بيانات NLI الإنجليزية الجديدة التي تضم أكثر من 3 آلاف مثال لكل منها ، كل منها يستخدم مقدارًا ثابتًا من وقت التعليق التوضيحي ، ولكن عددًا متنوعًا من الأمثلة لتلائم تلك الميزانية الزمنية. تُظهر تجاربنا على NLI وتعلم النقل نتائج سلبية: لا يتفوق أي من البروتوكولات البديلة على خط الأساس في تقييمات التعميم داخل NLI أو عند النقل إلى مهام مستهدفة خارجية. نستنتج أن كتابة العامل الجماعي لا يزال الخيار الأكثر شهرة لبيانات الاستلزام ، مما يبرز الحاجة إلى مزيد من أعمال جمع البيانات للتركيز على تحسين عمليات التعليقات التوضيحية المستندة إلى الكتابة.', 'fr': "Des ensembles de données d'inférence de langage naturel (NLI) à grande échelle tels que SNLI ou MNLI ont été créés en demandant aux travailleurs participatifs de lire une prémisse et d'écrire trois nouvelles hypothèses, une pour chaque relation sémantique possible (implication, contradiction et neutralité). Bien que ce protocole ait été utilisé pour créer des données de référence utiles, on ne sait toujours pas si le protocole d'annotation basé sur l'écriture est optimal à quelque fin que ce soit, puisqu'il n'a pas été évalué directement. En outre, il existe de nombreuses preuves que l'écriture participative peut introduire des artefacts dans les données. Nous étudions deux protocoles alternatifs qui créent automatiquement des paires candidates (prémisse, hypothèse) que les annotateurs doivent étiqueter. À l'aide de ces protocoles et d'une base de référence basée sur l'écriture, nous collectons plusieurs nouveaux ensembles de données NLI anglais de plus de 3 000 exemples chacun, chacun utilisant un temps d'annotation fixe, mais un nombre variable d'exemples pour s'adapter à ce budget de temps. Nos expériences sur le NLI et l'apprentissage par transfert montrent des résultats négatifs\xa0: aucun des protocoles alternatifs ne surpasse le niveau de référence dans les évaluations de la généralisation au sein du NLI ou sur le transfert vers des tâches cibles externes. Nous concluons que l'écriture participative reste l'option la plus connue pour les données d'implication, soulignant la nécessité de poursuivre le travail de collecte de données afin de se concentrer sur l'amélioration des processus d'annotation basés sur l'écriture.", 'hi': 'SNLI या MNLI जैसे बड़े पैमाने पर प्राकृतिक भाषा अनुमान (NLI) डेटासेट को crowdworkers को एक आधार पढ़ने और तीन नई परिकल्पनाओं को लिखने के लिए कहकर बनाया गया है, प्रत्येक संभावित शब्दार्थ संबंधों (अनिवार्यता, विरोधाभास और तटस्थ) के लिए एक। हालांकि इस प्रोटोकॉल का उपयोग उपयोगी बेंचमार्क डेटा बनाने के लिए किया गया है, यह स्पष्ट नहीं है कि लेखन-आधारित एनोटेशन प्रोटोकॉल किसी भी उद्देश्य के लिए इष्टतम है या नहीं, क्योंकि इसका सीधे मूल्यांकन नहीं किया गया है। इसके अलावा, पर्याप्त सबूत हैं कि क्राउडवर्कर लेखन डेटा में कलाकृतियों को पेश कर सकता है। हम दो वैकल्पिक प्रोटोकॉल की जांच करते हैं जो स्वचालित रूप से लेबल करने के लिए एनोटेटर के लिए उम्मीदवार (आधार, परिकल्पना) जोड़े बनाते हैं। इन प्रोटोकॉल और लेखन-आधारित आधार रेखा का उपयोग करते हुए, हम प्रत्येक 3k से अधिक उदाहरणों के कई नए अंग्रेजी एनएलआई डेटासेट एकत्र करते हैं, जिनमें से प्रत्येक एनोटेटर समय की एक निश्चित मात्रा का उपयोग करता है, लेकिन उस समय बजट को फिट करने के लिए उदाहरणों की एक अलग संख्या। एनएलआई और ट्रांसफर लर्निंग पर हमारे प्रयोग नकारात्मक परिणाम दिखाते हैं: वैकल्पिक प्रोटोकॉल में से कोई भी एनएलआई के भीतर सामान्यीकरण के मूल्यांकन में आधार रेखा को बेहतर नहीं करता है या बाहरी लक्ष्य कार्यों में स्थानांतरण पर। हम निष्कर्ष निकालते हैं कि crowdworker लेखन अभी भी अनिवार्य डेटा के लिए सबसे अच्छा ज्ञात विकल्प है, लेखन-आधारित एनोटेशन प्रक्रियाओं में सुधार पर ध्यान केंद्रित करने के लिए आगे के डेटा संग्रह कार्य की आवश्यकता को उजागर करता है।', 'ja': 'SNLIやMNLIなどの大規模な自然言語推論（ NLI ）データセットは、クラウドワーカーに前提を読み取って3つの新しい仮説を書くように依頼することによって作成されています。これは、可能な意味関係（帰結、矛盾、および中立）ごとに1つです。 このプロトコルは有用なベンチマークデータを作成するために使用されていますが、書き込みベースのアノテーションプロトコルが直接評価されていないため、どのような目的に最適かはまだ不明です。 さらに、クラウドワーカーの書き込みがデータにアーティファクトを導入できるという十分な証拠があります。 注釈者がラベル付けする候補（前提、仮説）ペアを自動的に作成する2つの代替プロトコルを調査します。 これらのプロトコルと書き込みベースのベースラインを使用して、私たちは3 k以上の例のいくつかの新しい英語のNLIデータセットを収集し、それぞれが固定量のアノテーター時間を使用しますが、その時間予算に合わせてさまざまな数の例を使用します。 NLIと転移学習に関する私たちの実験は、否定的な結果を示しています。NLI内の一般化の評価や外部のターゲットタスクへの転送では、代替プロトコルのいずれもベースラインを上回ることはありません。 私たちは、クラウドワーカーによる書き込みが、依然として関連データの最もよく知られたオプションであると結論付け、書き込みベースの注釈プロセスの改善に焦点を当てるために、さらなるデータ収集作業の必要性を強調しています。', 'zh': '大自然语言推理(NLI)数集(如SNLI若MNLI),因众包工作者读取前提而编三新假设以创之,每设应语义(蕴涵,矛盾中立)。 虽协议已施于有用之准数,而未详其注释之可否,以其未直评也。 至于证据表明,众包引伪影数据。 臣等考二代协议,当自创候选(前提,假设)对,供注释者标记。 用此协基线,吾得数新英语NLI数集,每数过3000示例,每集用定注,然不同数者示例以适宜时间预算。 NLI迁学实验示负面:NLI内泛化评移外任,无替协议优基线。 臣等所论,众包工作者文犹蕴涵数之最知名者也,凸显增数采必要性,专注于改注。', 'ru': 'Масштабные наборы данных вывода естественного языка (NLI), такие как SNLI или MNLI, были созданы путем обращения к краудерам с просьбой прочитать предпосылку и написать три новые гипотезы, по одной для каждой возможной семантической связи (влечение, противоречие и нейтральность). Хотя этот протокол использовался для создания полезных эталонных данных, остается неясным, является ли протокол аннотации на основе записи оптимальным для какой-либо цели, поскольку он не оценивался непосредственно. Кроме того, существует достаточно доказательств того, что краудбрейкер может вносить артефакты в данные. Мы исследуем два альтернативных протокола, которые автоматически создают пары-кандидаты (предпосылки, гипотезы) для аннотаторов для маркировки. Используя эти протоколы и базовую линию на основе письменной формы, мы собираем несколько новых наборов данных NLI на английском языке, каждый из которых содержит более 3 тыс. примеров, каждый из которых использует фиксированное количество времени аннотации, но различное количество примеров, чтобы соответствовать этому временному бюджету. Наши эксперименты по изучению NLI и передачи показывают отрицательные результаты: ни один из альтернативных протоколов не превосходит базовый уровень в оценках обобщения в рамках NLI или при переходе к внешним целевым задачам. Мы приходим к выводу, что краудбрейк по-прежнему является наиболее известным вариантом данных о влечении, подчеркивая необходимость дальнейшей работы по сбору данных, чтобы сосредоточиться на улучшении процессов аннотирования на основе письменной формы.', 'ga': 'Cruthaíodh tacair sonraí ar mhórscála tátal teanga nádúrtha (NLI) ar nós SNLI nó MNLI trí iarraidh ar oibrithe sluaite bunphrionsabal a léamh agus trí hipitéis nua a scríobh, ceann amháin do gach caidreamh shéimeantach féideartha (tiontúlacht, contrárthacht, agus neodrach). Cé gur úsáideadh an prótacal seo chun sonraí tagarmharcála úsáideacha a chruthú, níl sé soiléir fós an bhfuil an prótacal nótaí scríofa optamach chun críche ar bith, ós rud é nach ndearnadh meastóireacht dhíreach air. Ina theannta sin, tá go leor fianaise ann gur féidir le scríbhneoireacht slua-oibrithe déantáin a thabhairt isteach sna sonraí. Déanaimid imscrúdú ar dhá phrótacal eile a chruthaíonn go huathoibríoch péirí iarrthóra (maoin, hipitéis) le haghaidh nótaíeoirí a lipéadú. Ag baint úsáide as na prótacail seo agus bunlíne bunaithe ar scríbhneoireacht, bailímid roinnt tacar sonraí nua de chuid LNÉ Béarla de níos mó ná 3k sampla an ceann, gach ceann ag baint úsáide as méid seasta ama anótaire, ach líon éagsúil samplaí a d’oirfeadh don bhuiséad ama sin. Léiríonn ár dturgnaimh ar LNÉ agus foghlaim aistrithe torthaí diúltacha: Ní sháraíonn aon cheann de na prótacail mhalartacha an bhunlíne i meastóireachtaí ar ghinearálú laistigh de LNÉ nó ar aistriú chuig tascanna sprice lasmuigh. Bainimid de thátal as go bhfuil an scríbhneoireacht slua-oibrithe fós ar an rogha is fearr aitheanta maidir le sonraí teagmhála, rud a léiríonn an gá atá le tuilleadh oibre bailithe sonraí chun díriú ar phróisis nótaí bunaithe ar scríobh a fheabhsú.', 'hu': 'Az olyan nagyszabású természetes nyelvi következtetés (NLI) adathalmazokat hoztak létre, mint az SNLI vagy az MNLI, amelyek arra kérték a közösségi munkásokat, hogy olvassanak el egy előfeltételt és írjanak meg három új hipotézist, minden lehetséges szemantikai kapcsolatra egyet (vonatkozás, ellentmondás és semleges). Bár ezt a protokollt használták hasznos referenciaadatok létrehozására, nem világos, hogy az írásalapú jegyzetelési protokoll optimális-e bármilyen célra, mivel azt nem értékelték közvetlenül. Továbbá bőséges bizonyíték áll rendelkezésre arra, hogy a közösségi munkások írása tárgyakat vezethet be az adatokba. Két alternatív protokollt vizsgálunk, amelyek automatikusan létrehoznak jelöltpárokat (premise, hipotézis) a kommentátorok címkézésére. Ezeket a protokollokat és egy írásalapú alapkészletet használva több mint 3 ezer példát tartalmazó angol NLI adatkészletet gyűjtünk össze, amelyek mindegyike rögzített mennyiségű kommentátor időt használ, de változó számú példát használ az adott időköltségvetéshez. Az NLI és a transzfer tanulással végzett kísérleteink negatív eredményeket mutatnak: az alternatív protokollok egyike sem haladja meg az alapvető értékeléseket az NLI-n belül vagy a külső célfeladatokra való átvitel során. Arra a következtetésre jutunk, hogy a crowdworker írás továbbra is a vonatkozási adatok legismertebb lehetősége, kiemelve, hogy további adatgyűjtési munkákra van szükség az írásalapú jegyzetelési folyamatok javítására.', 'el': 'Μεγάλης κλίμακας σύνολα δεδομένων συμπερασμάτων φυσικής γλώσσας (NLI) όπως SNLI ή MNLI έχουν δημιουργηθεί ζητώντας από τους crowdworkers να διαβάσουν μια υπόθεση και να γράψουν τρεις νέες υποθέσεις, μία για κάθε πιθανή σημασιολογική σχέση (συνεπεία, αντίφαση και ουδέτερη). Ενώ αυτό το πρωτόκολλο έχει χρησιμοποιηθεί για τη δημιουργία χρήσιμων δεδομένων αναφοράς, παραμένει ασαφές εάν το πρωτόκολλο σχολιασμού με βάση τη γραφή είναι βέλτιστο για οποιονδήποτε σκοπό, δεδομένου ότι δεν έχει αξιολογηθεί άμεσα. Επιπλέον, υπάρχουν άφθονες αποδείξεις ότι η γραφή μπορεί να εισάγει αντικείμενα στα δεδομένα. Ερευνούμε δύο εναλλακτικά πρωτόκολλα που δημιουργούν αυτόματα υποψήφια ζεύγη (υπόθεση, υπόθεση) για επισήμανση σχολιαστών. Χρησιμοποιώντας αυτά τα πρωτόκολλα και μια βάση βάσης γραφής, συλλέγουμε διάφορα νέα σύνολα δεδομένων της αγγλικής γλώσσας από παραδείγματα πάνω από 3το καθένα, χρησιμοποιώντας ένα σταθερό ποσό χρόνου σχολιασμού, αλλά ποικίλο αριθμό παραδειγμάτων που ταιριάζουν σε αυτόν τον χρονοπροϋπολογισμό. Τα πειράματά μας για τη μάθηση και τη μάθηση μεταφοράς δείχνουν αρνητικά αποτελέσματα: Κανένα από τα εναλλακτικά πρωτόκολλα δεν ξεπερνά τη βασική βάση στις αξιολογήσεις της γενικοποίησης εντός ή στη μεταφορά σε εξωτερικές εργασίες στόχου. Συμπεραίνουμε ότι η συγγραφή εξακολουθεί να είναι η πιο γνωστή επιλογή για δεδομένα εμπλοκής, τονίζοντας την ανάγκη για περαιτέρω εργασίες συλλογής δεδομένων για να επικεντρωθεί στη βελτίωση των διαδικασιών σχολιασμού βασισμένων στη γραφή.', 'ka': 'დიდი მაგალითი თავისუფალური ენის ინფრენცია (NLI) მონაცემები, როგორც SNLI ან MNLI, შექმნილია, როგორც მუშაობელი მუშაობელებისთვის საკითხვა პრემიზა და დაწერა სამი ახალი ჰიპოტეზა, ერთი ყოველ შესაძლებელ მაგრამ ეს პროტოკოლის გამოყენება საჭირო ბენქმარკის მონაცემებისთვის შექმნა, ეს უცნობიერია თუ წერილის დაბათი ბენქმარკის პროტოკოლის ოპტიმალური იყო, რადგან ის არ დამატებით, არსებობს ძალიან წარმოდგენება, რომ მუშაობელი წერილი შეუძლია მონაცემებში არტიტაკტები ჩვენება. ჩვენ განსხვავებთ ორი ალტერტური პროტოკოლას, რომელიც ავტომატურად კანდიდენტის (premise, hypothesis) ზოგების შექმნა, რომელიც ანოტოტორიების მართლად დავწერებთ ამ პროტოკოლობის გამოყენება და დაწერების ბაზი ხაზის გამოყენება, ჩვენ შევყენებთ რამდენიმე ახალი ანგლისური NLI მონაცემების სამუშაო სამუშაო სამუშაო, ყოველთვის გამოყენება განსაზღვრებული წ ჩვენი ექსპერიმენტები NLI და ტრანსპერიმენტის შესწავლების შესაძლებლობა გამოჩვენება negatifური შედეგები: არაფერი ალტენტიფიკური პროტოკოლობი არ გავაკეთებს ზენერალიზაციის განსაზღვ ჩვენ დავაკეთებთ, რომ მუშაობელი წერილის უკეთესი უცნობილი მონაცემებისთვის მონაცემებისთვის, რომელიც აღწერილია უფრო უკეთესი მონაცემების კოლექციის მუშა', 'lt': 'Didelio masto gamtinės kalbos išvados (NLI) duomenų rinkiniai, pavyzdžiui, SNLI arba MNLI, buvo sukurti paprašius visuomenės darbuotojų perskaityti patalpą ir parašyti tris naujas hipotezes, vieną kiekvienam galimam semantiniam santykiui (įtraukimas, prieštaravimas ir neutralumas). Nors šis protokolas buvo naudojamas siekiant sukurti naudingus lyginamuosius duomenis, vis dar neaišku, ar raštu pagrįstas anotacijos protokolas bet kuriuo tikslu yra optimalus, nes jis nebuvo tiesiogiai įvertintas. Be to, yra pakankamai įrodymų, kad visuomenės darbuotojų rašymas gali įvesti dirbinius į duomenis. Mes tiriame du alternatyvius protokolus, kurie automatiškai sukuria kandidatų (prielaidą, hipotezę) poras, kad annotatoriai būtų ženklinami. Taikant šiuos protokolus ir raštu pagrįstą bazę, renkame keletą naujų anglų NLI duomenų rinkinių, kurių kiekvienas sudaro daugiau kaip 3k pavyzdžių, kiekvienas naudojant fiksuotą annotatorių laiko sumą, bet skirtingą skaičių pavyzdžių, kad atitiktų tą laiko biudžetą. Mūsų NLI eksperimentai ir mokymasis perkėlimo srityje rodo neigiamus rezultatus: nė vienas iš alternatyvių protokolų neatitinka bendrosios NLI vertinimų arba perkėlimo į išor ės tikslines užduotis bazės. Galime daryti išvadą, kad visuomenės darbuotojų rašymas tebėra geriausia žinoma galimybė įtraukti duomenis, pabrėžiant poreikį toliau rengti duomenis, siekiant sutelkti dėmesį į raštu pagrįstų anotacijų procesų tobulinimą.', 'mk': 'Податоците за голема природна инференција на јазикот (НЛИ), како што се СНЛИ или МНЛИ, се создадени барајќи од луѓето да прочитаат претпоставка и да напишат три нови хипотези, една за секоја можна семантична врска (вмешаност, контрадиција и неутралност). Иако овој протокол е употребен за создавање корисни податоци за споредба, останува нејасно дали протоколот за анотација базиран на пишување е оптимален за било која цел, бидејќи не е проценет директно. Покрај тоа, постојат доволни докази дека напишувањето на луѓето може да воведе артефакти во податоците. Истражуваме два алтернативни протоколи кои автоматски создаваат парови кандидати (претпоставка, хипотеза) за анататорите да се означат. Користејќи ги овие протоколи и врз основа на пишување, собираме неколку нови англиски НЛИ податоци од повеќе од 3k примери секој, секој користејќи фиксна количина време за анотатор, но различни примери за да се вклопи во тој временски буџет. Нашите експерименти за НЛИ и трансферентно учење покажуваат негативни резултати: ниту еден од алтернативните протоколи не го надминува основното значење во проценките на генерализацијата во НЛИ или на трансференцијата на надворешни метни задачи. Завршуваме дека напишувањето на луѓето сé уште е најдобрата опција за податоци за вклучување, истакнувајќи ја потребата од понатамошна работа за собирање податоци за да се фокусира на подобрување на процесите на анатација базирани на пишување.', 'kk': 'SNLI немесе MNLI секілді үлкен масштабтағы табиғи тілдер инференциясы (NLI) деген деректер жиындары көпшіліктердің премизасын оқу және үш жаңа гипотезаны жазуын сұрау үшін жаңа гипотезаларды жазуды сұрады. Бұл әрбір мүм Бұл протокол пайдалы белгілер деректерін құру үшін қолданылады, бірақ жазу негіздеген белгілер протоколы кез келген мақсаттарына оптимал болып тұрады, себебі ол тікелей бағаламаған. Қосымша, көпшілік жазушылардың деректерінде артефакттарды таңдауға болады. Біз белгілеу үшін кандидаттарды автоматты түрде құратын екі альтернативті протоколды зерттейміз. Бұл протоколдарды және жазу негізгі сызығын қолдану үшін бірнеше жаңа ағылшын NLI деректер жиынын 3k мысалдардан артық түрде жинақтаймыз, әрбір жазбалардың белгілі уақытын қолдану үшін, бірақ уақыт бюджетіне ке NLI және аудару оқыту тәжірибелеріміз негативті нәтижелерін көрсетеді: Альтернативті протоколдардың бір нәтижелері NLI ішіндегі жалпы оқиғалардың негізгі жолын не нақты тапсырмалардың Біз көпшіліктердің жазуының ең жақсы мәліметін жазып жатқан параметрлерін жазып, жазу негізінде жазылу процестерін жақсарту үшін қосымша деректер жинақтау жұмысының қажеттігін боя', 'ms': 'Set data keterangan bahasa alam (NLI) skala besar seperti SNLI atau MNLI telah dicipta dengan meminta pekerja ramai untuk membaca premis dan menulis tiga hipotesis baru, satu untuk setiap hubungan semantik yang mungkin (entailment, kontradiksi, dan neutral). Sementara protokol ini digunakan untuk mencipta data benchmark berguna, ia masih tidak jelas sama ada protokol anotasi berdasarkan tulisan optimal untuk mana-mana tujuan, kerana ia tidak diuji secara langsung. Furthermore, there is ample evidence that crowdworker writing can introduce artifacts in the data.  Kami menyelidiki dua protokol alternatif yang secara automatik mencipta pasangan calon (premis, hipotesis) untuk penganotator untuk label. Dengan menggunakan protokol ini dan dasar tulisan, kita mengumpulkan beberapa set data NLI bahasa Inggeris yang baru dari lebih 3k contoh masing-masing, masing-masing menggunakan jumlah tetap masa annotator, tetapi bilangan contoh yang berbeza untuk muat dengan anggaran masa itu. Eksperimen kami pada NLI dan pembelajaran pemindahan menunjukkan keputusan negatif: tiada protokol alternatif melampaui dasar dalam penilaian generalisasi dalam NLI atau pemindahan ke tugas sasaran luar. Kami menyimpulkan bahawa penulisan orang ramai masih pilihan terbaik yang diketahui untuk data penyelesaian, menyatakan keperluan untuk kerja koleksi data lanjut untuk fokus pada meningkatkan proses anotasi berdasarkan tulisan.', 'ml': 'വലിയ സ്വാഭാവിക ഭാഷ അപകടത്തിനുള്ള (NLI) പോലെ SNLI അല്ലെങ്കില്\u200d MNLI പോലുള്ള ഡാറ്റാസസേറ്റുകള്\u200d സൃഷ്ടിക്കപ്പെട്ടിരിക്കുന്നു. ഒരു മൂന്നു പുതിയ വിചാരണകള്\u200d വായ While this protocol has been used to create useful benchmark data, it remains unclear whether the writing-based annotation protocol is optimal for any purpose, since it has not been evaluated directly.  അതിനുശേഷം, ഒരുപാട് തെളിവുകളുണ്ട്, പ്രധാനപ്പെട്ട കൂടുതല്\u200d കൂടുതല്\u200d ജോലിക്കാര്\u200d എഴുതുന്നത് ഡേറ്റാകളി നമ്മള്\u200d രണ്ടു വിറ്റുള്ള രണ്ട് പ്രോട്ടോക്കോളുകളെ അന്വേഷിക്കുന്നു. അത് സ്വയം പ്രാര്\u200dത്ഥിക്കുന്ന പ്രിയേറ്റര്\u200dക ഈ പ്രോട്ടോക്കോളുകള്\u200d ഉപയോഗിച്ച് എഴുതുന്നതിന്റെ അടിസ്ഥാനത്തിലുള്ള ബെസ്ലൈന്\u200d ഉപയോഗിച്ച്, നമ്മള്\u200d ഒരുപാട് പുതിയ ഇംഗ്ലീഷ് NLI ഡാറ്റാസറ്റുകള്\u200d  നമ്മുടെ പരീക്ഷണങ്ങള്\u200d NLI യില്\u200d നിന്നും പഠിക്കുന്നതിലേക്കും മാറ്റുന്നതിലേക്കും നഷ്ടമായ ഫലങ്ങള്\u200d കാണിക്കുന്നു: മറ്റൊരു നിര്\u200dദ്ദേശങ്ങളിലും നി ഞങ്ങള്\u200d അവസാനിപ്പിക്കുന്നത് പരിചയപ്പെടാത്ത വിവരങ്ങള്\u200dക്കുള്ള ഏറ്റവും നല്ല ഉപാധിയാണ് കൂടുതല്\u200d വിവരങ്ങള്\u200d ശേഖരിക്കുന്നത്, എഴുതുന്നതിന', 'mt': 'Ġie maħluq sett ta’ dejta fuq skala kbira ta’ inferenza lingwistika naturali (NLI) bħall-SNLI jew l-MNLI billi ntalbu lill-ħaddiema kollha biex jaqraw premessa u jiktbu tliet ipoteżi ġodda, waħda għal kull relazzjoni semantika possibbli (involviment, kontradizzjoni, u newtrali). Filwaqt li dan il-protokoll intuża biex tinħoloq dejta ta’ referenza utli, għadu mhux ċar jekk il-protokoll ta’ annotazzjoni bbażata fuq il-kitba huwiex ottimali għal kwalunkwe għan, peress li ma ġiex evalwat direttament. Barra minn hekk, hemm biżżejjed evidenza li l-kitba ta’ crowdworker tista’ tintroduċi artifatti fid-dejta. Aħna ninvestigaw żewġ protokolli alternattivi li awtomatikament joħolqu pari kandidati (premessa, ipoteżi) għall-annotaturi biex jiġu ttikkettati. Bl-użu ta’ dawn il-protokolli u linja bażi bbażata fuq il-kitba, a ħna nġabru diversi settijiet ta’ dejta ġodda tal-NLI Ingliżi ta’ aktar minn 3k eżempju kull wieħed, kull wieħed bl-użu ta’ ammont fiss ta’ ħin għall-annotaturi, iżda numru varjat ta’ eżempji biex jaqblu ma’ dak il-baġit taż-żmien. Our experiments on NLI and transfer learning show negative results: None of the alternative protocols outperforms the baseline in evaluations of generalization within NLI or on transfer to outside target tasks.  Aħna nikkonkludu li l-crowdworker għadu l-aħjar għażla magħrufa għad-dejta ta’ involviment, li tenfasizza l-ħtieġa għal aktar ħidma ta’ ġbir tad-dejta biex tiffoka fuq it-titjib tal-proċessi ta’ annotazzjoni bbażati fuq il-kitba.', 'mn': 'SNLI эсвэл MNLI зэрэг томоохон байгалийн хэл халдвар (NLI) өгөгдлийн сангууд олон ажилтнуудын ажилтнуудыг суурь уншиж, гурван шинэ гипотез бичихийг хүсэж, нэг нь боломжтой semantic холбоотой бүрт нэг юм. Энэ протокол хэрэглэгчийн баримт өгөгдлийг бий болгохын тулд хэрэглэгдсэн ч бичих санааны протокол нь ямар нэгэн зорилго дээр эерэг байх эсэхийг тодорхойгүй байдаг. Үүнээс гадна олон ажилтнуудын бичих нь өгөгдлийн хувьд уран бүтээгдэхүүнийг танилцуулж чадна гэсэн олон баталгаа байна. Бид хоёр өөрчлөлтийн протоколыг судалж байна. Энэ нь автоматаар нэр дэвшигчдийн (premise, hypothesis) хоёрыг бий болгодог. Эдгээр протоколууд болон бичих суурь шугам ашиглан бид хэдэн шинэ англи хэлний NLI өгөгдлийн сангуудыг 3k-аас илүү жишээний жишээг бүрт цуглуулж байна. Хүн бүрт тодорхой хэмжээний хугацаа ашиглаж, гэхдээ цаг хугацааны тө NLI болон суралцах судалгааны туршилтууд сөрөг үр дүнг харуулж байна: Альтернатив протоколуудын аль ч нэг нь NLI-ийн ерөнхийлөгчийн оюутнуудын үндсэн шугам эсвэл гадаад зорилготой ажил руу шилжүүлж чадахгүй. Бид олон нийтийн ажилтнуудын бичиж байгаа нь хамгийн сайн мэдэгдэх сонголт, өгөгдлийн цуглуулалтын хэрэгцээ нь бичиж суурилуулах үйл явцуудыг сайжруулахын тулд анхаарлаа тодорхойлж байна.', 'pl': 'Wielkoskalowe zbiory danych dotyczących wniosków języka naturalnego (NLI), takie jak SNLI czy MNLI, zostały stworzone poprzez poproszenie crowdworkerów o przeczytanie założenia i napisanie trzech nowych hipotez, jednej dla każdej możliwej relacji semantycznej (implikacja, sprzeczność i neutralna). Chociaż protokół ten został wykorzystany do tworzenia użytecznych danych referencyjnych, nie jest jasne, czy protokół adnotacji oparty na zapisie jest optymalny do jakiegokolwiek celu, ponieważ nie został on oceniony bezpośrednio. Ponadto istnieje wiele dowodów na to, że pisanie crowdworkera może wprowadzać artefakty do danych. Badamy dwa alternatywne protokoły, które automatycznie tworzą pary kandydatów (założenia, hipotezy) dla adnotatorów do etykietowania. Korzystając z tych protokołów i bazy bazowej opartej na pisaniu, zbieramy kilka nowych angielskich zestawów danych NLI z przykładów ponad 3k, każdy z nich używa stałej ilości czasu adnotatorów, ale różnej liczby przykładów pasujących do tego budżetu czasu. Nasze eksperymenty dotyczące NLI i uczenia się transferowego wykazują negatywne wyniki: żaden z alternatywnych protokołów nie przewyższa podstawowych w ocenie uogólnienia w obrębie NLI lub przenoszeniu do zewnętrznych zadań docelowych. Stwierdzamy, że pisanie crowdworkerów nadal jest najbardziej znaną opcją dla danych związanych z zaangażowaniem, podkreślając potrzebę dalszych prac zbierania danych, aby skupić się na ulepszaniu procesów adnotacji opartych na pisaniu.', 'sr': 'Velika velika prirodna infekcija jezika (NLI) podataka kao što su SNLI ili MNLI stvorena je tražeći od gužve radnika da pročitaju premiju i napišu tri nove hipoteze, jednu za svake moguće semantičke veze (želja, kontradikcija i neutralna). Iako je ovaj protokol korišćen za stvaranje korisnih podataka o referenciji, ostaje jasan da li je protokol za annotaciju na pisanju optimalan za svaku svrhu, pošto nije direktno procjenjen. Osim toga, postoji dosta dokaza da pišenje publikatora može predstaviti artefakte u podacima. Istražujemo dve alternativne protokole koje automatski stvore par kandidata (premise, hipoteza) za annotatore da se označe. Koristeći ove protokole i početnu liniju na pisanju, skupljamo nekoliko novih engleskih NLI podataka od preko 3k primjera svakog, svakog koristeći određenu količinu annotator a vremena, ali različite broj primjera da se uklapa u taj proračun vremena. Naši eksperimenti o NLI-u i prevozu učenja pokazuju negativne rezultate: nijedan od alternativnih protokola ne iznosi početnu liniju u procjenama generalizacije unutar NLI-a ili na prevozu na izvan ciljnih zadataka. Zaključili smo da ljudi koji napišu najpoznatiju opciju za podatke o uključenju, naglašavaju potrebu za dodatnim kolekcijama podataka da se fokusiraju na poboljšanju procesa annotacije na pisanju.', 'ro': 'Seturi de date pe scară largă de inferență a limbajului natural (NLI) precum SNLI sau MNLI au fost create prin solicitarea crowdworkerilor să citească o premisă și să scrie trei ipoteze noi, una pentru fiecare posibilă relație semantică (implicare, contradicție și neutră). Deși acest protocol a fost utilizat pentru a crea date utile de referință, rămâne neclar dacă protocolul de adnotare bazat pe scriere este optim pentru orice scop, deoarece nu a fost evaluat direct. În plus, există dovezi ample că scrierea crowdworker poate introduce artefacte în date. Investigăm două protocoale alternative care creează automat perechi de candidați (premisă, ipoteză) pentru adnotatori de etichetat. Folosind aceste protocoale și o bază de referință bazată pe scriere, colectăm mai multe seturi de date NLI noi de peste 3k exemple fiecare, fiecare utilizând o cantitate fixă de timp adnotator, dar un număr variat de exemple pentru a se potrivi acelui buget de timp. Experimentele noastre privind NLI și transferul de învățare arată rezultate negative: Niciunul dintre protocoalele alternative nu depășește nivelul de referință în evaluările generalizării în cadrul NLI sau în transferul către sarcini țintă exterioară. Concluzionăm că scrierea crowdworker încă este cea mai cunoscută opțiune pentru datele implicate, subliniind necesitatea de a lucra în continuare de colectare a datelor pentru a se concentra pe îmbunătățirea proceselor de adnotare bazate pe scriere.', 'si': 'Large-scal Native language Infrence (NLI) data sets, e.g. SNLI හෝ MNLI, ලොකු වැඩකරුවන්ට ප්\u200dරධානයක් කියවන්න සහ අළුත් භාෂාව ලියවන්න සඳහා ප්\u200dරශ්නයක් තුනක් ලියවන්න, එක හැම ප්\u200d මේ ප්\u200dරොටෝකෝල් ප්\u200dරයෝජනය ප්\u200dරයෝජනය කරන්න පුළුවන් බෙන්ච්මාර්ක් දත්ත නිර්මාණය කරන්න භාවිත කරලා තියෙනවා නම්, ලියන්නේ  ඉතින්, ගොඩක් සාක්ෂියක් තියෙනවා මිනිස්සු ව්\u200dයාපාරකයා ලියන්න පුළුවන් විදිහට තියෙන්නේ. අපි පරීක්ෂණය කරන්නේ වෙනස් ප්\u200dරොටෝකල් දෙකක් තියෙන්නේ. ස්වයංක්\u200dරියාවිතයෙන් නිර්මාණය (ප්\u200dරීමිස්, හි මේ ප්\u200dරොටොකෝල් සහ ලියපු අධාරණ ප්\u200dරමාණයක් භාවිත කරනවා, අපි අලුත් ඉංග්\u200dරීසි NLI දත්ත සේට් සම්බන්ධ කරනවා, හැමෝම 3k උදාහරණයක්ම, හැම අපේ පරීක්ෂණය NLI සහ ප්\u200dරවේශනය සඳහා ප්\u200dරවේශනය සඳහා අනතුරු ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති අපි අවස්ථාවෙන්නේ මිනිස්සු වැඩකරුවන් ලියනවා තාමත් දත්ත අවස්ථාවක් වෙනුවෙන් හොඳම විකල්පයක් තියෙනවා, තවත් දත්ත සං', 'sv': 'Storskaliga datauppsättningar som SNLI eller MNLI har skapats genom att be crowdworkers att läsa en premiss och skriva tre nya hypoteser, en för varje möjlig semantisk relation (involvering, motsägelse och neutral). Även om detta protokoll har använts för att skapa användbara benchmarkdata, är det fortfarande oklart om det skrivbaserade kommenteringsprotokollet är optimalt för något ändamål, eftersom det inte har utvärderats direkt. Dessutom finns det gott om bevis för att crowdworker skrivning kan introducera artefakter i data. Vi undersöker två alternativa protokoll som automatiskt skapar kandidatpar (premiss, hypotes) för kommentatorer att märka. Med hjälp av dessa protokoll och en skrivbaserad baslinje samlar vi in flera nya engelska NLI-datauppsättningar med över 3 000 exempel vardera, var och en med en fast mängd kommentatortid, men ett varierande antal exempel för att passa den tidsbudgeten. Våra experiment på NLI och transfer learning visar negativa resultat: Inget av de alternativa protokollen överträffar baslinjen i utvärderingar av generalisering inom NLI eller vid överföring till externa måluppgifter. Vi drar slutsatsen att crowdworker writing fortfarande är det mest kända alternativet för involveringsdata, vilket belyser behovet av ytterligare datainsamlingsarbete för att fokusera på att förbättra skrivbaserade anteckningsprocesser.', 'so': 'Sirko afka dabiicadda ah (NLI) waxaa la abuuray (SNLI) ama MNLI oo ah kooxaha macluumaadka (SNLI ama MNLI) oo lagu weyddiinaya shaqaalaha badan inay akhriyaan horay iyo qoraan saddex fikir oo cusub, mid ka mid ah xiriir kasta oo suurtagal ah (entailmaan, kala duwanaan iyo nøytral). Inta lagu isticmaalay in la sameeyo macluumaad faa’iido leh oo la isticmaalo, laakiin ma ogayn in qoraalka lagu qoray uu yahay qaababka wax ku caadi ah, sababtoo ah aan toos loo qiimeyn. Furthermore, there is ample evidence that crowdworker writing can introduce artifacts in the data.  Waxaannu baaraynaa laba qoraal oo kala duwan, kuwaas oo si automati ah u sameynaya kandidada (horumar, hypothesis) labo ah oo labo ka mid ah baaraandegista. Isticmaalka qaabilaadahan iyo saldhigga qoraalka waxaynu soo ururinnaa koox warqad ah oo cusub oo Ingiriiska NLI ah oo ka badan 3 tusaalooyin, mid walbana wuxuu ku isticmaalaa waqti cayiman, laakiin tusaalooyin kala duduwan, si aan u habboonayno bajeti waqtigaas. Imtixaanka ku saabsan barashada NLI iyo badalka waxbarashadu waxay muuqataa resulto negativ ah: Mid ka mid ah protokollada bedelka ayaa ka muuqata qiimeynta dhalashada NLI gudaheeda ama ka wareejinta shaqada dibadda ee goalka. Waxaynu dhamaystirnaa in shaqaalaha badnaan qorayo habka ugu wanaagsan ee loo yaqaan macluumaadka aqoonta, waxaana tusinayaa baahida shaqada la soo ururiyo macluumaad dheeraad ah si uu ugu focussado horumarinta baaraandegista qoraalka.', 'no': 'Stor skala naturspråk-infeksjonar (NLI) som SNLI eller MNLI er oppretta ved å spørja folkarbeidarar om å lesa eit premise og skriva tre nye hypotese, ein for kvar mogleg semantiske forhold (innføring, kontradikt og nøytralt). Mens denne protokollen er brukt for å laga nyttige benchmark data, er det ikkje klart om skrivebasert notasjonsprotokollen er optimal for noko mål, sidan den ikkje er evaluert direkte. I tillegg er det mykje bevis at folkarbeidsgiveren kan introdusera artifaktar i dataene. Vi undersøker to alternative protokollar som automatisk lagar kandidat (premise, hypotese) par for merkelapper. Bruk desse protokollene og ein skrivebasert baseline, samler vi fleire nye engelske NLI-datasett med over 3k eksemplar kvar, kvar med eit fast mengd av annoteratortid, men eit ulike tal eksemplar som skal passast til denne tidspunktet. Eksperimentane våre på NLI og overføringslæring viser negativ resultat: Ingen av alternativ protokollene utfører baselinja i evalueringa av generellisering i NLI eller ved overføring til utenfor mål oppgåver. Vi avsluttar at folkarbeidsgiveren skriv fortsatt den beste kjente valet for innholdsdata, og markerer nødvendighet for å få fram fleire datasamlingar for å fokusera på å forbetra skrivebaserte notasjonsprosessar.', 'ta': 'பெரிய அளவு இயல்பான மொழி குறைவு (NLI) தகவல் அமைப்பு @ info மேலும், பல தெளிவுகள் உள்ளன மக்கள் எழுதுபவர்கள் தகவலில் உள்ள பொருள்களை அறிவிக்க முடியும். நாம் இரண்டு மாற்று நெறிமுறைகளை தானாகவே தேர்ந்தெடுத்து விளக்கச்சீட்டாளர்களுக்கு ஜோடிகளை உருவாக்குகிறோம். இந்த நெறிமுறைகளையும் எழுதும் அடிப்படையிலான அடிப்படையில் பயன்படுத்தி, நாம் பல புதிய ஆங்கிலத்திற்கு மேல் 3k உதாரணத்தையும் சேகரிக்கிறோம், ஒவ்வொரு ந NLI மற்றும் கற்றல் மாற்றும் சோதனைகளில் எதிர்மறை முடிவுகள் காட்டும்: மாற்று நெறிமுறைகளில் எதுவும் நெறிமுறைகளில் பொதுவாக்கத்தின் பொதுவான நாம் முடிவு செய்து கூட்டு வேலையாளர் இன்னும் அறியப்படாத தகவல்களுக்கான சிறந்த த விருப்பத்தேர்வை எழுதுகிறோம். மேலும் தகவல் தொகுப்ப', 'it': "Dataset di inferenza del linguaggio naturale su larga scala (NLI) come SNLI o MNLI sono stati creati chiedendo ai crowdworker di leggere una premessa e scrivere tre nuove ipotesi, una per ogni possibile relazione semantica (implicazione, contraddizione e neutralità). Sebbene questo protocollo sia stato utilizzato per creare dati di benchmark utili, non è chiaro se il protocollo di annotazione basato sulla scrittura sia ottimale per qualsiasi scopo, dal momento che non è stato valutato direttamente. Inoltre, ci sono ampie prove che la scrittura di crowdworker può introdurre artefatti nei dati. Investighiamo due protocolli alternativi che creano automaticamente coppie di candidati (premessa, ipotesi) per gli annotatori da etichettare. Utilizzando questi protocolli e una base di base basata sulla scrittura, raccogliamo diversi nuovi set di dati NLI inglesi di oltre 3k esempi ciascuno, ognuno utilizzando una quantità fissa di tempo di annotazione, ma un numero variabile di esempi per adattarsi a quel budget di tempo. I nostri esperimenti su NLI e transfer learning mostrano risultati negativi: nessuno dei protocolli alternativi supera la base di riferimento nelle valutazioni della generalizzazione all'interno di NLI o sul trasferimento verso attività target esterne. Concludiamo che la scrittura di crowdworker è ancora l'opzione più nota per i dati di implicazione, evidenziando la necessità di ulteriori lavori di raccolta dati per concentrarsi sul miglioramento dei processi di annotazione basati sulla scrittura.", 'ur': 'بہت بڑی نسبت طبیعی زبان ایفارنس (NLI) ڈاٹ سٹے جیسے SNLI یا MNLI پیدا کئے گئے ہیں کہ جماعت کارکنوں کو ایک نمایس پڑھنا اور تین نو فرضیاں لکھنا، ایک ہر امکان سیمنٹی رابطہ کے لئے (سرکشی, مخالفت اور نائرٹی) ہے۔ حالانکہ یہ پروٹروکول مفید بنچممارک ڈیٹا بنانے کے لئے استعمال کئے گئے ہیں، یہ غیر معلوم ہے کہ لکھنے کی بنیادی اٹروٹیٹ پروٹروکول کسی طرح کے لئے اچھا ہے، کیونکہ یہ مستقیم مطالبہ نہیں کیا گیا ہے. اور اس کے علاوہ، بہت سی نشانیاں ہیں کہ گروہوں کے لکھنے والے ڈیٹوں میں آرٹیفٹ معلوم کر سکتے ہیں. ہم دو الٹ پیٹروٹوکول کی تحقیق کرتے ہیں جن کو لابلیٹر کے لئے کاندینٹ (premise, hypothesis) جوڑے بناتے ہیں۔ ان پروٹروکولوں اور نوشتہ بنیس لین کے استعمال کرتے ہیں، ہم نے ہر ایک سے زیادہ نو انگلیسی NLI ڈاٹ سٹ کو تین کی مثالیں جمع کرتے ہیں، ہر ایک ایک مضبوط مقدار وقت کے استعمال کرتا ہے، لیکن اس وقت بوجٹ کے مطابق مختلف مثالیں جمع کرتے ہیں۔ ہماری آزمائش NLI اور ترنسیٹر سینٹر کے ذریعے منفی نتیجے دکھاتے ہیں: کوئی الٹ پیٹروٹکول NLI کے اندر عمومی آزمائش کے ارزش میں بیس لین نہیں کرتا یا باہر تابع کاموں کی ترنسیٹ پر۔ ہم تصمیم لیتے ہیں کہ جماعت کارگر لکھنے کے لئے بہترین جاننے والی انتخاب لکھنے کے لئے ہے، اور اضافہ ڈیٹا جمع کرنے کے لئے نیاز کی تدبیر کرنے کے لئے لکھنے کی بنیاد رکھنے والی اضافہ پرسسوں کو اچھی طرح کی تدبیر کرتا ہے۔', 'vi': 'Những tập tin về ngôn ngữ tự nhiên trên diện rộng (NLI) như SNLI hay MNLI được tạo ra bằng cách yêu cầu nhân công nhân đọc một giả thuyết và viết ba giả thuyết mới, một cho mỗi mối quan hệ theo ngữ nghĩa có thể (tính to án, mâu thuẫn, trung lập, trung lập) Tuy nhiên giao thức này được dùng để tạo ra dữ liệu tiêu chuẩn hữu ích, nhưng vẫn chưa rõ liệu giao thức ghi chép có thích hợp cho bất kỳ mục đích nào, vì nó không được đánh giá trực tiếp. Hơn nữa, có nhiều bằng chứng cho thấy việc viết báo cáo có thể đưa ra cổ vật trong dữ liệu. Chúng tôi điều tra hai giao thức thay thế tự động tạo ra ứng viên (tiền đề, giả thuyết) cặp cho nhà biên bản để dán nhãn. Sử dụng những giao thức này và một cơ sở biên bản viết, chúng tôi thu thập vài tập tin mới về ngôn ngữ Anh Quốc về tồn tại hơn 3k mỗi loại, mỗi loại dùng một số thời gian ghi chú cố, nhưng một số trường hợp khác nhau để phù hợp với ngân sách thời gian đó. Những thí nghiệm về NLI và Việc học chuyển nhượng của chúng tôi cho thấy kết quả tiêu cực: Không có giao thức nào được thực hiện trên cơ sở cơ bản trong các đánh giá tổng hợp trong Nội dung NLI hay chuyển qua các nhiệm vụ chưa đạt mục tiêu. Chúng tôi kết luận rằng việc điền kinh vẫn là lựa chọn sáng suốt nhất về dữ liệu giao tiếp, nhấn mạnh nhu cầu thu thập dữ liệu thêm để tập trung vào việc cải tiến tiến tiến tiến tiến tiến tiến tiến tiến tiến tiến trình ghi âm.', 'uz': "Name While this protocol has been used to create useful benchmark data, it remains unclear whether the writing-based annotation protocol is optimal for any purpose, since it has not been evaluated directly.  Ko'pchilik, bir ko'p hujjatlar maʼlumotga yozuvchi insonlarni ishlab chiqarish mumkin. Biz ikkita boshqa protokollarni o'rganamiz, bu bilan avtomatik rivojlanuvchi (prefiks, hypothesis) qoʻllaniladi. Bu protokollarni va yozish asosida ishlatish mumkin, biz har bir necha yangi ingliz NLI maʼlumotlar tarkibini uchta misol bilan bir necha ko'plab ko'plab turamiz, har bir bir xil annotator soatini ishlatish mumkin, lekin bu vaqt bajeti davomida bir necha misollar. NLI va o'rganishning tajribalarimiz negative natijalarini ko'rsatadi: boshqa protokollar hech qachon narsalar NLI ichidagi generalisiya yoki chegara vazifalarga olishda bir asosiy tarkibini bajaradi. Biz murakkab qilamiz, ma'lumot maʼlumotning eng yaxshi ma'lumotni yozish uchun hamma narsa yozish kerakligini ko'rsatish mumkin.", 'bg': 'Големите масиви от данни за изводи на естествения език (НЛИ) като SNLI или MNLI са създадени чрез искане на crowdworkers да прочетат дадена предпоставка и да напишат три нови хипотези, по една за всяка възможна семантична връзка (обвързване, противоречие и неутрална). Въпреки че този протокол е използван за създаване на полезни бенчмаркови данни, остава неясно дали протоколът за анотация, базиран на писане, е оптимален за каквато и да е цел, тъй като не е бил оценяван пряко. Освен това има достатъчно доказателства, че писането на crowdworkers може да въведе артефакти в данните. Проучваме два алтернативни протокола, които автоматично създават двойки кандидат (предпоставка, хипотеза) за етикетиране на анотаторите. Използвайки тези протоколи и базирана на писане базова линия, ние събираме няколко нови английски НЛИ набора от данни от над 3 000 примера всеки, всеки използвайки фиксирано количество време за анотатор, но различен брой примери, за да се впише в този бюджет за време. Нашите експерименти с НЛИ и трансферно обучение показват отрицателни резултати: Никой от алтернативните протоколи не превъзхожда базовите стойности при оценките на обобщаването в НЛИ или при прехвърлянето към външни целеви задачи. Извеждаме заключението, че писането на crowdworkers все още е най-известният вариант за включване на данни, подчертавайки необходимостта от по-нататъшна работа по събиране на данни, за да се съсредоточи върху подобряване на процесите на анотация, базирани на писане.', 'nl': 'Grootschalige datasets van natuurlijke taal (NLI) zoals SNLI of MNLI zijn gecreëerd door crowdworkers te vragen een premise te lezen en drie nieuwe hypothesen te schrijven, één voor elke mogelijke semantische relatie (implicatie, contradictie en neutraal). Hoewel dit protocol is gebruikt om nuttige benchmarkgegevens te maken, blijft het onduidelijk of het schrijfgebaseerde annotatieprotocol voor welk doel dan ook optimaal is, omdat het niet direct is geëvalueerd. Verder is er voldoende bewijs dat crowdworker schrijven artefacten in de data kan introduceren. We onderzoeken twee alternatieve protocollen die automatisch kandidaat (premise, hypothese) paren creëren voor annotatoren om te labelen. Met behulp van deze protocollen en een schrijfbaseline verzamelen we verschillende nieuwe Engelse NLI datasets van meer dan 3k voorbeelden, elk met een vaste hoeveelheid annotatortijd, maar een variërend aantal voorbeelden om in dat tijdsbudget te passen. Onze experimenten op NLI en transfer learning tonen negatieve resultaten: geen van de alternatieve protocollen overtreft de baseline bij evaluaties van generalisatie binnen NLI of bij overdracht naar externe doeltaken. We concluderen dat crowdworker writing nog steeds de bekendste optie is voor implicatiegegevens, wat de noodzaak benadrukt om verder data te verzamelen om te focussen op het verbeteren van schrijfgebaseerde annotatieprocessen.', 'da': 'Datasæt som SNLI eller MNLI er skabt ved at bede crowdworkere om at læse en forudsætning og skrive tre nye hypoteser, en for hver mulig semantisk relation (involvering, modsigelse og neutral). Selvom denne protokol er blevet brugt til at skabe nyttige benchmark data, er det stadig uklart, om den skrivebaserede annotationsprotokol er optimal til ethvert formål, da den ikke er blevet evalueret direkte. Derudover er der rigelige beviser for, at crowdworker skrivning kan introducere artefakter i dataene. Vi undersøger to alternative protokoller, som automatisk opretter kandidater (premise, hypotese) par for kommentatorer at mærke. Ved hjælp af disse protokoller og en skrivebaseret baseline indsamler vi flere nye engelske NLI datasæt med over 3k eksempler hver, der hver bruger en fast mængde kommentatortid, men et varierende antal eksempler, der passer til det tidsbudget. Vores eksperimenter med NLI og transfer learning viser negative resultater: Ingen af de alternative protokoller overstiger baseline i evalueringer af generalisering inden for NLI eller ved overførsel til eksterne målopgaver. Vi konkluderer, at crowdworker writing stadig er den mest kendte mulighed for involveringsdata, hvilket understreger behovet for yderligere dataindsamlingsarbejde for at fokusere på at forbedre skrivebaserede annotationsprocesser.', 'hr': 'Velika velika prirodna infekcija jezika (NLI) podataka poput SNLI ili MNLI stvorena je tražeći od gužve radnika da pročitaju premiju i napišu tri nove hipoteze, jednu za svaku moguću semantičku vezu (intenzivnost, kontradikcija i neutralna). Iako je ovaj protokol korišćen za stvaranje korisnih podataka o referenciji, ostaje nesvjesno da li je protokol oznake na pisanju optimalan za svaku svrhu, jer nije direktno procjenjen. Osim toga, postoji dosta dokaza da pisanje publikatora može predstaviti artefakte u podacima. Istražujemo dva alternativna protokola koji automatski stvore par kandidata (premise, hipoteza) za označavanje annotatora. Koristeći te protokole i početnu liniju na pisanju, skupljamo nekoliko novih engleskih NLI podataka od preko 3k primjera svakog, svakog koristeći određenu količinu annotator a vremena, ali različite broj primjera koji bi se uklopili u taj proračun vremena. Naši eksperimenti o NLI-u i učenju prijenosa pokazuju negativne rezultate: nijedan od alternativnih protokola ne iznosi početnu liniju u procjenama generalizacije unutar NLI-a ili na prijenos na izvan ciljnih zadataka. Zaključili smo da publikator piše još uvijek najpoznatiju opciju za podatke o uključenju, naglašavajući potrebu za dodatnim prikupljanjem podataka da se usredotoči na poboljšanje procesa oznake na pisanju.', 'de': 'Große Datensätze zur Inferenz natürlicher Sprache (NLI) wie SNLI oder MNLI wurden erstellt, indem Crowdworker gebeten wurden, eine Prämisse zu lesen und drei neue Hypothesen zu schreiben, eine für jede mögliche semantische Beziehung (Implementation, Widerspruch und Neutralität). Während dieses Protokoll verwendet wurde, um nützliche Benchmarkdaten zu erstellen, bleibt unklar, ob das schreibbasierte Annotationsprotokoll für jeden Zweck optimal ist, da es nicht direkt ausgewertet wurde. Darüber hinaus gibt es reichlich Hinweise darauf, dass Crowdworker-Schreiben Artefakte in die Daten einbringen kann. Wir untersuchen zwei alternative Protokolle, die automatisch Kandidatenpaare (Prämisse, Hypothese) für Annotatoren erstellen. Mithilfe dieser Protokolle und einer schreibbasierten Baseline sammeln wir mehrere neue englische NLI-Datensätze mit jeweils über 3k Beispielen, wobei jeweils eine feste Anzahl von Anmerkungszeiten verwendet wird, aber eine unterschiedliche Anzahl von Beispielen, die diesem Zeitbudget entsprechen. Unsere Experimente zu NLI und Transfer Learning zeigen negative Ergebnisse: Keines der alternativen Protokolle übertrifft die Baseline bei der Auswertung der Generalisierung innerhalb von NLI oder beim Transfer auf externe Zielaufgaben. Wir kommen zu dem Schluss, dass Crowdworker-Schreiben immer noch die bekannteste Option für Einbeziehungsdaten ist, was die Notwendigkeit weiterer Datenerfassungsarbeiten hervorhebt, um sich auf die Verbesserung schreibbasierter Annotationsprozesse zu konzentrieren.', 'fa': 'مجموعه\u200cهای داده\u200cهای طبیعی بزرگ (NLI) مثل SNLI یا MNLI با خواستن کارگران جمعیت برای خواندن یک جایگاه و نوشتن سه فرضیه جدید، یکی برای هر رابطه\u200cهای semantic ممکن (اراده، مخالفت و ناتوانی) ایجاد شده\u200cاند. در حالی که این پروتکل برای ایجاد داده\u200cهای صندوق مفید استفاده شده است، هنوز معلوم نیست که پروتکل اخطار بر بنیاد نوشتن برای هر هدف بهترین است، چون مستقیم ارزیابی نشده است. علاوه بر این، مدرک بسیار زیادی وجود دارد که نوشتن کارگران جمعیت می\u200cتواند واقعیت\u200cهای هنری را در داده\u200cها معرفی کند. ما دوتا پروتکل جایگزینی را تحقیق می\u200cکنیم که به طور خودکار جفت کاندیداتی (پیش\u200cفرض، فرضیه) را برای نویسندگان برای نویسندگان ایجاد می\u200cکنند. با استفاده از این پروتکل\u200cها و یک خط بنیادی بنیاد نوشتن، چند مجموعه داده\u200cهای انگلیسی NLI جدید از بیش از ۳ کیلومتر برای هر یک جمع می\u200cکنیم، هر یک با استفاده از مقدار زمان نوشته\u200cکننده ثابت می\u200cشود، ولی تعداد مثالهای متفاوتی برای اندازه به این آزمایش\u200cهای ما روی NLI و انتقال یادگیری نتایج منفی را نشان می\u200cدهد: هیچ یک از پروتکل\u200cهای alternative در ارزیابی ارزیابی عمومی در NLI یا در انتقال به وظیفه\u200cهای هدف خارج نمی\u200cکند. ما نتیجه می\u200cدهیم که گروهکاران هنوز بهترین گزینه\u200cای می\u200cنویسند برای داده\u200cهای استخدام، نیازی برای جمع\u200cآوری داده\u200cهای بیشتری برای بهتر کردن فرایندهای اظهار نوشتن تمرکز کنند.', 'ko': '대규모 자연언어추리(NLI) 데이터 집합, 예를 들어 SNLI나 MNLI는 대중에게 하나의 전제를 읽고 세 가지 새로운 가설을 작성하도록 요구함으로써 만들어진 것으로 모든 가설은 가능한 의미 관계(함축, 모순과 중성)에 대응한다.이 프로토콜은 유용한 기준 데이터를 만드는 데 사용되었지만, 쓰기 기반 주석 프로토콜이 그 어떠한 목적에도 적용되는지, 직접적인 평가가 이루어지지 않았기 때문이다.이 밖에 중공업 창작이 데이터에 인공제품을 도입할 수 있다는 충분한 증거가 있다.우리는 주석자가 표시하도록 후보(전제, 가설) 쌍을 자동으로 만드는 두 가지 대체 프로토콜을 연구했다.이러한 프로토콜과 쓰기 기반의 기선을 이용하여 우리는 몇 개의 새로운 영어 NLI 데이터 집합을 수집했다. 각각 3k가 넘는 예시가 있고 각각 고정된 주석기 시간을 사용했지만 서로 다른 수량의 예시는 시간 예산에 부합된다.NLI와 이전 학습에서의 실험은 부정적인 결과를 보여 주었다. NLI 내 또는 외부 목표 임무로 이전하는 범위화 평가에서 대체 프로토콜이 기준선보다 우수한 것은 없었다.우리는crowdworker 창작은 여전히 데이터를 포함하는 가장 좋은 선택이라는 결론을 얻었고 데이터 수집 작업의 필요성을 강조하여 창작을 바탕으로 하는 주석 과정 개선에 전념했다.', 'sw': 'Ugonjwa wa lugha za asili kwa kiasi kikubwa (NLI) data kama vile SNLI au MNLI imetengenezwa kwa kuwaomba wafanyakazi wa umma wasoma utafiti na kuandika imani tatu mpya, moja kwa kila mahusiano ya kimapenzi (inayofahamika, tofauti na katikati). Wakati protoko hii imetumiwa kutengeneza taarifa za kutumia bendera, bado haijajulikana kama protoko ya matangazo ya kuandika kwa sababu yoyote, kwa sababu haijavutiwa moja kwa moja. Zaidi ya hayo, kuna ushahidi mkubwa wa kuandika kwa wafanyakazi wa umma kunaweza kuwasilisha vitu katika taarifa. Tunafanya uchunguzi wa protoko mbili mbadala ambazo zinatengeneza mgombea binafsi (premise, hypothesis) kwa matangazo. Kwa kutumia protoko hizi na msingi wa kuandika, tunakusanya seti mpya ya data za Kiingereza za NLI za zaidi ya mifano mitatu kila mmoja, kila mmoja kwa kutumia kiasi kikubwa cha muda wa tatizo, lakini mifano tofauti yanayofanana na bajeti hiyo. Jaribio letu la NLI na kuhamisha elimu zinaonyesha matokeo hasi: Hakuna protoko mbadala yoyote yanaonyesha msingi katika tathmini za uzalishaji ndani ya NLI au katika kuhamisha kazi za nje ya malengo. Tunahitimisha kuwa mfanyakazi wa umma bado anaandika chaguo bora zaidi la taarifa za watu wasiofahamu, tunaonyesha hitaji la kazi za kukusanya takwimu zaidi ili lengo la kuboresha michakato yanayoandikwa kwa kuandika.', 'tr': 'SNLI ýa-da MNLI ýaly uly gödek dili alyp barlamagy üçin köp adamlar üçin üç täze hypotes ýazmagy üçin döredildi, her mümkin semantik baglaýyşlar üçin bir tane (gaýşartma, kontrast we neutral) düzümler üçin bejerildi. Bu protokol ullanylşy benchmark maglumaty bejermek üçin ullanylşy bolsa, ýazmakda tabanly täblisa protokol onalty üçin optimaldyr, sebäbi ol düzgün deňlenmedi. Munuň üçin köp işgärler ýazmagyň sungatlary bardygyna köp kanlag bar. Biz iki seçenek protokollary otomatik olarak kandidaty bejermek üçin hasaplanýarlar. Bu protokollary we ýazmakda tabanly baz hatlary ullanýarys, we her biri 3k mysal üstünde birnäçe täze Iňlis dili NLI veri setirlerini ýygnaýar, her biri möhüm bir nusgatçy wagtyny ulanýar, ýöne wagtyň budžetynda ýazmak üçin birnäçe mysal çykýar. NLI üçin synanyşlarymyz we öwrenmek üçin negatif netijeleri görkezýär: Başga bir protokolyň biri NLI içinde döredilmiş hasaplamalarda esasy hatlary ýok edip bilmez. Biz milli işgärleri taýýarlamak üçin adatça bilinen seçenekleri ýazmak üçin, daş toplantyň işini ýazmak üçin üns bermeli täzeliklerini gowylaşdyrmak üçin gurlaşýarys.', 'sq': 'Të dhënat në shkallë të madhe të inferencës së gjuhës natyrore (NLI) të tilla si SNLI apo MNLI janë krijuar duke i kërkuar njerëzve të lexojnë një premtesë dhe të shkruajnë tre hipoteza të reja, një për çdo marrëdhënie të mundshme semantike (përfshirje, kontradikcion dhe neutrale). Ndërsa ky protokoll është përdorur për të krijuar të dhëna të dobishme reference, mbetet e paqartë nëse protokolli i anotacionit me bazë shkrimi është optimal për ndonjë qëllim, pasi nuk është vlerësuar drejtpërdrejt. Përveç kësaj, ka prova të mjaftueshme se shkrimi i popullsisë mund të futë artifakte në të dhënat. Ne hetojmë dy protokolle alternativë që automatikisht krijojnë çifte kandidate (premtesa, hipoteza) për anotatorët për të etiketuar. Duke përdorur këto protokolle dhe një bazë bazuar në shkrim, ne mbledhim disa grupe të dhënash të reja angleze NLI prej mbi 3k shembuj secili, secili duke përdorur një sasi të caktuar të kohës së anotatorit, por një numër të ndryshëm shembujsh për të përshtatur atë buxhet kohor. Eksperimentet tona mbi NLI dhe mësimin e transferimit tregojnë rezultate negative: asnjë nga protokollet alternativë nuk ekziston në bazë në vlerësimet e gjeneralizimit brenda NLI apo në transferimin në detyrat e jashtme të objektivit. We conclude that crowdworker writing still the best known option for entailment data, highlighting the need for further data collection work to focus on improving writing-based annotation processes.', 'af': "Groot-skaal natuurlike taal inferensie (NLI) datastelle soos SNLI of MNLI is geskep deur versoek van skakelwerkers om 'n premise te lees en drie nuwe hipotees te skryf, een vir elke moontlike semantiese verhouding (bedryf, kontraksie en neutrale). Terwyl hierdie protokol is gebruik word om nuttige benchmark data te skep, bly dit onbekende of die skryfbaseerde annotasie protokol optimal is vir enige doel, omdat dit nie direk geevalueer is nie. Maar daar is ample bevestigheid dat skakelwerker skryf kunstenaars in die data kan voorsien. Ons ondersoek twee alternatiewe protokolle wat automaties kandidate (premise, hypotese) paar skep vir annotators na etiket. By gebruik van hierdie protokolle en 'n skrifgebaseerde basislien, versamel ons verskeie nuwe Engels NLI datastelle van oor 3k voorbeelde elkeen, elkeen gebruik 'n vaste hoeveelheid annotator tyd, maar 'n verskeie aantal voorbeelde om daardie tyd budžet te pas. Ons eksperimente op NLI en oordrag leer negatiewe resultate vertoon: Geen van die alternatiewe protokolle uitvoer die basisline in evaluasies van generalisering binne NLI of op oordrag na buite doel opdragte. Ons sluit dat skakelwerker nog die beste bekende opsie skryf vir opsies data, verlig die behoefte vir verdere data versameling werk om fokus te maak op die verbetering van skrifgebaseerde annotasie prosesse.", 'am': 'ትልቅ የፍጥረት ቋንቋ ድምጽ (NLI) ዳታተሮችን እንደ SNLI ወይም MNLI የተፈጠሩ የድምፅ አካባቢዎች ፕሮግራም እና ሦስት አዲስ ጉዳይ እንዲያነቡ ለመጠየቃቸው፣ አንዱ ለሁሉም የሚቻለው የsemantic ግንኙነት (ተቃውሞ እና የውይይይት). ይህ protocol በተጠቃሚ የbenchmark data ለመፍጠር በተጠቀመ ጊዜ፣ የጽሑፍ-based ማስታወቂያ ፕሮግራሙል ከሆነ ማንኛውም ምክንያት ፍላጎት ቢሆን አያስተውልም፡፡ ከዚህም በላይ ብዙ ማስረጃ አለ፣ የሕዝብ ሠራተኞች ጽሑፎችን ከዳታዎች ውጤቶችን ለማግኘት ይችላል፡፡ ሁለት ሌሎችን ፕሮጀክት እናምርመራለን፡፡ እነዚህን ፕሮግራሞች እና የጽሑፍ መደገፊያውን በመጠቀም አዲስ የኢንጂልዩን NLI ዳታዎችን በ3 ምሳሌዎች ላይ እንሰበስባለን፤ እያንዳንዳቸውም በተወሰነ ቁጥር የሚያስታወቅ ጊዜ እናስቀምጣለን፣ ነገር ግን የዚያን ሰዓት budget ለመግባት የተለያዩ ምሳሌዎችን እናስቀምጣለን፡፡ የNLI ፈተናዎች እና ትምህርት ማቀናቀል ፍጥረቶችን negative ያሳያል፤ በተለዩ ፕሮግራሞች ማንም በNLI ውስጥ አካባቢ እንዲሆን ወይም ወደ ውጭ ወደ አካላቢው ስራ ለመስጠት የሚደረገውን መሠረት አይደርስም፡፡ የድምፅ ሠራተኞች የሚታወቀው የዳታ መሆኑን ለማሳወቅ የሚታወቀው ምርጫዎች፣ የዳታ ሰብስብ ሥራን ለመጠቀም የጽሑፍ-ተመሳሳይ ተቃውሞ የሚያስፈልገውን ማስታወቂያውን እናሳውቃለን፡፡', 'hy': 'Բազմազան բնական լեզվի եզրակացության (ՆԼԻ) տվյալների համակարգերը, ինչպիսիք են ՍՆԼԻ կամ ՄՆԼԻ, ստեղծվել են ժողովրդի աշխատակիցներին խնդրելով կարդալ նախադրությունը և գրել երեք նոր հիպոթեզներ, մեկը յուրաքանչյուր հնարավոր սեմանտիկ հարաբերության համար (ներգրավ Մինչդեռ այս պրոտոկոլը օգտակար համեմատական տվյալներ ստեղծելու համար օգտակար է, դեռևս անհասկանալի է, թե գրելով հիմնված նոտացիայի պրոտոկոլը որևէ նպատակի համար օպտիմալ է, քանի որ այն անմիջապես չի գնահատվել: Ավելին, բազմաթիվ ապացույցներ կան, որ ժողովրդավար գրողները կարող են տվյալների մեջ արտերֆեկտներ ներկայացնել: Մենք ուսումնասիրում ենք երկու այլընտրանքային պրոտոկոլ, որոնք ինքնաբերաբար ստեղծում են թեկնածու (ենթադրություն, հիպոթեզի) զույգեր annoտորների համար: Օգտագործելով այս պրոտոկոլները և գրավոր հիմքերը, մենք հավաքում ենք մի քանի նոր անգլերեն ՆԼԻ տվյալների համակարգեր, որոնց յուրաքանչյուրը մոտ 3k օրինակ է, յուրաքանչյուրը օգտագործելով որոշակի ժամանակ, բայց տարբեր օրինակներ, որ համապատասխանեն ժամանակի բյուջե ՆԼԻ-ի և փոխանցման ուսումնասիրությունների մեր փորձարկումները բացասական արդյունքներ են ցույց տալիս. ոչ մեկ այլընտրանքային պրոտոկոլներից ոչ մեկը չի արտադրում հիմքը ՆԼԻ-ի ներսում գլխավորման գնահատման կամ փոխանցման դեպի դրսի Մենք եզրակացնում ենք, որ ժողովրդի աշխատակիցները գրում են դեռևս ամենալավ հայտնի տարբերակը ներգրավման տվյալների համար, շեշտելով ավելի շատ տվյալների հավաքածու աշխատանքի կարիքը, որպեսզի կենտրոնանան գրելով հիմնված annoտացիոն', 'bn': 'প্রাকৃতিক ভাষার আক্রান্ত (এনলি) ডাটাসেট, যেমন এসএনলি অথবা এমএনলির সৃষ্টি করা হয়েছে জনতা কর্মীদের কাছে একটি প্রেসিডেন্ট পড়া এবং তিনটি নতুন ধারণা লিখার আহ্বান জানানো  যদিও এই প্রোটোকল ব্যবহার করা হয়েছে বেনম্যার্ক ডাটা তৈরি করার জন্য, তবে লেখা ভিত্তিক বিজ্ঞাপন প্রোটোকল কোন উদ্দেশ্যের জন্য অপ্রায় কিছু না ক এছাড়াও, অনেক প্রমাণ রয়েছে যে প্রচার কর্মীরা লিখতে পারেন তথ্যে প্রকাশ করতে পারেন। আমরা দুটি বিকল্প প্রোটোকল অনুসন্ধান করি যেগুলো স্বয়ংক্রিয়ভাবে প্রার্থী তৈরি করে (প্রার্থী, হিপাইথিসি) লেবেলে এই প্রোটোকল এবং লেখা ভিত্তিক ভিত্তিক বেসাইন ব্যবহার করে আমরা বেশ কয়েকটি নতুন ইংরেজি এনলি ডাটাসেট সংগ্রহ করি, প্রত্যেকেই একটি নির্ধারিত সময় ব্যবহার করে, কিন্তু সময় এনলিতে আমাদের পরীক্ষা এবং শিক্ষা পরিবর্তনের পরীক্ষা নেতিবাচক ফলাফল প্রদর্শন করে: বিকল্প প প্রোটোকলের মধ্যে কেউ নেই এনলির মধ্যে জেনারেলিজেশনের মূল্য আমরা উপসংহার প্রদান করেছি যে গ্রুপ কর্মীরা এখনও পরিচিত তথ্যের জন্য সর্বোচ্চ পরিচিত বিকল্প লিখেছেন, যেখানে আরো তথ্য সংগ্রহের কাজের প্', 'az': 'SNLI və MNLI kimi böyük ölçülü təbiətli dil infeksiyonu (NLI) veri quruları, qüvvətçilərdən öyrənmək və üç yeni hipotesi yazmaq üçün yaradılmışdır, hər mümkün semantik ilişkiler üçün bir quruluşdur (çətin, nifaq və nötrəlik). Bu protokol faydalı benchmark məlumatı yaratmaq üçün istifadə ediləndə, yazıb-tabanlı notlama protokolünün hər bir məqsəd üçün optimal olduğunu bilmir, çünki o doğrudan değerlənmədi. Daha sonra, çox dəlillər var ki, qüvvətli yazıcıların məlumatlarda məlumatları tanıyabilir. İki alternatif protokol araşdırırıq ki, indikator etiketləri üçün avtomatik olaraq (premise, hypothesis) çift yaradır. Bu protokolları və yazıb-tabanlı sinyallərini istifadə edirək, hər biri üç k üstündə olan yeni İngiliz NLI veri qurmaqlarını toplayırıq, hər biri müəyyən vaxt müəyyən sayı ilə istifadə edir, lakin o vaxt budžetına uymaq üçün müxtəlif nümunələr var. NLI təcrübələrimiz və transfer öyrənməyimiz negatif sonuçları göstərir: alternativ protokolların hiçbiri NLI içində generalizasyon təcrübələrində və ya məqsəd işlərinə daşınmasında əsas səhifələri istifadə etməz. Biz çəkirik ki, qüvvətçilər yazmaq üçün hələ də ən yaxşı bilən seçimlər yazmaq üçün yazmaq üçün daha çox məlumat koleksiyonu işlətmək üçün məlumatlarını təşkil edir.', 'bs': 'Velika velika prirodna infekcija jezika (NLI) podataka poput SNLI ili MNLI stvorena je tražeći od gužve radnika da čitaju premiju i napišu tri nove hipoteze, jednu za svaku moguću semantičku vezu (intenzivnost, kontradikcija i neutralna). Iako je ovaj protokol korišćen za stvaranje korisnih podataka o referenciji, ostaje jasan da li je protokol o annotaciji na pisanju optimalan za svaku svrhu, pošto nije direktno procjenjen. Osim toga, postoji dosta dokaza da pisanje gužve može predstaviti artefakte u podacima. Istražujemo dva alternativna protokola koji automatski stvore par kandidata (premise, hipoteza) za označavanje annotatora. Koristeći ove protokole i početnu liniju na pisanju, skupljamo nekoliko novih engleskih NLI podataka od preko 3k primjera svakog, svakog koristeći određenu količinu annotator a vremena, ali različite broj primjera koji se uklapaju u taj proračun vremena. Naši eksperimenti o NLI-u i prevozu učenja pokazuju negativne rezultate: nijedan od alternativnih protokola ne iznosi početnu liniju u procjenama generalizacije unutar NLI-a ili na prevozu na izvan ciljnih zadataka. Zaključili smo da publikator piše još uvijek najpoznatiju opciju za podatke o uključenju, naglašavajući potrebu za dodatnim kolekcijama podataka da se usredotoči na poboljšanje procesa annotacije na pisanju.', 'id': 'Seting data dari bahasa alam (NLI) skala besar seperti SNLI atau MNLI telah diciptakan dengan meminta para pekerja keramaian untuk membaca sebuah premis dan menulis tiga hipotesis baru, satu untuk setiap hubungan semantis yang mungkin (entailment, kontradiksi, dan neutral). Meskipun protokol ini telah digunakan untuk menciptakan data benchmark berguna, masih tidak jelas apakah protokol anotasi berdasarkan tulisan optimal untuk tujuan apapun, karena itu belum dievaluasi secara langsung. Selain itu, ada bukti yang cukup bahwa penulisan pekerja keramaian dapat memperkenalkan artefak dalam data. Kami menyelidiki dua protokol alternatif yang secara otomatis menciptakan pasangan kandidat (premise, hipotesis) untuk anotator untuk label. Using these protocols and a writing-based baseline, we collect several new English NLI datasets of over 3k examples each, each using a fixed amount of annotator time, but a varying number of examples to fit that time budget.  Eksperimen kami pada NLI dan pembelajaran transfer menunjukkan hasil negatif: tidak ada protokol alternatif yang melampaui batas dasar dalam evaluasi generalisasi dalam NLI atau pada transfer ke tugas target luar. Kami menyimpulkan bahwa penulis penonton masih pilihan terbaik yang dikenal untuk data penyelesaian, menyatakan kebutuhan untuk koleksi data lebih lanjut untuk fokus pada meningkatkan proses anotasi berdasarkan tulisan.', 'ca': "S'han creat conjunts de dades de gran escala de inferència de llenguatges naturals (NLI), com SNLI o MNLI, demanant als treballadors de multitud que llegeixin una premisa i escriguin tres hipòtesis noves, una per cada possible relació semàntica (involucració, contradicció i neutral). Mentre aquest protocol s'ha utilitzat per crear dades útils de referència, encara no és clar si el protocol d'anotació basat en escriptura és optim per qualsevol objectiu, ja que no ha estat avaluat directament. Furthermore, there is ample evidence that crowdworker writing can introduce artifacts in the data.  Investiguem dos protocols alternativs que creen automàticament parells de candidats (premises, hipòtesis) per a que els anotators etiquetin. Utilitzant aquests protocols i una base de referència basada en escriptura, recollim diversos nous conjunts de dades anglesos de NLI de més de 3k exemples cada, cada un fent servir una quantitat fixa de temps d'anotació, però un nombre variat d'exemples per ajustar aquest pressupost temporal. Els nostres experiments en NLI i l'aprenentatge de transfer ència mostran resultats negatius: cap dels protocols alternativs supera la base de referència en evaluacions de generalització dins NLI o en transferència a tasques externes. Conclouem que els treballadors encara escriuen la millor opció coneguda per a les dades d'involucració, destacant la necessitat de treballar més sobre la col·lecció de dades per centrar-se en millorar els processos d'anotació basats en l'escriptura.", 'cs': 'Rozsáhlé datové sady inference přirozeného jazyka (NLI), jako jsou SNLI nebo MNLI, byly vytvořeny požádáním crowdworkerů, aby si přečetli předpoklad a napsali tři nové hypotézy, jednu pro každý možný sémantický vztah (implikace, rozpor a neutrální). Zatímco tento protokol byl použit k vytváření užitečných referenčních dat, zůstává nejasné, zda je anotace založená na zápisu optimální pro jakýkoliv účel, protože nebyl vyhodnocen přímo. Kromě toho existuje dostatek důkazů, že crowdworker psaní může do dat zavést artefakty. Zkoumáme dva alternativní protokoly, které automaticky vytvářejí kandidátské (předpoklady, hypotézy) páry pro anotátory k označení. Pomocí těchto protokolů a základní základní linie založené na zápisu shromažďujeme několik nových anglických datových sad NLI více než 3k příkladů, každý používá pevné množství času anotátorů, ale různý počet příkladů, které odpovídají tomuto časovému rozpočtu. Naše experimenty na NLI a transferovém učení ukazují negativní výsledky: Žádný z alternativních protokolů nepřekoná základní hodnotu při hodnocení zobecnění v rámci NLI nebo při přenosu na externí cílové úlohy. Dospěli jsme k závěru, že crowdworker psaní stále nejznámější možností pro implikační data, což zdůrazňuje potřebu dalšího sběru dat se zaměřit na zlepšení procesů anotace založených na psaní.', 'et': 'Laiaulatuslikud looduskeele järelduste andmekogumid, nagu SNLI või MNLI, on loodud paludes ühistöötajatel lugeda eeldust ja kirjutada kolm uut hüpoteesi, üks iga võimaliku semantilise suhte kohta (kaasamine, vastuolu ja neutraalne). Kuigi seda protokolli on kasutatud kasulike võrdlusandmete loomiseks, jääb ebaselgeks, kas kirjutamisel põhinev annotatsiooniprotokoll on optimaalne mistahes eesmärgil, kuna seda ei ole otseselt hinnatud. Lisaks on piisavalt tõendeid, et ühistöötajate kirjutamine võib andmetes esemeid tuua. Uurime kahte alternatiivset protokolli, mis automaatselt loovad kandidaadipaarid (eeldus, hüpotees) märgistamiseks. Nende protokollide ja kirjutamispõhise lähtejoone abil kogume mitmeid uusi inglise NLI andmekogumeid, millest igaüks koosneb üle 3k näitest, igaüks kasutab kindlaksmääratud koguse annotatori aega, kuid erineva arvu näiteid, mis sobivad sellele ajaeelarvele. Meie NLI ja siirdeõppe eksperimendid näitavad negatiivseid tulemusi: Ükski alternatiivne protokoll ei ületa algväärtust üldistamise hindamisel NLI sees või üleminekul väljaspool sihtülesandeid. Järeldame, et ühistöötajate kirjutamine on endiselt kõige tuntum võimalus kaasamisandmete jaoks, rõhutades vajadust edasise andmekogumistöö järele, et keskenduda kirjutamispõhiste annoteerimisprotsesside parandamisele.', 'fi': 'Laajamittaiset luonnollisen kielen päättelyaineistot (NLI), kuten SNLI tai MNLI, on luotu pyytämällä joukkotyöntekijöitä lukemaan premissan ja kirjoittamaan kolme uutta hypoteesia, yksi jokaista mahdollista semanttista suhdetta varten (asiayhteys, ristiriita ja neutraali). Vaikka tätä protokollaa on käytetty hyödyllisten vertailutietojen luomiseen, on edelleen epäselvää, onko kirjoituspohjainen merkintäprotokolla optimaalinen mihin tahansa tarkoitukseen, koska sitä ei ole arvioitu suoraan. Lisäksi on runsaasti näyttöä siitä, että joukkotyöläisten kirjoittaminen voi tuoda esineitä dataan. Tutkimme kahta vaihtoehtoista protokollaa, jotka luovat automaattisesti ehdokasparit (oletus, hypoteesi) merkinnälle. Näiden protokollien ja kirjoituspohjaisen perusaikataulun avulla keräämme useita uusia englanninkielisiä NLI-tietokokonaisuuksia, joista jokainen sisältää yli 3k esimerkkiä, joista jokainen käyttää tiettyä määrää huomautusaikaa, mutta vaihtelevaa määrää esimerkkejä kyseiseen aikabudjettiin sopivaksi. NLI:n ja siirtooppimisen kokeilut osoittavat negatiivisia tuloksia: Mikään vaihtoehtoisista protokollista ei ylitä lähtötasoa NLI:n yleistymisen arvioinnissa tai siirtymisessä ulkopuolisiin kohdetehtäviin. Päätämme, että joukkotyöläisten kirjoittaminen on edelleen tunnetuin vaihtoehto implementointidatalle, mikä korostaa tarvetta jatkaa tiedonkeruutyötä, jotta kirjoituspohjaisten merkintöjen parantamiseen voitaisiin keskittyä.', 'ha': "An halitta data tsakanin da aka ƙayyade lugha mai girma (NLI) da aka halitta SNLI ko MNLI kamar an halitta umarni da ke tambayi mutane su karatun wani prefaka kuma su rubũta sau uku na hanyoyi, kowane wa kowane dangantaka na semantic (entailment, motsi, kuma neutral). A lokacin da aka yi amfani da wannan shirin a ƙiƙiro data na bangon amfani da, ba ya kasa gane shi ba, ko lalle zasu na da amfani da lokacin zane-zane-zane-zane-zane-rubutun da aka rubũta zuwa wani amfani da, amma ba a ƙaddara shi dira ba. Furan haka, akwai bayan mãsu yawa cewa rubũtun mutane da ke iya iya ƙara da masu takarda cikin data. Ko ƙidãya karkacin wasu biyu na dabar-daba, da za'a halin kanana (prefaka, tumbaka) biyu zuwa alama. Yi amfani da waɗannan shiryoyin ayuka da wani salon da aka rubũta, muna samun wasu masu tsari na Ingiriya na NLI masu yawa daga misãlai uku, ko kõwane, da yana amfani da lokaci mai ƙayyade taƙaita, kuma amma wasu misãlai masu daban da za'a fito da buƙatan wannan lokaci. Kayan jarrabai da ke samun shirin nuna matsalar nega: Babu wasu shiryoyin ayuka na dabar-daban, bã ya iya ƙayyade salon da za'a iya ƙayyade littãfin da ke cikin NLI ko kuma a shige zuwa aikin bayan shine. Tuna ƙara cewa mafiya amfani da aikin umarni da ke rubũta yana da mafi kyaun zaɓen da aka sani ga data masu sani, yana bayyana muhimmin da ake da muhimmada wa aikin tãrayyar data masu ƙaranci dõmin ya yi zura ga improve aikin mai takarda da aka rubũta.", 'sk': 'Obsežni nabori podatkov o sklepanju naravnega jezika (NLI), kot sta SNLI ali MNLI, so bili ustvarjeni tako, da so množični delavci prosili, naj preberejo predpostavko in napišejo tri nove hipoteze, po eno za vsako možno semantično razmerje (posledica, protislovje in nevtralno). Čeprav je bil ta protokol uporabljen za ustvarjanje uporabnih referenčnih podatkov, ostaja nejasno, ali je protokol opombe na podlagi pisanja optimalen za kateri koli namen, saj ni bil ocenjen neposredno. Poleg tega obstaja veliko dokazov, da lahko množično pisanje vnese artefakte v podatke. Preučujemo dva alternativna protokola, ki avtomatično ustvarita kandidatne pare (premisa, hipoteza) za označevanje označevalcev. Z uporabo teh protokolov in osnovnega načrta, ki temelji na pisanju, zbiramo več novih angleških naborov podatkov NLI z več kot 3.000 primerov, vsak uporablja fiksno količino časa označevalnika, vendar različno število primerov, ki ustrezajo temu časovnemu proračunu. Naši eksperimenti na NLI in transfernem učenju kažejo negativne rezultate: Noben od alternativnih protokolov ne presega osnovne vrednosti pri ocenjevanju generalizacije znotraj NLI ali pri prenosu na zunanje ciljne naloge. Sklepamo, da je pisanje množičnih delavcev še vedno najbolj znana možnost za podatke o vključevanju, pri čemer poudarjamo potrebo po nadaljnjem delu zbiranja podatkov, da se osredotočimo na izboljšanje postopkov zapisovanja, ki temeljijo na pisanju.', 'he': 'קבוצות נתונים על שפת טבעית (NLI) במידה גדולה, כמו SNLI או MNLI, נוצרו על ידי ביקשת מאנשי הקהל לקרוא הניסיון ולכתוב שלושה היפותזיות חדשות, אחת לכל מערכת יחסים סמנטיות אפשרית (מעורבות, התנגדות ונטרליות). למרות שהפרוטוקול הזה השתמש כדי ליצור נתונים שימושיים בנקודת רמז, עדיין לא ברור אם פרוטוקול ההכתבות המבוסס על כתיבה הוא אופטימלי לכל מטרה, מכיוון שהוא לא הועריך ישירות. חוץ מזה, יש מספיק ראיות שכתיבת עובדי הקהל יכולה להציג חפצים במידע. אנחנו חוקרים שני פרוטוקולים אלטרנטיביים שיוצרים אוטומטית זוגות מועמדים באמצעות הפרוטוקולים האלה ובסיפון מבוסס בכתיבה, אנו אוספים כמה קבוצות נתונים חדשות של NLI אנגלית של יותר מ-3k דוגמאות לכל אחד, כל אחד באמצעות סכום קבוע של זמן ציונים, אבל מספר שונה של דוגמאות כדי להתאים לתקציב הזמן הזה. הניסויים שלנו על NLI וללמדת העברה מראים תוצאות שליליות: אף אחד מהפרוטוקולים האלטרנטיביים לא מעלים את הבסיס בהערכות של הגנרליזציה בתוך NLI או על העברה למשימות מחוץ למטרה. אנחנו מסתיימים שכתבת עובדי הקהל עדיין האופציה הכי ידועה למידע מעורבב, ומדגישה את הצורך לעבודה נוספת לאספת נתונים כדי להתמקד בשיפור תהליכים הערות על בסיס כתיבה.', 'jv': 'Suara pernik-scale nganggo pernik diangkat sing luwih (NLI) sampeyan dataset sing koyo sNLI karo MNLI kang dibalikno ning nguasai pernik hukum kanggo basa lawak nggawe pratike karo telu suputes sing uwis, sing dumateng kanggo sabên seneng pernik (tanggal, suputeksi lan ijolan). Protokol iki wis digawe kanggo nggawe dadi nggunaké bench, dadi ora bisa ngono terus dadi, dadi mbukake sekolakno sing basa nggunaken protokol sing apik dhéwé, dadi ora iso nggunakake ditambah. Gak bener, ana karo akeh pisan sing paling-upan kanggo tukang mangkat pisan neng artik sing bisa nggawe barang nggawe dadi. Awak dhéwé éngleksi duruha protokol sing automatik nyelarakno nggawe Kelangan (bongkar, suputes) sing dibutuhke tarjamahan kanggo etikete. Ngawe nggunakake protokol iki lan basa sing basa-basa sing nggambar, kita cokaké awak dhéwé dataset inggilis NLI sing ngewehi kantor 3 k bisalalan sabên, sabên iki nggawe sistem sing titik dhéwé tanggal, nganggo akeh ketahan sampeyan kanggo dianggap Awakdhéwé éntukno NLI karo nggawe aturan anyar mungkin dadi bener dadi: Awak dhéwé éntuk sing beraksi hukum kanggo pisan artik sing luwih apik perusahaan kanggo awak dhéwé kuwi nggawe isiné perusahaan data sing bisa ngubah dhéwé, dadi sing ngendalikno nggawe ngubah dhéwé kuwi nggawe gerakan oleh operasi tambah nggawe', 'bo': 'སྤྱི་ཚོགས་ཅན་གྱི་རང་རིས་སྐད་ཀྱི་གསལ་བརྗོད་པ་ཆེ་བའི་སྐད་ཡིག་ཆ་གསལ་བཤད་ཀྱི་ཆེད་དུ་བསམ་བློ་གཏོང་པ་དང་མཉམ་དུ་འཇུག་སྤྱི་ཚོགས་ལ་འཇུག་དགོས་མཁན་མེད་པའི་རྣམ་པ While this protocol is used to create useful benchmark data, it remains unclear whether the writing-based annotation protocol is optimal for any purpose, since it has not been evaluated directly. ད་དུང་། མི་མང་གི་བྲིས་ཡིག་ཆ་ཉིད་ལ་སྒྲུབ་ཅན་གྱི་རྒྱུ་རྩལ་བ་མང་ཙམ་ཡོད་པ་རེད། ང་ཚོས་རང་འགུལ་གྱིས་རྟོགས་པ་གསར་འཛུགས་པའི་འདྲ་བཟོ་སྲོལ་གྱི་མཐུན་སྒྲིག་ཆ་གཉིས་བརྟག་ཞིབ་བྱེད་ཀྱི་ཡོད། We collect new English NLI datasets of over 3k examples each using a fixed amount of annotator time, but a varying number of examples to fit that time budget. NLI ཡི་སྐོར་གྱི་བརྟག་ཞིབ་དང་སྐྱེལ་འདྲེན་གྱི་ཚད་རྐྱེན་སྟངས་མངོན་གསལ་བ་ཡོད། ང་ཚོས་མཉམ་ལས་རྩོལ་བ་གྱིས་འབྲི་གི་གདམ་ཀ་གསལ་པོ་དེ་ལས་ཀྱང་གསལ་ཤོས་ཡོད་པའི་གདམ་ཀ་གསལ་བཤད་ཀྱི་ཡོད།'}
{'en': 'Answering Product-related Questions with Heterogeneous Information', 'ar': 'الإجابة على الأسئلة المتعلقة بالمنتج بمعلومات غير متجانسة', 'es': 'Responder a preguntas relacionadas con los productos con información heterogénea', 'pt': 'Respondendo a perguntas relacionadas ao produto com informações heterogêneas', 'fr': "Réponses aux questions relatives aux produits à l'aide d'informations hétérogènes", 'ja': '異種情報での製品関連の質問への回答', 'zh': '以异构对', 'hi': 'विषम जानकारी के साथ उत्पाद से संबंधित प्रश्नों के उत्तर देना', 'ru': 'Ответы на вопросы, связанные с продуктом, с помощью гетерогенной информации', 'ga': 'Ag Freagairt Ceisteanna a Bhaineann le Táirge le Faisnéis Ilchineálach', 'ka': 'Name', 'el': 'Απάντηση σε ερωτήσεις σχετικά με το προϊόν με ετερογενείς πληροφορίες', 'hu': 'A termékkel kapcsolatos kérdések megválaszolása heterogén információkkal', 'it': 'Rispondere alle domande relative al prodotto con informazioni eterogene', 'kk': 'Үндіктерге қатысты сұрақтардың жауап беру', 'lt': 'Atsakymai į su preparatu susijusius klausimus naudojant heterogeninę informaciją', 'mk': 'Одговарање на прашањата поврзани со производот со хетерогенска информација', 'ms': 'Jawab soalan berkaitan Produk dengan Maklumat Heterogen', 'ml': 'ഹെറോജെന്റിയോ വിവരങ്ങളുമായി പ്രൊട്ടോക്ട് ചോദ്യങ്ങള്\u200dക്ക് ഉത്തരം നല്\u200dകുന്നു', 'mt': 'Tweġiba għal Mistoqsijiet relatati mal-Prodott b’Informazzjoni Eteroġenea', 'mn': 'Heterogeneous Information-тай бүтээгдэхүүнтэй асуултуудыг хариулах нь', 'pl': 'Odpowiadanie na pytania związane z produktem za pomocą informacji heterogennych', 'no': 'Svar på produktrelaterte spørsmål med Heterogene informasjon', 'ro': 'Răspunsul la întrebări legate de produs cu informații heterogene', 'sr': 'Odgovor na pitanja vezana za proizvod sa Heterogenijom informacijom', 'so': "Ka jawaabta su'aalaha la xiriira qoyska ee la xiriira qoyska ee la xiriira macluumaadka Heterogeneous", 'si': 'උත්පාදය සම්බන්ධ ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරතික්ෂණය හෙට්\u200dරෝජනියෝ තොරතුරු සමග', 'sv': 'Svara på produktrelaterade frågor med heterogen information', 'ta': 'பொருள் தொடர்புடைய கேள்விகளுக்கு பதிலளிக்கப்படுகிறது', 'ur': 'پروڈکوٹ کے معاملات کے ساتھ سوال جواب دیتے ہیں', 'uz': 'Name', 'vi': 'Đáp ứng sản phẩm với thông tin dị sắc', 'hr': 'Odgovor na pitanja povezanih s proizvodom s Heterogenijom informacijom', 'de': 'Beantwortung produktbezogener Fragen mit heterogenen Informationen', 'id': 'Jawab Pertanyaan Berkait Produk dengan Informasi Heterogen', 'bg': 'Отговаряне на въпроси свързани с продукта с хетерогенна информация', 'nl': 'Het beantwoorden van productgerelateerde vragen met heterogene informatie', 'da': 'Besvarelse af produktrelaterede spørgsmål med heterogene oplysninger', 'sw': 'Jibu maswali yanayohusiana na Product with Heterogeneous information', 'fa': 'پاسخ دادن سوالات مربوط به مواد با اطلاعات تروژن', 'tr': 'Heterogen Maglumat bilen janlaşdyrylýan soraglary jogap berilip', 'af': 'Antwoord met produktverwante vrae met Heterogenieus Informasie', 'hy': 'Պատասխանը արտադրության հետ կապված հարցերին հետերոգեն տեղեկատվության հետ', 'ko': '제품 관련 질문에 이기종 정보로 답변', 'sq': 'Përgjigja pyetjeve të lidhura me prodhimet me informacionin heterogjen', 'am': 'ቦታ፦', 'bs': 'Odgovor na pitanja vezane za proizvod sa Heterogenijom informacijom', 'cs': 'Odpověď na otázky související s produktem pomocí heterogenních informací', 'az': 'Heterogen Malümatı ilə Product-related suallarına cavab vermək', 'et': 'Tootega seotud küsimustele vastamine heterogeense teabega', 'fi': 'Vastaaminen tuotteisiin liittyviin kysymyksiin heterogeenisillä tiedoilla', 'bn': 'Name', 'ca': 'Respondent a preguntes relacionades amb els productes amb informació heterogène', 'jv': 'Gawe Perintah Panjenengan kang Gambar Informasi kanggo Heterogène', 'ha': 'Mai karɓa wa tambayar Farawa da Cikakken Bayani', 'sk': 'Odgovarjanje na vprašanja, povezana z izdelki, s heterogenimi informacijami', 'he': 'לענות על שאלות קשורות למוצרים עם מידע טרוגני', 'bo': 'Heterogeneous ཆ་འཕྲིན་དང་ཐོག་ཏུ་འབྲེལ་བ་དང་མཉམ་དུ་གཏོང་དགོས་པ'}
{'en': 'Providing  instant response  for product-related questions in E-commerce question answering platforms can greatly improve users’ online shopping experience. However, existing product question answering (PQA) methods only consider a single information source such as user reviews and/or require large amounts of labeled data. In this paper, we propose a novel framework to tackle the PQA task via exploiting heterogeneous information including natural language text and attribute-value pairs from two information sources of the concerned product, namely product details and user reviews. A heterogeneous information encoding component is then designed for obtaining unified representations of information with different formats. The sources of the candidate snippets are also incorporated when measuring the question-snippet relevance. Moreover, the  framework  is trained with a specifically designed weak supervision paradigm making use of available answers in the training phase. Experiments on a real-world dataset show that our proposed  framework  achieves superior performance over state-of-the-art models.', 'ar': 'يمكن أن يؤدي توفير استجابة فورية للأسئلة المتعلقة بالمنتج في منصات الإجابة عن الأسئلة في التجارة الإلكترونية إلى تحسين تجربة التسوق عبر الإنترنت للمستخدمين بشكل كبير. ومع ذلك ، فإن طرق الإجابة على أسئلة المنتج (PQA) الحالية لا تراعي سوى مصدر معلومات واحد مثل مراجعات المستخدم و / أو تتطلب كميات كبيرة من البيانات المصنفة. في هذه الورقة ، نقترح إطارًا جديدًا لمعالجة مهمة PQA من خلال استغلال المعلومات غير المتجانسة بما في ذلك نص اللغة الطبيعية وأزواج قيمة السمة من مصدرين للمعلومات للمنتج المعني ، وهما تفاصيل المنتج ومراجعات المستخدم. ثم تم تصميم مكون ترميز المعلومات غير المتجانسة للحصول على تمثيلات موحدة للمعلومات بتنسيقات مختلفة. يتم أيضًا دمج مصادر مقتطفات المرشح عند قياس ملاءمة مقتطف السؤال. علاوة على ذلك ، يتم تدريب الإطار باستخدام نموذج إشراف ضعيف مصمم خصيصًا باستخدام الإجابات المتاحة في مرحلة التدريب. تُظهر التجارب على مجموعة بيانات في العالم الحقيقي أن إطار العمل المقترح يحقق أداءً فائقًا مقارنة بأحدث النماذج.', 'es': 'Proporcionar respuestas instantáneas a las preguntas relacionadas con los productos en las plataformas de respuesta a preguntas de comercio electrónico puede mejorar en gran medida la experiencia de compra en línea Sin embargo, los métodos de respuesta a preguntas sobre productos (PQA) existentes solo tienen en cuenta una única fuente de información, como las reseñas de los usuarios, y/o requieren grandes cantidades de datos etiquetados. En este documento, proponemos un marco novedoso para abordar la tarea de PQA mediante la explotación de información heterogénea, incluidos el texto en lenguaje natural y los pares atributo-valor de dos fuentes de información del producto en cuestión, a saber, los detalles del producto y las reseñas de los usuarios. A continuación, se diseña un componente de codificación de información heterogéneo para obtener representaciones unificadas de información con diferentes formatos. Las fuentes de los fragmentos candidatos también se incorporan al medir la relevancia del fragmento de pregunta. Además, el marco está entrenado con un paradigma de supervisión débil específicamente diseñado que utiliza las respuestas disponibles en la fase de capacitación. Los experimentos en un conjunto de datos del mundo real muestran que nuestro marco propuesto logra un rendimiento superior en comparación con los modelos de última generación.', 'fr': "Fournir une réponse instantanée aux questions relatives aux produits dans les plateformes de réponse aux questions du commerce électronique peut grandement améliorer l'expérience d'achat en ligne des utilisateurs Toutefois, les méthodes de réponse aux questions sur les produits (PQA) existantes ne prennent en compte qu'une seule source d'informations, comme les avis des utilisateurs, et/ou nécessitent de grandes quantités de données étiquetées. Dans cet article, nous proposons un nouveau cadre pour aborder la tâche PQA en exploitant des informations hétérogènes, y compris le texte en langage naturel et les paires attribut-valeur provenant de deux sources d'information du produit concerné, à savoir les détails du produit et les avis des utilisateurs. Un composant de codage d'informations hétérogènes est ensuite conçu pour obtenir des représentations unifiées d'informations avec différents formats. Les sources des extraits candidats sont également intégrées lors de la mesure de la pertinence de l'extrait de question. De plus, le cadre est formé avec un paradigme de supervision faible spécialement conçu en utilisant les réponses disponibles dans la phase de formation. Des expériences sur un jeu de données réel montrent que le framework que nous proposons atteint des performances supérieures à celles des modèles de pointe.", 'pt': 'Fornecer respostas instantâneas para perguntas relacionadas a produtos em plataformas de resposta a perguntas de comércio eletrônico pode melhorar muito a experiência de compra online dos usuários. No entanto, os métodos existentes de resposta a perguntas do produto (PQA) consideram apenas uma única fonte de informação, como avaliações de usuários e/ou exigem grandes quantidades de dados rotulados. Neste artigo, propomos uma nova estrutura para lidar com a tarefa de PQA por meio da exploração de informações heterogêneas, incluindo texto em linguagem natural e pares de valor de atributo de duas fontes de informação do produto em questão, ou seja, detalhes do produto e avaliações de usuários. Um componente de codificação de informações heterogêneas é então projetado para obter representações unificadas de informações com diferentes formatos. As fontes dos snippets candidatos também são incorporadas ao medir a relevância do snippet de pergunta. Além disso, a estrutura é treinada com um paradigma de supervisão fraco especificamente projetado, fazendo uso das respostas disponíveis na fase de treinamento. Experimentos em um conjunto de dados do mundo real mostram que nossa estrutura proposta alcança desempenho superior em relação aos modelos de última geração.', 'zh': '于电子商务问答平台中供产物相关者即时响应,可大改用户者网购验。 然见物问答 (PQA) 法惟思单信息源,如用户论/,多所标数。 本文有新框架,因两物相关者信息源(即产品详细信息与用户论)异构息(自然语言文属性-值对)以决PQA务。 然后设一异构信息编码组件,以得异式之信。 量事片段相关性时,并选代码本。 此外,宜框架用专计弱监范式培训之,利用培训段者可对案。 真实世界数集之实验,吾言框架先于至先者也。', 'ja': 'Eコマースの質問回答プラットフォームで製品関連の質問に即座に回答することで、ユーザーのオンラインショッピングエクスペリエンスを大幅に向上させることができます。 ただし、既存の製品質問回答（ PQA ）方法は、ユーザーレビューなどの単一の情報源のみを考慮し、および/または大量のラベル付けされたデータを必要とします。 本稿では，対象製品の2つの情報源，すなわち製品の詳細とユーザーレビューから，自然言語のテキストと属性値のペアを含む異種情報を活用することにより， PQAタスクに取り組むための新たな枠組みを提案する． 次いで、異種情報符号化コンポーネントは、異なるフォーマットを有する情報の統一された表現を取得するように設計される。 質問スニペットの関連性を測定する際に、候補スニペットのソースも組み込まれます。 さらに、フレームワークは、トレーニング段階で利用可能な回答を利用して、特別に設計された弱い監督パラダイムでトレーニングされます。 現実のデータセットでの実験では、提案されたフレームワークが最先端のモデルよりも優れたパフォーマンスを達成していることが示されています。', 'hi': 'ई-कॉमर्स प्रश्न का उत्तर देने वाले प्लेटफार्मों में उत्पाद से संबंधित प्रश्नों के लिए त्वरित प्रतिक्रिया प्रदान करना उपयोगकर्ताओं के ऑनलाइन शॉपिंग अनुभव में बहुत सुधार कर सकता है। हालांकि, मौजूदा उत्पाद प्रश्न उत्तर (PQA) विधियाँ केवल एक ही जानकारी स्रोत पर विचार करती हैं जैसे कि उपयोगकर्ता समीक्षाएँ और / या लेबल किए गए डेटा की बड़ी मात्रा की आवश्यकता होती है। इस पेपर में, हम संबंधित उत्पाद के दो सूचना स्रोतों से प्राकृतिक भाषा पाठ और विशेषता-मूल्य जोड़े सहित विषम जानकारी का शोषण करने के माध्यम से PQA कार्य से निपटने के लिए एक उपन्यास ढांचे का प्रस्ताव करते हैं, अर्थात् उत्पाद विवरण और उपयोगकर्ता समीक्षा। एक विषम जानकारी एन्कोडिंग घटक तब विभिन्न प्रारूपों के साथ जानकारी के एकीकृत प्रतिनिधित्व प्राप्त करने के लिए डिज़ाइन किया गया है। प्रश्न-स्निपेट प्रासंगिकता को मापते समय उम्मीदवार स्निपेट के स्रोतों को भी शामिल किया जाता है। इसके अलावा, ढांचे को विशेष रूप से डिज़ाइन किए गए कमजोर पर्यवेक्षण प्रतिमान के साथ प्रशिक्षित किया जाता है जो प्रशिक्षण चरण में उपलब्ध उत्तरों का उपयोग करता है। एक वास्तविक दुनिया डेटासेट पर प्रयोगों से पता चलता है कि हमारा प्रस्तावित ढांचा अत्याधुनिक मॉडल पर बेहतर प्रदर्शन प्राप्त करता है।', 'ru': 'Мгновенный ответ на вопросы, связанные с продуктами, на платформах ответов на вопросы электронной коммерции может значительно повысить удобство онлайн-покупок для пользователей. Тем не менее, существующие методы ответа на вопросы о продукте (PQA) учитывают только один источник информации, такой как обзоры пользователей и/или требуют больших объемов маркированных данных. В этой статье мы предлагаем новую структуру для решения задачи PQA путем использования гетерогенной информации, включая текст на естественном языке и пары "атрибут-значение" из двух источников информации о соответствующем продукте, а именно сведений о продукте и обзоров пользователей. Компонент гетерогенного кодирования информации затем предназначен для получения унифицированных представлений информации с различными форматами. Источники снимков-кандидатов также учитываются при измерении релевантности снимков вопросов. Кроме того, в рамках подготовки кадров используется специально разработанная парадигма слабого надзора с использованием имеющихся ответов на этапе подготовки кадров. Эксперименты с реальным набором данных показывают, что предлагаемая нами система обеспечивает превосходную производительность по сравнению с современными моделями.', 'ga': 'Is féidir feabhas mór a chur ar thaithí siopadóireachta ar líne na n-úsáideoirí trí fhreagra láithreach a sholáthar ar cheisteanna a bhaineann le táirgí ar ardáin freagartha ceisteanna Ríomhthráchtála. Mar sin féin, ní bhreathnaíonn modhanna freagartha ceisteanna táirge (PQA) atá ann faoi láthair ach ar fhoinse amháin faisnéise amhail léirmheasanna úsáideoirí agus/nó éilíonn siad líon mór sonraí lipéadaithe. Sa pháipéar seo, molaimid creat nua chun dul i ngleic leis an tasc PQA trí leas a bhaint as faisnéis ilchineálach lena n-áirítear téacs teanga nádúrtha agus péirí luach aitreabúide ó dhá fhoinse faisnéise den táirge lena mbaineann, eadhon sonraí an táirge agus léirmheasanna úsáideoirí. Deartar comhpháirt ilchineálach um ionchódú faisnéise ansin chun léiriúcháin aontaithe faisnéise a fháil le formáidí éagsúla. Cuimsítear foinsí ghearrthóga na n-iarrthóirí freisin agus ábharthacht na gceisteanna agus an mhírbhiotán á thomhas. Ina theannta sin, tá an creat oilte le paraidím maoirseachta lag atá deartha go sonrach agus baintear úsáid as na freagraí atá ar fáil sa chéim oiliúna. Léiríonn turgnaimh ar thacar sonraí ón bhfíorshaol go mbaineann ár gcreat molta feidhmíocht níos fearr i gcomparáid le samhlacha den scoth.', 'el': 'Η παροχή άμεσης απάντησης για ερωτήσεις σχετικά με το προϊόν στις πλατφόρμες απαντήσεων ερωτήσεων ηλεκτρονικού εμπορίου μπορεί να βελτιώσει σημαντικά την εμπειρία αγορών των χρηστών. Ωστόσο, οι υπάρχουσες μέθοδοι απάντησης ερωτήσεων προϊόντων (PQA) λαμβάνουν υπόψη μόνο μια ενιαία πηγή πληροφοριών, όπως σχόλια χρηστών και/ή απαιτούν μεγάλες ποσότητες δεδομένων με ετικέτα. Στην παρούσα εργασία, προτείνουμε ένα νέο πλαίσιο για την αντιμετώπιση του έργου ΠQA μέσω της αξιοποίησης ετερογενών πληροφοριών, συμπεριλαμβανομένων κειμένων φυσικής γλώσσας και ζευγαριών χαρακτηριστικών-αξίας από δύο πηγές πληροφοριών του οικείου προϊόντος, δηλαδή λεπτομέρειες προϊόντος και αξιολογήσεις χρηστών. Στη συνέχεια, ένα ετερογενές στοιχείο κωδικοποίησης πληροφοριών σχεδιάζεται για την απόκτηση ενοποιημένων αναπαραστάσεων πληροφοριών με διαφορετικές μορφές. Οι πηγές των υποψηφίων αποσπασμάτων ενσωματώνονται επίσης κατά τη μέτρηση της συνάφειας ερωτήσεων-αποσπασμάτων. Επιπλέον, το πλαίσιο εκπαιδεύεται με ένα ειδικά σχεδιασμένο αδύναμο πρότυπο επίβλεψης χρησιμοποιώντας διαθέσιμες απαντήσεις στη φάση κατάρτισης. Τα πειράματα σε ένα πραγματικό σύνολο δεδομένων δείχνουν ότι το προτεινόμενο πλαίσιο επιτυγχάνει ανώτερη απόδοση σε σχέση με μοντέλα τελευταίας τεχνολογίας.', 'hu': 'A termékkel kapcsolatos kérdésekre az e-kereskedelmi kérdésre adott azonnali válasz jelentősen javíthatja a felhasználók online vásárlási élményét. A meglévő termékkérdésre válaszoló (PQA) módszerek azonban csak egyetlen információforrást, például felhasználói értékeléseket vesznek figyelembe, és/vagy nagy mennyiségű címkézett adatot igényelnek. Ebben a tanulmányban egy új keretrendszert javasolunk a PQA feladat megoldására az érintett termék két információforrásából, nevezetesen a termék részleteiből és a felhasználói értékelésekből származó heterogén információk, beleértve a természetes nyelvű szövegeket és attribútum-érték párokat. Ezután egy heterogén információkódoló összetevőt terveztek az információk egységes ábrázolására különböző formátumokban. A jelölt részletek forrásait a kérdés-részlet relevanciájának mérésekor is figyelembe veszik. Ezenkívül a keretrendszert egy speciálisan kialakított gyenge felügyeleti paradigmával képezik, amely a képzési szakaszban rendelkezésre álló válaszokat használja fel. Egy valós adatkészleten végzett kísérletek azt mutatják, hogy javasolt keretrendszerünk kiváló teljesítményt ér el a korszerű modellekhez képest.', 'ka': 'E-commerce კითხვების პასუხისთვის შესაძლებელია ძალიან გაუკეთება მომხმარებელების online shopping experience. მაგრამ მსგავსი პროდისტის კითხვის გასაღები (PQA) მეტოვები მხოლოდ ერთი ინფორმაციის ფოსტა, როგორც მომხმარებელი განახლება და/ან უნდა მოჭირდება დიდ ზოგიერთი ამ დომენტში ჩვენ პროგრამის პროგრამის პროგრამის ორი ინფორმაციის გამოსახულება, რომელიც პროგრამის დეტალები და გამოსახულებელი გამოსახულებული ინფორმაციის გამოსახულებაში პროგრამის პროგრამის პროგრამის პროგ Name კონდიდეტური სნეპტების ფონტები კიდევ იყენება, როდესაც კითხვის სნეპტების მნიშვნელობის შესახებ. დამატებით, ფრამეტრი განაკეთებულია სპექტიკურად განაკეთებული დანარჩენის პარადიგმა, რომელიც შესაძლებელი პასუხების გამოყენება განაკეთებების ფაზში. ექსპერიმენტები რეალური მსოფლიოს მონაცემების შესახებ, რომ ჩვენი პროგრამები უფრო მეტად უფრო მეტად მონაცემების შესახებ.', 'it': "Fornire risposte istantanee alle domande relative ai prodotti nelle piattaforme di risposta alle domande di E-commerce può migliorare notevolmente l'esperienza di acquisto online degli utenti. Tuttavia, i metodi di risposta alle domande di prodotto esistenti (PQA) considerano solo una singola fonte di informazioni come le recensioni degli utenti e/o richiedono grandi quantità di dati etichettati. In questo articolo, proponiamo un nuovo framework per affrontare il compito PQA sfruttando informazioni eterogenee tra cui testo in linguaggio naturale e coppie attributo-valore provenienti da due fonti di informazione del prodotto interessato, vale a dire i dettagli del prodotto e le recensioni degli utenti. Un componente eterogeneo di codifica delle informazioni è quindi progettato per ottenere rappresentazioni unificate delle informazioni con formati diversi. Le fonti degli snippet dei candidati sono anche incorporate quando si misura la rilevanza di question-snippet. Inoltre, il framework è formato con un paradigma di supervisione debole specificamente progettato facendo uso delle risposte disponibili nella fase di formazione. Esperimenti su un set di dati del mondo reale dimostrano che il framework proposto raggiunge prestazioni superiori rispetto ai modelli all'avanguardia.", 'lt': "Providing instant response for product-related questions in E-commerce question answering platforms can greatly improve users' online shopping experience.  Tačiau esamuose produktų klausimų atsakymo (PQA) metoduose atsižvelgiama tik į vieną informacijos šaltinį, pvz., naudotojų peržiūras ir (arba) reikalaujama didelio kiekio etiketėmis pažymėtų duomenų. Šiame dokumente siūlome naują sistemą PQA užduotims spręsti naudojant įvairiapusią informaciją, įskaitant natūralių kalbų tekstą ir atributų ir vertės poros iš dviejų atitinkamo produkto informacijos šaltinių, t. y. produkto detales ir vartotojų peržiūras. Tuomet heterogeniška informacijos kodavimo sudedamoji dalis skirta vienodai atspindėti įvairių formų informaciją. Matuojant klausimų klausimų klausimų klausimų klausimus taip pat įtraukiami kandidatų snippet ų šaltiniai. Be to, sistema parengta taikant specialiai sukurtą silpną priežiūros paradigm ą, naudojant turimus atsakymus mokymo etape. Eksperimentai iš tikrojo pasaulio duomenų rinkinio rodo, kad mūsų siūloma sistema užtikrina geresnius rezultatus nei moderniausi modeliai.", 'kk': 'E-commerce сұрақтарының жауап беру платформаларының онлайн сұрақтарының тез жауап беру мүмкін пайдаланушылардың онлайн сұрақтарының тәжірибесін жақсартуға болады. Бірақ бар продукттың сұрақтарының жауап беру (PQA) әдістері тек пайдаланушылардың қарау мен/немесе жарлық мәліметтердің үлкен санын қажет етеді. Бұл қағазда, біз PQA тапсырмасын жетероген мәліметті қолдану үшін, тәуелді тіл мәтін мен атрибуттық мәнінің екі мәліметтің көзінен, мәліметтің егжей- тегжейлерін және пайдаланушыларды қарау үшін Гетероген мәліметтің кодтамасының компоненті біріктірілген мәліметті түрлі пішімдермен алу үшін құрылады. Кандидаттардың көздері да сұрақ-снипеттің маңыздылығын өлшемінде қосылған. Сонымен қатар, бағдарлама өзгертілген бақылау парадигміне ұқсас беріледі. Бақылау кезінде жауаптарды қолдануға болады. Шын әлемдегі деректер жиынының тәжірибелері біздің қолданатын фрейміміздің күй- жайы моделдерінің жоғары жағдайын жеткізеді.', 'mk': 'Обезбедувањето итен одговор за прашањата поврзани со производите во платформите за одговори на прашањата за електронска трговија може значително да го подобри онлајн купувањето на корисниците. Сепак, постојните методи на одговор на прашањата за производот (PQA) сметаат само за еден извор на информации како што се прегледувањата на корисниците и/или бараат големи количини на обележани податоци. Во овој весник, предложуваме нова рамка за решавање на задачата на ПКА преку искористување хетерогенски информации, вклучувајќи го и текстот на природниот јазик и парови вредности-атрибути од два извори на информации за вклучениот производ, имено деталите на производот и преглед Хетерогенски компонент за кодирање на информациите е потоа дизајниран за добивање единствени претставувања на информациите со различни формати. Изворите на кандидатските снимки се, исто така, вклучени кога се мери релевантноста на прашањето-снимката. Moreover, the framework is trained with a specifically designed weak supervision paradigm making use of available answers in the training phase.  Експериментите на базата на податоци на реалниот свет покажуваат дека нашата предложена рамка постигнува супериорна резултатност над најсовремените модели.', 'ms': 'Menyediakan jawapan segera untuk soalan berkaitan dengan produk dalam platform jawapan soalan e-commerce boleh meningkatkan pengalaman belanja online pengguna. However, existing product question answering (PQA) methods only consider a single information source such as user reviews and/or require large amounts of labeled data.  Dalam kertas ini, kami cadangan baru untuk menangani tugas PQA melalui mengeksploitasi maklumat heterogeni termasuk teks bahasa alami dan pasangan nilai-atribut dari dua sumber maklumat produk tersebut, iaitu perincian produk dan ulasan pengguna. Komponen pengekodan maklumat heterogen kemudian direka untuk mendapatkan perwakilan maklumat yang bersatu dengan format yang berbeza. Sumber snippet calon juga disertai bila mengukur relevansi snippet-soalan. Selain itu, kerangka dilatih dengan paradigm a pengawasan lemah yang direka secara khusus yang menggunakan jawapan tersedia dalam fase latihan. Experiments on a real-world dataset show that our proposed framework achieves superior performance over state-of-the-art models.', 'mt': 'L-għoti ta’ rispons immedjat għal mistoqsijiet relatati mal-prodott fil-pjattaformi li jwieġbu għall-mistoqsijiet dwar il-kummerċ elettroniku jista’ jtejjeb ħafna l-esperjenza tax-xiri onlajn tal-utenti. Madankollu, il-metodi eżistenti li jwieġbu għall-mistoqsijiet dwar il-prodott (PQA) jikkunsidraw biss sors wieħed ta’ informazzjoni bħal reviżjonijiet tal-utent u/jew jeħtieġu ammonti kbar ta’ dejta ttikkettata. F’dan id-dokument, qed nipproponu qafas ġdid biex nindirizzaw il-kompitu tal-PQA permezz tal-isfruttar ta’ informazzjoni eteroġenea inkluż it-test tal-lingwa naturali u l-pari tal-valur tal-attributi minn żewġ sorsi ta’ informazzjoni tal-prodott ikkonċernat, jiġifieri d-dettalji tal-prodott u r-reviżjonijiet tal-utent. Komponent eteroġenu tal-kodifikazzjoni tal-informazzjoni mbagħad huwa ddisinjat biex jinkisbu rappreżentazzjonijiet unifikati tal-informazzjoni b’formati differenti. Is-sorsi tal-snippets kandidati huma inkorporati wkoll meta titkejjel ir-rilevanza tal-snippets tal-mistoqsijiet. Barra minn hekk, il-qafas huwa mħarreġ b’paradigm a ta’ superviżjoni dgħajfa mfassla speċifikament li tuża t-tweġibiet disponibbli fil-fażi tat-taħriġ. Experiments on a real-world dataset show that our proposed framework achieves superior performance over state-of-the-art models.', 'ml': 'പ്ലാറ്റ്ഫോമുകള്\u200dക്ക് ഉത്തരം നല്\u200dകുന്നതിനുള്ള ഇ-കമ്പനിസ് ചോദ്യങ്ങള്\u200dക്ക് ഉടനെ ഉത്തരവ് നല്\u200dകുന്നതിന് ഉപയോക്താക്കളുടെ ഓ എന്നാലും നിലവിലുള്ള പ്രൊജറ്റ് ചോദ്യം ഉത്തരം നല്\u200dകുന്നത് (പിക്യൂഎ) രീതികള്\u200d ഉപയോക്താവിന്റെ പരിശോധനവും /അല്ലെങ്കില്\u200d ലേബെ ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d പിക്യൂഎ ജോലിയെ തിരഞ്ഞെടുക്കാന്\u200d പ്രാധാന്യ വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നതിലൂടെ പ്രാവേകഭാഷ വിവരങ്ങളും പ്രധാനപ്പെട്ട വിവരങ്ങളുടെ രണ് വ്യത്യസ്ത ഫോര്\u200dമാറ്റുകളുമായി വിവരങ്ങളുടെ പ്രതിനിധികള്\u200d ലഭ്യമാക്കുന്നതിനായി ഒരു ഹെറോജനീസ് വിവരങ്ങള്\u200d കോഡിങ പ്രാര്\u200dത്ഥിക്കുന്ന സ്നിപ്പെറ്റുകളുടെ സ്രോതസ്സുകളും ചേര്\u200dക്കുന്നു അതുകൊണ്ടും, ഈ ഫ്രെയിമെയില്\u200d പ്രത്യേകിച്ച് ദുര്\u200dബലനിരീക്ഷിക്കപ്പെട്ട ഒരു പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു. പര ഒരു യഥാര്\u200dത്ഥ ലോക ഡാറ്റാസേറ്റിലെ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട ഫ്രെയിമേക്ക് സ്', 'no': 'Tilbyr ein øyeblikk svar på produktrelaterte spørsmål i e-kommerksspørsmålet som svarar på e-kommerksplattformar, kan mykje forbetra brukaren sin online shopping experience. Det eksisterande metodar for å svara på produktspørsmål (PQA) gjer imidlertid berre eit enkelt informasjonskjelde som brukarausjonar og/eller krev stor mengda merkelige data. I denne papiret foreslår vi eit nytt rammeverk for å handsama PQA-oppgåva ved å bruka heterogenesk informasjon, inkludert naturspråkstekst og attributtverdi-par frå to informasjonskjelde for det tilgjengelege produktet, dvs. produktdetaljar og brukargrensesjonar. Ein heterogenesk informasjonskodingskomponent er derfor utforma for å få unifiserte representasjonar av informasjon med ulike formatar. Kjeldene til kandidatsnippet er også inkluderte når du målar svar på spørsmålssnippet. I tillegg er rammeverket utlært med eit spesielt utforma svakt overvaking paradigm som gjer bruk av tilgjengelege svar i øvingsfasen. Eksperimentar på eit datasett for verkeleg verda viser at vår foreslått rammeverk gjer høgre utvikling over kunstmodeller.', 'ro': 'Oferirea unui răspuns instantaneu la întrebările legate de produse în platformele de răspuns la întrebări de comerț electronic poate îmbunătăți considerabil experiența de cumpărături online a utilizatorilor. Cu toate acestea, metodele existente de răspuns la întrebările produselor (PQA) iau în considerare doar o singură sursă de informații, cum ar fi recenziile utilizatorilor și/sau necesită cantități mari de date etichetate. În această lucrare, propunem un cadru nou pentru abordarea sarcinii PQA prin exploatarea informațiilor eterogene, inclusiv a textului limbajului natural și a perechilor atribute-valoare din două surse de informații ale produsului în cauză, și anume detaliile produsului și recenziile utilizatorilor. O componentă eterogenă de codificare a informațiilor este apoi concepută pentru obținerea reprezentărilor unificate ale informațiilor cu diferite formate. Sursele fragmentelor candidate sunt, de asemenea, incluse atunci când se măsoară relevanța fragmentelor de întrebare. Mai mult decât atât, cadrul este instruit cu o paradigmă de supraveghere slabă concepută special, utilizând răspunsurile disponibile în faza de formare. Experimentele pe un set de date din lumea reală arată că cadrul nostru propus obține performanțe superioare față de modelele de ultimă generație.', 'pl': 'Zapewnienie natychmiastowej odpowiedzi na pytania związane z produktem w platformach e-commerce może znacznie poprawić wrażenia użytkowników z zakupami online. Jednak istniejące metody odpowiedzi na pytania produktowe (PQA) uwzględniają tylko jedno źródło informacji, takie jak opinie użytkowników i/lub wymagają dużej ilości etykietowanych danych. W niniejszym artykule proponujemy nowe ramy rozwiązania zadania PQA poprzez wykorzystanie heterogenicznych informacji, w tym tekstu języka naturalnego oraz par atrybutów-wartości, z dwóch źródeł informacji o danym produkcie, a mianowicie szczegółów produktu i recenzji użytkowników. Następnie zaprojektowany jest różnorodny komponent kodowania informacji w celu uzyskania ujednoliconych reprezentacji informacji o różnych formatach. Źródła fragmentów kandydatów są również uwzględniane podczas pomiaru znaczenia fragmentów pytania. Ponadto ramy są szkolone w oparciu o specjalnie zaprojektowany paradygmat słabego nadzoru wykorzystujący dostępne odpowiedzi na etapie szkolenia. Eksperymenty na rzeczywistym zbiorze danych pokazują, że proponowany framework osiąga lepszą wydajność w porównaniu z najnowocześniejszymi modelami.', 'mn': 'Э-худалдааны асуултын хариултын платформуудад бүтээгдэхүүнтэй холбоотой асуултуудын шууд хариулт гаргах нь хэрэглэгчдийн онлайн худалдааны туршлагыг ихэвчлэн сайжруулж чадна Гэхдээ бараг бүтээгдэхүүний асуултын хариулт (PQA) арга нь зөвхөн хэрэглэгчийн шинжилгээ болон/эсвэл маш их хэмжээний тэмдэглэгдсэн мэдээллийн эх үүсвэр гэж боддог. Энэ цаасан дээр бид PQA-ын ажил дээр байгалийн хэл текст болон харьцаа үнэ цэнэтэй хоёр мэдээллийн эх үүсвэрээс хоёр мэдээллийн эх үүсвэрээс холбогдох шинэ хэлбэрийг ашиглаж, бүтээгдэхүүний details болон хэрэглэгчийн шинжилгээ ашигла Хетероген мэдээллийн кодломжтой компонент нь өөр хэлбэртэй мэдээллийн нэгдсэн илтгэл гаргахад зориулагдсан. Харин сонголтын хэмжээсүүдийн эх үүсвэр нь асуулт асуудлын хамааралтай байдлыг хэмжээхэд мөн нэгдэж байна. Үүнээс гадна хэмжээсүүд нь сургалтын дасгал дээр хариултыг ашиглаж чадах сул хандлагын парадигмыг тодорхой бүтээгдэхүүнээр сургалт хийгдсэн. Үнэндээ дэлхийн өгөгдлийн сангийн туршилтын туршилт нь бидний санал дэвшүүлсэн хэлбэрүүд урлагийн загвараас илүү өндөр үйл ажиллагааг гаргадаг.', 'so': "Jawaab dhaqso ah oo ku siinaya su'aalaha la xiriira ganacsiga ee ka jawaaba jardiinada ganacsiga ee E-shirkadda waxaad si weyn u bedelan kartaa aragtida ganacsiga ee internetka. Si kastaba ha ahaatee, jawaabta su'aalaha waxyaabaha jiraa (PQA) qaababka ay ka fikiraan nooc macluumaad oo kaliya, sida wargelinta iyo/ama u baahan yihiin macluumaad badan oo la qoray. Qoraalkan waxaynu ka soo jeedaynaa qoraal warqad ah si aan u tacliino shaqada PQA via isticmaalka macluumaadka kala duduwan, kuwaas oo ah macluumaadka afka dabiiciga ah iyo labada nooc ee macluumaadka la xiriira, tusaale ahaan dhaqaalaha macluumaadka iyo baaritaanka isticmaalayaasha. Wixii macluumaad kooxa la xiriira waxaa lagu sameeyaa marka lagu qorayo in lagu helo noocyo kala duduwan oo macluumaad ah. Waxaa sidoo kale lagu qoraa alaabta suurtagalka ah marka lagu qiyaasayo habka suurtagalka. Sidoo kale waxaa lagu tababariyaa firaaqada lagu qoray qaab gaar ah oo lagu talo galay ilaalinta taageerada oo isticmaalaya jawaabaha la heli karo fasaxa waxbarashada. Imtixaamo ku saabsan macluumaadka qaranka ee caalamiga ah waxay muujiyaan in qashinkeennu uu soo jeeday ay ay sameyn karaan tababar ka sarreeya samooyinka farshaxanka.", 'sv': 'Att ge omedelbar respons på produktrelaterade frågor i e-handelsplattformar kan avsevärt förbättra användarnas onlineshoppingupplevelse. Dock beaktar befintliga metoder för att besvara produktfrågor endast en enda informationskälla som användarrecensioner och/eller kräver stora mängder märkta data. I denna uppsats föreslår vi ett nytt ramverk för att hantera PQA-uppgiften genom att utnyttja heterogen information inklusive text på naturligt språk och attribut-värdepar från två informationskällor för den berörda produkten, nämligen produktinformation och användarrecensioner. En heterogen informationskodningskomponent utformas sedan för att erhålla enhetliga representationer av information med olika format. Källorna till kandidatutdragen tas också med vid mätning av frågeutdragets relevans. Dessutom utbildas ramverket med ett särskilt utformat svagt handledningsparadis som utnyttjar tillgängliga svar i utbildningsfasen. Experiment på en verklig datauppsättning visar att vårt föreslagna ramverk uppnår överlägsen prestanda jämfört med state-of-the-art modeller.', 'sr': 'Postavljanje trenutnog odgovora na pitanja vezane za proizvod u pitanju e-komercijalnog pitanja na platformama odgovora na odgovor na pitanje može mnogo poboljšati iskustvo online kupovine korisnika. Međutim, postojeće metode odgovora na pitanje proizvoda (PQA) smatraju jedinstvenim izvorom informacija poput pregleda korisnika i/ili zahteva velike količine označenih podataka. U ovom papiru predlažemo novi okvir za rješavanje zadatka PQA, koristeći heterogenezne informacije uključujući prirodni tekst jezika i parove prirodne vrijednosti od dva izvora informacija dotaknutog proizvoda, to je detalje proizvoda i preglede korisnika. Potom je heterogenena komponenta kodiranja informacija dizajnirana za dobivanje ujedinjenih predstavljanja informacija sa različitim formatima. Izvori kandidatskih snippeta takođe su uključeni kada se mjeri relevantnost pitanja. Osim toga, okvir je obučen posebno dizajniranim slabom paradigmom nadzora koji koristi dostupne odgovore na fazi obuke. Eksperimenti na setu podataka u stvarnom svijetu pokazuju da naš predloženi okvir postiže superiornu izvršnost nad modelima države umjetnosti.', 'si': 'Name නමුත්, තියෙන්නේ ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරශ්න (PQA) ප්\u200dරශ්නයක් ප්\u200dරශ්න විතරයි, ප්\u200dරයෝජකයා පරීක්ෂණය සහ/නැත්න මේ පැත්තේ, අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නය භාෂාව පාළුවන් සහ ගොඩක් විශ වෙනස් විදියට තොරතුරු සංකේතනයක් සැකසුම් වෙනුවෙන් තොරතුරු සංකේතනයක් ලැබීමට සැකසුම් කරයි. ප්\u200dරශ්නය-ස්නිප්ට් ගැන අවශ්\u200dය විශ්වාසයෙන් අවශ්\u200dය වෙනුවෙන් ස්නිප්ට් ස්ථානය කරනවා. ඒ වගේම, ප්\u200dරශ්නයක් විශේෂයෙන් විශේෂයෙන් නිර්මාණය කරපු ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් තියෙනවා ප්\u200dරශ ඇත්ත ලෝකයේ දත්ත සැට් එකේ පරීක්ෂණය පෙන්වන්නේ අපේ ප්\u200dරයෝජනය කරපු පරීක්ෂණයක් විශ්වාස කරනවා කියලා.', 'ta': "Providing instant response for product-related questions in E-commerce question answering platforms can greatly improve users' online shopping experience.  ஆனால், இருக்கும் பொருள் கேள்வி பதில் (PQA) முறைமைகள் பயனர் முகவரி மற்றும்/அல்லது குறிப்பிட்ட தரவு பெரிய அளவு தேவை இந்த காகிதத்தில், நாம் ஒரு புதிய சட்டத்தை பிகியூஏ செயல்பாட்டில் செயல்படுத்துவதற்கு தேவைப்பட்டுள்ள இரண்டு தகவல் மூலங்களில் இரு தகவல் மூலங்களில் இருந்து இயற வெவ்வேறு வடிவங்களுடன் ஒன்றிணைக்கப்பட்ட தகவல் குறியீட்டு பொருள் வடிவமைக்கப்பட்டுள்ளது. தேர்ந்தெடுக்கப்பட்ட கேள்வி ஸ்னிப்ட் தொடர்பை அளவு முறையில் சேர்க்கும் மூலங்களும் சேர்க்கப்பட்டது. மேலும், இந்த சட்டத்தில் ஒரு குறிப்பிட்ட வடிவமைக்கப்பட்ட பலவீனமான கண்காணிப்பு பரிமாற்றம் பயிற்சி செய்யப்படுகிறது,  ஒரு உண்மையான உலக தரவுத்தளத்தின் முன்னோட்டப்பட்ட சட்டத்தில் மேலான செயல்பாடு பெறுகிறது என்று காட்டுகிறது.", 'ur': 'E-commerce سوال کے سوال کے بارے میں اضافہ کے سوال کے لئے فوراً جواب دینے کی ضرورت جواب دینے کی وجہ سے استعمال کرنے والے آنلاین خرپ کرنے کے تجربہ کو بہت زیادہ بہتر کر سکتا ہے. However, existing product question replying (PQA) methods only consider a single information source such as user reviews and/or require large amounts of labeled data. اس کاغذ میں ہم نے ایک نوی فرمیک پیشنهاد کرتا ہے کہ PQA تابع کے ساتھ مختلف معلومات کا استعمال کرے اور طبیعی زبان کی پیغام کے ساتھ دو معلومات کے منبع سے پیدا کریں، یعنی محصولات کا معلومات اور کارساز کی رسی کے ساتھ۔ اس کے بعد مختلف فرموٹوں کے ساتھ معلومات کی ایک متحدہ نمایش حاصل کرنے کے لئے طراحی کی جاتی ہے. سؤال-snippet مرتبہ کے اندازے میں کڈینڈیٹ سکینپٹوں کے سراسر بھی جمع کئے جاتے ہیں. اس کے علاوہ، فرمود ایک مخصوص طراحی کمزور نظر والی پارادیگ کے ساتھ تعلیم کی جاتی ہے کہ تدریس فوج میں موجود جواب استعمال کرتا ہے. ایک حقیقی دنیاوی ڈیٹ سٹ کے تجربے دکھاتے ہیں کہ ہمارے پیشنهاد فرمود کے ذریعے بہترین عملکرد حاصل کرتا ہے.', 'uz': "Name However, existing product question answering (PQA) methods only consider a single information source such as user reviews and/or require large amounts of labeled data.  Bu hujjatda, biz ma'lumotning ikki maʼlumot manbasidagi tarkibi tilning tabiiy matnni va attribute qiymatining ikki maʼlumotlar manbasiga PQA vazifani boshqarish orqali rivojlanishni istaysiz. Name @ info: whatsthis Ko'rsatilgan, freym taʼminlovchi darajada mavjud javoblarni ishlatish mumkin. Mavjud dunyo maʼlumotlar tarkibini tajriba qilish imkoniyatlarimiz, yaxshi ko'paytirilgan freymmiz sohalar modellari davlatdan yuqori bajarish imkoniyatini bajaradi.", 'vi': 'Cung cấp đáp ứng ngay cho các câu hỏi có liên quan đến sản phẩm trong câu hỏi trả lời trên mạng có thể cải thiện kinh nghiệm mua sắm trực tuyến. Tuy nhiên, các phương pháp trả lời câu hỏi hàng tồn tại (PQA) chỉ cân nhắc một nguồn thông tin duy nhất như kiểm tra người dùng và/ hay đòi hỏi một lượng lớn dữ liệu dán nhãn. Trong tờ giấy này, chúng tôi đề xuất một cơ sở mới để giải quyết nhiệm vụ PQA bằng cách khai thác các thông tin khác nhau, gồm cả ngôn ngữ tự nhiên và giá trị của các tài liệu từ hai nguồn thông tin của sản đó, cụ thể là chi tiết hàng hóa và kiểm tra người dùng. Một thành phần mã hóa thông tin khác nhau được thiết kế để đạt được các biểu tượng thống nhất về thông tin với các mô hình khác nhau. Nguồn gốc của các đoạn trích ứng cử viên cũng được áp dụng khi đánh giá nguồn liên quan của các câu hỏi. Hơn nữa, cơ chế được đào tạo với một mô hình chỉ dẫn yếu đặc biệt thiết kế, sử dụng các câu trả lời có sẵn trong giai đoạn huấn luyện. Các thí nghiệm trên một bộ dữ liệu thực tế cho thấy rằng bộ khung của chúng tôi đạt được hiệu suất cao hơn các mô hình hiện đại.', 'nl': 'Het bieden van direct antwoord op productgerelateerde vragen in e-commerce vragenantwoordplatforms kan de online winkelervaring van gebruikers aanzienlijk verbeteren. Bestaande methoden voor het beantwoorden van productvragen (PQA) houden echter slechts rekening met één informatiebron, zoals gebruikersbeoordelingen en/of vereisen grote hoeveelheden gelabelde gegevens. In dit artikel stellen we een nieuw kader voor om de PQA-taak aan te pakken door gebruik te maken van heterogene informatie, waaronder tekst in natuurlijke taal en attribuut-waarde paren uit twee informatiebronnen van het betrokken product, namelijk productdetails en gebruikersreviews. Een heterogene informatie codering component wordt vervolgens ontworpen voor het verkrijgen van uniforme representaties van informatie met verschillende formaten. De bronnen van de kandidaat snippets worden ook meegenomen bij het meten van de vraag-snippet relevantie. Bovendien wordt het raamwerk getraind met een specifiek ontworpen zwak supervisie paradigma waarbij gebruik wordt gemaakt van beschikbare antwoorden in de trainingsfase. Experimenten op een real-world dataset tonen aan dat ons voorgestelde framework superieure prestaties behaalt ten opzichte van state-of-the-art modellen.', 'da': 'At give øjeblikkelig svar på produktrelaterede spørgsmål i e-handels spørgsmål besvarelse platforme kan i høj grad forbedre brugernes online shopping oplevelse. Eksisterende metoder til besvarelse af produktspørgsmål (PQA) tager dog kun hensyn til en enkelt informationskilde som f.eks. brugeranmeldelser og/eller kræver store mængder mærkede data. I denne artikel foreslår vi en ny ramme til løsning af PQA-opgaven ved at udnytte heterogene oplysninger, herunder natursprogtekst og attributværdipar fra to informationskilder for den pågældende vare, nemlig produktoplysninger og brugeranmeldelser. En heterogen informationskodningskomponent er derefter designet til at opnå ensartede repræsentationer af oplysninger med forskellige formater. Kilderne til kandidatudsnittet indarbejdes også ved måling af spørgsmål-udsnittets relevans. Desuden trænes rammerne med et specifikt designet svagt overvågningsparademe, der gør brug af tilgængelige svar i uddannelsesfasen. Eksperimenter med et datasæt i virkeligheden viser, at vores foreslåede ramme opnår overlegen ydeevne i forhold til state-of-the-art modeller.', 'bg': 'Предоставянето на незабавен отговор на въпроси, свързани с продукта в платформите за отговор на въпроси в електронната търговия може значително да подобри онлайн пазаруването на потребителите. Съществуващите методи за отговор на въпроси на продукта обаче разглеждат само един източник на информация, като например потребителски прегледи и/или изискват големи количества етикетирани данни. В настоящата статия предлагаме нова рамка за справяне със задачата за ОКК чрез използване на хетерогенна информация, включително текст на естествен език и двойки атрибути-стойност от два източника на информация за съответния продукт, а именно детайли за продукта и потребителски отзиви. След това хетерогенен информационен кодиращ компонент е предназначен за получаване на единни представи на информация с различни формати. Източниците на фрагментите кандидати също са включени при измерване на релевантността на фрагментите въпрос. Освен това рамката е обучена със специално разработена слаба парадигма за надзор, използвайки наличните отговори във фазата на обучение. Експериментите върху набор от данни от реалния свят показват, че нашата предложена рамка постига превъзходно представяне в сравнение с най-съвременните модели.', 'hr': 'Postavljanje trenutnog odgovora na pitanja vezane za proizvod u pitanju e-trgovine odgovarajućim platformama može znatno poboljšati iskustvo kupovine interneta korisnika. Međutim, postojeće metode odgovora na pitanje proizvoda (PQA) smatraju jedinstvenim izvorom informacija poput pregleda korisnika i/ili zahtijevaju velike količine označenih podataka. U ovom papiru predlažemo novi okvir za rješavanje zadatka PQA-a koristeći heterogenne informacije uključujući tekst prirodnog jezika i parove prirodne vrijednosti od dva izvora informacija dotičnog proizvoda, a to je detalje proizvoda i preglede korisnika. Onda je komponent heterogenenog kodiranja informacija dizajniran za dobivanje ujedinjenih predstavljanja informacija s različitim formatima. Izvori kandidatskih snippeta također su uključeni kada se mjeri relevantnost pitanja. Osim toga, okvir je obučen s određenim slabom paradigmom nadzora koji koristi dostupne odgovore na fazi obuke. Eksperimenti na setu podataka u stvarnom svijetu pokazuju da naš predloženi okvir postiže nadmoćni učinkoviti nad modelima države umjetnosti.', 'de': 'Die sofortige Antwort auf produktbezogene Fragen in E-Commerce-Fragebeantworterplattformen kann das Online-Einkaufserlebnis der Nutzer erheblich verbessern. Bestehende Methoden zur Beantwortung von Produktfragen (PQA) berücksichtigen jedoch nur eine einzige Informationsquelle wie z.B. Nutzerbewertungen und/oder erfordern große Mengen an markierten Daten. In diesem Beitrag schlagen wir ein neuartiges Framework vor, um die PQA-Aufgabe zu bewältigen, indem heterogene Informationen einschließlich natursprachlicher Texte und Attribut-Wert-Paare aus zwei Informationsquellen des betroffenen Produkts, nämlich Produktdetails und Benutzerbewertungen, genutzt werden. Eine heterogene Informationskodierungskomponente wird dann entworfen, um einheitliche Darstellungen von Informationen mit verschiedenen Formaten zu erhalten. Die Quellen der Kandidaten-Snippets werden auch bei der Messung der Frage-Snippet-Relevanz berücksichtigt. Darüber hinaus wird das Framework mit einem speziell entwickelten schwachen Supervisionsparadigma trainiert, das verfügbare Antworten in der Trainingsphase nutzt. Experimente an einem realen Datensatz zeigen, dass unser vorgeschlagenes Framework eine überlegene Leistung gegenüber modernen Modellen erzielt.', 'id': 'Menyediakan jawaban instant untuk pertanyaan berkaitan dengan produk dalam pertanyaan E-commerce menjawab platform dapat meningkatkan pengalaman belanja online pengguna. Namun, metode yang ada untuk menjawab pertanyaan produk (PQA) hanya mempertimbangkan sumber informasi tunggal seperti penelitian pengguna dan/atau memerlukan jumlah besar data yang ditabel. Dalam kertas ini, kami mengusulkan cadangan baru untuk mengatasi tugas PQA melalui mengeksploitasi informasi heterogene termasuk teks bahasa alam dan pasangan nilai-atribut dari dua sumber informasi produk tersebut, yaitu rincian produk dan penelitian pengguna. Komponen pengekodan informasi heterogene kemudian dirancang untuk mendapatkan perwakilan informasi yang bersatu dengan format yang berbeda. Sumber snippet kandidat juga terlibat ketika mengukur relevansi snippet pertanyaan. Selain itu, kerangka dilatih dengan paradigm a pengawasan yang sangat lemah yang direncanakan secara khusus yang menggunakan jawaban yang tersedia dalam fase pelatihan. Eksperimen di dataset dunia nyata menunjukkan bahwa cadangan kami yang diusulkan mencapai prestasi yang lebih baik daripada model terbaik.', 'ko': '전자상거래 질의응답 플랫폼에서 제품 관련 질문에 즉각적인 회답을 제공하면 사용자의 온라인 쇼핑 체험을 크게 개선할 수 있다.그러나 기존의 제품 퀴즈(PQA) 방법은 사용자 평론과/또는 대량의 표기 데이터가 필요한 단일 정보원만 고려한다.본고에서 우리는 새로운 프레임워크를 제시하여 PQA 임무를 처리했다. 이 프레임워크는 관련 제품의 두 가지 정보원(즉 제품 디테일과 사용자 평론)에서 나온 이구적 정보를 활용하여 자연 언어 텍스트와 속성 값 쌍을 포함한다.그리고 서로 다른 형식의 정보를 통일적으로 표시하기 위해 이구적 정보 인코딩 구성 요소를 설계했다.문제 세션의 관련성을 평가할 때 후보 세션의 출처도 포함됩니다.이 프레임워크는 전문적으로 설계된 약한 감독 모델로 교육을 하고 교육 단계의 사용 가능한 답안을 활용한다.실제 데이터 집합에서의 실험은 우리가 제시한 구조가 가장 선진적인 모델보다 더 높은 성능을 가진다는 것을 보여준다.', 'fa': 'اجازه دادن پاسخ فوری برای سوالات مربوط به محصولات تولید در سؤال پاسخ\u200cدهنده\u200cی برنامه\u200cهای برنامه\u200cهای برنامه\u200cهای برنامه\u200cگذاری می\u200cتواند تجربه خرید آنلاین کاربر را بسیار بهتر کند. با این حال، روش\u200cهای پاسخ سوال محصولات موجود (PQA) تنها یک منبع اطلاعاتی مثل تحقیقات کاربر و/یا نیاز به مقدار بزرگی از داده\u200cهای برچسب می\u200cکنند. در این کاغذ، ما یک چهارچوب نوی پیشنهاد می\u200cکنیم تا از طریق استفاده از اطلاعات متفاوتی که شامل متن زبان طبیعی و جفت\u200cهای ارزشمند متفاوتی از دو منبع اطلاعات از محصول متعلق به آن موجود حل کند، یعنی جزئیات محصول و تحقیقات کاربر،  سپس بخش رمزبندی اطلاعات متفاوت برای گرفتن نمایش\u200cهای متحد اطلاعات با فرم\u200cهای متفاوت طراحی می\u200cشود. منبع اسنایپت کاندیداتی همچنین در زمان اندازه مربوط به مربوط به مربوط به مربوط به مربوط به مربوط به مربوط به سؤال ها شامل می شوند. علاوه بر این، چهارچوب با یک پارادیگ نظارت ضعیف طراحی شده است که از پاسخهای موجود در مرحله آموزش استفاده می کند. تجربه\u200cها در مجموعه داده\u200cهای دنیای واقعی نشان می\u200cدهند که چهارچوب پیشنهاد ما در مورد مدل\u200cهای دولتی هنر انجام می\u200cدهد.', 'sw': 'Kutoa majibu ya haraka kwa maswali yanayohusiana na bidhaa katika maswali ya biashara ya E-biashara yanaweza kuboresha uzoefu wa manunuzi mtandaoni. Hata hivyo, mbinu zilizopo zinazojibu swali la bidhaa (PQA) zinachukua chanzo moja tu cha habari kama vile utafiti wa watumiaji na/au zinahitaji kiasi kikubwa cha taarifa zilizowekwa. Katika gazeti hili, tunapendekeza mfumo wa riwaya wa kukabiliana na kazi ya PQA kwa kutumia taarifa za asili ikiwa ni pamoja na maandishi ya lugha asili na thamani mbili kutoka vyanzo vya habari vya bidhaa zinazohusika, ikiwa ni maelezo ya kina na utafiti wa watumiaji. Kifaa cha taarifa kinachojumuisha kwa kiasi kikubwa kinaundwa kwa ajili ya kupata uwakilishi wa taarifa kwa namna tofauti. Chanzo za vikosi vya wagombea pia zinajumuishwa pale wakipima umuhimu wa suala hilo. Zaidi ya hayo, mfumo huo umefundishwa na utaratibu wa ufuatiliaji wa udhaifu unaotumia majibu yanayopatikana katika hatua ya mafunzo. Majaribio kwenye seti ya taarifa za dunia halisi yanaonyesha kuwa mfumo wetu unapendekezwa unafanikiwa ufanisi wa ubora wa hali ya sanaa.', 'tr': 'E-komerca soragy üçin täsirli soraglary üçin aýratyn jogap berilýär. Ýöne bolan näçe produkt soragy jogap (PQA) yöntemleri diňe ullançy maslahat çeşmesi ýaly ýeke bir maglumat çeşmesini we/ýada etilgeli maglumatyň uly kadalaryny talap edýär. Bu kagyzda, biz PQA zadyny beýleki maglumatlary ulanyp, tebigy dil metin we hasaplanjak üçin iki maglumatyň çeşmesinden, munuň hasaplanjak we ullanyşyň barlamagyny teklip etmek üçin bir roman çerçevesini teklip edýäris. Eterogenen maglumat ködleme komponenti indir, beýleki biçimler bilen birleşmiş maglumaty ýerine ýetirmek üçin tasarlanýar. Adatça snippeleriniñ kaynaklary soragynyň relevantyny ölçünde hem çykyp bardyr. Munuň üçin, çerýäk düzümlenmiş azajyk nadirim paradigmy bilen bilim taýýarlanmasynda jogaplary ulanýar. Gerçek dünýäde maglumat setirinde örän barlag biziň teklip eden çarpyşymyz möhüm nusgalaryň üstünden başarýandygyny görkezýär.', 'af': "Die verskaffing van ongelukkige antwoord vir produktverwante vrae in e-kommerksie vraag antwoord platforme kan groot verbeter gebruikers se online koop-erfaring. Alhoewel, bestaande produktvraag antwoord (PQA) metodes bedoel slegs 'n enkele inligting bron soos gebruiker hersiening en/of benodig groot hoeveelheid etiketeerde data. In hierdie papier voorstel ons 'n nuwe raamwerk om die PQA taak te trek deur die uitbreiding van heterogeneese inligting insluitend natuurlike taal teks en attribute-waarde paar van twee inligting bronne van die betrokke produkt, naamlik produktdetails en gebruikerresensies. Name Die bronne van die kandidate snippets is ook inkorporeer wanneer die vraag-snippet relevansie gemeet word. Ook, die raamwerk is onderwerp met 'n spesifieke swak supervisie paradigme wat beskikbaar antwoorde gebruik word in die onderwerp fase. Eksperimente op 'n regte wêreld datastel wys dat ons voorgestelde raamwerk superior effektuur verkry oor die staat van die kunste modele.", 'am': 'በኢ-ነጋዴ ጥያቄ ላይ የፍሬት ጉዳይ ጥያቄን ለመቀበል የፕላጦማርቶች መልስ በመጠየቅ ጊዜ የኢንተርኔት ገበያጭ እድል ፈቃድ የተጠቃሚዎችን በመስመር ገበያዎች መሻል ይችላል፡፡ ምንም እንኳን፣ የአሁኑን የፍሬት ጥያቄ መልስ (PQA) ዘዴዎች እንደ ተጠቃሚ ተመልከት እና/ወይም የበለጠ የዳታ ጥያቄ እንዲያስፈልጋቸው ብቻ አንድ የመረጃ ምንጭ ይመልሳሉ። በዚህ ካላት፣ የሥልጣን ቋንቋ ጽሑፍ እና የአፍሪካ ጉዳይ የሁለት መረጃ ክፍሎች፣ የፍጥረት ዝርዝሮች እና የጦማር ክፍል እና የተጠቃሚ ክፍተቶችን በመጠቀም የPQA ሥርዓትን ለመቀናቀል አቅራቢያ እና መፍጠር እና የተጠቃሚ ክፍተቶችን በመጠቀም እና አቅራቢያ እና የሥልዓት መረጃ አካውንድ አካውንድ ክፍል በተለየ ፎርማቶች የተለየ መረጃዎችን ለማግኘት ነው፡፡ የፓርላማው ግንኙነት በሚለካ ጊዜ የአካባቢዎቹ ምንጮች ደግሞ ተጨማሪ ናቸው፡፡ ደግሞም፣ ፍሬመሬት በተለየ ደካማ የስልጣን ማዕከላዊ ፍላጎት በተመሳሳይ፣ በተስተማሪው ደረጃው ውስጥ የተገኘውን መልስ በመጠቀም ያስተምራል፡፡ Experiments on a real-world dataset show that our proposed framework achieves superior performance over state-of-the-art models.', 'az': 'E-ticarət sualına cavab verən platformların online alışveriş təcrübəsini çox yaxşılaşdıra bilər. Ancaq məhsul sualının cavabı (PQA) metodları yalnız istifadəçi tərzlərini və/və ya böyük nömrələri etiketlənmiş məlumatları kimi tək bir məlumat mənbəsini gözləyir. Bu kağızda, biz PQA işini çəkmək üçün yeni bir çerçive təklif edirik. Təbiətli dil metini və təbiətli qiymətli çiftlər də məlumatın iki məlumatın mənbəsindən, məlumatın detaylarını və istifadəçilərini istifadə etmək vasitəsilə istifadə edirik. Bir heterogenel məlumat kodlama komponenti, sonra müxtəlif formatlar ilə birləşdirilmiş məlumatları almaq üçün hazırlanmışdır. Kandidata snippetlərin mənbələri də sual-snippet bağlılığını ölçərkən birləşdirilmişdir. Daha sonra, çarşıq müəyyən edilmiş zəif gözləmə paradigmi ilə təhsil edilir ki, təhsil fəzində faydalanır. Gerçek dünya verilənlərin təcrübələri göstərir ki, təklif edilmiş frameworklərimiz mövcud modellərin üstünlüyünü başa düşər.', 'sq': 'Duke ofruar përgjigje të menjëhershme për pyetjet lidhur me prodhimet në platformet e përgjigjes për pyetjet e tregtisë elektronike mund të përmirësojë mjaft përvojën e blerjeve në internet të përdoruesve. Megjithatë, metodat ekzistuese për përgjigjen e pyetjeve të prodhimit (PQA) konsiderojnë vetëm një burim të vetëm informacioni të tillë si shqyrtimet e përdoruesve dhe/ose kërkojnë sasi të mëdha të të dhënave të etiketuara. In this paper, we propose a novel framework to tackle the PQA task via exploiting heterogeneous information including natural language text and attribute-value pairs from two information sources of the concerned product, namely product details and user reviews.  Një përbërës heterogjene e kodimit të informacionit është projektuar pastaj për të marrë përfaqësime të unifikuara të informacionit me formate të ndryshme. Burimet e kërcimeve të kandidatit janë përfshirë gjithashtu kur matën rëndësinë e kërcimeve. Moreover, the framework is trained with a specifically designed weak supervision paradigm making use of available answers in the training phase.  Eksperimentet në një set të dhënash të botës reale tregojnë se kuadri ynë i propozuar arrin performancë më të lartë se modelet më të moderne.', 'hy': 'Էլեկտրոնային առևտրի հարցերին պատասխանելու հարցերին անմիջական պատասխան տրամադրելը կարող է մեծապես բարելավել օգտագործողների առցանց գնումների փորձը: Այնուամենայնիվ, գոյություն ունեցող արտադրանքի հարցերին պատասխանող մեթոդները ընդունում են միայն մեկ տեղեկատվական աղբյուր, ինչպիսիք են օգտագործողների վերանայմանները և (կամ) պահանջում են մեծ քանակությամբ պիտակ տվյալներ: Այս թղթի մեջ մենք առաջարկում ենք նոր շրջանակ, որպեսզի լուծենք PQA-ի խնդիրը, օգտագործելով հերոգենյա տեղեկատվություն, ներառյալ բնական լեզվի տեքստը և առանձնահատկությունների-արժեքի զույգերը անհանգստացած արտադրության երկու տեղեկատվական Հետո հետերոգեն տեղեկատվության կոդավորման բաղադրիչ է նախագծված տեղեկատվության միասնական ներկայացումների ստանալու համար տարբեր ֆորմատներով: Հարցողի կտորների աղբյուրները ներառված են նաև հարցերի և կտորների կարևորության չափման ժամանակ: Ավելին, շրջանակը կրթություն է ստանում հատուկ ձևավորված թույլ վերահսկողության պարադիգմայով, որը օգտագործում է հասանելի պատասխանները կրթության ժամանակ: Իրական աշխարհի տվյալների համակարգի փորձարկումները ցույց են տալիս, որ մեր առաջարկած շրջանակը հասնում է լավագույն արդյունքների, քան նորագույն մոդելները:', 'cs': 'Poskytování okamžité odpovědi na otázky související s produktem v platformách pro zodpovězení otázek elektronického obchodu může výrazně zlepšit zážitek z online nakupování uživatelů. Stávající metody odpovědi na otázky produktu (PQA) však berou v úvahu pouze jeden zdroj informací, jako jsou recenze uživatelů a/nebo vyžadují velké množství označených dat. V tomto článku navrhujeme nový rámec pro řešení úkolu PQA prostřednictvím využití heterogenních informací včetně textu přirozeného jazyka a párů atributů-hodnoty ze dvou informačních zdrojů dotčeného produktu, konkrétně detailů o produktu a recenzí uživatelů. Následně je navržena heterogenní komponenta kódování informací pro získání jednotných reprezentací informací v různých formátech. Zdroje kandidátských úryvků jsou také zahrnuty při měření relevance úryvku otázky. Navíc je rámec trénován speciálně navrženým paradigmatem slabého dohledu využívajícím dostupných odpovědí ve fázi školení. Experimenty na reálném světě ukazují, že náš navrhovaný framework dosahuje vynikajícího výkonu oproti nejmodernějším modelům.', 'bn': 'ই-বাণিজ্যিক প্রশ্নের প্রশ্নের জন্য দ্রুত প্রতিক্রিয়া প্রদান করে প্ল্যাটফর্মে ব্যবহারকারীদের অনলাইন শপিং অভিজ্ঞতার ব তবে বিদ্যমান প্রযুক্তি প্রশ্নের উত্তর (পিকিউএ) পদ্ধতি শুধুমাত্র একটি তথ্য উৎস যেমন ব্যবহারকারীর প্রতিবেদন এবং/অথবা বিশাল তথ্যের প্ এই কাগজটিতে আমরা প্রস্তাব করি পিকিউএ কাজের মাধ্যমে প্রাকৃতিক ভাষা লেখা এবং বৈশিষ্ট্যের দুই তথ্য উৎস থেকে প্রাকৃতিক তথ্য ব্যবহার করে পিকিউএ কাজের সাথে  বিভিন্ন ধরনের তথ্য প্রতিনিধিত্বের জন্য একটি জাতীয় তথ্য এনকোডিং কম্পোনেন্ট নির্ধারণ করা হয়। প্রার্থীদের স্নিপেটের উৎস একই সাথে যোগাযোগ করা হয়েছে প্রশ্ন-স্নিপেটের প্রাসঙ্গিক পরিমাপের সময়। এছাড়াও, এই ফ্রেমের কাঠামো প্রশিক্ষণ প্রদান করা হয়েছে বিশেষ করে দুর্বল পর্যবেক্ষণ প্যারাডিমের মাধ্যমে যা প্রশিক্ষণে প্রস্তাবিত ফ্রেমের কার্যক্রম দেখাচ্ছে যে রাষ্ট্র-অফ-শিল্প মডেলের চেয়ে বেশী ভালো কার্যক্রম অর্জন করে।', 'bs': 'Postavljanje trenutnog odgovora na pitanja vezane za proizvod u pitanju e-komercijalnog pitanja na platformama odgovarajuće odgovore na pitanje može znatno poboljšati iskustvo kupovine interneta korisnika. Međutim, postojeće metode odgovora na pitanje proizvoda (PQA) smatraju jedinstvenim izvorom informacija poput pregleda korisnika i/ili zahtijevaju velike količine označenih podataka. U ovom papiru predlažemo novi okvir za rješavanje zadatka PQA, koristeći heterogenne informacije uključujući prirodni tekst jezika i parove prirodne vrijednosti od dva izvora informacija dotičnog proizvoda, to je detalje proizvoda i preglede korisnika. Onda je komponent heterogenenog kodiranja informacija dizajniran za dobivanje ujedinjenih predstavljanja informacija sa različitim formatima. Izvori kandidatskih snippeta također su uključeni kada se mjeri relevantnost pitanja. Osim toga, okvir je obučen sa specifično dizajniranom slabom paradigmom nadzora koji koristi dostupne odgovore na fazi obuke. Eksperimenti o setu podataka na stvarnom svijetu pokazuju da naš predloženi okvir postigne nadmoćnu izvršnost nad modelima države umjetnosti.', 'et': 'Tootega seotud küsimustele kohese vastuse pakkumine e-kaubanduse küsimustele vastamise platvormides võib oluliselt parandada kasutajate internetiostukogemust. Olemasolevates tooteküsimustele vastamise meetodites arvestatakse siiski ainult ühte teabeallikat, näiteks kasutajate ülevaateid ja/või nõutakse suurt hulka märgistatud andmeid. Käesolevas dokumendis pakume välja uudse raamistiku põhjaliku kvaliteedi hindamise ülesande lahendamiseks, kasutades ära heterogeenset teavet, sealhulgas looduskeelset teksti ja atribuudi-väärtuse paare asjaomase toote kahest teabeallikast, nimelt toote üksikasjadest ja kasutajate ülevaatest. Seejärel luuakse heterogeenne teabekodeerimiskomponent erinevate formaatidega teabe ühtsete esituste saamiseks. Kandidaadilõike allikad on lisatud ka küsimuse lõike asjakohasuse mõõtmisel. Lisaks sellele koolitatakse raamistikku spetsiaalselt välja töötatud nõrga järelevalveparadigmaga, kasutades koolitusfaasis kättesaadavaid vastuseid. Eksperimentid reaalmaailma andmekogumiga näitavad, et meie pakutud raamistik saavutab parima jõudluse kui kaasaegsed mudelid.', 'fi': 'Välittömän vastauksen tarjoaminen tuotteisiin liittyviin kysymyksiin verkkokaupan kysymysvastausalustoissa voi parantaa huomattavasti käyttäjien verkkokauppakokemusta. Olemassa olevissa tuotekysymysten vastaamismenetelmissä (PQA) otetaan kuitenkin huomioon vain yksi tietolähde, kuten käyttäjien arvostelut, ja/tai vaaditaan suuria määriä merkittyjä tietoja. Tässä artikkelissa ehdotamme uudenlaista kehystä PQA-tehtävän ratkaisemiseksi hyödyntämällä heterogeenistä tietoa, kuten luonnonkielistä tekstiä ja attribuutti-arvo-pareja, kahdesta asianomaisen tuotteen tietolähteestä, eli tuotetiedoista ja käyttäjien arvosteluista. Tämän jälkeen suunnitellaan heterogeeninen tiedon koodauskomponentti, jolla saadaan yhtenäinen esitys eri muodoissa olevasta informaatiosta. Hakijan katkelmien lähteet otetaan huomioon myös kysymyskatkelmien relevanssia mitattaessa. Lisäksi viitekehyksessä käytetään erityisesti suunniteltua heikkoa valvontaparadigmaa, jossa hyödynnetään koulutusvaiheessa saatavilla olevia vastauksia. Kokeet reaaliaikaisella aineistolla osoittavat, että ehdotettu viitekehys saavuttaa ylivoimaisen suorituskyvyn uusimpiin malleihin verrattuna.', 'ca': "La resposta instant ània a preguntes relacionades amb productes en plataformes de resposta a preguntes de comerç electrònic pot millorar molt l'experiència de compra en línia dels usuaris. No obstant això, els mètodes existents de resposta a preguntes de producte (PQA) només consideren una única font d'informació com les revisions dels usuaris i/o requereixen grans quantitats de dades etiquetades. En aquest paper, proposem un nou marc per abordar la tasca PQA explotant informació heterogenea, incloent el text natural del llenguatge i parells de valors-atributs de dues fonts d'informació del producte en qüestió, a saber, els detalls del producte i les revisions dels usuaris. Un component de codificació d'informació heterogène està dissenyat per obtenir representacions unificades d'informació amb diferents formats. The sources of the candidate snippets are also incorporated when measuring the question-snippet relevance.  A més, el marc està entrenat amb un paradigm a de supervisió fàcil dissenyat específicament fent servir les respostes disponibles en la fase d'entrenament. Els experiments d'un conjunt de dades del món real mostren que el nostre marc proposat aconsegueix un rendiment superior en comparació amb els models més avançats.", 'jv': 'Ngenyongno instant respons kanggo nganggo gampang barang nggawe layang pangan E-komersi politenessoffpolite"), and when there is a change ("assertivepoliteness Nang pepulan iki, kita mudhun akeh barêng-barêng kanggo nggawe PqA task nganggep nggawe informasi sing beraksi lan gambaran langa-barêng kotak sing katêpakan karo perangkat dhéwé informasi sing bakal dhéwé, nambah informasi alamat sak banjuré karo paket nggawe usul. Teng ProgressBars Nambah, akeh rampun dipunangé awak dhéwé nggawe aturan dipunangé perbudhakan langgar-langgar kuwi nggawe barang nggawe barang nggawe barang maning. Gebudhakan langkung barang dataset sing paling-barang nggambar kuwi dianggawe pancen dumadhi sing gawe barang nggawe barang dumadhi state-of-the-arts model kuwi.', 'sk': 'Zagotavljanje takojšnjega odgovora na vprašanja, povezana z izdelki, v platformah za odgovarjanje na vprašanja elektronskega trgovanja lahko zelo izboljša uporabnikove spletne nakupovalne izkušnje. Vendar obstoječe metode odgovarjanja na vprašanja izdelkov (PQA) upoštevajo le en vir informacij, kot so pregledi uporabnikov in/ali zahtevajo velike količine označenih podatkov. V tem prispevku predlagamo nov okvir za reševanje naloge PQA z izkoriščanjem heterogenih informacij, vključno z besedilom v naravnem jeziku in parom atributov-vrednosti iz dveh virov informacij zadevnega izdelka, in sicer podrobnosti o izdelkih in pregledih uporabnikov. heterogena komponenta kodiranja informacij je nato zasnovana za pridobivanje enotnih predstavitev informacij z različnimi formati. Viri kandidatnih delčkov so vključeni tudi pri merjenju ustreznosti delčkov vprašanja. Poleg tega je okvir usposobljen s posebej zasnovano šibko paradigmo nadzora, ki uporablja razpoložljive odgovore v fazi usposabljanja. Poskusi v resničnem svetu kažejo, da naš predlagani okvir dosega vrhunsko učinkovitost v primerjavi z najsodobnejšimi modeli.', 'he': 'ההזדמנות של תשובה מיידית לשאלות קשורות למוצרים במסחר אלקטרוני בתשובות לפלטפורמות עונות על הסחר אלקטרוני יכולה לשפר באופן גדול את חווית קניות באינטרנט של המשתמשים. עם זאת, שיטות התשובה לשאלות מוצרים קיימות (PQA) שוקלות רק מקור מידע אחד כמו ביקורות משתמשים ו/או דורשות כמויות גדולות של נתונים מסומנים. בעיתון הזה, אנו מציעים מסגרת חדשה להתמודד עם משימה PQA דרך ניצול מידע heterogeneous כולל טקסט שפה טבעית וזוגות ערך-תכונה משני מקורות מידע של המוצר המודאג, כלומר פרטים מוצר ובדיקות משתמשים. רכיב הקוד מידע היטרוגני מתוכנן לאחר מכן כדי להשיג מייצגים מאוחדים של מידע עם צורות שונות. The sources of the candidate snippets are also incorporated when measuring the question-snippet relevance.  חוץ מזה, המסגרת מאומנת עם פרדיגמה של פיקוח חלש שמתכננת במיוחד, שמשתמשת בתשובות זמינות בשלב האימון. ניסויים על קבוצת נתונים בעולם האמיתי מראים שהמסגרת המוצעת שלנו משיגה ביצועים עדיפים מעל מודלים חדשים.', 'ha': "Kuma ka bãyar da majibu masu hushi na masu tambaya da manunuwa masu husu da su cikin tambayi na-fatauci na-mainukiya, kan su ƙara wajen cinikin masu amfani da kwamfyuta. A lokacin da ake karɓa wa masu tambayi na halarce (PQA) hanyoyin bayani kawai, za'a bincike kima guda kamar misãlin tafarkin mai amfani da/kõ kuma yana buƙata girma tsarin da aka rubũta. Daga wannan takardan, Munã buɗa wani firam na nowaya dõmin su yi mataimaki ga aikin PQA, a yi amfani da amfani da data masu tsakanin littãfin da littãfin asili da kimar-nau'i biyu daga sourcen information na halarcen da ke husũma, duk daki-daki da misãlai na amfani. An design wani compound na kode information na seerogenous, sa'an nan an design a sami masu motsi da tsari masu haɗi da daban-daban. Tsarin snuffle na kandidan da aka shigar da shi a lokacin da aka ƙayyade masu da amfani da tambayar-snuffle. Ko da haka, an sanar da firam da wani paradigm wanda aka ƙayyade wa masu rauni na tsari, don ya yi amfani da masu buƙata cikin fasa na tattalin. Kayan jarrabo a kan danne-duniya masu gaske yana nuna cewa firam da ake buƙata masu ƙaranci da mazaƙin-masu-sanawa.", 'bo': 'E-commerce་ཡོད་པའི་གནས་ཚུལ་དང་འབྲེལ་བའི་གསལ་བཤད་ལ་མཚམས་ཁག However, existing product question answering (PQA) methods only consider a single information source such as user reviews and/or require large amounts of labeled data. འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་རྐྱེན་གྱི་ལས་འགུལ་གྱི་བཟོ་བརྗོད་ཅིག་སྤྲོད་བྱས་ནས་ PQA དུས་སྐྱེན་ཡིག དམིགས་འཛུགས་ཀྱི་ཆ་འཕྲིན་གསལ་གྲངས་སྒྲིག་ཆ་ཤས་ཞིག་ནི་དབྱིབས་མ་འདྲ་བ་དང་མཉམ་དུ་དབྱིབས ཞུགས་པ་ཚོའི་ནང་དུ་མཛོད་ཁང་གི་རྒྱུ་དངོས་ཀྱི་ནང་དོན་དག་གི་གནས་ཚུལ་འདྲི་ཞིབ་བཟོ་སྐབས་ཀྱང་incorporate་ཡོད། ད་དུང་། གཞུང་སྒྲིག་འདི་ལྟར་དམིགས་བསལ་བྱས་བའི་ལྟ་རྟོག་ཁང་ཅིག་གིས་མཐུན་སྣེ་ཚོགས་སྤྱོད་ཐུབ། དངོས་གནས་སྟངས་དང་འཛམ་གླིང་ཡོད་པའི་བརྡ་སྟོན་པར་གྱི་སྒེར་གྱི་ཕྱོགས་གཞུང་དུ་ང་ཚོའི་སྔོན་སྒྲིག་བཀོད་རིས་གཞན་པའི་མ'}
{'en': 'Multi-view Classification Model for Knowledge Graph Completion', 'ar': 'نموذج تصنيف متعدد العرض لإكمال الرسم البياني المعرفي', 'fr': "Modèle de classification multi-vues pour l'achèvement du Knowledge Graph", 'pt': 'Modelo de classificação de várias visualizações para conclusão do gráfico de conhecimento', 'es': 'Modelo de clasificación multivista para completar Knowledge Graph', 'zh': '所以知图谱成者多视图类也', 'ja': 'ナレッジグラフ補完のためのマルチビュー分類モデル', 'hi': 'बहु-दृश्य वर्गीकरण मॉडल ज्ञान ग्राफ़ पूर्णता के लिए', 'ru': 'Многовидовая классификационная модель для заполнения графа знаний', 'ga': 'Samhail Aicmithe Il-amharc chun Grafa Faisnéise a Chríochnú', 'ka': 'უცნობიერი გრაფიკის დასრულება', 'hu': 'Többnézetes osztályozási modell a tudásgraf kiegészítéséhez', 'el': 'Μοντέλο ταξινόμησης πολλαπλών προβολών για την ολοκλήρωση γραφήματος γνώσης', 'it': 'Modello di classificazione multi-view per il completamento del grafico di conoscenza', 'lt': 'Daugiavaizdinis žinių grafiko užbaigimo klasifikavimo modelis', 'mk': 'Multi-view Classification Model for Knowledge Graph Completion', 'ms': 'Model Klasifikasi Multi-view untuk Penyempurnaan Graf Pengetahuan', 'ml': 'അറിവ് ഗ്രാഫ് പൂര്\u200dത്തിയാക്കുന്നതിനുള്ള ഒരുപാട് ക്ലാസിഷന്\u200d മോഡല്\u200d', 'mt': 'Mudell ta’ Klassifikazzjoni Multiviżjoni għat-Tlestija tal-Grafika tal-Għarfien', 'mn': 'Мэдлэг график дуусгах олон харагдах классификацийн загвар', 'kk': 'Мәлім графикалық толтыру үшін көптеген көрініс классификациялау үлгісі', 'no': 'Klassifikasjonsmodell for fleire visingar for fullføring av kjenningsgrafen', 'pl': 'Wieloosobowy model klasyfikacji dla uzupełniania wykresu wiedzy', 'ro': 'Model de clasificare multi-vizualizare pentru completarea graficului de cunoștințe', 'si': 'Name', 'sr': 'Model klasifikacije višestrukog pogleda za kompletnost grafika znanja', 'sv': 'Klassificeringsmodell med flera vyer för färdigställande av kunskapsdiagram', 'ta': 'அறிவு வரைப்படம் முடிப்பதற்கான பல- காட்சி வகைப்படுத்தல் மாதிரி', 'ur': 'علم گراف کامل کے لئے بہت سی نظر کلاسیفی موڈل', 'so': 'Qoraalka fasaxa aqoonta ee muuqashada kala duduwan', 'uz': 'Maò¥lumot grafikni toò£ldirish uchun multi- koò£rinish usuli', 'vi': 'KCharselect unicode block name', 'bg': 'Модел за класификация на множество изгледи за завършване на графика на знанието', 'nl': 'Classificatiemodel met meerdere weergaven voor het voltooien van kennisgrafieken', 'da': 'Klassificeringsmodel med flere visninger til fuldførelse af vidensgrafer', 'hr': 'Model klasifikacije višestrukog pogleda za završavanje znanja grafika', 'de': 'Klassifizierungsmodell mit mehreren Ansichten für die Vervollständigung von Knowledge Graph', 'id': 'Model Klasifikasi Multi-view untuk Penyempurnaan Graf Pengetahuan', 'fa': 'مدل کلاس\u200cسازی چندین نمایش برای کامل گراف دانش', 'ko': '지식도 완성의 다시도 분류 모델', 'sw': 'Modeli ya Makala ya Kusini kwa Kutimiza Graph ya Ujuzi', 'tr': 'Bilnen Graph Tamamlandyrmasy üçin Ýagtylamak modi', 'af': 'Veelvuldige aansig Klassifikasie Model vir kennis graf voltooiing', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Գիտելու գրաֆիկի ավարտացման բազմատեսակ դասակարգման մոդել', 'az': 'Bilən Grafik Tamamlaması üçün çoxlu Görüş Klasifikasyon Modeli', 'sq': 'Modeli i klasifikimit Multi-View për kompletimin e grafikut të njohurisë', 'bn': 'জ্ঞান গ্রাফ সম্পূর্ণের জন্য বহুভিউ ক্লাসিকেশন মডেল', 'ca': 'Model de classificació multivista per a completar el gràfic del coneixement', 'bs': 'Model klasifikacije višestrukog pogleda za kompletanje znanja grafika', 'cs': 'Vícezobrazený klasifikační model pro dokončování znalostního grafu', 'et': 'Teadmisgraafiku täitmise mitmevaateline klassifitseerimismudel', 'fi': 'Moninäkymäinen luokitusmalli tietokaavion viimeistelyä varten', 'jv': 'iCalImp', 'sk': 'Model razvrščanja več pogledov za dokončanje grafikona znanja', 'ha': '@ action', 'bo': 'ཤེས་པའི་དཔེ་རིས་རྣམ་གྲངས་ཁ་བསྡུས་ཀྱི་སྣ་མང་བོའི་དབྱེ་རིགས', 'he': 'מודל קליфікаציה מרובה-ראייה לשימוש גרף ידע'}
{'en': 'Most previous work on knowledge graph completion conducted single-view prediction or calculation for candidate triple evaluation, based only on the content information of the candidate triples. This paper describes a novel multi-view classification model for knowledge graph completion, where multiple classification views are performed based on both content and context information for candidate triple evaluation. Each classification view evaluates the validity of a candidate triple from a specific viewpoint, based on the content information inside the candidate triple and the context information nearby the triple. These classification views are implemented by a unified neural network and the classification predictions are weightedly integrated to obtain the final evaluation. Experiments show that, the multi-view model brings very significant improvements over previous methods, and achieves the new state-of-the-art on two representative datasets. We believe that, the flexibility and the scalability of the multi-view classification model facilitates the introduction of additional information and resources for better performance.', 'fr': "La plupart des travaux précédents sur l'achèvement des graphes de connaissances ont mené une prédiction ou un calcul à vue unique pour l'évaluation triple du candidat, uniquement sur la base des informations de contenu des triplets candidats. Cet article décrit un nouveau modèle de classification multi-vues pour la complétion de graphes de connaissances, dans lequel plusieurs vues de classification sont effectuées à la fois sur la base du contenu et des informations contextuelles pour la triple évaluation des candidats. Chaque vue de classification évalue la validité d'un triple candidat d'un point de vue spécifique, sur la base des informations de contenu à l'intérieur du triple candidat et des informations contextuelles proches du triple. Ces vues de classification sont mises en œuvre par un réseau neuronal unifié et les prédictions de classification sont intégrées de manière pondérée pour obtenir l'évaluation finale. Les expériences montrent que le modèle multi-vues apporte des améliorations très significatives par rapport aux méthodes précédentes et atteint la nouvelle technologie sur deux ensembles de données représentatifs. Nous pensons que la flexibilité et l'évolutivité du modèle de classification multi-vues facilitent l'introduction d'informations et de ressources supplémentaires pour de meilleures performances.", 'ar': 'أجرى معظم العمل السابق على إكمال الرسم البياني المعرفي تنبؤًا أو حسابًا فرديًا للتقييم الثلاثي للمرشح ، بناءً على معلومات المحتوى لثلاث مرات المرشح فقط. تصف هذه الورقة نموذجًا جديدًا لتصنيف متعدد العروض لإكمال الرسم البياني المعرفي ، حيث يتم إجراء عروض تصنيف متعددة بناءً على معلومات المحتوى والسياق لتقييم المرشح الثلاثي. تقوم كل طريقة عرض تصنيف بتقييم صحة مرشح ثلاثي من وجهة نظر محددة ، بناءً على معلومات المحتوى داخل المرشح الثلاثي ومعلومات السياق القريبة من الثلاثي. يتم تنفيذ عروض التصنيف هذه من خلال شبكة عصبية موحدة ويتم دمج تنبؤات التصنيف بشكل مرجح للحصول على التقييم النهائي. تُظهر التجارب أن نموذج العرض المتعدد يجلب تحسينات كبيرة جدًا مقارنة بالطرق السابقة ، ويحقق أحدث ما توصل إليه العلم في مجموعتي بيانات تمثيلية. نعتقد أن المرونة وقابلية التوسع في نموذج التصنيف متعدد العروض يسهل إدخال معلومات وموارد إضافية لتحسين الأداء.', 'pt': 'A maioria dos trabalhos anteriores sobre preenchimento de gráfico de conhecimento conduziu previsão ou cálculo de visualização única para avaliação tripla candidata, com base apenas nas informações de conteúdo das triplas candidatas. Este artigo descreve um novo modelo de classificação de múltiplas visualizações para preenchimento de grafos de conhecimento, onde múltiplas visualizações de classificação são executadas com base em informações de conteúdo e contexto para avaliação tripla de candidatos. Cada visão de classificação avalia a validade de um triplo candidato de um ponto de vista específico, com base nas informações de conteúdo dentro do triplo candidato e nas informações de contexto próximas ao triplo. Essas visualizações de classificação são implementadas por uma rede neural unificada e as previsões de classificação são integradas de forma ponderada para obter a avaliação final. Experimentos mostram que o modelo multi-view traz melhorias muito significativas em relação aos métodos anteriores e atinge o novo estado da arte em dois conjuntos de dados representativos. Acreditamos que a flexibilidade e a escalabilidade do modelo de classificação multi-view facilitam a introdução de informações e recursos adicionais para um melhor desempenho.', 'es': 'La mayoría de los trabajos anteriores sobre la finalización de gráficos de conocimiento realizaron predicciones o cálculos de una sola vista para la evaluación triple de candidatos, basándose únicamente en la información de contenido de las triples candidatas. Este artículo describe un novedoso modelo de clasificación multivista para completar gráficos de conocimiento, en el que se realizan múltiples vistas de clasificación en función de la información de contenido y contexto para la triple evaluación del candidato. Cada vista de clasificación evalúa la validez de una triple candidata desde un punto de vista específico, en función de la información de contenido dentro de la triple candidata y la información de contexto cercana a la triple. Estas vistas de clasificación se implementan mediante una red neuronal unificada y las predicciones de clasificación se integran de manera ponderada para obtener la evaluación final. Los experimentos muestran que el modelo multivista aporta mejoras muy significativas con respecto a los métodos anteriores y logra el nuevo estado de la técnica en dos conjuntos de datos representativos. Creemos que la flexibilidad y la escalabilidad del modelo de clasificación multivista facilitan la introducción de información y recursos adicionales para un mejor rendimiento.', 'ja': 'ナレッジグラフの完了に関する以前の仕事のほとんどは、候補者三重評価のための単一ビュー予測または計算を、候補者三重評価のコンテンツ情報のみに基づいて実施した。 本論文では，知識グラフ完成のための新規のマルチビュー分類モデルについて述べた。このモデルでは，候補者の三重評価のためのコンテンツ情報と文脈情報の両方に基づいて複数の分類ビューが実行される。 各分類ビューは、候補トリプル内のコンテンツ情報及びトリプルの近くのコンテキスト情報に基づいて、特定の視点から候補トリプルの妥当性を評価する。 これらの分類図は、統一されたニューラルネットワークによって実装され、分類予測は、最終評価を得るために重み付けされて統合される。 実験によると、マルチビューモデルは、以前の方法よりも非常に大きな改善をもたらし、2つの代表的なデータセットで最新のものを実現します。 マルチビュー分類モデルの柔軟性とスケーラビリティは、より良いパフォーマンスのための追加情報とリソースの導入を容易にすると考えています。', 'zh': '前多知识图谱成事皆单视图算,唯在三元组。 本文引一以知识图谱成者新型多视图分模形,其基于义上下文信行数分视图,以候三重评估。 凡类视图皆以三元组内息与三元组左右上下文息,以特定视点料三元之有效性。 凡此诸类视图一之神经网络,以类占之加权集成之,以成其终。 实验明多视图模形显改于前法,并于两代表性数集上成其最先进之术。 吾信之,多视图类灵活性可扩展性助引入他信息、资源,以得其善。', 'hi': 'नॉलेज ग्राफ पूरा होने पर अधिकांश पिछले काम ने उम्मीदवार ट्रिपल मूल्यांकन के लिए एकल-दृश्य भविष्यवाणी या गणना आयोजित की, जो केवल उम्मीदवार ट्रिपल की सामग्री जानकारी के आधार पर थी। यह पेपर ज्ञान ग्राफ पूरा होने के लिए एक उपन्यास बहु-दृश्य वर्गीकरण मॉडल का वर्णन करता है, जहां उम्मीदवार ट्रिपल मूल्यांकन के लिए सामग्री और संदर्भ जानकारी दोनों के आधार पर कई वर्गीकरण दृश्य किए जाते हैं। प्रत्येक वर्गीकरण दृश्य एक विशिष्ट दृष्टिकोण से एक उम्मीदवार ट्रिपल की वैधता का मूल्यांकन करता है, जो उम्मीदवार ट्रिपल के अंदर की सामग्री जानकारी और ट्रिपल के पास की संदर्भ जानकारी के आधार पर होता है। इन वर्गीकरण विचारों को एक एकीकृत तंत्रिका नेटवर्क द्वारा लागू किया जाता है और अंतिम मूल्यांकन प्राप्त करने के लिए वर्गीकरण भविष्यवाणियों को भारित रूप से एकीकृत किया जाता है। प्रयोगों से पता चलता है कि, मल्टी-व्यू मॉडल पिछले तरीकों पर बहुत महत्वपूर्ण सुधार लाता है, और दो प्रतिनिधि डेटासेट पर नए अत्याधुनिक को प्राप्त करता है। हमारा मानना है कि, बहु-दृश्य वर्गीकरण मॉडल का लचीलापन और स्केलेबिलिटी बेहतर प्रदर्शन के लिए अतिरिक्त जानकारी और संसाधनों की शुरुआत की सुविधा प्रदान करता है।', 'ru': 'Большая часть предыдущей работы по заполнению графа знаний проводилась с однократным прогнозом или расчетом для тройной оценки кандидата, основанной только на информации о содержании тройки кандидата. В этой статье описывается новая модель многовидовой классификации для заполнения графа знаний, где выполняется несколько представлений классификации на основе как содержания, так и контекстной информации для тройной оценки кандидата. Каждый вид классификации оценивает достоверность тройного кандидата с определенной точки зрения на основе информации о содержимом внутри тройного кандидата и контекстной информации рядом с тройным. Эти классификационные представления реализуются унифицированной нейронной сетью, а классификационные прогнозы взвешенно интегрируются для получения окончательной оценки. Эксперименты показывают, что модель с несколькими представлениями приносит очень значительные улучшения по сравнению с предыдущими методами и достигает нового уровня на двух репрезентативных наборах данных. Мы считаем, что гибкость и масштабируемость многовидовой модели классификации облегчает введение дополнительной информации и ресурсов для повышения эффективности.', 'ga': 'Rinne an chuid is mó den obair a rinneadh roimhe seo ar chríochnú ghraif eolais tuar nó ríomh aon-amharc le haghaidh meastóireacht thriarach iarrthóra, bunaithe ar fhaisnéis faoi ábhar na dtrí iarrthóirí amháin. Déanann an páipéar seo cur síos ar shamhail aicmithe ilamhairc úrnua chun graif eolais a chomhlánú, ina ndéantar dearcthaí aicmithe iolracha bunaithe ar fhaisnéis faoi ábhar agus comhthéacs araon le haghaidh meastóireacht thriarach an iarrthóra. Déanann gach radharc rangaithe meastóireacht ar bhailíocht iarrthóra triarach ó thaobh sainiúil de, bunaithe ar an bhfaisnéis faoin ábhar taobh istigh den iarrthóir tríarach agus ar an bhfaisnéis faoin gcomhthéacs in aice leis an triúracht. Cuirtear na tuairimí aicmithe seo chun feidhme trí líonra néarúil aontaithe agus déantar na réamh-mheastacháin aicmithe a chomhtháthú go ualaithe chun an mheastóireacht deiridh a fháil. Léiríonn turgnaimh go dtugann an tsamhail il-amhairc feabhsuithe an-suntasach ar mhodhanna roimhe seo, agus go mbaineann sé amach an úrscothacht nua ar dhá thacar sonraí ionadaíocha. Creidimid, mar gheall ar sholúbthacht agus inscálaitheacht na samhla aicmithe il-amhairc, go n-éascaítear faisnéis bhreise agus acmhainní breise a thabhairt isteach ar mhaithe le feidhmíocht níos fearr.', 'hu': 'A legtöbb korábbi tudásdiagram elkészítésével kapcsolatos munka egynézetes előrejelzést vagy számítást végzett a jelölt hármas értékeléséhez, kizárólag a jelölt háromszoros tartalmi információi alapján. Ez a tanulmány egy új, többnézetes osztályozási modellt ír le a tudásdiagram kiegészítéséhez, ahol több osztályozási nézetet végeznek mind a tartalom, mind a kontextus információk alapján a jelölt hármas értékeléshez. Minden osztályozási nézet egy hármas jelölt érvényességét egy adott nézőpontból értékeli, a hármas jelölt tartalmi információi és a hármas közelében lévő kontextus információk alapján. Ezeket az osztályozási nézeteket egy egységes neurális hálózat hajtja végre, és az osztályozási előrejelzéseket súlyosan integrálják a végső értékelés eléréséhez. A kísérletek azt mutatják, hogy a multi-view modell nagyon jelentős fejlesztéseket hoz a korábbi módszerekhez képest, és két reprezentatív adatkészleten éri el az új korszerűséget. Hisszük, hogy a többnézetes osztályozási modell rugalmassága és skálázhatósága megkönnyíti a jobb teljesítmény érdekében további információk és erőforrások bevezetését.', 'el': 'Οι περισσότερες προηγούμενες εργασίες για την ολοκλήρωση γραφήματος γνώσης διεξήγαγαν πρόβλεψη ή υπολογισμό μίας προβολής για την τριπλή αξιολόγηση υποψηφίων, με βάση μόνο τις πληροφορίες περιεχομένου των τριπλής υποψηφίων. Η παρούσα εργασία περιγράφει ένα νέο μοντέλο ταξινόμησης πολλαπλών προβολών για την ολοκλήρωση γραφήματος γνώσης, όπου πραγματοποιούνται πολλαπλές προβολές ταξινόμησης με βάση τόσο το περιεχόμενο όσο και τις πληροφορίες περιβάλλοντος για την τριπλή αξιολόγηση υποψηφίων. Κάθε προβολή ταξινόμησης αξιολογεί την εγκυρότητα ενός υποψηφίου τριπλού από μια συγκεκριμένη άποψη, με βάση τις πληροφορίες περιεχομένου μέσα στο υποψήφιο τριπλό και τις πληροφορίες περιβάλλοντος κοντά στο τριπλό. Αυτές οι απόψεις ταξινόμησης υλοποιούνται από ένα ενοποιημένο νευρωνικό δίκτυο και οι προβλέψεις ταξινόμησης ενσωματώνονται σημαντικά για να επιτευχθεί η τελική αξιολόγηση. Τα πειράματα δείχνουν ότι το μοντέλο πολλαπλών προβολών φέρνει πολύ σημαντικές βελτιώσεις σε σχέση με τις προηγούμενες μεθόδους και επιτυγχάνει τη νέα κατάσταση της τεχνολογίας σε δύο αντιπροσωπευτικά σύνολα δεδομένων. Πιστεύουμε ότι η ευελιξία και η επεκτασιμότητα του μοντέλου ταξινόμησης πολλαπλών προβολών διευκολύνει την εισαγωγή πρόσθετων πληροφοριών και πόρων για καλύτερη απόδοση.', 'ka': 'უფრო მეტი უცნობიერი გრაფიკის დასრულებაზე გავაკეთებული ერთხედვის წარმოდგენა ან გამოწვება კანდიდენტის სამჯერ წარმოდგენისთვის, მხოლოდ კანდიდენტის სამჯერ ამ დოკუფიკაციის აღწერა პრომენტი მრავალური ხედის კლასიფიკაციის მოდელი, რომელსაც კონდიდენტის სამჯერ განსაზღვრებისთვის მრავალური კლასიფიკაციის ხედი გამოყენებულია. ყოველ კლასიფიკაციის ხედვის განსაზღვრებულია კანდიდატის სამჯერ მნიშვნელობა განსაზღვრებული ხედვით, რომელიც სამჯერ კანდიდატის სამჯერ ინფორმაციის შესახებ და სამჯერ მზად ამ კლასიფიკაციის ხედვის ერთადერთი ნეიროლური ქსელის გამოყენება და კლასიფიკაციის წარმოდგენები უფრო მნიშვნელოვანია, რომ მივიღოთ ბოლო წარმოდგენება. ექსპერიმენტები გამოჩვენება, რომ მრავალური ხელსახულების მოდელი ძალიან მნიშვნელოვანი გაუქმედება წინ მეტოვებზე და ახალი ხელსახულების სახელსახულების შესაძლებლობა ორი რესპ ჩვენ ვფიქრობთ, რომ მრავალური კლასიფიკაციის მოდელის гиტქიბულობა და სკალაბულობა უფრო მეტი ინფორმაციის და რესურსის გადაყენება.', 'it': "La maggior parte dei lavori precedenti sul completamento del grafico della conoscenza ha condotto una previsione o calcolo a vista singola per la valutazione tripla del candidato, basata solo sulle informazioni di contenuto del candidato triplicato. Questo articolo descrive un nuovo modello di classificazione multi-view per il completamento del grafico della conoscenza, in cui vengono eseguite più visualizzazioni di classificazione basate sia sul contenuto che sulle informazioni di contesto per la valutazione tripla del candidato. Ogni vista di classificazione valuta la validità di un candidato triplo da un punto di vista specifico, in base alle informazioni contenute nel candidato triplo e alle informazioni di contesto vicine al triplo. Queste viste di classificazione sono implementate da una rete neurale unificata e le previsioni di classificazione sono pesantemente integrate per ottenere la valutazione finale. Gli esperimenti dimostrano che il modello multi-view apporta miglioramenti molto significativi rispetto ai metodi precedenti e raggiunge il nuovo stato dell'arte su due set di dati rappresentativi. Crediamo che la flessibilità e la scalabilità del modello di classificazione multi-view faciliti l'introduzione di informazioni e risorse aggiuntive per migliorare le prestazioni.", 'lt': 'Dauguma ankstesnių žinių grafiko užbaigimo darbų atliko trijų kandidatų vertinimo vieno požiūrio prognozę arba skaičiavimą remiantis tik trijų kandidatų turinio informacija. Šiame dokumente aprašomas naujas daugialypis klasifikavimo modelis, skirtas žinių grafikai užbaigti, kuriame daugialypis klasifikavimo požiūris atliekamas remiantis tiek turinio, tiek konteksto informacija, skirta trigubam kandidato vertinimui. Kiekvienoje klasifikavimo apžvalgoje vertinamas trigubo kandidato galiojimas konkrečiu požiūriu, remiantis trigubo kandidato turinio informacija ir artima trigubo kandidato turinio informacija. Šios klasifikacijos išvados įgyvendinamos vieningo nervų tinklo, o klasifikacijos prognozės yra svertingai integruotos galutiniam vertinimui gauti. Eksperimentai rodo, kad daugialypis modelis labai pagerina ankstesnius metodus ir pasiekia naują pažangą dviejuose tipiniuose duomenų rinkiniuose. Manome, kad daugialypio klasifikavimo modelio lankstumas ir mastingumas palengvina papildomos informacijos ir išteklių įdiegimą siekiant geresnių rezultatų.', 'kk': 'Алдыңғы білім графикасының толтыруының көпшілігі кандидаттың үш рет оқиғаларының мазмұның мәліметіне негізделген бір көрініс не есептеу үшін бір- бір көрініс алдында Бұл қағаз білім графикалық толтыру үшін көптеген көрініс шектеу үлгісін түсіндіреді. Бірнеше шектеу көрінісі кандидаттардың үш рет оқу үшін мазмұны мен контексті мәліметіне негіздел Әрбір классификациялық көрініс кандидаттың үш рет қарау нүктесінен, кандидаттың үш рет мәліметінің негізінде және үш жағындағы контексті мәліметінің дұрыстығын бағалады. Бұл классификациялық көріністер біріктірілген невралдық желінен іске асырылады, және классификациялық бағалау үшін соңғы оқиғаны алу үшін тең түрлі біріктірілген. Тәжірибелер бірнеше көрініс үлгісі алдыңғы әдістерде өте маңызды жақсартылып, екі негізгі деректер жиынында жаңа орындау күйін жеткізеді. Біз біздің сенеміз, көп көріністі классификациялау үлгісінің гибкілігі мен масштабы қосымша мәлімет мен ресурстарды жақсы істеу үшін енгізуге көмектеседі.', 'ms': 'Kebanyakan pekerjaan terdahulu pada pelengkapan graf pengetahuan dilakukan ramalan-pandangan tunggal atau pengiraan untuk penilaian trek calon, berdasarkan hanya maklumat kandungan calon tiga calon. Kertas ini menggambarkan model kelasukan berbilang-paparan baru untuk pelengkapan graf pengetahuan, di mana paparan kelasukan berbilang dilakukan berdasarkan kedua-dua kandungan dan maklumat konteks untuk penilaian trek calon. Setiap paparan klasifikasi menilai kehendak calon tiga kali dari titik pandangan khusus, berdasarkan maklumat kandungan dalam calon tiga kali dan maklumat konteks dekat tiga kali. Paparan klasifikasi ini dilaksanakan oleh rangkaian saraf bersatu dan ramalan klasifikasi secara berat disertakan untuk mendapatkan penilaian akhir. Experiments show that, the multi-view model brings very significant improvements over previous methods, and achieves the new state-of-the-art on two representative datasets.  Kami percaya bahawa fleksibiliti dan skalabiliti model klasifikasi pemandangan berbilang memudahkan perkenalan maklumat tambahan dan sumber untuk prestasi yang lebih baik.', 'mk': 'Повеќето претходни работи на завршувањето на графикот на знаење спроведоа еднопогледна предвидување или пресметка за кандидатската тројна оценка, базирана само на информациите за содржината на кандидатите тројни. Овој документ опишува нов модел на мултипоглед за класификација за завршување на графикот на знаење, каде што се изведуваат многуте погледи за класификација врз основа на содржината и контекстните информации за кандидатската три-проценка Секој класификациски поглед ја оценува валидноста на кандидатот трипати од специфична точка на поглед, врз основа на информациите за содржината во кандидатот трипати и контекстните информации во близина на трипати. Овие разгледувања за класификација се имплементирани од унифицирана нервна мрежа и предвидувањата за класификација се тешко интегрирани за да се добие конечна оценка. Експериментите покажуваат дека мултипогледниот модел носи многу значителни подобрувања во однос на претходните методи и постигнува нова најнова технологија на двата претставнички податоци. Веруваме дека флексибилноста и скалабилноста на моделот за класификација со мултипоглед го олеснуваат воведувањето на дополнителни информации и ресурси за подобра перформанса.', 'ml': 'വിജ്ഞാനത്തിന്റെ ഗ്രാഫ് പൂര്\u200dത്തിയുടെ മുമ്പുള്ള ജോലിയില്\u200d ഏറ്റവും മുമ്പുള്ള ജോലി പ്രാര്\u200dത്ഥിതിയുടെ വിവരങ്ങള്\u200d മൂന്നിരട്ടി  പരിജ്ഞാനത്തിന്റെ ഗ്രാഫ് പൂര്\u200dത്തിയ്ക്കുള്ള ഒരു നോവല്\u200d പല-കാഴ്ചയുടെ ക്ലാസ്ഫിക്ഷന്\u200d മോഡല്\u200d വിശദീകരിക്കുന്നു. പ്രാര്\u200dത്ഥിതിയുടെ മ പ്രത്യേക ക കാഴ്ചയില്\u200d നിന്നും പ്രാര്\u200dത്ഥിക്കുന്ന വിവരങ്ങള്\u200d അടിസ്ഥാനമായി വിവരങ്ങളിലുള്ള വിവരങ്ങളിലുള്ള വിവരങ്ങള്\u200dക്കും മൂന്നിലുള്ള ഈ ക്ലാസിഫിക്ഷന്\u200d കാഴ്ചകള്\u200d ഒരു യൂണിക്കൂട്ടിയ നെയൂറല്\u200d നെറുല്\u200d നെറ്റര്\u200d നെറ്റ്\u200cവര്\u200dക്ക് പ്രവര്\u200dത്തിപ്പിക്കുന്നു. അവസാന വ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു, മുമ്പുള്ള രീതികളില്\u200d വളരെ ഗുരുതരമായ മെച്ചപ്പെടുത്തുന്നു. രണ്ടു പ്രതിനിധികളുടെ ഡാ നമ്മള്\u200d വിശ്വസിക്കുന്നു, പല്ലിക്കാഴ്ചയുടെ ക്ലാസ്ഫിക്ഷന്\u200d മോഡലിന്റെ സ്വാഭാവികതയും കൂടുതല്\u200d വിവരങ്ങളും വിഭവങ്ങളും കൂടുതല്\u200d', 'mt': 'Il-biċċa l-kbira tax-xogħol preċedenti dwar it-tlestija tal-grafika tal-għarfien wettaq tbassir jew kalkolu b’vista waħda għall-evalwazzjoni tripla tal-kandidat, ibbażat biss fuq l-informazzjoni tal-kontenut tat-tripli tal-kandidat. Dan id-dokument jiddeskrivi mudell ġdid ta’ klassifikazzjoni b’diversi viżijiet għat-tlestija tal-grafika tal-għarfien, fejn jitwettqu fehmiet multipli ta’ klassifikazzjoni bbażati kemm fuq il-kontenut kif ukoll fuq l-informazzjoni tal-kuntest għall-evalwazzjoni tripla tal-kandidati. Kull opinjoni ta’ klassifikazzjoni tevalwa l-validità ta’ kandidat triplu minn perspettiva speċifika, ibbażata fuq l-informazzjoni tal-kontenut ġewwa l-kandidat triplu u l-informazzjoni tal-kuntest qrib it-triplu. Dawn il-fehmiet tal-klassifikazzjoni huma implimentati minn netwerk newrali unifikat u t-tbassir tal-klassifikazzjoni huwa integrat b’mod peżat biex tinkiseb l-evalwazzjoni finali. L-esperimenti juru li, il-mudell multiviżjoni jġib titjib sinifikanti ħafna fuq il-metodi preċedenti, u jikseb l-aktar avvanzat ġdid fuq żewġ settijiet ta’ dejta rappreżentattivi. Aħna nemmnu li l-flessibbiltà u l-iskalabbiltà tal-mudell ta’ klassifikazzjoni b’diversi viżijiet jiffaċilitaw l-introduzzjoni ta’ informazzjoni u riżorsi addizzjonali għal prestazzjoni aħjar.', 'no': 'Dei fleste førre arbeida på kunnskapsgrafen fullføringa gjer foregåve eller kalkulasjon av enkelvisningar for tredje evaluering av kandidatene, basert berre på innhaldsinformasjonen om kandidate-tredjeler. Denne papiret beskriver ein novel fleirvisingsklassifikasjonsmodul for kunnskapsgrafen fullføring, der fleire klassifikasjonsvisingar vert utført basert på både innhald og kontekstinformasjon for kandidattribelevaluering. Kvar klassifikasjonsvisinga evaluerer dersom ein kandidat er trådløg frå eit spesifikke visingspunkt, basert på innhaldsinformasjonen i kandidaten trådløg og kontekstinformasjonen nær den tredjedelen. Disse klassifikasjonsvisingane er implementert av eit einaste neuralnettverk, og klassifikasjonsverdiane er vektig integrerte for å få den siste evalueringa. Eksperiment viser at multivisingsmodellen gjer veldig signifikante forbedringar over tidlegare metoder, og oppnår den nye kunsttilstanden på to reprezentative datasett. Vi tror at fleksibilitet og skalabiliteten av multivisningskolassifikasjonsmodulen gjer tilgjengeleg innføring av ekstra informasjon og ressursar for betre utviklingar.', 'mn': 'Ихэнх мэдлэг график дуусахын тулд хамгийн өмнөх ажиллагаа нь одоогийн үзэл төлөвлөгөө эсвэл хэмжээний гурван дуусахын тулд нэг үзэл төлөвлөгөө эсвэл тооцоолол хийсэн. Зөвхөн хэ Энэ цаас мэдлэг график дуусахын тулд олон үзэгдлийн хуваалтын загварыг тайлбарладаг. Энэ цаас нь хэдэн хуваалтын үзэгдлийг дамжуулан дамжуулан гурван дүгнэлт хийгддэг. Бүх ангилалын үзэл бүр тодорхой үзэл цэгээс гурав дахин дахин захирагчдын үнэ цэнэтэй байдлыг үнэлдэг. Харин одоогоор гурав дахин дахин хамгийн ойрхон мэдээлэл болон хамгийн ойрхон мэдээлэл Эдгээр ангилалын үзэл нь нэгтгэл мэдрэлийн сүлжээгээр дамжуулагдсан бөгөөд ангилалын таамаглал нь төгсгөл дүгнэлт гаргахын тулд хэмжээтэй нэгтгэгддэг. Олон үзэл загвар нь өмнөх арга загвараар маш чухал сайжруулах боломжтой болж, хоёр төлөөлөгч өгөгдлийн санд шинэ урлагийн байр суурь гаргах боломжтой байна. Бид үүнийг итгэдэг. Олон-тооны ангилалын загварын урсгалын бөгөөд хэмжээний хэмжээний масштаб нь нэмэлт мэдээлэл болон нөөц хөрөнгө хөгжүүлэхэд илүү сайн ажиллагаанд ор', 'pl': 'Większość poprzednich prac nad uzupełnianiem wykresu wiedzy przeprowadziła prognozę jednoosobową lub obliczenia dla potrójnej oceny kandydata, oparte wyłącznie na informacjach treściowych potrójnych kandydatów. Niniejszy artykuł opisuje nowy model klasyfikacji wielu widoków dla uzupełniania wykresów wiedzy, w którym wykonywane są wiele widoków klasyfikacji w oparciu o informacje treściowe i kontekstowe do potrójnej oceny kandydata. Każdy widok klasyfikacji ocenia ważność potrójnego kandydata z określonego punktu widzenia, na podstawie informacji o treści wewnątrz potrójnego kandydata i informacji kontekstowych w pobliżu potrójnego. Te widoki klasyfikacji są implementowane przez ujednoliconą sieć neuronową, a prognozy klasyfikacji są ważnie zintegrowane w celu uzyskania ostatecznej oceny. Eksperymenty pokazują, że model multi-view przynosi bardzo znaczące ulepszenia w stosunku do poprzednich metod i osiąga nowy state-of-the-art na dwóch reprezentatywnych zbiorach danych. Uważamy, że elastyczność i skalowalność modelu klasyfikacji wielu widoków ułatwia wprowadzanie dodatkowych informacji i zasobów dla lepszej wydajności.', 'ro': 'Cele mai multe lucrări anterioare privind finalizarea graficului cunoștințelor au efectuat predicții unice sau calcule pentru evaluarea triplă a candidatului, bazate doar pe informațiile conținutului candidatului triplează. Această lucrare descrie un nou model de clasificare multi-view pentru completarea graficului cunoștințelor, în care vizualizările multiple de clasificare sunt efectuate atât pe baza conținutului, cât și a informațiilor contextuale pentru evaluarea triplă a candidatului. Fiecare vizualizare de clasificare evaluează validitatea unui candidat triplu dintr-un punct de vedere specific, pe baza informațiilor conținutului din interiorul candidatului triplu și a informațiilor contextuale din apropierea triplului. Aceste vizualizări de clasificare sunt implementate de o rețea neurală unificată, iar predicțiile de clasificare sunt integrate în mod ponderal pentru a obține evaluarea finală. Experimentele arată că modelul multi-view aduce îmbunătățiri foarte semnificative față de metodele anterioare și atinge noul state-of-the-art pe două seturi de date reprezentative. Considerăm că flexibilitatea și scalabilitatea modelului de clasificare multi-view facilitează introducerea de informații și resurse suplimentare pentru o performanță mai bună.', 'si': 'ගොඩක් මුලින් දැනගන්න ග්\u200dරාෆ් සම්පූර්ණය සඳහා දැනගන්න පුළුවන් විදියට එක-ප්\u200dරකාශ විශ්වාස කරලා තියෙන තුනක්  මේ පත්තුව සම්පූර්ණය සඳහා දැනගන්න ග්\u200dරාෆ් සම්පූර්ණය සඳහා විවෘත විවෘත විවෘත විවෘත විවෘත කරනවා, කාන්ඩියාට තුන හැම විශේෂණ දර්ශනයක් විශේෂ දර්ශනයෙන් ප්\u200dරතිශේෂිත තුනක් තුනක් විශේෂ ප්\u200dරතිශ්ණයෙන් ප්\u200dරතිශේෂ තුනක් වලි මේ විශේෂණ ප්\u200dරකාරයක් අන්තිම විශ්ලේෂණයක් අන්තිම විශ්ලේෂණය ලබාගන්න අන්තිම විශ්ලේෂණය සඳහා සංවිධා පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට, විශේෂ ප්\u200dරවෘති මදුල් ප්\u200dරවෘත්තිය ප්\u200dරවෘත්තිය ගැන ගොඩක් විශේෂ විශ අපි විශ්වාස කරනවා කියලා, විශිෂ්ට විශේෂය සහ විශිෂ්ට පරීක්ෂණ ප්\u200dරමාණයේ අතර තොරතුරු සහ උපකරණ සඳහා හො', 'so': 'Shaqo badan oo ku saabsan dhamaanka fasaxa aqoonta waxay sameeyeen wax la sii sheego oo keliya ama xisaab u sameeyay qiimeyn saddex jeer ah oo ay ku saleysan macluumaadka ku qoran labada jeer ee kandida. Warqaddan waxaa ku qoran tusaale ahaan fasax kala duduwan oo loo sameynayo fasaxa aqoonta, kaas oo lagu sameeyaa aragtida fasaxa kala duduwan oo lagu sameynayo ku saleysan qoraalka kooxaha iyo macluumaadka kooxeedka ee qiimeynta kandidada ah saddex jeer. Muuqashada fasax walba waxaa qiimeynaya suurtagalka suurtagalka ah saddex jeer, iyadoo ku saleysan macluumaadka ku jira kandida saddex jeer iyo macluumaadka kooxaha ah ee ku dhow saddex jeer. Muuqashadan fasaxa waxaa lagu sameeyaa shabakadda neurada ee la xiriiray, oo waxaa si miisaan ah loo qabsadaa qiimeynta ugu dambeeya. Imtixaanka waxaa muuqda in tusaalaha aragtida badan uu keeno beddelmo aad u weyn oo ka sii kordhaya qaababka hore, wuxuuna gaadhaa xaaladda cusub ee farshaxanka labada kooban ee macluumaadka wakiilka. Waxaynu aaminsanahay in dhaqdhaqaalaha iyo caqliga sameynta qaababka kala duduwan waxay u sahlisaa in la soo saaro macluumaad dheeraad ah iyo resources si ay u samayso.', 'sv': 'De flesta tidigare arbeten med färdigställande av kunskapsgrafer genomförde en-vy förutsägelse eller beräkning för kandidatens trippelutvärdering, baserat endast på innehållsinformationen för kandidaten trippelar. Denna uppsats beskriver en ny multi-view klassificeringsmodell för färdigställande av kunskapsgrafer, där flera klassificeringsvyer utförs baserat på både innehåll och kontextinformation för kandidatens trippelutvärdering. Varje klassificeringsvy utvärderar validiteten av en kandidattrippel ur en specifik synvinkel, baserat på innehållsinformationen inuti kandidattrippel och sammanhangsinformationen i närheten av trippel. Dessa klassificeringsvyer implementeras av ett enhetligt neuralt nätverk och klassificeringsprognoserna är viktigt integrerade för att få den slutliga utvärderingen. Experiment visar att multi-view modellen ger mycket betydande förbättringar jämfört med tidigare metoder, och uppnår den nya state-of-the-art på två representativa datauppsättningar. Vi anser att flexibiliteten och skalbarheten hos multiview-klassificeringsmodellen underlättar införandet av ytterligare information och resurser för bättre prestanda.', 'sr': 'Većina prethodnog rada o završetku znanja grafika provedena je predviđanja jednostavnog pogleda ili izračuna za trostruku procjenu kandidata, zasnovana samo na sadržajnoj informaciji kandidatskih trostruka. Ovaj papir opisuje novi model klasifikacije višestrukog pogleda za završavanje grafika znanja, gdje se izvršavaju višestruki klasifikacijski pogled na temelju obje sadržaja i kontekstske informacije za trostruku procjenu kandidata. Svaki pogled klasifikacije procjenjuje validnost kandidata trostruko iz određenog pogleda, na osnovu informacija o sadržaju unutar trostrukog kandidata i kontekstske informacije u blizini trostrukog pogleda. Ove klasifikacije provede ujedinjena neuralna mreža i predviđanja klasifikacije su teško integrisane kako bi dobili konačnu procjenu. Eksperimenti pokazuju da, multivizualni model donosi veoma značajne poboljšanje u prethodnim metodama i postiže novo stanje umjetnosti na dva reprezentativna dataseta. Vjerujemo da fleksibilnost i skalabilnost multivizualnog modela klasifikacije olakšava uvođenje dodatnih informacija i resursa za bolju provedbu.', 'ur': 'زیادہ پہلے علم گراف کامل کے بارے میں ایک دیدہ کی پیش بینی یا شمارش کے لئے کڈینڈیٹ تین ارزش کے لئے کیا گیا تھا، صرف کڈینڈیٹ تین تین کے منزل معلومات پر بنیاد ہے. This paper describes a new multi view classification model for knowledge graph completion, where multiple classification views are performed based on both content and context information for candidate triple evaluation. Each classification view evaluates the validity of a candidate triple from a specific viewpoint, based on the content information within the candidate triple and the context information near the triple. یہ کلاسیفوں نظر ایک متحدہ نیورل نیٹورک کے ذریعے عملہ کی جاتی ہیں اور کلاسیفوں کی پیش بینی بالکل تول کے ساتھ پورا تفریق کی جاتی ہیں۔ آزمائش دکھاتے ہیں کہ ملتی-بیوی موڈل پہلے طریقے پر بہت اچھے سوداگری لاتا ہے اور دو نمایشن ڈیٹ سٹ پر نئی ایٹیٹ-ایٹ کو پہنچاتا ہے. ہم اس بات پر یقین رکھتے ہیں کہ بہت زیادہ معلومات اور سرمایہ کے مطابق بہترین عمل کے لئے اضافہ کی معلومات اور سرمایہ کا مطابق اور مطابق مطابق ہے.', 'ta': 'முந்தைய அறிவு வரைப்படம் முடிவில் பெரும்பாலான வேலை முந்தைய வார்த்தையாளர் மூன்று மதிப்பிற்கு மட்டும் தனிப்பட்ட காட்சி முடிவ இந்த தாள் அறிவு வரைபடத்தை முடிப்பதற்கான புதிய பல காட்சி வகைப்படுத்தல் மாதிரி விவரிக்கிறது, அங்கு தேர்ந்தெடுக்கும் மூன்று முறை மதிப்பிற ஒவ்வொரு வகுப்புக் காட்சி இந்த வகுப்பாட்டு காட்சிகள் ஒரு ஒன்றிணைக்கப்பட்ட புதிய பிணையத்தினால் செயல்படுத்தப்படுகிறது மற்றும் வகுப்பு முன்னோட்டங்கள் ம முயற்சிகள் பல காட்சி மாதிரி முந்தைய முறைமைகளை மிகவும் முக்கியமான முன்னேற்றங்களை கொண்டு வருகிறது, மற்றும் இரண்டு பிரதிநிதித்த நாங்கள் நம்புகிறோம், பல பார்வை வகைப்படுத்தல் மாதிரியின் தேவையான தகவல் மற்றும் வளங்களை சிறந்த செயல்பாட்டிற்கு முன்னேற்றும', 'uz': "Bu ko'pchilik ilmiy grafik toʻldirish uchun bir necha koʻrinishi yoki uchta qidirish uchun hisoblanadi, faqat nafaqat turli maʼlumotga asoslangan. Bu hujjatda ilmiy grafik toʻldirish uchun bir necha darajalashtirish modeli koʻrinadi. Bu yerda esa bir necha darajalashtirish koʻrinishini bajariladi. @ info Ushbu klassifning koʻrinishini birlashtirilgan neural tarmoqning orqali ishga tushiriladi va darajalashtirish oldini qo'yish uchun oxirigi qiymatga qoʻyiladi. Tajribalar ko'rsatadi, ko'plab-koʻrish modeli oldingi usullarda juda muhim yaxshi o'zgarishni olib keladi, va ikkita representing maʼlumotlar sohasida yangi holatni bajaradi. Biz shunday ishonamizki, ko'pchilik darajalashtirish modelining cheksizligi va ko'pchilik darajasi modelini bajarish uchun qoʻshimcha maʼlumot va rasmlarni ishlashga yordam beradi.", 'vi': 'Phần lớn công việc trước về việc hoàn thành đồ thị kiến thức đã thực hiện dự đoán hay tính toán cho ứng viên đánh giá ba lần, chỉ dựa trên nội dung của nhóm ứng viên. Tờ giấy này mô tả một mô hình phân hạng đa cảnh mới cho việc hoàn thành đồ thị tri thức, nơi có nhiều quan điểm phân loại được thực hiện dựa trên cả nội dung và ngữ cảnh cho ứng viên đánh giá ba mặt. Mỗi ô xem phân loại ước lượng giá trị của một ứng viên ba người theo một quan điểm cụ thể, dựa trên nội dung của ứng viên ba người và các thông tin ngữ cảnh xung quanh ba người. Những quan điểm phân loại này được thực hiện bởi một mạng thần kinh thống nhất và dự đoán phân loại được tổng hợp trọng lực để đạt được kết quả đánh giá cuối cùng. Thí nghiệm cho thấy, mô hình đa dạng mang đến những cải tiến rất quan trọng so với các phương pháp trước đây, và đạt được trạng thái mới trên hai bộ dữ liệu đại diện. Chúng tôi tin rằng sự linh hoạt và khả năng leo thang của mô hình phân hạng đa phương sẽ giúp tạo ra thêm thông tin và nguồn lực để đạt hiệu suất tốt hơn.', 'bg': 'Повечето предишни работи по завършване на графиката на знанието са извършвали прогнозиране или изчисление за тройна оценка на кандидатите, базирани само на съдържанието на информацията на кандидатите за тройна оценка. Настоящата статия описва нов модел за класификация с множество изгледи за завършване на графика на знанието, при който се извършват множество класификационни изгледи въз основа на съдържанието и контекстната информация за тройна оценка на кандидатите. Всеки класификационен изглед оценява валидността на кандидат тройна от конкретна гледна точка, въз основа на съдържанието на информацията вътре в кандидат тройна и контекстната информация близо до тройната. Тези класификационни възгледи се реализират чрез единна невронна мрежа и класификационните прогнози са сериозно интегрирани, за да се получи окончателната оценка. Експериментите показват, че многообразният модел носи много значителни подобрения в сравнение с предишните методи и постига ново състояние на изкуството върху два представителни набора от данни. Вярваме, че гъвкавостта и мащабируемостта на модела за класификация с множество изгледи улесняват въвеждането на допълнителна информация и ресурси за по-добра производителност.', 'hr': 'Većina prethodnog rada o završetku grafika znanja provedena je prognoza jednostavnog pogleda ili izračuna za trostruku procjenu kandidata, temeljena samo na sadržajnoj informaciji o trostrukim kandidatima. Ovaj papir opisuje nov model klasifikacije višepogleda za završavanje grafika znanja, gdje se izvršavaju višestruki pogled klasifikacije na temelju obje informacija sadržaja i konteksta za trostruku procjenu kandidata. Svaki pogled klasifikacije procjenjuje vrijednost kandidata trostruko iz određenog pogleda na temelju informacija o sadržaju unutar trostrukog kandidata i kontekstske informacije u blizini trostrukog pogleda. Te klasifikacijske poglede provede ujedinjena nervna mreža i predviđanja klasifikacije su teško integrirane kako bi dobili konačnu procjenu. Eksperimenti pokazuju da, multivizualni model donosi veoma značajne poboljšanje nad prethodnim metodama i postiže novo stanje umjetnosti na dva predstavnika podataka. Vjerujemo da fleksibilnost i skalabilnost multivizualnog modela klasifikacije olakšava uvođenje dodatnih informacija i resursa za bolju učinku.', 'nl': 'De meeste eerdere werken aan kennisgrafiekvoltooiing voerden single-view voorspelling of berekening uit voor kandidaat triple evaluatie, alleen gebaseerd op de inhoudsinformatie van de kandidaat triples. Dit artikel beschrijft een nieuw multi-view classificatiemodel voor kennisgrafiekvoltooiing, waarbij meerdere classificatieweergaven worden uitgevoerd op basis van zowel inhoud als context informatie voor kandidaat drievoudige evaluatie. Elke classificatieweergave evalueert de geldigheid van een kandidaat triple vanuit een specifiek gezichtspunt, op basis van de inhoudsinformatie in de kandidaat triple en de contextinformatie in de buurt van de triple. Deze classificatieweergaven worden geïmplementeerd door een verenigd neuraal netwerk en de classificatievoorspellingen zijn gewichtig geïntegreerd om de uiteindelijke evaluatie te verkrijgen. Experimenten tonen aan dat het multi-view model zeer belangrijke verbeteringen brengt ten opzichte van eerdere methoden, en de nieuwe state-of-the-art bereikt op twee representatieve datasets. Wij geloven dat de flexibiliteit en schaalbaarheid van het multi-view classificatiemodel de invoering van aanvullende informatie en middelen voor betere prestaties vergemakkelijkt.', 'da': 'De fleste tidligere arbejder med vidensgraffærdiggørelse gennemførte single-view forudsigelse eller beregning for kandidatens tredobbelte evaluering, udelukkende baseret på indholdsoplysningerne for kandidaten tredobbelte. Denne artikel beskriver en ny multi-view klassifikationsmodel til færdiggørelse af vidensgrafer, hvor flere klassifikationsvisninger udføres baseret på både indholds- og kontekstinformation til kandidatens tredobbelte evaluering. Hver klassifikationsvisning evaluerer gyldigheden af en kandidattredobbelt ud fra et bestemt synspunkt, baseret på indholdsoplysningerne inde i kandidattredobbeltet og kontekstinformationerne i nærheden af tredobbeltet. Disse klassifikationsvisninger implementeres af et samlet neuralt netværk, og klassifikationsforudsigelserne integreres vægtigt for at opnå den endelige evaluering. Eksperimenter viser, at multi-view modellen bringer meget betydelige forbedringer i forhold til tidligere metoder, og opnår den nye state-of-the-art på to repræsentative datasæt. Vi mener, at fleksibiliteten og skalerbarheden af multi-view klassifikationsmodellen letter introduktionen af yderligere information og ressourcer for bedre ydeevne.', 'de': 'Die meisten früheren Arbeiten zur Vervollständigung von Wissensgraphen führten Single-View Vorhersage oder Berechnung für die Kandidat Triple Evaluation durch, basierend nur auf den Inhaltsinformationen der Kandidat Triple. In dieser Arbeit wird ein neuartiges Multi-View-Klassifizierungsmodell zur Vervollständigung von Wissensgraphen beschrieben, bei dem mehrere Klassifizierungsansichten auf der Grundlage von Inhalt- und Kontextinformationen für die dreifache Bewertung von Kandidaten durchgeführt werden. Jede Klassifikationsansicht bewertet die Gültigkeit eines Kandidaten-Tripels aus einer bestimmten Perspektive, basierend auf den Inhaltsinformationen innerhalb des Kandidaten-Tripels und den Kontextinformationen in der Nähe des Tripels. Diese Klassifikationsansichten werden von einem einheitlichen neuronalen Netzwerk implementiert und die Klassifikationsvorsagen gewichtig integriert, um die endgültige Auswertung zu erhalten. Experimente zeigen, dass das Multi-View-Modell gegenüber bisherigen Methoden sehr signifikante Verbesserungen bringt und den neuen Stand der Technik auf zwei repräsentativen Datensätzen erreicht. Wir glauben, dass die Flexibilität und Skalierbarkeit des Multi-View-Klassifikationsmodells die Einführung zusätzlicher Informationen und Ressourcen für eine bessere Leistung erleichtert.', 'id': 'Kebanyakan pekerjaan sebelumnya dalam menyelesaikan grafik pengetahuan dilakukan prediksi pandangan tunggal atau kalkulasi untuk evaluasi kandidat tiga kali, berdasarkan hanya informasi isi kandidat tiga kali. Kertas ini menggambarkan model klasifikasi multipandangan baru untuk menyelesaikan grafik pengetahuan, di mana pandangan klasifikasi berbilang dilakukan berdasarkan isi dan informasi konteks untuk evaluasi kandidat tiga kali. Setiap tampilan klasifikasi mengevaluasi validitas kandidat tiga kali dari sudut pandang spesifik, berdasarkan informasi isi dalam kandidat tiga kali dan informasi konteks dekat tiga kali. Pandangan klasifikasi ini dieksploitasi oleh jaringan saraf bersatu dan prediksi klasifikasi secara berat terintegrasi untuk mendapatkan evaluasi akhir. Eksperimen menunjukkan bahwa, model multi-view membawa peningkatan yang sangat signifikan atas metode sebelumnya, dan mencapai state-of-the-art baru pada dua set data yang mewakili. Kami percaya bahwa fleksibilitas dan skalabilitas model klasifikasi multipandangan memudahkan penemuan informasi tambahan dan sumber daya untuk prestasi yang lebih baik.', 'fa': 'بیشتر کارهای قبلی در مورد تموم کردن گراف دانش پیش بینی یک دید یا محاسبات برای ارزیابی سه کاندیدا انجام داده است، فقط بر اساس اطلاعات محتوای سه کاندیدا. این کاغذ یک مدل جدیدی از طریق جدیدی برای تموم کردن گراف دانش را توصیف می\u200cکند، جایی که دیدگان جدیدی از طریق جدیدی بر اساس اطلاعات محتویات و محتویات برای ارزیابی سه کاندیده انجام می\u200cشوند. هر دیدۀ مختصات ارزیابی قابلیت یک کاندیده سه برابر از یک نقطه نظر خاص، بر اساس اطلاعات محتوای درون سه برابر کاندیده و اطلاعات محتوای نزدیک سه برابر است. این دیدگاه\u200cهای مختصات توسط شبکه عصبی متحد و پیش\u200cبینی\u200cهای مختصات برای رسیدن ارزیابی نهایی با وزن متصل می\u200cشوند. تجربه\u200cها نشان می\u200cدهند که مدل بین\u200cالمثالی بهترین\u200cهای بسیار بزرگی بر روش\u200cهای قبلی می\u200cآورد و وضعیت\u200cهنری جدید را در دو مجموعه داده\u200cهای نماینده می\u200cرساند. ما باور می\u200cکنیم که flexibility and scalability of the multi view classification model facilitates the introduction of additional information and resources for better performance.', 'ko': '이전에 지식도 보완에 관한 대부분의 작업은 후보 3원조의 내용 정보만 바탕으로 후보 3원조에 대해 단시도 예측이나 계산을 실시했다.본고는 새로운 지식도에서 완성된 다시도 분류 모델을 묘사하는데 그 중에서 내용과 상하문 정보를 바탕으로 여러 가지 분류시도를 집행하여 후보 삼중 평가를 실시한다.각 분류 보기는 후보 삼원조 내부의 내용 정보와 삼원조 부근의 상하문 정보에 따라 특정한 각도에서 후보 삼원조의 유효성을 평가한다.이러한 분류 보기는 하나의 통일된 신경 네트워크로 실현되고 분류 예측을 가중 집적하여 최종 평가를 얻는다.실험에 의하면 다시도 모델은 이전의 방법보다 매우 현저하게 개선되었고 두 개의 대표적인 데이터 집합에서 최신 수준을 실현했다.우리는 다시도 분류 모델의 유연성과 신축성이 추가 정보와 자원을 도입하여 더욱 좋은 성능을 얻는 데 도움이 될 것이라고 믿는다.', 'sw': 'Kazi nyingi zilizopita juu ya kumaliza picha za maarifa ilifanya utabiri au hisabu moja kwa moja kwa ajili ya uchunguzi wa tatu wa mgombea, kwa kutumia taarifa za maudhui ya tatu za wagombea. Gazeti hili linaelezea mtindo wa usambazaji wa riwaya mbalimbali kwa ajili ya kuumiza maarifa ya ufahamu, ambapo maoni kadhaa ya usambazaji yanafanyika kwa msingi wa maudhui na taarifa za muktadha kwa ajili ya uchunguzi wa mara tatu wa wagombea. Kila mtazamo wa kutangaza ukweli wa mgombea mara tatu kutoka kwenye mtazamo maalum, kwa kutumia taarifa za maudhui ndani ya mgombea mara tatu na taarifa za muktadha karibu na watatu. Maoni haya ya kutangaza yanatekelezwa na mtandao wa neura uliojojaa na utabiri wa usambazaji unaunganishwa sana ili kupata tathmini ya mwisho. Majaribio yanaonyesha kuwa, mtindo wa mitazamo mbalimbali unaleta maboresho makubwa zaidi ya njia zilizopita, na kupata hali mpya ya sanaa kwenye seti za wawili za wakilishi. Tunaamini kwamba, ujasiri na uvunjaji wa muundo wa usambazaji wa mitindo mbalimbali unasaidia kutengeneza taarifa na rasilimali kwa ajili ya utendaji bora.', 'tr': 'Bilim grafiklerinden öňki işi, kandidyň üç sany maglumatynda adatça maglumatyň maglumatynda daýarylýar. Bu kagyz bilgi grafik tamamlamak üçin bir çoklu görnöşim klasifikasy nusgasyny tassyklaýar, nirede birnäçe klasifikasyon görnöşimi we kontekst maglumaty kandidyň üçin üç netijesi üçin bellenilýär. Her ýygnam görnöşimi adatýanyň üç sany takyk görnöşinden daýanýar, kandidýanyň üç sany maglumatynyň içine daýanýar we üç sany ýanyň golaýyndaky kontekst maglumatynyň deňleýär. Bu klasifikasyon görnüşleri birleşik bir näral şebekege tarapyndan implementedilir we klasifikasyon öňünden soňky çykyşlygy bolmak üçin ýokary bellenilýär. Experimentalar, köp görnüş nusgasy öňki yönlerde örän möhüm gelişmeleri getirip bilýär we iki reprezentan veri setirinde täze möhüm gelişmeleri ýetip bilýär. Biziň pikirimçe, multi-görnüş klasifikasy nusgasynyň fleksibilitçesi we derejesi gowy etmäge kömekleýär.', 'af': "Mees vorige werk op kennis graaf voltooiing gedoen enkel- aansig voorskou of berekening vir kandidate tripel evaluering, gebaseer slegs op die inhoud inligting van die kandidate tripel. Hierdie papier beskrywe 'n roman multi- view klasifikasie model vir kennis graaf voltooiing, waar veelvuldige klasifikasie aansigte word uitgevoer gebaseer op beide inhoud en konteks inligting vir kandidate tripel evaluering. Elke klasifikasie besigtig evalueer die geldigheid van 'n kandidate tripel van' n spesifieke aansigpunt, gebaseer op die inhoud inligting binne die kandidate tripel en die konteksinligting naby die tripel. Hierdie klasifikasie aansigte word geïmplementeer deur 'n eenvoudige neuralnetwerk en die klasifikasie voorskou is gewigtig integreer om die eindelike evaluasie te kry. Eksperimente wys dat, die multi-besigtig model bring baie betaling verbeteringe oor vorige metodes en bereik die nuwe staat van die kuns op twee reprezentante datastelle. Ons glo dat, die fleksibiliteit en die skalabiliteit van die multi-sig klasifikasie model die inligting van addisionele inligting en hulpbronne vir beter prestasie is.", 'sq': 'Shumica e punës së mëparshme mbi përfundimin e grafikut të njohurive kryen parashikime apo llogaritje me një pamje të vetme për vlerësimin e trefishtë të kandidatit, bazuar vetëm në informacionin e përmbajtjes së trefishtë të kandidatit. Ky dokument përshkruan një model të ri klasifikimi me shumë pamje për kompletimin e grafikut të njohurive, ku pamjet e klasifikimit të shumëfishtë kryehen bazuar si në përmbajtjen ashtu edhe në informacionin e kontekstit për vlerësimin e trefishtë të kandidatit. Çdo pamje klasifikimi vlerëson vlerësimin e një kandidati të trefishtë nga një pikëpamje specifike, bazuar në informacionin e përmbajtjes brenda kandidatit të trefishtë dhe informacionin e kontekstit pranë trefishit. Këto pikëpamje klasifikuese zbatohen nga një rrjet i unifikuar nervor dhe parashikimet e klasifikimit janë të integruar me peshë për të marrë vlerësimin përfundimtar. Eksperimentet tregojnë se modeli me shumë pamje sjell përmirësime shumë të rëndësishme ndaj metodave të mëparshme dhe arrin gjendjen e re të aktuale në dy grupe të dhënash përfaqësuese. Ne besojmë se fleksibiliteti dhe shkallëzimi i modelit të klasifikimit me shumë pamje lehtëson futjen e informacionit dhe burimeve shtesë për performancë më të mirë.', 'am': 'የቀድሞው የእውቀት ቀለም ማድረግ ላይ የሚደረገውን አብዛኛዎቹ የአካባቢው የሦስት ድምፅ ማሰናየት ወይም ቁጥጥር ማድረግ ነው፡፡ ይህ ፕሮግራም የብዙ ተመልካች የክፍተት ዓይነት ለእውቀት ቀለም መፈጸም የሚያሳውቀው ነው፡፡ የአካባቢው መልዕክት በሦስት ሦስት ጊዜ እና የግንኙነት መረጃ በአቅራቢያ ላይ የሚኖረው የግንኙነት መረጃ በማስተካከል የአካባቢው የሦስት ዓይነት የአካባቢው ግንኙነትን ያስተካክላል፡፡ እነዚህ የክፍለ ግንኙነት አየር መረብ ይደረጋሉ፡፡ ፈተናዎች፣ የብዙ ዓይነቶች ሞዴል የቀድሞው ሥርዓት ላይ እጅግ የበለጠ ትክክል ማድረግ እና በሁለቱ ተሟጋቾች ላይ አዲስ የ-የ-የ-የ-የ-art ሥርዓት እንዲደርስ ያሳያል፡፡ እናምናለን፣ ብዙዎችን ዓይነቶች በተለያዩ ሞዴል የጥሩ መረጃዎችንና ሀብትን ለመስጠት ማግኘት ማግኘት ይችላል፡፡', 'hy': 'Most previous work on knowledge graph completion conducted single-view prediction or calculation for candidate triple evaluation, based only on the content information of the candidate triples.  Այս թղթին նկարագրում է գիտելիքի գրաֆիկի ավարտացման նոր բազմատեսակ դասակարգման մոդելը, որտեղ բազմաթիվ դասակարգման տեսանկյուններ են կատարվում, հիմնված և տեղեկատվության պարունակության, և կոնտեքստի վրա,  Յուրաքանչյուր դասակարգման տեսանկյունից գնահատվում է թեկնածու երեք անգամ հատուկ տեսանկյունից, հիմնված թեկնածու երեք անգամ ներսում տեղեկատվության պարունակության վրա և երեք անգամ մոտ կոնտեքստի տեղեկատվության վրա: Այս դասակարգման տեսանկյունները իրականացվում են միավորված նյարդային ցանցի կողմից, և դասակարգման կանխատեսումները կարևորաբար ինտեգրված են վերջնական գնահատման համար: Փորձարկումները ցույց են տալիս, որ բազմատեսակ մոդելը շատ կարևոր բարելավումներ է բերում նախորդ մեթոդների նկատմամբ և հասնում է նոր տեխնոլոգիաներին երկու ներկայացուցիչ տվյալների համակարգերի վրա: Մենք հավատում ենք, որ բազմատեսակ դասակարգման մոդելի ճկունությունը և ընդլայնելիությունը հնարավորություն են տալիս ավելին տեղեկատվություն և ռեսուրսներ ներկայացնել ավելի լավ արդյունավետության համար:', 'az': 'Bilim grafı tamamlama haqqında çox əvvəlki işlər, kandidəyə üç dəfə müəyyən edilən üç dəfə məlumatının məlumatlarına dayanan tək görünüş və ya hesablama təşkil edilmişdir. Bu kağıt elm grafı tamamlama üçün yeni çoxlu görünüş klasifikasyonu modelini təsdiqləyir, bu da çoxlu klasifikasyon görünümləri həmçinin sadiqi və kontekst məlumatlarının üç dəfə təsdiqlənməsi üçün təsdiqlənir. Hər dəyişiklik görünüşü müəyyən bir görünüş nöqtəsindən üç dəfə kandidəyin və üç dəfə yaxınlarındakı kontekst məlumatına dayanılır. Bu klasifikasiya görüntüləri birləşdirilmiş bir nöral a ğ tərəfindən istifadə edilir və klasifikasiya tədbirləri son değerlendirmək üçün ağırlıqla birləşdirilmişdir. Həqiqətən, çoxlu görünüş modeli əvvəlki metodların üstündə çox möhkəm düzəltmələri göstərir və iki temsilci verilən qutularda yeni sanatın durumunu başa çatdırır. Biz inanırıq ki, çoxlu görünüş klasifikasyonu modelinin fleksibiliyyəti və ölçülüyü daha yaxşı performans üçün çoxlu məlumat və resursların girişməsini olaraq olar.', 'bs': 'Većina prethodnog rada o završetku znanja grafika provedena je predviđanja jednostavnog pogleda ili izračuna za trostruku procjenu kandidata, temeljena samo na sadržajnoj informaciji o trostrukim kandidatima. Ovaj papir opisuje novi model klasifikacije višepogleda za završavanje grafika znanja, gdje se izvršavaju višestruki pogled klasifikacije na temelju informacija o sadržaju i kontekstu za trostruku procjenu kandidata. Svaki pogled klasifikacije procjenjuje validnost kandidata trostruko iz određenog pogleda, na temelju informacija o sadržaju unutar trostrukog kandidata i kontekstske informacije u blizini trostrukog pogleda. Ove klasifikacijske poglede provede ujedinjena neuralna mreža i predviđanja klasifikacije su teško integrirane kako bi dobili konačnu procjenu. Eksperimenti pokazuju da, multivizualni model donosi veoma značajne poboljšanje u prethodnim metodama i postiže novo stanje umjetnosti na dva reprezentativna dataseta. Vjerujemo da fleksibilnost i skalabilnost multivizualnog modela klasifikacije olakšava uvođenje dodatnih informacija i resursa za bolju provedbu.', 'bn': 'জ্ঞান গ্রাফ সম্পূর্ণ বেশীরভাগ কাজ শুরু করেছে প্রার্থীর ত্রিবারের তথ্য ভিত্তিক ভিত্তিক ভিত্তিতে প্রার্থীর বিষয়বস্তুর উপরে এক এই পত্রিকা জ্ঞান গ্রাফ সম্পূর্ণ করার জন্য একটি মাল্টিভিউ ক্লাসেফ মডেল বর্ণনা করেছে, যেখানে প্রার্থীর ত্রিবার মূল্যের জন্য বেশ কিছু বিভি প্রার্থীর ভিতরের বিষয়বস্তুর তথ্য ভিত্তিতে এবং প্রার্থী ত্রিবিন্দুর প্রার্থীর তথ্যের ভিত্তিতে প্রত্যেক বিভিন্ন তথ্যের বৈধ এই গ্রাফিকেশনের দৃষ্টিভঙ্গি একটি একত্রিত নিউরেল নেটওয়ার্ক দ্বারা বাস্তবায়ন করা হয়েছে এবং শেষ পর্যায়ের মূল্য পাওয়ার জন্যে ক্লা পরীক্ষাগুলো দেখাচ্ছে যে মাল্টিভিউ মডেল পূর্ববর্তী পদ্ধতিতে অনেক গুরুত্বপূর্ণ উন্নতি প্রদান করেছে এবং দুই প্রতিনিধিদের ডাটা আমরা বিশ্বাস করি যে, মাল্টিভিউ ক্লাসাফিকেশন মডেলের স্বাভাবিকতা এবং সুবিধা প্রদর্শনের জন্য আরো ভালো তথ্য ও সম্পদ প্রকাশ করার সুযোগ', 'cs': 'Většina předchozích prací na dokončování znalostního grafu prováděla jednoznačnou predikci nebo výpočet pro trojnásobné hodnocení kandidáta, založený pouze na obsahových informacích kandidáta trojice. Tento článek popisuje nový vícepohledový klasifikační model pro dokončení znalostního grafu, kde jsou prováděny více klasifikačních pohledů na základě obsahových i kontextových informací pro trojnásobné hodnocení kandidáta. Každé klasifikační zobrazení hodnotí platnost kandidátské trojice z konkrétního pohledu na základě obsahových informací uvnitř kandidátské trojice a kontextových informací blízkých trojice. Tyto klasifikační pohledy jsou implementovány sjednocenou neuronovou sítí a klasifikační predikce jsou integrovány pro získání konečného vyhodnocení. Experimenty ukazují, že multi-view model přináší velmi významné zlepšení oproti předchozím metodám a dosahuje nového stavu techniky na dvou reprezentativních datových sadách. Věříme, že flexibilita a škálovatelnost klasifikačního modelu více pohledů usnadňuje zavádění dalších informací a zdrojů pro lepší výkon.', 'et': 'Enamik varasemaid teadmisgraafikute lõpetamise tööd viis läbi kandidaatide kolmekordse hindamise ühevaatelise prognoosi või arvutuse, mis põhines ainult kandidaatide kolmekordse sisuteabe põhjal. Käesolevas töös kirjeldatakse uut mitmevaatelist klassifitseerimismudelit teadmiste graafiku täitmiseks, kus tehakse mitu klassifitseerimisvaatet kandidaatide kolmekordse hindamise sisu- ja kontekstiteabe põhjal. Iga klassifikatsioonivaade hindab kandidaadi kolmekordse kehtivust konkreetsest vaatenurgast, tuginedes kandidaadi kolmekordse sisu infole ja konteksti infole selle lähedal. Need klassifitseerimisvaated rakendatakse ühtse närvivõrgu kaudu ja klassifitseerimisprognoosid integreeritakse kaalukalt lõpphinnangu saamiseks. Eksperimentid näitavad, et mitmevaade mudel toob varasemate meetoditega võrreldes väga olulisi parandusi ja saavutab uue tehnika taseme kahe representatiivse andmekogumi puhul. Usume, et mitmevaatelise klassifitseerimismudeli paindlikkus ja skaleeritavus hõlbustab täiendava teabe ja ressursside kasutuselevõttu parema jõudluse saavutamiseks.', 'fi': 'Suurin osa aiemmista tietograafien täydennystöistä suoritti yhden näkymän ennusteita tai laskelmia ehdokkaan kolminkertaista arviointia varten, joka perustui vain ehdokkaan kolminkertaisten sisältötietoihin. Tässä artikkelissa kuvataan uutta monikulmaista luokitusmallia tietokaavion täydentämiseksi, jossa tehdään useita luokitusnäkymiä sekä sisällön että kontekstitietojen perusteella ehdokkaiden kolminkertaista arviointia varten. Kukin luokittelunäkymä arvioi ehdokkaan kolminkertaisen pätevyyden tietystä näkökulmasta perustuen ehdokkaan kolminkertaisen sisällötietoon ja kolminkertaisen lähellä olevaan kontekstitietoon. Nämä luokittelunäkymät toteutetaan yhtenäisellä hermoverkolla ja luokitusennusteet integroidaan painovoimaisesti lopullisen arvioinnin saamiseksi. Kokeet osoittavat, että moninäkymämalli tuo erittäin merkittäviä parannuksia aikaisempiin menetelmiin verrattuna ja saavuttaa uuden huipputason kahdessa edustavassa aineistossa. Uskomme, että moninäkymäluokituksen joustavuus ja skaalautuvuus helpottavat lisätietojen ja resurssien käyttöönottoa suorituskyvyn parantamiseksi.', 'ca': "La majoria dels treballs anteriors sobre la completació del gràfic del coneixement van fer predicció o càlcul d'una sola vista per a la tripla evaluació del candidat, basant-se només en la informació del contingut dels triples candidats. Aquest paper descriu un nou model de classificació multivista per a la completació del gràfic del coneixement, on es fan vistes de classificació múltiples basades tant en contingut com en informació contextual per a la tripla evaluació de candidats. Cada vista de classificació valora la validez d'un candidat triple d'un punt de vista específic, basat en la informació del contingut dins el candidat triple i la informació del context prop del triple. Aquestes vistes de classificació són implementades per una xarxa neural unificada i les prediccions de classificació són integrades pesadament per obtenir l'evaluació final. Experiments show that, the multi-view model brings very significant improvements over previous methods, and achieves the new state-of-the-art on two representative datasets.  Creiem que la flexibilitat i l'escalabilitat del model de classificació multivista faciliten l'introducció de informació i recursos adicionals per a millor rendiment.", 'jv': 'Laptop" and "Desktop Gambar iki rambarang nggawe modèl nyelarang multi-view kawit karo mulai perusahaan anyar tentang Yuta Kelkanan Sentrus menehi menehi winih sing ngewehke nguasai tambah alat sing berarti alat karo klasik punika ingkang dipunaaken kanggo ndelok ujaran Name Awak dhéwé ngpisan karo, langgar-langgar lan esuk-langgar kuwi model multi-view kudu nyebutaké awak dhéwé karo kesempatan kanggo awak dhéwé kanggo awak dhéwé.', 'he': 'רוב העבודה הקודמת על סיום גרף הידע ביצעה צפייה אחת או חישוב עבור הערכה השלישית של המועמדים, מבוססת רק על מידע התוכן של המועמדים השלישיים. המסמך הזה מתאר מודל מסווג חדש במספר תצפים עבור השלמת גרף ידע, שבו צופים מסווגים מרובים מבוססים גם על תוכן וגם על מידע הקשר עבור הערכה משולשת המועמדים. כל נוף מסווג מעריך את האישיות של מועמד משולש מנקודה מסוימת, מבוסס על מידע התוכן בתוך המועמד השולש והמידע הקשר ליד השולש. הנקודות הסווגות האלה מופעלות על ידי רשת עצבית מאוחדת והצפיות הסווגות מושלמות במשקל כדי להשיג את הערכה הסופית. ניסויים מראים שהמודל המולט-הנוף מביא שיפורים משמעותיים מאוד על שיטות קודמות, ומשיג את המצב החדש של המידע על שני קבוצות נתונים מייצגים. אנו מאמינים ש, הגמישות והאפשרות של מודל ההקלטה המולטל-הנוף מקדים את הכניסה של מידע ומשאבים נוספים עבור ביצועים טובים יותר.', 'sk': 'Večina prejšnjih del na področju zaključevanja grafov znanja je izvedla napoved ali izračun za trojno ocenjevanje kandidatov na podlagi vsebinskih informacij kandidatov trojnic. V prispevku je opisan nov model klasifikacije z več pogledi za dokončanje grafov znanja, kjer se izvajajo več pogledov klasifikacije na podlagi vsebinskih in kontekstnih informacij za trojno ocenjevanje kandidatov. Vsak pogled klasifikacije ocenjuje veljavnost kandidata trojnega z določenega stališča, na podlagi vsebinskih informacij znotraj kandidata trojnega in kontekstnih informacij v bližini trojnega. Te klasifikacijske poglede izvaja enotno nevronsko omrežje, napovedi klasifikacije pa so težko integrirane za pridobitev končne ocene. Poskusi kažejo, da model z več pogledi prinaša zelo pomembne izboljšave v primerjavi s prejšnjimi metodami in dosega novo stanje tehnike na dveh reprezentativnih naborih podatkov. Verjamemo, da fleksibilnost in razširljivost modela razvrstitve več pogledov olajšata uvajanje dodatnih informacij in virov za boljšo učinkovitost.', 'ha': "Babu mafi yawan aikin da ya gabata a kan cikakken graphi na ilmi ya yi wani basĩri ko kuma ya yi ƙidãya wa rabo sau biyu, amma, a kan tsarin maɓallin tsarin wanda ya canza ɗin ɗabi'a. Wannan takardan na faɗa ɗa wani misãlin sigarin masu motsi da multi-vieni wa cikakken fassaran ilmi, a inda za'a samar da viewnai masu yawa, a kan bincike masu tsari da tsarin maɓallin mazaɓa wa muhalli biyu. Kowace kallon mai fasa yana ƙayyade inganci na wata sau uku daga wani pointi na ƙayyade, a kan sali da maɓallin tsari guda na kanarin uku uku da maɓallin mazaɓa a ƙarƙashin uku. Wannan zanen sigarin za'a yi amfani da shi na jerin neural na da kuma an haɗa bayanin kayan sigarin da nau'i mai nau'i dõmin ya sami ƙarshen ƙaddara. Tajararin na nuna, misalin multi-vieni na zo da mafiya girma kan hanyõyin da suka gabata, kuma yana sami halin-sanaren a kan danna biyu. Tuna yi ĩmãni, fleksibinci da mala'ani na misalin misalin misalin misalin mulki yana da amfani da introduta addi information da resource wa mafarin aiki.", 'bo': 'གྲངས་སྐོར་གྱི་རྣམ་གྲངས་མཇུག་བསྡུ་རུང་བའི་ཆེས་མཐའ་དུ་རྐྱེན་སྐྱེས་ལ། ཤོག དབྱེ་སྟངས་ཀློག་སྟངས་རེ་རེད་སྐྱེས དབྱེ་སྟངས་ལྟ་ཀློག་འདི་ཚོ་ནི་དབྱིབས་མཐུན་གྱི་དྲ་རྒྱ་ཞིག་གིས་སྒྲིག་ཡོད་པ་དང་དབྱེ་སྟངས Experiments show that, the multi-view model brings very significant improvements over the previous methods, and achieves the new state-of-the-art on two representative datasets. ང་ཚོས་བསམ་ན་ཆུང་བ་དང་སྣ་མང་གྲངས་ཀྱི་དབྱེ་རིམ་གྱི་ཚད་རིམ་མཐུན་རྐྱེན་ཚད་ཀྱིས་མཐུན་གྱི་གསལ་བཤད་དང་རྒྱུ་ཆས་མང་ཙམ་'}
{'en': 'ExpanRL : Hierarchical Reinforcement Learning for Course Concept Expansion in MOOCs E xpan RL : Hierarchical Reinforcement Learning for Course Concept Expansion in  MOOC s', 'ar': 'ExpanRL: التعلم التعزيزي الهرمي لتوسيع مفهوم الدورة التدريبية في MOOCs', 'es': 'ExpanRL: Aprendizaje por refuerzo jerárquico para la expansión del concepto de curso en MOOC', 'fr': "ExpanRL\xa0: apprentissage par renforcement hiérarchique pour l'extension du concept de cours dans les MOOC", 'pt': 'ExpanRL: Aprendizado por Reforço Hierárquico para Expansão do Conceito do Curso em MOOCs', 'zh': 'ExpanRLć›°:MOOCäą‹ĺ¤§ç•Ąäąź', 'hi': 'ExpanRL: MOOCs में पाठ्यक्रम अवधारणा विस्तार के लिए पदानुक्रमित सुदृढीकरण सीखना', 'ru': 'ExpanRL: Обучение иерархическому подкреплению для расширения концепции курса в MOOC', 'ja': 'ExpanRL ： MOOCにおけるコース構想拡大のための階層強化学習', 'ga': 'ExpanRL: Foghlaim Treisithe Ordlathach le haghaidh Fairsingiú Coincheapa Cúrsa i MOOCanna', 'ka': 'QRegExp', 'el': 'Η Ιεραρχική Μάθηση Ενίσχυσης για την Επέκταση της έννοιας του μαθήματος στα ΜΟΟΚ', 'hu': 'ExpanRL: Hierarchikus megerősítési tanulás a tanfolyamkoncepció bővítéséhez MOOC-okban', 'it': "ExpanRL: apprendimento di rinforzo gerarchico per l'espansione del concetto di corso nei MOOC", 'lt': 'ExpanRL: Hierarchical Reinforcement Learning for Course Concept Expansion in MOOCs', 'kk': 'ЭкспанRL: Хирархикалық теңдеу оқытуы MOOCs', 'mk': 'RL: Иерархиско зајакнување на учењето за проширување на концептот на курсот во MOOCs', 'ms': 'RL: Hierarchical Reinforcement Learning for Course Concept Expansion in MOOCs', 'mt': 'ExpanRL: Tagħlim ta’ tisħiħ ġerarkiku għal Tkabbir tal-Kunċett tal-Kurs f’MOOCs', 'mn': 'ЭкспанRL: МООК-д дасгал ойлголтын төлөө суралцах', 'ml': 'എക്സ്പാന്\u200dഎല്\u200d: മൊഒക്സിലുള്ള കോഴ്സ് കോണ്\u200dസെപ്റ്റ് എക്സ്പെന്\u200dഷന്\u200d പഠിപ്പിക്കുന്നതിനുള്ള ഹൈറരാക്കിക്', 'pl': 'ExpanRL: Hierarchiczne uczenie się wzmacniające dla rozszerzenia koncepcji kursu w MOOCs', 'ro': 'ExpanRL: Învățare de consolidare ierarhică pentru extinderea conceptului de curs în MOOC', 'sr': 'EksplanRL: Hierarchical strengthening Learning for Course Concept Expansion in MOOCs', 'no': 'RL: Hierarchical reinforcement Learning for Course Concept Expansion in MOOCsRL: Hierarchical Reinforcement Learning for Course Concept Expansion in MOOCs', 'si': 'RL: හියර්චිකාල් විශාලනයක් ඉගෙනගන්න පුළුවන්RL: හියර්චිකාල් විශාලනය MOOCs', 'sv': 'ExpanRL: Hierarkisk förstärkning lärande för kurskonceptexpansion i MOOC', 'so': 'ExpanRL: Hierarchical Reinforcement Learning for Course Concept Expansion in MOOCs', 'ta': 'எக்ஸ்பான்ஆர்: விளையாட்டு வெளியேற்றத்திற்கான விரிவாக்கம்', 'ur': 'RL', 'uz': 'Name', 'vi': 'KCharselect unicode block name', 'bg': 'Обучение по йерархично укрепване за разширяване на концепцията на курса в МООК', 'da': 'ExpanRL: Hierarkisk forstærkning af læring til kursuskonceptudvidelse i MOOCs', 'hr': 'RL: Hierarchical strengthening Learning for Course Concept Expansion in MOOCs', 'nl': 'ExpanRL: Hiërarchisch Versterkingsleren voor Cursusconceptuitbreiding in MOOCs', 'de': 'ExpanRL: Hierarchisches Verstärkungslernen zur Kurskonzepterweiterung in MOOCs', 'id': 'RL: Perkuatan Hierarkis Belajar untuk Perluasan Koncept Kurs dalam MOOC', 'ko': 'ExpanRL: MOOC 코스 개념 확장을 위한 계층형 강화 학습', 'fa': 'RL: یادگیری برای تغییر تغییر توجه در MOOCs', 'sw': 'ExpanRL: Kufundisha Mapinduzi ya Udhibiti wa Kujifunza Mapinduzi ya Mapinduzi katika MOOOCs', 'tr': 'RL: Hierarchical Reinforcement Learning for Course Concept Expansion in MOOCs', 'af': 'Please take the official translations! You find them here: http: // europa. eu. int/ eur- lex/ lex/ LexUriServ/ LexUriServ. do? uri=CELEX: 32001L0059: EN: HTML', 'sq': 'RL: Mësimi i forcimit hierarkik për zgjerimin e konceptit të kursit në MOOCs', 'am': 'Please take the official translations! You find them here: http: // europa. eu. int/ eur- lex/ lex/ LexUriServ/ LexUriServ. do? uri=CELEX: 32001L0059: EN: HTML', 'hy': 'RL: Հիերախիկ ուժեղացման ուսումնասիրությունը դասընթացի գաղափարի ընդլայնման համար', 'az': 'RL: 칐yr톛nm톛k 칬yr톛nm톛si MOOCs', 'bn': 'এক্সপ্যানআরএলঃ মোওসিসে কোর্স কনসেপ্ট বিস্তারিত শিক্ষা', 'bs': 'RL: Hierarchical strengthening Learning for Course Concept Expansion in MOOCs', 'ca': 'ExpanRL: Aprendiment Hierarquic Reinforcement for Course Concept Expansion in MOOCs', 'cs': 'ExpanRL: Hierarchické posílení učení pro rozšíření konceptu kurzu v MOOCs', 'et': 'ExpanRL: Hierarhiline tugevdamine kursuse kontseptsiooni laiendamiseks MOOCs', 'fi': 'ExpanRL: Hierarkisen vahvistuksen oppiminen kurssikonseptin laajentamiseen MOOC:issa', 'ha': 'text-editor-action', 'he': 'ExpanRL: Hierarchical Reinforcement Learning for Course Concept Expansion in MOOCs', 'sk': 'ExpanRL: Hierarhično krepitev učenja za razširitev koncepta predmeta v MOOC', 'bo': 'ExpanRL: Hierarchical Reinforcement Learning for Course Concept Expansion in MOOCs', 'jv': 'Expansion'}
{'en': 'Within the prosperity of Massive Open Online Courses (MOOCs), the education applications that automatically provide extracurricular knowledge for MOOC users become rising research topics. However, MOOC courses’ diversity and rapid updates make it more challenging to find suitable new knowledge for students. In this paper, we present ExpanRL, an end-to-end hierarchical reinforcement learning (HRL) model for concept expansion in  MOOCs . Employing a two-level HRL mechanism of seed selection and concept expansion, ExpanRL is more feasible to adjust the expansion strategy to find new concepts based on the students’ feedback on expansion results. Our experiments on nine novel datasets from real MOOCs show that ExpanRL achieves significant improvements over existing methods and maintain competitive performance under different settings.', 'ar': 'في إطار ازدهار الدورات التدريبية المفتوحة على الإنترنت (MOOCs) ، أصبحت التطبيقات التعليمية التي توفر تلقائيًا المعرفة اللامنهجية لمستخدمي MOOC موضوعات بحثية صاعدة. ومع ذلك ، فإن تنوع دورات MOOC والتحديثات السريعة تجعل من الصعب العثور على معرفة جديدة مناسبة للطلاب. في هذه الورقة ، نقدم ExpanRL ، نموذج التعلم التعزيزي الهرمي الشامل (HRL) لتوسيع المفهوم في MOOCs. باستخدام آلية HRL ذات مستويين لاختيار البذور وتوسيع المفهوم ، فإن ExpanRL أكثر جدوى لضبط استراتيجية التوسع للعثور على مفاهيم جديدة بناءً على تعليقات الطلاب على نتائج التوسيع. تُظهر تجاربنا على تسع مجموعات بيانات جديدة من MOOCs الحقيقية أن ExpanRL تحقق تحسينات كبيرة على الأساليب الحالية وتحافظ على الأداء التنافسي في ظل إعدادات مختلفة.', 'fr': "Dans le cadre de la prospérité des cours en ligne ouverts et massifs (MOOC), les applications éducatives qui fournissent automatiquement des connaissances parascolaires aux utilisateurs de MOOC deviennent des sujets de recherche de plus en plus nombreux. Cependant, la diversité et les mises à jour rapides des cours MOOC rendent plus difficile la recherche de nouvelles connaissances adaptées aux étudiants. Dans cet article, nous présentons ExpanRL, un modèle d'apprentissage par renforcement hiérarchique (HRL) de bout en bout pour l'expansion de concepts dans les MOOC. En utilisant un mécanisme HRL à deux niveaux de sélection de semences et d'expansion de concept, ExpanRL est plus facile d'ajuster la stratégie d'expansion afin de trouver de nouveaux concepts en fonction des commentaires des étudiants sur les résultats de l'expansion. Nos expériences sur neuf nouveaux ensembles de données issus de véritables MOOC montrent que ExpanRL apporte des améliorations significatives par rapport aux méthodes existantes et maintient des performances compétitives dans différents contextes.", 'pt': 'Dentro da prosperidade dos Massive Open Online Courses (MOOCs), os aplicativos educacionais que fornecem automaticamente conhecimento extracurricular para usuários de MOOCs se tornam tópicos de pesquisa em ascensão. No entanto, a diversidade dos cursos MOOC e as atualizações rápidas tornam mais desafiador encontrar novos conhecimentos adequados para os alunos. Neste artigo, apresentamos o ExpanRL, um modelo de aprendizado por reforço hierárquico (HRL) de ponta a ponta para expansão de conceito em MOOCs. Empregando um mecanismo HRL de dois níveis de seleção de sementes e expansão de conceito, ExpanRL é mais viável para ajustar a estratégia de expansão para encontrar novos conceitos com base no feedback dos alunos sobre os resultados da expansão. Nossos experimentos em nove novos conjuntos de dados de MOOCs reais mostram que o ExpanRL alcança melhorias significativas em relação aos métodos existentes e mantém um desempenho competitivo em diferentes configurações.', 'es': 'Dentro de la prosperidad de los cursos en línea abiertos masivos (MOOC), las aplicaciones educativas que proporcionan automáticamente conocimientos extracurriculares a los usuarios de MOOC se convierten en temas de investigación cada vez más importantes. Sin embargo, la diversidad de los cursos MOOC y las actualizaciones rápidas hacen que sea más difícil encontrar nuevos conocimientos adecuados para los estudiantes. En este artículo, presentamos ExpanRL, un modelo de aprendizaje por refuerzo jerárquico (HRL) de extremo a extremo para la expansión de conceptos en MOOC. Empleando un mecanismo de HRL de dos niveles de selección de semillas y expansión de conceptos, ExpanRL es más factible para ajustar la estrategia de expansión para encontrar nuevos conceptos basados en los comentarios de los estudiantes sobre los resultados de la expansión. Nuestros experimentos en nueve conjuntos de datos novedosos de MOOC reales muestran que ExpanRL logra mejoras significativas con respecto a los métodos existentes y mantiene un rendimiento competitivo en diferentes entornos.', 'ja': 'MOOC （ Massive Open Online Course ）の隆盛の中で、MOOCユーザーに課外的な知識を自動的に提供する教育アプリケーションは、増加する研究トピックとなっている。しかし、MOOCコースの多様性と迅速な更新により、学生に適した新しい知識を見つけることはより困難になります。本稿では， MOOCにおける概念拡張のためのエンドツーエンドの階層強化学習（ HRL ）モデルであるExpanRLを提示する．シード選択とコンセプト拡張の2段階のHRLメカニズムを採用したExpanRLは、拡張戦略を調整して、拡張結果に対する学習者のフィードバックに基づいて新しいコンセプトを見つけることがより実現可能です。実物のMOOCからの9つの新規データセットの実験では、ExpanRLは既存の方法よりも大幅な改善を達成し、異なる設定下で競争力のあるパフォーマンスを維持することが示されています。', 'zh': '大开在线程(MOOC)之盛,自为MOOC用户供课外知之教应用程序为升研究课题。 然MOOC课程之多样性,与速更新,使为学者得其宜更具挑战性。 本文,我们介绍了ExpanRL,这是一种用MOOC中大概扩展的端端分层强化学习(HRL)模样。 ExpanRL用二等HRL机,以弟子之反馈,调广策以见新更具可行性。 吾于真MOOC九新数集之实验,ExpanRL于见法之本,显而改之,各置而竞争力之。', 'ru': 'В рамках процветания массовых открытых онлайн-курсов (MOOC) образовательные приложения, которые автоматически предоставляют внеклассные знания для пользователей MOOC, становятся растущими темами исследований. Однако разнообразие курсов MOOC и их быстрое обновление затрудняют поиск подходящих новых знаний для студентов. В этой статье мы представляем ExpanRL, сквозную иерархическую модель обучения подкреплению (HRL) для расширения концепции в MOOC. Используя двухуровневый механизм отбора семян и расширения концепции HRL, ExpanRL более целесообразно скорректировать стратегию расширения, чтобы найти новые концепции на основе отзывов студентов о результатах расширения. Наши эксперименты на девяти новых наборах данных из реальных MOOC показывают, что ExpanRL достигает значительных улучшений по сравнению с существующими методами и поддерживает конкурентоспособную производительность в различных условиях.', 'hi': 'बड़े पैमाने पर ओपन ऑनलाइन पाठ्यक्रम (MOOCs) की समृद्धि के भीतर, शिक्षा अनुप्रयोग जो स्वचालित रूप से MOOC उपयोगकर्ताओं के लिए अतिरिक्त ज्ञान प्रदान करते हैं, बढ़ते अनुसंधान विषय बन जाते हैं। हालांकि, MOOC पाठ्यक्रमों की विविधता और तेजी से अपडेट छात्रों के लिए उपयुक्त नए ज्ञान को खोजने के लिए इसे और अधिक चुनौतीपूर्ण बनाते हैं। इस पेपर में, हम ExpanRL, MOOCs में अवधारणा विस्तार के लिए एक एंड-टू-एंड पदानुक्रमित सुदृढीकरण सीखने (HRL) मॉडल प्रस्तुत करते हैं। बीज चयन और अवधारणा विस्तार के दो-स्तरीय एचआरएल तंत्र को नियोजित करते हुए, विस्तार परिणामों पर छात्रों की प्रतिक्रिया के आधार पर नई अवधारणाओं को खोजने के लिए विस्तार रणनीति को समायोजित करने के लिए ExpanRL अधिक व्यवहार्य है। वास्तविक MOOCs से नौ उपन्यास डेटासेट पर हमारे प्रयोगों से पता चलता है कि ExpanRL मौजूदा तरीकों पर महत्वपूर्ण सुधार प्राप्त करता है और विभिन्न सेटिंग्स के तहत प्रतिस्पर्धी प्रदर्शन को बनाए रखता है।', 'ga': 'Laistigh de rathúnas na gCúrsaí Ollmhóra Oscailte Ar Líne (MOOCanna), déantar topaicí taighde atá ag ardú i bhfeidhmchláir oideachais a sholáthraíonn eolas seach-churaclaim go huathoibríoch d’úsáideoirí MOOC. Mar sin féin, bíonn sé níos dúshlánaí eolas nua oiriúnach a aimsiú do mhic léinn mar gheall ar éagsúlacht agus nuashonruithe tapa chúrsaí MOOC. Sa pháipéar seo, cuirimid i láthair ExpanRL, samhail foghlama treisithe ordlathach ó cheann go ceann (HRL) le haghaidh leathnú coincheapa i MOOCs. Agus meicníocht HRL dhá leibhéal á úsáid aige maidir le roghnú síolta agus leathnú coincheap, tá sé níos indéanta ag ExpanRL an straitéis leathnaithe a choigeartú chun coincheapa nua a aimsiú bunaithe ar aiseolas na mac léinn ar thorthaí leathnaithe. Léiríonn ár dturgnaimh ar naoi dtacar sonraí núíosacha ó fhíor-MOOCanna go mbaineann ExpanRL feabhsuithe suntasacha amach thar na modhanna atá ann cheana féin agus go gcoimeádann sé feidhmíocht iomaíoch faoi shuímh éagsúla.', 'hu': 'A Massive Open Online Courses (MOOC) jólétében a MOOC felhasználók számára automatikusan nyújtó oktatási alkalmazások egyre növekvő kutatási témákká válnak. A MOOC kurzusok sokszínűsége és gyors frissítése azonban nehezebbé teszi a megfelelő új ismeretek megtalálását a diákok számára. Ebben a tanulmányban bemutatjuk az ExpanRL-t, egy end-to-end hierarchikus megerősítési tanulási modellt (HRL) a MOOC koncepcióbővítésére. A vetőmag kiválasztásának és koncepcióbővítésének kétszintű HRL mechanizmusával az ExpanRL megvalósíthatóbb a bővítési stratégia módosítása, hogy új koncepciókat találjon a diákok bővítési eredményekre vonatkozó visszajelzései alapján. A valódi MOOC-ból származó kilenc új adatkészleten végzett kísérleteink azt mutatják, hogy az ExpanRL jelentős javulást ér el a meglévő módszerekhez képest, és versenyképes teljesítményt tart fenn különböző beállítások között.', 'el': 'Μέσα στην ευημερία των μαζικών ανοικτών διαδικτυακών μαθημάτων, οι εκπαιδευτικές εφαρμογές που παρέχουν αυτόματα εξωσχολική γνώση στους χρήστες γίνονται αυξανόμενα ερευνητικά θέματα. Ωστόσο, η ποικιλία των μαθημάτων και οι γρήγορες ενημερώσεις καθιστούν πιο δύσκολη την εύρεση κατάλληλων νέων γνώσεων για τους φοιτητές. Σε αυτή την εργασία, παρουσιάζουμε ένα ολοκληρωμένο μοντέλο εκμάθησης ιεραρχικής ενίσχυσης για την επέκταση εννοιών σε ΜΟΟΚ. Χρησιμοποιώντας έναν μηχανισμό επιλογής σπόρων δύο επιπέδων και επέκτασης εννοιών, το είναι πιο εφικτό να προσαρμόσει τη στρατηγική επέκτασης για να βρει νέες έννοιες με βάση τα σχόλια των μαθητών σχετικά με τα αποτελέσματα επέκτασης. Τα πειράματά μας σε εννέα νέα σύνολα δεδομένων από πραγματικούς ΜΟΟΚ δείχνουν ότι επιτυγχάνει σημαντικές βελτιώσεις έναντι των υφιστάμενων μεθόδων και διατηρεί ανταγωνιστικές επιδόσεις σε διαφορετικές ρυθμίσεις.', 'ka': 'მასიური გახსნილი ინტერნეტიკური კურსების (MOOCs) პრობლეუფიციაში განსწავლებელი პროგრამები, რომელიც MOOC მომხმარებისთვის ავტომატურად განსწავლებელი მეცნიერება გახს მაგრამ, MOOC კურსის განსხვავებას და სწრაფად განახლებას უფრო შესაძლებელია, რომ სტუდენტებისთვის შესაძლებელი ახალი ცნობილებები მოიძებნა. ამ დომენტში ჩვენ გამოყენებთ "ExpanRL" მოდელს, რომელიც MOOCs-ში კონცექტის გაფართლებისთვის იერაქტიკალური სწავლება (HRL) მოდელს. ორ-დონე HRL მონიშნული და კონცექტის გაფართლების მექანიზმის გამოყენება, ExpanRL უფრო შესაძლებელია გაფართლების სტრაქტიფიკაციის გაფართლებისთვის ახალი კონცექტის შესახებ სტუდენტების გა ჩვენი ექსპერიმენტები 9 პრომენტის მონაცემების მონაცემების მონაცემების განმავლობაში ჩვენი ექსპერიმენტები გამოიყენება, რომ ExpanRL მიიღება მნიშვნელოვანი გაუქ', 'it': "All'interno della prosperità dei Massive Open Online Courses (MOOC), le applicazioni educative che forniscono automaticamente conoscenze extrascolastiche per gli utenti MOOC diventano argomenti di ricerca crescenti. Tuttavia, la diversità dei corsi MOOC e i rapidi aggiornamenti rendono più difficile trovare nuove conoscenze adatte per gli studenti. In questo articolo, presentiamo ExpanRL, un modello end-to-end di apprendimento gerarchico di rinforzo (HRL) per l'espansione dei concetti nei MOOC. Utilizzando un meccanismo HRL a due livelli di selezione dei semi e espansione del concetto, ExpanRL è più fattibile per adattare la strategia di espansione per trovare nuovi concetti basati sul feedback degli studenti sui risultati di espansione. I nostri esperimenti su nove nuovi set di dati provenienti da MOOC reali mostrano che ExpanRL ottiene miglioramenti significativi rispetto ai metodi esistenti e mantiene prestazioni competitive in diverse impostazioni.", 'kk': 'МООК пайдаланушыларының автоматты түрде білім беру бағдарламалары көтерілген зерттеу нақыштары болып тұр. Бірақ MOOC курстарының әртүрлі және тез жаңартулары студенттерге жаңа білім табуға көмектеседі. Бұл қағазда, MOOC концепциялық кеңейту үшін ЭкспанRL үлгісін келтіреміз. Екі деңгейі HRL таңдау мен концепциялардың кеңейту механизмін қолдану, ExpanRL кеңейту стратегиясын жаңа концепцияларды табу үшін студенттердің жауап беру нәтижесіне негізделген жаңа концепцияларды баптау үшін жа Біздің тәжірибеміз, шын MOOC деген тоғыз романдық деректер жинақтарында, ExpanRL бар әдістер арқылы үлкен жақсартылып, әртүрлі баптаулар арқылы әртүрлі жақсартылы', 'mk': 'Во рамките на просперитетот на масивните отворени онлајн курси (МООК), образовните апликации кои автоматски обезбедуваат екстракуларно знаење за корисниците на МООК стануваат сé поголеми истражувачки теми. Сепак, различноста на курсите на МООК и брзите оновременувања го прават потешко да се најде соодветно ново знаење за студентите. Во овој весник, го претставуваме ExpanRL, модел од крај до крај на хиерархиско засилување на учењето (HRL) за проширување на концептот во MOOCs. Користејќи двојно ниво механизам на ХРЛ за селекција на семето и проширување на концептот, ExpanRL е пофесибилен за прилагодување на стратегијата за проширување за да се најдат нови концепти базирани на реакциите на студентите за резултатите на проширувањето. Нашите експерименти на девет нови податоци од вистинските МООК покажуваат дека ExpanRL постигнува значителни подобрувања во однос на постоечките методи и одржува конкурентна резултатност под различни услови.', 'lt': 'Naudojant masinius atviruosius internetinius kursus (angl. Massive Open Online Courses, MOOC), švietimo programos, kurios automatiškai suteikia ne mokyklines žinias MOOC naudotojams, tampa vis svarbesnėmis mokslinių tyrimų temomis. Tačiau dėl MOOC kursų įvairovės ir greito atnaujinimo studentams sunkiau rasti tinkamų naujų žinių. Šiame dokumente pristatome ExpanRL, galutinio hierarchinio stiprinimo mokymosi (angl. end-to-end reinforcement learning, HRL) model į, skirtą koncepcijos plėtimui MOOC. Taikant dviejų lygių sėklos atrankos ir koncepcijos plėtimo HRL mechanizmą, ExpanRL yra įmanoma pritaikyti plėtros strategiją siekiant rasti naujas koncepcijas, pagrįstas studentų pastabomis dėl plėtros rezultatų. Mūsų eksperimentai dėl devynių naujų duomenų rinkinių iš tikrųjų MOOC rodo, kad ExpanRL gerokai pagerina esamus metodus ir išlaiko konkurencingumą įvairiomis aplinkybėmis.', 'ms': 'Dalam kemakmuran Masive Open Online Courses (MOOCs), aplikasi pendidikan yang secara automatik menyediakan pengetahuan ekstraskurikular bagi pengguna MOOC menjadi topik penyelidikan yang meningkat. Namun, kebanyakan kursus MOOC dan kemaskini cepat membuat ia lebih mencabar untuk mencari pengetahuan baru yang sesuai untuk pelajar. Dalam kertas ini, kami memperkenalkan ExpanRL, model pembelajaran kuasa hierarkis (HRL) akhir-akhir untuk pengembangan konsep dalam MOOCs. Menggunakan mekanisme HRL dua tahap pemilihan benih dan pengembangan konsep, ExpanRL lebih mudah untuk menyesuaikan strategi pengembangan untuk mencari konsep baru berdasarkan balas balik pelajar mengenai keputusan pengembangan. Eksperimen kami pada sembilan set data baru dari MOOCs sebenar menunjukkan bahawa ExpanRL mencapai peningkatan yang signifikan atas kaedah yang ada dan menjaga prestasi kompetitif di bawah tetapan yang berbeza.', 'ml': 'മോഓസി ഉപയോക്താക്കള്\u200dക്ക് വേണ്ടി വിദ്യാഭ്യാസം നല്\u200dകുന്ന വിദ്യാഭ്യാസത്തിനുള്ള പ്രയോഗങ്ങള്\u200d എന്നാലും MOOC കോര്\u200dസിന്റെ വ്യത്യാസവും വേഗത്തിലുള്ള പുതുക്കങ്ങളും വിദ്യാര്\u200dത്ഥികള്\u200dക്ക് വേണ്ടി പുതിയ അറിവ് കണ ഈ പത്രത്തില്\u200d, നമ്മള്\u200d എക്സ്പാന്\u200dആര്\u200dഎലിനെ കാണിക്കുന്നു, അവസാനത്തേക്കുള്ള അവസാനത്തേക്കുള്ള വിദ്യാഭ്യാസ പഠിപ്പിക്കുന്നതിനുള് വിത്ര തെരഞ്ഞെടുക്കുന്നതിന്റെയും ആശയം വികസിപ്പിക്കുന്നതിന്റെയും രണ്ട് നിലയില്\u200d HRL മെക്കീനിസം ഉപയോഗിക്കുന്നു. വികസിപ്പിന്റെ ഫലങ്ങള്\u200d അടിസ്ഥ യഥാര്\u200dത്ഥ MOOCs-ല്\u200d നിന്നുള്ള ഒമ്പതു നോവല്\u200d ഡേറ്റാസറ്റുകളില്\u200d നിന്നും നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു എക്സ്പാന്\u200dആര്\u200dഎല്\u200d നിലവ', 'mt': 'Fil-prosperità tal-Korsijiet Massivi Miftuħa Online (MOOCs), l-applikazzjonijiet tal-edukazzjoni li awtomatikament jipprovdu għarfien extrakurrikulari għall-utenti tal-MOOC isiru suġġetti ta’ riċerka li qed jiżdiedu. Madankollu, id-diversità tal-korsijiet MOOC u aġġornamenti rapidi jagħmluha aktar diffiċli li jinstab għarfien ġdid xieraq għall-istudenti. F’dan id-dokument, qed nippreżentaw l-ExpanRL, mudell ta’ tagħlim ġerarkiku ta’ rinfurzar minn tarf għal tarf (HRL) għall-espansjoni tal-kunċetti fil-MOOCs. Permezz ta’ mekkaniżmu ta’ żewġ livelli ta’ HRL għall-għa żla taż-żerriegħa u l-espansjoni tal-kunċett, ExpanRL huwa aktar fattibbli biex tiġi aġġustata l-istrateġija ta’ espansjoni biex jinstabu kunċetti ġodda bbażati fuq ir-reazzjonijiet tal-istudenti dwar ir-riżultati tal-espansjoni. L-esperimenti tagħna fuq disa’ settijiet ta’ dejta ġodda minn MOOCs reali juru li ExpanRL tikseb titjib sinifikanti fuq metodi eżistenti u żżomm il-prestazzjoni kompetittiva f’ambjenti differenti.', 'mn': 'Масс нээлттэй онлайн сургалтын хөгжилтэй байдлын дотор MOOC хэрэглэгчид автоматаар сургалтын мэдлэг хангадаг боловсрол хэрэглэгчид судалгааны сэдэв нэмэгддэг. Гэвч MOOC хичээлийн олон төрлийн болон хурдан шинэчлэлүүд оюутнуудад хэрэгтэй шинэ мэдлэг олох нь илүү хэцүү болгодог. Энэ цаасан дээр бид "ExpanRL"-г MOOCs-д ойлголтын нэмэлт загварын төгсгөлд эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь эцэст нь нэмэлт сурал Хоёр төвөгтэй HRL-ын тарианы сонголт болон ойлголтын өргөн механизмийг ашиглах нь ExpanRL нь сурагчдын өргөн үр дүн дээр шинэ ойлголтыг олох шинэ ойлголтын тулд нэмэгдүүлэх стратегийг зөвшөөрөх боломжтой. Манай бодит МООК-ын 9 шинэ өгөгдлийн сангийн туршилтын туршилтууд ЭкспанРЛ суурилсан аргачлал дээр маш чухал сайжруулах болон өрсөлдөөний үйл ажиллагааг өөр өөр хэмжээсүүд дотор хадгала', 'pl': 'W ramach dobrobytu masywnych otwartych kursów online (MOOC), aplikacje edukacyjne, które automatycznie dostarczają pozaprogramowej wiedzy użytkownikom MOOC, stają się coraz większymi tematami badawczymi. Jednak różnorodność kursów MOOC i szybkie aktualizacje sprawiają, że znalezienie odpowiedniej nowej wiedzy dla studentów jest trudniejsze. W artykule przedstawiamy ExpanRL, kompleksowy model uczenia się hierarchicznego (HRL) dla rozszerzania koncepcji w MOOCs. Wykorzystując dwupoziomowy mechanizm HRL selekcji nasion i rozszerzania koncepcji, ExpanRL jest bardziej wykonalne do dostosowania strategii ekspansji w celu znalezienia nowych koncepcji w oparciu o opinie studentów na wynikach ekspansji. Nasze eksperymenty na dziewięciu nowych zbiorach danych z prawdziwych MOOCs pokazują, że ExpanRL osiąga znaczące ulepszenia w stosunku do istniejących metod i utrzymuje konkurencyjność w różnych ustawieniach.', 'ro': 'În cadrul prosperității cursurilor online deschise masive (MOOC), aplicațiile educaționale care oferă automat cunoștințe extrașcolare utilizatorilor MOOC devin subiecte de cercetare în creștere. Cu toate acestea, diversitatea cursurilor MOOC și actualizările rapide fac mai dificilă găsirea de noi cunoștințe adecvate pentru studenți. În această lucrare, prezentăm ExpanRL, un model end-to-end de învățare ierarhică de armare (HRL) pentru extinderea conceptului în MOOC. Utilizând un mecanism HRL pe două niveluri de selecție a semințelor și extindere a conceptului, ExpanRL este mai fezabil pentru a ajusta strategia de expansiune pentru a găsi noi concepte bazate pe feedback-ul studenților cu privire la rezultatele expansiunii. Experimentele noastre pe nouă seturi de date noi din MOOC reale arată că ExpanRL realizează îmbunătățiri semnificative față de metodele existente și menține performanța competitivă în diferite setări.', 'no': 'I framferdigheten av massive Open Online Courses (MOOCs) blir utdanningsprogrammene som automatisk tilbyr ekstra curricular kunnskap for MOOC-brukarar økt forskningsemne. Men MOOC-kursar har mangfold og raske oppdateringar meir vanskeleg å finna passende nye kunnskap for studentar. I denne papiret presenterer vi ekspanRL- modellen for utviding av konseptar i MOOCs i ein hierarkisk reinforcement- læring (HRL). For å bruka ein to nivå HRL-mekanisme for frøutvalet og utviding av konseptar, er ExpanRL meir feilig for å justera utvidingsstrategien for å finna nye konseptar basert på tilbakemelding av studentene på utvidingsresultatet. Eksperimentane våre på ni novel datasett frå verkeleg MOOCs viser at ExpanRL gjer signifikante forbedringar over eksisterande metodar og vedlikehald konkurentære utviklingar under ulike innstillingar.', 'sr': 'U prosperitetu masovnih otvorenih online kursa (MOOC), obrazovne aplikacije koje automatski pružaju ekstra nastavne znanje za korisnike MOOC-a postaju povećane istraživačke teme. Međutim, MOOC kursa raznolikost i brze aktualizacije čine izazovnijim pronalaženjem odgovarajućih novih znanja za studente. U ovom papiru predstavljamo ekspanRL, hijerarhičko učenje pojačanja (HRL) model za proširenje koncepta u MOOCs-u. Za upotrebu mehanizma dva nivoa HRL selekcije semena i proširenja koncepta, ExpanRL je veća mogućnost da se prilagodi strategija proširenja za pronalaženje novih koncepta na osnovu reakcije studenata na rezultatima proširenja. Naši eksperimenti na devet novih seta podataka iz pravih MOOC pokazuju da ExpanRL postigne značajne poboljšanje u postojećim metodama i održava konkurentne funkcije pod različitim nastavama.', 'sv': 'Inom välståndet i Massive Open Online Courses (MOOC) blir utbildningsapplikationer som automatiskt tillhandahåller extracurricular kunskap för MOOC-användare växande forskningsämnen. MOOC-kursernas mångfald och snabba uppdateringar gör det dock svårare att hitta lämplig ny kunskap för studenter. I denna uppsats presenterar vi ExpanRL, en end-to-end hierarkisk förstärkning lärande (HRL) modell för konceptexpansion i MOOC. Med hjälp av en tvånivås HRL-mekanism för fröurval och konceptexpansion är ExpanRL mer genomförbar att anpassa expansionsstrategin för att hitta nya koncept baserat på studenternas feedback på expansionsresultat. Våra experiment på nio nya datauppsättningar från riktiga MOOC visar att ExpanRL uppnår betydande förbättringar jämfört med befintliga metoder och upprätthåller konkurrenskraftig prestanda under olika inställningar.', 'si': 'මැසිව් අර්ලායින් කෝස්ස් එක්ක (MOOCs) සාමාන්\u200dය විශ්වාසයෙන්, MOOC ප්\u200dරයෝජකයන්ට ස්වයංක්\u200dරියාවිත විශ්වාසයෙන් ප නමුත් MOOC කාර්ස් වගේ විවිධානය සහ ඉක්මනින් අවස්ථානය කරන්න ඒක විශ්වාස කරන්න පුළුවන් අලුත් දැනගන්න. මේ පත්තරේ අපි ප්\u200dරතිචාරයක් ප්\u200dරතිචාර කරනවා එප්පැන්ර්ල්, අවසානයෙන් අවසානයෙන් අවසානයෙන් ඉගෙනීම (HRL) මදුල්ය MOOC සීඩ් තෝරණය සහ අභිවෘත විස්තර දෙකක් තෝරණය HRL පද්ධතියක් භාවිත කරන්න, එප්පාන්RL විස්තර විස්තර විස්තාරණය සඳහා අලුත් අභිවෘතිය අපේ පරීක්ෂණය අවුල් තොරතුරු දත්ත සෙට් නයක් ඇත්ත MOOCs වලින් පෙන්වන්න පුළුවන් විදිහට එප්පැන්ර්ල් වලින් තියෙන්න', 'so': 'Koorasyada shabakadda ee furan (MOOCs) ee guud ku jirta, codsiga waxbarashada ee iskuulka ah oo si gaar ah loo baranayo aqoonta qaaliga ah ee isticmaalayaasha MOOOC waxay noqdeen maadooyinka waxbarashada korsocota. Si kastaba ha ahaatee koorasyada MOOC oo kala duduwan iyo taariikhda dhaqdhaqaaqa ah waxay ka dhigataa dhibaato badan in ardayda loo helo aqoonta cusub oo ku haboon. In this paper, we present ExpanRL, an end-to-end hierarchical reinforcement learning (HRL) model for concept expansion in MOOCs.  Isu sameynta qalabka doorashada farcanka iyo koritaanka dhanka labada daraf ah, ExpanRL waa suurtogal in la beddelo qorshaha koritaanka si loo helo fikrada cusub oo lagu saleynayo dib u celinta arimaha koritaanka ee ardayda. Imtixaanadayada ku qoran sagaal sawirada ee runta ah ee MOOOCs waxay muujiyaan in ExpanRL uu helo hagaajin aad u weyn oo ka kordhiya qaababka joogta ah iyo in uu ku dadaalo tababar adag oo ka hooseeya hababka kala duduwan.', 'ta': "மிகப்பெரிய திறந்த இணைய மாற்றுகளின் (MOOCs) வளர்ச்சியில், MOOC பயனர்களுக்கு தானாகவே உயர்ந்த அறிவு கொடுக்கும் கல்வி பயன்பாடுகள் அதிகரிக்க எனினும், MOOC மாணவர்களின் பல்வேறு மற்றும் வேகமான புதுப்பித்தல் அது மாணவர்களுக்கு பொருத்தமான புதிய அறிவை கண்டுபி இந்த காகிதத்தில், நாம் எக்ஸ்பான்ஆர்எல், முடிவுக்கு முடிவுக்கு முடிவுக்கு மாதிரி கல்வி படிப்பு (HRL) மாதிரி MOOCs விரிவாக் Employing a two-level HRL mechanism of seed selection and concept expansion, ExpanRL is more feasible to adjust the expansion strategy to find new concepts based on the students' feedback on expansion results.  உண்மையான MOOCs இருந்து ஒன்பது புதிய தகவல் அமைப்புகளில் இருந்து எங்கள் சோதனைகள் காட்டுகிறது எக்ஸ்பான்ஆர்எல் ஏற்கனவே இருக்கும் முறைகளை", 'ur': "ماسی اوپن آنلاین کورس (MOOCs) کی خوش حالی میں، سکونت کی کاربریاں جو MOOC کارساز کے لئے اضافہ علم دے رہے ہیں، اضافہ تحقیق کے موضوع میں اضافہ ہوتے ہیں. However, MOOC courses' diversity and rapid updates make it more challenging to find suitable new knowledge for students. اس کاغذ میں ہم ExpanRL کو نشان دیتے ہیں، ایک پایان پائیں پائیں پائیں پائیں پائیں پائیں پھیلانے کے لئے (HRL) موڈل MOOCs میں مفصل پھیلانے کے لئے۔ دو سطح HRL مکانیسم کے مکانیسم کا استعمال کرنا، ExpanRL بڑھنے کے نتیجے پر نو تفسیر لگانے کے لئے بہت حلم ہے. ہماری آزمائش نو نو روانی ڈاٹ سٹ کے ذریعے واقعی MOOCs سے نشان دیتی ہے کہ ExpanRL موجود طریقوں پر بہت اضافہ حاصل کرتا ہے اور مختلف تنظیمات کے ذریعے مسابقات کے ساتھ مسابقات کرتا ہے.", 'uz': "Name Lekin, MOOC kursining turli va tez yangiliklari o'quvchilari uchun yetarli maʼlumot topish qiziqaradi. Bu qogʻozda, biz ExpanRL, oxiriga oxirgi hierarchik o'rganish (HRL) modeli MOOC'da o'zgartirish uchun foydalanish modeli. Name Bizning 9 novel maʼlumotlarimiz haqiqiqiy MOOOClar tarkibidagi tajribalarimizni ko'rsatadi ExpanRL mavjud usullarda juda muhim yaxshi o'zgarishni va boshqa moslamalar davomida rivojlantirish muvaffaqiyatlarini saqlaydi.", 'vi': 'Trong sự thịnh vượng của chương trình Mạng rộng mở (tổ chức giám sát) các chương trình giáo dục tự động cung cấp kiến thức ngoại khóa cho người dùng MOOC trở thành các chủ đề nghiên cứu. Tuy nhiên, sự đa dạng của tổ chức các khóa MOOC và những cập nhật nhanh làm cho nó trở nên khó khăn hơn để tìm kiếm những kiến thức mới thích hợp cho sinh viên. Trong tờ giấy này, chúng tôi giới thiệu Bung, một kiểu để tập thắt lại hệ thống cấp dưới (HRL) cho việc phát triển khái niệm trong tổ chức MOOCs. Việc áp dụng cơ chế HRL hai cấp với việc chọn hạt giống và phát triển khái niệm, rộng lớn thì khả thi hơn để điều chỉnh chiến lược mở rộng để tìm ra ý kiến mới dựa trên phản hồi của học sinh về kết quả mở rộng. Các thí nghiệm trên chín tập tin mới từ các tổ chức MOOC thật sự cho thấy rằng Công ty Mọi người đã đạt được những cải tiến đáng kể về các phương pháp đã có và duy trì khả năng cạnh tranh tại các môi trường khác nhau.', 'bg': 'В рамките на просперитета на масовите отворени онлайн курсове (МООК) образователните приложения, които автоматично предоставят извънкласни знания за потребителите на МООК, се превръщат в нарастващи изследователски теми. Въпреки това, многообразието на курсовете и бързите актуализации правят по-трудно намирането на подходящи нови знания за учениците. В настоящата статия представяме модел за разширение на концепцията в МООК. Използвайки двустепенен механизъм за избор на семена и разширяване на концепцията, е по-осъществимо да коригира стратегията за разширяване, за да намери нови концепции въз основа на обратната връзка на учениците относно резултатите от разширяването. Нашите експерименти с девет нови набора от данни от реални МООК показват, че постига значителни подобрения в сравнение със съществуващите методи и поддържа конкурентна производителност при различни настройки.', 'da': "Inden for velstanden af Massive Open Online Courses (MOOCs), bliver de uddannelsesprogrammer, der automatisk giver ekstra viden til MOOC brugere, stigende forskningsemner. MOOC-kursernes mangfoldighed og hurtige opdateringer gør det dog mere udfordrende at finde passende ny viden til de studerende. I denne artikel præsenterer vi ExpanRL, en end-to-end hierarkisk forstærkning læring (HRL) model til konceptudvidelse i MOOC'er. Ved hjælp af en to-niveau HRL mekanisme for frøvalg og konceptudvidelse er ExpanRL mere muligt at justere ekspansionsstrategien for at finde nye koncepter baseret på elevernes feedback på ekspansionsresultater. Vores eksperimenter med ni nye datasæt fra ægte MOOC'er viser, at ExpanRL opnår betydelige forbedringer i forhold til eksisterende metoder og opretholder konkurrencedygtige resultater under forskellige indstillinger.", 'nl': "Binnen de welvaart van Massive Open Online Courses (MOOC's) worden de onderwijsapplicaties die automatisch extracurriculaire kennis verstrekken aan MOOC gebruikers steeds meer onderzoeksthema's. De diversiteit van MOOC-cursussen en snelle updates maken het echter moeilijker om geschikte nieuwe kennis te vinden voor studenten. In dit artikel presenteren we ExpanRL, een end-to-end hiërarchisch versterkingsmodel (HRL) voor conceptuitbreiding in MOOCs. Door gebruik te maken van een HRL-mechanisme op twee niveaus van zaadselectie en conceptuitbreiding, is ExpanRL haalbaarer om de uitbreidingsstrategie aan te passen om nieuwe concepten te vinden op basis van de feedback van de studenten op uitbreidingsresultaten. Onze experimenten met negen nieuwe datasets van echte MOOCs tonen aan dat ExpanRL aanzienlijke verbeteringen ten opzichte van bestaande methoden bereikt en concurrerende prestaties behoudt onder verschillende instellingen.", 'hr': 'U prosperitetu masovnih otvorenih online kursa (MOOC), obrazovne aplikacije koje automatski pružaju ekstra nastavne znanje za korisnike MOOC-a postaju rastuće istraživačke teme. Međutim, MOOC uči raznolikost i brze aktualizacije čini težim pronalaženje odgovarajućih novih znanja učenicima. U ovom papiru predstavljamo ExpanRL, model za proširenje koncepta u MOOCs-u hijerarhičkog pojačanja (HRL). Za upotrebu mehanizma dvorazine HRL-a izbora semena i proširenja koncepta, ExpanRL je moguće prilagoditi strategiju proširenja za pronalaženje novih koncepta na temelju povratka studenata na rezultatima proširenja. Naši eksperimenti na devet novih podataka iz pravih MOOC pokazuju da ExpanRL postigne značajne poboljšanje u postojećim metodama i održava konkurentne učinke pod različitim nastavama.', 'de': 'Im Rahmen des Wohlstands von Massive Open Online Courses (MOOCs) werden Bildungsanwendungen, die automatisch außerschulisches Wissen für MOOC-Nutzer bereitstellen, zu steigenden Forschungsthemen. Die Vielfalt der MOOC-Kurse und die schnellen Aktualisierungen machen es jedoch schwieriger, geeignete neue Kenntnisse für Studierende zu finden. In diesem Beitrag stellen wir ExpanRL vor, ein durchgängiges hierarchisches Verstärkungslernen (HRL)-Modell zur Konzepterweiterung in MOOCs. Durch den Einsatz eines zweistufigen HRL-Mechanismus der Saatgutauswahl und der Konzepterweiterung ist ExpanRL besser geeignet, die Expansionsstrategie anzupassen, um neue Konzepte basierend auf dem Feedback der Studenten zu den Expansionsergebnissen zu finden. Unsere Experimente an neun neuartigen Datensätzen aus realen MOOCs zeigen, dass ExpanRL signifikante Verbesserungen gegenüber bestehenden Methoden erzielt und die Wettbewerbsfähigkeit unter verschiedenen Settings aufrechterhält.', 'ko': '대규모 온라인 오픈커리큘럼(MOOC)이 번창하면서 MOOC 이용자에게 자동으로 사교육을 제공하는 교육 앱이 신흥 연구 과제로 떠올랐다.그러나 MOOC 과정의 다양성과 신속한 갱신은 학생들에게 적합한 새로운 지식을 찾는 데 더욱 도전적이다.본고에서 우리는 ExpanRL, 단도직입적인 층별 강화 학습(HRL) 모델을 제시하여 MOOC의 개념 확장에 사용했다.ExpanRL은 피드 선택과 개념 확장 두 개의 HRL 메커니즘을 사용하고 학생들이 확장 결과에 대한 피드백에 따라 확장 전략을 조정하여 새로운 개념을 발견하는 것이 더욱 가능하다.우리가 실제 MOOC에서 나온 9개의 새로운 데이터 집합에서의 실험에서 ExpanRL은 기존 방법에 비해 현저한 개선을 얻었고 서로 다른 설정에서 경쟁력 있는 성능을 유지했다.', 'fa': 'در حالی که توسط برخورداری مسائل باز آنلاین (MOOCs) کاربرد آموزشی که به طور خودکار دانش بیرون آموزشی برای کاربران MOOC به عنوان موضوع تحقیق افزایش می\u200cشوند. با این حال، مختلفیت و فعالیت\u200cهای سریع MOOC را درس می\u200cگیرد تا دانش\u200cهای جدید مناسب برای دانش\u200cآموزان پیدا کند سخت\u200cتر باشد. در این کاغذ، ما مدل پشتیبانی (HRL) را برای گسترش مفهوم در MOOCs نشان می دهیم. استفاده از یک مکانیسم HRL دو سطح از انتخاب دانه و گسترش مفهوم، ExpanRL برای تنظیم استراتژی گسترش برای پیدا کردن مفهوم جدید بر پایه بازگشت دانش آموزان بر نتیجه گسترش بیشتر قابل است. آزمایش\u200cهای ما در نو مجموعه داده\u200cهای رمانی از MOOC واقعی نشان می\u200cدهند که ExpanRL بر روش\u200cهای موجود پیشرفت\u200cهای بزرگی می\u200cیابد و عملکرد رقابتی را تحت تنظیمات مختلف نگه می\u200cدارد.', 'id': "Dalam kemakmuran Massive Open Online Courses (MOOCs), aplikasi pendidikan yang secara otomatis menyediakan pengetahuan ekstraskurikuluar bagi pengguna MOOC menjadi topik penelitian yang meningkat. However, MOOC courses' diversity and rapid updates make it more challenging to find suitable new knowledge for students.  Dalam kertas ini, kami memperkenalkan ExpanRL, sebuah model pembelajaran perubahan hierarkis (HRL) akhir-akhir untuk ekspansi konsep dalam MOOC. Menggunakan mekanisme HRL dua tingkat dari seleksi benih dan ekspansi konsep, ExpanRL lebih mudah untuk menyesuaikan strategi ekspansi untuk menemukan konsep baru berdasarkan feedback siswa tentang hasil ekspansi. Our experiments on nine novel datasets from real MOOCs show that ExpanRL achieves significant improvements over existing methods and maintain competitive performance under different settings.", 'sw': "Katika mafanikio ya Mabara makubwa ya Mafuriko ya Mtandaoni (MOOCs), matumizi ya elimu yanayotoa maarifa kwa wenyewe kwa watumiaji wa MOOOC yanakua mada zinazoongezeka kwa utafiti. However, MOOC courses' diversity and rapid updates make it more challenging to find suitable new knowledge for students.  Katika karatasi hii, tunawasilisha ExpanRL, mtindo wa kuimarisha elimu ya mwisho (HRL) wa kuongezeka kwa dhana ya MOOCs. Kutumia mfumo wa HRL wa ngazi mbili wa uchaguzi wa seed na kuongezeka kwa dhana, ExpanRL ni muhimu zaidi kuboresha mkakati wa kuongezeka ili kutafuta dhana mpya zinazohusu matokeo ya kuongezeka kwa wanafunzi. Majaribio yetu kwenye seti za taarifa tisa za riwaya kutoka kwa MOOOCs halisi yanaonyesha kwamba ExpanRL hupata maboresho makubwa zaidi ya njia zilizopo na kuendelea utendaji wa ushindani chini ya mazingira tofauti.", 'af': "Binne die voorspoedigheid van Massive Open Online Courses (MOOCs), word die opvoedkundige programme wat outomaties ekstra-opvoedkundige kennis verskaf vir MOOC gebruikers opgroei ondersoek onderwerpe. Maar MOOC-kurse se diversiteit en vinnige opdaterings maak dit meer moeilik om geskikte nuwe kennis vir studente te vind. In hierdie papier, voorsien ons ExpanRL, 'n einde-na-einde hierarkies versterking leer (HRL) model vir konsepte uitbreiding in MOOCs. By die gebruik van 'n twee vlak HRL-mekanisme van saadskeuse en konsepte uitbreiding, is ExpanRL meer moontlik om die uitbreidingsstrategie te korrigeer om nuwe konsepte te vind gebaseer op die terugmelding van die studente op uitbreidingsresultate. Ons eksperimente op nege nuwe datastel van reël MOOCs wys dat ExpanRL betekende verbeteringe oor bestaande metodes bereik en mededingstekens onder verskillende instellings behou.", 'sq': 'Within the prosperity of Massive Open Online Courses (MOOCs), the education applications that automatically provide extracurricular knowledge for MOOC users become rising research topics.  Megjithatë, diversiteti i kurseve të MOOC dhe përditësimet e shpejta e bëjnë më të vështirë të gjesh njohuri të përshtatshme të reja për studentët. Në këtë letër, ne paraqesim ExpanRL, një model nga fundi në fund të mësimit të forcimit hierarkik (HRL) për zgjerimin e konceptit në MOOCs. Duke përdorur një mekanizëm të dy niveleve HRL të zgjedhjes së frymëve dhe zgjerimit të konceptit, ExpanRL është më i realizueshëm për të rregulluar strategjinë e zgjerimit për të gjetur koncepte të reja bazuar në feedback të studentëve mbi rezultatet e zgjerimit. Eksperimentet tona në nëntë grupe të dhënash të reja nga MOOCs reale tregojnë se ExpanRL arrin përmirësime të rëndësishme lidhur me metodat ekzistuese dhe mban performancën konkurruese nën ambiente të ndryshme.', 'tr': "Y체ksek A챌 Online Courses (MOOCs) m체mkin챌iliginde, MOOC ullan챌ylaryny흫 체st체ne 철흫ki bilim 체첵tgeden bilim 체첵tgetmekleri 체챌in 철n체mden 챌ykan ara힊tyrma temalarynda 체첵tge첵채r. 횦철ne, MOOC okuw챌ylar 체챌in n채챌e g철rn체힊likleri we 챌alt g체ncelle힊meleri t채ze bilim tapmakda has kyn챌ylyk edip bil첵채r. Bu kagyzda, MOOCs'da d체힊체njeleri 체챌in bir i첵erarhi첵a 체st체nlik 철wrenmek 체챌in ExpanRL'i g철rkezip ber첵채ris. Eksi derejede HRL ta첵dan sa첵lamak we d체힊체nj채ni흫 d철wletlerini ulanmak, ExpanRL okuw챌ylary흫 netijelerine da첵alan t채ze d체힊체nj채ni tapmak 체챌in t채ze d체힊체nj채ni bejermek 체챌in daha m체mkin챌idir. Bizim MOOC-ny흫 9 roman sanatyndaky deneylerimiz ExpanRL bar 채hli d철wletlerde m철h체m geli힊meleri 첵체ze 챌yk첵ar we 챌yky힊ykly hereket etm채ni farkl캇 d체z체mlerden gara힊첵ar.", 'am': 'በሙሉ ክፈት የመስመር ኮርቨርስቲ (MOOCs) ትምህርት ፕሮግራሞች፣ ለMOOC ተጠቃሚዎች የበዛ ምርመራ ጉዳዮች ሆነዋል፡፡ ነገር ግን የMOOC ተማሪዎችን ልዩ ልዩ እና ፈጥኖ አዲስ እውቀት ለማግኘት ይጨምሩታል፡፡ በዚህ ካላት አካባቢ ውስጥ የፍጻሜው የመጨረሻ አዳራርካዊ ትምህርት (HRL) ምሳሌ በMOOCs ለመስፋት እናቀርባለን፡፡ በሁለት ደረጃ ላይ HRL የዘር ምርጫ እና የሕንጻውን ማሰናከል በመጠቀም የExpanRL ስርዓት በተማሪዎቹ ፍጥረቶች ላይ የመጠቀምን መልስ በመጠቀም ላይ አዲስ ጥናት ማግኘት ይችላል፡፡ እውነተኛ MOOCs የዘጠኝ የመረጃ ዳታዎችን ፈተናዎች ExpanRL በተገኘ ሥርዓቶች ላይ ትልቅ ማድረግ እንዲያገኝ እና በተለየ ባሕላዊ ግንኙነትን እንዲጠብቁ ያሳያል፡፡', 'az': "Massive Open Online Courses (MOOCs) təhsil içində, MOOC istifadəçiləri üçün avtomatik olaraq təhsil edilən təhsil proqramları təhsil edir. Ancaq MOOC tərzlərinin müxtəlifliyini və tez güncelləri öğrencilərə uyğun yeni bilgi tapmaq daha çətin edər. Bu kağızda, MOOCs-da konsept genişlənməsi üçün bir hiyerarşik yenilənmək öyrənməsi (HRL) modeli ExpanRL'i göstəririk. İki səviyyə HRL seçimlərinin və konseptlərin genişlənməsinin mehanizmisini istifadə etmək, ExpanRL öğrencilərin genişlənmə sonuçlarına dayanan yeni fikirləri tapmaq üçün genişlənmə stratejisini düzəltmək üçün daha münasibdir. Bizim doqquz yeni MOOC verilən təcrübələrimiz göstərir ki, ExpanRL mövcuddur metodlar üzərində mövcuddur düzəltmələri və müqayisədə müqayisədə performansı müxtəlif tərzlərin altında saxlayır.", 'bn': 'ব্যাপক উন্মুক্ত অনলাইন কোর্সের সমৃদ্ধির মাধ্যমে এমওসি ব্যবহারকারীদের জন্য স্বয়ংক্রিয়ভাবে বিদেশী জ্ঞান প্রদান করা শিক্ষার্থী প্রো তবে MOOC কোর্সের বৈচিত্র্য এবং দ্রুত আপডেটগুলো শিক্ষার্থীদের জন্য নতুন জ্ঞান খুঁজে বের করার জন্য আরো চ্যালেঞ এই কাগজটিতে আমরা এক্সপ্যানআরএল উপস্থাপন করছি, যা শেষ পর্যন্ত শিক্ষা শেখার (এইচআরএল) মডেল মোডেল, যা মোওকিসের ধারণা বিস্তৃতির জন্য। বৃক্ষ নির্বাচন এবং ধারণা বিস্তৃতির দুই স্তরের এক এইচআরএল মেক্সিনেমা ব্যবহার করে, বিস্তৃত ফলাফলের উপর ভিত্তিতে ছাত্রদের বিস্তৃতি প্রতিক্রিয়ার উপর ভিত্তিতে নত সত্যিকারের MOOCs থেকে নয়টি নোভেল ডাটাসেটের উপর আমাদের পরীক্ষা দেখা যাচ্ছে যে এক্সপ্যানআরএল বিদ্যমান পদ্ধতির উপর বিশাল উন্নতি পেয়েছে', 'bs': 'U prosperitetu masovnih otvorenih online kursa (MOOC), obrazovne aplikacije koje automatski pružaju ekstra nastavne znanje za korisnike MOOC-a postaju rastuće istraživačke teme. Međutim, MOOC kursa raznolikost i brze aktualizacije čine teže pronaći odgovarajuće nove znanje studentima. U ovom papiru predstavljamo ExpanRL, model za proširenje koncepta u MOOC-u hijerarhičkog pojačanja (HRL). Zaposlenje mehanizma dvonivoa HRL-a selekcije semena i proširenja koncepta, ExpanRL je veće moguće za prilagođenje strategije proširenja za pronalaženje novih koncepta na osnovu reakcije studenata na rezultatima proširenja. Naši eksperimenti na devet novih podataka iz pravih MOOC pokazuju da ExpanRL postigne značajne poboljšanje u postojećim metodama i održava konkurentne funkcije pod različitim nastavama.', 'hy': 'Մոսիվ օնլայն դասընթացների զարգացման մեջ կրթական ծրագրերը, որոնք ինքնաբերաբար տրամադրում են անդասական գիտելիքներ Մոսիվ օնլայն դասընթացների օգտագործողների համար, դառնում են աճող հետազոտական թեմաներ: Սակայն, ՄՕՕԿ-ի դասընթացների բազմազանությունը և արագ վերականգնումները դարձնում են ավելի դժվար ուսանողների համար նոր գիտելիքներ գտնել: Այս թղթի մեջ մենք ներկայացնում ենք Expan RL-ը, մի վերջ-վերջ հիերարխիկ ուժեղացման ուսումնասիրության (HRL) մոդել, որն օգտագործում է հասկացության ընդլայնումը մոդելներում: Օգտագործելով սերմների ընտրության և գաղափարի ընդլայնման երկու մակարդակի HRL մեխանիզմը, Expan RL-ը ավելի հնարավոր է ընդլայնման ռազմավարությունը հարմարեցնելու համար նոր գաղափարներ գտնելու համար, որոնք հիմնված են ուսանողների արձագանքների վրա ընդլայնման արդյունք Մեր ինն նոր տվյալների փորձարկումները իրական ՄՕՕԿ-ներից ցույց են տալիս, որ Expan RL-ը կարևոր բարելավումներ է հասնում գոյություն ունեցող մեթոդների վերաբերյալ և պահպանում է մրցակցության արդյունքը տարբեր միջավ', 'ca': "Dentre la prosperitat dels cursos massius oberts en línia (MOOCs), les aplicacions educatius que proporcionen automàticament coneixement extracurricular als usuaris de MOOC es converteixen en temes de recerca en creixement. Però la diversitat dels cursos MOOC i les actualitzacions ràpides fan més difícil trobar coneixements adequats per als estudiants. In this paper, we present ExpanRL, an end-to-end hierarchical reinforcement learning (HRL) model for concept expansion in MOOCs.  Utilitzant un mecanisme de selecció de semilles i expansió de conceptes a dos nivells, ExpanRL és més viable per ajustar l'estratègia d'expansió per trobar nous conceptes basats en el feedback dels estudiants sobre els resultats d'expansió. Els nostres experiments en nou nou nou conjunts de dades de MOOCs reals mostren que ExpanRL aconsegueix millores significatives sobre els mètodes existents i manté el rendiment competitiu en diferents entorns.", 'cs': 'V rámci prosperity masivních otevřených online kurzů (MOOCs) se vzdělávací aplikace, které automaticky poskytují mimoškolní znalosti uživatelům MOOC, stávají rostoucími výzkumnými tématy. Rozmanitost kurzů MOOC a rychlé aktualizace však činí náročnější najít vhodné nové znalosti pro studenty. V tomto článku představujeme ExpanRL, model end-to-end hierarchického zesílení učení (HRL) pro rozšíření konceptů v MOOCs. Využitím dvouúrovňového HRL mechanismu výběru osiva a rozšíření konceptu je ExpanRL proveditelnější upravit strategii expanze tak, aby nalezl nové koncepty založené na zpětné vazbě studentů na výsledcích expanze. Naše experimenty na devíti nových datových sadách z reálných MOOCs ukazují, že ExpanRL dosahuje významných zlepšení oproti stávajícím metodám a udržuje konkurenční výkon v různých nastaveních.', 'et': 'Massiivsete avatud online-kursuste (MOOC) jõukuse raames muutuvad MOOC-i kasutajatele automaatselt õppekavavälisi teadmisi pakkuvad haridusrakendused kasvavaks uurimisteemaks. Kuid MOOC kursuste mitmekesisus ja kiired uuendused muudavad õpilastele sobivate uute teadmiste leidmine keerulisemaks. Käesolevas töös tutvustame ExpanRL-i, end-to-end hierarhilise tugevdamise õppe (HRL) mudelit kontseptsioonide laiendamiseks MOOCs. Kasutades seemnevaliku ja kontseptsiooni laiendamise kahetasandilist HRL-mehhanismi, on ExpanRL võimalik laienemisstrateegiat kohandada, et leida uusi kontseptsioone, mis põhinevad õpilaste tagasisidel laienemise tulemuste kohta. Meie eksperimendid üheksa uudse andmekogumiga reaalsetest MOOCidest näitavad, et ExpanRL saavutab olulisi parandusi võrreldes olemasolevate meetoditega ja säilitab konkurentsivõime erinevates tingimustes.', 'fi': 'Massiivisten avoimien online-kurssien (MOOC) kukoistuksessa MOOC-käyttäjille automaattisesti opetussovelluksista tulee nouseva tutkimusaihe. MOOC-kurssien monipuolisuus ja nopeat päivitykset tekevät opiskelijoille sopivan uuden tiedon löytämisestä haastavampaa. Tässä työssä esittelemme ExpanRL:n, end-to-end hierarkkisen vahvistuksen oppimisen (HRL) mallin konseptien laajentamiseen MOOC:issa. Käyttämällä kaksitasoista siementen valintaa ja konseptin laajentamista koskevaa HRL-mekanismia ExpanRL on helpompi mukauttaa laajentumisstrategiaa uusien konseptien löytämiseksi opiskelijoiden palautteen pohjalta. Kokeet yhdeksällä uudella datajoukolla oikeista MOOC-laitteista osoittavat, että ExpanRL saavuttaa merkittäviä parannuksia nykyisiin menetelmiin verrattuna ja ylläpitää kilpailukykyä eri tilanteissa.', 'ha': "Within the prosperity of Massive Open Online Courses (MOOCs), the education applications that automatically provide extracurricular knowledge for MOOC users become rising research topics.  Haƙĩƙa, ko da yaushe MOOC masu turbuɗo da kodi masu sauka, yana ƙaranci ta gane ta da zane-zane masu daidai. Ga wannan takardan, Munã halatar da ExpanRL, wata misãlin ƙarami zuwa ƙari mai ƙara wa tabbatarwa da ake ƙara (HRL) wa faɗaɗawa na zato cikin MOOOCs. Aka amfani da wani aminci na HRL-daraja biyu na zaɓen zura da faɗa ɗawa zato, ExpanRL yana mafi fasahan a gyarata kimar faɗaɗawa dõmin a sami zaɓen wata zato-yanzu a kan karatun masu saka kan fassarar faɗaɗawa. Kayan jarrabõyinmu na samun data na node 9 daga gaskiya MOOOCs ke nuna cewa ExpanRL ya sami mafiya girma kan hanyoyin wanda ke da shi kuma ya tsare aikin da za'a yi ƙidãya a cikin kewayi dabam-dabam.", 'sk': 'V okviru blaginje množičnih odprtih spletnih tečajev (MOOC) postanejo izobraževalne aplikacije, ki samodejno zagotavljajo izvenšolsko znanje uporabnikom MOOC, rastoče raziskovalne teme. Vendar pa je zaradi raznolikosti MOOC tečajev in hitrih posodobitev zahtevnejše iskanje ustreznega novega znanja za študente. V prispevku predstavljamo ExpanRL, model hierarhičnega ojačevanja (HRL) od konca do konca za razširitev koncepta v MOOC. Z uporabo dvostopenjskega mehanizma HRL za izbiro semen in širitev koncepta je ExpanRL bolj izvedljiv za prilagoditev strategije širitve in iskanje novih konceptov, ki temeljijo na povratnih informacijah študentov o rezultatih širitve. Naši eksperimenti na devetih novih naborih podatkov iz resničnih MOOC kažejo, da ExpanRL dosega znatne izboljšave v primerjavi z obstoječimi metodami in ohranja konkurenčno zmogljivost v različnih nastavitvah.', 'bo': 'MIOC ལག་ལེན་པ་ཚོའི་ནང་དུ་ཆེ་བའི་ཁ་ཕྱེད་ཀྱི་གློག་འཕྲིན་གྱི་མཐོ་རྐྱེན་ནང་དུ། ཡིན་ནའང་། MOOC གི་སྣེ་ཚོགས་དང་འཕྱུར་འགྲོས་ཀྱི་ཆ་འཕྲིན་དུ་འགྱུར་བ་སྐྱེན་ཐབས་ཤེས་འཇུག་བྱེད་པར་མཐོང འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་ཀྱིས་དུས་མཐའ་མཇུག་གི་མདུན་བསྡད་པའི་རྣམ་པ་ལ་མཐོང་ཐབས་ཤིག་སྟེ། འཇིག་སྣོད་གཉིས་ཀྱི་གནས་སྟངས་འདེམས་པ་དང་ཆ་རྐྱེན་ཚད་ཀྱི་ཐབས་ལམ་གཉིས་ཡོད་པ་ཞིག་ལག་ལེན་ཐབས་ཤིག་གནང་། ང་ཚོའི་བརྟག་པར་ཕྱོགས་ཚོགས་གསར་འགུལ་གྱི་གནད་སྡུད་འགྱུར་བ་ནས་MOOCs་དངོས་ཡོད་པའི་སྒེར་གྱིས་ExpanRL གྱིས་གནས་ཡུལ་ཐབས་ལམ་ལ་ཉེ་', 'jv': 'Nanging kapan tanggal gawe masalah Open online Nanging, ajeng-ajeng MOOC kowé nggawe sistem sing beraksi lan ijol-ijol sing gak nggawe barang nggawe layang-ijolan kanggo kowé nggawe salang ijol-ijolan kanggo sabêr-ijolan winih. In this paper, we present ExpanRL, an end-to-end model for design expantion in MOOCs. Ngawe ngilanggar alih iki-lawang HRL karo perusahaan winih lan kewasi nggawe barang kelas, ExpanRL dumadhi kapan kanggo nambah kebutaan pangan Awak dhéwé éntuk mulai dataset sing gak 9 (MOOCs) nggawe barang kelas ExpanRL supoyo barang nggawe barang nggawe sistem sing isih perusahaan karo sistem sing gak dhéwé lan hukum sistem sing berarti akeh perusahaan manut gak dhéwé.', 'he': 'בתוך השגחה של קורסים אונליין פתוחים מסיביים (MOOCs), היישומים לחינוך שמספקים באופן אוטומטי ידע מחוץ לתכנית למשתמשים MOOC הופכים לנושאים מחקרים עולים. עם זאת, מגוון קורסים MOOC ומעדכונים מהירים הופכים אותו לאתגר יותר למצוא ידע חדש מתאים לתלמידים. בעיתון הזה, אנו מציגים את ExpanRL, מודל של גייררכי התגבורה מסוף לסוף (HRL) למידל להרחיבה של מושג במועדון MOOCs. באמצעות מנגנון HRL בשני רמות של בחרת זרעים והפיתוח מושג, ExpanRL אפשרי יותר להתאים את אסטרטגיית ההפיצה כדי למצוא מושג חדש מבוסס על התגובה של התלמידים על תוצאות ההפיצה. הניסויים שלנו על תשע קבוצות נתונים חדשות ממועדונים אמיתיים מראים שExpanRL משיג שיפורים משמעותיים על שיטות קיימות ולשמור על ביצועים תחרותיים במסגרות שונות.'}
{'en': 'You May Like This Hotel Because... : Identifying Evidence for Explainable Recommendations', 'pt': 'Você pode gostar deste hotel porque ...: Identificando evidências para recomendações explicáveis', 'ar': 'قد يعجبك هذا الفندق لأن ...: تحديد الأدلة لتوصيات قابلة للتفسير', 'es': 'Puede que te guste este hotel porque...: Identificación de evidencia para recomendaciones explicables', 'fr': 'Vous aimerez peut-être cet hôtel parce que...\xa0: Identifier des preuves pour des recommandations explicables', 'ja': 'あなたはこのホテルが好きかもしれません。なぜなら... ：説明可能な推奨事項の証拠を特定するからです', 'zh': '或喜此店,以...: 为可解之议定证也', 'hi': 'आप इस होटल को पसंद कर सकते हैं क्योंकि ...: समझाने योग्य सिफारिशों के लिए सबूत की पहचान करना', 'ru': 'Вам может понравиться этот отель, потому что ...: Выявление доказательств для объяснимых рекомендаций', 'ga': "B'fhéidir gur mhaith leat an t-óstán seo mar gheall ar ...: Fianaise a Aithint le haghaidh Moltaí Inmhínithe", 'el': 'Μπορεί να σας αρέσει αυτό το ξενοδοχείο επειδή... Εντοπισμός αποδεικτικών στοιχείων για επεξηγημένες συστάσεις', 'hu': 'Lehet, hogy tetszik ez a hotel, mert ...: A magyarázható ajánlásokhoz szükséges bizonyítékok azonosítása', 'ka': 'თქვენ შეგიძლიათ ამ ჰოტელის მოყვაროთ, რადგან... Name', 'kk': 'Бұл отел сияқты көре аласыз, себебі... Түсінетін рекомендациялар үшін мәліметтерді анықтау', 'lt': 'Galite mėgsti šį viešbutį, nes... Identifying Evidence for Explainable Recommendations', 'mk': 'Може да ви се допадне овој хотел бидејќи... Идентификување на докази за објаснувачки препораки', 'ml': 'നിങ്ങള്\u200dക്ക് ഈ ഹോട്ടലിനെ ഇഷ്ടമാക്കാം, കാരണം... വിശദീകരിക്കുന്ന ശുദ്ധങ്ങള്\u200dക്കുള്ള തെളിവുകള്\u200d തിരിച്ചറിയുക', 'it': 'Ti potrebbe piacere questo hotel perché ...: Identificazione delle prove per le raccomandazioni esplicative', 'mn': 'Та энэ хотын дуртай байх учир нь ...: Тодорхойлж чадах зөвлөгөөний баталгаа тайлбарлах', 'no': 'Du kan likea denne hotelen fordi ...: Identifiserer dokument for utforskar anbefalingar', 'pl': 'Może spodoba ci się ten hotel, ponieważ...: Identyfikacja dowodów dla wyjaśnionych zaleceń', 'ms': 'Anda mungkin suka Hotel ini kerana ...: Identifying Evidence for Explainable Recommendations', 'ro': 'S-ar putea să vă placă acest hotel pentru că ...: Identificarea dovezilor pentru recomandări explicabile', 'sr': 'Možda vam se sviða ovaj hotel jer... Identifikacija dokaza za objašnjive preporuke', 'si': 'ඔයාට මේ හෝටල් කැමති වෙන්න පුළුවන් මොකද ...: Name', 'so': 'Hotelkaas waad noqon kartaa sababtoo ah... Aqoonsiga dalbashada', 'sv': 'Du kanske gillar detta hotell eftersom ...: Identifiera bevis för förklarande rekommendationer', 'ta': 'You May Like This Hotel Because ...:  விளக்ககூடிய பரிந்துரைகளுக்கான ஆதரவை அடையாளம்', 'ur': 'آپ اس ہٹل کو پسند کریں کیونکہ ...: واضح سفارش کے لئے دلیل پہچان رہے ہیں', 'mt': "Inti Tista 'Tixbaħ Dan il-lukanda Minħabba ...: Identifying Evidence for Explainable Recommendations", 'uz': 'Bu hotel kabi siz mumkin Chunki ...: Name', 'vi': 'Bạn có thể thích khách sạn này bởi vì... Tìm kiếm bằng chứng về lời khuyên giải thích', 'hr': 'Možete voljeti ovaj hotel jer... Identifikacija dokaza za objašnjive preporuke', 'bg': 'Този хотел може да ти хареса, защото... Идентифициране на доказателства за обясними препоръки', 'da': 'Du kan godt lide dette hotel fordi ...: Identificering af dokumentation for forklarbare henstillinger', 'nl': 'Misschien vind je dit hotel leuk omdat...: Identificeren van bewijsmateriaal voor verklarende aanbevelingen', 'fa': 'ممکنه از اين هتل خوشت بياد چون... شناسایی مدرک برای توصیه\u200cهای قابل توضیح', 'de': 'Vielleicht gefällt Ihnen dieses Hotel, weil ...: Identifizierung von Beweisen für erklärbare Empfehlungen', 'id': 'Anda mungkin suka Hotel ini karena ...: Identifikasi bukti untuk rekomendasi yang bisa dijelaskan', 'ko': '너는 아마 이 호텔을 좋아할 것이다. 왜냐하면설명 가능한 건의의 증거를 확정하다', 'sw': 'Unaweza kama Hoteli hii kwa sababu ...: Kutambua ushahidi kwa Mapendekezo yanayoeleweka', 'af': 'Jy mag Soos Hierdie Hotel Omdat ...: Name', 'sq': 'Mund ta pëlqesh këtë hotel sepse... Identifikimi i provave për rekomandime të shpjeguara', 'tr': 'You may Like This Hotel Because ...:  Explainable Recommendations for Identifying Evidence', 'am': "እንደዚህ ሆቴል ልትመስል ይችላል ስለ ...: ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Դուք կարող եք սիրել այս հյուրանոցը, որովհետև... Բացատրելի խորհուրդների ապացույցներ հայտնաբերելը', 'az': 'Siz bu Otlu sevirsiniz çünki ... Anlaşılabilir Tövsiyələr üçün dəlillər təsdiqləyici', 'bn': 'আপনি এই হোটেল পছন্দ করতে পারেন কারণ ...: ব্যাখ্যাত পরামর্শের জন্য প্রমাণ পরিচিতি', 'bs': 'Možete voljeti ovaj hotel jer... Identifikacija dokaza za objašnjive preporuke', 'et': 'Sulle võib see hotell meeldida, sest... Selgitatavate soovituste tõendite kindlakstegemine', 'ca': 'Pots agradar aquest hotel perquè... Identificar la prova de recomanacions explicables', 'cs': 'Možná se vám tento hotel líbí, protože...: Identifikace důkazů pro vysvětlitelná doporučení', 'fi': 'Saatat pitää tästä hotellista, koska... Selitettäviä suosituksia koskevien todisteiden tunnistaminen', 'sk': 'Ta hotel vam bo morda všeč, ker ... Opredelitev dokazov za pojasnljiva priporočila', 'he': 'אתה יכול לאהוב את המלון הזה כי... מזהה ראיות למלצות מסבירות', 'ha': 'Kana iya zama kamar wannan hotel... Banner page', 'jv': 'Kowe iso koyo Hotel iki Soalé ...: Personal settings', 'bo': 'ཁྱོད་ཀྱིས་འདི་ལྟ་བུ་ཡིན་པ་རྒྱུ་མཚན་ནི་་་ Explain Recommendations for Identifying Evidence'}
{'en': 'Explainable recommendation is a good way to improve user satisfaction. However, explainable recommendation in  dialogue  is challenging since it has to handle  natural language  as both input and output. To tackle the challenge, this paper proposes a novel and practical task to explain evidences in recommending hotels given vague requests expressed freely in  natural language . We decompose the process into two subtasks on hotel reviews : Evidence Identification and Evidence Explanation. The former predicts whether or not a sentence contains evidence that expresses why a given request is satisfied. The latter generates a  recommendation sentence  given a request and an  evidence sentence . In order to address these subtasks, we build an Evidence-based Explanation dataset, which is the largest  dataset  for explaining evidences in recommending hotels for vague requests. The experimental results demonstrate that the BERT model can find evidence sentences with respect to various vague requests and that the LSTM-based model can generate recommendation sentences.', 'ar': 'تعتبر التوصية القابلة للتفسير طريقة جيدة لتحسين رضا المستخدم. ومع ذلك ، فإن التوصية القابلة للتفسير في الحوار تمثل تحديًا نظرًا لأنه يتعين عليها التعامل مع اللغة الطبيعية كمدخلات ومخرجات. لمواجهة التحدي ، تقترح هذه الورقة مهمة جديدة وعملية لشرح الأدلة في التوصية بالفنادق بالنظر إلى الطلبات الغامضة التي يتم التعبير عنها بحرية بلغة طبيعية. نقسم العملية إلى مهمتين فرعيتين في مراجعات الفنادق: تحديد الأدلة وشرح الأدلة. يتنبأ الأول بما إذا كانت الجملة تحتوي على دليل يوضح سبب تلبية طلب معين أم لا. هذا الأخير يولد توصية الجملة بناء على طلب وحكم دليل. من أجل معالجة هذه المهام الفرعية ، قمنا ببناء مجموعة بيانات توضيحية مبنية على الأدلة ، وهي أكبر مجموعة بيانات لشرح الأدلة في التوصية بالفنادق للطلبات الغامضة. توضح النتائج التجريبية أن نموذج BERT يمكنه العثور على جمل أدلة فيما يتعلق بطلبات غامضة مختلفة وأن النموذج القائم على LSTM يمكن أن يولد جمل توصية.', 'fr': "Une recommandation explicable est un bon moyen d'améliorer la satisfaction des utilisateurs. Cependant, la recommandation explicable dans le dialogue est difficile car il doit gérer le langage naturel à la fois comme entrée et comme sortie. Pour relever ce défi, cet article propose une tâche nouvelle et pratique pour expliquer les preuves de la recommandation d'hôtels suite à des demandes vagues exprimées librement dans un langage naturel. Nous décomposons le processus en deux sous-tâches sur les évaluations d'hôtels\xa0: identification des preuves et explication des preuves. Le premier prédit si une phrase contient ou non des preuves qui expriment pourquoi une demande donnée est satisfaite. Ce dernier génère une phrase de recommandation en fonction d'une demande et d'une peine de preuve. Afin de répondre à ces sous-tâches, nous créons un jeu de données d'explication basé sur des preuves, qui est le plus grand ensemble de données pour expliquer les preuves dans la recommandation d'hôtels pour des demandes vagues. Les résultats expérimentaux démontrent que le modèle BERT peut trouver des phrases de preuve concernant diverses demandes vagues et que le modèle basé sur LSTM peut générer des phrases de recommandation.", 'pt': 'A recomendação explicável é uma boa maneira de melhorar a satisfação do usuário. No entanto, a recomendação explicável no diálogo é um desafio, pois precisa lidar com a linguagem natural como entrada e saída. Para enfrentar o desafio, este artigo propõe uma tarefa nova e prática para explicar evidências na recomendação de hotéis atendendo a solicitações vagas expressas livremente em linguagem natural. Decompomos o processo em duas subtarefas em avaliações de hotéis: Identificação de Evidências e Explicação de Evidências. O primeiro prevê se uma sentença contém ou não evidências que expressam por que um determinado pedido é satisfeito. Este último gera uma sentença de recomendação diante de um pedido e uma sentença de prova. Para abordar essas subtarefas, construímos um conjunto de dados de explicação baseada em evidências, que é o maior conjunto de dados para explicar evidências na recomendação de hotéis para solicitações vagas. Os resultados experimentais demonstram que o modelo BERT pode encontrar sentenças de evidência a respeito de várias solicitações vagas e que o modelo baseado em LSTM pode gerar sentenças de recomendação.', 'es': 'Una recomendación explicable es una buena forma de mejorar la satisfacción del usuario. Sin embargo, la recomendación explicable en el diálogo es un desafío, ya que tiene que manejar el lenguaje natural como entrada y salida. Para hacer frente al desafío, este artículo propone una tarea novedosa y práctica para explicar las evidencias en la recomendación de hoteles ante solicitudes vagas expresadas libremente en lenguaje natural. Descomponemos el proceso en dos subtareas sobre las revisiones de hoteles: Identificación de la evidencia y Explicación de la evidencia. El primero predice si una oración contiene o no evidencia que exprese por qué se satisface una solicitud dada. Este último genera una sentencia de recomendación dada una solicitud y una sentencia de prueba. Para abordar estas subtareas, creamos un conjunto de datos de Explicación basada en la evidencia, que es el conjunto de datos más grande para explicar las evidencias en la recomendación de hoteles para solicitudes vagas. Los resultados experimentales demuestran que el modelo BERT puede encontrar sentencias de evidencia con respecto a varias solicitudes vagas y que el modelo basado en LSTM puede generar oraciones de recomendación.', 'ja': '説明可能な推奨事項は、ユーザー満足度を向上させる良い方法です。 しかし、対話で説明可能な推奨は、入力と出力の両方として自然言語を扱わなければならないため、困難である。 この課題に取り組むために、自然言語で自由に表現される漠然とした要請を与えられたホテルを推奨する際の証拠を説明するための斬新で実用的な課題を提案する。 ホテルのレビューでは、エビデンス識別とエビデンスの説明という2つのサブタスクにプロセスを分解します。 前者は、文に与えられた要求が満たされる理由を表す証拠が含まれているか否かを予測する。 後者は要求文と証拠文に与えられた推奨文を生成する。 これらのサブタスクに対処するために、エビデンスベースの説明データセットを構築します。これは、あいまいなリクエストに対してホテルを推奨する際のエビデンスを説明するための最大のデータセットです。 実験結果は、BERTモデルが様々な曖昧な要求に関して証拠文を見つけることができ、LSTMベースのモデルが推奨文を生成することができることを示している。', 'zh': '说者,所以崇用户满意度之善术也。 然其言有挑战性,必输自然语言以处之也。 应对,本文发一项新颖实用的事务,以解释在以自然语言自由的模糊要求的事情推荐酒店的证据。 分解为酒店论者二子:证识证解。 前者占句与否给定请足之证也。 后生一给定请议句一证。 为此等务,结证数集,此为模糊请荐酒店时解释证最大数集也。 实验结果表明,BERT模能针诸模糊求证句,盖LSTM之模形可以成荐句也。', 'ru': 'Объяснимая рекомендация - хороший способ повысить удовлетворенность пользователей. Тем не менее, объяснимая рекомендация в диалоге является сложной, поскольку она должна обрабатывать естественный язык как входной, так и выходной. Для решения этой проблемы в настоящем документе предлагается новаторская и практическая задача по разъяснению доказательств при рекомендации гостиниц с учетом расплывчатых запросов, свободно выраженных на естественном языке. Мы декомпозируем процесс на две подзадачи по отзывам об отелях: «Идентификация доказательств» и «Объяснение доказательств». Первый предсказывает, содержит ли приговор доказательства, которые выражают, почему данная просьба удовлетворена. В последнем случае выносится рекомендательный приговор с учетом просьбы и доказательственный приговор. Для решения этих подзадач мы создаем набор данных «Объяснение на основе фактических данных», который является самым крупным набором данных для объяснения доказательств при рекомендации гостиниц для расплывчатых запросов. Экспериментальные результаты показывают, что модель BERT может находить доказательства предложений в отношении различных неопределенных запросов и что модель на основе LSTM может генерировать рекомендации предложений.', 'hi': 'समझा सिफारिश उपयोगकर्ता की संतुष्टि में सुधार करने का एक अच्छा तरीका है। हालांकि, संवाद में समझाने योग्य सिफारिश चुनौतीपूर्ण है क्योंकि इसे इनपुट और आउटपुट दोनों के रूप में प्राकृतिक भाषा को संभालना पड़ता है। चुनौती से निपटने के लिए, यह पेपर प्राकृतिक भाषा में स्वतंत्र रूप से व्यक्त किए गए अस्पष्ट अनुरोधों को देखते हुए होटलों की सिफारिश करने में सबूतों की व्याख्या करने के लिए एक उपन्यास और व्यावहारिक कार्य का प्रस्ताव करता है। हम प्रक्रिया को होटल समीक्षाओं पर दो उप-कार्यों में विघटित करते हैं: साक्ष्य पहचान और साक्ष्य स्पष्टीकरण। पूर्व भविष्यवाणी करता है कि एक वाक्य में सबूत शामिल हैं या नहीं जो व्यक्त करता है कि किसी दिए गए अनुरोध को क्यों संतुष्ट किया जाता है। उत्तरार्द्ध एक अनुरोध और एक सबूत वाक्य दिया एक सिफारिश वाक्य उत्पन्न करता है। इन उप-कार्यों को संबोधित करने के लिए, हम एक साक्ष्य-आधारित स्पष्टीकरण डेटासेट का निर्माण करते हैं, जो अस्पष्ट अनुरोधों के लिए होटलों की सिफारिश करने में सबूतों की व्याख्या करने के लिए सबसे बड़ा डेटासेट है। प्रयोगात्मक परिणाम दर्शाते हैं कि BERT मॉडल विभिन्न अस्पष्ट अनुरोधों के संबंध में सबूत वाक्यों को पा सकता है और यह कि LSTM-आधारित मॉडल सिफारिश वाक्य उत्पन्न कर सकता है।', 'ga': 'Is bealach maith é moladh inmhínithe chun sástacht úsáideoirí a fheabhsú. Mar sin féin, tá sé dúshlánach moladh so-mhínithe a thabhairt san idirphlé toisc go gcaithfidh sé teanga nádúrtha a láimhseáil mar ionchur agus aschur. Chun dul i ngleic leis an dúshlán, molann an páipéar seo tasc nua agus praiticiúil chun fianaise a mhíniú maidir le hóstáin a mholadh iarrataí doiléir a chuirtear in iúl go saor i dteanga nádúrtha. Déanaimid an próiseas a dhianscaoileadh ina dhá fhothasc ar athbhreithnithe óstán: Aithint Fianaise agus Míniú Fianaise. Déanann an chéad cheann a thuar cé acu an bhfuil nó nach bhfuil fianaise i bpianbhreith a chuireann in iúl cén fáth a gcomhlíontar iarratas ar leith. Gineann an dara ceann abairt mholta nuair a thugtar iarratas agus pianbhreith fianaise. Chun aghaidh a thabhairt ar na fotascanna seo, tógaimid tacar sonraí Mínithe atá Bunaithe ar Fhianaise, arb é an tacar sonraí is mó chun fianaise a mhíniú maidir le hóstáin a mholadh le haghaidh iarratais doiléire. Léiríonn na torthaí turgnamhacha gur féidir le samhail CRET abairtí fianaise a aimsiú maidir le hiarratais doiléire éagsúla agus gur féidir leis an tsamhail atá bunaithe ar LSTM abairtí molta a ghiniúint.', 'ka': 'გამოსახულებელი პროცემენტი არის საუკეთესო გზა, რომელიც გამოიყენებელი საკეთესო საკეთესო შესაძლებლობა. მაგრამ, დიალოგიში განახსნა შესაბამისი რემონეკცია უნდა გავაკეთოთ, რადგან ის უნდა გადაწყენოთ თავისუფალური ენათი, როგორც შესაბამისი და გამო ამ წიგნის გამოსახულებლად, ეს წიგნის პრომენტიკური და პრაქტიკური დავალება, რომელიც გამოსახულებელება ჰოტელის შესაძლებელებაში გამოსახულებელია, რომელიც სახულო წიგნის თავი ჩვენ პროცესი ორი საკუთარი პროცესი ჰოტელური განსხვავებაში გადაწყენებთ: საკუთარი იდენტიფიკაცია და საკუთარი განსხვავება. პირველი წარმოდგენა თუ არა თუ არა წარმოდგენა წარმოდგენება, რომელიც გამოსახულებს რატომ მინდგენებული წარმოდგენა. შემდეგ შექმნა მოწყობილობა, რომელიც მოთხოვნილია და მოწყობილობა. ამ საკუთარი საკუთარი შესახებ, ჩვენ ვაკეთებთ საკუთარი საკუთარი საკუთარი მონაცემების შესახებ, რომელიც უფრო დიდი მონაცემების საკუთარი საკუთარი განახსენება ჰოტელის შესახებ ექსპერიმენტიური შედეგები აჩვენებენ, რომ BERT მოდელის შესაძლებელია განსხვავებული განსხვავებული მოთხოვრებისთვის წარმოდგენების შესახებ და რომ LSTM-ის მოდელის შესაძლებელია მოწყობ', 'hu': 'A magyarázható ajánlás jó módja a felhasználók elégedettségének javítására. Azonban a párbeszédben megmagyarázható ajánlás kihívást jelent, mivel a természetes nyelvet mind bemenetként, mind kimenetként kell kezelnie. A kihívás megoldása érdekében ez a tanulmány egy új és gyakorlati feladatot javasol, amely magyarázza a szállodák ajánlásának bizonyítékait, amelyek a természetes nyelven szabadon kifejezett homályos kéréseket adnak. A folyamatot két részfeladatra bontjuk fel a szállodai értékeléseken: a bizonyítékok azonosítása és a bizonyítékok magyarázata. Az előbbi előrejelzi, hogy egy mondat tartalmaz-e olyan bizonyítékot, amely kifejezi, hogy egy adott kérelem miért teljesül. Ez utóbbi ajánlási ítéletet hoz létre egy kérelem és egy bizonyítéki ítéletet. Ezeknek az alcsoportoknak a kezelése érdekében bizonyítékokon alapuló magyarázat adatkészletet építünk, amely a legnagyobb adatkészlet a bizonyítékok elmagyarázására, amikor homályos kérésekre szállodákat ajánlunk. A kísérleti eredmények azt mutatják, hogy a BERT modell bizonyítékokat talál különböző homályos kérésekre vonatkozóan, és hogy az LSTM alapú modell ajánlási mondatokat generál.', 'el': 'Η επεξηγημένη σύσταση είναι ένας καλός τρόπος για να βελτιωθεί η ικανοποίηση των χρηστών. Ωστόσο, η εξήγητη σύσταση στον διάλογο είναι πρόκληση, δεδομένου ότι πρέπει να χειριστεί τη φυσική γλώσσα τόσο ως εισαγωγή όσο και ως έξοδο. Για να αντιμετωπιστεί η πρόκληση, η παρούσα εργασία προτείνει ένα νέο και πρακτικό καθήκον για την επεξήγηση αποδεικτικών στοιχείων για την σύσταση ξενοδοχείων με ασαφή αιτήματα που εκφράζονται ελεύθερα στη φυσική γλώσσα. Χωρίζουμε τη διαδικασία σε δύο δευτερεύουσες εργασίες για τις κριτικές ξενοδοχείων: Αναγνώριση αποδεικτικών στοιχείων και Επεξήγηση αποδεικτικών στοιχείων. Η πρώτη προβλέπει εάν μια ποινή περιέχει ή όχι αποδεικτικά στοιχεία που εκφράζουν τον λόγο για τον οποίο ικανοποιείται ένα συγκεκριμένο αίτημα. Η τελευταία παράγει πρόταση σύστασης με αίτηση και ποινή αποδεικτικών στοιχείων. Προκειμένου να αντιμετωπιστούν αυτές οι δευτερεύουσες εργασίες, κατασκευάζουμε ένα σύνολο δεδομένων επεξήγησης βάσει αποδεικτικών στοιχείων, το οποίο είναι το μεγαλύτερο σύνολο δεδομένων για την επεξήγηση αποδεικτικών στοιχείων για την σύσταση ξενοδοχείων για ασαφή αιτήματα. Τα πειραματικά αποτελέσματα καταδεικνύουν ότι το μοντέλο BERT μπορεί να βρει αποδεικτικές προτάσεις σε σχέση με διάφορα αόριστα αιτήματα και ότι το μοντέλο που βασίζεται στην LSTM μπορεί να δημιουργήσει προτάσεις συστάσεων.', 'it': "Una raccomandazione spiegabile è un buon modo per migliorare la soddisfazione degli utenti. Tuttavia, una raccomandazione spiegabile nel dialogo è difficile poiché deve gestire il linguaggio naturale sia come input che output. Per affrontare la sfida, questo lavoro propone un compito nuovo e pratico per spiegare le evidenze nel raccomandare alberghi a richieste vaghe espresse liberamente in linguaggio naturale. Scomponiamo il processo in due sottoattività sulle recensioni degli hotel: Identificazione delle prove e Spiegazione delle prove. Il primo prevede se una frase contiene o meno prove che esprimono il motivo per cui una determinata richiesta è soddisfatta. Quest'ultimo genera una sentenza di raccomandazione data una richiesta e una sentenza di prova. Per rispondere a queste sottoattività, costruiamo un set di dati di spiegazione basato su evidenze, che è il più grande set di dati per spiegare le prove nel raccomandare hotel per richieste vaghe. I risultati sperimentali dimostrano che il modello BERT può trovare frasi di prova rispetto a varie richieste vaghe e che il modello basato su LSTM può generare frasi di raccomandazione.", 'kk': 'Пайдаланушының жақсы жақсы түсініктемесі. Бірақ диалогта түсініктіретін рекомендациялары, өйткені бұл табиғи тілді енгізу мен шығыс ретінде әсер ету керек. Бұл қағаз өзгерту үшін романдық және практикалық тапсырманы таңдау үшін отелерді таңдау үшін тапсырмаларды таңдау үшін тапсырмаларды таңдау үшін таңдайды. Біз процесті хотелдердің редакцияларында екі субсайтына бөліп тастадық: құжаттар идентификациясы мен құжаттар түсініктемесі. Бұрынғы сұраныс келтірілген сұраныстың қажеттілігін белгілейтінін көрсетеді. Соңғы сұрақ мен мәліметті келтірілген сұрақ құрылады. Бұл ішкі сұрақтарды таңдау үшін, біз бағытты таңдау деректер жиынын құрамыз. Бұл - бағытты сұрақтар үшін хотелдерді таңдау үшін ең үлкен деректер жиыны. Тәжірибелі нәтижелер BERT үлгісінің әртүрлі түрлі сұрауларға қатынау үшін мәліметтерді таба алады және LSTM негіздеген үлгісінің мәліметтерді жасай алады.', 'ml': 'വ്യക്തമായ ശുപാര്\u200dശ ഉപയോക്താവിന്റെ തൃപ്തിപ്പെടുത്താന്\u200d നല്ല വഴിയാണ്. എന്നാലും ഡയലോഗില്\u200d വിശദീകരിക്കാന്\u200d കഴിയാത്ത ശുപാര്\u200dശ ചോദ്യം ചോദ്യം ചെയ്യുന്നു. അത് സ്വാഭാവികമായ ഭാഷ പ് ഈ ചോദ്യത്തെ എതിര്\u200dക്കാന്\u200d ഈ പത്രത്തില്\u200d സ്വാഭാവിക ഭാഷയില്\u200d സ്വാഭാവികമായി പ്രസ്താവിക്കുന്ന ഹോട്ടലുകളില്\u200d വ്യക്തമായി വിശ ഹോട്ടല്\u200d പരിചയപ്പെടുത്തുന്ന രണ്ട് സബ്ട്ടേഷനിലേക്ക് നമ്മള്\u200d പ്രക്രിയയെ കുറിച്ച് വെക്കുന്നു. തെളിവുകള്\u200d തിര ഒരു വാക്കില്\u200d തെളിവുകള്\u200d ഉണ്ടോ എന്ന് പ്രഖ്യാപിക്കുന്നു അവസാനം ഒരു ആവശ്യപ്പെട്ട വാക്കും തെളിവുകളുടെ വാക്കും കൊണ്ട് ഒരു ശുപാര്\u200dശ വാക്ക് ഉണ്ടാക്കുന്ന ഈ സബ്ട്ടാസുകളെ വിശദീകരിക്കാന്\u200d വേണ്ടി നാം തെളിവുകള്\u200d അടിസ്ഥാനമായ ഒരു എക്സ്പ്ലാനേഷന്\u200d ഡാറ്റാസെറ്റ് നിര്\u200dമ്മിക്കുന്നു. അത് തെളി പരീക്ഷണത്തിന്റെ ഫലം കാണിച്ചു കൊണ്ടിരിക്കുന്നു ബെര്\u200dട്ടി മോഡല്\u200d തെളിവുകളുടെ വാക്കുകള്\u200d കണ്ടെത്താന്\u200d സാധിക്കുന്നു. വ്യത്യസ', 'lt': 'Paaiškinama rekomendacija yra tinkamas būdas pagerinti vartotojų pasitenkinimą. However, explainable recommendation in dialogue is challenging since it has to handle natural language as both input and output.  Siekiant išspręsti šį uždavinį, šiame dokumente siūloma nauja ir praktinė užduotis paaiškinti įrodymus rekomenduojant viešbučius, atsižvelgiant į neaiškius laisvai natūraliomis kalbomis išreikštus prašymus. Šis procesas suskirstomas į dvi viešbučių apklausas: įrodymų identifikavimą ir įrodymų paaiškinimą. The former predicts whether or not a sentence contains evidence that expresses why a given request is satisfied.  Pastaruoju atveju pateikiamas rekomendacinis sakinys, kuriame pateikiamas prašymas ir įrodymai. Siekiant išspręsti šiuos paklausimus, sukuriame įrodymais pagrįstą paaiškinimų duomenų rinkinį, kuris yra didžiausias duomenų rinkinys, kuriame paaiškinami įrodymai rekomenduojant viešbučius neapibrėžtiems prašymams. Eksperimentiniai rezultatai rodo, kad BERT modelis gali rasti įrodymų sakinius dėl įvairių neaiškų prašymų ir kad LSTM pagrįstas modelis gali sukelti rekomendacinius sakinius.', 'mk': 'Објаснувачката препорака е добар начин да се подобри задоволството на корисникот. Сепак, објаснувачката препорака во дијалогот е предизвикувачка бидејќи мора да се справи со природниот јазик како влез и излез. За да се справи со предизвикот, овој весник предлага нова и практична задача за објаснување на доказите во препорачувањето на хотелите со оглед на нејасните барања изразени слободно на природен јазик. Го разделуваме процесот во две потпрашања за рецензиите на хотелот: идентификација на доказите и објаснување на доказите. The former predicts whether or not a sentence contains evidence that expresses why a given request is satisfied.  Втората генерира реченица за препорака со барање и доказна реченица. In order to address these subtasks, we build an Evidence-based Explanation dataset, which is the largest dataset for explaining evidences in recommending hotels for vague requests.  Експерименталните резултати покажуваат дека моделот БЕРТ може да најде доказни реченици во врска со различни нејасни барања и дека моделот базиран на ЛСТМ може да генерира реченици за препорака.', 'ms': 'Rekomendasi yang boleh dijelaskan adalah cara yang baik untuk meningkatkan kepuasan pengguna. However, explainable recommendation in dialogue is challenging since it has to handle natural language as both input and output.  Untuk menghadapi cabaran, kertas ini mengusulkan tugas baru dan praktik untuk menjelaskan bukti dalam menyarankan hotel diberikan permintaan yang tidak jelas yang diberikan secara bebas dalam bahasa alam. Kami pecahkan prosesnya menjadi dua subtasks pada ulasan hotel: Identifikasi Bukti dan Penjelasan Bukti. Pertama meramalkan sama ada kalimat mengandungi bukti yang mengekspresikan mengapa permintaan tertentu dipenuhi atau tidak. The latter generates a recommendation sentence given a request and an evidence sentence.  In order to address these subtasks, we build an Evidence-based Explanation dataset, which is the largest dataset for explaining evidences in recommending hotels for vague requests.  Hasil percubaan menunjukkan bahawa model BERT boleh mencari kalimat bukti berkaitan dengan beberapa permintaan yang tidak jelas dan bahawa model berdasarkan LSTM boleh menghasilkan kalimat rekomendasi.', 'mn': 'Тайлбарлах зөвлөгөө бол хэрэглэгчийн удирдлагааг сайжруулах сайн арга юм. Гэвч диалогт тайлбарлах боломжтой зөвлөгөө нь байгалийн хэлний оролцоо болон үр дүн болгох боломжтой. Сорилтыг зогсоохын тулд энэ цаас нь байгалийн хэл дээр чөлөөтэй илэрхийлж байгаа зохиол болон практикийн даалгаварыг тайлбарлах зорилготой. Бид энэ үйл явцыг хоёр давтамжтайгаар хоёр давтамжтайгаар хувааж, хоёр давтамжтайгаар хувааж, баталгааны тодорхойлолт. Өмнөх нь өгүүлбэр яагаад өгсөн хүсэл хангалттай байгааг илэрхийлж байгааг тодорхойлдог. Эцэст нь хүсэл болон баримт өгүүлбэр өгсөн зөвлөгөө бий болгодог. Эдгээр суурь шаардлагатай талаар бид баталгаатай тодорхойлолтын өгөгдлийн санг бүтээж байна. Энэ бол хамгийн том өгөгдлийн санг, хамгийн тодорхойлолтой шаардлагатай хотын суурь нутгийг тайлбарлах боломжтой. Эдгээр туршилтын үр дүнд БЕРТ загвар нь олон тодорхой хүсэлтэй холбоотой баримт өгүүлбэрийг олж чадна. LSTM-ын загвар нь зөвлөгөөний өгүүлбэрийг гаргаж чадна.', 'no': 'Forklarbart anbefaling er ein god måte å forbedra tilfredsstilling til brukaren. Men det er vanskeleg å forklare området i dialogen sidan det må handtera naturspråk som både inndata og utdata. For å løse utfordringen, foreslår denne papiret ein novel og praktisk oppgåve for å forklare evidentitet i tilrådd til hotellar gjeven ugyldig førespurnader uttrykt fritt i naturspråk. Vi dekomprimerer prosessen til to underspørsmål på hotelreviewer: Dokumentidentifikasjon og utklaring av dokument. Den tidlegare forventar om eit setning inneheld bevis som uttrykker korleis ein oppgitt førespurnad er tilfredsstilt. Den siste lager eit anbefalingssetjing gitt ein førespurnad og eit bevissetjing. For å handtera desse underspørsmålene, bygger vi eit dataset som er basert på Dokumentbasert utforsking, som er den største dataset for å forklare evidentitet i tilrådd til hotellar for ugyldig førespurnader. Den eksperimentelle resultatene viser at BERT-modellen kan finna beviselssetningar med respekt til ulike ugyldig førespurnader og at LSTM-basert modellen kan laga anbefalingssetningar.', 'pl': 'Wyjaśniona rekomendacja to dobry sposób na poprawę satysfakcji użytkowników. Jednak wytłumaczalne zalecenie w dialogu jest wyzwaniem, ponieważ musi obsługiwać język naturalny zarówno jako wejście, jak i wyjście. Aby sprostać temu wyzwaniu, niniejszy artykuł proponuje nowatorskie i praktyczne zadanie wyjaśniające dowody w rekomendowaniu hoteli podawanych niejasnych żądań wyrażonych swobodnie w języku naturalnym. Proces ten rozkładamy na dwa podzadania dotyczące recenzji hotelu: Identyfikacja dowodów i Wyjaśnienie dowodów. Pierwszy przewiduje, czy zdanie zawiera dowody wyrażające, dlaczego dany wniosek został spełniony. Ta ostatnia generuje wyrok rekomendacyjny z wnioskiem i wyrok dowodowy. Aby rozwiązać te podzadania, budujemy zbiór danych wyjaśniających oparty na dowodach, który jest największym zbiorem danych służącym do wyjaśniania dowodów w rekomendowaniu hoteli na niejasne wnioski. Wyniki eksperymentalne pokazują, że model BERT może znaleźć zdania dowodowe w odniesieniu do różnych niejasnych wniosków i że model oparty na LSTM może generować zdania rekomendacyjne.', 'mt': 'Explainable recommendation is a good way to improve user satisfaction.  However, explainable recommendation in dialogue is challenging since it has to handle natural language as both input and output.  Biex tiġi indirizzata l-isfida, dan id-dokument jipproponi kompitu ġdid u prattiku biex jiġu spjegati l-evidenzi fir-rakkomandazzjoni ta’ lukandi minħabba talbiet vagi espressi b’mod ħieles fil-lingwa naturali. Aħna niddekomponu l-proċess f’żewġ sottomistoqsijiet dwar ir-reviżjonijiet tal-lukandi: Identifikazzjoni tal-Evidenza u Spjegazzjoni tal-Evidenza. L-ewwel jipprevedi jekk sentenza tinkludix evidenza li tesprimi għaliex talba partikolari hija sodisfatta jew le. The latter generates a recommendation sentence given a request and an evidence sentence.  Sabiex nindirizzaw dawn is-sottomistoqsijiet, aħna nibnu sett ta’ dejta ta’ Spjegazzjoni bbażat fuq l-Evidenza, li huwa l-akbar sett ta’ dejta li jispjega l-evidenzi fir-rakkomandazzjoni ta’ lukandi għal talbiet vagi. Ir-riżultati sperimentali juru li l-mudell BERT jista’ jsib sentenzi ta’ evidenza fir-rigward ta’ diversi talbiet vagi u li l-mudell ibbażat fuq LSTM jista’ jiġġenera sentenzi ta’ rakkomandazzjoni.', 'ro': 'Recomandarea explicabilă este o modalitate bună de a îmbunătăți satisfacția utilizatorilor. Cu toate acestea, recomandarea explicabilă în dialog este o provocare, deoarece trebuie să trateze limbajul natural atât ca intrare, cât și ca ieșire. Pentru a face față provocării, această lucrare propune o sarcină nouă și practică de explicare a dovezilor în recomandarea hotelurilor primite cereri vagi exprimate liber în limbaj natural. Descompunem procesul în două subactivităţi pe recenziile hotelului: identificarea probelor şi explicarea probelor. Primul prezice dacă o propoziție conține sau nu dovezi care exprimă motivul pentru care o anumită cerere este satisfăcută. Aceasta din urmă generează o sentință de recomandare dată o cerere și o sentință de probă. Pentru a aborda aceste subactivități, construim un set de date de explicații bazat pe dovezi, care este cel mai mare set de date pentru explicarea dovezilor în recomandarea hotelurilor pentru solicitări vagi. Rezultatele experimentale demonstrează că modelul BERT poate găsi propoziții de probă cu privire la diferite cereri vagi și că modelul bazat pe LSTM poate genera propoziții de recomandare.', 'sr': 'Objašnjiva preporuka je dobar način da poboljšamo zadovoljstvo korisnika. Međutim, objašnjavajuća preporuka u dijalogu je izazovna jer mora rešiti prirodni jezik kao ulaz i izlaz. Da bi se riješio izazov, ovaj papir predlaže roman i praktični zadatak da objasni dokaze u preporukama hotela koji su dobili nespretne zahteve koje su slobodno izražene na prirodnom jeziku. Rasporedimo proces u dva podataka u hotelskim pregledima: Identifikacija dokaza i objašnjenje dokaza. Bivši predviđaju da li rečenica sadrži ili ne dokaze koji izražavaju zašto je određena zahteva zadovoljana. Posljednja stvara preporuku za zahtev i kaznu za dokaze. Da bi se obratili ovim podacima, izgradili smo komplet podataka na osnovu dokaza, koji je najveći komplet podataka za objašnjavanje dokaza u preporukama hotela za nesreće zahteve. Eksperimentalni rezultati pokazuju da model BERT može pronaći dokaze u pogledu različitih nespretnih zahteva i da model na LSTM-u može stvoriti preporuke.', 'sv': 'Förklarbara rekommendationer är ett bra sätt att förbättra användarnöjdheten. Förklarbara rekommendationer i dialog är dock utmanande eftersom det måste hantera naturligt språk som både input och output. För att ta itu med utmaningen föreslår denna uppsats en ny och praktisk uppgift att förklara bevis för att rekommendera hotell som fått vaga önskemål uttryckta fritt i naturligt språk. Vi delar upp processen i två underuppgifter på hotellrecensioner: Bevis identifiering och Bevisförklaring. Den förstnämnda förutspår om en dom innehåller bevis som uttrycker varför en given begäran är tillfredsställd eller inte. Den senare genererar en rekommendationsdom med en begäran och en bevisdom. För att ta itu med dessa underuppgifter bygger vi ett Evidensbaserad Förklaringsdataset, som är den största datauppsättningen för att förklara bevis för att rekommendera hotell för vaga förfrågningar. De experimentella resultaten visar att BERT-modellen kan hitta bevisuppgifter med avseende på olika vaga förfrågningar och att den LSTM-baserade modellen kan generera rekommendationsuppgifter.', 'so': "Talo-bixinta caddeyn waa hab wanaagsan in uu horumariyo heshiiska isticmaalaha. Si kastaba ha ahaatee talo faa'iido ah oo ku saabsan dialogue waa dhibaato, sababtoo ah waa in ay u baahan tahay in luqada dabiicadda ah u maamulo sida input iyo soo bixinta. Si uu u qabsado dhibaatada, warqaddaas wuxuu u soo jeedaa shaqada warqadda iyo tababar leh si uu ugu caddeeyo caddeynta in lagu talo diro hoteelada la siiyo codsiyada si xor ah oo lagu bixiyo afka dabiicadda ah. Waxaannu koobnaynaa baaritaanka hoteelka labada shaqo oo ku qoran baaritaanka: Aqoonsiga iyo bandhigyada caddeynta. Wixii hore uu soo sheegay in uu ku qoro qoraal uu ku jiro caddeyn ku qoran sababta codsiga la siiyo. Qofka dambe wuxuu soo saaraa go'a an la taliyo oo lagu siiyo codsi iyo go'aan caddeyn. Si aad u baahan karto samooyinkaas, waxaynu dhisnaa sawir ku saabsan caddeynta, taas oo ah sawirada ugu weyn, si loo caddeeyo caddeynta in lagu talo diro hoteelada si aad u weydiisato. Imtixaanka waxaa ka muuqda in modelka BERT uu heli karo imtixaan ku saabsan codsiga kala duduwan iyo in muusikada LSTM ku saleysan uu soo saari karo go'dooyin talo ah.", 'ta': 'விளக்கமான பரிந்துரைகள் பயனர் திருப்தியை மேம்படுத்த ஒரு நல்ல வழி. ஆனால், உரையாடலில் விளக்கமுடியாத பரிந்துரைகள் சவால் செய்கிறது, ஏனெனில் அது இயல்பான மொழியை உள்ளீடு மற்றும் வ சவாலை எதிர்பார்க்க, இந்த தாள் ஒரு புதிய மற்றும் செயல் செய்தி தெளிவுபடுத்தும் விளக்கும் தெளிவான வேண்டும் என்பதை இயற்க நாம் செயல்பாட்டை ஹோட்டல் முன்னோட்டத்தில் இரண்டு துணை பணிகளுக்கு குறைவாக்குகிறோம்: தெளிவான அடையாளம் மற்றும்  கொடுக்கப்பட்ட கோரிக்கையை ஏன் திருப்தியடைந்தது என்று கூறும் முந்தைய வாக்கியத்தில் உள்ளதா அல்லது இல் பின்வரும் ஒரு கோரிக்கையும் ஒரு தெளிவான வாக்கியத்தையும் கொடுக்கப்பட்ட பரிந்துரையான வாக் இந்த உப பணிகளை முகவரிப்பதற்கு, நாம் ஒரு தெளிவான வெளிப்பாட்டு தகவல் அமைப்பை உருவாக்குகிறோம், இது வெளிப்படையான கோரிக்கைகளுக்கு தெளிவ The experimental results demonstrate that the BERT model can find evidence sentences with respect to various vague requests and that the LSTM-based model can generate recommendation sentences.', 'si': 'ප්\u200dරශ්නය කරන්න පුළුවන් ප්\u200dරශ්නයක් තමයි පාවිච්චි සතුටු වැඩ කරන හොඳ විදියක්. නමුත්, සංවාදයේ පැහැදිලි ප්\u200dරශ්නය කරන්න පුළුවන් ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරන්න පුළුවන් සංවාදයේ ප අභ්\u200dයානය වෙනුවෙන්, මේ පත්තු ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා ස්වාභාවික භාෂාත්මක විශ්වාස කරන්න හෝටල් වල ප්\u200dරශ අපි මේ ප්\u200dරක්\u200dරියාව හෝටල් පරීක්ෂණාවල් දෙකක් විතරයි: සාක්ෂි පරීක්ෂණය සහ සාක්ෂි පරීක්ෂණය. මුලින් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා කියලා ප්\u200dරශ්නයක් තියෙනවා කියලා ප්\u200dරශ්නයක් තියෙනවා ක අන්තිම ප්\u200dරශ්නයක් සහ සාක්ෂි වචනයක් දෙන්න ප්\u200dරශ්නයක් නිර්මාණය කරනවා. මේ විශ්වාස කරගන්න, අපි සාක්ෂික විස්තරණ දත්ත සෙට් එකක් හදන්න, ඒක තමයි විශාල දත්ත සෙට් විස්තර කරන්න පුළුවන් දත්ත සැට. පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ BERT මොඩල් එක්ක සාක්ෂික වාක්ෂා හොයාගන්න පුළුවන් විවිධ විශ්වාස', 'ur': 'کھول کھول دینے والی سفارش ایک اچھا طریقہ ہے کہ کارساز کی خوشنودی بہتر کرے۔ However, explainable recommendation in dialog is challenging since it has to handle natural language as both input and output. چلنے کے لئے یہ کاغذ ایک روانی اور عمدہ کام کی پیشنهاد کرتا ہے کہ ہٹل کو سفارش کرنے کے لئے واضح نشانیاں بیان کریں جن کے ذریعے غیر واضح خواہشوں کو طبیعی زبان میں آزاد طور پر بیان کیا جاتا ہے. ہم نے اس پروسس کو ہٹل روشن کے بارے میں دو سوٹسس میں تقسیم کردیا: دلیل شناسایی اور دلیل واضح. اس سے پہلے ایک بات کی تصدیق کرتا ہے کہ کوئی دلیل ہے یا نہ جس کی تصدیق کرتی ہے پیچھے ایک سفارش فیصلہ پیدا کرتا ہے جو ایک سفارش اور ایک دلیل فیصلہ دی جاتی ہے۔ یہ سپٹسسٹوں کے بارے میں ہم ایک دلیل واضح تحفظ ڈیٹسٹ بناتے ہیں، جو بہت بڑی ڈیٹسٹ ہے کہ ہٹل کو بغیر بغیر خواہشوں کے لئے نشانیاں بیان کرنے کے لئے نشانیاں سفارش کرنے کے لئے۔ آزمائش کے نتائج دکھاتے ہیں کہ BERT موڈل مختلف غیر غیر معلومات کے ساتھ گواہی دینے کے لئے گواہی دینے کے قابل ہے اور یہ کہ LSTM بنیاد موڈل مطالبہ کرنے کے قابل ہے.', 'vi': 'Giải thích được lời khuyên là cách tốt để làm người dùng hài lòng. Tuy nhiên, lời khuyên trong cuộc đối thoại có thể giải thích khó khăn vì nó phải dùng ngôn ngữ tự nhiên như cả nhập lẫn xuất. Để giải quyết thử thách, bài báo này đề xuất một nhiệm vụ mới và thực tế để giải thích bằng chứng khi đề nghị khách sạn với những yêu cầu mơ hồ được bộc lộ tự do trong ngôn ngữ tự nhiên. Chúng tôi phân hủy quá trình làm hai chi tiết về đánh giá khách sạn: xác nhận chứng cứ và Giải thích bằng chứng. Câu trước tiên tiên tiên đoán xem câu án có chứa bằng chứng nào chứng minh tại sao một yêu cầu được đáp ứng. Cái này đưa ra một lời đề nghị đưa ra một yêu cầu và một bản bằng chứng. Để giải quyết các vấn đề này, chúng tôi xây dựng một bộ dữ liệu Giải thích bằng chứng, nó là bộ dữ liệu lớn nhất để giải thích bằng chứng về việc đề nghị khách sạn. Các kết quả thử nghiệm đã chứng minh rằng mô hình của BERT có thể tìm thấy các câu chứng cứ liên quan đến nhiều yêu cầu mơ hồ khác nhau và rằng mô hình dựa trên LSD có thể tạo ra các lời khuyên.', 'uz': '@ info Lekin, muloqat oynasida aniqlash talab qilinadi, chunki u natijada tilni kiritish va natijasida boshqarish kerak. Бу саҳифа тажовузкорликни тижорат қилиш учун, қонун лойиҳа ва фаолият вазифасини бажариш учун қонун тилда кўрсатилган hotellarni тавсия этиш учун баёнотлар кўрсатади. We decompose the process into two subtasks on hotel reviews: Evidence Identification and Evidence Explanation.  @ info: whatsthis Name Bu tub vazifalarni boshqarish uchun biz tashqari talab qilingan hodisa soʻrov uchun hujjatlarni баён qilish uchun eng katta maʼlumot setini yaratimiz. Tekshirish natijalari BERT modeli turli taʼminlov soʻrovlari bilan hujjatlarni topishi mumkin va LSTM asosida modeli soʻzlarni yaratish mumkin.', 'da': 'Forklarelig anbefaling er en god måde at forbedre brugernes tilfredshed på. Men forklarelige anbefalinger i dialog er udfordrende, da det skal håndtere naturligt sprog som både input og output. For at imødegå denne udfordring foreslår denne artikel en ny og praktisk opgave at forklare beviser ved anbefaling af hoteller, der er givet vage ønsker udtrykt frit i naturligt sprog. Vi opdeler processen i to underopgaver på hotelanmeldelser: Bevis Identifikation og Bevis Forklaring. Førstnævnte forudsiger, om en sætning indeholder beviser, der udtrykker, hvorfor en given anmodning er opfyldt. Sidstnævnte giver anledning til en anbefalingsdom og en bevisdom. For at løse disse underopgaver bygger vi et Evidence-based Explanation datasæt, som er det største datasæt til forklaring af beviser i anbefaling af hoteller til vage forespørgsler. De eksperimentelle resultater viser, at BERT-modellen kan finde evidenssætninger i forhold til forskellige vage anmodninger, og at den LSTM-baserede model kan generere anbefalingssætninger.', 'nl': 'Verklaarbare aanbeveling is een goede manier om de gebruikerstevredenheid te verbeteren. Verklaarbare aanbeveling in dialoog is echter een uitdaging omdat het natuurlijke taal moet behandelen als input en output. Om deze uitdaging aan te pakken, stelt dit document een nieuwe en praktische taak voor om bewijsmateriaal uit te leggen in het aanbevelen van hotels die vage verzoeken ontvangen die vrij in natuurlijke taal worden uitgedrukt. We verdelen het proces in twee subtaken over hotelbeoordelingen: Bewijsidentificatie en Bewijsverklaring. Het eerste voorspelt of een zin al dan niet bewijs bevat waaruit blijkt waarom aan een bepaald verzoek wordt voldaan. Dit laatste genereert een aanbevelingsvonnis bij een verzoek en een bewijsvonnis. Om deze subtaken aan te pakken bouwen we een Evidence-based Explation dataset, de grootste dataset voor het uitleggen van bewijsmateriaal bij het aanbevelen van hotels voor vage verzoeken. De experimentele resultaten tonen aan dat het BERT-model bewijszinnen kan vinden met betrekking tot verschillende vage verzoeken en dat het LSTM-gebaseerde model aanbevelingszinnen kan genereren.', 'bg': 'Обясняемата препоръка е добър начин за подобряване на удовлетвореността на потребителите. Обясняемите препоръки в диалога обаче са предизвикателство, тъй като трябва да се справят с естествения език както като вход, така и като изход. За да се справи с предизвикателството, настоящата статия предлага нова и практическа задача да се обяснят доказателствата при препоръчването на хотели на неясни искания, изразени свободно на естествен език. Разлагаме процеса на две подзадачи на хотелските прегледи: Идентификация на доказателства и Обяснение на доказателства. Първият прогнозира дали дадено изречение съдържа доказателства, които изразяват защо дадено искане е удовлетворено. Последният генерира препоръка за постановяване на искане и доказателство. За да отговорим на тези подзадачи, изграждаме набор от данни за обяснение, основан на доказателства, който е най-големият набор от данни за обясняване на доказателства при препоръчване на хотели за неясни искания. Експерименталните резултати показват, че моделът BERT може да намери доказателствени изречения по отношение на различни неясни искания и че базираният на LSTM модел може да генерира препоръки изречения.', 'hr': 'Objašnjiva preporuka je dobar način za poboljšanje zadovoljstva korisnika. Međutim, objašnjavajuća preporuka u dijalogu je izazovna jer mora riješiti prirodni jezik kao ulaz i izlaz. Za rješavanje izazova ovaj novinar predlaže novi i praktični zadatak objašnjavanja dokaza u preporuki hotela koji su dobili nespretne zahtjeve slobodno izražene na prirodnom jeziku. Razdvojili smo proces u dvije podatke o hotelskim pregledima: Identifikacija dokaza i objašnjenje dokaza. Bivši predviđa da li rečenica sadrži ili ne dokaze koji izražavaju zašto je određena zahtjev zadovoljan. Posljednja stvara preporuku koja je dobila zahtjev i kaznu za dokaze. Da bismo se riješili ovim podacima, izgradili smo komplet podataka o objašnjenju na temelju dokaza, koji je najveći komplet podataka za objašnjavanje dokaza u preporukama hotela za nespretne zahtjeve. Eksperimentalni rezultati pokazuju da model BERT može pronaći dokaze u pogledu različitih nespretnih zahtjeva i da model na LSTM-u može stvoriti preporuke.', 'de': 'Erklärbare Empfehlungen sind eine gute Möglichkeit, die Benutzerzufriedenheit zu verbessern. Erklärbare Empfehlungen im Dialog sind jedoch eine Herausforderung, da sie natürliche Sprache sowohl als Input als auch Output behandeln müssen. Um diese Herausforderung anzugehen, schlägt dieses Papier eine neuartige und praktische Aufgabe vor, Beweise für die Empfehlung von Hotels zu erklären, die vage Anfragen, die frei in natürlicher Sprache ausgedrückt werden, erhalten. Wir zerlegen den Prozess in zwei Teilaufgaben zu Hotelbewertungen: Beweisidentifikation und Beweiserklärung. Ersteres sagt voraus, ob ein Satz Beweise enthält, die ausdrücken, warum ein gegebener Antrag erfüllt wird. Letzteres erzeugt einen Empfehlungssatz mit einem Antrag und einen Beweissatz. Um diese Teilaufgaben zu beantworten, bauen wir einen evidenzbasierten Erklärungsdatensatz auf, der der größte Datensatz zur Erklärung von Beweisen bei der Empfehlung von Hotels für vage Anfragen ist. Die experimentellen Ergebnisse zeigen, dass das BERT-Modell Beweissätze für verschiedene vage Anfragen finden kann und dass das LSTM-basierte Modell Empfehlungssätze generieren kann.', 'id': 'Rekomendasi yang bisa dijelaskan adalah cara yang baik untuk meningkatkan kepuasan pengguna. However, explainable recommendation in dialogue is challenging since it has to handle natural language as both input and output.  Untuk mengatasi tantangan ini, kertas ini mengusulkan tugas baru dan praktis untuk menjelaskan bukti dalam merekomendasikan hotel memberikan permintaan yang tidak jelas yang diberikan secara bebas dalam bahasa alam. Kami menghancurkan prosesnya menjadi dua subtasks pada resensi hotel: Identifikasi Bukti dan Penjelasan Bukti. Pertama memprediksi apakah kalimat mengandung bukti yang mengekspresikan mengapa permintaan tertentu puas. Yang terakhir menghasilkan kalimat rekomendasi diberikan permintaan dan kalimat bukti. Untuk mengatasi subtasks ini, kami membangun dataset penjelasan berdasarkan bukti, yang merupakan dataset terbesar untuk menjelaskan bukti dalam merekomendasikan hotel untuk permintaan yang tidak jelas. Hasil percobaan menunjukkan bahwa model BERT dapat menemukan kalimat bukti mengenai berbagai permintaan yang tidak jelas dan bahwa model berdasarkan LSTM dapat menghasilkan kalimat rekomendasi.', 'ko': '해석적 추천은 사용자 만족도를 높이는 좋은 방법이다.그러나 대화의 해석 가능한 추천은 도전적이다. 왜냐하면 자연 언어를 입력과 출력으로 동시에 처리해야 하기 때문이다.이 도전에 대응하기 위해 본고는 참신하고 실용적인 임무를 제시하고 자연 언어에서 모호한 요구를 자유롭게 표현하는 상황에서 호텔을 추천하는 증거를 설명한다.우리는 이 과정을 호텔 평론의 두 가지 임무인 증거 식별과 증거 해석으로 분해할 것이다.전자는 한 문장에 어떤 요구가 왜 만족을 얻었는지를 나타내는 증거가 포함되어 있는지 예측한다.후자는 청구와 증거 판결에 따라 추천 판결을 생성한다.이러한 하위 임무를 해결하기 위해 우리는 증거를 바탕으로 하는 해석 데이터 집합을 구축했다. 이것은 가장 큰 데이터 집합으로 모호한 요구에 대한 호텔 추천 증거를 해석하는 데 사용된다.실험 결과 BERT 모델은 다양한 모호한 요청에 대해 증거문을 찾을 수 있고, LSTM 모델을 바탕으로 추천문을 생성할 수 있다는 것이 밝혀졌다.', 'fa': 'پیشنهاد قابل توضیح راهی خوب برای بهترین راضی کاربر است. با این حال، پیشنهاد قابل توضیح در محاورۀ محاورۀ محاورۀ مشکل است، زیرا باید زبان طبیعی را به عنوان ورودی و نتیجه تحمل کند. برای حل چالش، این کاغذ یک وظیفه رمانی و کاری را پیشنهاد می\u200cکند تا نشانه\u200cهایی را توضیح دهد در پیشنهاد هتل\u200cهایی که درخواست\u200cهای ناشناس به زبان طبیعی آزاد نشان داده می\u200cشوند. ما این فرایند را به دو زیر سؤال در بررسی های هتل تقسیم می کنیم: شناسایی مدرک و توضیح مدرک. پیش\u200cبینی می\u200cکند که آیا یک جمله شامل شواهد است یا نه که نشان می\u200cدهد چرا یک طلب داده راضی شده است. آخرین یک مجازات پیشنهاد را تولید می\u200cکند که یک درخواست و یک مجازات مدرک داده شده است. برای حل این تحقیقات، ما مجموعه داده\u200cهای توضیح بر اساس مدرک ساختیم، که بزرگترین مجموعه داده\u200cهای توضیح نشانه\u200cهای توضیح در توصیح هتل برای درخواست\u200cهای غیرقابل است. نتایج آزمایشی نشان می\u200cدهد که مدل BERT می\u200cتواند جمله\u200cهای شواهد را با احترام درخواست\u200cهای مختلف متفاوت پیدا کند و مدل بنیاد LSTM می\u200cتواند جمله\u200cهای پیشنهاد را تولید کند.', 'sw': 'Mapendekezo yanayoelezea ni njia nzuri ya kuboresha heshima ya watumiaji. Hata hivyo, pendekezo lisiloeleweka katika mazungumzo ni changamoto kwani inapaswa kukabiliana na lugha ya asili kama vile input na matokeo. To tackle the challenge, this paper proposes a novel and practical task to explain evidences in recommending hotels given vague requests expressed freely in natural language.  Tunapunguza mchakato huo katika majukumu mawili kwenye tafiti ya hoteli: Utambulisho na Utafiti wa Uthibitisho. Tabiri za zamani ikiwa hukumu hiyo ina ushahidi unaoonyesha kwa nini ombi lililotolewa linaridhishwa. Matokeo ya mwisho yanatengeneza hukumu iliyotolewa na maombi na hukumu ya ushahidi. Ili kuzungumzia kazi hizi, tunajenga seti ya taarifa za Maelezo yenye ushahidi, ambayo ni seti kubwa zaidi ya data kwa ajili ya kuelezea ushahidi katika kupendekeza hoteli kwa ajili ya maombi yasiyo na maana. Matokeo ya majaribio yanaonyesha kuwa muundo wa BERT unaweza kupata hukumu za ushahidi kwa kuhusiana na maombi mbalimbali na kwamba muundo wa LSTM unaweza kutengeneza hukumu za mapendekezo.', 'tr': 'Aýatlyk maslahat ullanyşylaryň hoşa ýyşlygyny geliştirmek üçin gowy ýol. Ýöne, dialogda düşünjeli maslahatlar çözümlidir, sebäbi dogry dili hem girdi hem çykyş şeklinde çykmalydygy üçin. Sowçylygy çözmek üçin bu kagyz tebigy dilde boş görülen otelleri maslahat etmek üçin roman we praktik zady teklip edýär. We decompose the process into two subtasks on hotel reviews: Evidence Identification and Evidence Explanation. Öňki sözleriň näme üçin berilen islegiň hoşal edilýändigini a ýdýan ýa-da döwletleriň bardygyny tahmin edip bilýär. Soňky bir sorag we şahadet sözlemi berilen täsirli sözlemi döreýär. Bu subtasklary çözmek üçin, biz Evidence-based Explanation dataset in şa edýäris, which is the largest dataset for explaining evidences in recommending hotels for vague requests. Deneysel netijeler BERT modeliniň dürli wajyp isleýän çykyşlara maglumatlary tapyp biljekdigini görkeýär we LSTM tabanly modeliniň teklip sözlerini döredip biljekdigini görkeýär.', 'af': "Verduidelike aanbeveling is 'n goeie manier om gebruiker versadiging te verbeter. Maar, verduidelike aanbeveling in die dialoog is vanskeilig omdat dit moet natuurlike taal behandel as beelde invoer en uitvoer. Om die uitdrukking te probeer, stel hierdie papier 'n roman en praktiese taak voorstel om duidelikhede te verduidelik in die aanbevesting van hotels gegee ongelukkige versoeke wat vry in natuurlike taal uitgevoer word. Ons ontkoppel die proses in twee subtaske op hotel hersienings: Dokumente Identifikasie en Verduidelikheid. Die vorige voorskou of 'n seting bevat getuienis wat uitdruk waarom' n gegewe versoek versadig is versadig. Name In order to address these subtasks, we build an Evidence-based Explanation dataset, which is the largest dataset for explaining evidences in recommending hotels for vague requests. Die eksperimentale resultate bevestig dat die BERT-model kan bevestigheidsetinge met respek na verskillende vague versoeke vind en dat die LSTM-gebaseerde model kan genereer aanbevestigheidsetinge.", 'sq': 'Rekomendacioni i shpjeguar është një mënyrë e mirë për të përmirësuar kënaqësinë e përdoruesit. Megjithatë, rekomandimi i shpjegueshëm në dialog është sfidues pasi duhet të trajtojë gjuhën natyrore si hyrje dhe dalje. Për të trajtuar sfidën, ky dokument propozon një detyrë të re dhe praktike për të shpjeguar provat në rekomandimin e hoteleve duke dhënë kërkesa të paqarta shprehura lirisht në gjuhën natyrore. Ne e ndajmë procesin në dy nënpyetje në revistat e hotelit: identifikimi i provave dhe shpjegimi i provave. E para parashikon nëse një fjalim përmban apo jo prova që shprehin pse një kërkesë e caktuar është e kënaqur. Kjo e fundit gjeneron një dënim rekomandimi duke dhënë një kërkesë dhe një dënim provash. Me qëllim që të trajtojmë këto nënpyetje, ne ndërtojmë një set të dhënash të shpjegimit të bazuar në prova, i cili është grupi më i madh i të dhënash për shpjegimin e provave në rekomandimin e hoteleve për kërkesa të paqarta. Rezultatet eksperimentale tregojnë se modeli BERT mund të gjejë dënime provash lidhur me kërkesa të ndryshme të paqarta dhe se modeli bazuar në LSTM mund të gjenerojë dënime rekomandimi.', 'hy': "Բացատրելի խորհուրդը լավ միջոց է օգտագործողների բավարարման բարելավման համար: Այնուամենայնիվ, բացատրելի խորհուրդը խիստ դժվար է, քանի որ այն պետք է բնական լեզուն վերաբերի որպես ներմուծք և արտադրություն: Խնդիրը լուծելու համար այս թերթին առաջարկում է նոր և պրակտիկ խնդիր՝ բացատրելու ապացույցները հյուրանոցների խորհուրդ տալու համար, որոնք անորոշ խնդրանքներ են արտահայտվում ազատ բնական լեզվով: Մենք բաժանում ենք գործընթացը հյուրանոցի վերլուծությունների երկու ենթահարցերով' ապացույցների հայտնաբերումը և ապացույցների բացատրությունը: The former predicts whether or not a sentence contains evidence that expresses why a given request is satisfied.  Վերջինը ստեղծում է խորհուրդ նախադասություն, որը տալիս է խնդրանք և ապացույցի նախադասություն: Այս ենթահարցերի լուծման համար մենք կառուցում ենք ապացույցների վրա հիմնված բացատրության տվյալների համակարգ, որը ամենամեծ տվյալների համակարգը է ապացույցների բացատրելու համար հյուրանոցների խորհուրդ տալիս անորոշ խնդրանքների համար: Փորձարկվող արդյունքները ցույց են տալիս, որ BER-ի մոդելը կարող է գտնել ապացույցների նախադասություններ տարբեր անորոշ խնդրանքների հետ կապված և որ LSMT-ի հիմնված մոդելը կարող է ստեղծել խորհուրդ տալու նախադասություններ:", 'az': 'Yaxşılaşdırılabilir təbliğ istifadəçilərin razılığını artırmaq üçün yaxşı bir yoldur. Lakin, dialogda açıq-aydın təbliğ edilə bilən təbliğ çətindir, çünki bu təbiətli dili də giriş və çıxış kimi istifadə etmək lazımdır. Bu kağıt çəkilmək üçün, təbiətli dildə özgür dildə ifadə edilən müxtəlif istəklər təbliğ etmək üçün yeni və praktik bir işi təbliğ edir. Biz bu prosesini hotel nəzarətlərində iki dəyişikliyə parçalayırıq: kanıt kimlik və kanıt açıqlaması. Əvvəlki cümlənin niyə təmin edildiyini ifade edən dəlillər barəsində olmadığını təmin edir. Sonrakı bir istehza və dəlilik sözləri təbliğ edir. Bu dəyişiklikləri çəkmək üçün, biz dəlilik tabanlı açıqlama verilən verilən qurğu in şa edirik. Bu, çox böyük verilən qurğudur, həqiqətən də, çox çətin istəyirlər üçün otelleri təbliğ edir. Müxtəlif sonuçlar, BERT modeli müxtəlif müxtəlif istəklərə qarşı dəlil cümlələr tapır və LSTM-ə dayanan modellərin tədbir cümlələrini təşkil edə bilər.', 'bn': 'ব্যবহারকারীদের সন্তুষ্টি উন্নত করার একটি ভাল উপায়। তবে ডায়ালগে ব্যাখ্যা করার পরামর্শ চ্যালেঞ্জ করছে যেহেতু এটি প্রাকৃতিক ভাষাকে ইনপুট এবং আউটপুট হিসেবে স্ব এই চ্যালেঞ্জের মুখোমুখি হওয়ার জন্য এই পত্রিকাটি প্রাকৃতিক ভাষায় ব্যাখ্যা করার জন্য একটি উপন্যাস এবং বাস্তবতার কাজ প্রস্তাব আমরা এই প্রক্রিয়াকে হোটেল পর্যবেক্ষণের দুটি সাবট্যাকাজে কমিয়ে দিচ্ছি: প্রমাণ পরিচয় এবং প্রমাণ বিস্তারিত প্রমাণ। প্রাক্তন ভবিষ্যদ্বাণী করা হয়েছে যে একটি বাক্যের মধ্যে প্রমাণ রয়েছে কেন প্রদান করা অনুরোধ সন্তুষ্ট। পরবর্তীতে অনুরোধ এবং প্রমাণের বাক্য দিয়ে একটি সুপারিশ বাক্য তৈরি করে। এই সাবট্যাক্সের কথা বলার জন্য আমরা একটি প্রমাণ ভিত্তিক এক্সপ্ল্যানেশন ডাটাসেট তৈরি করি, যা বিভিন্ন অনুরোধের জন্য প্রমাণ ব্যাখ্যা করার জন্য পরীক্ষার ফলাফল দেখাচ্ছে যে বেরেটি মডেল বিভিন্ন ভিন্ন ভিত্তিক অনুরোধের প্রতি প্রমাণের বাক্য পাওয়া যাবে এবং এলএসএমভিত্তিক মডেল', 'bs': 'Objašnjiva preporuka je dobar način za poboljšanje zadovoljstva korisnika. Međutim, objašnjavajuća preporuka u dijalogu je izazovna jer mora riješiti prirodni jezik kao ulaz i izlaz. Da bi se riješio izazov, ovaj papir predlaže roman i praktični zadatak da objasni dokaze u preporuki hotela koji su dobili nespretne zahtjeve slobodno izražene na prirodnom jeziku. Rasporedimo proces u dva podataka u hotelskim pregledima: Identifikacija dokaza i objašnjenje dokaza. Bivši predviđaju da li rečenica sadrži ili ne dokaze koji izražavaju zašto je određena zahtjev zadovoljan. Posljednja stvara preporuku za zahtjev i kaznu za dokaze. Da bi se riješili ovim podacima, izgradili smo komplet podataka za objašnjenje na temelju dokaza, koji je najveći komplet podataka za objašnjavanje dokaza u preporuki hotela za nespretne zahtjeve. Eksperimentalni rezultati pokazuju da model BERT može pronaći dokaze u pogledu različitih nesvjesnih zahtjeva i da model na LSTM-u može stvoriti preporuke.', 'ca': "Una recomendació explicable és una bona manera de millorar la satisfacció dels usuaris. Però la recomendació explicable en el diàleg és difícil, ja que ha de tractar el llenguatge natural com a entrada i output. Per abordar el repte, aquest paper propon una tasca nova i pràctica per explicar les evidències en recomanar hotels donant peticions vagues expresses lliurament en llenguatge natural. Descomprim el procés en dues subterrànies en recenses d'hotel: Identificació de la prova i Explicació de la prova. La primera prediu si una frase conté o no evidències que expliquen per què una petición dada està satisfeta. Aquesta última genera una frase de recomendació dada una petición i una frase d'evidència. Per abordar aquestes subterrànies, construïm un conjunt de dades basat en Evidence Explanation, que és el conjunt de dades més gran per explicar les evidències en recomanar hotels a peticions vagues. Els resultats experimentals demostren que el model BERT pot trobar frases d'evidència en relació a diverses peticions vagues i que el model basat en LSTM pot generar frases de recomendació.", 'cs': 'Vysvětlitelné doporučení je dobrým způsobem, jak zlepšit spokojenost uživatelů. Vysvětlitelné doporučení v dialogu je však náročné, protože musí zvládnout přirozený jazyk jako vstup i výstup. K řešení této výzvy navrhuje tento příspěvek nový a praktický úkol vysvětlit důkazy v doporučování hotelů s vágními požadavky vyjádřenými volně v přirozeném jazyce. Proces rozložíme na dva dílčí úkoly ohledně hodnocení hotelů: Identifikace důkazů a Vysvětlení důkazů. První předpovídá, zda věta obsahuje důkazy, které vyjadřují, proč je daná žádost splněna. Tento rozsudek vytváří doporučující rozsudek s žádostí a rozsudek o důkazy. Za účelem řešení těchto dílčích úkolů vytváříme důkazní sadu, což je největší sada dat pro vysvětlení důkazů při doporučování hotelů pro vágní požadavky. Experimentální výsledky ukazují, že model BERT dokáže nalézt důkazní věty s ohledem na různé vágní požadavky a že model založený na LSTM může generovat doporučující věty.', 'am': 'የሚታወቅ ጉዳይ የተጠቃሚውን ደስታ ለማሻል መልካም መንገድ ነው፡፡ ነገር ግን የፍጥረት ቋንቋ እና ውጤት እንዲያቆም ግለፅ የሚያስፈልገው ጥያቄ ነው፡፡ To tackle the challenge, this paper proposes a novel and practical task to explain evidences in recommending hotels given vague requests expressed freely in natural language.  ፕሮጀክቱን በhotel ድምፅ ላይ ሁለት ደብዳቤዎችን እና ማስረጃ እና ማስረጃዎችን ለማግኘት እናደርጋለን፡፡ የቀድሞው ውይይት የፊደል ግንኙነት መክፈት ቢኖር ወይም እንዳይኖር ማስረጃ አለውና የተሰጠው ፈቃድ ለምን እንዲጠግብ ይናገራል፡፡ የመጨረሻው የጥያቄ ውይይት እና ማስረጃ ፍርድ መግለጫ ይፈልጋል፡፡ እነዚህን ደብዳቤዎች ለመቀላቀል እናስፈልጋለን፡፡ ፈተናው ውጤቶች የBERT ሞዴል በተለያዩ ጥያቄ ፈቃድ ላይ ማስረጃዎችን ማግኘት እንዲችል እና LSTM-based ሞዴል የተመሳሳይ ቃላትን እንዲወስድ ይችላል፡፡', 'et': 'Selgitatav soovitus on hea viis kasutajate rahulolu parandamiseks. Selgitatav soovitus dialoogis on aga keeruline, sest see peab käsitlema loomulikku keelt nii sisendi kui väljundina. Selle probleemi lahendamiseks pakutakse käesolevas dokumendis välja uudne ja praktiline ülesanne selgitada tõendeid hotellide soovitamisel, millele esitatakse vabalt looduslikus keeles väljendatud ebamääraseid taotlusi. Me jagame protsessi kaheks alamülesandeks hotellide ülevaates: tõendite identifitseerimine ja tõendite selgitamine. Esimene ennustab, kas lause sisaldab tõendeid, mis väljendavad, miks antud taotlus rahuldatakse. Viimane annab soovituskaitse taotluse kohta ja tõendikaristuse. Nende alamülesannete lahendamiseks ehitame tõendipõhise selgituse andmekogumi, mis on suurim andmekogum tõendite selgitamiseks hotellide ebamäärase päringu soovitamisel. Eksperimentaalsed tulemused näitavad, et BERT mudel võib leida tõendilauseid erinevate ebamäärasete taotluste kohta ja et LSTM-il põhinev mudel võib luua soovituslaused.', 'fi': 'Selitettävä suositus on hyvä tapa parantaa käyttäjien tyytyväisyyttä. Selitettävä suositus vuoropuhelussa on kuitenkin haastavaa, sillä siinä on käsiteltävä luonnollista kieltä sekä syötteenä että tuotoksena. Haasteen ratkaisemiseksi tässä asiakirjassa ehdotetaan uudenlaista ja käytännöllistä tehtävää selittää näyttöä siitä, että hotelleja suositellaan epämääräisille pyynnöille, jotka ilmaistaan vapaasti luonnollisella kielellä. Hajaamme prosessin kahteen alatehtävään hotelliarvioita varten: todisteiden tunnistus ja todisteiden selitys. Ensimmäinen ennustaa, sisältääkö lause todisteita siitä, miksi tietty pyyntö täytetään. Jälkimmäinen antaa suosituksen pyynnöstä ja todistuslauseen. Näiden alitehtävien ratkaisemiseksi rakennamme Evidence-based Explination datasetin, joka on suurin aineisto todisteiden selittämiseen hotellien suosittelemisessa epämääräisiin pyyntöihin. Kokeelliset tulokset osoittavat, että BERT-mallissa voidaan löytää näyttölauseita erilaisista epämääräisistä pyynnöistä ja että LSTM-pohjainen malli voi tuottaa suosituslauseita.', 'sk': 'Razložljiva priporočila so dober način za izboljšanje zadovoljstva uporabnikov. Vendar pa je pojasnljivo priporočilo v dialogu izziv, saj mora obravnavati naravni jezik kot vhod in izhod. Za reševanje tega izziva v prispevku predlaga novo in praktično nalogo, da se pojasnijo dokazi pri priporočanju hotelov z nejasnimi zahtevami, izraženimi prosto v naravnem jeziku. Postopek razdelimo na dve podnalogi pri pregledih hotelov: identifikacija dokazov in pojasnjevanje dokazov. Prvi predvideva, ali stavek vsebuje dokaze, ki izražajo, zakaj je določena zahteva izpolnjena. Slednji ustvari priporočilno kazen za zahtevo in dokazno kazen. Za reševanje teh podnalog zgradimo podatkovni nabor pojasnil, ki temelji na dokazih, ki je največji nabor podatkov za pojasnjevanje dokazov pri priporočanju hotelov za nejasne zahteve. Rezultati poskusov kažejo, da lahko BERT model najde dokazne stavke v zvezi z različnimi nejasnimi zahtevami in da lahko model, ki temelji na LSTM, ustvari priporočilne stavke.', 'jv': 'Awakdhéwé kesempatan sing apik kanggo nggawe aksi memperusahaan. politenessoffpolite"), and when there is a change ("assertivepoliteness Mbok nggawe perbudhakan kanggo mbelanga, kartu iki supaya batirmu kanggo nyeanye nggawe perintah lan pratike nggawe perintah kanggo nggawe dolanan ingkang dolanan sing nyimpen kanggo ngerasakno ora kebebasan winih. We decompse the operation to Two Subtasks on Hot Previews: Dokumen ID and Dokumen Expression. Laptop" and "Desktop Monday In order to Address this Subtasks, we rebuke an Dokumen-basa Open-Relation dataset, that is the maximum dataset for comprommunicating evencies in mending Hots for informations. Rejalaké sing paling nggambar barang nggambar daké model BERT iso nggawe sapa pertualangan karo panggayutan ingkang sampeyan sing paling nggap, lan model sing basa gambar LTT iso nggawe pertualangan.', 'ha': "Babu shawarar da ake bayyana shi, shi ne wata hanya mai kyau dõmin ya improve yardar da mai amfani da shi. A lokacin da aka buɗa buƙata a cikin zauren akwatin bayani, yana mai tsumma, don haka sai ya kamata ta yi amfani da harshen asimi kamar da za'a shiga da fitarwa. To, in motsa wa kimar, wannan takarda yana bukãtar da wani aikin nan da zai iya bayyana bayani a cikin buƙata hotels da aka buƙata requests wanda aka nuna da buɗari cikin harshen asiyya. Munã keɓa aikin da ke cikin taskõki biyu a kan hotel'ura: Yinin da ya gaba yana da shaidar a ƙunsa da shaidar da ke bayyana cewa don a yarda da tambayar da aka ba. Dakata na ƙãga wani cire da aka ba da wata so da wani cire bayani. Dõmin ka yi jãyayya ga wannan subaikin, muna samar da tsarin bayani na Explanation, wannan yana da mafi girma ga danna-bayani dõmin ya bayyana bayani ga masu buƙata cikin shawarar hotels da za'a buƙata tambayar buƙata. Matarin jarrabai sun nuna cewa misalin BERT za'a iya sãmun shaidar bayani game da tambayar, masu buƙata dabam'a, kuma da misalin a kan LSSM, ya iya ƙara cire masu shawara.", 'he': 'המלצה הסבירה היא דרך טובה לשפר את סיפוק המשתמשים. בכל אופן, המלצה המסבירה בדיאלוג היא מאתגרת מכיוון שהיא צריכה להתמודד עם שפה טבעית ככניסה וגם כניסה. כדי להתמודד עם האתגר, העיתון הזה מציע משימה רומנית ופרקטית להסביר ראיות בהמלצות מלונות בהתנו בקשות ערומות שהובילו בחינם בשפה טבעית. אנחנו מפרקים את התהליך לשני תוצאות על ביקורות במלון: זיהוי ראיות וסבר ראיות. The former predicts whether or not a sentence contains evidence that expresses why a given request is satisfied.  האחרון יוצר משפט ממלצה שנתנה בקשה ומשפט ראיות. כדי להתמודד עם השאלות האלה, אנו בונים קבוצת נתונים בהסבר מבוססת ראיות, שהיא קבוצת נתונים הגדולה ביותר להסביר ראיות בהמלצות מלונות לבקשות בלתי ברורות. תוצאות הניסויים מראות שהדוגמנית BERT יכולה למצוא משפטי ראיות בנוגע לבקשות ערומות שונות ושדוגמנית מבוססת LSTM יכולה ליצור משפטים ממלצות.', 'bo': 'གསལ་བཤད་བཏུབ་པའི་བསམ་བློ་གཏོང་ནི་སྤྱོད་མཁན་གྱི་བྱ་སྟངས་དགའ་ཕྱོགས་གཅིག་རེད། However, explainable recommendation in dialog is challenging since it has to handle natural language as both input and output. གདོང་ལེན་ཐབས་མེད་པར། ཤོག་བྱང་འདིས་གསར་གཏོང་དང་སྒྲུབ་གྱི་བྱ་འགུལ་ཞིག་ལ་རྟོགས་པ་ཁག་གནད་ཁོངས་གཏོང་རྒྱུ་དང་། We decompose the process into two subtasks on hotel reviews: Evidence Identification and Evidence Explanation. སྔོན་མའི་སྔོན་འཛིན་གྱིས་དམ་འཛུགས་བྱེད་པའི་རྗེས་ཐོག་ཅིག་ཡོད་མིན་དགོས་མིན་འདུག ཁོ་བོས་འདིས་དགོས་པ་དེ་དག་ལྟ་ཞིབ་དང་བརྟན་བཤད་པ་ཞིག་ལ་གཏོང་བྱེད་ཐུབ་ཀྱི་ཡོད། To address these subtasks, we build an Evidence-based Explanation dataset, which is the largest dataset for explaining evidences in recommending hotels for vague requests. experimental results demonstrate that the BERT model can find evidence sentences with respect to various vague requests and that the LSTM based model can generate recommendations.'}
{'en': 'A Unified Framework for Multilingual and Code-Mixed Visual Question Answering', 'ar': 'إطار موحد للإجابة على الأسئلة المرئية متعددة اللغات والمختلطة برموز', 'es': 'Un marco unificado para respuestas a preguntas visuales multilingües y de código mixto', 'fr': 'Un cadre unifié pour les réponses visuelles aux questions multilingues et mixtes', 'pt': 'Uma estrutura unificada para respostas a perguntas visuais multilíngues e de código misto', 'ja': '多言語とコードが混在した視覚的な質問への回答のための統一されたフレームワーク', 'zh': '多言与代码合视问答者同框架', 'hi': 'बहुभाषी और कोड-मिश्रित दृश्य प्रश्न उत्तर के लिए एक एकीकृत रूपरेखा', 'ru': 'Унифицированная структура для многоязычного и кодово-смешанного визуального ответа на вопросы', 'ga': 'Creat Aontuithe le haghaidh Freagraí Amhairc Ilteangacha agus Cóid-Mheasctha', 'hu': 'Egységes keretrendszer a többnyelvű és kódkevert vizuális kérdések megválaszolására', 'ka': 'Name', 'el': 'Ένα ενιαίο πλαίσιο για την πολύγλωσση και μικτή οπτική απάντηση ερωτήσεων', 'it': 'Un quadro unificato per la risposta alle domande visive multilingue e codificate', 'lt': 'Bendra daugiakalbių ir kodų mišrių vizualinių klausimų atsakymo sistema', 'kk': 'Көп тілді және код араластырылған көрінетін сұрақ жауап беру үшін біріктірілген фреймдер', 'mk': 'Унифицирана рамка за повеќејазични и комбинирани визуелни одговори на прашања', 'ms': 'Name', 'ml': 'Multilingual, Code- Mixed Visual Query', 'mt': 'Qafas Unifikat għat-tweġiba għal mistoqsijiet viżwali multilingwi u mħallta mal-Kodiċi', 'mn': 'Олон хэл болон код холбогдсон хариултын асуулт хариултын нэгтгэл бүтэц', 'no': 'Name', 'pl': 'Ujednolicone ramy dla wielojęzycznego i kodowego odpowiadania na wizualne pytania', 'ro': 'Un cadru unificat pentru răspunsul la întrebări vizuale multilingve și mixte de coduri', 'sr': 'Jednostavni okvir za odgovor na vizualno i mešano vizualno pitanje', 'si': 'ගොඩක් භාෂාවක් සහ කෝඩ් මික්ස් ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරතිච්චාරයක් වෙනුවෙන් එක්කරණ වැඩ', 'sv': 'En enhetlig ram för flerspråkig och kodblandad visuell frågeställning', 'so': 'A Unified Framework for multiple luqadood and Code-Mixed Questions', 'ta': 'பல மொழி மற்றும் குறியீட்டு கலக்கப்பட்ட காட்சி கேள்விக்கான ஒருங்கிணைக்கப்பட்ட சட்டம்', 'ur': 'Multilingual and Code-Mixed Visual Question Answering', 'uz': 'Name', 'vi': 'Một bộ khung hợp nhất cho câu trả lời đa ngôn ngữ và mã hoà ảo', 'bg': 'Унифицирана рамка за многоезично и смесено с кодове визуално отговаряне на въпроси', 'hr': 'Jediničan okvir za odgovor na višejezičke i mješane vizuelne pitanja', 'da': 'En fælles ramme for flersproget og kodeblandet visuel spørgsmål besvarelse', 'nl': 'Een uniform raamwerk voor meertalig en code-gemengd visueel antwoord op vragen', 'de': 'Ein einheitliches Framework für mehrsprachige und Code-Mixed visuelle Fragebeantwortung', 'id': 'Sebuah Framework Unified for Multilingual and Code-Mixed Visual Question Answering', 'ko': '통일된 다중 언어와 코드가 혼합된 시각적 문답 프레임워크', 'fa': 'Name', 'tr': 'Çoklu diller we ködlemeler görkezilen sorag jogapy üçin bir Birleşik Framework', 'sw': 'Miundombi ya Muungano kwa ajili ya Maswali ya Visual Mijingo ya Lugha na Mijingo', 'af': 'Name', 'sq': 'Një kuadër i unifikuar për përgjigjet e pyetjeve vizuale shumëgjuhëse dhe të përziera me kod', 'hy': 'A Unified Framework for Multilingual and Code-Mixed Visual Question Answering', 'am': 'Multiቋንቋ እና Code-Mixed Visual Question', 'az': 'Çoxlu dilli və Kod Karışmış Görünül Soruşu Cevapı üçün Birleşdirilmiş Framework', 'bn': 'Name', 'cs': 'Jednotný rámec pro vícejazyčné a kódově smíšené vizuální odpovědi na otázky', 'bs': 'Jediničan okvir za odgovor na višejezičko i mešano vizuelno pitanje', 'et': 'Ühtne raamistik mitmekeelseks ja koodisegatud visuaalseks küsimustele vastamiseks', 'ca': 'Un marc unificat per respondre a preguntes visuals multilingües i combinades amb codis', 'fi': 'Yhtenäinen kehys monikieliselle ja koodisekoitteiselle visuaaliselle kysymysvastaukselle', 'jv': 'Una Unify', 'sk': 'Enotni okvir za večjezično in mešano kodo vizualno odgovarjanje na vprašanja', 'ha': 'KCharselect unicode block name', 'he': 'מסגר מאוחד לענות על שאלות חזותיות רבות שפויות ומערובות בקוד', 'bo': 'སྐད་རིགས་དང་སྒྲིག་ཆ་མཐུན་པའི་མཐུན་སྣེ་ཚོགས་ཀྱི་གནད་སྐོར་ལ་སྒྲིག་གཞུང་ཞིག་གིས་ལན་པར།'}
{'en': 'In this paper, we propose an effective deep learning framework for multilingual and code- mixed visual question answering. The pro- posed model is capable of predicting answers from the questions in Hindi, English or Code- mixed (Hinglish : Hindi-English) languages. The majority of the existing techniques on Vi- sual Question Answering (VQA) focus on En- glish questions only. However, many applica- tions such as  medical imaging ,  tourism , visual assistants require a multilinguality-enabled module for their widespread usages. As there is no available dataset in English-Hindi VQA, we firstly create Hindi and Code-mixed VQA datasets by exploiting the linguistic properties of these languages. We propose a robust tech- nique capable of handling the multilingual and code-mixed question to provide the answer against the visual information (image). To better encode the multilingual and code-mixed questions, we introduce a hierarchy of shared layers. We control the behaviour of these shared layers by an attention-based soft layer sharing mechanism, which learns how shared layers are applied in different ways for the dif- ferent languages of the question. Further, our model uses bi-linear attention with a residual connection to fuse the language and image fea- tures. We perform extensive evaluation and ablation studies for English, Hindi and Code- mixed VQA. The evaluation shows that the proposed multilingual model achieves state-of- the-art performance in all these settings.', 'ar': 'في هذه الورقة ، نقترح إطارًا فعالًا للتعلم العميق للإجابة على الأسئلة المرئية متعددة اللغات والمختلطة بالكود. النموذج المقترح قادر على التنبؤ بالإجابات من الأسئلة باللغات الهندية أو الإنجليزية أو اللغات المختلطة (Hinglish: Hindi-English). تركز غالبية الأساليب الموجودة في الإجابة على الأسئلة (VQA) على أسئلة اللغة الإنجليزية فقط. ومع ذلك ، فإن العديد من التطبيقات ، مثل التصوير الطبي ، السياحة ، المساعدين البصريين تتطلب وحدة متعددة اللغات ممكّنة لاستخدامها على نطاق واسع. نظرًا لعدم وجود مجموعة بيانات متاحة باللغة الإنجليزية-الهندية VQA ، نقوم أولاً بإنشاء مجموعات بيانات VQA الهندية والمختلطة برموز من خلال استغلال الخصائص اللغوية لهذه اللغات. نقترح تقنية قوية قادرة على التعامل مع السؤال متعدد اللغات والمختلط بالشفرة لتقديم إجابة مقابل المعلومات المرئية (الصورة). لترميز الأسئلة متعددة اللغات والمختلطة بالكود بشكل أفضل ، نقدم تسلسلاً هرميًا للطبقات المشتركة. نحن نتحكم في سلوك هذه الطبقات المشتركة من خلال آلية مشاركة الطبقة اللينة القائمة على الانتباه ، والتي تتعلم كيفية تطبيق الطبقات المشتركة بطرق مختلفة للغات المختلفة للسؤال. علاوة على ذلك ، يستخدم نموذجنا الانتباه ثنائي الخط مع اتصال متبقي لدمج خصائص اللغة والصورة. نقوم بإجراء دراسات تقييم واستئصال مكثفة للغة الإنجليزية والهندية و VQA المختلطة. يُظهر التقييم أن النموذج متعدد اللغات المقترح يحقق أداءً متطورًا في جميع هذه الإعدادات.', 'fr': "Dans cet article, nous proposons un cadre d'apprentissage profond efficace pour répondre à des questions visuelles multilingues et mixtes par code. Le modèle proposé est capable de prédire les réponses aux questions en hindi, en anglais ou en langues codées (Hinglish\xa0: Hindi-Anglais). La majorité des techniques existantes de réponse aux questions visuelles (VQA) se concentrent uniquement sur les questions en anglais. Cependant, de nombreuses applications telles que l'imagerie médicale, le tourisme, les assistants visuels nécessitent un module multilinguisme pour leurs usages répandus. Comme il n'existe aucun jeu de données disponible en VQA anglais-hindi, nous créons d'abord des ensembles de données VQA en hindi et en code mixte en exploitant les propriétés linguistiques de ces langues. Nous proposons une technique robuste capable de traiter la question multilingue et mixte de code afin de fournir la réponse par rapport aux informations visuelles (image). Pour mieux coder les questions multilingues et mixtes, nous introduisons une hiérarchie de couches partagées. Nous contrôlons le comportement de ces couches partagées par un mécanisme de partage de couches souples basé sur l'attention, qui apprend comment les couches partagées sont appliquées de différentes manières pour les différentes langues de la question. De plus, notre modèle utilise l'attention bilinéaire avec une connexion résiduelle pour fusionner les caractéristiques du langage et de l'image. Nous effectuons des études d'évaluation et d'ablation approfondies pour l'anglais, l'hindi et le VQA codé mixte. L'évaluation montre que le modèle multilingue proposé atteint des performances de pointe dans tous ces contextes.", 'es': 'En este artículo, proponemos un marco de aprendizaje profundo eficaz para respuestas visuales multilingües y de código mixto a preguntas. El modelo propuesto es capaz de predecir las respuestas de las preguntas en hindi, inglés o con código mixto (Hinglish: hindi-inglés). La mayoría de las técnicas existentes de respuesta visual a preguntas (VQA) se centran únicamente en preguntas en inglés. Sin embargo, muchas aplicaciones, como imágenes médicas, turismo y asistentes visuales, requieren un módulo compatible con el multilingüismo para su uso generalizado. Como no hay un conjunto de datos disponible en VQA inglés-hindi, primero creamos conjuntos de datos de VQA en hindi y código mixto explotando las propiedades lingüísticas de estos idiomas. Proponemos una técnica sólida capaz de manejar la pregunta multilingüe y de código mixto para proporcionar la respuesta contra la información visual (imagen). Para codificar mejor las preguntas multilingües y de código mixto, introducimos una jerarquía de capas compartidas. Controlamos el comportamiento de estas capas compartidas mediante un mecanismo de uso compartido de capas suaves basado en la atención, que aprende cómo se aplican las capas compartidas de diferentes maneras para los diferentes idiomas de la pregunta. Además, nuestro modelo utiliza atención bilineal con una conexión residual para fusionar las características del lenguaje y la imagen. Realizamos extensos estudios de evaluación y ablación para VQA en inglés, hindi y código mixto. La evaluación muestra que el modelo multilingüe propuesto logra un rendimiento de vanguardia en todos estos entornos.', 'pt': 'Neste artigo, propomos uma estrutura eficaz de aprendizado profundo para respostas visuais multilíngues e de código misto. O modelo proposto é capaz de prever as respostas das perguntas nos idiomas hindi, inglês ou code-mixed (hinglish: hindi-inglês). A maioria das técnicas existentes de Visual Question Answering (VQA) concentra-se apenas em perguntas em inglês. No entanto, muitos aplicativos, como imagens médicas, turismo, assistentes visuais exigem um módulo habilitado para multilinguismo para uso generalizado. Como não há conjunto de dados disponível em VQA inglês-hindi, primeiro criamos conjuntos de dados VQA hindi e code-mixed explorando as propriedades linguísticas desses idiomas. Propomos uma técnica robusta capaz de lidar com a questão multilíngue e mista de código para fornecer a resposta em relação à informação visual (imagem). Para codificar melhor as questões multilíngues e de código misto, introduzimos uma hierarquia de camadas compartilhadas. Controlamos o comportamento dessas camadas compartilhadas por meio de um mecanismo de compartilhamento de camada suave baseado em atenção, que aprende como as camadas compartilhadas são aplicadas de maneiras diferentes para as diferentes linguagens da questão. Além disso, nosso modelo usa atenção bilinear com uma conexão residual para fundir os recursos de linguagem e imagem. Realizamos extensos estudos de avaliação e ablação para VQA em inglês, hindi e code-mixed. A avaliação mostra que o modelo multilíngue proposto alcança desempenho de última geração em todos esses cenários.', 'ja': 'この論文では、多言語とコードが混在した視覚的な質問に答えるための効果的なディープラーニングフレームワークを提案します。 親ポーズモデルは、ヒンディー語、英語、またはコード混合（ヒンディー語：ヒンディー語-英語）言語の質問から回答を予測することができます。 V - sual Question Answering （ VQA ）に関する既存のテクニックの大部分は、明瞭な質問のみに焦点を当てている。 しかし、医用画像診断、観光、視覚アシスタントなどの多くの用途では、広範囲にわたる使用のために多言語対応モジュールが必要である。 英語-ヒンディー語のVQAには利用可能なデータセットがないため、まずこれらの言語の言語的特性を利用して、ヒンディー語とコード混合のVQAデータセットを作成します。 視覚情報に対する答えを提供するために、多言語とコードが混在した質問に対処できる堅牢なテクノロジーを提案します（画像）。 多言語とコードが混在した質問をより良くエンコードするために、共有レイヤーの階層を導入します。 私たちは、注意に基づくソフトレイヤー共有メカニズムによって、これらの共有レイヤーの挙動を制御します。このメカニズムは、質問の異なる言語に対して共有レイヤーがどのように異なる方法で適用されるかを学習します。 さらに、私たちのモデルは、言語と画像の特徴を融合させるために、残留接続を伴う双線形の注目を使用しています。 私たちは、英語、ヒンディー語、およびコード混合VQAのための広範な評価とアブレーション研究を行っています。 この評価は、提案された多言語モデルが、これらすべての設定で最先端のパフォーマンスを達成することを示している。', 'zh': '于本文中,有效深学框架,施于多言代码混合视听问答。 pro-pose能从印地语,英语代码混合(Hinglish:Hindi-English)言语占对。 凡Vi-sual问答(VQA)多见术惟En-glish。 然多用,如医学成像,游行,视助理须一支多言语者模块乃可博用。 英语-印地语 VQA 中无可用之数集,故先因此言语属性以创印地语代码混合 VQA 数集。 吾有强大之术,能处多言代码混合之问,以供视息(图)之对。 为善语代码混编码,引入共享层次结构。 以意力之软层,共制其行,以机学之共享层何以异宜而用之? 此外,吾形用残差接者双线性注意以合言语图像。 吾于英语,印地语与代码混VQA博论消息。 评估明白,所言多言模形,皆得其先进之性。', 'hi': 'इस पेपर में, हम बहुभाषी और कोड-मिश्रित दृश्य प्रश्न के उत्तर के लिए एक प्रभावी गहरी सीखने की रूपरेखा का प्रस्ताव करते हैं। प्रो-पोज्ड मॉडल हिंदी, अंग्रेजी या कोड-मिश्रित (हिंग्लिश: हिंदी-अंग्रेजी) भाषाओं में प्रश्नों के उत्तरों की भविष्यवाणी करने में सक्षम है। Vi-sual Question Answering (VQA) पर मौजूदा तकनीकों का अधिकांश भाग केवल एन-ग्लिश प्रश्नों पर ध्यान केंद्रित करता है। हालांकि, चिकित्सा इमेजिंग, पर्यटन, दृश्य सहायकों जैसे कई अनुप्रयोगों को उनके व्यापक उपयोगों के लिए एक बहुभाषी-सक्षम मॉड्यूल की आवश्यकता होती है। चूंकि अंग्रेजी-हिंदी वीक्यूए में कोई डेटासेट उपलब्ध नहीं है, इसलिए हम सबसे पहले इन भाषाओं के भाषाई गुणों का शोषण करके हिंदी और कोड-मिश्रित वीक्यूए डेटासेट बनाते हैं। हम एक मजबूत तकनीक का प्रस्ताव करते हैं जो दृश्य जानकारी (छवि) के खिलाफ उत्तर प्रदान करने के लिए बहुभाषी और कोड-मिश्रित प्रश्न को संभालने में सक्षम है। बहुभाषी और कोड-मिश्रित प्रश्नों को बेहतर ढंग से एन्कोड करने के लिए, हम साझा परतों का एक पदानुक्रम पेश करते हैं। हम इन साझा परतों के व्यवहार को एक ध्यान-आधारित नरम परत साझा करण तंत्र द्वारा नियंत्रित करते हैं, जो सीखता है कि प्रश्न की अलग-अलग भाषाओं के लिए विभिन्न तरीकों से साझा परतों को कैसे लागू किया जाता है। इसके अलावा, हमारा मॉडल भाषा और छवि fea-tures फ्यूज करने के लिए एक अवशिष्ट कनेक्शन के साथ द्वि-रैखिक ध्यान का उपयोग करता है। हम अंग्रेजी, हिंदी और कोड-मिश्रित वीक्यूए के लिए व्यापक मूल्यांकन और एब्लेशन अध्ययन करते हैं। मूल्यांकन से पता चलता है कि प्रस्तावित बहुभाषी मॉडल इन सभी सेटिंग्स में अत्याधुनिक प्रदर्शन प्राप्त करता है।', 'ru': 'В этой статье мы предлагаем эффективную основу глубокого обучения для многоязычного и кодово-смешанного визуального ответа на вопросы. Пропозиционная модель способна предсказывать ответы на вопросы на хинди, английском или смешанном с кодом (хинди: хинди-английский) языках. Большинство существующих методик ответа на вопросы (VQA) сосредоточены только на вопросах на английском языке. Тем не менее, многие приложения, такие как медицинская визуализация, туризм, визуальные ассистенты, требуют модуля с поддержкой многоязычия для их широкого использования. Поскольку в VQA на английском языке и хинди нет доступного набора данных, мы, во-первых, создаем наборы данных VQA на хинди и код-смешанные наборы данных, используя лингвистические свойства этих языков. Мы предлагаем надежную технологию, способную обрабатывать многоязычный и смешанный с кодом вопрос, чтобы дать ответ на визуальную информацию (изображение). Чтобы лучше кодировать многоязычные и смешанные вопросы, мы вводим иерархию общих слоев. Мы контролируем поведение этих общих слоев с помощью механизма совместного использования мягких слоев, основанного на внимании, который изучает, как общие слои применяются различными способами для различных языков вопроса. Кроме того, наша модель использует билинейное внимание с остаточной связью, чтобы объединить язык и изображения. Мы проводим обширные исследования по оценке и абляции для английского языка, хинди и смешанного кода VQA. Оценка показывает, что предлагаемая многоязычная модель достигает самых современных показателей во всех этих условиях.', 'ga': 'Sa pháipéar seo, molaimid creat domhain foghlama éifeachtach chun ceisteanna amhairc ilteangacha agus códmheasctha a fhreagairt. Tá an tsamhail mholta in ann freagraí ó na ceisteanna i Hiondúis, Béarla nó Cód-mheasctha (Hinglish: Hiondúis-Béarla) a thuar. Is ar cheisteanna Béarla amháin a dhíríonn formhór na dteicníochtaí atá ann faoi láthair maidir le Freagraí Fíor-Cheisteanna (VQA). Mar sin féin, tá modúl ilteangach-chumasaithe ag teastáil ó go leor iarratas ar nós íomháú leighis, turasóireacht, cúntóirí amhairc dá n-úsáidí forleathan. Toisc nach bhfuil aon tacar sonraí ar fáil i VQA Béarla-Hiondúis, cruthaímid ar dtús tacair sonraí VQA Hiondúis agus Cód-mheasctha trí leas a bhaint as airíonna teangeolaíocha na dteangacha seo. Molaimid teicníocht láidir atá in ann an cheist ilteangach agus cód-mheasctha a láimhseáil chun an freagra a sholáthar i gcoinne na faisnéise amhairc (íomhá). Chun na ceisteanna ilteangacha agus cód-mheasctha a ionchódú níos fearr, tugaimid isteach ordlathas de shraitheanna comhroinnte. Déanaimid rialú ar iompar na sraitheanna comhroinnte seo trí mheicníocht roinnte ciseal bog aird-bhunaithe, a fhoghlaimíonn conas a chuirtear sraitheanna roinnte i bhfeidhm ar bhealaí éagsúla do theangacha éagsúla na ceiste. Ina theannta sin, úsáideann ár múnla aird dhélíneach agus nasc iarmharach chun gnéithe teanga agus íomhá a chomhleá. Déanaimid staidéir fhairsing mheasúnaithe agus eiblithe do VQA Béarla, Hiondúis agus Cód-mheasctha. Léirítear sa mheastóireacht go mbaineann an tsamhail ilteangach atá beartaithe feidhmíocht den scoth amach sna suíomhanna seo go léir.', 'ka': 'ამ წიგნაში ჩვენ ვფიქრდებით ძალიან ძალიან სწავლებელი ფრამეტრი მრავალური და კოდის შესაბამისათვის ვიზუალური კითხვების შესაბამისათვის. პროპოზეციული მოდელი შესაძლებელია წარმოიდგინოთ ჰინდური, ანგლისური ან კოდის შემთხვევაში (ჰინდლისური: ჰინდური-ანგლისური) წარმოიდგინოთ. ვი- სამუშაო კითხვების გარეშე (VQA) მხოლოდ En- glish კითხვების გარეშე მეტი ტექნოგიები. მაგრამ, ბევრი პროგრამები, როგორც მედიცინური გამოსახულები, რურიზმი, ვიზუალური asistenტები მოჭირდება მრავალენგუალურობის მოდულის შესაძლებელი მოდული, როგორც რადგან ინგლისური-ჰინდური VQA-ში არ არის ხელმისაწყებელი მონაცემები, ჩვენ პირველად ინდური და კოდისური VQA მონაცემების კოდისური დანაცემების შესახებ ამ ენების ლუნგური ჩვენ შეგიძლიათ ძალიან ძალიან ტექნოლოგიური ინფორმაციის შესაძლებლობა მრავალენგური და კოდის შესაძლებელი კითხვა, რომელიც ვიზუალური ინფორმაციის (გამოსახულების) გასახულ მრავალენგური და კოდის შესაბამისი კითხვების უკეთესი კოდის კოდის შესაბამისთვის, ჩვენ ჩვენ გავაკეთებთ საერთო მრავალის ჰიერაქტია. ჩვენ კონტროლისთვის ამ საზოგადოებული შაბის მონაცემების მონაცემების მექანსი, რომელიც ვისწავლის თუ რამდენიმე საზოგადოებული შაბები განსხვავებული გზებისთვის გამოყენება. მეორე, ჩვენი მოდელი გამოყენება ორ-ლეინური დაახლოებით, საკუთარი დაკავშირებით ენის და გამოსახულების fea-სურაციების შემდეგ. ჩვენ გავაკეთებთ განსაზღვრებული განსაზღვრება და გავაკეთებული ინგლისური, ჰინდური და კოდის შესაძლებელი VQA. განსაზღვრება ჩვენებს, რომ მრავალენგური მოდელის შესაძლებლობა ყველა ამ პარამეტრებში მრავალენგური მოდელის შესაძლებლობა.', 'el': 'Στην παρούσα εργασία, προτείνουμε ένα αποτελεσματικό πλαίσιο βαθιάς μάθησης για την πολύγλωσση και μικτή οπτική απάντηση ερωτήσεων. Το προτεινόμενο μοντέλο είναι ικανό να προβλέψει απαντήσεις από τις ερωτήσεις στα Χίντι, στα Αγγλικά ή σε μικτές γλώσσες κώδικα (Χίντι-Αγγλικά). Η πλειονότητα των υφιστάμενων τεχνικών για την απάντηση των ερωτήσεων επικεντρώνεται μόνο σε γενικές ερωτήσεις. Ωστόσο, πολλές εφαρμογές όπως η ιατρική απεικόνιση, ο τουρισμός, οι οπτικοί βοηθοί απαιτούν μια ενότητα με δυνατότητα πολυγλωσσίας για την ευρεία χρήση τους. Δεδομένου ότι δεν υπάρχει διαθέσιμο σύνολο δεδομένων στα Αγγλικά-Χίντι VQA, δημιουργούμε αρχικά σύνολα δεδομένων Χίντι και μικτού κώδικα αξιοποιώντας τις γλωσσικές ιδιότητες αυτών των γλωσσών. Προτείνουμε μια ισχυρή τεχνολογία ικανή να χειριστεί την πολύγλωσση και κωδικοποιημένη ερώτηση για να δώσει την απάντηση έναντι των οπτικών πληροφοριών (εικόνα). Για να κωδικοποιήσουμε καλύτερα τις πολυγλωσσικές και μικτές ερωτήσεις κώδικα, εισάγουμε μια ιεραρχία κοινών επιπέδων. Ελέγχουμε τη συμπεριφορά αυτών των κοινών στρωμάτων με έναν μηχανισμό επιμερισμού μαλακών στρωμάτων που βασίζεται στην προσοχή, ο οποίος μαθαίνει πώς τα κοινά στρώματα εφαρμόζονται με διαφορετικούς τρόπους για τις διαφορετικές γλώσσες της ερώτησης. Επιπλέον, το μοντέλο μας χρησιμοποιεί διγραμμική προσοχή με υπολειμματική σύνδεση για να συγχωνεύσει τα χαρακτηριστικά της γλώσσας και της εικόνας. Εκτελούμε εκτενείς μελέτες αξιολόγησης και αφαίρεσης για Αγγλικά, Χίντι και μικτό κώδικα. Η αξιολόγηση δείχνει ότι το προτεινόμενο πολύγλωσσο μοντέλο επιτυγχάνει επιδόσεις τελευταίας τεχνολογίας σε όλες αυτές τις ρυθμίσεις.', 'hu': 'Jelen tanulmányban hatékony mélytanulási keretrendszert javasolunk a többnyelvű és kódolt vegyes vizuális kérdések megválaszolására. A javasolt modell képes hindi, angol vagy kódkevert (hindi-angol) nyelvű kérdésekre adott válaszokat előrejelezni. A vizuális kérdések megválaszolására vonatkozó meglévő technikák többsége csak egyszerű kérdésekre összpontosít. Mindazonáltal számos alkalmazás, mint például az orvosi képalkotás, a turizmus, a vizuális asszisztensek, széles körű használatához többnyelvűségre alkalmas modult igényel. Mivel az angol-hindi VQA nyelven nincs elérhető adatkészlet, először hindi és kódkeverékes VQA adatkészleteket hozunk létre ezen nyelvek nyelvi tulajdonságainak kihasználásával. Olyan robusztus technológiát javaslunk, amely képes kezelni a többnyelvű és kódkevert kérdést, hogy a vizuális információ (kép) ellen választ adjon. A többnyelvű és kódkeverékes kérdések jobb kódolása érdekében bevezetjük a megosztott rétegek hierarchiáját. Ezeknek a közös rétegeknek a viselkedését figyelem-alapú lágy rétegmegosztó mechanizmussal szabályozzuk, amely megtanulja, hogyan alkalmazzák a megosztott rétegeket különböző módon a kérdés különböző nyelveihez. Továbbá modellünk bi-lineáris figyelmet használ egy maradék kapcsolattal a nyelv és a kép tulajdonságainak egyesítésére. Átfogó értékelési és ablációs tanulmányokat végzünk angol, hindi és kódkevert VQA számára. Az értékelés azt mutatja, hogy a javasolt többnyelvű modell mindezen körülmények között korszerű teljesítményt ér el.', 'it': "In questo articolo, proponiamo un efficace framework di deep learning per rispondere alle domande visive multilingue e codificate. Il modello proposto è in grado di predire le risposte delle domande in Hindi, Inglese o Code-Mixed (Hinglish: Hindi-English). La maggior parte delle tecniche esistenti sulla risposta alle domande vi- suali (VQA) si concentra solo su domande semplici. Tuttavia, molte applicazioni come imaging medico, turismo, assistenti visivi richiedono un modulo multilingue per i loro usi diffusi. Poiché non esistono set di dati disponibili in inglese-hindi VQA, creiamo in primo luogo set di dati Hindi e Code-mixed VQA sfruttando le proprietà linguistiche di queste lingue. Proponiamo una solida tecnologia in grado di gestire la domanda multilingue e code-mixed per fornire la risposta contro l'informazione visiva (immagine). Per codificare meglio le domande multilingue e miste di codice, introduciamo una gerarchia di livelli condivisi. Controlliamo il comportamento di questi strati condivisi attraverso un meccanismo di condivisione soft layer basato sull'attenzione, che impara come i livelli condivisi vengono applicati in modi diversi per i diversi linguaggi della domanda. Inoltre, il nostro modello utilizza l'attenzione bi-lineare con una connessione residua per fondere le caratteristiche del linguaggio e dell'immagine. Eseguiamo approfonditi studi di valutazione e ablazione per inglese, hindi e codice misto VQA. La valutazione dimostra che il modello multilingue proposto raggiunge prestazioni all'avanguardia in tutti questi contesti.", 'kk': 'Бұл қағазда біз көптілік және код араластырылған визуалдық сұрақтардың жауап беру үшін эффективті түсінікті қолдануға ұсынамыз. Пропозиция үлгісі хиндық, ағылшын немесе код араластырылған (Hinglish: Hindi- English) тілдерінің жауаптарын алдын алады. Vi- кәдімгі сұрақ жауап беру (VQA) үшін бар техникалардың көпшілігі тек En- glish сұрақтарына назар аудару. Бірақ, медицина кескіні, туризмі, визуалдық көмекшілердің көптеген қолданбаларының көптеген модулі керек. Ағылшын-хиндық VQA тілдерінде қол жеткізбеген деректер жинағы жоқ, біріншіден бұл тілдердің лингвистикалық қасиеттерін қолдану арқылы хиндық және код араластырылған VQA деректер жинақтарын құр Біз көп тілді және код арасындағы сұрақтарды қамтамасыз ету үшін күшті технологиялық жауап беруге мүмкіндік береді. Көптілік және код арасындағы сұрақтарды жақсы кодтау үшін біз ортақ қабаттардың иерархиясын таңдаймыз. Біз бұл ортақтастырылған қабаттардың әрекеттерін сұрақтың dif- ferent тілдеріне қалай ортақтастыру механизмі арқылы бақылап, қалай ортақтастырылған қабаттарды бақылаймыз. Қосымша, біздің үлгіміз тіл және кескіндің феа- тураларын біріктіру үшін қалдық қосылым арқылы сызық түрлі қызықты қолданады. Біз ағылшын, хинди және код араластырылған VQA үшін кеңейтілген оқу және қолдану зерттеулерін орындаймыз. Бұл оқиға қолданылатын көптілік үлгісінің бұл параметрлердің күй- жайы әдістерін жеткізеді.', 'mk': 'Во овој весник предложуваме ефикасна рамка за длабоко учење за мултијазички и мешан визуелен одговор на прашања. Пропозираниот модел е способен да предвидува одговори од прашањата на хинди, англиски или код- мешани (хинди- англиски) јазици. Повеќето од постоечките техники за визуален одговор на прашања (VQA) се фокусираат само на прашањата на En- glish. Сепак, многу апликации како што се медицинската слика, туризмот, визуелните асистенти бараат мултијазични модули за нивните широки употреби. Бидејќи нема достапни податоци на англиско-хиндиско VQA, ние прво создаваме хиндиски и кодови мешани VQA податоци со искористување на јазичните сопствености на овие јазици. Ние предложуваме силна техника способна да се справи со мултијазичкото прашање и кодово мешано прашање за да обезбеди одговор против визуелните информации (слика). За подобро да ги кодираме мултијазичните и кодовите мешани прашања, воведуваме хиерархија на заеднички слоеви. Го контролираме однесувањето на овие споделени слоеви со мек механизам за споделување на слоеви базиран на внимание, кој научи како споделени слоеви се применуваат на различни начини за различните јазици на прашањето. Покрај тоа, нашиот модел користи билинијарно внимание со остатокот на поврзаност за да ги спои јазиците и сликите. We perform extensive evaluation and ablation studies for English, Hindi and Code- mixed VQA.  Оваа оценка покажува дека предложениот мултијазичен модел постигнува најдобри резултати во сите овие поставувања.', 'lt': 'Šiame dokumente siūlome veiksmingą gilaus mokymosi sistemą daugiakalbiams ir kodų mišriems vizualiniams klausimams atsakyti. Siūlomas model is gali nuspėti atsakymus į klausimus Hindi, English arba Code- mixed (anglų kalba: Hindi- English). Dauguma esamų metodų, susijusių su vizualiniais atsakymais į klausimus (VQA), daugiausia dėmesio skiria tik angliškiems klausimams. Vis dėlto daugeliui programų, pavyzdžiui, medicininio vaizdo kūrimo, turizmo, vizualinių asistentų, jų plačiam naudojimui reikalingas daugiakalbystės modulis. Kadangi anglų ir Hindi VQA duomenų rinkinio nėra, pirmiausia sukuriame Hindi ir Code-mixed VQA duomenų rinkinius naudojant šių kalbų kalbines savybes. Siūlome patikimą technologiją, galinčią išspręsti daugiakalbį ir su kodais susijusį klausimą, kad būtų pateiktas atsakymas prieš vizualiąją informaciją (vaizdą). Siekiant geriau koduoti daugiakalbius ir kodų mišrius klausimus, įvedame bendrų sluoksnių hierarchiją. Mes kontroliuojame šių bendrų sluoksnių elgesį taikant dėmesiu grindžiamą minkštųjų sluoksnių dalijimosi mechanizmą, kuris išmoko, kaip bendri sluoksniai skirtingais būdais taikomi skirtingoms klausimo kalboms. Further, our model uses bi-linear attention with a residual connection to fuse the language and image fea- tures.  Atliekame išsamius anglų, hindų ir kodų mišinio VQA vertinimo ir abliacijos tyrimus. Vertinimas rodo, kad siūlomu daugiakalbiu modeliu visose šiose aplinkybėse pasiekti pažangiausi rezultatai.', 'ms': 'Dalam kertas ini, kami melamar kerangka pembelajaran dalam yang efektif untuk menjawab soalan visual berbilang bahasa dan kod-campuran. Model pro-posed mampu meramalkan jawapan dari soalan dalam bahasa Hindi, Inggeris atau Kod-campuran (Hinglish: Hindi-English). Kebanyakan teknik yang wujud pada Jawapan soalan Vi- sual (VQA) fokus pada soalan En- glish sahaja. Namun, banyak aplikasi seperti imej perubatan, turis, pembantu visual memerlukan modul yang dibenarkan berbilang bahasa untuk penggunaan luas mereka. Kerana tiada set data yang tersedia dalam VQA Inggeris-Hindi, kita pertama-tama mencipta set data VQA Hindi dan Kod-campuran dengan mengeksploitasi ciri-ciri bahasa bahasa ini. Kami cadangkan teknologi yang kuat yang mampu mengendalikan soalan berbilang bahasa dan kod-campuran untuk memberikan jawapan terhadap maklumat visual (imej). Untuk mengekodkan lebih baik soalan berbilang bahasa dan kod-campuran, kami memperkenalkan hierarki lapisan terkongsi. Kami mengawal perilaku lapisan berkongsi ini dengan mekanisme berkongsi lapisan lembut berdasarkan perhatian, yang mempelajari bagaimana lapisan berkongsi dilaksanakan dengan cara yang berbeza untuk bahasa berbeza soalan. Lagipun, model kami menggunakan perhatian bidirelinear dengan sambungan yang tersisa untuk menghidupkan bahasa dan imej bultures. Kami melakukan kajian penilaian dan ablasi luas untuk bahasa Inggeris, Hindi dan Kod-campuran VQA. Evaluasi menunjukkan bahawa model berbilang bahasa yang diusulkan mencapai prestasi state-of-the-art dalam semua tetapan ini.', 'ml': 'In this paper, we propose an effective deep learning framework for multilingual and code- mixed visual question answering.  പോസ്റ്റ് മോഡല്\u200d ഹിന്ദി, ഇംഗ്ലീഷോ കോഡോ മിഷ്ടപ്പെട്ട ചോദ്യങ്ങളില്\u200d നിന്നും ഉത്തരം പ്രവചിപ്പിക്കാന്\u200d കഴിയുന്നു. നിലവിലുള്ള സാങ്കേതികവിദ്യകളില്\u200d ഏറെപ്പേരും വി- സ്വാല്\u200d ചോദ്യങ്ങളുടെ ഉത്തരം (വിക്യൂഎ) ചോദ്യങ്ങളില്\u200d മാത്രമേ ശ്രദ് എങ്കിലും മെഡിക്കല്\u200d ചിത്രം, ടൂരിസ്റ്റം, കാഴ്ചപ്പെടുത്തുന്ന സഹായികള്\u200d അവരുടെ വിശാലമായ ഉപയോഗങ്ങള്\u200dക്കായി ഒരു പല ഭാഷ- പ്രയോഗങ്ങള്\u200d ആ ഇംഗ്ലീഷ്-ഹിന്ദി വിക്യൂഎയില്\u200d ലഭ്യമല്ലാത്ത ഡാറ്റാസെറ്റ് ആദ്യം ഞങ്ങള്\u200d ഹിന്ദിയും കോഡും മിഷ്ടപ്പെട്ട വിക്യൂഎ ഡാറ്റാസറ്റുകള്\u200d സ കാഴ്ച വിവരങ്ങള്\u200dക്കെതിരെ ഉത്തരം നല്\u200dകാന്\u200d കഴിയുന്ന ഒരു റോബോസ്റ്റ് ടെക്കോച്ചിക്ക് പ്രായശ്ചിത്തം ചെയ്യുന്നുണ്ട്. പല ഭാഷകങ്ങളും കോഡ് മിഷ്ടപ്പെട്ട ചോദ്യങ്ങളും കൂടുതല്\u200d കോഡ് ചെയ്യുന്നതിന് നല്ലതായി നമ്മള്\u200d പങ്കുചേര്\u200dന്ന തടാക് ഈ പങ്കാളികളുടെ സ്വഭാവം നമ്മള്\u200d നിയന്ത്രിക്കുന്നു. ചോദ്യത്തിന്റെ വ്യത്യസ്ത ഭാഷകള്\u200dക്ക് എങ്ങനെ പങ്കുചേര്\u200dക്കുന്നു അതിനുശേഷം, നമ്മുടെ മോഡല്\u200d ബി ലൈനൈര്\u200d ശ്രദ്ധയോടെ ഉപയോഗിക്കുന്നു. ഭാഷ, ചിത്രത്തിന്റെയും വിഭാഗങ്ങളുടെയും പ്ര ഇംഗ്ലീഷ്, ഹിന്ദി, കോഡ് മിഷ്ടപ്പെട്ട വിക്യൂഎ വിന്\u200dഡിക്ക് വേണ്ടി വിശാലമായ വിലാസങ്ങളും വിലാസപ്രകാ ഈ സജ്ജീകരണങ്ങളില്\u200d പ്രൊദ്ദേശിക്കപ്പെട്ട പല ഭാഷകങ്ങളുടെ മോഡല്\u200d അവസ്ഥ നിലനില്\u200dക്കുന്നു', 'mn': 'Энэ цаасан дээр бид олон хэл болон кодын төвөгтэй хариултын үндсэн суралцах суралцах үйл ажиллагааг санал болгож байна. Пропороз загвар нь Хинди, Англи, Кодлог (Хинглис: Хинди-Англи) хэлний асуултуудаас хариултыг таамаглах боломжтой. Ви-жинхэнэ асуулт хариулт (VQA) дээрх оршиж буй техникуудын ихэнх нь зөвхөн Энглиш асуултуудад анхаарлаа хандуулдаг. Гэвч эмнэлгийн төсөөлөл, турист, харааны тусламжтайгаар олон хэрэглэгчдийн тусламжтайгаар олон хэлний тусламжтайгаар ашиглах модуль хэрэгтэй. Англи-Хинди VQA-д өгөгдлийн сангууд байхгүй учраас бид эхлээд Hindi болон Code-Mixed VQA өгөгдлийн сангуудыг эдгээр хэлний хэлний хувьцааны чанарыг ашиглаж байдаг. Бид олон хэл болон кодын төвөгтэй асуултыг хариулт өгөх боломжтой технологийг санал болгож байна. Бид олон хэл болон кодын цуглуулсан асуултуудыг илүү сайн кодлохын тулд хуваалцагдсан давхаргыг танилцуулдаг. Бид эдгээр хэсгүүдийн харилцааны үйл ажиллагааг анхаарлын төвөгтэй энгийн хэмжээний хуваалцах механизмээр удирдаж байна. Энэ нь асуултын дифферент хэл дээр хэрхэн хуваалцагдсан хэсгүүдийг өөр өөр аргаар хэрэглэгддэг Дараа нь бидний загвар нь хэл болон зурагт хамтдаа холбогдох холбоотой холбоотой холбоотой холбоотой холбоотой холбоотой. Бид Англи, Хинди, Кодекс-холбогдсон VQA-ын хувьд нэмэлт үнэлгээ, ашиглах судалгааг хийдэг. Дэлхийн шалгалт нь олон хэл загварын төлөвлөгөө нь эдгээр бүх төлөвлөгөөнд урлагийн үйл ажиллагааг гаргадаг.', 'no': 'I denne papiret foreslår vi ein effektiv dyp læringsrammeverk for å svara på fleirspråk og kodefelt visuell spørsmål. Den proposerte modellen er i stand til å foregå svara frå spørsmålene på hindiske, engelske eller kodeflekse (Hinglis: hindiske- engelske) språk. Dei fleste av dei eksisterande teknikka på Vi- vanlege spørsmålssvar (VQA) er berre fokusert på en- glish spørsmål. Men mange applikasjonar som medisinsk bilding, turismen, visuelle assistentar krev ein modul med fleirspråk på bruk av dei breidde bruka. Som ingen tilgjengeleg dataset i engelsk-hindisk VQA, oppretter vi først hindiske og kodeflikte VQA-datasett ved å bruka dei lingviske eigenskapane av desse språka. Vi foreslår ein robust teknikk som kan handtera det fleire språk og kode-blandet spørsmålet for å gjera svaret mot det visuelle informasjonen (bilete). For å bedre kode dei fleirspråka og kodeflikte spørsmålene, introduserer vi ein hierarki av delte lag. Vi kontrollerer oppførselen av desse delte lagene med ein merksomsetjingsmekanismekanismen for å dele fleire lag. Dette lærer korleis delte lag er brukt på ulike måtar for dei dif-ferente språka i spørsmålet. I tillegg bruker modellen vårt bitlineær oppmerksomhet med eit restituell tilkopling for å fjerna språket og biletformet. Vi utfører utvidende evalueringsstudiar og aktiveringsstudiar for engelsk, hindisk og kodemeksa VQA. Evalueringa viser at den foreslåde fleirspråksmodellen gjer tilstand til kunstfullføring i alle desse innstillingane.', 'mt': 'F’dan id-dokument, qed nipproponu qafas effettiv ta’ tagħlim profond għat-tweġiba għal mistoqsijiet viżivi multilingwi u mħallta mal-kodiċi. Il-mudell propost huwa kapaċi jipprevedi tweġibiet mill-mistoqsijiet bl-Indjan, bl-Ingliż jew bil-Kodiċi mħallta (Ingliż-Indjan). Il- maġġoranza tat- tekniki eżistenti dwar it- tweġiba għall- mistoqsijiet vizwali (VQA) jiffokaw biss fuq mistoqsijiet bl- Ingliż. However, many applica- tions such as medical imaging, tourism, visual assistants require a multilinguality-enabled module for their widespread usages.  Peress li m’hemmx sett ta’ dejta disponibbli fil-VQA Ingliż-Indjan, l-ewwel aħna nħolqu settijiet ta’ dejta tal-VQA Indjan u mħallta fil-Kodiċi billi napprofitaw il-karatteristiċi lingwistiċi ta’ dawn il-lingwi. Aħna nipproponu teknika robust a li kapaċi timmaniġġja l-mistoqsija multilingwi u mħallta bil-kodiċi biex tipprovdi t-tweġiba kontra l-informazzjoni viżiva (immaġni). Biex nikkodifikaw a ħjar il-mistoqsijiet multilingwi u mħallta mal-kodiċi, aħna nintroduċu ġerarkija ta’ saffi kondiviżi. Aħna nikkontrollaw l-imġiba ta’ dawn is-saffi kondiviżi permezz ta’ mekkaniżmu ta’ kondiviżjoni tas-saffi rotob ibbażat fuq l-attenzjoni, li jitgħallem kif is-saffi kondiviżi jiġu applikati b’modi differenti għall-lingwi differenti tal-kwistjoni. Barra minn hekk, il-mudell tagħna juża attenzjoni bi-lineari b’konnessjoni residwa biex jgħaqqad il-lingwa u l-ħbula tal-immaġni. Għandna nagħmlu studji estensivi ta’ evalwazzjoni u ablazzjoni għall-Ingliż, l-Indjan u l-VQA mħallta mal-Kodiċi. L-evalwazzjoni turi li l-mudell multilingwi propost jikseb prestazzjoni avvanzata f’dawn l-ambjenti kollha.', 'pl': 'W niniejszym artykule proponujemy skuteczne ramy głębokiego uczenia dla wielojęzycznych i kodowo-mieszanych wizualnych odpowiedzi na pytania. Zaproponowany model jest w stanie przewidzieć odpowiedzi na pytania w języku hindi, angielskim lub kodowo-mieszanym (hindi: hindi-angielski). Większość istniejących technik dotyczących odpowiedzi na wizualne pytania (VQA) koncentruje się wyłącznie na pytaniach podglądających. Jednakże wiele aplikacji, takich jak obrazowanie medyczne, turystyka, asystenci wizualni, wymaga modułu obsługującego wielojęzyczność dla ich powszechnego zastosowania. Ponieważ w angielsko-hindi VQA nie ma dostępnych zbiorów danych, najpierw tworzymy hindi i kodowo mieszane zestawy danych VQA poprzez wykorzystanie właściwości językowych tych języków. Proponujemy solidną technologię zdolną do obsługi wielojęzycznych i kodowych pytań, aby dostarczyć odpowiedzi na informację wizualną (obraz). Aby lepiej zakodować pytania wielojęzyczne i mieszane z kodem, wprowadzamy hierarchię wspólnych warstw. Kontrolujemy zachowanie tych wspólnych warstw za pomocą mechanizmu dzielenia się miękkimi warstwami opartego na uwadze, który uczy się, jak wspólne warstwy są stosowane na różne sposoby dla różnych języków pytania. Ponadto nasz model wykorzystuje uwagę dwuliniową z resztkowym połączeniem, aby połączyć cechy języka i obrazu. Wykonujemy szeroko zakrojone badania ewaluacyjne i ablacyjne dla angielskiego, hindi i kodowo-mieszanego VQA. Ocena pokazuje, że proponowany model wielojęzyczny osiąga najnowocześniejszą wydajność we wszystkich tych ustawieniach.', 'ro': 'În această lucrare, propunem un cadru eficient de învățare profundă pentru răspunsul vizual multilingv și cod-mixt la întrebări. Modelul propus este capabil să predică răspunsuri din întrebări în limbile hindi, engleză sau cod mixt (hinglish: hindi-engleză). Majoritatea tehnicilor existente privind răspunsul la întrebări vizuale (VQA) se concentrează numai pe întrebări english. Cu toate acestea, multe aplicaţii precum imagistica medicală, turismul, asistenţii vizuali necesită un modul multilingvistic pentru utilizarea lor largă. Deoarece nu există seturi de date disponibile în limba engleză-hindi VQA, creăm în primul rând seturi de date hindi și cod-mixte VQA prin exploatarea proprietăților lingvistice ale acestor limbi. Propunem o tehnologie robustă capabilă să gestioneze întrebarea multilingvă și cod-mixtă pentru a oferi răspunsul împotriva informațiilor vizuale (imagine). Pentru a codifica mai bine întrebările multilingve și amestecate de coduri, introducem o ierarhie a straturilor partajate. Controlăm comportamentul acestor straturi partajate printr-un mecanism de partajare a straturilor moi bazat pe atenție, care învață cum straturile partajate sunt aplicate în moduri diferite pentru diferitele limbi ale întrebării. Mai mult, modelul nostru folosește atenția bi-liniară cu o conexiune reziduală pentru a fuziona caracteristicile limbajului și imaginii. Realizăm studii extinse de evaluare și ablație pentru limba engleză, hindi și cod-mixt VQA. Evaluarea arată că modelul multilingv propus atinge performanțe de ultimă generație în toate aceste setări.', 'sr': 'U ovom papiru predlažemo efikasno duboko učenje okvira za odgovor na višejezičko i kodirano vizuelno pitanje. Propozirani model je sposoban da predvidi odgovore iz pitanja na hindskim, engleskim ili kodskim jezicima. Većina postojećih tehnika na odgovoru na Vi-uobičajene pitanja (VQA) fokusirala se samo na pitanja En-glish. Međutim, mnoge aplikacije poput medicinske slike, turizma, vizualne asistente zahtevaju modul omogućen na multijezičnost za njihove široke upotrebe. Pošto nema dostupnih podataka na engleskom-hindskom VQA-u, prvo stvorimo indijske i kod-pomešane VQA podatake koristeći jezičke vlasništvo tih jezika. Predlažemo jaèe tehnièke nièeve sposobne za rješavanje multijezičkog i mešanog pitanja za odgovor protiv vizuelnih informacija (slika). Da bismo bolje kodirali multijezičke i mešane pitanja, predstavljamo hijerarhiju zajedničkih slojeva. Kontroliramo ponašanje ovih zajedničkih slojeva mehanizam dijeljenja slojeva na pažnji, koji nauči kako se zajednički slojevi primjenjuju na različite načine za jezike pitanja. Nadalje, naš model koristi dvolinearnu pažnju sa ostatkom veze za spajanje jezika i fotografije fea-turea. Izvodimo veće procjene i proučavanje ablacije za engleski, hindski i kodeks kombinirane VQA. Procjenjivanje pokazuje da predloženi multijezički model postiže postupak stanja umjetnosti u svim tim nastavama.', 'si': 'මේ පත්තරේ අපි ප්\u200dරශ්නයක් කරනවා විශේෂ භාෂාවක් සහ කෝඩ් වලින් ප්\u200dරශ්නයක් ප්\u200dරතික්රියා කරන්න. හින්දී, ඉංග්\u200dරීසි හෝ කෝඩ් මිශ්ලිෂ් (හින්දී- ඉංග්\u200dරීසි) භාෂාවට ප්\u200dරශ්න ප්\u200dරශ්නයක් පිළිබඳින් ප්\u200d වී- සුවල් ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරතිච්චාර (VQA) වලින් ඉතින් ඉන්න තාක්ෂණික විශාල ප්\u200dරශ්න වලින් අවධ නමුත්, වෛද්\u200dය පින්තූරණය, ප්\u200dරවේශනය, ප්\u200dරවේශනය සහායකයෝ ගොඩක් භාෂාවක් සක්\u200dරීය වෙනුවෙන් මොඩියුල් අවශ්\u200d ඉංග්\u200dරීසිය-හින්දී VQA වල ලැබෙන දත්ත සැට් නෑ, අපි පළමු හින්දි සහ කෝඩ් මික්ස් VQA දත්ත සැට් නිර්මාණය කරනවා මේ භාෂාවල අපි ප්\u200dරශ්නයක් සැලසුම් කරනවා විශ්වාසික තේක්ෂණාකාරීය- නික් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් බලන්න පුළුවන් විදිහට ව ගොඩක් භාෂාවක් සහ කෝඩ් මිස්ස් ප්\u200dරශ්නයක් හොඳටම සංකේතනය කරන්න, අපි කොටස් සංවිධානයක් පෙනුම්  අපි අවධානය සම්බන්ධ කළ හැකියාව පාලනය කරන්නේ මෙම හැකියාවක් ප්\u200dරශ්නයේ dif- ferent භාෂාවට කොච්චර හැකියාවක් ප්\u200dරශ්නයක් වෙන තවත්, අපේ මොඩේල් එක්ක දුර්වලින් අවධානයක් භාෂාව සහ පින්තූර fea- අවධානයක් එක්ක පාවිච්චි කරනවා. අපි ඉංග්\u200dරීසි, හින්දි සහ කෝඩ් මිශ්\u200dරීය VQA සඳහා විශාල විශාල විශ්වාසය සහ සක්\u200dරීය අධ්\u200dයාන විශ්ලේෂණය පෙන්වන්නේ වැඩි භාෂාවක් මොඩල් විශ්ලේෂණයක් සාමාන්\u200dය විශ්ලේෂණය සම්පූර්ණයෙන්', 'so': "Warqadan waxan ka soo jeedaynaa koob waxbarasho aad u shaqeeya oo aad u samaysan karto jawaabta su'aalaha muuqashada ee luuqadaha kala duduwan iyo kooxda kala duduwan. Tusaale qofka la soo jeedo wuxuu awoodaa inuu ka hor dhigo jawaabaha su'aalaha ku qoran luuqadaha Hindi, Ingiriis ama koowaad (Hinglish: Hindi-Ingiriis). Inta badan teknolojiyada joogta ee ku jira jawaabta su'aalaha Vi-suu (VQA) waxay focus on su'aalaha En-glish oo keliya. Si kastaba ha ahaatee codsiyo badan, tusaale ahaan sawir caafimaad ah, safar, caawiyayaasha aragga waxay u baahan yihiin qalabka ay leeyihiin isticmaalkooda oo ballaadhan. As there is no available dataset in English-Hindi VQA, we firstly create Hindi and Code-mixed VQA datasets by exploiting the linguistic properties of these languages.  Waxaynu soo jeedaynaa teknolojiyo khamiis ah oo awoodda in uu ka qabsado su'aalaha luuqadaha kala duduwan iyo kooxaha si aan uga jawaabno macluumaadka aragga (sawirka). Si aad ugu fiican u kooban karto su'aalaha luuqadaha kala duduwan iyo kooxaha kala duduwan, waxaynu soo bandhigaynaa hierarkii xarumo kala duduwan. Waxaynu u maamulnaa dabiicaddan qaybahan la qaybsaday, taas oo baranaya sida laguugu sameeyo qasnadaha kala duduwan oo loogu codsaday luqadaha suurtagalka ah. Sidoo kale modellkayagu wuxuu ku isticmaalaa iskuul si uu u fududeeyo luqada iyo sawirka. Waxbarashada qiimeynta iyo dalbashada ee afka Ingiriis, Hindi iyo Codeyda ee ku xiran VQA ayaannu sameynaa waxbarasho aad u badan. Qiimeynta waxaa ka muuqata in qaababka la soo jeedo tusaale ahaan luuqadaha kala duduwan uu gaadho sameynta farshaxanka oo dhan.", 'sv': 'I denna uppsats föreslår vi ett effektivt ramverk för djupinlärning för flerspråkig och kodblandad visuell frågeställning. Den föreslagna modellen kan förutsäga svar från frågorna på hindi, engelska eller kodblandade (hingliska: hindi-engelska) språk. Majoriteten av de befintliga teknikerna för att besvara frågor (VQA) fokuserar enbart på enkla frågor. Många tillämpningar som medicinsk bildbehandling, turism, visuella assistenter kräver dock en flerspråkig modul för sina utbredda användningsområden. Eftersom det inte finns någon tillgänglig datamängd på engelsk-hindi VQA skapar vi först hindi- och kodblandade VQA-datauppsättningar genom att utnyttja språkens språkliga egenskaper. Vi föreslår en robust teknik som kan hantera den flerspråkiga och kodblandade frågan för att ge svaret mot den visuella informationen (bilden). För att bättre koda flerspråkiga och kodblandade frågor introducerar vi en hierarki av delade lager. Vi kontrollerar beteendet hos dessa delade lager genom en uppmärksamhetsbaserad mekanism för delning av mjuka lager, som lär oss hur delade lager appliceras på olika sätt för de olika språken i frågan. Vidare använder vår modell bi-linjär uppmärksamhet med en kvarvarande koppling för att smälta språk- och bildegenskaper. Vi utför omfattande utvärderings- och ablationsstudier för engelska, hindi och kodblandade VQA. Utvärderingen visar att den föreslagna flerspråkiga modellen uppnår toppmoderna prestanda i alla dessa miljöer.', 'ta': 'இந்த காகிதத்தில், நாம் பல மொழிகள் மற்றும் குறியீட்டு கலந்த பார்வை கேள்விக்கு ஒரு ஆழமான கற்றுக் கொள்ளும் சட The pro- posed model is capable of predicting answers from the questions in Hindi, English or Code- mixed (Hinglish: Hindi-English) languages.  வி- தேவை கேள்விக்கு பதில் (VQA) இருக்கும் தொழில்நுட்பத்தில் பெரும்பாலானவர்கள் ஒரு - கிலிஷ் கேள்வி ஆயினும், பல பயன்பாடுகள், மருத்துவ உருவாக்கத்தைப் போன்ற பயணம், பார்வையுடைய உதவியாளர்கள் தங்கள் விரிவான பயன்பாடுகளுக்கு பல மொழி செயல்படுத் @ info: whatsthis பார்வை தகவல்களுக்கு எதிராக விடையை கையாள முடியும் பல மொழிகள் மற்றும் குறியீட்டு கலப்பு கேள்வியை கையாள முடியும் ஒரு த பல மொழி மற்றும் குறியீட்டு கலக்கப்பட்ட கேள்விகளை சிறந்த குறியீட்டாக்க, நாம் பகிர்ந்த அடுக்குகளின் முனையமை நாம் இந்த பகிர்ந்த அடுக்குகளின் செயல்பாட்டை கட்டுப்படுத்துகிறோம் மென்மை அடுக்கு பங்கிடும் முறைமையால், இது கேள்வின் diffferent மொழிகளு மேலும், எங்கள் மாதிரி ஒரு மாதிரி கவனத்தை பயன்படுத்துகிறது மொழி மற்றும் படத்தின் குணங்களை குறைக்கும் மொழி மற்று நாங்கள் ஆங்கிலம், ஹின்டி மற்றும் குறியீடு கலந்த VQA க்கு விரிவான ஆய்வுகளை செய்கிறோம். இந்த அனைத்து அமைப்புகளிலும் பரிந்துரைக்கப்பட்ட பல மொழி மாதிரி மாதிரி மாதிரி செயல்பாட்டை பெறுகிறது.', 'ur': 'اس کاغذ میں، ہم ایک عمدہ عمیق سیکھنے کا فرمود پیش کرتے ہیں multilingual and code-mixed visual question reply کے لئے. مقررہ موڈل ہینڈی، انگلیسی یا کوڈ میں مختلف (ہینڈی-انگلیسی) زبانوں میں سے جواب کی پیش بینی کرنے کے قابل ہے. وی- سوئل سؤال جواب دینے (VQA) پر بہت سے موجود تکنیک ہیں صرف انگلیش سؤال پر تمرکز کریں۔ However, many applica tions- such as medical imaging, tourism, visual assistants require a multilinguality-enabled module for their widespread use. کیونکہ انگلیسی-ہندی VQA میں کوئی موجود ڈاٹ سٹ نہیں ہے، ہم پہلی بار ہندی اور کوڈ-میکسٹ VQA ڈاٹ سٹ بناتے ہیں، ان زبانوں کی زبان کی خصوصیت کے مطابق۔ ہم ایک مضبوط تکنولوژی نیک کی پیشنهاد کرتے ہیں جو بہت سی زبان اور کڈ ملائدہ سوال کی مدد کرسکتی ہے کہ visual information (تصویر) کے خلاف جواب دے۔ بہترین زبان اور کڈ میکس سوال کے لئے ہم شریک لہروں کے ایک حکومت پیش کریں گے۔ ہم ان مشترک لہروں کے رفتار کو کنترل کرتے ہیں ایک دھوپ لہروں کے شریک مکانیسم کے ذریعہ سے، جسے سمجھتا ہے کہ کس طرح مشترک لہروں کو سوال کے dif-ferent زبانوں کے لئے کاربرد کیا جاتا ہے۔ اور اس کے بعد، ہماری مدل دوسری خطی توجه کا استعمال کرتا ہے کہ زبان اور تصویر فیا- ترور کو پیدا کرنے کے لئے باقی رہنے والی اتصال کے ساتھ۔ ہم انگلیسی، ہینڈی اور کڈ-میکس VQA کے لئے بہت زیادہ ارزش اور آبلی تحقیقات کرتے ہیں. یہ ارزیابی دکھاتا ہے کہ پیشنهاد ملتی زبان کی موڈل یہ سب امستیوں میں موجود ہے۔', 'uz': "Bu qogʻozda biz bir necha tillar va kodlash mixidagi ko'plab savol javob berish uchun juda foydali o'rganish qandaydi. Koʻrsatilgan model Hindiston, Ingliz yoki kodi mixed (Hinglish: Hindi- Ingliz tilida) savollaridan javob beradi. Vi- suv savol javobi (VQA) haqida mavjud teknologilar faqat En- glish savollariga fokus. Ammo, ko'pchilik rasmlari, tourism, ko'rish yordamchilari uchun multiliy ishlatadigan moduli kerak. Ingliz- Hindi VQA tilida maʼlumotlar oʻrnatilgan boʻlishi mumkin, birinchi marta Hindi va Code- mixed VQA maʼlumotlar tarkibini foydalanish mumkin. Biz ko'p tillar va kodlash mix savollarini qo'llash mumkin, ko'rinish haqida javob berish mumkin. To better encode the multilingual and code-mixed questions, we introduce a hierarchy of shared layers.  Biz shu bilan bog'liq qatlamlarning xususiyatlarini boshqaramiz, bu savol uchun qanday bog'liq qanday qo'llangan qanday qo'llanmalar qo'llaniladi. Koʻrsatgich, bizning modelimiz tilning va rasm moslamalarini yozib olish uchun boshqa aloqa bilan foydalanadi. Biz ingliz, Hindi va Code-miksus VQA uchun kengaytirish va qoidalarni bajaramiz. Qiymatni ko'rsatadi, pulni bir necha tillar modeli shu moslamalarda shaxsiy ishni bajaradi.", 'vi': 'Trong tờ giấy này, chúng tôi đề xuất một cơ sở học sâu sắc hiệu quả cho việc trả lời các câu hỏi hình ảnh đa dạng. Mô hình được sắp xếp có khả năng dự đoán câu trả lời từ câu hỏi bằng tiếng Hindi, Anh hay mã trộn (Hinglish: tiếng Hindi-English). Hầu hết các kỹ thuật hiện thời về Trả lời các câu hỏi kiểu VI (VQA) chỉ tập trung vào các câu hỏi kiểu En- glish. Tuy nhiên, nhiều ứng dụng như phim y tế, du lịch, các nhân viên trực quan yêu cầu một mô-đun có khả năng phát triển nhiều thứ. Vì không có bộ dữ liệu nào có sẵn trong hệ thống VQA Anh-Hindi, chúng ta đầu tiên tạo dữ liệu VQA hỗn hợp mã bằng cách khai thác các đặc tính ngôn ngữ này. Chúng tôi đề nghị một công nghệ mạnh mẽ có khả năng xử lý câu hỏi đa dạng và mã trộn để có câu trả lời dựa trên hình ảnh. Để mã hóa các câu hỏi đa dạng và mã trộn tốt hơn, chúng tôi giới thiệu một hệ thống cấp độ chia sẻ. Chúng tôi kiểm soát hành vi của những lớp xã hội này bằng một cơ chế chia sẻ lớp mềm dựa trên sự chú ý, nó học cách chia sẻ lớp được áp dụng theo cách khác nhau cho ngôn ngữ khác nhau của câu hỏi. Hơn nữa, mô hình của chúng ta sử dụng sự chú ý lưỡng tuyến với kết nối còn lại để làm nóng ngôn ngữ và ảnh. Chúng tôi thực hiện nghiên cứu đánh giá và giải thoát rộng rãi về tiếng Anh, tiếng Hindi và mã trộn VHA. Bản đánh giá này cho thấy mô hình đa dạng đề xuất đạt đến trình độ cao nghệ thuật trong tất cả các thiết lập này.', 'bg': 'В настоящата статия предлагаме ефективна рамка за дълбоко обучение за многоезично и кодово смесено визуално отговаряне на въпроси. Предложеният модел е способен да предвижда отговори от въпросите на хинди, английски или кодово смесени езици (хинди-английски). По-голямата част от съществуващите техники за визуално отговаряне на въпроси (VQA) се фокусират само върху ясни въпроси. Въпреки това, много приложения като медицинско изображение, туризъм, визуални асистенти изискват многоезичен модул за широко разпространеното им използване. Тъй като няма наличен набор от данни в английско-хинди ВКВ, ние първо създаваме хинди и кодово смесени ВКВ набори от данни, като използваме езиковите свойства на тези езици. Предлагаме стабилна технология, способна да се справи с многоезичния и кодово смесен въпрос, за да даде отговор срещу визуалната информация (изображение). За да кодираме по-добре многоезичните и смесените с кодове въпроси, въвеждаме йерархия на споделените слоеве. Контролираме поведението на тези споделени слоеве чрез механизъм за споделяне на меки слоеве, базиран на вниманието, който научава как споделените слоеве се прилагат по различен начин за различните езици на въпроса. Освен това нашият модел използва двулинейно внимание с остатъчна връзка за сливане на езика и характеристиките на изображението. Извършваме обширни проучвания за оценка и аблация на английски, хинди и кодово смесени ВКА. Оценката показва, че предложеният многоезичен модел постига най-съвременни резултати във всички тези условия.', 'nl': 'In dit artikel stellen we een effectief deep learning framework voor meertalig en code-gemengd visueel antwoord op vragen voor. Het voorgestelde model kan antwoorden voorspellen op de vragen in Hindi, Engels of Code gemengd (Hinglish: Hindi-Engels) talen. Het merendeel van de bestaande technieken op het gebied van Vi- sual Question Respwering (VQA) is gericht op eenvoudige vragen. Veel toepassingen zoals medische beeldvorming, toerisme, visuele assistenten vereisen echter een meertaligheid-enabled module voor hun wijdverbreide gebruik. Omdat er geen dataset beschikbaar is in Engels-Hindi VQA, maken we eerst Hindi en Code-gemengde VQA datasets door gebruik te maken van de linguïstische eigenschappen van deze talen. Wij stellen een robuuste techniek voor die in staat is om de meertalige en codegemengde vraag aan te pakken om het antwoord te geven tegen de visuele informatie (beeld). Om de meertalige en code-gemengde vragen beter te coderen, introduceren we een hiërarchie van gedeelde lagen. We controleren het gedrag van deze gedeelde lagen door een attentie-gebaseerd soft layer sharing mechanisme, dat leert hoe gedeelde lagen op verschillende manieren worden toegepast voor de verschillende talen van de vraag. Verder maakt ons model gebruik van bi-lineaire aandacht met een restverbinding om de taal- en beeldeigenschappen samen te voegen. Wij voeren uitgebreide evaluatie- en ablatiestudies uit voor Engels, Hindi en Code-gemengde VQA. Uit de evaluatie blijkt dat het voorgestelde meertalige model in al deze omgevingen state-of-the-art prestaties levert.', 'da': 'I denne artikel foreslår vi en effektiv grundlæringsramme for flersproget og kodeblandet visuel spørgsmålsbesvarelse. Den foreslåede model er i stand til at forudsige svar fra spørgsmålene på hindi, engelsk eller kodeblandet (hinglisk: hindi-engelsk) sprog. Størstedelen af de eksisterende teknikker til besvarelse af spørgsmål (VQA) fokuserer udelukkende på små spørgsmål. Mange ansøgninger som f.eks. medicinsk billedbehandling, turisme, visuelle assistenter kræver dog et flersproget modul til deres udbredte anvendelse. Da der ikke er noget tilgængeligt datasæt på engelsk-hindi VQA, skaber vi først hindi og kodeblandede VQA datasæt ved at udnytte sprogenes sproglige egenskaber. Vi foreslår en robust teknologi, der er i stand til at håndtere det flersprogede og kodeblandede spørgsmål for at give svaret mod den visuelle information (billede). For bedre at kode de flersprogede og kodeblandede spørgsmål indfører vi et hierarki af delte lag. Vi kontrollerer opførselen af disse delte lag ved hjælp af en opmærksomhedsbaseret mekanisme til deling af bløde lag, der lærer, hvordan delte lag anvendes på forskellige måder for spørgsmålets forskellige sprog. Desuden bruger vores model bi-lineær opmærksomhed med en restforbindelse til at fusionere sprog- og billedegenskaber. Vi udfører omfattende evaluerings- og ablationsstudier for engelsk, hindi og kodeblandet VQA. Evalueringen viser, at den foreslåede flersprogede model opnår avancerede resultater i alle disse indstillinger.', 'de': 'In diesem Beitrag schlagen wir ein effektives Deep Learning Framework für die Beantwortung mehrsprachiger und code-mixed visueller Fragen vor. Das vorgestellte Modell ist in der Lage, Antworten auf die Fragen in Hindi, Englisch oder Code-Mixed (Hinglisch: Hindi-Englisch) Sprachen vorherzusagen. Die Mehrheit der bestehenden Techniken zur visuellen Fragebeantworterung (VQA) konzentrieren sich nur auf einfache Fragen. Viele Anwendungen wie medizinische Bildgebung, Tourismus, visuelle Assistenten benötigen jedoch für ihren weit verbreiteten Einsatz ein mehrsprachiges Modul. Da es in Englisch-Hindi VQA keinen verfügbaren Datensatz gibt, erstellen wir zunächst Hindi und Code-Mixed VQA Datensätze, indem wir die linguistischen Eigenschaften dieser Sprachen ausnutzen. Wir schlagen eine robuste Technologie vor, die in der Lage ist, die mehrsprachige und code-gemischte Frage zu bearbeiten, um die Antwort auf die visuelle Information (Bild) zu geben. Um die mehrsprachigen und code-mixed Fragen besser zu kodieren, führen wir eine Hierarchie von geteilten Ebenen ein. Wir steuern das Verhalten dieser geteilten Schichten durch einen aufmerksamkeitsbasierten Soft Layer Sharing Mechanismus, der lernt, wie geteilte Schichten auf unterschiedliche Weise für die verschiedenen Sprachen der Frage angewendet werden. Weiterhin nutzt unser Modell bi-lineare Aufmerksamkeit mit Restverbindung, um Sprache und Bild miteinander zu verschmelzen. Wir führen umfangreiche Evaluations- und Ablationsstudien für Englisch, Hindi und Code-Mixed VQA durch. Die Auswertung zeigt, dass das vorgeschlagene mehrsprachige Modell in all diesen Settings den neuesten Stand der Technik erreicht.', 'hr': 'U ovom papiru predlažemo efikasno duboko učenje okvira za odgovor na višejezičko i kodirano vizualno pitanje. Propozirani model je sposoban predvidjeti odgovore iz pitanja na hindskim, engleskim ili mještenim kodovima (Hinglish: Hindi-English). Većina postojećih tehnika na odgovoru na Vi- uobičajene pitanja (VQA) fokusirala se samo na pitanja En- glish. Međutim, mnogi aplikaciji poput medicinske slike, turizma, vizualne pomoćnike zahtijevaju modul omogućen na multijezičnost za njihove široke upotrebe. Budući da nema dostupnih podataka na engleskom-hindskom VQA-u, prvo stvorimo indijske i kodirane VQA podatake koristeći jezičke vlasništvo tih jezika. Predlažemo jačan tehnički brak sposoban za rješavanje multijezičkog i mješanog pitanja za odgovor protiv vizuelnih informacija (slika). Da bi bolje kodirali multijezičke i kod-miješane pitanja, predstavljamo hijerarhiju zajedničkih slojeva. Kontroliramo ponašanje ovih zajedničkih slojeva mehanizam dijeljenja slojeva na temelju pažnje, koji uči kako se zajednički slojevi primjenjuju na različite načine za jezike pitanja. Nadalje, naš model koristi dvolinearnu pažnju sa ostatkom povezanjem kako bi spasili jezik i slike fea-tures. Proučavamo široke procjene i aktivacije za engleske, hindske i kodeksne VQA. Procjenjivanje pokazuje da predloženi multijezički model postigne postupak stanja umjetnosti u svim tim nastavama.', 'id': 'Dalam kertas ini, kami mengusulkan cadangan belajar dalam yang efektif untuk menjawab pertanyaan visual berbagai bahasa dan kode-campuran. Model pro-posed mampu memprediksi jawaban dari pertanyaan dalam bahasa Hindi, Inggris atau Code-mixed (Hinglish: Hindi-English). Kebanyakan teknik yang ada pada jawaban pertanyaan vizual (VQA) fokus pada pertanyaan En- glish saja. Namun, banyak aplikasi seperti gambar medis, turis, asisten visual membutuhkan modul yang diaktifkan multibahasa untuk penggunaan yang luas. Karena tidak ada dataset tersedia dalam VQA Inggris-Hindi, kita pertama-tama menciptakan dataset VQA Hindi dan Code-Mixed dengan mengeksploitasi properti bahasa bahasa-bahasa ini. Kami mengusulkan teknologi yang kuat yang mampu menangani pertanyaan multibahasa dan kode-campuran untuk memberikan jawaban terhadap informasi visual (gambar). Untuk mengkode lebih baik pertanyaan multibahasa dan kode-campuran, kami memperkenalkan hierarki dari lapisan berbagi. We control the behaviour of these shared layers by an attention-based soft layer sharing mechanism, which learns how shared layers are applied in different ways for the dif- ferent languages of the question.  Selain itu, model kami menggunakan perhatian bi-linear dengan koneksi sisa untuk menggabungkan bahasa dan gambar bulur. Kami melakukan studi ekstensif evaluasi dan ablasi untuk bahasa Inggris, Hindi dan Kode-campuran VQA. Evaluasi menunjukkan bahwa model berbagai bahasa yang diusulkan mencapai prestasi terbaik dalam semua pengaturan ini.', 'sw': 'In this paper, we propose an effective deep learning framework for multilingual and code- mixed visual question answering.  Mradi huo unaodhibitiwa una uwezo wa kutabiri majibu kutoka kwenye maswali yanayohusiana na Kihindi, Kiingereza au Code (Hinglish: Kiingereza). Wengi wa mbinu zilizopo kwenye jibu la swali la Vi-suala (VQA) linalenga tu maswali ya En-glish. Hata hivyo, matumizi mengi kama vile picha za kitabibu, utalii, wasaidizi wa kuona wanahitaji vifaa vinavyowezekana kwa matumizi mengi. Kwa kuwa hakuna taarifa zinazopatikana kwa lugha za Kiingereza-Hindi VQA, kwanza tunatengeneza seti za data zinazochanganyika kwa Kihindi na Code kwa kutumia utaalam wa lugha hizi. Tunazipendekeza teknolojia ya ubaguzi- yenye uwezo wa kukabiliana na swali linalochanganyika kwa lugha nyingi na kodi ili kutoa jibu dhidi ya taarifa za kuona (picha). Ili kutangaza zaidi maswali yanayochanganyika na lugha mbalimbali, tunaonyesha makusanyiko ya vipande vinavyoshirikiana. Tunawadhibiti tabia za vipande hivi vilivyosambazwa na mfumo wa kushirikiana na vipande vya kijinga, ambao unajifunza vipi vipi vilivyotumiwa kwa njia tofauti kwa lugha zenye uzito wa swali hilo. Zaidi ya hayo, mifano yetu inatumia mtazamo wa mistari kwa kutumia kiungo cha kudumu ili kupunguza lugha na picha. Tunafanya tafiti za kutathmini na kuboresha kwa ajili ya lugha ya Kiingereza, Hindi na Code zilizochanganyika na VQA. Tathmini hiyo inaonyesha kuwa muundo uliopendekezwa wa lugha nyingi unafanikiwa utendaji wa hali ya sanaa katika mazingira haya yote.', 'ko': '본고에서 우리는 효과적인 다중 언어와 코드가 혼합된 시각적 문답 심도 있는 학습 구조를 제시했다.제시된 모델은 인디언, 영어 또는 코드 혼합(Hinglish:Hindi-English) 언어 문제의 답을 예측할 수 있다.기존 가상문답(VQA) 기술은 대부분 영어 문제에만 초점을 맞췄다.그러나 많은 응용, 예를 들어 의료 영상, 관광, 시각 조수 등은 다양한 언어를 지원하는 모듈을 필요로 하여 그들의 광범위한 사용을 만족시켜야 한다.영어 인디언 VQA에 사용할 수 있는 데이터 집합이 없기 때문에 우리는 먼저 이러한 언어의 언어 특성을 이용하여 인디언과 코드가 혼합된 VQA 데이터 집합을 만든다.우리는 다중 언어와 코드가 혼합된 문제를 처리하고 시각 정보(영상)에 따라 답을 제공할 수 있는 강력한 기술을 제시했다.다중 언어와 코드가 혼합된 문제를 더욱 잘 인코딩하기 위해 우리는 공유층의 차원 구조를 도입했다.우리는 주의력을 바탕으로 하는 소프트 공유 메커니즘을 통해 이러한 공유층의 행위를 통제하고 이 메커니즘은 공유층이 어떻게 서로 다른 방식으로 문제의 서로 다른 언어에 응용되는지 배운다.그 밖에 우리 모델은 쌍선형 주의와 잉여 연결을 사용하여 언어와 이미지 특징을 융합시킨다.우리는 영어, 인디언, 코드가 혼합된 VQA에 대해 광범위한 평가와 연구를 진행했다.평가에 따르면 제시된 다중 언어 모델은 모든 환경에서 가장 선진적인 성능에 이르렀다.', 'fa': 'در این کاغذ، ما پیشنهاد می\u200cکنیم یک چهارچهار عمیق یادگیری برای جواب سوال\u200cهای بینایی که با زبان و کد مختلف شده است. مدل پیش\u200cنمایش قادر است جواب\u200cها را از سوال\u200cهای هندی، انگلیسی یا کد مختلف (Hinglish: Hindi-English) پیش\u200cنمایش دهد. بیشتر تکنیک\u200cهای موجود در پاسخ سوال وی- عادی (VQA) فقط روی سوال\u200cهای انگلیش تمرکز می\u200cکند. با این حال، بسیاری از کاربردها- مثل تصویر پزشکی، توریسم، دستیاران دیده\u200cای برای استفاده\u200cهای گسترده\u200cشان نیاز دارند که مدول\u200cهای بسیاری از زبان\u200cهای فعال شده\u200cاند. چون مجموعه داده\u200cهای موجود در انگلیسی-هندی VQA وجود ندارد، اول ما داده\u200cهای VQA با استفاده از ویژه\u200cهای زبان\u200cشناسی این زبان\u200cها هندی و کد پیوسته ایجاد می\u200cکنیم. ما پیشنهاد می\u200cکنیم یک تکنولوژی قوی که قادر به مدیریت سؤال متوسط زبان و کد است تا پاسخ بر خلاف اطلاعات دیده (تصویر) را بدهیم. برای بهتر کردن سوال\u200cهای مختلف زبان و کد\u200cهای مختلف، یک سطح مشترک را معرفی می\u200cکنیم. ما رفتار این لایه\u200cهای مشترک را کنترل می\u200cکنیم با یک مکانیسم مشترک لایه\u200cهای نرم بر روی توجه، که می\u200cفهمیم چگونه لایه\u200cهای مشترک به روش\u200cهای مختلف برای زبانهای dif-ferent سوال کاربرد می\u200cشوند. بعلاوه، مدل ما توجه دو خط با ارتباط باقی مانده برای ترکیب زبان و تصویر فیا- ترکیب استفاده می کند. ما تحقیقات گسترده و فعالیت برای انگلیسی، هندی و کد مختلف VQA انجام می دهیم. این ارزیابی نشان می دهد که مدل چندین زبان پیشنهاد به انجام وضعیت هنری در تمام این تنظیمات رسیده است.', 'tr': 'Bu kağıtda, çoklu diller ve kodlar için etkileşimli bir şekilde karışık görüntü sorular cevap teklif ediyoruz. Prowasyonly nusga Hindistança, Iňlisçe ýa-da Karışma dilinden jogaplary önlemek mümkin edip biler. Vi-sual sorag cevaplaması üzerindeki mevcut tekniklerin çoğunu sadece en-gliş sorulara odaklandırır. Ýöne köp uygulamalar (tıbbi imaging, turizm, görsel kömekçiler) ýaly köp dilli işleýän modüller üçin örän köp dilli işleýän modüli gerek. Iňlisçe-hindi VQA dilinde hiç hili maglumatlar ýok sebäbi, biz ilkinji gezek bu dilleriň lingwistiki häsiýetlerini ulanarak Hindi we Kod karmaşgalan VQA sanlaryny bejerdik. Biz görsel maglumat (surat) bilen jogap berip başarmak üçin güçlü bir teknolojik teknolojini taslaýarys. Birnäçe diller we ködlemeler karışık soraglary gowurak üçin, paylaşyk kalamlaryň iýerarhiýasyny tanyşdyrýarys. Biz bu paylaşyk katlaryň davranışyny soragyň dif-ferent dilleri üçin nähili paylaşyk edilýäni bilýäris. Mundan soňra, biziň nusgamyz çyzgyly üns berip dili we surat çykyşlaryny birleştirmek üçin çyzgyly üns ulanýar. Biz Iňlisçe, Hindiler we Kod karıştırılýan VQA üçin örän çözümleme we çözgürlük öwrenmelerini gerçekleýäris. Ýardamçylyk görkezýär ki, bu düzümlerde teklip eden bir näçe dil nusgasynyň durumyny üstün edip bilýär.', 'am': 'በዚህ ፕሮግራም፣ ለብዙ ቋንቋዎች እና ለኮድ የተቀላቀለ የራእይ ጥልቅ ትምህርት ፍሬሜዎችን ለመቀበል እናዘጋጅታለን፡፡ የፖስታ ሞዴል በHindi፣ እንግሊዘኛ ወይም Code-mixed (Hinglish: Hindi-እንግሊዘኛ) ቋንቋዎችን ለመቀበል ይችላል፡፡ የቪQA ጥያቄ መልስ (VQA) በተገኘው ጥያቄዎች ብዙዎቹ በዓይን-glish ጥያቄዎች ብቻ ላይ ትኩረት፡፡ ነገር ግን ብዙ ፕሮግራም-ፕሮግራሞች እንደ መድኃኒት አካባቢ፣ ጉዞ፣ የራእይ ረዳቶች ለመሰፋት በተቃራኒው ተጠቃሚዎች የብዙ ቋንቋ ተግባር ያስፈልጋሉ፡፡ በንግልዝኛ-Hindi VQA ውስጥ ዳታ-setet እንደሌለ በመጀመሪያ የHindi እና Code-mixed VQA ዳታዎችን በመጠቀም እነዚህን ቋንቋዎች የቋንቋዎች ስህተት በመጠቀም እናደርጋለን፡፡ የራእይ መረጃ (ምስል) ላይ መልስ ለመስጠት የሚችለውን የቋንቋ እና የኮድ ቋንቋን ለመቀላቀል የሚችለውን የሮቦት ቴክኖጂ እናስባለን፡፡ To better encode the multilingual and code-mixed questions, we introduce a hierarchy of shared layers.  የዚህን ተካፋፊ ደረጃዎች የአካባቢ ደረጃን በመጠቀም እናስቆጣለን፡፡ ከዚህም በላይ ሞዴሌያችን የቋንቋ እና የምስል ግንኙነትን ለመጠቀም የባይlineር ትኩረት ይደረጋል፡፡ በንግግሊዝኛ፣ Hindi እና Code-Mixed VQA (VQA) የተለየውን የአፍላጎት ማስታወቂያ እና የአደጋጋጋጅነት አስተማርነው እናደርጋለን፡፡ ማስታወቂያው የተዘጋጀው የቋንቋ ቋንቋ ሞዴል በዚህ ባሕላት ሁሉ የ-የ-የ-አርእስት ድረግ እንዲደርስ ያሳያል፡፡', 'af': "In hierdie papier, voorstel ons 'n effektief diep leer raamwerk vir multitaal en kode gemengde visuele vraag antwoord. Die proposeerde model is in staat om antwoorde te voorskou van die vraagte in Hindi, Engels of Kode- gemengde (Hinglish: Hindi- Engels) tale. Die meeste van die bestaande teknike op Vi- gewone vraag antwoord (VQA) fokus slegs op En- glish vrae. Maar baie aansoek- toepassings soos mediese beeld, tourisme, visuele assistente benodig 'n multilingualiteit-geaktiveerde module vir hul breeduitbreide gebruike. Omdat daar geen beskikbaar datastel in Engels-Hindi VQA is nie, skep ons eerste Hindi en Code-gemengde VQA datastel deur die lingvisse eienskappe van hierdie tale te gebruik. Ons voorstel 'n kragtige teknologie- nique wat moontlik is om die multilinglike en kodgemengde vraag te hanteer om die antwoord teen die visuele inligting (beeld) te verskaf. Om die meerderlingse en kodgemengde vrae te beter kodeer, introduseer ons 'n hierarkie van gedeelde laag. Ons beheer die gedrag van hierdie gedeelde laag deur 'n aandag-gebaseerde sagte laag deel mekanisme, wat leer hoe gedeelde laag aanwend word in verskillende maniere vir die dif- ferent tale van die vraag. Verder, ons model gebruik bi-lineêre aandag met 'n oorblyfstelike verbinding om die taal en beeld fea-tures te verbind. Ons doen uitbreidige evaluering en ablasie studies vir Engels, Hindi en kode gemengde VQA. Die evaluasie wys dat die voorgestelde multilinglike model in alle hierdie instellings staat-van-kuns-prestasie bereik.", 'sq': 'Në këtë letër, propozojmë një kuadër të efektshëm mësimi të thellë për përgjigjen e pyetjeve vizuale të shumëgjuhëshme dhe të përziera me kod. Modeli i propozuar është i aftë të parashikojë përgjigjet nga pyetjet në gjuhët Hindi, Anglisht apo Code- mixed (Hinglish: Hindi-English). Shumica e teknikave ekzistuese në përgjigjet vizuale të pyetjeve (VQA) përqëndrohen vetëm në pyetjet e shkëlqyera. Megjithatë, shumë aplikacione të tilla si imazhi mjekësor, turizmi, asistentët vizualë kërkojnë një modul të mundësuar nga shumëgjuhësia për përdorimin e tyre të gjerë. Sepse nuk ka të dhëna në dispozicion në anglisht-Hindi VQA, ne fillimisht krijojmë të dhëna në gjuhë dhe në kod të përzier VQA duke shfrytëzuar pronësitë gjuhësore të këtyre gjuhëve. Ne propozojmë një teknikë të fortë të aftë për të trajtuar pyetjen shumëgjuhëse dhe të përzier me kode për të dhënë përgjigjen kundër informacionit vizual (imazhi). Për të koduar më mirë pyetjet shumëgjuhësore dhe të përziera me kode, ne prezantojmë një hierarki të shtresave të përbashkëta. Ne kontrollojmë sjelljen e këtyre shtresave të përbashkëta me një mekanizëm të ndarjes së shtresave të buta bazuar në vëmendje, i cili mëson se si shtresat e përbashkëta aplikohen në mënyra të ndryshme për gjuhët e ndryshme të pyetjes. Për më tepër, modeli ynë përdor vëmendjen dy-lineare me një lidhje të mbetur për të fusionuar gjuhën dhe imazhet. Ne kryejmë studime ekstensive të vlerësimit dhe ablacionit për anglisht, Hindi dhe Kod- të përzier VQA. Vlerësimi tregon se modeli shumëgjuhës i propozuar arrin performancë më të lartë në të gjitha këto rregullime.', 'hy': "Այս թղթի մեջ մենք առաջարկում ենք մի արդյունավետ խորը սովորելու շրջանակ բազլեզու և կոդի-խառնված վիզուալ հարցերի պատասխանելու համար: Հինդի, անգլերենի կամ կոդ-խառնված (Հինդի-անգլերենի) հարցերից պատասխաններ կանխատեսելու կարողանում է: Վիզուալ հարցերի պատասխանի (VQA) մեծամասնությունը կենտրոնանում է միայն Էնգլիշ հարցերի վրա: Այնուամենայնիվ, շատ ծրագրեր, ինչպիսիք են բժշկական պատկերացումը, թուրիզմը, վիզուալ օգնականները, անհրաժեշտ են բազմալեզվությամբ հնարավոր մոդուլներ իրենց տարածված օգտագործման համար: Քանի որ անգլերեն-հնդիկ VQA-ի մեջ հասանելի տվյալների համակարգ չկա, մենք առաջինը ստեղծում ենք հնդիկ և կոդի-խառնված VQA-ի տվյալների համակարգ օգտագործելով այս լեզուների լեզվաբանական հատկությունները: Մենք առաջարկում ենք ուժեղ տեխնոլոգիա, որը կարող է լուծել բազլեզու և կոդի խառնված հարցը' պատասխան տալու տեսողական տեղեկատվության դեմ: Մենք ավելի լավ կոդավորելու համար բազլեզու և կոդի խառնված հարցերը ներկայացնում ենք ընդհանուր շերտերի հիերարխիան: Մենք վերահսկում ենք այս ընդհանուր շերտերի վարքագիծը ուշադրության հիմնված փափուկ շերտի կիսման մեխանիզմի միջոցով, որը սովորում է, թե ինչպես են ընդհանուր շերտերը կիրառվում հարցի տարբեր լեզուների համար տարբեր ձևերով: Ավելին, մեր մոդելը օգտագործում է երկգծային ուշադրություն, որտեղ մնացած կապ կապված է լեզվի և պատկերի փետուրների խառնելու համար: Մենք կատարում ենք անգլերենի, հնդինդի և կոդի-խառնված VQA-ի մեծ գնահատման և աբլացիայի ուսումնասիրություններ: Արժեքը ցույց է տալիս, որ առաջարկված բազլեզու մոդելը հասնում է ամենաբարձր արդյունքներին այս բոլոր միջոցներում:", 'az': 'Bu kağızda, çoxlu dil və kodla karışıq görünüş sual cavab vermək üçün effektiv bir öyrənmə çerçivi təklif edirik. Proposed modeli Hindi, İngilizce və Kod-karıştırılmış (Hindi-İngilizce) dillərin cavablarını öyrənə bilər. Vi-sual sual cavab vermək (VQA) barəsindəki mevcut tekniklərin çoxunu ancaq En-glish suallarına odaqlanır. Lakin, təhsil görüntüsü, turizm, göylər köməkçiləri üçün çoxlu dil qabiliyyətli modulu istəyirlər. İngiliz Hindi VQA dillərin dili özelliklərini istifadə edərək, ilk dəfə Hindi və Kod-karışıq VQA veri quruları yaratdıq. Biz çoxlu dil və kodla karışıq sualları müdafiə edə biləcək güclü bir tekniki təklif edirik. Çoxlu dil və kodla karışmış sualları daha yaxşı kodlamaq üçün, paylaşılan səviyyələrin hierarhiyasını tanıyırıq. Biz bu paylaşılmış səviyyələrin davranışlarını soruşunun dif-ferent dillərinə nə qədər paylaşıldığını öyrənən yumuşaq səviyyə paylaşım mehānismi ilə kontrol edirik. Daha sonra, modellərimiz dili və görüntü fea-türünü birləşdirmək üçün iki-linear təsiri ilə istifadə edir. Biz İngilizce, Hindi və Kod-karışıq VQA üçün geniş değerlendirmə və ablasiya təhsil etdik. Bu değerlendirmə göstərir ki, təbliğ edilmiş çoxlu dil modeli bütün bu qurğularda mövcud-sanat performansını başa çatdırır.', 'ca': "En aquest paper, proposem un marc eficaç d'aprenentatge profund per respondre a preguntes visuals multilingües i combinades amb codi. El model proposat és capaç de predir respostes de les preguntes en Hindi, anglès o Code-Mixed (Hinglish: Hindi-English). La majoria de les tècniques existents en resposta a preguntes visuals (VQA) es centren només en preguntes en anglès. Tot i així, moltes aplicacions com la imatge mèdica, el turisme, els assistents visuals requereixen un módul multilingüístic per als seus usos generalitzats. As there is no available dataset in English-Hindi VQA, we firstly create Hindi and Code-mixed VQA datasets by exploiting the linguistic properties of these languages.  Proposem una tecnologia robust a capaç de manejar la pregunta multillengua i combinada de codis per proporcionar la resposta contra la informació visual (imatge). Per codificar millor les preguntes multilingües i combinades amb codis, introduim una jerarquia de capes compartides. Controlem el comportament d'aquestes capes compartides amb un mecanisme de compartir capes suaves basat en l'atenció, que aprene com es aplican capes compartides de diferents maneres per a les llengües diferents de la pregunta. També, el nostre model utilitza atenció bi-linear amb una connexió residual per fusionar les plomes de llenguatge i imatge. Fem extensos estudis d'evaluació i ablació per anglès, Hindi i Code-Mixed VQA. L'avaluació mostra que el model multillenguatge proposat aconsegueix un rendiment més avançat en tots aquests entorns.", 'bs': 'U ovom papiru predlažemo efikasno duboko učenje okvira za odgovor na višejezičko i kodirano vizualno pitanje. Propozitivni model je sposoban predvidjeti odgovore iz pitanja na hindskim, engleskim ili kodskim jezicima. Većina postojećih tehnika na odgovoru na Vi-uobičajene pitanja (VQA) fokusirala se samo na pitanja En-glish. Međutim, mnoge aplikacije poput medicinske slike, turizma, vizualne asistente zahtijevaju modul omogućen na multijezičnost za njihove široke upotrebe. Zato što nema dostupnih podataka na engleskom-hindskom VQA-u, prvo stvorimo indijske i kodirane VQA podatake koristeći jezičke vlasništvo tih jezika. Predlažemo jačan tehnički brak sposoban za rješavanje multijezičkog i mešanog pitanja za odgovor protiv vizuelnih informacija (slika). Da bismo bolje kodirali multijezičke i kodirane pitanja, predstavljamo hijerarhiju zajedničkih slojeva. Kontroliramo ponašanje ovih zajedničkih slojeva mehanizam dijeljenja slojeva na pažnji, koji nauči kako se dijeljeni slojevi primjenjuju na različite načine za jezike pitanja. Nadalje, naš model koristi dvolinearnu pažnju sa ostatkom veze za spajanje jezika i fotografskih fea-turea. Izvodimo široke procjene i aktivacije za engleske, hindske i kodeksne VQA. Procjenjivanje pokazuje da predloženi multijezički model postigne postupak stanja umjetnosti u svim tim nastavacima.', 'cs': 'V tomto článku navrhujeme efektivní rámec hlubokého učení pro vícejazyčné a kódově smíšené vizuální odpovědi na otázky. Navržený model je schopen předpovídat odpovědi z otázek v hindštině, angličtině nebo kódově smíšených jazycích (hindština-angličtina). Většina stávajících technik na vizuální odpovědi na otázky (VQA) se zaměřuje pouze na základní otázky. Nicméně mnoho aplikací, jako jsou lékařské zobrazování, cestovní ruch, vizuální asistenti, vyžaduje pro své široké použití modul s podporou vícejazyčnosti. Vzhledem k tomu, že v anglicko-hindštině VQA neexistuje žádný datový soubor, nejprve vytváříme hindštinu a kódově smíšené VQA datové sady využitím jazykových vlastností těchto jazyků. Navrhujeme robustní techniku schopnou zvládnout vícejazyčnou a kódově smíšenou otázku a poskytnout odpověď na vizuální informaci (obrázek). Pro lepší kódování vícejazyčných a kódově smíšených otázek zavádíme hierarchii sdílených vrstev. Chování těchto sdílených vrstev řídíme mechanismem sdílení měkkých vrstev založeným na pozornosti, který se naučí, jak jsou sdílené vrstvy aplikovány různými způsoby pro různé jazyky otázky. Náš model dále využívá bi-lineární pozornost se zbytkovým propojením pro spojení jazykových a obrazových vlastností. Provádíme rozsáhlé hodnotící a ablační studie pro angličtinu, hindštinu a kódově smíšené VQA. Vyhodnocení ukazuje, že navržený vícejazyčný model dosahuje nejmodernějšího výkonu ve všech těchto prostředích.', 'bn': 'এই কাগজটিতে আমরা বহুভাষা এবং কোড মিশ্রিত দৃষ্টিভঙ্গি প্রশ্নের উত্তরের জন্য একটি কার্যকর গভীর শিক্ষার কার্যক্রম প্ প্রস্তাবিত মডেল হিন্দি, ইংরেজি অথবা কোড মিশ্রিত (হিঙ্গ্লিশ: হিন্দি ইংরেজী) ভাষায় প্রশ্নের উত্তর ভবিষ্যদ্বাণী করতে সক্ষম। ভি- মামলা প্রশ্নের উত্তর (ভিকিউএ) নিয়ে বেশীরভাগ বিদ্যমান প্রযুক্তিগুলো শুধুমাত্র এন- গ্লিশ প্রশ্নের উপর মনোযোগ দিয়ে তবে অনেক অ্যাপ্লিকেশন, যেমন চিকিৎসা চিত্র, পর্যটন, দৃশ্যমান সহকারীদের তাদের ব্যবহারের জন্য একটি বহুভাষিক-সক্রিয় মডিউল প্রয়োজন। যেহেতু ইংরেজী হিন্দি ভিকিউএ-এর কোনো ডাটাসেট নেই, আমরা প্রথমে এই ভাষার ভাষার ভাষার ভাষার বৈশিষ্ট্য ব্যবহার করে হিন্দি এবং কোড মিশ্রিত আমরা একটি রোবট প্রযুক্তির প্রস্তাব করছি যা মাল্টিভাষা এবং কোড মিশ্রিত প্রশ্ন হাতে সক্ষম, যাতে দৃশ্য তথ্য (ছবি) বিরুদ্ধে উত্তর মাল্টিভাষা এবং কোড মিশ্রিত প্রশ্নের জন্যে ভালো কোড করার জন্য, আমরা শেয়ার করা স্তরের একটি হিয়ারেরার্কি পরিচিত করি। আমরা এই প্রশ্নের প্রযুক্তিগত ভাষার জন্য ভিন্ন ভিন্ন ভিত্তিক কাঠামো শেয়ার করার মাধ্যমে মনোযোগ প্রদান করি কাঠামোর আচরণ নিয়ন্ত্রণ করি। এছাড়াও, আমাদের মডেল বাই-লাইনারের মনোযোগ ব্যবহার করে ভাষা এবং ছবির বৈশিষ্ট্য ব্যবহার করে। আমরা ইংরেজী, হিন্দি এবং কোড মিশ্রিত ভিকিউএ-এর জন্য বিস্তারিত মূল্য এবং আগুনের গবেষণা শুরু করি। এই মূল্যায়ন দেখা যাচ্ছে যে প্রস্তাবিত বহুভাষার মডেল এই সমস্ত বৈশিষ্ট্যের রাষ্ট্র-শিল্পের প্রদর্শনের সাথে পৌঁ', 'et': 'Käesolevas dokumendis pakume välja tõhusa sügavõppe raamistiku mitmekeelseks ja koodisega visuaalseks küsimustele vastamiseks. Pakutud mudel suudab prognoosida küsimustele vastuseid hindi, inglise või koodsega (hinglish: hindi-inglise keel). Enamik olemasolevatest viieküsimustele vastamise tehnikatest keskendub ainult heledatele küsimustele. Paljud rakendused, näiteks meditsiinilised pildid, turism, visuaalsed assistendid, vajavad siiski mitmekeelsust toetavat moodulit nende laialdaseks kasutamiseks. Kuna inglise-hindi VQA-s andmekogumit ei ole, loome esmalt hindi- ja koodisegatud VQA-andmekogumit, kasutades ära nende keelte keelelisi omadusi. Pakume välja tugeva tehnoloogia, mis suudab käsitleda mitmekeelset ja koodisegatud küsimust, et anda vastus visuaalse informatsiooni (pildi) vastu. Mitmekeelsete ja koodisegatud küsimuste paremaks kodeerimiseks võtame kasutusele jagatud kihtide hierarhia. Me kontrollime nende jagatud kihtide käitumist tähelepanupõhise pehme kihi jagamise mehhanismi abil, mis õpib, kuidas jagatud kihte rakendatakse erinevates keeltes. Lisaks kasutab meie mudel kahelineaarset tähelepanu koos jääksidega keele ja pildi omaduste ühendamiseks. Teostame ulatuslikke hindamis- ja ablatsiooniuuringuid inglise, hindi ja koodsega VQA-le. Hindamine näitab, et kavandatud mitmekeelne mudel saavutab kõigis nimetatud tingimustes tipptasemel tulemuslikkuse.', 'fi': 'Tässä artikkelissa ehdotamme tehokasta syväoppimista monikieliseen ja koodisekoitettuun visuaaliseen kysymyksiin vastaamiseen. Ehdotettu malli pystyy ennustamaan vastauksia kysymyksiin hindi-, englanti- tai koodisekoitetuilla (hinglish: hindi-englanti) kielillä. Suurin osa nykyisistä viisivuotiseen kysymykseen vastaamiseen liittyvistä tekniikoista keskittyy vain kiiltäviin kysymyksiin. Monissa sovelluksissa, kuten lääketieteellisessä kuvantamisessa, matkailussa ja visuaalisissa avustajissa, tarvitaan kuitenkin monikielisyyttä tukeva moduuli laajalle levinneisyydelleen. Koska englannin-hindin VQA-kielellä ei ole saatavilla aineistoa, luomme ensin hindi- ja koodisekoitettuja VQA-aineistoja hyödyntämällä näiden kielten kielellisiä ominaisuuksia. Ehdotamme vankkaa tekniikkaa, joka pystyy käsittelemään monikielistä ja koodisekoitettua kysymystä vastatakseen visuaaliseen informaatioon (kuva). Monikielisten ja koodisekoitettujen kysymysten koodaamiseksi otamme käyttöön jaettujen tasojen hierarkian. Näiden jaettujen kerrosten käyttäytymistä ohjataan huomiopohjaisella pehmeän kerrosten jakomekanismilla, joka oppii miten jaettuja kerroksia sovelletaan eri tavoin kysymyksen eri kieliin. Lisäksi mallimme käyttää kaksilineaarista huomiota jäännösyhteydellä yhdistääkseen kielen ja kuvan ominaisuudet. Teemme laajoja arviointi- ja ablaatiotutkimuksia englannin, hindin ja koodisekoitetun VQA:n osalta. Arviointi osoittaa, että ehdotetulla monikielisellä mallilla saavutetaan uusinta suorituskykyä kaikissa näissä tilanteissa.', 'jv': 'Nang pepulan iki, kita supoyo nggawe sistem sing luwih apik kanggo ngerasar luwih karo akeh lan kode -- pingko ajeng seneng pisan Manual model sing perbudhakan iso dianggap banjurne gambaran karo pangrungan ingkang, Inggris karo Côd-karo barang. Piyambak hal teknik sing dituluk kanggo nambah winih-sual kang respon (VqA) ingkang dipun-ingkang en-glish seneng dipun politenessoffpolite Sampeyan ora ono dataset sing isa nggambar kanggo ngirim-hinti VqA, awake dhéwé isih ngubah batar tentang karo kode-karo VqA sing dipungot barang kelanganan ingkang. Awak dhéwé ngerbah tekno sing bot- nik kabèh nggawe gerakan akeh bantuan karo pakem karo pergambar barang nggawe informasi ning weruh (gambar). Ngawe ngubah luwih apik lengkang karo kode karo akeh pisan karo, kita ngubah perusahaan karo kalaman karo nggawe barang nggawe Awak dhéwé menehi nggawe alam-alam iki dipun-alam iki bakal terus diungubah winih sing bakal terus diungubah Lah, model sing wis digawe karo sistem 2Lineêr Awak dhéwé éntuk dhéwé éntukno-éntukno karo perusahaan kanggo ngilanggar, barang-barang karo Cwanger Wandepasyon wong liyane karo model sing supoyo akeh luwih-luwih iso nggawe gerakan tarjamah lan sampeyan kuwi.', 'he': 'בעיתון הזה, אנו מציעים מסגרת למידה עמוקה יעילה לענות על שאלות ויזואליות רבות ושונות. המודל המועמד הוא מסוגל לחזות תשובות מהשאלות בשפה הינדית, אנגלית או קוד-מעורבת (הינגלית: הינדית-אנגלית). רוב הטכניקות הקיומות על תשובות לשאלות ויסואליות (VQA) מתמקדות רק בשאלות מלאה. בכל אופן, תוכניות רבות כמו דמיון רפואי, תיירים, עוזרים ויזואליים דורשים מודול מורכב לשונות עבור השימושים הרחבים שלהם. כיוון שאין קבוצת נתונים זמינה ב VQA אנגלי-הינדי, אנו קודם כל יוצרים קבוצות נתונים של VQA הינדי ומערובות קודים על ידי ניצל את תכונות השפה של השפות הללו. אנו מציעים טכניקה חזקה מסוגלת לטפל בשאלה רבת-שפתית ומערובת קודים כדי לספק את התשובה נגד מידע ויזואלי (תמונה). כדי לקוד טוב יותר את שאלות רבות שפות ומערבות קודים, אנחנו מציגים הייררכיה של שכבות משותפות. אנחנו שולטים בהתנהגות של שכבות משותפות אלה על ידי מנגנון שיתוף שכבות רכה מבוסס תשומת לב, שמלמד איך שכבות משותפות מתפקדות בדרכים שונות לשפות שונות של השאלה. בנוסף, המודל שלנו משתמש בשימוש בילינרי תשומת לב עם חיבור שנותר כדי למחוז את השפה והצילומים. אנו מבצעים מחקרי עריכה ורחבי עבור אנגלית, הינדית וקוד-ערובה VQA. The evaluation shows that the proposed multilingual model achieves state-of- the-art performance in all these settings.', 'ha': "Ga wannan takardan, Munã buɗa wani firam mai amfani da matsayi mai fasahawa wa jibar da tambayi masu cikin mulki-harshe da kodi-da-haɗe da masu basĩri. @ item Spelling dictionary Baɓartansu da ke da masu buƙata kan Jabu'ar Mu- sual (vQA) ana fokus a kan masu tambayar A-glish kawai. Kayya, da yawa shiryoyin ayuka kamar misãlin zane-zane za'a yi amfani da kafin, tare safari, yana da mataimaki masu gani, sun ƙayyade wata module da aka yi amfani da masu amfani da multilingu wanda ke fara da shi. As there is no available dataset in English-Hindi VQA, we firstly create Hindi and Code-mixed VQA datasets by exploiting the linguistic properties of these languages.  Tuna goyya da wani techni mai karo- mai awon ya yi aiki ga masu tambayar mulki'ala da kodi-da aka haɗa shi zuwa ga ya bãyar da jabu a kan zane (zane). Dõmin ka fi kodi masu tambayar mulki-littafi da kodi-da-haɗi, za mu ƙara wata hirarci na zane-zane da aka raba shi. Tuna kangara aikin waɗannan abun da aka raba su haɗa su zuwa wani zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane. Furan, misalinmu yana amfani da muhalli na bi-line da wata mazauni mai mutu zuwa ya buɗe tsarin harshen da zane. Munã cika karatun masu ƙaddara da muhimmanci wa-muhimmada na Ingiriya, Hindiya da Code-da-haɗe vQA. Ana nuna cewa, misalin mulki-lingui wanda aka buƙata yana sãmun mai halin-sanar cikin duk wannan tsaro.", 'sk': 'V tem prispevku predlagamo učinkovit okvir globokega učenja za večjezično in kodno mešano vizualno odgovarjanje na vprašanja. Predlagani model je sposoben napovedati odgovore na vprašanja v hindujščini, angleščini ali kodno mešanih jezikih. Večina obstoječih tehnik za odgovarjanje na vprašanja (VQA) se osredotoča samo na enostavna vprašanja. Vendar pa za številne aplikacije, kot so medicinsko slikanje, turizem, vizualni pomočniki, potrebujejo modul, ki omogoča večjezičnost, za njihovo široko uporabo. Ker ni na voljo nobenega nabora podatkov v angleško-hindijskem VQA, najprej ustvarimo hindijske in kodno mešane VQA nabore podatkov z izkoriščanjem jezikovnih lastnosti teh jezikov. Predlagamo robustno tehnološko tehniko, ki lahko obravnava večjezično in kodno mešano vprašanje, da bi zagotovili odgovor proti vizualnim informacijam (sliki). Za boljše kodiranje večjezičnih in kodno mešanih vprašanj uvajamo hierarhijo plasti v skupni rabi. Obnašanje teh skupnih plasti nadzorujemo s pozornostjo temelječim mehkim mehanizmom za delitev plasti, ki se nauči, kako se skupne plasti uporabljajo na različne načine za različne jezike vprašanja. Poleg tega naš model uporablja bi-linearno pozornost s preostalo povezavo za združitev jezika in slike. Izvajamo obsežne ocenjevalne in ablacijske študije za angleščino, hindijščino in kodno mešano VQA. Ocena kaže, da predlagani večjezični model dosega najsodobnejše delovanje v vseh teh okoljih.', 'bo': 'འོག་གི་ཤོག་བུ་འདིའི་ནང་དུ་སྣ་སྐད་ཡིག་དང་kod(mixed visual question)དང་མཐུན་སྣ་ཚོགས་ཀྱི་ལྟ་སྟངས་གྱི་བཀོད་རིམ་སྟོན་གྱི་ཡོ pro- posed model is able to predict answers from the questions in Hindi, English or Code- mixed (Hinglish: Hindi-English) languages. Vi-sual questionnaire(VQA)ལ་གནས་ཡོད་པའི་བཟོ་རྩོམ་འབྲི་མིའི་ཆེ་ཆུང་ཀྱི་ནང་དུ་ཨིན་glish་འདྲི་ཚིག་ཁོ་ན་ལ་བློ་གཏོང་བ། ཡིན་ནའང་། ཉེར་སྤྱོད་ཆ་མང་པོ་ཞིག་དག་ལྟ་བུའི་བརྙན་རིས་དང་། སྐུལ་ལྟ་བུ་དང་མཐོང་བའི་རོགས སྐད་ཡིག་གི་ནང་དུ་ཡིག་ཆ་སྒྲིག་ཆ་འཕྲིན་བཏོན་མི་འདུག་ ང་ཚོས་དང་པོ་མཐའ་ནས་སྐད་རིགས་ཀྱི་རང་འགུལ་གྱི་སྐད་ཡིག ང་ཚོས་མཐོང་སྣང་དང་། མཐོང་བའི་ཆ་འཕྲིན་དང་། སྒྲ་བརྙན་གྱི་ཐབས་ལམ་སྤྱོད་ཀྱི་ཐབས་ལམ་ཡིན། སྐད་རིགས་དང་སྦྲེལ་བ་དག་གི་དྲི་ཚིག་འདྲི་ཚིག་དག་བསམ་བློ་གཏད་དགོས་པ་དེ་ང་ཚོས་མཉམ་སྤྱོད་པའི་བང་རིམ ང་ཚོས་རྣམས་མཐུན་པའི་བང་རིམ་འདི་དག་གི་བྱ་སྟངས་ལ་དམིགས་བསལ་མཐུན་ནུས་པའི་མཉེན་རིམ་ཆ་བཤད་ཀྱི་ཐབས་ལམ་མ་འདྲ་བྱེད་ཀྱི་ཡོད། ད་དུང་བར་ན། ང་ཚོའི་མ་དབྱིབས་འདིས་སྐད་ཡིག་དང་བརྙན་རིས་པར་རིས་ཆ་མཉམ་དུ་གྲལ་རིམ ང་ཚོས་དབྱིན་ཡིག་དང་ Hindi དང་ཐུག་ཁྲམ་གྱི་རྩོལ་བ་ཆ་རྩིས་བཏོན་གཏོང་ནི་ཤེས་ལྡན་བྱེད་ཀྱི་ཡོད། དབྱེ་བཟོ་བ་ནི་སྔོན་འཆར་ཡོད་པའི་སྐད་རིགས་དབྱིབས་གནས་སྟངས་དང་གནས་སྟངས་ཀྱི་སྒྲིག་འགོད་འདི་དག་གི་ནང་ལ་རྒྱས་ཡོད'}
{'en': 'Measuring What Counts : The Case of Rumour Stance Classification', 'fr': 'Mesurer ce qui compte\xa0: le cas de la classification des positions de rumeur', 'es': 'Midiendo lo que cuenta: el caso de la clasificación de posturas de rumores', 'pt': 'Medindo o que conta: o caso da classificação da postura de boatos', 'ar': 'قياس ما يهم: تصنيف حالة الشائعات', 'zh': '量要因素,讹言立场分类之例', 'ja': '何が重要かを測定する：噂のスタンス分類のケース', 'ru': 'Измерение того, что имеет значение: случай классификации позиции слухов', 'hi': 'मापने क्या मायने रखता है: अफवाह रुख वर्गीकरण का मामला', 'ga': 'Ag Tomhas Cad is Áireamh: Cás Aicmiú Seasaimh Rumor', 'ka': 'მარტირება რომელიც შეფარდება: სურათის კლასიფიკაცია', 'hu': 'Mérni, mit számít: A pletyka álláspontjának besorolása', 'it': 'Misurare ciò che conta: il caso della classificazione della posizione delle voci', 'el': 'Μετρώντας τι μετράει: Η περίπτωση της ταξινόμησης της θέσης των φήμων', 'kk': 'Нәтижелерді өлшеу: The Case of Rumour Stance Classification', 'lt': 'Svarbiausių dalykų vertinimas: garsų nuomonės klasifikavimo atvejis', 'mk': 'Одмерувањето на она што е важно: Класификацијата на гласините', 'ms': 'Mengukur apa yang dihitung: Kejadian Klasifikasi Keadaan Rumor', 'ml': 'എന്ത് കണക്കുകള്\u200d അളന്നുകൊണ്ടിരിക്കുന്നു:', 'mn': 'Юу тооцоолох вэ?', 'ro': 'Măsurarea ce contează: Cazul clasificării stării zvonurilor', 'mt': 'Il-Kejl ta’ X’Għadd: Il-Klassifikazzjoni tal-Istanza tas-Rumori', 'sr': 'Izmjerenje šta broji: slučaj klasifikacije ružnog stanja', 'pl': 'Pomiar tego, co się liczy: przypadek klasyfikacji stanu plotek', 'si': 'The case of Rumina Stance Classication', 'so': 'Measures What Account: Case of Rumour Stance Classification', 'sv': 'Mätning av vad som räknas: Fallet med rykte Stance Klassificering', 'no': 'Målar kva tal: The Case of Rumour Stance Classification', 'ta': 'என்ன எண்ணிக்கை: The Case of Rumor Stance Classification', 'ur': 'کس گنتی کا اندازہ کرتا ہے: The Case of Rumour Stance Classification', 'vi': 'Đóng cái này Bao gồm: Cái khẩu súng bằng máy', 'uz': 'Qanday oò£lchamini oò£zgartirish: The Case of Rumor Stance Classification', 'bg': 'Измерване на това, което има значение: Случаят с класификацията на слуховете', 'da': 'Måling af hvad der tæller: Tilfældet med rygter Stance Klassificering', 'hr': 'Mjerenje što broji: slučaj klasifikacije ružnog stanja', 'nl': 'Meten wat telt: het geval van geruchtstandclassificatie', 'de': 'Messen, was zählt: Der Fall der Gerüchthaltung Klassifizierung', 'ko': '무엇이 중요한가: 헛소문 입장 분류 사례', 'id': 'Measuring What Counts: The Case of Rumour Stance Classification', 'fa': 'اندازه\u200cگیری که شماره\u200cها می\u200cشود: پرونده\u200cی کلاس\u200cشناسی استنس', 'sw': 'Kupima kiasi gani: Mashtaka ya Kutangaza Ukweli', 'af': 'Met Wat Tel: The Case of Rumour Stance Classification', 'tr': 'Näme hasaplanjak: The Case of Rumour Stance Classification', 'am': 'ምንኛ ቁጥር', 'sq': 'Mësimi i asaj që numëron: rasti i klasifikimit të qëndrimit të zërave', 'az': 'Nə hesab edir: The Case of Rumour Stance Classification', 'bs': 'Izmjerenje šta broji: slučaj klasifikacije ružnog stanja', 'bn': 'কি হিসাব পরিমাপ: গুজব স্টেনের কেস', 'cs': 'Měření toho, co se počítá: Případ klasifikace pověstí', 'et': 'Mõõtmine, mida loeb: kuulujuttude seisundi klassifitseerimine', 'ca': 'Measuring What Counts: The Case of Rumour Stance Classification', 'fi': 'Mitataan mikä on tärkeintä: Huhun tilanne Stance luokitus', 'hy': 'Ինչ է կարևոր, հաշվի առնելը. ձայների դասակարգման դեպքը', 'jv': 'Meturan Panjenengan WHAT: The Case of', 'ha': 'Measuring What Counts: The Case of Rumour Stance Classification', 'bo': 'རྩིས་མེད་ཅི་ཞིག་ཚད་གཞི། སྣང་ཚུལ་གྱི་གནས་ཚུལ་གྱི་ རྣམ་པ་Stance སྒེར་གྱི་རྣམ་པ།', 'he': 'למדוד מה נחשב: מקרה מסווג עמדת השמועות', 'sk': 'Merjenje, kaj šteje: Primer govoric Stance Klasifikacija'}
{'en': 'Stance classification can be a powerful tool for understanding whether and which users believe in  online rumours . The task aims to automatically predict the stance of replies towards a given  rumour , namely support, deny, question, or comment. Numerous methods have been proposed and their performance compared in the RumourEval shared tasks in 2017 and 2019. Results demonstrated that this is a challenging problem since naturally occurring rumour stance data is highly imbalanced. This paper specifically questions the evaluation metrics used in these shared  tasks . We re-evaluate the systems submitted to the two RumourEval tasks and show that the two widely adopted metrics    accuracy  and macro-F1   are not robust for the four-class imbalanced task of rumour stance classification, as they wrongly favour systems with highly skewed accuracy towards the majority class. To overcome this problem, we propose new evaluation metrics for rumour stance detection. These are not only robust to imbalanced data but also score higher systems that are capable of recognising the two most informative minority classes (support and deny).', 'ar': 'يمكن أن يكون تصنيف الموقف أداة قوية لفهم ما إذا كان المستخدمون يؤمنون بالإشاعات عبر الإنترنت أم لا. تهدف المهمة إلى التنبؤ تلقائيًا بموقف الردود تجاه شائعة معينة ، أي الدعم أو الرفض أو السؤال أو التعليق. تم اقتراح العديد من الطرق ومقارنة أدائها في المهام المشتركة لـ RumourEval في عامي 2017 و 2019. وأظهرت النتائج أن هذه مشكلة صعبة لأن بيانات موقف الشائعات التي تحدث بشكل طبيعي غير متوازنة للغاية. تتساءل هذه الورقة على وجه التحديد عن مقاييس التقييم المستخدمة في هذه المهام المشتركة. نحن نعيد تقييم الأنظمة المقدمة إلى مهمتي RumourEval ونوضح أن المقياسين المعتمدين على نطاق واسع - الدقة والماكرو F1 - ليسا قويين للمهمة غير المتوازنة من أربع فئات لتصنيف موقف الشائعات ، لأنها تفضل بشكل خاطئ الأنظمة ذات الانحراف الشديد الدقة تجاه فئة الأغلبية. للتغلب على هذه المشكلة ، نقترح مقاييس تقييم جديدة لاكتشاف موقف الشائعات. هذه ليست فقط قوية للبيانات غير المتوازنة ولكنها أيضًا تسجل أنظمة أعلى قادرة على التعرف على فئتين من فئات الأقليات الأكثر إفادة (الدعم والرفض).', 'fr': "La classification des positions peut être un outil puissant pour comprendre si et quels utilisateurs croient aux rumeurs en ligne. La tâche vise à prédire automatiquement la position des réponses à une rumeur donnée, à savoir soutenir, refuser, poser une question ou commenter. De nombreuses méthodes ont été proposées et leurs performances comparées dans les tâches partagées RumourEval en 2017 et 2019. Les résultats ont démontré qu'il s'agit d'un problème difficile étant donné que les données de position des rumeurs naturelles sont très déséquilibrées. Ce document s'interroge spécifiquement sur les mesures d'évaluation utilisées dans ces tâches partagées. Nous réévaluons les systèmes soumis aux deux tâches RumourEval et montrons que les deux métriques largement adoptées - précision et macro-F1 - ne sont pas robustes pour la tâche déséquilibrée à quatre classes de classification de la position de la rumeur, car elles favorisent à tort les systèmes avec une précision très biaisée en faveur de la classe majoritaire. Pour surmonter ce problème, nous proposons de nouvelles mesures d'évaluation pour la détection de la position de la rumeur. Ils sont non seulement robustes face aux données déséquilibrées, mais ils obtiennent également des scores plus élevés pour les systèmes capables de reconnaître les deux classes minoritaires les plus informatives (soutien et refus).", 'es': 'La clasificación de posturas puede ser una herramienta poderosa para comprender si los usuarios creen en los rumores en línea y qué usuarios creen en ellos. La tarea tiene como objetivo predecir automáticamente la postura de las respuestas ante un rumor dado, es decir, apoyar, negar, cuestionar o comentar. Se han propuesto numerosos métodos y se ha comparado su rendimiento en las tareas compartidas de RumoureVal en 2017 y 2019. Los resultados demostraron que este es un problema desafiante, ya que los datos naturales de la postura de los rumores están muy desequilibrados. Este documento cuestiona específicamente las métricas de evaluación utilizadas en estas tareas compartidas. Reevaluamos los sistemas sometidos a las dos tareas de RumoureVal y mostramos que las dos métricas ampliamente adoptadas —precisión y macro-F1— no son sólidas para la tarea desequilibrada de cuatro clases de clasificación de posturas de rumores, ya que favorecen erróneamente los sistemas con una precisión muy sesgada hacia la clase mayoritaria. Para superar este problema, proponemos nuevas métricas de evaluación para la detección de posturas de rumores. Estos no solo son sólidos para datos desequilibrados, sino que también obtienen una puntuación más alta en los sistemas que son capaces de reconocer las dos clases minoritarias más informativas (apoyo y rechazo).', 'pt': 'A classificação de posturas pode ser uma ferramenta poderosa para entender se e quais usuários acreditam em rumores online. A tarefa visa prever automaticamente a postura das respostas em relação a um determinado boato, ou seja, apoiar, negar, questionar ou comentar. Vários métodos foram propostos e seu desempenho comparado nas tarefas compartilhadas RumourEval em 2017 e 2019. Os resultados demonstraram que esse é um problema desafiador, pois os dados de postura de rumores que ocorrem naturalmente são altamente desequilibrados. Este artigo questiona especificamente as métricas de avaliação usadas nessas tarefas compartilhadas. Reavaliamos os sistemas submetidos às duas tarefas RumourEval e mostramos que as duas métricas amplamente adotadas – precisão e macro-F1 – não são robustas para a tarefa desequilibrada de quatro classes de classificação de postura de rumores, pois favorecem erroneamente sistemas com precisão para a classe majoritária. Para superar esse problema, propomos novas métricas de avaliação para detecção de postura de boatos. Estes não são apenas robustos a dados desequilibrados, mas também pontuam sistemas mais altos que são capazes de reconhecer as duas classes minoritárias mais informativas (suporte e negação).', 'ja': 'スタンス分類は、ユーザーがオンラインの噂を信じているかどうか、どのユーザーが信じているかを理解するための強力なツールです。 このタスクは、特定の噂、つまりサポート、否定、質問、またはコメントに対する返信のスタンスを自動的に予測することを目的としています。 多くの方法が提案されており、2017年と2019年のRumourEval共有タスクでそれらのパフォーマンスを比較しました。 自然発生的な噂のスタンスデータは非常に不均衡であるため、これは困難な問題であることが実証された。 本稿では、これらの共有タスクで使用される評価指標について具体的に質問します。 私たちは、2つのRumourEvalタスクに提出されたシステムを再評価し、正確性とマクロF 1という2つの広く採用されている指標が、噂のスタンス分類の4つのクラスの不均衡なタスクに対して堅牢ではないことを示します。これは、正確性が多数派クラスに大きく偏っているシステムを誤って好んでいるからです。 この問題を克服するために、噂のスタンス検出のための新しい評価指標を提案します。 これらは、アンバランスなデータに対して堅牢であるだけでなく、最も情報量の多い2つの少数クラス（サポートと拒否）を認識することができるより高いスコアのシステムです。', 'hi': 'रुख वर्गीकरण यह समझने के लिए एक शक्तिशाली उपकरण हो सकता है कि क्या और कौन से उपयोगकर्ता ऑनलाइन अफवाहों में विश्वास करते हैं। कार्य का उद्देश्य स्वचालित रूप से किसी दिए गए अफवाह के प्रति उत्तरों के रुख की भविष्यवाणी करना है, अर्थात् समर्थन, इनकार, प्रश्न, या टिप्पणी। 2017 और 2019 में अफवाहएवल साझा कार्यों की तुलना में कई तरीकों का प्रस्ताव किया गया है और उनके प्रदर्शन का प्रस्ताव किया गया है। परिणामों से पता चला है कि यह एक चुनौतीपूर्ण समस्या है क्योंकि स्वाभाविक रूप से होने वाली अफवाह रुख डेटा अत्यधिक असंतुलित है। यह पेपर विशेष रूप से इन साझा कार्यों में उपयोग किए जाने वाले मूल्यांकन मीट्रिक पर सवाल उठाता है। हम दो अफवाह ों के कार्यों के लिए प्रस्तुत प्रणालियों का फिर से मूल्यांकन करते हैं और दिखाते हैं कि दो व्यापक रूप से अपनाए गए मीट्रिक - सटीकता और मैक्रो-एफ 1 - अफवाह रुख वर्गीकरण के चार-वर्ग असंतुलित कार्य के लिए मजबूत नहीं हैं, क्योंकि वे गलत तरीके से बहुसंख्यक वर्ग की ओर अत्यधिक विषम सटीकता के साथ सिस्टम का पक्ष लेते हैं। इस समस्या को दूर करने के लिए, हम अफवाह रुख का पता लगाने के लिए नए मूल्यांकन मीट्रिक का प्रस्ताव करते हैं। ये न केवल असंतुलित डेटा के लिए मजबूत हैं, बल्कि उच्च प्रणालियों को भी स्कोर करते हैं जो दो सबसे अधिक जानकारीपूर्ण अल्पसंख्यक वर्गों (समर्थन और इनकार) को पहचानने में सक्षम हैं।', 'zh': '立场分类可以为知用户孰用户信在线讹言之强器。 当务在自占给定讹言报复,即赞成之,否,质疑论。 2017年与2019年RumourEval共事,已多方法,较其性能。 结果表明者,挑战性也,自然讹言立数不平也。 本文专以共享之论指标发之。 重估提交二RumourEval之统,并明两广指标 - 准确性宏观F1 - 于讹言立场之类四不平,盖其误偏于众也。 为克此问,新言立场检测评指标。 此非徒有鲁棒性于不平之数,而识两息之最富者少群(支拒)之统得分益高。', 'ru': 'Классификация позиций может быть мощным инструментом для понимания того, верят ли и кто из пользователей в онлайн-слухи. Задача состоит в том, чтобы автоматически предсказать позицию ответов в отношении того или иного слуха, а именно поддержки, отрицания, вопроса или комментария. Были предложены многочисленные методы, и их эффективность сравнивалась в общих задачах RumourEval в 2017 и 2019 годах. Результаты показали, что это сложная проблема, поскольку данные о естественной позиции слухов сильно дисбалансированы. В настоящем документе конкретно ставятся под сомнение оценочные показатели, используемые в этих общих задачах. Мы переоцениваем системы, представленные для двух задач RumourEval, и показываем, что две широко принятые метрики – точность и макро-F1 – не являются надежными для четырехклассовой несбалансированной задачи классификации позиции слухов, поскольку они ошибочно отдают предпочтение системам с высокой точностью по отношению к классу большинства. Чтобы преодолеть эту проблему, мы предлагаем новые оценочные показатели для обнаружения позиции слухов. Они не только надежны для получения несбалансированных данных, но и характеризуются более высокими показателями систем, способных распознавать два наиболее информативных класса меньшинств (поддержка и отрицание).', 'ga': 'Is féidir le haicmiú seasaimh a bheith ina uirlis chumhachtach chun a thuiscint cé acu an gcreideann úsáideoirí i ráflaí ar líne agus cé na cinn a chreideann. Tá sé mar aidhm ag an tasc seasamh na bhfreagraí i leith ráfla áirithe a thuar go huathoibríoch, is é sin tacaíocht, séanadh, ceistiú nó trácht. Moladh go leor modhanna agus cuireadh a bhfeidhmíocht i gcomparáid le tascanna comhroinnte RumourEval in 2017 agus 2019. Léiríodh sna torthaí gur fadhb dhúshlánach í seo ós rud é go bhfuil an-éagothroime i sonraí seasamh ráflaí a tharlaíonn go nádúrtha. Ceistíonn an páipéar seo go sonrach an mhéadracht mheastóireachta a úsáidtear sna tascanna comhroinnte seo. Déanaimid athmheasúnú ar na córais a cuireadh isteach chuig an dá thasc RumourEval agus léirímid nach bhfuil an dá mhéadracht a nglactar go forleathan leo – cruinneas agus macra-F1 – láidir do thasc éagothroime na gceithre aicme maidir le haicmiú ráflaí, toisc go bhfuil siad i bhfabhar córais a bhfuil sceabhach mór orthu go mícheart. cruinneas i dtreo rang an tromlaigh. Chun an fhadhb seo a shárú, molaimid méadracht mheastóireachta nua chun ráflaí a bhrath. Ní hamháin go bhfuil siad seo láidir i leith sonraí éagothroime ach tá scór acu freisin ar chórais níos airde atá in ann an dá rang mionlaigh is faisnéiseach a aithint (tacaíocht agus séanadh).', 'el': 'Η ταξινόμηση θέσης μπορεί να είναι ένα ισχυρό εργαλείο για την κατανόηση του αν και ποιοι χρήστες πιστεύουν σε διαδικτυακές φήμες. Το έργο στοχεύει στην αυτόματη πρόβλεψη της στάσης των απαντήσεων σε μια δεδομένη φήμη, δηλαδή υποστήριξη, άρνηση, ερώτηση ή σχόλιο. Έχουν προταθεί πολυάριθμες μέθοδοι και η απόδοσή τους συγκρίνεται στο πλαίσιο των κοινών καθηκόντων τους 2017 και 2019. Τα αποτελέσματα έδειξαν ότι αυτό είναι ένα προκλητικό πρόβλημα, δεδομένου ότι τα φυσικά δεδομένα για τη στάση των φήμων είναι εξαιρετικά ανισορροπημένα. Αυτή η εργασία αμφισβητεί συγκεκριμένα τις μετρήσεις αξιολόγησης που χρησιμοποιούνται σε αυτές τις κοινές εργασίες. Αναξιολογούμε τα συστήματα που υποβλήθηκαν στις δύο εργασίες και καταδεικνύουμε ότι οι δύο ευρέως υιοθετημένες μετρήσεις: ακρίβεια και μακρο-F1 δεν είναι ανθεκτικές για το τετράταξη ανισορροπίας καθορισμού θέσεων φήμης, καθώς ευνοούν λανθασμένα συστήματα με εξαιρετικά στρεβλωμένη ακρίβεια προς την πλειοψηφική τάξη. Για να ξεπεραστεί αυτό το πρόβλημα, προτείνουμε νέες μετρήσεις αξιολόγησης για τον εντοπισμό της στάσης των φήμων. Αυτά δεν είναι μόνο ανθεκτικά σε ανισορροπημένα δεδομένα, αλλά επίσης βαθμολογούν υψηλότερα συστήματα που είναι σε θέση να αναγνωρίσουν τις δύο πιο ενημερωτικές μειονοτικές τάξεις (υποστήριξη και άρνηση).', 'hu': 'A helyzet osztályozása hatékony eszköz lehet annak megértéséhez, hogy a felhasználók hisznek-e az online pletykákban. A feladat célja, hogy automatikusan megjósolja a válaszok álláspontját egy adott pletykára, nevezetesen támogatásra, tagadásra, kérdésre vagy megjegyzésre. Számos módszert javasoltunk és teljesítményüket összehasonlítottuk a RumourEval 2017-ben és 2019-ben megosztott feladatokban. Az eredmények azt mutatták, hogy ez kihívást jelent, mivel a természetesen előforduló pletykák álláspontjára vonatkozó adatok nagymértékben kiegyensúlyozatlanok. Ez a tanulmány kifejezetten megkérdőjelezi az ezekben a megosztott feladatokban használt értékelési mutatókat. Újraértékeljük a két RumourEval feladathoz benyújtott rendszert, és megmutatjuk, hogy a két széles körben elfogadott mérőszám - a pontosság és a makro-F1 - nem megfelelő a pletykaállások osztályozásának négy osztályú kiegyensúlyozatlan feladatához, mivel tévesen kedvelik a rendszereket, nagyon ferde pontossággal a többségi osztály felé. A probléma leküzdése érdekében új értékelési mutatókat javasolunk a pletykák álláspontjának felismeréséhez. Ezek nemcsak a kiegyensúlyozatlan adatokhoz szükségesek, hanem magasabb rendszereket is mutatnak, amelyek képesek felismerni a két leginformatívabb kisebbségi osztályt (támogatás és tagadás).', 'kk': 'Станс классификациясы онлайн сөйлеріне қандай және қандай пайдаланушылардың сенгенін түсіну үшін күшті құрал болуы мүмкін. Тапсырма келтірілген жауаптарды автоматты түрде көрсету мақсаты: қолдау, қабылдау, сұрақ немесе түсініктеме. 2017 және 2019 жылы RumourEval жалпы тапсырмаларында салыстырылған бірнеше әдістер ұсынылды. Нәтижелер бұл қиын мәселе деп көрсетілді, өйткені табиғатты оқиғалардың мәліметі өте дәл-балансияланған. Бұл қағаз осы ортақтастырылған тапсырмаларда қолданылатын оқу метрикаларын сұрақтайды. Біз екі RumourEval тапсырмаларына жүйелерді қайта бағалап, екі жалпы қолданылған метрикалық - дұрыс және макро-F1 - дұрыс және төрт класс дибалансияланған сұрақтарды классификациялау тапсырмасы үшін дұрыс емес, себебі олар көпшілікті класса арқылы Бұл мәселеге көтеру үшін жаңа оқу метрикаларын табу үшін қолданамыз. Бұл тек балансияланған деректер үшін дұрыс емес, сондай-ақ бұл екі ең мәліметті аздық классын анықтауға мүмкіндік беретін жүйелерді бағалауға болады (қолдау және жоқ).', 'ka': 'სტანსის კლასიფიკაცია შეიძლება იყოს ძალიან ხელსაწყო, რომელიც მომხმარებელი იფიქრობენ თუ არა და რომელიც მომხმარებელი ინტერნეტის ხ დავალების მიზეზი ავტომატურად გადაწყვეტა განსხვავებების სტანციას, რომელიც დაეხმარება, დაკავშირება, კითხვა, ან კომენტირება. რამდენიმე მეტები იყენებულია და მათი გამოყენება რომელისგან 2017 და 2019 წლის საზოგადოებაში გაყოფილი საქმებში. შედეგი გამოჩვენებულია, რომ ეს ძალიან შესაძლებელი პრობლემა, რადგან საუბრალოდ მოხდება სიტყვანის მონაცემები ძალიან განბალიზებულია. ეს დაახლოები განსაკუთრებულად კითხვა, რომლებიც ამ საზოგადოებული დავალებში გამოყენებულია. ჩვენ შევუმუშაოთ სისტემები, რომლებიც ორი პუმურიველ დავაკეთებული დავაკეთებულია და ჩვენ ჩვენ ჩვენ აღმოჩნეთ, რომ ორი უფრო დავაკეთებული მეტრიკა - მაკრო-F1 - არიან ძალიან 4-კლასის განბლანსულებული დავაკეთებულია სისტემის კლასიფიკა ამ პრობლემას გადავიწყენოთ, ჩვენ დავიწყებთ ახალი განსაზღვრების მეტრიკის განსაზღვრებისთვის. ეს არა მხოლოდ უფრო ძალიან განმავლობული მონაცემებისთვის, მაგრამ უფრო მეტი სისტემები, რომლებიც შეუძლია აღმოჩნოთ ორი უფრო ინფორმაციური მეტირების კლასის (და', 'lt': 'Standartų klasifikavimas gali būti galinga priemonė suprasti, ar ir kurie vartotojai tiki internetiniais gandais. The task aims to automatically predict the stance of replies towards a given rumour, namely support, deny, question, or comment.  Buvo pasiūlyta daug metodų ir jų rezultatai palyginti su bendrais RumourEval uždaviniais 2017 ir 2019 m. Rezultatai parodė, kad tai sunki problem a, nes natūraliai atsirandantys gandų požiūrio duomenys yra labai disbalansuoti. Šiame dokumente konkrečiai kyla abejonių dėl vertinimo rodiklių, naudojamų šiose bendrose užduotyse. Pervertiname sistemas, pateiktas dviem RumourEval užduotims, ir parodome, kad du plačiai patvirtinti metriniai rodikliai - tikslumas ir makro-F1 - nėra patikimi keturių klasių disbalansuotos užduoties, susijusios su garsų pozicijos klasifikavimu, nes jie neteisingai remia sistemas, kurios labai tikslios daugumos klasės atžvilgiu. Norėdami įveikti šią problem ą, siūlome naujus vertinimo rodiklius, skirtus atradų pozicijai nustatyti. Tai ne tik tvirtai susiję su disbalansuotais duomenimis, bet ir didesnių sistemų, galinčių pripažinti dvi labiausiai informuojančias mažumų klases (parama ir atsisakymas).', 'it': 'La classificazione delle posizioni può essere un potente strumento per capire se e quali utenti credono nelle voci online. Il compito mira a prevedere automaticamente la posizione delle risposte verso una data voce, vale a dire sostegno, negazione, domanda o commento. Numerosi metodi sono stati proposti e le loro prestazioni sono state confrontate nei compiti condivisi di RumourEval nel 2017 e 2019. I risultati hanno dimostrato che si tratta di un problema impegnativo poiché i dati sulle posizioni delle voci presenti in natura sono altamente sbilanciati. Questo articolo mette in discussione specificamente le metriche di valutazione utilizzate in queste attività condivise. Rievaluiamo i sistemi sottoposti ai due compiti RumourEval e mostriamo che le due metriche ampiamente adottate - accuratezza e macro-F1 - non sono robuste per il compito sbilanciato di quattro classi di classificazione delle posizioni rumour, in quanto favoriscono erroneamente sistemi con una precisione altamente distorta verso la classe maggioritaria. Per superare questo problema, proponiamo nuove metriche di valutazione per il rilevamento delle posizioni di rumour. Questi non sono solo robusti per dati sbilanciati, ma anche punteggi più alti che sono in grado di riconoscere le due classi minoritarie più informative (supporto e negazione).', 'ms': 'Stance classification can be a powerful tool for understanding whether and which users believe in online rumours.  Tugas bermaksud untuk secara automatik meramalkan kedudukan jawapan terhadap khabar angin tertentu, iaitu sokongan, menolak, soalan, atau komentar. Banyak kaedah telah diusulkan dan prestasi mereka dibandingkan dalam tugas RumourEval berkongsi pada 2017 dan 2019. Hasil menunjukkan bahawa ini adalah masalah yang mencabar kerana data pendapat khabar angin yang berlaku secara alami sangat tidak seimbang. Kertas ini secara khusus menanyakan metrik penilaian yang digunakan dalam tugas berkongsi ini. Kami mengevaluasi semula sistem yang dihantar kepada dua tugas RumourEval dan menunjukkan bahawa dua metrik yang diadopsi secara luas - ketepatan dan makro-F1 - tidak kuat untuk tugas empat kelas yang tidak seimbang pengecualian kedudukan khabar angin, kerana mereka salah menyokong sistem dengan ketepatan yang sangat terkurang terhadap kelas kebanyakan. Untuk mengatasi masalah ini, kami cadangkan metrik penilaian baru untuk pengesan posisi khabar angin. Ini bukan sahaja kuat kepada data yang tidak seimbang tetapi juga skor sistem yang lebih tinggi yang mampu mengenali dua kelas minoriti yang paling maklumat (sokongan dan menolak).', 'mk': 'Класификацијата на станиците може да биде моќна алатка за разбирање дали и кои корисници веруваат во онлајн гласини. Оваа задача има за цел автоматски да го предвиде ставот на одговорите кон одредена гласина, имено поддршка, негирање, прашање или коментар. Беа предложени бројни методи и нивните резултати во споредба со „RumourEval“ споделени задачи во 2017 и 2019 година. Резултатите покажаа дека ова е предизвикувачки проблем бидејќи природно се појавуваат гласини дека податоците за ставот на гласините се многу нерамнотежни. Овој документ специфично ги сомнева метриките на евалуацијата кои се користат во овие заеднички задачи. Ние повторно ги проценуваме системите поднесени на двете задачи на RumourEval и покажуваме дека двете широко усвоени метрики - точност и макро-F1 - не се силни за нерамнотежната задача од четири класи на класификацијата на гласините за став, бидејќи тие погрешно им се допаѓаат на системите со висока прецизност кон мнозинската класа. За да го надминеме овој проблем, предлагаме нови метрики за проценка на гласините. Тие не се само силни за нерамнотежни податоци, туку и постигнуваат повисоки системи кои се способни да ги признаат двете најинформативни малцински класи (поддршка и негирање).', 'ml': 'Stance classification can be a powerful tool for understanding whether and which users believe in online rumours.  കൊടുത്ത വാക്കുകളുടെ ഉത്തരങ്ങളുടെ സ്ഥിതിയെ സ്വയം പ്രവചിപ്പിക്കാനുള്ള ജോലിയാണ് ഉദ്ദേശിക്കുന്നത്, പിന്തുണയ ധാരാളം രീതികള്\u200d പ്രോദേശിപ്പിക്കപ്പെട്ടിരിക്കുന്നു. അവയുടെ പ്രകടനം റമൂര്\u200dവെല്\u200d പങ്കുചേര്\u200dത്ത ജോലികളില്\u200d  അതിന്റെ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് ഇതൊരു വിലപാട് പ്രശ്നമാണെന്നാണ്. സ്വാഭാവികമായി സംഭവിക്കുന്ന വ ഈ പേപ്പ് പ്രത്യേകിച്ച് ചോദിക്കുന്നു രണ്ടു റൂമൂര്\u200dവെല്\u200d ജോലികള്\u200dക്ക് കീഴ്പെടുത്തിയ സിസ്റ്റമുകള്\u200d നമ്മള്\u200d വീണ്ടും വിലയിച്ചു കാണിക്കുകയും ചെയ്യുന്നു. രണ്ട് വിശാലമായ മെട്രിക്കങ്ങള്\u200d- ശരിയായിട്ടും മാക്രോ- എഫ്1 - നാ ഈ പ്രശ്നത്തെ പരിജയപ്പെടുത്താന്\u200d, നമ്മള്\u200d പുതിയ വിവേചന മെട്രിക്കുകള്\u200d പ്രാര്\u200dത്ഥിക്കുന്നു ഇത് തികഞ്ഞ വിവരങ്ങളിലേക്ക് മാത്രമല്ല, പക്ഷെ ഏറ്റവും വിവരമറിയുന്ന ഏറ്റവും ചെറുതായ വിവരങ്ങളുള്ള ക്ലാസുകളെ തിരിച്ചറിയാന്\u200d കഴിയ', 'mn': 'Станс хуваалтын хуваалтыг интернет дуу ярианд итгэдэг эсэхийг ойлгохын тулд хүчтэй хэрэгсэл болно. Үүний зорилго нь өгөгдсөн шүлэг дээр хариултыг автоматаар таамаглах зорилго юм. Энэ нь дэмжих, буруу, асуулт, эсвэл тэмдэглэх зорилго юм. Маш олон арга зам санал өгсөн бөгөөд тэдний үйл ажиллагаа 2017 болон 2019 онд RumourEval-д харьцуулсан. Үүний үр дүнд энэ нь хэцүү асуудал гэдгийг харуулсан. Яагаад гэвэл байгалийн байдлын мэдээллийг маш их тэнцүү байдаг. Энэ цаас ялангуяа эдгээр хуваалцагдсан ажил дээр хэрэглэгдсэн үнэлгээний метрикийг асуудаг. Бид RumourEval хоёр даалгаврын системийг дахин дүгнэж, хоёр шинэ хүлээн зөв, макро-F1-ийн тохиромжтой хэмжээсүүдийг дахин дүгнэж чадахгүй гэдгийг харуулж байна. Энэ асуудлыг даван туулахын тулд бид шинэ үнэлгээний метрикийг шинэ санал өгдөг. Эдгээр нь зөвхөн тэнцвэртэй өгөгдлийн талаар хүчтэй биш, мөн хамгийн их мэдээллийн цөөнх хэсгийг таних боломжтой өндөр системүүдийг тооцоолж байна.', 'pl': 'Klasyfikacja stanu może być potężnym narzędziem do zrozumienia, czy i którzy użytkownicy wierzą w plotki online. Celem zadania jest automatyczne przewidywanie stanowiska odpowiedzi wobec danej plotki, a mianowicie poparcie, zaprzeczanie, pytanie lub komentarz. Zaproponowano liczne metody i porównano ich wydajność w ramach RumourEval wspólnych zadań w latach 2017 i 2019. Wyniki wykazały, że jest to problem wymagający, ponieważ naturalnie występujące dane dotyczące stanu plotek są bardzo niezrównoważone. Niniejszy artykuł szczególnie kwestionuje wskaźniki oceny stosowane w tych wspólnych zadaniach. Ponownie oceniamy systemy przedłożone do dwóch zadań RumourEval i pokazujemy, że dwie powszechnie przyjęte wskaźniki: większa dokładność i makro-F1 dawki nie są solidne dla czteroklasowych zadań niezrównoważonej klasy klasyfikacji stanowiska plotek, ponieważ błędnie faworyzują systemy o wysokiej skróconej dokładności wobec klasy większości. Aby przezwyciężyć ten problem, proponujemy nowe wskaźniki oceny dla wykrywania stanowiska plotek. Są one nie tylko solidne w odniesieniu do niezrównoważonych danych, ale również zdolne do rozpoznania dwóch najbardziej informacyjnych klas mniejszości (poparcie i zaprzeczenie).', 'mt': "Il-klassifikazzjoni tal-pożizzjoni tista’ tkun għodda qawwija biex wieħed jifhem jekk u liema utenti jemmnux f’rumori onlajn. Il-kompitu għandu l-għan li jipprevedi awtomatikament il-pożizzjoni tat-tweġibiet lejn rumor partikolari, jiġifieri appoġġ, ċa ħda, mistoqsija, jew kumment. Ġew proposti bosta metodi u l-prestazzjoni tagħhom imqabbla fil-kompiti kondiviżi ta’ RumourEval fl-2017 u l-2019. Ir-riżultati wrew li din hija problem a ta’ sfida peress li d-dejta dwar il-pożizzjoni tar-rumori li sseħħ b’mod naturali hija żbilanċjata ħafna. Dan id-dokument jiddubita speċifikament il-metriċi ta’ evalwazzjoni użati f’dawn il-kompiti kondiviżi. Aħna nivvalutaw mill-ġdid is-sistemi sottomessi liż-żewġ kompiti RumourEval u nuru li ż-żewġ metriċi adottati b'mod wiesa' - il-preċiżjoni u l-makro-F1 - mhumiex robusti għall-kompitu żbilanċjat ta' erba' klassijiet tal-klassifikazzjoni tal-pożizzjoni tar-rumor, peress li huma b'mod żbaljat jiffavorixxu sistemi b'preċiżjoni żbaljata ħafna lejn il-klassi maġġoritarja. Biex tingħeleb din il-problema, nipproponu metriċi ġodda ta’ evalwazzjoni għall-identifikazzjoni tal-pożizzjoni tar-rumori. Dawn mhumiex biss b’saħħithom għal dejta żbilanċjata iżda wkoll għandhom sistemi ogħla li huma kapaċi jirrikonoxxu ż-żewġ klassijiet minoritarji l-aktar informativi (appoġġ u ċaħda).", 'no': 'Stance-klassifikasjon kan vera eit kraftig verktøy for å forstå om brukarar tror på online rumorer og kva. Oppgåva må automatisk forhåndsvisa staden for svarar mot ein gitt rumor, som er støtte, nekt, spørsmål eller kommentar. Mange metodar er foreslått og utviklinga sine sammenlignet i RumourEval delte oppgåver i 2017 og 2019. Resultat viste at dette er eit vanskeleg problem sidan naturleg oppstår rumorestasjonsdata er svært ulik. Denne papiret spør spesielt om evalueringsmetrikane som brukar i desse delte oppgåva. Vi evaluerer systema gjenopprett til dei to RumourEval-oppgåva og viser at dei to breidde godtatte metrikane - akkurat og makro-F1 - er ikkje robust for det fire klassiske imbalanserte oppgåva av rumorestasjonsklassifikasjonen, sidan dei feil står for systema med stor akkurat mot dei fleste klassen. For å overføra dette problemet, foreslår vi nye evalueringsmetrikar for oppdaging av rumorestasjon. Desse er ikkje berre kraftige for ulike data, men også reknar høgare systemar som kan gjenkjenne dei to mest informativte minoritetsklassene (støtte og nekta).', 'ro': 'Clasificarea poate fi un instrument puternic pentru a înțelege dacă și ce utilizatori cred în zvonurile online. Sarcina urmărește să prezică automat poziția răspunsurilor față de un anumit zvon, și anume sprijinul, negarea, întrebarea sau comentariul. Au fost propuse numeroase metode și performanța lor comparată în sarcinile partajate de RumourEval în 2017 și 2019. Rezultatele au demonstrat că aceasta este o problemă dificilă, deoarece datele privind poziția zvonurilor care apar în mod natural sunt foarte dezechilibrate. Această lucrare pune întrebări specifice valorile de evaluare utilizate în aceste sarcini partajate. Reevaluăm sistemele supuse celor două sarcini RumourEval și arătăm că cele două măsurători adoptate pe scară largă - precizia și macro-F1 - nu sunt robuste pentru sarcina dezechilibrată de patru clase de clasificare a poziției zvonurilor, deoarece favorizează în mod greșit sistemele cu o precizie extrem de distorsionată față de clasa majoritară. Pentru a depăși această problemă, propunem noi valori de evaluare pentru detectarea poziției zvonurilor. Acestea nu sunt doar solide pentru datele dezechilibrate, ci și pentru sistemele superioare care sunt capabile să recunoască cele două clase minoritare cele mai informative (susțină și negă).', 'so': "Takhasuska shaqadu wuxuu noqon karaa qalabka xoogga leh oo ku garan karo in isticmaalayaashu ay rumaystaan wararka internetka. Shaqadu wuxuu ku qoran yahay inuu horay u sii sheegayo xaaladda jawaabaha warqada la qoray, tusaale ahaan kaalmeynta, diida, su'aalka ama kommentaha. Waxaa la soo jeeday qaabooyin badan oo ay sameyn jireen oo la barbaran karo shuqullada lagu qaybsaday RumourEval 2017 iyo 2019. Resultiyada waxay muuqatay in taasu dhibaato adag tahay, sababtoo ah marka dabiicadda ka soo dhaca macluumaadka xaaladda beenta ah aad looma simo. Kanu wuxuu si gaar ah ka weydiinayaa qiimeynta qaababka lagu isticmaalayo shaqaalahaas. Waxaynu mar kale qiimeynaynaa nidaamka loo soo dhiibay labada shuqul ee RumourEval, waxaana tusaynaa in labada qaab oo ballaadhan loo soo qaaday metric - saxda iyo macro-F1 - looma xado fasalka afarta fasalka oo aan isku mid ahayn shaqo fasalka warqada ah, sababtoo ah waxay si khalad ah u jecel yihiin nidaamka aad u saxday fasalka badan. Si aan dhibaatadan uga adkaado, waxaynu soo jeedinnaa qalabka qiimeynta cusub si aan u ogaano xaaladda beenta. Kuwaasu ma ahan macluumaad aan la garanayn oo kaliya, laakiin waxay sidoo kale shaqeeyaan nidaam sare oo aqoonsan karta labada fasalada ugu badan ee macluumaadka (kaalmeynta iyo diidinta).", 'sr': 'Klasifikacija stanica može biti moćna alata za razumevanje da li i koje korisnici veruju u online glasine. Taj zadatak je cilj automatski predviđati stanje odgovora na određenu glasinu, a to je podrška, poricanje, pitanje ili komentar. Predloženi su brojni metodi i njihov učinkovit u usporedbi u podjeljenim zadacima RumourEval 2017. i 2019. godine. Rezultati su pokazali da je ovo izazovni problem pošto se prirodno dogaðaju glasine, podaci o stanju stanja su veoma neravnoteženi. Ovaj papir posebno ispituje metrike za procjenu koja se koristi u ovim zajedničkim zadacima. Ponovno procjenjujemo sisteme podnošene dva zadatka RumourEval i pokazujemo da dve široko usvojene metrike - tačnost i makro-F1 - nisu robne za četiri klase imbalansiranog zadatka klasifikacije glasina stanja, jer nepravedno podržavaju sisteme sa visokom iskrenom preciznošću prema većini klase. Da bi prevarili ovaj problem, predlažemo nove procjene metrike za otkrivanje glasina. To nisu samo moćne za nepravilne podatke, već i rezultate višeg sistema koji su sposobni da prepoznaju dve najinformativnije klase manjina (podrška i poriču).', 'sv': 'Stance klassificering kan vara ett kraftfullt verktyg för att förstå om och vilka användare tror på rykten online. Uppgiften syftar till att automatiskt förutsäga svarens inställning till ett visst rykte, nämligen stöd, förneka, fråga eller kommentar. Flera metoder har föreslagits och deras prestanda jämförts i RumourEval delade uppgifter 2017 och 2019. Resultaten visade att detta är ett utmanande problem eftersom data om naturligt förekommande rykten är mycket obalanserade. Denna uppsats ifrågasätter specifikt de utvärderingsmetoder som används i dessa delade uppgifter. Vi omvärderar de system som lämnats in för de två RumourEval-uppgifterna och visar att de två allmänt använda mätvärdena - noggrannhet och makro-F1 - inte är robusta för den fyrklassiga obalanserade uppgiften med klassificering av ryktesställningar, eftersom de felaktigt gynnar system med mycket snedvriden noggrannhet mot majoritetsklassen. För att lösa detta problem föreslår vi nya utvärderingsmetoder för detektering av rykten. Dessa är inte bara robusta för obalanserade data, utan även högre system som kan känna igen de två mest informativa minoritetsklasserna (stöd och förneka).', 'si': 'ස්ටෑන්ස් විශ්වාස කරන්න පුළුවන් අන්ලයින් කියලා විශ්වාස කරන්න පුළුවන් බලාපොරොත්තු උපකර කාර්ය ස්වයංක්\u200dරමයෙන් ප්\u200dරතිචාරයක් දෙන්න ප්\u200dරතිචාරයක් ගැන ප්\u200dරතිචාරයක් ස්වයංක්\u200dරමයෙන් ප්\u200dරතිචා සංඛ්\u200dයාත්මක විදියට ප්\u200dරතිචාර කරලා තියෙන්නේ, ඒ වගේම ඔවුන්ගේ ප්\u200dරතිචාර විදියට ප්\u200dරතිචාර කර ප්\u200dරතිචාරයක් පෙන්වන්න පුළුවන් විදිහට මේක ප්\u200dරශ්නයක් කියලා ප්\u200dරශ්නයක් තියෙනවා ස්වභාවිතයෙන් ස මේ පත්තුව විශේෂයෙන් ප්\u200dරශ්නයක් විශේෂයෙන් මේට්\u200dරික් විශ්වාස කරන්න ප්\u200dරශ්නයක් මෙම අපි ආපහු විශ්වාස කරනවා පද්ධතිය දෙන්නම් රූමියර්වේල් වැඩේ දෙන්නම් ප්\u200dරතික්\u200dරියා කරනවා ඒ වගේම ප්\u200dරතික්\u200dරියාත්මක දෙන්නම් ප්\u200dරතික්\u200dරියාත්මක විශ්වාස කරනවා කියලා ප මේ ප්\u200dරශ්නයක් වැඩ කරන්න, අපි අළුත් විශ්වාස මෙට්\u200dරික්ස් එක ප්\u200dරශ්නය කරනවා කියලා. මේවා නිර්මාණය කරපු දත්ත විතරක් නෙවෙයි නමුත් වැඩි පද්ධති පද්ධතියක් පරික්ෂා කරන්න පුළුවන් විතරක් නෙවෙයි, ඒ ව', 'ur': 'استنس کلاسیفون ایک طاقتور ابزار ہے کہ سمجھ سکتے ہیں کہ کیا اور کون کارساز آنلاین افسانے پر ایمان رکھتے ہیں۔ اس کام کا ارادہ یہ ہے کہ ایک عظیم کے بارے میں جواب دینے کی موقعیت کو اپنے ساتھ پیش کرو، یعنی حمایت، انکار، سوال، یا توضیح. بہت سی طریقے پیشنهاد کیے گئے ہیں اور ان کی عملکرد 2017 اور 2019 میں RumourEval کے مشترک کاموں میں مقابلہ کیے گئے ہیں. نتائج دکھائے گئے کہ یہ ایک مشکل ہے جبکہ طبیعی طور پر اترا ہوا رغبت موقعیت ڈیٹا بہت برابر ہے. یہ کاغذ مخصوصا سوال کرتا ہے کہ ان مشترک کاموں میں استعمال کیا جاتا ہے. ہم نے ان سیستموں کو دوبارہ تحقیق کر دیا جو دو روmourEval کے کاموں پر پیش کیے گئے ہیں اور دکھا دیتے ہیں کہ ان دونوں وسیع مٹریک - دقیق اور مکروF1 - چار کلاس کی غیر قابل غیر قابل تعلق کے کام کے لئے نہیں ہیں، کیونکہ وہ بہت سی کلاس کے مطابق غیر قابل تعلق کے سیستموں پر غلط تعلق رکھتے ہیں۔ اس مسئلہ پر غالب ہونے کے لئے ہم نئی ارزیابی متریک کی پیشنهاد کریں گے۔ یہ نہیں صرف غیر قابل تعمیر کی دکھائی کے لئے ہیں بلکہ اس سے بھی زیادہ سیستموں کو ثابت قدم رکھتے ہیں جو دو بہترین غیر معلومات کے کلاس کو پہچان سکتے ہیں (مدد اور انکار کرنے کے لئے).', 'ta': 'நிலை வகைப்படுத்தல் வலிமையான கருவியாக இருக்கலாம் ஆன்லைன் வார்த்தைகள் நம்புகிறார் கொடுக்கப்பட்ட குறிப்பிட்ட வார்த்தைக்கு பதில் நிலையை தானாகவே முன்கூற வேண்டும். பல முறைகள் பரிந்துரைக்கப்பட்டுள்ளது மற்றும் அவர்கள் செயல்பாடு தொடர்பு கொண்டிருக்கிறது RumourEval 2017 மற்றும் 2019ல் பங்க முடிவுகள் காண்பிக்கப்பட்டுள்ளது இது சவாலிக்கையான பிரச்சனை இந்த காகிதத்தில் குறிப்பிட்ட மதிப்பீடு மெட்ரிக்கள் இந்த பங்கிட்ட பணிகளில் பயன்படுத்தப்பட்டுள் மீண்டும் சொல்லப்பட்ட இரண்டு செயல்களுக்கு வழங்கப்பட்ட அமைப்புகளை மீண்டும் பரிசோதிக்கவும் மற்றும் இவை இரண்டு விரிவாக பயன்படுத்தப்பட்ட மெட்ரிக்கள் - சரியாக மற்றும் மேக்ரோ-F1 - நான்கு வக இந்த பிரச்சனையை வெற்றி பெற, நாம் புதிய ஆய்வு முறைகளை பரிந்துரைக்கிறோம் குரல் நிலையில் கண்டு These are not only robust to imbalanced data but also score higher systems that are capable of recognising the two most informative minority classes (support and deny).', 'vi': 'Bản phân loại Stance có thể là một công cụ mạnh mẽ để hiểu liệu và những người dùng tin vào những tin đồn trực tuyến. Nhiệm vụ này nhằm hướng tới việc dự đoán tự động phản ứng của lời đồn, là hỗ trợ, từ chối, câu hỏi, hay bình luận. Nhiều phương pháp đã được đề xuất và kết quả của chúng được so sánh trong các nhiệm vụ chia sẻ RumourEvl tại Ngực và Ngực. Kết quả cho thấy đây là một vấn đề thách thức vì những dữ liệu xung đột xuất hiện tự nhiên không cân bằng. Tờ giấy này đặt câu hỏi cụ thể về tỉ lệ đánh giá được dùng trong các nhiệm vụ chia sẻ. Chúng tôi đánh giá lại hệ thống được giao cho hai nhiệm vụ Rumour Evol và cho thấy hai hệ thống đo lường được phổ biến chính xác và macro-F1 không vững chắc cho nhiệm vụ phù hợp phân loại phỏng tin đồn, vì chúng sai lầm chọn hệ thống với độ chính xác cao cao với hạng đa số. Để giải quyết vấn đề này, chúng tôi đề xuất tỉ lệ đánh giá mới để phát hiện trang tin đồn. Đây không chỉ là dữ liệu thiếu cân bằng, mà còn ghi được các hệ thống cao hơn có khả năng nhận diện hai lớp thiểu số thông tin nhất (hỗ trợ và từ chối).', 'uz': "Stans classifikasi onlayn gapiradigan foydalanuvchilar nima gapirishga ishonchini tushunish uchun katta vosita bo'ladi. Name Ko'pchilik usullar talab qilindi va RumourEval 2017 va 2019 yilda qayta ishlarda qismlashtirilgan vazifalarga kamaytirilgan. @ info Ushbu qogʻoz shu bilan bogʻliq vazifalarga ishlatilgan qiymatning metriklaridan foydalanadi. Biz ikkita Rumor Eval vazifalarini qaytadan qiymatmiz va ikkita kengaytirilgan metriklarni ko'rsatdik - tasdiqlik va makro-F1 - to'rt sinfning to'rtta sinfga oʻxshash vazifani olib tashlaydi, chunki ularning ko'plab sinfga juda ko'proq aniqlangan tizimlarni ko'proq foydalanadi. Bu muammolarni oshirish uchun biz yangi qiymatni qiymatlash metriklarini anglatamiz. Bu faqat imkoniyatli maʼlumot uchun olib tashlanmaydi, balki ikkita haqiqida maʼlumot minority sinfni (qoʻllash va rad etish mumkin boʻlgan eng yuqori tizimlarni aniqlash mumkin.", 'nl': 'Stance classificatie kan een krachtig hulpmiddel zijn om te begrijpen of en welke gebruikers geloven in online geruchten. De taak beoogt automatisch de houding van antwoorden te voorspellen ten opzichte van een bepaald gerucht, namelijk steun, ontkennen, vragen of commentaar. Talrijke methoden zijn voorgesteld en hun prestaties vergeleken in de gedeelde taken van RumourEval in 2017 en 2019. De resultaten toonden aan dat dit een uitdagend probleem is, aangezien natuurlijk voorkomende geruchtstandpunten zeer onevenwichtig zijn. In dit artikel wordt specifiek gekeken naar de evaluatiestatistieken die worden gebruikt in deze gedeelde taken. We evalueren de systemen die aan de twee RumourEval-taken zijn voorgelegd en laten zien dat de twee algemeen aangenomen metrics: nauwkeurigheid en macro-F1 p niet robuust zijn voor de vier-klassen onevenwichtige taak van geruchtstandclassificatie, omdat ze ten onrechte systemen met zeer scheeve nauwkeurigheid ten opzichte van de meerderheidsklasse prefereren. Om dit probleem op te lossen, stellen we nieuwe evaluatiestatistieken voor voor het detecteren van geruchten standpunten. Deze zijn niet alleen robuust tegen onevenwichtige gegevens, maar scoren ook hogere systemen die in staat zijn om de twee meest informatieve minderheidsklassen te herkennen (ondersteuning en ontkennen).', 'bg': 'Класификацията на позициите може да бъде мощен инструмент за разбиране дали и кои потребители вярват в онлайн слухове. Задачата има за цел автоматично да предвиди позицията на отговорите към даден слух, а именно подкрепа, отричане, въпрос или коментар. Предложени са множество методи и тяхното представяне сравнено в споделените задачи през 2017 и 2019 г. Резултатите показаха, че това е предизвикателен проблем, тъй като данните за естествената позиция на слуховете са силно дисбалансирани. Тази статия конкретно поставя под въпрос показателите за оценка, използвани в тези споделени задачи. Преоценяваме системите, подложени на двете задачи и показваме, че двете широко приети показатели - точност и макро-Формула - не са стабилни за четирикласната дисбалансирана задача на класификация на позицията на слуховете, тъй като те неправилно благоприятстват системи с силно изкривена точност спрямо класа на мнозинството. За да преодолеем този проблем, предлагаме нови измервателни показатели за откриване на позицията на слуховете. Те са не само стабилни към дисбалансирани данни, но и по-високи системи, които са способни да разпознават двете най-информативни малцинствени класове (подкрепа и отричане).', 'hr': 'Klasifikacija stanica može biti moćan alat za razumijevanje da li i koje korisnici vjeruju u online glasine. Cilj zadatka je automatski predviđati stanje odgovora na određenu glasinu, a to je podrška, poricanje, pitanje ili komentar. Predloženi su brojni metodi i njihov učinkovit u usporedbi s djelovanjem RumourEval-a u 2017. i 2019. godine. Rezultati su pokazali da je ovo izazovni problem jer su podaci o stanju glasina vrlo neravnoteženi. Ovaj papir posebno pita mjere procjene koje se koriste u ovim zajedničkim zadatkima. Ponovno procjenjujemo sisteme podnošene dva zadatka RumourEval-a i pokazujemo da dvije široko usvojene metrike - preciznost i makro-F1 - nisu jake za četiri klase imbalansirane zadatke klasifikacije glasina stanja, jer nepravedno podržavaju sustave s visokom iskrenom preciznošću prema većini klase. Za prevladanje ovog problema predlažemo nove procjene metrike za otkrivanje glasina. To nisu samo snažni za neravnotežene podatke, već također rezultiraju viši sustavi koji su sposobni prepoznati dvije najinformativnije klase manjina (podrška i odbijanje).', 'da': 'Stance klassificering kan være et kraftfuldt redskab til at forstå, om og hvilke brugere tror på online rygter. Opgaven sigter mod automatisk at forudsige svarenes holdning til et givet rygte, nemlig støtte, benægte, spørge eller kommentere. Der er blevet foreslået talrige metoder og deres resultater sammenlignet i RumourEval delte opgaver i 2017 og 2019. Resultaterne viste, at dette er et udfordrende problem, da naturligt forekommende rygteinformationer er stærkt ubalancerede. Dette dokument stiller specifikt spørgsmålstegn ved de evalueringsmetrics, der anvendes i disse delte opgaver. Vi genvurderer de systemer, der er indsendt til de to RumourEval-opgaver, og viser, at de to vidt anvendte målinger - nøjagtighed og makro-F1 - ikke er robuste til den fireklasses ubalancerede opgave med rygtestænkning klassificering, da de fejlagtigt favoriserer systemer med stærkt skæv nøjagtighed i forhold til majoritetsklassen. For at løse dette problem foreslår vi nye evalueringsmålinger til detektering af rygter. Disse er ikke kun robuste til ubalancerede data, men scorer også højere systemer, der er i stand til at genkende de to mest informative minoritetsklasser (støtte og benægte).', 'id': 'Stance classification can be a powerful tool for understanding whether and which users believe in online rumours.  Tugas ini bermaksud untuk secara otomatis memprediksi posisi jawaban terhadap rumor tertentu, yaitu dukungan, menyangkal, pertanyaan, atau komentar. Banyak metode telah diusulkan dan prestasi mereka dibandingkan dalam RumourEval berbagi tugas pada 2017 dan 2019. Hasil menunjukkan bahwa ini adalah masalah yang menantang karena data posisi rumor yang terjadi secara alami sangat tidak seimbang. This paper specifically questions the evaluation metrics used in these shared tasks.  We re-evaluate the systems submitted to the two RumourEval tasks and show that the two widely adopted metrics - accuracy and macro-F1 - are not robust for the four-class imbalanced task of rumour stance classification, as they wrongly favour systems with highly skewed accuracy towards the majority class.  To overcome this problem, we propose new evaluation metrics for rumour stance detection.  Ini bukan hanya kuat untuk data yang tidak seimbang tetapi juga skor sistem yang lebih tinggi yang mampu mengakui dua kelas minoritas yang paling informatif (dukungan dan menyangkal).', 'de': 'Die Stanzklassifizierung kann ein mächtiges Werkzeug sein, um zu verstehen, ob und welche Nutzer an Online-Gerüchte glauben. Die Aufgabe zielt darauf ab, automatisch die Haltung der Antworten zu einem bestimmten Gerücht vorherzusagen, nämlich zu unterstützen, zu leugnen, zu hinterfragen oder zu kommentieren. Zahlreiche Methoden wurden vorgeschlagen und ihre Leistung in den gemeinsamen Aufgaben von RumourEval in 2017 und 2019 verglichen. Die Ergebnisse zeigten, dass dies ein herausforderndes Problem ist, da natürlich vorkommende Gerüchthaltungsdaten stark unausgewogen sind. In diesem Papier werden speziell die Bewertungsmetriken in diesen gemeinsamen Aufgaben untersucht. Wir evaluieren die Systeme, die den beiden RumourEval-Aufgaben unterzogen wurden, neu und zeigen, dass die beiden weit verbreiteten Metriken: Genauigkeit und Makro-F1 p nicht robust für die Vier-Klassen-Ungleichgewichte-Klassifikation sind, da sie fälschlicherweise Systeme mit stark verzerrter Genauigkeit gegenüber der Mehrheitsklasse bevorzugen. Um dieses Problem zu überwinden, schlagen wir neue Bewertungsmetriken für die Erkennung von Gerüchten vor. Diese sind nicht nur robust gegen ungleichgewichtige Daten, sondern auch höhere Systeme, die in der Lage sind, die beiden informativsten Minderheitenklassen zu erkennen (Unterstützung und Ablehnung).', 'ko': '입장 분류는 사용자가 온라인 루머를 믿는지, 어떤 사용자가 온라인 루머를 믿는지 파악하는 유력한 도구다.이 임무는 주어진 루머에 대한 지지, 부인, 문제, 논평에 대한 답변을 자동으로 예측하는 데 목적을 두고 있다.2017년과 2019년의 Rumoreval 공유 임무에서는 이미 많은 방법을 제시하고 그것들의 성능을 비교했다.그 결과 자연적으로 발생하는 루머의 입장 데이터가 고도로 불균형하기 때문에 도전적인 문제였다.본고는 특히 이러한 공유 임무에 사용되는 평가 지표에 대해 의문을 제기한다.우리는 두 개의 Rumor Eval 임무에 제출된 시스템을 재평가하고, 두 가지 광범위하게 사용되는 지표인 정확도와 Macro-F1을 나타냈다. 루머의 입장 분류에 대한 네 가지 불균형 임무는 안정적이지 않다. 왜냐하면 그들은 정확도가 다수의 유형으로 기울어지는 시스템에 잘못된 경향이 있기 때문이다.이 문제를 극복하기 위해 우리는 새로운 유언비어 입장 검측 평가 지표를 제시했다.그들은 불균형 데이터에 대해 노봉성을 가지고 있을 뿐만 아니라 두 정보량이 가장 많은 소수 집단 유형(지원과 거부)을 식별할 수 있는 시스템의 득점도 높다.', 'fa': 'طراحی استنس می تواند یک ابزار قدرتمند برای فهمیدن آیا و کدام کاربر به شایعات آنلاین اعتقاد دارند. این وظیفه را هدف می\u200cدهد که موقعیت پاسخ به شایعه\u200cای که به آن داده شده پیش بینی کند، یعنی پشتیبانی، انکار، سوال، یا توضیح دهد. روش\u200cهای تعدادی پیشنهاد داده شده و عملکرد آنها در مقایسه با وظیفه\u200cهایی که در سال ۲۰۱۷ و ۲۰۱۹ مشترک بودند مقایسه شده است. نتیجه\u200cها نشان دادند که این یک مشکل سخت\u200cکننده است از آنجا که داده\u200cهای شرایط طبیعی اتفاق می\u200cافتد، خیلی نابرابری شده است. این کاغذ مخصوصا سوال می\u200cکند که متریک ارزیابی در این کار مشترک استفاده می\u200cشود. ما سیستم\u200cها را دوباره ارزیابی می\u200cکنیم که به دو وظیفه\u200cای روم\u200cایول ارزیابی شده\u200cاند و نشان می\u200cدهیم که دو متریک - دقیق و مکرو-اف1 - برای وظیفه\u200cای نابرابری از چهار طبقه\u200cای از شرایط شایعه\u200cهایی که به اشتباهی از سیستم\u200cها با دقیق بسیاری از کلاس\u200cهای بیشتری به نظر می\u200cآورند، قدر برای تغییر این مشکل، ما پیشنهاد می\u200cکنیم متریک ارزیابی جدید برای شناسایی شرایط شایعات. اینها نه تنها برای داده های نابرابری قوی هستند بلکه سیستم های بالاتری که قادر به شناختن دو کلاس کوچک های اطلاعات بیشتری هستند (پشتیبانی و انکار).', 'sw': 'Utafiti wa kituo kinaweza kuwa chombo kikuu cha kuelewa kama na watumiaji gani wanaamini uvumi wa mtandaoni. Kazi hiyo inakusudia kutabiri msimamo wa majibu kwenye uvumi ulio pewa, kama vile kuunga mkono, kukataa, kuuliza, au maoni. Utawala kadhaa umependekezwa na utendaji wao ulilinganishwa na kazi za RumourEval zilizoshirikishwa mwaka 2017 na 2019. Matokeo yalionyesha kuwa hili ni tatizo la changamoto kwani takwimu za msimamo wa ukweli zinazotokea ni ukosefu mkubwa. This paper specifically questions the evaluation metrics used in these shared tasks.  Tutathmini tena mfumo uliotolewa kwenye kazi hizi mbili za Ujumbe wa Habari na kuonyesha kuwa mbinu hizo zilizochukuliwa vizuri - ukweli na makro-F1 - hawawezi kubaguliwa kwa kazi za darasa nne zisizo na usawa wa msimamo wa uvumi, kwa sababu wanaipenda mifumo yenye uhakika mkubwa kwa darasa kubwa. Ili kushinda tatizo hili, tunapendekeza mbinu mpya ya uchunguzi wa ukweli. Hawa si tu kwa ajili ya takwimu zisizo na usawa bali pia hupandisha mfumo wa juu ambao una uwezo wa kutambua darasa hizo mbili zenye taarifa (kuunga mkono na kukataa).', 'af': "Stance klasifikasie kan 'n kragtige hulpmiddel wees vir verstaan of en wat gebruikers in online rumours glo. Die taak bepaal om outomaties die staanse van antwoorde te voorskou na 'n gegewe rumor, bedoel ondersteun, verwerp, vraag of kommentaar. Algemeen metodes is voorgestel en hulle prestasie vergelyk in die RumourEval deel opdragte in 2017 en 2019. Resultate het bevestig dat hierdie is 'n pragtige probleem, omdat natuurlik die rumourstaanse data voorgekom is baie onbalanse. Hierdie papier spesifieke vra die evaluering metries gebruik word in hierdie gedeelde taak. Ons reevalueer die stelsels wat aan die twee RumourEval-opdragte ondersteun is en wys dat die twee vaste aangeneem metrike - akkuraat en makro-F1 - nie sterk is vir die vier klasse imbalanseerde opdrag van rumour staatsklasifikasie nie, omdat hulle verkeerd guns stelsels met baie skakel presies teen die meeste klas nie. Om hierdie probleem te oorwin, voorstel ons nuwe evalueringsmetries vir rumour staatsopdekking. Hierdie is nie net kragtige na onbalanse data nie, maar ook tel hoëre stelsels wat is in staat om die twee mees informatiewe minoriteitsklasse te herken (ondersteun en verweier).", 'tr': 'Stans klasifikasy internede a ýdyşylara ynanýanlaryny düşünmek üçin güýçli bir araç bolup biler. Görev berilen a ýdyşyň jogabynyň durumyny awtomatik täze tahmin etmek maksady bolýar.Şeýle bolsa desteklenmek, inkar etmek, soragy ýa-da terjime etmek. Aç sany yöntemler teklip edildi we olaryň etkinlikleri RumourEval 2017 we 2019-nji ýylda gurlap çykyşleri bilen gurlapdyr. Netijenler bu kynçylyk kynçylykdygyny görkezildi, dogry ýagdaýyň durum maglumaty örän täsirli däldir. Bu kagyz şol paylaşyk işinde ulanylan çykyş metriklerini kesinlikle soraýar. Biz RumourEval iki zada berilen sistemalary ýene-de deňleýäris we iki köp üýtgedilen metrikleriň dogrylygyny we makro-F1-iň dört synpdaky aýratyn taýýarlanmagy üçin dört synpdaky aýratyn taýýarlanmagy üçin ýok däldir, sebäbi olar köp synpdaky derejesini boýun gaýtalandyrýarlar. Şu meseläni üstden çykmak üçin, diňe jogabat tapmak üçin täze deňlenme metriklerini teklip edýäris. Bular diňe täze daty täze etmek üçin güýçli däl, ýöne bu iki iň informatiýa azyndan täze synplary tanamak üçin ýokary sistemalary gowy görkez.', 'sq': 'Klasifikimi i qëndrimit mund të jetë një mjet i fuqishëm për të kuptuar nëse dhe cili përdorues beson në thashethemet online. The task aims to automatically predict the stance of replies towards a given rumour, namely support, deny, question, or comment.  U propozuan metoda të shumta dhe paraqitja e tyre krahasuar me detyrat e përbashkëta të RumourEval në 2017 dhe 2019. Rezultatet treguan se ky është një problem sfidues pasi të dhënat e qëndrimit të thashethemeve që ndodhin natyralisht janë shumë të paekuilibruara. Ky dokument pyet specifikisht metrikat e vlerësimit të përdorura në këto detyra të përbashkëta. We re-evaluate the systems submitted to the two RumourEval tasks and show that the two widely adopted metrics - accuracy and macro-F1 - are not robust for the four-class imbalanced task of rumour stance classification, as they wrongly favour systems with highly skewed accuracy towards the majority class.  To overcome this problem, we propose new evaluation metrics for rumour stance detection.  Këto nuk janë vetëm të forta për të dhënat e paekuilibruara, por gjithashtu shënojnë sisteme më të larta që janë në gjendje të njohin dy klasat më informative të pakicave (mbështetje dhe mohim).', 'hy': 'Stance classification can be a powerful tool for understanding whether and which users believe in online rumours.  The task aims to automatically predict the stance of replies towards a given rumour, namely support, deny, question, or comment.  Շատ մեթոդներ են առաջարկվել և դրանց արտադրողությունը համեմատել է 2017-ին և 2019-ին ընդհանուր ձայների ընթացքում: Արդյունքները ցույց տվեցին, որ սա մարտահրավեր է, քանի որ բնական ձայների դիրքի տվյալները բարձր անհավասարակշռություն ունեն: This paper specifically questions the evaluation metrics used in these shared tasks.  We re-evaluate the systems submitted to the two RumourEval tasks and show that the two widely adopted metrics - accuracy and macro-F1 - are not robust for the four-class imbalanced task of rumour stance classification, as they wrongly favour systems with highly skewed accuracy towards the majority class.  Այս խնդիրը հաղթահարելու համար մենք առաջարկում ենք նոր գնահատման մետրիկներ լսումների դիրքի հայտնաբերման համար: These are not only robust to imbalanced data but also score higher systems that are capable of recognising the two most informative minority classes (support and deny).', 'az': 'Stance klasifikasiyası internette söhbətlərə in and ığını və hansı istifadəçiləri anlamaq üçün güclü bir vasitə olar. Bu işin təkrar verilən sözlərə cavab verəcəyi şəkildə təkrar-təkrar təşkil etmək məqsədilə idi: dəstək, inkar, sual və ya komentar. 2017 və 2019-də RumourEval paylaşdığı işlərdə qarşılaşdırılmış çox metodlar təbliğ edilmişdir. Sonuçlar göstərdilər ki, bu çox çətin bir problemdir, çünki doğal olaraq gələn səslər durum məlumatları çox müqayisədir. Bu kağıt bu paylaşdırılmış işlərdə istifadə edilən değerlendirmə metriklərini soruşur. Biz iki RumourEval işinə göndərilən sistemləri yenidən değerləşdiririk və iki geniş qəbul edilmiş metrik - doğruluğu və makro-F1 - dörd sınıf müəyyən edilmiş səslər müəyyən edilməsi üçün qüvvətli deyildir, çünki onlar çoxluğuna qarşı çoxluğu dəstə ilə sistemləri haqsız yerə yaxınlıq edirlər. Bu problemi üstün etmək üçün yeni değerlendirmə metrikləri təklif edirik. Bunlar yalnız müəyyən edilmiş verilənlərə güclü deyildir, lakin bu iki ən informativ azınlıq dəstəsini tanıma qadir olan yüksək sistemləri də müəyyən edirlər.', 'am': 'የስቴን መግለጫ ማስተውል ኃይለኛ መሆኑን እና ተጠቃሚዎቹ በonline ውጤቶች የሚያምኑ መሆኑን ለማስተዋል ይችላል፡፡ ስራው በተሰጠው ውሸት፣ ደግሞም፣ ክደዋል፣ ጥያቄ ወይም ትርጓሜ ለመቀበል የሚደረገውን መልዕክቶች በራስነት ለመቀበል ይችላል፡፡ በሪሙርEval ውስጥ በ2017 እና 2019 በተካፈሉት ስራዎችን ተካክሎ የተዘጋጀ ሥርዓቶች ተጨማሪው፡፡ ፍጥረቶቹ የውጤት ዳታዎች በጣም ትክክለኛ እንደሆነ ይህ የሚያቃጥል መከራ ነው፡፡ ይህ ገጽ በተለያዩ ስራ ውስጥ የተጠቃሚ ሚትርኮችን ይጠይቃል፡፡ የሁለቱን የውይይት አድራጊዎች የደረሱትን ስርዓቶች እንደገና እናሳውቃለን፣ ሁለቱም ተቃውሞ የተመረጡትን እና ማክሮ-F1 - ለአራቱ ክፍል የውይይት ሁኔታ ትክክለኛ ስርዓት ሳይሰርቁ፣ በተሳሳታም ስርዓት ወደ አብዛኞቹ ክፍል ይደሰታሉ፡፡ To overcome this problem, we propose new evaluation metrics for rumour stance detection.  These are not only robust to imbalanced data but also score higher systems that are capable of recognising the two most informative minority classes (support and deny).', 'bn': 'Stance classification can be a powerful tool for understanding whether and which users believe in online rumours.  এই কাজের উদ্দেশ্য হচ্ছে স্বয়ংক্রিয়ভাবে একটি গুজবের প্রতি উত্তরের অবস্থা ভবিষ্যদ্বাণী করা যায়, যেমন সমর্থন, অস্বীকার করে, প ২০১৭ এবং ২০১৯ সালে রুমুর ইভাল শেয়ার কর্মসূচীর তুলনায় তাদের অনেক পদ্ধতি প্রস্তাব করা হয়েছে। ফলাফল প্রদর্শন করেছে যে এটা একটি চ্যালেঞ্জ সমস্যা যেহেতু স্বাভাবিকভাবে গুজবের অবস্থানের তথ্য অত্যন্ত অসম্মত। এই পত্রিকাটি বিশেষ করে এই শেয়ার কর্মগুলোতে ব্যবহার করা মেট্রিকের মূল্য প্রশ্ন করেছে। We re-evaluate the systems submitted to the two RumourEval tasks and show that the two widely adopted metrics - accuracy and macro-F1 - are not robust for the four-class imbalanced task of rumour stance classification, as they wrongly favour systems with highly skewed accuracy towards the majority class.  এই সমস্যাকে জয়ী করার জন্য আমরা গুজবের অবস্থান সনাক্ত করার জন্য নতুন মেট্রিক প্রস্তাব করি। এগুলো শুধুমাত্র অসম্পূর্ণ তথ্যের কাছে রোবট করা নয়, কিন্তু উচ্চ সিস্টেম স্কোর করে যারা এই দুটি তথ্য সংখ্যালঘু শ্রেণীদের', 'bs': 'Klasifikacija stanica može biti moćna alata za razumijevanje da li i koje korisnici vjeruju u online glasine. Cilj zadataka je automatski predviđati stanje odgovora na određenu glasinu, a to je podrška, poricanje, pitanje ili komentar. Predloženi su brojni metodi i njihov učinkovit u usporedbi u podjeljenim zadacima RumourEval 2017. i 2019. godine. Rezultati su pokazali da je ovo izazovni problem jer su podaci o stanju glasina veoma neravnoteženi. Ovaj papir posebno ispituje mjere procjene koje se koriste u ovim zajedničkim zadatkima. Ponovno procjenjujemo sisteme podnošene dva zadatka RumourEval i pokazujemo da dvije široko usvojene metrike - preciznost i makro-F1 - nisu robne za četiri klase imbalansiranog zadatka klasifikacije glasina stanja, jer nepravedno podržavaju sisteme sa visokom iskrenom preciznošću prema klasi većine. Da bi prevarili ovaj problem, predlažemo nove procjene metrike za otkrivanje glasina. To nisu samo moćne za nepravilne podatke, već i rezultate višeg sustava koji su sposobni prepoznati dvije najinformativnije klase manjina (podrška i poricanje).', 'cs': 'Klasifikace postojů může být výkonným nástrojem pro pochopení, zda a kteří uživatelé věří v online fámy. Cílem úkolu je automaticky předvídat postoj odpovědí k dané fámě, konkrétně podpořit, popřít, otázkám nebo komentáři. Bylo navrženo mnoho metod a jejich výkonnost byla porovnána v RumourEvalu sdílené úkoly v letech 2017 a 2019. Výsledky ukázaly, že se jedná o náročný problém, protože přirozeně se vyskytující pověsti o postojích jsou vysoce nerovnovážené. Tento článek konkrétně otázky hodnotících metrik používaných v těchto sdílených úkolech. Přehodnocujeme systémy předložené k těmto dvěma úkolům RumourEval a ukážeme, že dvě široce přijaté metriky: přesnost a makro-F1 dopad nejsou robustní pro čtyřtřídní nevyvážený úkol klasifikace postojů zvěstí, protože nesprávně upřednostňují systémy s vysokou zkosenou přesností vůči většinové třídě. Abychom tento problém překonali, navrhujeme nové hodnotící metriky pro detekci pověstí. Ty jsou nejen robustní vůči nevyváženým datům, ale také skórují vyšší systémy, které jsou schopny rozpoznat dvě nejinformativnější menšinové třídy (podpora a popírání).', 'ca': "La classificació de posicions pot ser una eina poderosa per entendre si i quins usuaris creuen en rumors en línia. La tasca té l'objectiu de predir automàticament la posició de les respostes cap a una rumora dada, a saber, el suport, la negació, la pregunta o el comentari. S'han proposat molts mètodes i el seu rendiment comparat a la RumourEval va compartir tasques al 2017 i 2019. Results demonstrated that this is a challenging problem since naturally occurring rumour stance data is highly imbalanced.  Aquest paper dubta específicament les mètriques d'evaluació utilitzades en aquestes tasques compartides. Vam reevaluar els sistemes submetits a les dues tasques de RumourEval i demostrar que les dues mètriques amplament adoptades, la precisió i la macro F1, no són robustes per a la tasca desequilibrada de quatre classes de classificació de posició rumorosa, perquè favoreixen equivocadament sistemes amb molta precisió desorientada cap a la classe majoritària. Per superar aquest problema, proposem nous mètrics d'evaluació per detectar la posició rumorosa. No només són robustes a dades desequilibradas, sinó també puntueixen sistemes més alts capaços de reconèixer les dues classes minoritàries més informatives (suport i negació).", 'et': 'Stance klassifitseerimine võib olla võimas vahend, et mõista, kas ja millised kasutajad usuvad online kuulujutte. Ülesande eesmärk on automaatselt ennustada vastuste seisukohta teatud kuulujutu suhtes, nimelt toetada, eitada, küsida või kommenteerida. RumourEvali jagatud ülesannetes 2017. ja 2019. aastal on välja pakutud arvukaid meetodeid ja nende tulemuslikkust võrreldakse. Tulemused näitasid, et tegemist on keerulise probleemiga, kuna looduslikult esinevad kuulujutude seisukoha andmed on väga tasakaalustamatud. Käesolevas dokumendis küsitakse konkreetselt nende jagatud ülesannete hindamismeetodeid. Me hindame uuesti kahele RumourEvali ülesandele esitatud süsteeme ja näitame, et kaks laialdaselt kasutusele võetud mõõdikut - täpsus ja makro-F1 - ei ole neljaklassilise tasakaalustamatu ülesande jaoks vastupidavad, sest need eelistavad valesti süsteeme, mille täpsus on väga kõrge enamusklassi suunas. Selle probleemi lahendamiseks pakume välja uued hindamismeetodikud kuulujuttude hoiakute tuvastamiseks. Need ei ole mitte ainult tugevad ja tasakaalustamatud andmed, vaid ka kõrgemad süsteemid, mis suudavad ära tunda kahte kõige informatiivsemat vähemusklassi (toetus ja eitamine).', 'fi': 'Stance-luokitus voi olla tehokas työkalu ymmärtää, uskovatko ja mitkä käyttäjät verkkohuhuihin. Tehtävän tavoitteena on automaattisesti ennustaa vastausten kanta tiettyyn huhun, nimittäin tukea, kieltää, kysyä tai kommentoida. RumourEvalin yhteisissä tehtävissä vuosina 2017 ja 2019 on ehdotettu lukuisia menetelmiä ja niiden suorituskykyä verrattu. Tulokset osoittivat, että tämä on haastava ongelma, koska luonnollisesti esiintyvät huhujen kantatiedot ovat hyvin epätasapainoisia. Tässä artikkelissa kyseenalaistetaan erityisesti näiden jaettujen tehtävien arviointimittareita. Arvioimme uudelleen kahteen RumourEval-tehtävään toimitetut järjestelmät ja osoitamme, että kaksi laajasti hyväksyttyä mittaria - tarkkuus ja makro-F1 - eivät ole vankkoja neljän luokan epätasapainoiseen tehtävään huhun asennon luokitteluun, koska ne suosivat väärin järjestelmiä, joilla on erittäin vääristynyt tarkkuus kohti enemmistöluokkaa. Tämän ongelman ratkaisemiseksi ehdotamme uusia arviointimittareita huhujen asennon havaitsemiseen. Nämä eivät ole ainoastaan vankkoja ja epätasapainoisia tietoja, vaan myös parempia järjestelmiä, jotka pystyvät tunnistamaan kaksi informatiivisinta vähemmistöluokkaa (tuki ja kieltäminen).', 'he': 'מסווג עמדה יכול להיות כלי חזק להבין אם ומשתמשים מאמינים בשמועות באינטרנט. המשימה מתכוונת לחזות באופן אוטומטי את עמדת התשובות כלפי שמועה מסוימת, כלומר תמיכה, כחשה, שאלה או תגובה. הציעו שיטות רבות והביצועים שלהם בהשוואה במשימות משותפות בשמועה בשנות 2017 ו-2019. התוצאות הראו שזו בעיה מאתגרת מאחר שמדובר באופן טבעי נתוני עמדת השמועה לא מאוזנים באופן גבוה. הנייר הזה מפקפק במיוחד את מטריות הערכה שהשתמשו במשימות המשותפות האלה. אנו מחדש מערכות שנשלחו לשני המשימות של השמועות, ונראה ששני המטריקות המאומצות באופן רחב - מדויקת ומאקרו-F1 - אינן חזקות למשימה של ארבע מעמדות בלתי מאוזנת של מסווג עמדת השמועות, כיוון שהם טועים מעדיפים מערכות עם מדויקת מוגזמת לגמרי לכיתה הרוב. כדי להתגבר על הבעיה הזאת, אנחנו מציעים מטריות עריכה חדשות לגלות עמדת השמועה. These are not only robust to imbalanced data but also score higher systems that are capable of recognising the two most informative minority classes (support and deny).', 'sk': 'Klasifikacija stanja je lahko močno orodje za razumevanje, ali in kateri uporabniki verjamejo v spletne govorice. Cilj naloge je samodejno napovedati stališče odgovorov do dane govorice, in sicer podpora, zanikanje, vprašanje ali komentar. V skupnih nalogah RumourEval v letih 2017 in 2019 smo predlagali številne metode in primerjali njihovo uspešnost. Rezultati so pokazali, da je to problem zahteven, saj so podatki o naravnem stališču govoric zelo neravnoteženi. V tem članku se posebej sprašujejo meritve ocenjevanja, ki se uporabljajo pri teh opravilih v skupni rabi. Ponovno ocenimo sisteme, predložene dvema nalogama RumourEval, in pokažemo, da obe široko sprejeti meritvi - natančnost in makro-F1 - nista robustni za štirikolesno neravnoteženo nalogo klasifikacije položaja govoric, saj napačno podpirata sisteme z visoko izkrivljeno natančnostjo do večinskega razreda. Da bi premagali ta problem, predlagamo nove meritve ocenjevanja za odkrivanje stališča govoric. Ti niso le robustni do neravnoteženih podatkov, temveč tudi sistemi, ki lahko prepoznajo dva najbolj informativna manjšinska razreda (podpora in zanikanje).', 'ha': "Ana iya zama mai ƙarfi ga fahimta ko kuma wanne masu amfani da za'a yi ĩmãni da sunan na'ura. Kayan aiki yana kasa gabani farat ɗaya ga gyare na musamman zuwa wani rumi wanda aka bai wa, misali, ƙarfafa, tambayi, ko kalma. An buƙata wasu hanyõyi da aka sammenfata su a cikin aikin Rumoureval da aka raba shi a 2017 da 2019. Matamarra suka nuna cewa wannan wata matalauci ne mai tsanani, don haka da data na danne halarce a bakwai za'a faɗa. Wannan takardar da ke tambaya masu ƙayyade metric da ake amfani da cikin wannan aikin da aka raba su. Tuna yin rabo ga tsarin da aka saka zuwa aikin Rumoureval biyu kuma Muke nuna cewa, misalin su biyu masu faɗi - tsari da macro-F1 - ba za'a yi ɓarna ba ga aikin nau'in-nau'i na huɗu-nau'in fassarar danganta na rumori, kamar yadda suna yarda da tsari na da tsari mai girma zuwa daraja mafi yawanci. To domin ta rinjãye wannan mataimaki, sai mu buɗa metric-yanzu ga ganin na'ura. Waɗannan ba za'a goge zuwa data da ba da taƙaita ba, kuma suna ƙari tsarin da za'a iya iya gane su biyu masu ƙaranci masu yiwuwa da bã zã su iya sani ba (masu ƙaranci da zã su kãfirta).", 'jv': 'Yukono punika ingkang dipunangé kuwi nggawe sistem sing luwih apik dhéwé karo iso nguasai online. Ombudhakan iku mbukak ngerti perbudhakan kanggo sabanjuré suparahan kanggo masalah Ere simbol sing dibutuhi cara sing rumangno karo halekan nggawe ngupakan karo durung-cara durung ing, durung-durung ye nggawe Kasunyatan 2011 lan 2011. Pametuné kaé sawetara bener iki dadi nggunaken kuwi, dadi kapan-kapan sing apik bênêr sing apik bênêr. Laptop" and "Desktop Awak dhéwé-nggunian sistem sing nyelaraké segala macro-F1 iki ngono hal segala macro-F1 sing gak dhéwé kuwi kesempatan sing gak dhéwé, perusahaan karo hal segala macro-F1 sing ora ono alam sing perusahaan kanggo kalagayut aksi winih dhéwé kesempatan kanggo langgar rumuran, lan uwis hal dhéwé nggawe sistem sing gak dhéwé, ngono Mbok dianggo kowe nggawe uwis seneng pisan kanggo Kemerdekaan nggo ngerasakno Dheke ora ono jeneng pêrbudhakan kanggo mbakdahane dadi sing bisa basa, dadi iso nggoleki sistem sing luwih apik sing bisa gabungi iki kelas informasi sing gak dhéwé (ndhekané karo ingkang).', 'bo': 'Stance classification can be a powerful tool for understanding whether and which users believe in online rumors. བྱ་འགུལ་གྱི་དམིགས གྲངས་འབོར་ཐབས་ལམ་ལ་བསམ་བློ་བཏང་བ་དང་ཁོང་ཚོའི་ལས་འགན་སྐྱོན་རྐྱེན་གྱི་ལྟར་བཤད་ཀྱི་ཡོད། གཟའ་འབྲས་བྱ་ཚིག་དག་གི་དཀའ་ངལ་ཆེན་པོ་ཞིག་ཡིན། This paper specifically questions the evaluation metrics used in these shared tasks. We re-evaluate the systems submitted to the two RumourEval tasks and show that the two widely adopted metrics - accuracy and macro-F1 - are not robust for the four-class imbalanced task of rumour stance classification, as they wrongly favour systems with highly skewed accuracy towards the majority class. To overcome this problem, we propose new evaluation metrics for rumour stance detection. འདི་དག་ནི་ཆུང་ཕྱོགས་བཤོལ་བྱེད་པའི་གནས་ཚུལ་གཅིག་པུ་མིན་པར། བྱེད་སྲིད་པའི་མ་ལག'}
