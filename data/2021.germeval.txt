{'en': 'DFKI SLT at GermEval 2021 : Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'ar': 'DFKI SLT في GermEval 2021: التدريب المسبق متعدد اللغات وزيادة البيانات لتصنيف السمية في تعليقات وسائل التواصل الاجتماعي', 'pt': 'DFKI SLT na GermEval 2021: Pré-treinamento multilíngue e aumento de dados para a classificação de toxicidade em comentários de mídia social', 'es': 'DFKI SLT en GermEval 2021: preentrenamiento multilingüe y aumento de datos para la clasificación de toxicidad en los comentarios de las redes sociales', 'fr': 'DFKI SLT à GermEval 2021\xa0: Pré-entraînement multilingue et augmentation des données pour la classification de la toxicité dans les médias sociaux Commentaires', 'ja': 'DFKI SLT at GermEval 2021: Multilingual Pre - Training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'ru': 'DFKI SLT at GermEval 2021: Многоязычное предварительное обучение и расширение данных для классификации токсичности в комментариях социальных сетей', 'hi': 'GermEval 2021 में DFKI SLT: सामाजिक मीडिया टिप्पणियों में विषाक्तता के वर्गीकरण के लिए बहुभाषी पूर्व-प्रशिक्षण और डेटा संवर्धन', 'zh': 'DFKI SLT在GermEval 2021上:多言预练数增强,以社交媒体论毒性分类', 'ga': 'DFKI SLT ag GermEval 2021: Réamh-oiliúint Ilteangach agus Méadú Sonraí le haghaidh Aicmiú Tocsaineachta sna Meáin Shóisialta', 'ka': 'DFKI SLT-ს GermEval 2021-ში: მრავალენგური წინატვირთვის და მონაცემების აგგენტირება ტექსიკურის კლასიფიკაციაში სოციალური მედია კომენტებში', 'el': 'Πολυγλωσσική προεκπαίδευση και αύξηση δεδομένων για την ταξινόμηση της τοξικότητας στα μέσα κοινωνικής δικτύωσης Σχόλια', 'it': 'DFKI SLT a GermEval 2021: Pre-formazione multilingue e aumento dei dati per la classificazione della tossicità nei social media Commenti', 'hu': 'DFKI SLT a GermEval 2021-en: Többnyelvű előképzés és adatbővítés a toxicitás osztályozásához a közösségi médiában Hozzászólások', 'kk': 'DFKI SLT at GermEval 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'mk': 'DFKI SLT на GermEval 2021: Мултијазичен предобук и зголемување на податоците за класификацијата на токсичноста во коментарите на социјалните медиуми', 'lt': 'DFKI SLT GermEval 2021: Daugiakalbis parengiamasis mokymas ir duomenų didinimas toksiškumo klasifikavimui socialinėje žiniasklaidoje', 'ml': 'ജെര്\u200dമ്മെവാല്\u200d 2021-ല്\u200d DFKI SLT: സോഷ്യല്\u200d മീഡിയ വിവരങ്ങളിലെ ടോക്സിക്സിക്സിയുടെ ക്ലാസിക്കേഷനുള്ള വിവരങ്ങള്\u200d', 'ms': 'DFKI SLT at GermEval 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'mn': 'DFKI SLT at GermEval 2021: Multilingual Pre-training and Data increase for the Classification of Toxicity in Social Media Comments', 'mt': 'DFKI SLT fil-GermEval 2021: Pretaħriġ Multilingwi u Żieda fid-Dejta għall-Klassifikazzjoni tat-Tossiċità fil-Kummenti tal-Midja Soċjali', 'no': 'DFKI SLT på GermEval 2021: Multispråk føreøving og data-augmentasjon for klassifisering av toksikitet i sosiale mediakommentarar', 'sr': 'DFKI SLT na GermEval 2021: Većina jezika pre obuke i povećanja podataka za klasifikaciju toksičnosti u komentarima društvenih medija', 'ro': 'DFKI SLT la GermEval 2021: Pre-formare multilingvă și augmentarea datelor pentru clasificarea toxicității în rețelele sociale Comentarii', 'pl': 'DFKI SLT na GermEval 2021: Wielojęzyczne przedszkolenia i rozszerzenie danych dla klasyfikacji toksyczności w mediach społecznościowych Komentarze', 'si': 'DFKI SLT at Germeval 2021: Multilanguage pre-Training and Data Agmentation for the Classication of Toxicity in the Human Media Comment', 'so': 'DFKI SLT at GermEval 2021: Waxbarashada hore-horaadka iyo codsiga macluumaadka ee dhameysashada Toxicity ee macluumaadka bulshada', 'ta': 'DFKI SLT at GermEval 2021: Social Media Comments Classification of Toxicity', 'sv': 'DFKI SLT på GermEval 2021: Flerspråkig fortbildning och dataökning för klassificering av toxicitet i sociala medier Kommentarer', 'ur': 'DFKI SLT GermEval 2021 میں: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'uz': 'GermEval 2021 da DFKI SLT: Social Media Comments Classification for Toxicity', 'vi': 'DFS SLT ở GermEvl 2021: đa ngôn ngữ tiền đào tạo và gia tăng dữ liệu cho Việc phân cấp độc tính trong đối phương', 'nl': 'DFKI SLT op GermEval 2021: Meertalige Voortraining en Data Augmentatie voor de Classificatie van Toxiciteit in Social Media Reacties', 'hr': 'DFKI SLT na GermEval 2021: Većina jezičkih predobuka i povećanja podataka za klasifikaciju toksičnosti u komentarima društvenih medija', 'de': 'DFKI SLT bei GermEval 2021: Mehrsprachige Vor- und Datenaufbereitung zur Klassifizierung von Toxizität in Social Media Kommentare', 'da': 'DFKI SLT på GermEval 2021: Flersproget foruddannelse og dataudvidelse til klassificering af toksicitet i sociale medier Kommentarer', 'ko': 'DFKI SLT가 GermEval 2021: 소셜 미디어 리뷰 중독성 분류를 위한 다국어 사전 교육 및 데이터 확장', 'bg': 'ДФКИ СЛТ на ДжермЕвал 2021: Многоезично предобучение и увеличаване на данните за класификацията на токсичността в социалните медии Коментари', 'sw': 'DFKI SLT kwenye GermEval 2021: Mafunzo ya Ujumbe wa lugha na Kuunga mkono data kwa ajili ya Kutangaza Usukosefu katika Maoni ya Mitandao ya Kijamii', 'id': 'DFKI SLT di GermEval 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'tr': 'DFKI SLT at GermEval 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'fa': 'DFKI SLT at GermEval 2021: Multilingual Pre-Training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'am': 'DFKI SLT at GermEval 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'az': 'DFKI SLT at GermEval 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'sq': 'DFKI SLT në GermEval 2021: Paratrainimi shumëgjuhës dhe rritja e të dhënave për klasifikimin e toksicitetit në komentet e medias sociale', 'hy': 'DFKI-ը "ԳերմԵվալ 2021-ում": Բազլեզու նախապատրաստման և տվյալների աճը սոցիալական լրատվամիջոցների թունավորության դասակարգման համար', 'bs': 'DFKI SLT na GermEval 2021: Većina jezičkih predobuka i povećanja podataka za klasifikaciju toksičnosti u komentarima društvenih medija', 'bn': 'জেরমেভাল ২০২১-এ ডিএফকি এসএলটি: সামাজিক মিডিয়া মন্তব্যে টোক্সিকি ক্লাসিকেশনের জন্য বহুভাষী প্রশিক্ষণ ও তথ্য অংশগ্রহণের জন্য', 'ca': 'DFKI SLT a GermEval 2021: Pre-entrenament multilingüe i augment de dades per a la classificació de toxicitat en comentaris dels mitjans socials', 'cs': 'DFKI SLT na GermEvalu 2021: Vícejazyčné předškolení a rozšíření dat pro klasifikaci toxicity v sociálních médiích Komentáře', 'af': 'DFKI SLT by GermEval 2021: Veelvuldige voorwerp en data-opvulling vir die klassifisering van Toksiksiteit in sosiale media kommentaar', 'fi': 'DFKI SLT GermEvalissa 2021: Monikielinen esikoulutus ja tietojen lisääminen myrkyllisyysluokitukseen sosiaalisessa mediassa Kommentit', 'et': 'DFKI SLT GermEval 2021: mitmekeelne eelkoolitus ja andmete täiendamine toksilisuse klassifitseerimiseks sotsiaalmeedias Kommentaarid', 'jv': 'DFKi SLT nang germinval 2020: Multi-Linguial Pri-carani lan data AGKAMETI kanggo Kelasi Ketokisan kanggo Komentar', 'sk': 'DFKI SLT na GermEvalu 2021: Večjezično predusposabljanje in dopolnitev podatkov za klasifikacijo toksičnosti v socialnih medijih Komentarji', 'ha': 'KCharselect unicode block name', 'he': 'DFKI SLT at GermEval 2021: Multilingual Pre-Training and Data Augmentation for the Classification of Toxicity in Social Media Comments', 'bo': 'DFKI SLT at GermEval 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments'}
{'en': 'We present our submission to the first subtask of GermEval 2021 (classification of German Facebook comments as toxic or not). Binary sequence classification is a standard NLP task with known state-of-the-art methods. Therefore, we focus on ', 'ar': 'نقدم مساهمتنا إلى المهمة الفرعية الأولى لـ GermEval 2021 (تصنيف تعليقات فيسبوك الألمانية على أنها سامة أم لا). تصنيف التسلسل الثنائي هو مهمة قياسية في البرمجة اللغوية العصبية مع أحدث الأساليب المعروفة. لذلك ، نركز على إعداد البيانات باستخدام طريقتين مختلفتين: التدريب المسبق الخاص بالمهمة وزيادة البيانات. أولاً ، نقوم مسبقًا بتدريب المحولات متعددة اللغات (XLM-RoBERTa و MT5) على 12 مجموعة بيانات لاكتشاف الكلام بتسع لغات مختلفة. من حيث F1 ، نلاحظ تحسنًا بنسبة 10 ٪ في المتوسط ، باستخدام التدريب المسبق الخاص بالمهمة. ثانيًا ، نقوم بزيادة البيانات عن طريق وضع علامة على التعليقات غير الموسومة المأخوذة من Facebook لزيادة حجم مجموعة بيانات التدريب بنسبة 79٪. تحصل النماذج التي تم تدريبها على مجموعة بيانات التدريب المعززة في المتوسط على +0.0282 (+ 5٪) درجة F1 مقارنة بالنماذج التي تم تدريبها على مجموعة بيانات التدريب الأصلية. أخيرًا ، يتيح لنا الجمع بين الطريقتين الحصول على درجة F1 تبلغ 0.6899 مع XLM- RoBERTa و 0.6859 مع MT5. كود المشروع متاح على: https://github.com/airKlizz/germeval2021toxic.', 'fr': "Nous présentons notre soumission à la première sous-tâche de GermEval 2021 (classification des commentaires Facebook allemands comme toxiques ou non). La classification de séquences binaires est une tâche de PNL standard avec des méthodes connues de pointe. Par conséquent, nous nous concentrons sur la préparation des données en utilisant deux techniques différentes\xa0: la pré-formation spécifique à une tâche et l'augmentation des données. Tout d'abord, nous préformons des transformateurs multilingues (XLM-Roberta et MT5) sur 12 ensembles de données de détection de discours haineux dans neuf langues différentes. En termes de F1, nous constatons une amélioration de 10\xa0% en moyenne, grâce à un pré-entraînement spécifique à la tâche. Ensuite, nous augmentons les données en étiquetant les commentaires non étiquetés, extraits de Facebook, afin d'augmenter la taille de l'ensemble de données d'entraînement de 79\xa0%. Les modèles entraînés sur l'ensemble de données d'entraînement augmenté obtiennent en moyenne +0,0282 (+5\xa0%) score F1 par rapport aux modèles formés sur l'ensemble de données d'entraînement d'origine. Enfin, la combinaison des deux techniques nous permet d'obtenir un score F1 de 0,6899 avec XLM-Roberta et de 0,6859 avec MT5. Le code du projet est disponible à l'adresse suivante\xa0: https://github.com/airKlizz/germeval2021toxic.", 'es': 'Presentamos nuestra presentación a la primera subtarea de GermEval 2021 (clasificación de los comentarios alemanes de Facebook como tóxicos o no). La clasificación de secuencias binarias es una tarea estándar de PNL con métodos conocidos de última generación. Por lo tanto, nos centramos en la preparación de datos mediante el uso de dos técnicas diferentes: preentrenamiento específico para tareas y aumento de datos. Primero, entrenamos previamente a los transformadores multilingües (XLM-Roberta y MT5) en 12 conjuntos de datos de detección de incitación al odio en nueve idiomas diferentes. En términos de F1, observamos una mejora del 10% en promedio, mediante el entrenamiento previo específico de la tarea. En segundo lugar, realizamos un aumento de datos etiquetando los comentarios sin etiqueta, tomados de Facebook, para aumentar el tamaño del conjunto de datos de capacitación en un 79%. Los modelos entrenados en el conjunto de datos de entrenamiento aumentado obtienen en promedio una puntuación F1 de +0,0282 (+5%) en comparación con los modelos entrenados en el conjunto de datos de entrenamiento original. Finalmente, la combinación de las dos técnicas nos permite obtener una puntuación F1 de 0.6899 con XLM-Roberta y de 0.6859 con MT5. El código del proyecto está disponible en: https://github.com/airKlizz/germeval2021toxic.', 'pt': 'Apresentamos nossa submissão para a primeira subtarefa do GermEval 2021 (classificação dos comentários alemães do Facebook como tóxicos ou não). A classificação de sequências binárias é uma tarefa padrão de NLP com métodos conhecidos de última geração. Portanto, nos concentramos na preparação de dados usando duas técnicas diferentes: pré-treinamento específico para tarefas e aumento de dados. Primeiro, pré-treinamos transformadores multilíngues (XLM-RoBERTa e MT5) em 12 conjuntos de dados de detecção de discurso de ódio em nove idiomas diferentes. Em termos de F1, notamos uma melhora de 10% em média, usando o pré-treinamento específico da tarefa. Em segundo lugar, realizamos o aumento de dados rotulando comentários não rotulados, retirados do Facebook, para aumentar o tamanho do conjunto de dados de treinamento em 79%. Modelos treinados no conjunto de dados de treinamento aumentado obtêm em média +0,0282 (+5%) de pontuação F1 em comparação com modelos treinados no conjunto de dados de treinamento original. Por fim, a combinação das duas técnicas permite obter uma pontuação F1 de 0,6899 com XLM-RoBERTa e 0,6859 com MT5. O código do projeto está disponível em: https://github.com/airKlizz/germeval2021toxic.', 'ja': '私たちは、GermEval 2021の最初のサブタスク（ドイツのFacebookコメントの毒性の有無の分類）に提出します。 バイナリ配列分類は、既知の最先端の方法を用いた標準的なNLPタスクである。 したがって、タスク固有の事前トレーニングとデータ拡張という2つの異なるテクニックを使用して、データの準備に焦点を当てます。 まず、多言語変圧器（ XLM - RoBERTaおよびMT 5 ）を9つの言語の12のヘイトスピーチ検出データセットで事前にトレーニングします。 F 1では、タスク固有の事前トレーニングを使用して、平均10 ％の改善が見られます。 第二に、トレーニングデータセットのサイズを79 ％増加させるために、Facebookから取得したラベルのないコメントにラベルを付けることにより、データ拡張を行います。 拡張トレーニングデータセットでトレーニングされたモデルは、元のトレーニングデータセットでトレーニングされたモデルと比較して、平均して+0.0282 (+5%) F 1スコアを得る。 最後に、２つの技術の組み合わせにより、ＸＬＭ － ＲｏＢＥＲＴａでは０ ． ６ ８ ９ ９、ＭＴ ５では０ ． ６ ８ ５ ９のＦ１スコアを得ることができる。 プロジェクトのコードは、https://github.com/airKlizz/germeval2021toxicから入手できます。', 'zh': '以GermEval 2021为首(论德国Facebook为有毒)。 二进制序者,一准之NLP务,有已知之先进也。 故吾以二术注于数:特定于事者,练数以益之。 先九语者12仇音检数集上预练多言转换器(XLM-RoBERTaMT5)。 以F1言之,谨于用特定预训练均升10%。 其次,以Facebook未标论行之,以练数集之大小增79%。 比于集上练之数,比于训练之数集上均得 +0.0282 (+5%) F1 分。 此二术者,使得XLM-RoBERTa之F1为0.6899,MT5F1为0.6859。 该项目代码可于下位得之,https://github.com/airKlizz/germeval2021toxic。', 'hi': 'हम GermEval 2021 के पहले उप-कार्य के लिए अपना सबमिशन प्रस्तुत करते हैं (जर्मन फेसबुक टिप्पणियों का वर्गीकरण विषाक्त के रूप में या नहीं)। बाइनरी अनुक्रम वर्गीकरण ज्ञात अत्याधुनिक विधियों के साथ एक मानक एनएलपी कार्य है। इसलिए, हम दो अलग-अलग तकनीकों का उपयोग करके डेटा तैयारी पर ध्यान केंद्रित करते हैं: कार्य-विशिष्ट पूर्व-प्रशिक्षण और डेटा वृद्धि। सबसे पहले, हम नौ अलग-अलग भाषाओं में 12 हेटस्पीच डिटेक्शन डेटासेट पर बहुभाषी ट्रांसफॉर्मर (XLM-RoBERTa और MT5) को पूर्व-प्रशिक्षित करते हैं। एफ 1 के संदर्भ में, हम कार्य-विशिष्ट पूर्व-प्रशिक्षण का उपयोग करके औसतन 10% का सुधार देखते हैं। दूसरा, हम प्रशिक्षण डेटासेट के आकार को 79% तक बढ़ाने के लिए Facebook से ली गई अनलेबल टिप्पणियों को लेबल करके डेटा वृद्धि करते हैं। संवर्धित प्रशिक्षण डेटासेट पर प्रशिक्षित मॉडल मूल प्रशिक्षण डेटासेट पर प्रशिक्षित मॉडल की तुलना में औसत +0.0282 (+5%) F1 स्कोर पर प्राप्त करते हैं। अंत में, दो तकनीकों का संयोजन हमें XLM- RoBERTa के साथ 0.6899 का F1 स्कोर और MT5 के साथ 0.6859 प्राप्त करने की अनुमति देता है। परियोजना का कोड पर उपलब्ध है: https://github.com/airKlizz/germeval2021toxic।', 'ru': 'Мы представляем наше представление по первой подзадаче GermEval 2021 (классификация немецких комментариев в Facebook как токсичные или нет). Классификация бинарной последовательности является стандартной задачей NLP с известными современными методами. Поэтому мы фокусируемся на подготовке данных с использованием двух различных методов: предварительного обучения с учетом конкретных задач и увеличения объема данных. Во-первых, мы предварительно обучаем многоязычные трансформаторы (XLM-RoBERTa и MT5) на 12 наборах данных обнаружения молчания на девяти разных языках. Что касается F1, то мы отмечаем улучшение в среднем на 10%, используя специальное предварительное обучение. Во-вторых, мы выполняем увеличение данных путем маркировки немаркированных комментариев, взятых из Facebook, чтобы увеличить размер обучающего набора данных на 79%. Модели, обученные на дополненном обучающем наборе данных, получают в среднем +0.0282 (+5%) балла F1 по сравнению с моделями, обученными на исходном обучающем наборе данных. Наконец, комбинация двух методов позволяет нам получить оценку F1 0,6899 с XLM- RoBERTa и 0,6859 с MT5. Код проекта доступен по ссылке: https://github.com/airKlizz/germeval2021toxic.', 'ga': 'Cuirimid ár n-aighneacht i láthair don chéad fhothasc de GermEval 2021 (aicmiú tuairimí Gearmáinise Facebook mar thocsaineach nó nach bhfuil). Is tasc caighdeánach NLP é an t-aicmiú seicheamh dénártha a bhfuil modhanna aitheanta den scoth aige. Mar sin, dírímid ar ullmhú sonraí trí dhá theicníc éagsúla a úsáid: réamhoiliúint a bhaineann go sonrach le tasc agus méadú sonraí. Ar dtús, déanaimid réamhthraenáil ar chlaochladáin ilteangacha (XLM-RoBERTa agus MT5) ar 12 thacar sonraí um bhrath fuathchainte i naoi dteanga éagsúla. I dtéarmaí F1, tugaimid faoi deara feabhas 10% ar an meán, ag baint úsáide as réamhoiliúint tasc-shonracha. Ar an dara dul síos, déanaimid méadú ar shonraí trí nótaí tráchta neamhlipéadaithe, a tógadh ó Facebook, a lipéadú chun méid an tacair sonraí oiliúna a mhéadú 79%. Faigheann samhlacha arna n-oiliúint ar an tacar sonraí oiliúna méadaithe +0.0282 (+5%) ar an meán scór F1 i gcomparáid le samhlacha a fuair oiliúint ar an mbunshonraí oiliúna. Ar deireadh, ligeann an meascán den dá theicníc dúinn scór F1 de 0.6899 a fháil le XLM- RoBERTa agus 0.6859 le MT5. Tá cód an tionscadail ar fáil ag: https://github.com/airKlizz/germeval2021toxic.', 'el': 'Παρουσιάζουμε την υποβολή μας στην πρώτη υποταγή του GermEval 2021 (ταξινόμηση των γερμανικών σχολίων ως τοξικά ή όχι). Η ταξινόμηση δυαδικής αλληλουχίας είναι μια τυπική εργασία με γνωστές μεθόδους τελευταίας τεχνολογίας. Ως εκ τούτου, εστιάζουμε στην προετοιμασία δεδομένων χρησιμοποιώντας δύο διαφορετικές τεχνικές: ειδική προ-εκπαίδευση και αύξηση δεδομένων. Πρώτον, προετοιμάζουμε πολύγλωσσους μετασχηματιστές (και ΜΤ5) σε 12σύνολα δεδομένων ανίχνευσης σε εννέα διαφορετικές γλώσσες. Όσον αφορά το F1, παρατηρούμε μια βελτίωση των 10% κατά μέσο όρο, χρησιμοποιώντας ειδική προετοιμασία εργασίας. Δεύτερον, διενεργούμε αύξηση δεδομένων επισημαίνοντας σχόλια χωρίς σήμανση, τα οποία λαμβάνονται από το Facebook, για να αυξήσουμε το μέγεθος του συνόλου δεδομένων κατάρτισης κατά 79%. Τα μοντέλα που εκπαιδεύονται στο σύνολο δεδομένων αυξημένης εκπαίδευσης λαμβάνουν κατά μέσο όρο +0,0282 (+5%) βαθμολογία F1 σε σύγκριση με τα μοντέλα που εκπαιδεύονται στο αρχικό σύνολο δεδομένων εκπαίδευσης. Τέλος, ο συνδυασμός των δύο τεχνικών μας επιτρέπει να αποκτήσουμε βαθμολογία 0.6899 με XLM- RoBERTa και 0.6859 με ΜΤ5. Ο κώδικας του έργου διατίθεται στη διεύθυνση: https://github.com/airKlizz/germeval2021toxic.', 'hu': 'Bemutatjuk benyújtásunkat a GermEval 2021 első részfeladatához (a német Facebook megjegyzések toxikusnak vagy nemnek minősítése). A bináris sorozat osztályozása egy szabványos NLP feladat ismert, korszerű módszerekkel. Ezért az adatok előkészítésére összpontosítunk két különböző technika alkalmazásával: feladatspecifikus előképzés és adatbővítés. Először is többnyelvű transzformátorokat (XLM-RoBERTa és MT5) készítünk elő 12 hatespeech érzékelő adatkészleten kilenc különböző nyelven. Az F1 tekintetében átlagosan 10%-os javulást észlelünk feladatspecifikus előképzés alkalmazásával. Másodszor, az adatok bővítését a Facebookról származó, feliratlan megjegyzések címkézésével végezzük el, hogy 79%-kal növeljük a képzési adatok méretét. A kibővített edzésadatokra képzett modellek átlagosan +0,0282 (+5%) F1 pontszámot kapnak az eredeti edzésadatokra képzett modellekhez képest. Végül a két technika kombinációja lehetővé teszi, hogy F1 pontszámot kapjunk XLM- RoBERTa esetén 0,6899, MT5 esetén pedig 0,6859. A projekt kódja a következő címen érhető el: https://github.com/airKlizz/germeval2021toxic.', 'it': "Presentiamo la nostra presentazione alla prima sottomissione di GermEval 2021 (classificazione dei commenti tedeschi Facebook come tossici o meno). La classificazione delle sequenze binarie è un'attività NLP standard con metodi noti all'avanguardia. Pertanto, ci concentriamo sulla preparazione dei dati utilizzando due tecniche diverse: pre-training specifico per attività e aumento dei dati. In primo luogo, pre-addestriamo trasformatori multilingue (XLM-RoBERTa e MT5) su 12 set di dati di rilevamento hatespeech in nove lingue diverse. In termini di F1, notiamo un miglioramento medio del 10%, utilizzando il pre-training specifico per attività. In secondo luogo, eseguiamo l'aumento dei dati etichettando commenti non etichettati, presi da Facebook, per aumentare le dimensioni del set di dati di formazione del 79%. I modelli addestrati sul set di dati di allenamento aumentato ottengono in media un punteggio F1 +0,0282 (+5%) rispetto ai modelli addestrati sul set di dati di allenamento originale. Infine, la combinazione delle due tecniche ci permette di ottenere un punteggio F1 di 0,6899 con XLM- RoBERTa e 0,6859 con MT5. Il codice del progetto è disponibile all'indirizzo: https://github.com/airKlizz/germeval2021toxic.", 'lt': 'Pateikiame savo pastabą pirmajam „GermEval 2021“ paklausimui (Vokietijos Facebook komentarų klasifikavimas toksišku ar ne). Dvišalė sekos klasifikacija yra standartinė NLP užduotis su žinomais naujausiais metodais. Therefore, we focus on data preparation by using two different techniques: task-specific pre-training and data augmentation.  Pirma, mes parengiame daugiakalbius transformatorius (XLM-RoBERTa ir MT5) 12 neapykantos kalbos aptikimo duomenų rinkinių devyniomis skirtingomis kalbomis. Kalbant apie F1, pastebime vidutiniškai 10 proc. pagerėjimą, naudojant konkrečiai užduotims skirtą išankstinį mokymą. Second, we perform data augmentation by labelling unlabelled comments, taken from Facebook, to increase the size of the training dataset by 79%.  Išplėsto mokymo duomenų rinkinyje parengti modeliai gauna vidutiniškai +0,0282 (+5 %) F1 rezultatą, palyginti su modeliais, parengtais pradiniame mokymo duomenų rinkinyje. Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5.  Projekto kodas pateikiamas adresu: https://github.com/airKlizz/germeval2021toxic.', 'ka': 'ჩვენ დავწეროთ პირველი გერმEval 2021-ის საკითხვაში (გერმანეთის Facebook ის კომენტრების კლასიფიკაცია როგორც ტოქსიური ან არა). ბინერი კოლეფიკაცია არის სტანდარტული NLP დავალება, რომელიც უცნობილი კოლეფიკაცია. ამიტომ, ჩვენ განსხვავებული ტექნოგიების გამოყენებით მონაცემების დაეყენებაზე დავყენებთ: საქმე განსხვავებული საქმე განსხვავებული მონაცემების და მონა პირველი, ჩვენ მრავალენგური ტრანფორმაციები (XLM-RoBERTa და MT5) 12 წინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინა F1-ის განსაზღვრებით, ჩვენ აღმოჩნეთ განსაზღვრებული 10%-ის განსაზღვრება, რომელიც საშუალოდ განსაზღვრებულია საშუალოდ. მეორე, ჩვენ მონაცემების აგგექტირება მონაცემებით, რომლებიც ტვისუფუქოდან გამოიყენებული კომენტაქტებით, 79%-ით გამოიყენებული მონაცემების ზო მოდელები, რომლებიც აგეგმენტირებული განაკლების მონაცემების საზოგადო მონაცემების საზოგადო +0.0282 (+5%) F1 მონაცემების საზოგადოდ მოდელებით, რომლებიც განაკლებული საბოლოოდ, ორი ტექნექციების კომბიზაცია გვაქვს, რომ F1 წერტილი 0.6899-ზე XLM- RoBERTa და 0.6859 MT5-ზე მიიღებთ. პროექტის კოდი შესაძლებელია: https://github.com/airKlizz/germeval2021toxic.', 'ml': 'ഞങ്ങള്\u200d ജെര്\u200dമെവാല്\u200d 2021-ന്\u200dറെ ആദ്യത്തെ സബ്ജാസിന്\u200dറെ അടിസ്ഥാനത്തിലേക്ക് കൊടുക്കുന്നു. ജര്\u200dമ്മന്\u200d ഫേസ്ക്ക് വിവരങ Binary sequence classification is a standard NLP task with known state-of-the-art methods.  അതുകൊണ്ട്, രണ്ടു വ്യത്യസ്ത സാങ്കേതികവിദ്യകള്\u200d ഉപയോഗിച്ച് ഡേറ്റാ തയ്യാറാക്കുന്നതിനെപ്പറ്റി ഞങ്ങള്\u200d ശ്രദ്ധിക് ആദ്യം, ഞങ്ങള്\u200d പല ഭാഷ മാറ്റങ്ങളുടെ ട്രെയിന്\u200d മുന്\u200dപ് ട്രെയിന്\u200d ചെയ്യുന്നു (എക്സ്\u200cഎലി- റോബെര്\u200dട്ടാ- എംടി5) 12 വെറുപ്പു F1-ന്റെ കാര്യത്തില്\u200d, നമ്മള്\u200d പത്ത് ശതമാനത്തില്\u200d മെച്ചപ്പെടുത്തുന്നത് കണ്ടിട്ടുണ്ട്, ജോലിയുടെ പ്രത്യേക പര രണ്ടാമത്, നമ്മള്\u200d വിവരങ്ങള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നത് പരിശീലന ഡാറ്റാസറ്റിന്റെ വലിപ്പം 79 ശതമാനത്തിനുള്ള വിവരങ്ങള്\u200d കൂടുതല്\u200d ഫ ആഗ്മെന്റ് ചെയ്ത ട്രെയിനിങ്ങളുടെ ഡാറ്റാസെറ്റില്\u200d പഠിപ്പിക്കപ്പെട്ട മോഡലുകള്\u200d സാധാരണ +0. 0282 (+5%) F1 സ്കോര്\u200d അവസാനം, ഈ രണ്ട് സാങ്കേതികവിദ്യകളുടെ കൂട്ടിക്കൂട്ടത്തില്\u200d എഫ്1 സ്കോര്\u200d 0. 6899 കൊണ്ട് എക്സ്\u200cഎലി- റോബെര്\u200dട്ടാവും 0. 6859 എംടി5 ക പദ്ധതിയുടെ കോഡ് ലഭ്യമല്ല: https://github.com/airKlizz/germeval2021toxic.', 'mk': 'Го претставуваме нашето поднесување на првиот потпрашање на GermEval 2021 (класификација на германските коментари на Фејсбук како токсични или не). Бинарна класификација на секвенца е стандардна NLP задача со познати најнови методи. Затоа, се фокусираме на подготвувањето на податоците со користење на две различни техники: предобука специфична за задачите и зголемување на податоците. Прво, предобучуваме мултијазични трансформатори (XLM-RoBERTa и MT5) на 12 податоци за детекција на говор на омраза на девет различни јазици. Во поглед на Ф1, забележуваме подобрување од 10 отсто во просек, користејќи предобука специфична за задачите. Второ, спроведуваме зголемување на податоците со означување на неозначени коментари, земени од Фејсбук, за зголемување на големината на податоците за обука за 79 отсто. Моделите обучени на зголемениот набор податоци за обука добиваат просечно +0,0282 (+5 %) оценка F1 во споредба со моделите обучени на оригиналниот набор податоци за обука. Конечно, комбинацијата на двете техники ни овозможува да добиеме оценка F1 од 0,6899 со XLM-RoBERTa и 0,6859 со MT5. The code of the project is available at:  https://github.com/airKlizz/germeval2021toxic.', 'ms': 'Kami memperkenalkan penghantaran kami kepada subtanyaan pertama GermEval 2021 (klasifikasi komentar Facebook Jerman sebagai racun atau tidak). Klasifikasi urutan binari adalah tugas NLP piawai dengan kaedah-keadaan-seni yang diketahui. Oleh itu, kita fokus pada persiapan data dengan menggunakan dua teknik yang berbeza: praselatihan khusus tugas dan peningkatan data. Pertama, kita melatih pengubah berbilang bahasa (XLM-RoBERTa dan MT5) pada 12 set data pengesan pidato benci dalam sembilan bahasa yang berbeza. Dalam terma F1, kita melihat peningkatan 10% pada rata-rata, menggunakan praselatihan khusus tugas. Kedua, kami melakukan peningkatan data dengan mengetikkan ulasan tanpa label, diambil dari Facebook, untuk meningkatkan saiz set data latihan dengan 79%. Model dilatih pada set data latihan bertambah mendapatkan rata-rata skor F1 +0.0282 (+5%) dibandingkan dengan model dilatih pada set data latihan asal. Akhirnya, kombinasi dua teknik membolehkan kita mendapatkan skor F1 0.6899 dengan XLM-RoBERTa dan 0.6859 dengan MT5. The code of the project is available at:  https://github.com/airKlizz/germeval2021toxic.', 'mt': 'Aħna nippreżentaw is-sottomissjoni tagħna għall-ewwel sottomistoqsija ta’ GermEval 2021 (klassifikazzjoni tal-kummenti Ġermaniżi fuq Facebook bħala tossiċi jew le). Il-klassifikazzjoni tas-sekwenza binarja hija kompitu standard NLP b’metodi l-aktar avvanzati magħrufa. Għalhekk, niffokaw fuq it-tħejjija tad-dejta billi nużaw żewġ tekniki differenti: taħriġ minn qabel speċifiku għall-kompiti u żieda fid-dejta. L-ewwel nett, aħna nħarrġu minn qabel trasformaturi multilingwi (XLM-RoBERTa u MT5) fuq 12-il sett ta’ dejta dwar l-individwazzjoni tad-diskors ta’ mibegħda f’disa’ lingwi differenti. F’termini ta’ F1, innotaw titjib ta’ medja ta’ 10 %, bl-użu ta’ taħriġ minn qabel speċifiku għall-kompiti. It-tieni nett, nagħmlu żieda fid-dejta billi ttikkettjaw kummenti mhux immarkati, meħuda minn Facebook, biex iżidu d-daqs tas-sett tad-dejta tat-taħriġ b’79 %. Il-mudelli mħarrġa fuq is-sett ta’ dejta ta’ taħriġ miżjud jiksbu medja ta’ +0.0282 (+5%) punteġġ F1 meta mqabbel ma’ mudelli mħarrġa fuq is-sett ta’ dejta oriġinali ta’ taħriġ. Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5.  Il-kodiċi tal-proġett huwa disponibbli fuq: https://github.com/airKlizz/germeval2021toxic.', 'mn': 'Бид 2021 оны GermEval-ын анхны суурь асуултыг (Герман Фейсбук комментарийнхээ хувьд хохиромжтой эсвэл хохиромжтой хэлбэрээр) тайлбарлаж байна. Бинарийн дарааллын дарааллын хуваалтыг нь мэдэгдэх үйл ажиллагаатай стандарт NLP юм. Тиймээс бид өгөгдлийн бэлтгэл дээр хоёр өөр технологи ашиглан анхаарлаа анхаарлаа төвлөрүүлнэ: даалгаварын өмнөх бэлтгэл болон өгөгдлийн нэмэлт. Эхлээд бид олон хэлний шилжүүлэгчдийг (XLM-RoBERTa, MT5) 12 үзэн ядах ярианы мэдээллийн сангуудыг 9 өөр хэлний сургуульд сургаж байна. F1-ийн хувьд бид дундаж 10%-ын сайжруулалтыг анзаарсан. Хоёрт, бид Фейсбуктаас авсан тайлбаруудыг нэмэгдүүлж өгөгдлийн сангийн хэмжээг 79%-аар нэмэгдүүлэх болно. Өнгөрсөн сургалтын өгөгдлийн санд сургалтын загвар нь дундаж +0.0282 (+5%) F1 оноо авдаг. Анхны сургалтын өгөгдлийн санд сургалтын загвартай харьцуулсан загвартай. Эцэст нь, хоёр технологиудын нэгтгэл бидэнд XLM-RoBERTa болон 0.6859 MT5-тай F1 оноо авах боломжтой. Дэлхийн код бол: https://github.com/airKlizz/germeval2021toxic.', 'pl': 'Przedstawiamy naszą zgłoszenie do pierwszego podzadania GermEval 2021 (klasyfikacja niemieckich komentarzy na Facebooku jako toksyczne lub nie). Klasyfikacja sekwencji binarnej jest standardowym zadaniem NLP ze znanymi najnowocześniejszymi metodami. Dlatego skupiamy się na przygotowaniu danych przy użyciu dwóch różnych technik: specyficznego szkolenia przedszkoleniowego i powiększaniu danych. Najpierw wstępnie trenujemy transformatory wielojęzyczne (XLM-RoBERTa i MT5) na 12-ciu zestawach danych wykrywania hatespech w dziewięciu różnych językach. Pod względem F1 zauważamy poprawę średnio 10% przy użyciu specyficznego treningu wstępnego. Po drugie, wykonujemy powiększenie danych poprzez oznakowanie nieoznakowanych komentarzy, pochodzących z Facebooka, aby zwiększyć rozmiar zbioru danych szkoleniowych o 79%. Modele trenowane na podstawie rozszerzonego zbioru danych treningowych uzyskują średnio +0,0282 (+5%) F1 wynik w porównaniu z modelami trenowanymi na oryginalnym zbiorze danych treningowych. Wreszcie połączenie tych dwóch technik pozwala nam uzyskać wynik F1 0.6899 z XLM- RoBERTa i 0.6859 z MT5. Kod projektu dostępny jest na stronie: https://github.com/airKlizz/germeval2021toxic.', 'no': 'Vi presenterer vårt oppføring til den første underspørjinga av GermEval 2021 (klassifisering av tysk Facebook-kommentarar som toksisk eller ikkje). Binærsekvensklassifikasjon er ein standard NLP-oppgåve med kjente state-of-the-art-metodar. Det er derfor vi fokuserer på dataforberedning ved å bruka to ulike teknikk: oppgåver spesifikke føreøving og data økning. Først treng vi fleirspråkstransformerande (XLM-RoBERTa og MT5) på 12 hatespeech-oppdagingsdatasett i ni ulike språk. I tillegg til F1 merker vi at det gjennomsnittlig forbetringa av 10% ved å bruka oppgåvespesifikke føreøving. For det andre, utfører vi dataaugmentasjon ved å merke ikkje merkelige kommentarar, henta frå Facebook, for å auka storleiken på opplæringsdataset med 79%. Modellar trengte på augmenterte treningsdataset får gjennomsnittlig +0,0282 (+5%) F1- poeng samanlikna med modeller trent på opprinnelige treningsdataset. I slutt kan kombinasjonen av dei to teknikkene få oss til å få eit F1- poeng med 0, 6899 med XLM- RoBERTa og 0, 6859 med MT5. Prosjektet er tilgjengeleg på: https://github.com/airKlizz/germeval2021toxic.', 'sr': 'Predstavljamo svoju predanost prvom podpitanju GermEval 2021 (klasifikacija njemačkih komentara na Facebooku kao toksična ili ne). Klasifikacija binarnih sekvencija je standardni NLP zadatak sa poznatim metodama umetnosti. Stoga se fokusiramo na pripremu podataka koristeći dve različite tehnike: predobuku zadataka i povećanje podataka. Prvo, predvježbamo višejezičke transformatore (XLM-RoBERTa i MT5) na 12 podataka za detekciju govora mržnje na devet različitih jezika. S obzirom na F1, primećujemo poboljšanje od 10% u prosjeku, koristeći predobuku predodređenih zadataka. Drugo, povećavamo podatke označavajući neizbiljne komentare, uzete iz Fejsbuka, kako bi povećali veličinu seta podataka obuke za 79%. Modeli obučeni na povećanom setu podataka obuke dobijaju prosječan rezultat +0,0282 (+5%) F1 u usporedbi s modelima obučenim na originalnom setu podataka obuke. Konačno, kombinacija dva tehnika omogućava da dobijemo rezultat F1 od 0,6899 sa XLM-RoBERTom i 0,6859 sa MT5. Kod projekta je dostupan na: https://github.com/airKlizz/germeval2021toxic.', 'ro': 'Prezentăm trimiterea noastră la prima subactivitate a GermEval 2021 (clasificarea comentariilor germane Facebook ca toxice sau nu). Clasificarea secvențelor binare este o sarcină standard NLP cu metode cunoscute de ultimă generație. Prin urmare, ne concentrăm pe pregătirea datelor prin utilizarea a două tehnici diferite: pregătirea specifică sarcinilor și mărirea datelor. În primul rând, pregătim transformatoare multilingve (XLM-RoBERTa și MT5) pe 12 seturi de date de detectare a hatespeech în nouă limbi diferite. În ceea ce privește F1, observăm o îmbunătățire de 10% în medie, folosind pregătirea specifică sarcinii. În al doilea rând, efectuăm mărirea datelor prin etichetarea comentariilor fără etichete, preluate de pe Facebook, pentru a crește dimensiunea setului de date de formare cu 79%. Modelele instruite pe setul de date de antrenament augmentat obțin în medie +0,0282 (+5%) scor F1 comparativ cu modelele instruite pe setul de date de antrenament original. În cele din urmă, combinația celor două tehnici ne permite să obținem un scor F1 de 0.6899 cu XLM- RoBERTa și 0.6859 cu MT5. Codul proiectului este disponibil la adresa: https://github.com/airKlizz/germeval2021toxic.', 'so': 'Waxaannu soo bandhignaa sameynta ugu horeysa shabakadda GermEval 2021 (kalajarida afka Jarmalka ah oo ku qoran commentarada ku saabsan maandooriyaha ama ma aha). Xiriirka labada xilliga waa shaqada caadiga ah oo lagu yaqaan dowlad-state-of-the-art methods. Sidaa darteed, waxaynu ku kalsoonaynaa diyaarinta macluumaadka, si aan ugu isticmaalno laba qaabilsan oo kala duduwan: waxbarasho-horaadka iyo kordhinta data. Marka ugu horeysa, waxaynu wax ku tababarinnaa bedelka luuqadaha kala duduwan (XLM-RoBERTA iyo MT5) oo ku qoran 12 macluumaad baaritaanka hadalka nacayb ah oo ku qoran sagaal luuqadood oo kala duduwan. Qaybta F1, waxaynu fiirinaynaa horumarinta ugu horumarinta 10 boqolkiiba, waxaynu isticmaalnaa waxbarasho gaar ah. Second, we perform data augmentation by labelling unlabelled comments, taken from Facebook, to increase the size of the training dataset by 79%.  Tusaalada waxbarashada lagu baranayo iskuulka tacliinta la kordhiyey waxey heli karaan qiyaastii +0.0282 (+5%) scorka F1 oo la barto samooyin lagu tababaray kooxda waxbarashada asalka ah. Ugu dambaysta, qalabka labada tacliin ayaa inagu ogolaa in aan helno F1 koox 0.6899 oo XLM-RoBERTA iyo 0.6859 oo MT5 ah. Codeynta project waxaa laga helaa: https://github.com/airKlizz/germeval2021toxic.', 'sv': 'Vi presenterar vårt bidrag till den första underuppgiften av GermEval 2021 (klassificering av tyska Facebook kommentarer som giftiga eller inte). Binär sekvensklassificering är en standard NLP-uppgift med kända toppmoderna metoder. Därför fokuserar vi på dataförberedelse genom att använda två olika tekniker: uppgiftsspecifik pre-training och dataförstärkning. Först utbildar vi flerspråkiga transformatorer (XLM-RoBERTa och MT5) på 12 datauppsättningar för hatespeech på nio olika språk. När det gäller F1 märker vi en förbättring på 10% i genomsnitt, med hjälp av uppgiftsspecifik pre-training. För det andra utför vi dataökning genom att märka omärkta kommentarer, hämtade från Facebook, för att öka storleken på träningsdatauppsättningen med 79%. Modeller som tränats på den utökade träningsdatauppsättningen får i genomsnitt +0,0282 (+5%) F1-poäng jämfört med modeller som tränats på den ursprungliga träningsdatauppsättningen. Slutligen, kombinationen av de två teknikerna tillåter oss att få en F1 poäng på 0,6899 med XLM- RoBERTa och 0,6859 med MT5. Koden för projektet finns på följande adress: https://github.com/airKlizz/germeval2021toxic.', 'si': 'අපි ජර්ම් එව්ල් 2021 ගේ පළමු ප්\u200dරශ්නයකට අපේ ප්\u200dරශ්නයක් පෙන්වන්නේ (ජර්මාන් ෆේස්බුක් ප්\u200dරශ්නයක් විශේෂ Binary sequence classification is a standard NLP job with Known state-of-the-art means. ඉතින්, අපි දත්ත සූදානම් කරන්නේ වෙනස් තාක්ෂණික දෙකක් භාවිත කරන්න: වැඩක් විශේෂ ප්\u200dරධානය සහ දත්ත මුලින්ම, අපි ගොඩක් භාෂාවක් වෙනස් භාෂාවක් නිර්මාණය කරනවා (XLM-RoBERTa සහ MT5) විරෝධ කතාවක් හොයාගන්න දත්ත ස F1 වලින්, අපි පරීක්ෂණයෙන් 10% විශේෂතාවක් පරීක්ෂණය කරන්න පුළුවන් දැනගත්තා. දෙවෙනි විදියට, අපි දත්ත විශාලනය කරන්නේ ප්\u200dරශ්නයක් තොරතුරු නැති කිරීමක් ලේබල් කරන්න, ෆේස්බක් වලින් ගත්ත,  ප්\u200dරධානය කරලා තියෙන ප්\u200dරධානය කරලා තියෙන ප්\u200dරධානය කරලා තියෙන ප්\u200dරධානය +0.0282 (+5%) F1 ප්\u200dරධානය සඳහා ප්\u200dරධානය කරලා ත අන්තිමේදී, ප්\u200dරවේශය දෙකක් සම්බන්ධයෙන් අපිට ප්\u200dරවේශ කරන්න පුළුවන් වෙනවා XLM- RoBERTa සහ MT5 සම්බන්ධයෙන් F1 ප්\u200dරවේශයක් 0. 6899 ව්\u200dයාපෘතියේ කෝඩ තියෙන්නේ: https://github.com/airKlizz/germeval2021toxic.', 'ta': 'நாங்கள் ஜெர்ம்Eval 2021-ன் முதல் துணை பணிக்கு எங்கள் சரணக்கூறை கூறுகிறோம் (ஜெர்மன் ஃபெஸ்குப் குறிப்புகளை புதிய அல இருநிலை வரிசை வகைப்படுத்தல் நிலையான NLP செயல் எனவே, நாம் இரண்டு வித்தியாசமான தொழில்நுட்பங்களை பயன்படுத்தி தரவு தயாரிப்பு மீது கவனம் செலுத்துகிறோம்: பணி குறிப முதலில், நாம் பல மொழி மாற்றங்கள் (XLM- RoBERTA மற்றும் MT5) 12 வெறுப்பு பேச்சு கண்டுபிடிப்பு தகவல் அமைப்புகளில் ஒன்பது வேறு மொழி F1 குறிப்பிட்ட முன் பயிற்சியை பயன்படுத்தி நாம் சராசரியாக 10% மேம்படுத்துவதை கவனிக்கிறோம். இரண்டாவது, நாம் குறிப்பிடாத குறிப்பிட்ட குறிப்புகளை குறிப்பிட்ட தகவல் சேர்ப்பை செயல்படுத்துகிறோம், பேசியிலிருந்த கூடுதல் பயிற்சி தரவுத்தளத்தில் பயிற்சி செய்யப்பட்ட மாதிரிகள் சராசரி  +0. 0282 (+5%) F1 மதிப்புகளை மூல பயிற்சி தரவுத்தளத்தில் பயி Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5.  திட்டத்தின் குறியீடு இதில் உள்ளது: https://github.com/airKlizz/germeval2021toxic.', 'ur': 'ہم نے جرمایول 2021 کی پہلی سپسٹ پرسٹ میں اپنے تسلیم کو پیش کیا ہے (جرمن فیس بوک کی تسلیم کے طور پر جسمی یا نہیں) جرمی فیس بوک کی تسلیم کرنا۔ Binary sequence classification is a standard NLP task with known state-of-the-art methods. لہٰذا ہم دو مختلف ٹیکنیک استعمال کے ذریعہ ڈیٹا تیار کرنے پر تمرکز کرتے ہیں: task-specific pre-training اور data increase. پہلے ہم ایک دوسری زبان کی مختلف زبانوں میں 12 hatespeech detection datasets پر multilingual transformers (XLM-RoBERTa اور MT5) ترین کریں۔ F1 کے مطابق، ہم متوسط پر 10% کی سوداگری کو دیکھتے ہیں، کام کے مطابق مخصوص پیش آموزش کے مطابق۔ دوسرا، ہم ڈیٹا اضافہ کر رہے ہیں، بغیر قابل تعلیم کے مطابق، فیس بوک سے لیبل کیا گیا ہے، کہ تطابق ڈیٹا سٹ کے اندازے 79% سے اضافہ کریں۔ افزایش کی ترینسی ڈیٹ سٹ پر آموزش کی موڈلیاں متوسط +0.0282 (+5%) F1 اسکور کے مطابق موڈلیاں جو اصلی ترینسی ڈیٹ سٹ پر آموزش کی جاتی ہیں۔ آخر میں، دو ٹیکنیک کی ترکیب ہمیں 0.6899 کی F1 اسکور ملنے کی اجازت دیتی ہے XLM- RoBERTa اور 0.6859 MT5 کے ساتھ. پروژیکل کا کوڈ موجود ہے: https://github.com/airKlizz/germeval2021toxic.', 'kk': 'Біз 2021 жылы GermEval (неміс Фейсбук түсініктемелерін негізгі немесе емес) алғашқы суретіне келтіреміз. Бинарлық реттерді таңдау - белгілі орындау әдістері бар NLP тапсырмасының стандартты тапсырмасы. Сондықтан, біз деректерді дайындау үшін екі түрлі техникалық қолданып: тапсырманың алдындағы оқытуы мен деректерді көптеу үшін көздеген. Біріншіден, біз көптеген тілді түрлендірушерді (XLM- RoBERTa және MT5) 12 жалғыз сөзді анықтау деректер қорларына 9 тілде ауыстырмыз. F1 нәтижесінде, біз орташа 10% жұмыс істеу арқылы тапсырманың алдындағы оқытуын қолданатын. Екіншіден, Фейсбуктан алған түсініктемелерді белгілеп деректерді көшейту үшін 79% дегенге өзгертіп жатқан. Кеңейтілген оқыту деректер жиынында оқыту үлгілері орташа +0, 0282 (+5%) F1 нүктесі бастапқы оқыту деректер жиынында оқыту үлгілерімен салыстырылады. Соңында, екі технологиялардың біріктірімізге 0, 6899 XLM- RoBERTa және 0, 6859 MT5 дегенмен F1 нөмірін алуға мүмкіндік береді. Жобаның коды: https://github.com/airKlizz/germeval2021toxic.', 'uz': "Biz GermEval 2021'ning birinchi tub vazifasini (Olmoncha Facebook tafsilotlarini ko'proq ko'rinishimiz mumkin). @ info: whatsthis Therefore, we focus on data preparation by using two different techniques: task-specific pre-training and data augmentation.  Birinchisi, biz bir necha tillar o'zgarishlarni (XLM-RoBERTA va MT5) o'rganishdan oldin to'qqat so'zlar bilan bir necha so'zlarni o'rganamiz. F1 davomida, biz vazifaning foydalanuvchi oldini foydalanishimiz oddiy 10% uzoqligini ko'rganamiz. Ikkinchi so'zda, biz foydalanuvchi notoʻgʻri izohlar yordamida foydalanuvchi maʼlumot soʻzni 79%'ga oshirish uchun foydalanamiz. Name Oxiri, ikkita teknologiya birlashtirish imkoniyatini MT5 bilan 0.6899ning 0.6899ning 0.6899ni ishga tushirish imkoniyatini beradi. Loyiha kodlash mavjud emas: https://github.com/airKlizz/germeval2021toxic.", 'vi': 'Chúng tôi xin trình bày sự đệ trình của mình vào phần đầu tiên của GermEvl 2021 (phân loại các bình luận trên Facebook của Đức là độc hại hay không). Mã nhị phân phân phân là một công việc tiêu chuẩn của chọc dò tủy sống với các phương pháp hiện đại. Chúng tôi tập trung vào việc chuẩn bị dữ liệu bằng cách sử dụng hai kỹ thuật khác nhau: Đầu tiên, chúng tôi khởi tạo các máy biến dạng đa dạng (XLM-RoennTa và MTV) trên 12 Hat-seel bóc trần ngôn ngữ khác nhau. Trên dạng dạng F1, chúng tôi nhận thấy một sự cải tiến trên trung bình, nhờ vào khóa huấn luyện đặc biệt. Thứ hai, chúng tôi thực hiện việc tăng cường dữ liệu bằng cách dán nhãn các bình luận chưa được ghi rõ, dựa trên Facebook, để tăng kích thước dữ liệu về huấn luyện tập trên đường cao. Mẫu được huấn luyện trên tập tin gia tăng đạt được trung bình +0.282 (+5=)) số F1 so với các mẫu được đào tạo trên tập tin ban đầu. Cuối cùng, sự kết hợp của hai kỹ thuật cho phép chúng ta đạt được điểm F1 của 0.6899 với XLM- Roerbta và 0.6899 với MTV. The code of the project is available at: https://github.com/airKlizz/germeval2021toxic.', 'bg': 'Представяме нашето представяне на първата подзадача на класификация на немските коментари във Фейсбук като токсични или не. Класификацията на двоичната последователност е стандартна задача с известни най-съвременни методи. Затова се фокусираме върху подготовката на данните, като използваме две различни техники: специфично за задачата предварително обучение и увеличаване на данните. Първо, предварително обучаваме многоезични трансформатори (XLM-RoBERTa и MT5) на 12 набора от данни за откриване на хетспех на девет различни езика. По отношение на Формула 1 забелязваме подобрение средно от 10%, като използваме специфично предварително обучение. Второ, ние извършваме увеличаване на данните чрез етикетиране на незабелязани коментари, взети от Фейсбук, за да увеличим размера на набора от данни за обучение с 79%. Моделите, обучени по разширения набор от данни за обучение, получават средно +0.0282 (+5%) резултат в сравнение с моделите, обучени по оригиналния набор от данни за обучение. И накрая, комбинацията от двете техники ни позволява да получим резултат от 0.6899 при ХЛМ- РоBERTa и 0.6859 при МТ5. Кодът на проекта е достъпен на адрес: https://github.com/airKlizz/germeval2021toxic.', 'nl': 'We presenteren onze inzending aan de eerste subtaak van GermEval 2021 (classificatie van Duitse Facebook reacties als giftig of niet). Binaire sequentieclassificatie is een standaard NLP-taak met bekende state-of-the-art methoden. Daarom richten we ons op gegevensvoorbereiding door gebruik te maken van twee verschillende technieken: taakspecifieke pre-training en data augmentation. Eerst trainen we meertalige transformatoren (XLM-RoBERTa en MT5) op 12 hatespech detectie datasets in negen verschillende talen. Qua F1 zien we gemiddeld een verbetering van 10% door middel van taakspecifieke pretraining. Ten tweede voeren we data augmentatie uit door niet-gelabelde reacties, afkomstig van Facebook, te labelen, om de grootte van de trainingsdataset met 79%. Modellen getraind op de augmented training dataset verkrijgen gemiddeld +0,0282 (+5%) F1 score vergeleken met modellen die getraind zijn op de originele training dataset. Tot slot, de combinatie van de twee technieken stelt ons in staat om een F1 score te verkrijgen van 0.6899 met XLM-RoBERTa en 0.6859 met MT5. De code van het project is beschikbaar op: https://github.com/airKlizz/germeval2021toxic.', 'da': 'Vi præsenterer vores indsendelse til den første underopgave af GermEval 2021 (klassificering af tyske Facebook kommentarer som giftige eller ej). Binær sekvensklassificering er en standard NLP-opgave med kendte state-of-the-art metoder. Derfor fokuserer vi på dataforberedelse ved hjælp af to forskellige teknikker: opgavespecifik pre-training og data augmentation. Først træner vi flersprogede transformere (XLM-RoBERTa og MT5) på 12 hatespeech detektionsdatasæt på ni forskellige sprog. Med hensyn til F1 bemærker vi en forbedring på 10% i gennemsnit ved hjælp af opgavespecifik pre-training. For det andet udfører vi dataforøgelse ved at mærke ikke-mærkede kommentarer, taget fra Facebook, for at øge størrelsen af træningsdatasættet med 79%. Modeller, der er trænet på det udvidede træningsdatasæt, får gennemsnitligt +0,0282 (+5%) F1 score sammenlignet med modeller, der er trænet på det oprindelige træningsdatasæt. Endelig giver kombinationen af de to teknikker os mulighed for at opnå en F1 score på 0,6899 med XLM- RoBERTa og 0,6859 med MT5. Koden for projektet findes på: https://github.com/airKlizz/germeval2021toxic.', 'hr': 'Predstavljamo svoju prednost prvom podpitanju GermEval 2021 (klasifikacija njemačkih komentara Facebook-a kao otrovna ili ne). Klasifikacija binarnih sekvencija je standardni zadatak NLP sa poznatim metodama umjetnosti. Stoga se fokusiramo na pripremu podataka koristeći dvije različite tehnike: predobuku za zadatke i povećanje podataka. Prvo, mi predvježbamo višejezičke transformatore (XLM-RoBERTa i MT5) na 12 podataka otkrivanja govora mržnje na devet različitih jezika. S obzirom na F1, primjećujemo poboljšanje od 10% prosječno, koristeći predobuku predodređenog zadatka. Drugo, povećavamo podatke označavajući neizbiljne komentare, uzete iz Facebook-a, kako bi povećali veličinu podataka obuke za 79%. Modeli obučeni na povećanom setu podataka obuke dobivaju prosječan rezultat +0,0282 (+5%) F1 u usporedbi s modelima obučenim na početnom setu podataka obuke. Konačno, kombinacija dva tehnika omogućava da dobijemo rezultat F1 od 0,6899 s XLM-RoBERTom i 0,6859 s MT5. Kod projekta je dostupan na: https://github.com/airKlizz/germeval2021toxic.', 'de': 'Wir präsentieren unsere Einreichung zum ersten Teilauftrag von GermEval 2021 (Klassifizierung deutscher Facebook-Kommentare als toxisch oder nicht). Binäre Sequenzklassifizierung ist eine Standard-NLP-Aufgabe mit bekannten State-of-the-Art-Methoden. Daher konzentrieren wir uns auf die Datenaufbereitung mit zwei verschiedenen Techniken: aufgabenspezifisches Pre-Training und Data Augmentation. Zunächst trainieren wir mehrsprachige Transformatoren (XLM-RoBERTa und MT5) auf 12-Hatespech-Detektionsdatensätzen in neun verschiedenen Sprachen. In Bezug auf F1 bemerken wir eine Verbesserung von durchschnittlich 10% durch aufgabenspezifisches Vortraining. Zweitens führen wir eine Datenvergrößerung durch, indem wir nicht gekennzeichnete Kommentare von Facebook kennzeichnen, um die Größe des Trainingsdatensatzes um 79%. Modelle, die auf dem erweiterten Trainingsdatensatz trainiert werden, erhalten im Durchschnitt +0,0282 (+5%) F1 Score im Vergleich zu Modellen, die auf dem ursprünglichen Trainingsdatensatz trainiert wurden. Schließlich ermöglicht uns die Kombination der beiden Techniken eine F1-Punktzahl von 0.6899 mit XLM-RoBERTa und 0.6859 mit MT5 zu erhalten. Der Code des Projekts ist verfügbar unter: https://github.com/airKlizz/germeval2021toxic.', 'fa': 'ما تسلیم کردن خود را به اولین زیر سوال GermEval 2021 (فرقه\u200cای از توضیح فیسبوک آلمانی به عنوان سمی یا نه) پیشنهاد می\u200cکنیم. گرم\u200cبندی دویینی یک کار NLP استاندارد با روش\u200cهای موقعیت هنر شناخته می\u200cشود. بنابراین، ما با استفاده از دو تکنیک مختلف روی آماده داده ها تمرکز می کنیم: آموزش پیش از کار و افزایش داده های مختلف. اول، ما پیش از آموزش تغییردهندگان چندین زبان (XLM-RoBERTa و MT5) را روی مجموعه داده\u200cهای شناسایی ۱۲ سخنرانی متنفر در ۹ زبان متفاوت آموزش می\u200cدهیم. در مورد F1، متوجه شدیم که توسعه ۱۰ درصد در متوسط، با استفاده از آموزش پیش از آموزش مشخص وظیفه است. دوم، ما توسط برچسب توضیح نامه\u200cای که از فیسبوک گرفته شده\u200cاند، افزایش داده\u200cها را انجام می\u200cدهیم تا اندازه\u200cهای مجموعه داده\u200cهای آموزش را به 79 درصد افزایش دهیم. نمونه\u200cهای آموزش روی مجموعه داده\u200cهای آموزش بیشتر در میانگین +0.0282 (+5%) F1 در مقایسه با نمونه\u200cهای آموزش شده در مجموعه داده\u200cهای آموزش اصلی می\u200cگیرند. بالاخره، ترکیب دو تکنیک به ما اجازه می دهد که یک امتیاز F1 از 0.6899 با XLM- RoBERTa و 0.6859 با MT5 دریافت کنیم. کد پروژه موجود است: https://github.com/airKlizz/germeval2021toxic.', 'sw': 'Tunawasilisha ujumbe wetu wa kwanza kwenye jukumu la GermEval 2021 (uangalifu wa maoni ya Facebook ya Ujerumani kama sumu au la). Kugawanyika kwa mfululizo wa pili ni kazi ya kawaida ya NLP yenye utaratibu wa hali ya sanaa. Kwa hiyo, tunajikita kwenye maandalizi ya taarifa kwa kutumia mbinu mbili tofauti: mafunzo maalum ya kabla na kuongeza taarifa. Kwanza, tunajifunza mabadiliko ya lugha mbalimbali (XLM-RoBERTa na MT5) katika taarifa za kutambua hotuba 12 za chuki kwa lugha tisa tofauti. In terms of F1, we notice an improvement of 10% on average, using task-specific pre-training.  Pili, tunafanya kuongezeka kwa takwimu kwa kutambua maoni yasiyotambuliwa, yaliyochukuliwa kutoka Facebook, ili kuongeza ukubwa wa takwimu za mafunzo kwa asilimia 79. Modeli zilizofundishwa katika takwimu za mafunzo zilizoongezeka zinazopata wastani +0.0282 (+5%) score za F1 ukilinganishwa na modeli zilizofundishwa katika seti ya mafunzo ya asili. Mwisho, muungano wa mbinu hizi unaruhusu kupata kipindi cha F1 cha 0.6899 na XLM-RoBERTa na 0.6859 na MT5. Sheria ya mradi inapatikana kwa: https://github.com/airKlizz/germeval2021toxic.', 'ko': 'GermEval 2021에 제출한 첫 번째 하위 임무(독일 페이스북 리뷰의 독성 여부 분류)이진 시퀀스 분류는 가장 진보된 방법을 채택한 표준 NLP 작업입니다.따라서 우리는 두 가지 다른 기술을 사용하여 데이터를 준비하는 데 중점을 둘 것이다. 그것이 바로 특정한 임무의 예비 교육과 데이터 확충이다.우선, 우리는 9가지 서로 다른 언어의 12개hatespeech 검측 데이터 집합에서 다언어 변형금강(XLM RoBERTA와 MT5)을 미리 훈련한다.F1의 경우 임무에 특정된 예훈련을 사용하면 평균 10% 높아진다는 것을 알아차렸다.그 다음으로 페이스북에서 온 미표기 논평을 표시함으로써 훈련 데이터 집합의 크기를 79% 늘렸다.원시 훈련 데이터 집합에서 훈련한 모델에 비해 증강훈련 데이터 집합에서 훈련한 모델은 평균 +0.0282(+5%) F1 점수를 받았다.마지막으로 이 두 가지 기술의 결합으로 XLM-RoBERTA와 MT5의 F1 성적은 각각 0.6899와 0.6859이다.프로젝트 코드는 다음 웹 사이트에서 사용할 수 있습니다.https://github.com/airKlizz/germeval2021toxic.', 'sq': 'Ne paraqesim paraqitjen tonë në nënpyetjen e parë të GermEval 2021 (klasifikimi i komenteve gjermane në Facebook si toksike apo jo). Klasifikimi binar i sekuencës është një detyrë standard NLP me metoda të njohura më të larta. Prandaj, ne përqëndrohemi në përgatitjen e të dhënave duke përdorur dy teknika të ndryshme: paratrainimin specifik për detyrat dhe rritjen e të dhënave. Së pari, ne paratrajnojmë transformuesit shumëgjuhësorë (XLM-RoBERTa dhe MT5) në 12 grupe të dhënash për zbulimin e fjalëve të urrejtjes në nëntë gjuhë të ndryshme. Në lidhje me F1, ne vëmë re një përmirësim prej 10% mesatarisht, duke përdorur përpara-trainimin specifik për detyrat. Së dyti, ne kryejmë rritjen e të dhënave duke etiketuar komentet pa etiketë, të marrë nga Facebook, për të rritur madhësinë e të dhënave të trainimit me 79%. Modelet e stërvitura në grupin e të dhënave të rritura të stërvitjes marrin mesatarisht +0.0282 (+5%) rezultat F1 krahasuar me modelet e stërvitura në grupin e të dhënave origjinale të stërvitjes. Më në fund, kombinimi i të dy teknikave na lejon të marrim një rezultat F1 prej 0.6899 me XLM-RoBERTa dhe 0.6859 me MT5. Kodi i projektit është në dispozicion në: https://github.com/airKlizz/germeval2021toxic.', 'am': 'የጌርምEval 2021 የመጀመሪያውን አዋጅ (የጀርመን የፌስቡክ ትርጉም እንደ ሰክሲ ወይም አይደለም) አቀረብን፡፡ የአሁኑን ፋይል አስቀምጥ ስለዚህም ሁለት የተለየ ልዩ ደረጃዎች በመጠቀም የዳታ ማዘጋጀት እናስከትናለን፡፡ በመጀመሪያ፣ ብዙ ቋንቋዎች ለውጦችን (XLM-RoBERTA እና MT5) በ12 የጥል ንግግር አጣራጭ ዳታዎችን በዘጠኝ ልዩ ቋንቋዎች ላይ እናስተማርካለን፡፡ F1 በተደረገ የሥርዓት ቀድሞ ትምህርት የተጠቃሚ ትምህርት የተደረገውን 10 በመቶ ያበረታናል፡፡ በሁለተኛው፣ ከፌስቡክ የተወሰደውን የዳታ ማስታወቂያውን በ79 በመቶ በማድረግ እናሳድጋለን፡፡ አዲስ ዶሴ ፍጠር በመጨረሻም፣ የሁለቱን ቴክኖዎች ቁጥጥር የ0.6899ን የ. የፕሮጀክት ኮድ፦ https://github.com/airKlizz/germeval2021toxic.', 'hy': 'Մենք ներկայացնում ենք մեր ներկայացումը գերմանական Ֆեյսբուքի մոտեցումների դասակարգման որպես թունավոր կամ ոչ: Երկունական հաջորդականության դասակարգումը ստանդարտ ՆԼՊ խնդիր է, որն ունի հայտնի ամենաբարձր մեթոդներ: Այսպիսով, մենք կենտրոնանում ենք տվյալների պատրաստման վրա, օգտագործելով երկու տարբեր մեթոդներ՝ խնդիրների մասնավոր նախապատրաստման և տվյալների աճի միջոցով: Նախ և առաջ, մենք նախապատրաստում ենք բազմալեզու վերափոխողներին (XLM-ROBERta և MT5) 12 ատելության խոսքի հայտնաբերման տվյալների համակարգերին ինը տարբեր լեզուներով: F1-ի տեսանկյունից մենք նկատում ենք 10 տոկոսի բարելավումը միջինում, օգտագործելով խնդիրների մասնավոր նախապատրաստման գործընթացը: Երկրորդ, մենք կատարում ենք տվյալների բարձրացումը ֆեյսբուքից վերցված բացահայտված մեկնաբանությունների պիտակավորման միջոցով, որպեսզի կրթության տվյալների համակարգի չափերը 79 տոկոսով բարձրացնենք: Աճեցված ուսումնասիրության տվյալների համակարգում սովորեցված մոդելները ստանում են միջին +0.02 82 (+5") F1 գնահատականը, համեմատած նախնական ուսումնասիրության տվյալների համակարգում սովորեցված մոդելների հետ: Վերջապես, երկու մեթոդների միավորումը թույլ է տալիս ստանալ F1-ի 0.6899 գնահատականը XLM-ROBERta-ի և 0.6859-ի հետ MT5-ի հետ: Նախագծի կոդը հասանելի է https://github.com/airKlizz/germeval2021toxic.', 'af': "Ons stel ons ondersoek aan die eerste ondersoek van GermEval 2021 (klasifikasie van Duitse Facebook kommentaar as toxies of nie). Binêre volgorde klasifikasie is 'n standaard NLP taak met bekende state-of-the-art metodes. Daarom, ons fokus op data voorbereiding deur twee verskillende teknike te gebruik: opdragspesifieke voorbereining en data vergroot. Eerste, ons trein multitaalske transformeerders (XLM-RoBERTa en MT5) op 12 haatspraak beskrywing datastelle in nege verskillende tale. In terms of F1, ons aanmerk 'n verbetering van 10% op gemiddelde, met gebruik van taak spesifieke voor-oefening. Tweede, ons uitvoer data augmentasie deur die merkeling van ongeabelde kommentaar, geneem van Facebook, om die grootte van die opvoerdatasset by 79% te vermeerder. Modele wat opgelei is op die vergroot onderwerp datastel, kry op gemiddelde +0. 0282 (+5%) F1 telling vergelyk met modele wat opgelei is op die oorspronklike onderwerp datastel. Eindelik, die kombinasie van die twee teknike laat ons toe om 'n F1 telling van 0. 6899 te kry met XLM- RoBERTa en 0. 6859 met MT5. Die kode van die projek is beskikbaar by: https://github.com/airKlizz/germeval2021toxic.", 'id': 'Kami mempersembahkan pengiriman kami ke subtask pertama dari GermEval 2021 (klasifikasi komentar Facebook Jerman sebagai racun atau tidak). Klasifikasi urutan binari adalah tugas NLP standar dengan metode state-of-the-art yang diketahui. Therefore, we focus on data preparation by using two different techniques: task-specific pre-training and data augmentation.  First, we pre-train multilingual transformers (XLM-RoBERTa and MT5) on 12 hatespeech detection datasets in nine different languages.  In terms of F1, we notice an improvement of 10% on average, using task-specific pre-training.  Kedua, kami melakukan peningkatan data dengan mengetikkan komentar tanpa label, diambil dari Facebook, untuk meningkatkan ukuran dataset latihan dengan 79%. Model dilatih pada set data pelatihan bertambah mendapatkan rata-rata +0.0282 (+5%) skor F1 dibandingkan dengan model dilatih pada set data pelatihan asli. Akhirnya, kombinasi dari dua teknik memungkinkan kita untuk mendapatkan skor F1 0,6899 dengan XLM-RoBERTa dan 0,6859 dengan MT5. Kode proyek tersedia di: https://github.com/airKlizz/germeval2021toxic.', 'az': 'Biz ilk GermEval 2021-in ilk d…ôf…ô soruŇüduńüumuza (Alman Facebook-in m…ôlumatlarńĪnńĪ zehirli v…ô ya yoxdur) t…ôsdiql…ôyirik. ńįkinci sńĪralama sńĪralama bilinmiŇü NLP iŇül…ôridir. Bel…ôlikl…ô, iki m√ľxt…ôlif tekniki istifad…ô ed…ôr…ôk m…ôlumatlar hazńĪrlamasńĪna odaqlanńĪrńĪq: task-specific pre-training v…ô data augmentation. ńįlk d…ôf…ô, biz 12 nifr…ôt s√∂zl…ôri keŇüfetm…ô veri qurmaqlarńĪnńĪ doqquz f…ôrqli dild…ô √ßoxlu dil transformat√ßńĪlarńĪ (XLM-RoBERTa v…ô MT5) t…ôhsil edirik. F1 il…ô birlikd…ô, ortalama 10%-in yaxŇüńĪlńĪńüńĪnńĪ √∂yr…ôndik, iŇül…ôri t…ôhsil edil…ôn √∂yr…ônm…ôk √ľ√ß√ľn istifad…ô edirik. ńįkincisi, biz Facebook-d…ôn alńĪnmńĪŇü Ňü…ôhad…ôtl…ôri etiketl…ôm…ôkl…ô veril…ôn m…ôlumatlarńĪ artńĪrmaq √ľ√ß√ľn m…ôlumatlarńĪn b√∂y√ľkl√ľy√ľn√ľ 79%-…ô artńĪrdńĪq. √úst√ľnl√ľk t…ôhsil quruluńüunda t…ôhsil edil…ôn modell…ôrd…ô ortalama +0.0282 (+5%) F1 po√ßt alńĪndńĪ. √Ėzg√ľr t…ôhsil quruluńüunda t…ôhsil edil…ôn modell…ôrl…ô qarŇüńĪlaŇüdńĪ. Sonunda, iki tehnikl…ôrin birl…ôŇüdirilm…ôsi biz…ô XLM- RoBERTa v…ô 0. 6859 MT5 il…ô F1 d…ôqiq…ôsini almańüa imkan verir. Layih…ônin kodu faydalanńĪr: https://github.com/airKlizz/germeval2021toxic.', 'bn': 'আমরা জের্মেভাল ২০২১ এর প্রথম সাবাক্ষাৎকারের প্রতি আমাদের জবাব উপস্থাপন করছি (জার্মান ফেসবুকের মন্তব্য ব্যস্ত বা ব্ বাইনারি সেকেন্ড ক্লাস্ফিকেশন একটি স্ট্যান্ডার্ড এনএলপি কাজ, যার সাথে পরিচিত রাষ্ট্র-of-the-art পদ্ধতি। তাই আমরা দুই ভিন্ন প্রযুক্তি ব্যবহার করে তথ্য প্রস্তুতি নিয়ে মনোযোগ দিচ্ছি: কাজের জন্য নির্দিষ্ট প্রশিক্ষণ এবং তথ প্রথমত, আমরা বিভিন্ন ভাষায় বিভিন্ন ভাষায় বিভিন্ন ভাষায় বিভিন্ন ভাষায় প্রশিক্ষণের পূর্বে ট্রেনিং বিনিময় (XLM-RoBERTA এব এফ১-এর ব্যাপারে আমরা সাধারণত ১০% উন্নতি দেখেছি, কাজের জন্য নির্দিষ্ট প্রশিক্ষণ ব্যবহার করেছি। দ্বিতীয়, আমরা তথ্য বাড়তে পারি অলেবার্তা মন্তব্যের মাধ্যমে, যা ফেসবুক থেকে নেওয়া হয়েছে, যাতে প্রশিক্ষণের ডাটাসেটের আকার বৃদ্ Models trained on the augmented training dataset obtain on average +0.0282 (+5%) F1 score compared to models trained on the original training dataset.  অবশেষে, এই দুই প্রযুক্তির সংযোগ আমাদের এফ১ স্কোর পেতে দেয়, যার মাধ্যমে এক্সএলM-রবের্তা এবং ০.6859 এমটি৫ দিয়ে। প্রকল্পের কোড পাওয়া যাচ্ছে: https://github.com/airKlizz/germeval2021toxic.', 'bs': 'Predstavljamo svoju predanost prvom podpitanju GermEval 2021 (klasifikacija njemačkih komentara Facebook-a kao otrovna ili ne). Klasifikacija binarne sekvence je standardni zadatak NLP sa poznatim metodama umjetnosti. Stoga se fokusiramo na pripremu podataka koristeći dvije različite tehnike: predobuku predodređenih zadataka i povećanje podataka. Prvo, mi predvježbamo multijezičke transformere (XLM-RoBERTa i MT5) na 12 podataka za detekciju mržnjačkog govora na devet različitih jezika. S obzirom na F1, primijetili smo poboljšanje od 10% u prosjeku, koristeći predobuku predodređenog zadatka. Drugo, povećavamo podatke označavajući neizbiljne komentare, uzete iz Facebook-a, kako bi povećali veličinu seta podataka obuke za 79%. Modeli obučeni na povećanom setu podataka obuke dobijaju prosječan rezultat +0,0282 (+5%) F1 u usporedbi s modelima obučenim na originalnom setu podataka obuke. Konačno, kombinacija dva tehnika omogućava da dobijemo rezultat F1 od 0,6899 sa XLM-RoBERTom i 0,6859 sa MT5. Kod projekta je dostupan na: https://github.com/airKlizz/germeval2021toxic.', 'et': 'Esitleme oma esitlust GermEval 2021 esimesele alamülesandele (Saksa Facebooki kommentaaride klassifitseerimine toksilisteks või mitte). Binaarne jada klassifitseerimine on standardne NLP ülesanne, millel on teadaolevad kaasaegsed meetodid. Seetõttu keskendume andmete ettevalmistamisele kahe erineva tehnika abil: ülesandespetsiifiline eelkoolitus ja andmete suurendamine. Esiteks koolitame mitmekeelseid transformaatoreid (XLM-RoBERTa ja MT5) 12 hatespeechi tuvastamise andmekogumile üheksas erinevas keeles. F1 osas märkame keskmiselt 10% paranemist, kasutades ülesandespetsiifilisi eelkoolitusi. Teiseks suurendame andmeid märgistades Facebookist võetud märgistamata kommentaare, et suurendada koolitusandmete mahtu 79%. Lisatud treeningu andmekogumi alusel treenitud mudelid saavad keskmiselt +0,0282 (+5%) F1 skoori võrreldes algse treeningu andmekogumi alusel treenitud mudelitega. Lõpuks, kahe tehnika kombinatsioon võimaldab meil saada F1 skoor 0,6899 XLM-RoBERTa ja 0,6859 MT5. Projekti kood on kättesaadav aadressil: https://github.com/airKlizz/germeval2021toxic.', 'tr': "Biz GermEval 2021-nji ýyldan ilkinji soragymyza (Alman Facebookyň töwürlerini toksik ýa-da däldir) berýäris. _BAR_ Şol sebäpli, maglumat taýýarlamagyny iki dürli tekniki ulanarak üns berýäris: zadyň ön-okuw we maglumatyň ýetişdirmegi üçin. Ilkinji gezek, biz 12 ýigrençä çykyş sözlerini 9 dürli dilde köp dil üýtgetmenleri (XLM-RoBERTa we MT5) öňünden öňünden öňünden çykarýarys. F1'de ortalamada 10% gelişmegi fark edýäris. Öň öňünden öňünden öňünden öňünden öňünden öňünden gelen täzelikleri ulanýarys. Ikinjisi, biz Facebook-den alınan ýazylmaz terjimeleri etiketleýän maglumatlaryň ulyklaryny 79% tarapyna artyp berýäris. Köçeklenen eğitim datawatlarynda öwrenmeli modeller +0.0282 (+5%) F1 sany öwrenmesi üçin önünji eğitim datawatlarynda öwrenmeli modellere karşılaşdyrylýar. Soňunda, iki tekniklerin birleşmesi bizim için 0,6899 XLM-RoBERTa we 0,6859 MT5'de bir F1 अंतर almamıza mümkin edýär. Bu faýlyň kody bar: https://github.com/airKlizz/germeval2021toxic.", 'fi': 'Esittelemme lähetyksemme GermEval 2021:n ensimmäiseen alatehtävään (saksalaisten Facebook-kommenttien luokittelu myrkyllisiksi tai ei-toksisiksi). Binäärisekvenssiluokitus on standardi NLP-tehtävä, jossa käytetään tunnettuja viimeisimpiä menetelmiä. Siksi keskitymme datan valmisteluun käyttämällä kahta eri tekniikkaa: tehtäväkohtaista esikoulutusta ja datan lisäämistä. Ensin esikoulutamme monikielisiä muuntajia (XLM-RoBERTa ja MT5) 12 hatespeech-tunnistustietoon yhdeksällä eri kielellä. F1:n osalta huomaamme keskimäärin 10 prosentin parannuksen tehtäväkohtaisella esikoulutuksella. Toiseksi suoritamme datan lisäämisen merkitsemällä Facebookista otetut merkinnättömät kommentit kasvattaaksemme koulutusaineiston kokoa 79%. Lisätyllä harjoitusaineistolla koulutetut mallit saavat keskimäärin +0,0282 (+5%) F1-pisteen verrattuna alkuperäisellä harjoitusaineistolla koulutettuihin malleihin. Näiden kahden tekniikan yhdistelmä mahdollistaa F1-pisteen 0,6899 XLM-RoBERTa:lla ja 0,6859 MT5:llä. Hankkeen koodi on saatavilla osoitteessa: https://github.com/airKlizz/germeval2021toxic.', 'cs': 'Představujeme náš příspěvek k prvnímu podúkolu GermEval 2021 (klasifikace německých Facebook komentářů jako toxické nebo ne). Klasifikace binární sekvence je standardní úloha NLP se známými nejmodernějšími metodami. Proto se zaměřujeme na přípravu dat pomocí dvou různých technik: předškolení specifické pro úkoly a rozšíření dat. Nejprve předtrénujeme vícejazyčné transformátory (XLM-RoBERTa a MT5) na 12hatespech detekčních datových sadách v devíti různých jazycích. Pokud jde o F1, zaznamenáváme zlepšení v průměru o 10% pomocí předškolení specifického pro úkoly. Za druhé provádíme rozšíření dat označením neoznačených komentářů převzatých z Facebooku, abychom zvýšili velikost tréninkového datového souboru o 79%. Modely trénované na rozšířeném tréninkovém datovém setu získávají průměrně +0,0282 (+5%) F1 skóre ve srovnání s modely trénovanými na původním tréninkovém datovém setu. Konečně, kombinace obou technik nám umožňuje získat F1 skóre 0.6899 s XLM- RoBERTa a 0.6859 s MT5. Kód projektu je k dispozici na adrese: https://github.com/airKlizz/germeval2021toxic.', 'ca': "Presentam la nostra subministració a la primera subterrània de GermEval 2021 (classificació dels comentaris alemanys de Facebook com tòxics o no). La classificació de seqüència binaria és una tasca standard de NLP amb mètodes coneguts d'última generació. Per tant, ens centrem en la preparació de dades utilitzant dues tècniques diferents: la pré-capacitació específica de les tasques i el augment de les dades. Primer, preparem transformadors multilingües (XLM-RoBERTa i MT5) en 12 conjunts de dades de detecció de discurs d'odi en nou llengües diferents. En termes de F1, observem una millora del 10% en mitjana, fent servir una formació previa específica. Segon, fem un augment de dades etiquetant comentaris no etiquetats, fets de Facebook, per augmentar la mida del conjunt de dades d'entrenament en un 79%. Els models entrenats en el conjunt de dades de capacitació augmentat obtienen una mitjana de +0,0282 (+5%) puntuació F1 en comparació amb els models entrenats en el conjunt de dades original de capacitació. Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5.  El codi del projecte està disponible a: https://github.com/airKlizz/germeval2021toxic.", 'ha': "Muna halatar da musuluntmu zuwa farkon sub-aikin Germeval 2021 (mai classified of Jarman Facebook as a giya ko kuma ba). Classification ɗin sau biyu is an daidaita aikin NLP na da shiryoyin-state-of-the-art. Saboda haka, munã fokusar da shirin data da za'a yi amfani da misãlai biyu masu diƙayyade: shirin-na-gaba-wa-aikin da za'a ƙara data. Kayyan, za'a tafiyar da shifottori masu multiziman mutane (XLM-RoBERTA da MT5) a kan data na gane na'ura 12 cikin harshe guda. Ga bayan F1, za'a gane kodi mai kyau a tsakanin %10, kuma ana yi amfani da wani aikin da aka ƙayyade wa zaman shawara. Piki, za'a cika ƙaramako da data da ba'a yi alama ba, da aka karɓa daga Facebook, dõmin Mu ƙara girma da tsarin data na shirin da 79%. Models wanda aka yi wa shirin a kan data na gamuwa da aka augutar da za'a sami mai dãma+0.082 (+5%) F1 score, sami da misãlai wanda aka yi wa tsari a kan danne na farko. Ga ƙarshe, komai da tufãfin biyu yana yarda mu iya samun F1 kodi na 0.6899 da XLM-RoBERTA da 0.6859 da MT5. Koden ɗin mazaɓa na da: https://github.com/airKlizz/germeval2021toxic.", 'he': 'אנחנו מציגים את השיחה שלנו לתת השאלה הראשונה של GermEval 2021 מסווג רצף שתיים הוא משימה סטנדרטית של NLP עם שיטות מוקדמות ידועות. לכן, אנו מתמקדים בהכירת נתונים על ידי השימוש בשני טכניקות שונות: אימון מוקדם ספציפי למשימה וגדלת נתונים. ראשית, אנו מתאמנים על משתנים רבות שפות (XLM-RoBERTa ו-MT5) על 12 קבוצות מידע זיהוי נאום שנאה בתשע שפות שונות. במונחים של F1, אנחנו שמים לב שיפור של 10% בממוצע, בשימוש באימונים מראשיים מסויימים למשימות. שנית, אנו מבצעים גידול נתונים על ידי סימני הערות ללא סימנים, שנלקחו מפייסבוק, כדי לגדל את גודל קבוצת נתונים האימונים ב-79%. דוגמנים מאומנים על קבוצת נתוני האימונים המוגברים מקבלים בממוצע +0.0282 (+5%) נקודת F1 בהשוואה לדוגמנים מאומנים על קבוצת נתוני האימונים המקורית. Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5.  הקוד של הפרויקט זמין ב: https://github.com/airKlizz/germeval2021toxic.', 'jv': 'Awak dhéwé mengko nggawe barang-barang sampek kanggo nganggo sesuk dhéwé, German, nggawe sawar nggo Komentar Febèk dhéwé (geklasipun barang tok atawa ora iso wae). AllProgressBar Ngalok, kita kang dipun-ingkang data reader ngegambar gambar 2 teknik gak bener: task-special Awak dhéwé, éwé mulai-luwih banter sampeyan kanggo sabanjur (XLM-RBERT lan MT5) lan 12 kuwi alam-alam kuwi alam-alam panjenengan dataset kanggo siita saben. F1 ditambah barang, kita sampeyan kanggo 10% uwong di waenganggo nggawe task-special preemption. Siji-siji, kita ngerti podhaan manut nang ingkang komentar sing gak nggawe, kawula-tanggal ne bukane saiki, kawula-tanggal ne seneng dataset tukakan dhéwé, padha-uteg, padha-uteg. EMAIL OF TRANSLATORS Sampeyan ngirim perusahaan karo teknik sing dibutuhke awak dhéwé ngewehku F1 puntuan 0.6 karo XLM- RBERT karo 0.6 barêng MT5. Bong kode pergunaké ning acara: https://github.com/airKlizz/germeval2021toxic.', 'sk': 'Predstavljamo svojo oddajo na prvo podnalogo GermEval 2021 (razvrstitev nemških Facebook komentarjev kot strupenih ali ne). Klasifikacija dvojnega zaporedja je standardno opravilo NLP z znanimi najsodobnejšimi metodami. Zato se osredotočamo na pripravo podatkov z uporabo dveh različnih tehnik: predusposabljanje za posamezne naloge in povečanje podatkov. Najprej predusposabljamo večjezične transformatorje (XLM-RoBERTa in MT5) na 12 naborih podatkov o detekciji hatespeech v devetih različnih jezikih. Z vidika F1 opazimo povprečno 10-odstotno izboljšanje s predusposabljanjem za posamezne naloge. Drugič, izvajamo povečanje podatkov z označevanjem neoznačenih komentarjev iz Facebooka, da bi povečali velikost nabora podatkov o usposabljanju za 79%. Modeli, usposobljeni na podlagi povečanega nabora podatkov o vadbi, dobijo povprečno +0,0282 (+5%) rezultata F1 v primerjavi z modeli, usposobljenimi na podlagi originalnega nabora podatkov o vadbi. Končno, kombinacija obeh tehnik nam omogoča doseganje rezultata F1 0,6899 pri XLM- RoBERTa in 0,6859 pri MT5. Koda projekta je na voljo na: https://github.com/airKlizz/germeval2021toxic.', 'bo': 'ང་ཚོས་GermEval 2021(German Facebook comments as toxic or not) ལ་ཐུག་གཟུགས་དང་པོ་དེ་གསལ་བཤད་པ་ཡིན། Binary sequence classification is a standard NLP task with known state-of-the-art methods. དེར་བརྟེན། ང་ཚོས་ཐབས་ལམ་མི་འདྲ་བ་གཉིས་ཀྱི་སྤྱོད་པར་གྲ་སྒྲིག་ཆ་འཕྲིན་བྱེད་ཀྱི་ཡོད། དང་པོ་དེ། ང་ཚོས་སྐད F1་ནང་གི་སྲོལ་ཚོགས་ལྟར། ང་ཚོས་རྒྱ་ནག་ནང་གི་ཚད་ལྡན་༡༠་ཡར་རྒྱས་གཏོང་བ་ཞིག་ཡོད། Second, we perform data augmentation by labelling unlabelled comments, taken from Facebook, to increase the size of the training dataset by 79%. by 79%. The first step is to increase the size of the training dataset by 79%. Models trained on the augmented training dataset obtain on average +0.0282 (+5%) F1 score compared to models trained on the original training dataset. མཐའ་མཇུག་དུ་ཐབས་ལམ་གཉིས་ཀྱི་མཉམ་སྦྲེལ་མཐུད་ན་ང་ཚོའི་རིམ་པ་ཞིག་གི་ཁྱབ་ཆོག་ཡོད། ལས་འགུལ་ཀྱི་ཨང་རྟགས་སྤྱོད་ཚར་ཡོད་པ： https://github.com/airKlizz/germeval2021toxic.'}
{'en': 'WLV-RIT at GermEval 2021 : Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments', 'ar': 'WLV-RIT في GermEval 2021: التعلم متعدد المهام باستخدام المحولات لاكتشاف التعليقات السامة والجذابة والمطالبة بالحقائق', 'pt': 'WLV-RIT na GermEval 2021: Aprendizado multitarefa com transformadores para detectar comentários tóxicos, envolventes e de alegação de fatos', 'fr': 'WLV-RIT à GermEval 2021\xa0: Apprentissage multitâche avec des transformateurs pour détecter les commentaires toxiques, engageants et factuels', 'es': 'WLV-RIT en GermEval 2021: Aprendizaje multitarea con transformadores para detectar comentarios tóxicos, atractivos y de afirmación de hechos', 'ja': 'GERMEval 2021におけるWLV - RIT ：有毒性、魅力的で事実を主張するコメントを検出するためのトランスフォーマーを使用したマルチタスク学習', 'hi': 'GermEval 2021 में WLV-RIT: ट्रांसफॉर्मर के साथ मल्टीटास्क लर्निंग विषाक्त, आकर्षक और तथ्य-दावा टिप्पणियों का पता लगाने के लिए', 'zh': 'WLV-RIT于GermEval 2021:用变压器多任务学,以检有毒,引人入胜实之论', 'ru': 'WLV-RIT на GermEval 2021: Многозадачное Обучение с Трансформаторами для того чтобы обнаружить Токсичные, Увлекательные, и Факты Заявляя Комментарии', 'ga': 'WLV-RIT ag GermEval 2021: Foghlaim Ilthasc le Claochladáin chun Tuairimí Tocsaineacha, Rannpháirteacha agus Éilimh Fíricí a Bhrath', 'ka': 'WLV-RIT GermEval 2021-ში: მრავალრამეტური დასწავლობა ტრანფორმენტებით განახსნა ტოქსიკური, მოწყობილობა და ფაქტის კლამიმინირების კომენტებით', 'el': 'Πολυtasking εκμάθηση με μετασχηματιστές για την ανίχνευση τοξικών, εμπλεκόμενων και ισχυριστικών γεγονότων Σχόλια', 'hu': 'WLV-RIT a GermEval 2021-en: többfeladatos tanulás transzformátorokkal a mérgező, elkötelezett és tényállító megjegyzések felismerésére', 'it': 'WLV-RIT a GermEval 2021: Apprendimento multitasking con i trasformatori per rilevare tossicità, coinvolgimento e affermazione dei fatti', 'lt': 'WLV-RIT „GermEval 2021“: Daugiauždavinio mokymasis su transformatoriais toksiniam nustatymui, dalyvavimui ir faktų ieškiniui nustatyti', 'kk': 'GermEval 2021- дегі WLV- RIT: Токсикалық, бағыттау және факт- көлемдеу комментарияларын анықтау үшін көптеген тапсырмаларды оқыту', 'ms': 'WLV-RIT di GermEval 2021: Pelajaran Berbanyak Tugas Dengan Penukar untuk Mengesan Komen Toksik, Bergabung, dan Menaklumkan Fakta', 'mk': 'WLV-RIT на GermEval 2021: Мултизадачно учење со трансформирачи за детектирање на токсични, ангажирани и факти', 'mt': 'WLV-RIT at GermEval 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments', 'ml': 'ജെര്\u200dമ്മെവാല്\u200d 2021-ലെ WLV-RIT: ടോക്സിക്ക്, എഞ്ചിങ്ങിംഗ്, ഫാക്റ്റ്-ക്ലാമിങ്ങ് കണക്കിന്റെ അഭിപ്രായങ്ങള്\u200d', 'pl': 'WLV-RIT na GermEval 2021: Wielozadaniowe uczenie się z transformatorami do wykrywania toksycznych, angażujących i faktów Komentarze', 'no': 'WLV-RIT på GermEval 2021: Multitask Learning with Transformers to Detect Toxic, Engaging and Fact-Claiming Comments', 'mn': 'GermEval 2021 оны WLV-RIT: Тохиромжтой, хөдөлгөөн, үнэндээ нэмэгдүүлэх хэмжээсүүдтэй олон ажил суралцах нь', 'ro': 'WLV-RIT la GermEval 2021: Învățare multifuncțională cu transformatori pentru a detecta toxicitatea, implicarea și afirmarea faptelor Comentarii', 'sr': 'WLV-RIT na GermEval 2021. godine: Multitask učenje sa transformatorima za otkrivanje toksičnih, inženjerskih i činjeničnih komentara', 'si': 'WLV-RIT at Germeval 2021: Multi-job learning with Transferers to Detect Toxic, Engage, and Factor-Claaming Comment', 'so': 'WLV-RIT at GermEval 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments', 'sv': 'WLV-RIT på GermEval 2021: Multitask Learning med transformatorer för att upptäcka giftiga, engagerande och faktaupplicerande kommentarer', 'ta': 'WLV-RIT at GermEval 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments', 'ur': 'جرمیول 2021 میں WLV-RIT: ٹوکسیکسی، انجینگ، اور حقیقت-کلمینگ ٹوکینگ ٹوکینگ یاد کرنے کے لئے بہت سی ٹوکیٹ سیکھنا', 'uz': 'Comment', 'vi': 'WLAV-RIT tại GermEvl 2021: phát triển nhiều nhiệm vụ với các biến hình để tìm ra độc tính, xung đột và Ý kiến thực tế', 'bg': 'Многофункционално обучение с трансформатори за откриване на токсични, ангажиращи и фактически коментари', 'nl': 'WLV-RIT op GermEval 2021: Multitask Leren met Transformers om Giftige, Aantrekkende en Fact Claiming Reacties', 'hr': 'WLV-RIT na GermEval 2021. godine: učenje mnogobrojnih zadataka s transformatorima za otkrivanje toksičnih, inženjerskih i činjeničnih komentara', 'da': 'WLV-RIT på GermEval 2021: Multitask Learning med transformatorer til at opdage giftige, engagerende og fakta-påstandende kommentarer', 'ko': 'WLV-RIT, GermEval 2021: 변압기를 통한 멀티태스킹 학습을 통해 독성, 흥미진진하고 사실을 주장하는 논평을 검출', 'id': 'WLV-RIT di GermEval 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments', 'de': 'WLV-RIT auf der GermEval 2021: Multitasking Learning mit Transformatoren zur Erkennung toxischer, motivierender und faktenbezogener Reaktionen', 'fa': 'WLV', 'sw': 'WLV-RIT kwenye GermEval 2021: Kufundisha na Watafsiri kwa Kutambua Toxico, Uingereza na Maoni yanayohusu', 'tr': "WLV-RIT GermEval 2021'de GermEval'da Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments", 'af': 'Name', 'sq': 'WLV-RIT në GermEval 2021: Mësimi i shumëdetyrave me transformuesit për të zbuluar komentet toksike, të angazhuara dhe të pretenduara fakte', 'am': 'WLV-RIT at GermEval 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments', 'bn': 'গের্মেভাল ২০২১-এ উলভি-রিট: ট্রান্সফর্মার্সারের সাথে অনেক কাজ শিক্ষা দেয়া হচ্ছে টোক্সিকা, ইঞ্জিঙ্গিং এবং ফ্যাক্ট-ক', 'az': 'GermEval 2021-də WLV-RIT: Toksik, Engaging və Fakat-Claiming Komentlərini keşfetmək üçün Transformers ilə çoxlu işlər öyrənmək', 'bs': 'WLV-RIT na GermEval 2021: Multitask učenje s transformatorima za otkrivanje toksičnih, inženjerskih i činjeničnih komentara', 'cs': 'WLV-RIT na GermEval 2021: Multiúlohové učení s transformátory pro detekci toxických, angažujících a faktových komentářů', 'ca': 'WLV-RIT a GermEval 2021: Aprendiment multitascat amb transformadors per detectar comentaris tòxics, enganxats i factuals', 'et': 'WLV-RIT GermEval 2021: mitmeülesandeline õpe transformaatoritega toksiliste, kaasavate ja faktide väidetavate kommentaaride tuvastamiseks', 'fi': 'WLV-RIT GermEvalissa 2021: Monitehtäväoppiminen muuntajien kanssa myrkyllisten, osallistavien ja faktojen toteamiseksi', 'hy': 'ՎԼV-RIT-ը, ԳերմԵվալ 2021 թվականին. Մոտագործողների հետ բազմախնդիր սովորելը թունավոր, ներգրավված և փաստեր պահանջող մեկնաբանություններ հայտնաբերելու համար', 'ha': 'QUnicodeControlCharacterMenu', 'he': 'WLV-RIT at GermEval 2021: Multitask Learning with Transformers to detect toxic, Engaging and Fact-Claiming Comments', 'sk': 'WLV-RIT na GermEvalu 2021: Večopravilno učenje s transformatorji za odkrivanje strupenih, vključujočih in dejstev', 'bo': 'WLV-RIT at GermEval 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments', 'jv': 'WLV-RIT nang germinval 2020: Multitask Learning with Transformer to detect Toksi, Ingaging, and'}
{'en': 'This paper addresses the identification of toxic, engaging, and fact-claiming comments on ', 'ar': 'تتناول هذه الورقة تحديد التعليقات السامة والجذابة والمدعومة للحقائق على وسائل التواصل الاجتماعي. استخدمنا مجموعة البيانات التي أتاحها منظمو المهمة المشتركة GermEval2021 التي تحتوي على أكثر من 3000 تعليق توضيحي يدويًا على Facebook باللغة الألمانية. بالنظر إلى ارتباط المهام الثلاث ، تعاملنا مع المشكلة باستخدام نماذج محولات كبيرة مدربة مسبقًا وتعلم متعدد المهام. تشير نتائجنا إلى أن التعلم متعدد المهام يحقق أداءً متفوقًا على نهج تعلم المهمة المفردة الأكثر شيوعًا في جميع المهام الثلاث. نقدم أفضل أنظمتنا إلى GermEval-2021 تحت اسم الفريق WLV-RIT.', 'es': 'Este artículo aborda la identificación de comentarios tóxicos, atractivos y de afirmación de hechos en las redes sociales. Utilizamos el conjunto de datos puesto a disposición por los organizadores de la tarea compartida GermEval2021 que contenía más de 3000 comentarios de Facebook anotados manualmente en alemán. Teniendo en cuenta la relación de las tres tareas, abordamos el problema utilizando grandes modelos de transformadores preentrenados y aprendizaje multitarea. Nuestros resultados indican que el aprendizaje multitarea logra un rendimiento superior al enfoque más común de aprendizaje de una sola tarea en las tres tareas. Presentamos nuestros mejores sistemas a GermeVal-2021 bajo el nombre del equipo WLV-RIT.', 'pt': 'Este artigo aborda a identificação de comentários tóxicos, envolventes e de alegação de fatos nas mídias sociais. Usamos o conjunto de dados disponibilizado pelos organizadores da tarefa compartilhada GermEval2021 contendo mais de 3.000 comentários do Facebook anotados manualmente em alemão. Considerando o relacionamento das três tarefas, abordamos o problema usando grandes modelos de transformadores pré-treinados e aprendizado multitarefa. Nossos resultados indicam que o aprendizado multitarefa atinge um desempenho superior à abordagem de aprendizado de tarefa única mais comum em todas as três tarefas. Submetemos nossos melhores sistemas ao GermEval-2021 sob o nome de equipe WLV-RIT.', 'fr': "Ce document traite de l'identification des commentaires toxiques, engageants et revendiquant des faits sur les réseaux sociaux. Nous avons utilisé le jeu de données mis à disposition par les organisateurs de la tâche partagée GermeVal2021 contenant plus de 3 000 commentaires Facebook annotés manuellement en allemand. Compte tenu de la relation entre les trois tâches, nous avons abordé le problème à l'aide de grands modèles de transformateurs préentraînés et de l'apprentissage multitâche. Nos résultats indiquent que l'apprentissage multitâche permet d'obtenir des performances supérieures à l'approche d'apprentissage par tâche unique plus courante dans les trois tâches. Nous soumettons nos meilleurs systèmes à GERMEVAL-2021 sous le nom d'équipe WLV-RIT.", 'ja': 'この論文では、ソーシャルメディア上で有毒で魅力的で事実を主張するコメントを特定することに取り組んでいます。私たちは、GermEval 2021共有タスクの主催者によって利用可能になったデータセットを使用しました。このデータセットには、3,000を超える手動で注釈を付けたドイツ語のFacebookコメントが含まれています。3つのタスクの関連性を考慮して、大型の事前訓練された変圧器モデルとマルチタスク学習を使用して問題にアプローチしました。私たちの結果は、マルチタスク学習が3つのタスクすべてにおいて、より一般的な単一タスク学習アプローチよりも優れたパフォーマンスを達成することを示しています。当社は、チーム名WLV - RITとして、当社の最高のシステムをGermEval -2021に提出します。', 'ru': 'В этом документе рассматривается выявление токсичных, увлекательных и претендующих на факты комментариев в социальных сетях. Мы использовали набор данных, предоставленный организаторами совместной задачи GermEval2021, содержащей более 3000 ручных комментариев Facebook на немецком языке. Учитывая взаимосвязь трех задач, мы подошли к решению проблемы, используя большие предварительно обученные модели трансформаторов и многозадачное обучение. Наши результаты показывают, что многозадачное обучение достигает производительности, превосходящей более распространенный подход к обучению по одной задаче во всех трех задачах. Мы представляем наши лучшие системы компании GermEval-2021 под названием команды WLV-RIT.', 'zh': '本文讨识社交媒体有毒、引人入胜、声称事实之论。 臣等用GermEval2021共享之组织者数集,其中包3,000多手动注者德语Facebook论。 念此三相关性者,吾以大变压器、多任务学为之。 吾之的结果表明,凡三务之中,多任务学之性优于常见者也。 以至统提GermEval-2021,其团队名曰WLV-RIT。', 'hi': 'यह पेपर सोशल मीडिया पर विषाक्त, आकर्षक और तथ्य-दावा करने वाली टिप्पणियों की पहचान को संबोधित करता है। हमने GermEval2021 साझा कार्य के आयोजकों द्वारा उपलब्ध कराए गए डेटासेट का उपयोग किया, जिसमें जर्मन में 3,000 से अधिक मैन्युअल रूप से एनोटेट की गई फेसबुक टिप्पणियां शामिल थीं। तीन कार्यों की संबद्धता को ध्यान में रखते हुए, हमने बड़े पूर्व-प्रशिक्षित ट्रांसफार्मर मॉडल और मल्टीटास्क सीखने का उपयोग करके समस्या से संपर्क किया। हमारे परिणामों से संकेत मिलता है कि मल्टीटास्क लर्निंग सभी तीन कार्यों में अधिक सामान्य एकल कार्य सीखने के दृष्टिकोण से बेहतर प्रदर्शन प्राप्त करता है। हम टीम के नाम WLV-RIT के तहत GermEval-2021 के लिए हमारी सबसे अच्छी प्रणालियों को प्रस्तुत करते हैं।', 'ga': 'Tugann an páipéar seo aghaidh ar thuairimí tocsaineacha, mealltacha agus fíorais a shainaithint ar na meáin shóisialta. D’úsáideamar an tacar sonraí a chuir lucht eagraithe an taisc chomhroinnte GermEval2021 ar fáil a chuimsigh breis agus 3,000 tráchtaireacht Facebook i nGearmáinis a bhí anótáilte de láimh. Ag cur san áireamh a bhaineann leis na trí thasc, chuamar i ngleic leis an bhfadhb trí úsáid a bhaint as samhlacha claochladán réamhoilte agus foghlaim ilthasc. Léiríonn ár dtorthaí go n-éiríonn le foghlaim ilthasc feidhmíocht níos fearr ná an cur chuige foghlama tasc aonair is coitianta i ngach ceann de na trí thasc. Cuirimid ár gcórais is fearr faoi bhráid GermEval-2021 faoin ainm foirne WLV-RIT.', 'ka': 'ეს დოკუმენტი საზოგადომი საზოგადომი მედიაში განსაზოგადოება. ჩვენ გამოიყენეთ მონაცემების სექტი, რომელიც GermEval2021-ის ორგანიზატორების გაყოფილი მონაცემები, რომელიც პირდაპირად მონაცემებული Facebook-ის კომენტრები გერმანეთ სამი დავალების შესახებ, ჩვენ მივიღეთ პრობლემას, რომელიც გამოყენებული დიდი პროფექტირების მოდელები და მულტი დავალების სწავლების გამოყენება. ჩვენი წარმოდგენების შესახებ, რომ მრავალრამეტური სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშ ნაი-ეჲბპთრვ ნთ ჟთჟრვმთ ოპაგთმ ნა დვპმვგალ-2021 ოჲე თმვრჲ ნა რთოა WLV-RIT.', 'el': 'Η παρούσα εργασία ασχολείται με τον εντοπισμό τοξικών, ελκυστικών και ισχυρών σχολίων στα μέσα κοινωνικής δικτύωσης. Χρησιμοποιήσαμε το σύνολο δεδομένων που ήταν διαθέσιμο από τους διοργανωτές της κοινής εργασίας που περιείχε πάνω από 3.000 χειροκίνητα σχόλια στο Facebook στα γερμανικά. Λαμβάνοντας υπόψη την συσχέτιση των τριών εργασιών, προσεγγίσαμε το πρόβλημα χρησιμοποιώντας μεγάλα προ-εκπαιδευμένα μοντέλα μετασχηματιστών και εκμάθηση πολλαπλών εργασιών. Τα αποτελέσματά μας δείχνουν ότι η εκμάθηση πολλαπλών εργασιών επιτυγχάνει απόδοση ανώτερη από την πιο κοινή προσέγγιση εκμάθησης ενιαίας εργασίας και στις τρεις εργασίες. Υποβάλλουμε τα καλύτερα συστήματά μας στην ομάδα με το όνομα ομάδας.', 'hu': 'Ez a tanulmány a mérgező, vonzó és tényállító megjegyzések azonosításával foglalkozik a közösségi médiában. A GermEval2021 megosztott feladat szervezői által rendelkezésre bocsátott adatkészletet használtuk, amely több mint 3000 kézzel jegyzett Facebook-hozzászólást tartalmaz német nyelven. A három feladat kapcsolódását figyelembe véve nagyméretű, előre képzett transzformátormodellek és multitasking tanulás segítségével közelítettük meg a problémát. Eredményeink azt mutatják, hogy a többfeladatos tanulás mindhárom feladatban jobb teljesítményt ér el, mint a gyakoribb egyfeladatos tanulási megközelítés. Legjobb rendszereinket WLV-RIT csapatnéven küldjük be a GermEval-2021-nek.', 'kk': 'Бұл қағаз әлемдік медиақтардың тәсіліктерін белгілейтін, қатынасыз және факттардың түсініктерін анықтайды. GermEval2021 бағдарламаларының ортақ тапсырмасының ортақтастырылған деректер жиынын қолдандық, олардың неміс тіліктерінде 3 000 жылдан артық белгілері бар. Үш тапсырманың қатынасыздығын қарастырып, көп тапсырманың оқыту үшін үлкен түрлендіруші үлгілерін және көп тапсырманың оқытуын қолданатын мәселеге келдік. Біздің нәтижелеріміз көптеген тапсырмаларды оқыту үш тапсырмалардың жалпы бір тапсырманың оқыту арқылы көптеген оқыту арқылы болады. Біз ең жақсы жүйелерімізді WLV-RIT деген топ атауының астында GermEval-2021-ге жібереміз.', 'lt': 'Šiame dokumente nagrinėjamos toksinių, įtraukių ir faktų pareikštų pastabų dėl socialinės žiniasklaidos nustatymas. Naudojome germEval2021 organizatorių pateiktą duomenų rinkinį, kuriame buvo daugiau kaip 3 000 rankiniu būdu anotuotų Facebook komentarų vokiečių kalba. Atsižvelgdami į šių trijų užduočių ryšį, spręsėme šią problem ą naudojant didelius iš anksto parengtus transformatorių modelius ir daugiafunkcinį mokymąsi. Mūsų rezultatai rodo, kad daugelio užduočių mokymasis visose trijose užduotyse užtikrina geresnius rezultatus nei bendras vienos užduočių mokymosi metodas. GermEval-2021 pateiksime geriausias sistemas pagal komandos pavadinimą WLV-RIT.', 'mk': 'Овој документ се обраќа на идентификацијата на токсични, интересни и фактовни коментари за социјалните медиуми. Го користевме сетот на податоци на организаторите на GermEval2021 споделена задача со повеќе од 3.000 рачно анотирани коментари на Фејсбук на германски. Со оглед на поврзаноста на трите задачи, пристапивме кон проблемот користејќи големи предобучени трансформаторски модели и мултизадачно учење. Нашите резултати покажуваат дека мултизадачното учење постигнува перформанса супериорна од позаедничкиот пристап на едноставно учење задачи во сите три задачи. Ги поднесуваме нашите најдобри системи на GermEval-2021 под името на тимот WLV-RIT.', 'it': "Questo articolo affronta l'identificazione di commenti tossici, coinvolgenti e fattuali sui social media. Abbiamo utilizzato il dataset messo a disposizione dagli organizzatori del compito condiviso GermEval2021 contenente oltre 3.000 commenti Facebook annotati manualmente in tedesco. Considerando la relazione dei tre compiti, abbiamo affrontato il problema utilizzando grandi modelli di trasformatori pre-addestrati e l'apprendimento multitask. I nostri risultati indicano che l'apprendimento multitasking raggiunge prestazioni superiori al più comune approccio di apprendimento singolo in tutte e tre le attività. Inviamo i nostri migliori sistemi a GermEval-2021 sotto il nome del team WLV-RIT.", 'ms': 'Kertas ini mengarahkan pengenalan komentar beracun, menarik, dan fakta-claiming pada media sosial. We used the dataset made available by the organizers of the GermEval2021 shared task containing over 3,000 manually annotated Facebook comments in German.  Considering the relatedness of the three tasks, we approached the problem using large pre-trained transformer models and multitask learning.  Our results indicate that multitask learning achieves performance superior to the more common single task learning approach in all three tasks.  Kami menghantar sistem terbaik kami kepada GermEval-2021 di bawah nama pasukan WLV-RIT.', 'ml': 'ഈ പേപ്പറിന്\u200dറെ തിരിച്ചറിയുന്നത് പ്രോക്സിക്ക്, ചേര്\u200dക്കുന്നത്, സാമൂഹിക മാധ്യമങ്ങളില്\u200d വെച്ച് സത്യത്ത ജര്\u200dമ്മനില്\u200d 3,000 കൂടുതല്\u200d ഫെക്സുകാരുടെ കൈയ്യില്\u200d കുറ്റപ്പെടുത്തിയ ഫെസ്റ്റ് মন്റോപ്പുകള്\u200d ഉള്\u200dപെടുത്തിയ ജെര്\u200dമ്മെവ ഈ മൂന്നു ജോലികളുടെ ബന്ധങ്ങളെക്കുറിച്ച് ആലോചിച്ച് നമ്മള്\u200d പ്രശ്നം സമീപിച്ചു കൊണ്ടിരുന്നു. മുമ്പ് പരിശീലന മോഡലു നമ്മുടെ ഫലങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നത് മൂന്നു ജോലികളില്\u200d ഏറ്റവും സാധാരണമായ ഒരു ജോലി പഠിക്കുന്നതിനെക്കാ ഞങ്ങള്\u200d നമ്മുടെ ഏറ്റവും നല്ല സിസ്റ്റം ജെര്\u200dമെവാല്\u200d-2021 കീഴിലേക്ക് കൊടുക്കുന്നു. ടീം WLV-RIT എന്ന് പേര്.', 'mt': 'This paper addresses the identification of toxic, engaging, and fact-claiming comments on social media.  Użajna s-sett tad-dejta li sar disponibbli mill-organizzaturi tal-GermEval2021 kompitu kondiviż li kien fih aktar minn 3,000 kumment annotat manwalment fuq Facebook bil-Ġermaniż. Meta wieħed jikkunsidra r-rabta tat-tliet kompiti, aħna approċċjna l-problema bl-użu ta’ mudelli kbar ta’ trasformaturi mħarrġa minn qabel u tagħlim multikompiti. Ir-riżultati tagħna jindikaw li t-tagħlim multikompiti jikseb prestazzjoni superjuri għall-approċċ aktar komuni tat-tagħlim uniku tal-kompiti fit-tliet kompiti kollha. We submit our best systems to GermEval-2021 under the team name WLV-RIT.', 'no': 'Denne papiret adresserer identifiseringa av toksiske, engasjerande og faktiske kommentarar på sosiale media. Vi brukte datasettet som er tilgjengeleg av organisatorene av GermEval2021 delt oppgåve som inneheld over 3 000 manuelt merke Facebook-kommentarar i tysk. Dersom vi gjer oppgåva med høve til at dei tre oppgåva er tilgjengelege, har vi nærmet problemet ved å bruka store føretrainerte transformeringsmodeller og multioppgåver-læring. Resultatet våre tyder på at multioppgåver læring gjennomfører utviklinga over den vanlege enkelte oppgåvelæringstilnærming i alle tre oppgåver. Vi sender dei beste systemene våre til GermEval-2021 under gruppenamnet WLV-RIT.', 'pl': 'Niniejszy artykuł dotyczy identyfikacji toksycznych, angażujących i twierdzących fakty komentarzy w mediach społecznościowych. Wykorzystaliśmy zestaw danych udostępniony przez organizatorów wspólnego zadania GermEval2021 zawierający ponad 3.000 ręcznie adnotacje na Facebooku w języku niemieckim. Biorąc pod uwagę związek trzech zadań, podejśliśmy do problemu za pomocą dużych, wstępnie przeszkolonych modeli transformatorów i wielozadaniowego uczenia się. Nasze wyniki wskazują, że wielozadaniowe uczenie się osiąga wydajność lepszą niż bardziej powszechne podejście do nauki pojedynczego zadania we wszystkich trzech zadaniach. Nasze najlepsze systemy składamy do GermEval-2021 pod nazwą zespołu WLV-RIT.', 'mn': 'Энэ цаас нийгмийн мэдээллийн тухай хохиромжтой, сонирхолтой, үнэндээ илэрхийлж буй захиралтуудыг тодорхойлдог. Бид GermEval2021-ийн зохион байгуулагчид гаргасан өгөгдлийн санг Герман хэлний 3,000 гараас илүү өргөн Facebook-ийн хэлэлцээг ашигласан. Гурван даалгаварын харилцааны тухай ойлгоход бид асуудлыг асуудлын тулд том урд сургалтын шилжүүлэгч загвар болон олон ажлын сургалтыг ашиглан ойлгосон. Бидний үр дүн нь олон ажлын суралцах үйл ажиллагааны үйл ажиллагаа 3 дахь ажиллагааны нэг ажлын суралцах аргыг илүү өндөр хүргэж чадна. Бид хамгийн шилдэг системийг WLV-RIT баг нэртэй GermEval-2021-д оруулдаг.', 'ro': 'Această lucrare abordează identificarea comentariilor toxice, angajatoare și care pretind fapte pe rețelele de socializare. Am folosit setul de date pus la dispoziție de organizatorii sarcinii partajate GermEval2021 conținând peste 3.000 de comentarii Facebook adnotate manual în limba germană. Având în vedere relația celor trei sarcini, am abordat problema utilizând modele mari de transformare pre-instruite și învățarea multitask. Rezultatele noastre indică faptul că învățarea cu mai multe sarcini atinge performanțe superioare abordării mai comune de învățare cu o singură sarcină în toate cele trei sarcini. Trimitem cele mai bune sisteme ale noastre la GermEval-2021 sub numele de echipă WLV-RIT.', 'so': 'Warqaddan waxaa ku qoran aqoonsiga mukhaadaraadka, la wadaajinta iyo commentarka xaqiiqa ah ee shabakadda bulshada. Waxaannu isticmaalnay taariikhda ay qabanqaabiyayaasha GermEval2021 shaqada la qaybsaday oo ku jirta wax ka badan 3,000 oo qof oo afka Jarmalka ku qoran commentaro. Sidaan ka fiirsanayno xiriirka saddexda shaqadooda, waxaynu u soo dhowaynay dhibaatada, waxaynu isticmaalnay tusaalooyin waaweyn oo la bedeli karo horay iyo waxbarasho kala duduwan. Abaalkayaga waxaa loola jeedaa in waxbarashada kala duduwan uu dhamaan saddexda shaqo oo dhan ku gaadho sameynta waxbarashada oo ka sarreeya dhamaantood. We submit our best systems to GermEval-2021 under the team name WLV-RIT.', 'sv': 'Denna uppsats behandlar identifiering av giftiga, engagerande och faktabaserade kommentarer på sociala medier. Vi använde den dataset som gjorts tillgänglig av arrangörerna av GermEval2021 delade uppgift innehållande över 3 000 manuellt kommenterade Facebook kommentarer på tyska. Med tanke på sambandet mellan de tre uppgifterna närmade vi oss problemet med hjälp av stora förklädda transformatormodeller och multitasking learning. Våra resultat indikerar att multitasking learning uppnår prestanda som är överlägsen den vanligaste metoden för single task learning i alla tre uppgifter. Vi skickar in våra bästa system till GermEval-2021 under teamnamnet WLV-RIT.', 'ta': 'இந்த காகிதத்தில் புதிய, இணைத்தல், மற்றும் உண்மையான குறிப்புரைய குறிப்புரைகளை குறிக்கிறது. ஜெர்ம்Eval2021 க்கு மேல் 3,000 க்கு மேற்பட்ட பேச்சு கைமுறையாக குறிப்பிட்ட வேலையை கொண்டிருக்கும் நிறுவப்பட்ட தகவல் அமை மூன்று பணிகளின் தொடர்புகளை பார்த்து, பெரிய பயிற்சி மாற்றம் மாற்றம் மாதிரிகள் மற்றும் பல்கேள்வி கற்றத்தை பயன்படுத்தி நா Our results indicate that multitask learning achieves performance superior to the more common single task learning approach in all three tasks.  நாங்கள் எங்கள் சிறந்த அமைப்புகளை ஜெர்ம்வெல்-2021 க்கு வழங்குகிறோம் WLV-RIT கீழ் அணி பெயர்.', 'ur': 'یہ کاغذ سوسیل میڈیا کے متعلق جسمی، مشغول اور حقیقت کی تعلیمات کی پہچان کرتی ہے. ہم نے جرمی Eval2021 کے سازمان کرنے والوں کے ذریعے دسترسی ڈیٹ سٹ کو استعمال کیا ہے جو 3,000 سے زیادہ جرمن میں فیس بوک کمانٹ کا ذریعہ رکھا ہے۔ ان تین کاموں کی تعلق کے بارے میں ہم نے اس مسئلہ کے پاس پہنچ گئے جو بڑی پیش آموزش کی تغییر مدل اور بہت سی کام کی تعلیم کے مطابق ہے. ہمارے نتیجے نشان دیتے ہیں کہ multitask learning achieves performance superior to the more common task learning approach in all three tasks. ہم نے اپنے بہترین سیسٹم کو ٹیم کے نام کے نیچے جرمEval-2021 میں ڈال دیا ہے.', 'si': 'මේ පැත්තේ සාමාජික මාධ්\u200dයමාධ්\u200dයමයේ විෂ්\u200dය, සම්බන්ධතාවක් සහ ඇත්තටම ප්\u200dරශ්නයක් තියෙනවා. අපි ජර්ම්වේල් 2021 ගේ සංයෝජකයන්ගේ දත්ත සෙට් පාවිච්චි කරනවා ජර්මාන් වලින් සංයෝජකයෙන් සැකසුම් විතරයි ජර්ම වැඩක් තුනක් ගැන සම්බන්ධතා වෙනුවෙන් අපි ප්\u200dරශ්නයට ලොකු ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරනවා ප්\u200dරශ්නයක් ප්\u200dරයෝජනය අපේ ප්\u200dරතිචාරය පෙන්වන්නේ විශේෂ කාර්ය ඉගෙන ගන්න පුළුවන් විශේෂ ප්\u200dරතිචාරයක් වඩා සාමාන්\u200dය වැ අපි අපේ හොඳම පද්ධතිය ජර්ම් එව්ල්-2021 වලට WLV-RIT කණ්ඩායමේ නමේ අඩු වෙනවා.', 'sr': 'Ovaj papir se bavi identifikacijom toksičnih, angažovanih i činjeničnih komentara na društvenim medijima. Koristili smo komplet podataka koji su dostupni organizatori GermEval2021 zajedničkog zadatka koji sadrže preko 3.000 manuelnih komentara Facebook na njemačkom. S obzirom na povezanost tri zadatka, pristupili smo problem koristeći velike predobučene modele transformera i učenje multizadataka. Naši rezultati ukazuju na to da učenje multitaska postiže učenje iznad učenja više od zajedničkog jedinstvenog pristupa učenja zadataka u svim tri zadataka. Poslaæemo najbolje sisteme GermEval-2021 pod tim imenom WLV-RIT.', 'uz': "Ushbu qogʻoz jamiyat media bilan ta'minlovchi, va haqiqiqiy ifodalarni aniqlashni anglatadi. Biz GermEval2021 tashkilotlari tomonidan 3,000 dan ortiq qo'lbola qo'llangan Facebook izohlarini qo'llab qo'llangan tashkilotlar tomonidan qo'llangan. Uch vazifalar bilan bog'liq haqida, biz o'rganishdan oldin o'zgartirish modellari va multiask o'rganishni yordamida muammolarni ko'rdik. Bizning natijalarimiz, ko'pchilik o'rganishni o'rganishni hamma uchta vazifalarga ko'proq bir necha vazifa o'rganishdan ko'proq amalni bajaradi. Biz eng yaxshi tizimmizni GermEval-2021 guruhga WLV-RIT nomli guruhga koʻchimiz.", 'vi': 'Tờ giấy này đề cập đến nhận dạng các bình luận về chất độc, hấp dẫn và thực tế trên mạng xã hội. Chúng tôi đã sử dụng bộ dữ liệu được sắp xếp bởi các tổ chức của nhiệm vụ chia sẻ GermEvul2021 có ghi chú bằng tay trên Facebook bằng kênh 3,000. Dựa trên quan hệ của ba nhiệm vụ, chúng tôi tiếp cận vấn đề bằng các mô hình biến đổi được huấn luyện lớn và học nhiều nhiệm vụ. Kết quả của chúng ta cho thấy việc học đa nhiệm vụ đạt được hiệu quả vượt trội hơn cách thức học tập một nhiệm vụ phổ biến trong ba nhiệm vụ. Chúng ta gửi hệ thống tốt nhất của mình cho GermEvl-2021, tên là WV-RIT.', 'da': 'Denne artikel omhandler identifikation af giftige, engagerende og faktahævdende kommentarer på sociale medier. Vi brugte det datasæt, som arrangørerne af GermEval2021 delte opgave stillede til rådighed, indeholdende over 3.000 manuelt kommenterede Facebook kommentarer på tysk. I betragtning af sammenhængen mellem de tre opgaver nærmede vi os problemet ved hjælp af store prætrænede transformermodeller og multitask learning. Vores resultater indikerer, at multitask learning opnår en ydeevne, der er bedre end den mere almindelige single task learning tilgang i alle tre opgaver. Vi sender vores bedste systemer til GermEval-2021 under teamnavnet WLV-RIT.', 'nl': 'Dit artikel behandelt de identificatie van giftige, boeiende en feiten claimende opmerkingen op sociale media. We gebruikten de dataset die beschikbaar is gesteld door de organisatoren van de gedeelde taak GermEval2021 met meer dan 3.000 handmatig geannoteerde Facebook reacties in het Duits. Gezien de samenhang van de drie taken hebben we het probleem benaderd met behulp van grote voorgetrainde transformatormodellen en multitask learning. Onze resultaten geven aan dat multitask leren prestaties behaalt die superieur zijn aan de meer voorkomende single task learning aanpak in alle drie de taken. Wij leveren onze beste systemen aan GermEval-2021 onder de teamnaam WLV-RIT.', 'hr': 'Ovaj papir se obraća na identifikaciju toksičnih, uključujućih i činjeničnih komentara o društvenim medijima. Koristili smo komplet podataka koji su dostupni organizatori GermEval2021 zajedničkog zadatka sadržavali preko 3.000 manuelnih komentara na Facebook-u na njemačkom. S obzirom na povezanost tri zadatka, pristupili smo problem koristeći velike predobučene modele transformera i učenje multizadataka. Naši rezultati ukazuju na to da učenje višezadataka postiže učenje iznad učenja više od zajedničkog jedinstvenog pristupa učenja zadataka u svim tri zadataka. Predajemo naše najbolje sustave GermEval-2021 pod tim imenom WLV-RIT.', 'bg': 'Настоящата статия разглежда идентифицирането на токсични, ангажиращи и фактически коментари в социалните медии. Използвахме набора от данни, предоставен от организаторите на споделената задача съдържаща над 3000 ръчно анотирани коментара във Фейсбук на немски език. Като се има предвид свързаността на трите задачи, подходихме към проблема с помощта на големи предварително обучени трансформаторни модели и многозадачно обучение. Нашите резултати показват, че многозадачното обучение постига по-добра производителност от по-често срещания подход за обучение на една задача и при трите задачи. Предоставяме най-добрите си системи на ГермЕвал-2021 под името на екипа.', 'de': 'Dieser Beitrag befasst sich mit der Identifizierung giftiger, ansprechender und faktenbezogener Kommentare in sozialen Medien. Wir nutzten den von den Organisatoren der geteilten Aufgabe GermEval2021 zur Verfügung gestellten Datensatz mit über 3.000 manuell kommentierten Facebook-Kommentaren in deutscher Sprache. Angesichts der Zusammenhänge der drei Aufgaben näherten wir uns dem Problem mit großen vortrainierten Transformatormodellen und Multitask Learning. Unsere Ergebnisse deuten darauf hin, dass Multitask-Lernen in allen drei Aufgaben eine Leistung erreicht, die dem allgemeineren Einzeltask-Lernansatz überlegen ist. Wir reichen unsere besten Systeme bei GermEval-2021 unter dem Teamnamen WLV-RIT ein.', 'id': 'Kertas ini mengarahkan identifikasi dari komentar racun, menarik, dan fakta-klaim pada media sosial. We used the dataset made available by the organizers of the GermEval2021 shared task containing over 3,000 manually annotated Facebook comments in German.  Mengingat hubungan dari tiga tugas, kami mendekati masalah dengan menggunakan model transformer besar yang terlatih dan belajar multitugas. Hasil kami menunjukkan bahwa belajar multitask mencapai prestasi yang lebih tinggi dari pendekatan belajar tugas tunggal yang lebih umum dalam tiga tugas. Kami mengirim sistem terbaik kami ke GermEval-2021 di bawah nama tim WLV-RIT.', 'fa': 'این کاغذ مشخص شناسایی مسموم، مشارکت و ادعای حقیقت در رسانه\u200cهای اجتماعی است. ما از مجموعه\u200cهای داده\u200cها که توسط سازمان\u200cکنندگان کاری GermEval2021 در دسترسی داده شده\u200cایم، استفاده کردیم که بیش از ۳۰۰۰ توضیح\u200cهای فیسبوک را در آلمان به دستگیر داده\u200cایم. با توجه به رابطه\u200cای از سه کار، با استفاده از مدل\u200cهای تغییر\u200cپذیر پیش آموزش و یادگیری چندین کار به مشکل نزدیک شدیم. نتیجه\u200cهای ما نشان می\u200cدهند که یادگیری بسیاری از کارهای زیادی بیشتر از روش یادگیری یک کار در تمام سه کار می\u200cرسد. ما بهترین سیستم\u200cهامون رو به GermEval-2021 تحت اسم تیم WLV-RIT می\u200cفرستیم.', 'ko': '본고는 소셜 미디어에 독이 있고 흥미진진하며 사실을 주장하는 평론의 식별을 논의했다.GermEval2021 공유 임무 수행자가 제공한 데이터 세트에는 독일어로 수동으로 표시된 페이스북 리뷰 3천여개가 포함됐다.이 세 가지 임무 간의 관련성을 고려하여 우리는 미리 훈련된 대형 변압기 모형과 다중 임무 학습을 이용하여 이 문제를 해결한다.우리의 연구 결과에 의하면 모든 세 가지 임무 중에서 다중 임무 학습의 표현은 더욱 흔히 볼 수 있는 단일 임무 학습 방법보다 우수하다는 것을 알 수 있다.GermEval-21에 WLV-RIT 팀의 이름으로 최고의 시스템을 제출했습니다.', 'sw': 'Gazeti hili linaelezea utambulisho wa sumu, kuhusisha na maoni yanayodai ukweli kwenye mitandao ya kijamii. Tulitumia taarifa zilizotolewa na waandaaji wa jukumu la GermEval2021 ambalo lilijumuisha zaidi ya 3,000 zilizotoa maoni ya Facebook kwa mkono nchini Ujerumani. Kuzingatia uhusiano wa kazi hizo tatu, tulikaribia tatizo kwa kutumia mifano makubwa ya mabadiliko ya awali na kujifunza kwa mambo mengi. Matokeo yetu yanaonyesha kuwa mafunzo mengi yanafanikiwa zaidi ya utendaji wa kazi moja kwa moja katika kazi tatu zote. Tunaitumia mifumo yetu bora zaidi kwa GermEval-2021 chini ya timu inayoitwa WLV-RIT.', 'tr': 'Bu kagyz sosyal medýýatlar hakynda toksik, gaýşartýan we hakykatdanam sözlerini tanyşdyrýar. Biz GermEval2021-iň GermEval2021-iň düzenleyicileriniň meňzeşlikleri üçin 3,000 üstden ýakyn Facebookyň komehlerini alman bilen paýlaşdyk. Üç zadyň aýratynlygyna düşünýän bolsa, biz uly öňünden öňünden täsirli transformer modellerini we multitask öwrenmesini ulanyp meselene çözdik. Biziň netijelerimiz köp zady öwrenmek üç zadyň hemme üç zadynda esasy zady öwrenmek üçin üstünlik gazandyrýar. Biz iň gowy sistemamyzy GermEval-2021-e WLV-RIT toparynyň adynda goýýarys.', 'af': 'Hierdie papier adreseer die identifikasie van toksiske, aansamende en feit-aankommentaar op sosiale media. Ons het die datastel gebruik wat beskikbaar gemaak is deur die organiseerders van die GermEval2021 deel taak wat meer 3,000 hand aanmerk Facebook kommentaar in Duits bevat. Omdat ons die verpligtigheid van die drie taak aangekom het, het ons die probleem aangekom met die gebruik van groot voorafgeleerde transformeermodele en multitaak leer. Ons resultate wys dat multitaak leer uitvoerder is superior aan die meer gemeenskaplike enkele taak leer toegang in alle drie taak. Ons stuur ons beste stelsels aan GermEval-2021 onder die span naam WLV-RIT.', 'am': 'ይህም ገጽ ማኅበራዊ ሚዲያ ላይ የጥቁር፣ እና አካባቢ እና የውይይት ማወያየትን የሚያሳውቃት ነው፡፡ የGermEval2021 ተካሄደው አካባቢዎች የፌስቡክ ትርጉም በጀርመን 3,000 በላይ የተጠቃሚ የፌስቡክ አስተያየት እየተገኘውን የዳታ ሳተር ተጠቃሚ ነበር፡፡ የሦስቱ ስራ ግንኙነት በተመለከቱ ጊዜ፣ ብዙ ቀድሞ ተማሪ እና ብዙ ልዩ ትምህርት በመጠቀም ወደ ችግር ደረስን፡፡ ፍሬዎቻችን በሦስት ስራ ሁሉ ላይ ከሁሉም አብዛኛዎቹ ትምህርት ትምህርት ትምህርት የሚሻለውን ትምህርት ማድረግ የሚያሳየው ነው፡፡ ከቡድን በታች WLV-RIT እናስገዛለን፡፡', 'az': "Bu kağıt sosyal media barəsində zehirli, işarə salmaq və həqiqəti təsdiqləyən şəkillərin kimliğini təsdiqləyir. Biz GermEval2021'nin düzəltənçilərinin müəyyən edilmiş verilən qurğunu Almanca ilə 3.000-dən artıq Facebook şəkilləri barəsində istifadə etdik. Üç işin bağlılığını düşünürək, böyük əvvəlcə təhsil edilmiş transformer modellərini və çox işin öyrənməsini vasitəsilə problem ə yaxınlaşdıq. Bizim sonuçlarımız çoxlu işin öyrənməsi üç işin ən orta işin öyrənməsi tərəfindən daha üstün performansını göstərir. Biz ən yaxşı sistemimizi VLV-RIT adlı ekibi ilə GermEval-2021-ə göndəririk.", 'bn': 'এই পত্রিকা সামাজিক প্রচার মাধ্যমে ব্যস্ত, যোগাযোগ এবং সত্যিকারের ব্যাপারে মন্তব্যের পরিচয় চিহ্নিত করেছে। আমরা জার্মানে ৩,০০০ বেশী ফেসবুক মন্তব্য প্রকাশ করেছিলাম জেরম ইভাল২০১২ এর সংগঠকদের দ্বারা যে ডাটাসেট ব্যবহার করেছিল, তা ব্যবহা এই তিনটি কাজের সম্পর্ক বিবেচনা করে আমরা বিশাল প্রশিক্ষিত পরিবর্তন মডেল ব্যবহার করে সমস্যার কাছে এসেছিলাম এবং মাল্টিটিশিক্ষা শিক আমাদের ফলাফল দেখাচ্ছে যে মাল্টিউটিশিক্ষা শিক্ষা শিক্ষা প্রকাশ করে তিনটি কাজের মধ্যে সবচেয়ে সাধারণ এক কাজ শিক্ষা  আমরা আমাদের সবচেয়ে ভালো সিস্টেম গের্মভাল-২০২১ টিমের নাম WLV-RIT এর অধীনে প্রদান করি।', 'bs': 'Ovaj papir se obraća na identifikaciju toksičnih, angažovanih i činjeničnih komentara o društvenim medijima. Koristili smo komplet podataka koji su dostupni organizatori GermEval2021 zajedničkog zadatka sadržavali preko 3.000 manuelnih komentara na Facebooku na njemačkom. S obzirom na povezanost tri zadatka, pristupili smo problem koristeći velike predobučene modele transformera i učenje multizadataka. Naši rezultati ukazuju na to da učenje multizadataka postiže učenje iznad učenja više od zajedničkog jedinstvenog pristupa učenja zadataka u svim tri zadataka. Predajemo najbolje sisteme GermEval-2021 pod tim imenom WLV-RIT.', 'ca': "Aquest article aborda l'identificació de comentaris tòxics, atractius i factuals als mitjans socials. Vam utilitzar el conjunt de dades que els organitzadors del GermEval2021 compartien tasca que conté més de 3.000 comentaris de Facebook anotats manualment en alemany. Tenint en compte la relació de les tres tasques, vam abordar el problema utilitzant grans models de transformador pré-entrenats i aprenentatge multitasca. Els nostres resultats indican que l'aprenentatge multitasca aconsegueix un rendiment superior a l'enfocament d'aprenentatge únic de les tres tasques. Enviem els nostres millors sistemes a GermEval-2021 sota el nom d'equip WLV-RIT.", 'cs': 'Tento článek se zabývá identifikací toxických, poutavých a faktických komentářů na sociálních médiích. Použili jsme datovou sadu zpřístupněnou organizátory sdíleného úkolu GermEval2021 obsahující více než 3.000 ručně anotované Facebook komentáře v němčině. Vzhledem k souvislosti těchto tří úkolů jsme k problému přistupovali pomocí velkých předškolených transformátorových modelů a multitasking learningu. Naše výsledky ukazují, že víceúlohové učení dosahuje výkonu lepšího než běžnější přístup k učení jednotlivých úkolů ve všech třech úkolech. Naše nejlepší systémy předkládáme GermEval-2021 pod týmovým názvem WLV-RIT.', 'et': 'Käesolevas dokumendis käsitletakse toksiliste, kaasahaaravate ja fakte väidetavate kommentaaride tuvastamist sotsiaalmeedias. Kasutasime GermEval2021 jagatud ülesande korraldajate poolt kättesaadavaks tehtud andmekogumit, mis sisaldas üle 3000 käsitsi märgitud Facebooki kommentaari saksa keeles. Arvestades kolme ülesande seotust, lähenesime probleemile suurte eelkoolitud transformaatormudelite ja multiülesandeõppe abil. Meie tulemused näitavad, et mitme ülesandega õppimine saavutab kõigis kolmes ülesandes parema tulemuse kui tavalisem ühe ülesandega õppimine. Me esitame oma parimad süsteemid GermEval-2021 meeskonna nime WLV-RIT all.', 'hy': 'Այս թղթին դիտարկում է թունավոր, հետաքրքիր և փաստեր պահանջող մեկնաբանություններ սոցիալական լրատվամիջոցների մասին: Մենք օգտագործեցինք տվյալների համակարգը, որը հասանելի էր Գերմ Ավալ 2021 կազմակերպողների կողմից, ընդհանուր առաջադրանքը, որը պարունակում էր ավելի քան 3000 ձեռքով գրված Ֆեյսբուքի մեկնաբանություններ գերմաներեն լեզվով: Եթե հաշվի առնենք երեք խնդիրների կապը, մենք մոտեցանք խնդիրը օգտագործելով մեծ նախապատրաստված վերափոխողների մոդելներ և բազմախնդիրներ սովորելով: Մեր արդյունքները ցույց են տալիս, որ բազմախնդիրների ուսումնասիրությունը հասնում է առավել լավ արդյունք, քան առավել ընդհանուր խնդիրների ուսումնասիրությունը բոլոր երեք խնդիրներում: We submit our best systems to GermEval-2021 under the team name WLV-RIT.', 'fi': 'Tässä artikkelissa käsitellään myrkyllisten, mukaansatempaavien ja faktoja esittävien kommenttien tunnistamista sosiaalisessa mediassa. Käytimme GermEval2021-jaetun tehtävän järjestäjien käyttöön antamaa aineistoa, joka sisälsi yli 3 000 manuaalisesti merkittyä Facebook-kommenttia saksaksi. Kun otetaan huomioon näiden kolmen tehtävän yhteys, lähestyimme ongelmaa käyttämällä isoja esikoulutettuja muuntajamalleja ja monitehtäväoppimista. Tuloksemme osoittavat, että monitehtäväoppimisella saavutetaan parempi suorituskyky kuin yleisemmällä yksittäisellä tehtävällä oppimisella kaikissa kolmessa tehtävässä. Toimitamme parhaat järjestelmämme GermEval-2021:een tiiminimellä WLV-RIT.', 'sq': 'Ky dokument trajton identifikimin e komenteve toksike, të angazhuese dhe të deklarueshme të fakteve mbi mediat sociale. Ne përdorëm grupin e të dhënave të bërë të disponueshme nga organizatorët e GermEval2021 të detyrës së përbashkët që përmban mbi 3,000 komente të anotuara manualisht në Facebook në gjermani. Duke konsideruar lidhjen e tre detyrave, ne u afruam problemit duke përdorur modele të mëdha të transformuesve të stërvitur para-stërvitur dhe mësimin e shumëdetyrave. Rezultatet tona tregojnë se mësimi i shumëdetyrave arrin performancë më të lartë se metoda më e përbashkët e mësimit të detyrave të vetme në të tre detyrat. We submit our best systems to GermEval-2021 under the team name WLV-RIT.', 'jv': 'Gambar iki dadi nggambar tok, nggambar, lan nambah-nambah kang Komentar anyar tentang karo media sotiki. Awak dhéwé ngéwangi dataset nggawe ngubah akeh negoro-negoro GemEscapel2020 1 sing dikarolan terus 3.000 sing manut kanggo nyelarakno Komentar Google neng aleman. Ingat kalagayaan kanggo kalagayaan karo mulalah sanggungu telu operasi, awake nambah ngono perbleman sing gawe ngubah model sing tolaran bantuan karo akeh multitask. Rejaling kita ngomong ngerti, multitask ömrung pengguna supoyo nggawe ngerti apakno sing beraksi maneh lan ning telu tasks. Awak dhéwé ngeremusi sistem sing luwih dumadhi kanggo Gemebal-2020 sak nganggo pernik WLV-RIT.', 'ha': "Wannan takardan na addu'a gane na mataki, kuma yana haɗa da mataimaki a kan mitandata jamii. Mun yi amfani da dataset wanda aka samar da shi na organizers of the Germevaal2021 mai rabo aikin da ke ƙunsa da over 3,000 na da hannayen da aka sanar da shi a Jarman. Aka kula da masu husũma na aikin waɗannan uku, muka sami matabbata a cikin misalin mu yi amfani da misãlai masu motsi masu motsi mai kawaici da sanar da masu multi-aska. MatamayinMu na nũna cewa, learning masu mulki yana sãmun mafiya mafiya mafiya aikin da aka sani a cikin dukkan aikin aiki uku. Munã sakar da mafiya kyauta ga Germeval-2021 ƙarƙashin jama'a da sunan WLV-RT.", 'sk': 'Ta prispevek obravnava identifikacijo strupenih, privlačnih in dejstvenih komentarjev na družbenih omrežjih. Uporabili smo nabor podatkov, ki so ga na voljo organizatorji skupne naloge GermEval2021, vsebuje več kot 3.000 ročno označenih Facebook komentarjev v nemščini. Glede na povezanost treh nalog smo problemu pristopili z uporabo velikih vnaprej usposobljenih transformatorskih modelov in večopravilnega učenja. Naši rezultati kažejo, da večopravilno učenje doseže boljšo zmogljivost od bolj običajnega pristopa učenja posameznih nalog pri vseh treh nalogah. Naše najboljše sisteme predložimo v GermEval-2021 pod imenom ekipe WLV-RIT.', 'he': 'העיתון הזה מתייחס לזיהוי ההערות הרעילות, מעניינות ומטענות עובדות על תקשורת חברתית. We used the dataset made available by the organizers of the GermEval2021 shared task containing over 3,000 manually annotated Facebook comments in German.  בהתחשב בקשר של שלושת המשימות, הגענו לבעיה באמצעות דוגמנים גדולים של משתנים מאומנים מראש וללמד משימות רבות. התוצאות שלנו מצביעות שלמדת משימות רבות משיגה ביצועים טובים יותר על גישת לימוד משימות אחת יותר בשלושת המשימות. אנחנו שולחים את המערכות הטובות ביותר שלנו לגרמEval-2021 תחת שם הקבוצה WLV-RIT.', 'bo': 'ཤོག་བྱང་འདིས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཐོག་དང་མཉམ་དུ་གཏོང་བའི་གསལ་བཤད་རྟོན་བྱེད་ཀྱི་ཡོད། ང་ཚོས་GermEval2021 ཡི་དོན་ཚན་གྱི་ལས་འགུལ་སྐྱོད་པ་ལ་སྤྱོད་པའི་གནད་སྡུད་ཚན་བཙུགས་ཡོད་པ་དེ་ཉེན་ལ་རང་ཉིད་ལ་ངོས་ཐོག བྱ་འགུལ་གསུམ་གྱི་ལེགས་སྐྱེད་ཚད་ལ་བསམ་བློ་བཏང་པ་ཡིན་ན། ང་ཚོས་བློ་གཏོང་གི་སྔོན་གྲངས་སྒྲིག་འཛུགས་པའི་དཔེ་གཞི་རྩོལ ང་ཚོའི་གྲུབ་འབྲས་བ་དེ་མང་ལས་སྡུད་ལ་སྐྱོན་བརྗོད་པར་མཐུན་རྐྱེན་ཚད་མང་ཤོས་ཏེ། ང་ཚོས་དབང་གི་མིང་WLV-RIT་ནང་དུ་རང་གི་མ་ལག་ཆེ་ཤོས་ཡོད་པ་ལས་(GermEval-2021)ལ་མཇུག་བསྡད་པ་ཡིན།'}
{'en': 'TUW-Inf at GermEval2021 : Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments', 'ar': 'TUW-Inf في GermEval2021: الطرق المستندة إلى القواعد والمختلطة لاكتشاف التعليقات السامة والتفاعلية والمطالبة بالحقائق', 'pt': 'TUW-Inf em GermEval2021: Métodos híbridos e baseados em regras para detectar comentários tóxicos, envolventes e de alegação de fatos', 'fr': 'TUW-Inf à Germeval2021\xa0: méthodes hybrides et basées sur des règles pour détecter les commentaires toxiques, engageants et factuels', 'ja': 'TUW - Inf at GermEval 2021 ：有毒性、魅力、および事実を主張するコメントを検出するためのルールベースおよびハイブリッド方法', 'hi': 'GermEval2021 पर TUW-Inf: विषाक्त, आकर्षक, और तथ्य-दावा टिप्पणियों का पता लगाने के लिए नियम-आधारित और हाइब्रिड तरीके', 'es': 'TUW-inf en GermeVal2021: métodos híbridos y basados en reglas para detectar comentarios tóxicos, atractivos y de afirmación de hechos', 'ga': 'TUW-Inf ag GermEval2021: Modhanna Riail-bhunaithe agus Hibrideacha chun Tuairimí Tocsaineacha, Rannpháirteacha agus Éilimh Fíricí a Bhrath', 'zh': 'GermEval2021上TUW-Inf:检有毒,引人入胜事实声明论之混法也', 'ru': 'TUW-Inf на GermEval2021: основанные на правилах и гибридные методы для обнаружения токсичных, вовлекающих и фактологических комментариев', 'hu': 'TUW-Inf a GermEval2021-en: Szab찼lyalap첬 챕s hibrid m처dszerek a m챕rgez흷, 챕rintett 챕s t챕ny찼ll챠t처 megjegyz챕sek kimutat찼s찼ra', 'el': 'Το ΤΕΕ-Ινφ στο ΓκέρμΕal2021: Κανόνες-βασισμένες και υβριδικές μέθοδοι ανίχνευσης τοξικών, εμπλεκόμενων και ισχυριστικών γεγονότων Σχόλια', 'kk': 'TUW- Inf at GermEval2021: Toxic, Engaging, and Fact- Claiming Comments for Detecting Rule-based and Hybrid Methods', 'it': 'TUW-Inf a GermEval2021: Metodi basati su regole e ibridi per rilevare tossicità, coinvolgimento e rivendicazione dei fatti Commenti', 'lt': 'TUW-Inf GermEval2021: taisyklėmis pagrįsti ir hibridiniai toksiškumo, įtraukimo ir faktų ieškinio nustatymo metodai', 'ka': 'TUW-Inf at GermEval2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging and Fact-Claiming Comments', 'mk': 'TUW-Inf на GermEval2021: Правилно-базирани и хибридни методи за детектирање токсични, ангажирани и фактични коментари', 'ms': 'TUW-Inf di GermEval2021: Kaedah berdasarkan peraturan dan Hybrid untuk mengesan Komen Toksik, Bergabung, dan Menaklumkan Fakta', 'mt': 'TUW-Inf f’GermEval2021: Metodi bbażati fuq ir-regoli u ibridi għad-Detezzjoni ta’ Kummenti Tossiċi, ta’ Engagement u ta’ Talbiet ta’ Fatti', 'ml': 'ഗെര്\u200dമെവാല്\u200d2021-ലെ ടുവി- ഇന്\u200dഫ്: ടോക്സിക്ക്, എഞ്ചിങ്ങിങ്ങ്, ഫാക്റ്റ് ക്ലാമിങ്ങ് അഭിപ്രായങ്ങള്\u200d', 'mn': 'GermEval2021 оны TUW-Inf: Хогийн, хөдөлгөөн, үнэндээ нэмэгдүүлэх загваруудын үндсэн, гибрид арга загварууд', 'pl': 'TUW-Inf w GermEval2021: Metody wykrywania toksycznych, angażujących i faktów oparte na regułach i hybrydowych', 'ro': 'TUW-Inf la GermEval2021: Metode bazate pe reguli și hibride pentru detectarea toxicității, implicarea și afirmarea faptelor comentarii', 'so': 'TUW-Inf at GermEval2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments', 'sv': 'TUW-Inf på GermEval2021: Regelbaserade och hybridmetoder för att upptäcka toxiska, engagerande och faktaupplicerande kommentarer', 'ta': 'ஜெர்ம்Eval2021 ல் TUW- Inf: Toxic, Engaging, and Fact- Claiming Comments', 'sr': 'TUW-Inf na GermEval2021: Pravilne i hibridne metode za otkrivanje toksičnih, inženjerskih i faktualnih komentara', 'si': 'TUW-Inf at Germeval2021: Rule-based and hybroid ways for Detection Toxic, Engage, and Factor-Claaming Comment', 'ur': 'جرمEval2021 میں TUW-Inf: توکسیکسی، انجینگ، اور حقیقت-کلمینگ کی تعلیمات کے لئے قانون بنیاد اور ہیبراڈ طریقے', 'no': 'TUW-Inf på GermEval2021: Regelbasert og hybridmetodar for oppdaging av toksisk, sprøytebruk og faktiskklassifisering av kommentarar', 'uz': 'GermEval2021- da TUW- Inf: Toksisini aniqlash uchun qoidalar va Hybrid usullari', 'vi': 'Điều U.W-Inf ở GermEvul2021: Quy định và Dùng người giám sát độc tố, xung đột và khai thác dữ liệu', 'bg': 'ТУУ-Инф на базирани на правила и хибридни методи за откриване на токсични, ангажиращи и твърдящи факти коментари', 'nl': 'TUW-Inf op GermEval2021: Regelgebaseerde en hybride methoden voor het detecteren van giftige, aangrijpende en feitenclaimende reacties', 'da': 'TUW-Inf på GermEval2021: Regelbaserede og hybride metoder til påvisning af giftige, engagerende og fakta-påstandende kommentarer', 'hr': 'TUW-Inf na GermEval2021: Pravilna i hibridna metoda za otkrivanje toksičnih, inženjerskih i učinkovitih komentara', 'de': 'TUW-Inf bei GermEval2021: Regelbasierte und hybride Methoden zur Detektion von Giftstoffen, Engaging und Fact Claiming Kommentare', 'ko': 'GermEval 2021의 TUW Inf: 독이 있고 매력적이며 사실을 주장하는 의견을 측정하기 위한 규칙 기반 혼합 방법', 'id': 'TUW-Inf di GermEval2021: Metode berdasarkan peraturan dan Hybrid untuk mendeteksi Komentar Toksik, Menyerangan, dan Penyakit Fakta', 'fa': 'TUW-Inf at GermEval2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging and Fact-Claiming Comments', 'sw': 'TUW-Inf katika GermEval2021: Utawala wa sheria na Hybrid kwa ajili ya Kutambua Toxico, Uingereza, na Maoni yanayohusu', 'tr': 'TUW-Inf at GermEval2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments', 'af': 'TUW-Inf by GermEval2021: Reël-gebaseerde en Hybrid-metodes vir ontdekking van toksikies, inrigtings en fakt-klaimering kommentaar', 'az': 'TUW-Inf at GermEval2021: Toksik, Engaging və Fact-Claiming Comments Determing Rule-based and Hybrid Methods', 'sq': 'TUW-Inf në GermEval2021: Metoda bazuar në rregulla dhe hibrida për zbulimin e komenteve toksike, të angazhimit dhe të pretendimit të fakteve', 'hy': 'Գերմե-Ավալ 2021-ի TEW-Ինֆ-ն. Տոքսիկ, ներգրավված և փաստեր հայտնաբերող մեկնաբանություններ հայտնաբերելու օրենքների և հիբրիդ մեթոդներ', 'am': 'TUW-Inf at GermEval2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging and Fact-Claiming Comments', 'cs': 'TUW-Inf na GermEval2021: Pravidla založené a hybridní metody pro detekci toxických, angažujících a faktových tvrzení Komentáře', 'bs': 'TUW-Inf na GermEval2021: Pravilne i hibridne metode za otkrivanje toksičnih, inženjerskih i činjeničnih komentara', 'bn': 'গের্ম ইভাল২০১২-এর টিউব-ইনফ: টোক্সিকো, ইঞ্জিঙ্গিং এবং ফ্যাক্ট-ক্লামিং মন্তব্যের জন্য নিয়ম ভিত্তিক এবং হাইব্রিড মাধ্যম', 'et': 'TUW-Inf GermEval2021: reeglipõhised ja hübriidsed meetodid toksiliste, kaasamise ja faktide väidemise avastamiseks', 'ca': "TUW-Inf a GermEval2021: Métodes basats en regles i híbrids per detectar comentaris tòxics, d'involucració i de reclamació de fets", 'fi': 'TUW-Inf GermEval2021: sääntöpohjaiset ja hybridiset menetelmät myrkyllisten, osallistavien ja faktojen toteamiseksi', 'jv': 'paper size', 'ha': 'TUW-Inf at Germevaal2021: Rule-based and Hybri Method for Finding Tox, Engagiing, and Fact-Claimiing Commons', 'sk': 'TUW-Inf na GermEval2021: Pravila temelječe in hibridne metode za odkrivanje strupenih, vključevanje in trditev dejstev', 'bo': 'TUW-Inf at GermEval2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments', 'he': 'TUW-Inf בגרמניה'}
{'en': 'This paper describes our methods submitted for the GermEval 2021 shared task on identifying toxic, engaging and fact-claiming comments in social media texts (Risch et al., 2021). We explore simple strategies for semi-automatic generation of rule-based systems with high ', 'ar': 'تصف هذه الورقة طرقنا المقدمة لمهمة GermEval 2021 المشتركة بشأن تحديد التعليقات السامة ، والمشاركة ، وتلك التي تدعي الحقائق في نصوص وسائل التواصل الاجتماعي (Risch et al. ، 2021). نحن نستكشف استراتيجيات بسيطة للإنشاء شبه التلقائي للأنظمة المستندة إلى القواعد بدقة عالية واسترجاع منخفض ، ونستخدمها لتحقيق تحسينات عامة طفيفة على المصنف القياسي القائم على BERT.', 'fr': "Cet article décrit les méthodes que nous avons soumises pour la tâche partagée GermEval 2021 sur l'identification des commentaires toxiques, engageants et factuels dans les textes de médias sociaux (Risch et al., 2021). Nous explorons des stratégies simples pour la génération semi-automatique de systèmes basés sur des règles avec une haute précision et un faible rappel, et nous les utilisons pour obtenir de légères améliorations globales par rapport à un classificateur basé sur BERT standard.", 'pt': 'Este artigo descreve nossos métodos enviados para a tarefa compartilhada GermEval 2021 sobre a identificação de comentários tóxicos, envolventes e de alegação de fatos em textos de mídia social (Risch et al., 2021). Exploramos estratégias simples para geração semiautomática de sistemas baseados em regras com alta precisão e baixo recall, e as usamos para obter pequenas melhorias gerais em relação a um classificador padrão baseado em BERT.', 'es': 'Este documento describe nuestros métodos presentados para la tarea compartida de GermEval 2021 sobre la identificación de comentarios tóxicos, atractivos y de afirmación de hechos en los textos de las redes sociales (Risch et al., 2021). Exploramos estrategias simples para la generación semiautomática de sistemas basados en reglas con alta precisión y baja recuperación, y las utilizamos para lograr ligeras mejoras generales con respecto a un clasificador estándar basado en BERT.', 'ja': '本稿では、ソーシャルメディアテキスト（ Risch et al., 2021 ）における有毒で魅力的で事実を主張するコメントを特定するためのGermEval 2021の共有タスクのために提出された方法について説明します。高精度かつ低リコールのルールベースシステムの半自動生成のためのシンプルな戦略を探求し、標準的なBERTベースの分類器よりも全体的にわずかな改善を達成するために使用します。', 'zh': '本文述GermEval 2021共同任务之法,其事涉识社交媒体文本有毒,引人入胜实论(Risch等,2021)。 求半自动之道,有高精度有率,以成 BERT 之微。', 'hi': 'यह पेपर सोशल मीडिया ग्रंथों (रिश एट अल। हम उच्च परिशुद्धता और कम याद के साथ नियम-आधारित प्रणालियों की अर्ध-स्वचालित पीढ़ी के लिए सरल रणनीतियों का पता लगाते हैं, और एक मानक BERT-आधारित क्लासिफायर पर मामूली समग्र सुधार प्राप्त करने के लिए उनका उपयोग करते हैं।', 'ru': 'В этой статье описываются наши методы, представленные для совместного задания GermEval 2021 по выявлению токсичных, привлекательных и фактологических комментариев в текстах социальных сетей (Risch et al., 2021). Мы изучаем простые стратегии полуавтоматической генерации основанных на правилах систем с высокой точностью и низким запаздыванием и используем их для достижения небольших общих улучшений по сравнению со стандартным классификатором на основе BERT.', 'ga': 'Déanann an páipéar seo cur síos ar na modhanna atá againn a cuireadh isteach le haghaidh tasc comhroinnte GermEval 2021 maidir le tráchtanna tocsaineacha, tarraingteacha agus éilitheacha fíricí a aithint i dtéacsanna meán sóisialta (Risch et al., 2021). Déanaimid iniúchadh ar straitéisí simplí maidir le giniúint leath-uathoibríoch de chórais riailbhunaithe le cruinneas ard agus le haisghairm íseal, agus úsáidimid iad chun feabhsuithe foriomlána beaga a bhaint amach thar aicmitheoir caighdeánach bunaithe ar BERT.', 'hu': 'Ez a tanulmány bemutatja a GermEval 2021 közös feladatához benyújtott módszereinket a mérgező, vonzó és tényállító megjegyzések azonosítására a közösségi média szövegekben (Risch et al., 2021). Egyszerű stratégiákat vizsgálunk a nagy pontossággal és alacsony visszahívással rendelkező szabályalapú rendszerek félautomata generálására, és ezeket használjuk arra, hogy egy szabványos BERT-alapú osztályozóval szemben enyhe általános javulást érjünk el.', 'el': 'Η παρούσα εργασία περιγράφει τις μεθόδους που υποβλήθηκαν για το κοινό έργο για τον εντοπισμό τοξικών, ελκυστικών και ισχυρών σχολίων στα κείμενα κοινωνικών μέσων (κ.α., 2021). Ερευνούμε απλές στρατηγικές για την ημιαυτόματη παραγωγή συστημάτων βασισμένων σε κανόνες με υψηλή ακρίβεια και χαμηλή ανάκληση, και τις χρησιμοποιούμε για να επιτύχουμε μικρές γενικές βελτιώσεις σε σχέση με έναν τυποποιημένο ταξινομητή βασισμένο σε BERT.', 'it': "Questo articolo descrive i nostri metodi presentati per il compito condiviso di GermEval 2021 sull'identificazione di commenti tossici, coinvolgenti e fattuali nei testi dei social media (Risch et al., 2021). Esploriamo strategie semplici per la generazione semi-automatica di sistemi basati su regole con alta precisione e basso richiamo, e le utilizziamo per ottenere lievi miglioramenti generali rispetto a un classificatore standard basato su BERT.", 'lt': 'Šiame dokumente aprašomi mūsų metodai, pateikti „GermEval 2021“ bendrai užduotims nustatyti toksines, įtraukias ir faktus pareikšiančias pastabas social in ės žiniasklaidos tekstuose (Risch et al., 2021 m.). We explore simple strategies for semi-automatic generation of rule-based systems with high precision and low recall, and use them to achieve slight overall improvements over a standard BERT-based classifier.', 'mk': 'Овој документ ги опишува нашите методи поднесени за GermEval 2021 заедничката задача за идентификување токсични, интересни и фактовни коментари во текстовите на социјалните медиуми (Risch et al., 2021). We explore simple strategies for semi-automatic generation of rule-based systems with high precision and low recall, and use them to achieve slight overall improvements over a standard BERT-based classifier.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ രീതികള്\u200d വിശദീകരിക്കുന്നു ജെര്\u200dമെവാല്\u200d 2021-ന് വേണ്ടി ചേര്\u200dത്തിരിക്കുന്ന പ്രവര്\u200dത്തനത്തിന് വേണ്ടി ഞങ്ങളുടെ രീതി നിയമപരമായ സിസ്റ്റങ്ങളുടെ സാമാതൃക തലമുറകള്\u200dക്കുള്ള എളുപ്പമായ പദ്ധതികള്\u200d ഞങ്ങള്\u200d പരിശോധിക്കുന്നു. അതിന്റെ ഉയര്\u200dന്ന പരിശോധനവും കുറഞ്ഞ ഓര്\u200dമ്മയ', 'kk': 'Бұл қағаз 2021 жылы GermEval бағытталған тапсырманың тәсілдерімізді (Risch et al., 2021). Біз жарты автоматты түрде ережелер негізделген жүйелерді қарапайым стратегияларды зерттеп, қарапайым дәл жақсы және төменгі еске салу арқылы, оларды стандартты BERT-негізделген классификациясының жалпы жақ', 'ms': 'Kertas ini menggambarkan kaedah kami yang dihantar untuk tugas berkongsi GermEval 2021 mengenai mengenali pengenalan komentar beracun, menarik dan mengklaim fakta dalam teks media sosial (Risch et al., 2021). Kami mengeksplorasi strategi sederhana untuk generasi setengah-automatik sistem berdasarkan peraturan dengan ketepatan tinggi dan pengingatan rendah, dan menggunakannya untuk mencapai peningkatan keseluruhan sedikit melalui klasifikasi berdasarkan BERT piawai.', 'mt': 'Dan id-dokument jiddeskrivi l-metodi tagħna ppreżentati għall-kompitu kondiviż GermEval 2021 dwar l-identifikazzjoni ta’ kummenti tossiċi, involuti u li jsostnu l-fatti fit-testi tal-midja soċjali (Risch et al., 2021). Aħna nesploraw strateġiji sempliċi għall-ġenerazzjoni semiawtomatika ta’ sistemi bbażati fuq ir-regoli bi preċiżjoni għolja u b’ġbir lura baxx, u nużawhom biex jinkiseb titjib ġenerali żgħir fuq klassifikatur standard ibbażat fuq BERT.', 'mn': 'Энэ цаасан нь Нийгмийн мэдээллийн хэвлэлийн текст (Risch et al., 2021) дээрх хохиромжтой, сонирхолтой, үнэндээ илэрхийлж буй загваруудыг тодорхойлдог арга загварыг GermEval 2021 онд тайлбарлаж байна. Бид энгийн төвөгтэй байгууллагын төвшин автоматик байгууллагын системийн энгийн стратегийг судалж, бага зэрэг тодорхойлолтой, бага зэрэг санамсаргүй байгууллагын тулд бага зэрэг сайжруулах хэрэгтэй.', 'no': 'Denne papiret beskriver metodane våre som er sendt til den delte oppgåva GermEval 2021 om å identifisera toksiske, engasjerande og faktiske kommentarar i sosiale media-tekstar (Risch et al., 2021). Vi undersøker enkle strategiar for halvautomatisk generering av regelbaserte systemer med høg presisjon og låg rekning, og bruker dei for å oppnå litt overalt forbedringar over ein standardsklassifiserer på BERT-basert.', 'ka': 'ეს დოკუმენტი აღწერს ჩვენი მეტები, რომლებიც ჯერმEval 2021 წლის გაყოფილი დავალებისთვის განსაზღვრება ტექსტის ტოქსიკური, დაკავშირებული და ფაქტიკური კომენტრები (Risch et al., 2021). ჩვენ განვიყვანეთ უხოლოდ სტრატიგური სტრატიგური განვითარებისთვის სტრატიგური განვითარებისთვის სტრატიგური განვითარებისთვის, რომელიც უფრო მარტივია და მარტივია დახმარებისთვის, და გამ', 'pl': 'Niniejszy artykuł opisuje nasze metody zgłoszone do wspólnego zadania GermEval 2021 dotyczące identyfikacji toksycznych, angażujących i twierdzących fakty komentarzy w tekstach mediów społecznościowych (Risch et al., 2021). Badamy proste strategie półautomatycznego generowania systemów opartych na regułach z wysoką precyzją i niską ilością odzyskiwania i wykorzystujemy je do osiągnięcia niewielkich ogólnych ulepszeń w porównaniu ze standardowym klasyfikatorem opartym na BERT.', 'sr': 'Ovaj papir opisuje naše metode podignute za zajednički zadatak GermEval 2021. godine o identifikaciji toksičnih, angažovanih i činjeničnih komentara u tekstima društvenih medija (Risch et al., 2021). Istražujemo jednostavne strategije za polu-automatsku generaciju sistema baziranih na pravilima sa visokom preciznošću i niskom sjećanjem, i koristimo ih kako bi postigli malo ukupnih poboljšanja na standardnom klasifikatoru na BERT-u.', 'si': 'මේ පැත්තේ අපේ විධානය විස්තර කරනවා ජර්ම් එව්ල් 2021 වෙනුවෙන් සාමාජික මාධ්\u200dයම පාළුවන් විශ්වාස කරලා තියෙන්නේ විශ්වාසික,  අපි සාමාන්\u200dය ව්\u200dයාපෘතිය පරීක්ෂණයක් පරීක්ෂණය කරනවා නීති පද්ධතියේ අධික ප්\u200dරමාණය සහ අඩුම ප්\u200dරමාණය සඳහා අඩුම ප්\u200dරමාණය සඳහා ඒවා ප්\u200d', 'ro': 'Această lucrare descrie metodele noastre depuse pentru sarcina partajată GermEval 2021 privind identificarea comentariilor toxice, angajatoare și afirmarea faptelor în textele rețelelor de socializare (Risch et al., 2021). Explorăm strategii simple pentru generarea semi-automată a sistemelor bazate pe reguli cu precizie ridicată și rechemare redusă și le folosim pentru a obține ușoare îmbunătățiri generale față de un clasificator standard bazat pe BERT.', 'ur': 'This paper describes our methods submitted for the GermEval 2021 shared task on identifying toxic, engaging and fact-claiming comments in social media texts (Risch et al., 2021). ہم نصف-اتوماٹیکی سیستموں کے لئے ساده استراتژیکوں کی تحقیق کرتے ہیں جو بالا دقیق اور کم یاد رکھتے ہیں، اور ان کو استعمال کرتے ہیں کہ ایک استارڈیٹ BERT-based classifier پر تھوڑا سامان اضافہ کریں.', 'sv': 'Denna uppsats beskriver våra metoder som lämnats in för GermEval 2021 delade uppgift att identifiera giftiga, engagerande och faktabaserade kommentarer i sociala medier texter (Risch et al., 2021). Vi utforskar enkla strategier för halvautomatisk generering av regelbaserade system med hög precision och låg återkallelse, och använder dem för att uppnå små övergripande förbättringar jämfört med en standardklassificering baserad på BERT.', 'so': 'This paper describes our methods submitted for the GermEval 2021 shared task on identifying toxic, engaging and fact-claiming comments in social media texts (Risch et al., 2021).  Waxaynu baaraynaa qoraalo fudud oo u sahlan dabiicadda nidaamka qaynuunka ah oo hoos u qoran, waxaana isticmaalaynaa si aan u gaadhno hagaajinta si yar oo ugu horumarinta fasalka standardka ah ee BERT.', 'ta': 'இந்த காகிதத்தை குறிப்பிடுகிறது ஜெர்ம்வெல் 2021 க்கான எங்கள் முறைகள் வழங்கப்பட்டுள்ளது பாதுகாப்பு, சமூக ஊடகங்கள் உரைகளில் உள்ள குறிப்புகள நாம் சுலபமான திட்டங்களை கண்டறிகிறோம் அதிக துல்லியமாக மற்றும் குறைந்த நினைவுடன் விதியாசமான அமைப்புகளின் பாதி தானாகவே உருவாக்கும் முறைகளை', 'uz': "Бу саҳифа, GermEval 2021 учун тўпланган усулларимизни кўрсатади, мамлакат медиа манфаатларида аниқлаш, ҳужжат мувофиқ манфаатлар (Risch et al, 2021). Biz oddiy strategiyalarni o'rganamiz, qoidalar asosida avtomatik avtomatik avtomatik avtomatik avtomatik avtomatik avtomatik foydalanamiz va juda qisqarli darajaga ega bo'lishi uchun ularni foydalanamiz.", 'vi': 'Tờ giấy này mô tả phương pháp được gửi đến cho nhiệm vụ chia sẻ GermEvl 2021 sẽ xác định các bình luận về độc hại, kích hoạt và thực tế trong văn bản truyền thông xã hội (Risch et al., 2021). Chúng tôi khám phá các chiến lược đơn giản cho việc chế tạo các hệ thống quy luật dựa theo độ chính xác cao và thu hồi thấp, và sử dụng chúng để đạt được những cải tiến nhẹ trên các phân loại gốc BERT tiêu chuẩn.', 'bg': 'Настоящата статия описва нашите методи, представени за споделената задача за идентифициране на токсични, ангажиращи и фактически коментари в текстове в социалните медии (Риш и др., 2021). Проучваме прости стратегии за полуавтоматично генериране на системи, базирани на правила с висока прецизност и ниско изземване, и ги използваме за постигане на леки цялостни подобрения спрямо стандартен класификатор.', 'da': 'Denne artikel beskriver vores metoder, der er indsendt til GermEval 2021 delte opgave med at identificere giftige, engagerende og faktahævdende kommentarer i tekster på sociale medier (Risch et al., 2021). Vi undersøger enkle strategier for semi-automatisk generering af regelbaserede systemer med høj præcision og lav tilbagekaldelse og bruger dem til at opnå små samlede forbedringer i forhold til en standard BERT-baseret klassificering.', 'hr': 'Ovaj papir opisuje naše metode podignute za zajednički zadatak GermEval 2021. godine o identifikaciji toksičnih, uključujućih i činjeničnih komentara u tekstima društvenih medija (Risch et al., 2021). Istražujemo jednostavne strategije za polu-automatsku generaciju sustava baziranih na pravilima sa visokom preciznošću i niskom sjećanjem, i koristimo ih kako bi postigli malo ukupnih poboljšanja na standardnom klasifikatoru na BERT-u.', 'nl': 'Dit artikel beschrijft onze methoden die zijn ingediend voor de gezamenlijke taak van GermEval 2021 om giftige, boeiende en feiten claimende opmerkingen in sociale media teksten te identificeren (Risch et al., 2021). We onderzoeken eenvoudige strategieën voor het semi-automatische genereren van regelgebaseerde systemen met hoge precisie en weinig terugroepactie, en gebruiken deze om lichte algemene verbeteringen te bereiken ten opzichte van een standaard BERT-classificator.', 'de': 'Diese Arbeit beschreibt unsere Methoden, die für die gemeinsame Aufgabe von GermEval 2021 eingereicht wurden, giftige, ansprechende und faktenbezogene Kommentare in Social-Media-Texten zu identifizieren (Risch et al., 2021). Wir erforschen einfache Strategien zur halbautomatischen Generierung regelbasierter Systeme mit hoher Präzision und geringem Rückruf und nutzen sie, um leichte Verbesserungen gegenüber einem Standard-BERT-basierten Klassifikator zu erzielen.', 'id': 'Kertas ini menjelaskan metode kami yang dikirim untuk GermEval 2021 tugas berbagi untuk mengidentifikasi komentar beracun, menarik dan mengklaim fakta dalam teks media sosial (Risch et al., 2021). Kami mengeksplorasi strategi sederhana untuk generasi semi-otomatis sistem berdasarkan aturan dengan presisi tinggi dan pengingatan rendah, dan menggunakannya untuk mencapai peningkatan keseluruhan sedikit atas klassifikasi berdasarkan BERT standar.', 'ko': '본고는 GermEval 2021 공유 임무에 대한 제출 방법을 설명한다. 이 임무는 소셜미디어 텍스트에 독이 있고 흥미진진하며 사실을 주장하는 평론(Risch 등, 2021년)을 식별하기 위한 것이다.우리는 반자동적으로 높은 정밀도와 낮은 리콜율을 생성하는 규칙 기반 시스템의 간단한 전략을 탐색하고 이를 사용하여 표준 버트 분류기 기반의 경미한 전체적인 개선을 실현했다.', 'fa': 'این کاغذ روش\u200cهای ما را برای کار مشترک GermEval 2021 در مورد شناسایی مشترک\u200cهای سمی، مشترک و حقیقت\u200cگیری در متن\u200cهای رسانه\u200cهای اجتماعی (Risch et al., 2021) توصیف می\u200cکند. ما استراتژی ساده برای نسل\u200cهای نیمه\u200cاتوماتیک سیستم\u200cهای قانونی با دقیق و یادآوری پایین استفاده می\u200cکنیم، و از آنها استفاده می\u200cکنیم تا به کمی توسعه\u200cهای عمومی روی یک گروه\u200cشناسی استاندارد BERT برسد.', 'sw': 'Gazeti hili linaelezea njia zetu zilizotolewa kwa ajili ya GermEval 2021 zinazoshiriki kazi ya kutambua sumu, kuhusisha na maoni yanayodai ukweli katika maandishi ya mitandao ya kijamii (Risch et al, 2021). Tunafanya mikakati rahisi kwa ajili ya kizazi cha mifumo yenye msingi wa utawala kwa kiwango kikubwa na kumbukumbu kidogo, na tunatumia ili kupata maboresho kidogo zaidi ya kiwango cha kawaida cha BERT.', 'tr': "Bu kagyz GermEval 2021-nji GermEval 2021-iň netijesinde toksik, suratly mediýalyň metinlerinde (Risch et al., 2021-nji ýylda) sahyp eden täzeliklerimizi tassyklaýar. Biz ýarym-awtomatik taýýarlanan düzgün sistemalary üçin ýokary derejesi we düşük hatyrlamak bilen basit stratejikleri keşfetýäris we olary BERT'yň standart klasifikatynda biraz ilerlemek üçin ullanýarys.", 'sq': 'Ky dokument përshkruan metodat tona të paraqitura për GermEval 2021 detyrën e përbashkët për identifikimin e komenteve toksike, të angazhueshme dhe të deklarueshme të fakteve në tekstet e medias sociale (Risch et al., 2021). Ne eksplorojmë strategji të thjeshta për gjenerimin gjysmë-automatik të sistemeve me bazë rregullash me preçizion të lartë dhe tërheqje të ulët dhe i përdorim për të arritur përmirësime të lehta të përgjithshme mbi një klasifikues standart me bazë në BERT.', 'af': "Hierdie papier beskrywe ons metodes wat vir die GermEval 2021 gedeelde taak voorgestuur is om toxiese, engang en feit-aanvaardige kommentaar te identifiseer in sosiale media tekste (Risch et al., 2021). Ons ondersoek eenvoudige strategies vir semi-automatiese generasie van reël-gebaseerde stelsels met hoë presisie en lae rekening, en gebruik hulle om klein algemene verbeteringe te bereik oor 'n standaard BERT-gebaseerde klassifiseerder.", 'am': 'ይህ ገጽ ለGermEval 2021 የተሰኘውን ሥርዓታችንን በማኅበራዊ ሚዲያ ጽሑፎች (Risch et al, 2021) በማረጋገጥ ጥቁር፣ እና የእውነትን አስተያየት በማኅበራዊ ሚዲያዎች ጽሑፎችን በመጠቀም እና አስተያየት የሚለውን ሥርዓት ይናገራል፡፡ የሥርዓት መሠረት በተመሳሳይ እና ትንሽ ማስታወስ የሆኑትን ቀላል ስርዓት እናፈልጋለን፡፡', 'hy': 'Այս թղթին նկարագրում է մեր մեթոդները, որոնք ներկայացվել են Գերմ Էվալ 2021 թվականին ընդհանուր խնդիրը թունավոր, ներգրավող և փաստեր հայտնելու համար սոցիալական լրատվամիջոցների տեքստերում (Ռիշ և այլն., 2021 թվականը): Մենք ուսումնասիրում ենք կանոններով հիմնված համակարգերի կիսաավտոմատիկ սերունդի պարզ ռազմավարությունները բարձր ճշգրիտությամբ և ցածր հիշեցումներով, և օգտագործում ենք դրանք ընդհանուր փոքր բարելավման համար ստանդարտ BER-ի հիմնված դասակարգչի', 'az': 'Bu kağıt 2021 GermEval üçün təklif edilmiş metodlarımızı sosyal media məktublarında (Risch et al., 2021) təsdiqləyici şəkilləri tanıtmaq haqqında paylaşır. Biz yarı-avtomatik qüvvətli sistem sistemlərini yüksək dəqiqliyyat və düşük yada salmaq üçün basit stratejikləri keşfetirik və onları standart BERT-ə dayanan klasifikatçı ilə küçük düzəltmək üçün istifadə edirik.', 'bn': 'এই পত্রিকাটি জেরমেভাল ২০২১-এর জন্য আমাদের পদ্ধতি প্রদান করা হয়েছে যাতে সামাজিক প্রচার মাধ্যমের টেক্সটে ব্যাক্সিক, বাস্তবতা চিহ্নিত এবং  We explore simple strategies for semi-automatic generation of rule-based systems with high precision and low recall, and use them to achieve slight overall improvements over a standard BERT-based classifier.', 'bs': 'Ovaj papir opisuje naše metode podignute za zajednički zadatak GermEval 2021. godine o identifikaciji toksičnih, uključujućih i činjeničnih komentara u tekstima društvenih medija (Risch et al., 2021). Istražujemo jednostavne strategije za polu-automatsku generaciju sustava baziranih na pravilima sa visokom preciznošću i niskom sjećanju, i koristimo ih kako bi postigli malo ukupnih poboljšanja na standardnom klasifikatoru na BERT-u.', 'ca': "Aquest paper descriu els nostres mètodes presentats per a GermEval 2021 en la tasca compartida d'identificar comentaris tòxics, atractius i factuals en textos dels mitjans socials (Risch et al., 2021). Exploram estratègies senzilles per a generar sistemes semiautomàtics basats en regles amb alta precisió i baixa recuperació, i les utilitzem per aconseguir una petita millora global sobre un classificador standard basat en BERT.", 'cs': 'Tento článek popisuje naše metody předložené pro sdílený úkol GermEval 2021 na identifikaci toxických, poutavých a faktově tvrdých komentářů v textech sociálních médií (Risch et al., 2021). Prozkoumáme jednoduché strategie pro poloautomatickou generaci systémů založených na pravidlech s vysokou přesností a nízkým stavem a používáme je k dosažení mírných celkových zlepšení oproti standardnímu klasifikátoru založenému na BERT.', 'et': 'Käesolevas dokumendis kirjeldatakse meie meetodeid, mis on esitatud GermEval 2021 jagatud ülesandeks toksiliste, kaasavate ja fakte väidetavate kommentaaride tuvastamiseks sotsiaalmeedia tekstides (Risch jt., 2021). Uurime lihtsaid strateegiaid reeglitel põhinevate süsteemide poolautomaatseks genereerimiseks väga täpse ja madala tagasivõtmisega ning kasutame neid, et saavutada standardse BERT-põhise klassifikaatoriga võrreldes kergeid üldisi parandusi.', 'fi': 'Tässä artikkelissa kuvataan GermEval 2021:n yhteiseen tehtävään lähetettyjä menetelmiä myrkyllisten, mukaansatempaavien ja faktoja väittävien kommenttien tunnistamiseksi sosiaalisen median teksteissä (Risch et al., 2021). Tutkimme yksinkertaisia strategioita sääntöpohjaisten järjestelmien puoliautomaattiseen tuottamiseen erittäin tarkasti ja alhaisella takaisinvedolla ja käytämme niitä saavuttaaksemme pieniä parannuksia tavalliseen BERT-luokitukseen verrattuna.', 'ha': "Wannan karatun yana bayyana hanyoyinmu wanda aka wajabta zuwa Germeval 2021 mai shirin aikin da aka nuna mataimaki, kuma yana haɗa da izni na gaskata cikin littafan mitanda na jamii (Rishh et al, 2021). Tuna ƙidãya masu sauƙi zuwa birnin na'urar-farat farat-farat na'urar-raye na'ura, kuma masu amfani da su dõmin ya sami ƙarami kodi a kan mai daidaita matsayin BERT.", 'sk': 'Ta prispevek opisuje naše metode, predložene za skupno nalogo GermEval 2021 o prepoznavanju strupenih, privlačnih in dejstvenih komentarjev v besedilih na družbenih omrežjih (Risch et al., 2021). Preučujemo preproste strategije za polavtomatsko proizvodnjo sistemov na podlagi pravil z visoko natančnostjo in nizkim odpoklicem ter jih uporabljamo za doseganje manjših splošnih izboljšav v primerjavi s standardnim klasifikatorjem na podlagi BERT.', 'he': 'העיתון הזה מתאר את השיטות שלנו שנשלחו עבור GermEval 2021 משימה משותפת על זיהוי תגובות רעילות, מעורבות ומטענות עובדות בטקסטים של התקשורת החברתית (Risch et al., 2021). אנו חוקרים אסטרטגיות פשוטות לדור חצי אוטומטי של מערכות מבוססות על חוקים עם מדויקה גבוהה ובחזרה נמוכה, ולהשתמש בהן כדי להשיג שיפורים כלליים קלים מעל מסגר סטנדרטי מבוסס על BERT.', 'jv': 'Perintah iki rambaran ngerngerwih manut sing nyimpen nggawe nggawe gerasun Geminval 2020 nggawe gerasun nggawe gerasun nggambar tok, nggambar nggawe Komentar mengko iso nggawe nggambar texts media sotiki (Rich et al, 2020). Awak dhéwé éntuk sistem sing sampeyan kanggo kelas-otomatik kanggo ngerasai sistem sing dadi supoyo barang kanggo awak dhéwé, lan ijdigo kuwi nggawe sistem sing bisa dianggap kanggo ngelarang supoyo akeh lan akeh banter', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་ཐབས་ལམ་ལ་བཤད་པ་དེ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་གྱི་ཚིག We explore simple strategies for semi-automatic generation of rule-based systems with high precision and low recall, and use them to achieve slight overall improvement over a standard BERT based classifier.'}
{'en': 'Data Science Kitchen at GermEval 2021 : A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'ar': 'مطبخ علوم البيانات في GermEval 2021: مجموعة مختارة رائعة من الميزات المنتقاة يدويًا ، يتم تسليمها طازجة من الفرن', 'fr': 'Data Science Kitchen au GermEval 2021\xa0: une sélection raffinée de caractéristiques sélectionnées à la main, livrées fraîchement sorties du four', 'es': 'Cocina de ciencia de datos en GermEval 2021: una excelente selección de características seleccionadas a mano, entregadas recién salidas del horno', 'pt': 'Cozinha de ciência de dados na GermEval 2021: uma excelente seleção de recursos escolhidos a dedo, entregues frescos do forno', 'ja': 'GermEval 2021のデータサイエンスキッチン：オーブンから新鮮に届ける、手作業で選んだ機能のファインセレクション', 'zh': 'GermEval 2021上数科学厨:精选功能,付以烤箱新', 'hi': 'GermEval 2021 में डेटा साइंस किचन: हाथ से चुनी गई सुविधाओं का एक अच्छा चयन, ओवन से ताजा वितरित', 'ru': 'Data Science Kitchen на выставке GermEval 2021: прекрасный выбор функций, подобранных вручную и доставленных свежими из духовки', 'ga': 'Cistin Eolaíocht Sonraí ag GermEval 2021: Rogha Mín de Ghnéithe Lámh-Roghnaithe, Seachadta Úr ón Oigheann', 'el': 'Κουζίνα Επιστήμης Δεδομένων στο Μια λεπτή επιλογή από χειροποίητα χαρακτηριστικά, που παραδίδονται φρέσκα από τον φούρνο', 'hu': 'Data Science Kitchen a GermEval 2021-ben: A kézzel válogatott funkciók finom választéka, frissen szállítva a sütőből', 'ka': 'დეტატური მეცნიერების კუფნი დერმEval 2021-ში: საკმაოდ მონიშნული ფუტურების მონიშნული არჩევა, საკმაოდ მონიშნული ფუტურები', 'it': 'Data Science Kitchen a GermEval 2021: una raffinata selezione di caratteristiche raccolte a mano, consegnate fresche dal forno', 'kk': '2021 жылы GermEval- де деректер ғылым кухнясы: Қол таңдалған мүмкіндіктерді жақсы таңдау', 'lt': 'Duomenų mokslinė virtuvė GermEval 2021 m.: Gerai pasirinktos rankomis pasirinktos savybės, pristatytos šviežios iš kiaušidžių', 'mk': 'Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'ms': 'Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'ml': 'ഗെര്\u200dമെവാല്\u200d 2021-ലെ ഡേറ്റാ ശാസ്ത്രശാസ്ത്ര കിച്ചന്\u200d: കൈ-തെരഞ്ഞെടുത്ത വിശിഷ്ടമുള്ള തെരഞ്ഞെടുക്കുക', 'mn': '2021 оны GermEval-ын өгөгдлийн шинжлэх ухааны газар: Гараа сонгогдсон чадваруудын сайн сонголт, Цэцэгээс сайн цэцэглэгдсэн', 'mt': 'Data Science Kitchen at GermEval 2021: A Fine Selection of Handpicked Features, Delivered Fresh from the Oven', 'no': 'Data vitenskapsvinkel på GermEval 2021: Eit fint utval av handvelgte funksjonar, Delivert frå Oven', 'sr': 'Kuhinja za znanje podataka u GermEval 2021: Dobar izbor izabranih karaktera, isporučen svježe od Ovine', 'ro': 'Bucătăria științifică a datelor la GermEval 2021: O selecție fină de caracteristici alese manual, livrate proaspăt din cuptor', 'pl': 'Data Science Kuchnia w GermEval 2021: Dobry wybór ręcznie dobranych cech, dostarczanych świeżo z piekarnika', 'si': 'දත්ත විද්\u200dයානය කිචෙන්', 'so': 'Qediya sayansi ee GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'ta': 'ஜெர்ம்வெல் 2021 ல் தகவல் அறிவியல் செக்: கையில் தேர்ந்தெடுக்கப்பட்ட பண்புகளின் நல்ல தேர்ந்தெடுப்பு, ஒவெனிலிருந்து மீட', 'sv': 'Data Science Kitchen på GermEval 2021: Ett fint urval av handplockade funktioner, levereras färskt från ugnen', 'ur': 'جرمیول 2021 میں ڈیٹا سائنس کیچین: ایک اچھا انتخاب ہاتھ پکڑے ہوئے فرصت، اوورن سے تازہ دفع کیا گیا', 'uz': 'Comment', 'vi': 'Data Science Kitchen ở GermEvl 2021: A fine selection of Hand-Picked Featurs, Soloned from the Oven', 'bg': 'Научна кухня за данни в фина селекция от ръчно подбрани функции, доставени прясно от фурната', 'hr': 'Kuhinja za znanje podataka u GermEval 2021. godine: Dobar izbor rukom izabranih karaktera, isporučena svježa od ovca', 'da': 'Data Science Kitchen på GermEval 2021: Et fint udvalg af håndplukkede funktioner, leveret frisk fra ovnen', 'de': 'Data Science Küche bei GermEval 2021: Eine feine Auswahl an handverlesenen Merkmalen, frisch aus dem Ofen geliefert', 'id': 'Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'nl': 'Data Science Kitchen bij GermEval 2021: Een fijne selectie van met de hand geplukte kenmerken, vers uit de oven geleverd', 'ko': 'GermEval 2021의 데이터 과학 주방: 정선한 기능, 신선한', 'fa': 'آشپزخانه دانش داده در GermEval 2021: انتخاب خوبی از ویژه\u200cهای دستی برگزیده شده، تازه\u200cای از Oven', 'af': "Data Wetenskappyk by GermEval 2021: 'n Fine Keuse van Hand-Gekies Funksies, Verlaai Fres van die Oven", 'tr': 'GermEval 2021-nji ýylda Data Science Kitchen: El-Saýlanan Ösümlikleriň Gowy Saýlaw, Ovandan Taze Saýlaw', 'sw': 'Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'hy': 'Գիտություն տվյալների խոհանոցը, ԳերմԵվալ 2021 թվականին. Ձեռքով ընտրված առանձնահատկությունների գեղեցիկ ընտրությունը, Հաշվից նոր ներկայացված', 'az': "GermEval 2021-də Data Science Kitchen: Əl seçilmiş Özelliklərin İyi Seçimi, Oven'dən Təze Delivered", 'sq': 'Kuzhinë e Shkencës së të dhënave në GermEval 2021: Një zgjedhje e mirë e karakteristikave të zgjedhura me dorë, e dërguar të freskët nga Oven', 'am': 'የዳታ የሳይንስ ደረጃዎች በGermEval 2021: A fine selection of Hand-Picked Features, Delivered Fresh from the Oven', 'bn': 'গের্মেভাল ২০২১-এ ডাটা বিজ্ঞান কিচেন: হাত-নির্বাচিত বৈশিষ্ট্যের একটি ভালো নির্বাচন, অভেন থেকে ফ্রিশ ফ্রেস', 'bs': 'Kuhinja za znanje podataka u GermEval 2021: Dobar izbor izabranih karaktera, isporučena svježe od Ovine', 'ca': 'Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'cs': 'Data Science Kuchyně u GermEval 2021: Jemný výběr ručně vybíraných vlastností, dodávaných čerstvě z trouby', 'fi': 'Data Science Kitchen GermEvalissa 2021: Hieno valikoima käsin valittuja ominaisuuksia, toimitettu tuoreena uunista', 'et': 'Andmeteaduse köök GermEval 2021: peen valik käsitsi valitud funktsioone, mis tarnitakse värskelt ahjust', 'he': 'Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'ha': 'KCharselect unicode block name', 'sk': 'Podatkovna znanstvena kuhinja na GermEvalu 2021: fina izbira ročno izbranih funkcij, dostavljenih sveže iz pečice', 'bo': 'Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven', 'jv': 'data Sayensi Kitch nang germinval 2020: A Fine Select of hand-pick Options, Delivered Refrsh from the Olen'}
{'en': 'This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for ', 'pt': 'Este artigo apresenta a contribuição da tarefa compartilhada da Data Science Kitchen na GermEval 2021 na identificação de comentários tóxicos, envolventes e de alegação de fatos. A tarefa visa estender a identificação de linguagem ofensiva, incluindo subtarefas adicionais que identificam comentários que devem ser priorizados para verificação de fatos por moderadores e gerentes de comunidade. Nossa contribuição se concentra em uma abordagem de engenharia de recursos com um backend de classificação convencional. Combinamos embeddings semânticos e de estilo de escrita derivados de redes neurais profundas pré-treinadas com recursos numéricos adicionais, projetados especificamente para essa tarefa. Conjuntos de classificadores de regressão logística e máquinas de vetor de suporte são usados para derivar previsões para cada subtarefa por meio de um esquema de votação majoritária. Nosso melhor envio alcançou pontuações F1 com média macro de 66,8%, 69,9% e 72,5% para a identificação de comentários tóxicos, envolventes e de alegação de fatos.', 'ar': 'تعرض هذه الورقة مساهمة مطبخ علوم البيانات في مهمة GermEval 2021 المشتركة بشأن تحديد التعليقات السامة والجذابة والمدعومة بالحقائق. تهدف المهمة إلى توسيع نطاق تحديد اللغة الهجومية ، من خلال تضمين مهام فرعية إضافية تحدد التعليقات التي يجب ترتيبها حسب الأولوية للتحقق من الحقائق من قبل الوسطاء ومديري المجتمع. تركز مساهمتنا على نهج هندسة الميزات مع خلفية تصنيف تقليدية. نحن نجمع بين الزخارف الدلالية وأسلوب الكتابة المستمدة من الشبكات العصبية العميقة المدربة مسبقًا مع ميزات عددية إضافية ، مصممة خصيصًا لهذه المهمة. تُستخدم مجموعات مصنّفات الانحدار اللوجستي وآلات المتجهات الداعمة لاشتقاق تنبؤات لكل مهمة فرعية عبر مخطط تصويت الأغلبية. حقق أفضل ما قدمناه متوسط درجات F1 متوسط الحجم بنسبة 66.8٪ و 69.9٪ و 72.5٪ لتحديد التعليقات السامة والجذابة والمدعومة بالحقائق.', 'es': 'Este artículo presenta la contribución de la tarea compartida de Data Science Kitchen en GermEval 2021 sobre la identificación de comentarios tóxicos, atractivos y de afirmación de hechos. La tarea tiene como objetivo ampliar la identificación del lenguaje ofensivo, mediante la inclusión de subtareas adicionales que identifiquen los comentarios que los moderadores y los administradores de la comunidad deben priorizar para la verificación de datos. Nuestra contribución se centra en un enfoque de ingeniería de funciones con un motor de clasificación convencional. Combinamos incrustaciones semánticas y de estilo de escritura derivadas de redes neuronales profundas previamente entrenadas con funciones numéricas adicionales, diseñadas específicamente para esta tarea. Se utilizan conjuntos de clasificadores de regresión logística y máquinas de vectores de soporte para derivar predicciones para cada subtarea mediante un esquema de votación por mayoría. Nuestra mejor presentación logró puntuaciones F1 macropromediadas de 66,8, 69,9 y 72,5% para la identificación de comentarios tóxicos, atractivos y que afirman hechos.', 'fr': "Cet article présente la contribution de la tâche partagée Data Science Kitchen à GermEval 2021 sur l'identification des commentaires toxiques, engageants et factuels. La tâche vise à étendre l'identification du langage offensant, en incluant des sous-tâches supplémentaires qui identifient les commentaires qui devraient être priorisés pour la vérification des faits par les modérateurs et les gestionnaires de communauté. Notre contribution se concentre sur une approche d'ingénierie des fonctionnalités avec un backend de classification classique. Nous combinons des intégrations sémantiques et de style d'écriture dérivées de réseaux neuronaux profonds pré-entraînés avec des fonctionnalités numériques supplémentaires, spécialement conçues pour cette tâche. Des ensembles de classificateurs de régression logistique et de machines à vecteurs de support sont utilisés pour dériver des prévisions pour chaque sous-tâche via un système de vote majoritaire. Notre meilleure soumission a obtenu des scores F1 macro-moyens de 66,8\xa0%, 69,9\xa0% et 72,5\xa0% pour l'identification de commentaires toxiques, engageants et revendiquant des faits.", 'ja': '本稿では、有毒で魅力的で事実を主張するコメントの特定に関する2021年のGermEvalのデータサイエンスキッチンの共有タスクの貢献を紹介します。このタスクは、モデレーターとコミュニティマネージャーによるファクトチェックのために優先すべきコメントを特定する追加のサブタスクを含めることで、不快な言葉の識別を拡大することを目的としています。当社の貢献は、従来の分類バックエンドを使用した機能工学的アプローチに焦点を当てています。私たちは、このタスクのために特別に設計された追加の数値機能を備えた、事前にトレーニングされた深いニューラルネットワークから派生したセマンティックおよびライティングスタイルの埋め込みを組み合わせます。ロジスティック回帰分類子およびサポートベクターマシンのアンサンブルは、多数決スキームを介して各サブタスクの予測を導出するために使用される。当社の最良の提出物は、有毒で魅力的で事実を主張するコメントを特定するための66.8%、69.9%、72.5%のマクロ平均F 1スコアを達成しました。', 'zh': '本文引GermEval 2021上数科学庖厨识毒,引人入胜与事实称论者共同任务献。 务在广犯言之识,包额外之任,宜优加版主社区经理核之。 我们的贡献集在有旧法后端的特征。 吾将自预练之深神经网络遣生之语义,与造化之风格,与专门之巧者合数。 逻辑归分器与向量机合用多投票方案遣生每子职占之。 臣等最佳者宏观均F1得分,分为66.8%,69.9%与72.5%,以识有毒,引人入胜事称论。', 'hi': 'यह पेपर GermEval 2021 में डेटा साइंस किचन के योगदान को प्रस्तुत करता है, जो विषाक्त, आकर्षक और तथ्य-दावा करने वाली टिप्पणियों की पहचान पर साझा कार्य करता है। कार्य का उद्देश्य आक्रामक भाषा की पहचान का विस्तार करना है, जिसमें अतिरिक्त उप-कार्य शामिल हैं जो टिप्पणियों की पहचान करते हैं जिन्हें मध्यस्थों और सामुदायिक प्रबंधकों द्वारा तथ्यों की जांच के लिए प्राथमिकता दी जानी चाहिए। हमारा योगदान एक पारंपरिक वर्गीकरण बैकएंड के साथ एक फीचर-इंजीनियरिंग दृष्टिकोण पर केंद्रित है। हम अतिरिक्त संख्यात्मक विशेषताओं के साथ पूर्व-प्रशिक्षित गहरे तंत्रिका नेटवर्क से व्युत्पन्न शब्दार्थ और लेखन शैली एम्बेडिंग को जोड़ते हैं, विशेष रूप से इस कार्य के लिए डिज़ाइन किया गया है। लॉजिस्टिक प्रतिगमन क्लासिफायरऔर समर्थन वेक्टर मशीनों के ensembles का उपयोग बहुमत मतदान योजना के माध्यम से प्रत्येक उप-कार्य के लिए भविष्यवाणियों को प्राप्त करने के लिए किया जाता है। हमारा सबसे अच्छा सबमिशन ने विषाक्त, आकर्षक और तथ्य-दावा टिप्पणियों की पहचान के लिए 66.8%, 69.9% और 72.5% के मैक्रो-औसत F1-स्कोर प्राप्त किए।', 'ru': 'В этом документе представлен вклад Data Science Kitchen на совместном задании GermEval 2021 по выявлению токсичных, привлекательных и фактологических комментариев. Задача заключается в расширении идентификации оскорбительных формулировок путем включения дополнительных подзадач, определяющих комментарии, которые должны быть приоритетными для проверки фактов модераторами и общинными менеджерами. Наш вклад сосредоточен на функционально-инженерном подходе с традиционным бэкендом классификации. Мы объединяем семантические и письменные вложения, полученные из предварительно обученных глубоких нейронных сетей, с дополнительными числовыми признаками, специально разработанными для этой задачи. Ансамбли классификаторов логистической регрессии и опорных векторных машин используются для получения прогнозов по каждой подзадаче с помощью схемы мажоритарного голосования. Наша лучшая заявка достигла макрооценок F1 66,8%, 69,9% и 72,5% для выявления токсичных, привлекательных и претендующих на факты комментариев.', 'ga': 'Cuirtear i láthair sa pháipéar seo an méid a chuir an Data Science Kitchen le chéile ag GermEval 2021 comhthasc maidir le tuairimí tocsaineacha, tarraingteacha agus fíorais a shainaithint. Tá sé mar aidhm ag an tasc sainaithint na teanga maslacha a leathnú, trí fho-tascanna breise a chur san áireamh a shainaithníonn tuairimí ar cheart tosaíocht a thabhairt dóibh le haghaidh seiceáil fíricí ag modhnóirí agus bainisteoirí pobail. Díríonn ár rannchuidiú ar chur chuige gné-innealtóireacht a bhfuil inneall aicmithe traidisiúnta aige. Comhcheanglaímid leabaithe stíl shéimeantach agus scríbhneoireachta a dhíorthaítear ó líonraí néarúla domhain réamh-oilte le gnéithe uimhriúla breise, atá deartha go sonrach don tasc seo. Úsáidtear ensembles d’aicmitheoirí Aischéimniúcháin Lóistíochta agus Meaisíní Veicteoir Tacaíochta chun réamh-mheastacháin a fháil do gach fothasc trí scéim vótála tromlaigh. Bhain ár n-aighneacht ab fhearr scóir mhacra-mheánmhéide F1 de 66.8%, 69.9% agus 72.5% chun tuairimí tocsaineacha, mealltacha agus fíorais a shainaithint.', 'ka': 'ამ დოკუნტში მონაცემული მეცნიერების კუფნის დამატება GermEval 2021-ში გაყოფილი სამუშაო სამუშაო დაახლოებით ტოქსიკური, დაკავშირებული და ფაქტიკური კომენტრების განსაზ სამუშაო მიზეზია, რომ მოდინარების და საზოგადოებო მენეჯერების განსაზღვრებისთვის განსაზღვრება, რომლებიც მოდინარებული კომენტრების განსაზღვრება, რომლებიც მოდინარების და საზო ჩვენი დამატებით კონტუნციონალური კლასიფიკაციის ფონტაქტის-ინზინერიკური მონაცემებისთვის. ჩვენ სენმანტიკური და დაწერის სტილის შებრუნებები, რომლებიც წინ განაკეთებული ძალიან განსწავლებული ნეიროლური ქსელებიდან დამატებული ნეიროლური ფუნქციებით, განსაკუთ ლოგისტიკური რეგრესის კლასიფიკაციების და ვექტორის მექანების გამოყენება გამოიყენება, რომ ყოველ სექსიკური მექანების გამოყენება. ჩვენი საუკეთესო წარმოიდგინე მაკრო განსაზღვრებული F1 მონაცემები 66,8%, 69,9% და 72,5%-ის განსაზღვრებისთვის ტოქსიკური, დაკავშირებული და ფაქტიკური კომენტრების განსაზღვრება.', 'el': 'Η παρούσα εργασία παρουσιάζει τη συμβολή της κουζίνας δεδομένων στο κοινό έργο για τον εντοπισμό τοξικών, εμπλεκόμενων και ισχυρών σχολίων. Το έργο στοχεύει στην επέκταση του προσδιορισμού προσβλητικών γλωσσών, συμπεριλαμβανόμενοι πρόσθετες δευτερεύουσες εργασίες που προσδιορίζουν σχόλια που θα πρέπει να έχουν προτεραιότητα για τον έλεγχο γεγονότων από τους συντονιστές και τους διαχειριστές κοινότητας. Η συνεισφορά μας επικεντρώνεται σε μια προσέγγιση μηχανικής χαρακτηριστικών με ένα συμβατικό σύστημα ταξινόμησης. Συνδυάζουμε σημασιολογικές και γραπτές ενσωματώσεις που προέρχονται από προ-εκπαιδευμένα βαθιά νευρωνικά δίκτυα με πρόσθετα αριθμητικά χαρακτηριστικά, ειδικά σχεδιασμένα για αυτό το έργο. Τα σύνολα ταξινομητών λογιστικής παλινδρόμησης και διανυσματικών μηχανών υποστήριξης χρησιμοποιούνται για την εξαγωγή προβλέψεων για κάθε δευτερεύουσα εργασία μέσω ενός συστήματος ψηφοφορίας πλειοψηφίας. Η καλύτερη υποβολή μας πέτυχε μακρομεσαίες βαθμολογίες 66,8%, 69,9% και 72,5% για τον προσδιορισμό τοξικών, ελκυστικών και ισχυρών παρατηρήσεων.', 'hu': 'Ez a tanulmány bemutatja a GermEval 2021 Data Science Kitchen közös feladatát a mérgező, vonzó és tényállító észrevételek azonosításával kapcsolatban. A feladat célja a sértő nyelv azonosításának kiterjesztése, olyan további részfeladatok bevonása, amelyek azonosítják a megjegyzéseket, amelyeket a moderátorok és közösségi menedzserek ténylegellenőrzéséhez priorizálni kell. Közreműködésünk a hagyományos osztályozási backend funkciómérnöki megközelítésére összpontosít. Az előre képzett mélyneurális hálózatokból származó szemantikai és írási stílusú beágyazásokat kombináljuk további numerikus funkciókkal, amelyeket kifejezetten erre a feladatra terveztek. A logisztikai regresszió osztályozók és a támogató vektorgépek együtteseit használják arra, hogy az egyes részfeladatokra vonatkozó előrejelzéseket többségi szavazási rendszeren keresztül származtassák. Legjobb beadványunk 66,8%, 69,9% és 72,5% makro-átlagos F1 pontszámot ért el a mérgező, vonzó és tényállító megjegyzések azonosítására.', 'it': "Questo articolo presenta il contributo della Data Science Kitchen al compito condiviso di GermEval 2021 sull'identificazione di commenti tossici, coinvolgenti e fattuali. Il compito mira ad estendere l'identificazione del linguaggio offensivo, includendo ulteriori sottoattività che identificano i commenti che dovrebbero essere prioritari per il controllo dei fatti da parte di moderatori e community manager. Il nostro contributo si concentra su un approccio di feature-engineering con un backend di classificazione convenzionale. Combiniamo incorporazioni semantiche e di scrittura derivate da reti neurali profonde pre-addestrate con caratteristiche numeriche aggiuntive, specificamente progettate per questo compito. Gli insiemi di classificatori di regressione logistica e macchine vettoriali di supporto sono utilizzati per ricavare previsioni per ogni sottoattività tramite uno schema di voto a maggioranza. La nostra migliore presentazione ha ottenuto punteggi F1 macro-medi del 66,8%, 69,9% e 72,5% per l'identificazione di commenti tossici, coinvolgenti e fattuali.", 'kk': 'Бұл қағаз ГермEval 2021 жылы Деректер ғылымды кухнясының қатынасын көрсетеді. Түсініктерді белгілеу, қатынастыру және факты қатынастыру үшін бөліктелген тапсырманы көрсетеді. Тапсырманың мақсатында, модераторлар мен қоғамды менеджерлердің артықшылығын тексеру үшін түсініктемелерді таңдау үшін қосымша қосымша қосымша суреттерді кеңейтуге болады. Біздің көмегіміз кәдімгі классификациялық бағдарламасының функциялық инженерлік арқылы көмектеседі. Біз бұл тапсырма үшін құрылған симантикалық және жазу стилінің ендірімізді біріктіреміз. Бұл тапсырма үшін осы тапсырма үшін қосымша сандарлық мүмкіндіктермен алды Логистикалық регрессия классификациясының және вектордың қолдау машиналарын әрбір субсұраныстың көпшілігін дауыс сұлбасынан алдындау үшін қолданылады. Біздің ең жақсы жұмыс істеу макроорташа F1- нәтижесін 66,8%, 69,9% және 72,5% нәтижесін, қатынасыз және факт жайлы түсініктемелерді анықтау үшін жеткізді.', 'lt': 'Šiame dokumente pateikiamas „GermEval 2021“ duomenų mokyklos indėlis į bendrą užduotį, susijusią su toksinių, įtraukių ir faktų pareiškimų nustatymu. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers.  Mūsų indėlis daugiausia dėmesio skiria ypatybių inžinerijos metodui su įprastu klasifikavimo pagrindu. Mes deriname semantinius ir rašymo stilius, gautus iš iš iš anksto parengtų giliųjų nervų tinklų, su papildomomis skaitmeninėmis savybėmis, specialiai sukurtomis šiai užduotims. Logistinės regresijos klasifikatorių ir paramos vektorių įrenginių rinkiniai naudojami kiekvieno paklausos prognozėms gauti naudojant daugumos balsavimo sistemą. Mūsų geriausiai pateiktame dokumente pasiekti 66,8 %, 69,9 % ir 72,5 % makroekonominiai F1 rodikliai toksiniams, įtraukiamiems ir faktus teigiantiems komentarams nustatyti.', 'mk': 'Овој документ го претставува придонесот на Кујната за податоци на GermEval 2021 заедничка задача за идентификација на токсични, интересни и фактични коментари. Задачата има за цел проширување на идентификацијата на офанзивниот јазик, вклучувајќи дополнителни потпрашања кои идентификуваат коментари кои треба да бидат приоритетирани за проверка на факти од страна на модераторите и менаџерите на заедницата. Нашиот придонес се фокусира на пристапот на инженерство со конвенционална класификација. Комбинираме семантични и пишувачки стили вградени од предобучени длабоки нервни мрежи со дополнителни бројни карактеристики, специфично дизајнирани за оваа задача. Енсемблите на класификаторите за логистичка регресија и векторните машини за поддршка се користат за да се извлечат предвидувања за секоја подпрашање преку шема за гласање на мнозинството. Нашето најдобро поднесување достигна макро-просечни оценки на F1 од 66,8 отсто, 69,9 отсто и 72,5 отсто за идентификација на токсични, интересни и фактовни коментари.', 'ms': 'Kertas ini memperkenalkan kontribusi Data Science Kitchen di GermEval 2021 tugas berkongsi mengenai pengenalan komentar yang beracun, menarik, dan mengklaim fakta. Tugas ini bermaksud memperluas pengenalan bahasa yang menyerang, dengan termasuk subtanya tambahan yang mengenalpasti ulasan yang patut diberi keutamaan untuk pemeriksaan fakta oleh moderator dan pengurus komuniti. Kontribusi kami fokus pada pendekatan teknik-fitur dengan bahagian belakang klasifikasi konvensional. Kami menggabungkan bentuk gaya semantik dan menulis yang berasal dari rangkaian saraf dalam yang terlatih sebelum ini dengan ciri-ciri nombor tambahan, secara khusus direka untuk tugas ini. Ensemble bagi klasifikasi Regresi Logistik dan Mesin Vektor Sokongan digunakan untuk mendatangkan ramalan untuk setiap subtask melalui skema pemilihan kebanyakan. Pemberian terbaik kami mencapai makro-rata-rata-F1 skor 66.8%, 69.9% dan 72.5% untuk pengenalan komentar yang beracun, menarik, dan mengaku fakta.', 'mt': 'Dan id-dokument jippreżenta l-kontribut tal-Kċina tax-Xjenza tad-Dejta fi GermEval 2021 kompitu kondiviż dwar l-identifikazzjoni ta’ kummenti tossiċi, involuti u li jsostnu l-fatti. Il-kompitu għandu l-għan li jestendi l-identifikazzjoni tal-lingwa offensiva, billi jinkludi sottomistoqsijiet addizzjonali li jidentifikaw kummenti li għandhom jiġu prijoritizzati għall-verifika tal-fatti minn moderaturi u maniġers tal-komunità. Our contribution focuses on a feature-engineering approach with a conventional classification backend.  We combine semantic and writing style embeddings derived from pre-trained deep neural networks with additional numerical features, specifically designed for this task.  L-Ensembles tal-klassifikaturi tar-Regressjoni Loġistika u l-Magni tal-Vetturi ta’ Appoġġ jintużaw biex jiġu dderivati tbassir għal kull sottotalba permezz ta’ skema ta’ vot maġġoritarju. L-aħjar sottomissjoni tagħna kisbet punteġġi F1 makro-medji ta’ 66.8%, 69.9% u 72.5% għall-identifikazzjoni ta’ kummenti tossiċi, involuti u li jsostnu l-fatti.', 'ml': 'ഈ പത്രത്തില്\u200d ജെര്\u200dമെവാല്\u200d 2021 ലെ ഡേറ്റാ ശാസ്ത്ര കിച്ചിന്റെ ഭാഗമാണ് പങ്കുചേര്\u200dത്തിരിക്കുന്നത്. വിദ്യാഭാരം തിരിച്ചറിയുന് The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers.  നമ്മുടെ ഭാഗങ്ങള്\u200d ഒരു സാധാരണ ക്ലാസ്ഫിക്ഷന്\u200d ബാക്കിന്\u200dറെ പിന്നില്\u200d ശ്രദ്ധിക്കുന്നു. മുമ്പ് പരിശീലിക്കപ്പെട്ട ആഴത്തിലെ ന്യൂറല്\u200d വര്\u200dക്കുകളില്\u200d നിന്നും സെമാന്റിക്കും രീതിയില്\u200d നിന്നും എഴുതിയ സ്റ്റൈലുകള്\u200d ഞങ്ങള ലോഗിസ്റ്റിക് റെഗ്രഷന്\u200d വിഭവങ്ങളുടെയും പിന്തുണയ്ക്കുന്ന വെക്റ്റര്\u200d മെഷീനുകളുടെയും എനിമെല്ലുകള്\u200d ഒരു വോട്ട് സ്കീമിനുമുഖ നമ്മുടെ ഏറ്റവും നല്ല സമ്മാനം 66.', 'mn': 'Энэ цаас 2021 оны Гермевалд өгөгдлийн шинжлэх ухааны мухлагын нэр дэвшилтийг харуулдаг. Үүний зорилго нь зөрчилдөг хэл болон нийгмийн удирдагчид үнэндээ шалгахад анхаарлыг тодорхойлж чадна. Бидний зорилго нь хувилбарын инженерчлэлийн арга зам дээр төвлөрүүлдэг. Бид өмнө сургалтын гүн гүнзгий мэдрэлийн сүлжээгээс илүү тоо хэмжээний чанартай, ялангуяа энэ үйл ажилд зохион бүтээгдэхүүнээс гарсан семантик болон бичих хэлбэрүүдийг нэгтгэдэг. Логистикийн регрессийн хуваарилагч болон дэмжих вектор машинуудын шинжлэх ухаан нь ихэнх сонголтын төлөвлөгөө аргаар суурь асуулт бүрт таамаглах хэрэгтэй. Бидний хамгийн шилдэг тайлбар нь 66.8%, 69.9% болон 72.5% хохиромжтой, хохиромжтой, үнэндээ хэлж буй тайлбаруудыг тодорхойлох макро дундаж үзүүлсэн.', 'no': 'Denne papiret viser bidrag til datavitenskapsvinken i GermEval 2021 delt oppgåve om identifiseringa av toksiske, engasjerande og faktiske kommentarar. Oppgåva må utvida identifikasjonen av offensivspråk ved å inkludera ekstra underspørsmål som identifiserer kommentarar som skal prioritert for å kontrollera faktum av moderatorar og fellesskapshandsamarar. Bidrag vårt fokuserer på ein funksjonsengineering tilnærming med ein konvensjonell klassifikasjonsmodul. Vi kombinerer semantiske og skrivingsstilinnbygging som er avhengig frå føretrainerte dype neuralnettverk med fleire numeriske funksjonar, spesielt utforma for denne oppgåva. Brukar brukar av logistiske regresjonsklasseringar og støtte vektormaskiner for å få forhåndsvising for kvar underspørjing gjennom ein fleire stemmeoppsett. Det beste oppføringa vårt oppnådd makro gjennomsnittt F1-poeng med 66,8 %, 69,9 % og 72,5 % for identifiseringa av toksiske, engasjerande og faktiske kommentarar.', 'pl': 'W artykule przedstawiono wkład wspólnego zadania kuchni danych GermEval 2021 dotyczącego identyfikacji toksycznych, angażujących i twierdzących fakty komentarzy. Celem zadania jest rozszerzenie identyfikacji języka obraźliwego poprzez dodatkowe podzadania identyfikujące komentarze, które powinny być priorytetowe do sprawdzania faktów przez moderatorów i menedżerów społeczności. Nasz wkład koncentruje się na podejściu inżynierii funkcji z konwencjonalnym backendem klasyfikacji. Łączymy osadzenia semantyczne i pisemne pochodzące ze wstępnie przeszkolonych głębokich sieci neuronowych z dodatkowymi funkcjami numerycznymi, specjalnie zaprojektowanymi do tego zadania. Zestawy klasyfikatorów regresji logistycznej i maszyn wektorowych wsparcia są używane do wywodzenia prognoz dla każdego podzadania za pomocą schematu głosowania większością. Nasze najlepsze zgłoszenie uzyskało makro średnie wyniki F1 66,8%, 69,9% i 72,5% do identyfikacji toksycznych, angażujących i twierdzących fakty komentarzy.', 'ro': 'Această lucrare prezintă contribuția bucătăriei științifice de date la GermEval 2021 sarcina comună privind identificarea comentariilor toxice, captivante și de afirmare a faptelor. Sarcina urmărește extinderea identificării limbajului ofensator, prin includerea subactivităților suplimentare care identifică comentariile care ar trebui prioritizate pentru verificarea faptelor de către moderatori și manageri de comunitate. Contribuția noastră se concentrează pe o abordare de inginerie a caracteristicilor cu un backend convențional de clasificare. Combinăm încorporări semantice și scrise derivate din rețele neuronale profunde pre-instruite cu caracteristici numerice suplimentare, concepute special pentru această sarcină. Ansamblurile de clasificatoare de regresie logistică și mașini vectoriale de suport sunt folosite pentru a obține previziuni pentru fiecare subactivitate printr-o schemă de vot majoritar. Cea mai bună depunere a noastră a obținut scoruri F1 macro-medii de 66,8%, 69,9% și 72,5% pentru identificarea comentariilor toxice, captivante și care susțin faptele.', 'so': 'Qoraalkan wuxuu ka qeybqaadaa Keshiinta cilmiga Data ee GermEval 2021 shaqo lagu sharciyey aqoonsiga maandooriyaha, isku biirida iyo kommentaha xaqiiqda. Shaqada waxaa loola jeedaa in la sii fidiyo aqoonsiga luqada dembiga ah, kuwaas oo ku jira shaqooyin dheeraad ah oo ku qoran heshiiska ay ku qoran tahay horumarinta xaqiiqyada iyo maamulaha bulshada. Hadalkeenu wuxuu ku nool yahay qaab baabuur ah oo la xiriira dhamaadka fasaxa caadiga ah. Waxaannu isugu soo ururinaynaa hababka semantika iyo qoritaanka oo ka soo baxay shabakado aad u dheer oo neurada ah, waxayna leedahay noocyo badan, si gaar ah loo qoray shaqadaas. Isticmaalayaasha qorshaha codeynta oo badan waxaa loo isticmaalaa in lagu sameeyo wax la sii sheego subtashka oo dhan. Madaxalkayaga ugu wanaagsan waxay gaadheen iskuullada F1 ee macro-dhexe 66.8 boqolkiiba, 69.9 boqolkiiba iyo 72.5 boqolkiiba aqoonsashada mukhaadaraadka, isku xiridda iyo commentarada xaqiiqa ah.', 'sv': 'Denna uppsats presenterar bidraget från Data Science Kitchen på GermEval 2021 delade uppgift om identifiering av giftiga, engagerande och faktauppförande kommentarer. Uppgiften syftar till att utöka identifieringen av stötande språk genom att inkludera ytterligare underuppgifter som identifierar kommentarer som bör prioriteras för faktakontroll av moderatorer och community managers. Vårt bidrag fokuserar på ett funktionstekniskt tillvägagångssätt med en konventionell klassificeringsbackend. Vi kombinerar semantisk och skrivstil inbäddningar härledda från pre-utbildade djupa neurala nätverk med ytterligare numeriska funktioner, speciellt utformade för denna uppgift. Ensembler av Logistic Regression klassificerare och Support Vector Machines används för att härleda förutsägelser för varje underaktivitet via ett majoritetsbeslutningsschema. Vår bästa inlämning uppnådde makrogränsade F1-poäng på 66,8%, 69,9% och 72,5% för identifiering av toxiska, engagerande och faktaundervisande kommentarer.', 'si': 'මේ පත්තුවේ ජර්ම්වේල් 2021 වල දත්ත විද්\u200dයාන්\u200dය කිචන්ගේ සම්බන්ධය පෙන්වන්න පුළුවන් විද්\u200dයාවක්, සම්බන්ධ විද්\u200dයාවක් ස මේ වැඩේ ඉලක්කම් වෙන්නේ අපරාධ භාෂාවේ පරීක්ෂණය වැඩ කරන්න, සම්පූර්ණය සහ සමාජ ප්\u200dරධානකයෙන් ප්\u200dරධාන පරීක්ෂණය කරන්න සඳහ අපේ සම්බන්ධ විශේෂතාවක් ඉංජිනියාර්ජින් වලට සාමාන්\u200dය විශේෂතාවක් පස්සම් එක්ක ප්\u200dර අපි සෙමැන්ටික් සහ ලියන්නේ විස්තාරයක් සම්බන්ධ කරනවා මේ වැඩ සඳහා විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් ප්\u200dරධානය Name අපේ හොඳම පිළිගන්න පුළුවන් මැක්රෝ අවුරුද්ධ F1-ස්කෝර් 66.8%, 69.9% සහ 72.5% විෂ්\u200dය, සම්පූර්ණය සහ ඇත්ත ප්\u200dරශ්නයක් තියෙන්න', 'ta': 'இந்த தாள் ஜெர்ம்Eval 2021 ல் தரவு அறிவியல் கிச்சனின் பங்கீட்டை குறிப்பிடுகிறது தொடர்ந்து, இணைத்து மற்றும் உண்மையான குறிப்புரைகள்  கூடுதல் துணை பணிகளைக் கொண்டு கூடுதல் குறிப்புரைகளை கண்டுபிடிக்க வேண்டும் என்று உண்மையை சரிபார்ப்பதற்கு முன்னுரிமைப்படுத்த வே எங்கள் பங்குகள் ஒரு சாதாரண வகுப்பு பின்னணி ஒரு குணங்கள் பொறிய முறையில் கவனம் செலுத்துகிறது. நாம் முன் பயிற்சிக்கப்பட்ட ஆழமான புதிய வலைப்பின்னல்களிலிருந்து வரையப்பட்ட பெமான்டிக் மற்றும் எழுதும் பாணியை ஒன்று சேர்க பெரும்பாலான தொகுப்பு திட்டத்தின் மூலம் ஒவ்வொரு துணை பணிக்கும் முன்னுரிமைகளை கொண்டு வருவதற்காக குறிப்பிடுகிறது. எங்கள் சிறந்த பரிமாற்றம் 66.8%, 69.9% மற்றும் 72.5% துன்பத்தை கண்டுபிடிக்க, சேர்த்தல் மற்றும் உண்மையான குறிப்புரைகளுக்கு மேக்ரோ சராசரி F', 'ur': 'This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. اس کام کا ارادہ یہ ہے کہ فساد کی زبان کی شناسایی کشادہ کریں، اور اس کے ذریعہ اضافہ زیادہ مطالبات بھی شامل کریں جو مطالبات کی شناسایی کریں جو مدرساتور اور کمونٹی مدیرانوں کے ذریعہ حقیقت کی چک کرنے کے لئے پہلی دکھائی ہمارا حصہ ایک فرصت-انجینریسی طریقہ پر مشغول ہوتا ہے ایک سنتی کلاسپیٹ پکنڈ کے ساتھ. ہم اس کام کے لئے مخصوصا طراحی کیا گیا تھا جو پہلے تدریس کی عمیق نیورل نیورل نیٹورک سے پیدا ہوئی سیمنٹی اور لکھنے کی استیل ایمبڈینگ کو ترکیب کرتے ہیں۔ لوجیسٹیکی ریگرس کلیسٹر اور پشتیبانی ویکتور ماشینوں کی مثالیں ہر سوٹ پرسٹ کے لئے ایک اکثر وٹ نقشه کے ذریعے پیش بینی کرنے کے لئے استعمال کیے جاتے ہیں. ہماری بہترین تحویل نے 66.8%, 69.9% اور 72.5% کے مطابق سمیٹ، مشغول اور حقیقت کی تعریف کے لئے مکرو متوسط F1 سکوٹ پہنچ گئے۔', 'sr': 'Ovaj papir predstavlja doprinos kuhinje za znanje podataka u GermEval 2021. delom zadatka o identifikaciji toksičnih, angažovanih i činjeničnih komentara. Taj zadatak je cilj da proširi identifikaciju ofanzivnog jezika, uključujući i dodatne podupire koje identifikuju komentare koje bi trebale biti prioritisane za provjeru činjenica od strane moderatora i menadžera zajednice. Naš doprinos se fokusira na pristup inženjerstvom sa konvencionalnim klasifikacijom. Kombinacija semantičnih i pisanih stilova iz predobučenih dubokih neuronskih mreža sa dodatnim brojnim karakteristikama, posebno dizajniranim za ovaj zadatak. Primjeri klasifikatora logičke regresije i motora za podršku vektora koriste se za otkrivanje predviđanja za svaku podpitanje putem većine glasačke šeme. Naša najbolja predstava postigla je makro-srednji rezultat F1 od 66,8%, 69,9% i 72,5% za identifikaciju toksičnih, angažovanih i činjeničnih komentara.', 'uz': "This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments.  Bu vazifa esa hisoblash tilini aniqlash imkoniyatini ko'paytirish uchun, boshqa vazifalarni qoʻshish imkoniyatini aniqlash kerak. Hujjatlarni va jamiyat boshqaruvchilari bilan boshqarish uchun muhim imkoniyatini koʻrsatish kerak. Bizning qanday qanday paydo bo'lgan tashkilotlar bir oddiy darajadagi narsa bilan foydalanadi. Biz avval o'rganilgan eng yaxshi neyron tarmoqdan semantik va yozish uslublarni birlashtiramiz, bu vazifa uchun qoʻshimcha raqamli xususiyatlar bilan birlashtiramiz. Name Bizning eng eng yaxshi xabarlarimiz 66.8%, 69.9% va 72.5% tizimni aniqlash uchun makro-o'rtacha F1 darajaga ega bo'ldi, va haqiqiqiy izohlarni qidirish uchun.", 'vi': 'Tờ giấy này trình bày sự đóng góp của Data Science Kitchen tại GermEvil 2021 có nhiệm vụ chia sẻ về nhận dạng các nhận xét về độc hại, kích động và thực tế. Nhiệm vụ này nhằm kéo dài việc nhận dạng ngôn ngữ tấn công, bằng cách thêm các phụ đề bổ sung để xác định các bình luận cần được ưu tiên cho việc kiểm tra thực tế bởi các bậc thầy và quản lý cộng đồng. Sự đóng góp của chúng tôi nhằm vào một kế hoạch đặc trưng với hậu phương phân loại thông thường. Chúng ta kết hợp các sự nhúng vào kiểu chữ nghĩa và văn bản từ những mạng thần kinh sâu được đào tạo trước với các tính năng số khác, được thiết kế đặc biệt cho nhiệm vụ này. Những trường hợp phân loại ra áp dụng theo logic và cấu trúc Vectror* hỗ trợ được dùng để dự đoán về mỗi mặt phụ đề thông qua một phương pháp biểu quyết đa số. Sự đệ trình tốt nhất của chúng tôi đã đạt được siêu số F1-điểm giá trị cao cao của 62.8 Name, 69. và 72.5 không. để xác định được các bình luận có độc, hấp dẫn và thực tế.', 'da': 'Denne artikel præsenterer bidraget fra Data Science Kitchen på GermEval 2021 delte opgave om identifikation af giftige, engagerende og faktahævdende kommentarer. Opgaven sigter mod at udvide identifikationen af stødende sprog ved at inkludere yderligere underopgaver, der identificerer kommentarer, som bør prioriteres til fact-checking af moderatorer og community managers. Vores bidrag fokuserer på en feature-engineering tilgang med en konventionel klassificering backend. Vi kombinerer semantisk og skrivestil embeddings afledt af præ-trænede dybe neurale netværk med yderligere numeriske funktioner, specielt designet til denne opgave. Ensembler af Logistic Regression klassificeringer og Support Vector Machines bruges til at udlede forudsigelser for hver underopgave via en flertalsafstemning ordning. Vores bedste indsendelse opnåede makro-gennemsnitlige F1-scorer på 66,8%, 69,9% og 72,5% til identifikation af giftige, engagerende og faktiske kommentarer.', 'bg': 'Настоящата статия представя приноса на Кухнята за научни данни към споделената задача за идентифициране на токсични, ангажиращи и твърдящи факти коментари. Задачата има за цел да разшири идентифицирането на офанзивен език, като включи допълнителни подзадачи, които идентифицират коментари, които трябва да бъдат приоритизирани за проверка на фактите от модераторите и мениджърите на общността. Нашият принос се фокусира върху подхода на функционален инженеринг с конвенционален бекенд за класификация. Ние комбинираме семантични и стилови вграждания, получени от предварително обучени дълбоки невронни мрежи, с допълнителни числови функции, специално проектирани за тази задача. Ансамбли от класификатори за логистична регресия и поддържащи векторни машини се използват за извличане на прогнози за всяка подзадача чрез схема за гласуване с мнозинство. Нашето най-добро представяне постигна макросредни резултати от 66,8%, 69,9% и 72,5% за идентифициране на токсични, ангажиращи и твърдящи факти коментари.', 'hr': 'Ovaj papir predstavlja doprinos kuhinje za znanje podataka u GermEval 2021. dijeljenog zadatka o identifikaciji toksičnih, uključenih i činjeničnih komentara. Cilj zadataka je proširiti identifikaciju ofanzivnog jezika, uključujući dodatne podatke kojima se identificiraju komentari koji bi trebali biti prioritizirani za provjeru činjenica od strane moderatora i upravljača zajednice. Naš doprinos se fokusira na pristup inženjerstvom sa konvencionalnim klasifikacijom. Kombinacija semantičkih i pisanih stilova iz predobučenih dubokih neuronskih mreža s dodatnim brojnim karakteristikama, posebno dizajniranim za ovaj zadatak. Primjeri klasifikatora logičke regresije i strojeva podrške vektora koriste se za otkrivanje predviđanja za svaku podpitanje putem većine glasačkog šema. Naša najbolja predstava postigla je makro-srednji rezultat F1 od 66,8%, 69,9% i 72,5% za identifikaciju toksičnih, uključujućih i činjeničnih komentara.', 'nl': 'Dit artikel presenteert de bijdrage van de Data Science Kitchen op GermEval 2021 gedeelde taak over het identificeren van giftige, boeiende en feiten claimende opmerkingen. De taak heeft tot doel de identificatie van aanstootgevende taal uit te breiden, door extra subtaken op te nemen die opmerkingen identificeren die prioriteit moeten krijgen voor fact-checking door moderators en community managers. Onze bijdrage richt zich op een feature-engineering aanpak met een conventionele classificatie backend. We combineren semantische en schrijfstijl embeddings afgeleid van vooraf getrainde diepe neurale netwerken met extra numerieke functies, speciaal ontworpen voor deze taak. Ensembles van Logistic Regression classificators en Support Vector Machines worden gebruikt om voorspellingen af te leiden voor elke subtaak via een meerderheidsstemschema. Onze beste inzending behaalde macro-gemiddelde F1-scores van 66,8%, 69,9% en 72,5% voor het identificeren van giftige, boeiende en feiten claimende opmerkingen.', 'de': 'Dieser Beitrag stellt den Beitrag der Data Science Kitchen bei GermEval 2021 zur Identifizierung toxischer, ansprechender und faktenbezogener Kommentare vor. Die Aufgabe zielt darauf ab, die Identifizierung anstößiger Sprache zu erweitern, indem zusätzliche Teilaufgaben hinzugefügt werden, die Kommentare identifizieren, die für die Überprüfung von Fakten durch Moderatoren und Community-Manager priorisiert werden sollten. Unser Beitrag konzentriert sich auf einen Feature-Engineering-Ansatz mit einem herkömmlichen Klassifikations-Backend. Wir kombinieren semantische und schreibende Einbettungen aus vortrainierten tiefen neuronalen Netzwerken mit zusätzlichen numerischen Merkmalen, die speziell für diese Aufgabe entwickelt wurden. Ensembles aus Klassifikatoren für logistische Regression und Support Vector Machines werden verwendet, um Vorhersagen für jede Teilaufgabe über ein Mehrheitswahlschema abzuleiten. Unsere beste Einreichung erzielte makro-durchschnittliche F1-Scores von 66,8%, 69,9% und 72,5% zur Identifizierung von toxischen, ansprechenden und faktenbezogenen Kommentaren.', 'ko': '본고는 GermEval 2021 공유 임무 데이터 과학 주방이 독이 있고 매력적이며 사실을 주장하는 평론을 식별하는 데 기여한 바를 소개한다.이 임무는 공격적인 언어의 식별 범위를 확대하는 데 목적을 둔다. 평론을 식별하는 추가 하위 임무를 포함하고 판주와 지역사회 관리자는 평론에 대해 우선적으로 사실 검사를 해야 한다.우리의 공헌은 전통적인 분류 백엔드를 가진 특징적인 공사 방법에 집중되었다.우리는 사전에 훈련된 심층 신경 네트워크에서 추출한 의미와 쓰기 스타일을 추가적인 디지털 특징과 결합시켜 이 임무를 위해 설계할 것이다.논리 회귀 분류기와 벡터기 지원 집합은 다수의 투표 방안을 통해 모든 하위 임무를 예측하는 데 사용된다.Dell의 최고 제출 점수는 66.8%, 69.9%, 72.5%의 F1 평균 점수를 획득하여 독성, 흥미진진함, 사실 공언을 식별하는 데 사용되었습니다.', 'fa': 'این کاغذ مشترک آشپزخانه علم اطلاعات در GermEval 2021 در مورد شناسایی توضیح\u200cهای سمی، مشترک و درخواست\u200cکننده حقیقت را نشان می\u200cدهد. این وظیفه هدف دارد که شناسایی زبان فساد را گسترش دهد، با شامل تحقیقات اضافه\u200cای که توضیح\u200cها را شناسایی کنند که باید برای بررسی حقیقت توسط مدیراتوران و مدیراتوران جامعه به اولویت بررسی کنند. شرکت ما روی یک روش مهندسی ویژه\u200cهای ویژه با یک پشتیبانی سرگرمی سنتی تمرکز می\u200cکند. ما از شبکه های عصبی پیش آموزش شده با ویژه های تعدادی تعدادی بیشتری، مخصوصا برای این کار طراحی شده\u200cایم، جمع می\u200cکنیم. فعالیت\u200cهای گروهی\u200cکننده\u200cهای گروهی منطقی و دستگاه\u200cهای پشتیبانی ویکتور استفاده می\u200cشود تا پیش\u200cبینی برای هر زیر پرسیدن با طریق بسیاری از برنامه\u200cهای رای\u200cدهنده\u200cای استفاده می\u200cشود. بهترین تحویل ما به عنوان تعریف مکرومتوسط F1 در حدود 66.8%, 69.9% و 72.5% برای شناسایی مشاهده\u200cهای سمی، مشغول و درخواست\u200cکننده\u200cی حقیقت رسیده است.', 'id': 'Kertas ini memperlihatkan kontribusi Data Science Kitchen di GermEval 2021 berbagi tugas mengenai identifikasi komentar yang beracun, menarik, dan mengklaim fakta. Tugas ini bermaksud memperluas identifikasi bahasa yang menyerang, dengan termasuk subtasks tambahan yang mengidentifikasi komentar yang seharusnya diprioritisasi untuk pemeriksaan fakta oleh moderator dan manajer komunitas. Kontribusi kami fokus pada pendekatan teknik-fitur dengan backend klasifikasi konvensional. Kami menggabungkan pembangunan gaya semantis dan menulis yang berasal dari jaringan saraf dalam yang terlatih sebelumnya dengan ciri-ciri numerik tambahan, secara khusus dirancang untuk tugas ini. Ensemble dari klasifikasi Regresi Logistik dan Pembantu Mesin Vektor digunakan untuk mendapatkan prediksi untuk setiap subtask melalui skema pemilihan mayoritas. Pemberian terbaik kami mencapai nilai F1 makro-rata-rata 66,8%, 69,9% dan 72,5% untuk identifikasi komentar yang beracun, menarik, dan mengklaim fakta.', 'tr': "Bu kagyz GermEval 2021-nji GermEval'da Data Science Kitchen'yň zehirli, gatnaşyk we hakykatdanam ylalaşyklaryň bardygyny ylalaşýar. Bu zadyň maksady moderatörler we jemgyýet müdiri tarapyndan üçin wajyp barlamaly terjimeleri bejermek üçin janlaşdyrmak üçin janlaşdyrylmagyny gollaşdyrmak. Biziň gabdalymyz adatça klasifikasiýa bilen özellikler-enjiniýanyň tassygyna üns berýär. Biz semantik we ýazma tarzından öňünden öňünden gelinýän derin nöral şebeklerden, bu görev üçin özellikle tasarlanýan esasy karakterlerle birleşýäris. логиstik regressiň klasifikatynyň üýtgewleri we vektör makinelerin ullanýar. Biziň iň gowy teslimanymyz 66,8%, 69,9% we 72,5% toksik, suratly we çözümleri tanamak üçin makro ortalama noktalaryny ýetdi.", 'sw': 'This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments.  Kazi hiyo inakusudia kuongeza utambulisho wa lugha ya matusi, ikiwa ni pamoja na kazi za ziada zinazoonyesha maoni ambayo yanapaswa kuwa kipaumbele kwa kutangaza ukweli na watawala wa jamii. Mchango wetu unajikita kwenye mbinu za ubunifu wenye msingi wa usambazaji wa kawaida. Tunaunganisha mitandao ya kisasa na kuandika mazingira yaliyotokana na mitandao ya kijamii yaliyofunzwa kabla yenye vipengele kadhaa, hasa kwa ajili ya kazi hii. Baadhi ya maafisa wa ukandamizaji wa KiLogistic na Mashine ya Kuunga mkono inatumika kupata utabiri kwa kila juhudi kwa kupitia mpango wa kura wengi. Ujumbe wetu bora ulifikia vipindi vya F1 vya wastani wa asilimia 66.8, asilimia 69.9 na asilimia 72.5 kwa kutambua sumu, kujihusisha na maoni yanayodai ukweli.', 'sq': 'Ky dokument paraqet kontributin e Kuzhinës së Shkencës së të dhënave në GermEval 2021 detyrë të përbashkët mbi identifikimin e komenteve toksike, të angazhuese dhe të deklarueshme të fakteve. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers.  Kontributi ynë përqëndrohet në një qasje inxhinieri-funksionesh me një sfond klasifikimi konvencional. Ne kombinojmë përfshirje semantike dhe stili shkrimi të prodhuara nga rrjetet e thella nervore të paratrajnuara me karakteristika numërore shtesë, specifikisht të dizajnuara për këtë detyrë. Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme.  Paraqitja jonë më e mirë arriti rezultate makro-mesatare F1 prej 66.8%, 69.9% dhe 72.5% për identifikimin e komenteve toksike, të angazhuese dhe të deklarueshme të fakteve.', 'am': 'ይህ ገጽ የዳታ ሳይንስ ኪኪስን በጌርምEval 2021 የደረጃ ማውጣት፣ በጥስ እና ውይይት አካባቢ እና አካባቢ ማስታወቂያውን በማስታወቅ የተጠቃሚ ስራ ያሳያል፡፡ ስራው የአሰናክል ቋንቋ ማሳየትን ለመጨመር ይችላል፣ በተጨማሪም ማስታወቂያዎች እና ማኅበራዊ መሳሪያ ማሳየት እንዲያስፈልጉት ማስታወቂያውን ለማሳመር ይችላል፡፡ አካሄዳችን በተቃውሞ የግንኙነት መፍጠር መጨረሻ ላይ ያሳያል፡፡ ለዚህ ስራ በተለየ የተጠቃሚ የጥልቅ የነዌብ መረብ ውስጥ የተገኘውን የsemantic እና የጽሑፍ ዘይት ጥቅሎች እናሳስባለን፡፡ ምርጫዎች Our best submission achieved macro-averaged F1-scores of 66.8%, 69.9% and 72.5% for the identification of toxic, engaging, and fact-claiming comments.', 'hy': 'Այս հոդվածը ներկայացնում է Գիտության տվյալների խոհանոցի ներդրումը, որը կազմում է "ԳերմԷվալ 2021" համագործակցած խնդիրը թունավոր, ներգրավող և փաստեր պահանջող մեկնաբանությունների հայտնաբերման մասին: Այս խնդիրը նպատակն է ընդլայնել խոցելի լեզվի բացահայտումը, ներառելով ավելին ենթախնդիրներ, որոնք բացահայտում են մեկնաբանություններ, որոնք պետք է հատկապես հատուկ լինեն փաստերի ստուգելու համար մոդերատորների և համայնքի ղեկավարների կո Our contribution focuses on a feature-engineering approach with a conventional classification backend.  Մենք համադրում ենք սեմանտիկ և գրողական ոճի ներդրումներ, որոնք ստացվում են նախապատրաստված խորը նյարդային ցանցերից, ավելին թվային առանձնահատկությունների հետ, մասնավորապես այս խնդրի համար: Լոգիստիկ ռեգրեսիայի դասակարգումների և աջակցության մեքենաների նշանները օգտագործվում են յուրաքանչյուր ենթախնդիր կանխատեսելու համար մեծամասնության քվեարկության ծրագրով: Մեր լավագույն ներկայացումը հասավ 66.8, 69.9 և 72.5 տոկոսի մակրոմիջին F1-գնահատականներին թունավոր, ներգրավող և փաստեր պայմանավորող մոտեցումների հայտնաբերման համար:', 'af': "Hierdie papier stel die bydraag van die Data Science Kitchen by GermEval 2021 deel opdrag op die identifiseering van toksiske, engaging en feit-aandrukking kommentaar. Die taak bepaal om die identifikasie van offensivele taal te verleng deur bygelyking van addisionele subtaske wat kommentaar identifiseer wat prioriteer moet word vir feit-kontrole deur moderators en gemeenskapsbestuurders. Ons bydraai fokus op 'n funksie-inženierige toegang met 'n konvensionale klassifikasie agtergrond. Ons kombinieer semantiese en skryfstyl inbêdings wat van voroefende diep neuralnetwerke afgelei word met addisionele numeriese funksies, spesifieke ontwerp vir hierdie taak. Ensemblers van Logistiese Regresie klassifiseerders en ondersteun Vektor Masjiene word gebruik om voorskoue vir elke ondersteun deur 'n meeste stem skema afgelei te maak. Ons beste ondersteuning het makro-gemiddelde F1-telling van 66,8%, 69,9% en 72,5% bereik vir die identifiseering van toksiske, engang en feit-aansoek kommentaar.", 'bs': 'Ovaj papir predstavlja doprinos kuhinje za znanje podataka u GermEval 2021. dijeljenog zadatka o identifikaciji toksičnih, uključujućih i tvrdljivih komentara. Taj zadatak je cilj proširiti identifikaciju ofanzivnog jezika, uključujući dodatne podatke koje identificiraju komentare koje bi trebale biti prioritisane za provjeru činjenica od strane moderatora i upravljača zajednice. Naš doprinos se fokusira na pristup inženjerstvom sa konvencionalnim klasifikacijom. Kombinacija semantičnih i pisanih stilova iz predobučenih dubokih neuronskih mreža sa dodatnim brojnim karakteristikama, posebno dizajniranim za ovaj zadatak. Primjeri klasifikatora logičke regresije i motora za podršku vektora koriste se za otkrivanje predviđanja za svaku podpitanje putem većine glasačkog šema. Naša najbolja predstava postigla je makro-srednji rezultat F1 od 66,8%, 69,9% i 72,5% za identifikaciju toksičnih, uključenih i činjeničnih komentara.', 'bn': 'এই পত্রিকাটি জের্মেভাল ২০২১-এ ডাটা বিজ্ঞান কিচেনের অবদান প্রদান করেছে ব্যস্ত, যোগাযোগ এবং সত্যিকারের দাবী মন্তব্যের পরিচয় নিয়ে প এই কাজের উদ্দেশ্য হচ্ছে আক্রমণের ভাষার পরিচয় বৃদ্ধি করা, যার মধ্যে আরো সাবটাকাজ রয়েছে যারা মন্তব্য চিহ্নিত করে যা আধুনিক এবং সম্প্রদায়ের ম্ আমাদের অংশগ্রহণযোগ্যতার প্রতি একটি বৈশিষ্ট্য-ইঞ্জিনিয়ার প্রতিক্রিয়ায় মনোযোগ দিয়েছে। আমরা পূর্ব প্রশিক্ষিত নিউরেল নেটওয়ার্ক থেকে সেমেন্টিক এবং লেখার স্টাইল বিভিন্ন সংখ্যার সাথে একত্রিত করি, বিশেষ করে এই কাজের জন্য Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme.  আমাদের সর্বশ্রেষ্ঠ প্রতিক্রিয়া ম্যাক্রো গড়ে ৬৬.', 'az': "Bu kańüńĪt 2021-ci GermEval'da Data Science Kitchen'in istifad…ô etdiyi m…ôlumatlarńĪn zehirli, engang v…ô fakt-claiming Ňü…ôkill…ôrinin tanńĪmlamasńĪ haqqńĪnda paylaŇüńĪr. Bu iŇüin v…ôzif…ôsi, moderatorlar v…ô toplum m√ľd√ľrl…ôri t…ôsdiql…ônm…ôk √ľ√ß√ľn …ôvv…ôlc…ô t…ôsdiql…ônm…ôk lazńĪmdńĪr. Bizim qeyrimiz, conventional classification backend il…ô f…ôrqli inŇĺenjeri t…ôrzin…ô odaqlanńĪr. Biz semantik v…ô yazmaq still…ôrini, …ôvv…ôlc…ô t…ôhsil edilmiŇü derin n√∂ral ańülarńĪndan …ôlav…ô edilmiŇü, bu iŇüin √ľ√ß√ľn m√ľ…ôyy…ôn edilmiŇü, √ßox sayńĪsal x√ľsusiyy…ôtl…ôrl…ô birl…ôŇüdiririk. Lojistik Regresiya klasifikatńĪnńĪn v…ô Vekt√∂r Makinel…ôrinin imzalarńĪ h…ôr bir subtask √ľ√ß√ľn √ßox s…ôsl…ôr taslańüńĪ vasit…ôsil…ô t…ôdbir almaq √ľ√ß√ľn istifad…ô edilir. Bizim …ôn yaxŇüńĪ t…ôsdiql…ôrimiz makro-ortalama F1-n√ľmun…ôl…ôrini 66,8%, 69,9% v…ô 72,5%-in zehirli, iŇüg…ônc…ôli v…ô fakt-t…ôsdiql…ôyici t…ôsdiql…ônm…ôsi √ľ√ß√ľn baŇüa d√ľŇüd√ľ.", 'ca': "Aquest paper presenta la contribució de la Data Science Kitchen de GermEval 2021, tasca compartida en la identificació de comentaris tòxics, interessants i factuals. La tasca mira a estendre l'identificació del llenguatge ofensiu, inclouent subtaskes adicionals que identifiquen comentaris que haurien de ser prioritzats per a la verificació de fets pels moderadors i els gerents de la comunitat. La nostra contribució es centra en un enfocament d'enginyeria de característiques amb un backend de classificació convencional. Combinem incorporacions d'estil semàntic i d'escriptura derivades de xarxes neuronals profundes pré-entrenades amb característiques numèriques adicionals, dissenyades específicament per aquesta tasca. Els Ensembles de classificadors de regressió logística i les Màquines de Suport Vector s'utilitzen per a derivar prediccions per cada subtema a través d'un esquema de votació majoritària. Our best submission achieved macro-averaged F1-scores of 66.8%, 69.9% and 72.5% for the identification of toxic, engaging, and fact-claiming comments.", 'et': 'Käesolevas töös tutvustatakse GermEval 2021. aasta andmeteaduse köögi panust toksiliste, kaasavate ja faktide väidetavate kommentaaride tuvastamisel. Ülesande eesmärk on laiendada solvava keele identifitseerimist, lisades täiendavaid alamülesandeid, mis tuvastavad kommentaarid, mis peaksid olema prioriteetsed moderaatorite ja kogukonna juhtide poolt faktide kontrollimiseks. Meie panus keskendub funktsionaalsele tehnilisele lähenemisviisile, millel on traditsiooniline klassifitseerimise taustaprogramm. Kombineerime semantilise ja kirjutamisstiili manustamise, mis on saadud eelnevalt väljaõpetatud sügavatest närvivõrkudest, täiendavate numbriliste funktsioonidega, mis on spetsiaalselt loodud selleks ülesandeks. Logistilise regressiooni klassifitseerijate ja tugivektorimasinate ansambleid kasutatakse iga alamülesande prognooside tuletamiseks häälteenamuse skeemi kaudu. Meie parim esitus saavutas makrokeskmise F1 skoori 66,8%, 69,9% ja 72,5% toksiliste, kaasavate ja faktidele väidetavate kommentaaride tuvastamiseks.', 'fi': 'Tässä artikkelissa esitellään GermEval 2021:n Data Science Kitchenin panos myrkyllisten, mukaansatempaavien ja faktoja esittävien kommenttien tunnistamiseen. Tehtävällä pyritään laajentamaan loukkaavan kielen tunnistamista lisäämällä siihen lisätehtäviä, jotka tunnistavat kommentteja, jotka tulisi priorisoida valvojien ja yhteisön johtajien tietojen tarkistamiseksi. Panoksemme keskittyy ominaisuuksien suunnitteluun, jossa on perinteinen luokitustausta. Yhdistämme ennalta koulutetuista syvähermoverkoista johdetut semanttiset ja kirjoitustyyliset upotukset tähän tehtävään erityisesti suunniteltuihin numeerisiin ominaisuuksiin. Logistisen regression luokittelijoiden ja tukivektorikoneiden kokoonpanoja käytetään johtamaan ennusteita jokaiselle alatehtävälle enemmistöäänestyksellä. Paras julkaisumme saavutti 66,8%, 69,9% ja 72,5% F1-pisteet myrkyllisten, mukaansatempaavien ja faktoja väittävien kommenttien tunnistamiseksi.', 'cs': 'Tento článek představuje příspěvek Data Science Kitchen na GermEval 2021 sdíleného úkolu na identifikaci toxických, poutavých a faktických komentářů. Cílem úkolu je rozšířit identifikaci urážlivého jazyka, zahrnutím dalších dílčích úkolů, které identifikují komentáře, které by měly být upřednostňovány pro kontrolu faktů moderátory a manažery komunity. Náš příspěvek se zaměřuje na funkční inženýrství s konvenčním klasifikačním backendem. Kombinujeme vkládání sémantického a psacího stylu odvozené z předškolených hlubokých neuronových sítí s dalšími numerickými funkcemi, speciálně navrženými pro tento úkol. Soubory klasifikátorů logistické regrese a podpůrných vektorových strojů slouží k odvození predikcí pro každý dílčí úkol prostřednictvím schématu hlasování většinou. Naše nejlepší podání dosáhlo makro-průměrných F1 skóre 66,8%, 69,9% a 72,5% pro identifikaci toxických, poutavých a faktických komentářů.', 'jv': 'Perintah iki bakal nggawe nyimpen kelas nang Kitken data Sayensi nang Geminval 2020 kuwi bagian nggawe gerakan kanggo ngilangno nggambar torah-torah, ngilangno, lan nglanggar-torah kuwi etik. Mbak saiki wis nambah kanggo nambah keamanan anyar luwih dumadhi, lan gambar tarjamahan liyane sing dumadhi nggawe Komentar sing kudu perintahaan kanggo nguasai pawaran kanggo nguasai pawaran karo modetor lan menejer komunitas. Name We combine semanti and writing style embedding Alpha" for "a", "Bravo" for "b Awak dhéwé sing nglanggar nggawe macro-mediarané kanggo talungkur kanggo 6.8%, 9.9% lan 75.5% kanggo kejahatan pangan toksisan, jewisan, lan pangan-jewisan komentar.', 'he': 'העיתון הזה מציג את התרומה של המטבח המדעי המידע בגרמו-אוול 2021 משימה משותפת על זיהוי ההערות הרעילות, מעניינות ומטענות עובדות. המשימה מתכוונת להאריך את הזהות של שפת פגיעה, בכך שכלול תוצאות נוספות מזהה תגובות שעליהן להעדיפות לבדוק עובדות על ידי מודרטורים ומנהלים קהילתיים. התרומה שלנו מתמקדת על גישה הנדסה-תכונות עם רקע מסווג קונבנסיונלי. אנחנו משלבים תוספות סמנטיות וסגנון כתיבה שנוצרו מרשתות עצביות עמוקות מתאמנות מראש עם תכונות מספריות נוספות, המיועד במיוחד למשימה זו. סמלים של מסגרי חזרה לוגיסטית ומכונות Vector תמיכה משתמשים כדי לקבל חזיונות לכל תחתונה דרך תכנית הצבעה מרוב. הגישה הטובה ביותר שלנו השיגה נקודות F1 בממוצע מקרו של 66.8%, 69.9% ו-72.5% לזהות הערות רעילות, מעורבות ומטענות עובדות.', 'sk': 'V prispevku je predstavljen prispevek kuhinje za znanost podatkov na skupni nalogi GermEval 2021 pri identifikaciji strupenih, privlačnih in dejstvenih komentarjev. Cilj naloge je razširitev identifikacije žaljivega jezika z vključitvijo dodatnih podnalog, ki opredeljujejo komentarje, ki bi jih morali prednostno obravnavati moderatorji in vodje skupnosti. Naš prispevek se osredotoča na pristop funkcijskega inženiringa z običajno klasifikacijsko hrbtenico. Združujemo semantične in pisalne vgradnje iz vnaprej usposobljenih globokih nevronskih omrežij z dodatnimi numeričnimi funkcijami, ki so posebej zasnovane za to nalogo. Skupini klasifikatorjev logistične regresije in podpornih vektorskih strojev se uporabljajo za izpeljavo napovedi za vsako podnalogo prek sheme glasovanja z večino. Naša najboljša predložitev je dosegla makropovprečne ocene F1 66,8%, 69,9% in 72,5% za identifikacijo strupenih, privlačnih in dejstvenih komentarjev.', 'ha': "Wannan takardan na gauraya wa Kiki na Data a Germeval 2021 mai shirin aikin da aka gane shi na zafi, kuma yana haɗa da izni na gaskata. Kayan aikin yana kasancẽwa ƙãra ganin harshen na ƙiyayya, da kuma akwai wasu task õki masu ƙaranci waɗanda ke gane mawaƙo da za'a yi amfani da su ga jarraba gaskiya na da manajan masu motsi da jamii. Bayanmu na muhalli zuwa ga wata mataimaki na masu aikin muhimmi da bakin mai zaman darajawa. Munã haɗa salon na semanti da ke rubũtãwa da bakwai da aka zo daga jerin na zaman-wa'anar neural na ƙari da wasu masu haske, haske da aka ƙayyade wa wannan aikin. KCharselect unicode block name Madagaskiyõyinmu da kyakkyawan aikin F1 ya sami babban matro-score na 66.8%, 69.9 da 7.5%, dõmin an gane shi ga matafiyar giya, da kuma ma'anar gaskiyar.", 'bo': 'ཤོག་བྱང་འདིས་ GermEval 2021ལྟ་བུའི་ནང་དུ་ཡིག་ཆ་སྐྱེན་གྱིས་ཞིབ་ཆའི་གོ་སྐབས་བཤད་ཀྱི་རྐྱེན་སྐྱོང་། བྱ་འགུལ་གྱི་དམིགས་ཡུལ་ནི་ཡིན་སྡུད་དམིགས་ཡུལ་ནི་ཕན་ཚུན་གཏོང་རུང་བ་དང་མཉམ་སྡུད་དོ་དམ་པ་ཚོགས་ཀྱིས་མཁན Our contribution focuses on a feature-engineering approach with a conventional classification backend. We combine semantic and writing style embeddings derived from pre-trained deep neural networks with additional numerical features, specifically designed for this task. ནུས་པ་ལག་ལེན་པའི་ཆེན་རྣམས་དབྱེ་སྟངས་དང་རྒྱབ་སྐྱོར་ཅན་གྱི་སྒོ་འབྱེད་ཀྱི་ལག་ལེན་འཐབ་ཡོད། ང་ཚོའི་ཆེས་མཐའ་མ་ཡུལ་གྱིས་གསལ་བརྗོད་མཁན་66.8%, 69.9% དང 72.5% ཡིས་སྐྱེས་ཚོགས་དང་ཐོག་བཤད་ཀྱི་ནང་འདྲེན་བ་རྐྱེན་ཐུབ་སོང་།'}
{'en': 'HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification', 'ar': 'HunterSpeechLab في GermEval 2021: هل يدعي تعليقك حقيقة؟ الضمانات السياقية لتصنيف تعليقات ادعاء الحقائق الألماني', 'pt': 'HunterSpeechLab no GermEval 2021: seu comentário afirma um fato? Incorporações contextualizadas para classificação alemã de comentários de reivindicação de fatos', 'fr': 'HunterSpeechLab au GermEval 2021\xa0: Votre commentaire revendique-t-il un fait\xa0? Embeddings contextualisés pour la classification des commentaires de revendication de faits allemands', 'es': 'HunterSpeechLab en GermEval 2021: ¿Su comentario afirma ser un hecho? Incrustaciones contextualizadas para la clasificación alemana de comentarios sobre afirmaciones de hechos', 'ja': 'HunterSpeechLab at GermEval 2021:あなたのコメントは事実を主張しますか？ドイツ語の事実を主張するコメント分類のための文脈化された埋め込み', 'zh': 'HunterSpeechLab在GermEval 2021上,君论称实否? 用德语事实声明注类上下文嵌之', 'ru': 'HunterSpeechLab на конференции GermEval 2021: Заявляет ли ваш комментарий о факте? Контекстуализированные вложения для немецкой фактологической классификации комментариев', 'hi': 'GermEval 2021 में हंटरस्पीचलैब: क्या आपकी टिप्पणी एक तथ्य का दावा करती है? जर्मन तथ्य-दावा टिप्पणी वर्गीकरण के लिए संदर्भित एम्बेडिंग', 'ga': "HunterSpeechLab ag GermEval 2021: An Éilíonn Do Trácht Fíricí? Leabaithe Comhthéacsúla d'Aicmiú Tráchtanna Gearmánacha Éilimh ar Fhíricí", 'el': 'Το σχόλιό σας ισχυρίζεται ένα γεγονός; Ενσωματώσεις πλαισίων για γερμανικά σχόλια για ισχυρισμούς γεγονότων Ταξινόμηση σχολίων', 'hu': 'HunterSpeechLab a GermEval 2021-ben: A hozzászólása tényt állít? Kontextualizált beágyazások a német tényállításhoz Comment Osztályozás', 'ka': 'HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment', 'it': 'HunterSpeechLab a GermEval 2021: il tuo commento rivendica un fatto? Integrazioni contestualizzate per la rivendicazione tedesca dei fatti', 'kk': '2021 Гермевальдегі HunterSpeechLab: Түсініктемеңіздің шындығын қалайсыз ба? Неміс факт- классификациялау үшін контекстуалды ендірулерComment', 'mk': 'HunterSpeechLab на GermEval 2021: Дали вашиот коментар тврди факт? Name', 'ms': 'HunterSpeechLab di GermEval 2021: Adakah Komen anda menuntut fakta? Name', 'lt': 'HunterSpeechLab at GermEval 2021: Ar Jūsų komentaras reikalauja fakto? Konkstualizuotos įrangos, skirtos Vokietijos faktų pareiškimo komentarų klasifikacijai', 'ml': 'ഗെര്\u200dമെവാല്\u200d 2021: നിങ്ങളുടെ ക്ലായം A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification', 'mt': 'HunterSpeechLab f’GermEval 2021: Il-Kumment tiegħek jitlob fatt? Embeddings Contextualized for German Fact-Claiming Comment Classification', 'mn': '2021 оны Гермевалд ХантерСпехЛаб: Түүнийг хэлэх үнэн гэж үү? Германы Фактик-Классификацийн контекстүүд', 'no': 'HunterSpeechLab på GermEval 2021: Er kommentaren din løp ein faktus? Comment', 'pl': 'HunterSpeechLab w GermEval 2021: Czy Twój komentarz twierdzi, że jest faktem? Kontekstualizowane osadzenia dla niemieckiej klasyfikacji komentarza faktowego', 'si': 'හැන්ටර් ස්පෙච්ලේබ් ජර්ම් එවෙල් 2021 වල: ඔයාගේ ප්\u200dරතිචාරයක් ඇත්තද? Comment', 'ro': 'HunterSpeechLab la GermEval 2021: Comentariul tău pretinde un fapt? Încorporări contextualizate pentru afirmarea faptelor germane Comentariu Clasificare', 'sr': 'HunterSpeechLab u GermEval 2021: Kontekstualizirani integraciji za njemaèke klasifikacije èinjenica', 'so': 'HunterSpeechLab at GermEval 2021: Je Comment Claim A Fact? Soo wareegayaasha Jarmalka', 'ur': 'GermEval 2021 میں HunterSpeechLab: Does your Comment Claim A Fact? Comment', 'sv': 'HunterSpeechLab på GermEval 2021: Påstår din kommentar ett faktum? Kontextualiserade inbäddningar för tyska faktagranspråk Kommentar Klassificering', 'ta': 'ஜெர்ம்Eval 2021: உங்கள் குறிப்பு A Face? Comment', 'uz': 'Lab at GermEval 2021: Your Comment Claim A Fact? Comment', 'vi': 'Hunter SpeechLab ở GermEvl 2021: Bài phát biểu của anh có thực tế không? Ảnh chiếu tương ứng cho khai thác dữ liệu Đức', 'bg': 'Лаборатория на ДжермЕвал 2021: Коментарът ви твърди ли факт? Контекстualiзирани вграждания за класификация на коментари с твърдения за факти в Германия', 'hr': 'HunterSpeechLab na GermEval 2021: Comment', 'nl': 'HunterSpeechLab bij GermEval 2021: Claimt uw commentaar een feit? Gecontextualiseerde embeddings voor Duitse fact-claiming Comment Classificatie', 'de': 'HunterSpeechLab bei GermEval 2021: Behauptet Ihr Kommentar eine Tatsache? Kontextualisierte Einbettungen für die Klassifizierung der deutschen Faktenklausel', 'id': 'HunterSpeechLab di GermEval 2021: Apakah Komentar Anda Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification', 'ko': 'Germ Eval 2021:당신의 댓글은 이것이 사실이라고 주장합니까?독일 사실 진술 평론 분류의 어경화 삽입', 'sw': 'Lab ya HunterSpeechLab kwenye GermEval 2021: Je Comment Claim A Fact? Comment', 'tr': 'HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment', 'af': "HunterSpeechLab by GermEval 2021: Het u Kommentaar Claim 'n Faak? Comment", 'sq': 'HunterSpeechLab në GermEval 2021: A pretendon komenti juaj një fakt? Embeddings Contextualized for German Fact-Claiming Comment Classification', 'am': 'Lab at GermEval 2021: Is Your Comment Claim A Fact? Comment', 'da': 'HunterSpeechLab på GermEval 2021: Hævder din kommentar et faktum? Kontekstualiserede indlejringer til tysk fact-claying Kommentar Klassificering', 'hy': 'Hunter SpeechLab-ը, ԳերմԷվալ 2021 թվականին. արդյո՞ք ձեր մեկնաբանությունը փաստ է պահանջում: Comment', 'az': 'GermEval 2021-də HunterSpeechLab: Sizin Komutanınız bir həqiqəti iddia edir? Almanca Fakat-Klasifikası üçün Kontekst Yazılımlar', 'fa': 'HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment', 'ca': 'HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact?  Embeddings Contextualized for German Fact-Claiming Comment Classification', 'et': 'HunterSpeechLab GermEval 2021: kas teie kommentaar väidab fakti? Saksa faktide väidetavate kommentaaride klassifitseerimise kontekstualiseeritud manustamised', 'fi': 'HunterSpeechLab GermEvalissa 2021: väittääkö kommenttisi faktaa? Konteksturoidut upotukset saksankielisille faktojen väittämistä koskeville kommenteille', 'cs': 'HunterSpeechLab na GermEval 2021: Tvrdí váš komentář fakt? Kontextualizované vložení pro klasifikaci německých faktů', 'bn': 'গের্মেভাল ২০২১-এ হান্টার স্পেকল্যাব: তোমার গ্লায়াম কি এক ফ্যাক্ট? Comment', 'bs': 'HunterSpeechLab u GermEval 2021: Kontekstualizirani integraciji za njemačku klasifikaciju činjenica', 'jv': 'John Doe ? Name', 'he': 'HunterSpeechLab ב GermEval 2021: האם הערה שלך טוענת עובדה? קישורים קונטקסטוליזציונים לסיפור העובדות הגרמניות', 'sk': 'HunterSpeechLab na GermEvalu 2021: Ali vaš komentar trdi dejstvo? Konteksturirane vdelave za nemško razvrstitev komentarjev za trditev dejstev', 'ha': 'Lab at GermEal 2021: Shin The Claim A Fact? KCharselect unicode block name', 'bo': 'HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? རང་ཉིད་ཀྱི་དོན་དག་ཕྱོགས་སྒྲིག་འགོད་ཀྱི་སྣང་ཚུལ་ལྡན་རྣམ་པ'}
{'en': 'In this paper we investigate the efficacy of using contextual embeddings from multilingual BERT and ', 'ar': 'في هذه الورقة ، نحقق في فعالية استخدام الزخارف السياقية من BERT متعدد اللغات والألمانية BERT في تحديد التعليقات التي تدعي الحقائق باللغة الألمانية على وسائل التواصل الاجتماعي. بالإضافة إلى ذلك ، ندرس تأثير صياغة مشكلة التصنيف كمشكلة تعلم متعددة المهام ، حيث يحدد النموذج السمية والتفاعل مع التعليق بالإضافة إلى تحديد ما إذا كان يدعي الحقائق. نحن نقدم مقارنة شاملة بين النموذجين المعتمدين على BERT مقارنة بخط أساس الانحدار اللوجستي ونبين أن ميزات BERT الألمانية المدربة باستخدام هدف متعدد المهام تحقق أفضل درجة F1 في مجموعة الاختبار. تم تنفيذ هذا العمل كجزء من إرسال إلى مهمة GermEval 2021 المشتركة بشأن تحديد تعليقات ادعاء الحقائق.', 'pt': 'Neste artigo, investigamos a eficácia do uso de embeddings contextuais de BERT multilíngue e BERT alemão na identificação de comentários de alegação de fatos em alemão nas mídias sociais. Além disso, examinamos o impacto de formular o problema de classificação como um problema de aprendizado multitarefa, onde o modelo identifica a toxicidade e o engajamento do comentário, além de identificar se é uma afirmação de fato. Fornecemos uma comparação completa dos dois modelos baseados em BERT em comparação com uma linha de base de regressão logística e mostramos que os recursos de BERT alemães treinados usando um objetivo multitarefa atingem a melhor pontuação F1 no conjunto de teste. Este trabalho foi feito como parte de uma submissão à tarefa compartilhada GermEval 2021 sobre a identificação de comentários de alegação de fatos.', 'es': 'En este artículo investigamos la eficacia del uso de incrustaciones contextuales de BERT multilingües y BERT alemán para identificar comentarios que afirman hechos en alemán en las redes sociales. Además, examinamos el impacto de formular el problema de clasificación como un problema de aprendizaje multitarea, en el que el modelo identifica la toxicidad y el compromiso del comentario, además de identificar si se trata de una afirmación de hechos. Proporcionamos una comparación exhaustiva de los dos modelos basados en BERT en comparación con una línea de base de regresión logística y mostramos que las entidades BERT alemanas entrenadas con un objetivo multitarea logran la mejor puntuación de F1 en el conjunto de pruebas. Este trabajo se realizó como parte de una presentación a la tarea compartida de GermEval 2021 sobre la identificación de comentarios de denuncia de hechos.', 'fr': "Dans cet article, nous étudions l'efficacité de l'utilisation d'intégrations contextuelles du BERT multilingue et du BERT allemand pour identifier les commentaires factuels en allemand sur les réseaux sociaux. En outre, nous examinons l'impact de la formulation du problème de classification en tant que problème d'apprentissage multitâche, où le modèle identifie la toxicité et l'engagement du commentaire en plus de déterminer s'il s'agit d'allégations factuelles. Nous fournissons une comparaison approfondie des deux modèles basés sur BERT par rapport à une base de régression logistique et montrons que les entités BERT allemandes entraînées à l'aide d'un objectif multi-tâches obtiennent le meilleur score F1 sur l'ensemble de tests. Ce travail a été effectué dans le cadre d'une soumission à la tâche partagée GermEval 2021 sur l'identification des commentaires factuels.", 'ja': 'この論文では、ソーシャルメディア上のドイツ語での事実を主張するコメントを特定する際に、多言語のBERTとドイツ語のBERTからの文脈埋め込みを使用することの有効性を調査します。さらに、分類問題をマルチタスク学習問題として定式化することの影響を検討する。そこでは、モデルは毒性とコメントのエンゲージメントを特定し、それが事実主張であるかどうかを特定する。ロジスティック回帰ベースラインと比較した2つのBERTベースモデルの徹底的な比較を提供し、マルチタスク目標を使用して訓練されたドイツのBERT特徴が試験セット上で最高のF 1スコアを達成することを示します。この作業は、事実を主張するコメントの特定に関するGermEval 2021への提出の一部として行われました。', 'zh': '于本文中,研用多言BERT与德语BERT上下文嵌社交媒体识德语事实声明论有效性。 又考分类为多任务学,其形定是非声明之外,定注毒参与度。 二基于BERT,与逻辑归基线周比,明用多任务之所习德国BERT试集上至F1之分也。 此其所以GermEval 2021知事实声明论议之一体也。', 'ru': 'В этой статье мы исследуем эффективность использования контекстных вложений из многоязычных BERT и German BERT в выявлении фактологических комментариев на немецком языке в социальных сетях. Кроме того, мы изучаем влияние формулирования проблемы классификации как многозадачной проблемы обучения, где модель идентифицирует токсичность и вовлеченность комментария в дополнение к определению того, является ли он фактологическим. Мы предоставляем тщательное сравнение двух моделей, основанных на BERT, по сравнению с базовой линией логистической регрессии и показываем, что немецкие функции BERT, обученные с использованием многозадачной цели, достигают лучшего балла F1 на тестовом наборе. Эта работа была выполнена в рамках представления на рассмотрение GermEval 2021 общей задачи по выявлению комментариев с изложением фактов.', 'hi': 'इस पेपर में हम सोशल मीडिया पर जर्मन में तथ्य-दावा टिप्पणियों की पहचान करने में बहुभाषी BERT और जर्मन BERT से प्रासंगिक एम्बेडिंग का उपयोग करने की प्रभावकारिता की जांच करते हैं। इसके अतिरिक्त, हम वर्गीकरण समस्या को बहु-कार्य सीखने की समस्या के रूप में तैयार करने के प्रभाव की जांच करते हैं, जहां मॉडल यह पहचानने के अलावा विषाक्तता और टिप्पणी की सगाई की पहचान करता है कि क्या यह तथ्य-दावा है। हम एक रसद प्रतिगमन आधार रेखा की तुलना में दो BERT आधारित मॉडल की पूरी तरह से तुलना प्रदान करते हैं और दिखाते हैं कि एक बहु-कार्य उद्देश्य का उपयोग करके प्रशिक्षित जर्मन BERT विशेषताएं परीक्षण सेट पर सबसे अच्छा F1 स्कोर प्राप्त करती हैं। यह काम GermEval 2021 साझा कार्य के लिए एक सबमिशन के हिस्से के रूप में किया गया था तथ्य-दावा टिप्पणियों की पहचान पर।', 'ga': 'Sa pháipéar seo déanaimid imscrúdú ar a éifeachtaí atá sé úsáid a bhaint as leabaithe comhthéacsúla ó BERT ilteangach agus ó BERT Gearmáinise chun tráchtanna a éilíonn fíricí i nGearmáinis ar na meáin shóisialta a aithint. Ina theannta sin, scrúdaíonn muid an tionchar a bheadh ag fadhb an aicmithe a fhoirmliú mar fhadhb foghlama il-tasc, áit a n-aithnítear sa tsamhail tocsaineacht agus rannpháirtíocht na tráchtaireachta chomh maith le sainaithint an bhfuil fíoras á éileamh. Cuirimid comparáid críochnúil ar fáil idir an dá mhúnla atá bunaithe ar CRET i gcomparáid le bonnlíne aischéimnithí loighistice agus léirímid go mbaineann gnéithe BERT Gearmánacha oilte ag baint úsáide as cuspóir il-tasc an scór F1 is fearr ar an tacar tástála. Rinneadh an obair seo mar chuid d’aighneacht chuig GermEval 2021 comhthasc maidir le tuairimí a éilíonn fíricí a aithint.', 'hu': 'Ebben a tanulmányban a BERT és a német BERT kontextuális beágyazásainak hatékonyságát vizsgáljuk a közösségi médiában megjelenő, német nyelvű megjegyzések azonosításában. Ezenkívül megvizsgáljuk a besorolási probléma többfeladatos tanulási problémaként való megfogalmazásának hatását, ahol a modell azonosítja a megjegyzés toxicitását és elkötelezettségét, valamint azonosítja, hogy tényállításról van szó. Alapos összehasonlítást nyújtunk a két BERT alapú modell logisztikai regressziós alapjával összehasonlítva, és megmutatjuk, hogy a többfeladatos célkitűzéssel kiképzett német BERT funkciók elérik a legjobb F1 pontszámot a tesztkészleten. Ezt a munkát a GermEval 2021 közös feladatának benyújtása részeként végeztük a tényállító észrevételek azonosításával kapcsolatban.', 'el': 'Σε αυτή την εργασία διερευνούμε την αποτελεσματικότητα της χρήσης περιεχομένων ενσωμάτωσης από πολυγλωσσικό BERT και γερμανικό BERT στον εντοπισμό ισχυριζόμενων γεγονότων σχολίων στα γερμανικά στα μέσα κοινωνικής δικτύωσης. Επιπλέον, εξετάζουμε τον αντίκτυπο της διατύπωσης του προβλήματος ταξινόμησης ως μαθησιακό πρόβλημα πολλαπλών εργασιών, όπου το μοντέλο προσδιορίζει την τοξικότητα και την εμπλοκή του σχολίου, εκτός από τον προσδιορισμό του αν είναι ισχυρισμός γεγονότων. Παρέχουμε μια εμπεριστατωμένη σύγκριση των δύο μοντέλων που βασίζονται στο BERT σε σύγκριση με μια βάση λογιστικής παλινδρόμησης και δείχνουν ότι τα γερμανικά χαρακτηριστικά του BERT που εκπαιδεύονται χρησιμοποιώντας έναν στόχο πολλαπλών εργασιών επιτυγχάνουν την καλύτερη βαθμολογία F1 στο σύνολο δοκιμών. Το έργο αυτό πραγματοποιήθηκε στο πλαίσιο μιας υποβολής στο κοινό έργο της GermEval 2021 σχετικά με τον προσδιορισμό των παρατηρήσεων που ισχυρίζονται γεγονότα.', 'ka': 'ამ დოგომაში ჩვენ შევხედავთ კონტექსტური ინბედინგიების გამოყენება მრავალენგური BERT და გერმანეთის BERT-ის განსაზღვრებით ფაქტის კონტაქტის კონტაქტის გამოყენება საზოგად დამატებით, ჩვენ კლასიფიკაციის პრობლემას ფორმულაციის შესახებ გავაკეთებთ, რომელსაც მოდელემა ტექსტიურობა და კომენტურის შესახებ განვიცნობა თუ არა ეს ფაქტის შესახებ. ჩვენ გვეყენებთ ბერტის ორი მოდელთან დამატებული მოდელების დამატებით ლოგისტიკური რეგრესის ბაზი ხაზი და ჩვენ ჩვენებთ, რომ გერმანეთი BERT ფუნქციები, რომლებიც მრავალ დავალების მიყენებული მიზეზით, გავაკ ეს სამუშაო გავაკეთებულია როგორც ჯერმEval 2021-ში გაყოფილი სამუშაო სამუშაო სამუშაო შესახებ ფაქტის კომენტრების განსაზღვრებაზე.', 'kk': 'Бұл қағазда біз бірнеше тілді BERT және неміс BERT тілдерінің неміс мәліметтерінің жазбаларын анықтау үшін неміс мәліметтерінің жазбаларын қолдануға мүмкіндігін зерттеп отырмыз. Қосымша, біз классификациялау мәселесін бірнеше тапсырма оқыту мәселесі ретінде формуляциялау нәтижесін тексереміз. Бұл үлгі тек қандай тапсырманы анықтау үшін, мәселелердің тәсіліктерінің тоғызд Біз, логистикалық регрессия негізгі жолымен салыстырылған екі BERT негізгі үлгілерді тұрақты салыстырып, неміс BERT қасиеттері бірнеше тапсырма мақсатын қолдану арқылы бірнеше тапсырма мақсатын қолдану үшін те Бұл жұмыс 2021 жылы GermEval-ге ортақ тапсырманы таңдау үшін факты жайлы түсініктемелерді анықтау үшін ортақ тапсырманың бөлігі болды.', 'it': "In questo articolo esaminiamo l'efficacia dell'utilizzo di incorporazioni contestuali di BERT multilingue e BERT tedesco nell'identificare commenti di fatto in tedesco sui social media. Inoltre, esaminiamo l'impatto della formulazione del problema di classificazione come un problema di apprendimento multi-task, dove il modello identifica la tossicità e l'engagement del commento oltre a identificare se è fact-claim. Forniamo un confronto approfondito dei due modelli basati su BERT confrontati con una base di regressione logistica e mostriamo che le caratteristiche BERT tedesche addestrate utilizzando un obiettivo multi-task raggiungono il miglior punteggio F1 sul set di test. Questo lavoro è stato svolto nell'ambito di una presentazione al compito condiviso GermEval 2021 sull'identificazione dei commenti di fatto.", 'mk': 'Во овој весник ја истражуваме ефикасноста на употребата на контекстни вложувања од мултијазичните БЕРТ и Германските БЕРТ во идентификацијата на коментари кои тврдат факти на германски за социјалните медиуми. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming.  Ние обезбедуваме темелна споредба на двата модели базирани на БЕРТ во споредба со логистичката регресна основа и покажуваме дека германските БЕРТ карактеристики тренирани користејќи мултизадачна цел го постигнуваат најдобриот резултат F1 на тестот. Оваа работа беше направена како дел од поднесувањето на GermEval 2021 заедничка задача за идентификација на коментарите кои тврдат факти.', 'ms': 'Dalam kertas ini kami menyelidiki kegagalan menggunakan penyembedding kontekstual dari BERT berbilang bahasa dan BERT Jerman dalam mengenalpasti komentar-mengklaim fakta dalam Jerman pada media sosial. Selain itu, kami memeriksa kesan daripada membentuk masalah klasifikasi sebagai masalah pembelajaran berbilang-tugas, di mana model mengenalpasti toksiciti dan keterlibatan komentar selain mengenalpasti sama ada ia adalah fakta-claiming. Kami menyediakan perbandingan teliti dua model berdasarkan BERT dibandingkan dengan dasar regresi logistik dan menunjukkan bahawa ciri-ciri BERT Jerman dilatih menggunakan objektif berbilang-tugas mencapai skor F1 terbaik pada set ujian. This work was done as part of a submission to GermEval 2021 shared task on the identification of fact-claiming comments.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d സാമൂഹ്യ മാധ്യമങ്ങളില്\u200d നിന്നും പല ഭാഷകങ്ങളില്\u200d നിന്നും ജര്\u200dമ്മന്\u200d ബെര്\u200dട്ടിയില്\u200d നിന്നും അഭിപ്രായം ഉപയോഗിക്കുന് കൂടാതെ, ക്ലാസ്ഫിക്ഷന്\u200d പ്രശ്നത്തിന്റെ പ്രഭാവം നമ്മള്\u200d പരിശോധിക്കുന്നത് പല ജോലി പഠിക്കുന്ന പ്രശ്നങ്ങളായിട്ടാണ്. അതിന്റെ മോഡല്\u200d വിഷയത്തിലും  ഒരു ലോഗിസ്റ്റിക്ക് റിക്രഷന്\u200d ബെസ്റ്റ് ബെര്\u200dട്ടിന്റെ അടിസ്ഥാനത്തുള്ള രണ്ട് മോഡലുകളുടെ തുല്യമായ ഒരു തുല്യമായ തുല്യമാണ് ഞങ്ങള്\u200d നല്\u200dകുന്നത്. പരീക്ഷണസെറ്റി ഗെര്\u200dമെവാല്\u200d 2021-ലേക്ക് കൊടുക്കുന്നതിന്\u200dറെ ഒരു ഭാഗമായി ഈ ജോലി ചെയ്തതാണ് സത്യത്തിന്\u200dറെ അഭിപ്രായത്തിന്\u200dറെ തി', 'mt': 'F’dan id-dokument ninvestigaw l-effikaċja tal-użu ta’ inkorporazzjonijiet kuntestwali minn BERT multilingwi u BERT Ġermaniż fl-identifikazzjoni ta’ kummenti li jsostnu l-fatti fil-Ġermaniż dwar il-midja soċjali. Barra minn hekk, jeżaminaw l-impatt tal-formulazzjoni tal-problem a ta’ klassifikazzjoni bħala problema ta’ tagħlim b’ħafna kompiti, fejn il-mudell jidentifika t-tossiċit à u l-involviment tal-kumment flimkien mal-identifikazzjoni ta’ jekk huwiex dikjarazzjoni ta’ fatti. Aħna nipprovdu tqabbil bir-reqqa taż-żewġ mudelli bbażati fuq BERT meta mqabbel ma’ linja bażi ta’ rigressjoni loġistika u nuru li l-karatteristiċi Ġermaniżi BERT imħarrġa bl-użu ta’ objettiv multikompitu jilħqu l-a ħjar punteġġ F1 fis-sett tat-test. Dan ix-xogħol sar bħala parti minn sottomissjoni lill-GermEval 2021 kompitu komuni dwar l-identifikazzjoni ta’ kummenti li jsostnu l-fatti.', 'mn': 'Энэ цаасан дээр бид олон хэлний BERT болон Герман BERT-ын орчин үеийн төвлөрүүлэлтийг Германы нийгмийн мэдээллийн тухай мэдээллийг тодорхойлж чадахын тулд нөлөөтэй байдлыг судалж байна. Мөн бид хэлбэрийн асуудлыг олон ажлын суралцах асуудлыг тодорхойлох нөлөөг судалж байна. Загварын загвар нь тодорхойлолтой байдлыг тодорхойлдог. Үнэндээ тодорхойлдог эсэхийг тодорхойлдог. Бид Логистикийн регрессийн суурь шулуунтай харьцуулсан хоёр BERT суурь загварын жишээлбэл харьцуулж, Герман BERT нь олон ажлын зорилго ашиглан сургалтын чадварыг харуулж байна. Энэ ажил 2021 оны GermEval-д үнэндээ илэрхийлж буй комментарын тодорхойлолтын тухай хуваалцах ажлын нэг хэсэг болсон.', 'no': 'I denne papiret undersøker vi effektiviteten for å bruka kontekstiske innbygging frå fleirspråk BERT og tysk BERT i å identifisera faktiske kommentarar i tysk på sosiale media. I tillegg undersøker vi effekten til å formera klassifikasjonsprobleten som eit problem med å lære fleire oppgåver, der modellen identifiserer toksikitet og involvering av kommentaren i tillegg til å identifisera om det er faktisk opplæring. Vi tilbyr ein røyd samanlikning av dei to BERT-baserte modelane samanlikna med ein logistisk regresjonsbaselinje og viser at tysk BERT-funksjonar trengte med eit multioppgåvemål gjer det beste F1-poeng på testsettet. Dette arbeidet vart gjort som del av ein tillegg til GermEval 2021 delt oppgåve om identifiseringa av faktisk kommentarar.', 'lt': 'Šiame dokumente mes tiriame, kaip veiksminga naudoti daugiakalbį BERT ir Vokietijos BERT turinčius kontekstinius įterpimus nustatant faktus teigiančias komentaras vokiečių kalba apie social in ę žiniasklaidą. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming.  Mes išsamiai palyginame du BERT pagrįstus modelius, palyginti su logistinės regresijos pradiniu lygiu, ir parodome, kad Vokietijos BERT savybės, parengtos naudojant daugiafunkcinį tikslą, pasiekia geriausią bandymų rinkinio F1 rezultatą. Šis darbas buvo atliktas pateikus „GermEval 2021“ bendrą užduotį nustatyti faktus pareiškančias pastabas.', 'ro': 'În această lucrare investigăm eficacitatea utilizării încorporărilor contextuale de la BERT multilingv și BERT german în identificarea comentariilor în limba germană pe rețelele de socializare. În plus, examinăm impactul formulării problemei de clasificare ca o problemă de învățare multi-task, în cazul în care modelul identifică toxicitatea și implicarea comentariului în plus față de identificarea dacă este o afirmație de fapt. Oferim o comparație aprofundată a celor două modele bazate pe BERT în comparație cu o bază de regresie logistică și arătăm că caracteristicile BERT germane instruite utilizând un obiectiv multi-task obțin cel mai bun scor F1 pe setul de test. Această lucrare a fost realizată în cadrul unei transmiteri către GermEval 2021 a sarcinii comune privind identificarea comentariilor care susțin fapte.', 'sr': 'U ovom papiru istražujemo učinkovitost korištenja kontekstualnih integracija iz multijezičkih BERT-a i njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo uticaj formiranja klasifikacijskog problem a kao problem sa učenjem multizadataka, gde je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi sa početnom linijom logističke regresije i pokažemo da njemačka BERT karakteristika obučena koristeći cilj višezadataka postiže najbolji rezultat F1 na testu. Ovaj rad je urađen kao deo podataka GermEvalu 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.', 'si': 'මේ පත්තරේ අපි පරීක්ෂණය කරනවා සාමාජික මිඩියාවේ ජර්මන් වල සාමාජිකයෙන් ජර්මන් වල සාමාජික ක්\u200dරියාත්මක ප්\u200dරයෝජනය කරන්න ස තවත්, අපි පරීක්ෂා කරන්නේ විශේෂණ ප්\u200dරශ්නයක් වගේ විශේෂණ ප්\u200dරශ්නයක් ගොඩක් වැඩි වැඩක් ඉගෙන ගන්න ප්\u200dරශ්නයක් වගේ, මොඩේල් එකේ විශ අපි BERT පරීක්ෂණයේ හොඳම F1 ස්කෝර් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් පරීක් මේ වැඩේ ජෙර්ම් එව්ල් 2021 වලට පිළිගන්න පුළුවන් කොටසක් විදිහට කරලා තියෙන්නේ ඇත්තටම පිළිගන්න ප්\u200dරශ', 'so': 'Qoraalkan ayaannu ka baaraynaa faa’iidada isticmaalka warqadaha joogtada ah ee BERT iyo Jarmalka BERT si aan ugu ogaano commentarada warqada bulshada ee Jarmalka ah. Sidoo kale waxaynu fiirinaynaa saamaynta u sameynta dhibaatada fasaxda sida dhibaato waxbarasho badan oo kale, kaas oo modelku ku qoran yahay dhibaatada waxbarashada, taas oo ku qoran tijaabada iyo wadashada commentarka iyo sidoo kale ayan aqoonsanaynaa in ay tahay mid ku habboon. Waxaannu sameynaa tusaalaha labada BERT ee asalka ah oo la barbarbaro qoraalka regression baseline, waxaana muujinaynaa in Jarmalka BERT ay ku tababartay isticmaalka shaqo badan, waxay gaadhaa kooxda ugu wanaagsan ee F1 ee imtixaanka. Shaqodaas waxaa loo sameeyay qeyb ka mid ah warqada GermEval 2021 oo lagu sharciyey aqoonsiga commentarada xaqiiqa ah.', 'sv': 'I denna uppsats undersöker vi effekten av att använda kontextuella inbäddningar från flerspråkiga BERT och tyska BERT för att identifiera fakta-hävdande kommentarer på tyska på sociala medier. Dessutom undersöker vi effekten av att formulera klassificeringsproblemet som ett inlärningsproblem med flera uppgifter, där modellen identifierar toxicitet och engagemang av kommentaren samt identifierar om det är faktagranspråk. Vi ger en grundlig jämförelse av de två BERT-baserade modellerna jämfört med en logistisk regressionsvärde och visar att tyska BERT-funktioner som tränats med ett multi-task-mål uppnår bästa F1-poäng i testuppsättningen. Detta arbete gjordes som en del av en inlämning till GermEval 2021 delad uppgift om identifiering av faktabaserade kommentarer.', 'ta': 'இந்த காகிதத்தில் நாம் பல மொழி BERT மற்றும் ஜெர்மன் பிரெட்டில் இருந்து தற்போதைய முழுமையான குறிப்புகளை பயன்படுத்தும் விளைவுகளை தேடுக Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming.  பிரெட் அடிப்படையில் உள்ள இரண்டு பிரெட்டின் மாதிரிகளை ஒப்பிட்டுக் கொண்டு ஜெர்மன் பிரெட்டின் குணங்களை பயன்படுத்தி பல பணிக்காட்டியை பயிற்சி செய்துள் இந்த வேலை ஜெர்ம்வெல் 2021 க்கு ஒரு ஒப்பிட்ட பகிர்ந்த பணியாக செய்யப்பட்டுள்ளது உண்மையான குறிப்பிட்ட குறிப்ப', 'ur': 'ہم اس کاغذ میں متوسط زبان BERT اور جرمن BERT سے متوسط انبودینگ کے استعمال کرنے کے اقتدار کی تحقیق کرتے ہیں جرمن میں سوسیل میڈیا کے ذریعے جرمن کی مثالیں معلوم کرنے کے لئے۔ اور اضافہ، ہم نے کلاسپیٹ مسئلہ کی تعلیم کے مطابق مشکل کی تأثیر کی تحقیق کی ہے، جہاں مدل سمجھ رہا ہے اور مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق م ہم نے دو BERT بنیادی موڈل کے مطابق مطابق مطابق مطابق مقایسہ کی اور دکھا دیتے ہیں کہ جرمن BERT کے مطابق multi-task موضوع کے مطابق تعلیم کی جاتی ہے ایک امتحان سٹ کے سب سے بہترین F1 اسکور کو پہنچ سکتا ہے. یہ کام جرمEval 2021 کے لئے ایک حصہ کے طور پر کیا گیا تھا جو حقیقت کی تصدیق کرنے والی کمانٹروں کے معاملہ میں شریک کام کیا گیا تھا.', 'pl': 'W niniejszym artykule badamy skuteczność wykorzystania kontekstowych osadzeń z wielojęzycznych BERT i niemieckich BERT w identyfikacji komentarzy twierdzących fakty w języku niemieckim w mediach społecznościowych. Dodatkowo badamy wpływ sformułowania problemu klasyfikacji jako wielozadaniowego problemu uczenia się, w którym model identyfikuje toksyczność i zaangażowanie komentarza, a także identyfikuje, czy jest on twierdzący fakty. Przeprowadzamy dokładne porównanie dwóch modeli opartych na BERT w porównaniu z regresją logistyczną i pokazujemy, że niemieckie cechy BERT trenowane przy użyciu obiektu wielozadaniowego osiągają najlepszy wynik F1 w zestawie testowym. Prace te zostały wykonane w ramach zgłoszenia do GermEval 2021 wspólnego zadania dotyczącego identyfikacji uwag twierdzących fakty.', 'uz': "Bu hujjatda biz bir necha tildan BERT va Olmoncha BERT kabi xil tildan foydalanishning effektini o'rganamiz. Olmoniyadagi haqiqiqiy qo'llangan izohlarni ko'paytirish uchun o'rganamiz. Ko'pchilik, biz bir necha vazifa o'rganish muammolari sifatida darajalashtirish muammolarini ko'rib chiqaramiz. Bu yerda model to ʻgʻri va izohni aniqlaydi, bu haqiqiqiy talab qilishini anglatadi. Biz ikkita BERT asosida o'xshash modellarni o'xshash qilamiz va bir necha vazifa obʼektidan foydalanishga o'rganish imkoniyatlarni bir necha qavsga o'rganish imkoniyatlarini sinov sohasida eng eng yaxshi F1 scori bajaradi. Bu ishni GermEval 2021 ga bogʻliq vazifani aniqlash uchun ishga bajarildi.", 'vi': 'Trong tờ giấy này, chúng tôi nghiên cứu hiệu quả của việc sử dụng tác nhân ngữ chung từ BERT đa dạng và BERT Đức để xác định các bình luận về xã hội trên Đức. Thêm vào đó, chúng tôi nghiên cứu tác động của việc phát triển vấn đề phân loại thành vấn đề học tập nhiều nhiệm vụ, nơi mô hình xác định độc tính và cam kết của lời bình luận, thêm vào việc xác định xem nó có được thực tế không. Chúng tôi cung cấp một so sánh hoàn hảo với hai mô hình nền phục hồi hàng hoá được so sánh với một cơ sở hồi quy mô hàng hoá Đức và cho thấy các đặc điểm thiếu sót được huấn luyện bằng nhiều nhiệm vụ đạt được điểm F1 tốt nhất trong bộ thử nghiệm. Việc này được thực hiện như một phần của việc đệ trình cho GermEvl 2021 sẽ có nhiệm vụ chia sẻ về nhận dạng những nhận xét thực tế.', 'da': 'I denne artikel undersøger vi effektiviteten af at bruge kontekstuelle indlejringer fra flersprogede BERT og tyske BERT til at identificere fakta-hævdende kommentarer på tysk på sociale medier. Derudover undersøger vi effekten af at formulere klassificeringsproblemet som et multi-task learning problem, hvor modellen identificerer toksicitet og engagement af kommentaren samt identificerer, om det er faktahævdende. Vi leverer en grundig sammenligning af de to BERT-baserede modeller sammenlignet med en logistisk regression baseline og viser, at tyske BERT-funktioner trænet ved hjælp af et multi-task mål opnår den bedste F1 score på testsættet. Dette arbejde blev udført som en del af en indsendelse til GermEval 2021 delt opgave om identifikation af faktahævdende kommentarer.', 'hr': 'U ovom papiru istražujemo djelotvornost korištenja kontekstualnih integracija iz multijezičkih BERT-a i njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo učinak formuliranja klasifikacijskog problem a kao problem sa učenjem multizadataka, gdje je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi s početnom linijom logističke regresije i pokazujemo da njemačke BERT karakteristike obučene s višezadatačnim ciljem postignu najbolji rezultat F1 na testu. Ovaj rad je učinio kao dio podataka GermEvalu 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.', 'nl': 'In dit artikel onderzoeken we de effectiviteit van het gebruik van contextuele embeddings van meertalige BERT en Duitse BERT bij het identificeren van feiten claimende opmerkingen in het Duits op sociale media. Daarnaast onderzoeken we de impact van het formuleren van het classificatieprobleem als een multi-task leerprobleem, waarbij het model de toxiciteit en betrokkenheid van de opmerking identificeert naast het identificeren van de fact claiming. We bieden een grondige vergelijking van de twee BERT gebaseerde modellen vergeleken met een logistieke regressie baseline en laten zien dat Duitse BERT-functies getraind met behulp van een multi-task objectief de beste F1 score op de testset behalen. Dit werk werd gedaan als onderdeel van een inzending aan GermEval 2021 gedeelde taak over het identificeren van feiten claimende opmerkingen.', 'de': 'In diesem Beitrag untersuchen wir die Wirksamkeit kontextueller Einbettungen von mehrsprachigen BERT und deutschen BERT bei der Identifizierung faktenbezogener Kommentare in Deutsch in sozialen Medien. Darüber hinaus untersuchen wir die Auswirkungen der Formulierung des Klassifizierungsproblems als Mehraufgaben-Lernproblem, wobei das Modell Toxizität und Engagement des Kommentars identifiziert sowie identifiziert, ob es sich um Fakten-Claiming handelt. Wir führen einen gründlichen Vergleich der beiden BERT-basierten Modelle mit einer logistischen Regressionsbasis durch und zeigen, dass deutsche BERT-Features, die mit einem Multi-Task-Ziel trainiert wurden, die beste F1-Punktzahl im Testset erzielen. Diese Arbeit wurde im Rahmen einer gemeinsamen Aufgabe an GermEval 2021 zur Identifizierung faktenbezogener Kommentare durchgeführt.', 'bg': 'В настоящата статия изследваме ефикасността на използването на контекстуални вграждания от многоезични BERT и немски BERT за идентифициране на фактически коментари на немски език в социалните медии. Освен това изследваме въздействието на формулирането на проблема за класификация като проблем с многозадачи за учене, където моделът идентифицира токсичността и ангажираността на коментара в допълнение към идентифициране дали той е фактически претендиращ. Предлагаме задълбочено сравнение на двата модела базирани на базата на логистична регресия в сравнение с базовата линия и показваме, че германските функции, обучени с помощта на многозадача, постигат най-добрия резултат от теста. Тази работа беше направена като част от подаване на споделена задача за идентифициране на фактически коментари.', 'id': 'Dalam kertas ini kami menyelidiki efektivitas menggunakan embedding kontekstual dari BERT berbagai bahasa dan BERT Jerman dalam mengidentifikasi komentar fakta-klaim dalam Jerman pada media sosial. Selain itu, kami memeriksa dampak dari formulasi masalah klasifikasi sebagai masalah belajar multi-tugas, di mana model mengidentifikasi toksicitas dan keterlibatan komentar selain mengidentifikasi apakah itu fakta-klaim. Kami menyediakan perbandingan teliti dari dua model berdasarkan BERT dibandingkan dengan dasar regresi logistik dan menunjukkan bahwa fitur BERT Jerman dilatih menggunakan tujuan multi-tugas mencapai skor F1 terbaik pada set tes. Kerja ini dilakukan sebagai bagian dari pengiriman kepada GermEval 2021 tugas berbagi mengenai identifikasi komentar fakta-claiming.', 'ko': '본고에서 우리는 다어버트와 독일어버트의 언어 환경을 이용하여 소셜 미디어에 독일어 사실 진술 평론을 식별하는 유효성을 연구했다.그 밖에 우리는 분류 문제를 다중 임무 학습 문제로 표현하는 영향도 연구했다. 이 모델은 평론이 사실 성명인지 아닌지를 확인하는 것 외에 평론의 독성과 참여도를 확정했다.우리는 두 개의 버트 기반 모델과 논리 회귀 기선을 철저하게 비교하고 다중 임무 목표 훈련을 사용하는 독일의 버트 특징이 시험집에서 최상의 F1 점수를 얻었다는 것을 나타냈다.이 작업은 GermEval 2021 공유 임무에 제출한 일부분으로 이루어졌으며, 이 임무는 사실을 식별하고 의견을 진술하는 데 관련된다.', 'sw': 'Katika karatasi hii tunachunguza ufanisi wa kutumia vifaa vya kimataifa kutoka kwa lugha mbalimbali vya BERT na Ujerumani BERT katika kutambua maoni yanayodai ukweli nchini Ujerumani kwenye mitandao ya kijamii. Kwa nyongeza, tunachunguza athari ya kutengeneza tatizo la kutangaza darasa kama tatizo la kujifunza kazi nyingi, ambapo model inaonyesha kuchochea na ushirikiano wa maoni hiyo pamoja na kutambua kama ni madai ya ukweli. Tunatoa ulinganisho mkubwa wa mifano miwili yenye msingi wa BERT ukilinganishwa na msingi wa ukandamizaji wa kisiasa na kuonyesha kwamba Ujerumani BERT hususani zilizofundishwa kwa kutumia lengo la kazi nyingi hufanikiwa vipimo bora vya F1 kwenye seti ya mtihani. Kazi hii ilifanyika kama sehemu ya kuutumia ujumbe wa GermEval 2021 ulishirikiana na kazi ya kutambua maoni yanayodai ukweli.', 'tr': "Bu kagyzda biz multi dilli BERT we Almança BERT-nyň multi dilinden duşuşyklary barlamak üçin nemesçe medýädäki suratlaryny tanyşdyrylýarys. Mundan hem, biz klasifikasiýa meseläni bir näçe-täbli öwrenme meseläsi hökmünde soraglaşýarys. Modeli çykyş etmek üçin toksyzlyk we komerniň işbirligini tanap-etmek üçin tanap berer. Biz BERT'yň iki nusgalarynyň logistik regressiýa baseline bilen karşılaşyk çykyşyny we Alman BERT'yň multi-täblik maksadyny ulanyp öwrenmegi mümkin edýän nusgalarynyň üstüne ýetip barýandygyny görkez. Bu işi 2021-nji GermEval'a gönderilýän täzeliklerini barlamak üçin paýlandy.", 'fa': 'در این کاغذ ما از استفاده از وسیله\u200cهای متوسط از BERT و BERT متوسط آلمانی تحقیق می\u200cکنیم تا توضیح\u200cهای حقیقت را در رسانه\u200cهای اجتماعی در آلمان شناسایی کنیم. اضافه\u200cای از این، ما تاثیر فرمول مشکل فرمول\u200cسازی را به عنوان مشکل یادگیری چندین کار تحقیق می\u200cکنیم، جایی که مدل سمی و مشترک توضیح را علاوه بر شناسایی که آیا آن حقیقت\u200cشناسی است، شناسایی می\u200cکند. ما یک مقایسه کامل از دو مدل بنیادی BERT را در مقایسه با یک خط بنیادی بازگشت لوژیک پیشنهاد می\u200cکنیم و نشان می\u200cدهیم که ویژه\u200cهای BERT آلمانی با استفاده از هدف چندین کار آموزش داده شده با بهترین امتیاز F1 در مجموعه آزمایش می\u200cرسد. این کار به عنوان بخشی از تسلیم به جرمEval 2021 کار مشترک در مورد شناسایی توضیح\u200cهای حقیقت\u200cجویی انجام شد.', 'am': 'በዚህ ገጾች ውስጥ የሁለተኛውን የብሬት ቋንቋ እና የጀርመን ብERT ውይይት በጀርመን በማኅበራዊ ሚዲያ ላይ የውሸት ጥያቄዎችን ለማረጋገጥ ጥያቄን እናሳውቃለን፡፡ በተጨማሪም፣ የግንኙነቱን መግለጫ እንደ ብዙ ትምህርት ትምህርት መሆኑን በመፍጠር ላይ እናሳያልን፤ ሞዴል የጥካት እና የመስመር ግንኙነት ማረጋገጥ እውነተኛ ጥያቄ እንደ ሆነ ማረጋገጥ ነው፡፡ በሁለቱ BERT-based ምሳሌዎች በተለየ logistic regression baseline እናሳያቸዋለን፡፡ የጀርመን BERT የብዙዎች አካሄድ በተጠቃሚ ትክክል የተማረ የF1 score በመፈተናው ደረጃ እንዲደርስ እናሳያቸዋለን፡፡ ይህ ሥራ ለጌርEval 2021 የውሸት አካባቢ ትርጉም በማግኘት ላይ የተካፈለ ስራ እንዲሆን ተደረገ፡፡', 'sq': 'Në këtë letër ne hetojmë efektshmërinë e përdorimit të përfshirjeve kontekstuale nga BERT shumëgjuhëse dhe BERT gjermane në identifikimin e komenteve që pretendojnë fakte në gjermanë mbi mediat sociale. Përveç kësaj, ne shqyrtojmë ndikimin e formulimit të problem it të klasifikimit si një problem mësimi me shumë detyra, ku modeli identifikon toksicitetin dhe përfshirjen e komentit përveç identifikimit nëse është fakt-deklarim. Ne ofrojmë një krahasim të plotë të dy modeleve të bazuar në BERT krahasuar me një bazë logjistike të regresionit dhe tregojmë se funksionet gjermane të BERT të trajnuara duke përdorur një objektiv shumëdetyror arrijnë rezultatin më të mirë të F1 në grupin e testimeve. Ky punë u bë si pjesë e një paraqitjeje ndaj GermEval 2021 detyrë të përbashkët mbi identifikimin e komenteve që pretendojnë fakte.', 'af': "In hierdie papier ondersoek ons die effektiviteit van die gebruik van contextual inbêdings van multilinglike BERT en Duitse BERT in die identifiseer van feit-aanklaarde kommentaar in Duitse op sosiale media. In addition, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. Ons verskaf 'n groot vergelyking van die twee BERT gebaseerde modele vergelyk met 'n logistike regresie basislien en wys dat Duitse BERT funksies onderwerp deur 'n multi-taak doel bereik die beste F1 telling op die toets stel. Hierdie werk is gedoen as deel van 'n ondersoek aan GermEval 2021 gedeel taak op die identifiseer van faktuur-aansoek kommentaar.", 'az': "Bu kağıtda, çoxlu dil BERT və Alman BERT'dan müxtəlif məlumatları istifadə etmək üçün Alman dilində çoxlu məlumatları təsdiqləmək üçün istifadə edirik. Daha çox iş öyrənməsi problemi olaraq klasifikasiya problemini, modeli istifadə etmək üçün zehirliyi və şəkillərin istifadəsini təsdiq edir. Biz iki BERT tabanlı modellərin loģistiki regresiya baseline ilə qarşılaşdığı müddətli bir qarşılaşdırmağını təmin edirik və Almanca BERT özelliklərinin çoxlu işlər məqsədilə təhsil edildiyini göstəririk ki, testdə ən yaxşı F1 nöqtəsini nəsib edir. Bu işin 2021 GermEval'a paylaşdığı şəhadətlərin təsdiqlənməsi haqqında paylaşdığı işin bir parças ı olaraq etdi.", 'bn': 'এই পত্রিকায় আমরা সামাজিক মিডিয়ায় জার্মানের বাস্তবতা দাবী করার জন্য বিভিন্ন ভাষায় বিবের্ট এবং জার্মান বার্টি থেকে বিভিন্ন ভাষায় ব তাছাড়াও, আমরা এই ক্লাসাফিকেশনের সমস্যা গঠনের প্রভাব পরীক্ষা করি বহুক্ষেত্র-কাজের শিক্ষা সমস্যা হিসেবে, যেখানে মডেল ব্যস্ত এবং মন্তব্যের অংশগ্রহণের পর We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set.  এই কাজটি গের্মেভাল ২০২১-এর প্রতি প্রদানের একটি অংশ হিসেবে করা হয়েছে বাস্তবতা দাবী করা মন্তব্যের পরিচিতি নিয়ে।', 'bs': 'U ovom papiru istražujemo učinkovitost korištenja kontekstualnih integracija iz multijezičkih BERT i Njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo učinak formiranja klasifikacijskog problem a kao problem sa multizadatačnim učenjem, gdje je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi sa početnom linijom logističke regresije i pokazujemo da njemačka BERT karakteristika obučena koristeći cilj višezadataka postiže najbolji rezultat F1 na testu. Ovaj rad je urađen u sklopu podataka GermEval 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.', 'ca': "En aquest paper investigam l'eficacia d'utilitzar integracions contextuals de BERT multilingüe i BERT alemanya per identificar comentaris que afirmaven fets en alemany en els mitjans socials. A més, examinem l'impacte de la formulació del problem a de classificació com un problema d'aprenentatge multitascat, on el model identifica la toxicitat i l'involucració del comentari a més d'identificar si està afirmant els fets. Ens proporcionem una comparació detallada dels dos models basats en BERT comparat amb una base de regressió logística i demostrem que les característiques alemanes de BERT entrenats fent servir un objectiu multitasc aconsegueixen el millor puntuatge F1 en el conjunt de tests. Aquesta feina va ser feta com part d'una presentació a GermEval 2021 de tasca compartida sobre la identificació de comentaris que afirmaven fets.", 'hy': "Այս թղթի մեջ մենք ուսումնասիրում ենք, թե արդյունավետությունը օգտագործելով բազլեզու BER-ի և գերմանացի BER-ի կոնտեքստոնալ ներդրումներ' հասարակական լրատվամիջոցների մասին գերմանացի լեզվով փաստեր հայտնելու համար: Ավելին, մենք ուսումնասիրում ենք դասակարգման խնդիրը որպես բազմախնդիր ուսուցման խնդիր ձևավորելու ազդեցությունը, որտեղ մոդելը որոշում է մոտեցումների թունավորությունը և ներգրավումը, բացի նրանից, թե արդյոք այն փաստեր է պնդում: Մենք տրամադրում ենք երկու BER-ի հիմնված մոդելների հիմնական համեմատությունը, համեմատելով լոգոստիկ ռեգրեսիայի հիմնական հիմքի հետ, և ցույց ենք տալիս, որ գերմանական BER-ի առանձնահատկությունները, որոնք վարժեցվել են օգտագործելով բազմախնդիր օբ Այս աշխատանքը կատարվել է որպես մի մաս, որը ներկայացվել է Գերմ Էվալ 2021 թվականին ընդհանուր խնդիրը փաստեր պահանջող մեկնաբանությունների հայտնաբերման մասին:", 'cs': 'V tomto článku zkoumáme efektivitu využití kontextových vložení z vícejazyčného BERT a německého BERT při identifikaci faktových komentářů v němčině na sociálních médiích. Dále zkoumáme dopad formulace klasifikačního problému jako multi-tasking learning problému, kde model identifikuje toxicitu a angažovanost komentáře a zároveň identifikuje, zda se jedná o faktické tvrzení. Poskytujeme důkladné srovnání dvou modelů založených na BERT ve srovnání s logistickou regresí základní linií a ukážeme, že německé vlastnosti BERT trénované pomocí multi-tasking objektivu dosahují nejlepšího F1 skóre v testovací sadě. Tato práce byla provedena v rámci předložení společného úkolu GermEval 2021 na identifikaci skutečnostních komentářů.', 'et': 'Käesolevas töös uurime mitmekeelsete BERTi ja saksa BERTi kontekstipõhiste manustamiste tõhusust sotsiaalmeedias faktidele väidetavate kommentaaride tuvastamisel saksa keeles. Lisaks uurime klassifitseerimisprobleemi kui mitmeülesandelise õppeprobleemi sõnastamise mõju, kus mudel tuvastab kommentaari toksilisuse ja kaasatuse lisaks tuvastab, kas see on faktidele väidetav. Pakume põhjalikku võrdlust kahe BERT-põhise mudeli võrreldes logistilise regressiooni algväärtusega ja näitame, et Saksa BERT-funktsioonid, mis on treenitud mitme ülesandega, saavutavad testikomplekti parima F1 skoori. See töö tehti osana GermEval 2021 jagatud ülesandest tuvastada fakte väidetavad kommentaarid.', 'fi': 'Tässä artikkelissa selvitämme monikielisten BERT- ja saksankielisten BERT-upotusten käytön tehokkuutta faktoja väittävien kommenttien tunnistamisessa saksaksi sosiaalisessa mediassa. Lisäksi tarkastelemme luokitteluongelman muotoilun vaikutusta monitehtäväoppimisongelmana, jossa malli tunnistaa kommentin myrkyllisyyden ja sitoutumisen sekä selvittää, onko se faktaesitys. Vertaamme perusteellisesti molempia BERT-pohjaisia malleja logistiseen regressioon ja osoitamme, että monitehtävätavoitteella koulutetut saksalaiset BERT-ominaisuudet saavuttavat parhaan F1-pisteen testisarjassa. Tämä työ tehtiin osana GermEval 2021:n jaettua tehtävää faktoja esittävien kommenttien tunnistamisesta.', 'jv': 'Nang pepulan iki, awak dhéwé nyokot nggunakake effek nggambar embedding contextual karo multilanggar BERT karo BERT nggambar barang kelangan kuwi nggawe Komentar sapa-kedahané ning aleman nganggo media sotiane. Label Awak dhéwé ngewehke perusahaan karo model sing sampek duwé BERT sampek karo perusahaan langgambar barang nggawe barang resmi Wuhané iki wis rampun ning pating nggawe gerapakan dhe germinval 2020 ora bisa ngejaraké perusahaan anyong komentar nggawe barang-barang.', 'sk': 'V tem prispevku raziskujemo učinkovitost uporabe kontekstualnih vdelav večjezičnih BERT in nemških BERT pri prepoznavanju komentarjev v nemščini na družbenih omrežjih. Poleg tega preučujemo vpliv oblikovanja klasifikacijskega problema kot večopravilnega učenja, kjer model identificira toksičnost in vključenost komentarja poleg ugotavljanja, ali gre za trditev dejstev. Zagotovili smo temeljito primerjavo obeh modelov BERT v primerjavi z izhodiščem logistične regresije in pokazali, da nemške funkcije BERT, usposobljene z večopravilnim ciljem, dosegajo najboljšo rezultato F1 v testnem naboru. To delo je bilo opravljeno v okviru predložitve skupne naloge GermEval 2021 za identifikacijo pripomb, ki trdijo dejstva.', 'ha': 'A cikin wannan takarda, Munã yin ƙidãya a kan amfani da matsayin mataimaki daga multi-lingui BERT da Jajeruman BERT dõmin a gane iznin da ke faɗa gaskiya a cikin jeruman a kan mitandan jamii. Ina ƙaranci, Munã jarraba matsalar kunnuwa masu fasalin kamar wata fitina na mai amfani da aiki masu yawa, a inda motel yana gane aikin mai tozarci da kuma ana sami izni da kuma a bayan ka gane shi ko yana madaidaita. Tuna samar da misãlai biyu masu basa BERT sami da kuma a danne logistic regression Baselin kuma Muke nuna cewa karatun BERT na da amfani da abun multi-aikin ya sami mafi kyaun F1 score kan jarraba. Wannan aikin aka samar da shi kamar wani juyi zuwa Germeval 2021 mai shirin aikin da aka samu shi a kan gane na-dai-rayon.', 'he': 'בעיתון הזה אנו חוקרים את היעילות של השימוש בתכניות קונטקסטיות מ-BERT רבשפותית וגרמנית BERT בזיהוי תגובות בעובדות בגרמנית על תקשורת חברתית. בנוסף, אנו בודקים את ההשפעה של התייצבות של בעיית ההקלטה כבעיה ללמוד במשימות רבות, שבו המודל מזהה רעילות ומתערבות של התערבות בנוסף לזהות אם זו טענת עובדות. אנו מספקים שיוואי יסודי של שני הדוגמנים המבוססים על BERT בהשוואה לבסיס גירוס לוגיסטי ומראים שהתכונות גרמניות BERT מאומנות באמצעות מטרה רבה משימות משיגות את הציון F1 הטוב ביותר בסט הבדיקות. העבודה הזו נעשתה כחלק מההועברה לגרמEval 2021 משימה משותפת על זיהוי העובדות טוענות עובדות.', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་སྤྱི་ཚོགས་སྐད་ཡིག་གི་BERT དང་སྐད་ཡིག་BERT་ལས་ཕན་ཚུན་ཐུག་གཏོང་ཁང་ལ་གཏོང་མཁན་གྱི་ལྟ་བ་རྟོགས་བ འོན་ཀྱང་། ང་ཚོས་དབྱེ་རིག་གི་དཀའ་ངལ་སྤྲོད་ཀྱི་ཆ་རྐྱེན་གྱི་དཀའ་ངལ་ཞིབ་དཔྱད་བྱས་ན། We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set. ལས་ཀ་འདི་ནི་(GermEval)སྤྱི་ཚོལ་༢༠༡༢་ལོའི་ནང་དུ་འཇུག་སྣོད་འཛིན་གྱི་ལས་ཀ་གསལ་བཤད་པ་ཞིག་ངོས་འཛིན་བྱེད་སོང་།'}
