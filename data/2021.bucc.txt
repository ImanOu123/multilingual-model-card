{'en': 'Syntax-aware Transformers for Neural Machine Translation : The Case of Text to Sign Gloss Translation', 'ar': 'المحولات المدركة للنحو للترجمة الآلية العصبية: حالة النص لتوقيع ترجمة اللمعان', 'fr': 'Transformateurs sensibles à la syntaxe pour la traduction automatique neuronale\xa0: le cas de la traduction texte-signe Gloss', 'pt': 'Transformadores com reconhecimento de sintaxe para tradução de máquina neural: o caso da tradução com brilho de texto para sinal', 'es': 'Transformadores sensibles a la sintaxis para la traducción automática neuronal: el caso de la traducción brillante de texto a signo', 'ja': '神経機械翻訳のための構文認識トランスフォーマー：グロス翻訳に署名するテキストのケース', 'ru': 'Синтаксис-аудативные трансформаторы для нейронного машинного перевода: случай перевода текста на глянцевый знак', 'zh': '神经机器翻译语法感知转换器:文本署光泽译例', 'hi': 'तंत्रिका मशीन अनुवाद के लिए वाक्यविन्यास-जागरूक ट्रांसफॉर्मर: ग्लॉस अनुवाद पर हस्ताक्षर करने के लिए पाठ का मामला', 'ga': 'Claochladáin atá feasach ar chomhréir le haghaidh Aistriúchán Néar-Inneallta: Cás an Téacs a Shínigh Aistriúchán Snasta', 'el': 'Μετασχηματιστές που γνωρίζουν τη σύνταξη για τη Νευρική Μηχανική Μετάφραση: Η περίπτωση της Μετάφραση Κειμένου προς Σημάδι Γλώσσας', 'hu': 'Szintaxistudatos transzformátorok a neurális gépi fordításhoz: A szöveg és aláírás fényes fordítás esete', 'ka': 'სინტაქსის ცნობიერებული ტრანფორმაციები ნეიროლური მაქსინის გასაგულისხმებისთვის: The Case of Text to Sign Gloss Translation', 'kk': 'Нейрондық машинаны аудару үшін синтаксис түрлендірушілері: The Case of Text to Sign Gloss Translation', 'it': 'Trasformatori compatibili con la sintassi per la traduzione automatica neurale: il caso della traduzione lucida da testo a segno', 'mk': 'Синтакси свесни трансформирачи за превод на неврални машини: Случајот на текст за потпишување на превод на светлина', 'ml': 'Syntax-aware Transformers for Neural Machine Translation: The Case of Text to Sign Gloss Translation', 'mt': 'Trasformaturi konxji mis-sintaxi għat-Traduzzjoni tal-Magna Newrali: Il-Każ tat-Test biex tiġi ffirmata t-Traduzzjoni tal-Gloss', 'mn': 'Синтаксис мэдрэмжтэй шилжүүлэгчдийн мэдрэмжтэй шилжүүлэгч: The Case of Text to Sign Gloss Translation', 'lt': 'Sintaksiniai transformatoriai neuroninių mašinų vertimui: teksto, kuriuo galima pasirašyti sklandų vertimą, atvejis', 'no': 'The Case of Text to Sign Gloss Translation', 'pl': 'Transformatory świadome składni dla neuronowego tłumaczenia maszynowego: przypadek tłumaczenia tekstu na znak', 'ms': 'Penukar sedar-sintaks untuk Penerjemahan Mesin Neural: Kasus Teks untuk Tandatangan Penerjemahan Glos', 'si': 'සංකේතය අවශ්\u200dය වාර්තාවක් සඳහා සංකේතය පරිවර්තනය කරන්න', 'ro': 'Transformatoare conștiente de sintaxă pentru traducerea automată neurală: cazul traducerii lucioase a textului în semn', 'sr': 'Синтаксични трансформатори за превод невралног машина: The Case of Text to Sign Gloss Translation', 'so': 'Translation for Neural machine: The Case of Text to Sign Glus Translation', 'sv': 'Syntaxmedvetna transformatorer för neural maskinöversättning: Fallet med text till signering Gloss Översättning', 'ta': 'நெயுரல் இயந்திரத்தின் மொழிபெயர்ப்புக்கான ஒத்தியக்கூடிய மொழிமாற்றுப்பொருள்', 'ur': 'The Case of Text to Sign Gloss Translation', 'vi': 'Dịch biến hình thần kinh cho máy biến hình thức Syntax nhận thức: the Case of Text to ký Gloss Translation', 'uz': 'Tarjima qilish', 'da': 'Syntaksbevidste transformatorer til Neural maskinoversættelse: Sagen med tekst til tegn Gloss oversættelse', 'nl': 'Syntax-bewuste transformatoren voor neuronale machinevertaling: het geval van tekst naar teken glanzende vertaling', 'de': 'Syntaxbewusste Transformatoren für neuronale maschinelle Übersetzung: Der Fall von Text to Sign Gloss Translation', 'bg': 'Синтаксисни трансформатори за неврален машинен превод: случаят на превод на текст за подписване на гланц', 'hr': 'Prevoditelji s sintaksijom svjesne transformacije neuroloških uređaja: The Case of Text to Sign Gloss Translation', 'fa': 'ترجمه\u200cکننده\u200cهای سنتاکس برای ترجمه ماشین عصبی: The Case of Text to Sign Gloss Translation', 'id': 'Transformer yang menyadari sintaks untuk Translation Mesin Neural: Kasus Teks untuk menandatangani Translation Gloss', 'ko': '신경 기계 번역 중의 문법 감지 변압기: 텍스트에서 기호로의 전환', 'sw': 'Watafsiri wenye ufahamu wa kodi kwa ajili ya Tafsiri ya Mashine ya Njerumani: Kesi ya Maandishi ya Kusaini Tafsiri ya Glus', 'tr': 'Nural Maşynyň terjimesi üçin Sintaks-bilinç Terjimeler: The Case of Text to Sign Gloss Translation', 'am': 'undo-type', 'af': 'Sintaks- bewyse Transformeerders vir Neural Masjien Vertaling: The Case of Text to Sign Gloss Translation', 'hy': 'Նյարդային մեքենայի թարգմանման սինտաքսին գիտակցած թարգմանիչներ. Գլայս թարգմանման նշանակելու տեքստի դեպքը', 'az': 'Nöral Makin Çeviri üçün Sintaksi-Bilən Transformatçılar: The Case of Text to Sign Gloss Translation', 'bs': 'Sintaksijski transformatori za prevod neuroloških strojeva: The Case of Text to Sign Gloss Translation', 'ca': 'Transformers conscients de sintaxis per traducció de màquines neurals: El cas de text per signar traducció de brill', 'sq': 'Transformuesit në dijeni të sintaksave për përkthimin e makinës nervore: rasti i tekstit për të nënshkruar përkthimin e shkëlqimit', 'cs': 'Transformátory neurálního strojového překladu s ohledem na syntaxi: Případ překladu lesku textu na znamení', 'et': 'Süntaksiteadlikud transformaatorid neuroaalse masintõlke jaoks: teksti allkirjastamise juhtum läikivaks tõlkimiseks', 'bn': 'নিউরাল মেশিন অনুবাদের জন্য সিন্ক্স্যাক্স- সচেতন ট্রান্সফার্সার: গ্লাস অনুবাদের স্বাক্ষর করার কেসে', 'fi': 'Syntaksitietoiset muuntajat neurokääntämiseen: Tekstin allekirjoitus kiiltäväksi käännökseksi', 'jv': 'Ngucap Senaksi yang dipunangguna kanggo Ketok Manus Inggal: The Case of Text to Sign', 'ha': '@ info: whatsthis', 'he': 'תורגם ע"י Qsubs ע"י Qsubs מצוות', 'sk': 'Transformatorji, ki se zavedajo sintakse za nevralno strojno prevajanje: primer prevoda besedila za podpis sijaja', 'bo': 'ནུས་མེད་ལག་འཁྱེར་གྱི་སྐད་ཡིག་ཆ་ལྟ་བུའི་དབྱེ་སྟངས་ལ་འགྱུར་ཆས་པ：The Case of Text to Sign Gloss Translation'}
{'en': 'It is well-established that the preferred mode of communication of the deaf and hard of hearing (DHH) community are Sign Languages (SLs), but they are considered low resource languages where natural language processing technologies are of concern. In this paper we study the problem of text to SL gloss Machine Translation (MT) using Transformer-based architectures. Despite the significant advances of MT for spoken languages in the recent couple of decades, MT is in its infancy when it comes to SLs. We enrich a Transformer-based architecture aggregating syntactic information extracted from a dependency parser to word-embeddings. We test our model on a well-known dataset showing that the syntax-aware model obtains performance gains in terms of MT evaluation metrics.', 'es': 'Está bien establecido que el modo de comunicación preferido de la comunidad de personas sordas y con problemas de audición (DHH) son los lenguajes de signos (SL), pero se consideran lenguajes de bajos recursos donde las tecnologías de procesamiento del lenguaje natural son motivo de preocupación. En este artículo estudiamos el problema de la traducción automática (MT) de texto a SL gloss utilizando arquitecturas basadas en Transformer. A pesar de los importantes avances de la MT para los idiomas hablados en las últimas décadas, la MT está en sus inicios en lo que respecta a los SL. Enriquecemos una arquitectura basada en Transformer que agrega información sintáctica extraída de un analizador de dependencias a incrustaciones de palabras. Probamos nuestro modelo en un conjunto de datos bien conocido que muestra que el modelo sensible a la sintaxis obtiene ganancias de rendimiento en términos de métricas de evaluación de MT.', 'pt': 'Está bem estabelecido que o modo de comunicação preferido da comunidade de surdos e deficientes auditivos (DHH) são as Línguas de Sinais (SLs), mas são consideradas línguas de baixo recurso onde as tecnologias de processamento de linguagem natural são uma preocupação. Neste artigo estudamos o problema de tradução automática de texto para SL gloss (MT) usando arquiteturas baseadas em Transformer. Apesar dos avanços significativos da TA para as línguas faladas nas últimas décadas, a TA está em sua infância quando se trata de SLs. Enriquecemos uma arquitetura baseada em Transformer agregando informações sintáticas extraídas de um analisador de dependência para embeddings de palavras. Testamos nosso modelo em um conjunto de dados bem conhecido, mostrando que o modelo sensível à sintaxe obtém ganhos de desempenho em termos de métricas de avaliação de MT.', 'ar': 'من المعروف جيدًا أن الأسلوب المفضل للاتصال لمجتمع الصم وضعاف السمع (DHH) هو لغات الإشارة (SLs) ، لكنها تعتبر لغات منخفضة الموارد حيث تكون تقنيات معالجة اللغة الطبيعية مصدر قلق. في هذا البحث قمنا بدراسة مشكلة النص إلى الترجمة الآلية (MT) باستخدام تقنيات تعتمد على Transformer. على الرغم من التقدم الكبير في الترجمة الآلية للغات المنطوقة في العقدين الأخيرين ، فإن الترجمة الآلية في مهدها عندما يتعلق الأمر بخدمات الترجمة. نحن نثري بنية قائمة على المحولات تجمع المعلومات النحوية المستخرجة من محلل التبعية إلى تضمين الكلمات. نحن نختبر نموذجنا على مجموعة بيانات معروفة جيدًا توضح أن النموذج المدرك للبناء يحصل على مكاسب في الأداء من حيث مقاييس تقييم الترجمة الآلية.', 'fr': "Il est bien établi que le mode de communication préféré des personnes sourdes et malentendantes (DHP) est le langage des signes (SL), mais elles sont considérées comme des langues à faibles ressources pour lesquelles les technologies de traitement du langage naturel sont préoccupantes. Dans cet article, nous étudions le problème de la traduction automatique (MT) de texte en SL brillant à l'aide d'architectures basées sur Transformer. Malgré les avancées significatives de la traduction automatique pour les langues parlées au cours des dernières décennies, la MT en est encore à ses balbutiements en matière de langues parlées. Nous enrichissons une architecture basée sur Transformer qui regroupe les informations syntaxiques extraites d'un analyseur de dépendances vers des intégrations de mots. Nous testons notre modèle sur un ensemble de données bien connu montrant que le modèle sensible à la syntaxe obtient des gains de performance en termes de métriques d'évaluation MT.", 'zh': '众所周知,聋哑人听障塞(DHH)社区首选交流为手语(SL),然以为低资源言语,其自然语言术可忧也。 本文者,治转换器之架构,SL光泽机器翻译(MT)也。 虽数十年间,机器翻译得重大进展于口语,而机器翻译步于SL。 富于 Transformer 之架构,将取句法于解析器。 试我于众集上,明语法知于机器翻译指标也。', 'hi': 'यह अच्छी तरह से स्थापित है कि बहरे और सुनने की कठिन (डीएचएच) समुदाय के संचार का पसंदीदा तरीका साइन लैंग्वेज (एसएल) हैं, लेकिन उन्हें कम संसाधन भाषाओं में माना जाता है जहां प्राकृतिक भाषा प्रसंस्करण प्रौद्योगिकियां चिंता का विषय हैं। इस पेपर में हम ट्रांसफॉर्मर-आधारित आर्किटेक्चर का उपयोग करके एसएल ग्लॉस मशीन ट्रांसलेशन (एमटी) के लिए पाठ की समस्या का अध्ययन करते हैं। हाल के कुछ दशकों में बोली जाने वाली भाषाओं के लिए एमटी की महत्वपूर्ण प्रगति के बावजूद, एमटी अपनी प्रारंभिक अवस्था में है जब यह एसएल की बात आती है। हम एक ट्रांसफॉर्मर-आधारित आर्किटेक्चर को समृद्ध करते हैं जो शब्द-एम्बेडिंग के लिए निर्भरता पार्सर से निकाली गई वाक्यात्मक जानकारी को एकत्रित करता है। हम एक प्रसिद्ध डेटासेट पर अपने मॉडल का परीक्षण करते हैं जो दिखाता है कि वाक्यविन्यास-जागरूक मॉडल एमटी मूल्यांकन मीट्रिक के संदर्भ में प्रदर्शन लाभ प्राप्त करता है।', 'ja': '聴覚障害者および難聴者（ DHH ）コミュニティの好ましいコミュニケーションモードは手話（ SL ）であることは確立されているが、自然言語処理技術が懸念される低資源言語と見なされている。本稿では、Transformerベースのアーキテクチャを使用したSL GLOSS Machine Translation (MT)へのテキストの問題について検討する。ここ数十年、口語のためのMTが大幅に進歩したにもかかわらず、SLに関してはMTは初期段階にあります。依存パーサーから抽出された構文情報をワード埋め込みに集約するトランスフォーマーベースのアーキテクチャを充実させます。私たちは、構文認識モデルがMT評価指標の観点からパフォーマンスの向上を得ることを示す、よく知られたデータセットでモデルをテストします。', 'ru': 'Хорошо известно, что предпочтительным способом общения сообщества глухих и слабослышащих (DHH) являются языки жестов (SL), но они считаются языками с ограниченными ресурсами, где вызывают озабоченность технологии обработки естественного языка. В этой статье мы изучаем проблему преобразования текста в SL Glass Machine Translation (MT) с использованием архитектур на основе трансформаторов. Несмотря на значительные успехи, достигнутые за последние пару десятилетий в использовании МП для разговорных языков, МП находится в зачаточном состоянии, когда речь заходит о СЛ. Мы обогащаем архитектуру на основе Трансформатора, агрегируя синтаксическую информацию, извлеченную из анализатора зависимостей, до словесных вложений. Мы тестируем нашу модель на хорошо известном наборе данных, показывающем, что синтаксис-аудированная модель получает прирост производительности с точки зрения метрик оценки MT.', 'ga': 'Tá sé bunaithe go maith gurb é an modh cumarsáide is fearr le daoine bodhra agus lagéisteachta (DHH) ná Teangacha Comharthaíochta (SLanna), ach meastar gur teangacha íseal-acmhainne iad agus is ábhar imní iad teicneolaíochtaí próiseála teanga nádúrtha. Sa pháipéar seo déanaimid staidéar ar fhadhb an téacs go SL gloss Machine Translation (MT) ag baint úsáide as ailtireachtaí Trasfhoirmeoir-bhunaithe. In ainneoin an dul chun cinn suntasach atá déanta ag MT do theangacha labhartha le scór bliain anuas, tá MT ina thús nuair a thagann sé go dtí SL. Saibhrímid ailtireacht atá bunaithe ar Trasfhoirmeoir a chomhbhailíonn faisnéis chomhréire a bhaintear as parsálaí spleáchais go leabaithe focal. Déanaimid tástáil ar ár múnla ar thacar sonraí aitheanta a thaispeánann go bhfaigheann an tsamhail atá feasach ar chomhréir gnóthachain feidhmíochta i dtéarmaí méadrachta meastóireachta MT.', 'hu': 'Megállapított, hogy a süket és hallássérültek (DHH) közösségének preferált kommunikációs módja a jelnyelvek (SLs), de ezeket alacsony forrású nyelveknek tekintik, ahol a természetes nyelvfeldolgozási technológiák aggodalomra adnak okot. Ebben a tanulmányban a Transzformátor alapú architektúrák segítségével tanulmányozzuk a szöveg SL fényességének (MT) problémáját. Annak ellenére, hogy az elmúlt néhány évtizedben a beszélt nyelvek tekintetében az MT jelentős előrelépéseket mutatott be, az MT még csecsemőkorában van, amikor az SL-kről van szó. Gazdagítunk egy Transformer-alapú architektúrát, amely a függőség-elemzőből kinyert szintaktikus információkat a szó-beágyazásokba aggregálja. Modellünket egy jól ismert adatkészleten teszteljük, amely kimutatja, hogy a szintaxistudatos modell teljesítménynövekedést ér el az MT értékelési mutatók szempontjából.', 'kk': 'Қар және тыңдау күтпеген (DHH) коммуникациясының қосылым түрі - қолтаңбалау тілдер (SL) деген жақсы құрылған, бірақ олар табиғлық тілдерді өңдеу технологияларының қатынасы бар ресурстар тілдерінің төмен тілд Бұл қағазда біз мәтіндің мәселесін SL gloss Machine Translation (MT) архитектураларды қолдану архитектураларды зерттейміз. Жуырдағы жылдық жылдық MT тілдерінің маңызды өзгертілігіне қарамастан, MT балаларында SL-ге қатысты. Біз түрлендіруші архитектураны бағаладық, синтактикалық мәліметті, тәуелдік талдаушынан сөздерді ендіру үшін алып тастаған. Біз моделімізді белгілі деректер жиынында тексереміз, синтаксис түсінікті үлгісі MT бағалау метрикалық қасиеттерінде жылдамдығын алады.', 'lt': 'Gerai nustatyta, kad geriausia kurčių ir klausomųjų bendruomenės (DHH) ryšių forma yra ženklų kalbos (SL), tačiau jos laikomos mažai išteklių turinčiomis kalbomis, kurioms kelia susirūpinimą natūralios kalbos apdorojimo technologijos. In this paper we study the problem of text to SL gloss Machine Translation (MT) using Transformer-based architectures.  Nepaisant reikšmingos MT pažangos kalboms per pastaruosius kelis dešimtmečius, MT yra pirmą kartą, kai kalbama apie SL. Mes praturtiname Transformuotoje grindžiamą architektūrą, apibendrinančią sintaksinę informaciją, gautą iš priklausomybės analizatoriaus į žodžių įterpimus. Mūsų model į išbandome gerai žinomu duomenų rinkiniu, rodančiu, kad sintaksui žinomas modelis gauna rezultatų pagerėjimą MT vertinimo metrijos atžvilgiu.', 'mk': 'Добро е утврдено дека преферираниот начин на комуникација на глувите и тешките слушање (DHH) заедници се јазици на знаци (SL), но тие се сметаат за јазици со ниски ресурси каде што природните технологии за обработување јазици се загрижени. Во овој весник го проучуваме проблемот со текстот на SL gloss Machine Translation (MT) користејќи трансформни архитектури. И покрај значителните напредоци на МТ за разговараните јазици во последните неколку децении, МТ е во свое детство кога станува збор за СЛ. We enrich a Transformer-based architecture aggregating syntactic information extracted from a dependency parser to word-embeddings.  Ние го тестираме нашиот модел на познат податок кој покажува дека моделот со свесност за синтаксија добива придобивки во однос на метриката на оценката на МТ.', 'el': 'Είναι καθιερωμένο ότι ο προτιμώμενος τρόπος επικοινωνίας της κοινότητας κωφών και κωφών (DHH) είναι οι Νοηματικές Γλώσσες (SLs), αλλά θεωρούνται γλώσσες χαμηλού πόρου όπου οι τεχνολογίες επεξεργασίας φυσικής γλώσσας αποτελούν αντικείμενο ανησυχίας. Στην παρούσα εργασία μελετάμε το πρόβλημα της μηχανικής μετάφρασης κειμένου σε γυαλιστερή μηχανική μετάφραση (ΜΤ) χρησιμοποιώντας αρχιτεκτονικές βασισμένες σε μετασχηματιστή. Παρά τις σημαντικές προόδους της ΜΤ για τις ομιλούμενες γλώσσες τις τελευταίες δεκαετίες, η ΜΤ είναι στα νηπιακά της χρόνια όταν πρόκειται για τις ΜΤ. Εμπλουτίζουμε μια αρχιτεκτονική βασισμένη στον μετασχηματιστή συγκεντρώνοντας συντακτικές πληροφορίες που εξάγονται από έναν αναλυτή εξάρτησης σε ενσωμάτωση λέξεων. Δοκιμάζουμε το μοντέλο μας σε ένα γνωστό σύνολο δεδομένων που δείχνει ότι το μοντέλο που γνωρίζει τη σύνταξη επιτυγχάνει κέρδη απόδοσης όσον αφορά τις μετρήσεις αξιολόγησης ΜΤ.', 'it': "È risaputo che il modo di comunicazione preferito della comunità di sordi e ipoacusici (DHH) sono i linguaggi dei segni (SLs), ma sono considerati linguaggi a bassa risorsa dove le tecnologie di elaborazione del linguaggio naturale sono di preoccupazione. In questo articolo studiamo il problema del testo a SL gloss Machine Translation (MT) utilizzando architetture basate su Transformer. Nonostante i progressi significativi della MT per le lingue parlate negli ultimi due decenni, MT è nella sua infanzia quando si tratta di SLs. Arricchiamo un'architettura basata su Transformer che aggrega informazioni sintattiche estratte da un parser di dipendenze a incorporazioni di parole. Testiamo il nostro modello su un set di dati ben noto, dimostrando che il modello consapevole della sintassi ottiene guadagni di performance in termini di metriche di valutazione MT.", 'mt': 'Huwa stabbilit sew li l-mod preferut ta’ komunikazzjoni tal-komunità tas-sordi u tas-smigħ diffiċli (DHH) huma Lingwi Sinjali (SLs), iżda huma kkunsidrati lingwi b’riżorsi baxxi fejn it-teknoloġiji tal-ipproċessar tal-lingwi naturali huma ta’ tħassib. F’dan id-dokument nistudjaw il-problema tat-test għat-Traduzzjoni SL tal-Magni Gloss (MT) bl-użu ta’ arkitetturi bbażati fuq Transformer. Minkejja l-avvanzi sinifikanti tal-MT għal-lingwi mitkellma f’dawn l-aħħar għexieren ta’ snin, il-MT tinsab fl-infanzja tagħha fir-rigward tal-SLs. Aħna nagħmlu arrikkiment f’arkitettura bbażata fuq it-Transformer li tgħaqqad l-informazzjoni sintattika estratta minn analizzatur tad-dipendenza għal inkorporazzjonijiet tal-kliem. Aħna ntestjaw il-mudell tagħna fuq sett ta’ dejta magħruf sew li juri li l-mudell konxju mis-sintaks jikseb kisbiet fil-prestazzjoni f’termini ta’ metriċi ta’ evalwazzjoni MT.', 'ml': 'സ്വാഭാവിക ഭാഷയുടെ സാങ്കേതികമായ സാങ്കേതികവിദ്യയുടെയും കഠിനമായ വായിക്കേള്\u200dപ്പിന്റെയും മികച്ച രീതിയില്\u200d സ്ഥാപിക്കപ്പെടുന്നു ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d എസ്എല്\u200d ഗ്ലാസ് മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിന്\u200dറെ പ്രശ്നം പഠിക്കുന്നു. ട്രാന്\u200dസ്ഫോര്\u200dമാ സംസാരിക്കുന്ന ഭാഷകള്\u200dക്കുള്ള എംടിയുടെ ഏറ്റവും പ്രധാനപ്പെട്ട മുന്നോട്ടുണ്ടെങ്കിലും കഴിഞ്ഞ രണ്ടു കൊല്ലങ്ങളില്\u200d എ ആശ്രയിക്കുന്ന പാര്\u200dട്ടിങ്ങില്\u200d നിന്നും വാക്ക് അകത്തേക്ക് പുറത്തെടുക്കപ്പെട്ട സിന്\u200dടാക്ടിക്ക് വിവരങ്ങള്\u200d കൂട്ട ഞങ്ങള്\u200d നമ്മുടെ മോഡല്\u200d പരീക്ഷിക്കുന്നു. സിന്റാക്സ് പരിശോധിക്കുന്ന മോഡല്\u200d എംടി വിലാസപ്രകാരം മെട്രിക്കുകളില്\u200d നിന്നും പ', 'mn': 'Хуух, хэцүү сонсох (DHH) нийгмийн холбоотой холбоотой байдал нь Хүсэг хэл (SLs) гэдгийг сайн ойлгосон. Гэхдээ тэд байгалийн хэл үйлдвэрлэх технологиудын тухай бага боломжтой хэл гэж боддог. Энэ цаасан дээр бид SL gloss Machine Translation (MT) болон Трансфер суурь барилгуудыг ашиглан текстын асуудлыг судалж байна. Сүүлийн хэдэн арван жилийн дотор ярианы хэлний MT-ийн чухал хөгжлийн үр дүнд орж байгаа ч, MT нь SL-ийн хүүхдүүдэд байдаг. Бид Трансформер суурилсан архитектурыг хамтын синтактик мэдээллийг хамтын хамааралтай хуваарилагчдын хувьд нэмэгдүүлсэн. Бид өөрсдийн загварыг мэдэх өгөгдлийн хэлбэрээр шалгаж үзүүлдэг. Синтаксис мэдэх загвар нь MT-ын оюутнуудын метрик хэлбэрээр ажиллагааны зарцуулалт авдаг гэдгийг харуулж байна.', 'ms': 'Ia ditetapkan dengan baik bahawa mod komunikasi yang disukai bagi komuniti pekak dan keras pendengaran (DHH) adalah Bahasa Tanda (SL), tetapi mereka dianggap bahasa sumber rendah di mana teknologi pemprosesan bahasa alami adalah bimbang. Dalam kertas ini kami mempelajari masalah teks ke SL gloss Machine Translation (MT) menggunakan arkitektur berasaskan Transformer. Walaupun kemajuan yang signifikan dari MT untuk bahasa bercakap dalam beberapa dekade terakhir, MT masih kecil apabila ia berkaitan dengan SL. Kami memperkaya arkitektur berasaskan Transformer yang menggabungkan maklumat sintaktik yang dikeluarkan dari penghurai dependensi ke penyembedding perkataan. Kami menguji model kami pada set data yang diketahui menunjukkan bahawa model yang sedar-sintaks mendapatkan keuntungan prestasi dalam terma metrik penilaian MT.', 'ro': 'Este bine stabilit faptul că modul preferat de comunicare al comunității surzi și cu deficiențe de auz (DHH) sunt limbile semnelor (SL), dar acestea sunt considerate limbi cu resurse reduse în cazul în care tehnologiile de prelucrare a limbajului natural sunt de îngrijorare. În această lucrare studiem problema textului în SL gloss Machine Translation (MT) folosind arhitecturi bazate pe Transformer. În ciuda progreselor semnificative ale MT pentru limbile vorbite în ultimele decenii, MT este la început atunci când vine vorba de SLs. Îmbogățim o arhitectură bazată pe Transformer, agregând informații sintactice extrase dintr-un parser de dependență la încorporări de cuvinte. Testăm modelul nostru pe un set de date bine cunoscut care arată că modelul conștient de sintaxă obține câștiguri de performanță în ceea ce privește măsurătorile de evaluare MT.', 'pl': 'Jest dobrze ustalone, że preferowanym sposobem komunikacji osób niesłyszących i niesłyszących (DHH) są języki migowe (SLs), ale są one uważane za języki niskiego zasobu, w których niepokojące są technologie przetwarzania języków naturalnych. W niniejszym artykule badamy problem tłumaczenia maszynowego tekstu na połysk SL (MT) z wykorzystaniem architektur opartych na transformatorze. Pomimo znaczących postępów MT dla języków mówionych w ostatnich kilku dekadach, MT jest w powiatkach, jeśli chodzi o SLs. Wzbogacamy architekturę opartą na Transformerze agregującą informacje składniowe wyodrębnione z parsera zależności do osadzeń słów. Testujemy nasz model na dobrze znanym zbiorze danych pokazującym, że model świadomy składni uzyskuje wzrost wydajności w zakresie wskaźników oceny MT.', 'sr': 'Dobro je utvrđeno da je preferirani režim komunikacije gluh i teškog saslušanja (DHH) zajednice znakovi jezika (SL), ali se smatra niskim jezicima resursa gdje su tehnologije obrade prirodnog jezika zabrinuta. U ovom papiru proučavamo problem teksta na SL gloss Machine Translation (MT) koristeći arhitekture na transformeru. Uprkos značajnim napredovima MT-a za govore jezike u poslednjih par decenija, MT je u svojoj maloj djetinjstvi kad se radi o SLS-u. Obogaæavamo arhitekturu na transformaciji koji okuplja sintaktièke informacije izvuèene iz analizatora zavisnosti do ukljuèenja reèi. Testiramo naš model na poznatom setu podataka pokazujući da model svesti sintaksa dobija dobitak izvedbe u smislu metrika MT procjene.', 'ka': 'ძალიან დარწმუნებული იქნება, რომ ძალიან ძალიან ძალიან სხვადასხვა საზოგადოებო (DHH) საზოგადოებო კომუნიკაციის პროგრამი იქნება სიმბოლო ენები (SLs), მაგრამ ისინი აღმოჩნდება მარტივი ამ დოკუნეში ჩვენ ტექსტის პრობლემა SL დლასის მაქსინის გასაგრძელება (MT) გამოყენებული ტრანფორმების აქტიქტურების გამოყენება. MT-ის მნიშვნელოვანი წარმოდგენებისთვის შემდეგ ბოლო წარმოდგენებისთვის, MT-ს თავის ბავშვებში, როდესაც SLs-ზე მოდის. ჩვენ ტრანფორმეტრის დაფარდებული არქტიქტურის აღქტიქტურაცია, რომელიც სინტექტიკური ინფორმაციის აღქტრებულია, რომელიც დადაფარდებულობის პანსერიდან სიტ ჩვენ ჩვენი მოდელის მოცემული მონაცემების შესახებ, რომელსაც სინტაქსის შესახებ მოდელის მონაცემულება მიიღება MT განსაზღვრების მეტრიკის შესახებ.', 'si': 'ඒක හොඳට ස්ථාපනය කරලා තියෙන්නේ බහුරු සහ අහන්න හරි සමාජාත්මක සංවේදනය (DHH) සමාජාත්මක ස්ථාපනය භාෂාවක් (SLs), නමුත් ඔවුන් අඩ මේ පත්තරේ අපි ප්\u200dරශ්නයක් පරිවර්තනය කරන්නේ පත්තරේ ප්\u200dරශ්නය SL ග්\u200dලෝස් මෙෂින් පරිවර්තනය (MT) වලට පරි MT ගේ වැදගත් වැඩේ අන්තිම දහස් දෙකක් වලින් කතා කරපු භාෂාවට වැඩ කරන්න තිබුණා නමුත්, MT එක තමයි SLs වලින් ඉන්නේ ඒ අපි ප්\u200dරවර්තනයක් අධාරිත විද්\u200dයාපකයක් සම්බන්ධ විද්\u200dයාපකය සම්බන්ධ විද්\u200dයාපක තොරතුරු සම්බන්ධ විද්\u200dය අපි අපේ මොඩල් පරීක්ෂා කරනවා හොඳින් දත්ත සූදානයක් පෙන්වන්න පුළුවන් විදිහට MT විශ්ලේෂණ මෙට්\u200dරික්ස් වල', 'so': "Waxaa si wanaagsan loo xaqiijiyey in qaabka la xiriira kuwa dhega la' iyo dhegaha maqalka (DHH) ay yihiin luqadaha saxiibka (SLs), laakiin waxaa looga xisaabiyaa luqadaha hoose ee rasmi ah, meesha ay ka baaraandegiso teknolojiyada afka dabiiciga ah. Qoraalkan waxaynu ku baranaynaa dhibaatada matxafka ee SL gloss machine tarjumaadda (MT) isticmaalaya taariikhda asalka ah. Inta kastoo ay horumarinta MT ee luqadaha lagu hadlo ee ugu dambeeyey labadii decadood, MT waxay ku jirtaa dhalmada marka uu soo gaadho SLs. We enrich a Transformer-based architecture aggregating syntactic information extracted from a dependency parser to word-embeddings.  Tusaalkayaga waxaan ku tijaabinaynaa kooxda macluumaadka si fiican loo yaqaan, waxan tusinayaa in qaabka sameynta ee la aqoonsan yahay uu helo sameynta qaababka qiimeynta MT.", 'no': 'Det er veldig oppretta at den foretrukte modus for kommunikasjon av den døve og vanskeleg hørringsfolkningen (DHH) er Sign Languages (SLs), men dei vert kalla som lave ressursspråk der naturspråkshandteringsteknologiar er bekymret. I denne papiret studerer vi problemet med teksten til SL gloss Machine Translation (MT) med Transformer-basert arkitektur. Til tross av dei viktige avanserte MT for talespråk i de siste par tiår, er MT i infanten når det kommer til SLs. Vi røyk eit transformeringsarkitektur som koplar syntaksisk informasjon ut frå ein avhengighetsanalyser til ordinnbygging. Vi testar modellen vårt på eit godt kjent datasett som viser at syntaksmerke modellen får utviklingar i form av MT-evalueringsmetrikar.', 'ur': 'بہتر معلوم ہے کہ بہرے اور سخت سننے والے (DHH) جماعت کی پیغام کی ترجیح کی حالت نشانی زبانیں (SLS) ہیں، لیکن ان کو کم منبع زبانیں سمجھی جاتی ہیں جہاں طبیعی زبان پردازی تکنولوژی کا ذمہ دار ہے. ہم اس کاغذ میں متن کا مسئلہ SL گلوس ماشین ترجمہ (MT) کی استعمال کرتے ہیں۔ اچھے دو دستور میں MT کی بڑی بڑی پیشرفت کے باوجود، جب وہ SLS کے پاس آتا ہے تو MT اس کے بچے میں ہے۔ ہم نے ایک ترنسفور بنیادی معماری امکانات کو ثروت بخشی جسے ایک ڈیرنسیٹ پارٹر سے واپس-ایمبڈینگ کی طرف اٹھایا گیا ہے۔ ہم اپنے مدل کو ایک خوب جانتا ڈیٹ سٹ پر امتحان کرتے ہیں کہ سینٹکس جانتا ہوا موڈل MT evaluation metrics کے مطابق کامیابی حاصل کرتا ہے۔', 'sv': 'Det är väletablerat att det föredragna kommunikationssättet för döva och hörselskadade (DHH) samhället är teckenspråk (SLs), men de anses vara lågresursspråk där teknik för bearbetning av naturligt språk är oroande. I denna uppsats studerar vi problemet med text till SL gloss Machine Translation (MT) med Transformer-baserade arkitekturer. Trots de betydande framstegen av MT för talade språk under de senaste decennierna är MT i sin linda när det gäller SLs. Vi berikar en Transformer-baserad arkitektur som aggregerar syntaktisk information som extraheras från en beroendetolkare till ordinbäddningar. Vi testar vår modell på en välkänd datauppsättning som visar att den syntaxmedvetna modellen uppnår prestandaförbättringar i termer av MT-utvärderingsmetoder.', 'ta': 'செவிடர்கள் மற்றும் கேட்கும் கடினமான (DHH) சமூகத்தின் விருப்பமான தொடர்பு முறைமையை சரியாக நிறுவப்படுத்தப்பட்டுள்ளது ஆனால் இயல்பான மொழி செயல்பாட இந்த காகிதத்தில் நாம் உரையின் பிரச்சனையை SL கண்ணாடி இயந்திரம் மொழிபெயர்ப்பு (MT) மாற்று அடிப்படையில் உள்ள அடிப் அண்மையில் அண்மையில் பேசும் மொழிகளுக்கு MT முன்னேற்றங்கள் இருந்தாலும், எஸ்எல்களுக்கு வரும்போது MT குழந்தை நாம் மாற்று அடிப்படையில் உள்ள அடிப்படைப்புகளை செலுத்துகிறோம். சார்ந்த சார்பு பரிசுத்தம் இருந்து வெளியேற்றப்பட்ட ஒ நாம் எங்கள் மாதிரியை ஒரு நன்றாக அறியப்பட்ட தரவுத்தளத்தில் சோதிக்கிறோம் அது தெரியும் ஒத்திசைப்படுத்தும் மாதிரி MT மதிப்ப', 'vi': 'Rõ ràng là cách giao tiếp ưa thích của cộng đồng điếc và khó nghe (DHH) là Ngôn ngữ dấu hiệu (SL) nhưng chúng được coi là ngôn ngữ ít tài nguyên, nơi công nghệ xử lý ngôn ngữ tự nhiên có liên quan. In this paper we study the problem of text to L glophí Machine Translation (MTV) using transformer-based kiến trúc. Mặc dù các bước tiến quan trọng của kênh MTV về ngôn ngữ được phát biểu trong vài thập kỷ gần đây, kênh MTV đang mới khởi đầu khi nói về trượt tuyết. Chúng tôi giàu một kiến trúc Transformer để tổng hợp các thông tin cú pháp chiết xuất từ một phân tích phụ thuộc tới sự nhúng vào từ. Chúng tôi thử nghiệm mẫu của chúng tôi trên một tập tin nổi tiếng cho thấy rằng mô hình thức cú pháp nhận thức đạt được lợi nhuận nhờ lượng đo tổ chức MTV.', 'uz': "Name Bu qogʻozda biz SL gloss Mashini tarjima qilish (MT) uchun matn muammosini o'rganamiz. Yaqinda ko'pchilik yillarda gapiradigan tillar uchun MT'ning muhim darajasi bo'lsa ham, MT'ning chaqaloqlarida SLs'ga kelayotganda. Biz o'zgarishga asoslangan tashkilotlarni tasdiqlash uchun qo'shilgan sintaktik maʼlumotini ko'paydik. Biz yaxshi taʼminlovchi maʼlumotlar tarkibida modelimizni sintaksa modeli MT qiymati metriklarini bajaradi.", 'nl': 'Het is duidelijk dat de voorkeurswijze van communicatie van doven en slechthorenden (DHH) gebarentalen (SLs) zijn, maar ze worden beschouwd als laagdrempelige talen waar natuurlijke taalverwerkingstechnologieën van belang zijn. In dit artikel bestuderen we het probleem van tekst naar SL gloss Machine Translation (MT) met behulp van Transformer-gebaseerde architecturen. Ondanks de aanzienlijke vooruitgang van MT voor gesproken talen in de afgelopen decennia, MT staat in de kinderschoenen als het gaat om SLs. We verrijken een op Transformer gebaseerde architectuur die syntactische informatie aggregeert uit een afhankelijkheidsparser naar woord-embeddings. We testen ons model op een bekende dataset waaruit blijkt dat het syntaxisbewuste model prestatiewinst behaalt in termen van MT-evaluatiestatistieken.', 'da': 'Det er veletableret, at den foretrukne kommunikationsmåde for døve og hørehæmmede (DHH) samfund er tegnsprog (SLs), men de betragtes som sprog med lav ressource, hvor teknologier til behandling af natursprog er af betydning. I denne artikel undersøger vi problemet med tekst til SL gloss Machine Translation (MT) ved hjælp af Transformer-baserede arkitekturer. På trods af de betydelige fremskridt med MT for talte sprog i de seneste par årtier, MT er i sin barndom, når det kommer til SLs. Vi beriger en Transformer-baseret arkitektur, der samler syntaktiske oplysninger udvundet fra en afhængighedsfortolker til ordindlejringer. Vi tester vores model på et velkendt datasæt, der viser, at den syntaksbevidste model opnår performance gevinster i form af MT evalueringsmetrics.', 'bg': 'Установено е, че предпочитаният начин на комуникация на общността на глухите и трудно слуховите (ДХХ) са жестовите езици, но те се считат за езици с нисък ресурс, където технологиите за обработка на естествените езици представляват безпокойство. В настоящата статия изследваме проблема с текста до гланцов машинен превод (МТ), използвайки архитектури на базата на трансформатори. Въпреки значителния напредък на МТ за говорените езици през последните няколко десетилетия, МТ е в ранна детска възраст, когато става въпрос за СЛ. Ние обогатяваме базирана на трансформатор архитектура, обединяваща синтактична информация, извлечена от анализатор на зависимости към вграждане на думи. Тестваме модела си на добре познат набор от данни, показващ, че моделът, осъзнаващ синтаксиса, постига подобрения по отношение на показателите за оценка на МТ.', 'de': 'Es ist allgemein bekannt, dass die bevorzugte Art der Kommunikation von Gehörlosen und Schwerhörigen (DHH) Gebärdensprachen (SLs) sind, aber sie gelten als ressourcenarme Sprachen, wo natürliche Sprachverarbeitungstechnologien von besonderem Interesse sind. In diesem Beitrag untersuchen wir das Problem der maschinellen Übersetzung von Text zu SL Gloss (MT) unter Verwendung von Transformer-basierten Architekturen. Trotz der erheblichen Fortschritte der MT für gesprochene Sprachen in den letzten Jahrzehnten, ist MT in Bezug auf SLs noch in den Kinderschuhen. Wir bereichern eine Transformer-basierte Architektur, die syntaktische Informationen aus einem Abhängigkeitsparser zu Wort-Einbettungen aggregiert. Wir testen unser Modell an einem bekannten Datensatz, der zeigt, dass das syntaxbewusste Modell Leistungszuwächse in Bezug auf MT-Bewertungsmetriken erzielt.', 'hr': 'Dobro je utvrđeno da je preferirani način komunikacije gluh i teškog saslušanja zajednice (DHH) znakovi jezika (SL), ali se smatra niskim jezicima resursa gdje su tehnologije obrade prirodnog jezika zabrinuta. U ovom papiru proučavamo problem teksta na SL gloss Machine Translation (MT) koristeći arhitekture na transformeru. Unatoč značajnim napredovima MT-a za govorne jezike u posljednjih nekoliko desetljeća, MT je u svojoj djetinjstvu kad se radi o SLS-ima. Obogaćavamo arhitekturu na transformatoru koja skuplja sintaktične informacije izvučene iz analizatora zavisnosti do uključenja riječi. Testiramo naš model na poznatom setu podataka pokazujući da model svjesnog sintaksa dobija dobitak učinkovitosti u smislu metrika MT procjene.', 'id': 'Sudah ditentukan dengan baik bahwa mode komunikasi yang disukai dari komunitas tuli dan keras pendengaran (DHH) adalah bahasa tanda (SL), tetapi mereka dianggap bahasa sumber daya rendah di mana teknologi proses bahasa alami adalah khawatir. Dalam kertas ini kami mempelajari masalah teks ke SL gloss Machine Translation (MT) menggunakan arsitektur berdasarkan Transformer. Meskipun kemajuan yang signifikan dari MT untuk bahasa berbicara dalam beberapa dekade terakhir, MT berada di masa kanak-kanak ketika itu berkaitan dengan SL. Kami memperkaya arsitektur berdasarkan Transformer yang menggabungkan informasi sintaks yang diekstraksi dari parser dependensi ke embedding kata. Kami menguji model kami pada set data yang dikenal menunjukkan bahwa model yang sadar sintaks mendapatkan keuntungan prestasi dalam terma metrik evaluasi MT.', 'ko': '청각장애인과 중청인(DHH) 커뮤니티의 선호 교류 방식은 수화(SLs)로 알려져 있지만, 자연 언어 처리 기술이 주목받는 곳에서는 수화가 저자원 언어로 꼽힌다.본고에서 우리는 변환기 기반의 텍스트부터 기계번역(MT) 문제를 연구했다.비록 최근 몇 십 년 동안 구어 기계 번역은 중대한 진전을 거두었지만 기계 번역은 SLs 방면에서 여전히 시작 단계에 있다.우리는 의존항 해석기에서 추출한 문법 정보를 단어에 삽입하는 변환기 기반 구조를 풍부하게 했다.우리는 유명한 데이터 집합에서 우리의 모델을 테스트한 결과 문법 감지 모델이 기계 번역 평가 지표에서 성능을 향상시켰다는 것을 알 수 있다.', 'sw': 'Inawekwa vizuri kwamba njia ya mawasiliano ya viziwi na vigumu ya kusikiliza (DHH) ni lugha za saini (SLs), lakini wanachukuliwa kuwa lugha ndogo ya rasilimali ambazo teknolojia za asili zina wasiwasi. Katika karatasi hii tunasoma tatizo la maandishi kwa Tafsiri ya Mashine ya Siasa (MT) kwa kutumia majengo yenye asili ya Transfer. Pamoja na maendeleo makubwa ya MT kwa lugha zinazozungumza katika miongo miwili ya hivi karibuni, MT yuko kwenye utotoni wake pale inapofika kwenye mashirika ya SLs. We enrich a Transformer-based architecture aggregating syntactic information extracted from a dependency parser to word-embeddings.  Tunajaribu mtindo wetu kwenye seti ya taarifa maarufu inayoonyesha kuwa modeli inayofahamika na kodi inapata ufanisi unaofanika kwa njia za uchunguzi wa MT.', 'sq': 'Është e vendosur mirë se mënyra e preferuar e komunikimit të komunitetit të shurdhër dhe të vështirë të dëgjimit (DHH) janë gjuhët e sinjalizuara (SL), por ato konsiderohen gjuhë me burime të ulëta ku janë shqetësuese teknologjitë natyrore të procesimit të gjuhës. Në këtë letër ne studiojmë problemin e tekstit në SL gloss Machine Translation (MT) duke përdorur arkitektura me bazë në Transformer. Megjithë përparimet e rëndësishme të MT për gjuhët e folura në disa dekada të fundit, MT është në fëmijërinë e saj kur vjen puna për SL. Ne e pasurojmë një arkitekturë me bazë në Transformer duke mbledhur informacion sintaktik të nxjerrë nga një analizues varësie në përfshirje fjalësh. Ne testojmë model in tonë në një grup të dhënash të njohur që tregon se modeli i ndërgjegjshëm për sintaksi merr fitime performancash në lidhje me metrikat e vlerësimit MT.', 'fa': 'در حالی که ترجیح داده شده\u200cای از ارتباطات جامعه\u200cهای کران و سخت شنیدن (DHH) زبان\u200cهای نشانه\u200cای (SLS) است، ولی آنها زبان\u200cهای منابع پایین به نظر می\u200cآیند که تکنولوژی\u200cهای پرداخت زبان طبیعی در آن اهمیت دارند. در این کاغذ ما مشکل متن را به ترجمه ماشینی SL gloss (MT) با استفاده از معماری\u200cهای بنیاد ترجمه\u200cکننده مطالعه می\u200cکنیم. با وجود پیشرفت مهمتری از MT برای زبان صحبت در چند دهه اخیر، MT در کودکان خود در زمان رسیدن به SLs است. ما یک معماری بنیاد تغییر\u200cدهنده را ثروتمند می\u200cکنیم که اطلاعات سنتاکتیک را جمع می\u200cکند که از یک پالایه\u200cدهنده بستگی به پالایه\u200cهای کلمات استخراج شده است. ما مدل خود را روی یک مجموعه داده شناخته می\u200cکنیم که نشان می\u200cدهد که مدل آگاهی از سنتاکس به عنوان متریک ارزیابی MT برنده\u200cهای فعالیت می\u200cیابد.', 'tr': 'Gulaý we diňlemek kyn (DHH) jemgyýetiniň (Sign Languages) sözleriniň tercih edilen nusgasy (SLs) diýip kabul edildi, ýöne tebigy dil işleýän teknolojileriň aladasynyň azajyk dillerini düşünýärler. Bu kagyzda biz SL gloss Makina Terjime (MT) bilen metin meselesini öwrenýärik. Son ýylda gürleýän diller üçin MT öňünden täsirli gelişmelere rağmen, MT-iň SLs-iň çagasynda. Biz Transformer tabanly bir arhitektura baglanýarys. Bir baglançydan kelime baglançysyna golaýlaýan sintaktik maglumaty çykarýarys. Biziň modelimizi tanaýan bir datasetede barýarys. Sintaks-tanyş modeliniň MT deňleme metriklerinde etkinlik gazanlygyny görkezýär.', 'am': 'የደንቆሮዎች እና የመስማት ደንቆሮዎች የደንቆሮዎች እና የመስማት ቋንቋዎች (SLs) የተመረጠው መልዕክት እንደተደረገ መልካም ነው፤ ነገር ግን የፍጥረት ቋንቋ ቴክኖሎጂ ተሟጋቾች የሆኑት የክፍል ቋንቋዎች ናቸው፡፡ በዚህ ገጽ የጽሑፉን ጉዳይ ወደ SL የድምፅ መኪን ትርጓሜ (MT) በተከታተለ የመዝገብ መሠረቶች እናስተምራለን፡፡ በአለፉት ሁለት ዐሥር ዓመታት የንግግር ቋንቋዎች የሚናገሩ የMT ግንኙነት ምንም እንኳ ቢሆንም MT ወደ SLs በመጣበት ጊዜ በሕፃንነቱ ውስጥ ነው፡፡ በተመሳሳይ ተቃዋሚው ተቃዋሚዎች ወደ word-embedding ያወጣ የSyntactic መረጃዎችን እናሳድጋለን፡፡ የሲንካስብ ሞዴል የMT ማስታወቂያ ሚትርክቶችን እንዲያገኝ የሚታየው የድምፅ ማድረግ እንዲያገኝ እናስፈትናለን፡፡', 'af': "Dit is goed vasgestel dat die voorkeur modus van kommunikasie van die doof en moeilikheid van hoor gemeenskap (DHH) teken tale (SLs) is, maar hulle word aangesien as lae hulpbron tale waar natuurlike taal-verwerking teknologie is van bekommerding. In hierdie papier ondersoek ons die probleem van teks na SL glos Masjien Vertaling (MT) deur te gebruik Transformer-gebaseerde arkitektuure. Terwyl die betekende avansies van MT vir praat tale in die onlangse paar dekades, is MT in sy infancy wanneer dit kom na SLs. Ons ryk 'n Transformer-gebaseerde arkitektuur wat saamgeneem sintaktieke inligting wat uit 'n afhanklikheidspanseerder na woord-inbêding uitgevoer is. Ons probeer ons model op 'n goed bekende datastel wat wys dat die sintaks-bevestig model voorspoediging verskaf in terms of MT evaluering metries.", 'hy': 'Լավ հաստատված է, որ խուլ և դժվար լսող համայնքի (ԴՀՀ) հաղորդակցման ամենասիրելի միջոցը նշանակում են լեզուներ, բայց դրանք համարվում են ցածր ռեսուրսների լեզուներ, որտեղ անհանգստացնում են բնական լեզվի վերամշակման տեխնոլոգիաները: Այս թղթի մեջ մենք ուսումնասիրում ենք տեքստի խնդիրը ՍԼ-ի լուսավոր մեքենայի թարգմանություն (ՄԹ) օգտագործելով Transforme-ի հիմնված ճարտարապետություններ: Despite the significant advances of MT for spoken languages in the recent couple of decades, MT is in its infancy when it comes to SLs.  Մենք հարստանում ենք տրանֆորմային հիմնված ճարտարապետություն, որը համախմբում է սինտակտիկ տեղեկությունը, որը ստացվում է կախվածության վերլուծողից մինչև բառերի ներգրավումներ: Մենք փորձում ենք մեր մոդելը լավ հայտնի տվյալների համակարգի վրա, որը ցույց է տալիս, որ սինտաքսի գիտակցած մոդելը ստանում է արդյունավետության բարձրացում MT գնահատման մետրիկայի տեսքով:', 'az': "Sağır və eşitmək çətinliklərinin (DHH) toplumların əlaqəsi möcüzə dillərindir, lakin onlar təbiətli dil işləmə teknolojilərinin məxluqatı haqqında düşük qüvvət dillərini hesab edirlər. Bu kağızda, transformer-tabanlı arhitektürlər vasitəsilə SL gloss Machine Translation (MT) üçün metin problemini öyrənirik. Son on il içində söyləyən dillər üçün MT'nin möhkəm ilerliyinə baxmayaraq, MT SL ilə gəldiyi zaman çox uşaqlıdır. Biz Transformer-tabanlı arhitektura ehtiyac edirik ki, sintaktik məlumatları bir bağlılıq parçacısından sözlər-içərisinə çıxarılır. Biz modelimizi tanıdıqları verilənlər qutusunda sınayırıq ki, sintaksis-aware model in in MT değerlendirmə metrikləri ilə performans kazandığını göstərir.", 'bn': 'এটা ভালোভাবে স্থাপন করা হয়েছে যে বধির এবং শুনানোর কঠিন যোগাযোগের পছন্দ মোড (ডিএইচএইচ) সম্প্রদায় স্বাক্ষর করে ভাষা (এসএলএস), কিন্তু তাদের বিবেচনা কর এই কাগজটিতে আমরা এসএল গ্ল্যাস মেশিন অনুবাদ (এমটি) ট্রান্সফার্ন ভিত্তিক কাঠামো ব্যবহার করে টেক্সটের সমস্যা পড়ি। Despite the significant advances of MT for spoken languages in the recent couple of decades, MT is in its infancy when it comes to SLs.  আমরা একটি ট্রান্সফার্ন ভিত্তিক কাঠামো সমৃদ্ধ করি যা একটি নির্ভরিত প্যারেন্সি প্যারেডিং থেকে বের করা সিন্ট্যাকটিক তথ্ আমরা আমাদের মডেল পরীক্ষা করছি একটি পরিচিত ডাটাসেটে যেখানে দেখা যাচ্ছে যে সিন্যাক্স-সচেতন মডেল এমটি মূল্যায়ন মেটিকের মাধ্যমে', 'bs': 'Dobro je utvrđeno da je preferirani način komunikacije gluh i teškog saslušanja (DHH) zajednice znakovi jezika (SL), ali se smatra niskim jezicima resursa gdje su tehnologije obrade prirodnog jezika zabrinute. U ovom papiru proučavamo problem teksta na SL gloss Machine Translation (MT) koristeći arhitekture na transformeru. Uprkos značajnim napredovima MT-a za govorne jezike u poslednjih nekoliko decenija, MT je u svojoj djetinjstvu kada se radi o SLS-ima. Obogaćavamo arhitekturu baziranu na transformatoru koja skuplja sintaktične informacije izvučene iz analizatora zavisnosti do uključenja riječi. Testiramo naš model na poznatom setu podataka pokazujući da model svjesnog sintaksa dobija dobitak izvođenja u smislu metrika MT procjene.', 'cs': 'Je dobře zjištěno, že preferovaným způsobem komunikace neslyšících a neslyšících (DHH) komunity jsou znakové jazyky (SLs), ale jsou považovány za jazyky s nízkými zdroji, kde jsou technologie zpracování přirozeného jazyka znepokojující. V tomto článku se zabýváme problematikou strojového překladu textu do SL lesku (MT) pomocí architektur založených na transformátoru. Navzdory významnému pokroku MT v mluvených jazycích v posledních několika desetiletích je MT v plenkách, pokud jde o SLs. Obohacujeme architekturu založenou na transformátoru, která agreguje syntaktické informace extrahované z parseru závislostí na vložení slov. Testujeme náš model na dobře známé datové sadě, která ukazuje, že model orientovaný na syntaxi dosahuje zvýšení výkonu z hlediska metrik hodnocení MT.', 'et': 'On kindlaks tehtud, et kurtide ja kuulmispuudega inimeste eelistatud suhtlusviisiks on viipekeeled, kuid neid peetakse vähese ressursiga keelteks, kus looduskeelte töötlemise tehnoloogiad tekitavad muret. Käesolevas töös uurime teksti probleemi SL läikivaks masintõlkeks (MT), kasutades Transformer-põhiseid arhitektuure. Vaatamata MT märkimisväärsele arengule räägitavate keelte puhul viimastel aastakümnetel, on MT SLi puhul alles lapsepõlves. Me rikastame transformaatoril põhinevat arhitektuuri, mis koondab sõltuvuspartserist saadud süntaktilise teabe sõnade manustamiseks. Testime oma mudelit tuntud andmekogumiga, mis näitab, et süntaksiteadlik mudel saavutab tulemuslikkuse kasvu MT hindamise mõõdikutes.', 'ca': "És ben establit que el mètode preferit de comunicació de la comunitat surda i difícil d'entendre (DHH) són Llingues de signes (SLs), però són considerades llengües de baix recursos on les tecnologies naturals de processament de llengües són preocupants. En aquest paper estudiem el problema del text a la traducció de la màquina brillant SL (MT) utilitzant arquitectures basades en Transformer. Malgrat els avanços significatius de la MT per les llengües parlades en les últimes dècades, MT està en infancia quan es tracta dels SL. enriquecem una arquitectura basada en Transformer agrupant informació sinàctica extraïda d'un analitzador de dependencies a integracions de paraules. Testem el nostre model en un conjunt de dades conegut mostrant que el model conscient de la sintaxi obté guanys de rendiment en termes de mètriques d'evaluació MT.", 'fi': 'On vakiintunut, että kuurojen ja kuulovammaisten (DHH) yhteisön ensisijainen viestintämuoto ovat viittomakielet (SLs), mutta niitä pidetään vähävaraisina kielinä, joissa luonnolliset kielenkäsittelytekniikat aiheuttavat huolta. Tässä työssä tutkitaan tekstin ongelmaa SL gloss Machine Translation (MT) käyttäen Transformer-pohjaisia arkkitehtuureja. Vaikka MT on edistynyt huomattavasti puhuttujen kielten parissa viime vuosikymmeninä, MT on SLS:n suhteen vasta lapsenkengissään. Hyödynnämme muuntajapohjaista arkkitehtuuria yhdistämällä riippuvuuden parserista saadut syntaktiset tiedot sanaupotuksiin. Testaamme malliamme tunnetulla aineistolla, joka osoittaa, että syntaksitietoinen malli saavuttaa suorituskykyä mittausmittareiden suhteen.', 'jv': 'Punika dipun-perusahaan langkung rawuh akeh komunikasi karo akeh bantuan lan sakjane kanggo nglarakno (DHH) Dino Singa-Sign Languages Nang pepulan iki kita isih perbudhakan kanggo kelas teks kanggo SL luwih Manus Terjamahan (MT) nggambar aturan sing basa Transformer MT iku, ngrebut mbok atusan akeh pengguna anyar luwih dumadhi kayané kapan mrih, MT dumadhi kapan sithik dumadhi kapan SMs. Awak dhéwé ngweapon sistem sing paling transformer batir architecture Awak dhéwé éntuk model nyeneng ngerasakno dadi sing bisa diutag barang seneng manut karo model sing gawe barang nggawe barang manut karo MT nyong wektu manit', 'ha': "An daidaita shi da shirin da aka fi son wasiyyar da ma'abũcin saurãre da ƙeƙasassin saurãre (DHH) sunan Siki Lugha (SLs), kuma amma ana ƙaddara su da harshen marãye masu rauni da kuma masu shagala technogi na masu hushi. @ info Bayan zaman taɓa na MT wa lugha waɗanda aka yi wa magana a cikin takwai biyu na farko, MT yana cikin babyensa idan ta zuwa SLs. Ina wadãtar da wani matsayi na Transformer mai gauraya da information na samun syntactic wanda aka fito daga wani parse zuwa word-embedded. Tuna jarraba misalinmu a kan wani tsarin da aka sani mai bayani, yana nuna cewa misalin-mai-gaya na samu'a sami cikin metric muhalli na MT.", 'he': 'It is well-established that the preferred mode of communication of the deaf and hard of hearing (DHH) community are Sign Languages (SLs), but they are considered low resource languages where natural language processing technologies are of concern.  בעיתון הזה אנחנו לומדים את הבעיה של טקסט לתרגום מכונת גלוס SL (MT) באמצעות ארכיטקטורות מבוססת Transformer. למרות התקדמות המשמעותיות של MT לשפות מדברות בשנתיים האחרונים, MT נמצאת בתינוקות כשמדובר בס.ל. אנחנו מעשירים ארכיטקטורה מבוססת על טרנספורטר שמאספת מידע סינטקטי מווצא מעבד תלויות לתכניות מילים. אנחנו בודקים את המודל שלנו על קבוצת נתונים ידועה היטב שמראה שהמודל מודע לסינטקס מקבל תרופות ביצועים במטריות הערכה MT.', 'sk': 'Ugotovljeno je, da so najprimernejši način komunikacije gluhovih in slabo slušnih (DHH) skupnosti znakovni jeziki, vendar se štejejo za jezike z nizkimi viri, kjer so zaskrbljene tehnologije obdelave naravnih jezikov. V prispevku preučujemo problem besedila v slovenski strojni prevod (MT) z uporabo transformatorskih arhitektur. Kljub znatnemu napredku MT za govorjene jezike v zadnjih nekaj desetletjih je MT v otroštvu, ko gre za SLs. Obogatujemo arhitekturo na podlagi transformatorja, ki združuje sintaktične informacije, pridobljene iz razčlenjevalnika odvisnosti, v vdelave besed. Naš model testiramo na dobro znanem naboru podatkov, ki kažejo, da model, ki se zaveda sintakse, doseže večjo uspešnost v smislu meritev vrednotenja MT.', 'bo': 'རང་ཉིད་ཀྱི་སྤྱི་ཚོགས་ཀྱི་གཟུགས་རིས་འདིའི་མཐུན་རིམ་དང་མཐུན་པར་དགའ་བའི་ཐབས་ལམ་དེ་ནི་ཤེས་ཡོད་པའི་སྐད་ཡིག་གཟུགས་རིས། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་SL ཡི་གླེང་སྒྲོམ་གྱི་ནང་དུ་ཡིག་གི་དཀའ་ངལ་འདི་ལྟ་བུ་རྩོལ་བསྐྱེད་པ་གཞི་བཟ དེ་འདས་བའི་ལོ་བཅུ་ལྷག་པའི་ནང་དུ་MT(MT)ཡི་སྐད་རིགས་ལ་འགྱུར་བར་ཆེན་པོ་ཞིག་ལ་བསྟུན། We enrich a Transformer-based architecture aggregating syntactic information extracted from a dependency parser to word-embeddings. ང་ཚོའི་མིག'}
{'en': 'Employing Wikipedia as a resource for Named Entity Recognition in Morphologically complex under-resourced languages', 'pt': 'Empregando a Wikipedia como um recurso para reconhecimento de entidades nomeadas em linguagens morfologicamente complexas com poucos recursos', 'es': 'Emplear Wikipedia como recurso para el reconocimiento de entidades nombradas en idiomas morfológicamente complejos y de escasos recursos', 'ja': '形態学的に複雑でリソース不足の言語での名前付きエンティティ認識のリソースとしてのウィキペディアの採用', 'ar': 'استخدام ويكيبيديا كمصدر للتعرف على الكيان المحدد في اللغات المعقدة شكليًا قليلة الموارد', 'hi': 'रूपात्मक रूप से जटिल कम संसाधन वाली भाषाओं में नामित इकाई मान्यता के लिए एक संसाधन के रूप में विकिपीडिया को नियोजित करना', 'fr': "Utilisation de Wikipédia comme ressource pour la reconnaissance d'entités nommées dans les langues morphologiquement complexes et sous-ressources", 'ga': 'Vicipéid a úsáid mar acmhainn le haghaidh Aitheantas Aonán Ainmnithe i dteangacha atá casta go leor de na hacmhainní nach bhfuil mórán acmhainní acu', 'ru': 'Использование Википедии в качестве ресурса для распознавания именованных сущностей в морфологически сложных языках с недостаточным объемом ресурсов', 'zh': '以维基百科为形之不足者,名曰实体', 'ka': 'ვიკიპედიას როგორც რესურსის გამოყენება მოპოლოგიურად კომპლექსიურად გამოყენებული ინტერტის განახლებისთვის', 'hu': 'A Wikipédia használata forrásként a nevezett entitások felismeréséhez morfológiailag összetett alacsony erőforrásokkal rendelkező nyelveken', 'el': 'Χρήση της Βικιπαίδειας ως πόρου για την Αναγνώριση Οντότητας σε Μορφολογικά σύνθετες γλώσσες που δεν διαθέτουν πόρους', 'it': 'Utilizzare Wikipedia come risorsa per il riconoscimento delle entità nominate in linguaggi morfologicamente complessi con risorse insufficienti', 'kk': 'Википедияға Марфологиялық көптеген тілдерде аталған нысандарды анықтау ресурсы ретінде қолдану', 'lt': 'Wikipedia naudojimas kaip vardinio subjekto pripažinimo šaltinis morfologiškai sudėtingomis nepakankamai išteklių turinčiomis kalbomis', 'mk': 'Користење на Википедија како ресурс за препознавање на именувани ентитети на морфолошки комплексни јазици со недоволни ресурси', 'ml': 'വിക്കിപിഡിയ വിഭവങ്ങളായി മോര്\u200dഫോളോഗിക്കല്\u200d വിഭവങ്ങളില്\u200d പേരുള്ള എന്റിറ്റി തിരിച്ചറിയുന്നതിനുള്ള വിഭവങ്', 'ms': 'Menggunakan Wikipedia sebagai sumber untuk Pengenalan Entiti bernama dalam bahasa yang kompleks secara morfologik dibawah sumber-sumber', 'mt': 'L-użu tal-Wikipedia bħala riżorsa għar-Rikonoxximent tal-Entità Ismija f’lingwi morfoloġikament kumplessi b’riżorsi baxxi', 'mn': 'Википедийг Морфологик хэл дээр нэрлэгдсэн Нэгтийн Recognition болон', 'no': 'Bruk Wikipedia som ressurs for gjenkjenning av namnet entitet i morfologisk komplekse underressurserte språk', 'ro': 'Utilizarea Wikipedia ca resursă pentru recunoașterea entităților denumite în limbi morfologic complexe sub-resurse', 'pl': 'Wykorzystanie Wikipedii jako zasobu do rozpoznawania nazwanych podmiotów w językach morfologicznie złożonych niedostatecznie zasobów', 'sr': 'Zaposlenje Wikipedije kao resursa za priznanje imenovanih entiteta na morfološki kompleksnom jeziku pod resursima', 'si': 'Name', 'so': 'Shaqaalaha Wikipedia sida resource for Named Entity Recognition in Morphologically complex under-resourced languages', 'sv': 'Använda Wikipedia som resurs för Named Entity Recognition i morfologiskt komplexa underresursspråk', 'ta': 'Name', 'ur': 'ویکیپیڈیا کو نام رکھا ہوا انٹیٹی شناسی کے لئے ایک سرمایہ کے طور پر استعمال کرتا ہے', 'uz': 'Name', 'vi': 'Việc áp dụng Wikipedia như một tài nguyên cho Việc nhận dạng người có tên bằng ngôn ngữ phức tạp, thiếu nguồn lực.', 'bg': 'Използване на Уикипедия като ресурс за разпознаване на имена на лица в морфологически сложни езици с недостатъчно ресурси', 'da': 'Anvendelse af Wikipedia som ressource til anerkendelse af navngivne enheder på morfologisk komplekse sprog med underressourcer', 'nl': 'Wikipedia gebruiken als bron voor naamsbekendheid in morfologisch complexe talen met weinig middelen', 'de': 'Verwendung von Wikipedia als Ressource für Named Entity Recognition in morphologisch komplexen Unterressourcensprachen', 'id': 'Menggunakan Wikipedia sebagai sumber daya untuk Pengenalan Entitas bernama dalam bahasa yang rumit secara morfologis', 'ko': '위키백과를 자원으로 삼아 형태가 복잡하고 자원이 부족한 언어에서 명명된 실체 식별을 하다', 'hr': 'Zaposlenje Wikipedia kao resursa priznanja imenovanih područja na morfološki složenim jezicima pod resursima', 'sw': 'Kutumia Wikipedia kama rasilimali kwa ajili ya Kutambua Ujumbe wa Jinai katika lugha za Kimorphologically complex under-resource', 'tr': '횥첵tgedi첵any Marfologiki 첵체ze arkalanylan dillerde Ady Entity Tany힊ma 체챌in 챌e힊me h철km체nde ullan첵arlar', 'am': 'Wikipedia as a source for Named Entity Recognition in Morphologically complex under-resourced languages', 'fa': 'با استفاده از ویکیپدیا به عنوان منابع برای شناسایی عنوان واحدی در زبانهای زیر منابع مرفولژی پیچیده', 'hy': 'Վիքիփեդիայի օգտագործումը որպես ռեսուրս Մորֆոլոգիապես բարդ լեզուներում կոչված անհատականության ճանաչման համար', 'af': "Die werking van Wikipedia as 'n hulpbron vir genoemde Entity-herkenning in Morphologically kompleks onder-hulpbron taals", 'bn': 'Name', 'sq': 'Duke përdorur Wikipedian si një burim për njohjen e njësisë së emëruar në gjuhë të ndërlikuara nga ana morfologjike', 'ca': "Empregar la Wikipedia com un recurso per a la reconeixement d'entitats anomenades en llengües morfològicament complexes amb menys recursos", 'az': "İsmim Entity Recognition üçün Wikipedia'yi Morphologically complex under resource dillərində istifadə edir.", 'bs': 'Zaposlenje Wikipedia kao resursa za priznanje imenovanih entiteta na morfološki kompleksnom jeziku pod resursima', 'cs': 'Využití Wikipedie jako zdroje pro rozpoznávání jmenovaných entit v morfologicky složitých jazycích s nedostatečnými zdroji', 'et': 'Vikipeedia kasutamine nimetatud isikute tuvastamise ressursina morfoloogiliselt keerukates, alaressurssidega keeltes', 'fi': 'Wikipedian käyttäminen resurssina nimettyjen entiteettien tunnistamiseen morfologisesti monimutkaisilla aliresursseilla varustetuilla kielillä', 'jv': 'Ngawe', 'he': 'משתמש בויקיפדיה כמשאב לזהות איכות בשם בשפות מורפולוגית מורכבות', 'ha': 'KCharselect unicode block name', 'sk': 'Uporaba Wikipedije kot vira za prepoznavanje imenovanih subjektov v morfološko kompleksnih jezikih s premalo virov', 'bo': 'Name'}
{'en': 'We propose a novel approach for rapid prototyping of named entity recognisers through the development of semi-automatically annotated datasets. We demonstrate the proposed pipeline on two under-resourced agglutinating languages : the Dravidian language Malayalam and the Bantu language isiZulu. Our approach is weakly supervised and bootstraps training data from Wikipedia and Google Knowledge Graph. Moreover, our approach is relatively language independent and can consequently be ported quickly (and hence cost-effectively) from one language to another, requiring only minor language-specific tailoring.', 'ar': 'نقترح نهجًا جديدًا للنماذج الأولية السريعة لأدوات التعرف على الكيانات المسماة من خلال تطوير مجموعات البيانات المشروحة بشكل شبه تلقائي. نعرض خط الأنابيب المقترح على لغتين من لغات التراص قليلة الموارد: لغة درافيدية المالايالامية ولغة البانتو إيزولو. يخضع نهجنا للإشراف الضعيف ويقوم بتمهيد بيانات التدريب من ويكيبيديا و Google Knowledge Graph. علاوة على ذلك ، فإن نهجنا مستقل نسبيًا عن اللغة ويمكن بالتالي نقله بسرعة (ومن ثم فعاليته من حيث التكلفة) من لغة إلى أخرى ، مما لا يتطلب سوى خياطة ثانوية خاصة بلغة معينة.', 'fr': "Nous proposons une nouvelle approche pour le prototypage rapide de dispositifs de reconnaissance d'entités nommées grâce au développement d'ensembles de données annotés semi-automatiquement. Nous démontrons le pipeline proposé sur deux langues agglutinantes sous-dotées\xa0: la langue dravidienne malayalam et la langue bantoue isiZulu. Notre approche est faiblement supervisée et amorce les données de formation de Wikipédia et de Google Knowledge Graph. De plus, notre approche est relativement indépendante de la langue et peut donc être portée rapidement (et donc de manière rentable) d'une langue à une autre, ne nécessitant qu'une adaptation mineure spécifique à la langue.", 'es': 'Proponemos un enfoque novedoso para la creación rápida de prototipos de reconocedores de entidades nombradas mediante el desarrollo de conjuntos de datos anotados semiautomáticamente. Demostramos el proyecto propuesto en dos lenguas aglutinantes de escasos recursos: el idioma dravídico malayalam y el idioma bantú es el zulú. Nuestro enfoque es débilmente supervisado y arranca datos de entrenamiento de Wikipedia y Google Knowledge Graph. Además, nuestro enfoque es relativamente independiente del idioma y, por lo tanto, se puede trasladar rápidamente (y por lo tanto de forma rentable) de un idioma a otro, lo que requiere solo una pequeña adaptación específica del idioma.', 'pt': 'Propomos uma nova abordagem para prototipagem rápida de reconhecedores de entidades nomeadas através do desenvolvimento de conjuntos de dados anotados semiautomaticamente. Demonstramos o pipeline proposto em duas línguas aglutinantes com poucos recursos: a língua dravidiana malaiala e a língua bantu isiZulu. Nossa abordagem é fracamente supervisionada e utiliza dados de treinamento da Wikipedia e do Google Knowledge Graph. Além disso, nossa abordagem é relativamente independente do idioma e, consequentemente, pode ser portada rapidamente (e, portanto, de forma econômica) de um idioma para outro, exigindo apenas pequenas adaptações específicas do idioma.', 'ja': '私たちは、半自動的にアノテーションされたデータセットの開発を通じて、名前付きエンティティレグナイザーの迅速なプロトタイピングのための新しいアプローチを提案します。提案されているパイプラインは、資源不足のマラヤーラム語のドラヴィダ語とバントゥー語のisiZuluという2つのアグルティン言語で実演しています。当社のアプローチは弱く監督されており、ウィキペディアやGoogleナレッジグラフからのトレーニングデータをブートストラップします。さらに、私たちのアプローチは比較的言語に依存しないため、ある言語から別の言語に素早く（したがって費用対効果の高い）移植することができ、わずかな言語固有のテーラリングしか必要としません。', 'ru': 'Мы предлагаем новый подход к быстрому прототипированию именованных распознавателей сущностей посредством разработки полуавтоматически аннотированных наборов данных. Мы демонстрируем предлагаемый конвейер на двух агглютинирующих языках, не обеспеченных достаточными ресурсами: на малаяламском языке дравидия и на языке банту isiZulu. Наш подход слабо контролируется и загружает обучающие данные из Википедии и Google Knowledge Graph. Кроме того, наш подход относительно независим от языка и, следовательно, может быть быстро (и, следовательно, экономически эффективно) перенесен с одного языка на другой, требуя лишь незначительной адаптации к конкретному языку.', 'hi': 'हम अर्ध-स्वचालित रूप से एनोटेट किए गए डेटासेट के विकास के माध्यम से नामित इकाई पहचानकर्ताओं के तेजी से प्रोटोटाइप िंग के लिए एक उपन्यास दृष्टिकोण का प्रस्ताव करते हैं। हम दो कम संसाधन वाली एग्लूटीनेटिंग भाषाओं पर प्रस्तावित पाइपलाइन का प्रदर्शन करते हैं: द्रविड़ भाषा मलयालम और बंटू भाषा isiZulu। हमारा दृष्टिकोण कमजोर रूप से पर्यवेक्षित है और विकिपीडिया और Google ज्ञान ग्राफ़ से डेटा प्रशिक्षण के लिए बूटस्ट्रैप्स है। इसके अलावा, हमारा दृष्टिकोण अपेक्षाकृत भाषा स्वतंत्र है और परिणामस्वरूप एक भाषा से दूसरी भाषा में जल्दी से (और इसलिए लागत प्रभावी ढंग से) पोर्ट किया जा सकता है, जिसके लिए केवल मामूली भाषा-विशिष्ट सिलाई की आवश्यकता होती है।', 'zh': '发半自动注数集来速原型化名实体识别器新法。 两资贫乏凝言拟议管道:达罗毗荼语马拉雅拉姆语班图语isiZulu。 吾法受弱监督,导自维基百科Google图谱训练数。 此可以速言(故有成本效地)从一言而移一语,但须特定言少定。', 'ga': 'Molaimid cur chuige nua chun fréamhshamhaltú tapa a dhéanamh ar lucht aitheantais aonáin ainmnithe trí thacair sonraí leath-uathoibríoch anótáilte a fhorbairt. Léirímid an phíblíne atá beartaithe maidir le dhá theanga agglutinating gann-acmhainní: an teanga Dravidian Mailéalaimis agus an teanga Bantu isiZulu. Tá maoirsiú lag ar ár gcur chuige agus cuirtear bac ar shonraí oiliúna ó Vicipéid agus ó Google Knowledge Graph. Ina theannta sin, tá ár gcur chuige sách neamhspleách ó thaobh teanga de agus is féidir é a aistriú go tapa (agus dá réir sin go cost-éifeachtach) ó theanga amháin go teanga eile, rud nach dteastaíonn ach mion-oiriúnú teanga-shonrach.', 'ka': 'ჩვენ მინდა პრომენტის პროტიპის გამოყენება, რომელიც სახელ ინტერტიკის მოცნობილის პროტოტიპის გავაკეთებას, სახელ ავტომატურად მონატანტირებული მონატანების განვითა ჩვენ გამოჩვენებთ საზოგადომის გარეშე ორი რესუპორციური ადგლუტინაციის ენაზე: დირავიდიური ენაში მალაიალამ და ბანტუ ენაში isiZulu. ჩვენი პროგრამა უბრალოდ მონაცემულია და დაბუტურებული სკიპედია და Google Knowledge Graph-ის განათლების მონაცემულია. დამატებით, ჩვენი წარმოდგენა relatively language independent და შემდეგ შეიძლება ბრალოდ (და ამიტომ გამოიყენება-ეფექტიურად) ერთი ენაზე მეორე, რომელიც მხოლოდ მცირე ენათის განსაზღვრული კონფიგურაცი', 'el': 'Προτείνουμε μια νέα προσέγγιση για την ταχεία δημιουργία πρωτοτύπων ονομάτων αναγνωριστών οντοτήτων μέσω της ανάπτυξης ημιαυτόματα σχολιασμένων συνόλων δεδομένων. Επιδεικνύουμε τον προτεινόμενο αγωγό για δύο ελλιπείς συγκολλητικές γλώσσες: τη δραβιδική γλώσσα Μαλαγιάλαμ και τη γλώσσα Μπαντού είναι Ζουλού. Η προσέγγισή μας είναι ανεπαρκώς εποπτευμένη και χρησιμοποιεί δεδομένα εκπαίδευσης από τη Βικιπαίδεια και το Γνωσιακό Γράφημα της Google. Επιπλέον, η προσέγγισή μας είναι σχετικά γλωσσική ανεξάρτητη και κατά συνέπεια μπορεί να μεταφερθεί γρήγορα (και επομένως οικονομικά αποδοτικά) από τη μία γλώσσα στην άλλη, απαιτώντας μόνο μικρή γλωσσική προσαρμογή.', 'hu': 'Új megközelítést javasolunk a nevezett entitás felismerők gyors prototípusának gyártására félautomatikusan jegyzetelt adathalmazok fejlesztésével. Bemutatjuk a javasolt csővezetéket két nem erőforrásokkal rendelkező agglutináló nyelven: a dravidi Malayalam és a bantu nyelven isizulu. Megközelítésünk gyengén felügyelt és bootstraps képzési adatok a Wikipédiából és a Google Knowledge Graphból. Ezen túlmenően a megközelítésünk viszonylag nyelvfüggetlen, következésképpen gyorsan (és így költséghatékonyan) hordozható egyik nyelvről a másikra, és csak kisebb nyelvspecifikus szabást igényel.', 'it': "Proponiamo un nuovo approccio per la prototipazione rapida di identificatori di entità nominate attraverso lo sviluppo di set di dati annotati semi-automaticamente. Dimostriamo la pipeline proposta su due lingue agglutinanti sottorisorse: la lingua dravidiana Malayalam e la lingua bantu isiZulu. Il nostro approccio è debolmente supervisionato e bootstraps training dati da Wikipedia e Google Knowledge Graph. Inoltre, il nostro approccio è relativamente indipendente dalla lingua e può quindi essere trasportato rapidamente (e quindi economicamente) da una lingua all'altra, richiedendo solo una piccola personalizzazione linguistica specifica.", 'mk': 'We propose a novel approach for rapid prototyping of named entity recognisers through the development of semi-automatically annotated datasets.  Ние го демонстрираме предложениот гасовод на два јазици со недостаток на ресурси: дравидскиот јазик Малајајалам и јазикот Банту изулу. Нашиот пристап е слабо надгледуван и ги обучува податоците од Википедија и Google Knowledge Graph. Покрај тоа, нашиот пристап е релативно независен од јазикот и со тоа може да се пренесе брзо (и со тоа е ефикасно) од еден јазик до друг, барајќи само мало приспособување специфично на јазикот.', 'lt': 'Siūlome naują metodą greitam pavadintų subjektų pripažintojų prototipų nustatymui plėtojant pusautomatiškai anotuotus duomenų rinkinius. Mes parodome siūlomą vamzdyną dviem nepakankamai išteklių turinčiomis agglutinuojančiomis kalbomis: dravidijos kalba Malayalam ir Bantu kalba isiZulu. Mūsų požiūris yra silpnai prižiūrimas ir įjungia Wikipedia ir Google Knowledge Graph mokymo duomenis. Be to, mūsų požiūris yra palyginti nepriklausomas nuo kalbos ir todėl gali būti greitai (ir todėl ekonomiškai efektyviai) perkeltas iš vienos kalbos į kitą, reikalaujant tik nedidelio kalbos pritaikymo.', 'kk': 'Біз жарты автоматты түрде белгіленген деректер жинақтарын жасау арқылы аталған нысандардың тез прототиптерін жаңа түрде жасау арқылы жаңа тәртібін ұсынамыз. Біз қолданыстағы қосымша қосымша қосымша қосымша қосымша қосымша қосымша қосымша тілдерді көрсетедік: Дравидия тілі Малайям және Банту тілі isiZulu. Біздің қасиетіміз Википедия және Google Knowledge графикасындағы деректерді бақылау және жүктеуді бақылау. Сонымен қатар, біздің тәсілдігіміз сәйкес тілді тәуелсіз, сондықтан бір тілден бір тілден бір тілде тәуелсіз (және бұл үшін бұл тілден бір тілде тәуелсіз) жібере алады, тек кішк', 'ml': 'പേരിട്ട വസ്തുവിന്റെ തിരിച്ചറിയുന്നവരുടെ പേരില്\u200d പെട്ടെന്ന് പ്രോട്ടോട്ടിപ്പിനുള്ള നോവല്\u200d പ്രോട്ടോട്ടോപ്റ നമ്മള്\u200d നിര്\u200dദ്ദേശിക്കപ്പെട്ട രണ്ട് വിഭവങ്ങളുടെ ഭാഷകളില്\u200d പൈപ്പെലൈന്\u200d പ്രദര്\u200dശിപ്പിക്കുന്നു; ഡ്രാവിഡിയന്\u200d ഭാഷ മലായാലാമ ഞങ്ങളുടെ സമ്പാദം ദുര്\u200dബലമായി നിരീക്ഷിക്കപ്പെടുന്നതും വിക്കിപിഡിയയില്\u200d നിന്നും ഗൂഗിള്\u200d അറിവ് ഗ്രാഫില അതുകൊണ്ടും, നമ്മുടെ സമ്പ്രദായം വളരെ സ്വാതന്ത്ര്യമായ ഭാഷയാണ്. അതുകൊണ്ട് ഒരു ഭാഷയില്\u200d നിന്നും മറ്റൊരു ഭാഷയിലേക്കും വേഗം പോര്\u200dട്ട് ചെയ്യാന്\u200d സ', 'ms': 'Kami cadangkan pendekatan baru untuk prototip cepat pengenalpasti entiti bernama melalui pembangunan set data semi-automatik anotasi. Kami menunjukkan saluran paip yang diusulkan pada dua bahasa yang kurang sumber: bahasa Dravidia Malayalam dan bahasa Bantu isiZulu. Pendekatan kami adalah mengawasi lemah dan bootstraps latihan data dari Wikipedia dan Google Knowledge Graph. Moreover, our approach is relatively language independent and can consequently be ported quickly (and hence cost-effectively) from one language to another, requiring only minor language-specific tailoring.', 'mt': 'Aħna nipproponu approċċ ġdid għall-prototip rapidu ta’ rikonoxxituri ta’ entitajiet imsemmija permezz tal-iżvilupp ta’ settijiet ta’ dejta semiawtomatikament annotati. Aħna nuru l-pipeline propost dwar żewġ lingwi agglutinanti b’riżorsi baxxi: il-lingwa Dravidjana Malayalam u l-lingwa Bantu isiZulu. L-approċċ tagħna huwa sorveljat b’mod dgħajjef u jnaqqas id-dejta tat-taħriġ mill-Wikipedia u l-Google Knowledge Graph. Barra minn hekk, l-approċċ tagħna huwa relattivament indipendenti mil-lingwa u konsegwentement jista’ jinġabar malajr (u għalhekk b’mod kosteffettiv) minn lingwa għal oħra, li jeħtieġ biss tfassil minuri speċifiku għall-lingwa.', 'no': 'Vi foreslår eit nytt tilnærming for rask prototyping av gjenkjente entitet gjennom utviklinga av semiautomatisk oppmerkte datasett. Vi viser foreslått røyrlinje på to underressurserte aggluteringsspråk: Dravidisk språk Malayalam og Bantu-språket isiZulu. Tilnærminga vårt er viktig oversikt og oppstartslag opplæringsdata frå Wikipedia og Google Knowledge Graph. I tillegg er tilnærming vårt relativt språk uavhengig, og derfor kan bli portert raskt (og derfor kostnadseffektivt) frå ein språk til ein annan, derfor krev berre mindre språk-spesifikke tillegg.', 'pl': 'Proponujemy nowatorskie podejście do szybkiego prototypowania nazwanych identyfikatorów podmiotów poprzez opracowanie półautomatycznie adnotacyjnych zbiorów danych. Przedstawiamy proponowany rurociąg dotyczący dwóch niedostatecznie zasobów języków aglutynujących: języka drawidyjskiego Malayalam i języka Bantu jest Zulu. Nasze podejście jest słabo nadzorowane i bootstraps dane szkoleniowe z Wikipedii i Google Knowledge Graph. Ponadto nasze podejście jest stosunkowo niezależne od języka i w konsekwencji może być szybko (a tym samym opłacalnie) przeniesione z jednego języka do drugiego, wymagając jedynie niewielkiego dopasowania specyficznego języka.', 'mn': 'Бид нэрлэгдсэн бүтээгдэхүүний хурдан прототипчлэх шинэ арга замыг автоматжуулсан өгөгдлийн санг хөгжүүлэхээр сануулдаг. Бид хоёр төвөгтэй аглуутайн хэл дээр тайлбарласан хоолойн шугам нь Дравидийн хэл Малайалам, Банту хэл isiZulu гэдгийг харуулж байна. Бидний арга зам нь Wikipedia болон Google Knowledge Graph-ын сургалтын өгөгдлийг багасгаж байдаг. Мөн бидний арга зам нь харьцангуй хэл тус хамааралтай. Үүнээс хурдан (үүнээс үнэ цэнэтэй) нэг хэлээс нөгөө хэлээс нөгөө хэлээс нөгөө хэлээс нь бага хэл тодорхойлох шаардлагатай.', 'ro': 'Propunem o abordare nouă pentru prototiparea rapidă a recunoașterilor entităților denumite prin dezvoltarea seturilor de date adnotate semi-automat. Demonstrăm conducta propusă pe două limbi aglutinante insuficient de resurse: limba dravidiană Malayalam și limba bantu isiZulu. Abordarea noastră este slab supravegheată și datele de instruire bootstraps din Wikipedia și Google Knowledge Graph. Mai mult decât atât, abordarea noastră este relativ independentă de limbă și, prin urmare, poate fi transportată rapid (și, prin urmare, rentabil) de la o limbă la alta, necesitând doar o personalizare minoră specifică limbii.', 'si': 'අපි ප්\u200dරශ්නයක් කරනවා නාමක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් නිර්මාණය කරලා තියෙන්නේ  අපි ප්\u200dරශ්නයක් කරනවා පායිප්ලයින් දෙන්නෙක් අඩු සම්පූර්ණ භාෂාවක් වල: ඩ්\u200dරාවිඩියාන් භාෂාව මලායාලාම් සහ අපේ පරීක්ෂණය විකිපිඩියා සහ ගුගුල් දන්න ග්\u200dරාෆ් වලින් දුර්වලින් පරීක්ෂණය කරලා බටස්ට්\u200dරෑප් කරල තවත්, අපේ භාෂාව සාමාන්\u200dය භාෂාව ස්ථායිත වෙන්න පුළුවන්, ඒ වගේම ඉක්මනින් ඉක්මනින් ඉක්මනින් (ඒ වගේම ක්\u200dරියාත්මක ව', 'so': 'Waxaynu horumarinaynaa qaab warqad ah sameynta dhaqso oo lagu magacaabay qofka loo aqoonsaday marka loo horumariyo sawirada macluumaadka si bilowga ah. Waxaannu muujinnaa pipeline la soo jeeday oo ku qoran laba luqadood oo aan la isticmaali karin: luqada Drawiyan Malayalam iyo luqada isizulu. Dhaqdhaqaalahayaga waxaa la ilaaliyaa itaal daryeel iyo macluumaad waxbarasho oo lagu tababarayo ee Wikipedia iyo Graf aqoonta Googley. Sidoo kale dhaqdhaqaalahayagu waa luqadeena mid u xor ah, markaasna waxaa loo bandhigi karaa si dhaqso ah (sababtaas darteed kharash-faa’iido leh) oo af ilaa af kale looga baahan yahay mid ku qoran luqad yar oo kaliya.', 'sr': 'Predlažemo nov pristup brzom prototipiranju priznatih entiteta kroz razvoj polu-automatski notiranih podataka. Pokazali smo predloženu cijevinu na dva pod resursima agluticiranja jezika: Dravidski jezik Malayalam i Bantu jezik isiZulu. Naš pristup je slab nadzor i obuka podataka iz Wikipedia i Google Knowledge Grafa. Osim toga, naš pristup je relativno nezavisan jezik i stoga se može brzo prijaviti (i stoga se koštaju efikasno) od jednog jezika na drugog jezika, zahtevajući samo manje specifične praćenje jezika.', 'sv': 'Vi föreslår ett nytt tillvägagångssätt för snabb prototyp av namngivna entitetsigenkännare genom utveckling av halvautomatiskt kommenterade datauppsättningar. Vi visar den föreslagna pipeline på två underresourcerade agglutinerande språk: dravidiska språket Malayalam och bantu språket isizulu. Vårt tillvägagångssätt är svagt övervakat och bootstraps träningsdata från Wikipedia och Google Knowledge Graph. Dessutom är vårt tillvägagångssätt relativt språkoberoende och kan följaktligen snabbt (och därmed kostnadseffektivt) överföras från ett språk till ett annat, vilket endast kräver mindre språkspecifik skräddarsy.', 'ta': 'நாம் பெயர் பொருள் அடையாளங்களின் வேகமான முறைமையை உருவாக்குவதற்கு ஒரு புதிய செயல்பாட்டை பரிந்துரைக்கிறோம். We demonstrate the proposed pipeline on two under-resourced agglutinating languages: the Dravidian language Malayalam and the Bantu language isiZulu.  விகிபிடியா மற்றும் கூகுல் அறிவு வரைப்படத்திலிருந்து தகவல் பயிற்சியை கண்காணிக்கப்படுகிறது. மேலும், எங்கள் நெருக்கம் சுருக்கமான மொழி சுதந்திரமாக இருக்கும் மற்றும் அதனால் விரைவில் (மற்றும் அதனால் விலை செலவு செயல்படுத்தப்படும்) ஒரு ம', 'ur': 'ہم نے ایک نئی طریقہ پیش کرتا ہے جس کا نام اتنی پہچان کرنے والوں کے لئے سریع پروٹوٹیپینگ کا ذریعہ ہے نصف-اٹوٹیٹ ڈیٹ سٹ کی توسعہ سے۔ ہم نے پیغمبر کی پیشنهاد کی پیپ لین کو دکھایا ہے دو کم رسسورٹی زبانوں میں: ڈراویڈی زبان مالایالم اور بانٹو زبان ایزیزولو۔ ہمارا طریقہ کمزور تحقیق ہے اور بوٹ سٹرپ ویکیپیڈیا اور گوگل علم گراف سے آموزش دادہ کی آموزش کرتا ہے. اور اس کے بعد ہماری طریقہ مقابلہ میں زبان کی بے نیاز ہے اور اس کے نتیجہ میں ایک زبان سے دوسرے زبان سے سریع (اور اس کے نتیجہ میں) لے کر آ سکتا ہے، صرف تھوڑی زبان کے مطابق تدبیر کرنے کی ضرورت ہے۔', 'uz': "Biz quyidagi obʼektlarni avtomatik avtomatik taʼminlovchi maʼlumotlar tarkibini tahlash orqali tez qilish uchun novel usulini tahlil qilamiz. Biz tasavvur qilingan pipelin ikkita tashkilotlar tilida ko'rsatdik: Dravidian tili Malayalam va Bantu tili isizulu. Bizning murojaatiyatlarimiz juda tez taʼminlovchi va Wikipedia va Google Fan Grafikdan taʼminlovchi maʼlumotni boshqarishdir. Ko'pchilik, bizning tilimiz o'xshash tilda o'xshash bo'ladi va keyin bir tildan bir tildan foydalanish mumkin, faqat kichkina tilni qo'shish kerak.", 'vi': 'Chúng tôi đề xuất một phương pháp mới cho việc xử lý nhanh những người nhận diện thực thể tên bằng cách phát triển các tập tin đã được ghi chú gần tự động. Chúng tôi chứng minh khả năng cung cấp cho hai ngôn ngữ đậm đặc thiếu nguồn: ngôn ngữ của người Đức Malayaham và ngôn ngữ Banu isiZulu. Cách tiếp cận của chúng tôi được giám sát thiếu sót và khởi động dữ liệu tập luyện trên Wikipedia và Google knowledge Graph. Hơn nữa, cách tiếp cận của chúng ta là tương đối độc lập ngôn ngữ và do đó có thể được áp dụng nhanh chóng (và do đó có giá trị kinh tế) từ ngôn ngữ này sang ngôn ngữ khác, chỉ cần chỉnh sửa nhỏ.', 'nl': 'We stellen een nieuwe aanpak voor voor snelle prototyping van benoemde entiteitsherkenners door de ontwikkeling van semi-automatisch geannoteerde datasets. We demonstreren de voorgestelde pijplijn op twee onvoldoende beschikbare agglutinerende talen: de Dravidische taal Malayalam en de Bantu taal isiZulu. Onze aanpak wordt zwak begeleid en bootstraps trainingsgegevens uit Wikipedia en Google Knowledge Graph. Bovendien is onze aanpak relatief taalonafhankelijk en kan daardoor snel (en dus kosteneffectief) van de ene naar de andere taal worden overgezet, waarbij slechts een kleine taalspecifieke aanpassing vereist is.', 'hr': 'Predlažemo nov pristup brzom prototipiranju priznatih subjekta kroz razvoj polu-automatski notiranih podataka. Pokazali smo predloženu cijevinu na dva pod resursima aglutirajućih jezika: Dravidski jezik Malayalam i Bantu jezik isiZulu. Naš pristup je slab nadzor i podaci obuke iz Wikipedia i Google Knowledge Grafa. Osim toga, naš pristup je relativno nezavisan jezik i stoga se može brzo (i stoga se koštati učinkovito) prijaviti od jednog jezika na drugog jezika, zahtijevajući samo manje praćenje jezika specifičnog.', 'da': 'Vi foreslår en ny tilgang til hurtig prototype af navngivne entitetsgenkendere gennem udvikling af halvautomatisk annoterede datasæt. Vi demonstrerer den foreslåede pipeline på to underresourcerede agglutinerende sprog: det dravidiske sprog Malayalam og Bantu sproget isizulu. Vores tilgang er svagt overvåget og bootstraps træningsdata fra Wikipedia og Google Knowledge Graph. Desuden er vores tilgang relativt sproguafhængig og kan derfor hurtigt (og dermed omkostningseffektivt) overføres fra et sprog til et andet, hvilket kun kræver mindre sprogspecifik skræddersyelse.', 'id': 'Kami mengusulkan pendekatan baru untuk prototip cepat dari pengenal entitas bernama melalui pengembangan set data semi-otomatis anotasi. Kami menunjukkan saluran pipa yang diusulkan pada dua bahasa yang kurang sumber daya: bahasa Dravidia Malayalam dan bahasa Bantu isiZulu. pendekatan kita terlihat lemah dan bootstraps data latihan dari Wikipedia dan Google Knowledge Graph. Selain itu, pendekatan kita relatif bahasa independen dan konsekuensinya dapat dibawa dengan cepat (dan oleh itu rental-efektif) dari satu bahasa ke bahasa lainnya, yang membutuhkan hanya sedikit penyesuaian spesifik bahasa.', 'bg': 'Предлагаме нов подход за бързо прототипиране на наименовани разпознаватели на обекти чрез разработване на полуавтоматично анотирани набори от данни. Представяме предложения тръбопровод на два аглутиниращи езика с недостатъчен ресурс: дравидски език малаялам и бантуски език исулу. Нашият подход е слабо контролиран и събира данни за обучение от Уикипедия и Гугъл графика на знанието. Нещо повече, нашият подход е относително независим от езика и следователно може да бъде пренесен бързо (и следователно икономически ефективно) от един език на друг, изисквайки само незначителна езикова специфика.', 'fa': 'ما پیشنهاد می\u200cکنیم روش نویسی برای پیش\u200cنویسی سریع پیش\u200cنویسی پیش\u200cنویسی از طریق توسعه\u200cی مجموعه\u200cهای داده\u200cهای استفاده\u200cشده\u200cی نیم\u200cخودکار. ما این لوله پیشنهاد را در دو زبان زیر منطقه\u200cای نشان می\u200cدهیم: زبان دروادیه مالایالم و زبان بانتو isiZulu. دسترسی ما ضعیف تحت نظر قرار گرفته و داده های آموزشی از ویکیپدیا و گراف دانش Google است. در ضمن، دسترسی ما نسبتاً زبان مستقل است و به نتیجه می تواند سریع (و از این نتیجه با تأثیر قیمت) از یک زبان به یک زبان حمل شود، و تنها اندازه\u200cگیری به زبان خاص کوچک نیاز دارد.', 'ko': '우리는 반자동 주석 데이터 집합을 개발하여 신속하게 원형화된 명명 실체 식별기를 개발하는 새로운 방법을 제시했다.우리는 두 가지 자원이 부족한 접합 언어에서 제안된 파이프라인: 델라위어 말레이시아어와 반투어 이시조루어를 보여 주었다.우리의 방법은 위키백과와 구글 지식도에서 나온 훈련 데이터를 약하게 감독하고 유도하는 것이다.그 밖에 우리의 방법은 언어에 상대적으로 독립되어 있기 때문에 한 언어에서 다른 언어로 빠르게 (경제적으로) 이식할 수 있고 소량의 특정한 언어의 재단만 필요하다.', 'de': 'Wir schlagen einen neuartigen Ansatz für das Rapid Prototyping benannter Entitätenerkennungen durch die Entwicklung semiautomatisch annotierter Datensätze vor. Wir demonstrieren die vorgeschlagene Pipeline auf zwei unzureichenden Agglutinierungssprachen: der dravidischen Sprache Malayalam und der Bantu-Sprache isiZulu. Unser Ansatz ist schwach überwacht und bootstraps Trainingsdaten aus Wikipedia und Google Knowledge Graph. Darüber hinaus ist unser Ansatz relativ sprachunabhängig und kann daher schnell (und damit kostengünstig) von einer Sprache in eine andere portiert werden, wobei nur geringe sprachspezifische Anpassungen erforderlich sind.', 'af': "Ons voorstel 'n nuwe toegang vir vinnige prototipering van genoem entiteit herkenaars deur die ontwikkeling van semi- automaties opgemerkte datastelle. Ons wys die voorgestelde pyplyn op twee onder-hulpbronne agluteerde tale: die Dravidiëse taal Malayalam en die Bantu taal isiZulu. Ons toegang is swak ondersoek en opstarp onderwerp data van Wikipedia en Google Knowledge Graph. Ook, ons toegang is relativief taal onveilig en kan daarom vinnig (en daarom koste-effektief) van een taal na 'n ander ondersteun word, en net klein taal-spesifieke sterking vereis.", 'am': 'አካባቢው የሚታወቁትን የፍጥነት ፕሮግራም ለመፍጠር የረኀብ ጉዳይ አካባቢ አካባቢ አካባቢ አካባቢ አካባቢ መፍጠር እናስጀምራለን፡፡ We demonstrate the proposed pipeline on two under-resourced agglutinating languages: the Dravidian language Malayalam and the Bantu language isiZulu.  የጎግል እውቀት ግንኙነታችን ደካማ ነው፡፡ ደግሞም የቋንቋችን ነፃ ነጻ ነው፡፡', 'sw': 'Tunazipendekeza mbinu ya riwaya kwa ajili ya mifano ya haraka ya kutengeneza jina la entity kutambua kwa kupitia maendeleo ya seti za taarifa zinazovutiwa kwa mara mbili. Tunaonyesha pipeline inayopendekezwa kwenye lugha mbili isiyo na rasmi: lugha ya KiDravidi ya Malayalam na lugha ya Bantu isiZulu. Matokeo yetu ni dhaifu yanafuatiliwa na mafunzo ya taarifa kutoka Wikipedia na Graph ya Ujuzi wa Google. Zaidi ya hayo, mbinu yetu ni lugha yenye uhuru na kwa hiyo inaweza kuchukuliwa haraka (na hivyo gharama za gharama) kutoka lugha moja hadi nyingine, inayohitaji kufuatilia lugha madogo tu.', 'hy': 'Մենք առաջարկում ենք նոր մոտեցում անվանված էակների ճանաչողների արագ նախատիպ ստեղծելու համար, կիսաավտոմատ գրված տվյալների համակարգերի զարգացման միջոցով: Մենք ցույց ենք տալիս առաջարկած խողովակաշարը երկու թերռեսուրսներով խեղճող լեզուների վրա՝ Դրավիդիայի լեզուն՝ մալայալամը և Բանտու լեզուն՝ իսյուլուն: Մեր մոտեցումը թույլ է վերահսկվում և սկսում է վարժեցնել Վիքիփեդիայի և Google Knowledge Graf-ի տվյալները: Ավելին, մեր մոտեցումը հարաբերականորեն անկախ է լեզվից, և հետևաբար կարող է արագ (և հետևաբար գնահատականորեն) տեղափոխվել մեկ լեզվից մյուսին, որն անհրաժեշտ է միայն փոքր լեզվի մասնավորման:', 'tr': 'Biz "entitet" diýilip tanyşanlarynyň çalt prototik taýýarlamagyny ýarym-otomatik tanyşan veri setirlerini geliştirmegini teklip edýäris. Biz golaýlanmış iki golaý altynda teklip eden pipelini: Drawiýat dili Malayalam we Bantu dilinde isiZulu görkezilýäris. Biziň ýaryşymyz Wikipediýanyň we Google Bilgi Grafiýasyndan azajyk gözleýän we göçüp biljek maglumatlarymyz bar. Munuň ýagdaýymyz görä görä dilimiz täsirli ýuwaşsyz bolýar we şonuň üçin bir dilden täsirli ýuwaşlyk bilen (onuň üçin kän-täsirli bolmagy üçin) bir dile taýýarlanabilir. Diňe kiçi dillerden aýratyn taýýarlamak gerek', 'bn': 'আমরা স্বয়ংক্রিয়ভাবে বিরক্তিকর তথ্যের উন্নয়নের মাধ্যমে দ্রুত প্রোটোটোটাইপের জন্য একটি উপন্যাস প্রস্তাব করি। আমরা প্রস্তাবিত পাইপেলাইন দুটি নিম্নলিখিত ভাষায় প্রদর্শন করছি: ড্রাভিডিয়ার ভাষা মালায়ালাম এবং বাংটু ভাষা ইজুলুর উপর। উইকিপিডিয়া এবং গুগল জ্ঞান গ্রাফ থেকে বুটস্ট্র্যাপ প্রশিক্ষণের তথ্য দুর্বল পর্যবেক্ষণ করা হয়েছে। এছাড়াও, আমাদের পদক্ষেপ হচ্ছে আকর্ষণীয় ভাষার স্বাধীন এবং এর ফলে দ্রুত পোর্ট করা যাবে (এবং এর ফলে এক ভাষা থেকে এক ভাষা থেকে কার্যকর ভাষায়) যার জন', 'sq': 'Ne propozojmë një qasje të re për prototipin e shpejtë të njohësve të emëruar të njësive nëpërmjet zhvillimit të grupeve të dhënash gjysmë-automatike të anotuara. Ne demonstrojmë tubacionin e propozuar në dy gjuhë të pakufishme të aglutinuara: gjuhën dravidiane Malayalam dhe gjuhën Bantu isiZulu. Our approach is weakly supervised and bootstraps training data from Wikipedia and Google Knowledge Graph.  Përveç kësaj, qasja jonë është relativisht e pavarur nga gjuha dhe mund të sillet shpejt (dhe kështu me kosto-efektivitet) nga një gjuhë në tjetrën, duke kërkuar vetëm përshtatje të vogla specifike për gjuhën.', 'az': 'Biz, yarńĪ-avtomatik t…ôŇükil veril…ôn qurmaqlarńĪn t…ôŇükil etm…ôsi vasit…ôsil…ô adlńĪ entit…ô tanńĪyńĪcńĪlarńĪn tez prototipi √ľ√ß√ľn yeni bir yol t…ôklif edirik. Biz t…ôklif etdiyimiz bor √ßizgisini iki qonaqlarńĪn altńĪndakńĪ agglutinasyon dilind…ô g√∂st…ôririk: Dravid dili Malayalam v…ô Bantu dili isiZulu. Bizim t…ôrzimiz Wikipedia v…ô Google Knowledge Graph t…ôhsil edil…ôn m…ôlumatlarńĪ z…ôif g√∂zl…ôyir. Daha sonra, bizim t…ôr…ôfimiz relativ dil bańüńĪmsńĪzdńĪr v…ô buna g√∂r…ô d…ô d…ôrhal (v…ô buna g√∂r…ô d…ô qiym…ôtli olaraq) bir dild…ôn baŇüqa dil…ô t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ôf t…ôr…ô', 'bs': 'Predlažemo nov pristup brzom prototipiranju priznatih entiteta kroz razvoj polu-automatski notiranih podataka. Pokazali smo predloženu cijevinu na dva pod resursima aglutirajućih jezika: Dravidski jezik Malayalam i Bantu jezik isiZulu. Naš pristup je slab nadzor i podaci obuke iz Wikipedia i Google Knowledge Grafa. Osim toga, naš pristup je relativno nezavisan jezik i stoga se može brzo (i stoga se koštati efikasno) prijaviti od jednog jezika na drugog jezika, zahtijevajući samo manje praćenje jezika specifičnog.', 'et': 'Pakume välja uudse lähenemisviisi nimetatud olemitunnistajate kiireks prototüüpimiseks poolautomaatsete annoteeritud andmekogumite arendamise kaudu. Tutvustame kavandatud juhtmestikku kahel alaressursiga aglutineerival keelel: draviidi keel malayalam ja bantu keel isizulu. Meie lähenemine on nõrgalt jälgitav ja bootstraps treeningu andmed Wikipediast ja Google Knowledge Graphist. Lisaks on meie lähenemisviis suhteliselt keelesõltumatu ja seetõttu saab seda kiiresti (ja seega kulutõhusalt) ühest keelest teise transportida, nõudes vaid väikest keelelist kohandamist.', 'ca': "Proposem un enfocament nou per a prototipar ràpidament els reconeixents d'entitats anotats mitjançant el desenvolupament de conjunts de dades semi-automàticament anotats. Demonstrem el pipeline proposat en dues llengües aglutinants amb pocs recursos: el llenguatge dravídic malàyal i el llenguatge Bantu isZulu. El nostre enfocament està debidament supervisat i treina les dades de Wikipedia i Google Knowledge Graph. A més, el nostre enfocament és relativament independent del llenguatge i, per tant, pot ser portat ràpidament (i, per tant, rentablement) d'una llengua a l'altra, només necessitant una adaptació minor específica del llenguatge.", 'cs': 'Navrhujeme nový přístup pro rychlé prototypování pojmenovaných rozpoznávačů entit prostřednictvím vývoje poloautomaticky anotovaných datových sad. Ukážeme navrhovaný plynovod na dvou nedostatečně vybavených aglutinačních jazycích: dravidském jazyce malajálam a bantuském jazyce isZulu. Náš přístup je slabě dohlížený a bootstrapuje tréninková data z Wikipedie a Google Knowledge Graph. Navíc je náš přístup relativně jazykově nezávislý a může být proto přenášen rychle (a tedy cenově efektivně) z jednoho jazyka do druhého, což vyžaduje pouze menší jazykové přizpůsobení.', 'fi': 'Ehdotamme uutta lähestymistapaa nimettyjen entiteettitunnistimien nopeaan prototyyppiin kehittämällä puoliautomaattisia annotoituja datakokonaisuuksia. Esittelemme ehdotetun putkiston kahdella aliresurssisella agglutinaatiokielellä: dravidian kielellä malayalam ja bantun kielellä isizulu. Lähestymistapamme on heikosti valvottu ja bootstraps harjoitusdataa Wikipediasta ja Google Knowledge Graphista. Lisäksi lähestymistapamme on suhteellisen kieliriippumaton, ja sen vuoksi se voidaan siirtää nopeasti (ja siten kustannustehokkaasti) kieleltä toiselle, mikä edellyttää vain vähäistä kielikohtaista räätälöintiä.', 'sk': 'Predlagamo nov pristop za hitro prototipiranje imenovanih prepoznavalcev entitet z razvojem polavtomatsko označenih naborov podatkov. Predlagani plinovod predstavljamo na dveh aglutinacijskih jezikih s premalo virov: dravidskem jeziku malajalam in bantujem izzulu. Naš pristop je slabo nadzorovan in zajema podatke o usposabljanju iz Wikipedije in Google Knowledge Graph. Poleg tega je naš pristop relativno jezikovno neodvisen in ga je zato mogoče hitro (in s tem stroškovno učinkovito) prenesti iz enega jezika v drugega, kar zahteva le manjše jezikovno specifično prilagajanje.', 'ha': 'Munã goyyade wani matsayi na nowaya wa misalin abun da aka faɗa abun da aka sani game da the Development of data set by semi-farat-inganci. Tuna nuna da aka goyaye piilein a kan lugha biyu masu ƙaranci: lugha na Dandiyan Malayalam da harshen isiZulu. Mataimakinmu yana ƙaranci kuma an tsare data daga Taurar Sann na Wikimedia da Google. Kayya, hanyarmu na kamfata harshe, yana da huru kuma ana iya karatun da haraka (kuma dõmin haka masu kifi mai amfani da shi) daga harshen guda zuwa wani harshe, kuma yana tambayar ku da danganta masu ƙarami kawai.', 'jv': 'Awak dhéwé nggunakake sistem sing rawuh akeh kanggo ngilangno prototype anyir tentang karo nganggo sistem sing dadi iki dadi sing nguasakno Awak dhéwé éntuk ngéwangi tanggal sing nyeangké ning langa sing luwih banter: lenga Drawian, malayam lan lenga Bantu isiGulu. Ndoleh awak dhéwé kuwi nglanggar-sistem luwih nguasai karo mulasai kuwi nggawe dadi Wipediya karo Google knowness Graph. Lalika bener, akeh sing nglanga luwih dumateng lan akeh iso nglanggar bantuan (kaya nguasai njaluk-njaluk) sak sabên langa sampeyan liyane wis nguasai, akeh iso nglanggar langa sing nesaturan pur.', 'he': 'אנו מציעים גישה חדשה לאבטיפוס מהיר של מזהה ישויות בשם דרך הפיתוח של קבוצות נתונים חצי-אוטומטיות. אנחנו מציגים את הצינור המוצע בשתי שפות מתעצבנות מתחת למשאלות: שפת דראבידית מליאלאם ושפת בנטו איזיזולו. הגישה שלנו מפקחת בחולשה ומעטפת מידע אימון מוויקיפדיה וגוגל גרף ידע. חוץ מזה, הגישה שלנו היא יחסית עצמאית לשפה, ולכן אפשר להעביר אותה מהר (ולכן יעיל במחיר) משפה אחת לשפה אחרת, דורשת רק תצוגה קטנה ספציפית לשפה.', 'bo': 'ང་ཚོས་མིང་དང་འཛིན་པའི་དབུལ་གྱི་ཕྱོགས་སྐོར་ལ་རང་འགུལ་གྱིས་ཟིན་བྲིས་ཀྱི་ཐབས་ལམ་ལ་གསར་གཏོང་ཞིག་དང་། ང་ཚོས་རྗེས་སུ་འབྱུང་བའི་སྐད་རིགས་གཙང་འབོད་པའི་མ་གཟུགས་འབྲེལ་གཉིས་ཀྱི་ནང་དུ་སྔོན་འཆར་བྱས་པའི་རྒྱུད་དུ་བཀོད་པ་ཡིན། ང་ཚོའི་གཟུགས་སྐོར་ནི་Wikipedia དང Google Knowledge Graph ཡིས་བརྗོད་མཁན་གྱི་རྩོལ་མེད་སྟོན་པ་དང་འགོ་འཁྱེར་གྱི་ཐབས་ཤེས་ཡོད། འོན་ཀྱང་། ང་ཚོའི་ཐབས་ལམ་དེ་ཆུང་མཐའ་ནས་སྐད་ཡིག་ནི་སྟེང་ནས་མཐའ་འགྱུར་བ་ཞིག་ཏུ་འཇུག'}
{'en': 'Majority Voting with Bidirectional Pre-translation For Bitext Retrieval', 'ar': 'تصويت الأغلبية مع الترجمة المسبقة ثنائية الاتجاه لاسترداد Bitext', 'es': 'Votación mayoritaria con pretraducción bidireccional para la recuperación de bitexto', 'fr': 'Vote majoritaire avec pré-traduction bidirectionnelle pour la récupération de bitexte', 'pt': 'Votação por maioria com pré-tradução bidirecional para recuperação de bitexto', 'ja': 'ビットテキスト取得のための双方向事前翻訳による多数決', 'hi': 'Bitext पुनर्प्राप्ति के लिए द्विदिश पूर्व-अनुवाद के साथ बहुमत मतदान', 'zh': '双向预译者多投票 用于双文本检索', 'ru': 'Голосование большинства с двунаправленным предварительным переводом для получения битекста', 'ga': 'Vótáil Tromlaigh le Réamhaistriúchán Déthreo Chun Aisghabháil Biththéacs', 'ka': 'ბიტექსტის მიღებისთვის ბიტექსტის წინასწორედ გადასვლა', 'hu': 'Többségi szavazás kétirányú előfordítással Bitext visszaszerzéshez', 'el': 'Ψηφίζοντας πλειοψηφία με αμφίδρομη προ-μετάφραση για ανάκτηση bitext', 'it': 'Voto di maggioranza con pre-traduzione bidirezionale per il recupero di bitext', 'kk': 'Бит- тексті алу үшін екі бағытты алдындағы аудару үшін', 'lt': 'Daugumos balsavimas dvikryptiniu išankstiniu vertimu Bitext gavimui', 'mk': 'Гласање со мнозинство со двојно превод за добивање на Bitext', 'ms': 'Mengundi Keutamaan dengan Pre-terjemahan Dua Arah Untuk Pemulihan Bitext', 'ml': 'Majority Voting with Bidirectional Pre-translation For Bitext Retrieval', 'mt': 'Votazzjoni tal-Maġġoranza bi Pretraduzzjoni Bidirezzjonali għall-kisba tal-Bitext', 'mn': 'Хоёр багын алдын хөрөнгө оруулалтын гол санал', 'no': 'Storleik stemmer med to retning før omsetjing for bitteksthenting', 'pl': 'Większość głosów z dwukierunkowym tłumaczeniem wstępnym dla pobierania bitextu', 'ro': 'Votul majorității cu pre-traducere bidirecțională pentru recuperarea bitextului', 'sr': 'Veličina glasanja sa dvosmjernicalnim prevodom za otkupljanje bitexta', 'sv': 'Majoritetsomröstning med dubbelriktad förhandsöversättning för bitexthämtning', 'so': 'Inta badan Voting with Bidirectional Pre-translation For Bitext Retrieval', 'si': 'බිට්ටෙක්ස් ප්\u200dරවේශනය සඳහා ප්\u200dරධාන වෝට් කරන්න', 'ta': 'பைஉரை மீட்டெடுப்புக்கான இருதிசை முன்- மொழிபெயர்ப்புடன் பெரும்பாலான வாக்குதல்', 'ur': 'بیٹکسٹ پھیرنے کے لئے دو دقیق پیش ترجمہ کے ساتھ بڑی ویٹنگ', 'vi': 'Việc bỏ phiếu đa số với tiền dịch sẵn định hướng Cho tim giá trị Bitext', 'uz': '@ info: whatsthis', 'da': 'Flertallet stemmer med bidirektionel forhåndsoversættelse til bitext hentning', 'hr': 'Veličina glasanja s dvosmjernim prevodom za otkupljanje bitexta', 'nl': 'Meerderheid Stemmen met Bidirectionele Pre-vertaling Voor Bitext Retrieval', 'bg': 'Гласуване по мнозинство с двупосочен предварителен превод за извличане на биттекст', 'de': 'Mehrheitsabstimmung mit bidirektionaler Vorübersetzung für Bitext Retrieval', 'id': 'Pemilihan Keutamaan dengan Pre-terjemahan Biarah Untuk Pengambilan Bitext', 'ko': '양방향 사전 번역 기반의 다수결 투표 검색 기술', 'fa': '亘夭乇诏鬲乇蹖賳 乇丕蹖 亘丕 鬲乇噩賲賴 倬蹖卮 丕夭 丿賵 胤乇賮 亘乇丕蹖 亘丕夭蹖丕亘蹖 亘蹖鬲鈥宔xt', 'sw': 'Kura kwa ajili ya Bitext Retrieval', 'tr': 'Bitext Mazmuny üçin Edilmek üçin Gatulmak', 'af': 'Grootste stem met twee rigting voor- vertaling vir bitext ontvang', 'sq': 'Votimi i shumicës me parapërkthimin dy-drejtues për marrjen e Bitext', 'hy': 'Բազմաթիվ քվեարկություն երկիուղղությամբ նախաթարգմանելու համար', 'az': 'Bitext almas캼 칲칞칲n iki t톛r톛fd톛n 톛vv톛l 칞eviril톛n b칬y칲k s톛sl톛r', 'ca': 'Votació majoritària amb traducció bidireccionalper obtenir bitext', 'bn': 'বাইটেক্সট পুনরুদ্ধারের জন্য বাইডেডিয়াল পূর্ব- অনুবাদ দিয়ে বেশীরভাগ ভোট দিয়েছে', 'cs': 'Většina hlasování s obousměrným překladem pro vyhledávání bitextu', 'et': 'Enamiku hääletamine kahesuunalise eeltõlkega Bitexti taastamiseks', 'am': 'Voting with Bidirectional Pre-translation For Bitext Retrieval', 'fi': 'Enemmistöäänestys kaksisuuntaisella esikäsittelyllä Bitext-noutoa varten', 'bs': 'Veličina glasanja sa dvosmjernicalnim prevodom za otkupljanje bitexta', 'jv': 'translation', 'sk': 'Večinsko glasovanje z dvosmernim predprevodom za pridobivanje bitexta', 'he': 'הצבעה רבה עם התרגום קדם שתיים כיוונים לקבלת Bitext', 'ha': 'Majority Voting with Bidirectional Pre-translation For Bitext Retrieval', 'bo': 'Bitext ལོག་སླུང་ཕྱོགས་དང་འདྲ་བའི་སྔོན་ལྗོངས་ཀྱི་གཏོང་གཏོང་།'}
{'en': 'Obtaining high-quality parallel corpora is of paramount importance for training NMT systems. However, as many language pairs lack adequate gold-standard training data, a popular approach has been to mine so-called pseudo-parallel sentences from paired documents in two languages. In this paper, we outline some drawbacks with current methods that rely on an embedding similarity threshold, and propose a heuristic method in its place. Our method involves translating both halves of a paired corpus before mining, and then performing a majority vote on sentence pairs mined in three ways : after translating documents in language x to language y, after translating language y to x, and using the original documents in languages x and y. We demonstrate success with this novel approach on the Tatoeba similarity search benchmark in 64 low-resource languages, and on NMT in Kazakh and Gujarati. We also uncover the effect of resource-related factors (i.e. how much monolingual / bilingual data is available for a given language) on the optimal choice of bitext mining method, demonstrating that there is currently no one-size-fits-all approach for this task. We make the code and data used in our experiments publicly available.', 'ar': 'يعد الحصول على هيئة موازية عالية الجودة أمرًا بالغ الأهمية لتدريب أنظمة NMT. ومع ذلك ، نظرًا لأن العديد من الأزواج اللغوية تفتقر إلى بيانات تدريب مناسبة ذات معيار ذهبي ، فقد كان الأسلوب الشائع هو استخراج ما يسمى بالجمل "شبه الموازية" من المستندات المزدوجة بلغتين. في هذه الورقة ، نحدد بعض العيوب مع الأساليب الحالية التي تعتمد على عتبة التضمين التشابه ، ونقترح طريقة الكشف عن مجريات الأمور في مكانها. تتضمن طريقتنا ترجمة نصفي مجموعة النصوص المزدوجة قبل التنقيب ، ثم إجراء تصويت الأغلبية على أزواج الجمل المستخرجة بثلاث طرق: بعد ترجمة المستندات من اللغة x إلى اللغة y ، وبعد ترجمة اللغة من y إلى x ، واستخدام المستندات الأصلية في اللغات x و y. لقد أثبتنا النجاح مع هذا النهج الجديد في معيار بحث تشابه Tatoeba في 64 لغة منخفضة الموارد ، وعلى NMT باللغتين الكازاخستانية والغوجاراتية. نكشف أيضًا عن تأثير العوامل المتعلقة بالموارد (أي مقدار البيانات أحادية اللغة / ثنائية اللغة المتاحة للغة معينة) على الاختيار الأمثل لطريقة استخراج نص البت ، مما يدل على أنه لا يوجد حاليًا نهج واحد يناسب الجميع لهذا الغرض. مهمة. نجعل الكود والبيانات المستخدمة في تجاربنا متاحة للجمهور.', 'es': 'La obtención de cuerpos paralelos de alta calidad es de suma importancia para la formación de los sistemas de NMT. Sin embargo, dado que muchos pares de idiomas carecen de datos de entrenamiento adecuados, un enfoque popular ha sido extraer las llamadas oraciones «pseudo-paralelas» de documentos emparejados en dos idiomas. En este artículo, describimos algunos inconvenientes de los métodos actuales que se basan en un umbral de similitud de incrustación y proponemos un método heurístico en su lugar. Nuestro método consiste en traducir ambas mitades de un corpus pareado antes de extraer, y luego realizar una votación mayoritaria sobre los pares de oraciones extraídos de tres maneras: después de traducir documentos del idioma x al idioma y, después de traducir el idioma y a x, y usar los documentos originales en los idiomas x e y. éxito con este novedoso enfoque en el punto de referencia de búsqueda de similitud de Tatoeba en 64 idiomas de bajos recursos, y en NMT en kazajo y gujarati. También descubrimos el efecto de los factores relacionados con los recursos (es decir, cuántos datos monolingües/bilingües están disponibles para un idioma determinado) en la elección óptima del método de minería de bitexto, lo que demuestra que actualmente no hay un enfoque único para esta tarea. Ponemos a disposición del público el código y los datos utilizados en nuestros experimentos.', 'fr': "L'obtention de corpus parallèles de haute qualité est d'une importance capitale pour la formation des systèmes NMT. Cependant, comme de nombreuses paires de langues ne disposent pas de données de formation de référence adéquates, une approche populaire a été d'extraire des phrases dites «\xa0pseudo-parallèles\xa0» à partir de documents appariés en deux langues. Dans cet article, nous soulignons certains inconvénients des méthodes actuelles qui reposent sur un seuil de similarité d'intégration, et proposons une méthode heuristique à sa place. Notre méthode consiste à traduire les deux moitiés d'un corpus apparié avant l'extraction, puis à effectuer un vote majoritaire sur les paires de phrases extraites de trois manières\xa0: après avoir traduit des documents de la langue x vers la langue y, après avoir traduit la langue y vers x et utiliser les documents originaux dans les langues x et y. succès avec cette approche novatrice sur le critère de recherche de similarité Tatoeba dans 64 langues à faible ressource, et sur la NMT en kazakh et en gujarati. Nous découvrons également l'effet des facteurs liés aux ressources (c'est-à-dire la quantité de données monolingues/bilingues disponibles pour une langue donnée) sur le choix optimal de la méthode d'exploration bitexte, démontrant ainsi qu'il n'existe actuellement aucune approche universelle pour cette tâche. Nous mettons le code et les données utilisés dans nos expériences à la disposition du public.", 'pt': 'A obtenção de corpora paralelos de alta qualidade é de suma importância para o treinamento de sistemas NMT. No entanto, como muitos pares de idiomas não possuem dados de treinamento padrão-ouro adequados, uma abordagem popular tem sido extrair as chamadas frases “pseudo-paralelas” de documentos emparelhados em dois idiomas. Neste artigo, descrevemos algumas desvantagens dos métodos atuais que dependem de um limiar de similaridade incorporado e propomos um método heurístico em seu lugar. Nosso método envolve traduzir as duas metades de um corpus pareado antes da mineração e, em seguida, realizar uma votação majoritária nos pares de frases extraídos de três maneiras: depois de traduzir os documentos no idioma x para o idioma y, depois de traduzir o idioma y para x e usar os documentos originais em linguagens x e y. Demonstramos sucesso com essa nova abordagem no benchmark de pesquisa de similaridade Tatoeba em 64 idiomas de poucos recursos e no NMT em cazaque e gujarati. Também descobrimos o efeito de fatores relacionados a recursos (ou seja, quantos dados monolíngues/bilíngues estão disponíveis para um determinado idioma) na escolha ideal do método de mineração de bitexto, demonstrando que atualmente não há uma abordagem única para isso. tarefa. Disponibilizamos publicamente o código e os dados usados em nossos experimentos.', 'ja': 'NMTシステムをトレーニングするためには、高品質の並列体を得ることが最も重要です。 しかしながら、多くの言語ペアは適切なゴールドスタンダードのトレーニングデータを欠いているため、一般的なアプローチは、2つの言語のペアドキュメントからいわゆる「疑似並列」文を採掘することである。 本稿では，埋め込み類似度閾値に依存する現行手法の欠点を概説し，その代わりにヒューリスティック手法を提案する． 私たちの方法は、マイニングの前にペアになったコーパスの両半分を翻訳し、次に、3つの方法でマイニングされた文のペアで多数決を実行することです。言語xから言語yへの文書の翻訳後、言語yから言語xへの翻訳後、および言語xと言語yでの元の文書の使用後です。 私たちは、64の低資源言語のTatoeba類似性検索ベンチマークと、カザフ語とグジャラート語のNMTで、この新しいアプローチで成功を実証しています。 また、ビットテキストマイニング方法の最適な選択に対するリソース関連要因（すなわち、特定の言語で利用可能な単一言語/バイリンガルデータの量）の影響も明らかにし、このタスクには現在、万能のアプローチがないことを示しています。 当社は、実験で使用されたコードとデータを公開しています。', 'zh': '得高质量者并行语料库于训练 NMT 系统至重。 然多言足于黄金之数,一行之法,从二言之配对文档掘所谓"伪平行"句也。 凡本文,概述依嵌相似性阈值之病,立一启发式之法。 凡掘前翻译成语料库两半,然后以三对多投票:以语言x中文档翻译成y之后,以言语y翻译成x之后,及用语言xy之始文档。 64种低资源语Tatoeba相似性搜准及哈萨克语古吉拉特语NMT展此新功。 又揭资源相关(即给定语言可用者单语/双语数据量)于双文本掘法最佳,明目前无一当之宜也。 臣等明实验所用代码数。', 'hi': 'उच्च गुणवत्ता वाले समानांतर निगम प्राप्त करना एनएमटी प्रणालियों के प्रशिक्षण के लिए सर्वोपरि महत्व का है। हालांकि, चूंकि कई भाषा जोड़ों में पर्याप्त स्वर्ण-मानक प्रशिक्षण डेटा की कमी होती है, इसलिए एक लोकप्रिय दृष्टिकोण दो भाषाओं में युग्मित दस्तावेजों से तथाकथित "छद्म-समानांतर" वाक्यों का खनन करने के लिए किया गया है। इस पेपर में, हम वर्तमान विधियों के साथ कुछ कमियों को रेखांकित करते हैं जो एक एम्बेडिंग समानता सीमा पर भरोसा करते हैं, और इसके स्थान पर एक हेरिस्टिक विधि का प्रस्ताव करते हैं। हमारी विधि में खनन से पहले एक युग्मित कॉर्पस के दोनों हिस्सों का अनुवाद करना शामिल है, और फिर तीन तरीकों से खनन किए गए वाक्य जोड़े पर बहुमत वोट करना: भाषा x में दस्तावेज़ों का अनुवाद करने के बाद भाषा y को x में अनुवाद करने के बाद, और भाषाओं x और y में मूल दस्तावेजों का उपयोग करने के बाद। हम 64 कम संसाधन भाषाओं में ताटोबा समानता खोज बेंचमार्क पर इस उपन्यास दृष्टिकोण के साथ सफलता का प्रदर्शन करते हैं, और कजाख और गुजराती में एनएमटी पर। हम bitext खनन विधि के इष्टतम विकल्प पर संसाधन से संबंधित कारकों (यानी किसी दिए गए भाषा के लिए कितना मोनोलिंगुअल / द्विभाषी डेटा उपलब्ध है) के प्रभाव को भी उजागर करते हैं, यह प्रदर्शित करते हुए कि वर्तमान में इस कार्य के लिए कोई एक-आकार-फिट-सभी दृष्टिकोण नहीं है। हम अपने प्रयोगों में उपयोग किए जाने वाले कोड और डेटा को सार्वजनिक रूप से उपलब्ध कराते हैं।', 'ru': 'Получение высококачественных параллельных тел имеет первостепенное значение для обучения НМТ-систем. Однако, поскольку многие языковые пары не имеют достаточных данных для обучения по золотому стандарту, популярным подходом было извлечение так называемых «псевдопараллельных» предложений из парных документов на двух языках. В этой статье мы излагаем некоторые недостатки с текущими методами, которые опираются на встраивание порога подобия, и предлагаем эвристический метод на его месте. Наш метод включает в себя перевод обеих половин парного корпуса перед майнингом, а затем выполнение большинства голосов по парам предложений, добываемым тремя способами: после перевода документов на языке x на язык y, после перевода языка y на x и использования исходных документов на языках x и y. Мы демонстрируем успех с этим новым подходом по критерию поиска сходства Tatoeba на 64 языках с низким уровнем ресурсов, а также по NMT на казахском и гуджарати. Мы также раскрываем влияние факторов, связанных с ресурсами (то есть, сколько одноязычных/двуязычных данных доступно для данного языка) на оптимальный выбор метода майнинга bitext, демонстрируя, что в настоящее время не существует универсального подхода для этой задачи. Мы делаем код и данные, используемые в наших экспериментах, общедоступными.', 'ga': 'Tá sé ríthábhachtach corpas comhthreomhar ardchaighdeáin a fháil chun córais NMT a thraenáil. Mar sin féin, toisc nach bhfuil dóthain sonraí oiliúna caighdeánacha óir ag go leor péirí teangacha, ba é an cur chuige coitianta ná abairtí “pseudo-comhthreomhar” mar a thugtar orthu ó dhoiciméid péireáilte in dhá theanga. Sa pháipéar seo, tugaimid breac-chuntas ar roinnt míbhuntáistí a bhaineann le modhanna reatha atá ag brath ar thairseach cosúlachta leabú, agus molaimid modh heoraíoch ina áit. Is éard atá i gceist leis an modh atá againn ná an dá leath de chorpas péireáilte a aistriú roimh mhianadóireacht, agus ansin vóta tromlaigh a dhéanamh ar phéirí abairtí a baineadh amach ar thrí bhealach: tar éis doiciméid a aistriú i dteanga x go teanga y, tar éis teanga y a aistriú go x, agus na buncháipéisí a úsáid i teangacha x agus y. Léirímid rath leis an gcur chuige nua seo ar thagarmharc cuardaigh cosúlachta Tatoeba i 64 teanga íseal-acmhainne, agus ar NMT i Kazakh agus Gúisearáitis. Nochtaimid freisin éifeacht fachtóirí a bhaineann le hacmhainní (i.e. cé mhéad sonraí aonteangacha/dátheangacha atá ar fáil do theanga ar leith) ar an rogha is fearr maidir le modh mianadóireachta biththéacs, rud a thaispeánann nach bhfuil aon chur chuige amháin a oireann do chách ann faoi láthair. tasc. Cuirimid an cód agus na sonraí a úsáidtear inár dturgnaimh ar fáil go poiblí.', 'el': 'Η απόκτηση υψηλής ποιότητας παράλληλων σωμάτων είναι υψίστης σημασίας για την εκπαίδευση συστημάτων NMT. Ωστόσο, καθώς πολλά γλωσσικά ζεύγη στερούνται επαρκών δεδομένων κατάρτισης χρυσών προτύπων, μια δημοφιλής προσέγγιση ήταν η εξόρυξη των λεγόμενων "ψευδο-παράλληλων" προτάσεων από ζευγαρωμένα έγγραφα σε δύο γλώσσες. Στην παρούσα εργασία, περιγράφουμε ορισμένα μειονεκτήματα με τις τρέχουσες μεθόδους που βασίζονται σε ένα όριο ομοιότητας ενσωμάτωσης, και προτείνουμε μια heuristική μέθοδο στη θέση της. Η μέθοδος μας περιλαμβάνει τη μετάφραση και των δύο μισών ενός ζευγαριού σώματος πριν από την εξόρυξη, και στη συνέχεια τη διεξαγωγή ψηφοφορίας πλειοψηφίας σε ζεύγη προτάσεων που εξορυχθούν με τρεις τρόπους: μετά τη μετάφραση εγγράφων στη γλώσσα x στη γλώσσα y, μετά τη μετάφραση γλώσσας y σε x, Αποδεικνύουμε την επιτυχία με αυτή τη νέα προσέγγιση στο κριτήριο αναζήτησης ομοιότητας Tatoeba σε 64 γλώσσες χαμηλού πόρου, και στο NMT στα Καζακικά και Γκουτζαράτι. Επίσης, αποκαλύπτουμε την επίδραση των παραγόντων που σχετίζονται με τους πόρους (δηλαδή πόσα μονογλωσσικά/δίγλωσσα δεδομένα είναι διαθέσιμα για μια δεδομένη γλώσσα) στη βέλτιστη επιλογή της μεθόδου εξόρυξης αποδεικνύοντας ότι επί του παρόντος δεν υπάρχει ενιαία προσέγγιση για το έργο αυτό. Κάνουμε τον κώδικα και τα δεδομένα που χρησιμοποιούνται στα πειράματά μας δημόσια διαθέσιμα.', 'ka': 'უფრო მნიშვნელოვანი პარალელური კოპორაცია NMT სისტემებისთვის უფრო მნიშვნელოვანია. მაგრამ, რადგან მრავალი ენის ზოგები არსებობს მარტივი მონაცემები, პოლუპური პროგრამი იყო ჩემის რაც უნდა იყო "pseudo-parallel" მონაცემები ორი ენის დოკუმენტიდან. ამ დოკუნში, ჩვენ მიმდინარე მეტოვებით გამოყენებთ რამდენიმე კონფიგურაცია, რომელიც დავყენება განსხვავებული სინამდვილეობის დონფიგურაციას და მისი ადგილში ჰერის ჩვენი პროცემი შეფარდება ორივე ნახევარი ორივე კორპუსის გადატანაცია მინეთის წინ, და შემდეგ უფრო მეტი გადატანაცია მინეთის წინ სამი გზით: წინ x-ში წინ y-ზე გადატანაციის შემდეგ y-ს x-ზე, და გამოყენება ორიგინალური დოკუმენტების x და y ენაში. ჩვენ გამოყენებთ ამ პრომენტის წარმატებით რატოების სინამდვილეობის ძიება ბენქმმარკის 64 მარტივი რესურსის ენაში და NMT-ზე კაზაკში და დუჯ ჩვენ ასევე აღმოჩნეთ რესურსის შესახებ ფაქტორის ეფექტი (მაგალითად, რამდენიმე მონოლენგური/ორიენგური მონაცემები იქნება განახლებელი ენათისთვის) სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა მონაცემე ჩვენ ჩვენი ექსპერიმენტებში გამოყენებული კოდი და მონაცემები გავაკეთებთ.', 'it': 'Ottenere corpi paralleli di alta qualità è di fondamentale importanza per la formazione dei sistemi NMT. Tuttavia, poiché molte coppie linguistiche mancano di adeguati dati di formazione standard oro, un approccio popolare è stato quello di estrarre frasi cosiddette "pseudo-parallele" da documenti accoppiati in due lingue. In questo articolo, delineamo alcuni svantaggi con i metodi attuali che si basano su una soglia di somiglianza incorporante, e proponiamo un metodo euristico al suo posto. Il nostro metodo prevede la traduzione di entrambe le metà di un corpus accoppiato prima del mining, e poi l\'esecuzione di un voto a maggioranza su coppie di frasi estratte in tre modi: dopo aver tradotto documenti nella lingua x in lingua y, dopo aver tradotto la lingua y in x, Abbiamo dimostrato il successo con questo nuovo approccio sul benchmark di ricerca della somiglianza Tatoeba in 64 lingue a basso contenuto di risorse, e sul NMT in kazako e gujarati. Scopriamo anche l\'effetto dei fattori correlati alle risorse (cioè quanti dati monolingue/bilingui sono disponibili per una determinata lingua) sulla scelta ottimale del metodo di mining bitest, dimostrando che attualmente non esiste un approccio one-size-fits-all per questo compito. Rendiamo pubblicamente disponibili il codice e i dati utilizzati nei nostri esperimenti.', 'lt': 'Aukštos kokybės lygiagrečios korporacijos įgijimas yra labai svarbus mokymo NMT sistemoms. Tačiau, kadangi daugeliui kalbų porų trūksta tinkamų aukso standartinių mokymo duomenų, populiarus požiūris buvo panaudoti vadinamuosius "pseudolygiagrečius" sakinius iš dviejų kalbų parių dokumentų. Šiame dokumente apibūdiname kai kuriuos trūkumus taikant dabartinius metodus, kurie grindžiami įterpiama panašumo riba, ir siūlome heuristinį metodą vietoj jo. Mūsų metodas apima dviejų pusių poros korpuso vertimą prieš kasybą, o vėliau daugumos balsavimą dėl sakinių poros, kasuojamų trimis būdais: vertus dokumentus x kalba į y kalbą, vertus kalbą y į x, Naudodami šį naują metodą sėkmingai parodome Tatoeba panašumo paieškos lyginamąjį rodiklį 64 mažai išteklių turinčiomis kalbomis ir NMT Kazachų ir Gujaračio kalbomis. We also uncover the effect of resource-related factors (i.e. how much monolingual/bilingual data is available for a given language) on the optimal choice of bitext mining method, demonstrating that there is currently no one-size-fits-all approach for this task.  Mes viešai paskelbiame savo eksperimentuose naudojamą kodą ir duomenis.', 'kk': 'Жоғары сапатты параллель корпора қабылдау NMT жүйелерін оқыту үшін ең маңызды. Бірақ тіл екеуінің көпшілігі жеткілікті алтын- стандартты оқыту деректері жоқ болғанда, менің "псевдо- параллель" сөздерім екі тілде қос құжаттардан қос сөздерінен қатысты. Бұл қағазда біз қазірдегі әдістерді ендіру ұқсас шегіне сеніп, оның орнында геуристикалық әдістерді таңдаймыз. Біздің әдіміміз, балау алдында екі жарты корпусын аударып, үш түрде бойынша, үш түрде құжаттарды x тіліне y тіліне аударып, y тіліне x тіліне аударып, x мен y тілдерінде бастапқы құжаттарды қолдануға болады. Біз Tatoeba-тың 64 төмен ресурс тілдерінде және Казахстан және Гуджаратындағы NMT-тың сәттілігін көрсетедік. Біз сондай-ақ ресурстарымен қатысты факторлардың эффектін (мысалы, келтірілген тіл үшін қанша монолингі/екі тілді деректер қол жеткізілген) бағыттау әдісінің оптималы таңдау әдісін таңдап, осы тапсырма үшін бір өлшемі- Біз тәжірибемізде қолданылатын код мен деректер қолданылады.', 'hu': 'A kiváló minőségű párhuzamos korpuszok megszerzése kiemelkedő fontosságú az NMT rendszerek képzésében. Mivel azonban sok nyelvpár hiányzik a megfelelő aranyszínvonalú képzési adatokkal, népszerű megközelítés volt az, hogy úgynevezett "pszeudopárhuzamos" mondatokat bányásznak a párosított dokumentumokból két nyelven. Ebben a tanulmányban felvázolunk néhány hátrányt a jelenlegi módszerekkel, amelyek hasonlósági küszöbértékre támaszkodnak, és helyette heurisztikus módszert javasolunk. Módszerünk magában foglalja a párosított korpusz mindkét felének lefordítását a bányászat előtt, majd többségi szavazást végez a mondatpárokról három módon: dokumentumok x nyelvre történő lefordítása után y nyelvre, y nyelvre történő lefordítása után, Ezzel az újszerű megközelítéssel a Tatoeba hasonlóságkeresési referenciaértékén 64 alacsony erőforrású nyelven, valamint az NMT-n kazah és guzsárati nyelven bizonyítottuk sikerességét. Feltárjuk továbbá az erőforrásokhoz kapcsolódó tényezők (azaz mennyi egynyelvű/kétnyelvű adat áll rendelkezésre egy adott nyelvre) hatását a bitext bányászati módszer optimális kiválasztására, bizonyítva, hogy jelenleg nincs egy-mindenki számára egységes megközelítés erre a feladatra. A kísérleteinkben használt kódot és adatokat nyilvánosan hozzáférhetővé tesszük.', 'mk': 'Добивањето висококвалитетна паралелна корпора е од најважна важност за обуката на НМТ системите. Сепак, со оглед на тоа што многу јазички парови немаат соодветни златни стандардни податоци за обука, популарниот пристап беше на моите т.н. „псевдо-паралелни“ реченици од парирани документи на два јазици. Во овој документ, ги опишуваме некои недостатоци со сегашните методи кои се потпираат на вграден праг на сличност, и предложуваме хеористички метод на негово место. Нашиот метод вклучува преведување на двете половини од пар корпус пред рударството, а потоа спроведување мнозинско гласање за парови на реченици минирани на три начини: по преведувањето на документите на јазик Х на јазик Ј, по преведувањето на јазик Ј на Х, Ние демонстрираме успех со овој романски пристап на референтниот знак за пребарување на сличноста на Татоеба на 64 јазици со ниски ресурси и на НМТ на Казахски и Гуџарати. We also uncover the effect of resource-related factors (i.e. how much monolingual/bilingual data is available for a given language) on the optimal choice of bitext mining method, demonstrating that there is currently no one-size-fits-all approach for this task.  Ги правиме кодовите и податоците кои ги користиме во нашите експерименти јавно достапни.', 'ms': "Obtaining high-quality parallel corpora is of paramount importance for training NMT systems.  Namun, kerana banyak pasangan bahasa kekurangan data latihan piawai emas yang cukup, pendekatan populer telah menjadi saya yang dipanggil kalimat 'pseudo-parallel' dari dokumen pasangan dalam dua bahasa. Dalam kertas ini, kita menggambarkan beberapa kelemahan dengan kaedah semasa yang bergantung pada ambang persamaan, dan mencadangkan kaedah heuristik di tempatnya. Kaedah kita melibatkan menerjemahkan kedua-dua separuh dari satu corpus pasangan sebelum perlombongan, dan kemudian melakukan suara kebanyakan pasangan kalimat terlombongan dalam tiga cara: selepas menerjemahkan dokumen dalam bahasa x ke bahasa y, selepas menerjemahkan bahasa y ke x, - dan menggunakan dokumen asal dalam bahasa x dan y. Kami menunjukkan keberhasilan dengan pendekatan novel ini pada tanda referensi gelintaran Tatoeba dalam 64 bahasa sumber rendah, dan pada NMT dalam Kazakh dan Gujarati. Kami juga mengungkap kesan faktor berkaitan dengan sumber (iaitu berapa banyak data monobahasa/bilingual yang tersedia untuk bahasa tertentu) pada pilihan optimal kaedah lombong bitext, menunjukkan bahawa pada masa ini tiada pendekatan-satu-saiz-sepadan-semua untuk tugas ini. Kami membuat kod dan data yang digunakan dalam eksperimen kami tersedia kepada masyarakat.", 'no': 'Å få høg kvalitet parallelle korpora er viktig for opplæring av NMT-systemet. Men så mange språkparar manglar adequate gull-standard treningsdata, har ein populært tilnærming til mine så kalla « pseudoparallelle » setningar frå pare dokument på to språk. I denne papiret blir vi omforma noen teikningar med gjeldande metoder som er på ein innbygging av liknande grensesnitt, og foreslår ein heuristisk metode på plassen. Metoden vårt involverer å omsetja begge halvparten av ein par korpus før mining, og så utføra ein fleste stemme på setningsmar som er minert på tre måtar: etter omsetjinga av dokument i språk x til språk y, etter omsetjinga av språk y til x, Og bruk dei originale dokumenta i språk x og y. Vi viser suksess med denne roman tilnærming på Tatoeba-søkjemarket på 64 låg ressursspråk, og på NMT i Kazakh og Gujarati. Vi opnar også effekten av ressursrelaterte faktorer (t.d. kor mykje monolingual/bilinguelt data er tilgjengeleg for ein gitt språk) på optimal valet av bittekstminingsmetoden, som viser at det ikkje finst noko storleik-tilpassande tilnærming for denne oppgåva. Vi gjer koden og data brukt i eksperimentene våre offentlig tilgjengeleg.', 'ml': 'എംഎംടി സിസ്റ്റം പരിശീലിക്കുന്നതിനുള്ള പ്രധാന പ്രധാനപ്പെട്ടതാണ്. എന്നാലും അധികം ഭാഷ ജോടികള്\u200dക്ക് മതിയായ സ്വര്\u200dണ്ണസ്ഥാനമായ പരിശീലന വിവരങ്ങള്\u200d ഇല്ലെങ്കിലും, രണ്ടു ഭാഷകളില്\u200d നിന്നും എന്\u200dറെ ഇങ്ങനെ പ്രധാനപ്പെ In this paper, we outline some drawbacks with current methods that rely on an embedding similarity threshold, and propose a heuristic method in its place.  നമ്മുടെ രീതിയില്\u200d രണ്ട് പാതി കോര്\u200dപ്പുസിന്റെയും മുമ്പ് ഭാഷപ്പെടുത്തുന്നതിന് മുമ്പ്, പിന്നീട് മൂന്നു വഴിയില്\u200d മുഴുവന്\u200d ഭാഷ വോട്ട് നടത്തുന്നതിന ഭാഷയിലെ മൂല രേഖകള്\u200d എക്സ് യിയില്\u200d ഉപയോഗിക്കുകയും ചെയ്യുന്നു. ഈ നോവലിന്റെ നടപടിയില്\u200d നാം വിജയം കാണിക്കുന്നു. താട്ടോബാ തെരച്ചില്\u200d 64 കുറഞ്ഞ വിഭവങ്ങളുട വിഭവങ്ങളുടെ സംബന്ധിച്ചുള്ള വിഭവങ്ങളുടെ പ്രഭാവങ്ങളും ഞങ്ങള്\u200d കണ്ടെത്തുന്നു. (അതായത് കൊടുത്ത ഭാഷയ്ക്ക് എത്ര മോണോളില്\u200d/രണ്ടു ഭാഷ വിവരങ്ങള്\u200d ലഭ്യമാകുന്നു) ബിക്സ്റ്റ നമ്മുടെ പരീക്ഷണങ്ങളില്\u200d ഉപയോഗിക്കുന്ന കോഡും വിവരങ്ങളും പ്രത്യക്ഷമായി ലഭ്യമാക്കുന്നു.', 'pl': 'Uzyskanie wysokiej jakości korpusów równoległych ma ogromne znaczenie dla szkolenia systemów NMT. Jednakże, ponieważ wiele par językowych brakuje odpowiednich danych treningowych o złotym standardzie, popularnym podejściem było wydobywanie tzw. "pseudo-równoległych" zdań ze sparowanych dokumentów w dwóch językach. W niniejszym artykule przedstawiamy kilka wad obecnych metod, które opierają się na progu podobieństwa osadzenia, oraz zaproponujemy metodę heurystyczną w jego miejscu. Nasza metoda polega na tłumaczeniu obu połówek parowanego korpusu przed wydobyciem, a następnie przeprowadzeniu głosu większościowego na pary zdań wydobytych na trzy sposoby: po przetłumaczeniu dokumentów w języku x na język y, po przetłumaczeniu języka y na x, Wykazujemy sukces z tym nowatorskim podejściem do wyszukiwania podobieństwa Tatoeba w 64 językach niskich zasobów oraz NMT w językach kazachskim i gujarati. Odkrywamy również wpływ czynników związanych z zasobami (tj. ilość danych jednojęzycznych/dwujęzycznych jest dostępna dla danego języka) na optymalny wybór metody wydobywania bitekstów, pokazując, że obecnie nie istnieje jednolitego podejścia do tego zadania. Kod i dane wykorzystywane w naszych eksperymentach udostępniamy publicznie.', 'mt': 'Il-kisba ta’ korpora parallela ta’ kwalità għolja hija ta’ importanza kbira għat-taħriġ tas-sistemi NMT. Madankollu, peress li ħafna pari lingwistiċi m’għandhomx dejta adegwata ta’ taħriġ standard tad-deheb, approċċ popolari kien li jinħadmu l-hekk imsejħa sentenzi “psewdo-parallel” minn dokumenti pari f’żewġ lingwi. F’dan id-dokument, a ħna niddeskrivu xi nuqqasijiet bil-metodi attwali li jiddependu fuq limitu ta’ similarità inkorporat, u nipproponu metodu ewristiku minflok. Il-metodu tagħna jinvolvi t-traduzzjoni taż-żewġ nofs ta’ korpus par qabel it-tħaffir fil-minjieri, u mbagħad it-twettiq ta’ vot maġġoritarju fuq pari ta’ sentenzi minjieri bi tliet modi: wara t-traduzzjoni tad-dokumenti fil-lingwa x għal-lingwa y, wara t-traduzzjoni tal-lingwa y għal x, • u bl-użu tad-dokumenti oriġinali fil-lingwi x u y. Aħna nuru suċċess b’dan l-approċċ ġdid dwar il-punt ta’ riferiment tat-tiftix simili Tatoeba f’64 lingwa b’riżorsi baxxi, u dwar l-NMT fil-Każak u l-Gujarati. We also uncover the effect of resource-related factors (i.e. how much monolingual/bilingual data is available for a given language) on the optimal choice of bitext mining method, demonstrating that there is currently no one-size-fits-all approach for this task.  Aħna nagħmlu l-kodiċi u d-dejta użati fl-esperimenti tagħna disponibbli għall-pubbliku.', 'mn': 'Өндөр чанартай параллел корпора нь NMT системийн сургалтын тулд хамгийн чухал. Гэвч олон хэл хоёр нь зөвхөн алт-стандарт суралцах өгөгдлийн талаар байхгүй, олон хүн төрөлхтний арга баримтууд миний "pseudo-parallel" гэдэг хэлбэрээс хоёр хэлний баримтуудаас холбогдсон үг. Энэ цаасан дээр бид одоогийн арга барилгын төстэй хэмжээнд итгэдэг зарим арга барилгыг тайлбарлаж, түүний оронд хэмжээний арга барилгыг санал болгож байна. Бидний арга нь хоёр талыг хоёр хоёр корпус хөрөнгө оруулахаас өмнө орлуулж, дараа нь ихэнх нь хоёр хоёр хоёрыг гурван аргаар зохион өгүүлсэн үгийг дамжуулах болно: x хэлний дараа y хэлний дараа, y хэлний x хэлний дараа, Х, Y хэлний эхний баримтуудыг ашиглаж байна. Бид Tatoeba-ын төстэй шинэ арга баримтуудын амжилтыг 64 бага нөөцийн хэл болон Казах болон Гуджаратын NMT-д үзүүлдэг. Мөн бид үүсвэртэй холбоотой хүчин зүйлсийн нөлөөг (яг л нэг хэл/хоёр хэл өгөгдлийн мэдээллийг өгсөн хэл дээр хэр их боломжтой вэ гэдгийг) харуулж байна. Өөр үед энэ үйл ажилд хэн нэг хэмжээтэй байхгүй гэдгийг харуулж байна. Бид өөрсдийн туршилтанд код болон өгөгдлийг олон нийтэд ашиглаж чадна.', 'ro': 'Obținerea corpurilor paralele de înaltă calitate este de o importanță esențială pentru instruirea sistemelor NMT. Cu toate acestea, deoarece multe perechi lingvistice nu au date adecvate de instruire de calitate aurie, o abordare populară a fost extragerea așa-numitelor propoziții "pseudo-paralele" din documentele asociate în două limbi. În această lucrare, prezentăm unele dezavantaje cu metodele actuale care se bazează pe un prag de similitudine încorporată și propunem o metodă euristică în locul său. Metoda noastră implică traducerea ambelor jumătăți ale unui corpus pereche înainte de extragere, și apoi efectuarea unui vot majoritar pe perechile de propoziții extrase în trei moduri: după traducerea documentelor în limba x în limba y, după traducerea limbii y în x, Cu această abordare nouă demonstrăm succes în căutarea similarității Tatoeba în 64 de limbi cu resurse reduse, precum și pe NMT în kazahă și gujarati. De asemenea, descoperim efectul factorilor legate de resurse (adică cât de multe date monolingve/bilingve sunt disponibile pentru o anumită limbă) asupra alegerii optime a metodei bitext mining, demonstrând că în prezent nu există o abordare unică pentru această sarcină. Facem public codul și datele folosite în experimentele noastre.', 'sr': 'Uzdržavanje visokokvalitetnog paralelnog korporacije je od najvažnije važnosti za obuku NMT sistema. Međutim, pošto mnogi jezički parovi nedostaju odgovarajući podaci o obuci zlata-standard a, popularan je pristup mojim takozvanim "pseudoparalelnim" rečenicama iz parnih dokumenta na dva jezika. U ovom papiru, pokazujemo neke štete sa trenutnim metodama koji se oslanjaju na ugrađeni prag sličnosti i predlažemo heurističku metodu na njegovom mestu. Naš metod uključuje prevod oba polovine parovog korpusa pre rudarstva, a onda glasanje većine o parovima rečenica koje su rudane na tri naèina: nakon prevoda dokumenta na jezik x na jezik y, nakon prevoda jezika y na x, i koristeći originalne dokumente na jezicima x i y. Pokazujemo uspeh s ovim romanskim pristupom na kritiku pretraživanja sličnosti Tatoebe na 64 jezika niskog resursa, i na NMT u Kazahu i Gujarati. Takođe otkrivamo efekat faktora povezanih sa resursima (npr. koliko je monojezičkih/dvojezičkih podataka dostupno za određeni jezik) na optimalni izbor metode rudarstva ugriza, pokazujući da trenutno nema jedno veličine-odgovarajućeg pristupa ovom zadatku. Postavljamo šifru i podatke koje se koriste u našim eksperimentima javno dostupno.', 'sv': 'Att få högkvalitativa parallella korpor är av yttersta vikt för träning av NMT-system. Men eftersom många språkpar saknar tillräckliga utbildningsdata av guldstandard har ett populärt tillvägagångssätt varit att utvinna så kallade pseudoparallella meningar från parade dokument på två språk. I denna uppsats beskriver vi några nackdelar med nuvarande metoder som bygger på en inbäddad likhetströskel, och föreslår en heuristisk metod i dess ställe. Vår metod innebär att översätta båda halvorna av en parad korpus innan mining, och sedan utföra en majoritet omröstning på meningpar som bryts på tre sätt: efter att ha översatt dokument på språk x till språk y, efter att ha översatt språk y till x, Vi visar framgång med detta nya tillvägagångssätt på Tatoeba-jämförelseriktmärket på 64 lågresursspråk och på NMT på kazakiska och gujarati. Vi avslöjar också effekten av resursrelaterade faktorer (dvs hur mycket enspråkig/tvåspråkig data som finns tillgänglig för ett visst språk) på det optimala valet av bitext mining metod, vilket visar att det för närvarande inte finns någon one-size-fits-all metod för denna uppgift. Vi gör koden och data som används i våra experiment tillgängliga för allmänheten.', 'si': "නිම්ටි පද්ධතියේ ප්\u200dරශ්නයක් වෙනුවෙන් අතුරුද්ධ විශේෂ සාමාන්\u200dය කාර්පෝරාව අල්ලගන්න ප්\u200d නමුත්, භාෂාවක් ජෝඩු වලින් සම්පූර්ණයෙන් සුන්දානම් ප්\u200dරධාන දත්ත අවශ්\u200dයයි, මගේ වලින් 'pseudo-Parallel' කියලා භාෂාවක මේ පත්තරේ අපි ප්\u200dරතිචාර ප්\u200dරතිචාරයක් තියෙන්නේ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් තියෙන්නේ, සම්බන්ධ වෙනුවෙන් සමාන විද අපේ විධානය සම්බන්ධ වෙන්නේ වාර්තාව දෙන්නම් කොර්පුස් එක්ක කොර්පුස් එක්ක කොර්පුස් එක්ක කොර්පුස් එක්ක කොර්පුස් එක්ක කොර්පුස් කලින් පස අපි භාෂාව x සහ y වලින් ප්\u200dරතිලිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළ අපි ඒවගේම සම්බන්ධය සම්බන්ධ විශේෂයේ ප්\u200dරතිකාරය (ඉතින් කොච්චර භාෂාවක්/දෙවල් භාෂාවක් තොරතුරු ප්\u200dරතිකාරය සඳහා ප්\u200dරතිකාර කරන්න පුළුවන් විද අපි කෝඩ් සහ දත්ත ප්\u200dරයෝජනය කරනවා අපේ පරීක්ෂණාවට ප්\u200dරවේශනය කරන්න පුළුවන්.", 'so': "Helitaanka shirkadda lambarka ah waa muhiim muhiim u ah waxbarashada nidaamka NMT. However, as many language pairs lack adequate gold-standard training data, a popular approach has been to mine so-called 'pseudo-parallel' sentences from paired documents in two languages.  Qoraalkan waxaynu ku qornaa dabool-dhab ah oo ku saabsan qaababka soo socda oo isku mid ah, waxaana horumarinaynaa in meeshiisa lagu sameeyo qaab aad u dhaqdhaqaaqi karto. Qorshahayaga waxaa ku saabsan turjumidda labada meelood oo labada nooc oo labo ah ka hor inta aan dhameynin, kadibna cod ka dhigta qof badan oo ku qoran labada labood oo saddex qaab ah: kadib turjumidda dukumentiyada luuqada x-ka kadib afka y-x-ka kadib, turjumidda afka y-x-ka kadib, iyo isticmaalka dukumentiyada asalka ah oo ku qoran luuqadaha x iyo y. Waxaynu muujinaynaa liibaanka qoraalka ee Tatoeba oo u siman qoraalka raadinta oo ku qoran 64 luqadaha hoose-resource, iyo NMT oo ku qoran Kazakh iyo Gujarati. Sidoo kale waxaynu muujinnaa saamaynta ku saabsan asalka (tusaale ahaan inta luuqada la siiyo oo la heli karo moolooyinka labada luqadood) oo ku saabsan hababka ugu wanaagsan e e qorashada bitaalka, waxaynu caddaynaynaa inuusan shaqadan u jirin mid-mid-isku mid ah. Waxaan kaarka iyo macluumaadyada lagu isticmaalayo imtixaankayada si bayaan ah u heli karnaa.", 'ta': "உயர்தரமான இணைப்பு நிறுவனத்தை பெறுவது NMT அமைப்புகளுக்கு அளபுரிய முக்கியம். எனினும், எத்தனை மொழி ஜோடிகளுக்கு போதுமான தங்க- நிலையான பயிற்சி தகவல் இல்லை, என்னுடைய பிரபலமான செயல்பாடு இரு மொழிகளில் இருந்து 'பியூடோ-  இந்த காகிதத்தில், நாம் தற்போதைய முறைமைகளுடன் சில வரைபடங்களை வெளியிடுகிறோம், அதே போன்ற முறையில் நம்பிக்கை கொண்டு, அதன் இடத்தில்  எங்கள் முறைமையில் இரண்டு பாதி ஜோடி குறியீட்டை மொழிபெயர்ப்பு செய்யும் முன்பு, பிறகு மூன்று வழிகளில் சிறிய வாக்கியின் மீது பெரும்பாலான வாக்கி மூல ஆவணங்கள் x மற்றும் y மொழிகளில் பயன்படுத்துகின்றன. நாம் இந்த புத்தகத்தில் வெற்றியைக் காட்டுகிறோம் இதே போல தேடுதல் பென்க்மேக் 64 குறைந்த மூலத்தி மூலத்துடன் தொடர்புடைய காரணிகளின் விளைவை நாம் கண்டுபிடிக்கிறோம் (அதாவது, கொடுக்கப்பட்ட மொழிக்கு எவ்வளவு மொழிக்கு/இரு மொழிகள் தரவு கிடைக்கும்) பிட்டாக்ஸ் குழந்தை  நாம் எங்கள் சோதனைகளில் பயன்படுத்தப்பட்ட குறியீடு மற்றும் தகவல்களை பொதுவாக கிடைக்கும்.", 'ur': "NMT سیستموں کی آموزش کے لئے اچھی کیفیت پارالی کورپورا کا ذریعہ ہے۔ However, as many languages pairs lack adequate gold-standard training data, a popular approach has been called 'pseudo-parallel' sentences from paired documents in two languages. اس کاغذ میں، ہم نے ایک مقدار طریقے کے ساتھ روشن کر دیے ہیں جو اس کے جگہ پر بھروسہ رکھتے ہیں، اور ایک ہوریستی طریقہ کی پیشنهاد کرتے ہیں. ہماری طریقہ میں ایک جوڑا کورپوس کی دو حصہ کی ترجمہ کرنا ہے قبل اس کے، اور اس کے بعد بہت سی جماعت کی وٹ کرنا ہے جو تین طریقے سے مٹی ہوئی جماعت جوڑوں پر ہے: زبان میں x کی زبان y کی ترجمہ کے بعد، زبان y کی x کی ترجمہ کے بعد، اور اصلی دفتروں کو x اور y کی زبانوں میں استعمال کرتے ہیں. ہم اس کاغذ کے مطابق اس کاغذ کے مطابق اس طرح کامیابی کے ذریعہ تدبیر کرتے ہیں کہ Tatoeba کی سیدھی سیدھی سیدھی بنچم مارک کے مطابق 64 کم منبع زبانوں میں اور کازاق اور گوجراتی میں N ہم نے بھی منصفات کے ساتھ رابطہ دار فاکتوروں کا اثر (یعنی ایک زبان/دوبل زبان کے لئے کیسے ایک زبان کے لئے موجود ہے) بیٹکسٹ منڈنگ طریقے کے اچھی انتخاب کے ذریعہ سے ظاہر کر دیا ہے کہ اب اس کام کے لئے کوئی اندازہ-Fits-all طریقہ نہیں ہے۔ ہم نے ہمارے آزمائش میں کڈ اور ڈیٹا کو ظاہر طور پر موجود بنایا ہے.", 'uz': "Name Ammo, ko'pchilik tillar qoʻllari juda yetarli gull-standard taʼminlov maʼlumoti yo'q, bir mashhur usuli ikki tildagi qoʻllangan hujjatlardan 'pseudo-parallel' so'zlariga ega bo'ladi. Bu qogʻozda biz joriy usullar bilan bir necha chiroqlar bilan bir necha chiqaramiz va bir joyda bir heuristik usulni tasavvur qilamiz. Bizning usuli qo'shishdan oldin ikkita bir necha kopusni tarjima qilishimiz mumkin, va keyin uchta usuldan ko'pchilik qo'l bilan qo'llangan so'zlarni uchta usulda ishga tushirish uchun qo'shimcha kurat qiladi: tillarni x tilidan to'g'ri tilga o'rganishdan keyin, tillar y y y to'g va asl hujjatlarni X va y tilida ishlatish mumkin. Biz bu novel usulida Tatoeba bir xil qidirish imkoniyatini 64 qidirish imkoniyati tilida va Kazakh va Gujaratida NMT tilida muvaffaqiyatli ko'rsatdik. Biz bu vazifa uchun hech qanchalik katta qismni tanlash usulini ko'rsatumiz. Biz jarayonlarimizda ishlatilgan koda va maʼlumotlarni ochiq imtiyozlar bilan bog'liq qilamiz.", 'vi': 'Lấy được cấu trúc song đẳng cấp cao là quan trọng nhất trong việc huấn luyện các hệ thống NMT. Tuy nhiên, vì nhiều cặp ngôn ngữ thiếu dữ liệu đào tạo bằng vàng, một phương pháp phổ biến đã được dùng để khai thác những câu gọi là "giả song song song" từ các tài liệu ghép bằng hai ngôn ngữ. Trong tờ giấy này, chúng tôi mô tả một số trở ngại với các phương pháp hiện thời dựa trên một ngưỡng tương đồng nhúng tay, và đề xuất một phương pháp thần kinh ở vị trí của nó. Phương pháp của chúng ta là dịch hai nửa của một tập thể ghép trước khai mỏ, và sau đó thực hiện một phiếu bầu đa số cho các loại hình tử được khai quật bằng ba cách: sau khi dịch các tài liệu bằng ngôn ngữ x thành ngôn ngữ y, sau khi dịch ngôn ngữ y thành x, và sử dụng các tài liệu gốc bằng ngôn ngữ x và y. Chúng tôi chứng minh thành công với cách tiếp cận mới này về tiêu chuẩn tìm kiếm của Tatoeba bằng cách tìm kiếm tại bốn phương tiện ít, và về NMT ở Kazak và Gujarat. Chúng tôi cũng tìm ra tác động của các yếu tố liên quan đến tài nguyên (tức là bao nhiêu dữ liệu ngôn ngữ và hai ngôn ngữ sẵn sàng cho một ngôn ngữ cụ thể) vào phương pháp khai thác xương bằng thịt, cho thấy hiện tại không có phương pháp nào cho việc này. Chúng tôi công khai mã và dữ liệu sử dụng trong các thí nghiệm.', 'bg': 'Получаването на висококачествени паралелни корпуси е от първостепенно значение за обучението на НМТ системи. Въпреки това, тъй като много езикови двойки нямат адекватни данни за обучение със златен стандарт, популярен подход е да се извличат т.нар. "псевдопаралелни" изречения от сдвоени документи на два езика. В настоящата статия очертаваме някои недостатъци при съвременните методи, които разчитат на вграден праг на сходство, и предлагаме на негово място евристичен метод. Нашият метод включва превод и на двете половина на сдвоен корпус преди добиването, и след това провеждане на мнозинство гласуване за двойки изречения, добити по три начина: след превод на документи на език х на език у, след превод на език у на х, С помощта на оригиналните документи на езици демонстрираме успех с този нов подход за търсене на сходство в Татоеба на 64 езика с нисък ресурс, както и на НМТ в Казахстан и Гуджарати. Разкриваме и ефекта на свързаните с ресурсите фактори (т.е. колко моноезични/двуезични данни са налични за даден език) върху оптималния избор на метод за добив на битекст, демонстрирайки, че понастоящем няма уникален подход за тази задача. Ние правим кода и данните, използвани в нашите експерименти, публично достъпни.', 'hr': 'Uzdržavanje visokokvalitetnog paralelnog korporacije je od najvažnije važnosti za obuku NMT sustava. Međutim, pošto mnogi jezički parovi nedostaju odgovarajući podaci o obuci zlata-standard a, popularan je pristup mojim takozvanim "pseudoparalelnim" rečenicama iz parnih dokumenta na dva jezika. U ovom papiru, pokazujemo neke neuspjehe sa trenutnim metodama koje se oslanjaju na ugrađeni prag sličnosti i predlažemo heurističku metodu na njegovom mjestu. Naš metod uključuje prevod oba polovice parnog korpusa prije rudarstva, a onda glasanje većine o paru kazne koje su rudene na tri načina: nakon prevoda dokumenta na jezik x na jezik y, nakon prevoda jezika y na x, i koristeći originalne dokumente na jezicima x i y. Mi pokazujemo uspjeh s ovim novom pristupom o kritičnoj mjeri pretraživanja sličnosti Tatoeba na 64 jezika niskih resursa, a na NMT u Kazahskom i Gujaratiju. Također otkrivamo učinak faktora povezanih s resursima (tj. koliko je monojezičkih/dvojezičkih podataka dostupno za određeni jezik) na optimalni izbor metode rudarstva ugriza ugriza, pokazujući da trenutno ne postoji jedan odgovarajući pristup ovom zadatku. Postavljamo šifru i podatke koje se koriste u našim eksperimentima javno dostupno.', 'da': 'At opnå parallelle korpora af høj kvalitet er af afgørende betydning for træning af NMT systemer. Men da mange sprogpar mangler tilstrækkelige oplæringsdata af guldstandard, har en populær tilgang været at udvinde såkaldte pseudo-parallelle sætninger fra parrede dokumenter på to sprog. I denne artikel skitserer vi nogle ulemper med nuværende metoder, der er afhængige af en indlejring lighedstærskel, og foreslår en heuristisk metode i stedet. Vores metode indebærer at oversætte begge halvdele af et parret korpus før mining, og derefter udføre en flertalsafstemning på sætningspar mineret på tre måder: efter oversættelse af dokumenter på sprog x til sprog y, efter oversættelse af sprog y til x, og brug af de originale dokumenter på sprogene x og y. Vi demonstrerer succes med denne nye tilgang på Tatoeba lighedssøgning benchmark på 64 lav ressource sprog, og på NMT på kasakhsisk og gujarati. Vi afdækker også effekten af ressourcerelaterede faktorer (dvs. hvor mange ensprogede/tosprogede data der er tilgængelige for et givet sprog) på det optimale valg af bitext mining metode, hvilket viser, at der i øjeblikket ikke er nogen one-size-fits-all tilgang til denne opgave. Vi gør koden og data, der anvendes i vores eksperimenter, offentligt tilgængelige.', 'nl': "Het verkrijgen van hoogwaardige parallelle corpora's is van het grootste belang voor het trainen van NMT-systemen. Aangezien veel taalparen echter onvoldoende trainingsgegevens van gouden standaarden hebben, is een populaire benadering geweest om zogenaamde 'pseudo-parallelle' zinnen uit gekoppelde documenten in twee talen te halen. In dit artikel schetsen we enkele nadelen van huidige methoden die afhankelijk zijn van een inbedding gelijkenisdrempel, en stellen we een heuristische methode voor in de plaats daarvan. Onze methode bestaat uit het vertalen van beide helften van een gepaard corpus vóór het mijnen, en vervolgens het uitvoeren van een meerderheidsstemming over zinnenparen die op drie manieren zijn gemin: na het vertalen van documenten in taal x naar taal y, na het vertalen van taal y naar x, We demonstreren succes met deze nieuwe aanpak op de Tatoeba vergelijkingsbenchmark in 64-low-resource talen, en op NMT in Kazachst en Gujarati. We ontdekken ook het effect van resource-gerelateerde factoren (d.w.z. hoeveel monolingual/tweetalige data beschikbaar is voor een bepaalde taal) op de optimale keuze van bitext mining methode, waaruit blijkt dat er momenteel geen one-size-fits-all aanpak is voor deze taak. We maken de code en data die in onze experimenten worden gebruikt openbaar beschikbaar.", 'ko': "높은 품질의 병렬 언어 자료 라이브러리를 얻는 것은 NMT 시스템을 훈련하는 데 매우 중요하다.그러나 많은 언어들이 충분한 황금 표준 훈련 데이터가 부족하기 때문에 두 언어의 짝짓기 문서에서 이른바'위평행'문장을 발굴하는 것이 유행이다.본고에서 우리는 현재 싱크로율 한도값에 의존하는 방법의 일부 단점을 개괄하고 계발식 방법을 제시했다.우리의 방법은 발굴하기 전에 어료 라이브러리의 두 부분으로 번역한 다음에 세 가지 방식으로 발굴한 문장에 대해 다수결을 하는 것이다. x언어의 문서를 y언어로 번역한 후 y언어를 x언어로 번역한 후,언어 x와 y의 원본 문서를 사용합니다. 64가지 저자원 언어의 타토바 유사성 검색 기준과 카자흐어와 구자라트어의 NMT에서 이러한 새로운 방법의 성공을 증명했습니다.우리는 또한 자원과 관련된 요소(즉 주어진 언어에 얼마나 많은 단어/이중 언어 데이터가 사용할 수 있는지)가 가장 좋은 이중 텍스트 발굴 방법을 선택하는 데 미치는 영향을 제시하여 현재 이 임무에 적합한 통용적인 방법이 없다는 것을 나타냈다.우리는 실험에 사용된 코드와 데이터를 공개했다.", 'de': 'Der Erhalt hochwertiger paralleler Korpora ist für das Training von NMT-Systemen von größter Bedeutung. Da viele Sprachpaare jedoch keine ausreichenden Goldstandard-Trainingsdaten haben, ist ein beliebter Ansatz, sogenannte "pseudo-parallele" Sätze aus gepaarten Dokumenten in zwei Sprachen zu extrahieren. In diesem Beitrag skizzieren wir einige Nachteile aktueller Methoden, die auf einer eingebetteten Ähnlichkeitsschwelle beruhen, und schlagen stattdessen eine heuristische Methode vor. Unsere Methode besteht darin, beide Hälften eines gepaarten Korpus vor dem Mining zu übersetzen und dann eine Mehrheitsabstimmung über Satzpaare durchzuführen, die auf drei Arten gewonnen wurden: nach der Übersetzung von Dokumenten in Sprache x in Sprache y, nach der Übersetzung von Sprache y in x, Wir zeigen Erfolge mit diesem neuartigen Ansatz auf dem Tatoeba Ähnlichkeitssuch Benchmark in 64-ressourcenarmen Sprachen und auf NMT in Kasachisch und Gujarati. Wir decken auch den Einfluss ressourcenbezogener Faktoren auf die optimale Auswahl der Bitext-Mining-Methode auf und zeigen, dass es derzeit keinen einheitlichen Ansatz für diese Aufgabe gibt. Wir machen den Code und die Daten, die in unseren Experimenten verwendet werden, öffentlich zugänglich.', 'fa': 'تحمل کردن شرکت پارالی با کیفیت بالا مهم برای آموزش سیستم\u200cهای NMT است. با این حال، به اندازه\u200cی زیادی جفت زبان داده\u200cهای آموزش طلا استاندارد کافی لازم دارند، یک دستور محبوب به جمله\u200cهای من به عنوان جمله\u200cهای pseudo-parallel از سند جفت در دو زبان است. در این کاغذ، ما برخی از نقاشی را با روش\u200cهای جاری روشن می\u200cکنیم که بر یک نقاشی شبیه\u200cانگیز استفاده می\u200cکنند، و یک روش حوریست را در جای آن پیشنهاد می\u200cکنیم. روش ما شامل ترجمه کردن هر دو قسمت از یک کورپوس جفت قبل از ذخیره کردن است، و بعد از ترجمه کردن یک رأی بیشتری بر جفت مجازات معدنی به سه راه: بعد از ترجمه کردن مدارک به زبان x به زبان y، بعد از ترجمه کردن زبان y به x، و از مدارک اصلی به زبان x و y استفاده می کنیم. ما موفقیت را با این دستور رمانی روی برنامه جستجوی شبیه تاتویی در 64 زبان منابع کم و NMT در کازاک و گوجراتی نشان می دهیم. ما همچنین تاثیر faktورهای مربوط به منابع (به عنوان چقدر داده های یک زبان/دو زبان برای یک زبان داده شده) را در انتخاب بهترین راه خرید کردن متن غذا کشیدیم، نشان می دهیم که در حال حاضر هیچ طریق یک اندازه\u200cای برای این کار نیست. ما کد و اطلاعات را در آزمایشات عمومی در دسترس می دهیم.', 'sw': "Kupata kampuni ya kiwango kikubwa ni muhimu sana kwa mafunzo ya mfumo wa NMT. Hata hivyo, kwa kuwa wanandoa wengi wa lugha hawana taarifa za mafunzo ya kutosha ya dhahabu yenye kiwango cha kawaida, mbinu maarufu imekuwa ni kwangu nilivyoitwa 'pseudo-parallel' katika nyaraka mbili za lugha mbili. Katika karatasi hii, tunaelezea baadhi ya mbinu za sasa zinazotegemea kwenye eneo hilo linalofanana na hilo, na tunapendekeza njia ya heuristi katika nafasi yake. Our method involves translating both halves of a paired corpus before mining, and then performing a majority vote on sentence pairs mined in three ways: after translating documents in language x to language y, after translating language y to x, na kutumia nyaraka za asili kwa lugha x na y. Tunaonyesha mafanikio kwa njia hii ya riwaya kuhusu bendera za kutafuta Tatoeba zinazofanana na lugha 64 chini ya rasilimali, na NMT huko Kazakh na Gujarati. Pia tunagundua madhara ya sababu zinazohusiana na rasilimali (yaani ni kiasi gani takwimu za lugha na lugha mbili zinapatikana kwa lugha zilizopewa) katika uchaguzi bora wa madini ya madini, tunaonyesha kuwa kwa sasa hakuna njia yoyote inayofanikiwa kwa ajili ya kazi hii. We make the code and data used in our experiments publicly available.", 'af': "Onderhouding van hoë-kwaliteit parallele korpora is van paramount belangrikheid vir onderwerp van NMT stelsels. Maar, soos baie taal paars nie voldoende goud-standaard onderwerking data ontbreek nie, is 'n populêre toegang tot myne so genoem 'pseudo-paraleel' teikens van paarde dokumente in twee tale. In hierdie papier, ons uittrek sommige tekeninge met huidige metodes wat op 'n inbêde gelykenis drukking vertrou, en voorstel 'n heuristiese metode op sy plek. Ons metode verplig die vertaling van beide halwe van 'n paar korpus voor mining, en dan uitvoer 'n meeste stem op seënpaar wat op drie maniere minne is: na vertaling van dokumente in taal x na taal y, na vertaling van taal y na x, En gebruik die oorspronklike dokumente in tale x en y. Ons wys suksesvol met hierdie novel toegang op die Tatoeba soektog benchmark in 64 lae hulpbron tale en op NMT in Kazakh en Gujarati. Ons ontdek ook die effek van hulpbron-verwante faktore (i.e. hoeveel monolinge/bilinguele data is beskikbaar vir 'n gegewe taal) op die optimale kies van bitteks-minemetode, wat wys dat daar huidiglik geen een-grootte-pas-al toegang vir hierdie taak is nie. Ons maak die kode en data gebruik in ons eksperimente openlik beskikbaar.", 'sq': "Obtimi i korprave paralele të cilësisë së lartë është i rëndësishëm për trajnimin e sistemeve NMT. Megjithatë, pasi shumë çifte gjuhësh nuk kanë të dhëna të përshtatshme të trainimit të standartit të artë, një qasje popullore ka qenë për të miat të ashtuquajtura fjalë 'pseudo-paralele' nga dokumentet e çiftuar në dy gjuhë. Në këtë letër, ne përshkruajmë disa dëmtime me metodat aktuale që mbështeten në një prag të ngjashmërisë të përfshirë, dhe propozojmë një metodë heuristike në vend të saj. Metoda jonë përfshin përkthimin e të dyve gjysmave të një korpusi të çiftuar përpara minierës, dhe pastaj kryerjen e një votimi të shumicës mbi çiftet e dënimeve të minave në tre mënyra: pas përkthimit të dokumenteve në gjuhën x në gjuhën y, pas përkthimit të gjuhës y në x, Dhe duke përdorur dokumentet origjinale në gjuhët x dhe y. Ne zbulojmë gjithashtu efektin e faktorëve të lidhur me burimet (pra sa të dhëna monogjuhësore/dygjuhësore janë në dispozicion për një gjuhë të caktuar) mbi zgjedhjen optimale të metodës së minierës bitext, duke demonstruar se aktualisht nuk ekziston asnjë qasje e një-madhësie-përshtatet-të-të gjithë për këtë detyrë. Ne i bëjmë kodet dhe të dhënat e përdorura në eksperimentet tona të disponueshme publikisht.", 'tr': 'Yüksek kaliteli parallel korpora gözlemek NMT sistemalary okuwçylamak üçin has möhümdigidir. Ýöne köp dil çiftleriň ýeterli altyn standart eğitim maglumatynyň ýok bolsa, meniň diýilýän "pseudo-parallel" sözlerimi iki dilde bilim bar. Bu kagyzda, häzirki çykyşlar bilen daşary bir meňzeşlikli çykyşlar we onuň ýerinde bir heuristik yöntemi teklip edýäris. Biziň y öntemimiz miniň öňünden hem çift korpusyň ýarysyny terjime edip, soňra köp sany çykyşyň üç ýoly şeklinde mynanýan cümlelerinde ses bermeklidir: x dilinde y diline terjime edenden soňra, y diline x diline terjime edenden soňra, Öňki senden x we y dilinde esasy senedi ullanýarys. Biz Tatoeba ýakynlaşyklarynyň 64-nji kaynaklı dilde we Kazakh we Gujaratyň NMT-ynda başarnygy görkeýäris. Biz hem resurslar arasyndaky faktörleriň täsirini (meselâ, bir dil üçin näçe monodil/bilim maglumatlaryň bar) bitek taýýarlama metodasynyň i ň gowy seçgisini a çdyk, şol işiň üçin häzirki hiç hili bir ölçü-topar ýarym ýok diýip görkezilýän. Biz öz deneylerimizde köd we maglumaty halkara mejbur edip bilýäris.', 'am': 'የኮርፖርት ማግኘት የልልዩነት ተቃውሞ የNMT ስርዓቶች ማጠቃቀሚያ የሚያስፈልገው ነው፡፡ ነገር ግን ብዙዎች የቋንቋዎች ሁለት ሁለት ዓይነቶች በሁለት ቋንቋዎች ውስጥ የሚባለው ‘pseudo-parallel’ ፍርድ የደረሰብኝ የወርቅ-standard አስተማርነት ዳታ እንዳይጎድሉ፣ የሕዝብ ሥርዓት ነው፡፡ በዚህ ፕሮግራም፣ በአሁኑ ደረጃዎች ላይ የሚደገፉትን አንዳንዶችን ጥላቻ እናሳውቃለን፣ በስፍራውም የሀሪክኛ ሥርዓት እናሳልቃለን፡፡ በቋንቋ x ወደ ቋንቋ y ከመዘጋጀት በኋላ የቋንቋ ቋንቋ y ወደ x ከመትረፍ በኋላ፣ እና የመጀመሪያውን ሰነዶች በቋንቋዎች x እና y በመጠቀም እና በመጠቀም አቀናመጥን በጣቶባ በተመሳሳይ የፍላጎት ጉዳይት ላይ በ64 የዝቅተኛ ክፍል ቋንቋዎች እና በካዛክ እና ጉጋራቲ ላይ የNMT ክፍል እናሳየዋለን፡፡ ደግሞም የከተማዎች ጉዳይ የኩነቶች (ምናልባዊ ቋንቋ/ቋንቋ ቋንቋ መፍጠር እንዴት ያህል ለቋንቋ የሚቻል) የክፍል ቅድሚያ መቆጣጠር ማድረግ እናስታውቃለን፡፡ በሞከራችን ውስጥ የሚጠቀሙትን ኮድ እና ዳራዎችን በግልጽ እናደርጋለን፡፡', 'hy': 'ՆՄԹ համակարգերի ուսումնասիրության համար ամենակարևոր կարևոր է բարձր որակի զուգահեռ մարմնի ստանալը: Այնուամենայնիվ, քանի որ շատ լեզվի զույգերը բացակայում են բավարար ոսկու ստանդարտ ուսումնասիրության տվյալներ, հանրահայտ մոտեցումը երկու լեզուներով զույգ փաստաթղթերից հանդիսացած այսպես կոչված "կեղծ-զուգահեռ" նախադա Այս թղթի մեջ մենք որոշ թերություններ ենք նկարագրում ներկայիս մեթոդներով, որոնք հիմնված են նմանության սահմաններին ներառելու վրա, և առաջարկում են դրա փոխարեն հորիստիկ մեթոդ: Մեր մեթոդը ներառում է մի զույգ կորպոսի երկու կեսերը թարգմանել մինչև հանքահանումը, և հետո կատարել մեծամասնության քվեարկություն նախադասությունների զույգերի մասին, որոնք հանվել են երեք ձևերով. x-ի լեզվով փաստաթղթեր թարգմանելուց հետո y-ի լեզվո Եվ օգտագործելով սկզբնական փաստաթղթերը x և y լեզուներում, մենք ցույց ենք տալիս հաջողությունը Տատոեբայի նմանության որոնման հարաբերակցում 64 ցածր ռեսուրսների լեզուներում և NMT-ում Կազախ և Գուջարատիում: We also uncover the effect of resource-related factors (i.e. how much monolingual/bilingual data is available for a given language) on the optimal choice of bitext mining method, demonstrating that there is currently no one-size-fits-all approach for this task.  Մենք հանրային հասանելի ենք դարձնում մեր փորձարկումներում օգտագործվող կոդը և տվյալները:', 'bn': 'এনএমটি সিস্টেম প্রশিক্ষণের জন্য উচ্চমান প্যারালেল কর্পোরা প্রযুক্তির গুরুত্বপূর্ণ। তবে যেহেতু অনেক ভাষার জোড়ায় যথেষ্ট সোনার-স্ট্যান্ডার্ড প্রশিক্ষণের তথ্য পাওয়া যাচ্ছে তাই আমার জনপ্রিয় পদ্ধতি দুই ভাষায় যুক্ত নথি এই কাগজটিতে আমরা বর্তমান পদ্ধতির সাথে কিছু আবর্জনা দিয়ে লেখা দিয়েছি যারা একই ধরনের সাথে নির্ভর করে এবং তাদের স্থানে একটি হারিস্টিক আমাদের পদ্ধতিতে একটি জোড়া কোর্পাসের অর্ধেক ভাষায় অনুবাদ করার ব্যাপারে লিখেছে, তারপর সংখ্যাগরিষ্ঠ ভোট প্রদর্শন করেছে যারা তিনটি ভাষায় মিনিট করেছে: ভাষায় ন  and using the original documents in languages x and y. We demonstrate success with this novel approach on the Tatoeba similarity search benchmark in 64 low-resource languages, and on NMT in Kazakh and Gujarati.  আমরা সম্পদের সাথে সম্পর্কিত কারখানার প্রভাব আবিষ্কার করি (যেমন একটি ভাষার জন্য কতটা মোনোলিভাল/দুই ভাষার তথ্য পাওয়া যাচ্ছে) বিটেক্স মিনিং পদ্ধতির অপ্রাপ্ত পছন্দের বিষয় আমরা আমাদের পরীক্ষার মধ্যে ব্যবহৃত কোড এবং তথ্য প্রকাশ্যে ব্যবহার করি।', 'bs': 'Uzdržavanje visokokvalitetnog paralelnog korporacija je od najvažnije važnosti za obuku NMT-ovih sustava. Međutim, pošto mnogi jezički parovi nedostaju odgovarajući podaci o obuci zlata-standard a, popularan je pristup mojim takozvanim "pseudoparalelnim" rečenicama iz parnih dokumenta na dva jezika. U ovom papiru, pokazujemo neke neuspjehe sa trenutnim metodama koji se oslanjaju na ugrađeni prag sličnosti i predlažemo heurističku metodu na njegovom mjestu. Naš metod uključuje prevod oba polovine parovog korpusa prije rudarstva, a onda vodi većinu glasova o parovima kazne koje su rudane na tri načina: nakon prevoda dokumenta na jezik x na jezik y, nakon prevoda jezika y na x, i koristeći originalne dokumente na jezicima x i y. Pokazujemo uspjeh s ovim romanskim pristupom na kritiku pretraživanja sličnosti Tatoeba na 64 jezika niskih resursa, i na NMT u Kazahu i Gujarati. Takođe otkrivamo učinak faktora povezanih s resursima (npr. koliko je monojezičkih/dvojezičkih podataka dostupno za određeni jezik) na optimalni izbor metode rudarstva ugriza ugriza, pokazujući da trenutno ne postoji jedan-veličini odgovarajući pristup ovom zadatku. Postavljamo šifru i podatke koje se koriste u našim eksperimentima javno dostupno.', 'az': 'Yüksek kaliteli paralel korpora sahib olmaq NMT sistemlərinin təhsil etməsi üçün ən vacibdir. Lakin çox dil çiftləri altın-standart təhsil məlumatlarının istifadəsi olmadığı kimi, mənim "pseudo-parallel" sözlərimi iki dil içində cüt belə deyilən "pseudo-parallel" sözlərinə istifadə edir. Bu kağızda, bir neçə çəkilmə metodları ilə müəyyən edirik ki, bunun yerində bir heuristik yolu təklif edir. Bizim metodumuz minik məlumatından əvvəl hər ikisinin yarısını, sonra üç yolla minik cümlələrdən çox səs vermək istəyir: x dilini y dilinə çevirindən sonra, y dilini x dilinə çevirindən sonra, Və x və y dillərində orijinal belələri istifadə edirik. Biz Tatoeba-nın 64 düşük kaynaq dillərində və Kazahlı və Gujarati dillərində NMT-nin başarısızlığını göstəririk. Biz də resource-related faktörlərin (həmçinin bu i şin üçün bir dil üçün nə qədər monodil/ikili verilən məlumatların faydalandığını) gözəl seçim metodlarına görə bildiririk, bu işlər üçün əslində heç bir böyüklük-fits-all approach yoxdur. Biz eksperimentlərimizdə kodu və məlumatları açıq-aşkar faydalandırırıq.', 'cs': 'Získání vysoce kvalitních paralelních korpusů je zásadní pro trénink NMT systémů. Vzhledem k tomu, že mnoho jazykových párů chybí dostatečné údaje o tréninku zlatého standardu, bylo populárním přístupem těžit tzv. "pseudo-paralelní" věty ze spárovaných dokumentů ve dvou jazycích. V tomto článku nastíníme některé nevýhody současných metod, které spoléhají na vložení práhu podobnosti, a navrhujeme na její místo heuristickou metodu. Naše metoda zahrnuje překlad obou polovin párového korpusu před těžbou a následné hlasování většinového hlasování o větových párech vytěžených třemi způsoby: po překladu dokumentů v jazyce x do jazyka y, po překladu jazyka y do x, S tímto novým přístupem demonstrujeme úspěch na benchmarku vyhledávání podobností Tatoeba v 64 jazycích s nízkými zdroji a NMT v Kazašštině a Gujarati. Dále odhalujeme vliv faktorů souvisejících se zdroji (tj. kolik jednojjazyčných/dvojjazyčných dat je pro daný jazyk k dispozici) na optimální volbu metody těžby bitextu, což ukazuje, že v současné době neexistuje žádný univerzální přístup pro tento úkol. Kód a data použitá v našich experimentech zpřístupníme veřejně.', 'ca': "Obtenir un corpore paral·lel d'alta qualitat és de gran importància per a formar els sistemes NMT. Tot i així, com molts parells de llengües no tenen dades adequades d'entrenament d'or, un enfocament popular ha estat la meva anomenada frase pseudoparal·lela a partir de documents parellats en dues llengües. En aquest paper, esboquem alguns inconvenients amb mètodes actuals que es basan en un umbre de similitud incorporada, i proposem un mètode heurístic en seu lloc. El nostre mètode consisteix en traduir les dues meitats d'un corpus parellat abans de la mineria, i després fer una votació majoritària sobre parells de frases minerats de tres maneres: després de traduir els documents a la llengua x a la llengua y, després de traduir la llengua y a x,  and using the original documents in languages x and y. We demonstrate success with this novel approach on the Tatoeba similarity search benchmark in 64 low-resource languages, and on NMT in Kazakh and Gujarati.  També descobrim l'efecte dels factors relacionats amb els recursos (és a dir, quantes dades monolingües/bilingües hi ha disponibles per una llengua determinada) en l'opció óptima del mètode de mineria bitext, demostrant que actualment no hi ha un enfocament d'una sola mida per a tots aquests treballs. Fem públic el codi i les dades utilitzades en els nostres experiments.", 'et': 'Kvaliteetsete paralleelkorporatsioonide omandamine on NMT süsteemide koolitamisel äärmiselt oluline. Kuna paljudel keelepaaridel puuduvad piisavad kuldstandardite koolitusandmed, on populaarseks lähenemiseks olnud nn pseudoparalleelsete lausete kaevandamine paaritud dokumentidest kahes keeles. Käesolevas töös kirjeldame mõningaid puudusi praeguste meetodite puhul, mis põhinevad sarnasuse künnisel, ja pakume selle asemel välja heuristilise meetodi. Meie meetod hõlmab paaritud korpuse mõlema poole tõlkimist enne kaevandamist ja seejärel häälteenamuse läbiviimist lausepaaride kohta, mis kaevandatakse kolmel viisil: pärast dokumentide tõlkimist keeles x keelde y, pärast tõlkimist keelde y x, Kasutades originaaldokumente keeltes x ja y. Selle uudse lähenemisviisiga näitame edu Tatoeba sarnasuse otsingu võrdlusalusel 64 vähese ressursiga keeles ning NMT kasahhi ja gujarati keeles. Samuti avastame ressursiga seotud tegurite (st kui palju ühekeelseid/kakskeelseid andmeid konkreetse keele kohta on) mõju biteksti kaevandamise meetodi optimaalsele valikule, näidates, et praegu puudub kõigile sobiv lähenemisviis. Me teeme oma katsetes kasutatud koodi ja andmed avalikult kättesaadavaks.', 'fi': 'Laadukkaiden rinnakkaisten korpusten hankkiminen on ensiarvoisen tärkeää NMT-järjestelmien kouluttamisessa. Koska monilla kielipareilla ei kuitenkaan ole riittävää kultaista koulutustietoa, suosittu lähestymistapa on ollut kaivaa ns. "pseudo-rinnakkaisia" lauseita paridokumenteista kahdella kielellä. Tässä työssä hahmottelemme joitakin haittoja nykyisissä menetelmissä, jotka perustuvat upotuskynnykseen, ja ehdotamme sen sijaan heuristista menetelmää. Menetelmämme käsittää paritetun korpusen molempien puolien kääntämisen ennen kaivostoimintaa ja sen jälkeen enemmistöäänestyksen suorittamisen lausepareista, jotka on loukattu kolmella tavalla: asiakirjojen kääntämisen jälkeen kielellä x kielelle y, kääntämisen jälkeen kielellä y x, Tämä uusi lähestymistapa osoittaa menestystä Tatoeban samankaltaisuushakuvertailussa 64 vähäresurssisella kielellä sekä NMT:ssä Kazakstanissa ja Gujaratissa. Selvitämme myös resursseihin liittyvien tekijöiden (eli kuinka paljon yhdelle kielelle on saatavilla monikielistä/kaksikielistä dataa) vaikutusta bitekstin louhintamenetelmän optimaaliseen valintaan, mikä osoittaa, että tällä hetkellä ei ole olemassa yhtenäistä lähestymistapaa tähän tehtävään. Teemme kokeissamme käytetyn koodin ja datan julkisesti saataville.', 'id': "Obtaining high-quality parallel corpora is of paramount importance for training NMT systems.  However, as many language pairs lack adequate gold-standard training data, a popular approach has been to mine so-called 'pseudo-parallel' sentences from paired documents in two languages.  In this paper, we outline some drawbacks with current methods that rely on an embedding similarity threshold, and propose a heuristic method in its place.  Metode kami melibatkan menerjemahkan kedua-dua setengah corpus pasangan sebelum pengembaraan tambang, dan kemudian melakukan suara mayoritas pasangan kalimat yang dikembara dalam tiga cara: setelah menerjemahkan dokumen dalam bahasa x ke bahasa y, setelah menerjemahkan bahasa y ke x,  and using the original documents in languages x and y. We demonstrate success with this novel approach on the Tatoeba similarity search benchmark in 64 low-resource languages, and on NMT in Kazakh and Gujarati.  We also uncover the effect of resource-related factors (i.e. how much monolingual/bilingual data is available for a given language) on the optimal choice of bitext mining method, demonstrating that there is currently no one-size-fits-all approach for this task.  We make the code and data used in our experiments publicly available.", 'he': 'להשיג גופורה מקבילה של איכות גבוהה הוא חשוב ביותר לאימון מערכות NMT. עם זאת, כיוון שזוגות רבות חסרות מידע אימון זהב סטנדרטי, גישה פופולרית הייתה למשפטים שלי שנקראים "פסודו-מקבילים" ממסמכים זוגות בשתי שפות. בעיתון הזה, אנחנו מציירים כמה חסרות עם שיטות הנוכחיות שמסומכות על גבול דמיון מעורבב, ומצייעים שיטה היוריסטית במקומו. השיטה שלנו כוללת לתרגם את שני חצי של קופוס זוג לפני הכרות, ואז לבצע הצבעה מרוב על זוג משפטים מוכרים בשלושה דרכים: לאחר שתרגם מסמכים בשפה x לשפה y, לאחר שתרגם שפה y ל-x, בשימוש במסמכים המקוריים בשפות x ו-y. אנו מראים הצלחה עם הגישה הרומנית הזו על נקודת חיפוש דומה Tatoeba ב-64 שפות משאבים נמוכות, ובNMT בקזאק וגוג\'ארטי. אנחנו גם מגלים את ההשפעה של גורמים קשורים למשאבים (כלומר כמה נתונים מונושפתיים/שתיים שפתיים זמינים לשפה מסוימת) על הבחירה האופטימלית של שיטת הכירה של bitext, בהוכחה שאין כרגע גישה אחת-גודל-מתאימה לכל המשימה הזאת. אנחנו פועלים את הקוד והנתונים שנשתמשים בניסויים שלנו פנויים לציבור.', 'ha': "QUnicodeControlCharacterMenu Haƙĩƙa, da yawa da par biyu na harshe ba su da data mai daidai wa tsarin zĩnãriya-na'ura, wani aikin umakinci ya kasance zuwa garwaya na da sunan 'p'udo-parallel' daga takardar biyu cikin harshen biyu. Ga wannan takardan, Munã ƙara wasu durowa da hanyõyin da ke yanzu waɗand a ke dõgara a cikin wani shirin da ke daidaita, kuma Muke buƙata wata hanyor heuristic a gabansa. Tsarinmu yana amfani da fassarar rabin biyu ko kuma rubutu biyu a gabãnin ƙarami, kuma yana sami sauri mafi yawa a kan sauri biyu wanda aka ƙara da su a cikin hanyarwa sau uku: daban a fassar takardar cikin harshen x zuwa lugha y zuwa x, @ action: button We also uncover the effect of resource-related factors (i.e. how much monolingual/bilingual data is available for a given language) on the optimal choice of bitext mining method, demonstrating that there is currently no one-size-fits-all approach for this task.  Munã samun kodi da data da ke amfani da cikin jarrabayenmu, da bayyane.", 'sk': 'Pridobivanje visokokakovostnih vzporednih korpusov je ključnega pomena za usposabljanje sistemov NMT. Ker pa številni jezikovni pari nimajo ustreznih zlatih standardov podatkov o usposabljanju, je bil priljubljen pristop izkopavanje tako imenovanih "psevdo-paralelnih" stavkov iz združenih dokumentov v dveh jezikih. V prispevku opisujemo nekaj pomanjkljivosti pri sedanjih metodah, ki temeljijo na pragu vgradnje podobnosti, in predlagamo heuristično metodo na njenem mestu. Naša metoda vključuje prevod obeh polovic združenega korpusa pred rudarjenjem, nato pa izvedbo večinskega glasovanja o parih stavkov, izločenih na tri načine: po prevodu dokumentov v jezik x v jezik y, po prevodu jezika y v x, Z uporabo izvirnih dokumentov v jezikih x in y dokazujemo uspeh s tem novim pristopom pri iskanju podobnosti Tatoeba v 64 jezikih z nizkimi viri ter NMT v kazahščini in gujaratiju. Odkrivamo tudi učinek dejavnikov, povezanih z viri (tj. koliko enojezičnih/dvojezičnih podatkov je na voljo za določen jezik) na optimalno izbiro metode rudarjenja bitekstov, kar dokazuje, da za to nalogo trenutno ni enotnega pristopa, ki bi ustrezal vsem. Kodo in podatke, uporabljene v naših eksperimentih, dajemo javno na voljo.', 'jv': 'Ngubah ditambah-kaliwat tah-perusahaan kuwi dianggap kanggo ngilangno sistem NMT. politenessoffpolite, "), and when there is a change ("assertivepolite"), when there is a change ("assertivepolite"), when there is a change ("assertive Nang peber-ne, kita mulalah akeh drawbacks nggawe sistem sing wis an a dadi nguasai perusahaan karo sekang nggawe, lan jewisan akeh sistem heuristik. Awakdhéwé éntuk tanggal nggambar kelas telu, sampeyan tanggal nggawe gerakan kelas telu, lan unyak nggawe barang hukum sing beraksi kanggo kelas telu maneh: arep terjamahan dokumen nggawe x nggo langa y, arep terjamahan nggo langa y nggo x, Sampeyan nguasai dokumen sing dumadhi nang langga x lan y Awakdhéwé éntuk nggawe efek karo Ressource-Relative Faktur (i.e. Pilihan Monlanguage/Bilngual data yang dipunangé kanggo nggawe langgambar) nggawe sistem Optimisan karo bittext minemethod, ngêlangno, akeh ngêngguna kuwat saiki ora ono-size-confs-all method nggo nggawe task. Awak dhéwé ngéwangi kode lan data yang dipunangé ning perintah dhéwé', 'bo': 'སྤྱིར་བཏང་བའི་དབུལ་མཐུད་ཚད་ལྡན་པ་སྦྱོར་བའི་དབུལ་མཐུད་ཚད་གལ་ཆེ་བ་ཡིན། ཡིན་ནའང་། སྐད་ཡིག་ཆ་གཉིས་ཀྱིས་རྒྱ་གར་གྱི་གནས་སྟངས་བདེ་འཇགས་ངལ་མིན་འདུག། འུ་ཅག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་ད་ལྟོའི་ཐབས་ལམ་ལ་ཞིག་འཚོལ་མཐུན་པའི་རྒྱུན་ལམ་ཞིག་ཡོད་པ་དང་། ང་ཚོའི་ཐབས་ལམ་དུ་འདིའི་ནང་གི་མིང་དང་ཆུང་གཉིས་ལས་ཕར་ཆེན་ཕུང་ཞིག་གནང་བ་ཡིན་ནའང་། དེ་ནས་ཚོར་ཡིག སྐད་ཡིག་གི་ནང་དུ་ཐོག་མའི་ཡིག་ཆ་ལ་ཞིབ་བྱས་པ་ནི་ཨེགས་དང་ཝའི་ནང་དུ་ཡིག་གཟུགས་ཡོད། ང་ཚོས་རྒྱུ་དངོས་འབྲེལ་བ་དང་འབྲེལ་བའི་ཆ་རྐྱེན་པས་ཀྱང་མཐོང་ཐུབ་པ་དེ་གསལ་བཤད་ན། ང་ཚོས་ལག་ལེན་འཐབ་པའི་ཁོར་ཡིག་ཆ་དང་ཆ་འཕྲིན་ཡིག་ཆ་སྟོན་ཐུབ་པ་རེད།'}
{'en': 'EM Corpus : a comparable corpus for a less-resourced language pair Manipuri-English', 'ar': 'EM Corpus: مجموعة مماثلة لزوج لغوي أقل مواردًا من Manipuri-English', 'fr': 'EM Corpus\xa0: un corpus comparable pour une paire de langues moins riches Manipuri-Anglais', 'pt': 'EM Corpus: um corpus comparável para um par de idiomas com menos recursos Manipuri-Inglês', 'es': 'EM Corpus: un corpus comparable para un par de idiomas con menos recursos Manipuri-Inglés', 'ja': 'EMコーパス：資源の少ない言語ペアManipuri - Englishのための同等のコーパス', 'zh': 'EM语料库曰:少言曼尼普里语-英语类语料库', 'hi': 'EM कॉर्पस: एक कम संसाधन वाली भाषा जोड़ी मणिपुरी-अंग्रेजी के लिए एक तुलनीय कॉर्पस', 'ru': 'EM Corpus: сопоставимый корпус для менее обеспеченной ресурсами языковой пары манипури-английский', 'ga': 'EM Corpus: corpas inchomparáide le haghaidh péire teanga níos lú acmhainní Manipuri-Béarla', 'hu': 'EM Corpus: hasonló korpusz egy kevésbé erőforrásokkal rendelkező nyelvpárhoz Manipuri-English', 'el': 'EM Corpus: ένα συγκρίσιμο σώμα για ένα γλωσσικό ζεύγος με λιγότερους πόρους', 'ka': 'EM Corpus: შემდგომარებელი კორპუსი მანიპური-ანგლისური ენის ზოგისთვის', 'it': 'EM Corpus: un corpus comparabile per una coppia linguistica meno dotata di risorse Manipuri-Inglese', 'kk': 'EM Corpus: Манипури-ағылшын тілдің қос үшін салыстырмалы корпус', 'lt': 'EM Corpus: panašus corpus mažiau išteklių turinčiai kalbų porai Manipuri-anglų kalba', 'mk': 'ЕМ Корпус: споредлив корпус за помалку ресурсиран јазик пар манипури-англиски', 'ms': 'EM Corpus: corpus yang boleh dibandingkan untuk pasangan bahasa yang kurang berkuasa Manipuri-English', 'ml': 'EM Corpus: a comparable corpus for a less-resourced language pair Manipuri-English', 'mt': 'EM Corpus: korpus komparabbli għal par lingwistiku anqas riżorsi Manipuri-Ingliż', 'ro': 'EM Corpus: un corpus comparabil pentru o pereche de limbi mai puțin resurse Manipuri-Engleză', 'pl': 'EM Corpus: porównywalny korpus dla mniej zasobnej pary językowej Manipuri-English', 'sr': 'EM Corpus: usporedno korpus za manje resursnog jezičkog parova Manipuri-engleski', 'si': 'EM Corpus: අඩුම භාෂාවක් සම්පූර්ණයෙන් සම්පූර්ණයි භාෂාවක්', 'so': 'EM Corpus: qofka u eg luqada aan lacag lahayn labo Manipuri-Ingiriis', 'mn': 'EM Corpus: Манипури-Англи хэл дээр бага хүчтэй холбоотой корпус', 'sv': 'EM Corpus: en jämförbar korpus för ett mindre resursfyllt språkpar Manipuri-Engelska', 'ta': 'EM கார்புஸ்: ஒரு குறைந்த மூல மொழி ஜோடி மானிபுரி- ஆங்கிலம்', 'ur': 'EM Corpus: ایک کم رسسورٹ زبان جوڑے کے لئے ایک مقایسہ کورپوس Manipuri-English', 'no': 'EM Corpus: ein sammenlignbar korpus for ein lite ressursert språkport Manipuri-engelsk', 'vi': 'EM Corpus: một tập thể tương ứng với một đôi ngôn ngữ lỏng lẻo', 'uz': 'EM Korpus: Manipuri- Inglizchaga bir qiymati tarkibini', 'hr': 'EM Corpus: uspoređen korpus za manje resursnog jezičkog parova Manipuri-engleski', 'nl': 'EM Corpus: een vergelijkbaar corpus voor een taalpaar met minder middelen', 'bg': 'ЕМ Корпус: сравним корпус за по-малко ресурсна езикова двойка Манипури-Английски', 'de': 'EM Corpus: ein vergleichbarer Korpus für ein weniger ressourcenreiches Sprachpaar Manipuri-English', 'ko': 'EM 자료 라이브러리: Manipri English에 대한 리소스가 적은 언어 비교 자료 라이브러리', 'sw': 'EM Corpus: viungo vinavyofanana kwa ajili ya wawili wasio na rasmi wa lugha Manipuri-Kiingereza', 'fa': 'EM Corpus: یک کورپوس قابل مقایسه برای یک جفت زبان کمتری مانپوری-انگلیسی', 'da': 'EM Corpus: et sammenligneligt korpus for et mindre ressourcevenligt sprogpar Manipuri-engelsk', 'tr': 'EM Korpus: Manipuri-Iňlisçe ýeterlik dil üçin karşılaşýan korpus', 'sq': 'EM Corpus: një korpus i krahasueshëm për një çift gjuhësh më pak të burimeve Manipuri-Anglisht', 'af': 'EM Corpus: 芒聙聶n vergelykbare korpus vir 芒聙聶n minder-hulpbron taal paar Manipuri-Engels', 'id': 'EM Corpus: corpus yang dibandingkan untuk pasangan bahasa yang kurang sumber daya Manipuri-Inggris', 'hy': 'ԷՄ Կորպուս. ավելի քիչ ռեսուրսներ ունեցող լեզվի զույգի Մանիպուրի-անգլերենի համեմատական կորպուս', 'az': 'EM Corpus: az qüvvətli dil çift Manipuri-English', 'am': 'የኢሜይል ኮርፓስ: ለአንድ አነስተኛ ቋንቋ ዓይነቶች ማኒፉሪክ', 'bn': 'এম কোর্পাস: কম সম্পদের ভাষার জোড়া ম্যানিপুরি-ইংরেজি', 'ca': 'EM Corpus: un corpus comparable per a un parell de llenguatges menys recursos manipuri-anglès', 'et': 'EM Corpus: võrreldav korpus vähem ressurssidega keelepaari manipuri-inglise keele jaoks', 'bs': 'EM Corpus: usporedno korpus za manje resursnog jezičkog parova Manipuri-engleski', 'fi': 'EM Corpus: vertailukelpoinen korpus vähemmän varatulle kieliparille manipuri-englanti', 'cs': 'EM Corpus: srovnatelný korpus pro méně zdrojový jazykový pár Manipuri-English', 'jv': 'EM Kerpus: trus menyang karo perusahaan kanggo didasakno urip Manipur-Inggris', 'ha': 'KCharselect unicode block name', 'sk': 'EM Corpus: primerljiv korpus za manj sredstev jezikovni par manipuri-angleščina', 'bo': 'EM Corpus: སྤྱི་ཚོགས་ཅན་གྱི་འབྲེལ་བ་ཞིག་དང་མཉམ་འབྱུང་བའི་སྐད་རིགས་ཀྱི་འབྲེལ་བ་ཞིག་ནི། Manipuri-English', 'he': 'EM Corpus: קורפוס שווה לזוג שפת פחות משאבים מניפורי-אנגלית'}
{'en': 'In this paper, we introduce a sentence-level comparable text corpus crawled and created for the less-resourced language pair, Manipuri(mni) and English (eng). Our monolingual corpora comprise 1.88 million Manipuri sentences and 1.45 million English sentences, and our parallel corpus comprises 124,975 Manipuri-English sentence pairs. These data were crawled and collected over a year from August 2020 to March 2021 from a local newspaper website called ‘The Sangai Express.’ The resources reported in this paper are made available to help the low-resourced languages community for MT / NLP tasks.', 'pt': "Neste artigo, apresentamos um corpus de texto comparável em nível de sentença, rastreado e criado para o par de idiomas com menos recursos, Manipuri(mni) e inglês (eng). Nosso corpora monolíngue compreende 1,88 milhão de frases em Manipuri e 1,45 milhão de frases em inglês, e nosso corpus paralelo compreende 124.975 pares de frases em Manipuri-Inglês. Esses dados foram rastreados e coletados ao longo de um ano, de agosto de 2020 a março de 2021, de um site de jornal local chamado 'The Sangai Express'. Os recursos relatados neste documento são disponibilizados para ajudar a comunidade de idiomas com poucos recursos para tarefas de MT/NLP.", 'fr': "Dans cet article, nous présentons un corpus de texte comparable au niveau de la phrase analysé et créé pour la paire de langues moins ressources, manipuri (mni) et anglais (eng). Nos corpus monolingues comprennent 1,88 million de phrases manipuri et 1,45 million de phrases anglaises, et notre corpus parallèle comprend 124 975 paires de phrases manipuri-anglais. Ces données ont été explorées et collectées pendant un an, d'août 2020 à mars 2021, sur le site Web d'un journal local appelé «\xa0The Sangai Express\xa0». Les ressources mentionnées dans ce document sont mises à disposition pour aider la communauté linguistique à faibles ressources pour les tâches de MT/NLP.", 'ar': 'في هذه الورقة ، نقدم مجموعة نصية قابلة للمقارنة على مستوى الجملة تم الزحف إليها وتم إنشاؤها للزوج اللغوي الأقل موارد ، المانيبوري (mni) والإنجليزية (eng). تضم مجموعتنا أحادية اللغة 1.88 مليون جملة من الجمل المانيبورية و 1.45 مليون جملة باللغة الإنجليزية ، وتتألف مجموعتنا الموازية من 124،975 زوجًا من الجمل الإنجليزية المانيبورية. تم الزحف إلى هذه البيانات وجمعها على مدار عام من آب (أغسطس) 2020 إلى آذار (مارس) 2021 من موقع صحيفة محلية يسمى "The Sangai Express". تم توفير الموارد الواردة في هذه الورقة لمساعدة مجتمع اللغات منخفضة الموارد لمهام الترجمة الآلية / البرمجة اللغوية العصبية.', 'es': 'En este artículo, presentamos un corpus de texto comparable a nivel de oración rastreado y creado para el par de idiomas con menos recursos, Manipuri (mni) e inglés (eng). Nuestros corpus monolingües comprenden 1,88 millones de oraciones en Manipuri y 1,45 millones de oraciones en inglés, y nuestro corpus paralelo comprende 124,975 pares de oraciones en Manipuri e Inglés. Estos datos se rastrearon y recopilaron durante un año, desde agosto de 2020 hasta marzo de 2021, en el sitio web de un periódico local llamado «The Sangai Express». Los recursos informados en este documento están disponibles para ayudar a la comunidad de idiomas de bajos recursos para las tareas de MT/NLP.', 'zh': '本文引一句级比文本语料库,当语料库为资源少语Manipuri(mni)与英语(eng)行创。 吾单语语料库兼188万个曼尼普里语句与145万个英语句,吾平行语料库兼124,975曼尼普里语-英语句是也。 此数从2020年8月至2021年3月年中从土报纸网站"桑盖快车"中取收。 本文告资可以助匮语社区行 MT/NLP 事。', 'ja': "この論文では、リソースの少ない言語ペアであるManipuri （ mni ）とEnglish （ eng ）のためにクロールされ作成された文レベルに匹敵するテキストコーパスを紹介します。私たちの単一言語のコーパスは、188万のマニプーリ語の文章と145万の英語の文章で構成され、私たちの平行コーパスは124,975のマニプーリ語と英語の文章のペアで構成されています。これらのデータは、2020年8月から2021年3月までの1年間にわたって、「The Sangai Express」という地元の新聞のウェブサイトからクロールされ、収集されました。'この論文で報告されているリソースは、MT/NLPタスクのための低資源言語コミュニティを支援するために利用可能になっています。", 'ru': 'В этой статье мы представляем сопоставимый на уровне предложения текстовый корпус, обтекаемый и создаваемый для менее обеспеченной ресурсами языковой пары, Manipuri(mni) и English (eng). Наши одноязычные корпуса состоят из 1,88 миллиона предложений манипури и 1,45 миллиона английских предложений, а наш параллельный корпус состоит из 124 975 манипури-английских пар предложений. Эти данные сканировались и собирались в течение года с августа 2020 года по март 2021 года с сайта местной газеты «Сангай Экспресс». «Ресурсы, описанные в этом документе, предоставляются для оказания помощи сообществу языков с ограниченными ресурсами для выполнения задач MT/NLP.', 'hi': "इस पेपर में, हम एक वाक्य-स्तरीय तुलनीय पाठ कॉर्पस पेश करते हैं जो कम-संसाधन वाली भाषा जोड़ी, मणिपुरी (mni) और अंग्रेजी (eng) के लिए क्रॉल और बनाया गया है। हमारे मोनोलिंगुअल कार्पोरा में 1.88 मिलियन मणिपुरी वाक्य और 1.45 मिलियन अंग्रेजी वाक्य शामिल हैं, और हमारे समानांतर कॉर्पस में 124,975 मणिपुरी-अंग्रेजी वाक्य जोड़े शामिल हैं। इन आंकड़ों को अगस्त 2020 से मार्च 2021 तक एक स्थानीय समाचार पत्र वेबसाइट 'द संगई एक्सप्रेस' से एक साल में क्रॉल किया गया और एकत्र किया गया। इस पेपर में रिपोर्ट किए गए संसाधनों को एमटी / एनएलपी कार्यों के लिए कम संसाधन वाली भाषाओं के समुदाय की मदद करने के लिए उपलब्ध कराया गया है।", 'ga': "Sa pháipéar seo, tugaimid isteach corpas téacs inchomparáide ar leibhéal na habairte a crawláiltear agus a cruthaíodh don phéire teangacha is lú acmhainní, Manipuri(mni) agus Béarla (eng). Cuimsíonn ár gcorpas aonteangach 1.88 milliún abairt Manipuri agus 1.45 milliún abairt Bhéarla, agus cuimsíonn ár gcorpas comhthreomhar 124,975 péire abairtí Manipuri-Béarla. Craoladh agus bailíodh na sonraí seo thar thréimhse bliana ó Lúnasa 2020 go Márta 2021 ó shuíomh Gréasáin nuachtáin áitiúil ar a dtugtar `The Sangai Express.' Cuirtear na hacmhainní a thuairiscítear sa pháipéar seo ar fáil chun cabhrú leis an bpobal teangacha ar bheagán acmhainní le haghaidh tascanna MT/NLP.", 'hu': 'Ebben a tanulmányban bemutatunk egy mondatszintű, összehasonlítható szövegkorpuszt, amelyet a kevésbé erőforrásokkal rendelkező nyelvpárhoz készítettünk, Manipuri(mni) és angol (eng). Egynyelvű korpuszunk 1,88 millió manipuri mondatot és 1,45 millió angol mondatot tartalmaz, párhuzamos korpuszunk pedig 124 975 manipuri-angol mondatpárt tartalmaz. Ezeket az adatokat 2020 augusztusától 2021 márciusáig egy éven keresztül feltérképezték és gyűjtötték össze egy helyi újság honlapjáról, amelynek neve "The Sangai Express". A tanulmányban szereplő források elérhetővé teszik az alacsony erőforrásokkal rendelkező nyelvi közösségnek az MT/NLP feladatokhoz való segítségét.', 'el': 'Σε αυτή την εργασία, εισάγουμε ένα συγκρίσιμο σώμα κειμένου σε επίπεδο πρότασης που σαρώθηκε και δημιουργήθηκε για το γλωσσικό ζεύγος με λιγότερους πόρους, το Μανιπούρι και τα Αγγλικά. Τα μονογλωσσικά σώματά μας αποτελούνται από 1.88 εκατομμύρια φράσεις Μανιπουρί και 1.45 εκατομμύρια Αγγλικές φράσεις, ενώ το παράλληλο σώμα μας αποτελείται από 124,975 Μανιπουρί-Αγγλικά ζεύγη προτάσεων. Αυτά τα δεδομένα σαρώθηκαν και συλλέχθηκαν πάνω από ένα χρόνο από τον Αύγουστο 2020 έως τον Μάρτιο 2021 από έναν ιστότοπο τοπικής εφημερίδας που ονομάζεται "The Sangai Express". Οι πόροι που αναφέρονται σε αυτό το έγγραφο διατίθενται για να βοηθήσουν την κοινότητα γλωσσών με χαμηλούς πόρους για εργασίες ΜΤ/NLP.', 'ka': 'ჩვენ ამ წიგნაში ჩვენ შევცვალოთ წიგნალის შემდგომარებელი ტექსტის კორპუსს, რომელიც შექმნილია და შექმნილია ცოტა წიგნალის ზოგნალისთვის, მანიპური(mni) და ანგლისურ ჩვენი მონოლენგური კოპორაში არის 1,88 მილიონი მანიპური სიტყვები და 1,45 მილიონი ანგლისური სიტყვები, და ჩვენი პარალელი კოპორაში არის 124 975 მანიპური-ანგლისური სიტყვები. ეს მონაცემები 2020 წლიდან მარტი 2021 წლიდან ადგილური გვერდის საიბეტიდან "Sangai Express". ამ დოკუნტში შეტყობინებული რესურსები იყენება, რომ დახმარება MT/NLP დავალებებისთვის მარტივი ენების საზოგადოებაში.', 'it': "In questo articolo, introduciamo un corpus di testo comparabile a livello di frase scansionato e creato per la coppia di lingue meno risorse, Manipuri(mni) e Inglese (eng). I nostri corpora monolingue comprendono 1,88 milioni di frasi Manipuri e 1,45 milioni di frasi inglesi, e il nostro corpus parallelo comprende 124.975 coppie di frasi Manipuri-Inglese. Questi dati sono stati scansionati e raccolti nell'arco di un anno da agosto 2020 a marzo 2021 da un sito web del giornale locale chiamato `The Sangai Express.' Le risorse riportate in questo articolo sono messe a disposizione per aiutare la comunità delle lingue con scarse risorse per le attività MT/PNL.", 'lt': 'Šiame dokumente pristatome panašų tekstų lygį į sakinius, sukūrusį mažesnių išteklių kalbų porai, Manipuri(mni) ir anglų kalbai (eng.). Mūsų vienakalbis korporas sudaro 1,88 mln. Manipuri sakinių ir 1,45 mln. anglų sakinių, o mūsų lygiagretus korpusas sudaro 124,975 Manipuri-anglų sakinių poros. Šie duomenys buvo paimti ir surinkti per metus nuo 2020 m. rugpjūčio mėn. iki 2021 m. kovo mėn. iš vietos laikraščių interneto svetainės „Sangai Express“. Šiame dokumente nurodyti ištekliai skiriami siekiant padėti mažai išteklių turinčioms kalbų bendruomenėms vykdyti MT/NLP užduotis.', 'mk': 'Во овој весник, ние воведуваме споредлив текст корпус на ниво на реченици полн и создаден за помалку ресурсираниот јазик пар, Manipuri( mni) и англиски (eng). Нашиот монојазичен корпора сочинува 1,88 милиони манипури казни и 1,45 милиони англиски казни, а нашиот паралелен корпора сочинува 124,975 манипури-англиски парови. Овие податоци беа преземени и собрани во текот на една година од август 2020 до март 2021 година од локална веб-страница на весниците наречена „Сангаи експрес“. Ресурсите објавени во овој документ се ставени на располагање за помош на заедницата со ниски ресурси на јазици за задачите на МТ/НЛП.', 'kk': 'Бұл қағазда, сілтемелер деңгейінде салыстырылатын мәтін корпусын таңдап, көп ресурс тілдер, Манипури( mni) және ағылшын (eng) үшін құрылады. Біздің monolingual корпорамыз 1,88 млн. Манипури сөйлемелері және 1,45 млн. ағылшын сөйлемелері бар. Параллельді корпус 124 975 Манипури-ағылшын сөйлемелері бар. Бұл деректер 2020 жылдан бастап 2021 жылдың тамыз айының күні қазірдегі жергілікті жаңалық вебсайтынан "The Sangai Express" деп аталады. Бұл қағаздағы хабарлаған ресурстар MT/NLP тапсырмаларының көмектесу үшін төмен ресурстар тілдеріне көмектеседі.', 'ms': "Dalam kertas ini, kami memperkenalkan satu teks corpus yang boleh dibandingkan dengan kalimat-kalimat merangkak dan dicipta untuk pasangan bahasa yang kurang berkuasa, Manipuri(mni) dan Inggeris (eng). Korpora monobahasa kita terdiri dari 1.88 juta kalimat Manipuri dan 1.45 juta kalimat Inggeris, dan korpora paralel kita terdiri dari 124,975 pasangan kalimat Manipuri-Inggeris. Data ini diperiksa dan dikumpulkan selama setahun dari Agustus 2020 hingga Maret 2021 dari laman web surat kabar setempat yang dipanggil `Sangai Express.' Sumber yang dilaporkan dalam kertas ini dibuat tersedia untuk membantu komuniti bahasa sumber rendah untuk tugas MT/NLP.", 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഒരു വാക്ക് നിലനില്\u200dക്കുന്നതിന് തുല്യമായ പദാവലി കോര്\u200dപ്പുസിനെ പരിചയപ്പെടുത്തുകയും ചെയ്യുന്നു. കുറച്ച് സമ്പൂര്\u200dണ ഞങ്ങളുടെ മോനോളില്\u200d ഭാഷ കോര്\u200dപ്പോരാ 1.88 മില്ല്യണ്\u200d മാനിപ്പൂരിയുടെ ശിക്ഷകളും 1.45 മില്ല്യന്\u200d ഇംഗ്ലീഷ് വാക്കുകളും ഉണ്ട്, നമ്മുടെ പാരാളിലെ  2020 ആഗസ്റ്റ് 2021 മുതല്\u200d മാര്\u200dച്ച് 2021 വരെ ഈ വിവരങ്ങള്\u200d ഒരു വര്\u200dഷം വീഴ്ത്തിയിട്ടുണ്ടായിരുന്നു. സാങ്കായി എക്സ്പ്രെസ് എന്ന് പ ഈ പേപ്പറില്\u200d റിപ്പോര്\u200dട്ട് ചെയ്ത വിഭവങ്ങള്\u200d എംടി/NLP ജോലികള്\u200dക്ക് കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകങ്ങള്\u200d സഹായിക', 'mn': 'Энэ цаасан дээр бид өгүүлбэрт харьцуулагдмал текст корпус багассан, багассан хэл хоёр, Манипури(mni) болон Англи (eng) болон бүтээсэн. Бидний ганц хэл корпора нь 1.88 сая Манипури өгүүлбэртэй, 1.45 сая Англи хэлний өгүүлбэртэй. Бидний параллел корпус 124.975 Манипури-Англи хэлний өгүүлбэртэй холбоотой. Эдгээр мэдээллүүд 2020 оны 8-р сарын 2021 оны 3-р сарын үеэс "The Sangai Express" нэртэй газрын сонины вебсайтаас нэг жилийн турш цуглуулсан. Энэ цаасан дээрх мэдээллийн бүтээгдэхүүнүүд MT/NLP ажлын тусламжтайгаар бага хүчтэй хэлний нийгэмд туслах боломжтой болдог.', 'no': 'I denne papiret introduserer vi eit sammenlignbar tekstkorpus som er krølte og oppretta for den mindre ressurserte språkopla, Manipuri( mni) og engelske (eng). Vår monospråk korpora inneheld 1,88 millioner manipuri setningar og 1,45 millioner engelsk setningar, og vår parallelle korpus inneheld 124,975 manipuri-engelsk setningar. Desse data vart krølte og samla over eit år frå august 2020 til mart 2021 frå ein lokal nettside for jobben kalla « The Sangai Express ». Ressursene som er rapporterte i denne papira er tilgjengelege for å hjelpa samfunnet med låg ressursar for MT/NLP-oppgåver.', 'pl': 'W niniejszym artykule przedstawiamy porównywalny na poziomie zdań korpus tekstowy przeszukiwany i stworzony dla mniej zasobów pary językowej Manipuri(mni) i angielskiego (eng). Nasze jednojęzyczne korpusy składają się z 1,88 milionów zdań Manipuri i 1,45 milionów zdań angielskich, a nasz równoległy korpus składa się z 124,975 par zdań Manipuri-Angielski. Dane te zostały przeszukane i zebrane w ciągu roku od sierpnia 2020 do marca 2021 ze strony lokalnej gazety o nazwie "The Sangai Express". Zasoby opisane w niniejszym artykule są udostępniane w celu pomocy społeczności języków o niskich zasobach w realizacji zadań MT/NLP.', 'mt': 'F’dan id-dokument, a ħna nintroduċu test komparabbli fil-livell tas-sentenza corpus crawled u maħluq għall-par lingwistiku anqas riżorsi, Manipuri(mni) u Ingliż (eng). Il-korpura monolingwa tagħna tinkludi 1,88 miljun sentenza Manipuri u 1,45 miljun sentenza Ingliża, u l-korpus parallel tagħna tinkludi 124,975 pari ta’ sentenza Manipuri-Ingliż. Din id-dejta nġabret u nġabret tul sena minn Awwissu 2020 sa Marzu 2021 minn websajt lokali tal-gazzetti msejħa “The Sangai Express.” Ir-riżorsi rrappurtati f’dan id-dokument huma disponibbli biex jgħinu lill-komunità tal-lingwi b’riżorsi baxxi għall-kompiti MT/NLP.', 'ro': "În această lucrare, introducem un corpus text comparabil la nivel de frază, crawled și creat pentru perechea de limbi mai puțin resurse, Manipuri(mni) și engleză (eng). Corpora noastră monolingvă cuprinde 1,88 milioane de propoziții Manipuri și 1,45 milioane de propoziții în limba engleză, iar corpul nostru paralel cuprinde 124.975 perechi de propoziții Manipuri-Engleză. Aceste date au fost accesate cu crawlere și colectate peste un an, între august 2020 și martie 2021, de pe site-ul unui ziar local numit `The Sangai Express.' Resursele raportate în această lucrare sunt puse la dispoziție pentru a ajuta comunitatea lingvistică cu resurse reduse pentru sarcini MT/PNL.", 'sr': 'U ovom papiru predstavljamo poređeni tekst korpus na razini rečenica koji je pušio i stvorio za manje resursnog jezika par, Manipuri(mni) i engleski (engleski). Naša monojezička korpora sastoji od 1,88 miliona rečenica Manipuri i 1,45 miliona engleskih rečenica, a naš paralelni korpus sastoji od 124,975 parova za rečenice Manipuri-engleski. Ovi podaci su otpušteni i sakupljeni godinu dana od avgusta 2020. do marta 2021. sa lokalnog novinskog sajta po imenu «Sangai Express». Izjavljeni su resursi u ovom papiru dostupni da pomognu zajednici s niskim resursima za zadatak MT/NLP.', 'si': 'මේ පැත්තට, අපි වාක්ය සම්පූර්ණ පැත්තක් කොර්පුස් එකක් පෙන්වන්න පුළුවන් විදිහට පෙන්වන්න පුළුවන් විදිහට පෙන්වන්න ප අපේ එක භාෂාවික කොර්පෝරා එක්ක 1.88 මිලියන් මැනිපුරි වචනය සහ 1.45 මිලියන් ඉංග්\u200dරීසි වචනය සම්පූර්ණය සම්පූර්ණයේ 124.975 මනිප මේ තොරතුරු අවුස්ටෝ 2021 වලින් අවුරුද්දක් වලින් අවුරුද්දක් ගැන සංගලය කරලා තියෙන්නේ. මේ පත්තරේ තොරතුරු වාර්තාවක් ලැබුනේ MT/NLP වැඩේ සමාජාවට උදව් කරන්න.', 'so': 'Qoraalkan waxaan ku soo bandhignaa qoraal heer oo isku mid ah oo la qoray, waxaana loo abuuray labada luqada oo ka yar, Manipuri(mni) iyo Ingiriis (eng). Shirkadaha afka noogu qoran waa 1,88 milyan oo manipuri iyo 1,45 milyan oo afka Ingiriiska ah, qaybtayada noogu dhigayna waa 124,975 noocyo oo af Ingiriis ah. Macluumaadkaas waxaa laga soo ururiyey sanad ka badan Agosto 2020 ilaa Machi 2021 laga soo ururiyey bogagga wargeyska la yidhaahdo ‘The Sangai Express’. Macluumaadyada warqaddan lagu soo qoray waxaa laga heli karaa in lagu caawiyo bulshada luuqadaha hoose ee MT/NLP shaqooyinkooda.', 'sv': 'I den här uppsatsen introducerar vi en jämförbar textkorpus på meningsnivå som genomsökts och skapats för det mindre resurserade språkparet Manipuri(mni) och engelska (eng). Vår enspråkiga korpus består av 1,88 miljoner manipuri-meningar och 1,45 miljoner engelska meningar, och vår parallella korpus består av 124 975 manipuri-engelska meningar. Dessa data genomsöktes och samlades in under ett år från augusti 2020 till mars 2021 från en lokal tidning webbplats som heter "Sangai Express". Resurserna som redovisas i denna uppsats görs tillgängliga för att hjälpa den lågresurserade språkgemenskapen för MT/NLP-uppgifter.', 'ta': "இந்த காக்கியத்தில், நாம் ஒரு வாக்கு- மட்டத்திற்கு ஒப்பீடு உரை குறிப்பிட்டு குறைந்த மொழி ஜோடி, மானிபுரி( mni) மற்றும் ஆங்கிலத்திற 1.88 மில்லியன் மானிபுரி வாக்குகள் மற்றும் 1.45 மில்லியன் ஆங்கிலத்தின் வாக்கியங்கள், எங்கள் இணைய கார்புஸ் 124,975 மானிபுரி- ஆங்கிலம் வாக்க 2020 ஆகஸ்டிலிருந்து 2021 மார்ச் 2021 வரை ஒரு வருடத்திற்கு மேல் இந்த தகவல்கள் 'சாங்கா எக்ஸ்ப்ரெஸ்' என்ற ஒரு உள்ளூர் தெரியும் வலை இந்த காகிதத்தில் அறிவிக்கப்பட்ட மூலங்கள் MT/NLP பணிகளுக்கு குறைந்த மூலங்கள் சமூகத்தை உதவ உதவுவதற்கு கிடைக்கும்.", 'ur': 'اس کاغذ میں ہم ایک جماعت سطح کے مطابق مطابق متن کرپوس کو معلوم کریں گے جو بہت کم سازگار زبان جوڑے، Manipuri(mni) اور انگلیسی (eng) کے لئے پیدا کیا گیا ہے۔ ہمارا ایک زبان کورپورا 1.88 میلیون منپوری جماعت اور 1.45 میلیون انگلیسی جماعت میں ہے اور ہمارا مشابہ کورپوس 124.975 منپوری-انگلیسی جماعت جوڑے ہیں یہ اوگس 2020 سے مارس 2021 تک ایک سال سے لگائے گئے اور جمع کئے گئے ایک محلی کائنات ویسٹ ویٹ سائٹ سے "سانگای اکسپرس". اس کاغذ میں گزارے ہوئے رسورسوں کو MT/NLP کے کاموں کے لئے کم رسورس زبانوں کی کمونٹی کی مدد کرنے کے لئے موجود ہیں.', 'uz': 'Bu qogʻozda biz bir so\'zni o\'xshash matn corpusini ko\'rsamiz va qisqa murakkab bo\'lgan tilni, Manipuri(mni) va ingliz (eng) uchun yaratdik. Bizning monolingan kompaniyasiz 1.88 million Manipuri so\'zlari va 1.45 million ingliz tili so\'zlarimiz esa, va bizning parallel korpus 124,975 Manipuri-Ingliz tili so\'zlariga qo\'llangan. Ushbu maʼlumotlar 2020-Agostdan 2021-marta yildan bir yildan olingan va "Sangai Express" deb nomlangan lokal gazeti saytidan olingan. Ushbu qogʻozdagi qisqa murakkablar MT/NLP vazifalarini yordam beradi.', 'vi': 'Trong tờ giấy này, chúng tôi giới thiệu một văn bản tương đương mức án. Corpus đã bò và tạo ra cho một cặp ngôn ngữ ít nguồn, Manipuri(mn) và Anh (eng). Chúng ta có thể nói chung một ngôn ngữ phân loại 1.88 triệu tuyên án Manipur và 1.45 triệu triệu câu Anh đây, và tập thể tương đồng của chúng ta gồm 124,975 Manipura-Anh. Những dữ liệu này đã được bò và thu thập hơn một năm từ tháng Tám 2020 đến tháng đôi 2021 từ một trang web của báo địa phương gọi là: The Sangi Express." Các nguồn lực được báo cáo trên tờ giấy này được cung cấp để hỗ trợ cộng đồng ngôn ngữ ít nguồn cho các nhiệm vụ MT/N LP.', 'bg': 'В тази статия представяме съпоставим текстов корпус на ниво изречение, обхождан и създаден за по-малко ресурсната езикова двойка Манипури и Английски. Нашите едноезични корпуси включват 1,88 милиона манипурски изречения и 1,45 милиона английски изречения, а нашият паралелен корпус включва 124 975 манипурско-английски изречения. Тези данни са обхождани и събрани в продължение на една година от август 2020 г. до март 2021 г. от уебсайта на местния вестник, наречен "Сангай Експрес". Ресурсите, докладвани в този документ, са предоставени за подпомагане на езиковата общност с ниски ресурси за задачите по МТ/НЛП.', 'hr': 'U ovom papiru predstavljamo poređeni tekst korpus na razini rečenica koji je pušio i stvorio za manje resursni jezički par, Manipuri(mni) i engleski (eng). Naša monojezička tijela sadrži 1,88 milijuna rečenica Manipuri i 1,45 milijuna engleskih rečenica, a naš paralelni korpus sadrži 124.975 parova za rečenice Manipuri-engleski. Te podatke su otpuštene i skupljene godinu dana od kolovoza 2020. do ožujka 2021. godine na lokalnoj novinskoj stranici zvanoj "Sangai Express". Prijavljeni su resursi u ovom papiru dostupni kako bi pomogla zajednici s niskim resursima za zadatke MT/NLP.', 'da': "I denne artikel introducerer vi et sammenligneligt tekstkorpus på sætningsniveau, der er gennemgået og skabt til de mindre ressourcer sprogpar, Manipuri(mni) og engelsk (eng). Vores ensprogede korpus består af 1,88 millioner Manipuri sætninger og 1,45 millioner engelske sætninger, og vores parallelle korpus består af 124.975 Manipuri-engelske sætningspar. Disse data blev gennemgået og indsamlet over et år fra august 2020 til marts 2021 fra en lokal avis hjemmeside kaldet `Sangai Express.' De ressourcer, der rapporteres i dette dokument, stilles til rådighed for at hjælpe sprogfællesskabet med lav ressource til MT/NLP-opgaver.", 'nl': "In dit artikel introduceren we een vergelijkbaar tekstcorpus op zinsniveau dat gecrawld en gemaakt is voor het taalpaar met minder middelen, Manipuri(mni) en Engels (eng). Onze eentalige corpora bestaat uit 1.88 miljoen Manipuri zinnen en 1.45 miljoen Engelse zinnen, en ons parallelle corpus bestaat uit 124.975 Manipuri-Engelse zinnenparen. Deze gegevens werden gecrawld en verzameld van augustus 2020 tot maart 2021 vanaf een lokale krantenwebsite genaamd `The Sangai Express'. De in dit document gerapporteerde bronnen worden beschikbaar gesteld om de taalgemeenschap met weinig middelen te helpen bij MT/NLP-taken.", 'id': "Dalam kertas ini, kami memperkenalkan sebuah kalimat-tingkat teks corpus yang dapat dibandingkan merangkak dan diciptakan untuk pasangan bahasa yang kurang sumber daya, Manipuri(mni) dan Inggris (eng). Korpora monobahasa kita terdiri dari 1,88 juta kalimat Manipuri dan 1,45 juta kalimat Inggris, dan korpora paralel kita terdiri dari 124,975 pasangan kalimat Manipuri-Inggris. Data ini diperiksa dan dikumpulkan selama setahun dari Agustus 2020 sampai Maret 2021 dari situs surat kabar lokal yang disebut `Sangai Express.' Sumber daya yang dilaporkan dalam kertas ini dibuat tersedia untuk membantu komunitas bahasa dengan sumber daya rendah untuk tugas MT/NLP.", 'de': 'In diesem Beitrag stellen wir einen auf Satzebene vergleichbaren Textkorpus vor, der für das weniger ressourcenreiche Sprachpaar Manipuri(mni) und Englisch (eng) gecrawlt und erstellt wurde. Unsere einsprachigen Korpora bestehen aus 1,88 Millionen Manipuri-Sätzen und 1,45 Millionen englischen Sätzen, und unser paralleler Korpus besteht aus 124,975 Manipuri-Englischen Satzpaaren. Diese Daten wurden über ein Jahr von August 2020 bis März 2021 von einer lokalen Zeitungswebsite namens "The Sangai Express" gecrawlt und gesammelt. Die in diesem Papier berichteten Ressourcen werden zur Verfügung gestellt, um die ressourcenarme Sprachgemeinschaft bei MT/NLP-Aufgaben zu unterstützen.', 'ko': "본고에서, 우리는 자원이 비교적 적은 언어를 위해 Manipuri (mni) 와 English (eng) 를 그물에 오르게 하고, 문장급을 텍스트 자료 라이브러리에 비교할 수 있도록 소개했다.우리의 단어 자료 라이브러리는 188만 개의 마니푸리 문장과 145만 개의 영어 문장을 포함하고, 우리의 평행 자료 라이브러리는 124975개의 마니푸리 영어 문장 쌍을 포함한다.이 자료들은 2020년 8월부터 2021년 3월까지 1년여 동안 현지 신문 사이트'삼애속보'에서 수집한 것이다본 보고서의 자원은 자원이 부족한 언어 지역사회가 기계 번역/자연 언어 처리 임무를 완성하도록 돕는 데 사용될 수 있다.", 'fa': 'در این کاغذ، ما یک قالب متن قابل مقایسه به سطح جمله را معرفی می\u200cکنیم و برای جفت زبان کمتر، مانیپوری(mni) و انگلیسی (eng) ساخته می\u200cشویم. شرکت تنها زبان ما ۱.۸۸ میلیون جمله مانیپوری و ۱.۵۵ میلیون جمله انگلیسی وجود دارد، و شرکت همراه ما 124.975 جفت جمله مانیپوری-انگلیسی وجود دارد. این داده ها از آگوست ۲۰۰۲ تا مارچ ۲۰۱۱ از وبسایت روزنامه\u200cهای محلی به نام «The Sangai Express» جمع می\u200cشوند. منابع گزارش شده در این کاغذ برای کمک به جامعه زبان\u200cهای کمی برای کار MT/NLP در دسترسی دارند.', 'sw': 'Katika karatasi hii, tunaonyesha makampuni ya maandishi yanayofanana na kuanzishwa kwa ajili ya wawili wachache wa lugha, Manipuri(mni) na Kiingereza (eng). Shirika letu la lugha linajumuisha hukumu milioni 1.88 na hukumu milioni 1.45 ya Kiingereza, na makampuni yetu yanajumuisha hukumu ya watu 124,975 ya Kiingereza ya Manipuri. Takwimu hizi zilianguka na kukusanywa kwa zaidi ya mwaka kuanzia Agosti 2020 hadi Machi 2021 kutoka tovuti ya gazeti hilo lililoitwa ‘The Sangai Express’. Rasilimali zinazoripotiwa katika gazeti hili zinapatikana ili kusaidia jamii ya lugha zenye rasmi za chini kwa kazi za MT/NLP.', 'af': 'In hierdie papier, introduseer ons \'n setningvlak vergelykbare teks korpus gekraai en geskep vir die minder hulpbron taal paar, Manipuri( mni) en Engels (eng). Ons monolinglike korpora bevat 1,88 miljoen Manipuri setnings en 1,45 miljoen Engelske setnings, en ons parallele korporus bevat 124,975 Manipuri-Engelse setnings paar. Hierdie data is geskryf en versamel oor \'n jaar van August 2020 tot March 2021 van \'n plaaslike nuuspapier webwerp wat genoem word "The Sangai Express". Die hulpbronne wat in hierdie papier verkondig is, is beskikbaar om die lae-hulpbronne taalsgemeenskap te help vir MT/NLP-opdragte.', 'am': 'በዚህ ፕሮግራም፣ የጽሑፍ ካርፓስ ለታናሹ ቋንቋ ዓይነቶች፣ Manipuri(mni) እና እንግሊዘኛ (eng) የሚታያየውን የጽሑፍ ደረጃ እናሳውቃለን፡፡ አ.88 ሚሊዮን ማኒፉር ፍርድ እና 1.45 ሚሊዮን እንግሊዘኛ ፍርድ እና የፓራላይነታችን ኮርፓስ 124,975 ማንፒuri-እንግሊዘኛ የፍርድ ግንኙነት ሁለቶች ናቸው። እነዚህ ዳውሮች ከ2020 ጀምሮ ከመጋቢት 2021 ጀምሮ እስከ መጋቢት 2021 ድረስ “ሰንጋi Express” የተባለው የአገር የጋዜጠኛ ገጽ ድረ ገጽ የተሰበሰቡ ናቸው፡፡ በዚህ ገጽ ውስጥ የተዘጋጀው ዕቃዎች ለMT/NLP ስራዎችን ለመረዳት የቋንቋዎች ማኅበረሰብ ይገኛሉ፡፡', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք նախադասությունների մակարդակի համեմատական տեքստի կորպուս, որը թափվել է և ստեղծվել է ավելի քիչ ռեսուրսներ ունեցող լեզվի զույգի համար, Մանիպուրի և անգլերենի համար: Մեր միալեզու մարմինը կազմում է 1.88 միլիոն մանիպուրի նախադասություններ և 1.45 միլիոն անգլերեն նախադասություններ, իսկ մեր զուգահեռ մարմինը կազմում է 124,975 մանիպուրի-անգլերեն նախադասությունների զուգավորներ: Այս տվյալները վերցրել են և հավաքել 2020 թվականի օգոստոսից 2021 թվականի մարտի ընթացքում մեկ տարի տեղական թերթի կայքից, որը կոչվում է "Սանգայ Էքսպրեսը": Այս թղթի մեջ հայտարարված ռեսուրսները հասանելի են, որպեսզի օգնեն ցածր ռեսուրսներ ունեցող լեզուների համայնքին MT-ի և NSP-ի առաջադրանքների համար:', 'tr': "Bu kagyzda çykyş düzedilinde çykyş edilen metin korpusyny tanyşdyryp, iňlisçe (eng) iňlisçe çykyş üçin düzüldik. Biziň monodil korpusymyz 1,88 milýon sany Manipuri sözlerimiz we 1,45 milýon sany iňlisçe sözlerimiz bar we parallel korpusymyz 124,975 Manipuri-Iňlisçe sözlerimiz çiftleýär. Bu maglumatlar 2020-nji Awgust 2020-nji ýyldan Mart 2021-nji ýyldan bäri ýerli gazet habatyndan `The Sangai Express'. Bu kagyzda bildirilen resurslar MT/NLP täzimleri üçin iň ýokary hasaplanýan dillere kömek etmek üçin mejbur boldy.", 'bn': 'এই কাগজটিতে আমরা একটি শাস্তি স্তরের সাথে তুলনামূলক লেখা কর্পাসের সাথে পরিচয় করিয়ে দিচ্ছি যা কম সম্পদের ভাষার জোয়ার, মানিপুরি এবং ইংরেজি (ইংর আমাদের মনোলিভাল কোর্পোরা ১.৮৮ মিলিয়ন ম্যানিপুরির শাস্তি এবং ১. ২০২০০ আগস্ট থেকে ২০১২ পর্যন্ত স্থানীয় সংবাদপত্রের ওয়েবসাইট থেকে ‘সাঙ্গাই এক্সপ্রেস’ নামের এক বছর পর্যন্ত এই তথ্যগুলো ক্রুশ করা  এমটি/এনএলপি কাজের জন্য কম সম্পূর্ণ ভাষা সম্প্রদায়ের সাহায্যের জন্য এই প্রতিবেদনে প্রকাশিত সম্পদ প্রদান করা হয়েছে।', 'bs': 'U ovom papiru predstavljamo poređeni tekst korpus na razini rečenica koji je pušio i stvorio za manje resursnog jezičkog par, Manipuri(mni) i engleski (eng). Naša monojezička korpora sastoji od 1,88 miliona rečenica Manipuri i 1,45 miliona engleskih rečenica, a naš paralelni korpus sastoji od 124.975 parova za rečenice Manipuri-engleski. Te podatke su otpuštene i skupljene godinu dana od avgusta 2020. do marta 2021. sa lokalnog novinskog sajta po imenu «Sangai Express». Izjavljeni su resursi u ovom papiru dostupni da pomognu zajednici s niskim resursima za zadatak MT/NLP.', 'ca': 'En aquest article, introduïm un corpus de text comparable a nivell de frases que s\'arrassava i va crear per al parell de llenguatges menys recursos, Manipuri(mni) i anglès (eng). El nostre corpora monolingüe consisteix en 1,88 milions de frases de Manipuri i 1,45 milions de frases d\'anglès, i el nostre corpore paral·lel consisteix en 124.975 parells de frases de Manipuri-anglès. Aquestes dades van ser recollides durant un any d\'agost del 2020 al març del 2021 d\'una pàgina web local de diaris anomenada "The Sangai Express". Els recursos que es reporten en aquest paper estan disponibles per ajudar a la comunitat de llengües amb pocs recursos a les tasques MT/NLP.', 'sq': 'Në këtë letër, ne paraqesim një korpus teksti të ngjajshëm me nivelin e fjalëve të shprehur dhe krijuar për çiftin gjuhësor më pak të rezervuar, Manipuri(mni) dhe anglisht (eng). Korpora jonë monogjuhësore përfshin 1.88 milion dënime Manipuri dhe 1.45 milion dënime angleze, dhe Korpora jonë paralele përfshin 124,975 çifte dënimi Manipuri-angleze. Këto të dhëna u tërhoqën dhe u mblodhën gjatë një viti nga gushti 2020 deri në mars 2021 nga një uebsajt lokal i gazetave të quajtur "Sangai Express." Burimet e raportuara në këtë letër janë bërë në dispozicion për të ndihmuar komunitetin e gjuhëve me burime të ulta për detyrat MT/NLP.', 'cs': 'V tomto článku představujeme srovnatelný textový korpus na úrovni věty procházený a vytvořený pro méně zdrojový jazykový pár Manipuri(mni) a angličtinu (eng). Naše jednojjazyčné korpusy se skládají z 1,88 milionů vět Manipuri a 1,45 milionů anglických vět a náš paralelní korpus se skládá z 124,975 větových párů Manipuri-English. Tato data byla procházena a shromážděna více než rok od srpna 2020 do března 2021 z místních novinových stránek s názvem "The Sangai Express". Zdroje uvedené v tomto článku jsou zpřístupněny na pomoc komunitě jazyků s nízkými zdroji pro úkoly MT/NLP.', 'az': 'Bu kağıtda, biz cümlələr seviyyəti ilə müəyyən edilən mətn korpusu təşkil edirik və az qüvvətli dil çift, Manipuri(mni) və İngilizce (eng) üçün yaratdıq. Bizim monodil korporamız 1.88 milyon Manipuri sözləri və 1.45 milyon İngilizce sözləri var və parallel korpusumuz 124.975 Manipuri-İngilizce cümlələri çiftləridir. Bu məlumatlar "The Sangai Express" adlı yerli gazetecə sitəsindən 2020-dən Martdan 2021-ə qədər bir il boyunca yığıldılar. Bu kağıtda xəbərdar edilən resurslar MT/NLP işləri üçün düşük ressurslı dillər toplumuna kömək etmək üçün faydalanır.', 'fi': 'Tässä artikkelissa esittelemme lausetason vertailukelpoisen tekstikorpusen, joka on indeksoitu ja luotu vähemmän varatulle kieliparille Manipuri(mni) ja English (eng). Yksikielisiä korpussamme on 1,88 miljoonaa manipurilausetta ja 1,45 miljoonaa englanninkielistä lausetta, ja rinnakkaiskorpussamme 124 975 manipuri-englantilaista lauseparia. Näitä tietoja indeksoitiin ja kerättiin vuoden aikana elokuusta 2020 maaliskuuhun 2021 paikallisen sanomalehden verkkosivustolta nimeltä Sangai Express. Tässä asiakirjassa raportoidut resurssit on tarkoitettu auttamaan vähävaraista kieliyhteisöä MT/NLP-tehtävissä.', 'et': 'Käesolevas töös tutvustame lausetasemel võrreldavat tekstikorpust, mis on loodud vähem ressurssidega keelepaarile Manipuri(mni) ja inglise (eng). Meie ühekeelsed korpused koosnevad 1,88 miljonist manipuri lausest ja 1,45 miljonist inglise lausest ning meie paralleelne korpus koosneb 124 975 manipuri-inglise lausepaarist. Neid andmeid analüüsiti ja koguti aasta jooksul 2020. aasta augustist 2021. aasta märtsini kohaliku ajalehe veebilehelt nimega Sangai Express. Käesolevas dokumendis esitatud ressursid on kättesaadavad vähese ressursiga keelte kogukonna abistamiseks MT/NLP ülesannete täitmisel.', 'jv': "Nang pepulan iki, awake nambah kelas-perusahaan langgar bantuan karo nggawe nguasai winih lan nganggo nggawe barang langgar bantuan, Manipur(meni) lan Inggris (eng). Awak dhéwé, perusahaan lang sampeyan kanggo mulai 1. Dhèwèké iki diburèh lan ijol-ijol sing beraksi banjur tanggal asat ning acara 2020 sampek martén 2020 sampek webèh kaendahing dhéwé kuwi 'The SanGa Express.'; Awak dhéwé éntuk ning pepulan iki bakal bantuan kanggo bantuan kanggo langgambar nggo langgambar MT/NLP.", 'sk': "V prispevku predstavljamo primerljiv besedilni korpus na ravni stavkov, ki je bil preiskan in ustvarjen za manj sredstev jezikovnega pare, manipuri(mni) in angleščino (eng). Naši enojezični korpusi obsegajo 1,88 milijona manipurijskih stavkov in 1,45 milijona angleških stavkov, naš vzporedni korpus pa 124.975 manipurijsko-angleških stavkov. Ti podatki so bili pregledani in zbrani v enem letu od avgusta 2020 do marca 2021 na spletni strani lokalnega časopisa `The Sangai Express'. Viri, navedeni v tem dokumentu, so na voljo za pomoč jezikovni skupnosti z nizkimi viri pri nalogah MT/NLP.", 'ha': "Daga wannan takardan, Munã ƙara wata matsayin-daraja mai kama da matsayin nan, wanda aka yi kwaɗayi kuma aka halitta wa nau'i-biyu, Manipuri(mmi) da Ingiriya (eng). Shirin da ke karãtunsa na mantilar harshen na kammala 1.88 million Manipuri da saurãron Ingiriya miliyan 1.45, kuma makampuni da ke daidaita na rubutu na rubutu 124,975 ɗin Manipuri-Ingiriya. Wannan data aka yi crash da aka sama cikin shekara guda daga Agusti 2020 zuwa March 2021 daga wani website na lokal newspaper called `The Sangai Expression'. @ info", 'bo': 'ང་ཚོས་ཤོག ང་ཚོའི་སྐད་ཡིག་དབང་ཆ་གཅིག་པུ་ཡིན་པའི་མིང་ཚོགས་ཀྱི་ཚིག་རྟགས་༡༨༨་ཡིན་ཡང་ན་དབྱིན་ཡིག་ཚིག་དང་། དེ་ཚོའི་ས་ཆ་parallel་མིང་ཚོགས་ནང་དུ་ སྤྱི་ཚོགས་ཆ་འཕྲིན་ཡིག་ཆ་འདི་དག་སྤྱད་ནས་ལོའི་ཕྱི་ཟླ་༡༢༠༢༠་ལས་ཟླ་ཐོའི་ནང་དུ་བཏོན་ཡོད། ཤོག་བྱང་འདིའི་ནང་གི་རྒྱུ་དངོས་ཐོག་མཛོད་མང་པོ་ཞིག་ནི་MT/NLP བྱ་འགུལ་གྱི་ཐོག', 'he': 'בעיתון הזה, אנחנו מציגים טקסט קורפוס שווה ברמה של משפטים זוחל ויוצר לזוג שפה פחות משאבים, Manipuri (mni) ואנגלית (eng). Our monolingual corpora comprise 1.88 million Manipuri sentences and 1.45 million English sentences, and our parallel corpus comprises 124,975 Manipuri-English sentence pairs.  נתונים אלה נזחלו ונאספו במשך שנה מאגוסט 2020 עד מרץ 2021 מאתר עיתון מקומי שנקרא "הסנגאי אקספרס". המשאבים שנדווחים בעיתון הזה הופכים זמינים כדי לעזור לקהילת השפות עם משאבים נמוכים למשימות MT/NLP.'}
{'en': 'On Pronunciations in Wiktionary : Extraction and Experiments on Multilingual Syllabification and Stress Prediction', 'ar': 'حول النطق في ويكاموس: الاستخراج وتجارب على التقطيع متعدد اللغات والتنبؤ بالإجهاد', 'es': 'Sobre las pronunciaciones en Wikcionario: extracción y experimentos sobre silabificación multilingüe y predicción del estrés', 'fr': 'À propos des prononciations dans le Wiktionnaire\xa0: extraction et expériences sur la syllabification multilingue et la prédiction du stress', 'pt': 'Sobre as pronúncias no wikcionário: extração e experimentos sobre silabificação multilíngue e predição de acento', 'ja': 'ウィクショナリーの発音について：多言語音節化とストレス予測の抽出と実験', 'hi': 'Wiktionary में उच्चारण पर: निष्कर्षण और बहुभाषी Syllabification और तनाव भविष्यवाणी पर प्रयोगों', 'zh': '其维基词典中发音:多言音节、压力占取、实验', 'ru': 'О произношениях в Wiktionary: извлечение и эксперименты по многоязычной словаризации и прогнозирование стресса', 'ga': 'Ar Fhuaimniú san Vicífhoclóir: Eastóscadh agus Turgnaimh ar an Siollabas Ilteangach agus ar Thuar Strus', 'ka': 'Wiktionary', 'el': 'Σχετικά με τις προφορές στα βιβλικά: Εκχύλισμα και πειράματα για την πολύγλωσση Συλβοποίηση και την πρόβλεψη του στρες', 'hu': 'Kiejtések Wiktionáriumban: Kivonás és kísérletek a többnyelvű jelentésben és stressz-jóslásban', 'it': 'Sulle pronunce in Wiktionary: Estrazione ed Esperimenti sulla sillabazione multilingue e la previsione dello stress', 'lt': '„Ekstrakcija ir daugiakalbės silabifikacijos ir streso prognozės eksperimentai“', 'mk': 'On Pronunciations in Wiktionary: Extraction and Experiments on Multilingual Syllabification and Stress Prediction', 'kk': 'Көптілік силабификация және күштік алдын- ала тарқату және эксперименттер', 'ms': 'Pada Pengucapan dalam Wiktionary: Ekstraksi dan Eksperimen dalam Syllabifikasi Berbahasa dan Prediksi Teks', 'ml': 'വിക്ട്ടണ്ടറിയിലെ പ്രദര്\u200dശനങ്ങളില്\u200d: പലഭാഷകങ്ങളുടെയും പരീക്ഷണങ്ങള്\u200d', 'pl': 'O wymowach w wiktionarze: Ekstrakcja i eksperymenty na temat sylabifikacji wielojęzycznej i prognozowania stresu', 'ro': 'Pronunţii în limba wicţionară: Extracţie şi experimente privind silabificarea multilingvă şi predicţia stresului', 'mt': 'Dwar Pronunzjazzjonijiet fil-Wiktionary: Estrazzjoni u Esperimenti dwar Sillabifikazzjoni Multilingwi u Tbassir tal-istress', 'mn': 'Wiktionary-ын илтгэлийн тухай: олон хэл хэлний илтгэлийн болон стресст хэлэлцээний туршилт', 'si': 'වික්ටියෝරි වල ප්\u200dරශ්නයක් ගැන: බොහොම භාෂාවක් සිල්බිකේෂණය සහ ස්ට්\u200dරිස් ප්\u200dරශ්නය', 'so': 'Wiktionary: Extraction and Imtixaan ku saabsan bandhigyada luuqadaha kala duduwan iyo Preference Stress', 'sr': 'O izgovorima u Viktoriji: Ekstrakcija i eksperimenti o multijezičkoj silabifikaciji i predviđanju stresa', 'no': 'På uttaler i Wiktionary: Extraction and Experiments on Multilingual Syllabification and Stress Prediction', 'sv': 'Uttalande i Wiktionary: Extraktion och experiment på flerspråkig kursplanering och stress förutsägelse', 'ta': 'விக்டிக்கரியில் உள்ள முன்னோட்டங்களில்: பல மொழிகள் தொடர்பு மற்றும் விருப்பங்கள் முன்னோட்டம்', 'ur': 'ویکتیورنی کی تعلیمات پر: Multilingual Syllabification and Stress Prediction پر اخراج اور تجربے', 'uz': 'Comment', 'vi': 'Về phát âm ở bói thái: chiết xuất và thử nghiệm... định dạng đa ngôn ngữ và dự đoán stress', 'bg': 'Относно произношенията във викционарния речник: извличане и експерименти по многоезична формулировка и прогнозиране на стреса', 'hr': 'O izjavama u Wiktionary: Ekstrakcija i iskustva o multijezičkoj silabifikaciji i predviđanju stresa', 'da': 'Om udtaler i Wiktionary: Ekstraktion og eksperimenter om flersproget sprogsproget sprogsprog og stress forudsigelse', 'nl': 'Over uitspraken in het Wiktionary: Extractie en Experimenten op Meertalige Syllabificatie en Stress Voorspelling', 'de': 'Zur Aussprache im Wiktionary: Extraktion und Experimente zur mehrsprachigen Syllabifizierung und Stressvorhersage', 'fa': 'در مورد تفصیلات در ویکتیورنی: اخراج و تجربه در مورد تفصیلات و استرس چندین زبان', 'ko': 'Wiktionary에서의 발음: 다중 음성 절화와 중음 예측의 추출과 실험', 'sw': 'Katika matangazo ya Wiktionary: Utoa na Majaribu kuhusu Kubunga kwa lugha nyingi na Utawala wa Kishinikizo', 'af': 'Op uitsprekkings in Wiktionary: Uitpakking en Eksperimente op Multilingual Syllabifikasie en Stres voorvloediging', 'tr': 'Wiktionaryda aýdymlar üzerinde: Çoklu dilli sözleşme we Güçlik Prezentasy', 'sq': 'Për shprehjet në Wiktionary: Ekstraksion dhe eksperimente mbi silabifikimin shumëgjuhës dhe parashikimin e stresit', 'id': 'Dalam Pronunciasi di Wiktionary: Ekstraksi dan Eksperimen di Multilingual Syllabification dan Prediction Stress', 'bn': 'উইক্টশনারিতে প্রজোনেশন: বহুভাষী সিল্যাবিবিউশন এবং চাপের পছন্দের বিরুদ্ধে বহির্বিচার এবং পরীক্ষা', 'az': "Wiktionary'da danışmalar haqqında: çoxlu dil sözləri və qüvvət təsiri barəsindəki təcrübələr", 'bs': 'O izjavama u Wiktionaryju: izvlačenje i iskustva o multijezičkoj silabifikaciji i predviđanju stresa', 'cs': 'O výslovnostech ve viktionáři: extrakce a experimenty na vícejazyčné sylabifikaci a predikci stresu', 'et': 'Wiktsõnaraamatu häälduste kohta: väljavõte ja eksperimendid mitmekeelse sõnastuse ja stressi prognoosimise kohta', 'am': 'በWiktionary: Extraction and Experiments on Multilingual Syllabification and Stress Prediction', 'fi': 'Wiktionaryn ääntämisistä: Extraktio ja kokeet monikielisestä sanamuodosta ja stressin ennustamisesta', 'ca': "En les pronunciacions en wiktionari: Extracció i experiments sobre sílabificació multilingüe i predicció d'estrès", 'hy': 'Վիքցիոնարում արտահայտությունների մասին. Բազլեզու խմբավորումների և սթրեսի կանխատեսման վերաբերյալ արտահայտությունները', 'jv': 'Ngubah Ngucap Wiksiyony', 'he': 'על הצהרות בוויקציונרי: מחלץ וניסויים על שיטה רבה-שפותית ומחזית לחץ', 'ha': 'KCharselect unicode block name', 'sk': 'O izgovorih v viktionarju: ekstrakcija in eksperimenti o večjezičnem prevzemanju in napovedovanju stresa', 'bo': "Wiktionary's ནང་གི་གསལ་བཤད་ཀྱི་སྐད་སྙན་ཚུ། སྒྲ་ཚིགས་རྩིས་བ་དང་སྒྲ་ཚིགས་ཀྱི་སྒེར་གྱི་གཏོང་།"}
{'en': 'We constructed parsers for five non-English editions of Wiktionary, which combined with pronunciations from the English edition, comprises over 5.3 million IPA pronunciations, the largest pronunciation lexicon of its kind. This dataset is a unique comparable corpus of IPA pronunciations annotated from multiple sources. We analyze the dataset, noting the presence of machine-generated pronunciations. We develop a novel visualization method to quantify syllabification. We experiment on the new combined task of multilingual IPA syllabification and stress prediction, finding that training a massively multilingual neural sequence-to-sequence model with copy attention can improve performance on both high- and low-resource languages, and multi-task training on stress prediction helps with syllabification.', 'ar': 'قمنا ببناء موزعي لخمسة إصدارات غير إنجليزية من ويكاموس ، والتي تضم أكثر من 5.3 مليون نطق من الطبعة الإنجليزية ، وهي أكبر معجم نطق من نوعه. مجموعة البيانات هذه عبارة عن مجموعة فريدة قابلة للمقارنة من كلمات IPA المنطوقة المشروحة من مصادر متعددة. نقوم بتحليل مجموعة البيانات ، مع ملاحظة وجود النطق الناتج عن الآلة. نقوم بتطوير طريقة تصور جديدة لتقدير التقسيم. نجرب على المهمة المشتركة الجديدة المتمثلة في تقسيم IPA متعدد اللغات والتنبؤ بالإجهاد ، ووجدنا أن تدريب نموذج تسلسل عصبي متعدد اللغات على نطاق واسع مع الانتباه إلى النسخ يمكن أن يحسن الأداء في كل من اللغات عالية ومنخفضة الموارد ، والتدريب متعدد المهام على يساعد التنبؤ بالإجهاد في التقسيم اللفظي.', 'fr': "Nous avons construit des analyseurs pour cinq éditions non anglaises du Wiktionnaire, qui, combinées aux prononciations de l'édition anglaise, comprennent plus de 5,3 millions de prononciations IPA, le plus grand lexique de prononciation de ce type. Cet ensemble de données est un corpus unique et comparable de prononciations IPA annotées à partir de sources multiples. Nous analysons l'ensemble de données en notant la présence de prononciations générées par machine. Nous développons une nouvelle méthode de visualisation pour quantifier la syllabification. Nous expérimentons la nouvelle tâche combinée de syllabification IPA multilingue et de prédiction du stress, en découvrant que l'entraînement d'un modèle neuronal séquence-séquence à séquence massivement multilingue avec attention à la copie peut améliorer les performances dans les langues à ressources élevées et faibles, et une formation multitâche sur la prédiction du stress aide à la syllabification.", 'es': 'Construimos analizadores para cinco ediciones de Wikcionario que no están en inglés, que combinadas con las pronunciaciones de la edición en inglés, comprenden más de 5.3 millones de pronunciaciones AFI, el léxico de pronunciación más grande de su tipo. Este conjunto de datos es un corpus único comparable de pronunciaciones AFI anotadas de múltiples fuentes. Analizamos el conjunto de datos, observando la presencia de pronunciaciones generadas por máquinas. Desarrollamos un novedoso método de visualización para cuantificar la silabificación. Experimentamos en la nueva tarea combinada de silabificación IPA multilingüe y predicción de estrés, descubriendo que el entrenamiento de un modelo neuronal de secuencia a secuencia masivamente multilingüe con atención de copia puede mejorar el rendimiento en idiomas de recursos altos y bajos, y el entrenamiento multitarea en la predicción del estrés ayuda con la silabificación.', 'pt': 'Construímos analisadores para cinco edições não inglesas do Wikcionário, que, combinadas com as pronúncias da edição em inglês, abrangem mais de 5,3 milhões de pronúncias IPA, o maior léxico de pronúncia desse tipo. Este conjunto de dados é um corpus comparável exclusivo de pronúncias IPA anotadas de várias fontes. Analisamos o conjunto de dados, observando a presença de pronúncias geradas por máquina. Desenvolvemos um novo método de visualização para quantificar a silabificação. Nós experimentamos a nova tarefa combinada de silabificação IPA multilíngue e previsão de estresse, descobrindo que treinar um modelo de sequência a sequência neural multilíngue com atenção à cópia pode melhorar o desempenho em idiomas de alto e baixo recurso e treinamento multitarefa em a previsão de estresse ajuda com a silabificação.', 'ja': '5つの非英語版Wiktionaryの構文解析器を構築しました。英語版からの発音と組み合わせると、530万以上のIPA発音を含み、この種の最大の発音辞書です。このデータセットは、複数のソースから注釈されたIPA発音のユニークな同等のコーパスです。私たちは、機械で生成された発音の存在に留意して、データセットを分析します。音節化を定量化するための新規の視覚化方法を開発しました。私たちは、多言語IPAシラバライゼーションとストレス予測の新しい複合タスクを実験し、コピーに注意を払った大規模な多言語ニューラルシーケンスツーシーケンスモデルのトレーニングは、高リソース言語と低リソース言語の両方でパフォーマンスを向上させることができ、ストレス予測のマルチタスクトレーニングはシラバライゼーションに役立つことを発見しました。', 'zh': '吾为五非英语者维基词典为解析器,解析器与英语音合,过于530万个IPA,此其大发音词典也。 此数集从多所注 IPA 音之特比语料库。 论数集,机器生音存焉。 开一新可视化以量化音化。 试多言IPA音节新组,见复制意者大言神经序高资低资源言,多任务节化。', 'ru': 'Мы построили парсеры для пяти неанглоязычных изданий Wiktionary, которые в сочетании с произношениями из английского издания содержат более 5,3 миллиона произношений IPA, крупнейший в своем роде лексикон произношения. Этот набор данных представляет собой уникальный сопоставимый корпус произношений IPA, аннотированных из нескольких источников. Мы анализируем набор данных, отмечая наличие машинных произношений. Мы разрабатываем новый метод визуализации для количественной оценки словаризации. Мы экспериментируем над новой комбинированной задачей многоязычного слогабирования и прогнозирования стресса IPA, обнаружив, что обучение массивной многоязычной нейронной модели последовательности с вниманием к копированию может улучшить производительность как на языках с высоким, так и низким уровнем ресурсов, а многозадачное обучение прогнозированию стресса помогает в слогабировании.', 'hi': 'हमने विक्षनरी के पांच गैर-अंग्रेजी संस्करणों के लिए पार्सर का निर्माण किया, जो अंग्रेजी संस्करण के उच्चारण के साथ संयुक्त है, जिसमें 5.3 मिलियन से अधिक आईपीए उच्चारण शामिल हैं, जो अपनी तरह का सबसे बड़ा उच्चारण शब्दकोश है। यह डेटासेट कई स्रोतों से एनोटेट किए गए आईपीए उच्चारणों का एक अद्वितीय तुलनीय कॉर्पस है। हम डेटासेट का विश्लेषण करते हैं, मशीन-जनित उच्चारण की उपस्थिति को ध्यान में रखते हुए। हम syllabification को मापने के लिए एक उपन्यास विज़ुअलाइज़ेशन विधि विकसित करते हैं। हम बहुभाषी आईपीए सिलेबेशन और तनाव भविष्यवाणी के नए संयुक्त कार्य पर प्रयोग करते हैं, यह पाते हुए कि कॉपी ध्यान के साथ बड़े पैमाने पर बहुभाषी तंत्रिका अनुक्रम-से-अनुक्रम मॉडल को प्रशिक्षित करने से उच्च और निम्न-संसाधन दोनों भाषाओं पर प्रदर्शन में सुधार हो सकता है, और तनाव की भविष्यवाणी पर बहु-कार्य प्रशिक्षण सिलेबिंग के साथ मदद करता है।', 'ga': 'Rinneamar parsálaithe do chúig eagrán neamhBhéarla de Vicífhoclóir, a chuimsigh breis agus 5.3 milliún fuaimniú ón IPA, an foclóir foghraíochta is mó dá chineál, in éineacht le fuaimniú an Bhéarla. Is corpas uathúil inchomparáide é an tacar sonraí seo d’fhuaimeanna an Fhorais Riaracháin atá anótáilte ó fhoinsí iolracha. Déanaimid anailís ar an tacar sonraí, ag tabhairt faoi deara láithreacht fuaimniú meaisín-ghinte. Forbraímid modh léirshamhlaithe nua chun an siollabas a chainníochtú. Déanaimid tástáil ar an tasc nua comhcheangailte de shiollabais ilteangach IPA agus tuar struis, ag fáil amach gur féidir le hoiliúint a chur ar shamhail sheicheamh-go-seicheamh néarúil atá thar a bheith ilteangach le haird ar chóip feabhas a chur ar fheidhmíocht ar theangacha ard-acmhainne agus íseal-acmhainne, agus oiliúint ilthasc ar. cabhraíonn tuar struis leis an siollabas.', 'ka': 'ჩვენ ვიკუთონის ხუთ არ ანგლისური რედაქტირებისთვის პარასერების შექმნა, რომლებიც ანგლისური რედაქტირებისთვის გამოყენებულია, რომლებიც 5.3 მილიონის IPA-ს გამოყენება, რაც უფრო დიდი გამოყენ ეს მონაცემების საქაღალდე უნიკალური შემდგომარებელი კორპუსია, რომელიც უფრო რამდენიმე მსოფლიოდან აღწერა. ჩვენ მონაცემების კონტაქტის ანალიზაცია, მაქინის შექმნილი გამოსახულებების მისახედვით. ჩვენ პრომენტური ვიზუალიზაციის მეტი განვითარებთ სილაბიზაციის კვანტიფიკაციისთვის. ჩვენ ექსპერიმენტებით მრავალური IPA სილაბიფიკაციის და სტრესის წარმოდგენების ახალი კომბიუნური დავაკეთება, რომელიც აღმოვაჩინეთ, რომ მასტივიური მრავალური ნეიროლური წარმოდგენების მოდელს, რომელიც კომბიფიკაციის შესაძლებელია გაუფეთ', 'hu': 'A Wiktionary öt nem angol nyelvű kiadásához készítettünk elemzőket, amelyek az angol nyelvű kiejtésekkel kombinálva több mint 5,3 millió IPA kiejtést tartalmaznak, ami a legnagyobb kiejtési lexikon a maga nemében. Ez az adatkészlet egyedülálló, összehasonlítható IPA kiejtésekből áll, amelyeket több forrásból hirdettek meg. Elemezzük az adatkészletet, figyelembe véve a gép által generált kiejtések jelenlétét. Új vizualizációs módszert dolgozunk ki a szótagosítás számszerűsítésére. Kísérletezünk a többnyelvű IPA szótagosítás és stressz-előrejelzés új kombinált feladataival, megállapítva, hogy egy masszívan többnyelvű neurális szekvencia-szekvencia modell másolási figyelemmel történő kiképzése javíthatja a teljesítményt mind a nagy, mind az alacsony erőforrású nyelveken, a stressz-előrejelzés többfeladatos képzése pedig segít a szótagosításban.', 'el': 'Κατασκευάσαμε αναλυτές για πέντε μη αγγλικές εκδόσεις του το οποίο σε συνδυασμό με τις προφορές από την αγγλική έκδοση περιλαμβάνει πάνω από 5,3 εκατομμύρια προφορές IPA, το μεγαλύτερο λεξικό προφοράς του είδους του. Αυτό το σύνολο δεδομένων είναι ένα μοναδικό συγκρίσιμο σώμα προφορών IPA που ανακοινώνονται από πολλές πηγές. Αναλύουμε το σύνολο δεδομένων, σημειώνοντας την παρουσία προφορών που δημιουργούνται από μηχανές. Αναπτύσσουμε μια νέα μέθοδο απεικόνισης για τον ποσοτικό προσδιορισμό της συλλαβητικότητας. Πειραματιζόμαστε στο νέο συνδυασμένο έργο της πολύγλωσσης συλλαβητικής και πρόβλεψης στρες, διαπιστώνοντας ότι η εκπαίδευση ενός μαζικά πολύγλωσσου μοντέλου νευρωνικής αλληλουχίας με προσοχή αντιγράφων μπορεί να βελτιώσει την απόδοση τόσο σε γλώσσες υψηλής όσο και χαμηλής περιεκτικότητας, και η εκπαίδευση πολλαπλών εργασιών για την πρόβλεψη στρες βοηθά στην συλλαβοποίηση.', 'mk': 'Конструиравме анализатори за пет неанглиски изданија на Викционари, кои се комбинирани со изјаснувања од англиското издание, вклучуваат над 5,3 милиони изјаснувања на ИПА, најголемиот лексикон од ваков вид. Овој груп податоци е уникатен споредлив корпус на изрази на ИПА анотирани од повеќе извори. We analyze the dataset, noting the presence of machine-generated pronunciations.  Развиваме нов метод на визуелизација за квантификување на силабификацијата. Експериментираме на новата комбинирана задача на мултијазичката силабификација на ИПА и предвидувањето на стресот, откривајќи дека обуката на масовен мултијазичен модел од нервна секвенца до секвенца со кописко внимание може да ја подобри резултатот на јазиците со високи и ниски ресурси, и мултијазичката обука на', 'lt': 'Mes sukūrėme analizatorius penkioms ne angliškoms Wiktionary redakcijoms, kurios kartu su angliškos redakcijos išraiškais sudaro daugiau kaip 5,3 mln. IPA išraiškų, didžiausias tokios rūšies išraiškos leksikonas. Šis duomenų rinkinys yra unikalus palyginamas IPA pareiškimų rinkinys, užrašytas iš kelių šaltinių. Analizuojame duomenų rinkinį, atkreipiant dėmesį į mašinų sukeltų išraiškų buvimą. Mes sukuriame naują vizualizavimo metodą, kad kiekybiškai įvertintume silabifikaciją. Eksperimentuojame naują kombinuotą daugiakalbio IPA silabifikavimo ir streso prognozavimo užduotį, nustatydami, kad mokymas masiškai daugiakalbio modelio iš eilės į eilę, atkreipiant dėmesį į kopijas, gali pagerinti rezultatus tiek aukšto lygio, tiek mažo išteklio kalbomis, o daugiakalbio mokymas streso prognozavimo srityje padeda silabifikavimui.', 'it': "Abbiamo costruito parser per cinque edizioni non inglesi di Wiktionary, che combinate con le pronunce dell'edizione inglese, comprende oltre 5,3 milioni di pronunce IPA, il più grande lessico di pronuncia del suo genere. Questo set di dati è un corpus comparabile unico di pronunce IPA annunciate da più fonti. Analizziamo il dataset, notando la presenza di pronunce generate dalla macchina. Sviluppiamo un nuovo metodo di visualizzazione per quantificare la sillabazione. Sperimentiamo il nuovo compito combinato di sillabazione IPA multilingue e previsione dello stress, scoprendo che l'addestramento di un modello neurale sequenziale-sequenziale massivamente multilingue con attenzione alla copia può migliorare le prestazioni sui linguaggi ad alta e bassa risorsa, e la formazione multi-task sulla previsione dello stress aiuta con la sillabazione.", 'kk': 'Біз бес ағылшын емес Wiktionary редакциясының талдаушыларын құрдық. Бұл ағылшын редакциясынан біріктірілген, 5,3 миллион IPA сөйлемелері, оның ең үлкен сөйлемелері. Бұл деректер жинағы - бірнеше көзінен белгіленген IPA жазбаларының бірнеше салыстырмалы корпус. Біз деректер қорларын анализ, машинаның құрылған сөйлемелердің барлығын көріп тұрмыз. Біз силабификациялау үшін романдық визуализациялау әдісін жасаймыз. Біз көп тілді IPA силабификациясын және стресс бақылау үшін жаңа біріктірілген тапсырманы тәжірибелеміз, көшірмелеу үлгісін көшірмелеу үлгісін көшірмелеу үлгісі көшірмелеу үлгісін көшірмелеу үлгісін көшірмелеу үлгісін көшірмелеу үлгі', 'ms': 'Kami membangun maklumat untuk lima edisi Wiktionary yang bukan bahasa Inggeris, yang bergabung dengan ungkapan dari edisi Inggeris, mengandungi lebih dari 5.3 juta ungkapan IPA, leksikon ungkapan terbesar jenisnya. Set data ini adalah korpus unik yang boleh dibandingkan bagi ungkapan IPA yang dicatat dari sumber berbilang. Kami menganalisis set data, memperhatikan kehadiran perkataan yang dijana oleh mesin. Kami mengembangkan kaedah visualisasi baru untuk kuantifikasikan syllabification. Kami eksperimen pada tugas kombinasi baru dari silabifikasi IPA berbilang bahasa dan prediksi tekanan, mencari bahawa latihan model saraf berbilang bahasa yang besar-besaran berturut-turut dengan perhatian salinan boleh meningkatkan prestasi dalam bahasa-bahasa tinggi dan rendah-sumber, dan latihan berbilang tugas pada prediksi tekanan membantu dengan silabifikasi.', 'mt': "Inbnejna parsers għal ħames edizzjonijiet mhux Ingliżi ta' Wiktionary, li flimkien ma' pronunzjonijiet mill-edizzjoni Ingliża, jinkludu aktar minn 5.3 miljun pronunzja IPA, l-ikbar lexicon ta' pronunzja tat-tip tagħha. Dan is-sett ta’ dejta huwa korpus uniku komparabbli ta’ dikjarazzjonijiet tal-IPA annotati minn diversi sorsi. We analyze the dataset, noting the presence of machine-generated pronunciations.  Aħna niżviluppaw metodu ġdid ta' viżwalizzazzjoni biex nikkwantifikaw is-sillabifikazzjoni. Aħna ninsperimentaw fuq il-kompitu kombinat il-ġdid tas-sillabifikazzjoni multilingwi tal-IPA u t-tbassir tal-istress, u nsibu li t-taħriġ ta’ mudell multilingwi ta’ sekwenza għal sekwenza newrali b’attenzjoni ta’ kopja jista’ jtejjeb il-prestazzjoni kemm fil-lingwi b’riżorsi għoljin kif ukoll baxxi, u taħriġ multilingwi dwar it-tbassir tal-istress jgħin fis-sillabifikazzjoni.", 'mn': 'Бид Англи хэлний таван биш Англи хэвлэлийн хувилбаруудыг зохион байгуулсан. Англи хэвлэлийн хэвлэлээс хамтдаа илүү олон 5.3 сая IPA хэлэлцүүлэгүүд байдаг. Энэ өгөгдлийн сангууд нь олон эх үүсвэрээс илэрхийлэгдсэн IPA-ын харьцуулагдмал корпус юм. Бид өгөгдлийн хэлбэрийг шинжилгээд машины гаргасан хэлбэрүүдийг анзаарсан. Бид илэрхийллийг тооцоолохын тулд шинэ үзүүлэлтийн аргыг хөгжүүлнэ. Бид олон хэлний IPA илэрхийлэл болон стресс тодорхойлолтын шинэ даалгаварын тухай туршилт хийж байгаа. Мөн олон хэлний мэдрэлийн дарааллаас анхаарлын төвлөрүүлэлт нь өндөр болон бага боломжтой хэл дээр ажиллагааг сайжруулж чадна.', 'ml': 'ഞങ്ങള്\u200d വിക്ട്ടണ്ടറിയിലെ അഞ്ച് ഇംഗ്ലീഷില്ലാത്ത എഴുത്തുകള്\u200dക്ക് പാര്\u200dസറുകള്\u200d നിര്\u200dമ്മിച്ചു. അത് ഇംഗ്ലീഷ് എഡിഷനില്\u200d നിന്നും ഒരുമിച്ചിരിക്കുന്ന ഈ ഡാറ്റാസസെറ്റ് പല ഉറവിടങ്ങളില്\u200d നിന്നും വിവരിച്ചിരിക്കുന്ന IPA പ്രഖ്യാപങ്ങളുടെ ഒരു വ്യത്യസ്തമായ കോര്\u200dപ്പ നമ്മള്\u200d ഡാറ്റാസെറ്റിനെ അന്വേഷിക്കുന്നു, യന്ത്രത്തില്\u200d ഉണ്ടാക്കിയ പ്രസംഗികളുടെ സ്ഥിതിയെ കാണുന നമ്മള്\u200d ഒരു നോവല്\u200d കാഴ്ചപ്പെടുത്തുന്ന രീതിയില്\u200d നിര്\u200dമ്മിക്കുന്നു. പല ഭാഷകങ്ങളുടെയും ഐപിയുടെയും സ്ട്രെസ്സിന്റെയും പ്രവചനങ്ങളുടെയും പുതിയ ബന്ധപ്പെട്ട ജോലിയില്\u200d ഞങ്ങള്\u200d പരീക്ഷിക്കുന്നു. ഒരു വലിയ മണ്ണില്\u200d ന്യൂറല്\u200d സെക്കന്\u200dസ് മോഡല്\u200d പരിശീലിപ്പിക്കുന്നത് പകര്\u200dപ്', 'pl': 'Zbudowaliśmy parsery dla pięciu nieangielskich edycji Wiktionary, które w połączeniu z wymowami z edycji angielskiej składają się z ponad 5,3 milionów wymow IPA, największego tego rodzaju leksykonu wymowy. Ten zbiór danych jest unikalnym porównywalnym korpusem wypowiedzi IPA ogłaszanych z wielu źródeł. Analizujemy zbiór danych, zauważając obecność wypowiedzi generowanych maszynowo. Opracowujemy nową metodę wizualizacji do ilościowego określenia sylabifikacji. Eksperymentujemy nad nowym połączonym zadaniem wielojęzycznej sylabifikacji IPA i przewidywania stresu, stwierdzając, że trening masowo wielojęzycznego modelu sekwencji neuronowej z uwagą na kopiowanie może poprawić wydajność zarówno w językach o wysokich jak i niskich zasobach, a wielozadaniowe szkolenia z zakresu przewidywania stresu pomaga w sylabifikacji.', 'ro': 'Am construit parsere pentru cinci ediții non-engleze ale Wiktionary, care combinate cu pronunțiile din ediția engleză, cuprinde peste 5,3 milioane de pronunții IPA, cel mai mare lexicon de pronunție de acest gen. Acest set de date este un corpus unic comparabil de pronunții IPA anunțate din mai multe surse. Analizăm setul de date, observând prezența pronunțiilor generate de mașină. Dezvoltăm o nouă metodă de vizualizare pentru a cuantifica programarea. Experimentăm pe noua sarcină combinată de programare IPA multilingvă și predicție a stresului, constatând că instruirea unui model neural secvență-la-secvență masiv multilingv cu atenție la copiere poate îmbunătăți performanța atât în limbile cu resurse mari, cât și reduse, iar instruirea multi-sarcini privind predicția stresului ajută la programare.', 'sr': 'Izgradili smo parsere za pet ne-engleskih redikcija Wiktionary-a, koja je kombinovana sa izgovorima iz Engleskog izdanja, sastoji od preko 5,3 miliona izjava IPA-a, najvećih izjava leksiona njegove vrste. Ova kompleta podataka je jedinstven usporedljiv korpus IPA proglašavanja iz višestrukih izvora. Analiziramo setu podataka, primećujući prisustvo proglašavanja iz mašine. Razvijamo novu vizualizaciju metodu da kvantificiramo silabifikaciju. Eksperimentiramo na novi kombinirani zadatak multijezičkih IPA silabifikacije i predviđanja stresa, otkrivajući da obuka masivnog multijezičkog neuralnog sekvenčnog model a sa kopijskom pažnjom može poboljšati učinkovitost na jezicima visokog i niskog resursa, i multi task obuku predviđanja stresa pomaže sa silabifikacijom.', 'no': 'Vi konstruerte tolkarar for fem ikkje-engelske redigeringar av Wiktionary, som kombinerte med uttaler frå engelsk utdataet, inneheld over 5,3 millioner IPA-uttaler, den største uttaleleksikonen av sitt type. Denne datasettet er ein unikt sammenlignbar korpus av IPA- uttaler som er merkt frå fleire kilder. Vi analyserer datasettet og merker på at det finst maskinelaga uttaler. Vi utviklar eit nytt visualiseringsmetode for kvantifikasjon av syllabifikasjon. Vi eksperimenterer på den nye kombinasjonen oppgåva av fleirspråk IPA-syllabifikasjon og stress-forhåndsvising, og finn at opplæring av ein massivt multispråk neuralsekvens-til-sekvens-modell med kopi-oppmerking kan forbetra utviklinga på både høg og låg ressursspråk, og fleiroppgåver-opplæring på stres-forhåndsvising hjelper med sylla', 'so': 'We constructed parsers for five non-English editions of Wiktionary, which combined with pronunciations from the English edition, comprises over 5.3 million IPA pronunciations, the largest pronunciation lexicon of its kind.  Taasinimadan waa qof u eg oo IPA ka mid ah naadiyooyin ay ka soo bandhigtay sourceo badan. Ana analyshannaa sawirada, waxaynu ogaysiinnaa joogitaanka muuqashada mashiinka. Waxaynu horumarinaa qaab muuqashada warqadda si aan u qiyaasno in la soo bandhigiso. Waxaynu tijaabinaynaa shaqada cusub ee IPA la isku darsameynayo oo kala duduwan, waxaynu ogaannahay in lagu tababarayo qaab aad u badan oo kala duduwan neurada kala duduwan oo aad u dhaqdhaqaaqi karo in uu hagaajiyo muuqashada aragtida nuurada oo aad u dhaqdhaqaaqi karo luuqadaha sare iyo hoos-resourceyaasha, waxbarashada shaqo badan oo ku saabsan tababarida stress-ka ayaa caawinaya in la sameeyo isbeddelaajiyo.', 'si': 'අපි ඉංග්\u200dරීසිය නොවෙන් ඉංග්\u200dරීසියානු සංපාදනය පහක් වෙනුවෙන් පරිස්තර කළා, ඒ වගේම ඉංග්\u200dරීසිය සංපාදනයෙන් සම්බන්ධ කරලා ඉං මේ තොරතුරු සම්බන්ධයක් තමයි IPA ප්\u200dරවේශනයේ විශේෂ සම්බන්ධයක් විතරයි. අපි දත්ත සෙට් විශ්ලේෂණය කරනවා, මැෂින් නිර්මාණය කරලා තියෙන්නේ කියලා. අපි ක්\u200dරියාත්මක විශ්වාස කරන්න අලුත් විද්\u200dයාත්මක විද්\u200dයාපයක් නිර්මාණය කරනවා. අපි අලුත් භාෂාවික IPA සිලාබිෆික්ෂණය සහ විශ්වාස කරපු අවස්ථාවයේ අළුත් සම්බන්ධ වැඩේ පරීක්ෂණය කරනවා, හොයාගන්නේ මැස්සිල් භාෂාවික විශ්වාස කරපු විශ්වාස ක', 'ta': 'நாங்கள் ஐந்து ஆங்கிலத்தில் இல்லாத திருத்தங்களுக்கு பார்சர்களை உருவாக்கி, அது ஆங்கிலம் தொகுப்பிலிருந்து வெளியீடுகளுடன் இணைந்து, 5.3 மில்லியன் IPA விள இந்த தகவல் அமைப்பு பல மூலங்களிலிருந்து அறிவிக்கப்பட்ட IPA பொருத்தமான குறியீடுகள் ஆகும். நாங்கள் தகவல் அமைப்பை ஆராய்வு செய்கிறோம், இயந்திரம் உருவாக்கப்பட்ட பொருள் இருப்பதை குறித்து. நாம் ஒரு புதிய பார்வைப்பு முறைமையை உருவாக்குகிறோம். பல மொழி IPA தொகுப்பு மற்றும் stress முற்படுத்தலின் புதிய செயல்பாட்டில் நாம் பரிசோதிக்கிறோம், இது கண்டுபிடித்து கொண்டு ஒரு மிக்க பல மொழி புதிய நெருக்கல் தொடர்ச்சி மாதிரி மாதிரி மாதிரியை நகல்', 'sv': 'Vi konstruerade parsers för fem icke-engelska utgåvor av Wiktionary, som tillsammans med uttalen från den engelska utgåvan, omfattar över 5,3 miljoner IPA-uttal, det största uttalslexikonet i sitt slag. Datauppsättningen är en unik jämförbar korpus av IPA-uttalanden som annonseras från flera källor. Vi analyserar datauppsättningen och noterar förekomsten av maskingenererade uttalanden. Vi utvecklar en ny visualiseringsmetod för att kvantifiera kursifiering. Vi experimenterar på den nya kombinerade uppgiften med flerspråkig IPA-kursifiering och stressprediktion, och finner att träning av en massivt flerspråkig neural sekvens-till-sekvensmodell med copy-uppmärksamhet kan förbättra prestanda på både hög- och lågresursspråk, och multi-task träning om stressprediktion hjälper till med kursifiering.', 'ur': 'ہم نے ویکتیورنی کی پانچ غیر انگلیسی ایڈیزونیوں کے لئے پارس بنائے، جو انگلیسی ایڈیزونیوں سے آپس میں آپس میں 5.3 میلیون IPA کی تعریف ہے، اس کی سب سے بڑی تعریف لکھی لکھی ہے۔ یہ ڈاٹ سٹ ایک ایسا مقایسہ کورپوس ہے جو IPA کی تعلیمات متعدد سورجوں سے آگاہ کی گئی ہے. ہم ڈاٹ سٹ کو تحقیق کرتے ہیں، ماشین کے پیدا کئے ہوئے تعلیمات کی موجودگی دیکھتے ہیں۔ ہم ایک نوی تصویزی طریقہ ایجاد کریں گے کہ اسلابیفٹ کی تعداد کریں۔ ہم multilingual IPA syllabification and stress prediction کے نو ترکیب کے کام پر آزمائش کرتے ہیں، اور یہ دیکھتے ہیں کہ ایک بہت زیادہ multilingual neural sequence-to-sequence موڈل کی تعلیم کرتی ہے جو کاپی کی توجه کے ساتھ کاپی کی توجه کے ساتھ بہت زیادہ اور کم-resource زبانوں پر عمل کی تدبیر کرتی ہے، اور استرس کی پیش بینی پر بہت سی ترکیب کی تدبیر کی', 'vi': 'Chúng tôi xây dựng phân tích cho năm bản không tiếng Anh của "xử pháp sư Pháp", kết hợp với phát âm từ ấn bản Anh, gồm hơn một triệu phát âm IPA, phát âm cao nhất theo kiểu đó. Đây là tập tin dữ liệu có thể so sánh tuyệt đối với phát âm IPA được ghi chú từ nhiều nguồn khác nhau. Chúng tôi phân tích dữ liệu, ghi chú các phát âm máy tạo ra. Chúng tôi phát triển một phương pháp mường tượng mới để xác định âm tiết. Chúng tôi thử nghiệm một công việc kết hợp lại của đã có thể giải quyết hết hệ thống học họp dưới đái họp mục họp, và thấy được rằng tập luyện tập luyện để dự stress giút trình cho âm học.', 'uz': "Biz Viktionary 5 notoʻgʻri ingliz tahrirlarining qismlari uchun parserlarini yaratdik. Bu ingliz tahrirlaridan bir necha 5.3 million IPA ta'minlovchilarga ega bo'lgan edi. @ info We analyze the dataset, noting the presence of machine-generated pronunciations.  Biz tashkilotni aniqlash uchun novel ko'rinish usulini yaratumiz. Biz bir necha tillar IPA bilan birlashtirish va boshqarish vazifani tajriba qilamiz, o'sha paytda, ko'p tillar tarkibi neyron cheksizlik modelini o'rganish mumkin. Nusxa olish modeli bilan bir necha necha neyron tartibi bilan bir necha darajada ishlatish imkoniyatini oshirish mumkin, va bir necha narsalar tilida bir necha vazifa o'rganishni o'rganish imkoniyatlarini ba", 'nl': 'We bouwden parsers voor vijf niet-Engelse edities van Wiktionary, die in combinatie met uitspraken uit de Engelse editie meer dan 5,3 miljoen IPA uitspraken bevatten, het grootste uitspraaklexicon in zijn soort. Deze dataset is een uniek vergelijkbaar corpus van IPA uitspraken uit meerdere bronnen. We analyseren de dataset en merken de aanwezigheid van machinegegenereerde uitspraken op. We ontwikkelen een nieuwe visualisatiemethode om sylabificatie te kwantificeren. We experimenteren met de nieuwe gecombineerde taak van meertalige IPA sylabificatie en stressvoorspelling, waarbij we vaststellen dat het trainen van een massaal meertalig neuraal sequence-to-sequence model met copy aandacht de prestaties kan verbeteren in zowel high- als low-resource talen, en multitask training over stress voorspelling helpt bij sylabificatie.', 'bg': 'Създадохме парсори за пет неанглийски издания на Уикиречника, който в комбинация с произношенията от английското издание съдържа над 5,3 милиона произношения по ИПА, най-големият речник по рода си. Този набор от данни е уникален сравним корпус от произношения, обявени от множество източници. Анализираме набора от данни, отбелязвайки наличието на машинно генерирани произношения. Разработваме нов метод за визуализация за количествено определяне на сричките. Експериментираме върху новата комбинирана задача за многоезично усвояване и прогнозиране на стреса, като откриваме, че обучението на масово многоезичен невронен модел последователност към последователност с внимание на копирането може да подобри производителността както на езици с висок, така и с нисък ресурс, а многозадачичното обучение за прогнозиране на стреса помага при усвояването на стреса.', 'da': 'Vi konstruerede fortolkere til fem ikke-engelske udgaver af Wiktionary, som kombineret med udtalelser fra den engelske udgave, omfatter over 5,3 millioner IPA udtalelser, det største udtaleleksikon af sin art. Dette datasæt er et unikt sammenligneligt korpus af IPA-udtalelser annonceret fra flere kilder. Vi analyserer datasættet og noterer tilstedeværelsen af maskingenererede udtalelser. Vi udvikler en ny visualiseringsmetode til at kvantificere pensifikation. Vi eksperimenterer med den nye kombinerede opgave med flersproget IPA-pensifikation og stress forudsigelse, idet vi finder ud af, at træning af en massivt flersproget neural sekvens-til-sekvens model med copy-opmærksomhed kan forbedre ydeevnen på både høj- og lav ressource sprog, og multi-opgave træning om stress forudsigelse hjælper med pensifikation.', 'hr': 'Napravili smo parsere za pet ne-engleskih redakcija Wiktionary-a, koja je kombinirana s izjavama iz Engleskog izdanja, sastoji od preko 5,3 milijuna izjava IPA-a, najveće izjave leksiona njegove vrste. Ova kompleta podataka je jedinstven usporedljiv korpus proglašavanja IPA iz višestrukih izvora. Analiziramo sastavu podataka, primjećujući prisustvo izrađenih izraza stroja. Razvijamo novu metodu vizualizacije kako bi kvantificirali silabifikaciju. Eksperimentiramo na novi kombinirani zadatak multijezičke silabifikacije i predviđanja stresa IPA-a, otkrivajući da obuka masivnog multijezičkog neuralnog sekvenčnog modela s kopijom pažnje može poboljšati učinkovitost na jezicima visokih i niskih resursa, te multizadatačna obuka za predviđanje stresa pomaže silabifikaciji.', 'de': 'Wir haben Parser für fünf nicht-englische Ausgaben von Wiktionary erstellt, die zusammen mit den Aussprachen aus der englischen Ausgabe über 5,3 Millionen IPA-Aussprachen umfassen, das größte Aussprache-Lexikon seiner Art. Dieser Datensatz ist ein einzigartiger vergleichbarer Korpus von IPA-Pronunciationen, der aus mehreren Quellen annotiert wurde. Wir analysieren den Datensatz und stellen fest, dass maschinell generierte Aussprachen vorhanden sind. Wir entwickeln eine neuartige Visualisierungsmethode zur Quantifizierung der Silbenbildung. Wir experimentieren mit der neuen kombinierten Aufgabe der mehrsprachigen IPA-Syllabifizierung und der Stressvorhersage und stellen fest, dass das Training eines massiv mehrsprachigen neuronalen Sequenz-zu-Sequenz-Modells mit Kopieraufmerksamkeit die Leistung sowohl in hoch- als auch ressourcenarmen Sprachen verbessern kann, und Multi-Task-Training zur Stressvorhersage hilft bei der Syllabifizierung.', 'fa': 'ما برای پنج تغییر انگلیسی غیر انگلیسی ویکتیونی ساختیم که با تغییرات از تغییر انگلیسی متحد شده است، بیش از ۵.۳ میلیون تغییرات IPA، بزرگترین تغییرات زبان نوع آن است. این مجموعه داده\u200cها یک مجموعه مقایسه\u200cکننده\u200cای متفاوت از گزارش\u200cهای IPA است که از منبع\u200cهای متعدد نشان داده شده است. ما مجموعه داده ها را تحلیل می کنیم، با توجه به موقعیت سخنرانی از دستگاه تولید می کنیم. ما یک روش تصویر جدید برای تعداد تعداد کلمات را توسعه می\u200cکنیم. ما روی کار جدید ترکیب کردن کلابی\u200cسازی و پیش\u200cبینی استرس IPA چندین زبان آزمایش می\u200cکنیم، و پیدا می\u200cکنیم که آموزش یک مدل کلی ترکیب عصبی\u200cسازی با توجه به کپی می\u200cتواند فعالیت\u200cسازی در زبان\u200cهای بالا و کم منبع\u200cسازی را بهتر کند، و آموزش چندین کار در پیش\u200cبینی\u200cسازی استرس', 'id': 'Kami membangun parser untuk lima edisi Wiktionary yang bukan bahasa Inggris, yang bergabung dengan pronunciasi dari edisi Inggris, mengandung lebih dari 5,3 juta pronunciasi IPA, leksikon pronunciasi terbesar semacam itu. Set data ini merupakan korpus unik yang bisa dibandingkan dari ungkapan IPA yang dicatat dari berbagai sumber. Kami menganalisis dataset, memperhatikan kehadiran pernyataan yang dibuat oleh mesin. Kami mengembangkan metode visualisasi baru untuk mengurangi silabifikasi. Kami eksperimen pada tugas kombinasi baru dari silabifikasi IPA berbagai bahasa dan prediksi stres, menemukan bahwa pelatihan model saraf berbagai bahasa besar-besaran dengan perhatian salinan dapat meningkatkan prestasi pada bahasa-bahasa yang tinggi dan rendah sumber daya, dan pelatihan multi-tugas pada prediksi stres membantu dengan silabifikasi.', 'sw': 'Tumejenga bunge kwa ajili ya toleo tano lisilo la Kiingereza la Wiktionary, ambalo liliunganisha watangazaji kutoka kwenye toleo la Kiingereza, linajumuisha matangazo ya IPA milioni 5.3, lengo kubwa la matangazo ya aina yake. Kitengo hiki cha taarifa ni chombo cha kipekee kinachofanana na matangazo ya IPA yaliyochapishwa na vyanzo vingi. We analyze the dataset, noting the presence of machine-generated pronunciations.  Tunaendelea njia ya kuonyesha riwaya ya kuhakikisha utaratibu. Tunajaribu kazi mpya ya mchanganyiko wa utangazaji wa IPA kwa lugha mbalimbali na utabiri wa msisitizo, tunagundua kuwa mafunzo ya mtindo wa mfululizo wa neura wa lugha mbalimbali unaweza kuongeza ufanisi wa ufanisi katika lugha za juu na rasilimali za chini, na mafunzo ya kazi mbalimbali katika kutabiri ya msisitizo unasaidia kuingia.', 'ko': '우리는 다섯 개의 비영어 버전의 Wiktionary를 위해 해석기를 구축했고 영어 버전의 발음과 결합하여 530여만 개의 IPA 발음을 포함하는데 이것은 동종 중 가장 큰 발음 사전이다.이 데이터 집합은 여러 개의 출처에서 온 IPA 발음 주석을 포함하는 독특한 비교 가능한 자료 라이브러리이다.우리는 데이터 집합을 분석하여 기계가 생성하는 발음의 존재를 알아차렸다.우리는 새로운 시각화 방법을 개발하여 음절화를 계량화하였다.우리는 다중 언어 IPA 음절화와 압력 예측의 새로운 조합 임무에서 실험을 실시한 결과 대량의 다중 언어 신경 서열을 서열 모델에 훈련시키고 복제 주의를 가지면 고자원과 저자원 언어의 성능을 향상시킬 수 있으며 압력 예측의 다중 임무 훈련은 음절화에 도움이 된다는 것을 발견했다.', 'am': 'We constructed parsers for five non-English editions of Wiktionary, which combined with pronunciations from the English edition, comprises over 5.3 million IPA pronunciations, the largest pronunciation lexicon of its kind.  ይህ የዳታ ሰርቨሮች ከብዙ ምንጮች የተመሳሳይ የIPA አካባቢዎች አካባቢ ነው፡፡ የዳታ ሳጥን እናስተምረዋለን የመኪን አወራጅ ሲሆን እናሳውቃለን፡፡ የአሁኑን አቀማመጥ እናሳውቃለን፡፡ ብዙ ቋንቋዎች የIPA መፍጠር እና የድምፅ ውይይት ለመፍጠር አዲስ የተጠቃሚ ስራ ላይ እናደርጋለን፡፡', 'af': "Ons het verwerkers gebou vir vyf nie-Engelse redigeerings van Wiktionary, wat saamgekombineer met uitsprekkings van die Engelse uitdrukking, bevat oor 5.3 miljoen IPA uitsprekkings, die grootste uitsprekking lexikon van sy soort. Hierdie datastel is 'n unieke vergelykbare korpus van IPA uitdrukkings wat van veelvuldige bronne aangekies word. Ons analyseer die datastel, aanmerk die aangesigheid van masjien genereerde uitdrukkings. Ons ontwikkel 'n nuwe visualiseringmetode om syllabifikasie te quantifiseer. Ons eksperimenteer op die nuwe gekombineerde taak van multitale IPA syllabifikasie en stress voorskou, en vind dat die onderwerp van 'n massief multitale neuralsekwensie-na-sekwensie model met kopie aandag kan verbeter effektuur op beide hoë en lae-hulpbron tale, en multi-taak onderwerp op stres voorskou hulp met syllabifikasie.", 'tr': 'Biz Wiktionary diýip beş iňlisçe ýok editiýasynda çykyşçylar ýapdyk. Iňlisçe düzgün gürrüňler bilen birleşýär. 5.3 milyon iňlisçe IPA döwletlerinden daşary, onuň iň uly aýdym leşiklisi bar. Bu veri setir IPA birden beýleki karşılaşykly bir korpusdyr. Biz veri setini analyzýarys we makine döredilen aýdymlaryň barlygyny üns berýäris Biz syllabiýatyny janlaşdyrmak üçin täze bir görselleştirme yöntemi geliştirdik. Biz multi diller IPA syllabiýatynda we stres önümlerinde täze bir gezek üzerinde synanyşýarys, nuwasy bilen örän köp dilli, ýokary we ýokary çeşmeler dilinde eserleşmeleri gowurap biler we stres önümlerinde köp işlemek üçin kömek edip biler.', 'bn': 'আমরা উইক্টনেরি পাঁচটি অই-ইংরেজি সংস্করণের জন্য পার্সার নির্মাণ করেছি, যা ইংরেজী সংস্করণ থেকে প্রচারণার সাথে একত্রিত হয়েছে, যা ৫. এই ডাটাসেট বিভিন্ন সূত্র থেকে বিবেচনা করা আইপিএ প্রচারণার একটি অনন্য কোর্পাস। আমরা ডাটাসেট বিশ্লেষণ করি, মেশিন উৎপাদনের উপস্থিতি লক্ষ্য করি। আমরা একটি নভেল দৃষ্টিভঙ্গি পদ্ধতি তৈরি করি সংস্করণ পরিমাপের জন্য। আমরা মাল্টিভাষার আইপিএ প্রতিষ্ঠান এবং চাপের ভবিষ্যৎবাণীর নতুন একত্রিত কর্মসূচীতে পরীক্ষা করছি, আবিষ্কার করেছি যে একটি ব্যাপক বহুভাষার নিউরেল সেকেন্ড-সেকেন্ড মডেলের প্রশিক্ষণের প্রশিক্ষণ যার ফলে', 'sq': 'Ne ndërtuam analizues për pesë edicione jo-angleze të Wiktionary, të cilat kombinohen me shprehjet nga edicioni angleze, përfshijnë mbi 5.3 milion shprehje IPA, lexikona më e madhe e shprehjes së llojit të saj. Ky grup i të dhënave është një korpus unik i krahasueshëm i shprehjeve IPA të anotuara nga burime të shumta. We analyze the dataset, noting the presence of machine-generated pronunciations.  Ne zhvillojmë një metodë të re vizualizimi për të cilësuar silabifikimin. Ne eksperimentojmë mbi detyrën e re të kombinuar të silabifikimit dhe parashikimit të stresit të IPA-s shumëgjuhës, duke gjetur se trajnimi i një modeli masiv shumëgjuhës nga sekuenca në sekuencë neurale me vëmendje kopje mund të përmirësojë performancën në gjuhët me burime të larta dhe të ulta dhe trajnimi shumëdetyror mbi parashikimin e stresit ndihmon me silabifikimin.', 'hy': 'We constructed parsers for five non-English editions of Wiktionary, which combined with pronunciations from the English edition, comprises over 5.3 million IPA pronunciations, the largest pronunciation lexicon of its kind.  Այս տվյալների համակարգը բազմաթիվ աղբյուրներից գրված IPA արտահայտությունների յուրահատուկ համեմատական կորպուս է: Մենք վերլուծում ենք տվյալների համակարգը, նկատում ենք մեքենայի ստեղծված արտահայտությունների գոյությունը: Մենք զարգանում ենք նոր վիզուալիզացիայի մեթոդ, որպեսզի չափեցնենք խմբավորումը: Մենք փորձում ենք IPA-ի բազլեզու խմբավորման և սթրեսի կանխատեսման նոր համադրված խնդրի վրա, հայտնաբերելով, որ սթրեսի կանխատեսման բազլեզու նյարդային հաջորդականության մոդելի ուսումնասիրելը կոպիայի հետ ուշադրություն դարձնելով կարող է բարելավել արտադրողությունը բարձր և ցածր ռեսուրսների լեզուներ', 'ca': "Vam construir analistes per cinc edicions no angleses de Wiktionary, que combinades amb pronunciacions de l'edició anglesa, componen més de 5,3 milions de pronunciacions de l'IPA, el més gran lexicó de pronunciació del seu tipus. Aquest conjunt de dades és un cos únic comparable de pronunciacions IPA anotats de múltiples fonts. Analitzem el conjunt de dades, observant la presença de pronunciacions generades per màquina. Desenvolvem un nou mètode de visualització per quantificar la sílabificació. Experimentem en la nova tasca combinada de la sillabificació multilingüe de l'IPA i la predicció de l'estrès, descobrint que formar un model massivament multilingüe de seqüència neuronal amb atenció còpia pot millorar el rendiment en llengües d'alt i baix recurso, i formar multitasca en predicció de l'estrès ajuda a la sillabificació.", 'cs': 'Postavili jsme parsery pro pět neanglických edicí Wiktionary, které v kombinaci s výslovnostmi z anglického vydání tvoří více než 5,3 miliony IPA výslovností, největší výslovnostní lexikon svého druhu. Tato datová sada je jedinečným srovnatelným korpusem výslovností IPA oznámených z více zdrojů. Analyzujeme datovou sadu a zaznamenáváme přítomnost strojově generovaných výslovností. Vyvíjíme novou vizualizační metodu pro kvantifikaci sylabifikace. Experimentujeme na novém kombinovaném úkolu vícejazyčné oslabování IPA a predikce stresu a zjišťujeme, že trénink masivně vícejazyčného neuronového sekvenčního modelu s pozorností kopírování může zlepšit výkon v jazycích s vysokými i nízkými zdroji, a víceúkolový trénink na predikci stresu pomáhá při oslabování.', 'et': 'Ehitasime parserid viiele wiktsõnaraamatu mitte-ingliskeelsele väljaandele, mis koos ingliskeelse väljaande hääldustega hõlmab üle 5,3 miljoni IPA häälduse, suurima hääldusleksikoni oma laadi. See andmekogum on unikaalne võrreldav IPA häälduste korpus, mis on teatatud mitmest allikast. Analüüsime andmekogumit, märkides masinagenereeritud häälduste olemasolu. Töötame välja uue visualiseerimismeetodi silbimise kvantifitseerimiseks. Me eksperimenteerime uut kombineeritud ülesannet mitmekeelseks IPA silpeerimiseks ja stressiprognoosimiseks, leides, et massiivselt mitmekeelse neuraalse järjestuse mudeli koopiatähelepanuga koopia võib parandada jõudlust nii suure kui ka vähese ressursiga keeltes ning mitmekeelseks koolituseks stressiprognoosimiseks aitab silpeerimiseks.', 'fi': 'Rakensimme jäsentäjiä viidelle ei-englanninkieliselle Wiktionaryn painokselle, joka yhdistettynä englanninkieliseen painokseen sisältää yli 5,3 miljoonaa IPA-ääntämistä, joka on lajissaan suurin ääntämissanasto. Tämä aineisto on ainutlaatuinen vertailukelpoinen IPA-lausumien korpus, joka on ilmoitettu useista lähteistä. Analysoimme aineistoa ja huomioimme koneellisesti tuotettujen lausumien läsnäolon. Kehitämme uudenlaisen visualisointimenetelmän tavutuksen kvantifiointiin. Kokeilemme uutta monikielistä IPA:n tavuttamista ja stressin ennustamista yhdistävää tehtävää. Havaitsemme, että massiivisen monikielisen neurosekvenssimallin harjoittelu kopioinnin huomiolla voi parantaa suorituskykyä sekä suuriresurssisilla että pieniresurssisilla kielillä, ja stressin ennustamiseen liittyvä monitehtävä auttaa tavuttamisessa.', 'az': "Biz Wiktionary'in beş İngilizə olmayan edityonları üçün parçacılar inşa etdik. İngilizə edityonundan sözlər birlikdə 5,3 milyon IPA sözləri var. Bu sözlərin ən böyük sözləri. Bu veri qurğusu, çoxlu mənbələrdən bildirilmiş IPA ifadələrinin eşitməli bir korpusudur. Biz verilən qurğuları analiz edirik, makinat ürəkləndirilmiş ifadələr barəsində. Biz sözləri kvantifikat etmək üçün yeni bir vizualizasyon metodu təhsil edirik. Biz çoxlu dil IPA silabifikasyonun və stres tədbirlərinin yeni birləşdirilmiş işlərini təcrübə edirik. Bu təcrübə ilə çoxlu dil nöral sequence-to-sequence modeli təcrübə edir ki, təcrübə ilə çoxlu təcrübə ilə təcrübə etmək hər ikisinin yüksək və düşük ressurs dillərində təcrübəsini daha yaxşılaşdıra bilər, və stre", 'bs': 'Izgradili smo parsere za pet ne-engleskih redakcija Wiktionary-a, koja je kombinovana sa izjavama iz Engleskog izdanja, sastoji od preko 5,3 miliona izjava IPA-a, najveće izjave leksiona njegove vrste. Ova kompleta podataka je jedinstven usporedbeni korpus proglašavanja IPA-a iz višestrukih izvora. Analiziramo set podataka, primjećujući prisustvo proglašavanja iz mašine. Razvijamo novu vizualizaciju metodu da kvantificiramo silabifikaciju. Eksperimentiramo na novi kombinirani zadatak multijezičke silabifikacije i predviđanja stresa IPA-a, otkrivajući da obuka masivnog multijezičkog neuralnog sekvenčnog modela sa kopijom pažnje može poboljšati učinkovitost na jezicima visokog i niskog resursa, te multi task obuku predviđanja stresa pomaže silabifikaciji.', 'jv': 'Awak dhéwé nggawe perusahaan kanggo limo urip sing gak Bek-Inggris, sing wis ditambakno karo perusahaan kanggo dino Inggris, dadi wis vector 5.3 miliyon dolanan sing perusahaan ipA, gak perusahaan langkung akeh lanjuré. Multicast Awak dhéwé nyokalé dataset Anyone Awak dhéwé éntukno karo nggambar nggawe sistem sing bagian nggambar aturan karo sistem multilenguase', 'ha': "Mun gina parparser wa shan taƙaitori 5 na'urar-Ingiriya, wanda ke koma da matalauta daga taƙaitorin Ingiriya, yana da zaɓangare 5.3 miliyan IPA, da dukkan kashi mafi girma. Wannan dataset yana da wani inganci na IPA da aka sanar da shi daga wasu sources. Ana yi anayyar da tsarin bayani, idan an gane cẽtare da aka halitta mashine. Tuna buɗe wata hanyor kallon da za'a ƙayyade salimilin. Tuna jarrabi cikin aikin da aka samu da shirin IPA na mulki-lingui, kuma munã gane cẽwa, yana da amfani da shirin misãlai mai yawan mutane na neura-zuwa-sequence na mulki-lingui, yana iya ƙaranci ga aikin muhimmanci a cikin lugha sarki da ƙasan-resource, kuma ma'anar mulki-aikin da ke yi na taimako da misalin littafin na ƙaranci.", 'sk': 'Izdelali smo razčlenjevalnike za pet ne-angleških izdaj Wiktionarja, ki v kombinaciji z izgovori iz angleške izdaje obsega več kot 5,3 milijona izgovorjav IPA, največji izgovorjavni leksikon te vrste. Ta nabor podatkov je edinstven primerljiv korpus IPA izgovorjav, napovedanih iz več virov. Analiziramo nabor podatkov in ugotavljamo prisotnost strojno generiranih izgovorov. Razvijamo novo metodo vizualizacije za kvantifikacijo zlaganja. Eksperimentiramo na novi kombinirani nalogi večjezičnega učenja IPA in napovedovanja stresa, ugotovili smo, da lahko usposabljanje množičnega večjezičnega modela nevronskega zaporedja v zaporedje s pozornostjo kopiranja izboljša učinkovitost v jezikih z visokimi in nizkimi viri, večopravilno usposabljanje o napovedovanju stresa pa pomaga pri učenju učenja stresa.', 'bo': 'We constructed parsers for five non-English editions of Wiktionary, which combined with pronunciations from the English edition, comprises over 5.3 million IPA pronunciations, the largest pronunciation lexicon of it. It contains over 5.3 million IPA pronunciations, the largest pronunciation lexicon of it. སྒྲིག་ཆ་འཕྲིན་ཡིག་ཆ་འདི་ནི་རང་ཉིད་ཀྱི་གནད་དོན་འགྱུར་བའི་མཁའ་དབུགས་ཞིག་རེད། ང་ཚོས་ལག་ཆས་གསར་བསྐྲུན་པའི་གསལ་བརྗོད་ཀྱི་གནད་སྡུད་ཚན་བཙལ་ཞིབ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་དུས་འཕགས་ཀྱི་ཐབས་ལམ་ཞིག་ལ་བཟོ་རྩོམ་གཏོང་བྱེད་ཀྱི་ཡོད། We experiment on the new combined task of multilingual IPA syllabification and stress prediction, finding that training a massively multilingual neural sequence-to-sequence model with copy attention can improve performance on both high- and low-resource languages, and multi-task training on stress prediction helps with syllabification.', 'he': 'בנינו חוקרים עבור חמישה הוצאות לא אנגליות של ויקציונרי, אשר שולבים עם הצהרות מההוצאה האנגלית, כוללים מעל 5.3 מיליון הצהרות IPA, הלקסיקון הגדול ביותר של סוג זה. קבוצת המידע הזו היא גופוס יחיד שווה של ביטויות IPA שמשמעות ממקורים רבים. אנו מנתחים את קבוצת המידע, שמים לב לנוכחות הבטאות שנוצרות מהמכונה. אנחנו מפתחים שיטת ויזואליזציה חדשה כדי לקוונטיביזציה. We experiment on the new combined task of multilingual IPA syllabification and stress prediction, finding that training a massively multilingual neural sequence-to-sequence model with copy attention can improve performance on both high- and low-resource languages, and multi-task training on stress prediction helps with syllabification.'}
{'en': 'A Dutch Dataset for Cross-lingual Multilabel Toxicity Detection', 'fr': 'Un ensemble de données néerlandais pour la détection multilingue de la toxicité en plusieurs étiquettes', 'ar': 'مجموعة بيانات هولندية لاكتشاف السمية متعددة اللغات عبر اللغات', 'es': 'Un conjunto de datos holandés para la detección multilingüe de toxicidad multietiqueta', 'pt': 'Um conjunto de dados holandês para detecção de toxicidade multilabel em vários idiomas', 'zh': '用跨语多标毒性检测的荷兰语数据集', 'ru': 'Голландский набор данных для многоязычного определения токсичности', 'ja': 'クロスリンガルマルチラベル毒性検出用のオランダのデータセット', 'hi': 'क्रॉस-लिंगुअल मल्टीलेबल विषाक्तता का पता लगाने के लिए एक डच डेटासेट', 'ga': 'Tacar Sonraí Ollainnis le haghaidh Braite Tocsaineachta Illipéid Trasteangacha', 'hu': 'Hollandia adatkészlet a többnyelvű, többcímkés toxicitás kimutatására', 'ka': 'Name', 'kk': 'Қосымша тілді көп- белгілерді толқынды анықтау үшін Нидерландық деректер қорыName', 'it': 'Un dataset olandese per il rilevamento multilingue della tossicità', 'el': 'Ολλανδικό σύνολο δεδομένων για την ανίχνευση τοξικότητας πολλαπλών ετικετών', 'ms': 'Name', 'ml': 'Name', 'mt': 'Sett ta’ Dejta Olandiż għas-Sejbien ta’ Tossiċità Multitikketta Cross-lingual', 'lt': 'Nyderlandų daugiakalbio toksiškumo nustatymo duomenų rinkinys', 'mk': 'Name', 'mn': 'Хөгжлийн олон хэлбэрийн тохиромжтой байдлын голландын өгөгдлийн сан', 'no': 'Name', 'ro': 'Un set de date olandez pentru detectarea toxicității multilingve', 'sr': 'Holandski datum za otkrivanje toksičnosti preko jezika', 'pl': 'Holenderski zestaw danych dla wielojęzycznego wykrywania toksyczności wielojęzycznej', 'si': 'Name', 'so': 'Lacagta iskuulka iyo luqada Finnishka Multilabel Toxicity', 'ur': 'Name', 'sv': 'Ett holländskt dataset för flerspråkig toxicitetsdetektion', 'ta': 'Name', 'vi': 'Truyền dữ liệu Hà Lan về phát hiện độc tố đa ngôn ngữ rộng', 'uz': 'Name', 'nl': 'Een Nederlandse dataset voor meertalige toxiciteitsdetectie', 'bg': 'Нидерландски набор от данни за междуезично многоетикетно откриване на токсичност', 'da': 'Et hollandsk datasæt til påvisning af toksicitet på tværs af flere sprog', 'id': 'Sebuah Dataset Belanda untuk Deteksi Toksitas Multilabel Selata Bahasa', 'hr': 'Nizozemski podaci za otkrivanje toksičnosti preko jezika', 'de': 'Ein niederländischer Datensatz für mehrsprachige Toxizitätserkennung', 'sw': 'Taarifa ya Uholanzi kwa ajili ya Utafiti wa Toxicity', 'fa': 'Name', 'ko': '네덜란드 다중 언어 다중 라벨 독성 검출 데이터 집합', 'af': 'Name', 'sq': 'Një bazë të dhënash hollandeze për zbulimin e toksicitetit ndërgjuhësor', 'tr': 'Çoklu-etiket Toxicity Detection', 'am': 'Multilabel Toxicity Detection', 'bs': 'Holandski podaci za otkrivanje toksičnosti preko jezika', 'az': 'Daha çox dilli çoxlu etiket Toxicity Detection', 'hy': 'A Dutch Dataset for Cross-lingual Multilabel Toxicity Detection', 'ca': 'Un conjunt de dades holandeses per a la detecció de toxicitat multilingüística', 'bn': 'Name', 'et': 'Hollandi andmekogum mitmekeelse toksilisuse tuvastamiseks', 'fi': 'Hollantilainen tietokokonaisuus monikielistä myrkyllisyyden havaitsemista varten', 'cs': 'Nizozemský datový soubor pro detekci toxicity vícejazyčných značek', 'jv': 'Name', 'he': 'מסד נתונים הולנדי לגלות רעילות רבות בשפתיים', 'ha': 'KCharselect unicode block name', 'sk': 'Nizozemski nabor podatkov za večjezično odkrivanje toksičnosti', 'bo': 'སྐད་རིགས་འདྲ་བ་དང་བསྟུན་ནས་དབྱིབས་ཤོག་བྱང་ཆ་སྐྱེལ་བའི་གནས་སྡུད་མཚམས་ཤོག་བྱས།'}
{'en': 'Multi-label toxicity detection is highly prominent, with many research groups, companies, and individuals engaging with it through shared tasks and dedicated venues. This paper describes a cross-lingual approach to annotating multi-label text classification on a newly developed Dutch language dataset, using a model trained on English data. We present an ensemble model of one Transformer model and an LSTM using Multilingual embeddings. The combination of multilingual embeddings and the Transformer model improves performance in a cross-lingual setting.', 'pt': 'A detecção de toxicidade com vários rótulos é altamente proeminente, com muitos grupos de pesquisa, empresas e indivíduos envolvidos com ela por meio de tarefas compartilhadas e locais dedicados. Este artigo descreve uma abordagem multilíngue para anotar classificação de texto com vários rótulos em um conjunto de dados de idioma holandês recém-desenvolvido, usando um modelo treinado em dados em inglês. Apresentamos um modelo ensemble de um modelo Transformer e um LSTM usando embeddings multilíngues. A combinação de incorporações multilíngues e o modelo Transformer melhora o desempenho em uma configuração multilíngue.', 'ar': 'يعد اكتشاف السمية متعدد العلامات أمرًا بارزًا للغاية ، حيث تشارك العديد من المجموعات البحثية والشركات والأفراد معها من خلال المهام المشتركة والأماكن المخصصة. تصف هذه الورقة نهجًا متعدد اللغات للتعليق على تصنيف النص متعدد التسميات على مجموعة بيانات باللغة الهولندية تم تطويرها حديثًا ، باستخدام نموذج تم تدريبه على البيانات الإنجليزية. نقدم نموذجًا مجمعًا لطراز محول واحد و LSTM باستخدام الزخارف متعددة اللغات. يعمل الجمع بين حفلات الزفاف متعددة اللغات ونموذج Transformer على تحسين الأداء في بيئة متعددة اللغات.', 'es': 'La detección de toxicidad con múltiples etiquetas es muy importante, ya que muchos grupos de investigación, empresas e individuos participan en ella a través de tareas compartidas y lugares dedicados. Este documento describe un enfoque multilingüe para anotar la clasificación de texto de múltiples etiquetas en un conjunto de datos de idioma holandés recientemente desarrollado, utilizando un modelo entrenado en datos en inglés. Presentamos un modelo de conjunto de un modelo Transformer y un LSTM mediante incrustaciones multilingües. La combinación de incrustaciones multilingües y el modelo Transformer mejora el rendimiento en un entorno multilingüe.', 'fr': "La détection de la toxicité multi-étiquettes occupe une place prépondérante, de nombreux groupes de recherche, entreprises et particuliers s'y engageant par le biais de tâches partagées et de lieux dédiés. Cet article décrit une approche multilingue pour annoter une classification de texte multi-étiquettes sur un ensemble de données en néerlandais nouvellement développé, à l'aide d'un modèle formé sur des données en anglais. Nous présentons un modèle d'ensemble composé d'un modèle Transformer et d'un LSTM utilisant des intégrations multilingues. La combinaison d'intégrations multilingues et du modèle Transformer améliore les performances dans un environnement multilingue.", 'ja': 'マルチラベル毒性検出は非常に顕著であり、多くの研究グループ、企業、個人が共有されたタスクと専用の会場を通じてそれに関与しています。この論文では、英語データで訓練されたモデルを使用して、新たに開発されたオランダ語データセット上のマルチラベルテキスト分類に注釈を付けるためのクロスリンガルアプローチについて説明します。1つのトランスフォーマーモデルと、多言語埋め込みを使用したLSTMのアンサンブルモデルをご紹介します。多言語埋め込みとTransformerモデルの組み合わせにより、クロスリンガル環境でのパフォーマンスが向上します。', 'ru': 'Многоцелевое обнаружение токсичности очень заметно, многие исследовательские группы, компании и отдельные лица взаимодействуют с ним через совместные задачи и специализированные объекты. В настоящем документе описывается межъязыковой подход к аннотированию многоуровневой текстовой классификации на вновь разработанном наборе данных на голландском языке с использованием модели, подготовленной на основе данных на английском языке. Мы представляем ансамблевую модель одной модели трансформатора и LSTM с использованием многоязычных вложений. Сочетание многоязычных вложений и модели Трансформатора улучшает производительность в межъязыковой среде.', 'zh': '多标毒检甚异,多所研小组,公私共享,专在其中。 本文述一跨语法,用英语数训练,于新发荷兰语数集上注多标本分。 我立Transformer模与一多言嵌LSTM者为模。 多言嵌 Transformer ,合而言之。', 'hi': 'मल्टी-लेबल विषाक्तता का पता लगाना अत्यधिक प्रमुख है, जिसमें कई शोध समूह, कंपनियां और व्यक्ति साझा कार्यों और समर्पित स्थानों के माध्यम से इसके साथ संलग्न हैं। यह पेपर अंग्रेजी डेटा पर प्रशिक्षित मॉडल का उपयोग करके एक नव विकसित डच भाषा डेटासेट पर बहु-लेबल पाठ वर्गीकरण को एनोटेट करने के लिए एक क्रॉस-लिंगुअल दृष्टिकोण का वर्णन करता है। हम बहुभाषी एम्बेडिंग का उपयोग करके एक ट्रांसफॉर्मर मॉडल और एक एलएसटीएम का एक पहनावा मॉडल पेश करते हैं। बहुभाषी एम्बेडिंग और ट्रांसफॉर्मर मॉडल का संयोजन एक क्रॉस-लिंगुअल सेटिंग में प्रदर्शन में सुधार करता है।', 'ga': 'Tá braite tocsaineachta illipéid thar a bheith feiceálach, agus go leor grúpaí taighde, cuideachtaí agus daoine aonair ag plé leis trí thascanna roinnte agus trí ionaid thiomnaithe. Déanann an páipéar seo cur síos ar chur chuige tras-teangach maidir le haicmiú téacs illipéid a anótáil ar thacar sonraí nua-fhorbartha san Ollainnis, ag baint úsáide as múnla atá oilte ar shonraí Béarla. Cuirimid samhail ensemble de shamhail Trasfhoirmeora amháin i láthair agus LSTM ag baint úsáide as leabaithe Ilteangacha. Feabhsaítear feidhmíocht i suíomh tras-teangach mar gheall ar an meascán de leabú ilteangach agus an tsamhail Trasfhoirmeora.', 'ka': 'მრავალური ტექსტიკური განსახულება ძალიან მნიშვნელოვანია, მრავალური განსწავლებელი ჯგუფები, კომპანიები და ადამიანები, რომლებიც ამას გადავუმატებენ საზოგადოებ ახალი განვითარებული ჰონდელის სახელის მონაცემების მოდულის გამოყენება, ანგლისური მონაცემების მოდულის გამოყენება. ჩვენ ერთი ტრანსპორმეტრის მოდელს და LSTM-ს გამოყენებული მრავალენგური ინბიდნენტის მოდელს ჩვენ ჩვენ ჩვენ ჩვენ ჩვენებთ. მრავალენგური შებრუნების და ტრანფორმების მოდელის კომბუნციაცია უფრო მრავალენგური შებრუნებაში.', 'it': "Il rilevamento di tossicità multi-etichetta è molto importante, con molti gruppi di ricerca, aziende e individui coinvolti con esso attraverso compiti condivisi e sedi dedicate. Questo articolo descrive un approccio multilingue per annotare la classificazione di testo multi-etichetta su un set di dati in lingua olandese di recente sviluppo, utilizzando un modello addestrato sui dati inglesi. Presentiamo un modello ensemble di un modello Transformer e un LSTM utilizzando incorporazioni multilingue. La combinazione di incorporazioni multilingue e il modello Transformer migliora le prestazioni in un'impostazione multilingue.", 'el': 'Η ανίχνευση τοξικότητας πολλαπλών ετικετών είναι ιδιαίτερα εμφανής, με πολλές ερευνητικές ομάδες, εταιρείες και άτομα που ασχολούνται με αυτό μέσω κοινών καθηκόντων και ειδικών χώρων. Η παρούσα εργασία περιγράφει μια γλωσσική προσέγγιση για την ταξινόμηση κειμένου πολλαπλών ετικετών σε ένα πρόσφατα αναπτυγμένο σύνολο δεδομένων ολλανδικής γλώσσας, χρησιμοποιώντας ένα μοντέλο εκπαιδευμένο σε αγγλικά δεδομένα. Παρουσιάζουμε ένα μοντέλο συνόλου ενός μοντέλου μετασχηματιστή και ενός χρησιμοποιώντας Πολυγλωσσικές ενσωμάτωσης. Ο συνδυασμός των πολύγλωσσων ενσωμάτωσης και του μοντέλου βελτιώνει την απόδοση σε ένα γλωσσικό περιβάλλον.', 'kk': 'Көптеген белгілердің тоғыздығын анықтау үшін көптеген зерттеу топтары, компаниялар және бөлек тапсырмаларды және бөлек жерлері арқылы ортақтастыратын адамдар бар. Бұл қағаз жаңа жасалған Нидерландша тіл деректер қорларында көп жарлық мәтін классификациясын жаңа жасалған, ағылшын деректеріне оқылған үлгі қолданып, көп жарлық мәтін классифи Біз бір түрлендіру үлгісін және бірнеше тілді ендіру үлгісін қолданатын LSTM үлгісін таңдаймыз. Көптілік ендіру және Түрлендіру үлгісі көптілік параметрлерінде жылдамдығын жасайды.', 'mk': 'Детектирањето на мултиетиката токсичност е многу истакнато, со многу истражувачки групи, претпријатија и индивидуали кои се вклучуваат во неа преку заеднички задачи и посветени места. This paper describes a cross-lingual approach to annotating multi-label text classification on a newly developed Dutch language dataset, using a model trained on English data.  Презентираме ансембл модел на еден трансформер модел и ЛСТМ користејќи мултијазички вложувања. Комбинацијата на мултијазични внесувања и моделот Трансформер ја подобрува резултатот во прекујазични услови.', 'hu': 'A többcímkézett toxicitás kimutatása rendkívül kiemelkedő, számos kutatócsoport, vállalat és magánszemély közös feladatokon és dedikált helyszíneken keresztül vesz részt. Ez a tanulmány egy újonnan kifejlesztett holland nyelvű adatkészleten történő többcímkés szövegosztályozás jegyzetelésének többnyelvű megközelítését ismerteti, angol adatokra képzett modell segítségével. Bemutatjuk egy transzformátor modell és egy LSTM együttes modelljét többnyelvű beágyazásokkal. A többnyelvű beágyazások és a Transformer modell kombinációja javítja a teljesítményt egy többnyelvű beállításban.', 'lt': 'Daugiaženklis toksiškumo nustatymas yra labai svarbus, o daugelis mokslinių tyrimų grupių, bendrovių ir asmenų dalyvauja atliekant bendras užduotis ir specialias vietas. Šiame dokumente aprašomas daugiakalbis metodas, kaip anotuoti daugiakalbį teksto klasifikavimą naujai sukurtame Nyderlandų kalbos duomenų rinkinyje, naudojant anglų duomenimis parengtą model į. We present an ensemble model of one Transformer model and an LSTM using Multilingual embeddings.  Daugiakalbių įdėjimų ir Transformer modelio derinys gerina tarpkalbinius rezultatus.', 'ms': 'Pengesanan toksiciti berbilang-label adalah sangat terkenal, dengan banyak kumpulan kajian, syarikat, dan individu yang terlibat dengannya melalui tugas berkongsi dan tempat yang ditugaskan. Kertas ini menggambarkan pendekatan saling bahasa untuk anotasi klasifikasi teks multi-label pada set data bahasa Belanda yang baru dikembangkan, menggunakan model yang dilatih pada data bahasa Inggeris. Kami memperkenalkan model ensemble bagi satu model Transformer dan LSTM menggunakan penyembedding berbilang bahasa. Kombinasi pelbagai pelbagai bahasa dan model Transformer memperbaiki prestasi dalam tetapan saling bahasa.', 'ml': 'ഒരുപാട് ടോക്സിക്സിറ്റി കണ്ടുപിടിക്കുന്നത് വളരെ പ്രധാനപ്പെട്ടിരിക്കുന്നു. പല പഠിക്കുന്ന ഗ്രൂപ്പുകള്\u200d, കമ്പനികള്\u200d, വ്യക്തികള ഈ പേപ്പറിന്റെ വിശദീകരിക്കുന്നു ഇംഗ്ലീഷ് വിവരങ്ങളില്\u200d പരിശീലിക്കപ്പെട്ട ഒരു മോഡല്\u200d ഉപയോഗിച്ച് ഒരു മോഡല്\u200d ഉപയോഗിച്ചുകൊണ്ട് പല ഞങ്ങള്\u200d ഒരു ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200dസ് മോഡലിന്\u200dറെ ഒരു മാതൃകയെ കാണിച്ചുകൊടുക്കുന്നു. ഒരു എംഎസ്റ്റിംഗ് മുഴുവന്\u200d  പല ഭാഷകങ്ങളുടെയും ട്രാന്\u200dസ്ഫോര്\u200dമാറ്റര്\u200d മോഡലുകളുടെയും കൂട്ടിചേര്\u200dക്കുന്നത് ക്രിസ്ലിങ്ലിന്\u200dറെ സെറ്റി', 'mn': 'Олон төрлийн хохиромжтой хохиромжтой байдлыг олон судалгааны бүлгүүд, компаниуд, хуваалцах ажил, хуваалцах газрыг ашиглаж байгаа хүмүүс маш чухал байдаг. Энэ цаас дахин хөгжигдсэн Нидерландын хэлний өгөгдлийн сангийн олон загварын текст хуваалцааны тухай олон хэлний арга загварыг тайлбарладаг. Бид нэг Трансформ загварын загвар болон олон хэлний интербингүүдийг ашиглаж LSTM-ийн загвар өгсөн. Ихэнх хэл болон Трансфер загварын нэгтгэл нь олон хэл хэлний тохиолдолд үйл ажиллагааг сайжруулдаг.', 'ro': 'Detectarea toxicității cu mai multe etichete este foarte proeminentă, multe grupuri de cercetare, companii și persoane fizice implicate în aceasta prin sarcini comune și locuri dedicate. Această lucrare descrie o abordare translingvistică a adnotării clasificării textelor cu mai multe etichete pe un set de date nou dezvoltat în limba olandeză, folosind un model instruit pe date în limba engleză. Vă prezentăm un model de ansamblu al unui model Transformer și al unui LSTM folosind încorporări multilingve. Combinația de încorporări multilingve și modelul Transformer îmbunătățește performanța într-un cadru interlingv.', 'pl': 'Wykrywanie toksyczności wieloznakowych jest bardzo ważne, a wiele grup badawczych, firm i osób zaangażowanych w to działa poprzez wspólne zadania i dedykowane miejsca. Niniejszy artykuł opisuje wielojęzyczne podejście do adnotacji wielojęzykowej klasyfikacji tekstu na nowo opracowanym zbiorze danych języka holenderskiego z wykorzystaniem modelu przeszkolonego na danych angielskich. Przedstawiamy model zespołowy jednego modelu Transformera i LSTM z wykorzystaniem osadzeń wielojęzycznych. Połączenie wielojęzycznych osadzeń i modelu Transformer poprawia wydajność w warunkach wielojęzycznych.', 'mt': 'Multi-label toxicity detection is highly prominent, with many research groups, companies, and individuals engaging with it through shared tasks and dedicated venues.  Dan id-dokument jiddeskrivi approċċ translingwistiku għall-annotazzjoni tal-klassifikazzjoni tat-test b’ħafna tikketti fuq sett ta’ dejta tal-lingwa Olandiża żviluppat mill-ġdid, bl-użu ta’ mudell imħarreġ fuq dejta Ingliża. Aħna nippreżentaw mudell ta’ ensemble ta’ mudell wieħed ta’ Transformer u LSTM bl-użu ta’ inkorporazzjonijiet multilingwi. Il-kombinazzjoni ta’ inkorporazzjonijiet multilingwi u l-mudell Transformer ittejjeb il-prestazzjoni f’ambjent translingwi.', 'sr': 'Mnoge oznake otkrivanje toksičnosti je veoma poznato, sa mnogim istraživačkim grupama, kompanijama i pojedincima koje se s njim bave putem zajedničkih zadataka i posvećenih mjesta. Ovaj papir opisuje cross-language pristup annotaciji multi-label tekst klasifikacije na novom razvijenom nizozemskom setu podataka, koristeći model obučen na engleskim podacima. Predstavljamo model ensemble jednog transformera i LSTM koristeći multijezičke integracije. Kombinacija multijezičkih integracija i model a Transformera poboljšava izvođenje u međujezičkom postavljanju.', 'si': 'ගොඩක් ලේබුල් විශේෂතාව හොයාගන්න බොහෝ ප්\u200dරශ්ණයි, ගොඩක් පරීක්ෂණ කණ්ඩායම, සමාගම, සහ විශේෂකයෙන් ඒක සමඟ ස Name Name ගොඩක් භාෂාවක් සංවිධානය සහ ප්\u200dරවර්තනයක් නිර්මාණය විශ්වාස කරනවා ක්\u200dරියාකාරීය භාෂාවක් ස', 'no': 'Det er veldig viktig å oppdaga toksikitet med fleire merkelapper, med mange forskningsgrupper, selskaper og individuar som er med det gjennom delte oppgåver og spesifiserte stader. Denne papiret beskriver ein krysspråk tilnærming til å merke mellommerkelige tekstklassifikasjon på eit nytt utvikla nederlandsk språk- datasett med eit modell trent på engelske data. Vi presenterer ein ensemble modell for ein transformeringsmodell og ein LSTM med fleirspråk innbygging. Kombinasjonen av fleirspråk innbygging og Transformeringsmodellen forbedrar utviklinga i eit krysspråk innstilling.', 'so': 'Multi-label toxicity detection is highly prominent, with many research groups, companies, and individuals engaging with it through shared tasks and dedicated venues.  Kanu wuxuu ku qoran yahay qaab luqad kala duduwan si uu u caddeeyo fasaxa qoraalka oo kala duduwan, oo ku qorayo macluumaadka luuqada Dutch oo cusub horumaray, isagoo isticmaalaya model lagu tababaray macluumaadka Ingiriiska. Waxaynu sameynaa tusaale u eg qaab mid ah oo turjumay iyo LSTM oo isticmaalaya qalabka luuqadaha badan. Isku xiriirka qalabka luuqadaha kala duduwan iyo modelka turjumista ayaa kordhisa bandhigyada qoraalka luuqadaha kala duwan.', 'ta': 'பல விளக்கச்சீட்டு புவியியல் கண்டுபிடிப்பது மிகவும் பெரியது, பல ஆராய்ச்சி குழுக்கள், நிறுவனங்கள், மற்றும் தனிப்பட்ட பணிகள் மற்றும் தனி இந்த தாள் ஒரு முறைமை ஆங்கிலத்தில் பயிற்சி செய்யப்பட்ட மாதிரியை பயன்படுத்தி பல- label உரை வகைப்பாட்டை புதிய உருவாக்கும் தரவுத்தளத்தி நாம் ஒரு மாற்று மாதிரி மாதிரி மற்றும் ஒரு LSTM மாதிரி மாதிரியை பயன்படுத்தி பல மொழிகள் உள்ளீடுகளை பயன்படுத்துகி பல மொழி பொருள்களின் கூட்டுதல் மற்றும் மாற்றி மாதிரி மாதிரியின் செயல்பாட்டை மேம்படுத்துகிறது ஒரு கிரும்ம', 'sv': 'Multi-label toxicitet detektering är mycket framträdande, med många forskargrupper, företag och individer som engagerar sig i det genom delade uppgifter och dedikerade platser. Denna uppsats beskriver ett flerspråkigt tillvägagångssätt för att kommentera fleretikett textklassificering på ett nyutvecklat holländska språkdataset, med hjälp av en modell utbildad på engelska data. Vi presenterar en ensemblemodell av en Transformer modell och en LSTM med flerspråkiga inbäddningar. Kombinationen av flerspråkiga inbäddningar och Transformer-modellen förbättrar prestandan i en flerspråkig inställning.', 'ur': 'بہت سی لیبل جسمی شناسایت بہت اہم ہے، بہت سی تحقیقات گروپ، کمپنیوں اور افراد کے ساتھ اس کے ساتھ مشترک کام اور مقرر جگہ کے ذریعہ مشترک ہوتے ہیں. This paper describes a cross-lingual approach to annotating multi-label text classification on a new developed Dutch language data set, using a model trained on English data. ہم ایک ٹرنفسر موڈل اور ایک LSTM کے ایک انسبل موڈل کو پیش کرتے ہیں۔ بہت سی زبان انڈینگ اور ترفنسر موڈل کی ترفنسر کی ترفنس کرسی زبان تنظیم میں عملکرد بہتر کر دیتی ہے.', 'uz': "Ko'pchilik toxiclikni aniqlash juda katta ajoyib, ko'pchilik qidirish guruhlari, kompaniyalar va shu vazifalar bilan birlashtirilgan odamlar bilan o'rganish mumkin. Name Biz bir shaxsiy modelni o'rganimiz va bir necha tillar foydalanuvchi LSTM modeli. Koʻpburchak tillar bilan birlashtirish va Transfer modeli bir necha tillar moslamasidagi amalni bajaradi.", 'vi': 'Việc phát hiện độc tố đa nhãn là rất nổi bật, với nhiều nhóm nghiên cứu, công ty, và cá nhân hợp tác với nó qua các công việc chia sẻ và các địa điểm chuyên biệt. Tờ giấy này mô tả một phương pháp ngôn ngữ khác nhau để ghi chú mã hoá văn bản đa nhãn trên một tập tin ngôn ngữ Hà Lan mới phát triển, sử dụng một mô hình được đào tạo trên dữ liệu Anh. Chúng tôi giới thiệu một mô hình cho một biến hình và một LSTM dùng đa ngôn ngữ tham nhũng. Sự kết hợp của sự nhúng vào đa dạng và mô hình transformer cải thiện hiệu suất trong một môi trường ngôn ngữ khác nhau.', 'hr': 'Otkrivanje višeoznačenog toksičnosti je vrlo poznato, s mnogim istraživačkim grupama, kompanijama i pojedincima koje se s njim okupljaju putem zajedničkih zadataka i posvećenih mjesta. Ovaj papir opisuje međujezički pristup annotaciji klasifikacije višeoznačenih teksta na novom razvijenom nizozemskom setu podataka, koristeći model obučen na engleskim podacima. Predstavljamo model ensemble jednog transformera i LSTM koristeći multijezičke integracije. Kombinacija višejezičkih integracija i model Transformer a poboljšava učinkovitost u međujezičkom postavljanju.', 'nl': 'Multi-label toxiciteitsdetectie is zeer prominent, waarbij veel onderzoeksgroepen, bedrijven en individuen zich ermee bezighouden via gedeelde taken en speciale locaties. Dit artikel beschrijft een meertalige benadering van het annoteren van multi-label tekstclassificatie op een nieuw ontwikkelde Nederlandstalige dataset, met behulp van een model getraind op Engelse data. We presenteren een ensemble model van één Transformer model en een LSTM met behulp van meertalige embeddings. De combinatie van meertalige embeddings en het Transformer-model verbetert de prestaties in een meertalige omgeving.', 'da': 'Multi-label toksicitetsdetektion er meget fremtrædende, med mange forskningsgrupper, virksomheder og enkeltpersoner, der engagerer sig i det gennem fælles opgaver og dedikerede steder. Denne artikel beskriver en tværsproget tilgang til annotering af flere etiketter tekst klassifikation på et nyudviklet hollandsk sprog datasæt ved hjælp af en model trænet på engelsk data. Vi præsenterer en ensemble model af en Transformer model og en LSTM ved hjælp af flersprogede indlejringer. Kombinationen af flersprogede indlejringer og Transformer-modellen forbedrer ydeevnen i en tværsproget indstilling.', 'de': 'Die Multi-Label-Toxizitätserkennung ist sehr prominent, wobei viele Forschungsgruppen, Unternehmen und Einzelpersonen sich mit ihr durch gemeinsame Aufgaben und dedizierte Orte beschäftigen. Dieser Beitrag beschreibt einen sprachübergreifenden Ansatz zur Annotation von Multi-Label-Textklassifikationen auf einem neu entwickelten niederländischen Datensatz unter Verwendung eines Modells, das auf englischen Daten trainiert wurde. Wir präsentieren ein Ensemblemodell aus einem Transformer-Modell und einem LSTM mit mehrsprachigen Einbettungen. Die Kombination aus mehrsprachigen Einbettungen und dem Transformer-Modell verbessert die Leistung in einer sprachübergreifenden Umgebung.', 'bg': 'Откриването на токсичност с множество етикети е силно видно, като много изследователски групи, компании и физически лица се ангажират с него чрез споделени задачи и специализирани места. Настоящата статия описва междуезичен подход за анотиране на многоетикетна текстова класификация върху новоразработен холандски език набор от данни, използвайки модел, обучен на английски данни. Представяме ансамбълен модел на един трансформаторен модел и ЛСТМ, използвайки многоезични вграждания. Комбинацията от многоезични вграждания и модела на трансформатора подобрява производителността в междуезична настройка.', 'id': 'Deteksi toksicitas multi-label sangat terkenal, dengan banyak kelompok penelitian, perusahaan, dan individu yang terlibat dengan hal itu melalui tugas berbagi dan tempat yang didedikasikan. Kertas ini menggambarkan pendekatan saling bahasa untuk menganoterasi klasifikasi teks multi-label pada set data bahasa Belanda yang baru dikembangkan, menggunakan model yang dilatih pada data bahasa Inggris. Kami mempersembahkan model ensemble dari satu model Transformer dan LSTM menggunakan embedding berbilang bahasa. Kombinasi pembangunan berbagai bahasa dan model Transformer meningkatkan prestasi dalam pengaturan berbagai bahasa.', 'ko': '다중 라벨 독성 검출이 두드러져 많은 연구팀, 회사와 개인이 공유 임무와 전용 장소를 통해 참여한다.본고는 새로 개발된 네덜란드어 데이터 집합에 다중 라벨 텍스트 분류를 주석하고 영어 데이터에서 훈련하는 모델을 사용하는 다중 언어 방법을 묘사한다.우리는 다중 언어로 삽입된 변압기 모델과 LSTM의 통합 모델을 제시했다.다중 언어 삽입과 Transformer 모델의 결합은 다중 언어 환경에서의 성능을 향상시켰다.', 'fa': 'شناسایی سمی چندین برچسب بسیار مهم است، با گروه\u200cهای تحقیقات، شرکت\u200cها و افراد زیادی که از طریق وظیفه\u200cهای مشترک و محل\u200cهای مخصوص با آن مشارکت می\u200cکنند. این کاغذ یک روش متفاوت زبان برای تنظیم فرهنگ متن چندین نقاشی در مجموعه داده\u200cهای زبان هلندی تازه توصیف می\u200cکند، با استفاده از یک مدل روی داده\u200cهای انگلیسی آموزش داده می\u200cشود. ما یک مدل انجمن از یک مدل تغییر دهنده و LSTM را با استفاده از انجمن\u200cهای زیادی زبان نشان می\u200cدهیم. ترکیب پیوندهای زیادی زبان و مدل تغییر دهنده در یک تنظیم متوسط زبان بهتر می\u200cشود.', 'af': "Veelvuldige etikette toxisiteit-beskrywing is baie belangrik, met baie ondersoek groepe, maatskappye en individue wat met dit saamgaan deur deelde taak en besonderhede plekke. Hierdie papier beskrywe 'n kruistaalske toegang om multi- label teks klassifikasie op 'n nuwe ontwikkelde Nederlandse taal datastel te annoteer, gebruik 'n model onderwerp op Engelske data. Ons stel 'n ensemble model van een Transformer model en 'n LSTM gebruik Multilingual Inbêding. Die kombinasie van multilingse inbêdings en die Transformer model verbeter prestasie in 'n kruistale instelling.", 'am': 'ብዙው የጥምቀት ግጭት፣ በብዙ ምርምርጫዎች፣ ካምፓርቲዎች እና የተካፈሉት ሰዎች በተለያዩ ስራ እና በተለየ ቦታዎች ጋር የሚጠያየቁ ናቸው፡፡ ይህ ፕሮግራም በንግግሊዝኛ ዳታዎችን በመጠቀም የብዙ-label ጽሑፍ ክፍተቶችን ለመግለጥ የቋንቋ ቋንቋ ይናገራል፡፡ የአንድ ተርጓሚ ሞዴል እና የLSTM ብዙልቋንቋ አካባቢዎችን በመጠቀም እናቀርባለን፡፡ የብዙ ቋንቋዎች አካባቢዎች እና የተለየ ሞዴል በተለየ ቋንቋ ማዘጋጀት የራሱን ጥያቄ ያሳድጋል፡፡', 'tr': 'Birnäçe etiket toksiýetleri tanamak örän wajypdyr, birnäçe ylmy toparlar, kompaniýalary we adamlary onuň bilen paylaşyk görevleri we wezip ýerleri bilen birleşýärler. Bu kagyz täze gelişmeden hollança diller datajylary üçin multi-label metin klasifikasyny a ňladmak üçin cross-lingual taýýarlandyrýar. Biz bir Transformer nusgasyny we bir LSTM ködlemelerini ullanýarys. Çoklu diller birleşdirmeleri we Transformer modeli çarpaz diller çykyşynda eserlerni gowdurýar.', 'sw': 'Kugundua vibaya vifaa vingi ni maarufu sana, pamoja na makundi mengi ya utafiti, makampuni, na watu wanaohusisha kwa kupitia kazi zilizoshirikiana na maeneo maalum. Gazeti hili linaelezea mbinu za lugha mbalimbali za kutangaza tafsiri ya maandishi ya viungo vingi kwenye seti ya data za lugha za Kiholanzi mpya zilizoendelea, kwa kutumia mifano inayofundishwa kwenye takwimu za Kiingereza. Tunaweza kutengeneza mfano wa modeli moja ya Transformer na LSTM kwa kutumia viungo vya lugha nyingine. Kuunganishwa kwa viungo vya lugha mbalimbali na modeli ya Transfer inaboresha utendaji katika mazingira ya lugha.', 'sq': 'Gjetja e toksicitetit me shumë etiketa është shumë e shquar, me shumë grupe kërkimore, kompani dhe individë që angazhohen me të nëpërmjet detyrave të përbashkëta dhe vendeve të përkushtuara. Ky dokument përshkruan një qasje ndërgjuhësore për të shënuar klasifikimin e tekstit me shumë etiketa në një grup të dhënash të reja të zhvilluar në gjuhën hollandeze, duke përdorur një model të trajnuar në të dhënat angleze. Ne prezantojmë një model ensemble të një modeli Transformer dhe një LSTM duke përdorur përfshirje shumëgjuhëse. The combination of multilingual embeddings and the Transformer model improves performance in a cross-lingual setting.', 'az': '√áoxlu etiketli toxicit keŇüif √ßoxlu araŇütńĪrma qruplarńĪ, Ňüirketl…ôri v…ô Ňü…ôrikl…ôri il…ô birlikd…ô paylaŇüan iŇül…ôr v…ô m…ôxsusdur. Bu kańüńĪt yeni geliŇümiŇü Hollandi dil veril…ônl…ôrin m…ôlumatlarńĪnńĪn √ßoxlu etiketli m…ôtn klasifikasiyasńĪnńĪ t…ôsdiql…ôm…ôk √ľ√ß√ľn √ßoxlu dil t…ôrzini t…ôsdiql…ôyir. ńįngiliz…ô m…ôlumatlarńĪnda t…ôhsil edil…ôn modeli istifad…ô edir. Biz bir Transformer modelinin ensemble modelini v…ô √ßoxlu dil i√ß…ôril…ôrini kullanan LSTM modelini g√∂st…ôririk. M√ľxt…ôlif dill…ôrin birl…ôŇüdirilm…ôsi v…ô Transformer modeli √ßoxlu dill…ôrin birl…ôŇüdirilm…ôsini √ßoxlu t…ôrzd…ô yaxŇüńĪlaŇüdńĪrńĪr.', 'bs': 'Otkrivanje višeoznačenog toksičnosti je vrlo poznato, s mnogim istraživačkim grupama, kompanijama i pojedincima koje se s njim bave putem zajedničkih zadataka i posvećenih mjesta. Ovaj papir opisuje međujezički pristup annotaciji klasifikacije višeetičkih teksta o novom razvijenom nizozemskom setu podataka, koristeći model obučen na engleskim podacima. Predstavljamo model ensemble jednog transformera i LSTM koristeći multijezičke integracije. Kombinacija multijezičkih integracija i model a Transformera poboljšava učinkovitost u međujezičkom postavljanju.', 'hy': 'Բազմաթիվ պիտակների թունավորության հայտնաբերումը շատ նշանակալի է, քանի որ շատ հետազոտությունների խմբեր, ընկերություններ և անհատներ գործում են դրանով ընդհանուր խնդիրների և նվիրված վայրերի միջոցով: Այս աշխատանքը նկարագրում է երկլեզվային մոտեցումը բազմապիտակ տեքստի դասակարգման նկարագրելու համար նորից զարգացած հոլանդական լեզվի տվյալների համակարգի վրա, օգտագործելով անգլերենի տվյալներով սովորեցված մոդել: Մենք ներկայացնում ենք մեկ տրանֆորմերի մոդելի համակարգչային մոդել և LSMT-ը՝ օգտագործելով բազմալեզու ներդրումներ: Բազլեզու ներդրումների և Թրանսֆերմերի մոդելի համադրությունը բարելավում է արտադրությունը լեզուների միջև:', 'ca': "La detecció de toxicitats multietiquetades és molt prominentamb molts grups de recerca, empreses i individus que s'hi dediquen a través de tasques compartides i llocs dedicats. Aquest article descriu un enfocament translingüístic per anotar la classificació de textos multietiquetats en un nou conjunt de dades de llenguatge holandès, utilitzant un model entrenat en dades angleses. Presentam un model d'ensemble d'un model Transformer i un LSTM utilitzant incorporacions multilingües. La combinació d'incorporacions multilingües i el model Transformer millora el rendiment en un entorn translingüístic.", 'cs': 'Detekce toxicity s více štítky je vysoce prominentní, přičemž mnoho výzkumných skupin, firem a jednotlivců se s ní zabývá prostřednictvím sdílených úkolů a vyhrazených míst. Tento článek popisuje vícejazyčný přístup k anotování klasifikace textu na nově vyvinuté nizozemské jazykové sadě s využitím modelu trénovaného na anglických datech. Představujeme souborový model jednoho transformátorového modelu a LSTM s využitím vícejazyčných vložení. Kombinace vícejazyčných vložení a modelu Transformer zlepšuje výkon v různých jazycích.', 'bn': 'অনেক গবেষণা গ্রুপ, কোম্পানি এবং ব্যক্তির সাথে যোগাযোগ করা কাজ এবং বিশেষ ক্ষেত্রের মাধ্যমে অনেক ব্যক্তি বিশেষ করে যায়। এই পত্রিকা একটি নতুন উন্নয়ন করা ডাচ ভাষার ডাটাসেটের উপর একটি মডেল ব্যবহার করে অনেক লেখা টেক্সফিকেশন ব্যাখ্যা করার জন্য একটি ক্রাশ-ভাষায় ব্যবহৃত আমরা একটি ট্রান্সফ্রান্সফ্রান্স মডেল এবং একটি এলস্টিএম ব্যবহার করে বহুভাষায় ভাষা ব্যবহার করে একটি মডেল উপস্থাপন করি। মাল্টিভাষার প্রবেশ এবং ট্রান্সফ্রান্সফ্রেন্ড মডেলের সংযোগ ক্রান্ত ভাষাভাষী বৈশিষ্ট্যের কাজের উন্নত', 'fi': 'Monimerkkinen myrkyllisyyden havaitseminen on erittäin näkyvää, ja monet tutkimusryhmät, yritykset ja yksilöt osallistuvat siihen yhteisten tehtävien ja omistettujen tilojen kautta. Tässä artikkelissa kuvataan monikielistä lähestymistapaa huomautusten tekemiseen monikieliseen tekstiluokitukseen äskettäin kehitetyssä hollanninkielisessä aineistossa käyttäen englanninkielistä aineistoa. Esittelemme kokoonpanomallin yhdestä Transformer-mallista ja LSTM-mallista monikielisiä upotuksia käyttäen. Monikielisten upotusten ja Transformer-mallin yhdistelmä parantaa suorituskykyä monikielisessä ympäristössä.', 'et': 'Mitme märgisega toksilisuse tuvastamine on väga silmapaistev, paljud uurimisrühmad, ettevõtted ja üksikisikud tegelevad sellega jagatud ülesannete ja spetsiaalsete kohtade kaudu. Käesolevas dokumendis kirjeldatakse keeleülest lähenemisviisi mitmemärgiselise teksti klassifikatsiooni märgistamiseks hiljuti välja töötatud hollandi keele andmekogumile, kasutades inglise keele andmetel koolitatud mudelit. Esitleme ühe Transformeri mudeli ja LSTM ansambli mudelit, kasutades mitmekeelseid manustamisi. Mitmekeelsete manustamiste ja Transformeri mudeli kombinatsioon parandab jõudlust keeltevahelises olukorras.', 'he': 'זיהוי רעילות עם תווים רבים הוא מבהיר מאוד, עם קבוצות מחקר רבות, חברות, ואנשים שמתעסקים איתו דרך משימות משותפות ומקומות מסורתים. This paper describes a cross-lingual approach to annotating multi-label text classification on a newly developed Dutch language dataset, using a model trained on English data.  אנחנו מציגים מודל אנסמבל של מודל טרנספורר אחד ו LSTM בשימוש תוכניות רבות שפות. שילוב של תוכניות רבות שפות ומודל הטרנספורסטר משפר את ההופעה בסביבה דרך שפות.', 'sk': 'Odkrivanje toksičnosti z več oznakami je zelo pomembno, številne raziskovalne skupine, podjetja in posamezniki se z njo ukvarjajo prek skupnih nalog in namenskih prostorov. Ta prispevek opisuje večjezični pristop k označevanju razvrstitve besedila z več oznakami na novo razvitem nizozemskem jezikovnem naboru podatkov z uporabo modela, usposobljenega za angleške podatke. Predstavljamo ansambelni model enega transformatorskega modela in LSTM z uporabo večjezičnih vdelav. Kombinacija večjezičnih vdelav in modela transformatorja izboljšuje učinkovitost v večjezičnih nastavitvah.', 'ha': "Ana gane aikin mai tozari da yawa, da jama'a mãsu yawa, makampuni da mutane da ke haɗa da shi a cikin aikin da aka raba shi. Wannan takardan na bayyana wata hanyor-fassara na-lingui dõmin ya sanar da fasarin matsayin multi-label a kan tsarin danne na harshen Dushen na yanzu-yanzu, kuma yana amfani da wani motel wanda aka sanar da shi kan data na Ingiriya. Tuna gabatar da wani misali na Shirin Transformer da wani LSM da ke amfani da masu sakan cikin multiziman. Tsarin da aka haɗa masu cikin mulki-lingui da shirin Tafiyar da aka ƙara mafarin gabanin da ke cikin tsarin-harshe-tsohon.", 'jv': 'Menu item to Open a dialog Perkara iki rambarang kelas kotang langgar sampeyan kanggo nggawe akeh multi-label teks nggawe dataset sing apik sing luwih dumaten, Ngawe nguwe model sing bisa data Inggris. Awak dhéwé éntuk model ensembedle ning model Transformer sampek lan LTT nggawe Multilanguage embedding. Tatanan karo akeh akeh langkung sampeyan lan model Transformer dumadhi nggawe gerasane kapan langgar.', 'bo': 'མཐོང་སྣང་མང་བོ་ཞིག་དང་མཐོང་སྣང་ནི་གསལ་བཤད་ཆེན་པོ་ཞིག་ཡོད། དབུལ་སྡེ་མང་པོ་ཞིག་དང་། ལས་ཀ་གསལ་བཤད་ཀྱི་བྱ་སྟངས་དང་ཁྱ ཤོག ང་ཚོས་རྣམ་གྲངས་ཀྱི་དབྱིབས་བཟོའི་མ་དབྱིབས་གཅིག་དང་སྒྲིག་ཡིག་ཆ་སྐད་ཀྱི་ཁ་རྟགས་ཞིག་སྟོན་པ སྐད་རིགས་ཀྱི་སྒྲིག་མཐུད་དང་བསྒྱུར་བཅོས་ཐབས་ལམ་གྱི་མཉམ་དུ་ཚད་ལུགས་སྐད་ཀྱི་སྒྲིག་འགོད་ནང་གི་ལས་འཕགས་ཀྱི་ཡོད།'}
