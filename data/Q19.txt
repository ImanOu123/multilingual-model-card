{'en': 'Semantic Neural Machine Translation Using AMR', 'fr': 'Traduction automatique neuronale sémantique utilisant AMR', 'ar': 'الترجمة الآلية العصبية الدلالية باستخدام AMR', 'es': 'Traducción automática neuronal semántica mediante AMR', 'pt': 'Tradução automática neural semântica usando AMR', 'ja': 'AMRを使用したセマンティック神経機械翻訳', 'zh': '用 AMR 之语义神经机器翻译', 'ru': 'Семантический нейронный машинный перевод с использованием AMR', 'hi': 'शब्दार्थ तंत्रिका मशीन अनुवाद AMR का उपयोग कर', 'ga': 'Aistriúchán Meaisín Séimeantach Néarach ag Úsáid AMR', 'ka': 'Name', 'el': 'Σημαντική Νευρική Μηχανική Μετάφραση χρησιμοποιώντας AMR', 'hu': 'Szemantikus neurális gépi fordítás AMR használatával', 'kk': 'AMR қолданатын Semantic Neural Machine аудармасы', 'it': 'Traduzione automatica neurale semantica utilizzando AMR', 'mk': 'Семантична неврална машина за превод користејќи AMR', 'lt': 'Semantinės neurologinės mašinos vertimas naudojant AMR', 'ms': 'Terjemahan Mesin Neural Semantic menggunakan AMR', 'ml': 'AMR ഉപയോഗിക്കുന്ന സെമാന്റിക് നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷ', 'mt': 'Traduzzjoni Semantika ta’ Magna Newrali li tuża AMR', 'mn': 'АМР хэрэглэх Semantic Neural Machine Translation', 'pl': 'Semantyczne neuronowe tłumaczenie maszynowe za pomocą AMR', 'no': 'Semantisk neuralmaskinsomsetjing ved bruk av AMR', 'ro': 'Traducere automată neutră semantică folosind AMR', 'sr': 'Semantièna neuronska prevoda sa AMR-om', 'si': 'AMR පාවිච්චි කරන්න සෙමැන්ටික් න්\u200dයූරල් මැෂින් පරිවර්තනය', 'so': 'Semantic Neural Machine Translation Using AMR', 'sv': 'Semantisk neural maskinöversättning med AMR', 'ta': 'AMR பயன்படுத்தி செமாண்டிக் நெயுரல் மொழிபெயர்ப்பு', 'ur': 'سیمنٹی نیورال ماشین ترجمه AMR کی استعمال کرتی ہے', 'uz': 'Name', 'vi': 'Dịch sang thần kinh trung học Sử dụng AMR', 'bg': 'Семантичен неврален машинен превод с помощта на АМР', 'hr': 'Semantična neurološka prevoda korištenja AMR', 'nl': 'Semantische Neurale Machine Translation met AMR', 'da': 'Semantisk neural maskinoversættelse ved hjælp af AMR', 'de': 'Semantische neuronale maschinelle Übersetzung mit AMR', 'id': 'Terjemahan Mesin Neural Semantik Menggunakan AMR', 'fa': 'ترجمه ماشین عصبی از استفاده از AMR', 'ko': 'AMR 기반 의미 신경 기계 번역', 'tr': 'AMR ullanýan Semantik Neural Maşynyň terjimesi', 'sw': 'Tafsiri ya Mashine ya Neural kwa kutumia AMR', 'af': 'Semantiese neurale masjien vertaling wat gebruik AMR', 'sq': 'Translation Semantik Neural Machine Using AMR', 'am': 'ትርጉም', 'bn': 'AMR ব্যবহার করে সেমান্টিক নিউরাল মেশিন অনুবাদ', 'hy': 'Սեմանտիկ նյարդային մեքենայի թարգմանություն օգտագործելով AMR', 'az': 'AMR istifad톛sind톛 Semantik N칬ral Makina 칂eviri', 'bs': 'Semantična neuronska prevoda sa AMR-om', 'ca': 'Traducció Semàtica de Màquines Neurals Utilizant AMR', 'cs': 'Sémantický neuronový strojový překlad pomocí AMR', 'et': 'Semantiline neuraalne masintõlge AMR abil', 'fi': 'Semanttinen hermojen konekäännös AMR:n avulla', 'jv': 'semanti Nyural Majin Terjamahan kang amR', 'sk': 'Semantični nevralni strojni prevod z uporabo AMR', 'ha': 'translation', 'he': 'שימוש במכונה נוירולית סמנטית', 'bo': 'Semantic Neural Machine Translation using AMR'}
{'en': 'It is intuitive that semantic representations can be useful for machine translation, mainly because they can help in enforcing meaning preservation and handling data sparsity (many sentences correspond to one meaning) of machine translation models. On the other hand, little work has been done on leveraging semantics for neural machine translation (NMT). In this work, we study the usefulness of AMR (abstract meaning representation) on NMT. Experiments on a standard English-to-German dataset show that incorporating AMR as additional knowledge can significantly improve a strong attention-based sequence-to-sequence neural translation model.', 'pt': 'É intuitivo que as representações semânticas possam ser úteis para a tradução automática, principalmente porque podem ajudar na preservação do significado e no tratamento da escassez de dados (muitas frases correspondem a um significado) de modelos de tradução automática. Por outro lado, pouco trabalho foi feito para alavancar a semântica para tradução automática neural (NMT). Neste trabalho, estudamos a utilidade da AMR (representação de significado abstrato) na NMT. Experimentos em um conjunto de dados padrão de inglês para alemão mostram que incorporar AMR como conhecimento adicional pode melhorar significativamente um modelo de tradução neural de sequência a sequência baseado em atenção.', 'fr': "Il est intuitif que les représentations sémantiques peuvent être utiles pour la traduction automatique, principalement parce qu'elles peuvent aider à renforcer la préservation du sens et à gérer la dispersion des données (de nombreuses phrases correspondent à une seule signification) des modèles de traduction automatique. D'autre part, peu de travail a été fait sur l'utilisation de la sémantique pour la traduction automatique neuronale (NMT). Dans ce travail, nous étudions l'utilité de l'AMR (représentation abstraite du sens) sur la NMT. Des expériences sur un ensemble de données standard de l'anglais vers l'allemand montrent que l'intégration de la RAM en tant que connaissances supplémentaires peut améliorer de manière significative un modèle de traduction neuronale séquence-séquence à séquence basé sur l'attention.", 'ar': 'من البديهي أن التمثيلات الدلالية يمكن أن تكون مفيدة للترجمة الآلية ، وذلك أساسًا لأنها يمكن أن تساعد في فرض الحفاظ على المعنى والتعامل مع تباين البيانات (العديد من الجمل تتوافق مع معنى واحد) لنماذج الترجمة الآلية. من ناحية أخرى ، تم إنجاز القليل من العمل على الاستفادة من الدلالات للترجمة الآلية العصبية (NMT). في هذا العمل ، ندرس فائدة AMR (تمثيل المعنى المجرد) على NMT. تُظهر التجارب على مجموعة بيانات قياسية من الإنجليزية إلى الألمانية أن دمج AMR كمعرفة إضافية يمكن أن يحسن بشكل كبير نموذج ترجمة عصبية قوي قائم على الانتباه من التسلسل إلى التسلسل.', 'es': 'Es intuitivo que las representaciones semánticas pueden ser útiles para la traducción automática, principalmente porque pueden ayudar a reforzar la preservación del significado y a gestionar la escasez de datos (muchas oraciones corresponden a un significado) de los modelos de traducción automática. Por otro lado, se ha trabajado poco en el aprovechamiento de la semántica para la traducción automática neuronal (NMT). En este trabajo, estudiamos la utilidad de la AMR (representación de significado abstracto) en la NMT. Los experimentos en un conjunto de datos estándar de inglés a alemán muestran que la incorporación de AMR como conocimiento adicional puede mejorar significativamente un modelo de traducción neuronal de secuencia a secuencia basado en la atención.', 'hi': 'यह सहज ज्ञान युक्त है कि शब्दार्थ प्रतिनिधित्व मशीन अनुवाद के लिए उपयोगी हो सकता है, मुख्य रूप से क्योंकि वे मशीन अनुवाद मॉडल के अर्थ संरक्षण को लागू करने और डेटा स्पार्सिटी (कई वाक्य एक अर्थ के अनुरूप हैं) को संभालने में मदद कर सकते हैं। दूसरी ओर, तंत्रिका मशीन अनुवाद (एनएमटी) के लिए शब्दार्थ का लाभ उठाने पर बहुत कम काम किया गया है। इस काम में, हम NMT पर AMR (अमूर्त अर्थ प्रतिनिधित्व) की उपयोगिता का अध्ययन करते हैं। एक मानक अंग्रेजी-से-जर्मन डेटासेट पर प्रयोगों से पता चलता है कि अतिरिक्त ज्ञान के रूप में एएमआर को शामिल करने से एक मजबूत ध्यान-आधारित अनुक्रम-से-अनुक्रम तंत्रिका अनुवाद मॉडल में काफी सुधार हो सकता है।', 'ru': 'Интуитивно понятно, что семантические представления могут быть полезны для машинного перевода, главным образом потому, что они могут помочь в обеспечении сохранения смысла и обработке разреженности данных (многие предложения соответствуют одному значению) моделей машинного перевода. С другой стороны, мало было сделано для того, чтобы использовать семантику для нейронного машинного перевода (НМП). В этой работе мы изучаем полезность АМР (абстрактного смыслового представления) на НМТ. Эксперименты на стандартном английском-немецком наборе данных показывают, что включение АМР в качестве дополнительного знания может значительно улучшить сильную модель нейронной трансляции на основе последовательности, основанной на внимании.', 'ja': '意味表現が機械翻訳に有用であることは直感的である。これは主に、意味の保存を強制し、機械翻訳モデルのデータの乏しさ（多くの文は1つの意味に対応する）を処理するのに役立つからである。一方、神経機械翻訳（ NMT ）のセマンティクスを活用する作業はほとんど行われていない。本研究では、NMTにおけるAMR （抽象的意味表現）の有用性を研究する。標準的な英語からドイツ語へのデータセットの実験では、追加の知識としてAMRを組み込むことで、強い注意力に基づく配列間ニューラル翻訳モデルを大幅に改善することができることが示されています。', 'zh': '直观曰:语义之于机器翻译也,可以助强制执行机器翻译存数疏(众句应)。 其一,用语义神经机器翻译(NMT)所为甚寡。 于是考之AMR(象之义)有用于NMT。 英语至德语数集之实验,以AMR为附益之知,显改基于注意之强序神经译模形。', 'ga': 'Tá sé iomasach gur féidir le léirithe shéimeantacha a bheith úsáideach le haghaidh aistriúchán meaisín, go príomha toisc go bhféadann siad cuidiú le caomhnú brí a fhorfheidhmiú agus le láimhseáil ganntanas sonraí (comhfhreagraíonn go leor abairtí do bhrí amháin) samhlacha meaisín-aistriúcháin. Ar an láimh eile, is beag obair atá déanta ar shéimeantaic a ghiaráil le haghaidh aistriúchán meaisín néaraíoch (NMT). Sa obair seo, déanaimid staidéar ar a úsáidí atá AMR (léiriú teibí brí) ar NMT. Léiríonn turgnaimh ar thacar sonraí caighdeánach Béarla-go-Gearmáinis gur féidir feabhas suntasach a chur ar mhúnla láidir aistriúcháin néar-seicheamh-go-seicheamh atá bunaithe ar aird, trí AMR a ionchorprú mar eolas breise.', 'ka': 'ინტევიტიურია, რომ სემონტიკური გამოსახულებები შეიძლება იყოს საჭირო მანქანის გარგულისთვის, რადგან ისინი შეიძლება დახმარება მანქანის გარგულისთვის შესაძლებლობად მონაცემების შესახებ და დაკავშირ მეორე მხოლოდ, პატარა სამუშაო გავაკეთება ნეიროლური მანქანის გარგულისთვის (NMT) სიმენტიკაში. ამ სამუშაოში, ჩვენ NMT-ში AMR (აბსტრაქტური სიტყვების გამოყენება) გამოყენებელობას ვისწავლით. სტანდარტური ანგლისური და გერმანური მონაცემების მოცემების გამოცდილებები აჩვენებენ, რომ AMR-ს დაყენება როგორც დამატებული მეცნიერები შეუძლია მნიშვნელოვანად უფრო უფრო მე', 'el': 'Είναι διαισθητικό ότι οι σημασιολογικές αναπαραστάσεις μπορούν να είναι χρήσιμες για τη μηχανική μετάφραση, κυρίως επειδή μπορούν να βοηθήσουν στην επιβολή της διατήρησης νοήματος και του χειρισμού της σπανιότητας δεδομένων (πολλές προτάσεις αντιστοιχούν σε ένα νόημα) των μοντέλων μηχανικής μετάφρασης. Από την άλλη πλευρά, έχει γίνει μικρή εργασία για τη χρήση της σημασιολογίας για τη νευρωνική μηχανική μετάφραση (NMT). Στην παρούσα εργασία, μελετάμε τη χρησιμότητα της ΑΜR (αφηρημένης συμβολικής αναπαράστασης) στην NMT. Τα πειράματα σε ένα τυποποιημένο σύνολο δεδομένων από Αγγλικά προς Γερμανικά δείχνουν ότι η ενσωμάτωση της ΑΜR ως συμπληρωματικής γνώσης μπορεί να βελτιώσει σημαντικά ένα ισχυρό μοντέλο μετάφρασης αλληλουχίας σε αλληλουχία βασισμένο στην προσοχή.', 'hu': 'intuitív, hogy a szemantikai reprezentációk hasznosak lehetnek a gépi fordításban, főként azért, mert segíthetnek a gépi fordítási modellek jelentésének megőrzésében és kezelésében (sok mondat egy jelentésnek felel meg). Másrészről kevés munkát végeztünk a neurális gépi fordítás (NMT) szemantikájának kihasználásán. Ebben a munkában az AMR (absztrakt jelentésreformáció) hasznosságát vizsgáljuk NMT-n. Egy szabványos angol-német adatkészleten végzett kísérletek azt mutatják, hogy az AMR kiegészítő tudásként való beépítése jelentősen javíthatja az erős figyelem-alapú szekvencia-szekvencia neurális fordítási modellt.', 'it': "È intuitivo che le rappresentazioni semantiche possano essere utili per la traduzione automatica, principalmente perché possono aiutare a far rispettare la conservazione del significato e gestire la scarsità dei dati (molte frasi corrispondono a un significato) dei modelli di traduzione automatica. D'altra parte, poco lavoro è stato fatto per sfruttare la semantica per la traduzione automatica neurale (NMT). In questo lavoro, studiamo l'utilità di AMR (rappresentazione astratta del significato) su NMT. Esperimenti su un set di dati standard inglese-tedesco mostrano che incorporare AMR come conoscenza aggiuntiva può migliorare significativamente un forte modello di traduzione neurale sequenza-sequenza basato sull'attenzione.", 'kk': 'Семантикалық таңбалар машинаны аудару үшін пайдалы болуы мүмкін, негізінде өйткені олар мақсатты деректерді сақтау және қамтамасыз ету үшін көмектесе алады (көп сөздер бір мәліметке сәйкес келетін) машинаны аудару ү Біріншіден, невралдық компьютерді аудару (NMT) үшін симантикалық жұмыс істеді. Бұл жұмыс ішінде, біз AMR (абстракты мәліметті) NMT жұмысының пайдалығын зерттейміз. Стандартты ағылшын тілінен неміс деректер жиынының тәжірибелері AMR дегенді қосымша білім ретінде қосу үшін күшті нақты ретінде негізделген невралдық аудару үлгісін өзгерте алады.', 'ms': 'Ia adalah intuitif bahawa perwakilan semantik boleh berguna untuk terjemahan mesin, terutamanya kerana ia boleh membantu dalam memaksa makna penyimpanan dan mengendalikan kecepatan data (banyak kalimat sepadan dengan satu makna) bagi model terjemahan mesin. Di sisi lain, sedikit kerja telah dilakukan untuk menggunakan semantik untuk terjemahan mesin saraf (NMT). Dalam kerja ini, kami mempelajari kebaikan AMR (perwakilan makna abstrak) pada NMT. Eksperimen pada set data bahasa Inggeris ke Jerman piawai menunjukkan bahawa mengangkut AMR sebagai pengetahuan tambahan boleh meningkatkan secara signifikan model terjemahan saraf berdasarkan perhatian yang kuat.', 'ml': 'മെഷിന്\u200d പരിഭാഷയ്ക്ക് വേണ്ടി സെമാന്റിക് പ്രതിനിധികള്\u200dക്ക് പ്രയോജനപ്പെടാന്\u200d സാധിക്കുന്നതാണ്, പ്രധാനപ്പെട്ട കാരണം അവര്\u200dക്ക് മെഷിന്\u200d പരിഭാഷകളുടെ അർഥ മറുവശത്ത് ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷയ്ക്ക് വേണ്ടി സെമാന്റിക്സ് ലൈവര്\u200dജ് ചെയ്തിരിക്കുന്നു ഈ പ്രവര്\u200dത്തനത്തില്\u200d നമ്മള്\u200d NMT-ല്\u200d AMR-ന്റെ ഉപയോഗങ്ങള്\u200d പഠിക്കുന്നു. ഒരു സാധാരണ ഇംഗ്ലീഷ്-ലേക്ക്-ജര്\u200dമ്മന്\u200d ഡാറ്റാസെറ്റിലെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു, കൂടുതല്\u200d അറിവുകള്\u200d എഎംആര്\u200d ചേര്\u200dക്കുന്നത്', 'lt': 'Įsivaizdu, kad semantiniai rodmenys gali būti naudingi vertimui mašinomis, daugiausia todėl, kad jie gali padėti užtikrinti mašin ų vertimo modelių reikšmės išsaugojimą ir tvarkymą duomenų nedažnumu (daugelis sakinių atitinka vieną reikšmę). Kita vertus, nedidelis darbas buvo atliktas dėl semantikos sverto nervinių mašinų vertimui (NMT). In this work, we study the usefulness of AMR (abstract meaning representation) on NMT.  Experiments on a standard English-to-German dataset show that incorporating AMR as additional knowledge can significantly improve a strong attention-based sequence-to-sequence neural translation model.', 'mk': 'Интуитивно е дека семантичките претставувања можат да бидат корисни за машински превод, главно затоа што можат да помогнат во спроведувањето на значењето зачувување и управуваое со скратноста на податоците (многу реченици соодветуваат на едно значење) на машинските преводни мо On the other hand, little work has been done on leveraging semantics for neural machine translation (NMT).  Во оваа работа ја проучуваме корисноста на АМР (апстрактно значење претставување) на НМТ. Experiments on a standard English-to-German dataset show that incorporating AMR as additional knowledge can significantly improve a strong attention-based sequence-to-sequence neural translation model.', 'mt': 'Huwa intwittiv li r-rappreżentazzjonijiet semantiċi jistgħu jkunu utli għat-traduzzjoni bil-magna, l-aktar minħabba li jistgħu jgħinu fl-infurzar tat-tifsira tal-preservazzjoni u l-immaniġġjar tal-iskarsezza tad-dejta (ħafna sentenzi jikkorrispondu għal tifsira waħda) tal-mudelli tat-traduzzjoni bil-magna. Min-naħa l-oħra, ftit sar xogħol fuq l-ingranaġġ tas-semantika għat-traduzzjoni tal-magni newrali (NMT). F’din il-ħidma, nistudjaw l-utilità tal-AMR (rappreżentazzjoni tat-tifsira astratta) fuq l-NMT. L-esperimenti fuq sett ta’ dejta standard Ingliż-Ġermaniż juru li l-inkorporazzjoni tal-AMR bħala għarfien addizzjonali tista’ ttejjeb b’mod sinifikanti mudell ta’ traduzzjoni newrali b’sekwenza għal sekwenza bbażat fuq l-attenzjoni b’mod qawwi.', 'mn': 'Машин хөрөнгө оруулалт болон өгөгдлийг хадгалах болон удирдах боломжтой гэдэг нь ойлгомжтой. Яагаад гэвэл тэд машины хөрөнгө оруулалт загварын хэмжээсүүдийг хадгалах боломжтой болохоор туслах боломжтой. Нөгөө талаар, мэдрэлийн машин хөрөнгө оруулахын тулд жижиг ажил хийгдсэн. Энэ ажлын тулд бид NMT дээр АМР-ын хэрэглээнийг судалдаг. Англи болон Германы стандарт өгөгдлийн сангийн туршилтын туршилт нь AMR-г нэмэлт мэдлэг гэх мэт нэмэлт мэдлэг болгон анхаарлын дарааллаас дарааллаар анхаарлын дарааллаар дамжуулан сэтгэл хөдлөлийн загварыг', 'no': 'Det er intuitivt at semantiske representasjonar kan vera nyttig for maskinsomsetjing, hovudsakelig fordi dei kan hjelpa for å gjera meningslagring og handtering av datasparsitet (mange setningar tilsvarar eitt mening) av maskinsomsetjingsmodular. On the other hand, little work has been done on leveraging semantics for neural machine translation (NMT). I denne arbeiden studerer vi nyttigheten av AMR (abstrakt meningsrepresentasjon) på NMT. Eksperimentar på eit standard dataset for engelsk til tysk viser at inkludering av AMR som ekstra kunnskap kan betydelig forbedra ein sterk oppmerksomsetjingsbasert sekvens-til-sekvens neuraloversettelsmodell.', 'pl': 'Jest intuicyjne, że reprezentacje semantyczne mogą być przydatne w tłumaczeniu maszynowym, głównie dlatego, że mogą pomóc w wymuszaniu zachowania znaczenia i obsłudze ograniczoności danych (wiele zdań odpowiada jednemu znaczeniu) modeli tłumaczenia maszynowego. Z drugiej strony, niewiele prac zostało zrobione nad wykorzystaniem semantyki do neuronowego tłumaczenia maszynowego (NMT). W niniejszej pracy badamy przydatność AMR (abstrakcyjna reprezentacja znaczenia) na NMT. Eksperymenty na standardowym zbiorze danych angielsko-niemieckim pokazują, że włączenie AMR jako dodatkowej wiedzy może znacznie poprawić silny model translacji sekwencji-sekwencji oparty na uwadze.', 'ro': 'Este intuitiv faptul că reprezentările semantice pot fi utile pentru traducerea automată, în principal pentru că pot ajuta la impunerea păstrării semnificațiilor și gestionarea spartății datelor (multe propoziții corespund unui semnificație) modelelor de traducere automată. Pe de altă parte, s-a făcut puține eforturi pentru valorificarea semanticii pentru traducerea automată neurală (NMT). În această lucrare, studiem utilitatea AMR (reprezentarea abstractă a semnificației) pe NMT. Experimentele pe un set standard de date engleză-germană arată că încorporarea AMR ca cunoștințe suplimentare poate îmbunătăți semnificativ un model de traducere neurală secvență-secvență bazat pe atenție.', 'sr': 'intuitivno je da semantičke predstave mogu biti korisne za prevod mašine, uglavnom zato što mogu pomoći u provedbi značaja očuvanja i rješavanja rezervnosti podataka (mnoge rečenice odgovaraju jednom smislu) modela prevoda mašine. S druge strane, napravljeno je mali rad na primjeni semantika za prevod neuralne mašine (NMT). U ovom poslu, proučavamo korisnost AMR (abstraktivna predstavljanja značenja) na NMT-u. Eksperimenti o standardnom setu podataka na engleskom i njemačkom pokazuju da uključivanje AMR kao dodatno znanje značajno može poboljšati jaki model neurološkog prevoda na pažnji na sekvenci.', 'si': 'ඒක සෙමාන්තික ප්\u200dරතිනිධානය ප්\u200dරයෝජනය වෙනුවෙන් ප්\u200dරයෝජනය වෙනුවෙන් ප්\u200dරයෝජනය වෙන්න පුළුවන්, විශේෂයෙන් ඔවුන්ට ප්\u200dරයෝජනය කරන්න අනිත් පැත්තෙන්, පුංචි වැඩ කරලා තියෙන්නේ න්\u200dයූරල් මැෂින් වාර්තාව (NMT) සඳහා සිමාන්තික විදි මේ වැඩේ අපි අධ්\u200dයානය කරන්නේ නිම්ටි වල AMR ගේ ප්\u200dරයෝජනය. ඉංග්\u200dරීසියෙන් ජර්මන් දත්ත සෙට් එකේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට AMR විශ්වාස කරන්න පුළුවන් විශේෂයෙන් බලන්', 'sv': 'Det är intuitivt att semantiska representationer kan vara användbara för maskinöversättning, främst för att de kan hjälpa till att upprätthålla betydelsebevarande och hantera datasparhet (många meningar motsvarar en mening) i maskinöversättningsmodeller. Å andra sidan har lite arbete gjorts med att utnyttja semantik för neural maskinöversättning (NMT). I detta arbete studerar vi användbarheten av AMR (abstrakt betydelserepresentation) på NMT. Experiment på en vanlig engelsk-tysk datauppsättning visar att införlivande av AMR som ytterligare kunskap avsevärt kan förbättra en stark uppmärksamhetsbaserad sekvens-till-sekvens neural översättningsmodell.', 'so': "Waxey muhiim u tahay in koontarooyinka semantika ay faa’iido u noqon karaan turjumaadda machine, khaaska darteed waxay ku caawin karaan in ay ku sameyn karaan sameynta macluumaadka badbaadada iyo dhaqdhaqaalaha macluumaadka (erayo badan oo u eg isku micneheeda). Hada kalena shaqada yar waxaa la sameeyay in la sameynayo semantika tarjumidda maskinada neurada (NMT). Markaas waxan waxaynu ka baranaynaa faa'iidada AMR (abstract meaning representation) ee NMT. Imtixaanka ku saabsan aqoonta afka Ingiriiska-Jarmalka waxaa muujiya in la soo geliyo AMR sida aqoonta dheeraad ah uu u beddeli karo tilmaamaha turjumidda neurada ee ku saleysan daryeelka aad u adag.", 'ta': 'இயந்திரத்தின் மொழிபெயர்ப்பு மொழிபெயர்ப்பிற்கு அர்த்தமுள்ளதாக இருக்கலாம் என்பதால் முக்கியமாக, கணினி மொழிபெயர்ப்பு மாதிரிகளின் பொருத்தமுள்ள பல வா மற்றொரு பக்கத்தில், புதிய இயந்திரம் மொழிபெயர்ப்புக்கு அரைமாற்றம் வழங்கும் சிறிய வேலை செய்யப்பட்டுள்ளது. In this work, we study the usefulness of AMR (abstract meaning representation) on NMT.  ஒரு இயல்பான ஆங்கிலத்தில் இருந்து ஜெர்மன் தரவுத்தளத்தில் உள்ள சோதனைகள் காட்டுகிறது AMR என்பது கூடுதல் அறிவு என்பது ஒரு வலிமையான கவனம் அடிப்படையில் உள்ள', 'ur': 'یہ منظور ہے کہ سیمنٹی نمایش ماشین ترجمہ کے لئے مفید ہو سکتی ہیں، زیادہ اس لئے کہ وہ مفید ترجمہ نمائندوں کے ذریعہ حفاظت کرنے اور حفاظت کرنے کے لئے مدد کرسکتے ہیں۔ دوسری طرف، نئورل ماشین ترجمہ (NMT) کے لئے سیمانٹیکوں کے ذریعے کم کام کیا گیا ہے۔ ہم اس کام میں NMT پر AMR کا فائدہ پڑھتے ہیں۔ ایک استاندارد انگلیسی سے جرمانی ڈیٹ سٹ پر تجربے دکھاتے ہیں کہ AMR کو اضافہ علم کے طور پر شامل کرتا ہے ایک مضبوط توجه کی سطح سے اضافہ کرتا ہے۔', 'uz': "Name Boshqa bir tomonda, neyron maskina tarjima qilish (NMT) uchun semantik yordamida ishlayapdi. Bu ishda biz NMT'da AMR (abstract representation) foydalanishni o'rganamiz. Name", 'vi': 'Theo trực giác thì các biểu tượng theo ngữ nghĩa có thể hữu dụng cho dịch thuật cỗ máy, chủ yếu bởi vì chúng có thể giúp sức sức thực hiện khả năng bảo tồn và xử lý thông tin Sơ sài (nhiều câu tương ứng với một ý nghĩa) của các mô hình dịch cỗ máy. Mặt khác, đã làm rất ít việc về thuật ngữ pháp điều khiển dịch cỗ máy thần kinh (NMB). Trong công việc này, chúng tôi nghiên cứu sự hữu ích của AMR (đại diện nghĩa trừu tượng) về NMT. Thí nghiệm trên một bộ dữ liệu Anh-Đức tiêu chuẩn cho thấy rằng chấp nhận AMR như là kiến thức bổ sung có thể cải thiện đáng kể một mô hình dịch thần kinh dựa trên tần số.', 'bg': 'Интуитивно е, че семантичните представи могат да бъдат полезни за машинния превод, главно защото те могат да помогнат за налагането на запазването на значението и обработката на оскъдността на данните (много изречения съответстват на едно значение) на моделите за машинен превод. От друга страна, малко работа е направена по усвояване на семантиката за невронен машинен превод (НМТ). В тази работа изследваме полезността на АМР (абстрактно представяне на значението) върху НМТ. Експерименти върху стандартен английски-немски набор от данни показват, че включването на АМР като допълнителни знания може значително да подобри силно базиран на вниманието модел на невронен превод последователност към последователност.', 'hr': 'intuitivno je da semantičke predstave mogu biti korisne za prevod strojeva, uglavnom zato što mogu pomoći u provedbi značaja očuvanja i rješavanja rezervnosti podataka (mnoge rečenice odgovaraju jednom smislu) modela prevoda strojeva. S druge strane, mali posao je obavljen na primjenu semantika za prevod neuralnih strojeva (NMT). U ovom poslu, proučavamo korisnost AMR (abstraktivno značenje) na NMT-u. Eksperimenti o standardnom setu podataka engleskog i njemačkog pokazuju da uključivanje AMR kao dodatno znanje značajno može poboljšati jaki model neurološkog prevoda na pozornosti osnovanog sekvencijom na sekvenciji.', 'nl': 'Het is intuïtief dat semantische representaties nuttig kunnen zijn voor machinevertaling, vooral omdat ze kunnen helpen bij het handhaven van betekenisbehoud en het omgaan met data sparsity (veel zinnen corresponderen met één betekenis) van machinevertaalmodellen. Aan de andere kant is er weinig werk gedaan aan het inzetten van semantiek voor neuronale machinevertaling (NMT). In dit werk bestuderen we het nut van AMR (abstract meaning representation) op NMT. Experimenten op een standaard Engels-Duitse dataset tonen aan dat het opnemen van AMR als aanvullende kennis een sterk aandachtsgebonden sequence-to-sequence neural translation model aanzienlijk kan verbeteren.', 'da': 'Det er intuitivt, at semantiske repræsentationer kan være nyttige til maskinoversættelse, hovedsageligt fordi de kan hjælpe med at håndhæve betydningsbevarelse og håndtere datasparthed (mange sætninger svarer til én betydning) af maskinoversættelsesmodeller. På den anden side er der ikke gjort meget arbejde med at udnytte semantik til neural maskinoversættelse (NMT). I dette arbejde undersøger vi nytten af AMR (abstrakt betydning repræsentation) på NMT. Eksperimenter på et almindeligt engelsk-tysk datasæt viser, at inddragelse af AMR som ekstra viden kan forbedre en stærk opmærksomhedsbaseret sekvens-til-sekvens neural oversættelsesmodel betydeligt.', 'de': 'Es ist intuitiv, dass semantische Repräsentationen für die maschinelle Übersetzung nützlich sein können, vor allem weil sie bei der Durchsetzung der Bedeutungserhaltung und beim Umgang mit Datenschwierigkeit (viele Sätze entsprechen einer Bedeutung) von maschinellen Übersetzungsmodellen helfen können. Auf der anderen Seite wurde wenig daran gearbeitet, Semantik für die neuronale maschinelle Übersetzung (NMT) einzusetzen. In dieser Arbeit untersuchen wir die Nützlichkeit von AMR (abstrakte Bedeutungsrepräsentation) auf NMT. Experimente an einem Standard-Englisch-Deutsch-Datensatz zeigen, dass die Einbeziehung von AMR als zusätzliches Wissen ein starkes aufmerksamkeitsbasiertes Sequenz-zu-Sequenz neuronales Translationsmodell signifikant verbessern kann.', 'ko': '직관적으로 말하자면 의미 표시는 기계 번역에 매우 유용하다. 주로 의미 표시는 의미 보존과 기계 번역 모델의 데이터 희소성을 강화하고 처리하는 데 도움이 되기 때문이다(많은 문장이 하나의 의미에 대응한다).다른 한편, 의미를 이용해 신경기계번역(NMT)을 하는 작업은 드물다.이 작업에서 우리는 AMR(추상적 의미 표시)의 NMT에서의 유용성을 연구했다.표준 영어에서 독일어 데이터 세트에서의 실험에 따르면 AMR을 추가 지식으로 사용하면 강력한 주의에 기반한 서열부터 서열 신경 번역 모델까지 현저하게 개선할 수 있다.', 'id': 'Ini intuitif bahwa represisi semantis dapat berguna untuk terjemahan mesin, terutama karena mereka dapat membantu memaksa arti penyimpanan dan menangani kecepatan data (banyak kalimat yang cocok dengan satu arti) dari model terjemahan mesin. Di sisi lain, sedikit pekerjaan telah dilakukan untuk menggunakan semantik untuk terjemahan mesin saraf (NMT). Dalam pekerjaan ini, kami mempelajari kebaikan AMR pada NMT. Eksperimen pada set data standar bahasa Inggris-Jerman menunjukkan bahwa memasukkan AMR sebagai pengetahuan tambahan dapat meningkatkan secara signifikan model terjemahan saraf berdasarkan perhatian yang kuat.', 'fa': 'این مفهوم است که نمایش\u200cهای semantic می\u200cتوانند برای ترجمه\u200cهای ماشین مفید باشند، در اصل زیرا می\u200cتوانند کمک کنند در عملکرد معنی حفاظت و کنترل ذخیره داده\u200cها (بسیاری از جمله\u200cها به یک معنی) از مدل ترجمه\u200cهای ماشین. از طرف دیگر، کارهای کوچک روی تغییرات سیمانتیک برای ترجمه ماشین عصبی (NMT) انجام شده است. در این کار، ما استفاده از AMR در NMT مطالعه می کنیم. تجربه\u200cهایی روی مجموعه داده\u200cهای انگلیسی و آلمانی استاندارد نشان می\u200cدهند که جمع آمریکا به عنوان علم اضافه می\u200cتواند یک مدل ترجمه\u200cهای عصبی با توجه بسیار قوی را بهتر کند.', 'sw': 'Ni muhimu kwamba maonesho ya kimapenzi yanaweza kuwa na manufaa kwa kutafsiri mashine, hasa kwa sababu wanaweza kusaidia kutekeleza maana ya kuhifadhi na kutumika taarifa (sentensi nyingi zinalinganisha na maana moja) ya modeli za tafsiri za mashine. Kwa upande mwingine, kazi ndogo imefanywa kwa kutumia miambo kwa ajili ya kutafsiri mashine ya ubongo (NMT). In this work, we study the usefulness of AMR (abstract meaning representation) on NMT.  Majaribio kwenye seti ya taarifa za kawaida za Kiingereza hadi Ujerumani yanaonyesha kuwa kuingiza AMR kwa kuwa maarifa ya ziada yanaweza kuboresha muundo wa tafsiri yenye msimamo mkali wa mfululizo wa mfululizo wa taratibu.', 'tr': "Semantik täzelikler maşynyň terjime edilmesi üçin ulanyp biljek üçin, ýöne sebäbi olar maşynyň terjime modelleriniň niýetlerini goramaga we golaýlamaga kömek edip bilýärler. Diňe ýagdaýda, neural maşynyň terjimesi (NMT) üçin semantik taýýarlanmak üçin kiçijik işlem edildi. Bu çalışmada, AMR'nin kullanımını NMT'de çalışıyoruz. Öň bellenen Iňlis-we Almança maglumatlary üçin örnekler AMR'i ekleýän bilim ýaly daşary baglanma täsirinde näyral terjime modelini gowylaşdyryp biler.", 'af': "Dit is intuitief dat semantiese voorstellings kan bruikbaar wees vir masjien vertaling, hoofsaaklik omdat hulle kan help in die verskaffing van betekenis om data sparsiteit te bewaar en te handtrek (baie setnings ooreenstemmende aan een betekening) van masjien vertaling modele. Aan die ander kant is die klein werk gedoen op die uitvoering van semantieke vir neurale masjien vertaling (NMT). In hierdie werk, ondersoek ons die gebruikerheid van AMR (abstrakte betekenis verteenwoording) op NMT. Eksperimente op 'n standaard Engels-na-Duitse datastel wys dat die inkorporering van AMR as addisionele kennis kan betekeurig 'n sterk aandag-gebaseerde sekvensie-na-sekvensie neurale vertalingsmodel verbeter.", 'sq': 'Është intuitive që përfaqësimet semantike mund të jenë të dobishme për përkthimin e makinave, kryesisht sepse ato mund të ndihmojnë në zbatimin e kuptimeve ruajtje dhe trajtimin e shpejtësisë së të dhënave (shumë fjalë korrespondojnë me një kuptim) të modeleve të përkthimit të makinave. On the other hand, little work has been done on leveraging semantics for neural machine translation (NMT).  Në këtë punë, ne studiojmë dobinë e AMR (përfaqësimin abstrakt të kuptimit) në NMT. Eksperimentet në një set të dhënash standard anglez-gjerman tregojnë se përfshirja e AMR si njohuri shtesë mund të përmirësojë në mënyrë të konsiderueshme një model të fortë të përkthimit nervor nga sekuenca në sekuencë bazuar në vëmendje.', 'am': 'የሳንሱር ትርጉም ሞዴላዎችን በመጠበቅ እና የዳታ ማቀናቀል ማግኘት ማድረግ ይችላል፡፡ በሌላው ክፍል፣ ጥቂት ሥራ ለኔural machine translation (NMT) ሲሰጥ ነው፡፡ በዚህ ሥራ በNMT ላይ የAMR ጥቅም እናስተምራለን፡፡ በጤናዊ እንግሊዘኛ-ወደ ጀርመን-ጀርመን ዳታተር ላይ የሚደረግ ፈተናዎች አሜሪካን እንደተጨማሪ እውቀት ሲያሳየው የጽኑ ትኩረት-ለግንኙነት የኔural ትርጉም ሞዴል በማሳመር ይችላል፡፡', 'hy': 'Ինտուիտիվ է, որ սեմանտիկ ներկայացումները կարող են օգտակար լինել մեքենայի թարգմանման համար, հիմնականում այն պատճառով, որ նրանք կարող են օգնել մեքենայի թարգմանման մոդելների իմաստը պահպանելու և վերահսկելու համար: Մյուս կողմից, քիչ աշխատանք է արվել նյարդային մեքենայի թարգմանման (NMT) սեմանտիկայի օգտագործման վրա: Այս աշխատանքում մենք ուսումնասիրում ենք ԱՄՌ-ի օգտակարությունը NMT-ի վրա: Անգլերենի-գերմանացի ստանդարտ տվյալների փորձարկումները ցույց են տալիս, որ AMR-ի ներառումը որպես ավելացված գիտելիք կարող է նշանակալի բարելավել ուշադրության հիմնված ուշադրության հաջորդականության նյարդային թարգմանման մոդելը:', 'az': "Semantik göstəricilər maşın tercüməsinə faydalı olar, çünki onlar maşın tercüməsi modellerinin məlumatı qorumaq və məlumatların təhlükəsizlik etmək üçün kömək edə bilərlər. Digər tərəfindən, nöral maşına çevirilən (NMT) semantik istifadə etmək üçün küçük işlər yapıldı. Bu işdə, biz NMT-də AMR (abstrakt anlama göstəricisi) faydalanılığını öyrənirik. Standardlı İngilizə-Almanca verilən quruluğu təcrübələrin AMR'i əlavə bilgi kimi daxil edilən təcrübələrin çox qüvvətli təcrübə-sıralama nöral tercümə modelini daha yaxşılaşdıra bilər.", 'bn': 'এটা বুদ্ধিমান যে মেশিন অনুবাদের জন্য সেমেন্টিক প্রতিনিধিত্ব ব্যবহার করতে পারে, বিশেষ করে কারণ তারা মেশিন অনুবাদের মডেলের মানে সংরক্ষণ এবং হাতে সংরক্ষণ এবং স অন্যদিকে, নিউরেল মেশিন অনুবাদের জন্য সেম্যান্টিক্স প্রদান করার জন্য ছোট কাজ করা হয়েছে। এই কাজে আমরা এনএমটিতে এএমআরের ব্যবহার গবেষণা করছি (এমআরের প্রতিনিধিত্বের মানে প্রতিনিধিত্ব) একটি স্ট্যান্ডার্ড ইংরেজি থেকে জার্মান ডাটাসেটে পরীক্ষার পরীক্ষা দেখা যাচ্ছে যে এএমআর যোগাযোগ করা হচ্ছে যেহেতু আরো জ্ঞান যোগাযোগ করা হচ্ছে', 'bs': 'intuitivno je da semantičke predstave mogu biti korisne za prevod strojeva, uglavnom zato što mogu pomoći u provedbi značaja očuvanja i rješavanja rezervnosti podataka (mnoge rečenice odgovaraju jednom smislu) modela prevoda strojeva. S druge strane, mali posao je obavljen na primjenu semantika za prevod neuralnih strojeva (NMT). U ovom poslu, proučavamo korisnost AMR (abstraktivna predstavljanja značenja) na NMT-u. Eksperimenti o standardnom setu podataka na engleskom i njemačkom pokazuju da uključivanje AMR kao dodatno znanje značajno može poboljšati jaki model neurološkog prevoda na pozornosti osnovanog sekvencijom na sekvenciji.', 'ca': "És intuïtiu que les representacions semàntiques poden ser útils per a la traducció màquina, principalment perquè poden ajudar a aplicar el sentit de conservació i manipulació de l'escassetat de dades (moltes frases corresponden a un sentit) dels models de traducció màquina. D'altra banda, no s'ha fet gaire feina en aprofitar la semàntica per a la traducció neural de màquines (NMT). En aquest treball estudiem l'utilitat de l'AMR (representació abstracta del significat) en la NMT. Els experiments d'un conjunt de dades estàndard anglès-alemanès demostren que incorporar AMR com coneixement adicional pot millorar significativament un model de traducció neuronal basat en seqüència a seqüència.", 'cs': 'Je intuitivní, že sémantické reprezentace mohou být užitečné pro strojový překlad, zejména proto, že mohou pomoci při vynucování uchovávání významu a manipulaci s datovou řídkostí (mnoho vět odpovídá jednomu významu) modelů strojového překladu. Na druhé straně bylo provedeno málo práce na využití sémantiky pro neuronový strojový překlad (NMT). V této práci studujeme užitečnost AMR (abstraktní reprezentace významu) na NMT. Experimenty na standardním anglicko-německém datovém souboru ukazují, že začlenění AMR jako dalších znalostí může výrazně zlepšit silný model sekvence-sekvence založený na pozornosti.', 'et': 'On intuitiivne, et semantilised esitused võivad olla masintõlke jaoks kasulikud, peamiselt seetõttu, et need aitavad kaasa masintõlkemudelite tähenduste säilitamisele ja andmete vähesuse käsitlemisele (paljud laused vastavad ühele tähendusele). Teisest küljest on tehtud vähe tööd neuromasintõlke semantika kasutamisel. Käesolevas töös uurime AMR (abstraktse tähenduse representatsiooni) kasulikkust NMT-l. Standardse inglise-saksa andmekogumi eksperimendid näitavad, et AMR lisateadmistena võib märkimisväärselt parandada tugevat tähelepanu põhinevat järjestuse-järjestuse neuraalse tõlke mudelit.', 'fi': 'On intuitiivista, että semanttiset esitykset voivat olla hyödyllisiä konekäännöksessä, lähinnä siksi, että ne voivat auttaa vahvistamaan merkitysten säilyttämistä ja käsittelemään konekäännösmallien datan niukkuutta (monet lauseet vastaavat yhtä tarkoitusta). Toisaalta semantiikan hyödyntämisessä neurokonekäännöksessä (NMT) on tehty vähän työtä. Tässä työssä tutkitaan AMR:n (abstraktin merkityksen representation) hyödyllisyyttä NMT:ssä. Kokeet standardista englannin-saksa-aineistosta osoittavat, että AMR:n sisällyttäminen lisätietona voi merkittävästi parantaa vahvaa huomiota perustuvaa sekvenssin-sekvenssin neurokäännösmallia.', 'jv': 'Wis Nang kabèh-kabèh, akeh sing gawe lan sematik nggawe sistem sing nyeraning alat kanggo tarjamahan alat (NMT). Nang barêng-barêng iki, kéné uwis bantên seneng penggunaké AM R (ukuran alêb dilangan gambar) ning NMT. Isopo sing ngengambar data set Inggris-kanggo German kuwi nggawe barang gambar kuwi mau ngerasai AM R dumadhi kanggo ngerasai kesempatan sing bisa bantuan nguasai seneng opera sing usul tapi tarjamahan tapi tanggal sekondir -nganggo sekondir', 'ha': '@ info: whatsthis Ga da na guda, an aikata aiki kaɗan a kan kudai semantiki wa fassarar maɓallin neural (NMT). Daga wannan aikin, munã karatun amfani da AMR (mai raɗawa da fassarar aiki) a kan NMT. Tajararin a kan tsarin da aka daidaita ta Ingiriya-zuwa-Jarman yana nuna cewa, ta shigar da AMR kamar da ilmi ƙaranci za ta kyautata wani misãlin fassarar-daban-zuwa-sequence mai ƙarfi ga fassarar neural.', 'sk': 'Intuitivno je, da so semantične predstavitve lahko koristne za strojno prevajanje, predvsem zato, ker lahko pomagajo pri uveljavljanju ohranjanja pomena in obdelavi redkosti podatkov (mnogi stavki ustrezajo enemu pomenu) modelov strojnega prevajanja. Po drugi strani pa je bilo malo dela opravljenega na področju izkoriščanja semantike za nevronsko strojno prevajanje (NMT). V tem delu preučujemo uporabnost AMR (abstraktna predstavitev pomena) na NMT. Eksperimenti na standardnem angleško-nemškem naboru podatkov kažejo, da lahko vključitev AMR kot dodatnega znanja bistveno izboljša močan model nevronskega prevajanja, ki temelji na pozornosti.', 'bo': 'འདི་ལྟ་བུ ཕྱོགས་གཞན་ཞིག་ནས་(NMT)ནང་དུ་སྐྱེས་ཆེན་ལག་ལེན་བྱེད་པའི་semantics་ལ་ལས་ཀ་ཆུང་ཆུང་ཞིག་བྱས་ཡོད། འོན་ཀྱང་། ང་ཚོས་NMT ནང་གི་AMR(abstract meaning representation) ཡི་སྤྱོད་མཁན་འདི་ལྟ་བུ་བཏོན་ཡོད། Experiments on a standard English-to-German dataset show that incorporating AMR as additional knowledge can significantly improve a strong attention-based sequence-to-sequence neural translation model.', 'he': 'זה אינטואיטיבי שהמייצגים סמנטיים יכולים להיות שימושיים לתרגום מכונות, בעיקר בגלל שהם יכולים לעזור להכריח משמעות שמירה ומטפל בהחלטת נתונים (משפטים רבים מתאימים למחשבה אחת) של מודלים התרגום מכונות. מצד שני, נעשה מעט עבודה על השימוש בסמנטיקה לתרגום מכונות עצביות (NMT). בעבודה הזאת, אנו לומדים את השימוש של AMR (מייצג משמעות אוסטרקטית) על NMT. ניסויים על קבוצת נתונים אנגלית-לגרמנית סטנדרטית מראים שמכילת AMR כידע נוסף יכולה לשפר באופן משמעותי מודל התרגום עצבי מבוסס על תשומת לב חזק.'}
{'en': 'Joint Transition-Based Models for Morpho-Syntactic Parsing : Parsing Strategies for MRLs and a Case Study from Modern Hebrew', 'ar': 'النماذج المستندة إلى الانتقال المشتركة للتحليل الصرفي النحوي: استراتيجيات التحليل للقواعد الحدودية القصوى للمخلفات ودراسة حالة من اللغة العبرية الحديثة', 'es': 'Modelos conjuntos basados en la transición para el análisis morfosintáctico: estrategias de análisis para los LMR y un estudio de caso del hebreo moderno', 'pt': 'Modelos baseados em transição conjunta para análise morfossintática: estratégias de análise para MRLs e um estudo de caso do hebraico moderno', 'fr': "Modèles communs basés sur la transition pour l'analyse syntaxique morpho-syntaxique\xa0: stratégies d'analyse pour les LMR et étude de cas de l'hébreu moderne", 'ja': 'Morpho - Syntactic Parsingのためのジョイントトランジションベースモデル： MRLのための解析戦略と現代ヘブライ語のケーススタディ', 'ru': 'Совместные переходные модели для морфо-синтаксического анализа: стратегии анализа для MRL и тематическое исследование на современном иврите', 'hi': 'Morpho-Syntactic पार्सिंग के लिए संयुक्त संक्रमण-आधारित मॉडल: MRLs के लिए पार्सिंग रणनीतियों और आधुनिक हिब्रू से एक केस स्टडी', 'zh': '盖转换之合形句法解析模形:MRL 之解析策,与今希伯来语之例', 'ga': 'Comhshamhlacha Tras-Bhunaithe le haghaidh Parsála Morpho-Syntactic: Straitéisí Parsála le haghaidh MRLanna agus Cás-staidéar ón Nua-Eabhrais', 'hu': 'Közös átmeneti modellek a morfo-szintaktikus értelmezéshez: az MRL-ekre vonatkozó értelmezési stratégiák és a modern héber esettanulmány', 'ka': 'Name', 'el': 'Κοινά μεταβατικά μοντέλα για τη Μορφο-Συντακτική Ανάλυση: Στρατηγικές ανάλυσης για ΑΟΚ και μια μελέτη περίπτωσης από τη σύγχρονη εβραϊκή γλώσσα', 'kk': 'Морфо- синтактикалық талдау үшін біріктірілген трансиациялық негізделген үлгілер: MRL- тың талдау стратегиялары мен Қазіргі Иврит тілінен әріпті оқу үлгілері', 'it': "Modelli congiunti basati sulla transizione per l'analisi morfo-sintattica: strategie di analisi per gli LMR e un caso di studio dall'ebraico moderno", 'mk': 'Joint Transition-Based Models for Morpho-Syntactic Parsing: Parsing Strategies for MRLs and a Case Study from Modern Hebrew', 'ms': 'Model Berdasarkan Peralihan Berkongsi untuk Menghurai Morfo-Sintaktik: Strategi Menghurai MRL dan kajian kes dari Hebrew Modern', 'ml': 'മോര്\u200dഫോ- സിന്റാക്റ്റിക്ക് പാര്\u200dസിങ്ങിനുള്ള മോഡലുകള്\u200dക്കു് യൂണ്ട് ചെയ്യുക: എംആര്\u200dഎല്\u200dസിനുള്ള സ്ട്രേറ്റേജികള്\u200d പാര്\u200d', 'mt': 'Mudelli Konġunti bbażati fuq it-Tranżizzjoni għall-Analiżi Morfo-Sintattika: Strateġiji ta’ Analiżi għall-MRLs u Studju ta’ Każijiet minn Ebrej Modern', 'pl': 'Wspólne modele przejściowe analizy morfo-syntaktycznej: strategie analizy NDP i studium przypadku z nowoczesnego hebrajskiego', 'mn': 'Морфо-синтактик шинжилгээний төлөвлөгөө: MRL-ын шинжилгээ, Орчин Хеврийн Судалгааны судалгаа', 'lt': 'Bendri pereinamojo laikotarpio modeliai morfosintaktiniam analizavimui: MRL analizavimo strategijos ir šiuolaikinio hebrajų atvejų tyrimas', 'ro': 'Modele comune bazate pe tranziție pentru analizarea morfo-sintactică: strategii de analizare a LMR-urilor și un studiu de caz din ebraică modernă', 'so': 'Joint Transition-Based Models for Morpho-Syntactic Parsing: Parsing Strategies for MRLs and a Case Study from Modern Hebrew', 'sv': 'Gemensamma övergångsbaserade modeller för morfosyntaktisk tolkning: tolkningsstrategier för MRL och en fallstudie från modern hebreiska', 'ta': 'மோர்போக்- ஒத்திசைவு பாடலுக்கான மாற்றம்- அடிப்படையான மாதிரிகள்', 'no': 'Joint Transition-Based Models for Morpho-Syntactic Tolking: Tolking Strategies for MRLs and a Case Study from Modern Hebrew', 'si': 'Name', 'ur': 'Morpho-Syntactic Parsing کے لئے جوئن ٹرانسیشن-بنسٹ موڈل: MRL کے استراتژیات پارسینگ اور مدرن ہبری سے کیس پڑھنا', 'sr': 'Zajednički model na transiciji za morfosintaktičko razmatranje: Analiza strategije za MRL i studija slučajeva modernog hebrejskog', 'uz': 'Name', 'vi': 'KCharselect unicode block name Lý thuyết ngắn ngắn gọn về dịch vụ', 'da': 'Fælles overgangsbaserede modeller for morfosyntaktisk fortolkning: fortolkningsstrategier for maksimalgrænseværdier og et casestudie fra moderne hebraisk', 'de': 'Joint Transition Based Models for Morpho-Syntaktic Parsing: Parsing Strategies for MRL and a Case Study from Modern Hebräisch', 'id': 'Model Berdasarkan Transisi Komuni untuk Analisasi Morfo-Sintaktik: Analisasi Strategi untuk MRL dan Studi Kasus dari Hebrew Modern', 'nl': "Joint Transition Based Models for Morfo-Syntactic Parsing: Parsing Strategies for MRL's and a Case Study from Modern Hebreeuws", 'hr': 'Zajednički modeli na temelju prijenosa morfosintaktičkog razmatranja: Očitanje strategija za MRL-e i ispitivanje slučaja modernog hebrejskog', 'fa': 'Models Based Transition-Based for Morpho-Syntactic Parsing: Parsing Strategies for MRLs and a Case Study from Modern Hebrew', 'bg': 'Съвместни преходни модели за морфо-синтактично анализиране: стратегии за анализиране на МДГОВ и казус от съвременен иврит', 'sw': 'Mradi wa pamoja wa michango kwa ajili ya Uimbaji wa Kimorpho-Syntactic: Mradi wa Kuimba MRLs na Utafiti wa kesi kutoka Kibraania Kihisia cha Modern', 'af': "Joint Transition-Based Models for Morpho-Syntactic Parsing: Verwerking Strategies for MRLs en 'n Cas Study van Moderne Hebreefs", 'sq': 'Modele të përbashkëta për analizimin morfo-sintaktik bazuar në tranzicion: analizimi i strategjive për MRL dhe një studim rastesh nga Hebreja moderne', 'tr': 'Morfo-Syntaktik Parsing Strategies for MRLs we a Case Study from Modern Hebrew', 'am': 'ለመርፎ-Syntactic ማዘጋጀት ተጨማሪ ምርጫዎች', 'az': 'Morpho-Sintaktik Parsing üçün birləşdirilmiş Transition-Based Modellər: MRL Strategies for Parsing and a Case Study from Modern Hebrew', 'ko': '연합 전환을 바탕으로 하는 형태-문법 분석 모델: MRLs의 분석 전략과 현대 히브리어의 사례 연구', 'bs': 'Zajednički modeli na transiciji za morfosintaktičko razmatranje: Analiza strategija za MRL-e i studija slučajeva modernog hebrejskog', 'ca': "Models Conjunts de Transició per l'Analització Morfo-Sintàctica: Estratègies d'Analització per LMR i un estudi de cas de l'Hebreu Modern", 'et': 'Morfosüntaktilise analüüsi ühised üleminekupõhised mudelid: jääkide piirnormide analüüsimisstrateegiad ja kaasaegse heebrea juhtumiuuring', 'cs': 'Společné přechodové modely pro morfo-syntaktické analýzy: strategie analýzy MLR a případová studie z moderní hebrejštiny', 'fi': 'Yhteiset siirtymäpohjaiset mallit morfosyntaktiselle analysoinnille: jäämien enimmäismääriä koskevat analyysistrategiat ja tapaustutkimus nykyhepreasta', 'hy': "Մորֆո-սինտակտիկ վերլուծության ընդհանուր վերաբերյալ հիմնված համընդհանուր մոդելներ' ՄՌԼ-ի վերլուծության ռազմավարական ռազմավարական համակարգեր և ժամանակակից եբրայից ստացված դեպքերի ուսումնասիրություն", 'bn': 'মোর্ফো-সিন্ট্যাক্টিক পার্সিং এর জন্য যুক্ত পরিবর্তন- ভিত্তিক মডেল: এমআরএল এর জন্য পার্সিং স্ট্রেটিজি এবং আধুনিক হিব্রু থেক', 'jv': 'Joint transfer-basic model for Marpho', 'ha': '@ item Text character set', 'sk': 'Skupni prehodni modeli za morfossintaktično razčlenjanje: strategije razčlenjanja MRL in študija primera iz sodobne hebrejščine', 'he': 'מודלים משותפים מבוססים על העברה עבור בדיקת מורפו-סינטקטית: אסטרטגיות בדיקת MRLs ומחקר תיקים מהיהודי המודרני', 'bo': 'Joint Transition-Based Models for Morpho-Syntactic Parsing: Parsing Strategies for MRLs and a Case Study from Modern Hebrew'}
{'en': 'In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks. However, for languages with complex and ambiguous word-internal structure, known as morphologically rich languages (MRLs), it has been hypothesized that syntactic context may be crucial for accurate MA&D, and vice versa. In this work we empirically confirm this hypothesis for Modern Hebrew, an MRL with complex morphology and severe word-level ambiguity, in a novel transition-based framework. Specifically, we propose a joint morphosyntactic transition-based framework which formally unifies two distinct transition systems, morphological and syntactic, into a single transition-based system with joint training and joint inference. We empirically show that MA&D results obtained in the joint settings outperform MA&D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.', 'ar': 'في خطوط أنابيب البرمجة اللغوية العصبية القياسية ، يسبق التحليل الصرفي وإزالة الغموض (MA & D) المهام النحوية والدلالية النهائية. ومع ذلك ، بالنسبة للغات ذات البنية الداخلية للكلمات المعقدة والغامضة ، والمعروفة باللغات الغنية شكليًا (MRLs) ، فقد تم الافتراض بأن السياق النحوي قد يكون حاسمًا في عملية MA&D الدقيقة ، والعكس صحيح. في هذا العمل نؤكد بشكل تجريبي هذه الفرضية للغة العبرية الحديثة ، MRL مع التشكل المعقد والغموض الشديد على مستوى الكلمة ، في إطار عمل جديد قائم على التحول. على وجه التحديد ، نقترح إطارًا مشتركًا قائمًا على التحول الصرفي الذي يوحد رسميًا نظامين مختلفين للتحول ، المورفولوجي والنحوي ، في نظام واحد قائم على الانتقال مع تدريب مشترك واستدلال مشترك. لقد أظهرنا تجريبياً أن نتائج MA & D التي تم الحصول عليها في الإعدادات المشتركة تفوق نتائج MA & D التي تم الحصول عليها بواسطة المكونات المستقلة ذات الصلة ، وأن نتائج التحليل الشامل التي تم الحصول عليها بواسطة نظامنا المشترك تقدم حالة جديدة من الفن لتحليل التبعية العبرية.', 'pt': 'Em pipelines de NLP padrão, a análise morfológica e a desambiguação (MA&D) precedem as tarefas de downstream sintáticas e semânticas. No entanto, para línguas com estrutura interna de palavras complexa e ambígua, conhecidas como línguas morfologicamente ricas (MRLs), foi levantada a hipótese de que o contexto sintático pode ser crucial para MA&D preciso e vice-versa. Neste trabalho, confirmamos empiricamente essa hipótese para o hebraico moderno, um MRL com morfologia complexa e ambiguidade severa em nível de palavra, em uma nova estrutura baseada em transição. Especificamente, propomos uma estrutura baseada em transição morfossintática conjunta que unifica formalmente dois sistemas de transição distintos, morfológicos e sintáticos, em um único sistema baseado em transição com treinamento conjunto e inferência conjunta. Mostramos empiricamente que os resultados de MA&D obtidos nas configurações conjuntas superam os resultados de MA&D obtidos pelos respectivos componentes autônomos, e que os resultados de análise de ponta a ponta obtidos por nosso sistema conjunto apresentam um novo estado da arte para análise de dependência do hebraico.', 'es': 'En las canalizaciones de PNL estándar, el análisis morfológico y la desambiguación (AM&D) preceden a las tareas descendentes sintácticas y semánticas. Sin embargo, para los lenguajes con una estructura interna de palabras compleja y ambigua, conocidas como lenguajes ricos en morfología (LMR), se ha planteado la hipótesis de que el contexto sintáctico puede ser crucial para una AM&D precisa, y viceversa. En este trabajo confirmamos empíricamente esta hipótesis para el hebreo moderno, un LMR con morfología compleja y ambigüedad grave a nivel de palabras, en un marco novedoso basado en la transición. Específicamente, proponemos un marco conjunto basado en la transición morfosintáctica que unifica formalmente dos sistemas de transición distintos, morfológico y sintáctico, en un único sistema basado en la transición con entrenamiento conjunto e inferencia conjunta. Demostramos empíricamente que los resultados de AyD obtenidos en los entornos conjuntos superan a los resultados de AyD obtenidos por los respectivos componentes independientes, y que los resultados de análisis de extremo a extremo obtenidos por nuestro sistema conjunto presentan un nuevo estado de la técnica para el análisis de la dependencia hebrea.', 'fr': "Dans les pipelines NLP standard, l'analyse morphologique et la désambiguïsation (MA&D) précèdent les tâches syntaxiques et sémantiques en aval. Cependant, pour les langues dont la structure interne des mots est complexe et ambiguë, appelées langages morphologiquement riches (LMR), on a émis l'hypothèse que le contexte syntaxique peut être crucial pour une MA&D précise, et vice versa. Dans ce travail, nous confirmons empiriquement cette hypothèse pour l'hébreu moderne, une LMR avec une morphologie complexe et une ambiguïté sévère au niveau des mots, dans un nouveau cadre basé sur la transition. Plus précisément, nous proposons un cadre basé sur la transition morphosyntaxique conjointe qui unifie formellement deux systèmes de transition distincts, morphologique et syntaxique, en un seul système basé sur la transition avec entraînement conjoint et inférence conjointe. Nous montrons empiriquement que les résultats de MA&D obtenus dans les paramètres d'articulation surpassent les résultats de MA&D obtenus par les composants autonomes respectifs, et que les résultats d'analyse de bout en bout obtenus par notre système conjoint présentent un nouvel état de l'art pour l'analyse de dépendance hébraïque.", 'ja': '標準的なNLPパイプラインでは、形態分析と曖昧さ解消（ MA&amp;D ）が構文的および意味的な下流タスクに先行する。 しかし、形態論的に豊富な言語（ MRL ）として知られる複雑で曖昧な単語-内部構造を持つ言語については、構文コンテキストが正確なMA&amp;Dにとって重要であり、その逆もまた重要である可能性があると仮定されている。 この研究では、複雑な形態と深刻な単語レベルの曖昧さを持つMRLである現代ヘブライ語のためのこの仮説を、新規の移行ベースのフレームワークで実証的に確認します。 具体的には、形態学的および構文学的な2つの異なる遷移システムを、共同訓練と共同推論を伴う単一の遷移ベースのシステムに正式に統一する、共同形態素遷移ベースのフレームワークを提案する。 我々は、ジョイント設定で得られたMA&amp;D結果が、それぞれのスタンドアロンコンポーネントによって得られたMA&amp;D結果よりも優れていることを経験的に示し、我々のジョイントシステムによって得られたエンドツーエンドの構文解析結果は、ヘブライ語依存構文解析のための最新技術を提示することを示している。', 'hi': 'मानक एनएलपी पाइपलाइनों में, रूपात्मक विश्लेषण और बहुविकल्पी (एमए एंड डी) वाक्यात्मक और शब्दार्थ डाउनस्ट्रीम कार्यों से पहले होता है। हालांकि, जटिल और अस्पष्ट शब्द-आंतरिक संरचना वाली भाषाओं के लिए, जिसे रूपात्मक रूप से समृद्ध भाषाओं (एमआरएल) के रूप में जाना जाता है, यह परिकल्पना की गई है कि वाक्यात्मक संदर्भ सटीक एमए एंड डी के लिए महत्वपूर्ण हो सकता है, और इसके विपरीत। इस काम में हम अनुभवजन्य रूप से आधुनिक हिब्रू के लिए इस परिकल्पना की पुष्टि करते हैं, एक उपन्यास संक्रमण-आधारित ढांचे में जटिल आकृति विज्ञान और गंभीर शब्द-स्तर की अस्पष्टता के साथ एक एमआरएल। विशेष रूप से, हम एक संयुक्त morphosyntactic संक्रमण-आधारित ढांचे का प्रस्ताव करते हैं जो औपचारिक रूप से दो अलग-अलग संक्रमण प्रणालियों, रूपात्मक और वाक्यात्मक, को संयुक्त प्रशिक्षण और संयुक्त अनुमान के साथ एक एकल संक्रमण-आधारित प्रणाली में एकीकृत करता है। हम अनुभवजन्य रूप से दिखाते हैं कि संयुक्त सेटिंग्स में प्राप्त एमए एंड डी परिणाम संबंधित स्टैंडअलोन घटकों द्वारा प्राप्त एमए एंड डी परिणामों को पछाड़ते हैं, और हमारे संयुक्त प्रणाली द्वारा प्राप्त एंड-टू-एंड पार्सिंग परिणाम हिब्रू निर्भरता पार्सिंग के लिए कला की एक नई स्थिति पेश करते हैं।', 'zh': '准NLP管道,形析消歧义(MA&D)先句法语义下流。 然于杂模糊之词内部结构,谓之形容丰(MRL),已设句法上下文于正者MA&D或至重反之亦然。 此一新型框架之中,经验性证今希伯来语之伪设,今希伯来语杂形重单词歧义之MRL也。 具体来说有一于合形句法框架,框架正以两渡之统(形态学与句法)为一,合教合理之统。 吾以经验明之,合置中得者MA&D优于独立组件得之MA&D,而吾合统得之端解析为希伯来语赖解析供一新之技术水平。', 'ru': 'В стандартных трубопроводах NLP морфологический анализ и дезагрегирование (MA&amp;D) предшествуют синтаксическим и семантическим последующим задачам. Тем не менее, для языков со сложной и неоднозначной внутренней структурой слов, известных как морфологически богатые языки (MRL), была выдвинута гипотеза, что синтаксический контекст может иметь решающее значение для точного MA&amp;D, и наоборот. В этой работе мы эмпирически подтверждаем эту гипотезу для современного иврита, MRL со сложной морфологией и сильной двусмысленностью на уровне слов, в новой переходной структуре. В частности, мы предлагаем совместную морфосинтаксическую переходную структуру, которая формально объединяет две различные переходные системы, морфологическую и синтаксическую, в единую переходную систему с совместным обучением и совместным выводом. Мы эмпирически показываем, что результаты MA&amp;D, полученные в совместных настройках, превосходят результаты MA&amp;D, полученные соответствующими отдельными компонентами, и что результаты сквозного синтаксического анализа, полученные нашей совместной системой, представляют собой новый уровень техники для синтаксического анализа зависимостей на иврите.', 'ga': 'I bpíblínte caighdeánacha NLP, déantar anailís mhoirfeolaíoch agus dí-athbhrí (MA&D) roimh thascanna iartheachtacha comhréire agus shéimeantacha. I gcás teangacha a bhfuil struchtúr inmheánach focal casta agus débhríoch acu, áfach, ar a dtugtar teangacha atá saibhir ó thaobh moirfeolaíochta (MRLanna), tá hipitéisiú déanta go bhféadfadh comhthéacs comhréire a bheith ríthábhachtach le haghaidh MA&D cruinn, agus a mhalairt. Sa saothar seo deimhnímid go heimpíreach an hipitéis seo don Nua-Eabhrais, MRL le moirfeolaíocht chasta agus débhríocht dhian ar leibhéal na bhfocal, i gcreat úrnua atá bunaithe ar an trasdul. Go sonrach, molaimid comhchreat morphosyntactic-bhunaithe trasdula a aontóidh go foirmiúil dhá chóras trasdula ar leith, moirfeolaíocha agus comhréire, isteach i gcóras amháin tras-bhunaithe le comh-oiliúint agus tátail comhpháirteacha a dhéanamh. Léirímid go heimpíreach go n-éiríonn níos fearr leis na torthaí MA&D a fhaightear sna comhshuíomhanna ná na torthaí MA&D a fhaigheann na comhpháirteanna neamhspleácha faoi seach, agus go dtugann torthaí parsála ceann-go-deireadh a fhaigheann ár gcomhchóras staid nua den scoth maidir le parsáil spleáchais Eabhraise.', 'hu': 'A standard NLP csővezetékekben a morfológiai elemzés és egyértelműsítés (MA&D) megelőzi a szintaktikai és szemantikai downstream feladatokat. Azonban az összetett és kétértelmű szó-belső struktúrájú nyelvek esetében, amelyeket morfológiailag gazdag nyelvekként ismernek, feltételezték, hogy a szintaktikus kontextus kulcsfontosságú lehet a pontos MA&D szempontjából, és fordítva. Ebben a munkában empirikusan megerősítjük ezt a hipotézist a modern héberre, egy komplex morfológiával és súlyos szószintű kétértelműséggel rendelkező MRL-re, egy új átmeneti alapú keretben. Konkrétan egy közös morfoszintatikus átmeneti alapú keretrendszert javasolunk, amely formálisan egyesíti két különböző, morfológiai és szintaktikus átmeneti rendszert, egyetlen átmeneti alapú rendszerbe, közös képzéssel és közös következtetéssel. empirikusan megmutatjuk, hogy a közös beállításokban kapott MA&D eredmények felülmúlják az adott önálló komponensek által kapott MA&D eredményeket, és hogy a közös rendszerünk által kapott end-to-end elemzési eredmények a héber függőség elemzésének új korszerűségét jelentik.', 'it': "Nelle pipeline standard NLP, l'analisi morfologica e la disambiguazione (MA&D) precede le attività sintattiche e semantiche a valle. Tuttavia, per i linguaggi con struttura interna di parole complessa e ambigua, noti come linguaggi morfologicamente ricchi (MRLs), è stato ipotizzato che il contesto sintattico possa essere cruciale per un'accurata MA&D, e viceversa. In questo lavoro confermiamo empiricamente questa ipotesi per l'Ebraico Moderno, un LMR con morfologia complessa e grave ambiguità a livello di parola, in un nuovo quadro basato sulla transizione. Nello specifico, proponiamo un quadro comune basato sulla transizione morfosintattica che unifica formalmente due distinti sistemi di transizione, morfologici e sintattici, in un unico sistema basato sulla transizione con formazione congiunta e inferenza congiunta. Mostriamo empiricamente che i risultati MA&D ottenuti nelle impostazioni congiunte superano i risultati MA&D ottenuti dai rispettivi componenti standalone, e che i risultati di analisi end-to-end ottenuti dal nostro sistema congiunto presentano un nuovo stato dell'arte per l'analisi delle dipendenze ebraiche.", 'ka': 'სტანდარტური NLP პერილინში, მორპოლოგიური ანალიზაცია და განამბიგუაცია (MA&D) წინაღმდეგ სინტაქტიური და ჟენმანტიური ქვემოსტრიმიური დავალება. მაგრამ, კომპლექსი და ამბიზუალური სიტყვების ინტერქტურაციისთვის, რომელიც მორპოლოგიურად ღარიბული ენები (MRLs), იყო ჰიპოტესტიზებული რომ სინტაქტიული კონტექსტი შეიძლება იყოს მნიშვნ ამ სამუშაოში ჩვენ ემპერიკურად ამ ჰიპოტეზას აღწერეთ მოდინარე ჰებრის, MRL-ს კომპლექსიკური მოპოროლოგია და ძალიან სიტყვების ამბიდვიტია, პრომენტის გადა განსაკუთრებულად, ჩვენ შევძლებთ ერთადერთი მოპროფსინტაქტიური გადატანაციის ფრამეტურად ერთადერთებული ორი განსხვავებული გადატანაციის სისტემი, მოპოროლოგიური და სინტაქტიური სისტემიში ერთადერთი გადატანაციის და ერთადერთ ჩვენ ემპერიკურად გამოჩვენებთ, რომ MA&D წარმოდგენები, რომლებიც ერთადერთი პარამეტრებში მიღებული MA&D წარმოდგენების შემდეგ, რომლებიც მიღებული შემდეგი სტანდონენტის კომპონენტებით, და ეს წარმოდგენების შემდეგ გა', 'el': 'Στους τυποποιημένους αγωγούς η μορφολογική ανάλυση και αποσαφήνιση (MA&D) προηγείται συντακτικών και σημασιολογικών μεταγενέστερων εργασιών. Ωστόσο, για γλώσσες με σύνθετη και διφορούμενη δομή λέξης-εσωτερικής δομής, γνωστές ως μορφολογικά πλούσιες γλώσσες (ΑΟΚ), έχει τεθεί η υπόθεση ότι το συντακτικό πλαίσιο μπορεί να είναι κρίσιμο για την ακριβή MA&D και αντίστροφα. Στην παρούσα εργασία επιβεβαιώνουμε εμπειρικά αυτή την υπόθεση για τη Σύγχρονη Εβραϊκή, ένα ΑΟΚ με σύνθετη μορφολογία και σοβαρή ασάφεια σε επίπεδο λέξεων, σε ένα νέο πλαίσιο βασισμένο στη μετάβαση. Συγκεκριμένα, προτείνουμε ένα κοινό μορφοσυντακτικό μεταβατικό πλαίσιο το οποίο ενοποιεί επίσημα δύο διαφορετικά μεταβατικά συστήματα, μορφολογικά και συντακτικά, σε ένα ενιαίο μεταβατικό σύστημα με κοινή εκπαίδευση και κοινή συναγωγή. Αποδεικνύουμε εμπειρικά ότι τα αποτελέσματα που λαμβάνονται στις κοινές ρυθμίσεις ξεπερνούν τα αποτελέσματα που λαμβάνονται από τα αντίστοιχα αυτόνομα συστατικά, και ότι τα αποτελέσματα ανάλυσης τέλους προς τέλους που λαμβάνονται από το κοινό μας σύστημα παρουσιάζουν μια νέα κατάσταση της τεχνολογίας για την ανάλυση εβραϊκής εξάρτησης.', 'kk': 'Стандартты NLP конвейзерінде морфологиялық анализ және дисамбигуация (MA&D) синтактикалық және семантикалық төменгі тапсырмалардың алдында болады. Бірақ, морфологиялық баяны тілдер (MRL) деп белгіленген комплекс және ақылмас сөздердің ішкі құрылымының тілдері үшін синтактикалық контекст дұрыс MA&D үшін маңызды болуы мүмкін, және қарсы қайта қарсы Бұл жұмыс ішінде біз көзгертілген еврей гипотезаны, комплекс морфология мен қатты сөздер деңгейіндегі амбигиттік мәліметті, романдық ауыстыру негізіндегі фреймінде қолданып тұрмы Ескерілікті, біз морфосинтактикалық ауыстыру негіздеген қосымша қосымша қосымша, ол официально екі түрлі ауыстыру жүйесін, морфологиялық және синтактикалық, бір ауыстыру жүйесіне біріктіріп, біріктірі Біз империялық баптауларда MA&D нәтижелерін көрсетедік. Біздің бір-бірінші компоненттеріміздің MA&D нәтижелеріне сәйкес жеткізген нәтижелерінен жаңа мәліметті көрсетеді. Біздің бірінші жүйеміздің соңындағы талдау', 'lt': 'Standartiniuose NLP vamzdynuose morfologinė analizė ir nedviprasmiškumas (MA&D) atliekami prieš sintaktines ir semantines tolesnes užduotis. Tačiau kalboms, turinčioms sudėtingą ir dviprasmišką žodžių vidaus struktūrą, vadinamas morfologiškai turtingomis kalbomis (DLK), buvo daroma hipotezė, kad sintaktinis kontekstas gali būti labai svarbus tiksliam MA&D ir atvirkščiai. In this work we empirically confirm this hypothesis for Modern Hebrew, an MRL with complex morphology and severe word-level ambiguity, in a novel transition-based framework.  Konkrečiai siūlome bendrą morfosintaktinę pereinamojo laikotarpio sistemą, kuria oficialiai suvienodinamos dvi atskiros perėjimo sistemos, morfologinės ir sintaktinės, į vieną pereinamojo laikotarpio sistemą su bendru mokymu ir bendra išvada. We empirically show that MA&D results obtained in the joint settings outperform MA&D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.', 'ms': 'Dalam saluran paip NLP piawai, analisis morfologik dan penyahambiguasi (MA&D) terdahulu tugas sintaktik dan semantik turun. Bagaimanapun, untuk bahasa dengan struktur dalaman perkataan yang kompleks dan ambigu, dikenali sebagai bahasa yang kaya secara morfologik (MRL), ia telah dipotong bahawa konteks sintaktik mungkin penting untuk MA&D yang tepat, dan sebaliknya. Dalam kerja ini kami secara empirik mengesahkan hipotesis ini untuk Hebrew Modern, MRL dengan morfologi kompleks dan ambiguiti tahap perkataan yang berat, dalam kerangka berasaskan transisi yang baru. Secara khusus, kami melamar kerangka morfosintaktik berdasarkan transisi yang secara rasmi menyatukan dua sistem transisi yang berbeza, morfologik dan sintaktik, ke dalam sistem transisi berdasarkan satu dengan latihan bersama dan kesimpulan bersama. We empirically show that MA&D results obtained in the joint settings outperform MA&D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.', 'mt': 'Fil-pajpijiet standard NLP, l-analiżi morfoloġika u d-diżambiguazzjoni (MA&D) jippreċedu kompiti sintetiċi u semantiċi downstream. Madankollu, għal lingwi bi struttura interna kumplessa u ambigwa tal-kliem, magħrufa bħala lingwi morfoloġikament rikki (MRLs), ġie ipotetizzat li l-kuntest sintetiku jista’ jkun kruċjali għal MA&D preċiża, u viċi versa. F’dan ix-xogħol a ħna kkonfermaw empirikament din l-ipoteżi għall-Ebrej Modern, MRL b’morfoloġija kumplessa u ambigwità severa fil-livell tal-kliem, f’qafas ġdid ibbażat fuq tranżizzjoni. B’mod speċifiku, qed nipproponu qafas konġunt ibbażat fuq tranżizzjoni morfosintattika li formalment jgħaqqad żewġ sistemi ta’ tranżizzjoni distinti, morfoloġiċi u sintattiċi, f’sistema unika bbażata fuq tranżizzjoni b’taħriġ konġunt u inferenza konġunta. B’mod empiriku nuru li r-riżultati tal-MA&D miksuba fl-ambjenti konġunti jaqbżu r-riżultati tal-MA&D miksuba mill-komponenti indipendenti rispettivi, u li r-riżultati tal-analiżi minn tarf sa tarf miksuba mis-sistema konġunta tagħna jippreżentaw avvanz ġdid għall-analiżi tad-dipendenza Ebrajka.', 'ml': 'In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks.  എന്നിട്ടും മോര്\u200dഫോളജിക്കല്\u200d സമ്പന്നരായ ഭാഷകള്\u200d എന്ന പേരുള്ള വാക്കുകളും ഉള്ളിലുള്ള ഉള്\u200dക്കൂട്ടത്തിലുള്ള ഭാഷകള്\u200dക്ക്, സിന്\u200dടാക്ടിക്കിക്ക് സംസാരിക്കു ഈ പ്രവര്\u200dത്തനത്തില്\u200d നമ്മള്\u200d ആധുനിക ഹെബ്രൂബിന്റെ ഹൈപ്പിറ്റസിസിനെ ശാസ്ത്രീകരിക്കുന്നു. പ്രശ്നമുള്ള മോര്\u200dഫോളജിയും കഠിനമായ വാക്ക് ന പ്രത്യേകിച്ച്, നമ്മള്\u200d ഒരു യൂട്ട് മോര്\u200dഫോസിനിറ്റിക്ക് സ്ഥാനമായി പ്രായശ്ചിത്തം ചെയ്യുന്നു. അത് രണ്ട് വ്യത്യസ്ത വ്യത്യസ്ത വ്യവസ്ഥകള്\u200d, മോര്\u200dഫോളിക്കല്\u200d സ നമ്മുടെ കൂട്ടത്തിലുള്ള സഹപ്രവര്\u200dത്തനങ്ങളില്\u200d MA &D ഫലങ്ങള്\u200d പ്രവര്\u200dത്തിക്കുന്നത് മാത്രമായ സ്ഥിതിയുടെ ഫലങ്ങളാണെന്ന് നമ്മുടെ സഹസ്ഥിതിയില്\u200d നിന്നും അവസാനിക്കുന്നു. ആ', 'mk': 'Во стандардните нафтоводи на НЛП, морфолошката анализа и дезамбигуација (МА&Д) претходат на синтактичките и семантичките задачи по текот. Сепак, за јазиците со комплексна и двогледна внатрешна структура на зборови, позната како морфолошки богати јазици (МРЛ), се хипотезира дека синтактичкиот контекст може да биде клучен за прецизната МА&Д и обратно. In this work we empirically confirm this hypothesis for Modern Hebrew, an MRL with complex morphology and severe word-level ambiguity, in a novel transition-based framework.  Специфично, предложуваме заедничка морфосинтактичка рамка базирана на транзиција која официјално обединува два различни транзициски системи, морфолошки и синтактички, во еден систем базиран на транзиција со заедничка обука и заедничка инференција. We empirically show that MA&D results obtained in the joint settings outperform MA&D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.', 'mn': 'Стандарттай NLP хоолойн шугам дээр морфологик шинжилгээ болон эвдэмжлэх (MA&D) нь синтактик болон semantic доорх үйл ажиллагааны өмнө явдаг. Гэхдээ үүнийг морфологийн баян хэл (MRL) гэж нэрлэдэг комплекс болон амархан дотоод үг бүтцийн хэлний хувьд синтактик нөхцөл нь зөв МА&D болон эсрэг нь чухал байж болох боломжтой гэж боддог. Энэ ажлын хувьд бид орчин үеийн Хеврийн төсөөллийг тодорхойлж байна. МРЛ нь цогц өөрчлөлт, хэт хэмжээний үг хэмжээний хэмжээний хэмжээний хэмжээний хэмжээнд зориулагддаг. Ялангуяа бид хоёр ялгаатай шилжүүлэлтийн систем, морфосинтактик, синтактик, нэг шилжүүлэлтийн систем болон нийлбэртэй халдвартай нэгтгэдэг морфосинтактик шилжүүлэлтийн систем руу нэгтгэдэг. Бид хамтдаа MA&D-ын үр дүнг хамтдаа олж авсан зүйлс нь хамтдаа хамтдаа хамтдаа хамтдаа олж авсан MA&D-ын үр дүнг илүү үр дүнтэй болж харуулж байна. Тэгээд хамтдаа хамтдаа хуваалцах үр дүнг бидний хамтдаа хамтдаа олж авсан Х', 'no': 'I standard NLP-røyrlinjer går morfologisk analyse og disambiguasjon (MA&D) før syntaktiske og semantiske nedstrømmeoppgåver. Men for språk med komplekse og ambiguous ord-interne struktur, kjent som morfologisk rike språk (MRL), er det hypotisert at syntaktisk kontekst kan vera viktig for nøyaktig MA&D, og motsatt. I dette arbeidet stadfestar vi empirisk denne hipotesen for Modern Hebrew, en MRL med komplekse morfologi og sterke ord-nivå ambiguity, i eit nytt overgang-basert rammeverk. Spesielt foreslår vi eit samanlig morfosyntaktisk overgangsbasert rammeverk som formelt unifiserer to ulike overgangssystemer, morfologiske og syntaktiske, til eit enkelt overgangsbasert system med samanlig trening og kople infeksjon. Vi viser empirisk at MA&D-resultatet som er oppretta i samanhengsinnstillingane utfører MA&D-resultatet som er oppretta av dei tilhøyrande samanhengskomponentane, og at tillesingsresultatet som er oppretta av samlingssystemet vårt er nytt i kunsten for å tolka Hebrew avhengigheit.', 'pl': 'W standardowych rurociągach NLP analiza morfologiczna i dyskryminacja (MA&D) poprzedza zadania składniowe i semantyczne. Jednakże w przypadku języków o złożonej i niejednoznacznej strukturze wewnętrznej słowa, znanych jako języki bogate morfologicznie (MRL), stwierdzono hipotezę, że kontekst składni może mieć kluczowe znaczenie dla dokładnego MA&D i odwrotnie. W niniejszej pracy empirycznie potwierdzamy tę hipotezę dla współczesnego hebrajskiego, MRL o złożonej morfologii i ciężkiej dwuznaczności na poziomie słów, w nowej strukturze opartej na przejściu. W szczególności proponujemy wspólne ramy morfosyntaktyczne oparte na przejściu, które formalnie łączy dwa odrębne systemy przejściowe, morfologiczne i składniowe, w jeden system oparty na przejściu ze wspólnym szkoleniem i wspólnym wnioskiem. Empirycznie pokazujemy, że wyniki MA&D uzyskane w ustawieniach wspólnych przewyższają wyniki MA&D uzyskane przez poszczególne samodzielne komponenty, a wyniki kompleksowego parsowania uzyskane przez nasz wspólny system stanowią nowy stan techniki dla parsowania zależności hebrajskiej.', 'si': 'ප්\u200dරමාණය NLP පායිප්ලින්ස් වලින්, මොර්ෆෝලෝගික විශ්ලේෂණය සහ අසංක්\u200dරීය (MA&D) සංක්\u200dරීය සහ සෙමාන්ටික්  නමුත්, පරික්ෂිත සහ අන්තිම වචන සඳහා භාෂාවට, මොර්ෆෝලෝජික විශාල භාෂාවක් වලින් (MRLs) දැනගත්ත භාෂාවට, ඒක හිතාගත්තා වි මේ වැඩේ අපි අධ්\u200dයානික හබ්\u200dරියෝ වලින් මේ අභිප්\u200dරායාත්මක විශ්වාස කරනවා, MRL සම්පූර්ණ විශ්වාස සහ ශාක්තික වචන වචන විශේෂයෙන්ම, අපි සම්බන්ධ විදියට මෝර්ෆෝසින්ටක්ටික් සංවිධානය සඳහා සංවිධානයෙන් ප්\u200dරවිධානයක් ප්\u200dරවිධානය කරන්න ප්\u200dරවිධාන අපි පෙන්වන්නේ MA&D ප්\u200dරතිචාර විදියට සම්බන්ධ සැකසුම් වලින් ප්\u200dරතිචාර කරපු MA&D ප්\u200dරතිචාර ප්\u200dරතිචාර කරපු ප්\u200dරතිචාරයක් වලින් ප්\u200dරතිචාර කරපු අ', 'sr': 'U standardnim NLP cijevima, morfološka analiza i disambiguacija (MA&D) predviđaju sintaktične i semantične poslove. Međutim, za jezike sa složenim i ambigućom unutrašnjom strukturom riječi, poznatom kao morfološki bogati jezici (MRL), bila je hipotezacija da sintaktički kontekst može biti ključni za tačnu MA&D, i suprotno. U ovom poslu mi empirički potvrđujemo ovu hipotezu modernog hebrejskog, MRL sa kompleksnom morfologijom i teškom ambiguitnošću riječi na nivou, u novom okviru na temelju tranzicije. Posebno predlažemo zajednički morfosintaktički okvir na osnovu transicije koji formalno ujedinjava dva različita prelaznog sistema, morfološkog i sintaktičkog, u jednog sustava na osnovu transicije sa zajedničkom obukom i zajedničkom infekcijom. Mi empirički pokazujemo da rezultati MA D-a koji su dobili u zajedničkim nastavama iznose rezultate MAD-a koji su dobili odgovarajući jedinstveni komponenti, i da rezultati analize kraja do kraja koji su dobili naš zajednički sistem predstavljaju novo stanje umetnosti za analizu hebrejske zavisnosti.', 'so': 'Baaritaanka morfologiga iyo disambiguutada (MA&D) ee caalamka ah ee NLP ayaa horumarinaya shaqada syntactic iyo semantic downstream. Si kastaba ha ahaatee, luuqadaha ku qoran qoraalka hoose ee adag iyo qalloocan, oo loo yaqaan luuqadaha hodanka ah (MRLs), waxaa loo malaynayaa in kooxaha syntactic ay muhiim u tahay MA &D, iyo sharafta ka geesta ah. Shaqadan waxaan si fiican ugu xaqiijinaynaa fikiritaankan Cibraaniga Modern ah, kaas oo ah MRL oo ku qoran dhaqdhaqaaq adag iyo heer aad u adag oo hadal ah, waxaana ku qoran qoraal warqad ah oo ku qoran. Si gaar ah, waxaynu u soo jeedaynaa qoraal ka mid ah oo ku qoran wadajirka morphosyntactika, taas oo si rasmi ah u qabsata laba nidaam oo kala duduwan oo kala duduwan, morphological iyo syntactic, oo ah nidaam kooban oo ku qoran waxbarasho wadajir ah iyo cudur wadajir ah. Waxaynu si fudud ugu muujinnaa in MA &D resultiyadii ay ka heleen qorshaha wadajirka ah oo ka soo baxay MA &D resultiyadii ay ka heleen qaybaha taageeriga ah, dhammaadka dhammaadka baaritaanka dhammaadka ay ka heleen nidaamka wadajirka ah, waxay keeneen xaalad cusub oo ay u fidiyaan baarlamaanka ammaanta Cibraaniyadu.', 'ro': 'În conductele standard PNL, analiza morfologică și dezambiguizarea (MA&D) precede sarcinile sintactice și semantice din aval. Cu toate acestea, pentru limbile cu structură complexă și ambiguă internă de cuvinte, cunoscute sub numele de limbi bogate din punct de vedere morfologic (LMR), s-a ipotezat că contextul sintactic poate fi crucial pentru MA&D exact și invers. În această lucrare confirmăm empiric această ipoteză pentru ebraica modernă, o LMR cu morfologie complexă și ambiguitate severă la nivel de cuvânt, într-un cadru nou bazat pe tranziție. În mod specific, propunem un cadru comun bazat pe tranziție morfosintactică, care unifică formal două sisteme distincte de tranziție, morfologice și sintactice, într-un singur sistem bazat pe tranziție, cu formare comună și inferență comună. Aratăm empiric că rezultatele MA&D obținute în setările comune depășesc rezultatele MA&D obținute de componentele independente respective și că rezultatele analizării end-to-end obținute de sistemul nostru comun prezintă o nouă stare de tehnologie pentru analizarea dependenței ebraice.', 'sv': 'I standard NLP pipelines föregår morfologisk analys och disambiguation (MA&D) syntaktiska och semantiska nedströmsuppgifter. Men för språk med komplex och tvetydig ordintern struktur, så kallade morfologiskt rika språk (MRL), har det antagits att syntaktiskt sammanhang kan vara avgörande för korrekt MA&D, och vice versa. I detta arbete bekräftar vi empiriskt denna hypotes för modern hebreiska, ett MRL med komplex morfologi och svår ordnivå tvetydighet, i ett nytt övergångsbaserat ramverk. Specifikt föreslår vi ett gemensamt morfosyntaktiskt övergångsbaserat ramverk som formellt förenar två distinkta övergångssystem, morfologiska och syntaktiska, till ett enda övergångsbaserat system med gemensam träning och gemensam inferens. Vi visar empiriskt att MA&D-resultat som erhållits i de gemensamma inställningarna överträffar MA&D-resultat som erhållits av respektive fristående komponenter, och att end-to-end-tolkningsresultat som erhållits av vårt gemensamma system presenterar ett nytt state of the art för hebreisk beroendetolkning.', 'ta': 'நிலையான NLP பைப்லைன்களில், morphological analysis and disambiment (MA&D) ஒத்திசைவு மற்றும் semantic downstream பணிகளை முன்னேறுகிறது. ஆனால், சிக்கலான மற்றும் வார்த்தையுடைய உள்ளூர்ந்த அமைப்புகளுடன் மொழிகளுக்கு, மொழிப்பொருளாக பணக்கூடிய மொழிகள் (MRLs) என்று அறியப்படும் என்று எண்ணப்பட்டு இந்த வேலையில் நாம் ஒரு புதிய மாற்றம் அடிப்படையிலான சட்டத்தில் இந்த குறிப்பை உறுதிப்படுத்துகிறோம். Specifically, we propose a joint morphosyntactic transition-based framework which formally unifies two distinct transition systems, morphological and syntactic, into a single transition-based system with joint training and joint inference.  We empirically show that MA&D results obtained in the joint settings outperform MA&D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.', 'ur': 'استاندارد NLP پائيپ لين میں، مورفولوژيکي تحليل اور نامبوغّات (MA&D) کے سامنے سينٹکسيک اور سيمانٹيک لائنٹریم کے کام آگے چلتے ہیں. However, for languages with complex and ambiguous word-internal structure, known as morphology rich languages (MRLs), it is hypothesized that syntactic context may be crucial for accurate MA&D, and vice versa. اس کام میں ہم مضبوط طور پر اس تفصیل کی تصدیق کریں جو مدرن یہوری کے لئے ہے، ایک MRL کی پیچیدہ موفولوژی اور سخت کلمات سطح غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر خاص طور پر، ہم ایک مشترک مورفوسینٹاکٹیکی تغییر پر بنیاد رکھنے والی فرم پیشنهاد کرتے ہیں جو دو مختلف تغییر سیستم، مورفولژیک اور سینٹاکٹیکی، ایک تغییر-بنیاد سیسٹم میں مشترک تغییر اور مشترک تغییر کے ساتھ متحد کرتا ہے. ہم مضبوط طور پر نشان دیتے ہیں کہ MA&D نتیجے جو joint settings میں حاصل کئے گئے ہیں MA&D نتیجے مضبوط استانڈیٹ کے سامنے حاصل کئے گئے ہیں، اور ان نتیجے جو ہمارے joint system کے ذریعہ حاصل کئے گئے ہیں ان کے نتیجے جو ہبری اعتباری پارسینگ کے لئے نئی ایٹیٹ کے لئے حا', 'uz': "Name Lekin, murakkablik va murakkab ichki so'zlar tuzuvlari (MRLs) deb nomlangan murakkab so'zlar tillari uchun, bu sintaktik tarkibi muhim bo'lishi mumkin. Bu vazifani biz birinchi darajada, Modern Yahudiycha uchun bu hypotheyasini tasdiqlash mumkin, murakkab morfologiya va alvorlig soʻzning balandligini, novel o'zgarishning asosida yaratilgan darajada MRL'ni tasdiqlash mumkin. Ko'rsatganda, biz bir bir necha morphosyntactic tarjima asosida yaratishni talab qilamiz, bu ikkita teng tarjima tizim, morfologik va syntactik bilan bir tarjima va bir bir bir xil taʼminlovchi va bir bog'liq infeksiyatli bilan bir tarjima tizimga birlashtiradi. Biz tasavvur qilamiz, birlashtirish moslamalarida MA va D natijalarini boshqarish mumkin, va biz birlashtirish tizimmiz bilan birlashtirish muvaffaqiyatlarimiz haqida yetarli sahifalarning yangi holatini yetadi.", 'vi': 'Trong những đường ống tiêu chuẩn khôn lỏi, phân tích lịch sử và biến dạng (MA/ D) đi trước các công việc theo dòng chảy. Tuy nhiên, đối với các ngôn ngữ phức tạp và mơ hồ về cấu trúc nội dung từ, được biết đến như các ngôn ngữ có vị trí giàu có quyết định có thể là hoàn cảnh cú pháp thuật rất quan trọng để đạt chuẩn MA, D, và ngược lại. Trong công trình này, chúng tôi có kinh nghiệm xác nhận giả thuyết này cho người Do Thái hiện đại, một MRL với quyết tâm nhiều từ phức tạp và sự mập mờ nghiêm trọng ở mức độ chữ, trong một khung thời kỳ mới. Cụ thể, chúng tôi đề xuất một cơ quan chuyển đổi lưỡng tính phối hợp hợp hợp hợp hai hệ nối tiếp, hình thức và cấu trúc, thành một hệ thống nối tiếp với giáo dục phối hợp và suy luận đồng. Chúng tôi có kinh nghiệm cho thấy kết quả MA/ D được kết quả tại các thiết lập chung còn hơn là các kết quả MA/ D được kết quả phân tích bởi các thành phần riêng biệt, và kết quả phân tích kết thúc bằng hệ thống chung của chúng tôi lại tạo ra một trạng thái mới cho phân tích phụ thuộc Do Thái.', 'da': 'I standard NLP-rørledninger går morfologisk analyse og disambiguation (MA&D) forud for syntaktiske og semantiske downstream-opgaver. For sprog med kompleks og tvetydig ordintern struktur, kendt som morfologisk rige sprog (MRL), er det imidlertid blevet antaget, at syntaktisk kontekst kan være afgørende for nøjagtig MA&D og omvendt. I dette arbejde bekræfter vi empirisk denne hypotese for moderne hebraisk, en MRL med kompleks morfologi og alvorlig ordniveau tvetydighed, i en ny overgangsbaseret ramme. Specielt foreslår vi en fælles morfosyntaktisk overgangsbaseret ramme, der formelt forener to forskellige overgangssystemer, morfologiske og syntaktiske, til et enkelt overgangsbaseret system med fælles træning og fælles inferens. Vi viser empirisk, at MA&D resultater opnået i de fælles indstillinger overstiger MA&D resultater opnået af de respektive enkeltstående komponenter, og at end-to-end parsing resultater opnået af vores fælles system giver en ny state of the art for hebraisk afhængighedsanalyse.', 'bg': 'В стандартните тръбопроводи на НЛП морфологичният анализ и разграничението (МА&D) предхождат синтактични и семантични задачи надолу по веригата. Въпреки това, за езици със сложна и двусмислена дума-вътрешна структура, известни като морфологично богати езици (МДГОВ), е направена хипотеза, че синтактичният контекст може да бъде от решаващо значение за точните ОУ и обратно. В тази работа емпирично потвърждаваме тази хипотеза за съвременен иврит, МДГОВ със сложна морфология и тежка двусмисленост на ниво дума, в нова рамка, базирана на преход. По-конкретно, ние предлагаме съвместна морфосинтактична преходна рамка, която формално обединява две отделни преходни системи, морфологична и синтактична, в една система, базирана на преход със съвместно обучение и съвместно заключение. Емпирично показваме, че резултатите от МА&Д, получени в съвместните настройки, превъзхождат резултатите от МА&Д, получени от съответните самостоятелни компоненти, и че резултатите от анализ от край до край, получени от нашата съвместна система, представят ново състояние на изкуството за анализ на зависимостта на евреите.', 'hr': 'U standardnim cijevima NLP-a, morfološka analiza i disambiguacija (MA&D) predstavljaju sintaktične i semantične spuštene zadatke. Međutim, za jezike sa složenom i ambigućom unutarnjom strukturom riječi, poznatom kao morfološki bogati jezici (MRL), bila je hipotezacija da sintaktički kontekst može biti ključni za tačnu MA&D, a suprotno. U ovom poslu empirički potvrđujemo ovu hipotezu modernog hebrejskog, MRL sa kompleksnom morfologijom i teškom ambiguitetom razine riječi, u novom okviru na temelju prijenosa. Posebno predlažemo zajednički okvir na morfosintaktičkoj premještaji koji formalno ujedini dva različita sustava premještaja, morfološkog i sintaktičkog sustava u jednom sustavu temeljenom na premještaju s zajedničkim obukom i zajedničkom infekcijom. Mi empirički pokazujemo da rezultati MA&D dobiveni u zajedničkim nastavacima iznosi rezultate MA&D koji su dobili odgovarajući jedinstveni komponenti, te rezultati analize koji su dobili naš zajednički sustav predstavljaju novo stanje umjetnosti za analizu hebrejske zavisnosti.', 'nl': "In standaard NLP-pijpleidingen gaat morfologische analyse en disambiguatie (MA&D) vooraf aan syntactische en semantische downstreamtaken. Echter, voor talen met complexe en dubbelzinnige woord-interne structuur, bekend als morfologisch rijke talen (MRL's), is verondersteld dat syntactische context cruciaal kan zijn voor nauwkeurige MA&D, en vice versa. In dit werk bevestigen we empirisch deze hypothese voor Modern Hebreeuws, een MRL met complexe morfologie en ernstige dubbelzinnigheid op woordniveau, in een nieuw transitie-gebaseerd kader. Specifiek stellen we een gezamenlijk morfosyntactisch transitiegebaseerd raamwerk voor dat formeel twee verschillende transitiesystemen, morfologisch en syntactisch, verenigt in een enkel transitiegebaseerd systeem met gezamenlijke training en gezamenlijke conclusie. We tonen empirisch aan dat MA&D resultaten verkregen in de gezamenlijke instellingen beter presteren dan MA&D resultaten verkregen door de respectieve stand-alone componenten, en dat end-to-end parsing resultaten verkregen door ons gezamenlijke systeem een nieuwe state of the art vormen voor Hebreeuwse afhankelijkheidsparsing.", 'ko': '표준 NLP 파이프라인에서 문법 및 의미 다운스트림 작업보다 문법 분석 및 변조(MA&D)가 우선합니다.그러나 단어의 내부 구조가 복잡하고 애매모호한 언어, 즉 이른바 형태풍부언어(MRLs)에 대해 어떤 사람들은 문법적 경계가 정확한 MA&D에 매우 중요하다고 가정하고 반대로도 마찬가지다.이 작업에서 우리는 새로운 전환을 바탕으로 하는 틀에서 현대 히브리어(복잡한 어형과 심각한 단어급의 잘못된 뜻을 가진 MRL)의 이 가설을 실증 검증했다.구체적으로 말하자면 우리는 연합형태 문법 전환을 바탕으로 하는 틀을 제시했다. 이 틀은 형태와 문법 두 가지 서로 다른 전환 시스템을 연합훈련과 연합추리를 가진 전환에 기반한 시스템으로 정식으로 통일시켰다.우리의 경험에 의하면 연합 설정에서 얻은 MA&D 결과는 각자의 독립된 구성 요소에서 얻은 MA&D 결과보다 낫고 우리의 연합 시스템이 얻은 끝에서 끝까지 해석 결과는 히브리어 의존 해석에 새로운 기술 상태를 제공했다.', 'de': 'In Standard-NLP-Pipelines geht die morphologische Analyse und Disambiguation (MA&D) syntaktischen und semantischen nachgelagerten Aufgaben voraus. Für Sprachen mit komplexer und mehrdeutiger wortinterner Struktur, die als Morphologically Rich Languages (MRLs) bekannt sind, wurde jedoch die Hypothese aufgestellt, dass syntaktischer Kontext für eine genaue MA&D entscheidend sein kann und umgekehrt. In dieser Arbeit bestätigen wir empirisch diese Hypothese für das moderne Hebräisch, einen MRL mit komplexer Morphologie und schwerer Wortmehrdeutigkeit, in einem neuartigen Übergangs-basierten Rahmen. Konkret schlagen wir ein gemeinsames morphosyntaktisches Übergangssystem vor, das zwei verschiedene Übergangssysteme formal, morphologisch und syntaktisch, zu einem einzigen Übergangssystem mit gemeinsamem Training und gemeinsamer Inferenz vereint. Wir zeigen empirisch, dass MA&D-Ergebnisse, die in den Joint-Einstellungen erzielt werden, die MA&D-Ergebnisse der jeweiligen Standalone-Komponenten übertreffen, und dass End-to-End-Parsing-Ergebnisse unseres Joint-Systems einen neuen Stand der Technik für hebräische Abhängigkeitsparsing darstellen.', 'id': 'Dalam pipa standar NLP, analisis morfologi dan penyelesaian (MA&D) mendahului tugas syntaktik dan semantis turun. Namun, untuk bahasa dengan struktur interna kata yang kompleks dan ambigu, dikenal sebagai bahasa yang kaya secara morfologis (MRL), telah dipotosi bahwa konteks sintaks mungkin penting untuk MA&D akurat, dan sebaliknya. Dalam pekerjaan ini kami secara empiris mengkonfirmasi hipotesis ini untuk Hebrew Modern, MRL dengan morfologi kompleks dan ambigusi tingkat kata yang berat, dalam rangka yang baru berdasarkan transisi. Secara spesifik, kami mengusulkan sebuah sistem morfosintaktik kongsi berdasarkan transisi yang secara resmi menyatukan dua sistem transisi yang berbeda, morfologi dan sintaksi, ke dalam sistem transisi berdasarkan satu dengan pelatihan kongsi dan kesimpulan kongsi. Kami secara empiris menunjukkan bahwa hasil MA&D yang diperoleh dalam pengaturan kongsi melebihi hasil MA&D yang diperoleh oleh komponen standar yang sesuai, dan hasil penghuraian akhir-akhir yang diperoleh oleh sistem kongsi kami menunjukkan state of the art baru untuk penghuraian dependensi Yahudi.', 'fa': 'در خط لوله\u200cهای استاندارد NLP، تحلیل مورفولوژیکی و ناآزمایش (MA&D) از وظیفه\u200cهای سنتاکتیک و semantic downstream پیش می\u200cرود. با این حال، برای زبانها با ساختاری کلمه\u200cهای پیچیده و غیرقابل توجه، به عنوان زبانهای مورفولوژیکی ثروتمند (MRLs) شناخته شده، فرض شده است که محیط سنتاکتیک ممکن است برای MA&D دقیق مهم باشد، و بر خلاف آن. در این کار ما این فرضیه را برای ابریشمی مدرن تصدیق می\u200cکنیم، MRL با مورفولوژی پیچیده و غیرقابلیت سخت کلمه\u200cای در یک چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچها مخصوصا، ما یک چهارچوب متصل به تغییر متصل مورفوسینتیک را پیشنهاد می کنیم که رسمی دو سیستم تغییر متفاوت، مورفولوژیک و سنتاکتیک را متصل می کند، به یک سیستم متصل به تغییر متصل با تمرین متصل و تغییر متصل می کند. ما به صورت عمومی نشان می دهیم که نتیجه\u200cهای MA&D که در تنظیمات مشترک یافته\u200cاند از نتیجه\u200cهای MA&D که توسط بخش\u200cهای مختلف تنهایی یافته\u200cاند، و نتیجه\u200cهای پایان\u200cپایان\u200cپایان\u200cپایان\u200cپایان که توسط سیستم مشترک ما یافته\u200cاند، یک وضعیت جدید هنر', 'sw': 'Katika mistari ya NLP za kawaida, uchambuzi wa morphological na ubaguzi (MA&D) unakabiliwa na kazi za ushirikiano na sekunde za mto. Hata hivyo, kwa lugha zenye muundo mgumu na usio na matatizo, unaojulikana kama lugha zenye utajiri wa kimfolojia (MRLs), imefikiri kuwa muktadha wa pamoja unaweza kuwa muhimu wa MA&D, na vibaya vinginevyo. Katika kazi hii tunathibitisha nadharia hii kwa Kihebu cha Modern, MRL yenye utata wa morphology na uelewa mkubwa wa maneno, katika mfumo wa mpito wa riwaya. Kwa ujumla, tunapendekeza mfumo wa pamoja wa mpito wa morphosyntactic ambao kwa ujumla unaunganisha mifumo miwili tofauti, mfumo wa kifolojia na ushirikiano, katika mfumo mmoja wa mpito wenye mafunzo ya pamoja na maambukizi ya pamoja. We empirically show that MA&D results obtained in the joint settings outperform MA&D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.', 'sq': 'In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks.  Megjithatë, për gjuhët me strukturë të ndërlikuar dhe të ndërlikuar fjalë-të brendshme, të njohur si gjuhë morfologjikisht të pasura (MRLs), është hipotezuar se konteksti sintaktik mund të jetë vendimtar për MA&D të saktë dhe përkundrazi. Në këtë punë ne empirikisht konfirmojmë këtë hipotezë për Hebrenjtë Modern, një MRL me morfologji komplekse dhe ambiguri të ashpër në nivelin e fjalëve, në një kuadër të ri bazuar në tranzicion. Veçanërisht, ne propozojmë një kuadër të përbashkët morfosintaktik bazuar në tranzicion i cili zyrtarisht bashkon dy sisteme të ndryshme tranzicioni, morfologjik dhe sintaktik, në një sistem të vetëm bazuar në tranzicion me trajnim të përbashkët dhe përfundim të përbashkët. Ne empirikisht tregojmë se rezultatet e MA&D të fituara në rregullimet e përbashkëta tejkalojnë rezultatet e MA&D të fituara nga përbërësit respektive të vetmuar dhe se rezultatet e analizimit përfundimtar të fituara nga sistemi ynë i përbashkët paraqesin një gjendje të re të teknologjisë për analizimin e varësisë hebre.', 'tr': 'Standart NLP pipelini içinde morfolojik analizi we çykyşyklama (MA&D) syntaktik we semantik düşürmek zadalardan öňe gidýär. Yöne, karmaşık we wajyp söz-daşary struktur bilen bilinen diller üçin, morfologiki baý diller (MRLs) diýip bilinen, sintaktik kontekstler MA&D üçin has möhüm bolup biler diýip pikir edildi. Bu işde biz häzirki ýähüd dili üçin bu hypotezi mümkin bir morfologiýa we gaty söz derejesi ýok bir şekilde tassyklanýarlar. Adatça, biz morfosyntaktik bir göçümleşme tabanly bir çerçew teklip edip, ol formaliýa iki farklı göçümleşme sistemini, morfoklojik we sintaktik bir göçümleşme sistemine birleştirir. Biz eýrek görkezilýän ýagdaýda MA&D netijesi häzirki ýekelikde bolan komponentler tarapyndan berilýän MA&D netijesinde bolan netijesini görkeýäris we bu syýasatyň soňunda çykyş netijesi bolan ýagdaýyň täze bir ýagdaý häzirki baglanyşyk analysiýasy üçin bar.', 'hy': "In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks.  Այնուամենայնիվ, բարդ և երկիմաստ բառերի ներքին կառուցվածքի լեզուների համար, հայտնի որպես մորֆոլոգիապես հարուստ լեզուներ (ՄՌԼ), ենթադրվել է, որ սինտակտիկ կոնտեքստը կարող է կարևոր լինել ճշգրիտ ՄԱ-ի և հակառակը: Այս աշխատանքի ընթացքում մենք էմպրիկապես հաստատում ենք ժամանակակից եբրայի այս հիպոթեզը' բարդ մորֆոլոգիայի և խիստ բառերի մակարդակի անհավասարության մակարդակի մագնիսական ռեզոնանսային ռեզոնանսային ռեզոնանսային ռեզոնան Specifically, we propose a joint morphosyntactic transition-based framework which formally unifies two distinct transition systems, morphological and syntactic, into a single transition-based system with joint training and joint inference.  Մենք էմպիրիկապես ցույց ենք տալիս, որ կազմակերպության մեջ ստացված MA+D արդյունքները գերազանցում են MA+D արդյունքները, որոնք ստացվել են համապատասխանատվության առանձին բաղադրիչների միջոցով, և մեր կազմակերպության միջոցով ստացված վերջնական վերլուծության արդյունքները նոր տեխնոլոգիա են ներ", 'bn': 'স্ট্যান্ডার্ড এনএলপি পাইপেলাইনে মরোফোলিক্যাল বিশ্লেষণ এবং বিভ্রান্ত বিশ্লেষণ (MA&D) সিন্ট্রাক্টিক এবং সেমেন্টিক ডা তবে মোরফোলজিক্যাল সমৃদ্ধ ভাষার (এমআরএলস) নামে পরিচিত ভাষাগুলোর জন্যে সম্পূর্ণ এবং আভ্যন্তরীণ শব্দের কাঠামোর জন্য ভাষাগুলোর জন্যে এটি ধারণা করা হয়েছে যে সঠ এই কাজে আমরা আধুনিক হিব্রুর জন্য এই হিপাতিস্ততা নিশ্চিত করি, যার একটি এমআরএল, যার সাথে জটিল মরোফোলজি এবং কঠিন শব্দের মাধ্যমে গুরুত্বপূর্ণ বিষয় বিশেষ করে, আমরা একটি যৌথ মরোফোসিক্যাটিক প্রবেশের ভিত্তিক কাঠামো প্রস্তাব করি যা আনুষ্ঠানিকভাবে দুটি বিভিন্ন প্রবেশ সিস্টেম, মরোফোলজিক্যাল এবং সিন্ট্রা আমরা ক্ষমতাশালীভাবে দেখাচ্ছি যে যৌথ বৈশিষ্ট্যের মাধ্যমে MA ও ডি ফলাফল পাওয়া গেছে যারা শ্রেণীর নির্ভরশীল পার্জিং এর ফলাফল পাওয়া গেছে, আর আমাদের যৌথ সিস্টেমের ফলাফল শেষ করে', 'af': "In standaard NLP-pypline, morfologiese analisie en ontsammings (MA&D) voorheen sintaktieke en semantiese onderstreem opdragte. Maar, vir tale met kompleks en ongelukkige woord-interne struktuur, bekend as morfologiese ryk tale (MRLs), is dit hipotesis gemaak dat sintaktieke konteks kan belangrik wees vir presies MA&D, en vice versa. In hierdie werk bevestig ons hierdie hipotees vir Moderne Hebreeus, 'n MRL met kompleks morfologie en swaar woord-vlak onbekende, in 'n nuwe oorgang-gebaseerde raamwerk. Spesifieke, ons voorstel 'n joint morfosyntaktike oorgang-gebaseerde raamwerk wat formeel twee verskillende oorgang-stelsels, morfologiese en sintaktike, in 'n enkele oorgang-gebaseerde stelsel met joint oerring en joint inferensie eenmaak. Ons wys empiriese dat MA&D resultate ontvang in die koppelinge instellings oorskryf MA&D resultate wat deur die respektiewe standalone komponente ontvang is, en die end-to-end verwerking resultate wat deur ons joint stelsel ontvang is, voorsien 'n nuwe staat van die kuns vir Hebreeus afhanklikheid verwerking.", 'bs': 'U standardnim cijevima NLP-a, morfološka analiza i disambiguacija (MA&D) predstavljaju sintaktične i semantične spuštene zadatke. Međutim, za jezike sa složenom i ambigućom unutarnjom strukturom riječi, poznatom kao morfološki bogati jezici (MRL), bila je hipotezacija da sintaktički kontekst može biti ključni za tačnu MA&D, i suprotno. U ovom poslu empirički potvrđujemo ovu hipotezu modernog hebrejskog, MRL sa kompleksnom morfologijom i teškom ambiguitnošću na razini riječi, u novom okviru na temelju tranzicije. Posebno, predlažemo zajednički morfosintaktički okvir na osnovu prijenosa koji formalno ujedinjava dva različita sustava prejenosa, morfoloških i sintaktičkih sustava u jednom sustavu na osnovu prijenosa s zajedničkom obukom i zajedničkom infekcijom. Mi empirički pokazujemo da rezultati MA&D koji su dobili u zajedničkim nastavama iznose rezultate MA&D koji su dobili odgovarajući jedinstveni komponenti, i da rezultati analize koji su dobili naš zajednički sistem predstavljaju novo stanje umjetnosti za analizu hebrejske zavisnosti.', 'cs': 'V standardních NLP potrubích předchází morfologická analýza a disambiguace (MA&D) syntaktickým a sémantickým následným úkolům. Nicméně u jazyků se složitou a nejednoznačnou slovní strukturou, známých jako morfologicky bohaté jazyky (MRL), byla předpokládána hypotéza, že syntaktický kontext může být klíčový pro přesné MA&D a naopak. V této práci empiricky potvrzujeme hypotézu pro moderní hebrejštinu, MRL se složitou morfologií a závažnou nejednoznačností slova v novém přechodovém rámci. Konkrétně navrhujeme společný morfosyntaktický přechodový rámec, který formálně sjednocuje dva odlišné přechodové systémy, morfologické a syntaktické, do jediného přechodového systému se společným tréninkem a společnou inferencí. Empiricky ukazujeme, že výsledky MA&D získané ve společném nastavení překonávají výsledky MA&D získané příslušnými samostatnými komponenty a že výsledky koncové analýzy získané naším společným systémem představují nový stav techniky pro analýzu hebrejských závislostí.', 'am': 'በሜኑባዊ አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ. However, for languages with complex and ambiguous word-internal structure, known as morphologically rich languages (MRLs), it has been hypothesized that syntactic context may be crucial for accurate MA&D, and vice versa.  በዚህ ሥራ ለአዲስ ዕብራይስጥ፣ ሙግት ሞፎሎጂ እና የቋንቋ-ቋንቋ ፍሬማት፣ በመጠቀም ላይ ባለው የአሁኑ ዕብራዊ ጉዳይ፣ ይህንን ጉዳይ እናረጋግጣለን፡፡ በተለይም፣ የተለያየ ሁለት የተለየ የክፍለ ጥናት፣ ሞሮፎሎጂ እና Syntactic፣ በአንድ ተካባቢ ትምህርት ተማሪ እና ተማሪዎችን እና የግንኙነት ውጤት ጋር የተመሳሳይ የክፍለ ጥረት እና የተመሳሰለውን እናደርጋለን፡፡ አዲስ የዕብራይስጥ ተደጋፊነት ማ እና አካባቢ አካላት የተገኘውን የMA እና ፍሬዎችን በማድረግ እና የመጨረሻው የፍሬት ውጤቶች በዕብራይስጥ ጥረት ማኅበረሰብ የተገኘውን አዲስ የዓረብ ብሔራዊ ፓርቲ አካባቢ እናደርጋለን፡፡', 'az': "Standart NLP pipelines içində, morfolojik analizi və disambiguasyon (MA&D) sintaktik və semantik aşağı gələn işlərdən əvvəl gəlir. Lakin, kompleks və mühürlü söz içərisində olan dillər üçün, morfolojik zəngin dillər (MRL) kimi bilinirlər, sintaktik məlumat tam MA&D üçün çox mövcud olaraq və buna baxmayaraq düşünülmüşdür. Bu işlərdə biz bu hökmünü Modern Hebrew üçün təsdiqləyirik, kompleks morfoloji və a ğır söz səviyyəsi səviyyəsi olan MRL'i yeni bir dəyişiklik sistemində təsdiqləyirik. Özellikle, biz birlikdə təcrübə və birlikdə təcrübə ilə birlikdə iki müxtəlif təcrübə sistemini, morfolojik və sintaktik bir sistemə təklif edirik. Biz həqiqətən də, MA&D sonuçlarını ortaq qurğularında qazandığını göstəririk ki, həmçin in həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin təvəkküllük ayırılması üçün yeni bir sanatın məlumatının yeni durumu göstərir.", 'et': 'Standardsetes NLP torujuhtmetes eelneb morfoloogiline analüüs ja eristamine (MA&D) süntaktiliste ja semantiliste järgnevate ülesannete puhul. Keerulise ja ebaselge sõnasisese struktuuriga keelte puhul, mida tuntakse morfoloogiliselt rikkalike keeltena (MRL), on siiski oletatud, et süntaktiline kontekst võib olla täpse MA&D jaoks väga oluline ja vastupidi. Käesolevas töös kinnitame empiiriliselt seda hüpoteesi kaasaegse heebrea keerulise morfoloogia ja raske sõnataseme ebaselguse jääkide piirnormi uudses üleminekupõhises raamistikus. Konkreetselt pakume välja ühise morfosüntaktilise üleminekupõhise raamistiku, mis ametlikult ühendab kaks erinevat üleminekusüsteemi, morfoloogilist ja süntaktilist, üheks üleminekupõhiseks süsteemiks ühise koolituse ja ühise järeldusega. Empiiriliselt näitame, et ühisseadetes saadud MA&D tulemused ületavad MA&D tulemusi, mis on saadud vastavate eraldiseisvate komponentide puhul, ning et meie ühissüsteemiga saadud lõpp-lõpuni parsimise tulemused annavad heebrea sõltuvuse parsimisel uue tehnika taseme.', 'fi': 'Standardissa NLP-putkistossa morfologinen analyysi ja erottelu (MA&D) edeltää syntaktisia ja semanttisia loppupään tehtäviä. Kielten osalta, joilla on monimutkainen ja epäselvä sana-sisäinen rakenne, eli morfologisesti rikkaat kielet (MRL), on kuitenkin esitetty hypoteesia, että syntaktinen konteksti voi olla ratkaisevan tärkeä tarkan MA&D:n kannalta ja päinvastoin. Tässä työssä vahvistamme empiirisesti tämän hypoteesin modernille heprealle, jossa on monimutkainen morfologia ja vaikea sanatason epäselvyys, uudessa siirtymäpohjaisessa kehyksessä. Erityisesti ehdotamme yhteistä morfosyntaktista siirtymäjärjestelmää, joka muodollisesti yhdistää kaksi erillistä siirtymäjärjestelmää, morfologista ja syntaktista, yhdeksi siirtymäpohjaiseksi järjestelmäksi, jossa on yhteinen koulutus ja yhteinen päätelmä. Empiirisesti osoitamme, että yhteisasetuksissa saadut MA&D-tulokset ylittävät kunkin erillisen komponentin MA&D-tulokset ja että yhteisjärjestelmämme tuottamat end-to-end-parsaustulokset edustavat uutta tekniikkaa heprealaisen riippuvuuden parsauksessa.', 'ca': "In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks.  Tanmateix, per a llengües amb estructura interna de paraules complexa i ambigua, coneguda com llengües morfològicament rics (LMR), s'ha hipòtesiat que el context sinàctic pot ser crucial per a una MA&D exacta, i vice versa. En aquest treball, empíricament confirmem aquesta hipòtesi per a l'hebreu modern, una LMR amb morfologia complexa i ambigüitat severa de nivell de paraules, en un nou marc basat en la transició. Concretament, proposem un marc conjunt basat en transició morfosinàctica que unifica formalment dos sistemes de transició distints, morfològics i sinàctics, en un únic sistema basat en transició amb formació conjunta i inferència conjunta. Mostrem empíricament que els resultats de MA&D obtinguts en les condicions conjuntes superen els resultats de MA&D obtinguts pels respectius components independents, i que els resultats d'analització de final a final obtinguts pel nostre sistema conjunt presenten un nou avançat en l'analització de la dependencia hebreua.", 'he': 'In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks.  בכל אופן, לשפות עם מבנה פנימי מילים מורכב ומבוגד, הידוע בשפות עשירות מורפולוגית (MRLs), הונחה שקשר סינטקטי יכול להיות קריטי עבור MA&D מדויק, והפך. בעבודה הזאת אנו מאשרים אימפרית את ההיפתוזיה הזו עבור היברי המודרני, MRL עם מורפולוגיה מורכבת ומאורבולוגיה ברמה מילים חמורה, במסגרת חדשה מבוססת מעבר. Specifically, we propose a joint morphosyntactic transition-based framework which formally unifies two distinct transition systems, morphological and syntactic, into a single transition-based system with joint training and joint inference.  אנו מראים באימפריקה כי תוצאות MA&D שנקבלו במסדרות המשותפות מעליות תוצאות MA&D שנקבלו על ידי המרכיבים הבודדים המתאימים, והתוצאות המחקר הסופי-לסופי שנקבלו על ידי המערכת המשותפת שלנו מציגות מצב חדש של האמנות עבור בדיקת תלויות היברית.', 'sk': 'V standardnih cevovodih NLP morfološka analiza in razjasnitev (MA&D) pred sintaktičnimi in semantičnimi nadaljnjimi opravili. Pri jezikih s kompleksno in dvoumno besedno-notranjo strukturo, znanimi kot morfološko bogati jeziki (MRL), je bila hipoteza, da je sintaktični kontekst ključnega pomena za natančno MA&D in obratno. V tem delu empirično potrjujemo to hipotezo za sodobno hebrejščino, MRL s kompleksno morfologijo in hudo besedno dvoumnostjo, v novem prehodnem okviru. Natančneje predlagamo skupni morfosintaktični prehodni okvir, ki formalno združuje dva različna tranzicijska sistema, morfološki in sintaktični, v en sam tranzicijski sistem s skupnim usposabljanjem in skupnim sklepanjem. Empirično dokazujemo, da rezultati MA&D, pridobljeni v skupnih nastavitvah, presegajo MA&D rezultate, pridobljene z ustreznimi samostojnimi komponentami, in da rezultati razčlenitve od konca do konca, pridobljeni z našim skupnim sistemom, predstavljajo novo stanje razčlenitve hebrejske odvisnosti.', 'ha': "In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks.  A lokacin da aka yi wa harshen da masu haɗi da maganar-mai guda, wanda aka sanar da harshen marofogi masu riki (MRLs), an yi zaton, cewa muhimmin muhimmi na muhimmin muhimmada ga MA`D, da kuma misalin versa. Daga wannan aikin da Muke tabbatar da wannan hanyoyi wa Yãrabci na Kidurowa, wata MRL mai haɗuwa da morfologi da sauri mai tsananin maganar-daraja, a cikin firam mai shawara da aka danne a yanzu. A ƙayyade, Munã ƙayyade wani firam na haɗi da morfosyntactic mai shawara da ke daidaita shi, wanda ke samu'i biyu masu shagala, da mutfologi da syntactic, zuwa a cikin wani system mai bastarwa da ke sami'a tare da aikin haɗi da kuma ana sami wata cuta. Tuna nuna matsalar MA & D da fassarar da suka samu da mutane na daidaita matsalar MA & D da matsalar da suka samu da jama'a masu hushi, kuma da matsalar parse na ƙarshen dawwama da na musamman da ke samar da shi na halarce wani halin na sanar da ake yi wa parge na Hebrew.", 'jv': 'Ngawe Standard NLP Pipembers, modroloje lan dismbiguation (MA&D) kuwi bagian le semanti downtreams tasks. politenessoffpolite, "), and when there is a change ("assertivepoliteness Nang gawar iki, kita kedhanan empires mengko aces nyong nggunakaké ngerasakno karo Moderno Hebrew, an a MRL karo komplikasi mroles lan gambarang langgar-langgar ambeki, ning basa seneng nglanggar-basa basa gambar. Awak-ngomong, kita supoyo nggawe sistem sing nyeleh karo Transform Awak dhéwé éntuk perusahaan denganêr nggawe barang nggawe barang nggawe barang nggawe barang nggawe barang nggawe barang nggawe barang nggawe barang nggawe barang nggawe barang nggawe bakal terus mulai nggawe sistem sing dibutuhé perusahaan anyar nggawe barang nggawe barang nggawe cara nggawe barang nggawe Hebrew', 'bo': 'In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks. However, for languages with complex and ambiguous word-internal structure, known as morphologically rich languages (MRLs), it has been hypothesized that syntactic context may be crucial for accurate MA&D, and vice versa. In this work we empirically confirm this hypothesis for Modern Hebrew, an MRL with complex morphology and severe word-level ambiguity, in a novel transition-based framework. Specifically, we propose a joint morphosyntactic transition-based framework which formally unifies two distinct transition systems, morphological and syntactic, into a single transition-based system with joint training and joint inference. ང་ཚོས་འཛིན་གྱིས་MA&D ནང་གི་མཐུན་སྒྲིག'}
{'en': 'Synchronous Bidirectional Neural Machine Translation', 'ar': 'الترجمة الآلية العصبية ثنائية الاتجاه المتزامنة', 'es': 'Traducción automática neuronal bidireccional sincrónica', 'fr': 'Traduction automatique neuronale bidirectionnelle synchrone', 'pt': 'Tradução automática neural bidirecional síncrona', 'ja': '同期双方向ニューラル・マシン・トランスレーション', 'zh': '同步双向神经机器翻译', 'hi': 'तुल्यकालिक द्विदिश तंत्रिका मशीन अनुवाद', 'ru': 'Синхронный двунаправленный нейронный машинный перевод', 'ga': 'Aistriúchán Meaisín Neural Déthreo Shioncrónach', 'ka': 'სინქრონიური ორედირექციონალური ნეირალური მაქინის გადატყვება', 'it': 'Traduzione automatica bidirezionale sincrona neurale', 'el': 'Συγχρονική αμφίδρομη νευρωνική μηχανική μετάφραση', 'hu': 'Szinkron kétirányú neurális gépi fordítás', 'kk': 'Қадамдастырылған екі бағытты нейралық машинаны аудару', 'lt': 'Sinchroninis dvikryptinis neurologinis mašinos vertimas', 'ms': 'Terjemahan Mesin Neural Biarah Sinkron', 'mk': 'Name', 'ml': 'സിങ്ക്രോണിസ് ബൈഡിഡയല്\u200d നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുക', 'mt': 'Traduzzjoni Sinkronika Bidirezzjonali tal-Magna Newrali', 'mn': 'Хоёрдугаар тархины мэдрэлийн машин хөрөнгө', 'no': 'Synkronisert to retningsverktøyomsetjing', 'pl': 'Synchroniczne dwukierunkowe neuronowe tłumaczenie maszynowe', 'ro': 'Traducere automată sincronă bidirecţională neurală', 'sr': 'Sinkrona dvosmjerna neuronska prevoda mašine', 'si': 'සංවිධානය දෙපාර්ථික ප්\u200dරවේශනය', 'sv': 'Synkron dubbelriktad neural maskinöversättning', 'so': 'Turjumidda maskinenka koowaad', 'ta': 'ஒத்திசைவு இருதிசை நெயுரல் இயந்திரம் மொழிபெயர்ப்பு', 'ur': 'سینکرون دودئیرسیٹن نیورال ماشین ترجمہ', 'uz': 'Name', 'vi': 'Dịch riêng của máy não', 'bg': 'Синхронен двупосочен неврален машинен превод', 'da': 'Synkron bidirektionel neural maskinoversættelse', 'nl': 'Synchrone Bidirectionele Neurale Machine Translation', 'hr': 'Sinkrona dvosmjerna neuronska prevoda stroja', 'id': 'Synchronous Bidirectional Neural Machine Translation', 'de': 'Synchrone bidirektionale neuronale maschinelle Übersetzung', 'ko': '동기 쌍방향 신경', 'fa': 'ترجمه ماشین عصبی دوراهی هماهنگ', 'sw': 'Synchronous Bidirectional Neural Machine Translation', 'tr': 'Hat sanlary Bidirectional Nural Mazmunlar terjime', 'af': 'Sinkroon Bidireksionale Neurale Masjien Vertaling', 'sq': 'Translation Sinkrone Bidirectional Neural Machine', 'am': 'ትርጉም', 'hy': 'Synchronous Bidirectional Neural Machine Translation', 'bs': 'Sinkrona dvosmjerna neuronska prevoda stroja', 'bn': 'সাইক্রোনিয়াল নিউরেল মেশিন অনুবাদ', 'ca': 'Traducció de màquina neuronal bidireccional sincronizada', 'cs': 'Synchronní obousměrný neurální strojový překlad', 'et': 'Sünkroonne kahesuunaline närvide masintõlge', 'fi': 'Synkroninen kaksisuuntainen neurokonekäännös', 'az': 'Sinkron iki yĂ¶nÉ™lli nĂ¶ral maĹźÄ±n Ă§evirimi', 'jv': 'Sampeyan Bidirectiontel Njaral Majin Terjamahan', 'sk': 'Sinhroni dvosmerni živčni strojni prevod', 'ha': '@ info: whatsthis', 'bo': 'མཉམ་སྦྲགས་ཅན་གྱི་འདྲ་བ་གཉིས་དབར་གྱི་མིང་ལག་གི་སྒྱུར་བཅོས', 'he': 'תורגם וסונכרן ע"י'}
{'en': 'Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right. However, this kind of unidirectional decoding framework can not make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs. In this paper, we introduce a synchronous bidirectionalneural machine translation (SB-NMT) that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time. Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model. Then, we present an interactive decoding model in which left-to-right (right-to-left) generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left (left-to-right) decoding. We extensively evaluate the proposed SB-NMT model on large-scale NIST ChineseEnglish, WMT14 EnglishGerman, and WMT18 RussianEnglish translation tasks. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points, respectively, and obtains the state-of-the-art performance on ChineseEnglish and EnglishGerman translation tasks.', 'ar': 'تؤدي الأساليب الحالية للترجمة الآلية العصبية (NMT) إلى إنشاء رمز تسلسل اللغة الهدف رمزًا برمزًا من اليسار إلى اليمين. ومع ذلك ، لا يمكن لهذا النوع من إطار عمل فك التشفير أحادي الاتجاه الاستفادة الكاملة من السياقات المستقبلية للجانب المستهدف والتي يمكن إنتاجها في اتجاه فك التشفير من اليمين إلى اليسار ، وبالتالي يعاني من مشكلة المخرجات غير المتوازنة. في هذا البحث ، نقدم ترجمة آلية عصبية ثنائية الاتجاه متزامنة (SB-NMT) تتنبأ بمخرجاتها باستخدام فك التشفير من اليسار إلى اليمين ومن اليمين إلى اليسار في وقت واحد وبشكل تفاعلي ، من أجل الاستفادة من كل من التاريخ والمعلومات المستقبلية في نفس الوقت. على وجه التحديد ، نقترح أولاً خوارزمية جديدة تتيح فك تشفير ثنائي الاتجاه متزامن في نموذج واحد. بعد ذلك ، نقدم نموذجًا تفاعليًا لفك التشفير لا يعتمد فيه التوليد من اليسار إلى اليمين (من اليمين إلى اليسار) على مخرجاته التي تم إنشاؤها مسبقًا فحسب ، بل يعتمد أيضًا على السياقات المستقبلية التي تنبأ بها الاتجاه من اليمين إلى اليسار (من اليسار إلى اليسار) -right) فك التشفير. نقوم بتقييم نموذج SB-NMT المقترح على نطاق واسع على مهام الترجمة الصينية-الإنجليزية ، WMT14 الإنجليزية-الألمانية ، WMT18 الروسية-الإنجليزية على نطاق واسع. توضح النتائج التجريبية أن نموذجنا يحقق تحسينات كبيرة على نموذج Transformer القوي بمقدار 3.92 و 1.49 و 1.04 نقطة BLEU ، على التوالي ، ويحصل على أحدث أداء في مهام الترجمة الصينية-الإنجليزية والإنجليزية-الألمانية.', 'pt': 'As abordagens existentes para a tradução automática neural (NMT) geram a sequência do idioma de destino token por token da esquerda para a direita. No entanto, esse tipo de estrutura de decodificação unidirecional não pode fazer uso total dos contextos futuros do lado do destino que podem ser produzidos na direção de decodificação da direita para a esquerda e, portanto, sofre com o problema de saídas desbalanceadas. Neste artigo, apresentamos uma tradução automática bidirecional-neural síncrona (SB-NMT) que prevê suas saídas usando decodificação da esquerda para a direita e da direita para a esquerda simultaneamente e interativamente, a fim de alavancar tanto o histórico quanto as informações futuras ao mesmo tempo. Especificamente, primeiro propomos um novo algoritmo que permite a decodificação bidirecional síncrona em um único modelo. Em seguida, apresentamos um modelo de decodificação interativo no qual a geração da esquerda para a direita (direita para a esquerda) não depende apenas de suas saídas geradas anteriormente, mas também depende de contextos futuros previstos pela direita para a esquerda (da esquerda para a esquerda). -direita) decodificação. Avaliamos extensivamente o modelo SB-NMT proposto em tarefas de tradução de grande escala NIST chinês-inglês, WMT14 inglês-alemão e WMT18 russo-inglês. Os resultados experimentais demonstram que nosso modelo alcança melhorias significativas em relação ao modelo Transformer forte em 3,92, 1,49 e 1,04 pontos BLEU, respectivamente, e obtém o desempenho de última geração em tarefas de tradução chinês-inglês e inglês-alemão.', 'fr': "Les approches existantes de la traduction automatique neuronale (NMT) génèrent la séquence de langue cible jeton par jeton de gauche à droite. Cependant, ce type de cadre de décodage unidirectionnel ne peut pas exploiter pleinement les contextes futurs côté cible qui peuvent être produits dans une direction de décodage de droite à gauche, et souffre donc du problème de sorties déséquilibrées. Dans cet article, nous présentons une traduction automatique synchrone bidirectionnelle—neuronale (SB-NMT) qui prédit ses sorties en utilisant le décodage de gauche à droite et de droite à gauche simultanément et de manière interactive, afin d'exploiter à la fois l'historique et les informations futures en même temps. Plus précisément, nous proposons d'abord un nouvel algorithme qui permet le décodage bidirectionnel synchrone dans un seul modèle. Ensuite, nous présentons un modèle de décodage interactif dans lequel la génération de gauche à droite (de droite à gauche) dépend non seulement de ses sorties générées précédemment, mais repose également sur des contextes futurs prédits par le décodage de droite à gauche (de gauche à droite). Nous évaluons de manière approfondie le modèle SB-NMT proposé sur des tâches de traduction à grande échelle du NIST chinois—anglais, WMT14 anglais-allemand et WMT18 russe-anglais. Les résultats expérimentaux démontrent que notre modèle obtient des améliorations significatives par rapport au modèle Transformer fort de 3,92, 1,49 et 1,04 point BLEU, respectivement, et obtient les performances de pointe pour les tâches de traduction chinois—anglais et anglais-allemand.", 'es': 'Los enfoques existentes para la traducción automática neuronal (NMT) generan la secuencia del idioma de destino ficha por ficha de izquierda a derecha. Sin embargo, este tipo de marco de decodificación unidireccional no puede hacer pleno uso de los contextos futuros del lado del objetivo que se pueden producir en una dirección de decodificación de derecha a izquierda, y por lo tanto sufre el problema de las salidas desequilibradas. En este artículo, presentamos una traducción automática bidireccional-neuronal sincrónica (SB-NMT) que predice sus resultados mediante la decodificación de izquierda a derecha y de derecha a izquierda de forma simultánea e interactiva, para aprovechar tanto la historia como la información futura al mismo tiempo. Específicamente, primero proponemos un nuevo algoritmo que permite la decodificación bidireccional sincrónica en un solo modelo. A continuación, presentamos un modelo de decodificación interactivo en el que la generación de izquierda a derecha (de derecha a izquierda) no solo depende de sus salidas generadas previamente, sino que también se basa en contextos futuros predichos por la decodificación de derecha a izquierda (de izquierda a derecha). Evaluamos exhaustivamente el modelo SB-NMT propuesto en tareas de traducción a gran escala del NIST chino—inglés, WMT14 inglés—alemán y WMT18 ruso-inglés. Los resultados experimentales demuestran que nuestro modelo logra mejoras significativas con respecto al sólido modelo Transformer en 3,92, 1,49 y 1,04 puntos BLEU, respectivamente, y obtiene el rendimiento más avanzado en las tareas de traducción del chino al inglés y del inglés al alemán.', 'ja': '神経機械翻訳（ ＮＭＴ ）への既存のアプローチは、左から右へのトークンごとのターゲット言語シーケンスを生成する。 しかしながら、この種の一方向復号化フレームワークは、右から左への復号化方向で生成され得るターゲット側の将来のコンテキストを十分に利用することができず、したがって、不均衡な出力の問題に苦しむ。 本稿では、歴史と未来の情報の両方を同時に活用するために、左から右へ、右から左へのデコードを同時に対話的に使用してその出力を予測する同期双方向ニューラル機械翻訳（ SB - NMT ）を紹介する。 具体的には、まず単一のモデルで同期双方向デコードを可能にする新しいアルゴリズムを提案する。 次に、我々は、左から右（右から左）の生成が、その以前に生成された出力に依存するだけでなく、右から左（左から右）のデコードによって予測される将来のコンテキストにも依存するインタラクティブなデコードモデルを提示する。 私たちは、大規模なNIST中国語-英語、WMT 14英語-ドイツ語、およびWMT 18ロシア語-英語翻訳タスクで提案されたSB - NMTモデルを幅広く評価しています。 実験結果は、当社のモデルが、強力なトランスフォーマーモデルよりも、それぞれ3.92、1.49、1.04のBLEUポイントの大幅な改善を達成し、中国語-英語および英語-ドイツ語の翻訳タスクで最先端のパフォーマンスを得ることを実証しています。', 'zh': '今之神经机器翻译(NMT)法从左到右历而成目标语言序列。 然则单向解码框架不可尽用者,左解码之上下文也,而输之不平也。 本文引一同步双向神经机器翻译(SB-NMT),用从左到右、从右到左解码同时与交互式卜其输,以同时信息。 具体来说,首建同步双向解码新算法。 然后为交互式解码形,其从左到右(从右到左)生不独出于前,又赖于从右到左(从左到右)解码占之上下文。 博评SB-NMT大NIST中文-英语,WMT14英语 - 德语WMT18俄语 - 英语翻译之任。 实验结果表明,比于强变形金刚,则增3.92、1.49、1.04 BLEU,取最先进于中英、英德译。', 'hi': 'तंत्रिका मशीन अनुवाद (NMT) के लिए मौजूदा दृष्टिकोण लक्ष्य भाषा अनुक्रम टोकन-दर-टोकन को बाएं से दाएं उत्पन्न करते हैं। हालांकि, इस तरह का यूनिडायरेक्शनल डिकोडिंग फ्रेमवर्क लक्ष्य-पक्ष भविष्य के संदर्भों का पूरा उपयोग नहीं कर सकता है जिसे दाएं-से-बाएं डिकोडिंग दिशा में उत्पादित किया जा सकता है, और इस प्रकार असंतुलित आउटपुट के मुद्दे से ग्रस्त है। इस पेपर में, हम एक तुल्यकालिक द्विदिश-तंत्रिका मशीन अनुवाद (एसबी-एनएमटी) पेश करते हैं जो एक ही समय में इतिहास और भविष्य की जानकारी दोनों का लाभ उठाने के लिए एक साथ और इंटरैक्टिव रूप से बाएं-से-दाएं और दाएं-से-बाएं डिकोडिंग का उपयोग करके अपने आउटपुट की भविष्यवाणी करता है। विशेष रूप से, हम पहले एक नए एल्गोरिथ्म का प्रस्ताव करते हैं जो एक ही मॉडल में तुल्यकालिक द्विदिश डिकोडिंग को सक्षम बनाता है। फिर, हम एक इंटरैक्टिव डिकोडिंग मॉडल प्रस्तुत करते हैं जिसमें बाएं-से-दाएं (दाएं-से-बाएं) पीढ़ी न केवल अपने पहले से उत्पन्न आउटपुट पर निर्भर करती है, बल्कि दाएं-से-बाएं (बाएं से दाएं) डिकोडिंग द्वारा भविष्यवाणी किए गए भविष्य के संदर्भों पर भी निर्भर करती है। हम बड़े पैमाने पर NIST चीनी-अंग्रेजी, WMT14 अंग्रेजी-जर्मन, और WMT18 रूसी-अंग्रेजी अनुवाद कार्यों पर प्रस्तावित SB-NMT मॉडल का बड़े पैमाने पर मूल्यांकन करते हैं। प्रयोगात्मक परिणामों से पता चलता है कि हमारा मॉडल क्रमशः 3.92, 1.49, और 1.04 BLEU अंकों द्वारा मजबूत ट्रांसफॉर्मर मॉडल पर महत्वपूर्ण सुधार प्राप्त करता है, और चीनी-अंग्रेजी और अंग्रेजी-जर्मन अनुवाद कार्यों पर अत्याधुनिक प्रदर्शन प्राप्त करता है।', 'ru': 'Существующие подходы к нейронному машинному переводу (NMT) генерируют токен целевой языковой последовательности слева направо. Однако такого рода однонаправленная структура декодирования не может в полной мере использовать будущие целевые контексты, которые могут быть созданы в направлении декодирования справа налево, и, таким образом, страдает от проблемы несбалансированных результатов. В этой статье мы вводим синхронный двунаправленный нейронный машинный перевод (SB-NMT), который предсказывает свои выходы, используя декодирование слева направо и справа налево одновременно и интерактивно, чтобы одновременно использовать как историю, так и будущую информацию. В частности, мы сначала предлагаем новый алгоритм, который позволяет синхронное двунаправленное декодирование в одной модели. Затем мы представляем интерактивную модель декодирования, в которой генерация слева направо (справа налево) не только зависит от ранее сгенерированных результатов, но и опирается на будущие контексты, предсказанные декодированием справа налево (слева направо). Мы тщательно оцениваем предложенную модель SB-NMT на масштабных китайско-английских задачах перевода NIST, английско-немецких задачах WMT14 и русско-английских задачах перевода WMT18. Экспериментальные результаты показывают, что наша модель достигает значительных улучшений по сравнению с сильной моделью Transformer на 3,92, 1,49 и 1,04 балла BLEU, соответственно, и получает современную производительность по китайско-английским и английско-немецким задачам перевода.', 'ga': 'Gineann cuir chuige reatha maidir le haistriúchán meaisín néarach (NMT) seicheamh na sprioctheanga comhartha ar chomhartha ó chlé go deas. Mar sin féin, ní féidir leis an gcineál seo creata díchódaithe aontreoch úsáid iomlán a bhaint as comhthéacsanna taobh sprice amach anseo ar féidir a tháirgeadh i dtreo díchódaithe ó dheas go clé, agus dá bhrí sin tá saincheist na n-aschur neamhchothrom ag fulaingt leis. Sa pháipéar seo, tugaimid isteach aistriúchán meaisín sioncrónach déthreo-nearach (SB-NMT) a thuar a aschuir trí úsáid a bhaint as díchódú clé go deas agus ó dheas go comhuaineach agus go hidirghníomhach, chun an stair agus an fhaisnéis sa todhchaí a ghiaráil. ag an am céanna. Go sonrach, molaimid ar dtús algartam nua a chumasaíonn díchódú sioncronach déthreoch i múnla amháin. Ansin, cuirimid múnla díchódaithe idirghníomhach i láthair ina mbraitheann giniúint ó chlé go deas (ar dheis go clé) ní hamháin ar a haschuir a ghintear roimhe seo, ach ina mbraitheann sí freisin ar chomhthéacsanna sa todhchaí arna dtuar ag ceart go clé (clé go dtí). -ceart) díchódaithe. Déanaimid measúnú forleathan ar an tsamhail SB-NMT atá beartaithe ar thascanna aistriúcháin ar mhórscála NIST Sínis-Béarla, WMT14 Béarla-Gearmáinis, agus WMT18 Rúisis-Béarla. Léiríonn torthaí turgnamhacha go mbaineann ár múnla feabhsuithe suntasacha amach thar an tsamhail láidir Transformer le 3.92, 1.49, agus 1.04 pointe BLEU, faoi seach, agus faigheann sé an fheidhmíocht den scoth ar thascanna aistriúcháin Sínis-Béarla agus Béarla-Gearmáinis.', 'el': 'Οι υπάρχουσες προσεγγίσεις για τη νευρωνική μηχανική μετάφραση (NMT) παράγουν την ακολουθία γλώσσας-στόχο από αριστερά προς τα δεξιά. Ωστόσο, αυτό το είδος ενός μονοκατευθυνόμενου πλαισίου αποκωδικοποίησης δεν μπορεί να αξιοποιήσει πλήρως τα μελλοντικά πλαίσια της στοχευόμενης πλευράς, τα οποία μπορούν να παραχθούν με κατεύθυνση αποκωδικοποίησης από δεξιά προς αριστερά, και συνεπώς υποφέρει από το ζήτημα των μη ισορροπημένων αποτελεσμάτων. Στην παρούσα εργασία, εισάγουμε μια σύγχρονη αμφίδρομη-νευρωνική μηχανική μετάφραση (SB-NMT), η οποία προβλέπει τα αποτελέσματά της χρησιμοποιώντας αποκωδικοποίηση από αριστερά προς δεξιά και από δεξιά προς αριστερά ταυτόχρονα και αλληλεπιδραστικά, προκειμένου να αξιοποιήσει ταυτόχρονα τόσο την ιστορία όσο και τις μελλοντικές πληροφορίες. Συγκεκριμένα, προτείνουμε πρώτα έναν νέο αλγόριθμο που επιτρέπει τη συγχρονισμένη αμφίδρομη αποκωδικοποίηση σε ένα μόνο μοντέλο. Στη συνέχεια, παρουσιάζουμε ένα διαδραστικό μοντέλο αποκωδικοποίησης στο οποίο η παραγωγή από αριστερά προς δεξιά (από δεξιά προς αριστερά) δεν εξαρτάται μόνο από τις προηγούμενες αποδόσεις της, αλλά βασίζεται επίσης σε μελλοντικά πλαίσια που προβλέπονται από αποκωδικοποίηση από δεξιά προς αριστερά (από αριστερά προς δεξιά). Αξιολογούμε εκτενώς το προτεινόμενο μοντέλο σε μεγάλης κλίμακας κινεζικά-αγγλικά, αγγλικά-γερμανικά και ρωσικά-αγγλικά μεταφραστικά καθήκοντα. Τα πειραματικά αποτελέσματα καταδεικνύουν ότι το μοντέλο μας επιτυγχάνει σημαντικές βελτιώσεις έναντι του ισχυρού μοντέλου μετασχηματιστή κατά τα σημεία 3.92, 1.49 και 1.04 αντίστοιχα, και επιτυγχάνει την υπερσύγχρονη απόδοση σε κινεζικά-αγγλικά και αγγλικά-γερμανικά μεταφραστικά καθήκοντα.', 'it': "Gli approcci esistenti alla traduzione automatica neurale (NMT) generano la sequenza della lingua di destinazione token per token da sinistra a destra. Tuttavia, questo tipo di quadro di decodifica unidirezionale non può sfruttare appieno i contesti futuri di destinazione che possono essere prodotti in una direzione di decodifica da destra a sinistra, e quindi soffre del problema di output sbilanciati. In questo articolo, presentiamo una traduzione automatica bidirezionale-neurale sincrona (SB-NMT) che prevede i suoi output utilizzando la decodifica da sinistra a destra e da destra a sinistra simultaneamente e interattivamente, al fine di sfruttare sia la storia che le informazioni future allo stesso tempo. Nello specifico, proponiamo innanzitutto un nuovo algoritmo che consente la decodifica bidirezionale sincrona in un unico modello. Quindi, presentiamo un modello di decodifica interattiva in cui la generazione da sinistra a destra (da destra a sinistra) non dipende solo dai suoi output generati in precedenza, ma si basa anche su contesti futuri previsti dalla decodifica da destra a sinistra (da sinistra a destra). Valutiamo ampiamente il modello SB-NMT proposto su larga scala nelle attività di traduzione NIST cinese-inglese, WMT14 inglese-tedesco e WMT18 russo-inglese. I risultati sperimentali dimostrano che il nostro modello raggiunge miglioramenti significativi rispetto al modello Transformer forte rispettivamente di 3,92, 1,49 e 1,04 punti BLEU e ottiene le prestazioni all'avanguardia nelle attività di traduzione cinese-inglese e inglese-tedesco.", 'hu': 'A neurális gépi fordítás (NMT) meglévő megközelítései balról jobbra generálják a célnyelvi szekvenciát. Ez a fajta egyirányú dekódolási keret azonban nem tudja teljes mértékben kihasználni a céloldali jövőbeli kontextusokat, amelyek jobbról balra dekódolhatók, és így a kiegyensúlyozatlan kimenetek problémájától szenved. Ebben a tanulmányban bemutatunk egy szinkron kétirányú-neurális gépi fordítást (SB-NMT), amely balról jobbra és jobbról balra dekódolással egyidejűleg és interaktív módon előrejelzi kimeneteit annak érdekében, hogy mind a történelem, mind a jövőbeli információk egyidejűleg hasznosíthatók legyenek. Konkrétan először egy új algoritmust javasolunk, amely lehetővé teszi a szinkron kétirányú dekódolást egyetlen modellben. Ezután bemutatunk egy interaktív dekódolási modellt, amelyben a bal-jobbról jobbra (jobbról balra) generáció nemcsak a korábban generált kimenetektől függ, hanem a jobb-balra (balról jobbra) dekódolás által előrejelzett jövőbeli kontextusokra is támaszkodik. A javasolt SB-NMT modellt nagyszabású NIST kínai-angol, WMT14 angol-német és WMT18 orosz-angol fordítási feladatokban értékeljük. Kísérleti eredmények azt mutatják, hogy modellünk jelentős javulást ér el az erős Transformer modellhez képest 3,92, 1,49, illetve 1,04 BLEU ponttal, valamint a kínai-angol és angol-német fordítási feladatokhoz képest.', 'ka': 'მხოლოდ ნეიროლური მაქსინის გარგზავნა (NMT) მიწყებული ენის წერტილის წერტილის წერტილის token- by- token მარცხენა და მარცხენა. მაგრამ, ეს სახელი ერთეთრექციონალური ევკოდირების ფრამეტრი არ შეიძლება ყველაფერი გამოყენება მიზედან მომავალური კონტექსტზე, რომელიც შეიძლება გამოყენება მარცხნივ მარცხნივ მარცხნივ მარც ამ დომენტში ჩვენ ჩვენ შევცვალოთ სინქრონური მენეირექციონალ-ნეირექციონალ მანქანის გაგრძელება (SB-NMT), რომელიც წარმოდგენს მისი გაგრძელება მარცხენა და მარცხენა და მარცხენა მარცხენა დიკოდირებას ერთად და ინტერქციონა განსაკუთრებულია, ჩვენ პირველი მინდა ახალი ალგორიტიმ, რომელიც ერთი მოდელში სინქრონური მედირექციონალური ევკოდირექციის შესაძლებელია. შემდეგ ჩვენ ჩვენ ინტერექტიური დეკოდირების მოდელს ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენებთ, რომელიც მარჯვნიდან მარჯვნიდან მარჯვნიდან (მარჯვნიდან მარჯვნიდან) დეკოდირებით არ ჩვენ ძალიან გავამუშავებთ შესაძლებელი SB-NMT მოდელის დიდი მაგალითი NIST კინელი, WMT14 ინგლისური-გერმანური და WMT18 პროსური-ანგლისური გაგრძელება. ექსპერიმენტიური წარმოდგენა, რომ ჩვენი მოდელი უფრო მნიშვნელოვანელოვანია 3.92, 1.49 და 1.04 BLEU წარმოდგენებით, და ჩინეთი-ანგლისური და ინგლისური-გერმანური გარგენისთვის წარმოდგენება.', 'mk': 'Постојаните пристапи до нервен машински превод (NMT) генерираат секвенца на јазик на мета token- by- token од лево на десно. Сепак, овој вид на еднонасочна рамка за декодирање не може целосно да ги искористи идните контексти на страната на целта кои може да се произведуваат во право-лево декодирање, и со тоа страдаат од прашањето на небалансираните излези. In this paper, we introduce a synchronous bidirectional-neural machine translation (SB-NMT) that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time.  Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model.  Потоа, претставуваме интерактивен модел на декодирање во кој генерацијата од лево до десно (од десно до лево) не зависи само од претходно генерираните излези, туку и од идните контексти предвидени со декодирање од десно до лево (од лево до десно). Ги проценуваме предложените СБ-НМТ модели на голема ниСТ кинески-англиски, ВМТ14 англиски-германски и ВМТ18 руски-англиски преведувачки задачи. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points, respectively, and obtains the state-of-the-art performance on Chinese-English and English-German translation tasks.', 'ml': 'ന്യൂറല്\u200d യന്ത്രത്തിന്റെ പരിഭാഷക്ക് (NMT) നിലവിലുള്ള അടുത്തുവരുന്ന സമീപത്തുകള്\u200d ഇടത്തോട്ട് നിന്നും വലത്തോട്ട് നിന്നും  എന്നാലും ഇത്തരം തിരഞ്ഞെടുക്കുന്ന കോഡിങ്ങ് ഫ്രെയിമെക്ക് പൂര്\u200dണ്ണമായി ഉപയോഗിക്കാന്\u200d സാധിക്കുന്നില്ല. അത് വലത്തോട്ടും ഇടത്തോട്ടും കോഡിങ്ങ് ത ഈ പത്രത്തില്\u200d നമ്മള്\u200d ഒരു സങ്കീര്\u200dണ്ണമായ ബിഡിരിക്കന്\u200d ന്യൂറല്\u200d മെഷിന്\u200d പരിഭാഷയെ പരിചയപ്പെടുത്തുന്നു. അത് ഇടത്തോട്ടും വലത്തോട്ടും ഇടത്തോട്ടും ഇടത്തോട്ടും ഇടത്തോട്ടും ഇടത്തോട്ടും കുറ Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model.  പിന്നെ നമ്മള്\u200d ഇടത്തോട്ട് വലത്തോട്ടും ഇടത്തോട്ടും ഇടത്തോട്ടും തലമുറതലമുറയില്\u200d നിന്നും അതിന്\u200dറെ മുമ്പ് ഉണ്ടാക്കിയ പുറത്ത് മാത്രമേ ആശ്രയിക്കുന്നുള്ളൂ, പക്ഷെ വലത ഞങ്ങള്\u200d വിശാലമായി പ്രാദോഷ്ട്രം ചെയ്ത SB-NMT മോഡല്\u200d വിലാസപ്പെടുത്തുന്നു. NIST ചൈനീസ്-ഇംഗ്ലീഷ്, WMT14 ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d, WMT18 റു പരീക്ഷണത്തിന്റെ ഫലങ്ങള്\u200d വ്യക്തമാക്കിയിരിക്കുന്നു നമ്മുടെ മോഡല്\u200d 3. 92, 1. 49, 1. 04 ബിലിയൂ പോയിന്റുകള്\u200dക്ക് വേണ്ടി വളരെ മെച്ചപ്പെടുത്തുന്നത്, ചൈനീസ്- ഇംഗ്ലീഷ്- ജര', 'mt': 'Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right.  Madankollu, dan it-tip ta’ qafas ta’ dekodifikazzjoni unidirezzjonali ma jistax jagħmel użu sħiħ mill-kuntesti futuri min-naħa tal-mira li jistgħu jiġu prodotti f’direzzjoni ta’ dekodifikazzjoni minn lemin għal xellug, u għalhekk isofri mill-kwistjoni ta’ riżultati mhux bilanċjati. F’dan id-dokument, a ħna nintroduċu traduzzjoni sinkronika ta’ magni bidirezzjonali-newrali (SB-NMT) li tipprevedi l-eżiti tagħha bl-użu ta’ dekodifikazzjoni mix-xellug għal-lemin u mix-xellug simultanjament u interattivament, sabiex tinbena kemm l-istorja kif ukoll l-informazzjoni futura fl-istess ħin. Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model.  Then, we present an interactive decoding model in which left-to-right (right-to-left) generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left (left-to-right) decoding.  Aħna jevalwaw b’mod estensiv il-mudell SB-NMT propost dwar kompiti ta’ traduzzjoni fuq skala kbira NIST Ċiniż-Ingliż, WMT14 Ingliż-Ġermaniż, u WMT18 Russu-Ingliż. Riżultati esperimentali juru li l-mudell tagħna jikseb titjib sinifikanti fuq il-mudell b’saħħtu Transformer bi 3.92, 1.49, u 1.04 punti BLEU, rispettivament, u jikseb l-aħjar prestazzjoni fuq kompiti ta’ traduzzjoni Ċiniża-Ingliża u Ingliża-Ġermaniża.', 'mn': 'Бүгдээрээ мэдрэлийн машины хөрөнгө оруулалт (NMT) нь зорилготой хэл дарааллын ток-by-ток баруун руу үүсгэдэг. Гэвч энэ төрлийн нэг багын загвар нь ирээдүйн зорилготой орчинд баруун зүүн, зүүн тархинд бүтээж чадах зорилготой орчинд бүрэн ашиглаж чадахгүй. Иймээс тэнцвэртэй үр дүн асуудлын асуудлыг шаналдаг. Энэ цаасан дээр бид түүх болон ирээдүйн мэдээллийг нэг зэрэг ашиглан зүүн, баруун, баруун, баруун, зүүн зэрэг шилжүүлэх болон интерактив байдлын шилжүүлэлтийг тайлбарлаж байна. Эхлээд бид нэг загвар дээр шинэ алгоритм шинээр санал болгож байна. Тэгээд бид зүүн, баруун, баруун (баруун, зүүн, зүүн) үеийнх нь өмнө үүсгэсэн үр дүн дээр хамаарч байгаагүй интерактив загварын загварыг илэрхийлж байна. Баруун, зүүн, баруун (зүүн, баруун) үеийнх нь мөн ирээдүйн орчинд хамаарч байна. Бид том хэмжээний NIST Хятад-Англи, WMT14 Англи-Герман, WMT18 Российн-Англи хэлний хөрөнгө оруулах ажлын тухай санал дэвшүүлсэн SB-NMT загварыг нэмэгдүүлэн үнэлдэг. Эмчилгээний үр дүнд бидний загвар нь 3.92, 1.49 болон 1.04 BLEU цэг дээр хүчирхэг Трансфер загварын тулд чухал сайжруулалт гаргаж, Хятад-Англи, Англи-Германы орчуулалтын даалгаврууд дээр урлагийн үйл ажиллагааг гаргаж байна.', 'no': 'Det eksisterande tilnærmingar til neuralmaskinsomsetjing (NMT) lager målsprøvesekvensen token-by-token frå venstre til høgre. Men denne typen unidirektivne dekodingsrammeverket kan ikkje fullstendig bruka av framtidige kontekstane for målside som kan lagast i ein retning til høgre til venstre, og dermed blir problemet med ubebalanserte utdata. I denne papiret introduserer vi ein synkronisk oversettelse av neuralmaskina (SB-NMT) som foregår utdata sitt ved høgre-til-høgre og høgre-til-venstre dekoding samtidig og interaktivt for å levera både historien og framtidige informasjon samtidig. Spesielt, vi først foreslår ein ny algoritme som slår på synkronisk bidireksjonal dekoding i ein enkel modell. Deretter presenterer vi eit interaktiv dekodingsmodell der det ikkje berre høgre til venstre (høgre til venstre) er avhengig av dei førre genererte utdata, men også er avhengig av framtidige kontekstar som foregår av dekoding høgre til venstre (venstre til høgre). Vi evaluerer det foreslåde SB-NMT-modellet på stor grad NIST kinesisk-engelsk, WMT14 engelsk-tysk og WMT18 russisk-engelsk oversettelsesoppgåver. Eksperimentale resultat viser at modellen vårt når det gjer signifikante forbedringar over den sterke transformeringsmodellen med 3,92, 1,49 og 1,04 BLEU-punkt, og får tilstanden til kunsthandlinga på kinesisk-engelsk og engelsk-tysk omsetjingsprogrammet.', 'pl': 'Istniejące podejścia do neuronowego tłumaczenia maszynowego (NMT) generują sekwencję języka docelowego token po tokenie od lewej do prawej. Jednakże tego rodzaju jednokierunkowe ramy dekodowania nie mogą w pełni wykorzystać przyszłych kontekstów docelowych, które mogą być produkowane w kierunku dekodowania od prawej do lewej, a tym samym cierpią na problem niezrównoważonych wyników. W niniejszym artykule przedstawiamy synchroniczne dwukierunkowe tłumaczenie maszynowe (SB-NMT), które przewiduje jej wyjścia przy użyciu dekodowania lewo-prawo i prawo-lewo jednocześnie i interaktywnie, w celu wykorzystania zarówno historii, jak i przyszłości informacji w tym samym czasie. W szczególności, najpierw proponujemy nowy algorytm umożliwiający synchroniczne dekodowanie dwukierunkowe w jednym modelu. Następnie przedstawiamy interaktywny model dekodowania, w którym generowanie lewej do prawej (prawej do lewej) zależy nie tylko od wcześniej generowanych wyników, ale także od przyszłych kontekstów przewidywanych dekodowaniem prawej do lewej (lewej do prawej). Szczegółowo oceniamy proponowany model SB-NMT na dużej skali NIST chińsko-angielski, WMT14 angielsko-niemiecki i WMT18 rosyjsko-angielski zadania tłumaczeniowe. Wyniki eksperymentalne pokazują, że nasz model osiąga znaczące ulepszenia w stosunku do silnego modelu Transformera odpowiednio o punkty 3.92, 1.49 i 1.04 BLEU oraz uzyskuje najnowocześniejszą wydajność w zakresie tłumaczeń chińsko-angielskich i angielsko-niemieckich.', 'kk': 'Невралдық компьютерді аудару (NMT) арқылы бар жағдайлар мақсатты тіл ретінде сол жақтан оң жақтан белгілеу тогін құрады. Бірақ бұл түрлі бірбағытты декодтау қоршауы оң жақтан сол жақтан декодтау бағыттарында құрылатын мақсатты келесі контексттерді толық қолдануға болмайды. Сонымен қатар бағытталмаған шығыс мәселесі болады. Бұл қағазда біз бірден сол жақтан сол жақтан оң жақтан сол жақтан интерактивті декодтау үшін, тарихты және келесі мәліметті бірден өзгерту үшін синхроналық невралдық компьютердің аударуын (SB- NMT) келтіреміз. Ескерту үшін біріншіден қадамдастыру үлгісін қолдануға мүмкіндік беретін жаңа алгоритм жұмыс істейміз. Содан кейін, біз сол жақтан оң жақтан (оң жақтан сол жақтан) құрылған интерактивті декодтау үлгісін таңдаймыз. Сонымен қатар, оң жақтан сол жақтан (сол жақтан оң жақтан) декодтау үлгісінен тәуелді емес. Біз SB-NMT үлкен өлшемді NIST қытайша-ағылшын, WMT14 ағылшын- неміс және WMT18 рус- ағылшын аудармаларының тапсырмаларының үлкен үлгі үлгі үлгі үлгі үлгісін қолд Эксперименталдық нәтижелері біздің үлгіміздің 3,92, 1,49 және 1,04 BLEU нәтижелері үшін күш түрлендіруші үлгісінің жақсы жақсартылығын көрсетеді. Қытай-ағылшын және ағылшын-неміс аудару тапсырмаларындағы к', 'ro': 'Abordările existente pentru traducerea automată neurală (NMT) generează secvența limbii țintă token-by-token de la stânga la dreapta. Cu toate acestea, acest tip de cadru de decodare unidirecțională nu poate utiliza pe deplin contextele viitoare din partea țintă care pot fi produse într-o direcție de decodare de la dreapta la stânga și, prin urmare, suferă de problema rezultatelor dezechilibrate. În această lucrare, introducem o traducere automată bidirecțională-neurală sincronă (SB-NMT) care prezice ieșirile sale folosind decodarea de la stânga la dreapta și de la dreapta la stânga simultan și interactiv, pentru a valorifica atât istoria, cât și informațiile viitoare în același timp. Mai exact, propunem mai întâi un nou algoritm care permite decodarea sincronă bidirecțională într-un singur model. Apoi, prezentăm un model interactiv de decodare în care generarea de la stânga la dreapta (de la dreapta la stânga) nu depinde doar de ieșirile generate anterior, ci se bazează și pe contextele viitoare prevăzute de decodarea de la dreapta la stânga (de la stânga la dreapta). Evaluăm pe scară largă modelul SB-NMT propus pentru sarcini de traducere NIST chineză-engleză, WMT14 engleză-germană și WMT18 rusă-engleză. Rezultatele experimentale demonstrează că modelul nostru obține îmbunătățiri semnificative față de modelul puternic Transformer cu 3,92, 1,49 și respectiv 1,04 puncte BLEU și obține performanțe de ultimă oră în ceea ce privește sarcinile de traducere chineză-engleză și engleză-germană.', 'sr': 'Postoje pristupi prevodu neuralne mašine (NMT) stvaraju znak za ciljne jezičke sekvence od lijeve do desne strane. Međutim, ovakva vrsta jednodirektivnog okvira za dekodiranje ne može potpuno iskoristiti buduće kontekste ciljne strane koje se mogu proizvesti u pravom desnom na levom pravcu za dekodiranje, i tako pati od pitanja nepravednog ishoda. U ovom papiru predstavljamo sinhronski prevod neuralne mašine (SB-NMT), koji predviđa svoje izlaze koristeći lijevo-desno-desno-desno-lijevo dekodiranje istovremeno i interaktivno, kako bi uticali na istoriju i buduće informacije u isto vrijeme. Posebno, prvi put predlažemo novi algoritam koji omogućava sinhronski bidirektivni dekodiranje u jednom modelu. Onda predstavljamo interaktivan model dekodiranja u kojem generacija lijeve na desno na lijevo (desno na lijevo) ne samo zavisi od njegovih prethodnih ishoda, nego takođe oslanja na buduće kontekste predviđene desno na lijevo (lijevo na desno). Prošireno procjenjujemo predloženi model SB-NMT na velikoj skali NIST kineskog-engleskog, WMT14 engleskog-nemačkog i WMT18 ruskog-engleskog prevodnog zadataka. Eksperimentalni rezultati pokazuju da naš model postiže značajne poboljšanja nad jakim modelom transformera sa 3,92, 1,49 i 1,04 BLEU bodova, odnosno, i dobija državnu predstavu umjetnosti na zadatke prevođenja kineskog i engleskog i njemačkog jezika.', 'so': 'Turjumidda neural machine (NMT) ayaa soo saara qoraalka luqada ee la jeedo token-by-token xagga bidix ilaa midig. Si kastaba ha ahaatee, nooca kooxaha ah oo qurxinta shaqaalaha ah ma wada isticmaali karo tartanka mustaqbalka ee jimicsiga, taas oo lagu soo saari karo dhanka midig iyo bidixda, sababtuna waxay ka dhibaataysaa dhibaatada soo bixinta aan la qiimo karin. Qoraalkan waxaynu ku soo bandhignaa tarjumaadka baabuurta neurada ah (SB-NMT) oo soo hor jeeda midigta iyo midigta iyo bidixda, si aan u soo dirno taariikhda iyo macluumaadka mustaqbalka. Si gaar ah, marka ugu horeysa waxaynu soo jeedaynaa algorithm cusub oo ku habboon kara kaadeynta hal qaab ah. Markaas waxaynu keenaynaa model isku mid ah oo ku qoran qarniga bidixda iyo bidixda (midigta-ilaa bidixda) oo aan ku xiran dhamaantood oo kaliya midhihiisa hore ka soo baxay, wuxuuse ku xiran karaa xilliyada mustaqbalka ah oo ka horraysa qorraxda midigta-ilaa-bidixda (midigta-midigta). Tusaalada la soo jeeday SB-NMT oo ku saabsan qoraalka afka badan ee NIST Shiino-Ingiriis, WMT14 Ingiriis-Jarmal iyo WMT18 shaqooyinka turjumaadda afka ingiriiska-Ingiriis. Imtixaanka waxaa ka muuqda in modellkayagu uu kordhin karo qaab ahaan 3.92, 1.49 iyo 1.04 BLEU, wuxuuna helaa sameynta farshaxanka farshaxanka ah oo ku qoran shaqooyinka turjumidda Shiino-Ingiriis iyo Ingiriis-Jarmal.', 'sv': 'Befintliga metoder för neural maskinöversättning (NMT) genererar målspråkssekvensen token för token från vänster till höger. Denna typ av enriktad avkodningsram kan dock inte fullt ut utnyttja de framtida kontexterna på målsidan som kan produceras i en dekodningsriktning från höger till vänster, och lider därmed av frågan om obalanserade resultat. I denna uppsats introducerar vi en synkron dubbelriktad-neural maskinöversättning (SB-NMT) som förutspår dess utgångar med hjälp av vänster-till-höger och höger-till-vänster avkodning samtidigt och interaktivt, för att utnyttja både historia och framtida information på samma gång. Specifikt föreslår vi först en ny algoritm som möjliggör synkron dubbelriktad avkodning i en enda modell. Sedan presenterar vi en interaktiv avkodningsmodell där vänster-till-höger (höger-till-vänster) generation inte bara beror på dess tidigare genererade utgångar, utan också förlitar sig på framtida kontexter som förutses av höger-till-vänster (vänster-till-höger) avkodning. Vi utvärderar ingående den föreslagna SB-NMT-modellen på storskaliga NIST kinesiska-engelska, WMT14 engelsk-tyska och WMT18 rysk-engelska översättningsuppgifter. Experimentella resultat visar att vår modell uppnår betydande förbättringar jämfört med den starka Transformermodellen med 3,92, 1,49 respektive 1,04 BLEU poäng, och uppnår toppmoderna prestanda i kinesiska-engelska och engelsk-tyska översättningsuppgifter.', 'ta': 'Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right.  ஆனால், இந்த வகையான தனிப்பட்ட அலங்காரத்தின் சட்டத்தை முழுமையாக பயன்படுத்த முடியாது இலக்க- பக்கம் எதிர்கால முடிவுகளை உருவாக்கும் வலப்புறமும் இடப்புறமு இந்த காக்கியத்தில், நாம் ஒரு ஒத்திசைக்கூடிய ஒத்திசைநிரல் புதிய மொழிமாற்றி (SB- NMT) மொழிமாற்றியமைக்கிறோம். அது அதன் வெளியீடு குறிப்பிட்டு, நாம் முதலில் ஒரு புதிய முறைமையை பரிந்துரைக்கிறோம். அது ஒற்றை மாதிரியில் ஒத்திசைவு குறியீட்ட பின்னர், நாம் ஒரு இடைவெளி அலங்காரத்தின் மாதிரியை காண்பிக்கிறோம். இதில் இடப்புறத்திலிருந்து வலப்புறத்திலிருந்து இடதுபுறத்திலிருந்து இடப்புறத்திலிருந்து இட @ info சோதனையின் முடிவுகள் தெரிவிக்கும் மாதிரி 3. 92, 1. 49, மற்றும் 1. 04 பிலியு புள்ளிகள் மற்றும் சீனா- ஆங்கிலம் மற்றும் ஜெர்மன் மொழிபெயர்ப்பு பணிகளில் மாதிரி செயல்பாட்டை', 'ur': 'موجود نیورال ماشین ترجمہ (NMT) کے لئے موجود موجود طریقے ہیں کہ موجود زبان ترجمہ ٹوکنن بائیں سے دائیں طرف سے پیدا کرتا ہے۔ However, this type of unidirectional decoding framework cannot complete use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffer from the problem of unbalanced outputs. اس کاغذ میں ہم ایک سینکرون بیڈیریکسون-نیورال ماشین کی ترجمہ (SB-NMT) کو معرفی کرتے ہیں جو بائیں سے دائیں سے بائیں سے اور دائیں سے بائیں سے دھوکیڈ کے استعمال کرتے ہیں، تاریخ اور مستقبل معلومات کو ایک ہی دفعہ کے مطابق اضافہ کرنے کے لئے۔ مخصوص طور پر، ہم پہلے ایک نئی الگوریٹم کی پیشنهاد کریں جو ایک مدل میں سینکرون دوئرکیشن ڈیکوڈ کرتا ہے. پھر ہم ایک انٹراکیٹ ڈیکوڈ موڈل پیش کرتے ہیں جس میں بائیں بائیں بائیں سے دائیں کی نسل صرف اس سے پہلے پیدا کئے ہوئے نتیجے پر اعتماد نہیں کرتی بلکہ دائیں بائیں سے بائیں کے ڈیکوڈ سے پیش کیا گیا ہے ہم بہت بڑے اندازے کے NIST چینی-انگلیسی، WMT14 انگلیسی-جرمنی اور WMT18 روسی-انگلیسی ترجمہ کے کاموں پر پیشنهاد کی SB-NMT موڈل کا ارزش کریں گے. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points respectively, and obtains the state-of-the-art performance on Chinese-English and English-German translation tasks.', 'lt': 'Esami metodai nervinių mašinų vertimui (NMT) sukuria tikslinės kalbos sekos ženklą po ženklo iš kairės į dešinę. However, this kind of unidirectional decoding framework cannot make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs.  Šiame dokumente pristatome sinchroninį dvikryptinį ir nervinį mašin ų vertimą (SB-NMT), kuris numato jo rezultatus, naudojant vienu metu ir interaktyviai dešinėje į dešinę ir dešinėje į kairę kodavimą, kad būtų galima sutelkti istoriją ir būsimą informaciją tuo pačiu metu. Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model.  Then, we present an interactive decoding model in which left-to-right (right-to-left) generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left (left-to-right) decoding.  Mes išsamiai vertiname siūlomą SB-NMT model į dėl didelio masto NIST kinų-anglų, WMT14 anglų-vokiečių ir WMT18 rusų-anglų vertimo užduočių. Eksperimentiniai rezultatai rodo, kad mūsų modelis gerokai pagerina stiprų Transformer model į atitinkamai 3,92, 1,49 ir 1,04 BLEU taškų, o Kinijos-anglų ir anglų-vokiečių vertimo užduočių pažangiausi rezultatai.', 'si': 'ඉතින් ඉතින් ප්\u200dරවේශය න්\u200dයූරල් යන්ත්\u200dරය භාෂාව (NMT) ලක්ෂ භාෂාව ප්\u200dරවේශය ටෝකෙන් වෙන්න පුළුවන්. නමුත්, මේ වර්ගයක් ප්\u200dරමාණයක් ප්\u200dරමාණයක් නිර්මාණය කරන්න බෑ ඉලක්ක-පැත්තේ අනාගතයේ අනාගතයේ ප්\u200dරමාණයක් සම්පූර්ණය කරන්න පුළුවන් වෙන් මේ පැත්තේ, අපි සමාන්\u200dය විදියට සමාන්\u200dය විදියට-න්\u200dයූරාල් මැෂින් අවවාදය (SB-NMT) කිරීම් කරනවා ඒකේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති විශේෂයෙන්, අපි මුලින්ම අළුත් ඇල්ගෝරිතම් කිරීමක් ප්\u200dරතිස්ථාපනය කරනවා, ඒකෙන් එක්ක මොඩල් එකෙන් සමා ඊට පස්සේ, අපි පෙන්වන්නේ ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක (දකුණු දකුණු දකුණු දකුණු  අපි ලොකු ප්\u200dරමාණය NIST චීනි-ඉංග්\u200dරීසි, WMT14 ඉංග්\u200dරීසි-ජර්මන්, WMT18 රුසියි-ඉංග්\u200dරීසි භාෂා වැඩේ ප්\u200dරයෝජනය කරනවා. පරීක්ෂණාත්මක ප්\u200dරතික්ෂාව පෙන්වන්නේ අපේ මොඩල් එක්ක ශක්තිමත් ප්\u200dරතික්\u200dරියාත්මක විශාල විස්තර කරනවා 3.92, 1.49, සහ 1.04 BLUE ප්\u200dරතික්\u200dරියාත්මක විස', 'ms': 'Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right.  However, this kind of unidirectional decoding framework cannot make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs.  In this paper, we introduce a synchronous bidirectional-neural machine translation (SB-NMT) that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time.  Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model.  Then, we present an interactive decoding model in which left-to-right (right-to-left) generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left (left-to-right) decoding.  Kami menilai secara ekstensif model SB-NMT yang diusulkan pada skala besar NIST Cina-Inggeris, WMT14 Inggeris-Jerman, dan WMT18 tugas terjemahan Rusia-Inggeris. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points, respectively, and obtains the state-of-the-art performance on Chinese-English and English-German translation tasks.', 'uz': "@ info: whatsthis Lekin, bu bir xil kodlash freymi kelajakdagi xizmatlarni to ʻliq ishlatib boʻlmaydi. Uni chapdan chapga kodlash usulida yaratish mumkin. Bu qogʻozda biz bir xil tarjima (SB-NMT) tarjima qilamiz, bu yerda chap-chap va chap-chap kodlash usulini ko'rsatadi, va bu paytda bir nechta tarixi va kelajak maʼlumotni bir vaqtda yozib olish uchun. Koʻrsatilgan, biz birinchi marta birinchi birinchi bir modelda synchronous bidirktikal kodlash imkoniyatini beradi. Keyin biz chap tomondan (chapdan chapga) uzunlar faqat avval yaratilgan natijalariga ishlatmaydi, balki kelajakdagi qismlarga ishlatadigan qismlarga ishlatadi. Biz katta xitoycha- Inglizcha, WMT14 Inglizcha- Olmonchaga va WMT18 Ruscha- Inglizcha tarjima vazifalarini qiymatimiz. Tajriba natijalari esa modelmiz 3.92, 1.49 va 1.04 BLEU nuqta bilan kuchli Transformer modeliga juda yaxshi o'zgarishni ko'rsatadi va Xitoycha- Ingliz- Ingliz- Ingliz- Olmonchaga tarjima qilish vazifalarining holatini qabul qiladi.", 'vi': 'Sự tồn tại của các tiếp cận dịch máy thần kinh (NMB) tạo ra chuỗi ngôn ngữ đích, tượng trưng từ trái sang phải. Tuy nhiên, loại khung dẫn không thể định hướng này không thể tận dụng hoàn to àn các mặt tương lai đối với mục tiêu mà chúng ta có thể tạo ra theo hướng dẫn dẫn dẫn dẫn dẫn dẫn dẫn dẫn dẫn giữa phải và trái, và do đó chúng ta phải chịu đựng những kết quả không cân bằng. Trong tờ giấy này, chúng tôi giới thiệu một bản dịch thiết bị thần kinh đồng bộ (SB-NMT) dự đoán kết quả của nó bằng cách giải mã trái-phải-phải-sang-trái đồng thời và tương tác, để hỗ trợ cả lịch sử và thông tin tương lai cùng lúc. Cụ thể, chúng tôi đề xuất một thuật toán mới cho phép thiết lập di động đồng bộ trong một mô hình duy nhất. Sau đó, chúng tôi có một mô hình giải mã tương tác trong đó thế hệ từ trái sang phải không chỉ phụ thuộc vào các kết quả được tạo ra trước đây, mà còn phụ thuộc vào các ngữ cảnh tương lai được dự đoán bởi thiết kế từ phải sang phải. Chúng tôi đánh giá sâu về mô hình ước tính của SBN-NMT trên diện lớn NIST tiếng Trung Quốc-Anh, WRT14 người Anh-Đức, và WRT18 dịch vụ tiếng Nga-Anh. Kết quả thí nghiệm chứng minh rằng mô hình của chúng ta đạt được những cải tiến đáng kể về mô hình biến biến mạnh của 3.92, 1.42, và 1.04 liên quan tới nguyên tắc dịch vụ Hoa Kỳ và Anh-Đức.', 'bg': 'Съществуващите подходи за невронен машинен превод генерират последователността на целевия език символ по символ от ляво на дясно. Този вид рамка за еднопосочно декодиране обаче не може да използва изцяло бъдещите контексти от целевата страна, които могат да бъдат произведени в посока декодиране отдясно наляво, и по този начин страдат от проблема с небалансираните резултати. В настоящата статия представяме синхронен двупосочно-неврален машинен превод (СБ-НМТ), който прогнозира изходите си, използвайки едновременно и интерактивно декодиране от ляво на дясно и дясно на ляво, за да се възползва едновременно от историята и бъдещата информация. По-конкретно, първо предлагаме нов алгоритъм, който позволява синхронно двупосочно декодиране в един модел. След това представяме интерактивен декодиращ модел, в който генерирането от ляво на дясно (дясно на ляво) зависи не само от генерираните преди това изходи, но и от бъдещите контексти, прогнозирани от декодирането от дясно на ляво (ляво на дясно). Обширно оценяваме предложения модел за превод на широкомащабни преводни задачи на китайско-английски език, английски-немски език и руски-английски език. Експерименталните резултати показват, че нашият модел постига значителни подобрения спрямо силния трансформаторен модел съответно с 3,92, 1,49 и 1,04 точки и постига най-съвременните резултати по китайско-английски и английски-немски преводни задачи.', 'hr': 'Postojeći pristupi prevodu neuralnih strojeva (NMT) stvaraju znak po znaku ciljnog jezika iz lijeve na desno. Međutim, ovakva vrsta jednosmjernog okvira za dekodiranje ne može potpuno iskoristiti buduće kontekste ciljne strane koje se mogu proizvesti u pravom desnom u lijevom smjeru za dekodiranje, te tako pati od pitanja neoravnoteženih ishoda. U ovom papiru predstavljamo sinhronski prevod neuralnih strojeva (SB-NMT), koji predviđa svoje ishode koristeći lijevo-desno-desno-lijevo dekodiranje istovremeno i interaktivno, kako bi utjecali na isto vrijeme i povijest i buduće informacije. Posebno, prvi put predlažemo novi algoritam koji omogućava sinhronski bidirektivni dekodiranje u jednom modelu. Onda predstavljamo interaktivan model dekodiranja u kojem se generacija lijeve na lijevo (desno na lijevo) ne samo ovisi o svojim prethodnim ishodama, već i oslanja na buduće kontekste predviđene desno na lijevo (lijevo na desno). Prošireno procjenjujemo predloženi model SB-NMT na velikoj skali NIST kineskog-engleskog, WMT14 engleskog-njemačkog i WMT18 ruskog-engleskog prevodnog zadataka. Eksperimentalni rezultati pokazuju da naš model postigne značajne poboljšanje nad snažnim modelom transformera od 3,92, 1,49 i 1,04 BLEU bodova, odnosno, i dobija državni učinkoviti na kineskom-engleskom i njemačkom prevođenju.', 'nl': 'Bestaande benaderingen voor neuronale machinevertaling (NMT) genereren de doeltaalsequentie token-by-token van links naar rechts. Dit soort unidirectioneel decoderingskader kan echter niet ten volle gebruik maken van de toekomstige doelcontexten die in een van rechts naar links decoderingsrichting kunnen worden geproduceerd, en lijdt dus onder het probleem van onevenwichtige outputs. In dit artikel introduceren we een synchrone bidirectionele neurale machinevertaling (SB-NMT) die zijn outputs voorspelt met behulp van links-naar-rechts en rechts-naar-links decodering tegelijkertijd en interactief, om zowel de geschiedenis als toekomstige informatie tegelijkertijd te benutten. Specifiek stellen we eerst een nieuw algoritme voor dat synchrone bidirectionele decodering in één model mogelijk maakt. Vervolgens presenteren we een interactief decoderingsmodel waarin het genereren van links naar rechts (van rechts naar links) niet alleen afhankelijk is van de eerder gegenereerde outputs, maar ook afhankelijk is van toekomstige contexten voorspeld door rechts naar links (van links naar rechts) decodering. We evalueren het voorgestelde SB-NMT model uitgebreid op grootschalige NIST Chinees-Engels, WMT14 Engels-Duits en WMT18 Russisch-Engels vertaaltaken. Experimentele resultaten tonen aan dat ons model significante verbeteringen bereikt ten opzichte van het sterke Transformer model met respectievelijk 3.92, 1.49 en 1.04 BLEU punten, en de state-of-the-art prestaties behaalt voor Chinees-Engels en Engels-Duits vertaaltaken.', 'da': 'Eksisterende tilgange til neural maskinoversættelse (NMT) genererer målsprogssekvensen token for token fra venstre mod højre. Denne form for ensrettet afkodningsramme kan imidlertid ikke udnytte de fremtidige sammenhænge på målsiden fuldt ud, som kan produceres i en retning af afkodning fra højre mod venstre, og lider derfor af spørgsmålet om ubalancerede output. I denne artikel introducerer vi en synkron bidirectional-neural machine translation (SB-NMT), der forudsiger sine output ved hjælp af venstre-til-højre og højre-til-venstre afkodning samtidig og interaktivt, for at udnytte både historie og fremtidig information på samme tid. Specielt foreslår vi først en ny algoritme, der muliggør synkron bidirektionel afkodning i en enkelt model. Derefter præsenterer vi en interaktiv afkodningsmodel, hvor venstre mod højre (højre mod venstre) generation ikke kun afhænger af dens tidligere genererede output, men også afhænger af fremtidige sammenhænge forudsiget af højre mod venstre (venstre mod højre) afkodning. Vi evaluerer grundigt den foreslåede SB-NMT model på store NIST kinesisk-engelsk, WMT14 engelsk-tysk og WMT18 russisk-engelsk oversættelsesopgaver. Eksperimentelle resultater viser, at vores model opnår betydelige forbedringer i forhold til den stærke Transformer model med henholdsvis 3,92, 1,49 og 1,04 BLEU point, og opnår den nyeste ydeevne på kinesisk-engelsk og engelsk-tysk oversættelsesopgaver.', 'de': 'Bestehende Ansätze zur neuronalen maschinellen Übersetzung (NMT) generieren die Zielsprachensequenz token-by-token von links nach rechts. Diese Art von unidirektionalem Dekodierungsrahmen kann jedoch die zielseitigen zukünftigen Kontexte, die in einer Rechts-nach-Links-Dekodierungsrichtung produziert werden können, nicht voll ausnutzen und leidet daher unter dem Problem unausgewogener Outputs. In diesem Beitrag stellen wir eine synchrone bidirektional-neurale maschinelle Übersetzung (SB-NMT) vor, die ihre Ergebnisse simultan und interaktiv mittels left-to-right und right-to-left Dekodierung vorhersagt, um sowohl die Geschichte als auch zukünftige Informationen gleichzeitig zu nutzen. Konkret schlagen wir zunächst einen neuen Algorithmus vor, der synchrone bidirektionale Dekodierung in einem einzigen Modell ermöglicht. Anschließend stellen wir ein interaktives Dekodierungsmodell vor, bei dem die Erzeugung von links nach rechts (rechts nach links) nicht nur von den zuvor generierten Outputs abhängt, sondern auch von zukünftigen Kontexten abhängt, die durch die Dekodierung von rechts nach links (links nach rechts) vorhergesagt werden. Wir evaluieren das vorgeschlagene SB-NMT Modell ausführlich für NIST Chinesisch-Englisch, WMT14 Englisch-Deutsch und WMT18 Russisch-Englisch Übersetzungsaufgaben. Experimentelle Ergebnisse zeigen, dass unser Modell signifikante Verbesserungen gegenüber dem starken Transformer-Modell um 3.92-, 1.49- und 1.04 BLEU-Punkte erzielt und die State-of-the-Art-Leistung bei Übersetzungsaufgaben Chinesisch-Englisch und Englisch-Deutsch erreicht.', 'id': 'pendekatan yang ada untuk terjemahan mesin saraf (NMT) menghasilkan urutan bahasa sasaran token-by-token dari kiri ke kanan. However, this kind of unidirectional decoding framework cannot make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs.  Dalam kertas ini, kami memperkenalkan sebuah penyerjemahan mesin saraf-bidireksi sinkronis (SB-NMT) yang memprediksi hasilnya menggunakan dekoding kiri ke kanan dan kanan ke kiri secara bersamaan dan interaktif, untuk menggunakan sejarah dan informasi masa depan pada saat yang sama. Secara spesifik, kita pertama-tama melamar algoritma baru yang memungkinkan dekodasi bidireksi sinkronis dalam satu model. Kemudian, kami mempersembahkan model dekoding interaktif di mana generasi kiri ke kanan (kanan ke kiri) tidak hanya bergantung pada hasil yang sebelumnya dihasilkan, tetapi juga bergantung pada konteks masa depan yang diprediksi oleh dekoding kanan ke kiri (kiri ke kanan). Kami mengevaluasi secara ekstensif model SB-NMT yang diusulkan pada skala besar NIST Cina-Inggris, WMT14 Inggris-Jerman, dan WMT18 tugas terjemahan Rusia-Inggris. Hasil eksperimen menunjukkan bahwa model kita mencapai peningkatan yang signifikan atas model Transformer kuat dengan 3,92, 1,49, dan 1,04 poin BLEU, secara respektif, dan mendapatkan prestasi terbaik pada tugas terjemahan Cina-Inggris dan Inggris-Jerman.', 'ko': '기존의 신경기계번역(NMT) 방법은 왼쪽에서 오른쪽으로 표시를 따라 목표 언어 서열을 생성한다.그러나 이런 단방향 디코딩 프레임워크는 오른쪽에서 왼쪽으로 디코딩하는 방향에서 발생하는 목표 측의 미래 상하문을 충분히 이용할 수 없기 때문에 출력의 불균형이 존재한다.본고에서 우리는 동기쌍방향신경기계번역(SB-NMT)을 소개했는데 왼쪽에서 오른쪽과 오른쪽에서 왼쪽으로 디코딩을 동시에 상호작용하여 출력을 예측함으로써 역사와 미래 정보를 동시에 이용하도록 한다.구체적으로 말하자면 우리는 먼저 새로운 알고리즘을 제기하여 하나의 모델에서 동기화 양방향 디코딩을 실현할 수 있다.그 다음에 우리는 인터랙티브 디코딩 모델을 제시했다. 그 중에서 왼쪽에서 오른쪽(오른쪽에서 왼쪽으로)의 생성은 이전에 생성된 출력에 의존할 뿐만 아니라 오른쪽에서 왼쪽(왼쪽에서 오른쪽으로) 디코딩 예측의 미래 상하문에 의존한다.우리는 대규모 NIST 중국어-영어, WMT14 영어-독일어와 WMT18 러시아어-영어 번역 임무에서 제안된 SB-NMT 모델을 광범위하게 평가했다.실험 결과 우리 모델은 강변압기 모델보다 각각 3.92, 1.49, 1.04개의 BLEU점을 높였고 한영과 영독 번역 임무에서 가장 선진적인 성능을 거두었다.', 'fa': 'نزدیک\u200cهای موجود به ترجمه ماشین عصبی (NMT) نشان\u200cهای تعریف زبان هدف را از چپ به راست تولید می\u200cکند. با این حال، این نوع چهارچوب\u200cسازی متحدی نمی\u200cتواند از موضوع آینده\u200cهای هدف کامل استفاده کند که می\u200cتواند در مسیر دکوندن راست و چپ تولید شود، و به همین دلیل از موضوع نتیجه\u200cهای متصل نشده رنج می\u200cدهد. در این کاغذ، ما یک ترجمه\u200cی ماشین\u200cهای عصبی (SB-NMT) را معرفی می\u200cکنیم که نتیجه\u200cهایش را پیش\u200cبینی می\u200cکند که با دستگاه\u200cهای چپ و راست و راست و چپ همزمان و متقابل تغییر می\u200cدهد، تا هر دو اطلاعات تاریخ و آینده را در یک زمان تغییر دهیم. دقیقا، ما اولین بار الگوریتم جدید را پیشنهاد می\u200cکنیم که در یک مدل یک دستگاه دستگاه\u200cهای دوره\u200cای هماهنگ را اجازه می\u200cدهد. سپس ما یک مدل تغییر فعالی را نشان می دهیم که نسل چپ به راست بستگی به نتیجه های پیش از آن نیست، بلکه همچنین بستگی به شرایط آینده که توسط تغییر تغییر دادن به سمت راست به سمت چپ است. ما مدل پیشنهاد SB-NMT را به وسیع ارزش می\u200cدهیم که در مقیاس بزرگ NIST چینی-انگلیسی، WMT14 انگلیسی-آلمانی و WMT18 ترجمه\u200cهای روسی-انگلیسی است. نتیجه\u200cهای تجربه\u200cی ما نشان می\u200cدهند که مدل ما بر روی مدل تغییر\u200cدهنده قوی با 3.92، 1.49 و 1.04 نقطه\u200cهای بلوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئوئو', 'tr': 'Öň bar maşynyň terjimesine (NMT) maksady dil terjimesini soldan saga çenli token edir. Ýöne bu tip bir görnöşim kodlemesi welin gelejekde maksady çykyşyny doly ulanyp bilmeýär. Bu şekilde sag-dan sola kodlemek modunda döredilebilir we bu şekilde çykyşlaryň meselesi bar. Bu kagyzda biz synchron ikinji görnöş-näral maşynyň terjimesini (SB-NMT) ýene-de soldan we sagdan soldan söňe kodlemegini hem etkileşiklik bilen tanyşdyrýarys. Taryhdan we gelejek maglumatyň ikisini hem etkileşiklik bilen üýtgetmek üçin tanyşdyrýarys. Adatça, biz ilkinji gezek täze bir algoritm teklip edip, bir nusgada synkron iki dikreşikli ködleme mümkin edýäris Sonra, biz etkileşimli bir ködleme nusgasyny görkezip. Bu nusgasynda soldan saga-saga-sola bağlanmaýar. Bu nusgasyna diňe öňki döredilen netijesine bağlanmaýar, ýöne saga-sola-saga taýýarlanan gelejek contextlere daşar. Biz SB-NMT nusgasyny uly görkezilýän NIST Çinçe-Iňlisçe, WMT14 Iňlisçe-Almança we WMT18 Rus-Iňlisçe terjime edilýän zadyň üstine çykýarys. Aramanyň netijesi biziň nusgymyzyň 3.92, 1.49 we 1.04 BLEU noktalary bilen güýçli Transformer nusgasynda möhüm gelişmeleri ýetip bilýär we Hytaý-Iňlis we Iňlis-Almanyň terjime edilen täzeliklerde bolup bilýär.', 'sq': 'Përkthimet ekzistuese për përkthimin e makinës nervore (NMT) gjenerojnë sekuencën e gjuhës objektive token-by-token nga e majta në e djathtë. Megjithatë, ky lloj kuadri i dekodimit të njëdrejtuar nuk mund të bëjë përdorim të plotë të konteksteve të ardhshme të anës së objektivit që mund të prodhohen në një drejtim dekodimi të djathtë në të majtë dhe kështu vuan nga çështja e daljeve të paekuilibruara. Në këtë letër, ne paraqesim një përkthim sinkron dy-drejtues-neural makinë (SB-NMT) që parashikon rezultatet e saj duke përdorur dekodimin e majtë në të djathtë dhe të djathtë në të majtë në të njëjtën kohë dhe interaktivisht, me qëllim që të përdorim si historinë, ashtu edhe informacionin e ardhshëm në të njëjtën kohë. Veçanërisht, ne së pari propozojmë një algoritëm të ri që mundëson dekodimin dy-drejtues sinkronik në një model të vetëm. Pastaj, ne paraqesim një model dekodimi interaktiv në të cilin gjenerata e majtë në të djathtë (djathtë në të majtë) nuk varet vetëm nga prodhimet e tij të gjeneruara më parë, por mbështetet gjithashtu në kontekstet e ardhshme të parashikuara nga dekodimi i djathtë në të majtë (majtë në të djathtë). Ne vlerësojmë gjerësisht modelin e propozuar SB-NMT mbi detyrat e përkthimit në shkallë të madhe NIST kinez-anglisht, WMT14 anglisht-gjerman dhe WMT18 rusisht-anglisht. Rezultatet eksperimentale tregojnë se modeli ynë arrin përmirësime të rëndësishme lidhur me modelin e fortë Transformer me 3.92, 1.49 dhe 1.04 pikë BLEU respektivisht dhe merr shfaqjen më të lartë në detyrat e përkthimit kinez-anglez dhe anglez-gjerman.', 'sw': 'Zipo karibu na tafsiri ya mashine ya neural (NMT) kutengeneza mfululizo wa lugha inayolenga token-by-token kutoka kushoto hadi kulia. Hata hivyo, mfumo huu wa decodi wa moja kwa moja hauwezi kutumia mikutano ya mustakabali ambao yanaweza kutengenezwa kwenye mwelekeo wa kulia na kushoto, na hivyo yanaumia kutokana na suala la matokeo yasiyo na usawa. Katika karatasi hii, tunaonyesha tafsiri ya mashine yenye ushirikiano mkubwa (SB-NMT) inayotabiri matokeo yake kwa kutumia decodi ya kushoto na kushoto kwa wakati mmoja na kwa moja, ili kutumia taarifa za historia na mustakabali kwa wakati huo huo. Kwa ujumla, tunapendekeza kwa mara ya kwanza mialgorithi mpya ambayo inawezesha kuongezeka kwa ushirikiano katika muundo mmoja. Kisha, tunaweka mfano wa decodi moja kwa moja ambapo kizazi chake kushoto na kushoto (kulia na kushoto) sio tu hutegemea matokeo yake yaliyozaliwa awali, bali pia hutegemea matatizo ya baadaye yanayotarajiwa na decodi ya kulia na kushoto na kulia. Tutathmini kwa kiasi kikubwa muundo wa SB-NMT unaopendekezwa katika kazi za tafsiri za Kiingereza kwa kiasi kikubwa ya NIST-China-English, WMT14 Kiingereza na WMT18-Kiingereza. Matokeo ya majaribio yanaonyesha kwamba mifano yetu inapata maboresho makubwa zaidi ya mifano yenye nguvu ya Transfer kwa asilimia 3.92, 1.49, na 1.04 BLEU, na hutumia maonesho ya sanaa katika kazi za tafsiri za Kiingereza na Kiingereza.', 'af': "Bestaande toegang tot neurale masjien vertaling (NMT) genereer die doel taal volgorde token- by- token van links na regs. Maar hierdie soort van unidireksionale dekoding raamwerk kan nie volledige gebruik maak van die doel-kant toekomstige konteks wat in 'n regs na links dekoding rigting kan produseer word nie, en daarom lyf van die probleem van onbalanse uitvoerdes. In hierdie papier, introduseer ons 'n sinkroon binireksjoneel-neurale masjien vertaling (SB-NMT) wat sy uitvoerdes voorskou met links-na-regs en regs-na-links dekodering simultaan en interaktief, om beide van die geskiedenis en toekomstige inligting op dieselfde tyd te verwys. Spesifieke, ons voorstel eerste 'n nuwe algoritme wat sinkroon bidireksjonale dekodering in 'n enkele model aktiveer. Toe voorsien ons 'n interaktief dekoding model waarin links-na-regs (regs-na-links) generasie nie alleen afhang van sy voorheen genereerde uitvoerdes nie, maar ook afsluit op toekomstige konteks wat deur regs-na-links (links-na-regs) dekoding voorskou word. Ons uitbreidig die voorgestelde SB-NMT-model op groot-skaal NIST Sjinese-Engels, WMT14 Engels-Duits en WMT18 Russe-Engels-vertaling opdragte evalueer. Eksperimentale resultate bevestig dat ons model betekende verbeteringe verkry oor die sterk Transformer model deur 3.92, 1.49 en 1.04 BLEU punte, respektief, en verkry die staat van die kunsten-prestasie op Sjinese-Engels en Engels-Duitse vertalingstaak.", 'hy': 'Նյարդային մեքենայի թարգմանման (NMT) գոյություն ունեցող մոտեցումները ստեղծում են նպատակային լեզվի հաջորդականությունը նշան-առ-նշան ձախ դեպի աջ: Այնուամենայնիվ, այս տեսակի միաուղղակի կոդավորման շրջանակը չի կարող ամբողջովին օգտագործել ապագա նպատակային կոնտեքստները, որոնք կարող են արտադրվել աջ-ձախ կոդավորման ուղղությամբ, և այսպես տառապում են անհավասարակշռությունների խնդիրը: In this paper, we introduce a synchronous bidirectional-neural machine translation (SB-NMT) that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time.  Հատկապես, մենք առաջին անգամ առաջարկում ենք նոր ալգորիթմ, որը հնարավորություն է տալիս սինկրոնական երկուղղային բաժանել մեկ մոդելի մեջ: Then, we present an interactive decoding model in which left-to-right (right-to-left) generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left (left-to-right) decoding.  Մենք էքսպենսիվ գնահատում ենք SB-NMT-ի առաջարկած մոդելը լայնածավալ ՆԻՍԹ չինական-անգլերեն, ՈւՄԹ14 անգլերեն-գերմաներեն և ՈւՄԹ18 ռուս-անգլերեն թարգմանման խնդիրներում: Փորձարկվող արդյունքները ցույց են տալիս, որ մեր մոդելը հասնում է նշանակալի բարելավումների վերաբերյալ ուժեղ տրանֆորմային մոդելը, 3.92-ով, 1.49-ով և 1.04-ով, համապատասխանաբար, և հասնում է Չինաստանի-Անգլերենի և Անգլերենի-գերմանացի թարգման', 'az': 'NMT m…ôqs…ôd dil sequence token-by-token-i soldan sańüa √ßevir…ôr. Ancaq bu c√ľr bir t…ôr…ôfli kodlama √ßer√ßivesi sańüdan soldan kodlamaq t…ôr…ôfind…ô yaradńĪlabilir v…ô buna g√∂r…ô d…ô m√ľ…ôyy…ôn edilm…ômiŇü √ßńĪxńĪŇülarńĪn problemind…ôn …ôlaq…ôli olar. Bu kańüńĪzda, biz bir-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin-birinin- √Ėzellikle, ilk d…ôf…ô bir modell…ô sinkron bitireksiyonlu kodlama m√ľmk√ľn olan yeni bir algoritm t…ôklif edirik. Sonra, biz bir interaktif kodlama modelini g√∂st…ôririk ki soldan sańüa t…ôr…ôf (sańüa t…ôr…ôf ) n…ôsli ancaq …ôvv…ôlc…ô yaratdńĪńüńĪ sonlarńĪna bańülńĪ deyil, ancaq sańüa t…ôr…ôf (soldan sańüa t…ôr…ôf) kodlamasńĪ il…ô t…ôdbir edil…ôn g…ôl…ôc…ôk m…ôs…ôl…ôl…ôr…ô d…ô bańülńĪ olur. Biz b√∂y√ľk √∂l√ß√ľd…ô NIST √áin-ńįngilizce, WMT14 ńįngilizce-Almanca v…ô WMT18 Rus-ńįngilizce √ßeviri iŇül…ôrind…ô t…ôklif edilmiŇü SB-NMT modelini √ßox deńüerl…ôŇüdiririk. M√ľxt…ôlif sonu√ßlarńĪmńĪz modell…ôrimizin g√ľcl√ľ Transformer modeli 3.92, 1.49 v…ô 1.04 BLEU noktalarńĪ il…ô m√∂hk…ôm uzlaŇüdńĪrmańüńĪnńĪ g√∂st…ôrir v…ô √áin-ńįngiliz…ô v…ô ńįngiliz…ô-Almanca √ßeviriŇü iŇül…ôri bar…ôsind…ô sanatlńĪ performansńĪ q…ôbul edir.', 'bn': 'Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right.  However, this kind of unidirectional decoding framework cannot make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs.  এই কাগজটিতে আমরা একটি সিক্রোনিয়ারিক-নিউরেল মেশিন অনুবাদ (এসবি-এনএমটি) উপস্থাপন করি যা বাম থেকে ডান থেকে বাম থেকে বাম থেকে বামে কোডিং ব্যবহার করে তার আউটপুটগুলো একই সাথে এবং একই সময় বিশেষ করে, আমরা প্রথমে একটি নতুন অ্যালগরিদম প্রস্তাব করি যা এক মডেলে সিক্রোনিক বিদ্রেক্রিয়ান ডিকোডিং সক্রিয় করে। তারপর আমরা একটি ইন্টারনেকটিভ ডিকোডিং মডেল উপস্থাপন করি যেখানে বাম থেকে ডান থেকে (ডান থেকে বামে) প্রজন্ম তার পূর্ববর্তী তৈরি আউটপুটের উপর নির্ভর করে না, কিন্তু তার উপর নির্ভ আমরা ব্যাপক ভাবে প্রস্তাবিত এসবি-এনএমটি মডেলের মূল্য মুল্যায়ন করি বিশাল পর্যায়ে NIST চীন-ইংরেজী, WMT14 ইংরেজী জার্মান এবং WMT18 রুশ-ইংর পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের মডেল ৩. ৯২, ১. ৪৯ এবং ১. ০৪ বিলিউ বিন্দুর মধ্যে শক্তিশালী ট্রান্সফ্রান্সফ্রান্স মডেলের উপর গুরুত্বপূর্ণ উন্নতি পেয়েছে এবং চীনা-ইং', 'am': 'የአሁኑን ደረጃ ማሻሻል ትርጉም (NMT) ያስጀምር ነገር ግን ይህ ዓይነት የኢትዮጵያ የድምፅ አካባቢ ፍሬም የቀኝ ወደ ግራ ወደ ግራ ወደ ቀኝ ማቀናቀል ማቀናቀል የሚችሉትን የግንኙነቱን ጉዳይ ሙሉ ሊጠቀም አይችልም፡፡ In this paper, we introduce a synchronous bidirectional-neural machine translation (SB-NMT) that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time.  በተለያይነት፣ አስቀድመን አንዲት ዓይነት የሳንቆሮን አዲስ አሌጎርቲም እናሳውቃለን፡፡ በዚያን ጊዜ የግራ-ወደ ቀኝ (ቀኝ-ወደ ግራ) ትውልድ አስቀድሞ የተፈጠረውን ውጤቶች ብቻ አይደገፍም፥ ነገር ግን በቀኝ-ወደ ቀኝ (ግራ-ወደ ቀኝ) ማቀናቀል በሚለው የመጨረሻው ውጤቶች ላይ ይታመናል፡፡ በተዘጋጀው SB-NMT ሞዴል በዛፊቱ የቻይና-እንግሊዘኛ፣ WMT14 እንግሊዘኛ-ጀርመን እና WMT18 የሩሽኛ-እንግሊዘኛ ትርጉም ስራዎችን እናስተውልታለን፡፡ ፈተናው ውጤቶች በቻይና-እንግሊዘኛ እና በጀርመን-ጀርመን-ጀርመን-ጀርመን-ጀርመን ትርጓሜ ትርጓሜ ስራዎችን በ3.92፣ 1.49 እና 1.04 BLEU ነጥቦች ላይ የበለጠውን ትክክል ማድረግ እንዲያገኛል፡፡', 'cs': 'Stávající přístupy k neuronovému strojovému překladu (NMT) generují cílovou sekvenci token po tokenu zleva doprava. Tento druh jednosměrného dekódovacího rámce však nemůže plně využít cílové budoucí kontexty, které lze vytvořit ve směru dekódování doprava doleva, a proto trpí problémem nevyvážených výstupů. V tomto článku představujeme synchronní obousměrný neuronový strojový překlad (SB-NMT), který předpovídá jeho výstupy pomocí dekódování vlevo-doprava a pravo-doleva současně a interaktivně, aby mohl využít historické i budoucí informace současně. Konkrétně nejprve navrhujeme nový algoritmus, který umožňuje synchronní obousměrné dekódování v jednom modelu. Následně představujeme interaktivní dekódovací model, ve kterém generování levé dopravy (vpravo doleva) závisí nejen na jejích dříve generovaných výstupech, ale také na budoucích kontextech předpovídaných dekódováním zprava doleva (zleva doprava). Důkladně hodnotíme navržený model SB-NMT na rozsáhlých NIST čínsko-anglických, WMT14 anglicko-německých a WMT18 rusko-anglických překladatelských úlohách. Experimentální výsledky ukazují, že náš model dosahuje významných zlepšení oproti silnému modelu Transformer o body 3.92, 1.49 a 1.04 BLEU a získává nejmodernější výkon při čínsko-anglických a anglicko-německých překladatelských úlohách.', 'ca': "Els enfocaments existents a la traducció neural de màquines (NMT) generen la seqüència de llenguatge alvo fitxa per fitxa d'esquerra a dreta. However, this kind of unidirectional decoding framework cannot make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs.  En aquest article introduïm una traducció bidireccional-neural sincronizada (SB-NMT) que prediu les seves produccions fent servir la decodificació d'esquerra a dreta i d'esquerra a esquerra simultàneament i interactivament, per aprofitar al mateix temps la història i la futura informació. Concretament, primer proposem un nou algoritme que permet la descodificació bidireccional sincronitzada en un únic model. Llavors presentem un model de decodificació interactiu en el qual la generació d'esquerra a dreta (dreta a esquerra) no només depèn dels seus productes generats anteriorment, sinó també depèn dels futurs contextos predits per la decodificació d'esquerra a dreta. Evaluam ampliament el model SB-NMT proposat en tasques de traducció de gran escala NIST xinès-anglès, WMT14 anglès-alemany i WMT18 russo-anglès. Els resultats experimentals demostren que el nostre model aconsegueix millores significatives en relació amb el fort model Transformer en 3,92, 1,49 i 1,04 punts BLEU, respectivament, i obté l'actuació més avançada en tasques de traducció xinesa-anglesa i anglesa-alemana.", 'bs': 'Postojeći pristupi prevodu neuralnih strojeva (NMT) stvaraju znak po znaku ciljnog jezika iz lijeve na desno. Međutim, ovakva vrsta jednodirektivnog okvira za dekodiranje ne može potpuno iskoristiti buduće kontekste ciljne strane koje se mogu proizvesti u pravom desnom na lijevom smjeru za dekodiranje, te tako pati od pitanja neoravnoteženih ishoda. U ovom papiru predstavljamo sinhronski prevod neuralnih strojeva (SB-NMT), koji predviđa svoje ishode koristeći lijevo-desno-desno-lijevo dekodiranje istovremeno i interaktivno, kako bi uticali na istoriju i buduće informacije u isto vrijeme. Posebno, prvi put predlažemo novi algoritam koji omogućava sinhronski bidirektivni dekodiranje u jednom modelu. Onda predstavljamo interaktivan model dekodiranja u kojem generacija lijeve na lijevo (desno na lijevo) ne samo zavisi od njegovih prethodnih ishoda, već i oslanja na buduće kontekste predviđene desno na lijevo (lijevo na desno). Proširoko procjenjujemo predloženi model SB-NMT na velikoj skali NIST kineskog-engleskog, WMT14 engleskog-njemačkog i WMT18 ruskog-engleskog prevodnog zadataka. Eksperimentalni rezultati pokazuju da naš model postigne značajne poboljšanje nad jakim modelom transformera sa 3,92, 1,49 i 1,04 BLEU bodova, odnosno, i dobija državni učinkoviti o kineskim i engleskim i njemačkim prevodnim zadacima.', 'et': 'Olemasolevad lähenemisviisid neuraalsele masintõlkele (NMT) genereerivad sihtkeele järjestuse token-by-token vasakult paremale. Selline ühesuunaline dekodeerimisraamistik ei saa siiski täielikult ära kasutada sihtpoolset tuleviku konteksti, mida saab luua paremalt vasakule dekodeerimise suunas, ning kannatab seega tasakaalustamata väljundite küsimuse all. Käesolevas töös tutvustame sünkroonset kahesuunalist-neuraalset masintõlket (SB-NMT), mis prognoosib oma väljundeid kasutades samaaegselt ja interaktiivselt vasakult paremale ja paremalt vasakule dekodeerimist, et samal ajal kasutada nii ajaloo kui ka tulevast infot. Täpsemalt pakume esmalt välja uue algoritmi, mis võimaldab sünkroonset kahesuunalist dekodeerimist ühes mudelis. Seejärel esitame interaktiivse dekodeerimismudeli, kus vasakult paremale (paremalt vasakule) generatsioon ei sõltu mitte ainult varem loodud väljunditest, vaid tugineb ka tulevastele kontekstidele, mida ennustab paremalt vasakule (vasakult paremale) dekodeerimine. Hindame põhjalikult väljapakutud SB-NMT mudelit suuremahuliste NIST hiina-inglise, WMT14 inglise-saksa ja WMT18 vene-inglise tõlketööde puhul. Eksperimentaalsed tulemused näitavad, et meie mudel saavutab tugeva Transformeri mudeliga võrreldes märkimisväärseid parandusi vastavalt 3,92, 1,49 ja 1,04 BLEU punkti võrra ning saavutab kaasaegse tulemuse hiina-inglise ja inglise-saksa tõlketöödel.', 'fi': 'Nykyiset lähestymistavat neurokonekäännökseen (NMT) tuottavat kohdekielen sekvenssin token-token-token-merkiltä vasemmalta oikealle. Tällaisessa yksisuuntaisessa dekoodauskehyksessä ei kuitenkaan voida hyödyntää täysimääräisesti kohdepuolen tulevia konteksteja, joita voidaan tuottaa oikealta vasemmalle dekoodauskehyksessä ja jotka kärsivät näin ollen epätasapainoisista tuotoksista. Tässä työssä esitellään synkroninen kaksisuuntainen konekäännös (SB-NMT), joka ennustaa tuotoksensa vasemmalta oikealle ja oikealta vasemmalle dekoodaamalla samanaikaisesti ja vuorovaikutteisesti, jotta voidaan hyödyntää sekä historiaa että tulevaa tietoa samanaikaisesti. Erityisesti ehdotamme ensin uutta algoritmia, joka mahdollistaa synkronoidun kaksisuuntaisen dekoodauksen yhdessä mallissa. Tämän jälkeen esittelemme interaktiivisen dekoodamallin, jossa vasemmalta oikealle (oikealta vasemmalle) sukupolvi ei riipu vain aiemmin luoduista tuotoksista, vaan myös luota tuleviin konteksteihin, joita oikealta vasemmalle (vasemmalta oikealle) dekoodaminen ennustaa. Arvioimme laajasti ehdotettua SB-NMT-mallia suurissa NIST kiina-englanti-, WMT14 englanti-saksa- ja WMT18 venäjä-englanti käännöstehtävissä. Kokeelliset tulokset osoittavat, että mallimme saavuttaa merkittäviä parannuksia vahvaan Transformer-malliin verrattuna 3,92, 1,49 ja 1,04 BLEU-pistettä sekä saavuttaa huipputason suorituskyvyn kiina-englanti- ja englanti-saksa-käännöstehtävissä.', 'jv': 'buddy politenessoffpolite"), "politenessoffpolite"), "politenessoffpolite"), "politenessoffpolite"), "politenessoffpolite"), "politenessoffpolite"), "politenessoffpolite"), "politenessoff Nang pepulan iki, kita mulai nyulung tanggal apakno (S B-NMT) sing dianggap banjure nggawe kayah-kayah lan kayah-kayah lan ngawe lan sampek iso nggawe lan tambah-sampek, kaya iso nggawe tarjamahan kanggo ngilanggar kewatakan informasi nglanggar sampek dadi. Laptop" and "Desktop Format autodetect Awak dhéwé éntuk luwih nggawe model sing nggawe sB-NMT nganggep banter-scale NIRT Cainan-Inggris, WW14 Inggris-German, lan WW18 Rus-Inggris barang. Rejelongé sing paling nggambar kuwi model sing bisa nggawe diulangno nggawe modèl Transformer sing bisa nggawe 3.', 'ha': "@ action: button A lokacin da, wannan firam na komai ba ta iya cika amfani da matsayin-side na goani wanda za'a iya samar da shi a gaba dama da hagu, kuma yana da shi daga matsalan matsayin da ba'a daidaita. Daga wannan takardan, Munã ƙara wani fassarar kwamfyuta na ƙarurar-neural (SB-NMT) wanda ke ƙayyade fassararsa na yi amfani da kodi na dama-dama da hagu sami kuma masu yin amfani da shi, dõmin ya cika laban bayan historin da kuma bayan bayani sami guda. A ƙayyade, Muna goyyade farkon wata algoritm na daban, wanda yana iya amfani da kodi na ƙaranci cikin wani misali guda. Sa'an nan kuma, Munã yanzu wani misãlin zĩnãriya mai fara, wanda kizazi ya shige ta dama-dama (dama-hagu) ba ta ƙayyade kawai ga fitarwa wanda ya ƙãga gaba, kuma amma yana dõgara ga masu ƙarami masu jiran da ke ƙayyade kodunta dama-dama (hagu-dama). @ item Spelling dictionary Matarin jarrabai na nuna cewa misalinmu yana sami marubuci mai girma game da misalin Transformer mai ƙarfi a shekara 3.92, 1.49, da 1.04 BLEU points, kuma yana sami mai fassarar-mazaƙin-sanar a kan aikin China-Ingiriya da Ingirin-Jerumani.", 'sk': 'Obstoječi pristopi k nevronskemu strojnemu prevajanju (NMT) ustvarijo zaporedje ciljnega jezika žeton za žetonom z leve proti desni. Vendar pa tovrstni enosmerni dekodirni okvir ne more v celoti izkoristiti ciljnih prihodnjih kontekstov, ki jih je mogoče ustvariti v smeri dekodiranja od desne proti levi, zato trpi zaradi vprašanja neuravnoteženih rezultatov. V prispevku predstavljamo sinhrono dvosmerno-nevralno strojno prevajanje (SB-NMT), ki hkrati in interaktivno napoveduje svoje izhode z uporabo dekodiranja od leve proti desni in desni proti levi, da bi hkrati izkoristili zgodovino in prihodnje informacije. Natančneje, najprej predlagamo nov algoritem, ki omogoča sinhrono dvosmerno dekodiranje v enem modelu. Nato predstavljamo interaktivni model dekodiranja, v katerem generacija od leve proti desni (od desne proti levi) ni odvisna samo od prej ustvarjenih izhodov, temveč se opira tudi na prihodnje kontekste, ki jih predvideva dekodiranje od leve proti levi (od leve proti desni). Obsežno ocenjujemo predlagani model SB-NMT na obsežnih prevajalskih nalogah NIST kitajsko-angleščina, WMT14 angleščina-nemščina in WMT18 rusko-angleščina. Eksperimentalni rezultati kažejo, da je naš model dosegel znatne izboljšave v primerjavi z močnim transformatorskim modelom za 3,92, 1,49 in 1,04 točke BLEU ter dosegel najsodobnejšo uspešnost pri prevajalskih nalogah kitajsko-angleščina in angleško-nemščina.', 'bo': 'Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right. ཡིན་ནའང་། འདི་ལྟ་བུའི་ཁྱད་པར་དབྱིབས་གནས་སྟངས་ཕྱོགས་ཀྱི་ཁྲོད་ཅིག ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་མཉམ་དུ་མཐུན་རིམ་བཀོད་པའི་རྩིས་འཁྲུལ་བ་ཞིག་སྟོན་བྱེད་ཀྱི་ཡོད། ཁྱད་པར་ན། ང་ཚོས་དང་པོ་ལ་སྔོན་གྱིས་རྣམ་པ་ཞིག་གི་སྔོན་སྒྲིག་སྟངས་འདིར་མཉམ་འབྱུང་བའི་ལྟ་བུའི་སྒྲིག འོན་ཀྱང་། ང་ཚོས་བློ་གཏད་ཀྱི་དཔེ་གཞི་གཅིག་པ་དེ་གཡོན་ཕྱོགས་ལས་གཡས་ཕྱོགས་ཀྱི་ནང་དུ་འཇུག་སྣོད་ནང་ལ་མཐུད་སྣང་མེད་པར། མ་འོངས་ལ་རང་ཉིད་ཀྱི་གནད་སྡུད་ཕྱོགས་སུ་མཉམ We extensively evaluate the proposed SB-NMT model on large-scale NIST Chinese-English, WMT14 English-German, and WMT18 Russian-English translation tasks. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points respectively, and obtains the state-of-the-art performance on Chinese-English and English-German translation tasks.', 'he': 'גישות קיימות לתרגום מכונת עצבית (NMT) יוצרות את רצף שפת המטרה סימן-על-סימן משמאל לימין. עם זאת, סוג זה של מסגרת פיתוח לא מכוונת לא יכול להשתמש במלוא בתוך הקשר העתיד של צד המטרה שיכול להיוצר בכיוון פיתוח ימין לשמאל, ולכן סובל מהנושא של תוצאות לא מאוזנות. בעיתון הזה, אנו מציגים תרגומת מכונת עיצבית שתי כיוונים סינכרונית (SB-NMT) שמחזיקה את התוצאות שלה באמצעות פיתוח שמאל-ימין ומימין-שמאל באותו זמן ואינטראקטיבי, על מנת לנצל גם את ההיסטוריה וגם את המידע העתידי באותו זמן. במיוחד, אנו מציעים קודם אלגוריתם חדש שמאפשר לפענח שני כיוונים סינכרוני במודל אחד. ואז, אנחנו מציגים מודל פיתוח אינטראקטיבי בו דור שמאל ימין (ימין לשמאל) לא רק תלוי בתוצאות שנוצרו קודם לכן, אלא גם תלוי בקשר עתיד שנחזה על ידי פיתוח ימין לשמאל (שמאל ימין). אנחנו מעריכים באופן רחב את מודל SB-NMT המוצע על משימות התרגום הרוסי-אנגלית בסולם גדול NIST סיני-אנגלית, WMT14 אנגלית-גרמנית, WMT18. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points, respectively, and obtains the state-of-the-art performance on Chinese-English and English-German translation tasks.'}
{'en': 'GILE : A Generalized Input-Label Embedding for Text Classification', 'pt': 'GILE: Uma incorporação generalizada de rótulo de entrada para classificação de texto', 'fr': "GILE\xa0: intégration généralisée d'étiquettes d'entrée pour la classification de texte", 'ar': 'GILE: تضمين معمم لتسمية الإدخال لتصنيف النص', 'es': 'GILE: una incrustación generalizada de etiquetas de entrada para la clasificación de texto', 'zh': 'GILE:广义输标嵌', 'ja': 'GILE:テキスト分類のための一般化された入力ラベル埋め込み', 'hi': 'GILE: पाठ वर्गीकरण के लिए एक सामान्यीकृत इनपुट-लेबल एम्बेडिंग', 'ru': 'GILE: Встраивание обобщённой метки ввода для классификации текста', 'ga': 'GILE: Leabú Lipéad Ionchuir Ginearálaithe le haghaidh Aicmiú Téacs', 'ka': 'Constellation name (optional)', 'el': 'Μια γενικευμένη ενσωμάτωση ετικετών εισόδου για ταξινόμηση κειμένου', 'kk': 'GILE: Мәтін классификациясының жалпы ендіру жарлығы', 'hu': 'GILE: Általános bemeneti címke beágyazás a szövegosztályozáshoz', 'lt': 'GILE: Įterpiamas bendras įėjimo ženklas tekstui klasifikuoti', 'it': 'GILE: Embedding generalizzato di etichette di input per la classificazione del testo', 'mk': 'ГИЛЕ: Генерализирано внесување на ознака за внесување за класификација на текст', 'ms': 'GILE: Penjelmaan Label-Input Umum untuk Klasifikasi Teks', 'mt': 'GILE: Tikketta Ġeneralizzata tal-Input Embedding għall-Klassifikazzjoni tat-Test', 'mn': 'GILE: Текст классификацийн нэвтрүүлэлт', 'pl': 'GILE: Ogólne osadzanie etykiet wejściowych dla klasyfikacji tekstu', 'no': 'GILE: Ein generelt innskriftsmerkelapp innebygging for tekstklassifikasjon', 'ml': 'GILE: Text Classification', 'sr': 'GILE: Generalizirani ulazni etiketi za klasifikaciju teksta', 'ro': 'GILE: O încorporare generalizată a etichetelor de intrare pentru clasificarea textelor', 'si': 'Description', 'ur': 'GILE: ایک عمومی اینپوٹ- لابل پیغام کلاسیفشن کے لئے ایمبڈ', 'ta': 'GILE: உரை வகைப்படுத்தலுக்கான பொதுவான உள்ளீட்டு விளக்கச்சீட்டு உட்பொதி', 'sv': 'GILE: En generaliserad inbäddning av inmatningsetikett för textklassificering', 'so': 'GILE: A General Input-label Embedding for Text Classification', 'uz': 'GILE: Matn klassification uchun umumiy kiritish yorliqi', 'vi': 'GILE: Nhúng nhãn tự đặt chung cho hạng mục văn bản', 'bg': 'ГИЛ: Общо вграждане на входни етикети за класификация на текста', 'hr': 'GILE: Generalizirana uključena etiketa za klasifikaciju teksta', 'nl': 'GILE: Een algemene input-label insluiten voor tekstclassificatie', 'da': 'GILE: En generel indlejring af input-label til tekstklassifikation', 'de': 'GILE: Eine generalisierte Eingabe-Label Einbettung für die Textklassifizierung', 'id': 'GILE: A Generalised Input-Label Embedding for Text Classification', 'ko': 'GILE: 텍스트 분류에 사용되는 광범위한 입력 탭 삽입 알고리즘', 'sw': 'GILE: Label ya Kijumla ya Kuingia kwa ajili ya Makala', 'sq': 'GILE: A Generalized Input-Label Embedding for Text Classification', 'fa': 'Constellation name (optional)', 'hy': 'ԳԻԼ. Տեքստի դասակարգման համար ընդհանուր մուտքագրման պիտակ', 'tr': 'GILE: Metin Sınıflandırmak üçin Umumy Girdi-etiket', 'az': 'Constellation name (optional)', 'af': 'Constellation name (optional)', 'bs': 'GILE: Generalizirani ulazni etiketi za klasifikaciju teksta', 'am': 'አቀማመጥ', 'ca': "GILE: Una etiqueta d'entrada generalitzada per a classificar text", 'cs': 'GILE: Všeobecné vložení vstupních štítků pro klasifikaci textu', 'et': 'GILE: Üldine sisendmärgise põimimine teksti klassifitseerimiseks', 'bn': 'GILE: টেক্সট ক্লাসিশনের জন্য একটি সাধারণ ইনপুট- লেবেল এমবেডিং', 'fi': 'GILE: Yleinen syöttötunnisteen upotus tekstin luokittelua varten', 'jv': 'string" in "context_BAR_stringNew', 'sk': 'GILE: Splošna vgradnja nalepk za klasifikacijo besedila', 'he': 'GILE: תווית כניסה גנרליזציה למסגרת טקסט', 'ha': 'GILE: KCharselect unicode block name', 'bo': 'GILE: སྤྱིར་བཏོན་ཡོད་པའི་འཇུག་སྟངས་ཁ་རྟགས་ཀྱི་ཁ་རྟགས་བཙུགས་ཡོད་པ'}
{'en': 'Neural text classification models typically treat output labels as categorical variables that lack description and semantics. This forces their parametrization to be dependent on the label set size, and, hence, they are unable to scale to large label sets and generalize to unseen ones. Existing joint input-label text models overcome these issues by exploiting label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels happen often at the expense of weak performance on the labels seen during training. In this paper, we propose a new input-label model that generalizes over previous such models, addresses their limitations, and does not compromise performance on seen labels. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. We evaluate models on full-resource and low- or zero-resource text classification of multilingual news and biomedical text with a large label set. Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.', 'ar': 'عادةً ما تتعامل نماذج تصنيف النص العصبي مع تسميات المخرجات كمتغيرات فئوية تفتقر إلى الوصف والدلالات. هذا يفرض أن تكون معاملاتهم معتمدة على حجم مجموعة الملصقات ، وبالتالي ، فهم غير قادرين على التوسع في مجموعات الملصقات الكبيرة والتعميم على المجموعات غير المرئية. تتغلب نماذج نصوص تسمية الإدخال المشتركة الحالية على هذه المشكلات من خلال استغلال أوصاف الملصقات ، لكنها غير قادرة على التقاط علاقات تسمية معقدة ، ولها معايير صارمة ، ومكاسبها على الملصقات غير المرئية تحدث غالبًا على حساب الأداء الضعيف على الملصقات التي شوهدت أثناء التدريب. في هذه الورقة ، نقترح نموذجًا جديدًا لتسمية الإدخال يعمم على النماذج السابقة ويعالج حدودها ولا يضر بالأداء على الملصقات المرئية. يتكون النموذج من تضمين ملصق إدخال غير خطي مشترك بسعة يمكن التحكم فيها ووحدة تصنيف مشتركة تعتمد على الفضاء يتم تدريبها مع فقدان الانتروبيا لتحسين أداء التصنيف. نقوم بتقييم النماذج على تصنيف نصي كامل الموارد ومنخفض أو معدوم الموارد للأخبار متعددة اللغات والنص الطبي الحيوي مع مجموعة ملصقات كبيرة. يتفوق نموذجنا على النماذج أحادية اللغة ومتعددة اللغات التي لا تستفيد من دلالات الملصقات ونماذج مساحة تسمية الإدخال السابقة المشتركة في كلا السيناريوهين.', 'es': 'Los modelos de clasificación de texto neuronal suelen tratar las etiquetas de salida como variables categóricas que carecen de descripción y semántica. Esto obliga a que su parametrización dependa del tamaño del conjunto de etiquetas y, por lo tanto, no pueden escalar a conjuntos de etiquetas grandes y generalizar a juegos invisibles. Los modelos conjuntos de texto de etiquetas de entrada existentes solucionan estos problemas al explotar las descripciones de etiquetas, pero no pueden capturar relaciones de etiquetas complejas, tienen una parametrización rígida y sus ganancias en etiquetas invisibles a menudo se producen a expensas del bajo rendimiento de las etiquetas observadas durante la capacitación. En este artículo, proponemos un nuevo modelo de etiquetas de entrada que generaliza sobre dichos modelos anteriores, aborda sus limitaciones y no compromete el rendimiento de las etiquetas vistas. El modelo consiste en una incrustación de etiquetas de entrada no lineal conjunta con capacidad controlable y una unidad de clasificación dependiente del espacio conjunto que está entrenada con pérdida de entropía cruzada para optimizar el rendimiento de la clasificación. Evaluamos modelos de clasificación de textos de recursos completos y de recursos bajos o nulos de noticias multilingües y textos biomédicos con un juego de etiquetas grande. Nuestro modelo supera a los modelos monolingües y multilingües que no aprovechan la semántica de etiquetas ni los modelos anteriores de espacio de etiquetas de entrada conjunta en ambos escenarios.', 'fr': "Les modèles de classification de texte neuronal traitent généralement les étiquettes de sortie comme des variables catégorielles dépourvues de description et de sémantique. Cela force leur paramétrisation à dépendre de la taille de l'ensemble d'étiquettes et, par conséquent, ils ne peuvent pas être mis à l'échelle à de grands ensembles d'étiquettes et généralisés à des ensembles d'étiquettes invisibles. Les modèles de texte d'entrée et d'étiquette conjoints existants surmontent ces problèmes en exploitant les descriptions d'étiquettes, mais ils sont incapables de saisir des relations d'étiquette complexes, ont une paramétrisation rigide et leurs gains sur les étiquettes invisibles se produisent souvent au détriment de faibles performances sur les étiquettes vues pendant la formation. Dans cet article, nous proposons un nouveau modèle d'étiquette d'entrée qui généralise par rapport aux modèles précédents, aborde leurs limites et ne compromet pas les performances sur les étiquettes vues. Le modèle se compose d'une intégration d'étiquette d'entrée non linéaire conjointe avec une capacité contrôlable et d'une unité de classification dépendante de l'espace articulaire qui est entraînée avec une perte d'entropie croisée afin d'optimiser les performances de classification. Nous évaluons des modèles sur la classification textuelle des ressources complètes et des ressources faibles ou nulles des actualités multilingues et des textes biomédicaux avec un grand ensemble d'étiquettes. Notre modèle surpasse les modèles monolingues et multilingues qui ne tirent pas parti de la sémantique des étiquettes et des modèles d'espace d'entrée et d'étiquette conjoints précédents dans les deux scénarios.", 'pt': 'Os modelos de classificação de texto neural normalmente tratam os rótulos de saída como variáveis categóricas que carecem de descrição e semântica. Isso força sua parametrização a depender do tamanho do conjunto de rótulos e, portanto, eles são incapazes de escalar para conjuntos de rótulos grandes e generalizar para conjuntos não vistos. Os modelos de texto de rótulos de entrada conjuntos existentes superam esses problemas explorando descrições de rótulos, mas são incapazes de capturar relacionamentos de rótulos complexos, têm parametrização rígida e seus ganhos em rótulos não vistos geralmente acontecem às custas de desempenho fraco nos rótulos vistos durante o treinamento. Neste artigo, propomos um novo modelo de rótulo de entrada que generaliza sobre modelos anteriores, aborda suas limitações e não compromete o desempenho em rótulos vistos. O modelo consiste em uma incorporação de rótulo de entrada não linear conjunta com capacidade controlável e uma unidade de classificação dependente do espaço de articulação que é treinada com perda de entropia cruzada para otimizar o desempenho da classificação. Avaliamos modelos de classificação de texto com recursos completos e com poucos ou zero recursos de notícias multilíngues e texto biomédico com um grande conjunto de rótulos. Nosso modelo supera os modelos monolíngues e multilíngues que não aproveitam a semântica de rótulos e os modelos de espaço de entrada-rótulo conjuntos anteriores em ambos os cenários.', 'ja': 'ニューラルテキスト分類モデルは、典型的には、出力ラベルを、記述および意味論を欠く分類変数として扱う。 これにより、パラメータ化はラベルセットのサイズに依存するように強制され、したがって、大きなラベルセットにスケーリングし、見えないものに一般化することはできません。 既存のジョイントインプットラベルテキストモデルは、ラベル記述を利用することによってこれらの問題を克服しますが、複雑なラベル関係をキャプチャすることができず、堅固なパラメータ化を持ち、見えないラベルでの利得は、トレーニング中に見られるラベルのパフォーマンスの低下を犠牲にして発生することがよくあります。 本稿では，これまでのモデルよりも一般化し，限界に対処し，見たラベルのパフォーマンスを損なわない新しいインプットラベルモデルを提案する． モデルは、制御可能な容量を有するジョイント非線形入力ラベル埋め込みと、分類性能を最適化するためにクロスエントロピー損失でトレーニングされたジョイント空間依存分類ユニットで構成されています。 私たちは、多言語ニュースとバイオメディカルテキストのフルリソースと低リソースまたはゼロリソースのテキスト分類に関するモデルを、大きなラベルセットで評価します。 当社のモデルは、両方のシナリオでラベルセマンティクスと以前の共同入力ラベル空間モデルを活用していない単語および多言語モデルを上回っています。', 'zh': '神经文本分模常以输标为少言语义之变量。 是故参数化依于小大,故不能广于大而广于不见也。 今有合输标签者,因其克之,不可得而得者,有严参数化,而其益于不见者,常以死练见者为贱。 凡新输标签,可概前法,以决其局限性,不损所见。 凡模形有可控容者非线性输标签嵌合空间依赖性分类单元成,该单元因交叉熵损训练以优化性能。 评估有大标签集多言新闻与生物医学文本全资、低资源零资源文本分类模型。 吾模优于单语与多言,二者皆无所用语义与前合输空。', 'hi': 'तंत्रिका पाठ वर्गीकरण मॉडल आमतौर पर आउटपुट लेबल को स्पष्ट चर के रूप में मानते हैं जिनमें वर्णन और शब्दार्थ की कमी होती है। यह उनके पैरामेट्रिज़ेशन को लेबल सेट आकार पर निर्भर होने के लिए मजबूर करता है, और इसलिए, वे बड़े लेबल सेट को स्केल करने और अनदेखी लोगों को सामान्यीकृत करने में असमर्थ हैं। मौजूदा संयुक्त इनपुट-लेबल टेक्स्ट मॉडल लेबल विवरणों का शोषण करके इन मुद्दों को दूर करते हैं, लेकिन वे जटिल लेबल संबंधों को पकड़ने में असमर्थ हैं, कठोर पैरामेट्राइजेशन करते हैं, और अनदेखी लेबल पर उनके लाभ अक्सर प्रशिक्षण के दौरान देखे गए लेबल पर कमजोर प्रदर्शन की कीमत पर होते हैं। इस पेपर में, हम एक नए इनपुट-लेबल मॉडल का प्रस्ताव करते हैं जो पिछले ऐसे मॉडलों पर सामान्यीकरण करता है, उनकी सीमाओं को संबोधित करता है, और देखे गए लेबल पर प्रदर्शन से समझौता नहीं करता है। मॉडल में नियंत्रणीय क्षमता के साथ एक संयुक्त nonlinear इनपुट-लेबल एम्बेडिंग और एक संयुक्त-अंतरिक्ष-निर्भर वर्गीकरण इकाई होती है जिसे वर्गीकरण प्रदर्शन को अनुकूलित करने के लिए क्रॉस-एन्ट्रॉपी हानि के साथ प्रशिक्षित किया जाता है। हम एक बड़े लेबल सेट के साथ बहुभाषी समाचार और बायोमेडिकल पाठ के पूर्ण-संसाधन और कम-या शून्य-संसाधन पाठ वर्गीकरण पर मॉडल का मूल्यांकन करते हैं। हमारा मॉडल मोनोलिंगुअल और बहुभाषी मॉडल से बेहतर प्रदर्शन करता है जो दोनों परिदृश्यों में लेबल शब्दार्थ और पिछले संयुक्त इनपुट-लेबल स्पेस मॉडल का लाभ नहीं उठाते हैं।', 'ru': 'Нейронные модели классификации текста обычно рассматривают выходные метки как категориальные переменные, которым не хватает описания и семантики. Это заставляет их параметризацию зависеть от размера набора меток, и, следовательно, они не могут масштабироваться до больших наборов меток и обобщаться до невидимых. Существующие совместные текстовые модели с входными ярлыками преодолевают эти проблемы, используя описания ярлыков, но они не в состоянии фиксировать сложные взаимосвязи ярлыков, имеют жесткую параметризацию, и их достижения на невидимых ярлыках часто происходят в ущерб слабой производительности на ярлыках, наблюдаемых во время обучения. В этой статье мы предлагаем новую модель входной этикетки, которая обобщает предыдущие такие модели, рассматривает их ограничения и не ставит под угрозу производительность на видимых этикетках. Модель состоит из совместного нелинейного вложения входной метки с контролируемой емкостью и блока совместной пространственно-зависимой классификации, который обучается с перекрестными энтропическими потерями для оптимизации производительности классификации. Мы оцениваем модели полноресурсной и малоресурсной или нулевой текстовой классификации многоязычных новостей и биомедицинского текста с большим набором этикеток. Наша модель превосходит одноязычные и многоязычные модели, которые не используют семантику меток и предыдущие модели совместного пространства входных данных и меток в обоих сценариях.', 'ga': 'De ghnáth déileálann samhlacha aicmithe téacs néaracha le lipéid aschuir mar athróga catagóiriúla nach bhfuil cur síos orthu ná an tséimeantaic. Cuireann sé seo iallach ar a bparaiméadracht a bheith ag brath ar mhéid na lipéad, agus, mar sin, níl siad in ann scála a dhéanamh go tacair lipéid mhóra agus ginearálú chuig na cinn nach bhfacthas riamh cheana. Sáraítear na saincheisteanna sin trí thuairiscí lipéid a shaothrú i samhlacha comhpháirteacha téacs lipéid ionchuir, ach ní féidir leo gaolmhaireachtaí casta lipéad a ghabháil, tá paraiméadracht docht acu, agus tarlaíonn a ngnóthachan ar lipéid nach bhfacthas riamh cheana ar chostas lagfheidhmíochta ar na lipéid a fheictear le linn na hoiliúna. Sa pháipéar seo, molaimid múnla lipéad ionchuir nua a dhéanann ginearálú ar shamhlacha dá leithéid roimhe seo, a thugann aghaidh ar a dteorainneacha, agus nach gcuireann isteach ar fheidhmíocht ar lipéid a fheictear. Is éard atá sa tsamhail comhlipéad neamhlíneach ionchuir a neadaíonn cumas inrialaithe agus aonad aicmithe comhspás-spleách atá oilte le caillteanas tras-eantrópachta chun an fheidhmíocht aicmithe a bharrfheabhsú. Déanaimid meastóireacht ar shamhlacha ar aicmiú téacs lán-acmhainne agus acmhainní íseal nó nialasach ar nuacht ilteangach agus ar théacs bithleighis le tacar mór lipéad. Feidhmíonn ár múnla níos fearr ná samhlacha aonteangacha agus ilteangacha nach n-eascraíonn séimeanaic lipéad agus samhlacha spáis comhlipéid ionchuir roimhe seo sa dá chás.', 'el': 'Τα νεανικά μοντέλα ταξινόμησης κειμένου συνήθως αντιμετωπίζουν τις ετικέτες εξόδου ως κατηγοριακές μεταβλητές που στερούνται περιγραφής και σημασιολογίας. Αυτό αναγκάζει την παραμετροποίηση τους να εξαρτάται από το μέγεθος του συνόλου ετικετών και, ως εκ τούτου, δεν είναι σε θέση να κλιμακωθούν σε μεγάλα σύνολα ετικετών και να γενικεύσουν σε αόρατα. Τα υπάρχοντα κοινά μοντέλα κειμένου εισαγωγής-ετικέτας ξεπερνούν αυτά τα ζητήματα αξιοποιώντας περιγραφές ετικετών, αλλά δεν είναι σε θέση να συλλάβουν πολύπλοκες σχέσεις ετικετών, έχουν άκαμπτη παραμετροποίηση και τα κέρδη τους σε αόρατες ετικέτες συμβαίνουν συχνά σε βάρος της αδύναμης απόδοσης στις ετικέτες που παρατηρούνται κατά τη διάρκεια της εκπαίδευσης. Σε αυτή την εργασία, προτείνουμε ένα νέο μοντέλο εισαγωγής-ετικέτας που γενικεύει σε σχέση με προηγούμενα τέτοια μοντέλα, αντιμετωπίζει τους περιορισμούς τους και δεν θέτει σε κίνδυνο την απόδοση στις ορατές ετικέτες. Το μοντέλο αποτελείται από μια κοινή μη γραμμική ενσωμάτωση ετικετών εισόδου-εισόδου με ελεγχόμενη ικανότητα και μια μονάδα ταξινόμησης που εξαρτάται από το κοινό-χώρο που εκπαιδεύεται με απώλεια διασταυρούμενης εντροπίας για τη βελτιστοποίηση της απόδοσης ταξινόμησης. Αξιολογούμε μοντέλα για την πλήρη και χαμηλή ή μηδενική ταξινόμηση κειμένων πολυγλωσσικών ειδήσεων και βιοϊατρικού κειμένου με μεγάλο σύνολο ετικετών. Το μοντέλο μας ξεπερνά τα μονογλωσσικά και πολυγλωσσικά μοντέλα που δεν αξιοποιούν τη σημασιολογία ετικετών και προηγούμενα κοινά μοντέλα χώρου εισόδου-ετικετών και στα δύο σενάρια.', 'ka': 'ნეიროლური ტექსტის კლასიფიკაციის მოდელები ტიპულად გამოყენება ლექტები როგორც კატეგორიალური ცვლილები, რომლებიც გამოყენება და სიმენტიკები არს ეს მათი პარამეტრიზაციას უნდა იყოს ჩატვირთებული ზომიდან დააყენებული, და ამიტომ მათი არ შეუძლებელია დიდი ჩატვირთების ზომიდან მარცხოვრება და გენერალიზაცია არ არსებობს ერთადერთი მონაცემების ტექსტის მოდელები ამ პრობლემების გამოყენებით, მაგრამ ისინი არ შეუძლებელია კომპლექსი ტექსტის შესახებ, არსებობენ კომპლექსი ტექსტის შესახებ, არსებობენ პარამეტრიზაცია და ის ამ დოკუნეში ჩვენ ახალი მონაცემების მოდელს, რომელიც წინ ასეთი მოდელების განმავლობაში გენერალიზება, მისი დროების მისამართება და არ გამოყენებს კომპრომიზებას ჩვენებული eti მოდელის შეფარდება კონტროლიფიკაციის კონტროლიფიკაციის შესახებ და კონტროლიფიკაციის კონტროლიფიკაციის კონტროლიფიკაციის ერთეულისთვის, რომელიც კრესიკოლიფიკაციის კონტროლიფიკაციის გამოსახულებლა ჩვენ მოდელები მულ რესურსის და ცოლ რესურსის ტექსტის კლასიფიკაციაში მრავალენგური ინფორმაციის და ბიომედიციური ტექსტის შესახებ, რომელიც დიდი რესურსის შესა ჩვენი მოდელი მონოლენგური და მრავალენგური მოდელეები გავაკეთებს, რომლებიც არ შეუძლიათ ლებლიკური სიმენტიკები და წინაღალდეგი მრავალური სიმენტიკების მოდელეები ორი', 'it': "I modelli di classificazione del testo neurale tipicamente trattano le etichette di output come variabili categoriche prive di descrizione e semantica. Questo costringe la loro parametrizzazione a dipendere dalla dimensione del set di etichette, e, quindi, non sono in grado di scalare a grandi set di etichette e generalizzare a quelli invisibili. I modelli di testo comuni input-label esistenti risolvono questi problemi sfruttando le descrizioni delle etichette, ma non sono in grado di catturare relazioni di etichetta complesse, hanno una parametrizzazione rigida e i loro guadagni su etichette invisibili avvengono spesso a scapito di prestazioni deboli sulle etichette osservate durante la formazione. In questo articolo, proponiamo un nuovo modello di input-label che generalizzi sui modelli precedenti di questo tipo, affronti i loro limiti e non comprometta le prestazioni sulle etichette viste. Il modello consiste in un embedding congiunto non lineare di input-label con capacità controllabile e un'unità di classificazione congiunta-spazio-dipendente che è addestrata con perdita di entropia incrociata per ottimizzare le prestazioni di classificazione. Valutiamo modelli di classificazione dei testi a risorse complete e a risorse basse o zero di notizie multilingue e testi biomedici con un set di etichette di grandi dimensioni. Il nostro modello supera i modelli monolingue e multilingue che non sfruttano la semantica delle etichette e i precedenti modelli comuni di spazio input-label in entrambi gli scenari.", 'hu': 'A neurális szövegosztályozási modellek általában kategorikus változóként kezelik a kimeneti címkéket, amelyek hiányzik a leírás és a szemantika. Ez arra kényszeríti a paraméterezésüket, hogy a címkészlet méretétől függően legyen, így nem tudnak nagy címkészletekre skálázni és általánosítani a láthatatlanokra. A meglévő közös bemeneti-címke szövegmodellek ezeket a problémákat a címke leírásainak kihasználásával oldják meg, de nem képesek összetett címke kapcsolatokat rögzíteni, merev paraméterezéssel rendelkeznek, és a láthatatlan címkéken elért eredményeik gyakran a címkék gyenge teljesítményének rovására fordulnak elő. Ebben a tanulmányban egy új input-label modellt javasolunk, amely általánosítja a korábbi ilyen modelleket, kezeli azok korlátait, és nem veszélyezteti a látható címkék teljesítményét. A modell egy vezérelhető kapacitással rendelkező, közös, nemlineáris bemeneti címke beágyazásból és egy közös térfüggő osztályozási egységből áll, amelyet keresztentrópia veszteséggel képeztek az osztályozási teljesítmény optimalizálására. Többnyelvű hírek és orvosbiológiai szövegek teljes forrású és alacsony vagy nulla forrású szövegosztályozására vonatkozó modelleket értékeljük nagy címkekészlettel. Modellünk mindkét forgatókönyvben felülmúlja az egynyelvű és többnyelvű modelleket, amelyek nem használják a címke szemantikáját és a korábbi közös bemeneti-címke térmodelleket.', 'ms': 'Model klasifikasi teks saraf biasanya menjaga label output sebagai pembolehubah kategori yang kekurangan keterangan dan semantik. Ini memaksa parametrisasi mereka bergantung pada saiz set label, dan, oleh itu, mereka tidak dapat skala ke set label besar dan umumkan kepada yang tidak terlihat. Model teks input-label kongsi yang wujud mengatasi isu-isu ini dengan mengeksploitasi deskripsi label, tetapi mereka tidak dapat menangkap hubungan label kompleks, mempunyai parametrisasi yang ketat, dan keuntungan mereka pada label yang tidak terlihat sering berlaku pada biaya prestasi lemah pada label yang dilihat semasa latihan. Dalam kertas ini, kami cadangkan model input-label baru yang menyebarkan lebih daripada model sebelumnya, mengarahkan keterangan mereka, dan tidak kompromi prestasi pada label yang dilihat. Model ini terdiri dari label input-bukan linear bersatu yang memasukkan dengan kapasitas yang boleh dikawal dan unit klasifikasi bergantung-ruang bersatu yang dilatih dengan kehilangan entropi salib untuk optimumkan prestasi klasifikasi. Kami menilai model pada kelasukan teks sumber penuh dan sumber rendah atau sifar bagi berita berbilang bahasa dan teks biomedikal dengan set label besar. Model kita melebihi model monobahasa dan berbilang bahasa yang tidak menggunakan label semantik dan model ruang input-label terdahulu dalam kedua-dua skenario.', 'kk': 'Нейрондық мәтін классификациялау үлгілері, әдетте шығыс жарлықтарын сипаттамасы мен семантикалық деген категориялық айнымалылар ретінде қалайды. Бұл параметрлерін жарлық орнатылған өлшеміне тәуелді, сондықтан олар үлкен жарлық жиындарына масштабтау және көрсетілмейді. Бар жалпы енгізу жарлығының мәтін үлгілері жарлығының сипаттамасын қолдану арқылы осы мәселелерді көмектеседі, бірақ олар комплекс жарлықтар қатынасын қабылдауға болмайды, дұрыс параметрлерін қабылдауға болады, және олардың көріні Бұл қағаздың жаңа енгізу үлгісін ұсынып, алдыңғы үлгілерді жалғастырып, шектеулерін адрестеп, көрінетін жарлықтардың істеуін көмектеспейді. Бұл үлгі басқару мүмкіндігі мен біріктірілген бос орын тәуелді классификациялық бірлігі, біріктірілген ентропиялық жоғалу үшін біріктірілген жоғалу үшін біріктірілген нелиниялық енгізу жарлығы Біз үлгілерді толық ресурс мен төмен не нөл ресурс мәтінді бірнеше тілдік жаңалықтар және биомедикалық мәтінді үлкен жарлықтарды бағалаймыз. Біздің үлгіміз екі сценарияда бірнеше тілді мен бірнеше тілді үлгілерді өзгертпейді. Бұл белгілерді семантикалық пен алдыңғы келтірілген кеңістік үлгілерді екі сценарияда', 'lt': 'Neural text classification models typically treat output labels as categorical variables that lack description and semantics.  This forces their parametrization to be dependent on the label set size, and, hence, they are unable to scale to large label sets and generalize to unseen ones.  Existing joint input-label text models overcome these issues by exploiting label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels happen often at the expense of weak performance on the labels seen during training.  Šiame dokumente siūlome naują įvesties etiketės model į, kuris apibendrina ankstesnius tokius modelius, atsižvelgia į jų apribojimus ir nekelia pavojaus matytiems etiketėms. Modelą sudaro jungtinis nelinijinis įvesties ženklas su kontroliuojamu pajėgumu ir jungtinis nuo erdvės priklausomas klasifikavimo vienetas, kuris mokomas su kryžminiu entropijos praradimu siekiant optimizuoti klasifikavimo charakteristikas. Vertiname daugiakalbių naujienų ir biomedicinio teksto, kuriame pateikiama didelė etiketė, visiškų išteklių ir mažų arba nulinių išteklių teksto klasifikavimo modelius. Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.', 'ml': 'നെയുറല്\u200d ടെക്സ്റ്റ് ക്ലാസ്ഫിക്ഷന്\u200d മോഡലുകള്\u200d സാധാരണ പുറപ്പെടുത്തുന്ന ലേബ്ലുകള്\u200d വിശദീകരണവും സെമാന്റിക്സ ലേബ്ലേറ്റിന്റെ വലിപ്പം ആശ്രയിക്കുന്നതിനായി അവയുടെ പാരാമീറ്ററിഷനെ ഇത് പ്രവര്\u200dത്തിപ്പിക്കുന്നു. അതിനാല്\u200d അവര്\u200dക്ക് വലിയ ലേ ലേബിള്\u200d വിശദീകരണങ്ങള്\u200d ഉപയോഗിക്കുന്നതിനാല്\u200d നിലവിലുള്ള സഹജമായ ഇന്\u200dപുട്ട് ലേബിലേറ്റ് ടെക്സ്റ്റ് മാതൃകങ്ങള്\u200d പരിജയപ്പെടുത്തുവാന്\u200d അവര്\u200dക്ക് കഴിയില്ല, പരിശീലനത്തി ഈ പത്രത്തില്\u200d, മുമ്പുള്ള ഇങ്ങനെയുള്ള മോഡലുകളില്\u200d സാധാരണമാക്കുന്ന ഒരു പുതിയ ഇന്\u200dപുട്ട് ലേബ് മോഡല്\u200d ഞങ്ങള്\u200d പ്രായശ്ചിത്തം ചെയ്യുന നിയന്ത്രിക്കാവുന്ന ശക്തിയോടും നിയന്ത്രിക്കാവുന്ന സ്പെയിസ്റ്റ് ആശ്രയിക്കുന്ന ക്ലാസ്പെയിഷനിന്റെ ക്ലാസ്റ്റിഫ്റ്റ് ആശ്രയിക്കുന്ന ഒര ഞങ്ങള്\u200d മോഡലുകളെ മുഴുവന്\u200d വിഭവങ്ങളിലും കുറഞ്ഞ വിഭവങ്ങളിലും പൂര്\u200dണ്ണമായ വിഭവങ്ങളിലും പദാവലിയിലെ വാര്\u200dത്തകളിലും ബൈവിയോമിക്കല്\u200d വാ നമ്മുടെ മോഡല്\u200d മൊണോളില്\u200dഭാഷകങ്ങളും പല ഭാഷകങ്ങളും പ്രവര്\u200dത്തിപ്പിക്കുന്നു. ലേബറ്റിന്റെ സെമാന്റിക്സും മുമ്പ് യൂട്ട് ഇന്\u200dപു', 'mk': 'Моделите за класификација на неуралниот текст обично ги третираат излезните етикети како категорички променливи кои немаат опис и семантика. Ова ја принуди нивната параметризација да зависи од големината на поставената етикета, и затоа тие не можат да се скалираат на големи поставени етикети и да се генерализираат на невидени. Постојаните заеднички текстови модели на вложена етикета ги надминуваат овие прашања со искористување на описите на етикетата, но тие не можат да фатат комплексни односи со етикетата, имаат цврста параметризација, и нивните добивки на невидени етикети честопати се случуваат на трошок на слабата перформанса на етикетите вид Во овој документ, предложуваме нов модел на вложена етикета кој се генерализира во однос на претходните вакви модели, се обраќа на нивните ограничувања и не ја компромитира перформансата на видени етикети. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance.  Ние ги проценуваме моделите на целосен ресурс и ниско или нула ресурс класификација на текст на мултијазични вести и биомедички текст со голем сет на етикети. Нашиот модел ги надминува монојазичните и мултијазичните модели кои не влијаат на семантиката на етикетата и претходните заеднички вселенски модели на влезот-етикетата во двата сценарија.', 'mn': 'Тархины текст хуваалтын загварууд ихэвчлэн үржүүлэх загваруудыг тайлбарлах болон semantics албагүй категорийн хувьсагчид гэж үздэг. Энэ нь тэдний параметрийг загварын хэмжээнд хамааралтай болгож байна. Тэгэхээр тэд том загварын хэмжээнд хэмжээтэй болж, харагдахгүй зүйлсийг ерөнхийлөгч болгож чадахгүй. Эдгээр асуудлуудыг загварын тодорхойлолтоор ашиглан хамтдаа орж ирсэн бичил загварын загваруудыг давхарлаа. Гэхдээ тэд комплекс загварын харилцаа барьж чадахгүй, хүчтэй параметрийг барьж чадахгүй, харин тэдний шинжлэх загварууд сургалтын үед харагда Энэ цаасан дээр бид өмнө ийм загваруудыг ерөнхийлөгчилж, хязгаарлалтыг удирдаж, харагдаж байгаа загваруудыг тодорхойлж чадахгүй шинэ бичсэн загварын загварыг санал болгож байна. Энэ загвар нь хяналттай чадвартай холбогдсон шулуун биш шулууны оролцоогүй загварын нэгжтэй бөгөөд хамааралтай загварын холбогдолтой хуваалцах нэгжтэй холбогдолтой юм. Бид олон хэлний мэдээллийн, биологийн медицины текстүүдийн бүрэн болон бага эсвэл 0-нүүрстөрөгчийн текстүүдийн хуваалцааны загварыг үнэлдэг. Бидний загвар нь нэг хэл болон олон хэл загваруудыг дамжуулдаг. Эдгээр загварууд хоёр хувилбарт нэг хэл загваруудыг ашиглахгүй.', 'no': 'Klassifikasjonsmodeller for neiraltekst behandler vanlegvis utdata- merkelappar som kategoriske variabler som manglar skildring og semantikk. Dette påkraver parametriseringa sine til å vera avhengig av merkelappen sett storleik, og derfor kan dei ikkje skalera til store merkelappane og generellisera til ukjende. Det eksisterande felles tekstmodeller for innskriftsmerkelappen overfører desse problemene ved å bruka merkelappebeskrivelser, men dei kan ikkje henta komplekse merkelappunksjonar, ha sterke parametrisering, og hendinga på ukjende merkelapper skjer ofte på uttrykket av svake uttrykk på merkelappene som ser under opplæring. I denne papiret foreslår vi eit nytt innskriftsmerkelappemodell som genereliserer over førre slike modeller, adresserer grensene sine, og ikkje kompromerer utviklinga på sette merkelapper. Modellen består av ei kopla ikkje-lineær innskriftsmerkelapp innebygd med kontrollbare kapasitet og ei kopla mellomromavhengig klassifikasjonseining som er trent med tap av krysentropi for å optimalisera klassifikasjonsfunksjon. Vi evaluerer modeller på fullstendig ressurs og låg- eller null- ressurstekstklassifikasjon av fleirspråk nyhetar og biomedisk tekst med ein stor merkelapp. Modellen vårt utfører monospråk og fleirspråk modeller som ikkje leverer merkelappen semantikk og førre fleire mellommerkelapper i begge scenarior.', 'ro': 'Modelele de clasificare a textelor neurale tratează de obicei etichetele de ieșire ca variabile categorice care lipsesc descriere și semantică. Acest lucru forțează parametrizarea lor să fie dependentă de dimensiunea setului de etichete și, prin urmare, ei nu sunt capabili să scaleze la seturi mari de etichete și să generalizeze la cele nevăzute. Modelele text de intrare și etichete comune existente depășesc aceste probleme prin exploatarea descrierilor etichetelor, dar ele nu sunt capabile să capteze relații complexe de etichete, au parametrizare rigidă, iar câștigurile lor pe etichetele nevăzute se întâmplă adesea în detrimentul performanțelor slabe pe etichete observate în timpul antrenamentului. În această lucrare, propunem un nou model de intrare-etichetă care generalizează asupra modelelor anterioare, abordează limitările acestora și nu compromite performanța pe etichetele văzute. Modelul constă dintr-o încorporare neliniară de intrare-etichetă comună cu capacitate controlabilă și o unitate de clasificare dependentă de spațiu comun care este instruită cu pierdere de entropie încrucișată pentru a optimiza performanța clasificării. Evaluăm modele privind clasificarea textelor cu resurse complete și cu resurse reduse sau zero a știrilor multilingve și a textelor biomedicale cu un set mare de etichete. Modelul nostru depășește modelele monolingve și multilingve care nu utilizează semantica etichetelor și modelele anterioare de spațiu de intrare-etichetă comune în ambele scenarii.', 'sr': 'Modeli klasifikacije neuronskog teksta obično tretiraju etikete izlaza kao kategorijske varijante koje nedostaju opis i semantike. To nudi da njihova parametrizacija zavisi od veličine određene etikete, i zato oni ne mogu da skalaju na velike sete etikete i generalizuju na nevidljive. Postoje zajednički modeli teksta oznake za ulazak prevladaju te probleme iskorištavanjem opisa oznake, ali oni nisu u mogućnosti da uhvate kompleksne odnose oznake, imaju krute parametrizacije, a njihove dobitke na nevidljivim etiketama se često dešavaju na troškovi slabe funkcije na etiketama koje su vidjele tokom treninga. U ovom papiru predlažemo novi model ulaznog etiketa koji generalizuje preko prethodnih takvih model a, adresuje njihove ograničenja i ne kompromisuje performancu na viđenim etiketama. Model se sastoji od zajedničkog nelinearnog ulaznog etiketa ugrađenog sa kontrolnom kapacitetom i zajedničkom klasifikacijskom jedinicom ovisnom od svemira koja je obučena sa gubitkom krsno entropije kako bi optimizirala klasifikaciju. Procjenjujemo modele na klasifikaciji teksta punog resursa i niskog ili nulog resursa multijezičkih vijesti i biomedicinskog teksta sa velikim nametom. Naš model iznosi monojezičke i multijezičke modele koji ne utiču na etikete semantike i prethodne zajedničke svemirske modele za ulazak u obje scenarije.', 'so': "Tusaaladaha tababaridda ee qoraalka naadiga ah sida caadiga ah waxaa loo isticmaalaa alaabta soo baxa oo kala duwan oo aan u baahnayn sawir iyo semantika. Tani waxay ku xiran karaan parameterisadooda, waxayna ku xiran yihiin tirada calaamadda, sababtaas darteed ma awoodi karaan inay kor u qaadaan xarumaha calaamada waaweyn iyo inay u soo bandhigaan meelaha qarsoon. Tusaalooyinka qoraalka ee wadajirka ah ee laga soo qoro qoraalkaas waxay ku adkaan karaan warqadaha calaamada, laakiin way awoodi kari waayaan inay qabtaan xiriirka qalabka adag, waxay leeyihiin mid si adag u isticmaalaya, faa'iidadooda ku baxana baalasha qarsoon waxey marar badan ku dhacaan kharashka tababarka tababarka lagu arag xilliga waxbarashada. Qoraalkan waxaynu soo jeedaynaa model cusub oo laga soo bandhigayo tusaale ahaan hore oo kale, waxaana ku qoraynaa xuduudaha, mana sameynayo tababarka lagu arko alaabta. Tusaalada waxaa ka mid ah mid ka mid ah mid ka mid ah wadajir-aan-linear input-label oo ku qoran awoodda kontroll leh iyo qaybta iskuulka oo wadajir-space-ku xiran, oo lagu baran karo khasaarada korontopy si uu u optimiso fasaxa fasaxa. Tusaalada waxaan ku qiimeynaynaa qoraalka qoraalka hoose-iyo-hoos-ama-zero-resource ee warbixinta luuqadaha kala duduwan iyo qoraalka biomedical ah oo ku qoran calaamad weyn. Tusaale'dayadu wuxuu sameeyaa tusaalooyin luuqado kala duduwan oo aan ku isticmaalin calaamada semantics iyo samooyinka hore oo ka mid ah mid-ka-gala-label-label labadoodaba.", 'sv': 'Neurala textklassificeringsmodeller behandlar vanligtvis utmatningsetiketter som kategoriska variabler som saknar beskrivning och semantik. Detta tvingar deras parametrisering att vara beroende av etikettuppsättningens storlek, och därför kan de inte skala till stora etikettuppsättningar och generalisera till osynliga. Befintliga gemensamma textmodeller löser dessa problem genom att utnyttja etikettbeskrivningar, men de kan inte fånga komplexa etikettrelationer, har stel parametrisering, och deras vinster på osynliga etiketter sker ofta på bekostnad av svag prestanda på etiketterna som ses under träning. I denna uppsats föreslår vi en ny inmatningsmodell som generaliserar över tidigare sådana modeller, tar itu med deras begränsningar och inte kompromissar prestanda på sedda etiketter. Modellen består av en gemensam icke-linjär inmatningsmärkning med kontrollerbar kapacitet och en gemensam rymdberoende klassificeringsenhet som utbildas med korsentropiförlust för att optimera klassificeringsprestandan. Vi utvärderar modeller för full- och låg- eller nollresurstextklassificering av flerspråkiga nyheter och biomedicinsk text med en stor etikettuppsättning. Vår modell överträffar enspråkiga och flerspråkiga modeller som inte utnyttjar etikettsemantik och tidigare gemensamma inmatningsmodeller för etiketter i båda scenarierna.', 'ta': 'நெருல் உரை வகைப்படுத்தல் மாதிரிகள் வழக்கமாக வெளியீட்டு சிட்டைகளை வகைப்பட்ட மாறிகளாக பயன்படுத்துகிறது. விவரிப்பும இது விளக்கச்சீட்டு அளவு சார்ந்து கொள்ள அளபுருவை செய்ய முடியாது, அதனால் பெரிய விளக்கச் சீட்டு அமைப்புகளுக்கு அளவிட முடியாத தற்போதைய சேரும் உள்ளீட்டு உரை மாதிரிகள் சிட்டை விளக்கங்களை பயன்படுத்தி இந்த விஷயங்களை வெற்றி பெறுகிறது, ஆனால் அவர்களால் சிக்கலான விளக்கச்சீட்டு உறவுகளை பிடிக்க முடியாத இந்த தாளில், நாம் முந்தைய மாதிரியில் புதிய உள்ளீட்டு மாதிரியை பரிந்துரைக்கிறோம். இது முந்தைய மாதிரிகளில் பொதுவாக்கும், அவற இந்த மாதிரியில் உள்ளீடு- விளக்கம் கட்டுப்படுத்தக்கூடிய சக்தியுடன் உட்பொதிந்த ஒரு இணைக்கோடு அல்லாத உள்ளீட்டு விளக்கச்சீட்டு மற்றும் ஒரு joint- space- சா நாம் முழு மூலத்திலும் குறைந்த அல்லது பூஜ்ஜியமான மூலத்திலும் உரை வகைப்பிலும் மாதிரிகளை மதிப்பிடுகிறோம் பல மொழி செய்தியும எங்கள் மாதிரி மொன்மொழி மற்றும் பல மொழி மாதிரி மாதிரிகளை செயல்படுத்துகிறது இவை இரண்டு காட்சிகளிலும் முந்தைய இணைய உள்ளீட்டு வெள', 'ur': 'نائورل ٹیکسٹ کلاسپیٹ موڈل معمولاً اپوٹ وٹ وٹ لیبل کو کلاسپیٹ ویرئیٹ کے طور پر دکھاتے ہیں جن کی توصیف اور سیمانٹیک نہیں ہے. یہ ان کے پارامیٹریزی کو لابل سٹ کی سائز پر اعتماد کرنے کے لئے مجبور کرتا ہے، اور لہذا وہ بڑے لابل سٹ تک اسکیل نہیں کر سکتے اور غیب کی سائل کو آسان کر سکتے ہیں۔ Existing joint input-label text models overcome these issues by using label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels often happen at the expense of weak performance on the labels seen during training. اس کاغذ میں ہم ایک نئی اینٹ لیبل موڈل پیشنهاد کرتے ہیں جو پہلے ایسے موڈل پر جرائل کرتا ہے، ان کی محدودیت کو ادرس کرتا ہے، اور دیکھے لیبل پر کامپیوتر کمزور نہیں کرتا۔ Model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. ہم نے مدلکوں کو پورا-سروسیس اور کم یا صفر-سروسیس ٹیکسٹ کلیسٹ پر مطالعہ کرلیا ہے multilingual news اور biomedical text کے ایک بڑے لیبل سٹ کے ساتھ. ہمارا موڈل ایک زبان اور ملتی زبان کی موڈلیاں کامل کرتا ہے جو لیبل سیمانٹیکوں اور پہلے سے پیدا ہونے والی اینپ لابل فضا موڈلیاں دونوں سینا ریوئیوں میں نہیں لگاتے۔', 'mt': 'Mudelli ta’ klassifikazzjoni tat-test newrali tipikament jittrattaw it-tikketti tal-output bħala varjabbli kategoriċi li m’għandhomx deskrizzjoni u semantika. Dan iġġiegħel lill-parametrizzazzjoni tagħhom tkun dipendenti fuq id-daqs tas-sett tat-tikketta, u għalhekk ma jistgħux jikbru l-iskala għal settijiet kbar ta’ tikketta u jiġġeneralizzaw għal dawk li ma jidhrux. Il-mudelli tat-test konġunti eżistenti tat-tikketta tal-input jegħlbu dawn il-kwistjonijiet billi jisfruttaw deskrizzjonijiet tat-tikketta, iżda ma jistgħux jaqbdu relazzjonijiet kumplessi tat-tikketta, ikollhom parametrizzazzjoni riġida, u l-kisbiet tagħhom fuq tikketti mhux osservati sikwit iseħħu bi spiża ta’ prestazzjoni dgħajfa fuq it-tikketti li dehru waqt it-taħriġ. F’dan id-dokument, qed nipproponu mudell ġdid ta’ tikketta tal-input li jiġġeneralizza fuq mudelli preċedenti bħal dawn, jindirizza l-limitazzjonijiet tagħhom, u ma jikkompromettix il-prestazzjoni fuq tikketti li jidhru. Il-mudell jikkonsisti f’tikketta tal-input konġunta mhux lineari li tinkorpora b’kapaċità kontrollabbli u unit à ta’ klassifikazzjoni konġunta dipendenti fuq l-ispazju li hija mħarrġa b’telf ta’ entropija trasversali biex tiġi ottimizzata l-prestazzjoni tal-klassifikazzjoni. Aħna jevalwaw mudelli dwar klassifikazzjoni tat-test b’riżorsi sħa ħ u b’riżorsi baxxi jew żero ta’ aħbarijiet multilingwi u test bijomediku b’sett kbir ta’ tikketta. Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.', 'pl': 'Neuralne modele klasyfikacji tekstu zazwyczaj traktują etykiety wyjściowe jako zmienne kategoryczne, które brakują opisu i semantyki. To zmusza ich parametryzację do uzależnienia od wielkości zestawu etykiet, a zatem nie są w stanie skalować do dużych zestawów etykiet i uogólniać na niewidoczne. Istniejące wspólne modele tekstowe wejścia-etykiety pokonują te problemy poprzez wykorzystanie opisów etykiet, ale nie są w stanie uchwycić złożonych relacji etykiet, mają sztywną parametryzację, a ich zyski na niewidocznych etykietach zdarzają się często kosztem słabej wydajności etykiet widocznych podczas szkolenia. W niniejszym artykule proponujemy nowy model wejściowo-etykietowy, który uogólnia względem poprzednich takich modeli, uwzględnia ich ograniczenia i nie narusza wydajności na widzianych etykietach. Model składa się ze wspólnego nieliniowego osadzenia etykiety wejściowej z kontrolowaną pojemnością i jednostki klasyfikacyjnej zależnej od przestrzeni złączonej, która jest trenowana z utratą entropii krzyżowej w celu optymalizacji wydajności klasyfikacji. Oceniamy modele klasyfikacji tekstów pełnych i niskich lub zerowych, wielojęzycznych wiadomości i tekstów biomedycznych z dużym zestawem etykiet. Nasz model przewyższa modele jednojęzyczne i wielojęzyczne, które nie wykorzystują semantyki etykiet i poprzednich wspólnych modeli przestrzeni wejścia-etykiety w obu scenariuszach.', 'si': 'න්\u200dයූරාල් පාළුවේ විශේෂණ මොඩල් සාමාන්\u200dයයෙන්ම ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිපත්ත මේකෙන් ඔවුන්ගේ ප්\u200dරමාණිකරණය ලේබුල් සැකසුම් ප්\u200dරමාණයට අවශ්\u200dය වෙන්න පුළුවන්, ඉතින්, ඔවුන් ලේබුල් සැට් වලට වැ Exist shared input-label text Model overnade this challenge by exploding Labels Description, but are inactive to Capture Compressed Labels සම්බන්ධතාවක්, have rigid Paratrizing, and the win on Unseen Labels is oft at the sum of weaker Perfection on the Labels seen in the Training. මේ පැත්තේ අපි අළුත් ඇතුළු ලේබල් මොඩේල් එකක් ප්\u200dරතිචාර කරනවා ඒ වගේ මොඩේල් වලින් සාමාන්\u200dය වෙනුවෙන්, ඔවුන්ගේ සීමාවන මොඩල් එක්ක පාලනය කරන්න පුළුවන් ක්\u200dරියාත්මක සමග සම්බන්ධ නොලිනියර් ඇතුළු ලබේල් එක්ක සම්බන්ධ වෙන්න පුළුවන් සමග සම්බන්ධ වෙ අපි පූර්ණ- සම්පූර්ණ- සහ අඩු සම්පූර්ණ- සහ ශූර්ණ- සම්පූර්ණ- සම්පූර්ණ- සම්පූර්ණ- සම්පූ අපේ මෝඩල් එක භාෂාවක් සහ ගොඩක් භාෂාවක් මෝඩල් කරන්න පුළුවන් වෙනවා ඒ වගේම ලේබුල් සෙමැන්ටික් සහ කලින් සම්බන්ධ', 'uz': "Name Bu yerda ularning parametrlarini yorliqning oʻlchamidan ishlatishga ishonchini bajaradi, va shunday qilib ular katta yorliq satrlariga oʻtishi mumkin. Mavjud birinchi qoʻyish yozuv matn modellari yordamida bu muammolarni yozib olish mumkin, lekin ular murakkab yorliq bogʻlamalarini olib tashlab boʻlmaydi, yetarli parametriklashtirish mumkin, yetishmaydigan yorlarning amalni ko'rib chiqish vaqti yordamida ko'rib chiqish tugmasi yordamida yomon. Bu hujjatda, biz oldingi modellardan generalisi yangi input- yorliq modelini talab qilamiz, ularning chegaralarini boshqaradi, va koʻrsatilgan yorliqlarda bajarish imkoniyatini kamaytirilmaydi. Name Biz bir necha tillar news va biotikal matnning butun manbalar va nuqta manbalar matn darajasini qiymatimiz, katta yorliq yordamida. Bizning modelimiz bir necha tillar va bir xil modellarini bajaradi. Bu ikkita scenariosda hech qanday bir bir bir nechta qo'shish mumkin.", 'vi': 'Mẫu phân loại chữ thần kinh thường coi các nhãn xuất là các biến số không miêu tả và ngữ pháp. Điều này khiến cho thiết bị đo lường của chúng trở nên phụ thuộc vào kích thước của nhãn đặt, và do đó, chúng không thể quy mô với các thiết lập nhãn lớn và tổng hợp thành những cái chưa thấy. Các mô hình văn bản nhãn nhập chung hiện tại giải quyết những vấn đề này bằng cách khai thác các mô tả nhãn, nhưng chúng không thể nắm bắt các mối quan hệ nhãn hiệu phức tạp, thiết kế siêu âm cứng, và lợi nhuận trên nhãn vô hình thường xảy ra vì hiệu suất kém trên nhãn được nhìn thấy trong huấn luyện. Trong tờ giấy này, chúng tôi đề nghị một mô hình nhãn nhập mới tổng hợp hơn các mô hình trước đó, chấp nhận giới hạn của chúng, và không ảnh hưởng đến các nhãn đã thấy. The model consists of a joint non-linear nhập-markings embedding with control capacity and a join-space-dependence classification unit that is educated with cross-entropy loss to tối ưu hoá hoá hoá hoá hoá hoá hoá performance. Chúng tôi đánh giá các mô hình về các tài nguyên đầy đủ và loại văn bản nhỏ hay không chứa nhiều nguồn tin và văn bản sinh học với một bộ nhãn lớn. Trong cả hai kịch bản, mẫu của chúng tôi hoàn thiện ngôn ngữ và ngôn ngữ nhiều loại mà không tác động được ngữ pháp và biểu mẫu chung nhãn nội dung.', 'da': 'Neurale tekstklassifikationsmodeller behandler typisk outputetiketter som kategoriske variabler, der mangler beskrivelse og semantik. Dette tvinger deres parametrisering til at være afhængig af etiketsættets størrelse, og derfor er de ikke i stand til at skalere til store etiketsæt og generalisere til usynlige. Eksisterende fælles input-label tekstmodeller løser disse problemer ved at udnytte etiketbeskrivelser, men de er ikke i stand til at indfange komplekse etiketrelationer, har stiv parametrisering, og deres gevinster på usynlige etiketter sker ofte på bekostning af svag ydeevne på etiketterne set under træning. I denne artikel foreslår vi en ny input-label model, der generaliserer over tidligere sådanne modeller, adresserer deres begrænsninger og ikke kompromitterer ydeevnen på set etiketter. Modellen består af en fælles ikke-lineær input-label indlejring med kontrollerbar kapacitet og en fælles-rum-afhængig klassificeringsenhed, der er trænet med cross-entropi tab for at optimere klassificeringens ydeevne. Vi evaluerer modeller for fuld ressource og lav- eller nul-ressource tekst klassificering af flersprogede nyheder og biomedicinsk tekst med et stort labelsæt. Vores model overgår ensprogede og flersprogede modeller, der ikke udnytter etiketsemantik og tidligere fælles input-label rummodeller i begge scenarier.', 'hr': 'Modeli klasifikacije neuronskog teksta obično tretiraju etikete izlaza kao kategorijske promjene koje nedostaju opis i semantike. To nudi da njihova parametrizacija zavisi od veličine određene etikete, i stoga oni ne mogu skalirati na velike sete etikete i generalizirati na nepoznate. Postoje zajednički modeli teksta oznake za ulazak prevladaju te probleme iskorištavanjem opisa oznake, ali oni ne mogu uhvatiti kompleksne odnose oznake, imaju krute parametrizacije, a njihovi dobiti na nevidljivim etiketama često se događaju na troškovi slabe učinke na etiketama viđenim tijekom obuke. U ovom papiru predlažemo novi model ulaznog etiketa koji generalizira preko prethodnih takvih model a, adresira njihove ograničenja i ne kompromisuje učinkovitost na viđenim etiketama. Model se sastoji od zajedničkog nelinearnog ulaznog etiketa ugrađenog s kontrolnom kapacitetom i zajedničkom klasifikacijskom jedinicom ovisnom o svemiru koja je obučena s gubitkom preko entropije kako bi optimizirala klasifikaciju. Procjenjujemo modele o klasifikaciji teksta punog resursa i niskog ili nulog resursa multijezičkih vijesti i biomedicinskog teksta s velikim oznakem. Naš model iznosi monojezičke i višejezičke modele koji ne utiču na etikete semantike i prethodne zajedničke svemirske modele u obje scenarije.', 'bg': 'Моделите за класификация на неврални текстове обикновено третират изходните етикети като категорични променливи, които нямат описание и семантика. Това принуждава параметризацията им да зависи от размера на набора етикети и следователно те не могат да мащабират до големи набори етикети и да обобщят до невидими такива. Съществуващите съвместни текстови модели за въвеждане и етикет преодоляват тези проблеми чрез използване на описания на етикети, но те не са в състояние да уловят сложни връзки на етикети, имат строга параметризация и печалбите им от невидими етикети често се случват за сметка на слабото представяне на етикетите, наблюдавани по време на обучението. В тази статия предлагаме нов модел на входно-етикет, който обобщава предишните модели, адресира техните ограничения и не компрометира производителността на видимите етикети. Моделът се състои от съединено нелинейно вграждане на входен етикет с контролируем капацитет и съединено-пространствено-зависима класификационна единица, която е обучена с загуба на кръстосана ентропия за оптимизиране на класификационната ефективност. Оценяваме модели за класификация на текста с пълен ресурс и нисък ресурс или нулев ресурс на многоезични новини и биомедицински текстове с голям набор етикети. Нашият модел превъзхожда едноезичните и многоезичните модели, които не използват семантиката на етикетите и предишните съвместни модели на входно-етикетно пространство и в двата сценария.', 'de': 'Neurale Textklassifizierungsmodelle behandeln Ausgabeetiketten typischerweise als kategoriale Variablen, denen es an Beschreibung und Semantik mangelt. Dies zwingt ihre Parametrisierung dazu, von der Größe der Beschriftungssätze abhängig zu sein, weshalb sie nicht in der Lage sind, auf große Beschriftungssätze zu skalieren und auf unsichtbare zu verallgemeinern. Bestehende gemeinsame Eingabe-Label-Textmodelle überwinden diese Probleme, indem sie Beschreibungen von Etiketten ausnutzen, aber sie sind nicht in der Lage, komplexe Beschriftungsbeziehungen zu erfassen, haben eine starre Parametrisierung, und ihre Gewinne bei unsichtbaren Etiketten gehen oft zu Lasten der schwachen Leistung der Etiketten, die während des Trainings beobachtet werden. In diesem Beitrag schlagen wir ein neues Input-Label-Modell vor, das sich gegenüber früheren Modellen verallgemeinert, deren Einschränkungen adressiert und die Leistung auf gesehenen Etiketten nicht beeinträchtigt. Das Modell besteht aus einer gemeinsamen nichtlinearen Input-Label-Einbettung mit steuerbarer Kapazität und einer joint-space-abhängigen Klassifizierungseinheit, die mit Cross-Entropieverlusten trainiert wird, um die Klassifizierungsleistung zu optimieren. Wir evaluieren Modelle zur vollständigen und ressourcenarmen Textklassifizierung von mehrsprachigen Nachrichten und biomedizinischen Texten mit einem großen Etikettenset. Unser Modell übertrifft in beiden Szenarien ein- und mehrsprachige Modelle, die keine Label-Semantik und frühere gemeinsame Eingabe-Label-Raummodelle nutzen.', 'id': 'Model klasifikasi teks saraf biasanya memperlakukan label output sebagai variabel kategori yang kurang deskripsi dan semantik. Ini memaksa parametrisasi mereka untuk bergantung pada ukuran set label, dan, oleh itu, mereka tidak dapat skala ke set label besar dan generalisasi ke yang tidak terlihat. Model teks input-label kongsi yang ada mengatasi isu-isu ini dengan mengeksploitasi deskripsi label, tetapi mereka tidak dapat menangkap hubungan label kompleks, memiliki parametrisasi yang ketat, dan keuntungan mereka pada label yang tidak terlihat sering terjadi pada biaya prestasi lemah pada label yang terlihat selama latihan. Dalam kertas ini, kami mengusulkan model input-label baru yang menyebarkan lebih dari model sebelumnya, mengatasi batasan mereka, dan tidak merusak prestasi pada label yang terlihat. Model ini terdiri dari label input nonlinear kongsi yang memasukkan dengan kapasitas yang dapat dikendalikan dan unit klasifikasi bergantung pada ruang kongsi yang dilatih dengan kehilangan entropi salib untuk optimisasi prestasi klasifikasi. Kami mengevaluasi model pada sumber daya penuh dan klasifikasi teks sumber daya rendah atau nol dari berita multibahasa dan teks biomedis dengan set label besar. Model kita melebihi model monobahasa dan multibahasa yang tidak menggunakan label semantik dan model ruang input-label sebelumnya dalam kedua skenario.', 'fa': 'مدل\u200cهای ویژه\u200cبندی متن عصبی معمولاً برچسب\u200cهای خروجی را به عنوان متغیر\u200cهای گوناگونی درمان می\u200cکنند که توصیف و سیمانتیک کم دارند. این باعث می\u200cشود پارامتریزی آنها به اندازه تنظیم برچسب بستگی داشته باشند، و بنابراین آنها نمی\u200cتوانند به مجموعه\u200cهای بزرگ برچسب مقیاس کنند و به مجموعه\u200cهای غیرقابل مشاهده گردند. مدل\u200cهای متن\u200cنوشته\u200cی ورودی مشترک با استفاده از توضیح\u200cهای نقاشی، این مشکلات را با استفاده از توضیح\u200cهای نقاشی تغییر می\u200cدهند، ولی آنها نمی\u200cتوانند رابطه\u200cهای نقاشی پیچیده را بگیرند، پارامتریزی سخت داشته باشند، و پیروزی\u200cهایشان بر نقاشی\u200cهای نابینا ا در این کاغذ، ما یک مدل جدیدی از نقاشی ورودی را پیشنهاد می کنیم که در این مدل های قبلی ژنرالیز می کند، به محدودیت هایشان نشان می دهد، و عملکرد روی نقاشی دیده را تغییر نمی دهد. Model consists of a joint non-linear input-label embedded with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. ما مدل\u200cها را در کلی منابع کامل و تنظیم متن کم یا صفر منابع از خبرهای زیادی زبان و متن بیوپزشکی با یک مجموعه برچسب بزرگ ارزیابی می\u200cکنیم. مدل ما مدل های یک زبان و چندین زبان را اجرا می کند که مدل های فضایی که در هر دو سناریو نقاشی از نقاشی و نقاشی که با نقاشی از نقاشی و نقاشی که با نقاشی از نقاشی به نقاشی وارد می شود در هر دو سن', 'nl': "Neurale tekstclassificatiemodellen behandelen uitvoerlabels meestal als categorische variabelen zonder beschrijving en semantiek. Dit dwingt hun parametrisering afhankelijk te zijn van de grootte van de labelset, en daarom zijn ze niet in staat om te schalen naar grote labelsets en te generaliseren naar ongeziene. Bestaande gezamenlijke invoer-label tekstmodellen overwinnen deze problemen door gebruik te maken van labelbeschrijvingen, maar ze zijn niet in staat om complexe labelrelaties vast te leggen, hebben een rigide parametrisering en hun winsten op onzichtbare labels gebeuren vaak ten koste van zwakke prestaties op de labels die tijdens de training worden gezien. In dit artikel stellen we een nieuw input-label model voor dat generaliseert ten opzichte van eerdere dergelijke modellen, hun beperkingen aanpakt en geen afbreuk doet aan de prestaties op zichtbare labels. Het model bestaat uit een gezamenlijke niet-lineaire input-label embedding met controleerbare capaciteit en een joint-space-afhankelijke classificatieeenheid die is getraind met cross-entropieverlies om classificatieprestaties te optimaliseren. We evalueren modellen op full-resource en low- of zero-resource tekstclassificatie van meertalig nieuws en biomedische tekst met een grote labelset. Ons model presteert beter dan eentalige en meertalige modellen die geen gebruik maken van labelsemantiek en eerdere gezamenlijke input-label ruimtemodellen in beide scenario's.", 'tr': 'Nöral metin klasifikasyon modelleri genelde çıqtı etiketleri kategorik çarpmalar olarak hasaplar ve semantik yoktur. Bu onların parametriýasyny etiket düzümlerniň ululykna baglanmagy mümkin edýär we bu sebäpli olar uly etiket düzümlerine gollaşdyryp bilmeýär we ony janlaşdyryp bilmeýär. Existen birleşik girdi-etiket metin nusgalary etiket deskriplerini ulanyp bu meseleleri üstüne geçirip bilmeýär emma olar karmaşık etiket baglaýyşlaryny yakalamak başarmaýarlar, hakyky parametrizaýarlar bar we olaryň gaýd edilmegi kän etiketlerde görünýän etiketleriň hasaplamasynda kän bir şekilde başarýarlar. Bu kagyzda, täze bir girdi etiket modelini öňki nusgalaryň üstünde döredilen nusgalary barlaýar we görkezilen etiketlerde etkinleşen täze bir nusga teklip edýäris. Bu nusga kontrol edilebilir kapasitet bilen birleşik gabdaly gaýd etmek üçin çizgi gabdaly gaýd etmek üçin birleşik gabdaly gaýd etmek üçin birleşik gabdaly gaýd etmek üçin birleşik gabdaly etiketlerdir. Biz nusgalary tam-resop we düşük-ýa-da 0-resop metin klasifikasynda çykýarys Biziň nusgamyz hem dilli hem köp dilli nusgalary çykarýar.', 'af': "Nurale teks klasifikasie modele tipies behandel uitset etikette as kategoriese veranderlikes wat ontbreek beskrywing en semantieke. Hierdie verkrag hulle parametrisasie om afhanklik te wees van die etiket stel grootte, en daarom, hulle is nie moontlik na skaal na groot etiket stel en generelliseer na onversekende. Bestaande joint invoer- label teks modelle oorwin hierdie probleme deur die uitbreiding van etiket beskrywings, maar hulle is nie moontlik om kompleks etiket verhoudings te vang, het rigte parametrisasie, en hulle verskaffings op ongesiende etikette gebeur dikwels op die koste van swak prestasie op die etikette gesien tydens onderriging. In hierdie papier, voorstel ons 'n nuwe invoer- etiket model wat generaliseer oor vorige sodanige modele, adresse hul beperkings, en nie kompromiseer prestasie op gesien etikette nie. Die model bestaan van 'n gemeenskap onlineêre invoer-etiket inbêer met kontroleer kapasiteit en 'n gemeenskap-spasie-afhanklike klasifikasie eenheid wat onderwerp word met kruis-entropie verlies om klasifikasie-prestasie te optimaliseer. Ons evalueer modele op volle- hulpbron en lae- of nul- hulpbron teks klasifikasie van multitaalske nuus en biomediese teks met 'n groot etiket stel. Ons model uitvoer monotale en multitaalse modele wat nie etiket semantiek en vorige joint invoer-etiket spasiemodele in beide scenarios verwyder nie.", 'ko': '신경 텍스트 분류 모델은 일반적으로 출력 라벨을 설명과 의미가 부족한 분류 변수로 본다.이 때문에 매개 변수화는 탭 집합의 크기에 의존하기 때문에 대형 탭 집합으로 확장할 수도 없고, 보이지 않는 탭 집합으로 확대할 수도 없다.기존의 연합 입력 라벨 텍스트 모델은 라벨 묘사를 이용하여 이러한 문제점을 극복했지만 복잡한 라벨 관계를 포착하지 못하고 엄격한 매개 변수화를 가지며 보이지 않는 라벨에 대한 수익은 훈련 기간에 보이는 라벨에 좋지 않은 것을 대가로 한다.본고에서 우리는 새로운 입력 라벨 모델을 제시했다. 이 모델은 이전의 입력 라벨 모델을 보급하고 그들의 한계를 해결했으며 SEED 라벨의 성능에 영향을 주지 않았다.이 모델은 용량을 제어할 수 있는 비선형 연합 입력 라벨 삽입과 공간과 관련된 연합 분류 단원으로 구성되어 있으며 이 단원은 교차 엔트로피 손실을 통해 분류 성능을 최적화하기 위해 훈련을 실시한다.우리는 큰 라벨집을 가진 다국어 뉴스와 생물의학 텍스트의 전체 자원과 낮은 자원 또는 제로 자원 텍스트 분류 모델을 평가했다.이 두 가지 상황에서 우리의 모델은 모두 라벨의 의미를 이용하지 않고 이전의 연합 입력 라벨 공간 모델의 단일 언어와 다중 언어 모델보다 우수하다.', 'sw': 'Mfano wa usambazaji wa maandishi ya kijasiri mara nyingi hutumia alama za utoaji kama mabadiliko ya kigezo ambazo hazina maelezo na semantika. Hii inawalazimisha ubaguzi wao kutegemea ukubwa wa alama, na kwa hiyo, hawana uwezo wa kuelekea kwenye seti kubwa za alama na kuzuia vifaa vinavyofichikana. Mradi wa maandishi ya viungo vya pamoja unashinda suala hili kwa kutumia maelezo ya alama, lakini hawana uwezo wa kukabiliana na mahusiano magumu, wanachambua vibaya, na mafanikio yao kwenye mabango yasiyofahamika mara nyingi yanatokea kwa gharama kubwa ya utendaji wa mabango yanayoonekana wakati wa mafunzo. Katika karatasi hii, tunapendekeza modeli mpya ya input inayotengeneza zaidi ya mifano kama ilivyopita, hujadili vizuizi vyao, na haijapunguza utendaji wa tabia zilizotazama. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance.  Tunatathmini mifano ya rasilimali kamili na usambazaji wa maandishi yenye rasilimali ya chini au sifuri ya habari za lugha mbalimbali na ujumbe wa kitabibu kwa seti kubwa. Mfano wetu unaonyesha mifano ya lugha na lugha mbalimbali ambazo hazina mifano ya kiungo na mifano ya anga za kwanza za katika maeneo yote.', 'az': 'Nöral metin klasifikasiya modelləri genellikle çıxış etiketlərini tanımlamaq və semantik olmayan kategorikalı dəyişikliklər kimi təhrif edirlər. Bu onların parametrizaqlarını etiket təyin edilmiş böyüklüyündən bağlı olmağa məcbur edir. Buna görə də onlar böyük etiket qurularına dəyişə bilməzlər və görmədikləri etiket qurularına genel dəyişə bilməzlər. Müxtəlif girdi etiketli mətn modelleri etiketli tərzlərini istifadə edərək bu məsələləri üstün edir, amma onlar kompleks etiketli ilişkiləri yakala bilməzlər, qüvvətli parametrizaqları var, və görünməyən etiketlərdə onların qazanışları çox dəfə təhsil etdikdə görünən etiketlərdə zəif performans hesabında olur. Bu kağızda, əvvəlki modellərdə generalizasyon edən yeni girdi etiketli modeli təklif edirik, onların sınırlarını təklif edir və görünülmüş etiketlərdə performansını təklif etməz. Model kontrol edilebilir qabiliyyəti ilə birləşdirilmiş çizgi girdi etiketi və birləşdirilmiş kosmos-bağlı klasifikasiya birimi ilə birləşdirilmiş çoxlu entropi kaybı ilə təhsil edilmiş klasifikasiya performansını optimizləmək üçün təhsil edilən bir nöqtədir. Biz çoxlu dil xəbərlərin və biomedicin mətnlərin tamamlanması və düşük-ya-sıfır-ressurs mətnlərin klasifikasiyasını çəkirik. Bizim modellərimiz hər iki scenarioda etiketli semantik və əvvəlki istifadə etiketi kosmosu modellərini istifadə etməyən monodil və çoxlu dil modellərini göstərir.', 'sq': 'Modelet e klasifikimit të tekstit nervor tipikisht trajtojnë etiketat e daljes si ndryshuesit kategorikë që mungon përshkrimi dhe semantikë. Kjo detyron parametrizimin e tyre të varet nga madhësia e caktuar e etiketës, dhe kështu, ata nuk janë në gjendje të shkallojnë në set të mëdha të etiketës dhe të gjeneralizojnë në të padukshmet. Modelet ekzistuese të përbashkëta të tekstit të etiketave të hyrjes i kapërcejnë këto çështje duke shfrytëzuar përshkrimet e etiketave, por ato nuk janë në gjendje të kapin marrëdhënie komplekse të etiketave, kanë parametrizim të ashpër dhe fitimet e tyre në etiketat e padukshme ndodhin shpesh në dëm të performancës së dobët në etiketat e parë gjatë trajnimit. Në këtë letër, ne propozojmë një model të ri të etiketës së hyrjes që gjeneralizohet mbi modelet e mëparshëm të tilla, trajton kufizimet e tyre dhe nuk kompromiton performancën në etiketat e parë. Modeli përbëhet nga një etiketë e përbashkët jo-lineare të hyrjes me kapacitet të kontrollueshëm dhe një njësi klasifikimi të përbashkët-të varur nga hapësira që është trajnuar me humbje ndër-entropi për të optimizuar performancën e klasifikimit. We evaluate models on full-resource and low- or zero-resource text classification of multilingual news and biomedical text with a large label set.  Modeli ynë paraqet modelet monogjuhësore dhe shumëgjuhësore që nuk përdorin etiketën semantike dhe modelet e mëparshme të përbashkëta të hyrjes-etiketës hapësirore në të dy skenarët.', 'am': 'የኩነቶች የጽሑፍ መክፈቻ ሞዴሎች በተለየ የውጤት ምልክቶችን እንደ ክፍተር መለያየት እና መግለጫ የላቸውም ይህ የፋይል ምርጫዎች በlabel መጠን ላይ እንዲታመሙ ይችላል፡፡ የአሁኑ የበይነመረብ-የጽሑፍ ምሳሌዎች እነዚህ ጉዳዮችን በመጠቀም የበረራ ጽሑፎችን አሸንፋሉ፥ ነገር ግን በተጨማሪው የጽሑፍ ግንኙነት መያዝ አይችሉም፣ ጥሩ ማረፊያ አለባቸው፡፡ በዚህ ፕሮግራም፣ የቀድሞው እንደዚህ ዓይነቶች በተለየ አዲስ የinput-label model እናሳልጋለን፣ የግንኙነታቸውን አድራጊ እናደርጋለን፡፡ The model consists of a joint nonlinear input-label containing control capability and a joint-space-dependent classification unit that is trained by cross-entropy loss to optimize classification performance. በሙሉ resource እና በ0-resource ጽሑፍ ጽሑፍ ክፍተቶችን በብዙ ቋንቋዎች ዜና እና የbiomedical ጽሑፍ በታላቅ label እናስመስክራለን፡፡ ሞዴሌያችን በሁለቱ ስናናይኖች ውስጥ የደረጃ ማህበረሰብ እና የብዙ ቋንቋዎች ዓይነቶችን የሚያደርጉ ናቸው፡፡', 'bs': 'Modeli klasifikacije neuronskog teksta obično tretiraju etikete izlaza kao kategorijske varijante koje nedostaju opis i semantike. To primorava njihovu parametrizaciju da zavise od veličine postavljene etikete, i zato oni ne mogu skalirati na velike sete etikete i generalizirati na nevidljive. Postoje zajednički modeli teksta oznake za ulazak prevladaju te probleme iskorištavanjem opisa oznake, ali nisu u mogućnosti da uhvate kompleksne odnose oznake, imaju krute parametrizacije, a njihovi dobiti na nevidljivim etiketama se često dešavaju na troškovi slabe učinke na etiketama viđenim tijekom obuke. U ovom papiru predlažemo novi model ulaznog etiketa koji generalizuje preko prethodnih takvih model a, adresuje njihove ograničenja i ne kompromisuje učinkovitost na viđenim etiketama. Model se sastoji od zajedničkog nelinearnog ulaznog etiketa ugrađenog sa kontrolnom kapacitetom i zajedničkom klasifikacijskom jedinicom ovisnom o svemiru koja je obučena s gubitkom prekretropije kako bi optimizirala klasifikaciju. Procjenjujemo modele o klasifikaciji teksta punog resursa i niskog ili nulog resursa multijezičkih vijesti i biomedicinskog teksta sa velikim namještajem etiketa. Naš model iznosi monojezičke i multijezičke modele koji ne utiču na etikete semantike i prethodne zajedničke svemirske modele za ulazak u obje scenarije.', 'hy': 'Neural text classification models typically treat output labels as categorical variables that lack description and semantics.  Սա ստիպում է նրանց պարամետրիզացիան կախված լինել պիտակի սահմանափակումների չափից, և դրանք չեն կարողանում մեծացնել մեծ պիտակի սահմանափակումների և ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ըն Գոյություն ունի միասին ներմուծման-պիտակի տեքստի մոդելներ, որոնք հաղթահարում են այս խնդիրները օգտագործելով պիտակի նկարագրությունները, բայց նրանք չեն կարողանում պատկերացնել բարդ պիտակի հարաբերությունները, ունեն խիստ պարամետրիզացիա, և դրանց շահույթը անտեսանելի պիտակների վրա հաճախ տեղի Այս թղթի մեջ մենք առաջարկում ենք նոր մուտք-պիտակ մոդել, որը ընդհանրացնում է նախորդ մոդելների վերաբերյալ, վերաբերում է նրանց սահմանափակումներին և չի վնասում տեսանելի պիտակների արդյունքը: Մոդելը կազմված է միասին ոչ գծային մուտքագրման պիտակից, որը ներառված է կառավարելի հնարավորության հետ և միասին տարածության կախված դասակարգման միավորից, որը վարժեցվում է խաչը-էնտրոպիայի կորստով որպեսզի օպտիմացվի դասակար Մենք գնահատում ենք բազմալեզու նորությունների և կենսաբժշկական տեքստի ամբողջ ռեսուրսների և ցածր կամ զրոյից ռեսուրսների դասակարգումների մոդելները մեծ պիտակում: Մեր մոդելը արտադրում է միալեզու և բազլեզու մոդելներ, որոնք չեն օգտագործում սեմանտիկայի պիտակները և նախորդ միավոր մուտք-պիտակ տիեզերական մոդելները երկու սցենարներում:', 'cs': 'Neurální klasifikační modely textu obvykle považují výstupní štítky za kategorické proměnné, které postrádají popis a sémantiku. To nutí jejich parametrizaci záviset na velikosti sady štítků, a proto nejsou schopny škálovat na velké sady štítků a zobecnit na neviditelné. Stávající společné textové modely vstupu-štítku tyto problémy překonávají využitím popisů štítků, ale nejsou schopny zachytit složité vztahy štítků, mají pevnou parametrizaci a jejich zisky u neviditelných štítků docházejí často na úkor slabého výkonu štítků viděných během školení. V tomto článku navrhujeme nový model vstupních štítků, který generalizuje předchozí takové modely, řeší jejich omezení a neohrožuje výkon viděných štítků. Model se skládá ze společného nelineárního vložení vstupních štítků s kontrolovatelnou kapacitou a klasifikační jednotky závislé na spojovém prostoru, která je trénována se ztrátou křížové entropie pro optimalizaci klasifikačního výkonu. Hodnotíme modely pro klasifikaci vícejazyčných zpráv a biomedicínského textu s velkou sadou etiket. Náš model překonává monojazyčné a vícejazyčné modely, které nevyužívají sémantiku štítků a předchozí společné modely vstupu-štítků prostoru v obou scénářích.', 'et': 'Närviteksti klassifitseerimise mudelid käsitlevad väljundsilte tavaliselt kategoorialiste muutujatena, millel puudub kirjeldus ja semantika. See sunnib nende parametriseerimist sõltuma sildikomplekti suurusest ja seetõttu ei saa nad suurte sildikomplektideni skaleerida ja üldistada nähtamatuteks. Olemasolevad ühised sisend-sildi tekstimudelid lahendavad need probleemid sildi kirjelduste kasutamisega, kuid nad ei suuda jäädvustada keerulisi sildi seoseid, neil on jäik parametreerimine ja nende kasu nähtamatute sildide kasutamisel toimub sageli koolituse käigus nähtud sildide nõrga jõudluse arvelt. Käesolevas töös pakume välja uue sisendmärgise mudeli, mis üldistab varasemaid selliseid mudeleid, käsitleb nende piiranguid ja ei ohusta nähtud märgiste jõudlust. Mudel koosneb juhitava võimsusega liigesest mittelineaarsest sisendmärgist ja liigesest-ruumist sõltuvast klassifikatsiooniüksusest, mis on koolitatud ristentroopiakao optimeerimiseks klassifitseerimisjõudluse optimeerimiseks. Hindame mitmekeelsete uudiste ja biomeditsiiniliste tekstide täisressurssiga ja vähese või nulliressurssiga klassifitseerimise mudeleid suure märgistuskomplektiga. Meie mudel ületab ühe- ja mitmekeelseid mudeleid, mis ei kasuta sildi semantikat ega varasemaid ühiseid sisend-sildi ruumimudeleid mõlemas stsenaariumis.', 'fi': 'Neurotekstiluokitusmallit käsittelevät tulosmerkintöjä tyypillisesti kategorisina muuttujina, joilla ei ole kuvausta ja semantiikkaa. Tämä pakottaa niiden parametrisoinnin riippumaan etikettijoukon koosta, joten ne eivät pysty skaalaamaan suuriin etikettiryhmiin ja yleistymään näkymättömiin. Nykyiset yhteiset syöttö- ja tarratekstimallit voittavat nämä ongelmat hyödyntämällä tarrakuvauksia, mutta ne eivät kykene kuvaamaan monimutkaisia tarrasuhteita, niiden parametrisointi on jäykkä, ja niiden voitot näkymättömistä etiketeistä tapahtuvat usein koulutuksen aikana havaittujen etikettien heikon suorituskyvyn kustannuksella. Tässä työssä ehdotamme uutta input-label -mallia, joka yleistyy aikaisempiin malleihin verrattuna, käsittelee niiden rajoituksia eikä vaaranna näytettyjen labelien suorituskykyä. Malli koostuu yhdistetystä epälineaarisesta syöttöetiketistä, jolla on hallittavissa oleva kapasiteetti, sekä liitos-avaruudesta riippuvasta luokitusyksiköstä, joka on koulutettu ristientropiahäviöllä luokittelun optimoimiseksi. Arvioimme monikielisten uutisten ja biolääketieteellisten tekstien täysressurssien ja vähäresurssisten tekstien luokittelumalleja suurella etikettisarjalla. Mallimme toimii paremmin kuin yksikieliset ja monikieliset mallit, jotka eivät hyödynnä etiketin semantiikkaa ja aiempia yhteisiä syöte-etiketti-tilamalleja molemmissa skenaarioissa.', 'bn': 'নিউরেল টেক্সট ক্লাস্ফিকেশন মডেল সাধারণত আউটপুট লেবেল বিভাগের বিভাগ হিসেবে ব্যবহার করুন, যা বর্ণনা এবং সেমেন এটি তাদের প্যারামিটারিজেশন লেবেল সেটের আকারের উপর নির্ভর করতে বাধ্য করে, আর এর ফলে তারা বিশাল ল লেবেলেট সেটের দিকে আকারে যাত্রা করতে  বিদ্যমান যুক্ত ইনপুট-লেবেলের টেক্সট মডেল লেবেল বিবরণ ব্যবহারের মাধ্যমে এই বিষয়গুলোকে বিজয়ী করেছে, কিন্তু তারা কমপ্লেক্স লেবেলেটের সম্পর্ক গ্রহণ করতে পারে না, তাদের প এই কাগজটিতে আমরা একটি নতুন ইনপুট-লেবেল মডেল প্রস্তাব করি যা পূর্বের এই মডেলের উপর জেনারেল করে, তাদের সীমাবদ্ধতা ঠিকানা করে এবং তাদের লেব মোডেলের মধ্যে একটি যৌথ অলাইনিয়ার ইনপুট- লেবেলের মধ্যে রয়েছে যা নিয়ন্ত্রণের ক্ষমতা এবং একটি যৌথ-স্পেস-নির্ভরিত ক্লাস্ফিকেশন ইউনিট যা ক্লাসাফিকেশনের আমরা পুরোপুরি সম্পদ এবং নিম্নলিখিত কিংবা শুধুমাত্র বিশাল লেবেলেটের সংবাদ এবং বায়োমেডিকেল টেক্সটের মূল্যায়ন করি। আমাদের মডেল মোনোলিভাল এবং বহুভাষায় মডেল প্রদর্শন করে যারা দুটো সিনেম্যান্টিক এবং পূর্ববর্তী যোগাযোগ ইনপুট-লেবেল স্থানের', 'ca': "Neural text classification models typically treat output labels as categorical variables that lack description and semantics.  Això obliga la seva parametrització a dependre de la mida del conjunt d'etiquetes, i, per tant, no són capaços d'escalar a grans conjunts d'etiquetes i generalitzar-se a aquells invisibles. Els models de text conjunts d'etiquetes d'entrada superen aquests problemes explotant descripcions d'etiquetes, però no són capaços de capturar relacions complexes d'etiquetes, tenen parametrització rígida, i els seus guanys en etiquetes invisibles aconsegueixen sovint a càrrega del frac rendiment de les etiquetes vistes durant l'entrenament. En aquest paper, proposem un nou model d'etiqueta d'entrada que s'generalitza sobre els models anteriors, aborda les seves limitacions i no compromet el rendiment de les etiquetes vistes. El model consisteix en una etiqueta d'entrada no linear conjunta incorporada amb capacitat controlable i una unitat de classificació dependent de l'espai conjunt que està entrenada amb pèrdua de transentropia per optimitzar el rendiment de la classificació. Evaluam models de classificació de text amb recursos complets i amb recursos baixos o zero de notícies multilingües i text biomèdic amb un gran conjunt d'etiquetes. El nostre model supera els models monolingües i multilingües que no utilitzen l'etiqueta semàntica i els models espacials anteriors d'entrada conjunta en ambdós escenaris.", 'ha': "@ label: listbox Wannan na ƙara parameteriyarsu don a ƙayyade girmar label, kuma bã zã su iya iya fito zuwa matsayin ayuka babba, kuma su samu gaɓõya masu ɓõya. @ label: listbox In this paper, we propose a new input-label model that generalizes over previous such models, addresses their limitations, and does not compromise performance on seen labels.  @ info: whatsthis Tuna ƙaddara misãlai kan fasalin matsayin cikakken resource da kasa- ko-nufi, wa'anar lãbãri na mulki-mulki da littãfin da aka daidaita wani label mai girma. MisalinMu na samar da misãlai masu motsi na monoli da mulki-lingui, waɗanda bã su samar wa label semantiki kuma misãlai na farko da ke cikin cikin tsari biyu.", 'he': 'דוגמנים מסווג טקסט נוירוני בדרך כלל מתייחסים לתוויות יציאה כמשתנים קטגוריים שאין להם תיאור וסמנטיקה. זה מכריח את הפרמטריזציה שלהם להיות תלוי בגודל התווית, ולכן, הם לא מסוגלים להגדיל לתוויות גדולות ולהגדיל לתוויות בלתי נראות. מודלים טקסטים משותפים קיומים של תווית כניסה מתגברים על הנושאים האלה על ידי ניצל תיאורים של תוויות, אבל הם לא יכולים לתפוס מערכות יחסים מסובכות של תוויות, יש פרמטריזציה קשה, והרווחות שלהם על תוויות בלתי נראות קורות לעתים קרובות על חשבון ביצועים חלשים על תוויות שנראות בעיתון הזה, אנו מציעים מודל חדש של תווית כניסה שמתפתח על מודלים כאלה קודמים, מתייחס למגבלותיהם, ולא מפחיד ביצועים על תוויות ראויות. המודל כולל תווית כניסה לא לינרית משותפת עם יכולת שליטה ויחידת קליפורניה משותפת-תלויה בחלל שאומנת עם אובדן אנטרופיה צלב כדי לאופטיזם ביצועי קליפורניה. אנו מעריכים מודלים על מסווג טקסט מלא משאבים נמוכים או אפס של חדשות רבות שפות וטקסט ביומדיקלי עם תווית גדולה. המודל שלנו מוביל מודלים מונושפות ומרבות שפות שלא משתמשים בתווית סמנטיקה ומודלים חלליים משותפים קודמים בשני התקרים.', 'sk': 'Modeli razvrščanja živčnih besedil običajno obravnavajo izhodne oznake kot kategorične spremenljivke, ki nimajo opisa in semantike. To prisili, da je njihova parametrizacija odvisna od velikosti nabora oznak, zato jih ni mogoče razširiti na velike nabore oznak in posplošiti na nevidne. Obstoječi skupni vhodni besedilni modeli premagajo te težave z izkoriščanjem opisov oznak, vendar pa ne morejo zajeti kompleksnih odnosov oznak, imajo togo parametrizacijo, njihove koristi pri nevidnih oznakah pa se pogosto zgodijo na račun slabe zmogljivosti oznak, opaženih med usposabljanjem. V prispevku predlagamo nov model vhodne oznake, ki se posploši nad prejšnjimi modeli, obravnava njihove omejitve in ne ogroža zmogljivosti na videnih oznakah. Model je sestavljen iz skupne nelinearne vhodne oznake s krmilljivo zmogljivostjo in skupno-prostorsko odvisne klasifikacijske enote, ki je usposobljena z izgubo navzkrižne entropije za optimizacijo klasifikacijske učinkovitosti. Z velikim naborom oznak ocenjujemo modele za klasifikacijo besedila s polnimi viri in nizkimi ali ničelnimi viri večjezičnih novic in biomedicinskih besedil. Naš model presega enojezične in večjezične modele, ki v obeh scenarijih ne izkoriščajo semantike oznak in prejšnjih skupnih modelov prostora vhodnih oznak.', 'jv': 'email-custom-header-Security First letter Joint input-label text model label Genjer Awak dhéwé éntuk model ning komplit-recurs lan basa-perusahaan kelas-perusahaan seneng basa multilanggar lan seneng biasak bantuan kanggo nambah label sing gak dhéwé. modelo sing wis nambah, dadine languangkat lan akeh multilenguang modelo sing ora nggawe etiket sematik lan banjure nggawe modelo input-label space nang saboh sanes.', 'bo': 'Neural text classification models typically treat output labels as categorical variables that lack description and semantics. This forces their parametrization to be dependent on the label set size, and, hence, they are unable to scale to large label sets and generalize to unseen ones. Existing joint input-label text models overcome these issues by exploiting label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels happen often at the expense of weak performance on the labels seen during training. In this paper, we propose a new input-label model that generalizes over previous such models, addresses their limitations, and does not compromise performance on seen labels. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. ང་ཚོས་རྣམ་པ་མང་པོ་དང་མཐོ་རྣམ་པ་མང་པོ་ཞིག་ཡོད་པའི་མིག་གཟུགས་རིས་མང་པོ་ཞིག་དང་། རྣམ་པ་མིག་གཟུགས་རིས Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.'}
{'en': 'Autosegmental Input Strictly Local Functions', 'ar': 'المدخلات القطاعية الوظائف المحلية بدقة', 'es': 'Funciones estrictamente locales de entrada autosegmental', 'pt': 'Funções estritamente locais de entrada segmentada', 'fr': "Fonctions strictement locales d'entrée autosegmentaire", 'zh': '自分段输严本函数', 'ja': 'オートセグメンタル入力は厳密にローカル関数です', 'ru': 'Автосегментарный ввод строго локальных функций', 'hi': 'स्वत: खंड यी इनपुट कड़ाई से स्थानीय कार्य', 'ga': 'Ionchur Autodeighilteach Feidhmeanna go docht Áitiúil', 'el': 'Αυτόματη εισαγωγή αυστηρά τοπικών λειτουργιών', 'hu': 'Automatikus szegmentális bemenet szigorúan helyi függvények', 'ka': 'Comment', 'it': 'Input autosegmentale Funzioni strettamente locali', 'kk': 'Авто сегменталдық келтірілген жергілікті функциялары', 'lt': 'Autosegmentalinis įvestis', 'mk': 'Автозементален внес строго локални функции', 'ms': 'Comment', 'ml': 'പ്രാദേശിക ഫങ്ഷനുകള്\u200d', 'mt': 'Funzjonijiet Struttament Lokali ta’ Input Awtosegmentali', 'mn': 'Автометр орнуудын орнуудын функцүүд', 'no': 'Comment', 'ro': 'Funcții de intrare automată strict locale', 'sr': 'Autosegmentalni ulaz strogo lokalne funkcije', 'pl': 'Autosegmentalne wejście wyłącznie lokalne funkcje', 'si': 'Comment', 'so': 'Isticmaalka dhimiska', 'ta': 'Autosegmental Input Strictly Local Functions', 'sv': 'Automatisk inmatning strikt lokala funktioner', 'ur': 'Comment', 'uz': 'Comment', 'vi': 'Nhập tự động Hàm cục bộ', 'da': 'Autosegmental input strengt lokale funktioner', 'bg': 'Автосегментален вход стриктно локални функции', 'hr': 'Autosegmentalni ulaz strogo lokalne funkcije', 'nl': 'Autosegmentale invoer strikt lokale functies', 'id': 'Autosegmental Input Tepat Fungsi Lokal', 'de': 'Autosegmentale Eingabe ausschließlich lokaler Funktionen', 'ko': '자동 세그먼트 입력 엄격한 국부 함수', 'sw': 'Functions', 'tr': 'Otomatik Gaýd Etmek Editçi', 'af': 'Outomatiese Invoer Strikte Plaaslike Funksies', 'am': 'ምርጫዎች', 'fa': 'Comment', 'hy': 'Autosegmental Input Strictly Local Functions', 'bn': 'স্বয়ংক্রিয়ভাবে ইনপুট স্থানীয় ফাংশন', 'bs': 'Autosegmentalni ulaz strogo lokalne funkcije', 'ca': 'Entrada autosegmental Funcions estrictament locals', 'sq': 'Funksionet lokale të hyrjes automatike', 'az': 'Avtomatik Seqmental Girdi Sətraflı Yerli Funksiyalar', 'cs': 'Autosegmentální vstup přísně lokální funkce', 'et': 'Automaatne sisend rangelt kohalikud funktsioonid', 'fi': 'Automaattinen syöttö tiukasti paikalliset toiminnot', 'jv': 'structural navigation', 'ha': '@ action', 'sk': 'Samosegmentalni vnos strogo lokalne funkcije', 'he': 'הפונקציות המקומיות באוטוסגמליות', 'bo': 'རང་འགུལ་གྱིས་སྦྱར་ཡོད་པའི་འཇུག་སྣོད་ཀྱིས་རང་ཁུལ་གྱི་ལས་འགན'}
{'en': 'Autosegmental representations (ARs ; Goldsmith, 1976) are claimed to enable local analyses of otherwise non-local phenomena Odden (1994). Focusing on the domain of tone, we investigate this ability of ARs using a computationally well-defined notion of locality extended from Chandlee (2014). The result is a more nuanced understanding of the way in which ARs interact with phonological locality.', 'pt': 'Representações autossegmentais (ARs; Goldsmith, 1976) são reivindicadas para permitir análises locais de fenômenos não locais Odden (1994). Com foco no domínio do tom, investigamos essa habilidade dos ARs usando uma noção computacionalmente bem definida de localidade estendida de Chandlee (2014). O resultado é uma compreensão mais sutil da maneira pela qual os RAs interagem com a localidade fonológica.', 'ar': 'يُزعم أن التمثيلات القطاعية الذاتية (ARs ؛ Goldsmith ، 1976) تتيح التحليلات المحلية للظواهر غير المحلية أودين (1994). مع التركيز على مجال النغمة ، نقوم بالتحقيق في قدرة ARs باستخدام مفهوم حسابي محدد جيدًا للموقع الممتد من Chandlee (2014). والنتيجة هي فهم أكثر دقة للطريقة التي تتفاعل بها AR مع الموقع الصوتي.', 'fr': "Les représentations autosegmentaires (AR\xa0; Goldsmith, 1976) sont censées permettre des analyses locales de phénomènes autrement non locaux Odden (1994). En nous concentrant sur le domaine du ton, nous étudions cette capacité des RA à l'aide d'une notion de localité bien définie sur le plan informatique, développée à partir de Chandlee (2014). Le résultat est une compréhension plus nuancée de la façon dont les RA interagissent avec la localité phonologique.", 'es': 'Se afirma que las representaciones autosegmentarias (ARs; Goldsmith, 1976) permiten el análisis local de fenómenos que de otro modo no serían locales Odden (1994). Centrándonos en el dominio del tono, investigamos esta capacidad de los RA utilizando una noción computacionalmente bien definida de localidad extendida desde Chandlee (2014). El resultado es una comprensión más matizada de la forma en que los AR interactúan con la localidad fonológica.', 'hi': 'स्वत: खंडीय अभ्यावेदन (एआर; गोल्डस्मिथ, 1976) को अन्यथा गैर-स्थानीय घटनाओं के स्थानीय विश्लेषण को सक्षम करने का दावा किया जाता है ओडेन (1994)। टोन के डोमेन पर ध्यान केंद्रित करते हुए, हम चांडली (2014) से विस्तारित इलाके की कम्प्यूटेशनल रूप से अच्छी तरह से परिभाषित धारणा का उपयोग करके एआर की इस क्षमता की जांच करते हैं। परिणाम जिस तरह से एआर ध्वन्यात्मक इलाके के साथ बातचीत करते हैं, उसकी अधिक सूक्ष्म समझ है।', 'ja': 'オートセグメンタル表現（ Ａ Ｒ ；ゴールドスミス、１ ９ ７ ６ ）は、そうでなければ非局所的な現象の局所的な分析を可能にするように主張されている（ Ｏｄｄｅｎ ， １ ９ ９ ４ ）。トーンの領域に焦点を当てて、私たちは、Chandlee （ 2014 ）から拡張された局所性の計算的に十分に定義された概念を使用して、ARのこの能力を調査します。その結果、ARが音声学的な局所性と相互作用する方法をより微妙に理解することになる。', 'zh': '自分段 (AR; Goldsmith,1976)称能析Odden(1994)。 注于音调之域,吾以Chandlee(2014)广之数明义局部性名以究AR之能。 AR与语音局部性相得更精微。', 'ru': 'Утверждается, что автосегментарные представления (ARs; Goldsmith, 1976) позволяют проводить локальные анализы нелокальных явлений, в противном случае не являющихся локальными явлениями (1994). Сосредоточившись на области тона, мы исследуем эту способность AR, используя вычислительно четко определенное понятие локальности, расширенное из Chandlee (2014). В результате получается более нюансированное понимание того, как АПВ взаимодействуют с фонологической локальностью.', 'ga': 'Maítear go bhféadfaí anailísí áitiúla a dhéanamh ar fheiniméin neamh-áitiúla eile Odden (1994). Agus muid ag díriú ar an réimse ton, déanaimid imscrúdú ar an gcumas seo atá ag ARanna ag baint úsáide as nóisean de cheantar atá sainithe go maith ó thaobh ríomha de ó Chandlee (2014). Is é an toradh atá air ná tuiscint níos nua-aimseartha ar an mbealach a idirghníomhaíonn TÉ leis an gceantar fóineolaíoch.', 'ka': 'ავტოჟეგენტალური გამოსახულებები (ARS; Goldsmith, 1976) იქნება, რომ ადგილური ანალიზების შესაძლებლობა სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა ფენომე ჩვენ ვაკეთებთ ARS-ის შესაძლებლობას, რომელიც ფანელედან გაფარდებული ლოკალურობის კომპუტაციალურად განსაზღვრებულია. პროცექტი არის უფრო მუშაობელი განსხვავება, როგორც ARS კონტოლოგიური ლოკალურობის შესახებ.', 'el': 'Οι αυτοτμηματικές αναπαραστάσεις (ARs; Goldsmith, 1976) ισχυρίζονται ότι επιτρέπουν τοπικές αναλύσεις άλλων μη τοπικών φαινομένων Odden (1994). Εστιάζοντας στον τομέα του τόνου, διερευνούμε αυτή την ικανότητα των ARs χρησιμοποιώντας μια υπολογιστικά καλά καθορισμένη έννοια της τοποθεσίας που επεκτάθηκε από το Τσάντλι (2014). Το αποτέλεσμα είναι μια πιο διαφοροποιημένη κατανόηση του τρόπου με τον οποίο αλληλεπιδρούν οι ΑΡ με τη φωνολογική τοποθεσία.', 'hu': 'Az önszegmentális reprezentációk (ARs; Goldsmith, 1976) azt állítják, hogy lehetővé teszik az egyébként nem helyi jelenségek helyi elemzését Odden (1994). A hang tartományára összpontosítva az AR képességét egy Chandlee-től (2014) kiterjesztett számítástechnikailag jól meghatározott lokalitási fogalommal vizsgáljuk. Az eredmény egy árnyaltabb megértést jelent arról, hogy az AR-k miként kölcsönhatnak a fonológiai helyszínekkel.', 'it': 'Le rappresentazioni autosegmentali (ARs; Goldsmith, 1976) sono state rivendicate per consentire analisi locali di fenomeni altrimenti non locali Odden (1994). Concentrandoci sul dominio del tono, esaminiamo questa capacità degli AR utilizzando una nozione computazionale ben definita di località estesa da Chandlee (2014). Il risultato è una comprensione più sfumata del modo in cui gli AR interagiscono con la località fonologica.', 'kk': 'Авто сегменталдық таңбалары (ARs; Goldsmith, 1976) Оден (1994) жергілікті емес жергілікті таңбаларының анализацияларын рұқсат етеді. Тундың доменіне көңіл беру үшін, АРС-тың бұл мүмкіндігін Чандле (2014 жылы) дегеннен кеңейтілген жергіліктерінің есептеу жақсы анықталған ойымызды қолданып зерттейміз. Нәтижесі - ARS фонологиялық жергіліктерімен қатынас арқылы көмектесетін түсінікті.', 'lt': 'Teigiama, kad autosegmentinės nuorodos (ARs; Goldsmith, 1976 m.) leidžia atlikti vietinę analizę kitokių ne vietos reiškinių Odden (1994 m.). Fokusuojant į tono sritį, mes tiriame šį AR gebėjimą naudojant skaičiavimu gerai apibrėžtą vietovės sąvoką, išplėstą nuo Čandelio (2014 m.). Rezultatas yra nuodugniau suprantamas, kaip ARs sąveikauja su fonologine vietove.', 'mk': 'Автозементалните претставувања (АР; Голдсмит, 1976) се тврдат дека овозможуваат локални анализи на инаку нелокалните феномени Оден (1994). Со фокус на доменот на тонот, ја истражуваме способноста на АР користејќи компјутационално добро дефинирана идеја за локалитет продолжена од Чендли (2014). Резултатот е понианцирано разбирање на начинот на кој АР влијаат со фонолокалната локалитет.', 'ms': 'Autosegmental representations (ARs; Goldsmith, 1976) are claimed to enable local analyses of otherwise non-local phenomena Odden (1994).  Focusing on the domain of tone, we investigate this ability of ARs using a computationally well-defined notion of locality extended from Chandlee (2014).  Hasilnya adalah pemahaman yang lebih berwarna-warna tentang cara ARs berinteraksi dengan lokasi fonologi.', 'ml': 'ഓട്ടോസെഗ്മെന്\u200dറ് പ്രതിനിധികള്\u200d (ARs; ഗോള്\u200dഡ്മിത്ത്, 1976) അല്ലെങ്കില്\u200d ലോക്കല്\u200d സ്ഥാനമില്ലാത്ത പ്രാദേശികമായ വിഭവങ്ങള്\u200d ഓഡന്\u200d  ടോണിന്റെ ഡോമെയിനില്\u200d ശ്രദ്ധിക്കുന്നു, ഞങ്ങള്\u200d ആര്\u200dസിന്റെ കഴിവിനെ പരിശോധിക്കുന്നു. ചാന്\u200dഡെലില്\u200d നിന്നും വിശാലമായ സ്ഥാനത്തില അതിന്റെ ഫലമാണ് ARs ഫോളോളജിക്കല്\u200d സ്ഥാനത്തോടൊപ്പം ബന്ധപ്പെടുന്ന വഴിയെക്കുറിച്ച് കൂടുതല്\u200d വിവേകമുള്ള', 'mt': 'Ir-rappreżentazzjonijiet awtosegrammali (ARs; Goldsmith, 1976) huma ddikjarati li jippermettu analiżi lokali ta’ fenomeni mhux lokali inkella Odden (1994). Filwaqt li niffokaw fuq id-dominju tat-ton, ninvestigaw din il-kapaċità ta’ ARs bl-użu ta’ kunċett ta’ lokalità ddefinit b’mod komputattiv tajjeb estiż minn Chandlee (2014). Ir-riżultat huwa fehim aktar nuanċjat tal-mod kif l-ARs jinteraġixxu mal-lokalità fonoloġika.', 'mn': 'Автометрийн загварын үзүүлэлт (ARs; Goldsmith, 1976) нь орчин нутгийн үйл явдлыг Оден (1994) бусад орчин нутгийн үйл явдлын шинжилгээг боловсруулах боломжтой гэж үздэг. Үн дуу холбооны тухай бид АР-ын чадварыг 2014 онд Чандлейгээс өргөн газрын тодорхойлолтой ойлголтыг ашиглан судалж байна. Үүний үр дүнд АР-ын фонологикийн орон нутгийн харилцааны аргыг илүү ойлгох болно.', 'no': 'Automatiske representasjonar (ARs; Goldsmith, 1976) vert tvrd på å slå på lokale analyser av ulike ikkje-lokale fenomenar Odden (1994). Fokuserer vi på tonedomenet, så undersøker vi at ARS-kapasiteten kan brukast eit datamaskin godt definert noe om lokalitet utvida frå Chandlee (2014). Resultatet er ein mer nuanced forståelse av måten ARS saman med fonologisk lokalitet.', 'pl': 'Reprezentacje autosegmentalne (ARs; Goldsmith, 1976) są twierdzone, że umożliwiają lokalne analizy zjawisk innych niż lokalne Odden (1994). Koncentrując się na dziedzinie tonu, badamy tę zdolność ARów przy użyciu obliczeniowo dobrze zdefiniowanego pojęcia lokalności rozszerzonego od Chandlee (2014). Rezultatem jest bardziej niuansowane zrozumienie sposobu, w jaki ARy oddziałują z lokalizacją fonologiczną.', 'ro': 'Reprezentările autosegmentale (ARs; Goldsmith, 1976) sunt susținute pentru a permite analize locale ale fenomenelor altfel non-locale Odden (1994). Focalizându-ne pe domeniul tonului, investigăm această capacitate a ARs folosind o noțiune calculațional bine definită de localitate extinsă de la Chandlee (2014). Rezultatul este o înțelegere mai nuanțată a modului în care AR interacționează cu localitatea fonologică.', 'sr': 'Autosegmentalne predstave (ARs; Goldsmith, 1976) tvrde se da omogućavaju lokalne analize inače neolokalnih fenomena Odden (1994). Fokusirajući se na domenu tone, istražujemo ovu sposobnost ARs koristeći računalno dobro definiranu ideju lokalnosti proširenu iz Chandlee (2014). Rezultat je manje razumevanje način a na koji se ARS odnosi na fonološku lokaciju.', 'si': 'ස්වයංක්\u200dරීය විශ්ලේෂණය (ARs; Goldsmith, 1976) කියන්නේ ස්ථානික විශ්ලේෂණය සක්\u200dරීය කරන්න ස්ථානික විශ්ලේෂණය සක්\u200dරීය කරන චැන්ඩල් වලින් ස්ථානය සඳහා පරීක්ෂණය කරනවා, අපි පරීක්ෂණය කරන්නේ ARs මේ ක්\u200dරියාත්මක පරීක්ෂණය කරන්නේ. ප්\u200dරතිචාරයක් තමයි ආර්ස් පොනොලෝජික ස්ථානයෙන් සම්බන්ධ වෙන්න ප්\u200dරතිචාරයක්.', 'so': 'Autosegmental representations (ARs; Goldsmith, 1976) are claimed to enable sameyn kara baaritaanka deegaanka (1994). Goobta codka, waxaynu ka baaraynaa awooddan AR-yada, waxaynu isticmaalnaa fikrada aad u qoran ee degmada ka soo baxay Chandlee (2014). The result is a more nuanced understanding of the way in which ARs interact with phonological locality.', 'ta': 'தானியங்கி தொகுதி பிரதிநிதிகள் (ARs; Goldsmith, 1976) இல்லையென்றால் உள்ளூர் பொருள் இல்லாத விஷயங்களை இயக்குவதற்கு கூறுகிறது. தொனியின் களம் மீது கவனம் செலுத்துகிறது, நாம் இந்த ARs இயல்பைத் தேடுகிறோம், சான்டில் இருந்து விரிவாக்கப்பட்ட உள்ளூர்ந்த கருத்த முடிவு என்னவென்றால் ARs தொழில்நுட்பமான இடத்துடன் தொடர்பு கொள்ள வேண்டும்.', 'sv': 'Autosegmentala representationer (ARs; Goldsmith, 1976) hävdas möjliggöra lokala analyser av annars icke-lokala fenomen Odden (1994). Med fokus på tonens domän undersöker vi denna förmåga hos ARs med hjälp av en beräkningsmässigt väl definierad lokalitetsuppfattning utvidgad från Chandlee (2014). Resultatet är en mer nyanserad förståelse för hur AR interagerar med fonologisk lokalitet.', 'ur': 'اٹوٹوسگریٹ نمایش (ARS; Goldsmith, 1976) کو دوسری غیر محلی نمایش اوڈن (1994) کی محلی تحلیل کرنے کے لئے منظور کیا گیا ہے۔ ٹون کے ڈومینٹ پر Focus کیا جاتا ہے، ہم ARS کی اس قابلیت کی تحقیق کررہے ہیں جو Chandlee (2014) سے پھیلائی ہوئی محاسبات کے مطابق کامپیوتروں سے خوب واضح طور پر معلوم ہوتی ہے۔ نتیجہ یہ ہے کہ ARS اس طرح کے مطابق فانولوژیکی محل سے اضافہ کرتا ہے۔', 'uz': "Avto-segmental (ARs; Goldsmith, 1976) taʼminlovchilar qoʻllaniladi. Aks holda lokal munosabatlarni lokal tarjima qilish (1994). Tovush domen'ida fokuslash, biz AR'larning imkoniyatini qidirib, 2014 Chandlee (2014) tomonidan ajratilgan murakkab yaxshi fikrlar bilan o'rganamiz. natijasi ARs fonologi lokal mahalliy bilan bog'liqni o'rganishga ko'proq tushunish.", 'vi': 'Các biểu tượng chụp tự vệ (ARs; GoldSmith, 19Thank) được cho phép phân tích địa phương về các hiện tượng khác ngoài địa phương (1994). Tập trung vào lĩnh vực giọng điệu, chúng tôi điều tra khả năng của ARs sử dụng một khái niệm về địa điểm được tính xác định rộng ra từ Chandlee (thậm chí bây giờ). Kết quả là sự hiểu biết mơ hồ hơn về cách mà ARS tác động với địa điểm âm danh.', 'da': "Autosegmentale repræsentationer (ARs; Guldsmed, 1976) hævdes at muliggøre lokale analyser af ellers ikke-lokale fænomener Odden (1994). Med fokus på tonedomænet undersøger vi ARs'ernes evne ved hjælp af et beregningsmæssigt veldefineret begreb om lokalitet udvidet fra Chandlee (2014). Resultatet er en mere nuanceret forståelse af den måde, hvorpå ARs interagerer med fonologisk lokalitet.", 'bg': 'Автосегменталните представяния (ARs; Goldsmith, 1976) позволяват локални анализи на иначе нелокални явления Odden (1994). Фокусирайки се върху областта на тона, изследваме тази способност на АР, използвайки изчислително добре дефинирано понятие за местност, разширено от Чандли (2014). Резултатът е по-нюансирано разбиране за начина, по който АР взаимодействат с фонологичната локалност.', 'hr': 'Autosegmentalne predstave (ARs; Goldsmith, 1976) tvrde se da omogućavaju lokalne analize neolokalnih fenomena Odden (1994). Fokusirajući se na domenu tone, istražujemo ovu sposobnost ARs koristeći računalno dobro definiranu pojmu lokalnosti proširenu iz Chandlee (2014). Rezultat je razumijevanje način a na koji se ARS mijenja sa fonološkim lokalnim mjestima.', 'nl': 'Autosegmentale representaties (ARs; Goldsmith, 1976) worden beweerd om lokale analyses van anders niet-lokale fenomenen Odden (1994) mogelijk te maken. We richten ons op het domein van toon en onderzoeken dit vermogen van ARs met behulp van een computationeel goed gedefinieerd begrip van lokaliteit, uitgebreid vanaf Chandlee (2014). Het resultaat is een genuanceerder begrip van de manier waarop ARs interageren met fonologische lokaliteit.', 'de': 'Autosegmentale Repräsentationen (ARs; Goldsmith, 1976) sollen lokale Analysen ansonsten nicht-lokaler Phänomene Odden (1994) ermöglichen. Mit dem Fokus auf die Domäne des Tons untersuchen wir diese Fähigkeit von ARs unter Verwendung eines computergestützten, gut definierten Lokalitätsbegriffs, der von Chandlee (2014) erweitert wurde. Das Ergebnis ist ein differenzierteres Verständnis der Art und Weise, wie ARs mit phonologischer Lokalität interagieren.', 'ko': '자동 세그먼트 표현(ARs; Goldsmith, 1976)은 다른 비국부적 현상을 국부적으로 분석할 수 있다고 여겨진다.음조 분야에 초점을 맞추어 우리는Chandlee(2014)에서 확장된 계산에서 양호한 국부적 개념을 정의하여 ARs의 이런 능력을 연구한다.그 결과 AR이 음성 위치와 상호작용하는 방식에 대해 더 세밀하게 이해한 것이다.', 'fa': 'نمایش\u200cهای خود جدایی (ARs; Goldsmith, 1976) به عنوان تحلیل\u200cهای محلی غیر محلی اودن (1994) فعال می\u200cشوند. با تمرکز روی صوت، این توانایی ARS را با استفاده از یک نظر کامپیوتری خوب تعریف شده از محلی که از Chandlee (2014) گسترده شده تحقیق می\u200cکنیم. نتیجه یک درک بیشتری از طریقی است که ARS با محل تلفنی ارتباط داشته باشد.', 'id': 'Perwakilan otosegmen (ARs; Goldsmith, 1976) diklaim untuk memungkinkan analisis lokal dari fenomena tidak lokal Odden (1994). Fokus pada domain nada, kami menyelidiki kemampuan ARs ini menggunakan gagasan lokalitas yang ditentukan secara komputasi dengan baik dari Chandlee (2014). Hasilnya adalah pemahaman yang lebih nuansi tentang cara ARs berinteraksi dengan lokalitas fonologi.', 'sq': 'Autosegmental representations (ARs; Goldsmith, 1976) are claimed to enable local analyses of otherwise non-local phenomena Odden (1994).  Duke u përqëndruar në domenin e tonit, ne hetojmë këtë aftësi të ARs duke përdorur një koncept të përcaktuar kompjuterikisht mirë të lokalitetit të zgjeruar nga Chandlee (2014). Rezultati është një kuptim më i nuancuar i mënyrës se si ARs interaktojnë me lokalitetin fonologjik.', 'am': 'የፖስቲካዊ ምርጫዎች (ARs; Goldsmith, 1976) ባሕላዊ የአገሪካ ስህተት ባይኖር የአካባቢ ግንኙነት አካባቢ (1994) እንዲያስችል ይጠራሉ፡፡ የድምጽ አካባቢ ላይ በመጠቀም፣ ከቻንደሌ (2014) የተዘጋጀውን የአርስ አካባቢ በመጠቀም እናሳውቃለን፡፡ ፍጻሜውም አርስ ከፎሎጂካዊ ቦታ ጋር የሚጋጠሙበት መንገድን በማስተዋል የበለጠ ማስተዋል ነው፡፡', 'sw': 'Wawakilishi wa kujitegemea (ARs; Goldsmith, 1976) wanadai kuwa na uwezekano wa uchambuzi wa maeneo mengine yasiyofanywa na matukio yasiyokuwa ya ndani (1994). Kwa kutumia mtazamo wa sauti, tunachunguza uwezo huu wa AR kwa kutumia dhana inayoelezea kwa hisabati inayoenea kutoka Chandlee (2014). Matokeo yake ni kuelewa zaidi kwa namna AR inavyohusiana na maeneo ya kifolojia.', 'tr': "Otomatik segmental temsiller (ARs; Altsmith, 1976) ýerli çykyşlaryň Oden (1994) döwletleriniň analyzasyna mümkin edip bilýärler. Ton domain'a odaklanmak gerekirse, ARs'in bu gücünü Chandlee (2014-nji ýyldan uzatlanan ýerleri) bilgisayarlaryna göz önüne getirip bilýäris. netijede ARS-iň phonolojik ýerler bilen nähili etkileşişiniň düşünmesi nähili daşyrlyk.", 'af': "Autosegmentale voorstellings (ARs; Goldsmith, 1976) word aangeroep om plaaslike analisies van anders nie-plaaslike fenomene Odden (1994) te aktiveer. Fokus op die domein van tone, ondersoek ons hierdie moontlikheid van ARs met 'n rekenaar goed gedefinieerde notie van lokaliteit uitgebrei van Chandlee (2014). Die resultaat is 'n meer nuanced verstanding van die manier waarin ARs interaksie met fonologiese lokaliteit.", 'bs': 'Autosegmentalne predstave (ARs; Goldsmith, 1976) tvrde se da omogućavaju lokalne analize drugačije neolokalnih fenomena Odden (1994). Fokusirajući se na domenu tone, istražujemo ovu sposobnost ARs koristeći računalno dobro određenu ideju lokalnosti proširenu iz Chandlee (2014). Rezultat je manje razumijevanje način a na koji se ARS odnosi na fonološku lokaciju.', 'ca': "Autosegmental representations (ARs; Goldsmith, 1976) are claimed to enable local analyses of otherwise non-local phenomena Odden (1994).  En centrar-nos en el domini del ton, investigam aquesta habilitat d'ARs utilitzant una noció de localitat ben definida computacionalment estesa de Chandlee (2014). El resultat és una comprensió més nuanciada de la manera en què les ARs interact úen amb la localitat fonològica.", 'hy': 'Ավտոսեգմենտալ ներկայացումները (ԱՌ, Գոլդսմիթ, 1976) ենթադրում են, որ հնարավորություն են տալիս տեղական վերլուծություններ այլ ոչ տեղական երևույթի Օդդենի (1994) մասին: Մենք կենտրոնացնում ենք տոնի ոլորտում, ուսումնասիրում ենք ԱՌ-ների այս կարողությունը օգտագործելով Հաշխարհային առումով լավ սահմանված տեղակայության հասկացություն, որը ընդլայնվել է Չանդլին (2014 թվականից): Արդյունքն ավելի նյուանսավոր է հասկանալու, թե ինչպես են ԱԱ-ները փոխազդում ֆոնոլոգիական տեղակայության հետ:', 'az': 'Autosegmental representations (ARs; Goldsmith, 1976) are claimed to enable local analyses of otherwise non-local phenomena Odden (1994). Sonun domeininə fokus edirək, biz bu ARS yetkinliğini Chandlee (2014-dən genişləndirilmiş yerlərin çoxluğu ilə hesablayaraq tanımlanmış fikri ilə araşdırırıq). Sonuç, ARS fonolojik yerləşdirilməsi ilə qarşılaşdığı yolun daha çox dəyişiklikdir.', 'bn': 'স্বয়ংক্রিয়ভাবে প্রতিনিধিত্ব (আর্স; গোল্ডমিথ, ১৯৭৬) অন্যান্য স্থানীয় বিশ্লেষণ অডেন (১৯৪)। টনের ডোমেইনের দিকে মনোযোগ দিয়ে আমরা আরের এই ক্ষমতার তদন্ত করছি গণনাত্রিকভাবে স্থানীয় ধারণা ব্যবহার করে চ্যান্ডেল (২০১৪) থেকে বাড়িয় The result is a more nuanced understanding of the way in which ARs interact with phonological locality.', 'cs': 'Autosegmentální reprezentace (ARs; Goldsmith, 1976) umožňují lokální analýzu jinak nekomístních jevů Odden (1994). Zaměřením se na oblast tónu zkoumáme tuto schopnost ARs pomocí výpočetně dobře definovaného pojmu lokality rozšířeného z Chandlee (2014). Výsledkem je nuancovanější porozumění způsobu, jakým ARs interagují s fonologickou lokalitou.', 'et': 'Autosegmentaalsed representatsioonid (ARs; Goldsmith, 1976) väidetavalt võimaldavad muidu mittekohaliste nähtuste kohalikku analüüsi Odden (1994). Tooni valdkonnale keskendudes uurime ARde võimet, kasutades arvutuslikult hästi määratletud asukoha mõistet, mis on laiendatud Chandlee (2014). Tulemuseks on nüansilisem arusaam sellest, kuidas ARd suhtlevad fonoloogilise asukohaga.', 'fi': 'Autosegmenttisten esitysten (ARs; Goldsmith, 1976) väitetään mahdollistavan paikallisten analyysien muutoin ei-paikallisista ilmiöistä Odden (1994). Keskittyen sävyn domeeniin tutkimme tätä ARin kykyä käyttäen laskennallisesti hyvin määriteltyä paikkakunnan käsitettä, joka on laajennettu Chandleesta (2014). Tuloksena on monivivahteisempi ymmärrys tavasta, jolla ARs:t toimivat vuorovaikutuksessa fonologisen paikkakunnan kanssa.', 'jv': 'Layout Fokosing on the domain of ton, we istrage this power of ARs used a komputely wel- defined Notion of locale expanded from channele (2013). Pametuné malah luwih kelas kuwi nggawe sawasara karo hal-bawih jarang ARs karo lokal kelas telegram.', 'sk': 'Avtosegmentalne reprezentacije (ARs; Goldsmith, 1976) naj bi omogočale lokalne analize sicer ne-lokalnih pojavov Odden (1994). S poudarkom na domeni tona raziskujemo to sposobnost ARs z uporabo računalniško dobro opredeljenega pojma lokalnosti, razširjenega iz Chandleeja (2014). Rezultat je bolj niansirano razumevanje načina interakcije ARs s fonološko lokalnostjo.', 'he': "מייצגים אוטוסגמליים (ARs; Goldsmith, 1976) טוענים לאפשר ניתוח מקומי של תופעות לא מקומיות אחרת אודן (1994). מתמקדים בתחום הטון, אנו חוקרים את היכולת הזו של ARs בשימוש רעיון מחשבי מוגדר היטב של מקום המתואר מ צ'נדלי (2014). התוצאה היא הבנה נואנסית יותר על הדרך שבה ARs מתקשרים עם מקום פונולוגי.", 'ha': "Ana dai masu motsari da farat-segmental (ARs; Goldmith, 1976) za'a zartar da Anarari lokal, idan ba haka ba, filename na lokal (1994). Fokus kan duk sauri, muna tambayar wannan abincin AR da ke amfani da wani hanyar da aka ƙaddara shi a lissafin da aka faɗa daga Chandle (2014). Mataimakin ta zama mafi ƙaranci ga fahimtar hanya da YR ke yi haɗa da lokacin folojiki.", 'bo': 'རང་འགུལ་གྱི་དོན་དག་གནས་སྟངས་གསལ་བཤད་པ(ARs; Goldsmith, 1976)ནི་ས་གནས Focusing on the domain of tone, we investigate this ability of ARs using a computationally well-defined notion of locality extended from Chandlee (2014). གྲུབ་འབྲས་འདི་ARs ཡིས་སྒྲུང་འབྲེལ་གྱི་གནས་ཁོངས་དང་མཐུན་འགྱུར་བའི་ཐབས་ལམ་ལ་ཕན་རྐྱེན་ཐབས་ཤིག་རེད།'}
{'en': 'SECTOR : A Neural Model for Coherent Topic Segmentation and Classification', 'ar': 'القطاع: نموذج عصبي لتجزئة وتصنيف الموضوع المتماسك', 'pt': 'SETOR: Um Modelo Neural para Segmentação e Classificação Coerente de Tópicos', 'fr': 'SECTEUR\xa0: Un modèle neuronal pour une segmentation et une classification cohérentes des sujets', 'es': 'SECTOR: Un modelo neuronal para la segmentación y clasificación coherente de temas', 'ja': 'セクター：一貫したトピックセグメンテーションと分類のためのニューラルモデル', 'ru': 'СЕКТОР: Нейронная модель для когерентной тематической сегментации и классификации', 'hi': 'सेक्टर: सुसंगत विषय विभाजन और वर्गीकरण के लिए एक तंत्रिका मॉडल', 'zh': '行业:连贯主题分神经', 'ga': 'EARNÁIL: Samhail Néarach le haghaidh Deighilt agus Aicmiú Comhleanúnach Topaicí', 'ka': 'კონექტორი: კონეტერენტის ტემიკური სეგენტიფიკაციის და კლასიფიკაციის ნეიროლური მოდელი', 'hu': 'ÁGAZAT: Neurális modell a koherens témaszegmentációhoz és osztályozáshoz', 'el': 'ΤΟΜΕΑΣ: Νευρικό Μοντέλο για τη συνεκτική τμηματοποίηση και ταξινόμηση θεμάτων', 'it': 'SETTORE: Un modello neurale per segmentazione e classificazione coerenti degli argomenti', 'lt': 'SEKTORAS: Neuralinis modelis nuosekliai teminei segmentacijai ir klasifikacijai', 'mk': 'Сектор: Неурален модел за сегментација и класификација на кохерентна тема', 'kk': 'СЕКТОР: Координативті нақыштар сегментациясы мен классификациясы үшін нейрондық модель', 'ms': 'SEKTOR: Model Neural untuk Segmentasi dan Klasifikasi Topik Sama', 'ml': 'സെക്റ്റര്\u200d: കോഹെറെന്റ് വിഭാഗത്തിനുള്ള ഒരു നെയുറല്\u200d മോഡല്\u200d', 'mt': 'SETTUR: Mudell Newrali għas-Segmentazzjoni u l-Klassifikazzjoni Tematika Koerenti', 'mn': 'ШАБЛАН: Координатын сэдэв хэвлэлт болон классификацийн мэдрэлийн загвар', 'no': 'Constellation name (optional)', 'ro': 'SECTOR: Un model neural pentru segmentarea și clasificarea coerentă a subiectelor', 'pl': 'SEKTOR: Model neuronowy spójnej segmentacji i klasyfikacji tematów', 'si': 'සෙක්ටර්: සංවිධාන විද්\u200dයාව සහ ක්\u200dරාසිකරණය සඳහා න්\u200dයූරල් මොඩේල්', 'sr': 'Neuralni model za koherentnu temu segmentaciju i klasifikaciju', 'so': 'SECTOR: Model Neural for Coherent Topic Segment and Classification', 'sv': 'SEKTOR: En neural modell för sammanhängande ämnessegmentering och klassificering', 'ta': 'SECTOR: கூட்டத்திற்கான பொருள் பிரிப்பு மற்றும் வகைப்படுத்தலுக்கான புதிய மாதிரி', 'ur': 'SECTOR: ایک نئورل موڈل کوئرلنٹ ٹیمیک سپٹمنٹ اور کلاسیفٹ کے لئے', 'uz': 'Sertifikat', 'vi': 'Mô hình thần kinh cho mô tả chi tiết và phân hạng theo chủ đề hợp', 'bg': 'Сектор: Невроден модел за съгласувана тематична сегментация и класификация', 'hr': 'SEKTOR: Neuralni model za koherentnu temu segmentaciju i klasifikaciju', 'da': 'Sektor: En neural model for sammenhængende emneområdesegmentering og klassificering', 'nl': 'SECTOR: Een neuraal model voor coherente topic segmentatie en classificatie', 'de': 'SECTOR: Ein neuronales Modell für kohärente Themensegmentierung und Klassifizierung', 'id': 'SEKTOR: Model Neural untuk Segmentasi dan Klasifikasi Topik Koerent', 'fa': 'SECTOR: یک مدل عصبی برای جداگاهی و کلاسیف موضوع هماهنگ', 'ko': '부채형: 주제의 분할과 분류를 연결하는 신경 네트워크 모델', 'sw': 'SECTOR: Utawala wa Neural kwa ajili ya Kugawanywa na Kugawanywa', 'tr': 'SECTOR: Coherent Tema Segmentation and Classification üçin bir näral Modeli', 'sq': 'Një model neuronal për segmentimin dhe klasifikimin e temave koherente', 'af': "SECTOR: ' n Neurale Model vir Koerente Tema Segmentasie en Klassifikasie", 'hy': 'ՍԵկտոր. Կոերեկտ թեմայի սեգմետացիայի և դասակարգման նեյրոնային մոդել', 'am': 'ምርጫዎች', 'az': 'SEKTOR: M칲xt톛lif m톛s톛l톛l톛r Segmentasyonu v톛 Klasifikasyonu 칲칞칲n n칬ral Modeli', 'bn': 'সেক্টর: কহেরেন্ট বিষয় বিভাগ এবং ক্লাসিফেশনের জন্য নিউরেল মডেল', 'ca': 'SECTOR: A Neural Model for Coherent Topic Segmentation and Classification', 'bs': 'SEKTOR: Neuralni model za koherentnu temu segmentaciju i klasifikaciju', 'et': 'SEKTOR: Neuraalne mudel sidusa teema segmenteerimiseks ja klassifitseerimiseks', 'cs': 'SEKTOR: Neurální model pro koherentní segmentaci a klasifikaci témat', 'fi': 'ALA: Neuraalimalli johdonmukaisen aihepiirin segmentoinnille ja luokittelulle', 'jv': 'SEKTOR: model Njuaral kanggo koheret Tema segmentatisi lan kelas', 'sk': 'SEKTOR: Nevralni model za usklajeno segmentacijo in klasifikacijo teme', 'ha': 'KCharselect unicode block name', 'he': 'מודל נוירולי לסגמנציה ונושא תואם', 'bo': 'SECTOR: Coherent Topic Segmentation and Classification ཡི་སྐྱེས་བའི་མ་དབྱིབས་དཔེ་རིགས'}
{'en': 'When searching for information, a human reader first glances over a document, spots relevant sections, and then focuses on a few sentences for resolving her intention. However, the high variance of document structure complicates the identification of the salient topic of a given section at a glance. To tackle this challenge, we present SECTOR, a model to support machine reading systems by segmenting documents into coherent sections and assigning topic labels to each section. Our deep neural network architecture learns a latent topic embedding over the course of a document. This can be leveraged to classify local topics from plain text and segment a document at topic shifts. In addition, we contribute WikiSection, a publicly available data set with 242k labeled sections in English and German from two distinct domains : diseases and cities. From our extensive evaluation of 20 architectures, we report a highest score of 71.6 % F1 for the segmentation and classification of 30 topics from the English city domain, scored by our SECTOR long short-term memory model with Bloom filter embeddings and bidirectional segmentation. This is a significant improvement of 29.5 points F1 over state-of-the-art CNN classifiers with baseline segmentation.', 'es': 'Al buscar información, un lector humano primero echa un vistazo a un documento, detecta las secciones relevantes y luego se centra en unas pocas frases para resolver su intención. Sin embargo, la gran variación de la estructura del documento complica la identificación del tema principal de una sección dada de un vistazo. Para hacer frente a este desafío, presentamos SECTOR, un modelo para apoyar los sistemas de lectura automática mediante la segmentación de documentos en secciones coherentes y la asignación de etiquetas temáticas a cada sección. Nuestra arquitectura de red neuronal profunda aprende un tema latente que se incrusta en el transcurso de un documento. Esto se puede aprovechar para clasificar los temas locales a partir del texto sin formato y segmentar un documento en los cambios de tema. Además, contribuimos con WikiSection, un conjunto de datos disponible al público con 242 000 secciones etiquetadas en inglés y alemán de dos dominios distintos: enfermedades y ciudades. A partir de nuestra amplia evaluación de 20 arquitecturas, obtenemos una puntuación más alta del 71,6% F1 para la segmentación y clasificación de 30 temas del dominio de la ciudad inglesa, puntuada por nuestro modelo de memoria a corto plazo a largo plazo SECTOR con incrustaciones de filtros Bloom y segmentación bidireccional. Esta es una mejora significativa de 29,5 puntos F1 con respecto a los clasificadores CNN de última generación con segmentación de referencia.', 'ar': 'عند البحث عن معلومات ، يلقي القارئ البشري أولاً نظرة سريعة على مستند ، ويرصد الأقسام ذات الصلة ، ثم يركز على بضع جمل لتحديد نيته. ومع ذلك ، فإن التباين الكبير في بنية المستند يعقد تحديد الموضوع البارز لقسم معين في لمحة. لمواجهة هذا التحدي ، نقدم SECTOR ، نموذجًا لدعم أنظمة القراءة الآلية عن طريق تقسيم المستندات إلى أقسام متماسكة وتعيين تسميات مواضيع لكل قسم. تتعلم بنية الشبكة العصبية العميقة الخاصة بنا موضوعًا كامنًا يتم تضمينه على مدار المستند. يمكن الاستفادة من ذلك لتصنيف الموضوعات المحلية من نص عادي وتقسيم المستند عند تحولات الموضوع. بالإضافة إلى ذلك ، نساهم بـ WikiSection ، وهي مجموعة بيانات متاحة للجمهور تحتوي على 242 ألف قسم مُصنّف باللغتين الإنجليزية والألمانية من مجالين متميزين: الأمراض والمدن. من خلال تقييمنا الشامل لـ 20 معمارية ، أبلغنا عن أعلى درجة 71.6٪ F1 لتجزئة وتصنيف 30 موضوعًا من مجال المدينة الإنجليزية ، سجلها نموذج ذاكرة SECTOR طويل المدى الخاص بنا مع تضمين مرشح Bloom والتجزئة ثنائية الاتجاه. هذا تحسن كبير بمقدار 29.5 نقطة F1 على أحدث مصنفات CNN مع تجزئة أساسية.', 'pt': 'Ao pesquisar informações, um leitor humano primeiro olha um documento, identifica seções relevantes e, em seguida, concentra-se em algumas frases para resolver sua intenção. No entanto, a alta variação da estrutura do documento complica a identificação do tópico mais importante de uma determinada seção à primeira vista. Para enfrentar este desafio, apresentamos o SECTOR, um modelo para apoiar os sistemas de leitura automática, segmentando documentos em seções coerentes e atribuindo rótulos de tópicos a cada seção. Nossa arquitetura de rede neural profunda aprende um tópico latente incorporado ao longo de um documento. Isso pode ser aproveitado para classificar tópicos locais de texto simples e segmentar um documento em mudanças de tópicos. Além disso, contribuímos com o WikiSection, um conjunto de dados disponível publicamente com 242 mil seções rotuladas em inglês e alemão de dois domínios distintos: doenças e cidades. A partir de nossa extensa avaliação de 20 arquiteturas, relatamos uma pontuação mais alta de 71,6% F1 para a segmentação e classificação de 30 tópicos do domínio da cidade inglesa, pontuados por nosso modelo de memória de longo prazo SETOR com embeddings de filtro Bloom e segmentação bidirecional. Esta é uma melhoria significativa de 29,5 pontos F1 em relação aos classificadores CNN de última geração com segmentação de linha de base.', 'fr': "Lors de la recherche d'informations, un lecteur humain jette d'abord un coup d'œil sur un document, repère les sections pertinentes, puis se concentre sur quelques phrases pour résoudre son intention. Cependant, la grande variation de la structure du document complique l'identification du sujet principal d'une section donnée en un coup d'œil. Pour relever ce défi, nous présentons SECTOR, un modèle qui prend en charge les systèmes de lecture automatique en segmentant les documents en sections cohérentes et en attribuant des étiquettes de sujet à chaque section. Notre architecture de réseau neuronal profond apprend un sujet latent intégré au cours d'un document. Cela peut être utilisé pour classer les sujets locaux à partir de texte brut et segmenter un document en fonction des changements de sujet. En outre, nous contribuons à WikiSection, un ensemble de données accessible au public avec 242 000 sections étiquetées en anglais et en allemand dans deux domaines distincts\xa0: les maladies et les villes. À partir de notre évaluation approfondie de 20 architectures, nous avons obtenu le score le plus élevé de 71,6\xa0% F1 pour la segmentation et la classification de 30 sujets du domaine de la ville anglaise, obtenu par notre modèle de mémoire longue à court terme SECTOR avec intégration de filtres Bloom et segmentation bidirectionnelle. Il s'agit d'une amélioration significative de 29,5 points F1 par rapport aux classificateurs CNN de pointe avec segmentation de base.", 'ja': '情報を検索するとき、人間の読者はまずドキュメントを一目見て、関連するセクションを見つけ、次に彼女の意図を解決するためのいくつかの文章に焦点を当てます。 しかし、文書構造の分散が大きいため、特定のセクションの顕著なトピックを一目で特定することが困難になります。 この課題に取り組むために、文書を一貫性のあるセクションにセグメント化し、各セクションにトピックラベルを割り当てることで、機械読み取りシステムをサポートするモデルであるセクターを提示します。 当社の深層ニューラルネットワークアーキテクチャは、文書の過程に埋め込まれた潜在的なトピックを学習します。 これを利用して、プレーンテキストからローカルトピックを分類し、トピックシフトでドキュメントをセグメント化することができます。 さらに、病気と都市という2つの異なるドメインから、英語とドイツ語で242,000とラベル付けされたセクションを備えた一般に利用可能なデータセットであるWikiSectionに寄稿しています。 20のアーキテクチャの広範な評価から、私たちは、ブルームフィルター埋め込みと双方向セグメンテーションを備えたセクターの長期短期記憶モデルによってスコア付けされた、英語の都市ドメインからの30のトピックのセグメンテーションと分類の最高スコア71.6 ％ F 1を報告しています。 これは、ベースラインのセグメンテーションを備えた最先端のCNN分類子よりも29.5ポイントF 1の大幅な改善である。', 'zh': '及搜索信息,人读者先览文档,得其部分,然后专注数句以决其意。 然其高异,一目了然定其突出主题变得复杂。 为此挑战,SIDE也,是机器读其统也,分文档为连贯而为之主机器读之。 深神经网络架构学文档嵌题。 可用纯文本中分类,转换分段文档。 献WikiSection,此一公数集也,其包两异域者242k英语德语:疾病城邑。 据我们对20种架构的广评,我们报告了英国城邑领域的30个主题的细分和分类的最高分为71.6%F1,由我们的官司长短期记忆模形评分,该模形有Bloom过滤器嵌双向分割。 与有基线之最先进CNN分类器相比,此F1之29.5分显改也。', 'hi': 'जानकारी की खोज करते समय, एक मानव पाठक पहले एक दस्तावेज़ पर नज़र डालता है, प्रासंगिक वर्गों को स्पॉट करता है, और फिर उसके इरादे को हल करने के लिए कुछ वाक्यों पर ध्यान केंद्रित करता है। हालांकि, दस्तावेज़ संरचना का उच्च विचरण एक नज़र में किसी दिए गए अनुभाग के मुख्य विषय की पहचान को जटिल बनाता है। इस चुनौती से निपटने के लिए, हम SECTOR, सुसंगत वर्गों में दस्तावेजों को विभाजित करके और प्रत्येक अनुभाग को विषय लेबल असाइन करके मशीन रीडिंग सिस्टम का समर्थन करने के लिए एक मॉडल प्रस्तुत करते हैं। हमारी गहरी तंत्रिका नेटवर्क वास्तुकला एक दस्तावेज के दौरान एम्बेडिंग एक अव्यक्त विषय सीखती है। यह सादे पाठ से स्थानीय विषयों को वर्गीकृत करने और विषय शिफ्ट पर एक दस्तावेज़ को विभाजित करने के लिए लाभ उठाया जा सकता है। इसके अलावा, हम WikiSection, दो अलग-अलग डोमेन से अंग्रेजी और जर्मन में 242k लेबल वाले अनुभागों के साथ एक सार्वजनिक रूप से उपलब्ध डेटा सेट का योगदान करते हैं: रोग और शहर। 20 आर्किटेक्चर के हमारे व्यापक मूल्यांकन से, हम अंग्रेजी शहर डोमेन से 30 विषयों के विभाजन और वर्गीकरण के लिए 71.6% एफ 1 के उच्चतम स्कोर की रिपोर्ट करते हैं, जो ब्लूम फ़िल्टर एम्बेडिंग और द्विदिश विभाजन के साथ हमारे सेक्टर के दीर्घकालिक मेमोरी मॉडल द्वारा स्कोर किया गया है। यह बेसलाइन विभाजन के साथ अत्याधुनिक सीएनएन क्लासिफायरपर 29.5 अंक एफ 1 का एक महत्वपूर्ण सुधार है।', 'ru': 'При поиске информации читатель сначала смотрит на документ, замечает соответствующие разделы, а затем фокусируется на нескольких предложениях для разрешения своего намерения. Вместе с тем значительная разница в структуре документов с первого взгляда затрудняет выявление основной темы данного раздела. Чтобы решить эту проблему, мы представляем СЕКТОР, модель для поддержки систем машинного считывания путем сегментации документов на последовательные разделы и присвоения меток тем для каждого раздела. Наша архитектура глубокой нейронной сети изучает скрытую тему, внедряемую в ходе работы над документом. Это может быть использовано для классификации локальных тем из простого текста и сегментации документа при смене тем. Кроме того, мы предоставляем WikiSection, общедоступный набор данных с 242 тысячами помеченных разделов на английском и немецком языках из двух разных областей: болезней и городов. Из нашей обширной оценки 20 архитектур мы сообщаем о самом высоком показателе 71,6% F1 для сегментации и классификации 30 тем из английского городского домена, оцененных нашей СЕКТОРАЛЬНОЙ моделью долгосрочной краткосрочной памяти с встраиванием фильтров Bloom и двунаправленной сегментацией. Это является значительным улучшением на 29,5 пункта F1 по сравнению с современными классификаторами CNN с базовой сегментацией.', 'ga': 'Nuair a bhíonn faisnéis á cuardach aici, breathnaíonn léitheoir daonna ar dhoiciméad ar an gcéad dul síos, aimsíonn sé na codanna ábhartha, agus ansin díríonn sé ar chúpla abairt chun a rún a réiteach. Mar sin féin, cuireann an éagsúlacht ard i struchtúr na ndoiciméad níos casta le sainaithint sracfhéachaint ar an ábhar suntasaí i mír ar leith. Chun dul i ngleic leis an dúshlán seo, cuirimid SECTOR i láthair, samhail chun tacú le córais meaisínléitheoireachta trí dhoiciméid a dheighilt ina gcodanna soiléire agus lipéid topaicí a shannadh do gach rannóg. Foghlaimíonn ár n-ailtireacht dhomhain líonra néaraigh ábhar folaigh a neadaíonn thar thréimhse doiciméid. Is féidir é seo a ghiaráil chun topaicí áitiúla a rangú ó ghnáth-théacs agus doiciméad a dheighilt ag aistrithe topaicí. Ina theannta sin, cuirimid WikiSection ar fáil, tacar sonraí atá ar fáil go poiblí le 242k rannóg lipéadaithe i mBéarla agus i nGearmáinis ó dhá réimse ar leith: galair agus cathracha. Ón measúnú fairsing a rinneamar ar 20 ailtireacht, tuairiscímid scór is airde de 71.6% F1 maidir le deighilt agus aicmiú 30 ábhar ó fhearann na cathrach Béarla, arna scóráil ag ár múnla cuimhne gearrthéarmach SECTOR le leabaithe scagaire Bloom agus deighilt déthreo. Is feabhas suntasach é seo de 29.5 pointe F1 thar aicmitheoirí CNN úrscothacha le deighilt bunlíne.', 'ka': 'როდესაც ინფორმაციის ძებნა, ადამიანის კითხველი პირველი დოკუმენტის შესახებ, შესახებ მნიშვნელოვანი სექციები, და შემდეგ კონუქტირება მნიშვნელოვანი წარმოდგენისთ მაგრამ, დოკუმენტის სტრუქტურაციის მაღალი განრავლობა კომპლექტირებს განსაზღვრება, რომელიც განსაზღვრებული სექციოს სტრუქტურაციის განსაზღვ ამ გამოცდილების გარეშე, ჩვენ SECTOR-ს მოდელს, რომელიც მაქსინური კითხვის სისტემის დახმარებას დოკუმენტების შესაძლებლობით კონკუმენტების შესაძლებლობით დავწყებთ და ყოვე ჩვენი ძალიან ნეიროლური ქსელის აქტიქტიქტიკური აღმოჩენა, რომელიც დოკუმენტის გარეშე დაკავშირებულია. Name დამატებით, ჩვენ WikiSection-ს დამატებით, საუკეთესოდ ხელსაწყებელი მონაცემები, რომელიც 242k წერტილი წერტილი ანგლისში და გერმანეთში ორი განსხვავებული კომენტებით: დაავად 20 არქტიქტურების უფრო დიდი განსაზღვრებით, ჩვენ 71.6% F1-ის უფრო დიდი წერტილის სივდუმენტი და კლასიფიკაციაში 30 ტემები ინგლისური დომინიდან, რომელიც ჩვენი SECTOR-ის ძალიან სივდუმენტის მეხსიერების მოდელიდან გამოწერა ეს არის გასანიშვნელოვანი წარმოდგენება 29.5 წარმოდგენების F1 წარმოდგენებით CNN-ის კლასიფიკაციაზე, რომლებიც მუშაობელი წარმოდგენებით.', 'el': 'Όταν αναζητά πληροφορίες, ένας άνθρωπος αναγνώστης κοιτάζει πρώτα ένα έγγραφο, εντοπίζει σχετικές ενότητες και στη συνέχεια επικεντρώνεται σε μερικές προτάσεις για την επίλυση της πρόθεσής του. Ωστόσο, η υψηλή διακύμανση της δομής του εγγράφου περιπλέκει τον προσδιορισμό του σημαντικού θέματος μιας δεδομένης ενότητας με μια ματιά. Για την αντιμετώπιση αυτής της πρόκλησης, παρουσιάζουμε ένα μοντέλο για την υποστήριξη συστημάτων αυτόματης ανάγνωσης με την κατάτμηση εγγράφων σε συνεκτικές ενότητες και την ανάθεση ετικετών θεμάτων σε κάθε τμήμα. Η βαθιά αρχιτεκτονική νευρωνικών δικτύων μαθαίνει ένα λανθάνον θέμα ενσωμάτωσης κατά τη διάρκεια ενός εγγράφου. Αυτό μπορεί να χρησιμοποιηθεί για την ταξινόμηση τοπικών θεμάτων από απλό κείμενο και την τμηματοποίηση ενός εγγράφου σε αλλαγές θεμάτων. Επιπλέον, συνεισφέρουμε στο WikiSection, ένα κοινό διαθέσιμο σύνολο δεδομένων με ετικέτες 242στα αγγλικά και γερμανικά από δύο διαφορετικούς τομείς: ασθένειες και πόλεις. Από την εκτενή αξιολόγηση των 20αρχιτεκτονικών μας, αναφέρουμε υψηλότερη βαθμολογία 71,6% F1 για την τμηματοποίηση και ταξινόμηση 30 θεμάτων από τον τομέα της αγγλικής πόλης, βαθμολογημένη από το μοντέλο μακροχρόνιας βραχυπρόθεσμης μνήμης μας με ενσωμάτωση φίλτρων και αμφίδρομη τμηματοποίηση. Πρόκειται για σημαντική βελτίωση των 29,5 σημείων F1 έναντι των σύγχρονων ταξινομητών CNN με κατανομή βάσης.', 'hu': 'Amikor információt keres, egy emberi olvasó először ránéz egy dokumentumra, meglátja a releváns részeket, majd néhány mondatra összpontosít, hogy megoldja szándékát. A dokumentumszerkezet nagy eltérése azonban megnehezíti egy adott szakasz kiemelkedő témájának azonosítását. Ennek a kihívásnak a megoldása érdekében bemutatjuk a SECTOR modellt, amely támogatja a gépi olvasási rendszereket azáltal, hogy a dokumentumokat koherens szakaszokra szegmentálja és témaköri címkéket rendel minden szakaszhoz. A mély neurális hálózat architektúránk egy látens témát tanul meg egy dokumentum során. Ez felhasználható a helyi témák egyszerű szövegből történő osztályozására és a dokumentumok témaváltásakor történő szegmentálására. Továbbá hozzájárulunk a WikiSection-hez, egy nyilvánosan elérhető adatkészlethez, amely 242 ezer angol és német nyelvű címkével rendelkezik, két különböző területből: betegségekből és városokból. 20 architektúra kiterjedt értékeléséből 71,6%-os F1 pontszámot számoltunk be az angol városi domain 30 témájának szegmentálására és osztályozására, melyet a SECTOR rövid távú memória modellünk értékelt Bloom szűrőbeágyazással és kétirányú szegmentálással. Ez 29,5 pontos F1-es jelentős javulást jelent a legkorszerűbb CNN osztályozókkal szemben, kiindulási szegmentációval.', 'it': "Quando si cerca informazioni, un lettore umano guarda prima un documento, individua sezioni rilevanti e poi si concentra su alcune frasi per risolvere la sua intenzione. Tuttavia, l'elevata variabilità della struttura del documento complica l'identificazione dell'argomento saliente di una determinata sezione a colpo d'occhio. Per affrontare questa sfida, presentiamo SECTOR, un modello per supportare i sistemi di lettura automatica segmentando i documenti in sezioni coerenti e assegnando etichette tematiche a ciascuna sezione. La nostra architettura di rete neurale profonda impara un argomento latente incorporato nel corso di un documento. Questo può essere utilizzato per classificare gli argomenti locali dal testo semplice e segmentare un documento a cambi di argomento. Inoltre, contribuiamo a WikiSection, un set di dati pubblicamente disponibile con 242k sezioni etichettate in inglese e tedesco da due domini distinti: malattie e città. Dalla nostra ampia valutazione di 20 architetture, riportiamo un punteggio più alto del 71,6% F1 per la segmentazione e classificazione di 30 argomenti dal dominio cittadino inglese, ottenuto dal nostro modello di memoria a lungo termine SECTOR con incorporazioni di filtri Bloom e segmentazione bidirezionale. Si tratta di un miglioramento significativo di 29,5 punti F1 rispetto ai classificatori CNN all'avanguardia con segmentazione basale.", 'lt': 'When searching for information, a human reader first glances over a document, spots relevant sections, and then focuses on a few sentences for resolving her intention.  Tačiau didelis dokumentų struktūros skirtumas apsunkina tam tikro skirsnio svarbiausios temos nustatymą žvilgsniu. Siekdami spręsti šį uždavinį, pristatysime SECTOR, model į, kuriuo remiamos mašinų skaitymo sistemos, skirstant dokumentus į nuoseklius skirsnius ir kiekvienam skirsniui priskiriant temines etiketes. Mūsų gilaus nervų tinklo architektūra moko latentišką temą, įtraukiamą dokumento metu. Tai gali būti naudojama siekiant klasifikuoti vietines temas iš paprasto teksto ir atskirti dokumentą keičiant temas. Be to, prisidedame prie WikiSection, viešai prieinamo duomenų rinkinio su 242k žymėtomis anglų ir vokiečių kalbomis iš dviejų skirtingų sričių: ligų ir miestų. Iš mūsų išsamaus 20 architektūrų vertinimo pranešame, kad didžiausias 71,6 % F1 taškas segmentuojant ir klasifikuojant 30 temų iš anglų miesto domeno, įvertintas mūsų SECTOR ilgalaikio trumpalaikio atminties modelio su Bloom filtrų įdėjimais ir dvikryptine segmentacija. Tai reikšmingas 29,5 punkto F1 pagerėjimas, palyginti su naujausiais CNN klasifikatoriais su pradine segmentacija.', 'kk': 'Мәліметті іздегенде, бірінші адамдар оқушы құжатты, қатынастық бөліктерді қарап, кейін оның мақсатын шешу үшін бірнеше сөздерге көздейді. Бірақ құжаттың құрылымының жоғары айырмашылығы келтірілген бөлімінің тұмандығының идентификациясын көмектеседі. Бұл мәселелерді шешу үшін біз СЕКТОР дегенді, құжаттарды сәйкес бөліктеріне бөліп, әрбір бөлігіне нақышты жарлықтарын қолдау үшін машинаны оқу жүйелерін қолдау үші Құжаттың ішінде ендірілген невралдық желінің архитектурасы келесі нақышты оқыды. Бұл жергілікті тақырыптарды кәдімгі мәтіннен және құжатты тақырыпты ауыстыруға көмек мәтіннен классификациялауға болады. Қосымша, біз Викисекциясына көмектесеміз: аурулар мен қалалар: 242k бөлігін ағылшын және неміс тілінде белгілеген бөліктермен көмектесетін деректерді көмектесеміз. 20 архитектуралардың кеңейтілген бағалауынан 71,6% F1 деген ең жоғары нәтижесін ағылшын қала доменінің 30 нақыштарды сегментациялау мен классификациялау үшін хабарлаймыз. Бұл біздің SECTOR қысқайт жады моделіміз Bloom сүзгілерін ендіру мен екі Бұл CNN классификациясының 29,5 нүкте F1-нің негізгі сегментациясы бойынша маңызды жақсарту.', 'mk': 'Кога бара информации, човечкиот читач прво погледнува над документот, забележува релевантни секции, а потоа се фокусира на неколку реченици за решавање на нејзината намера. Сепак, високата варијанса на структурата на документот ја комплицира идентификацијата на ослободната тема на одреден дел од поглед. За да го решиме овој предизвик, го претставуваме СеКТОР, модел за поддршка на системите за читање на машините со сегментирање на документите во кохерентни секции и додавање на теми етикети на секој секција. Нашата длабока нервна мрежа архитектура научи тајна тема вклучена во текот на документот. Ова може да се искористи за класификување на локалните теми од обичен текст и сегментирање на документ на смени на тема. Покрај тоа, придонесуваме во WikiSection, јавно достапен податок со 242k обележани секции на англиски и германски од два различни домени: болести и градови. Од нашата екстремна оценка на 20 архитектури, пријавуваме највисок резултат од 71,6 отсто Ф1 за сегментацијата и класификацијата на 30 теми од англискиот градски домен, оценет од нашиот долгорочен модел на сеќавање на SECTOR со вградени филтри на Блум и двојно сегментација. Ова е значително подобрување од 29,5 поени Ф1 во однос на најсовремените класификатори на СНН со основна сегментација.', 'ml': 'വിവരങ്ങള്\u200d തിരയുമ്പോള്\u200d ഒരു മനുഷ്യന്\u200d ഒരു രേഖയില്\u200d ആദ്യ നോട്ടം നോക്കുന്നു, പ്രധാനപ്പെട്ട വിഭാഗങ്ങള്\u200d കണ്ടു, പിന്നീട് അവളുടെ ഉദ് എന്നാലും, രേഖയുടെ ഘടനയുടെ ഉയര്\u200dന്ന വ്യത്യാസം ഒരു കണ്ണില്\u200d കൊടുക്കപ്പെട്ട വിഭാഗത്തിന്റെ തിരിച്ചറിയുന്നതിനെ പ ഈ ചോദ്യങ്ങളെ എതിര്\u200dത്താന്\u200d, ഞങ്ങള്\u200d സെക്ട്രോറിനെ കാണിക്കുന്നു, യന്ത്ര വായിക്കുന്ന സിസ്റ്റം പിന്തുണയ്ക്കുന്ന ഒരു മോഡല്\u200d കൊണ്ടുവന്ന നമ്മുടെ ആഴത്തെ നെയൂറല്\u200d നെറ്റര്\u200d ശൂന്യമായ ഒരു രേഖയുടെ പ്രക്രിയത്തില്\u200d പ്രവേശിക്കുന്ന ഒരു പ്രമേയം പഠിക് സാധാരണ പദാവലിയില്\u200d നിന്നും ലോക്കല്\u200d പ്രമേയങ്ങള്\u200d വ്യക്തമാക്കുവാനും, പ്രമേയത്തിന്\u200dറെ മാറ്റങ്ങളില്\u200d നിന്നും ഒരു രേഖ വ അതുകൂടാതെ, വികിസെക്ഷനില്\u200d നിന്നും നമ്മള്\u200d ഭാഗങ്ങളില്\u200d നിന്നും വ്യത്യസ്തമായ രണ്ടു ഡോമെന്\u200dമെനുകളില്\u200d നിന്നും നോഗങ്ങളും പട്ടണങ്ങളുമ From our extensive evaluation of 20 architectures, we report a highest score of 71.6% F1 for the segmentation and classification of 30 topics from the English city domain, scored by our SECTOR long short-term memory model with Bloom filter embeddings and bidirectional segmentation.  ഇത് 29. 5 പോയിന്\u200dറ് F1-നെ ബെസ്ലൈന്\u200d സിഎന്\u200dഎന്\u200d സിപ്ലൈന്\u200d വിഭാഗങ്ങളുടെ സ്റ്റേറ്റ് സ്റ്റേറ്റ് സിന്\u200dഎന്\u200d എന്\u200dഎന്\u200d ക്ലാസ്ഫ', 'ms': 'Apabila mencari maklumat, pembaca manusia memandang pertama ke atas dokumen, melihat seksyen yang berkaitan, dan kemudian fokus pada beberapa kalimat untuk memecahkan tujuannya. Namun, variasi tinggi struktur dokumen memudahkan pengenalan topik utama bagi seksyen tertentu pada pandangan. Untuk menghadapi cabaran ini, kami memperkenalkan SECTOR, model untuk menyokong sistem pembacaan mesin dengan menyegmen dokumen ke seksyen yang konsisten dan menyerahkan label topik ke setiap seksyen. Arkitektur rangkaian saraf dalam kita belajar topik tersembunyi memasukkan dalam perjalanan dokumen. Ini boleh digunakan untuk mengklasifikasikan topik setempat dari teks biasa dan segmen dokumen pada perubahan topik. Selain itu, kami menyumbangkan WikiSection, set data yang tersedia kepada masyarakat dengan 242k seksyen yang ditabel dalam bahasa Inggeris dan Jerman dari dua domain yang berbeza: penyakit dan bandar. Dari penilaian ekstensif 20 arkitektur kami, kami laporkan skor tertinggi 71.6% F1 untuk segmen dan klasifikasi 30 topik dari domain bandar Inggeris, ditakdirkan oleh model ingatan jangka pendek SECTOR kami dengan penerbangan penapis Bloom dan segmen bidireksi. Ini merupakan peningkatan yang signifikan 29.5 titik F1 atas klasifikasi CNN-state-of-the-art dengan segmen dasar.', 'mt': 'Meta qed ifittex informazzjoni, qarrej uman iħares l-ewwel lejn dokument, iqiegħed taqsimiet rilevanti, u mbagħad jiffoka fuq ftit sentenzi biex isolvi l-intenzjoni tiegħu. Madankollu, il-varjanza għolja tal-istruttura tad-dokument tikkumplika l-identifikazzjoni tas-suġġett salienti ta’ taqsima partikolari f’għajnejn. To tackle this challenge, we present SECTOR, a model to support machine reading systems by segmenting documents into coherent sections and assigning topic labels to each section.  L-arkitettura tan-netwerk newrali profond tagħna tagħlim suġġett moħbi li jinkorpora matul dokument. Dan jista’ jiġi sfruttat biex jiġu kklassifikati suġġetti lokali minn test sempliċi u jiġi segment at dokument f’bidliet ta’ suġġetti. Barra minn hekk, nikkontribwixxu WikiSection, sett ta’ dejta disponibbli għall-pubbliku b’sezzjonijiet ittikkettati 242k bl-Ingliż u l-Ġermaniż minn żewġ oqsma distinti: mard u bliet. Mill-evalwazzjoni estensiva tagħna ta’ 20 arkitettura, nirrappurtaw l-ogħla punteġġ ta’ 71.6% F1 għas-segmentazzjoni u l-klassifikazzjoni ta’ 30 suġġett mid-dominju tal-belt Ingliża, punteġġi mill-mudell tal-memorja fit-tul tagħna tas-SECTOR b’inkorporazzjonijiet tal-filtri tad-demm u segmentazzjoni bidirezzjonali. This is a significant improvement of 29.5 points F1 over state-of-the-art CNN classifiers with baseline segmentation.', 'mn': 'Мэдээллийг хайж байхдаа хүний уншигч баримт дээр анхны харвал, холбоотой хэсэгт харагдаж, дараа нь өөрийн зорилго шийдэхэд хэдэн өгүүлбэрийг анхаарлаа хандуулдаг. Гэхдээ баримтын бүтэц өндөр өөрчлөлт нь хараад өгөгдсөн хэсэг дээрх сайхан сэдвийг тодорхойлдог. Энэ сорилтыг зогсоохын тулд бид СЕКТОР-г, машины унших системийг дэмжих загвар өгдөг. Документуудыг нэгтгэл хэсэгт хувааж, сэдвийн загваруудыг хэсэгт хувааж өгдөг. Бидний гүн гүнзгий мэдрэлийн сүлжээний архитектур баримт дээр дүгнэгдсэн сүүлийн сэдвийг сурсан. Орон нутгийн сэдвүүдийг нийтлэг текст болон сэдвийн шилжүүлэгт баримтыг хэвлэхэд тусалж болно. Үүнээс гадна бид WikiSection-д олон нийтэд хэрэглэгддэг өгөгдлийн хувьд англи, Герман хэлний 242k хэсэгт хоёр төрлийн хэсэгт холбогдсон: өвчин, хот. Бидний 20 архитектуруудын өргөн үнэлгээгээс бид Англи хотын дотор 30 сэдэв загварын 71.6% F1 хэмжээний хамгийн өндөр тооны үзүүлэлт өгсөн. Блум сүзэгчийн загвар болон хоёр загварын 30 сэдэв загварын хуваалтыг бидний SECTOR-ын богино хугацааны санамж загварын Энэ бол суурь шугам хэмжээний хуваалтын төвшинд F1 цэгийн 29.5 цэгийн сайжруулалт юм.', 'pl': 'Podczas poszukiwania informacji człowiek najpierw spojrzy na dokument, zauważa odpowiednie sekcje, a następnie skupia się na kilku zdaniach, aby rozwiązać swoją intencję. Jednak duża różnica struktury dokumentu komplikuje identyfikację ważnego tematu danej sekcji na pierwszy rzut oka. Aby sprostać temu wyzwaniu, przedstawiamy model SECTOR, który wspiera systemy odczytu maszynowego poprzez segmentowanie dokumentów na spójne sekcje i przypisywanie etykiet tematów do każdej sekcji. Nasza głęboka architektura sieci neuronowej uczy się ukrytego tematu osadzania w trakcie dokumentu. Można to wykorzystać do klasyfikowania lokalnych tematów z tekstu zwykłego i segmentowania dokumentu podczas zmian tematów. Ponadto wprowadzamy WikiSection, publicznie dostępny zestaw danych z oznaczonymi 242k sekcjami w języku angielskim i niemieckim z dwóch różnych domen: chorób i miast. Z naszej szerokiej oceny architektur 20,6% F1 zgłaszamy najwyższy wynik 71,6% F1 dla segmentacji i klasyfikacji 30 tematów z angielskiej domeny miasta, oceniany przez nasz model pamięci krótkoterminowej SECTOR z osadzeniami filtrów Bloom i segmentacją dwukierunkową. Jest to znacząca poprawa poziomu 29,5 punktów F1 w porównaniu z najnowocześniejszymi klasyfikatorami CNN z segmentacją bazową.', 'no': 'Når du søkjer etter informasjon, så er ei menneskelesar første sjølv over eit dokument, plasser relevante deler, og så fokuserer på nokre setningar for å løysa vilje henne. Det høge variansen av dokumentstrukturen kompliserer imidlertid identifiseringa av det salient emnet i ei oppgjevne delen på ein bakgrunn. For å løsa denne utfordringen, presenterer vi SECTOR eit modell for å støtta maskinelesingssystemet ved å segmentera dokument inn i koherente deler og tilordna temaetikettar til kvar del. Vårt dyp neuralnettverkstarkitektur lærer ein latent emne som innebygger over eit dokument. Dette kan brukast til å klassifisera lokale emner frå vanleg tekst og segmentera eit dokument ved temaskifter. I tillegg bidra vi WikiSection, eit offentlig tilgjengeleg data set med 242k merkelige deler på engelsk og tysk frå to ulike domene: sykdommer og byer. Fra vår utvida evaluering av 20 arkitektur rapporterer vi ein høgste poeng av 71,6% F1 for segmentasjonen og klassifikasjonen av 30 emne frå engelsk bydomenet. Dette er oppgitt av vår langsiktige minnemodell i SECTOR-modellen med Bloom-filter-innbygging og bidireksjonal segmentasjon. Dette er ein betydelig forbedring av 29,5 punkt F1 over tilstanden av kunstklassifiseringane CNN med baseline segmentasjon.', 'ro': 'Când caută informații, un cititor uman se uită mai întâi peste un document, observă secțiuni relevante și apoi se concentrează pe câteva propoziții pentru rezolvarea intenției sale. Cu toate acestea, variația ridicată a structurii documentelor complică identificarea subiectului esențial al unei anumite secțiuni dintr-o privire. Pentru a face față acestei provocări, vă prezentăm SECTOR, un model care sprijină sistemele de citire automată prin segmentarea documentelor în secțiuni coerente și atribuirea etichetelor subiectelor fiecărei secțiuni. Arhitectura noastră de rețea neurală profundă învață un subiect latent încorporat pe parcursul unui document. Acest lucru poate fi utilizat pentru a clasifica subiectele locale din text simplu și segmenta un document la schimbarea subiectelor. În plus, contribuim la WikiSection, un set de date disponibil public cu 242.000 de secțiuni etichetate în limba engleză și germană din două domenii distincte: boli și orașe. Din evaluarea noastră extinsă a 20 de arhitecturi, raportăm cel mai mare scor de 71,6% F1 pentru segmentarea și clasificarea a 30 de subiecte din domeniul orașului englez, scorat de modelul nostru SECTOR de memorie pe termen lung scurt cu încorporări de filtre Bloom și segmentare bidirecțională. Aceasta reprezintă o îmbunătățire semnificativă de 29,5 puncte F1 față de clasificatorii CNN de ultimă generație cu segmentare inițială.', 'so': 'Markii aad raadineyso macluumaadka, qof akhriska ah ayaa marka hore fiirinaya dukumenti, wuxuu fiiriyaa qaybaha la xiriira, markaasna wuxuu ku kalsoonaadaa dhawr erayo si uu u xalliyo qastigeeda. Si kastaba ha ahaatee bedelka sare ee dhismaha dukumentiyada ayaa soo burburinaya aqoonsiga mada bukaanka ee qeybta la siiyey oo aad fiirinaysaa. Si aan u tacliino dhibaatadan, waxaynu soo bandhignaynaa SECTOR, model in lagu kaalmeeyo nidaamka akhrinta mashiinka ee lagu qoro qoraalka qaybaha wadajirka ah oo loo qaybiyo alaabta madaxaha. Arkitirimada shabakadda naadiga ah ee mool dheer wuxuu baranayaa mada la soo dhowaaday oo ku soo wareegsan koorasyada dukumentiga. This can be leveraged to classify local topics from plain text and segment a document at topic shifts.  WikiSection waxaa kale oo aan ka qeybqaadanaynaa macluumaad caadiga ah oo lagu qoray 242k qeybood oo lagu qoray afka Ingiriis iyo Jarmalka laga qoray laba meelood oo kala duduwan: cuduro iyo magaalooyin. Qiimeynta dhaadheerka ah ee 20 dhismaha, waxaynu ka soo qoraynaa koox ugu sarreeya 71.6% F1, si loo kala sooco iyo fasaxo 30 madaamaha magaalada Ingiriiska, waxaa loo qoray modelkeen xasuusta wakhti dheer ah ee SECTOR oo ku qoran baaritaanka Bloom iyo qayb-qaybinta. Tani waa hagaajinta 29.5 barta F1 oo ku qoran dowladda-qoriga CNN-da oo ku qoran qeybinta qoraalka hoose.', 'sr': 'Kada traži informacije, ljudski čitač prvi pogleda na dokument, stavlja relevantne sekcije, a onda se fokusira na nekoliko rečenica za rješavanje njene namjere. Međutim, visoka varijancija strukture dokumenta komplikuje identifikaciju salijente teme određenog dijela na pogledu. Da bi se riješili ovaj izazov, predstavljamo SECTOR, model za podršku sistema čitanja mašina, segmentirajući dokumente u koherentne sekcije i dodavajući etikete tema svakom sekciji. Naša duboka neuralna mreža arhitektura nauči latentnu temu koja se uključuje tokom dokumenta. To se može uticati na klasifikaciju lokalnih tema iz prostog teksta i segmentiranje dokumenta na promjenama tema. Osim toga, mi doprinosimo WikiSection, javno dostupni podaci koji su postavljeni sa 242k odjela na engleskom i njemačkom iz dva različita domena: bolesti i gradova. Iz naše široke procjene 20 arhitektura, prijavili smo najviši rezultat od 71,6% F1 za segmentaciju i klasifikaciju 30 tema iz domena engleskog grada, koje je rezultirao naš dugoročni model sjećanja SECTOR a sa integracijama Bloom filtra i dvodirektivnom segmentacijom. Ovo je značajno poboljšanje 29,5 bodova F1 preko državnih CNN klasifikatora sa početnim segmentacijom.', 'sv': 'När man söker information tittar en mänsklig läsare först på ett dokument, upptäcker relevanta avsnitt och fokuserar sedan på några meningar för att lösa hennes avsikt. Den höga variationen i dokumentstrukturen komplicerar dock identifieringen av det viktiga ämnet i ett givet avsnitt i en blick. För att möta denna utmaning presenterar vi SECTOR, en modell som stöder maskinlässystem genom att segmentera dokument i sammanhängande avsnitt och tilldela ämnesetiketter till varje avsnitt. Vår djupa neurala nätverksarkitektur lär sig ett latent ämne inbäddning under loppet av ett dokument. Detta kan användas för att klassificera lokala ämnen från vanlig text och segmentera ett dokument vid ämnesskift. Dessutom bidrar vi med WikiSection, en allmänt tillgänglig datauppsättning med 242k märkta avsnitt på engelska och tyska från två olika domäner: sjukdomar och städer. Från vår omfattande utvärdering av 20 arkitekturer rapporterar vi en högsta poäng på 71,6% F1 för segmentering och klassificering av 30 ämnen från den engelska stadsdomänen, betygsatt av vår SECTOR-modell med lång korttidsminne med Bloom filter inbäddningar och tvåriktad segmentering. Detta är en signifikant förbättring med 29,5 poäng F1 jämfört med toppmoderna CNN-klassificerare med baslinjesegmentering.', 'si': 'තොරතුරු හොයාගන්න, මිනිස්සු කියවන්න පුළුවන් ලිපිණියක් ගැන බලන්න, සම්බන්ධතාවක් තියෙන්න, ඊට පස්සේ එයාගේ අදහ නමුත්, විශේෂයේ වෙනස් වෙනස් විදියට පරික්ෂා කරන්න පුළුවන් විදියට දෙන්න ප්\u200dරශ්නයක් බලන්න. මේ අභ්\u200dයානය සටන් කරන්න, අපි SECTOR වෙනුවෙන්, පද්ධතිය කියවන්න පද්ධතිය සහයෝගයක් සඳහා පද්ධතිය සඳහා පද්ධතිය සඳහා ප්\u200dරශ් අපේ ගොඩක් න්\u200dයුරෝල් ජාල විද්\u200dයාපෘතිය සිද්ධ විද්\u200dයාපෘතියක් ලේස්තුවක් ඉගෙන ගන්නවා. මේක ස්ථානික ප්\u200dරශ්න විදේශ පරීක්ෂණය කරන්න පුළුවන් විදිහට ස්ථානික පාළුවන් සහ විදිහට විදිහට ඒ වගේම, අපි විකිසෙක්ෂන් එක්ක ප්\u200dරතිකාරයෙන් පිළිගන්න පුළුවන් දත්ත සම්බන්ධයෙන් ඉංග්\u200dරීසි සහ ජර්මන් වලින්  අපේ විශාල විශ්වාස 20 විශ්වාසයෙන්, අපි 71.6% F1 විශ්වාස කරනවා ඉංග්\u200dරීසි නගරය ඩොමේනියෙන් විශ්වාස 30 විශ්වාස කරනවා, අපේ SECTOR ලොකු කාලකාල මතක මතක මදුල් ම මේක තමයි 29.5 පින්තූර F1 විශේෂ විශේෂයෙන් විශේෂ කරන්නේ නිර්මාණයේ ක්\u200dරියාත්මක CNN ක්\u200dරියාසිකරුවන්ග', 'ta': 'தகவலை தேடும் போது, ஒரு மனிதன் படிப்பான் ஆவணத்திற்கு முதல் பார்வையை தேடும், தொடர்பு பிரிவுகளை பார்க்கும், பின்னர் சில வாக்குகள ஆயினும், அதிக ஆவண அமைப்புகளின் மாறுபாடு ஒரு பார்வையில் கொடுக்கப்பட்ட பிரிவின் குறிப்பிட்ட பிரிவின் அடையா இந்த சவாலை எதிர்பார்ப்பதற்கு, நாம் SECTOR, கணினி படிக்கும் முறைமையை ஆதரிக்க ஒரு மாதிரி காண்பிக்கிறோம். ஆவணங்களை பிரித்து கொண்டு ஒவ்வொ எங்கள் ஆழமான புதிய பிணைய பிணையத்தின் கட்டுப்பாடுகள் ஒரு சமீபத்தில் உள்ள தலைப்பை ஒரு ஆவணத்தின் முறையில் சூழ் @ info: whatsthis கூடுதலாக, நாம் விகிபிரிவு, பொது கிடைக்கும் தகவல் அமைப்பு, ஆங்கிலம் மற்றும் ஜெர்மன் மொழியில் இரு வித்தியாசமான களங்களில் இருந் 20 அட்டவணைகளின் விரிவாக மதிப்பிலிருந்து, நாம் மிக அதிக மதிப்பெண்களை அறிவிக்கிறோம் 71.6% F1 ஆங்கிலத்தின் நகரத்து களத்திலிருந்து 30 தலைப்புகளை பிரித்தல் மற்றும் வகைப்படுத்தல் முறையி 29. 5 புள்ளிகள் F1 நிலையில் CNN வகுப்பாளர்களுக்கு மேலான முன்னேற்றம் உள்ளது.', 'ur': 'جب معلومات تلاش کرتے ہیں، ایک انسان پڑھنے والا پہلی بار ایک سند پر نگاہ کرتا ہے، مربوط قسموں کو جگہ دیتا ہے، پھر اس کے قصد کو حل کرنے کے لئے چند جماعتوں پر تمرکز کرتا ہے. However, the high variance of document structure complicates the identification of the salient topic of a given section at a glance. اس چال کے ساتھ ہم نے SECTOR کو ایک موڈل پیش کیا ہے جو ماشین پڑھنے کی سیستموں کی مدد کرتا ہے، سندھائے مہینٹ کے ساتھ مہینٹ پڑھنے کی سفارش کرتا ہے اور ہر قسم کے لئے ٹوپ لیبل مقرر کرتا ہے. ہماری عمیقی نیورال نیٹ ورک معماری ایک لاٹینٹ ٹوپ سکھاتی ہے جو ایک دکھانٹ کے روسطے پر جمع ہوتی ہے۔ یہ صریح ٹیکسٹ سے محلی ٹیکسٹوں کا کلاس کرنا اور ٹیکسٹ شیفٹ پر ایک ڈیکسٹم ٹیکسٹ کرنا ہے۔ اس کے علاوہ ہم ویکیسکیٹ کا حصہ ادا کریں گے، ایک کھلی طور پر موجود ڈیٹ سٹ کے ساتھ 242k لکیٹے ٹکٹ انگلیسی اور جرمن میں دو مختلف ڈومین سے، بیماری اور شہروں سے۔ ہمارے 20 معماروں کی وسیع ارزیابی سے ہم 71.6% F1 کے سب سے زیادہ اسکور کو انگلیسی شہر ڈمین سے 30 موضوعوں کا سکونٹ اور کلاسپینٹ کے لئے گزارتے ہیں، جو بلوم فیلٹر ڈیمڈینگ کے ساتھ ہمارے SECTOR کی طویل مدت مہمانی موڈل کے ذریعہ سے سکونٹ کیا گیا ہے۔ This is a significant improvement of 29.5 points F1 over state-of-the-art CNN classifiers with baseline segmentation.', 'uz': "Agar maʼlumotni qidirishda, oddiy oʻquvchi qoʻlboladan birinchi ko'rinadi, muhim qismlarni ko'radi va keyin u qancha bir so'zlarni qidirish uchun foydalanadi. However, the high variance of document structure complicates the identification of the salient topic of a given section at a glance.  Bu murakkab qilishga, biz SECTOR, mashinani o'qish tizimini qoʻllash modelini bir nechta qismlarga qoʻllash va mavzu tegnlarini har bir qismlarga qoʻllash mumkin. Bizning juda yaxshi neyron tarmoq muammosi hujjat davomida keladigan mavzuni o'rganadi. Name Ko'pchilik, biz WikiSection'ga bog'liq maʼlumot tarkibi, ingliz tilidagi 242k qismlar va Olmonchadan ikki alohida qo'llangan ikki xil domani: kasallik va шаҳарлар. 20 arxivlar davomida qiymatimizdan, biz Ingliz шаҳарда 30 muammolarni ajratish va darajalashtirish uchun eng yuqori darajaga 71.6% F1 haqida xabar beramiz, biz SECTOR xotira modeli bilan boshqa qisqa paydo bo'ladigan, Bloom filterning qismlari va bir qanchalik qismlari bilan boshlanamiz. Bu 29.5 nuqta F1 dan birinchi darajali CNN turli darajalari bilan birinchi darajali ajratish imkoniyati.", 'vi': 'Khi tìm kiếm thông tin, người đọc nhìn vào một tài liệu, phát hiện những phần liên quan, và tập trung vào vài câu để giải quyết ý định của cô ta. Tuy nhiên, sự thay đổi lớn của cấu trúc tài liệu phức tạp việc xác định được chủ đề chính của một phần cụ thể chỉ trong nháy mắt. Để đối phó với thách thức này, chúng tôi giới thiệu một loại mô hình để hỗ trợ hệ thống đọc máy bằng cách chia tài liệu vào các khu vực liên quan và đặt nhãn đề tài liệu vào mỗi phần. Kiến trúc mạng thần kinh sâu thẳm của chúng tôi học một chủ đề tiềm ẩn được thêm vào một tài liệu. Việc này có thể được dùng để phân loại các chủ đề địa phương từ văn bản thường và phân đoạn một tài liệu tại các thay đổi chủ đề. Thêm vào đó, chúng tôi đóng phần dữ liệu sẵn sàng công khai với phần 242k được đánh dấu bằng tiếng Anh và Đức từ hai miền khác nhau: bệnh và thành phố. Từ sự đánh giá phong phú của nhà kiến trúc 20, chúng tôi báo cáo điểm cao nhất của 71.6=. F1 cho việc phân loại và phân loại 9m các chủ đề khỏi miền thành phố Anh Quốc, được đánh dấu bởi mô hình bộ nhớ ngắn hạn của chúng tôi, với sự nhúng bộ lọc Bloom và phân biệt trực tiếp. Đây là một cải tiến đáng kể của 29.5 các điểm F1 so với các phân loại CNN hiện đại với phân chia cơ sở.', 'bg': 'Когато търси информация, човек читател първо поглежда към документ, забелязва съответните раздели и след това се фокусира върху няколко изречения за решаване на намерението си. Въпреки това, високата вариация на структурата на документа усложнява идентифицирането на важната тема на даден раздел с един поглед. За да се справим с това предизвикателство, представяме модел за подпомагане на системите за машинно четене чрез сегментиране на документите в съгласувани раздели и определяне на тематични етикети за всеки раздел. Нашата дълбока невронна мрежа архитектура научава латентна тема вграждане по време на документа. Това може да бъде използвано за класифициране на локални теми от обикновен текст и сегментиране на документ при сменяне на темите. В допълнение, ние допринасяме за Уикисекция, публично достъпен набор от данни с 242к раздели на английски и немски език от две различни области: болести и градове. От нашата обширна оценка на 20 архитектури, ние отчитаме най-висок резултат от 71.6% за сегментацията и класификацията на 30 теми от английския градски домейн, оценени от нашия модел за дългосрочна краткосрочна памет със вградени филтри и двупосочна сегментация. Това е значително подобрение от 29,5 точки спрямо най-съвременните класификатори с базова сегментация.', 'nl': 'Bij het zoeken naar informatie kijkt een menselijke lezer eerst naar een document, ziet relevante secties en richt zich vervolgens op een paar zinnen om haar intentie op te lossen. De grote variatie in de documentstructuur bemoeilijkt echter de identificatie van het belangrijkste onderwerp van een bepaalde sectie in één oogopslag. Om deze uitdaging aan te pakken, presenteren we SECTOR, een model om machine reading systemen te ondersteunen door documenten te segmenteren in coherente secties en topic labels toe te wijzen aan elke sectie. Onze diepe neurale netwerkarchitectuur leert een latent onderwerp inbedden in de loop van een document. Dit kan worden gebruikt om lokale onderwerpen te classificeren uit platte tekst en een document te segmenteren bij onderwerpen verschuivingen. Daarnaast dragen we WikiSection bij, een publiek toegankelijke dataset met 242k gelabelde secties in het Engels en Duits uit twee verschillende domeinen: ziekten en steden. Uit onze uitgebreide evaluatie van 20-architecturen, rapporteren we een hoogste score van 71,6% F1 voor de segmentatie en classificatie van 30 onderwerpen uit het Engelse stadsdomein, gescoord door ons SECTOR long-term memory model met Bloom filter embeddings en bidirectionele segmentatie. Dit is een significante verbetering van 29,5 punten F1 ten opzichte van state-of-the-art CNN classificatoren met baseline segmentatie.', 'da': 'Når man søger information, kigger en menneskelig læser først på et dokument, spotter relevante afsnit og fokuserer derefter på nogle få sætninger til at løse hendes hensigt. Men den høje variation i dokumentstruktur komplicerer identifikationen af det vigtigste emne i et givet afsnit på et øjeblik. For at tackle denne udfordring præsenterer vi SECTOR, en model, der understøtter maskinlæsesystemer ved at segmentere dokumenter i sammenhængende sektioner og tildele emneotiketter til hver sektion. Vores dybe neurale netværksarkitektur lærer et latent emne indlejring i løbet af et dokument. Dette kan bruges til at klassificere lokale emner ud fra almindelig tekst og segmentere et dokument ved emneskift. Derudover bidrager vi med WikiSection, et offentligt tilgængeligt datasæt med 242k mærkede sektioner på engelsk og tysk fra to forskellige domæner: sygdomme og byer. Fra vores omfattende evaluering af 20 arkitekturer rapporterer vi en højeste score på 71,6% F1 for segmentering og klassificering af 30 emner fra det engelske bydomæne, scoret af vores SECTOR langtidshukommelsesmodel med Bloom filter indlejringer og bidirektionel segmentering. Dette er en betydelig forbedring på 29,5 point F1 i forhold til state-of-the-art CNN klassifikationer med baseline segmentering.', 'hr': 'Kada traži informacije, ljudski čitač prvi pogleda na dokument, stavlja relevantne dijelove i onda se fokusira na nekoliko rečenica za rješavanje njene namjere. Međutim, visoka varijancija strukture dokumenta komplicira identifikaciju salijente teme određenog dijela na pogledu. Za rješavanje ovog izazova predstavljamo SECTOR model za podršku sustava čitanja strojeva sadržavajući dokumente u sasluženim dijelovima i dodavajući temske etikete svakom dijelu. Naša duboka arhitektura neuronske mreže nauči latentnu temu koja se uključuje tijekom dokumenta. To se može uticati na klasifikaciju lokalnih tema iz običnog teksta i segmentiranje dokumenta na promjenama teme. Osim toga, doprinosimo WikiSection-u, javno dostupnim podacima koje su postavljene s 242k dijelovima označene na engleskom i njemačkom iz dva različita domena: bolesti i gradova. Iz naše široke procjene 20 arhitektura, prijavili smo najviši rezultat od 71,6% F1 za segmentaciju i klasifikaciju 30 tema iz domena engleskog grada, koje je rezultirao naš kratkoročni model sjećanja SECTOR-a s integracijama Bloom filtra i dvodirektivnom segmentacijom. To je značajno poboljšanje 29,5 bodova F1 nad državnim CNN klasifikatorima s početnim segmentacijom.', 'de': 'Bei der Suche nach Informationen blickt ein menschlicher Leser zuerst auf ein Dokument, entdeckt relevante Abschnitte und konzentriert sich dann auf ein paar Sätze, um seine Absicht zu lösen. Die hohe Varianz der Dokumentenstruktur erschwert jedoch die Identifizierung des wichtigsten Themas eines bestimmten Abschnitts auf einen Blick. Um diese Herausforderung anzugehen, stellen wir SECTOR vor, ein Modell zur Unterstützung maschineller Lesesysteme, indem Dokumente in zusammenhängende Abschnitte unterteilt und jedem Abschnitt Themenbezeichnungen zugewiesen werden. Unsere Deep Neuronal Network Architektur lernt im Laufe eines Dokuments ein latentes Thema Einbettung. Dies kann genutzt werden, um lokale Themen aus Klartext zu klassifizieren und ein Dokument bei Themenverschiebungen zu segmentieren. Darüber hinaus tragen wir WikiSection bei, einen öffentlich zugänglichen Datensatz mit 242k markierten Abschnitten in Englisch und Deutsch aus zwei verschiedenen Domänen: Krankheiten und Städte. Aus unserer umfangreichen Evaluation von 20-Architekturen berichten wir einen Höchstwert von 71,6% F1 für die Segmentierung und Klassifizierung von 30-Themen aus dem englischen Stadtgebiet, bewertet durch unser SECTOR-Langzeitgedächtnismodell mit Bloom-Filtereinbettungen und bidirektionaler Segmentierung. Dies ist eine signifikante Verbesserung von 29,5-Punkten F1 gegenüber modernen CNN-Klassifikatoren mit Baseline-Segmentierung.', 'id': 'Ketika mencari informasi, seorang pembaca manusia melihat pertama dokumen, melihat bagian yang relevan, dan kemudian fokus pada beberapa kalimat untuk memecahkan tujuannya. Namun, variasi tinggi struktur dokumen menyulitkan identifikasi topik utama bagi bagian tertentu pada pandangan. Untuk mengatasi tantangan ini, kami mempersembahkan SECTOR, model untuk mendukung sistem pembacaan mesin dengan segmen dokumen ke bagian yang konsisten dan menyerahkan label topik ke setiap bagian. Arkitektur jaringan saraf dalam kita mempelajari topik tersembunyi yang terlibat dalam perjalanan dokumen. This can be leveraged to classify local topics from plain text and segment a document at topic shifts.  Selain itu, kami berkontribusi WikiSection, set data yang tersedia publik dengan 242k bagian yang ditabel dalam bahasa Inggris dan Jerman dari dua daerah yang berbeda: penyakit dan kota. Dari evaluasi ekstensif kami dari 20 arsitektur, kami melaporkan skor tertinggi 71,6% F1 untuk segmen dan klasifikasi 30 topik dari daerah kota Inggris, yang dicatat oleh model memori jangka pendek SECTOR kami dengan penerbangan filter Bloom dan segmen bidireksi. Ini adalah peningkatan signifikan dari 29,5 poin F1 atas klasifikasi CNN state-of-the-art dengan segmentasi dasar.', 'sw': 'Wakati akitafuta taarifa, msomaji wa binadamu anaangalia kwa mara ya kwanza kwenye nyaraka, anaona sehemu zinazohusiana, na kisha anazitia makini kwenye sentensi chache kwa kutatua nia yake. Hata hivyo, tofauti kubwa ya muundo wa nyaraka inachanganya utambulisho wa mada ya mgonjwa wa kipande kinachopewa kwa tazama. Ili kukabiliana na changamoto hili, tunawasilisha SECTOR, modeli ya kuunga mkono mfumo wa kusoma mashine kwa kugawanya nyaraka katika sekta za pamoja na kuweka alama za mada kwa kila sehemu. Ujengo wetu wa ndani wa mtandao wa neura unajifunza mada ya hivi karibuni yanayoingia katika kipindi cha nyaraka. Hii inaweza kusambaza mada za maeneo kutoka kwa ujumbe wa wazi na kugawanya nyaraka wakati wa mabadiliko ya mada. Zaidi ya hayo, tunachangia WikiSection, taarifa zinazopatikana hadharani zinazowekwa na vipande 242 vilivyowekwa kwa lugha ya Kiingereza na Kijerumani kutoka maeneo mawili tofauti: magonjwa na miji. Kutokana na tathmini zetu kwa kiasi kikubwa wa majengo 20, tunaripoti kiwango kikubwa cha asilimia 71.6 F1 kwa ajili ya kutenganisha na kutanganisha mada 30 kutoka ndani ya jiji la Kiingereza, kinachochezwa na modeli ya kumbukumbu yetu ya muda mrefu kwa kutumia mfumo wa mfumo wa mabomu na kuchangwa kwa vigogo vya kiuchumi. Hii ni maendeleo makubwa ya pointi 29.5 ya F1 juu ya wataalamu wa aina ya sanaa wa CNN wenye sehemu ya msingi.', 'tr': "Maglumat gözleýände, adam okuwçysy ilkinji gezek bir sened üstünde gözleýän, nähili bölekler üçin üns berýär we soňra maksadyny çözmek üçin birnäçe sözlere üns berýär. Ýöne, sened düzümleriniň ýokary üýtgeşigi berilen bölegiň salient meýdanynyň tanymyny çarpýar. Bu kynçylygy çözmek üçin SEKTOR'y görkezip, senedi kohereket bölgelere segmentleýän we her bölüme tema etitlerini taýýarlamak üçin bir nusga görkezip. Biziň gaty nuýral a ýry arhitekterimiz senediň ýüzünde soňky bir tema öwrenýär. Bu ýer meýdançalary saýla metin we senedi meýdançasynda çaplamak üçin mümkin edip biler. Mundan soňra WikiSection'a, 242k sany iňlis we Almança dilinde etilen bölmeler bilen publikak meňzeş maglumatlar goşulýarys: hasaplar we şäherlerden. 20 arhitekturyň ýokary deňlenmesinden 71.6% F1 iňlis şäheriň domenynyň segmentasy we klasifikasy üçin iňlis şäheriň 30 temasynyň iň ýokary derejesinden berilýäris we ol biziň SECTORymyzyň ýokary gijä wagt ýazma nusgasymyz bilen bellenilýär. Bu CNN sanat segmentasy bilen 29.5 punkt F1 derejesinde möhüm gelişmektedir.", 'ko': '정보를 검색할 때 인류 독자는 먼저 문서를 훑어보고 관련 부분을 찾아낸 다음에 몇 마디 말로 그녀의 의도를 해결한다.그러나 문서 구조의 높은 차이로 인해 한 눈에 주어진 장과 절의 현저한 주제를 식별할 수 있어 복잡해졌다.이 도전에 대응하기 위해 우리는 SECTOR를 제기했다. 이것은 기계 읽기 시스템을 지원하는 모델로 문서를 일관된 부분으로 나누고 각 부분에 주제 라벨을 분배한다.우리의 심층 신경 네트워크 구조는 문서 과정에서 잠재적인 주제를 배운다.이것은 순수한 텍스트에서 로컬 테마를 분류하고 테마가 변환될 때 문서를 분할하는 데 사용할 수 있습니다.또한 두 분야(질병과 도시)에서 온 영어와 독일어 표기 242k개를 포함하는 공개 데이터 세트를 제공합니다.20개 건축에 대한 광범위한 평가에서 우리는 영어 도시 분야 30개 주제의 분할과 분류의 최고 점수가 71.6%F1이라고 보고했다. 이 점수는 블룸 필터를 끼워넣고 양방향으로 분할하는 부서의 장기 단기 기억 모델에서 나온 것이다.최첨단 CNN 분류기와 비교하면 29.5점의 눈에 띄는 개선이다.', 'fa': 'وقتی دنبال اطلاعات جستجو می\u200cکند، یک خواننده انسان اول از یک سند نگاه می\u200cکند، بخش\u200cهای مربوط به آن، و سپس روی چند جمله برای حل قصد او تمرکز می\u200cکند. با این حال، تغییر بالا از ساختار سند شناسایی موضوع موضوع استفاده شده را در یک نگاه پیچیده می\u200cکند. برای حل این چالش، ما یک مدل برای پشتیبانی از سیستم خواندن ماشین به عنوان جدا کردن سند\u200cها به بخش\u200cهای هماهنگ و مقرر کردن برچسب\u200cهای موضوع به هر بخش پیشنهاد می\u200cکنیم. معماری شبکه عصبی عمیق ما یک موضوع لاتین را در طول یک سند یاد می\u200cگیرد. این می\u200cتواند برای تشکیل موضوع محلی از متن معمولی و بخش یک سند در تغییرات موضوع تحویل داده شود. در addition, we contribute WikiSection, a publicly available data set with 242k labeled sections in English and German from two different domains: diseases and cities. از ارزیابی وسیع ۲۰ معماری ما، بالاترین امتیاز ۱۷.۶% F1 را برای بخش\u200cبندی و گروه\u200cبندی ۳۰ عنوان از دامنۀ شهری انگلیسی گزارش می\u200cدهیم، که توسط مدل حافظه کوتاه مدت SECTOR ما با پالایه\u200cهای فلتری بلوم و بخش\u200cبندی دوره\u200cای است. این بهترین توجه بزرگی از ۲۹.۵ نقطه F1 بر اساس شرکت\u200cکننده\u200cهای هنر سین\u200cان با جدایی\u200cهای پایین\u200cخط است.', 'af': "Wanneer om inligting te soek, 'n mensleser eerste kyk oor 'n dokument, plekke relevante seksies, en dan fokus op 'n paar setnings vir die oplossing van haar bedoeling. Maar die hoë variasie van dokumentstruktuur kompliseer die identifikasie van die salient onderwerp van 'n gegewe artikel by 'n kyk. Om hierdie uitdrukking te probeer, laat ons voorsien 'n model om masjien lees stelsels te ondersteun deur dokumente te segmenteer in koerende artikels en onderwerp etikette aan elke artikel toewys. Ons diep neuralnetwerk-arkitektuur leer 'n latente onderwerp wat binne oor die kurs van 'n dokument. Hierdie kan wees verwyder om plaaslike onderwerpe te klassifiseer van eenvoudige teks en segmenteer 'n dokument by onderwerp veranderinge. In addition, we contribute WikiSection, a publicly available data set with 242k labelled sections in English and German from two distinct domains: diseases and cities. Van ons uitbreidige evaluering van 20 arkitektuurs, rapporteer ons 'n hoogste telling van 71.6% F1 vir die segmentasie en klasifikasie van 30 onderwerpe van die Engels stad domein, wat deur ons SECTOR lank kort-tydelike geheue model met Bloom filter inbettings en bidireksjonale segmentasie gegee het. Hierdie is 'n betekende verbetering van 29.5 punte F1 oor staat-van-kuns CNN klassifiseerders met basisline segmentasie.", 'sq': 'Kur kërkon informacion, një lexues njerëzor shikon së pari mbi një dokument, vë në pikë seksione të rëndësishme dhe pastaj përqëndrohet në disa fjalë për zgjidhjen e qëllimit të saj. Megjithatë, varianca e lartë e strukturës së dokumentit komplikon identifikimin e temës së rëndësishme të një seksioni të caktuar në një sy. To tackle this challenge, we present SECTOR, a model to support machine reading systems by segmenting documents into coherent sections and assigning topic labels to each section.  Arkitektura jonë e rrjetit nervor të thellë mëson një temë të fshehtë të përfshirë gjatë një dokumenti. Kjo mund të përdoret për të klasifikuar temat lokale nga teksti i thjeshtë dhe për të segmentuar një dokument në ndryshime tematike. In addition, we contribute WikiSection, a publicly available data set with 242k labeled sections in English and German from two distinct domains: diseases and cities.  Nga vlerësimi ynë i gjerë i 20 arkitekturave, raportojmë një pikë më të lartë prej 71.6% F1 për segmentimin dhe klasifikimin e 30 temave nga domenia e qytetit anglez, të shënuar nga modeli ynë i kujtesës afat-shkurtër SECTOR me përfshirje të filtrave Bloom dhe segmentimin dy-drejtues. Kjo është një përmirësim i rëndësishëm prej 29.5 pikësh F1 mbi klasifikuesit e CNN-së më të lartë me segmentimin bazë.', 'hy': 'Ինֆորմացիա փնտրելիս մարդ կարդացողը նայում է փաստաթղթի վրա, կենտրոնանում է նշանակալի հատվածներ, հետո կենտրոնանում է մի քանի նախադասությունների վրա, որպեսզի լուծի իր մտադրությունը: Այնուամենայնիվ, փաստաթղթի կառուցվածքի բարձր տարբերությունը դժվարանում է որոշակի հատվածի կարևոր թեման հայացքների վրա հայացք բերելը: Այս մարտահրավերի լուծման համար մենք ներկայացնում ենք SECT-ը, մի մոդել, որը օգնում է մեքենային կարդալու համակարգերին սեգմետրելով փաստաթղթերը համապատասխանատու հատվածներով և յուրաքանչյուր հատվածի թեմայի պիտակները: Մեր խորը նյարդային ցանցի ճարտարապետությունը սովորում է մի թաքնված թեմա, որը ներառվում է փաստաթղթի ընթացքում: Սա հնարավոր է օգտագործել դասակարգելու տեղական թեմաները պարզ տեքստից և բաժանելու փաստաթղթին թեմայի փոփոխությունների ժամանակ: Ավելին, մենք ներդրում ենք WiKi-բաժինը, հանրային հասանելի տվյալների համակարգը 242k-ի անգլերեն և գերմաներեն բաժիներով երկու տարբեր ոլորտներից՝ հիվանդություններից և քաղաքներից: 20 ճարտարապետության մեծ գնահատման արդյունքում մենք հայտարարում ենք 71.6 տոկոսի F1 ամենաբարձր գնահատականը Անգլերենի քաղաքի ոլորտում 30 թեմայի սեգրեգացիայի և դասակարգումների համար, որոնք գնահատվել են մեր SEկտորի երկարաժամկետ հիշողության մոդելի միջոցով Բլոմ ֆիլտրի ներդրումներով Սա 29.5 միավորի F1 նշանակալի բարելավում է CNN-ի ամենաբարձր դասակարգումների դեպքում հիմնական սեգմետրացիայով:', 'am': 'መረጃ ሲፈልግ፣ የሰው አነባቢ አስቀድሞ ወደ ሰነዱን ተመልከት፣ የተጠቃሚ ክፍል እየተመለከተ፣ ከዚያም በኋላ በአካባቢዋ ለመፈጸም በጥቂት ደረጃዎች ላይ ትክክል ያደርጋል፡፡ ነገር ግን የሰነድ አካባቢ ግንኙነት ከፍተኛ ውጤት በተሰጠው ክፍል ላይ የሚታወቀውን አካባቢ ያሳውቃል፡፡ ይህንን ምናልባት ለመቀበል፣ SECTOR፣ የሞክራዊ አካባቢ ሰነዱን ወደ ተካሄደ ክፍሎች ለመደገፍ እና ለሁሉም ክፍሎች መሳሪያ ምልክቶችን ለመደገፍ ምሳሌ እናቀርባለን፡፡ የጥልቅ የኔትርክ መረብ መሠረት አካባቢ የሰነድ ክፍል ላይ የሚወጣውን አዲስ ጉዳይ ያስተምራል፡፡ ይህ ሰነዱን በመለወጥ ላይ ማሳየት ይችላል፡፡ በተጨማሪም፣ WikiSection፣ በንግግሊዝና በጀርመን 242 ሺሕ በተለየ ውይይት የተገኘ የዳታ ክፍሎች ከሁለት ልዩ ውይይቶች፣ ደዌዎችና ከተሞችን እና እናሳርጋለን፡፡ 20 የመዝገብ ግንኙነት አካባቢዎች ከደረጃችን፣ 71.6 በመቶ F1፣ የኢንግሊዝኛ ከተማ ውይይት ውስጥ 30 ጉዳዮች መግለጫ እና መክፈቻን እናገልጻለን፡፡ ይህ የ29.5 ነጥቦች የCNN ክፍተቶችን በመስመር ግንኙነት አካባቢ የ.', 'az': "Malümatı axtardığında, insan oxuyucusu ilk dəfə belə baxır, məlumatlı bölümlərə baxır və sonra onun niyyətini çəkmək üçün bir neçə cümlələrə odaqlanır. Lakin, belə bir bölümün yüksək dəyişiklik quruluşunun tanımasını bir baxışda komplikləşdirir. Bu çətinliklə çəkilmək üçün, SECTOR'u, maşın oxumaq sistemlərini birləşdirən bölümlərə segment etmək və hər bölümə məlumat etiketlərini təyin etmək üçün modeli göstəririk. Bizim derin nöral a ğ arhitektarımız bir məsələnin üstündə olan latent məsələsini öyrənir. Bu, yerli məsələləri düz metin və məsəl dəyişikliklərindən ayırmaq üçün dəyişiklik olar. Üstəlik, WikiSection'i, İngilizce və Almanca məlumatları olan 242k məlumatları ilə a çıq-aşkar məlumatları təklif edirik: xəstəlik və şəhərlər. 20 arhitektür müəyyənləşdirilməsindən ən yüksək nöqtəsi 71,6% F1'nin İngiliz şəhər domeinindən 30 məsələlərin segmentasiyası və klasifikasiyası üçün xəbər veririk. Sənin SECTORumuzdan uzun-uzun qısa sürəkli yaddaş modeli Bloom filtr inşallarını və ikidireksiyonlu segmentasiyası ilə müəyyən edilmişdir. Bu, əsas səhifələri ilə müəyyən edilmiş CNN klasifikatının 29.5 noktalarının F1 üstündə mövcuddur.", 'bn': 'তথ্য অনুসন্ধান করার সময় একজন মানুষের পাঠক একটি নথির উপর প্রথম দৃষ্টির দিকে তাকিয়ে আছেন, যার সাথে সংশ্লিষ্ট বিভাগের দিকে দেখা যায় তবে নথির কাঠামোর উচ্চ পার্থক্য একটি দৃষ্টিতে দেখা যাচ্ছে একটি বিভাগের ব্যালেন্ট বিষয়টির পরিচিতি জটিল করে। এই চ্যালেঞ্জের মুখোমুখি হওয়ার জন্য আমরা সেক্টরের উপস্থাপন করি, মেশিন পড়তে সমর্থন করার একটি মডেল, যার মাধ্যমে ডকুমেন্ট বিভাগে বিভক্ত করে প্রত আমাদের গভীর নিউরেল নেটওয়ার্ক কাঠামো একটি সাম্প্রতিক বিষয় শিখতে পাচ্ছে যা একটি নথির কোর্সের মাধ্যমে বিভিন্ন সাধারণ টেক্সট থেকে স্থানীয় বিষয়গুলোকে স্থানীয় বিষয়গুলোকে বিভাগ করার জন্য এটি প্রাপ্ত করা যাবে এবং বিষয় পরিবর এছাড়াও আমরা উইকিসেকেটকে অবদান দিচ্ছি, যা প্রকাশ্যে পাওয়া যাচ্ছে একটি তথ্য যা ইংরেজি এবং জার্মান ভাষায় ২৪ কিছু লেবেল করা হয়েছে, যা  আমাদের ২০ সাম্প্রতিষ্ঠানের বিস্তৃত মূল্য থেকে আমরা ইংরেজি শহর ডোমেইন থেকে ৩০ বিষয় বিভক্ত এবং বিভক্তির জন্য ৭১. ৬% এফ১ এর সর্বোচ্চ স্কোর র রিপোর্ট করেছি, যা আমাদের সেকেটর দীর্ঘ মেমর ২৯.', 'ca': "When searching for information, a human reader first glances over a document, spots relevant sections, and then focuses on a few sentences for resolving her intention.  Tot i així, la gran variació de l'estructura dels documents complica la identificació del tema salient d'una secció dada. Per afrontar aquest repte, presentem SECTOR, un model que suporta els sistemes de lectura màquina segmentant els documents en seccions coherents i asignant etiquetes temàtiques a cada secció. La nostra arquitectura profunda de la xarxa neuronal aprenen un tema latent incorporat al llarg d'un document. Això pot ser utilitzat per classificar temes locals de text senzill i segmentar un document en canvis de tema. A més, contribuïm a WikiSection, un conjunt de dades disponibles al públic amb 242k de seccions etiquetades en anglès i alemany de dos dominis distints: malalties i ciutats. A partir de la nostra extensa evaluació de 20 arquitectures, reportem una puntuació més alta del 71,6% F1 per la segmentació i classificació de 30 temes del domini de la ciutat anglesa, puntuada pel nostre model de memòria a curt termini SECTOR amb incorporacions de filtres Bloom i segmentació bidireccional. Això és una millora significativa de 29,5 punts F1 sobre els classificadors CNN més avançats amb segmentació basal.", 'bs': 'Kada traži informacije, ljudski čitač prvi pogleda na dokument, stavlja relevantne sekcije, a onda se fokusira na nekoliko rečenica za rješavanje njene namjere. Međutim, visoka varijancija strukture dokumenta komplicira identifikaciju salijente teme određenog dijela na pogledu. Da bi se riješili ovaj izazov, predstavljamo SECTOR model za podršku sustava čitanja mašina, segmentirajući dokumente u saslužene dijelove i dodavajući etikete tema svakom dijelu. Naša duboka arhitektura neuronske mreže nauči latentnu temu koja se uključuje tokom dokumenta. To se može uticati na klasifikaciju lokalnih tema iz prostog teksta i segmentiranje dokumenta na promjenama teme. Osim toga, mi doprinosimo WikiSection-u, javno dostupnim podacima koje su postavljene sa 242k dijelova označene na engleskom i njemačkom iz dva različita domena: bolesti i gradova. Iz naše široke procjene 20 arhitektura, izvještavamo najviši rezultat od 71,6% F1 za segmentaciju i klasifikaciju 30 tema iz domena engleskog grada, koje je rezultirao naš dugoročni model sjećanja SECTOR-a sa integracijama Bloom filtra i dvodirektivnom segmentacijom. To je značajno poboljšanje 29,5 bodova F1 nad državnim CNN klasifikatorima s početnim segmentacijom.', 'cs': 'Při hledání informací se čtenář nejprve podívá na dokument, všimne relevantních částí a poté se soustředí na několik vět k vyřešení svého záměru. Vysoká odchylka struktury dokumentů však komplikuje identifikaci významného tématu dané sekce na první pohled. Pro řešení této výzvy představujeme model SECTOR, který podporuje systémy strojového čtení segmentováním dokumentů do soudržných sekcí a přiřazováním popisků témat každé sekci. Naše hluboká architektura neuronové sítě se naučí latentní téma vložení v průběhu dokumentu. To lze využít k klasifikaci místních témat z prostého textu a segmentování dokumentu při posunu témat. Kromě toho přispíváme WikiSection, veřejně dostupnou datovou sadu s 242k označenými sekcemi v angličtině a němčině ze dvou odlišných domén: chorob a měst. Z našeho rozsáhlého hodnocení 20-architektur vykazujeme nejvyšší skóre 71,6% F1 pro segmentaci a klasifikaci 30 témat z anglické městské domény, hodnocené naším modelem dlouhodobé paměti SECTOR s vložením filtru Bloom a obousměrnou segmentací. Jedná se o významné zlepšení 29,5 bodů F1 oproti nejmodernějším klasifikátorům CNN s výchozí segmentací.', 'et': 'Teavet otsides vaatab inimlugeja esmalt üle dokumendi, märkab asjakohaseid jaotisi ja keskendub seejärel mõnele lausele oma kavatsuse lahendamiseks. Dokumendi struktuuri suur erinevus raskendab aga konkreetse jaotise olulise teema tuvastamist. Selle probleemi lahendamiseks tutvustame mudelit SECTOR, mis toetab masinlugemise süsteeme, segmenteerides dokumendid sidusateks jaotisteks ja määrates teemamärgised igale jaotisele. Meie sügava närvivõrgu arhitektuur õpib dokumendi käigus varjatud teema manustamist. Seda saab kasutada kohalike teemade klassifitseerimiseks lihttekstist ja dokumendi segmendimiseks teemavahetuste ajal. Lisaks aitame kaasa WikiSection, avalikult kättesaadav andmekogum, mis sisaldab 242k inglise- ja saksakeelseid sektsioone kahest erinevast valdkonnast: haigused ja linnad. Meie 20 arhitektuuri ulatusliku hindamise põhjal on meil Inglise linnadomeeni 30 teema segmenteerimise ja klassifitseerimise tulemus 71,6% F1, mis on hinnatud meie SECTORi pikaajalise lühiajalise mälu mudeli poolt Bloomi filtri manustamise ja kahesuunalise segmenteerimisega. See tähendab olulist paranemist 29,5 punkti F1 võrra võrreldes tipptasemel CNN klassifikaatoritega, mis on algtaseme segmenteeritud.', 'fi': 'Etsiessään tietoa ihmislukija vilkaisee ensin asiakirjaa, huomaa relevantteja osioita ja keskittyy sitten muutamaan lauseeseen tarkoituksensa ratkaisemiseksi. Asiakirjarakenteen suuri vaihtelu vaikeuttaa kuitenkin tietyn osion keskeisen aiheen tunnistamista yhdellä silmäyksellä. Tämän haasteen ratkaisemiseksi esittelemme SECTOR-mallin, joka tukee konelukujärjestelmiä segmentoimalla asiakirjat johdonmukaisiksi osiksi ja jakamalla aiheotsikot kuhunkin osioon. Syvän neuroverkkoarkkitehtuurimme oppii piilevän aiheen upottamisen dokumentin aikana. Tätä voidaan hyödyntää luokittelemaan paikalliset aiheet tavallisesta tekstistä ja segmentoimaan asiakirjan aihepiirinvaihdoksissa. Lisäksi osallistumme WikiSection, julkisesti saatavilla oleva tietokokonaisuus, jossa on 242k englannin- ja saksankielisiä osioita kahdesta eri alueesta: sairaudet ja kaupungit. Laajasta 20 arkkitehtuurin arvioinnista raportoimme korkeimman 71,6% F1 segmentoinnista ja luokittelusta 30 aihepiirin englanninkielisestä kaupunkialueesta. SECTOR:n lyhyen aikavälin muistimallimme Bloom-suodatinupotuksilla ja kaksisuuntaisella segmentoinnilla on pistemäärä. Tämä on merkittävä parannus 29,5 pisteellä F1 verrattuna viimeisimpiin CNN-luokituksiin, joissa on lähtötilanteen segmentointi.', 'jv': 'Where\'s that politenessoffpolite"), and when there is a change ("assertivepoliteness Ngawe kang nggawe perbudhakan iki, kita nambah SEKTOR, model kanggo nggunakake sistem basa gambar nggawe Dokumen seneng pisan seneng pisan kanggo nggawe etiket tema kanggo saben sektor. Arkirektur sing dibungan uwong kelas nang sampek Kasama sing dumateng rambarang text-tool-action Nambah, awak dhéwé nyubagi Wikseksi, data yang dipunangé kanggo nyebutané karo 24k sing nganggo sekolahan kanggo inggiles karo aleman sing sampek duruh sabên: sak karo kalungé. We report a extreme number of 75.6% F1 for the segmentation and category of 30 Iki lunak akeh bantuan kanggo ngertuangan atus 30.5 puntuan F1 kuwi duluran-atus" sing basa sampek dadi sing perusahaan banget.', 'sk': 'Pri iskanju informacij človeški bralec najprej pogleda na dokument, opazi ustrezne dele in se nato osredotoči na nekaj stavkov za rešitev svojega namena. Vendar pa velika razlika strukture dokumenta otežuje prepoznavanje pomembne teme danega oddelka na prvi pogled. Za reševanje tega izziva predstavljamo SECTOR, model za podporo sistemov strojnega branja z segmentacijo dokumentov v skladne dele in dodelitvijo tematskih oznak vsakemu oddelku. Naša arhitektura globokega nevronskega omrežja se med dokumentom nauči latentne teme vdelave. To je mogoče uporabiti za razvrščanje lokalnih tem iz navadnega besedila in segmentiranje dokumenta pri premikih teme. Poleg tega prispevamo WikiSection, javno dostopen nabor podatkov z 242k označenimi odseki v angleščini in nemščini iz dveh različnih področij: bolezni in mesta. Iz naše obsežne ocene 20 arhitektur poročamo o najvišji oceni 71,6% F1 za segmentacijo in klasifikacijo 30 tem iz angleške mestne domene, ocenjeni po našem modelu SECTOR dolgoročnega kratkoročnega pomnilnika z vdelavami Bloomovih filtrov in dvosmerno segmentacijo. To je znatno izboljšanje za 29,5 točke F1 v primerjavi z najsodobnejšimi klasifikatorji CNN z osnovno segmentacijo.', 'ha': "Idan za ka nẽmi taimako a kan takardar, wani karatun mutum ya farkon dũba a kan takardar, yana nuna rabo masu muhimmin, kuma yana zura fokus a kan ƙanshi kaɗan da ya raba kansa. Haƙĩƙa, juyin tsawo na tsarin takardar, ya ƙudura ganin maɓallin salon da aka bai wa wani rabin da aka yi dũbi. To, dõmin ka yi motsi ga wannan tsohon, muna halatar da shirin SANTOR, yana ƙara shirin ya ƙarfafa karatun masu karatun na ƙarƙashin kwamfyuta, kuma mu raba alama masu cikin duk section. Our deep neural network architecture learns a latent topic embedding over the course of a document.  Wannan za'a iya ƙayyade zuwa ka rarraba maɓallin lokaci daga matsayin mai sauƙin, kuma ka goge wata takardar idan an canza mazaɓa. Da wannan, Munã ƙara wa Wikisection, a bayan bayan data na da shi na daidaita da rabo 24,2k na rubũta cikin Ingiriya da Jamanya daga sauri biyu daban dabam-dabam: jiran da alƙaryun. Daga ƙidãya masu iya ƙayyade matsayin 20, za mu yi rabo matsayin tsohon 71.6% F1 zuwa rabon da aka rarraba matsayin 30 masu cikin birnin Ingiriya, an yi amfani da misalin lokacin memory na tsawo na kasar zaman lokacin da filin Bloom ke fitarwa da rabo. Wannan yana mai kyau ga 29.5 points F1 over state-of-the-art CNN-classifiers with segment-base-line.", 'he': 'כשמחפשת מידע, קורא אנושי מסתכל ראשון מעל מסמך, מרגיש חלקים רלוונטיים, ואז מתמקד בכמה משפטים לפתור את כוונתה. עם זאת, ההחלטה הגבוהה של מבנה המסמכים מסובכת את זיהוי הנושא המפורסם של חלק מסוים במבט. כדי להתמודד עם האתגר הזה, אנחנו מציגים את SECTOR, מודל לתמוך במערכות קריאה מכונות על ידי מחלקת מסמכים לחלקים תואם ארכיטקטורת הרשת העצבית העמוקה שלנו לומדת נושא מוסתר מתכנן במהלך מסמך. אפשר להשתמש בזה כדי לקlassifika נושאים מקומיים מ טקסט פשוט ומחלק מסמך במחלקות נושאים. בנוסף, אנו תורמים WikiSection, קבוצת נתונים זמינה לציבור עם 242k תווים בשם אנגלית וגרמנית משני תחומות בודדים: מחלות וערים. From our extensive evaluation of 20 architectures, we report a highest score of 71.6% F1 for the segmentation and classification of 30 topics from the English city domain, scored by our SECTOR long short-term memory model with Bloom filter embeddings and bidirectional segmentation.  זהו שיפור משמעותי של 29.5 נקודות F1 מעל מסגרי CNN מצוין ביותר עם סגמנציה בסיסית.', 'bo': 'ཆ་འཕྲིན་འཚོལ་བཤེར་བྱེད་སྐབས་ཡིག་ཆ་ལྟ་ཀློག་པ་ཞིག་གིས་ཡིག་ཆ་དང་པོ་ཞིག་ལ་བལྟ་ཀློག ཡིན་ནའང་། ཡིག་གེའི་བཟོ་བཀོད་པ་གི་མཐོ་རིམ་མཐོ་རིམ་པ་དེ་ལྟ་ཀློག To tackle this challenge, we present SECTOR, a model to support machine reading systems by segmenting documents into coherent sections and assigning topic labels to each section. ང་ཚོའི་နབ་གཞུང་གི་སྒྲིག་འཛིན་གྱི་དྲ་རྒྱ་ནི་ཡིག་ཆ་གི་འགྲོ་བཞིན་གྱི་གཏོང་མཚམས་ཤེས་བྱེད་དོ། འདི་ནི་རང་ཁུལ་གྱི་གནད་དོན་ཡིག་གི་ཡིག་གི་དང་ཡིག་གེའི་གླེང་སྒྲོམ་ནང་གི་གཏན་ཁེལ་གཏང་བ In addition, we contribute WikiSection, a publicly available data set with 242k labeled sections in English and German from two distinct domains: diseases and cities. From our extensive evaluation of 20 architectures, we report a highest score of 71.6% F1 for the segmentation and classification of 30 topics from the English city domain, scored by our SECTOR long-term memory model with Bloom filter embeddings and bidirectional segmentation. འདི་ནི་རྒྱལ་ཁབ་ཀྱི་གནས་སྟངས་CNN་ཆ་འཕྲིན་ཡོད་པའི་སྒེར་གྱི་ཚད་རྒྱལ་ཁབ་ཆེན་པོ་ཞིག་རེད།'}
{'en': 'Complex Program Induction for Querying Knowledge Bases in the Absence of Gold Programs', 'fr': "Induction à un programme complexe pour interroger des bases de connaissances en l'absence de programmes Gold", 'ar': 'برنامج تعريفي معقد للاستعلام عن قواعد المعرفة في غياب البرامج الذهبية', 'es': 'Introducción a programas complejos para consultar bases de conocimientos en ausencia de programas Gold', 'pt': 'Indução de Programa Complexo para Consultar Bases de Conhecimento na Ausência de Programas Gold', 'ja': 'ゴールドプログラムがない場合のナレッジベースを照会するための複雑なプログラム紹介', 'ru': 'Введение в комплексную программу запроса баз знаний при отсутствии золотых программ', 'zh': '访以无金牌计者知识库其杂序', 'hi': 'गोल्ड प्रोग्राम की अनुपस्थिति में नॉलेज बेस क्वेरी करने के लिए जटिल प्रोग्राम प्रेरण', 'ga': 'Ionduchtú Clár Coimpléascach chun Bonn Eolais a Cheansú maidir le hEasláithreacht Cláir Óir', 'ka': 'Name', 'hu': 'Komplex programindukció az arany programok hiányában lévő tudásbázisok lekérdezéséhez', 'it': 'Induzione complessa del programma per interrogare le basi di conoscenza in assenza di programmi Gold', 'el': 'Σύνθετη επαγωγή προγράμματος για την αναζήτηση βάσεων γνώσης κατά την απουσία προγραμμάτων χρυσού', 'lt': 'Sudėtinė programa, kuria siekiama ieškoti žinių bazių nesant aukso programų', 'kk': 'Алтын бағдарламалардың жоқ дегенде білім негізін сұрау үшін толық бағдарлама индукциясы', 'mk': 'Комплексна индукција на програмата за барање на бази на знаење во отсуството на златни програми', 'ms': 'Complex Program Induction for Querying Knowledge Bases in the Absence of Gold Programs', 'ml': 'അറിവുകളുടെ അടിസ്ഥാനങ്ങള്\u200d ചോദിക്കുന്നതിനായി കോമ്പ്ളോക്സ് പ്രോഗ്രാം നിര്\u200dണ്ണയിക്കുക', 'mt': 'Induzzjoni kumplessa tal-Programm għat-Tfittxija tal-Bażijiet tal-Għarfien fin-Nuqqas ta’ Programmi tad-Deheb', 'mn': 'Алтын программын байхгүй байдлын мэдлэг суурь сурагчдыг асуух төвөгтэй програм', 'no': 'Comment', 'ro': 'Inducția complexă a programelor pentru interogarea bazelor de cunoștințe în absența programelor de aur', 'si': 'Name', 'so': 'Induction of Complex Program for Query Bass of Knowledge in the Absence of Gold Programs', 'sv': 'Komplex programinduktion för att fråga kunskapsbas i frånvaro av guldprogram', 'ta': 'கேள்வி அறிவிப்பு அடிப்படைகளுக்கான சிக்கல் நிரல் காட்சிName', 'ur': 'گلڈ پروگراموں کے بغیر موجود علم بنسس پوچھنے کے لئے مکمل پروگرامی انڈاکٹینس', 'pl': 'Kompleksowa indukcja programu do zapytania baz wiedzy w przypadku braku programów złota', 'sr': 'Kompleks program Indukcija za pitanje znanstvenih baza u nedostatku zlatnih programa', 'uz': 'Name', 'vi': 'Cấu trúc chương trình phức tạp cho việc tìm kiếm Nhà trình mà không có chương trình Vàng', 'nl': "Complexe programmainductie voor het opvragen van kennisbases bij afwezigheid van goudprogramma's", 'bg': 'Комплексна програмна индукция за запитване на бази знания при липса на златни програми', 'da': 'Kompleks programinduktion til forespørgsel af vidensbaser i fravær af guld programmer', 'hr': 'Kompleks program Indukcija za pitanje znanstvenih baza u nedostatku zlatnih programa', 'ko': 'Gold 프로그램 없이 Knowledgebase를 조회하는 복잡한 프로그램 요약법', 'de': 'Komplexe Programminduktion zur Abfrage von Wissensbasen in Abwesenheit von Goldprogrammen', 'id': 'Induksi Program Kompleks untuk Mencari Pangkalan Pengetahuan Dalam Tanpa Program Emas', 'fa': 'برنامه\u200cی پیچیده\u200cای برای پرسیدن پایه\u200cهای علمی در غیر برنامه\u200cهای طلا', 'sw': 'Mpango wa kompyuta wa Mpango wa Kuhoji Mipango ya Ujuzi katika Kutokana na Mipango ya dhahabu', 'af': 'Kompleksie Program Induksie vir navraag van kennis Basies in die absens van Goud Programme', 'hy': 'Գիտության հիմքերի ուսումնասիրելու համար բարդ ծրագրի ինդուկցիան ոսկու ծրագրերի բացակայության դեպքում', 'tr': 'Altyn Programlaryň ýok bolmadykda bilgi bazlary soraglamak üçin kompleks programi Induksiýa', 'sq': 'Induktimi kompleks i programit për kërkimin e bazave të njohurive në mungesën e programeve të artë', 'bn': 'সোনার প্রোগ্রামগুলোর বিরুদ্ধে জ্ঞান বেস প্রশ্নের জন্য কমপ্লেক্স প্রোগ্রাম পরিচালনা', 'az': 'Altın proqramların yoxdur olmasında bilgi bazları soruşmaq üçün kompleks proqramma Induksyonu', 'am': 'ምርጫዎች', 'cs': 'Komplexní programová indukce pro dotazování znalostních bází při absenci zlatých programů', 'et': 'Keerulise programmi induktsioon teadmistebaaside pärimiseks kuldprogrammide puudumisel', 'fi': 'Monimutkainen ohjelma tietokantojen kyselyyn Gold-ohjelmien puuttuessa', 'ca': 'Complex Program Induction for Querying Knowledge Bases in the Absence of Gold Programs', 'bs': 'Kompleks program Indukcija za pitanje baza znanja u odsustvu zlatnih programa', 'jv': 'Ngubah Program Daftar Softar kanggo Kebebasan Bilih Daftar nang Apakumentar Program Golus', 'ha': "Yi Shirin Ayuka na Complex wa Fara Masa Sani'a cikin Ƙara na Shiryoyin Ayuka na Gul", 'he': 'תוכנית מורכבת למחקר בסיסי ידע בנעדרת תוכניות זהב', 'sk': 'Kompleksna indukcija programa za poizvedbo baz znanja v odsotnosti zlatih programov', 'bo': 'མཇུག་བསྡུ་བའི་བྱ་རིམ་Induction for Querying Knowledge Bases in the absence of Gold Programs'}
{'en': 'Recent years have seen increasingly complex question-answering on knowledge bases (KBQA) involving logical, quantitative, and comparative reasoning over KB subgraphs. Neural Program Induction (NPI) is a pragmatic approach toward modularizing the reasoning process by translating a complex natural language query into a multi-step executable program. While NPI has been commonly trained with the ‘‘gold’’ program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain. There, practically only natural language queries and the corresponding answers can be provided for training. The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes NPI for KBQA ambitious and challenging. We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type. CIPITR solves complex KBQA considerably more accurately than key-value memory networks and neural symbolic machines (NSM). For moderately complex queries requiring 2- to 5-step programs, CIPITR scores at least 3 higher F1 than the competing systems. On one of the hardest class of programs (comparative reasoning) with 510 steps, CIPITR outperforms NSM by a factor of 89 and memory networks by 9 times.', 'es': 'En los últimos años se ha observado una respuesta a preguntas cada vez más compleja en las bases de conocimientos (KBQA) que implican un razonamiento lógico, cuantitativo y comparativo sobre los subgráficos KB. La inducción de programas neuronales (NPI) es un enfoque pragmático para modular el proceso de razonamiento mediante la traducción de una consulta compleja de lenguaje natural en un programa ejecutable de varios pasos. Si bien NPI ha sido entrenado comúnmente con el programa «oro» o su boceto, para aplicaciones realistas de KBQA, estos programas de oro son costosos de obtener. Allí, prácticamente solo se pueden proporcionar consultas en lenguaje natural y las respuestas correspondientes para la formación. La explosión combinatoria resultante en el espacio del programa, junto con las recompensas extremadamente escasas, hacen que el NPI para KBQA sea ambicioso y desafiante. Presentamos Inducción al Programa Imperativo Complejo de Recompensas de Terminal Rewards (CIPITR), un programador neuronal avanzado que mitiga la dispersión de recompensas con recompensas auxiliares y restringe el espacio del programa para corregir semánticamente los programas utilizando restricciones de alto nivel, el esquema KB y el tipo de respuesta inferido. CIPITR resuelve KBQA complejos de forma considerablemente más precisa que las redes de memoria clave-valor y las máquinas neuronales simbólicas (NSM). Para consultas moderadamente complejas que requieren programas de 2 a 5 pasos, CIPITR obtiene una puntuación de F1 al menos 3 veces más alta que los sistemas de la competencia. En una de las clases de programas más difíciles (razonamiento comparativo) con 5 a 10 pasos, CIPITR supera a NSM en un factor de 89 y a las redes de memoria en 9 veces.', 'ar': "شهدت السنوات الأخيرة إجابة متزايدة للأسئلة على قواعد المعرفة (KBQA) تتضمن التفكير المنطقي والكمي والمقارن على الرسوم البيانية الفرعية لـ KB. تحريض البرنامج العصبي (NPI) هو نهج عملي نحو تعديل عملية التفكير من خلال ترجمة استعلام لغة طبيعية معقد إلى برنامج تنفيذي متعدد الخطوات. بينما تم تدريب NPI بشكل عام باستخدام برنامج `` gold '' أو الرسم التخطيطي الخاص به ، بالنسبة لتطبيقات KBQA الواقعية ، فإن مثل هذه البرامج الذهبية باهظة الثمن للحصول عليها. هناك ، من الناحية العملية ، يمكن تقديم استفسارات اللغة الطبيعية فقط والإجابات المقابلة للتدريب. الانفجار الاندماجي الناتج في مساحة البرنامج ، إلى جانب المكافآت المتفرقة للغاية ، يجعل NPI لـ KBQA طموحًا وصعبًا. نقدم استقراء البرنامج الحتمي المعقد من المكافآت الطرفية (CIPITR) ، وهو مبرمج عصبي متقدم يخفف من تباين المكافآت بمكافآت إضافية ، ويحد من مساحة البرنامج إلى البرامج الصحيحة دلاليًا باستخدام قيود عالية المستوى ، ومخطط KB ، ونوع الإجابة المستنتج. يحل CIPITR KBQA المعقدة بشكل أكثر دقة بكثير من شبكات الذاكرة ذات القيمة الرئيسية والآلات الرمزية العصبية (NSM). بالنسبة إلى الاستعلامات المعقدة إلى حد ما التي تتطلب برامج من 2 إلى 5 خطوات ، فإن CIPITR يسجل 3 على الأقل أعلى من F1 من الأنظمة المنافسة. في واحدة من أصعب فئة من البرامج (التفكير المقارن) مع 5-10 خطوات ، يتفوق CIPITR في الأداء على NSM بعامل 89 وشبكات الذاكرة بنسبة 9 مرات.", 'pt': "Nos últimos anos, temos visto respostas de perguntas cada vez mais complexas em bases de conhecimento (KBQA) envolvendo raciocínio lógico, quantitativo e comparativo sobre subgráficos KB. A Indução de Programa Neural (NPI) é uma abordagem pragmática para modularizar o processo de raciocínio traduzindo uma consulta de linguagem natural complexa em um programa executável de várias etapas. Embora o NPI tenha sido comumente treinado com o programa ``gold'' ou seu esboço, para aplicações KBQA realistas, esses programas gold são caros de obter. Lá, praticamente apenas consultas em linguagem natural e as respostas correspondentes podem ser fornecidas para treinamento. A explosão combinatória resultante no espaço do programa, juntamente com recompensas extremamente escassas, torna o NPI para KBQA ambicioso e desafiador. Apresentamos o Complex Imperative Program Induction from Terminal Rewards (CIPITR), um programador neural avançado que mitiga a escassez de recompensas com recompensas auxiliares e restringe o espaço do programa a programas semanticamente corretos usando restrições de alto nível, esquema KB e tipo de resposta inferida. CIPITR resolve KBQA complexo de forma consideravelmente mais precisa do que redes de memória de valor-chave e máquinas simbólicas neurais (NSM). Para consultas moderadamente complexas que exigem programas de 2 a 5 etapas, o CIPITR pontua pelo menos 3 pontos F1 mais altos do que os sistemas concorrentes. Em uma das classes de programas mais difíceis (raciocínio comparativo) com 5 a 10 etapas, o CIPITR supera o NSM por um fator de 89 e as redes de memória em 9 vezes.", 'fr': "Ces dernières années, les réponses aux questions sur les bases de connaissances (KBQA) ont été de plus en plus complexes, impliquant un raisonnement logique, quantitatif et comparatif par rapport aux sous-graphes de connaissances. L'induction par programme neuronal (NPI) est une approche pragmatique visant à modulariser le processus de raisonnement en traduisant une requête complexe en langage naturel en un programme exécutable en plusieurs étapes. Alors que NPI a été généralement formé avec le programme «\xa0gold\xa0» ou son sketch, pour des applications KBQA réalistes, de tels programmes Gold sont coûteux à obtenir. Pratiquement, seules les requêtes en langage naturel et les réponses correspondantes peuvent être fournies pour la formation. L'explosion combinatoire qui en résulte dans l'espace de programme, ainsi que les récompenses extrêmement rares, rendent le NPI pour KBQA ambitieux et stimulant. Nous présentons Complex Imperative Program Induction from Terminal Rewards (CIPITR), un programmeur neuronal avancé qui atténue la dispersion des récompenses avec des récompenses auxiliaires, et restreint l'espace du programme aux programmes de correction sémantique à l'aide de contraintes de haut niveau, d'un schéma de base de connaissances et d'un type de réponse inféré. CIPITR résout les KBQA complexes de manière beaucoup plus précise que les réseaux de mémoire clé-valeur et les machines neuronales symboliques (NSM). Pour les requêtes modérément complexes nécessitant des programmes en 2 à 5 étapes, CIPITR obtient au moins 3 fois plus de F1 que les systèmes concurrents. Sur l'une des classes de programmes les plus difficiles (raisonnement comparatif) avec 5 à 10 étapes, CIPITR surpasse NSM d'un facteur 89 et les réseaux de mémoire de 9 fois.", 'ja': '近年、知識ベース（ KBQA ）では、KBサブグラフを用いた論理的、定量的、比較的複雑な推論が行われている。 ニューラルプログラム誘導（ NPI ）は、複雑な自然言語クエリを多段階の実行可能プログラムに変換することによって、推論プロセスをモジュール化するための実用的なアプローチです。 NPIは一般的に「ゴールド」プログラムまたはそのスケッチでトレーニングされていますが、現実的なKBQAアプリケーションでは、ゴールドプログラムなどは高価です。 そこでは、実際には自然言語の問い合わせと対応する回答のみをトレーニングのために提供することができます。 結果として生じるプログラム空間の組み合わせ爆発と、極めてまばらな報酬は、KBQAのNPIを野心的で挑戦的なものにしています。 高度なニューラルプログラマであるComplex Imperative Program Induction from Terminal Rewards (CIPITR)を提示し、補助的な報酬で報酬の希少性を軽減し、プログラム空間を高レベルの制約、KBスキーマ、および推測される回答タイプを使用して意味論的に修正するプログラムに制限します。 CIPITRは、キー値メモリネットワークやニューラルシンボリックマシン（ NSM ）よりもかなり正確に複雑なKBQAを解決します。 2〜5段階のプログラムを必要とする中程度に複雑なクエリでは、CIPITRは競合するシステムよりもF 1のスコアが少なくとも3高い。 5〜10ステップの最もハードなクラスのプログラム（比較推論）では、CIPITRはNSMを89倍、メモリネットワークを9倍上回ります。', 'zh': '近年以来,知识库(KBQA)问益杂,涉库子图逻辑,定量比较推理。 神经程序归 (NPI) 者自然语言询其多步骤可执行程序模块化理之实也。 虽NPI常用"黄金"、"其草图",而于见实之KBQA应用程序,其得本甚高。 其实供自然语言询对培训。 由是项目空合,及至疏之赏,使KBQANPI雄心勃勃有挑战性。 臣等言终端奖(CIPITR)之杂令,CIPITR为高神经程序员,所以奖轻奖疏,而用高级约束,KB式与推断之类,限以语义正。 CIPITR比键直存储器网络与神经符机器(NSM)更定杂KBQA。 须 2 至 5 步程序中等杂问,CIPITR F1 得分至少,高于竞 3 。 5-10步最难之程(比较推理)一上,CIPITR性倍于NSM89,内存网络高倍9。', 'hi': "हाल के वर्षों में ज्ञान के आधार (KBQA) पर तेजी से जटिल प्रश्न-उत्तर देखा गया है जिसमें KB subgraphs पर तार्किक, मात्रात्मक और तुलनात्मक तर्क शामिल हैं। तंत्रिका कार्यक्रम प्रेरण (एनपीआई) एक बहु-चरण निष्पादन योग्य कार्यक्रम में एक जटिल प्राकृतिक भाषा क्वेरी का अनुवाद करके तर्क प्रक्रिया को मॉड्यूलराइज़ करने की दिशा में एक व्यावहारिक दृष्टिकोण है। जबकि एनपीआई को आमतौर पर 'गोल्ड' प्रोग्राम या इसके स्केच के साथ प्रशिक्षित किया गया है, यथार्थवादी केबीक्यूए अनुप्रयोगों के लिए इस तरह के सोने के कार्यक्रम प्राप्त करना महंगा है। वहां, व्यावहारिक रूप से केवल प्राकृतिक भाषा के प्रश्नों और संबंधित उत्तरों को प्रशिक्षण के लिए प्रदान किया जा सकता है। कार्यक्रम अंतरिक्ष में परिणामी संयुक्त विस्फोट, बेहद विरल पुरस्कारों के साथ, केबीक्यूए के लिए एनपीआई को महत्वाकांक्षी और चुनौतीपूर्ण बनाता है। हम टर्मिनल रिवार्ड्स (CIPITR) से जटिल अनिवार्य कार्यक्रम प्रेरण प्रस्तुत करते हैं, एक उन्नत तंत्रिका प्रोग्रामर जो सहायक पुरस्कारों के साथ इनाम sparsity को कम करता है, और उच्च-स्तरीय बाधाओं, KB स्कीमा, और अनुमानित उत्तर प्रकार का उपयोग करके प्रोग्राम स्पेस को शब्दार्थ रूप से सही करने के लिए प्रतिबंधित करता है। CIPITR जटिल KBQA को कुंजी-मूल्य मेमोरी नेटवर्क और तंत्रिका प्रतीकात्मक मशीनों (एनएसएम) की तुलना में काफी अधिक सटीक रूप से हल करता है। 2- से 5-चरणीय कार्यक्रमों की आवश्यकता वाले मध्यम जटिल प्रश्नों के लिए, CIPITR प्रतिस्पर्धी प्रणालियों की तुलना में कम से कम 3 उच्च F1 स्कोर करता है। 5-10 चरणों के साथ कार्यक्रमों (तुलनात्मक तर्क) के सबसे कठिन वर्ग में से एक पर, CIPITR एनएसएम को 89 के कारक और मेमोरी नेटवर्क को 9 गुना से बेहतर बनाता है।", 'ru': 'В последние годы возникают все более сложные вопросы - ответы на базы знаний (KBQA), включающие логические, количественные и сравнительные рассуждения по подграфам KB. Индукция нейронных программ (NPI) - это прагматический подход к модуляции процесса рассуждений путем перевода сложного запроса на естественный язык в многошаговую исполняемую программу. В то время как NPI был обычно обучен с «золотой» программой или ее эскизом, для реалистичных приложений KBQA такие золотые программы дорого получить. Там для обучения могут быть предоставлены только запросы на естественном языке и соответствующие ответы. Получившийся в результате комбинаторный взрыв в программном пространстве, наряду с чрезвычайно редкими вознаграждениями, делает NPI для KBQA амбициозным и сложным. Мы представляем комплексную индукцию императивных программ от Terminal Rewards (CIPITR), продвинутого нейронного программиста, который смягчает редкость вознаграждений вспомогательными вознаграждениями и ограничивает пространство программы семантически правильными программами с использованием высоких ограничений, схемы КБ и типа прогнозируемого ответа. CIPITR решает сложные KBQA значительно точнее, чем сети памяти с ключевыми значениями и нейросимволические машины (NSM). Для умеренно сложных запросов, требующих от 2-х до 5-ти ступенчатых программ, CIPITR оценивается как минимум на 3 балла выше F1, чем конкурирующие системы. На одном из самых сложных классов программ (сравнительное мышление) с 5–10 шагами CIPITR превосходит NSM в 89 раз, а сети памяти - в 9 раз.', 'ga': "Le blianta beaga anuas tá ceisteanna á bhfreagraí ar bhoinn eolais (KBQA) ag éirí níos casta agus a bhaineann le réasúnaíocht loighciúil, chainníochtúil agus chomparáideach thar fhoghraif KB. Is cur chuige pragmatach é Ionduchtú Cláir Néaracha (NPI) chun an próiseas réasúnaíochta a mhodúlú trí cheist chasta teanga nádúrtha a aistriú go clár inrite ilchéime. Cé go bhfuil an NPI oilte go coitianta leis an gclár ``óir'' nó lena sceitse, d'fheidhmchláir réalaíocha KBQA tá sé costasach a leithéid de chláir óir a fháil. Ní féidir ach ceisteanna teanga nádúrtha agus na freagraí comhfhreagracha a chur ar fáil don oiliúint. Mar gheall ar an bpléasc comhcheangailte i spás cláir mar thoradh air, mar aon le luach saothair an-bheag, tá NPI do KBQA uaillmhianach agus dúshlánach. Cuirimid i láthair Ionduchtú Clár Riachtanach Coimpléascach ó Luaíochtaí Teirminéil (CIPITR), ard-ríomhchláraitheoir néarúil a mhaolaíonn teimhneacht luach saothair le luach saothair cúnta, agus a chuireann srian le spás cláir chun cláir a cheartú go séimeantach ag baint úsáide as srianta ardleibhéil, scéimre KB, agus cineál freagra tátal. Réitíonn CIPITR KBQA casta i bhfad níos cruinne ná líonraí cuimhne eochairluacha agus meaisíní siombalacha néaracha (NSM). Maidir le fiosrúcháin measartha casta a éilíonn cláir 2- go 5-chéim, scórálann CIPITR 3 F1 ar a laghad níos airde ná na córais iomaíocha. Ar cheann de na cláir is deacra (réasúnaíocht chomparáideach) le 5-10 gcéim, tá 9 n-uaire níos fearr ag CIPITR ná NSM fachtóir 89 agus líonraí cuimhne.", 'ka': 'შემდეგ წლის შემდეგ კომპლექციური კითხვების პასუხი კომპლექტირებულია, რომელიც ლოგიკური, კომრატიური და კომპორტიური პასუხი KB სპეგრაფიების შესახებ. ნეიროლური პროგრამის ინდექცია (NPI) არის პრაგმატიური პროგრამია, რომელიც მოდულიარებას პროცესის მონაცემის პროცესის შეცვლით კომპლექსი ნაიროლური ენერგიის კითხვაში მრავა NPI პროგრამით ან მისი სკექტით განაკეთებული იყო, როცა რეალური KBQA პროგრამიების შესაძლებელად იყოს, რაც მოიღება საშლიო პროგრამი. მაშინ, პროქტიკურად მხოლოდ ნაირადი ენის კითხვები და შესაძლებელი პასუხები შეიძლება განაკეთება. პროგრამის სივრცეში შემდეგ კომბინონაციური ექსპროზაცია, საკმაოდ მუშაობის შემდეგ, KBQA ამბიციო და შესაძლებელია NPI. ჩვენ კომპლექსი ინტეპერაციული პროგრამის ინდექცია ტერმინალის შემდეგ (CIPITR), განვითარებული ნეიროლური პროგრამირებელი, რომელიც შემდეგ შემდეგ შემდეგ გადაუმუშავებელი მუშაობის შემდეგ, და პროგრამის სივმპერაციის სივმპერაცია CIPITR კომპლექსი KBQA უფრო მნიშვნელოვანია, უფრო მნიშვნელოვანი მეხსიერების ქსელებიდან და ნეიროლური სიმბოლიკური მაქანებიდან (NSM) გადაწყება საშუალოდ კომპლექსიკური კითხვებისთვის, რომლებიც 2- 5- კვადრატის პროგრამების შესაძლებლობად, CIPITR შესაძლებელია სამი უფრო მეტი F1- ზე, ვიდრე კო პროგრამების ერთი უფრო რთული კლასიდან (შემდგომარებული პარამენტი) 5-10 ნაწილიდან CIPITR უფრო გავაკეთება NSM-ს 89-ის და მეხსიერის ქსელების ფაქტორიდან 9-ჯერ.', 'hu': 'Az elmúlt években egyre összetettebb tudásbázisokon (KBQA) kérdések válaszoltak, amelyek logikai, mennyiségi és összehasonlító érvelést is magukban foglalnak a KB-részterületeken. A Neural Program Induction (NPI) egy pragmatikus megközelítés az érvelési folyamat modulárizálására, egy komplex természetes nyelvű lekérdezés többlépéses futtatható programba való lefordításával. Míg az NPI-t általában az "arany" programmal vagy annak vázlatával képezték, a reális KBQA alkalmazások esetében az ilyen arany programokat drága beszerezni. Itt gyakorlatilag csak természetes nyelvi kérdések és a megfelelő válaszok adhatók meg a képzéshez. Az ebből eredő kombinációs robbanás a programtérben, valamint a rendkívül ritka jutalmak, ambiciózussá és kihívásokkal teli NPI-t tesznek a KBQA számára. Bemutatjuk a Komplex Imperative Program Induction from Terminal Rewards (CIPITR), egy fejlett idegprogramozó, amely segédjutalmakkal enyhíti a jutalom ritkaságát, és korlátozza a programterületet szemantikailag korrekciós programokra magas szintű korlátozások, KB séma és következtetett választípus segítségével. A CIPITR jelentősen pontosabban oldja meg a komplex KBQA-t, mint a kulcsértékű memóriahálózatok és az idegi szimbolikus gépek (NSM). Közepesen összetett lekérdezések esetén, amelyek 2-5 lépéses programokat igényelnek, a CIPITR legalább 3 F1-t ér el, mint a versenyző rendszerek. Az egyik legnehezebb programosztályon (összehasonlító érvelés) 5–10 lépéssel, a CIPITR 89-szeres túllépi az NSM-et és 9-szeres memóriahálózatot.', 'el': 'Τα τελευταία χρόνια έχουν δει ολοένα και πιο περίπλοκη απάντηση σε ερωτήματα σε βάσεις γνώσης (KBQA) που περιλαμβάνει λογική, ποσοτική και συγκριτική συλλογιστική σε υπογραφήματα ΚΒ. Η επαγωγή νευρωνικού προγράμματος (ΝΠI) είναι μια ρεαλιστική προσέγγιση για τη μορφοποίηση της διαδικασίας συλλογισμού μεταφράζοντας ένα σύνθετο ερώτημα φυσικής γλώσσας σε ένα εκτελέσιμο πρόγραμμα πολλαπλών βημάτων. Ενώ το NPI έχει εκπαιδευτεί συνήθως με το πρόγραμμα "χρυσός" ή το σκίτσο του, για ρεαλιστικές εφαρμογές τέτοια χρυσά προγράμματα είναι ακριβά στην απόκτηση. Εκεί, πρακτικά μόνο ερωτήματα φυσικής γλώσσας και οι αντίστοιχες απαντήσεις μπορούν να παρασχεθούν για εκπαίδευση. Η επακόλουθη συνδυασμένη έκρηξη στο χώρο του προγράμματος, μαζί με εξαιρετικά σπάνιες ανταμοιβές, καθιστά το NPI για το KBQA φιλόδοξο και προκλητικό. Παρουσιάζουμε την σύνθετη επαγωγή επιτακτικού προγράμματος από τις τελικές ανταμοιβές (έναν προηγμένο νευρωνικό προγραμματιστή που μετριάζει την έλλειψη ανταμοιβών με βοηθητικές ανταμοιβές και περιορίζει το χώρο του προγράμματος σε σημασιολογικά σωστά προγράμματα χρησιμοποιώντας περιορισμούς υψηλού επιπέδου, σχήμα ΚΒ και συνακόλουθο τύπο απάντησης. Το CIPITR επιλύει το πολύπλοκο KBQA σημαντικά πιο ακριβή από τα δίκτυα μνήμης κλειδιών και τις νευρωνικές συμβολικές μηχανές (NSM). Για μέτρια σύνθετα ερωτήματα που απαιτούν προγράμματα 2-έως 5-βημάτων, το CIPITR βαθμολογεί τουλάχιστον 3 υψηλότερα από τα ανταγωνιστικά συστήματα. Σε μία από τις δυσκολότερες κατηγορίες προγραμμάτων (συγκριτική συλλογιστική) με 5–10 βήματα, το CIPITR ξεπερνά την NSM κατά έναν παράγοντα 89 και τα δίκτυα μνήμης κατά εννέα φορές.', 'it': 'Gli ultimi anni hanno visto la risposta alle domande sempre più complessa su basi di conoscenza (KBQA) coinvolgendo ragionamenti logici, quantitativi e comparativi su sottografi KB. Neural Program Induction (NPI) è un approccio pragmatico verso la modularizzazione del processo di ragionamento traducendo una complessa query di linguaggio naturale in un programma eseguibile multi-step. Mentre NPI è stato comunemente addestrato con il programma "gold" o il suo schizzo, per applicazioni KBQA realistiche tali programmi gold sono costosi da ottenere. Qui, praticamente, solo domande linguistiche naturali e le risposte corrispondenti possono essere fornite per la formazione. L\'esplosione combinatoria risultante nello spazio del programma, insieme a ricompense estremamente scarse, rende NPI per KBQA ambizioso e impegnativo. Presentiamo Complex Imperative Program Induction from Terminal Rewards (CIPITR), un programmatore neurale avanzato che mitiga la scarsità delle ricompense con ricompense ausiliarie e limita lo spazio del programma a programmi semanticamente corretti utilizzando vincoli di alto livello, schema KB e tipo di risposta dedotto. CIPITR risolve KBQA complessi in modo notevolmente più accurato rispetto alle reti di memoria chiave e alle macchine simboliche neurali (NSM). Per query moderatamente complesse che richiedono programmi da 2 a 5 fasi, CIPITR ottiene almeno 3 F1 superiori rispetto ai sistemi concorrenti. In uno dei programmi più difficili (ragionamento comparativo) con 5-10 passaggi, CIPITR supera NSM di un fattore di 89 e le reti di memoria di 9 volte.', 'lt': 'Pastaraisiais metais kyla vis sudėtingesnių klausimų atsakymų žinių bazėse (KBQA), įskaitant logišką, kiekybinį ir lyginamąjį KB pografų pagrindimą. Neural Program Induction (NPI) yra pragmatiškas metodas moduliuoti motyvavimo procesą vertant sudėtingą natūralų kalbų klausimą į daugiapakopę vykdomąją program ą. Nors NPI paprastai buvo mokoma pagal program ą „auksas“ arba jos schemą, realioms KBQA programoms tokios aukso programos yra brangios gauti. Mokymui galima pateikti tik natūralius kalbų klausimus ir atitinkamus atsakymus. The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes NPI for KBQA ambitious and challenging.  Mes pristatome kompleksinę Imperatyviąją program ą „Induction from Terminal Awards“ (CIPITR), pažangią nervų programuotoją, kuris mažina atlyginimų nedidelį skaičių papildomomis atlyginimais ir apriboja programų erdvę tik semantiškai koreguojančiomis programomis, naudojant aukšto lygio apribojimus, KB schemą ir nuspręstą atsakymo tipą. CIPITR daug tiksliau išsprendžia sudėtingą KBQA nei pagrindinės vertės atminties tinklai ir neurologinės simbolinės mašinos (NSM). Vidutinio sunkumo užklausose, kuriose reikalingos 2–5 etapų programos, CIPITR rezultatai yra bent 3 didesni už konkuruojančias sistemas. Vienoje iš sunkiausių programų klasių (lyginamasis motyvavimas) su 5–10 žingsnių CIPITR veikia NSM 89 kartais, o atminties tinklai 9 kartus.', 'kk': "Соңғы жылдар KB субграфиктерінің логикалық, санаттық және салыстырмалы сезімдерінің мәлімет негізінде (KBQA) сұрақ жауаптарын көрген. Нейрондық бағдарламаның индукциясы (NPI) көп қадамды орындалатын бағдарламаға комплексті табиғдарламаның сұранысын аударып, бақылау процесін модульдерлеу үшін прагматикалық тәсілі. NPI көпшілікті `gold' бағдарламасы немесе оның сұлбасы бойынша оқылған болғанда, KBQA қолданбалары бұл алтын бағдарламаларды алу үшін бағатты. Ол жерде тек табиғи тіл сұрақтары және сұрақтар қолданылады. Бағдарлама бос орындағы комбинациялық жұмыс жұмыс істейтін жұмыс көмегімен, KBQA амбициялық және шақыру үшін NPI жасайды. Біз терминал қайтару (CIPITR) дегеннен комплексті императивті бағдарлама индукциясын таңдаймыз. Бұл көмектесілік жоғары деңгейіндегі шектеулерді, KB сұлбасын және жауап түрін қолданып, бағдарламаның кеңістігін көмектесілік жоғары ше CIPITR комплексті KBQA- ды кілт- мәндерінің жады және невралдық символдық машиналарының (NSM) желілерінен дұрыс шешу. Орташа комплекс сұрақтар үшін 2- мен 5- қадам бағдарламаларды талап етеді, CIPITR бағдарламалардың сұрақтарын бақылау жүйелерінен кемінде 3 жоғары F1 деп саналады. Бағдарламалардың ең қиын класында (салыстырмалы тәуелдеу) 5-10 қадамдарымен CIPITR 89 және жады желіктерінің факторынан 9 рет NSM жұмыс істейді.", 'mk': "Во последните години се покомплексни одговори на прашања на базите на знаење (КБКА) кои вклучуваат логично, квантитивно и споредливо размислување во врска со подграфите на КБ. Индукција на невралната програма (NPI) е прагматичен пристап кон модулизацијата на процесот на размислување со преведување на комплексна природна прашање на јазик во мултичекорна извршна програма. While NPI has been commonly trained with the ``gold'' program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain.  Таму може да се обезбедат само природни прашања за јазик и соодветните одговори за обука. Резултатот на комбинаторната експлозија во програмскиот простор, заедно со екстремно мали награди, го прави НПИ за КБКА амбициозен и предизвикувачки. Презентираме комплексна императивна индукција на програмата од терминалните награди (CIPITR), напредниот невропски програмер кој ја намалува наградата на малоста со помошни награди, и го ограничува програмскиот простор на семантично коректни програми користејќи високи ограничувања, КБ шема и тип на одговор. CIPITR го решава комплексното KBQA значително попрецизно од мрежите на меморија со клучна вредност и неуралните симболички машини (NSM). За модерно комплексни прашања кои бараат програми од 2 до 5 чекори, CIPITR оценува најмалку 3 повисоки F1 од конкурентните системи. На една од најтешките програми (споредливо размислување) со 5-10 чекори, ЦИПИТР го надминува НСМ со фактор од 89 и мемориските мрежи за 9 пати.", 'ms': "Tahun-tahun terakhir telah melihat jawapan soalan semakin kompleks pada pangkalan pengetahuan (KBQA) yang melibatkan alasan logik, kuantitatif, dan perbandingan atas subgraf KB. Indukti Program Neural (NPI) adalah pendekatan pragmatik menuju modularisasi proses alasan dengan menerjemahkan pertanyaan bahasa semulajadi kompleks ke dalam program boleh dilaksanakan berbilang-langkah. Sementara NPI biasanya dilatih dengan program ``gold'' atau sketsanya, untuk aplikasi KBQA realistik program emas seperti itu mahal untuk diperoleh. Di sana, hampir hanya pertanyaan bahasa biasa dan jawapan yang sepadan boleh diberikan untuk latihan. Penyebab letupan kombinatorial dalam ruang program, bersama dengan hadiah yang sangat sedikit, membuat NPI untuk KBQA ambisius dan menantang. Kami perkenalkan Induksi Program Imperatif Kompleks dari Balasan Terminal (CIPITR), pemrogram saraf maju yang mengurangi kemurahan balasan dengan balasan tambahan, dan menghalang ruang program untuk program yang betul secara semantik menggunakan keterangan tahap tinggi, skema KB, dan jenis jawapan yang disusulkan. CIPITR menyelesaikan KBQA kompleks jauh lebih tepat daripada rangkaian memori nilai-kunci dan mesin simbolik saraf (NSM). Untuk pertanyaan sederhana kompleks yang memerlukan program 2-5 langkah, CIPITR skor sekurang-kurangnya 3 F1 lebih tinggi daripada sistem yang bersaing. Dalam salah satu kelas paling sukar program (alasan perbandingan) dengan 5-10 langkah, CIPITR melampaui NSM dengan faktor 89 dan rangkaian ingatan dengan 9 kali.", 'mt': "Is-snin reċenti raw tweġibiet dejjem aktar kumplessi għall-mistoqsijiet dwar il-bażijiet tal-għarfien (KBQA) li jinvolvu raġunament loġiku, kwantitattiv u komparattiv fuq is-sottografi tal-KB. L-Induzzjoni tal-Programm Newrali (NPI) hija approċċ prammatiku lejn il-modulazzjoni tal-proċess ta’ raġunament billi tiġi tradotta mistoqsija kumplessa tal-lingwa naturali fi programm eżekuttiv f’diversi stadji. Filwaqt li l-NPI kien imħarreġ b’mod komuni bil-programm `deheb'' jew l-iskedju tiegħu, għal applikazzjonijiet realistiċi KBQA dawn il-programmi tad-deheb huma għaljin biex jinkisbu. There, practically only natural language queries and the corresponding answers can be provided for training.  L-isplużjoni kombinatorja li tirriżulta fl-ispazju tal-programmi, flimkien ma’ premjijiet estremament baxxi, tagħmel l-NPI għal KBQA ambizzjuża u sfida. Aħna nippreżentaw Induzzjoni Komplessa Imperattiva tal-Programm mir-Rigwardji Terminali (CIPITR), programmator newrali avvanzat li jtaffi l-sparsità tal-premju bi premji awżiljarji, u jirrestrinġi l-ispazju tal-programm għal programmi korretti semantikament bl-użu ta’ restrizzjonijiet ta’ livell għoli, skema KB, u tip ta’ tweġiba inferita. CIPITR isolvi KBQA kumpless b’mod konsiderevolment aktar preċiż minn netwerks ta’ memorja b’valur ewlieni u magni simboliċi newrali (NSM). Għal mistoqsijiet moderatament kumplessi li jeħtieġu programmi minn 2 sa 5 stadji, is-CIPITR jikkalkula mill-inqas 3 F1 ogħla mis-sistemi kompetittivi. Fuq waħda mill-aktar klassi iebsa ta’ programmi (raġunament komparattiv) b’5-10 passi, CIPITR jaqbeż l-NSM b’fattur ta’ 89 u n-netwerks tal-memorja b’9 darbiet.", 'ml': "അടുത്ത വര്\u200dഷങ്ങള്\u200d കെബി സബ്രാഗ്രാഫുകളെക്കുറിച്ചുള്ള വിജ്ഞാനത്തിന്റെ (കെബിക്യൂഎ) ബേസില്\u200d ഉള്ള ചോദ്യങ്ങളുടെ ഉത്തരം കൂടുതല്\u200d ക്ര നെയുറല്\u200d പ്രോഗ്രാം ഇന്\u200dഡിനോട്ടിങ്ഷന്\u200d (NPI) ഒരു കാര്യത്തിന്റെ പ്രക്രിയയിലേക്ക് മോഡ്യൂളിലേക്ക് മാറ്റുന്ന ഒരു പ്രോഗ്രാമികമായ 'സ്വര്\u200dണ്ണം' പ്രോഗ്രാമോ അതിന്\u200dറെ സ്കേച്ചോ കൊണ്ട് NPI പ്രയോഗങ്ങള്\u200d സാധാരണ പരിശീലിക്കപ്പെട്ടിരിക്കുന്ന സമയത്ത്, യഥാര്\u200dത്ഥ കെബിക അവിടെ, സ്വാഭാവിക ഭാഷയുടെ ചോദ്യങ്ങള്\u200d മാത്രമാണ് ചോദിക്കുന്നത്. പ്രതിരോധിക്കുന്ന ഉത്തരം പരിശീലനത്തി പ്രോഗ്രാമിന്\u200dറെ സ്പെയില്\u200d കൂടുതല്\u200d മിനുക്കുന്ന പ്രതിഫലങ്ങളോടൊപ്പം, കെബിക്യൂഎയ്ക്കുള്ള NPI ആഗ്രഹിക്കുന്നു വി ടെര്\u200dമിനല്\u200d വീണ്ടെടുക്കുന്നതില്\u200d നിന്നുള്ള കമ്പ്ലെക്സ് പ്രോഗ്രാം നിര്\u200dമ്മാണിക്കുന്നത്, മുന്\u200dഗണന ന നെയൂറല്\u200d പ്രോഗ്രാമേറ്റര്\u200d, കൂടുതല്\u200d പ്രതിഫലങ്ങള്\u200dക്കുള്ള പ്രതിഫലം നഷ്ടപ്പെടു കീ- മൂല്യമുള്ള മെമ്മറി ശെരുക്കളെക്കാളും ന്യൂറല്\u200d ചിഹ്നങ്ങളുടെ യന്ത്രങ്ങളെക്കാളും സിപിടിറ്റര്\u200d കെബിക്യൂഎം പരിഹരിക്കു 2- 5- step പ്രോഗ്രാമുകള്\u200d ആവശ്യപ്പെടുന്ന ആധുനികമായ കുഴപ്പമുള്ള ചോദ്യങ്ങള്\u200dക്ക് സിഐപിറ്റര്\u200d സ്കോര്\u200dട്ട് ചെയ്യുന്നതിനാല 5-10 പടികളുമായി ഏറ്റവും കഠിനമായ പ്രോഗ്രാമുകളില്\u200d ഒന്നില്\u200d, സിപിടിറ്റര്\u200d എംഎമിനെ പ്രവര്\u200dത്തിപ്പിക്കുന്നു. 89 പ്രോഗ്രാമിന്റെയും മെമ്മറ", 'mn': "Сүүлийн жилүүд мэдлэг суурь (KBQA) дээр илүү нарийн асуулт хариултыг харж байгаа нь логик, хэмжээст, харьцуулсан хариултыг КБ-ийн зураг дээр харьцуулсан. Цөмийн програм индуктаци (NPI) нь олон алхам хэрэгжүүлэх програм руу комплекс байгалийн хэл квадратыг орлуулаад шалтгаан үйлдвэрлэх процессийг модульчлэхэд прагматикийн арга юм. NPI нь ихэвчлэн `алт'-ийн программыг эсвэл түүний сүлжээнд суралцагдсан ч бодит KBQA программын хувьд ийм алт программыг авах үнэтэй. Тэнд зөвхөн байгалийн хэлний квери болон хариултуудыг суралцах боломжтой. Үүний үр дүнд программын орон зайд нэгтгэл гайхалтай нүүрстөрөгч нүүрстөрөгч нүүрстөрөгч нь KBQA-ын зорилготой, зорилготой NPI-г хийдэг. Бид Терминал Rewards (CIPITR) ээс комплекс үндсэн програм индукцийг тайлбарлаж, хөгжсөн сэтгэл хөтөлбөр нь тусламжтай шагналыг багасгаж, хөтөлбөрийн орон зайг өндөр түвшинд хязгаарлах, KB схема болон халдвар авсан хариултын төрлийг ашиглан багасгадаг. CIPITR комплекс KBQA-г түлхүүр утгатай санамжийн сүлжээ болон мэдрэлийн символ машин (NSM) дээс илүү зөв шийддэг. Одоогийн төвөгтэй төвөгтэй квадратуудын тулд 2-ээс 5-аас хөтөлбөрийн шаардлагатай CIPITR нь өрсөлдөг системээс хамгийн бага 3 өндөр F1-г гаргадаг. 5-10 алхам хамгийн хэцүү программын нэг хэсэгт CIPITR нь 89-н хүчин зүйл болон 9 дахин дурсамжийн сүлжээнд NSM-г нэмэгдүүлдэг.", 'pl': 'W ostatnich latach coraz bardziej złożone były odpowiedzi na pytania w oparciu o bazy wiedzy (KBQA) obejmujące logiczne, ilościowe i porównawcze rozumowanie nad podgrafami KB. Neuronal Program Induction (NPI) to pragmatyczne podejście do modułowania procesu rozumowania poprzez tłumaczenie złożonego zapytania języka naturalnego na wieloetapowy program wykonywalny. Podczas gdy NPI był powszechnie przeszkolony z programem "złotego" lub jego szkicu, dla realistycznych aplikacji KBQA takie programy złotego są drogie w uzyskaniu. Tam można zapewnić praktycznie tylko zapytania językowe naturalne i odpowiedzi na nie. Wynikająca z tego eksplozja kombinacyjna w przestrzeni programu wraz z niezwykle rzadkimi nagrodami sprawia, że NPI dla KBQA jest ambitny i wymagający. Prezentujemy Complex Imperative Program Induction from Terminal Rewards (CIPITR), zaawansowany programista neuronowy, który łagodzi słabość nagród za pomocą nagród pomocniczych i ogranicza przestrzeń programu do korekty semantycznej programów przy użyciu ograniczeń wysokiego poziomu, schematu KB i wywnioskowanego typu odpowiedzi. CIPITR rozwiązuje złożone KBQA znacznie dokładniej niż sieci pamięci o wartości kluczowej i neuronowe maszyny symboliczne (NSM). W przypadku umiarkowanie złożonych zapytań wymagających programów 2- do 5-stopniowych CIPITR wynika co najmniej 3-stopniowo wyższą F1 niż konkurencyjne systemy. W jednej z najtrudniejszych klas programów (rozumowanie porównawcze) z 5–10 krokami, CIPITR przewyższa NSM o czynnik 89, a sieci pamięci o 9-krotnie.', 'sr': "Posljednje godine su viđene veće kompleksne odgovore na pitanje na bazama znanja (KBQA), uključujući logičko, kvantitativno i usporedno razmišljanje po podgrafcima KB. Indukcija neuroloških program a (NPI) je pragmatični pristup modularizaciji procesa razumanja prevodeći kompleksno prirodno jezičko pitanje u multikoracijski program koji može izvršiti. Iako je NPI obično obučen programom `zlato'' ili skećem, za realistične aplikacije KBQA, takve zlatne programe su skupe za dobivanje. Tamo se može pružiti praktično samo prirodne ispitivanja jezika i odgovarajuće odgovore za obuku. Rezultat kombinacijske eksplozije u programskom prostoru, zajedno sa izuzetno rezervnim nagradama, čini NPI ambicioznim i izazovnim za KBQA. Predstavljamo kompleksno imperativnu programsku indukciju od Terminal Rewards (CIPITR), naprednog neuralnog programera koji smanjuje nagradu sparsitnosti sa pomoænim nagradama, i ogranièava prostor programa da semantički ispravi programe koristeći ogranièenja visokog nivoa, KB šemu i infekciju vrsta odgovora. CIPITR reši kompleksne KBQA mnogo tačnije od ključne vrednosti sjećanja i neuralne simbolične mašine (NSM). Za moderno kompleksno pitanje koje zahtevaju 2 do 5 koraka programe, CIPITR rezultat najmanje 3 viših F1 od konkurentnih sustava. Na jednoj od najtežih klasa programa (usporedno razmišljanje) sa 5-10 koraka, CIPITR nadmaže NSM faktorom 89 i sjećanja mreža do 9 puta.", 'ro': 'În ultimii ani, răspunsurile la întrebări din ce în ce mai complexe pe baze de cunoștințe (KBQA) implicând raționamente logice, cantitative și comparative asupra subgrafiilor KB. Neural Program Induction (NPI) este o abordare pragmatică spre modularea procesului de raționament prin traducerea unei interogări complexe de limbaj natural într-un program executabil în mai mulți pași. În timp ce NPI a fost în mod obișnuit instruit cu programul "gold" sau schița sa, pentru aplicațiile KBQA realiste, astfel de programe gold sunt scumpe de obținut. Acolo, practic, doar interogările lingvistice naturale și răspunsurile corespunzătoare pot fi furnizate pentru formare. Explozia combinatorie rezultată în spațiul de program, împreună cu recompensele extrem de rare, face NPI pentru KBQA ambițioasă și provocatoare. Vă prezentăm Complex Imperative Program Induction from Terminal Rewards (CIPITR), un programator neuronal avansat care atenuează lipsa recompenselor cu recompense auxiliare și restrânge spațiul de program la programe corecte semantic folosind constrângeri de nivel înalt, schema KB și tipul de răspuns dedus. CIPITR rezolvă KBQA complexe considerabil mai precis decât rețelele de memorie cu valoare cheie și mașinile simbolice neurale (NSM). Pentru interogările moderat complexe care necesită programe în 2 până la 5 pași, CIPITR scorează cel puțin 3 F1 mai mare decât sistemele concurente. Pe una dintre cele mai grele clase de programe (raționament comparativ) cu 5-10 pași, CIPITR depășește NSM cu un factor de 89 și rețelele de memorie de 9 ori.', 'si': "අන්තිම අවුරුද්දු දැක්කා විශේෂ ප්\u200dරශ්න- උත්තර (KBQA) දැනගන්නේ දන්න බේස් වලට ලෝකික, ප්\u200dරමාණය, සහ KB සබ්ගරාෆ්  න්\u200dයුරල් ප්\u200dරක්\u200dරියාමක විද්\u200dයාපනය (NPI) තමයි ප්\u200dරාග්මික විද්\u200dයාපනයක් විද්\u200dයාපනය කරන්න ප්\u200dරක්\u200dරියාපනය විද්\u200dයාපනය කරනවා සම්ප්\u200dර NPI සාමාන්\u200dය විදියට ``gold' වැඩසටහන නැත්නම් ඒකේ ස්කේච් එක්ක ප්\u200dරශ්නය කරලා තියෙනවා නමුත්, ඇත්තටම KBQA වැඩසටහන් එහෙම ර මෙතන, ස්වභාවික භාෂාව ප්\u200dරශ්නයක් විතරයි සම්බන්ධ උත්තර ප්\u200dරශ්නයක් විතරයි. වැඩසටහන අවස්ථාවයේ සංවිධානය ප්\u200dරවේශනයක් තියෙන්නේ, ගොඩක් ප්\u200dරවේශනයක් තියෙන්නේ, KBQA අවස්ථාවක් සහ අවශ්\u200dය ව අපි සම්පූර්ණ විශේෂ ප්\u200dරවෘත්තියක් ප්\u200dරවෘත්තියක් ප්\u200dරවෘත්තිය (CIPITR) වලින් ප්\u200dරවෘත්තියක් ප්\u200dරවෘත්තියක් ප්\u200dරවෘත්තියක් ප්\u200dරවෘත්තිය කරනවා, සහ ප්\u200dරවෘ CIPITR සම්පූර්ණයෙන් KBQA විශේෂය කරනවා යතුරු මතක ජාලය සහ න්\u200dයූරාල සංකේතික යන්ත්\u200dරය (NSM) වඩා වඩා සුරුදු වි සාමාන්\u200dය ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් 2- 5- පැත්තේ වැඩසටහන් අවශ්\u200dය වෙනුවෙන්, CIPITR ප්\u200dරශ්නයක් අඩුම 3ක ප්\u200dරවෘත්තියේ අමාරුත්ම ක්\u200dරියාපකරණයේ එක්කෙනෙක් (සම්පූර්ණ හේතුවක්) 5-10 පැත්තක් තියෙනවා, CIPITR ක්\u200dරියාපකරණයේ NSM එක", 'sv': 'De senaste åren har det skett allt mer komplexa frågeställningar på kunskapsbaser (KBQA) med logiskt, kvantitativt och jämförande resonemang över KB-undergrafer. Neural Program Induction (NPI) är ett pragmatiskt tillvägagångssätt för att modulera resonemanget genom att översätta en komplex naturlig språkfråga till ett körbart program i flera steg. Medan NPI ofta har tränats med "guld"-programmet eller dess skiss, för realistiska KBQA-program är sådana guldprogram dyra att erhålla. Där kan praktiskt taget bara naturliga språkfrågor och motsvarande svar ges för utbildning. Den resulterande kombinatoriska explosionen i programutrymmet, tillsammans med extremt få belöningar, gör NPI för KBQA ambitiös och utmanande. Vi presenterar Complex Imperative Program Induction from Terminal Rewards (CIPITR), en avancerad neural programmerare som minskar belöningarnas sparsamhet med hjälpbelöningar, och begränsar programutrymmet till semantiskt korrekta program med hjälp av begränsningar på hög nivå, KB-schema och inferterad svarstyp. CIPITR löser komplexa KBQA betydligt mer exakt än nyckelvärdeminnesnätverk och neurala symboliska maskiner (NSM). För måttligt komplexa frågor som kräver 2- till 5-stegsprogram får CIPITR minst 3 F1 högre än konkurrerande system. På en av de svåraste klasserna av program (jämförande resonemang) med 5–10 steg överträffar CIPITR NSM med en faktor på 89 och minnesnätverk med 9 gånger.', 'so': "Sanooyinkii ugu dambeeyey waxay arkeen jawaabta su'aalaha adag oo ku saabsan saldhigyada aqoonta (KBQA) oo ku saabsan logical, qiyaas iyo isbarbardhig ka saabsan submarinta KB. Muujinta qorshaha naadiga ah (NPI) waa qaab caadiga ah oo u soo jeeda hababka ku habboonaanta hababka sababta ah oo lagu turjumayo qoraalka afka maskaxda ah oo hoos u dhaqdhaqaaq ah oo loo sameeyo barnaamijyo wax badan oo la sameeyo. Inta lagu baranayo barnaamijka `dahabka'' ama sawirkiisa, marka lagu codsado xarumaha dahabka ee dhabta ah ee KBQA waa qaali in la helo. Sida caadiga ah waxaa lagu heli karaa su'aalo luuqada asalka ah oo kaliya iyo jawaabaha ku habboon waxbarashada. Dagaalka labaatanka ah ee ka soo baxay xafiiska programka, iyo mushahaaro aad u yar, wuxuu ka dhigaa NPI oo ka mid ah KBQA xiiso iyo dhibaatooyin. We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type.  CIPITR wuxuu si aad ah u xajisaa qalabka kooxa KBQA si aad uga sahlan shabakada xusuusta qiimaha ah iyo mashiinada neural symbolic (NSM). Xirar adag oo aad u baahan tahay programka 2-5-step, CIPITR score ugu yaraan 3 ka sarreeya F1 nidaamka tartanka. Mid ka mid ah fasalka barnaamijyada ugu adag (isbarbardhigga sababta) oo leh 5-10 tallaabo, CIPITR wuxuu ku soo bandhigaa xaalad 89 iyo shabakado xasuusta 9 jeer.", 'ta': "அண்மைய ஆண்டுகள் அறிவிப்பு அடிப்படைகளில் கேள்விக்கு பதில் கூடிய சிக்கலான விடையை பார்த்துள்ளார் நெருக்கர் நிரல் காட்சி( NPI) என்பது காரணங்களின் செயலை மாற்றுவதற்கு ஒரு சிக்கலான இயல்பான மொழி கேள்வியை பல- படி செயல்படுத்தக்கூடிய நிர NPI பொதுவாக 'தங்கம்' நிரல் அல்லது அதன் ஸ்காக்கியால் பயிற்சி செய்யப்பட்டிருக்கும் போது, உண்மையான KBQA பயன்பாடுகளுக்கு இது போன்ற தங் அங்கே உண்மையில் இயல்பான மொழி கேள்விகள் மட்டும் மற்றும் பொருத்தமான பதில் பயிற்சிக்கு வழங்கலாம். முடிவில் நிரல் வெடிப்பில் இருக்கும் முடிவு வெடிப்பு, மிகவும் சிறிது விகிதமான விகிதத்துடன், கேபிக்யாவிற்கு NP நாங்கள் முனையத்தில் இருந்து செயல்படுத்தும் நிரல் திட்டத்தை காண்பிக்கிறோம், ஒரு மேம்பட்ட நெயுரல் நிரல் நிரல் அது கூடுதல் விகிதத்தை குறைக்கிறது, மற்றும் நிரல் இடைவெளி அதிக நிலை கட் CIPITR சிக்கல் KBQA தீர்மானிக்கும் விசை- மதிப்பு நினைவவல்புகளையும் புதிய குறியீட்டு இயந்திரங்களையும் விட அதிக சரியாக த 2- to 5- step நிரல்கள் தேவைப்படும் தற்போதைய சிக்கல் கேள்விகளுக்கு, CIPITR மதிப்புகள் குறைந்தது 3 அதிகமான F1 கணினிகளை விட அதிகமானது. 5 - 10 படிகளுடன் மிகவும் கடினமான நிரல்களில் ஒரு வகுப்பில் சிபிடிஆர் 89 மற்றும் நினைவு வலைப்பின்னல்களை 9 முறை வெளியேற்றுகிறது.", 'no': 'Siste år har sett meir komplekse spørsmål-svar på kunnskapsbaser (KBQA) som involverer logisk, kvantitativ og sammenlignbare grunnlag over KB-undergraf. NPI er ein pragmatisk tilnærming mot modularisering av rasjonsprosessen ved å oversette ein kompleks naturleg språk- spørjing til eit fleirsteg køyrbar program. Mens NPI er ofte trent med programmet « gull » eller skikket, for realistiske KBQA-program slike gull-program er dykka for å få. Det finst praktisk berre naturspråkkspørjingar og tilsvarande svar for trening. Det følgjande kombinasjonsfluksjonen i programmerommet, saman med ekstremt spare tiltak, gjer NPI for KBQA ambisyv og utfordring. Vi presenterer kompleks Imperativ program- induksjon frå terminalreturnering (CIPITR), ein avansert neural programmer som minkar sparsiteten med hjelpelige utgåver, og begrenser programmerommet til semantisk korrigere program med høg nivåbegrensningar, KB- skjema og søkte svartype. CIPITR løyser komplekse KBQA betydelig meir nøyaktig enn nøkkelverdiens minnet og neuralsymbolske maskiner (NSM). For moderne komplekse spørsmål som krev 2- til 5- steg- program, vil CIPITR- poeng minst 3 høgare F1 enn konkurentsystema. På ein av dei vanskeste klassene av programmer (samanlikning) med 5–10 trekk vil CIPITR utføre NSM med ein faktor av 89 og minnetverk med 9 ganger.', 'ur': "اگلوں سالوں نے علم بنسس (KBQA) میں زیادہ پیچیدہ سوال جواب دینے والی باتیں دیکھی ہیں جن میں منطقی، منطقی اور مثالفی بحث کیب کے متعلق ہے۔ نئورل پروگرام اینڈکوٹسین (NPI) ایک مطابق مطابق ہے کہ مطابق مطابق طبیعی زبان کی کوریاں multi-step executable پروگرام میں ترجمہ کریں۔ حالانکہ NPI عادت طور پر `سونے' پروگرام یا اس کے اسکیچ کے ساتھ تعلیم کی جاتی ہے، حقیقی KBQA پروگرام کے لئے ایسے سونے کے پروگرام حاصل کرنے کے لئے بہت گران ہیں. وہاں، صرف طبیعی زبان کے سوال اور مناسب جواب کی تعلیم کے لئے دیے جاتے ہیں. اس کے نتیجے میں پروگرامی فضا میں اتارنے والی انفجار، بہت کم اجر کے ساتھ، KBQA کے لئے NPI کو مہربانی اور مشکل بناتا ہے. ہم ترمینلی Rewards (CIPITR) سے کاملکس امپراتیو پروگرامی انڈاکٹینس کو پیش کرتے ہیں، ایک پیشرفت نائرول پروگرامر جو مہربانی اجرت کے ساتھ پارچیتی کو کمٹاتا ہے، اور پروگرامی جگہ کو کمٹاتا ہے کہ اچھی سطح کی محدودیت، KB اسکیم اور کمٹی جواب کی طرح استعمال کریں، اور پروگرامی جگہ کو CIPITR پیچیدہ KBQA کو کلی-ارزش یادگاری نیٹورک اور نیورال سیمبولی ماشین (NSM) سے زیادہ دقیق حل کرتا ہے۔ آسانی پیچیدہ سوال کے لئے 2-5-step پروگراموں کی ضرورت ہے، CIPITR اسکور کم کم 3 زیادہ F1 مسابقه سیستموں سے ہے۔ پیروگراموں میں سے ایک سخت کلاس پر (مقایسہ منظور) 5-10 سطح کے ساتھ، CIPITR 89 اور یاد نیٹورک نیٹورک کے فاکتور سے NSM کو 9 دفعہ سے زیادہ اضافہ کرتا ہے۔", 'uz': "Yaqinda yillar KBQA (KBQA) haqida murakkab savollar javob beradi, logical, quantitativ va qiymati va KB subgrafiklari haqida murakkab qilish mumkin. Name Umumiy `gold' dasturi yoki bu sketch' dastur bilan NPI o'rganilganda, bu dastur qiyin bo'lishi uchun KBQA dasturlari juda qiyin. There, practically only natural language queries and the corresponding answers can be provided for training.  Dasturning bo'yicha komatorial eksplosiyati, juda kichkina paytlar bilan ko'rsatadi, KBQA uchun NPI g'oyalari va qiyin qiladi. Biz Terminal Qaytaridan kompleks amalga oshirish dasturini taqdimot qilamiz, taʼminlovchi soʻzlarni koʻpaytirish uchun qoʻshimcha neyrol dasturi, va dasturning joyini semantik to ʻgʻri dasturlarni kichik darajada, KB uskunalar va taʼminlovchi javob turini ishlatish mumkin. Name Name 5-10 qadam bilan eng eng qiyin dasturlardan biri, CIPITR 89 va xotira tarmoqni 9 marta ishga tushirish mumkin.", 'vi': 'Những năm gần đây đã thấy câu trả lời thắc mắc ngày càng phức tạp về các căn cứ kiến thức (KBQA) liên quan đến các lí lẽ logic, về số lượng và so sánh về siêu thị KB. Trình đầu tư chương trình thần kinh (NPI) là một phương pháp thực dụng để điều chỉnh quá trình lập trình lập trình bằng cách dịch một yêu cầu ngôn ngữ tự nhiên phức tạp thành một chương trình thực thi đa bước. Trong khi NPI đã được huấn luyện phổ biến với chương trình « Vàng » hay bản phác thảo của nó, cho các ứng dụng KBQA thực tế thì những chương trình vàng đó rất đắt tiền để có được. Ở đó, thực tế chỉ có các câu hỏi ngôn ngữ tự nhiên và câu trả lời tương ứng được cung cấp cho huấn luyện. Kết quả của vụ nổ kết hợp trong không gian chương trình, cùng với những phần thưởng cực hẹp, làm cho NPR cho KBQA rất tham vọng và đầy thử thách. Chúng tôi giới thiệu phức tạp Trình Đầu Công Trình phức tạp từ chương trình đỉnh của phần mềm đầu tiên, một lập trình viên thần kinh có thể giảm nhẹ độ cao của các phần thưởng phụ, và hạn chế không gian chương trình với các chương trình có thể đạt được các chương trình theo nghi thức, sử dụng các giới hạn cấp cao, KB gian, và loại trả lời ngược. CIITR giải quyết xong KBQA phức tạp hơn nhiều so với các mạng nhớ giá trị chủ chốt và các cỗ máy biểu tượng thần kinh (NSM). Với các câu hỏi phức tạp cần chương trình 2-5-Step, Nhật Bản ghi ít nhất 3 cao F1 hơn các hệ thống cạnh tranh. Trên một trong những loại chương trình khó nhất (lý lẽ tương đối) với năm lần;8910 bước, CIITR hoàn thiện NSM (nhân tố 899 và mạng bộ nhớ) theo chín lần.', 'bg': 'През последните години се наблюдава все по-сложно отговаряне на въпроси на базата на знания (KBQA), включващо логически, количествени и сравнителни разсъждения върху КБ подграфи. Индукцията на невралната програма (НПИ) е прагматичен подход към модуларизиране на процеса на разсъждаване чрез превод на сложна заявка за естествен език в многостепенна изпълнима програма. Докато НПИ обикновено е обучаван с програмата "злато" или нейната скица, за реалистични приложения на КБК такива програми за злато са скъпи за получаване. Там практически само заявки за естествен език и съответните отговори могат да бъдат предоставени за обучение. Получената от това комбинаторна експлозия в програмното пространство, заедно с изключително оскъдните награди, правят НДК амбициозни и предизвикателни. Представяме комплексна императивна програмна индукция от напреднал невронен програмист, който намалява оскъдността на наградите с помощни награди и ограничава пространството на програмата до семантично коригиране на програми, използвайки ограничения на високо ниво, схема и извлечен тип отговор. CIPITR решава сложния KBQA значително по-точно от ключовите паметни мрежи и невронните символични машини (НСМ). За умерено сложни заявки, изискващи програми от 2 до 5 стъпки, има поне 3 по-високи резултати от конкурентните системи. На една от най-трудните програми (сравнително разсъждаване) с 5-10 стъпки, превъзхожда НСМ с коефициент 89 и паметните мрежи с 9 пъти.', 'nl': "De afgelopen jaren is het antwoord op vragen op kennisbases (KBQA) steeds complexer geworden met logisch, kwantitatief en vergelijkend redeneren over KB-subgrafieken. Neural Program Induction (NPI) is een pragmatische benadering om het redeneringsproces te moduleren door een complexe natuurlijke taalquery te vertalen naar een uitvoerbaar programma met meerdere stappen. Hoewel NPI vaak getraind is met het 'goud' programma of de schets ervan, zijn dergelijke goudprogramma's voor realistische KBQA toepassingen duur om te verkrijgen. Daar kunnen praktisch alleen natuurlijke taalvragen en de bijbehorende antwoorden worden verstrekt voor training. De resulterende combinatorische explosie in de programmaruimte, samen met extreem schaarse beloningen, maakt NPI voor KBQA ambitieus en uitdagend. We presenteren Complex Imperative Program Induction van Terminal Rewards (CIPITR), een geavanceerde neurale programmeur die spaarzaamheid van beloningen vermindert met hulpbeloningen, en de programmaruimte beperkt tot semantisch correcte programma's met behulp van beperkingen op hoog niveau, KB-schema en afgeleid antwoordtype. CIPITR lost complexe KBQA aanzienlijk nauwkeuriger op dan sleutelwaardegeheugennetwerken en neurale symbolische machines (NSM). Voor matig complexe query's die 2-tot 5-staps programma's vereisen, scoort CIPITR ten minste drie hogere F1 dan de concurrerende systemen. Op een van de moeilijkste klasse van programma's (vergelijkend redeneren) met 5-10 stappen, presteert CIPITR NSM met een factor 89 en geheugennetwerken met negen keer.", 'da': "De seneste år har der været stadig mere komplekse spørgsmål-besvarelser på vidensbaser (KBQA), der involverer logisk, kvantitativ og sammenlignende ræsonnement over KB-undergrafer. Neural Program Induction (NPI) er en pragmatisk tilgang til modularisering af ræsonnementsprocessen ved at oversætte en kompleks naturlig sprogforespørgsel til et multi-trins eksekverbart program. Mens NPI ofte er blevet uddannet med 'guld' programmet eller dets skitse, er sådanne guld programmer dyre at få for realistiske KBQA applikationer. Der kan praktisk talt kun naturlige sprogforespørgsler og de tilsvarende svar gives til uddannelse. Den resulterende kombinatoriske eksplosion i programrummet, sammen med ekstremt sparsomme belønninger, gør NPI for KBQA ambitiøs og udfordrende. Vi præsenterer Kompleks Imperative Program Induction from Terminal Rewards (CIPITR), en avanceret neural programmør, der mindsker belønningernes sparsomhed med hjælpebetalinger og begrænser programpladsen til semantisk korrekte programmer ved hjælp af begrænsninger på højt niveau, KB skema og udledt svartype. CIPITR løser komplekse KBQA betydeligt mere præcist end nøgleværdihukommelsesnetværk og neurale symbolske maskiner (NSM). For moderat komplekse forespørgsler, der kræver 2- til 5-trins programmer, scorer CIPITR mindst 3 højere F1 end de konkurrerende systemer. På en af de sværeste klasser af programmer (komparativ ræsonnement) med 5-10 trin, CIPITR overgår NSM med en faktor på 89 og hukommelsesnetværk med 9 gange.", 'hr': "Posljednje godine su vidjeli sve kompleksnije odgovore na pitanje na bazama znanja (KBQA), uključujući logičko, kvantitativno i usporedno razmišljanje u podstavke KB-a. Indukcija neurološkog program a (NPI) je pragmatični pristup modularizaciji razumnog procesa prevodeći kompleksni prirodni jezički zahtjev u multikoracijski program koji se može izvršiti. Iako je NPI obično obučen s programom 'zlato' ili skećem, za realističke aplikacije KBQA, takve zlatne programe su skupe za dobivanje. Tamo se može pružiti praktično samo prirodne ispitivanja jezika i odgovarajuće odgovore za obuku. Rezultat kombinacijske eksplozije u programskom prostoru, zajedno s izuzetno rezervnim nagradama, čini NPI ambicioznim i izazovnim za KBQA. Predstavljamo kompleksno imperativnu programsku indukciju iz povratka terminala (CIPITR), naprednog neuralnog programera koji smanjuje nagradu sparsitnosti s pomoćnim nagradama i ograničava prostor programa na semantički ispravnu programu koristeći ograničenja visokog nivoa, KB šemu i zaraženu vrstu odgovora. CIPITR rješava kompleksni KBQA značajno preciznije od ključne vrijednosti sjećanja i neuralne simbolične stroje (NSM). Za srednje kompleksne ispitivanje koje zahtijevaju programe od 2 do 5 koraka, CIPITR rezultat najmanje 3 viših F1 od konkurentnih sustava. Na jednoj od najtežih klasa programa (usporedno razmišljanje) s 5-10 koraka, CIPITR nadmaže NSM čimbenicom od 89 i sjećanja mreža do 9 puta.", 'fa': 'سالهای اخیر بیشتر از حد پیچیده\u200cتر از پایگاه\u200cهای علمی (KBQA) که شامل منطقی، تعداد و منطقی در زیر زیر\u200cگراف\u200cهای KB است، پاسخ سوال\u200cهای پیچیده\u200cتر را دیده\u200cاند. تنظیم برنامه\u200cهای عصبی (NPI) یک روش پراگرماتیک به سمت موډول\u200cسازی فرایند منطقی با ترجمه کردن یک پرسش زبان طبیعی پیچیده به برنامه\u200cای قابل اجرای چندین قدم است. در حالی که NPI معمولا با برنامه طلا یا sketch آن آموزش داده شده است، برای برنامه\u200cهای واقعی KBQA چنین برنامه\u200cهای طلا برای گرفتن گران است. در آنجا، تقریبا فقط سوال زبان طبیعی و جواب\u200cهای متفاوتی برای آموزش می\u200cتوانند داده شوند. نتیجه انفجار ترکیبی در فضای برنامه، همراه با پاداش بسیار کمی، NPI را برای KBQA آمیز و مشکل می کند. ما تأثیر برنامه\u200cی پادشاهی کاملکس را از برنامه\u200cهای تأثیر ترمینال (CIPITR) پیشنهاد می\u200cکنیم، یک برنامه\u200cکننده\u200cی عصبی پیشرفته که پاداش\u200cهای پاداش کمک می\u200cکند، و فضای برنامه را محدود می\u200cکند تا برنامه\u200cهای تأثیر سطح بالا، برنامه\u200cهای KB و نوع جواب\u200cهای تأثیر CIPITR KBQA پیچیده را از شبکه\u200cهای حافظه\u200cهای کلید و ماشین\u200cهای سیمبولیک عصبی (NSM) به طور کامل دقیق تر حل می\u200cکند. برای پرسش های متوسط پیچیده\u200cای که برای برنامه\u200cهای ۲ تا ۵ قدم نیاز دارند، CIPITR حداقل ۳ قدم بالاتر از سیستم\u200cهای رقابت می\u200cباشد. در یکی از سخت\u200cترین کلاس برنامه\u200cها (دلیل مقایسه) با 5-10 قدم، CIPITR به عنوان یک faktor از 89 و شبکه حافظه تا 9 بار به NSM اجرا می\u200cکند.', 'sw': "Miaka ya hivi karibuni imeshuhudia kujibu maswali magumu kwenye misingi ya maarifa (KBQA) yanayohusu logical, kiasi na kinachofananisha hoja juu ya vifaa vya KB. Ujenzi wa Programu ya NPI (NPI) ni mbinu muhimu kuelekea kuelekeza mchakato wa maana kwa kutafsiri utafiti wa lugha ya asili katika programu inayotekelezwa kwa hatua nyingi. Wakati NPI imefundishwa mara nyingi kwa mpango wa 'dhahabu' au michoro yake, kwa matumizi ya KBQA halisi ni gharama kama hizo za dhahabu kupata. Hali, kwa hakika, maswali ya lugha ya asili na majibu yanayojibu yanaweza kutolewa kwa ajili ya mafunzo. The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes NPI for KBQA ambitious and challenging.  We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type.  CIPITR inatoa tatizo la KBQA kwa kiasi kikubwa zaidi ya mitandao ya kumbukumbu muhimu na mashine za kiungo (NSM). Kwa maswali matatizo ya kisasa yanayohitaji programu ya hatua 2-5, CIPITR score angalau 3 juu ya F1 kuliko mifumo ya ushindani. Katika moja ya vipindi vigumu zaidi vya programu (maana yanayolinganisha) na hatua 5-10, CIPITR inafanya NSM kwa sababu ya 89 na mitandao ya kumbukumbu kwa mara 9.", 'de': 'In den letzten Jahren ist die Beantwortung von Fragen auf Wissensbasen (KBQA) mit logischem, quantitativem und vergleichendem Denken über KB-Subgraphen immer komplexer geworden. Neural Program Induction (NPI) ist ein pragmatischer Ansatz zur Modularisierung des Argumentationsprozesses durch die Übersetzung einer komplexen natürlichen Sprachabfrage in ein mehrstufiges ausführbares Programm. Während NPI üblicherweise mit dem "Gold"-Programm oder seiner Skizze trainiert wurde, sind solche Goldprogramme für realistische KBQA-Anwendungen teuer zu erhalten. Dort können praktisch nur natursprachliche Fragen und die entsprechenden Antworten für Schulungen bereitgestellt werden. Die daraus resultierende kombinatorische Explosion des Programmraums und die extrem spärlichen Belohnungen machen NPI für KBQA ehrgeizig und herausfordernd. Wir präsentieren Complex Imperative Program Induction von Terminal Rewards (CIPITR), einen fortschrittlichen neuronalen Programmierer, der Belohnungsschwierigkeit durch Hilfsbelohnungen mindert und den Programmraum auf semantisch korrekte Programme unter Verwendung von High-Level-Einschränkungen, KB-Schema und abgeleitetem Antworttyp beschränkt. CIPITR löst komplexe KBQA deutlich genauer als Schlüsselwertspeichernetze und neuronale symbolische Maschinen (NSM). Bei mittelkomplexen Abfragen, die 2- bis 5-stufige Programme erfordern, punktet CIPITR mindestens drei höhere F1 als die konkurrierenden Systeme. Auf einer der härtesten Klassen von Programmen (vergleichendes Denken) mit 5-10 Schritten übertrifft CIPITR NSM um einen Faktor 89 und Speichernetzwerke um das 9-fache.', 'id': "Tahun-tahun terakhir telah melihat jawaban pertanyaan yang semakin kompleks pada dasar pengetahuan (KBQA) yang melibatkan alasan logis, kuantitatif, dan perbandingan atas subgraf KB. Program Neural Induction (NPI) adalah pendekatan pragmatis menuju modularisasi proses reasoning dengan menerjemahkan pertanyaan bahasa alam kompleks ke program yang dapat dilaksanakan multi-langkah. Sementara NPI biasanya dilatih dengan program 'emas' atau sketsanya, untuk aplikasi KBQA realistis program emas seperti itu mahal untuk mendapatkan. Di sana, praktis hanya pertanyaan bahasa alami dan jawaban yang sesuai dapat disediakan untuk pelatihan. Penyebab ledakan kombinatorial di ruang program, bersama dengan hadiah yang sangat sedikit, membuat NPI untuk KBQA ambisius dan menantang. Kami mempersembahkan Induksi Program Imperatif Kompleks dari Pembayaran Terminal (CIPITR), seorang programmer saraf maju yang mengurangi kemudahan penghargaan dengan penghargaan tambahan, dan membatasi ruang program untuk program yang secara semantis benar menggunakan batasan tingkat tinggi, skema KB, dan tipe jawaban yang diperkirakan. CIPITR memecahkan KBQA kompleks jauh lebih akurat dari jaringan memori nilai kunci dan mesin simbolik saraf (NSM). Untuk pertanyaan yang sangat kompleks yang memerlukan program 2-5 langkah, CIPITR skor setidaknya 3 F1 lebih tinggi dari sistem yang bersaing. On one of the hardest class of programs (comparative reasoning) with 5-10 steps, CIPITR outperforms NSM by a factor of 89 and memory networks by 9 times.", 'af': "Onlangse jaar het die meerder kompleks vraag- antwoord gesien op kennis bases (KQA) wat logiese, kvantitatiewe en vergelykbare redening oor Kb subgraaf invoer. Neurale Program Induksie (NPI) is 'n pragmatiske toegang tot modularisering van die redering proses deur 'n kompleks natuurlike taal navraag in' n multi- step uitvoerbare program te vertaling. Terwyl NPI gewoonlik opgelei is met die 'goud' program of sy sketch, vir realistiese KQA-programme sodanige goud programme is koste om te kry. Daar, praktiese slegs natuurlike taal vrae en die ooreenstemmende antwoordes kan voorsien word vir onderwerp. Die resulteerde kombinatoriese eksplosie in program ruimte, saam met ekstrem sparse vergelde, maak NPI vir KQA ambisieus en uitgelaat. Ons stel kompleks Imperative Program Induksie van Terminaal Rewars (CIPITR), ' n gevorderde neuralprogrammeer wat verloor sparsiteit met hulpbrekende vergelde, en beperk die program ruimte na semantiese korrekte programme te gebruik hoë vlak beheinings, Kb skema en vergelykde antwoord tipe. CIPITR los kompleks KQA aansienlik meer presies as sleutel- waarde geheue netwerke en neurale simboliese masjiene (NSM). Vir middels komplekse vraagte wat 2- to 5- stappe programme benodig, CyPITR tellers minste 3 hooghearde F1 as die mededingsstelsels. Op een van die hardeste klas van programme (vergelykbaar redening) met 5-10 stappe, CIPITR uitvoer NSM deur 'n faktor van 89 en geheue netwerke deur 9 maal.", 'am': "Recent years have seen increasingly complex question-answering on knowledge bases (KBQA) involving logical, quantitative, and comparative reasoning over KB subgraphs.  የውይይት ፕሮግራም ማሳየት (NPI) የውይይት ፕሮግራም አካባቢ ቋንቋን በመግለጥ በተጨማሪው ቋንቋ ጠይቅ ለመፍጠር ወደ ብዙ-ደረጃዎች ተሟጋቾች ፕሮግራም ለመግለጥ የሚችል አዋጅ ነው፡፡ በ'ወርቅ' ፕሮግራም ወይም ቀስክ የተማሩ ሲሆኑ የNPI ፕሮግራሙን እንደዚህ የወርቅ ፕሮግራሞች ለማግኘት ዋጋ ነው፡፡ በዚያ፣ የፍጥረት ቋንቋ ጥያቄዎች ብቻ ሲሆኑ እና የመስጠት መልስ ለትምህርት ማድረግ ይችላል፡፡ በፕሮግራም ቦታ ውስጥ የኮንዶታዊ ቦታ፣ በተጨማሪም ዋጋ፣ ለKBQA አፍቃሪ እና አፍቃሪነት የሚያደርጋት NPI፡፡ ተርሚናል ውስጥ ቅድሚያ የፕሮግራሙን ማነሻ (CIPITR) እናሳየዋለን፤ ትክክለኛውን የነዌብ ፕሮግራም የዋጋውን ምርጫዎች በተጨማሪ ዋጋ የሚያጎድል እና የፕሮግራሙን ቦታ በክፍለ ደረጃ ማቀናቀል ፕሮግራሙቶችን ከክፍለ ደረጃ ግንኙነት፣ የKB ስሜማ እና የመስጠት መልስ ዓይነት እና አካባቢ ነው። CIPITR ትክክለኛውን KBQA በቁልፍ-value ማስታወሻ መረብ እና የነዌብ ምልክት መሳሪያዎች (NSM) በመፍታት ይፈጽማል። 2 - 5 ደረጃ ፕሮግራም እንዲያስፈልጋቸው በተቃውሞው ውይይቶች ላይ CIPITR scores at least 3 ከፍተኛ F1 ደረጃዎች ከችግሮች. 5-10 ደረጃዎች በተደረገ የፕሮግራሞች አንዱ ላይ CIPITR የ89 እና የመስታሰቢያ መረብ በ9 ጊዜ ያሳያል፡፡", 'ko': "최근 몇 년 동안 지식 라이브러리 문답(KBQA)은 갈수록 복잡해지고 KB 서브맵에 대한 논리, 정량과 비교 추리와 관련된다.신경 프로그램 요약(NPI)은 복잡한 자연 언어 조회를 다단계 실행 프로그램으로 변환함으로써 추리 과정을 모듈화하는 실용적인 방법이다.NPI는 통상적으로'황금'계획이나 그 초도를 통해 교육을 진행하지만 현실적인 KBQA 응용 프로그램에 대해서는 이런 황금 계획의 획득 원가가 매우 높다.그곳에서는 사실상 교육을 위해 자연 언어 조회와 상응하는 답안만 제공할 수 있다.이로 인해 발생한 프로그램 공간 조합 폭발과 극히 드문 보상으로 KBQA의 NPI는 야심차고 도전적이었다.우리는 복잡한 명령식 프로그램 귀납 단말기 보상(CIPITR)을 제시했다. 이것은 선진적인 신경 프로그래머로서 보조 보상을 통해 보상의 희소성을 완화시키고 고급 제약, 지식 라이브러리 모델과 추정 답안 유형을 사용하여 프로그램 공간을 의미의 정확한 순서로 제한한다.CIPITR은 키값 기억망과 신경기호기(NSM)보다 복잡한 KBQA 문제를 더 정확하게 해결한다.2~5단계 프로그램이 필요한 중등 복잡한 조회에 대해 CIPITR의 F1 점수는 적어도 경쟁 시스템보다 3점 높다.가장 어려운 프로그램(비교 추리)에는 5~10단계가 있는데 CIPITR이 NSM보다 89배, 메모리 네트워크보다 9배 좋다.", 'az': "Son illərdə, KB subgraflarında logik, kvantitatlı və müqayisədə müzakirə müzakirə olunan bilgi üssələri (KBQA) barəsində daha çox kompleks sual cavabı görmüşdü. NPI müxtəlif təbiətli dil sualını çoxlu adım icra edilə bilən proqramına çevirib razılıq prosesini modularizaşdırmaq üçün pragmatik tərzidir. NPI çox çox 'altın' proqramı və ya sketchi ilə təhsil edilmiş halda, bu altın proqramları almaq üçün gerçek KBQA proqramları üçün xərclənir. Orada yalnız təbiətli dil soruşmaları və müəyyən cavabları təhsil etmək üçün təhsil edilə bilər. Növbəti proqramın kosmosundaki kombinatorial patlaması, çox az mükafatları ilə birlikdə KBQA üçün NPI məşğul və çətin edir. Biz Terminal Rewards (CIPITR) tərəfindən kompleks Imperative Program Induction (kompleks Imperative Program Induction) göstəririk. Bu, yüksək səviyyə müəyyənləşdirmələri, KB schema və düşürülmüş cevap türünü istifadə edərək, çox yüksək səviyyə müəyyənləşdirən bir nöral programcısı ilə mükafatlandırır. CIPITR kompleks KBQA'yi anahtar qiyməti yaddaş ağlarından və nöral simbolik maşınlardan daha doğrudan çəkir. Ortada kompleks soruşmalar üçün 2-5-adım proqramları lazımdır, CIPITR müharibə sistemlərindən ən az 3 yüksək F1 nəticəsi. 5-10 adımları ilə müqayisədə ən çətin proqramların birində, CIPITR 89 və 9 dəfə hafıza a ğlarının faktoru ilə NSM'i üstün edir.", 'hy': 'Վերջին տարիները տեսել են ավելի բարդ հարցերի պատասխաններ գիտելիքի հիմքերի վրա, որոնք ներառում են տրամաբանական, քանակական և համեմատական մտածողություն ԿԲ ենթագրաֆիկների վերաբերյալ: Նյարդային ծրագրի ինդուկցիան (ՆՈՊ) պրագմատիկ մոտեցում է մտածողության գործընթացի մոդուլարիզացիայի համար՝ բարդ բնական լեզվի հարցում թարգմանելով բազմաքայլերի կատարելագործելի ծրագրի մեջ: Մինչդեռ ՆՊԻ-ը սովորաբար ուսուցանվել է "ոսկու" ծրագրով կամ դրա դիզայներով, իրական ԿԲՔԱ ծրագրերի համար այդպիսի ոսկու ծրագրերը թանկ են ստանալու: Այնտեղ, գրեթե միայն բնական լեզվի հարցեր և համապատասխան պատասխաններ կարող են տրամադրվել ուսուցման համար: Արդյունքում ծրագրային տարածության համադրական պայթյունը, ինչպես նաև չափազանց քիչ պարգևատվությունները, դարձնում է ԿԲՔԱ-ի համար անհրաժեշտ և մարտահրավեր: Մենք ներկայացնում ենք Թերմինալ Արժեքներից ստացված համակարգչային ծրագրի ինդուկցիա (CIPiTre), զարգացած նյարդային ծրագրավորող, որը նվազեցնում է պարգևատրությունը օգտագործելով օգտագործվող պարգևատրություններ, և սահմանափակում է ծրագրի տարածքը սեմանտիկապես ճիշտ ծրագրերի վրա՝ օգտագործելով բար CIPL-ն ավելի ճշգրիտ լուծում է խճճված KOQA-ը, քան հիշողության ցանցերը և նյարդային սիմվոլիկ մեքենաները (NSM). Միջինս բարդ հարցերի համար, որոնք պահանջում են 2-5 քայլ ծրագրեր, CIPL-ը նշում է առնվազն 3 ավելի բարձր F1-ը, քան մրցակցող համակարգերը: 5-10 քայլներով ամենաբարդ ծրագրերից մեկում (համեմատական մտածելակերպ) CIPiT-ը ինը անգամ գերազանցում է NSM-ին 89 անգամ, իսկ հիշողության ցանցերը՝ 9 անգամ:', 'bn': "সাম্প্রতিক বছরগুলো জ্ঞানের বেস (কেবিকিউএ) সম্পর্কে জ্ঞানের প্রশ্নের উত্তর বৃদ্ধিমান জটিল প্রশ্নের উত্তর দেখেছে যার মধ্যে লোগিক, পর নিউরেল প্রোগ্রাম নির্মাণ (এনপিআই) একটি প্রাকৃতিক প্রক্রিয়ার প্রতি ব্যাক্তিগত পদ্ধতি যা মোডামুলেটিং করে একটি জটিল প্রাকৃতিক ভাষ এনপিআই সাধারণত 'সোনার' প্রোগ্রাম বা স্ক্যাচের সাথে প্রশিক্ষণ প্রদান করা হয়েছে, কিন্তু বাস্তবতার কেবিকিউএ অ্যাপলিকেশন এই সেখানে প্রাকৃতিক ভাষার প্রশ্ন এবং প্রশিক্ষণের জন্য সংশোধনী উত্তর প্রদান করা যাবে। এর ফলে প্রোগ্রামের স্পেসে বিস্ফোরণের মিনিটেরিয়াল বিস্ফোরণ, অত্যন্ত স্মার্স পুরস্কারের সাথে এনপিআই কেবিকিউএ এর জন্ We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type.  CIPITR সমাধান করে কে- বিকিউ- এর জটিল মেমরি নেটওয়ার্ক এবং নিউরেল প্রতীক মেশিন (NSM) এর চেয়ে বেশি সঠিকভাবে সমাধান করে। প্রতিযোগিতা সিস্টেমের চেয়ে অন্তত ৩ থেকে বেশী বেশী জটিল প্রশ্নের জন্য সিআইপিটার স্কোর। ৫-১০ পদক্ষেপের সাথে প্রোগ্রামের সবচেয়ে কঠিন ক্লাসে সিআইপিটার ৮৯ এবং স্মৃতির নেটওয়ার্কের মাধ্যমে ৯ বার প্রকাশ করেছে।", 'tr': "Soňky ýyllar KiB grafiklerinde logik, quantitat we salyklaşyk sebäpleri barada karmaşık soraglaryň jogaplary (KBQA) üstünde görýärler. NPI mantal programi üçin razylygy işlemek üçin gaty bir tebigy dil soragyny multi-ýolumny öwrülerek pragmatik ýagdaýdur. NPI köplenç 'altyn' programi ýa-da özüniň çizmegi bilen bilinýär. Bu ýaly altyn programler üçin baýlyk çykýar. Şu ýerde diňe tebigy dil soraglary we täsirli jogabalary okuw üçin berilebilir. Programiň seleňinde birleşik, iň az üýtgewler bilen birleşik, NPI'i KBQA üçin hili höwesli we çözgüli döredýär. Biz Terminal Ýerinden kompleks iň umydlaýyn Program Induksyzlygy (CIPITR), gelişmiş näral program çisi, kömekli täsirlerle azaltyp, programiň seleňini ýokary derejesi ýok derejesi, KB şemalary we hasaplanýan jogabat hilini ulanyp programlary semantik derejesi çykarýar. KIPITR karmaşık KBQA açyk Mykdarlyk aýtlary we neiral simbolik eýtlary (NSM) den has dogry çözdi. Orta karmaşık soraglar üçin 2-we 5-adım programlere gerek, CIPITR ýaryşy sistemlerden iň azyndan 3 iň yüksek F1 sany çykar. 5-10 adımlar bilen programlaryň iň kyn synpynda CIPITR 89-nji we 9 gezek a ýratyn netijesi tarapyndan NSM'i üstün edýär.", 'cs': 'V posledních letech bylo zaznamenáno stále složitější odpovědi na otázky na znalostních bázích (KBQA) zahrnující logické, kvantitativní a srovnávací uvažování nad podgrafy KB. Neuronová indukce programu (NPI) je pragmatický přístup k modularizaci procesu uvažování překladem komplexního dotazu přirozeného jazyka do vícestupňového spustitelného programu. Zatímco NPI byl běžně trénován s "zlatým" programem nebo jeho nákresem, pro realistické aplikace KBQA jsou tyto zlaté programy drahé získat. Tam lze pro školení poskytnout prakticky pouze dotazy přirozeného jazyka a odpovídající odpovědi. Výsledná kombinační exploze programového prostoru spolu s extrémně řídkými odměnami činí NPI pro KBQA ambiciózní a náročné. Představujeme komplexní imperativní program indukce z terminálních odměn (CIPITR), pokročilý neuronový programátor, který zmírňuje řídkost odměn pomocí pomocných odměn a omezuje prostor programu na sémanticky korektní programy pomocí omezení na vysoké úrovni, KB schéma a odvozeného typu odpovědi. CIPITR řeší komplexní KBQA podstatně přesněji než paměťové sítě s klíčovou hodnotou a neuronové symbolické stroje (NSM). U středně složitých dotazů vyžadujících dvoukrokové až pětikrokové programy, CIPITR skóre alespoň o tři vyšší F1 než konkurenční systémy. Na jedné z nejtěžších tříd programů (komparativní uvažování) s 5-10 kroky CIPITR překonává NSM o faktor 89 a paměťové sítě o devítkrát.', 'sq': "Vitet e fundit kanë parë përgjigje gjithnjë e më komplekse pyetjesh mbi bazat e njohurive (KBQA) duke përfshirë arsyetim logjik, kuantitativ dhe krahasues mbi nëngrafitë e KB. Programi Neural Induction (NPI) është një metodë pragmatike drejt modulimit të procesit të arsyetimit duke përkthyer një kërkesë komplekse të gjuhës natyrore në një program të zbatueshëm me shumë hapa. While NPI has been commonly trained with the 'gold' program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain.  Atje, praktikisht vetëm pyetjet natyrore të gjuhës dhe përgjigjet korrespondente mund të ofrohen për trajnimin. Shpërthimi kombinatori që rezulton në hapësirën e programit, së bashku me shpërblime jashtëzakonisht të pakta, bën NPI për KBQA ambicioz dhe sfidues. Ne paraqesim Indukcionin Kompleks Imperativ të Programit nga Çmimet Terminale (CIPITR), një programues i avancuar nervor që lehtëson shpërblimin e paktësisë me shpërblimin ndihmës dhe kufizon hapësirën e programit për të korrektuar në mënyrë semantike programet duke përdorur kufizime të nivelit të lartë, skemën KB dhe llojin e përgjigjes së përfunduar. CIPITR zgjidh KBQA kompleks me shumë më saktësi se rrjetet e kujtesës me vlerë kyçe dhe makinat simbolike neuronale (NSM). Për pyetje moderatamente komplekse që kërkojnë programe prej 2 deri në 5 hapash, CIPITR shënon së paku 3 F1 më të lartë se sistemet konkurruese. On one of the hardest class of programs (comparative reasoning) with 5-10 steps, CIPITR outperforms NSM by a factor of 89 and memory networks by 9 times.", 'bs': "Posljednje godine su vidjeli sve kompleksnije odgovore na pitanje na bazama znanja (KBQA) uključujući logičko, kvantitativno i usporedno razmišljanje po podgrafcima KB. Indukcija neuronskog program a (NPI) je pragmatičan pristup modularizaciji procesa razumanja prevodeći kompleksni prirodni jezički zahtev u multikoracijski program koji se može izvršiti. Iako je NPI obično obučen s programom 'zlato' ili skećem, za realistične aplikacije KBQA, takve zlatne programe su skupe za dobivanje. Tamo se može pružiti praktično samo prirodne ispitivanja jezika i odgovarajući odgovori za obuku. Rezultat kombinacijske eksplozije u programskom prostoru, zajedno sa izuzetno rezervnim nagradama, čini NPI ambicioznim i izazovnim za KBQA. Predstavljamo kompleksno imperativnu programsku indukciju iz povratka terminala (CIPITR), naprednog neuralnog programera koji smanjuje nagradu sparsitnosti s pomoćnim nagradama, i ograničava prostor programa da semantički ispravi programe koristeći ograničenja visokog nivoa, KB šemu i inficirane vrste odgovora. CIPITR reši kompleksni KBQA značajno tačnije od ključne vrijednosti sjećanja i neuralne simbolične mašine (NSM). Za moderno kompleksne ispitivanje koje zahtijevaju 2 do 5 koraka programe, CIPITR rezultate najmanje 3 više F1 od konkurentnih sustava. Na jednoj od najtežih klasa programa (usporedno razmišljanje) sa 5-10 koraka, CIPITR nadmaže NSM faktorom 89 i sjećanja mreža do 9 puta.", 'ca': "Els últims anys han vist respostes cada cop més complexes a preguntes en bases de coneixement (KBQA) que impliquen raonament lògic, quantitatiu i comparatiu sobre subgràfics de KB. L'Inducció del Program a Neural (NPI) és un enfocament pragmàtic cap a modular el procés de raonament traducint una pregunta natural complexa en un programa executable en moltes etapes. Mentre que NPI ha estat format comument amb el programa 'or' o el seu esboç, per aplicacions realistes KBQA aquests programes d'or són costosos d'obtenir. Allà, pràcticament només es poden proporcionar preguntes naturals de llenguatge i les respostes correspondents per a l'entrenament. L'explosió combinatorial que resulta en l'espai de programes, juntament amb recompensas extremadament escases, fa que l'INP per KBQA sigui ambiciós i desafiant. Presentam l'Inducció Complexa Imperativa del Programa a partir dels Compromís Terminal (CIPITR), un programador neuronal avançat que mitiga la escassetat de recompensa amb recompensas auxiliars i limita l'espai del programa a programes senànticament correctes fent servir restriccions d'alt nivell, esquema KB i tipus de resposta inferida. CIPITR soluciona KBQA complexe de manera considerablement més precisa que les xarxes de memòria de valor clau i les màquines simbóliques neuronals (NSM). Per a preguntes moderadament complexes que requereixen programes de 2 a 5 etapes, CIPITR puntueix al menys 3 F1 més alts que els sistemes competidors. On one of the hardest class of programs (comparative reasoning) with 5-10 steps, CIPITR outperforms NSM by a factor of 89 and memory networks by 9 times.", 'et': 'Viimastel aastatel on teadmistebaasidel (KBQA) järjest keerulisem küsimustele vastamine, mis hõlmab loogilist, kvantitatiivset ja võrdlevat arutlust KB alagraafikutes. Neural Program Induction (NPI) on pragmaatiline lähenemine arutlusprotsessi modulariseerimisele, tõlkides keerulise looduskeele päringu mitmeastmeliseks käivitatavaks programmiks. Kuigi NPI-d on tavaliselt koolitatud kuldprogrammi või selle sketchi abil, on realistlike KBQA rakenduste jaoks selliste kuldprogrammide hankimine kallis. Seal saab koolituseks anda praktiliselt ainult looduskeelseid päringuid ja vastavaid vastuseid. Sellest tulenev programmiruumi kombinatiivne plahvatus koos äärmiselt hõredate preemiatega muudab KBQA NPI ambitsioonikaks ja väljakutseks. Esitleme Complex Imperative Program Induction from Terminal Rewards (CIPITR), täiustatud neuroprogrammeerija, mis leevendab tasude nappust abitasudega ja piirab programmi ruumi semantiliselt korrigeerivate programmide abil, kasutades kõrgetasemelisi piiranguid, KB skeeme ja järeldatud vastuse tüüpi. CIPITR lahendab keerulise KBQA oluliselt täpsemalt kui võtmeväärtusega mäluvõrgud ja närvisümboolsed masinad (NSM). Mõõdukalt keerukate päringute puhul, mis nõuavad 2-5-astmelisi programme, on CIPITR-i tulemused vähemalt 3 kõrgemad F1 kui konkureerivad süsteemid. Ühes kõige raskemas klassis programme (võrdlev arutluskäik) 5-10 sammuga ületab CIPITR NSM-i teguriga 89 ja mäluvõrkude 9 korda.', 'fi': 'Viime vuosina on tapahtunut yhä monimutkaisempia tietopohjaisia kysymyksiä (KBQA), joissa on käytetty loogista, kvantitatiivista ja vertailevaa päättelyä KB-alakaavioiden avulla. Neural Program Induction (NPI) on pragmaattinen lähestymistapa päättelyprosessin modulointiin kääntämällä monimutkaisen luonnollisen kielen kyselyn monivaiheiseksi suoritettavaksi ohjelmaksi. Vaikka NPI:tä on yleisesti koulutettu kultaohjelmalla tai sen luonnoksella, realistisiin KBQA-sovelluksiin tällaisten kultaohjelmien hankkiminen on kallista. Koulutukseen voidaan antaa käytännössä vain luonnollisen kielen kyselyjä ja vastaavia vastauksia. Ohjelmatilan kombinatorinen räjähdys ja erittäin harvat palkkiot tekevät NPI:stä kunnianhimoisen ja haastavan. Esittelemme Complex Imperative Program Induction from Terminal Rewards (CIPITR), kehittyneen neuroohjelmoijan, joka vähentää palkkion niukkuutta apupalkinnoilla ja rajoittaa ohjelmatilan semanttisesti korjaamaan ohjelmia käyttämällä korkean tason rajoituksia, KB-kaavioita ja johdettua vastaustyyppiä. CIPITR ratkaisee monimutkaisen KBQA:n huomattavasti tarkemmin kuin avainarvomuistiverkot ja neurosymboliset koneet (NSM). Keskivaikeasti monimutkaisissa kyselyissä, joissa vaaditaan 2–5-vaiheisia ohjelmia, CIPITR-pisteet ovat vähintään 3 korkeammat kuin kilpailevat järjestelmät. Yhdessä vaikeimmista ohjelmista (vertaileva päättely), jossa on 5-10 vaihetta, CIPITR ylittää NSM:n kertoimella 89 ja muistiverkot 9 kertaa.', 'he': 'בשנים האחרונות ראו תשובות לשאלות מורכבות יותר ויותר על בסיסי ידע (KBQA) שמעניינות הגיונית, כיוונטיבית ושוואה על תחתיות KB. תוכנית נוירואלית (NPI) היא גישה פרגמטית לכיוון מודולרית תהליך ההיגיון על ידי תרגום בקשה טבעית מורכבת לשפה לתוכנית ניצחת במספר צעדים. בעוד NPI הוכשר בדרך כלל עם תוכנית הזהב או הסקיץ שלה, עבור שימושים KBQA מציאותיים תוכניות זהב כאלה יקרות להשיג. שם, כמעט רק שאלות שפות טבעיות והתשובות המתאימות יכולות לתת לאימון. הפיצוץ הקובינטוריאלי הנוצא בחלל התוכנית, יחד עם פרסים נדירים ביותר, הופך את NPI עבור KBQA שאפתני ומתאגר. אנו מציגים התכנית אימפרטיבית מורכבת משכורות טמינליות (CIPITR), מתכנן עצבי מתקדם שמקל את התפרסות העדיפות עם פרסים עזריים, ומגבלת את מרחב התכנית לתכניות נכונות סמנטית באמצעות מחסומים ברמה גבוהה, סגמה KB, וסוג התשובה המתוצאת. CIPITR פותר KBQA מורכב בהרבה יותר מדויק מרשתות זיכרון בערך מפתח ומכונות סמליות עצביות (NSM). עבור שאלות מורכבות במידה דורשות תוכניות של 2 עד 5 צעדים, CIPITR נקודות לפחות 3 F1 גבוהות יותר מהמערכות המתחרות. באחד מהכיתה הקשה ביותר של תוכניות (הסיבה שיוותית) עם 5-10 צעדים, CIPITR מפעיל NSM על ידי גורם של 89 ורשתות זיכרון על ידי 9 פעמים.', 'sk': 'V zadnjih letih je bilo vse bolj zapleteno odgovarjanje na vprašanja na osnovi znanja (KBQA), ki vključuje logično, kvantitativno in primerjalno razmišljanje v podgrafih KB. Neural Program Induction (NPI) je pragmatičen pristop k modularizaciji procesa razmišljanja s prevajanjem kompleksne poizvedbe naravnega jezika v izvedljiv program z več koraki. Medtem ko se NPI običajno usposablja s programom "zlato" ali njegovo skico, je za realistične aplikacije KBQA takšne zlate programe drago pridobiti. Tam je za usposabljanje mogoče zagotoviti praktično samo vprašanja v naravnem jeziku in ustrezne odgovore. Posledična kombinacijska eksplozija v programskem prostoru, skupaj z izjemno redkimi nagradami, naredi NPI za KBQA ambiciozen in zahteven. Predstavljamo vam kompleksni imperativni program indukcije iz Terminal Rewards (CIPITR), naprednega nevronskega programerja, ki zmanjšuje redkost nagrad s pomožnimi nagradami in omejuje programski prostor na semantično popravljanje programov z uporabo omejitev visoke ravni, sheme KB in sklepane vrste odgovora. CIPITR rešuje kompleksne KBQA precej natančneje kot pomnilniška omrežja s ključno vrednostjo in nevronskimi simboličnimi stroji (NSM). Za zmerno zapletene poizvedbe, ki zahtevajo programe v 2 do 5 korakih, CIPITR ocenjuje vsaj 3 višje F1 kot konkurenčni sistemi. Na enem od najtežjih programov (primerjalno razmišljanje) s 5-10 koraki CIPITR presega NSM za faktor 89, pomnilniška omrežja pa za 9-krat.', 'ha': "Yinin da suka sani an ƙara tambayar su mai tsanani a kan basar ilmi (KBQA) mai amfani da logical, gwargwadon da kuma masu sami da jãyayya kan subgrafyutan KB. Shirin shirin Naural na Naurar (NPI) shi ne wata mazaɓa mai fassara zuwa modulori da za'a fassara wani sura cikin harshen da ke cikin wata shirin da za'a zartar da wasu-daban. A lokacin da aka sanar da NPI wa kawaici da shirin 'zĩnãriya' ko miskiyar kwamfyuta, ko da shiryoyin KBQA masu yiwuwa na shiryoyin ayuka na zĩnãriya masu nau'i a gane su. Halin, za'a iya ƙayyade tambayar lugha masu natsi kawai kuma a iya samar da masĩfun da suke daidai zuwa mafarin. Ga ta ƙara wata firgita ta komatiyatori cikin filin shirin ayuka, da kuma da musanyi mai girma, sai ya sanya NPI wa KBQA mai kwaɗayi da mai gauraya. Tuna halatar da Shirin Ayuka na Complex Indoyi daga Tammar Mai Gabatãwa (CIPTIR), wata na tsẽre na shiryoyin neural wanda ke cire kwamfyuta da sakamakon taƙaitacce, kuma yana ƙunsa da shirin ayuka zuwa na daidaita shiryoyin ayukan da aka yi amfani da tsari masu sarrafa da babban daraja, na ƙayyade KB da nau'in da aka buga zafi. KCharselect unicode block name @ action: button Daga wani daga fasin shiryoyin ayuka mafi tsanani (masu samura da fasa) da 5-10 ƙõfõfi, CIPTIR na tafiyar NSM da faktor na 89 da jerin hukar tunar dace 9 sau.", 'bo': "འཕྲལ་གསོག་པའི་ལོ་ངོ་ཚོས་མཐོ་རྣམས་མཐོང་ནི་དབྱིབས་ཤེས་ཀྱི་གཞི་གཞི་རྟེན་ནས་ཕན་ཚུན་ལས་དཀའ་ངལ་ཆེ་བ་ལྷན་འདུག Neural Program Induction (NPI) is a pragmatic approach toward modularizing the reasoning process by translating a complex natural language query into a multi-step executable program. NPI ་ནི་རྒྱུན་ལྡན་གྱིས་ 'golden'བྱ་རིམ་ཡང་ན་དེའི་ངང་ཁེབས་ཀྱིས་གཞི་སྒྲིག་ཡོད་ནའང་། དངོས་ཡོད་ཐོག་ལས་སྤྱོད་འདི་ལྟ་བུ དེ་རིང་གིས་སྤྱིར་བཏང་བའི་རང་བཞིན་གྱི་སྐད་ཡིག་གདོང་ལེན་དང་མཐུན་པ་ཚོར་དོ་སྤྲོད་དགོས། དབྱེ་རིམ་གྱི་བར་སྟོང་ནང་མཉམ་ལས་མཇུག་བསྡུ་བར་ཐག་མིན་པའི་མཐའ་སྡུར་ལ་མཉམ་དུ་བསྡུར་ན། We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type. CIPITR solves complex KBQA considerably more accurately than key-value memory networks and neural symbolic machines (NSM). For moderately complex queries requiring 2-to 5-step programs, CIPITR scores at least 3 higher F1 than the competing systems. Additional hint for power users: This KDEPrint GUI element corresponds to the CUPS command line argument On one of the hardest class of programs (comparative reasoning) with 5-10 steps, CIPITR outperforms NSM by a factor of 89 and memory networks by 9 times.", 'jv': 'biasane sampeyang mrogram NPI Sampeyan NPI wis digawe ngomongke oleh \'golang\' program apa karo nganggo sak dadi, kaya aplikasi sistem kiban segala kejahatan Didalah, saiki dipun langkung popong dadi lan mbubatuhke respon sing bisa ngewehke nggawe cara-cara. Rewis dipoleh komunikasi sing paling-paling kanggo kalaha program luwih, lan akeh barang sing apik, iso nggawe NPI kanggo kKA ambetisi lan tambahan sing apik. Awakdhéwé nglebokake komplit imperatve Program Ukunggawe Terminal Reward CIPITR Ngubah akeh komplikasi MB politenessoffpolite"), and when there is a change ("assertivepoliteness Nanging kabeh kelas sing karo pasang kelas program (karo akeh sampeyan) karo 5-10 tekau, CIPITR iso nggawe NM karo pektoral kanggo Keterarangkan karo 9 kere'}
{'en': 'DREAM : A Challenge Data Set and Models for Dialogue-Based Reading Comprehension', 'ar': 'DREAM: مجموعة بيانات التحدي ونماذج لفهم القراءة القائم على الحوار', 'es': 'DREAM: Un conjunto de datos de desafío y modelos para la comprensión lectora basada en el diálogo', 'pt': 'DREAM: Um conjunto de dados de desafio e modelos para compreensão de leitura baseada em diálogo', 'fr': 'DREAM\xa0: Un ensemble de données et des modèles de défis pour la compréhension de lecture basée sur le dialogue', 'ja': 'DREAM ：ダイアログベースの読解のためのチャレンジデータセットとモデル', 'zh': '梦想:基于对话的读解的数集和模形', 'ru': 'DREAM: набор данных и модели для понимания чтения на основе диалога', 'hi': 'DREAM: एक चुनौती डेटा सेट और संवाद-आधारित पढ़ने की समझ के लिए मॉडल', 'ga': 'Aisling: Dúshlán Tacar Sonraí agus Múnlaí don Léamhthuiscint Bunaithe ar Chomhphlé', 'el': 'Ένα σύνολο δεδομένων και μοντέλα πρόκλησης για κατανόηση ανάγνωσης βάσει διαλόγου', 'kk': 'DREAM: Диалог негіздеген оқу құрылғысының шақыру деректерін және үлгілері', 'ka': 'DREAM: მონაცემები და მოდელები დიალოგის დაბათი კითხვის კომპრენციაზე', 'hu': 'DREAM: Kihívási adatkészlet és modellek a párbeszéd alapú olvasási megértéshez', 'lt': 'MANIMAS: Iššūkių duomenų rinkinys ir dialogu pagrįsto skaitymo supratimo modeliai', 'ms': 'DREAM: Set Data tantangan dan Model untuk Pemahaman Pembacaan Berasas Dialog', 'mk': 'ДРЕМ: Состав на податоци за предизвики и модели за разбирање на читање базирано на дијалог', 'it': 'DREAM: un set di dati e modelli di sfida per la comprensione della lettura basata sul dialogo', 'ml': 'ഡയലോഗ് അടിസ്ഥാനമായി വായിക്കുന്നതിനുള്ള മോഡലുകള്\u200d', 'mt': 'IĦLAM: Sett ta’ Dejta ta’ Sfida u Mudelli għal Komprensjoni tal-qari bbażata fuq id-Djalogu', 'no': 'DREAM: Eit utfordringsdatasett og modeller for dialogbasert lesingskomprehensing', 'mn': 'ДАЙЛАМ: Диалог-based унших хэмжээний төлөвлөгөө болон загвар', 'pl': 'DREAM: Zestaw danych i modele wyzwań dla zrozumienia czytania opartego na dialogu', 'ro': 'DREAM: un set de date și modele de provocări pentru înțelegerea lecturii bazate pe dialog', 'sr': 'ДРЕМ: Набор и модели дана за четање на диалогу', 'sv': 'DREAM: En utmaning datauppsättning och modeller för dialogbaserad läsförståelse', 'ta': 'DREAM: உரையாடல் அடிப்படையான படித்தல் முடிப்புக்கான செயல்படுத்தல் தரவு அமைப்புகள் மற்றும் மாதிரிகள்', 'so': 'DREAM: A Challenge Data Set and Models for Dialog-Based Reading Composition', 'si': 'DREAM: ප්\u200dරශ්න දත්ත සැකසුම් සහ සංවාදය සඳහා ප්\u200dරශ්න සැකසුම් සඳහා සංවාදය සඳහා කියවන්න සංවාද', 'ur': 'ڈرائم: ایک چالونگ ڈاٹ سٹ اور موڈل ڈالیلوگ بنیاد پڑھنے کی کمپرینس کے لئے', 'uz': 'Name', 'vi': 'DREAM: A Challeng Data Set và mẫu cho chương trình đọc dựa trên thoại', 'bg': 'Мечта: набор от данни за предизвикателства и модели за разбиране на четене въз основа на диалог', 'hr': 'DREAM: Podatak izazova i modeli za kompresiju čitanja na dijalogu', 'da': 'DREAM: Et udfordringsdatasæt og modeller til dialogbaseret læseforståelse', 'nl': 'DREAM: Een dataset en modellen voor dialooggebaseerde leesinzichten', 'de': 'DREAM: Ein Challenge Data Set und Modelle für dialogbasiertes Leseverständnis', 'id': 'DREAM: A Challenge Data Set dan Models for Dialogue-Based Reading Comprehension', 'fa': 'DREAM: یک مجموعه داده\u200cهای چالش و مدل\u200cهای خواندن بر پایه\u200cی دیalog', 'ko': '꿈: 대화의 읽기와 이해를 바탕으로 하는 도전 데이터 집합과 모델', 'sw': 'DREAM: Mpango wa Taarifa za Challenge na Modeli kwa ajili ya Kusoma Msomaji Msingi wa Dialogu', 'sq': 'DREAM: A Challenge Data Set dhe Models for Dialogue-Based Reading Comprehension', 'af': 'Constellation name (optional)', 'tr': 'DREAM: Diýalogdan tabalany okamak üçin bir Challenge Maglumaty Setir we Modeller', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'bn': 'DREAM: ডায়ালগ-ভিত্তিক ভিত্তিক পাঠকরণের জন্য একটি চ্যালেঞ্জেন ডাটা সেট এবং মডেল', 'hy': 'Խնդիրների տվյալների համակարգ և մոդելներ', 'az': 'DREAM: Dialoog 칖st칲nd톛ki Oqurma 칖st칲nl칲y칲 칲칞칲n challenge Data Set v톛 Modell톛r', 'bs': 'DREAM: Podatak izazova i modeli za kompresiju čitanja na dijalogu', 'ca': 'DREAM: Un conjunt de dades de reptes i models per a una comprensió de lectura basada en diàleg', 'cs': 'DREAM: Výzva datová sada a modely pro porozumění dialogovému čtení', 'et': 'DREAM: väljakutse andmekogum ja dialoogipõhise lugemise mudelid', 'fi': 'DREAM: Haasteaineisto ja mallit dialogipohjaiseen lukemiseen', 'jv': 'DEREM: A Changenge data Set and model for Dialog-bazed Reading Compréncion', 'sk': 'DREAM: nabor podatkov o izzivih in modeli za razumevanje branja na podlagi dialoga', 'he': 'חלום: קבוצת נתונים של אתגרים ומדוגמנים להבינה קריאה מבוססת בדיאלוגים', 'ha': 'KCharselect unicode block name', 'bo': 'DREAM: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension'}
{'en': 'We present DREAM, the first dialogue-based multiple-choice reading comprehension data set. Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our data set contains 10,197 multiple-choice questions for 6,444 dialogues. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding. DREAM is likely to present significant challenges for existing reading comprehension systems : 84 % of answers are non-extractive, 85 % of questions require reasoning beyond a single sentence, and 34 % of questions also involve commonsense knowledge. We apply several popular neural reading comprehension models that primarily exploit surface information within the text and find them to, at best, just barely outperform a rule-based approach. We next investigate the effects of incorporating dialogue structure and different kinds of general world knowledge into both rule-based and (neural and non-neural) machine learning-based reading comprehension models. Experimental results on the DREAM data set show the effectiveness of dialogue structure and general world knowledge. DREAM is available at https://dataset.org/dream/.', 'pt': 'Apresentamos DREAM, o primeiro conjunto de dados de compreensão de leitura de múltipla escolha baseado em diálogo. Coletados de exames de inglês como língua estrangeira projetados por especialistas humanos para avaliar o nível de compreensão de alunos chineses de inglês, nosso conjunto de dados contém 10.197 perguntas de múltipla escolha para 6.444 diálogos. Em contraste com os conjuntos de dados de compreensão de leitura existentes, o DREAM é o primeiro a se concentrar no entendimento aprofundado do diálogo com várias partes. DREAM provavelmente apresentará desafios significativos para os sistemas de compreensão de leitura existentes: 84% das respostas não são extrativas, 85% das perguntas exigem raciocínio além de uma única frase e 34% das perguntas também envolvem conhecimento de senso comum. Aplicamos vários modelos populares de compreensão de leitura neural que exploram principalmente informações de superfície dentro do texto e os encontramos, na melhor das hipóteses, apenas superando uma abordagem baseada em regras. Em seguida, investigamos os efeitos da incorporação de estrutura de diálogo e diferentes tipos de conhecimento geral do mundo em modelos de compreensão de leitura baseados em regras e (neurais e não neurais) baseados em aprendizado de máquina. Os resultados experimentais no conjunto de dados DREAM mostram a eficácia da estrutura do diálogo e do conhecimento geral do mundo. DREAM está disponível em https://dataset.org/dream/.', 'ar': 'نقدم DREAM ، أول مجموعة بيانات لفهم القراءة متعددة الخيارات تعتمد على الحوار. تم جمعها من اختبارات اللغة الإنجليزية كلغة أجنبية التي صممها خبراء بشريون لتقييم مستوى فهم متعلمي اللغة الصينية للغة الإنجليزية ، وتحتوي مجموعة البيانات الخاصة بنا على 10197 سؤالًا متعدد الخيارات لـ 6444 حوارًا. على عكس مجموعات بيانات فهم القراءة الحالية ، فإن DREAM هو أول من يركز على فهم متعمق للحوار متعدد الأطراف. من المرجح أن يمثل DREAM تحديات كبيرة لأنظمة فهم القراءة الحالية: 84٪ من الإجابات غير استخلاصية ، و 85٪ من الأسئلة تتطلب تفكيرًا يتجاوز جملة واحدة ، و 34٪ من الأسئلة تتضمن أيضًا معرفة منطقية. نطبق العديد من نماذج فهم القراءة العصبية الشائعة التي تستغل بشكل أساسي المعلومات السطحية داخل النص وتجدها ، في أحسن الأحوال ، بالكاد تتفوق على النهج القائم على القواعد. نقوم بعد ذلك بالتحقيق في آثار دمج بنية الحوار وأنواع مختلفة من المعرفة العامة العامة في كل من نماذج فهم القراءة القائمة على التعلم الآلي والقائمة على القواعد (العصبية وغير العصبية). تظهر النتائج التجريبية على مجموعة بيانات DREAM فعالية بنية الحوار والمعرفة العامة بالعالم. DREAM متاح على https://dataset.org/dream/.', 'fr': "Nous présentons DREAM, le premier ensemble de données de compréhension de lecture à choix multiples basé sur le dialogue. Collectés à partir d'examens d'anglais langue étrangère conçus par des experts humains pour évaluer le niveau de compréhension des apprenants chinois de l'anglais, notre ensemble de données contient 10 197 questions à choix multiples pour 6 444 dialogues. Contrairement aux ensembles de données de compréhension de lecture existants, DREAM est le premier à se concentrer sur la compréhension approfondie du dialogue multipartite multi-tours. DREAM est susceptible de présenter des défis importants pour les systèmes de compréhension de la lecture existants\xa0: 84\xa0% des réponses ne sont pas extractives, 85\xa0% des questions nécessitent un raisonnement au-delà d'une seule phrase et 34\xa0% des questions impliquent également des connaissances de bon sens. Nous appliquons plusieurs modèles populaires de compréhension de la lecture neuronale qui exploitent principalement les informations de surface dans le texte et nous trouvons qu'ils surpassent, au mieux, à peine une approche basée sur des règles. Nous étudierons ensuite les effets de l'intégration de la structure du dialogue et de différents types de connaissances générales du monde dans des modèles de compréhension de la lecture basés sur des règles et (neuronaux et non neuronaux) basés sur l'apprentissage automatique. Les résultats expérimentaux sur l'ensemble de données DREAM montrent l'efficacité de la structure du dialogue et de la connaissance générale du monde. DREAM est disponible sur https://dataset.org/dream/.", 'es': 'Presentamos DREAM, el primer conjunto de datos de comprensión lectora de opción múltiple basado en diálogos. Recopilados de exámenes de inglés como lengua extranjera diseñados por expertos humanos para evaluar el nivel de comprensión de los estudiantes de chino que aprenden inglés, nuestro conjunto de datos contiene 10 197 preguntas de opción múltiple para 6 444 diálogos. A diferencia de los conjuntos de datos de comprensión lectora existentes, DREAM es el primero que se centra en la comprensión profunda del diálogo multipartito de múltiples turnos. Es probable que DREAM presente desafíos significativos para los sistemas de comprensión de lectura existentes: el 84% de las respuestas no son extractivas, el 85% de las preguntas requieren razonamiento más allá de una sola oración y el 34% de las preguntas también involucran conocimientos de sentido común. Aplicamos varios modelos populares de comprensión de lectura neuronal que explotan principalmente la información superficial dentro del texto y descubrimos que, en el mejor de los casos, apenas superan un enfoque basado en reglas. A continuación, investigamos los efectos de incorporar la estructura del diálogo y diferentes tipos de conocimiento general del mundo en modelos de comprensión lectora basados en reglas y basados en aprendizaje automático (neuronal y no neuronal). Los resultados experimentales del conjunto de datos DREAM muestran la eficacia de la estructura del diálogo y el conocimiento general del mundo. DREAM está disponible en https://dataset.org/dream/.', 'zh': '首建对语之多端,择读解数集DREAM。 吾数集从人伦之设英语以为外语考试收,以质中文之士英语解水平,吾数集包6,444一对之10,197多选择题。 比之读解数集,DREAM首注于深入多回合多方对解之数集。 DREAM或大挑战于见读:84%是非提取性,85%过句理,34%及常识。 宜以流行数种神经读解模形,要在文本中阳信,但强优其量充其量法耳。 接下,我们将对话结构和不同的世界知识入基于规矩和(神经和非神经)机器学习的读解模样。 DREAM数集实验结果显示对话结构,与世界知识之有效性。 DREAM在 https://dataset.org/dream/。', 'ru': 'Мы представляем набор данных DREAM, первый набор данных для понимания чтения, основанный на диалоге с множественным выбором. Наш набор данных, собранный из экзаменов на знание английского языка как иностранного, разработанных экспертами-человеками для оценки уровня понимания китайскими учащимися английского языка, содержит 10 197 вопросов с несколькими вариантами ответа для 6 444 диалогов. В отличие от существующих наборов данных понимания чтения, DREAM в первую очередь фокусируется на углубленном понимании многоповоротного многопартийного диалога. СОН, вероятно, будет представлять значительные проблемы для существующих систем понимания чтения: 84% ответов не извлекаются, 85% вопросов требуют рассуждений, помимо одного предложения, и 34% вопросов также включают в себя знания здравого смысла. Мы применяем несколько популярных моделей понимания нейронного чтения, которые в основном используют поверхностную информацию в тексте и находят их, в лучшем случае, просто едва ли превосходящими основанный на правилах подход. Далее мы исследуем последствия включения структуры диалога и различных видов общих мировых знаний в модели понимания чтения как на основе правил, так и (нейронного и ненейронного) машинного обучения. Экспериментальные результаты по набору данных МЕЧТЫ показывают эффективность структуры диалога и общих мировых знаний. МЕЧТА доступна по адресу https://dataset.org/dream/.', 'hi': 'हम DREAM, पहला संवाद-आधारित बहु-विकल्प पढ़ने की समझ डेटा सेट प्रस्तुत करते हैं। अंग्रेजी के चीनी शिक्षार्थियों की समझ के स्तर का मूल्यांकन करने के लिए मानव विशेषज्ञों द्वारा डिज़ाइन की गई विदेशी भाषा परीक्षाओं के रूप में अंग्रेजी से एकत्र, हमारे डेटा सेट में 6,444 संवादों के लिए 10,197 बहुविकल्पीय प्रश्न शामिल हैं। मौजूदा रीडिंग कॉम्प्रिहेंशन डेटा सेट के विपरीत, DREAM इन-डेप्थ मल्टी-टर्न मल्टी-पार्टी डायलॉग समझ पर ध्यान केंद्रित करने वाला पहला व्यक्ति है। DREAM मौजूदा पढ़ने की समझ प्रणालियों के लिए महत्वपूर्ण चुनौतियों को पेश करने की संभावना है: 84% उत्तर गैर-निष्कर्षण हैं, 85% प्रश्नों को एक वाक्य से परे तर्क की आवश्यकता होती है, और 34% प्रश्नों में सामान्य ज्ञान भी शामिल होता है। हम कई लोकप्रिय तंत्रिका पढ़ने की समझ मॉडल लागू करते हैं जो मुख्य रूप से पाठ के भीतर सतह की जानकारी का शोषण करते हैं और उन्हें पाते हैं, सबसे अच्छा, बस मुश्किल से एक नियम-आधारित दृष्टिकोण से आगे निकलते हैं। हम अगले दोनों नियम आधारित और (तंत्रिका और गैर तंत्रिका) मशीन सीखने आधारित पढ़ने की समझ मॉडल में संवाद संरचना और सामान्य विश्व ज्ञान के विभिन्न प्रकार को शामिल करने के प्रभावों की जांच करते हैं। DREAM डेटा सेट पर प्रयोगात्मक परिणाम संवाद संरचना और सामान्य विश्व ज्ञान की प्रभावशीलता दिखाते हैं। DREAM https://dataset.org/dream/ पर उपलब्ध है।', 'ja': '私たちは、最初の対話ベースの多肢選択読解データセットであるDREAMを提示します。 英語の中国語学習者の理解度を評価するために、人間の専門家によって設計された外国語試験として英語から収集されたデータセットには、6,444の対話のための10,197の複数選択問題が含まれています。 既存の読解データセットとは対照的に、DREAMは深いマルチターンマルチパーティーダイアログの理解に焦点を当てた最初のものです。 夢は、既存の読解システムに重大な課題を提示する可能性が高い。答えの84%は非抽象的であり、85%の質問は単一の文章を超えた推論を必要とし、34%の質問は常識的な知識も含んでいる。 私たちは、主にテキスト内の表面情報を利用して、せいぜいルールベースのアプローチをほとんど上回らないようにする、いくつかの人気のあるニューラルリーディング理解モデルを適用します。 次に、ルールベースと（神経および非神経）機械学習ベースの読解モデルの両方に対話構造とさまざまな種類の一般的な世界知識を組み込むことの効果を調査します。 夢のデータセットの実験結果は、対話構造と一般的な世界知識の有効性を示している。 DREAMはhttps://dataset.org/dream/で入手できます。', 'ga': 'Cuirimid DREAM i láthair, an chéad tacar sonraí léamhthuisceana ilroghnacha bunaithe ar chomhphlé. Bailithe ó scrúduithe Béarla mar Theanga Iasachta atá deartha ag saineolaithe daonna chun leibhéal tuisceana na bhfoghlaimeoirí Síneacha ar an mBéarla a mheas, tá 10,197 ceist ilroghnacha le haghaidh 6,444 agallamh inár dtacar sonraí. I gcodarsnacht leis na tacair sonraí léamhthuisceana atá ann cheana féin, is é DREAM an chéad duine a dhírigh ar thuiscint dhomhain ar idirphlé ilpháirtí ilchodach. Is dócha go gcruthóidh DREAM dúshláin shuntasacha do na córais léamhthuisceana atá ann faoi láthair: tá 84% de na freagraí neamh-eastóscach, éilíonn 85% de na ceisteanna réasúnaíocht thar aon abairt amháin, agus baineann 34% de na ceisteanna le heolas ciallmhar. Cuirimid i bhfeidhm go leor samhlacha néarthuisceana a bhfuil an-tóir orthu a bhaineann leas go príomha as faisnéis dromchla laistigh den téacs agus a aimsíonn gur ar éigean a éiríonn leo, ar an mbealach is fearr, ná cur chuige bunaithe ar rialacha. An chéad uair eile déanaimid imscrúdú ar na héifeachtaí a bhaineann le struchtúr comhphlé agus cineálacha éagsúla eolais ghinearálta an domhain a ionchorprú i múnlaí léamhthuisceana meaisín-bhunaithe bunaithe ar rialacha agus (néaracha agus neamhnéaracha). Léiríonn torthaí turgnamhacha ar thacar sonraí DREAM éifeachtacht an struchtúir idirphlé agus eolas ginearálta an domhain. Tá DREAM ar fáil ag https://dataset.org/dream/.', 'hu': 'Bemutatjuk a DREAM-et, az első párbeszéd alapú többválasztású olvasásértési adatkészletet. Az angol mint idegen nyelv vizsgákból gyűjtöttük össze, amelyeket emberi szakértők terveztek, hogy értékeljék a kínai angol nyelvtanulók megértési szintjét, adatkészletünk 10 197 többválasztásos kérdést tartalmaz 6 444 párbeszédhez. A meglévő olvasásértési adatkészletekkel ellentétben a DREAM az első, aki a mélyreható többfordulós párbeszéd megértésére összpontosít. A DREAM valószínűleg jelentős kihívásokat jelent a meglévő olvasásértő rendszerek számára: a válaszok 84%-a nem nyersanyag, a kérdések 85%-a egyetlen mondatot meghaladó indokolást igényel, és a kérdések 34%-a közértelmes ismereteket is magában foglal. Számos olyan népszerű neurális olvasásértő modellt alkalmazunk, amelyek elsősorban a szövegben lévő felületi információkat használják ki, és úgy találják, hogy a legjobb esetben alig teljesítenek túl egy szabályalapú megközelítést. Ezt követően vizsgáljuk a párbeszédstruktúra és a különböző típusú általános világtudás beépítésének hatásait szabályalapú és (neurális és nem neurális) gépi tanulás alapú olvasásértési modellekbe. A DREAM adatkészlet kísérleti eredményei mutatják a párbeszédstruktúra hatékonyságát és az általános világtudás hatékonyságát. DREAM elérhető a következő címen: https://dataset.org/dream/.', 'el': 'Παρουσιάζουμε το πρώτο σύνολο δεδομένων κατανόησης ανάγνωσης πολλαπλών επιλογών βασισμένο σε διάλογο. Συλλεγμένα από εξετάσεις Αγγλικής ως Ξένης Γλώσσας που έχουν σχεδιαστεί από ανθρώπινους ειδικούς για να αξιολογήσουν το επίπεδο κατανόησης των Κινέζων που μαθαίνουν αγγλικά, το σύνολο δεδομένων μας περιέχει 10,197 ερωτήσεις πολλαπλής επιλογής για διαλόγους 6,444. Σε αντίθεση με τα υπάρχοντα σύνολα δεδομένων κατανόησης ανάγνωσης, το είναι το πρώτο που επικεντρώνεται σε βάθος στην κατανόηση διαλόγου πολλών μερών. Το DREAM είναι πιθανό να παρουσιάσει σημαντικές προκλήσεις για τα υπάρχοντα συστήματα κατανόησης ανάγνωσης: 84% των απαντήσεων είναι μη εξαγωγικές, 85% των ερωτήσεων απαιτούν συλλογισμό πέρα από μία πρόταση και 34% των ερωτήσεων περιλαμβάνουν επίσης γνώση κοινής λογικής. Εφαρμόζουμε διάφορα δημοφιλή μοντέλα κατανόησης νευρωνικής ανάγνωσης που εκμεταλλεύονται κυρίως τις επιφανειακές πληροφορίες μέσα στο κείμενο και τα βρίσκουν, στην καλύτερη περίπτωση, μόλις που ξεπερνούν μια προσέγγιση βασισμένη σε κανόνες. Στη συνέχεια διερευνούμε τις επιπτώσεις της ενσωμάτωσης δομής διαλόγου και διαφορετικών ειδών γενικής παγκόσμιας γνώσης τόσο σε μοντέλα κατανόησης ανάγνωσης βασισμένα σε κανόνες όσο και (νευρωνικά και μη νευρωνικά) βασισμένα στη μηχανική μάθηση. Τα πειραματικά αποτελέσματα στο σύνολο δεδομένων δείχνουν την αποτελεσματικότητα της δομής διαλόγου και της γενικής παγκόσμιας γνώσης. Το DREAM διατίθεται στη διεύθυνση https://dataset.org/dream/.', 'it': "Vi presentiamo DREAM, il primo set di dati di comprensione della lettura a scelta multipla basato sul dialogo. Raccolto da esami di inglese come lingua straniera progettati da esperti umani per valutare il livello di comprensione degli studenti cinesi di inglese, il nostro set di dati contiene 10.197 domande a risposta multipla per 6.444 dialoghi. A differenza dei set di dati esistenti per la comprensione della lettura, DREAM è il primo a concentrarsi sulla comprensione approfondita del dialogo multi-turno. DREAM presenta probabilmente sfide significative per i sistemi di comprensione della lettura esistenti: l'84% delle risposte non sono estrattive, l'85% delle domande richiede ragionamenti oltre una singola frase e il 34% delle domande coinvolge anche conoscenze di buon senso. Applichiamo diversi popolari modelli di comprensione della lettura neurale che sfruttano principalmente le informazioni superficiali all'interno del testo e li troviamo, nel migliore dei casi, a malapena superiori a un approccio basato su regole. Successivamente esaminiamo gli effetti di incorporare la struttura del dialogo e diversi tipi di conoscenza generale del mondo in modelli di comprensione della lettura basati su regole e (neurali e non neurali) basati sull'apprendimento automatico. I risultati sperimentali sul set di dati DREAM mostrano l'efficacia della struttura del dialogo e della conoscenza generale del mondo. DREAM è disponibile all'indirizzo https://dataset.org/dream/.", 'lt': 'Mes pristatome SAMAS, pirmąjį dialogu pagrįstą daugelio pasirinkimų skaitymo duomenų rinkinį. Iš anglų surinktų ekspertų parengtų užsienio kalbos egzaminų, skirtų įvertinti Kinijos anglų kalbos mokinių supratimo lygį, mūsų duomenų rinkinyje yra 10 197 klausimų, susijusių su 6 444 dialogais. Priešingai nei esami skaitymo supratimo duomenų rinkiniai, DREAM pirmasis sutelkia dėmesį į išsamų daugiapakopį daugiapakopį dialogą. Gali kilti didelių sunkumų, susijusių su esamomis skaitymo supratimo sistemomis: 84 proc. atsakymų yra neišsamūs, 85 proc. klausimų reikalauja daugiau nei vieną sakinį pagrįsti, o 34 proc. klausimų taip pat apima bendrą žinią. Mes taikome keletą populiarių neurologinio skaitymo supratimo modelių, kurie pirmiausia naudoja tekste esančią paviršiaus informaciją ir rasti jas, kad geriausia, tik vos viršytų taisyklėmis pagrįstą metodą. Toliau tiriame dialogo struktūros ir įvairių pasaulio žinių įtraukimo į taisyklėmis grindžiamus ir (nervinius ir ne nervinius) skaitymo modelius poveikį. DREAM duomenų rinkinio eksperimentiniai rezultatai rodo dialogo struktūros ir bendrųjų pasaulinių žinių veiksmingumą. DREAM is available at  https://dataset.org/dream/.', 'kk': 'Біз DREAM дегенді бірінші диалог негізінде бірнеше таңдау бағдарламасын оқу. Ағылшын тілінен адамдар эксперттерінің ағылшын тілдерінің түсініктерінің деңгейін оқу үшін құрылған тыс тілдерді тексеру ретінде біріктірілген. Деректер жиынында 6 444 диалогтар үшін 10 197 көп таңдау сұрақта Мынау оқу деректерді түсініктеріне қарсы, DREAM - көп партиялық диалогтың түсініктерін бірінші түсініктеріне қарсы. DREAM бар оқу жүйелерінде маңызды мәселелерді көрсету мүмкін: 84% жауаптардың түсініктемесі емес, 85% сұрақтардың бір сұрақтардан артық мәселелерді талап етеді, 34% сұрақтардың көпшілікті мәлі Біз бірнеше белгілі невралды оқу үлгілерін қолдануға болады. Бұл мәтінің ішінде негізгі мәліметті жұмыс істеп, оларды жақсы жағдайда ережелердің негізінде тәсілдігінен тыс Біз келесі диалог құрылымын және әлемдегі әлемдегі әлемдегі білім түрлерінің негізделген, невралды және невралды емес механизм оқу үлгілеріне негізделген әрекеттерді зерттейміз. DREAM деректерінің эксперименталдық нәтижелері диалог құрылымының және әлемдік білімдерінің ең әсерілігін көрсетеді. DREAM бар https://dataset.org/dream/.', 'ms': 'Kami perkenalkan DREAM, set data pemahaman pembacaan berbagai pilihan berdasarkan dialog pertama. Dikumpulkan dari bahasa Inggeris sebagai ujian bahasa asing yang direka oleh ahli manusia untuk menilai tahap pemahaman pelajar bahasa Inggeris Cina, set data kita mengandungi 10,197 soalan pilihan berbilang untuk 6,444 dialog. Sebaliknya dengan set data pemahaman pembacaan yang ada, DREAM adalah yang pertama untuk fokus pada pemahaman dialog berbilang-putaran dalam-dalam. DREAM mungkin akan menghasilkan cabaran yang signifikan untuk sistem pemahaman pembacaan yang ada: 84% jawapan tidak ekstraktif, 85% soalan memerlukan alasan melampaui satu kalimat, dan 34% soalan juga melibatkan pengetahuan umum. Kami menerapkan beberapa model pemahaman pembacaan saraf populer yang terutama mengeksploitasi maklumat permukaan dalam teks dan mencari mereka untuk, pada yang terbaik, hampir tidak melampaui pendekatan berdasarkan peraturan. Seterusnya, kita menyelidiki kesan dari memasukkan struktur dialog dan jenis-jenis pengetahuan umum dunia ke dalam model pemahaman pembacaan berbasis peraturan dan mesin (saraf dan bukan saraf). Keputusan percubaan pada set data DREAM menunjukkan keefektivitas struktur dialog dan pengetahuan umum dunia. DREAM is available at  https://dataset.org/dream/.', 'mk': 'Презентираме DREAM, првиот дијалог-базиран многутрален избор за читање на податоци за разбирање. Собирани од англиски како испитувања на странски јазик дизајнирани од човечки експерти за проценка на нивото на разбирање на кинеските ученици на англиски јазик, нашиот податок содржи 10.197 прашања со повеќе избори за 6.444 дијалози. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding.  ДРЕАМ најверојатно ќе претстави значителни предизвици за постоечките системи за разбирање на читањето: 84 отсто од одговорите не се екстрактивни, 85 отсто од прашањата бараат размислување надвор од една реченица, а 34 отсто од прашањата исто така вклучуваат заедничко знаење. Ние аплицираме неколку популарни модели за разбирање на нервното читање кои примарно ги искористуваат површините информации во текстот и ги најдовме за, во најдобар случај, едвај да го надминат пристапот базиран на правила. Следно ги истражуваме ефектите од вклучувањето на структурата на дијалогот и различни видови на генерално светско знаење во моделите за разбирање на читање базирани на правила и (неурални и неурални) машини. Експерименталните резултати на наборот на податоци на ДРЕАМ ја покажуваат ефикасноста на структурата на дијалогот и општите светски знаења. DREAM е достапна на https://dataset.org/dream/.', 'ml': 'ആദ്യത്തെ ഡയലോഗ് അടിസ്ഥാനമായി പല തെരഞ്ഞെടുപ്പുകള്\u200d വായിക്കുന്ന ഡാറ്റാ വായിക്കുന്നതിനെ ഞങ്ങള്\u200d ഡ്ര ഇംഗ്ലീഷില്\u200d നിന്നും ഒരു വിദേശ ഭാഷ പരീക്ഷണ പരീക്ഷണത്തില്\u200d നിന്നും ഒരുമിച്ചുകൂട്ടിയിരിക്കുന്നു. ചൈനീസ് പഠിക്കുന്നവരുടെ അടിസ്ഥാനത്തെ പരിശോധനം  നിലവിലുള്ള വായിക്കുന്ന വിവരങ്ങളുടെ ഡാറ്റാ സജ്ജീകരണങ്ങള്\u200dക്ക് വിരോധമാണെങ്കില്\u200d, ഡ്രെയിഎമാണ് ആദ്യം- ആഴത്തില്\u200d അളവ നിലവിലുള്ള വായിക്കുന്ന സിസ്റ്റത്തിനുള്ള പ്രധാനപ്പെട്ട വിലാസങ്ങള്\u200d ഡ്രെയാമിന്റെ കൂടിയിരിക്കുന്നു പ്രധാനപ്പെട്ട ന്യൂറല്\u200d വായിക്കുന്ന മോഡലുകള്\u200d ഞങ്ങള്\u200d പ്രയോഗിക്കുന്നു. പ്രധാനപ്പെട്ട ട ടെക്സ്റ്റില്\u200d വിവരങ്ങള്\u200d ഉപയോഗിക്കുന പിന്നീട് നമ്മള്\u200d സംസാരിക്കുന്ന ഡയലോഗ് ഘടനയില്\u200d ചേര്\u200dക്കുന്നതിന്റെ പ്രഭാവങ്ങളും വ്യത്യസ്ത വിവിധ വിവരങ്ങളുടെ വിവരങ്ങളും നിയമപരമായ വിവരങ് DREAM ഡേറ്റാ സജ്ജീകരണത്തിന്റെ പരീക്ഷണ ഫലങ്ങള്\u200d സംസാരിക്കുന്നത് ഡയലോഗ് ഘടനയുടെയും പൊതുവായ ലോകത്തിന്റെ  DREAM ലഭ്യമല്ല https://dataset.org/dream/.', 'mn': 'Бид анхны диалог дээр олон сонголт унших өгөгдлийг ойлгохын тулд DREAM-г харуулж байна. Хятадын мэргэжилтнүүд Англи хэлний англи хэлний оюутнуудын тухай ойлгохын тулд англи хэлний гадаад хэлний шалгалтын хувьд цуглуулагдсан бөгөөд бидний өгөгдлийн багц нь 6 444 диалогын тухай 10 197 олон сонголтын асуултууд Мөн унших өгөгдлийн сангийн ойлголтын эсрэг DREAM бол олон партийн диалогын ойлголтын гүн гүнзгий хэлбэрээр анхаарлаа анхаарлаа анхаарлаа хандуулах юм. DREAM нь суурилсан унших ойлголтын системийн чухал сорилтуудыг тайлбарлах магадгүй: хариултын 84% нь нэмэгдэхгүй, 85% асуултуудын 85% нь ганц өгүүлбэрээс илүү шалтгаан шаардлагатай, 34% асуултуудын мэдлэг бас ихэвчлэн нэмэгддэг. Бид хэдэн алдартай мэдрэлийн мэдээллийг текст дотор ашиглаж, хамгийн сайн нь тэднийг зөвхөн дүрэм суурилсан арга замыг бага зэрэг ашиглаж чадахгүй байдаг. Дараа нь бид диалог бүтэц болон дэлхийн ерөнхий төрлийн мэдлэг хоёуланг дүрэм дээр, мэдрэлийн болон мэдрэлийн биш мэдрэлийн суралцах машины суралцах загваруудын тухай нэгтгэх нөлөөг судалж байна. DREAM өгөгдлийн туршилтын үр дүн нь диалог бүтээгдэхүүний үр дүнтэй байдлыг харуулдаг. ДОРОМ нь https://dataset.org/dream/.', 'ka': 'ჩვენ აჩვენებთ DREAM, პირველი დიალოგის განსაზღვრებული მრავალური მონიშვნების შესახებ. ჩვენი მონაცემების სექსტი ახალგაზრდება 6 444 დიალოგებისთვის 10 197 რამდენიმე გამოყენებული კითხვებისთვის, რომლებიც ადამიანის ექსპერტების გამოყენებული ინგლისოდან კოლექტირებულია. DREAM არის პირველი, რომელიც მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ დიალოგის გაგრძნობას. DREAM შესაძლებელია გაჩვენება მნიშვნელოვანი წარმოდგენების სისტემისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვის წარმოდგენება: 84% წარმოდგენების არ არის ექსტრაქტიური, 85% კ ჩვენ ვიყენებთ რამდენიმე პოლიპური ნეიროლური წაკითხვის მოდელები, რომლებიც პირდაპირად ტექსტში გამოიყენებენ საფეხური ინფორმაციის ინფორმაციას და დაიძებენ, რომ მათ უფ ჩვენ შემდეგ განსხვავებთ დიალოგის სტრუქტურის და განსხვავებული სამყარო ცნობილების ეფექტურების შესახებ მსოფლიოს მსოფლიოში და (ნეიროლური და უნეიროლური) მაქინის სწავლების DREAM მონაცემების შესახებ ექსპერიმენტიური შედეგები დიალოგის სტრუქტურის ეფექტიკურობას და საერთო მსოფლიო ცოცხლების ექს DREAM შესაძლებელია https://dataset.org/dream/.', 'pl': 'Prezentujemy DREAM, pierwszy oparty na dialogu zestaw danych dotyczących rozumienia wielokrotnego wyboru. Zestaw danych zebrany z egzaminów z języka angielskiego jako języka obcego zaprojektowanych przez ekspertów ludzkich w celu oceny poziomu zrozumienia chińskiego uczących się języka angielskiego, zawiera 10,197 pytania wielokrotnego wyboru dla dialogów 6,444. W przeciwieństwie do istniejących zbiorów danych dotyczących rozumienia czytania, DREAM jest pierwszym, który skupia się na dogłębnym zrozumieniu dialogu wielu stron. DREAM prawdopodobnie stanowi istotne wyzwania dla istniejących systemów rozumienia czytania: 84% odpowiedzi nie są ekstrakcyjne, 85% pytań wymaga rozumowania poza jednym zdaniem, a 34% pytań obejmuje również zdrową wiedzę. Stosujemy kilka popularnych neuronowych modeli rozumienia odczytu, które przede wszystkim wykorzystują informacje powierzchniowe w tekście i uważają, że w najlepszym wypadku ledwo przewyższają podejście oparte na regułach. Następnie badamy efekty włączenia struktury dialogu i różnego rodzaju ogólnej wiedzy świata do modeli zrozumienia czytania opartych na regułach i (neuronowych i nieneuronowych) opartych na uczeniu maszynowym. Wyniki eksperymentalne na zbiorze danych DREAM pokazują skuteczność struktury dialogu i ogólnej wiedzy świata. DREAM jest dostępny na stronie internetowej https://dataset.org/dream/.', 'ro': 'Vă prezentăm DREAM, primul set de date de înțelegere a citirii multiple bazat pe dialog. Colectat din examenele de limba engleză ca limbă străină concepute de experți umani pentru a evalua nivelul de înțelegere al cursanților chinezi de limba engleză, setul nostru de date conține 10.197 întrebări cu răspuns multiplu pentru 6.444 dialoguri. Spre deosebire de seturile de date existente de înțelegere a citirii, DREAM este primul care se concentrează pe înțelegerea profundă a dialogului multi-partid. DREAM este probabil să prezinte provocări semnificative pentru sistemele existente de înțelegere a lecturii: 84% dintre răspunsuri nu sunt extractive, 85% dintre întrebări necesită raționament dincolo de o singură propoziție, iar 34% dintre întrebări implică, de asemenea, cunoștințe de bun sens. Aplicăm mai multe modele populare de înțelegere a citirii neurale care exploatează în primul rând informațiile de suprafață din text și le găsim, în cel mai bun caz, doar cu greu depășesc o abordare bazată pe reguli. În continuare, investigăm efectele încorporării structurii dialogului și a diferitelor tipuri de cunoaștere generală a lumii în modele de înțelegere a lecturii bazate pe reguli și (neurale și non-neurale) bazate pe învățare automată. Rezultatele experimentale ale setului de date DREAM arată eficiența structurii dialogului și a cunoștințelor generale ale lumii. DREAM este disponibil la https://dataset.org/dream/.', 'no': 'Vi presenterer DREAM, den første dialogbaserte fleire vala som lesar forståking av datasettet. Samla frå engelsk som eit eksterne språk-eksaminasjon designert av menneske ekspertar for å evaluera forståkingsnivået til kinesiske lærarar av engelsk. Datasettet inneheld 10 197 fleire val-spørsmål for 6 444 dialogar. I contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi turn multi party dialog understanding. DREAM vil sannsynlegvis gjere signifikante utfordringar for eksisterande lesingsforstålsystemer: 84 % av svar er ikkje-ekstraktiv, 85 % av spørsmål krev grunnlag enn eit enkelt setning, og 34 % av spørsmål involverer også vanleg kunnskap. Vi bruker fleire populære neurallesingsforståkingsmodular som brukar hovudsakelig overflatesinformasjon i teksten og finn dei til det beste, bare bare ganske ut ein regelbasert tilnærming. Vi så undersøker effekten av inkludering av dialogstrukturen og ulike typar generelle verdenskunnskap i både regelbaserte og (neurale og ikkje-neurale) maskinelæringsbaserte lesingsforståkingsmodular. Eksperimentale resultat på DREAM-datasettet viser effektiviteten av dialogstrukturen og viste verdenskjenning. DREAM er tilgjengeleg på https://dataset.org/dream/.', 'sr': 'Predstavljamo DREAM, prvi sastav podataka o razumijevanju više izbora na dijalogu. Skupljeno iz Engleskog kao ispitivanje vanjskih jezika koje su napravljene ljudskim ekspertima kako bi procenili razinu razumevanja kineskih učenika engleskog jezika, naš sastav podataka sadrži 10 197 višeizbornih pitanja za 6 444 dijaloga. U suprotnost postojećim setima podataka o razumijevanju čitanja, DREAM je prvi koji se fokusira na razumijevanje multistrantnih dijaloga u dubini. DREAM će vjerojatno predstaviti značajne izazove za postojeće sisteme razumijevanja čitanja: 84% odgovora su ne-ekstraktivni, 85% pitanja zahteva razumnost izvan jednog rečenika, a 34% pitanja uključuju i znanje zajedničkog smisla. Primjenjujemo nekoliko popularnih modela razumevanja neuralnih čitanja koji primarno iskorištavaju površinske informacije unutar teksta i pronađu ih da, u najboljem slučaju, jedva iznosi pravilni pristup. Sledeće istražujemo učinke uključenja strukture dijaloga i različitih vrsta svetskog znanja u modele razumijevanja na osnovu pravila i (neuralne i ne-neuralne) mašine na osnovu učenja. Eksperimentalni rezultati na setu podataka DREAM pokazuju učinkovitost strukture dijaloga i svetskog znanja. DREAM je dostupan na https://dataset.org/dream/.', 'si': 'අපි DREAM වෙනුවෙන්, පලවෙනි සංවාදය අධාරිත වෙනුවෙන් ගොනු තොරතුරු කියවන්න. ඉංග්\u200dරීසියෙන් ඉංග්\u200dරීසියෙන් ප්\u200dරදේශ භාෂාව පරීක්ෂණයක් විදියට මිනිස්සු විශ්වාසිකයෙන් සැකසුම් කරලා ඉංග්\u200dරීසියාගේ  ප්\u200dරතිදේශයේ කියවන්නේ දත්ත සෙට්ටුවට විරුද්ධ වෙනුවෙන්, DREAM තමයි මුලින්ම ගොඩක් ගොඩක් පාර්ටි සංවාදය තේරුම් DREAM ප්\u200dරශ්නයක් විතරයි තියෙන්නේ කියවන්න ප්\u200dරශ්නයක් සඳහා වැදගත් අභ්\u200dයානයක් තියෙන්නේ: ප්\u200dරශ්නයක් 84% නොප්\u200dරශ්නයක්, ප්\u200dරශ්නයක අපි ප්\u200dරමාණයෙන් ප්\u200dරශ්ණ න්\u200dයුරෝල් කියවන්නේ මොඩේල්ස් වලින් ප්\u200dරශ්ණ තොරතුරු ප්\u200dරශ්ණය කරනවා ඒ වගේම පිළිබඳ තොරතු අපි ඊළඟ පරීක්ෂණය කරන්නේ සංවාද සංවාද සංවාදය සහ වෙනස් වර්ගයක් ලෝකය දන්නේ නීති අධාරණය සහ (න්\u200dයූරාල් නොන්යූරාල් සහ) මැ DREAM දත්ත සූදානයේ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ සංවාද සංවාද ස DREAM අවස්ථාවයි. https://dataset.org/dream/.', 'mt': 'Aħna nippreżentaw DREAM, l-ewwel sett ta’ dejta ta’ komprensjoni tal-qari b’għażliet multipli bbażat fuq id-djalogu. Miġbura mill-Ingliż bħala eżamijiet tal-lingwa barranija mfassla minn esperti umani biex jevalwaw il-livell ta’ fehim ta’ studenti Ċiniżi tal-Ingliż, is-sett ta’ dejta tagħna fih 10,197 mistoqsija b’għa żla multipla għal 6,444 djalogu. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding.  L-DREAM x’aktarx jippreżenta sfidi sinifikanti għas-sistemi eżistenti ta’ fehim tal-qari: 84% tat-tweġibiet mhumiex estrattivi, 85% tal-mistoqsijiet jeħtieġu raġunament lil hinn minn sentenza waħda, u 34% tal-mistoqsijiet jinvolvu wkoll għarfien komuni. We apply several popular neural reading comprehension models that primarily exploit surface information within the text and find them to, at best, just barely outperform a rule-based approach.  Imbagħad ninvestigaw l-effetti tal-inkorporazzjoni tal-istruttura tad-djalogu u tipi differenti ta’ għarfien ġenerali fid-dinja kemm fil-mudelli ta’ komprensjoni tal-qari bbażati fuq ir-regoli kif ukoll (newrali u mhux newrali). Ir-riżultati esperimentali dwar is-sett tad-dejta DREAM juru l-effettività tal-istruttura tad-djalogu u l-għarfien ġenerali tad-dinja. IĦLAM huwa disponibbli fuq https://dataset.org/dream/.', 'sv': 'Vi presenterar DREAM, den första dialogbaserade flervalsdata för läsförståelse. Vår datauppsättning innehåller 10 197 flervalsfrågor för 6 444 dialoger, insamlad från engelskans som främmande språk som utformats av mänskliga experter för att utvärdera förståelsenivån hos kinesiska elever i engelska. I motsats till befintliga läsförståelsedatauppsättningar är DREAM först med att fokusera på djupgående multi-turn dialog förståelse för flera parter. DREAM kommer sannolikt att innebära betydande utmaningar för befintliga läsförståelsesystem: 84% av svaren är icke-extraherande, 85% av frågorna kräver resonemang utöver en enda mening, och 34% av frågorna innefattar också allmännyttig kunskap. Vi tillämpar flera populära neurala läsförståelse modeller som i första hand utnyttjar ytinformation i texten och finner dem i bästa fall knappt överträffa ett regelbaserat tillvägagångssätt. Därefter undersöker vi effekterna av att integrera dialogstruktur och olika typer av allmän världskunskap i både regelbaserade och (neurala och icke-neurala) maskininlärningsbaserade läsförståelsemodeller. Experimentella resultat på DREAM-datauppsättningen visar hur effektiv dialogstrukturen och den allmänna världskunskapen är. DREAM finns på https://dataset.org/dream/.', 'so': "Waxaynu soo jeednaa DREAM, kooxda qoraalka ee ugu horeeyay doorasho kala duduwan oo aan akhrinno qoraalka kooxa. Baaritaanka afka Ingiriiska oo ah baaritaanka qalaad ee dadku uu u qoray inuu qiimeeyo heerka hoose ee barbarashada Shiino ee ingiriisiga, kooxda macluumaadkayagu waxay ku jirtaa 10,197 su'aalo doorasho badan oo kala duduwan oo ay ku qoran labaad 6,444. Si ka duwan qoraalka qoraalka hoose-dhigista, DREAM waa kan ugu horreeya in aad ku kalsoonaato waxgarashada dialogue-dialog badan oo aad u leedahay. Waxaa suurtowda in DREAM uu soo jeedo dhibaatooyin muhiim ah oo ay jiraan nidaamka hoose-dhigista akhriska: 84% jawaabayaashu waa mid aan la saarin, 85% oo su'aaluhuna waxay u baahan yihiin sabab ka badan hal kaliya, 34% oo su'aaluna waxay ka mid yihiin aqoonta shirkadda. Waxaan codsanaynaa tusaalooyin akhriska kooxaha ah oo aad ugu horeysa u baahan karto macluumaadka surfa ee buuxda iyo si ugu yaraan ugu baahan qaab gaar ah. Waxaynu soo socdaa baaraynaa saamaynta ku saabsan qoraalka sameynta iyo aqoonta kala duduwan ee caalamiga ah oo ku qoran qoraalka iyo muusikada waxbarashada aasaasiga ah (neurada iyo neurada). Imtixaanka ku saabsan danbiyada DREAM wuxuu tusaa effektada dhismaha dialogka iyo aqoonta caalamiga ah. DREAM waxaa laga helaa https://dataset.org/dream/.", 'ta': 'நாம் DREAM, முதல் உரையாடல் அடிப்படையிலான பல்வேறு தேர்வு படிக்கும் தொகுதி தகவல் அமைப்பு ஆங்கிலத்திலிருந்து இங்கிலத்திலிருந்து சேகரிக்கப்பட்ட மொழி பரிசோதனைகளாக திரட்டப்பட்டுள்ளது, ஆங்கிலத்தின் மொத்தமான மாணவர்களை மதிப்பிடுவதற்கு, எங் இருக்கும் படிக்கும் தொகுதி தகவல் அமைப்புகளுக்கு மாறுபடி DREAM ஆழம் பல- முறை பல- party உரையாடல் புரிந்து கொள்ள முதலில் உள்ளது. DREAM is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve commonsense knowledge.  நாம் பல பிரபலமான புதிய புதிய வாசிப்பு தொகுதி மாதிரிகளை பயன்படுத்துகிறோம். அது முதன்மையாக உரையில் உள்ள மேல் தகவலை வெளியிடுகிறது மற் அடுத்து நாம் உரையாடல் உரையாடல் உரையாடல் அமைப்பு மற்றும் வேறு வகையான உலக அறிவை சேர்த்துக் கொள்ள விதிமுறையில் மற்றும் (பாதுகாப்பு மற்றும் ப DREAM தகவல் அமைப்பின் சோதனையின் முடிவுகள் உரையாடல் உரையாடல் அமைப்பு மற்றும் பொதுவான உலக அறிவு காட்டுகிறது. DREAM கிடைக்கும் https://dataset.org/dream/.', 'ur': 'ہم ڈرام کو پیش کرتے ہیں، پہلی ڈرائج کی بنیاد پر بہت سی انتخاب پڑھنے والی ڈیٹ سٹ. انگلیسی سے بیگانی زبان کی آزمائش کے طور پر جمع کئے گئے ہیں جو انسان کے متخصص لوگوں نے انگلیسی کی تعلیم کے سطح کی تعلیم کے لئے طراحی کئے ہیں، ہمارے ڈیٹ سٹے میں 6,444 ڈیٹ کے لئے 10,197 چند انتخاب سوال ہیں۔ موجود پڑھنے کی سمجھنے کے مقابلہ میں ڈرائم سب سے پہلا ہے جو بہت سی پڑھنے والی مجموعہ پارتی کی سمجھ پر تمرکز کرتا ہے. DREAM بہت ممکن ہے کہ موجود پڑھنے کی سمجھ سیسٹم کے لئے اہم چالیں پیش کرے: 84% جواب غیر اخلاقی ہیں، 85% سوال کے سوال میں ایک جماعت کے سوا بغیر دلیل کی ضرورت ہے، اور 34% سوال میں بھی معمولی علم کا شامل ہے۔ ہم بہت سے مشهور نورول پڑھنے کی مثالیں لکھتے ہیں جو سب سے پہلے متن میں سطح معلومات کو استعمال کرتے ہیں اور ان کو بہترین طریقے سے دیکھتے ہیں کہ صرف ایک قانون کی بنیادی طریقے سے زیادہ کم کام کرتے ہیں. ہم اس کے بعد بھی تحقیق کریں کہ دیالوگ ساختار اور مختلف طریقوں کی دنیا کی معلومات کی وجہ سے دونوں قانون کی بنیادی اور (نیورل اور غیر نیورل) ماشین کی تعلیم کی بنیادی کی پڑھنے کی معلومات میں ہے DREAM ڈیٹا سٹ پر جہاد کا نتیجہ دکھا رہا ہے کہ диалог ساختار اور عمومی دنیاوی علم کا فعالیت دکھاتا ہے. DREAM اس میں موجود ہے https://dataset.org/dream/.', 'uz': "Biz DREAM, birinchi dialog asosida muloqat tanlangan bir necha tanlangan maʼlumot tizimini o'qish. Inglizcha taʼminlovchilar ingliz tilidan o'rganish uchun odamlar o'zgarishga tayyorlanmagan ingliz tilidagi ingliz tilidan bir nechta tanlangan so'zlardan olingan, bizning ma'lumotlar tarkibini 6,444 dialoglar uchun 10,197 ta'plab tanlangan savollar bor. Name Ehtimol DREAM mavjud o'qish kompyuterni o'qish tizimi uchun juda muhim muammolar rivojlanishi mumkin: 84% javoblar ekstraktiv emas, 85% soʻzlar bir so'zdan ortiq so'zlar uchun sabablar kerak, 34% soʻzlar faqat kompyuterning илмi bilan murakkab beradi. Biz bir necha popular neyrolik o'qish modellarini qo'llab qolamiz, aslida matn ichida jadvalning maʼlumotini ko'rib chiqaradi va ularni ko'paytirish mumkin, bu qoidaga asosiy usulni bajarish mumkin. Keyingi biz muloqat tuzuvchilarining tashkilotlarini va har xil dunyo turlarini o'rganish asosida va o'rganish asosida o'rganish o'quvchi kompyuterni o'rganish modellariga o'zgartirish natijalarini o'rganamiz. Name DREAM mavjud https://dataset.org/dream/.", 'vi': 'Chúng tôi giới thiệu DREAM, tập tin nhận diện theo nhiều lựa chọn đầu tiên. Thu thập từ tiếng Anh làm bài kiểm tra ngôn ngữ ngoại ngữ được thiết kế bởi các chuyên gia về đánh giá cấp độ hiểu biết của học viên Trung Quốc về tiếng Anh, nhóm dữ liệu của chúng tôi chứa câu hỏi có nhiều lựa chọn cho 6,44. Trái với tập tin nắm bắt tập tin, DREAM là người đầu tiên tập trung vào việc hiểu biết nhiều đối tác rộng hơn. Tiến sĩ DREAM có khả năng sẽ đưa ra thử thách đáng kể cho hệ thống hiểu biết có thể tồn tại. 84 phần trăm các câu trả lời không có khai thác. 85. Chúng tôi áp dụng các mô hình hiểu biết về hệ thần kinh phổ biến, thứ nhất sử dụng thông tin trên bề mặt trong văn bản và tìm ra chúng, tốt nhất, chỉ vừa thoát khỏi một phương pháp quy định. Tiếp theo chúng ta sẽ điều tra các tác động của việc nhập cấu trúc đối thoại và các loại kiến thức toàn cầu vào cả các mô hình hiểu biết trên quy luật lẫn (thần kinh và không-thần kinh) về máy móc. Các kết quả thử nghiệm của tập đoàn dữ liệu DREAM đã phát triển hiệu quả của cấu trúc đối thoại và kiến thức toàn cầu. mơ có sẵn ở https://dataset.org/dream/.', 'nl': 'We presenteren DREAM, de eerste dialoggebaseerde multiple-choice leesbegripsgegevensset. Verzameld uit examens Engels als vreemde taal ontworpen door menselijke experts om het begripsniveau van Chinese studenten Engels te evalueren, bevat onze dataset 10,197 multiple-choice vragen voor 6,444 dialogen. In tegenstelling tot bestaande datasets met leesbegrip, is DREAM de eerste die zich richt op diepgaand multi-turn dialoogbegrip met meerdere partijen. DREAM zal waarschijnlijk aanzienlijke uitdagingen opleveren voor bestaande leesbegripssystemen: 84% van de antwoorden zijn niet-extractief, 85% van vragen vereist redenering boven één enkele zin en 34% van vragen omvat ook gezond verstand. We passen verschillende populaire neurale leesbegripsmodellen toe die voornamelijk oppervlakteinformatie binnen de tekst exploiteren en vinden dat ze in het beste geval nauwelijks beter presteren dan een op regels gebaseerde benadering. Vervolgens onderzoeken we de effecten van het integreren van dialoogstructuur en verschillende soorten algemene wereldkennis in zowel regelgebaseerde als (neurale en niet-neurale) machine learning gebaseerde leesbegripsmodellen. Experimentele resultaten op de DREAM dataset tonen de effectiviteit van dialoogstructuur en algemene wereldkennis aan. DREAM is beschikbaar op: https://dataset.org/dream/.', 'hr': 'Predstavljamo DREAM, prvi sastav podataka o razumijevanju više izbora na dijalogu. Skupljeni s engleskog kao ispitivanja vanjskih jezika koje su napravljene ljudskim stručnjacima za procjenu razine razumijevanja kineskih učenika engleskog jezika, naš sastav podataka sadrži 10 197 višeizbornih pitanja za 6 444 dijaloga. U suprotnost postojećim setima podataka o razumijevanju čitanja, DREAM je prvi koji se usredotoči na razumijevanje multistranskih dijaloga u dubinu. DREAM će vjerojatno predstaviti značajne izazove za postojeće sustave razumijevanja čitanja: 84% odgovora nisu ekstraktivni, 85% pitanja zahtijevaju razumnost izvan jednog rečenika, a 34% pitanja uključuju i znanje uobičajenog smisla. Primjenjujemo nekoliko popularnih modela razumijevanja neuralnih čitanja koji primarno iskorištavaju površinske informacije unutar teksta i najbolje ih nalazimo da jedva nadmaže pravilni pristup. Sljedeće istražujemo učinak uključenja strukture dijaloga i različitih vrsta općeg svjetskog znanja na modelima učenja na osnovu pravila i (neuralno i ne-neuralno) strojeva. Eksperimentalni rezultati na sastavu podataka DREAM pokazuju učinkovitost strukture dijaloga i općeg svjetskog znanja. DREAM je dostupan na https://dataset.org/dream/.', 'da': 'Vi præsenterer DREAM, det første dialogbaserede flervalgsdatasæt til læseforståelse. Indsamlet fra engelsk som fremmedsprog eksamener designet af menneskelige eksperter til at vurdere forståelsesniveauet for kinesiske elever af engelsk, vores datasæt indeholder 10.197 flervalgsspørgsmål til 6.444 dialoger. I modsætning til eksisterende læseforståelsesdata er DREAM den første til at fokusere på dybdegående multi-turn dialog forståelse. DREAM vil sandsynligvis udgøre betydelige udfordringer for eksisterende læseforståelsessystemer: 84% af svarene er ikke-ekstraktive, 85% af spørgsmålene kræver ræsonnement ud over en enkelt sætning, og 34% af spørgsmålene involverer også almindelig viden. Vi anvender flere populære neurale læseforståelsesmodeller, der primært udnytter overfladeinformation i teksten og finder dem til i bedste fald bare knap nok at overgå en regelbaseret tilgang. Vi undersøger derefter effekten af at indarbejde dialogstruktur og forskellige former for generel verdenskendskab i både regelbaserede og (neurale og ikke-neurale) maskinlæringsbaserede læseforståelsesmodeller. Eksperimentelle resultater på DREAM datasættet viser effektiviteten af dialogstruktur og generel verdenskendskab. DREAM er tilgængelig på https://dataset.org/dream/.', 'bg': 'Представяме първия набор от данни за разбиране на четенето, базиран на диалог. Събирани от изпити по английски като чужд език, разработени от човешки експерти, за да оценят нивото на разбиране на китайските учащи английски език, нашият набор от данни съдържа 10 197 въпроса с многократен избор за 6 444 диалога. За разлика от съществуващите набори от данни за разбиране на четенето, Дрийъм е първият, който се фокусира върху задълбоченото многостранно разбиране на диалога. Мечтата вероятно ще представлява значителни предизвикателства за съществуващите системи за разбиране на четенето: 84% от отговорите са неекстрактивни, 85% от въпросите изискват разсъждения отвъд едно изречение, а 34% от въпросите включват и общо разумно знание. Ние прилагаме няколко популярни модела на невронно разбиране за четене, които предимно експлоатират повърхностната информация в текста и откриват, че в най-добрия случай едва превъзхождат подход, основан на правила. След това изследваме ефектите от включването на структурата на диалога и различните видове общи световни познания както в базираните на правила, така и (невронно и не-невронно) модели за разбиране на четене, базирани на машинно обучение. Експерименталните резултати на набора от данни показват ефективността на структурата на диалога и общите световни познания. DREAM е на разположение на https://dataset.org/dream/.', 'id': 'Kami mempersembahkan DREAM, set data pemahaman berbasis dialog pertama. Dikumpulkan dari bahasa Inggris sebagai pemeriksaan bahasa asing yang dirancang oleh ahli manusia untuk mengevaluasi tingkat pemahaman pelajar bahasa Inggris Cina, set data kami mengandung 10.197 pertanyaan pilihan ganda untuk 6.444 dialog. Sebaliknya dengan set data pemahaman pembacaan yang ada, DREAM adalah yang pertama untuk fokus pada pemahaman dalam-dalam dialog multi-putar. DREAM mungkin akan menghasilkan tantangan yang signifikan untuk sistem pemahaman pembacaan yang ada: 84% jawaban tidak ekstraktif, 85% pertanyaan memerlukan alasan melebihi satu kalimat, dan 34% pertanyaan juga melibatkan pengetahuan umum. Kami menerapkan beberapa model pemahaman pembacaan saraf populer yang terutama mengeksploitasi informasi permukaan dalam teks dan menemukannya untuk, pada yang terbaik, hampir tidak melampaui pendekatan berdasarkan aturan. Kita berikutnya menyelidiki efek dari memasukkan struktur dialog dan jenis pengetahuan umum dunia yang berbeda ke dalam model pemahaman pembacaan berdasarkan aturan dan mesin pembacaan (saraf dan bukan saraf). Hasil eksperimen pada set data DREAM menunjukkan efektivitas struktur dialog dan pengetahuan umum dunia. DREAM tersedia di https://dataset.org/dream/.', 'de': 'Wir prﾃ､sentieren DREAM, den ersten dialogbasierten Multiple-Choice-Leseverstﾃ､ndnisdatensatz. Unser Datensatz enthﾃ､lt 10,197 Multiple-Choice-Fragen fﾃｼr 6,444-Dialoge, die von menschlichen Experten entwickelt wurden, um das Verstﾃ､ndnis von Chinesisch-Lernenden zu bewerten. Im Gegensatz zu bestehenden Leseverstﾃ､ndnisdatensﾃ､tzen konzentriert sich DREAM erstmals auf ein tiefes Multi-Turn-Multi-Party-Dialogverstﾃ､ndnis. DREAM dﾃｼrfte die bestehenden Leseverstﾃ､ndnissysteme vor erhebliche Herausforderungen stellen: 84% der Antworten sind nicht extraktiv, 85% der Fragen erfordern ﾃ彙erlegungen ﾃｼber einen einzigen Satz hinaus und 34% der Fragen beinhalten auch gesundes Wissen. Wir wenden mehrere gﾃ､ngige neuronale Leseverstﾃ､ndnismodelle an, die primﾃ､r Oberflﾃ､cheninformationen im Text ausnutzen und feststellen, dass sie bestenfalls einen regelbasierten Ansatz kaum ﾃｼbertreffen. Als nﾃ､chstes untersuchen wir die Auswirkungen der Integration von Dialogstrukturen und verschiedenen Arten von allgemeinem Weltwissen in regelbasierte und (neuronale und nicht-neuronale) maschinelles Lernen basierte Leseverstﾃ､ndnismodelle. Experimentelle Ergebnisse am DREAM Datensatz zeigen die Effektivitﾃ､t von Dialogstruktur und allgemeinem Weltwissen. DREAM ist erhﾃ､ltlich unter https://dataset.org/dream/.', 'ko': '첫 번째 대화 기반 다중 선택 읽기 이해 데이터 세트 DREAM을 보여줍니다.우리의 데이터는 인류 전문가들이 중국 영어 학습자의 영어 이해 수준을 평가하기 위해 디자인한 영어를 외국어 시험으로 삼아 10197개의 선택문제를 포함하고 총 6444개의 대화를 포함한다.기존 읽기와 이해 데이터 세트에 비해 DREAM은 심도 있는 멀티 라운드 다방면의 대화와 이해에 관심을 가진 최초의 사람이다.꿈은 기존의 읽기와 이해 시스템에 중대한 도전을 가져올 수 있다. 84%의 답안은 비추출식이고 85%의 답안은 한 마디 이외의 추리가 필요하며 34%의 답안은 상식지식과 관련된다.우리는 몇 가지 유행하는 신경 읽기 이해 모델을 응용했는데 이런 모델은 주로 텍스트의 표면 정보를 이용하고 그것들의 양이 규칙에 기초한 방법보다 겨우 낫다는 것을 발견했다.이어서 우리는 대화 구조와 서로 다른 유형의 일반 세계 지식을 규칙과 (신경과 비신경) 기계 학습을 바탕으로 하는 읽기 이해 모델에 포함시키는 효과에 대해 연구했다.꿈 데이터 집합에서의 실험 결과는 대화 구조와 일반 세계 지식의 유효성을 나타냈다.DREAM은https://dataset.org/dream/.', 'fa': 'ما DREAM را پیشنهاد می\u200cکنیم، اولین مجموعه\u200cی اطلاعات متوجه شدن چندین انتخاب بر اساس گفتگو. از انگلیسی به عنوان یک امتحان زبان خارجی که توسط متخصص بشر طراحی شده است برای ارزیابی سطح فهمیدن دانش آموزان چینی از انگلیسی جمع شده است، مجموعه داده های ما ۱۰.197 سوال چندین انتخاب برای ۶.444 گفتگو دارد. در مقابل با مجموعه\u200cهای اطلاعات درک خواندن موجود DREAM اولین است که روی درک مشاوره\u200cهای مختلف\u200cگروه\u200cهای عمیق تمرکز می\u200cکند. DREAM احتمالاً چالش\u200cهای مهم برای سیستم\u200cهای فهمیدن خواندن موجود است: 84 درصد جواب\u200cها غیر خارج\u200cکننده\u200cاند، 85 درصد سوال\u200cها دلیل\u200cهای بیشتر از یک جمله نیاز دارند، و 34 درصد سوال\u200cها همچنین دانش\u200cهای معمولی\u200cاند. ما چندتا مدل درک مغز مغز مشهور را استفاده می\u200cکنیم که در اصل اطلاعات سطح در متن استفاده می\u200cکند و در نهایت آنها را پیدا می\u200cکنیم که به سختی از یک روش بر پایه قانون بیشتر از آن انجام می\u200cدهد. ما بعدش اثرات ساختار گفتگو و نوع دانش جهانی مختلف را تحقیق می\u200cکنیم در مدل\u200cهای یادگیری از نظر قانونی و (نوعی و غیر عصبی) دستگاه\u200cهای یادگیری متوجه شده است. نتیجه\u200cهای تجربه روی مجموعه داده\u200cهای DREAM نشان می\u200cدهد فعالیت ساختار محاوره و دانش جهانی عمومی. DREAM در https://dataset.org/dream/.', 'sw': 'Tunawasilisha DREAM, kituo cha kwanza cha mazungumzo yanayohusiana na chaguo mbalimbali cha kusoma taarifa za kompyuta. Wakusanyika kutoka Kiingereza kama utafiti wa lugha ya kigeni uliobuniwa na wataalam wa binadamu ili kutathmini kiwango cha msingi cha wanafunzi wa Kichina wa Kiingereza, seti ya takwimu zetu ina maswali ya chaguo mengi ya miaka 10,197 kwa ajili ya mazungumzo 6,444. Tofauti na seti za taarifa za msingi za kusoma, DREAM ni wa kwanza ya kutazama uelewa wa mazungumzo ya kisiasa wa vyama vingi vingi. DREAM ina uwezekano wa kuweka changamoto kubwa kwa mfumo wa mfumo wa kompyuta wa kusoma: asilimia 84 wapo ya majibu yasiyoeleweka, asilimia 85 ya maswali yanahitaji kuwa na sababu zaidi ya hukumu moja, na asilimia 34 ya maswali pia yanahusisha maarifa ya umma. Tunatumia mifano kadhaa maarufu ya kusoma taratibu ambazo kwa ujumla hutumia taarifa za uso katika ujumbe wa maandishi na kuwapatia, angalau, si vigumu tu kutekeleza mbinu za msingi wa sheria. Baadae tunachunguza madhara ya kuingiza muundo wa mazungumzo na aina mbalimbali ya maarifa ya ulimwengu wa jumla katika mbinu za kujifunza kwa msingi wa sheria na mashine isiyo na taratibu. Matokeo ya majaribio kuhusu takwimu za DREAM yanaonyesha ufanisi wa muundo wa mazungumzo na maarifa ya jumla ya dunia. DREAM is available at  https://dataset.org/dream/.', 'tr': "DREAM'i, birinji dijalogda birnäçe seçmeli maglumat düzümlerini okamak üçin belledik. Iňlisçe baglanýan adamlaryň uzmanlary tarapyndan Iňlisçe öwrenmeleriň derejesini deňlemek üçin guruldyran daşary dil synaglary hökmünde, biziň maglumatlarymyz 6,444 dialoglar üçin 10,197 sany çykyş soraglary bar. Öň bar okama maglumat düzümleriniň garşynda, DREAM multi-party düzümlerniň derinliklerine üns bermek üçin birinjisi dir. DREAM bolan okama sistemalary üçin wajyp kynçylyklary görkezmäge mümkin edip bilýär: 84% jogabynyň gaýd edilmedigi bolup, 85% soragynyň ýeke sözläniň öňünden akyl bermesi gerek, we 34% soragynyň daşary duýdurma bilimi hem bolup geçýär. Biz birnäçe meşhur näural okama nuwasynyň düşünmesi modellerini uygulaýarys we olaryň üstüne görnüş maglumatlaryny tekstiň içinden ulanýarlar we olaryň üstünde düzgün kararlar taýýarlanmagynyň ýok. Biz indiki diniň düzgünlerini daşary ýaly düzgünlere daşary ýaly düzgünlere daşary ýaly düzgünlere daşary ýaly (neural we non-neural) maşynyň öwrenmesine daşary ýaly düzgünlere üýtgeden täsirlerini inceleýäris. DREAM maglumatyň netijesi bardygynda dýalogyň strukturyň we dünýädäki bilgilerin täsirini görkezýär. DREAM bar https://dataset.org/dream/.", 'sq': 'Ne prezantojmë DREAM, grupin e parë të zgjedhjeve të shumëfishta të zgjedhjeve të bazuar në dialog. Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our data set contains 10,197 multiple-choice questions for 6,444 dialogues.  Në kundërshtim me grupet ekzistuese të të dhënash të kuptimit të leximit, DREAM është i pari që përqëndrohet në kuptimin e thellë të dialogut me shumë anë. DREAM ka gjasa të paraqesë sfida të rëndësishme për sistemet ekzistuese të kuptimit të leximit: 84% e përgjigjeve nuk janë ekstraktive, 85% e pyetjeve kërkojnë arsyetim përtej një fjalie të vetme dhe 34% e pyetjeve përfshijnë gjithashtu njohuri të përbashkët. Ne aplikojmë disa modele të njohura të kuptimit të leximit nervor që kryesisht shfrytëzojnë informacionin e sipërfaqes brenda tekstit dhe i gjejmë a to për, në më të mirën, vetëm mezi të kalojnë një qasje bazuar në rregulla. Pastaj ne hetojmë efektet e përfshirjes së strukturës së dialogut dhe llojeve të ndryshme të njohurive të përgjithshme botërore në modelet e kuptimit të leximit të bazuar në rregulla dhe (nervore dhe jo-nervore). Rezultatet eksperimentale në grupin e të dhënave DREAM tregojnë efektshmërinë e strukturës së dialogut dhe njohurinë e përgjithshme botërore. DREAM është në dispozicion në https://dataset.org/dream/.', 'af': "Ons voorsien DREAM, die eerste dialoog gebaseer veelvuldige keuses lees verstandige data stel. Ons data set bevat 10,197 veelvuldige keuses vrae vir 6,444 dialoog. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialog understanding. DREAM is waarskynlik waarskynlik om betekende uitdagings te voorsien vir bestaande lees verstandingsstelsels: 84% van antwoordes is nie-extraktief, 85% van vrae benodig redening buite 'n enkele seting, en 34% van vrae is ook gewoonlike kennis. Ons het verskeie populêre neuralse lees verstaan modele aanwend wat voorskynlik oorspronklike informasie binne die teks uitgebruik en hulle vind om, op die beste, net skaars 'n reël-gebaseerde toegang te uitvoer. Ons volgende ondersoek die effekte van die inkorporering van dialoog struktuur en verskillende soorte algemene wêreld kennis binne beide reël gebaseerde en (neurale en nie-neurale) masjien leer-gebaseerde lees-verstandingsmodele. Eksperimentale resultate op die DREAM data stel vertoon die effektiviteit van dialoog struktuur en algemene wêreld kennis. DREAM is beskikbaar by https://dataset.org/dream/.", 'am': "የመጀመሪያው dialog-based በብዙ ምርጫዎች የድምፅ አካባቢ ዳታዎችን ማነብ እናቀርባለን፡፡ የቻይና ተማሪዎችን የንግልዝኛ ደረጃውን ለማስተዋል የውጭ ቋንቋ ፈተና እንዲሆን ከንግግሊዘኛ የተሰበሰቡ ናቸው፤ ዳራታችን የ10,197 ብዛት ምርጫ ጥያቄዎችን 6,444 ጥያቄዎች ይኖራል፡፡ በአሁኑ አንብቡ የድምፅ አካባቢ ዳታ ማሰናጃ በተቃውሞ DREAM የጥልቅ multi-party የመስመር ማስተዋል መጀመሪያ ነው፡፡ DREAM የአስቸጋሪው አካባቢ መፍትወት ስርዓቶችን ለመቀላቀል የሚያስፈልግ ግንኙነቶችን ማሳየት ይችላል፤ 84 በመቶ መልሶች ያልተወለዱ ናቸው፤ 85 በመቶ ጥያቄዎች ከአንዲት ፍርድ በስተቀር ክርክር ያስፈልጋሉ፥ 34 በመቶ ጥያቄዎች ደግሞ የድምፅ እውቀትን ያስተካክላሉ፡፡ በጽሑፉ ውስጥ የደረጃ መረጃን ለመጠቀም እናደርጋለን፡፡ በኋላም የጦማሪያን አካባቢ እና የልዩ ልዩ ዓይነት የዓለም እውቀትን በማቀናቀል እና በሥርዓት መሠረት እና (የደዌብ እና የነጥብ እና የሌለባቸው) መሳሪያዎች የሚማርከውን ጥናት እናምርመራለን፡፡ የDREAM ዳታ ማዕከላዊ ጥናት እና የዓለም አዋቂ እውቀት ጥያቄን ያሳያል፡፡ ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s https://dataset.org/dream/.", 'hy': 'Մենք ներկայացնում ենք "Երազ"-ը, առաջին երկխոսում հիմնված բազմաթիվ ընտրությունների ընթերցման տվյալների համակարգը: Հաւաքումված անգլերենից որպես օտար լեզվի քննություններ, որոնք ստեղծվել են մարդկային մասնագետների կողմից, որպեսզի գնահատեն անգլերենի չինական ուսանողների հասկացության մակարդակը, մեր տվյալների համակարգը պարունակում է 10,197 բազմապատկած հարց Ի հակադրություն գոյություն ունեցող ընթերցման ընկալումների տվյալների համակարգերին, առաջինն է, որ կենտրոնացնում է խորը բազմակողմների բազմակողմների խմբախոսքի ընկալումների վրա: DREAM is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve commonsense knowledge.  Մենք կիրառում ենք մի քանի հայտնի նյարդային կարդալու ընկալումների մոդելներ, որոնք հիմնականում օգտագործում են տեքստի մեջ գտնվող մակերևույթի տեղեկատվությունը և գտնում են դրանք, լավագույն դեպքում, միայն հազիվ են արտահայտվում կանոն Հաջորդ անգամ մենք ուսումնասիրում ենք, թե ինչպես են ներառվում երկխոսակցության կառուցվածքը և աշխարհի տարբեր գիտելիքների տարբեր տեսակները օրենքների և (նեյրոնային և ոչ նեյրոնային) մեքենայի ուսումնասիրության հիմնված ընթերցման մոդելների մե Դրեյամ տվյալների համակարգի փորձարկման արդյունքները ցույց են տալիս երկխոսության կառուցվածքի արդյունավետությունը և աշխարհի ընդհանուր գիտելիքները: Դրեյմը հասանելի է https://dataset.org/dream/.', 'az': "Biz DREAM'i, ilk dialoğu-tabanlı çoxlu seçimlər oxuyan məlumat qutusunu göstəririk. İngilizdən İngilizce dilindən İngilizce öyrənənənlərin anlaşılması üçün insanların təhsil edilmiş xəbərlər kimi İngilizce dilindən toplanmış, verilən qurğumuz 6 444 dialoglar üçün 10 197 çox seçilmiş suallar barəsindədir. Mevcut oxumaq məlumatlarının anlaşılması tərəfindən əvvəlki DREAM, çoxlu-çoxlu dəyişiklik məlumatlarının anlaşılmasına baxmayan ilk dəyişiklikdir. DREAM mövcuddur oxumaq sistemlərinin mövcuddur çətinlikləri göstərməyə mümkün ola bilər: 84% cavabların istifadə edilməz, 85% sualların tək cümlədən artıq dəyişiklik istəyir, 34% sualların də çoxlu bilikləri olmalıdır. Biz bir neçə məşhur nöral okuma modellərini istifadə edirik ki, ilk dəfə üzərində məlumatları istifadə edir və onları ən yaxşısında, sadəcə qayda-qüvvəsi tərəfind ən az qaldırır. Sonradan biz diyal quruluğu və dünyanın müxtəlif türlü ünvanlıq bilənlərin, həmçinin nöral və nöral olmayan maşın öyrənməsi modellərinə istifadə etdiyimiz təsirlərini incidirik. DREAM verilənlərin təcrübələrinin müxtəlif sonuçları dijalog quruluşunun və dünya elmi ehtiyacını göstərir. DREAM mövcuddur https://dataset.org/dream/.", 'bn': 'আমরা ড্রিয়াম, প্রথম ডায়ালগ ভিত্তিক বেছে নেওয়া বেছে নিয়েছি কনফিগারেন্স ডাটা সেট। ইংরেজি থেকে বিদেশী ভাষা পরীক্ষা হিসেবে সংগ্রহ করা হয়েছে মানব বিশেষজ্ঞ যারা ইংরেজী শিক্ষার স্তরের মূল্যায়ন করার জন্য। আমাদের ডাটা সেটে ৬,৪৪৪ ডো বিদ্যমান পাঠানো সম্পূর্ণ তথ্য সেটের বিপরীতে, ড্রিয়াম হচ্ছে প্রথম গভীরে অন্তর্ভুক্ত মাল্টি পার্টি ডায়ালগের ব্যাপারে মন বিদ্যমান পাঠের সংক্রান্ত সিস্টেমের জন্য ড্রিএম বিশাল চ্যালেঞ্জ উপস্থাপন করতে পারে: ৮৪ শতাংশ উত্তর অক্রিয়াকর্তা, ৮৫% প্রশ্নের প্রয়োজন এক বাক্যের বাইরে যুক আমরা বেশ কয়েকটি জনপ্রিয় নিউরেল পড়তে পারি সম্পূর্ণ মডেল যারা প্রধান টেক্সটের ভিতরে তথ্য বিস্ফোরণ করে এবং তাদের খুঁজে বের করে যায়, শু পরবর্তীতে আমরা ডায়ালগ কাঠামো এবং বিভিন্ন ধরনের সাধারণ বিশ্বের জ্ঞান যোগাযোগ করার প্রভাব তদন্ত করি শিক্ষা ভিত্তিক ভিত্তিক মেশিনের শিক্ষা ও Experimental results on the DREAM data set show the effectiveness of dialogue structure and general world knowledge.  DREAM উপস্থিত https://dataset.org/dream/.', 'bs': 'Predstavljamo DREAM, prvi sastav podataka o razumijevanju više izbora na dijalogu. Skupljeni sa engleskog kao ispitivanja vanjskih jezika koje su dizajnirali ljudski stručnjaci za procjenu razine razumijevanja kineskih učenika engleskog jezika, naš sastav podataka sadrži 10 197 višeizbornih pitanja za 6 444 dijaloga. U suprotnost postojećim setima podataka o razumijevanju čitanja, DREAM je prvi koji se fokusira na razumijevanje multistrantskog dijaloga u dubini. DREAM će vjerojatno predstaviti značajne izazove za postojeće sustave razumijevanja čitanja: 84% odgovora su ne-ekstraktivni, 85% pitanja zahtijevaju razumijevanje izvan jedne rečenice, a 34% pitanja također uključuju znanje zajedničkog smisla. Primjenjujemo nekoliko popularnih modela razumijevanja neuralnih čitanja koji primarno iskorištavaju površinske informacije unutar teksta i pronađu ih da, najbolje, jedva iznosi pravilni pristup. Sledeće istražujemo učinke uključenja strukture dijaloga i različitih vrsta svetskog znanja u modele razumijevanja na osnovu pravila i (neuralne i ne-neuralne) mašine na osnovu učenja. Eksperimentalni rezultati na sastavu podataka DREAM pokazuju učinkovitost strukture dijaloga i općeg svjetskog znanja. DREAM je dostupan na https://dataset.org/dream/.', 'ca': "Presentam DREAM, el primer conjunt de dades de comprensió de lectura basat en diàleg múltiple. Recollits d'anglès com a exàmens de llenguatge estranger dissenyats per experts humans per avaluar el nivell de comprensió dels aprenents xinesos d'anglès, el nostre conjunt de dades conté 10.197 preguntes de múltiples eleccions per 6.444 diàlegs. A diferència dels conjunts de dades de comprensió de lectura existents, DREAM és el primer a centrar-se en una comprensió profunda del diàleg multipartit. DREAM is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve commonsense knowledge.  Aplicam varis models populars de comprensió de lectura neuronal que explotan principalment la informació sobre la superfície dins el text i les trobem per, al millor, només gairebé superar un enfocament basat en les regles. Després investigam els efectes d'incorporar l'estructura del diàleg i diferents tipus de coneixement mundial en models de comprensió de lectura basats en regles i (neuronal i no neuronal). Els resultats experimentals del conjunt de dades DREAM mostren l'eficacia de l'estructura del diàleg i el coneixement mundial general. El somni està disponible en https://dataset.org/dream/.", 'cs': 'Představujeme DREAM, první dialog založený na multiple-choice datový soubor porozumění čtení. Náš datový soubor shromážděný ze zkoušek z angličtiny jako cizího jazyka navržených lidskými odborníky pro hodnocení úrovně porozumění čínštiny studentům angličtiny obsahuje 10,197 otázky s více výběrem pro 6,444 dialogy. Na rozdíl od existujících datových sad porozumění čtení je DREAM první, kdo se zaměřuje na hloubkové porozumění dialogu s více stranami. DREAM pravděpodobně představuje významné výzvy pro stávající systémy porozumění čtení: 84% odpovědí nejsou extraktivní, 85% otázek vyžaduje uvažování nad rámec jedné věty a 34% otázek také zahrnuje zdravý rozumný vědomí. Aplikujeme několik populárních neuronových modelů porozumění čtení, které primárně využívají povrchové informace v textu a zjišťují, že v nejlepším případě sotva překonávají přístup založený na pravidlech. Dále zkoumáme vliv začlenění dialogové struktury a různých druhů obecných znalostí světa do modelů porozumění čtení založených na pravidlech i (neuronových a neurálních) strojovém učení. Experimentální výsledky na datové sadě DREAM ukazují efektivitu struktury dialogu a obecné znalosti světa. DREAM je k dispozici na adrese https://dataset.org/dream/.', 'et': 'Esitleme DREAM, esimese dialoogipõhise mitmevalikulise lugemise mõistmise andmekogumi. Kogutud inglise keele kui võõrkeelena ekspertide poolt loodud ekspertide poolt inglise keele mõistmise taseme hindamiseks, meie andmekogum sisaldab 10 197 valikuküsimust 6444 dialoogi jaoks. Erinevalt olemasolevatest lugemise mõistmise andmekogumitest on DREAM esimene, kes keskendub sügavale mitmekäigulisele dialoogi mõistmisele. DREAM kujutab tõenäoliselt endast olulisi väljakutseid olemasolevatele lugemise mõistmise süsteemidele: 84% vastustest ei ole ekstraktiivsed, 85% küsimustest vajavad arutlust väljaspool ühte lauset ja 34% küsimustest hõlmavad ka üldse mõistlikke teadmisi. Me rakendame mitmeid populaarseid närvilugemise mõistmise mudeleid, mis kasutavad peamiselt tekstis sisalduvat pinnainformatsiooni ja leiavad, et need parimal juhul lihtsalt ületavad reeglipõhist lähenemisviisi. Seejärel uurime dialoogi struktuuri ja erinevate üldiste maailmateadmiste kaasamise mõju nii reeglitel põhinevatesse kui ka (neuraalsetesse ja mittenneuraalsetesse) masinõppel põhinevatesse lugemismudelitesse. DREAM andmekogumi katsetulemused näitavad dialoogi struktuuri ja üldiste maailmateadmiste tõhusust. DREAM on saadaval aadressil https://dataset.org/dream/.', 'fi': 'Esittelemme DREAM, ensimmäisen dialogiin perustuvan monivalintaisen lukuymmärryksen aineiston. Aineistomme on kerätty englannin kielen vieraana kielenä -kokeista, joiden tarkoituksena on arvioida kiinalaisten englannin oppijoiden ymmärtämistasoa. Toisin kuin olemassa olevat lukuymmärryksen aineistot, DREAM on ensimmäinen, joka keskittyy syvälliseen monikierroksen vuoropuhelun ymmärtämiseen. DREAM tuo todennäköisesti merkittäviä haasteita olemassa oleville lukujen ymmärtämisjärjestelmille: 84% vastauksista ei ole ekstraktiivisia, 85% kysymyksistä vaatii yhden lauseen ylittävää päättelyä ja 34% kysymyksistä sisältää myös yleistä tietämystä. Sovellamme useita suosittuja neurolukujen ymmärtämismalleja, jotka hyödyntävät ensisijaisesti tekstin pintatietoja ja löytävät ne parhaimmillaan vain hädin tuskin ylittämään sääntöpohjaista lähestymistapaa. Seuraavaksi tutkimme dialogirakenteen ja erilaisten yleistietojen sisällyttämisen vaikutuksia sekä sääntöpohjaisiin että (neuro- ja ei-neuropohjaisiin) koneoppimiseen perustuviin lukuymmärrysmalleihin. Kokeelliset tulokset DREAM-aineistosta osoittavat dialogirakenteen ja yleisen maailmankuvan tehokkuuden. DREAM on saatavilla osoitteessa https://dataset.org/dream/.', 'jv': 'text-box-mode Sumangkat karo Inggris nganggo perusahaan langkung rawut karo perusahaan anyar tentang kanggo nggunakake kapan kanggo langgar sampek Pangan inggris, dadi sing nyimpen karo 10. EMAIL (Adverti voice 2) Awak dhéwé éntuk sistem sing paling-popular neng sampek model sing luwih basa nêrung kuwi kesempatan ngono nggawe ndelok ngono kuwi nggawe, ditambah dhéwé, kuwi ora bisa teka rule-sabanjuré. Awake next Rejalaké sing paling nggambar dadi DELAM kuwi nggawe barang seneng pisan neng ngerasahan barang iki alam sing ngerasakno. friendly time" string for the current day, strftime format. like "Today 12:34 am https://dataset.org/dream/.', 'he': 'אנחנו מציגים את חלום, קבוצת נתונים של הבנה בהתבסס בהחלטה רבה על ידי דיאלוג הראשון. Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our data set contains 10,197 multiple-choice questions for 6,444 dialogues.  בניגוד לקבוצות נתונים שקיימות בקריאה, DREAM הוא הראשון להתמקד בהבנה עמוקה של דיאלוג רב-סיבובים. DREAM סביר להניח אתגרים משמעותיים למערכות הבנה קריאה קיימות: 84% מהתשובות הן לא חושפות, 85% מהשאלות דורשות הגיון מעבר למשפט אחד, ו-34% מהשאלות כוללות גם ידע משמעותי. אנחנו משתמשים במספר דוגמנים של הבנה של קריאה עצבית פופולריים שמניצלים בעיקר מידע על פני השטח בתוך הטקסט וממצאים אותם, במקרה הטוב, בקושי עולים על גישה מבוססת על חוקים. אנו חוקרים הבא את ההשפעות של שיתוף מבנה דיאלוג וסוגים שונים של ידע כללי בעולם למודלים של בינה קריאה מבוססים על חוקים ומכונות (עצביות ולא עצביות). תוצאות ניסויים על קבוצת הנתונים של DREAM מראות את היעילות של מבנה דיאלוג וידע עולם כללי. חלום זמין ב https://dataset.org/dream/.', 'sk': 'Predstavljamo DREAM, prvi nabor podatkov o razumevanju branja, ki temelji na dialogu. Naš nabor podatkov je zbran na podlagi izpitov angleščine kot tujega jezika, ki so jih človeški strokovnjaki oblikovali za oceno ravni razumevanja kitajskih učencev angleščine, zato vsebuje 10.197 vprašanj z več izbiro za 6.444 dialogov. V nasprotju z obstoječimi nabori podatkov o razumevanju branja je DREAM prvi, ki se osredotoča na poglobljeno razumevanje večstranskega dialoga. DREAM bo verjetno predstavljal pomembne izzive za obstoječe sisteme razumevanja branja: 84% odgovorov ni ekstraktivnih, 85% vprašanj zahteva razlago nad enim stavkom, 34% vprašanj pa vključuje tudi splošno znanje. Uporabljamo več priljubljenih modelov nevronskega razumevanja branja, ki predvsem izkoriščajo površinske informacije v besedilu in ugotavljajo, da v najboljšem primeru komaj presegajo pristop, ki temelji na pravilih. V nadaljevanju raziskujemo učinke vključevanja dialogne strukture in različnih vrst splošnega svetovnega znanja v modele branja, ki temeljijo na pravilih in (nevronsko in ne-nevronsko) strojnega učenja. Eksperimentalni rezultati podatkovnega nabora DREAM kažejo učinkovitost strukture dialoga in splošnega svetovnega znanja. DREAM je na voljo na spletni strani https://dataset.org/dream/.', 'ha': "Munã halatar da DERAM, da na farkon zauren akwatin bayani na farkon zaɓani masu karatun danne na ƙaranci. Ana haɗa daga Ingiriya kamar jarrabo na Lugha na Gani wanda mutum na ƙayyade dõmin su evaluce daraja na masu sani na Kiyãki na Ingiriya, tsarin data na ƙunsa da wasu maswali masu yawa na zauren zauren akwai 10,197 na cikin zauren akwatin bayani 6,444. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding.  Ana yiwuwa, DTRAM zai gaura masu yiwuwa masu muhimmi wa'urar karãtun littafin da ke gaba: 84% na matsalan su ne ba masu farata, 85% na tambayar su yana da rabo a bayan wata kalma guda, kuma 34% daga masĩfun sun sami da ilmi na kommison. Munã amfani da wasu misãlai masu karatun karãtun littafin neural da ke ƙara bayani a cikin littãfin kuma za mu iya amfani da su, a lokacin da, ko da kuma kada sai su sami wata hanyoyi a kan rubutun. Munã ƙara yin ƙidãya a cikin shirin akwatin zauren akwatin bayani da wasu nau'i'a cikin zane na cikin su a cikin rubutun da masu karatun karatun masu karatun da kuma (neural da ne-neura). Matarin jarraba kan data na daidaita DTRAM na nuna aikin tsarin zauren akwatin bayanin zauren akwatin bayani da ilmi na duniya. QUnicodeControlCharacterMenu https://dataset.org/dream/.", 'bo': 'ང་ཚོས་DREAM་ལྟ་སྟངས་འཛུགས་པའི་ཆ་འཕྲིན་གྱི་ཌའི་ལོག དབྱིན་ཡིག་གི་ནང་དུ་ཡོད་པའི་སྐད་ཡིག་གཙོ་བོ་ཞིག་ལས་རྒྱལ་ཁབ་ཀྱི་དཔྱད་ཞིག In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialog understanding. DREAM ནི་གནས་ཡོད་པའི་ལྟ་ཀློག་ནུས་ཡོད་པའི་དཀའ་ངལ་ཆེན་པོ་བྱེད་སྐབས་ཡོད་ཆེན་ཅིག་འཆར་ཐབས་མེད། ལན་གསལ་གྱི་84% We apply several popular neural reading comprehension models that primarily exploit surface information in the text and find them to, at best, just barely outperform a rule-based approach. འུ་ཚོས་གྲངས་ཤིག་གིས་དབྱེ་རིམ་དཔྱད་དབྱེ་རིམ་དང་མཐུན་པའི་རྗེས་སུ་དབྱིན་ཡོད་པའི་འཇིག་རྟེན་ལ་གཞི་བཞག་ཡོད་པའི་སྣེ་མཐུན་རྣམས་ཀློག DREAM གནས་ཚུལ་གྱི་སྒེར་གྱི་གྲུབ DREAM སྤྱོད་ཐུབ་པ https://dataset.org/dream/.'}
{'en': 'Syntax-aware Semantic Role Labeling without Parsing', 'ar': 'وصف الأدوار الدلالية مع مراعاة بناء الجملة دون تحليل', 'es': 'Etiquetado semántico de roles con reconocimiento de sintaxis sin análisis', 'fr': 'Étiquetage sémantique des rôles sensibles à la syntaxe sans analyse syntaxique', 'pt': 'Rotulagem de papéis semânticos com reconhecimento de sintaxe sem análise', 'ja': '構文認識セマンティックロールのラベル付け(解析なし)', 'zh': '无解析者语法知语义角', 'hi': 'पार्सिंग के बिना सिंटैक्स-जागरूक सिमेंटिक रोल लेबलिंग', 'ru': 'Семантическая разметка ролей с распознаванием синтаксиса без разбора', 'ga': 'Lipéadú Róil Shéimeantach atá feasach ar chomhréir gan Parsáil', 'ka': 'სინტაქსური სემანტიკური პროლის ლაბლიერი გადაწყვება', 'el': 'Σημαντική επισήμανση ρόλων με συναρμολόγηση χωρίς ανάλυση', 'hu': 'Szintaxistudatos szemantikus szerepkörcímkézés értelmezés nélkül', 'kk': 'Синтаксисті талдау жоқ Semantic Role Labeling', 'it': 'Etichettatura semantica consapevole della sintassi senza parsing', 'ms': 'Label Rol Semantik Sedia-Sintaks tanpa Menghurai', 'ml': 'പാര്\u200dസിങ് ഇല്ലാതെ സിന്റാക്സ് അറിയുന്ന സെമാന്റിക് റോള്\u200d ലാബില്\u200dങ്ങ്', 'lt': 'Sintetiškai žinomas Semantinis vaidmens ženklinimas be analizavimo', 'mn': 'Синтаксис мэдэхгүй Semantic Role Labeling', 'no': 'Semantisk rolletiketting utan tolking', 'pl': 'Znakowanie ról semantycznych w oparciu o składnię bez parsowania', 'ro': 'Etichetarea rolurilor semantice conștientă de sintaxă fără parsare', 'mk': 'Семантичко означување на улогата без анализирање', 'sr': 'Sintaksija svesna semantička oznake uloge bez analize', 'mt': 'Tikkettar Semantiku tar-Rwol b’Sentaks Mingħajr Analiżi', 'sv': 'Syntaxmedveten semantisk rollmärkning utan tolkning', 'si': 'වාක්ෂාව- දැනගන්න සෙමැන්ටික් ප්\u200dරදේශ ලේබිලින් නැතුව', 'so': 'Qashinka galmada ee sintada-ogeysiisa', 'ta': 'பாசிங்கு இல்லாமல் ஒத்திசைப்படுத்தப்படும் செமான்டிக் பள்ளி', 'ur': 'سینٹکس-آگاہ سیمنٹی رول لیبلینگ بغیر پارسینگ', 'uz': 'Name', 'vi': 'KCharselect unicode block name', 'da': 'Syntaksbevidst semantisk rollemærkning uden fortolkning', 'hr': 'Semantička označavanja uloga bez razmatranja', 'bg': 'Етикетиране на семантични роли без анализ', 'nl': 'Syntaxisbewuste semantische rollabeling zonder parsing', 'de': 'Syntaxbewusste semantische Rollenbeschriftung ohne Parsing', 'id': 'Label Rol Semantik Bersadar Sintaks tanpa Menganalisis', 'fa': 'برچسب نقشه\u200cهای سیمانتیک را بدون تولید به سینتکس آگاه می\u200cشود', 'sw': 'Msimamo wa Kisemantic Msichoba bila kuimba', 'af': 'Sintaks- bewys Semantiese roletiket sonder verwerking', 'sq': 'Etiketimi i rolit Semantik i Sintaksit pa analizim', 'ko': '해석할 필요가 없는 문법 감지 의미 역할 표기', 'am': 'ፋይል sን መክፈት አልቻለም፦ %s፦ %s', 'az': 'Sintaks-aware Semantik Rol Labeling', 'bn': 'পার্সিং ছাড়া সিন্যাক্স-সচেতন সেমান্টিক রোল লেবেলিং', 'tr': 'Semantik Roler Namaýyşçysy', 'bs': 'Semantička etiketa uloga bez razmatranja', 'ca': 'Etiquetat de paper Semàtic conscient de la sintaxi sense analitzar', 'cs': 'Sémantické označování rolí s ohledem na syntaxi bez analýzy', 'hy': 'Comment', 'fi': 'Syntaksitietoinen Semanttinen Roolimerkintä ilman jäsentelyä', 'et': 'Süntaksiteadlik semantiline rolli märgistamine ilma parsimiseta', 'jv': 'structural navigation', 'ha': 'KCharselect unicode block name', 'sk': 'Označevanje semantične vloge brez razčlenitve', 'he': 'תווית תפקיד סמנטית מודעת לסינטקס ללא מעבדה', 'bo': 'ཡིག་སྒྲུང་མེད་པའི་ཚིག་རྟགས་ལྟ་ཀློག་པའི་semantic Role Labeling'}
{'en': 'In this paper we focus on learning dependency aware representations for semantic role labeling without recourse to an external parser. The backbone of our model is an LSTM-based semantic role labeler jointly trained with two auxiliary tasks : predicting the dependency label of a word and whether there exists an arc linking it to the predicate. The auxiliary tasks provide syntactic information that is specific to semantic role labeling and are learned from training data (dependency annotations) without relying on existing dependency parsers, which can be noisy (e.g., on out-of-domain data or infrequent constructions). Experimental results on the CoNLL-2009 benchmark dataset show that our model outperforms the state of the art in English, and consistently improves performance in other languages, including Chinese, German, and Spanish.', 'ar': 'في هذه الورقة ، نركز على تعلم التمثيلات المدركة للتبعية لوصف الأدوار الدلالية دون اللجوء إلى محلل خارجي. العمود الفقري لنموذجنا هو أداة تسمية الأدوار الدلالية القائمة على LSTM والتي تم تدريبها بشكل مشترك مع مهمتين مساعدتين: التنبؤ بتسمية التبعية لكلمة وما إذا كان هناك قوس يربطها بالمسند. توفر المهام المساعدة معلومات نحوية خاصة بتسمية الأدوار الدلالية ويتم تعلمها من بيانات التدريب (شروح التبعية) دون الاعتماد على محللات التبعية الحالية ، والتي يمكن أن تكون صاخبة (على سبيل المثال ، على البيانات خارج المجال أو الإنشاءات غير المتكررة). تُظهر النتائج التجريبية على مجموعة البيانات المعيارية CoNLL-2009 أن نموذجنا يتفوق في الأداء على أحدث التقنيات في اللغة الإنجليزية ، ويحسن الأداء باستمرار في اللغات الأخرى ، بما في ذلك الصينية والألمانية والإسبانية.', 'es': 'En este artículo nos centramos en aprender representaciones conscientes de la dependencia para el etiquetado semántico de roles sin recurrir a un analizador externo. La columna vertebral de nuestro modelo es un etiquetador de roles semánticos basado en LSTM entrenado conjuntamente con dos tareas auxiliares: predecir la etiqueta de dependencia de una palabra y si existe un arco que la vincule con el predicado. Las tareas auxiliares proporcionan información sintáctica específica del etiquetado semántico de roles y se aprenden de los datos de entrenamiento (anotaciones de dependencias) sin depender de los analizadores de dependencias existentes, que pueden ser ruidosos (por ejemplo, en datos fuera del dominio o construcciones poco frecuentes). Los resultados experimentales del conjunto de datos de referencia ConLL-2009 muestran que nuestro modelo supera al estado del arte en inglés y mejora constantemente el rendimiento en otros idiomas, incluidos el chino, el alemán y el español.', 'fr': "Dans cet article, nous nous concentrons sur l'apprentissage des représentations sensibles aux dépendances pour l'étiquetage sémantique des rôles sans recourir à un analyseur externe. L'épine dorsale de notre modèle est un étiqueteur de rôle sémantique basé sur LSTM formé conjointement avec deux tâches auxiliaires\xa0: prédire l'étiquette de dépendance d'un mot et s'il existe un arc le reliant au prédicat. Les tâches auxiliaires fournissent des informations syntaxiques spécifiques à l'étiquetage sémantique des rôles et sont apprises à partir de données d'apprentissage (annotations de dépendance) sans dépendre des analyseurs de dépendances existants, qui peuvent être bruyants (par exemple, sur des données hors domaine ou des constructions peu fréquentes). Les résultats expérimentaux de l'ensemble de données de référence ConLL-2009 montrent que notre modèle surpasse l'état de l'art en anglais et améliore constamment les performances dans d'autres langues, notamment le chinois, l'allemand et l'espagnol.", 'pt': 'Neste artigo, nos concentramos em aprender representações conscientes de dependência para rotulagem de papéis semânticos sem recorrer a um analisador externo. A espinha dorsal do nosso modelo é um rotulador de função semântica baseado em LSTM treinado em conjunto com duas tarefas auxiliares: prever o rótulo de dependência de uma palavra e se existe um arco ligando-o ao predicado. As tarefas auxiliares fornecem informações sintáticas específicas para rotulagem de função semântica e são aprendidas com dados de treinamento (anotações de dependência) sem depender de analisadores de dependência existentes, que podem ser ruidosos (por exemplo, em dados fora de domínio ou construções infrequentes). Resultados experimentais no conjunto de dados de referência CoNLL-2009 mostram que nosso modelo supera o estado da arte em inglês e melhora consistentemente o desempenho em outros idiomas, incluindo chinês, alemão e espanhol.', 'ja': 'この論文では、外部構文解析器に依存せずに、セマンティックロールのラベル付けのための依存関係認識表現を学習することに焦点を当てている。私たちのモデルのバックボーンは、LSTMベースの意味的役割ラベラーであり、2つの補助的なタスクで共同トレーニングされています。1つの単語の依存関係ラベルを予測し、それを述語に結びつけるアークが存在するかどうかです。補助タスクは、セマンティックロールラベルに固有の構文情報を提供し、既存の依存関係構文解析器に依存することなく、トレーニングデータ（依存関係注釈）から学習され、これはノイズ（例えば、ドメイン外データまたは頻繁ではない構文）となり得る。CoNLL -2009ベンチマークデータセットの実験結果は、当社のモデルが英語の最先端を上回り、中国語、ドイツ語、スペイン語を含む他の言語のパフォーマンスを一貫して向上させていることを示しています。', 'hi': 'इस पेपर में हम एक बाहरी पार्सर का सहारा लिए बिना शब्दार्थ भूमिका लेबलिंग के लिए निर्भरता जागरूक अभ्यावेदन सीखने पर ध्यान केंद्रित करते हैं। हमारे मॉडल की रीढ़ एक LSTM-आधारित शब्दार्थ भूमिका लेबलर है जो संयुक्त रूप से दो सहायक कार्यों के साथ प्रशिक्षित है: एक शब्द के निर्भरता लेबल की भविष्यवाणी करना और क्या इसे विधेय से जोड़ने वाला एक चाप मौजूद है। सहायक कार्य वाक्यात्मक जानकारी प्रदान करते हैं जो शब्दार्थ भूमिका लेबलिंग के लिए विशिष्ट है और मौजूदा निर्भरता पार्सर पर भरोसा किए बिना प्रशिक्षण डेटा (निर्भरता एनोटेशन) से सीखा जाता है, जो शोर हो सकता है (उदाहरण के लिए, आउट-ऑफ-डोमेन डेटा या अक्सर निर्माणों पर)। CoNLL-2009 बेंचमार्क डेटासेट पर प्रयोगात्मक परिणाम बताते हैं कि हमारा मॉडल अंग्रेजी में कला की स्थिति को मात देता है, और चीनी, जर्मन और स्पेनिश सहित अन्य भाषाओं में लगातार प्रदर्शन में सुधार करता है।', 'zh': '其在本文,专注于学语义角色标签者赖感知,而无诉诸外解析器。 吾道一于LSTM之语义角,二佐而教之:占单词者恃其链接于谓词之弧。 佐命供特定于语义角之语法,而习数于数(恃注)之学,而不恃于今之恃解析器,此解析器或嘈杂之(,域外数不烦之)也。 CoNLL-2009 准数集之实验结果表明,吾形于英语,优于今术,续增他语(兼中文、德语、西班牙语)之性。', 'ru': 'В этой статье мы сосредоточимся на изучении представлений, основанных на зависимости, для обозначения семантических ролей без обращения к внешнему парсеру. Основой нашей модели является основанный на LSTM семантический ролевой маркер, обученный совместно с двумя вспомогательными задачами: предсказание метки зависимости слова и наличие дуги, связывающей его с предикатом. Вспомогательные задачи предоставляют синтаксическую информацию, которая специфична для обозначения семантических ролей и извлекается из обучающих данных (аннотации зависимостей), не полагаясь на существующие парсеры зависимостей, которые могут быть шумными (например, на внедоменные данные или нечастые конструкции). Экспериментальные результаты по базовому набору данных CoNLL-2009 показывают, что наша модель превосходит современный английский язык и постоянно улучшает производительность на других языках, включая китайский, немецкий и испанский.', 'ga': 'Sa pháipéar seo dírímid ar léiriú atá feasach ar spleáchas a fhoghlaim le haghaidh lipéadú róil shéimeantach gan dul i muinín parsálaí seachtrach. Is é cnámh droma ár múnla ná lipéadóir róil shéimeantach bunaithe ar LSTM atá comh-oilte le dhá thasc chúnta: lipéad spleáchais an fhocail a thuar agus an bhfuil stua ann a nascann é leis an tuar. Soláthraíonn na tascanna cúnta faisnéis chomhréire a bhaineann go sonrach le lipéadú ról shéimeantach agus a fhoghlaimítear ó shonraí oiliúna (nótaí spleáchais) gan a bheith ag brath ar pharsálaithe spleáchais atá ann cheana féin, ar féidir leo a bheith torannach (m.sh., ar shonraí lasmuigh den fhearann nó ar thógálacha neamhchoitianta). Léiríonn torthaí turgnamhacha ar thacar sonraí tagarmharcála CoNLL-2009 go sáraíonn ár múnla an úrscothacht i mBéarla, agus go bhfeabhsaítear feidhmíocht i dteangacha eile go seasta, lena n-áirítear an tSínis, an Ghearmáinis agus an Spáinnis.', 'ka': 'ამ დომენტში ჩვენ განვიცემულებთ განსაკუთრებულობაზე გამოცემულებული რესპეცენტაციებისთვის სიმენტიკური პროლის ლაბელიერებისთვის, გარეშე გარეშე პა ჩვენი მოდელის ბეჭდვილი არის LSTM-ის სენმანტიკური პროლის ლებლიერი, რომელიც ორი დახმარებული დავალებით განაკეთებულია: სიტყვის დასამხმარებელობის ლებლიერი დაწყვება და თუ არა არსებობს ბეჭდვის პროლი დახმარებული დავალებები სინტექტიკური ინფორმაცია, რომელიც სემონტიკური პროლის მართლაზე სპექტიკურია და სწავლებიან ინფორმაციის მონაცემებისგან (დამხმარებული ინფორმაციები) განმავლობაში, რომელიც შეიძლება იყოს სინტაქტიკური ინფ ექსპერიმენტიური შედეგები CoNLL-2009 ბენქმარკური მონაცემების შესახებ ჩვენი მოდელი ინგლისურად გავაკეთება და სხვა ენების შესახებ უფრო მეტადება, რომელიც ჩინეთი, გერმანეთი და სპან', 'el': 'Σε αυτή την εργασία εστιάζουμε στις αναπαραστάσεις που έχουν επίγνωση της μαθησιακής εξάρτησης για τη σημασιολογική σήμανση ρόλων χωρίς προσφυγή σε έναν εξωτερικό αναλυτή. Η ραχοκοκαλιά του μοντέλου μας είναι ένας σημασιολογικός μαρκαριστής ρόλων βασισμένος σε LSTM από κοινού εκπαιδευμένος με δύο βοηθητικές εργασίες: την πρόβλεψη της ετικέτας εξάρτησης μιας λέξης και το αν υπάρχει τόξο που την συνδέει με το predicate. Οι βοηθητικές εργασίες παρέχουν συντακτικές πληροφορίες που είναι συγκεκριμένες για τη σημασιολογική σήμανση ρόλων και μαθαίνονται από δεδομένα κατάρτισης (σχόλια εξάρτησης) χωρίς να βασίζονται σε υπάρχοντες αναλυτές εξάρτησης, οι οποίοι μπορεί να είναι θορυβώδεις (π.χ. σε δεδομένα εκτός τομέα ή σπάνιες κατασκευές). Τα πειραματικά αποτελέσματα στο σύνολο δεδομένων αναφοράς δείχνουν ότι το μοντέλο μας ξεπερνά την κατάσταση της τεχνολογίας στα αγγλικά και βελτιώνει σταθερά την απόδοση σε άλλες γλώσσες, συμπεριλαμβανομένων των κινεζικών, γερμανικών και ισπανικών.', 'hu': 'Ebben a tanulmányban a függőségtudatos reprezentációk tanulására összpontosítunk külső elemző nélkül. Modellünk gerincét egy LSTM alapú szemantikai szerepkör-címkéző két kiegészítő feladat képezi: egy szó függőségi címkéjének előrejelzése és létezik-e ív, amely összeköti a predikátumot. A kiegészítő feladatok olyan szintaktikus információkat nyújtanak, amelyek a szemantikai szerepkörcímkézésre vonatkoznak, és a képzési adatokból (függőségi jegyzetek) tanulhatnak anélkül, hogy a meglévő függőségi elemzőkre támaszkodnának, amelyek zajosak lehetnek (pl. tartományonkívüli adatok vagy ritka konstrukciók). A CoNLL-2009 benchmark adatkészlet kísérleti eredményei azt mutatják, hogy modellünk felülmúlja az angol nyelvű legkorszerűbb teljesítményt, és következetesen javítja a teljesítményt más nyelveken, beleértve a kínai, német és spanyol nyelveken.', 'it': "In questo articolo ci concentriamo sull'apprendimento delle rappresentazioni consapevoli della dipendenza per l'etichettatura semantica dei ruoli senza ricorrere a un parser esterno. La spina dorsale del nostro modello è un etichettatore di ruolo semantico basato su LSTM formato congiuntamente con due compiti ausiliari: predire l'etichetta di dipendenza di una parola e se esiste un arco che la collega al predicato. Le attività ausiliarie forniscono informazioni sintattiche specifiche per l'etichettatura semantica dei ruoli e vengono apprese dai dati di formazione (annotazioni di dipendenza) senza affidarsi ai parser di dipendenza esistenti, che possono essere rumorosi (ad esempio, su dati fuori dominio o costruzioni rare). I risultati sperimentali sul set di dati di riferimento CoNLL-2009 mostrano che il nostro modello supera lo stato dell'arte in inglese e migliora costantemente le prestazioni in altre lingue, tra cui cinese, tedesco e spagnolo.", 'kk': 'Бұл қағазда, сыртқы талдаушыларға қайта келтірілмеген семантикалық роль жарлығының тәуелсіздігін оқытуға көмектесеміз. Біздің моделіміздің көмектесу жарлығы - LSTM негіздеген семантикалық роль жарлығы, екі көмектесу тапсырмаларымен біріктірілген: сөздің тәуелсіздік жарлығын алдын- алап көру және оны предицикалықта сілтемелеу Көмектесу тапсырмалары семантикалық роль жарлығына белгіленген синтактикалық мәлімет береді және бақылау деректерінен (тәуелсіздік жарлықтар) бірге тәуелсіздік талдаушыларға сенім бермейді, олар дыбыс болуы мүмкін (мысалы, домендық CoNLL- 2009 банк деректер жиынының эксперименталдық нәтижелері біздің моделіміз ағылшын тіліндегі суреттің күйін жасап, басқа тілдерде, қытайлық, неміс және испан тілдерінде жұмыс істейді.', 'mk': 'Во овој документ се фокусираме на учењето на зависноста свесни претставувања за семантичното означување на улогата без користење на надворешен анализатор. Работата на нашиот модел е семантичен означувач на улога базиран на LSTM обучен заедно со две помошни задачи: предвидување на означувањето на зависноста на збор и дали постои арк кој го поврзува со предикатот. Помошните задачи обезбедуваат синтактички информации кои се специфични за семантичното означување на улогата и се научуваат од обуката на податоците (анотации за зависност) без да се потпираат на постојните анализатори за зависност, кои можат да бидат бучни (np., на податоци надвор од доменот или нечесто конструкции). Експерименталните резултати на базата на податоци CoNLL-2009 покажуваат дека нашиот модел ја надминува најсовремената технологија на англиски јазик и постојано ја подобрува резултатот на други јазици, вклучително и на кинески, германски и шпански јазик.', 'ms': 'Dalam kertas ini, kita fokus pada pembelajaran dependensi perwakilan yang sedar untuk label peranan semantik tanpa menggunakan penghurai luaran. Tulang belakang model kita adalah label peranan semantik berdasarkan LSTM dilatih bersama dengan dua tugas bantuan: meramalkan label dependensi perkataan dan sama ada ada lengkung yang menghubungkannya dengan predikat. Tugas bantuan menyediakan maklumat sintaktik yang spesifik untuk label peranan semantik dan belajar dari data latihan (anotasi dependensi) tanpa bergantung pada penghurai dependensi yang wujud, yang boleh menjadi bunyi (cth., pada data luar domain atau konstruksi jarang). Keputusan percubaan pada set data benchmark CoNLL-2009 menunjukkan bahawa model kita melampaui kemajuan dalam bahasa Inggeris, dan secara konsisten meningkatkan prestasi dalam bahasa lain, termasuk bahasa Cina, Jerman, dan Sepanyol.', 'ml': 'In this paper we focus on learning dependency aware representations for semantic role labeling without recourse to an external parser.  നമ്മുടെ മോഡലിന്റെ പിന്നോട്ട് ബാക്ക്ബോണ്\u200d ഒരു LSTM-അടിസ്ഥാനമായ സെമാന്റിക്ക് റോള്\u200d ലേബര്\u200d ആണ്. രണ്ടു കൂട്ടിചേര്\u200dന്ന ജോലികളുമായി പഠിപ്പിച്ചത്: ഒരു വ അധികാരികമായ ജോലികള്\u200d സെമാന്റിക്ക് റോള്\u200d ലേബിള്\u200d ചെയ്യുന്നതിന് വിശിഷ്ടമായ വിവരങ്ങള്\u200d നല്\u200dകുന്നു. പരിശീലനത്തില്\u200d നിന്നും പഠിക്കുന്നതില്\u200d നിന്നും നിലവിലുള്ള ആശ്രയിക്കുന കോണ്\u200dഎല്\u200d- 2009 ബെങ്ക്മാര്\u200dക്ക് ഡാറ്റാസെറ്റിന്റെ പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു ഞങ്ങളുടെ മോഡല്\u200d ഇംഗ്ലീഷിലെ കലാകാര്യ സ്ഥിതിയെ പ', 'lt': 'Šiame dokumente daugiausia dėmesio skiriame mokymosi priklausomybės sąmoningam atstovavimui semantinio vaidmens ženklinimui be išorinio analizatoriaus. Mūsų modelio nugaros kaulas yra LSTM pagrįstas semantinis vaidmens žymeklis, bendrai apmokytas su dviem pagalbinėmis užduotimis: numatomas žodžio priklausomybės žymeklis ir ar egzistuoja lankas, jungiantis jį su predikatu. Pagalbinės užduotys teikia sintaksinę informaciją, kuri yra specifinė semantiniam vaidmens ženklinimui ir kuri mokoma iš mokymo duomenų (priklausomybės anotacijos), nesiremiant esamais priklausomybės analizatoriais, kurie gali būti triukšmingi (pvz., ne srities duomenimis arba nedažnais konstrukcijomis). Experimental results on the CoNLL-2009 benchmark dataset show that our model outperforms the state of the art in English, and consistently improves performance in other languages, including Chinese, German, and Spanish.', 'mn': 'Энэ цаасан дээр бид суралцах хамааралтай байдлыг суралцах нь гадаад ажиллагч дээр дахин дахин хуваалцах боломжгүй суралцах талаар анхаарлаа хандуулдаг. Бидний загварын backbone бол LSTM-д суурилсан semantic role labeler jointly trained with two auxiliary tasks: predicting the dependency label of a word and whether there is an arc linking it to the predicate. Эхлээд тусламжтай ажил нь semantic role labeling-д тодорхой синтактик мэдээллийг өгч, сургалтын мэдээллээс сурсан (хамааралтай байдлын нэр тодорхойлолт) суралцаж байгаа хамааралтай ажиллаачид, чимээгүй байх боломжтой (жишээ нь, холбоотой мэдээллээс эсвэл хамаара CoNLL-2009 оны банклайн өгөгдлийн сангийн туршилтын үр дүнд бидний загвар Англи хэлний урлагийн байдлыг дамжуулж, Хятад, Герман, Испан хэлний оронд өөр хэлний үйл ажиллагааг сайжруулдаг.', 'ro': 'În această lucrare ne concentrăm pe învățarea reprezentărilor conștiente de dependență pentru etichetarea rolurilor semantice fără a apela la un parser extern. Coloana vertebrală a modelului nostru este un etichetator de roluri semantic bazat pe LSTM instruit în comun cu două sarcini auxiliare: predicția etichetei de dependență a unui cuvânt și dacă există un arc care îl leagă de predicat. Sarcinile auxiliare furnizează informații sintactice specifice etichetării rolurilor semantice și sunt învățate din datele de instruire (adnotări de dependență) fără a se baza pe analizoarele de dependență existente, care pot fi zgomotoase (de exemplu, pe date din afara domeniului sau construcții rare). Rezultatele experimentale ale setului de date CoNLL-2009 arată că modelul nostru depășește performanța de ultimă oră în limba engleză și îmbunătățește în mod constant performanța în alte limbi, inclusiv chineză, germană și spaniolă.', 'no': 'I denne papiret fokuserer vi på å lære avhengighetsrepresentasjonar for semantisk rolletiketting utan å gjenoppretta til ein ekstern tolkar. Bakgrunnsbanen i modellen vårt er ein LSTM-basert semantisk rolletikett som er kopla trent med to hjelpeoppgåver: forventar avhengighetsmerkelappen til eit ord og om det finst ein boge som koplar han til predikaten. Hjelpeoppgåvene gjev syntaksisk informasjon som er spesifisert for semantisk rolletiketting og er lært frå opplæringsdata (avhengighetsnotasjonar) utan å rely på eksisterande avhengighetsanalysar, som kan vera støy (f.eks. på uten domenedata eller etterfølgjande konstruksjonar). Eksperimentale resultat på benchmarkdatasettet CoNLL-2009 viser at modellen vårt utfører kunstået på engelsk, og konsekvent forbetrar utviklinga på andre språk, inkludert kinesisk, tysk og spansk.', 'pl': 'W niniejszym artykule skupiamy się na uczeniu się świadomych reprezentacji dla semantycznego oznaczania roli bez użycia zewnętrznego parsera. Kręgosłup naszego modelu jest oparty na LSTM semantyczny oznaczacz roli, który wspólnie przeszkolony jest z dwoma zadaniami pomocniczymi: przewidywaniem etykiety zależności słowa i czy istnieje łuk łączący go z predykatem. Zadania pomocnicze dostarczają informacji składniowych, które są specyficzne dla semantycznego oznaczania roli i są uczone z danych treningowych (adnotacji zależności) bez polegania na istniejących parserach zależności, które mogą być szumowe (np. na danych poza domeną lub rzadkich konstrukcjach). Wyniki eksperymentalne na temat zbioru danych referencyjnych CoNLL-2009 pokazują, że nasz model przewyższa najnowocześniejszą technologię w języku angielskim i konsekwentnie poprawia wydajność w innych językach, w tym chińskim, niemieckim i hiszpańskim.', 'mt': 'F’dan id-dokument niffokaw fuq rappreżentazzjonijiet konxji mid-dipendenza fuq it-tagħlim għat-tikkettar tar-rwol semantiku mingħajr rikors għal analizzatur estern. Is-sinsla tad-dahar tal-mudell tagħna hija tikketta tar-rwol semantiku bbażata fuq LSTM imħarrġa b’mod konġunt ma’ żewġ kompiti awżiljarji: it-tbassir tat-tikketta tad-dipendenza ta’ kelma u jekk jeżistix ark li jgħaqqadha mal-predikat. Il-kompiti awżiljarji jipprovdu informazzjoni sinrattika li hija speċifika g ħat-tikkettar tar-rwol semantiku u titgħallem mid-dejta tat-taħriġ (annotazzjonijiet tad-dipendenza) mingħajr ma jiddependu fuq analizzaturi tad-dipendenza e żistenti, li jistgħu jkunu storbjużi (eż., fuq dejta barra d-dominju jew kostruzzjonijiet mhux frekwenti). Riżultati esperimentali dwar is-sett ta’ dejta ta’ referenza CoNLL-2009 juru li l-mudell tagħna huwa l-aktar avvanzat fl-Ingliż, u b’mod konsistenti jtejjeb il-prestazzjoni f’lingwi oħra, inklużi ċ-Ċiniż, il-Ġermaniż u l-Ispanjol.', 'sr': 'U ovom papiru fokusiramo se na znanje zavisnosti svesti predstavljanja semantičke uloge bez preusmjerenja prema vanjskom analizatoru. Vrh našeg model a je semantički etiketer osnovan na LSTM-u zajedno obučen sa dve pomoćne zadatke: predviđanje etikete zavisnosti riječi i postoji li ga konja povezana sa predikatom. Pomoćni zadatak pružaju sintaktične informacije koje su specifične za etiketiranje semantičkih uloga i uče se od podataka obuke (annotacije zavisnosti) bez oslanjanja na postojeće parsere zavisnosti, koje mogu biti buksne (npr. na podatke o izvan domena ili sledeće konstrukcije). Eksperimentalni rezultati na setu podataka o benchmarku CoNLL-2009 pokazuju da naš model iznosi stanje umjetnosti na engleskom jeziku i stalno poboljšava izvođenje na drugim jezicima, uključujući kineske, nemačke i španjolske.', 'si': 'මේ පත්තරේ අපි ඉගෙන ගන්න අවශ්\u200dයතාවක් දැනගෙන ඉගෙන ගන්න පුළුවන් විදිහට සෙමැන්ටික් භාවිතාවක් ලේබි අපේ මොඩල් එකේ පස්සේ බැක්බෝන් තමයි LSTM-අධාරිත සැමැන්තික භාවිත ලේබෝර් එක්ක සම්බන්ධ වෙන්න පුළුවන් වෙන්නේ: වචනයේ අවශ්\u200dයතාවක් ල උදව් වැඩක් සෙමැන්ටික් භාවිතාවක් ලේබිල් වලට විශේෂ තොරතුරු දෙන්න පුළුවන් සහ සෙමාන්ටික් භාවිතාවක් ලේබිල් වලට සඳහා ප්\u200dරශ්නයක් දත්ත (අවශ්\u200dයතා CoNLL-2009 බෙන්ච්මාර්ක් දත්ත සෙට් එකේ පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ මොඩල් ඉංග්\u200dරීසියේ ඉංග්\u200dරීසියේ ඉංග්\u200dරී', 'so': 'Qoraalkan waxaynu ku kalsoonaynaa barashada ku xiran ee aqoonta ku saabsan qofka kalebta ah ee lagu baaraandegayo cilmiga dibadda ah. Tilmaankayaga dhabta ah waa labeexad qayb ah oo ku saleysan LSTM, taasoo lagu wada tababaray labo shaqo la xiriira: ka sii daabaco calaamadda ku xiran ee ereyga iyo in ay jiraan arc ku xiriira uu ku xiriiro predictiga. Shaqooyinka la xiriira waxay bixiyaan macluumaad la xiriira, kaas oo si gaar ah loo qorayo qayb semantik ah, oo laga barto macluumaadka waxbarashada (faa’iido ku xiriira xiriirka ku xiran) iyadoon ku kalsoonayn baarlamayaasha ay ku xiran tahay, taas oo cod u noqon kara (tusaale ahaan macluumaadka aan ka baxsaneyn ama dhismaha dib u socda). Imtixaanka ku saabsan kooNLL-2009 taariikhda bangiga waxay muujiyaan in modelkayagu ka muuqata xaaladda farshaxanka ingiriisiga, sidoo kalena wuu beddelaa muuqashada afka kale, kuwaas oo ah Shiino, Jarmal iyo Isbanish.', 'ta': 'இந்த காகிதத்தில் நாம் கற்றுக் கொள்ளும் சார்ந்த படிப்புகளை அறிந்து கொள்ளும் சார்ந்து கொள்ளும் பொருட்களை புரட எங்கள் மாதிரியின் பின்னோக்கு ஒரு LSTM-அடிப்படையிலுள்ள பாமான்டிக் பங்கு குறிப்பாகும் இரண்டு கூட்டுதல் பணிகளுடன் ஒன்றாக பயிற்சி செய்யப்பட்டுள்ளது: ஒர கூடுதல் செயல்கள் ஒருங்கிணைப்பு தகவல்களை வழங்குகிறது அது பெமான்டிக் விளையாட்டிற்கு குறிப்பிட்ட மற்றும் பயிற்சி தகவலிலிருந்து கற்றுக் கொள்ளப்படுகிறது (சார்ந்த சார்பு  கோஎன்எல்- 2009 பென்க்மார்க் தரவுத்தளத்தின் சோதனையின் முடிவுகள் காட்டுகிறது எங்கள் மாதிரி ஆங்கிலத்தில் கலைஞர் நிலையை வெளியேற்றுகிறது மற்றும் ம', 'sv': 'I denna uppsats fokuserar vi på att lära beroendemedvetna representationer för semantisk rollmärkning utan att använda en extern parser. Ryggraden i vår modell är en LSTM-baserad semantisk rollmärkning som utbildas gemensamt med två hjälpuppgifter: förutsäga beroendeetiketten för ett ord och om det finns en båge som länkar det till predikatet. Hjälpuppgifterna ger syntaktisk information som är specifik för semantisk rollmärkning och lärs från utbildningsdata (beroendeanteckningar) utan att förlita sig på befintliga beroendetolkare, vilket kan vara bullriga (t.ex. data utanför domänen eller ovanliga konstruktioner). Experimentella resultat på CoNLL-2009 benchmark datauppsättningen visar att vår modell överträffar den senaste tekniken på engelska och konsekvent förbättrar prestandan på andra språk, inklusive kinesiska, tyska och spanska.', 'ur': 'اس کاغذ میں ہم ایک خارجی پارچر کے بغیر کسی کو دوباره حاصل کرنے کے لئے سیمنٹی رول لابلینگ کے معاملہ کی تعلیم کی تعلیم کے ذریعہ منتظر ہیں. ہمارے موڈل کی پشت ہڈی ایک LSTM-based semantic role labeler ہے جو دو مددگار کاموں کے ساتھ آموزش کی جاتی ہے: ایک لفظ کے اعتباری لابل کی پیش بینی کرتی ہے اور کیا اسے پیش بینی کے ساتھ ایک چوپ ہے یا کوئی چوپ ہے۔ مددگار تاسکیوں نے سینٹکتیک معلومات پیدا کی ہے جو سیمنٹی رول لیبلینگ کے لئے مخصوص ہے اور ان کی آموزش دادہ سے (اعتباری یادہانی) سکھائی جاتی ہیں بغیر اس کے کہ موجود اعتباری پارسر پر اعتماد کرتی ہیں، جو آواز ہو سکتی ہے CoNLL-2009 بنچم مارک ڈاٹ سٹ پر تجربہ کا نتیجہ دکھاتا ہے کہ ہمارا مدل انگلیسی میں آرتی کی حالت سے زیادہ اضافہ کرتا ہے اور دوسری زبانوں میں عملکرد بہتر کرتا ہے، جیسے چین، جرمن اور اسپانیایی میں۔', 'vi': 'Trong tờ giấy này chúng tôi tập trung vào các biểu tượng dựa vào việc nắm giữ các vai trò theo ngữ nghĩa mà không cần phải dùng tới phân tích ngoại giao. The backbone of our model is a LSTM-based semantics role labrer together educated with two phụ tá jobs: dự đoán the dependence Nhãn of a word and whether there exists a làu kết nối nó với the Đặt. Các công việc phụ hỗ trợ cung cấp thông tin cú pháp cụ thể cho việc mô phỏng các vai trò theo ngữ pháp và được học hỏi từ dữ liệu huấn luyện (ghi chú phụ thuộc) mà không dựa vào các phân tích phụ thuộc, có thể ồn ào (v.d. trên dữ liệu ngoại ngữ hay những công trình trình hiếm hoi). Kết quả thí nghiệm trên tập tin tiêu chuẩn Colt-2009 cho thấy rằng mô hình của chúng ta hoàn thiện trạng thái nghệ thuật bằng tiếng Anh, và luôn cải thiện hiệu suất tại các ngôn ngữ khác, kể cả Trung Quốc, Đức và Tây Ban Nha.', 'uz': "Bu qogʻozda biz tashqi parametrlarni o'rganishga qo'shish uchun qo'llanmiz. Modemizning backboni - LSTM asosida semantik role labeler - ikkita xil vazifalar bilan birlashtirilgan bir xil vazifalar bilan o'rganish: so'zning ishlatuvchi yorligini oldinga va uni predikt bilan bogʻlash mumkin. Tashkilot vazifalari semantik role lab chiqarish uchun muhim maʼlumot beradi va maʼlumot maʼlumotidan o'rganadi. Mavjud tashkilotni ishlatmaydigan tashqaruvchilarga ishlatilmaydi. Masalan, domen maʼlumotdan bajariladigan amalga oshirish mumkin. KoNLL-2009 benchmark maʼlumotlari haqida tajriba natijalari esa modelimiz ingliz tilidagi sanatlarning holatini bajaradi va hamma tillardan xitoycha, Olmon va Ispanchadan iborat boshqa tillarda bajarish natijasini bajaradi.", 'bg': 'В тази статия се фокусираме върху представянето на зависимостта от ученето за семантично етикетиране на роли без прибягване до външен анализатор. Гръбнакът на нашия модел е базиран на семантичен ролеви етикет, обучен съвместно с две спомагателни задачи: предсказване на етикета на зависимост на дадена дума и дали съществува дъга, свързваща я с предиката. Помощните задачи предоставят синтактична информация, която е специфична за семантичното етикетиране на ролите и се научава от тренировъчни данни (анотации на зависимост), без да се разчита на съществуващи анализатори на зависимост, които могат да бъдат шумни (напр. на данни извън домейна или редки конструкции). Експерименталните резултати от сравнителния набор от данни показват, че нашият модел превъзхожда най-съвременните постижения на английски език и постоянно подобрява производителността на други езици, включително китайски, немски и испански.', 'hr': 'U ovom papiru usredotočili smo se na znanje ovisnosti svesti predstavljanja semantičke uloge bez preusmjerenja vanjskom analizatoru. Kost našeg model a je semantički etiketer osnovan na LSTM-u zajedno obučen s dvije pomoćne zadatke: predviđanje oznake zavisnosti riječi i postoji li ga konja povezujući s predikatom. Pomoćni zadatak pružaju sintaktične informacije koje su specifične za etiketiranje semantičkih uloga i uče se od podataka obuke (izjave o zavisnosti) bez oslanjanja na postojeće parsere zavisnosti, koje mogu biti bučne (npr. na podaci o izvan domena ili navedene konstrukcije). Eksperimentalni rezultati u skupini podataka o referenciji CoNLL-2009 pokazuju da naš model nadmašuje stanje umjetnosti na engleskom jeziku i konsekventno poboljšava učinkovitost na drugim jezicima, uključujući kineske, njemačke i španjolske.', 'de': 'In diesem Beitrag konzentrieren wir uns auf lernabhﾃ､ngigkeitsbewusste Reprﾃ､sentationen fﾃｼr semantische Rollenbeschriftung ohne Rﾃｼckgriff auf einen externen Parser. Das Rﾃｼckgrat unseres Modells ist ein LSTM-basierter semantischer Rollenmarkierer, der gemeinsam mit zwei Hilfsaufgaben trainiert wurde: die Vorhersage der Abhﾃ､ngigkeitslabel eines Wortes und ob es einen Bogen gibt, der es mit dem Prﾃ､dikat verbindet. Die Hilfsaufgaben liefern syntaktische Informationen, die spezifisch fﾃｼr die semantische Rollenbeschriftung sind und aus Trainingsdaten (Abhﾃ､ngigkeitsanotationen) gelernt werden, ohne sich auf vorhandene Abhﾃ､ngigkeitsparser zu verlassen, die verrauscht sein kﾃｶnnen (z.B. auf Out-of-Domain-Daten oder seltene Konstruktionen). Experimentelle Ergebnisse des CoNLL-2009 Benchmark-Datensatzes zeigen, dass unser Modell den Stand der Technik in Englisch ﾃｼbertrifft und die Leistung in anderen Sprachen, einschlieﾃ殕ich Chinesisch, Deutsch und Spanisch, kontinuierlich verbessert.', 'nl': 'In dit artikel richten we ons op leerafhankelijkheidsbewuste representaties voor semantische rollabeling zonder gebruik te maken van een externe parser. De ruggengraat van ons model is een LSTM-gebaseerde semantische rollabeler die gezamenlijk getraind is met twee hulptaken: het voorspellen van het afhankelijkheidslabel van een woord en of er een boog bestaat die het koppelt aan het predicaat. De hulptaken bieden syntactische informatie die specifiek is voor semantische rollabeling en worden geleerd van trainingsgegevens (afhankelijkheidsannotaties) zonder te vertrouwen op bestaande afhankelijkheidsparsers, die lawaaierig kunnen zijn (bijvoorbeeld op out-of-domain data of zeldzame constructies). Experimentele resultaten op de CoNLL-2009 benchmark dataset tonen aan dat ons model beter presteert dan de state of the art in het Engels en consistent de prestaties verbetert in andere talen, waaronder Chinees, Duits en Spaans.', 'da': 'I denne artikel fokuserer vi på at lære afhængighedsbevidste repræsentationer for semantisk rollemærkning uden brug af en ekstern fortolker. Rygraden i vores model er en LSTM-baseret semantisk rollemærkning uddannet i fællesskab med to hjælpeopgaver: at forudsige afhængighedsmærkningen af et ord, og om der findes en bue, der forbinder det til prædikatet. Hjælpeopgaverne giver syntaktiske oplysninger, der er specifikke for semantisk rollemærkning og læres af træningsdata (afhængighedsannotationer) uden at stole på eksisterende afhængighedsfortolkere, som kan være støjende (f.eks. på data uden for domænet eller sjældne konstruktioner). Eksperimentelle resultater på CoNLL-2009 benchmark datasættet viser, at vores model overgår den nyeste teknologi på engelsk og konsekvent forbedrer ydeevnen på andre sprog, herunder kinesisk, tysk og spansk.', 'fa': 'در این کاغذ ما تمرکز می کنیم روی تعلیم بستگی آگاهی از نمایش های آگاهی برای نمایش نقش semantic بدون بازرسی به یک بازرسی خارجی. استخوان مدل ما یک برچسب نقش semantic based on LSTM با دو کار کمک آموزش داده شده است: پیش بینی کردن نقشه بستگی یک کلمه و آیا یک برچسب وجود دارد که آن را به پیش بینی می کند. وظیفه\u200cهای کمک اطلاعات سنتاکتیک را می\u200cدهند که برای برچسب نقشه\u200cهای سنتاکتیک خاص است و از داده\u200cهای آموزش (اظهار اعتماد) بدون اعتماد به برچسب\u200cهای بستگی موجود می\u200cباشند، که می\u200cتوانند صدا باشند (مثال، در داده\u200cهای خارج از دامنه یا ساختار غیر از دامنه\u200cها). نتیجه\u200cهای تجربه روی مجموعه داده\u200cهای سنجیر CoNLL-2009 نشان می\u200cدهد که مدل ما وضعیت هنری به انگلیسی را بیشتر انجام می\u200cدهد، و همیشه عملکرد در زبانهای دیگر، شامل چینی، آلمانی و اسپانیایی، بهتر می\u200cشود.', 'sw': 'Katika gazeti hili tunajikita kwenye kujifunza kutegemea hadhira ya kuelezea maoni kwa ajili ya jukumu la kimapenzi bila kuingia tena kwa mchanganyiko wa nje. Mifuko ya muundo wetu ni mchezo wa jukumu la kimapenzi anayeishi LSTM umefundishwa pamoja na kazi mbili za ushirikiano: kutabiri alama ya kutegemea neno na kama kuna arc inayounganisha na utabiri. Kazi za ushirikiano zinatoa taarifa za ushirikiano ambazo ni maalum kwa jukumu la kimapenzi na wanajifunza kutokana na taarifa za mafunzo (matangazo ya kutegemea kutegemea) bila kutegemea mabunge ya kutegemea, ambayo inaweza kuwa na kelele (kwa mfano juu ya takwimu za ndani au majengo yanayotokea). Matokeo ya majaribio kwenye taarifa za bendera za CoNLL-2009 yanaonyesha kuwa modeli yetu inaonyesha hali ya sanaa ya Kiingereza, na kwa kawaida inaboresha ufanisi wa lugha nyingine, ikiwa ni pamoja na Kichina, Kijerumani na Kihispania.', 'id': 'In this paper we focus on learning dependency aware representations for semantic role labeling without recourse to an external parser.  Tulang belakang model kita adalah sebuah label peran semantis berdasarkan LSTM terlatih bersama dengan dua tugas bantuan: memprediksi label dependensi dari kata dan apakah ada lengkung yang menghubungkannya dengan predikat. Tugas bantuan menyediakan informasi sintaks yang spesifik untuk label peran semantis dan dipelajari dari data pelatihan (anotasi dependensi) tanpa bergantung pada parser dependensi yang ada, yang dapat berbunyi (misalnya pada data luar domain atau konstruksi tidak sering). Hasil eksperimental pada set data benchmark CoNLL-2009 menunjukkan bahwa model kita melebihi state of the art dalam bahasa Inggris, dan secara konsisten meningkatkan prestasi dalam bahasa lain, termasuk bahasa Cina, Jerman, dan Spanyol.', 'ko': '본고에서 우리는 외부 해석기에 의존하지 않는 상황에서 의미 역할 표기의 의존 감지 표현을 배우는 데 중심을 두었다.우리 모델의 핵심은 LSTM의 의미 역할 표시기를 바탕으로 두 가지 보조 임무와 연합하여 훈련하는 것이다. 단어의 의존성 라벨과 술어에 연결된 호가 존재하는지 예측하는 것이다.보조 임무는 의미 역할 표시에 특정한 문법 정보를 제공하고 훈련 데이터(의존항 주석)에서 배운다. 기존의 의존항 해석기에 의존하지 않고 이런 해석기는 소음(예를 들어 역외 데이터나 빈번하지 않은 구조상)이 있을 수 있다.CoNLL-2009 기준 데이터 세트에서의 실험 결과에 따르면 우리의 모델은 영어에서 최신 수준보다 우수하고 다른 언어(중국어, 독일어, 스페인어 포함)에서도 지속적으로 향상되었다.', 'tr': 'Bu kagyzda semantik rol etiketlemesi üçin baglanylyk öwrenmek üçin daşaryk tansçysyny üçin üns berýäris. Biziň modelimiz LSTM tabanly semantik rol etiketleridir. iki kömek işi bilen birlikte eğlenen: bir sözüň bağlygynyň etiketini öňden geçirmek we ony öňden uzaklaşdyrmak üçin bir bagly etiketleridir. Ýardamçy g örenler semantik rol etiketlemesine takyk edilen syntaktik maglumatlary bererler we bu maglumatlardan (baglançlyk sözlerinden) bar baglanyşyk parseylere ynamly bolup bilerler. Olar sesli bolup biler (meselâ, domeniň daşysynda ýa-da netijeli düzenlemelerde). CoNLL', 'sq': 'Në këtë letër ne përqëndrohemi në mësimin e varësisë përfaqësimet e vetëdijshme për etiketën semantike të rolit pa përdorur një analizues të jashtëm. Kostulla e shpinës e model it tonë është një etiketës semantike me bazë në LSTM të trajnuar së bashku me dy detyra ndihmëse: parashikimi i etiketës së varësisë së një fjale dhe nëse ekziston një ark që e lidh atë me predikatën. Detyrat ndihmëse ofrojnë informacion sintaktik që është specifik për etiketën semantike të rolit dhe mësohen nga trajnimi i të dhënave (anotacionet e varësisë) pa u mbështetur në analizuesit ekzistues të varësisë, të cilat mund të jenë zhurmë (për shembull, në të dhënat jashtë domenit apo ndërtimet e pakufakta). Rezultatet eksperimentale në bazën e të dhënave të CoNLL-2009 tregojnë se modeli ynë mbizotëron gjendjen e artit në anglisht dhe përmirëson vazhdimisht shfaqjen në gjuhë të tjera, duke përfshirë kinezën, gjermaninë dhe spanjollin.', 'am': 'በዚህ ፕሮግራም የውጭ ተቃዋሚውን ለማምጣት የስሜኒካዊ ተግባር ማሳየትን እናሳውቃለን፡፡ የሞዴላያችን ጀርባ (LSTM) የተመሳሳይ የስራ ሥራ ሁለት ተማሪ የተጠቃሚ የLSTM ተማሪ ነው፤ የቃላችን የታመነ ምልክት እና ለፍጻሜው የሚያስገኘው አርክስ ቢኖር ይኖራል፡፡ የአጠቃላይ ስራዎች ለsemantic role ማሳየት የተለየ እና ከአስተማሪ ዳታ (የታመነች ማስታወቂያ) በተገኘ የአሁኑ የታመነ ፓርራር ሳይታመን እና ድምፅ (ምሳሌ ከውጭ የውጭ ዳታ ወይም ከግንኙነት ግንኙነቶች) የሚችል የሲንቲካካዊ መረጃ ይሰጣቸዋል፡፡ የኮንጆል-2009 የbenchmark ዳርሰት ፈተና ፍሬዎችን በንግግሊዝኛ የዐርላዊ ቋንቋ እና በቻይና፣ ጀርመን እና ስፓኒሽ ቋንቋ ውስጥ የፊደሎችን ፍሬት ያሳድጋል፡፡', 'hy': "Այս թղթի մեջ մենք կենտրոնանում ենք սովորելու կախվածության վրա, գիտակցած սեմանտիկ դերի պիտակում առանց օգտագործելու արտաքին վերլուծողի: Մեր մոդելի ետնամասը LSMT-ով հիմնված սեմանտիկ դերի պիտակ է, որը միասին վարժեցված է երկու օգնական խնդիրներով' բառի կախվածության պիտակ կանխատեսելով, և արդյոք գոյություն ունի մի ամբողջ ամբողջ ամբողջ ամբողջ ամբողջ ամբողջ ամբողջ ամ Օգնական առաջադրանքները տրամադրում են սինտակտիկ տեղեկատվություն, որը հատուկ է սեմանտիկ դերի պիտակումից և սովորվում է կրթության տվյալներից (կախվածության նկարագրություններ), առանց հիմնվելու գոյություն ունեցող կախվածության վերլուծումների վրա, որոնք կարող են աղմկոտ լինել (օրինակ, արտահանրային տվյալների կամ հազ ԿոՆԼ-2009-ի համեմատային տվյալների համակարգի փորձարկման արդյունքները ցույց են տալիս, որ մեր մոդելը գերազանցում է արվեստի լավագույնը անգլերենում և մշտապես բարելավում է արվեստը այլ լեզուներում, ներառյալ չինական, գերմանացի և իսպաներեն", 'az': 'Bu kağızda, semantik rol etiketlərinin bağımlılıqlarını öyrənməyə başlayırıq, daxil bir parçacıya geri dönmədən. Modelimizin arxa sümükləri LSTM tabanlı semantik rol etiketidir. İki kömək işi ilə birlikdə təhsil edilmişdir: bir sözün bağlılığı etiketini təmin edir və ya onu predikatlara bağlayan bir arc var mı? Yardımcıl işlər semantik rol etiketinə müəyyən edilən sintaktik məlumatları təmin edir və mövcuddur bağımlılıq ayırıcılarına g üvən olmadan təhsil verilən məlumatlardan öyrənirlər, bu səslə olar (məsələn, domena verilən və yaxşı inşallardan öyrənirlər). CoNLL-2009 benchmark verilənlərin təcrübələrinin sonuçları göstərir ki, modellərimiz İngilizce sanatın durumunu üstün edir və həmişə digər dillərdə, Çinli, Alman və İspanyolca da istifadə edir.', 'af': "In hierdie papier fokus ons op die leer afhanklikheid waarskynlike voorstellings vir semantiese roletiketting sonder herstelling na 'n eksterne ontleerder. Die backbone van ons model is 'n LSTM-gebaseerde semantiese roletikelaar saamgevoer met twee hulpbron opdragte: voorskou die afhanklikheid etiket van 'n woord en of daar bestaan 'n book wat dit na die predikaat verkoppel het. Die hulpbrukke opdragte verskaf sintaktieke inligting wat spesifieke is vir semantiese roletiketing en word geleer van onderwerp data (afhanklikheidsintaksies) sonder om te vertrou op bestaande afhanklikheidsintaksies, wat kan geluid wees (bv. op buite-domein data of onvolledige konstruksies). Eksperimentale resultate op die CoNLL-2009-benchmarkdatastel vertoon dat ons model die staat van die kuns in Engels uitvoer, en bestuurlik verbeter die prestasie in ander tale, insluitend Sjinees, Duits en Spaanse.", 'bn': 'এই কাগজটিতে আমরা বাইরের প্রতিনিধিত্ব ছাড়া সেমান্টিক ভূমিকা লেবেলের প্রতিনিধিত্ব শিখতে নির্ভর করতে মনোযোগ দিচ্ছি। আমাদের মডেলের ব্যাকবোন হচ্ছে এলস্টিএম ভিত্তিক সেম্পেন্টিক ভূমিকা লেবেলার যুক্ত দুটি সমর্থক কাজের সাথে প্রশিক্ষিত: একটি শব্দের নির্ভর লেবেলের প্রতিযোগিতার কাজ সিন্ট্যাকটিক তথ্য প্রদান করে যা সেম্পেন্টিক ভূমিকা লেবেল করার জন্য বিশেষ তথ্য প্রদান করে এবং প্রশিক্ষণের তথ্য (নির্ভরশীল বিবেচনা) থেকে শিখা হয়েছে বিদ্যমান কএনএল-২০০৯ বেনম্যার্ক ডাটাসেটের পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের মডেল ইংরেজি ভাষায় শিল্পের অবস্থা প্রদর্শন করে এবং অন্যান্য ভাষায় চীনা, জার্মান', 'et': 'Käesolevas töös keskendume õppimise sõltuvuse teadlikele esitustele semantilise rolli märgistamiseks ilma välist parserit kasutamata. Meie mudeli selgroog on LSTM-il põhinev semantiline rollimärgis, mida koolitatakse ühiselt kahe abiülesandega: sõna sõltuvusmärgise prognoosimine ja kas on olemas kaar, mis ühendab selle predikaadiga. Abiülesanded annavad süntaktilist teavet, mis on spetsiifiline semantilise rolli märgistamisele ja mida õpitakse koolitusandmetest (sõltuvuse annotatsioonid), toetumata olemasolevatele sõltuvuspartseritele, mis võivad olla mürakad (nt domeenivälised andmed või harvaesinevad konstruktsioonid). CoNLL-2009 võrdlusandmekogumi eksperimentaalsed tulemused näitavad, et meie mudel ületab inglise keeles tehnika taseme ning parandab pidevalt jõudlust teistes keeltes, sealhulgas hiina, saksa ja hispaania keeles.', 'fi': 'Tässä artikkelissa keskitytään oppimisriippuvuuden tietoisiin representaatioihin semanttisen roolimerkinnän osalta ilman ulkoista jäsentäjää. Mallimme selkäranka on LSTM-pohjainen semanttinen roolitunniste, joka on koulutettu yhdessä kahden aputehtävän kanssa: sanan riippuvuusmerkinnän ennustaminen ja onko olemassa kaari, joka yhdistää sen predikaattiin. Aputehtävät tuottavat syntaktista tietoa, joka on spesifistä semanttiseen roolimerkintään ja joka opitaan harjoitusdatasta (riippuvuusmerkinnät) tukeutumatta olemassa oleviin riippuvuusmerkinnöihin, jotka voivat olla meluisia (esim. toimialueen ulkopuoliseen dataan tai harvinaisiin rakenteisiin). Kokeelliset tulokset CoNLL-2009-vertailuaineistosta osoittavat, että mallimme suoriutuu englannin kielen huipputasosta ja parantaa jatkuvasti suorituskykyä muilla kielillä, kuten kiina, saksa ja espanja.', 'bs': 'U ovom papiru fokusiramo se na predstavljanje svesti zavisnosti učenja semantičke uloge bez preusmjerenja vanjskom analizatoru. Kost našeg model a je semantički etiketer na LSTM-u zajedno obučen sa dvije pomoćne zadatke: predviđanje etikete zavisnosti riječi i postoji li ga koša povezuje sa predikatom. Pomoćni zadatak pružaju sintaktične informacije koje su specifične za etiketiranje semantičkih uloga i uče se od podataka obuke (annotacije zavisnosti) bez oslanjanja na postojeće parsere zavisnosti, koje mogu biti buke (npr. podataka o izvan domena ili neizravne konstrukcije). Eksperimentalni rezultati u skupini podataka o referenciji CoNLL-2009 pokazuju da naš model iznosi stanje umjetnosti na engleskom jeziku i konsekventno poboljšava učinkovitost na drugim jezicima, uključujući kineske, nemačke i španjolske.', 'ca': "En aquest paper ens centrem en representacions conscients de la dependència d'aprenentatge per etiquetar el paper semàntic sense recurrir a un analitzador extern. El cos vertebral del nostre model és un etiquetador de paper semàntic basat en LSTM entrenat conjuntament amb dues tasques auxiliars: predir l'etiqueta de dependencia d'una paraula i si existeix un arc que l'enllaça al predicat. Les tasques auxiliars proporcionen informació sinàctica que és específica per etiquetar el paper semàntic i es aprenen a partir de dades d'entrenament (anotacions de dependencies) sense confiar en els analitzadors de dependencies existents, que poden ser ruidosos (per exemple, en dades fora de domini o construccions poc freqüents). Els resultats experimentals del conjunt de dades de referència CoNLL-2009 mostren que el nostre model supera l'avançat en anglès i millora constantment el rendiment en altres llengües, incloent xinès, alemany i espanyol.", 'cs': 'V tomto článku se zaměřujeme na učení závislosti vědomé reprezentace pro sémantické označování rolí bez použití externího parseru. Páteří našeho modelu je sémantický označovač rolí založený na LSTM společně trénovaný se dvěma pomocnými úkoly: predikcí závislosti značky slova a zda existuje oblouk spojující jej s predikátem. Pomocné úlohy poskytují syntaktické informace specifické pro sémantické označování rolí a jsou učeny z tréninkových dat (anotací závislostí) bez spoléhání na existující analyzávislosti, které mohou být hlučné (např. na mimo doménu data nebo vzácné konstrukce). Experimentální výsledky referenčních dat CoNLL-2009 ukazují, že náš model překonává nejmodernější angličtinu a důsledně zlepšuje výkon v jiných jazycích, včetně čínštiny, němčiny a španělštiny.', 'jv': 'Nang pember iki, kita ngubungke nggawe mesthi luwih akeh njaluk luwih dumateng semantar kelompok kuwi etiket sing ora nggawe ngubah panelusuran. Rasane Help tasks Resulot perangkat langkung nggambar barêng nggambar CoNLL-2007 kuwi model sing nyimpen kanggo ngerasahan kanggo kalem surat kanggo inggiles, lan sumelan dhéwé ngerasahan kanggo ngerasahan langkung urip liyane, tambah pitik, german lan spanyola.', 'he': 'בעיתון הזה אנו מתמקדים ללמוד תלויות מודעות מייצגים לתפקיד סמנטי תווים ללא שימוש בפרסם חיצוני. העצם הגב של המודל שלנו הוא תווית תפקיד סמנטי מבוססת על LSTM מאומנת יחד עם שתי משימות עזריות: לחזות את תווית ההתלויות של מילה ואם קיים קו שמקשר אותה למחזה. המשימות העוזרות מספקות מידע סינטאקטי שמסופק לתיקוי תפקידים סמנטיים ומלמדים מתוך מידע אימון (ציוני תלויות) בלי לסמוך על מחקרי תלויות קיימים, שיכולים להיות רעשים (למשל על מידע מחוץ לתחום או בנויות נדירות). תוצאות ניסויים על קבוצת הנתונים של CoNLL-2009 מראות שהדוגמא שלנו עולה על המצב האמנותי באנגלית, ושתפר באופן קבוע את ההופעה בשפות אחרות, כולל סינית, גרמנית וספרדית.', 'ha': "A cikin wannan takarda, Munã fokus wa karanta masu da inganci wa masu yiwuwa na halartawa wa kima da ake aikatãwar da kuma bã da amfani da wani parser na bakwai. Bagon kwamfyutan ayuka na shirin ayuka, shi ne mai ƙayyade LSM-basin aikin semantiki wanda aka yi shirin da shi a haɗi da aikin biyu masu inganci: Ana yi bayani ga alama ɗin maganar kuma ko akwai wani arc wanda zai haɗa shi da na ƙayyade. Kayan aikin inganci na bãyar da data na syntactic wanda za'a ƙayyade wa kima na semantic mai lissafa kuma an sanar da su daga data na shirin (kunyar zartar da inganci) kuma bã ya dõgara a kan parse masu da ke da inganci, wanda za'a iya sauya (misali, kan bayan-bayan-guda ko da ake samun na-bincike). Jarrabi'ar jarrabãwa na koNLL-2009", 'sk': 'V tem prispevku se osredotočamo na predstavitve, ki se zavedajo učne odvisnosti za semantično označevanje vlog brez uporabe zunanjega razčlenjevalnika. Hrbtenica našega modela je semantični označevalec vlog, ki temelji na LSTM, skupaj usposobljen z dvema pomožnima nalogama: napovedovanjem oznake odvisnosti besede in ali obstaja lok, ki jo povezuje s predikatom. Pomožna opravila zagotavljajo sintaktične informacije, ki so specifične za semantično označevanje vlog in se naučijo iz podatkov o usposabljanju (opombe odvisnosti), ne da bi se zanašali na obstoječe razčlenjevalnike odvisnosti, ki so lahko hrupni (npr. na podatke zunaj domene ali redke konstrukcije). Eksperimentalni rezultati referenčnega nabora podatkov CoNLL-2009 kažejo, da naš model presega najsodobnejše v angleščini in dosledno izboljšuje učinkovitost v drugih jezikih, vključno s kitajščino, nemščino in španščino.', 'bo': 'In this paper we focus on learning dependency representations for semantic role labeling without recourse to an external parser. The backbone of our model is an LSTM-based semantic role labeler jointly trained with two auxiliary tasks: predicting the dependency label of a word and whether there exists an arc linking it to the predicate. The auxiliary tasks provide syntactic information that is specific to semantic role labeling and are learned from training data (dependency annotations) without relying on existing dependency parsers, which can be noisy (e.g., on out-of-domain data or infrequent constructions). CoNLL'}
{'en': 'No Word is an IslandA Transformation Weighting Model for Semantic Composition', 'es': 'Ninguna palabra es una isla: un modelo de ponderación de transformación para la composición semántica', 'pt': 'Nenhuma palavra é uma ilha - um modelo de ponderação de transformação para composição semântica', 'ar': 'لا توجد كلمة جزيرة - نموذج ترجيح التحول للتكوين الدلالي', 'fr': 'No Word is an Island\xa0: un modèle de pondération de transformation pour la composition sémantique', 'hi': 'कोई शब्द एक द्वीप नहीं है - शब्दार्थ रचना के लिए एक परिवर्तन भार मॉडल', 'ja': 'No Wordは、セマンティックコンポジションのためのアイランドA変換重み付けモデルです', 'ru': 'Ни одно слово не является моделью весовых коэффициентов трансформации для семантической композиции', 'zh': '无字者,孤岛——语义之转加权也', 'ga': 'Is Oileán é Gan Fhocal - Samhail Ualaithe Claochlaithe don Chumadóireacht Shéimeantach', 'hu': 'Nincs szó egy sziget-A transzformációs súlyozási modell a szemantikus összetételhez', 'el': 'Καμία λέξη δεν είναι ένα νησί-ένα μοντέλο στάθμισης μετασχηματισμού για τη σημαντική σύνθεση', 'kk': 'Ешбір сөз - Айланда- А түрлендіру үлгісі - Semantic Composition үшін түрлендіру үлгісі', 'mk': 'No Word is an Island-A Transformation Weighting Model for Semantic Composition', 'ms': 'No Word is an Island-A Transformation Weighting Model for Semantic Composition', 'ka': 'არაფერი სიტყვა არ არის სემანტიკური კომპოზიციაციის ტრანფორმაციის განმავლობის მოდელი', 'lt': 'Nė vienas žodis nėra Semantinės sudėties transformacijos koeficiento modelis', 'mn': 'Хэрэг үг нь Semantic Composition-ын Айланд-А өөрчлөлт хэмжээний загвар биш', 'no': 'Ingen ord er eit «Island-A» transformeringsvektsmodell for semiantisk samansetting', 'mt': 'No Word is an Island-A Transformation Weighting Model for Semantic Composition', 'ro': 'Niciun cuvânt nu este un model de ponderare a transformării insulei pentru compoziția semantică', 'it': 'Nessuna parola è un modello di ponderazione della trasformazione Island-A per la composizione semantica', 'ml': 'വാക്ക് ഒന്നുമില്ല സെമാന്റിക് കോമ്പോസിഷനുള്ള ഒരു ദ്വീപ്- A വ്യാപ്റ്റനേഷന്\u200d വൈറ്റിങ്ങ് മോഡ', 'so': 'No word is an island-A Transformation Weighting Model for Semantic Composition', 'pl': 'No Word to wyspa-A model ważenia transformacji dla kompozycji semantycznej', 'ta': 'செமாண்டிக் கூட்டத்திற்கு எந்த வார்த்தையும் ஒரு தீவு- A மாற்றுதல் வாய்ப்பு மாதிரி', 'ur': 'کوئی کلمه ایسا نہیں ہے کہ ایک آیلند-ا ٹرانسافٹ ویٹینگ موڈل سیمنٹی کمپیشن کے لئے ہے', 'sr': 'Nema reči da je model transformacije za semantičku kompoziciju otoka-A', 'sv': 'Inget ord √§r en √∂-en transformationsv√§gningsmodell f√∂r semantisk komposition', 'si': 'කිසිම වචනයක් අයිල්යාන්ඩ් එකක් නැහැ සෙමැන්ටික් සංවිධානය සඳහා වෙනස් විමුණ මොඩල්', 'uz': 'Name', 'vi': 'Không có từ nào là một Mô hình Thay đổi cân bằng bằng trên đảo cho thành phần kỳ diệu', 'bg': 'Нито дума не е модел за претегляне на трансформацията за семантична композиция', 'nl': 'Geen woord is een eiland-A transformatie weegmodel voor semantische compositie', 'da': 'Intet ord er en ø-en transformationsvægtningsmodel for semantisk sammensætning', 'hr': 'Nijedna riječ nije model transformacije za semantičku kompoziciju otoka-A', 'id': 'No Word is an Island-A Transformation Weighting Model for Semantic Composition', 'fa': 'هیچ کلمه یک مدل وزن تغییر اندازهٔ جزیره\u200cای برای ترکیب سیمانتیک نیست', 'sw': 'Hakuna neno ni Mradi wa Mabadiliko ya Kisiwa-A', 'tr': 'Hiç bir söz adaly-A terjime etmek nusgasy', 'de': 'No Word ist ein Island-A Transformation Gewichtungsmodell für semantische Komposition', 'af': "Geen Woord is 'n Eilande- A Transformasie Wegting Model vir Semantiese Komposisie", 'ko': '무사는 고도-어의 구성의 전환 가중 모델이다', 'hy': 'Ոչ մի բառ սեմանտիկ կառուցվածքի փոխակերպման չափման մոդել չէ', 'sq': 'No Word is an Island-A Transformation Weighting Model for Semantic Composition', 'am': 'No Word is an Island-A Transformation Weighting Model for Semantic Composition', 'az': 'Heç bir Söz Semantik Komposisyon üçün Ada-A Transformation Weight Modeli deyildir', 'ca': "cap paraula és un model de peso de transformació de l'illa-A per a la composició semàtica", 'et': 'No Word on saar-A transformatsiooni kaalumise mudel semantilise koostise jaoks', 'fi': 'No Word on saari-A transformaation painotusmalli semanttiselle koostumukselle', 'bn': 'সেম্যান্টিক কম্পোসিশনের জন্য কোন শব্দ নেই দ্বীপ- এ পরিবর্তনের উইটিং  মডেল', 'bs': 'Nijedna riječ nije model transformacije za semantičku kompoziciju otoka-A', 'cs': '탐찼dn챕 slovo je Island-A transforma훾n챠 v찼탑챠c챠 model pro s챕mantickou kompozici', 'jv': 'Ora Kemerdekaan sing isa otor-A Transformation', 'he': 'שום מילה היא מודל משקל איי-איי-איי למערכת סמנטית', 'sk': 'Nobena beseda ni model za tehtanje preobrazbe otoka-A za semantično sestavo', 'ha': '@ item Text character set', 'bo': 'ཡིག་ཆ་ནི་ཆེད་མཉམ་དུ་མཚོན་རྟགས་ལ་འགྱུར་བའི་གཟུགས་རིས་ཅིག་མིན་འདུག'}
{'en': 'Composition models of distributional semantics are used to construct phrase representations from the representations of their words. Composition models are typically situated on two ends of a spectrum. They either have a small number of parameters but compose all phrases in the same way, or they perform word-specific compositions at the cost of a far larger number of parameters. In this paper we propose transformation weighting (TransWeight), a composition model that consistently outperforms existing models on nominal compounds, adjective-noun phrases, and adverb-adjective phrases in English, German, and Dutch. TransWeight drastically reduces the number of parameters needed compared with the best model in the literature by composing similar words in the same way.', 'fr': "Des modèles de composition de sémantique distributionnelle sont utilisés pour construire des représentations de phrases à partir des représentations de leurs mots. Les modèles de composition sont généralement situés aux deux extrémités d'un spectre. Ils ont soit un petit nombre de paramètres mais composent toutes les phrases de la même manière, soit ils réalisent des compositions spécifiques au mot au prix d'un nombre beaucoup plus élevé de paramètres. Dans cet article, nous proposons la pondération de transformation (TransWeight), un modèle de composition qui surpasse constamment les modèles existants sur les composés nominaux, les phrases adjectif-nom et les phrases adverbe-adjectifs en anglais, en allemand et en néerlandais. TransWeight réduit considérablement le nombre de paramètres nécessaires par rapport au meilleur modèle de la littérature en composant des mots similaires de la même manière.", 'pt': 'Modelos de composição de semântica distributiva são usados para construir representações de frases a partir das representações de suas palavras. Os modelos de composição estão tipicamente situados em duas extremidades de um espectro. Eles têm um pequeno número de parâmetros, mas compõem todas as frases da mesma maneira, ou executam composições específicas de palavras ao custo de um número muito maior de parâmetros. Neste artigo, propomos a ponderação de transformação (TransWeight), um modelo de composição que supera consistentemente os modelos existentes em compostos nominais, locuções adjetivas-substantivas e locuções advérbio-adjetivas em inglês, alemão e holandês. O TransWeight reduz drasticamente o número de parâmetros necessários em comparação com o melhor modelo da literatura ao compor palavras semelhantes da mesma maneira.', 'es': 'Los modelos de composición de semántica distributiva se utilizan para construir representaciones de frases a partir de las representaciones de sus palabras. Los modelos de composición suelen estar situados en dos extremos de un espectro. O bien tienen un pequeño número de parámetros pero componen todas las frases de la misma manera, o realizan composiciones específicas de palabras a costa de un número mucho mayor de parámetros. En este artículo proponemos la ponderación de transformación (TransWeight), un modelo de composición que supera consistentemente a los modelos existentes en compuestos nominales, frases adjetivo-sustantivo y frases adverbo-adjetivo en inglés, alemán y holandés. TransWeight reduce drásticamente el número de parámetros necesarios en comparación con el mejor modelo de la literatura al componer palabras similares de la misma manera.', 'ar': 'تُستخدم نماذج تكوين دلالات التوزيع لبناء تمثيلات العبارات من تمثيلات كلماتهم. توجد نماذج التركيب عادةً على طرفي الطيف. لديهم إما عدد صغير من المعلمات ولكنهم يؤلفون جميع العبارات بنفس الطريقة ، أو يؤدون تركيبات خاصة بالكلمات على حساب عدد أكبر بكثير من المعلمات. في هذا البحث نقترح ترجيح التحويل (TransWeight) ، وهو نموذج تكوين يتفوق باستمرار على النماذج الحالية على المركبات الاسمية ، وعبارات الصفة الاسمية ، وعبارات صفة الظرف باللغات الإنجليزية والألمانية والهولندية. يقلل TransWeight بشكل كبير من عدد المعلمات المطلوبة مقارنة بأفضل نموذج في الأدبيات من خلال تكوين كلمات مماثلة بنفس الطريقة.', 'hi': 'वितरणात्मक शब्दार्थ के संरचना मॉडल का उपयोग उनके शब्दों के प्रतिनिधित्व से वाक्यांश प्रतिनिधित्व के निर्माण के लिए किया जाता है। संरचना मॉडल आमतौर पर एक स्पेक्ट्रम के दो सिरों पर स्थित होते हैं। उनके पास या तो पैरामीटर की एक छोटी संख्या है लेकिन सभी वाक्यांशों को उसी तरह से लिखते हैं, या वे बहुत बड़ी संख्या में मापदंडों की कीमत पर शब्द-विशिष्ट रचनाएं करते हैं। इस पेपर में हम ट्रांसफॉर्मेशन वेटिंग (ट्रांसवेट) का प्रस्ताव करते हैं, एक रचना मॉडल जो लगातार नाममात्र यौगिकों, विशेषण-संज्ञा वाक्यांशों और अंग्रेजी, जर्मन और डच में क्रियाविशेषण-विशेषण वाक्यांशों पर मौजूदा मॉडल को मात देता है। ट्रांसवेट इसी तरह से समान शब्दों की रचना करके साहित्य में सबसे अच्छे मॉडल की तुलना में आवश्यक मापदंडों की संख्या को काफी कम कर देता है।', 'ja': '分布意味論の構成モデルは、それらの単語の表現からフレーズ表現を構築するために使用される。組成モデルは、典型的には、スペクトルの２つの端に位置する。パラメータの数は少ないが、すべてのフレーズを同じ方法で構成するか、はるかに多くのパラメータを費やして単語固有の構成を実行します。この論文では、英語、ドイツ語、オランダ語の公称化合物、形容詞-名詞句、副詞-形容詞句で既存のモデルを一貫して上回る構成モデルであるトランスフォーメーションウェイト（ TransWeight ）を提案した。TransWeightは、同様の単語を同じ方法で作成することにより、文献の最良のモデルと比較して、必要なパラメータの数を大幅に削減します。', 'zh': '布语义复合,以造其单词短语。 合成模常在光谱两端。 有少参数,有同短语,有牺牲参数特定单词。 本文中,转换加权(TransWeight),是为合模形,在英语,德语与荷兰语中名义化合物,形容词 - 名词短语与副词 - 形容词短语终优于今。 比文献之最善者,TransWeight以相似之单词,大大减少参数之数。', 'ru': 'Композиционные модели дистрибутивной семантики используются для построения репрезентаций фраз из репрезентаций их слов. Модели композиций обычно расположены на двух концах спектра. Они либо имеют небольшое количество параметров, но составляют все фразы одинаково, либо выполняют словосочетания за счет гораздо большего количества параметров. В этой статье мы предлагаем взвешивание преобразования (TransWeight), композиционную модель, которая последовательно превосходит существующие модели по номинальным соединениям, прилагательным-назывным фразам и наречиям-наречиям-наречиям на английском, немецком и голландском языках. TransWeight резко сокращает количество необходимых параметров по сравнению с лучшей моделью в литературе, составляя аналогичные слова таким же образом.', 'ga': 'Baintear úsáid as samhlacha cumadóireachta de shéimeantaic dáileacháin chun léiriúcháin frása a chruthú as léiriúcháin a gcuid focal. Is gnách go mbíonn samhlacha cumadóireachta suite ar dhá cheann an speictrim. Bíonn líon beag paraiméadair acu ach cumann siad gach frása ar an mbealach céanna, nó déanann siad cumadóireacht a bhaineann go sonrach le focail ar chostas líon i bhfad níos mó paraiméadair. Sa pháipéar seo molaimid ualú claochlaithe (TransWeight), múnla cumadóireachta a sháraíonn go seasta na múnlaí atá ann cheana féin ar chomhdhúile ainmniúla, frásaí aidiachtacha-ainmfhocail, agus frásaí dobhriathair-aidiachta sa Bhéarla, sa Ghearmáinis agus san Ollainnis. Laghdaíonn TransWeight go mór líon na bparaiméadar a theastaíonn i gcomparáid leis an múnla is fearr sa litríocht trí fhocail chomhchosúla a chumadh ar an mbealach céanna.', 'el': 'Τα μοντέλα σύνθεσης της διανεμητικής σημασιολογίας χρησιμοποιούνται για την κατασκευή αναπαραστάσεων φράσεων από τις αναπαραστάσεις των λέξεων τους. Τα μοντέλα σύνθεσης βρίσκονται συνήθως σε δύο άκρες ενός φάσματος. Είτε έχουν μικρό αριθμό παραμέτρων αλλά συνθέτουν όλες τις φράσεις με τον ίδιο τρόπο, είτε εκτελούν συνθέσεις που αφορούν τις λέξεις με κόστος ενός πολύ μεγαλύτερου αριθμού παραμέτρων. Σε αυτή την εργασία προτείνουμε τη στάθμιση μετασχηματισμού (ένα μοντέλο σύνθεσης που ξεπερνά σταθερά τα υπάρχοντα μοντέλα για ονομαστικές ενώσεις, φράσεις επίθετου-ουσιαστικού και φράσεις επίθετου-επίθετου στα αγγλικά, γερμανικά και ολλανδικά. Το μειώνει δραστικά τον αριθμό των παραμέτρων που απαιτούνται σε σύγκριση με το καλύτερο μοντέλο στη βιβλιογραφία συνθέτοντας παρόμοιες λέξεις με τον ίδιο τρόπο.', 'hu': 'A disztribúciós szemantika kompozíciós modelljeit használják a kifejezések reprezentációinak létrehozására szavaik reprezentációjából. A kompozíciós modellek jellemzően a spektrum két végén helyezkednek el. Vagy kis számú paraméterrel rendelkeznek, de minden kifejezést ugyanúgy alkotnak, vagy szóspecifikus kompozíciókat végeznek sokkal nagyobb számú paraméter árán. Jelen tanulmányban a transzformációs súlyozást (TransWeight) javasoljuk, amely egy olyan kompozíciós modell, amely következetesen felülmúlja a meglévő modelleket a névleges vegyületek, melléknév-főnév kifejezések és határozó-melléknév kifejezések angol, német és holland nyelven. A TransWeight drasztikusan csökkenti a szükséges paraméterek számát a szakirodalom legjobb modelljével összehasonlítva, hasonló szavakat írva.', 'kk': 'Дисплюциялық семантикалық құрылғы үлгілері сөздерінің кескіндерінен сөздерді құру үшін қолданылады. Композиция үлгілері әдетте спектрондың екі соңында орналасады. Олардың немесе кішкентай параметрлері бар, бірақ барлық сөздерді бірдей түрде құрастырып, немесе сөздерді өзгерту үлкен параметрлердің санына арналған құрылғыларды орындайды. Бұл қағазда біз түрлендіру үлгісін (TransWeight) таңдаймыз. Бұл композициялық үлгісі номиналдық композициялар, adjective- noun фразалар және adverb- adjective фразалар ағылшын, неміс және голландық тіліндегі үлгілерден тұрақты TransWeight деген параметрлердің санын әдебиеттердің ең жақсы моделімен салыстырып, бір түрде ұқсас сөздерді құру арқылы көтереді.', 'mk': 'Композициските модели на дистрибуционална семантика се користат за конструкција на претставувања на фразите од претставувањата на нивните зборови. Композициските модели се обично лоцирани на два краја на спектрот. They either have a small number of parameters but compose all phrases in the same way, or they perform word-specific compositions at the cost of a far larger number of parameters.  In this paper we propose transformation weighting (TransWeight), a composition model that consistently outperforms existing models on nominal compounds, adjective-noun phrases, and adverb-adjective phrases in English, German, and Dutch.  TransWeight drastically reduces the number of parameters needed compared with the best model in the literature by composing similar words in the same way.', 'ka': 'განსაზღვრებული სიმენტიკის კომპოზიციონის მოდელები გამოყენებულია ტრაზის გამოსახულებების გამოსახულებლად. კომპოზეციის მოდელები ტიპოლურად სპექტრმის ორი კუთხეში დაადგილებიან. ისინი იყოს პარამეტრების პარამეტრები, მაგრამ ყველა ფრამეტრები ერთად შექმნა, ან ისინი სიტყვას სპექტიფიკური კომპოზიციები გავაკეთებენ ძალიან დიდი პარამეტრების ამ დოკუნეში ჩვენ დავიწყებთ ტრანფორმაციის სიმაღლე (TransWeight) კომპოზიციის მოდელი, რომელიც კომპოზიციის მოდელის შემდეგ არსებობს ნომინალური კომპონეციებში, აექექტური სახელის ფრაზები და აექექტურ TransWeight drastically reduces the number of parameters needed in comparison with the best model in the literature by composing similar words in the same way.', 'ms': 'Model komposisi semantik distribusi digunakan untuk membina perwakilan frasa dari perwakilan perkataan mereka. Model komposisi biasanya berada di dua ujung spektrum. They either have a small number of parameters but compose all phrases in the same way, or they perform word-specific compositions at the cost of a far larger number of parameters.  Dalam kertas ini kami cadangkan penimbangan pengubahan (TransWeight), model komposisi yang secara konsisten melebihi model yang wujud pada komponen nominal, frasa-nama-adjektif, dan frasa-adjektif adverb dalam bahasa Inggeris, Jerman, dan Belanda. TransWeight mengurangkan secara drastik bilangan parameter yang diperlukan dibandingkan dengan model terbaik dalam literatur dengan komposisi perkataan yang sama dengan cara yang sama.', 'it': 'I modelli di composizione della semantica distributiva sono utilizzati per costruire rappresentazioni di frasi dalle rappresentazioni delle loro parole. I modelli di composizione sono tipicamente situati su due estremità di uno spettro. Essi hanno un piccolo numero di parametri ma compongono tutte le frasi nello stesso modo, o eseguono composizioni specifiche di parole al costo di un numero molto maggiore di parametri. In questo articolo proponiamo la ponderazione di trasformazione (TransWeight), un modello di composizione che supera costantemente i modelli esistenti su composti nominali, frasi aggettivo-sostantivo e frasi avverbio-aggettivo in inglese, tedesco e olandese. TransWeight riduce drasticamente il numero di parametri necessari rispetto al miglior modello in letteratura componendo parole simili nello stesso modo.', 'lt': 'Composition models of distributional semantics are used to construct phrase representations from the representations of their words.  Sudėties modeliai paprastai yra dviejuose spektro galuose. Jie turi nedidelį parametrų skaičių, bet sudaro visas frazes taip pat, arba jie atlieka žodžiui būdingas sudėtis už gerokai didesnį parametrų skaičių. Šiame dokumente siūlome perskaičiavimo koeficientą (TransWeight), sudėties model į, kuris nuosekliai viršija esamus modelius vardinių junginių, adjektyvinių frazių ir adverb adjektyvinių frazių anglų, vokiečių ir olandų kalbomis. TransWeight drastically reduces the number of parameters needed compared with the best model in the literature by composing similar words in the same way.', 'ml': 'വാക്കുകളുടെ പ്രതിനിധികളില്\u200d നിന്നും വാക്കുകളുടെ പ്രതിനിധികള്\u200d നിര്\u200dമ്മിക്കാന്\u200d ഉപയോഗിക്കുന്ന കമ്പോഷന്\u200d മോ ഒരു സ്പെക്ട്രാമിന്റെ രണ്ട് അവസാനത്തേക്ക് കോമ്പോഷന്\u200d മോഡലുകള്\u200d സാധാരണ സ്ഥാപിക്കുന്നു. അവയ്ക്ക് ഒരു ചെറിയ അളവുകളുണ്ടാവും, പക്ഷെ എല്ലാ വാക്കുകളും ഒരേ രീതിയില്\u200d കൂട്ടുക, അല്ലെങ്കില്\u200d വാക്കിന്റെ പ്രത്യേകിച്ചിട്ടുള്ള സ ഈ പത്രത്തില്\u200d നമ്മള്\u200d മാറ്റം തൂക്കുന്നത് (ട്രാന്\u200dസ്\u200cവൈറ്റ്), നിലവിലുള്ള മോഡല്\u200d നിലനില്\u200dക്കുന്ന മോഡല്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു ഇംഗ്ലീഷ്, ജര്\u200dമ്മന്\u200d, ഹാച്ചില ട്രാന്\u200dവെയ്റ്റ് സാഹിത്യത്തിലെ ഏറ്റവും നല്ല മോഡലുമായി ആവശ്യമുള്ള പരാമീറ്ററുകളുടെ എണ്ണം കുറവ് വരുത്തുന്നു. ഒരേ രീതിയി', 'pl': 'Modele kompozycyjne semantyki dystrybucyjnej są wykorzystywane do konstruowania reprezentacji fraz z reprezentacji ich słów. Modele kompozycyjne są zwykle umieszczone na dwóch końcach widma. Albo mają niewielką liczbę parametrów, ale komponują wszystkie frazy w ten sam sposób, albo wykonują kompozycje specyficzne dla słów kosztem znacznie większej liczby parametrów. W niniejszym artykule proponujemy ważenie transformacyjne (TransWeight), model kompozycji, który konsekwentnie przewyższa istniejące modele związków nominalnych, zwrotów rzeczowników i zwrotów przysłówkowo-przymiotnikowych w języku angielskim, niemieckim i holenderskim. TransWeight drastycznie zmniejsza liczbę potrzebnych parametrów w porównaniu z najlepszym modelem w literaturze, komponując podobne słowa w ten sam sposób.', 'mt': 'Composition models of distributional semantics are used to construct phrase representations from the representations of their words.  Composition models are typically situated on two ends of a spectrum.  Huma jew għandhom numru żgħir ta’ parametri iżda jikkostitwixxu l-frażijiet kollha bl-istess mod, jew iwettqu kompożizzjonijiet speċifiċi għall-kliem bi spiża ta’ numru ferm akbar ta’ parametri. F’dan id-dokument qed nipproponu l-ippeżar tat-trasformazzjoni (TransWeight), mudell ta’ kompożizzjoni li b’mod konsistenti jaqbeż il-mudelli eżistenti fuq komposti nominali, frażijiet b’isem a ġġettiv, u frażijiet b’isem aġġettiv bl-Ingliż, bil-Ġermaniż u bl-Olandiż. TransWeight drastically reduces the number of parameters needed compared with the best model in the literature by composing similar words in the same way.', 'sr': 'Modeli kompozicije distribucijskih semantika se koriste za konstrukciju fraze iz predstavljanja njihovih reči. Modeli kompozicije se obično nalaze na dva kraja spektra. Ili imaju mali broj parametara, ali sastavljaju sve rečenice na isti način, ili izvršavaju rečeno specifične kompozicije po cijeni mnogo većeg broja parametara. U ovom papiru predlažemo težinu transformacije (TransWeight), model kompozicije koji konsekventno iznosi postojeće modele na nominalnim spojevima, adjektivnim imenskim rečenicama i reklamskim rečenicama na engleskom, njemačkom i holandskom jeziku. TransWeight drastično smanjuje broj parametara potrebnih u usporedbi sa najboljim modelom u literaturi, sastavljajući slične reči na isti način.', 'no': 'Komposisjonsmodeller for distribusjonssemantikk vert brukt for å konstruere frasisrepresentasjonar frå representasjonane av ordene sine. Komposisjonsmodeller er normalt sett på to ender av ein spektrum. Dei har anten ein liten tal parametra, men lager alle fraser på samme måte, eller utfører dei ordspesifikke komponentar ved kostnaden til eit langt større tal parametra. I denne papiret foreslår vi transformasjonsverke (TransWeight) eit komponentsmodell som konsistent utfører eksisterande modeller på nominale samlingar, adjektiv- namn- frasar og adverb- adjektiv frasar på engelsk, tysk og nederlandsk. Overvekt reduserer kor mange parametra trengte i sammenligning med den beste modellen i litteraturen ved å skriva liknande ord på samme måte.', 'mn': 'Дэлхийн семантикийн жишээн загварууд үгийнхээ илэрхийллийг бүтээхэд хэрэглэгддэг. Сонголтын загварууд ихэвчлэн спектромын хоёр төгсгөлд байдаг. Эсвэл жижиг хэмжээний параметр байдаг гэхдээ бүх өгүүлбэрийг ижил хэлбэрээр бий болгож, эсвэл илүү том хэмжээний зардлыг тодорхойлж чаддаг. Энэ цаасан дээр бид өөрчлөлтийн жинтэй (TransWeight) загварыг санал болгож байна. Энэ бүтэц загвар нь нэр төрлийн холбоотой, нэр төрлийн хэлбэрүүд, англи, Герман, Нидерландын хэлний адаберб-adjective хэлбэрүүд дээр үргэлжлүүлдэг. TransWeight нь уран зохиолын хамгийн сайн загвартай харьцуулахад хэрэгтэй параметр тоог багасгаж байна.', 'ro': 'Modelele de compoziție ale semanticii distribuționale sunt folosite pentru a construi reprezentări de fraze din reprezentările cuvintelor lor. Modelele de compoziție sunt de obicei situate pe două capete ale unui spectru. Fie au un număr mic de parametri, dar compun toate frazele în același mod, fie efectuează compoziții specifice cuvintelor cu prețul unui număr mult mai mare de parametri. În această lucrare propunem ponderea transformării (TransWeight), un model de compoziție care depășește în mod constant modelele existente pe compuși nominali, fraze adjective-substantiv și fraze adverb-adjective în engleză, germană și olandeză. TransWeight reduce drastic numărul de parametri necesari în comparație cu cel mai bun model din literatură, compunând cuvinte similare în același mod.', 'so': 'Tusaalada kooxaha qaybsiga waxaa loo isticmaalaa in lagu dhiso qof ka mid ah qof ka tirsan kara hadalkooda. Tusaale qeyb-dhigista waxaa inta badan lagu qoraa laba daraf oo ka mid ah labada dhinac. Waxay leeyihiin tiro yar oo isku mid ah, ama waxay sameeyaan qeybo gaar ah oo ay ku qaataan tirada aad u weyn. Qoraalkan waxaan ka soo jeedaynaa bedelka bedelka miisaanka (TransWeight), model sawirida ah oo ku sameynaya tusaalaha joogta ah oo ku qoran xarunta qoyska, hadalka isbedelka, iyo hadalka bedelka ee afka Ingiriiska, Jarmalka iyo Dutch. Weight si aad ah ayaa u hoosaysiiya tirada loo baahan yahay oo la barbardhigyo tusaalaha ugu fiican ee warqada ku qoran si isku mid ah ugu sameynta hadallada isku mid ah.', 'si': 'විදුලිය සෙමැන්ටික්ස්ටික්ස් සංවිධානයේ සංවිධානය සංවිධානය භාවිත කරනවා ඔවුන්ගේ වචන සංවි සංවිධානයක් සාමාන්\u200dයයෙන්ම ස්පෙක්ටර්ම් එකේ අංක දෙකක් තියෙනවා. ඔවුන්ට පොඩි සංඛ්යාවක් තියෙනවා නමුත් ඔවුන්ට එකම විදියට සියළු ප්\u200dරකාරයක් සම්බන්ධ කරන්න, නැත්තම් ඔවුන් වචන විශේෂ මේ පැත්තේ අපි ප්\u200dරතිචාරණය විශාලය (TransWeight), සංවිධානයක් ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරණය කරන්න ප්\u200dරතිචාරයක් ප්\u200dරතිචාරණය කරන්නේ, නාමිකල් සංවිධානය TransWeight dramatically minimises the number of parametrics needed to compare with the better Model in the litteratura by composing the comparison Words in the one way.', 'sv': 'Sammansättningsmodeller av distributionsemantik används för att konstruera frasrepresentationer från representationer av deras ord. Kompositionsmodeller är vanligtvis belägna i två ändar av ett spektrum. Antingen har de ett litet antal parametrar men komponerar alla fraser på samma sätt, eller så utför de ordspecifika kompositioner på bekostnad av ett mycket större antal parametrar. I denna uppsats föreslår vi transformationsviktning (TransWeight), en kompositionsmodell som konsekvent överträffar befintliga modeller på nominella föreningar, adjektiv-substantiv fraser och adverb-adjektiv fraser på engelska, tyska och nederländska. TransWeight minskar drastiskt antalet parametrar som behövs jämfört med den bästa modellen i litteraturen genom att komponera liknande ord på samma sätt.', 'ta': 'பங்கீட்டு அமைப்புகளின் கூட்டு மாதிரி கூட்டு மாதிரிகள் வழக்கமாக இரண்டு முடிவில் இருக்கும். இவைகளில் ஒரு சிறிய அளபுருகள் இருக்கிறது ஆனால் அனைத்து சொற்களையும் ஒரே வழியில் கூட்டுகிறது, அல்லது அதிகமாக பெரிய அளபுருகளின் விலை இந்த காகிதத்தில் நாம் மாற்றம் எடை( TransWeight), ஒரு கூட்டும் மாதிரி தொகுப்பு, தற்போதைய மாதிரிகளில் இருக்கும் பொருட்களில் இருக்கும் மாதிரிகளை செயல்படுத்துகிறது, சரியான Transweight dramatically reduces the number of parameters required to compare to the best model in the literature by composing similar words in the same way.', 'ur': 'تقسیم سیمانٹیکس کی پیدائش نمونڈل ان کے کلمات کی نمونڈیوں سے فرض نمونڈیوں کو بنانے کے لئے استعمال کیا جاتا ہے. مکانوسٹن نمڈلوں معمولاً ایک جسم کے دو قسموں پر موجود ہیں. ان کے پاس ایک چھوٹی تعداد پارامیٹر ہے لیکن تمام فرشتوں کو ایک ہی طرح جوڑ لیتے ہیں، یا وہ ایک بہت بڑی پارامیٹروں کے مطابق کلمات کے مطابق لکھتے ہیں. ہم اس کاغذ میں تغییر وزن (TransWeight) کی پیشنهاد کریں گے، ایک کامپیوتر موڈل جو ایک دوسرے سے موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود موجود مو TransWeight ایک ہی طریقہ سے برابر کلمات لکھنے کے مطابق ضرورت کی پارامیٹروں کی تعداد کم کر دیتا ہے۔', 'vi': 'Các mô hình tổng hợp của ngữ pháp phân phối được dùng để xây dựng các biểu tượng từ biểu tượng của ngôn ngữ. Các mô hình sự kết hợp thường nằm ở hai đầu của phổ quang. Chúng có một số lượng nhỏ các tham số, nhưng cấu tạo tất cả các cụm từ cùng một cách, hoặc là chúng thực hiện các hợp tác riêng từ với giá trị của một số tham số lớn hơn. Trong tờ giấy này, chúng tôi đề nghị cân bằng chuyển đổi (Transweight), một mô hình cấu hình hoàn hảo hoàn toàn vượt trội các mô hình hiện tại về các hợp chất biểu tượng, từ tính từ, và cụm từ từ từ từ, bằng tiếng Anh, Đức và Hà Lan. Nửa Weight giảm tối đa số lượng các tham số cần thiết so với mô hình tốt nhất trong văn học bằng cách trộn các từ tương tự theo cùng một cách.', 'uz': "Name Name Ularning bir necha parametrlar bor, lekin hamma so'zlarni bir xil qilish mumkin yoki ularning eng katta parametrlar sonini bajaradi. Bu hujjatda, biz o'zgarishni o'zgartirish (TransWeight) o'zgarishni talab qilamiz, bir kompyuterning modeli davom etishni boshlaydi. Bu shaklga o'zgarishni o'zgartirish imkoniyatini o'zgartiradi. TransWeight taʼminlovchi parametrlar soni o'xshash so'zlarni bir xil tomoniga kamaytirish mumkin.", 'da': 'Sammensætningsmodeller af distributions semantik bruges til at konstruere sætningsrepræsentationer ud fra repræsentationerne af deres ord. Kompositionsmodeller er typisk placeret i to ender af et spektrum. De har enten et lille antal parametre, men komponerer alle sætninger på samme måde, eller de udfører ordspecifikke kompositioner på bekostning af et langt større antal parametre. I denne artikel foreslår vi transformationsvægtning (TransWeight), en sammensætningsmodel, der konsekvent overgår eksisterende modeller på nominelle forbindelser, adjektiv-substantiv sætninger og adverb-adjektiv sætninger på engelsk, tysk og hollandsk. TransWeight reducerer drastisk antallet af parametre, der kræves sammenlignet med den bedste model i litteraturen ved at komponere lignende ord på samme måde.', 'bg': 'Композиционни модели на дистрибуционната семантика се използват за изграждане на фразови представи от представянето на техните думи. Моделите на композицията обикновено са разположени на два края на спектъра. Те или имат малък брой параметри, но съставят всички фрази по един и същ начин, или изпълняват специфични думи композиции на цената на много по-голям брой параметри. В настоящата статия предлагаме преобразуване на теглото (транстегловно), композиционен модел, който последователно надминава съществуващите модели на номинални съединения, прилагателни-съществителни фрази и рекламни-прилагателни фрази на английски, немски и холандски език. ТрансТегло драстично намалява броя на необходимите параметри в сравнение с най-добрия модел в литературата чрез композиране на подобни думи по същия начин.', 'de': 'Kompositionsmodelle der verteilten Semantik werden verwendet, um Phrasen-Repräsentationen aus den Repräsentationen ihrer Wörter zu konstruieren. Kompositionsmodelle befinden sich typischerweise an zwei Enden eines Spektrums. Sie haben entweder eine kleine Anzahl von Parametern, komponieren aber alle Phrasen auf die gleiche Weise, oder sie führen wortspezifische Kompositionen auf Kosten einer viel größeren Anzahl von Parametern durch. In diesem Beitrag schlagen wir Transformationsgewichtung (TransWeight) vor, ein Kompositionsmodell, das bestehende Modelle für nominale Verbindungen, Adjektiv-Substantiv-Phrasen und Adverb-Adjektiv-Phrasen in Englisch, Deutsch und Niederländisch durchwegs übertrifft. TransWeight reduziert die Anzahl der benötigten Parameter im Vergleich zum besten Modell in der Literatur drastisch, indem ähnliche Wörter auf die gleiche Weise komponiert werden.', 'nl': 'Samenstellingsmodellen van distributionele semantiek worden gebruikt om frase representaties te construeren uit de representaties van hun woorden. Compositiemodellen bevinden zich meestal aan twee uiteinden van een spectrum. Ze hebben ofwel een klein aantal parameters maar stellen alle zinnen op dezelfde manier samen, of ze voeren woordspecifieke composities uit ten koste van een veel groter aantal parameters. In dit artikel stellen we transformatie weiging (TransWeight) voor, een compositiemodel dat consistent overtreft bestaande modellen op nominale verbindingen, bijvoeglijk naamwoord zinnen en bijvoeglijk naamwoord zinnen in het Engels, Duits en Nederlands. TransWeight vermindert het aantal benodigde parameters drastisch ten opzichte van het beste model in de literatuur door vergelijkbare woorden op dezelfde manier te componeren.', 'hr': 'Modeli kompozicije distribucijskih semantika se koriste za konstrukciju fraze iz predstavljanja njihovih riječi. Modeli kompozicije se obično nalaze na dva kraja spektra. Ili imaju mali broj parametara, ali sastavljaju sve rečenice na isti način, ili izvršavaju riječi specifične sastave na troškovi daleko većeg broja parametara. U ovom papiru predlažemo težinu transformacije (TransWeight), model kompozicije koji konsekventno iznosi postojeće modele na nominalnim spojevima, adjektivnim imenskim rečenicama i reklamskim rečenicama na engleskom, njemačkom i holandskom jeziku. TransWeight drastično smanjuje broj parametara potrebnih u usporedbi s najboljim modelom u književnosti sastavljajući slične riječi na isti način.', 'id': 'Model komposisi dari semantik distribusi digunakan untuk membangun represensi frasa dari represensi kata-kata mereka. Model komposisi biasanya berada di dua ujung spektrum. Mereka sama ada memiliki sejumlah kecil parameter tetapi membuat semua frasa dengan cara yang sama, atau mereka melakukan komposisi spesifik kata pada biaya sejumlah parameter yang jauh lebih besar. Dalam kertas ini kami mengusulkan pembagian transformasi (TransWeight), model komposisi yang secara konsisten melebihi model yang ada pada komponen nominal, frasa-nama-adjektif, dan frasa-adjektif adverb dalam bahasa Inggris, Jerman, dan Belanda. TransWeight secara drastis mengurangi jumlah parameter yang diperlukan dibandingkan dengan model terbaik dalam literatur dengan menggambarkan kata-kata yang sama dengan cara yang sama.', 'ko': '분포어의학의 구사 모델은 단어의 표현에서 단어의 표현을 구성하는 데 쓰인다.성분 모형은 보통 스펙트럼의 양 끝에 위치한다.그것들은 소량의 매개 변수가 있지만, 같은 방식으로 모든 단어를 조합하거나, 대량의 매개 변수를 대가로 특정한 단어의 조합을 집행한다.본고에서 우리는 전환권중(TransWeight)을 제기했다. 이것은 조합 모델로 영어, 독일어와 네덜란드어의 명사성 복합어, 형용사-명사단어와 부사-형용사단어는 시종 기존 모델보다 우수하다.문헌에서 가장 좋은 모델에 비해 TransWeight는 비슷한 단어를 같은 방식으로 조합함으로써 필요한 매개 변수의 수를 크게 줄였다.', 'tr': 'Bölümçi semantikleriň aýratyn nusgalary sözleriniň suratlaryndan çykarmak üçin ullanýar. Çykyş nusgalary adatça spektrumyň iki uňunda durulýar. Ya da kiçi bir sany parameterler bar emma bütün sözleri bir şekilde ýazylýarlar, ýöne sözleri takyklaýarlar. Ullakan bir sany parameterleriň bederi üçin ullanylýar. Bu kagyzda, iňlisçe, nemesçe we hollandçe eserleýän çykyş şeklinde üýtgetmeli terjime etmegi teklip edip otyrýarys. Ýagtyzlyk edebiýatdaky iň gowy nusga bilen deňleýän parametrolaryň sanyny bir şekilde ýazmak bilen düşürir.', 'fa': 'نمونه\u200cهای ترکیب سیمانتیک\u200cهای تقسیم برای ساختن نمایش\u200cهای عبارت از نمایش\u200cهای کلمات آنها استفاده می\u200cشود. مدلهای ترکیب معمولاً در دو قسمت یک спектر موجود می شوند. آنها یا تعداد اندکی از پارامترها دارند، ولی تمام جمله\u200cها را به همان طریق ترکیب می\u200cکنند، یا ترکیب\u200cهای مخصوص کلمه را به هزینه تعداد بزرگتری از پارامترها انجام می\u200cدهند. در این کاغذ ما پیشنهاد می\u200cکنیم که وزن تغییر (TransWeight) یک مدل تغییر\u200cسازی که همیشه مدل موجود موجود در ترکیب\u200cهای نومیل، عبارت\u200cهای نومیل و عبارت\u200cهای اضافه\u200cای به انگلیسی، آلمانی و هلندی\u200cها را بیشتر انجام می\u200cدهد. ترانوزت تعداد پارامترها نیاز به مقایسه با بهترین مدل ادبیات با ترکیب کلمات مشابه به همان طریق کاهش می\u200cکند.', 'sw': 'Mradi wa mikutano ya usambazaji unatumiwa kujenga uwakilishi wa maneno kutoka kwenye uwakilishi wa maneno yao. Mradi wa komposition kwa kawaida huwekwa kwenye upande wa miwili wa michoro. Wanaweza kuwa na idadi ndogo lakini wanatengeneza maneno yote kwa namna hiyo, au wanafanya vifaa maalum vya maneno kwa gharama ya idadi kubwa ya parameters. Katika gazeti hili tunapendekeza kubadilishana uzito (TransWeight), modeli ya ubunifu ambao kwa ujumla unafanya mifano ya kuwepo kwenye viungo vya uteuzi, maneno yasiyo ya kisheria, na maneno yanayobadilishwa kwa lugha ya Kiingereza, Kijerumani na Kiholanzi. Weight inapunguza kwa kiasi kikubwa idadi ya parameter zinazohitajika kulinganisha na mtindo bora wa fasihi kwa kutengeneza maneno yanayofanana kwa namna hiyo.', 'sq': 'Modelet e kompozitave të semantikës shpërndarëse përdoren për të ndërtuar përfaqësime frazësh nga përfaqësimet e fjalëve të tyre. Composition models are typically situated on two ends of a spectrum.  Ato ose kanë një numër të vogël parametrash por përbëjnë të gjitha frazat në të njëjtën mënyrë, ose kryejnë kompozita specifike fjalësh me kosto të një numri shumë më të madh parametrash. Në këtë letër propozojmë peshimin e transformimit (TransWeight), një model kompozitivësh që vazhdimisht mbivlerëson modelet ekzistuese në përbërjet nominale, frazat me emër shtesë dhe frazat me emër shtesë në anglisht, gjermanisht dhe hollandez. TransWeight drastically reduces the number of parameters needed compared with the best model in the literature by composing similar words in the same way.', 'hy': 'Դաշխատային սեմանտիկայի կառուցվածքային մոդելները օգտագործվում են արտահայտությունների ներկայացումների կառուցման համար իրենց բառերի ներկայացումներից: Համակարգման մոդելները սովորաբար գտնվում են սպեկտրի երկու ծայրերում: They either have a small number of parameters but compose all phrases in the same way, or they perform word-specific compositions at the cost of a far larger number of parameters.  Այս թղթի մեջ մենք առաջարկում ենք վերափոխման կենտրոնացման (Trans-Gewer) կենտրոնացման մոդել, որը մշտապես գերազանցում է գոյություն ունեցող մոդելները անգլերենում, գերմաներենում և հոլանդերենում: Trans-Ուշը խիստ նվազեցնում է հարկավոր պարամետրերի թիվը, համեմատած գրականության լավագույն մոդելի հետ, նույն կերպ ստեղծելով նման բառեր:', 'af': "Komposisiemodelle van verspreidingssemantieke word gebruik om frase voorstellings te konstrukteer van die voorstellings van hul woorde. Komposisiemodelle is tipies op twee einde van 'n spektrum situasie. Hulle het of 'n klein nommer van parameters, maar alle frase op dieselfde manier opstelle, of hulle uitvoer woord-spesifieke opstellings na die koste van 'n ver groter nommer van parameters. In hierdie papier voorstel ons transformasie weegting (TransWeight)  'n kompozisie model wat bestaande modelles op nominale verbindings, adjective-noun frase en adverb-adjective frase in Engels, Duits en Nederlandse uitvoer. TransWeight drastiese verduur die aantal parameters wat benodig is vergelyk met die beste model in die literaat deur gelyke woorde op dieselfde manier te stel.", 'am': 'አካባቢው የክፍለ አካባቢ ምሳሌዎች ቃሎቻቸውን አካባቢ እንዲያሳርጉ ይጠቀማሉ፡፡ አቀማመጥ አካል አካላት አነስተኛ አካል ቢኖሩ ግን ሁሉን አካላት በአንድ ዓይነት አካባቢ ይደረጋሉ፤ ወይም ከታናሹ ምርጫዎች በሚበልጠው መጠን ይቆጥራሉ፡፡ በዚህ ፕሮግራም፣ የእንግሊዝኛ፣ ጀርመን እና ኬንድጓድ፣ የግንኙነት አካላት፣ የግንኙነት አካላት እና አቀማመጥ-አካባቢ ቃላትን በንግሊዝኛ፣ የጀርመን እና የኬንድጓድ እና የአፍሪክ ቃላትን መዝገብ እና የአፍሪካዊ ቃላትን መዝገብ እናደርጋለን፡ TransWeight drastically reduces the number of parameters needed compared with the best model in the literature by composing similar words in the same way.', 'ca': "Els models de composició de la semàntica distribucional s'utilitzen per construir representacions de frases a partir de les representacions de les seves paraules. Els models de composició es troben típicament a dos extrems d'un espectre. They either have a small number of parameters but compose all phrases in the same way, or they perform word-specific compositions at the cost of a far larger number of parameters.  En aquest paper proposem ponderació de transformació (TransWeight), un model de composició que contínuament supera els models existents en composts nominals, frases de nom adjectiu i frases adverb-adjectives en anglès, alemany i holandès. TransWeight redueix dràsticament el nombre de paràmetres requerits comparat amb el millor model de la literatura composant paraules similars de la mateixa manera.", 'bs': 'Modeli kompozicije distribucijskih semantika se koriste za konstrukciju fraze iz predstavljanja njihovih riječi. Modeli kompozicije se obično nalaze na dva kraja spektra. Ili imaju mali broj parametara, ali sastavljaju sve rečenice na isti način, ili izvršavaju rečeno specifične kompozicije na cijenu mnogo većeg broja parametara. U ovom papiru predlažemo težinu transformacije (TransWeight), model kompozicije koji konsekventno nadmašuje postojeće modele za nominalne spojeve, adjektivne ime fraze i reklamske fraze na engleskom, njemačkom i holandskom jeziku. TransWeight drastično smanjuje broj parametara potrebnih u usporedbi sa najboljim modelom u literaturi, sastavljajući slične riječi na isti način.', 'bn': 'তাদের কথার প্রতিনিধিত্ব থেকে প্রতিনিধিত্ব নির্মাণের জন্য ব্যবহার করা হয়েছে। কম্পোজিশন মডেল সাধারণত একটি দুই প্রান্তের দিকে অবস্থিত। তাদের কাছে কিছু সংখ্যার সংখ্যা আছে কিন্তু একই ভাবে সব শব্দগুলো তৈরি করে, অথবা তারা শব্দ-নির্দিষ্ট সংখ্যাগুলোর মূল্যে বেশী বড়। এই কাগজটিতে আমরা প্রস্তাব করছি পরিবর্তনের ওজন (ট্রান্সউইটট), একটি সংস্করণ মডেল যা নিয়মিত মোডেলের বিষয়বস্তুতে বিদ্যমান মডেল প্রদর্শন করে, সংযোগিতা নির্ধারিত বাক্য, এবং ইং ট্রান্সউইটটি সাহিত্যের সেরা মডেলের সাথে তুলনায় প্রয়োজনীয় পরামিতির সংখ্যা কমিয়ে দিয়েছে একই ভাবে একই কথা তুলে ধরে।', 'cs': 'Kompoziční modely distribuční sémantiky slouží k konstrukci frázových reprezentací z reprezentací jejich slov. Kompoziční modely jsou obvykle umístěny na dvou koncích spektra. Buď mají malý počet parametrů, ale skládají všechny fráze stejným způsobem, nebo provádějí slovně specifické kompozice za cenu mnohem většího počtu parametrů. V tomto článku navrhujeme transformační vážení (TransWeight), kompoziční model, který konzistentně překonává existující modely na jmenových sloučeninách, adjektivně-podstatných frázích a příslovně-adjektivních frázích v angličtině, němčině a nizozemštině. TransWeight drasticky snižuje počet potřebných parametrů ve srovnání s nejlepším modelem v literatuře složením podobných slov stejným způsobem.', 'et': 'Distributsioonilise semantika kompositsioonimudeleid kasutatakse fraaside esitamiseks nende sõnade esitustest. Kompositsioonimudelid asuvad tavaliselt spektri kahel otsal. Neil on kas väike arv parameetreid, kuid nad koostavad kõik fraasid samamoodi, või nad teevad sõnaspetsiifilisi kompositsioone palju suurema arvu parameetrite hinnaga. Käesolevas töös pakume välja transformatsiooni kaalumine (TransWeight), kompositsioonimudel, mis järjekindlalt ületab olemasolevaid mudeleid nominaalsete ühendite, omadussõna-nimisõna fraaside ja adverb-omadussõna fraaside osas inglise, saksa ja hollandi keeles. TransWeight vähendab oluliselt vajalike parameetrite arvu võrreldes kirjanduse parima mudeliga, koostades sarnaseid sõnu samal viisil.', 'fi': 'Jakelusemantiikan koostumusmalleja käytetään muodostamaan fraasiesityksiä niiden sanojen esittämisestä. Koostumusmallit sijaitsevat tyypillisesti spektrin kahdessa päässä. Niillä on joko pieni määrä parametreja, mutta ne muodostavat kaikki lauseet samalla tavalla, tai ne suorittavat sanakohtaisia sävellyksiä paljon suuremman määrän parametreja kustannuksella. Tässä työssä ehdotamme muunnospainotusta (TransWeight), joka on koostumusmalli, joka on johdonmukaisesti parempi kuin olemassa olevat mallit nimellisten yhdisteiden, adjektiivi-substantiivilauseoiden ja adverbi-adjektiivilauseiden osalta englanniksi, saksaksi ja hollanniksi. TransWeight vähentää merkittävästi tarvittavien parametrien määrää kirjallisuuden parhaaseen malliin verrattuna säveltämällä samankaltaisia sanoja samalla tavalla.', 'az': 'Sözlərinin ifadələrindən ifadələr inşa etmək üçün dağıtıcı semantik modelləri istifadə edilir. Komposisyon modelləri genellikle bir spektrumun iki ucunda yerləşdirilir. Onlar ya küçük bir sayı parametrlərin var, lakin bütün ifazləri eyni yolla birləşdirirlər, ya da daha böyük bir sayı parametrlərin müqabilində yazılmış sözləri ilə birləşdirirlər. Bu kağızda transformasyon a ğırlığını (TransWeight) təklif edirik. Bu, nominal birliklərdə, adjektiv-isimli sözlər və İngilizce, Alman və Holandik dilində adverb-adjektiv sözləri müəyyən edir. TransWeight həmçin in həmçinin bənzər sözləri yazıb dəftərdəki ən yaxşı modellərlə müqayisədə ehtiyacı olan parametron sayını dəyişdirir.', 'jv': 'Sample Sample Sample Tulung Sample rate Debian testing parameters Nang pepulan iki, kita supoyo nggawe ndhukung nggunggo urip nggawe Kasi, model sing dadi nyimpen kuwi model sing isih saben nggawe biyanan input dhéwé, adiectve-nambarang, lan basa-adiectve nggo inggilis, German, lan Olunalan. Name', 'he': 'מודלים מורכבים של סמנטיקה פיצוחית משתמשים לבנות מיצוגים ביטויים מהמיצוגים של המילים שלהם. דוגמני מורכב נמצאים בדרך כלל בשני קצוות של ספקטרום. או שיש להם מספר קטן של פרמטרים, אך מורכבים את כל המשפטים באותה הדרך, או שהם מבצעים פיצועים מסויימים למילים במחיר של מספר הרבה יותר גדול של פרמטרים. In this paper we propose transformation weighting (TransWeight), a composition model that consistently outperforms existing models on nominal compounds, adjective-noun phrases, and adverb-adjective phrases in English, German, and Dutch.  משקל טרנס מפחיד באופן דרסטי את מספר הפרמטרים הנדרשים בהשוואה לדוגמא הטובה ביותר בספרות על ידי רישום מילים דומות באותה הדרך.', 'ha': "@ info Ana zama misalin Composition a ɗabi'a, ana sitar da bakin biyu na bakin wani spectrum. Suna da ƙidãyar parameteri guda ko kuma su sami duk mistakardar da ke daidaita, ko kuma su cika composition na-ƙayyade da kwamfyutan da aka fi girma. A cikin wannan takardan, Munã buɗa musammali masu nau'i (TransWet), wata motel mai daidaita wanda ke samu da shi yana samar da misãlai masu gaba a kan ƙananan masu daidai, da fassarar-na'urar-juyi, da maganar-juyi cikin Ingirin, Jarman da kuma Dutsun. TransWeight drastically reduces the number of parameters needed compared with the best model in the literature by composing similar words in the same way.", 'sk': 'Komposicijski modeli distribucijske semantike se uporabljajo za gradnjo fraznih reprezentacij iz reprezentacij njihovih besed. Modeli kompozicije so običajno nameščeni na dveh koncih spektra. Imajo bodisi majhno število parametrov, vendar sestavljajo vse fraze na enak način, ali pa izvajajo besedno specifične kompozicije za ceno veliko večjega števila parametrov. V prispevku predlagamo transformacijsko tehtanje (TransWeight), model kompozicije, ki dosledno presega obstoječe modele pri nominalnih spojinah, pridevnikih-samostalnih frazah in pridevnikih-pridevnikih v angleščini, nemščini in nizozemščini. TransWeight drastično zmanjšuje število potrebnih parametrov v primerjavi z najboljšim modelom v literaturi s sestavljanjem podobnih besed na enak način.', 'bo': 'Composition models of distributional semantics are used to construct phrase representations from the representation of their words. མཛོད་ཁང་མིག་དཔེ་དབྱིབས་སྣང་གི་བརྗོད་ཀྱི་མཐའ་གཉིས་ཀྱི་ནང་དུ་ཡོད་པ་རེད། They either have a small number of parameters but compose all phrases in the same way, or they perform word-specific compositions at the cost of a far larger number of parameters. འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་རྗེས་སུ་བཟོ་བཅོས་མཁན་དག་པ་དེ་ནི་རྣམ་པ་ཅིག་གིས་ཡོད་པའི་མིག་ཆའི་སྐྱེས་ཚིག་དང་། TransWeight drastically reduces the number of parameters needed compared with the best model in the literature by composing similar words in the same way.'}
