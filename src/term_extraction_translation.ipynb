{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from models.llm import call\n",
    "from models.utils import *\n",
    "from models.config import get_model_config\n",
    "\n",
    "# from prompts import *\n",
    "\n",
    "out = open('/dev/stdout', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'llama3_8b'\n",
    "# def llm_config_func(llm):\n",
    "#     llm.temperature = 0\n",
    "#     llm.max_tokens = 4096\n",
    "#     return llm\n",
    "# config = get_model_config(model)\n",
    "\n",
    "### llama2 7b\n",
    "# model = 'llama2_7b'\n",
    "# def llm_config_func(llm):\n",
    "#     llm.temperature = 0\n",
    "#     llm.max_tokens = 2048\n",
    "#     return llm\n",
    "# config = get_model_config(model)\n",
    "\n",
    "### gpt3.5\n",
    "model = 'gpt-3.5-turbo'\n",
    "def llm_config_func(llm):\n",
    "    llm.temperature = 0.8\n",
    "    llm.max_tokens = 4096\n",
    "    return llm\n",
    "config = get_model_config(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mc_file_paths = []\n",
    "for filename in os.listdir(\"data_model_cards/claude3\"):\n",
    "    mc_file_paths.append(\"data_model_cards/claude3/\"+filename)\n",
    "\n",
    "f = open(mc_file_paths[0], \"r\")\n",
    "mc_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting scientific jargon from English model cards\n",
    "\n",
    "prompt = [\n",
    "    \"\"\"You are a language expert with a focus on machine translation. Your task is to analyze the following text and identify scientific jargon or terminology within the field of machine learning that might be challenging for machine translation software to accurately translate. List these terms in a clear, concise format.\n",
    "        Response Format: [Term 1, Term 2, Term 3, ...]\"\"\",\n",
    "        \n",
    "    \"\"\"The following text is:\n",
    "       \"{text}\"\n",
    "    \"\"\".format(text=mc_text)\n",
    "]\n",
    "\n",
    "res = call(\n",
    "    prompt,\n",
    "    llm_config_func,\n",
    "    has_system_prompt=True,\n",
    "    model_version=model,\n",
    "    verbose=True,\n",
    "    **config\n",
    ")\n",
    "\n",
    "term_lst = list(map(lambda s: s.strip(), res[1:-1].split(\",\"))) # could be better \n",
    "\n",
    "print(res, term_lst, file=out)\n",
    "\n",
    "# translating scientific jargon into other languages and store in dictionary "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
