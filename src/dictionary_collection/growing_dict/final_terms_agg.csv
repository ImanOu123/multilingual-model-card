,google_English,google_Arabic,gpt35_Arabic,claude3_Arabic,google_Chinese,gpt35_Chinese,claude3_Chinese,google_French,gpt35_French,claude3_French,google_Japanese,gpt35_Japanese,claude3_Japanese,google_Russian,gpt35_Russian,claude3_Russian
0,10-fold cross validation,10 أضعاف التحقق من صحة الصليب,التحقق الصلب المتقاطع بمقدار ١٠ أضعاف,تحقق مضاعف العشرة,10倍交叉验证,十折交叉验证,10-折交叉验证,Validation croisée 10 fois,- 10-fold validation croisée,validation croisée 10 fois,10 分割相互検証,10倍交差検証,10分割交差検証,10-кратная перекрестная проверка,"""['10-кратные разбиения датасета Мы предоставляем количество кластеров и антител в каждой части нашей 10-кратной перекрестной проверки. При выборе части i для тестирования мы используем часть i − 1 для валидации (для части 1 в качестве тестового набора",10-кратная перекрестная проверка
1,1d convolution,1D الإلتواء,- التصفيح الأحادي البُعد,عملية التضمين الأحادية البعد,一维卷积,1D 卷积,一维卷积 (1d convolution),convolution 1d,Convolution 1D,convolution 1d,1次元畳み込み,1次元畳み込み,1次元畳み込み,1d свертка,1D свертка,одномерная свертка
2,2 norm,2 القاعدة,القاعدة 2,معيار 2,2 标准,2范数,2范数,2 norme,norme 2,Norme 2,2 ノルム,2 ノルム,2ノルム,2 норма,2 норма,Норма-2
3,2d convolution,الإلتواء 2D,التبعية الثنائية الأبعاد,تراصف ثنائي الأبعاد,二维卷积,2D 卷积,二维卷积,convolution 2D,convolution 2D,convolution 2D,2次元畳み込み,2D畳み込み,2次元畳み込み,2d свертка,2D свертка,2d свертка
4,2d image,صورة ثنائية الأبعاد,صورة ثنائية الأبعاد,صورة ثنائية الأبعاد,二维图像,2D 图像,二维图像,image 2D,image 2D,image 2D,2D画像,2D 画像,2次元画像,2D изображение,2d изображение,2D изображение
5,2d image synthesis,تركيب الصور ثنائية الأبعاد,تخليق صور ثنائية الأبعاد,تركيب الصور ثنائية الأبعاد,二维图像合成,2D图像合成,2d图像合成,Synthèse d'images 2D,Synthèse d'images 2D,synthèse d'images 2D,2D画像合成,2次元画像合成,2次元画像合成,синтез 2D-изображений,Синтез изображений 2D,Синтез двумерного изображения
6,2d-3d correspondence,المراسلات ثنائية وثلاثية الأبعاد,المراسب ثنائية الأبعاد والثلاثية الأبعاد,مقابلة ثنائية الأبعاد - ثلاثية الأبعاد,2d-3d对应,2D-3D对应,二维三维对应关系,correspondance 2D-3D,correspondance 2D-3D,correspondances 2d-3d,2D-3D対応,2D-3D対応,2次元-3次元対応,2д-3д переписка,2D-3D соответствие,2D-3D соответствие
7,3d bounding box,مربع محيط ثلاثي الأبعاد,صندوق تحديد ثلاثي الأبعاد,صندوق احتواء ثلاثي الأبعاد,3d 边界框,3D边界框,三维包围盒,Boîte englobante 3D,boîte englobante 3D,boîte englobante 3D,3Dバウンディングボックス,3D バウンディングボックス,3次元バウンディングボックス,3D ограничительная рамка,3D ограничивающий параллелепипед,трехмерный ограничивающий параллелепипед
8,3d computer vision,رؤية حاسوبية ثلاثية الأبعاد,رؤية الحاسوب ثلاثية الأبعاد,الرؤية الحاسوبية ثلاثية الأبعاد,3D计算机视觉,三维计算机视觉,三维计算机视觉,Vision par ordinateur 3D,- Vision par ordinateur 3D,La vision par ordinateur 3D,3Dコンピュータビジョン,3Dコンピュータビジョン,3次元コンピュータビジョン,3D компьютерное зрение,3D компьютерное зрение,трехмерное компьютерное зрение
9,3d convolutional network,شبكة تلافيفية ثلاثية الأبعاد,شبكة التحويل الثنائي الثلاثي الأبعاد,شبكة التضمين ثلاثية الأبعاد,3d 卷积网络,三维卷积网络 (3d convolutional network),三维卷积网络,Réseau convolutif 3D,réseau convolutionnel 3D,réseau convolutionnel 3D,3D畳み込みネットワーク,3D 畳み込みネットワーク (3D convolutional network),3次元畳み込みネットワーク,3D сверточная сеть,3D сверточная сеть,трёхмерная сверточная сеть
10,3d geometry,هندسة ثلاثية الأبعاد,هندسة ثلاثية الأبعاد,هندسة ثلاثية الأبعاد,3d 几何,三维几何,三维几何,Géométrie 3D,géométrie 3D,géométrie 3D,3D ジオメトリ,3Dジオメトリ,3次元ジオメトリ,3d геометрия,трёхмерная геометрия,3D геометрия
11,3d human pose estimation,تقدير وضعية الإنسان ثلاثي الأبعاد,تقدير وضع الإنسان ثلاثي الأبعاد,تقدير وضعية الجسم البشري ثلاثي الأبعاد,3d 人体姿势估计,3D人体姿态估计,三维人体姿态估计,Estimation de la pose humaine en 3D,estimation de la pose humaine en 3D,estimation de la pose humaine 3D,3D 人間の姿勢推定,3次元人間ポーズ推定,3次元人体姿勢推定,3D оценка позы человека,оценка позы человека в 3D,оценка 3D-позы человека
12,3d localization,توطين ثلاثي الأبعاد,التموقع ثلاثي الأبعاد,تحديد المواقع ثلاثي الأبعاد,3D 定位,三维定位,三维定位,localisation 3D,localisation 3D,Localisation 3D,3D ローカリゼーション,3Dローカライゼーション,3次元位置推定,3D локализация,3D локализация,3D локализация
13,3d mesh,شبكة ثلاثية الأبعاد,شبكة ثلاثية الأبعاد,شبكة ثلاثية الأبعاد,3d 网格,3D网格,3d 网格,maillage 3D,maillage 3D,maillage 3D,3Dメッシュ,3Dメッシュ,3次元メッシュ,3d сетка,3D сетка,3D меш
14,3d model,نموذج 3D,نموذج ثلاثي الأبعاد,نموذج ثلاثي الأبعاد,3d模型,三维模型,三维模型,modèle 3D,modèle 3D,modèle 3D,3Dモデル,3Dモデル,3Dモデル,3D модель,3D модель,3D-модель
15,3d object detection,كشف الكائنات ثلاثية الأبعاد,اكتشاف الكائنات ثلاثية الأبعاد,الكشف عن الكائنات ثلاثية الأبعاد,3D 物体检测,3D物体检测,三维目标检测,Détection d'objets 3D,détection d'objet en 3D,détection d'objets 3D,3Dオブジェクト検出,3次元物体検出 (3d object detection),3次元物体検出,Обнаружение 3D-объектов,3D обнаружение объектов,обнаружение 3D-объектов
16,3d point,نقطة ثلاثية الأبعاد,نقطة ثلاثية الأبعاد,نقطة ثلاثية الأبعاد,3d 点,三维点,三维点,point 3D,point 3D,point 3D,3Dポイント,3Dポイント,3次元点,3d точка,3D точка,3D точка
17,3d point cloud,سحابة نقطة ثلاثية الأبعاد,- تجميع نقاط ثلاثية الأبعاد,سحابة نقاط ثلاثية الأبعاد,3d 点云,三维点云,3D 点云,Nuage de points 3D,nuage de points 3D,Nuage de points 3D,3D点群,3D ポイントクラウド,3次元ポイントクラウド,3D облако точек,3D облако точек,облако точек 3D
18,3d pose,تشكل 3D,- توجيه ٣D,وضعية ثلاثية الأبعاد,3d 姿势,三维姿势,三维姿态,pose 3D,pose 3D,pose 3D,3Dポーズ,3Dポーズ,3次元ポーズ,3D поза,3D поза,позиция 3D
19,3d reconstruction,إعادة الإعمار ثلاثية الأبعاد,- التكوين ثلاثي الأبعاد,استنساخ ثلاثي الأبعاد,3D重建,三维重建,三维重建,reconstitution 3D,reconstruction 3D,reconstruction 3D,3D再構成,3D再構築,3次元再構築,3D реконструкция,3D реконструкция,Трехмерная реконструкция
20,3d scene,مشهد ثلاثي الأبعاد,المشهد ثلاثي الأبعاد,مشهد ثلاثي الأبعاد,3d 场景,3D场景,三维场景,scène 3D,- 3D scène,Scène 3D,3Dシーン,3Dシーン,3次元シーン,3D сцена,3D сцена,трёхмерная сцена
21,3d scene geometry,هندسة المشهد ثلاثي الأبعاد,هندسة المشهد ثلاثية الأبعاد,نهجية هندسة المشهد ثلاثي الأبعاد,3D场景几何,3D场景几何形状,3D场景几何,Géométrie de la scène 3D,géométrie de scène 3D,géométrie de la scène 3D,3Dシーンジオメトリ,3Dシーンのジオメトリ,3次元シーンジオメトリ,геометрия 3D сцены,3D сценарий геометрии,геометрию 3D-сцены
22,3d structure,هيكل ثلاثي الأبعاد,الهيكل ثلاثي الأبعاد,البنية ثلاثية الأبعاد,3D结构,三维结构,三维结构,Structure 3D,structure en 3D,structure 3D,3D構造,3次元構造,3次元構造,3D структура,3D структура,3D структура
23,5-fold cross validation,التحقق من الصحة عبر 5 أضعاف,التقسيم المتقاطع الخماسي,التحقق المتقاطع ذو الخمس طيات,5倍交叉验证,5倍交叉验证,5重交叉验证,Validation croisée 5 fois,Validation croisée à 5 volets,validation croisée 5 fois,5 分割相互検証,5分割交差検証,5分割交差検証,5-кратная перекрестная проверка,5-кратная перекрестная проверка,5-кратная перекрестная проверка
24,Adafactor,ادافاكتور,أدافاكتور,عامل آدا,阿达法特,"Adafactor
自适应因子",Adafactor,Adaptateur,Adafactor,Adafactor,アダファクター,アダファクタ,Adafactorのまま,Адафактор,Adafactor,Adafactor
25,Adam,آدم,آدم,آدم,亚当,Adam,Adam,Adam,Adam,Adam,アダム,アダム,アダム,Адам,Адам,Адам
26,Adam algorithm,خوارزمية آدم,خوارزمية آدم,خوارزمية آدم,亚当算法,Adam算法,Adam算法,Algorithme d'Adam,algorithme Adam,algorithme Adam,アダムアルゴリズム,アダムアルゴリズム (Adam algorithm),Adamアルゴリズム,Алгоритм Адама,алгоритм Адам,Алгоритм Адама
27,Adam optimiser,آدم محسن,محسن آدم,معادل آدم,亚当优化器,Adam 优化器,Adam优化器,Optimiseur Adam,optimiseur Adam,optimiseur Adam,アダム・オプティマイザー,Adamオプティマイザ,Adamoputimaizā,Адам оптимизатор,Оптимизатор Адам,Оптимизатор Адама
28,Adam optimization,آدم الأمثل,تحسين آدم,محسّن آدم,亚当优化,Adam 优化算法,Adam优化算法,Optimisation Adam,optimisation Adam,optimisation Adam,アダムの最適化,Adam最適化,Adam 最適化,Оптимизация Адама,Оптимизация Адама,Оптимизация Адама
29,Adam optimization algorithm,خوارزمية التحسين آدم,- تحسين خوارزمية آدم,خوارزمية تحسين آدم,Adam优化算法,Adam 优化算法,Adam优化算法,Algorithme d'optimisation d'Adam,algorithme d'optimisation Adam,algorithme d'optimisation Adam,Adam 最適化アルゴリズム,Adam最適化アルゴリズム,Adamの最適化アルゴリズム,Алгоритм оптимизации Адама,алгоритм оптимизации Adam,Алгоритм оптимизации Адам
30,Adam optimizer,آدم محسن,محسن آدم,ُمحسِّن آدم,亚当优化器,Adam优化器,Adam优化器,Optimiseur Adam,- Optimiseur Adam,Optimiseur Adam,アダムオプティマイザー,Adamオプティマイザ,Adamの最適化手法,Адам оптимизатор,Оптимизатор Адам,Оптимизатор Адама
31,Apriori,أبريوري,أبيريوري,خوارزمية أبريوري,阿普里奥里,先验，Apriori,先验,A priori,Apriori,Apriori,アプリオリ,アプリオリ,アプリオリ,Априори,Априори,Априори
32,Artificial Intelligence,الذكاء الاصطناعي,الذكاء الاصطناعي,الذكاء الاصطناعي,人工智能,人工智能 (Artificial Intelligence),人工智能,Intelligence artificielle,- Intelligence Artificielle,Intelligence Artificielle,人工知能,人工知能 (Jinkō chino),人工知能,Искусственный интеллект,Искусственный интеллект,Искусственный интеллект
33,Autoencoder,التشفير التلقائي,تشفير تلقائي,شفرة ذاتية,自动编码器,自动编码器,自编码器,Encodeur automatique,Autoencodeur,Autoencoder,オートエンコーダー,"""['我々は、オートエンコーダーアーキテクチャのための新しい自己教師付きトレーニング戦略を提案しており、合成ビューのみで訓練することで、さまざまなRGBセンサー上で堅牢な3Dオブジェクトの向き推定を可能にしています。', '2層",自己エンコーダ,Автоэнкодер,Автоэнкодер,Автокодировщик
34,Autonomous Systems,الأنظمة الذاتية,أنظمة مستقلة,أنظمة مستقلة,自治系统,自主系统 (Autonomous Systems),自主系统,Systèmes autonomes,Systèmes autonomes,Systèmes autonomes,自律システム,自律システム (Jiritsu Shisutemu),自律システム,Автономные системы,Автономные системы,Автономные Системы (AS)
35,Azuma-Hoeffding inequality,عدم المساواة بين أزوما وهوفدينج,معادلة آزوما-هوفدينغ,متباينة أزوما-هوفدينج,东-霍夫丁不等式,阿兹玛-霍夫丁不等式,Azuma-Hoeffding 不等式,Inégalité d'Azuma-Hoeffding,Inégalité d'Azuma-Hoeffding,inégalité d'Azuma-Hoeffding,東・ヘフディング不等式,吾妻-ヘフディングの不等式,アズマ-ホフディング不等式,Неравенство Азумы-Хефдинга,Неравенство Ацумы-Хефдинга,Неравенство Азумы-Хёффдинга
36,B-spline,ب-الخط,- B-سبلاين,سبلين-بي,B样条,B-样条,B-样条曲线,Spline B,B-spline,B-spline,B スプライン,B-スプライン,B-スプライン,B-сплайн,B-сплайн,B-сплайн
37,Baseline,حدود,المعيار,مستوى أساسي,基线,基准 (Baseline),基线,Référence,Référence,Référence,ベースライン,ベースライン,ベースライン,Базовый уровень,Базовый (Baseline),Базовая линия
38,Basis Pursuit,السعي الأساس,السعي وراء الأساسية,مُلاحَقَة الأساس,基础追求,基 Pursuit,基追求,Poursuite de base,Recherche de base,Poursuite de Base,基礎の追求,ベイシス追求,基底追跡,Базовое преследование,Погоня за основами,Поиск базиса
39,Baum-Welch algorithm,خوارزمية باوم ويلش,خوارزمية باوم-ويلش,خوارزمية باوم-ويلش,鲍姆-韦尔奇算法,Baum-Welch 算法,鲍姆-韦尔奇算法,Algorithme de Baum-Welch,algorithme Baum-Welch,algorithme de Baum-Welch,バウム・ウェルチアルゴリズム,Baum-Welch アルゴリズム,ボーム・ウェルチアルゴリズム,Алгоритм Баума-Уэлча,Алгоритм Баума-Велша,алгоритм Баума-Велша
40,Bayes,بايز,بيز,بايز,贝叶斯,贝叶斯,贝叶斯,Bayès,Bayes,Bayes,ベイズ,ベイズ,ベイズ,Байес,Байес,Байес
41,Bayes classifier,مصنف بايز,- تصنيف بايز,طبقة بايز,贝叶斯分类器,贝叶斯分类器,贝叶斯分类器,Classificateur Bayesien,classifieur de Bayes,Classifieur bayésien,ベイズ分類器,ベイズ分類器,ベイズ分類器,классификатор Байеса,- Bayes классификатор,Байесовский классификатор
42,Bayes factor,عامل بايز,عامل بايز,عامل بايز,贝叶斯因子,贝叶斯因子,贝叶斯因子,Facteur Bayes,Facteur de Bayes,Facteur de Bayes,ベイズ因子,ベイズ因子,ベイズ因子,Байесовский фактор,Фактор Байеса,Фактор Байеса
43,Bayes formula,صيغة بايز,صيغة بايز,قانون بايز,贝叶斯公式,贝叶斯公式,贝叶斯公式,Formule de Bayes,formule de Bayes,formule de Bayes,ベイズの公式,ベイズの定理,ベイズの定理,Формула Байеса,Формула Байеса,формула Байеса
44,Bayes net,صافي بايز,شبكة بايزية,شبكة بايز,贝叶斯网,贝叶斯网络 (Bayes net),贝叶斯网络,Filet bayésien,réseau Bayésien,réseau bayésien,ベイズネット,ベイズネット,ベイズネット,Байесовская сеть,байесовская сеть,Байесовская сеть
45,Bayes optimal classifier,بايز المصنف الأمثل,المصنف الأمثل بنظرية بايس,مصنف بايز الأمثل,贝叶斯最优分类器,贝叶斯最优分类器,贝叶斯最优分类器,Classificateur optimal de Bayes,classifieur optimal de Bayes,Classifieur optimal bayésien,ベイズ最適分類器,ベイズ最適分類器 (Bayes optimal classifier),ベイズ最適分類器,Оптимальный классификатор Байеса,Баесовский оптимальный классификатор,Байесовский оптимальный классификатор
46,Bayes risk,خطر بايز,مخاطر بايز,مخاطر بايز,贝叶斯风险,贝叶斯风险,贝叶斯风险,Risque bayésien,risque de Bayes,risque de Bayes,ベイズリスク,ベイズリスク,ベイズリスク,Байесовский риск,Риск Байеса,байесовский риск
47,Bayes risk decoding,بايز يخاطر بفك التشفير,فك تشفير المخاطر بايزية,حفظ الترميز لمخاطر بايز,贝叶斯风险解码,贝叶斯风险解码,贝叶斯风险解码,Décryptage du risque bayésien,décodage du risque de Bayes,Décodage du risque bayésien minimal,ベイズリスクデコーディング,ベイズリスク復号,ベイズリスク復号化,Декодирование байесовского риска,декодирование с минимальным риском Байеса,Байесовское рискованное декодирование
48,Bayes rule,حكم بايز,قاعدة بايز,شرط بايز,贝叶斯法则,贝叶斯定理,贝叶斯规则,Règle de Bayes,règle de Bayes,règle de Bayes,ベイズ則,ベイズの定理,ベイズの法則,Правило Байеса,Правило Байеса,Правило Байеса
49,Bayes theorem,مبرهنة بايز,نظرية بايز,نظرية بايز,贝叶斯定理,贝叶斯定理,贝叶斯定理,Théorème de Bayes,Théorème de Bayes,théorème de Bayes,ベイズの定理,ベイズの定理,ベイズの定理,Теорема Байеса,Теорема Байеса,Теорема Байеса
50,Bayes-Nash equilibrium,توازن بايز-ناش,- توازن بايس-ناش,توازن بايز-ناش,贝叶斯-纳什均衡,贝叶斯-纳什均衡,贝叶斯纳什均衡,Équilibre Bayes-Nash,Équilibre de Bayes-Nash,Équilibre de Bayes-Nash,ベイズ・ナッシュ均衡,ベイズ・ナッシュ均衡,ベイズ・ナッシュ均衡,Равновесие Байеса-Нэша,Равновесие Байеса-Наши,Равновесие по Байесу-Нэшу
51,Bayesian Network,شبكة بايزي,شبكة بايزية,شبكة بايزية,贝叶斯网络,贝叶斯网络,贝叶斯网络,Réseau bayésien,- Réseau bayésien,Réseau bayésien,ベイジアンネットワーク,ベイジアンネットワーク,ベイジアンネットワーク,Байесовская сеть,Байесовская сеть,Байесовская сеть
52,Beam Search,بحث شعاع,البحث بالشعاعات,البحث الشعاعي,波束搜索,束搜索,束搜索,Recherche de faisceau,Recherche en faisceau,Recherche par faisceau,ビームサーチ,ビームサーチ,ビーム探索,Поиск луча,Жучковый поиск,Лучевой поиск
53,Bellman,قارع الناقوس,بيلمان,بلمان,贝尔曼,贝尔曼,贝尔曼,Bellman,Bellman,Bellman,ベルマン,ベルマン,ベルマン,Беллман,Беллман,Беллман
54,Bellman backup,النسخ الاحتياطي بيلمان,نسخ احتياطي بيلمان,إرجاع بلمان,行李员备份,贝尔曼备份,Bellman 备份,Sauvegarde du Bellman,sauvegarde de Bellman,Mise à jour de Bellman,ベルマンバックアップ,ベルマン・バックアップ,ベルマンバックアップ,Резервное копирование Беллмана,Резервное копирование Беллмана,Беллмановское резервное копирование
55,Bellman equation,معادلة بيلمان,معادلة بيلمان,معادلة بلمان,贝尔曼方程,贝尔曼方程,贝尔曼方程,Équation de Bellman,équation de Bellman,équation de Bellman,ベルマン方程式,ベルマン方程式 (Bellman equation),ベルマン方程式,уравнение Беллмана,Уравнение Беллмана,Уравнение Беллмана
56,Bellman error,خطأ بيلمان,خطأ بيلمان,خطأ بلمان,贝尔曼错误,贝尔曼误差,贝尔曼误差,Erreur Bellman,erreur de Bellman,erreur de Bellman,ベルマンエラー,ベルマン誤差,ベルマン誤差,Ошибка Беллмана,ошибка Беллмана,погрешность Беллмана
57,Bellman operator,مشغل بيلمان,عامل بيلمان,معامل بيلمان,行李员接线员,贝尔曼算子,贝尔曼算子,Opérateur Bellman,opérateur de Bellman,opérateur de Bellman,ベルマンオペレーター,ベルマン演算子 (Beruman Enzanshi),ベルマン演算子,Оператор Беллмана,Оператор Беллмана,оператор Беллмана
58,Berkeley parser,محلل بيركلي,محلل بيركلي,محلل بيركلي,伯克利解析器,伯克利句法分析器,伯克利句法分析器,analyseur Berkeley,Analyseur de Berkeley,analyseur syntaxique de Berkeley,バークレーパーサー,バークレー・パーサー,バークレーパーサー,Парсер Беркли,Беркли парсер,Анализатор Беркли
59,Berkeley segmentation dataset,مجموعة بيانات تجزئة بيركلي,مجموعة بيانات تقسيم بيركلي,مجموعة بيانات تقطيع بيركلي,伯克利分割数据集,伯克利分割数据集,伯克利分割数据集,Ensemble de données de segmentation de Berkeley,Ensemble de données de segmentation de Berkeley,Ensemble de données de segmentation de Berkeley,バークレーのセグメンテーション データセット,バークレー・セグメンテーション・データセット,バークレー分割データセット,Набор данных сегментации Беркли,"""Из-за увеличения количества параметров модели мы обучаем RTF 2 и каждый последующий этап с 500 обучающими изображениями, случайным образом обрезанными из обучающей части набора данных сегментации Беркли [1] и размытыми с помощью случайно выбранных",Беркли набор данных для сегментации
60,Bernoulli,برنولي,بيرنولي,برنولي,伯努利,伯努利,伯努利分布,Bernoulli,Bernoulli,Bernoulli,ベルヌーイ,ベルヌーイ,ベルヌーイ,Бернулли,Бернулли,Бернулли
61,Bernoulli distribution,توزيع برنولي,توزيع برنولي,توزيع برنولي,伯努利分布,伯努利分布,伯努利分布,Distribution de Bernoulli,- Distribution de Bernoulli,distribution de Bernoulli,ベルヌーイ分布,ベルヌーイ分布,ベルヌーイ分布,Распределение Бернулли,Бернуллиевское распределение,распределение Бернулли
62,Bernoulli likelihood,احتمال برنولي,احتمالية بيرنولي,احتمالية برنولي,伯努利似然,贝努利似然率,伯努利似然,Probabilité de Bernoulli,Vraisemblance de Bernoulli,Vraisemblance de Bernoulli,ベルヌーイ尤度,ベルヌーイ尤度,ベルヌーイ尤度,Вероятность Бернулли,Логарифмическая функция правдоподобия Бернулли,Вероятность Бернулли
63,Bernoulli random variable,برنولي متغير عشوائي,المتغير العشوائي بيرنولي,متغير عشوائي برنولي,伯努利随机变量,伯努利随机变量,伯努利随机变量,Variable aléatoire de Bernoulli,Variable aléatoire de Bernoulli,Variable aléatoire de Bernoulli,ベルヌーイ確率変数,ベルヌーイ確率変数,ベルヌーイ確率変数,Случайная величина Бернулли,Случайная величина Бернулли,Бернуллиевская случайная переменная
64,Bernoulli sampling,أخذ عينات برنولي,- تعيين بيرنولي,سحب برنولي,伯努利采样,伯努利抽样,伯努利采样,Échantillonnage de Bernoulli,Échantillonnage de Bernoulli,échantillonnage de Bernoulli,ベルヌーイサンプリング,ベルヌーイサンプリング,ベルヌーイサンプリング,Выборка Бернулли,Сэмплирование Бернулли,Выборка Бернулли
65,Bernoulli trial,محاكمة برنولي,التجربة برنولي,محاولة برنولي,伯努利试验,伯努利试验,伯努利试验,Procès Bernoulli,Essai de Bernoulli,épreuve de Bernoulli,ベルヌーイ裁判,ベルヌーイ試行,ベルヌーイ試行,Суд над Бернулли,Бернуллиевский опыт,испытание Бернулли
66,Bernoulli variable,متغير برنولي,متغير بيرنولي,متغير برنولي,伯努利变量,伯努利变量,伯努利变量,Variable de Bernoulli,- Variable de Bernoulli,Variable de Bernoulli,ベルヌーイ変数,ベルヌーイ変数,ベルヌーイ変数,переменная Бернулли,Бернуллиевская переменная,Берноуллиевская переменная
67,Bernstein's inequality,عدم المساواة في برنشتاين,متساواة بيرنشتاين,انحراف برنشتاين,伯恩斯坦不等式,贝恩斯均衡定理,伯恩斯坦不等式,L'inégalité de Bernstein,- Inégalité de Bernstein,Inégalité de Bernstein,バーンスタインの不等式,ベルンシュタインの不等式 (Bernstein's inequality),ベルンシュタインの不等式,Неравенство Бернштейна,Неравенство Бернштейна,Неравенство Бернштейна
68,Bethe approximation,تقريب بيته,- تقريب بيثي,تقريب بيتي,贝特近似,Bethe逼近法,贝叶近似,Rapprochement de Bethe,approximation Bethe,L'approximation de Bethe,ベーテ近似,ベーテ近似,ベーテ近似,Приближение Бете,Аппроксимация Бете,Приближение Бете
69,Bhattacharyya coefficient,معامل بهاتاشاريا,معامل بهاتاشاريا,معامل بهاتاشاريا,巴氏系数,巴氏系数,巴查里亚系数,Coefficient de Bhattacharya,Coefficient de Bhattacharyya,coefficient de Bhattacharyya,バタチャリヤ係数,バッタチャリア係数 (Bhattacharyya coefficient),バタチャリヤ係数,Коэффициент Бхаттачарьи,Коэффициент Бхаттачарьи,коэффициент Бхаттачарьи
70,Boltzmann distribution,توزيع بولتزمان,توزيع بولتزمان,توزيع بولتزمان,玻尔兹曼分布,玻尔兹曼分布,玻尔兹曼分布,Distribution Boltzmann,- Distribution de Boltzmann,distribution de Boltzmann,ボルツマン分布,ボルツマン分布,ボルツマン分布,Распределение Больцмана,Распределение Больцмана,распределение Больцмана
71,Boltzmann exploration,استكشاف بولتزمان,استكشاف بولتزمان,استكشاف بولتزمان,玻尔兹曼探索,玻尔兹曼探索,波尔兹曼探索,Exploration Boltzmann,Exploration de Boltzmann,Exploration de Boltzmann,ボルツマン探査,ボルツマン探索,ボルツマン探索,Исследование Больцмана,Эксплорация Больцмана,исследование Больцмана
72,Bonferroni correction,تصحيح بونفيروني,تصحيح بونفيروني,تصحيح بونفيروني,邦费罗尼校正,邦费罗尼校正,本富罗尼校正,Correction de Bonferroni,Correction de Bonferroni,Correction de Bonferroni,ボンフェローニ補正,ボンフェローニ補正,ボンフェローニ補正,Поправка Бонферрони,Коррекция Бонферрони,Бонферрони-коррекция
73,Borda score,نقاط بوردا,نقاط بوردا,تقييم بوردا,博达分数,波达分数,波达分数,Score Borda,score de Borda,Score de Borda,ボルダスコア,ボルダ得点,ボルダ得点,Оценка Борда,Оценка Борда,Бордовые баллы
74,Bradley-Terry Model,نموذج برادلي تيري,نموذج برادلي تيري,نموذج برادلي-تيري,布拉德利-特里模型,Bradley-Terry模型,布拉德利-特里模型,Modèle Bradley-Terry,Modèle de Bradley-Terry,Modèle de Bradley-Terry,ブラッドリー・テリーモデル,ブラッドリー・テリーモデル (Bradley-Terry Model),ブラドリー・テリー・モデル,Модель Брэдли-Терри,Модель Брэдли-Терри,Модель Брэдли-Терри
75,Branch and Bound,فرع وملزمة,- تفرع وربط,تفريع وحصر,分支定界,分支定界,分支定界法,Branche et lié,"Branch and Bound ; et Branch and Bound itératif.', 'Ici, ils appliquent Branch and Bound et des sous-estimateurs convexes au problème général du problème bilinéaire, qui inclut (1), à la fois sous les normes L 1 et L 2. Cette approche est prouvée globalement optimale, mais est",Séparation et évaluation,ブランチアンドバウンド,枝刈り法,分枝限定法,Ветвь и граница,Метод ветвей и границ,Метод ветвей и границ
76,Bregman's method,طريقة بريجمان,طريقة بريغمان,طريقة بريغمان,布雷格曼法,布雷格曼方法,布雷格曼方法,La méthode de Bregman,méthode de Bregman,la méthode de Bregman,ブレグマン法,ブレーグマン法,ブレグマンの方法,метод Брегмана,Метод Брегмана,Метод Бреґмана
77,Chamfer distance,مسافة الشطب,مسافة التحلل,مسافة التفريغ,倒角距离,钗距离,锥切距离,Distance de chanfrein,- Distance de chanfrein,Distance de chanfrein,面取り距離,チャンファー距離,チャンファー距離,Расстояние фаски,Расстояние Чамфера,расстояние Чемфера (Chamfer distance)
78,Charniak parser,محلل تشارنياك,محلل تشارنياك,محلل تشارنياك,查尼亚克解析器,查尼亚克分析器,Charniak句法分析器,analyseur Charniak,Analyseur Charniak,analyseur syntaxique de Charniak,チャーニアックパーサー,チャーニアック・パーサー,チャーニアク構文解析器,Чарняк парсер,Charniak парсер,Парсер Чарньяка
79,Chebyshev acceleration,تسارع تشيبيشيف,تسارع شيبيشيف,تسريع شيبيشيف,切比雪夫加速度,切比雪夫加速,切比雪夫加速,Accélération de Chebyshev,Accélération de Chebyshev,Accélération de Tchebychev,チェビシェフ加速,チェビシェフ加速,チェビシェフ加速,Чебышевское ускорение,Ускорение Чебышева,Ускорение Чебышева
80,Chebyshev polynomial,تشيبيشيف متعدد الحدود,متعددات تشيبيشيف,متعدد حدود شيبيشيف,切比雪夫多项式,切比雪夫多项式 (Chebyshev polynomial),切比雪夫多项式,Polynôme de Tchebychev,polynôme de Chebyshev,polynôme de Chebyshev,チェビシェフ多項式,チェビシェフ多項式,チェビシェフ多項式,Полином Чебышева,Многочлен Чебышева,Многочлен Чебышева
81,Chomsky normal form,شكل تشومسكي العادي,صيغة تشومسكي العادية,الصيغة الشومسكية العادية,乔姆斯基范式,乔姆斯基范式,乔姆斯基范式,Forme normale de Chomsky,forme normale de Chomsky,forme normale de Chomsky,チョムスキー正規形,チョムスキー標準形,チョムスキー標準形,Нормальная форма Хомского,Форма Чомского-Нормала,Хомского нормальная форма
82,Chu-Liu-Edmonds algorithm,خوارزمية تشو ليو إدموندز,خوارزمية تشو ليو ادموندز,خوارزمية تشو-ليو-إدموندز,Chu-Liu-Edmonds 算法,朱刘艾德蒙兹算法,储流-埃德蒙兹算法,Algorithme de Chu-Liu-Edmonds,- Algorithme Chu-Liu-Edmonds,algorithme de Chu-Liu-Edmonds,Chu-Liu-Edmonds アルゴリズム,中留・リュー・エドモンズ法,朱留-エドモンズアルゴリズム,Алгоритм Чу-Лю-Эдмондса,Алгоритм Чу-Лю-Эдмондса,алгоритм Чу-Лю-Эдмондса
83,Chung-Lu model,نموذج تشونغ لو,نموذج تشانغ-لو,نموذج تشونغ-لو,中路模型,中鲁模型,重庆卢模型,Modèle Chung-Lu,modèle Chung-Lu,modèle de Chung-Lu,Chung-Lu モデル,中間ルモデル,チャン・ルーモデル,Модель Чунг-Лу,Модель Чжун-Лу,Модель Чунг-Лу
84,Cohen's kappa,كابا كوهين,كوهينز كابا,معامل كوهين كابا,科恩的卡帕,科恩的kappa,科恩's kappa,Le kappa de Cohen,kappa de Cohen,kappa de Cohen,コーエンのカッパ,Cohenのカッパ,コーヘンのカッパ,Каппа Коэна,Коэн каппа,Коэффициент каппа Коэна
85,Cohen's kappa coefficient,معامل كابا كوهين,معامل كوهين لكابا,معامل ارتباط كوهين,科恩卡帕系数,科恩的Kappa系数,科恩卡帕系数,Coefficient kappa de Cohen,Coefficient kappa de Cohen,Coefficient kappa de Cohen,コーエンのカッパ係数,コーエンのカッパ係数,コーヘンのカッパ係数,Коэффициент каппа Коэна,коэффициент каппа Коэна,Коэффициент каппа Коэна
86,Cohen's κ,كوهين ك,قيمة كوهين كابا,معامل كوهين كابا,科恩的κ,科恩的κ,Cohen's κ系数,Le κ de Cohen,Cohen's κ,Cohen's κ,コーエンのκ,コーエンのκ,コーヘンのカッパ係数,κ Коэна,Коэффициент κ Коэна,Коэффициент Коэна κ
87,Condorcet winner,الفائز كوندورسيه,الفائز كوندورسيه,الفائز كوندورسيه,孔多塞获胜者,Condorcet 胜者,康多塞特获胜者,Vainqueur Condorcet,gagnant de Condorcet,Vainqueur de Condorcet,コンドルセ優勝者,コンドルセ勝者,コンドルセ勝者,Победитель Кондорсе,Победитель по методу Кондорсе,Кондорсе победитель
88,Contrastive Learning,التعلم المتناقض,التعلم التبايني,التعلم التباينيّ,对比学习,对比学习,对比学习,Apprentissage contrasté,Apprentissage contrastif,Apprentissage contrastif,対照学習,コントラスティブラーニング,対照学習,Контрастное обучение,Контрастное обучение,Контрастное обучение
89,Coreset,مجموعة الأساسية,- تعظيم النواة,مجموعة أساسية,核心集,核心集,核心集,Ensemble de base,Noyau,Coeur d'ensemble,コアセット,コアセット,コアセット,Базовый набор,ядро (coreset),Массив данных
90,Corpora,الجسد,المواد اللغوية,مجموعات نصوص,语料库,//osf.io/53tfs/上找到。'，'通常，具有细粒度结构的语料库和检索任务涉及针对特定任务设置的检,语料库,Corpus,"//osf.io/53tfs/.', ""Les corpus et les tâches de recherche avec une structure fine généralement abordent le développement de systèmes de recherche construits à des",Corpus,コーパス,//osf.io/53tfs/,コーパス,Корпора,Корпусы,Корпусы
91,Corpus,جسم,مجموعة البيانات,مجموعة نصوص,语料库,语料库,语料库,Corpus,Corpus,Corpus,コーパス,コーパス,コーパス,Корпус,корпус,Корпус
92,Cosine Similarity,تشابه جيب التمام,التشابه الكوسيني,تشابه القِيم التآلفية,余弦相似度,余弦相似度,余弦相似性,Similitude cosinus,Similarité cosinus,Similarité cosinus,コサイン類似度,コサイン類似度,コサイン類似度,Косинусное сходство,Косинусное сходство,Косинусное сходство
93,Cosine distance,مسافة جيب التمام,المسافة الكوسينية,مسافة الجيب التربيعي,余弦距离,余弦距离,余弦距离,Distance cosinus,Distance cosinus,Distance cosinus,コサイン距離,コサイン距離,コサイン距離,Косинусное расстояние,Косинусное расстояние,Косинусное расстояние
94,Covariance,التغاير,التباين المشترك,تباين,协方差,协方差,协方差,Covariance,Covariance,Covariance,共分散,共分散,共分散,Ковариация,Ковариация,Ковариация
95,Datalog,سجل البيانات,داتالوج,قواعد البيانات,数据记录,数据日志 (Datalog),数据逻辑,Journal de données,Datalog,Datalog,データログ,データログ,データログ,Журнал данных,Datalog,Дейталог
96,Dataset,مجموعة البيانات,مجموعة البيانات,مجموعة البيانات,数据集,数据集,数据集,Base de données,Ensemble de données,ensemble de données,データセット,データセット (Dataset),データセット,Набор данных,Набор данных,Набор данных
97,Decoder,فك التشفير,"الفكك
Decoder",مفسر,解码器,解码器,解码器,Décodeur,Décodeur,Décodeur,デコーダ,デコーダー,デコーダ,Декодер,Декодер,Декодер
98,Deep Belief Network,شبكة الاعتقاد العميق,شبكة الاعتقاد العميقة,شبكة المعتقدات العميقة,深度信念网络,深度信念网络,深度信念网络,Réseau de croyance profonde,Réseau de Croyances Profondes,Réseau de croyances profondes,深い信念のネットワーク,ディープ・ビリーフ・ネットワーク,深層ビリーフネットワーク,Сеть глубоких убеждений,Глубокая сеть уверенности,Глубокая вероятностная сеть
99,Deep learning,تعلم عميق,التعلم العميق,تعلم عميق,深度学习,深度学习,深度学习,L'apprentissage en profondeur,Apprentissage profond,Apprentissage profond,ディープラーニング,ディープラーニング,深層学習,Глубокое обучение,Глубокое обучение,Глубокое обучение
100,Denoising Autoencoder,تقليل الضوضاء التشفير التلقائي,ترميز تلقائي للحذف الضوضاء,مصفي الضوضاء التلقائي,去噪自动编码器,降噪自编码器,去噪自编码器 (Denoising Autoencoder),Encodeur automatique de débruitage,Autoencodeur de débruitage,Autoencodeur de débruitage,ノイズ除去オートエンコーダー,デノイジングオートエンコーダ,デノイジングオートエンコーダー,Автоэнкодер с шумоподавлением,Декодировщик с удалением шума,Автокодировщик с подавлением шума
101,Detectron,كاشف,تحديدرون,كاشف,探测器,Detectron,探测器,Détectron,Detectron,Détectron,ディテクトロン,検出器 (Kenshutsuki),Detectron,Детектор,Detectron,Детектрон
102,Dijkstra's algorithm,خوارزمية ديكسترا,خوارزمية دايكسترا,خوارزمية ديكسترا,迪杰斯特拉算法,Dijkstra算法,Dijkstra算法,L'algorithme de Dijkstra,algorithme de Dijkstra,algorithme de Dijkstra,ダイクストラのアルゴリズム,ダイクストラのアルゴリズム,ディクストラ・アルゴリズム,Алгоритм Дейкстры,Алгоритм Дейкстры,Алгоритм Дейкстры
103,Dirac measure,قياس ديراك,قياس ديراك,قياس ديراك,狄拉克测度,狄拉克测度,狄拉克测度,Mesure de Dirac,Mesure de Dirac,mesure de Dirac,ディラック測定,ディラック測度 (Dirac measure),ディラックのmeasure,Мера Дирака,Мера Дирака,Мера Дирака
104,Dirichlet,ديريشليت,- التوزيع ديريشليه,ديريكلي,狄利克雷,狄利克雷,狄利克雷分布,Dirichlet,Dirichlet,Dirichlet,ディリクレ,ディリクレ,ディリクレ分布,Дирихле,Дирихле,Дирихле
105,Dirichlet prior,ديريشليت قبل,التوزيع السابق لديريشليه,افتراضية دريشليه,狄利克雷先验,狄利克雷先验,狄利克雷先验,Dirichlet prieur,prior de Dirichlet,loi a priori de Dirichlet,ディリクレ事前,ディリクレ先行分布,ディリクレ事前分布,Дирихле приор,Априорное распределение Дирихле,Распределение Дирихле
106,Dropout,أوقع,- تساقط,إسقاط,辍学,随机失活,丢弃,Abandonner,Dropout,Abandon,ドロップアウト,ドロップアウト,ドロップアウト,Выбывать,Dropout,Обратное распространение ошибки
107,Dynamic Programming,البرمجة الديناميكية,برمجة ديناميكية,البرمجة الديناميكية,动态规划,动态规划,动态规划,Programmation dynamique,Programmation dynamique,Programmation dynamique,動的プログラミング,ダイナミックプログラミング,動的計画法,Динамическое программирование,Динамическое программирование,Динамическое программирование
108,Elastic Net,شبكة مرنة,شبكة مرنة,شبكة مرنة,弹性网,弹性网,弹性网,Filet élastique,Réseau élastique,Réseau élastique,弾性ネット,エラスティックネット,エラスティックネット,Эластичная сетка,Эластичная сеть,Упругая Сеть
109,Electra,إلكترا,إلكترا,الكترا,伊莱克特拉,电气化,伊雷克特拉,Electre,Electra,Electra,エレクトラ,エレクトラ,Electra,Электра,Электра,Электра
110,Encoder-Decoder,التشفير-فك التشفير,المُشفر-فك المُشفر,مشفر - فك شفرة,编码器-解码器,编码器-解码器,编码器-解码器,Encodeur-Décodeur,Encodeur-Décodeur,Encodeur-Décodeur,エンコーダ-デコーダ,エンコーダー・デコーダー,エンコーダー・デコーダー,Кодер-декодер,Энкодер-декодер (ED),Кодер-декодер
111,Epanechnikov kernel,نواة إيبانيشنيكوف,نواة إبانيتشيكوف,متجه إيبانشنيكوف,埃帕内奇尼科夫内核,依巴内科夫核,Epanechnikov核,Noyau Epanechnikov,noyau d'Epanechnikov,noyau d'Epanechnikov,エパネチニコフカーネル,エパネチニコフカーネル,エパネチニコフカーネル,Ядро Епанечникова,ядро Эпанечникова,ядро Епанечникова
112,Euclidean,الإقليدية,يوروكليدية,القليدية,欧几里得,欧几里得,欧几里得,Euclidien,Euclidien,Euclidienne,ユークリッド,ユークリッド距離,ユークリッド,евклидов,Евклидов,Евклидово
113,Euler step,خطوة أويلر,خطوة أويلر,خطوة أويلر,欧拉步,欧拉步,欧拉步骤,étape d'Euler,pas d'Euler,pas d'Euler,オイラーステップ,オイラーステップ,オイラーステップ,шаг Эйлера,Эйлеров шаг,Шаг Эйлера
114,Fairseq,فيرسيك,Fairseq,Fairseq,费尔序列,Fairseq,Fairseq,Fairseq,Fairseq,Fairseq,フェアセク,Fairseq,Fairseq,Фэрсек,Fairseq,Fairseq
115,Fano's inequality,عدم المساواة فانو,عدم المساواة فانو,متراجحة فانو,法诺不等式,范诺不等式,法诺不等式,L'inégalité de Fano,Inégalité de Fano,inégalité de Fano,ファノの不等式,ファーノの不等式,ファノの不等式,Неравенство Фано,неравенство Фано,Неравенство Фано
116,Feature Pyramid Network,ميزة شبكة الهرم,شبكة الهرم الميزاتية,شبكة هرم الميزات,特征金字塔网络,特征金字塔网络,特征金字塔网络 (FPN),Réseau pyramidal de fonctionnalités,Réseau de pyramide de fonctionnalités (FPN),Réseau pyramidal de caractéristiques (FPN),機能ピラミッドネットワーク,特徴ピラミッドネットワーク (FPN),特徴ピラミッドネットワーク (FPN),Функциональная пирамидальная сеть,Сеть пирамид признаков,Сеть пирамиды признаков
117,Fleiss' kappa,فليس كابا,- تساوي فيلايس,معامل كابا لفلايس,弗莱斯河童,费利斯kappa,Fleiss'卡帕系数,Le kappa de Fleiss,kappa de Fleiss,Kappa de Fleiss,フライスのカッパ,フライスのカッパ,フリース・カッパ,Каппа Флейса,коэффициент каппа Флейса,каппа Флейсса
118,Floyd-Warshall algorithm,خوارزمية فلويد-وارشال,خوارزمية فلويد-وارشال,خوارزمية فلويد-وارشال,Floyd-Warshall 算法,弗洛伊德-沃舍尔算法,佛洛伊德-沃舍尔算法,Algorithme de Floyd-Warshall,algorithme de Floyd-Warshall,algorithme de Floyd-Warshall,フロイド・ウォーシャルアルゴリズム,フロイド・ワーシャル法,フロイド・ワーシャル・アルゴリズム,Алгоритм Флойда-Уоршалла,Алгоритм Флойда-Уоршелла,Алгоритм Флойда-Уоршелла
119,Fokker-Planck equation,معادلة فوكر-بلانك,معادلة فوكر-بلانك,معادلة فوكر-بلانك,福克-普朗克方程,福克-普朗克方程,福克-普朗克方程,équation de Fokker-Planck,équation de Fokker-Planck,Équation de Fokker-Planck,フォッカー・プランク方程式,フォッカー・プランク方程式,フォッカー・プランク方程式,Уравнение Фоккера-Планка,Уравнение Фоккера-Планка,Уравнение Фоккера-Планка
120,Fourier Transform,تحويل فورييه,- التحويلات الفورية,تحويل فورييه,傅里叶变换,傅里叶变换,傅里叶变换,Transformée de Fourier,Transformation de Fourier,Transformée de Fourier,フーリエ変換,フーリエ変換,フーリエ変換,Преобразование Фурье,Преобразование Фурье,Преобразование Фурье
121,Frobenius Norm,معيار فروبينيوس,المعيار الفروبنيوس,معيار فروبينيوس,弗罗贝尼乌斯范数,弗罗贝尼乌斯范数,弗罗贝尼乌斯范数,Norme de Frobenius,Norme de Frobenius,Norme de Frobenius,フロベニウス・ノルム,フロベニウス・ノルム,フロベニウスノルム,Фробениус Норма,Норма Фробениуса,Норма Фробениуса
122,Frobenius inner product,فروبينيوس المنتج الداخلي,- التحليل الداخلي فروبنيوس,المنتج الداخلي الفروبينيوسي,弗罗贝尼乌斯内积,弗罗贝尼乌斯内积,傅立叶内积,Produit intérieur Frobenius,Produit scalaire de Frobenius,produit scalaire de Frobenius,フロベニウスの内積,フロベニウス内積,フロベニウス内積,Внутренний продукт Фробениуса,Произведение Фробениуса,Фробениусово скалярное произведение
123,Fréchet,فريشيه,- تقديرات فريشيت,مطلق,弗雷谢特,弗雷歇,弗雷舍分布,Fréchet,Fréchet,Fréchet,フレシェ,フレシェ,フレシェ分布,Фреше,"""['Для демонстрации того, что ненулевые значения α могут привести к лучшим оценкам ln Z в настройке низкоранговых возмущений, мы сравниваем границы Фреше и трюки Вейбулла U(α) с границей трюка Гумбеля U(0) на общей дискретной графической модели с",Фреше
124,Gamma prior,جاما قبل,الأولوية الجاما,توزيع جاما السابق,伽玛先验,伽马先验,Gamma先验,Gamma avant,Prior Gamma,loi a priori gamma,ガンマ事前,ガンマ事前分布 (Gamma prior),ガンマ事前分布,Гамма приор,- Гамма-априорное,гамма-распределение
125,Gauss-Newton algorithm,خوارزمية غاوس-نيوتن,خوارزمية غاوس-نيوتن,خوارزمية غاوس-نيوتن,高斯-牛顿算法,高斯-牛顿算法,高斯-牛顿算法,Algorithme de Gauss-Newton,algorithme Gauss-Newton,algorithme de Gauss-Newton,ガウスニュートンアルゴリズム,ガウス・ニュートン法,ガウス・ニュートン法,Алгоритм Гаусса-Ньютона,Алгоритм Гаусса-Ньютона,Алгоритм Гаусса-Ньютона
126,Gauss-Seidel method,طريقة غاوس سايدل,طريقة جاوس-سيدل,طريقة غاوس-سايدل,高斯-赛德尔法,高斯-塞德尔方法 (Gauss-Seidel method),高斯-塞代尔方法,Méthode Gauss-Seidel,méthode de Gauss-Seidel,Méthode de Gauss-Seidel,ガウス・ザイデル法,ガウス・ザイデル法,ガウス・ザイデル法,Метод Гаусса-Зейделя,Метод Гаусса-Зейделя,метод Гаусса-Зейделя
127,Generative Adversarial Networks,شبكات الخصومة التوليدية,شبكات الانتاج التنافسيّة,شبكات التوليد المعارض,生成对抗网络,生成对抗网络,生成对抗网络,Réseaux adverses génératifs,Réseaux antagonistes génératifs,Réseaux Antagonistes Génératifs,敵対的生成ネットワーク,生成的対抗ネットワーク (Generative Adversarial Networks),"生成対adversarialネットワーク (Generative Adversarial Networks)
GAN (GANs)",Генеративно-состязательные сети,Генеративные противоборствующие сети,Генеративные состязательные сети (GANs)
128,Gensim,جينسيم,جينسيم,Gensim جينسيم,根森,Gensim,生成语义模型 (Gensim),Gensim,Gensim,gensim,ゲンシム,Gensim,ジェンシム,Генсим,Gensim,Гензим
129,Gibbs Sampling,أخذ عينات جيبس,- التحليل العيني جيبس,عينة جيبس,吉布斯抽样,吉布斯抽样,吉布斯采样,Échantillonnage Gibbs,Échantillonnage de Gibbs,Échantillonnage de Gibbs,ギブス・サンプリング,ギブスサンプリング (Gibbs Sampling),ギブスサンプリング,Выборка Гиббса,Сэмплирование Гиббса,Гиббсовская выборка
130,Gibbs iteration,تكرار جيبس,التكرار غيبس,تكرار جيبس,吉布斯迭代,吉布斯抽样(iteration),吉布斯迭代,Itération de Gibbs,itération de Gibbs,itération de Gibbs,ギブズの反復,ギブス・イテレーション,ギブスイテレーション,Итерация Гиббса,Итерация Гиббса,Итерация Гиббса
131,Gibbs sampler,جيبس ​​أخذ العينات,- التحليل العيني غيبز,مسح جيبس,吉布斯采样器,吉布斯采样器,吉布斯采样器,Échantillonneur Gibbs,Échantillonneur de Gibbs,Échantillonneur de Gibbs,ギブスサンプラー,ギブスサンプラー,ギブスサンプラー,Сэмплер Гиббса,Гиббсовский сэмплер,Гиббсовский сэмплер
132,GoogLeNet,جوجل لينت,جوجل نت,GoogLeNet,谷歌网,谷歌网络,GoogLeNet,GoogleLeNet,GoogLeNet,GoogLeNet,GoogLeNet,グーグルネット,GoogLeNet,ГуглЛеНет,GoogLeNet,GoogLeNet
133,Gradient,الانحدار,التدرج,تدرج,坡度,梯度 (Gradient),梯度,Pente,Gradient,Gradient,勾配,勾配,勾配,Градиент,Градиент,Градиент
134,Ground Truth,الحقيقة الأرضية,الحقيقة الأساسية,الحقيقة الأرضية,地面真相,地面真相,实地真实情况,Vérité terrain,Vérité terrain,Vérité terrain,グラウンドトゥルース,グラウンド トゥルース,正解データ,Основная истина,- Земная правда,Реальные данные
135,Gröbner basis,أساس غروبنر,قواعد غروبنر,قاعدة غرونر,格罗布纳基础,格劳布纳基底,格罗布纳基础,Base de Gröbner,Base de Gröbner,Base de Gröbner,グレブナー基底,グレブナ基底,グロブナー基底,базис Грёбнера,Базис Грёбнера,Базис Грёбнера
136,Gumbel,غامبل,جامبل,Gumبل,甘贝尔,古柏尔,Gumbel分布,Gumbel,Gumbel,Gumbel,ガンベル,ガンベル,ガンベル,Гумбель,Гумбеля,Гумбеля
137,Gumbel distribution,توزيع غامبل,توزيع غمبل,توزيع جمبل,甘贝尔分布,古朴尔分布,Gumbel分布,Distribution de gommes,distribution de Gumbel,distribution de Gumbel,ガンベル分布,ガンベル分布,ガンベル分布,Распространение Гумбеля,Распределение Гумбеля,распределение Гумбеля
138,Gumbel-softmax distribution,توزيعة غامبل-سوفت ماكس,التوزيع جامبل-سوفتماكس,توزيع جامبل-سوفت ماكس,Gumbel-softmax 分布,古贝尔-Softmax分布,冯布尔-softmax分布,Distribution Gumbel-softmax,- Distribution Gumbel-softmax,Distribution Gumbel-softmax,ガンベルソフトマックス分布,ガンベル-ソフトマックス分布,ガンベル-ソフトマックス分布,Распределение Gumbel-softmax,распределение Гумбеля-софтмакс,Распределение Гамбела-софтмакс
139,Haar wavelet,مويجات هار,تحويلات هار,تويجة هار,哈尔小波,Haar小波,小波,Ondelette de cheveux,ondelette de Haar,Ondelette de Haar,ハール ウェーブレット,Haarウェーブレット,ハール・ウェーブレット,Вейвлет Хаара,Вейвлет Хаар,вейвлет Хаара
140,Hadamard matrix,مصفوفة هادمارد,مصفوفة هادامارد,مصفوفة هادمارد,哈达玛矩阵,哈达玛矩阵,哈达码矩阵,Matrice d'Hadamard,- Matrice de Hadamard,Matrice de Hadamard,アダマール行列,ハダマード行列 (Hadamard matrix),アダマール行列,Матрица Адамара,Матрица Хадамара,Матрица Адамара
141,Hadamard product,منتج هادمارد,- تركيبة هادامارد,ضرب هادامارد,哈达玛产品,哈达玛乘积,阿达马积,Produit Hadamard,Produit de Hadamard,produit de Hadamard,アダマール積,ハダマード積 (Hadamard product),ハダマード積,Произведение Адамара,Произведение Хадамара,Поточечное произведение
142,Hankel matrix,مصفوفة هانكل,مصفوفة هانكل,مصفوفة هانكل,汉克尔矩阵,Hankel矩阵,汉克尔矩阵,Matrice de Hankel,matrice de Hankel,Matrice de Hankel,ハンケル行列,ハンケル行列 (Hankel matrix),ハンケル行列,Матрица Ханкеля,Матрица Ханкеля,Матрица Хенкеля
143,Hausdorff distance,مسافة هاوسدورف,مسافة هاوسدورف,مسافة هاوسدورف,豪斯多夫距离,豪斯多夫距离,豪斯多夫距离,Distance de Hausdorff,- Distance de Hausdorff,distance de Hausdorff,ハウスドルフ距離,ハウスドルフ距離,ハウスドルフ距離,Расстояние Хаусдорфа,Расстояние Хаусдорфа,Хаусдорфово расстояние
144,Hellinger distance,مسافة هيلنجر,- مسافة هيلينغر,مسافة هيلينجر,海灵格距离,Hellinger 距离,赫林格距离,Distance de Hellinger,distance de Hellinger,Distance de Hellinger,ヘリンジャー距離,ヘリンガー距離,ヘリンガー距離,Расстояние Хеллингера,Расстояние Хеллингера,Расстояние Хеллингера
145,Helmholtz machine,آلة هيلمهولتز,آلة هلمهولتز,آلة هلمهولتز,亥姆霍兹机,赫尔姆霍兹机,赫尔姆霍兹机器 (Helmholtz machine),Machine de Helmholtz,Machine de Helmholtz,Machine de Helmholtz,ヘルムホルツマシン,ヘルムホルツマシン (Helmholtz machine),ヘルムホルツ機械,Машина Гельмгольца,Машина Гельмгольца,Машина Гельмгольца
146,Hiero system,نظام هيرو,نظام هيرو,نظام هيرو,希罗系统,Hiero系统,层次系统,Système Hiéro,système Hiero,système Hiero,ハイエロシステム,ヒエロシステム,Hiero システム,Система Иеро,- Hiero система,Иеросистема
147,Hodge decomposition,تحلل هودج,تحليل هودج,تفكيك هودج,霍奇分解,霍奇分解,Hodge分解,Décomposition de Hodge,Décomposition de Hodge,Décomposition de Hodge,ホッジ分解,ホッジ分解,ホッジ分解,Разложение Ходжа,Декомпозиция Ходжа,Разложение Ходжа
148,Hoeffding's inequality,عدم المساواة هوفدينج,معادلة هوفدينج,متساوية هوفدينج,霍夫丁不等式,霍夫丁不等式,霍夫丁不等式,L'inégalité de Hoeffding,Inégalité de Hoeffding,inégalité de Hoeffding,ヘフディングの不等式,ヘフディングの不等式,ヘフディングの不等式,Неравенство Хефдинга,Неравенство Хефдинга,Неравенство Хёффдинга
149,HowTo100M,كيفية100M,كيفية100 مليون,كيف الوصول إلى 100 مليون,如何100M,HowTo100M,如何100M,Comment100M,HowTo100M,HowTo100M,HowTo100M,HowTo100M,HowTo100M,HowTo100M,HowTo100M,КакСделать100М
150,Huber norm,قاعدة هوبر,المعيار الهوبرية,معيار هوبر,胡贝尔范数,胡伯范数,哈伯范数,Norme Huber,norme de Huber,Norme de Huber,フーバーノルム,ヒューバー標準,ヒューバー・ノルム,Норма Губера,норма Хьюбера,Норма Хьюбера
151,Hyper-parameter,فرط المعلمة,المعلمة فوق الأخرى,معلمة فائقة,超参数,超参数,超参数,Hyper-paramètre,Hyper-paramètre,Hyper-paramètre,ハイパーパラメータ,ハイパーパラメータ,ハイパーパラメータ,Гиперпараметр,- Гиперпараметр,Гиперпараметр
152,Inception network,شبكة البداية,شبكة الانطلاق,شبكة البدء,创始网络,启示网络,Inception 网络,Réseau de création,réseau Inception,Réseau inception,インセプションネットワーク,インセプションネットワーク,Inception ネットワーク,Начальная сеть,Сеть Inception,Сеть Inception
153,Independent Cascade,تتالي مستقل,- المجال المستقل,السلسلة المستقلة,独立级联,独立级联,独立级联模型,Cascade indépendante,Cascade Indépendante,Cascade indépendante,独立したカスケード,独立カスケード,独立カスケード,Независимый Каскад,Независимая каскада,Независимый Каскад
154,Inside-outside algorithm,خوارزمية من الداخل إلى الخارج,- تحليل داخلي-خارجي,خوارزمية داخل-خارج,内外算法,内外算法,内外算法,Algorithme intérieur-extérieur,Algorithme intérieur-extérieur,Algorithme Inside-Outside,インサイド・アウトサイドアルゴリズム,アルゴリズムのインサイド・アウトサイド,内側外側アルゴリズム,Алгоритм внутри-вне,Алгоритм Inside-Outside,Алгоритм внутренний-внешний
155,Ising model,نموذج إيسينج,النموذج إيزينج,نموذج إيسنغ,伊辛模型,伊辛模型,伊辛模型,Modèle d'Ising,Modèle d'Ising,modèle d'Ising,イジングモデル,イジング模型,アイシングモデル,Модель Изинга,Модель Изинга,модель Изинга
156,Iverson bracket,قوس ايفرسون,قوس إيفرسون,نقاوسة إيفرسون,艾弗森支架,伊弗森括弧,Iverson括号,Support Iverson,crochets d'Iverson,Crochet d'Iverson,アイバーソンブラケット,アイバーソン括弧,アイバーソン括弧,Кронштейн Айверсона,Скобка Айверсона,Квадратные скобки Айверсона
157,Jaccard,جاكارد,جاكارد,جاكارد,杰卡德,Jaccard,Jaccard相似系数,Jaccard,Jaccard,Jaccard,ジャカード,ジャカード,ジャッカード,Жаккар,Jaccard,Жаккар
158,Jaccard index,مؤشر جاكارد,مؤشر جاكارد,مُعامل جاكارد,杰卡德指数,Jaccard指数,Jaccard系数,Index Jaccard,- Indice de Jaccard,indice de Jaccard,ジャカードインデックス,ジャッカード指数,ジャッカード指数,Индекс Жаккара,Индекс Жаккара,Индекс Жаккара
159,Jensen's inequality,عدم المساواة جنسن,عدم المساواة لجنسن,متساوية جنسن,詹森不等式,詹森不等式,詹森不等式,L'inégalité de Jensen,Inégalité de Jensen,Inégalité de Jensen,ジェンセンの不等式,ジェンセンの不等式 (Jensen's inequality),ジェンセンの不等式,Неравенство Дженсена,неравенство Йенсена,Неравенство Йенсена
160,Jensen-Shannon,جنسن شانون,جنسن - شانون,جنسن-شانون,詹森-香农,Jensen-Shannon,詹森-香农,Jensen Shannon,Jensen-Shannon,Jensen-Shannon,ジェンセン・シャノン,ジェンセン・シャノン,ジェンセン・シャノン,Дженсен-Шеннон,Дженсен-Шеннон,Дженсен-Шеннон
161,Jensen-Shannon Divergence,اختلاف جنسن شانون,الانحراف جنسن-شانون,انحراف جينسن-شانون,詹森-香农散度,Jensen-Shannon 散度,詹森-香农散度,Divergence Jensen-Shannon,- Divergence de Jensen-Shannon,Divergence de Jensen-Shannon,ジェンセンとシャノンのダイバージェンス,ジェンセン・シャノンダイバージェンス,ジェンセン-シャノン発散度,Расхождение Дженсена-Шеннона,Метрика Дивергенции Йенсена-Шеннона,Дивергенция Дженсена-Шеннона
162,Kalman filter,مرشح كالمان,مرشح كالمان,مرشح كالمان,卡尔曼滤波器,卡尔曼滤波器,卡尔曼滤波器,Filtre de Kalman,Filtre de Kalman,filtre de Kalman,カルマンフィルター,カルマンフィルタ,カルマンフィルター,Фильтр Калмана,Фильтр Калмана,фильтр Кальмана
163,Kendall's τ,كيندال τ,- التاو كندال,معامل كندال تاو,肯德尔的 τ,肯德尔tau,肯德尔秩相关系数τ,Le τ de Kendall,τ de Kendall,Kendall's τ,ケンダルのτ,ケンダールのτ,ケンドールの順位相関係数τ,τ Кендалла,коэффициент Кендалла τ,Кендалла τ
164,Keras,كيراس,كيراس,كيراس,喀拉斯,Keras,Keras,Kéras,Keras,Keras,ケラス,Keras,Keras はそのまま使用,Керас,Keras,Керас
165,Kleene closure,إغلاق كلين,إغلاق كليني,عبارة كلين للإغلاق,克林封闭,Kleene闭包,Kleene闭包,Fermeture Kleene,Fermeture de Kleene,fermeture de Kleene,クリーンクロージャ,クリーン閉包,クリーン閉包 (Kleene closure),Закрытие Клини,- Клиническое замыкание,Замыкание Клини
166,Kneser-Ney smooth,كنيسر-ناي ناعم,التنعيم الكنيزير-ناي,تملية كنيزر-ني,克内瑟-内伊光滑,Kneser-Ney平滑,克内舍-尼平滑,Kneser-Ney lisse,lissage de Kneser-Ney,lissage de Kneser-Ney,ニーゼル・ネイ・スムース,Kneser-Neyスムージング,クネッサーニー平滑化,Кнезер-Ней гладкий,Сглаживание Kneser-Ney,Сглаживание Кнесера-Нея
167,Kolmogorov-Smirnov test,اختبار كولموجوروف-سميرنوف,اختبار كولموغوروف-سميرنوف,اختبار كولموجوروف-سميرنوف,柯尔莫哥洛夫-斯米尔诺夫检验,科尔莫哥洛夫-斯米尔诺夫检验,科尔莫哥罗夫-斯米尔诺夫检验,Test de Kolmogorov-Smirnov,Test de Kolmogorov-Smirnov,test de Kolmogorov-Smirnov,コルモゴロフ・スミルノフ検定,コルモゴロフ・スミルノフ検定,コルモゴロフ・スミルノフ検定,Тест Колмогорова-Смирнова,Тест Колмогорова-Смирнова,Тест Колмогорова-Смирнова
168,Krippendorff's α,كريبندورف ألفا,ألفا كريبندورف,ألفا كريبندورف,克里彭多夫α,克里彭多夫α,克里朋多夫阿尔法系数,α de Krippendorff,α de Krippendorff,α de Krippendorff,クリッペンドルフα,クリッペンドルフのα,Krippendorff's α → クリッペンドルフのアルファ,α Криппендорфа,α Криппендорфа,Коэффициент α Криппендорфа
169,Kronecker delta,دلتا كرونيكر,دلتا كرونيكر,دلتا كرونيكر,克罗内克三角洲,克罗内克δ,克罗内克尔delta,Delta du Kronecker,delta de Kronecker,delta de Kronecker,クロネッカーデルタ,クロネッカー・デルタ,クロネッカーデルタ,Кронекера дельта,Дельта Кронекера,Кронекер-дельта
170,Kronecker product,منتج كرونيكر,"\n d dt vec(W ) = −H(t)vec(W ). (6 \n ) \n', 'There",ضرب كرونيكر,克罗内克积,克罗内克积,克罗内克积,Produit Kronecker,produit de Kronecker,produit de Kronecker,クロネッカー積,クロネッカー積,クロネッカー積,Продукт Кронекера,Произведение Кронекера,произведение Кронекера
171,Kullback Leibler divergence,انحراف كولباك ليبلر,الانحراف كولباك ليبلر,اختلاف كولباك - لايبلر,库尔贝克·莱布勒散度,Kullback-Leibler 散度,库尔巴克-莱布勒散度,Divergence de Kullback Leibler,divergence de Kullback-Leibler,divergence de Kullback-Leibler,カルバック・ライブラー発散,クルバック・ライブラー・ダイバージェンス,クルバック・ライブラー発散量,Расхождение Кульбака-Лейблера,Дивергенция Кульбака-Лейблера,Расхождение Кульбака-Лейблера
172,Lanczos iteration,تكرار لانكزوس,الطريقة لانكزوس,تكرار لانكزوس (Lanczos iteration),兰佐斯迭代,兰索斯迭代,朗佐斯迭代,Itération de Lanczos,itération de Lanczos,itération de Lanczos,ランチョス反復,ランチョス反復,ランチョス反復法,Итерация Ланцоша,Итерация Ланцош,итерация Ланцоша
173,Langevin dynamic,ديناميكية لانجفين,- التحريك الديناميكي لانجفين,ديناميات لانجفين,朗之万动态,兰什万动力学,朗之万动力学,Dynamique Langevinoise,dynamique de Langevin,dynamique de Langevin,ランジュバンダイナミック,ランジュバン動力学,ランジュバン動力学,Ланжевен динамичный,Ланжевиновская динамика,Динамика Ланжевена
174,Laplace smoothing,تجانس لابلاس,التسويق لابلاس,تملُّس لابلاس,拉普拉斯平滑,拉普拉斯平滑化,拉普拉斯平滑,Lissage de Laplace,Lissage de Laplace,lissage de Laplace,ラプラス平滑化,ラプラス平滑化,ラプラス平滑化,Сглаживание по Лапласу,Сглаживание Лапласа,сглаживание Лапласа
175,Laplace-Beltrami operator,عامل لابلاس بلترامي,المشغل لابلاس-بيلترامي,معامل لابلاس-بلترامي,拉普拉斯-贝尔特拉米算子,拉普拉斯-贝尔特拉米算子,拉普拉斯-贝尔特拉米算子,Opérateur Laplace-Betrami,opérateur de Laplace-Beltrami,opérateur de Laplace-Beltrami,ラプラス・ベルトラミ演算子,ラプラス・ベルトラミ演算子,ラプラス・ベルトラミ作用素,Оператор Лапласа-Бельтрами,оператор Лапласа-Бельтрами,оператор Лапласа-Бельтрами
176,Lasso,لاسو,لاسو,الرمي,套索,套索,套索法,Lasso,Lasso,Lasso,なげなわ,ラッソ,ラッソ,Лассо,Лассо,Ласcо
177,Lasso penalty,عقوبة لاسو,عقوبة الحبل,عقوبة اللاسو,套索惩罚,套索惩罚,套索惩罚,Pénalité au lasso,Pénalité Lasso,Pénalité Lasso,なげなわペナルティ,Lassoペナルティ,ラッソペナルティ,Лассо пенальти,Пенальти Лассо,Штраф Лассо
178,Lemma,ليما,- محلل (Lemma),مُصْطَلَح,引理,引理,引理,Lemme,Lemme,Lemme,補題,補題,補題,Лемма,Лемма,Лемма
179,Levenberg-Marquardt algorithm,خوارزمية ليفنبرج ماركوارت,خوارزمية ليفنبرغ-ماركواردت,خوارزمية ليفنبرغ-ماركوارت,Levenberg-Marquardt 算法,莱文伯格-马夸特算法,勒文伯格-马夸特算法,Algorithme de Levenberg-Marquardt,algorithme de Levenberg-Marquardt,algorithme de Levenberg-Marquardt,レーベンバーグ・マルカートアルゴリズム,レーベンベルグ・マーカード法,レーベンバーグ・マーカート法,Алгоритм Левенберга-Марквардта,алгоритм Левенберга-Марквардта,Алгоритм Левенберга-Марквардта
180,Levenshtein distance,مسافة ليفنشتاين,- التباعد ليفنشتاين,مسافة ليفينشتاين,编辑距离,莱文斯坦距离,莱文斯坦距离,Distance de Levenshtein,distance de Levenshtein,distance de Levenshtein,レーベンシュタイン距離,レーベンシュタイン距離,レーベンシュタイン距離,Расстояние Левенштейна,Расстояние Левенштейна,Расстояние Левенштейна
181,Levenshtein edit distance,مسافة تحرير ليفنشتاين,مسافة تحرير ليفنشتاين,مسافة تحرير ليفنشتاين,编辑距离,莱文斯坦编辑距离,莱文斯坦编辑距离,Distance de modification de Levenshtein,distance d'édition de Levenshtein,distance d'édition de Levenshtein,レーベンシュタイン編集距離,レーベンシュタイン編集距離,レーベンシュタイン編集距離,Расстояние редактирования Левенштейна,Расстояние редактирования Левенштейна,Расстояние Левенштейна
182,Libratus,ليبراتوس,ليبراتوس,ليبراتوس,天秤座,脑图算法,图书馆,Balance,Libratus,Libratus,天秤座,リブラタス,リブラタス,Весы,Либратус,Либратус
183,Linformer,لينفورمر,المعامل الخطي,لينفورمر,林弗默,Linformer,线性transformer,Linformer,Linformer,Linformer,リンフォーマー,リンフォーマー,リンフォーマー (Linformer),Линформер,Linformer,Линформер
184,Lipschitz,ليبشيتز,ليبشيتز,ليبشيتز,利普希茨,Lipschitz - 利普希茨,Lipschitz 李普希茨条件,Lipschitz,Lipschitz,Lipschitz,リプシッツ,リプシッツ,リプシッツ条件,Липшиц,"""['Мы предполагаем, что функция связи является L σ-липшицевой и второго порядка L 2-липшицевой. Функция связи ведет себя как кумулятивная функция плотности вероятности. Например, общим выбором функции связи является стандартная логистическая функция σ (x) = 1",Липшица
185,Lipschitz constant,ثابت ليبشيتز,الثابتة المعرفة ليبشيتز,ثابت ليبشتز,利普希茨常数,利普希茨常数,利普希茨常数,Constante de Lipschitz,constante de Lipschitz,constante de Lipschitz,リプシッツ定数,リプシッツ定数,リプシッツ定数,Константа Липшица,Константа Липшица,Константа Липшица
186,Lipschitz continuity,استمرارية ليبشيتز,- تواصل ليبشتز,استمرارية ليبشيتز,利普希茨连续性,利普希茨连续性,利普希茨连续性,Continuité lipschitzienne,Continuité de Lipschitz,continuité de Lipschitz,リプシッツ連続性,リプシッツ連続性,リプシッツ連続性,Липшицева непрерывность,Непрерывность Липшица,Непрерывность по Липшицу
187,Lipschitz continuous,ليبشيتز مستمر,مستمر بالتحديدية ليبشيتز,مستمر ليبشتز,利普希茨连续,利普希茨连续,利普希茨连续,Lipschitz continu,Lipschitz continue,à variation lipschitzienne,リプシッツ連続,リプシッツ連続,リプシッツ連続,Липшицев непрерывный,Липшицева непрерывность,Липшиц-непрерывная
188,Lipschitz function,وظيفة ليبشيتز,دالة ليبشيتز,دالة ليبشتز,利普希茨函数,利普希茨函数,利普希茨函数,Fonction Lipschitz,- Fonction Lipschitz,fonction Lipschitzienne,リプシッツ関数,リプシッツ関数 (Lipschitz 関数),リプシッツ関数,Функция Липшица,Липшицева функция,Липшицева функция
189,Lipschitzness,شفة الشفاه,اللبسشيزية,تحديد ليبشيتز,利普希茨尼斯,"""['在这里，我们认为小的稳健泛化误差应该意味着小的训练误差和小的利普希茨常数。另一个重要的不匹配是，我们在ℓ2上陈述了利普希茨性的普适韧性定律，而[MMS + 18]中的实验是关于ℓ∞上",利普希茨性质,Lipschitzness,Lipschitzianité,Lipschitzité,リップシッツネス,リプシッツ性,リプシッツ性,Липшицкость,Липшицевость,Липшицевость
190,Log Gaussian cox process,سجل عملية كوكس غاوس,- تسلسل كوكس اللوغاريتمي,عملية كوكس لوغاريتمية غاوسية,对数高斯 cox 过程,对数高斯Cox过程 (Log Gaussian Cox Process),对数高斯-Cox过程,Log du processus cox gaussien,Processus de Cox gaussien logarithmique,Processus de Cox log-gaussien,対数ガウス cox プロセス,ログガウスコックス過程,ログ正規コックス過程,Логарифмический гауссов процесс Кокса,Лог-гауссовский процесс Кокса,Логнормальный процесс Кокса
191,Longformer,منذ فترة طويلة,- التنظيم الطويل,"""لونغفورمر""",长形器,长形器,长序列转换器,Forme longue,Longformer,Longformeur,ロングフォーマー,ロングフォーマー,ロングフォーマー,Лонгформер,Longformer,Лонгформер
192,Lucene,لوسين,"""['في وقت لاحق، استخدم تيدلا وياماموتو (2018) مجموعة بيانات تم إنشاؤها يدويًا لتدريب نموذج الذاكرة القصيرة والطويلة (LSTM) للتقسيم المورفولوجي في اللغة التج",لوسين,卢塞恩,Lucene,Lucene,Lucène,Lucene,Lucene,ルシーン,Lucene,Lucene,Лусене,Lucene,Люсин
193,Lyapunov function,وظيفة لابونوف,دالة ليابانوف,دالة ليابونوف,李亚普诺夫函数,李雅普诺夫函数,李雅普诺夫函数,Fonction Lyapunov,fonction de Lyapunov,Fonction de Lyapunov,リアプノフ関数,リアプノフ関数,リャプノフ関数,функция Ляпунова,Функция Ляпунова,Функция Ляпунова
194,Mahalanobis distance,مسافة ماهالانوبيس,المسافة مهالانوبيس,مسافة ماهالانوبيس,马哈拉诺比斯距离,马哈拉诺比斯距离,马哈拉诺比斯距离,Distance de Mahalanobis,Distance de Mahalanobis,Distance de Mahalanobis,マハラノビス距離,マハラノビス距離,マハラノビス距離,Расстояние Махаланобис,Махаланобисовское расстояние,Махаланобисово расстояние
195,Mahalanobis distance function,وظيفة المسافة ماهالانوبيس,- مسافة مهالانوبيس الوظيفية,دالة مسافة ماهالانوبيس,马氏距离函数,马哈拉诺比斯距离函数,马哈拉诺比斯距离函数,Fonction de distance de Mahalanobis,- Fonction de distance de Mahalanobis,fonction de distance de Mahalanobis,マハラノビス距離関数,マハラノビス距離関数,マハラノビス距離関数,Функция расстояния Махаланобиса,Функция расстояния Махаланобиса,Функция расстояния Махаланобиса
196,Mahalanobis matrix,مصفوفة ماهالانوبيس,المصفوفة المهالانوبيسية,مصفوفة ماهالانوبيس,马氏矩阵,马哈拉诺比斯矩阵,马哈拉诺比斯矩阵,Matrice de Mahalanobis,- Matrice de Mahalanobis,matrice de Mahalanobis,マハラノビス行列,マハラノビス行列 (Mahalanobisu gyōretsu),マハラノビス行列,Матрица Махаланобиса,Матрица Махаланобиса,Матрица Махаланобиса
197,Mahalanobis metric,ماهالانوبيس متري,- متري ماهالانوبيس,مقياس ماهالانوبيس,马哈拉诺比斯度量,马哈拉诺比斯度量,马哈拉诺比斯度量,Métrique Mahalanobis,Métrique de Mahalanobis,métrique de Mahalanobis,マハラノビス指標,マハラノビス距離,マハラノビス距離尺度,Метрика Махаланобиса,Махаланобисовская метрика,Метрика Махаланобиса
198,Manhattan distance,مسافة مانهاتن,المسافة الرجلية,المسافة المانهاتنية,曼哈顿距离,曼哈顿距离,曼哈顿距离,Distance de Manhattan,distance de Manhattan,Distance de Manhattan,マンハッタンの距離,マンハッタン距離,マンハッタン距離,Расстояние Манхэттен,Манхэттенское расстояние,Манхэттенское расстояние
199,Marching Cubes,مكعبات المسيرة,مكعبات المشي,مكعبات سائرة,行进立方体,Marching Cubes (走方格),行进立方体,Cubes de marche,Marching Cubes,Cubes de marche,マーチングキューブ,マーチングキューブ,マーチングキューブ,Марширующие кубики,Метод Марчинг Кубес,Маршрутные кубики
200,Markov,ماركوف,ماركوف,سلسلة ماركوف,马尔可夫,马尔可夫,马尔可夫,Markov,"""[""Par conséquent, le DPP ne s'applique pas aux deux cas discutés ci-dessus. Enfin, nous analysons le cas avec un contrôleur déterministe dépendant de l'historique et un adversaire convexe Markovien. Nous considérons la politique dépendante de l'historique telle que π 2i = a 1 , i = 1, 2, . . ."", ""Si nous observons l'état B, nous choisirons l'action alternative pour les étapes",Markovien,マルコフ,"""したがって、DPPは上述の二つのケースには適用できません。最後に、歴史に依存する決定的制御器とマルコフ凸な敵対者を持つケースを分析します。π2i = a1、i = 1, 2、...のような歴史に依存する方針を考慮します。"", ""もし",マルコフ過程,Марков,Марков,Марковский
201,Markov Chain,سلسلة ماركوف,سلسلة ماركوف,سلسلة ماركوف,马尔可夫链,马尔可夫链,马尔可夫链,Chaîne de Markov,Chaîne de Markov,Chaîne de Markov,マルコフ連鎖,マルコフ連鎖 (Markov Chain),マルコフ連鎖,Марковская цепь,Цепь Маркова,Марковская цепь
202,Markov Chain Monte Carlo,سلسلة ماركوف مونت كارلو,سلسلة ماركوف مونتي كارلو,سلسلة ماركوف مونت كارلو,马尔可夫链蒙特卡罗,马尔可夫链蒙特卡罗,马尔可夫链蒙特卡罗法 (MCMC),Chaîne de Markov Monte Carlo,Chaîne de Markov Monte Carlo,Chaîne de Markov Monte Carlo,マルコフ連鎖モンテカルロ法,"""['サンプリングアプローチは通常、マルコフ連鎖モンテカルロ（MCMC）サンプリングに基づいており、その中で事後分布が定常分布となるマルコフ連鎖が定義されます。最適化アプローチは通常、変分推論に基づい",マルコフ連鎖モンテカルロ法,Марковская цепь Монте-Карло,Марковская цепь Монте-Карло (MCMC),Марковская цепь Монте-Карло
203,Markov Random Field,حقل ماركوف العشوائي,- مجال عشوائي ماركوف,حقل ماركوف العشوائي,马尔可夫随机场,马尔可夫随机场,马尔可夫随机场,Champ aléatoire de Markov,Champ aléatoire de Markov,Champ aléatoire de Markov,マルコフランダムフィールド,マルコフランダムフィールド,マルコフ確率場,Марковское случайное поле,Марковское случайное поле,Марковское случайное поле
204,Markov assumption,افتراض ماركوف,- تقدير ماركوف المخفي,فرضية ماركوف,马尔可夫假设,马尔可夫假设,马尔可夫假设,Hypothèse markovienne,hypothèse de Markov,hypothèse markovienne,マルコフ仮定,"""['y * = arg max  \n A standard hidden Markov model (HMM) can decompose the result of Equation 1 using first order Markov assumption and independence assumptions into P (x|y) = n t=1 P (x t |y t ) and P (y) = n t=1 P (y t |y t−1 ).', ""Early approaches for map localization [5,7,10,20] make use of Monte Carlo methods and the Markov assumption to maintain a sample-based posterior representation of",マルコフ仮定,Марковское предположение,предположение Маркова,предположение Маркова
205,Markov blanket,بطانية ماركوف,الغطاء الماركوفية,التغليف الماركوفي,马尔科夫毯,马尔可夫毯,马尔可夫毯,Couverture markovienne,Couverture de Markov,Couverture de Markov,マルコフブランケット,- マルコフブランケット,マルコフ空間,Марковское одеяло,Марковское одеяло,Марковский барьер
206,Markov chain model,نموذج سلسلة ماركوف,نموذج سلسلة ماركوف,نموذج سلسلة ماركوف,马尔可夫链模型,马尔可夫链模型,马尔可夫链模型,Modèle de chaîne de Markov,modèle de chaîne de Markov,modèle de chaîne de Markov,マルコフ連鎖モデル,マルコフ連鎖モデル,マルコフ連鎖モデル,Модель цепи Маркова,Модель марковской цепи,модель марковских цепей
207,Markov decision Process,عملية اتخاذ القرار ماركوف,عملية قرارية ماركوف,عملية اتخاذ القرار الماركوفية,马尔可夫决策过程,马尔可夫决策过程,马尔可夫决策过程,Processus de décision markovien,Processus de décision de Markov,Processus décisionnel de Markov,マルコフ決定プロセス,マルコフ決定過程,マルコフ決定過程,Марковское решение Процесс,Процесс принятия решений Маркова,Марковский процесс принятия решений
208,Markov game,لعبة ماركوف,لعبة ماركوف,لعبة ماركوف,马尔可夫博弈,马尔可夫博弈,马尔可夫博弈,Jeu de Markov,jeu de Markov,Jeu de Markov,マルコフゲーム,マルコフゲーム (Markov game),マルコフゲーム,Марковская игра,Марковская игра,Марковская игра
209,Markov kernel,نواة ماركوف,نواة ماركوف,نواة ماركوف,马尔可夫核,马尔可夫核,马尔可夫核,Noyau de Markov,noyau de Markov,Noyau de Markov,マルコフカーネル,マルコフカーネル (Markov kernel),マルコフ核,Марковское ядро,Марковское ядро,Марковское ядро
210,Markov logic,منطق ماركوف,منطق ماركوف,منطق ماركوف,马尔可夫逻辑,马尔可夫逻辑,马尔可夫逻辑,Logique markovienne,logique de Markov,logique markovienne,マルコフ論理,マルコフロジック (Markov logic),マルコフ論理,Марковская логика,Марковская логика,Марковская логика
211,Markov logic network,شبكة منطق ماركوف,شبكة منطق ماركوف,شبكة منطق ماركوف,马尔可夫逻辑网络,马尔科夫逻辑网络,"马尔可夫逻辑网络

MLN",Réseau logique markovien,- Réseau logique de Markov,réseau logique markovien,マルコフ論理ネットワーク,マルコフ論理ネットワーク (Markov logic network),マルコフ論理ネットワーク,Марковская логическая сеть,Сеть логики Маркова,сеть маркова логики
212,Markov model,نموذج ماركوف,- تصميم ماركوف,نموذج ماركوف,马尔可夫模型,马尔可夫模型,马尔可夫模型,Modèle de Markov,"""['Ce modèle Markov segmentaire (Holmes et Russell, 1999) est naturel pour modéliser les formes d'onde. Il décompose la forme d'onde Q en segments locaux, chacun étant une ""forme"" fonctionnelle paramétrique avec du bruit additif, et les segments sont ""liés"" de manière Markovienne.', 'Nous développons notre modèle d'induction POS basé sur le HMM basé sur les caractéristiques de Berg-Kirkpatrick et al.",modèle de Markov,マルコフモデル,マルコフモデル (Markov model),マルコフモデル,Марковская модель,Марковская модель,Марковская модель
213,Markov network,شبكة ماركوف,شبكة ماركوف,شبكة ماركوف,马尔可夫网络,马尔可夫网络,马尔可夫网络,Réseau markovien,Réseau de Markov,réseau de Markov,マルコフネットワーク,マルコフネットワーク,マルコフネットワーク,Марковская сеть,Марковская сеть,Марковская сеть
214,Markov process,عملية ماركوف,عملية ماركوف,عملية ماركوف,马尔可夫过程,马尔可夫过程,马尔可夫过程,Processus de Markov,Processus de Markov,processus de Markov,マルコフ過程,マルコフ過程,マルコフ過程,Марковский процесс,Марковский процесс,Марковский процесс
215,Markov property,ملكية ماركوف,الخاصية الـمـاركوفية,خاصية ماركوف,马尔可夫性质,马尔可夫性质,马尔可夫性质,Propriété de Markov,- Propriété de Markov,propriété markovienne,マルコフ特性,マルコフ性,マルコフ性質,Марковская недвижимость,Свойство Маркова,Марковское свойство
216,Markov state,دولة ماركوف,الحالة الماركوفية,حالة ماركوف,马尔可夫状态,马尔可夫状态,马尔可夫状态,État de Markov,État de Markov,état markovien,マルコフ州,マルコフ状態,マルコフ状態,Марковское состояние,Марковское состояние,состояние Маркова
217,Markov transition,انتقال ماركوف,- تحول ماركوف,صيرورات ماركوف,马尔可夫转移,马尔可夫转移,马尔可夫转移,transition markovienne,Transition de Markov,transition de Markov,マルコフ遷移,マルコフ遷移,マルコフ遷移,Марковский переход,Марковские переходы,Марковские переходы
218,Markov transition matrix,مصفوفة انتقال ماركوف,مصفوفة انتقال ماركوف,صفيفة انتقال ماركوف,马尔可夫转移矩阵,马尔可夫转移矩阵,马尔可夫转移矩阵,Matrice de transition de Markov,- Matrice de transition de Markov,Matrice de transition de Markov,マルコフ遷移行列,マルコフ遷移行列 (Markov transition matrix),マルコフ遷移行列,Матрица марковского перехода,Марковская матрица переходов,Матрица переходов Маркова
219,Markov's inequality,عدم المساواة ماركوف,عدم المساواة لـ ماركوف,متساوية ماركوف,马尔可夫不等式,马尔可夫不等式,马尔可夫不等式,L'inégalité de Markov,Inégalité de Markov,inégalité de Markov,マルコフの不等式,マルコフの不等式,マルコフの不等式,Неравенство Маркова,Неравенство Маркова,неравенство Маркова
220,MatConvNet,MatConvNet,ماتكونفنت,شبكة التراص الرياضية (MatConvNet),矩阵卷积网络,MatConvNet,MatConvNet,MatConvNet,MatConvNet,MatConvNet,MatConvNet,MatConvNet,MatConvNet,МатКонвНет,MatConvNet,MatConvNet
221,Matching Network,شبكة المطابقة,الشبكة المطابقة,شبكة المطابقة,匹配网络,匹配网络,匹配网络,Réseau correspondant,Réseau d'appariement,Réseau d'appariement,マッチングネットワーク,マッチングネットワーク (Matching Network),マッチングネットワーク,Соответствующая сеть,Сеть сопоставления (Matching Network),Сеть сопоставления
222,Matrix completion,استكمال المصفوفة,استكمال المصفوفة,استكمال المصفوفة,矩阵补全,矩阵补全,矩阵完成,Achèvement de la matrice,Complétion de matrice,Complétion de matrice,マトリックス補完,マトリックス完了,行列完成,Завершение матрицы,Заполнение матрицы,Завершение матрицы
223,Matérn kernel,نواة الأم,نواة ماتيرن,لبّاة متيرن,马腾内核,马特恩核,Matérn核函数,Noyau maternel,Noyau de Matérn,noyau de Matérn,マザーンカーネル,マテルンカーネル,マテルン核,Материнское ядро,Ядро Матерна,ядро Матерна
224,Maximum satisfiability,الحد الأقصى من الرضا,- تلبية الحد الأقصى (Maximum Satisfiability),أقصى إرضاء,最大满足度,最大可满足性 (Maximum Satisfiability),最大满足性问题,Satisfaction maximale,Problème de satisfiabilité maximale,Satisfiabilité maximale,最大の満足度,最大満足性,最大充足性 (saidai jūsoku-sei),Максимальная выполнимость,Максимальная удовлетворимость,Максимальная выполнимость
225,Metropolis Hastings,متروبوليس هاستينغز,متروبوليس هاستنغز,متروبوليس هاستنجز,黑斯廷斯大都会,大都会哈斯廷算法,大都市哈斯廷斯算法,Métropole Hastings,Metropolis Hastings,Metropolis-Hastings,メトロポリス・ヘイスティングス,メトロポリス・ヘイスティングス,メトロポリス・ヘイスティングス法,Метрополис Гастингс,Метрополис-Гастингс,Алгоритм Метрополиса-Хастингса
226,Metropolis algorithm,خوارزمية متروبوليس,- تَرتيب الملكيةية العقارية,خوارزمية ميتروبوليس,大都会算法,大都会算法,大都市算法,Algorithme de métropole,Algorithme de Metropolis,algorithme de Metropolis,メトロポリスアルゴリズム,メトロポリス法,メトロポリスアルゴリズム,Алгоритм Метрополиса,алгоритм Метрополис,Алгоритм Метрополиса
227,Metropolis method,طريقة متروبوليس,طريقة ميتروبوليس,طريقة متروبوليس,都市法,Metropolis 方法,大都市算法,Méthode Métropole,méthode de Metropolis,Méthode de Metropolis,メトロポリス方式,メトロポリス法,メトロポリス法,Метод Метрополиса,Метод Метрополиса,Метод Метрополиса
228,Metropolis-Hastings acceptance ratio,متروبوليس-هاستينغز نسبة القبول,معدل قبول متروبوليس-هاستينجس,نسبة قبول ميتروبوليس-هاستنغز,大都会-黑斯廷斯录取率,Metropolis-Hastings接受率,大都市-黑斯廷接受率,Taux d'acceptation de Metropolis-Hastings,Taux d'acceptation Metropolis-Hastings,taux d'acceptation de Metropolis-Hastings,メトロポリスとヘイスティングスの合格率,メトロポリス・ヘイスティングス受容比,メトロポリス・ヘイスティングス受理比率,Коэффициент принятия Метрополиса-Гастингса,Отношение принятия Метрополис-Гастингса,Отношение принятия Метрополиса-Хастингса
229,Metropolis-Hastings algorithm,خوارزمية متروبوليس-هاستينغز,- تسلسل متروبوليس هاستينجز,خوارزمية ميتروبوليس-هاستنجز,Metropolis-Hastings 算法,大都会 - 哈斯廷斯算法,大都会-黑斯廷斯算法,Algorithme de Métropole-Hastings,- Algorithme Metropolis-Hastings,algorithme de Metropolis-Hastings,メトロポリス・ヘイスティングスアルゴリズム,メトロポリス-ヘイスティングスアルゴリズム,メトロポリス・ヘイスティングス・アルゴリズム,Алгоритм Метрополиса-Гастингса,Алгоритм Метрополиса-Гастингса,Алгоритм Метрополиса-Хастингса
230,Metropolis-Hastings sampler,متروبوليس-هاستينغز العينات,مُولِّد ميتروبوليس-هاستينغس,عينة ميتروبوليس-هاستنغز,大都会-黑斯廷斯采样器,哈斯廷斯-哈斯廷斯取样器,梅特罗波利斯-哈斯廷斯采样器,Échantillonneur Metropolis-Hastings,échantillonneur Metropolis-Hastings,échantillonneur de Metropolis-Hastings,メトロポリス - ヘイスティングスのサンプラー,メトロポリス・ヘイスティングス・サンプラー (Metropolis-Hastings sampler),メトロポリス・ヘイスティングスサンプラー,Сэмплер Метрополис-Гастингс,Сэмплер Метрополиса-Гастингса,Выборщик Метрополиса-Хастингса
231,Monte Carlo,مونتي كارلو,- التكامل العشوائي,طريقة مونت كارلو,蒙特卡洛,蒙特卡罗,蒙特卡罗,monte Carlo,Monte Carlo,Monte Carlo,モンテカルロ,モンテカルロ,モンテカルロ法,Монте-Карло,Монте-Карло,Монте-Карло
232,Monte Carlo Dropout,التسرب من مونت كارلو,إسقاط مونتي كارلو,تسرب مونتي كارلو,蒙特卡洛辍学,蒙特卡罗辍学,蒙特卡罗丢弃法,Abandon de Monte Carlo,Monte Carlo Dropout,Monte Carlo Dropout appliqué par abandon,モンテカルロドロップアウト,モンテカルロドロップアウト,モンテカルロドロップアウト,Монте-Карло Отсев,Выпадение Монте-Карло,Метод Монте-Карло дропаута
233,Monte Carlo Tree Search,بحث شجرة مونت كارلو,بحث شجرة مونتي كارلو,البحث ذو الشجرة مونتي كارلو,蒙特卡罗树搜索,蒙特卡罗树搜索,蒙特卡罗树搜索,Recherche d'arbres de Monte-Carlo,Recherche d'Arbre de Monte Carlo,Recherche arborescente Monte Carlo,モンテカルロツリー検索,モンテカルロ木探索,モンテカルロ木探索,Поиск по дереву Монте-Карло,Метод поиска дерева Монте-Карло,Метод Монте-Карло для построения деревьев поиска решений
234,Monte Carlo algorithm,خوارزمية مونت كارلو,خوارزمية مونتي كارلو,خوارزمية مونت كارلو,蒙特卡罗算法,蒙特卡罗算法,蒙特卡罗算法,Algorithme de Monte Carlo,algorithme de Monte Carlo,algorithme de Monte-Carlo,モンテカルロアルゴリズム,モンテカルロアルゴリズム (Monte Carlo algorithm),モンテカルロアルゴリズム,Алгоритм Монте-Карло,Алгоритм Монте-Карло,Алгоритм Монте-Карло
235,Monte Carlo approximation,تقريب مونت كارلو,تقريب مونتي كارلو,تقريب مونت كارلو,蒙特卡罗近似,蒙特卡罗逼近,蒙特卡罗近似,Rapprochement de Monte-Carlo,Approximation de Monte Carlo,approximation de Monte Carlo,モンテカルロ近似,モンテカルロ近似,モンテカルロ近似,Приближение Монте-Карло,Монте-Карло аппроксимация,Монте-Карло аппроксимация
236,Monte Carlo estimate,تقديرات مونت كارلو,التقدير مونتي كارلو,تقدير مونت كارلو,蒙特卡罗估计,蒙特卡罗估计,蒙特卡罗估计,Estimation Monte-Carlo,Estimation de Monte Carlo,estimation de Monte Carlo,モンテカルロ推定,モンテカルロ推定,モンテカルロ推定,Оценка Монте-Карло,Оценка методом Монте-Карло,Оценка Монте-Карло
237,Monte Carlo estimation,تقدير مونت كارلو,تقدير مونتي كارلو,تقدير مونت كارلو,蒙特卡罗估计,蒙特卡洛估计,蒙特卡罗估计,Estimation Monte-Carlo,estimation Monte Carlo,estimation Monte-Carlo,モンテカルロ推定,モンテカルロ推定,モンテカルロ推定,Оценка Монте-Карло,Оценка методом Монте-Карло,Монте-Карло оценка
238,Monte Carlo estimator,مقدر مونت كارلو,مُقَدِّر مونت كارلو,مقدر مونتي كارلو,蒙特卡洛估计器,蒙特卡罗估计器,蒙特卡洛估计器,Estimateur Monte Carlo,estimateur Monte Carlo,Estimateur de Monte Carlo,モンテカルロ推定器,モンテカルロ推定器,モンテカルロ推定量,Оценщик Монте-Карло,Оценщик Монте-Карло,Оценка методом Монте-Карло
239,Monte Carlo method,طريقة مونتي كارلو,طريقة مونتي كارلو,طريقة مونت كارلو,蒙特卡罗法,蒙特卡罗方法 (Monte Carlo method),蒙特卡罗方法,Méthode Monte Carlo,méthode de Monte Carlo,méthode de Monte-Carlo,モンテカルロ法,モンテカルロ法,モンテカルロ法,Метод Монте-Карло,Метод Монте-Карло,Метод Монте-Карло
240,Monte Carlo sample,عينة مونت كارلو,عينات مونتي كارلو,عينات مونت كارلو,蒙特卡罗样本,蒙特卡洛样本,蒙特卡罗采样,Échantillon de Monte-Carlo,échantillon de Monte Carlo,échantillon Monte Carlo,モンテカルロサンプル,モンテカルロサンプル,モンテカルロサンプル,Образец Монте-Карло,- Monte Carlo выборка,Монте-Карло выборка
241,Monte Carlo search,إبحث فى مونت كارلو,البحث مونتي كارلو,البحث مونت كارلو,蒙特卡罗搜索,蒙特卡罗搜索,蒙特卡罗搜索,Recherche Monte-Carlo,Recherche Monte Carlo,recherche de Monte Carlo,モンテカルロ検索,モンテカルロ探索,モンテカルロ探索,Поиск в Монте-Карло,Поиск Монте-Карло,Метод Монте-Карло
242,Monte Carlo simulation,محاكاة مونت كارلو,محاكاة مونتي كارلو,محاكاة مونت كارلو,蒙特卡罗模拟,蒙特卡罗模拟,蒙特卡罗模拟,Simulation de Monte-Carlo,Simulation de Monte Carlo,simulation de Monte Carlo,モンテカルロシミュレーション,モンテカルロシミュレーション,モンテカルロシミュレーション,Моделирование Монте-Карло,Метод Монте-Карло,Моделирование методом Монте-Карло
243,Monte-Carlo return,عودة مونت كارلو,عائدة مونتي كارلو,مُعاد مونت كارلو,蒙特卡洛往返,蒙特卡罗回报,蒙特卡罗回报,Retour à Monte-Carlo,rendement Monte-Carlo,Retour de Monte-Carlo,モンテカルロ復帰,モンテカルロリターン,モンテカルロリターン,Возвращение в Монте-Карло,Возврат Монте-Карло,Монте-Карло возврат
244,Moore-Penrose pseudo-inverse,مور-بنروز معكوس زائف,- معكوسة زيودو بنروز مزيفة,العكس الزائف لمور-بنروز,Moore-Penrose 伪逆,Moore-Penrose 伪逆,摩尔-彭罗斯伪逆,Pseudo-inverse de Moore-Penrose,pseudo-inverse de Moore-Penrose,pseudo-inverse de Moore-Penrose,ムーア・ペンローズ擬似逆関数,Moore-Penrose擬似逆,ムーア・ペンローズ疑似逆行列,Псевдообратный метод Мура-Пенроуза,Псевдообрат Мура-Пенроуза,Псевдообратная матрица Мура-Пенроуза
245,Morfessor,مورفيسور,مورفيسور,مورفسور,莫费索,Morfessor,形态分割器,Morfesseur,Morfessor,Décomposeur,モルフェッサー,モーフェッサー,モルフェッサー,Морфессор,Морфессор,Морфессор
246,Nadaraya-Watson estimator,مقدر نادرايا واتسون,مقدر نادارايا-واتسون,مقدر نادرايا-واتسون,Nadaraya-Watson 估计器,纳德拉亚-沃森估计器,纳达拉亚-沃森估计量,Estimateur Nadaraya-Watson,estimateur de Nadaraya-Watson,Estimateur de Nadaraya-Watson,ナダラヤ・ワトソン推定器,ナダラヤ・ワトソン推定量,ナダラヤ=ワトソン推定量,Оценщик Надарая-Ватсона,Оценщик Надарая-Уотсона,Оценка Надарая-Уотсона
247,Naive Bayes,ساذج بايز,- التصنيف البايزي الساذج,بايز الساذج,朴素贝叶斯,朴素贝叶斯,朴素贝叶斯,Bayes naïf,Naive Bayes,Naive Bayes,ナイーブ・ベイズ,素朴ベイズ,単純ベイズ,Наивный Байес,Наивный Байес,Наивный байесовский классификатор
248,Naive Bayes classifier,المصنف ساذج بايز,مصنف بايز الساذج,مُصَنِّف بايز السَّاذِج,朴素贝叶斯分类器,朴素贝叶斯分类器,朴素贝叶斯分类器,Classificateur naïf de Bayes,classifieur Bayesien naïf,classifieur naïf bayésien,単純ベイズ分類器,単純ベイズ分類器,ナイーブベイズ分類器,Наивный классификатор Байеса,Наивный байесовский классификатор,Наивный классификатор Байеса
249,Nash equilibria,توازنات ناش,"- التواز الناش
- سياسعة الناش",توازنات ناش,纳什均衡,纳什均衡,纳什均衡,Équilibres de Nash,équilibres de Nash,équilibres de Nash,ナッシュ均衡,ナッシュ均衡,ナッシュ均衡,Равновесия Нэша,Равновесие по Нэшу,Нэшевские равновесия
250,Nash welfare,رفاهية ناش,رفاهية ناش,الرفاهية النَاشية,纳什福利,纳什福利,纳什福利,Bien-être de Nash,Bien-être de Nash,Bien-être de Nash,ナッシュの福祉,ナッシュ厚生,ナッシュ厚生,Нэш благосостояния,Велфер Нэша,Вэлфер Нэша
251,Nearest Neighbor,اقرب جار,أقرب جار,أقرب جار,最近的邻居,最近邻Neighbor,最近邻,Voisin le plus proche,Plus proche voisin,Plus proche voisin,最近隣,最近傍点,最近傍,Ближайший сосед,Ближайший сосед,Ближайший сосед
252,Nesterov momentum,زخم نيستيروف,زخم نيستيروف,زخم نسترف,涅斯特罗夫动量,Nesterov动量,纳斯特罗夫动量,L'élan de Nesterov,Momentum de Nesterov,Moment de Nesterov,ネステロフの勢い,ネステロフモーメンタム,ネステロフモーメンタム,Нестеров импульс,"""['Для уменьшения потребления памяти на видеокартах обратитесь к нашему техническому отчету о память-эффективной реализации DenseNets [26]. Следуя [8], мы используем коэффициент затухания весов 10-4 и метод Нестерова [35] равный 0.9 без з",Нестеровский момент
253,Neural Information Processing Systems,نظم معالجة المعلومات العصبية,نظم معالجة المعلومات العصبية,أنظمة معالجة المعلومات العصبية,神经信息处理系统,神经信息处理系统,神经信息处理系统,Systèmes de traitement de l'information neuronale,Systèmes de traitement de l'information neuronale,Systèmes de traitement de l'information neuronale,神経情報処理システム,ニューラル情報処理システム,ニューラル情報処理システム,Нейронные системы обработки информации,Нейронные системы обработки информации,Нейронные системы обработки информации
254,Neural Network,الشبكة العصبية,شبكة عصبية,شبكة عصبية,神经网络,神经网络,神经网络,Réseau neuronal,Réseau de neurones,Réseau de neurones,ニューラルネットワーク,ニューラルネットワーク,ニューラルネットワーク,Нейронная сеть,Нейронная сеть,Нейронная сеть
255,Newton method,طريقة نيوتن,- التحليل العددي لنيوتن,طريقة نيوتن,牛顿法,牛顿法,牛顿法,Méthode de Newton,méthode de Newton,méthode de Newton,ニュートン法,ニュートン法 (Nyūton-hō),ニュートン法,метод Ньютона,Метод Ньютона,метод Ньютона
256,Newton's method,طريقة نيوتن,طريقة نيوتن,طريقة نيوتن,牛顿法,牛顿法,牛顿法,La méthode de Newton,méthode de Newton,méthode de Newton,ニュートン法,ニュートン法,ニュートン法,метод Ньютона,Метод Ньютона,Метод Ньютона
257,Nom-Bank,نوم-بنك,"""['على الرغم من تغطيتها الكبيرة، لا يغطي بنك الأسماء جميع الحجج داخل الجملة ويتجاهل حجج خارج الجملة تمامًا. هذه الحجج، التي نسميها ضمنية، مهمة لمعالجة المعن",بنك الأسماء,名义银行,非主题银行,名词论元库,Nom-Banque,Nom-Bank,Banque de noms,ノムバンク,ノムバンク,Nomバンク,Ном-Банк,Ном-Банк,Ном-Банк
258,Nyström approximation,تقريب نيستروم,تقريب نايستروم,تقريب Nyström,尼斯特罗姆近似,奈斯特伦近似,Nyström逼近,approximation de Nyström,Approximation de Nyström,approximation de Nyström,ニストローム近似,ナイストレム近似,ニーストロム近似,Приближение Нистрема,Аппроксимация Найстрёма,Приближение Нистрёма
259,Ornstein-Uhlenbeck,أورنستين أولينبيك,أورنستين-أولنبيك,عملية أورنشتاين-أولنبيك,奥恩斯坦-乌伦贝克,奥恩斯坦-乌伦贝克,奥恩斯坦-乌伦贝克过程,Ornstein-Uhlenbeck,Ornstein-Uhlenbeck,Ornstein-Uhlenbeck,オーンスタイン・ウーレンベック,オーレンスタインウーレンベック,オルンシュタイン・ウーレンベック過程,Орнштейн-Уленбек,Орнштейн-Уленбек,Орнштейн-Уленбек
260,Pareto dominate,باريتو يهيمن,تفوق باريتو,يتفوق باريتو,帕累托占主导地位,帕累托支配,帕累托优势,Pareto domine,dominer de Pareto,dominer au sens de Pareto,パレート支配,パレート支配,パレート優位,Парето доминирует,Парето-доминирование,Парето-доминировать
261,Pareto frontier,حدود باريتو,الحدود باريتو,حدود باريتو,帕累托前沿,帕累托前沿,帕累托边界,Frontière de Pareto,frontière de Pareto,Frontière de Pareto,パレートフロンティア,パレートフロンティア,Pareto最適曲線,граница Парето,граница Парето,Парето-граница
262,Pearson correlation,إرتباط بيرسون,الترابط بيرسون,ارتباط بيرسون,皮尔逊相关系数,皮尔逊相关性,皮尔逊相关系数,Corrélation de Pearson,Corrélation de Pearson,corrélation de Pearson,ピアソン相関,ピアソン相関,ピアソン相関係数,Корреляции Пирсона,Корреляция Пирсона,Коэффициент корреляции Пирсона
263,Pearson correlation coefficient,معامل ارتباط بيرسون,معامل ارتباط بيرسون,معامل ارتباط بيرسون,皮尔逊相关系数,皮尔逊相关系数,皮尔逊相关系数,Coefficient de corrélation de Pearson,- Coefficient de corrélation de Pearson,coefficient de corrélation de Pearson,ピアソン相関係数,ピアソン相関係数,ピアソンの相関係数,Коэффициент корреляции Пирсона,Коэффициент корреляции Пирсона,Коэффициент корреляции Пирсона
264,Pearson's correlation,ارتباط بيرسون,- الترابط بيرسون,ارتباط بيرسون,皮尔逊相关系数,皮尔逊相关性,皮尔逊相关系数,Corrélation de Pearson,Corrélation de Pearson,coefficient de corrélation de Pearson,ピアソンの相関関係,"""他の人気のある歪み測定のクラスには、正規化されたドット積（コサイン類似度）やピアソンの相関などの方向の類似関数が含まれます。クラスタリングタスクに最適な歪み測定を選択する際は、データセットの固有の特性を考",ピアソンの相関,Корреляция Пирсона,Корреляция Пирсона,Коэффициент корреляции Пирсона
265,Pearson's correlation coefficient,معامل ارتباط بيرسون,معامل الترابط بيرسون,معامل ارتباط بيرسون,皮尔逊相关系数,皮尔逊相关系数,皮尔逊相关系数,Coefficient de corrélation de Pearson,Coefficient de corrélation de Pearson,Coefficient de corrélation de Pearson,ピアソンの相関係数,ピアソンの相関係数,ピアソンの相関係数,Коэффициент корреляции Пирсона,Коэффициент корреляции Пирсона,Коэффициент корреляции Пирсона
266,Pearson's r,بيرسون ر,معامل بيرسون,نسبة بيرسون,皮尔逊氏,皮尔逊相关系数,皮尔逊相关系数,Pearson,coefficient de corrélation de Pearson,Pearson's r,ピアソンのr,ピアソンのr,Pearsonのr,Пирсона р,Коэффициент корреляции Пирсона,Коэффициент Пирсона
267,Pearson's r correlation,علاقة بيرسون r,الارتباط بيرسون لـ r,معامل ارتباط بيرسون,皮尔逊 r 相关性,皮尔逊相关系数,皮尔逊相关系数,Corrélation r de Pearson,corrélation de Pearson,coefficient de corrélation de Pearson,ピアソンのr相関,ピアソンのr相関,ピアソンの相関係数,R-корреляция Пирсона,Корреляция Пирсона,Корреляция Пирсона r
268,Penn English Treebank,بنسلفانيا تريبانك الإنجليزية,- التجمع اللغوي للغة الإنجليزية في بن (Penn English Treebank),شجرة بنسلفانيا الإنجليزية,宾夕法尼亚大学英语树库,宾夕法尼亚英语语料库,宾州英语树库,Banc d'arbres Penn English,Penn English Treebank,Penn Treebank anglais,ペン・イングリッシュ・ツリーバンク,ペン英語ツリーバンク,ペン英語ツリーバンク (Penn English Treebank),Пенн Инглиш Трибэнк,Пеннский английский деревянный банк,Пенсильванский корпус английского языка
269,Penn Treebank corpus,مجموعة بن تريبانك,مجموعة بين تريبانك,جسم بن تريبانك,宾夕法尼亚大学树库语料库,宾夕法尼亚树库语料库,宾夕法尼亚树库语料库 (Penn Treebank corpus),Corpus Penn Treebank,- Corpus Penn Treebank,corpus Penn Treebank,ペン・ツリーバンク・コーパス,ペンツリーバンクコーパス,Penn Treebank コーパス,Корпус Пенн-Трибэнк,Корпус Penn Treebank,корпус Penn Treebank
270,Perceptron,بيرسبترون,البيرسيبترون,المستقبل,感知器,感知器,感知机,Perceptron,Perceptron,Perceptron,パーセプトロン,パーセプトロン,単層パーセプトロン,Персептрон,Перцептрон,Перцептрон
271,Perron-Frobenius theorem,نظرية بيرون فروبينيوس,نظرية بيرون-فروبنيوس,نظرية بيرون-فروبينيوس,佩伦-弗罗贝尼乌斯定理,培龙-弗罗贝尼乌斯定理,佩伦-弗罗贝尼乌斯定理,Théorème de Perron-Frobenius,Théorème de Perron-Frobenius,théorème de Perron-Frobenius,ペロン・フロベニウスの定理,ペロン・フロベニウスの定理,ペロン・フロベニウス定理,Теорема Перрона-Фробениуса,Теорема Перрона-Фробениуса,Теорема Перрона-Фробениуса
272,Pinsker's inequality,عدم المساواة بينسكر,عدم المساواة بينسكر,متساوية بينسكر,平斯克不等式,平斯克不等式,平斯克不等式,L'inégalité de Pinsker,Inégalité de Pinsker,inégalité de Pinsker,ピンスカーの不等式,ピンスカーの不等式,ピンスカーの不等式,Неравенство Пинскера,Неравенство Пинскера,Неравенство Пинскера
273,Pitman-Yor process,عملية بيتمان-يور,عملية بيتمان-يور,عملية بيتمان-يور,皮特曼-约尔法,皮特曼-尤尔过程,皮特曼-约尔过程,Processus Pitman-Yor,Processus Pitman-Yor,processus de Pitman-Yor,ピットマン・ヨールプロセス,ピットマン・ヨア過程 (Pitman-Yor Process),ピットマン・ヨア過程,Процесс Питмана-Йора,Процесс Питмана-Йора,Процесс Питмана-Йора
274,Poisson matting,حصيرة بواسون,التظليل بواسطة معادلة بواسون,تحسين بواسون,泊松抠图,泊松抠图,泊松抠像,Tapis de poisson,Poisson matting,Matting de Poisson,ポアソンマット,ポアソンマッティング,ポワソンマッティング,Пуассоновое матирование,Пуассоновская маскировка,Пуассоновское размытие изображения
275,Poisson model,نموذج بواسون,النموذج البواسوني,نموذج بواسون,泊松模型,泊松模型,泊松模型,Modèle de Poisson,modèle de Poisson,Modèle de Poisson,ポアソンモデル,ポアソンモデル,ポアソンモデル,Модель Пуассона,Модель Пуассона,Пуассоновская модель
276,Poisson process,عملية بواسون,عملية بواسون,عملية بوأسون,泊松过程,泊松过程,泊松过程,Processus de Poisson,processus de Poisson,Processus de Poisson,ポアソン過程,ポアソン過程,ポアソン過程,Пуассоновский процесс,Процесс Пуассона,Пуассоновский процесс
277,Poisson regression,انحدار بواسون,- تحليل بواسون,انحدار بواسون,泊松回归,泊松回归,泊松回归,Régression de Poisson,Régression de Poisson,régression de Poisson,ポアソン回帰,ポアソン回帰,ポアソン回帰,Регрессия Пуассона,Регрессия Пуассона,Регрессия Пуассона
278,Poisson sampling,أخذ عينات بواسون,التصويب البواسوني,أخذ عينات بواسون,泊松采样,泊松抽样,泊松采样,Échantillonnage de Poisson,Échantillonnage de Poisson,échantillonnage de Poisson,ポアソンサンプリング,ポアソンサンプリング,ポアソン抽出,Выборка по Пуассону,Пуассоновская выборка,Пуассоновское семплирование
279,Potts model,نموذج بوتس,نموذج بوتس,نموذج بوتس,波茨模型,波茨模型,波茨模型,Modèle Potts,modèle de Potts,modèle de Potts,ポッツモデル,ポッツモデル,ポッツモデル,Модель Поттса,Модель Поттса,Модель Поттса
280,Prop-Bank,بنك الدعم,بروب بانك,بنك الدعامات,自营银行,语义角色标注库,论元行库,Prop-Banque,Prop-Bank,PropBank,プロップバンク,プロップバンク,プロップバンク,Проп-Банк,Проп-банк,Банк предикатов
281,Py-Torch,باي الشعلة,باي تورش,باي-تورش,Py-Torch,PyTorch,PyTorch,Torche Py,PyTorch,PyTorch,パイトーチ,パイ・トーチ,PyTorch,Пай-Факел,Пай-Торч,PyTorch
282,Rademacher average,راديماخر متوسط,"""['نتجه الآن إلى متغير أكثر توحيدًا من المبرهنة 1، والذي يعتمد على مفاهيم مألوفة لتعقيد الدوال استنادًا إلى متوسطات راديماخر. لعينة x 1 ، . . . ، x n",متوسط رادمشر,拉德马赫平均数,拉德马赫平均。,拉德马赫平均值,Moyenne Rademacher,moyenne de Rademacher,moyenne de Rademacher,ラドマッハ平均,ラデマッハー平均,ラデマッハー平均,Среднее Радемахера,радемахеровское среднее,Среднее Радемахера
283,Radon-Nikodym derivative,مشتق الرادون نيكوديم,المشتقة رادون-نيكوديم,المشتقة الرادونية-نيكوديمية,氡-Nikodym 衍生物,Radon-Nikodym 导数,拉东-尼科丁导数,Dérivé Radon-Nikodym,dérivée de Radon-Nikodym,Dérivée de Radon-Nikodym,ラドンニコジム誘導体,ラドン・ニコディム導関数,ラドン・ニコディム導関数,Производное Радона-Никодима,Производная Радона-Никодима,Производная Радона-Никодима
284,Random Forest,غابة عشوائية,- تجميع عشوائي,غابة عشوائية,随机森林,随机森林,随机森林,Forêt aléatoire,Forêt aléatoire,Forêt aléatoire,ランダムフォレスト,ランダムフォレスト,ランダムフォレスト,Случайный лес,Случайный лес,Случайный Лес
285,Rao-blackwellization,راو بلاكويليزيشن,- المعايرة براو-بلاكويلية,التراو-التسويد,拉奥-布莱克韦尔化,Rao-Blackwell化,拉奥-布莱克维尔化,Rao-blackwellisation,Rao-Blackwellisation,Rao-blackwellisation,Rao-ブラックウェル化,Rao-Blackwell化,ラオ・ブラックウェル化法,Рао-блэквеллизация,Рао-Блэквеллизация,Рао-блэквеллизация
286,Recurrent Neural Network,الشبكة العصبية المتكررة,شبكة عصبونية متكررة,شبكة عصبية متكررة,循环神经网络,循环神经网络 (Recurrent Neural Network),循环神经网络,Réseau neuronal récurrent,Réseau de neurones récurrent,Réseau de neurones récurrents,リカレント ニューラル ネットワーク,再帰ニューラルネットワーク,再帰ニューラルネットワーク,Рекуррентная нейронная сеть,Рекуррентная нейронная сеть,Рекуррентная нейронная сеть
287,Reformer,المصلح,المحسن,الإصلاحي (Reformer),塑身机,改革者,重构模型,Réformateur,Réformateur,Réformateur,改革者,改革者 (Kaikakusha),リフォーマー (Reformer),Реформатор,Реформатор,Реформатор
288,ResNeXt,ريسنيكست,ResNeXt,شبكة التكرار التالية,剩余下一个,ResNeXt,残递神经网络,ResNeXt,ResNeXt,ResNeXt,レスネクスト,ResNeXt,ResNeXt (ResNetの次の拡張版),Реснекст,ResNeXt,ResNeXt
289,Robertson-Webb model,نموذج روبرتسون ويب,نموذج روبرتسون-ويب,نموذج روبرتسون-ويب,罗伯逊-韦伯模型,罗伯逊-韦伯模型,罗伯逊-韦伯模型,Modèle Robertson-Webb,Modèle de Robertson-Webb,modèle de Robertson-Webb,ロバートソン・ウェッブモデル,ロバートソン・ウェブモデル (Robertson-Webb model),ロバートソン・ウェブモデル,Модель Робертсона-Уэбба,модель Робертсона-Уэбб,Модель Робертсона-Уэбба
290,Runge-Kutta,رونج-كوتا,رونغ-كوتا,طريقة رانج-كوتا,龙格-库塔,Runge-Kutta算法,Runge-Kutta 龙格库塔法,Runge-Kutta,Runge-Kutta,Runge-Kutta,ルンゲ クッタ,ルンゲ・クッタ,ルンゲ＝クッタ,Рунге-Кутта,Метод Рунге-Кутты,Метод Рунге-Кутты
291,Runge-Kutta method,طريقة رونج-كوتا,طريقة رنج-كوتا,طريقة رنج-كوتا,龙格-库塔法,龙格-库塔法,朗格-库塔法,Méthode Runge-Kutta,méthode de Runge-Kutta,méthode de Runge-Kutta,ルンゲ・クッタ法,ルンゲクッタ法,ルンゲ・クッタ法,Метод Рунге-Кутты,Метод Рунге-Кутта 4-го порядка,Метод Рунге-Кутты
292,Rényi entropy,ريني إنتروبيا,التشوش الريني,إنتروبيا رينيي,雷尼熵,Rényi熵,雷尼熵,Entropie Rényi,Entropie de Rényi,Entropie de Rényi,レンイエントロピー,レニー・エントロピー,レニーエントロピー,Энтропия Реньи,Энтропия Реньи,Энтропия Рéнйи
293,S-expression,تعبير S,تعبير-إس-التعبيرات,التعبير الصريح (S-expression),S-表达,S-表达式,S-表达式,Expression S,S-expression,Expression-S,S式,S-式,S式 (エス-しき),S-выражение,S-выражение,S-выражения
294,Schur complement,تكملة شور,المثيل شور,مكمل شور,舒尔补语,舒尔补,舒尔补,Complément de Schur,Complément de Schur,Complément de Schur,シュール補体,シューア補題,シューア補間,дополнение Шура,Шура-дополнение,Шур-дополнение
295,Scikit-learn,Scikit تعلم,"""['(v) نتائج تجريبية شاملة على البيانات الاصطناعية والواقعية لحلول LMS الشائعة في مكتبة سكاي كيت للتعلم باستخدام CPython أو توزيع إنتل.']""",حزمة Scikit-learn,Scikit-learn,Scikit-learn,Scikit-learn,Scikit-apprendre,Scikit-learn,Scikit-apprendre,Scikit-Learn,Scikit-learn,Scikit-learn,Scikit-обучение,Scikit-learn,Scikit-learn
296,Semantic Scholar,عالم دلالي,موسوعة العلم الدلالي,الباحث الدلالي,语义学者,语义学者,语义学者 (Semantic Scholar),Érudit sémantique,- Semantic Scholar,Savant sémantique,意味学者,セマンティック・スカラー,セマンティック・スカラー (Semantic Scholar),Семантический ученый,Семантический ученый,семантический ученый
297,Semantic Web,الويب الدلالي,الويب الدلالي,الويب الدلالي,语义网,语义网,语义网,Web sémantique,Toile Sémantique,Toile sémantique,セマンティックウェブ,セマンティック・ウェブ,意味ウェブ,Семантическая сеть,Семантическая паутина,Семантическая Паутина
298,Seq2Seq,Seq2Seq,التسلسل إلى التسلسل,تتابع إلى تتابع,序列到序列,Seq2Seq,序列到序列,Séq2Séq,Seq2Seq,Seq2Seq,シーケンス 2 シーケンス,Seq2Seq,系列から系列へのモデル,Seq2Seq,Seq2Seq,Seq2Seq -> Seq2Seq
299,Set cover,تعيين الغطاء,- تغطية المجموعة,غطاء المجموعة,设置封面,集合覆盖,集合覆盖问题,Définir la couverture,Couverture d'ensemble,Couverture d'ensemble,セットカバー,セット被覆,集合被覆問題,Установить крышку,Покрытие множеством,Задача о покрытии множества
300,Shannon entropy,إنتروبيا شانون,التشوش شانون,إنتروبيا شانون,香农熵,香农熵,香农熵,Entropie de Shannon,- Entropie de Shannon,entropie de Shannon,シャノンのエントロピー,シャノンエントロピー (Shanon entoropī),シャノンエントロピー,Энтропия Шеннона,Энтропия Шеннона,Энтропия Шеннона
301,Sherman-Morrison formula,صيغة شيرمان موريسون,صيغة شيرمان موريسون,صيغة شيرمان-موريسون,谢尔曼-莫里森公式,Sherman-Morrison公式,谢尔曼-莫里森公式,Formule Sherman-Morrison,Formule de Sherman-Morrison,Formule de Sherman-Morrison,シャーマン・モリソン式,シャーマン・モリソンの公式,シャーマン・モリソン公式,Формула Шермана-Моррисона,Формула Шермана-Моррисона,Формула Шермана-Моррисона
302,Sherman-Morrison-Woodbury formula,صيغة شيرمان-موريسون-ودبري,صيغة شيرمان-موريسون-وودبوري,صيغة شيرمان-موريسون-وودبري,谢尔曼-莫里森-伍德伯里公式,谢尔曼-莫里森-伍德伯里公式,舍尔曼-莫里森-伍德伯里公式,Formule Sherman-Morrison-Woodbury,Formule de Sherman-Morrison-Woodbury,formule de Sherman-Morrison-Woodbury,シャーマン・モリソン・ウッドベリー式,シャーマン・モリソン・ウッドベリーの公式 (Sherman-Morrison-Woodbury formula),シャーマン・モリソン・ウッドベリー公式,Формула Шермана-Моррисона-Вудбери,Формула Шермана-Моррисона-Вудбери,Формула Шермана-Моррисона-Вудбери
303,Sinkhorn algorithm,خوارزمية سينكورن,خوارزمية Sinkhorn,خوارزمية سينكهورن,沉克霍恩算法,Sinkhorn算法,辛克霍恩算法,Algorithme Sinkhorn,Algorithme de Sinkhorn,algorithme de Sinkhorn,シンクホーンアルゴリズム,Sinkhornアルゴリズム,シンクホーン・アルゴリズム,Алгоритм Синкхорна,Алгоритм Синкхорна,Алгоритм Синкхорна
304,Sparsemax,سبارسماكس,المتناثرة,تراصفي,稀疏最大,稀疏最大值,稀疏最大化,clairsemémax,Sparsemax,Sparsemax,スパースマックス,スパースマックス,スパースマックス,Спарсемакс,Sparsemax - Спарсмакс,Спарсемакс
305,Spearman's correlation,علاقة سبيرمان,ترابط سبيرمان,معامل ارتباط سبيرمان,斯皮尔曼相关系数,斯皮尔曼相关（Spearman's correlation）,斯皮尔曼相关系数,Corrélation de Spearman,- Corrélation de Spearman,corrélation de Spearman,スピアマンの相関関係,スピアマンの相関,スピアマンの相関係数,Корреляция Спирмена,Корреляция Спирмена,Коэффициент ранговой корреляции Спирмена
306,Spearman's correlation coefficient,معامل ارتباط سبيرمان,معامل ارتباط سبيرمان,معامل ارتباط سبيرمان,斯皮尔曼相关系数,斯皮尔曼相关系数,斯皮尔曼相关系数,Coefficient de corrélation de Spearman,- Coefficient de corrélation de Spearman,Coefficient de corrélation de Spearman,スピアマンの相関係数,スピアマンの順位相関係数,スピアマンの順位相関係数,Коэффициент корреляции Спирмена,Коэффициент корреляции Спирмена,Коэффициент ранговой корреляции Спирмена
307,Spearman's rank correlation coefficient,معامل ارتباط الرتب لسبيرمان,معامل ارتباط سبيرمان للرتب,معامل ارتباط رتب سبيرمان,Spearman 等级相关系数,斯皮尔曼等级相关系数,斯皮尔曼等级相关系数,Coefficient de corrélation de rang de Spearman,Coefficient de corrélation de rang de Spearman,coefficient de corrélation des rangs de Spearman,スピアマンの順位相関係数,スピアマンの順位相関係数,スピアマンの順位相関係数,Коэффициент ранговой корреляции Спирмена,Коэффициент корреляции рангов Спирмена,Коэффициент ранговой корреляции Спирмена
308,Squared Exponential kernel,النواة الأسية التربيعية,نواة التربيع التسلسلي,متجه معامل التربيع الأسي,平方指数核,平方指数核,平方指数核,Noyau exponentiel au carré,Noyau exponentiel au carré,noyau exponentiel carré,二乗指数カーネル,二乗指数カーネル,二乗指数カーネル,Ядро квадратной экспоненты,Квадратичное экспоненциальное ядро,Ядро квадратичной экспоненты
309,Stanford Parser,ستانفورد محلل,محلل ستانفورد,محلل ستانفورد,斯坦福解析器,斯坦福解析器,斯坦福句法分析器,Analyseur Stanford,Stanford Parser,Analyseur de Stanford,スタンフォードパーサー,スタンフォードパーサー,スタンフォードパーサー (Stanford Parser),Стэнфордский парсер,Stanford Парсер,Анализатор Стэнфорда (Stanford Parser)
310,Stanford Sentiment Treebank,ستانفورد سينتمنت تريبانك,شجرة مشاعر ستانفورد,بنك شجرة مشاعر ستانفورد,斯坦福情绪树库,斯坦福情感树库,斯坦福情感树库,Banque d'arbres de sentiments de Stanford,Stanford Sentiment Treebank,Banque d'arbres de sentiments de Stanford,スタンフォード・センチメント・ツリーバンク,スタンフォード感情木構造データセット,スタンフォード感情ツリーバンク,Стэнфордское дерево настроений,Stanford Sentiment Treebank - Дерево настроения Стэнфорда,Стэнфордский эмоциональный корпус
311,Stanford dependency,تبعية ستانفورد,التبعية ستانفورد,الاعتماديات ستانفوردية,斯坦福依赖,斯坦福依存,斯坦福依存关系,Dépendance à Stanford,Dépendances de Stanford,dépendances de Stanford,スタンフォードへの依存,スタンフォード依存関係,スタンフォード依存構造,Стэнфордская зависимость,Stanford зависимости,Стэнфордские зависимости
312,Stanford dependency framework,إطار التبعية في ستانفورد,الإطار الاعتمادي لجامعة ستانفورد,إطار الاعتمادية في ستانفورد,斯坦福依赖框架,斯坦福依赖关系框架,斯坦福依存框架,Cadre de dépendance de Stanford,Cadre de dépendance de Stanford,cadre de dépendance de Stanford,スタンフォード依存関係フレームワーク,スタンフォード依存フレームワーク,スタンフォード依存構造フレームワーク,Стэнфордская структура зависимостей,Фреймворк зависимостей Stanford,Структура зависимостей Стэнфордского университета
313,Stanford dependency parser,محلل التبعية في ستانفورد,محلل التبعيات من جامعة ستانفورد,محلل التركيب التوالدي لستانفورد,斯坦福依存解析器,斯坦福依存句法分析器,斯坦福依存句法分析器,Analyseur de dépendances de Stanford,Analyseur syntaxique de Stanford,analyseur de dépendances de Stanford,スタンフォード依存関係パーサー,スタンフォード依存構文解析器,スタンフォード依存構造解析器,Стэнфордский парсер зависимостей,Парсер зависимостей Стэнфорда,Парсер синтаксических зависимостей Стэнфорда
314,Stanford question answer dataset,مجموعة بيانات الإجابة على أسئلة ستانفورد,مجموعة بيانات أسئلة ستانفورد,مجموعة بيانات أسئلة وأجوبة ستانفورد,斯坦福问答数据集,斯坦福问题回答数据集,斯坦福问答数据集 (SQuAD),Ensemble de données de réponse aux questions de Stanford,Ensemble de données de questions réponses de Stanford,Ensemble de données de questions-réponses de Stanford (SQuAD),スタンフォードの質問回答データセット,スタンフォード質問応答データセット,スタンフォード質問回答データセット (SQuAD),Стэнфордский набор данных вопросов и ответов,Набор данных Stanford по вопросам и ответам,Набор вопросов и ответов Стэнфордского университета (Stanford Question Answer Dataset)
315,Subgraph,رسم بياني فرعي,الرسم البياني الجزئي,رسم بياني فرعي,子图,子图,子图,Sous-graphique,Sous-graphique,Sous-graphe,サブグラフ,部分グラフ (Subgraph),部分グラフ,Подграф,Подграф,подграф
316,Support Vector Machine,دعم شاحنات النقل,آلة الدعم بالنواقل,نظام الدعم الفاصل,支持向量机,支持向量机,支持向量机,Machine à vecteurs de support,"""['apprendre les fonctions latentes pour la régression ordinale, et (7) la machine à vecteurs de support Laplacien (LapSVM) (Melacci et Mikhail 2011), un schéma de classification SVM semi-supervisé.', 'En plus du Lasso hiérarchique faible non-convexe et convexe, nous appliquons la forêt aléatoire (RF), la machine à vecteurs de support (SVM) et la régression logistique parcimonieuse sur les",Machine à vecteurs de support,サポートベクターマシン,サポートベクトルマシン (Support Vector Machine),サポートベクターマシン,Машина опорных векторов,Машина опорных векторов,Машина опорных векторов
317,Swin-S,سوين-S,سوين-إس,شَوين-إس,斯温-S,Swin-S,移位窗口Transformer,Swin-S,Swin-S,Swin-S,スウィンS,スイン-S,"シフトウィンドウに基づいたSwinTransformerアーキテクチャは、スライディングウィンドウに基づいた変種と比較して、Swin-T、Swin-S、Swin-Bでそれぞれ4.1/1.5、4.0/1.5、3.6/1.5倍高速である。

Swin-S",Свин-С,Swin-S - Свин-С,Swin-S
318,T5-11b,T5-11ب,T5-11ب,T5-11b,T5-11b,T5-11B,T5-11B,T5-11b,T5-11B,T5-11B,T5-11b,T5-11B,T5-11B,Т5-11б,T5-11b,T5-11б
319,T5-11b model,نموذج T5-11b,- ت5-11ب نموذج,نموذج T5-11b,T5-11b型号,T5-11B模型,T5-11b 模型,Modèle T5-11b,Modèle T5-11B,modèle T5-11b,T5-11bモデル,T5-11bモデル,T5-11bモデル,Модель Т5-11б,модель T5-11b,Модель T5-11B
320,T5-large,T5-كبير,T5-كبير,T5-كبيرة,T5-大号,T5大,T5-大型模型,T5-grand,T5-large,T5-large,T5-大,T5-Large,T5-大規模モデル,Т5-большой,T5-Большой,T5-large
321,Tanh,تانه,- التانج,تانه,谭,双曲正切 (Tanh),双曲正切函数 (Tanh),Tanh,Tanh,Tanh,タン,Tanh,タンハ関数,Тань,Тангенс-гиперболический (Tanh),Тангенс гиперболический
322,Taylor approximation,تقريب تايلور,- تقريب تايلور,تقريب تايلور,泰勒近似,泰勒展开近似,泰勒近似,approximation de Taylor,- Approximation de Taylor,Approximation de Taylor,テイラー近似,テイラー近似,テイラー近似,Аппроксимация Тейлора,Аппроксимация Тейлора,Приближение Тейлора
323,Theano,ثينو,تيانو,تيانو,西阿诺,Theano,Theano,Théano,Theano,Theano,テアノ,テアノ,Theano,Теано,Theano,Теано
324,Toeplitz matrix,مصفوفة توبليتز,مصفوفة توبليتز,مصفوفة توبليتز,托普利兹矩阵,Toeplitz矩阵,托普利茨矩阵,Matrice de Toeplitz,- Matrice de Toeplitz,matrice de Toeplitz,テプリッツ行列,トープリッツ行列 (Tōpurittsu gyōretsu),トープリッツ行列,Матрица Теплица,Матрица Тёплица,Матрица Тёплица
325,Transformer,محول,المحول,محول,变压器,转换器,变换器 (Transformer),Transformateur,Transformateur,Transformateur,変成器,トランスフォーマー,トランスフォーマ,Трансформатор,Трансформер,Трансформер
326,Treebank,تريبانك,مصرف الشجرة,بنك الشجرة,树库,树库,树库,Banc d'arbres,Banque d'arbres,Banque d'arbres,ツリーバンク,木構造データベース,木構造付きコーパス,Древесный берег,"""['В других случаях преобразование в категориальную грамматику различает категории, которые объединены в деревообразном корпусе.', 'Такой лес в стиле деревообразного корпуса легче обрабатывать для переранжировки, поскольку многие характеристики могут быть",Банк деревьев
327,Tucker decomposition,تحلل تاكر,تحليل تاكر,تحليل توكر,塔克分解,Tucker分解,塔式分解,Décomposition de Tucker,Décomposition de Tucker,décomposition de Tucker,タッカー分解,Tucker分解,タッカー分解,Разложение Такера,Декомпозиция Таккера,Тензорное разложение Такера
328,Unigram,يونيجرام,وحدة كلمة,نقرة واحدة,一元语法,单字频率,单元语,Unigramme,Unigram,Unigramme,ユニグラム,単語頻度,ユニグラム,Униграмма,Униграмма,Униграмма
329,Universal dependency,التبعية العالمية,- التبعية العالمية,الاعتماديات العالمية,普遍依赖性,,通用依存关系,Dépendance universelle,Dépendance universelle,dépendances universelles,普遍的な依存関係,ユニバーサル依存関係,汎用依存関係 (はんよういぞんかんけい),Универсальная зависимость,Универсальная зависимость,универсальные зависимости (Universal Dependencies)
330,Upper confidence Bound,الثقة العليا ملزمة,- التقييد الثقة العلوي,حد الثقة الأعلى,置信上限,上置信界限 (Upper Confidence Bound),上置信边界 (Upper Confidence Bound),Limite de confiance supérieure,Limite de confiance supérieure,Borne de confiance supérieure,上限信頼限界,上側信頼境界 (UCB),上限信頼区間,Верхняя доверительная граница,Верхняя доверительная граница (UCB),Верхняя доверительная граница
331,Vandermonde matrix,مصفوفة فاندرموند,مصفوفة فانديرموند,مصفوفة فاندرموند,范德蒙矩阵,范德蒙矩阵,范德蒙矩阵,Matrice de Vandermonde,- Matrice de Vandermonde,Matrice de Vandermonde,ヴァンデルモンド行列,ヴァンデルモンド行列,バンデルモンド行列,Матрица Вандермонда,матрица Вандермонда,матрица Вандермонда
332,Vertex cover,غطاء قمة الرأس,- تغطية الرأسية,غطاء الرأس,顶点覆盖,顶点覆盖,顶点覆盖,Couverture du sommet,Couverture de sommets,Couverture de sommets,頂点カバー,頂点被覆 (vertex cover),頂点被覆,Крышка вершины,Вершинное покрытие,Вершинное покрытие
333,Viterbi,فيتربي,فيتيربي,فيتربي,维特比,维特比,维特比,Viterbe,Viterbi,Viterbi,ビタビ,ヴィタービ,ビタビ,Витерби,Витерби,Витерби
334,Viterbi algorithm,خوارزمية فيتيربي,خوارزمية فيتيربي,خوارزمية فيتربي,维特比算法,维特比算法,维特比算法,Algorithme de Viterbi,algorithme de Viterbi,algorithme de Viterbi,ビタビアルゴリズム,ヴィタビアルゴリズム (Viterbi algorithm),ビタビアルゴリズム,Алгоритм Витерби,Алгоритм Витерби,Алгоритм Витерби
335,Wasserstein distance,مسافة فاسرشتاين,مسافة فازرشتاين,مسافة واسرشتاين,瓦瑟斯坦距离,Wasserstein距离,瓦谢斯坦距离,Distance de Wasserstein,distance de Wasserstein,Distance de Wasserstein,ワッサーシュタイン距離,ワッサシュタイン距離,ワッセルスタイン距離,Расстояние Вассерштейна,Расстояние Вассерштейна,Расстояние Вассерштейна
336,Weibull,ويبول,- توزيع وايبول,وايبل,威布尔,威布尔,威布尔 (Weibull),Weibull,Weibull,Weibull,ワイブル,ワイブル,ワイブル分布,Вейбулл,Вейбулл,Вейбулл
337,Weisfeiler-Lehman test,اختبار فايسفيلر-ليمان,اختبار ويسفيلر-ليمان,اختبار ويسفيلر-ليهمان,魏斯费勒-雷曼检验,维斯费勒-莱曼检验,魏斯费勒-莱曼测试,Test de Weisfeiler-Lehman,test de Weisfeiler-Lehman,test de Weisfeiler-Lehman,ヴァイスファイラー・リーマン検定,ワイスファイラー・レーマンテスト,Weisfeiler-Lehmanテスト,Тест Вейсфейлера-Лемана,Тест Вейсфейлера-Леймана,Тест Вайсфайлера-Лемана
338,Wiener process,عملية وينر,- عملية وينر,عملية وينر,维纳过程,维纳过程,维纳过程,Processus de saucisse,- Processus de Wiener,processus de Wiener,ウィンナー法,ウィーナー過程,ウィーナープロセス,Винеровский процесс,Процесс Винера,Винеровский процесс
339,Wilcoxon sign-rank test,اختبار رتبة علامة ويلكوكسون,اختبار ويلكوكسون للمرتبة الموقعية,اختبار ويلكوكسون للرتب الإشارية,Wilcoxon 符号秩检验,威尔科克森符号秩检验,威尔科克森符号秩检验,Test de signe-rang de Wilcoxon,Test de Wilcoxon signé-rang,test des rangs signés de Wilcoxon,ウィルコクソンのサインランク検定,ウィルコクソン符号順位検定,ウィルコクソン符号付き順位和検定,Знако-ранговый критерий Уилкоксона,тест Вилкоксона на знаки рангов,Wilcoxon знаковый ранговый критерий
340,Winograd Schema,مخطط فينوغراد,مخطط وينوغراد,مخطط وينوغراد,维诺格拉德模式,维诺格拉德模式,维诺格拉语境模式,Schéma de Winograd,Schéma de Winograd,Schéma de Winograd,ウィノグラードスキーマ,ウィノグラード・スキーマ (Winograd Schema),ウィノグラード・スキーマ,Схема Винограда,Схема Винограда,Схема Винограда
341,Winograd Schema Challenge,تحدي مخطط فينوغراد,تحدي وينوغراد للمخططات,تحدي شيما وينوغراد,Winograd 模式挑战,温罗格模式挑战,文诺格式挑战,Défi du schéma Winograd,Défi de schéma Winograd,Défi du schéma de Winograd,Winograd スキーマ チャレンジ,ウィノグラード・スキーマ・チャレンジ,ウィノグラードスキーマチャレンジ,Вызов схемы Винограда,Вызов Виноградовой схемы,Проблема схемы Винограда (Winograd Schema Challenge)
342,Winogrande,فينوغراندي,وينوغراندي,وينوجراند,维诺格兰德,威诺格兰德,维诺大问题集,Winogrande,Winogrande,Winogrande,ウィノグランデ,ウィノグランデ,ウィノグランデ,Виногранде,Виногранде,Виноград
343,Woodbury matrix identity,هوية مصفوفة وودبيري,هوية مصفوفة وودبوري,مُعادلة وودبري للمصفوفات,伍德伯里矩阵恒等式,伍德伯矩阵恒等式,伍德伯里矩阵恒等式,Identité matricielle de Woodbury,Identité de la matrice de Woodbury,Identité matricielle de Woodbury,ウッドベリー行列のアイデンティティ,ウッドベリー行列恒等式,ウッドベリー行列恒等式,Матричное тождество Вудбери,Идентичность матрицы Вудбери,Матричная идентичность Вудбери
344,Word2Vec,Word2Vec,وورد تو فيك,نموذج الكلمات,词向量,词向量,Word2Vec,Mot2Vec,Word2Vec,Word2Vec,Word2Vec,Word2Vec,Word2Vec,Word2Vec,Word2Vec,Word2Vec
345,a * algorithm,خوارزمية *,الگوريتم A*,خوارزمية ايه*,一个*算法,A * 算法,A*算法,un * algorithme,un algorithme A*,algorithme A*,* アルゴリズム,A*アルゴリズム,A*アルゴリズム,a * алгоритм,"""['Наш алгоритм расширяет ускорения, достигнутые в 1-м случае лучшего варианта, до случая k-лучшего и является оптимальным при тех же условиях, что и стандартный алгоритм A*.', 'Основной алгоритм A* работает с элементами вывода I(A, i, j),",Алгоритм A*
346,a/b test,اختبار أ/ب,اختبار a/b,اختبار أ/ب,a/b 测试,A/B测试,A/B测试,test a/b,test a/b,test A/B,a/b テスト,"""['We used A/B tests for more targeted comparisons between different systems, namely cold-start vs. fine-tuned and neural vs. concatenative.']""",A/Bテスト,а/б тест,тест A / B,тестирование a/b
347,a2c,a2c,م2ج,نظام a2c,a2c,A2C,A2C (Advantage Actor-Critic),a2c,A2C,a2c,a2c,A2C,A2C (Advantage Actor-Critic),а2с,"""['Модели PLS предоставляют более реалистичную, вероятностную оценку безопасности вместо детерминированной, что позволяет балансировать безопасность и награду, и таким образом контролировать риск. и др., 2015], A2C [Mnih и др., 2016], и т. д.",a2c
348,abductive explanation,تفسير خاطف,تفسير استقرائي,تفسير استقرائي,溯因解释,归纳性解释,归纳式解释,explication abductive,explication abductive,explication abductive,誘拐的な説明,帰納的説明,帰納的説明,абдуктивное объяснение,абдуктивное объяснение,абдуктивное объяснение
349,ablation analysis,تحليل الاجتثاث,تحليل الاستئصال,تحليل الإزالة,消融分析,消融分析 (ablation analysis),消融分析,analyse d'ablation,- Analyse d'ablation,Analyse d'ablation,アブレーション分析,消融解析 (shōmyō kaiseki),切除分析,абляционный анализ,анализ абляции,анализ аблации
350,ablation experiment,تجربة الاجتثاث,تجارب الاستئصال,تجربة استئصال,消融实验,消融实验,消融实验,expérience d'ablation,expérience d'ablation,expérience d'ablation,アブレーション実験,消融実験 (shoumyou jikken),切除実験,эксперимент по абляции,эксперимент по абляции,эксперимент по удалению
351,ablation study,دراسة الاجتثاث,- تحقيق الاستئصال,دراسة الاستئصال,消融研究,消融研究,消融研究,étude d'ablation,étude d'ablation,étude d'ablation,アブレーション研究,削除研究,除去研究,абляционное исследование,абляционное исследование,изучение аблации
352,abstraction,التجريد,التجريد,تجريد,抽象,抽象化,抽象化,abstraction,abstraction,abstraction,抽象化,抽象化 (Choushouka),抽象化,абстракция,абстракция,абстракция
353,abstraction heuristic,ارشادي التجريد,- تجريدية الذكاءية,خوارزمية التجريد,抽象启发式,抽象启发式,抽象启发式,heuristique d'abstraction,heuristique d'abstraction,heuristique d'abstraction,抽象化ヒューリスティック,抽象ヒューリスティック,抽象ヒューリスティック,эвристика абстракции,эвристика абстрагирования,эвристика абстракции
354,abstractive summarization,تلخيص تجريدي,- التلخيص الانطلاقي,تلخيص استنباطي,抽象概括,抽象摘要生成 (abstractive summarization),抽象总结,résumé abstrait,résumé abstrait,résumé abstrait,抽象的な要約,抽象的要約,要約生成,абстрактное обобщение,абстрактное резюмирование,обобщающее резюмирование
355,accelerate gradient descent,تسريع نزول التدرج,التسارع في الهبوط الشيبي,تسريع تدرج الانحدار,加速梯度下降,加速梯度下降,加速梯度下降,accélérer la descente de pente,descente de gradient accélérée,descente de gradient accélérée,勾配降下を加速する,加速勾配降下 (kasoku kouritu kouka),加速勾配降下法,ускорить градиентный спуск,ускоренный градиентный спуск,ускоренный градиентный спуск
356,acceptance function,وظيفة القبول,وظيفة القبول,دالة القبول,接受函数,接受函数,接受函数,fonction d'acceptation,fonction d'acceptation,fonction d'acceptation,受付機能,受容関数 (Juyou Kansuu),受理関数,функция принятия,функция принятия,функция принятия
357,acceptance probability,احتمال القبول,احتمالية القبول,احتمالية القبول,接受概率,接受概率,接受概率,probabilité d'acceptation,probabilité d'acceptation,probabilité d'acceptation,合格確率,受容確率,受理確率,вероятность принятия,вероятность принятия,Вероятность принятия
358,accumulate error,تراكم الخطأ,تراكم الخطأ,تراكم الخطأ,累积误差,累积误差,累积误差,accumuler des erreurs,erreur accumulée,erreur accumulée,累積誤差,蓄積誤差,蓄積誤差,накапливать ошибку,накапливать ошибку,накопленная ошибка
359,accuracy,دقة,الدقة,دقة,准确性,准确度,精度,précision,précision,précision,正確さ,正確性,精度,точность,- Точность,точность
360,acoustic feature,الميزة الصوتية,السمة الصوتية,الميزة الصوتية,声学特征,声学特征,声学特征,caractéristique acoustique,- Caractéristique acoustique,Caractéristique acoustique,音響特性,音響特徴,音響特徴量,акустическая особенность,- Акустическая характеристика,акустическая черта
361,acoustic model,نموذج صوتي,نموذج صوتي,نموذج صوتي,声学模型,声学模型,声学模型,modèle acoustique,modèle acoustique,modèle acoustique,音響モデル,音響モデル (onkyo moderu),音響モデル,акустическая модель,акустическая модель,Акустическая модель
362,acquisition function,وظيفة الاستحواذ,وظيفة الاستحواذ,دالة الاكتساب,采集功能,获取函数,采集函数,fonction d'acquisition,fonction d'acquisition,fonction d'acquisition,取得機能,取得関数 (shutoku kansu),取得関数,функция сбора данных,функция приобретения,функция приобретения
363,action classification,تصنيف العمل,تصنيف الإجراءات,تصنيف الفعل,动作分类,动作分类,动作分类,classement des actions,Classification d'actions,classification d'actions,アクションの分類,アクション分類 (Action Bunrui),行動分類,классификация действий,Классификация действий,В компьютерном зрении действие классификации
364,action embedding,تضمين الفعل,تضمين الإجراءات,تضمين العمل,动作嵌入,动作嵌入,动作嵌入,intégration d'actions,intégration de l'action,plongement d'action,アクションの埋め込み,アクション埋め込み (akushon maemi),アクション埋め込み,встраивание действий,действие встраивания,действие вложения
365,action recognition,التعرف على الفعل,تعرف الإجراءات,تَمَيُّز الفِعل,动作识别,动作识别,动作识别,reconnaissance d'action,reconnaissance d'action,reconnaissance des actions,行動認識,アクション認識 (Action Recognition),行動認識,распознавание действий,распознавание действий,распознавание действий
366,action sequence,تسلسل العمل,تسلسل الإجراءات,سلسلة الإجراءات,动作顺序,动作序列,行动序列,séquence d'actions,séquence d'action,séquence d'actions,アクションシーケンス,アクションシーケンス,行動シーケンス,последовательность действий,последовательность действий,последовательность действий
367,action set,مجموعة العمل,مجموعة الإجراءات,مجموعة الإجراءات,动作组,动作集,行动集,ensemble d'actions,Ensemble d'actions,ensemble d'actions,アクションセット,アクションセット (Akushon setto),行動集合,набор действий,набор действий,множество действий
368,action space,مساحة العمل,مجال الإجراءات,فضاء العمل,行动空间,动作空间,行动空间,espace d'action,espace d'action,espace d'actions,アクションスペース,アクションスペース (Akushon Supēsu),行動空間,пространство действия,пространство действий,пространство действий
369,action-value function,وظيفة قيمة العمل,دالة قيمة الإجراءات,دالة قيمة العمل,行动价值函数,动作-值函数,行为价值函数,fonction de valeur d'action,fonction de valeur d'action,fonction de valeur d'action,行動価値関数,アクション価値関数,行動価値関数,функция значения действия,функция ценности действия,функция ценности действия
370,actionability,قابلية التنفيذ,قدرة التنفيذ,قابلية التنفيذ,可操作性,可行性,可操作性,actionnabilité,actionabilité,exploitabilité,実行可能性,アクション可能性 (Akushon kanō-sei),行動可能性,действенность,действенность,возможность воздействия
371,activation,التنشيط,تنشيط,تنشيط,激活,激活 (Activation),激活,Activation,- Activation,activation,アクティベーション,活性化,アクティベーション,активация,активация,активация
372,activation function,وظيفة التنشيط,وظيفة التنشيط,دالة التنشيط,激活函数,激活函数,激活函数,fonction d'activation,fonction d'activation,fonction d'activation,活性化関数,活性化関数 (kasseika kansu),活性化関数,функция активации,функция активации,функция активации
373,activation matrix,مصفوفة التنشيط,مصفوفة التنشيط,مصفوفة التفعيل,激活矩阵,激活矩阵 (activation matrix),激活矩阵,matrice d'activation,matrice d'activation,matrice d'activation,活性化マトリックス,活性化行列 (Kasseika Gyōretsu),活性化行列,матрица активации,матрица активации,матрица активации
374,activation vector,ناقلات التنشيط,المُتَنَشِّط الناقع,متجه التفعيل,激活向量,激活向量,激活向量,vecteur d'activation,vecteur d'activation,vecteur d'activation,活性化ベクトル,活性化ベクトル (kasseika bekutoru),活性化ベクトル,вектор активации,вектор активации,Вектор активации
375,active learning,تعليم فعال,التعلم النشط,التعلم النشط,主动学习,主动学习,主动学习,apprentissage actif,apprentissage actif,apprentissage actif,能動的学習,アクティブラーニング,能動的学習,активное изучение,активное обучение,активное обучение
376,active learning loop,حلقة التعلم النشط,حلقة التعلم النشط,حلقة التعلم النشط,主动学习循环,主动学习循环,主动学习循环,boucle d'apprentissage active,boucle d'apprentissage actif,boucle d'apprentissage actif,アクティブラーニングループ,アクティブラーニングループ (active learning loop),アクティブラーニングループ,цикл активного обучения,активный цикл обучения,активный цикл обучения
377,active set,مجموعة نشطة,المجموعة النشطة,المجموعة النشطة,活动集,活跃集,活动集合,ensemble actif,ensemble actif,ensemble actif,アクティブセット,アクティブセット,アクティブセット,активный набор,активный набор,активное множество
378,activity detection,كشف النشاط,الكشف عن النشاطات,الكشف عن النشاط,活动检测,活动检测,活动检测,détection d'activité,détection d'activité,détection d'activité,アクティビティの検出,活動検出 (Katsudō kenshutsu),活動検出,обнаружение активности,определение активности,обнаружение активности
379,activity recognition,التعرف على النشاط,التعرف على النشاط,نظام التعرف على النشاط,活动识别,活动识别,活动识别,reconnaissance d'activité,Reconnaissance d'activité,reconnaissance d'activité,アクティビティの認識,活動認識,行動認識 (koudou ninshiki),признание активности,Распознавание деятельности,распознавание деятельности
380,actor,الممثل,الممثل,ممثل,演员,演员,行为者,acteur,acteur,acteur,俳優,アクター,行為者,актер,актер,актор
381,actor critic algorithm,خوارزمية الناقد الفاعل,- توجيهي نقاد الخوارزمية,خوارزمية الممثل الناقد,演员评论家算法,演员评论算法,演员评论者算法,algorithme critique d'acteur,- Algorithme acteur-critique,algorithme acteur-critique,俳優批評家のアルゴリズム,- アクター批評家アルゴリズム,行為者評価者アルゴリズム,алгоритм критика актера,алгоритм актор-критик,алгоритм актер-критик
382,actor network,شبكة الفاعل,شبكة الممثلين,شبكة مُمثل,演员网络,演员网络 (actor network),行为者网络,réseau d'acteurs,réseau d'acteurs,réseau d'acteurs,アクターネットワーク,アクターネットワーク,アクターネットワーク,актерская сеть,сеть актеров,сеть актеров
383,actor-critic framework,إطار الفاعل الناقد,الإطار الممثل-الناقد,الإطار المُمثِّل-النَّاقِد,演员-评论家框架,演员-评论家框架,演员-评论家框架,cadre acteur-critique,cadre acteur-critique,cadre acteur-critique,俳優と批評家の枠組み,アクター・クリティックフレームワーク,俳優批評フレームワーク,модель актер-критик,"""['Мы применяем актер-критик каркас (Саттон и др., 2000), который использует сеть политики π θ (a t |s t ) (актер) и сеть ценности V π φ (s t ) (критик) для формулирования политики и функции значения состояния соответственно.', '2017) алгорит",актер-критик фреймворк
384,actor-critic method,طريقة الممثل الناقد,طريقة الممثل-الناقد,طريقة الممثل النقدي,演员批评家法,演员-评论家方法,演员-评论家方法,méthode acteur-critique,méthode acteur-critique,méthode acteur-critique,俳優批評家メソッド,アクター・クリティック法,行為-評価手法,актерско-критический метод,метод актер-критик,метод актера-критика
385,adapter,مشترك كهربائي,محول,محول,适配器,适配器,适配器,adaptateur,adaptateur,adaptateur,アダプタ,"""['この設定では、すべての手法の並行プラッグインモジュールがシリアルよりも優れたパフォーマンスを示しています。さらに、学習が難しい増分言語ペアの状況は、まだアダプタで生きています。', '私たちは「FLoRes」を使用し、t-SNE（Van der Maatenお",アダプター,адаптер,адаптер,адаптер
386,adapter-base fine-tuning,ضبط قاعدة المحول,طريقة ضبط النماذج باستخدام المحول الأساسي,ضبط دقيق قائم على المحول,基于适配器的微调,适配器基础微调,适配器微调,réglage fin de la base de l'adaptateur,adaptation de base fine-tuning,Adaptation fine-tuning des adaptateurs,アダプターベースの微調整,アダプターベースのファインチューニング,アダプター ベース ファインチューニング,точная настройка адаптера,адаптерная настройка базы,Настройка на основе адаптера
387,adaptive boosting algorithm,خوارزمية التعزيز التكيفي,- تعديل خوارزمية التعزيز التكيفي,خوارزمية التعزيز التكيفي,自适应增强算法,自适应增强算法,自适应提升算法,algorithme de boosting adaptatif,algorithme de renforcement adaptatif,algorithme de renforcement adaptatif,適応ブースティングアルゴリズム,適応ブースティングアルゴリズム,適応的ブースティングアルゴリズム,адаптивный алгоритм повышения,Алгоритм адаптивного усиления (AdaBoost),адаптивный алгоритм бустинга
388,adaptive thresholding,عتبة التكيف,تحديد عتبة التكيفية,عتبة تكيفية,自适应阈值处理,自适应阈值化,自适应阈值分割,seuillage adaptatif,seuillage adaptatif,seuillage adaptatif,適応型しきい値処理,適応的しきい値処理,適応的しきい値処理,адаптивное пороговое определение,адаптивное пороговое преобразование,Адаптивное пороговое преобразование
389,additive gaussian noise,الضوضاء الغوسية المضافة,ضوضاء غاوسية إضافية,ضجيج جاوسي إضافي,加性高斯噪声,加性高斯噪声 (Additive Gaussian Noise),加性高斯噪声,bruit gaussien additif,- Bruit gaussien additif,bruit gaussien additif,加算ガウスノイズ,加算ガウシアンノイズ,加算性ガウスノイズ,аддитивный гауссов шум,аддитивный гауссовский шум,аддитивный гауссовский шум
390,additive noise,الضوضاء المضافة,ضوضاء إضافية,ضجيج إضافي,加性噪声,添加噪声 (additive noise),加性噪声,bruit additif,bruit additif,bruit additif,付加的なノイズ,加法ノイズ,加算雑音,аддитивный шум,аддитивный шум,шумовые добавки
391,adjacency,الملاصقة,- تجاورية,مجاورة,邻接,邻接 (adjacency),邻接性,proximité,adjacence,adjacence,隣接,隣接 (りんせつ),隣接性,соседство,смежность,смежность
392,adjacency matrix,مصفوفة الجوار,مصفوفة الجوار,صفوف المجاورة,邻接矩阵,邻接矩阵,邻接矩阵,matrice de contiguïté,matrice d'adjacence,matrice d'adjacence,隣接行列,隣接行列 (りんせつぎょうれつ),隣接行列,матрица смежности,матрица смежности,матрица смежности
393,advantage function,وظيفة الميزة,دالة الميزة,دالة الميزة,优势函数,优势函数,优势函数,fonction d'avantage,fonction d'avantage,fonction d'avantage,アドバンテージ関数,アドバンテージ関数,優位関数,функция преимущества,функция преимущества,функция преимущества
394,advcl,com.advcl,عبارة_advcl,جملة ظرفية,广告,副从句,状中关系,advcl,advcl,proposition circonstancielle,advcl,付加子,副修飾節,реклама,advcl,обстоятельственное придаточное
395,adversarial attack,هجوم معادٍ,هجوم عدائي,هجوم عدواني,对抗性攻击,对抗性攻击 (adversarial attack),对抗攻击,attaque contradictoire,attaque adversaire,attaque adversariale,敵対的攻撃,敵対的攻撃,対抗攻撃,враждебное нападение,атака адверсариатов,адверсарная атака
396,adversarial dataset,مجموعة بيانات معادية,مجموعة بيانات معادية,بيانات معادية,对抗数据集,对抗性数据集 (adversarial dataset),对抗数据集,ensemble de données contradictoires,ensemble de données adversaires,ensemble de données adversariales,敵対的データセット,敵対的データセット,敵対的データセット,состязательный набор данных,набор данных для атак,наборы данных с противодействием
397,adversarial example,مثال عدائي,مثال عدائي,مثال عدائي,对抗性例子,对抗性示例 (adversarial example),对抗性样本,exemple contradictoire,exemple adversaire,exemple adversaire,敵対的な例,敵対的な例,敵対的例,состязательный пример,адверсарное примерение,адверсивный пример
398,adversarial filtering,التصفية العدائية,- تصفية عدائية,ترشيح معاكس,对抗性过滤,对抗性过滤,对抗性过滤,filtrage contradictoire,filtration adversaire,filtrage antagoniste,敵対的フィルタリング,対抗的フィルタリング,敵対的フィルタリング,состязательная фильтрация,адверсарное фильтрование,адверсативная фильтрация
399,adversarial input,المدخلات العدائية,المدخلات العدائية,مُدخلات ضِديَّة,对抗性输入,对抗性输入,对抗性输入,contribution contradictoire,entrée adversaire,entrée adversariale,敵対的な入力,不正な入力,対立入力,состязательный вклад,атакующий ввод,вредоносный вход
400,adversarial learning,التعلم العدائي,التعلم العدائي,تعلم معارض,对抗性学习,对抗学习 (adversarial learning),对抗性学习,apprentissage contradictoire,apprentissage adversarial,apprentissage adverse,敵対的な学習,対抗的学習 (Taikōteki gakushū),対立学習,состязательное обучение,адверсарное обучение,имитационное обучение
401,adversarial loss,خسارة معادية,الخسارة العدائية,خسارة معادية,对抗性损失,对抗损失,对抗性损失,perte contradictoire,perte adversaire,perte adversariale,敵対的損失,敵対的損失 (tekitaiteki sonshitsu),対抗損失,состязательный проигрыш,адверсариальная потеря,противоадверсарная потеря
402,adversarial network,شبكة معادية,شبكة معادية,شبكة معادية,对抗网络,对抗网络,对抗网络,réseau contradictoire,"""Notre réseau adversaire est entièrement convolutionnel et a été conçu de telle sorte que le champ réceptif des derniers neurones de la couche R θ et D φ soit similaire. Nous entraînons d'abord le réseau R θ avec seulement la perte d'auto-régularisation pendant 1 000 étapes, et D φ pendant 200 étapes. (1) Notre objectif n'est pas de générer des images pixel réalistes, mais plutôt d'apprendre un discriminateur",réseau antagoniste,敵対的ネットワーク,敵対的ネットワーク,対抗ネットワーク,враждебная сеть,атакующая сеть,сетевая вражда
403,adversarial perturbation,اضطراب معادي,التشويش العدائي,اضطراب معادٍ,对抗性扰动,对抗性扰动,对抗性扰动,perturbation contradictoire,perturbation adversaire,perturbation adversarielle,敵対的な摂動,敵対摂動 (adversarial perturbation),対抗的撹乱,враждебное возмущение,атакующее возмущение,вредоносное возмущение
404,adversarial prompt,موجه عدائي,المحفز العدائي,تحريض عدائي,对抗性提示,对抗性提示 (adversarial prompt),对抗性提示语,invite contradictoire,invite adversaire,invite provocante,敵対的なプロンプト,対抗的なプロンプト,敵対的プロンプト,состязательная подсказка,враждебный запрос,вредоносный запрос
405,adversarial robustness,متانة الخصومة,الصلابة التحملية,صلابة معادية,对抗鲁棒性,对抗性鲁棒性,对抗鲁棒性,robustesse contradictoire,robustesse adversariale,robustesse aux attaques adverses,敵対的な堅牢性,敵対的な耐性,敵対的ロバストネス,состязательная устойчивость,адверсативная устойчивость,стойкость к атакам
406,adversarial training,التدريب المضاد,التدريب التقاومي,تدريب معارض,对抗性训练,对抗训练,对抗训练,formation contradictoire,- Entraînement adversarial,entraînement adverse,敵対的トレーニング,敵対的トレーニング (tekitaiteki toreningu),対立訓練,состязательная подготовка,адверсарное обучение,Adверсативное обучение
407,adversary,الخصم,الخصم,مُعَادٍ,对手,对手,对手,adversaire,- Adversaire,adversaire,敵対者,敵 (Teki),敵対者,противник,противник,Злоумышленник
408,advmod,com.advmod,advmod,ظرف الحال,广告模式,修饰副词,状语,modmod,advmod,modifieur adverbial,advmod,副詞修飾,副詞修飾語,адвмод,advmod,обстоятельство
409,affine,نسيب,تشبعية,متجه,仿射,仿射 (affine),仿射,affine,affine,affine,アフィン,アフィン,アフィン,аффинный,аффинный,аффинный
410,affine subspace,الفضاء الفرعي التآلفي,"""['يترتب على ذلك أن الـPCA مرتبط بشكل وثيق بحالة البيانات اللامركزية، لأنه يهدف إلى العثور على مجال فرعي متجانس (لا يتقاطع مع الأصل)، الذي يتناسب بشكل أفضل",فضاء جزئي ملاصق,仿射子空间,仿射子空间,仿射子空间,sous-espace affine,sous-espace affine,sous-espace affine,アフィン部分空間,アフィン部分空間,親線形部分空間,аффинное подпространство,аффинное подпространство,Аффинное подпространство
411,affine transform,تحويل تقاربي,التحويل الرباطي,تحويل مائل,仿射变换,仿射变换,仿射变换,transformation affine,transformation affine,transformation affine,アフィン変換,アフィン変換 (afin henkan),線形変換,аффинное преобразование,аффинное преобразование,аффинное преобразование
412,affine transformation,تحويل تآلفي,التحويل الأفيني,تحويل متجه,仿射变换,仿射变换,仿射变换,Transformation affine,transformation affine,transformation affine,アフィン変換,アフィン変換 (Afintenka),アフィン変換,аффинное преобразование,аффинное преобразование,аффинное преобразование
413,affinity matrix,مصفوفة التقارب,مصفوفة التقارب,مصفوفة التآلف,亲和矩阵,亲和矩阵,亲和矩阵,matrice d'affinité,- Matrice d'affinité,matrice d'affinité,親和性マトリックス,親和行列,アフィニティ行列,матрица родства,матрица аффинности,Матрица сродства
414,affinity measure,قياس التقارب,مقياس التشابه,مقياس التجاذب,亲和度测量,亲和度测量,亲和力度量,mesure d'affinité,mesure d'affinité,mesure d'affinité,親和性の尺度,親和性測定,親和性尺度,мера близости,мера аффинности,мера сходства
415,agent architecture,بنية الوكيل,بنية الوكيل,بنية الوكيل,代理架构,代理架构,智能体架构,architecture des agents,architecture de l'agent,architecture d'agent,エージェントのアーキテクチャ,エージェントアーキテクチャ,エージェントアーキテクチャ,архитектура агента,архитектура агента,архитектура агента
416,agent learning,التعلم وكيل,تعلم العوامل,تعلم الوكيل,代理学习,智能体学习,智能体学习,apprentissage des agents,apprentissage de l'agent,apprentissage d'agent,エージェント学習,エージェント学習,エージェント学習,обучение агента,обучение агента,агентное обучение
417,agent policy,سياسة الوكيل,سياسة الوكيل,سياسة الوكيل,代理政策,代理政策 (Agent Policy),智能体策略,politique des agents,politique de l'agent,Politique d'agent,エージェントポリシー,エージェントポリシー (Agent Policy),エージェントポリシー,агентская политика,политика агента,политика агента
418,agent's policy,سياسة الوكيل,سياسة العامل,سياسة الوكيل,代理政策,策略(agent's policy),代理策略,politique de l'agent,Politique de l'agent,politique de l'agent,エージェントのポリシー,エージェントの方針,エージェントのポリシー,политика агента,политика агента,политика агента
419,agent-base model,نموذج قاعدة الوكيل,نموذج قائم على العوامل,نموذج قائم على الوكلاء,基于代理的模型,基于代理的模型 (Agent-Based Model),基于代理模型,modèle à base d'agents,modèle basé sur les agents,modèle à base d'agents,エージェントベースモデル,エージェントベースモデル (エージェントベースモデル),エージェントベースモデル,агентно-базовая модель,модель на основе агентов,агентная модель
420,aggregate function,وظيفة مجمعة,دالة تجميعية,دالة تجميع,聚合函数,聚合函数,聚合函数,fonction d'agrégation,fonction d'agrégation,fonction d'agrégation,集計関数,集約関数 (shuugou kansuu),集約関数,агрегатная функция,агрегационная функция,агрегатная функция
421,aggregation,تجميع,التجميع,تجميع,聚合,聚合,聚合,agrégation,agrégation,agrégation,集計,集約 (shuugou),集約,агрегирование,агрегация,агрегация
422,aggregation function,وظيفة التجميع,دالة التجميع,دالة التجميع,聚合函数,聚合函数,聚合函数,fonction d'agrégation,- Fonction d'agrégation,fonction d'agrégation,集計関数,集計関数,集約関数,функция агрегирования,Функция агрегирования,функция агрегации
423,aleatoric uncertainty,عدم اليقين العشوائي,عدم اليقين العشوائي,عدم اليقين العشوائي,任意不确定性,随机不确定性,随机不确定性,incertitude aléatoire,Incertitude aléatoire,incertitude aléatoire,偶然の不確実性,偶然的不確実性,偶発的不確実性,алеаторическая неопределенность,алеаторическая неопределенность,алеаторная неопределенность
424,algorithm,خوارزمية,- تحليل خوارزمية,خوارزمية,算法,算法,算法,algorithme,algorithme,algorithme,アルゴリズム,- アルゴリズム,アルゴリズム,алгоритм,алгоритм,алгоритм
425,algorithm class,فئة الخوارزمية,صنف الخوارزمية,فئة الخوارزمية,算法类,算法类,算法类,classe d'algorithme,classe d'algorithmes,classe d'algorithmes,アルゴリズムクラス,アルゴリズムクラス (Algorithm class),アルゴリズムクラス,класс алгоритма,класс алгоритмов,класс алгоритмов
426,algorithm design,تصميم الخوارزمية,تصميم خوارزمية,تصميم الخوارزمية,算法设计,算法设计,算法设计,conception d'algorithmes,- Conception d'algorithmes,Conception d'algorithmes,アルゴリズム設計,アルゴリズム設計 (arugorizumu sekkei),アルゴリズム設計,разработка алгоритма,дизайн алгоритма,проектирование алгоритмов
427,algorithmic approach,النهج الخوارزمي,النهج الخوارزمي,نهج خوارزمي,算法方法,算法方法,算法方法,approche algorithmique,approche algorithmique,approche algorithmique,アルゴリズム的アプローチ,アルゴリズムアプローチ (arugorizumu apurōchi),アルゴリズムアプローチ,алгоритмический подход,алгоритмический подход,алгоритмический подход
428,algorithmic bias,التحيز الخوارزمي,التحيز الخوارزمي,التحيز الخوارزمي,算法偏差,算法偏见,算法偏差,biais algorithmique,biais algorithmique,biais algorithmique,アルゴリズムのバイアス,アルゴリズムのバイアス,アルゴリズムのバイアス,алгоритмическая предвзятость,алгоритмический биас,алгоритмическая предвзятость
429,algorithmic fairness,العدالة الخوارزمية,- توازن خوارزمية,عدالة الخوارزمية,算法公平性,算法公平,算法公平性,équité algorithmique,équité algorithmique,équité algorithmique,アルゴリズムの公平性,アルゴリズムの公平性 (arugorizumu no kouheisei),アルゴリズムの公平性,алгоритмическая справедливость,алгоритмическая справедливость,алгоритмическая справедливость
430,algorithmic stability,الاستقرار الخوارزمي,استقرار خوارزمية,الاستقرار الخوارزمي,算法稳定性,算法稳定性,算法稳定性,stabilité algorithmique,stabilité algorithmique,stabilité algorithmique,アルゴリズムの安定性,アルゴリズムの安定性 (arugorizumu no antei-sei),アルゴリズムの安定性,алгоритмическая стабильность,алгоритмическая устойчивость,алгоритмическая устойчивость
431,alias table,جدول الاسم المستعار,جدول الاسم المستعار,جدول الكنى,别名表,别名表,别名表,table d'alias,- Table des alias,table des alias,別名テーブル,別名テーブル,エイリアステーブル,таблица псевдонимов,таблица псевдонимов,Таблица алиасов
432,alignment algorithm,خوارزمية المحاذاة,خوارزمية المحاذاة,خوارزمية المحاذاة,对齐算法,对齐算法,对准算法,algorithme d'alignement,algorithme d'alignement,algorithme d'alignement,アライメントアルゴリズム,アラインメントアルゴリズム (Arainimento arugorizumu),整列アルゴリズム,алгоритм выравнивания,алгоритм выравнивания,алгоритм выравнивания
433,alignment model,نموذج المحاذاة,نموذج المحاذاة,نموذج المحاذاة,对准模型,对齐模型,对齐模型,modèle d'alignement,- Modèle d'alignement,modèle d'alignement,アライメントモデル,アライメントモデル (Araimento Moderu),アライメントモデル,модель выравнивания,модель выравнивания,модель выравнивания
434,alpha compositing,تركيب ألفا,التركيب ألفا,مُرَكِّب ألفا,阿尔法合成,alpha合成,阿尔法合成,composition alpha,"""['Pendant l'entraînement, nous utilisons l'alpha compositing pour propager le signal d'entraînement à tous les échantillons le long d'un rayon. Cependant, au moment de l'inférence, nous calculons plutôt l'emplacement correspondant en utilisant l'échantillon unique avec la plus grande valeur alpha, ce qui a permis d'obtenir des résultats quantitativement similaires mais visuellement meilleurs. Architecture de réseau pour M θ.', 'Nous",composition alpha,アルファ合成,アルファ合成 (alpha compositing),アルファコンポジッティング,альфа-композитинг,альфа-композитинг,альфа-композитинг
435,alphabet size,حجم الأبجدية,حجم الأبجدية,حجم المجموعة الرمزية,字母大小,字母表大小,字母表大小,taille de l'alphabet,- Taille de l'alphabet,taille de l'alphabet,アルファベットサイズ,アルファベットのサイズ,アルファベットサイズ,размер алфавита,размер алфавита,размер алфавита
436,alternate least square,البديل المربع الأصغر,- التقريب بأقل مربع بديل,التربيع الأصغر المتناوب,交替最小二乘法,交替最小二乘,交替最小二乘法,moindres carrés alternés,moindres carrés alternés,moindres carrés alternés,代替最小二乗,交互最小二乗 (alternating least squares),交互最小二乗法,альтернативный метод наименьших квадратов,альтернативные наименьшие квадраты,метод наименьших альтернативных квадратов
437,alternate minimization,التقليل البديل,التصغير البديل,تقليل متناوب,交替最小化,交替最小化,交替最小化,minimisation alternative,minimisation alternative,minimisation alternée,代替最小化,交互最小化 (Kōgo saishinka),交互最小化,альтернативная минимизация,альтернативная минимизация,Поочередная минимизация
438,ambient space,الفضاء المحيط,المساحة المحيطة,الفضاء المحيط,环境空间,环境空间,环境空间,espace ambiant,Espace ambiant,espace ambiant,周囲空間,環境空間,周囲空間,окружающее пространство,амбиентное пространство,окружающее пространство
439,anaphora resolution,قرار الجناس,- تحليل الإشارة التناكرية,حل التناظر,照应解析,指代消解,代词消解,résolution de l'anaphore,résolution de l'anaphore,résolution de l'anaphore,照応解決,照応解析,同一指示解決,разрешение анафоры,решение анафорических выражений,разрешение анафоры
440,anaphoric reference,مرجع مجازي,الإشارة الانفعالية,مرجع إشاري,照应参考,回指参照,指代性指称,référence anaphorique,référence anaphorique,référence anaphorique,照応参照,代名詞の指示,指示代名詞的参照,анафорическая ссылка,анафорическая ссылка,анафорическая ссылка
441,ancestral sampling,أخذ عينات الأجداد,- تحليل العينة الأصلية,العينة الأصلية,祖先采样,祖先抽样,祖先采样,échantillonnage ancestral,échantillonnage ancestral,échantillonnage ancestral,祖先のサンプリング,祖先サンプリング (sosen sampling),先祖サンプリング,наследственная выборка,предковая выборка,предковое сэмплирование
442,anchor,مِرسَاة,نقطة مرجعية,مرساة,锚,锚点,锚框,ancre,ancre,ancre,アンカー,アンカー,アンカー,якорь,якорь,якорь
443,anchor box,صندوق مرساة,صندوق الربط,صندوق الإرساء,锚盒,锚框,锚框,boîte d'ancrage,Boîte d'ancrage,boîte d'ancrage,アンカーボックス,アンカーボックス,アンカーボックス (ankā bokkusu),якорный ящик,якорная коробка,якорный квадрат
444,annotated corpus,مجموعة مشروحة,المخزون المنسق,مدونة موسومة,带注释的语料库,标注语料库,带注释语料库,corpus annoté,corpus annoté,corpus annoté,注釈付きコーパス,注釈付きコーパス,注釈付きコーパス,аннотированный корпус,аннотированный корпус,размеченный корпус
445,annotated datum,مسند مشروح,البيانات المحددة,بيانات موسومة,带注释的数据,标注数据,带注释的数据,donnée annotée,donnée annotée,donnée annotée,注釈付きデータム,注釈付きデータ,注釈付きデータ,аннотированные данные,аннотированные данные,размеченное данное
446,annotation,حاشية. ملاحظة,تعليق,تعليقات,注解,标注,注释,annotation,annotation,annotation,注釈,注釈 (annotation),アノテーション,аннотация,аннотация,аннотация
447,annotation artifact,قطعة أثرية توضيحية,معلمة التعليقات,تشوّهات التَّدوين,注释工件,标注人工造成的错误,标注伪像,artefact d'annotation,artefact d'annotation,artefact d'annotation,注釈アーティファクト,注釈アーティファクト,アノテーション人為物,артефакт аннотации,аннотационный артефакт,артефакт аннотирования
448,annotation projection,إسقاط التعليق التوضيحي,إسقاط التعليقات,إسقاط التعليق الجملي,注释投影,注释投影,注释投影,projection d'annotations,projection d'annotation,projection d'annotations,注釈投影,注釈投影,アノテーション投影,проекция аннотаций,аннотационная проекция,проекция аннотаций
449,annotator,الحواشي,المعلق,مفوض,注释者,标注者,注释员,annotateur,annotateur,annotateur,アノテーター,アノテーター,アノテータ,аннотатор,аннотатор,аннотатор
450,annotator bias,تحيز التعليق التوضيحي,تحيز المنسق,تحيز المعلق,注释者偏见,注释者偏见,注释者偏差,biais de l'annotateur,biais de l'annotateur,biais d'annotation,アノテーターのバイアス,アノテーターの偏り,アノテータのバイアス,предвзятость аннотатора,"""['Конкретно, исследования человеческих оценок с использованием прямой оценки показали наличие аннотаторского эффекта, высокой дисперсии и последовательных эффектов, при которых аннотация одного элемента влияется на предшествующие элементы (Куликов и др",смещение аннотатора
451,anomaly detection,إكتشاف عيب خلقي,كشف الشوائب,كشف الشذوذ,异常检测,异常检测,异常检测,Détection d'une anomalie,détection d'anomalies,détection d'anomalies,異常検出,異常検知 (Ijo Kentei),異常検出,обнаружение аномалий,обнаружение аномалий,Обнаружение аномалий
452,anomaly score,درجة الشذوذ,نقاط الشذوذ,درجة الشذوذ,异常分数,异常分数,异常分数,score d'anomalie,score d'anomalie,score d'anomalie,異常スコア,異常スコア,異常スコア,оценка аномалии,оценка аномалий,аномальный балл
453,answer set,مجموعة الإجابة,مجموعة الإجابة,مجموعة الإجابة,答案集,答案集,安全回答集,ensemble de réponses,ensemble de réponses,ensemble de réponses,解答セット,回答セット,解答集合,набор ответов,набор ответов,множество ответов
454,answer set programming,برمجة مجموعة الإجابات,برمجة مجموعة الإجابات,برمجة مجموعة الإجابات,答案集编程,答案集编程,答集规划,programmation du jeu de réponses,programmation par ensemble de réponses,programmation par ensembles de réponses,解答セットプログラミング,回答セットプログラミング,回答集合プログラミング,программирование набора ответов,программирование на основе множеств ответов,программирование по наборам ответов
455,answer set solver,الإجابة مجموعة حلالا,محل حل مجموعة الإجابات,حال مجموعة الإجابة,答案集求解器,答案集求解器,答案集解算器,solveur d'ensemble de réponses,résolveur d'ensemble de réponses,solveur d'ensembles de réponses,解答セットソルバー,回答セットソルバー,応答集合ソルバー,решатель набора ответов,решатель множеств ответов,решатель ответных множеств
456,answer span,مدى الإجابة,نطاق الإجابة,نطاق الإجابة,答案跨度,答案跨度,答案跨度,durée de réponse,intervalle de réponse,extrait de réponse,解答範囲,回答スパン,回答範囲,диапазон ответов,ответный промежуток,отрывок ответа
457,answer variable,متغير الإجابة,متغير الإجابة,متغير الإجابة,答案变量,- 答案变量,回答变量,variable de réponse,variable de réponse,variable de réponse,答えの変数,回答変数,応答変数,переменная ответа,переменная ответа,Переменная ответа
458,antecedent,سالف,السابق,سابق,先行词,先行词,先决条件,antécédent,"""['D'abord, étant donné le grand nombre de singletons (Figure 1), il est plus probable que nous observions une amélioration des performances en supprimant les singletons. Deuxièmement, le caractère multi-tamis du système de coréférence de Stanford ne rend pas simple la décision de lier une mention à un antécédent même si nous savons qu'ils sont coréférents.', 'Les connaissances représentées dans GLUCOSE sont capturées sous forme de",antécédent,先例,先行述部,前件,антецедент,антецедент,предпосылка
459,antithetic sampling,أخذ العينات المضادة,عينات معاكسة,لعينة المعاكسة,对立抽样,对立抽样,反向采样,échantillonnage antithétique,échantillonnage antithétique,échantillonnage antithétique,アンチテーゼサンプリング,反対サンプリング (hantai sanpuringu),逆対称サンプリング,антитетическая выборка,антитетическое сэмплирование,противоположный отбор образцов
460,anytime algorithm,خوارزمية في أي وقت,خوارزمية في أي وقت,خوارزمية حينية,随时算法,随时算法,可随时算法,algorithme à tout moment,algorithme anytime,algorithme à temps quelconque,いつでもアルゴリズム,いつでもアルゴリズム (Itsudemo arugorizumu),いつでも可能なアルゴリズム,алгоритм в любое время,алгоритм в любое время,алгоритм в любое время
461,aperture problem,مشكلة الفتحة,مشكلة الفتحة,مشكلة الفتحة,光圈问题,光圈问题,孔径问题,problème d'ouverture,Problème d'ouverture,problème d'ouverture,絞りの問題,アパーチャ問題,アパーチャ問題,проблема с диафрагмой,проблема апертуры,проблема апертуры
462,appearance model,نموذج المظهر,نموذج المظهر,نموذج المظهر,外观模型,外观模型,外观模型,modèle d'apparence,- Modèle d'apparence,modèle d'apparence,外観モデル,外観モデル,外観モデル,внешний вид модели,модель внешнего вида,модель внешнего вида
463,apprenticeship learning,التعلم التلمذة الصناعية,التعلم التلمذة,تعلم التلمذة الصناعية,学徒学习,师傅学习,学徒学习,apprentissage par apprentissage,apprentissage par imitation,apprentissage par apprentissage,見習い学習,弟子入り学習,徒弟学習,обучение,обучение по образцу,обучение по принципу ученичества
464,approximate inference,الاستدلال التقريبي,- تقدير التستقراءية,الاستدلال التقريبي,近似推理,近似推理,近似推理,inférence approximative,inférence approximative,inférence approximative,おおよその推論,近似推論 (kinji suiron),近似推論,приблизительный вывод,приближенный вывод,приближенный вывод
465,approximate inference algorithm,خوارزمية الاستدلال التقريبي,- تقريب خوارزمية الاستدلال,خوارزمية استنتاج تقريبية,近似推理算法,近似推理算法,近似推理算法,algorithme d'inférence approximative,algorithme d'inférence approximative,algorithme d'inférence approximative,近似推論アルゴリズム,近似推論アルゴリズム (kinji suiron arugorizumu),概算推論アルゴリズム,приблизительный алгоритм вывода,алгоритм приближенного вывода,приближенный алгоритм вывода
466,approximate posterior,خلفي تقريبي,الاحتمال الشرطي التقريبي,التقريب البعدي,近似后验,近似后验,近似后验,postérieur approximatif,posterior approximatif,distribution a posteriori approximative,おおよその後部,近似事後分布,近似事後分布,приблизительный задний,приближенное апостериорное,приближенный апостериорный
467,approximate posterior distribution,التوزيع الخلفي التقريبي,التوزيع الشاذ تقريبيًا,التوزيع اللاحق التقريبي,近似后验分布,- 近似后验分布,近似后验分布,distribution postérieure approximative,- Distribution postérieure approximative,distribution approximative a posteriori,近似事後分布,近似事後分布,近似事後分布,приблизительное апостериорное распределение,приближенное апостериорное распределение,приблизительное апостериорное распределение
468,approximate similarity search,بحث التشابه التقريبي,البحث عن الشبه التقريبي,البحث عن التشابه التقريبي,近似相似度搜索,近似相似性搜索,近似相似性搜索,recherche de similarité approximative,"""Ainsi, les chercheurs ont considéré le problème de la recherche de similarité approximative, où un utilisateur bénéficie de compromis explicites entre la précision garantie et la vitesse d'une recherche.""",recherche de similarité approximative,近似類似検索,近似類似性検索,概略類似性検索,приблизительный поиск по сходству,приблизительный поиск похожих объектов,Приблизительный поиск похожих
469,approximation,تقريب,"""ثم نحسن الخوارزمية للحصول على حلاً زمنيًا خطيًا مع ضمانات تقريبية مماثلة. للقيم k ≤ رتبة (أ), نستخدم [A] k للدلالة على أفضل تقريب برتبة k للمصفوفة A. ن",تقريب,近似,逼近,近似,approximation,approximation,approximation,近似,近似解,近似,приближение,приближение,приближение
470,approximation algorithm,خوارزمية التقريب,خوارزمية تقريبية,خوارزمية تقريب,近似算法,逼近算法,近似算法,algorithme d'approximation,algorithme d'approximation,algorithme d'approximation,近似アルゴリズム,近似アルゴリズム,近似アルゴリズム,алгоритм аппроксимации,алгоритм аппроксимации,алгоритм приближения
471,approximation bind,ربط التقريب,الحد التقريبي,حد التقريب,近似绑定,逼近界限,近似束缚,liaison d'approximation,limite d'approximation,borne d'approximation,近似バインド,近似バインド,近似束縛,аппроксимационная привязка,приближение границы,приближенная связь
472,approximation error,خطأ تقريبي,خطأ التقريب,خطأ التقريب,近似误差,逼近误差,近似误差,erreur d'approximation,erreur d'approximation,erreur d'approximation,近似誤差,近似誤差,近似誤差,ошибка аппроксимации,ошибка аппроксимации,ошибка аппроксимации
473,approximation factor,عامل التقريب,عامل التقريب,معامل التقريب,近似因子,逼近因子,近似因子,facteur d'approximation,facteur d'approximation,facteur d'approximation,近似係数,近似係数,近似係数,коэффициент аппроксимации,коэффициент приближения,фактор приближения
474,approximation guarantee,ضمان التقريب,ضمان التقريب,ضمان التقريب,近似保证,近似保证,近似保证,garantie de rapprochement,garantie d'approximation,garantie d'approximation,近似保証,近似保証,近似保証,гарантия приближения,гарантия приближения,гарантия приближения
475,approximation ratio,نسبة التقريب,نسبة التقريب,نسبة التقريب,近似比,近似比率,近似比,rapport d'approximation,ratio d'approximation,rapport d'approximation,近似比,近似比率 (kinji hikaku ritsu),近似比率,коэффициент аппроксимации,коэффициент приближения,соотношение приближения
476,approximator,تقريبي,مقرب -قريب أو محاكٍ,مُقارِب,逼近器,逼近器,近似算子,approximateur,approximateur,approximateur,アプロシメータ,近似器,近似演算子,аппроксиматор,аппроксиматор,аппроксиматор
477,apriori algorithm,خوارزمية أولية,خوارزمية أبريوري,خوارزمية أبريوري,先验算法,Apriori算法,apriori算法,algorithme a priori,algorithme Apriori,Algorithme Apriori,アプリオリアルゴリズム,アプリオリ・アルゴリズム,apriori アルゴリズム,априорный алгоритм,алгоритм Apriori,априорный алгоритм
478,arc-factor model,نموذج عامل القوس,نموذج العقدة-العامل,نموذج العامل القوسي,弧因子模型,弧-因子模型,弧分解模型,modèle de facteur d'arc,modèle à facteurs d'arc,Modèle arc-factorisé,アークファクターモデル,アークファクターモデル (arc-factor model),arc-factor モデル,модель дугового фактора,модель с факторизацией дуг,arc-факторная модель
479,arcade learning environment,بيئة التعلم الممرات,بيئة تعلم الألعاب الأركيد,بيئة التعلم الصالة الألعاب,街机学习环境,街机学习环境,街机学习环境,environnement d'apprentissage d'arcade,- Environnement d'apprentissage des arcades,environnement d'apprentissage arcade,アーケード学習環境,アーケード学習環境 (Arcade Learning Environment),アーケードラーニング環境,аркадная обучающая среда,среда обучения в стиле Аркада,Среда обучения аркад
480,architectural modification,التعديل المعماري,التعديلات المعمارية,تعديلات معمارية,架构修改,体系结构修改,架构修改,modification architecturale,- Modification architecturale,modification architecturale,アーキテクチャの変更,アーキテクチャの変更,建築的変更,архитектурная модификация,архитектурные модификации,архитектурные модификации
481,architecture,بنيان,الهندسة المعمارية,معمارية,建筑学,架构,架构,architecture,architecture,architecture,建築,アーキテクチャ,アーキテクチャ,архитектура,архитектура,архитектура
482,architecture search,بحث الهندسة المعمارية,البحث عن الهندسة المعمارية,البحث عن البنية,架构搜索,架构搜索,架构搜索,recherche d'architecture,recherche d'architecture,recherche d'architecture,建築検索,アーキテクチャサーチ,アーキテクチャ検索,поиск архитектуры,поиск архитектуры,поиск архитектуры
483,arg max,وسيطة كحد أقصى,أرغ ماكس,أقصى قيمة,最大精量,最大参数,"argmax 的中文翻译是""最大化""。",argument maximum,arg max,arg max,引数最大,arg max,最大値を与える引数,аргумент макс.,arg макс,аргмакс
484,arg min,أرج دقيقة,"""['w ⇤ = arg min w X (x,y)`( x, y, w) (x, y, w) = i ⇤ y X i=1 h(P i (x, w), y) i ⇤ y = min i2{1..k} i s.t.', 'Note that the value of the norm q 2 has no effect as it is a constant throughout and does not change the identity of arg max or arg min. There are many scenarios in which MIPS arises naturally at places where the norms of the",أدنى حد,精氨酸最小值,最小化_ARGUMENT,极小化,argument min,arg min,arg min,引数の最小値,arg min,arg最小,аргумент мин,arg мин,аргмин
485,argument,دعوى,argument,حُجة,争论,参数,论元,argument,argument,argument,口論,引数,項 (こう),аргумент,аргумент,аргумент
486,argument identification,تحديد الحجة,تحديد الحجج,تحديد الحجة,论证识别,参数识别,论元识别,identification des arguments,identification des arguments,identification des arguments,引数の識別,引数の識別 (Argument Identification),論証識別,идентификация аргумента,идентификация аргументов,идентификация аргумента
487,argument relation,علاقة الحجة,علاقة الحجة,حالة الحجة,论证关系,参数关系,论元关系,relation argumentative,relation d'argument,relation argumentale,引数関係,引数関係,論証関係,отношение аргумента,связи аргумента,аргументные отношения
488,argument structure,هيكل الحجة,هيكل الحجة,هيكلة الحُجَج,论证结构,参数结构,论元结构,structure des arguments,structure argumentatif,structure argumentale,引数の構造,引数構造,項構造,структура аргументов,структура аргументации,структура аргумента
489,arity,arity,التعداد,ارية,数量,元数,元性,arité,arité,arité,アリティ,引数数,項数,арность,арность,арность
490,artificial agent,عامل اصطناعي,الوكيل الصناعي,وكيل اصطناعي,人工代理,人工代理,人工智能代理,agent artificiel,- Agent artificiel,agent artificiel,人工エージェント,人工エージェント (jinkou eejento),人工エージェント,искусственный агент,искусственный агент,искусственный агент
491,artificial intelligence system,نظام الذكاء الاصطناعي,نظام الذكاء الاصطناعي,نظام الذكاء الاصطناعي,人工智能系统,人工智能系统 (Artificial Intelligence System),人工智能系统,système d'intelligence artificielle,- Système d'intelligence artificielle,système d'intelligence artificielle,人工知能システム,人工知能システム,人工知能システム,система искусственного интеллекта,система искусственного интеллекта,искусственная интеллектуальная система
492,artificial neural network,شبكة اعصاب صناعية,شبكة عصبية اصطناعية,شبكة عصبية اصطناعية,人工神经网络,人工神经网络,人工神经网络,réseau neuronal artificiel,- Réseau neuronal artificiel,réseau de neurones artificiels,人工ニューラルネットワーク,人工ニューラルネットワーク,人工ニューラルネットワーク,искусственная нейронная сеть,искусственная нейронная сеть,искусственная нейронная сеть
493,assignment problem,مشكلة الاحالة,مشكلة التعيين,مشكلة التعيين,分配问题,分配问题,指派问题,problème d'affectation,problème d'affectation,problème d'affectation,割り当て問題,割り当て問題 (wariate mondai),割り当て問題,проблема с назначением,Проблема назначения,проблема назначения
494,association rule,قاعدة الارتباط,قاعدة الارتباط,قاعدة الارتباط,关联规则,关联规则 (association rule),关联规则,règle d'association,règle d'association,règle d'association,相関ルール,結合規則 (けつごうきそく),関連ルール,правило ассоциации,ассоциативное правило,правило ассоциации
495,association rule mining,التعدين قاعدة الرابطة,تعدين قواعد الارتباط,تنقيب قواعد الارتباط,关联规则挖掘,关联规则挖掘,关联规则挖掘,extraction de règles d'association,extraction de règles d'association,exploration de règles d'association,相関ルールマイニング,関連ルールマイニング,関連ルール発見,майнинг правил ассоциации,добыча правил ассоциаций,поиск ассоциативных правил
496,asymmetric transformation,التحول غير المتماثل,تحويل غير متناظر,تحويل غير متماثل,不对称变换,不对称转换,非对称变换,transformation asymétrique,transformation asymétrique,Transformation asymétrique,非対称変換,非対称変換,非対称変換,асимметричное преобразование,асимметричное преобразование,асимметричное преобразование
497,asymptotic bias,التحيز المقارب,الانحياز الوبائي,التحيز اللانهائي,渐近偏差,渐近偏差,渐进偏差,biais asymptotique,Biais asymptotique,biais asymptotique,漸近バイアス,漸近的なバイアス,収束バイアス,асимптотическое смещение,асимптотическая смещенность,асимптотическая смещенность
498,asymptotic notation,تدوين مقارب,تعبير حدود تقاربيّة,الترميز الحدي,渐近记号,渐近符号,渐近记号,notation asymptotique,- Notation asymptotique,notation asymptotique,漸近表記,漸近表記,漸近記法,асимптотическая запись,асимптотическая нотация,асимптотическая нотация
499,asymptotic variance,التباين المقارب,التباين اللازلي,التباين الاعتلالي,渐进方差,渐近方差,渐近方差,variance asymptotique,variance asymptotique,variance asymptotique,漸近分散,漸近分散,漸近分散,асимптотическая дисперсия,асимптотическая дисперсия,асимптотическая дисперсия
500,attack success rate,معدل نجاح الهجوم,معدل نجاح الهجوم,معدل نجاح الهجوم,攻击成功率,攻击成功率,攻击成功率,taux de réussite des attaques,Taux de réussite de l'attaque,taux de réussite d'attaque,攻撃成功率,攻撃成功率,攻撃成功率,вероятность успеха атаки,Успешность атаки,Коэффициент успешности атаки
501,attention,انتباه,الانتباه,الانتباه,注意力,注意力,注意力,attention,attention,attention,注意,アテンション,注目,внимание,внимание,внимание
502,attention distribution,توزيع الاهتمام,توزيع الانتباه,توزيع الانتباه,注意力分布,注意力分布,注意力分布,répartition de l'attention,distribution d'attention,distribution attentionnelle,注意力の分布,アテンション分布 (Atenshon bunpu),注目分布,распределение внимания,распределение внимания,распределение внимания
503,attention function,وظيفة الاهتمام,وظيفة الانتباه,وظيفة الانتباه,注意功能,注意力函数,注意力函数,fonction d'attention,- Fonction d'attention,fonction d'attention,アテンション機能,注目機能 (attention function),注目関数,функция внимания,функция внимания,функция внимания
504,attention head,رئيس الاهتمام,رأس الانتباه,رأس الانتباه,注意头,注意力头,注意力头,tête d'attention,tête d'attention,tête d'attention,注意頭,アテンションヘッド (Atenshon Heddo),注目ヘッド,внимание голова,голова внимания,Внимательная головка
505,attention layer,طبقة الاهتمام,طبقة الانتباه,طبقة الانتباه,注意力层,注意力层 (attention layer),注意力层,couche d'attention,- Couche d'attention,couche d'attention,注目層,アテンションレイヤー (Atenshon reiyā),注目層,слой внимания,слои внимания,слой внимания
506,attention map,خريطة الاهتمام,خريطة اهتمام,خريطة الانتباه,注意图,注意力图,注意力映射,carte d'attention,carte d'attention,carte d'attention,アテンションマップ,注目マップ,注目マップ,карта внимания,карта внимания,карта внимания
507,attention mask,قناع الاهتمام,قناع التركيز,قناع الانتباه,注意面具,关注蒙版 (Attention Mask),注意力掩码,masque d'attention,- Masque d'attention,masque d'attention,注意マスク,アテンションマスク,注目マスク,маска внимания,маска внимания,Маска внимания
508,attention matrix,مصفوفة الاهتمام,مصفوفة الانتباه,مصفوفة الانتباه,注意矩阵,注意力矩阵,注意力矩阵,matrice d'attention,matrice d'attention,matrice d'attention,アテンションマトリックス,注意マトリックス (Chūi matorikkusu),注意行列,матрица внимания,матрица внимания,матрица внимания
509,attention mechanism,آلية الاهتمام,آلية الانتباه,آلية الانتباه,注意机制,注意机制,注意力机制,mécanisme d'attention,mécanisme d'attention,mécanisme d'attention,注意メカニズム,注意機構,注目メカニズム,механизм внимания,механизм внимания,механизм внимания
510,attention model,نموذج الاهتمام,نموذج الانتباه,نموذج الانتباه,注意力模型,注意力模型,注意力模型,modèle d'attention,modèle d'attention,modèle d'attention,注目モデル,注目モデル,注意モデル,модель внимания,модель внимания,Модель внимания
511,attention module,وحدة الاهتمام,وحدة الانتباه,وحدة الانتباه,注意力模块,注意力模块,注意力模块,module d'attention,module d'attention,module d'attention,注意モジュール,注意モジュール (attention module),注意モジュール,модуль внимания,модуль внимания,модуль внимания
512,attention operation,عملية الاهتمام,العملية تركيزية,عملية الانتباه,注意操作,注意力操作,注意力运算,opération d'attention,- Opération d'attention,opération d'attention,注意操作,注目操作 (chumoku sōsa),注目操作,операция внимания,операция внимания,внимательная операция
513,attention pattern,نمط الاهتمام,نمط الانتباه,نمط الانتباه,注意模式,注意力模式,注意力模式,modèle d'attention,motif d'attention,motif d'attention,注意パターン,アテンションパターン,注意パターン,схема внимания,образцы внимания,вниманиепаттерн
514,attention score,درجة الاهتمام,نقاط الانتباه,درجة الانتباه,注意力分数,注意力分数,注意力分数,score d'attention,score d'attention,score d'attention,注意スコア,注目スコア,注目スコア,оценка внимания,оценка внимания,вниманию оценка
515,attention value,قيمة الاهتمام,قيمة الانتباه,قيمة الانتباه,关注值,注意力值 (attention value),注意力值,valeur d'attention,- Valeur d'attention,valeurs d'attention,注目値,注目値 (attention value),注目値,ценность внимания,значение внимания,значение внимания
516,attention weight,وزن الاهتمام,وزن الانتباه,وزن الانتباه,注意力权重,注意力权重,注意力权重,poids d'attention,poids d'attention,poids d'attention,注意の重み,注目の重み,注目度,вес внимания,вес внимания,вес внимания
517,attention-base model,نموذج قاعدة الاهتمام,نموذج قائم على التركيز,نموذج قائم على الانتباه,注意力基础模型,注意力模型,基于注意力的模型,modèle de base d'attention,- Modèle d'attention,modèle à base d'attention,アテンションベースモデル,注意ベースモデル,注意ベースモデル,"модель, основанная на внимании",модель на основе внимания,модель на основе внимания
518,attribute,يصف,صفة,سمة,属性,属性,属性,attribut,attribut,attribut,属性,属性,属性,атрибут,атрибут,атрибут
519,attribution,الإسناد,النسبية,التَّنْسِيب,归因,"""[""然后我们将它们总结在头部，并将结果用作第l层的归因：\nAttr（Al）= |h| h=1 Attrh（Al）= [ali，j] n×n \n""，'因此，刺激包括不相关的分心概念及其下属-在一个强大的模型中，这些概念不应影响将属性归因于正确概念（",归因,attribution,attribution,imputation,帰属,属性 (ぞくせい),帰属,атрибуция,атрибуция,Атрибуция
520,augmentation,زيادة,الزيادة,تكبير,增强,增强 (zēngqiáng),增强,augmentation,augmentation,augmentation,増強,拡張,拡張,увеличение,увеличение,усиление
521,augmented state space,مساحة الدولة المتزايدة,المساحة الحالية المعززة,حيز الحالة الموسع,增广状态空间,增强状态空间,增广状态空间,espace d'état augmenté,espace d'états augmenté,espace d'états augmenté,拡張状態空間,拡張状態空間 (Kakuchou Joutai Kuukan),拡張状態空間,расширенное пространство состояний,расширенное пространство состояний,расширенное пространство состояний
522,auto-regressive language model,نموذج اللغة التراجعي التلقائي,- تصنيف نموذج اللغة التلقائي,نموذج اللغة التراجعي الآلي,自回归语言模型,自回归语言模型,自回归语言模型,modèle de langage auto-régressif,- Modèle de langue auto-régressif,modèle de langage auto-régressif,自己回帰言語モデル,自己回帰言語モデル,自己回帰言語モデル,авторегрессионная языковая модель,авторегрессионная языковая модель,авторегрессионная языковая модель
523,auto-regressive model,نموذج الانحدار التلقائي,نموذج التنبؤ التلقائي,نموذج ذاتي الاسترجاع,自回归模型,自回归模型,自回归模型,modèle auto-régressif,modèle autorégressif,modèle auto-régressif,自己回帰モデル,自己回帰モデル (jikokaiki moderu),自己回帰モデル,авторегрессионная модель,авторегрессионная модель,авторегрессионная модель
524,auto-regressive process,عملية التراجع التلقائي,العملية التكرارية الذاتية,عملية ذاتية الانحدار,自回归过程,自回归过程,自回归过程,processus auto-régressif,processus auto-régressif,processus auto-régressif,自己回帰プロセス,自己回帰過程,自己回帰過程,авторегрессионный процесс,авторегрессионный процесс,автрегрессионный процесс
525,autocalibration,المعايرة التلقائية,المعايرة التلقائية,تعيير ذاتي,自动校准,自标定 (autocalibration),自动校准,auto-étalonnage,autocalibration,autocalibration,自動校正,オートキャリブレーション (autocalibration),自動校正,автокалибровка,автокалибровка,автокалибровка
526,autocorrelation,الارتباط التلقائي,التباين الذاتي,ارتباط ذاتي,自相关,自相关,自相关,autocorrélation,autocorrélation,autocorrélation,自己相関,自己相関,自己相関,автокорреляция,автокорреляция,автокорреляция
527,autodiff,com.autodiff,"""['بنفس الطريقة، يكون تكلفة حساب جاكوبيان H t بحوالي S(F + B) (باستخدام تقنية تفاضل تلقائي إما في النمط الأمامي أو الخلفي).','الخوارزمية 1 تحسين E qη [f θ (",توفيق ذاتي,自动比较,自动微分,自动微分,différentiel automatique,"K) i.i.d. ∼ q η , opérateur de Stein A , tailles de pas α t ,",différenciation automatique,自動差分,K) i.i.d. ∼ q,自動微分,автодифференциал,автовычисление,автодифференцирование
528,automata,أتمتة,آليات,آلة,自动机,自动机,自动机,automates,automates,automates,オートマトン,オートマトン,オートマトン,автоматы,автоматы,автоматы
529,automated mechanism design,تصميم الآلية الآلية,تصميم آلي للآليات,تصميم آلية آلي,自动化机构设计,自动机制设计,自动机制设计,conception de mécanismes automatisés,Conception de mécanismes automatisés,La conception automatisée de mécanismes,自動化機構設計,自動化メカニズム設計,自動メカニズム設計,автоматизированное проектирование механизмов,автоматизированный механизм проектирования,автоматизированное проектирование механизмов
530,automatic differentiation,التمايز التلقائي,التفاضل التلقائي,التفاضل الآلي,自动微分,自动微分,自动微分,différenciation automatique,différenciation automatique,différentiation automatique,自動微分,自動微分,自動微分,автоматическое дифференцирование,автоматическое дифференцирование,автоматическое дифференцирование
531,automatic evaluation,التقييم التلقائي,التقييم التلقائي,تقييم آلي,自动评估,自动评估,自动评估,évaluation automatique,évaluation automatique,évaluation automatique,自動評価,自動評価,自動評価 (じどうひょうか),автоматическая оценка,автоматическая оценка,автоматическая оценка
532,automatic post-editing,التحرير اللاحق التلقائي,التحرير التلقائي للمشاركات,التحرير الآلي اللاحق,自动后期编辑,自动后编辑,自动后编辑 (APE),post-édition automatique,post-édition automatique,post-édition automatique,自動ポストエディット,自動ポスト編集,自動事後編集 (じどうじごへんしゅう),автоматическое постредактирование,автоматическое пост-редактирование,автоматическая постредактирование
533,automatic speech recognition,التعرف التلقائي على الكلام,التعرف التلقائي على الكلام,التعرف التلقائي على الكلام,自动语音识别,自动语音识别,自动语音识别,reconnaissance vocale automatique,Reconnaissance automatique de la parole,reconnaissance automatique de la parole,自動音声認識,自動音声認識 (じどうおんせいにんしき),自動音声認識,автоматическое распознавание речи,автоматическое распознавание речи,автоматическое распознавание речи
534,automorphism,التشكل الذاتي,تشذيب ذاتي,تحوير ذاتي,自同构,自同态,自同构,automorphisme,automorphisme,automorphisme,自己同型性,自己同型写像 (じこどうけいしゃぞう),同型写像,автоморфизм,автоморфизм,автоморфизм
535,autonomous agent,وكيل مستقل,الوكيل المستقل,وكيل مستقل,自主代理,自主代理,自主代理,agent autonome,- Agent autonome,agent autonome,自律エージェント,自律エージェント (jiritsu eejento),自律エージェント,автономный агент,автономный агент,Автономный агент
536,autonomous vehicle,مركبة ذاتية الحكم,مركبة ذاتية القيادة,مركبة ذاتية القيادة,自动驾驶汽车,自主车辆,自动驾驶汽车,véhicule autonome,véhicule autonome,véhicule autonome,自動運転車,自律走行車 (jiritsu sōkōsha),自動運転車両,автономный автомобиль,автономное транспортное средство,автономный транспортный средства
537,autoregressive decoder,فك الترميز الانحداري الذاتي,مفكك التسلسل الذاتي,بدال تراجعي ذاتي,自回归解码器,自回归解码器,自回归解码器,décodeur autorégressif,décodeur autorégressif,décodeur autorégressif,自己回帰デコーダ,自己回帰デコーダ (jiko kaiki deko-da),自己回帰デコーダ,авторегрессионный декодер,авторегрессионный декодер,Авторегрессивный декодер
538,autoregressive generation,جيل الانحدار الذاتي,التوليد التكراري الذاتي,التوليد الذاتي للاستدعاء,自回归生成,自回归生成,自回归生成,génération autorégressive,génération autorégressive,génération autorégressive,自己回帰生成,自己回帰生成,自己回帰生成,авторегрессионное поколение,авторегрессионная генерация,автогрессивная генерация
539,auxiliary classifier,المصنف المساعد,مصنف مساعد,مُصَنّفٌ مُساعِد,辅助分类器,辅助分类器,辅助分类器,classificateur auxiliaire,classificateur auxiliaire,classifieur auxiliaire,補助分類子,補助分類器 (auxiliary classifier),補助分類器 (hosoku bunrui-ki),вспомогательный классификатор,вспомогательный классификатор,вспомогательный классификатор
540,auxiliary loss,خسارة مساعدة,الخسارة المساعدة,خسارة مساعدة,辅助损失,辅助损失,辅助损失,perte auxiliaire,perte auxiliaire,perte auxiliaire,補助損失,補助損失 (hojo sonsu),補助損失,вспомогательная потеря,вспомогательная потеря,вспомогательный убыток
541,auxiliary task,مهمة مساعدة,مهمة مساعدة,مهمة مساعدة,辅助任务,辅助任务,辅助任务,tâche auxiliaire,tâche auxiliaire,tâche auxiliaire,補助的な仕事,補助タスク,補助タスク,вспомогательная задача,вспомогательная задача,вспомогательная задача
542,auxiliary variable,متغير مساعد,- المتغير المساعد,متغير مساعد,辅助变量,辅助变量,辅助变量,variable auxiliaire,variable auxiliaire,variable auxiliaire,補助変数,補助変数 (hojo hensu),補助変数,вспомогательная переменная,вспомогательная переменная,вспомогательная переменная
543,auxillary loss,خسارة مساعدة,الخسارة الإضافية,خسارة مساعدة,辅助损失,辅助损失,辅助损失,perte auxiliaire,perte auxiliaire,perte auxiliaire,補助損失,補助損失,補助損失,вспомогательная потеря,вспомогательная потеря,вспомогательный убыток
544,average loss,متوسط ​​الخسارة,- المتوسط ​​الخسارة,متوسط الخسارة,平均损失,平均损失,平均损失,perte moyenne,- Perte moyenne,perte moyenne,平均損失,- 平均損失 (heikin sonshitsu),平均損失,средняя потеря,- Средний убыток,средние потери
545,average pool,تجمع متوسط,- التجمع المتوسط,طبقة التجميع المتوسط,平均池,平均池 (average pool),平均池化层,piscine moyenne,piscine moyenne,couche de pooling moyenne,平均的なプール,平均プール,平均プール,средний пул,"""['Каждый из этих слоев Softmax получает свой вход от слоя Полностью связанного (FC), построенного поверх слоя среднего пула, который, в свою очередь, построен поверх соответствующего слоя Конкатенации. Пусть DC0, DC1 и DC2 будут слоями Конкатенации, предшествующими",среднее сглаживание
546,average precision,متوسط ​​الدقة,الدقة المتوسطة,متوسط الدقة,平均精度,平均精度 (Average Precision),平均精度,précision moyenne,précision moyenne,précision moyenne,平均精度,平均精度,平均精度,средняя точность,- Средняя точность,средняя точность
547,averaged perceptron,متوسط ​​الإدراك الحسي,"""['تقارن جدول 3 أداء إعادة الترتيب للغابة مقابل إعادة تصنيف النتائج القياسية. لكلا النظامين، نستخدم أولاً فقط الميزات المحلية، ثم جميع الميزات. نستخدم مجموعة",- متوسط مستقبل,平均感知器,平均感知器,平均感知器,perceptron moyen,Perceptron moyen,perceptron moyenné,平均パーセプトロン,平均パーセプトロン,平均パーセプトロン,усредненный персептрон,усредненный персептрон,усредненный перцептрон
548,averaged perceptron algorithm,خوارزمية الإدراك المتوسط,خوارزمية البيرسيبترون المُعدلة,خوارزمية الترجيح المتوسط,平均感知器算法,平均感知机算法,平均感知器算法,algorithme de perceptron moyenné,- Algorithme du perceptron moyen,algorithme de perceptron moyenné,平均パーセプトロンアルゴリズム,平均されたパーセプトロンアルゴリズム,平均パーセプトロンアルゴリズム,усредненный алгоритм перцептрона,алгоритм усреднённого персептрона,алгоритм усредненного перцептрона
549,axis-align rectangle,مستطيل محاذاة المحور,مستطيل محاذي للمحور,مستطيل محاذٍ للمحور,轴对齐矩形,轴对齐矩形,轴对齐矩形,rectangle d'alignement d'axe,rectangle aligné sur l'axe,rectangle aligné sur les axes,軸揃えの長方形,軸に揃えられた長方形,軸に沿った長方形,прямоугольник с выравниванием по оси,"Прямоугольник, выровненный по осям","прямоугольник, выровненный по осям"
550,back-off strategy,استراتيجية التراجع,استراتيجية التراجع,استراتيجية التراجع,退避策略,回退策略,回退策略,stratégie de recul,stratégie de réduction,stratégie de repli,後退戦略,バックオフ戦略,バックオフ戦略,стратегия отступления,стратегия отступления,стратегия отступления
551,back-propagate,نشر خلفي,ترجيع الاختراق,انتشار خلفي,反向传播,反向传播,反向传播,rétropropager,rétropropager,rétropropager,逆伝播する,逆伝播,逆伝播する,обратное распространение,"""['Для этого мы предлагаем полностью дифференцируемую модель деформации и отображения человека, которая позволяет нам сравнивать отображение модели человека с изображением 2D и обратно распространять потери. Для обучения мы сначала захватываем видеопоследовательность в калибров",обратное распространение
552,back-propagate gradient,التدرج الخلفي نشر,"""نلاحظ أن هذا الاختلاف يؤدي إلى تدفق التدرجات المعكوسة التي تنفجر في طبقات الإخراج الجانبية عالية المستوى. لذا نقوم بضبط كيفية استخدامنا لعلامات الح",انتشار تدريجي للخلف,反向传播梯度,反向传播梯度,反向传播梯度,gradient de rétro-propagation,rétropropagation du gradient,rétropropagation du gradient,逆伝播勾配,バックプロパゲート勾配,逆伝播勾配,градиент обратного распространения,обратное распространение градиента,обратное распространение градиента
553,back-propagation algorithm,خوارزمية الانتشار الخلفي,خوارزمية الانتشار الخلفي,خوارزمية الانتشار العكسي,反向传播算法,反向传播算法,反向传播算法,algorithme de rétro-propagation,algorithme de rétropropagation,algorithme de rétropropagation,逆伝播アルゴリズム,バックプロパゲーションアルゴリズム,誤差逆伝播アルゴリズム,алгоритм обратного распространения ошибки,алгоритм обратного распространения,алгоритм обратного распространения
554,back-translation,الترجمة الخلفية,الترجمة العكسية,الترجمة العكسية,回译,反向翻译,反向翻译,traduction arrière,rétrotraduction,traduction arrière,逆翻訳,バック翻訳 (back-translation),逆翻訳,обратный перевод,обратный перевод,обратный перевод
555,backbone,العمود الفقري,العمود الفقري,العمود الفقري,骨干,骨干网络,主干网络,colonne vertébrale,"""['6.70e−3 0.39 ± 6.23e−3 0.47 ± 6.37e−3 0.47 ± 6.40e−3 0.68 ± 1.23e−2 72.55 ± 1.75e+0 \n (a) Résultats de l'étude d'ablation utilisant les légendes L1L2L3 combinées. Niveau d'entrée de l'expérience BLEU ↑ Perplexité ↓",colonne vertébrale,背骨,バックボーン (backbone),主幹,позвоночник,основа,Основная сеть
556,backbone model,نموذج العمود الفقري,- التصنيف الأساسي,نموذج الأساس,骨干模型,骨干模型,主干模型,modèle de base,modèle de base,modèle de base,バックボーンモデル,バックボーンモデル,基幹モデル,магистральная модель,модель основы,базовая модель
557,backbone network,شبكة العمود الفقري,شبكة العمود الفقري,شبكة الهيكل الأساسي,骨干网络,骨干网络,主干网络,réseau fédérateur,Nous adoptons le réseau de pyramide,réseau de base,バックボーンネットワーク,バックボーンネットワーク,基幹ネットワーク,магистральная сеть,"""Результаты ViT в классификации изображений обнадеживающие, но ее архитектура не подходит для использования в качестве общеупотребимой основной сети на плотных задачах компьютерного зрения или когда разрешение входного изображения высокое из-за низкоразрешенных карт признаков и",сквозная сеть
558,backdoor,الباب الخلفي,الباب الخلفي,باب خلفي,后门,后门,后门,porte arrière,porte dérobée,porte dérobée,裏口,バックドア,バックドア,черный ход,задняя дверь,закладка
559,backdoor adjustment,تعديل الباب الخلفي,التعديل الخلفي,تعديل الباب الخلفي,后门调整,背门调整,反向门调整,réglage de la porte dérobée,ajustement de porte dérobée,ajustement par la porte de derrière,バックドア調整,バックドア調整,裏口調整,регулировка задней двери,коррекция обратной двери,подвох-корректировка
560,backdoor attack,هجوم الباب الخلفي,هجوم الباب الخلفي,هجوم الباب الخلفي,后门攻击,后门攻击,后门攻击,attaque par porte dérobée,attaque en porte dérobée,attaque par porte dérobée,バックドア攻撃,バックドア攻撃,バックドア攻撃,бэкдор-атака,атака через заднюю дверь,атака со скрытным функционалом
561,backdoor sample,عينة الباب الخلفي,عينة باب خلفي,عينة الباب الخلفي,后门样本,后门样本,后门样本,échantillon de porte dérobée,échantillon de porte dérobée,échantillon porte dérobée,バックドアのサンプル,バックドアサンプル,バックドア・サンプル,образец бэкдора,обратный образец,бэкдор-образцы
562,background model,نموذج الخلفية,النموذج الخلفي,نموذج الخلفية,背景模型,背景模型,背景模型,modèle de fond,modèle de fond,modèle de fond,背景モデル,- 背景モデル,背景モデル,фоновая модель,фоновая модель,Обобщённая модель
563,background subtraction,الخلفية الطرح,- تباعد الخلفية,استخراج الخلفية,背景扣除,背景减法,背景减除,soustraction de fond,soustraction de l'arrière-plan,soustraction d'arrière-plan,バックグラウンド減算,背景差分 (haikei sabin),背景差分,вычитание фона,Вычитание фона,вычитание фона
564,backoff model,نموذج التراجع,النموذج الاحتياطي,نموذج الارتداد,退避模型,回退模型,回退模型,modèle de recul,"""['Comme le montre Cohen et al., 2010), la précision d'analyse du modèle TSG est fortement affectée par son modèle de réduction. Les effets de notre modèle de réduction hiérarchique sur les performances d'analyse sont évalués dans la Section 5.', 'De plus, lorsqu'une phrase est non analysable avec de grands fragments d'arbre, le parseur PTSG utilise généralement des règles CFG naïves dérivées de son modèle de réduction, ce",modèle de repli,バックオフモデル,バックオフモデル,バックオフモデル,модель отсрочки,обратная модель,модель резервного поведения
565,backpointer,backpointer,الرابط الخلفي,مُشير خَلْفي,反向指针,回指针,回指针,pointeur arrière,"""['L'arbre oracle y + peut être restauré de manière récursive en conservant des backpointers pour chaque ora[v](t), que nous omettons dans le pseudocode. La complexité temporelle de cet algorithme pour une phrase de l mots est O(|E| • l 2(a−1) ) où a est l'arité de la forêt.', 'L'objectif de l'algorithme d'analyse 1-best A * est de calculer le score intérieur de Viterbi du",Pointeur arrière,バックポインタ,バックポインタ,バックポインタ,обратный указатель,обратный указатель,обратный указатель
566,backprojection,الإسقاط الخلفي,- التصوير الخلفي,اسْتِرْجَاعُ التَّضْمِينِ,反投影,反投影,反投影,rétroprojection,rétroprojection,rétroprojection,逆投影,逆投影,逆投影,обратная проекция,обратная проекция,обратная проекция
567,backprop,backprop,1 ) the memory cost scales linearly with the unroll,التراجع,反向传播,反向传播,反向传播,arrière-plan,rétropropagation,rétropropagation,バックプロップ,バックプロップ,逆伝播,задняя опора,обратное распространение (backprop),обратное распространение
568,backpropagation,الانتشار العكسي,- تراجع الخلفية,التراجع,反向传播,反向传播,反向传播,rétropropagation,rétropropagation,rétropropagation,誤差逆伝播法,バックプロパゲーション,逆伝播,обратное распространение ошибки,обратное распространение,обратное распространение
569,backtracking line search,البحث عن خط التراجع,بحث خطي للتتبع,استرجاع البحث الخطي,回溯线搜索,回溯线搜索,回溯线搜索,recherche de ligne de retour en arrière,recherche linéaire de retour en arrière,recherche de ligne par retour sur trace,遡行ライン検索,逆戻りラインサーチ,後戻り線探索,поиск строки с возвратом,метод обратного поиска линии,обратный поиск линии
570,backward pass,تمريرة للخلف,التمرير الخلفي,مرور عكسي,向后传递,反向传播,反向传播,passe arrière,passe arrière,Propagation arrière,バックパス,逆伝播,逆伝播,пас назад,обратный проход,Обратный проход
571,bad case,حالة سيئة,حالة سيئة,حالة سيئة,坏情况,差劲案例,最坏情况,mauvais cas,cas défavorable,pire cas,悪いケース,悪いケース,最悪ケース,плохой случай,- Плохой случай,худший случай
572,bad-case regret,الأسف السيئ,الندم الأسوأ في الحالات سيئة,سوء الحالة ندم,糟糕的情况后悔,最坏情况遗憾,最坏情况下的遗憾,regret de mauvais cas,Regret en cas de pire scénario,regret du pire cas,悪い場合の後悔,最悪ケースの後悔,最悪の後悔,сожаление о плохом случае,плохое значение регрета,плохой случай сожаления
573,bag of feature,حقيبة من الميزة,حقيبة الميزات,حقيبة الميزات,特征袋,特征包,特征包,sac de fonctionnalités,Sac de caractéristiques,sac de traits,特徴のバッグ,特徴の袋 (Tokuchō no fukuro),バッグオブフィーチャー,сумка с функциями,мешок признаков,мешок признаков
574,bag-of-word,حقيبة من الكلمات,حقيبة الكلمات,كيس كلمات,词袋,词袋模型 (Bag-of-Word),词袋表示,sac de mots,sac de mots,sac-de-mots,一言一句,"""['そして、各画像は、画像からのすべてのSIFT特徴量をクラスタリングするためにk-meansを使用してコードブックを構築することで、単語袋（BoW）表現を使用して4000次元のトークン頻度（TF）特徴で表されます。', '経験的な観点から、特定の一",バッグオブワード,мешок со словами,мешок слов,мешок-слов
575,bag-of-word model,نموذج حقيبة الكلمات,نموذج كيس الكلمات,نموذج كيس الكلمات,词袋模型,词袋模型,词袋模型,modèle de sac de mots,Modèle sac de mots,modèle sac de mots,バッグオブワードモデル,単語袋モデル,バッグオブワードモデル,модель «мешок слов»,модель мешка слов,модель мешка слов
576,bag-of-word representation,تمثيل كيس من الكلمات,التمثيل بنظام حقيبة الكلمات,تمثيل كيس الكلمات,词袋表示法,词袋表示法,词袋表示,représentation en sac de mots,représentation sac-de-mots,représentation sac de mots,バッグオブワード表現,単語袋表現,bag-of-word表現,представление «мешок слов»,мешок слов,мешок-слов представление
577,bandit,قطاع الطرق,السارق,بانديت,土匪,摇臂赌博机 (bandit),探索-利用权衡问题,bandit,bandit,bras de bandit,盗賊,バンディット,腕探し,бандит,бандит,бандит
578,bandit feedback,ردود فعل قطاع الطرق,- تغذية اللصوص,إفادة القوات المتمردة,强盗反馈,强盗反馈,赌博者反馈,commentaires des bandits,feedback de bandit,rétroaction de bandit,盗賊のフィードバック,バンディットフィードバック,バンディット・フィードバック (bandit feedback),бандитский отзыв,фидбек бандитов,эксплоратор обратной связи
579,bandit learning,تعلم قطاع الطرق,تعلم اللص,تعلم اللصوص,强盗学习,强盗学习,行贼学习,apprentissage des bandits,apprentissage bandit,apprentissage par bandits,盗賊の学習,バンディット学習,バンディット学習,бандитское обучение,бандитский обучение,обучение бандитов
580,bandwidth parameter,معلمة عرض النطاق الترددي,معلمة النطاق الترددي,معامل النطاق الترددي,带宽参数,带宽参数,带宽参数,paramètre de bande passante,paramètre de bande passante,paramètre de largeur de bande,帯域幅パラメータ,帯域パラメータ (taiiki parameta),帯域幅パラメータ,параметр полосы пропускания,параметр полосы пропускания,параметр ширины полосы
581,bart-base,قاعدة بارت,بارت-بيس,نموذج قاعدي بارت,巴特基地,bart-base,bart-base模型,Bart-base,bart-base,bart-base,バートベース,bart-base,バート・ベース (bart-base),барт-база,bart-base,bart-base
582,bart-large,بارت كبير,بارت-كبير,النموذج الكبير لبارت (bart-large),巴特大号,bart-large,bart-large的中文翻译为大型bart模型,Bart-grand,bart-large,grand-bart,バート大,bart-large,バートラージ (bart-large),Барт-большой,bart-large,bart-large
583,barycentric coordinate,إحداثيات مركزية,إحداثيات باري المركزية,إحداثيات بارسينترية,重心坐标,重心坐标,重心坐标,coordonnée barycentrique,coordonnée barycentrique,coordonnées barycentriques,重心座標,重心座標,重心座標,барицентрическая координата,барицентрические координаты,барицентрические координаты
584,base classifier,المصنف الأساسي,الفاصل الأساسي,ُمصنف القاعدة,基分类器,基分类器,基分类器,classificateur de base,classificateur de base,classifieur de base,基本分類子,ベース分類器 (base classifier),ベースクラシファイア,базовый классификатор,базовый классификатор,классификатор базовый
585,base distribution,التوزيع الأساسي,التوزيع الأساسي,توزيع أساسي,基础分布,基础分布,基础分布,distribution de base,distribution de base,distribution de base,基本分布,ベース分布,基底分布,базовое распределение,базовое распределение,базовое распределение
586,base learner,المتعلم الأساسي,المتعلم الأساسي,متعلم أساسي,基础学习者,基本学习器,基础学习器,apprenant de base,apprenant de base,apprenant de base,基本学習者,ベースラーナー,ベース学習器,базовый ученик,базовый ученик,базовый алгоритм обучения
587,base model,نموذج القاعدة,النموذج الأساسي,نموذج أساسي,基础模型,基础模型,基本模型,modèle de base,modèle de base,modèle de base,ベースモデル,"Base Model
ベースモデル",ベースモデル,базовая модель,базовая модель,базовая модель
588,baseline algorithm,خوارزمية خط الأساس,- تقنية الخوارزمية الأساسية,خوارزمية أساسية,基线算法,基准算法,基准算法,algorithme de base,algorithme de référence,algorithme de référence,ベースラインアルゴリズム,ベースラインアルゴリズム,ベースラインアルゴリズム,базовый алгоритм,- Baseline алгоритм,базовый алгоритм
589,baseline method,طريقة خط الأساس,طريقة النسق الأساسي,الطريقة الأساسية,基线法,基准方法,基准方法,méthode de base,méthode de référence,méthode de référence,ベースラインメソッド,ベースライン手法,ベースラインメソッド,базовый метод,- Базовый метод,базовый метод
590,baseline model,نموذج خط الأساس,النموذج الأساسي,نموذج الأساس,基线模型,基准模型,基准模型,modèle de base,- Modèle de base,modèle de référence,ベースラインモデル,ベースラインモデル,ベースラインモデル,базовая модель,базовая модель,исходная модель
591,baseline parser,محلل خط الأساس,محلل الخط الأساسي,محلل القاعدة,基线解析器,基准解析器 (baseline parser),基准解析器,analyseur de base,analyseur de base,analyseur syntaxique de base,ベースラインパーサー,ベースラインパーサー,ベースラインパーサー,базовый парсер,базовый парсер,базовый синтаксический анализатор
592,baseline policy,سياسة خط الأساس,سياسة القاعدة,سياسة الأساس,基准政策,基线策略,基线策略,politique de base,- Politique de référence,politique de référence,ベースラインポリシー,ベースラインポリシー,ベースラインポリシー,базовая политика,базовая политика,базовая политика
593,baseline system,نظام خط الأساس,نظام القاعدة,نظام أساسي,基线系统,基准系统,基线系统,système de base,système de référence,système de référence,ベースラインシステム,ベースラインシステム,ベースラインシステム,базовая система,базовая система,эталонная система
594,basis function,وظيفة الأساس,وظائف القاعدة,دوال القاعدة,基函数,基函数,基函数,fonction de base,fonction de base,fonction de base,基底関数,基底関数,基底関数,базисная функция,базисная функция,Базисная функция
595,basis vector,ناقلات الأساس,متجه الأساس,متجه قاعدي,基向量,基向量,基向量,vecteur de base,vecteur de base,vecteur de base,基底ベクトル,基底ベクトル,ベーシスベクトル,базисный вектор,вектор базиса,базисный вектор
596,batch algorithm,خوارزمية دفعة,- تحليل دفعة,خوارزمية الدفعة,批处理算法,批处理算法,批量算法,algorithme par lots,algorithme par lot,algorithme par lots,バッチアルゴリズム,バッチアルゴリズム,バッチアルゴリズム,пакетный алгоритм,- Пакетный алгоритм,алгоритм пакетной обработки
597,batch dimension,البعد الدفعي,البعد التجميعي,بُعد الدفعة,批量尺寸,批次维度,批次维度,dimension de lot,- Dimension du lot,dimension du lot,バッチディメンション,バッチ次元,バッチ次元,размер партии,размер партии,размерность пакета
598,batch element,عنصر الدفعة,عنصر دفعة,عنصر الدفعة,批处理元素,批处理元素,批次元素,élément de lot,- Élément de lot,élément de lot,バッチ要素,バッチ要素,バッチ要素,элемент партии,элемент пакета,пакетный элемент
599,batch learning,التعلم الدفعي,التعلم بالدفعة,التعلم الدفعي,批量学习,批量学习,批量学习,apprentissage par lots,apprentissage par lots,apprentissage par lots,バッチ学習,バッチ学習 (batch learning),バッチ学習,пакетное обучение,- Пакетное обучение,пакетное обучение
600,batch mode,دفعة واسطة,- تعلم بالدُّفعات,وضع دفعي,批处理模式,批处理模式,批处理模式,temps différé,Mode par lot,mode par lots,バッチモード,バッチモード,バッチモード,пакетный режим,пакетный режим,пакетный режим
601,batch normalization,تطبيع الدفعة,تعويض الدفعة,تصحيح الدفعة,批量归一化,批量归一化,批量归一化,normalisation par lots,normalisation par lots,normalisation par lots,バッチ正規化,バッチ正規化,バッチ正規化,пакетная нормализация,нормализация пакетов,Нормализация партии
602,batch optimization,تحسين الدفعة,تحسين دفعة,تحسين الدفعة,批量优化,批量优化,批量优化,optimisation des lots,optimisation par lot,optimisation par lots,バッチの最適化,バッチ最適化,バッチ最適化,пакетная оптимизация,пакетная оптимизация,пакетная оптимизация
603,batch processing,تجهيز الدفعات,- تجهيز الدفعات,معالجة دُفعية,批量处理,批处理,批量处理,le traitement par lots,traitement par lots,traitement par lots,バッチ処理,バッチ処理,バッチ処理,пакетная обработка,Пакетная обработка,пакетная обработка
604,batch setting,إعداد الدفعة,إعداد دفعة,ضبط الدفعة,批量设置,批量设置,批量设置,réglage par lots,configuration par lots,par lots,一括設定,バッチ設定,バッチ設定,пакетная настройка,пакетная установка,партийная установка
605,batch training,تدريب دفعة,تدريب الدفعة,تدريب دفعي,批量训练,批量训练,批量训练,formation par lots,Entraînement par lots,entraînement par lots,バッチトレーニング,バッチトレーニング,バッチトレーニング,пакетное обучение,- Пакетное обучение,Пакетное обучение
606,bayesian active learning,التعلم النشط بايزي,التعلم النشط البايزي,التعلم النشط البايزي,贝叶斯主动学习,贝叶斯主动学习,贝叶斯主动学习,apprentissage actif bayésien,apprentissage actif bayésien,apprentissage actif bayésien,ベイジアンアクティブラーニング,ベイジアンアクティブラーニング,ベイズ的能動学習,байесовское активное обучение,байесовское активное обучение,Байесово активное обучение
607,bayesian analysis,تحليل بايزي,التحليل البايزياني,التحليل البايزي,贝叶斯分析,贝叶斯分析,贝叶斯分析,analyse bayésienne,Analyse bayésienne,analyse bayésienne,ベイジアン分析,ベイズ解析,ベイズ解析,байесовский анализ,байесовский анализ,байесовский анализ
608,bayesian approach,النهج بايزي,النهج البايزي,نهج بايزي,贝叶斯方法,贝叶斯方法,贝叶斯方法,approche bayésienne,- Approche bayésienne,approche bayésienne,ベイジアンアプローチ,ベイズ手法,ベイズ的アプローチ,байесовский подход,байесовский подход,Байесовский подход
609,bayesian clustering,التجميع البايزي,التجميع البايزياني,تجميع بايزي,贝叶斯聚类,贝叶斯聚类,贝叶斯聚类,clustering bayésien,regroupement bayésien,regroupement bayésien,ベイズクラスタリング,ベイズクラスタリング,ベイズクラスタリング,байесовская кластеризация,байесовская кластеризация,байесовская кластеризация
610,bayesian decision,قرار بايزي,القرار البايزياني,قرار بايزي,贝叶斯决策,贝叶斯决策,贝叶斯决策,décision bayésienne,décision bayésienne,décision bayésienne,ベイジアン決定,ベイジアン決定 (Bayesian decision),ベイズ決定,байесовское решение,Байесовское решение,байесовское решение
611,bayesian deep learning,التعلم العميق بايزي,تعلم التعمق البيزياني,التعلم العميق البايزي,贝叶斯深度学习,贝叶斯深度学习,贝叶斯深度学习,apprentissage profond bayésien,apprentissage profond bayésien,apprentissage profond bayésien,ベイジアンディープラーニング,ベイジアン深層学習,ベイズ深層学習,байесовское глубокое обучение,Байесовское глубокое обучение,байесовское глубокое обучение
612,bayesian evidence,الأدلة بايزي,الحجة البيزية,الدليل البايزي,贝叶斯证据,贝叶斯证据,贝叶斯证据,preuve bayésienne,preuve bayésienne,preuve bayésienne,ベイズ証拠,ベイジアン証拠,ベイズ証拠,байесовское свидетельство,байесовские доказательства,байесовское свидетельство
613,bayesian framework,الإطار بايزي,- الإطار البيزياني,إطار بايزي,贝叶斯框架,贝叶斯框架,贝叶斯框架,cadre bayésien,cadre bayésien,cadre bayésien,ベイジアンフレームワーク,ベイズフレームワーク,ベイズ的枠組み,байесовский подход,байесовская структура,байесовская рамка
614,bayesian game,لعبة بايزي,- تصنيف البايزية,لعبة بايزية,贝叶斯博弈,贝叶斯博弈,贝叶斯博弈,jeu bayésien,jeu bayésien,jeu bayésien,ベイジアンゲーム,ベイジアンゲーム,ベイジアンゲーム,байесова игра,байесовская игра,байесовская игра
615,bayesian inference,الاستدلال بايزي,- تستقراء بايزية,الاستدلال البايزي,贝叶斯推理,贝叶斯推断,贝叶斯推断,inférence bayésienne,inférence bayésienne,inférence bayésienne,ベイズ推論,ベイズ推論 (Beizu suiron),ベイズ推論,байесовский вывод,Байесовское выводирование,байесовское вывод
616,bayesian information Criterion,معيار المعلومات بايزي,معيار المعلومات البايسية,معيار المعلومات البايزي,贝叶斯信息准则,贝叶斯信息准则,贝叶斯信息准则,Information bayésienne Critère,Critère d'information bayésien,Critère d'information bayésien,ベイズ情報の基準,ベイズ情報基準,ベイズ情報量基準,Байесовский информационный критерий,Байесовский информационный критерий,Байесовский информационный критерий
617,bayesian learning,التعلم بايزي,التعلم البايزياني,التعلم البايزي,贝叶斯学习,贝叶斯学习,贝叶斯学习,apprentissage bayésien,apprentissage bayésien,apprentissage bayésien,ベイズ学習,ベイズ学習,ベイズ学習,байесовское обучение,байесовское обучение,байесовское обучение
618,bayesian method,الطريقة البايزية,الطرق البايزية,طريقة بايزية,贝叶斯方法,贝叶斯方法,贝叶斯方法,méthode bayésienne,- Méthode bayésienne,méthode bayésienne,ベイズ法,ベイズ法,ベイズ法,байесовский метод,байесовский метод,байесовский метод
619,bayesian model,نموذج بايزي,- تعميم النموذج البيزي للنموذج البيزي التسلسلي,نموذج بايزي,贝叶斯模型,贝叶斯模型,贝叶斯模型,modèle bayésien,modèle bayésien,modèle bayésien,ベイズモデル,ベイジアンモデル,ベイズモデル,байесовская модель,байесовская модель,байесовская модель
620,bayesian optimization,الأمثل بايزي,التحسين البايزياني,تحسين بايزي,贝叶斯优化,贝叶斯优化,贝叶斯优化,optimisation bayésienne,optimisation bayésienne,optimisation bayésienne,ベイジアン最適化,ベイズ最適化 (ベイジアン最適化),ベイズ最適化,байесовская оптимизация,Байесовская оптимизация,байесовская оптимизация
621,bayesian perspective,منظور بايزي,- التوجه البايسياني,وجهة نظر بيزية,贝叶斯视角,贝叶斯观点,贝叶斯视角,perspective bayésienne,- Perspective bayésienne,perspective bayésienne,ベイジアンパースペクティブ,ベイズの観点,ベイズ的観点,байесианская перспектива,байесовская перспектива,байесовская перспектива
622,bayesian probabilistic model,النموذج الاحتمالي بايزي,- تصميم برمجي بايزي للنمذجة الاحتمالية,نموذج احتمالي بايزي,贝叶斯概率模型,贝叶斯概率模型,贝叶斯概率模型,modèle probabiliste bayésien,Modèle probabiliste bayésien,modèle probabiliste bayésien,ベイジアン確率モデル,ベイズ確率モデル,ベイズ確率モデル,байесовская вероятностная модель,байесовская вероятностная модель,байесовская вероятностная модель
623,bayesian update,تحديث بايزي,تحديث بايزيان,تحديث بايزي,贝叶斯更新,贝叶斯更新,贝叶斯更新,mise à jour bayésienne,mise à jour bayésienne,mise à jour bayésienne,ベイズ更新,ベイジアン更新,ベイズ更新,байесовское обновление,байесовское обновление,байесовское обновление
624,beam search algorithm,خوارزمية البحث عن الشعاع,خوارزمية البحث الشعاعي,خوارزمية البحث بالشعاع,波束搜索算法,束搜索算法,束搜索算法,algorithme de recherche de faisceau,algorithme de recherche de faisceau,algorithme de recherche par faisceau,ビーム探索アルゴリズム,ビームサーチアルゴリズム,ビームサーチアルゴリズム,алгоритм поиска луча,Алгоритм жадного поиска,алгоритм лучевого поиска
625,beam search decoding,فك تشفير البحث شعاع,فك تشفير بحث الحزمة,فك ترميز البحث الشعاعي,波束搜索解码,束搜索解码,束搜索解码,décodage par recherche de faisceau,décodage de recherche de faisceau,décodage par recherche de faisceaux,ビームサーチデコーディング,ビームサーチデコード,ビーム探索デコーディング,декодирование поиска луча,декодирование с поиском лучевого пучка,поиск по лучам декодирования
626,beam search decoding algorithm,خوارزمية فك تشفير بحث الشعاع,خوارزمية فك تشفير البحث الشعاعي,خوارزمية ترميز البحث الشعاعي,波束搜索解码算法,束搜索解码算法,束搜索解码算法,algorithme de décodage par recherche de faisceau,algorithme de décodage par recherche de faisceau,algorithme de décodage par recherche de faisceaux,ビームサーチデコードアルゴリズム,ビームサーチデコーディングアルゴリズム,ビーム探索デコーディングアルゴリズム,алгоритм декодирования поиска луча,алгоритм декодирования с поиском пучка,Алгоритм декодирования с лучевым поиском
627,beam size,حجم الشعاع,- تحجيم الشعاع,حجم الشعاع,光束尺寸,束大小,束宽,taille du faisceau,taille du faisceau,taille du faisceau,ビームサイズ,ビームサイズ,ビームサイズ,размер луча,размер луча,размер луча
628,beam width,عرض الشعاع,عرض الشعاع,عرض الحزمة,波束宽度,光束宽度,束宽,largeur du faisceau,largeur du faisceau,largeur du faisceau,ビーム幅,ビーム幅,ビーム幅,ширина луча,ширина луча,ширина луча
629,behavior cloning,استنساخ السلوك,نسخ السلوك,إستنساخ السلوك,行为克隆,行为克隆,行为克隆,clonage de comportement,clonage de comportement,clonage comportemental,動作の複製,行動クローニング,行動クローニング,клонирование поведения,клонирование поведения,копирование поведения
630,behavior policy,سياسة السلوك,سياسة السلوك,سياسة السلوك,行为政策,行为策略,行为策略,politique comportementale,politique comportementale,politique de comportement,行動方針,振る舞いポリシー,行動方針,политика поведения,поведенческая стратегия,стратегия поведения
631,belief propagation,نشر الاعتقاد,انتشار الاعتقادات,نشر المعتقدات,信念传播,信念传播,信念传播,propagation des croyances,propagation de croyance,propagation de croyance,信念の伝播,信念伝播 (Shin'nen Denpa),確信伝搬,распространение убеждений,передача убеждений,распространение убеждений
632,belief state,دولة الاعتقاد,حالة الاعتقاد,حالة الاعتقاد,信念状态,信念状态,信念状态,état de croyance,État de croyance,état de croyance,信念状態,信念状態 (shin'nen joutai),信念状態,состояние убеждения,состояние убеждения,состояние убеждения
633,benchmark,المعيار,المعيار,مقياس أساسي,基准,基准,基准测试,référence,référence,référence,基準,ベンチマーク,ベンチマーク,эталон,бенчмарк,эталон
634,benchmark dataset,مجموعة البيانات المرجعية,مجموعة بيانات معيارية,مجموعة بيانات معيارية,基准数据集,基准数据集,基准数据集,ensemble de données de référence,jeu de données de référence,ensemble de données de référence,ベンチマークデータセット,ベンチマークデータセット,ベンチマークデータセット,эталонный набор данных,базовый набор данных,эталонный набор данных
635,benchmark task,مهمة مرجعية,مهمة معيارية,مهمة معيارية,基准任务,基准任务 (benchmark task),基准任务,tâche de référence,tâche de référence,tâche de référence,ベンチマークタスク,基準タスク (Benchmark Task),ベンチマークタスク,контрольная задача,базовая задача,эталонная задача
636,beta distribution,توزيع بيتا,التوزيع بيتا,توزيع بيتا,贝塔分布,贝塔分布,贝塔分布,distribution bêta,distribution bêta,distribution bêta,ベータ版の配布,ベータ分布,ベータ分布,бета-распределение,бета-распределение,распределение Бета
637,beta1,بيتا1,بيتا1,بيتا1,贝塔1,beta1,beta1 0.5,bêta1,beta1,beta1,ベータ1,ベータ1,beta1 0.5,бета1,бета1,beta1 0.5
638,between-class variance,التباين بين الطبقات,التباين بين الفئات,تباين بين الفئات,类间方差,类间方差,类间方差,variance entre les classes,- Variance entre les classes,variance inter-classe,クラス間の差異,クラス間分散,クラス間分散,межклассовая дисперсия,межклассовая дисперсия,межклассовая дисперсия
639,betweenness,بين,الوساطة,قابلية الوسطية,中间性,介数,介数,entre-deux,intermédiarité,intermédiarité,間,間接性 (Kansetsu-sei),媒介中心性,посредничество,промежуточность,промежуточность
640,bi-gram,ثنائية جرام,زوج الكلمات,ثنائي الكلمات,二元语法,二元组,二元语法,bi-gramme,"""['De plus, nous utilisons 50 000 caractéristiques éparses et binaires telles que ""Est-ce que le bi-gramme 'états-unis' est présent dans la sortie ?"", basé sur (Chiang et al., 2009). Nous utilisons un modèle de langue 3-grammes pour le décodage et un modèle de langue 5-grammes pour le rescorer.', 'Par exemple, LibMultiLabel n'utilise que des uni-grammes, tandis que Chalkidis et",bi-gramme,バイグラム,バイグラム,2つの文字からなる連続する文字列,биграмма,биграмма,биграмма
641,bi-level optimization,التحسين ثنائي المستوى,التحسين ثنائي المستوى,تحسين ثنائي المستوى,双层优化,双层优化,双层优化,optimisation à deux niveaux,optimisation bi-niveau,optimisation bi-niveau,2レベルの最適化,バイレベル最適化,2レベル最適化,двухуровневая оптимизация,двухуровневая оптимизация,двухуровневая оптимизация
642,bias,تحيز,الانحياز,انحياز,偏见,偏差,偏差,biais,biais,biais,バイアス,バイアス,バイアス,предвзятость,смещение,смещение
643,bias mitigation,تخفيف التحيز,تخفيف التحيز,التخفيف من التحيز,偏见缓解,偏见消除,偏差缓解,atténuation des biais,atténuation des biais,atténuation des biais,バイアスの軽減,バイアス軽減 (Baiasu keigen),バイアス緩和,смягчение предвзятости,уменьшение предвзятости,смягчение предвзятости
644,bias parameter,معلمة التحيز,معامل الانحياز,معامل الانحياز,偏置参数,偏置参数,偏置参数,paramètre de biais,paramètre de biais,paramètre de biais,バイアスパラメータ,バイアスパラメータ,バイアス パラメータ,параметр смещения,параметр смещения,Параметр смещения
645,bias term,مصطلح التحيز,مصطلح الانحياز,حد التحيز,偏差项,偏置项,偏置项,terme de biais,terme de biais,terme de biais,バイアス項,バイアス項,バイアス項,термин предвзятости,терметр смещения,смещение
646,bias vector,ناقلات التحيز,متجه الانحياز,متجه التحيز,偏差向量,偏置向量,偏置向量,vecteur de biais,vecteur de biais,vecteur de biais,バイアスベクトル,バイアスベクトル (bias vector),バイアスベクトル,вектор смещения,вектор смещения,вектор смещения
647,bias-variance tradeoff,مقايضة التحيز والتباين,التوازن بين الانحياز والتباين,موازنة التحيز والتباين,偏差-方差权衡,偏差-方差权衡,偏差-方差权衡,compromis biais-variance,compromis biais-variance,compromis biais-variance,バイアスと分散のトレードオフ,バイアス-バリアンストレードオフ,バイアス・分散トレードオフ,компромисс между смещением и дисперсией,компромисс между смещением и дисперсией,компромисс смещение-дисперсия
648,biased estimator,مقدر متحيز,مقدر متحيز,تقدير متحيز,有偏估计量,有偏估计量,有偏估计量,estimateur biaisé,estimateur biaisé,estimateur biaisé,偏った推定量,バイアスのある推定値,バイアス推定値,смещенная оценка,Смещенный оценщик,Смещенная оценка
649,bibliographic coupling,اقتران الببليوغرافية,الارتباط الببليوغرافي,الاقتران الببليوغرافي,书目耦合,文献耦合,文献耦合,couplage bibliographique,couplage bibliographique,couplage bibliographique,書誌結合,文献の結合,文献カップリング,библиографическая связь,библиографическая связь,библиографическая связь
650,bicubic interpolation,الاستيفاء التكعيبي,التكبير الثنائي الثنائي,انتساب ثنائي المكعب,双三次插值,双三次插值,双三次插值,interpolation bicubique,interpolation bicubique,interpolation bicubique,バイキュービック補間,バイキュービック補間,双三次補間,бикубическая интерполяция,бикубическая интерполяция,бикубическая интерполяция
651,bidirectional,ثنائي الاتجاه,ثنائي الاتجاه,ثنائي الاتجاه,双向,双向的,双向,bidirectionnel,bidirectionnel,bidirectionnelle,双方向,双方向性,双方向,двунаправленный,двунаправленный,двунаправленный
652,bidirectional Transformer,محول ثنائي الاتجاه,- المحول ثنائي الاتجاهات,مُحوِّل ثُنائيّ الاتجاه,双向变压器,双向Transformer,双向Transformer,Transformateur bidirectionnel,"""['De plus, le module de fusion et le réseau de pointeurs se composent de deux et d'une couche de blocs de transformateur bidirectionnel initialisés de manière aléatoire (Vaswani et al., 2017) respectivement. Nous menons des expériences sur un GPU RTX 6000. De plus, nous construisons le classificateur de style basé sur l'encodeur de LongLM BASE et T5 BASE pour le chinois et l'anglais, respectivement.',",Transformer bidirectionnel,双方向トランス,双方向Transformer,双方向Transformer,двунаправленный трансформатор,бидирекциональный Трансформер,двунаправленный преобразователь
653,bidirectional encoder,التشفير ثنائي الاتجاه,مُشفر ثنائي الاتجاه,مشفر ثنائي الاتجاه,双向编码器,双向编码器,双向编码器,codeur bidirectionnel,encodeur bidirectionnel,encodeur bidirectionnel,双方向エンコーダ,双方向エンコーダ（bidirectional encoder）,双方向エンコーダ,двунаправленный кодер,двунаправленный энкодер,двунаправленный энкодер
654,bidirectional heuristic search,البحث الإرشادي ثنائي الاتجاه,البحث الإستراتيجي ذو الاتجاهين,البحث الاستكشافي ثنائي الاتجاه,双向启发式搜索,双向启发式搜索,双向启发式搜索,recherche heuristique bidirectionnelle,Recherche heuristique bidirectionnelle,recherche heuristique bidirectionnelle,双方向ヒューリスティック検索,双方向ヒューリスティック探索,双方向ヒューリスティック探索,двунаправленный эвристический поиск,двунаправленный эвристический поиск,Двунаправленный эвристический поиск
655,bidirectional model,نموذج ثنائي الاتجاه,نموذج ثنائي الاتجاه,نموذج ثنائي الاتجاه,双向模型,双向模型,双向模型,modèle bidirectionnel,modèle bidirectionnel,modèle bidirectionnel,双方向モデル,双方向モデル,双方向モデル,двунаправленная модель,двунаправленная модель,двунаправленная модель
656,bidirectional search,بحث ثنائي الاتجاه,البحث ذو الاتجاهين,البحث ثنائي الاتجاه,双向搜索,双向搜索,双向搜索,recherche bidirectionnelle,recherche bidirectionnelle,recherche bidirectionnelle,双方向検索,双方向探索,双方向探索,двунаправленный поиск,Двунаправленный поиск,двунаправленный поиск
657,bidirectionality,ثنائية الاتجاه,الثنائية,تبادلية الاتجاه,双向性,双向性,双向性,bidirectionnalité,bidirectionnalité,bidirectionnalité,双方向性,双方向性,双方向性,двунаправленность,двунаправленность,двунаправленность
658,big-o notation,تدوين كبير يا,تدوين Big-O,الدلالة الكبيرة-أوميغا,大O表示法,大O符号,大O符号,notation big-o,- Notation big-O,notation grand O,ビッグオー表記,ビッグオー表記,大記号表記,обозначение «большое о»,нотация большого О,Большая Вогнутая нотация
659,bigram count,عدد بيجرام,عدد الزوجات الكبير,عدد الثنائيات,二元组数,双字计数,双元模型计数,nombre de bigrammes,décompte de bigrammes,compte de bigrammes,バイグラム数,バイグラムカウント,バイグラム数,количество биграмм,подсчет биграмм,количество биграмм
660,bigram language model,نموذج لغة بيجرام,نموذج لغة ثنائي الكلمات,نموذج لغة ثُنائي المقاطع,二元语言模型,二元语言模型,双元语言模型,modèle de langage bigramme,modèle de langue bigramme,modèle de langue bigramme,バイグラム言語モデル,バイグラム言語モデル,2グラム言語モデル,языковая модель биграммы,биграммная модель языка,биграммная языковая модель
661,bijective function,وظيفة موضوعية,دالة ثنائية تصاعدية,دالة ثُنائية التَّرابُط,双射函数,双射函数,双射函数,fonction bijective,fonction bijective,fonction bijective,全単射関数,単射関数,全単射関数,биективная функция,биективная функция,биективная функция
662,bijective mapping,رسم الخرائط الموضوعية,التصوير الثنائي,تصوير ثنائي التربيع,双射映射,双射映射,一一对应映射,cartographie bijective,mapping bijectif,application bijective,全単射マッピング,"""最近、1-WLアルゴリズムの変種を提案し、サブストラクチャのカウントをWL集約手順に組み込むことで、元の1-WLテストより強力なアルゴリズムを生み出します。アルゴリズムを説明するためには、",全単射写像,биективное отображение,биективное отображение,взаимно-однозначное отображение
663,bilateral filtering,الترشيح الثنائي,التصفية الثنائية,ترشيح ثنائي,双边过滤,双边滤波,双边滤波,filtrage bilatéral,filtrage bilatéral,filtrage bilatéral,双方向フィルタリング,両側フィルタリング (りょうがわフィルタリング),両側フィルタリング,двусторонняя фильтрация,билатеральная фильтрация,двухстороннее фильтрование
664,bilinear,خطين,ثنائي الخطية,خُطي ثنائي,双线性,双线性,双线性,bilinéaire,bilinéaire,bilinéaire,双線形,2次関数,2次線形,билинейный,билинейный,билинейный
665,bilinear form,شكل ثنائي,الشكل ذو الدرجتين,صيغة ثنائية الخطية,双线性形式,双线性形式,双线性形式,forme bilinéaire,forme bilinéaire,forme bilinéaire,双一次形式,二次形式,二次形式,билинейная форма,билинейная форма,билинейная форма
666,bilinear interpolation,الاستيفاء الثنائي,التكبير الثنائي المتقطع,التحويل الخطي المزدوج,双线性插值,双线性插值,双线性插值,interpolation bilinéaire,interpolation bilinéaire,interpolation bilinéaire,双一次補間,バイリニア補間,双線形補間,билинейная интерполяция,билинейная интерполяция,билинейная интерполяция
667,bilinear model,نموذج ثنائي,نموذج ثنائي الخطية,نموذج ثنائي الخطي,双线性模型,双线性模型,双线性模型,modèle bilinéaire,modèle bilinéaire,modèle bilinéaire,双線形モデル,バイリニアモデル,双線形モデル,билинейная модель,билинейная модель,билинейная модель
668,bilingual model,نموذج ثنائي اللغة,النموذج ثنائي اللغة,نموذج ثنائي اللغة,双语模型,双语模型,双语模型,modèle bilingue,modèle bilingue,modèle bilingue,バイリンガルモデル,バイリンガルモデル (bilingual model),双言語モデル,двуязычная модель,двуязычная модель,двуязычная модель
669,binarization,الثنائية,تثنيم,ثنائية,二值化,二值化,二值化,binarisation,binarisation,binarisation,二値化,バイナリ化,二値化,бинаризация,бинаризация,бинаризация
670,binary atom,ذرة ثنائية,ذرة ثنائية,ذرّة ثنائيّة,二元原子,二元原子,二元原子,atome binaire,atome binaire,atome binaire,二元原子,バイナリ原子,二項関係,бинарный атом,бинарный атом,бинарный атом
671,binary classification,التصنيف الثنائي,تصنيف ثنائي,تصنيف ثنائي,二元分类,"""['我们训练DeBERTa模型以区分真实事实与负样本，基于二元分类损失，使用ComFact（高等，2022年）基准提出的超参数。'，'其中h是连续的且h（0）= 0。从二元分类的缩减中可以清楚地看出h必须增加才能使方程（13）中的损失保持一致。",二分类,classification binaire,classification binaire,classification binaire,二項分類,二値分類 (nibun bunrui),2値分類,бинарная классификация,бинарная классификация,бинарная классификация
672,binary classification head,رأس التصنيف الثنائي,رأس التصنيف الثنائي,رأس التصنيف الثنائي,二元分类头,二元分类头,二元分类头,chef de classification binaire,- Tête de classification binaire,tête de classification binaire,二項分類ヘッド,バイナリ分類ヘッド,バイナリ分類ヘッド,глава бинарной классификации,бинарный классификационный блок,Бинарная классификационная головка
673,binary classification problem,مشكلة التصنيف الثنائي,مشكلة تصنيف ثنائي,مشكلة التصنيف الثنائي,二元分类问题,二元分类问题,二分类问题,problème de classification binaire,problème de classification binaire,problème de classification binaire,二項分類問題,バイナリ分類問題 (bainari bunrui mondai),2値分類問題,проблема бинарной классификации,бинарная задача классификации,проблема бинарной классификации
674,binary classification task,مهمة التصنيف الثنائي,مهمة تصنيف ثنائي,مهمة تصنيف ثنائية,二元分类任务,二分类任务,二元分类任务,tâche de classification binaire,tâche de classification binaire,tâche de classification binaire,二項分類タスク,バイナリ分類タスク,2値分類タスク,задача двоичной классификации,бинарная классификационная задача,задача бинарной классификации
675,binary classifier,المصنف الثنائي,مصنف ثنائي,مُصنِّف ثُنائي,二元分类器,二元分类器 (binary classifier),二分类器,classificateur binaire,classifieur binaire,classificateur binaire,バイナリ分類子,バイナリ分類器,2値分類器,двоичный классификатор,бинарный классификатор,бинарный классификатор
676,binary constraint,القيد الثنائي,القيد الثنائي,قيد ثنائي,二元约束,二进制约束,二元约束,contrainte binaire,contrainte binaire,contrainte binaire,バイナリ制約,バイナリ制約,2値制約,двоичное ограничение,бинарное ограничение,двоичное ограничение
677,binary cross entropy,الإنتروبيا الثنائية المتقاطعة,التقليل الثنائي من الانحراف,التباين المتقاطع الثنائي,二元交叉熵,二元交叉熵,二元交叉熵,entropie croisée binaire,entropie croisée binaire,entropie croisée binaire,バイナリクロスエントロピー,バイナリークロスエントロピー,2値クロスエントロピー,двоичная перекрестная энтропия,бинарная кросс-энтропия,Бинарная кросс-энтропия
678,binary cross-entropy loss,فقدان الإنتروبيا الثنائية,"""تم ضبط نماذج المحول للتنبؤ بالتسمية المستهدفة (صحيح أو خاطئ) من خلال تحسين فقدان الإنتروبيا الثنائي على الأهداف باستخدام محسن آدم. بال",خسارة الانتروبيا الثنائية المتقاطعة,二元交叉熵损失,二进制交叉熵损失,二元交叉熵损失,perte d'entropie croisée binaire,perte d'entropie croisée binaire,perte d'entropie croisée binaire,バイナリクロスエントロピー損失,バイナリ交差エントロピーロス,バイナリクロスエントロピー損失,бинарная кросс-энтропийная потеря,бинарная потеря кросс-энтропии,двоичная кросс-энтропийная потеря
679,binary decision tree,شجرة القرار الثنائية,شجرة القرار الثنائية,شجرة القرار الثنائية,二元决策树,二叉决策树,二叉决策树,arbre de décision binaire,arbre de décision binaire,arbre de décision binaire,二分決定木,バイナリ決定木,2値決定木,двоичное дерево решений,бинарное дерево принятия решений,Двоичное дерево решений
680,binary feature,ميزة ثنائية,ميزة ثنائية,ميزة ثنائية,二进制特征,二进制特征,二值特征,fonctionnalité binaire,fonction binaire,caractéristique binaire,バイナリ機能,バイナリ特徴,2値特徴,двоичная функция,бинарная характеристика,бинарный признак
681,binary label,التسمية الثنائية,- التصنيف الثنائي,تصنيف ثنائي,二进制标签,二进制标签,二值标签,étiquette binaire,étiquette binaire,étiquette binaire,バイナリラベル,バイナリラベル,2値ラベル,двоичная метка,Бинарная метка,бинарная метка
682,binary matrix,مصفوفة ثنائية,مصفوفة ثنائية,مصفوفة ثنائية,二元矩阵,二进制矩阵,二进制矩阵,matrice binaire,- Matrice binaire,matrice binaire,バイナリ行列,バイナリ行列,2値行列,двоичная матрица,бинарная матрица,Бинарная матрица
683,binary predicate,المسند الثنائي,منطقي ثنائي,صفة ثنائية,二元谓词,二元谓词,二元谓词,prédicat binaire,prédicat binaire,prédicat binaire,バイナリ述語,"""['私たちは、領域要素iを用いて一項述語Pをインスタンス化した結果のグラウンドアトムを示すためにP（i）と書き、領域要素iとjを用いて2項述語Qをインスタンス化した結果のグラウンドアトムを示すためにQ（i、j）と書",二項述語,бинарный предикат,бинарный предикат,бинарный предикат
684,binary relation,العلاقة الثنائية,العلاقة الثنائية,علاقة ثنائية,二元关系,二元关系,二元关系,relation binaire,- Relation binaire,relation binaire,二項関係,二項関係,二項関係,бинарное отношение,бинарное отношение,бинарное отношение
685,binary search,بحث ثنائي,البحث الثنائي,بحث ثنائي,二分查找,- 二分搜索,二分查找,recherche binaire,recherche binaire,recherche binaire,二分探索,二分探索 (にぶんたんさく),二分探索,двоичный поиск,бинарный поиск,Двоичный поиск
686,binary segmentation,تجزئة ثنائية,- تقسيم ثنائي,تقسيم ثنائي,二元分割,二值分割,二值分割,segmentation binaire,segmentation binaire,segmentation binaire,バイナリセグメンテーション,二値セグメンテーション,2値分割,двоичная сегментация,бинарная сегментация,двоичная сегментация
687,binary tree,شجرة ثنائية,شجرة ثنائية,شجرة ثنائية,二叉树,二叉树,二叉树,arbre binaire,arbre binaire,arbre binaire,二分木,バイナリ木 (bainariki),二分木,двоичное дерево,бинарное дерево,двоичное дерево
688,binary variable,متغير ثنائي,متغير ثنائي,متغير ثنائي,二元变量,二元变量,二值变量,variable binaire,variable binaire,variable binaire,バイナリ変数,二値変数 (にちぞうへんすう),二値変数,двоичная переменная,Бинарная переменная,двоичная переменная
689,binary vector,ناقلات ثنائية,المتجه الثنائي,متجه ثنائي,二元向量,二进制向量,二进制向量,vecteur binaire,vecteur binaire,vecteur binaire,バイナリベクトル,バイナリーベクトル,バイナリベクトル,бинарный вектор,бинарный вектор,бинарный вектор
690,binomial distribution,توزيع ثنائي,التوزيع الثنائي,توزيع ثنائي,二项分布,二项分布,二项分布,distribution binomiale,- Distribution binomiale,distribution binomiale,二項分布,二項分布,二項分布,биномиальное распределение,биномиальное распределение,биноминальное распределение
691,bioinformatic,المعلوماتية الحيوية,"""مجموعة من المشاكل التي تهدف إلى تجميع مجموعة معينة من الكائنات بطريقة معنوية - قد يختلف ""المعنى"" بناءً على التطبيق. هذه مشاكل أساسية في علوم الحاسوب مع تط",علم المعلوماتية الحيوية,生物信息学,生物信息学,生物信息学,bioinformatique,bioinformatique,bioinformatique,バイオインフォマティック,バイオインフォマティクス (baioinfomatikusu),バイオインフォマティクス,биоинформатический,биоинформатика,биоинформатика
692,biological neural network,الشبكة العصبية البيولوجية,شبكة عصبية حيوية,شبكة عصبية بيولوجية,生物神经网络,生物神经网络,生物神经网络,réseau neuronal biologique,réseau neuronal biologique,réseau neuronal biologique,生物学的神経ネットワーク,生物ニューラルネットワーク (seibutsu nyūraru nettowāku),生物学的神経回路網,биологическая нейронная сеть,биологическая нейронная сеть,биологическая нейронная сеть
693,bipartite,ثنائي,ثنائي الأطراف,ثنائي الأطراف,两部分,二部图,二分,bipartite,bipartite,biparti,二部構成の,2部グラフ,二部グラフ,двусторонний,делящийся на две части (bipartite),двудольный
694,bipartite graph,رسم بياني ثنائي,الرسم الثنائي,رسم ثنائي,二分图,二部图,二分图,graphe biparti,graphe biparti,graphe biparti,二部グラフ,二部グラフ,二部グラフ,двудольный граф,двудольный граф,двудольный граф
695,bipartite matching,مطابقة ثنائية,"""['نقارن في الخوارزميات على وظائف أكثر واقعية تظهر في التطبيقات. يوضح الشكل 4 العوامل التقريبية التجريبية لأدنى تكلفة لشجرة تغطية للتركيب الجزئي, تطابق ثن",مُطابقة ثُنائيّة,二分匹配,二分图匹配,二分匹配,correspondance bipartite,Appariement biparti,couplage biparti,二部マッチング,二部マッチング,二部グラフマッチング,двустороннее сопоставление,Двудольное совпадение,двупартитное согласование
696,bipartite structure,هيكل ثنائي,الهيكل ثنائي الأطراف,بنية ثنائية,二分结构,双部分结构,二分结构,structure bipartite,- Structure bipartite,structure bipartite,二部構造,二部構造,二部構造,двухчастная структура,Двудольная структура,двудольная структура
697,birth-death process,عملية الولادة والوفاة,العملية الولادة-الوفاة,عملية الولادة والوفاة,生死过程,出生-死亡过程,出生-死亡过程,processus naissance-mort,- Processus de naissance et de mort,processus de naissance-mort,誕生から死亡までの過程,誕生-死亡プロセス,誕生死滅過程,процесс рождения-смерти,процесс рождения-смерти,процесс рождения-смерти
698,bisection method,طريقة التنصيف,طريقة القسمة إلى نصفين,طريقة التنصيف,二分法,二分法,二分法,méthode de bissection,méthode de la bisection,méthode de bissection,二等分法,二分法,二分法,метод деления пополам,метод бисекции,метод бисекции
699,bisimulation,المحاكاة الثنائية,التشابه المزدوج,محاكاة مزدوجة,互模拟,双模拟化,双模拟,bisimulation,bisimulation,bisimulation,バイシミュレーション,二重同型性,双行シミュレーション,бисимуляция,бисимуляция,биссимуляция
700,bitext,bittext,نص مزدوج اللغة,نصوص ثنائية اللغة,双文本,双语文本,双语平行语料,bitexte,"""['Nous avons extrait une grammaire à partir de 220 millions de mots de bitexte arabe-anglais en utilisant l'approche de Galley et al. (2006), en extrayant des règles avec au plus 3 non-terminaux. Ces règles sont hautement lexicalisées. Environ 300 000 règles sont applicables pour une phrase typique de 30 mots; nous filtrons le reste.', 'Nous présentons un modèle de traduction statistique basé sur des phrases hiér",corpus bilingue,バイテキスト,バイテキスト,対訳コーパス,битовый текст,битекст,параллельный текст
701,bitvector,bitvector,متجه البت,متجه البت,位向量,比特向量,位向量,vecteur de bits,vecteur de bits,vecteur de bits,ビットベクトル,ビットベクトル,ビットベクトル,битвектор,битовый вектор,биттор
702,black-box,صندوق اسود,- تعلبة سوداء,صندوق أسود,黑盒子,黑盒,黑箱,boîte noire,boîte noire,boîte noire,ブラックボックス,- 黒箱,ブラックボックス,черный ящик,черный ящик,черный ящик
703,black-box model,نموذج الصندوق الأسود,نموذج صندوق أسود,نموذج صندوق أسود,黑盒模型,黑盒模型,黑盒模型,modèle de boîte noire,modèle de boîte noire,modèle boîte noire,ブラックボックスモデル,ブラックボックスモデル,ブラックボックスモデル,модель черного ящика,Черный ящик,"модель ""черного ящика"""
704,block coordinate descent,نزول إحداثيات الكتلة,النزول التدريجي للإحداثيات الكتلية,هبوط الإحداثيات المُجزَّأ,块坐标下降,分块坐标下降,块坐标下降,descente de coordonnées de bloc,descente de coordonnées par bloc,descente par coordonnées par blocs,ブロック座標降下,ブロック座標降下 (block coordinate descent),ブロック座標降下法,координатный спуск блока,блочный метод координатного спуска,блочный координатный спуск
705,block matrix,مصفوفة الكتلة,مصفوفة كتلية,مصفوفة كتلية,块矩阵,分块矩阵,分块矩阵,matrice de blocs,matrice de blocs,matrice par blocs,ブロック行列,ブロック行列,ブロック行列,блочная матрица,блочная матрица,блочная матрица
706,block-diagonal matrix,مصفوفة كتلة قطرية,مصفوفة قطرية الكتل,مصفوفة قطرية مجزأة,块对角矩阵,分块对角矩阵,块对角矩阵,matrice bloc-diagonale,matrice diagonale par blocs,matrice bloc-diagonale,ブロック対角行列,ブロック対角行列,ブロック対角行列,блок-диагональная матрица,блочно-диагональная матрица,блочно-диагональная матрица
707,bloom filter,مرشح الزهرة,فلتر الازدهار,مرشح زهري,布隆过滤器,布隆过滤器,布隆过滤器 (Bloom filter),filtre de floraison,filtre de Bloom,filtre de Bloom,ブルームフィルター,ブルームフィルタ,ブルームフィルタ,фильтр Блума,фильтр Блума,фильтр Блума
708,blur kernel,طمس النواة,نواة التمويه,نواة التشويش,模糊内核,模糊核,模糊核,flou du noyau,noyau de flou,noyau de flou,ブラーカーネル,ブラー・カーネル,ぼけカーネル,размытие ядра,ядро размытия,ядро размытия
709,boolean formula,صيغة منطقية,صيغة بولية,صيغة منطقية,布尔公式,布尔公式,布尔公式,formule booléenne,formule booléenne,formule booléenne,ブール式,ブール式,ブール式,булева формула,Булева формула,булева формула
710,boolean function,وظيفة منطقية,وظيفة بولية,دالة منطقية,布尔函数,布尔函数,布尔函数,fonction booléenne,fonction booléenne,fonction booléenne,ブール関数,ブール関数 (ブーリアン関数),論理関数,логическая функция,булева функция,булева функция
711,boolean variable,متغير منطقي,متغير بولياني,متغير منطقي,布尔变量,布尔变量,布尔变量,variable booléenne,- Variable booléenne,variable booléenne,ブール変数,ブーリアン変数,真理値変数,логическая переменная,булева переменная,булева переменная
712,boost algorithm,خوارزمية تعزيز,- تعزيز الخوارزمية,خوارزمية التعزيز,增强算法,提升算法,提升算法,algorithme de boost,algorithme de renforcement,algorithme de renforcement,ブーストアルゴリズム,ブーストアルゴリズム,強化アルゴリズム,алгоритм повышения,алгоритм усиления,алгоритм наращивания
713,boost approach,نهج تعزيز,طريقة تعزيز,منهج التعزيز,升压方法,提升方法,提升法,approche de renforcement,approche de renforcement,approche de renforcement,ブーストアプローチ,ブーストアプローチ (buusuto apurōchi),勾配ブースト法,подход к ускорению,метод увеличения,повышающий подход
714,bootstrap learning,التعلم التمهيدي,تعلم الحذاء (Bootstrap Learning),تعلم البدئي (bootstrap learning),引导学习,引导学习,自助学习,apprentissage bootstrap,"""['OLLIE (Mausam et al., 2012) suit l'idée de l'apprentissage bootstrap des modèles basé sur les chemins d'analyse de dépendance.', ""L'algorithme de OLLIE est similaire à celui du WOE parse - les deux systèmes suivent la structure de base de l'apprentissage bootstrap des modèles basé sur les chemins d'analyse de dépendance. Cependant, il y a trois différences significatives. WOE utilise",apprentissage par bootstrap,ブートストラップ学習,ブートストラップ学習 (bootstrap learning),ブートストラップ学習,предварительное обучение,обучение методом бутстрэп,Обучение по прецедентам
715,bootstrap resampling,إعادة أخذ العينات التمهيدية,إعادة العينات الأساسية,إعادة أخذ العينات البوتسترابية,自举重采样,引导重抽样,自举重采样,rééchantillonnage bootstrap,rééchantillonnage bootstrap,rééchantillonnage par la méthode du bootstrap,ブートストラップリサンプリング,ブートストラップ再標本化,ブートストラップリサンプリング,бутстреп-ресэмплинг,Bootstrap-перетасовка,повторное выборочное тестирование
716,bootstrap sample,عينة التمهيد,عينة الاستقراءّ المرتدة,عينة استرجاعية,引导样本,"bootstrap sample
自助采样",自助法重采样,échantillon d'amorçage,échantillon bootstrap,échantillon bootstrap,ブートストラップサンプル,ブートストラップサンプル,ブートストラップサンプル,образец начальной загрузки,Bootstrap выборка,выборка с возвращением
717,bottleneck,عنق الزجاجة,الزجاجة الرقبة,اختناق,瓶颈,瓶颈,瓶颈,goulot,goulot d'étranglement,goulot d'étranglement,ボトルネック,ボトルネック,ボトルネック,горлышко бутылки,узкое место,узкое место
718,bottleneck layer,طبقة عنق الزجاجة,- التبويب الضيق,طبقة الاختناق,瓶颈层,瓶颈层,瓶颈层,couche de goulot d'étranglement,couche d'étranglement,couche de goulot d'étranglement,ボトルネック層,ボトルネック層,ボトルネックレイヤー,узкий слой,Узкое место,слой сжатия
719,bottom-up,تصاعدي,الأسفل إلى الأعلى,من أسفل إلى أعلى,自下而上,自底向上,自底向上,de bas en haut,de bas en haut,ascendante,ボトムアップ,ボトムアップ,下位から上への,вверх дном,снизу вверх,снизу вверх
720,bottom-up learning,التعلم من أسفل إلى أعلى,التعلم من الأسفل إلى الأعلى,التعلم من الأسفل إلى الأعلى,自下而上的学习,自底向上学习,自底向上学习,apprentissage ascendant,apprentissage ascendant,apprentissage ascendant,ボトムアップ学習,ボトムアップ学習,下位から上への学習,обучение снизу вверх,"обучение ""снизу вверх""",обучение снизу вверх
721,bottom-up module,وحدة من أسفل إلى أعلى,وحدة من الأسفل إلى الأعلى,وحدة من أسفل إلى أعلى,自下而上的模块,自底向上模块,自底向上模块,module ascendant,- Module ascendant,module ascendant,ボトムアップモジュール,ボトムアップモジュール,下位モジュール,восходящий модуль,модуль снизу вверх,Модуль снизу вверх
722,bottom-up parsing,تحليل من أسفل إلى أعلى,تحليل من الأسفل إلى الأعلى,تحليل من الأسفل إلى الأعلى,自底向上解析,自底向上解析,自底向上解析,analyse ascendante,analyse ascendante,analyse ascendante,ボトムアップ解析,ボトムアップ構文解析,下位から解析する,восходящий синтаксический анализ,синтаксический анализ снизу вверх,восходящий синтаксический анализ
723,bound box,صندوق منضم,صندوق محدود,مربع محيط,装订盒,边界框,边界框,boîte reliée,boîte englobante,boîte englobante,バインドされたボックス,バウンディングボックス,境界ボックス,связанная коробка,граничная рамка,ограничивающий прямоугольник
724,bound rationality,العقلانية المقيدة,العقلانية المقيدة,العقلانية المحدودة,有限理性,有界理性,有限理性,rationalité liée,rationalité limitée,rationalité limitée,束縛された合理性,有界合理性,限定合理性,связанная рациональность,ограниченная рациональность,ограниченная рациональность
725,bound variable,متغير منضم,متغير مقيد,متغير مقيد,绑定变量,绑定变量,绑定变量,variable liée,- Variable lié,variable liée,バインドされた変数,束縛変数,束縛変数,связанная переменная,связанные переменные,cвязанная переменная
726,bounding box detection,كشف المربع المحيط,كشف مربع الحدود,كشف المربع المحيط,边界框检测,边界框检测,边界框检测,détection du cadre de délimitation,détection de boîte englobante,détection de boîte englobante,境界ボックスの検出,バウンディングボックス検出,バウンディングボックス検出,обнаружение ограничивающей рамки,обнаружение ограничивающего прямоугольника,граничная рамка обнаружения
727,bounding box regression,انحدار المربع المحيط,تصحيح مربع التحديد,تراجع مربع الحدود,边界框回归,边界框回归,边界框回归,régression de la boîte englobante,régression de la boîte englobante,régression de boîte englobante,境界ボックス回帰,境界ボックス回帰 (bounding box regression),境界ボックス回帰,регрессия ограничивающей рамки,регрессия ограничивающих рамок,регрессия ограничивающего прямоугольника
728,bounding box regressor,رجعي المربع المحيط,مُرتبط بتصحيح مربع الحدود,رجريسور مربع الحدود,边界框回归器,边界框回归器,边界框回归器,régresseur de boîte englobante,régresseur de boîte englobante,régression de boîte englobante,境界ボックスリグレッサー,バウンディングボックス回帰器,バウンディングボックスレグレッサー,регрессор ограничительной рамки,регрессор ограничивающей рамки,ограничивающий ящик регрессор
729,branch and bind algorithm,خوارزمية فرعية ومنضمة,خوارزمية الفروع والربط,خوارزمية التفرع والحد,分支定界算法,分支绑定算法,分支定界算法,algorithme de branchement et de liaison,algorithme de branchement et de liaison,algorithme d'énumération et d'évaluation,分岐限定アルゴリズム,枝刈り探索アルゴリズム (edakari tansaku arugorizumu),分岐限定法,алгоритм ветвей и границ,алгоритм ветвления и ограничения,алгоритм ветвей и границ
730,branch factor,عامل الفرع,عامل التفرع,نسبة التشعب,分支因子,分支因子,分支因子,facteur de branchement,facteur de branchement,facteur de branchement,分岐係数,分岐因子,分岐係数,отраслевой фактор,- Ветвлённость,ветвящийся фактор
731,breadth-first order,اتساع النظام الأول,الترتيب أولا بالعرض,ترتيب البحث العرضي,广度优先顺序,广度优先顺序,广度优先顺序,ordre en largeur d'abord,ordre en largeur d'abord,ordre de parcours en largeur,幅優先順,幅優先順序 (habu yūsen junjo),幅優先順序,порядок в ширину,порядок в ширину,порядок обхода в ширину
732,breadth-first search,اتساع البحث الأول,البحث أولاً في العرض,البحث حسب العرض,广度优先搜索,广度优先搜索,广度优先搜索,recherche en largeur,recherche en largeur,parcours en largeur,幅優先検索,幅優先探索,幅優先探索,поиск в ширину,поиск в ширину,поиск в ширину
733,bregman divergence,اختلاف بريجمان,تباين بريجمان,تباين بريجمان,布雷格曼散度,Bregman散度,勃雷格曼散度,divergence de Bregman,divergence de Bregman,divergence de Bregman,ブレグマンダイバージェンス,ブレグマン・ダイバージェンス,ブレグマン発散,дивергенция Брегмана,дивергенция Брегмана,Расхождение Брегмана
734,brute force search,بحث القوة الغاشمة,البحث بالقوة الغاشمة,بحث عشوائي,暴力搜索,暴力搜索,蛮力搜索,recherche par force brute,recherche par force brute,recherche par force brute,ブルートフォース検索,総当たり検索,全探索,поиск методом грубой силы,грубый поиск перебором,переборный поиск
735,bundle adjustment,تعديل الحزمة,ضبط البنية,ضبط الحزمة,捆绑调整,捆绑调整,捆绑调整,ajustement du paquet,ajustement de paquetage,ajustement de faisceau,バンドル調整,バンドル調整,バンドル調整,корректировка пакета,пакетная коррекция,уравнивание связок
736,burn-in,حرق في,"""['في حالة إعادة زيارة مستند في نموذج موضوع. بعد الاحتراق، من المرجح أن يكون تعيين الموضوع السابق لكلمة معينة لا يزال ذا صلة للتمريرة العينية الحالية.', 'في كل مرح",فترة التجنيب,老化,燃烧期,预热,brûlure,brûlage,rodage,焼き付き,バーンイン,燻製,записать в,"""['в случае повторного посещения документа в модели тем. После прогрева предыдущее назначение темы для данного слова вероятно все еще соответствует текущему проходу выборки.', 'На каждой фазе мы выбираем для 5000 итераций, отбрасывая первые 2000 для прогрева, и собираем выб",приработка
737,byte-pair encoding,ترميز زوج البايت,"""لنظم الترجمة الآلية ، نستخدم بدلاً من ذلك مفردات تصل إلى 5 آلاف رمز مستندة إلى ترميز الأزواج بايت المشترك (BPE؛ Sennrich et al.، 2015) المتعلم باستخدام م",ترميز الأزواج البايتية (BPE),字节对编码,字节对编码,字节对编码 (BPE),codage par paire d'octets,encodage de paires d'octets,encodage par paires d'octets (BPE),バイトペアエンコーディング,バイトペアエンコーディング,バイト対エンコーディング (BPE),кодирование пары байтов,кодирование пар байтов,Парное кодирование байтов
738,calculus of variation,حساب التباين,حساب التغيير,حساب التفاضل والتكامل,变分法,变分法,变分学,calcul de variation,calcul des variations,calcul des variations,変分法,変分法 (へんぶんほう),変分法,вариационное исчисление,калькулюс вариаций,вариационное исчисление
739,calibration,معايرة,المعايرة,معايرة,校准,校准 (calibration),校准,étalonnage,étalonnage,étalonnage,較正,較正 (Kakusei),校正,калибровка,калибровка,калибровка
740,calibration method,طريقة المعايرة,طريقة المعايرة,طريقة المعايرة,校准方法,校准方法 (calibration method),校准方法,méthode d'étalonnage,méthode de calibration,méthode d'étalonnage,校正方法,較正方法 (Kakusei hōhō),校正方法,метод калибровки,метод калибровки,метод калибровки
741,caltech-101,معهد كاليفورنيا للتكنولوجيا-101,- تقنية كالتك-101,كالتك-101,加州理工学院-101,加州理工学院101数据集,加州理工学院-101,caltech-101,Caltech-101,Caltech-101,カルテック-101,カルテック101,カルテック101,Калтех-101,Калтех-101,Калтех-101
742,camera calibration,معايرة الكاميرا,معايرة الكاميرا,معايرة الكاميرا,相机标定,摄像机校准,相机标定,calibrage de la caméra,étalonnage de la caméra,étalonnage de la caméra,カメラのキャリブレーション,カメラキャリブレーション (kamera karibureshon),カメラキャリブレーション,калибровка камеры,калибровка камеры,калибровка камеры
743,camera intrinsic,الكاميرا جوهرية,داخليات الكاميرا,ثوابت الكاميرا الداخلية,相机内在,相机内参,相机内参,caméra intrinsèque,intrinsèque de la caméra,paramètres intrinsèques de la caméra,カメラ固有の,カメラ固有,カメラ内部パラメータ,встроенная камера,- Камера внутренняя,камерные внутренние параметры
744,camera matrix,مصفوفة الكاميرا,مصفوفة الكاميرا,مصفوفة الكاميرا,相机矩阵,相机矩阵,相机矩阵,matrice de caméra,matrice de caméra,matrice de caméra,カメラマトリックス,カメラ行列 (kamera gyōretsu),カメラ行列,матрица камеры,матрицы камер,матрица камеры
745,camera parameter,معلمة الكاميرا,معلمات الكاميرا,معامل الكاميرا,相机参数,相机参数,相机参数,paramètre de la caméra,paramètre de la caméra,paramètres de la caméra,カメラパラメータ,カメラパラメータ,カメラパラメータ,параметр камеры,параметр камеры,параметры камеры
746,camera pose estimation,تقدير وضعية الكاميرا,تقدير وضع الكاميرا,تقدير وضع الكاميرا,相机姿态估计,相机姿态估计,相机姿态估计,estimation de la pose de la caméra,estimation de la pose de la caméra,estimation de la pose de la caméra,カメラの姿勢推定,カメラポーズ推定,カメラ姿勢推定,оценка позы камеры,оценка положения камеры,оценка позиции камеры
747,candidate generation,جيل المرشحين,إنتاج المرشحين,توليد المرشحين,候选人一代,候选生成,候选生成,génération de candidats,génération de candidats,génération de candidats,候補者の世代,候補生成,候補生成,поколение кандидатов,генерация кандидатов,генерация кандидатов
748,candidate set,مجموعة المرشح,مجموعة المرشحين,مجموعة المرشحين,候选集,候选集,候选集,ensemble de candidats,ensemble de candidats,ensemble de candidats,候補セット,候補セット (Kouho setto),候補セット,набор кандидатов,кандидатский набор,множество кандидатов
749,canny detector,كاشف حاذق,محدد كاني,كاشف كاني,精明探测器,坎尼检测器,卡尼边缘检测器,détecteur astucieux,détecteur de Canny,détecteur de Canny,賢い探知機,キャニー検出器 (Kyanī kenshutsuki),キャニー検出器,детектор канни,кенни детектор,Каннийский детектор
750,canny edge detector,كاشف الحافة الحاذق,مكتشف حواف كاني,كاشف حافات كاني,精明的边缘检测器,Canny边缘检测器,凯尼边缘检测器,détecteur de bord astucieux,détecteur de bordure canny,détecteur de contours Canny,鋭いエッジ検出器,キャニーエッジ検出器,エッジ検出器,детектор края канни,умный детектор края,детектор границ Кэнни
751,canonical basis,الأساس الكنسي,قاعدة كانونية,القاعدة القانونية,规范基础,规范基底,标准基,base canonique,base canonique,base canonique,正規の基礎,正準基底,標準基底,каноническая основа,каноническая база,канонический базис
752,canonical correlation analysis,تحليل الارتباط الكنسي,تحليل الارتباط الكنسي,تحليل الارتباط القانوني,典型相关分析,典范相关分析,正则相关分析,analyse de corrélation canonique,- Analyse de corrélation canonique,analyse de corrélation canonique,正準相関分析,正準相関分析 (canonical correlation analysis),正準相関分析,канонический корреляционный анализ,канонический корреляционный анализ,канонический корреляционный анализ
753,canonical form,الشكل الكنسي,الشكل الكانوني,الشكل القانوني,规范形式,规范形式,标准形式,Forme canonique,forme canonique,forme canonique,正規形,"""['現在のノード n ∈ N に対して。その後、{p c } c∈Q の積混合 p × (n, a; β) (式(2)) も、標準形の指数関数族のメンバーです：\n p × ( n , a ; β ) = exp [ β • T ( n , a ) − A ( n , β ) + B ( n , a ) ] , ここで T (",標準形式,каноническая форма,каноническая форма,каноническая форма
754,canonical frame,الإطار الكنسي,الإطار الكنوني,إطار القانوني,规范框架,规范帧,规范框架,cadre canonique,cadre canonique,repère canonique,正規フレーム,標準フレーム,正準フレーム,канонический кадр,каноническая рамка,канонической системы координат
755,canonical space,الفضاء الكنسي,المساحة الكانونية,الحيز القياسي,规范空间,标准空间,标准空间,espace canonique,espace canonique,espace canonique,正準空間,カノニカル空間,正規空間,каноническое пространство,каноническое пространство,каноническое пространство
756,canonicalization,تحديد العنوان القانوني,- التنميط القياسي,تقنين,规范化,规范化,规范化,canonisation,canonicalisation,canonicalisation,正規化,正準化,正準化,канонизация,канонизация,канонизация
757,capsule network,شبكة الكبسولة,شبكة الكبسولة,شبكة كبسولة,胶囊网络,胶囊网络,胶囊网络,réseau de capsules,réseau de capsules,réseau de capsules,カプセルネットワーク,カプセルネットワーク,カプセルネットワーク,капсульная сеть,сеть капсул,капсульная сеть
758,cardinality,عدد العناصر في المجموعة,عددية,عدد,基数,基数,基数,cardinalité,- Cardinalité,cardinalité,カーディナリティ,基数,基数,мощность,кардинальность,мощность
759,cardinality constraint,القيد الكاردينال,القيد الطيفي,قيد التعداد,基数约束,基数约束,基数约束,contrainte de cardinalité,- Contrainte de cardinalité,contrainte de cardinalité,カーディナリティ制約,基数制約,基数制約,ограничение мощности,ограничение на мощность,ограничение кардинальности
760,cascade model,نموذج تتالي,- موديل التسلسل المتسلسل,نموذج متدرج,级联模型,级联模型,级联模型,modèle en cascade,- Modèle en cascade,modèle en cascade,カスケードモデル,カスケードモデル,連鎖モデル,каскадная модель,модель каскада,каскадная модель
761,catastrophic forgetting,النسيان الكارثي,النسيان الكارثي,الفقدان الكارثي,灾难性遗忘,灾难性遗忘,灾难性遗忘,oubli catastrophique,oubli catastrophique,oubli catastrophique,壊滅的な忘却,重大な忘却,破壊的忘却,катастрофическое забвение,катастрофическое забывание,катастрофическое забывание
762,categorial grammar,القواعد الفئوية,قواعدية النحو,قواعد الفئات,范畴语法,范畴语法,范畴语法,grammaire catégorielle,grammaire catégorielle,grammaire catégorielle,カテゴリ文法,カテゴリー文法,範疇文法,категориальная грамматика,категориальная грамматика,категориальная грамматика
763,categorical cross-entropy,الانتروبيا القاطعة,الانحدار الصليبي الفئوي,الخسارة الترميزية المتقاطعة,分类交叉熵,分类交叉熵,类别交叉熵,entropie croisée catégorielle,- Entropie croisée catégorielle,entropie croisée catégorique,カテゴリカルクロスエントロピー,カテゴリカル交差エントロピー,カテゴリカル交差エントロピー,категориальная кросс-энтропия,категориальная кросс-энтропия,перекрёстная энтропия категорий
764,categorical distribution,التوزيع القاطع,التوزيع القاطع,توزيع فئوي,分类分布,分类分布,类别分布,répartition catégorielle,- Distribution catégorielle,distribution catégorique,カテゴリ分布,カテゴリカル分布,カテゴリ分布,категориальное распределение,категориальное распределение,категориальное распределение
765,categorical feature,الميزة الفئوية,ميزة تصنيفية,ميزة فئوية,分类特征,分类特征,类别特征,caractéristique catégorielle,caractéristique catégorielle,caractéristique catégorielle,カテゴリ特徴,"""['多様性に関しては、広く採用されている指標は、対照的な例の間のペアワイズ距離であり、距離は数値的およびカテゴリ的特徴に対して別々に定義されています[33,40]。このアプローチは、カテゴリ特徴を解",カテゴリ変数,категориальная особенность,категориальный признак,категориальный признак
766,causal effect,تأثير سببي,التأثير السببي,تأثير سببي,因果效应,因果效应 (cāusāo xiàoyì),因果效应,effet causal,Effet causal,effet causal,因果関係,因果効果,因果効果,причинный эффект,причинный эффект,влияние причинности
767,causal effect estimation,تقدير التأثير السببي,تقدير التأثير السببي,تقدير التأثير السببي,因果效应估计,因果效应估计,因果效应估计,estimation de l'effet causal,estimation de l'effet causal,estimation des effets causaux,因果関係の推定,因果効果推定,因果効果推定,оценка причинно-следственной связи,оценка причинно-следственного эффекта,оценка причинного эффекта
768,causal entropy,الانتروبيا السببية,الانحراف السببي,طاقة السببية,因果熵,因果熵,因果熵,entropie causale,entropie causale,entropie causale,因果エントロピー,因果エントロピー,因果エントロピー,причинная энтропия,причинная энтропия,причинная энтропия
769,causal graph,الرسم البياني السببي,رسم توضيحي سببي,رسم السببية,因果图,因果图,因果图,graphique causal,graphe causal,graphe causal,因果関係グラフ,因果グラフ (Inga Gurafu),因果グラフ,причинно-следственный график,причинно-следственный граф,причинный граф
770,causal inference,الاستدلال السببي,استنتاج السببية,الاستدلال السببي,因果推理,因果推断 (Causal Inference),因果推理,inférence causale,inférence causale,inférence causale,因果推論,因果推論,因果推論,причинный вывод,причинное заключение,причинно-следственный вывод
771,causal intervention,التدخل السببي,تدخل سببي,تدخل سببي,因果干预,因果干预,因果干预,intervention causale,intervention causale,intervention causale,因果関係のある介入,因果干渉 (inga kanshō),因果介入,причинное вмешательство,причинное вмешательство,причинное вмешательство
772,causal language model,نموذج اللغة السببية,نموذج لغة سببية,نموذج لغوي سببي,因果语言模型,因果语言模型,因果语言模型,modèle de langage causal,- Modèle de langage causal,modèle de langage causal,因果言語モデル,因果言語モデル (inga gengo moderu),因果言語モデル,причинно-языковая модель,модель причинно-следственного языка,Каузальная языковая модель
773,causal model,النموذج السببي,نموذج السببية,نموذج سببي,因果模型,因果模型,因果模型,modèle causal,modèle causal,modèle causal,因果モデル,因果モデル (inga moderu),因果モデル,причинно-следственная модель,причинная модель,причинная модель
774,causal reasoning,المنطق السببي,الاستدلال السببي,الاستدلال السببي,因果推理,因果推理,因果推理,raisonnement causal,raisonnement causal,raisonnement causal,因果推論,因果推論,因果推論,причинное рассуждение,причинное рассуждение,казуальное рассуждение
775,causal rule,القاعدة السببية,قاعدة سببية,قاعدة سببية,因果规则,因果规则 (cāiguō guīzé),因果规则,règle causale,règle causale,règle causale,因果律,因果的なルール,因果則,причинное правило,причинное правило,причинное правило
776,causal theory,النظرية السببية,نظرية السببية,نظرية السببية,因果论,因果理论 (Yīnguǒ lǐlùn),因果理论,théorie causale,théorie causale,théorie causale,因果理論,因果理論 (ingari riron),因果理論,причинная теория,теория причинности,причинная теория
777,cell state,حالة الخلية,حالة الخلية,حالة الخلية,细胞状态,细胞状态,细胞状态,état de la cellule,état de la cellule,état cellulaire,セルの状態,セル状態,セル状態,состояние клетки,Состояние клетки,состояние ячейки
778,center crop,مركز المحاصيل,التقطيع المركزي,قص مركزي,中心作物,中心裁剪,中心裁剪,culture centrale,recadrage au centre,culture centrée,センタークロップ,中央クロップ,中央切り抜き,центр урожая,центральный кадр,центральный кроп
779,center of projection,مركز الإسقاط,مركز الإسقاط,مركز الإسقاط,投影中心,投影中心,投影中心,centre de projection,centre de projection,centre de projection,投影の中心,射影の中心,射影中心,центр проекции,точка проекции,центр проекции
780,centrality measure,قياس المركزية,قياس الوسطية,مقياس المركزية,中心性测度,中心度测量,中心性度量,mesure de centralité,mesure de centralité,mesure de centralité,中心性の尺度,中心性尺度,中心性指標,мера центральности,мера центральности,мера центральности
781,centroid,النقطه الوسطى,مركز الثقل,مُركز الكُتلة,质心,重心,质心,centroïde,centroïde,barycentre,重心,重心 (juushin),重心,центроид,центроид,центроид
782,chain rule,قاعدة السلسلة,قاعدة السلسلة,قاعدة السلسلة,链式法则,链式法则,链式法则,règle de la chaîne,règle de chaîne,règle de dérivation en chaîne,連鎖法則,チェーンルール (Chēn rūru),連鎖法則,Правило цепи,правило цепи,правило цепочки
783,change of basis,تغيير الأساس,- تغيير قاعدة,تغيير القاعدة,基础的改变,基础变换,基底变换,changement de base,changement de base,changement de base,根拠の変更,基底の変換,基底変換,изменение основы,- Изменение базиса,Смена базиса
784,character embedding,تضمين الأحرف,تضمين الشخصيات,تضمين الحرف,字符嵌入,字符嵌入,字符嵌入,intégration de personnages,intégration de caractères,Plongement de caractères,文字の埋め込み,文字の埋め込み,文字埋め込み,встраивание символов,векторное представление символов,вложение символов
785,character n-gram,حرف ن غرام,نغرامات الأحرف,نجرام الحرفي,字符 n 元语法,字符n-gram,字符n元组,personnage n-gramme,caractère n-gramme,n-gramme de caractères,文字Nグラム,文字 n-グラム,文字n-gram,символ n-грамма,символьные n-граммы,символьные н-граммы
786,characteristic function,وظيفة مميزة,دالة مميزة,دالة مميزة,特征函数,特征函数,特征函数,fonction caractéristique,fonction caractéristique,fonction caractéristique,特徴的な機能,特性関数 (tokusei kansu),特性関数,характеристическая функция,характеристическая функция,характеристическая функция
787,characteristic polynomial,كثير الحدود مميزة,معادلة خاصة,معادلة مميزة,特征多项式,特征多项式,特征多项式,polynôme caractéristique,polynôme caractéristique,polynôme caractéristique,特性多項式,特性多項式,固有多項式,характеристический полином,характеристический многочлен,характеристический многочлен
788,characteristic vector,ناقلات مميزة,متجه الخصائص,متجه المميز,特征向量,特征向量,特征向量,vecteur caractéristique,vecteur caractéristique,vecteur caractéristique,固有ベクトル,特徴ベクトル (Tokuchō Bekutoru),特性ベクトル,характеристический вектор,характеристический вектор,характеристический вектор
789,chart parser,محلل الرسم البياني,محلل الرسم البياني,محلل الرسم البياني,图表解析器,图表分析器,图表分析器,analyseur de graphiques,"""['Cela malgré le fait que les deux systèmes peuvent rejeter les décisions d'attachement spéculatives. Dans le cas de l'analyseur de tableau avec des représentations composées de probabilités d'étiquettes pour chaque étendue, l'ajout d'un mot supplémentaire peut provoquer un changement vers une nouvelle analyse via la procédure de décodage CKY.', 'Les 30 adjectifs variaient en fréquence dans le BNC de 1,9 à",analyseur de graphe,チャートパーサー,チャートパーサー,チャートパーサー,парсер диаграмм,парсер диаграмм,синтаксический анализатор на основе диаграмм
790,chart parsing,تحليل الرسم البياني,تحليل الرسم البياني,تحليل الرسم البياني,图表解析,图表解析,图表解析,analyse de graphiques,analyse syntaxique en tableau,analyse syntaxique de diagramme,チャートの解析,チャート解析,チャート解析,анализ диаграммы,разбор графика,синтаксический разбор графа
791,chatbot,chatbot,- تشات بوت,محادثة آلية,聊天机器人,聊天机器人,聊天机器人,chatbot,chatbot,agent conversationnel,チャットボット,チャットボット (chatbot),チャットボット,чат-бот,чат-бот,чат-бот
792,checkpoint,نقطة تفتيش,نقطة فحص,نقطة التفتيش,检查站,检查点,检查点,point de contrôle,point de contrôle,point de contrôle,チェックポイント,チェックポイント,チェックポイント,контрольно-пропускной пункт,контрольная точка,контрольная точка
793,chemoinformatic,معلومات كيميائية,الكيمومعلوماتية,كيميائي المعلوماتية,化学信息学,化学信息学,化学信息学,chimioinformatique,chimioinformatique,chémoinformatique,ケモインフォマティック,化学情報学,化学情報学,хемоинформатический,хемоинформатика,хемоинформатический
794,chernoff bind,ربط تشيرنوف,- التقييد شيرنوف,حد شيرنوف,切尔诺夫绑定,切诺夫界 (Chernoff bound),切尔诺夫边界,liaison chernoff,borne de Chernoff,borne de Chernoff,チェルノフ・バインド,チェルノフ境界,チェルノフの束縛,Чернов Бинд,граница Чернова,оценка Чернова
795,chi-square distribution,توزيع مربع كاي,توزيع كاي مربع,توزيع كاي مربع,卡方分布,卡方分布,卡方分布,distribution du chi carré,- Distribution du chi carré,distribution du chi carré,カイ二乗分布,カイ二乗分布,カイ二乗分布,распределение хи-квадрат,распределение хи-квадрат,распределение хи-квадрат
796,chi-square test,اختبار مربع كاي,اختبار الكاي المربع,اختبار كاي تربيع,卡方检验,卡方检验,卡方检验,test du chi carré,test du chi-deux,test du chi carré,カイ二乗検定,カイ二乗検定 (Kai-nijou kentei),カイ二乗検定,тест хи-квадрат,Хи-квадрат тест,критерий хи-квадрат
797,child node,عقدة الطفل,العقدة الفرعية,عقدة فرعية,子节点,子节点,子节点,nœud enfant,nœud enfant,nœud enfant,子ノード,子ノード (Ko Nōdo),子ノード,дочерний узел,дочерний узел,дочерний узел
798,cholesky decomposition,التحلل الكولي,تصنيع تحليلي لجوليسكي,تحلل تشولسكي,胆囊分解,Cholesky分解,乔里斯基分解,décomposition cholesky,décomposition de Cholesky,décomposition de Cholesky,コレスキー分解,コレスキー分解,コレスキー分解,холецкий разложение,разложение Холецкого,разложение Холецкого
799,cholesky factor,العامل الكوليسكي,عامل شوليسكي,عامل شوليسكي,胆汁性因子,Cholesky分解因子,乔列斯基因子,facteur cholesky,facteur de Cholesky,facteur de Cholesky,コレスキー因子,コレスキー因子,コレスキー因子,холецкий фактор,фактор Холецкого,Холесский множитель
800,cholesky factorization,التخصيم الكوليسكي,عاملة تصنيف شوليسكي,التجزئة المثلثية الكولسكية,乔列斯基分解,乔列斯基分解,cholesky分解,factorisation cholesky,factorisation de Cholesky,factorisation de Cholesky,コレスキー因数分解,コレスキー分解 (cholesky factorization),コレスキー分解,факторизация Холецкого,факторизация Холецкого,Разложение Холецкого
801,chromosome,كروموسوم,"""على الرغم من أن خوارزمية الأساسية تم بناؤها باستخدام أفكار وآليات بسيطة، يمكن أن تكون تنفيذها معقدة للغاية. هناك وفرة كبيرة من التعديلات الممكنة على الخوارزمية الجين",صبغي,染色体,染色体 (Chromosome),染色体,chromosome,chromosome,chromosome,染色体,染色体,染色体,хромосома,хромосома,хромосома
802,chunk size,حجم قطعة,حجم القطعة,حجم الشريحة,块大小,分块大小,块大小,taille du morceau,- Taille du morceau,taille de bloc,チャンクサイズ,チャンクサイズ,チャンクサイズ,размер куска,"""['Прежде чем сравнивать пространства, полученные с различными индексами, мы должны установить параметры, необходимые для разделенных индексов EF, а именно размер блока для равномерного EF и параметры приближения 1, 2 для EF -оптимального.', 'В случае потоковой передачи речевой кодер может получить доступ к речевым данным",размер фрагмента
803,citation network,شبكة الاقتباس,شبكة الاقتباسات,شبكة الاقتباس,引文网络,引文网络,引文网络,réseau de citations,- Réseau de citation,réseau de citations,引用ネットワーク,引用ネットワーク,引用ネットワーク,сеть цитирования,сеть цитирования,сеть цитирования
804,class,فصل,- تصنيف,فئة,班级,类别,类别,classe,classe,classe,クラス,クラス (Class),クラス,сорт,класс,класс
805,class balance,التوازن الطبقي,توازن الصنف,توازن الفئات,班级平衡,类平衡,类别平衡,équilibre des classes,- Équilibre de classe,équilibre des classes,クラスバランス,クラスバランス (Kurasu Baransu),クラスバランス,баланс классов,баланс классов,Сбалансированность классов
806,class distribution,توزيع الطبقة,توزيع الفئات,توزيع الفئات,班级分布,类别分布,类别分布,répartition des classes,distribution des classes,distribution des classes,クラスの分布,クラス分布 (Class Distribution),クラス分布,распределение классов,распределение классов,распределение классов
807,class imbalance,عدم التوازن الطبقي,- التفاوت الطبقي,عدم التوازن الصنفي,阶级不平衡,类别不平衡,类别不平衡,déséquilibre de classe,déséquilibre de classe,déséquilibre de classe,階級の不均衡,クラスの不均衡 (Classの不均衡),クラスの不均衡,классовый дисбаланс,дисбаланс классов,несбалансированность классов
808,class label,تسمية الطبقة,تصنيف الصف,تصنيف الفئة,类别标签,类标签,类别标签,étiquette de classe,étiquette de classe,étiquette de classe,クラスラベル,クラスラベル (class label),クラスラベル,метка класса,метка класса,метка класса
809,class prior,الصف السابق,الأولوية الصنفية,احتمال سابق للفئة,课前,类先验,类先验,cours avant,prior de classe,probabilité a priori de classe,前のクラス,クラス事前確率 (class prior),クラス事前確率,предыдущий класс,классовый априори,априорная вероятность класса
810,classical planning,التخطيط الكلاسيكي,التخطيط الكلاسيكي,التخطيط الكلاسيكي,经典规划,经典规划,经典规划,planification classique,planification classique,planification classique,古典的な計画,クラシカルプランニング,古典的計画,классическое планирование,классическое планирование,классическое планирование
811,classification,تصنيف,التصنيف,تصنيف,分类,分类 (classification),分类,classification,classification,classification,分類,分類,分類,классификация,классификация,классификация
812,classification accuracy,دقة التصنيف,دقة التصنيف,دقة التصنيف,分类准确率,分类准确度,分类准确率,précision de la classification,précision de classification,précision de classification,分類精度,分類精度,分類精度,точность классификации,точность классификации,точность классификации
813,classification algorithm,خوارزمية التصنيف,خوارزمية التصنيف,خوارزمية التصنيف,分类算法,分类算法,分类算法,algorithme de classification,algorithme de classification,algorithme de classification,分類アルゴリズム,分類アルゴリズム (Bunrui arugorizumu),分類アルゴリズム,алгоритм классификации,алгоритм классификации,алгоритм классификации
814,classification approach,نهج التصنيف,النهج التصنيفي,نَهْجُ التَّصْنِيفِ,分类法,分类方法,分类方法,approche de classification,approche de classification,approche de classification,分類アプローチ,分類アプローチ (Bunrui apurōchi),分類アプローチ,классификационный подход,метод классификации,Подход к классификации
815,classification error,خطأ في التصنيف,خطأ التصنيف,خطأ التصنيف,分类错误,分类错误,分类错误率,erreur de classement,erreur de classification,erreur de classification,分類エラー,分類エラー,分類誤差,ошибка классификации,ошибка классификации,ошибка классификации
816,classification head,رئيس التصنيف,رأس التصنيف,رأس التصنيف,分类头,分类头,分类头,chef de classement,tête de classification,tête de classification,分類責任者,- 分類ヘッド,分類ヘッド,руководитель классификации,голова классификации,классификационная головка
817,classification loss,فقدان التصنيف,- تصنيف الخسارة,خسارة التصنيف,分类损失,分类损失,分类损失,perte de classification,perte de classification,perte de classification,分類損失,分類損失 (ぶんるいそんしつ),分類損失,потеря классификации,потеря классификации,потеря классификации
818,classification margin,هامش التصنيف,هامش التصنيف,هامش التصنيف,分类裕度,分类边距,分类边际,marge de classement,marge de classification,marge de classification,分類マージン,分類マージン,分類マージン,классификационная маржа,отступ классификации,классификационный отступ
819,classification method,طريقة التصنيف,طريقة التصنيف,طريقة التصنيف,分类方法,分类方法,分类方法,méthode de classement,méthode de classification,méthode de classification,分類方法,分類手法 (ぶんるいしゅほう),分類方法,метод классификации,метод классификации,метод классификации
820,classification metric,مقياس التصنيف,مقياس التصنيف,متر التصنيف,分类度量,分类度量,分类指标,métrique de classification,métrique de classification,Métrique de classification,分類メトリック,分類メトリック,分類指標,метрика классификации,метрика классификации,классификационная метрика
821,classification model,نموذج التصنيف,نموذج تصنيف,نموذج تصنيف,分类模型,分类模型,分类模型,modèle de classification,modèle de classification,modèle de classification,分類モデル,分類モデル (ぶんるいモデル),分類モデル,модель классификации,модель классификации,модель классификации
822,classification network,شبكة التصنيف,شبكة التصنيف,شبكة التصنيف,分类网络,分类网络,分类网络,réseau de classification,- Réseau de classification,réseau de classification,分類ネットワーク,分類ネットワーク,分類ネットワーク,классификационная сеть,сеть классификации,сеть классификации
823,classification objective,هدف التصنيف,هدف التصنيف,هدف التصنيف,分类目标,分类目标 (classification objective),分类目标,objectif de classement,objectif de classification,objectif de classification,分類の目的,分類目標 (bunrui mokuhyou),分類目的,цель классификации,классификационная цель,классификационная задача
824,classification problem,مشكلة التصنيف,مشكلة التصنيف,مشكلة التصنيف,分类问题,分类问题,分类问题,problème de classement,problème de classification,problème de classification,分類問題,分類問題 (ぶんるいもんだい),分類問題,проблема классификации,проблема классификации,классификационная задача
825,classification score,درجة التصنيف,نقاط التصنيف,درجة التصنيف,分类分数,分类得分,分类分数,note de classement,score de classification,score de classification,分類スコア,分類スコア,分類スコア,классификационный балл,оценка классификации,оценка классификации
826,classification task,مهمة التصنيف,مهمة التصنيف,مهمة التصنيف,分类任务,分类任务,分类任务,tâche de classification,tâche de classification,tâche de classification,分類タスク,- 分類タスク,分類タスク,задача классификации,задача классификации,классификационная задача
827,classification token,رمز التصنيف,رمز التصنيف,علامة التصنيف,分类标记,分类标记,分类标记符,jeton de classification,jeton de classification,jeton de classification,分類トークン,分類トークン,分類トークン,жетон классификации,токен классификации,классификационный токен
828,classifier,مصنف,مصنف,مصنف,分类器,分类器,分类器,classificateur,classifieur,classificateur,分類子,分類器,分類器,классификатор,классификатор,классификатор
829,clause learning,تعلم الجملة,تعلم الشروط,تعلم البنود,从句学习,子句学习,子句学习,apprentissage des clauses,apprentissage de clauses,apprentissage de clause,文節学習,節学習,節学習,пункт обучение,"""['• QCDCL, который можно рассматривать как простую модель, в которой мы можем принимать решения следуя порядку уровня кванторного префикса, делать распространение с помощью дизъюнктов и использовать классическое изучение дизъюнктов. Мы никогда не учимся или не использ",обучение клаузам
830,click model,انقر فوق النموذج,نموذج النقرات,نموذج النقر,点击模型,点击模型,点击模型,cliquez sur le modèle,modèle de clics,modèle de clic,モデルをクリック,クリックモデル (kurikku moderu),クリックモデル,нажмите модель,модель кликов,Модель кликов
831,clip range,نطاق المقطع,النطاق المقصود,نطاق القص,剪辑范围,剪辑范围,夹持范围,plage de clips,plage de clip,plage de clipping,クリップ範囲,クリップ範囲,クリップ範囲,диапазон клипа,диапазон обрезки,диапазон обрезания
832,clipping factor,عامل القطع,عامل القصّ,عامل التقليم,削波因子,裁剪因子,裁剪因子,facteur d'écrêtage,facteur de rognage,facteur de troncature,クリッピング係数,クリッピングファクター,クリッピング係数,коэффициент отсечения,фактор обрезки,обрезающий коэффициент
833,clipping threshold,عتبة القطع,- تراجع الحدود,عتبة التقليص,限幅阈值,"clipping threshold
剪切阈值",截断阈值,seuil d'écrêtage,seuil de rognage,seuil d'écrêtage,クリッピング閾値,クリッピング閾値 (Clipping Threshold),切り捨て閾値,порог отсечения,порог отсечения,порог отсечения
834,clique potential,إمكانات العصبة,الإمكان العصابي,إمكانية المجموعة المترابطة,派系潜力,团队潜力,团势能,potentiel de clique,potentiel de clique,potentiels de clique,派閥の可能性,クリークポテンシャル,クリークポテンシャル,потенциал клики,потенциал клики,сумма клик
835,close frequent itemset,إغلاق مجموعة العناصر المتكررة,مجموعة بنود متكررة مغلقة,مجموعة عناصر متكررة ومغلقة,关闭频繁项集,闭合频繁项集,紧凑频繁项集,fermer l'ensemble d'éléments fréquents,ensemble d'items fréquents clos,ensemble d'éléments fréquents fermés,よく使うアイテムセットを閉じる,閉じた頻出アイテムセット,密な頻出アイテムセット,закрыть часто встречающийся набор элементов,закрытый частый набор элементов,замкнутое частое множество элементов
836,close-book model,نموذج الكتاب المقرب,- النموذج الذي لا يمكن الوصول إليه,نموذج مغلق,闭卷模型,闭卷模型,闭卷模型,modèle de livre fermé,modèle de livre fermé,modèle à livre fermé,クローズブックモデル,クローズドブックモデル,クローズドブックモデル,модель закрытой книги,модель закрытой книги,закрытая модель
837,close-world,العالم القريب,عالم مغلق,عالم مغلق,封闭世界,封闭世界,封闭世界,monde proche,monde fermé,monde fermé,近い世界,クローズドワールド (Kurozudo Wārudo),閉鎖世界,тесный мир,закрытый мир,замкнутый мир
838,cloze prompt,موجه إغلاق,- تعليمة التمرير الناقص,تلميح اكتمال,完形填空提示,填空提示,完形提示,fermer l'invite,indice de suppression,prompt à trous,プロンプトを閉じる,クローズプロンプト (cloze prompt),空欄プロンプト,закрыть подсказку,тесты на заполнение пропусков,заполнение пропусков
839,cloze task,مهمة مغلقة,"1) the cloze task, i.e. to predict a masked token from the left and right context; and 2) next sentence prediction, i.e.', 'The pattern turns the input text into a cloze task, i.e. a sequence with a masked token or tokens that need to be filled. Let us use as example",مهمة الإكمال,完形填空任务,填空任务,阅读理解填空任务,clôturer la tâche,tâche de complétion,tâche de complétion,タスクを閉じる,穴埋め課題 (cloze task),空所補充課題,закрыть задачу,задание на заполнение пропусков,задача с пропусками
840,cluster algorithm,خوارزمية الكتلة,- تقنية تجميع العناصر,خوارزمية التجميع,聚类算法,聚类算法,聚类算法,algorithme de cluster,algorithme de regroupement,algorithme de clustering,クラスターアルゴリズム,クラスタリングアルゴリズム,クラスタリングアルゴリズム,кластерный алгоритм,алгоритм кластеризации,алгоритм кластеризации
841,cluster assignment,مهمة الكتلة,تعيين المجموعة,تعيين العنقود,聚类分配,集群分配,聚类分配,affectation de cluster,attribution de cluster,assignation de cluster,クラスタの割り当て,クラスター割り当て,クラスタ割り当て,назначение кластера,Assigning clusters - назначение кластеров,присвоение кластера
842,cluster center,مركز الكتلة,مركز العنقود,مركز العنقود,聚类中心,簇中心,簇中心,centre de cluster,centre de cluster,centre de grappe,クラスターセンター,クラスタ中心,クラスター中心,кластерный центр,центр кластера,центр кластера
843,cluster centroid,الكتلة النقطه الوسطى,مركز العناصر في العنقود,مركز التجمع,簇质心,簇中心,聚类中心点,centroïde du cluster,centroïde de regroupement,centroïde de cluster,クラスター重心,クラスター重心,クラスター中心,центроид кластера,центроид кластера,кластерный центроид
844,cluster criterion,معيار الكتلة,- تعيين مجموعة العناصر,معيار التجميع,聚类标准,簇判据,聚类准则,critère de cluster,critère de regroupement,critère de clustering,クラスター基準,クラスタ基準 (Kurasuta kijun),クラスター基準,кластерный критерий,критерий кластеризации,критерий кластеризации
845,cluster feature,ميزة الكتلة,ميزة التجمع,ميزة العنقود,聚类特征,簇特征,簇特征,fonctionnalité de cluster,caractéristique de cluster,caractéristiques de cluster,クラスター機能,クラスタ特徴,クラスタ素性,функция кластера,кластерный признак,кластерные признаки
846,cluster label,تسمية الكتلة,تصنيف العنقود,وصمة المجموعة,簇标签,簇标签,簇标签,étiquette de cluster,étiquette de cluster,étiquette de cluster,クラスタラベル,クラスターラベル,クラスターラベル,метка кластера,кластерная метка,метка кластера
847,cluster method,طريقة الكتلة,طريقة التجميع,طريقة التجميع,聚类法,聚类方法,聚类方法,méthode de cluster,méthode de regroupement,méthode de clustering,クラスター方式,クラスタリング手法,クラスター手法,кластерный метод,метод кластеризации,метод кластеризации
848,cluster problem,مشكلة الكتلة,مشكلة التجميع,مشكلة التجمع,集群问题,簇问题,聚类问题,problème de cluster,Problème de regroupement,problème de clustering,クラスター問題,クラスタ問題 (Cluster 問題),クラスター問題,проблема с кластером,- Кластерная проблема,кластерная проблема
849,cluster size,حجم الكتلة,حجم العنقود,حجم العُنقود,簇的大小,簇大小,簇大小,Taille de cluster,- Taille du cluster,taille des clusters,クラスターサイズ,クラスターサイズ,クラスターサイズ,размер кластера,размер кластера,размер кластера
850,co-occurrence,حدوث مشترك,تواجد مشترك,تواجد متزامن,同现,共现,共现,cooccurrence,co-occurrence,co-occurrence,共起,共起,共起,одновременное возникновение,совместное появление,совместная встречаемость
851,co-occurrence matrix,مصفوفة التواجد المشترك,مصفوفة التزاوج,مصفوفة التواجد المشترك,共现矩阵,共现矩阵,共现矩阵,matrice de cooccurrence,- Matrice de co-occurrence,matrice de co-occurrence,共起行列,共起行列,共起行列,матрица совпадений,матрица совместного появления,матрица совместной встречаемости
852,co-occurrence statistic,إحصائية التواجد المشترك,الإحصائيات المتزامنة,إحصائيات التواجد المشترك,共现统计,共现统计,共现统计,statistique de cooccurrence,statistique de co-occurrence,Statistiques de co-occurrence,共起統計,共起統計量,共起統計,статистика совместной встречаемости,статистика совместной встречаемости,сопутствующая статистика
853,co-reference,مرجع مشترك,"""من المدهش أن يحدد LUND، الذي تم تدريبه على Nom-Bank، عدد قليل جدًا من أزواج الحجج الوسيطة بالاسم دون التشاركية. سيجعلك المثال على ذلك واضحًا. للجملة، """,المرجعية المشتركة,共同参考,共指,共指,co-référence,co-référence,coréférence,共同参照,"""['Nom-Bankで訓練されたLUNDが共参照なしでほとんどの名詞を介した引数対を特定することが驚くべきことである。例を挙げると、""Clarcor、パッケージングとろ過製品の製造業者、が述べました...""という文において、ターゲット関係はClarcor",同一参照,совместная ссылка,"""['Удивительно, что LUND, обученный на Nom-Bank, идентифицирует так мало пар аргументов, связанных существительными без совпадения. Пример прояснит это. Для предложения ""Clarcor, производитель упаковочной и фильтрационной продукции, сказал ..."", целевое отношение между Clarcor и прод",сореферентность
854,co-training,التدريب المشترك,- التعليم المشترك,التدريب المشترك,共同培训,协同训练,协同训练,co-formation,co-entraînement,co-entrainement,共同トレーニング,共同訓練,協同学習,совместное обучение,совместное обучение,сопутствующее обучение
855,coarse correlated equilibria,التوازنات المرتبطة الخشنة,- توازنات الترابط الخشنة,التوازنات المترابطة الخشنة,粗相关平衡,粗略相关均衡,粗糙相关均衡,équilibres corrélés grossiers,équilibres corrélés grossiers,équilibres corrélés grossiers,粗相関平衡,粗い相関均衡,粗い相関均衡,грубые коррелированные равновесия,грубые коррелированные равновесия,коррелированные равновесия с грубой аппроксимацией
856,coarse correlated equilibrium,التوازن المترابط الخشن,توازن ترتيبية خشنة,التوازن المترابط الخشن,粗相关平衡,粗粒度相关均衡,粗糙相关均衡,équilibre corrélé grossier,équilibre corrélé grossier,équilibre corrélé grossier,粗相関平衡,粗い相関均衡,粗い相関均衡,грубое коррелированное равновесие,грубое коррелированное равновесие,грубое скоррелированное равновесие
857,coarse layer,طبقة خشنة,- تصنيف خشن,طبقة خشنة,粗层,粗糙层,粗层,couche grossière,couche grossière,couche grossière,粗層,粗層 (Sosou),粗層,грубый слой,грубый слой,грубый слой
858,coarse-to-fine,الخشنة إلى الناعمة,خشن إلى دقيق,من الناحية الدقيقة إلى الخشنة,由粗到细,粗到精,由粗到精,grossier à fin,grossier-à-fine,grossier-à-fin,粗いものから細かいものまで,粗→細,粗から細へ,от грубого до мелкого,грубый-до-тонкий,от грубого к детальному
859,coarse-to-fine approach,نهج الخشنة إلى الناعمة,نهج خشن إلى دقيق,الاستراتيجية المتدرجة من الخشن إلى الدقيق,由粗到细的方法,粗到细的方法,粗到细方法,approche grossière à fine,- Approche grossière à fine,approche grossière à fine,粗いものから細かいものへのアプローチ,粗・細アプローチ,粗から細へのアプローチ,подход от грубого к мелкому,грубо-тонкое приближение,Подход от грубого к тонкому
860,coarse-to-fine cascade,سلسلة من الخشنة إلى الناعمة,التتابع الخشن إلى الدقيق,تسلسل خشن إلى دقيق,由粗到细级联,粗到精级联,由粗到精级联,cascade grossière à fine,"p 1→0 (h, m) ⊂ F (I 0 )} \n La figure 2 représente une",cascade grossier-à-fin,粗いものから細かいものへのカスケード,粗いから細かいカスケード,粗から細へのカスケード,каскад от грубого к мелкому,"""['Индексные наборы более высокоуровневых моделей могут быть построены из индексных наборов моделей более низкого уровня, образуя иерархию, которую мы будем использовать в нашей грубой-к-тонкой каскад.', 'Оставшиеся индексы перв",каскад от грубого к тонкому
861,coarse-to-fine strategy,استراتيجية الخشنة إلى الناعمة,- تحديد الإستراتيجية من الخشن إلى الدقيق,استراتيجية من الخشن إلى الدقيق,由粗到细的策略,粗到精策略,粗到精策略,stratégie grossière à fine,stratégie grossière à fine,stratégie de grossier à fin,粗いものから細かいものへの戦略,粗密戦略,粗から細へのストラテジー,стратегия от грубого к мелкому,грубо-тонкая стратегия,"стратегия ""грубо к точно"""
862,codebook,كتاب الشفرات,الدليل البرمجي,كتاب الترميز,密码本,码本,码本,livre de codes,livre de codes,livre de codes,コードブック,コードブック,コードブック,кодовая книга,кодовая книга,кодовая книга
863,codomain,مجال الكود,مدى الشيفرة,مجال القيم,共域,值域,值域,codomaine,codomain,codomaine,コドメイン,コドメイン,対値域,кодомен,кодоменой,областьзначений
864,coefficient matrix,معامل المصفوفة,مصفوفة القوى الناتجة,مصفوفة المعاملات,系数矩阵,系数矩阵,系数矩阵,matrice de coefficients,matrice de coefficient,matrice de coefficients,係数行列,係数行列 (keisū gyōretsu),係数行列,матрица коэффициентов,матрица коэффициентов,матрица коэффициентов
865,cognitive model,النموذج المعرفي,النموذج الإدراكي,نموذج إدراكي,认知模型,认知模型,认知模型,modèle cognitif,modèle cognitif,modèle cognitif,認知モデル,認知モデル (Cognitive model),認知モデル,когнитивная модель,когнитивная модель,когнитивная модель
866,cognitive science,العلوم المعرفية,علم الإدراك,علم المعرفة,认知科学,认知科学,认知科学,sciences cognitives,science cognitive,science cognitive,認知科学,認知科学,認知科学,когнитивная наука,когнитивная наука,Когнитивная наука
867,cold start,بداية باردة,- تشغيل بارد,بدء بارد,冷启动,冷启动,冷启动,démarrage à froid,démarrage à froid,démarrage à froid,コールドスタート,コールドスタート,起動時の問題,холодный запуск,холодный старт,холодный старт
868,collaborative filtering,تصفية التعاونية,التصفية التعاونية,ترشيح تعاوني,协同过滤,协同过滤,协同过滤,filtrage collaboratif,filtrage collaboratif,filtrage collaboratif,協調フィルタリング,協調フィルタリング,協調フィルタリング,совместная фильтрация,совместная фильтрация,коллаборативная фильтрация
869,collaborative learning,التعلم التعاوني,التعلم التعاوني,التعلم التعاوني,协作学习,协作学习,协作学习,apprentissage collaboratif,apprentissage collaboratif,apprentissage collaboratif,協同学習,- 協調学習 (Kyouryou gakushuu),協同学習,совместное обучение,коллективное обучение,совместное обучение
870,collective inference,الاستدلال الجماعي,الاستدلال الجماعي,الاستدلال الجماعي,集体推理,集体推理,集体推理,inférence collective,inférence collective,inférence collective,集合的推論,集団推論,集合的推論,коллективный вывод,коллективное заключение,коллективный вывод
871,color channel,قناة اللون,- قناة اللون,قناة اللون,颜色通道,颜色通道,颜色通道,canal de couleur,canal de couleur,canal de couleur,カラーチャンネル,カラーチャンネル,カラーチャネル,цветовой канал,цветовой канал,цветовой канал
872,color constancy,ثبات اللون,ثبات اللون,ثبات اللون,颜色恒常性,颜色恒常性,颜色恒常性,constance des couleurs,constance de la couleur,constance des couleurs,色の恒常性,色不変性,色恒常性,постоянство цвета,цветовая постоянство,постоянство цвета
873,colorization,التلوين,التلوين,تلوين الصور,着色,着色化,上色,colorisation,colorisation,Colorisation,カラー化,カラーリゼーション (karāraizēshon),カラー化,раскрашивание,колоризация,колоризация
874,column space,مساحة العمود,المساحة العمودية,فضاء الأعمدة,柱空间,列空间,列空间,espace des colonnes,espace des colonnes,espace colonne,列スペース,列空間,列空間,пространство столбца,Пространство столбцов,пространство столбцов
875,column vector,ناقلات العمود,متجه العمود,متجه عمودي,列向量,列向量,列向量,vecteur colonne,vecteur colonne,vecteur colonne,列ベクトル,カラムベクトル,縦ベクトル,вектор-столбец,столбцовый вектор,столбцовый вектор
876,combinator,الموحد,مجموعات التركيب,مُرَكِّب,组合器,组合子,组合子,combinateur,combinateur,combinateur,コンビネーター,組み合わせ子 (kumiawaseko),組み合わせ関数,комбинатор,комбинатор,комбинатор
877,combinatorial explosion,انفجار اندماجي,انفجار مجموعات الجمعية,انفجار تركيبي,组合爆炸,组合爆炸,组合爆炸,explosion combinatoire,explosion combinatoire,explosion combinatoire,組み合わせ爆発,組み合わせ爆発,組合せ爆発,комбинаторный взрыв,комбинаторный взрыв,комбинаторный взрыв
878,combinatorial optimization,كومبيناتوريال الأمثل,أمثلة على الأمثلة المتشابكة,تحسين تركيبي,组合优化,组合优化,组合优化,optimisation combinatoire,optimisation combinatoire,optimisation combinatoire,組み合わせ最適化,組合せ最適化,組合せ最適化,комбинаторная оптимизация,комбинаторная оптимизация,комбинаторная оптимизация
879,combinatorial optimization problem,مشكلة الأمثل اندماجي,مشكلة تحسين تكاملية توافقية,مشكلة البرمجة التركيبية,组合优化问题,组合优化问题,组合优化问题,problème d'optimisation combinatoire,problème d'optimisation combinatoire,problème d'optimisation combinatoire,組み合わせ最適化問題,組み合わせ最適化問題,組合せ最適化問題,задача комбинаторной оптимизации,комбинаторная задача оптимизации,задача комбинаторной оптимизации
880,combinatory categorial grammar,القواعد النحوية التجميعية,نحو تصنيفي مجمع,نحو الفئات التركيبية,组合范畴语法,组合范畴语法 (Combinatory Categorial Grammar),组合范畴语法,grammaire catégorielle combinatoire,grammaire catégorielle combinatoire,grammaire catégorielle combinatoire,組み合わせカテゴリー文法,組み合わせカテゴリ文法,組み合わせ範疇文法,комбинаторная категориальная грамматика,Комбинаторная категориальная грамматика,комбинаторная категориальная грамматика
881,commonsense inference,الاستدلال المنطقي,الاستدلال بمنطق السلامة,الاستدلال العام المنطقي,常识推理,常识推理,常识推理,inférence de bon sens,inférence de bon sens,inférence de sens commun,常識的な推論,常識推論,常識推論,вывод здравого смысла,вывод на основе здравого смысла,вывод здравого смысла
882,commonsense knowledge,المعرفة المنطقية,المعرفة السليمة الشائعة,المعرفة العامة,常识性知识,常识知识,常识知识,connaissances de bon sens,connaissance du bon sens,connaissances de sens commun,常識的な知識,常識知識,常識知識,здравый смысл,здравый смысл,здравый смысл
883,commonsense knowledge graph,الرسم البياني للمعرفة المنطقية,رسم بياني للمعرفة السليمة الشائعة,شبكة معارف المنطق العام,常识性知识图谱,常识知识图谱,常识知识图谱,graphique des connaissances de bon sens,- Graph de connaissances du bon sens,graphe de connaissances de sens commun,常識知識グラフ,常識知識グラフ (joushiki chishiki graph),常識知識グラフ,График знаний здравого смысла,граф знаний здравого смысла,база знаний здравого смысла
884,commonsense reasoning,المنطق المنطقي,الاستدلال الشائعة,استدلال المنطق العام,常识推理,常识推理,常识推理,raisonnement de bon sens,"""['À partir du Tableau 10, nous pouvons constater que BART entraîné avec des chemins multi-sauts obtient de meilleures performances, car les chemins multi-sauts peuvent fournir plus d'informations contextuelles utiles pour le raisonnement de bon sens.', 'Ces tâches visent à apprendre aux modèles d'apprentissage automatique à réaliser diverses tâches telles que la reconnaissance d'objets, la compréhension des relations visuelles,",raisonnement de sens commun,常識的な推論,常識推論,常識推論,рассуждения здравого смысла,"""['Из таблицы 10 мы видим, что BART, обученный с многоходовыми путями, демонстрирует лучшую производительность, поскольку многоходовые пути могут предоставить больше контекстуальной информации, полезной для здравого смысла.', 'Эти задачи предназначены для обучения моделей маш",рассуждение здравого смысла
885,communication complexity,تعقيد الاتصالات,معقدات الاتصال,تعقيد الاتصال,通信复杂性,通信复杂度,通信复杂度,complexité de la communication,complexité de la communication,Complexité de communication,コミュニケーションの複雑さ,通信複雑さ,通信複雑性,сложность связи,коммуникационная сложность,коммуникационная сложность
886,communication graph,الرسم البياني للاتصالات,الرسم البياني للاتصالات,رسم الاتصال,通讯图,通信图,通信图,graphique de communication,graphe de communication,graphe de communication,コミュニケーショングラフ,通信グラフ,通信グラフ,коммуникационный граф,граф связи,граф связи
887,compatibility function,وظيفة التوافق,وظيفة التوافق,وظيفة التوافق,兼容功能,兼容性函数,相容性函数,fonction de compatibilité,fonction de compatibilité,fonction de compatibilité,互換機能,互換性関数,互換性関数,функция совместимости,Функция совместимости,cовместимостная функция
888,compatibility graph,الرسم البياني التوافق,الرسم البياني للتوافق,رسم التوافق,兼容性图,兼容性图,兼容图,graphique de compatibilité,- Graphique de compatibilité,graphe de compatibilité,互換性グラフ,互換性グラフ,互換性グラフ,график совместимости,Граф совместимости,граф совместимости
889,competitive ratio,نسبة تنافسية,نسبة التنافسية,نسبة التنافسية,竞争比,竞争比率,竞争比率,rapport de compétitivité,ratio compétitif,rapport de compétitivité,競争力,競合比,競争比率,конкурентное соотношение,Коэффициент конкуренции,конкурентное отношение
890,composition function,وظيفة التكوين,وظيفة التكوين,وظيفة التركيب,复合函数,组合函数,复合函数,fonction de composition,fonction de composition,fonction de composition,合成機能,構成関数 (Kousei Kansu),合成関数,функция композиции,функция композиции,композиционная функция
891,compositional generalization,التعميم التركيبي,التعميم التركيبي,التعميم التركيبي,成分概括,组合概括化,合成泛化,généralisation compositionnelle,généralisation compositionnelle,généralisation compositionnelle,構成的な一般化,構成的一般化,構成的一般化,композиционное обобщение,композиционная обобщенность,композиционное обобщение
892,compositional semantic,الدلالية التركيبية,الدلالة التركيبية,الدلالة التركيبية,组合语义,组合语义,组合语义,sémantique compositionnelle,sémantique compositionnelle,sémantique compositionnelle,構成的意味論,組成意味論,構成的意味論,композиционная семантика,композиционная семантика,композиционная семантика
893,compositionality,التركيبية,التركيبية,تركيبية,组合性,组合性,组合性,compositionnalité,compositionnalité,compositionnalité,構成性,構成性 (Kouseisei),合成性,композиционность,композициональность,композиционность
894,compressed sensing,الاستشعار المضغوط,الاستشعار المضغوط,استشعار مضغوط,压缩感知,"""['压缩感知和深度学习方法已经成为降低呼吸憋气持续时间的强大选择，表现出优异的性能。尽管有这些进展，对于几类受试群体来说，呼吸憋气CINE成像仍然具有挑战性，包括儿童和慢性阻",压缩感知,détection compressée,acquisition comprimée,Acquisition comprimée,圧縮センシング,圧縮センシング,圧縮センシング,сжатое зондирование,сжатое восприятие,метод сжатого восприятия
895,compressive sensing,الاستشعار عن الضغط,الاستشعار المضغوط,استشعار ضاغط,压缩传感,压缩感知,压缩感知,détection de compression,"""Par conséquent, la littérature populaire sur la compression par échantillonnage considère la résolution de la relaxation convexe, l'optimisation ℓ1, pour trouver la solution la plus clairsemée. Cependant, nous montrons que l'optimisation ℓ1 échoue à récupérer une fonction (même avec une clairvoyance constante) générée à l'aide du modèle aléatoire avec une forte probabilité lorsque n → ∞. Nous suivons une procédure",captation comprimée,圧縮センシング,圧縮センシング,圧縮センシング,компрессионное зондирование,Сжатое восприятие,компрессивное восприятие
896,computation complexity,تعقيد الحساب,تعقيد الحساب,تعقيد الحساب,计算复杂度,计算复杂度,计算复杂度,complexité du calcul,complexité de calcul,complexité de calcul,計算の複雑さ,計算複雑さ (Computation Complexity),計算複雑性,сложность вычислений,Сложность вычислений,вычислительная сложность
897,computation graph,الرسم البياني الحسابي,رسم الحساب,شبكة الحسابات,计算图,计算图,计算图,graphique de calcul,graphe de calcul,graphe de calcul,計算グラフ,計算グラフ,計算グラフ,граф вычислений,граф вычислений,вычислительный граф
898,computational argumentation,الحجج الحسابية,الحجة الحوسبة,المجادلة الحاسوبية,计算论证,计算论证,计算论证,argumentation informatique,- Argumentation computationnelle,argumentation computationnelle,計算論証,計算論議,計算論証,вычислительная аргументация,вычислительная аргументация,вычислительная аргументация
899,computational budget,الميزانية الحسابية,ميزانية الحسابية,ميزانية الحوسبة,计算预算,计算预算,计算预算,budget de calcul,- Budget computationnel,budget de calcul,計算予算,計算予算,計算リソース,вычислительный бюджет,вычислительный бюджет,вычислительный бюджет
900,computational complexity,التعقيد الحسابي,التعقيد الحسابي,التعقيد الحسابي,计算复杂度,计算复杂性,计算复杂度,complexité informatique,complexité computationnelle,Complexité de calcul,計算の複雑さ,計算複雑性 (けいさんふくざつせい),計算量,вычислительная сложность,Вычислительная сложность,вычислительная сложность
901,computational experiment,تجربة حسابية,تجربة حسابية,تجربة حاسوبية,计算实验,计算实验,计算实验,expérience informatique,expérience computationnelle,expérience de calcul,計算実験,計算実験,計算実験,вычислительный эксперимент,вычислительный эксперимент,Вычислительный эксперимент
902,computational graph,الرسم البياني الحسابي,الرسم البياني الحسابي,الرسم البياني الحسابي,计算图,计算图,计算图,graphique informatique,- Graph computationnel,graphe de calcul,計算グラフ,計算グラフ (けいさんぐらふ),計算グラフ,вычислительный граф,вычислительный граф,вычислительный граф
903,computational linguistic,اللغوية الحسابية,اللغويات الحاسوبية,علم اللغويات الحاسوبية,计算语言学,计算语言学,计算语言学,linguistique informatique,linguistique computationnelle,linguistique computationnelle,計算言語学,計算言語学 (けいさんげんごがく),計算言語学,компьютерная лингвистика,вычислительная лингвистика,Вычислительная лингвистика
904,computational model,النموذج الحسابي,النموذج الحسابي,نموذج حسابي,计算模型,计算模型,计算模型,modèle informatique,modèle computationnel,modèle computationnel,計算モデル,計算モデル,計算モデル,вычислительная модель,вычислительная модель,вычислительная модель
905,compute budget,حساب الميزانية,ميزانية الحسابات,ميزانية الحوسبة,计算预算,计算预算,算力预算,calculer le budget,budget de calcul,budget de calcul,予算を計算する,計算予算,計算リソース,рассчитать бюджет,бюджет вычислений,вычислительный бюджет
906,computer vision,رؤية الكمبيوتر,رؤية الحاسوب,الرؤية الحاسوبية,计算机视觉,计算机视觉,计算机视觉,vision par ordinateur,vision par ordinateur,vision par ordinateur,コンピュータビジョン,コンピュータビジョン,コンピュータビジョン,компьютерное зрение,компьютерное зрение,компьютерное зрение
907,computer vision model,نموذج الرؤية الحاسوبية,نموذج رؤية الحاسوب,نموذج الرؤية الحاسوبية,计算机视觉模型,计算机视觉模型,计算机视觉模型,modèle de vision par ordinateur,modèle de vision par ordinateur,modèle de vision par ordinateur,コンピュータービジョンモデル,コンピュータービジョンモデル (Computer Vision Model),コンピュータビジョンモデル,модель компьютерного зрения,модель компьютерного зрения,модель компьютерного зрения
908,concatenation,سلسلة,الدمج,ربط,级联,连接 (lián jiē),拼接,enchaînement,concaténation,concaténation,連結,連結 (れんけつ),連結,конкатенация,конкатенация,конкатенация
909,concatenation operation,عملية تسلسل,عملية الدمج,عملية الربط,串联运算,连接操作,级联操作,opération de concaténation,- Opération de concaténation,opération de concaténation,連結演算,連結演算,連結操作,операция конкатенации,конкатенационная операция,конкатенационная операция
910,concentration inequality,عدم المساواة في التركيز,تفاوت التركيز,- تفاوت التركيز,集中度不平等,浓度不等式,浓度不等式,inégalité de concentration,inégalité de concentration,inégalité de concentration,濃度の不平等,集中不等式,濃度不等式,неравенство концентрации,неравенство концентрации,концентрационное неравенство
911,concentration parameter,معلمة التركيز,معلمة التركيز,معامل التركيز,浓度参数,集中参数,浓度参数,paramètre de concentration,paramètre de concentration,paramètre de concentration,濃度パラメータ,濃度パラメータ (noudo parameta),濃度パラメータ,параметр концентрации,параметр концентрации,Параметр концентрации
912,concept,مفهوم,مفهوم,مفهوم,概念,概念 (concept),概念,concept,concept,notion,コンセプト,コンセプト (konseputo),概念,концепция,концепция,концепция
913,concept assertion,تأكيد المفهوم,تأكيد المفهومات,مفهوم إثبات,概念断言,概念断言 (concept assertion),概念断言,affirmation de concept,assertion de concept,assertion de concept,コンセプトの主張,概念主張,概念アサーション,утверждение концепции,утверждение концепции,утверждение концепции
914,concept atom,الذرة المفهوم,ذرة المفهوم,ذرة المفهوم,概念原子,概念原子,概念原子,concept atome,atome de concept,atome de concept,概念原子,概念アトム (Concept Atom),概念原子,концепция атома,концепт атом,концептный атом
915,concept class,فئة المفهوم,فصيلة المفهوم,صنف المفهوم,概念课,概念类,概念类,classe conceptuelle,"""['Ainsi, nos résultats de learnability sont définis en termes de classe de concept dans laquelle le concept cible est choisi, et une classe d'instance qui circonscrit l'ensemble des exemples utilisés par les requêtes d'équivalence et d'appartenance. Le message clé à retenir de cet article est que l'apprentissage actif est nécessaire pour extraire correctement et efficacement les réseaux de préférence dans les domaines à valeurs binaires.', '1 si |{",classe de concepts,コンセプトクラス,概念クラス,コンセプトクラス,концептуальный класс,класс концепций,класс понятий
916,concept drift,انجراف المفهوم,تحول المفهوم,تغير المفهوم,概念漂移,概念漂移,概念漂移,dérive conceptuelle,dérive de concept,dérive conceptuelle,コンセプトドリフト,概念ドリフト,コンセプトドリフト,дрейф концепции,дрейф концепции,дрейф концепции
917,concept inclusion,إدراج المفهوم,إدراج المفهوم,تضمين المفهوم,概念包容,概念包含,概念包含,inclusion de concepts,inclusion de concepts,inclusion de concept,コンセプトの包含,概念包含 (がいねんほうがん),概念包含,включение концепции,включение концепта,вложение концепции
918,concept name,اسم المفهوم,اسم المفهوم,اسم مفهوم,概念名称,概念名,概念名称,nom du concept,nom de concept,nom de concept,コンセプト名,コンセプト名 (konseputo mei),概念名,название концепции,концепт-имя,имя концепта
919,condition 1,الحالة 1,الشرط 1,شرط 1,条件1,条件1,条件1,état 1,condition 1,condition 1,条件1,条件1,条件1,условие 1,условие 1,условие 1
920,condition number,رقم الحالة,عدد الظروف,رقم الشرط,条件号,条件数,条件数,numéro d'état,"Les graphiques supérieurs montrent le facteur d'approximation de Nyström }K´p KpSq}˚{OPT k , où S est construit en utilisant une sélection de sous-ensembles gloutonne, en fonction de la taille du sous-ensemble k, pour un jeu de données fictif (κ est le nombre condition) et deux jeux de données Libsvm (σ est le paramètre RBF).', ""Cependant, il se comporte étrangement dans les jeux potentiels",nombre de conditionnement,条件番号,条件数,条件数,номер условия,число обусловленности,числовая обусловленность
921,conditional computation,الحساب المشروط,الحوسبة الشرطية,الحسابات المشروطة,条件计算,条件计算,条件计算,calcul conditionnel,calcul conditionnel,calcul conditionnel,条件付き計算,条件付き計算,条件付き計算,условное вычисление,условное вычисление,условные вычисления
922,conditional density,الكثافة المشروطة,الكثافة الشرطية,الكثافة الشرطية,条件密度,条件密度,条件密度,densité conditionnelle,densité conditionnelle,densité conditionnelle,条件密度,条件付き密度,条件付き密度,условная плотность,условная плотность,условная плотность
923,conditional distribution,التوزيع المشروط,التوزيع الشرطي,التوزيع الشرطي,条件分布,条件分布,条件分布,distribution conditionnelle,- Distribution conditionnelle,distribution conditionnelle,条件付き分布,条件付き分布,条件付き分布,условное распределение,условное распределение,условное распределение
924,conditional effect,تأثير مشروط,التأثير الشرطي,تأثير مشروط,条件效应,条件效果,条件效果,effet conditionnel,effet conditionnel,effet conditionnel,条件付き効果,条件付き効果,条件付き効果,условный эффект,условный эффект,условное воздействие
925,conditional entropy,الانتروبيا المشروطة,التشوش الشرطي,الترتيب الشرطي,条件熵,条件熵,条件熵,entropie conditionnelle,entropie conditionnelle,entropie conditionnelle,条件付きエントロピー,条件付きエントロピー,条件付きエントロピー,условная энтропия,условная энтропия,условная энтропия
926,conditional expectation,توقع مشروط,التوقع الشرطي,انتظار شرطي,条件期望,条件期望,条件期望,attente conditionnelle,espérance conditionnelle,expectation conditionnelle,条件付き期待,条件付き期待値 (jōken-tsuki kitai-chi),条件付き期待値,условное ожидание,условное математическое ожидание,условное ожидание
927,conditional generation,توليد مشروط,التوليد المشروط,توليد شرطي,条件生成,条件生成,条件生成,génération conditionnelle,Génération conditionnelle,génération conditionnelle,条件付き生成,条件付き生成,条件付き生成,условное поколение,Условная генерация,условное генерирование
928,conditional gradient,التدرج الشرطي,التدرج الشرطي,تدرج مشروط,条件梯度,条件梯度 (conditional gradient),条件梯度,gradient conditionnel,gradient conditionnel,gradient conditionnel,条件付き勾配,条件付き勾配,条件付き勾配,условный градиент,условный градиент,условный градиент
929,conditional independence,استقلال مشروط,الاستقلال الشرطي,استقلالية شرطية,条件独立性,条件独立,条件独立性,indépendance conditionnelle,indépendance conditionnelle,indépendance conditionnelle,条件付き独立性,条件付き独立,条件付き独立性,условная независимость,условная независимость,условная независимость
930,conditional independency,استقلال مشروط,الاستقلالية الشرطية,الاستقلالية الشرطية,条件独立性,条件独立性,条件独立性,indépendance conditionnelle,indépendance conditionnelle,indépendance conditionnelle,条件付き独立性,条件的独立性,条件付き非依存性,условная независимость,условная независимость,условная независимость
931,conditional likelihood,احتمال مشروط,احتمالية مشروطة,تقرير الاحتمالية المشروطة,条件可能性,条件似然率,条件似然 (conditional likelihood),vraisemblance conditionnelle,vraisemblance conditionnelle,vraisemblance conditionnelle,条件付き尤度,条件付き尤度,条件付き尤度,условная вероятность,условная вероятность,условная правдоподобность
932,conditional log likelihood,احتمال السجل الشرطي,الاحتمال الشرطي للسجلات,احتمالية اللوغاريتم المشروطة,条件对数似然,条件对数似然,条件对数似然,log de vraisemblance conditionnelle,vraisemblance conditionnelle logarithmique,vraisemblance log conditionnelle,条件付き対数尤度,条件付き対数尤度,条件付き対数尤度,условная логарифмическая вероятность,условное логарифмическое правдоподобие,условное логарифмическое правдоподобие
933,conditional log probability,احتمال السجل الشرطي,احتمالية اللوجاريتمية الشرطية,احتمالية لوغاريتمية شرطية,条件对数概率,条件对数概率,条件对数概率,probabilité logarithmique conditionnelle,probabilité logarithmique conditionnelle,probabilité log conditionnelle,条件付き対数確率,条件付き対数確率,条件付き対数確率,условная логарифмическая вероятность,условная логарифмическая вероятность,условная логарифмическая вероятность
934,conditional maximum entropy,الانتروبيا القصوى المشروطة,الإثراء الشرطي الأقصى,نظرية الاقصى انتروبيا السببية,条件最大熵,条件最大熵,条件最大熵,entropie maximale conditionnelle,entropie maximale conditionnelle,entropie maximale conditionnelle,条件付き最大エントロピー,条件付き最大エントロピー,条件付き最大エントロピー,условный максимум энтропии,условная максимальная энтропия,Условный максимум энтропии
935,conditional model,نموذج مشروط,النموذج الشرطي,نموذج شرطي,条件模型,条件模型,条件模型,modèle conditionnel,modèle conditionnel,modèle conditionnel,条件付きモデル,条件付きモデル (じょうけんつきモデル),条件付きモデル,условная модель,условная модель,условная модель
936,conditional probability,احتمال مشروط,احتمال مشروط,الاحتمالية الشرطية,条件概率,条件概率,条件概率,probabilite conditionnelle,probabilité conditionnelle,probabilité conditionnelle,条件付き確率,条件付き確率,条件付き確率,условная возможность,условная вероятность,условная вероятность
937,conditional probability distribution,التوزيع الاحتمالي المشروط,التوزيع الاحتمالي الشرطي,توزيع احتمالي شرطي,条件概率分布,条件概率分布,条件概率分布,distribution de probabilité conditionnelle,- Distribution de probabilité conditionnelle,distribution de probabilité conditionnelle,条件付き確率分布,条件付き確率分布,条件付き確率分布,условное распределение вероятностей,условное вероятностное распределение,условное распределение вероятностей
938,conditional random Field,حقل عشوائي مشروط,حقل عشوائي مشروط,حقل عشوائي شرطي,条件随机场,条件随机场,条件随机场 (Conditional Random Field),Champ aléatoire conditionnel,Champ aléatoire conditionnel,Champ aléatoire conditionnel,条件付きランダムフィールド,条件付きランダムフィールド (Jōken-tsuki Random Field),条件付き確率場,условное случайное поле,условное случайное поле,Условное случайное поле
939,conditional sampling,أخذ العينات المشروطة,التنميط الشرطي,أخذ عينات مشروطة,条件抽样,条件抽样,条件采样,échantillonnage conditionnel,échantillonnage conditionnel,échantillonnage conditionnel,条件付きサンプリング,条件付きサンプリング,条件付きサンプリング,условная выборка,условные выборки,условный отбор образцов
940,conditional text generation,توليد النص المشروط,تكوين النص الشرطي,توليد نصوص شرطية,条件文本生成,条件文本生成,有条件文本生成,génération de texte conditionnel,génération de texte conditionnelle,génération de texte conditionnelle,条件付きテキストの生成,条件付きテキスト生成,条件付きテキスト生成,генерация условного текста,условная генерация текста,условная генерация текста
941,conditioning,تكييف,التكييف,تكييف,调理,条件化,条件化,conditionnement,- Conditionnement,conditionnement,コンディショニング,条件づけ (jōkenzuke),条件付け (jōkenbuke),кондиционирование,кондиционирование,кондиционирование
942,conditioning vector,ناقلات التكييف,متجه التكييف,متجه التجهيز,条件向量,条件向量,条件向量,vecteur de conditionnement,vecteur de conditionnement,vecteur de conditionnement,コンディショニングベクトル,条件付きベクトル (きじょうつきベクトル),条件付けベクトル,вектор кондиционирования,вектор условий,вектор условий
943,confidence,ثقة,"- توثق
- الثقة",ثقة,信心,置信度,置信度,confiance,confiance,confiance,自信,信頼度,確信度,уверенность,Уверенность,уверенность
944,confidence bind,ربط الثقة,- تقييد الثقة,إرتباط الثقة,信心约束,置信度绑定,置信绑定,lien de confiance,"\n', 'Lorsqu'une limite de confiance valide qui est respectée avec une probabilité δ, nous prouvons que notre contrainte dans l'Eq (4) garantit la précision dans l'Eq (3). Lemme",liaison de confiance,信頼の絆,信頼バインド,信頼度束縛,доверие связывает,привязка доверия,доверительная связь
945,confidence interval,فاصل الثقة,فترة ثقة,فترة الثقة,置信区间,置信区间 (zhì xìn qūjiān),可信区间,Intervalle de confiance,intervalle de confiance,intervalle de confiance,信頼区間,信頼区間,信頼区間,доверительный интервал,интервал доверия,доверительный интервал
946,confidence map,خريطة الثقة,خريطة الثقة,خريطة الثقة,置信度图,置信度图,置信度映射图,carte de confiance,carte de confiance,carte de confiance,信頼度マップ,信頼度マップ (shinraido mappu),信頼度マップ,карта доверия,карта уверенности,карта доверия
947,confidence score,درجة الثقة,نقاط الثقة,مستوى الثقة,置信度得分,置信度得分,置信度分数,score de confiance,score de confiance,score de confiance,信頼スコア,信頼度スコア,確信スコア,показатель уверенности,уверенность оценка,рейтинг достоверности
948,confidence threshold,عتبة الثقة,- عتبة الثقة,نسبة الثقة المعتمدة,置信阈值,置信度阈值,置信度阈值,seuil de confiance,Seuil de confiance,seuil de confiance,信頼度のしきい値,- 確信度の閾値,信頼度閾値,порог доверия,порог уверенности,Порог достоверности
949,configuration,إعدادات,- تكوين,تشكيلة,配置,配置,配置,configuration,configuration,configuration,構成,構成 (こうせい),構成,конфигурация,конфигурация,конфигурация
950,confusion matrix,الارتباك مصفوفة,مصفوفة الالتباسات,مصفوفة الارتباك,混淆矩阵,混淆矩阵,混淆矩阵,matrice de confusion,matrice de confusion,matrice de confusion,混同行列,混同行列,混同行列,матрица путаницы,матрица ошибок,матрица ошибок
951,confusion network,شبكة الارتباك,شبكة الارتباك,شبكة الالتباس,混乱网络,混淆网络,混淆网络,réseau de confusion,réseau de confusion,réseau de confusion,混乱ネットワーク,混乱ネットワーク,混同ネットワーク,сеть путаницы,сеть путаницы,сеть неопределённостей
952,conjugate gradient,المترافقة التدرج,- تسلسل الانحدار المشترك,تدرج متعامد,共轭梯度,共轭梯度,共轭梯度,dégradé conjugué,gradient conjugué,gradient conjugué,共役勾配,共役勾配,共役勾配,сопряженный градиент,метод сопряженных градиентов,Метод сопряженных градиентов
953,conjugate gradient descent,نزول التدرج المترافق,الانحدار بالتدرج المشترك,استنزال التدرج المتزاوج,共轭梯度下降,共轭梯度下降,共轭梯度下降法,descente de gradient conjuguée,descente de gradient conjugué,descente du gradient conjugué,共役勾配降下法,共役勾配降下,共役勾配降下法,сопряженный градиентный спуск,метод сопряженных градиентов,метод спуска по сопряженным градиентам
954,conjugate gradient method,طريقة التدرج المترافق,طريقة التدرج المشتقة,طريقة متجهات التوجيه المتواصلة,共轭梯度法,共轭梯度法,共轭梯度法,méthode du gradient conjugué,méthode des gradients conjugués,méthode du gradient conjugué,共役勾配法,共役勾配法 (kyōyaku kōhai-hō),共役勾配法,метод сопряженных градиентов,метод сопряженных градиентов,Метод сопряженных градиентов
955,conjunct,مقترنة,تركيبات,عطف,连词,合取项,连接词,conjoint,"Comme θ ne contient pas de littéraux négatifs, elle est clairement satisfaisable et possède donc un modèle minimal unique. Soit V l'assignation de vérité qui représente ce modèle minimal.', 'Nous faisons cela en triant les conjonctifs avant de comparer deux arbres nœud par nœud. Il s'agit de la même métrique d'évaluation utilisée",conjonctif,接続する,"""['命題的ホーン形式θは、以下の連接子から構成されています。θには否定的なリテラルが含まれていないため、これは明らかに充足可能であり、したがって独自の最小モデルを持っています。この最小モデルを表す真理値割り当てをVとします。', 'これを行うために",接続語,соединение,конъюнкт,сочетание
956,conjunctive normal form,الشكل العادي المقترن,الشكل الطبيعي الترابطي,الصيغة الطبيعية التوفيقية,连接范式,合取范式 (CNF),合取范式,forme normale conjonctive,forme normale conjonctive,forme normale conjonctive,接続標準形,連言標準形,射影正規形,конъюнктивная нормальная форма,конъюнктивная нормальная форма,конъюнктивная нормальная форма
957,conjunctive query,الاستعلام المقترن,استعلام مشترك,استعلام ربطي,连词查询,联结查询,连接查询,requête conjonctive,requête conjonctive,requête conjonctive,接続クエリ,合言葉クエリ,連接問合せ,соединительный запрос,соединительный запрос,Конъюнктивный запрос
958,connected component,مكون متصل,المكون المتصل,المُكَوِّن المُتَّصِل,连通分量,连通分量,连通分量,composant connecté,composante connexe,composante connexe,接続コンポーネント,連結成分,連結成分,подключенный компонент,связный компонент,связная компонента
959,connectionist model,نموذج اتصالي,نموذج اتصالي,نموذج ترابطي,联结主义模型,连接模型,连接主义模型,modèle connexionniste,modèle connexionniste,modèle connexionniste,コネクショニストモデル,接続主義モデル,結合主義モデル,коннекционистская модель,модель на основе связей,коннекционистская модель
960,connectivity matrix,مصفوفة الاتصال,مصفوفة الاتصال,مصفوفة الترابط,连接矩阵,连通性矩阵,连接矩阵,matrice de connectivité,matrice de connectivité,matrice de connectivité,接続性マトリックス,接続行列 (せつぞくぎょうれつ),接続行列,матрица связности,матрица связности,матрица связности
961,consensus network decoding,فك تشفير الشبكة المتفق عليها,فك ترميز شبكة التوافق,شفرة شبكة التوافق,共识网络解码,共识网络解码,共识网络解码,décodage du réseau de consensus,décodage du réseau de consensus,décodage par consensus de réseau,コンセンサスネットワークのデコーディング,コンセンサスネットワークデコーディング,コンセンサスネットワークデコーディング,декодирование сети консенсуса,декодирование сети консенсуса,согласованное сетевое декодирование
962,consequent,يترتب على ذلك,نتيجة,تالية,结果,结果,后件,conséquent,conséquent,conséquent,結果としての,"""['まず、そのアルゴリズムは、前件と結果に重複するルールを検索します。次に、前件の同じ命題において唯一の違いを持つルールのグループを作成します。そして最後に、これらのグループのそれぞれについて、この命題の隣接するファジィ集合を持つルールを",後件,последующий,следствие,следствие
963,consistent estimator,مقدر ثابت,المقدر المتسق,مقدر متسق,一致估计量,一致估计量,一致估计量,estimateur cohérent,estimateur convergent,estimateur convergent,一貫した推定量,一貫性推定量 (ikanshō suteiryō),一致推定量,непротиворечивая оценка,согласованный оценщик,состоятельная оценка
964,constellation model,نموذج كوكبة,نموذج التكوينية,نموذج المجموعات النجمية,星座模型,星座模型,星座模型,modèle de constellation,modèle de constellation,modèle de constellation,星座モデル,星座モデル,星座モデル,модель созвездия,модель созвездия,модель созвездий
965,constituency parser,محلل الدائرة الانتخابية,محلل تشكيليات,محلل القرارات,选区解析器,成分分析器,短语结构分析器,analyseur de circonscription,analyseur de constituants,analyseur syntaxique par constituants,選挙区パーサー,構成要素解析器 (kousei youso kaiseki-ki),構成素パーサー,парсер избирательного округа,парсер составляющих,синтаксический анализатор составляющих
966,constituency parsing,تحليل الدائرة الانتخابية,تحليل التكوينية,تحليل التركيب البنيوي,选区解析,成分句法分析,短语结构分析,analyse de circonscription,analyse de constituants,analyse syntaxique par constituants,選挙区の解析,構成句解析,構成素解析,разбор избирательного округа,парсинг составляющих,разбор составляющих
967,constituency tree,شجرة الدائرة الانتخابية,شجرة الهيئة,شجرة تمثيلية,选区树,成分树,短语结构树,arbre de circonscription,- Arbre de constituants,arbre de constituants,選挙区ツリー,構成要素木 (kousei youso ki),構成素性木,дерево избирательных округов,дерево составляющих,разборное дерево
968,constituent parsing,التحليل التأسيسي,تحليل العناصر المكونة,تحليل المكونات,成分分析,成分分析,短语结构分析,analyse des constituants,l'analyse syntaxique des constituants,analyse syntaxique en constituants,構成要素の解析,構成要素解析 (kousei youso kaiseki),構成素解析,анализ составляющих,составной анализ (constituent parsing),составной синтаксический разбор
969,constituent structure,الهيكل التأسيسي,الهيكل الجزئي,البنية المكونة,构成结构,成分结构,成分结构,structure constituante,structure constituante,structure constituante,構成構造,構成要素構造 (kosei youso kozo),構成構造,учредительная структура,составная структура,составляющая структура
970,constrained beam search,بحث شعاع مقيد,البحث بشريط مقيد,البحث الشعاعي المقيد,约束波束搜索,约束束搜索,受约束束搜索,recherche de poutre contrainte,Recherche de faisceau contraint,recherche par faisceau contraint,拘束ビーム探索,制約ビームサーチ,制約付きビーム探索,ограниченный поиск луча,ограниченный поиск луча,ограниченный лучевой поиск
971,constrained decoding,فك التشفير المقيد,الفك التشديدي,ترميز مقيد,受限解码,受限解码,受约束解码,décodage contraint,décodage contraint,décodage contraint,制約付きデコード,制約付きデコーディング,制約付きデコーディング,ограниченное декодирование,ограниченная декодировка,ограниченное декодирование
972,constrained optimization,التحسين المقيد,أمثلة للتحسين المقيد,تحسين مقيّد,约束优化,约束优化,受约束优化,optimisation contrainte,optimisation contrainte,optimisation sous contraintes,制約付き最適化,制約最適化,制約付き最適化,ограниченная оптимизация,ограниченная оптимизация,Ограниченная оптимизация
973,constrained optimization problem,مشكلة التحسين المقيدة,مشكلة تحسين محدودة,مشكلة التحسين المقيدة,约束优化问题,受限优化问题,约束优化问题,problème d'optimisation contraint,problème d'optimisation contrainte,problème d'optimisation sous contraintes,制約付き最適化問題,制約付き最適化問題,制約付き最適化問題,задача ограниченной оптимизации,ограниченная задача оптимизации,задача с ограничениями оптимизации
974,constraint,قيد,"""نحن نستخدم قيد جدول لكل حافة للبساطة. كما قمنا بتضمين قيود القضاء على التماثل. لقد قمنا بتنفيذ هذا النموذج داخل حل CP concept (الذي يمكن العثور عليه في ملف src/crystal_maze.cc) الصغ",قيد,约束,约束,约束条件,contrainte,contrainte,contrainte,制約,制約 (せいやく),制約,ограничение,ограничение,ограничение
975,constraint generation,جيل القيد,توليد القيود,تَوليد القيود,约束生成,约束生成,约束生成,génération de contraintes,génération de contraintes,génération de contraintes,制約の生成,制約生成,制約生成,генерация ограничений,генерация ограничений,Генерация ограничений
976,constraint programming,برمجة القيد,برمجة القيود,برمجة القيود,约束规划,约束规划 (constraint programming),约束编程,programmation par contraintes,programmation par contraintes,programmation par contraintes,制約プログラミング,制約プログラミング (seiyaku puroguramingu),制約プログラミング,программирование ограничений,программирование ограничений,программирование с ограничениями
977,constraint propagation,انتشار القيد,انتشار القيود,جريان القيود,约束传播,约束传播,约束传播,propagation de contrainte,Propagation de contraintes,propagation de contraintes,制約の伝播,制約伝播 (seiyaku denpa),制約伝播,распространение ограничений,распространение ограничений,ðàñïðîñòðàíåíèå îãðàíè÷åíèé
978,constraint satisfaction,رضا القيد,- تحقيق القيد,التلبية القيدية,约束满足,约束满足,约束满足问题,satisfaction des contraintes,satisfaction de contrainte,satisfaction de contraintes,制約満足度,制約充足,制約充足問題,удовлетворение ограничений,удовлетворение ограничений,ограничение удовлетворения
979,constraint satisfaction problem,مشكلة رضا القيد,مشكلة تحقيق القيد,مشكلة إرضاء القيود,约束满足问题,约束满足问题 (constraint satisfaction problem),约束满足问题,problème de satisfaction de contraintes,Problème de satisfaction de contraintes,problème de satisfaction de contraintes,制約充足問題,制約充足問題 (seiyaku juzoku mondai),制約充足問題,проблема удовлетворения ограничений,Проблема удовлетворения ограничениями,проблема удовлетворения ограничений
980,constraint set,مجموعة القيد,مجموعة القيود,مجموعة القيود,约束集,约束集,约束集合,ensemble de contraintes,ensemble de contraintes,ensemble de contraintes,制約セット,制約セット,制約条件集合,набор ограничений,множество ограничений,набор ограничений
981,content model,نموذج المحتوى,نموذج المحتوى,نموذج المحتوى,内容模型,内容模型,内容模型,modèle de contenu,modèle de contenu,modèle de contenu,コンテンツモデル,コンテンツモデル (content model),コンテンツモデル,модель контента,модель содержания,модель контента
982,content selection,اختيار المحتوى,اختيار المحتوى,اختيار المحتوى,内容选择,内容选择,内容选择,sélection de contenu,sélection de contenu,sélection de contenu,コンテンツの選択,コンテンツ選択 (Content Selection),コンテンツ選択,выбор контента,выбор контента,подбор контента
983,context encoder,التشفير السياق,مشفر السياق,مشفّر السياق,上下文编码器,上下文编码器,上下文编码器,encodeur de contexte,"""un codeur de contexte""",codeur de contexte,コンテキストエンコーダ,コンテキストエンコーダー (context encoder),コンテクストエンコーダ,кодировщик контекста,контекстный кодировщик,кодировщик контекста
984,context free grammar,السياق النحوي الحر,قواعد النحو الخالية من السياق,قواعد بناء جملة خالية من السياق,上下文无关语法,上下文无关文法,无上下文文法,grammaire sans contexte,- Grammaire hors contexte,grammaire hors contexte,文脈自由文法,文脈自由文法 (ぶんみゃくじゆうぶんぽう),コンテキストフリー文法,контекстно-свободная грамматика,грамматика без контекста,бесконтекстная грамматика
985,context model,نموذج السياق,نموذج السياق,نموذج السياق,语境模型,上下文模型 (Context Model),上下文模型,modèle de contexte,modèle de contexte,modèle contextuel,コンテキストモデル,コンテキストモデル,コンテキストモデル,контекстная модель,модель контекста,контекстная модель
986,context vector,ناقل السياق,متجه السياق,مِتَجهُ السِّياقِ,上下文向量,上下文向量,上下文向量,vecteur de contexte,vecteur de contexte,vecteur contextuel,コンテキストベクトル,コンテキストベクトル,コンテクストベクトル,вектор контекста,вектор контекста,контекстный вектор
987,context window,نافذة السياق,نافذة السياق,نافذة السياق,上下文窗口,上下文窗口,上下文窗口,fenêtre contextuelle,fenêtre contextuelle,fenêtre de contexte,コンテキストウィンドウ,コンテキストウィンドウ,コンテキストウィンドウ,контекстное окно,окно контекста,контекстное окно
988,context-free language,لغة خالية من السياق,لغة بدون سياق,لغات خالية من السياق,上下文无关语言,无上下文语言,无环境语言,langage sans contexte,langage hors contexte,langage hors contexte,文脈自由言語,文脈自由言語,文脈自由言語,контекстно-свободный язык,бесконтекстный язык,контекстно-свободный язык
989,contextual embedding,التضمين السياقي,تضمين السياقية,ترميز سياقي,上下文嵌入,语境嵌入,上下文嵌入,intégration contextuelle,intégration contextuelle,représentation contextuelle,コンテキスト埋め込み,文脈埋め込み,文脈埋め込み,контекстное встраивание,контекстуальное вложение,контекстное встраивание
990,contextual feature,ميزة سياقية,الميزة السياقية,ميزة سياقية,上下文特征,上下文特征,上下文特征,fonctionnalité contextuelle,caractéristique contextuelle,caractéristique contextuelle,コンテキスト機能,文脈特徴,コンテキスト特徴量,контекстуальная особенность,контекстуальная особенность,контекстная особенность
991,contextual information,معلومات سياقية,معلومات سياقية,معلومات سياقية,上下文信息,"""为了惩罚T i捕获“过多”的上下文信息，我们修改后的目标（2）加入了一个惩罚项 •I(T i；X |X i)，该项测量了句子X作为整体给出的关于T i的信息量，超出了X i给出的信息量：\n'，'然而，这种模型不包括上下文信息，而上下文信息可能支持正确标",上下文信息,information contextuelle,- Information contextuelle,informations contextuelles,コンテキスト情報,文脈情報,コンテクスト情報,контекстная информация,контекстуальная информация,контекстная информация
992,contextual model,النموذج السياقي,النموذج السياقي,نموذج سياقي,语境模型,上下文模型,上下文模型,modèle contextuel,modèle contextuel,modèle contextuel,コンテキストモデル,文脈モデル (Contextual Model),コンテクストモデル,контекстная модель,контекстуальная модель,контекстная модель
993,contextual representation,التمثيل السياقي,التمثيل السياقي,تمثيل سياقي,语境表征,上下文表示,上下文表示,représentation contextuelle,représentation contextuelle,représentation contextuelle,文脈上の表現,文脈表現,文脈表現,контекстное представление,контекстуальное представление,контекстуальное представление
994,contextual vector,ناقلات السياقية,المتجه السياقي,متجه سياقي,上下文向量,上下文向量,上下文向量,vecteur contextuel,vecteur contextuel,vecteur contextuel,文脈ベクトル,文脈ベクトル,コンテクストベクトル,контекстуальный вектор,контекстный вектор,контекстный вектор
995,contextual word embedding,تضمين الكلمات السياقية,تضمين كلمات سياقية,تضمين الكلمات السياقية,上下文词嵌入,上下文词嵌入,上下文词嵌入,intégration contextuelle de mots,incrustation contextuelle de mots,plongement de mots contextuels,文脈上の単語の埋め込み,文脈的単語埋め込み,文脈依存単語埋め込み,контекстное встраивание слов,контекстуальные векторы слов,контекстное вложение слов
996,contextualize embedding,تضمين السياق,التضمين السياقي,تضمين السياق,情境化嵌入,上下文嵌入,上下文化嵌入,contextualiser l'intégration,intégration contextualisée,Embedding contextualisé,埋め込みをコンテキスト化する,コンテキスト化された埋め込み (Kontekisutoka sareta ume mi komi),文脈化埋め込み,контекстуализировать встраивание,контекстуализированное вложение,контекстуализированное встраивание
997,contextualize representation,تمثيل سياقي,التمثيل الموضوعي,تمثيل سياقي,情境化表达,上下文表示,上下文化表征,contextualiser la représentation,représentation contextualisée,représentation contextualisée,表現を文脈化する,文脈化表現,文脈化された表現,контекстуализировать представление,контекстуализированное представление,контекстуализированное представление
998,contextualize word vector,سياق ناقلات الكلمات,ناقل كلمات موضعي,متجه كلمة موضح السياق,语境化词向量,上下文化词向量,上下文词向量,contextualiser le vecteur de mots,vecteur de mot contextualisé,vecteur de mots contextualisé,単語ベクトルを文脈化する,文脈付きワードベクトル (Contextualized Word Vectors),文脈化単語ベクトル,контекстуализировать вектор слова,вектор слова с контекстом,контекстуализованный векторное представление слова
999,contingency table,طاولة الطوارئ,جدول الانحراف,جدول الاحتمالات المشروط,列联表,条件概率表,列联表,tableau de contingence,tableau de contingence,tableau de contingence,分割表,"""['表1に示された2×2の独立表では、φ相関係数の計算はφ = P (00) P (11) − P (01) P (10) p P (0+) P (1+) P (+0) P (+1)となります。 \n'、'ベイジアンネットワークまたは信念ネットワーク（BN）は、有向グラフィカルモデル",分割表,Таблица сопряженности,таблица сопряженности,таблица сопряженности
1000,continual learning,التعلم المستمر,التعلم المستمر,التعلم المستمر,持续学习,持续学习,持续学习,apprentissage continu,apprentissage continu,apprentissage continu,継続的な学習,継続学習,継続学習,постоянное обучение,непрерывное обучение,непрерывное обучение
1001,continuous normalize flow,تدفق التطبيع المستمر,تدفق تطويع مستمر,الدفق المعياري المستمر,连续标准化流量,连续归一化流,连续归一化流,flux normalisé continu,flux normalisé continu,écoulement normalisé continu,連続正規化フロー,連続正則化フロー (CNF),連続正規化フロー (CNF),непрерывная нормализация потока,непрерывные нормализующие потоки (CNF),Непрерывный нормализующий поток
1002,contrastive approach,نهج متناقض,- التقنية التباينية,نهج تباينيّ,对比法,对比方法 (contrastive approach),对比学习方法,approche contrastive,Approche contrastive,approche contrastive,対照的なアプローチ,対照的アプローチ,対照的アプローチ,контрастный подход,контрастный подход,контрастный подход
1003,contrastive fine-tuning,ضبط متناقض,ضبط الدقة المتناقضة,ضبط دقيق تباينيّ,对比微调,对比微调,对比式微调,réglage fin contrastif,- Contraste fine-tuning,Ajustement fin contrastif,コントラストの微調整,対照的な微調整,対比微調整,контрастная точная настройка,контрастная настройка (contrastive fine-tuning),контрастная подстройка
1004,contrastive loss,خسارة متناقضة,الخسارة التباينية,خسارة التباين,对比损失,对比损失,对比损失,perte contrastive,perte contrastive,perte contrastive,対照的な損失,コントラスティブ損失 (contrastive loss),対照損失,контрастная потеря,контрастная потеря,потеря контраста
1005,contrastive objective,الهدف المتناقض,الهدف التبايني,هدف تباينيّ,对比目标,对比客观 (contrastive objective),对比目标,objectif contrastif,objectif contrastif,objectif contrastif,対照的な目的,コントラスティブオブジェクティブ,対比目的,контрастирующая цель,контрастная цель,контрастивная цель
1006,control variate,التحكم متغير,- التحكم في المتغيرات,مُتغيِّرٌ ضابِطٌ,控制变量,控制变量,控制变量,variable de contrôle,variate de contrôle,contrôle variationnel,制御変数,制御変量 (Control Variate),統制変量,контрольная переменная,"""['Поскольку E qη [∇ η log q η (x)] = 0, оценка REINFORCE несмещенна для любого выбора b, и термин b∇ η log q η (x) известен как контрольная вариативная (CV) [42, гл. 8].', 'Объединив это все, мы можем использовать гради",контрольная переменная
1007,controllable text generation,توليد النص يمكن السيطرة عليها,إنتاج نص قابل للتحكم,تَوليد نَصّ متَحَكَّم,可控文本生成,可控文本生成,可控文本生成,génération de texte contrôlable,génération de texte contrôlable,Génération de texte contrôlable,制御可能なテキスト生成,制御可能なテキスト生成,制御可能なテキスト生成,управляемое создание текста,управляемая генерация текста,контролируемая генерация текста
1008,conv layer,طبقة التحويل,- المستوى التحويلي (conv layer),طبقة تراكبية,转换层,卷积层,卷积层,couche de conversion,couche conv,couche de convolution,コンバージョンレイヤー,畳み込み層,畳み込み層,конв-слой,сверточный слой,сверточный слой
1009,convergence,التقارب,تقارب,تقارب,收敛,收敛 (Convergence),收敛,convergence,- Convergence,convergence,収束,収束,収束,конвергенция,сходимость,сходимость
1010,convergence analysis,تحليل التقارب,تحليل التقارب,تحليل التقارب,收敛分析,收敛分析,收敛分析,analyse de convergence,- Analyse de convergence,analyse de la convergence,収束解析,収束解析,収束解析,анализ конвергенции,анализ сходимости,анализ сходимости
1011,convergence bound,ملزمة التقارب,حد الانحسار,حد التقارب,收敛界,收敛界限,收敛界,limite de convergence,limite de convergence,borne de convergence,収束限界,収束境界,収束境界,граница сходимости,граница сходимости,сходимость ограничения
1012,convergence criterion,معيار التقارب,معيار الاقتراب,معيار التقارب,收敛准则,收敛准则 (convergence criterion),收敛准则,critère de convergence,critère de convergence,critère de convergence,収束基準,収束基準 (Shūsoku Kijun),収束基準,критерий сходимости,критерий сходимости,критерий сходимости
1013,convergence rate,معدل التقارب,معدل التقارب,معدل التقارب,收敛速度,收敛速率,收敛速率,taux de convergence,taux de convergence,taux de convergence,収束率,収束速度 (shūsoku sokudo),収束速度,скорость сходимости,темп сходимости,скорость сходимости
1014,convergence time,وقت التقارب,وقت الاتفاقية,وقت التقارب,收敛时间,收敛时间,收敛时间,temps de convergence,temps de convergence,temps de convergence,収束時間,収束時間,収束時間,время конвергенции,время сходимости,время сходимости
1015,conversation history,تاريخ المحادثة,تاريخ الحوار,سجل المحادثة,对话历史,对话历史,对话历史记录,historique des conversations,historique de conversation,historique de la conversation,会話履歴,会話履歴,会話履歴,история разговоров,история разговора,история диалога
1016,conversational agent,وكيل المحادثة,وكيل محادثة,وكيل محادثة,会话代理,对话代理,对话式代理,agent conversationnel,- Agent conversationnel,agent conversationnel,会話エージェント,対話エージェント,対話エージェント,разговорный агент,разговорный агент,разговорный агент
1017,conversational dialogue system,نظام الحوار التحادثي,نظام حواري تحادثي,نظام حوار تفاعلي,对话系统,对话对话系统,交互式对话系统,système de dialogue conversationnel,- Système de dialogue conversationnel,système de dialogue conversationnel,会話型対話システム,会話ダイアログシステム (Kaiwa Daiarogu Shisutemu),対話型対話システム,разговорная диалоговая система,диалоговая система общения,система диалогового общения
1018,convex,محدب,محدب,مُقَعَّر,凸的,凸的,凸的,convexe,convexe,convexe,凸型,凸,凸,выпуклый,выпуклый,выпуклый
1019,convex combination,مزيج محدب,المزيج المحدب,مزيج محدب,凸组合,凸组合,凸组合,combinaison convexe,combinaison convexe,combinaison convexe,凸組み合わせ,凸結合,凸結合,выпуклая комбинация,выпуклая комбинация,линейная комбинация
1020,convex conjugate,مترافق محدب,المتغير المعكوس المحدب,المقارن المقعر,凸共轭,凸共轭,凸共轭,conjugué convexe,conjugé convexe,conjugué convexe,凸共役,凸共役,凸共役,выпуклое сопряжение,выпуклая сопряженная,выпуклая сопряженная
1021,convex constraint,القيد المحدب,القيد الناعم,قيد محدب,凸约束,凸约束,凸约束,contrainte convexe,- Contrainte convexe,contrainte convexe,凸型拘束,凸制約 (kyokuseiyaku),凸制約条件,выпуклое ограничение,выпуклое ограничение,Выпуклое ограничение
1022,convex decomposition,التحلل المحدب,- تقسيم محدب,تحليل محدب,凸分解,凸分解,凸分解,décomposition convexe,décomposition convexe,décomposition convexe,凸分解,凸分解 (kyokubunkai),凸分解,выпуклое разложение,выпуклое разложение,выпуклое разложение
1023,convex function,وظيفة محدبة,وظيفة محدبة,دالة محدبة,凸函数,凸函数,凸函数,fonction convexe,fonction convexe,fonction convexe,凸関数,凸関数,凸関数,выпуклая функция,выпуклая функция,Выпуклая функция
1024,convex hull,هيكل محدب,القشرة المحدبة,الغلاف المحدب,凸包,凸包,凸包,enveloppe convexe,enveloppe convexe,enveloppe convexe,凸包,凸包,凸包,выпуклая оболочка,выпуклая оболочка,выпуклая оболочка
1025,convex loss,خسارة محدبة,الخسارة الواقعة,خسارة محدبة,凸损失,凸损失,凸损失,perte convexe,perte convexe,perte convexe,凸損,凸損失 (kyokutsu sonshitsu),凸損失,выпуклая потеря,выпуклая потеря,выпуклая функция потерь
1026,convex objective,هدف محدب,- تكوين محدب,هدف محدب,凸物镜,凸目标,凸目标函数,objectif convexe,objectif convexe,objectif convexe,凸型対物レンズ,凸目的,凸目的関数,выпуклая цель,выпуклый объект,выпуклый критерий
1027,convex objective function,وظيفة موضوعية محدبة,دالة هدف محدبة,دالة هدف محدبة,凸目标函数,凸目标函数,凸目标函数,fonction objectif convexe,fonction objectif convexe,fonction objectif convexe,凸目的関数,凸目的関数,凸目的関数,выпуклая целевая функция,выпуклая целевая функция,выпуклая целевая функция
1028,convex optimization,الأمثل محدب,التحسين القاعدي,تحسين محدب,凸优化,凸优化,凸优化,optimisation convexe,optimisation convexe,optimisation convexe,凸最適化,凸最適化,凸最適化,выпуклая оптимизация,выпуклая оптимизация,выпуклая оптимизация
1029,convex optimization problem,مشكلة التحسين محدبة,مشكلة تحسين محدبة,مشكلة تحسين محدبة,凸优化问题,凸优化问题,凸优化问题,problème d'optimisation convexe,problème d'optimisation convexe,problème d'optimisation convexe,凸最適化問題,凸最適化問題,凸最適化問題,задача выпуклой оптимизации,выпуклая задача оптимизации,проблема выпуклой оптимизации
1030,convex problem,مشكلة محدبة,مشكلة محدبة,مشكلة محدبة,凸问题,凸问题,凸问题,problème convexe,problème convexe,problème convexe,凸問題,凸問題 (とつもんだい),凸問題,выпуклая задача,выпуклая задача,Выпуклая задача
1031,convex program,برنامج محدب,برنامج محدب,برنامج محدب,凸规划,凸规划,凸优化问题,programme convexe,programme convexe,programme convexe,凸プログラム,凸計画,凸プログラム,выпуклая программа,выпуклая программа,выпуклая программа
1032,convex proxy,وكيل محدب,بروكسي محدب,بديل محدب,凸代理,凸代理,凸代理,proxy convexe,approximation convexe,substitut convexe,凸型プロキシ,凸プロキシ,凸近似,выпуклый прокси,выпуклый прокси,выпуклый заместитель
1033,convex quadratic program,برنامج تربيعي محدب,برنامج تربيعي محدب,برنامج تربيعي محدب,凸二次规划,凸二次规划,凸二次规划,programme quadratique convexe,programme quadratique convexe,programme quadratique convexe,凸二次計画法,凸二次計画,凸二次計画問題,выпуклая квадратичная программа,выпуклая квадратичная программа,выпуклая квадратичная программа
1034,convex relaxation,استرخاء محدب,- تخفيف الانحناء,استرخاء محدب,凸松弛,凸松弛,凸松弛化,relaxation convexe,- Convexe relaxation,relaxation convexe,凸面緩和,凸緩和,凸緩和,выпуклая релаксация,выпуклое расслабление,выпуклое расслабление
1035,convex risk minimization,الحد من المخاطر محدبة,التقليل من المخاطر القمعية,تدنية المخاطر المحدبة,凸风险最小化,凸风险最小化,凸风险最小化,minimisation du risque convexe,minimisation du risque convexe,minimalisation du risque convexe,凸型リスクの最小化,凸リスク最小化,凸リスク最小化,выпуклая минимизация риска,выпуклая минимизация риска,Минимизация выпуклого риска
1036,convex set,مجموعة محدبة,مجموعة محدبة,مجموعة محدبة,凸集,凸集,凸集,ensemble convexe,- Ensemble convexe,ensemble convexe,凸セット,凸集合,凸集合,выпуклое множество,выпуклое множество,выпуклое множество
1037,convex surrogate,بديل محدب,بديل محدب,بَديل مُحَدَّب,凸代理,凸替代方案,凸替代物,substitut convexe,substitut convexe,substitut convexe,凸サロゲート,凸代理,凸代用関数,выпуклый суррогат,выпуклый заменитель,выпуклая суррогатная
1038,convex-concave,محدب مقعر,محايد-مقعر,محدب-مقعر,凸凹,凸凹,凸凹,concave convexe,convexe-concave,convexe-concave,凹凸,凸凹,凸凹,выпукло-вогнутый,выпукло-вогнутое,выпукло-вогнутый
1039,convexity,تحدب,توازنية,تحدّب,凸性,凹性,凸性,convexité,convexité,convexité,凸面,凸性,凸性,выпуклость,выпуклость,выпуклость
1040,convolution,التفاف,- تراسبية,تراكب,卷积,"""['H (•) 可以是一种由诸如批量归一化（BN）[14]、修正线性单元（ReLU）[6]、池化[19]或卷积（Conv）等操作构成的复合函数。我们将第th层的输出表示为x。残差网络。', '( f ↓i，f ↓j ) Q ↓j ( l ) 对样本 f ↓ Q ( m ) ( l ) 进行卷",卷积,convolution,convolution,opération de convolution,畳み込み,畳み込み,畳み込み,свертка,свёртка,сверточная операция
1041,convolution kernel,نواة الالتواء,نواة التبعية,نواة التضمين,卷积核,卷积核,卷积核,noyau de convolution,noyau de convolution,noyau de convolution,コンボリューションカーネル,畳み込みカーネル (tsumikomi kaaneru),畳み込み核,ядро свертки,ядро свертки,свёрточное ядро
1042,convolution layer,طبقة الالتواء,طبقة التباين,طبقة التضمين,卷积层,卷积层,卷积层,couche de convolution,- Couche de convolution,couche de convolution,畳み込み層,畳み込み層 (Convolution Layer),畳み込み層,слой свертки,Сверточный слой,слой свёртки
1043,convolution neural network,الشبكة العصبية التلافيفية,شبكة عصبية تقطيعية,شبكة عصبية متراكبة (convolution neural network),卷积神经网络,卷积神经网络,卷积神经网络,réseau neuronal à convolution,- Réseau de neurones à convolution,réseau neuronal convolutif,畳み込みニューラルネットワーク,畳み込みニューラルネットワーク,畳み込みニューラルネットワーク,нейронная сеть свертки,сверточная нейронная сеть,Свёрточная нейронная сеть
1044,convolution operation,عملية الالتفاف,عملية التحويل المتعامد,عملية الطي,卷积运算,卷积运算,卷积运算,opération de convolution,opération de convolution,opération de convolution,畳み込み演算,畳み込み演算,畳み込み演算,операция свертки,Операция свертки,свёрточная операция
1045,convolution operator,عامل الالتفاف,مشغل ترددية,عامل التطويق,卷积算子,卷积算子,卷积算子,opérateur de convolution,opérateur de convolution,opérateur de convolution,畳み込み演算子,畳み込み演算子,畳み込み演算子,оператор свертки,оператор свёртки,оператор свёртки
1046,convolutional,تلافيفي,تدرجية,معاوقية,卷积的,卷积,卷积,convolutif,"convolutional
- Convolutionnel",convolutionnel,畳み込み,"""['我々は、与えられたデータ分布を学習するために、m = 200のニューロンを持つ全結合、畳み込み、残余ネットワークを考慮します。各データ/学習者ペアに対して、我々はSGDを0.9のモーメンタムで使用し、テスト精度",畳み込み,сверточный,сверточные,сверточный
1047,convolutional architecture,العمارة التلافيفية,الهندسة التبادلية التناظرية,معمارية متموجة,卷积架构,卷积架构,卷积架构,architecture convolutive,- Architecture convolutionnelle,architecture convolutionnelle,畳み込みアーキテクチャ,畳み込みアーキテクチャ (Convolutional Architecture),畳み込みアーキテクチャ,сверточная архитектура,сверточная архитектура,свёрточная архитектура
1048,convolutional block,كتلة تلافيفية,كتلة تحويلية,الكتل التحويلية,卷积块,卷积块,卷积块,bloc convolutif,bloc de convolution,blocs convolutionnels,畳み込みブロック,畳み込みブロック,畳み込みブロック,сверточный блок,сверточный блок,сверточный блок
1049,convolutional decoder,وحدة فك التشفير التلافيفية,مفكك تحويلي,مُفكِّك التضمين,卷积解码器,卷积解码器,卷积解码器,décodeur convolutif,décodeur convolutionnel,décodeur convolutionnel,畳み込みデコーダ,畳み込みデコーダ,畳み込みデコーダー,сверточный декодер,сверточный декодер,свёрточный декодер
1050,convolutional encoder,التشفير التلافيفي,مُشفر تقابلي للتحويلات الطولية,مُرَمِّز متواري,卷积编码器,卷积编码器 (convolutional encoder),卷积编码器,codeur convolutif,codeur convolutionnel,encodeur convolutionnel,畳み込みエンコーダ,畳み込みエンコーダ,畳み込みエンコーダ,сверточный кодер,сверточный энкодер,сверточный кодировщик
1051,convolutional feature,ميزة تلافيفية,الميزات التحويلية,ميزات متراصة,卷积特征,卷积特征,卷积特征,caractéristique convolutive,Caractéristique de convolution,caractéristique convolutionnelle,畳み込み特徴,畳み込み特徴,畳み込み特徴量,сверточный признак,сверточные признаки,Сверточная особенность
1052,convolutional filter,مرشح تلافيفي,مرشح التباينية الفلكية,فلتر التضمين,卷积滤波器,卷积滤波器,卷积滤波器,filtre convolutif,filtre convolutif,filtre de convolution,畳み込みフィルタ,畳み込みフィルタ,畳み込みフィルタ,сверточный фильтр,- Convolutional filter - сверточный фильтр,Свёрточный фильтр
1053,convolutional kernel,نواة تلافيفية,نواة التحويلية العابرة,نواة الطي,卷积核,卷积核,卷积核,noyau convolutif,noyau de convolution,noyau de convolution,畳み込みカーネル,畳み込みカーネル (Convolutional Kernel),畳み込み核,сверточное ядро,сверточное ядро,свёрточное ядро
1054,convolutional layer,طبقة تلافيفية,الطبقة التكرارية,طبقة تحويل,卷积层,卷积层,卷积层,couche convolutive,- Couche convolutive,couche convolutionnelle,畳み込み層,畳み込み層,畳み込み層,сверточный слой,сверточный слой,свёрточный слой
1055,convolutional network,شبكة تلافيفية,شبكة تحويلية_CONVOLUTIONAL NETWORK,شبكة التراكبية,卷积网络,卷积网络,卷积网络,réseau convolutif,réseau de convolution,réseau convolutionnel,畳み込みネットワーク,畳み込みネットワーク (たたみこみネットワーク),畳み込みネットワーク,сверточная сеть,сверточная сеть,сверточная сеть
1056,convolutional neural net,الشبكة العصبية التلافيفية,شبكة عصبية تحويلية,شبكة عصبية حلزونية,卷积神经网络,卷积神经网络,卷积神经网络,réseau neuronal convolutif,réseau de neurones convolutionnels,réseau neuronal convolutionnel,畳み込みニューラルネット,畳み込みニューラルネット(Unchanged),畳み込みニューラルネット,сверточная нейронная сеть,сверточная нейронная сеть,Сверточная нейронная сеть
1057,convolutional neural network,الشبكة العصبية التلافيفية,شبكة عصبية تكرارية_CONVOLUTIONAL NEURAL NETWORK,شبكة عصبية ملتفة,卷积神经网络,卷积神经网络,卷积神经网络,réseau neuronal convolutif,- Réseau de neurones convolutionnel,réseau neuronal convolutionnel,畳み込みニューラル ネットワーク,畳み込みニューラルネットワーク (CNN),畳み込みニューラルネットワーク,сверточная нейронная сеть,сверточная нейронная сеть,Сверточная нейронная сеть
1058,convolutional representation,التمثيل التلافيفي,التمثيل التحويلي,التمثيل التراكبي,卷积表示,卷积表示,卷积表示,représentation convolutive,représentation par convolution,représentation convolutionnelle,畳み込み表現,畳み込み表現,畳み込み表現,сверточное представление,сверточное представление,сверточное представление
1059,cooling schedule,جدول التبريد,جدول تبريد,جدول التبريد,冷却时间表,冷却进度,冷却进度表,programme de refroidissement,programme de refroidissement,programme de refroidissement,冷却スケジュール,冷却スケジュール (Reikyaku Sukyūru),冷却スケジュール,график охлаждения,график охлаждения,график охлаждения
1060,coordinate ascent,تنسيق الصعود,الصعود التنسيقي,لفظ التصعيد التناسقي,坐标上升,坐标上升,坐标上升算法,coordonner la montée,ascension de coordonnées,montée coordonnée,座標上昇,座標上昇,座標上昇法,координировать восхождение,координатный подъем,координатный восхождение
1061,coordinate descent,تنسيق الهبوط,الانحدار التنازلي في التنسيق,هبوط مُتعامِد,坐标下降,坐标下降,坐标下降法,coordonnées de descente,descente de coordonnées,descente coordonnée,座標降下,座標降下 (zahyō kōka),座標降下法,координатный спуск,координатный спуск,координатный градиентный спуск
1062,coordinate descent algorithm,خوارزمية النسب الإحداثية,تكتيك الانحراف المتنسق,خوارزمية تنازل الإحداثيات,坐标下降算法,坐标下降算法,坐标下降算法,algorithme de descente de coordonnées,algorithme de descente de coordonnées,algorithme de descente coordonnée,座標降下アルゴリズム,座標降下アルゴリズム (zahyō kōka arugorizumu),座標降下アルゴリズム,алгоритм спуска по координатам,алгоритм координатного спуска,алгоритм покоординатного спуска
1063,coordinate frame,إطار الإحداثيات,الإطار الإحداثي,إطار مرجعي,坐标系,坐标系,坐标系,cadre de coordonnées,cadre de coordonnées,cadre de référence,座標フレーム,座標フレーム (zahyō fureemu),座標系,система координат,координатная система,Система координат
1064,copy mechanism,آلية النسخ,آلية النسخ,آلية النسخ,复制机制,复制机制 (copy mechanism),复制机制,mécanisme de copie,mécanisme de copie,mécanisme de copie,コピー機構,コピー機構,コピーメカニズム,механизм копирования,механизм копирования,механизм копирования
1065,core tensor,الموتر الأساسي,النواة الأساسية,​جوهر تانسوري,核心张量,核张量,核张量,tenseur de base,noyau de tenseur,noyau tensoriel,コアテンソル,コアテンソル,コアテンソル,основной тензор,ядро тензора,ядерный тензор
1066,coreference annotation,شرح المرجع الأساسي,تعليم الانصدام المشترك,ترميز المرجعية,共指注释,指代关系标注,指代标注,annotation de coréférence,- Annotation de coréférence,annotation de coréférence,共参照アノテーション,共参照注釈,共参照注釈,аннотация базовой ссылки,аннотация ядерных ссылок,сопоставление референций
1067,coreference chain,سلسلة مرجعية,سلسلة التشابه,سلسلة المرجع,共指链,"""['共指链c。在接下来的部分，我们介绍用于表示分类函数中的每个三元组的特征集。'，'我们的寿命模型在不是共指链的话语参照和是共指链的项目之间进行二元区分。我们数据中寿命分布（图1）表明这是一个自然的分割。'，'确定c是否是investment的iarg 2时，可以从c的",同位语链,chaîne de coréférence,- Chaîne de coréférence,chaîne de coréférence,相互参照チェーン,共参照鎖,照応詞連鎖,цепочка кореференции,цепочка кореференции,цепочка кореференции
1068,coreference resolution,القرار المرجعي,- تحليل التشابه النصي,حل الإشارات المتراجعة,共指消解,指代消解,同指消解,résolution de coréférence,résolution de coréférence,résolution de la coréférence,共参照解像度,共参照解析,前後参照解決,разрешение кореферента,Разрешение кореференции,разрешение кореференции
1069,coreference resolution model,نموذج القرار المرجعي,نموذج حل التشاركية,نموذج حل المرجعية,共指消解模型,指代消解模型,指代消解模型,modèle de résolution de coréférence,- Modèle de résolution de coréférence,modèle de résolution de la coréférence,共参照解決モデル,照応解決モデル,共参照解決モデル,модель разрешения кореференса,модель разрешения кореференции,модель разрешения кореференции
1070,coreference resolution system,نظام القرار المرجعي,نظام حل التشاركاتية الأساسية,نظام حل الإحالات المرجعية,共指消解系统,指代消解系统,同指消解系统,système de résolution de coréférence,- Système de résolution de coréférences,système de résolution de la coréférence,共参照解決システム,共参照解決システム,参照呼び解決システム,система разрешения кореференции,система разрешения кореференции,система разрешения корефренции
1071,coreferent,com.coreferent,مشارك في الإشارة,مترابطة,共指,共指 (gòng zhǐ),指同,coréférent,coreférent,coréférents,共参照,"""[...] coreferent word pairs, the words' maps greatly overlap, indicating coreferent understanding during generation. [...]""",同参照,кореферент,кореферентный,кореферентный
1072,correlate equilibrium,ربط التوازن,توازن مترابط,توازن ارتباطي,关联均衡,相关均衡,相关均衡,corréler l'équilibre,corrélation équilibre,équilibre corrélé,相関平衡,相関均衡 (Sōkan Kinkō),相関均衡,коррелировать равновесие,коррелированное равновесие,Коррелированное равновесие
1073,correlated equilibria,التوازنات المترابطة,توازنات ترابطية,توازنات متراصة,相关平衡,相关均衡,相关均衡,équilibres corrélés,équilibres corrélés,équilibres corrélés,相関平衡,相関均衡,相関された均衡,коррелированные равновесия,коррелированные равновесия,коррелированные равновесия
1074,correlation coefficient,معامل الارتباط,معامل الارتباط,معامل الارتباط,相关系数,相关系数,相关系数,Coefficient de corrélation,coefficient de corrélation,coefficient de corrélation,相関係数,相関係数,相関係数,коэффициент корреляции,Коэффициент корреляции,коэффициент корреляции
1075,correspondence matrix,مصفوفة المراسلات,مصفوفة المراسلة,مصفوفة التوافق,对应矩阵,对应矩阵,对应矩阵,matrice de correspondance,matrice de correspondance,matrice de correspondance,対応行列,対応行列 (taio gyouretsu),対応行列,матрица соответствия,матрица соответствия,матрица соответствий
1076,cosine,جيب التمام,جيب قوسي,تمام الزاوية,余弦,余弦,余弦,cosinus,cosinus,cosinus,余弦,コサイン,コサイン,косинус,косинус,косинус
1077,cosine decay,تسوس جيب التمام,تراجع الكوساين,انحدار جيبي تمامي,余弦衰减,余弦衰减,余弦衰减,désintégration du cosinus,décroissance cosinus,décroissance cosinus,コサイン減衰,コサイン減衰 (cosine decay),コサイン減衰,косинусный распад,косинусное затухание,косинусное затухание
1078,cosine decay schedule,جدول تسوس جيب التمام,جدول تحلل الكوساين,جدول التناقص الجيبي التربيعي,余弦衰减表,余弦衰减计划,余弦衰减调度,calendrier de désintégration du cosinus,- Calendrier de décroissance du cosinus,programme de décroissance cosinus,コサイン減衰スケジュール,コサイン減衰スケジュール,コサイン減衰スケジュール,график затухания косинуса,- Косинусное расписание убывания,косинусоидальный график уменьшения скорости обучения
1079,cosine learning rate schedule,جدول معدل التعلم جيب التمام,جدول تعلم معدل الجيب,جدول معدل التعلم الجيبي,余弦学习率表,余弦学习率调度,余弦学习率时间表,barème des taux d'apprentissage du cosinus,- Cosinus calendrier d'apprentissage,programme de diminution du taux d'apprentissage cosinus,コサイン学習率スケジュール,コサイン学習率スケジュール,コサイン学習率スケジュール,график скорости обучения косинуса,график скосинусного обучения с шагом обучения,расписание темпа обучения по косинусу
1080,cosine measure,قياس جيب التمام,قياس الجيبية,قياس جيب التمام,余弦测量,余弦相似度,余弦测度,mesure du cosinus,mesure du cosinus,mesure cosinus,コサイン測定,コサイン類似度,コサイン類似度,косинусная мера,косинусная мера,косинусная мера
1081,cosine schedule,جدول جيب التمام,الجدول الكوسيني,جدول جيب التمام,余弦时间表,余弦调度,余弦衰减,horaire cosinus,emploi de la planification du cosinus,rythme cosinus,コサインスケジュール,コサインスケジュール,コサイン減衰スケジュール,косинус график,косинусное расписание,косинусоидальное расписание
1082,cosine similarity measure,قياس التشابه جيب التمام,قياس التشابه بزاوية الجيب,مقياس التشابه التربيعي,余弦相似度度量,余弦相似度测量,余弦相似度衡量,mesure de similarité cosinus,- Mesure de similarité cosinus,mesure de similarité cosinus,コサイン類似度測定,コサイン類似度測定,コサイン類似度尺度,косинусная мера подобия,"""['Затем мы сгруппировали эти векторы с использованием алгоритма групповой агломерации с использованием косинусного сходства (Manning et al., 2008). Это сходство подходит, потому что оно сравнивает угол между векторами и не зависит от их величины (величина прямых в",косинусная мера сходства
1083,cost function,دالة التكلفه,وظيفة التكلفة,دالة التكلفة,成本函数,成本函数,代价函数,fonction de coût,fonction de coût,fonction de coût,コスト関数,コスト関数 (Cost function),費用関数,функция стоимости,функция стоимости,функция стоимости
1084,cost vector,ناقلات التكلفة,متجه التكلفة,مِتجه التكاليف,成本向量,成本向量,成本向量,vecteur de coût,- Vecteur de coûts,vecteur de coût,コストベクトル,コストベクトル,コストベクトル,вектор затрат,вектор стоимости,вектор стоимости
1085,cost volume,حجم التكلفة,حجم التكلفة,حجم التكلفة,成本量,成本体积,成本体积,volume des coûts,volume de coût,volume de coût,コストボリューム,コストボリューム,コスト体積,объем затрат,стоимость объема,стоимостный обьем
1086,cost-sensitive learning,التعلم الحساس للتكلفة,التعلم الذي يأخذ في الاعتبار التكلفة,التعلم الحساس للتكلفة,成本敏感型学习,成本敏感学习,成本敏感学习,apprentissage sensible aux coûts,apprentissage sensible au coût,apprentissage sensible au coût,コスト重視の学習,コスト感知学習,コスト感知学習,экономичное обучение,обучение с учетом стоимости,обучение с учетом стоимости
1087,counterexample,مكافحة المثال,مثال مضاد,مثال نقض,反例,反例,反例,contre-exemple,contre-exemple,contre-exemple,反例,反例,反例,контрпример,контрпример,контрпример
1088,counterfactual datum,مسند مخالف للواقع,بيانات مضادة,بيانات افتراضية,反事实数据,反事实数据 (fǎn shìshí shùjù),反事实数据,donnée contrefactuelle,donnée contrefactuelle,donnée contrefactuelle,反事実的なデータ,対事実データ,反実データ,контрфактические данные,контрфактические данные,контрфактические данные
1089,counterfactual example,مثال مضاد,المثال المضاد للواقع,أمثلة خاطئة,反事实例子,对立事例 (counterfactual example),反事实例子,exemple contrefactuel,exemple contrefactuel,exemple contrefactuel,反事実の例,カウンターファクチュアルの例 (Kauntāfakuchuaru no rei),反実仮想例,контрфактический пример,контрфактический пример,контрпример
1090,counterfactual fairness,العدالة المضادة,العدالة الافتراضية,عدالة الحالات البديلة,反事实公平,反事实公平,反事实公平,équité contrefactuelle,équité contrefactuelle,équité contrefactuelle,反事実の公平性,反事実的公平性 (Counterfactual fairness),反事実的公平性,контрфактическая справедливость,контрфактическая справедливость,контрфактическая справедливость
1091,counterfactual reasoning,المنطق المضاد,الاستدلال المضاد,الاستدلال المضاد للحقائق,反事实推理,反事实推理,反事实推理,raisonnement contrefactuel,raisonnement contrefactuel,raisonnement contrefactuel,反事実的な推論,仮説的推論,反実仮想推論,контрфактические рассуждения,контрфактуальное рассуждение,контрфактическое рассуждение
1092,counterfactual regret minimization,التقليل من الندم المضاد,"""['من أجل استخدام خوارزميات التكرار مثل تقنية الفجوة الزائدة أو تقليل الندم الافتراضي المضاد (CFR)، يمكن أن يستخدم المرء لعبة الأداة الموصوفة من قبل مور","التقليل من الأسف المضاد للواقع

CFR",反事实后悔最小化,反事实后悔最小化,反事实遗憾最小化 (CFR),minimisation contrefactuelle des regrets,minimisation des regrets contrefactuels,minimisation du regret contrefactuel,反事実的な後悔の最小化,反事実的後悔最小化,反事実的後悔最小化 (CFR),минимизация контрфактического сожаления,минимизация регретов контрфактуальных,минимизация контрфактуального сожаления (CFR)
1093,covariance function,وظيفة التغاير,دالة التباين,دالة التغاير,协方差函数,协方差函数,协方差函数,fonction de covariance,- Fonction de covariance,fonction de covariance,共分散関数,共分散関数 (kyoubunsan kansuu),共分散関数,ковариационная функция,функция ковариации,функция ковариации
1094,covariance kernel,نواة التغاير,نواة التشتت المشترك,نواة التغاير,协方差核,协方差核,协方差核函数,noyau de covariance,noyau de covariance,noyau de covariance,共分散カーネル,共分散カーネル,共分散カーネル,ковариационное ядро,ядерная ковариация,ковариационное ядро
1095,covariance matrix,مصفوفة التغاير,مصفوفة التباين,مصفوفة التغاير,协方差矩阵,协方差矩阵,协方差矩阵,matrice de covariance,- Matrice de covariance,matrice de covariance,共分散行列,共分散行列 (kyoubunsan gyouryoku),共分散行列,ковариационная матрица,матрица ковариации,матрица ковариации
1096,covariance model,نموذج التغاير,نموذج التباين المشترك,نموذج التغاير,协方差模型,协方差模型 (covariance model),协方差模型,modèle de covariance,- Modèle de covariance,modèle de covariance,共分散モデル,共分散モデル,共分散モデル,ковариационная модель,модель ковариации,Ковариационная модель
1097,covariance operator,عامل التغاير,مشغل التباين,عامل التباين المشترك,协方差算子,协方差算子,协方差算子,opérateur de covariance,opérateur de covariance,opérateur de covariance,共分散演算子,共分散演算子,共分散演算子,ковариационный оператор,оператор ковариации,оператор ковариации
1098,covariance parameter,معلمة التغاير,معلمات التباين,معامل التباين المشترك,协方差参数,协方差参数,协方差参数,paramètre de covariance,paramètre de covariance,paramètre de covariance,共分散パラメータ,共分散パラメータ,共分散パラメータ,параметр ковариации,параметр ковариации,Параметр ковариации
1099,covariance structure,هيكل التغاير,هيكل التباين المشترك,بنية التغاير,协方差结构,协方差结构,协方差结构,structure de covariance,structure de covariance,structure de covariance,共分散構造,共分散構造,共分散構造,ковариационная структура,структура ковариации,структура ковариации
1100,covariant derivative,مشتق مشترك,المشتقة التعاقبية,المشتقة المتجانسة,协变导数,共ariant导数,协变导数,dérivée covariante,dérivée covariante,dérivée covariante,共変導関数,共変導関数,同次微分,ковариантная производная,ковариантная производная,ковариантная производная
1101,covariate,متغير مشترك,متغير تعديلي,متغير مصاحب,协变量,协变量,协变量,covariable,covariable,covariable,共変量,共変量,共変量,ковариата,"""['Однако эти условия необходимо значительно усилить, чтобы учесть возможное смешение между X и Y, которое, даже при отсутствии смещения выборки, может потребовать корректировки для допустимых коэффициентов, а именно для коэффициентов, которые удовлетворяют",ковариат
1102,covariate shift,التحول المتغير,تحول المتغيرات الرئيسية,تحول المتغيرات المصاحبة,协变量平移,协变量转移,协变量偏移,changement de covariable,décalage de covariable,changement de covariable,共変量シフト,共変量シフト (Covariate Shift),共変量シフト,ковариатный сдвиг,сдвиг ковариативов,сдвиг ковариации
1103,credit assignment,مهمة الائتمان,تخصيص الائتمان,نسبة الفضل,学分分配,信用分配,贷记分配,cession de crédit,attribution de crédit,imputation de crédit,単位の割り当て,クレジット割り当て (credit assignment),クレジット割り当て,кредитное присвоение,присвоение кредита,распределение кредита
1104,credit assignment problem,مشكلة تخصيص الائتمان,مشكلة توزيع الائتمان,مشكلة تخصيص الائتمان,学分分配问题,学分分配问题,贷款分配问题,problème d'attribution de crédit,problème d'attribution de crédit,problème d'attribution du crédit,単位の割り当ての問題,クレジット割り当て問題,帰属問題,проблема с присвоением кредита,Проблема присвоения кредита,проблема присвоения заслуг
1105,criterion,معيار,معيار,معيار,标准,标准,准则,critère,critère,critère,基準,基準 (きじゅん),基準,критерий,критерий,критерий
1106,critic,الناقد,الناقد,ناقد,评论家,评论家,评价者,critique,critique,critique,評論家,"""COMAの集中型批評家はこの証明が成立するために不可欠である。""",評価者,критик,критик,критик
1107,critic loss,خسارة الناقد,خسارة النقاد,خسارة الناقد,评论家损失,评论家损失,评判器损失,perte de critique,perte de critique,perte du critique,批評家の損失,クリティック損失 (critic loss),評価損失 (hyōka sonshitsu),потеря критика,критический потеря,Потери критика
1108,critic network,شبكة الناقد,شبكة النقدية,شبكة النقد,评论家网络,评论者网络,评价网络,réseau critique,réseau de critique,réseau critique,批評家ネットワーク,評価者ネットワーク,評価者ネットワーク,сеть критиков,сеть критика,Сеть критика
1109,cross attention,عبر الاهتمام,الانتباه المشترك,انتباه متقاطع,交叉注意力,交叉注意力,交叉注意力,attention croisée,attention croisée,attention croisée,クロスアテンション,クロスアテンション,クロス注目,перекрестное внимание,перекрестное внимание,перекрестное внимание
1110,cross entropy,عبر الانتروبيا,التقاطع الإنتروبي,التربية المتقاطعة,交叉熵,交叉熵,交叉熵,entropie croisée,entropie croisée,entropie croisée,クロスエントロピー,クロスエントロピー,交差エントロピー,перекрестная энтропия,кросс-энтропия,Перекрёстная энтропия
1111,cross entropy error,خطأ الانتروبيا المتقاطعة,خطأ الانحدار المتقاطع,خطأ الإنتروبيا المتقاطعة,交叉熵误差,交叉熵错误 (Cross Entropy Error),交叉熵误差,erreur d'entropie croisée,erreur d'entropie croisée,erreur d'entropie croisée,クロスエントロピーエラー,クロスエントロピー誤差,交差エントロピー誤差,ошибка перекрестной энтропии,ошибка перекрёстной энтропии,перекрестная энтропийная ошибка
1112,cross entropy loss,خسارة الانتروبيا المتقاطعة,الخسارة المتقاطعة للتراكب,خسارة الاكتروبي المتقاطع,交叉熵损失,交叉熵损失,交叉熵损失,perte d'entropie croisée,perte d'entropie croisée,perte d'entropie croisée,クロスエントロピー損失,クロスエントロピー損失 (Cross Entropy Loss),交差エントロピー損失,перекрестная потеря энтропии,потеря перекрестной энтропии,перекрёстная энтропийная потеря
1113,cross validation,عبر المصادقة,التقسيم المتقاطع,تحقق متقاطع,交叉验证,交叉验证,交叉验证,validation croisée,validation croisée,validation croisée,相互検証,クロスバリデーション (Cross Validation),交差検証,перекрестная проверка,перекрестная проверка,перекрестная проверка
1114,cross-attention layer,طبقة عبر الاهتمام,طبقة التركيز المتقاطع,طبقة الانتباه المتقاطع,交叉注意力层,跨关注层,交叉注意力层,couche d'attention croisée,- Couche d'attention croisée,couche d'attention croisée,クロスアテンション層,クロスアテンション層 (kurosu atenshon sō),相互注目層,слой перекрестного внимания,Слой взаимного внимания,слой кросс-внимания
1115,cross-attention module,وحدة الاهتمام المتبادل,وحدة الانتباه المتقاطعة,وحدة الانتباه المتقاطع,交叉注意力模块,交叉注意力模块,交叉注意力模块,module d'attention croisée,module d'attention croisée,module d'attention croisée,クロスアテンションモジュール,クロスアテンションモジュール (kurosu atenshon mojuru),クロス注目モジュール,модуль перекрестного внимания,модуль перекрестного внимания,модуль перекрёстного внимания (cross-attention module)
1116,cross-correlation,الارتباط المتبادل,تقاطع الإرتباط,ارتباط متقاطع,互相关,交叉相关,互相关,corrélation croisée,corrélation croisée,Intercorrélation,相互相関,クロス相関 (Kurosu Sōkan),相互相関,взаимная корреляция,кросс-корреляция,сверточная кросс-корреляция
1117,cross-entropy loss function,وظيفة فقدان الانتروبيا,وظيفة فقد العشوائية المتشابكة,دالة خسارة الانتروبيا المتقاطعة,交叉熵损失函数,交叉熵损失函数,交叉熵损失函数,fonction de perte d'entropie croisée,fonction de perte de l'entropie croisée,fonction de perte d'entropie croisée,クロスエントロピー損失関数,交差エントロピー損失関数 (kousa entoropii sonshitsu kansuu),交差エントロピー損失関数,функция перекрестных энтропийных потерь,функция потерь перекрестной энтропии,функция потерь перекрёстной энтропии
1118,cross-entropy objective,الهدف عبر الانتروبيا,هدف الانحدار المتقاطع,هدف الانتروبيا المتقاطعة,交叉熵目标,交叉熵目标,交叉熵目标,objectif d'entropie croisée,objectif de cross-entropie,objectif d'entropie croisée,クロスエントロピー目標,クロスエントロピー目的関数 (Kurosuentoropy mokuteki kansū),交差エントロピー目的関数,перекрестная энтропия,кросс-энтропийный объектив,Целевая функция перекрёстной энтропии
1119,cross-lingual benchmark,المعيار بين اللغات,معيار متعدد اللغات,مقياس قطاعي اللغات,跨语言基准,跨语言基准测试,跨语言基准测试,référence multilingue,référentiel multilingue,référentiel inter-langues,言語を超えたベンチマーク,クロス言語ベンチマーク,言語横断ベンチマーク,межъязыковый тест,кросс-языковой бенчмарк,межъязыковой эталон
1120,cross-lingual embedding,التضمين عبر اللغات,تضمين بين اللغات,تضمين متعدد اللغات,跨语言嵌入,跨语言嵌入,跨语言嵌入,intégration multilingue,incorporation interlingue,plongement interlingue,言語を越えた埋め込み,クロスリンガル埋め込み,言語横断埋め込み,межъязыковое встраивание,кросс-языковое вложение,кросс-лингвистическое встраивание
1121,cross-lingual feature,ميزة عبر اللغات,الميزات العابرة للغات,ميزة متعددة اللغات,跨语言特征,跨语言特征,跨语言特征,fonctionnalité multilingue,caractéristique interlingue,caractéristique cross-lingue,クロスリンガル機能,"""['異種リソースの整合性を取る。前述したように、モデルアーキテクチャのユニバーサルエンコーダーは、我々のシステムが異なる形式論で重要な言語間特徴を学習するように強制する。', '我々の分析によると、最近の事",言語横断的特徴,межъязыковая функция,кросс-языковая особенность,межъязыковые признаки
1122,cross-lingual knowledge transfer,نقل المعرفة بين اللغات,نقل المعرفة العابرة للغات,نقل المعرفة عبر اللغات,跨语言知识转移,跨语言知识传递,跨语言知识迁移,transfert de connaissances multilingue,Transfert de connaissances interlinguales,transfert de connaissances translinguistique,言語を超えた知識の伝達,異言語間知識転移 (Cross-lingual knowledge transfer),言語横断知識転移,межъязыковая передача знаний,межъязыковой передачи знаний,перенос знаний между языками
1123,cross-lingual model,نموذج عبر اللغات,- التصنيف اللغوي المتقاطع,نموذج متعدد اللغات,跨语言模型,跨语言模型,跨语言模型,modèle multilingue,modèle multilingue,modèle multilingue,クロスリンガルモデル,クロスリンガルモデル,言語横断モデル,межъязыковая модель,модель межъязыковая,перекрёстноязыковая модель
1124,cross-lingual representation,التمثيل بين اللغات,التمثيل العابر للغات,التمثيل متعدد اللغات,跨语言表示,跨语言表示,跨语种表征,représentation multilingue,représentation interlingue,représentation inter-langues,言語を超えた表現,クロスリンガル表現,言語横断表現,межъязыковое представительство,- Перекрестное языковое представление,межъязыковое представление
1125,cross-lingual transfer,نقل عبر اللغات,- النقل اللغوي المتبادل,النقل اللغوي المتعدد,跨语言迁移,跨语言转移,跨语言迁移,transfert multilingue,"""Cela confirme que les effets bénéfiques du transfert interlingue ne compensent pas les gains obtenus grâce à des données de meilleure qualité.""",transfert inter-lingue,言語を越えた転送,異言語間転送,言語横断転移,межъязыковой перевод,межъязыковой трансфер,межъязыковой перенос
1126,cross-modal,عبر الوسائط,- تعدد الوسائط,متعدد الوسائط,跨模式,跨模态 (kuà móshì),跨模态,multimodal,"""Plusieurs études récentes (Cho et al., 2021 ; Wang et al., 2022a,c ; Lu et al., 2022) ont également commencé à construire un cadre de pré-formation unifié pour gérer un ensemble diversifié de tâches cross-modales et unimodales. La reconnaissance des lieux joue un rôle important dans la perception collaborative multirobot, telle que la recherche et le sauvetage aéroterrestre, afin d'identifier le même endroit qu'ils ont visit",multimodal,クロスモーダル,クロスモーダル,複数モダル,кросс-модальный,кросс-модальный,межмодальный
1127,cross-validate,التحقق من صحة,التقييم الصليبي,تحقق تصليبي متبادل,交叉验证,交叉验证 (cross-validate),交叉验证,validation croisée,valider croisée,valider croisée,相互検証,クロスバリデーション,交差検証する,перекрестная проверка,кросс-валидация,Кросс-валидировать
1128,cumulant generating function,وظيفة توليد تراكمية,وظيفة توليد الكميات الفردية,دالة توليد المُجَمِّع,累积生成函数,累积生成函数,累积矩生成函数,fonction génératrice de cumulant,fonction génératrice de cumulants,fonction génératrice des cumulants,キュムラント生成関数,累積生成関数,モーメント母関数の対数、累乗母関数,кумулянтная производящая функция,функция кумулянтового порождения,функция порождающая кумулянты
1129,cumulative density function,دالة الكثافة التراكمية,دالة الكثافة التراكمية,دالة الكثافة التراكمية,累积密度函数,累积密度函数,累积分布函数,fonction de densité cumulée,fonction de densité cumulée,fonction de répartition,累積密度関数,累積密度関数,累積分布関数,кумулятивная функция плотности,кумулятивная функция плотности,функция кумулятивного распределения
1130,cumulative distribution function,دالة التوزيع التراكمي,الدالة التوزيع التراكمي الإجمالي,دالة التوزيع التراكمية,累积分布函数,累积分布函数,累积分布函数,fonction de distribution cumulative,- Fonction de distribution cumulative,fonction de répartition,累積分布関数,累積分布関数,累積分布関数,кумулятивная функция распределения,кумулятивная функция распределения,функция кумулятивного распределения
1131,cumulative regret,الندم التراكمي,الندم التراكمي,ندم تراكمي,累积的遗憾,累积遗憾,累积遗憾,regret cumulatif,regret cumulatif,regret cumulé,累積した後悔,累積後悔,累積後悔,накопительное сожаление,Накопленное сожаление,Суммарное сожаление
1132,cumulative reward,مكافأة تراكمية,المكافأة التراكمية,المكافأة التراكمية,累积奖励,累积奖励,累积回报,récompense cumulée,récompense cumulée,récompense cumulative,累計報酬,累積報酬,累積報酬,накопительное вознаграждение,кумулятивное вознаграждение,суммарное вознаграждение
1133,curriculum learning,تعلم المناهج الدراسية,تعلم المنهجية,التعلم المنهجي,课程学习,课程学习,课程学习,programme d'apprentissage,"""L'apprentissage de programme existant (Wei et al., 2021) varie le taux de perturbation au niveau des mots pour atteindre différents niveaux de difficulté dans le cadre de l'apprentissage de programme avec des stratégies simples de perturbation de mots telles que le remplacement de synonymes, l'insertion aléatoire, l'échange et la suppression.""",apprentissage par curriculum,カリキュラム学習,カリキュラム学習 (Karikyuramu gakushū),カリキュラム学習,обучение по учебной программе,обучение по учебным планам,обучение по учебному плану
1134,curse of dimensionality,لعنة الأبعاد,لعنة الأبعاد,لعنة الأبعاد,维数诅咒,维度灾难,维数灾难,malédiction de la dimensionnalité,- Malédiction de la dimensionnalité,fléau de la dimensionnalité,次元の呪い,次元の呪い (jigen no noroi),次元の呪い,проклятие размерности,проклятье размерности,проклятие размерности
1135,cut plane,قطع الطائرة,المستوى القاطع,سطح القطع,切面,切割平面,切割平面,plan de coupe,plan de découpe,plan de coupe,切断面,カットプレーン,切断平面,разрезная плоскость,плоскость разделения,Секущая плоскость
1136,cut plane algorithm,خوارزمية قطع المستوى,خوارزمية الطائرة القاطعة,خوارزمية المستوى القاطع,剖切面算法,切平面算法,割平面算法,algorithme de plan de coupe,algorithme du plan de coupe,algorithme de plan de coupe,切断面アルゴリズム,カットプレーンアルゴリズム,切断平面アルゴリズム,алгоритм сечения плоскости,алгоритм разделяющей плоскости,Алгоритм отсекающей плоскости
1137,cut plane method,طريقة قطع الطائرة,طريقة القطع الطائفية,طريقة المستوى المقطوع,剖切面法,切平面法,切平面法,méthode du plan de coupe,"""['La méthode du plan de coupe du centre analytique (ACCPM) réduit la région admissible à chaque itération en utilisant une nouvelle coupe de la région admissible calculée en évaluant un sous-gradient de la fonction objectif au centre analytique de l'ensemble actuel, jusqu'à ce que le volume de la région réduite converge vers la précision cible. Cette méthode ne nécessite pas de différentiabilité.', 'Méthode du plan de coupe du centre analytique 1. Calculer",méthode des plans de coupe,切断面法,カット平面法 (cut plane method),切断平面法,метод плоскости сечения,метод разрезающей плоскости,метод секущих плоскостей
1138,cycle consistency,اتساق الدورة,الاتساق الدوري,اتساق الدورة,循环一致性,循环一致性,循环一致性,cohérence du cycle,cohérence de cycle,consistance cyclique,サイクルの一貫性,サイクル整合性,循環一貫性,постоянство цикла,циклическая согласованность,цикловая согласованность
1139,cycle consistency loss,فقدان اتساق الدورة,فقدان الاتساق في الدورة,خسارة اتساق الدورة,循环一致性损失,循环一致性损失,循环一致性损失,perte de cohérence du cycle,perte de cohérence de cycle,perte de cohérence cyclique,サイクルの一貫性の損失,サイクル一貫性損失,サイクル一貫性損失,потеря согласованности цикла,потеря последовательности цикла,потери цикличной согласованности
1140,cycle inequality,عدم المساواة في الدورة,عدم المساواة دورية,عدم تساوي الدورات,循环不等式,循环不等式,环不等式,inégalité des cycles,inégalité de cycle,inégalités de cycle,サイクルの不平等,サイクル不等式,環不等式,неравенство цикла,неравенства циклов,цикловое неравенство
1141,d-separation,د- الانفصال,"""مثلاً، قد تكون هناك تمثيلات هيكلية (رسومية) لأنواع معينة من التبادل الجزئي وبراهين منطقية مقابلة (بيرل 1988). وعلاوة على ذلك، سيكون من المثير للاهتمام تطوير نماذج ر",مُنفصل-د,d-分离,d-分离,无关路径分离,d-séparation,d-séparation,déséparer,d分離,d-分離,d-分離,d-разделение,d-разделение,обособление
1142,d_model,d_model,النموذج الديناميكي (d_model),أبعاد النموذج,d_模型,d_模型,模型维度,d_modèle,d_model,dimension_modèle,d_model,dモデル,モデル次元数,d_модель,d_model,разм_модели
1143,data augmentation,زيادة البيانات,تعزيز البيانات,زيادة البيانات,数据增强,数据增强,数据增强,augmentation des données,augmentation de données,augmentation des données,データ増強,データ拡張 (データ augmentation),データ拡張,увеличение данных,аугментация данных,увеличение данных
1144,data distribution,توزيع البيانات,توزيع البيانات,توزيع البيانات,数据分布,数据分布,数据分布,répartition des données,- Distribution de données,distribution des données,データ配信,データ分布,データ分布,распределение данных,распределение данных,распределение данных
1145,data imbalance,خلل في البيانات,عدم توازن البيانات,عدم توازن البيانات,数据不平衡,数据不平衡,数据不平衡,déséquilibre des données,déséquilibre des données,déséquilibre des données,データの不均衡,データの不均衡,データ不均衡,дисбаланс данных,дисбаланс данных,дисбаланс данных
1146,data manifold,مشعب البيانات,متعدد البيانات,مضغوط البيانات,数据流形,数据流形,数据流形,collecteur de données,variété de données,Variété des données,データマニホールド,データ多様体,データ多様体,коллектор данных,многообразие данных,множество данных
1147,data mining,بيانات التعدين,تنقيب البيانات,تنقيب البيانات,数据挖掘,数据挖掘 (shùjù wājié),数据挖掘,exploration de données,fouille de données,fouille de données,データマイニング,データマイニング,データマイニング,сбор данных,добыча данных,майнинг данных
1148,data point,نقطة البيانات,نقطة البيانات,نقطة البيانات,数据点,数据点,数据点,point de données,point de données,point de données,データポイント,データポイント,データポイント,точка данных,точка данных,точка данных
1149,data processing inequality,عدم المساواة في معالجة البيانات,عدم المساواة في معالجة البيانات,عدم مساواة معالجة البيانات,数据处理不平等,数据处理不等式,数据处理不等式,inégalité dans le traitement des données,Inégalité du traitement des données,inégalité de traitement des données,データ処理の不平等,データ処理不等式 (data processing inequality),データ処理の不等式,неравенство в обработке данных,неравенство обработки данных,неравенство обработки данных
1150,data sparseness,تناثر البيانات,تندرج البيانات,ندرة البيانات,数据稀疏性,数据稀疏,数据稀疏性,rareté des données,rareté des données,rareté des données,データの希薄性,データの希薄化,データ希薄性,разреженность данных,разреженность данных,разреженность данных
1151,data sparsity,تناثر البيانات,ندرة البيانات,نُدرة البيانات,数据稀疏性,数据稀疏性,数据稀疏性,rareté des données,rareté des données,Rareté des données,データの疎性,データの希薄化,データ希薄性,разреженность данных,Разреженность данных,недостаточность данных
1152,data structure,بنية البيانات,هيكل البيانات,هيكلية البيانات,数据结构,数据结构,数据结构,Structure de données,structure de données,structure de données,データ構造,データ構造,データ構造,структура данных,структура данных,структура данных
1153,data vector,ناقلات البيانات,- متجه البيانات,متجه البيانات,数据向量,数据向量,数据向量,vecteur de données,vecteur de données,vecteur de données,データベクトル,データベクトル,データベクトル,вектор данных,вектор данных,вектор данных
1154,data-to-text generation,توليد البيانات إلى النص,إنتاج النصوص من البيانات,توليد النص من البيانات,数据到文本生成,数据到文本生成,数据到文本生成,génération de données en texte,génération de texte à partir de données,génération de données en texte,データからテキストへの生成,データからテキスト生成,データからテキストを生成する,генерация данных в текст,генерация текста из данных,генерация текста из данных
1155,datalog program,برنامج سجل البيانات,برنامج داتالوغ,برنامج بيانات لوج,数据记录程序,数据日志程序 (datalog program),数据库逻辑程序,programme d'enregistrement de données,programme Datalog,programme de datalog,データログプログラム,データログプログラム,データログプログラム,программа регистрации данных,программа datalog,программа на языке Datalog
1156,dataset augmentation,زيادة مجموعة البيانات,توسيع مجموعة البيانات,توسيع مجموعة البيانات,数据集扩充,数据集增强,数据集增强,augmentation de l'ensemble de données,augmentation de jeu de données,augmentation de l'ensemble de données,データセットの拡張,データセット拡張,データセット拡張,увеличение набора данных,увеличение набора данных,увеличение набора данных
1157,dataset bias,تحيز مجموعة البيانات,تحيز البيانات,تحيز مجموعة البيانات,数据集偏差,数据集偏差,数据集偏差,biais de l'ensemble de données,biais de jeu de données,biais des données,データセットの偏り,データセットの偏り,データセットのバイアス,смещение набора данных,набор данных смещения,смещение набора данных
1158,dataset size,حجم مجموعة البيانات,حجم مجموعة البيانات,حجم مجموعة البيانات,数据集大小,数据集大小,数据集大小,taille de l'ensemble de données,- Taille de l'ensemble de données,taille de l'ensemble de données,データセットのサイズ,データセットサイズ,データセットサイズ,размер набора данных,размер набора данных,размер набора данных
1159,datasheet,ورقة البيانات,- تعليمات البيانات,نشرة البيانات,数据表,数据表,数据表,Fiche de données,fiche de données,fiche de données,データシート,データシート,データシート,техническая спецификация,документация данных,информационный листок
1160,datum bias,تحيز مسند,تحيز البيانات,انحياز البيانات,数据偏差,数据偏倚,数据偏差,biais de référence,biais de données,biais de données,データムバイアス,データの偏り,データ偏り,смещение исходных данных,смещение данных,смещение данных
1161,datum clustering,تجميع مسند,تجميع البيانات,تجميع البيانات,数据聚类,数据聚类,数据聚类,regroupement de données,regroupement de données,regroupement de données,データムクラスタリング,データクラスタリング (data clustering),データクラスタリング,кластеризация данных,кластеризация данных,кластеризация данных
1162,datum contamination,تلوث المسند,تلوث البيانات,تلوث البيانات,数据污染,数据污染,数据污染,contamination des données,contamination des données,contamination des données,データムの汚れ,データの汚染,データ汚染,загрязнение данных,загрязнение данных,загрязнение данных
1163,datum dependency,التبعية مسند,التبعية البيانية,اعتماد البيانات,数据依赖性,数据依赖,数据依赖性,dépendance aux données,- Dépendance de données,dépendance de données,データム依存性,データ依存関係,データ依存性,зависимость от исходных данных,зависимость данных,Зависимость данных
1164,datum fidelity,الإخلاص المسند,دقة البيانات,صِدق البيانات,数据保真度,数据保真度,数据保真度,fidélité aux données,fidélité des données,fidélité des données,データム忠実度,データの忠実度,データ忠実性,точность исходных данных,точность данных,точность данных
1165,datum filtering,تصفية المسند,تصفية البيانات,تصفية البيانات,数据过滤,数据筛选,数据过滤,filtrage des données,filtrage des données,filtrage des données,データムフィルタリング,データフィルタリング (Dēta firutaringu),データのフィルタリング,фильтрация данных,фильтрация данных,обработка данных
1166,datum generative process,عملية توليد المسند,عملية تكوين البيانات,عملية توليد البيانات,数据生成过程,数据生成过程 (datum generative process),数据生成过程,processus générateur de données,processus de génération de données,processus génératif de données,データム生成プロセス,データ生成プロセス (Data Sousei Process),データ生成プロセス,процесс создания данных,процесс генерации данных,процесс генерации данных
1167,datum matrix,مصفوفة مسند,مصفوفة بيانات,مصفوفة البيانات,数据矩阵,数据矩阵,数据矩阵,matrice de données,- Matrice de données,matrice de données,データム行列,データ行列,データ行列,базовая матрица,матрица данных,матрица данных
1168,datum mining algorithm,خوارزمية التعدين المسند,- تعدين البيانات وخوارزمية البيانات,خوارزمية تنقيب البيانات,数据挖掘算法,数据挖掘算法 (datum mining algorithm),数据挖掘算法,algorithme d'exploration de données,algorithme d'exploration de données,algorithme d'exploration de données,データマイニングアルゴリズム,データマイニングアルゴリズム (datum mining algorithm),データマイニングアルゴリズム,алгоритм извлечения данных,алгоритм добычи данных,Алгоритм интеллектуального анализа данных
1169,datum parallelism,مسند التوازي,توازن البيانات,تَوازِي البَيانات,基准平行度,数据并行ism,数据并行,parallélisme des références,parallélisme des données,parallélisme de données,データム平行度,データ並列化,データ並列,базовый параллелизм,параллелизм данных,параллелизм данных
1170,datum perturbation,اضطراب مسند,تشويش البيانات,تشويش البيانات,数据扰动,数据扰动,数据扰动,perturbation des données,perturbation des données,perturbation des données,データムの摂動,- 資料摂動,データ撹乱,возмущение исходных данных,пертурбация данных,данные возмущения
1171,davinci,دا فينشي,دافنشي,داڤنشي,达芬奇,达芬奇,davinci模型,da Vinci,davinci,davinci,ダ・ヴィンチ,ダヴィンチ,davinci,Да Винчи,davinci,давинчи
1172,decay parameter,معلمة الاضمحلال,معامل التحلل,معلمة التضاؤل,衰减参数,衰减参数,衰减参数,paramètre de désintégration,paramètre de décroissance,paramètre de décroissance,減衰パラメータ,減衰パラメータ (decay parameter),減衰パラメータ,параметр затухания,параметр затухания,параметр затухания
1173,decentralized algorithm,خوارزمية لامركزية,الخوارزمية اللامركزية,خوارزمية لامركزية,去中心化算法,分散算法,去中心化算法,algorithme décentralisé,algorithme décentralisé,algorithme décentralisé,分散型アルゴリズム,分散アルゴリズム (Decentralized Algorithm),分散型アルゴリズム,децентрализованный алгоритм,децентрализованный алгоритм,децентрализованный алгоритм
1174,decentralized optimization,التحسين اللامركزي,التحسين المركزي المفكك,تحسين موزع,分散优化,分散优化,分散优化,optimisation décentralisée,optimisation décentralisée,optimisation décentralisée,分散型最適化,分散最適化 (Bunsan saiteki-ka),分散最適化,децентрализованная оптимизация,децентрализованная оптимизация,децентрализованная оптимизация
1175,decision Transformer,محول القرار,محول القرارات,محول القرار,决策变压器,决策Transformer,决策变换器,décision Transformateur,transformateur de décision,Transformateur de décision,決定トランス,決定Transformer,決定トランスフォーマ,решение Трансформатор,Decision Transformer,Преобразователь решений
1176,decision boundary,حدود القرار,حد القرارات,حد القرار,决策边界,决策边界,决策边界,limite de décision,frontière de décision,frontière de décision,決定境界,決定境界 (kettei kyoukai),決定境界,граница решения,граница принятия решений,граница решения
1177,decision function,وظيفة القرار,وظيفة القرار,دالة القرار,决策函数,决策函数,决策函数,fonction de décision,- Fonction de décision,fonction de décision,決定関数,決定関数,決定関数,функция принятия решения,Функция принятия решения,функция принятия решений
1178,decision node,عقدة القرار,عقدة القرار,عقدة القرار,决策节点,决策节点,决策节点,nœud de décision,noeud de décision,nœud de décision,意思決定ノード,決定ノード (kettei nōdo),決定ノード,узел принятия решения,узел принятия решения,узел принятия решений
1179,decision policy,سياسة القرار,سياسة القرارات,سياسة القرار,决策政策,决策策略 (Decision Policy),决策策略,politique de décision,Politique de décision,politique de décision,決定方針,意思決定方針,意思決定方針,политика принятия решений,политика принятия решений,правила принятия решений
1180,decision problem,مشكلة القرار,مشكلة اتخاذ القرارات,مشكلة القرار,决策问题,决策问题 (juédì wèntí),决策问题,problème de décision,problème de décision,problème de décision,意思決定の問題,決定問題 (けっていもんだい),決定問題,проблема решения,Проблема принятия решения,Задача принятия решения
1181,decision rule,قاعدة القرار,قاعدة القرارات,قاعدة القرار,决策规则,决策规则,决策规则,règle de décision,règle de décision,Règle de décision,決定ルール,意思決定ルール (Ishikettei rūru),決定規則,правило принятия решения,правило принятия решения,правило принятия решений
1182,decision space,مساحة القرار,مساحة القرارات,فضاء القرار,决策空间,决策空间 (jué cè kōng jiān),决策空间,espace de décision,espace de décision,espace de décision,意思決定スペース,決定空間 (けっていくうかん),決定空間,пространство решений,пространство принятия решений,Пространство решений
1183,decision stump,جذع القرار,قرار الجذع,شجرة القرار البسيطة,决策树桩,决策树桩,决策树桩,souche de décision,tronc de décision,arbre de décision élémentaire,決断の切り株,決定スタンプ,決定つんぼ,тупик решения,решающий пень,Решающее деревце
1184,decision theory,نظرية القرار,نظرية اتخاذ القرارات,نظرية القرار,决策理论,决策理论,决策理论,théorie de la décision,théorie de la décision,théorie de la décision,意思決定理論,意思決定理論 (Ishikettei Riron),意思決定理論,теория принятия решений,теория принятия решений,теория принятия решений
1185,decision tree,شجرة القرار,شجرة القرارات,شجرة القرار,决策树,决策树,决策树,arbre de décision,arbre de décision,arbre de décision,デシジョンツリー,決定木 (けっていぎ),決定木,Древо решений,дерево решений,дерево решений
1186,decision variable,متغير القرار,المتغير القراري,متغير القرار,决策变量,决策变量,决策变量,variable de décision,variable de décision,variable décisionnelle,決定変数,決定変数 (けっていへんすう),決定変数,переменная решения,переменная принятия решения,переменная решения
1187,decode algorithm,خوارزمية فك التشفير,خوارزمية فك التشفير,خوارزمية الترميز,解码算法,解码算法 (decode algorithm),解码算法,algorithme de décodage,algorithme de décodage,algorithme de décodage,デコードアルゴリズム,デコードアルゴリズム (decode algorithm),復号アルゴリズム,алгоритм декодирования,алгоритм декодирования,алгоритм декодирования
1188,decode strategy,استراتيجية فك التشفير,استراتيجية فك التشفير,استراتيجية الترميز,解码策略,解码策略,解码策略,stratégie de décodage,stratégie de décodage,stratégie de décodage,デコード戦略,デコード戦略 (decode strategy),デコード戦略,стратегия декодирования,стратегия декодирования,стратегия декодирования
1189,decoder hidden state,فك الدولة المخفية,الحالة الخفية لفك الشفرة,حالة الترميز المخفية,解码器隐藏状态,解码器隐藏状态,解码器隐藏状态,état caché du décodeur,- État caché du décodeur,état caché du décodeur,デコーダの隠し状態,デコーダー隠れ状態,デコーダー隠れ状態,скрытое состояние декодера,скрытое состояние декодера,состояние скрытого слоя декодера
1190,decoder layer,طبقة فك التشفير,طبقة فك التشفير,طبقة المُرمِّز,解码器层,解码器层,解码器层,couche de décodeur,couche de décodeur,couche de décodeur,デコーダ層,デコーダーレイヤー,デコーダ層,слой декодера,слои декодера,Слой декодера
1191,decoder network,شبكة فك التشفير,شبكة فك التشفير,شبكة الفك الترميز,解码器网络,解码器网络,解码器网络,réseau de décodeur,- Réseau de décodeur,réseau de décodage,デコーダネットワーク,デコーダーネットワーク,デコーダーネットワーク,сеть декодера,сеть декодирования,декодерная сеть
1192,decoder output,إخراج فك التشفير,ناتج فك تشفير,مُخرَجات المُفَكِّر,解码器输出,解码器输出,解码器输出,sortie du décodeur,sortie du décodeur,sortie du décodeur,デコーダ出力,デコーダー出力,デコーダ出力,выход декодера,вывод декодера,Выход декодера
1193,decoder state,حالة فك التشفير,حالة فك الترميز,حالة المفكود,解码器状态,解码器状态,解码器状态,état du décodeur,état du décodeur,état du décodeur,デコーダの状態,デコーダー状態 (decoder state),デコーダ状態,состояние декодера,состояние декодера,состояние декодера
1194,decoder-only transformer,محول فك التشفير فقط,- المحول ذو الفكك فقط,محول لا مفكك فقط,仅解码器变压器,解码器专用变压器,解码器变换器,transformateur pour décodeur uniquement,transformateur à décodeur uniquement,transformateur décodeur uniquement,デコーダ専用トランスフォーマー,デコーダーのみのトランスフォーマー,デコーダーのみトランスフォーマー,преобразователь только для декодера,декодерный трансформер,декодер-трансформер
1195,decoding problem,مشكلة فك التشفير,مشكلة فك التشفير,مشكلة الترميز,解码问题,解码问题,解码问题,problème de décodage,problème de décodage,problème de décodage,デコードの問題,デコーディング問題,復号問題,проблема с декодированием,проблема декодирования,проблема декодирования
1196,decoding step,خطوة فك التشفير,خطوة فك تشفير,خطوة الترميز,解码步骤,解码步骤 (jiěmǎ bùzhòu),解码步骤,étape de décodage,étape de décodage,étape de décodage,デコードステップ,デコーディングステップ,デコーディングステップ,шаг декодирования,декодирующий шаг,шаг декодирования
1197,decomposable attention,اهتمام قابل للتحلل,- تركيز الانتباه القابل للتفكيك,انتباه قابل للتفكيك,可分解注意力,可分解式注意力,可分解注意力,attention décomposable,attention décomposable,attention décomposable,分解可能な注意,分解可能な注意力 (Bunkai-kanōna chūriyoku),分解可能な注意力,разлагаемое внимание,декомпозируемое внимание,разложимое внимание
1198,decomposable attention model,نموذج الاهتمام القابل للتحلل,نموذج الانتباه القابل للتحلل,نموذج الانتباه القابل للتحلل,可分解注意力模型,可分解注意力模型 (Decomposable Attention Model),可分解注意力模型,modèle d'attention décomposable,- Modèle d'attention décomposable,modèle d'attention décomposable,分解可能な注意モデル,分解可能な注意モデル (Decomposable Attention Model),分解可能な注意モデル,разложимая модель внимания,декомпозируемая модель внимания,модель разложимого внимания
1199,decomposition,تقسيم,تحليل,تفكيك,分解,分解,分解,décomposition,décomposition,décomposition,分解,"""['disparity d0) in I1; note that some of these nodes have been excluded for clarity. Black lines represent the data costs, blue lines the visibility constraint, and red lines the smoothness prior. to solving the graph, and, while the list length is variable, it tends to be around nN edges. The six red lines , which represent the smoothness costs of equation ( 5 ) for the only complete neighborhood , N = { p , q , r } , show how one triple clique is decomposed into six pairwise cliques , and an extra , latent",分解,разложение,декомпозиция,разложение
1200,decomposition method,طريقة التحلل,طريقة تحليلية,طريقة التحلل,分解法,分解方法,分解法,méthode de décomposition,méthode de décomposition,méthode de décomposition,分解方法,分解法,分解法,метод разложения,метод декомпозиции,метод декомпозиции
1201,deconvolution,تفكك,6 in,إزالة الطي,反卷积,反卷积,反卷积,déconvolution,déconvolution,déconvolution,デコンボリューション,逆畳み込み,畳み込みの逆演算,деконволюция,деконволюция,деконволюция
1202,deconvolution layer,طبقة تفكك,طبقة فك التحديد,طبقة فك الالتفاف,反卷积层,反卷积层,卷积转置层,couche de déconvolution,couche de déconvolution,couche de déconvolution,デコンボリューション層,デコンボリューション層,デコンボリューション層,слой деконволюции,слои деконволюции,слой развёртывания
1203,deconvolutional layer,طبقة deconvolutional,طبقة فك تكاملية,طبقة إزالة الطي,反卷积层,解卷积层,转置卷积层,couche déconvolutive,couche de déconvolution,couche déconvolutionnelle,逆畳み込み層,逆畳み込み層 (gyaku bichigomi sō),復コンボリューション層,деконволюционный слой,Слой деконволюции,слой деконволюции
1204,deep architecture,الهندسة المعمارية العميقة,الهندسة العميقة,هندسة عميقة,深层架构,深度架构,深层架构,architecture profonde,architecture profonde,architecture profonde,ディープアーキテクチャ,ディープアーキテクチャ (diipu ākitekucha),深層アーキテクチャ,глубокая архитектура,глубокая архитектура,глубокая архитектура
1205,deep convolutional network,شبكة تلافيفية عميقة,- التكامل العميق للشبكة التحويلية,شبكة التكامل العميقة,深度卷积网络,深度卷积网络 (deep convolutional network),深度卷积网络,réseau convolutif profond,réseau de convolution profonde,réseau convolutionnel profond,深い畳み込みネットワーク,ディープコンボリューショナルネットワーク,深層畳み込みネットワーク,глубокая сверточная сеть,глубокая сверточная нейронная сеть,глубокая сверточная сеть
1206,deep convolutional neural network,شبكة عصبية تلافيفية عميقة,شبكة عصبية تصادمية عميقة,شبكات عصبية تلافيفية عميقة,深度卷积神经网络,深度卷积神经网络,深度卷积神经网络,réseau neuronal convolutif profond,- Réseau de neurones convolutifs profonds,réseau neuronal convolutionnel profond,ディープ畳み込みニューラル ネットワーク,深層畳み込みニューラルネットワーク,深層畳み込みニューラルネットワーク,глубокая сверточная нейронная сеть,глубокая сверточная нейронная сеть,глубокая сверточная нейронная сеть
1207,deep feature,ميزة عميقة,الميزة العميقة,سمة عميقة,深层特征,深度特征,深度特征,fonctionnalité profonde,caractéristique profonde,descripteur profond,深い機能,ディープフィーチャー,深層特徴量,глубокая особенность,глубокий признак,глубокий признак
1208,deep generative model,النموذج التوليدي العميق,النموذج الانتاجي العميق,نموذج توليدي عميق,深度生成模型,深度生成模型,深度生成模型,modèle génératif profond,modèle génératif profond,modèle génératif profond,深い生成モデル,深層生成モデル,深層生成モデル,глубокая генеративная модель,глубокая генеративная модель,глубокая генеративная модель
1209,deep layer,طبقة عميقة,الطبقة العميقة,طبقة عميقة,深层,深层,深层,couche profonde,couche profonde,couche profonde,深層,深層,深層,глубокий слой,глубокий слой,глубокий слой
1210,deep learning architecture,بنية التعلم العميق,بنية التعلم العميق,معمارية التعلم العميق,深度学习架构,深度学习架构,深度学习架构,architecture d'apprentissage profond,- Architecture d'apprentissage profond,architecture d'apprentissage profond,深層学習アーキテクチャ,深層学習アーキテクチャ,ディープラーニングアーキテクチャ,архитектура глубокого обучения,архитектура глубокого обучения,глубокая архитектура обучения
1211,deep learning framework,إطار التعلم العميق,إطار التعلم العميق,إطار التعلم العميق,深度学习框架,深度学习框架,深度学习框架,cadre d'apprentissage profond,cadre d'apprentissage profond,Cadre d'apprentissage profond,深層学習フレームワーク,ディープラーニングフレームワーク,深層学習フレームワーク,структура глубокого обучения,фреймворк глубокого обучения,Фреймворк глубокого обучения
1212,deep learning model,نموذج التعلم العميق,نموذج التعلم العميق,نموذج التعلم العميق,深度学习模型,深度学习模型,深度学习模型,modèle d'apprentissage profond,Modèle d'apprentissage profond,modèle d'apprentissage profond,深層学習モデル,深層学習モデル (しんそうがくしゅうモデル),深層学習モデル,модель глубокого обучения,- Deep Learning модель,модель глубокого обучения
1213,deep learning system,نظام التعلم العميق,نظام التعلم العميق,نظام التعلم العميق,深度学习系统,深度学习系统,深度学习系统,système d'apprentissage profond,- Système d'apprentissage profond,système d'apprentissage profond,深層学習システム,ディープラーニングシステム,深層学習システム,система глубокого обучения,система глубокого обучения,система глубокого обучения
1214,deep model,نموذج عميق,النموذج العميق,نموذج عميق,深度模型,深度模型,深层模型,modèle profond,modèle profond,modèle profond,ディープモデル,深層モデル,深層モデル,глубокая модель,глубокая модель,глубокая модель
1215,deep net,شبكة عميقة,شبكة عميقة,شبكة عميقة,深网,深度网络,深度网络,filet profond,réseau profond,réseau profond,ディープネット,ディープネット,深層ネット,глубокая сеть,Глубокая нейросеть,глубокая сеть
1216,deep network,شبكة عميقة,شبكة عميقة,شبكة عميقة,深层网络,深度网络,深度网络,réseau profond,réseau profond,réseau profond,ディープネットワーク,ディープネットワーク,深層ネットワーク,глубокая сеть,глубокая сеть,глубокая сеть
1217,deep network architecture,بنية الشبكة العميقة,بنية شبكية عميقة,شبكة عميقة معمارية,深层网络架构,深度网络架构,深层网络架构,architecture de réseau profonde,architecture de réseau profond,architecture de réseau profond,ディープネットワークアーキテクチャ,深層ネットワークアーキテクチャ,深層ネットワーク アーキテクチャ,глубокая сетевая архитектура,- Глубокая архитектура сети (deep network architecture),глубокая сетевая архитектура
1218,deep neural model,النموذج العصبي العميق,النموذج العصبي العميق,نموذج عصبي عميق,深度神经模型,深度神经模型,深度神经网络模型,modèle neuronal profond,- Modèle neuronal profond,modèle neuronal profond,ディープニューラルモデル,深層ニューラルモデル,深層ニューラルモデル,глубокая нейронная модель,глубокая нейронная модель,глубокая нейронная модель
1219,deep neural net,شبكة عصبية عميقة,الشبكة العصبية العميقة,شبكة عصبية عميقة,深度神经网络,深度神经网络,深度神经网络,réseau neuronal profond,réseau neuronal profond,réseau de neurones profond,ディープニューラルネット,ディープニューラルネット,深層ニューラルネット,глубокая нейронная сеть,Глубокая нейронная сеть,глубокая нейронная сеть
1220,deep neural network,الشبكة العصبية العميقة,شبكة عصبية عميقة,شبكة عصبية عميقة,深度神经网络,深度神经网络,深度神经网络,réseau neuronal profond,réseau neuronal profond,réseau de neurones profond,ディープニューラルネットワーク,深層ニューラルネットワーク,深層ニューラルネットワーク,глубокая нейронная сеть,глубокая нейронная сеть,глубокая нейронная сеть
1221,deep q-learning,التعلم العميق,تعلم Q عميق,تعلم كيو العميق,深度q学习,深度Q学习,深度Q学习,apprentissage en profondeur,deep Q-learning,apprentissage profond par Q-learning,ディープ Q ラーニング,ディープQ学習,深層Q学習,глубокое q-обучение,глубокое Q-обучение,глубокое Q-обучение
1222,deep q-network,شبكة Q العميقة,- التحسين العميق للشبكة Q,شبكة كيو العميقة,深度q网络,深度 Q 网络,深度 Q 网络,réseau q profond,réseau Q profond,réseau de Q profond,ディープ Q ネットワーク,ディープQネットワーク (DQN),深層Qネットワーク,глубокая q-сеть,глубокая сеть Q-обучения,Глубокая сеть Q
1223,deep reinforcement learning,التعلم المعزز العميق,التعلم التعزيزي العميق,التعزيز العميق التعلم,深度强化学习,深度强化学习,深度强化学习,apprentissage par renforcement profond,apprentissage profond par renforcement,apprentissage par renforcement profond,深層強化学習,深層強化学習,深層強化学習,глубокое обучение с подкреплением,глубокое обучение с подкреплением,глубокое обучение с подкреплением
1224,deep supervision,الإشراف العميق,- التوجيه العميق,التدريب العميق,深度督导,深度监督,深度监督,supervision approfondie,supervision profonde,contrôle profond,深い監督,ディープ・スーパービジョン,深い監視,глубокий надзор,глубокая надзорность,глубокий надзор
1225,deeply-supervise net,شبكة مراقبة عميقة,شبكة مشرفة بعمق,شبكة إشراف عميق,深度监管网,深度监督网络,深度监督网络,réseau à supervision approfondie,réseau profondément supervisé,réseau à supervision profonde,ネットを徹底的に監視する,深く監視されたネット,深層監視ネット,сеть глубокого контроля,глубоко-надзорная сеть,глубоко-контролируемая сеть
1226,default logic,المنطق الافتراضي,المنطق الافتراضي,منطق الافتراضي,默认逻辑,默认逻辑,缺省逻辑,logique par défaut,logique par défaut,logique par défaut,デフォルトのロジック,デフォルト論理,デフォルト論理,логика по умолчанию,логика по умолчанию,логика умолчаний
1227,deformable template,قالب قابل للتشوه,القالب المتشوه,قالب قابل للتشوه,可变形模板,可变形模板 (deformable template),可变形模板,gabarit déformable,modèle déformable,modèles déformables,変形可能なテンプレート,可変テンプレート,変形可能なテンプレート,деформируемый шаблон,- Деформируемый шаблон,деформируемые шаблоны
1228,deformation field,مجال التشوه,حقل التشويه,حقل التشوه,变形场,变形场,形变场,champ de déformation,champ de déformation,champ de déformation,変形フィールド,変形場 (Henkei-ba),変形場,поле деформации,поле деформации,поле деформации
1229,degree distribution,توزيع الدرجة,توزيع الدرجات,توزيع الدرجات,学位分布,度分布,度分布,répartition des diplômes,distribution des degrés,distribution des degrés,度分布,度数分布,次数分布,распределение степеней,распределение степеней,распределение степеней
1230,delay reward,مكافأة التأخير,تأخير الجائزة,تأخير المكافأة,延迟奖励,延迟奖励,延迟奖励,retarder la récompense,récompense différée,retard de récompense,報酬を遅らせる,遅延報酬,遅延報酬,задержка вознаграждения,- Задержка вознаграждения,отсроченная награда
1231,delexicalization,إزالة المفردات,عملية إزالة المفردات,إزالة المعجم,去词汇化,去词化,去词汇化,délexicalisation,délexicalisation,délexicalisation,脱神経化,デレキシカリゼーション,非語彙化,делексикализация,деликсикация,делексикализация
1232,delta kernel,نواة دلتا,نواة دلتا,كرنك دلتا,德尔塔内核,德尔塔核,狄拉克核,noyau delta,noyau delta,noyau delta,デルタカーネル,デルタカーネル,デルタカーネル,дельта-ядро,дельта-ядро,ядерная дельта
1233,demographic parity,التكافؤ الديموغرافي,مساواة توزيع السكان,تكافؤ الخصائص الديموغرافية,人口平等,人口统计平等,人口统计学平等,parité démographique,parité démographique,parité démographique,人口平等,"""それらの中で、Demographic Parity (DP)（Pedreshi、Ruggieri、Turini、2008年）とEqualized Opportunity (EOp)（Hardt、Price、Srebro、2016年）は、最も広く使用されている定義の2つです。たとえば、人口平等（DP）は、予測が敏感な特徴とは独立していることを要求します。一方",人口統計的均等性,демографический паритет,демографическая паритетность,демографическое равенство
1234,dendrogram,dendrogram,شجرة العوامل,مخطط شجري,树状图,树状图,树状图,dendrogramme,dendrogramme,dendrogramme,樹状図,デンドログラム,樹形図,дендрограмма,дендрограмма,дендрограмма
1235,denoise diffusion probabilistic model,النموذج الاحتمالي لانتشار الضوضاء,نموذج الانتشار المحتمل لتنقية الضوضاء,نموذج الانتشار الاحتمالي لإزالة التشويش,去噪扩散概率模型,去噪扩散概率模型,去噪扩散概率模型,modèle probabiliste de diffusion du débruit,modèle probabiliste de diffusion de débruitage,modèle probabiliste de diffusion de débruitage,ノイズ除去拡散確率モデル,ノイズ除去拡散確率モデル,デノイズ拡散確率モデル,вероятностная модель диффузии с шумоподавлением,модель диффузии с подавлением шума,модель вероятностного шумоподавляющего диффузионного процесса (DDPM)
1236,denoise network,شبكة تقليل الضوضاء,شبكة تقليل الضوضاء,شبكة إزالة التشويش,去噪网络,去噪网络,去噪网络,réseau de débruitage,réseau de débruitage,réseau de débruitage,ノイズ除去ネットワーク,ノイズ除去ネットワーク,雑音除去ネットワーク,сеть с шумоподавлением,сеть для уменьшения шума,сеть дешумлирования
1237,denoise objective,تقليل الضوضاء الهدف,هدف تقليل الضوضاء,هدف إزالة التشويش,去噪目标,去噪目标,去噪目标,objectif de débruitage,objectif de débruitage,objectif de débruitage,ノイズ除去目標,ノイズ除去目的 (Noise removal objective),除去化目標,цель шумоподавления,дефектация цели,цель деноизинга
1238,denoise process,عملية تقليل الضوضاء,عملية التخفيف من الضوضاء,عملية إزالة التشويش,去噪过程,去噪过程,去噪过程,processus de débruitage,processus de débruitage,processus de débruitage,ノイズ除去プロセス,ノイズ除去プロセス,雑音除去処理,процесс шумоподавления,процесс удаления шума,процесс деноизинга
1239,denoise score match loss,دينوايز النتيجة خسارة المباراة,- تطابق درجة تقليل الضوضاء,خسارة مطابقة درجة إزالة التشويش,去噪得分 匹配损失,去噪分数匹配损失,去噪分数匹配损失,débruiter score match perte,perte de correspondance de score de débruitage,perte de correspondance des scores de débruitage,ノイズ除去スコアマッチ損失,ノイズ除去スコアマッチ損失,スコアマッチング損失の雑音除去,проигрыш в счете denoise,потеря соответствия оценки шума,потеря соответствия шума оценки
1240,denoise score matching,مطابقة درجة الضوضاء,تحسين التعادل النقدي للتخفيض من الضجيج,مطابقة نقاط إزالة التشويش,去噪分数匹配,去噪分数匹配,去噪分值匹配,correspondance des scores de débruitage,appariement des scores de débruitage,appariement de score de débruitage,ノイズ除去スコアマッチング,デノイズスコアマッチング,デノイズスコアマッチング,сопоставление показателей шумоподавления,оценка подавления шума,согласование оценок шумоподавления
1241,denoiser,مزيل الضوضاء,مزيل الضجيج,مُزيل الضوضاء,降噪器,去噪器,去噪器,débruiteur,débruiteur,désintégrateur,デノイザー,デノイザー,除去器,шумоподавитель,денойзер,обезшумитель
1242,denotation,دلالة,الدلالة,دلالة,表示,指示,指称,dénotation,dénotation,dénotation,表示,"""[ 'すべてのアクションシーケンスδに対して、M、 µ x q |= F（x、do（δ、S A））⇔ qがn k（0）の指示である場合、kが• 数0の場合、δの最後のアクションがAの場合; \n'、 '各タイプtに対して、エージェントは（AND t pi）を候補と",示す内容,обозначение,обозначение,денотация
1243,dense,كثيف,كثيف,مكثف,稠密,密集,密集的,dense,dense,dense,密集,密な,密,плотный,плотный,плотный
1244,dense attention,اهتمام كثيف,تركيز كثيف,ـ اهتمام كثيف,密集注意力,密集注意力,密集注意力,attention dense,attention dense,attention dense,集中的な注意,密な注意,密な注意力,плотное внимание,плотное внимание,плотное внимание
1245,dense depth map,خريطة عمق كثيفة,خريطة عمق كثيفة,خريطة عمق كثيفة,密集深度图,密集深度图,密集深度图,carte de profondeur dense,carte de profondeur dense,carte de profondeur dense,密な深度マップ,密な奥行きマップ,密な深度マップ,плотная карта глубины,плотная карта глубины,плотная карта глубины
1246,dense feature,ميزة كثيفة,الميزة الكثيفة,ميزة كثيفة,密集特征,密集特征,密集特征,élément dense,caractéristique dense,caractéristiques denses,密な特徴,密な特徴,密な特徴量,плотная особенность,- Плотные признаки,плотные признаки
1247,dense layer,طبقة كثيفة,الطبقة الكثيفة,طبقة مكثفة,致密层,密集层,密集层,couche dense,couche dense,couche dense,緻密な層,密な層,密層,плотный слой,плотный слой,плотный слой
1248,dense matrix,مصفوفة كثيفة,مصفوفة كثيفة,مصفوفة كثيفة,稠密矩阵,- 密矩阵,密集矩阵,matrice dense,matrice dense,matrice dense,密なマトリックス,密行列,密行列,плотная матрица,плотная матрица,плотная матрица
1249,dense network,شبكة كثيفة,الشبكة الكثيفة,شبكة كثيفة,密集网络,密集网络,稠密网络,réseau dense,réseau dense,réseau dense,高密度ネットワーク,密なネットワーク,密な網路,плотная сеть,плотная сеть,плотная сеть
1250,dense prediction,التنبؤ الكثيف,التنبؤ الكثيف,التنبؤ الكثيف,密集预测,密集预测,密集预测,prédiction dense,prédiction dense,prédiction dense,密な予測,密な予測 (みつなよそく),密な予測,плотное предсказание,- Плотное предсказание,плотное предсказание
1251,dense representation,تمثيل كثيف,- التمثيل الكثيف,التمثيل الكثيف,密集表示,密集表示,密集表示,représentation dense,représentation dense,représentation dense,密な表現,密な表現,密な表現,плотное представление,плотное представление,плотное представление
1252,dense vector,ناقلات كثيفة,ناقل كثيف,متجه كثيف,稠密向量,密集向量,稠密向量,vecteur dense,vecteur dense,vecteur dense,密なベクトル,密なベクトル,密次元ベクトル,плотный вектор,плотный вектор,плотный вектор
1253,density estimate,تقدير الكثافة,تقدير الكثافة,تقدير الكثافة,密度估计,密度估计,密度估计,estimation de la densité,estimation de densité,estimation de densité,密度推定,密度推定 (mimitsu suitei),密度推定,оценка плотности,оценка плотности,плотностная оценка
1254,density estimation,تقدير الكثافة,تقدير الكثافة,تقدير الكثافة,密度估计,密度估计 (density estimation),密度估计,estimation de la densité,estimation de densité,estimation de la densité,密度推定,密度推定,密度推定,оценка плотности,оценка плотности,оценка плотности
1255,density estimator,مقدر الكثافة,مقدر الكثافة,مقدر الكثافة,密度估计器,密度估计器,密度估计器,estimateur de densité,estimateur de densité,estimateur de densité,密度推定器,密度推定器,密度推定器,оценщик плотности,оценщик плотности,оценщик плотности
1256,density field,مجال الكثافة,مجال الكثافة,حقل الكثافة,密度场,密度场,密度场,champ de densité,champ de densité,champ de densité,密度フィールド,密度場 (mitsudo-ba),密度フィールド,поле плотности,- Плотностное поле,поле плотности
1257,density function,دالة الكثافة,وظيفة الكثافة,دالة الكثافة,密度函数,密度函数,密度函数,fonction de densité,fonction de densité,fonction de densité,密度関数,密度関数,密度関数,функция плотности,функция плотности,функция плотности
1258,density gradient,التدرج الكثافة,تدرج الكثافة,كثافة تدرج,密度梯度,密度梯度 (density gradient),密度梯度,gradient de densité,gradient de densité,densité gradient,密度勾配,密度勾配,密度勾配,градиент плотности,градиент плотности,градиент плотности
1259,density ratio,نسبة الكثافة,معدل الكثافة,نسبة الكثافة,密度比,密度比率,密度比率,rapport de densité,rapport de densité,rapport de densité,密度比,密度比,密度比,коэффициент плотности,плотностное отношение,соотношение плотностей
1260,dependency,الاعتماد,الاعتمادية,اعتمادية,依赖性,依赖关系,依赖关系,dépendance,dépendance,dépendance,依存,依存関係,依存関係,зависимость,зависимость,зависимость
1261,dependency arc,قوس التبعية,قوس الاعتماد,قوس التبعية,依赖弧,依赖弧,依赖弧,arc de dépendance,arc de dépendance,arc de dépendance,依存関係アーク,依存アーク,依存アーク,дуга зависимости,зависимостная дуга,дуга зависимости
1262,dependency feature,ميزة التبعية,ميزة الاعتمادية,ميزة الاعتماد,依赖特征,依赖特征,依存特征,fonctionnalité de dépendance,caractéristique de dépendance,traits dépendance,依存関係機能,依存特徴,依存性特徴,функция зависимости,признак зависимости,признаки зависимости
1263,dependency graph,الرسم البياني التبعية,رسم الارتباطات الوابلية,مخطّط الاعتماديّة,依赖图,依赖图,依赖图,graphique de dépendance,- Graphique de dépendance,graphe de dépendances,依存関係グラフ,依存グラフ,依存グラフ,граф зависимостей,граф зависимостей,граф зависимостей
1264,dependency label,تسمية التبعية,تسمية التبعية,علامة التبعية,依赖标签,依存标签,依存关系标签,étiquette de dépendance,étiquette de dépendance,Étiquette de dépendance,依存関係ラベル,依存ラベル,依存関係ラベル,метка зависимости,метка зависимости,Метка зависимости
1265,dependency model,نموذج التبعية,نموذج الاعتمادية,نموذج التبعية,依赖模型,依存模型,依存模型,modèle de dépendance,modèle de dépendance,modèle de dépendance,依存関係モデル,依存性モデル,依存モデル,модель зависимости,модель зависимости,модель зависимостей
1266,dependency parse,تحليل التبعية,تحليل الاعتمادية,تحليل التبعية,依存分析,依存句法分析,依存句法分析,analyse des dépendances,analyse de dépendance,analyse de dépendance,依存関係の解析,依存構文解析 (Dependency Parse),依存構文解析,анализ зависимостей,зависимостный синтаксический анализ,синтаксический анализ зависимостей
1267,dependency parse tree,شجرة تحليل التبعية,شجرة تحليل الاعتماد,شجرة التحليل الإعتمادي,依存分析树,依赖关系分析树,依存句法分析树,arbre d'analyse des dépendances,arbre syntaxique de dépendance,arbre de dépendances syntaxiques,依存関係解析ツリー,依存構文解析ツリー (Izon-koubun kaiseki tsurii),依存構文解析木,дерево разбора зависимостей,дерево зависимостей разбора,дерево зависимостей разбора
1268,dependency parser,محلل التبعية,محلل الاعتمادية,محلل الارتباط النحوي,依存解析器,依存分析器,依赖语法分析器,analyseur de dépendances,analyseur de dépendance,analyseur syntaxique de dépendances,依存関係パーサー,依存構文解析器 (dependency parser),依存構文解析器,парсер зависимостей,парсер зависимостей,синтаксический анализатор
1269,dependency parsing model,نموذج تحليل التبعية,نموذج تحليل التبعية,نموذج تحليل الاعتمادية,依存句法分析模型,依存句法分析模型,依存句法分析模型,modèle d'analyse des dépendances,modèle d'analyse de dépendance,modèle d'analyse syntaxique par dépendances,依存関係解析モデル,依存構文解析モデル (izon koubun kaiseki moderu),依存構文解析モデル,модель анализа зависимостей,модель синтаксического анализа зависимостей,зависимостная модель синтаксического анализа
1270,dependency path,مسار التبعية,مسار الاعتماد,مسار الاعتمادية,依赖路径,依赖路径,依存路径,chemin de dépendance,Chemin de dépendance,chemin de dépendance,依存関係パス,依存関係パス,依存関係パス,путь зависимости,зависимостный путь,путь зависимости
1271,dependency relation,علاقة التبعية,العلاقة التبعية,ارتباط تبعية,依赖关系,依赖关系,依赖关系,relation de dépendance,relation de dépendance,relation de dépendance,依存関係,依存関係,従属関係,отношение зависимости,связь зависимости,зависимостное отношение
1272,dependency representation,تمثيل التبعية,التمثيل التبعي,تمثيل الاعتمادية,依赖表示,依存关系表示,依存表示,représentation des dépendances,représentation des dépendances,représentation en dépendances,依存関係の表現,依存関係表現 (izon kankei hyōgen),依存表現,представление зависимостей,представление зависимости,представление зависимостей
1273,dependency structure,هيكل التبعية,هيكل الاعتماد,هيكل الاعتمادية,依赖结构,依赖结构,依存结构,structure de dépendance,- Structure de dépendance,structure de dépendance,依存構造,依存構造 (いぞんこうぞう),依存構造,структура зависимостей,структура зависимости,структура зависимостей
1274,dependency tree,شجرة التبعية,شجرة الاعتماد,شجرة الاعتماد,依赖树,依赖树,依存树,arbre de dépendance,arbre de dépendance,arbre de dépendance,依存関係ツリー,依存構造木 (Izon Kōzōki),依存木,дерево зависимостей,дерево зависимостей,древо зависимостей
1275,dependency treebank,بنك شجرة التبعية,- تصنيف شجري للتبعية,بنك الشجرة الإعتمادية,依赖树库,依存树库,依存树库,banque d'arbres de dépendance,corpus d'arbres de dépendances,treebank de dépendances,依存関係ツリーバンク,依存構造ツリーバンク,依存構造付きコーパス,дерево зависимостей,дерево зависимостей,банк деревьев зависимостей
1276,dependent variable,المتغير التابع,المتغير التابع,المتغير التابع,因变量,因变量,因变量,variable dépendante,variable dépendante,variable dépendante,従属変数,依存変数,従属変数,зависимая переменная,- Зависимая переменная,зависимая переменная
1277,depth estimation,تقدير العمق,تقدير العمق,تقدير العمق,深度估计,深度估计,深度估计,estimation de la profondeur,estimation de la profondeur,estimation de la profondeur,深さの推定,深度推定,深度推定,оценка глубины,оценка глубины,оценка глубины
1278,depth estimator,مقدر العمق,مقدر العمق,معايِر العُمق,深度估计器,深度估计器,深度估计器,estimateur de profondeur,estimateur de profondeur,estimateur de profondeur,深度推定器,深度推定器,深さ推定器,оценщик глубины,оценщик глубины,оценщик глубины
1279,depth image,صورة العمق,صورة العمق,صورة عمق,深度图像,深度图像,深度图像,image de profondeur,image de profondeur,image de profondeur,深度画像,深度画像,深度画像,изображение глубины,глубинное изображение,изображение глубины
1280,depth map,خريطة العمق,خريطة العمق,خريطة العمق,深度图,深度图,深度图,carte de profondeur,carte de profondeur,carte de profondeur,深度マップ,深度マップ (しんどマップ),奥行きマップ,карта глубины,карта глубины,карта глубины
1281,depth prediction,التنبؤ بالعمق,- تنبؤ العمق,توقع العمق,深度预测,深度预测,深度预测,prédiction de profondeur,prédiction de profondeur,prédiction de profondeur,深さの予測,深度予測 (しんどよそく),深度予測,прогноз глубины,предсказание глубины,предсказание глубины
1282,depth-first search,عمق البحث الأول,البحث بالعمق أولاً,بحث عمق أولاً,深度优先搜索,深度优先搜索,深度优先搜索,recherche en profondeur,"""['Nous pouvons effectuer une recherche en profondeur récursive de l'arbre d'énumération de l'ensemble d'échantillons pour détecter les cliques maximales des échantillons. Étant donné un ensemble d'échantillons S, l'arbre d'énumération de l'ensemble comporte 2 |S| nœuds. Cependant, nous n'avons jamais besoin de matérialiser un tel arbre.', 'pour chaque gène g k, générer",recherche en profondeur,深さ優先検索,深さ優先探索,深さ優先探索,поиск в глубину,поиск в глубину,поиск в глубину
1283,description logic,منطق الوصف,منطق الوصف,منطق الوصف,描述逻辑,描述逻辑,描述逻辑 (DL),logique de description,logique de description,logique de description,説明ロジック,記述論理,記述論理,логика описания,логика описания,логика описания
1284,descriptor,واصف,وصفية,واصف,描述符,描述符,描述子,descripteur,descripteur,descripteur,ディスクリプタ,ディスクリプタ,記述子,дескриптор,дескриптор,дескриптор
1285,design matrix,مصفوفة التصميم,مصفوفة التصميم,مصفوفة التصميم,设计矩阵,设计矩阵,设计矩阵,matrice de conception,matrice de conception,matrice de design,デザインマトリックス,設計行列 (sekkei gyōretsu),デザイン行列,матрица проектирования,матрица дизайна,матрица дизайна
1286,design space,مساحة التصميم,المساحة التصميمية,مساحة التصميم,设计空间,设计空间,设计空间,espace de conception,- Espace de conception,espace de conception,デザインスペース,設計空間 (sekkei kuukan),設計空間,дизайн пространства,пространство проектирования,пространство проектирования
1287,det,ديت,المُحدد,دالة المصفوفة,德特,行列式,det,dét,déterminant,déterminant,デット,行列式,det,дет,определитель,определитель
1288,detection,كشف,الكشف,كشف,检测,检测 (detection),检测,détection,détection,détection,検出,検出 (kenshutsu),検出,обнаружение,Обнаружение,обнаружение
1289,detection algorithm,خوارزمية الكشف,خوارزمية الكشف,خوارزمية الكشف,检测算法,检测算法,检测算法,algorithme de détection,algorithme de détection,algorithme de détection,検出アルゴリズム,検出アルゴリズム (kenshutsu arugorizumu),検出アルゴリズム,алгоритм обнаружения,алгоритм обнаружения,алгоритм обнаружения
1290,detection model,نموذج الكشف,نموذج الكشف,نموذج الكشف,检测模型,检测模型,检测模型,modèle de détection,- Modèle de détection,modèle de détection,検出モデル,検出モデル,検出モデル,модель обнаружения,модель обнаружения,модель обнаружения
1291,detection score,درجة الكشف,نقطة الكشف,درجة الكشف,检测分数,检测分数,检测分数,score de détection,score de détection,score de détection,検出スコア,検出スコア (kenshutsu sukoa),検出スコア,показатель обнаружения,оценка обнаружения,балл обнаружения
1292,detection window,نافذة الكشف,نافذة الكشف,نافذة الكشف,检测窗口,检测窗口,检测窗口,fenêtre de détection,fenêtre de détection,fenêtre de détection,検出ウィンドウ,検出ウィンドウ,検出ウィンドウ,окно обнаружения,окно обнаружения,окно обнаружения
1293,detector,كاشف,مُكَشف,كاشف,探测器,检测器,探测器,détecteur,détecteur,détecteur,検出器,検出器 (けんしゅつき),検出器,детектор,детектор,детектор
1294,determinantal point process,عملية النقطة الحاسمة,عملية النقطة الحاسمة,عملية نقطة محددية,行列式点过程,行列式点过程,行列式点过程,processus de point déterminant,processus ponctuel déterminantal,processus ponctuel déterminantal,決定点プロセス,決定的点過程,決定的点過程,детерминантный точечный процесс,детерминантный точечный процесс,детерминантальный точечный процесс
1295,deterministic algorithm,خوارزمية حتمية,"""['هل يمكن لخوارزمية التدقيق العشوائية أن تكون لها تعقيد استعلام أقل من تلك الخوارزمية المحددة الأمثل؟ باستخدام المثال أدناه، نجيب على هذا السؤال بالتأكيد. المثال",خوارزمية محددة,确定性算法,确定性算法,确定性算法,algorithme déterministe,algorithme déterministe,algorithme déterministe,決定論的アルゴリズム,決定論的アルゴリズム,確率的ではないアルゴリズム,детерминированный алгоритм,детерминированный алгоритм,Детерминированный алгоритм
1296,deterministic annealing,الصلب الحتمي,التلطيف التحديدي,تلدين حراري تحديدي,确定性退火,确定性退火,确定性退火,recuit déterministe,recuit déterministe,recuit déterministe,決定的アニーリング,決定諧和,決定論的アニーリング,детерминированный отжиг,детерминированное отжигание,детерминированный отжиг
1297,deterministic automaton,آلي حتمي,الآلة المحددة,آلة ذاتية التحديد,确定性自动机,确定性自动机,确定有限自动机,automate déterministe,- Automate déterministe,automate déterministe,決定論的オートマトン,確定性オートマトン (Kakuteisei Ōtomaton),確定的オートマトン,детерминированный автомат,детерминированный автомат,детерминированный автомат
1298,deterministic baseline,خط الأساس الحتمي,الخط القاعدي المحدد,خط أساس تحديدي,确定性基线,确定性基准,确定性基线,ligne de base déterministe,ligne de base déterministe,ligne de base déterministe,決定的なベースライン,決定論的ベースライン,決定論的ベースライン,детерминированная базовая линия,детерминированный базис,детерминистический базис
1299,deterministic finite automaton,آلي محدود حتمي,الأتومات المحددة النهائية المُحددة,آلة محددة متناهية,确定性有限自动机,确定有限自动机,确定有限自动机,automate fini déterministe,Automate fini déterministe,automate fini déterministe,決定論的有限オートマトン,確定性有限オートマトン (DFA),確定有限オートマトン,детерминированный конечный автомат,детерминированный конечный автомат,детерминированный конечный автомат
1300,deterministic policy,السياسة الحتمية,السياسة التحديدية,سياسة محددة,确定性政策,确定性策略,确定性策略,politique déterministe,politique déterministe,politique déterministe,決定的な政策,確定的ポリシー,確定的方針,детерминистская политика,детерминированная политика,Детерминированная политика
1301,deterministic rule,القاعدة الحتمية,قاعدة حاسمة,حكم محدد,确定性规则,确定性规则,确定性规则,règle déterministe,- Règle déterministe,règle déterministe,決定的な規則,確定的ルール,決定論的ルール,детерминированное правило,детерминированное правило,детерминированное правило
1302,dev set,مجموعة التطوير,مجموعة التطوير,مجموعة التنمية,开发集,开发集,开发集,ensemble de développement,"""['Pour tous les modèles, nous utilisons le jeu de dev et nous effectuons une validation croisée sur la régularisation des poids, la taille du vecteur de mots ainsi que le taux d'apprentissage et la taille du mini-lot pour AdaGrad. Les performances optimales de tous les modèles ont été obtenues avec des tailles de vecteur de mots comprises entre 25 et 35 dimensions et des tailles de lots comprises entre 20 et 30.', 'Nous analysons 200 prédictions incorrectes (c",ensemble de développement,開発セット,開発セット (dev set),評価用データセット,набор для разработчиков,набор для разработки,набор разработки
1303,development set,مجموعة التطوير,مجموعة التطوير,مجموعة التطوير,开发集,发展集,开发集,ensemble de développement,jeu de développement,ensemble de développement,開発セット,開発セット,開発セット,набор для разработки,набор для разработки,разработочный набор
1304,diagonal matrix,مصفوفة قطرية,مصفوفة قطرية,مصفوفة قطرية,对角矩阵,对角矩阵,对角矩阵,matrice diagonale,matrice diagonale,matrice diagonale,対角行列,対角行列,対角行列,диагональная матрица,диагональная матрица,диагональная матрица
1305,dialog system,نظام الحوار,نظام الحوار,نظام الحوار,对话系统,对话系统 (dialog system),对话系统,système de dialogue,système de dialogue,système de dialogue,ダイアログシステム,ダイアログシステム,対話システム,диалоговая система,система диалога,диалоговая система
1306,dialogue act,فعل الحوار,فعل الحوار,فعل الحوار,对话行为,对话行为,对话行为,acte de dialogue,acte de dialogue,acte de dialogue,対話行為,ダイアログアクト,対話行為,акт диалога,действие диалога,речевой акт
1307,dialogue context,سياق الحوار,سياق الحوار,مُحتوى الحوار,对话情境,对话上下文,对话背景,contexte du dialogue,contexte de dialogue,contexte du dialogue,対話のコンテキスト,- 対話コンテキスト,対話コンテキスト,контекст диалога,контекст диалога,диалоговый контекст
1308,dialogue generation,جيل الحوار,توليد الحوارات,توليد الحوار,对话生成,对话生成,对话生成,génération de dialogues,génération de dialogue,génération de dialogues,対話の生成,ダイアログ生成,対話生成,генерация диалога,генерация диалога,генерация диалогов
1309,dialogue history,تاريخ الحوار,تاريخ الحوار,حوار سابق,对话历史,对话历史,对话历史记录,histoire des dialogues,- Historique du dialogue,historique du dialogue,対話履歴,- 対話履歴,対話履歴,история диалога,история диалога,диалоговая история
1310,dialogue management,إدارة الحوار,إدارة الحوارات,إدارة الحوار,对话管理,对话管理,对话管理,gestion des dialogues,gestion du dialogue,gestion du dialogue,対話管理,ダイアログ管理,対話管理,управление диалогом,управление диалогом,управление диалогом
1311,dialogue state,دولة الحوار,حالة الحوار,حالة الحوار,对话状态,对话状态,对话状态,état de dialogue,état du dialogue,état du dialogue,対話状態,対話状態,対話状態,состояние диалога,состояние диалога,состояние диалога
1312,dialogue state tracker,تعقب حالة الحوار,تتبع حالة الحوار,متتبع حالة المحادثة,对话状态跟踪器,对话状态跟踪器,对话状态跟踪器,suivi de l'état du dialogue,suivi de l'état du dialogue,suivi de l'état du dialogue,対話状態トラッカー,- ダイアログ状態トラッカー,対話状態追跡器,трекер состояния диалога,отслеживатель состояния диалога,Отслеживатель диалогового состояния
1313,dialogue state tracking,تتبع حالة الحوار,تتبع حالة الحوار,تتبع حالة الحوار,对话状态跟踪,对话状态跟踪,对话状态跟踪,suivi de l'état du dialogue,suivi de l'état du dialogue,suivi de l'état du dialogue,対話状態の追跡,ダイアログ状態追跡,対話状態追跡,отслеживание состояния диалога,Отслеживание состояния диалога,отслеживание состояния диалога
1314,dialogue system,نظام الحوار,نظام الحوار,نظام الحوار,对话系统,对话系统,对话系统,système de dialogue,système de dialogue,système de dialogue,対話システム,ダイアログシステム,対話システム,диалоговая система,система диалога,система диалогов
1315,dialogue turn,بدوره الحوار,مناوبة الحوار,حوار دور,对话轮,对话轮,对话轮次,tour de dialogue,tour de dialogue,tour de dialogue,対話ターン,- 対話ターン,対話ターン,поворот диалога,- Поворот диалога,диалоговый ход
1316,dice coefficient,معامل النرد,معامل دايس,معامل دايس,骰子系数,Dice系数,戴斯系数,coefficient de dés,coefficient de Dice,coefficient de Dice,サイコロ係数,ダイス係数,ダイス係数,коэффициент кубика,Коэффициент Дайса,коэффициент Дайса
1317,dice loss,خسارة النرد,خسارة النرد,خسارة النرد,骰子损失,骰子损失,骰子损失,perte de dés,perte de dés,perte de Dice,サイコロの損失,ダイス損失,ダイスロス,проигрыш в кости,"\n L dice = 1 − 2 × TP 2 × TP + FN + FP (6) \n', 'Потеря онлайн-картографирования. Как и в [56], это включает потери для линий, разделителей и",функция потерь Дайса
1318,dictionary learning,تعلم القاموس,تعلم القاموس,تعلم القاموس,字典学习,字典学习,词典学习,apprentissage du dictionnaire,apprentissage de dictionnaire,apprentissage de dictionnaire,辞書学習,辞書学習 (Jisho Gakushu),辞書学習,изучение словаря,обучение словаря,обучение словарей
1319,dictionary matrix,مصفوفة القاموس,مصفوفة القاموس,مصفوفة القاموس,字典矩阵,字典矩阵,字典矩阵,matrice de dictionnaire,matrice de dictionnaire,matrice de dictionnaire,辞書行列,辞書行列 (jisho gyōretsu),辞書行列,словарная матрица,матрица словаря,матрица словаря
1320,diffeomorphism,تباين,تمييزية,تشريح متجانس,微分同胚,微分同胚映射,微分同胚,difféomorphisme,difféomorphisme,difféomorphisme,微分同相写像,差分同相写像,微分同相写像,диффеоморфизм,диффеоморфизм,диффеоморфизм
1321,differentiable function,وظيفة قابلة للتمييز,الدالة قابلة للتفاضل,دالة قابلة للتفاضل,可微函数,可微函数,可微函数,fonction différentiable,fonction différentiable,fonction différentiable,微分可能関数,微分可能な関数 (Bunpō kanōna kansū),微分可能な関数,дифференцируемая функция,дифференцируемая функция,дифференцируемая функция
1322,differentiable renderer,عارض قابل للتمييز,مقدم الرسومات قابل للتفاضل,مُعيد التصوير المُميز,可微渲染器,可微渲染器,可微渲染器,moteur de rendu différenciable,rendu différentiable,rendu différentiable,微分可能レンダラー,可微分レンダラー,微分可能なレンダラー,дифференцируемый рендерер,дифференцируемый рендерер,дифференцируемый рендерер
1323,differentiable rendering,تقديم متباينة,التقديم قابل للتفاضل,تصوير تفاضلي,可微渲染,不可微渲染,可微渲染,rendu différenciable,rendu différenciable,rendu différentiable,微分可能なレンダリング,差分可能なレンダリング,微分可能なレンダリング,дифференцируемый рендеринг,дифференцируемый рендеринг,дифференцируемая визуализация
1324,differentiable rendering function,وظيفة التقديم التفاضلية,دالة العرض قابلة للتفاضل,وظيفة التصوير التفاضلية,可微分渲染函数,可微渲染函数,可微渲染函数,fonction de rendu différenciable,fonction de rendu différentiable,fonction de rendu différentiable,微分可能レンダリング関数,微分可能なレンダリング関数 (bunpou kanou na rendaringu kansuu),微分可能なレンダリング関数,дифференцируемая функция рендеринга,дифференцируемая функция рендеринга,функция дифференцируемого рендеринга
1325,differential entropy,الانتروبيا التفاضلية,التراكيز الفارقة,إنتروبية تفاضلية,微分熵,微分熵,微分熵,entropie différentielle,entropie différentielle,entropie différentielle,微分エントロピー,微分エントロピー,微分エントロピー,дифференциальная энтропия,дифференциальная энтропия,дифференциальная энтропия
1326,differential privacy,الخصوصية التفاضلية,الخصوصية التفاضلية,الخصوصية التفاضلية,差别隐私,差分隐私,差分隐私,confidentialité différentielle,confidentialité différentielle,Vie privée différentielle,差分プライバシー,差分プライバシー,差分プライバシー,дифференциальная конфиденциальность,дифференциальная секретность,дифференциальная конфиденциальность
1327,diffusion matrix,مصفوفة الانتشار,مصفوفة الانتشار,مصفوفة الانتشار,扩散矩阵,扩散矩阵,扩散矩阵,matrice de diffusion,- Matrice de diffusion,matrice de diffusion,拡散マトリックス,拡散行列 (Kakusan Kōretsu),拡散行列,диффузионная матрица,матрица диффузии,матрица диффузии
1328,diffusion model,نموذج الانتشار,نموذج الانتشار,نموذج الانتشار,扩散模型,扩散模型,扩散模型,modèle de diffusion,modèle de diffusion,modèle de diffusion,普及モデル,拡散モデル,拡散モデル,диффузионная модель,модель диффузии,модель диффузии
1329,diffusion tensor,موتر الانتشار,توزيع الانتشار,مصفوفة الانتشار,扩散张量,扩散张量,扩散张量,tenseur de diffusion,tenseur de diffusion,tenseur de diffusion,拡散テンソル,拡散テンソル (Kakusan Tensor),拡散テンソル,тензор диффузии,тензор диффузии,тензор диффузии
1330,digamma function,وظيفة ديجاما,وظيفة الديغاما,دالة ديجاما,双伽玛函数,二次Ψ函数,伽马函数,fonction digamma,fonction digamma,fonction digamma,ディガンマ関数,ディガンマ関数,ディガンマ関数,дигамма-функция,дигамма функция,дигамма-функция
1331,digit classification,تصنيف الأرقام,تصنيف الأرقام,تصنيف الأرقام,数字分类,数字分类,数字分类,classification des chiffres,classification de chiffres,Classification de chiffres,桁分類,数字分類 (すうじぶんるい),数字分類,классификация цифр,классификация цифр,классификация цифр
1332,dilate convolution,تمدد الالتواء,التبسيط الموسع,تحويل التنقيح المتباعد,扩张卷积,扩张卷积,扩张卷积,dilater la circonvolution,convolution dilatée,convolution dilatée,拡張畳み込み,拡張畳み込み,希釈畳み込み,расширять свертку,расширенная свертка,Расширенная свертка
1333,dilation,تمدد,توسيع,توسيع,扩张,膨胀,膨胀,dilatation,dilatation,dilatation,拡張,膨張 (bouchou),膨張,расширение,"""Мы выполняем морфологическую эрозию и расширение на M i, чтобы получить маски динамических и статических областей соответственно, чтобы отключить потери возле границ маски. Мы контролируем систему с L mask и уменьшаем веса в динамических областях в 5 раз каждые 50K",растяжение
1334,dim,خافت,البُعد,دِيم,暗淡,维数,维数,faible,dim,dimensionalité,薄暗い,次元,次元数,тусклый,размерность,измерение
1335,dimension,البعد,"S * [X]، حيث d هو البعد و S * [X] هي القصة S مع الجملة X محاطة بنجوم.', 'كما ذكر، جميع التجارب المقدمة في الورقة ال",بُعد,方面,维度,维度,dimension,dimension,dimension,寸法,次元,次元,измерение,размерность,измерение
1336,dimension reduction,تخفيض البعد,تقليل الأبعاد,الحد من الأبعاد,降维,降维处理,降维,réduction dimensionnelle,Réduction de dimension,réduction de dimension,寸法削減,次元削減 (jigen sakugen),次元削減,уменьшение размеров,снижение размерности,уменьшение размерности
1337,dimensional vector,ناقلات الأبعاد,متجه بعدي,مُتَجِّه بُعْدي,维向量,维度向量,维向量,vecteur dimensionnel,vecteur dimensionnel,Vecteur dimensionnel,次元ベクトル,次元ベクトル,次元ベクトル,размерный вектор,многомерный вектор,Векторное пространство
1338,dimensionality,الأبعاد,الأبعادية,أبعاد,维数,维度,维数,dimensionnalité,dimensionnalité,dimensionnalité,次元性,次元数,次元数,размерность,размерность,размерность
1339,dimensionality reduction,تخفيض الأبعاد,تقليل الأبعاد,تقليص الأبعاد,降维,降维处理,降维,réduction de dimensionnalité,réduction de la dimensionnalité,réduction de dimension,次元削減,次元削減 (jigen sakugen),次元削減,уменьшение размерности,снижение размерности,уменьшение размерности
1340,dirac distribution,توزيع ديراك,توزيع ديراك,توزيع دیراك,狄拉克分布,狄拉克分布,狄拉克分布,répartition dirac,distribution de Dirac,distribution de Dirac,ディラック分布,ディラック分布,ディラックのデルタ関数,распределение Дирака,Дельта-функция,дельта-функция
1341,direct acyclic graph,الرسم البياني الحلقي الموجه,رسم بياني متجه غير دوري,رسم بياني موجه لاحلقي,有向无环图,有向无环图,有向无环图,Graphe acyclique dirigé,- Graph acyclique dirigé,graphe acyclique orienté,有向非巡回グラフ,有向非巡回グラフ,非循環有向グラフ,ориентированный ациклический граф,направленный ациклический граф,ориентированный ациклический граф
1342,direct edge,الحافة المباشرة,الحافة المباشرة,حافة موجهة,直接边缘,直接边,有向边,bord direct,arête directe,arête directe,ダイレクトエッジ,直接エッジ,直接エッジ,прямой край,прямое ребро,прямое ребро
1343,direct graph,رسم بياني مباشر,رسم بياني موجه,رسم بياني موجه,直接图,有向图,有向图,graphique direct,graphe dirigé,graphe orienté,直接グラフ,直接グラフ (chokusetsu gurafu),直接グラフ,прямой график,прямой граф,прямой граф
1344,direct graphical model,نموذج رسومي مباشر,النموذج البياني الموجهة,نموذج رسومي موجه,直接图形模型,直接图模型,直接概率图模型,modèle graphique direct,modèle graphique direct,modèle graphique dirigé,ダイレクトグラフィカルモデル,直接グラフィカルモデル,直接的なグラフィカルモデル,прямая графическая модель,напрямую графическая модель,прямая графическая модель
1345,direct tree,شجرة مباشرة,شجرة موجهة,شجرة موجهة,直接树,直接树,有向树,arbre direct,arbre direct,arbre dirigé,ダイレクトツリー,直接ツリー,直接木,прямое дерево,прямое дерево,прямое дерево
1346,dirichlet distribution,توزيع ديريشليت,توزيع ديريشليه,توزيع دريشليه,狄利克雷分布,狄利克雷分布,第里夏分布,distribution de dirichlet,distribution de Dirichlet,distribution de Dirichlet,ディリクレ分布,ディリクレ分布,ディリクレ分布,распределение Дирихле,распределение Дирихле,распределение Дирихле
1347,dirichlet process,عملية ديريشليت,- التسلسل ديريشليه,عملية ديريشليه,狄利克雷过程,狄利克雷过程,狄利克雷过程,processus de Dirichlet,processus de Dirichlet,processus de Dirichlet,ディリクレ法,ディリクレ過程,ディリクレ過程,процесс Дирихле,процесс Дирихле,процесс Дирихле
1348,disambiguation,توضيح,خوارزميات الوسم التل,تمييز,消歧义,消歧义 (disambiguation),消歧义,homonymie,désambiguïsation,désambiguïsation,曖昧さ回避,曖昧さ解消,曖昧性解消,значение,разрешение неоднозначности,снятие неоднозначности
1349,discount cumulative reward,خصم المكافأة التراكمية,مكافأة تراكمية مخفضة,نسبة المكافأة التراكمية المخصومة,折扣累积奖励,折扣累计奖励,折现累积奖励,récompense cumulative de réduction,récompense cumulée actualisée,récompense cumulative actualisée,割引累積報酬,割引累積報酬,割引累積報酬,накопительное вознаграждение со скидкой,скидка кумулятивного вознаграждения,дисконтированное кумулятивное вознаграждение
1350,discount factor,عامل الخصم,عامل الخصم,معامل الخصم,贴现系数,折扣因子,折现因子,facteur d'escompte,facteur d'escompte,facteur d'actualisation,割引率,割引率,割引率,коэффициент дисконтирования,коэффициент дисконтирования,коэффициент дисконтирования
1351,discount parameter,معلمة الخصم,معامل التخفيض,معامل الخصم,折扣参数,折扣参数,折扣参数,paramètre de remise,paramètre de réduction,paramètre d'escompte,割引パラメータ,割引パラメータ,割引パラメータ,параметр скидки,параметр скидки,параметр дисконтирования
1352,discount return,عودة الخصم,العائد المخفض,عائد مخصوم,折扣回报,折扣回报,折现回报,retour à prix réduit,rendement actualisé,retour actualisé,割引返品,割引リターン,割引報酬,возврат скидки,скидка на возврат,дисконтированная награда
1353,discount reward,مكافأة الخصم,مكافأة مخصومة,مكافأة مخصومة,折扣奖励,折扣奖励,折扣奖励,récompense de réduction,récompense réduite,Récompense actualisée,割引特典,割引報酬 (waribiki hoshu),割引報酬,вознаграждение со скидкой,скидка награды,дисконтированное вознаграждение
1354,discount state distribution,توزيع حالة الخصم,التوزيع الحالة المخفض,توزيع الحالة المخصومة,折扣状态分配,折扣状态分布,折扣状态分布,distribution d'état,distribution d'état actualisée,distribution d'états actualisée,割引状態の分布,割引状態分布,割引状態分布,государственное распределение,распределение с учетом скидки,распределение дисконтированных состояний
1355,discrete distribution,توزيع منفصل,التوزيع المتقطع,توزيع منفصل,离散分布,离散分布,离散分布,distribution discrète,- Distribution discrète,distribution discrète,離散分布,離散分布,離散分布,дискретное распределение,дискретное распределение,дискретное распределение
1356,discrete graphical model,نموذج رسومي منفصل,نموذج رسوم بيانية متقطعة,نموذج رسومي متقطع,离散图形模型,离散图模型,离散图形模型,modèle graphique discret,modèle graphique discret,modèle graphique discret,離散グラフィカルモデル,離散グラフィカルモデル,離散グラフィカルモデル,дискретная графическая модель,дискретная графическая модель,дискретная графическая модель
1357,discrete random variable,المتغير العشوائي المنفصل,متغير عشوائي diskreet,متغير عشوائي متقطع,离散随机变量,离散随机变量,离散随机变量,variable aléatoire discrète,variable aléatoire discrète,variable aléatoire discrète,離散確率変数,離散確率変数 (Risankanritsusu Hensu),離散確率変数,дискретная случайная величина,дискретная случайная величина,дискретная случайная величина
1358,discretization,التقدير,التقسيم القطعي,ترميز,离散化,"""['离散化是数据分析中的重要预处理步骤，在其中证明了具有最少分裂数的最优离散化问题是NP-Hard [6,35]。我们采用无监督的等频率离散器，将连续属性分割成具有相同实例数的桶 4。', '离散化后悔使用具有最小间隔∆的",离散化,discrétisation,discrétisation,Discrétisation,離散化,"""['離散化は、データ解析における重要な前処理ステップであり、最適な分割数を持つ最適な離散化問題はNP-Hardであることが証明されています[6,35]。ここでは、非監督学習の等確率discretizerを採用しています。これにより、連続属性が",離散化,дискретизация,дискретизация,дискретизация
1359,discriminant analysis,التحليل المميز,تحليل التمييز,تحليل التمييز,判别分析,判别分析,判别分析,Analyse discriminante,- Analyse discriminante,analyse discriminante,判別分析,識別分析 (shikibetsu bunseki),判別分析,дискриминантный анализ,дискриминантный анализ,дискриминантный анализ
1360,discriminant function,وظيفة تمييزية,وظيفة التمييز,دالة التمييز,判别函数,判别函数,判别函数,fonction discriminante,fonction discriminante,fonction discriminante,判別関数,判別関数,判別関数,дискриминантная функция,дискриминантная функция,функция дискриминанта
1361,discriminative,تمييزي,تمييزي,تميّزي,歧视性的,"""['我们目前使用自注意力模型来建模低分辨率输入。相比之下，大多数其他自监督结果使用基于CNN的编码器，这些编码器可以很容易地处理高分辨率图像。如何最好地弥合表现出色的自回归模型和辨别模型之间的差距并不是立即明显的。此外，我们发现我们的方法需要大",判别,discriminatoire,discriminatif,discriminant,差別的な,"""['現在、低解像度の入力をセルフアテンションでモデル化しています。それに対して、他のほとんどのセルフ教師なしの結果は、高解像度の画像と簡単に動作するCNNベースのエンコーダを使用しています。実行パフォーマンスの高い自己回帰モ",判別,дискриминационный,дискриминативный,дискриминативный
1362,discriminative approach,نهج تمييزي,النهج التمييزي,المنهج التمييزي,歧视性方法,辨别式方法,判别式方法,approche discriminatoire,approche discriminative,approche discriminative,差別的なアプローチ,識別的アプローチ (shikibetsu-teki apurōchi),識別的アプローチ,дискриминационный подход,дискриминативный подход,дискриминационный подход
1363,discriminative feature,الميزة التمييزية,الميزات التمييزية,ميزة تمييزية,判别特征,判别特征,判别特征,élément discriminant,caractéristique discriminative,caractéristique discriminante,差別的な特徴,識別的な特徴,識別特徴,отличительный признак,дискриминативная особенность,дискриминационный признак
1364,discriminative method,طريقة تمييزية,الطريقة التمييزية,طريقة تمييزية,判别法,判别方法,判别方法,méthode discriminante,méthode discriminative,méthode discriminante,判別方法,識別手法,識別法,дискриминационный метод,дискриминативный метод,дискриминационный метод
1365,discriminative model,نموذج تمييزي,النموذج التمييزي,نموذج تمييزي,判别模型,判别模型,判别模型,modèle discriminant,modèle discriminatif,modèle discriminant,識別モデル,識別モデル (Shikibetsu moderu),識別モデル,дискриминационная модель,дискриминативная модель,дискриминационная модель
1366,discriminative training,التدريب التمييزي,التدريب التمييزي,تدريب تمييزي,歧视性训练,判别式训练,判别训练,formation discriminante,Entraînement discriminatif,apprentissage discriminant,差別的な訓練,識別的トレーニング (shikibetsuteki torēningu),識別的学習,дискриминационное обучение,дискриминативное обучение,дискриминационное обучение
1367,discriminator,مميز,المميز,مميز,鉴别器,鉴别器 (Discriminator),判别器,discriminateur,discriminateur,discriminant,識別子,判別器 (handanshiki),識別器,дискриминатор,дискриминатор,дискриминатор
1368,discriminator network,شبكة التمييز,شبكة التمييز,شبكة التمييز,鉴别器网络,鉴别器网络,判别器网络,réseau discriminateur,réseau de discriminateur,réseau discriminateur,弁別ネットワーク,識別器ネットワーク (shibetsusha nettowāku),識別器ネットワーク,дискриминаторная сеть,дискриминаторная сеть,сеть дискриминатора
1369,disentangle,فصل,تفكيك,فصل,解开,解开,解缠,démêler,démêler,désembobiner,もつれを解く,属性を解きほぐす (zokuhogu),分離する,распутывать,развязать,расцеплять
1370,disentangled representation,التمثيل المفكك,التمثيل المفكك,تمثيل متباين,解开的表征,解缠表示,解缠表示,représentation démêlée,représentation désenchevêtrée,représentation désemboîtée,もつれの解けた表現,分離表現 (bunri hyougen),分離表現,распутанное представление,разделенное представление,разделенное представление
1371,disentanglement,فك التشابك,- التحرير,فصل الارتباط,解开,解缠,解缠,démêlage,démêlage,désembrouillement,もつれを解く,解体,分離,распутывание,распутывание,разделение
1372,disparity estimation,تقدير التفاوت,تقدير التفاوتات,تقدير التباين,视差估计,视差估计,视差估计,estimation de la disparité,estimation de disparité,estimation de la disparité,格差推定,不一致の推定 (fuhitsu no soutei),視差推定,оценка неравенства,оценка пространственного различия,оценка несоответствия
1373,disparity map,خريطة التفاوت,خريطة الاختلافات,خريطة التباين,视差图,视差图,视差图,carte des disparités,carte de disparité,carte de disparité,視差マップ,不一致マップ (ふいっちマップ),視差マップ,карта неравенства,карта диспаратности,карта смещений
1374,distance function,وظيفة المسافة,دالة المسافة,دالة مسافة,距离函数,距离函数 (jù lí hán shù),距离函数,fonction de distance,fonction de distance,fonction de distance,距離関数,距離関数 (きょりかんすう),距離関数,функция расстояния,функция расстояния,функция расстояния
1375,distance matrix,مصفوفة المسافة,مصفوفة المسافات,مصفوفة المسافات,距离矩阵,距离矩阵,距离矩阵,matrice de distance,matrice de distance,matrice de distances,距離行列,距離行列 (きょりぎょうれつ),距離行列,матрица расстояний,матрица расстояний,матрица расстояний
1376,distance measure,قياس المسافة,قياس المسافة,مقياس المسافة,距离测量,距离度量,距离度量,mesure de distance,mesure de distance,mesure de distance,距離測定,距離尺度 (きょりしゃくど),距離尺度,мера расстояния,мера расстояния,мера расстояния
1377,distance metric,متري المسافة,مقياس المسافة,مقياس المسافة,距离度量,距离度量,距离度量,métrique de distance,métrique de distance,métrique de distance,距離メトリック,距離メトリック,距離尺度,метрика расстояния,метрика расстояния,метрика расстояния
1378,distance transform,تحويل المسافة,تحويل المسافة,نقل المسافة,距离变换,距离变换,距离变换,transformation de distance,transformée de distance,transformation de distance,距離変換,距離変換 (きょりへんかん),距離変換,преобразование расстояния,трансформация расстояния,преобразование расстояния
1379,distant supervision,الإشراف البعيد,الرقابة البعيدة,الإشراف البعيد,远程监督,远程监督,远程监督,surveillance à distance,supervision à distance,supervision à distance,遠隔監視,遠隔監視 (distant supervision),遠隔監視,удаленное наблюдение,дистанционное наблюдение,дистанционное наблюдение
1380,distillation,التقطير,تقطير,تقطير,蒸馏,蒸馏 (zhēngliú),蒸馏,distillation,distillation,distillation,蒸留,"""['真のラベルの。私たちの結果は、アンサンブルが従来の定理とはまったく異なる方法で深層学習においてどのように機能するか、およびアンサンブルの出力に隠された「暗い知識」が蒸留に使用できる方法を示している。','未ラベ",蒸留,дистилляция,дистилляция,Дистилляция
1381,distribute learning,التعلم الموزع,التعلم الموزع,التعلم الموزع,分布式学习,分布式学习,分布式学习,apprentissage distribué,apprentissage distribué,apprentissage distribué,分散学習,分散学習 (Bunsan gakushū),分散学習,распределенное обучение,распределенное обучение,распределенное обучение
1382,distribute learning system,توزيع نظام التعلم,نظام تعلم موزع,نظام التعلم الموزع,分布式学习系统,分布式学习系统,分布式学习系统,distribuer le système d'apprentissage,système d'apprentissage distribué,système d'apprentissage distribué,分散学習システム,分散学習システム (Bunsan gakushu shisutemu),分散学習システム,распределенная система обучения,система распределенного обучения,распределенная обучающая система
1383,distribute representation,توزيع التمثيل,التمثيل الموزع,تمثيل موزع,分配代表权,分布式表示,分布式表示,distribuer la représentation,représentation distribuée,représentation distribuée,代表を分配する,- 分散表現 (ぶんさんひょうげん),分散表現,распределять представительство,Распределенное представление,распределенное представление
1384,distributed information retrieval,استرجاع المعلومات الموزعة,استرجاع المعلومات الموزعة,نظم استرجاع المعلومات الموزعة,分布式信息检索,分布式信息检索,分布式信息检索,récupération d'informations distribuées,recherche d'informations distribuée,Récupération d'informations distribuée,分散型情報検索,分散情報検索 (ぶんさんじょうほうけんさく),分散情報検索,распределенный поиск информации,- Распределенный поиск информации,распределенное извлечение информации
1385,distribution shift,تحول التوزيع,تحول التوزيع,انتقال التوزيع,分布转移,分布偏移,分布偏移,changement de distribution,changement de distribution,glissement de distribution,分布シフト,分布シフト (ぶんぷシフト),分布のシフト,сдвиг распределения,сдвиг распределения,распределение смещения
1386,distribution vector,ناقلات التوزيع,متجه التوزيع,متجه التوزيع,分布向量,分布向量,分布向量,vecteur de distribution,vecteur de distribution,vecteur de distribution,分布ベクトル,分布ベクトル (ぶんぷベクトル),分布ベクトル,вектор распределения,вектор распределения,вектор распределения
1387,distributional,التوزيعية,التوزيعية,توزيعي,分布式的,分布的,分布式的,distributionnel,distributionnel,distributionnelle,分布的な,分布的,分布的,распределительный,распределение,распределенный
1388,distributional feature,ميزة التوزيع,السمة التوزيعية,ميزة توزيعية,分布特征,分布特征,分布式特征,caractéristique de distribution,caractéristique distributionnelle,caractéristique distributionnelle,配信機能,分布特徴,分布特徴,особенность распределения,распределенная характеристика,дистрибуционная черта
1389,distributional hypothesis,فرضية التوزيع,فرضية التوزيعية,فرضية التوزيع,分布假说,分布假设,分布式假说,hypothèse de distribution,hypothèse distributionnelle,hypothèse distributionnelle,分布仮説,分布仮説 (ぶんぷかせつ),分布仮説,гипотеза распределения,гипотеза о распределении,распределенная гипотеза
1390,distributional model,النموذج التوزيعي,نموذج توزيعي,نموذج توزيعي,分布模型,分布模型,分布式模型,modèle de distribution,- Modèle de distribution,modèle distributionnel,分布モデル,分布モデル (Bunpu Moderu),分布モデル,модель распределения,- Распределительная модель,Дистрибуционная модель
1391,distributional representation,التمثيل التوزيعي,التمثيل التوزيعي,التمثيل التوزيعي,分布表征,分布式表示,分布式表示,représentation distributionnelle,représentation distributionnelle,représentation distributionnelle,分布表現,分布表現 (Bunpu Hyōgen),分布表現,распределительное представительство,распределительное представление,Распределенное представление
1392,distributional semantic,الدلالية التوزيعية,الدلالة التوزيعية,دلالات توزيعية,分布语义,分布语义,分布语义,sémantique distributionnelle,sémantique distributionnelle,sémantique distributionnelle,分散セマンティック,分布意味論,分布意味論,распределительная семантика,семантика распределения,распределительная семантика
1393,distributional semantic model,النموذج الدلالي التوزيعي,نموذج دلالي توزيعي,نموذج الدلالات التوزيعية,分布语义模型,分布语义模型,分布语义模型,modèle sémantique distributionnel,- Modèle sémantique distributionnel,modèle sémantique distributionnel,分散セマンティックモデル,- 分布意味モデル (Bunpu imi moderu),分布意味論モデル,распределительная семантическая модель,модель семантического распределения,дистрибутивная семантическая модель
1394,distributional similarity,التشابه التوزيعي,التشابه التوزيعي,التشابه التوزيعي,分布相似性,分布相似性,分布相似性,similarité de distribution,- Similarité distributionnelle,similarité distributionnelle,分布の類似性,- 分布的類似性 (Bunpoteki risansei),分布的類似性,сходство распределения,- Распределительная похожесть,распределительная похожесть
1395,distributional word representation,تمثيل الكلمات التوزيعية,التمثيل الكلامي التوزيعي,التمثيل التوزيعي للكلمات,分布词表示,分布式词表示,分布式词表示,représentation distribuée des mots,Représentation distributionnelle des mots,représentation distributionnelle des mots,分布的な単語表現,分散単語表現,分布表現単語,распределительное представление слова,- Распределенное словесное представление,распределенное представление слов
1396,distributionally robust optimization,التحسين التوزيعي القوي,أمثلة على تخفيف الفجوة في التمثيل باستخدام أمثلة تحليلية حيث تواجه النهج هذه المشكلة في قسم التجريبي (القسم 5) من طريقة الأمثلة في التخفيف من الفجوة في التمثيل.,"تحسين قوي توزيعيًا

DRO",分布稳健优化,分布鲁棒优化,分布鲁棒优化,optimisation robuste sur le plan distributionnel,optimisation robuste en termes de distribution,optimisation robuste par distribution,分布的に堅牢な最適化,分布的に堅牢な最適化 (distributionally robust optimization),分布的に頑健な最適化,устойчивая к распределению оптимизация,оптимизация с учетом распределения,дистрибуционно-робастная оптимизация
1397,divergence operator,عامل التباعد,مشغل التشتت,معامل التباعد,散度算子,散度算子,散度算子,opérateur de divergence,opérateur de divergence,opérateur de divergence,発散演算子,発散演算子 (はっさんえんざんし),発散演算子,оператор дивергенции,оператор дивергенции,оператор дивергенции
1398,diversity score,درجة التنوع,نقطة التنوع,درجة التنوع,多样性得分,多样性得分,多样性分数,score de diversité,- Score de diversité,score de diversité,多様性スコア,多様性スコア,多様性スコア,оценка разнообразия,оценка разнообразия,Балл разнообразия
1399,do-calculus,القيام بحساب التفاضل والتكامل,- التسلسل الزمني المُحسّن,حساب العمل,微积分,do-演算,干预演算,faire du calcul,calcul-do,calcul-do,微積分を行う,do-計算,do-計算,делать расчет,"""['Alternatively, if we discard W 2 and consider the null set for adjustment (Z = {}), condition (i) fails since there is an open backdoor path from X to Y (X ← W 2 ← U → Y ). Despite the inapplicability of the s-backdoor , P ( y|do ( x ) ) is still s-recoverable since , using do-calculus , we can show that Q = P ( y|do ( x ) , S = 1 ) , which reduces to w2 P ( y|x ,",исчисление do
1400,document,وثيقة,مستند,وثيقة,文档,文档,文档,document,document,document,書類,文書 (ぶんしょ),文書,документ,документ,документ
1401,document classification,تصنيف الوثيقة,تصنيف الوثائق,تصنيف الوثائق,文件分类,文件分类,文档分类,classement des documents,Classification de documents,classement de documents,文書の分類,文書分類,文書分類,классификация документов,классификация документов,классификация документов
1402,document clustering,تجميع المستندات,تجميع الوثائق,تجميع الوثائق,文档聚类,文档聚类,文档聚类,regroupement de documents,regroupement de documents,regroupement de documents,ドキュメントのクラスタリング,文書クラスタリング,文書クラスタリング,кластеризация документов,кластеризация документов,кластеризация документов
1403,document corpus,مجموعة الوثيقة,المعجم الوثائقي,مجموعة الوثائق,文档语料库,文档语料库,文档语料库,corpus documentaire,corpus de documents,corpus de documents,文書コーパス,文書コーパス,文書コーパス,корпус документов,корпус документов,корпус документов
1404,document retrieval,استرجاع الوثيقة,استرجاع المستندات,استرجاع الوثائق,文献检索,文档检索 (document retrieval),文档检索,récupération de documents,récupération de documents,récupération de documents,文書の検索,文書検索,文書検索,поиск документов,поиск документов,извлечение документов
1405,document summarization,تلخيص الوثيقة,تلخيص المستندات,تلخيص المستندات,文件摘要,文档摘要,文档摘要,résumé du document,résumé de document,résumé de document,文書の要約,文書要約,文書要約,обобщение документов,суммирование документов,обобщение документов
1406,document vector,ناقلات الوثيقة,متجه المستندات,متجه الوثيقة,文档向量,文件向量,文档向量,vecteur de documents,vecteur de document,vecteur de document,ドキュメントベクトル,ドキュメントベクトル,文書ベクトル,вектор документа,вектор документа,вектор документа
1407,document-level,على مستوى الوثيقة,- مستوى الوثيقة,على مستوى المستند,文档级,文档级,文档层面,au niveau du document,niveau du document,niveau du document,ドキュメントレベル,ドキュメントレベル,ドキュメントレベル,уровень документа,уровень документа,уровне документа
1408,document-topic assignment,مهمة موضوع الوثيقة,تعيين موضوع الوثيقة,تعيين الوثيقة للموضوع,文档主题分配,文档主题分配,文档主题分配,affectation de sujet de document,attribution de sujets aux documents,affectation document-sujet,文書トピックの割り当て,文書-トピックの割り当て,文書トピック割り当て,назначение темы документа,назначение темы документа,распределение документ-тема
1409,domain,اِختِصاص,مجال,مجال,领域,领域 (lǐngyù),领域,domaine,domaine,domaine,ドメイン,ドメイン,ドメイン,домен,домен,домен
1410,domain adaptation,التكيف المجال,تكييف المجال,تكيف النطاق,领域适应,领域自适应,领域适应,adaptation de domaine,adaptation de domaine,adaptation de domaine,ドメイン適応,ドメイン適応 (Domain Adaptation),ドメイン適応,адаптация домена,адаптация домена,перенос домена
1411,domain element,عنصر المجال,عنصر المجال,عنصر مجال,域元素,域元素,领域元素,élément de domaine,élément de domaine,élément de domaine,ドメイン要素,ドメイン要素,ドメイン要素,элемент домена,элемент области,элемент домена
1412,domain gap,فجوة المجال,فجوة المجال,فجوة النطاق,领域差距,领域差异,领域差距,écart de domaine,fossé de domaine,écart de domaine,ドメインギャップ,ドメインギャップ (domein gyappu),ドメインギャップ,доменный разрыв,доменный разрыв,расхождение между областями
1413,domain generalization,تعميم المجال,التعميم على المجالات,تعميم النطاق,领域泛化,领域泛化,领域泛化,généralisation de domaine,généralisation de domaine,généralisation de domaine,ドメインの一般化,ドメイン汎化,ドメイン一般化,генерализация предметной области,обобщение области,обобщение на различные домены
1414,domain knowledge,معرفة المجال,المعرفة المجالية,المعرفة المجالية,领域知识,领域知识,领域知识,connaissance du domaine,connaissances du domaine,connaissances du domaine,領域知識,領域知識,ドメイン知識,базовые знания,предметные знания,предметная область
1415,domain mismatch,عدم تطابق المجال,- تباين المجالات,عدم تطابق المجال,域不匹配,域不匹配,领域不匹配,incompatibilité de domaine,incompatibilité de domaine,désaccord de domaine,ドメインの不一致,ドメインミスマッチ,ドメインミスマッチ,несоответствие домена,доменное несоответствие,несоответствие доменов
1416,domain ontology,أنطولوجيا المجال,أونتولوجيا المجال,نظام تصنيف المجال,领域本体,领域本体论,领域本体论,ontologie de domaine,ontologie de domaine,ontologie de domaine,ドメインオントロジー,ドメインオントロジー,ドメインオントロジー,онтология предметной области,доменная онтология,онтология домена
1417,domain shift,تحول المجال,تحويل المجال,تحول المجال,域转移,领域偏移,领域漂移,changement de domaine,décalage de domaine,glissement de domaine,ドメインシフト,ドメインシフト,ドメインシフト,сдвиг домена,сдвиг домена,смещение домена
1418,domain transfer,نقل المجال,نقل المجالية,نقل النطاق,域名转移,领域迁移,领域迁移,transfert de domaine,transfert de domaine,transfert de domaine,ドメイン移管,ドメイン転送 (domein tensou),ドメイン転送,перенос домена,перенос домена,перенос домена
1419,domain-specific,خاص بالمجال,متخصص في المجال,تخصص المجال,特定领域的,领域特定,特定领域的,spécifique au domaine,spécifique au domaine,spécifique au domaine,ドメイン固有の,ドメイン固有,ドメイン特化型,специфичный для домена,Domain-specific - область-специфический,домено-специфический
1420,dot product,المنتج نقطة,الضرب النقطي,ضرب نقطي,点积,点积,点积,produit scalaire,produit scalaire,produit scalaire,ドット積,ドット積,内積,скалярное произведение,скалярное произведение,скалярное произведение
1421,dot-product attention,الاهتمام بالمنتج النقطي,الانتباه بضرب النقاط,انتباه ضرب النقطة,点积注意力,点积注意力,点积注意力,attention au produit scalaire,attention de produit scalaire,attention par produit scalaire,内積注意,ドット積注意,内積注目機構,внимание точечного произведения,внимание на скалярное произведение,Внимание скалярного произведения
1422,down-sample layer,طبقة العينة السفلية,طبقة التخفيض في العينة,طبقة التقليص,下采样层,下采样层,下采样层,couche de sous-échantillonnage,couche de sous-échantillonnage,Couche de sous-échantillonnage,ダウンサンプルレイヤー,ダウンサンプリング層,ダウンサンプリング層,слой пониженной выборки,слои уменьшения размера (down-sample layer),слой даунсэмплинга
1423,down-sampling,خفض العينات,التخفيض في العينة,تنزيل المعاينات,下采样,下采样,下采样,sous-échantillonnage,ré-échantillonnage,sous-échantillonnage,ダウンサンプリング,ダウンサンプリング,ダウンサンプリング,понижающая выборка,снижение частоты оцифровки,Дауншемплинг
1424,downsampling block,كتلة الاختزال,كتلة التحجيم السالبة,كتلة تصغير الحجم,下采样块,下采样块,下采样模块,bloc de sous-échantillonnage,bloc de sous-échantillonnage,bloc de sous-échantillonnage,ダウンサンプリングブロック,ダウンサンプリングブロック,ダウンサンプリングブロック,блок понижающей дискретизации,блок уменьшенияразложения,блок децимации
1425,downsampling factor,عامل الاختزال,عامل التخفيض في العينة,معامل تصغير العينات,下采样因子,下采样因子,下采样系数,facteur de sous-échantillonnage,facteur de sous-échantillonnage,facteur de sous-échantillonnage,ダウンサンプリング係数,ダウンサンプリングファクター (downsampling factor),ダウンサンプリング係数,коэффициент понижающей дискретизации,фактор снижения частоты дискретизации,коэффициент уменьшения
1426,downsampling layer,طبقة الاختزال,طبقة التخفيض في الدقة,طبقة تصغير العينات,下采样层,下采样层,下采样层,couche de sous-échantillonnage,couche de sous-échantillonnage,couche de sous-échantillonnage,ダウンサンプリング層,ダウンサンプリング層,ダウンサンプリング層,слой понижающей дискретизации,слой субдискретизации,слой дауснсэмплинга
1427,downstream dataset,مجموعة البيانات النهائية,مجموعة البيانات الناتجة,قاعدة بيانات تالية,下游数据集,下游数据集,下游数据集,ensemble de données en aval,- Jeu de données aval,ensemble de données en aval,下流のデータセット,- 下流データセット (karyū dētasetto),下流データセット,набор данных ниже по течению,данные для последующего использования,набор данных на выходе
1428,downstream model,نموذج المصب,نموذج متدفق,نموذج متدفق,下游模型,下游模型,下游模型,modèle en aval,modèle aval,modèle en aval,下流モデル,下流モデル (karyū moderu),ダウンストリームモデル,последующая модель,модель нижнего потока,модель понизу
1429,downstream performance,أداء المصب,الأداء النهائي,الأداء اللاحق,下游表现,下游性能,下游性能,performances en aval,performance en aval,performance en aval,下流のパフォーマンス,下流のパフォーマンス,下流のパフォーマンス,производительность ниже по течению,производительность на выходе,производительность на последующих задачах
1430,downstream task,مهمة المصب,المهمة الفرعية,مهمة تالية,下游任务,下游任务,下游任务,tâche en aval,tâche en aval,tâche en aval,下流タスク,下流タスク (karyū tasuku),下流タスク,последующая задача,задача последующей обработки,сопутствующая задача
1431,dropout distribution,توزيع التسرب,توزيع الانسحاب,توزيع دروب-أوت,辍学分布,"""['令p l = p(Y 1 ≻ Y 2 |θ l ),其中θ l ∼ q ϕ (θ)，表示使用第l个样本θ l 从退出分布中进行评估度量的预测。另外，让p = 1/L∑ l=1 p l表示平均预测。', '因此，在变分推断中提出了几种近似方法，例如寻找一个真后验的替代分",丢弃分布,répartition des abandons,distribution de dropout,distribution de suppression aléatoire,ドロップアウト分布,ドロップアウト分布,ドロップアウト分布,распределение отсева,распределение исключения,распределение dropout
1432,dropout layer,طبقة التسرب,طبقة الانسحاب,طبقة إسقاط,漏失层,丢弃层,丢弃层,couche d'abandon,- Couche de désactivation,couche de décrochage,ドロップアウト層,ドロップアウト層,ドロップアウト層,выпадающий слой,слой отсева,слой отсева
1433,dropout probability,احتمال التسرب,احتمالية الإسقاط,احتمالية التسرب,辍学概率,丢失概率,丢弃概率,probabilité d'abandon,probabilité de désactivation,probabilité d'abandon,ドロップアウトの確率,ドロップアウト確率,脱落確率,вероятность отсева,вероятность отсева,вероятность отсева
1434,dropout rate,معدل التسرب,معدل الانسحاب,معدل التسرب,辍学率,- 退出率,丢弃率,taux d'abandon,taux d'abandon,taux d'abandon,中退率,ドロップアウト率,除去率,уровень отчисления,"""['Использование нормализации слоев обеспечивает более быстрое обучение и более низкую потерю обучения, но приводит к более высокой потере на валидационном наборе при обучении модели 108M. Этот разрыв в обобщении остается даже в том случае, если мы тщательно настра",коэффициент отсева
1435,dropout ratio,نسبة التسرب,معدل الانسحاب,نسبة الإسقاط,辍学率,失活比率,丢失率,taux d'abandon scolaire,- Taux d'abandon,taux d'abandon,中退率,ドロップアウト比率,脱落率,коэффициент отсева,"""Мы устанавливаем коэффициент масштабирования потерь регуляризации на основе согласованности как α = 0,15 и коэффициент отсева как 0,1. Для вывода мы применяем алгоритм частичного поиска луча к обученной модели seq2seq. Мы устанав",коэффициент выпадения
1436,dual decomposition,التحلل المزدوج,التحليل المزدوج,التجزئة المزدوجة,对偶分解,双重分解,双分解,double décomposition,décomposition duale,décomposition duale,二重分解,二重分解,二重分解,двойное разложение,двойное разложение,двойное разложение
1437,dual encoder model,نموذج التشفير المزدوج,نموذج الترميز المزدوج,نموذج المشفر المزدوج,双编码器型号,双编码器模型,双编码器模型,modèle à double encodeur,- Modèle d'encodeur double,modèle à double encodeur,デュアルエンコーダーモデル,デュアルエンコーダーモデル,デュアルエンコーダーモデル,модель с двойным энкодером,модель двойного кодера,двунаправленная энкодерная модель
1438,dual norm,القاعدة المزدوجة,المعيار المزدوج,المعيار المقابل,双重规范,- 双共轭范数,对偶范数,double norme,norme duale,norme duale,二重規範,デュアルノルム,双対ノルム,двойная норма,двойная норма,двойственная норма
1439,dual objective,هدف مزدوج,الهدف المزدوج,نهج هدف مزدوج,双重目标,双目标,双重目标,double objectif,objectif double,objectif dual,二重の目的,二重目的,二重目的関数,двойная цель,двойная цель,двойная цель
1440,dual optimization problem,مشكلة التحسين المزدوج,مشكلة تحقيق التحسين المزدوج,مشكلة التحسين الثنائية,对偶优化问题,双重优化问题,对偶优化问题,problème de double optimisation,problème d'optimisation double,problème d'optimisation duale,二重最適化問題,二重最適化問題,双対最適化問題,проблема двойной оптимизации,двойная задача оптимизации,двойная оптимизационная задача
1441,dual parameter,المعلمة المزدوجة,معلمتان,ثنائي المعلمة,双参数,双参数,对偶参数,double paramètre,paramètre dual,paramètres duaux,デュアルパラメータ,デュアルパラメータ,二重パラメータ,двойной параметр,двойной параметр,двойной параметр
1442,dual problem,مشكلة مزدوجة,المشكلة المزدوجة,المشكلة المزدوجة,对偶问题,对偶问题,对偶问题,double problème,problème dual,problème dual,二重の問題,双対問題,双対問題,двойная проблема,дуальная задача,двойственная задача
1443,dual program,برنامج مزدوج,البرنامج المزدوج,برنامج مزدوج,双计划,对偶问题,对偶程序,double programme,programme dual,Programme dual,デュアルプログラム,二重プログラム (nijuu puroguramu),デュアルプログラム,двойная программа,двойная программа,двойственная программа
1444,dual solution,الحل المزدوج,الحل الثنائي,حل ثنائي,双解,双重解方案 (dual solution),对偶解,solution double,- Solution duale,solution duale,デュアルソリューション,二重解,双対解,двойное решение,двойное решение,двойственное решение
1445,dual variable,متغير مزدوج,المتغير المزدوج,متغير ثنائي,双变量,双重变量,对偶变量,double variable,"""['Notez que le sous-problème de l'opérateur proximal associé à la relaxation convexe dans [2] est résolu en recherchant la variable duale de manière différente avec une complexité temporelle O(d 2). En résumé, nous reformulons l'opérateur proximal pour le Lasso hiérarchique faible d'origine en factorisant les coefficients inconnus.', 'Reformulons ceci comme un problème de minimisation dans une variable p ∈ R n pour la",variable duale,二重変数,二重変数 (nijuu hensuu),双対変数,двойная переменная,двойная переменная,двойственная переменная
1446,duality gap,فجوة الازدواجية,فجوة الثنائية,الفجوة الازدواجية,二元差距,对偶间隙,对偶间隙,écart de dualité,écart de dualité,écart de dualité,二元性のギャップ,双対ギャップ,双対ギャップ,разрыв дуальности,разрыв двойственности,разрыв двойственности
1447,dynamic bayesian network,شبكة بايزي ديناميكية,شبكة بيزية ديناميكية,شبكة بايز الديناميكية,动态贝叶斯网络,动态贝叶斯网络,动态贝叶斯网络,réseau bayésien dynamique,réseau bayésien dynamique,réseau bayésien dynamique,動的ベイジアンネットワーク,ダイナミックベイジアンネットワーク,動的ベイジアンネットワーク,динамическая байесовская сеть,динамическая байесовская сеть,динамическая байесовская сеть
1448,dynamic model,نموذج ديناميكي,النموذج الديناميكي,نموذج ديناميكي,动态模型,动态模型,动态模型,modèle dynamique,modèle dynamique,modèle dynamique,動的モデル,動的モデル (Douteki Moderu),動的モデル,динамическая модель,динамическая модель,динамическая модель
1449,dynamic programming algorithm,خوارزمية البرمجة الديناميكية,خوارزمية البرمجة الديناميكية,خوارزمية البرمجة الديناميكية,动态规划算法,动态规划算法,动态规划算法,algorithme de programmation dynamique,algorithme de programmation dynamique,algorithme de programmation dynamique,動的計画法アルゴリズム,動的計画法アルゴリズム,動的プログラミングアルゴリズム,алгоритм динамического программирования,динамический алгоритм программирования,алгоритм динамического программирования
1450,dynamic time warp,تشوه الوقت الديناميكي,- تشويه الزمن الديناميكي,التشوه الديناميكي للزمن,动态时间扭曲,动态时间规整,动态时间规整,distorsion temporelle dynamique,alignement temporel dynamique,Distorsion dynamique du temps,ダイナミックタイムワープ,ダイナミックタイムワープ,動的時間伸縮法,динамическое искажение времени,динамическое выравнивание времени,динамическое временное искривление
1451,dynamical model,نموذج ديناميكي,النموذج الديناميكي,نموذج ديناميكي,动力学模型,动力学模型,动力学模型,modèle dynamique,- Modèle dynamique,modèle dynamique,力学モデル,動的モデル (Dōteki moderu),動力学モデル,динамическая модель,динамическая модель,динамическая модель
1452,dynamical system,نظام ديناميكي,نظام ديناميكي,نظام ديناميكي,动力系统,动力系统,动力系统,système dynamique,système dynamique,système dynamique,動的システム,動的システム,動力学系,динамическая система,динамическая система,динамическая система
1453,e-step,الخطوة الإلكترونية,الخطوة E,خطوة الانتشار,e步,"“['8) which indicates that incorporating constraints in the cluster assignment process is useful for these datasets. This result is reversed for News-Related-3 (Fig. 6), implying that in some cases using constraints in the E-step may be unnecessary, which agrees with previous results on other domains [6].', 'Standard structural EM scores each network using the log probability of the expected data, which is easily computed from the output of the E-step above. However, because our final goal is to correctly classify the ""things,"" we would rather score each structure using the log probability of the T",期望步,e-étape,E-étape,étape-E,イーステップ,Eステップ,E-ステップ,электронный шаг,E-шаг,шаг-Э
1454,early fusion,الانصهار المبكر,الاندماج المبكر,الدمج المبكر,早期融合,早期融合,早期融合,fusion précoce,fusion précoce,fusion précoce,初期融合,アーリーフュージョン (early fusion),初期融合,раннее слияние,Раннее слияние,ранний фьюжн
1455,early stop,توقف مبكر,- توقف مبكر,توقف مبكر,提早停止,提前停止,提前停止,arrêt anticipé,arrêt précoce,arrêt précoce,早めの停止,早期停止,早期停止,ранняя остановка,раннее прекращение,ранняя остановка
1456,earth-mover distance,مسافة محرك الأرض,المسافة المحركة للأرض,مسافة نقل الأرض,推土机距离,地球移动距离,运输距离,distance engin de terrassement,distance du transporteur terrestre,distance de transport,土工距離,地球移動距離,地球移動距離 (ちきゅういどうきょり),расстояние землеройной машины,Расстояние переноса земли,расстояние переноса земли
1457,edge detection,كشف الحد,الكشف عن الحواف,الكشف عن الحواف,边缘检测,边缘检测,边缘检测,détection des contours,détection de bordures,détection de contours,エッジ検出,エッジ検出 (Edge Detection),エッジ検出,обнаружение края,Обнаружение краев,обнаружение границ
1458,edge feature,ميزة الحافة,ميزة الحافة,ميزة الحافة,边缘特征,边缘特征,边特征,élément de bord,caractéristique des arêtes,caractéristique d'arête,エッジフィーチャ,エッジ特徴,エッジ特徴,крайняя особенность,крайние особенности,граневой признак
1459,edge label,تسمية الحافة,تسمية الحافة,ملصق الحافة,边缘标签,边标签,边标签,étiquette de bord,étiquette de bord,étiquette d'arête,エッジラベル,エッジラベル,エッジラベル,крайняя метка,Edge label - метка ребра,граничная метка
1460,edge prediction,التنبؤ الحافة,تنبؤ الحافة,التنبؤ بالحافة,边缘预测,边缘预测,边预测,prédiction de bord,prédiction de bord,prédiction d'arête,エッジ予測,エッジ予測 (edge prediction),エッジ予測,прогнозирование края,предсказание ребра,предсказание ребра
1461,edge set,مجموعة الحافة,مجموعة الحواف,مجموعة الحواف,边缘集,边集,边集,ensemble de bords,ensemble d'arêtes,ensemble d'arêtes,エッジセット,エッジセット,エッジセット,набор кромок,концентрация рёбер,набор ребер
1462,edge weight,وزن الحافة,وزن الحافة,وزن الحافة,边缘权重,边权,边权重,poids du bord,poids de l'arête,poids des arêtes,エッジの重み,エッジの重み,エッジ重み,вес кромки,вес ребра,граневой вес
1463,edit distance,تحرير المسافة,مسافة التحرير,المسافة التعديلية,编辑距离,编辑距离,编辑距离,modifier la distance,- Distance d'édition,distance d'édition,距離を編集する,編集距離,編集距離,изменить расстояние,расстояние редактирования,расстояние редактирования
1464,effective receptive field,مجال استقبال فعال,- التداخل الاستقبالي الفعال,تعريف المستقبل الفعال,有效感受野,有效感受野,有效感受野,champ récepteur efficace,- Champ réceptif effectif,Champ récepteur effectif,有効受容野,効果的受容野,有効受容野,эффективное рецептивное поле,- Эффективное рецептивное поле,эффективное рецептивное поле
1465,ego-motion,حركة الأنا,- تحرك الأنا,حركة الذات,自我运动,自我运动,自身运动,mouvement de l'ego,mouvement du moi,mouvement ego-centrique,エゴモーション,エゴモーション,自車運動,движение эго,Эго-движение,движение эго-транспортного средства
1466,eigen-decomposition,التحلل الذاتي,تحليل القيم الذاتية,تحليل القيم الذاتية,特征分解,特征分解,特征分解,décomposition propre,décomposition propre,décomposition par valeurs propres,固有分解,固有値分解,固有分解,собственное разложение,собственное разложение,собственное разложение
1467,eigenbasis,eigenbasis,أساس القيم الذاتية,قاعدة الأشكال الذاتية,特征基,特征基底,特征基,base propre,base propre,base propre,固有基準,固有ベクトル,固有ベクトル基底,собственный базис,собственный базис,cобственный базис
1468,eigendecay,eigendecay,تحلل القيمة الذاتية,تلاشي الشيء الذاتي,特征衰变,特征衰减,特征衰减,désintégration propre,décroissance propre,décroissance propre,固有減衰,固有減少 (koyu genshō),固有減衰,собственный распад,собственное затухание,Собственное затухание
1469,eigenfunction,وظيفة ذاتية,دالة القيم الذاتية,حالة موجية,本征函数,特征函数 (eigenfunction),特征函数,fonction propre,fonction propre,fonction propre,固有関数,固有関数,固有関数,собственная функция,собственная функция,собственная функция
1470,eigenspace,eigenspace,المساحة الخاصة,الفضاء المميز,特征空间,特征空间,特征空间,espace propre,\n Théorème 3 (Alignement des espaces propres). Sous l'équation,espace propre,固有空間,固有空間,固有空間,собственное пространство,собственное пространство,собственное пространство
1471,eigenspectrum,الطيف الذاتي,طيف القيم الذاتية,طيف الجذور المميزة,特征谱,特征谱,特征谱,spectre propre,spectre propre,spectre propre,固有スペクトル,固有スペクトル,固有スペクトル,собственный спектр,спектр собственных значений,собственный спектр
1472,eigenvalue,القيمة الذاتية,قيمة الذاتية,قيمة ذاتية,特征值,特征值,特征值,valeur propre,valeur propre,valeur propre,固有値,固有値 (eigenvalue),固有値,собственное значение,собственное значение,собственное значение
1473,eigenvalue decomposition,تحلل القيمة الذاتية,تحليل القيم الذاتية,تحليل القيم الذاتية,特征值分解,特征值分解,特征值分解,décomposition des valeurs propres,décomposition en valeurs propres,décomposition en valeurs propres,固有値分解,固有値分解 (koyuuchi bunkai),固有値分解,разложение собственных значений,декомпозиция собственных значений,разложение на собственные значения
1474,eigenvector,eigenvector,المتجه الذاتي,متجه ذاتي,特征向量,特征向量,特征向量,vecteur propre,vecteur propre,vecteur propre,固有ベクトル,固有ベクトル (koyū bekkutoru),固有ベクトル,собственный вектор,Собственный вектор,собственный вектор
1475,elastic net regularization,تنظيم صافي مرن,التنظيم الشبكي المرن,تنظيم الشبكة المرنة,弹性网络正则化,弹性网络正则化,弹性网络正则化,régularisation nette élastique,régularisation du filet élastique,régularisation élastique,弾性ネットの正則化,弾性ネット正則化,弾性ネット正則化,эластичная чистая регуляризация,регуляризация эластичной сети,эластичная сетевая регуляризация
1476,element-wise,عنصر الحكمة,عنصري الحكمة,بشكل عنصري,逐元素,"""['我们通过位置编码[95]和为每种提示类型和自由形式文本学习的嵌入来表示点和框，使用来自CLIP [82]的现成文本编码器将其相加。密集提示（即掩模）使用卷积嵌入，并与图像嵌入逐元素相加。掩模解码器。'，'应用线性投影层将所有组件",元素式,élément par élément,élément par élément,par éléments,要素ごと,要素ごと,要素ごと,поэлементно,поэлементно,поэлементно
1477,element-wise multiplication,الضرب بالعنصر,الضرب عنصر بعنصر,ضرب عنصر بعنصر,逐元素乘法,逐元素相乘,元素级乘法,multiplication par éléments,multiplication élément par élément,multiplication élément par élément,要素ごとの乗算,要素ごとの乗算,要素ごとの乗算,поэлементное умножение,поэлементное умножение,поэлементное умножение
1478,element-wise product,المنتج الحكيم,الضرب العنصري,ضرب العناصر لعنصر,元素乘积,逐元素乘积,元素积,produit par élément,produit élément par élément,produit élément par élément,要素ごとの積,要素ごとの積,要素毎の積,поэлементный продукт,произведение по элементам,поэлементное произведение
1479,elementary tree,شجرة ابتدائية,شجرة ابتدائية,شجرة أولية,初等树,基本树,初等树,arbre élémentaire,arbre élémentaire,arbre élémentaire,基礎ツリー,基本木,素素木,элементарное дерево,элементарное дерево,элементарное дерево
1480,eligibility trace,تتبع الأهلية,أثر الأهلية,مسار الأهلية,资格追踪,资格追踪,资格迹,trace d'éligibilité,trace d'éligibilité,trace d'éligibilité,資格追跡,適格性トレース,適格性トレース,трассировка приемлемости,след пригодности,следовательный след
1481,embedded deformation graph,الرسم البياني للتشوه المضمن,الرسم البياني للتشوه المضمن,جراف التشوه المُضمَّن,嵌入变形图,嵌入式变形图,嵌入式变形图,graphique de déformation intégré,graphe de déformation intégré,graphe de déformation incorporé,埋め込み変形グラフ,埋め込み変形グラフ (Maemebi Henkei Gurafu),埋め込み変形グラフ,встроенный график деформации,встроенный граф деформации,встроенный граф деформации
1482,embedding dimension,البعد التضمين,- تعبئة البعد,بُعد التضمين,嵌入维数,嵌入维度,嵌入维度,dimension d'incorporation,dimension d'incorporation,dimension d'incorporation,埋め込み寸法,埋め込み次元 (embedding dimension),埋め込み次元数,измерение внедрения,размер вложения,Размерность вложения
1483,embedding dimensionality,تضمين الأبعاد,"""وبعد ذلك نقوم بتدريب النموذج لمدة 3 دورات على 100 ألف زوج من الحقائق من لغة واحدة أو لغتين كما هو موضح بعد ذلك. نستخدم 3 طبقات مخفية (400 وحدة متكرر",تضمين أبعادي,嵌入维数,嵌入维度,嵌入维度,intégrer la dimensionnalité,dimensionnalité de l'incorporation,dimensionnalité de plongement,埋め込み次元,130,埋め込み次元数,вложение размерности,размерность вложения,размерность вложения
1484,embedding feature,ميزة التضمين,ميزة التضمين,تضمين الميزة,嵌入特征,嵌入特征,嵌入特征,fonctionnalité d'intégration,caractéristique d'incorporation,vecteurs de représentation,埋め込み機能,埋め込み特徴,埋め込み特徴量,функция встраивания,признак вложения,встраиваемая особенность
1485,embedding layer,طبقة التضمين,طبقة التضمين,طبقة التضمين,嵌入层,嵌入层,嵌入层,couche d'incorporation,couche d'intégration,couche d'embeddings,埋め込み層,埋め込み層 (うめこみそう),埋め込み層,слой внедрения,слои встраивания,слой встраивания
1486,embedding matrix,مصفوفة التضمين,مصفوفة التضمين,مصفوفة التضمين,嵌入矩阵,嵌入矩阵,嵌入矩阵,matrice d'intégration,- Matrice d'incorporation,matrice d'encastrement,埋め込み行列,埋め込み行列,埋め込みマトリックス,матрица внедрения,матрица вложения,матрица эмбеддинга
1487,embedding model,نموذج التضمين,نموذج تضمين,نموذج التضمين,嵌入模型,嵌入模型,嵌入模型,modèle d'intégration,modèle d'incorporation,modèle d'embeddings,埋め込みモデル,埋め込みモデル,埋め込みモデル,модель внедрения,модель вложения,Модель векторных представлений (embedding model)
1488,embedding parameter,معلمة التضمين,معلمات التضمين,معلمات التضمين,嵌入参数,嵌入参数,嵌入参数,paramètre d'intégration,paramètre d'incorporation,paramètre d'intégration,埋め込みパラメータ,埋め込みパラメータ,埋め込みパラメータ,параметр внедрения,параметр встраивания,Параметр встраивания
1489,embedding size,حجم التضمين,حجم التضمين,حجم التضمين,嵌入尺寸,嵌入大小,嵌入尺寸,taille d'intégration,- Taille de l'incorporation,taille d'embeddings,埋め込みサイズ,埋め込みサイズ,埋め込みサイズ,размер встраивания,размер вложения,размер вложения
1490,embedding space,مساحة التضمين,المساحة التضمينية,فضاء التضمين,嵌入空间,嵌入空间,嵌入空间,espace d'intégration,espace d'incorporation,espace de plongement,埋め込みスペース,埋め込み空間 (うめこみくうかん),埋め込み空間,пространство для встраивания,пространство вложения,пространство вложений
1491,embedding vector,ناقلات التضمين,متجه التضمين,متجه التضمين,嵌入向量,嵌入向量 (embedding vector),词嵌入向量,vecteur d'intégration,vecteur d'incorporation,vecteur d'embeddings,埋め込みベクトル,埋め込みベクトル (うめこみベクトル),埋め込みベクトル,вектор внедрения,вектор вложения,векторное представление
1492,embedding-base metric,متري قاعدة التضمين,مقياس مبني على تضمين,مقياس قائم على التضمين,嵌入基础度量,嵌入式基础度量,嵌入基础指标,métrique de base d'intégration,métrique basée sur l'incorporation,métrique basée sur les embeddings,埋め込みベースのメトリック,埋め込みベースのメトリック,埋め込みベースメトリック,метрика базы встраивания,метрика на основе вложений,метрика на основе эмбеддингов
1493,embodied agent,وكيل مجسم,الوكيل المتجسد,وكيل متجسد,体现代理人,具身代理,体现智能体,agent incarné,- Agent incarné,agent incarné,具現化されたエージェント,具現化エージェント (gugenka eejento),体現エージェント,воплощенный агент,воплощенный агент,воплощенный агент
1494,emission probability,احتمالية الانبعاث,احتمالية الانبعاث,احتمالية الانبعاث,发射概率,发射概率,发射概率,probabilité d'émission,probabilité d'émission,probabilité d'émission,放出確率,発射確率,発生確率,вероятность выброса,вероятность испускания,вероятность эмиссии
1495,emotion classification,تصنيف العاطفة,تصنيف العواطف,تصنيف المشاعر,情绪分类,情感分类,情感分类,classification des émotions,classification des émotions,classification des émotions,感情の分類,感情分類 (Kanjō Bunrui),感情分類,классификация эмоций,классификация эмоций,классификация эмоций
1496,empirical Bayes,بايز التجريبية,بيز تجريبي,بايز التجريبي,经验贝叶斯,经验贝叶斯,经验贝叶斯,Bayes empirique,Bayésien empirique,bayes empirique,経験的ベイズ,経験ベイズ,経験的ベイズ,эмпирический байесовский,эмпирический Байес,эмпирический байесовский подход
1497,empirical distribution,التوزيع التجريبي,التوزيع التجريبي,توزيع تجريبي,经验分布,经验分布,经验分布,distribution empirique,- Distribution empirique,distribution empirique,経験的分布,実証分布 (jisshou bunpu),経験分布,эмпирическое распределение,эмпирическое распределение,эмпирическое распределение
1498,empirical estimate,التقدير التجريبي,التقدير التجريبي,تقدير تجريبي,经验估计,经验估算,经验估计,estimation empirique,estimation empirique,estimation empirique,経験的推定,経験的推定 (けいけんてきすいてい),実証的推定値,эмпирическая оценка,эмпирическая оценка,эмпирическая оценка
1499,empirical estimator,مقدر تجريبي,مقدر تجريبي,مقدر تجريبي,经验估计量,经验估计者,经验估计量,estimateur empirique,estimateur empirique,estimateur empirique,経験的推定者,経験的推定子 (けいけんてきすいていし),経験的推定値,эмпирический оценщик,эмпирическая оценка,эмпирический оценщик
1500,empirical frequency,التردد التجريبي,التردد التجريبي,التكرار التجريبي,经验频率,经验频率,经验频率,fréquence empirique,fréquence empirique,fréquence empirique,経験的頻度,実証的周波数,経験的頻度,эмпирическая частота,эмпирическая частота,эмпирическая частота
1501,empirical loss,الخسارة التجريبية,الخسارة التجريبية,الخسارة التجريبية,经验损失,经验损失,经验损失,perte empirique,perte empirique,perte empirique,経験的損失,経験的損失 (けいけんてきそんしつ),実証損失,эмпирическая потеря,эмпирический потери,эмпирические потери
1502,empirical mean,يعني تجريبي,المتوسط التجريبي,المتوسط التجريبي,经验平均值,经验平均值,经验均值,moyenne empirique,moyenne empirique,moyenne empirique,経験的平均,実測平均,実証的平均値,эмпирическое среднее,эмпирическое среднее,Эмпирическое среднее
1503,empirical measure,مقياس تجريبي,القياس التجريبي,مقياس تجريبي,经验测量,经验测度,经验测度,mesure empirique,mesure empirique,mesure empirique,経験的尺度,経験的測定【けいけんてきそくてい】,実証的尺度,эмпирическая мера,эмпирическая мера,эмпирическая мера
1504,empirical minimizer,المصغر التجريبي,الحد الأدنى التجريبي,مُقَلِّل تجريبي,经验最小化器,经验化最小化器,经验最小化器,minimiseur empirique,minimiseur empirique,minimiseur empirique,経験的最小化ツール,実証的最小化者,経験的最小化関数,эмпирический минимизатор,эмпирический минимизатор,эмпирический минимизатор
1505,empirical process theory,نظرية العملية التجريبية,نظرية العملية التجريبية,نظرية العملية التجريبية,经验过程理论,经验过程理论,经验过程理论,théorie empirique des processus,théorie des processus empiriques,théorie des processus empiriques,経験的プロセス理論,経験的プロセス理論 (けいけんてき プロセス りろん),経験過程理論,теория эмпирических процессов,эмпирическая теория процессов,теория эмпирических процессов
1506,empirical risk,المخاطر التجريبية,المخاطر التجريبية,المخاطرة التجريبية,经验风险,经验风险,经验风险,risque empirique,risque empirique,risque empirique,経験的リスク,経験リスク (けいけん リスク),実証的リスク,эмпирический риск,эмпирический риск,эмпирический риск
1507,empirical risk minimization,التقليل من المخاطر التجريبية,أدنى تقليص للمخاطر التجريبية,تقليل المخاطر التجريبية,经验风险最小化,经验风险最小化,经验风险最小化,minimisation empirique des risques,minimisation du risque empirique,minimisation du risque empirique,経験的なリスクの最小化,実証リスク最小化,経験的リスク最小化,минимизация эмпирического риска,эмпирическое минимизирование риска,минимизация эмпирического риска
1508,empirical risk minimizer,التقليل من المخاطر التجريبية,مُقَلّلُ المَخاطر الْتَجريبِيّ.,مُقلِّل المخاطر التجريبي,经验风险最小化,经验风险最小化者,经验风险最小化器,minimiseur de risque empirique,minimiseur du risque empirique,minimiseur du risque empirique,経験的リスク最小化ツール,経験リスク最小化者,経験的リスク最小化器,эмпирический минимизатор риска,эмпирический минимизатор риска,эмпирический минимизатор риска
1509,empirical variance,التباين التجريبي,الانحراف التجريبي,التباين التجريبي,经验方差,经验方差,经验方差,variance empirique,variance empirique,variance empirique,経験的な差異,実務分散,経験的分散,эмпирическая дисперсия,эмпирическая дисперсия,эмпирическая дисперсия
1510,emulator,محاكي,محاكي,محاكي,模拟器,模拟器,模拟器,émulateur,émulateur,émulateur,エミュレータ,エミュレータ (emulator),シミュレータ,эмулятор,эмулятор,эмулятор
1511,encoder,التشفير,المُشفر,مُشَفِّر,编码器,编码器,编码器,encodeur,encodeur,codeur,エンコーダ,"""['エンコーダ \n FC ReLU FC BN FC ReLU FC ReLU デコーダ FC クラシファイア FC シグモイド \n 図1：DICNetの主要なフレームワーク。入力データはエンコーダによって処理され、次に加重フュージョンモジュール、不完全なインスタンスレベル対照",エンコーダー,кодер,Энкодер,кодер
1512,encoder layer,طبقة التشفير,طبقة الترميز,طبقة الترميز,编码器层,编码器层,编码器层,couche d'encodeur,couche d'encodeur,couche encodeur,エンコーダ層,エンコーダーレイヤー,エンコーダー層,слой кодера,слои энкодера,кодировочный слой
1513,encoder model,نموذج التشفير,نموذج الترميز,نموذج الترميز,编码器型号,编码器模型,编码器模型,modèle d'encodeur,modèle d'encodeur,modèle encodeur,エンコーダモデル,エンコーダーモデル,エンコーダモデル,модель кодера,модель кодировщика,модель энкодера
1514,encoder network,شبكة التشفير,شبكة الترميز,شبكة الترميز,编码器网络,编码器网络,编码器网络,réseau d'encodeurs,réseau d'encodeurs,réseau d'encodage,エンコーダネットワーク,エンコーダーネットワーク,エンコーダネットワーク,сеть кодировщика,сеть кодировщика,кодирующая сеть
1515,encoder state,حالة التشفير,حالة المشفر,حالة المشفر,编码器状态,编码器状态,编码器状态,état du codeur,état de l'encodeur,État de l'encodeur,エンコーダの状態,エンコーダー状態 (Enkōdā jōtai),エンコーダー状態,состояние кодировщика,состояние энкодера,состояние кодировщика
1516,encoder-decoder architecture,بنية التشفير وفك التشفير,بنية الترميز والفك تشبهية,هندسة الترميز والفك الترميزي,编码器-解码器架构,编码器-解码器架构,编码器-解码器架构,architecture codeur-décodeur,- Architecture encodeur-décodeur,architecture encodeur-décodeur,エンコーダ/デコーダ アーキテクチャ,エンコーダーデコーダーアーキテクチャ,エンコーダ-デコーダアーキテクチャ,архитектура кодера-декодера,архитектура кодировщик-декодировщик,архитектура энкодер-декодер
1517,encoder-decoder framework,إطار التشفير وفك التشفير,إطار الترميز والفكرة,إطار الترميز/فك الترميز,编码器-解码器框架,编码器-解码器框架,编码器-解码器框架,cadre d'encodeur-décodeur,cadre encodeur-décodeur,cadre encodeur-décodeur,エンコーダ/デコーダ フレームワーク,エンコーダーデコーダーフレームワーク,エンコーダデコーダ枠組み,платформа кодировщика-декодера,фреймворк кодировщик-декодер,кодер-декодер фреймворк
1518,encoder-decoder model,نموذج التشفير وفك التشفير,نموذج الترميز-فك الترميز,نموذج الترميز-فك الترميز,编码器-解码器模型,编码器-解码器模型 (encoder-decoder model),编码器-解码器模型,modèle d'encodeur-décodeur,modèle encodeur-décodeur,modèle encodeur-décodeur,エンコーダ-デコーダモデル,エンコーダーデコーダーモデル,エンコーダデコーダモデル,модель кодера-декодера,модель энкодер-декодер,модель энкодера-декодера
1519,end-of-sequence token,رمز نهاية التسلسل,رمز نهاية التسلسل,رمز إنهاء التسلسل,序列结束标记,结束序列标记,句尾标记符,jeton de fin de séquence,jeton de fin de séquence,jeton de fin de séquence,シーケンス終了トークン,シーケンスの終わりトークン,系列終了トークン,токен конца последовательности,токен конца последовательности,токен конца последовательности
1520,end-to-end learning,التعلم من النهاية إلى النهاية,التعلم من البداية إلى النهاية,التعلم من النهاية إلى النهاية,端到端学习,端到端学习,端到端学习,apprentissage de bout en bout,apprentissage bout à bout,apprentissage de bout en bout,エンドツーエンドの学習,エンドツーエンド学習,エンドツーエンド学習,сквозное обучение,Обучение от конца к концу,"обучение ""с конца в конец"""
1521,end-to-end model,نموذج نهاية إلى نهاية,- تحليل من البداية إلى النهاية,نموذج من البداية إلى النهاية,端到端模型,端到端模型,端到端模型,modèle de bout en bout,modèle de bout en bout,modèle de bout en bout,エンドツーエンドモデル,エンドツーエンドモデル,終端から終端までのモデル,сквозная модель,модель с конца до конца,"модель ""конца-в-конец"""
1522,end-to-end neural model,النموذج العصبي من نهاية إلى نهاية,نموذج عصبي من النهاية إلى النهاية,نموذج عصبي من البداية إلى النهاية,端到端神经模型,端到端神经模型,端到端神经模型,modèle neuronal de bout en bout,modèle neuronal de bout en bout,modèle neuronal de bout en bout,エンドツーエンドのニューラル モデル,エンドツーエンドニューラルモデル,終端から終端までのニューラルモデル,сквозная нейронная модель,модель нейронной сети от начала до конца,нейронная модель сквозного типа
1523,end-to-end pipeline,خط أنابيب من نهاية إلى نهاية,أنبوبة النهاية إلى النهاية,نظام متكامل من البداية إلى النهاية,端到端管道,端到端流水线,端到端流程,pipeline de bout en bout,pipeline de bout en bout,chaîne de traitement bout-en-bout,エンドツーエンドのパイプライン,エンドツーエンドのパイプライン,エンドツーエンドパイプライン,сквозной конвейер,конвейер end-to-end,сквозной конвейер
1524,end-to-end system,نظام نهاية إلى نهاية,نظام من النهاية إلى النهاية,نظام متكامل من البداية إلى النهاية,端到端系统,端到端系统,端到端系统,système de bout en bout,système de bout en bout,système de bout en bout,エンドツーエンドシステム,エンド・トゥ・エンド・システム,端から端までのシステム,сквозная система,"система ""от начала до конца""",Полная система
1525,end-to-end training,التدريب من النهاية إلى النهاية,التدريب من البداية إلى النهاية,التدريب من البداية إلى النهاية,端到端训练,端到端训练,端到端训练,formation de bout en bout,- Formation de bout en bout,apprentissage de bout en bout,エンドツーエンドのトレーニング,エンド・ツー・エンド トレーニング,一貫した訓練,сквозное обучение,тренировка от начала до конца,конца-в-конец обучение
1526,energy function,وظيفة الطاقة,وظيفة الطاقة,دالة الطاقة,能量函数,能量函数 (neng2 liang4 han4 shu4),能量函数,fonction énergétique,fonction d'énergie,fonction d'énergie,エネルギー関数,エネルギー関数 (Enerugī kansū),エネルギー関数,энергетическая функция,Энергетическая функция,функция энергии
1527,energy minimization,تقليل الطاقة,تقليل الطاقة,تقليل الطاقة,能源最小化,能量最小化,能量最小化,minimisation de l'énergie,minimisation d'énergie,minimisation d'énergie,エネルギーの最小化,エネルギー最小化 (Enerugī saishouka),エネルギー最小化,минимизация энергии,минимизация энергии,минимизация энергии
1528,energy minimization framework,إطار تقليل الطاقة,الإطار لتقليل الطاقة,إطار تقليل الطاقة,能源最小化框架,能量最小化框架,能量最小化框架,cadre de minimisation de l'énergie,cadre de minimisation d'énergie,cadre de minimisation de l'énergie,エネルギー最小化の枠組み,エネルギー最小化フレームワーク,エネルギー最小化フレームワーク,система минимизации энергопотребления,фреймворк минимизации энергии,энергоминимизационная рамка
1529,energy minimization problem,مشكلة تقليل الطاقة,مشكلة تقليل الطاقة,مشكلة تقليل الطاقة,能量最小化问题,能量最小化问题,能量最小化问题,problème de minimisation de l'énergie,problème de minimisation d'énergie,problème de minimisation d'énergie,エネルギー最小化問題,エネルギー最小化問題,エネルギー最小化問題,задача минимизации энергии,Проблема минимизации энергии,задача минимизации энергии
1530,ensemble classification,تصنيف الفرقة,التصنيف الجماعي,تصنيف المجموعة,集成分类,集成分类,集成分类,classement d'ensemble,classification en ensemble,classification par ensemble,アンサンブル分類,アンサンブル分類 (ensemble classification),アンサンブル分類,классификация ансамблей,ансамблевая классификация,Ансамблевая классификация
1531,ensemble classifier,مصنف الفرقة,مصنف التجمع,مصنف مجموعة,集成分类器,集成分类器,集成分类器,classificateur d'ensemble,classificateur en ensemble,classificateur d'ensemble,アンサンブル分類器,アンサンブル分類器 (Ansanburu bunrui-ki),アンサンブル分類器,классификатор ансамбля,ансамбль классификаторов,Ансамблевый классификатор
1532,ensemble learning,التعلم الجماعي,التعلم التجميعي,التعلم الجماعي,集成学习,集成学习,集成学习,apprentissage d'ensemble,apprentissage en ensemble,apprentissage d'ensemble,アンサンブル学習,アンサンブル学習 (Ansanburu gakushū),アンサンブル学習,ансамблевое обучение,ансамблевое обучение,Ансамблевое обучение
1533,ensemble method,طريقة المجموعة,طريقة التجميع,طريقة المجموعة,集成方法,集成方法,集成方法,méthode d'ensemble,méthode d'ensemble,méthode d'ensemble,アンサンブル法,アンサンブル法 (Ensemble Method),アンサンブル手法,ансамблевый метод,метод ансамбля,Метод ансамбля
1534,ensemble model,نموذج الفرقة,- تعميم النموذج,نموذج مجموعة,集成模型,集成模型,集成模型,modèle d'ensemble,modèle ensemble,modèle d'ensemble,アンサンブルモデル,アンサンブルモデル,アンサンブルモデル,модель ансамбля,ансамбль моделей,ансамблевая модель
1535,ensemble of classifier,مجموعة المصنف,تجميع مصنفات,مجموعة من أنظمة التصنيف,分类器的集合,分类器集合,分类器集合,ensemble de classificateur,ensemble de classificateurs,ensemble de classificateurs,分類器のアンサンブル,分類器のアンサンブル,分類器のアンサンブル,ансамбль классификатора,ансамбль классификаторов,ансамбль классификаторов
1536,ensemble size,حجم الفرقة,حجم التجميع,حجم المجموعة,乐团规模,集成大小,集成大小,taille de l'ensemble,taille de l'ensemble,taille de l'ensemble,アンサンブルサイズ,アンサンブルサイズ,アンサンブルサイズ,размер ансамбля,размер ансамбля,размер ансамбля
1537,entail,يستتبع,تترتب على,تستلزم,蕴涵,蕴含,蕴涵,entraîner,impliquer,impliquer,伴う,含意,含意する,влечь за собой,влечь,влечь за собой
1538,entailment,استلزم,"""['ثم، بالنسبة لجميع φ ∈ C، D |= φ إذا وفقًا ل D |= φ. يحدد هذا النظرية طريقة لإثبات أن التقدم FO صحيح لفئة من الجمل C. ببساطة، يقلل السؤال عن الإلزام (هل النظريتان",استلزام,蕴涵,蕴涵,蕴涵,implication,"""['Alors, pour tout φ ∈ C, D |= φ si et seulement si D |= φ. Ce théorème spécifie une méthode pour prouver qu'une progression FO est correcte pour une classe de phrases C. Essentiellement, cela réduit la question de l'implication (les deux théories impliquent le même ensemble de phrases dans C, à condition qu'elles impliquent le même ensemble de phrases dans LSα) à une question plus simple sur la satisfaction (tous les deux modèles des théories satisfont',",implication,含意,含意,含意,логическое следствие,влечение,вытекание
1539,entailment detection,كشف التبعية,الكشف عن الارتباطات,نظام كشف الاستتباط,蕴涵检测,蕴涵检测,蕴含检测,détection d'implication,détection d'implication,Détection d'implication,含意検出,帰結検出 (kaiketsu kenshutsu),含意検出,обнаружение последствий,обнаружение следствия,логическое следование
1540,entity,كيان,- التجسيم,كيان,实体,实体,实体,entité,- Entité,entité,実在物,実体 (jittai),エンティティ,сущность,сущность,сущность
1541,entity coreference,المرجع الأساسي للكيان,ترابط الكيانات,إحالة الكيان,实体共指,实体共指,实体消解,coréférence d'entité,-référence d'entité,coréférence d'entités,エンティティの相互参照,エンティティの共参照,エンティティ共参照,кореференция сущности,ссылка на сущности,сопоставление сущностей
1542,entity description,وصف الكيان,وصف الكيانات,وصف الكيان,实体描述,实体描述 (Entity Description),实体描述,description de l'entité,description de l'entité,description d'entité,エンティティの説明,エンティティ記述,エンティティ記述,описание сущности,описание сущности,описание сущности
1543,entity detection,كشف الكيان,كشف الكيانات,كشف الكيانات,实体检测,实体检测 (entity detection),实体检测,détection d'entité,détection d'entité,La détection d'entités,エンティティの検出,エンティティ検出 (Entity Detection),エンティティ検出,обнаружение объекта,обнаружение сущностей,обнаружение сущностей
1544,entity embedding,تضمين الكيان,تضمين الكيانات,تضمين الكيان,实体嵌入,实体嵌入,实体嵌入,intégration d'entité,plongement d'entité,plongement d'entité,エンティティの埋め込み,エンティティ埋め込み,エンティティ埋め込み,встраивание сущности,встраивание сущности,вложение сущности
1545,entity extraction,استخراج الكيان,استخراج الكيانات,استخراج الكيانات,实体提取,实体抽取,实体抽取,extraction d'entité,extraction d'entités,extraction d'entités,エンティティの抽出,エンティティ抽出 (Entiti chuushutsu),エンティティ抽出,извлечение сущности,извлечение сущностей,извлечение сущностей
1546,entity linker,رابط الكيان,مُرتبط الكيانات,ربط الكيانات,实体链接器,实体链接器 (entity linker),实体链接器,éditeur de liens d'entités,identificateur d'entité,lieur d'entités,エンティティリンカー,エンティティリンカー,エンティティリンカー,компоновщик объектов,связывающее лицо,сопоставитель сущностей
1547,entity linking,ربط الكيان,ربط الكيانات,ربط الكيان,实体链接,实体链接,实体链接,liaison d'entité,liaison d'entités,Liage d'entités,エンティティのリンク,エンティティリンキング,エンティティリンキング,"сущность, связывающая",сущность связывания,связывание сущностей
1548,entity mention,ذكر الكيان,ذكر الكيان,التعبير عن الكيان,实体提及,实体提及,实体提及,mention de l'entité,mention d'entité,mention d'entité,エンティティの言及,エンティティメンション,エンティティ言及,упоминание сущности,упоминание сущности,сущность упоминается
1549,entity recognition,الاعتراف بالكيان,تعرف الكيانات,التعرف على الكيانات,实体识别,实体识别,实体识别,reconnaissance d'entité,reconnaissance d'entités,reconnaissance d'entités,エンティティの認識,エンティティ認識,エンティティ認識,признание сущности,распознавание сущностей,распознавание именованных сущностей
1550,entity representation,تمثيل الكيان,تمثيل الكيانات,تمثيل الكيان,实体表示,实体表示,实体表示,représentation de l'entité,représentation de l'entité,représentation d'entité,エンティティ表現,エンティティ表現,エンティティ表現,представление сущности,представление сущности,представление сущности
1551,entity resolution,قرار الكيان,تحديد الكيانات,حل الكيانات,实体解析,实体解析,实体消歧,résolution d'entité,résolution d'entité,résolution d'entités,エンティティの解決,エンティティ解決 (Entiti kaikei),エンティティ解決,разрешение сущности,сопоставление сущностей,разрешение сущностей
1552,entity set,مجموعة الكيان,مجموعة الكيانات,مجموعة الكيانات,实体集,实体集,实体集,ensemble d'entités,ensemble d'entités,ensemble d'entités,エンティティセット,エンティティセット,エンティティ集合,набор сущностей,набор сущностей,набор сущностей
1553,entity type,نوع الكيان,- تصنيف الكيانات,نوع الكيان,实体类型,实体类型,实体类型,type d'entité,type d'entité,type d'entité,エンティティタイプ,エンティティタイプ (Entiti Taipu),エンティティの種別,тип объекта,тип сущности,тип сущности
1554,entropy,إنتروبيا,الانحباس,تروبيا,熵,熵,熵,entropie,- Entropie,entropie,エントロピ,エントロピー,エントロピー,энтропия,Энтропия,энтропия
1555,entropy estimation,تقدير الانتروبيا,تقدير الانحرافية,تقدير الإنتروبيا,熵估计,熵估计,熵估计,estimation de l'entropie,estimation de l'entropie,estimation de l'entropie,エントロピー推定,エントロピー推定 (Entropy estimation),エントロピー推定,оценка энтропии,оценка энтропии,оценка энтропии
1556,entropy function,وظيفة الانتروبيا,وظيفة الإنتروبي,دالة الترتيب العشوائي,熵函数,熵函数,熵函数,fonction d'entropie,- Fonction d'entropie,fonction d'entropie,エントロピー関数,エントロピー関数 (Entoropī kansū),エントロピー関数,энтропийная функция,функция энтропии,функция энтропии
1557,entropy loss,فقدان الانتروبيا,فقدان الانتروبي,فقدان الانتروبيا,熵损失,熵损失,熵损失,perte d'entropie,perte d'entropie,perte d'entropie,エントロピー損失,エントロピー損失,エントロピー損失,потеря энтропии,потеря энтропии,потеря энтропии
1558,entropy regularization,تنظيم الانتروبيا,التنظيم المنتروبي,تنظيم الاضطراب,熵正则化,熵正则化,熵正则化,régularisation de l'entropie,régularisation de l'entropie,régularisation d'entropie,エントロピー正則化,エントロピー正則化,エントロピー正則化,энтропийная регуляризация,регуляризация энтропии,регуляризация энтропии
1559,enumeration algorithm,خوارزمية التعداد,- ترتيب خوارزمية العداد,خوارزمية الترميز,枚举算法,枚举算法,枚举算法,algorithme d'énumération,algorithme d'énumération,algorithme d'énumération,列挙アルゴリズム,列挙アルゴリズム,列挙アルゴリズム,алгоритм перечисления,алгоритм перечисления,перечислительный алгоритм
1560,envy-freeness,الحسد,- التماسكية المتساوية,خلو من الحسد,无嫉妒,无嫉妒性 (envy-freeness),无嫉妒性,sans envie,absence d'envie,absence d'envie,羨望の無さ,エンヴィーフリーネス,嫉妬無し性 (shittoshinashi-sei),свобода от зависти,Энви-свобода,Отсутствие зависти
1561,eos,eos,نهاية الجملة,إِيوس (eos),埃欧斯,eos,终止符号,éos,eos,<eos>,イオス,終了符 (eos),eos の訳語は 終端記号 (しゅうたんきごう),Эос,eos,eos - конец последовательности
1562,epipolar constraint,القيد القطبي,القيد الإبيبولاري,قيد البؤري,对极约束,极线约束,对极约束,contrainte épipolaire,contrainte épipolaire,contrainte épipolaire,エピポーラ制約,エピポーラ制約 (epipolar constraint),視線束拘束条件,эпиполярное ограничение,эпиполярное ограничение,эпиполярное ограничение
1563,epipolar geometry,الهندسة القطبية,الهندسة الإبيبولارية,هندسة خطية مستوية,对极几何,对极几何,对极几何,géométrie épipolaire,géométrie épipolaire,géométrie épipolaire,エピポーラ幾何学,エピポーラ幾何学 (Epipōra kikagaku),対応幾何,эпиполярная геометрия,эпиполярная геометрия,геометрия эпиполярных линий
1564,epipolar line,خط Epipolar,الخط الثلاثي,خط الإبيبولار,极线,对极线,对极线,ligne épipolaire,ligne épipolaire,ligne épipolaire,エピポーラ線,エピポーラ線,エピポーラ線,эпиполярная линия,эпиполярная линия,эпиполярная линия
1565,epipole,epipole,نقطة الاهتمام,مركز الصورة,极点,极点,极点,épipole,épipôle,épipôle,エピポール,エピポール,エピポール,эпиполь,эпиполь,эпиполь
1566,episodic return,عودة عرضية,العائد النوعي,عائد الحلقة,偶发性回归,剧集回报,回合回报,retour épisodique,retour épisodique,retour épisodique,エピソード的な復帰,エピソードのリターン,エピソード報酬,эпизодическое возвращение,эпизодический возврат,эпизодическая выгода
1567,epistemic uncertainty,عدم اليقين المعرفي,عدم اليقين المعرفي,عدم اليقين المعرفي,认知不确定性,认知不确定性,认识论不确定性,incertitude épistémique,Incertitude épistémique,incertitude épistémique,認識論的不確実性,認識不確実性,モデル化/学習プロセスに関する不確実性,эпистемическая неопределенность,эпистемическая неопределенность,неопределенность познания
1568,epoch,عصر,الحقبة,حقبة,时代,时代,轮次,époque,- Époque,époque,時代,エポック,エポック,эпоха,эпоха,эпоха
1569,equalize odd,تعادل غريب,تعادل الفرص العجيبة,تعادل الفرص,均等奇数,平衡奇数,等化奇偶性,égaliser impair,égaliser les cotes,égalité des chances,奇数を均等化する,均等化オッズ,等化された偶数,уравнять нечетное,выравнивание нечетных,выравнивать шансы
1570,equivalence class,فئة التكافؤ,صنف المعادلة,فئة التكافؤ,等价类,等价类,等价类,classe d'équivalence,classe d'équivalence,classe d'équivalence,同等クラス,等価クラス (tōka kurasu),同値類,класс эквивалентности,класс эквивалентности,класс эквивалентности
1571,equivalence query,استعلام التكافؤ,استعلام المكافئات,استفسار المكافئة,等价查询,等价查询,等价查询,requête d'équivalence,requête d'équivalence,requête d'équivalence,等価性クエリ,等価クエリ (touka kueri),同値性質問,запрос эквивалентности,эквивалентный запрос,запрос эквивалентности
1572,equivariance,التكافؤ,"""ومع ذلك، نظرًا لأن الهندسيات الناتجة لا يمكن أن تحتفظ بالمتطابقية بالكامل، فقد لا يتم ضمان تعقيد العينات المطلوب للتدريب والتعميم (Garg et al.، 2020). لذلك، في",تكافؤ,等方差,等变性,等变性,équivariance,équivariance,Équivariance,等分散性,"""しかし、得られるアーキテクチャが完全な等変性を保持できないため、トレーニングおよび汎化に必要なサンプル複雑性が保証されないかもしれません（Garg et al.、2020）。そのため、本稿では等変GNNの解析と設計に焦点を当て",同変性,эквивариантность,эквивариантность,эквивариантность
1573,equivariant,متساوي,متوازي الضغط,متكافئ,等变,等变的,等变,équivariant,équivariant,équivariante,等価,準同変性 (Jun dōhen-sei),等変,эквивариантный,эквивариантный,эквивариантный
1574,error,خطأ,خطأ,خطأ,错误,错误,误差,erreur,Erreur,erreur,エラー,エラー,エラー,ошибка,Ошибка,ошибка
1575,error analysis,تحليل الأخطاء,تحليل الأخطاء,تحليل الأخطاء,误差分析,错误分析,错误分析,erreur d'analyse,Analyse d'erreur,analyse des erreurs,エラー分析,エラー分析,誤り分析,анализ ошибок,анализ ошибок,Анализ ошибок
1576,error bind,ربط الخطأ,حدّ الخطأ,الحد الخطأ,错误绑定,误差绑定,误差界限,erreur de liaison,limite d'erreur,Borne d'erreur,エラーバインド,エラーバウンド,エラーバウンド,ошибка привязки,предел ошибки,ошибочная связь
1577,error function,وظيفة الخطأ,دالة الخطأ,دالة الخطأ,误差函数,错误函数,误差函数,fonction d'erreur,fonction d'erreur,fonction d'erreur,誤差関数,エラー関数,誤差関数,функция ошибки,функция ошибки,функция ошибки
1578,error probability,احتمالية الخطأ,معدل الخطأ,خطأ احتمال,错误概率,错误概率,错误概率,probabilité d'erreur,probabilité d'erreur,probabilité d'erreur,エラーの確率,誤り確率,エラー確率,вероятность ошибки,вероятность ошибки,вероятность ошибки
1579,error rate,نسبة الخطأ,معدل الخطأ,معدل الخطأ,错误率,错误率,错误率,taux d'erreur,Taux d'erreur,taux d'erreur,エラー率,誤り率 (あやまりりつ),エラー率,частота ошибок,уровень ошибок,ошибка
1580,error tolerance,التسامح مع الخطأ,التسامح مع الخطأ,خطأ التسامح,容错性,错误容忍,误差容限,tolérance aux erreurs,- Tolérance aux erreurs,Tolérance d'erreur,誤差許容度,エラー許容度 (error tolerance),エラー許容,толерантность к ошибкам,допустимая ошибка,допустимая погрешность
1581,estimation error,خطأ في التقدير,خطأ التقدير,خطأ التقدير,估计误差,估计误差,估计误差,erreur d'estimation,Erreur d'estimation,erreur d'estimation,推定誤差,推定誤差,推定誤差,ошибка оценки,ошибка оценки,оценочная ошибка
1582,estimator,مقدر,- مقدر,مُقَدِّر,估计器,估计器,估计量,estimateur,estimateur,estimateur,推定者,推定値（エスティメータ）,推定量,оценщик,оценщик,оценщик
1583,euclidean distance,المسافة الإقليدية,المسافة الأقليدية,المسافة الإقليدية,欧氏距离,欧几里得距离,欧几里德距离,Distance euclidienne,- Distance euclidienne,distance euclidienne,ユークリッド距離,ユークリッド距離,ユークリッド距離,Евклидово расстояние,Евклидово расстояние,евклидово расстояние
1584,euclidean divergence,التباعد الإقليدي,الانحراف اليوروكليدية,تباعد إقليدي,欧氏散度,欧氏散度,欧几里德散度,divergence euclidienne,divergence euclidienne,divergence euclidienne,ユークリッド発散,ユークリッド距離,ユークリッド発散,евклидово расхождение,евклидова дивергенция,евклидово расхождение
1585,euclidean loss,الخسارة الإقليدية,الخسارة اليوركليدية,خسارة القالبية الإقليدية,欧氏损失,欧几里德损失,欧几里得损失,perte euclidienne,perte euclidienne,perte euclidienne,ユークリッド損失,ユークリッド損失,ユークリッドロス,евклидова потеря,Евклидова ошибка,евклидова потеря
1586,euclidean norm,القاعدة الإقليدية,"""['السمات الباقية ذات الأبعاد 361 التي تأتي من الإشارات المُحصل عليها من خلال تقنية ما بعد المعالجة مثل التحويل السريع لفورييه (FFT) والقيمة المُحسوبة باستخدام المعي",المعيار الإقليدي,欧几里得范数,欧几里得范数,欧几里德范数,norme euclidienne,norme euclidienne,norme euclidienne,ユークリッドノルム,ユークリッドノルム,ユークリッドノルム,евклидова норма,евклидова норма,Евклидова норма
1587,euclidean plane,الطائرة الإقليدية,المستوى اليوركليدي,مستوى إقليدي,欧几里得平面,欧几里得平面,欧几里德平面,plan euclidien,plan euclidien,plan euclidien,ユークリッド平面,ユークリッド平面,ユークリッド平面,евклидова плоскость,Евклидова плоскость,евклидова плоскость
1588,euclidean projection,الإسقاط الإقليدي,- التصوير الأقليدي المتوازي,إسقاط إقليدي,欧几里得投影,欧几里得投影,欧几里得投影,projection euclidienne,projection euclidienne,projection euclidienne,ユークリッド投影,ユークリッド射影,ユークリッドの射影,евклидова проекция,Евклидова проекция,евклидова проекция
1589,euclidean space,الفضاء الإقليدي,الفضاء الأقليدي,الفضاء الإقليدي,欧几里得空间,欧几里得空间,欧几里得空间,espace euclidien,espace euclidien,espace euclidien,ユークリッド空間,ユークリッド空間,ユークリッド空間,евклидово пространство,Евклидово пространство,евклидово пространство
1590,euclidean transformation,التحول الإقليدي,التحويل الأقليدي الخاص,تحويل إقليدي,欧氏变换,欧几里得变换,欧几里得变换,transformation euclidienne,- Transformation euclidienne,transformation euclidienne,ユークリッド変換,ユークリッド変換,ユークリッド変換,евклидово преобразование,Евклидово преобразование,эвклидово преобразование
1591,euler angle,زاوية أويلر,زوايا أويلر,زوايا أويلر,欧拉角,欧拉角,欧拉角,angle d'Euler,angle d'Euler,angle d'Euler,オイラー角,オイラー角,オイラー角,угол Эйлера,углы Эйлера,Углы Эйлера
1592,evaluation function,وظيفة التقييم,وظيفة التقييم,دالة التقييم,评价函数,评估函数,评估函数,fonction d'évaluation,fonction d'évaluation,fonction d'évaluation,評価関数,評価関数 (hyouka kansuu),評価関数,функция оценки,функция оценки,Функция оценки
1593,evaluation metric,مقياس التقييم,معيار التقييم,مقياس التقييم,评价指标,评估指标,评估指标,métrique d'évaluation,métrique d'évaluation,métrique d'évaluation,評価指標,評価メトリック,評価指標,метрика оценки,метрика оценки,метрика оценки
1594,evaluation set,مجموعة التقييم,مجموعة التقييم,مجموعة التقييم,评估集,评估集,评估集,ensemble d'évaluation,ensemble d'évaluation,ensemble d'évaluation,評価セット,評価セット (hyōka setto),評価セット,оценочный набор,набор оценки,набор для оценки
1595,event calculus,حساب الحدث,حساب الأحداث,حساب الحدث,事件演算,事件演算,事件演算,calcul d'événement,calcul d'événements,calcul d'événements,イベント微積分,イベント計算,イベント計算,исчисление событий,исчисление событий,Исчисление событий
1596,event coreference,مرجع الحدث,ترابط الأحداث,ربط الأحداث,事件共指,事件共指 (event coreference),事件共指,coréférence d'événement,coréférence d'événements,coreferĂ©rence d'Ă©vĂ©nements,イベント相互参照,イベント共参照,イベント共参照,Кореференция событий,событийная кореференция,событийная корефренция
1597,event detection,كشف الحدث,كشف الأحداث,كشف الحدث,事件检测,事件检测 (Event Detection),事件检测,détection d'événement,détection d'événements,détection d'événement,イベント検出,イベント検出,イベント検出,обнаружение событий,обнаружение событий,Обнаружение событий
1598,event extraction,استخراج الحدث,استخراج الأحداث,استخراج الحدث,事件提取,事件抽取,事件抽取,extraction d'événements,extraction d'événements,extraction d'événements,イベント抽出,イベント抽出,イベント抽出,извлечение событий,извлечение событий,извлечение событий
1599,evidence lower bind,الأدلة أقل ربط,"""في التقدير التغايري (VI)، يُستخدم الحد الدني للدليل (ELBO)، الذي يعتبر حدًا أدنى لسجل الاحتمالية التقريبي، في ضبط المعلمات الفائقة بشكل تلقائي (هوفمان وآخ",حد ادنى للدليل,证据下限,证据下界,证据下界,preuve limite inférieure,limite inférieure des preuves,borne inférieure de l'évidence,証拠の下限バインド,証拠下限結合 (しょうこげんげんけつごう),証拠下界 (ELBO),доказательства нижней границы,доказательство нижней границы,нижняя граница очевидности
1600,evidence maximization,تعظيم الأدلة,تعظيم الأدلة,تعظيم الدليل,证据最大化,证据最大化,证据最大化,maximisation des preuves,maximisation de l'évidence,maximisation de la vraisemblance,証拠の最大化,証拠最大化,証拠最大化,максимизация доказательств,максимизация доказательств,максимизация правдоподобия
1601,exact inference,الاستدلال الدقيق,- التستدل بدقة,الاستدلال الدقيق,精确推理,精确推理,准确推理,inférence exacte,inférence exacte,inférence exacte,正確な推論,厳密推論,正確な推論,точный вывод,точное заключение,точный вывод
1602,exact match,تطابق تام,تطابق دقيق,مطابقة تامة,完全符合,精确匹配,完全匹配,correspondance exacte,correspondance exacte,Correspondance exacte,完全に一致,- 精確一致 (Seikaku icchi),完全一致,полное совпадение,- Точное совпадение,прямое совпадение
1603,excess loss,الخسارة الزائدة,الخسارة الزائدة,الخسارة الزائدة,超额损失,多余损失,过度损失,perte excédentaire,perte excédentaire,perte excédentaire,超過損失,過剰損失,過剰損失,лишние потери,избыточные потери,избыточные потери
1604,exchangeability,قابلية التبادل,- تبادلية,تبادلية,互换性,可交换性,可交换性,échangeabilité,échangeabilité,permutabilité,交換可能性,交換可能性 (Koukan Kanousei),交換可能性,возможность обмена,обмениваемость,взаимозаменяемость
1605,existential quantifier,الكمي الوجودي,مقدّر الوجودية,وجودي,存在量词,存在量词,存在量词,quantificateur existentiel,quantificateur existentiel,quantificateur existentiel,存在量指定子,存在量化子,存在量化子,квантор существования,существенный квантификатор,существенный квантор
1606,expect loss,توقع الخسارة,الخسارة المتوقعة,الخسارة المتوقعة,预期损失,期望损失,期望损失,s'attendre à une perte,perte attendue,perte attendue,損失を期待する,期待損失 (Kitai songshitsu),期待損失,ожидать потери,ожидаемые потери,ожидаемый убыток
1607,expect reward,توقع المكافأة,- توقع مكافأة,المكافأة المتوقعة,期待奖励,期望奖励 (Qīwàng jiǎnglì),期望回报,espérer une récompense,attente de récompense,récompense attendue,報酬を期待する,期待報酬 (kitai hoshu),期待報酬,ожидать награды,ожидаемая награда,ожидаемое вознаграждение
1608,expect utility,نتوقع فائدة,المنفعة المتوقعة,فائدة متوقعة,期待效用,期望效用,期望效用,s'attendre à une utilité,utilité attendue,utilité espérée,実用性を期待する,期待効用 (Kitai Kōyō),期待効用,ожидать полезности,ожидаемая полезность,ожидаемая полезность
1609,expectation maximization,زيادة التوقعات,تعظيم التوقعات,تعظيم التوقع,期望最大化,期望最大化,期望最大化,maximisation des attentes,maximisation de l'espérance,maximisation de l'espérance,期待の最大化,期待値最大化,期待値最大化,максимизация ожиданий,метод максимизации ожидания,Максимизация ожиданий
1610,expectation maximization algorithm,خوارزمية تعظيم التوقعات,- تكرار الأملية القصوى,خوارزمية تعظيم التوقع (Expectation Maximization algorithm),期望最大化算法,期望最大化算法,期望最大化算法,algorithme de maximisation des attentes,algorithme d'optimisation de l'espérance,algorithme d'estimation-maximisation,期待値最大化アルゴリズム,期待値最大化アルゴリズム (kitai-ritsu saidaika arugorizumu),期待値最大化アルゴリズム,алгоритм максимизации ожидания,алгоритм максимизации ожидания,алгоритм максимизации ожидания
1611,experience replay,إعادة التجربة,إعادة تجربة الخبرة,إعادة تجربة,体验回放,经验重演,经验重放,rejouer l'expérience,expérience de rejeu,reprise d'expérience,体験リプレイ,経験再生,経験再生,повтор опыта,опыт повтора,Повторное использование опыта
1612,expert demonstration,مظاهرة الخبراء,عروض الخبراء,عرض خبير,专家演示,专家演示,专家示范,démonstration d'experts,démonstration d'expert,démonstrations expertes,専門家のデモンストレーション,エキスパートデモンストレーション,専門家による実演,экспертная демонстрация,экспертная демонстрация,демонстрация экспертов
1613,explicit-state search,بحث الحالة الصريحة,البحث في الحالة الصريحة,البحث عن الحالة الصريحة,显式状态搜索,显式状态搜索,显式状态搜索,recherche d'état explicite,recherche à état explicite,recherche d'états explicites,明示的状態検索,明示的状態探索,明示的状態探索,поиск в явном состоянии,явный поиск состояний,Поиск с явными состояниями
1614,explode gradient,تنفجر التدرج,تفجير التدرجات,انفجار التدرج,爆炸梯度,梯度爆炸,梯度爆炸,exploser le dégradé,"""Les gradients qui explosent dans des calculs très profonds entraînent un gradient inutilisable.""",explosion du gradient,爆発勾配,勾配爆発,勾配爆発,взорвать градиент,взрывной градиент,взрывной градиент
1615,exploitability,قابلية الاستغلال,الاستغلالية,استغلالية,可利用性,可利用性,可利用性,exploitabilité,exploitabilité,exploitabilité,悪用可能性,搾取可能性,利用可能性,возможность эксплуатации,Эксплуатируемость,эксплуатируемость
1616,exploration rate,معدل الاستكشاف,معدل الاستكشاف,معدل الاستكشاف,勘探率,探索率,探索率,taux d'exploration,taux d'exploration,taux d'exploration,探索率,探索率 (たんさくりつ),探索率,темпы разведки,темп исследования,скорость исследования
1617,exploratory data analysis,تحليل البيانات استكشافية,تحليل البيانات الاستكشافي,تحليل البيانات الاستكشافي,探索性数据分析,探索性数据分析,探索性数据分析,l'analyse exploratoire des données,analyse exploratoire des données,Analyse exploratoire des données,探索的データ分析,探索的データ分析,探索的データ解析,исследовательский анализ данных,анализ исследования данных,исследовательский анализ данных
1618,exponential complexity,التعقيد الأسي,التعقيد التربيعي,تعقيد أسي,指数复杂度,指数复杂度,指数复杂度,complexité exponentielle,complexité exponentielle,complexité exponentielle,指数関数的な複雑さ,指数的複雑さ (exponential complexity),指数関数的複雑性,экспоненциальная сложность,экспоненциальная сложность,экспоненциальная сложность
1619,exponential decay,تسوس الأسي,الانحسار التسلسلي,مايل تناقصي,指数衰减,指数衰减,指数衰减,décroissance exponentielle,décroissance exponentielle,décroissance exponentielle,指数関数的減衰,指数減衰,- 指数減衰 (しすうげんすい),экспоненциальное затухание,экспоненциальное затухание,экспоненциальное затухание
1620,exponential distribution,التوزيع الأسي,التوزيع الترابطي,توزيع أسي,指数分布,指数分布,指数分布,distribution exponentielle,- Distribution exponentielle,distribution exponentielle,指数分布,指数分布,指数分布,экспоненциальное распределение,экспоненциальное распределение,экспоненциальное распределение
1621,exponential family,عائلة الأسية,عائلة تصاعدية,عائلة أسية,指数族,指数家族,指数分布族,famille exponentielle,- Famille exponentielle,famille exponentielle,指数関数的家族,指数ファミリー,指数分布族,экспоненциальное семейство,экспоненциальное семейство,семейство экспоненциальных распределений
1622,exponential loss,الخسارة الأسية,- تراكم الخسارة الأسية,خسارة أسية,指数损失,指数损失,指数损失,perte exponentielle,- Perte exponentielle,perte exponentielle,指数関数的損失,指数損失 (shisuu sonshitsu),指数損失,экспоненциальная потеря,экспоненциальная потеря,экспоненциальный убыток
1623,exponential map,خريطة الأسية,التصوير التسلسلي,خريطة أسية,指数图,指数映射,指数映射,carte exponentielle,carte exponentielle,application exponentielle,指数関数マップ,指数写像 (exponential map),指数写像,экспоненциальная карта,экспоненциальное отображение,экспоненциальное отображение
1624,exponential move average,المتوسط ​​المتحرك الأسي,المتوسط المتحرك التراكمي الأسيّ,متوسط الحركة الأسية,指数移动平均线,指数移动平均,指数移动平均,moyenne mobile exponentielle,moyenne mobile exponentielle,moyenne mobile exponentielle,指数移動平均,指数移動平均,指数移動平均,экспоненциальная скользящая средняя,экспоненциальное скользящее среднее,экспоненциальное скользящее среднее
1625,exposure bias,تحيز التعرض,الانحياز للتعرض,تحيز التعرض,曝光偏差,曝光偏差,暴露偏差,biais d'exposition,biais d'exposition,biais d'exposition,露出バイアス,暴露バイアス,ばくろしこうか,смещение экспозиции,Проблема предвзятости обучения,смещение экспозиции
1626,extended Kalman filter,مرشح كالمان الموسع,مرشح كالمان الموسع,مرشح كالمان الممتد,扩展卡尔曼滤波器,扩展卡尔曼滤波器,扩展卡尔曼滤波器,filtre de Kalman étendu,Filtre de Kalman étendu,filtre de Kalman étendu,拡張カルマンフィルター,拡張カルマンフィルタ (Kalmna filter),拡張カルマンフィルタ (Extended Kalman Filter),расширенный фильтр Калмана,расширенный фильтр Калмана,расширенный фильтр Калмана
1627,extensive-form game,لعبة واسعة النطاق,لعبة الشكل الواسع,لعبة ذات شكل ممتد,广泛形式博弈,扩展式博弈,广义形式博弈,jeu de forme étendue,jeu forme étendue,jeu sous forme extensive,拡張形式のゲーム,拡張形式ゲーム (Kakuchō keishiki gēmu),広形ゲーム,игра развернутой формы,игра в развернутой форме,Игра в развернутой форме
1628,extractive question answer,إجابة السؤال الاستخراجي,الإجابة عن الأسئلة الاستخراجية,الإجابة عن الأسئلة الاستخراجية,提取问题答案,抽取式问答,提取式问题回答,réponse à la question extractive,réponse à une question extractive,réponse extractive aux questions,抽出的な質問の回答,抽出型質問応答,抜粋的質問応答,экстрактивный вопрос-ответ,"""['QuAC также принимает извлекающий вопросно-ответный подход, который ограничивает ответ как фрагмент текста, что обычно считается более простым для оценки.', 'Мы используем результаты этой внешней задачи для создания бенчмарка по обнаружению разложения для мет",извлечение ответов на вопросы
1629,extractive summarization,التلخيص الاستخراجي,تلخيص استخراجي,التلخيص الاستخراجي,提炼总结,抽取式摘要化,摘要式总结,résumé extractif,résumé extractif,résumé extractif,抽出的な要約,抜粋要約,抽出的要約,экстрактивное обобщение,извлекающее резюмирование,извлекающее реферирование
1630,extractor,مستخرج,مستخرج,مستخرج,提取器,提取器,提取器,extracteur,extracteur,extracteur,エキストラクター,抽出器 (Chushutsuki),抽出器,экстрактор,экстрактор,извлекатель
1631,f-divergence,و-الاختلاف,التباين f,القصور التفاضلي,f-散度,f-分歧 (f-divergence),f-散度,f-divergence,f-divergence,divergence-f,fダイバージェンス,f-ダイバージェンス,f-ダイバージェンス,f-дивергенция,f-расхождение,f-расхождение
1632,f-measure,قياس f,قياس F-ميلٌر,مقياس إف,f 测量,F-度量,F-测度,mesure f,mesure F,mesure-F,f値,F-測定,F測度,f-мера,F-мера,мера-F
1633,f-score,f-النتيجة,نسبة إف-سكور,معامل f,F分数,F分数,f分数,score f,score F,score-F,fスコア,Fスコア,F値,F-оценка,F-мера,F-балл
1634,f1 measure,قياس f1,قياس اف 1,قياس F1,f1 测量,F1指标,F1 分数,mesure f1,mesure F1,mesure f1,f1 測定,F1 メジャー,f1測度値,f1 мера,мера F1,мера f1
1635,f1 metric,متري f1,مقياس الإف ١,ُمعيار إف١,f1 度量,F1指标,f1 指标,métrique f1,métrique F1,Métrique f1,f1 メトリック,F1指標,F1メトリック,метрика f1,метрика F1,метрика f1
1636,f1 score,درجة f1,- معدل إف 1,مقياس اف واحد,F1 分数,F1得分,f1 分数,score f1,score F1,score f1,f1スコア,F1スコア,F1スコア,счет f1,F1-оценка,мера F1
1637,face detection,الكشف عن الوجه,كشف الوجه,الكشف عن الوجه,人脸检测,人脸检测 (face detection),人脸检测,détection facial,Détection de visage,détection de visage,顔検出,顔検出 (かおけんしゅつ),顔検出,распознавание лиц,обнаружение лиц,обнаружение лиц
1638,face detector,كاشف الوجه,مكتشف الوجوه,كاشف الوجه,人脸检测器,人脸检测器,人脸检测器,détecteur de visage,détecteur de visage,détecteur de visages,顔検出器,顔検出器,顔検出器,детектор лица,детектор лиц,детектор лиц
1639,face recognition,تمييز الوجوه,التعرف على الوجوه,التعرف على الوجه,人脸识别,人脸识别,人脸识别,reconnaissance de visage,- Reconnaissance faciale,reconnaissance faciale,顔認識,顔認識,顔認識,распознавание лица,распознавание лиц,распознавание лиц
1640,facial landmark,معلم الوجه,- تحديدات الوجه,معالم الوجه,面部标志,面部标志,人脸关键点,repère facial,repère facial,point de repère facial,顔のランドマーク,顔のランドマーク,顔ランドマーク,ориентир лица,точки лица,Опорные точки лица
1641,facial recognition,التعرف على الوجه,التعرف على الوجوه,التعرف على الوجوه,面部识别,人脸识别,人脸识别,la reconnaissance faciale,reconnaissance faciale,reconnaissance faciale,顔認識,顔認識,顔認識,распознавание лиц,распознавание лиц,Распознавание лиц
1642,fact verification,التحقق من الحقيقة,التحقق من الحقائق,التحقق من الحقائق,事实验证,事实验证,事实验证,vérification des faits,Vérification des faits,vérification des faits,事実確認,事実検証 (jijitsu kenshō),事実検証,проверка фактов,проверка фактов,проверка фактов
1643,factor analysis,تحليل العوامل,تحليل العوامل,التحليل العاملي,因子分析,因子分析 (factor analysis),因子分析,analyse factorielle,analyse factorielle,analyse factorielle,因子分析,因子分析 (いんしぶんせき),因子分析,факторный анализ,факторный анализ,факторный анализ
1644,factor graph,الرسم البياني للعامل,رسم عامل,رسم العوامل,因子图,因子图,因子图,graphique de facteur,graphe de facteurs,graphe de facteurs,ファクターグラフ,ファクターグラフ,因子グラフ,Факторный график,факторный граф,граф факторов
1645,factor matrix,مصفوفة العوامل,مصفوفة العوامل,مصفوفة العامل,因子矩阵,因子矩阵,因子矩阵,matrice de facteurs,- Matrice de facteurs,matrice de facteur,因子行列,要素行列,因子行列,матрица факторов,матрица факторов,матрица факторов
1646,factor of variation,عامل الاختلاف,عامل التباين,عامل تغيُّر,变异系数,变异因素,变化因素,facteur de variation,facteur de variation,facteur de variation,変動要因,変動要因,変化要因,фактор вариации,фактор изменения,фактор варьирования
1647,factorization,التخصيم,التحليل العاملي,تجزئة,因式分解,因数分解 (Factorization),因子分解,factorisation,factorisation,factorisation,因数分解,因数分解 (いんすうぶんかい),因子分解,факторизация,факторизация,факторизация
1648,factorization algorithm,خوارزمية التحليل,خوارزمية التعويض,خوارزمية التجزئة,因式分解算法,因子分解算法,分解算法,algorithme de factorisation,algorithme de factorisation,algorithme de factorisation,因数分解アルゴリズム,因子分解アルゴリズム,因子分解アルゴリズム,алгоритм факторизации,алгоритм факторизации,Алгоритм факторизации
1649,factorization method,طريقة التخصيم,طريقة التعويض,طريقة تجزئة العوامل,因式分解法,因子分解方法,因子分解法,méthode de factorisation,méthode de factorisation,méthode de factorisation,因数分解法,因子分解法 (Inshi bunkai-hō),因子分解法,метод факторизации,метод факторизации,метод факторизации
1650,failure probability,احتمال الفشل,احتمال الفشل,احتمالية الفشل,失效概率,失败概率,失败概率,probabilité de défaillance,probabilité d'échec,probabilité d'échec,失敗確率,失敗確率 (shippai kakuritsu),失敗確率,вероятность отказа,вероятность отказа,вероятность отказа
1651,fairness criterion,معيار العدالة,معيار العدالة,معيار العدالة,公平准则,公平性准则,公平性标准,critère d'équité,- Critère d'équité,critère d'équité,公平性の基準,公正基準,公平性基準,критерий справедливости,критерий справедливости,критерий справедливости
1652,fairness loss,فقدان العدالة,فقدان العدالة,خسارة الإنصاف,公平损失,公平性损失,公平性损失,perte d'équité,- Perte d'équité,perte d'équité,公平性の喪失,公平損失,公平性損失,потеря справедливости,Потеря справедливости,потеря справедливости
1653,fairness notion,فكرة العدالة,مفهوم العدالة,مفهوم العدالة,公平观念,公平概念 (fairness notion),公平概念,notion d'équité,notion d'équité,notion d'équité,公平性の概念,公平性概念,公平性概念,понятие справедливости,концепция справедливости,понятие справедливости
1654,faithfulness score,درجة الإخلاص,نقاط الأمانة,درجة الأمانة,忠诚度分数,忠实度评分,忠诚度分数,score de fidélité,score de fidélité,score de fidélité,忠実度スコア,忠実度スコア,忠実性スコア,оценка верности,оценка верности,степень достоверности
1655,false negative,سلبي خطأ,سلبي خاطئ,نتيجة سلبية خاطئة,假阴性,假阴性,漏检,faux négatif,faux négatif,faux négatif,偽陰性,誤検出 (false negative),偽陰性,ложноотрицательный результат,Ложноотрицательный,ложноотрицательный
1656,false negative rate,معدل سلبي كاذب,معدل السلبيات الزائفة,معدل السلبية الكاذبة,假阴性率,误拒率,假阴性率,taux de faux négatifs,Taux de faux négatifs,taux de faux négatifs,偽陰性率,誤検出率,偽陰性率,ложноотрицательный показатель,скорость ложных отрицательных результатов,частота ложноотрицательных случаев
1657,false positive rate,معدل إيجابي كاذب,معدل الإيجابيات الزائفة,معدل النتائج الإيجابية الكاذبة,误报率,误报率,虚报率,taux de faux positifs,- Taux de faux positifs,taux de faux positifs,偽陽性率,誤検知率 (false positive rate),偽陽性率,ложноположительный уровень,Ложноположительная оценка (FPR),ложноположительный коэффициент
1658,fanout,معجب في,انتشار,شعبة,扇出,扩散数,扇出度,sortance,"""['Nous représentons la structure récursive des communautés au sein de communautés comme un arbre Γ, de hauteur H. Nous montrerons qu'un simple arbre parfaitement équilibré avec un fanout constant b suffit pour entraîner une loi de puissance de densification, et nous concentrerons donc l'analyse sur ce modèle de base.', 'La complexité temporelle de la recherche en faisceaux est O(LBF), où L est la longueur maximale des identifiants (la profondeur",épanouissement,扇形に広がります,ファンアウト,ファンアウト,разветвление,мощность ветвления,разветвление
1659,fast fourier transform,تحويل فورييه السريع,- تحويل فورييه سريع,تحويل فورييه السريع,快速傅里叶变换,快速傅立叶变换,快速傅里叶变换,Transformée de Fourier Rapide,transformée de Fourier rapide,Transformée de Fourier rapide,高速フーリエ変換,高速フーリエ変換,高速フーリエ変換,быстрое преобразование Фурье,быстрое преобразование Фурье,быстрое преобразование Фурье
1660,fc layer,طبقة FC,طبقة fc,طبقة الاتصال الكامل,FC层,fc 层,全连接层,couche FC,couche fc,couche fc,FC層,fc レイヤー,全結合層,слой FC,fc слои,полносвязный слой
1661,feasible set,مجموعة ممكنة,المجموعة الممكنة,مجموعة ممكنة,可行集,可行集,可行集,ensemble réalisable,ensemble réalisable,ensemble réalisable,実現可能なセット,実行可能集合,実現可能集合,допустимый набор,допустимое множество,допустимое множество
1662,feature,ميزة,السمة,ميزة,特征,特征,特征,fonctionnalité,caractéristique,caractéristique,特徴,特徴,特徴量,особенность,признак,признак
1663,feature channel,قناة مميزة,قناة الميزة,قنوات السمات,特色频道,特征通道 (feature channel),特征通道,chaîne thématique,canal de caractéristiques,canaux de caractéristiques,特集チャンネル,特徴チャンネル (feature channel),特徴チャネル,функциональный канал,канал признаков,признаковые каналы
1664,feature correspondence,المراسلات المميزة,مطابقة السمات,مطابقة الميزات,特征对应,特征对应,特征对应,correspondance des fonctionnalités,correspondance des caractéristiques,correspondance de caractéristiques,機能対応,特徴対応,特徴対応,функция переписки,сопоставление признаков,соответствие признаков
1665,feature count,عدد الميزات,عدد الميزات,عدد السمات,特征数,特征数量,特征计数,nombre de fonctionnalités,- Nombre de caractéristiques,compte de caractéristiques,特徴数,特徴数,特徴量の個数,количество функций,количество характеристик,пересчет признаков
1666,feature descriptor,واصف الميزة,وصف الميزات,وصف الميزة,特征描述符,特征描述符,特征描述符,descripteur de fonctionnalité,descripteur de caractéristiques,descripteur de caractéristiques,機能記述子,特徴記述子 (Feature Descriptor),特徴記述子,дескриптор функции,дескриптор признака,дескриптор признаков
1667,feature detection,كشف الميزة,كشف الميزات,الكشف عن الميزات,特征检测,特征检测,特征检测,détection de fonctionnalités,- Détection de caractéristiques,détection de caractéristiques,特徴検出,特徴検出 (Tokuchō kenshutsu),特徴検出,обнаружение функций,обнаружение признаков,Обнаружение признаков
1668,feature detector,كاشف الميزة,مكتشف الميزة,مكتشف الملامح,特征检测器,特征检测器,特征检测器,détecteur de caractéristiques,détecteur de caractéristiques,détecteur de caractéristiques,特徴検出器,特徴検出器 (Tokuchō kenshutsuki),特徴検出器,детектор функций,детектор признаков,детектор признаков
1669,feature dimension,البعد الميزة,بُعد السمة,بُعد السمة,特征维度,特征维度,特征维度,cote d'entité,dimension des caractéristiques,dimension de caractéristiques,機能の寸法,"""['（l+1）番目のブロックへの入力X（l）∈ R^nx^dをX（0）= Xとして示し、ここでnはノード数、dは特徴次元です。入力X（l）に対して（l+1）-番目のブロックは次のように機能します：\nここで\n', 'δ i ≤ 1 - min(1/di、1/c",特徴次元,размер объекта,размерность признаков,признак измерения
1670,feature dimensionality,أبعاد الميزة,بُعد السمة,عُدد أبعاد الميزات,特征维数,特征维度,特征维数,dimensionnalité des fonctionnalités,dimensionnalité des caractéristiques,dimensionnalité des caractéristiques,特徴の次元,特徴次元数 (feature dimensionality),特徴次元数,размерность объекта,размерность признаков,размерность признаков
1671,feature embedding,تضمين الميزة,تضمين الميزات,تضمين الميزة,特征嵌入,特征嵌入,特征嵌入,intégration de fonctionnalités,"""['qui prend la pose quaternion et l'incorporation de caractéristiques encodées v τ (k) ∈ R l de son joint parent en entrée et génère v k ∈ R l , où l est la dimension de la caractéristique. Nous concaténons ensuite la caractéristique encodée pour chaque joint pour obtenir une incorporation de pose combinée \n p = [v 1 || . . .', 'Pour être précis, chaque nœud dans V, c'est-à-dire",Projection de caractéristiques,機能の埋め込み,特徴埋め込み (feature embedding),特徴埋め込み,встраивание функций,вложение признаков,матричное представление признаков
1672,feature encoder,ميزة التشفير,مشفر الميزات,مشفر الميزات,特征编码器,特征编码器,特征编码器,encodeur de fonctionnalités,encodeur de caractéristiques,encodeur de caractéristiques,機能エンコーダ,特徴エンコーダ,特徴エンコーダ,кодировщик функций,модуль кодировщика признаков,кодер признаков
1673,feature engineering,هندسة الميزات,هندسة السمات,هندسة الميزات,特征工程,特征工程,特征工程,ingénierie des fonctionnalités,ingénierie des caractéristiques,génie des caractéristiques,特徴エンジニアリング,特徴エンジニアリング (feature engineering),特徴量エンジニアリング,разработка функций,инженерия признаков,конструирование признаков
1674,feature extraction,ميزة استخراج,استخراج الميزات,استخراج المعالم,特征提取,特征提取,特征提取,extraction de caractéristiques,extraction de caractéristiques,extraction de caractéristiques,特徴抽出,特徴量抽出 (てきちょうりょう ちゅうしゅつ),特徴抽出,извлечение признаков,извлечение признаков,извлечение признаков
1675,feature extractor,مستخرج الميزة,مستخرج السمات,مُستخرج الميزات,特征提取器,特征提取器,特征提取器,extracteur de fonctionnalités,extracteur de caractéristiques,extracteur de caractéristiques,特徴抽出器,特徴抽出器 (feature extractor),特徴抽出器,экстрактор функций,извлекатель признаков,извлекатель признаков
1676,feature function,وظيفة الميزة,وظيفة الميزة,دالة الميزة,特征函数,特征函数,特征函数,fonction caractéristique,fonction de caractéristique,fonction de caractéristiques,特徴機能,特徴関数,特徴関数,функция функция,функция признаков,функция признака
1677,feature hashing,تجزئة الميزة,تجزئة الميزات,تهشير الميزات,特征散列,特征哈希,特征哈希,hachage des fonctionnalités,hachage de caractéristiques,hachage de caractéristiques,特徴ハッシュ,特徴ハッシング (feature hashing),特徴ハッシュ,хеширование функций,Хеширование признаков,хэширование признаков
1678,feature hierarchy,التسلسل الهرمي للميزات,تسلسل الميزات,هرميات الميزات,特征层次结构,特征层次结构,特征层次结构,hiérarchie des fonctionnalités,hiérarchie des caractéristiques,hiérarchie de caractéristiques,機能階層,特徴階層 (Tokuchō kaisō),特徴階層,иерархия функций,иерархия признаков,иерархия признаков
1679,feature map,خريطة الميزة,خريطة السمات,خارطة الميزات,特征图,特征图 (tè zhēng tú),特征图,carte des caractéristiques,carte des caractéristiques,carte des caractéristiques,機能マップ,特徴マップ (feature map),特徴マップ,карта объектов,карта признаков,карта признаков
1680,feature mapping function,وظيفة رسم الخرائط الميزة,وظيفة رسم السمة,دالة التضمين,特征映射函数,特征映射函数,特征映射函数,fonction de mappage des fonctionnalités,fonction de mappage des caractéristiques,fonction de mappage de caractéristiques,特徴マッピング関数,特徴マッピング関数 (Tokuchō mappingu kansū),特徴写像関数,функция сопоставления объектов,функция отображения признаков,функция отображения признаков
1681,feature matching,مطابقة الميزة,مطابقة الميزات,مطابقة الميزات,特征匹配,特征匹配,特征匹配,correspondance des fonctionnalités,correspondance de caractéristiques,appariement de caractéristiques,特徴マッチング,特徴の一致,特徴マッチング,сопоставление функций,сопоставление признаков,сопоставление признаков
1682,feature matrix,مصفوفة الميزة,مصفوفة السمات,مصفوفة الميزات,特征矩阵,特征矩阵 (feature matrix),特征矩阵,matrice de fonctionnalités,- Matrix de caractéristiques,matrice de caractéristiques,特徴マトリックス,特徴行列 (Feature Matrix),特徴マトリックス,матрица признаков,матрица признаков,матрица признаков
1683,feature model,نموذج الميزة,نموذج الميزات,نموذج الميزة,特征模型,特征模型,特征模型,modèle de fonctionnalités,modèle de caractéristiques,modèle de traits,機能モデル,特徴モデル (feature model),特徴モデル,функциональная модель,модель признаков,модель признаков
1684,feature normalization,تطبيع الميزة,تقييم الميزة,تطبيع السمات,特征归一化,特征归一化 (feature normalization),特征归一化,normalisation des fonctionnalités,normalisation des caractéristiques,normalisation des caractéristiques,特徴の正規化,特徴正規化 (feature normalization),特徴正規化,нормализация функций,нормализация признаков,нормализация признаков
1685,feature point,نقطة الميزة,نقطة الميزة,نقطة معلمة,特征点,特征点,特征点,point caractéristique,point de caractéristique,point caractéristique,特徴点,特徴点 (とくちょうてん),特徴点,характерная точка,точка признака,особенность точка
1686,feature pyramid,الهرم المميز,هرم الميزة,هرم المميزات,特征金字塔,特征金字塔 (feature pyramid),特征金字塔,pyramide des fonctionnalités,pyramide de caractéristiques,pyramide de caractéristiques,機能ピラミッド,特徴ピラミッド,特徴ピラミッド,Пирамида функций,пирамида признаков,пирамида признаков
1687,feature representation,تمثيل الميزة,التمثيل المميز للميزة,تمثيل الميزات,特征表示,特征表示,特征表示,Représentation des caractéristiques,représentation de caractéristiques,représentation des caractéristiques,特徴表現,特徴表現 (とくちょうひょうげん),特徴表現,представление объекта,представление признаков,представление признаков
1688,feature representation learning,تعلم تمثيل الميزة,تعلم تمثيل الميزات,تعلم تمثيل السمات,特征表示学习,特征表示学习,特征表示学习,apprentissage de la représentation des caractéristiques,- Apprentissage de la représentation des caractéristiques,apprentissage de représentation de caractéristiques,特徴表現学習,特徴表現学習,特徴表現学習,обучение представлению объектов,обучение представлению признаков,обучение представлению признаков
1689,feature selection,اختيار ميزة,اختيار الميزات,اختيار الميزات,特征选择,特征选择,特征选择,sélection de fonctionnalité,sélection de caractéristiques,sélection de caractéristiques,機能の選択,特徴選択 (てきちょうせんたく),特徴選択,выбор функции,отбор признаков,отбор признаков
1690,feature selector,محدد الميزة,محدد الميزات,محدد السمات,特征选择器,特征选择器,特征选择器,sélecteur de fonctionnalités,sélecteur de fonctionnalités,sélecteur de caractéristiques,機能セレクター,特徴選択器 (feature selector),特徴選択器,селектор функций,селектор признаков,селектор признаков
1691,feature set,مجموعة الميزات,مجموعة السمات,مجموعة الميزات,功能集,特征集,特征集合,jeu de fonctionnalités,"TENSE). L'importance de la catégorie c est alors définie comme \n f (c) = F 1 (C Φ ) - F 1 (C Φ\\φc ) (2) \n', 'Dans ce travail, nous avons très brièvement montré",ensemble de caractéristiques,機能セット,特徴セット (Tokuchō setto),特徴集合,набор функций,набор функций,набор признаков
1692,feature space,مساحة الميزة,المساحة المميزة,فضاء الميزات,特征空间,特征空间,特征空间,espace de fonctionnalités,espace de caractéristiques,espace de caractéristiques,特徴空間,特徴空間,特徴空間,пространство объектов,пространство признаков,пространство признаков
1693,feature template,قالب الميزة,قالب الميزة,قالب السمة,特征模板,特征模板,特征模板,modèle de fonctionnalité,modèle de fonctionnalité,gabarit de caractéristiques,フィーチャーテンプレート,特徴テンプレート,特徴テンプレート,шаблон объекта,шаблон признака,шаблон признаков
1694,feature vector,ناقلات الميزة,متجه سمة,ناقل السمات,特征向量,特征向量,特征向量,vecteur de caractéristiques,vecteur de caractéristiques,vecteur de caractéristiques,特徴ベクトル,特徴ベクトル,特徴ベクトル,вектор признаков,вектор признаков,Вектор признаков
1695,feature weight,وزن الميزة,وزن السمة,وزن الميزة,特征权重,特征权重,特征权重,poids caractéristique,poids de caractéristique,poids des traits,特徴の重み,特徴の重み,特徴量の重み,вес функции,вес признака,вес признака
1696,featurization,المميزات,عملية التمييز,تحويل الميزات,特征化,特征化 (featurization),特征提取,caractérisation,caractérisation,descriptivisation,特徴化,フィーチャリゼーション (fiicharaizeeshon),特徴量抽出,характеристика,фичеризация,векторизация
1697,featurized representation,تمثيل مميز,التمثيل المميز المعزز,تمثيل مُميز,特征化表示,特征化表示,特征化表示,représentation en vedette,représentation featurisée,représentation featurisée,特徴的な表現,特徴表現 (featurized representation),特徴表現,избранное представление,репрезентация функций,признаковое представление
1698,federated Learning,التعلم الاتحادي,التعلم الاتحادي,التعلم الموزع,联邦学习,联邦学习,联邦学习,Apprentissage fédéré,Apprentissage fédéré,Apprentissage fédéré,フェデレーションラーニング,フェデレーテッドラーニング (Federated Learning),連合学習 (れんごうがくしゅう),федеративное обучение,"""['Мы представляем обзор FS-G на рис. 1. В центре FS-G находится фреймворк федеративного обучения FederatedScope [38] с основными утилитами (т.е. формирование процедуры федеративного обучения) и совместимый с различными backend графового обучения.', 'В качестве",федеративное обучение
1699,feed forward,تغذية إلى الأمام,تغذية إلى الأمام,انتشار أمامي,前馈,前馈,前馈,anticiper,feed forward,propagation avant,フィードフォワード,フィードフォワード,フィードフォワード,подавать вперед,Прямое распространение,прямая передача
1700,feed forward network,شبكة التغذية إلى الأمام,شبكة إرسال متقدمة,شبكة الانتشار الأمامي,前馈网络,前馈网络,前馈网络,réseau de rétroaction,- Réseau à propagation avant,réseau de propagation avant,フィードフォワードネットワーク,フィードフォワードネットワーク (feed forward network),前向きネットワーク,сеть прямой связи,нейронная сеть прямого распространения,прямая сеть
1701,feed forward neural network,تغذية الشبكة العصبية إلى الأمام,شبكة عصبية إلى الأمام,شبكة عصبية ذات انتشار أمامي,前馈神经网络,前馈神经网络,前馈神经网络,réseau neuronal à rétroaction,- Réseau de neurones à propagation avant,réseau de neurones à propagation avant,フィードフォワードニューラルネットワーク,フィードフォワードニューラルネットワーク (feed forward neural network),前向き神経回路網,нейронная сеть прямой связи,нейронная сеть прямого распространения,прямопередающая нейронная сеть
1702,feed-forward layer,طبقة التغذية الأمامية,الطبقة الإيجابية الأمامية,طبقة الإرسال الأمامي,前馈层,前馈层,前馈层,couche de rétroaction,- Couche d'avance,couche d'entrée directe,フィードフォワード層,フィードフォワード層 (Feed-forward layer),順伝播層,слой прямой связи,"""['Декодер имеет структуру, аналогичную энкодеру, за исключением того, что на каждом слое декодера между слоем само-внимания и прямым слоем слоя многоголового внимания внимание уделяется выходу энкодера. Нормализация слоя (Ba et al., 2016) прим",слой прямого распространения
1703,feedback loop,ردود الفعل حلقة,دورة ردود الفعل,حلقة تغذية راجعة,反馈回路,反馈循环,反馈循环,boucle de rétroaction,boucle de rétroaction,boucle de rétroaction,フィードバックループ,フィードバックループ (Fiidobakku Ruupu),フィードバックループ,Обратная связь,обратная связь,обратная связь
1704,few shot learning,القليل من التعلم بالرصاص,التعلم بضع الصور,التعلم القليل الجرعات,少拍学习,小样本学习,少样本学习,quelques tirs d'apprentissage,apprentissage en quelques exemples,apprentissage par quelques exemples,数ショット学習,フューショットラーニング,少数ショット学習,обучение с небольшим количеством выстрелов,обучение на малом наборе данных,немногоэкземплярное обучение
1705,few-shot classification,تصنيف قليل الطلقات,تصنيف قليل العينات,التصنيف بالبرمجة القليلة,少样本分类,少样本分类,少量样本分类,classement en quelques coups,classification à quelques exemples,classification à quelques exemples,数ショット分類,フューショット分類,少数ショット分類,классификация по нескольким выстрелам,многозадачное метаобучение,классификация по малому количеству примеров
1706,few-shot example,مثال قليل النار,أمثلة قليلة في اللقطة,أمثلة قليلة,少数镜头示例,少样本示例,少量示例,exemple de quelques plans,exemple en quelques coups,exemple à quelques coups,数ショットの例,"few-shot example
few-shot 例",少数のサンプル例,пример с несколькими выстрелами,небольшое количество примеров,немногопримерная подача
1707,few-shot fine-tuning,ضبط قليل من اللقطات,ضبط نموذج التدريب بعد عدد قليل من المرات,ضبط دقيق قليل الإشارات,少量镜头微调,少样本微调,少样本精细调整,réglage fin en quelques plans,ajustement fin à quelques coups,ajustement fin sur peu d'exemples,数ショット微調整,フューショットファインチューニング,少数ショット微調整,точная настройка с несколькими кадрами,Малоэлементная настройка,мелкомасштабная настройка
1708,few-shot in-context learning,التعلم في السياق قليل الطلقات,التعلم في السياق القليل المؤثّر,التعلم في السياق بعينات قليلة,少样本情境学习,少样本上下文学习,小样本上下文学习,apprentissage contextuel en quelques étapes,apprentissage en contexte à quelques échantillons,apprentissage par quelques exemples en contexte,数回のコンテキスト内学習,few-shotインコンテキスト学習,少数ショットインコンテクスト学習,контекстное обучение с несколькими кадрами,обучение с небольшим количеством образцов в контексте,немногошаговое контекстное обучение
1709,few-shot prompting,مطالبة قليلة بالرصاص,"""['(2022), ولكننا نعمم ذلك أيضًا على المهام غير القابلة للنص كفهم التواريخ والاستنتاج المنطقي من خلال تحفيز قليل الصور GPT-3 (text-davinci-003) (Brown et al., 2020) و Codex (Chen et al.,",الاستدعاء القليل الجرعات,几次提示,少样本提示,少量示例提示,invite à quelques tirs,sollicitation à quelques coups,prompts à quelques exemples,数回のプロンプト,フューショットプロンプティング,少数ショットプロンプト,подсказка из нескольких кадров,малократное подсказывание,малопримерное подталкивание
1710,few-shot setting,إعداد عدد قليل من الطلقات,"""['في هذا الجزء، نهدف إلى استكشاف كيف يتأثر عدل التنبؤات النموذجية بعدد الأمثلة المتوازنة ديموغرافيًا (عادلة) في إعداد قليل البيانات. إعداد التقييم. نقوم",إعداد القليل من المثالات,少拍设置,"few-shot setting
Few-shot场景",小样本设置,réglage de quelques coups,configuration few-shot,contexte à peu d'exemples,数枚撮影設定,フューショット設定,少数ショット設定,настройка на несколько кадров,настройка небольшого числа обучающих примеров,режим малого числа выстрелов
1711,filter bank,بنك التصفية,مصرف الفلاتر,بنك المرشحات,滤波器组,滤波器组 (filter bank),滤波器组,banque de filtres,banque de filtres,banque de filtres,フィルターバンク,フィルターバンク (firuta banku),フィルタバンク,банк фильтров,фильтровая банка,банк фильтров
1712,filter weight,وزن الفلتر,وزن الفلتر,وزن المرشح,过滤器重量,滤波器权重,滤波器权重,poids du filtre,- Poids de filtre,poids du filtre,フィルターの重量,フィルターウェイト,フィルタ重み,вес фильтра,вес фильтра,Вес фильтра
1713,fine-grained sentiment classification,تصنيف المشاعر الدقيقة,التصنيف الدقيق للمشاعر,تصنيف المشاعر المتدرج,细粒度的情感分类,细粒度情感分类,细粒度情感分类,classification fine des sentiments,Classification fine des sentiments,classification de sentiments à grain fin,きめ細かい感情分類,微細な感情分類,詳細な感情分類,детальная классификация настроений,классификация мелкозернистых эмоциональных тональностей,тонкоградуированная классификация эмоциональной окраски
1714,fine-tune,ضبط دقيق,ضبطFe fine-tune,ضَبْطٌ دَقِيقٌ,微调,微调,微调,affiner,peaufiner,ajuster avec précision,微調整,ファインチューニング,微調整,тонкая настройка,доводить до совершенства,доналадить
1715,fine-tune model,نموذج الضبط الدقيق,نموذج ضبط دقيق,نموذج التهيئة الدقيقة,微调模型,微调模型,微调模型,affiner le modèle,affiner le modèle,modèle affiné,微調整モデル,feinチューニングモデル,微調整モデル,доработанная модель,модель доводки,Настроить модель
1716,finite horizon,الأفق المحدود,الأفق المحدود,أفق محدود,有限视野,有限时间跨度,有限时域,horizon fini,horizon fini,Horizon fini,有限の地平線,有限時間ホライズン,有限の時間範囲,конечный горизонт,конечный горизонт,конечный горизонт
1717,finite-state automata,أتمتة الحالة المحدودة,أوتوماتا ذات حالات محدودة,آليات محدودة الحالات,有限状态自动机,有限状态自动机,有限状态自动机,automates à états finis,automates finis en état,automates à états finis,有限状態オートマトン,有限状態オートマトン (finite-state automata),有限状態オートマトン,конечные автоматы,конечные автоматы,конечные автоматы
1718,first order method,طريقة الطلب الأول,أسلوب النظام من الدرجة الأولى,الطريقة من الرتبة الأولى,一阶法,一阶方法,一阶方法,méthode du premier ordre,méthode du premier ordre,méthode du premier ordre,一次法,一次法,一次法,метод первого порядка,метод первого порядка,метод первого порядка
1719,first-order,الطلب الأول,- ترتيب أول,من الرتبة الأولى,第一个订单,"""['最后，我们提供证据表明，在一阶情况下，完整的公理系统可能不存在，即使限制在最简单的默认推理形式。','这可以单独公理化，但我们在这里不这样做。这种依赖于可满足性的情况意味着在一阶设置中的这个公理的实例集合也不是递归可枚举",一阶,Premier ordre,de premier ordre,de premier ordre,最初の注文,"""['Finally we present evidence that it is unlikely that a complete axiom system exists in the first-order case, even when restricted to the simplest forms of default reasoning.', 'This could be axiomatized separately, but we do not do so here. This dependence on satisfiability means that the set of instances of this axiom in a first-order setting would not be recursively enumerable. This is unfortunately how it must be, however, since the valid sentences are not recursively enumerable either.', 'The language L of the situation calculus (McCarthy & Hayes 1969) is first-order with equality",一階,Первый заказ,первого порядка,первого порядка
1720,first-order language,لغة من الدرجة الأولى,اللغة من النوع الأول,لغة من الدرجة الأولى,一阶语言,一阶语言,一阶语言,langage du premier ordre,langage du premier ordre,langage du premier ordre,一次言語,一階述語言語 (ikkai jutugo gengo),一階述語論理,язык первого порядка,язык первого порядка,язык первого порядка
1721,first-order logic,منطق الدرجة الأولى,المنطق من المرتبة الأولى,منطق الرتبة الأولى,一阶逻辑,一阶逻辑,一阶逻辑,logique du premier ordre,logique du premier ordre,logique du premier ordre,一次論理,1階述語論理,命題論理,логика первого порядка,логика первого порядка,логика первого порядка
1722,first-order model,نموذج من الدرجة الأولى,نموذج من الدرجة الأولى,نموذج من الرتبة الأولى,一阶模型,一阶模型,一阶模型,modèle du premier ordre,modèle de premier ordre,modèle du premier ordre,一次モデル,一次モデル,一次モデル,модель первого порядка,модель первого порядка,Модель первого порядка
1723,first-order parsing,تحليل من الدرجة الأولى,التحليل من الدرجة الأولى,تحليل ترتيبي من الدرجة الأولى,一阶解析,一阶解析,一阶解析,analyse du premier ordre,analyse de premier ordre,analyse syntaxique d'ordre 1,一次解析,"""英語のデータセットでは、POSタグを使用しない低ランクモデルは、同じ条件で訓練された場合、一次解析で90.49%を達成し、ベースラインは86.70%を達成します。低ランクを使用して訓練された場合は、90.58%を達成します。NT-1stとNT-3rd（低ラン",一次構文解析,синтаксический анализ первого порядка,парсинг первого порядка,синтаксический разбор первого порядка
1724,fisher information matrix,مصفوفة معلومات الصياد,مصفوفة معلومات فيشر,مصفوفة معلومات فيشر,渔民信息矩阵,费舍尔信息矩阵,费希尔信息矩阵,matrice d'information des pêcheurs,matrice d'information de Fisher,matrice d'information de Fisher,漁師情報マトリックス,フィッシャー情報行列,フィッシャー情報行列,Информационная матрица Фишера,матрица информации Фишера,матрица информации Фишера
1725,fisher score,نقاط فيشر,نقطة فيشر,درجة فيشر,费舍尔评分,Fisher分数,费希尔分数,score de pêcheur,score de Fisher,score de Fisher,フィッシャースコア,フィッシャースコア (Fisher score),フィッシャースコア,счет Фишера,оценка Фишера,коэффициент Фишера
1726,fitness function,وظيفة اللياقة البدنية,دالة اللياقة,دالة اللياقة,适应度函数,适应度函数,适应度函数,fonction de remise en forme,fonction de fitness,fonction d'évaluation,フィットネス機能,適応関数,適応度関数,фитнес-функция,функция приспособленности,Функция приспособленности
1727,five-fold cross-validation,التحقق من صحة خمسة أضعاف,التقسيم الخماسي المتقاطع,التحقق المتقاطع الخماسي,五重交叉验证,五折交叉验证,五重交叉验证,validation croisée quintuple,validation croisée à cinq plis,validation croisée à cinq plis,5 重交差検証,五分割交差検証,5分割交差検証,пятикратная перекрестная проверка,пятикратная перекрестная проверка,пятикратная кросс-валидация
1728,fixed point,نقطة ثابتة,نقطة ثابتة,نقطة ثابتة,固定点,不动点,固定点,un point fixe,point fixe,point fixe,固定点,固定点,固定点,фиксированная точка,фиксированная точка,неподвижная точка
1729,fixed-parameter tractable,معلمة ثابتة قابلة للتتبع,عالية المعاملات الثابتة,مُعَالَجٌ بِمُعامِلِ ثابِت,固定参数易处理,固定参数可解,固定参数可解决,traitable à paramètres fixes,traitable en paramètre fixe,intractable avec paramètres fixés,固定パラメータの扱いやすい,固定パラメータトラクタブル,固定パラメータ可解,управляемый с фиксированными параметрами,фиксированно-параметризуемый,Разрешимый за фиксированное время
1730,fixed-point iteration,تكرار النقطة الثابتة,التكرار النقطي الثابت,طريقة تكرارية ثابتة النقطة,定点迭代,固定点迭代,固定点迭代,itération à virgule fixe,itération du point fixe,itération à point fixe,固定小数点の反復,固定点反復,固定点反復法,итерация с фиксированной точкой,итерация с фиксированной точкой,метод простых итераций
1731,fixpoint,نقطة الإصلاح,نقطة تثبيت,نقطة ثبات,固定点,不动点 (fixpoint),不动点,point fixe,point fixe,point fixe,固定点,"""['最小のノード値の修正点計算は、dMin x と KK 境界の遅延規則を考慮に入れて修正されることも可能です。', '通常の Datalog プログラムの修正点は、データ複雑度において PTIME で計算できます。しかし、限界線形プログラム P に対しては、",不動点,фиксированная точка,фиксированная точка,точка неподвижности
1732,float16,تعويم16,نصف الدقة (Float16),نقطة_محركة_16,浮动16,- 浮点16,float16 翻译为 半精度浮点数(half-precision floating-point),flotteur16,flottant16,bfloat16,float16,- 浮動小数点16 (furyou shousuudaten 16),"float16 は「半精度浮動小数点数」と翻訳されます。

半精度浮動小数点数",поплавок16,число с плавающей запятой 16-бит,полуслово16
1733,float32,float32,- تحويم32,تحويل النقطة العائمة 32,浮动32,浮点数32,float32的中文译文是单精度浮点数。,flotteur32,- float32,float32,float32,- 浮動小数点数32 (Fudō shōsūten 32),float32を日本語に直訳すると、単精度浮動小数点数になります。,float32,вещественное число с плавающей запятой (float32),float32 - одинарная точность (single precision)
1734,flow field,مجال التدفق,حقل التدفق,حقل التدفق,流场,流场,流场,champ d'écoulement,Champ de flux,champ de flux,流れ場,フロー場,流れ場,поле течения,поле потока,поле потока
1735,flow model,نموذج التدفق,نموذج تدفق,ذج التدفق,流动模型,流模型 (liú mó xíng),流模型,modèle de flux,- Modèle de flux,modèle de flux,フローモデル,フローモデル (Furō moderu),フローモデル,модель потока,модель потока,Потоковая модель
1736,focal loss,خسارة بؤرية,الخسارة البؤرية,خسارة البؤرة,焦点损失,焦点损失,焦点损失,perte focale,Perte focale,perte focale,焦点損失,焦点損失 (Shouten Sositsu),焦点損失,потеря очага,Фокусированная потеря,фокальная потеря
1737,forall,forall,للكل,كائن مهما كان,对全部,对于每个,对于所有,pour tous,forall,pour tout,すべてのために,すべての,万物について,для всех,для всех,Для всех
1738,forecasting,التوقع,- التنبؤ,نبؤات,预测,预测,预测,prévision,prévision,prévision,予測する,予測 (よそく),予測,прогнозирование,прогнозирование,прогнозирование
1739,foreground segmentation,تجزئة المقدمة,تقسيم الأمامية,تصنيف المقدمة,前景分割,前景分割,前景分割,segmentation du premier plan,segmentation de premier plan,segmentation d'avant-plan,前景のセグメンテーション,前景セグメンテーション,前景セグメンテーション,сегментация переднего плана,сегментация переднего плана,фоновая сегментация
1740,forget gate,ننسى البوابة,بوابة النسيان,بوابة النسيان,忘记门,遗忘门,遗忘门,oublier la porte,porte d'oubli,porte d'oubli,忘れた門,忘却ゲート (boukyaku geeto),忘却ゲート,забыть ворота,забывания воротной,Вентиль забывания
1741,forward algorithm,خوارزمية إلى الأمام,خوارزمية التقدم,خوارزمية الأمام,前向算法,前向算法,前向算法,algorithme de transfert,algorithme en avant,algorithme avant,順方向アルゴリズム,フォワードアルゴリズム (forward algorithm),前向きアルゴリズム,прямой алгоритм,Прямой алгоритм,алгоритм прямого распространения
1742,forward model,نموذج إلى الأمام,النموذج المتقدم,نموذج أمامي,正向模型,前向模型,正向模型,modèle avancé,modèle direct,modèle direct,フォワードモデル,フォワードモデル,前方モデル,передовая модель,Прямая модель,прямая модель
1743,forward pass,تمرير إلى الأمام,التمرير الأمامي,التمرير الأمامي,向前传球,前向传递,前向传播,Passe avant,passage en avant,propagation avant,フォワードパス,フォワードパス,順伝播,пас вперед,прямой проход,прямой проход
1744,forward process,عملية إلى الأمام,العملية الأمامية,العملية الأمامية,前进过程,前向过程,正向过程,processus avancé,processus direct,processus direct,前進プロセス,前方プロセス,順過程,прямой процесс,прямой процесс,прямой процесс
1745,forward propagation,الانتشار إلى الأمام,- توجيه إلى الأمام,نشر أمامي,前向传播,正向传播,前向传播,propagation vers l'avant,propagation avant,propagation avant,順伝播,フォワード伝播,前向き伝搬,прямое распространение,прямое распространение,прямое распространение
1746,forward-backward algorithm,خوارزمية للأمام والخلف,خوارزمية الإلى الوراء-إلى-الأمام,خوارزمية الأمام والخلف,前向-后向算法,前后向算法,前向-后向算法,algorithme avant-arrière,algorithme avant-arrière,algorithme avant-arrière,前方後方アルゴリズム,前向き後ろ向きアルゴリズム,前向き-後向きアルゴリズム,алгоритм вперед-назад,forward-backward алгоритм,алгоритм прямого-обратного хода
1747,foundation model,نموذج الأساس,نموذج الأساسية,نموذج أساسي,基础模型,基础模型,基础模型,modèle de fondation,modèle de base,modèle fondamental,基礎モデル,基盤モデル,基盤モデル,модель фундамента,Модель основы,модель основы
1748,fouri basis function,وظيفة أساس فوري,دوال قاعدية فوري,وظيفة قاعدة فوريه,傅里叶基函数,傅立叶基函数,傅里叶基函数,fonction de base de Fouri,fonction de base de Fourier,fonction de base de Fourier,fouri 基底関数,フーリエ基底関数,フーリエ基底関数,базисная функция Фури,базисные функции Фурье,Базисная функция Фурье
1749,fourier coefficient,معامل فورييه,معامل فورييه,معامل فورييه,傅里叶系数,傅立叶系数,傅里叶系数,coefficient de Fourier,coefficient de Fourier,Coefficient de Fourier,フーリエ係数,フーリエ係数,フーリエ係数,коэффициент Фурье,коэффициент Фурье,коэффициент Фурье
1750,fourier feature,ميزة فورييه,ميزات فوريه,ميزة فورييه,傅里叶特征,傅里叶特征,傅里叶特征,fonction de Fourier,caractéristique de Fourier,caractéristique de Fourier,フーリエ特徴,フーリエ特徴,フーリエ特徴量,функция Фурье,преобразование Фурье,Фурье-характеристики
1751,fourier frequency,تردد فورييه,ترددات فوريه,ترددات فورييه,傅立叶频率,傅立叶频率,傅里叶频率,fréquence de Fourier,fréquence de Fourier,Fréquence de Fourier,フーリエ周波数,フーリエ周波数,フーリエ周波数,частота Фурье,частота Фурье,Фурье-частота
1752,fp,fp,إطار في الثانية,لقطات في الثانية,FP,fps (每秒帧数),fp,fp,i/s,fps,FP,fps (フレーム毎秒),fp (frames per second),фп,к/с (кадров в секунду),кадр/с
1753,fp16,fp16,fp16,نصف سبك 16,FP16,fp16,半精度浮点数(fp16),fp16,fp16,fp16,FP16,fp16,fp16,фп16,fp16,fp16
1754,fp32,fp32,نقطة عائمة بـ 32 بت,fp32,FP32,fp32,fp32,fp32,fp32,fp32,FP32,fp32,fp32,фп32,fp32,fp32
1755,fractional program,برنامج كسور,برنامج كسري,برنامج كسري,分数计划,分数规划,分式规划,programme fractionnaire,programme fractionnaire,programme fractionnaire,分数プログラム,- 分数プログラム (busu puroguramu),分数計画問題,дробная программа,дробная программа,дробная программа
1756,frame,إطار,الإطار,إطار,框架,帧,帧,cadre,image,image,フレーム,フレーム,フレーム,рамка,кадр,кадр
1757,free variable,متغير حر,المتغير الحر,متغير حر,自由变量,自由变量,自由变量,variable libre,variable libre,variable libre,自由変数,自由変数,自由変数,свободная переменная,свободная переменная,свободная переменная
1758,frequency penalty,عقوبة التردد,عقوبة التردد,عقوبة التردد,频率损失,频率惩罚,频率惩罚,pénalité de fréquence,pénalité de fréquence,pénalité de fréquence,周波数ペナルティ,頻度ペナルティ,出現抑制係数,штраф за частоту,частотный штраф,частотный штраф
1759,frequency vector,ناقل التردد,متجه التردد,متجه التردد,频率向量,频率向量,频率向量,vecteur de fréquence,vecteur de fréquence,vecteur de fréquence,周波数ベクトル,頻度ベクトル (hin'ndo bekutoru),頻度ベクトル,вектор частоты,частотный вектор,Векто́р часто́т
1760,frequent close itemset,مجموعة عناصر وثيقة متكررة,- تكرار مجموعة العناصر القريبة,مجموعة عناصر متكررة ومغلقة,频繁关闭项集,频繁闭合项目集,频繁闭合项集,ensemble d'éléments à fermeture fréquente,ensemble d'éléments proches fréquents,ensemble d'articles fréquents et fermés,頻繁に閉じるアイテムセット,頻繁な閉じたアイテムセット,頻出密集アイテムセット,частое закрытие набора элементов,частые близкие наборы элементов,частый замкнутый набор элементов
1761,frequent item set,مجموعة العناصر المتكررة,مجموعات العناصر المتكررة,مجموعة العناصر المتكررة,频繁项集,频繁项集,频繁项集,ensemble d'articles fréquents,Ensemble d'éléments fréquents,ensemble d'articles fréquents,よく使うアイテムセット,頻繁アイテムセット,頻出アイテムセット,часто встречающийся набор предметов,часто встречающийся набор элементов,жесткий элемент
1762,frequent pattern,نمط متكرر,نمط متكرر,شكل متكرر,频繁模式,频繁模式,频繁模式,modèle fréquent,motif fréquent,motif fréquent,よくあるパターン,頻出パターン (hinshutsu patān),頻出パターン,частая закономерность,частый шаблон,частый шаблон
1763,frequent pattern mining,التعدين نمط متكرر,تنقيب الأنماط المتكررة,استخراج الأنماط المتكررة,频繁模式挖掘,频繁模式挖掘,频繁模式挖掘,exploration fréquente de modèles,extraction de motifs fréquents,fouille de motifs fréquents,頻繁なパターンマイニング,頻出パターン探査 (Frequent Pattern Mining),頻出パターン マイニング,частый анализ шаблонов,- Частое сопоставление шаблонов,Извлечение частых шаблонов
1764,fully connect graph,رسم بياني متصل بالكامل,الرسم البياني المتصل بالكامل,رسم بياني متصل كليًا,全连接图,全连接图,全连接图,graphique entièrement connecté,graphe entièrement connecté,graphe entièrement connecté,全結合グラフ,完全結合グラフ,完全グラフ,полностью связный граф,полностью связанный граф,полностью связанный граф
1765,fully connect layer,طبقة الاتصال بالكامل,طبقة متصلة بالكامل,طبقة متصلة كلياً,全连接层,全连接层,全连接层,couche de connexion complète,couche entièrement connectée,couche entièrement connectée,レイヤーを完全に接続します,フルコネクトレイヤー,全結合層,полностью соединительный слой,- Полностью связанный слой,полностью соединенный слой
1766,fully connect neural network,ربط الشبكة العصبية بشكل كامل,شبكة عصبية متصلة بالكامل,شبكة عصبية متصلة كليًا,全连接神经网络,全连接神经网络,全连接神经网络,connecter entièrement le réseau neuronal,réseau de neurones entièrement connecté,Réseau neuronal entièrement connecté,ニューラルネットワークを完全に接続する,全結合ニューラルネットワーク (zenketsugou nyu-rarunettowa-ku),全結合ニューラルネットワーク,полностью подключить нейронную сеть,Полностью связанная нейронная сеть,полносвязная нейронная сеть
1767,fully connected network,شبكة متصلة بالكامل,شبكة متصلة بالكامل,شبكة متصلة بالكامل,全连接网络,全连接网络,全连接网络,réseau entièrement connecté,réseau entièrement connecté,réseau entièrement connecté,完全に接続されたネットワーク,全結合ネットワーク,全結合ネットワーク,полностью подключенная сеть,Полностью связанная сеть,полносвязная сеть
1768,fully convolutional network,شبكة تلافيفية بالكامل,شبكة تحويلية كاملة التحصيل,شبكة كاملة الاحتواء,全卷积网络,全卷积网络,全卷积网络,réseau entièrement convolutif,réseau entièrement convolutionnel,réseau entièrement convolutionnel,完全な畳み込みネットワーク,完全畳み込みネットワーク (fully convolutional network),完全畳み込みネットワーク,полностью сверточная сеть,полностью сверточная сеть,полностью сверточная сеть
1769,fully convolutional neural network,شبكة عصبية تلافيفية بالكامل,شبكة عصبية تامة التكرار الثنائي,الشبكة العصبية التلافيفية الكاملة,全卷积神经网络,全卷积神经网络,全卷积神经网络,réseau neuronal entièrement convolutif,réseau neuronal entièrement convolutionnel,réseau neuronal entièrement convolutionnel,完全畳み込みニューラル ネットワーク,フルコンボリューショナルニューラルネットワーク,完全畳み込みニューラルネットワーク,полностью сверточная нейронная сеть,полностью сверточная нейронная сеть,полностью сверточная нейронная сеть
1770,fully-supervise model,نموذج الإشراف الكامل,النموذج المشرف بالكامل,نموذج مشرف تماما,全面监督模式,全监督模型,完全监督模型,modèle entièrement supervisé,modèle entièrement supervisé,modèle entièrement supervisé,完全監視モデル,フルサプライズモデル (Furu Sapuraizu Moderu),完全教師あり モデル,полностью контролируемая модель,полностью обученная модель,полностью контролируемая модель
1771,function approximation,تقريب الوظيفة,تقريب الوظيفة,تقريب الدالة,函数逼近,函数逼近,函数逼近,approximation de la fonction,approximation de fonction,approximation de fonction,関数近似,関数の近似 (Kansu no kinji),関数近似,аппроксимация функции,аппроксимация функции,функциональное приближение
1772,function approximator,تقريب الوظيفة,مقرب الوظيفة,مقارِب الدالة,函数逼近器,函数逼近器,函数逼近器,approximateur de fonction,approximant de fonction,approximateur de fonction,関数近似器,機能近似器,関数近似器,аппроксиматор функции,аппроксиматор функции,аппроксиматор функции
1773,function class,فئة الوظيفة,صنف الوظيفة,فئة الدالة,功能类,函数类,函数类,classe de fonction,classe de fonctions,classe de fonctions,関数クラス,関数クラス,関数クラス,класс функции,класс функций,класс функций
1774,function space,مساحة الوظيفة,- مساحة الدالة,فضاء الدوال,功能空间,函数空间,函数空间,espace fonctionnel,espace de fonctions,espace fonctionnel,ファンクションスペース,関数空間 (kansu kūkan),関数空間,функциональное пространство,пространство функций,пространство функций
1775,functionality assertion,تأكيد الوظيفة,تأكيد وظائفية,وظيفة تأكيدية,功能断言,功能性断言,功能断言 (gōngnéng duànyìng),affirmation de fonctionnalité,assertion de fonctionnalité,assertion de fonctionnalité,機能性の主張,機能性の主張,機能アサーション,утверждение функциональности,функциональное утверждение,функциональное утверждение
1776,fundamental matrix,مصفوفة أساسية,المصفوفة الأساسية,مصفوفة أساسية,基本矩阵,基础矩阵,基础矩阵,matrice fondamentale,matrice fondamentale,matrice fondamentale,基本行列,基本行列,基本行列,фундаментальная матрица,фундаментальная матрица,матрица фундаментальная
1777,fusion module,وحدة الانصهار,وحدة الدمج,وحدة الاندماج,融合模块,融合模块,融合模块,module de fusion,module de fusion,module de fusion,融合モジュール,融合モジュール (yuugou mojuru),融合モジュール,термоядерный модуль,модуль слияния,модуль слияния
1778,fuzzy matching,مطابقة غامضة,المطابقة غير الدقيقة,مطابقة ضبابية,模糊匹配,模糊匹配,模糊匹配,correspondance floue,- Correspondance floue,Appariement flou,ファジーマッチング,ファジー マッチング (fajii matchingu),あいまい一致,нечеткое соответствие,Растерянное сопоставление,нечёткое сопоставление
1779,g-value,قيمة ز,القيمة g,قيمة ج,g值,g值,g-值,valeur g,- Valeur g,valeur-g,g値,g-値,g値,значение g,g-значение,g-значение
1780,game tree,شجرة اللعبة,شجرة اللعبة,شجرة اللعبة,游戏树,游戏树,游戏树,arbre de jeu,Arbre de jeu,arbre de jeu,ゲームツリー,ゲームツリー,ゲーム木,дерево игры,игровое дерево,дерево игры
1781,game-theoretic analysis,التحليل النظري للعبة,تحليل لعبة اللعبة,تحليل نظرية الألعاب,博弈论分析,博弈论分析,博弈论分析,analyse de la théorie des jeux,- Analyse de la théorie des jeux,analyse théorique des jeux,ゲーム理論分析,ゲーム理論分析,ゲーム理論分析,теоретико-игровой анализ,игровой анализ,теоретико-игровой анализ
1782,gamma distribution,توزيع جاما,التوزيع الجاما,توزيع جاما,伽玛分布,伽玛分布,伽马分布,distribution gamma,distribution gamma,distribution gamma,ガンマ分布,ガンマ分布,ガンマ分布,гамма-распределение,гамма-распределение,гамма-распределение
1783,gate,بوابة,بوابة,بوابة,门,门,门控机制,grille,porte,Porte,ゲート,ゲート,ゲート,ворота,ворота,шлюз
1784,gating function,وظيفة النابضة,وظيفة البوابة,وظيفة التوجيه,门控功能,门控函数 (gating function),门控函数,fonction de déclenchement,fonction de filtrage,Fonction d'aiguillage,ゲート機能,ゲーティング関数,ゲーティング関数,стробирующая функция,функция управления доступом,управляющая функция
1785,gaussian blur,التمويه الضبابي,ضبابية غوسية,تمويه غاوسي,高斯模糊,高斯模糊,高斯模糊,flou gaussien,flou gaussien,flou gaussien,ガウスぼかし,ガウスぼかし,ガウシアンブラー,размытие по Гауссу,гауссовское размытие,гауссово размытие
1786,gaussian complexity,التعقيد الغوسي,التعقيد الكاوسي,تعقيد غاوسي,高斯复杂度,高斯复杂度,高斯复杂度,complexité gaussienne,complexité gaussienne,complexité gaussienne,ガウス複雑度,ガウス複雑さ,ガウス複雑性,гауссова сложность,гауссовская сложность,гауссова сложность
1787,gaussian component,مكون غاوسي,مكون غاوسي,مكون جاوسي,高斯分量,高斯组分,高斯分量,composante gaussienne,composante gaussienne,composante gaussienne,ガウス成分,ガウス成分,ガウス成分,гауссова компонента,- Гауссовская компонента,гауссова компонента
1788,gaussian conditional random field,حقل عشوائي مشروط غاوسي,حقل عشوائي شرطي غاوسي,حقل عشوائي شرطي جاوسي,高斯条件随机场,高斯条件随机场,高斯条件随机场,champ aléatoire conditionnel gaussien,champ aléatoire conditionnel gaussien,champ aléatoire conditionnel gaussien,ガウス条件付きランダム場,ガウシアン条件付きランダムフィールド,ガウス条件付き確率場,гауссово условное случайное поле,гауссовское условное случайное поле,условное случайное поле Гаусса
1789,gaussian density,كثافة غاوسية,كثافة غاوسية,الكثافة الجاوسية,高斯密度,高斯密度,高斯密度,densité gaussienne,densité gaussienne,densité gaussienne,ガウス密度,ガウス密度,ガウス密度,гауссова плотность,гауссовская плотность,гауссовская плотность
1790,gaussian distribution,التوزيع البياني,التوزيع الجاوسي,توزيع جاوسي,高斯分布,高斯分布,高斯分布,Distribution gaussienne,distribution gaussienne,distribution gaussienne,ガウス分布,ガウス分布,正規分布,распределение Гаусса,гауссовское распределение,нормальное распределение
1791,gaussian elimination,القضاء غاوسي,القضاء الجوسياني,الاستبعاد الجاوسي,高斯消去法,高斯消元法,高斯消元法,Élimination gaussienne,élimination gaussienne,élimination gaussienne,ガウス消去法,ガウスの消去法 (Gauss no shōkyohō),ガウス消去法,метод исключения Гаусса,Гауссовская элиминация,метод исключения Гаусса
1792,gaussian filter,مرشح غاوسي,مرشح غوسياني,فلتر جاوسي,高斯滤波器,高斯滤波器,高斯滤波器,filtre gaussien,filtre gaussien,filtre gaussien,ガウスフィルター,ガウシアンフィルタ,ガウシアンフィルター,фильтр Гаусса,гауссовский фильтр,гауссовский фильтр
1793,gaussian function,وظيفة غاوسية,الدالة الغاوسية,دالة جاوسية,高斯函数,高斯函数,高斯函数,fonction gaussienne,fonction gaussienne,fonction gaussienne,ガウス関数,ガウス関数,ガウス関数,функция Гаусса,гауссовская функция,гауссова функция
1794,gaussian initialization,التهيئة الغوسية,التهيئة الجاوسية,تهيئة جاوسية,高斯初始化,高斯初始化,高斯初始化,initialisation gaussienne,initialisation gaussienne,initialisation gaussienne,ガウス初期化,ガウス初期化,ガウス初期化,гауссова инициализация,гауссовская инициализация,гауссовская инициализация
1795,gaussian kernel,نواة غاوس,نواة جاوسية,نواة جاوسية,高斯核,高斯核,高斯核,noyau gaussien,noyau gaussien,noyau gaussien,ガウスカーネル,ガウシアンカーネル,ガウシアンカーネル,гауссово ядро,гауссовское ядро,гауссовское ядро
1796,gaussian likelihood,احتمال غاوسي,الاحتمال الجاوسي,احتمالية جاوسية,高斯似然,- 高斯似然率,高斯似然,vraisemblance gaussienne,vraisemblance gaussienne,vraisemblance gaussienne,ガウス尤度,ガウス尤度,ガウス尤度,гауссова вероятность,гауссовское правдоподобие,гауссовское правдоподобие
1797,gaussian matrix,مصفوفة غاوسية,مصفوفة غوسية,مصفوفة جاوسية,高斯矩阵,高斯矩阵,高斯矩阵,matrice gaussienne,matrice gaussienne,matrice gaussienne,ガウス行列,ガウシアン行列,ガウス行列,гауссова матрица,Гауссовская матрица,гауссовская матрица
1798,gaussian mixture,خليط غاوسي,مزيج غوسي,خليط جاوسي,高斯混合,高斯混合,高斯混合模型,mélange gaussien,mélange gaussien,mélange gaussien,混合ガウス,ガウス混合,ガウス混合分布,гауссова смесь,гауссовская смесь,смесь гауссиан
1799,gaussian mixture Model,نموذج الخليط الغوسي,نموذج الخليط الجاوسي,نموذج خليط غاوسي,高斯混合模型,高斯混合模型 (Gaussian Mixture Model),高斯混合模型,mélange gaussien Modèle,Modèle de mélange gaussien,Modèle de mélange gaussien,混合ガウスモデル,ガウス混合モデル,ガウス混合モデル,модель гауссовой смеси,Модель смеси Гаусса,Гауссовская смесь Модель
1800,gaussian model,نموذج غاوسي,النموذج الجاوسي,نموذج جاوسي,高斯模型,高斯模型,高斯模型,modèle gaussien,modèle gaussien,modèle gaussien,ガウスモデル,ガウスモデル,ガウスモデル,гауссова модель,Гауссовская модель,гауссова модель
1801,gaussian noise,الضوضاء الغوسية,ضوضاء غوسية,ضوضاء جاوسية,高斯噪声,高斯噪声,高斯噪声,bruit gaussien,bruit gaussien,bruit gaussien,ガウスノイズ,ガウスノイズ (gausunoizu),ガウス雑音,гауссов шум,гауссовский шум,гауссовский шум
1802,gaussian prior,غاوسي قبل,السابقة القوسية,افتراض جاوسي,高斯先验,高斯先验,高斯先验,a priori gaussien,prior gaussien,prior gaussien,ガウス事前分布,ガウス事前分布,ガウス事前分布,гауссов априор,гауссовский априорный,гауссовский приор
1803,gaussian process,عملية غاوسية,- تصنيع جاوسيان,عملية جاوسية,高斯过程,高斯过程,高斯过程,processus gaussien,processus gaussien,processus gaussien,ガウス過程,ガウス過程,ガウス過程,гауссов процесс,гауссовский процесс,гауссовский процесс
1804,gaussian process model,نموذج العملية الغوسية,نموذج عملية غاوسيانية,عملية غاوسية (Gaussian process),高斯过程模型,高斯过程模型,高斯过程模型,modèle de processus gaussien,- Modèle de processus gaussien,Modèle de processus gaussien,ガウス過程モデル,ガウス過程モデル,ガウス過程モデル,модель гауссовского процесса,модель гауссовского процесса,Модель гауссовского процесса
1805,gaussian process regression,انحدار عملية غاوس,عملية تحويل جاوسيانية,انحدار عملية غاوسية,高斯过程回归,高斯过程回归,高斯过程回归,régression du processus gaussien,régression de processus gaussien,régression par processus gaussien,ガウス過程回帰,ガウス過程回帰,ガウス過程回帰,регрессия гауссовского процесса,регрессия Гауссовского процесса,гауссова процессная регрессия
1806,gaussian random variable,متغير عشوائي غاوسي,متغير عشوائي غاوسي,متغير عشوائي جاوسي,高斯随机变量,高斯随机变量,高斯随机变量,variable aléatoire gaussienne,variable aléatoire gaussienne,variable aléatoire gaussienne,ガウス確率変数,ガウスランダム変数,ガウス確率変数,гауссова случайная величина,гауссовская случайная величина,гауссовская случайная величина
1807,gaussian smoothing,تجانس غاوسي,التنعيم الجاوسي,تملیس جاوسي,高斯平滑,高斯平滑,高斯平滑,lissage gaussien,lissage gaussien,lissage gaussien,ガウス平滑化,ガウシアン平滑化,ガウシアンスムージング,Гауссово сглаживание,Гауссовское сглаживание,гауссовское сглаживание
1808,gaussian variable,متغير غاوسي,متغير جوسياني,متغير غاوسي,高斯变量,高斯变量,高斯变量,variable gaussienne,variable gaussienne,variable gaussienne,ガウス変数,ガウス変数 (gaussu hensu),ガウス変数,гауссова переменная,гауссовская переменная,Гауссова переменная
1809,gaussian weight,الوزن الغوسي,وزن غاوسي,وزن جاوسي,高斯权重,高斯权重,高斯权重,poids gaussien,poids gaussien,poids gaussiens,ガウス重み,ガウス重み,ガウス重み,гауссов вес,- Гауссовский вес,гауссовский вес
1810,gene ontology,هذا هو المواد التي سوف تستخدم,تصنيف الجينات,علم مصطلحات الجينات,基因本体论,基因本体论,基因本体论,ontologie des gènes,ontologie des gènes,ontologie des gènes,遺伝子オントロジー,遺伝子オントロジー,遺伝子オントロジー,онтология генов,генетическая онтология,Онтология генов
1811,generalisation,تعميم,- تعميم,تعميم,概括,概括能力,泛化能力,généralisation,généralisation,généralisation,一般化,一般化,一般化 (ikinoka),обобщение,- Обобщение,Обобщение
1812,generalization,تعميم,التعميم,تعميم,概括,泛化,泛化能力,généralisation,généralisation,généralisation,一般化,一般化,一般化能力,обобщение,- Обобщение,обобщение
1813,generalization ability,القدرة على التعميم,القدرة على العمومية,قدرة التعميم,泛化能力,泛化能力,泛化能力,capacité de généralisation,capacité de généralisation,capacité de généralisation,一般化能力,汎化能力,一般化能力,способность к обобщению,способность к обобщению,способность к обобщению
1814,generalization bind,ربط التعميم,الربط التعميمي,حدود التعميم,泛化绑定,泛化绑定,泛化界限,liaison de généralisation,limite de généralisation,borne de généralisation,一般化バインド,一般化バインド,一般化限界 (generalization bound),связывание обобщения,общая связка,обобщающая граница
1815,generalization error,خطأ التعميم,خطأ التعميم,خطأ التعميم,泛化错误,泛化误差,泛化误差,erreur de généralisation,- Erreur de généralisation,erreur de généralisation,一般化エラー,一般化誤差 (ippanka gosa),汎化誤差,ошибка обобщения,ошибка обобщения,ошибка обобщения
1816,generalization gap,فجوة التعميم,فجوة التعميم العامة,الفجوة التعميمية,泛化差距,泛化差距,泛化差距,écart de généralisation,"""['Nous présentons nos résultats dans la Figure 5. Une dimension intrinsèque plus faible est à nouveau fortement corrélée avec un écart de généralisation relatif plus petit. Si nous interprétons la dimension intrinsèque comme une mesure de complexité, nous nous attendons à ce que l'écart de généralisation diminue avec la dimension intrinsèque.', 'Les méthodes traditionnelles cherchent à réduire l'écart de généralisation en réglant soigneusement les hyperparamètres",écart de généralisation,一般化ギャップ,一般化ギャップ,一般化ギャップ,разрыв в обобщении,разрыв обобщения,разрыв в обобщении
1817,generalization guarantee,ضمان التعميم,ضمان التعميم,ضمان التعميم,泛化保证,泛化保证,泛化保证,garantie de généralisation,garantie de généralisation,garantie de généralisation,一般化保証,一般化保証,一般化保証,гарантия обобщения,гарантия обобщения,генерализационная гарантия
1818,generalization performance,أداء التعميم,أداء التعميم العام,أداء التعميم,泛化性能,泛化性能,泛化性能,performance de généralisation,- Performance de généralisation,performance de généralisation,一般化パフォーマンス,一般化性能 (ippanka seinou),一般化性能,эффективность обобщения,обобщенная производительность,обобщающая способность
1819,generalized eigenvector,المتجهات الذاتية المعممة,متجهات ذات قيم عامة,متجه مميز معمم,广义特征向量,广义特征向量 (generalized eigenvector),广义特征向量,vecteur propre généralisé,vecteur propre généralisé,vecteur propre généralisé,一般化固有ベクトル,一般化固有ベクトル,一般化固有ベクトル,обобщенный собственный вектор,общий собственный вектор,обобщенный собственный вектор
1820,generalized linear mixed model,النموذج الخطي المختلط المعمم,النموذج المختلط العام الخطي,نماذج خطية مختلطة معممة,广义线性混合模型,广义线性混合模型,广义线性混合模型,modèle mixte linéaire généralisé,- Modèle linéaire mixte généralisé,modèle linéaire mixte généralisé,一般化線形混合モデル,一般化線形混合モデル (Generalized Linear Mixed Model),一般化線形混合モデル,обобщенная линейная смешанная модель,обобщенная линейная смешанная модель,обобщенная линейная смешанная модель
1821,generalized linear model,النموذج الخطي المعمم,النموذج الخطي العامّ,نموذج خطي عام,广义线性模型,广义线性模型 (GLM),广义线性模型,modèle linéaire généralisé,modèle linéaire généralisé,modèle linéaire généralisé,一般化線形モデル,一般化線形モデル (GLM),一般化線形モデル,обобщенная линейная модель,обобщенная линейная модель (GLM),обобщенная линейная модель
1822,generation model,نموذج الجيل,نموذج توليد الجملة,نموذج التوليد,生成模型,生成模型 (generation model),生成模型,modèle de génération,modèle de génération,modèle de génération,世代モデル,生成モデル (せいせいモデル),生成モデル,модель поколения,модель генерации,модель генерации
1823,generative,توليدي,- توليدية,توليدي,生成的,生成的,生成的,génératif,génératif,génératrice,原動力,生成的,生成的,порождающий,генеративный,генеративная
1824,generative Model,النموذج التوليدي,النموذج الإنشائي,نموذج توليدي,生成模型,生成模型,生成模型,Modèle génératif,Modèle génératif,modèle génératif,生成モデル,生成モデル,生成モデル,генеративная модель,генеративная модель,Генеративная модель
1825,generative adversarial network,شبكة الخصومة التوليدية,شبكة الجمعية التنافسية الإنتاجية,شبكة خصومية تولّدية,生成对抗网络,生成对抗网络,生成对抗网络,réseau contradictoire génératif,- Réseau génératif antagoniste,réseau antagoniste génératif,敵対的生成ネットワーク,生成対抗ネットワーク (せいせいたいこうねっとわーく),ジェネレーティブ対立ネットワーク,генеративно-состязательная сеть,генеративно-состязательная сеть,обобщенная состязательная сеть
1826,generative approach,النهج التوليدي,النهج التوليدي,المقاربة التوليدية,生成法,生成式方法,生成式方法,approche générative,- Approche générative,approche générative,生成的なアプローチ,生成的アプローチ,生成的アプローチ,генеративный подход,Генеративный подход,генеративный подход
1827,generative network,الشبكة التوليدية,شبكة توليدية,شبكة توليدية,生成网络,生成网络 (shēng chéng wǎng luò),生成网络,réseau génératif,- Réseau génératif,réseau génératif,生成ネットワーク,生成ネットワーク,ジェネレーティブネットワーク,генеративная сеть,генеративная сеть,сеть порождающая
1828,generative parser,محلل توليدي,محلل توليدية,محلل توليدي,生成解析器,生成式解析器,生成式句法分析器,analyseur génératif,analyseur génératif,analyseur génératif,生成パーサー,生成的なパーサ,生成パーサー,генеративный парсер,генеративный анализатор,порождающий парсер
1829,generative pre-training,التدريب المسبق التوليدي,التدريب التوليدي المسبق,التدريب المسبق التوليدي,生成预训练,生成式预训练,生成预训练,pré-formation générative,pré-entraînement génératif,pré-entraînement génératif,生成的な事前トレーニング,生成事前学習,生成事前学習,генеративная предварительная тренировка,генеративное предварительное обучение,генеративное предобучение
1830,generative probabilistic model,النموذج الاحتمالي التوليدي,نموذج احتمالي تكريمي,نموذج احتمالي توليدي,生成概率模型,生成概率模型,生成概率模型,modèle probabiliste génératif,modèle probabiliste génératif,modèle probabiliste génératif,生成確率モデル,生成確率モデル (せいそうかくりつモデル),生成確率モデル,генеративная вероятностная модель,генеративная вероятностная модель,генеративная вероятностная модель
1831,generative process,عملية توليدية,عملية توليدية,عملية توليدية,生成过程,生成过程,生成过程,processus génératif,processus génératif,processus génératif,生成プロセス,生成プロセス,生成過程,генеративный процесс,генеративный процесс,Генеративный процесс
1832,generator,مولد كهرباء,مُنشِّئ,مولد,发电机,生成器,生成器,Générateur,générateur,générateur,発生器,ジェネレータ,生成器,генератор,генератор,генератор
1833,generator architecture,هندسة المولدات,بنية مولد البيانات,هندسة المولّد,生成器架构,生成器架构,生成器架构,architecture du générateur,architecture du générateur,architecture génératrice,ジェネレータのアーキテクチャ,ジェネレーターアーキテクチャ,生成器アーキテクチャ,архитектура генератора,архитектура генератора,архитектура генератора
1834,generator network,شبكة المولدات,شبكة المولدات,شبكة المولد,发电机网络,生成器网络,生成器网络,réseau de générateurs,réseau générateur,réseau générateur,発電機ネットワーク,ジェネレーターネットワーク,生成器ネットワーク,генераторная сеть,сеть генераторов,сеть генератора
1835,genetic algorithm,الخوارزمية الجينية,خوارزمية جينية,خوارزمية جينية,遗传算法,遗传算法,遗传算法,algorithme génétique,Algorithme génétique,algorithme génétique,遺伝的アルゴリズム,遺伝的アルゴリズム (Iden-tekki Arugorizumu),遺伝的アルゴリズム,генетический алгоритм,генетический алгоритм,генетический алгоритм
1836,geodesic,الجيوديسية,- مسار جيوديسي,المسار الجيوديسي,测地线,测地线,测地线,géodésique,géodésique,géodésique,測地線,測地線,測地線,геодезический,геодезическая,геодезическая
1837,geodesic distance,المسافة الجيوديسية,المسافة الجيوديسية,مسافة جيوديسية,测地距离,测地距离,测地距离,distance géodésique,distance géodésique,distance géodésique,測地線距離,測地距離,測地距離,геодезическое расстояние,геодезическое расстояние,геодезическое расстояние
1838,geometric consistency,الاتساق الهندسي,الاتساق الهندسي,تناسق هندسي,几何一致性,几何一致性,几何一致性,consistance géométrique,cohérence géométrique,consistance géométrique,幾何学的一貫性,幾何学的一貫性 (kikagakuteki ikanshōsei),幾何学的一貫性,геометрическая согласованность,геометрическая согласованность,геометрическая согласованность
1839,geometric distribution,التوزيع الهندسي,التوزيع الهندسي الهندسي,توزيع هندسي,几何分布,几何分布,几何分布,distribution géométrique,distribution géométrique,distribution géométrique,幾何分布,幾何分布,幾何分布,геометрическое распределение,геометрическое распределение,геометрическое распределение
1840,geometric invariant,ثابت هندسي,المتغيرات الهندسية,مُتغَيِّرات هَنْدَسِيَّة ثابِتَة,几何不变量,几何不变量,几何不变量,invariant géométrique,invariant géométrique,invariant géométrique,幾何学的不変式,幾何学的不変量 (Kikagaku-teki fuhenryou),幾何的不変量,геометрический инвариант,геометрический инвариант,геометрическое инвариант
1841,geometric transformation,التحول الهندسي,تحويل هندسي,تحويل هندسي,几何变换,几何转换,几何变换,transformation géométrique,- Transformation géométrique,transformation géométrique,幾何学的変換,幾何変換 (kikihenkann),幾何変換,геометрическое преобразование,геометрическое преобразование,геометрическое преобразование
1842,geometry processing,معالجة الهندسة,معالجة الهندسة,معالجة الهندسة,几何处理,几何处理,几何处理,traitement de la géométrie,Traitement géométrique,traitement géométrique,ジオメトリ処理,ジオメトリ処理 (Geometry Processing),幾何処理,обработка геометрии,геометрическая обработка,обработка геометрии
1843,gibb distribution,توزيع جيب,توزيع جيبس,توزيع جيبز,吉布分布,吉布斯分布,吉布斯分布,distribution de Gibbs,distribution de Gibbs,distribution de Gibbs,ギブ分布,ギブス分布,ギブス分布,распределение Гибба,распределение Гиббса,гиббсовское распределение
1844,gini coefficient,معامل جيني,معامل جيني,معامل جيني,基尼系数,基尼系数,基尼系数,coefficient de Gini,coefficient de Gini,coefficient de Gini,ジニ係数,ジニ係数,ジニ係数,коэффициент Джини,коэффициент Джини,коэффициент Джини
1845,gist descriptor,واصف جوهر,وصف الجوهرية,وصف الملخص,要点描述符,主旨描述符,概要描述符,descripteur essentiel,descripteur d'essence,descripteur gist,要点記述子,要約記述子,主旨記述子 (shuushi kijutsushi),дескриптор сути,"(1) Набор данных по определению сцен на открытом воздухе (OSR) [11], содержащий 2688 изображений из 8 категорий. Мы используем 512-мерный дескриптор [11] суть в качестве характеристик изображения. 1. Б",дескриптор сути
1846,global average pooling,المتوسط ​​العالمي للتجميع,التجميع العالمي المتوسط,المتوسط العالمي للتجميع,全局平均池化,全局平均池化,全局平均池化,mise en commun moyenne mondiale,regroupement moyen global,pooling global moyen,世界的な平均プーリング,グローバル平均プーリング (gurobaru heikin puringu),グローバル平均プーリング,глобальное среднее объединение,глобальное усреднениеPooling,глобальное усреднение
1847,global average pooling layer,طبقة التجميع العالمية المتوسطة,طبقة التجميع العالمي المتوسط ​​(global average pooling),طبقة التجميع المتوسط العالمي,全局平均池化层,全局平均池化层,全局平均池化层,couche de mise en commun moyenne globale,couche de regroupement moyenne globale,couche de pooling moyen global,グローバル平均プーリング層,グローバル平均プーリング層,グローバル平均プーリング層,глобальный средний уровень объединения,глобальный слой пулинга средних,слой глобального усреднения
1848,global coordinate frame,إطار الإحداثيات العالمية,الإطار الإحداثي العالمي,إطار الإحداثيات الشامل,全局坐标系,全局坐标系统,全局坐标系,cadre de coordonnées global,cadre de coordonnées global,Cadre de coordonnées global,グローバル座標フレーム,グローバル座標フレーム (Global Coordinate Frame),全体座標系,глобальная система координат,глобальная система координат,глобальная система координат
1849,global illumination,الإضاءة العالمية,الإضاءة العالمية,- الإضاءة العالمية,全局照明,全局照明,全局照明,Illumination globale,illumination globale,illumination globale,グローバルイルミネーション,グローバルイルミネーション,グローバル照明,глобальное освещение,глобальное освещение,глобальное освещение
1850,global minima,الحد الأدنى العالمي,الأدنى العالمية,الحدود الصغرى العالمية,全局最小值,全局极小值,全局最小值,minimums globaux,minima globaux,minima globaux,大域的最小値,グローバル最小値,グローバル最小値,глобальные минимумы,глобальный минимум,глобальные минимумы
1851,global minimum,الحد الأدنى العالمي,الحد الأدنى العالمي,أدنى حد عالمي,全局最小值,全局最小值,全局最小值,minimum global,minimum global,minimum global,グローバルミニマム,グローバル最小値,グローバル最小値,глобальный минимум,глобальный минимум,глобальный минимум
1852,global model,نموذج عالمي,النموذج العالمي,نموذج عالمي,全球模式,全局模型,全局模型,modèle global,modèle global,modèle global,グローバルモデル,グローバルモデル,グローバルモデル,глобальная модель,глобальная модель,глобальная модель
1853,global objective,الهدف العالمي,الهدف العالمي,هدف عالمي,全球目标,全局目标,全局目标,objectif global,objectif global,Objectif global,世界的な目標,- グローバル目的 (Global Objective),グローバル目的関数,глобальная цель,глобальная цель,глобальный критерий
1854,global optima,الأمثل العالمية,قمم عالمية,الحلول العالمية المثلى,全局最优,全局最优解,全局最优解,optima global,optima globaux,optima globaux,グローバルオプティマ,グローバル最適解,グローバル最適解,глобальный оптимум,глобальная оптимум,глобальные оптимумы
1855,global optimization,التحسين العالمي,- تحسين عالمي,تهيئة شاملة,全局优化,全局优化,全局优化,optimisation globale,optimisation globale,optimisation globale,グローバル最適化,グローバル最適化,グローバル最適化,глобальная оптимизация,глобальная оптимизация,глобальная оптимизация
1856,global optimum,العالمي الأمثل,النقطة الأمثل العالمية,الحل الأمثل العالمي,全局最优,全局最优解,全局最优解,optimal global,optimum global,optimum global,全体最適,グローバル最適解,グローバル最適解,глобальный оптимум,глобальный оптимум,глобальный оптимум
1857,global pooling,التجميع العالمي,- تجميع عالمي,التجميع العالمي,全球汇集,全局池化,全局池化,mutualisation mondiale,regroupement global,poolage global,グローバルプーリング,グローバルプーリング (Global Pooling),グローバルプーリング,глобальное объединение,глобальное пулингирование,глобальное объединение
1858,global reward,مكافأة عالمية,- تكافأ عالمي,المكافأة العالمية,全球奖励,全局奖励,全局奖励,récompense mondiale,- Récompense globale,récompense globale,グローバル報酬,グローバル報酬,グローバル報酬,глобальная награда,глобальное вознаграждение,глобальное вознаграждение
1859,goal state,حالة الهدف,حالة الهدف,الحالة الهدف,目标状态,目标状态,目标状态,état d'objectif,"""['Nous disons qu'un état est atteignable dans P s'il est atteignable depuis l'état initial s 0. Un état s est résoluble s'il existe un état but atteignable à partir de s. Une solution à la tâche de planification, c'est-à-dire un plan, est une séquence d'actions π = a 1, . . .', 'Nous ajoutons tous les états visités à l'ensemble d'entraînement T, et les étiquet",état but,目標状態,目標状態 (mokuhyou joutai),目標状態,целевое состояние,целевое состояние,целевое состояние
1860,gold label,تسمية الذهب,تسمية ذهبية,البيانات الهدف,金标,金标签,金标准,étiquette doré,étiquette en or,étiquette de référence,ゴールドラベル,ゴールドラベル,正解ラベル,золотая этикетка,золотая метка,эталонная метка
1861,gold parse,تحليل الذهب,التحليل الذهبي,تحليل الذهب,黄金解析,黄金解析,金标准解析,analyse d'or,analyse en or,l'analyse syntaxique de référence,ゴールドパース,ゴールドパース,正解の構文解析,анализ золота,золотой разбор (gold parse),золотой разбор
1862,good-first search,البحث الجيد الأول,البحث الأولوي الجيد,البحث الجيد أولًا,良好优先搜索,最佳优先搜索,贪心最优搜索,bonne première recherche,recherche meilleur d'abord,recherche du meilleur d'abord,良い優先検索,優先度の低い探索 (good-first search),優良優先探索,добрый первый поиск,поиск с наилучшим первым выбором,поиск с наилучшим началом
1863,good-first search algorithm,خوارزمية البحث الجيدة الأولى,خوارزمية البحث الأفضل أولاً,خوارزمية البحث الأفضل أولاً,良好优先搜索算法,好-优先搜索算法,优先搜索算法,algorithme de recherche bon premier,algorithme de recherche meilleur premier,algorithme de recherche good-first,グッドファースト検索アルゴリズム,良い最初の探索アルゴリズム,良い最初探索アルゴリズム,алгоритм поиска по принципу «сначала добро»,алгоритм поиска с хорошим первым выбором,алгоритм поиска по лучшему первому шагу
1864,good-turing estimate,تقدير جيد,تقدير غود تورينغ,تقدير جود-تورنج,古德图灵估计,古德-图灵估计,好图灵估计,estimation de bonne qualité,estimation good-turing,estimateur de Good-Turing,順調な見積もり,グッド・チューリング推定,グード・チューリング推定,оценка Гуд-Тьюринга,оценка Гуд-Тьюринга,хороший оценка туринга
1865,gossip algorithm,خوارزمية القيل والقال,خوارزمية النميمة,خوارزمية التّثرثر,八卦算法,传言算法,传闻算法,algorithme de potins,algorithme de commérage,algorithme de bavardage,ゴシップアルゴリズム,ゴシップアルゴリズム,ゴシップアルゴリズム,алгоритм сплетен,алгоритм сплетен,алгоритм сплетен
1866,gradient accumulation,تراكم التدرج,تراكم الميل (gradient accumulation),تراكم التدرج,梯度累积,梯度累积,梯度累积,accumulation de gradient,accumulation de gradient,accumulation de gradients,勾配累積,勾配蓄積 (koubai chikuseki),勾配蓄積,накопление градиента,аккумуляция градиента,накопление градиентов
1867,gradient accumulation step,خطوة تراكم التدرج,- تراكم التدرجات في الخطوة,خطوة تراكم التدرج,梯度累积步骤,梯度累积步骤,梯度累积步数,étape d'accumulation de gradient,étape d'accumulation du gradient,étape d'accumulation de gradient,勾配累積ステップ,勾配蓄積ステップ,勾配蓄積ステップ,шаг накопления градиента,шаг накопления градиента,шаг накопления градиентов
1868,gradient ascent,صعود التدرج,صعود التدرج,تصاعد التدرج,梯度上升,梯度上升,梯度上升法,montée en pente,ascension de gradient,montée du gradient,勾配上昇,勾配上昇 (Koubai joushou),勾配上昇法,градиентный подъем,градиентный подъем,градиентный подъем
1869,gradient boost tree,شجرة تعزيز التدرج,شجرة التعزيز التدريجي,شجرة تدرج التعزيز,梯度提升树,梯度提升树,梯度提升树,arbre d'augmentation du dégradé,arbre de boost de gradient,arbre de renforcement de gradient,グラデーションブーストツリー,勾配ブースト木,勾配ブースティングツリー,Дерево градиентного повышения,градиентный бустинг деревьев,градиентное усиление деревьев
1870,gradient clipping,قطع التدرج,التقليم التدريجي,تقييد التدرج,梯度裁剪,梯度裁剪,梯度裁剪,découpage en dégradé,clipping de gradient,écrêtage de gradient,グラデーションクリッピング,勾配クリッピング (こうばいクリッピング),勾配クリッピング,градиентная обрезка,обрезка градиента,обрезание градиента
1871,gradient computation,حساب التدرج,حساب الميل,حساب التدرج,梯度计算,梯度计算,梯度计算,calcul du gradient,calcul du gradient,calcul du gradient,勾配計算,勾配計算,勾配計算,вычисление градиента,вычисление градиента,вычисление градиента
1872,gradient descent,نزول متدرج,الانحدار التدريجي,تدرج التدريج,梯度下降,梯度下降,梯度下降,Descente graduelle,Descente de gradient,descente de gradient,勾配降下法,勾配降下,勾配降下法,градиентный спуск,Градиентный спуск,метод градиентного спуска
1873,gradient descent algorithm,خوارزمية النسب التدرج,خوارزمية الانحدار التدريجي,خوارزمية الهبوط التدريجي,梯度下降算法,梯度下降算法,梯度下降算法,algorithme de descente de gradient,algorithme de descente de gradient,algorithme de descente de gradient,勾配降下法アルゴリズム,勾配降下アルゴリズム,勾配降下法,алгоритм градиентного спуска,алгоритм градиентного спуска,алгоритм градиентного спуска
1874,gradient estimate,تقدير التدرج,تقدير التدرجات,تقدير التدرج,梯度估计,梯度估计,梯度估计,estimation du gradient,estimation du gradient,estimation du gradient,勾配推定,勾配推定 (kōhai sūtei),勾配推定,оценка градиента,оценка градиента,оценка градиента
1875,gradient estimation,تقدير التدرج,تقدير التدرجات,تقدير التدرج,梯度估计,梯度估计,梯度估计,estimation du gradient,estimation du gradient,estimation du gradient,勾配推定,勾配推定 (Koubai Suitei),勾配推定,оценка градиента,оценка градиента,оценка градиента
1876,gradient estimator,مقدر التدرج,مقدر التدرج,مقدر التدرج,梯度估计器,梯度估计器,梯度估计器,estimateur de gradient,estimateur de gradient,estimateur de gradient,勾配推定器,勾配推定器 (kōsai suiteki-ki),勾配推定器,оценщик градиента,оценщик градиента,градиентный оценщик
1877,gradient explosion,انفجار التدرج,انفجار التدرج,انفجار التدرج,梯度爆炸,梯度爆炸,梯度爆炸,explosion de dégradé,explosion de gradient,explosion de gradient,勾配爆発,勾配爆発 (Kōsai Bakuhatsu),勾配爆発,градиентный взрыв,градиентный взрыв,взрыв градиента
1878,gradient flow,تدفق التدرج,تدفق التدرج,تدفق التدرج,梯度流,梯度流,梯度流,flux graduel,flux de gradient,flux de gradient,勾配の流れ,勾配フロー (Kōhai Furō),勾配フロー,градиентный поток,градиентный поток,поток градиента
1879,gradient information,معلومات التدرج,معلومات التدرجات,تدرج المعلومات,梯度信息,梯度信息,梯度信息,informations sur le dégradé,information de gradient,information du gradient,勾配情報,勾配情報 (koubai jouhou),勾配情報,информация о градиенте,градиентная информация,градиентная информация
1880,gradient method,طريقة التدرج,الطريقة التدريجية,طريقة التدرج,梯度法,梯度方法,梯度方法,méthode du dégradé,- Méthode du gradient,méthode de gradient,勾配法,勾配法 (Kōhaidō),勾配法,градиентный метод,метод градиента,метод градиентного спуска
1881,gradient norm,قاعدة التدرج,المعيار التدرجي,معيار التدرج,梯度范数,梯度范数,梯度范数,norme de gradient,norme du gradient,norme du gradient,勾配ノルム,勾配ノルム (koubai norumu),勾配ノルム,норма градиента,норма градиента,норма градиента
1882,gradient operator,عامل التدرج,مشغل التدرج,مشغل التدرج,梯度算子,梯度算子,梯度算子,opérateur de dégradé,- Opérateur de gradient,opérateur gradient,勾配演算子,勾配演算子,勾配演算子,оператор градиента,оператор градиента,оператор градиента
1883,gradient penalty,عقوبة التدرج,عقوبة التدرجية,شعيرة معدل التدرج,梯度惩罚,梯度惩罚,梯度惩罚,pénalité de gradient,pénalité de gradient,pénalité de gradient,勾配ペナルティ,勾配ペナルティ (Koubai Penalti),勾配ペナルティ,штраф за градиент,градиентное наказание,градиентное штрафование
1884,gradient signal,إشارة التدرج,إشارة التدرج,إشارة التدرج,梯度信号,梯度信号,梯度信号,signal de gradient,- Signal de gradient,signal de gradient,勾配信号,勾配信号,勾配シグナル,градиентный сигнал,градиентный сигнал,сигнал градиента
1885,gradient step,خطوة التدرج,خطوة التدرج,خطوة التدرج,梯度步长,梯度步骤,梯度步骤,étape de gradient,étape de gradient,pas de gradient,グラデーションステップ,勾配ステップ,勾配ステップ,градиентный шаг,шаг градиента,шаг градиента
1886,gradient term,مصطلح التدرج,مصطلح التدرج,مصطلح التدرج,梯度项,梯度项 (gradient term),梯度项,terme de gradient,terme de gradient,terme de gradient,勾配項,勾配項 (kōsoku-kō),勾配項,термин градиента,термин градиента,градиентный член
1887,gradient update,تحديث التدرج,تحديث التدرجات,تحديث التدرج,梯度更新,梯度更新 (Gradient Update),梯度更新,mise à jour du dégradé,mise à jour du gradient,mise à jour du gradient,グラデーションの更新,勾配更新 (Koubai Koushin),勾配更新,обновление градиента,обновление градиента,градиентное обновление
1888,gradient variance,تباين التدرج,تباين الميل,تباين المُتدرّج,梯度方差,梯度方差,梯度方差,variance de gradient,variance du gradient,variance du gradient,勾配分散,勾配分散 (kōsai bunsan),勾配の分散,дисперсия градиента,градиентная вариация,наклон дисперсии
1889,gradient vector,ناقلات التدرج,متجه التدرجات,متجه التدرج,梯度向量,梯度向量,梯度向量,vecteur de dégradé,vecteur de gradient,vecteur de gradient,勾配ベクトル,勾配ベクトル,勾配ベクトル,вектор градиента,градиентный вектор,вектор градиента
1890,gradient-base approach,نهج قاعدة التدرج,النهج القائم على التدرجات,منهج قائم على التدرج,基于梯度的方法,梯度基础方法,基于梯度的方法,approche à base de gradient,- Approche basée sur le gradient,approche basée sur le gradient,勾配ベースのアプローチ,勾配ベースアプローチ,勾配ベースアプローチ,градиентный подход,подход на основе градиента,подход на основе градиента
1891,gradient-base learning,التعلم القائم على التدرج,التعلم القائم على التدرجات,التعلم القائم على التدرج,基于梯度的学习,梯度基学习,基于梯度学习,apprentissage basé sur le gradient,apprentissage basé sur le gradient,apprentissage par gradient,勾配ベースの学習,勾配ベースの学習 (Kōsai bēsu no gakushū),勾配ベース学習,градиентное обучение,обучение на основе градиента,обучение на основе градиентов
1892,gradient-base method,طريقة قاعدة التدرج,طريقة قائمة على التدرج,طرق قائمة على التدرج,梯度法,梯度-based方法,基于梯度的方法,méthode de base de gradient,méthode basée sur le gradient,méthode basée sur le gradient,勾配ベース法,勾配ベースの方法 (Kōsai bēsu no hōhō),勾配ベース法,градиентный метод,метод на основе градиента,метод на основе градиента
1893,gradient-base optimization,تحسين قاعدة التدرج,تحسين قاعدة التدرجات,تحسين قائم على التدرج,基于梯度的优化,梯度优化 (gradient optimization),基于梯度的优化,optimisation de base de gradient,optimisation basée sur le gradient,Optimisation par gradient,勾配ベースの最適化,勾配ベースの最適化 (kōsai bēsu no saitekika),勾配ベース最適化,оптимизация на основе градиента,оптимизация на основе градиента,Оптимизация по градиенту
1894,gram matrix,مصفوفة جرام,مصفوفة غرام,مصفوفة غرام,克矩阵,格拉姆矩阵,格拉姆矩阵,matrice de grammes,matrice de Gram,matrice de Gram,グラム行列,グラム行列,グラム行列,граммовая матрица,матрица Грама,матрица Грама
1895,grammar inducer,الحافز النحوي,محرض القواعد النحوية,مُستَوحي قواعد,语法诱导子,语法诱导器,语法归纳器,inducteur de grammaire,inducteur de grammaire,inducteur de grammaire,文法誘導剤,文法誘導器,文法誘導器,грамматический стимулятор,грамматический индуктор,индуктор грамматики
1896,grammar induction,الحث النحوي,إنتاج القواعد النحوية,استنباط القواعد,语法归纳,语法归纳,语法归纳,introduction à la grammaire,induction de grammaire,induction grammaticale,文法導入,文法認定,文法誘導,грамматическая индукция,индукция грамматики,вывод грамматики
1897,grammatical error detection,كشف الأخطاء النحوية,الكشف عن الأخطاء النحوية,اكتشاف الأخطاء النحوية,语法错误检测,语法错误检测,语法错误检测,détection des erreurs grammaticales,détection des erreurs grammaticales,détection d'erreurs grammaticales,文法エラーの検出,文法エラー検出,文法的誤りの検出,обнаружение грамматических ошибок,обнаружение грамматических ошибок,обнаружение грамматических ошибок
1898,grandparent dependency,تبعية الأجداد,التبعية الجدية,اعتماد الجد,祖父母依赖,祖父母依赖,祖先依赖性,dépendance des grands-parents,dépendance des grands-parents,dépendance grand-parente,祖父母の依存関係,祖父母依存,祖先依存関係,зависимость от бабушки и дедушки,"""['Это позволяет этим функциям моделировать зависимости от бабушки, такие как (k *, i, l j) и зависимости между братьями, такие как (i, l j−1, l j).', 'произошло) . • G(y) - это набор зависимостей от бабушек первого типа. Каждая зависимость",зависимость от предка
1899,graph,رسم بياني,مخطط,رسم بياني,图形,图论,图,graphique,graphe,graphe,グラフ,グラフ,グラフ,график,Граф,граф
1900,graph Laplacian,الرسم البياني لابلاسيان,اللابلاسيان الرسمي,لابلاسيان الرسم البياني,图拉普拉斯,图拉普拉斯算子,图拉普拉斯矩阵,graphique Laplacien,Laplacien de graphe,laplacien du graphe,ラプラシアングラフ,グラフ・ラプラシアン,グラフラプラシアン,граф Лапласа,графовый Лапласиан,Лапласиан графа
1901,graph Transformer,محول الرسم البياني,محول الرسوم التوضيحية,مُحوِّل الرَّسْم البيانيّ,图变压器,图变换器,图Transformer,Transformateur graphique,Transformateur de graphe,graphe Transformeur,グラフトランス,グラフ トランスフォーマー,グラフTransformer,граф Трансформатор,Графовый трансформер,граф Трансформер
1902,graph adjacency matrix,مصفوفة الجوار الرسم البياني,مصفوفة قربية الرسم البياني,مصفوفة التجاور للرسم البياني,图邻接矩阵,图邻接矩阵,图邻接矩阵,matrice de contiguïté graphique,Matrice d'adjacence du graphe,matrice d'adjacence de graphe,グラフ隣接行列,グラフ隣接行列 (Graph adjacency matrix),グラフ隣接行列,матрица смежности графов,матрица смежности графа,матрица смежности графа
1903,graph attention,الاهتمام بالرسم البياني,آلية التركيز على الرسوم البيانية,انتباه الرسم البياني,图注意力,图注意力,图注意力,attention graphique,attention de graphe,Attention sur le graphe,グラフの注意,グラフアテンション,グラフアテンション,график внимания,графовое внимание,графовое внимание
1904,graph attention mechanism,آلية الاهتمام الرسم البياني,آلية الانتباه للرسم البياني,آلية انتباه الرسم البياني,图注意力机制,图注意力机制 (graph attention mechanism),图注意力机制,mécanisme d'attention graphique,mécanisme d'attention graphique,mécanisme d'attention sur les graphes,グラフアテンションメカニズム,グラフ注意メカニズム (Graph Attention Mechanism),グラフアテンションメカニズム,механизм внимания на графике,механизм внимания к графу,механизм графового внимания
1905,graph attention network,شبكة الاهتمام الرسم البياني,شبكة انتباه الرسم البياني,شبكة انتباه الرسم البياني,图注意力网络,图注意力网络,图注意力网络,réseau d'attention graphique,réseau d'attention graphique,réseau d'attention de graphe,グラフアテンションネットワーク,グラフ・アテンション・ネットワーク,グラフアテンションネットワーク,графическая сеть внимания,сеть внимания графика,сетевая архитектура с графовым вниманием
1906,graph classification,تصنيف الرسم البياني,- تصنيف الرسم البياني,تصنيف الرسم البياني,图分类,图分类,图分类,classification graphique,classification de graphes,classification de graphes,グラフの分類,グラフ分類,グラフ分類,классификация графов,классификация графов,классификация графов
1907,graph clustering,تجميع الرسم البياني,تجميع الرسوم البيانية,تجميع الرسم البياني,图聚类,图聚类,图聚类,regroupement de graphiques,regroupement de graphes,regroupement de graphes,グラフクラスタリング,グラフクラスタリング,グラフクラスタリング,кластеризация графов,графическая кластеризация,Кластеризация графов
1908,graph construction,بناء الرسم البياني,بناء الرسوم البيانية,بناء الرسم البياني,图构建,图构建,图构建,construction de graphiques,construction de graphe,construction de graphe,グラフ構築,グラフ構築,グラフ構築,построение графа,построение графа,построение графа
1909,graph contrastive learning,الرسم البياني التعلم المتناقض,تعلم التباين الرسمي,التعلم التباينيّ للرسم البياني,图对比学习,图对比学习,图对比学习,apprentissage contrastif graphique,apprentissage contrastif de graphes,apprentissage contrastif de graphes,グラフ対照学習,グラフ対比学習,グラフ対照的学習,графическое контрастное обучение,графовое контрастное обучение,контрастное обучение графов
1910,graph convolution,الإلتواء الرسم البياني,تحويل الرسم البياني,التشفير البياني,图卷积,图卷积,图卷积,convolution graphique,convolution de graphe,convolution de graphe,グラフの畳み込み,グラフ畳み込み (graph convolution),グラフ畳み込み,свертка графа,графовая свертка,графная свёртка
1911,graph convolution network,شبكة تلافي الرسم البياني,شبكة تحويل الرسوم البيانية,شبكة التطرق الرسومي بياني,图卷积网络,图卷积网络,图卷积网络 (GCN),réseau de convolution graphique,- Réseau de convolution de graphes,Réseau de convolution sur graphe,グラフ畳み込みネットワーク,- グラフ畳み込みネットワーク (graph convolution network),グラフ畳み込みネットワーク (GCN),сеть свертки графов,сеть свертки графа,Сетьграфическихсверток
1912,graph convolutional network,شبكة تلافيفية الرسم البياني,شبكة التحويل الرسم البياني,شبكة التضمين الجرافيكي المتجهة,图卷积网络,图卷积网络 (Graph Convolutional Network),图卷积网络,réseau convolutionnel graphique,- Réseau de convolution graphique,réseau de convolution de graphe,グラフ畳み込みネットワーク,グラフ畳み込みネットワーク,グラフ畳み込みネットワーク,графовая сверточная сеть,графовая сверточная сеть,сеть свёрточных графов
1913,graph cut,قطع الرسم البياني,قطع الرسم البياني,قص الرسم البياني,图形切割,图割,图割,coupe graphique,coupe de graphe,coupe de graphe,グラフカット,グラフカット,グラフカット,разрез графика,графовое разрезание,разрез графа
1914,graph cut algorithm,خوارزمية قطع الرسم البياني,خوارزمية قص الرسوم البيانية,خوارزمية قطع الرسم البياني,图割算法,图割算法 (graph cut algorithm),图割算法,algorithme de coupe graphique,Algorithme de coupe de graphe,algorithme de coupe de graphe,グラフカットアルゴリズム,グラフカットアルゴリズム,グラフカットアルゴリズム,алгоритм разрезания графа,алгоритм разреза графа,разрезание графа алгоритм
1915,graph dataset,مجموعة بيانات الرسم البياني,مجموعة بيانات الرسم البياني,مجموعة بيانات الرسم البياني,图数据集,图数据集,图数据集,ensemble de données graphiques,ensemble de données de graphiques,ensemble de données de graphes,グラフデータセット,グラフデータセット,グラフデータセット,набор графических данных,- Графовый набор данных,набор графовых данных
1916,graph datum,مسند الرسم البياني,بيانات الرسوم البيانية,بيانات الرسم البياني,图形数据,图数据,图数据,donnée graphique,donnée de graphe,donnée de graphe,グラフデータム,グラフデータ,グラフデータ,графовая база данных,графические данные,данные графа
1917,graph diameter,قطر الرسم البياني,قطر الرسم البياني,قُطْر الرسم البياني,图形直径,图直径,图直径,diamètre du graphique,diamètre du graphe,diamètre du graphe,グラフの直径,グラフ直径,グラフ直径,диаметр графика,диаметр графа,диаметр графа
1918,graph embedding,تضمين الرسم البياني,تضمين الرسم البياني,تضمين الرسم البياني,图嵌入,图嵌入,图嵌入,intégration de graphiques,plongement de graphe,plongement de graphe,グラフの埋め込み,グラフ埋め込み (Graph embedding),グラフ埋め込み,встраивание графа,вложение графа,отображение графа
1919,graph generator,مولد الرسم البياني,مُنشئ الرسوم البيانية,مولد الرسم البياني,图形生成器,图生成器,图生成器,générateur de graphiques,générateur de graphe,générateur de graphes,グラフジェネレーター,グラフ生成器,グラフ生成器,генератор графов,генератор графа,генератор графов
1920,graph isomorphism,التماثل البياني,تطابق الرسوم البيانية,تطابق البيانات الرسومية,图同构,图同构,图同构,isomorphisme graphique,isomorphisme de graphes,isomorphisme de graphes,グラフの同型性,グラフ同型性,グラフ同型,изоморфизм графов,изоморфизм графа,изоморфизм графа
1921,graph kernel,نواة الرسم البياني,نواة الرسم البياني,لب الرسم البياني,图内核,图核函数,图核,noyau graphique,noyau de graphe,noyau de graphe,グラフカーネル,グラフカーネル,グラフカーネル,ядро графа,графовое ядро,ядро графа
1922,graph laplacian matrix,الرسم البياني مصفوفة لابلاس,مصفوفة لابلاس للرسم البياني,مصفوفة لابلاسيان البياني,图拉普拉斯矩阵,图拉普拉斯矩阵,图拉普拉斯矩阵,graphique matrice laplacienne,- Matrice laplacienne du graphe,matrice laplacienne du graphe,グラフのラプラシアン行列,グラフ・ラプラシアン行列,グラフラプラシアン行列,графическая матрица Лапласа,матрица Лапласа графа,матрица лапласиана графа
1923,graph learning,تعلم الرسم البياني,تعلم الرسوم البيانية,تعلم الرسم البياني,图学习,图学习,图学习,apprentissage des graphiques,apprentissage de graphe,apprentissage de graphes,グラフ学習,グラフ学習,グラフ学習,графическое обучение,графическое обучение,обучение на графах
1924,graph matching,مطابقة الرسم البياني,مطابقة الرسوم البيانية,مطابقة الرسم البياني,图匹配,图匹配,图匹配,correspondance graphique,appariement de graphes,appariement de graphes,グラフマッチング,グラフマッチング,グラフマッチング,сопоставление графиков,сопоставление графов,сопоставление графов
1925,graph mining,التعدين الرسم البياني,تنقيب الرسوم البيانية,تعدين الرسوم البيانية,图挖掘,图挖掘,图挖掘,extraction de graphiques,extraction de graphes,extraction de graphes,グラフマイニング,グラフマイニング,グラフマイニング,майнинг графов,графовая добыча,шахтная разработка графов
1926,graph model,نموذج الرسم البياني,نموذج الرسم البياني,نموذج الرسم البياني,图模型,图模型,图模型,modèle graphique,- Modèle de graphe,modèle de graphe,グラフモデル,グラフモデル,グラフモデル,графовая модель,модель графа,модель графа
1927,graph neural Networks,الرسم البياني للشبكات العصبية,شبكات العصب الرسمية للرسم البياني,شبكات عصبية بيانية,图神经网络,图神经网络,图神经网络,réseaux de neurones graphiques,Réseaux neuronaux graphiques,Réseaux neuronaux sur graphes,グラフニューラルネットワーク,グラフニューラルネットワーク (GNNs),グラフニューラルネットワーク,граф нейронных сетей,Графовые нейронные сети,графовые нейронные сети
1928,graph neural network,الشبكة العصبية الرسم البياني,شبكة عصبونية للرسم البياني,شبكة عصبية بيانية,图神经网络,图神经网络,图神经网络,réseau neuronal graphique,réseau neuronal graphique,réseau de neurones graphiques,グラフニューラルネットワーク,グラフニューラルネットワーク,グラフニューラルネットワーク,графическая нейронная сеть,графовая нейронная сеть,граф нейронная сеть
1929,graph node,عقدة الرسم البياني,عقدة الرسم البياني,عقدة الرسم البياني,图节点,图节点,图节点,nœud de graphique,nœud de graphe,noeud de graphe,グラフノード,グラフのノード (Graph Node),グラフノード,узел графа,узел графа,узел графа
1930,graph partitioning,تقسيم الرسم البياني,- تقسيم الرسوم-grap partitioning,تقسيم الرسم البياني,图划分,图分区,图划分,partitionnement de graphe,partitionnement de graphe,partitionnement de graphe,グラフの分割,グラフ分割,グラフ分割,разбиение графа,разбиение графа,разбиение графа
1931,graph pattern,نمط الرسم البياني,نمط الرسم البياني,نمط الرسم البياني,图形模式,图案模式,图模式,motif graphique,motif graphique,motif graphique,グラフパターン,グラフパターン,グラフパターン,графический шаблон,графический узор,шаблон графа
1932,graph representation,تمثيل الرسم البياني,التمثيل البياني للرسمم,تمثيل البيانات الرسومية,图形表示,图表示,图表示,représentation graphique,représentation graphique,représentation graphique,グラフ表現,グラフ表現,グラフ表現,графическое представление,графическое представление,графовое представление
1933,graph sampling,أخذ عينات من الرسم البياني,عينة الرسم البياني,أخذ عينات من الرسم البياني,图采样,图采样,图采样,échantillonnage graphique,échantillonnage de graphe,échantillonnage de graphe,グラフサンプリング,グラフサンプリング (graph sampling),グラフサンプリング,выборка графика,метод выборки графа,выборка графа
1934,graph structure,هيكل الرسم البياني,هيكل الرسم البياني,بنية الرسم البياني,图结构,图结构,图结构,structure du graphique,structure de graphe,structure de graphe,グラフ構造,グラフ構造,グラフ構造,структура графа,структура графа,структура графа
1935,graph theory,نظرية الرسم البياني,نظرية الرسوم البيانية,نظرية البيانات,图论,图论 (Tú Lùn),图论,la théorie des graphes,théorie des graphes,théorie des graphes,グラフ理論,グラフ理論 (Graph Riron),グラフ理論,теория графов,теория графов,теория графов
1936,graph topology,طوبولوجيا الرسم البياني,- توبولوجيا الرسم البياني,توبولوجيا الرسم البياني,图拓扑,图拓扑结构,图拓扑结构,topologie graphique,topologie du graphe,topologie du graphe,グラフトポロジ,"""既存の非線形次元削減アルゴリズムに構造保存制約を組み込むことにより、これらの手法は局所距離に加えてグラフの構造を明示的に保存し、より正確な低次元の埋め込みを生成することができます。""",グラフトポロジー,графовая топология,топология графа,топология графа
1937,graph traversal,اجتياز الرسم البياني,عبور الرسوم البيانية,جولة الرسم البياني,图遍历,图形遍历,图遍历,parcours graphique,- Traversal de graphe,parcours de graphe,グラフの横断,グラフ走査,グラフトラバーサル,обход графа,обход графа,обход графа
1938,graph-base approach,النهج القائم على الرسم البياني,نهج قائم على الرسوم البيانية,نهج قائم على الرسم البياني,基于图的方法,图形基础方法,基于图的方法,approche basée sur des graphiques,Approche basée sur les graphes,approche basée sur les graphes,グラフベースのアプローチ,グラフベースのアプローチ (gurafu-beesu no apurōchi),グラフベースアプローチ,графический подход,графовый подход,Подход на основе графа
1939,graph-base dependency parsing,تحليل التبعية لقاعدة الرسم البياني,تحليل التبعية القائم على الرسم البياني,تحليل التبعية القائم على الرسم البياني,基于图的依存分析,基于图的依存句法分析,基于图的依存句法分析,analyse des dépendances à base de graphique,analyse syntaxique basée sur les graphes,analyse syntaxique par dépendances basée sur des graphes,グラフベースの依存関係の解析,グラフベース依存構造解析,グラフベース依存構造解析,анализ зависимостей на основе графа,графовый анализ зависимостей,графоаналитический синтаксический анализ зависимостей
1940,graph-base learning,التعلم القائم على الرسم البياني,التعلم القائم على الرسوم البيانية,التعلم القائم على الرسم البياني,基于图的学​​习,图形化学习,基于图的学习,apprentissage basé sur des graphiques,apprentissage basé sur les graphes,apprentissage basé sur les graphes,グラフベースの学習,グラフベース学習,グラフベース学習,обучение на основе графов,графовое обучение,обучение на основе графов
1941,graph-base method,طريقة قاعدة الرسم البياني,الأساليب المعتمدة على الرسوم البيانية,طريقة قائمة على الرسم البياني,基于图的方法,基于图的方法 (Graph-based method),基于图的方法,méthode basée sur un graphique,méthode basée sur les graphes,méthode basée sur le graphe,グラフベース法,グラフベースの方法,グラフベース法,метод на основе графов,метод на основе графов,метод на основе графа
1942,graph-base model,نموذج قاعدة الرسم البياني,نموذج مبني على الرسوم البيانية,نموذج مرتكز على الرسم البياني,基于图的模型,图形模型,基于图的模型,modèle basé sur un graphique,modèle basé sur un graphe,modèle à base de graphe,グラフベースモデル,グラフベースモデル,グラフベースモデル,графовая модель,модель на основе графов,графовая модель
1943,graph-base representation,تمثيل قاعدة الرسم البياني,التمثيل على أساس الرسوم البيانية,تمثيل قائم على الرسم البياني,基于图的表示,基于图的表示,基于图的表示,représentation graphique,représentation basée sur un graphe,représentation basée sur les graphes,グラフベースの表現,グラフベースの表現,グラフベース表現,представление на основе графа,графовое представление,график-представление
1944,graph-level task,مهمة على مستوى الرسم البياني,مهمة على مستوى الرسم البياني,مهمة على مستوى الرسم البياني,图级任务,图级任务,图级任务,tâche au niveau du graphique,tâche au niveau du graphe,tâche au niveau du graphe,グラフレベルのタスク,グラフレベルのタスク,グラフレベルタスク,задача уровня графа,задача на уровне графа,задача на уровне графа
1945,graphical model,نموذج رسومي,نموذج رسومي,نموذج بياني,图形模型,图形模型,图形模型,modèle graphique,modèle graphique,modèle graphique,グラフィカルモデル,- グラフィカルモデル,グラフィカルモデル,графическая модель,графическая модель,графический вероятностный вид
1946,graphlet,الجرافيت,منحنى الرسم,مقطع,图基元,图元,小子图,graphique,graphlet,sous-graphe,グラフレット,グラフレット,グラフレット,графлет,графлет,графлет
1947,graphlet kernel,نواة الجرافيت,نواة الرسم البياني,نواة الجرافليت,图基核,图核(kernel),小片段核,noyau de graphlet,noyau de graphlet,noyau graphlet,グラフレットカーネル,グラフレットカーネル,グラフレットカーネル,ядро графлета,графлет ядро,ядро графлет
1948,greedy,طماع,جشعية,جشع,贪婪的,"Greedy, LBP and TRW on the test set comprising 4952 images from PASCAL VOC 2007 dataset.', 'Therefore, the upper bound is equal to the lower bound. The branch-and-bound framework does not search for further, deeper branches. It will try to complete S c with or without a billboard and terminates after finishing the first iteration. Hence, BBS is slightly better than Greedy, but worse than LazyProbe on effectiveness.', 'Both M1 and MH drive down the error for a few",贪婪,cupide,glouton,glouton,よく深い,"""['5 および 3 つの近似手法（貪欲、LBP、TRW）を、PASCAL VOC 2007 データセットからの 4952 枚の画像で構成されるテストセットに適用した。', 'したがって、上限は下限と等しい。枝刈り探索フレームワークは、さらに深い枝を",貪欲法,жадный,Жадный,жадный
1949,greedy algorithm,خوارزمية الجشع,خوارزمية الجشع,خوارزمية جشعة,贪心算法,贪婪算法,贪心算法,algorithme gourmand,algorithme glouton,algorithme glouton,貪欲なアルゴリズム,貪欲アルゴリズム (tonyoku arugorizumu),貪欲アルゴリズム,жадный алгоритм,- Жадный алгоритм,жадный алгоритм
1950,greedy approach,النهج الجشع,النهج الطماع,طريقة الجشع,贪婪方法,贪婪算法,贪婪方法,approche gourmande,approche gloutonne,approche gloutonne,貪欲なアプローチ,貪欲法 (sokubaku-hou),貪欲アプローチ,жадный подход,жадный подход,жадный подход
1951,greedy decoding,فك التشفير الجشع,"الفك ""جريدي""",حفز الترميز,贪心解码,贪心解码,贪婪解码,décodage gourmand,décodage glouton,décodage glouton,貪欲なデコード,貪欲なデコーディング,貪欲(グリーディ)デコーディング,жадное декодирование,жадное декодирование,жадное декодирование
1952,greedy inference,الاستدلال الجشع,متسلسل الجشاء,استدلال جشع,贪心推理,贪婪推断,贪婪推理,inférence gourmande,inférence gourmande,inférence gloutonne,貪欲な推論,貪欲推論,貪欲的な推論,жадный вывод,жадное выводление,Жадный вывод
1953,greedy maximization,تعظيم الجشع,التكبير الجشع,تعظيم الطمع,贪心最大化,贪婪最大化,贪婪最大化,maximisation gourmande,maximisation vorace,maximisation gloutonne,貪欲な最大化,貪欲最大化,貪欲的最大化,жадная максимизация,жадной максимизации,жадная максимизация
1954,greedy method,طريقة الجشع,الطريقة الطماعة,طريقة جشعة,贪心法,贪心方法,贪婪方法,méthode gourmande,- Méthode gloutonne,méthode gloutonne,貪欲な方法,貪欲法,貪欲法,жадный метод,жадный метод,жадный метод
1955,greedy optimization,الأمثل الجشع,التحسين الجشع,تحسين جشع,贪心优化,贪婪优化,贪心优化,optimisation gourmande,optimisation gloutonne,optimisation gloutonne,貪欲な最適化,貪欲最適化,貪欲的最適化,жадная оптимизация,жадная оптимизация,жадная оптимизация
1956,greedy policy,سياسة الجشع,السياسة الطماعية,سياسة جشعة,贪婪政策,贪心策略,贪心策略,politique avide,politique avide,politique gourmande,貪欲な政策,貪欲方策,貪欲ポリシー,жадная политика,жадная стратегия,Жадная политика
1957,greedy search,البحث الجشع,البحث الجشع,البحث الجشع,贪心搜索,贪婪搜索,贪心搜索,recherche gourmande,recherche gloutonne,recherche gloutonne,貪欲な検索,貪欲探索,貪欲探索,жадный поиск,жадный поиск,жадный поиск
1958,greedy strategy,استراتيجية الجشع,استراتيجية الجشع,استراتيجية جشعة,贪婪策略,贪婪策略,贪心策略,stratégie gourmande,stratégie gourmande,stratégie gloutonne,貪欲な戦略,貪欲戦略,貪欲戦略,жадная стратегия,жадная стратегия,жадная стратегия
1959,grid cell,خلية الشبكة,خلية الشبكة,خلية الشبكة,网格单元,网格细胞,栅格细胞,cellule de grille,cellule en grille,cellule grille,グリッドセル,グリッド細胞,グリッド細胞,ячейка сетки,сетчатая клетка,ячейка сетки
1960,grid search,بحث الشبكة,بحث الشبكة,بحث الشبكة,网格搜索,网格搜索,网格搜索,recherche de grille,recherche en grille,recherche sur grille,グリッド検索,グリッドサーチ,グリッドサーチ,поиск по сетке,сеточный поиск,метод полного перебора
1961,grid-world,عالم الشبكة,عالم الشبكة,عالم الشبكة,网格世界,网格世界,网格世界,monde-grille,grille-monde,monde de grilles,グリッドワールド,グリッドワールド,グリッドワールド,сетчатый мир,сетка-мир,сетка миров
1962,ground atom,ذرة ارضية,الذرة الأساسية,ذرة أرضية,地面原子,基础原子,基原子,atome moulu,atome de base,atome de base,基底原子,グラウンドアトム,地面原子,основной атом,основной атом,основной атом
1963,ground set,مجموعة ارضية,مجموعة فرعية,مجموعة أساسية,地面设置,原始设定,基础集合,ensemble au sol,Ensemble de base,ensemble de base,グランドセット,グラウンドセット,基底集合,наземный набор,основное множество,основное множество
1964,ground truth label,تسمية الحقيقة الأرضية,علامة الحقيقة الأرضية,وصف حقيقي,地面实况标签,标准标签,真实标签,étiquette de vérité terrain,étiquette de vérité terrain,étiquette de vérité terrain,グラウンドトゥルースラベル,グラウンド トゥルース ラベル (ground truth label),正解ラベル,метка истинной истины,метка истинности данных,метка истины
1965,ground-truth box,صندوق الحقيقة الأرضية,مربع الحقيقة الأساسية,صندوق الحقيقة الأرضية,地面实况框,地面实况框,真实边界框,boîte de vérité terrain,boîte de vérité terrain,boîte réelle,グラウンドトゥルースボックス,正解ボックス (seikai bokkusu),正解ボックス,ящик с наземной правдой,коробка истинного положения,истинный ограничивающий блок
1966,grounded language learning,تعلم اللغة على الارض,تعلم اللغة المرتكزة,تعلم اللغة المتأصل,扎根语言学习,基于实际情境的语言学习,基于实体的语言学习,apprentissage des langues fondé sur la terre,Apprentissage de langage ancré,apprentissage de langage ancré,地に足の着いた言語学習,接地言語学習,現実に基づく言語学習,основательное изучение языка,обучение языку на основе основанных данных,Обоснованное обучение языку
1967,grounded supervision,الإشراف على الأرض,الإشراف المرتكز,إشراف مُرتكز,接地气的监督,基础监督,基于语境的监督,surveillance fondée,supervision ancrée,supervision ancrée,根拠のある監督,グラウンデッド・スーパーバイジョン,接地監督,обоснованный надзор,непосредственное обучение,наземное обучение
1968,group normalization,التطبيع الجماعي,تقييس المجموعة,تقنين المجموعة,群体标准化,组规范化,分组归一化,normalisation de groupe,normalisation de groupe,Normalisation de groupe,グループの正規化,グループ正規化,グループ正規化,групповая нормализация,Групповая нормализация,групповая нормализация
1969,group sparsity,تناثر المجموعة,التباعد الجماعي,التجمع النادر,群体稀疏性,组稀疏,群稀疏性,rareté du groupe,parseité de groupe,parcimonie de groupe,グループの疎性,- グループスパースネス,グループ疎性,разреженность группы,групповая разреженность,групповая разреженность
1970,gumbel noise,ضجيج غامبل,ضجيج غومبيل,ضوضاء جامبل,甘贝尔噪声,古贝尔噪音,贡布尔噪声,bruit de gomme,bruit de Gumbel,bruit de Gumbel,ガンベルノイズ,ガンベルノイズ (Gumbel noise),ガンベルノイズ,шум резинки,шум гумбеля,гумбелевский шум
1971,half-space,نصف المساحة,نصف المساحة,نصف فراغ,一半的空间,半空间,半空间,demi-espace,demi-espace,demi-espace,半角スペース,半空間 (hankūkan),半空間,полупространство,полупространство,полупространство
1972,hamiltonian Monte Carlo,هاميلتونيان مونتي كارلو,هاميلتوني مونتي كارلو,مونت كارلو الهاملتونية,哈密​​顿蒙特卡罗,哈密顿蒙特卡罗 (Hamiltonian Monte Carlo),哈密顿蒙特卡罗,Monte Carlo hamiltonien,Hamiltonien Monte Carlo,Monte Carlo hamiltonien,ハミルトニアン モンテカルロ法,ハミルトニアン・モンテカルロ,ハミルトニアンモンテカルロ,Гамильтониан Монте-Карло,Гамильтоновское Монте-Карло,гамильтонов Монте-Карло
1973,hamming distance,مسافة هامينغ,مسافة هامنغ,- المسافة الهامينج,汉明距离,汉明距离,海明距离,distance de frappe,- Distance de Hamming,distance de Hamming,ハミング距離,ハミング距離,ハミング距離,расстояние Хэмминга,расстояние Хэмминга,Расстояние Хэмминга
1974,hamming loss,خسارة هامينغ,- معدل هامينغ,خسارة هامنج,汉明损失,汉明损失,海明损失,perte de jambon,Perte de Hamming,perte de Hamming,ハミング損失,ハミング損失,ハミング損失,потеря Хэмминга,Потеря Хэмминга,потеря Хэмминга
1975,hand pose estimation,تقدير وضع اليد,تقدير وضع اليد,تقدير وضعية اليد,手部姿势估计,手部姿势估计,手姿态估计,estimation de la pose de la main,estimation de la pose de la main,estimation de la pose de la main,手の姿勢推定,手のポーズ推定 (Te no pōzu su-tei),手の姿勢推定,оценка позы руки,оценка позы руки,оценка позы руки
1976,hard attention,اهتمام صعب,الانتباه الثابت,تركيز صارم,努力关注,硬注意力,硬注意力,attention particulière,attention rigide,Attention dure,厳しい注意,ハードアテンション,ハードアテンション,пристальное внимание,жесткое внимание,жесткое внимание
1977,hash,التجزئة,تجزئة,تجزئة,散列,哈希,哈希,hacher,hachage,hachage,ハッシュ,ハッシュ,ハッシュ,хэш,= хеш χ t−1 G ( v,хеш-функция
1978,hash function,دالة تجزئة,دالة التجزئة,دالة التجزئة,哈希函数,哈希函数,哈希函数,fonction de hachage,fonction de hachage,fonction de hachage,ハッシュ関数,ハッシュ関数,ハッシュ関数,хэш-функция,хеш-функция,хэш-функция
1979,hash table,جدول التجزئة,جدول القيم المجزأة,جدول التجزئة,哈希表,哈希表,哈希表,table de hachage,table de hachage,table de hachage,ハッシュ表,ハッシュテーブル,ハッシュテーブル,хеш-таблица,хеш-таблица,хеш-таблица
1980,hashing algorithm,خوارزمية التجزئة,- تشفير الخوارزمية,خوارزمية التجزئة,散列算法,哈希算法,哈希算法,algorithme de hachage,algorithme de hachage,algorithme de hachage,ハッシュアルゴリズム,ハッシュアルゴリズム (hashu arugorizumu),ハッシュアルゴリズム,алгоритм хеширования,алгоритм хеширования,хеширующий алгоритм
1981,hate speech classifier,مصنف خطاب الكراهية,مصنف الخطاب الكراهية,مصنف خطاب الكراهية,仇恨言论分类器,仇恨言论分类器,仇恨言论分类器,classificateur de discours de haine,Classificateur de discours de haine,classificateur de discours haineux,ヘイトスピーチ分類器,ヘイトスピーチ分類器,差別的発言分類器,классификатор разжигания ненависти,классификатор ненавистной речи,классификатор языка ненависти
1982,hate speech detection,كشف خطاب الكراهية,الكشف عن خطاب الكراهية,الكشف عن خطاب الكراهية,仇恨言论检测,仇恨言论检测,仇恨言论检测,détection des discours de haine,- Détection de discours de haine,détection des discours haineux,ヘイトスピーチの検出,ヘイトスピーチ検出,憎悪表現検出,обнаружение разжигания ненависти,Определение ненавистнической речи,обнаружение языка ненависти
1983,head entity,كيان الرأس,الكيان الرئيسي,الكيان الرئيسي,头实体,- 头实体,头实体,entité principale,- Entité principale,entité principale,ヘッドエンティティ,ヘッドエンティティ,主体エンティティ,головное предприятие,главная сущность,головная сущность
1984,head word,كلمة الرأس,رأس الكلمة,الكلمة الرئيسة,中心词,头词,中心词,mot principal,mot tête,mot-tête,見出し語,ヘッドワード,中心語,главное слово,головное слово,вершинное слово
1985,heap structure,هيكل الكومة,هيكل الكومة,بنية الكومة,堆结构,堆结构,堆结构,structure de tas,structure de tas,Structure de tas,ヒープ構造,ヒープ構造,ヒープ構造,структура кучи,структура кучи,куча
1986,heatmap,خريطة الحرارة,- تباين الحرارة,خريطة الحرارة,热图,热度图,热力图,carte de chaleur,Carte de chaleur,carte thermique,ヒートマップ,ヒートマップ,ヒートマップ,Тепловая карта,карта интенсивности (heatmap),тепловая карта
1987,hedge algorithm,خوارزمية التحوط,خوارزمية التحوط,خوارزمية التحوط,对冲算法,对冲算法 (hedge algorithm),对冲算法,algorithme de couverture,algorithme de couverture,algorithme du hedge,ヘッジアルゴリズム,ヘッジアルゴリズム,ヘッジアルゴリズム,алгоритм хеджирования,алгоритм Hedge,алгоритм хеджирования
1988,hessian matrix,مصفوفة هسه,مصفوفة هيسيان,مصفوفة هسيان,粗麻布矩阵,海森矩阵,黑塞矩阵,matrice de hesse,matrice de Hessian,matrice hessienne,ヘシアン行列,ヘシアン行列 (Hessian matrix),ヘッセ行列,матрица гессеана,гессиановская матрица,матрица Гессе
1989,hessian-vector product,منتج ناقل هسه,ضرب هيسيان-متجه,ناتج متجه هيسيان,粗麻布向量积,黑塞矢量乘积,黑塞矩阵-向量乘积,produit vectoriel en toile de jute,produit du hessien-vecteur,produit hessien-vecteur,ヘシアンベクトル積,ヘッシアン-ベクトル積,ヘシアン・ベクトル積,произведение вектора гессеана,произведение гессиана на вектор,произведение гессиана на вектор
1990,heuristic algorithm,خوارزمية إرشادية,خوارزمية تكريرية,خوارزمية استكشافية,启发式算法,启发式算法,启发式算法,algorithme heuristique,Algorithme heuristique,algorithme heuristique,ヒューリスティックアルゴリズム,ヒューリスティックアルゴリズム,ヒューリスティックアルゴリズム,эвристический алгоритм,эвристический алгоритм,Эвристический алгоритм
1991,heuristic function,وظيفة ارشادية,وظيفة توجيهية,دالة إرشادية,启发式函数,启发函数,启发式函数,fonction heuristique,fonction heuristique,fonction heuristique,ヒューリスティック関数,"""[この論文では、我々はHC-Searchと呼ばれる構造化予測の新しいフレームワークについて研究しています。このフレームワークは従来の探索文献に密接に従います。鍵となるアイデアは、上記の各",ヒューリスティック関数,эвристическая функция,эвристическая функция,эвристическая функция
1992,heuristic search,البحث ارشادي,- مسح ذهني,بحث إرشادي,启发式搜索,启发式搜索,启发式搜索,recherche heuristique,recherche heuristique,recherche heuristique,ヒューリスティック検索,ヒューリスティック探索,発見的探索,эвристический поиск,эвристический поиск,эвристический поиск
1993,heuristic search algorithm,خوارزمية البحث ارشادي,- مفتاح البحث الحاذي العشوائي,حوار البحث التقريبي,启发式搜索算法,启发式搜索算法,启发式搜索算法,algorithme de recherche heuristique,algorithme de recherche heuristique,algorithme de recherche heuristique,ヒューリスティック検索アルゴリズム,ヒューリスティック探索アルゴリズム (Hyūrisutikku Tansaku Arugorizumu),ヒューリスティック探索アルゴリズム,эвристический алгоритм поиска,эвристический алгоритм поиска,Эвристический алгоритм поиска
1994,heuristic value,قيمة إرشادية,قيمة توجيهية,قيمة إرشادية,启发值,启发式价值,启发式值,valeur heuristique,valeur heuristique,valeur heuristique,ヒューリスティック値,ヒューリスティック値,ヒューリスティック価値,эвристическая ценность,эвристическое значение,эвристическое значение
1995,hidden Markov model,نموذج ماركوف المخفي,نموذج ماركوف الخفي,نموذج ماركوف المخفي,隐马尔可夫模型,隐马尔可夫模型,隐马尔可夫模型,modèle de Markov caché,modèle de Markov caché,modèle de Markov caché,隠れマルコフモデル,隠れマルコフモデル (Hidden Markov Model),隠れマルコフモデル,скрытая марковская модель,скрытая модель Маркова,скрытая марковская модель
1996,hidden dimension,البعد الخفي,- البُعد الخفي,البعد الخفي,隐藏维度,隐藏维度,隐藏维度,dimension cachée,dimension cachée,dimension cachée,隠された次元,隠れた次元 (kakureta jigen),潜在次元,скрытое измерение,скрытого измерения,скрытое измерение
1997,hidden dimension size,حجم البعد المخفي,حجم البعد الخفي,حجم البُعد المُخفي,隐藏尺寸大小,隐藏维度大小,隐层维度大小,taille des dimensions cachées,taille de la dimension cachée,Taille de dimension cachée,隠れた次元のサイズ,隠し次元サイズ,隠れ次元サイズ,размер скрытого измерения,размер скрытого измерения,размер скрытого слоя
1998,hidden dimensionality,الأبعاد الخفية,البُعد الخفي,نعومية مخفية,隐藏维度,隐藏维度,隐藏维度,dimensionnalité cachée,dimensionnalité cachée,dimensionnalité cachée,隠れた次元,隠れた次元数,隠れ次元数,скрытая размерность,скрытая размерность,скрытая размерность
1999,hidden embedding,التضمين الخفي,تضمين مخفي,تضمين مخفي,隐藏嵌入,隐藏嵌入,隐藏嵌入,intégration cachée,incorporation cachée,Représentation cachée,隠し埋め込み,隠れ埋め込み (hidden embedding),潜在埋め込み,скрытое встраивание,скрытые вложения,скрытое встраивание
2000,hidden feature,ميزة مخفية,السمة المخفية,ميزة مخفية,隐藏功能,隐藏特征,隐藏特征,fonctionnalité cachée,caractéristique cachée,caractéristique cachée,隠し機能,隠れた特徴,潜在特徴 (せんざいとくちょう),скрытая функция,скрытая функция,скрытый признак
2001,hidden layer,طبقة مخفية,الطبقة الخفية,طبقة مخفية,隐藏层,- 隐藏层,隐藏层,couche cachée,couche cachée,couche cachée,隠れ層,隠れ層 (Hidden Layer),隠れ層,скрытый слой,скрытый слой,скрытый слой
2002,hidden representation,التمثيل الخفي,التمثيل الخفي,التمثيل المُخفي,隐藏表示,隐藏表示,隐藏表示,représentation cachée,représentation cachée,représentation latente,隠された表現,隠れ表現,潜在表現,скрытое представление,скрытое представление,скрытое представление
2003,hidden size,الحجم المخفي,حجم مخفي,حجم المخفي,隐藏尺寸,隐藏大小,隐藏层大小,taille cachée,taille cachée,taille cachée,隠れたサイズ,隠れ層サイズ,隠れサイズ,скрытый размер,hidden size - размер скрытого состояния,скрытый размер
2004,hidden state,الدولة المخفية,الحالة الخفية,الحالة المخفية,隐藏状态,隐藏状态,隐藏状态,état caché,état caché,état caché,隠れた状態,隠れ状態 (hidden state),隠れ状態,скрытое состояние,скрытое состояние,скрытое состояние
2005,hidden state dimension,البعد الدولة المخفية,البُعد الخفي للحالة,بُعد الحالة المُخفية,隐藏状态维度,隐藏状态维度,隐藏状态维度,dimension d'état cachée,dimension de l'état caché,dimension d'état caché,隠れ状態の次元,隠れ状態の次元,隠れ状態次元,скрытое измерение состояния,скрытое измерение состояния,размерность скрытого состояния
2006,hidden state representation,تمثيل الدولة المخفية,التمثيل الحالة الخفية,تمثيل الحالة المخفية,隐藏状态表示,隐藏状态表示,隐藏状态表示,représentation d'état caché,- Représentation d'état caché,représentation de l'état caché,隠れた状態の表現,隠れ状態表現,隠れ状態表現,скрытое государственное представление,скрытое представление состояния,скрытое состояние представления
2007,hidden state vector,ناقلات الحالة المخفية,القيمة الخفية المتجهة,متجه الحالة المخفية,隐藏状态向量,隐藏状态向量,隐状态向量,vecteur d'état caché,vecteur d'état caché,vecteur d'état caché,隠れ状態ベクトル,隠れ状態ベクトル (hidden state vector),隠れ状態ベクトル,вектор скрытого состояния,вектор скрытого состояния,скрытый вектор состояния
2008,hidden unit,وحدة مخفية,وحدة مخفية,وحدة مخفية,隐藏单位,隐藏单元,隐藏单元,unité cachée,unité cachée,unité cachée,隠しユニット,隠れユニット (hidden unit),隠れユニット,скрытый блок,скрытая единица,скрытый узел
2009,hidden variable,المتغير المخفي,متغير مخفي,متغير مخفي,隐藏变量,隐藏变量,隐藏变量,variable cachée,variable cachée,variable cachée,隠し変数,- 隠れ変数 (Hidden Variable),潜在変数,скрытая переменная,скрытая переменная,скрытая переменная
2010,hierarchical agglomerative clustering,التجمعات التكتلية الهرمية,التجمع التسلسلي التسلسلي الهرمي,تجميع هرمي تراكمي,层次凝聚聚类,分层凝聚聚类,层次聚集clustering,regroupement agglomératif hiérarchique,regroupement hiérarchique agglomératif,Le clustering agglomératif hiérarchique,階層的凝集クラスタリング,階層的凝集クラスタリング,階層的凝集クラスタリング,иерархическая агломеративная кластеризация,Иерархическая агломеративная кластеризация,иерархическая агломеративная кластеризация
2011,hierarchical clustering,المجموعات الهرمية,التجميع الهرمي,تجميع هرمي,层次聚类,层次聚类,层次聚类,classification hiérarchique,regroupement hiérarchique,regroupement hiérarchique,階層的クラスタリング,階層的クラスタリング (Kaisō-teki clustering),階層的クラスタリング,иерархическая кластеризация,иерархическая кластеризация,иерархическая кластеризация
2012,hierarchical decoder,فك الترميز الهرمي,المُفسّر التسلسلي الهرمي,مُفَسِّر هرمي,分层解码器,分层解码器,分层解码器,décodeur hiérarchique,décodeur hiérarchique,décodeur hiérarchique,階層デコーダ,階層デコーダ,階層的デコーダ,иерархический декодер,иерархический декодер,иерархический декодер
2013,hierarchical feature,الميزة الهرمية,الميزات التسلسلية الهرمية,السمة الهرمية,层次特征,分层特征,层次特征,caractéristique hiérarchique,caractéristique hiérarchique,caractéristique hiérarchique,階層機能,階層的な特徴,階層的特徴,иерархическая функция,иерархическая характеристика,иерархические признаки
2014,hierarchical inference,الاستدلال الهرمي,الاستدلال التسلسلي,الاستدلال الهرمي,层次推理,层次推断,分层推理,inférence hiérarchique,inférence hiérarchique,inférence hiérarchique,階層的推論,階層推論,階層的推論,иерархический вывод,иерархический вывод,иерархический вывод
2015,hierarchical method,الطريقة الهرمية,الأساليب الهرمية,الطريقة الهرمية,层次法,分层方法,层次方法,méthode hiérarchique,- Méthode hiérarchique,méthode hiérarchique,階層的メソッド,階層的手法,階層的手法,иерархический метод,иерархический метод,иерархический метод
2016,hierarchical model,النموذج الهرمي,النموذج الهرمي,نموذج هرمي,层次模型,层次模型,分层模型,modèle hiérarchique,modèle hiérarchique,modèle hiérarchique,階層モデル,階層モデル,階層モデル,иерархическая модель,иерархическая модель,иерархическая модель
2017,hierarchical reinforcement learning,التعلم التعزيز الهرمي,التعلم التعزيزي التسلسلي الهرمي,تعلم تعزيزي هرمي,分层强化学习,分级强化学习,层次强化学习,apprentissage par renforcement hiérarchique,apprentissage par renforcement hiérarchique,apprentissage par renforcement hiérarchique,階層型強化学習,階層型強化学習,階層強化学習,иерархическое обучение с подкреплением,Иерархическое обучение с подкреплением,иерархическое обучение с подкреплением
2018,hierarchical representation,التمثيل الهرمي,التمثيل التسلسلي الهرمي,التمثيل الهرمي,层次表示法,层次表示,分层表示,représentation hiérarchique,représentation hiérarchique,représentation hiérarchique,階層表現,階層的表現,階層的表現,иерархическое представление,иерархическое представление,иерархическое представление
2019,hierarchical structure,الهيكل الهرمي,الهيكل التسلسليHierarchical Structure,بنية هرمية,层次结构,层次结构,层次结构,structure hiérarchique,structure hiérarchique,structure hiérarchique,階層構造,階層構造 (かいそうこうぞう),階層構造,иерархическая структура,иерархическая структура,иерархическая структура
2020,hierarchical topic model,نموذج الموضوع الهرمي,نموذج مواضيع تسلسلي,نموذج مواضيع هرمي,层次主题模型,分层主题模型 (Hierarchical Topic Model),层次主题模型,modèle de sujet hiérarchique,modèle de sujet hiérarchique,modèle de sujet hiérarchique,階層トピックモデル,階層トピックモデル,階層的トピックモデル,иерархическая тематическая модель,иерархическая тематическая модель,иерархическая тематическая модель
2021,hierarchy,تَسَلسُل,تسلسل هرمي,تسلسل هرمي,等级制度,分层结构,层级结构,hiérarchie,hiérarchie,hiérarchie,階層,階層 (かいそう),階層構造,иерархия,иерархия,иерархия
2022,high-dimensional datum,مسند عالي الأبعاد,بيانات عالية الأبعاد,بيانات عالية الأبعاد,高维数据,高维数据,高维数据,donnée de grande dimension,donnée de haute dimension,donnée de grande dimension,高次元データ,高次元データ,高次元データ,данные высокой размерности,Высокоразмерные данные,высокомерные данные
2023,high-dimensional space,مساحة عالية الأبعاد,المساحة العالية البعدية,فضاء عالي الأبعاد,高维空间,高维空间,高维空间,espace de grande dimension,espace de grande dimension,espace de grande dimension,高次元空間,高次元空間,高次元空間,многомерное пространство,- Высокомерное пространство,высокомерное пространство
2024,high-dimensionality,عالية الأبعاد,عالية الأبعادية,عالي البُعد,高维,高维度,高维性,haute dimensionnalité,haute dimensionalité,haute dimensionnalité,高次元性,高次元性,高次元性,многомерность,- Высокоразмерность,высокая размерность
2025,high-order feature,ميزة الترتيب العالي,ميزة من الدرجة العالية,طُرِز الرُّتَب العُليا,高阶特征,高阶特征,高阶特征,fonctionnalité d'ordre élevé,caractéristique d'ordre élevé,Caractéristique d'ordre supérieur,高次の特徴,高次特徴,高次特徴,функция высшего порядка,высокоуровневая особенность,высокопорядковый признак
2026,high-order model,نموذج عالي الترتيب,نموذج من الدرجة العالية,نموذج رتبة عالية,高阶模型,高阶模型,高阶模型,modèle d'ordre supérieur,modèle d'ordre élevé,modèle d'ordre supérieur,上位モデル,高次モデル,高次モデル,модель высшего порядка,высокоуровневая модель,высокопорядковая модель
2027,hill-climbing,تسلق التل,تسلق التل,تسلق التل,爬山,爬山算法,爬山法,escalade,montée de colline,escalade gloutonne,山登り,山登り,山登り法,скалолазание,подъем по холмам,метод восхождения на холм
2028,hinge loss,فقدان المفصلة,- متغير الخسارة المفصلية,خسارة المفصلة,铰链损失,铰链损失,合页损失,perte de charnière,perte de charnière,perte de porte,ヒンジの損失,ヒンジ損失,ヒンジ損失,потеря шарнира,функция потерь шарнира,потеря петли
2029,hinge loss function,وظيفة فقدان المفصلة,وظيفة الخسارة المفصلية,وظيفة خسارة المفصلة,铰链损失函数,铰链损失函数,铰链损失函数,fonction de perte de charnière,- Fonction de perte de charnière,fonction de perte à charnière,ヒンジ損失関数,ヒンジ損失関数 (hinge loss function),ヒンジ損失関数,функция потерь шарнира,Функция потерь с шарниром,функция потерь hinge
2030,histogram of orient gradient,رسم بياني للتدرج الشرقي,الهستوغرام للتدرجات الموجهة,مُساوي التوجه,东方梯度直方图,梯度直方图,梯度方向直方图,histogramme du gradient d'orientation,histogramme des gradients orientés,histogramme de gradients orientés,方向勾配のヒストグラム,勾配ヒストグラム,傾向勾配ヒストグラム,гистограмма восточного градиента,гистограмма ориентированных градиентов,гистограмма ориентированных градиентов
2031,hold-out data,بيانات الاحتجاز,بيانات الاحتفاظ,بيانات محجوزة,保留数据,保留数据,留存数据,données à retenir,données de réserve,données réservées,ホールドアウトデータ,保留データ,検証データ,данные о задержке,данные для проверки,удерживаемые данные
2032,homogeneous coordinate,إحداثيات متجانسة,إحداثي موحد,إحداثيات متجانسة,齐次坐标,齐次坐标,齐次坐标,coordonnée homogène,coordonnée homogène,coordonnées homogènes,同次座標,同次座標,同次座標,однородная координата,однородная координата,однородные координаты
2033,homographie,هوموغرافيا,التطابق,تصوير متناسق,同形异义词,同射变换 (homography),同构,homographie,homographie,homographie,同音異義語,"""['パラメータを移動平面でシーンとして表現することは、各平面に割り当てられたピクセル位置を画像間で簡単に変換したり、対応する同次変換を使用して3D空間にマッピングしたりするのに便利です。以下で定義するエネル",射影変換,гомография,гомография,гомография
2034,homography,التجانس,"\n H JI (π) -1 ∼ H IJ (π) -يجب فرض القيود الإضافية P i,3θ>",تصوير متطابق,单应性,单应性,同构,homographie,homographie,homographie,ホモグラフィー,ホモグラフィ (homography),同形写像,гомография,гомография,гомография
2035,homography matrix,مصفوفة التجانس,مصفوفة التطبيقية,مصفوفة التجانس,单应性矩阵,单应矩阵,单应矩阵,matrice d'homographie,- Matrice d'homographie,matrice d'homographie,ホモグラフィー行列,ホモグラフィ行列,同次写像行列,матрица гомографии,матрица гомографии,матрица гомографии
2036,homomorphism,التماثل,تشبه المورفيسم,مورفزم متجانس,同态,同态映射 (homomorphism),同态,homomorphisme,homomorphisme,homomorphisme,準同型性,ホモモルフィズム,同型写像,гомоморфизм,гомоморфизм,гомоморфизм
2037,horn theory,نظرية القرن,نظرية القرون,نظرية القرون,号角理论,角理论,霞恩理论,théorie du cor,théorie des cornes,théorie de Horn,ホーン理論,ホーン理論,角理論,теория рога,"\n', 'Однако эта техника не работает для теорий рогов, если одно из следствий q → χ, χ → q не является роговым. В пр",теория рогов
2038,huber loss,خسارة هوبر,خسارة هوبر,خسارة هوبر,胡伯损失,胡贝损失,哈伯损失,perte de Huber,perte de Huber,perte de Huber,ヒューバー損失,ヒューバー損失,ヒューバー損失,потеря Хубера,Потеря Хьюбера,функция потерь Хубера
2039,human annotation,شرح بشري,التعليق البشري,التدقيق البشري,人工注释,人工标注 (Ren2 Gong1 Biao1 Zhu4),人工标注,annotation humaine,- Annotation humaine,annotation humaine,人間による注釈,人間アノテーション (ningen anotēshon),人手による注釈,человеческие аннотации,человеческая аннотация,аннотация человека
2040,human pose,تشكل الإنسان,وضع الإنسان,وضع الإنسان,人体姿势,人体姿势,人体姿势,posture humaine,pose humaine,pose humaine,人間のポーズ,人間のポーズ,人体姿勢,поза человека,поза человека,поза человека
2041,human pose estimation,تقدير وضعية الإنسان,تقدير وضع الإنسان,تقدير وضعية الإنسان,人体姿势估计,人体姿势估计,人体姿态估计,estimation de la pose humaine,estimation de la pose humaine,estimation de la pose humaine,人間の姿勢推定,人間のポーズ推定 (ningen no pōzu suitei),人体姿勢推定,оценка позы человека,оценка позы человека,оценка позы человека
2042,human-computer interaction,تفاعل الإنسان والحاسوب,تفاعل الإنسان مع الحاسوب,تفاعل الإنسان والحاسوب,人机交互,人机交互,人机交互,interaction homme machine,Interaction humain-ordinateur,interaction homme-machine,人間とコンピュータの相互作用,ヒューマンコンピュータインタラクション (Human-Computer Interaction),ヒューマンコンピュータインタラクション,взаимодействие человека с компьютером,взаимодействие человека с компьютером,взаимодействие человека и компьютера
2043,human-in-the-loop,الإنسان في الحلقة,الإنسان في الحلقة,مشاركة بشرية في العملية,人在回路,人机协同 (Human-in-the-loop),人机协作,humain dans la boucle,humain-dans-la-boucle,humain dans la boucle,人間関係者,人間インザループ,ヒューマンインザループ,человек в курсе,человек в петле,человек в цикле
2044,human-machine interaction,التفاعل بين الإنسان والآلة,تفاعل الإنسان مع الآلة,تفاعل الإنسان والآلة,人机交互,人机交互,人机交互,interaction homme-machine,- Interaction homme-machine,interaction homme-machine,人間と機械の相互作用,人間と機械の相互作用 (Ningen to kikai no sōgo-sōsa),人機インタラクション,человеко-машинное взаимодействие,Взаимодействие человека с машиной,взаимодействие человека и машины
2045,hungarian loss,خسارة المجرة,الخسارة المجرية,خسارة هنغارية,匈牙利损失,匈牙利损失,匈牙利损失,perte hongroise,perte hongroise,perte hongroise,ハンガリーの損失,ハンガリー損失,ハンガリアン損失,венгерская потеря,венгерская потеря,венгерский расход
2046,hybrid model,نموذج هجين,النموذج المختلط,نموذج هجين,混合模型,混合模型,混合模型,modèle hybride,modèle hybride,modèle hybride,ハイブリッドモデル,ハイブリッドモデル,ハイブリッドモデル,гибридная модель,гибридная модель,гибридная модель
2047,hyper-graph,رسم بياني مفرط,الرسم البياني الهايبرية,رسم بياني فائق,超图,超图,超图,hypergraphe,hyper-graphe,hyper-graphe,ハイパーグラフ,ハイパーグラフ,超グラフ,гиперграф,гиперграф,гиперграф
2048,hyper-parameter tuning,ضبط المعلمة المفرطة,ضبط المعلمات الفائقة,ضبط فائق المعلمة,超参数调整,超参数调整,超参数调优,réglage des hyper-paramètres,réglage des hyperparamètres,ajustement des hyper-paramètres,ハイパーパラメータ調整,ハイパーパラメーター調整,ハイパーパラメータチューニング,настройка гиперпараметров,настройка гиперпараметров,Настройка гиперпараметров
2049,hyperband,النطاق الفائق,الحزمة الزائدة,تقنية هايبرباند,超频带,超频带,超带,hyperbande,hyperband,Hyperband,ハイパーバンド,ハイパーバンド,ハイパーバンド,гиперполоса,Гипердиапазон,гипербэнд
2050,hyperbolic space,مساحة زائدية,المساحة الهيبربولية,الفضاء الهايبربولي,双曲空间,双曲空间,双曲空间,espace hyperbolique,espace hyperbolique,espace hyperbolique,双曲空間,双曲空間,ハイパボリック空間,гиперболическое пространство,гиперболическое пространство,гиперболическое пространство
2051,hyperedge,مفرط الحافة,حافة فائقة,حافة فائقة,超边缘,超边,超边,hyperbord,hyperarête,hyperarête,ハイパーエッジ,ハイパーエッジ,超過辺,гиперкрай,гиперребро,гиперребро
2052,hypernym,hypernym,فوق تصنيفي,مصطلح أعلى,上位词,上位词,上位词,hyperonyme,hypernyme,hyperonyme,上位名称,上位語,上位語,гипероним,гипероним,гиперним
2053,hypernymy,hypernymy,- التفوقية,علاقة الارتباط العام,上位词,上义,上位词关系,hypernymie,hypernymie,hypernymie,誇大表現,上位概念 (hypernymy),上位語関係,гипернимия,гиперонимия,гипернимия
2054,hyperparameter optimization,تحسين المعلمة الفائقة,أمثلة ترجمات الألغام المتعددة,تحسين المعلمات الفائقة,超参数优化,超参数优化,超参数优化,optimisation des hyperparamètres,optimisation des hyperparamètres,optimisation des hyperparamètres,ハイパーパラメータの最適化,ハイパーパラメータの最適化,超パラメータ最適化,оптимизация гиперпараметров,оптимизация гиперпараметров,оптимизация гиперпараметров
2055,hyperparameter search,بحث المعلمة الفائقة,البحث عن المعلمات الفائقة,البحث عن معلمات فائقة,超参数搜索,超参数搜索,超参数搜索,recherche d'hyperparamètres,recherche d'hyperparamètres,recherche d'hyperparamètres,ハイパーパラメータ検索,ハイパーパラメーター探索,ハイパーパラメータ探索,поиск по гиперпараметру,поиск гиперпараметров,поиск гиперпараметров
2056,hyperparameter selection,اختيار المعلمة الفائقة,- تحديد المعلمة الفائقة,اختيار المُعلمات العليا,超参数选择,超参数选择,超参数选择,sélection d'hyperparamètres,sélection d'hyperparamètres,sélection des hyperparamètres,ハイパーパラメータの選択,ハイパーパラメーター選択,ハイパーパラメータ選択,выбор гиперпараметра,выбор гиперпараметров,подбор гиперпараметров
2057,hyperparameter setting,إعداد المعلمة الفائقة,- التعيينات فوق المعلمة,ضبط الهايبرمترات,超参数设置,超参数设置,超参数设置,réglage des hyperparamètres,réglage des hyperparamètres,paramètres hypermétriques,ハイパーパラメータ設定,ハイパーパラメーター設定,ハイパーパラメータ設定,настройка гиперпараметра,настройка гиперпараметров,настройка гиперпараметров
2058,hyperparameter space,مساحة المعلمة الفائقة,مجال معلمات التكيف,مجال البارامترات الفائقة,超参数空间,超参数空间,超参数空间,espace d'hyperparamètres,- Espace d'hyperparamètres,espace des hyperparamètres,ハイパーパラメータ空間,ハイパーパラメータ空間,ハイパーパラメータ空間,пространство гиперпараметров,пространство гиперпараметров,пространство гиперпараметров
2059,hyperplane,طائرة مفرطة,المستوى الفضائي الفائق,مستوى فائق,超平面,超平面,超平面,hyperplan,hyperplan,hyperplan,超平面,超平面,超平面,гиперплоскость,гиперплоскость,гиперплоскость
2060,hyperprior,فرط السابقة,هايبربايريور,معامل تغلب,超先验,超先验,超级先验,hyperprieur,hyperprior,hyperprior,ハイパープリア,ハイパープライオール,超パラメータ分布,гиперприорный,гипераприор,гиперпараметр
2061,hyponym,هيفونيم,تحت النوع,مرتبط,下位词,上位词,下位词,hyponyme,hyponyme,hyponyme,下名,下位語 (かいご),下位語,гипоним,гипоним,гипоним
2062,hyponymy,com.hyponymy,تفضيل النوعية,تَرَادُف,上下位关系,上下义关系 (hyponymy),下位关系,hyponymie,hyponymie,hyponymie,内名,下位語関係 (hyponymy),下位概念関係,гипонимия,гипонимия,гипонимия
2063,hypothesis class,فئة الفرضية,فصيلة الفرضية,فئة الفرضية,假设类,假设类,假设类,classe d'hypothèse,classe d'hypothèses,classe d'hypothèses,仮説クラス,仮説クラス,仮説クラス,класс гипотез,класс гипотез,гипотетический класс
2064,hypothesis set,مجموعة الفرضيات,مجموعة فرضية,مجموعة الفرضيات,假设集,假设集,假设集,ensemble d'hypothèses,Ensemble d'hypothèses,ensemble d'hypothèses,仮説セット,仮説セット,仮説集合,набор гипотез,набор гипотез,гипотетический набор
2065,hypothesis space,مساحة الفرضية,مجال الافتراضات,فضاء الفرضية,假设空间,假设空间,假设空间,espace d'hypothèse,espace d'hypothèses,espace d'hypothèses,仮説空間,仮説空間,仮説空間,пространство гипотез,пространство гипотез,пространство гипотез
2066,hypothesis test,اختبار الفرضية,اختبار الفرضية,اختبار الفرضية,假设检验,假设检验,假设检验,test d'hypothèse,test d'hypothèse,test d'hypothèse,仮説検定,仮説検定 (kisetsu kentei),仮説検定,проверка гипотезы,гипотезный тест,проверка гипотезы
2067,i.i.d,معرف الهوية,مستقلة وموزعة بشكل متساوٍ,انمطة مستقلة ومتوزعة بشكل متساو,内径,i.i.d.,独立同分布 (dú lì tóng fēn pù),je.i.d,i.i.d (indépendantes et identiquement distribuées),i.i.d = indépendantes et identiquement distribuées,i.i.d,独立同分布(Independent Identically Distributed),i.i.d. は独立同一分布 (dokuritsu dōitsubunpu) の略語です。,я.и.д.,i.i.d - н.о.р.,независимые и одинаково распределенные
2068,i.i.d. sample,معرف الهوية عينة,- تحليل i.i.d.,عينة مستقلة متساوية التوزيع,i.i.d.样本,独立同分布样本,独立同分布样本,je.i.d. échantillon,échantillon i.i.d.,échantillon i.i.d.,i.i.d.サンプル,独立同一分布サンプル,無相関かつ同一分布のサンプル,я и.д. образец,i.i.d. выборка,независимые и одинаково распределенные выборки
2069,idempotent,عاجز,"""إلا إذا كان C * الحد الأقصى العالمي ، يجب أن نتمكن من تحقيق تحسينات إضافية. ولكن إذا كانت L متجانسة (وتم تشغيلها حتى الاقتراب) ثم L (L (C)) = L (C). بالنظر إلى C و L D فق",متطابق,幂等的,幂等,幺等的,idempotent,idempotent,idempotente,冪等,冪等性,冪等,идемпотент,идемпотентный,идемпотентный
2070,identity function,تطابق وظيفي,وظيفة الهوية,دالة الهوية,恒等函数,身份函数,恒等函数,fonction d'identité,fonction d'identité,fonction identité,恒等関数,同一関数 (identity function),恒等関数,функция идентификации,функция идентичности,тождественная функция
2071,identity mapping,رسم خرائط الهوية,تعيين الهوية,تخطيط الهوية,恒等映射,身份映射,恒等映射,cartographie d'identité,mapping d'identité,mappage identité,アイデンティティマッピング,アイデンティティマッピング,同一マッピング,сопоставление идентичности,отображение идентичности,Отображение тождества
2072,identity matrix,مصفوفة الهوية,مصفوفة الهوية,مصفوفة الوحدة,单位矩阵,恒等矩阵,单位矩阵,matrice d'identité,matrice identité,matrice identité,単位行列,単位行列 (たんいぎょうれつ),単位行列,единичная матрица,единичная матрица,единичная матрица
2073,identity transformation,تحول الهوية,تحويل الهوية,تحويل الهوية,身份转变,身份变换,单位变换,transformation de l'identité,- Transformation d'identité,transformation identité,アイデンティティ変換,アイデンティティ変換,同一変換,трансформация личности,трансформация идентичности,тождественное преобразование
2074,image analysis,تحليل الصور,تحليل الصور,تحليل الصور,图像分析,图像分析,图像分析,l'analyse d'image,- Analyse d'image,analyse d'images,画像解析,画像解析,画像解析,анализ изображений,анализ изображений,анализ изображений
2075,image captioning,التعليق على الصورة,وصف الصورة,تعليق الصور,图像字幕,图像字幕生成,图像描述,sous-titrage d'image,légende d'image,légende d'image,画像のキャプション,画像キャプション付け (gazo kyapushon tsuke),画像キャプショニング,подпись к изображению,описание изображения,фотоподписывание
2076,image classification,تصنيف الصورة,تصنيف الصور,تصنيف الصور,图像分类,图像分类,图像分类,classement des images,Classification d'images,classification d'images,画像分類,画像分類 (gazou bunrui),画像分類,классификация изображений,классификация изображений,классификация изображений
2077,image compression,ضغط الصورة,ضغط الصورة,ضغط الصورة,图像压缩,图像压缩 (Image Compression),图像压缩,compression d'images,compression d'image,compression d'image,画像圧縮,画像圧縮 (がぞうあっしゅく),画像圧縮,сжатие изображений,сжатие изображения,сжатие изображений
2078,image denoise,تقليل الضوضاء الصورة,تنقية الصورة,إزالة التشويش من الصورة,图像去噪,图像去噪,图像去噪,débruitage de l'image,débruitage d'image,Débruitage d'image,画像のノイズ除去,画像のノイズ除去,画像ノイズ除去,шумоподавление изображения,обработка изображения,шумоподавление изображения
2079,image diffusion model,نموذج انتشار الصورة,نموذج انتشار الصور,نموذج انتشار الصورة,图像扩散模型,图像扩散模型 (image diffusion model),图像扩散模型,modèle de diffusion d'images,- Modèle de diffusion d'image,modèle de diffusion d'images,画像拡散モデル,イメージ拡散モデル,イメージ拡散モデル,модель диффузии изображений,модель диффузии изображения,модель диффузии изображений
2080,image embedding,تضمين الصورة,تضمين الصورة,تضمين الصورة,图像嵌入,图像嵌入,图像嵌入,intégration d'images,intégration d'image,représentation d'image,画像の埋め込み,画像埋め込み,画像埋め込み,встраивание изображений,вложение изображения,вложение изображения
2081,image encoder,تشفير الصورة,مشفر الصور,مُرمِّز الصورة,图像编码器,图像编码器,图像编码器,encodeur d'images,encodeur d'image,encodeur d'images,画像エンコーダ,画像エンコーダ,画像エンコーダ,кодер изображений,кодировщик изображения,кодировщик изображений
2082,image feature,ميزة الصورة,ميزة الصورة,ميزة الصورة,图像特征,图像特征 (Image feature),图像特征,fonctionnalité d'image,caractéristiques de l'image,Caractéristique d'image,画像の特徴,画像特徴,画像特徴,функция изображения,признак изображения,признаки изображения
2083,image generation,توليد الصورة,توليد الصور,توليد الصور,图像生成,图像生成,图像生成,génération d'images,génération d'images,génération d'images,画像生成,画像生成,画像生成,генерация изображения,генерация изображения,генерация изображений
2084,image inpainting,الصورة في الرسم,تعبئة الصورة,ملء الصور,图像修复,图像修复,图像修复,peinture d'image,inpainting d'image,inpeinture d'images,画像修復,画像修復 (がぞうしゅうふく),画像インペインティング,изображение,заполнение изображения,восстановление изображений
2085,image patch,تصحيح الصورة,صورة مجزأة,قطعة الصورة,图像补丁,图像块,图像块,patch d'image,patch d'image,portion d'image,画像パッチ,イメージパッチ (Imēji patchi),画像パッチ,патч изображения,изображение патч,изображение патча
2086,image plane,طائرة الصورة,مستوى الصورة,مستوى الصورة,像平面,图像平面,像平面,plan image,- Plan d'image,plan image,イメージプレーン,画像平面,画像平面,плоскость изображения,плоскость изображения,плоскость изображения
2087,image processing,معالجة الصورة,معالجة الصور,معالجة الصور,图像处理,图像处理,图像处理,traitement d'image,traitement d'images,traitement d'image,画像処理,画像処理,画像処理,Обработка изображения,обработка изображений,обработка изображений
2088,image pyramid,الهرم الصورة,هرم الصور,هرم الصورة,图像金字塔,图像金字塔,图像金字塔,pyramide d'images,pyramide d'images,pyramide d'images,画像ピラミッド,画像ピラミッド,画像ピラミッド,Пирамида изображений,пирамида изображений,пирамида изображений
2089,image recognition,التعرف على الصور,التعرف على الصور,التعرف على الصور,图像识别,图像识别 (Image Recognition),图像识别,reconnaissance d'images,reconnaissance d'images,reconnaissance d'images,画像認識,画像認識 (がぞうにんしき),画像認識,распознавание изображений,распознавание изображений,распознавание изображений
2090,image representation,تمثيل الصورة,تمثيل الصورة,تمثيل الصورة,图像表示,图像表示,图像表示,représentation d'images,représentation d'image,représentation d'image,画像表現,画像表現 (がぞうひょうげん),画像表現,представление изображения,изображение представление,представление изображения
2091,image restoration,استعادة الصورة,استعادة الصورة,إستعادة الصورة,图像修复,图像恢复,图像恢复,restauration d'images,restauration d'image,restauration d'image,画像修復,イメージの修復 (Imēji no shūfuku),画像復元,восстановление изображения,восстановление изображения,восстановление изображения
2092,image segmentation,تقطيع الصورة,تقسيم الصورة,تجزئة الصورة,图像分割,图像分割,图像分割,segmentation d'images,Segmentation d'image,segmentation d'image,画像のセグメンテーション,画像セグメンテーション,画像セグメンテーション,сегментация изображений,сегментация изображения,сегментация изображения
2093,image super-resolution,صورة فائقة الدقة,دقة الصورة الفائقة,تحسين دقة الصورة,图像超分辨率,图像超分辨率,图像超分辨率,image super-résolution,super-résolution d'image,super-résolution d'image,画像の超解像度,画像超解像度,画像超解像度化 (gazō chō kairyōdo-ka),изображение сверхвысокого разрешения,повышение разрешения изображения,сверхразрешение изображения
2094,image synthesis,تركيب الصورة,تركيب الصورة,تركيب الصور,图像合成,图像合成,图像合成,synthèse d'images,synthèse d'images,synthèse d'images,画像合成,画像合成,画像合成,синтез изображений,синтез изображений,синтез изображений
2095,image translation,ترجمة الصورة,ترجمة الصورة,ترجمة الصور,图像翻译,图像翻译,图像翻译,traduction d'images,traduction d'image,traduction d'image,画像翻訳,画像翻訳 (がぞうほんやく),画像変換,перевод изображений,перевод изображений,изображение перевода
2096,image-base rendering,تقديم قاعدة الصورة,التقديم القائم على الصورة,تصوير قائم على الصورة,基于图像的渲染,基于图像的渲染 (image-based rendering),基于图像的渲染,rendu à base d'image,rendu basé sur l'image,rendu basé sur l'image,イメージベースのレンダリング,画像ベースレンダリング,イメージベースレンダリング,рендеринг на основе изображения,рендеринг на основе изображений,Рендеринг на основе изображений
2097,image-text pre-training,التدريب المسبق على الصورة والنص,التدريب المسبق على الصور والنصوص,التدريب المسبق للنص والصورة,图文预训练,图文预训练,图像文本预训练,pré-formation image-texte,pré-entraînement image-texte,pré-entraînement image-texte,画像テキストの事前トレーニング,画像テキスト事前学習,画像・テキスト事前学習,предварительное обучение изображения и текста,предварительное обучение изображений и текста,предварительная подготовка изображений и текстов
2098,image-to-image translation,الترجمة من صورة إلى صورة,ترجمة الصورة إلى الصورة,ترجمة الصورة إلى صورة,图像到图像的翻译,图像到图像的转换,图像到图像翻译,traduction d'image à image,traduction d'image en image,traduction d'image à image,画像から画像への変換,画像対画像変換 (image-to-image translation),画像から画像への変換,перевод изображения в изображение,перевод изображения в изображение,перевод изображения в изображение
2099,imitation learning,التعلم بالتقليد,تعلم المحاكاة,حفظ تقليدي,模仿学习,模仿学习,模仿学习,apprentissage par imitation,apprentissage par imitation,apprentissage par imitation,模倣学習,模倣学習,模倣学習,имитационное обучение,имитационное обучение,подражательное обучение
2100,immediate consequence operator,عامل النتيجة المباشرة,عامل النتيجة الفورية,معالج النتيجة المباشرة,直接后果运算符,直接后果算子 (immediate consequence operator),直接后果算子,opérateur de conséquence immédiate,opérateur de conséquence immédiate,opérateur de conséquence immédiate,即結果演算子,即時帰結演算子 (Sokujiki kiketsu enzanshi),即時帰結演算子,оператор немедленного последствия,оператор немедленного следствия,оператор непосредственного вывода
2101,imperfect information,معلومات غير كاملة,معلومات غير كاملة,معلومات غير كاملة,不完善的信息,不完全信息,不完全信息,informations imparfaites,information imparfaite,information imparfaite,不完全な情報,情報の不完全さ,不完全情報,несовершенная информация,неполная информация,неполная информация
2102,implicit differentiation,الاشتقاق الضمني,التفاضل الضمني,التفاضل الضمني,隐分化,隐式微分,隐式微分,Différenciation implicite,différenciation implicite,différentiation implicite,暗黙的な微分,暗黙の微分 (Implicit Differentiation),陰的微分,неявное дифференцирование,Неявное дифференцирование,неявное дифференцирование
2103,implicit function,وظيفة ضمنية,وظيفة ضمنية,وظيفة ضمنية,隐函数,隐式函数,隐式函数,fonction implicite,fonction implicite,Fonction implicite,暗黙的な関数,暗黙の関数,暗黙の関数,неявная функция,неявная функция,неявная функция
2104,implicit representation,التمثيل الضمني,التمثيل الضمني,تمثيل ضمني,隐式表示,隐式表示,隐式表示,représentation implicite,représentation implicite,Représentation implicite,暗黙的な表現,暗黙の表現,暗黙的表現,неявное представление,неявное представление,Неявное представление
2105,implicit surface,السطح الضمني,سطح ضمني,سطح ضمني,隐式表面,隐式曲面,隐式曲面,surface implicite,surface implicite,surface implicite,暗黙的な曲面,暗黙の表面,陰関数表面,неявная поверхность,неявная поверхность,неявная поверхность
2106,importance sampling,أخذ العينات ذات الأهمية,عينة الترجيح,أخذ العينات الأهمية,重要性抽样,重要性采样,重要性采样,échantillonnage d'importance,échantillonnage d'importance,échantillonnage d'importance,重要度のサンプリング,重要度サンプリング,重要性サンプリング,выборка по важности,важность выборки,Выборка по важности
2107,importance sampling estimator,مقدر أهمية العينات,مقدر أهمية العينة,مقدر أخذ العينات الهامة,重要性抽样估计器,重要性抽样估计器,重要性采样估计器,estimateur d'échantillonnage d'importance,estimateur d'échantillonnage d'importance,estimateur par échantillonnage préférentiel,重要度サンプリング推定器,重要度サンプリング推定子,重要サンプリング推定量,оценщик выборки важности,Оценщик важности выборки,оценщик на основе выборки по важности
2108,importance weight,وزن الأهمية,الوزن الأساسي,وزن الأهمية,重要性权重,重要性权重,重要性权重,importance poids,poids d'importance,poids d'importance,重要度の重み,重要度重み (juuyoudo omomi),重み付け係数,вес важности,вес важности,важность веса
2109,in-context demonstration,مظاهرة في السياق,العرض ضمن السياق,عرض في السياق,情境演示,上下文演示,上下文示范,démonstration en contexte,démonstration en contexte,démonstration en contexte,コンテキスト内のデモンストレーション,文脈内デモンストレーション (bunmyaku-na demonsutore-shon),コンテキストデモンストレーション,контекстная демонстрация,демонстрация в контексте,демонстрация в контексте
2110,in-context example,مثال في السياق,أمثلة في السياق,مثل سياقية,上下文示例,上下文示例,上下文示例,exemple en contexte,exemple en contexte,exemples contextuels,コンテキスト内の例,コンテキスト内の例,コンテクスト例,контекстный пример,примеры в контексте,в условиях примера
2111,in-context learner,المتعلم في السياق,المتعلم في السياق,متعلم في السياق,情境学习者,上下文学习者 (in-context learner),基于上下文学习器,apprenant en contexte,"""['Qualité de l'instruction En fin de compte, nous avons vu comment certaines instructions produisent des réponses cohérentes et relativement performantes à travers différents modèles, tandis que d'autres ne le font pas (voir Section 4.1.4. Nous ajoutons ce dernier facteur pour voir quels autres types de facteurs aident l'apprenant en contexte à faire face à la qualité variable de l'instruction.', ""On peut noter les limites de cette approche en termes des différentes",Apprenant en contexte,文脈に沿った学習者,文脈学習者,コンテキスト学習者,"учащийся, работающий в контексте",в контексте обучающийся,обучающийся с учетом контекста
2112,in-context learning,التعلم في السياق,التعلم في السياق,التعلم في السياق,情境学习,上下文学习,基于上下文的学习,apprentissage en contexte,apprentissage contextuel,apprentissage en contexte,文脈に沿った学習,文脈学習 (ぶんみゃくがくしゅう),コンテキスト内学習,обучение в контексте,В контекстном обучении,обучение в контексте
2113,in-degree distribution,توزيع في الدرجة,توزيع درجة الوصولية,توزيع الدرجة الداخلية,入度分布,入度分布,入度分布,répartition par diplôme,- Distribution du degré entrant,distribution des degrés entrants,内次数分布,インディグリー分布,入次数分布,распределение по степени,распределение входящих степеней,Распределение входящих степеней
2114,in-distribution,في التوزيع,"""أداء في التوزيع قد يكون عامل مضلل عندما لا يؤدي أحد النماذج بشكل جيد على مجموعة اختبار في التوزيع، أو في تقسيم عشوائي للبيانات.""",نطاق التوزيع,分布中,分布内,分布内 (in-distribution),en distribution,en distribution,dans la distribution,流通中,分布内,分布内,распространение,внутрираспределение,в распределении
2115,in-domain,في المجال,في المجال,فِي المجال,域内,领域内 (in-domain),领域内的,dans le domaine,dans le domaine,dans-le-domaine,ドメイン内,ドメイン内,ドメイン内,внутридоменный,в пределах области,внутриобластной
2116,in-domain text,النص في المجال,النصوص داخل المجال,نص في نفس المجال,域内文本,领域内文本,领域内文本,texte dans le domaine,texte dans le domaine,texte dans le domaine,ドメイン内テキスト,ドメイン内テキスト,分野内テキスト,внутридоменный текст,текст внутри домена,текст из той же области
2117,in-neighbor,في الجار,الجار الداخلي,الجار الوارد,邻国,内邻居 (in-neighbor),入邻居,chez le voisin,voisin interne,voisin entrant,近所の,内隣人,入次数ノード,сосед,внутренний сосед (in-neighbor),входные соседи
2118,in-order traversal,اجتياز بالترتيب,الترتيب في الزيارة,جولة ترتيبية,中序遍历,中序遍历,中序遍历,parcours dans l'ordre,,parcours infixe,順序通りの走査,順序通りの走査,中序木巡回,обход по порядку,"""['Их алгоритм включает обход дерева в порядке. Посещая каждый узел, мы генерируем тег, который включает в себя направление дуги, соединяющей узел с его родителем, т. е. является ли этот узел левым или правым потомком своего родителя, и",обход в прямом порядке
2119,inception score,النتيجة البداية,نقطة بداية التقييم,درجة البدء,初始分数,起源分数,初始分数,note initiale,score d'inception,score d'initialisation,インセプションスコア,インセプションスコア,起源スコア,начальный счет,оценка начала,показатель зачатия
2120,incremental learning,التعلم المتزايد,التعلم التدريجي,تعلم تدريجي,渐进学习,增量学习,增量学习,apprentissage progressif,apprentissage incrémental,incrémention d'apprentissage,段階的な学習,インクリメンタルラーニング (incremental learning),増分学習,постепенное обучение,инкрементальное обучение,прирастающее обучение
2121,incremental parsing,تحليل تزايدي,التحليل التدريجي,تحليل تزايدي,增量解析,"""['这项工作受到增量解析的概念启发，如Larchevêque（1995年）和Lane和Henderson（2001年）的作品所实现的。就神经解析器而言，最近在增量解析方面取得的进展包括来自Yang和Deng（2020年）的attach-juxtapose解析器。','这些系统可以帮助我们改进对增量解析",增量解析,analyse incrémentielle,analyse incrémentale,analyse syntaxique incrémentielle,インクリメンタル解析,インクリメンタル構文解析 (incremental parsing),増分的構文解析,инкрементный анализ,"""['Эта работа вдохновлена концепцией инкрементального анализа, реализованной в работах, таких как Ларшевек (1995) и Лейн и Хендерсон (2001). Что касается нейронных анализаторов, недавние успехи в инкрементальном анализе включ",пошаговый разбор
2122,independent Cascade Model,نموذج تتالي مستقل,- تصنيف خط الحركة المستقل,نموذج السلسلة المستقلة,独立级联模型,独立级联模型,独立级联模型,Modèle en cascade indépendant,Modèle de cascade indépendante,Modèle de Cascade Indépendante,独立したカスケード モデル,独立カスケードモデル,独立カスケードモデル,независимая каскадная модель,Модель независимого каскада,модель независимого каскада
2123,independent component analysis,تحليل المكونات المستقلة,تحليل المكونات المستقلة,تحليل المكونات المستقلة,独立成分分析,独立分量分析 (Independent Component Analysis),独立成分分析,analyse indépendante des composants,analyse en composantes indépendantes,Analyse en composantes indépendantes,独立成分分析,独立成分分析 (dokuritsu sebun bunseki),独立成分分析,независимый компонентный анализ,независимый компонентный анализ,Анализ независимых компонент
2124,independent set,مجموعة مستقلة,مجموعة مستقلة,مجموعة مستقلة,独立组,独立集,独立集,ensemble indépendant,ensemble indépendant,ensemble indépendant,独立集合,独立集合 (dokuritsu shuugou),独立集合,независимый набор,независимое множество,независимое множество
2125,independent variable,متغير مستقل,المتغير المستقل,متغير مستقل,自变量,自变量,独立变量,variable indépendante,variable indépendante,variable indépendante,独立変数,独立変数 (dokuritsu hensū),独立変数,независимая переменная,независимая переменная,независимая переменная
2126,indicator matrix,مصفوفة المؤشر,مصفوفة المؤشرات,مصفوفة مؤشر,指标矩阵,指标矩阵,指示矩阵,matrice d'indicateurs,matrice d'indicateurs,matrice indicatrice,指標マトリックス,インジケーターマトリックス (indicator matrix),指標行列,индикаторная матрица,индикаторная матрица,матрица индикаторов
2127,indicator variable,متغير المؤشر,متغير الدلالة,متغير إشارة,指示变量,指示变量,指示变量,variable indicatrice,variable indicatrice,variable indicatrice,指標変数,指示変数,指示変数,индикаторная переменная,показательная переменная,фиктивная переменная
2128,indicator vector,ناقلات المؤشر,متجه المؤشر,متجه المؤشر,指示向量,指示向量,指示向量,vecteur indicateur,vecteur indicateur,vecteur indicateur,インジケーターベクトル,指標ベクトル (indicator vector),指示ベクトル,вектор индикатора,вектор индикаторов,вектор индикатора
2129,induce subgraph,حث الرسم البياني الفرعي,- تحفيز الرسوم البيانية,الفرعي المُحث,归纳子图,诱导子图,诱导子图,induire un sous-graphe,sous-graphe induit,sous-graphe induit,部分グラフを誘導する,誘導部分グラフ (Induced Subgraph),部分グラフ,вызвать подграф,индуцированный подграф,породить подграф
2130,induce variable,الحث المتغير,"- Inducing Variable
- متغير محفز",متغير مُحَدِّث,诱导变量,诱导变量,诱导变量,induire une variable,variable inducteur,variable d'induction,変数を誘導する,誘導変数 (Inducing Variables),誘導変数,вызвать переменную,индуцирующие переменные,вводимая переменная
2131,induction hypothesis,فرضية الحث,فرضية التناقض,فرضية الاستقراء,归纳假说,归纳假设,归纳假设,hypothèse d'induction,hypothèse d'induction,hypothèse d'induction,帰納仮説,帰納的仮説 (きのうてきかせつ),帰納法仮説,гипотеза индукции,Гипотеза индукции,индукционное предположение
2132,inductive bias,التحيز الاستقرائي,الإنحياز الاستقرائي,التحيز الاستقرائي,归纳偏置,归纳偏差,归纳偏置,biais inductif,biais inductif,biais inductif,誘導バイアス,帰納バイアス,帰納的バイアス,индуктивное смещение,индуктивное смещение,индуктивное смещение
2133,inductive learning,التعلم الاستقرائي,التعلم التستقري,تعلم استقرائي,归纳学习,归纳学习 (guīnà xuéxí),归纳学习,apprentissage inductif,apprentissage inductif,apprentissage inductif,帰納的学習,帰納学習 (kinou gakushu),帰納的学習,индуктивное обучение,индуктивное обучение,индуктивное обучение
2134,inf,الوقود النووي المشع,أدنى,أدنى,信息,inf,最小值,fam,inf,inférieur,無限,inf,最小値,инфа,inf,нижняя грань
2135,inference,الإستنباط,- تستنتج,الاستدلال,推理,推理,推理,inférence,inférence,inférence,推論,推論,推論,вывод,"""[...] Во время вывода мы используем размер луча 10 и максимальное количество 15 шагов декодирования, как в оригинальной статье. Обучение GENRE заняло около 16 часов на двух видеокартах Nvidia 3090ti за эпоху [...] Модель определяет совместную вероятность сегментированного предложения на исход",вывод
2136,inference algorithm,خوارزمية الاستدلال,- تطبيق خوارزمية الاستدلال,خوارزمية الاستدلال,推理算法,推断算法,推理算法,algorithme d'inférence,algorithme d'inférence,algorithme d'inférence,推論アルゴリズム,推論アルゴリズム (Suiron arugorizumu),推論アルゴリズム,алгоритм вывода,алгоритм вывода,алгоритм вывода
2137,inference machinery,آلات الاستدلال,آلية الاستدلال,آلية الاستدلال,推理机,推论机构,推理机制,machinerie d'inférence,machinerie d'inférence,Machinerie d'inférence,推論機械,推論機構,推論機構,машина вывода,механизм вывода,вывод оборудования
2138,inference method,طريقة الاستدلال,طريقة استنتاج,طريقة الاستدلال,推理法,推理方法,推理方法,méthode d'inférence,méthode d'inférence,méthode d'inférence,推論方法,推論方法 (すいろんほうほう),推論方法,метод вывода,метод вывода,метод вывода
2139,inference problem,مشكلة الاستدلال,مشكلة الاستدلال,مشكلة الاستدلال,推理问题,推理问题,推理问题,problème d'inférence,problème d'inférence,problème d'inférence,推論問題,推論問題 (すいろんもんだい),推論問題,проблема вывода,проблема вывода,проблема вывода
2140,inference procedure,إجراء الاستدلال,إجراء الاستدلال,إجراء الاستدلال,推理过程,推理过程,推理过程,procédure d'inférence,procédure d'inférence,procédure d'inférence,推論手順,推論手続き (Suiron Shikō),推論手続き,процедура вывода,процедура вывода,процедура вывода
2141,inference process,عملية الاستدلال,عملية الاستدلال,عملية الاستدلال,推理过程,推理过程,推理过程,processus d'inférence,processus d'inférence,processus d'inférence,推論プロセス,推論プロセス,推論プロセス,процесс вывода,Процесс вывода,процесс вывода
2142,inference rule,قاعدة الاستدلال,قاعدة استدلال,قاعدة استنتاج,推理规则,推理规则 (Inference Rule),推理规则,règle d'inférence,règle d'inférence,règle d'inférence,推論ルール,推論規則 (Suiron kisoku),推論規則,правило вывода,Правило вывода,правило вывода
2143,inference stage,مرحلة الاستدلال,مرحلة الاستدلال,مرحلة الاستدلال,推理阶段,推理阶段,推理阶段,étape d'inférence,étape d'inférence,étape d'inférence,推論段階,推論段階 (Inference stage),推論段階,стадия вывода,стадия вывода,стадия вывода
2144,inference task,مهمة الاستدلال,مهمة الاستدلال,مهمة الاستدلال,推理任务,推断任务,推理任务,tâche d'inférence,tâche d'inférence,tâche d'inférence,推論タスク,推論タスク (Suiron Task),推論タスク,задача вывода,задача вывода,задача вывода
2145,inference time,وقت الاستدلال,وقت الاستنتاج,وقت الاستدلال,推理时间,推理时间,推理时间,temps d'inférence,- Temps d'inférence,temps d'inférence,推論時間,推論時間 (Suiin Jikan),推論時間,время вывода,время вывода,время вывода
2146,infinite-horizon,الأفق اللانهائي,آفاق لا نهائية,أفق لانهائي,无限视野,- 无限时间界限,无限视野,horizon infini,horizon infini,horizon infini,無限の地平線,「この論文では、報酬が環境の状態、実行されたアクション、および各ステップで既知の事前分布からサンプリングされた外部パラメータに依存する無限地平のマルコフ決定過程（MDP）との相互作用を含めるようにこの設定を,無限時間視野,бесконечный горизонт,"""В этой статье мы расширяем эту настройку, чтобы включить взаимодействие в задаче принятия решений Маркова с бесконечным горизонтом (MDP), где вознаграждения зависят от состояния окружающей среды, выполненного действия, а также внешнего параметра, выбранного из",бесконечный горизонт
2147,influence diagram,مخطط التأثير,مخطط التأثير,شبكة تأثير,影响图,影响图,影响图,diagramme d'influence,- Diagramme d'influence,diagramme d'influence,影響図,影響図,影響図,диаграмма влияния,диаграмма влияния,влиятельная диаграмма
2148,influence function,وظيفة التأثير,وظيفة التأثير,دالة التأثير,影响函数,影响函数,影响函数,fonction d'influence,fonction d'influence,fonction d'influence,影響関数,影響関数 (えいきょうかんすう),影響関数,функция влияния,функция влияния,функция влияния
2149,influence maximization,تعظيم التأثير,أقصى تأثير,تعظيم التأثير,影响力最大化,影响最大化 (Influence Maximization),影响力最大化,maximisation de l'influence,maximisation de l'influence,maximisation de l'influence,影響力の最大化,影響最大化,影響最大化,максимизация влияния,максимизация влияния,развитие максимального влияния
2150,information Retrieval,استرجاع المعلومات,استرجاع المعلومات,استرجاع المعلومات,信息检索,信息检索,信息检索,récupération de l'information,Recherche d'information,Recherche d'informations,情報検索,情報検索,情報検索,поиск информации,Информационный поиск,поиск информации
2151,information bottleneck,عنق الزجاجة المعلومات,تقنية قناة البيانات,اختناق المعلومات,信息瓶颈,信息瓶颈,信息瓶颈,goulot d'étranglement de l'information,goulot d'étranglement de l'information,goulot d'information,情報のボトルネック,情報ボトルネック,情報の瓶詰め,информационное узкое место,информационное узкое место,информационное сужение
2152,information content,محتوى المعلومات,محتوى المعلومات,محتوى المعلومات,信息内容,信息内容,信息含量,contenu de l'information,contenu de l'information,contenu informationnel,情報内容,情報内容,情報量,информационное содержание,информационное содержание,информационное содержание
2153,information extraction,استخراج المعلومات,استخراج المعلومات,استخراج المعلومات,信息提取,信息提取,信息提取,extraction d'informations,extraction d'informations,extraction d'informations,情報抽出,情報抽出,情報抽出,извлечение информации,Извлечение информации,извлечение информации
2154,information gain,كسب المعلومات,مكسب المعلومات,كسب المعلومات,信息增益,信息增益,信息增益,gain d'informations,gain d'information,Gain d'information,情報獲得,情報利得,情報量,получение информации,прирост информации,Информационный прирост
2155,information retrieval system,نظام استرجاع المعلومات,نظام استرجاع المعلومات,نظام استرجاع المعلومات,信息检索系统,信息检索系统,信息检索系统,système de recherche d'informations,système de recherche d'information,système de recherche d'informations,情報検索システム,情報検索システム (jouhou kensaku shisutemu),情報検索システム,информационно-поисковая система,система поиска информации,система поиска информации
2156,information set,مجموعة المعلومات,مجموعة المعلومات,مجموعة معلومات,信息集,信息集,信息集,ensemble d'informations,Ensemble d'informations,ensemble d'informations,情報セット,情報セット,情報集合,информационный набор,набор информации,набор информации
2157,information theoretic,نظرية المعلومات,نظرية المعلوماتية,نظرية المعلومات,信息论,信息论,信息论的,théorie de l'information,théorique de l'information,théorique de l'information,情報理論,情報理論的,情報理論的な,теория информации,информационно-теоретическое,информационно-теоретический
2158,information theoretic measure,المقياس النظري للمعلومات,مقياس نظرية المعلومات,مقياس نظري للمعلومات,信息论测度,信息论度量,信息论量度,mesure théorique de l'information,- Mesure d'information théorique,mesure théorique de l'information,情報理論的尺度,情報理論的尺度,情報理論的尺度,теоретическая мера информации,мера информационной теории,информационно-теоретическая мера
2159,informer model,نموذج المخبر,نموذج معلوماتي,نموذج المُعلم,告密者模型,预报模型,信息提供者模型,modèle d'informateur,modèle Informer,modèle informateur,情報提供者モデル,インフォーマー・モデル (informa modoru),情報提供モデル,модель информера,Модель Informer,информационная модель
2160,infoset,infoset,مجموعة معلوماتية,مجموعة معلومات,信息集,信息集,信息集,ensemble d'informations,ensemble d'informations,ensemble d'informations,情報セット,情報セット,情報集合,информационный набор,информационное множество,информационное множество
2161,inhomogeneous Poisson process,عملية بواسون غير متجانسة,عملية بواسون غير متجانسة,عملية بواسون غير متجانسة,非齐次泊松过程,不均匀泊松过程,非均匀泊松过程,processus de Poisson inhomogène,processus de Poisson inhomogène,processus de Poisson inhomogène,不均一ポアソン過程,不均一ポアソン過程,不均一ポアソン過程,неоднородный процесс Пуассона,неоднородный пуассоновский процесс,неоднородный пуассоновский процесс
2162,initial distribution,التوزيع الأولي,التوزيع الأولي,التوزيع الأولي,初始分配,初始分布,初始分布,distribution initiale,distribution initiale,distribution initiale,初期配布,初期分布,初期分布,первоначальное распространение,начальное распределение,начальное распределение
2163,initial state,الحالة الأولية,الحالة الابتدائية,الحالة الابتدائية,初始状态,初始状态,初始状态,Etat initial,état initial,état initial,初期状態,初期状態,初期状態,начальное состояние,начальное состояние,начальное состояние
2164,initial state distribution,توزيع الحالة الأولية,التوزيع الابتدائي للحالة,توزيع الحالة الأولية,初始状态分布,初始状态分布,初始状态分布,répartition initiale de l'état,- Distribution de l'état initial,distribution de l'état initial,初期状態分布,初期状態分布,初期状態分布,распределение начального состояния,распределение начального состояния,начальное распределение состояний
2165,initialization,التهيئة,التهيئة,تهيئة,初始化,初始化,初始化,initialisation,initialisation,initialisation,初期化,初期化,初期化,инициализация,инициализация,инициализация
2166,injective function,وظيفة الحقن,دالة حاقنة,دالة حقية,内射函数,单射函数,单射函数,fonction injective,fonction injective,fonction injective,単射関数,単射関数 (tansha kansu),単射関数,инъективная функция,инъективная функция,вложение
2167,inlier,ضمني,العناصر المتوافقة,بيانات متماسكة,内点,内点,内点,inlier,"en 'choisissant' d'abord une ancre puis en suivant un chemin de HC pour 'résoudre'.', 'Théoriquement, les inliers formeraient des cliques dans le graphe, car les inliers",Epipont,インリア,アウトライア (outlier),イン-ライヤー,вкладыш,внутренняя точка,вхождений
2168,inner layer,الطبقة الداخلية,- التكسية الداخلية,طبقة داخلية,内层,内层,内层,couche intérieure,- Couche interne,couche interne,内層,内層,内部層,внутренний слой,- Внутренний слой,внутренний слой
2169,inner loop,الحلقة الداخلية,الحلقة الداخلية,الحلقة الداخلية,内循环,内部循环,内循环,Boucle intérieure,boucle interne,boucle interne,内側のループ,内側のループ,内部ループ,внутренний цикл,внутренний цикл,внутренний цикл
2170,inner node,العقدة الداخلية,العقدة الداخلية,عقدة داخلية,内部节点,内部节点,内部节点,nœud interne,- Noeud interne,nœud interne,内部ノード,内部ノード,内部ノード,внутренний узел,внутренний узел,внутренний узел
2171,inner product,منتج داخلي,المنتج الداخلي,ضرب داخلي,内积,内积,内积,produit intérieur,produit scalaire interne,produit scalaire,内部製品,内積,内積,внутренний продукт,внутреннее произведение,скалярное произведение
2172,input,مدخل,المدخل,المدخلات,输入,输入,输入,saisir,entrée,entrée,入力,入力,入力,вход,ввод,вход
2173,input context,سياق الإدخال,سياق الإدخال,تضمين السياق,输入上下文,输入上下文,输入上下文,contexte de saisie,contexte d'entrée,contexte d'entrée,入力コンテキスト,入力コンテキスト,入力コンテキスト,входной контекст,- Входной контекст,входной контекст
2174,input datum,مسند الإدخال,البيانات المدخلة,بيان المدخلات,输入数据,输入数据,输入数据,donnée d'entrée,donnée d'entrée,donnée d'entrée,入力データム,入力データ,入力データ,входная база данных,вводные данные,входные данные
2175,input embedding,تضمين المدخلات,تضمين الإدخال,تضمين المدخلات,输入嵌入,输入嵌入,输入嵌入,intégration d'entrée,incorporation d'entrée,plongement d'entrée,入力埋め込み,入力埋め込み (nyūryoku umekomi),入力埋め込み,встраивание входных данных,входное вложение,вложение входных данных
2176,input feature,ميزة الإدخال,السمة الداخلية,ميزة المُدخلات,输入特征,输入特征,输入特征,fonction d'entrée,caractéristique d'entrée,Caractéristique d'entrée,入力機能,入力特徴,入力特徴量,функция ввода,- Входная функция,входная характеристика
2177,input feature vector,ناقلات ميزة الإدخال,متجه سمة الإدخال,متجه السمات المدخلة,输入特征向量,输入特征向量,输入特征向量,vecteur de caractéristiques d'entrée,vecteur de caractéristiques d'entrée,vecteur de caractéristiques d'entrée,入力特徴ベクトル,入力特徴ベクトル,入力特徴ベクトル,входной вектор признаков,входной вектор признаков,входной векторный признак
2178,input filter,مرشح الإدخال,مرشح الإدخال,مُرشِّح المُدخلات,输入过滤器,输入过滤器,输入滤波器,filtre d'entrée,Filtre d'entrée,filtre d'entrée,入力フィルタ,入力フィルタ,入力フィルター,входной фильтр,входной фильтр,Входной фильтр
2179,input formula,صيغة الإدخال,صيغة الإدخال,الصيغة المدخلة,输入公式,输入公式,输入公式,formule de saisie,formule d'entrée,formule d'entrée,入力式,入力式,入力式,формула ввода,входная формула,входная формула
2180,input gate,بوابة الإدخال,بوابة الإدخال,بوابة المدخلات,输入门,输入门,输入门,porte d'entrée,porte d'entrée,porte d'entrée,入力ゲート,入力ゲート,入力ゲート,входные ворота,входные ворота,входной затвор
2181,input graph,رسم بياني للإدخال,الرسم البياني الداخلي,مُدخَل بيانيّ,输入图,输入图,输入图,graphique d'entrée,graphe d'entrée,graphe d'entrée,入力グラフ,入力グラフ,入力グラフ,входной график,входной граф,вводимый граф
2182,input image,صورة الإدخال,صورة الإدخال,صورة المدخلات,输入图像,输入图像,输入图像,image d'entrée,- Image d'entrée,image d'entrée,入力画像,入力画像 (nyuuryoku gazou),入力画像,входное изображение,входное изображение,вводное изображение
2183,input layer,طبقة الإدخال,الطبقة الداخلية للمدخلات,طبقة المدخلات,输入层,输入层,输入层,couche d'entrée,couche d'entrée,couche d'entrée,入力層,入力層,入力層,входной слой,Слой ввода,входной слой
2184,input length,طول الإدخال,طول الإدخال,طول الإدخال,输入长度,输入长度,输入长度,longueur d'entrée,longueur d'entrée,longueur d'entrée,入力長さ,入力長,入力長さ,входная длина,длина ввода,длина входных данных
2185,input matrix,مصفوفة الإدخال,مصفوفة الإدخال,المصفوفة المُدخلة,输入矩阵,输入矩阵,输入矩阵,matrice d'entrée,- Matrice d'entrée,matrice d'entrée,入力行列,入力行列,入力行列,входная матрица,- Входная матрица,вводная матрица
2186,input point,نقطة الإدخال,نقطة الإدخال,نقطة إدخال,输入点,输入点,输入点,point d'entrée,Point d'entrée,point d'entrée,入力ポイント,入力ポイント,入力点,точка входа,точка ввода,вводная точка
2187,input position,موضع الإدخال,موضع الإدخال,وضع الإدخال,输入位置,输入位置,输入位置,position d'entrée,position d'entrée,position d'entrée,入力位置,入力位置,入力位置,позиция ввода,входное положение,вводное положение
2188,input representation,تمثيل المدخلات,التمثيل الداخلي للمدخلات,تمثيل المدخلات,输入表示,输入表示,输入表示,représentation d'entrée,représentation de l'entrée,représentation d'entrée,入力表現,入力表現,入力表現,входное представление,входное представление,входное представление
2189,input resolution,دقة الإدخال,القرارة الداخلية,دقة الإدخال,输入分辨率,输入分辨率,输入分辨率,résolution d'entrée,résolution d'entrée,résolution d'entrée,入力解像度,入力解像度,入力解像度,входное разрешение,входное разрешение,разрешение входного изображения
2190,input sequence,تسلسل الإدخال,التسلسل الداخلي,سلسلة المُدخلات,输入序列,输入序列,输入序列,séquence d'entrée,séquence d'entrée,séquence d'entrée,入力シーケンス,入力シーケンス,入力シーケンス,входная последовательность,входная последовательность,входная последовательность
2191,input space,مساحة الإدخال,المساحة الداخلية,فضاء الإدخال,输入空间,输入空间,输入空间,espace de saisie,espace d'entrée,espace d'entrée,入力スペース,入力空間 (nyūryoku kūkan),入力空間,пространство ввода,пространство входных данных,пространство входных данных
2192,input tensor,موتر الإدخال,تدرج الإدخال,مصفوفة المدخلات,输入张量,输入张量,输入张量,tenseur d'entrée,tenseur d'entrée,tenseur d'entrée,入力テンソル,入力テンソル,入力テンソル,входной тензор,входной тензор,входной тензор
2193,input text,أدخل نصآ,نص الإدخال,نص المدخلات,输入文本,输入文本,输入文本,Texte de saisie,- Texte d'entrée,texte d'entrée,入力テキスト,入力テキスト (nyūryoku tekisuto),入力テキスト,ввод текста,- Вводной текст,входной текст
2194,input token,رمز الإدخال,رمز الإدخال,رمز المدخلات,输入令牌,输入令牌 (input token),输入标记,jeton d'entrée,jeton d'entrée,jeton d'entrée,入力トークン,入力トークン,入力トークン,входной токен,- Входной токен,входной токен
2195,input vector,ناقلات الإدخال,متجه الإدخال,متجه المدخلات,输入向量,输入向量,输入向量,vecteur d'entrée,vecteur d'entrée,vecteur d'entrée,入力ベクトル,入力ベクトル,入力ベクトル,входной вектор,входной вектор,вектор входных данных
2196,input-output pair,زوج المدخلات والمخرجات,زوج الإدخال والإخراج,ازواج المدخلات والمخرجات,输入输出对,输入-输出对,输入-输出对,paire entrée-sortie,paire d'entrée-sortie,paire entrée-sortie,入出力ペア,入力-出力ペア,入力-出力ペア,пара ввода-вывода,входно-выходной пары,входно-выходная пара
2197,instance,مثال,- تكرار,مثال,实例,实例,实例,exemple,instance,occurrence,実例,インスタンス,インスタンス,пример,"""['Кроме того, наш анализ показывает, что выученная сложность и надежность объяснимы, что помогает объяснить, как наша модель выводит правильную метку для каждого экземпляра. Наконец, был проведен анализ ошибок для понимания неправильных прогнозов.', 'Затем сокращение",экземпляр
2198,instance level,مستوى المثيل,مستوى الحالة,مستوى المثيل,实例级,实例级别,实例级别,niveau d'instance,- Niveau d'instance,niveau d'instance,インスタンスレベル,インスタンスレベル,インスタンスレベル,уровень экземпляра,уровень экземпляра,уровень экземпляра
2199,instance normalization,التطبيع المثال,تطبيع الحالة,تحييد المثيل,实例标准化,实例规范化 (Instance Normalization),实例归一化,normalisation des instances,normalisation d'instance,normalisation d'instance,インスタンスの正規化,インスタンス正規化 (Instance Normalization),インスタンス正規化,нормализация экземпляра,нормализация экземпляра,нормализация экземпляра
2200,instance segmentation,تجزئة المثال,التقسيم الفردي للحالات,تقسيم المثيلات,实例分割,实例分割,实例分割,segmentation des instances,segmentation d'instance,segmentation d'instances,インスタンスのセグメンテーション,インスタンスセグメンテーション,インスタンスセグメンテーション,сегментация экземпляров,сегментация экземпляров,семантическая сегментация экземпляров
2201,instance selection,اختيار المثيل,- تحديد الحالة,اختيار النموذج,实例选择,实例选择,实例选择,sélection d'instances,sélection d'instance,sélection d'instances,インスタンスの選択,インスタンス選択 (Insutansu sentaku),インスタンス選択,выбор экземпляра,выбор примеров,выбор экземпляров
2202,instance space,مساحة المثال,مساحة الحالة,فضاء الحالات,实例空间,示例空间,实例空间,espace d'instance,espace d'instance,espace d'instances,インスタンススペース,インスタンス空間 (Insutansu Kukan),インスタンス空間,пространство экземпляра,пространство экземпляров,пространство экземпляров
2203,instruction tuning,ضبط التعليمات,ضبط التعليمات,ضبط التعليمات,指令调优,指令调整,指令调优,réglage des instructions,ajustement des instructions,ajustement des instructions,命令チューニング,インストラクションチューニング,命令チューニング,инструкция по настройке,настройка инструкций,Подстройка инструкций
2204,integer linear program,برنامج خطي صحيح,برنامج خطي صحيح للأعداد الصحيحة,برنامج خطي صحيح,整数线性规划,整数线性规划,整数线性规划,programme linéaire entier,- Programme linéaire entier,programme linéaire en nombres entiers,整数線形計画法,整数線形計画 (seisuu senkei keikaku),整数線形計画問題,целочисленная линейная программа,целочисленная линейная программа,целочисленная линейная программа
2205,integer program,برنامج عدد صحيح,برنامج صحيح,برنامج صحيح,整数规划,整数规划 (IP),整数规划问题,programme entier,- Programme entier,programme entier,整数プログラム,整数プログラム (IP),整数計画問題,целочисленная программа,Целочисленная программа (IP),целочисленная программа
2206,integral image,صورة متكاملة,الصورة التكاملية,صورة تكاملية,积分图像,积分图,积分图像,image intégrale,image intégrale,image intégrale,インテグラルイメージ,積分画像 (sekibun gazō),積分画像,целостный образ,интегральное изображение,интегральное изображение
2207,integral operator,عامل متكامل,- المشغل التكاملي,مُشغِّل التكامل,积分算子,积分算子,积分算子,opérateur intégral,opérateur intégral,opérateur intégral,整数演算子,積分作用素,積分作用素,интегральный оператор,интегральный оператор,интегральный оператор
2208,integral probability metric,مقياس الاحتمالية المتكامل,المقياس الاحتمالي التكاملي,تكامل متري الاحتمال,积分概率度量,积分概率度量,积分概率度量,métrique de probabilité intégrale,métrique de probabilité intégrale,métrique de probabilité intégrale,積分確率メトリック,積分確率尺度 (integral probability metric),積分確率メトリック,интегральная вероятностная метрика,интегральная вероятностная метрика,интегральная метрика вероятности
2209,integrity constraint,قيد التكامل,قيد النزاهة,قيد النزاهة,完整性约束,完整性约束,完整性约束,contrainte d'intégrité,contrainte d'intégrité,contrainte d'intégrité,整合性制約,整合性制約,整合性制約,ограничение целостности,ограничение целостности,целостные ограничения
2210,intelligent agent,وكيل ذكي,الوكيل الذكي,وكيل ذكي,智能代理,智能代理,智能体,agent intelligent,agent intelligent,agent intelligent,インテリジェントエージェント,知能エージェント,知的エージェント,интеллектуальный агент,интеллектуальный агент,интеллектуальный агент
2211,intensity function,وظيفة الشدة,دالة الكثافة,دالة الشدة,强度函数,强度函数 (qiángdù hánshù),强度函数,fonction d'intensité,- Fonction d'intensité,fonction d'intensité,強度関数,強度関数,強度関数,функция интенсивности,функция интенсивности,Функция интенсивности
2212,intent,نية,النية,القصد,意图,意图,意图,intention,intention,intention,意図,意図,意図,намерение,намерение,намерение
2213,inter-annotator agreement,اتفاق بين المفسرين,اتفاق المعلمين الفرديين,مدى الاتفاق بين المصححين,注释者间协议,人工标注者间的一致性,注释者间一致性,accord inter-annotateur,- Accord inter-annotateur,accord inter-annotateurs,アノテーター間の合意,アノテータ間の一致,複数アノテータ間の一致率,соглашение между аннотаторами,согласованность между аннотаторами,межаннотационная согласованность
2214,interaction matrix,مصفوفة التفاعل,مصفوفة التفاعل,مصفوفة التفاعل,交互矩阵,互动矩阵,相互作用矩阵,matrice d'interaction,- Matrice d'interaction,matrice d'interaction,相互作用行列,インタラクション行列 (Intārakushon gyōretsu),相互作用行列,матрица взаимодействия,матрица взаимодействий,матрица взаимодействий
2215,interest point,نقطة الاهتمام,نقطة الاهتمام,نقطة اهتمام,兴趣点,兴趣点,兴趣点,point d'intérêt,- Point d'intérêt,Point d'intérêt,関心点,興味ポイント,興味点,точка интереса,точка интереса,точки интереса
2216,interior point method,طريقة النقطة الداخلية,- تقنية نقطة الداخلية,طريقة النقطة الداخلية,内点法,内点法,内点法,méthode du point intérieur,- Méthode du point intérieur,méthode de point intérieur,内点法,内点法,内点法,метод внутренней точки,метод внутренней точки,метод внутренней точки
2217,intermediate layer,طبقة المتوسطة,الطبقة الوسيطة,الطبقة الوسيطة,中间层,中间层,中间层,couche intermédiaire,- Couche intermédiaire,couche intermédiaire,中間層,中間層,中間層,промежуточный слой,Промежуточный слой,промежуточный слой
2218,intermediate representation,التمثيل الوسيط,التمثيل الوسيط,التمثيل الوسيط,中间表示,中间表示,中间表示,représentation intermédiaire,représentation intermédiaire,représentation intermédiaire,中間表現,中間表現,中間表現,промежуточное представление,Промежуточное представление,промежуточное представление
2219,internal edge,الحافة الداخلية,الحافة الداخلية,الحافة الداخلية,内边缘,内部边,内部边缘,bord interne,bord interne,arête interne,内部エッジ,内部エッジ,内部エッジ,внутренний край,внутренние рёбра,внутреннее ребро
2220,internal node,العقدة الداخلية,العقدة الداخلية,عقدة داخلية,内部节点,内部节点,内部节点,nœud interne,nœud interne,nœud interne,内部ノード,内部ノード,内部ノード,внутренний узел,внутренний узел,внутренний узел
2221,internal regret,الأسف الداخلي,الندم الداخلي,الندم الداخلي,内心后悔,内部后悔,内部遗憾,regret intérieur,regret interne,regret interne,内なる後悔,内部後悔,内的後悔,внутреннее сожаление,Внутренний регрет,внутреннее сожаление
2222,internal representation,التمثيل الداخلي,التمثيل الداخلي,التمثيل الداخلي,内部代表,内部表征,内部表示,représentation interne,représentation interne,représentation interne,内部表現,内部表現,内部表現,внутреннее представительство,Внутреннее представление,Внутреннее представление
2223,internal state,الحالة الداخلية,الحالة الداخلية,الحالة الداخلية,内部状态,内部状态,内部状态,état interne,état interne,état interne,内部状態,内部状態,内部状態,внутреннее состояние,внутреннее состояние,внутреннее состояние
2224,interpolation,إقحام,التقريب,استكمال,插值法,插值,插值法,interpolation,interpolation,interpolation,補間,補間 (ほかん),補間,интерполяция,интерполяция,интерполяция
2225,interpretability,قابلية التفسير,القابلية للتفسير,قابلية التفسير,可解释性,可解释性,可解释性,interprétabilité,interprétabilité,interprétabilité,解釈可能性,解釈可能性,解釈可能性,интерпретируемость,интерпретируемость,интерпретируемость
2226,interpretation function,وظيفة التفسير,وظيفة التفسير,دالة التفسير,解释功能,解释函数,解释函数,fonction d'interprétation,fonction d'interprétation,fonction d'interprétation,解釈機能,解釈関数 (kaisetsu kansu),解釈関数,функция интерпретации,функция интерпретации,функция интерпретации
2227,intersection-over-union,تقاطع فوق الاتحاد,- التقاطع على الاتحاد,اتحاد فوق التقاطع,并集上的交集,交并比,交并比,intersection sur union,intersection sur union,union-sur-intersection,交差オーバーユニオン,IoU (交差結合比),交差領域と和集合の比率,пересечение-над-объединением,- Пересечение-объединение,пересечение-над-объединением
2228,interval estimate,تقدير الفاصل الزمني,تقدير فاصلة,تقدير الفترة,区间估计,区间估计,区间估计,estimation de l'intervalle,estimation par intervalle,estimation par intervalle,間隔の推定,区間推定,区間推定,интервальная оценка,интервальная оценка,оценка интервала
2229,intractability,الاستعصاء,- العنيدية,صعوبة الحل,棘手性,不可约性,无解性,intraitabilité,intractabilité,intraictabilité,難治性,非効率性,難解性,несговорчивость,неразрешимость,вычислительная неразрешимость
2230,intrinsic,جوهري,ذاتي,معاملات داخلية,固有的,内在,内参数,intrinsèque,intrinsèque,intrinsèques,本質的な,固有の,内部パラメータ,внутренний,внутренние,внутренние
2231,intrinsic camera parameter,معلمة الكاميرا الجوهرية,معلمة الكاميرا الجوهرية,معامل الكاميرا الذاتي,相机固有参数,相机内参,内在相机参数,paramètre intrinsèque de la caméra,paramètre de la caméra intrinsèque,paramètres intrinsèques de la caméra,固有のカメラパラメータ,内部カメラパラメータ (naibu kamera parametā),内部カメラパラメータ,внутренний параметр камеры,внутренний параметр камеры,внутренние параметры камеры
2232,intrinsic dimension subspace,الفضاء الفرعي البعد الجوهري,البُعد الجوهري للفضاء الفرعي,فضاء البعد الجوهري,内在维度子空间,内在维度子空间 (Intrinsic Dimension Subspace),内在维度子空间,sous-espace de dimension intrinsèque,sous-espace de dimension intrinsèque,Sous-espace de dimension intrinsèque,固有次元部分空間,固有次元部分空間 (intrinsic dimension subspace),本質次元部分空間,Подпространство внутреннего измерения,внутреннее подпространство размерности,подпространство внутреннего измерения
2233,intrinsic dimensionality,الأبعاد الجوهرية,البُعد الجوهري,البعد الجوهري,内在维度,内在维度,内在维度,dimensionnalité intrinsèque,dimension intrinsèque,dimensionnalité intrinsèque,固有の次元性,固有次元数,固有次元数,внутренняя размерность,внутренняя размерность,внутреннее измерение
2234,intrinsic evaluation,التقييم الجوهري,- التقييم الجوهري,تقييم داخلي,内在评价,内在评估,内在评估,évaluation intrinsèque,- Évaluation intrinsèque,évaluation intrinsèque,本質的評価,内部評価,内在的評価,внутренняя оценка,внутренняя оценка,внутренняя оценка
2235,intrinsic image,صورة جوهرية,الصورة الجوهرية,الصورة الجوهرية,内在意象,内在图像,固有图像,image intrinsèque,image intrinsèque,image intrinsèque,本質的なイメージ,固有画像 (Koyū gazō),固有画像,внутренний образ,внутренний образ,врожденное изображение
2236,intrinsic parameter,المعلمة الجوهرية,المعلمة الجوهرية,معامل داخلي,内在参数,内参,内参数,paramètre intrinsèque,Paramètre intrinsèque,paramètres intrinsèques,組み込みパラメータ,固有パラメータ,内在パラメータ,внутренний параметр,внутренний параметр,внутренний параметр
2237,inverse document frequency,تردد الوثيقة العكسي,تردد المستند العكسي,معامل تردد المستند العكسي,逆文档频率,逆文档频率,逆文档频率,fréquence inverse des documents,fréquence inverse du document,fréquence inverse de document,逆ドキュメント頻度,逆文書頻度 (gyaku bunsho hin'ndo),逆文書頻度,обратная частота документов,обратная частота документа,обратная документная частота
2238,inverse dynamic model,النموذج الديناميكي العكسي,نموذج ديناميكي عكسي,نموذج الديناميكا العكسي,逆动态模型,逆动力学模型,逆动力学模型,modèle dynamique inverse,modèle dynamique inverse,modèle de dynamique inverse,逆動的モデル,逆動力学モデル (gyaku douryoku-gaku moderu),逆動力学モデル,обратная динамическая модель,обратная динамическая модель,обратная динамическая модель
2239,inverse problem,مشكلة عكسية,المشكلة العكسية,مشكلة معكوسة,逆问题,逆问题,逆问题,problème inverse,problème inverse,problème inverse,逆問題,逆問題,逆問題,обратная задача,обратная задача,обратная задача
2240,inverse reinforcement learning,التعلم التعزيز العكسي,التعلم العكسي للتعزيز,التعلم التعزيزي العكسي,逆向强化学习,逆强化学习,逆强化学习,apprentissage par renforcement inverse,apprentissage par renforcement inverse,apprentissage par renforcement inverse,逆強化学習,逆強化学習 (Inverse Reinforcement Learning),逆強化学習,обучение с обратным подкреплением,Обратное обучение с подкреплением,Обратное обучение с подкреплением
2241,inverse rendering,تقديم معكوس,عكس التقديم,العرض العكسي,逆向渲染,反渲染,逆渲染,rendu inverse,rendu inverse,rendu inverse,逆レンダリング,逆レンダリング,逆レンダリング,инверсный рендеринг,обратное воспроизведение,обратный рендеринг
2242,inverse role,دور عكسي,الدور المعكوس,دور عكسي,反作用,逆角色,逆角色,rôle inverse,rôle inverse,rôle inverse,逆の役割,逆役割 (gyaku yakuwari),逆役割,обратная роль,обратная роль,обратная роль
2243,inverse square root learning rate schedule,جدول معدل التعلم للجذر التربيعي العكسي,جدول تعلم معدل الجذر التربيعي العكسي,جدول معدل التعلم الجذر التربيعي العكسي,反平方根学习率表,逆平方根学习率调度,反平方根学习率时程表,barème du taux d'apprentissage de la racine carrée inverse,calendrier de taux d'apprentissage inverse de la racine carrée,programme de taux d'apprentissage en racine carrée inverse,逆平方根学習率スケジュール,逆平方根学習率スケジュール,逆平方根学習率スケジュール,"График скорости обучения, обратный квадратному корню",обратная квадратный корень график обучения,обратно пропорциональный квадратному корню график изменения темпа обучения
2244,inverse square root learning rate scheduler,معكوس الجذر التربيعي جدولة معدل التعلم,جدول جدول معدل التعلم عكس جذر التربيع,جدولة معدل التعلم بالجذر التربيعي المعكوس,反平方根学习率调度器,倒数平方根学习率调度器,反平方根学习率调度器,planificateur de taux d'apprentissage de racine carrée inverse,plannificateur de taux d'apprentissage en racine carrée inverse,Programmateur du taux d'apprentissage par racine carrée inverse,逆平方根学習率スケジューラ,逆二乗平方根学習率スケジューラ,逆平方根学習率スケジューラ,"планировщик скорости обучения, обратный квадратному корню",обратный квадратный корень планировщик скорости обучения,обратная квадратная корневая планировщик темпа обучения
2245,inverse transform sampling,أخذ عينات التحويل العكسي,عينة التحويل العكسي,عينة التحويل العكسي,逆变换采样,逆变换采样,逆变换采样,échantillonnage par transformée inverse,échantillonnage par transformation inverse,échantillonnage par transformation inverse,逆変換サンプリング,逆変換サンプリング,逆変換サンプリング,выборка обратного преобразования,обратное преобразование сэмплирования,обратное преобразование выборки
2246,invert index,مؤشر عكس,الفهرس المعكوس,فهرس عكسي,倒排索引,倒排索引,倒排索引,inverser l'indice,index inversé,index inversé,インデックスを反転する,転置インデックス (tenchi indekkusu),逆インデックス,инвертировать индекс,инвертированный индекс,инвертированный индекс
2247,invert list,قائمة عكس,قائمة معكوسة,قائمة معكوسة,倒置列表,倒排表,倒排列表,inverser la liste,liste inversée,liste inversée,リストを反転する,反転リスト,逆リスト,инвертировать список,обратный список,обращенный список
2248,invertible map,خريطة قابلة للعكس,- المسار العكسي,خريطة قابلة للعكس,可逆地图,可逆映射,可逆映射,carte inversible,carte inversible,application inversible,反転可能な地図,可逆な写像 (invertible map),可逆写像,обратимая карта,обратимое отображение,обратимое отображение
2249,invertible matrix,مصفوفة عكسية,مصفوفة قابلة للاستدارة,مصفوفة قابلة للانعكاس,可逆矩阵,可逆矩阵,可逆矩阵,matrice inversible,matrice inversible,matrice inversible,可逆行列,可逆行列,可逆行列,обратимая матрица,обратимая матрица,обратимая матрица
2250,iobj,com.iobj,منفعل فاعل غير مباشر,أداة جر غير مباشرة,目标,iobj,间接宾语,iobj,"""Pour les expressions de relation, nous développons sur les bords advmod, mod, aux, auxpass, cop, prt. Nous incluons également dobj et iobj dans le cas où ils ne sont pas dans un argument. Après avoir identifié les mots en arg/relation, nous choisissons leur ordre comme dans la phrase originale.""",objet indirect,iobj,間接目的語,間接目的語,iobj,iobj - косвенный объект,iobj - косвенное дополнение
2251,iso-surface extraction,استخراج سطح ايزو,استخراج سطح الآيزو (iso-surface extraction),استخراج سطح متساوي المستوى,等值面提取,等值面提取,等值面提取,extraction iso-surface,extraction d'iso-surface,extraction de surface iso,等値面抽出,等値面抽出 (tōtai-men chushutsu),等値面抽出,извлечение изо-поверхностей,извлечение изо-поверхности,изолинейная экстракция
2252,isotropic Gaussians,غاوسيين الخواص,متوزان غاوسيانية,توزيعات جاوسية متجانسة,各向同性高斯分布,各向同性高斯函数,各向同性高斯分布,Gaussiennes isotropes,gaussiennes isotropes,Gaussiennes isotropes,等方性ガウス,等方性ガウス分布,等方性ガウス分布,изотропные гауссианы,изотропные гауссовы функции,изотропные гауссовские распределения
2253,itemset,itemset,مجموعة العناصر,مجموعة عناصر,项集,项集,项集,ensemble d'éléments,Ensemble d'éléments,ensemble d'éléments,アイテムセット,アイテムセット,アイテムセット,набор элементов,набор элементов,набор элементов
2254,iterate,أعاد,التكرار,تكرار,迭代,迭代,迭代,répéter,itérer,itérer,反復する,反復,反復,повторять,итерация,Итерировать
2255,iterate conditional mode,تكرار الوضع الشرطي,وضعية التكرار المشروط,تكرار الوضع الشرطي,迭代条件模式,迭代条件模式,迭代条件模式 (ICM),itérer en mode conditionnel,mode conditionnelle itérée,modes conditionnels itérés,条件付き反復モード,繰り返し条件付きモード (ICM),反復条件付きモード / ICM,итерация условного режима,итеративный условный режим,итерированный условный режим
2256,iteration,تكرار,- التكرار,تكرار,迭代,迭代,迭代,itération,itération,itération,反復,反復,反復,итерация,итерация,итерация
2257,iteration complexity,تعقيد التكرار,تعقيد التكرار,معقدية التكرار,迭代复杂度,迭代复杂度,迭代复杂度,complexité de l'itération,complexité de l'itération,complexité des itérations,反復の複雑さ,反復の複雑性,イテレーション複雑度,сложность итерации,сложность итерации,сложность итерации
2258,iteration counter,عداد التكرار,عداد التكرار,عداد التكرار,迭代计数器,迭代计数器,迭代计数器,compteur d'itérations,compteur d'itération,compteur d'itération,反復カウンタ,繰り返し回数,反復カウンター,счетчик итераций,счётчик итераций,счетчик итераций
2259,iterative algorithm,خوارزمية تكرارية,خوارزمية تكرارية,خوارزمية تكرارية,迭代算法,迭代算法,迭代算法,algorithme itératif,algorithme itératif,algorithme itératif,反復アルゴリズム,反復アルゴリズム,反復アルゴリズム,итерационный алгоритм,итерационный алгоритм,итеративный алгоритм
2260,iterative deepening,تعميق متكرر,التعميق التكراري,تعميق متكرر,迭代深化,迭代加深,迭代深化,approfondissement itératif,approfondissement itératif,Approfondissement itératif,反復的な深化,反復深化,反復深化探索,итеративное углубление,Итеративное углубление,итеративное углубление
2261,iterative optimization,التحسين التكراري,التحسين التكراري,تحسين تكراري,迭代优化,迭代优化,迭代优化,optimisation itérative,optimisation itérative,optimisation itérative,反復最適化,反復最適化,反復最適化,итеративная оптимизация,итерационная оптимизация,итеративная оптимизация
2262,iterative optimization algorithm,خوارزمية التحسين التكرارية,- تحسين خوارزمية التكرارية,خوارزمية التحسين التكرارية,迭代优化算法,迭代优化算法,迭代优化算法,algorithme d'optimisation itératif,algorithme d'optimisation itératif,algorithme d'optimisation itératif,反復最適化アルゴリズム,反復最適化アルゴリズム (hanpuku saitekika arugorizumu),反復最適化アルゴリズム,алгоритм итеративной оптимизации,итерационный алгоритм оптимизации,Итеративный оптимизационный алгоритм
2263,iterative training algorithm,خوارزمية التدريب التكراري,خوارزمية التدريب التكراري,خوارزمية التدريب التكراري,迭代训练算法,迭代训练算法,迭代训练算法,algorithme de formation itératif,algorithme d'entraînement itératif,algorithme d'entraînement itératif,反復トレーニングアルゴリズム,イテレーティブトレーニングアルゴリズム (Iterative Training Algorithm),反復的訓練アルゴリズム,итерационный алгоритм обучения,итерационный алгоритм обучения,итеративный алгоритм обучения
2264,iteratively reweighte least square,أعيد وزنها بشكل متكرر المربع الأصغر,أصغر مربعات موزونة بشكل تكراري,المربعات الصغرى المعاد ترجيحها تكراريًا,迭代重新加权最小二乘法,迭代重新加权最小二乘,迭代重赋权最小二乘法,moindres carrés repondérés itérativement,moindres carrés repondérés de manière itérative,moindres carrés pondérés de manière itérative,反復的に再重み付けされた最小二乗,反復重み付き最小二乗法,反復的に再重み付けされた最小二乗法,итеративно перевзвешенный метод наименьших квадратов,Итерационная перевзвешенная метод наименьших квадратов,итеративно перевзвешенные наименьшие квадраты
2265,jaccard similarity,تشابه الجاكار,التشابه جاكارد,مقارنة جاكارد,杰卡德相似度,Jaccard相似度,杰卡德相似性,similitude jaccard,similarité de Jaccard,similitude de Jaccard,ジャカードの類似性,Jaccard 類似度,ジャッカード類似度,жаккардовое сходство,коэффициент Жаккара,коэффициент Жаккара
2266,jaccard similarity coefficient,معامل التشابه جاكارد,معامل تشابه جاكارد,معامل تشابه جاكارد,杰卡德相似系数,Jaccard相似系数,Jaccard相似系数,coefficient de similarité de Jaccard,- Coefficient de similarité de Jaccard,coefficient de similarité de Jaccard,ジャカード類似係数,Jaccard 類似係数,ジャカール類似性係数,коэффициент подобия Жаккара,коэффициент сходства Жаккара,коэффициент подобия Жаккара
2267,jacobian matrix,مصفوفة يعقوبية,مصفوفة جاكوبيان,مصفوفة جاكوبيان,雅可比矩阵,雅可比矩阵,雅可比矩阵,matrice jacobienne,matrice jacobienne,matrice jacobienne,ヤコビアン行列,ヤコビアン行列,ヤコビアン行列,матрица Якобиана,матрица Якоби,матрица Якоби
2268,joint density,كثافة المفاصل,الكثافة المشتركة,الكثافة المشتركة,关节密度,联合密度,联合密度,densité des joints,densité jointe,densité jointe,接合密度,共同密度,同時密度,плотность суставов,совместная плотность,совместная плотность
2269,joint distribution,توزيع المشترك,التوزيع المشترك,توزيع مشترك,联合分配,联合分布,联合分布,distribution conjointe,distribution conjointe,Distribution conjointe,共同配布,共同分布,同時分布,совместное распределение,совместное распределение,Совместное распределение
2270,joint embedding space,مساحة التضمين المشترك,المساحة المشتركة للتضمين,فضاء التضمين المشترك,联合嵌入空间,联合嵌入空间,联合嵌入空间,espace d'encastrement commun,espace d'incrustation conjoint,espace d'intégration conjoint,関節包埋空間,共有埋め込み空間 (kyou yuu ume komeru kuu kan),共同埋め込み空間,совместное пространство для установки,- Совместное вложенное пространство,совместное embedding-пространство
2271,joint encoding,الترميز المشترك,الترميز المشترك,ترميز مشترك,联合编码,联合编码,联合编码,codage conjoint,encodage conjoint,codage conjoint,ジョイントエンコーディング,共同符号化,共同エンコーディング,совместное кодирование,совместное кодирование,совместное кодирование
2272,joint entropy,الانتروبيا المشتركة,التشريك الانحداري,الاحتواء المشترك,联合熵,联合熵,联合熵,entropie conjointe,- Entropie conjointe,entropie jointe,結合エントロピー,共通エントロピー,結合エントロピー,совместная энтропия,совместная энтропия,совместная энтропия
2273,joint inference,الاستدلال المشترك,الاستدلال المشترك,استنتاج مشترك,联合推理,联合推理,联合推理,inférence conjointe,inférence conjointe,inférence jointe,共同推論,共同推論 (Joint Inference),結合推論,совместный вывод,совместный вывод,совместное вывод
2274,joint learning,التعلم المشترك,التعلم المشترك,- التعلم المشترك,共同学习,联合学习,联合学习,apprentissage conjoint,apprentissage conjoint,apprentissage conjoint,共同学習,共同学習,共同学習,совместное обучение,совместное обучение,совместное обучение
2275,joint learning algorithm,خوارزمية التعلم المشترك,خوارزمية التعلم المشترك,خوارزمية التعلم المشترك,联合学习算法,联合学习算法,联合学习算法,algorithme d'apprentissage conjoint,algorithme d'apprentissage conjoint,algorithme d'apprentissage conjoint,共同学習アルゴリズム,共同学習アルゴリズム (Kyōdō Gakushū Arugorizumu),共同学習アルゴリズム,алгоритм совместного обучения,алгоритм совместного обучения,алгоритм совместного обучения
2276,joint likelihood,احتمال مشترك,الاحتمال المشترك,احتمالية مشتركة,联合似然,联合似然,联合似然,probabilité conjointe,vraisemblance conjointe,vraisemblance jointe,同時尤度,共同尤度,結合尤度,совместная вероятность,совместная вероятность,совместная правдоподобность
2277,joint model,نموذج مشترك,النموذج المشترك,نموذج مشترك,联合模型,联合模型,联合模型,modèle commun,modèle conjoint,modèle conjoint,ジョイントモデル,共通モデル,結合モデル,совместная модель,совместная модель,объединенная модель
2278,joint policy,سياسة مشتركة,السياسة المشتركة,سياسة مشتركة,联合政策,联合策略,联合策略,politique commune,politique conjointe,politique conjointe,共同政策,共同方針,共同ポリシー,совместная политика,совместная стратегия,совместная политика
2279,joint probability,الاحتمال المشترك,احتمالية مشتركة,احتمال مشترك,联合概率,联合概率,联合概率,probabilité conjointe,probabilité conjointe,probabilité conjointe,同時確率,共同確率,共同確率,совместная вероятность,совместная вероятность,совместная вероятность
2280,joint probability distribution,التوزيع الاحتمالي المشترك,التوزيع المشترك للإحتمالات,توزيع الاحتمال المشترك,联合概率分布,联合概率分布,联合概率分布,distribution de probabilité conjointe,distribution de probabilité conjointe,distribution de probabilité conjointe,同時確率分布,共通確率分布,同時確率分布,совместное распределение вероятностей,совместное распределение вероятностей,совместное распределение вероятностей
2281,joint probability matrix,مصفوفة الاحتمالية المشتركة,مصفوفة احتمال مشتركة,مصفوفة الاحتمال المشترك,联合概率矩阵,联合概率矩阵,联合概率矩阵,matrice de probabilité conjointe,matrice de probabilité jointe,matrice de probabilité jointe,同時確率行列,共同確率行列,共同確率行列,совместная матрица вероятностей,- Совместная матрица вероятностей,матрица совместной вероятности
2282,joint probability table,جدول الاحتمال المشترك,جدول احتمال مشترك,جدول الاحتمالات المشتركة,联合概率表,联合概率表,联合概率表,table de probabilité conjointe,Table de probabilités conjointes,table de probabilité jointe,同時確率テーブル,共通確率表,共同確率表,совместная таблица вероятностей,совместная таблица вероятностей,совместная таблица вероятностей
2283,joint semantic space,الفضاء الدلالي المشترك,المساحة الدلالية المشتركة,الفضاء الدلالي المشترك,联合语义空间,联合语义空间,联合语义空间,espace sémantique commun,- Espace sémantique commun,espace sémantique conjoint,共同意味空間,共有意味空間 (kyouyou imi kuukan),共同意味空間,совместное смысловое пространство,- Совместное семантическое пространство,совместное семантическое пространство
2284,junction tree,شجرة الوصل,- تركيبة نقطة التقاء,شجرة العقد,连接树,连接树,连接树,arbre de jonction,arbre de jonction,arbre de jonction,ジャンクションツリー,接続木,接続木,дерево соединений,дерево соединений,Деревье соединений
2285,junction tree algorithm,خوارزمية شجرة الوصلات,"""تم حل مشاكل MAP باستخدام خوارزمية شجرة التفرع الدقيقة (JCT ، اليسار واليمين) ، أو انتشار الاعتقاد التقريبي (BP ، الوسط). في جميع الحالات ، ع",نظرية الشجرة الواصلة,连接树算法,联结树算法 (junction tree algorithm),junction tree 算法,algorithme d'arbre de jonction,algorithme de l'arbre de jonction,algorithme de l'arbre de jonction,ジャンクションツリーアルゴリズム,接点木アルゴリズム (junction tree algorithm),結合木アルゴリズム,алгоритм дерева соединений,алгоритм дерева соединений,Алгоритм объединенного дерева
2286,k near neighbor,ك أقرب جار,k أقرب جار,أقرب جار k,k 最近邻,k近邻,k近邻,k voisin le plus proche,k plus proche voisin,k plus proches voisins,k 最近隣の人,k近傍点,k近傍,к ближайший сосед,k ближайших соседей,k ближайших соседей
2287,k-center,مركز ك,- تقنية k-المركزية,مركز-ك,k中心,k-中心,k中心,k-centre,k-center,k-centre,K-センター,k-センター,k中心,k-центр,"""['Предыдущие исследования по кластеризации потоковых данных в основном сосредоточены на поиске однопроходных приближений к алгоритмам k-центра. Гуха и др. (2003) разрабатывают приближение с постоянным коэффициентом для кластеризации k-меди",k-центр
2288,k-d tree,شجرة ك-د,شجرة k-d,شجرة k-d,k-d树,k-d 树,k-d树,arbre kd,arbre k-d,arbre k-d,k-dツリー,k-dツリー,k-d木,к-д дерево,k-d дерево,k-d дерево
2289,k-good list,قائمة ك جيدة,قائمة k-good,قائمة أفضل k,k-好清单,k-好列表,k-最优候选列表,k-bonne liste,liste k-meilleure,listes des k-meilleurs,良いリスト,k-良好リスト,k-best リスト,к-хороший список,k-хороший список,список k-наилучших
2290,k-good parsing,ك-تحليل جيد,- تحليل k-جيد,تحليل ك-الجيد,k-好解析,k优解析,k-最佳分析,k-bonne analyse,Analyse k-bonne,analyse k-meilleurs,k-good 解析,k良い解析,k最良構文解析,k-хороший разбор,k-хороший синтаксический анализ,k-хорошее разбор
2291,k-hop neighbor,جار الكي هوب,الجار المتباعد بـ k قفزة,جار في مسافة k,k跳邻居,k-跳邻居,k跳邻居,voisin k-hop,voisin k-hop,voisin à k sauts,Kホップネイバー,k-ホップ隣接点,k-ホップ近傍,сосед по к-хопу,"""[""Этот феномен, называемый 'пересжатием', эвристически приписывается графическим узким местам, где количество k-шаговых соседей быстро растет с k. Мы предоставляем точное описание феномена пересжатия в ГНС и анализируем, как он возникает из узких мест",соседи на расстоянии k-хопов
2292,k-l divergence,ك-ل الاختلاف,انحراف كليبلر-لايبلر,تباين كولباك-ليبلر,k-l散度,K-L 散度,k-l散度,divergence k-l,divergence de K-L,divergence de Kullback-Leibler,k-l ダイバージェンス,K-L ダイバージェンス,KL情報量 (KL-ジョウホウリョウ),k-l расхождение,дивергенция Кульбака-Лейблера,k-l расхождение
2293,k-mean,ك-يعني,"""['نظرًا لعدم مشاركة القيود في إعادة تقدير ممثلي العنقود ، يظل هذا الخطوة هو نفسها كما هو الحال في K-Means للانحرافات بريجمان ، ونفسها كما هو الحال في SPKMEANS لتشابه ال",المُعَدِّل-ك,k均值,K-均值,k-均值聚类法,k-moyenne,k-moyenne,k-moyennes,K平均,"""['制約がクラスター代表値の再推定に関与しないため、このステップはブレグマンの分散の場合と同じであり、加重コサイン類似性のSPKMEANSの場合と同じです。次に、歪み尺度のパラメータ化された変種が使用された場合、', '結果が示すように、",k平均法,k-среднее,k-средних,k-средних
2294,k-mean algorithm,خوارزمية k-mean,خوارزمية الـ k-متوسط,خوارزمية k-mean,k均值算法,K均值算法,k-均值算法,algorithme k-moyenne,algorithme de k-moyennes,Algorithme des k-moyennes,K 平均アルゴリズム,K-平均アルゴリズム,k-平均アルゴリズム,алгоритм k-среднего,алгоритм k-средних,Алгоритм к-средних
2295,k-mean clustering,ك يعني التجميع,- التجميع بوساطة القيم الأقرب (k-mean clustering),تجميع ك-المتوسطات,k均值聚类,K均值聚类,k-均值聚类,clustering k-moyenne,regroupement k-moyennes,Partitionnement k-moyennes,K 平均クラスタリング,K-平均クラスタリング,k-平均クラスタリング,k-средняя кластеризация,k-средних кластеризация,Кластеризация k-средних
2296,k-means clustering algorithm,k-يعني خوارزمية التجميع,- تجميع البيانات بواسطة خوارزمية k-means,خوارزمية تجميع k-means,k-均值聚类算法,k均值聚类算法,k-均值聚类算法,algorithme de clustering k-means,algorithme de regroupement k-means,Algorithme de clustering k-moyennes,K-means クラスタリング アルゴリズム,k-平均 クラスタリング アルゴリズム,k平均クラスタリング法,алгоритм кластеризации k-средних,алгоритм кластеризации k-средних,алгоритм кластеризации k-средних
2297,k-nearest neighbor,ك-أقرب جار,"""تعتمد فئة العلامات المتعددة الجماعية (CML) (Ghamrawi و McCallum ، 2005) على مبدأ الانحراف الأقصى للتعامل مع البيانات متعددة العلامات من خلال ترميز ترابطات العلامات كشروط قيد. ي",أقرب جار,k-最近邻,K最近邻,k-最近邻,k-voisin le plus proche,k-plus proche voisin,plus proches voisins,k最近隣,semi-supervised clustering and k最近,k最近傍,k-ближайший сосед,"""['Коллективный мультиклассификатор (CML) (Гамрави и Маккалум, 2005) принимает принцип максимальной энтропии для работы с мультиклассовыми данными, кодируя корреляции меток как условия ограничений. Чжан и Чжоу (2007) использую",k-ближайших соседей
2298,k-nearest neighbor classifier,k-أقرب مصنف جار,- تصنيف الجار الأقرب k,مصنف أقرب جار-k,k-最近邻分类器,k最近邻分类器,k-近邻分类器,classificateur du k-voisin le plus proche,classificateur des k plus proches voisins,classificateur des k plus proches voisins,k最近傍分類器,k近傍分類器,k近傍分類器,k-классификатор ближайших соседей,классификатор k-ближайших соседей,k-ближайший соседний классификатор
2299,k-nearest neighbor graph,k-أقرب رسم بياني للجيران,الرسم البياني لأقرب الجيران k,رسم أقرب جار k,k-最近邻图,k最近邻图,k-最近邻图,graphique du k-voisin le plus proche,graphe des k-plus proches voisins,graphe des k plus proches voisins,k最近傍グラフ,k近傍グラフ,k近傍グラフ,граф k-ближайших соседей,k-ближайший сосед граф,граф k-ближайших соседей
2300,kernel,نواة,نواة,نواة,核心,核函数,核,noyau,noyau,noyau,カーネル,カーネル,カーネル,ядро,ядро,ядро
2301,kernel approximation,تقريب النواة,- تقريب النواة,ترجمة تقريب النواة,核近似,核近似,核近似,approximation du noyau,approximation du noyau,approximation noyau,カーネル近似,カーネル近似 (kāneru kinji),カーネル近似,приближение ядра,аппроксимация ядра,ядерное приближение
2302,kernel bandwidth,عرض النطاق الترددي للنواة,عرض اللبنة,حزمة النواة,内核带宽,内核带宽 (kernel bandwidth),核带宽,bande passante du noyau,largeur de bande du noyau,noyau de lissage,カーネル帯域幅,カーネル帯域 (kaaneru taiiki),カーネル帯域幅,пропускная способность ядра,ширина ядра,Ширина ядра
2303,kernel classifier,مصنف النواة,مصنف النواة,مصنف النواة,核分类器,核分类器,核分类器,classificateur de noyau,classifieur à noyau,classificateur à noyau,カーネル分類子,カーネル分類器 (ka-neru bunkaiki),カーネル分類器,классификатор ядра,ядерный классификатор,ядерный классификатор
2304,kernel density,كثافة النواة,الكثافة النواة,كثافة النواة,核密度,核密度,核密度估计,densité du noyau,densité du noyau,densité de noyau,カーネル密度,カーネル密度,カーネル密度推定,плотность ядра,ядерная плотность,плотность ядра
2305,kernel density estimate,تقدير كثافة النواة,- تقدير كثافة النواة,تقدير كثافة النواة,核密度估计,核密度估计,核密度估计,estimation de la densité du noyau,estimation de densité de noyau,estimation par noyau de densité,カーネル密度の推定,カーネル密度推定 (kernel density estimate),カーネル密度推定,оценка плотности ядра,оценка плотности ядра,оценка плотности ядра
2306,kernel density estimation,تقدير كثافة النواة,تقدير كثافة النواة,تقدير كثافة النواة,核密度估计,核密度估计,核密度估计,estimation de la densité du noyau,Estimation de densité noyau,estimation par noyau de densité,カーネル密度の推定,カーネル密度推定 (kernel density estimation),カーネル密度推定,оценка плотности ядра,ядерная оценка плотности,ядерная оценка плотности
2307,kernel evaluation,تقييم النواة,تقييم النواة,تقييم النواة,内核评估,核函数评估,核函数评估,évaluation du noyau,évaluation du noyau,évaluation du noyau,カーネル評価,カーネル評価 (kaaneru hyouka),カーネル評価,оценка ядра,оценка ядра,оценка ядра
2308,kernel function,وظيفة النواة,وظيفة النواة,دالة النواة,核函数,核函数,核函数,fonction du noyau,fonction noyau,fonction noyau,カーネル関数,カーネル関数 (ka-naru kansu),カーネル関数,функция ядра,функция ядра,ядерная функция
2309,kernel learning,تعلم النواة,تعلم النواة,تعلم النواة,内核学习,核学习,核学习,apprentissage du noyau,apprentissage du noyau,apprentissage noyau,カーネル学習,カーネル学習 (kernel learning),カーネル学習,обучение ядру,ядерное обучение,обучение ядер
2310,kernel learning problem,مشكلة تعلم النواة,مشكلة تعلم النواة,مشكلة تعلم النواة,核学习问题,核学习问题,核学习问题,problème d'apprentissage du noyau,problème d'apprentissage du noyau,problème d'apprentissage de noyau,カーネル学習の問題,カーネル学習問題 (kaaneru gakushuu mondai),カーネル学習問題,проблема с обучением ядра,проблема обучения ядра,проблема обучения ядра
2311,kernel machine,آلة النواة,آلة النواة,ماكينة النواة,内核机,核机器,核机器,machine à noyau,machine à noyau,machine à noyau,カーネルマシン,カーネルマシン,カーネル機械,ядро машины,ядро машины,ядерная машина
2312,kernel matrix,مصفوفة النواة,مصفوفة النواة,مصفوفة النواة,核矩阵,核矩阵 (Kernel Matrix),核矩阵,matrice du noyau,- Matrice noyau,matrice noyau,カーネルマトリックス,カーネル行列 (kāneru gyōretsu),カーネル行列,матрица ядра,ядро матрицы,ядерная матрица
2313,kernel method,طريقة النواة,طريقة النواة,طريقة النواة,核方法,核方法,核方法,méthode du noyau,méthode du noyau,méthode à noyau,カーネルメソッド,カーネル法 (ka-naru hou),カーネル法,метод ядра,метод ядра,метод ядер
2314,kernel operation,عملية النواة,عملية النواة,عملية النواة,内核操作,核操作,核操作,opération du noyau,- Opération de noyau,opération de noyau,カーネルの操作,カーネル演算,カーネル演算,работа ядра,ядро операции,ядерная операция
2315,kernel operator,مشغل النواة,مشغل النواة,تشغيل النواة,核运算符,核算子,核算子,opérateur du noyau,opérateur de noyau,noyau opérateur,カーネルオペレータ,カーネル演算子,カーネル演算子,оператор ядра,оператор ядра,оператор ядра
2316,kernel parameter,معلمة النواة,- تعديل النواة,المعلمة الحشوية,内核参数,核参数,核参数,paramètre du noyau,paramètre du noyau,paramètre de noyau,カーネルパラメータ,カーネルパラメータ,カーネルパラメータ,параметр ядра,параметр ядра,ядерный параметр
2317,kernel regression,انحدار النواة,- معالجة النواة,انحدار النواة,核回归,核回归 (kernel regression),核回归,régression du noyau,régression du noyau,régression de noyau,カーネル回帰,カーネル回帰 (kernel regression),カーネル回帰,регрессия ядра,ядро регрессии,Ядерная регрессия
2318,kernel ridge regression,انحدار ريدج النواة,تنويع النواة باستخدام تقنية الترجيع الأعظمية,انحدار الانتشار الصلب,核岭回归,核岭回归,核岭回归,régression de crête de noyau,régression ridge du noyau,régression crête du noyau,カーネルリッジ回帰,カーネルリッジ回帰,カーネル時系列回帰,регрессия гребня ядра,"""['Это очень мощный метод, поскольку он позволяет полностью байесовский подход к регрессии, последовательный подход к изучению ядра через маргинальное правдоподобие (детали см. в [26]), и интервалы неопределенности для апостериорных значений. Мы сразу",Ядерная гребневая регрессия
2319,kernel size,حجم النواة,حجم النواة,حجم النواة,内核大小,核大小,卷积核尺寸,taille du noyau,- Taille du noyau,taille du noyau,カーネルサイズ,カーネルサイズ,カーネルサイズ,размер ядра,размер ядра,размер ядра
2320,kernel smoothing,تجانس النواة,- المعالجة النواةية,تملیس النواة,核平滑,核平滑,核平滑,lissage du noyau,lissage de noyau,lissage par noyau,カーネルスムージング,カーネル平滑化 (kernel smoothing),カーネル平滑化,сглаживание ядра,сглаживание ядра,сглаживание ядром
2321,kernel space,مساحة النواة,مساحة النواة,مساحة النواة,内核空间,内核空间,核空间,espace noyau,espace noyau,espace noyau,カーネルスペース,カーネル空間 (kaaneru kuukan),カーネル空間,пространство ядра,пространство ядра,пространство ядра
2322,kernel spectrum,طيف النواة,طيف النواة,طيف النواة,核谱,核谱,核谱,spectre du noyau,spectre du noyau,spectre du noyau,カーネルスペクトル,カーネルスペクトル,カーネルスペクトル,спектр ядра,спектр ядра,ядерный спектр
2323,kernel trick,خدعة النواة,الحيلة النواة,خدعة النواة,内核技巧,核技巧,核技巧,astuce du noyau,astuce du noyau,astuce du noyau,カーネルトリック,カーネルトリック,カーネル トリック,трюк с ядром,Ядро трюк,ядерный трюк
2324,kernel value,قيمة النواة,قيم النواة,قيمة النواة,核值,核值,核值,valeur du noyau,valeur du noyau,valeur du noyau,カーネル値,カーネル値 (Kernel Value),カーネル値,значение ядра,значение ядра,значения ядра
2325,kernel weight,وزن النواة,وزن النواة,وزن النواة,粒重,核权重,核权重,poids du grain,- Poids du noyau,poids du noyau,カーネル重量,カーネル重み (kaaneru omomi),カーネル重み (kāneru jūmi),вес ядра,вес ядра,вес ядра
2326,kernel width,عرض النواة,عرض النواة,عرض النواة,内核宽度,核宽度,核宽度,largeur du noyau,largeur du noyau,largeur du noyau,カーネル幅,カーネル幅,カーネル幅,ширина ядра,ширина ядра,ширина ядра
2327,kernel-base classification,تصنيف قاعدة النواة,التصنيف بناءً على النواة,تصنيف قائم على النواة,基于内核的分类,核心基分类,核基分类,classification basée sur le noyau,Classification basée sur le noyau,classification à noyau de base,カーネルベースの分類,カーネルベース分類 (kernel-base classification),カーネルベース分類,классификация на основе ядра,классификация на основе ядра,классификация на основе ядра
2328,key,مفتاح,مفتاح,مفتاح,钥匙,关键,密钥,clé,clé,clé,鍵,キー,キー,ключ,ключ,ключ
2329,keypoint,النقطة الأساسية,نقطة مفتاحية,نقطة مفتاحية,关键,关键点,关键点,point clé,point clé,point clé,キーポイント,キーポイント,キーポイント,ключевой момент,ключевая точка,сопоставляющие точки
2330,keypoint detection,كشف نقطة المفاتيح,الكشف عن نقاط المفتاح,كشف النقاط المفتاحية,关键点检测,关键点检测 (keypoint detection),关键点检测,détection de points clés,détection de points clés,détection de points clés,キーポイント検出,キーポイント検出,重要ポイント検出,обнаружение ключевых точек,обнаружение ключевых точек,детекция ключевых точек
2331,keypoint detector,كاشف النقطة الرئيسية,مكتشف نقطة مفتاحية,كاشف النقاط الرئيسية,关键点检测器,关键点检测器,关键点检测器,détecteur de points clés,- Détecteur de points clés,Détecteur de points clés,キーポイント検出器,キーポイント検出器 (kīpointo kenshutsuki),キーポイント検出器,детектор ключевых точек,детектор ключевых точек,ключевой детектор
2332,keypoint location,موقع النقطة الرئيسية,مواقع نقطة المفتاح,موقع النقطة المفتاحية,关键点位置,关键点位置,关键点位置,emplacement du point clé,Localisation des points clés,emplacement des points clés,キーポイントの位置,キーポイントの位置,特徴点位置,местоположение ключевой точки,расположение ключевых точек,местоположение ключевой точки
2333,keypoint match,مباراة النقطة الرئيسية,مطابقة النقاط الرئيسية,مطابقة نقاط مفتاحية,关键点匹配,关键点匹配,关键点匹配,correspondance de points clés,correspondance de points clés,correspondance de points clés,キーポイントの一致,キーポイントマッチ,重要点の一致,совпадение по ключевым точкам,соответствие ключевых точек,Согласование ключевых точек
2334,knapsack problem,مشكلة الحقيبة,مشكلة الحقيبة الخاصة,مشكلة الحقيبة,背包问题,背包问题,背包问题,problème de sac à dos,problème du sac à dos,problème du sac à dos,ナップサック問題,ナップザック問題 (Napuzakku mondai),ナップサック問題,проблема с рюкзаком,Проблема рюкзака,задача о рюкзаке
2335,knowledge Base,قاعدة المعرفة,قاعدة المعرفة,قاعدة المعرفة,知识库,知识库,知识库,Base de connaissances,Base de connaissances,Base de connaissances,知識ベース,ナレッジベース (Knowledge Base),知識ベース,база знаний,База знаний,база знаний
2336,knowledge compilation,تجميع المعرفة,تجميع المعرفة,ترميز المعرفة,知识汇编,知识编译,知识编译,compilation de connaissances,compilation de connaissances,compilation des connaissances,知識の編集,知識コンパイル,知識コンパイル,компиляция знаний,компиляция знаний,компиляция знаний
2337,knowledge distillation,تقطير المعرفة,تقليل المعرفة,تقطير المعرفة,知识蒸馏,知识蒸馏,知识蒸馏,distillation des connaissances,distillation des connaissances,distillation des connaissances,知識の蒸留,知識蒸留,知識蒸留,дистилляция знаний,дистилляция знаний,передача знаний
2338,knowledge element,عنصر المعرفة,عنصر المعرفة,عنصر المعرفة,知识要素,知识元素,知识元素,élément de connaissance,élément de connaissance,élément de connaissance,知識要素,知識要素 (ちしきようそ),知識要素,элемент знаний,элемент знания,элемент знаний
2339,knowledge graph,الرسم البياني المعرفي,رسم معرفي للمعرفة,رسم المعرفة,知识图谱,知识图谱,知识图谱,graphe de connaissances,graphe de connaissance,graphe de connaissances,ナレッジグラフ,ナレッジグラフ (Knowledge Graph),知識グラフ,граф знаний,граф знаний,граф знаний
2340,knowledge graph completion,استكمال الرسم البياني المعرفي,اكمال رسم البيانات الخاص بالمعرفة,استكمال الرسم البياني للمعرفة,知识图谱补全,知识图谱补全,知识图谱补全,complétion du graphe de connaissances,complétion de graphes de connaissances,complétion de graphe de connaissances,ナレッジグラフの完成,ナレッジグラフ補完 (knowledge graph completion),知識グラフ補完,завершение графика знаний,завершение графа знаний,завершение графа знаний
2341,knowledge representation,تمثيل المعرفة,تمثيل المعرفة,تمثيل المعرفة,知识表示,知识表示,知识表示,représentation des connaissances,représentation des connaissances,représentation des connaissances,知識表現,知識表現,知識表現,представление знаний,представление знаний,представление знаний
2342,knowledge transfer,نقل المعرفة,نقل المعرفة,نقل المعرفة,知识传输,知识转移 (knowledge transfer),知识迁移,le transfert de connaissances,transfert de connaissances,transfert de connaissances,知識の伝達,知識の転送 (Chishiki no Tensō),知識転移,обмен знаниями,передача знаний,передача знаний
2343,l 1 -norm,ل 1 - القاعدة,النورم L1,مقياس L1,l 1 -范数,L1-范数,l1范数,l 1 -norme,norme L1,norme L1,l 1 -ノルム,L1ノルム,l1ノルム,л 1 -норма,L 1 -норм,l₁-норма
2344,l 1 distance,ل 1 المسافة,المسافة L1,مسافة L1,l 1距离,L1距离,L1距离,l 1 distance,distance L 1,distance L1,l 1 距離,L1距離,l1距離,л 1 расстояние,L1 расстояние,L1 расстояние
2345,l 2 -norm,ل 2 - القاعدة,الصيغة L 2 -norm,مُعيار l2,l 2 -范数,L 2-范数,L2范数,l 2 -norme,norme L2,norme L2,l 2 -ノルム,L 2 -ノルム,L2ノルム,л 2 -норма,L 2-норм,L2-норма
2346,l 2 distance,ل 2 المسافة,المسافة L 2,مسافة الاقتران الثاني,l 2 距离,L2距离,L2距离,l 2 distance,distance L2,distance L2,l2距離,L2距離,L2距離,л 2 расстояние,расстояние L2,расстояние l2
2347,l 2 loss,ل 2 خسارة,فقدان L2,خسارة إل ٢,l 2 损失,L 2 损失,L2损失,l 2 perte,perte L2,perte L2,l 2 損失,L 2損失,l2損失,л 2 потеря,потери L2,l2 потери
2348,l 2 regularization,ل 2 التسوية,التنظيم L 2,تنظيم L2,l 2 正则化,L 2 正则化,l2正则化,l 2 régularisation,régularisation L2,régularisation L2,l 2 正則化,L2 正則化,L2正則化,l 2 регуляризация,L 2 регуляризация,L 2 регуляризация
2349,l ∞ norm,ل ∞ القاعدة,المعيار اللامتناهي (L ∞),مُعيار لا-نهاية,l ∞ 范数,L∞范数,l∞范数,l ∞ norme,norme L ∞,norme l∞,l ∞ ノルム,L ∞ ノルム,l∞ノルム,l ∞ норма,L ∞ норма,нормa l∞
2350,l1 bind,ربط l1,الحد الأولية,حد l1,l1 绑定,L1 约束,l1约束,liaison l1,liaison L1,borne l1,l1バインド,L1バインド,l1束縛,l1 привязка,привязка l1,L1 связь
2351,l1 difference,الفرق l1,الفارق L1,فرق l1,l1 差异,L1差异,l1差异,différence l1,différence L1,différence l1,l1の差,L1 差異,l1差異,l1 разница,разница L1,l1 разность
2352,l1 loss,الخسارة L1,فقد l1,خسارة l1,l1损失,L1 损失,L1损失,perte l1,perte L1,perte l1,l1損失,L1損失,l1損失,потеря l1,L1 потеря,L1 потеря
2353,l1 penalty,عقوبة L1,عقوبة L1,عقوبة ال1,l1惩罚,L1 惩罚,l1惩罚,pénalité l1,pénalité L1,pénalité l1,l1 ペナルティ,L1 ペナルティ,l1ペナルティ,l1 штраф,"""['К сожалению, OGD не особенно эффективен в создании разреженных моделей. Фактически, простое добавление субградиента L1 штрафа к градиенту потерь (wt(w)) в основном никогда не приведет к коэффициентам, которые равны нулю. Более сложные подход",l1 штраф
2354,l1 regularization,تسوية L1,- التنظيم النووي المستوى 1,تنظيم L1,l1正则化,L1 正则化,l1 正则化,régularisation l1,régularisation L1,Régularisation l1,l1 正則化,L1 正則化,l1正則化,l1 регуляризация,L1 регуляризация,L1-регуляризация
2355,l1 term,مصطلح L1,المصطلح L1,مصطلح l1,l1 术语,L1项,l1项,l1 terme,terme L1,terme L1,l1期,L1項,l1項,срок l1,L1 терм,L1 член
2356,l2 error,خطأ L2,الخطأ L2,خطأ المربعات,l2错误,L2误差,l2误差,erreur l2,erreur L2,erreur quadratique moyenne,l2エラー,L2誤差,l2誤差,ошибка l2,L2 ошибка,квадратичная ошибка
2357,l2 regularisation,تسوية L2,"A bag-of-words (BoW) model that uses unigram features as input with term frequency-inverse document frequency feature selection (TF-IDF). We use SVM with a linear kernel, L2 regularisation",تنظيم إل2,l2正则化,L2 正则化,l2正则化,régularisation l2,régularisation L2,régularisation l2,l2 正則化,L2正規化,L2正則化,l2 регуляризация,L2 регуляризация,l2-регуляризация
2358,l2 regularizer,منظم L2,منظم L2,ضابط التنظيم L2,l2正则化器,L2 正则化器,L2正则化项,régularisateur l2,régulariseur L2,régularisateur L2,l2 正則化子,L2正則化者,L2正則化項,регуляризатор l2,L2 регуляризатор,регуляризатор L2
2359,l2 weight decay,l2 تسوس الوزن,تحلل الوزن L2,نحو الانحدار الوزني L2,l2权重衰减,L2权重衰减,L2正则化权重衰减,perte de poids l2,réduction de poids L2,décroissance de poids l2,l2 重量減衰,L2 重み減衰,L2重み減衰,l2 снижение веса,l2 весовое уменьшение,L2-регуляризация весов
2360,l2-normalization,l2-التطبيع,التطبيع L2,تعميم l2,l2-归一化,L2-归一化,L2正则化,normalisation l2,L2-normalisation,normalisation L2,l2-正規化,L2正規化,L2正規化,l2-нормализация,L2-нормализация,l2-нормализация
2361,label,ملصق,- تسمية,تصنيف,标签,标签,标签,étiquette,étiquette,étiquette,ラベル,ラベル,ラベル,этикетка,метка,метка
2362,label datum,مسند التسمية,البيانات المصنفة,بيانات موسومة,标签基准,标记数据,标注数据,donnée d'étiquette,donnée étiquetée,donnée étiquetée,ラベルデータム,ラベルデータ,ラベル付きデータ,данные этикетки,маркированные данные,метка данных
2363,label distribution,توزيع التسمية,توزيع التسميات,توزيع الملصقات,标签分布,标签分布,标签分布,distribution d'étiquettes,- Distribution des étiquettes,distribution des étiquettes,ラベル配布,ラベル分布,ラベル分布,распространение этикеток,распределение меток,Распределение меток
2364,label embedding,تضمين التسمية,تضمين التسمية,تضمين الوسم,标签嵌入,标签嵌入,标签嵌入,intégration d'étiquettes,incorporation d'étiquettes,incorporation d'étiquette,ラベルの埋め込み,ラベル埋め込み,可視化された埋め込みベクトル,встраивание меток,встраивание меток,векторное представление меток
2365,label example,مثال التسمية,مثال التسمية,مثال موسوم,标签示例,标签示例 (label example),标记示例,exemple d'étiquette,exemple de libellé,exemple étiqueté,ラベルの例,"""['次の主張を示します：Aの任意の段階で、これまでに表示されたラベル付き例のセットLがバージョンV = H[L]を導出する場合、Aはその後、whileループを終了する前に最大Cost(V)回の追加ラベルをクエリします。'、'帰納的仮説により、H L ∪ (x",ラベル例,пример этикетки,метка примера,меченный пример
2366,label graph,الرسم البياني التسمية,الرسم البياني الموسوم,رسم بيانات موسوم,标签图,标记图,标注图,graphique d'étiquette,graphe étiqueté,graphe étiqueté,ラベルグラフ,ラベル付きグラフ,ラベル付きグラフ,график меток,маркированный граф,помеченный граф
2367,label noise,ضجيج التسمية,ضوضاء التصنيف,ضوضاء التصنيف,标签噪声,标签噪声,标签噪音,bruit d'étiquette,bruit d'étiquetage,bruit d'étiquette,ラベルノイズ,ラベルノイズ,ラベルノイズ,шум этикетки,шум метки,шум метки
2368,label sequence,تسلسل التسمية,تسلسل العلامات,متسلسلة الملصقات,标签序列,标签序列 (label sequence),标签序列,séquence d'étiquettes,séquence d'étiquettes,séquence d'étiquettes,ラベルシーケンス,ラベルシーケンス (raberu shīkensu),ラベルシーケンス,последовательность меток,последовательность меток,последовательность меток
2369,label smoothing,تجانس التسمية,التلطيخ بالتسمية,تسوية التصنيف,标签平滑,标签平滑化,标签平滑,lissage des étiquettes,lissage des étiquettes,lissage des étiquettes,ラベルのスムージング,ラベル平滑化,ラベルスムージング,сглаживание меток,сглаживание меток,размытие меток
2370,label space,مساحة التسمية,مساحة التسمية,فضاء التصنيف,标签空间,标签空间,标签空间,espace d'étiquette,espace d'étiquettes,espace d'étiquettes,ラベルスペース,ラベルスペース (raberu supēsu),ラベル空間,пространство метки,Пространство меток,пространство меток
2371,label token,رمز التسمية,رمز التصنيف,لفظة الوسم,标签标记,标签令牌,标签token,jeton d'étiquette,jeton d'étiquette,jeton d'étiquette,ラベルトークン,ラベルトークン,ラベルトークン,токен метки,метка токен,меток токен
2372,label training datum,مسند التدريب التسمية,تسمية بيانات التدريب,بيانات التدريب الموسومة,标签训练数据,标签训练数据,标注训练数据,donnée de formation de l'étiquette,donnée d'entraînement étiquetée,donnée d'entraînement étiquetée,ラベルトレーニングデータム,ラベル付きトレーニングデータ,教師付きトレーニングデータ,данные обучения метки,метка обучающего набора данных,меченный обучающий пример
2373,label vector,ناقلات التسمية,متجه التسمية,متجه التصنيف,标签矢量,标签向量,标签向量,vecteur d'étiquette,vecteur d'étiquette,vecteur d'étiquettes,ラベルベクトル,ラベルベクトル (raberu bekutoru),ラベルベクトル,вектор этикетки,вектор меток,вектор меток
2374,lagrange multiplier,مضاعف لاغرانج,مضاعف لاجرانج,مضاعف لاجرانج,拉格朗日乘子,拉格朗日乘子,拉格朗日乘数,multiplicateur de Lagrange,multiplicateur de Lagrange,multiplicateur de Lagrange,ラグランジュ乗数,ラグランジュ乗数,ラグランジュ乗数,множитель Лагранжа,множитель Лагранжа,множитель Лагранжа
2375,lagrangian duality,ازدواجية لارانجيان,الثنائية اللاغرانجية,إزدواجية لاغرانج,拉格朗日对偶性,拉格朗日对偶,拉格朗日对偶,dualité lagrangienne,dualité lagrangienne,dualité lagrangienne,ラグランジュ双対性,ラグランジュ双対,ラグランジアン双対性,лагранжева двойственность,дуальность Лагранжа,Лагранжева двойственность
2376,lagrangian multiplier,مضاعف لارانجيان,- التضاعف لاجرانجيان,معامل لاغرانج,拉格朗日乘数,拉格朗日乘子,拉格朗日乘数,multiplicateur lagrangien,multiplicateur lagrangien,multiplicateur de Lagrange,ラグランジュ乗数,ラグランジュ乗数,ラグランジュの未定乗数,множитель Лагранжа,множитель Лагранжа,множитель Лагранжа
2377,lagrangian relaxation,استرخاء لارانجيان,الاسترخاء اللاغرانجي,ارتخاء لاغرانج,拉格朗日松弛,拉格朗日松弛,拉格朗日松弛法,relaxation lagrangienne,relaxation lagrangienne,relaxation lagrangienne,ラグランジュ緩和,ラグランジュ緩和,ラグランジュ緩和,лагранжева релаксация,Лагранжевское релаксация,Лагранжева релаксация
2378,lambda calculus,حساب التفاضل والتكامل لامدا,- معادلة لامبدا,حساب لامبدا,拉姆达演算,λ演算,lambda 演算,calcul lambda,Calcul lambda,calcul lambda,ラムダ計算,ラムダ計算 (Ryamuda keisan),ラムダ計算,лямбда-исчисление,лямбда-исчисление,Лямбда-исчисление
2379,lambertian reflectance,انعكاس لامبرت,تقدير الانعكاس لامبرتيان,انعكاس لامبرتي,朗伯反射率,朗伯反射,朗伯体反射,réflectance lambertienne,réflectance lambertienne,réflectance lambertienne,ランバート反射率,ランベルト反射,ランベルト反射,Ламбертианское отражение,ламбертовское отражение,ламбертово отражение
2380,landmark,معلم معروف,نقطة بارزة,معلم,地标,地标,关键点,point de repère,point de repère,repère,ランドマーク,目印 (mokuji),特徴点,ориентир,ориентир,ориентир
2381,landmark point,نقطة تاريخية,نقطة معلمية,نقطة معلم,地标点,地标点,关键点,point de repère,point de repère,point de repère,ランドマークポイント,ランドマークポイント,ランドマークポイント,Ориентир,точка ориентира,Опорная точка
2382,language drift,الانجراف اللغوي,انجراف اللغة,انحراف اللغة,语言漂移,语言漂移,语言漂移,dérive linguistique,dérive linguistique,déviation linguistique,言語の漂流,言語のドリフト (gengo no dorifuto),言語ドリフト,языковой дрейф,языковой дрейф,языковой дрейф
2383,language encoder,تشفير اللغة,مُشفر اللغة,شفرة اللغة,语言编码器,语言编码器,语言编码器,encodeur de langue,encodeur de langage,encodeur linguistique,言語エンコーダ,言語エンコーダ,言語エンコーダー,языковой кодер,языковой кодировщик,языковой кодировщик
2384,language generation,جيل اللغة,توليد اللغة,توليد اللغة,语言生成,语言生成,语言生成,génération de langage,génération de langage,génération de langage,言語の生成,言語生成,言語生成,генерация языка,генерация языка,Генерация языка
2385,language generation model,نموذج توليد اللغة,نموذج إنتاج اللغة,نموذج توليد اللغة,语言生成模型,语言生成模型,语言生成模型,modèle de génération de langage,modèle de génération de langage,modèle de génération de langage,言語生成モデル,言語生成モデル (Gengo Seisei Moderu),言語生成モデル,модель генерации языка,модель генерации языка,модель генерации языка
2386,language identification,تحديد اللغة,تحديد اللغة,تحديد اللغة,语言识别,语言识别,语言识别,identification de la langue,Identification de la langue,identification de la langue,言語の識別,言語識別 (gengo shikibetsu),言語識別,языковая идентификация,идентификация языка,определение языка
2387,language model,نموذج اللغة,نموذج لغوي,نموذج لغة,语言模型,语言模型,语言模型,modèle de langage,modèle de langage,modèle de langage,言語モデル,言語モデル (Gengo Moderu),言語モデル,языковая модель,языковая модель,Языковая модель
2388,language model pre-training,نموذج اللغة قبل التدريب,تدريب مسبق لنموذج اللغة,التدريب المسبق لنماذج اللغة,语言模型预训练,语言模型预训练,语言模型预训练,pré-formation sur le modèle linguistique,pré-entraînement des modèles de langage,pré-entraînement de modèle de langage,言語モデルの事前トレーニング,言語モデルの事前学習,言語モデル事前学習,предварительная подготовка языковой модели,предварительное обучение языковой модели,предобучение языковой модели
2389,language modeling toolkit,مجموعة أدوات نمذجة اللغة,حزمة تصميم اللغة التوجيهية,حقيبة أدوات نمذجة اللغة,语言建模工具包,语言建模工具包,语言建模工具包,boîte à outils de modélisation du langage,- Outil de modélisation linguistique,boîte à outils de modélisation linguistique,言語モデリングツールキット,言語モデリングツールキット,言語モデリングツールキット,инструментарий языкового моделирования,инструментарий моделирования языка,набор инструментов для языкового моделирования
2390,language pair,زوج لغوي,زوج اللغة,زوج اللغات,语言对,语言配对,语言对,paire de langues,paire de langues,paire de langues,言語ペア,言語ペア,言語ペア,языковая пара,языковая пара,язык-пара
2391,language representation,تمثيل اللغة,- تمثيل اللغة,تمثيل اللغة,语言表征,语言表示,语言表征,représentation linguistique,représentation linguistique,représentation linguistique,言語表現,言語表現,言語表現,языковое представление,языковое представление,языковое представление
2392,language transfer,نقل اللغة,انتقال اللغة,نقل اللغة,语言迁移,语言转移,语言迁移,transfert de langue,transfert de langue,transfert de langue,言語伝達,言語転移 (gengo ten'i),言語転移,языковой перевод,языковой перенос,перенос языка
2393,language understanding,فهم اللغة,فهم اللغة,فهم اللغة,语言理解,语言理解,语言理解,compréhension du langage,compréhension du langage,compréhension des langues,言語理解,言語理解 (Gengo Rikai),言語理解,понимание языка,понимание языка,понимание языка
2394,laplace approximation,تقريب لابلاس,التقريب لابلاس,تقريب لابلاس,拉普拉斯近似,拉普拉斯近似,拉普拉斯近似,approximation de Laplace,approximation de Laplace,approximation de Laplace,ラプラス近似,ラプラス近似,ラプラス近似,аппроксимация Лапласа,аппроксимация Лапласа,приближение Лапласа
2395,laplace distribution,توزيع لابلاس,التوزيع اللاپلاسي,توزيع لابلاس,拉普拉斯分布,拉普拉斯分布,拉普拉斯分布,distribution laplace,- Distribution de Laplace,distribution de Laplace,ラプラス分布,ラプラス分布,ラプラス分布,распределение Лапласа,распределение Лапласа,распределение Лапласа
2396,laplace noise,ضوضاء لابلاس,ضجيج لابلاس,ضجيج لابلاس,拉普拉斯噪声,拉普拉斯噪声,拉普拉斯噪声,bruit de Laplace,bruit de Laplace,bruit de Laplace,ラプラスノイズ,ラプラスノイズ,ラプラスノイズ,шум Лапласа,шум Лапласа,Шум Лапласа
2397,laplacian distribution,التوزيع اللابلاسي,التوزيع اللابلاسياني,توزيع لابلاسي,拉普拉斯分布,拉普拉斯分布,拉普拉斯分布,distribution laplacienne,- Distribution de Laplace,distribution laplacienne,ラプラシアン分布,ラプラシアン分布,ラプラス分布,распределение Лапласа,- Лапласовское распределение,Распределение Лапласа
2398,laplacian matrix,مصفوفة لابلاسية,مصفوفة لابلاسيان,مصفوفة لابلاس,拉普拉斯矩阵,拉普拉斯矩阵,拉普拉斯矩阵,matrice laplacienne,Matrice laplacienne,matrice laplacienne,ラプラシアン行列,ラプラシアン行列,ラプラシアン行列,матрица Лапласа,матрица Лапласа,матрица Лапласа
2399,laplacian smoothing,تجانس لابلاسي,التنعيم اللابلاسياني,تنعيم لابلاسي,拉普拉斯平滑,拉普拉斯平滑,拉普拉斯平滑,lissage laplacien,lissage laplacien,lissage laplacien,ラプラシアンスムージング,ラプラシアン平滑化,ラプラス平滑化,лапласово сглаживание,сглаживание Лапласа,сглаживание Лапласа
2400,large language model,نموذج لغة كبير,النموذج اللغوي الكبير,نموذج لغة ضخم,大语言模型,大型语言模型,大型语言模型,grand modèle de langage,grand modèle de langage,modèle de langage de grande taille,大規模な言語モデル,大規模言語モデル,大規模言語モデル,большая языковая модель,большая языковая модель,большая языковая модель
2401,large-margin learning,التعلم بهامش كبير,التعلم بحواف كبيرة,تعلم هامش كبير,大幅学习,大边界学习,大边界学习,apprentissage à grande marge,apprentissage à grand marge,apprentissage à grande marge,マージンの大きい学習,大きなマージン学習,大マージン学習,обучение с большой прибылью,обучение с большим зазором,обучение с большой разделяющей поверхностью
2402,latent code,الكود الكامن,الرمز الكامن,شفرة كامنة,潜在代码,潜在编码,潜码,code latent,code latent,code latent,潜在コード,潜在コード,潜在コード,скрытый код,Латентный код,скрытый код
2403,latent dimension,البعد الكامن,"""نلاحظ أنه قد تم إسقاط بُعد كامن. نشير إلى أن النماذج β-VAE ذات التمزيق العالي تعاني من إعادة بناء سيئة عند إسقاط الأبعاد الكامنة. يُظهر التقييم المقابل لمعامل MIG أ",بُعد كامن,潜在维度,潜在维度,隐藏维度,dimension latente,dimension latente,dimension latente,潜在次元,潜在次元 (latent dimension),潜在次元,скрытое измерение,латентное измерение,скрытое измерение
2404,latent dirichlet allocation,تخصيص ديريتشليت الكامنة,توزيع ديريشليه الخفي,توزيع ديريشليه الكامن,潜在狄利克雷分配,潜在狄利克雷分配,隐狄利克雷分布,allocation de dirichlet latente,allocation latente de Dirichlet,Allocation de Dirichlet Latente,潜在ディリクレ配分,潜在的ディリクレ配分,潜在ディリクレ配分,латентное распределение Дирихле,латентное распределение дирихле,скрытое распределение Дирихле
2405,latent distribution,التوزيع الكامن,التوزيع الكامن,توزيع كامن,潜在分布,潜在分布,隐分布,répartition latente,- Distribution latente,distribution latente,潜在的な分布,潜在分布,潜在分布,скрытое распределение,латентное распределение,скрытое распределение
2406,latent dynamic model,النموذج الديناميكي الكامن,نموذج ديناميكي كامن,نموذج حركي كامن,潜在动态模型,潜在动态模型,潜在动态模型,modèle dynamique latent,modèle dynamique latent,modèle dynamique latent,潜在動的モデル,潜在的な動的モデル,潜在ダイナミックモデル,скрытая динамическая модель,латентная динамическая модель,Скрытая динамическая модель
2407,latent embedding,التضمين الكامن,التضمين الكامن,التضمين الكامن,潜在嵌入,潜在嵌入,隐式嵌入,intégration latente,intégration latente,plongement latent,潜在的な埋め込み,潜在埋め込み (latent embedding),潜在埋め込みベクトル,скрытое встраивание,латентное вложение,скрытое встраивание
2408,latent factor,العامل الكامن,عامل كامن,عامل كامن,潜在因素,潜在因子,隐因子,facteur latent,facteur latent,facteur latent,潜在的要因,潜在因子 (latent factor),潜在因子,скрытый фактор,скрытый фактор,скрытый фактор
2409,latent feature,الميزة الكامنة,ميزة كامنة,سمة كامنة,潜在特征,潜在特征,潜在特征,caractéristique latente,caractéristique latente,caractéristique latente,潜在的な特徴,潜在特徴,潜在特徴,скрытая функция,латентная характеристика,скрытый признак
2410,latent function,وظيفة كامنة,الدالة الكامنة,دالة كامنة,潜在功能,潜在函数,隐函数,fonction latente,fonction latente,fonction latente,潜在機能,潜在関数 (latent function),潜在関数,скрытая функция,латентная функция,скрытая функция
2411,latent group,المجموعة الكامنة,مجموعة كامنة,المجموعات الكامنة,潜在群体,潜在群组,潜在群组,groupe latent,- Groupe latent,groupe latent,潜在的なグループ,潜在グループ (senzai gurūpu),潜在グループ,латентная группа,латентная группа,скрытая группа
2412,latent parameter,المعلمة الكامنة,المعلمة الكامنة,المعامل الكامن,潜在参数,潜在参数,隐含参数,paramètre latent,paramètre latent,paramètres latents,潜在パラメータ,潜在パラメータ,潜在パラメータ,скрытый параметр,латентный параметр,скрытый параметр
2413,latent representation,التمثيل الكامن,التمثيل الكامن,التمثيل الكامن,潜在表征,潜在表示,潜在表征,représentation latente,représentation latente,représentation latente,潜在表現,潜在表現,潜在表現,скрытое представление,латентное представление,скрытое представление
2414,latent reward function,وظيفة المكافأة الكامنة,وظيفة المكافأة الكامنة,وظيفة المكافأة الكامنة,潜在奖励函数,潜在奖励函数,潜在奖励函数,fonction de récompense latente,fonction de récompense latente,fonction de récompense latente,潜在報酬関数,潜在報酬関数 (latent reward function),潜在報酬関数,скрытая функция вознаграждения,скрытая функция вознаграждения,скрытая функция вознаграждения
2415,latent semantic,الدلالية الكامنة,الدلالة الكامنة,الدلالات الكامنة,潜在语义,潜在语义,潜在语义,sémantique latente,sémantique latente,sémantique latente,潜在的な意味論,潜在的意味,潜在的意味,скрытая семантика,латентная семантика,скрытая семантика
2416,latent semantic analysis,التحليل الدلالي الكامن,التحليل الدلالي الكامن,التحليل الكامن للدلالات,潜在语义分析,潜在语义分析,潜在语义分析,analyse sémantique latente,Analyse sémantique latente,analyse sémantique latente,潜在意味解析,潜在的意味分析,潜在的意味解析,скрытый семантический анализ,Латентный семантический анализ,скрытый семантический анализ
2417,latent space,الفضاء الكامن,- المساحة الكامنة,الفضاء الكامن,潜在空间,潜空间,潜在空间,espace latent,- Espace latent,espace latent,潜在空間,潜在空間 (senzai kuukan),潜在空間,скрытое пространство,скрытое пространство,скрытое пространство
2418,latent state,الحالة الكامنة,الحالة الكامنة,حالة كامنة,潜伏状态,潜在状态,潜在状态,état latent,état latent,État latent,潜在状態,潜在状態 (latent state),潜在状態,скрытое состояние,скрытое состояние,скрытое состояние
2419,latent topic,موضوع كامن,الموضوع الكامن,موضوع كامن,潜在话题,潜在主题 (latent topic),隐含主题,sujet latent,sujet latent,sujet latent,潜在的な話題,潜在トピック,潜在トピック,скрытая тема,латентная тема,скрытая тема
2420,latent variable,المتغير الكامن,- متغير كامن,متغير كامن,潜变量,潜在变量,隐变量,variable latente,variable latente,variable latente,潜在変数,潜在変数,潜在変数,скрытая переменная,скрытая переменная,скрытая переменная
2421,latent variable model,نموذج المتغير الكامن,نموذج المتغير الكامن,نموذج المتغير الكامن,潜变量模型,潜变量模型,潜变量模型,modèle à variable latente,modèle de variable latente,Modèle à variables latentes,潜在変数モデル,潜在変数モデル,潜在変数モデル,модель скрытой переменной,модель скрытых переменных,латентная переменная модель
2422,latent vector,ناقلات كامنة,المتجه الكامن,متجه كامن,潜在向量,潜在向量,隐向量,vecteur latent,vecteur latent,vecteur latent,潜在ベクトル,潜在ベクトル,潜在ベクトル,скрытый вектор,латентный вектор,скрытый вектор
2423,layer,طبقة,طبقة,طبقة,层,层级,层,couche,- Couche,couche,層,レイヤー,層,слой,слой,слой
2424,layer activation,تفعيل الطبقة,تنشيط الطبقة,تنشيط الطبقة,层激活,层激活,层激活,activation des couches,activation de couche,Activation des couches,レイヤーのアクティブ化,レイヤー活性 (layer activation),層活性化,активация слоя,активация слоя,активация слоя
2425,layer normalization,تطبيع الطبقة,تطبيع الطبقة,تنميط الطبقات,层归一化,层归一化,层归一化,normalisation des couches,normalisation des couches,normalisation des couches,レイヤーの正規化,レイヤー正規化 (Layer Normalization),層正規化,нормализация слоя,нормализация слоя,нормализация слоя
2426,layer-wise learning rate decay,تسوس معدل التعلم على مستوى الطبقة,انحسار معدل التعلم طبقة بطبقة,تناقص معدل التعلم حسب الطبقات,逐层学习率衰减,逐层学习率衰减,层级学习率衰减,décroissance du taux d'apprentissage par couche,décroissance du taux d'apprentissage par couche,Décroissance du taux d'apprentissage par couche,層ごとの学習率の減衰,レイヤーごとの学習率減衰 (layer-wise learning rate decay),層ごとの学習率減衰,снижение скорости обучения по слоям,убывание скорости обучения по слоям,Поэтапное уменьшение коэффициента обучения
2427,lazy grounding,التأريض البطيء,الأرضية الكسولة,التأسيس الكسول,懒惰接地,惰性实例化,延迟建模,mise à la terre paresseuse,instanciation paresseuse,Instanciation paresseuse,怠惰なグラウンディング,怠惰グラウンディング,遅延グラウンディング,ленивое заземление,ленивая редукция,ленивое обоснование
2428,leaf node,عقدة ورقة,العقدة الورقية,شجرة فرعية,叶节点,叶节点,叶子节点,noeud feuille,nœud feuille,nœud terminal,リーフノード,葉ノード,末端ノード,листовой узел,листовой узел,узловая вершина
2429,learn agent,تعلم الوكيل,العامل المتعلم,وكيل التعلم,学习代理,学习代理,学习智能体,agent d'apprentissage,agent d'apprentissage,agent apprenant,学習エージェント,学習エージェント,学習エージェント,учиться агент,учащийся агент,обучающий агент
2430,learn algorithm,تعلم الخوارزمية,خوارزمية التعلم,خوارزمية التعلم,学习算法,学习算法,学习算法,apprendre l'algorithme,algorithme d'apprentissage,algorithme d'apprentissage,アルゴリズムを学ぶ,学習アルゴリズム,学習アルゴリズム,выучить алгоритм,алгоритм обучения,алгоритм обучения
2431,learn method,تعلم الطريقة,الأسلوب التعلمي,طريقة التعلم,学习方法,学习方法,学习方法,apprendre la méthode,- Méthode d'apprentissage,méthode d'apprentissage,学習方法,学習方法,学習方法,метод изучения,метод обучения,Метод обучения
2432,learn model,تعلم النموذج,نموذج تعلم,نموذج متعلم,学习模型,学习模型,学习模型,apprendre le modèle,modèle appris,modèle appris,モデルを学習する,学習モデル (がくしゅうモデル),学習モデル,изучить модель,модель обучения,модель обучения
2433,learn paradigm,تعلم النموذج,نموذج التعلم,أنموذج التعلم,学习范式,学习范式 (Xuéxí fànxí),学习范式,apprendre le paradigme,paradigme d'apprentissage,paradigme d'apprentissage,パラダイムを学ぶ,学習パラダイム,学習パラダイム,изучить парадигму,"мы предполагаем, что как обычно есть набор положительных примеров, а кроме того, обучающийся может запросить, принадлежит",парадигма обучения
2434,learn problem,تعلم المشكلة,مشكلة التعلم,مشكلة التعلم,学习问题,学习问题,学习问题,apprendre le problème,problème d'apprentissage,problème d'apprentissage,問題を学ぶ,学習問題 (がくしゅうもんだい),学習問題,изучить проблему,проблема обучения,Проблема обучения
2435,learn representation,تعلم التمثيل,- التمثيل الذي تم تعلمه,تعلم التمثيل,学习表征,学习表示,学习表示,apprendre la représentation,représentation apprise,apprendre la représentation,表現を学ぶ,- 学習表現 (gakushu hyougen),表現を学習する,изучить представление,обученное представление,научиться представлению
2436,learn-to-rank algorithm,خوارزمية تعلم الترتيب,خوارزمية تعلم الترتيب,خوارزمية تعلم الترتيب,学习排序算法,学习排序算法,学习排序算法,algorithme d'apprentissage du classement,algorithme d'apprentissage pour classer,Algorithme d'apprentissage pour le classement,ランク付け学習アルゴリズム,学習順位付けアルゴリズム,順位付け学習アルゴリズム,алгоритм обучения ранжированию,алгоритм обучения ранжированию,алгоритм learn-to-rank
2437,learnability,قابلية التعلم,قابلية التعلم,قابلية التعلم,易学性,可学习性,可学习性,capacité d'apprentissage,aptitude à apprendre,apprenabilité,学習可能性,学習可能性 (がくしゅうかのうせい),学習可能性,обучаемость,обучаемость,обучаемость
2438,learnable parameter,المعلمة القابلة للتعلم,المعلمة القابلة للتعلم,معامل قابل للتعلم,可学习参数,可学习参数,可学习参数,paramètre apprenable,paramètre apprenable,paramètre apprenant,学習可能なパラメータ,学習可能なパラメータ (gakushu kanōna pārametā),学習可能パラメータ,обучаемый параметр,обучаемый параметр,обучаемый параметр
2439,learnable vector,ناقلات قابلة للتعلم,فضاء الناقل القابل للتعلم,متجه قابل للتعلم,可学习的向量,可学习向量,可学习向量,vecteur apprenable,vecteur apprenable,vecteur apprenant,学習可能なベクトル,学習可能なベクトル (がくしゅうかのうなべくとる),学習可能ベクトル,обучаемый вектор,обучаемый вектор,обучаемый вектор
2440,learner,المتعلم,المتعلم,متعلم,学习者,学习者,学习器,apprenant,- Apprenant,apprenant,学習者,学習者,学習器,ученик,ученик,обучающийся
2441,learning rate,معدل التعليم,معدل التعلم,معدل التعلم,学习率,学习率,学习率,taux d'apprentissage,taux d'apprentissage,taux d'apprentissage,学習率,学習率,学習率,скорость обучения,темп обучения,Коэффициент обучения
2442,learning rate decay,تسوس معدل التعلم,معدل تحلل معدل التعلم,معدل تناقص التعلم,学习率衰减,学习速率衰减,学习率衰减,diminution du taux d'apprentissage,taux d'apprentissage décroissant,dégradation du taux d'apprentissage,学習率の低下,学習率の減衰 (がくしゅうりつのげんすい),学習率減衰,снижение скорости обучения,скорость обучения затухания,убывание скорости обучения
2443,learning rate decay schedule,جدول تناقص معدل التعلم,جدول تدهور معدل التعلم,جدولة تناقص معدل التعلم,学习率衰减时间表,学习率衰减计划,学习率衰减时间表,calendrier de décroissance du taux d'apprentissage,calendrier de décroissance du taux d'apprentissage,Programme de décroissance du taux d'apprentissage,学習率減衰スケジュール,学習率減衰スケジュール,学習率減衰スケジュール,график снижения скорости обучения,график уменьшения скорости обучения,график снижения темпа обучения
2444,learning rate schedule,جدول معدل التعلم,جدول معدل التعلم,معدل التعلم الجدول الزمني,学习率表,学习率计划,学习率计划,barème des taux d'apprentissage,taux d'apprentissage planifié,Calendrier du taux d'apprentissage,学習率スケジュール,- 学習率スケジュール (learning rate schedule),学習率スケジューリング,график обучения,график скорости обучения,график обучения
2445,learning rate scheduler,جدولة معدل التعلم,مُجدول معدل التعلم,جدول معدلات التعلم,学习率调度器,学习率调度器,学习率调度器,planificateur de taux d'apprentissage,planificateur de taux d'apprentissage,programmateur de taux d'apprentissage,学習率スケジューラ,学習率スケジューラ (gakushuu-ritsu sukejuura),学習率スケジューラー,планировщик скорости обучения,скорость обучения (learning rate).scheduler,планировщик скорости обучения
2446,learning rate warmup,الاحماء معدل التعلم,معدل التعلم المبدئي,تدفئة معدل التعلم,学习率预热,学习率预热,学习率热身,échauffement du taux d'apprentissage,taux d'apprentissage d'amorçage,montée en puissance du taux d'apprentissage,学習率のウォームアップ,学習率ウォームアップ,学習率ウォームアップ,разминка скорости обучения,скорость обучения разогрева,нагрев скорости обучения
2447,least square,اقل تربيع,"""['(2) بينما يجب أن ينمو إجمالي الفضاء الفرعي بشكل خطي مع t mix ، فإن هذا ليس مطلوبًا لـ T total,clustering و T total,classification ، لأن طرقنا لتقدير النموذج (أي الأقل مربع وتقدير",مربعات الصغرى,最小二乘法,最小二乘,最小二乘,moins carré,moindres carrés,moindres carrés,最小二乗,最小二乗法 (さいしょうにじょうほう),最小二乗法,наименьших квадратов,метод наименьших квадратов,метод наименьших квадратов
2448,least square criterion,معيار المربع الأصغر,معيار أقل مربعا,معيار الربيعات الصغرى,最小二乘准则,最小二乘准则,最小二乘准则,critère des moindres carrés,critère des moindres carrés,critère des moindres carrés,最小二乗基準,最小二乗基準 (Saishou ni-jou kijun),最小二乗基準,критерий наименьших квадратов,критерий наименьших квадратов,наименьший квадратный критерий
2449,least square minimization,التقليل من المربعات الصغرى,التقليل بأقل مربعات,تصغير المربعات الصغرى,最小二乘最小化,最小二乘法最小化,最小二乘法,minimisation des moindres carrés,minimisation des moindres carrés,moindres carrés,最小二乗最小化,最小二乗法,最小二乗法,минимизация наименьших квадратов,минимизация методом наименьших квадратов,наименьших квадратов минимизация
2450,least square problem,مشكلة المربعات الصغرى,مشكلة التقريب الأقل,مشكلة المربعات الصغرى,最小二乘问题,最小二乘问题,最小二乘问题,problème des moindres carrés,problème des moindres carrés,problème des moindres carrés,最小二乗問題,最小二乗問題,最小二乗問題,задача наименьших квадратов,Проблема наименьших квадратов,проблема наименьших квадратов
2451,least square regression,الانحدار المربع الأصغر,"""تمت إظهار أن عمليات النقط القريبة توفر ضمانات تقريبية مثالية ليس فقط لـ CSSP ولكن أيضًا لمهام أخرى في جبر الخطي العددي، مثل انحدار أصغر مربع (على سبيل الم",انحدار المربعات الصغرى,最小二乘回归,最小二乘回归,最小二乘回归,régression des moindres carrés,régression des moindres carrés,régression des moindres carrés,最小二乗回帰,最小二乗回帰 (Saishou nijou kaikei),最小二乗回帰,регрессия наименьших квадратов,регрессия методом наименьших квадратов,метод наименьших квадратов
2452,least square solution,الحل المربع الأصغر,حل المربعات الأقلية,حل المربعات الصغرى,最小二乘解,最小二乘解,最小二乘解,solution des moindres carrés,solution des moindres carrés,solution des moindres carrés,最小二乗解,最小二乗解,最小二乗解,решение наименьших квадратов,решение методом наименьших квадратов,наименьшее квадратное решение
2453,leave-one-out,ترك واحد خارج,- ترك واحدًا,تحليل المفردات الواحدة,留一法,留一出,留一法,laisser-un-dehors,laisser-un-dehors,validation croisée simple,ワンアウト,1つ抜き法,外れ値除去法,оставить одного,исключая один элемент,исключения по одному
2454,left-to-right model,نموذج من اليسار إلى اليمين,نموذج من اليسار إلى اليمين,نموذج من اليسار إلى اليمين,从左到右模型,从左到右模型,从左到右模型,modèle de gauche à droite,modèle de gauche à droite,modèle de gauche à droite,左から右へのモデル,左から右へのモデル,左から右のモデル,модель слева направо,левосторонняя модель,Модель слева направо
2455,lemmatization,lemmatization,- تقنين الكلمات,السمة,词形还原,词形归并 (lemmatization),词形还原,lemmatisation,lemmatisation,lemmatisation,見出し語化,見出し語化,単語の基本形への変換,лемматизация,лемматизация,леммaтизaция
2456,length normalization,تطبيع الطول,التطويط طولي,تطبيع الطول,长度归一化,长度归一化,长度归一化,normalisation de la longueur,normalisation de la longueur,normalisation de longueur,長さの正規化,長さ正規化,長さ正規化,нормализация длины,нормализация длины,нормализация длины
2457,length penalty,عقوبة الطول,عقوبة الطول,عقوبة الطول,长度惩罚,长度惩罚,长度惩罚,pénalité de longueur,pénalité de longueur,pénalité de longueur,長さペナルティ,長さのペナルティ (Nagasa no penaruti),長さペナルティ,штраф за длину,"""['Мы устанавливаем коэффициент масштабирования потерь, основанных на согласованности, как α = 0,15 и коэффициент отсева как 0,1. Для вывода мы применяем алгоритм частичного поиска луча к обученной модели seq2seq. Мы устанавливаем длин",штраф за длину
2458,lexeme,معجم,مفردة,وحدة معجمية,词位,词元,词素,lexème,lexème,lexème,語彙素,語彙素,単語素,лексема,лексема,лексема
2459,lexical acquisition,اكتساب معجمي,اكتساب مفرداتي,اكتساب المفردات,词汇习得,词汇习得,词汇获取,acquisition lexicale,acquisition lexicale,acquisition lexicale,語彙の獲得,"""語彙習得、情報抽出、および意味分類の多くのプロジェクトにおいて、構造化された関連知識を捉えることが目標となってきました。""",語彙獲得,лексическое приобретение,лексическое приобретение,лексическое приобретение
2460,lexical acquisition algorithm,خوارزمية اكتساب المفردات,خوارزمية اكتساب المفردات,خوارزمية اكتساب المفردات,词汇获取算法,词汇获取算法,词汇获取算法,algorithme d'acquisition lexicale,algorithme d'acquisition lexicale,Algorithme d'acquisition lexicale,語彙獲得アルゴリズム,語彙獲得アルゴリズム (goi kakutoku arugorizumu),語彙獲得アルゴリズム,алгоритм лексического приобретения,алгоритм лексического приобретения,алгоритм лексического приобретения
2461,lexical ambiguity,الغموض المعجمي,الغموض اللغوي,لبس لفظي,词汇歧义,词汇歧义,词汇歧义,ambiguïté lexicale,ambiguïté lexicale,ambiguïté lexicale,語彙の曖昧さ,語彙の曖昧さ,語彙的曖昧さ,лексическая двусмысленность,лексическая неоднозначность,лексическая многозначность
2462,lexical entry,دخول معجمي,مدخل لغوي,مدخل قاموسي,词汇条目,词汇条目,词条,entrée lexicale,entrée lexicale,entrée lexicale,語彙エントリ,語彙エントリ,語彙項目,лексическая статья,лексическая запись,лексическая запись
2463,lexical exposure,التعرض المعجمي,التعرض المعجمي,تعرّض لغوي,词汇暴露,词汇曝光,词汇暴露,exposition lexicale,exposition lexicale,lexical exposition,語彙露出,"""[""これが起こった場合、事前に学習されたモデルと非事前に学習されたモデルの評価の不一致が、共起値の変動に寄与し、事前学習中の語彙曝露による事前学習モデルの性能が過大評価される可能性があります。可能な",語彙的露出,лексическое воздействие,лексическая экспозиция,лексическая экспозиция
2464,lexical feature,ميزة معجمية,الميزة المعجمية,ميزة لفظية,词汇特征,词汇特征,词汇特征,caractéristique lexicale,caractéristique lexicale,caractéristique lexicale,語彙的特徴,語彙的特徴,語彙的特徴,лексическая особенность,лексическая особенность,лексическая характеристика
2465,lexical functional grammar,النحو الوظيفي المعجمي,نحو القواعد اللغوية المعجمية,نحو الوظيفة المعجمية,词汇功能语法,词汇功能语法,词汇功能语法,grammaire fonctionnelle lexicale,grammaire fonctionnelle lexicale,grammaire lexicale fonctionnelle,語彙関数文法,語彙機能文法,語彙機能文法,лексическая функциональная грамматика,лексико-функциональная грамматика,лексико-функциональная грамматика
2466,lexical head,رأس معجمي,- المحتوى اللغوي الرئيسي,رأس لفظي,词汇中心词,词头,词头,tête lexicale,tête lexicale,tête lexicale,字句の頭,語彙的ヘッド,語彙的主要部,лексическая глава,лексическая голова,лексическая вершина
2467,lexical item,عنصر معجمي,عنصر معجمي,مدخل لغوي,词汇项,词项,词汇项,élément lexical,élément lexical,unité lexicale,語彙項目,語彙アイテム (goi aitemu),語彙項目,лексический элемент,лексический элемент,лексическая единица
2468,lexical knowledge,المعرفة المعجمية,المعرفة المفردية,معرفة معجمية,词汇知识,词汇知识,词汇知识,connaissance lexicale,- Connaissance lexicale,connaissances lexicales,語彙知識,語彙知識,語彙知識,лексические знания,лексические знания,лексические знания
2469,lexical model,النموذج المعجمي,نموذج لغوي,نموذج معجمي,词汇模型,词法模型,词汇模型,modèle lexical,modèle lexical,modèle lexical,語彙モデル,語彙モデル (ごいモデル),語彙モデル,лексическая модель,лексическая модель,Лексическая модель
2470,lexical overlap,التداخل المعجمي,تداخل مفرداتي,التداخل اللفظي,词汇重叠,词汇重叠,词汇重叠,chevauchement lexical,recouvrement lexical,chevauchement lexical,語彙の重複,語彙の重複,語彙の重複,лексическое перекрытие,лексическое перекрытие,лексическое перекрытие
2471,lexicalization,المعجمية,التمعن اللغوي,ترميز,词汇化,词汇化,词汇化,lexicalisation,lexicalisation,lexicalisation,語彙化,語彙化,語彙化,лексикализация,лексикализация,лексикализация
2472,lexicalized grammar,القواعد المعجمية,قواعد النحو المحسوسة,قواعد مُعجَمة,词汇化语法,词汇化语法,词汇化语法,grammaire lexicalisée,grammaire lexicalisée,grammaire lexicalisée,語彙化された文法,語彙化された文法 (goi-ka-sareta bunpou),語彙化された文法,лексикализированная грамматика,лексикализованная грамматика,лексикализованная грамматика
2473,lexicalized parsing model,نموذج التحليل المعجمي,النموذج النحوي الملخص,نموذج تحليل قواعد المعجم,词汇化分析模型,词汇化解析模型,词汇化句法分析模型,modèle d'analyse lexicalisée,- Modèle d'analyse syntaxique lexicalisé,modèle d'analyse syntaxique lexicalisé,語彙化された解析モデル,語彙化された解析モデル,語彙化構文解析モデル,лексикализованная модель синтаксического анализа,лексикализированная модель синтаксического анализа,лексикализованная модель разбора
2474,lexicon,معجم,معجم,معجم,词典,词汇表,词汇表,lexique,lexique,lexique,辞書,"""「したがって、モデルの信念、欲求、行動動詞における動詞クラスの尤度を、私たちの語彙の中で報告します。PCGの子供と大人の反応とモデルの反応を比較するために、500の入力フレームでモデルを訓練した後の2つのテストポイント",語彙,лексикон,лексикон,лексикон
2475,lexicon induction,تحريض المعجم,استدراك المعجم,التنميط المعجمي,词汇归纳,词汇诱导,词汇归纳,induction du lexique,induction de lexique,lexique inductif,語彙誘導,語彙誘導,語彙誘導,введение лексики,индукция лексикона,лексическая индукция
2476,lie algebra,كذبة الجبر,جبر الكذب,جبر لي,李代数,李代数,李代数,algèbre de mensonge,algèbre de Lie,algèbre de Lie,嘘代数,リー代数,リー環,алгебра лжи,алгебра Ли,алгебра Ли
2477,lifelong learning,التعلم مدى الحياة,التعلم مدى الحياة,تعلم مدى الحياة,终身学习,终身学习,终身学习,apprentissage tout au long de la vie,- Enseignement tout au long de la vie,apprentissage permanent,生涯学習,一生涯学習,生涯学習,обучение на протяжении всей жизни,пожизненное обучение,непрерывное обучение
2478,light field,مجال الضوء,مجال الضوء,مجال الضوء,光场,光场,光场,champ de lumière,champ lumineux,Champ de lumière,ライトフィールド,光場,光線場,световое поле,световое поле,Светопольное (световое поле)
2479,light field interpolation,الاستيفاء مجال الضوء,تقنيات تداخل حقل الضوء,استرجاع حقل الضوء,光场插值,光场插值,光场插值,interpolation de champ lumineux,interpolation de champ de lumière,interpolation de champ de lumière,ライトフィールド補間,ライトフィールド補間,光場補間,интерполяция светового поля,интерполяция светового поля,Интерполяция светового поля
2480,likelihood function,وظيفة الاحتمال,وظيفة الاحتمالية,دالة الاحتمال,似然函数,似然函数,似然函数,fonction de vraisemblance,- Fonction de vraisemblance,fonction de vraisemblance,尤度関数,尤度関数 (Yūdo kansū),尤度関数,функция правдоподобия,функция правдоподобия,функция правдоподобия
2481,likelihood ratio test,اختبار نسبة الاحتمالية,اختبار نسبة الاحتمالية,اختبار نسبة الأرجحية,似然比检验,似然比检验,似然比检验,test du rapport de vraisemblance,test du rapport de vraisemblance,test du rapport de vraisemblance,尤度比検定,尤度比検定 (likelihood ratio test),尤度比検定,тест отношения правдоподобия,тест отношения правдоподобия,тест отношения правдоподобия
2482,likelihood score,درجة الاحتمال,نتيجة الاحتمالية,درجة الاحتمال,似然得分,可能性评分 (likelihood score),似然分数,score de vraisemblance,score de vraisemblance,Score de vraisemblance,可能性スコア,尤度スコア,尤度スコア,оценка вероятности,оценка вероятности,Оценка правдоподобия
2483,likert scale,مقياس ليكرت,- التقييم الليكرت,مقياس ليكرت,利开特式量表,李克特量表,利克特量表,échelle de Likert,échelle de Likert,échelle de Likert,リッカートスケール,リカート尺度,リッカート尺度,Шкала Лайкерта,Ликерт шкала,шкала Ликерта
2484,line search,بحث الخط,- تفتيش الخط,بحث خطي,线搜索,线性搜索,线搜索,recherche de ligne,recherche de ligne,recherche linéaire,ライン検索,直線探索 (chokusen tansaku),ラインサーチ,поиск линии,линейный поиск,линейный поиск
2485,linear Transformer,محول خطي,المحول الخطي,محول خطي,线性变压器,线性变压器,线性Transformer,Transformateur linéaire,Transformateur linéaire,Transformateur linéaire,リニアトランス,リニア・トランスフォーマー,線形変換器,линейный трансформатор,Линейный трансформер,линейный Трансформер
2486,linear activation function,وظيفة التنشيط الخطي,وظيفة التنشيط الخطية,دالة التنشيط الخطية,线性激活函数,线性激活函数,"ē""Ŗå¤å""å½æ°",fonction d'activation linéaire,fonction d'activation linéaire,fonction d'activation linéaire,線形活性化関数,- 線形活性化関数 (sennkei kasseika kansu),å¹³é¢æ§åØē¾,линейная функция активации,линейная функция активации,линейная активационная функция
2487,linear algebra,الجبر الخطي,الجبر الخطي,الجبر الخطي,线性代数,线性代数,线性代数,algèbre linéaire,algèbre linéaire,algèbre linéaire,線形代数,線形代数学,線形代数,линейная алгебра,линейная алгебра,линейная алгебра
2488,linear classification,التصنيف الخطي,التصنيف الخطي,تصنيف خطي,线性分类,线性分类,线性分类,classification linéaire,classification linéaire,classification linéaire,線形分類,線形分類 (senkei-bunrui),線形分類,линейная классификация,линейная классификация,линейная классификация
2489,linear classification layer,طبقة التصنيف الخطية,الطبقة الخطية للتصنيف,طبقة التصنيف الخطي,线性分类层,线性分类层,线性分类层,couche de classification linéaire,couche de classification linéaire,couche de classification linéaire,線形分類層,線形分類層,線形分類層,слой линейной классификации,линейный классификационный слой,линейный классификационный слой
2490,linear classifier,المصنف الخطي,المصنف الخطي,صنف خطي,线性分类器,线性分类器,线性分类器,classificateur linéaire,-classificateur linéaire,classifieur linéaire,線形分類器,線形分類器 (senkei bunka-sha),線形分類器,линейный классификатор,линейный классификатор,линейный классификатор
2491,linear combination,تركيبة خطية,الجمع الخطي,مجموع حدي,线性组合,线性组合,线性组合,combinaison linéaire,combinaison linéaire,Combinaison linéaire,線形結合,線形結合,線形結合,линейная комбинация,линейная комбинация,линейная комбинация
2492,linear complexity,التعقيد الخطي,- التعقيد الخطي,ضبابية خطية,线性复杂度,线性复杂度,线性复杂度,complexité linéaire,complexité linéaire,complexité linéaire,線形の複雑さ,- 線形計算量,線形時間計算量,линейная сложность,линейная сложность,линейная сложность
2493,linear constraint,القيد الخطي,القيد الخطي,قيد خطي,线性约束,线性约束,线性约束条件,contrainte linéaire,Contrainte linéaire,contrainte linéaire,線形拘束,線形制約 (senkei seigai),線形制約,линейное ограничение,линейное ограничение,линейное ограничение
2494,linear decay,الاضمحلال الخطي,التحلل الخطي,تناقص خطي,线性衰减,线性衰减,线性衰减,décroissance linéaire,décroissance linéaire,décroissance linéaire,線形減衰,"""['訓練では、learning rateが1e-4、β 1 =0.9、β 2 =0.999、L2ウェイト減衰が0.01、最初の10,000ステップでのlearning rateのウォームアップ、およびlearning rateの線形減衰にAdamを使用します。すべての層でのドロップアウト確率は0",線形減衰,линейный распад,линейное затухание,линейное затухание
2495,linear decoder,وحدة فك الترميز الخطية,مُفكك خطي,مُفَكِّر خَطِّي,线性解码器,线性解码器,线性解码器,décodeur linéaire,Décodeur linéaire,décodeur linéaire,リニアデコーダ,線形デコーダ,線形デコーダ,линейный декодер,линейный декодер,линейный декодер
2496,linear discriminant analysis,التحليل التمييزي الخطي,- التحليل التمييزي الخطي,التحليل التمييزي الخطي,线性判别分析,线性判别分析 (linear discriminant analysis),线性判别分析,analyse discriminante linéaire,Analyse discriminante linéaire,analyse discriminante linéaire,線形判別分析,線形判別分析 (senkei handan bunseki),線形判別分析,линейный дискриминантный анализ,линейный дискриминантный анализ,линейный дискриминантный анализ
2497,linear equation,معادلة خط مستقيم,المعادلة الخطية,معادلة خطية,线性方程,线性方程组,线性方程,équation linéaire,- Equation linéaire,équation linéaire,一次方程式,線形方程式,一次方程式,линейное уравнение,линейное уравнение,линейное уравнение
2498,linear evaluation,التقييم الخطي,التقييم الخطي,تقييم خطي,线性评估,线性评估,线性评估,évaluation linéaire,évaluation linéaire,évaluation linéaire,線形評価,線形評価,線形評価,линейная оценка,линейная оценка,линейная оценка
2499,linear function,دالة خطية,الدالة الخطية,دالة خطية,线性函数,线性函数,线性函数,fonction linéaire,fonction linéaire,fonction linéaire,一次関数,線形関数,線形関数,линейная функция,линейная функция,линейная функция
2500,linear function approximation,تقريب الوظيفة الخطية,التقريب الخطي للدوال,تقريب دالة خطي,线性函数近似,线性函数逼近,线性函数逼近,approximation de la fonction linéaire,approximation de fonction linéaire,approximation linéaire de fonction,一次関数近似,線形関数近似 (senkei kansu kin'ni),線形関数近似,аппроксимация линейной функции,линейная аппроксимация функции,аппроксимация линейной функции
2501,linear inequality,عدم المساواة الخطية,- تفاضل خطي,متراجحة خطية,线性不等式,线性不等式,线性不等式,inégalité linéaire,Inégalité linéaire,inégalité linéaire,線形不等式,線形不等式,線形不等式,линейное неравенство,линейное неравенство,линейное неравенство
2502,linear interpolation,الاستيفاء الخطي,التداخل الخطي,التربيع الخطي,线性插值,线性插值,线性插值,interpolation linéaire,interpolation linéaire,interpolation linéaire,線形補間,線形補間 (senkei hokan),線形補間,линейная интерполяция,линейная интерполяция,линейная интерполяция
2503,linear kernel,نواة خطية,نواة خطية,نواة خطية,线性核,线性核,线性核,noyau linéaire,noyau linéaire,noyau linéaire,線形カーネル,線形カーネル,線形カーネル,линейное ядро,линейное ядро,линейное ядро
2504,linear layer,طبقة خطية,الطبقة الخطية,طبقة خطية,线性层,线性层,线性层,couche linéaire,couche linéaire,couche linéaire,線形層,- 線形層 (senkei-sou),線形層,линейный слой,линейный слой,линейный слой
2505,linear learning rate decay,تسوس معدل التعلم الخطي,انحسار معدل التعلم الخطي,انحدار معدل التعلم الخطي,线性学习率衰减,线性学习率衰减,线性学习率衰减,décroissance du taux d'apprentissage linéaire,taux de décroissance linéaire de l'apprentissage,Décroissance linéaire du taux d'apprentissage,学習率の線形減衰,線形学習率減衰,線形学習率減衰,линейное снижение скорости обучения,линейное затухание скорости обучения,линейное уменьшение темпа обучения
2506,linear learning rate schedule,جدول معدل التعلم الخطي,جدول تعلم سريع خطي,جدول معدل التعلم الخطي,线性学习率表,线性学习率调度,线性学习率时间表,calendrier de taux d'apprentissage linéaire,plan d'apprentissage linéaire,calendrier de taux d'apprentissage linéaire,線形学習率スケジュール,線形学習率スケジュール,線形学習率スケジュール,линейный график скорости обучения,линейное расписание темпа обучения,линейный график скорости обучения
2507,linear map,خريطة خطية,التطبيق الخطي,تحويلة خطية,线性映射,线性映射,线性映射,carte linéaire,application linéaire,application linéaire,線形マップ,- 線形写像 (senkei shazou),線形写像,линейная карта,линейное отображение,линейное отображение
2508,linear model,نموذج خطي,النموذج الخطي,خطي نموذج,线性模型,线性模型,线性模型,modèle linéaire,modèle linéaire,modèle linéaire,線形モデル,- 線形モデル (せんけいモデル),線形モデル,линейная модель,линейная модель,линейная модель
2509,linear predictor,متنبئ خطي,المتنبئ الخطي,المتنبئ الخطي,线性预测器,线性预测器,线性预测器,prédicteur linéaire,prédicteur linéaire,prédicteur linéaire,線形予測子,線形予測子,線形予測器,линейный предиктор,линейный предсказатель,линейный предиктор
2510,linear probe,مسبار خطي,المسح الخطي,البحث الخطي,线性探头,线性探针,线性探测器,sonde linéaire,sonde linéaire,sonde linéaire,リニアプローブ,線形プローブ,線形プローブ,линейный датчик,линейная зонд,линейный зонд
2511,linear program,برنامج خطي,البرنامج الخطي,برنامج خطي,线性规划,线性规划 (linear program),线性规划,programme linéaire,programme linéaire,programme linéaire,線形計画,線形プログラム,線形計画法,линейная программа,линейная программа,линейная программа
2512,linear programming relaxation,استرخاء البرمجة الخطية,الاسترخاء البرمجي الخطي,استرخاء البرمجة الخطية,线性规划松弛,线性规划松弛化,线性规划松弛,relaxation de programmation linéaire,relaxation de la programmation linéaire,relaxation par programmation linéaire,線形計画法緩和,線形計画緩和 (Senkei Keikaku Kanwa),線形計画緩和,линейное программирование релаксация,линейная программирование релаксация,релаксация линейного программирования
2513,linear projection,الإسقاط الخطي,التصوير الخطي,إسقاط خطي,线性投影,线性投影,线性映射,projection linéaire,projection linéaire,projection linéaire,線形投影,線形射影,線形射影,линейная проекция,линейная проекция,линейное проецирование
2514,linear regression,الانحدارالخطي,الانحدار الخطي,الانحدار الخطي,线性回归,线性回归,线性回归,régression linéaire,régression linéaire,régression linéaire,線形回帰,線形回帰,線形回帰,линейная регрессия,линейная регрессия,линейная регрессия
2515,linear regression model,نموذج الانحدار الخطي,نموذج الانحدار الخطي,نموذج الانحدار الخطي,线性回归模型,线性回归模型,线性回归模型,modèle de régression linéaire,modèle de régression linéaire,modèle de régression linéaire,線形回帰モデル,線形回帰モデル (senkei kaiki moderu),線形回帰モデル,модель линейной регрессии,линейная регрессионная модель,линейная регрессионная модель
2516,linear regressor,الانحدارالخطي,مُعَدّل خطي,متجه انحداري خطي,线性回归,线性回归器,线性回归器,régression linéaire,- Régresseur linéaire,régresseur linéaire,線形回帰,線形回帰器,線形回帰器,линейная регрессия,линейный регрессор,линейный регрессор
2517,linear scaling,التحجيم الخطي,التحجيم الخطي,تحجيم خطي,线性缩放,线性缩放,线性缩放,mise à l'échelle linéaire,mise à l'échelle linéaire,mise à l'échelle linéaire,線形スケーリング,線形スケーリング (Senkei Sukeiringu),線形スケーリング,линейное масштабирование,линейное масштабирование,линейное масштабирование
2518,linear scheduler,جدولة خطية,الجدول الزمني الخطي,جدول زمني خطي,线性调度器,线性调度器,线性调度器,planificateur linéaire,planificateur linéaire,programmateur linéaire,リニアスケジューラ,線形スケジューラ,線形スケジューラー,линейный планировщик,линейный планировщик,линейный планировщик
2519,linear separability,الانفصال الخطي,- تمييز خطي,تفريق خطي,线性可分性,线性可分性,线性可分离性,séparabilité linéaire,linéaire séparabilité,séparabilité linéaire,線形分離性,線形分離可能性,線形可分性,линейная разделимость,линейная разделимость,линейная разделимость
2520,linear system,النظام الخطي,النظام الخطي,نظام خطي,线性系统,线性系统,线性系统,système linéaire,système linéaire,système linéaire,線形システム,- 線形システム (Senkei Shisutemu),線形システム,линейная система,линейная система,линейная система
2521,linear threshold,عتبة خطية,العتبة الخطية,عتبة خطية,线性阈值,线性阈值,线性阈值模型,seuil linéaire,Seuil linéaire,seuil linéaire,線形しきい値,線形しきい値,線形閾値,линейный порог,линейный порог,линейный порог
2522,linear threshold model,نموذج العتبة الخطية,النموذج الخطي للعتبة,نموذج العتبة الخطي,线性阈值模型,线性阈值模型,线性阈值模型,modèle de seuil linéaire,modèle de seuil linéaire,modèle de seuil linéaire,線形閾値モデル,線形閾値モデル,線形しきい値モデル,линейная пороговая модель,линейная модель порога,линейная пороговая модель
2523,linear transform,تحويل خطي,التحويل الخطي,تحويل خطي,线性变换,线性变换,线性变换,transformation linéaire,- Transformation linéaire,transformée linéaire,線形変換,- 線形変換 (senkei hensan),線形変換,линейное преобразование,линейное преобразование,линейное преобразование
2524,linear transformation,التحول الخطي,التحويل الخطي,تحويل خطي,线性变换,线性变换,- 线性变换,transformation linéaire,transformation linéaire,- transformation linéaire,線形変換,線形変換 (senkei henden),線形変換,линейное преобразование,линейное преобразование,линейное преобразование
2525,linear transformation matrix,مصفوفة التحول الخطي,مصفوفة التحويل الخطي,مصفوفة التحويل الخطي,线性变换矩阵,线性变换矩阵,线性变换矩阵,matrice de transformation linéaire,- Matrix de transformation linéaire,matrice de transformation linéaire,線形変換行列,線形変換行列,線形変換行列,матрица линейного преобразования,линейная матрица преобразования,матрица линейного преобразования
2526,linear warm-up,الاحماء الخطي,التسخين الخطي,تسخين خطي,线性预热,线性预热,线性预热,échauffement linéaire,préchauffage linéaire,montée linéaire,リニアウォームアップ,線形ウォームアップ,線形ウォームアップ,линейная разминка,линейный прогрев,линейный разогрев
2527,linear-chain,سلسلة خطية,- تسلسل خطي,سلسلة خطية,线性链,线性链,线性链,chaîne linéaire,chaîne linéaire,chaîne linéaire,直鎖,線形連鎖,線形チェーン,линейно-цепной,линейная цепь,линейная цепь
2528,linear-quadratic regulator,منظم خطي تربيعي,المنظم الخطي المربعي,نظام التحكم الخطي-التربيعي,线性二次调节器,线性二次调节器 (LQR),线性二次调节器,régulateur linéaire-quadratique,régulateur linéaire quadratique,régulateur linéaire-quadratique,線形二次レギュレータ,線形二次レギュレータ (linear-quadratic regulator),線形二次レギュレータ,линейно-квадратичный регулятор,линейно-квадратичный регулятор,линейно-квадратический регулятор
2529,linearization,الخطية,الخطية,تخطيح,线性化,线性化,线性化,linéarisation,linéarisation,linéarisation,線形化,線形化,線形化,линеаризация,линейная аппроксимация,линеаризация
2530,link function,وظيفة الارتباط,وظيفة الربط,دالة الربط,链接功能,联系函数,联系函数,fonction de lien,fonction de lien,fonction de lien,リンク機能,リンク関数,リンク関数,функция ссылки,функция связи,функция связи
2531,link prediction,توقعات الارتباط,التنبؤ بالروابط,التنبؤ بالروابط,链接预测,链接预测,链路预测,prédiction de lien,prédiction de lien,prédiction de lien,リンク予測,リンク予測 (link prediction),リンク予測,прогнозирование ссылок,предсказание связей,прогнозирование связей
2532,local basis function,وظيفة الأساس المحلي,وظيفة قاعدية محلية,دالة الأساس المحلية,局部基函数,局部基函数,局部基函数,fonction de base locale,fonction de base locale,fonction de base locale,局所基底関数,局所基底関数,ローカル基底関数,локальная базисная функция,локальная базисная функция,локальная базисная функция
2533,local coherence,التماسك المحلي,الترابط المحلي,ترابط محلي,局部一致性,局部连贯,局部连贯性,cohérence locale,cohérence locale,cohérence locale,ローカルコヒーレンス,ローカル整合性,ローカル一貫性,локальная согласованность,локальная когерентность,локальная связность
2534,local consistency,الاتساق المحلي,الاتساق المحلي,ثبات محلي,局部一致性,局部一致性,局部一致性,cohérence locale,cohérence locale,cohérence locale,ローカルな一貫性,局所的一貫性,ローカル整合性,локальная согласованность,локальная согласованность,Локальная согласованность
2535,local context,السياق المحلي,السياق المحلي,محلي سياق,当地背景,"""['我们上面描述的特征本质上包括四个特征组：本地上下文（LC），全局上下文（GC），句法关系（SR）和POS特征。为了利用这样一个自然的特征拆分，我们探索了联合线性模型的以下扩展：\n'，'结果符合我们的期望。为了学习本地上下文（LC）",本地上下文,contexte local,contexte local,contexte local,ローカルコンテキスト,ローカルコンテキスト,局所的コンテキスト,местный контекст,локальный контекст,локальный контекст
2536,local coordinate frame,إطار الإحداثيات المحلية,الإطار المحلي للإحداثيات,إطار المحاور المحلي,局部坐标系,局部坐标系,局部坐标系,cadre de coordonnées locales,- Cadre de coordonnées local,cadre de coordonnées local,ローカル座標フレーム,ローカル座標系 (Local Coordinate Frame),ローカル座標系,локальная система координат,локальная система координат,локальная система координат
2537,local feature,الميزة المحلية,الميزة المحلية,سمة محلية,地方特色,本地特征,局部特征,caractéristique locale,caractéristique locale,caractéristique locale,局所的特徴,ローカル特徴,ローカル特徴,местная особенность,локальная особенность,локальная характеристика
2538,local geometry,الهندسة المحلية,الهندسة المحلية,الشكل الهندسي المحلي,局部几何,本地几何,局部几何,géométrie locale,géométrie locale,géométrie locale,ローカルジオメトリ,局所幾何 (Kyokusho Kikai),ローカル幾何学,локальная геометрия,локальная геометрия,локальная геометрия
2539,local image feature,ميزة الصورة المحلية,الميزة المحلية للصورة,ميزة صورة محلية,局部图像特征,本地图像特征 (local image feature),局部图像特征,fonctionnalité d'image locale,caractéristique d'image locale,descripteur d'image local,ローカル画像機能,ローカル画像特徴,局所画像特徴,локальная функция изображения,локальная характеристика изображения,локальная особенность изображения
2540,local maxima,الحد الأقصى المحلي,القمم المحلية,النقاط القصوى المحلية,局部最大值,局部最大值,局部最大值,maxima locaux,maxima locaux,maximums locaux,極大値,局所最大値,ローカル最大値,локальные максимумы,локальные максимумы,локальные максимумы
2541,local maximum,الحد الأقصى المحلي,القيمة المحلية القصوى,نقطة ذروة محلية,局部最大值,局部极大值,局部最大值,maximum local,maximum local,maximum local,極大値,局所最大値,ローカルマキシマム,локальный максимум,локальный максимум,локальный максимум
2542,local minima,الحد الأدنى المحلي,النقاط الدنيا المحلية,حدات صغرى محلية,局部最小值,局部极小值,局部最小值,minimums locaux,minima locaux,minima locaux,極小値,局所最小値,局所最小値,локальные минимумы,локальные минимумы,локальные минимумы
2543,local minimizer,المصغر المحلي,الحد الأدنى المحلي,مُصَغِّر مُحَلِّي,局部最小化器,局部极小值点,局部极小值点,minimiseur local,minimiseur local,minimiseur local,ローカルミニマイザー,局所最小値,ローカル最小化点,локальный минимизатор,локальный минимум,локальный минимизатор
2544,local minimum,الحد الأدنى المحلي,الحد الأدنى المحلي,الحد الأدنى المحلي,局部最小值,局部最小值,局部最小值,minimum local,minimum local,minimum local,極小値,局所最小値,ローカル最小値,локальный минимум,локальный минимум,локальный минимум
2545,local model,النموذج المحلي,نموذج محلي,نموذج محلي,本地模型,本地模型,局部模型,modèle local,modèle local,modèle local,ローカルモデル,ローカルモデル,ローカルモデル,местная модель,локальная модель,локальная модель
2546,local optima,الأمثل المحلي,الأقصى المحلية,محليات مثلى,局部最优,局部最优解,局部最优值,valeurs optimales locales,optima locaux,optima locaux,ローカルオプティマ,局所最適解,局所最適解,локальный оптимум,локальные оптимумы,локальные оптимумы
2547,local optimum,الأمثل المحلي,النقطة المحلية الأمثل,محلي أمثل,局部最优,局部最优解,局部最优解,optimal local,optimum local,optimum local,局所最適,局所最適解 (Kyokusho Saitekikai),局所最適解,локальный оптимум,локальный оптимум,локальный оптимум
2548,local parameter,المعلمة المحلية,المعلمة المحلية,معلمات محلية,局部参数,局部参数,局部参数,paramètre local,paramètre local,paramètres locaux,ローカルパラメータ,ローカルパラメータ,ローカルパラメータ,локальный параметр,локальный параметр,локальные параметры
2549,local search,البحث المحلي,البحث المحلي,البحث المحلي,本地搜索,局部搜索,局部搜索,recherche locale,recherche locale,recherche locale,ローカル検索,局所探索,ローカル探索,локальный поиск,локальный поиск,локальный поиск
2550,local search method,طريقة البحث المحلية,طريقة البحث المحلي,طريقة البحث المحلية,本地搜索法,局部搜索方法,局部搜索方法,méthode de recherche locale,méthode de recherche locale,méthode de recherche locale,ローカル検索方法,局所探索法,局所探索法,метод локального поиска,метод локального поиска,метод локального поиска
2551,local variable,متغير محلي,المتغير المحلي,متغير محلي,局部变数,局部变量,局部变量,variable locale,variable locale,variable locale,ローカル変数,ローカル変数 (Local Variable),ローカル変数,локальная переменная,локальная переменная,локальная переменная
2552,local window,نافذة محلية,نافذة محلية,النافذة المحلية,本地窗口,局部窗口,局部窗口,fenêtre locale,fenêtre locale,fenêtre locale,ローカルウィンドウ,ローカルウィンドウ,ローカルウィンドウ,локальное окно,локальное окно,локальное окно
2553,locality-sensitive hashing,التجزئة الحساسة للمنطقة,تجزء معايير التجزئة الحساسة للموقعية,تجميع الهاشات الحساس للموقع,局部敏感哈希,局部敏感哈希,对局部敏感哈希,hachage sensible à la localité,hachage sensible à la localité,hashage sensible à la localité,局所性を考慮したハッシュ化,局所性に敏感なハッシング (Kyokusho-sei ni Senshin-na Hashingu),局所性感受ハッシュ,хеширование с учетом местоположения,"хэширование, чувствительное к локальности",Хеширование с учетом локальности
2554,localization,الموقع,الموضعية,تحديد الموقع,本土化,本地化,定位,localisation,localisation,localisation,ローカリゼーション,ローカリゼーション,局所化,локализация,локализация,локализация
2555,location parameter,معلمة الموقع,معلم الموقع,معامل الموقع,位置参数,位置参数,位置参数,paramètre de localisation,paramètre de localisation,paramètre de localisation,位置パラメータ,位置パラメータ,位置母数,параметр местоположения,параметр местоположения,параметр положения
2556,log,سجل,- تسجيل,لوغاريتم,日志,"""['证明。我们通过归纳证明定理3.2。我们将log p θ (y | x) − λ • R greedy (y)的argmax表示为y R，并将贪婪搜索找到的解表示为y greedy。', '损失函数util(y i ,p i ,q j ,ā j ) = y i log(σ(F util (p i ,q j ,ā j )))(4)', '例如，对于语言对p(x, y)训练",对数,enregistrer,logarithme,journal,ログ,ログ,対数,бревно,лог,журнал
2557,log likelihood,تسجيل احتمال,- تسجيل الاحتمالية,احتمالية لوغاريتمية,对数似然,对数似然值,对数似然,log de vraisemblance,log-vraisemblance,vraisemblance des données,対数尤度,対数尤度,データの対数尤度,логарифм вероятности,логарифмическое правдоподобие,логарифмическая правдоподобность
2558,log loss,فقدان السجل,فقدان السجل,خسارة اللوغاريتم,对数损失,对数损失,对数损失,perte de journal,perte logarithmique,perte logarithmique,ログの損失,ログ損失,ログ損失,потеря журнала,Логарифмическая потеря,логарифмический убыток
2559,log marginal likelihood,سجل احتمالية هامشية,سجل الاحتمالية الحاشية,لوغاريتم الاحتمال الهامشي,对数边际似然,对数边际似然 (log marginal likelihood),对数边缘似然,log de vraisemblance marginale,log-vraisemblance marginale,log vraisemblance marginale,対数周辺尤度,ログ周辺尤度 (LML),対数周辺尤度,логарифм предельной вероятности,логарифмическое предельное правдоподобие,логарифмическое граничное правдоподобие
2560,log p,سجل ص,- تسجيل p,ذيل لوغاريتم الاحتمال,对数p,对数概率,log p 的中文翻译是 对数概率,journal p,log p,journal p,ログp,ログ p (keep as is),ログp,журнал р,лог p,Логарифмическая вероятность (log p)
2561,log partition function,وظيفة قسم السجل,وظيفة التقسيم اللوغاريتمي,دالة التجزئة اللوغاريتمية,对数分区函数,对数分割函数 (log partition function),对数分割函数,fonction de partition de journal,fonction de partition logarithmique,fonction de partition logarithmique,ログパーティション機能,ログパーティション関数,対数パーティション関数,функция разделения журнала,логарифмическая функция разбиения,логарифмическая партиционная функция
2562,log perplexity,سجل الحيرة,- تعقيد السجل,اللوغاريتم الترددي,记录困惑,对数困惑度,对数困惑度,journal perplexité,log perplexité,perplexité logarithmique,ログの複雑さ,ログパープレキシティ (log perplexity),ログパープレキシティ,войти в недоумение,логарифмическая перплексия,логарифмическая перплексность
2563,log probability,احتمال السجل,احتمالات اللوغاريتمية,احتمالية لوغاريتمية,对数概率,对数概率,对数概率,log de probabilité,probabilité logarithmique,probabilité logarithmique,対数確率,対数確率,ログ確率,логарифм вероятности,логарифм вероятности,вероятность логарифма
2564,log-likelihood function,وظيفة احتمال السجل,وظيفة سجل الاحتمالية,دالة الاحتمال اللوغاريتمية,对数似然函数,对数似然函数,对数似然函数,fonction de log-vraisemblance,fonction de log-vraisemblance,fonction de vraisemblance logarithmique,対数尤度関数,対数尤度関数,対数尤度関数,функция логарифмического правдоподобия,функция логарифма правдоподобия,функция логарифмического правдоподобия
2565,log-likelihood loss,خسارة احتمال السجل,الخسارة بالإحتمال اللوغاريمياء,خسارة اللوغاريتم التشابهية,对数似然损失,对数似然损失,负对数似然损失,perte de log-vraisemblance,perte de vraisemblance logarithmique,perte de log-vraisemblance,対数尤度損失,対数尤度損失,対数尤度損失,логарифмическая потеря вероятности,Потеря логарифма правдоподобия,потери отрицательного правдоподобия
2566,log-likelihood ratio,نسبة احتمال السجل,نسبة الإمكانية المتسجلة,نسبة اللوغاريتم للاحتمال,对数似然比,对数似然比,对数似然比,rapport de log-vraisemblance,rapport des logarithmes de vraisemblance,rapport de vraisemblance,対数尤度比,対数尤度比,対数尤度比,логарифмическое отношение правдоподобия,логарифмическое отношение правдоподобия,логарифмическое отношение правдоподобия
2567,log-linear model,النموذج الخطي اللوغاريتمي,نموذج لوغاريتمي خطي,نموذج لوغاريتمي خطي,对数线性模型,对数线性模型,对数线性模型,modèle log-linéaire,modèle log-linéaire,modèle log-linéaire,対数線形モデル,対数線形モデル (taijū senkei moderu),log線形モデル,лог-линейная модель,лог-линейная модель,логлинейная модель
2568,log-linear translation model,نموذج الترجمة الخطية,نموذج ترجمة لوغاريتمي تحليلي,نموذج الترجمة اللّوغاريتمي الخطي,对数线性翻译模型,对数线性翻译模型,对数线性翻译模型,modèle de traduction log-linéaire,modèle de traduction log-linéaire,modèle de traduction log-linéaire,対数線形変換モデル,対数線形翻訳モデル,対数線形翻訳モデル,лог-линейная модель перевода,модель лог-линейного перевода,log-линейная модель перевода
2569,log-log plot,مؤامرة سجل السجل,نمط البيانات اللوغاريتمي-اللوغاريتمي,رسم لوغاريتمي مزدوج,双对数图,对数-对数图,对数-对数曲线图,tracé log-log,graphique log-log,Tracé log-log,対数対数プロット,対数-対数プロット,log-log プロット,логарифмический график,логарифмический график,log-log график
2570,log-normal distribution,التوزيع الطبيعي للسجل,التوزيع لوغاريتمي-طبيعي,توزيع لوغاريتمي طبيعي,对数正态分布,对数正态分布,对数正态分布,distribution log-normale,distribution log-normale,distribution log-normale,対数正規分布,対数正規分布 (Taisū seiki bunpu),対数正規分布,логнормальное распределение,логнормальное распределение,логнормальное распределение
2571,log-odd score,سجل النتيجة الفردية,نقاط سجل الأرقام المحسوبة,درجة لوغاريتم الرجحان,对数奇分数,对数几率分数,对数几率得分,score log-impair,score de log-ratio,score de log-vraisemblance,対数奇数スコア,ログオッズスコア,対数オッズスコア,логарифмически-нечетный счет,Оценка логарифмической вероятности,оценка логарифма шансов
2572,log-prob,log-prob,- تسجيل احتمالية,احتمالية لوغاريتمية,对数概率,对数概率 (log-prob),对数概率,journal-prob,log-prob,log-vraisemblance,ログプロブ,対数確率,log確率,лог-проба,лог-вероятность,log-вероятность
2573,log-sum-exp,سجل مجموع EXP,- التسجيل المجموع التفاضلي,الصيغة log-sum-exp,对数和表达式,对数和指数函数,对数指数和,log-somme-exp,log-sum-exp,logsumexp,対数和式,対数和指数,ログ-サム-エクスポネンシャル,лог-сумма-эксп,"""['Для каждого запроса q i первый член M (q i , K) становится лог-суммой-экспоненты скалярного произведения фиксированного запроса q i и всех ключей, и мы можем определить f i (K) = ln \n L K j=1 e qik j / √ d. Из уравнения.', 'log L(x) = log k exp t −",логарифмическая-сумма-экспонента
2574,logical connective,اتصال منطقي,ربط منطقي,رابط منطقي,逻辑连接词,逻辑连接词,逻辑连接词,connecteur logique,connecteur logique,connecteur logique,論理接続詞,論理結合子,論理結合子,логическая связка,логическое связывание,логическая связка
2575,logical form,شكل منطقي,الشكل المنطقي,الصيغة المنطقية,逻辑形式,逻辑形式,逻辑形式,forme logique,forme logique,forme logique,論理形式,論理形式,論理形式,логическая форма,логическая форма,логическая форма
2576,logistic function,وظيفة لوجستية,الدالة اللوجستية,دالة لوجستية,物流功能,逻辑函数,逻辑函数,fonction logistique,fonction logistique,fonction logistique,ロジスティック関数,ロジスティック関数 (rojistikku kansuu),ロジスティック関数,логистическая функция,логистическая функция,логистическая функция
2577,logistic loss,خسارة لوجستية,الخسارة اللوجستية,خسارة اللوجستية,物流损失,逻辑损失,逻辑损失,perte logistique,perte logistique,perte logistique,物流損失,ロジスティック損失,ロジスティック損失,логистические потери,логистическая потеря,функция потерь логистической регрессии
2578,logistic regression,الانحدار اللوجستي,"""يمكن التفكير في التحويل اللوجستي كتنفيذ للتحويل الخطي تليه وظيفة سيجما على الإخراج، وبسبب ذلك تنتقل تحسيناتنا للتحويل الخطي إلى التحويل اللوجستي. تتراوح ت",الانحدار اللوجستي,逻辑回归,逻辑回归,逻辑回归,régression logistique,régression logistique,régression logistique,ロジスティック回帰,"""['ロジスティック回帰は、出力に対してシグモイド関数を実行した線形回帰の実行と考えることができるため、線形回帰の改善がロジスティックに持ち越される。私たちの改善範囲は、LAN上で5.95×から67.88×、WAN上",ロジスティック回帰,логистическая регрессия,логистическая регрессия,логистическая регрессия
2579,logistic regression classifier,مصنف الانحدار اللوجستي,مصنف التحليل اللوجستي,تصنيف الانحدار اللوجستي,逻辑回归分类器,逻辑回归分类器,逻辑回归分类器,classificateur de régression logistique,classificateur de régression logistique,classifieur par régression logistique,ロジスティック回帰分類器,ロジスティック回帰分類器,ロジスティック回帰分類器,классификатор логистической регрессии,логистический регрессионный классификатор,классификатор логистической регрессии
2580,logistic regression model,نموذج الانحدار اللوجستي,نموذج الانحدار اللوجستي,نموذج الانحدار اللوجستي,逻辑回归模型,逻辑回归模型,逻辑回归模型,modèle de régression logistique,- Modèle de régression logistique,modèle de régression logistique,ロジスティック回帰モデル,ロジスティック回帰モデル,ロジスティック回帰モデル,модель логистической регрессии,логистическая регрессионная модель,логистическая регрессионная модель
2581,logit,logit,اللوجات,لوجت,对数,"""['在上述公式中，我们可以忽略单视角数据对于1-logit i(F(t),X)项，因为它们非常小(参见声明G.10)。现在，如果我们取r = arg max r∈[m]w(t)i,r,v_i，我们必须有(每当v_i,1,v_i,2∈V(X)) Vi,r,(X)≥Ω(1)•ReLU w(t)i,r'，'在每",logit值,se connecter,"""['Dans la formule ci-dessus, nous pouvons ignorer les données de vue unique pour le terme 1 − logit i (F (t) , X) car elles sont extrêmement petites (voir Réclamation G.10). Maintenant, si nous prenons r = arg max r∈ [ m ] w ( t ) i , r , v i , , nous devons avoir ( chaque fois que v i,1 , v i,2 ∈ V ( X ) ) V i , r , ( X ) ≥ Ω",logit,ロジット,ロジット,ロジット,логит,логит,логит
2582,logit model,نموذج لوجيت,نموذج لوجيت,نموذج اللوجت,逻辑模型,对数几率模型,对数几率模型,modèle logit,modèle logit,modèle de régression logistique,ロジットモデル,ロジットモデル,ロジットモデル,логит-модель,модель логитов,логит-модель
2583,long-range dependency,التبعية طويلة المدى,التبعية طويلة المدى,اعتمادية بعيدة المدى,远程依赖,- 长程依赖,长程依赖,dépendance à long terme,dépendance à longue portée,dépendance à longue portée,長距離依存,"""['モデルのスケーラビリティを使用して、増加した集約ステップで大規模な近隣地域に対応する能力を説明します。この背後にある理由は、彼らの集約プロセスが固定ホップ近隣地域に制約されており、異なるノードの",長距離依存性,долгосрочная зависимость,долгосрочная зависимость,долговременная зависимость
2584,lookup table,جدول البحث,جدول البحث,جدول البحث,查找表,查找表,查找表,table de recherche,- Table de recherche,table de consultation,ルックアップテーブル,ルックアップテーブル,検索テーブル,Справочная таблица,таблица поиска,таблица просмотра
2585,loop closure,إغلاق الحلقة,- تقفل الحلقة,إغلاق الحلقة,闭环,闭环检测,闭环,fermeture de boucle,fermeture de boucle,fermeture de boucle,ループクロージャ,ループクロージャー,ループクロージャ,закрытие петли,замыкание петли,замыкание цикла
2586,loopy belief propagation,نشر الاعتقاد مجنون,- تنقل الاعتقاد الحلقي,انتشار الاعتقاد الحلقي,疯狂的信念传播,循环信念传播,环状信念传播,propagation de croyances folles,propagation des croyances en boucle,propagation des croyances cycliques,おかしな信念の伝播,ルーピービリーフ伝播,ループ信念伝播,беспорядочное распространение убеждений,циклическое распространение убеждений,Распространение ненадежных убеждений
2587,loss,خسارة,فقدان,دالة الخسارة,损失,损失,损失函数,perte,perte,perte,損失,損失 (そんしつ),損失,потеря,"""['Выбрав случайного ребенка z, который был ошибочно определен моделью, мы рассчитали −I up, потеря (z i , z test ) для каждой обучающей точки z i . Это явно выявило 4 обучающих детей, каждый из которых был влиятельнее в 30-40 раз, чем следующие по влиятельности примеры.', 'Таким",функционал потерь
2588,loss distribution,توزيع الخسارة,توزيع الخسارة,توزيع الخسارة,损失分布,损失分布,损失分布,répartition des pertes,distribution des pertes,distribution des pertes,損失の分配,損失分布 (Sonnai Bunsu),損失分布,распределение потерь,распределение потерь,распределение потерь
2589,loss function,فقدان وظيفة,وظيفة الخسارة,وظيفة الخسارة,损失函数,损失函数,损失函数,fonction de perte,- Fonction de perte,fonction de perte,損失関数,損失関数,損失関数,функция потерь,Функция потерь,функция потерь
2590,loss landscape,مشهد الخسارة,المناظر الضائعة,توضيح المنحدرات الخسارة,损失景观,损失景观,损失景观,paysage de perte,paysage de perte,paysage de perte,喪失の風景,損失地形 (Sonnichi),損失地形,пейзаж потери,потеря пейзажа,ландшафт потерь
2591,loss minimization,التقليل من الخسارة,تقليل الخسارة,تقليل الخسارة,损失最小化,损失最小化,损失最小化,minimisation des pertes,minimisation de perte,minimisation de la perte,損失の最小化,損失最小化,損失最小化,минимизация потерь,минимизация потерь,минимизация потерь
2592,loss term,مصطلح الخسارة,مصطلح الخسارة,مصطلح الخسارة,损失项,损失项,损失项,terme de perte,terme de perte,terme de perte,損失期間,損失項 (sosoku-kou),損失項,срок убытка,термин потерь,функция потерь
2593,lossy compression,الضياع,ضغط ذو فقدان,ضغط مفقد,有损压缩,有损压缩,有损压缩,la compression avec perte,compression avec perte,compression avec pertes,非可逆圧縮,損失圧縮,損失圧縮,сжатие с потерями,сжатие с потерями,сжатие с потерями
2594,lottery ticket hypothesis,فرضية تذكرة اليانصيب,- تفرضية تذكرة اليانصيب,فرضية اليانصيب,彩票假设,彩票假设,彩票假说,hypothèse d'un billet de loterie,- Hypothèse du billet de loterie,hypothèse du billet gagnant,宝くじ仮説,抽選券仮説,宝くじチケット仮説,гипотеза лотерейного билета,гипотеза лотерейного билета,гипотеза удачного билета
2595,low rank,مرتبة متدنية,- تصنيف منخفض,رتبة منخفضة,低等级,低秩,低阶,rang inférieur,de bas rang,rang faible,下位,低ランク,低ランク,низкий ранг,низкий ранг,низкого ранга
2596,low rank approximation,تقريب رتبة منخفضة,التقريب ذو المرتبة المنخفضة,تقريب الرتبة المنخفضة,低秩近似,低秩近似,低秩近似,approximation de rang faible,approximation de rang faible,approximation de faible rang,低ランク近似,低ランク近似 (tei ranku kinji),低ランク近似,аппроксимация низкого ранга,аппроксимация низкого ранга,низкоранговое приближение
2597,low-data regime,نظام البيانات المنخفضة,- المنظمة البيانات المنخفضة,نظام البيانات المنخفضة,低数据制度,低数据范围,少量数据环境,régime de données faibles,régime de faibles données,régime de données limitées,低データ体制,低データ領域,少量データ領域,режим с низким уровнем данных,режим недостаточных данных,режим с малым количеством данных
2598,low-dimensional embedding,التضمين منخفض الأبعاد,تضمين بعدي منخفض,التضمين ذو الأبعاد المنخفضة,低维嵌入,低维嵌入,低维嵌入,intégration de faible dimension,incorporation à basse dimension,plongement de faible dimension,低次元埋め込み,低次元埋め込み,低次元埋め込み,низкоразмерное вложение,низкоразмерное вложение,низкоразмерное встраивание
2599,low-dimensional representation,تمثيل منخفض الأبعاد,التمثيل ذو الأبعاد المنخفضة,تمثيل ذو أبعاد منخفضة,低维表示,低维表示,低维表示,représentation en basse dimension,représentation en basse dimension,représentation de faible dimension,低次元表現,低次元表現,低次元表現,низкоразмерное представление,низкоразмерное представление,низкоразмерное представление
2600,low-pass filter,مرشح تمرير منخفض,- تصفية مرشح الانخفاض,متر التردد المنخفض,低通滤波器,低通滤波器,低通滤波器,filtre passe bas,Filtre passe-bas,filtre passe-bas,ローパスフィルタ,低域通過フィルタ,低域フィルタ,фильтр нижних частот,низкочастотный фильтр,фильтр нижних частот
2601,low-rank factorization,التخصيم ذو الرتبة المنخفضة,تصنيع عوامل قليلة الرتبة,تجزئة منخفضة الرتبة,低阶因式分解,低秩分解,低秩分解,factorisation de bas rang,factorisation de rang faible,factorisation de faible rang,低階因数分解,低ランク分解,低ランク分解,факторизация низкого ранга,низкоранговая факторизация,Разложение низкого ранга
2602,low-rank matrix approximation,تقريب المصفوفة ذات الرتبة المنخفضة,التقريب الصفي المنخفض للمصفوفة,تقريب المصفوفة منخفضة الرتبة,低秩矩阵近似,低秩矩阵逼近,低秩矩阵近似,approximation matricielle de bas rang,approximation de matrice de rang faible,approximation de matrice de faible rang,低ランク行列近似,低ランク行列近似,低ランク行列近似,аппроксимация матрицы низкого ранга,Аппроксимация матриц низкого ранга,низкоранговое приближение матрицы
2603,lower bind,الربط السفلي,الحد السفلي,حَد أدنى,下限,下界,下界,liaison inférieure,borne inférieure,borne inférieure,下バインド,下部バインド,下限値,нижняя привязка,нижняя граница,нижняя граница
2604,m-estimation,تقدير م,- تقدير m,تقدير-م,m-估计,M-估计,极大估计,m-estimation,m-estimation,estimation-m,m推定,m-推定,M推定法,m-оценка,m-оценка,M-оценка
2605,m-step,خطوة م,خطوة الـM,خطوة م,m步,"""['在这个设置中，E步的形式与(4)相似，但是在r的总和中被替换为满足r 1,1 = 1和r N,N = 1的排列矩阵的总和。A的M步更新k+1保持不变。','HMRF-KMEANS的基本思想是：在E步中，给定当前的簇代表，每个数据点都被重新分配到",M步,m-pas,étape M,étape-m,mステップ,Mステップ,M-ステップ,м-шаг,m-шаг,Шаг-М
2606,mIoU,mIoU,معدل تداخل الانسجام (mIoU),نسبة الاتحاد المتوسطة (mIoU),米卢,平均交并比,mIoU,mIoU,"""['(2019), qui notent la ponctuation de BERT (Devlin et al., 2019) pour y assister largement. Pour les noms associés par ""et"" (rangée 5), les cartes se chevauchent moins (38,7 mIoU vs 50+), probablement en raison d'une séparation visuelle (par exemple, ""chat et chien"").', 'Pour remédier à cela, nous avons constaté que la suréchantillonnage des masques man",mIoU,ミオ,平均Intersection over Union,平均IoU,МИЛО,mIoU,mIoU
2607,mT5,mT5,إم تي 5,مت5 (mT5),mT5,mT5,mT5,mT5,"""Nous utilisons principalement mBART (mBART-large-50, mBART-50-large-NMT) et mT5 (mT5-small, mT5-base) pour nos modèles multilingues pré-entraînés de base.""",mT5,mT5,mT5,mT5,мТ5,mT5,мТ5
2608,machine comprehension,فهم الآلة,- تفهم الآلة,فهم الآلة,机器理解,机器理解,机器理解,compréhension des machines,compréhension de machine,compréhension automatique,機械の理解,機械理解 (Kikai Rikai),機械理解,машинное понимание,машинное понимание,машинное понимание
2609,machine learning,التعلم الالي,تعلم الآلة,تعلم الآلة,机器学习,机器学习,机器学习,apprentissage automatique,apprentissage automatique,apprentissage automatique,機械学習,"""['have entered into space by offering ""Machine Learning as a Service (MLaaS)"". MLaaS works in two different ways, depending on the enduser. The first scenario is companies offering their trained machine learning models that a customer can query to obtain the prediction result.', 'For future work, we plan to extend our meta-evaluation of MT to publications at conferences in other research domains, such as Machine Learning and Artificial Intelligence. As a final note, we would like to encourage NLP researchers to perform",機械学習,машинное обучение,Машинное обучение,машинное обучение
2610,machine learning algorithm,خوارزمية التعلم الآلي,- تحليل خوارزمية التعلم الآلي,خوارزمية التعلم الآلي,机器学习算法,机器学习算法,机器学习算法,algorithme d'apprentissage automatique,algorithme d'apprentissage automatique,algorithme d'apprentissage automatique,機械学習アルゴリズム,機械学習アルゴリズム,機械学習アルゴリズム,алгоритм машинного обучения,алгоритм машинного обучения,алгоритм машинного обучения
2611,machine learning classifier,مصنف التعلم الآلي,مصنف التعلم الآلي,صنف تعلم الآلة,机器学习分类器,机器学习分类器 (jī qì xué xí fēn lèi qì),机器学习分类器,classificateur d'apprentissage automatique,classificateur d'apprentissage automatique,classificateur d'apprentissage automatique,機械学習分類器,マシンラーニング分類器,機械学習分類器,классификатор машинного обучения,классификатор машинного обучения,машинный классификатор
2612,machine learning model,نموذج التعلم الآلي,نموذج التعلم الآلي,نموذج التعلم الآلي,机器学习模型,机器学习模型,机器学习模型,modèle d'apprentissage automatique,modèle d'apprentissage automatique,modèle d'apprentissage automatique,機械学習モデル,機械学習モデル (きかいがくしゅうモデル),機械学習モデル,модель машинного обучения,модель машинного обучения,модель машинного обучения
2613,machine learning repository,مستودع التعلم الآلي,مستودع التعلم الآلي,مستودع تعلم الآلة,机器学习存储库,机器学习库,机器学习仓库,référentiel d'apprentissage automatique,référentiel d'apprentissage automatique,dépôt d'apprentissage automatique,機械学習リポジトリ,機械学習リポジトリ (kikai gakushuu ripojitori),機械学習リポジトリ,репозиторий машинного обучения,репозиторий машинного обучения,машинное обучение репозиторий
2614,machine learning system,نظام التعلم الآلي,نظام التعلم الآلي,نظام التعلم الآلي,机器学习系统,机器学习系统,机器学习系统,système d'apprentissage automatique,système d'apprentissage automatique,système d'apprentissage machine,機械学習システム,機械学習システム (きかいがくしゅうシステム),機械学習システム,система машинного обучения,система машинного обучения,машинная система обучения
2615,machine reading,قراءة الآلة,قراءة الآلة,قراءة الآلة,机器阅读,机器阅读,机器阅读,lecture automatique,lecture automatique,lecture automatique,機械読み取り,機械読解 (kikai dokkai),機械読解,машинное чтение,машинное чтение,машинное чтение
2616,machine reading comprehension,فهم القراءة الآلية,الفهم الآلي للقراءة الآلية,فهم القراءة الآلية,机器阅读理解,机器阅读理解,机器阅读理解 (Machine Reading Comprehension),compréhension en lecture automatique,compréhension de lecture par machine,compréhension de lecture automatique,機械の読解力,機械読解能力 (Machine Reading Comprehension),機械読解能力,понимание машинного чтения,машинное понимание текста,машинное понимание прочитанного
2617,machine translation,الترجمة الآلية,ترجمة الآلة,الترجمة الآلية,机器翻译,机器翻译 (Machine Translation),机器翻译,traduction automatique,traduction automatique,traduction automatique,機械翻訳,"""['VOLTによって検索された語彙は、一般的に使用されている語彙よりもバイリンガル機械翻訳設定で優れています。Dingら（2019）は、2017年と2018年に機械翻訳の研究トラックで受け入れられ",機械翻訳,машинный перевод,машинный перевод,машинный перевод
2618,machine translation model,نموذج الترجمة الآلية,نموذج ترجمة آلية,نموذج الترجمة الآلية,机器翻译模型,机器翻译模型,机器翻译模型,modèle de traduction automatique,- Modèle de traduction automatique,modèle de traduction automatique,機械翻訳モデル,機械翻訳モデル,機械翻訳モデル,модель машинного перевода,модель машинного перевода,модель машинного перевода
2619,machine translation system,نظام الترجمة الآلية,نظام ترجمة الآلة,نظام الترجمة الآلية,机器翻译系统,机器翻译系统,机器翻译系统,système de traduction automatique,système de traduction automatique,système de traduction automatique,機械翻訳システム,機械翻訳システム,機械翻訳システム,система машинного перевода,система машинного перевода,машинная система перевода
2620,machine vision,رؤية الجهاز,رؤية الآلة,الرؤية الآلية,机器视觉,机器视觉,机器视觉,vision industrielle,- Vision par ordinateur,vision artificielle,マシンビジョン,マシンビジョン (Machine Vision),機械視覺,машинное зрение,машинное зрение,машинное зрение
2621,machine-generate text,إنشاء نص آليًا,نصوص تولد آلياً,نص منشأ آليًا,机器生成文本,机器生成的文本,机器生成文本,texte généré automatiquement,texte généré par machine,texte généré par machine,機械生成のテキスト,機械生成テキスト,機械生成テキスト,машинно-генерируемый текст,машинно-сгенерированный текст,Машинно-генерированный текст
2622,machine-in-the-loop,آلة في الحلقة,نمط التصميم الخاص بالجهاز في الحلقة,آلة في المسار,机器在环,机器在循环中,人机协作,machine dans la boucle,machine dans la boucle,machine-dans-la-boucle,マシンインザループ,マシン・インザ・ループ (machine-in-the-loop),人間介在型システム,машина в цикле,машина-в-петле,машина в цикле
2623,macro-F1,ماكرو F1,- الماكرو-F1,معدل F1 الكلي,宏F1,宏观-F1,宏F1值,macro-F1,"Comparaison des performances des aligneurs automatiques générés par mT5 avec le reste des méthodes en termes de macro-F1.', 'La méta-évaluation des métriques ci-dessus utilise le benchmark de détection des déséquilib",macro-F1,マクロ-F1,マクロF1,マクロF1,макро-F1,макро-F1,макро-F1
2624,macro-action,العمل الكلي,إجراءات ماكرو,إجراء كبير,宏观行动,宏观动作,宏操作,macro-action,macro-action,macro-action,マクロアクション,マクロアクション,大規模アクション,макродействие,макро-действие,макродействие
2625,macro-average,المتوسط ​​الكلي,- المتوسط الكبير,متوسط كبير,宏观平均,宏平均,宏平均,macro-moyenne,macro-moyenne,macro-moyenne,マクロ平均,マクロ平均,マクロ平均,макросредний,макро-среднее,макросреднее
2626,majority voting,تصويت الأغلبية,التصويت الأكثرية,التصويت بالأغلبية,多数投票,多数投票,多数投票,vote majoritaire,vote majoritaire,vote majoritaire,多数決,"""収集されたサンプルに基づいて、多数決投票により各観測値のラベルを取得し、変動情報基準を使用して結果のクラスターとグラウンド・トゥルースの間の相違性を測定して性能を評価しました。各パラメータ設定で、実験",過半数決,большинство голосов,голосование большинства,голосование большинством
2627,manifold,متعددة,التصنيف الفرعي,متعدد,歧管,流形,流形,collecteur,variété,variété,多様な,多様体,多様体,многообразие,многообразие,многообразие
2628,manifold hypothesis,فرضية متعددة,فرضية الرتبة,فرضية المُتعدّد,流形假设,流形假设,流形假设,hypothèse multiple,hypothèse de variété,hypothèse de variété,多様体仮説,多様体仮説,多様体仮説,многообразная гипотеза,гипотеза о многообразии,гипотеза многообразия
2629,manifold learn,تعلم متعددة,تعلم الأبعاد,تعلم المنضدة,流形学习,流形学习 (Liúxíng xuéxí),流形学习,apprendre plus,apprentissage de variété,apprentissage de variété,多様に学ぶ,多様体学習 (Tayotate Gakushu),多様体学習,многообразие знаний,множественное обучение,обучение на многообразии
2630,manifold projection,الإسقاط المتنوع,التصوير المتعدد الأشكال,إسقاط المتجهات,流形投影,流形投影,流形投影,projection multiple,projection sur la variété,projection sur une variété,多様体投影,多様体射影,多様体射影,многообразная проекция,многообразие проекции,проекция многообразия
2631,manifold structure,هيكل متعدد,هيكل الرقعة,التركيب المتجسد,流形结构,流形结构,流形结构,structure multiple,structure de variété,structure de variété,マニホールド構造,多様体構造,多様体構造,многообразная структура,многообразная структура,многообразная структура
2632,manifold-value datum,مسند القيمة المتعددة,البيانات ذات القيم المتعددة منصة,بيانات متجهة القيمة,多值数据,流形值数据,流形值数据,donnée de valeur multiple,donnée de valeur manifold,donnée à valeurs sur une variété,多様体値データム,多様体値データ,多様体値データ,данные многообразия,многообразие-значение данные,многозначное данное
2633,margin parameter,معلمة الهامش,معلمة الهامش,معامل الهامش,余量参数,边界参数,边际参数,paramètre de marge,paramètre de marge,paramètre de marge,マージンパラメータ,マージンパラメータ,マージンパラメータ,параметр поля,параметр отступления,параметр поля
2634,marginal density,الكثافة الهامشية,الكثافة الهامشية,الكثافة الهامشية,边际密度,边际密度,边缘密度,densité marginale,densité marginale,densité marginale,限界密度,マージナル密度 (marginal density),周辺密度,предельная плотность,маргинальная плотность,предельная плотность
2635,marginal distribution,التوزيع الهامشي,التوزيع الهامشي,التوزيع الهامشي,边际分布,边际分布,边缘分布,répartition marginale,distribution marginale,distribution marginale,限界分布,余部分布,端緣分布,предельное распределение,маргинальное распределение,предельное распределение
2636,marginal inference,الاستدلال الهامشي,الاستنتاج الهامشي,استدلال هامشي,边际推理,边缘推断,边际推理,inférence marginale,inférence marginale,inférence marginale,限界推論,マージナル推論,限界推論,предельный вывод,маргинальный вывод,маргинальный вывод
2637,marginal likelihood,احتمال هامشي,الاحتمالية الهامشية,الاحتمالية الحدية,边际可能性,边际似然,边缘似然,vraisemblance marginale,vraisemblance marginale,vraisemblance marginale,限界確率,周辺尤度,周辺尤度,предельная вероятность,предельное правдоподобие,предельное правдоподобие
2638,marginal log-likelihood,احتمالية السجل الهامشية,الإمكان الحدودي لتسجيل الإحتمالية,الاحتمالية اللوغاريتمية الهامشية,边际对数似然,边际对数似然,边缘对数似然,log-vraisemblance marginale,vraisemblance marginale logarithmique,vraisemblance marginale logarithmique,周辺対数尤度,マージナル対数尤度 (marginal log-likelihood),限界対数尤度,предельное логарифмическое правдоподобие,предельная логарифмическая правдоподобность,предельная логарифмическая правдоподобность
2639,marginal polytope,بوليتوب هامشي,المضلع الحافي,متعدد الأضلاع الهامشي,边缘多胞体,边际多面体,边缘多面体,polytope marginal,polytope marginal,polytope marginal,辺縁多面体,マージナルポリトープ,限界多面体,маргинальный многогранник,маргинальный политоп,краевой политоп
2640,marginal probability,احتمال هامشي,الاحتمال الهامشي,احتمالية طرفية,边际概率,边际概率,边际概率,probabilité marginale,probabilité marginale,probabilité marginale,限界確率,マージナル確率,余剰確率,предельная вероятность,предельная вероятность,предельная вероятность
2641,marginalization,التهميش,التهميش,هامشية,边缘化,边缘化,边缘化,marginalisation,marginalisation,marginalisation,疎外化,余辺化,周辺化,маргинализация,маргинализация,маржинализация
2642,mask,قناع,- تقنية القناع,ماسك,面具,掩码,掩码,masque,masque,masque,マスク,マスク,マスク,маска,маска,маска
2643,mask token,رمز القناع,رمز القناع,رمز القناع,掩码令牌,掩码标记,掩码标记,jeton de masque,jeton de masque,jeton masqué,マスクトークン,マスクトークン,マスクトークン,жетон маски,маскировочный токен,маскирующий токен
2644,mask vector,ناقل القناع,- تسلسل القناع,متجه القناع,面具矢量,掩码向量,掩码向量,vecteur de masque,vecteur de masque,vecteur de masque,マスクベクトル,マスクベクトル (masuku bekutoru),マスクベクトル,маска вектор,маска вектор,вектор маски
2645,masked input,مدخلات مقنعة,الإدخال المُقنع,تغطية المدخلات,屏蔽输入,蒙面输入,掩码输入,entrée masquée,entrée masquée,entrée masquée,マスクされた入力,マスクされた入力,マスク入力,маскированный ввод,маскированный ввод,маскированный ввод
2646,masked language model,نموذج لغة مقنعة,نموذج لغوي مقنع,نموذج لغة مقنع,掩码语言模型,掩蔽语言模型 (masked language model),掩码语言模型,modèle de langage masqué,modèle de langue masqué,modèle de langage masqué,マスクされた言語モデル,マスクされた言語モデル (MLM),マスク言語モデル,модель языка в масках,модель маскирования языка,маскированная языковая модель
2647,masked token,رمز مقنع,الرمز المقنع,كلمة مُخفية,掩码令牌,掩盖标记,遮蔽词元,jeton masqué,jeton masqué,jeton masqué,マスクされたトークン,マスクされたトークン,マスクされたトークン,замаскированный токен,маскированный токен,замаскированный токен
2648,masking function,وظيفة اخفاء,وظيفة التقنين,وظيفة التعتيم,掩蔽功能,屏蔽函数 (masking function),掩蔽函数,fonction de masquage,fonction de masquage,fonction de masquage,マスキング機能,マスキング関数 (masking function),マスキング関数,функция маскировки,маскирующая функция,маскирующая функция
2649,match algorithm,خوارزمية المباراة,خوارزمية التطابق,خوارزمية المطابقة,匹配算法,匹配算法,匹配算法,algorithme de correspondance,algorithme d'appariement,algorithme d'appariement,一致アルゴリズム,マッチングアルゴリズム,マッチングアルゴリズム,алгоритм сопоставления,алгоритм сопоставления,алгоритм сопоставления
2650,matching loss,خسارة مطابقة,الخسارة المطابقة,نقصان المطابقة,匹配损失,匹配损失,匹配损失,perte correspondante,perte de correspondance,perte d'appariement,マッチングロス,マッチング損失 (matching loss),マッチング損失,соответствующая потеря,- Соответствующий убыток,потери соответствия
2651,matrix,مصفوفة,المصفوفة,صفوف,矩阵,矩阵,矩阵,matrice,matrice,matrice,マトリックス,"""['− ‾‾⏊ ‾‾⏋ ‾‾⏋ ‾‾⏌ − 1 2 − 1 2 − 1 2 1 2 − 1 2 − 1 2 1 2 1 2 − 1 2 1 2 1 2 1 2 ‾‾⏉ ‾‾⏊ ‾‾⏊ ‾‾⏋ . This matrix is now",行列,матрица,матрица,матрица
2652,matrix approximation,تقريب المصفوفة,تقريب المصفوفة,تقريب المصفوفة,矩阵近似,矩阵逼近,矩阵近似,approximation matricielle,approximation de matrice,approximation matricielle,行列近似,マトリックス近似 (Matrix Approximation),行列近似,матричное приближение,аппроксимация матрицы,матричное приближение
2653,matrix decomposition,تحلل المصفوفة,تحليل البنية الرياضية,تحليل المصفوفة,矩阵分解,矩阵分解,矩阵分解,décomposition matricielle,décomposition de matrices,décomposition matricielle,行列分解,行列分解,行列分解,матричное разложение,декомпозиция матрицы,разложение матрицы
2654,matrix factorization,تحليل المصفوفة,عاملة القوام المصفوفي,تجزئة المصفوفة,矩阵分解,矩阵分解,矩阵分解,factorisation matricielle,factorisation de matrice,factorisation matricielle,行列分解,マトリックス分解 (Matrix Factorization),行列因子分解,матричная факторизация,"""['Разрыв между CF и LDA интересен - другие пользователи предоставляют более точную оценку предпочтений, чем только содержание. Прогнозирование за пределами матрицы - более сложная проблема, как показывает относительно более низкая полнота. В этой задаче CTR выполня",Матричное разложение
2655,matrix form,شكل مصفوفة,الشكل المصفوفي,صيغة المصفوفة,矩阵形式,矩阵形式,矩阵形式,forme matricielle,forme matricielle,forme matricielle,マトリックス形式,行列形式,行列形式,матричная форма,форма матрицы,матричная форма
2656,matrix inversion,انعكاس المصفوفة,عكس المصفوفة,عكس المصفوفة,矩阵求逆,矩阵求逆,矩阵求逆,inversion de matrice,inversion de matrice,inversion matricielle,逆行列,行列の逆行列,行列の逆算,инверсия матрицы,"""['В алгоритме полного перебора, поскольку количество существующих рёбер составляет ( ), а количество возможных новых рёбер для переключения составляет ( ) для каждого существующего ребра, размер Ω равен ( 2 ). Кроме того, старые и новые значения могут быть вычислены путем инверсии матрицы,",обратная матрица
2657,matrix multiplication,ضرب المصفوفة,ضرب المصفوفة,ضرب المصفوفات,矩阵乘法,矩阵乘法,矩阵乘法,multiplication matricielle,multiplication de matrices,multiplication matricielle,行列の乗算,行列の乗算 (Gyōretsu no jōsan),行列積,умножение матрицы,Умножение матриц,матричное умножение
2658,matrix norm,قاعدة المصفوفة,معيار المصفوفة,معيار المصفوفة,矩阵范数,矩阵范数 (Matrix Norm),矩阵范数,norme matricielle,norme de matrice,norme matricielle,行列ノルム,マトリックスノルム,行列ノルム,матричная норма,норма матрицы,матричная норма
2659,matrix sketching,رسم المصفوفة,الرسم البياني للمصفوفة,تلخيص المصفوفة,矩阵草图,矩阵草图,矩阵素描,esquisse matricielle,esquisse de matrice,esquisser des matrices,マトリックススケッチ,マトリックス スケッチング,行列スケッチング,матричный эскиз,матричный набросок,матричный эскиз
2660,matrix vector product,منتج ناقلات المصفوفة,ناتج مصفوفة متجه,ضرب مصفوفة بمتجه,矩阵向量积,矩阵向量乘积,矩阵向量乘积,produit vectoriel matriciel,produit matrice-vecteur,produit matrice-vecteur,行列ベクトル積,行列ベクトル積 (kouretsu bekutoru-seki),行列ベクトル積,матричное векторное произведение,произведение матрицы на вектор,произведение матрицы на вектор
2661,matrix-vector multiplication,ضرب المصفوفة والمتجه,ضرب مصفوفة-متجه,ضرب المصفوفة بالمتجه,矩阵向量乘法,矩阵-向量乘法,矩阵-向量乘法,multiplication matrice-vecteur,multiplication matrice-vecteur,multiplication matrice-vecteur,行列とベクトルの乗算,行列-ベクトルの乗算,行列ベクトル積,матрично-векторное умножение,умножение матрицы на вектор,матрично-векторное умножение
2662,matroid,matroid,"""الهدف هو العثور على مجموعة C ⊆ F من المرافق التي تقلل من تكلفة m (X، C)، و C ∈ S، أي C هو مجموعة مستقلة في المنطقة المعطاة. يرجى ملاحظة أن الوصف الصريح لمنطقة ذات مرتبة k قد",مصفوفة,拟阵,拟阵 (matroid),重子系,matroïde,matroïde,matroïde,マトロイド,マトロイド,マトロイド,матроид,матроид,тральная решетка
2663,matroid constraint,القيد الماتروي,قيود الماترويد,قيد المنشور,拟阵约束,阵roid约束,基质约束,contrainte matroïde,contrainte matroïde,contrainte matroïde,マトロイドコンストレイント,マトロイド制約 (Matoroido seiyaku),マトロイド制約,ограничение матроида,матроидный ограничение,матроидное ограничение
2664,max norm,الحد الأقصى للقاعدة,الحد الأقصى للنورم,ضابط الحد الأقصى,最大范数,最大范数,最大范数,norme maximale,norme maximale,Norme max,最大標準,最大ノルム,max ノルム,максимальная норма,макс норма,максимальная норма
2665,max pooling,الحد الأقصى للتجميع,- التجميع الأقصى,الحشد الأقصى,最大池化,"Since ""max pooling"" is an abbreviation commonly used in AI and machine learning contexts, it is recommended to keep the original English term to avoid confusion.",最大池化,mise en commun maximale,max pooling,Regroupement par maximum,最大プーリング,最大プーリング,最大プーリング,максимальное объединение,максимальное прореживание,Максимальное объединение
2666,max-margin,الحد الأقصى للهامش,الحد الأقصى للفجوة,هامش الحد الأقصى,最大保证金,最大间隔,最大间隔,marge maximale,marge maximale,max-marge,最大マージン,最大マージン,最大マージン,максимальная маржа,максимальный зазор,максимального отступа
2667,max-margin learning,تعلم الحد الأقصى للهامش,التعلم بالحد الأقصى للهامش,التعلم بهامش أقصى,最大边际学习,最大边际学习,最大边际学习,apprentissage à marge maximale,apprentissage à marge maximale,apprentissage à marge maximale,最大マージン学習,最大マージン学習,最大マージン学習,максимальное обучение,обучение с максимальным зазором,максимального отступа обучение
2668,max-pool,max-pool,تجميع بحد أقصى,تجميع أقصى قيمة,最大池,最大池化 (max-pool),最大池化层,piscine maximale,"\n', '-Pour un CNN avec",max-pool = max-pool,最大プール,最大プール,最大プーリング,Макс-пул,max-пулинг,макс-пулинг
2669,max-pooling layer,طبقة التجميع القصوى,الطبقة القصوى للتجميع,طبقة استخراج العناصر القصوى,最大池化层,最大池化层,最大池化层,couche de pooling maximum,couche de max-pooling,couche de max-pooling,最大プーリング層,最大プーリング層,max-poolingレイヤー,слой максимального пула,слои максимального пулинга,слой максимального объединения
2670,max-product semiring,الحد الأقصى للمنتج نصف الدائري,النصب النجمي الأقصى,شبكة الحاصل الأقصى,最大积半环,最大-乘积半环,最大乘积半环,semi-anneau de produit maximum,sémi-anneau max-produit,semiring max-produit,max-product セミリング,最大積半環 (max-product semiring),最大積半環,полукольцо макс-продукт,макс-произведение полукольцо,макс-произведение полукольцо
2671,maximal clique,الزمرة القصوى,- التجمع الأقصى,أكبر مجموعة فرعية كاملة البينية,最大集团,最大团,最大团,clique maximale,clique maximale,clique maximale,最大クリーク,最大クリーク,最大クリック,максимальная клика,максимальная клика,максимальная клика
2672,maximal frequent itemset,الحد الأقصى لمجموعة العناصر المتكررة,مجموعة العناصر الشائعة القصوى,أكبر مجموعة عناصر متكررة,最大频繁项集,最大频繁项目集,最大频繁项集,ensemble d'éléments fréquents maximaux,ensemble d'éléments fréquents maximaux,Ensemble d'items maximaux fréquents,最大頻度アイテムセット,最大頻出アイテムセット,最大頻出項目集合,максимальный частый набор элементов,максимальный частый набор элементов,максимальный частый itemset
2673,maximal frequent pattern,النمط المتكرر الأقصى,نمط تكرار أقصى,نمط شائع أقصى,最大频繁模式,最大频繁模式,最大频繁模式,modèle fréquent maximal,motif fréquent maximal,motif fréquent maximal,最大頻度パターン,最大頻出パターン,最大頻出パターン,максимально частый образец,максимальный часто встречающийся шаблон,максимальный частый шаблон
2674,maximization problem,مشكلة التعظيم,مشكلة التكثيف,مشكلة التعظيم,最大化问题,最大化问题,最大化问题,problème de maximisation,problème de maximisation,problème de maximisation,最大化問題,最大化問題 (さんだいかもんだい),最大化問題,задача максимизации,проблема максимизации,задача максимизации
2675,maximum a posteriori,الحد الأقصى اللاحق,- التكرار الأعظمية ما بعد السابقية,المعظم البعدي,最大后验概率,最大后验概率 (maximum a posteriori),最大后验概率,maximum a posteriori,maximum a posteriori,maximum a posteriori,最大事後的,最大事後確率 (maximum a posteriori),最大事後確率解,максимум апостериорно,максимум апостериори,максимум апостериорного
2676,maximum a posteriori estimation,الحد الأقصى للتقدير اللاحق,التقدير الأحتمالي الأقصى اللاحق,تقدير الأقصى الاحق,最大后验估计,最大后验估计,最大后验估计,estimation maximale a posteriori,estimation a posteriori maximale,estimation du maximum a posteriori,最大事後推定,事後確率最大推定 (MAP),最大事後確率推定,максимальная апостериорная оценка,оценка апостериори с максимальной вероятностью,максимальная апостериорная оценка
2677,maximum clique,أقصى زمرة,النقرة القصوى,أكبر متراص,最大集团,最大团,最大团,clique maximale,clique maximale,clique maximale,最大クリーク,最大クリーク,最大クリーク,максимальная клика,максимальная клика,максимальная клика
2678,maximum entropy,الانتروبيا القصوى,أقصى تشتت,أقصى إنتروبيا,最大熵,最大熵,最大熵,entropie maximale,entropie maximale,entropie maximale,最大エントロピー,最大エントロピー,最大エントロピー,максимальная энтропия,максимальная энтропия,максимальная энтропия
2679,maximum entropy model,نموذج الانتروبيا القصوى,نموذج الانحدار الأقصى,نموذج الانتروبيا القصوى,最大熵模型,最大熵模型,最大熵模型,modèle d'entropie maximale,modèle d'entropie maximale,modèle de l'entropie maximale,最大エントロピーモデル,saikou entoropii moderu),最大エントロピーモデル,модель максимальной энтропии,модель максимальной энтропии,модель максимальной энтропии
2680,maximum entropy principle,مبدأ الانتروبيا القصوى,مبدأ الانتروبية القصوى,مبدأ الاستروبيا القصوى,最大熵原理,最大熵原理,最大熵原理,principe d'entropie maximale,principe de l'entropie maximale,principe de l'entropie maximale,最大エントロピー原理,最大エントロピー原理,最大エントロピー原理,принцип максимальной энтропии,принцип максимальной энтропии,принцип максимальной энтропии
2681,maximum flow,الحد الأقصى للتدفق,التدفق الأقصى,تدفق أقصى,最大流量,最大流量,最大流量,débit maximal,débit maximal,flot maximum,最大流量,最大フロー,最大フロー,максимальный расход,максимальный поток,максимальный поток
2682,maximum likelihood,أقصى احتمال,أقصى احتمالية,أقصى احتمال,最大似然,最大似然 (maximum likelihood),最大似然,plausibilité maximum,maximum de vraisemblance,vraisemblance maximale,最大の可能性,最尤法 (さいゆうほう),最尤推定,максимальная вероятность,метод максимального правдоподобия,максимальное правдоподобие
2683,maximum likelihood estimate,الحد الأقصى لتقدير الاحتمال,التقدير الأقصى للإمكانيةية,تقدير الأرجحية القصوى,最大似然估计,最大似然估计,最大似然估计,estimation du maximum de vraisemblance,estimateur du maximum de vraisemblance,estimation du maximum de vraisemblance,最尤推定,最尤推定 (さいゆうすいてい),最尤推定,оценка максимального правдоподобия,оценка максимального правдоподобия,оценка по максимуму правдоподобия
2684,maximum likelihood estimation,أقصى تقدير احتمال,تقدير الاحتمال الأقصى,تقدير الأرجحية القصوى,最大似然估计,最大似然估计,最大似然估计,Estimation de vraisemblance maximale,estimation du maximum de vraisemblance,estimation du maximum de vraisemblance,最尤推定,最尤推定 (さいゆうすいてい),最尤推定,оценка максимального правдоподобия,оценка максимального правдоподобия,оценка максимального правдоподобия
2685,maximum likelihood estimator,مقدر الاحتمالية القصوى,مقدر الاحتمالية الأقصى,مقدر الأرجحية القصوى,最大似然估计器,最大似然估计器,最大似然估计量,estimateur du maximum de vraisemblance,estimateur du maximum de vraisemblance,estimateur du maximum de vraisemblance,最尤推定器,最尤推定量 (MLE),最尤推定量,оценка максимального правдоподобия,оценщик максимального правдоподобия,максимально правдоподобный оценщик
2686,maximum likelihood learning,أقصى احتمال للتعلم,التعلم بأقصى احتمالية,- تعلم الأرجحية القصوى,最大似然学习,最大似然学习,最大似然学习,apprentissage du maximum de vraisemblance,apprentissage du maximum de vraisemblance,apprentissage par maximum de vraisemblance,最尤学習,最尤学習,最尤学習,обучение с максимальной вероятностью,обучение методом максимального правдоподобия,максимальное правдоподобное обучение
2687,maximum mean discrepancy,أقصى متوسط ​​التناقض,- التباين الأقصى للمتوسط,الفرق المتوسط الأقصى,最大平均差异,最大均值差异,最大均值差异,écart moyen maximum,disparité maximale moyenne,divergence maximale moyenne,最大平均不一致,最大平均差異,最大平均離差,максимальное среднее расхождение,максимальная мера расхождения,максимальная средняя дискрепанция
2688,mean average precision,متوسط ​​الدقة,الدقة المتوسطة المتوسطة,متوسط الدقة المتوسط,平均精度,平均准确度 (mean average precision),平均精确率,moyenne précision moyenne,précision moyenne moyenne,Précision moyenne,平均平均精度,"""['このような品質の尺度の例として、精度@10（P@10）またはクエリの平均適合率（MAP）[22]があります。 クエリの難易度の推定は、いくつかの理由で有利です： \n 1. ユーザーへのフィードバック：ユーザーは「困難な」クエリを",平均適合率,средняя средняя точность,средняя средняя точность,среднее среднее точность
2689,mean field,يعني المجال,حقل متوسط,الحقل المتوسط,平均场,平均场,平均场,champ moyen,champ moyen,champ moyen,平均フィールド,平均場,平均場 (へいきんば),среднее поле,среднее поле,среднее поле
2690,mean function,وظيفة متوسطة,الدالة المتوسطة,دالة المتوسط,平均函数,均值函数 (mean function),均值函数,fonction moyenne,fonction moyenne,fonction moyenne,平均関数,平均関数,平均関数,средняя функция,средняя функция,среднее значение функции
2691,mean pooling,يعني تجميع,تجميع المتوسط,تجميع المتوسط,平均池化,均值汇聚,平均池化,mise en commun moyenne,moyenne en pooler,Regroupement moyen,平均プーリング,平均プーリング,平均プーリング,среднее объединение,усредненное объединение,Среднее объединение
2692,mean reciprocal rank,يعني رتبة متبادلة,"""['بالنسبة لكل استعلام في مجموعة الاستعلامات، نقوم بإجراء بحث عن أقرب جار باستخدام التشابه الكوسيني على التمثيل المُشفر لكل استعلام ونص في المجموعة المستهدفة. نحن",ترتيب متوسط المعكوس,平均倒数排名,平均倒数排名,平均倒数排名,rang réciproque moyen,rang réciproque moyen,rang réciproque moyen,平均相互順位,平均相互順位,平均逆数ランク,средний обратный ранг,- Средний обратный ранг,средний реципрокный ранг
2693,mean shape,يعني الشكل,الشكل المتوسط,شَكْل مُتَوَسِّط,平均形状,平均形状 (Mean Shape),平均形状,forme moyenne,forme moyenne,forme moyenne,平均的な形状,平均形,平均形状,средняя форма,- Средняя форма,средняя форма
2694,mean square error,متوسط ​​مربع الخطأ,خطأ المتوسط المربعي,خطأ المربع المتوسط,均方误差,均方误差,均方误差,erreur quadratique moyenne,erreur quadratique moyenne,erreur quadratique moyenne,平均二乗誤差,平均二乗誤差 (MSE),平均二乗誤差,среднеквадратическая ошибка,среднеквадратичная ошибка,средний квадрат ошибки
2695,mean vector,يعني ناقلات,متوسط المتجهات,متجه المتوسط,平均向量,均值向量,均值向量,vecteur moyen,vecteur moyen,vecteur moyen,平均ベクトル,平均ベクトル (heikin becutoru),平均ベクトル,средний вектор,- Средний вектор,среднее векторное значение
2696,mean-field approximation,تقريب المجال المتوسط,التقريب الحقلي المتوسط,تقريب الحقل المتوسط,平均场近似,均场近似,平均场近似,approximation du champ moyen,approximation de champ moyen,approximation du champ moyen,平均場近似,平均場近似,平均場近似,приближение среднего поля,среднепольное приближение,Приближение среднего поля
2697,measurable space,مساحة قابلة للقياس,المساحة القابلة للقياس,فضاء قابل للقياس,可测量的空间,可测空间,可测空间,espace mesurable,espace mesurable,espace mesurable,測定可能な空間,可測空間 (kaseki kuukan),測度可能空間,измеримое пространство,измеримое пространство,измеримое пространство
2698,measurement matrix,مصفوفة القياس,مصفوفة القياسات,مصفوفة القياس,测量矩阵,测量矩阵,测量矩阵,matrice de mesure,matrice de mesure,matrice de mesure,測定マトリックス,計測行列 (keisoku gyōretsu),計測行列,матрица измерений,матрица измерения,матрица измерений
2699,measurement noise,ضجيج القياس,ضوضاء القياس,ضوضاء القياس,测量噪声,测量噪声,测量噪声,bruit de mesure,bruit de mesure,bruit de mesure,測定ノイズ,- 測定ノイズ (sokutei noizu),計測ノイズ,шум измерения,шум измерения,Шум измерений
2700,mechanical Turk,تركي ميكانيكي,ترك ميكانيكي,تُرك آلي,机械土耳其人,机械土耳其,机械土耳其人,Turc mécanique,Mechanical Turk,Ouvrier mécanique Turc,メカニカルターク,"Mechanical Turk prompts. We report the scores for the systems in Table 4 These findings are striking, particularly because Midge uses the same input as the Kulkarni et al. system.', ""In recent years, however, crowdsourcing methods such Amazon's Mechanical Turk (AMT) have shaken up this scenario by making it possible to rapidly recruit large numbers of untrainned annotators at a low cost.""]""",機械的なターク,механический турок,механический турок,механический турок
2701,medical imaging,التصوير الطبي,التصوير الطبي,التصوير الطبي,医学影像,医学成像,医学影像,l'imagerie médicale,imagerie médicale,imagerie médicale,医療画像処理,医用画像処理 (いよう がぞう しょり),医療画像,медицинская визуализация,медицинское изображение,медицинская визуализация
2702,medoid,com.medoid,"""يتم عرض تسميات مجموعات البيانات المولدة، جنبًا إلى جنب مع عدد الوثائق وعنوان الوثيقة الوسيطة لكل مجموعة في الجدول ١٠.""",مديد,中心点,中心点 (medoid),中心对象,médoïde,médoïde,médoïde,メドイド,メドイド,中央値ドキュメント (chūsūchi dokumento),медоид,медоид,медоид
2703,membership inference attack,هجوم استنتاج العضوية,هجوم كشف العضوية,هجوم استنتاج العضوية,成员资格推理攻击,成员推断攻击 (membership inference attack),隐私成员推断攻击,attaque par inférence d'adhésion,attaque par inférence d'appartenance,attaque d'inférence d'appartenance,メンバーシップ推論攻撃,メンバーシップ推定攻撃 (Membership Inference Attack),メンバーシップ推論攻撃 (menbāshippu suiron kōgeki),атака на вывод членства,атака на участие в членстве,атака вывода о принадлежности
2704,membership query,الاستعلام عن العضوية,استعلام العضوية,استفسار العضوية,会员查询,成员查询,成员查询,requête d'adhésion,requête d'appartenance,requête d'appartenance,メンバーシップのクエリ,メンバーシップクエリ (membership query),所属クエリ,запрос на членство,запрос на членство,членские запросы
2705,memory bank,بنك الذاكرة,بنك الذاكرة,مصرف الذاكرة,记忆库,记忆库,内存库,banque de mémoire,- Mémoire de stockage,banque de mémoire,メモリバンク,メモリバンク,メモリバンク,банк памяти,банк памяти,банк памяти
2706,memory capacity,سعة الذاكرة,سعة الذاكرة,سعة الذاكرة,内存容量,内存容量,记忆容量,capacité mémoire,capacité de mémoire,capacité de mémoire,記憶容量,メモリ容量,記憶容量,емкость памяти,емкость памяти,объем памяти
2707,memory cell,خلية الذاكرة,خلية الذاكرة,ذاكرة خلية,记忆细胞,记忆细胞,记忆细胞,cellule mémoire,- Cellule de mémoire,Cellule mémoire,メモリセル,記憶細胞,メモリセル,ячейка памяти,ячейка памяти,клетка памяти
2708,memory complexity,تعقيد الذاكرة,تعقيد الذاكرة,تعقيد الذاكرة,记忆复杂性,内存复杂度,内存复杂度,complexité de la mémoire,complexité de la mémoire,complexité mémoire,記憶の複雑さ,メモリ複雑度 (Memory complexity),メモリ複雑度,сложность памяти,- Память сложности,памятная сложность
2709,mention detection,كشف الذكر,كشف الإشارة,كشف الإشارات,提及检测,提及检测,实体提及检测,mentionner la détection,détection de mention,détection des mentions,言及の検出,メンション検出 (mention detection),言及の検出,обнаружение упоминаний,обнаружение упоминаний,обнаружение упоминаний
2710,meronymy,ميرونيمي,الجزءية,الترادف الجزئي,默名,部分整体关系,部分关系,méronymie,méronymie,méronymie,メロニミー,部分-全体関係,部分全体関係,меронимия,меронимия,частеречность
2711,message passing,تمرير الرسالة,عبور الرسائل,مرور الرسالة,消息传递,消息传递,消息传递,passage de message,passage de message,passage de messages,メッセージパッシング,メッセージパッシング,メッセージパッシング,передача сообщений,передача сообщений,передача сообщений
2712,message passing algorithm,خوارزمية تمرير الرسالة,- التنقل بين الرسائل الخوارزمية,خوارزمية تمرير الرسائل,消息传递算法,消息传递算法,消息传递算法,algorithme de transmission de messages,algorithme de passage de message,algorithme de passage de messages,メッセージパッシングアルゴリズム,メッセージパッシングアルゴリズム,メッセージ渡しアルゴリズム,алгоритм передачи сообщений,алгоритм передачи сообщений,алгоритм передачи сообщений
2713,meta,ميتا,ميتا,ميتا,元,元,元,méta,méta,méta,メタ,メタ,メタ,мета,мета,мета
2714,meta-algorithm,خوارزمية التعريف,الميتا خوارزمية,خوارزمية ميتا,元算法,元算法,元算法,méta-algorithme,méta-algorithme,méta-algorithme,メタアルゴリズム,メタアルゴリズム (meta-algorithm),メタアルゴリズム,мета-алгоритм,Мета-алгоритм,мета-алгоритм
2715,meta-classifier,المصنف الفوقية,الميتا مصنف,صنف فوقي,元分类器,元分类器,元分类器,méta-classificateur,méta-classifieur,méta-classificateur,メタ分類子,メタ分類器 (meta-bunruisha),メタ分類器,метаклассификатор,мета-классификатор,мета-классификатор
2716,meta-dataset,مجموعة البيانات الوصفية,ميتا مجموعة البيانات,مجموعة البيانات الفائقة,元数据集,元数据集,元数据集,ensemble de métadonnées,méta-ensemble de données,méta-ensemble de données,メタデータセット,メタデータセット,メタデータセット,набор метаданных,мета-набор данных,мета-набор данных
2717,meta-evaluation,التقييم التلوي,التقييم الفوقي,تقييم ما بعد التقييم,元评价,元评价,元评估,méta-évaluation,méta-évaluation,méta-évaluation,メタ評価,メタ評価 (meta-hyouka),メタ評価,мета-оценка,"""['Наша метаоценка выявила недостатки в оценке МТ в большинстве аннотированных статей. Накопление этих недостатков и обеспокоенные тенденции, которые мы выявили, побудили нас предложить руководство по автоматической оценке МТ. Мы н",мета-оценка
2718,meta-learn,التعلم الفوقي,تعلم ميتا,تعلّم ميتا,元学习,元学习,元学习,méta-apprentissage,meta-apprentissage,méta-apprendre,メタ学習,メタラーン,メタ学習,метаобучение,мета-обучение,метаобучение
2719,meta-learner,ميتا المتعلم,التعلم الذاتي (Self-learning),متعلم فائق,元学习器,元学习者,元学习器,méta-apprenant,meta-apprenant,méta-apprenant,メタ学習者,メタラーナー,メタラーナー,мета-ученик,мета-обучающийся,мета-обучающийся
2720,meta-learning,التعلم التلوي,- تعلم التعلم,تعلم ميتا,元学习,元学习,元学习,méta-apprentissage,méta-apprentissage,Méta-apprentissage,メタ学習,メタラーニング,メタラーニング,метаобучение,Мета-обучение,метаобучение
2721,meta-loss,الخسارة الفوقية,الخسارة الفوقية,خسارة ميتا,元损失,元损失,元损失,méta-perte,méta-perte,méta-perte,メタロス,メタ損失 (meta-loss),メタ損失,мета-потеря,мета-потеря,мета-потери
2722,meta-parameter,المعلمة الفوقية,- التعديل-المعلمة,معامل متامتري,元参数,元参数,元参数,méta-paramètre,méta-paramètre,métaparamètre,メタパラメータ,メタパラメータ (meta-parameter),メタパラメータ,метапараметр,метапараметр,мета-параметр
2723,meta-testing,الاختبار التلوي,1 للتدريب التعدادي واختبار التعداد. يتم معدل النتائج,اختبار متا,元测试,元测试,元测试,méta-tests,"1 pour l'apprentissage méta et le méta-test. Les résultats rapportés sont moyennés sur toutes les tâches testées.', 'Parmi de nombreux candidats pour concevoir un mécanisme d'adaptation à travers θ T , nous constatons que l'ajustement des biais (Cai et",méta-test,メタテスト,メタテスト,メタテスト,мета-тестирование,мета-тестирование,мета-тестирование
2724,meta-training,التدريب الفوقي,التدريب الفوقي,تدريب متا,元训练,元训练,元训练,méta-formation,meta-entraînement,méta-entraînement,メタトレーニング,メタトレーニング,メタ学習,метатренинг,мета-обучение,мета-обучение
2725,metadata,البيانات الوصفية,البيانات الوصفية,بيانات التعريف,元数据,元数据,元数据,métadonnées,métadonnées,métadonnées,メタデータ,メタデータ (metadata),メタデータ,метаданные,метаданные,метаданные
2726,metric learning,التعلم المتري,تعلم المقاييس,تعلم القياس,度量学习,度量学习,度量学习,apprentissage métrique,apprentissage de métrique,apprentissage métrique,指標の学習,メトリックラーニング,メトリック学習,метрическое обучение,метрическое обучение,обучение метрики
2727,metric learning algorithm,خوارزمية التعلم المترية,خوارزمية تعلم المقاييس,خوارزمية تعلم المعيار,度量学习算法,度量学习算法,度量学习算法,algorithme d'apprentissage métrique,algorithme d'apprentissage de métriques,algorithme d'apprentissage de métrique,メトリクス学習アルゴリズム,距離学習アルゴリズム (Kyori Gakushu Arugorizumu),メトリック学習アルゴリズム,алгоритм обучения метрике,алгоритм обучения метрик,алгоритм метрического обучения
2728,metric score,النتيجة المترية,نقطة معيارية,درجة القياس,度量分数,度量分数,评测分数,score métrique,score métrique,score métrique,メトリックスコア,メトリックスコア,メトリックスコア,метрическая оценка,метрический балл,метрическая оценка
2729,metric space,الفضاء المتري,الفضاء المتري الذي يكون فيه الناخبون والمرشحون المضمنون معًا,فضاء متري,度量空间,度量空间,度量空间,espace métrique,espace métrique,espace métrique,メートル空間,メトリック空間 (metorikku kūkan),メトリック空間,метрическое пространство,метрическое пространство,метрическое пространство
2730,metropolis-hasting,تسارع المدينة,"""مما يظهر بشكل أوضح أن اختيارنا لعدد صغير نسبياً من خطوات ميتروبوليس-هاستينج (2 لكل عينة) كان كافياً. يمكن رؤية الأداء المحسن في وقت التشغيل لتنف",ميتروبوليس-هاستينج,黑斯廷特都会,"""['定理5（Maciuca和Zhu，2003）。设p（W），W ∈为马尔可夫链MC的不变（目标）概率，并且Q（W，W）= q（W）为Metropolis-Hasting方程（8）中的提议概率，则\n'，'这进一步显示我们选择相对较少数量的大都会-黑斯廷步骤（每个样本2",大都市-黑斯廷,métropole-hasting,Metropolis-Hasting,metropolis-hasting,メトロポリス・ヘイスティング,メトロポリス・ヘイスティング,メトロポリス・ヘイスティング法,Метрополис-Хастинг,метрополис-хастинг,метрополис-хастингс
2731,micro-average,المتوسط ​​الجزئي,المتوسط الميكروية,متوسط صغير,微观平均,微平均值,微平均,micro-moyenne,micro-moyenne,micro-moyenne,ミクロ平均,マイクロ平均,マイクロ平均,микросредний,микро-среднее,микроусреднение
2732,microarray datum,مسند ميكروأري,البيانات الصغيرة للمصفوفة,بيانات الصفيف المجهري,微阵列数据,微阵列数据,微阵列数据,données de micropuces,donnée de microréseau,donnée de microréseau,マイクロアレイデータ,マイクロアレイデータ,マイクロアレイデータ,данные микрочипа,микрочип данных,данные микрочипа
2733,mini-batch,دفعة صغيرة,الدُّفعة الصغيرة,دفعة صغيرة,小批量,小批量,小批量,mini-lot,mini-lot,mini-lot,ミニバッチ,ミニバッチ,ミニバッチ,мини-партия,мини-пакет,мини-партия
2734,mini-batch size,حجم دفعة صغيرة,حجم الدُفعات الصغيرة,حجم الدفعة الصغيرة,小批量大小,迷你批量大小,小批量大小,taille du mini-lot,taille du mini-lot,taille du mini-batch,ミニバッチサイズ,ミニバッチサイズ,ミニバッチサイズ,размер мини-партии,размер мини-пакета,размер мини-партии
2735,mini-batch training,تدريب دفعة صغيرة,التدريب بالدُفعات الصغيرة,تدريب بالدفعات الصغرى,小批量训练,小批量训练,小批量训练,formation en mini-lots,Entraînement par mini-lots,entraînement par mini-lots,ミニバッチトレーニング,ミニバッチ学習,ミニバッチ学習,мини-пакетное обучение,обучение на мини-пакетах,обучение с мини-партиями
2736,minima,الحد الأدنى,أدنى قيمة,أدنى القيم,最小值,最小值,极小值,minima,minimum,minima,ミニマ,最小値 (saishou-chi),局所最小値,минимумы,минимумы,минимумы
2737,minimax,com.minimax,الحد الأدنى,تصغير الحد الأقصى,极小极大,最小最大搜索,极小极大值,minimax,minimax,minimax,ミニマックス,最小最大 (minimax),最小最大値,минимакс,минимакс,миниmax
2738,minimax game,لعبة ميني ماكس,لعبة منافسة مصغرة,لعبة الحد الأدنى الأقصى,极小极大游戏,最小最大博弈,极小极大博弈,jeu minimax,jeu minimax,jeu minimax,ミニマックスゲーム,Minimaxゲーム,ミニマックスゲーム,минимакс игра,минимаксная игра,игра минимакс
2739,minimax optimization problem,مشكلة تحسين الحد الأدنى,مسألة تحسين مينيماكسية,مشكلة التحسين الصغرى-العظمى,极小极大优化问题,极小极大优化问题,极小极大优化问题,problème d'optimisation minimax,problème d'optimisation minimax,problème d'optimisation minimax,ミニマックス最適化問題,最小最大最適化問題,最小最大最適化問題,задача минимаксной оптимизации,проблема минимаксной оптимизации,задача минимакс-оптимизации
2740,minimax problem,مشكلة الحد الأدنى,مشكلة التصغير الأدنى,مشكلة الحد الأدنى الأقصى,极小极大问题,最小最大问题,极小极大问题,problème de minimax,problème minimax,problème minimax,ミニマックス問題,最小最大問題,ミニマックス問題,минимаксная задача,минимакс задача,проблема минимакса
2741,minimization problem,مشكلة التقليل,مشكلة الحد الأدنى,مشكلة التصغير,最小化问题,最小化问题,最小化问题,problème de minimisation,problème de minimisation,problème de minimisation,最小化問題,最小化問題,最小化問題,задача минимизации,Проблема минимизации,задача минимизации
2742,minimizer,شراع,الحد الأدنى,مُصغر,最小化器,最小化者 (Minimizer),极小化器,minimiseur,minimiseur,minimiseur,ミニマイザー,最小化手法者,最小化点,минимизатор,минимизатор,минимизатор
2743,minimum baye risk decoding,الحد الأدنى من مخاطر فك تشفير بايز,الفك الترميز بأدنى مخاطر بايس,ترميز الخطر البيزي الأدنى,最小贝叶斯风险解码,最小贝叶斯风险解码,最小贝叶斯风险解码,décodage du risque minimum de Bayes,décodage de risque bayésien minimal,décodage à risque bayésien minimal,最小限のベイズリスクのデコード,最小ベイズリスクデコーディング (minimum Bayes risk decoding),最小ベイズリスク復号化,декодирование минимального байесовского риска,декодирование с минимальным байесовским риском,минимальное байесовское рискованное декодирование
2744,minimum cut,الحد الأدنى للقطع,القَص الأدنى,القطع الأدنى,最小割,最小割,最小割,coupe minimale,coupe minimale,coupe minimale,最小カット,最小カット (minimum cut),最小カット,минимальный разрез,минимальное разрезание,минимальный разрез
2745,minimum description length,الحد الأدنى لطول الوصف,الطول الأدنى للوصف (MDL),أقل طول وصف,最小描述长度,最小描述长度,最小描述长度,longueur minimale de la description,- Minimum Longueur de Description,longueur de description minimale,最小の説明長,最小記述長 (MDL),最小記述長,минимальная длина описания,минимальная длина описания,минимальная длина описания
2746,minimum support,الحد الأدنى من الدعم,الدعم الأدنى,الدعم الأدنى,最低限度的支持,最小支持度,最小支持度,prise en charge minimale,support minimum,support minimum,最低限のサポート,最小サポート,最小サポート,минимальная поддержка,Минимальная поддержка,минимальная поддержка
2747,mirror descent,نزول المرآة,- تسلسل المرايا,نزول المرآة,镜像下降,镜像下降,镜面下降法,descente miroir,descente en miroir,descente miroir,ミラー降下,ミラーディセント,鏡面下降法,зеркальный спуск,зеркальное спускание,зеркальный спуск
2748,misclassification error,خطأ في التصنيف,خطأ التصنيف الخاطئ,خطأ التصنيف الخاطئ,错误分类错误,误分类误差,错误分类错误,erreur de classification,"""['L'optimisation directe de cet objectif convexe ne conduit pas à un séparateur avec une erreur faible, mais garantit que pour une fraction non négligeable de la masse loin du plan hyperplan de séparation, l'erreur de classification sera au plus η + .', 'Le but est de trouver une hypothèse h qui minimise l'erreur de classification. Nous proposons un algorithme en temps poly(d, 1/) pour ce problème avec une erreur de classification de η + . Nous fournissons",erreur de classification,誤分類エラー,誤分類エラー (Gobunrui Erā),誤分類エラー,ошибка классификации,ошибка неправильной классификации,ошибка неправильной классификации
2749,misclassification loss,خسارة سوء التصنيف,فقدان الصنف غير الصحيح,خسارة التصنيف الخاطئ,错误分类损失,误分类损失,误分类损失,perte due à une erreur de classification,perte de mauvaise classification,perte de classification erronée,誤分類損失,誤分類損失 (gobunrui sonshitsu),誤分類損失,потеря из-за неправильной классификации,потеря отнесения к неправильному классу,потери неправильной классификации
2750,misinformation detection,كشف المعلومات الخاطئة,كشف التضليل,الكشف عن المعلومات الخاطئة,错误信息检测,虚假信息检测,虚假信息检测,détection de désinformation,détection de la désinformation,détection de la désinformation,誤った情報の検出,誤情報検出,偽情報検出,обнаружение дезинформации,обнаружение дезинформации,обнаружение дезинформации
2751,mix weight,مزيج الوزن,وزن الخلط,وزن الخلط,混合重量,混合权重,混合权重,mélanger le poids,poids de mélange,poids de mélange,ミックスウェイト,ミックスウェイト,混合重み,вес смеси,веса смешивания,смесительный вес
2752,mixed integer programming,برمجة الأعداد الصحيحة المختلطة,برمجة الصحون المختلطة,برمجة عددية مختلطة,混合整数规划,混合整数规划 (MIP),混合整数规划,programmation d'entiers mixtes,programmation entière mixte,programmation linéaire en nombres mixtes,混合整数計画法,混合整数計画 (MIP),混合整数計画法,смешанное целочисленное программирование,смешанное целочисленное программирование,смешанное целочисленное программирование
2753,mixed precision,دقة مختلطة,الدقة المختلطة,الدقة المختلطة,混合精度,混合精度,混合精度,précision mixte,précision mixte,précision mixte,混合精度,混合精度 (kon'gō seido),混合精度,смешанная точность,смешанная точность,смешанная точность
2754,mixed precision training,التدريب الدقيق المختلط,التدريب بدقة مختلطة,تدريب بدقة مختلطة,混合精准训练,混合精度训练,混合精度训练,entraînement de précision mixte,Entraînement en précision mixte,entraînement en précision mixte,混合精度トレーニング,混合精度トレーニング,混合精度訓練,тренировка смешанной точности,Смешанное обучение точности,обучение со смешанной точностью
2755,mixed strategy,استراتيجية مختلطة,استراتيجية مختلطة,استراتيجية مختلطة,混合策略,混合策略,混合策略,stratégie mixte,stratégie mixte,stratégie mixte,混合戦略,混合戦略,混合戦略,смешанная стратегия,смешанная стратегия,смешанная стратегия
2756,mixed-integer program,برنامج الأعداد الصحيحة المختلطة,برنامج الصحون المختلطة,نظام متكامل متعدد,混合整数程序,混合整数规划,混合整数规划,programme à nombres entiers mixtes,programme mixte entier,programme en nombres mixtes,混合整数プログラム,混合整数プログラム,混合整数計画プログラム,смешанно-целочисленная программа,смешанная целочисленная программа,Смешанная целочисленная программа
2757,mixing matrix,مصفوفة الخلط,مصفوفة الخلط,مصفوفة الخلط,混合矩阵,混合矩阵,混合矩阵,matrice de mélange,matrice de mélange,matrice de mélange,混合マトリックス,混合行列 (kongou gyouretsu),混合行列,матрица смешивания,матрица смешивания,матрица смешивания
2758,mixing time,وقت الخلط,وقت الخلط,وقت الاختلاط,混合时间,混合时间,混合时间,temps de mélange,temps de mélange,Temps de mélange,混合時間,ミキシングタイム,混合時間,время смешивания,время смешивания,время перемешивания
2759,mixture component,مكون الخليط,مكون الخليط,مكون الخليط,混合物成分,混合成分,混合组分,composant du mélange,composant de mélange,composante de mélange,混合成分,混合成分 (kongou seibun),混合成分,компонент смеси,компонент смеси,компонент смеси
2760,mixture distribution,توزيع الخليط,توزيع مختلط,توزيع مختلط,混合分布,混合分布,混合分布,répartition du mélange,distribution de mélange,distribution de mélange,混合分布,混合分布,混合分布,распределение смеси,смешанное распределение,смесь распределений
2761,mixture model,نموذج الخليط,نموذج خليط,نموذج خليط,混合模型,混合模型,混合模型,modèle de mélange,modèle de mélange,modèle de mélange,混合モデル,混合モデル (kon'gō moderu),混合モデル,модель смеси,смесь модель,смесь моделей
2762,mixture of Gaussians,خليط من غاوسيين,مزيج من الجاوسيات,خليط من المنحنيات الاعتدالية,高斯混合,高斯混合物,高斯混合模型,mélange de Gaussiennes,mélange de Gaussiennes,mélange de gaussiennes,ガウスの混合,ガウス混合,ガウス混合モデル,смесь гауссиан,смесь гауссовых,смесь гауссиан
2763,mixture weight,وزن الخليط,وزن الخليط,وزن المزيج,混合物重量,混合权重,混合权重,poids du mélange,poids du mélange,poids de mélange,混合重量,混合重み (konkai omomi),混合重み,вес смеси,вес смеси,весовые коэффициенты смеси
2764,mixup,مزج,الخلط,خليط,混合,混合,混合,mélanger,mixup,mixage,混同,混合,ミックスアップ,смешивать,смешивание,смешивание
2765,mocap,لاقط الحركة,بيانات الحركة الثلاثية الأبعاد,حركة موقع,动作捕捉,动作捕捉,动作捕捉数据,capture vidéo,"des figures humaines dans une variété de vêtements sont rendues dans de nombreuses poses réalistes tirées de données de mocap.', 'Pour prévoir, nous alimentons d'abord les architectures avec (50) images clés de mocap, puis prévoy",capture de mouvements,モーションキャプチャ,モーキャプ,モーションキャプチャ,мокап,мокап,Захват движения
2766,modality,طريقة,وسيلة,صيغة,情态,"""由于不同的模式可能彼此相关，独立地对每个模式进行建模可能不够理想。我们还提出了一种新颖的模型，多模态复合概率上下文无关文法（MMC-PCFG），以更好地对这些模态之间的关联进行建模。在三个基准测试上进行的实验表明，在使用视频内容的每种模式时，可以获得",模态,modalité,modalité,modalité,モダリティ,モダリティ,モダリティ,модальность,модальность,модальность
2767,mode,وضع,نمط,وضع,模式,模式,模式,mode,mode,Mode,モード,モード,モード,режим,режим,мода
2768,mode collapse,انهيار الوضع,انهيار الوضعية,انهيار النمط,模式崩溃,模式崩溃 (mode collapse),模式崩溃,mode effondrement,Effondrement du mode,effondrement de mode,モード崩壊,モード崩壊,モード収束,свернуть режим,"""['проблемы нестабильности и режима коллапса (Брок и др., 2018; Хо и др., 2022) . Однако эти модели работают на извлечении высокоуровневых визуальных концепций из короткого текста и создают изображения, похожие на произведения искусства, котор",коллапс режима
2769,model,نموذج,النموذج,نموذج,模型,模型,模型,modèle,modèle,modèle,モデル,モデル (Model),モデル,модель,модель,модель
2770,model accuracy,دقة النموذج,دقة النموذج,دقة النموذج,模型精度,模型准确度,模型准确率,précision du modèle,- Précision du modèle,précision du modèle,モデルの精度,モデル精度,モデルの精度,точность модели,точность модели,точность модели
2771,model architecture,الهندسة المعمارية النموذجية,هندسة النموذج,هندسة النموذج,模型架构,模型架构,模型架构,architecture modèle,architecture du modèle,architecture du modèle,モデルアーキテクチャ,モデルアーキテクチャ,モデル構造,модель архитектуры,архитектура модели,архитектура модели
2772,model averaging,المتوسط ​​النموذجي,تقديم النموذج,ضم النماذج,模型平均,模型平均,模型平均,moyenne du modèle,moyennage de modèle,modèle moyennant,モデルの平均化,モデル平均,モデル平均化,усреднение модели,усреднение моделей,модельное усреднение
2773,model bias,التحيز النموذجي,الانحياز النموذجي,التحيز في النموذج,模型偏差,模型偏差,模型偏差,biais du modèle,biais du modèle,Biais de modèle,モデルバイアス,モデルの偏り,モデルバイアス,предвзятость модели,модельный уклон,предвзятость модели
2774,model capacity,قدرة النموذج,سعة النموذج,سعة النموذج,型号容量,模型容量 (Model Capacity),模型容量,capacité du modèle,- Capacité du modèle,capacité du modèle,モデル容量,モデル容量,モデル容量,мощность модели,емкость модели,ёмкость модели
2775,model card,بطاقة نموذجية,بطاقة النموذج,بطاقة النموذج,型号卡,模型卡,模型卡,carte modèle,fiche modèle,fiche modèle,モデルカード,モデルカード,モデルカード,модель карты,модельная карточка,карточка модели
2776,model checking,فحص النموذج,التحقق من النموذج,فحص النماذج,模型检验,模型检验,模型检查,vérification du modèle,Vérification de modèle,vérification de modèles,モデルチェック,モデルチェック,モデル検査,проверка модели,проверка модели,Проверка моделей
2777,model class,فئة النموذج,صنف النموذج,فئة النموذج,模型类,模型类,模型类,classe de modèle,classe de modèle,classe de modèles,モデルクラス,モデルクラス,モデルクラス,класс модели,класс моделей,класс моделей
2778,model comparison,مقارنة النموذج,مقارنة النماذج,مقارنة النماذج,型号对比,模型比较,模型比较,comparaison de modèles,comparaison de modèles,comparaison de modèles,モデル比較,モデル比較,モデル比較,сравнение моделей,сравнение моделей,Сравнение моделей
2779,model complexity,تعقيد النموذج,تعقيد النموذج,تعقيد النموذج,模型复杂度,模型复杂度,模型复杂度,complexité du modèle,complexité du modèle,complexité du modèle,モデルの複雑さ,モデルの複雑さ,モデルの複雑性,сложность модели,сложность модели,сложность модели
2780,model compression,ضغط النموذج,ضغط النموذج,ضغط النموذج,模型压缩,模型压缩,模型压缩,compression du modèle,compression de modèle,compression de modèle,モデル圧縮,モデル圧縮 (モデルあっしゅく),モデル圧縮,сжатие модели,сжатие модели,Сжатие моделей
2781,model convergence,تقارب النموذج,تقارب النموذج,اتفاق النموذج,模型收敛,模型收敛,模型收敛,convergence des modèles,convergence du modèle,convergence du modèle,モデルの収束,モデル収束 (moderu shuusoku),モデル収束,сходимость моделей,сходимость модели,сходимость модели
2782,model development,تطوير نموذج,تطوير النموذج,تطوير النموذج,模型开发,模型开发,模型开发,développement d'un modèle,développement du modèle,développement de modèle,モデル開発,モデル開発 (Moderu Kaihatsu),モデル開発,разработка модели,разработка модели,Разработка модели
2783,model distillation,التقطير النموذجي,تقطير النموذج,تقطير النموذج,模型蒸馏,模型蒸馏,模型蒸馏,modèle de distillation,distillation de modèle,distillation de modèle,モデル蒸留,モデル蒸留 (moderu jōmyaku),モデル知識転移,модель дистилляции,дистилляция модели,переганка моделей
2784,model distribution,توزيع النموذج,توزيع النموذج,توزيع النموذج,模型分布,模型分布,模型分布,distribution du modèle,distribution du modèle,"t ) pour promouvoir des sorties plus conservatrices. L'algorithme de décodage et le modèle de langue ensemble définissent une distribution Q sur le texte, que nous appelons la distribution du modèle.",モデルの配布,モデル分布 (Moderu bunpu),モデル分布,распределение модели,модельное распределение,модельное распределение
2785,model estimation,تقدير النموذج,تقدير النموذج,تقدير النموذج,模型估计,模型估计,模型估计,estimation du modèle,estimation du modèle,estimation de modèle,モデル推定,モデル推定,モデル推定,оценка модели,оценка модели,оценка модели
2786,model evaluation,تقييم النموذج,تقييم النموذج,تقييم النموذج,模型评估,模型评估,模型评估,évaluation du modèle,évaluation du modèle,évaluation de modèle,モデルの評価,モデル評価 (Moderu Hyōka),モデル評価,оценка модели,оценка модели,оценка модели
2787,model family,عائلة نموذجية,عائلة النموذج,عائلة النماذج,模范家庭,模型家族,模型系列,famille modèle,famille de modèles,famille de modèles,モデルファミリー,モデルファミリー,モデルファミリー,модельная семья,семейство моделей,семейство моделей
2788,model fine-tuning,ضبط النموذج,ضبط نموذج الموديل,ضبط دقيق للنموذج,模型微调,模型微调,模型微调,mise au point du modèle,ajustement fin du modèle,ajustement fin du modèle,モデルの微調整,モデルの微調整,モデルファインチューニング,точная настройка модели,Моделирование настройки (модель-настройка),Настройка модели
2789,model generalization,تعميم النموذج,قدرة النموذج على التعميم,تعميم النموذج,模型泛化,模型泛化,模型泛化能力,généralisation du modèle,généralisation du modèle,généralisation du modèle,モデルの一般化,モデルの一般化,モデルの一般化能力,обобщение модели,обобщение модели,обобщение модели
2790,model hyperparameter,المعلمة الفائقة النموذجية,- تعديلات النموذج الهايبرباراميترية,معامل نموذج فرعي,模型超参数,模型超参数,模型超参数,hyperparamètre de modèle,hyperparamètre du modèle,hyperparamètre du modèle,モデルのハイパーパラメータ,モデルハイパーパラメータ,モデルハイパーパラメータ,гиперпараметр модели,гиперпараметр модели,гиперпараметры модели
2791,model inference,الاستدلال النموذجي,- تصنيف النموذج,استنتاج النموذج,模型推理,模型推断 (Model Inference),模型推理,inférence de modèle,inférence de modèle,inférence de modèle,モデル推論,モデル推論 (Model Suiun),モデル推論,модельный вывод,вывод модели,вывод модели
2792,model initialization,تهيئة النموذج,- تهيئة النموذج,تهيئة النموذج,模型初始化,模型初始化,模型初始化,initialisation du modèle,initialisation du modèle,initialisation du modèle,モデルの初期化,モデルの初期化,モデル初期化,инициализация модели,инициализация модели,инициализация модели
2793,model interpretability,قابلية تفسير النموذج,التفسير النمائي للنموذج,قابلية تفسير النموذج,模型的可解释性,模型可解释性,模型可解释性,interprétabilité du modèle,interprétabilité du modèle,interprétabilité des modèles,モデルの解釈可能性,モデルの解釈可能性,モデル解釈性,интерпретируемость модели,интерпретируемость модели,интерпретируемость модели
2794,model interpretation,تفسير النموذج,تفسير النموذج,تفسير النموذج,模型解释,模型解释,模型解释,interprétation du modèle,interprétation du modèle,interprétation de modèle,モデルの解釈,モデル解釈,モデル解釈,интерпретация модели,интерпретация модели,интерпретация модели
2795,model layer,طبقة النموذج,طبقة النموذج,طبقة النموذج,模型层,模型层,模型层,couche de modèle,couche de modèle,couche de modèle,モデルレイヤー,モデル層 (モデルそう),モデル層,слой модели,слой модели,слой модели
2796,model m,نموذج م,نموذج M,نموذج م,型号 m,模型M,模型 M,modèle m,modèle M,modèle M,モデルM,モデルM,モデル M,модель м,модель M,модель M
2797,model output,إخراج النموذج,ناتج النموذج,نواتج النموذج,模型输出,模型输出,模型输出,sortie du modèle,sortie du modèle,modèle de sortie,モデル出力,モデル出力,モデル出力,выходные данные модели,выход модели,модельный вывод
2798,model parallelism,التوازي النموذجي,- توازي النموذج,تقسيم النموذج,模型并行性,模型并行ism,模型并行,parallélisme du modèle,parallélisme des modèles,parallélisme de modèle,モデルの並列性,モデル並列化,モデル並列化,модельный параллелизм,модель параллелизма,параллелизм моделей
2799,model parameter,المعلمة النموذجية,معلم النموذج,معامل النموذج,型号参数,模型参数,模型参数,paramètre du modèle,paramètre du modèle,paramètre de modèle,モデルパラメータ,モデルパラメータ (model parameter),モデルパラメータ,параметр модели,параметр модели,параметр модели
2800,model performance,أداء النموذج,أداء النموذج,أداء النموذج,模型性能,模型性能,模型表现,performances du modèle,- Performance du modèle,performance du modèle,モデルのパフォーマンス,モデルのパフォーマンス,モデルの性能,производительность модели,производительность модели,производительность модели
2801,model precision,دقة النموذج,الدقة النموذجية,دقة النموذج,模型精度,模型精确度,模型精度,précision du modèle,précision du modèle,précision du modèle,モデルの精度,モデル精度 (model precision),モデル精度,точность модели,точность модели,точность модели
2802,model prediction,التنبؤ النموذجي,التنبؤ بالنموذج,نبؤات النموذج,模型预测,模型预测,模型预测,prédiction du modèle,prédiction du modèle,prédiction du modèle,モデル予測,モデル予測,モデル予測,прогнозирование модели,предсказание модели,модельное предсказание
2803,model predictive control,نموذج التحكم التنبؤي,التحكم التنبؤي بالنموذج,التحكم التنبؤي بالنموذج,模型预测控制,模型预测控制,模型预测控制,modèle de contrôle prédictif,contrôle prédictif de modèle,contrôle par prédiction de modèle,モデル予測制御,モデル予測制御 (model predictive control),モデル予測制御,прогнозирующее управление моделью,модельное предиктивное управление,прогнозирующее управление моделью
2804,model representation,تمثيل النموذج,تمثيل النموذج,نموذج تمثيل,模型表示,模型表示,模型表示,représentation du modèle,représentation du modèle,représentation du modèle,モデル表現,モデル表現 (Moderu Hyōgen),モデル表現,представление модели,представление модели,модельное представление
2805,model robustness,متانة النموذج,قوة النموذج,متانة النموذج,模型稳健性,模型鲁棒性,模型鲁棒性,robustesse du modèle,robustesse du modèle,robustesse du modèle,モデルの堅牢性,モデルの頑健性 (moderu no kankeisei),モデルロバスト性,надежность модели,устойчивость модели,робастность модели
2806,model score,النتيجة النموذجية,نتيجة النموذج,النموذج نتيجة,模型得分,模型得分,模型分数,score de modèle,score du modèle,score du modèle,モデルスコア,モデルスコア,モデルスコア,оценка модели,балл модели,модельная оценка
2807,model selection,اختيار النموذج,اختيار النموذج,اختيار النموذج,选型,模型选择,模型选择,sélection du modèle,sélection de modèle,sélection de modèle,モデルの選択,モデル選択 (mooderu sentaku),モデル選択,выбор модели,выбор модели,выбор модели
2808,model size,حجم النموذج,حجم النموذج,حجم النموذج,型号尺寸,模型大小,模型大小,taille du modèle,taille du modèle,taille du modèle,モデルサイズ,モデルサイズ,モデルサイズ,размер модели,размер модели,размер модели
2809,model specification,نموذج مواصفات,مواصفات النموذج,مواصفات النموذج,型号规格,模型规范化,模型规范,Modèle Spécification,spécification du modèle,spécification du modèle,モデル仕様,モデル仕様 (Moderu shiyō),モデル仕様,спецификация модели,спецификация модели,спецификация модели
2810,model structure,هيكل النموذج,هيكل النموذج,بنية النموذج,模型结构,模型结构,模型结构,structure du modèle,structure du modèle,structure du modèle,モデル構造,モデル構造,モデル構造,структура модели,структура модели,структура модели
2811,model training,التدريب النموذجي,التدريب على النموذج,تدريب النموذج,模型训练,模型训练,模型训练,formation de modèle,Entraînement du modèle,apprentissage du modèle,モデルトレーニング,モデルトレーニング,モデル学習,обучение модели,обучение модели,обучение модели
2812,model update,تحديث النموذج,تحديث النموذج,تحديث النموذج,模型更新,模型更新,模型更新,mise à jour du modèle,mise à jour du modèle,Mise à jour du modèle,モデルのアップデート,モデル更新 (Moderu Koushin),モデル更新,обновление модели,обновление модели,обновление модели
2813,model variant,البديل النموذجي,- تغيير نموذجية,متغير النموذج,模型变体,模型变体,模型变体,variante de modèle,variante du modèle,variante de modèle,モデルバリエーション,モデルバリエント,モデル変種,вариант модели,вариант модели,вариант модели
2814,model weight,وزن النموذج,وزن النموذج,أوزان النموذج,型号重量,模型权重,模型权重,poids du modèle,poids du modèle,poids du modèle,モデルの重量,モデルの重み,モデル重み,вес модели,модельные веса,вес модели
2815,model's parameter,معلمة النموذج,"- تعديلات النموذج
- معلمات النموذج",معامل النموذج,模型参数,模型参数,模型参数,paramètre du modèle,paramètres du modèle,paramètres du modèle,モデルのパラメータ,モデルのパラメータ,モデルのパラメータ,параметр модели,параметры модели,параметры модели
2816,model-base approach,النهج القائم على النموذج,نهج قائم على النموذج,نهج قائم على النموذج,基于模型的方法,模型基方法,基于模型的方法,approche basée sur un modèle,approche basée sur le modèle,approche basée sur un modèle,モデルベースのアプローチ,モデルベースアプローチ (Model-based approach),モデルベースアプローチ,модельно-ориентированный подход,модельно-ориентированный подход,подход на основе модели
2817,model-base reinforcement learning,التعلم المعزز القائم على النموذج,تعلم التعزيز المعتمد على النموذج,تعلم التعزيز القائم على النموذج,基于模型的强化学习,基于模型的强化学习,基于模型的强化学习,apprentissage par renforcement basé sur un modèle,apprentissage par renforcement basé sur un modèle,apprentissage par renforcement basé sur des modèles,モデルベースの強化学習,モデルベース強化学習,モデルベース強化学習,обучение с подкреплением на основе моделей,модельное обучение с подкреплением,модельно-базированное обучение с подкреплением
2818,model-free approach,نهج خالي من النماذج,النهج الخالي من النموذج,نهج خالٍ من النموذج,无模型方法,无模型方法,无模型方法,approche sans modèle,- Approche sans modèle,approche sans modèle,モデルフリーのアプローチ,モデルフリーアプローチ,モデルフリーアプローチ,безмодельный подход,модель-независимый подход,подход без модели
2819,modular,وحدات,متعدد الوحدات,وحدوي,模块化的,模块化,模块化,modulaire,modulaire,modulaire,モジュラー,モジュラー,モジュラー,модульный,модульный,модульный
2820,modular architecture,العمارة المعيارية,الهندسة المعمارية المودولارية,بِنْيَة مُوَدُّولِيَّة,模块化架构,模块化架构,模块化架构,architecture modulaire,- Architecture modulaire,architecture modulaire,モジュール式アーキテクチャ,モジュラーアーキテクチャ,モジュラーアーキテクチャ,модульная архитектура,модульная архитектура,модульная архитектура
2821,module,وحدة,وحدة,وحدة,模块,模块 (módú),模块,module,module,module,モジュール,モジュール,モジュール,модуль,модуль,модуль
2822,moment matching,مطابقة اللحظة,مطابقة اللحظة,مطابقة اللحظة,矩匹配,矩匹配,矩配,moment correspondant,correspondance des moments,correspondance des moments,瞬間一致,モーメントマッチング,時間的一致法,совпадение моментов,метод сопоставления моментов,момент сопоставления
2823,momentum,دَفعَة,- الزخم,الزخم,势头,动量,动量,élan,"""['Par exemple, pour les tâches avec de plus grands ensembles de données, un taux d'apprentissage initial plus élevé et un momentum plus faible peuvent être plus appropriés, tandis que pour les tâches avec de plus petits ensembles de données, un taux d'apprentissage initial plus faible et un momentum plus élevé peuvent être plus appropriés.', 'Pour un Transformer sur LM1B avec une taille de lot de 2048, utilisez un taux d'apprentissage initial de 0,001",Quantité de mouvement,勢い,モメンタム,運動量,импульс,импульс,инерция
2824,momentum coefficient,معامل الزخم,معامل الزخم,معامل الزخم,动量系数,动量系数,动量系数,coefficient de quantité de mouvement,coefficient de momentum,coefficient d'inertie,運動量係数,運動量係数,運動量係数,коэффициент импульса,коэффициент импульса,коэффициент инерции
2825,momentum encoder,التشفير الزخم,مُشَفّر الزخم,مرمز الزخم,动量编码器,动量编码器,动量编码器,codeur d'impulsion,encodeur de momentum,codeur d'inertie,運動量エンコーダ,運動量エンコーダ,モーメンタムエンコーダ,датчик импульса,моментум-кодировщик,кодировщик моментума
2826,momentum term,مصطلح الزخم,مصطلح الزخم,حد الزخم,动量项,动量项,动量项,terme d'élan,terme de momentum,terme d'inertie,運動量項,モーメンタム項 (mo-mentamukou),運動量項,термин импульса,терм импульса,момент инерции
2827,monocular,أحادي,"""بشكل خاص بالنسبة لتطبيقات الأخيرة، سيكون من المهم أن نكون قادرين على التقاط الأداء البشري من خلال الفيديو أحادي العين. معظم الطرق الأحادية المثبتة فقط تلتقط الحركة",واحد العدسة,单眼的,单目,单眼,monoculaire,monoculaire,monoculaire,単眼,単眼(camera),単眼,монокуляр,монокулярный,Однокамерный
2828,monocular reconstruction,إعادة بناء أحادي العين,إعادة بناء أحادي العينية,الترميز البصري الأحادي,单眼重建,单目重建,单目重建,reconstruction monoculaire,Reconstruction monoculaire,reconstruction monoculaire,単眼再構成,単眼再構築,モノクラー3次元復元,монокулярная реконструкция,монокулярная реконструкция,монокулярная реконструкция
2829,monolingual baseline,خط الأساس أحادي اللغة,القاعدة الأساسية أحادية اللغة,خط أساس أحادي اللغة,单语基线,单语基准线,单语种基线,ligne de base unilingue,référence monolingue,base monolingue,単一言語ベースライン,単一言語のベースライン,単言語ベースライン,одноязычный базовый уровень,моноязычный базовый уровень,одноязычный базовый уровень
2830,monolingual corpora,أجساد أحادية اللغة,- تجميعات لغوية أحادية,مجموعات لغوية أحادية,单语语料库,单语语料库 (monolingual corpora),单语语料库,corpus monolingues,corpus monolingue,corpus monolingue,単一言語コーパス,単一言語コーパス,単言語コーパス,одноязычные корпуса,монолингвальные корпуса,монолингвальные корпуса
2831,monolingual corpus,جسم أحادي اللغة,المخزون النصي أحادي اللغة,نص أحادي اللغة,单语语料库,单语语料库,单语言语料库,corpus monolingue,corpus monolingue,corpus monolingue,単一言語コーパス,単言語コーパス,単言語コーパス,одноязычный корпус,одноязычный корпус,корпус на одном языке
2832,monolingual dataset,مجموعة بيانات أحادية اللغة,مجموعة بيانات أحادية اللغة,مجموعة بيانات أحادية اللغة,单语数据集,单语数据集,单语语料库,ensemble de données monolingues,- Jeu de données monolingue,ensemble de données monolingue,単一言語データセット,単言語データセット (tangengo datasetto),単一言語データセット,одноязычный набор данных,монолингвальный набор данных,набор данных на одном языке
2833,monolingual datum,مسند أحادي اللغة,معطى أحادي اللغة,بيانات أحادية اللغة,单语资料,单语数据,单语语料,donnée unilingue,donnée monolingue,donnée monolingue,単一言語データ,単一言語のデータ,単言語デー​タ,одноязычные данные,монолингвальный набор данных,одноязычные данные
2834,monolingual embedding,التضمين أحادي اللغة,تضمين أحادي اللغة,تضمين أحادي اللغة,单语言嵌入,单语嵌入,单语种嵌入,intégration monolingue,incrustation monolingue,Plongement monolingue,単一言語の埋め込み,単言語埋め込み (tangengo umekomi),単言語埋め込み,одноязычное встраивание,монолингвальное вложение,одноязычное встраивание
2835,monolingual model,نموذج أحادي اللغة,- تعلم اللغة الواحدة,نموذج أحادي اللغة,单语模型,单语模型,单语言模型,modèle monolingue,- Modèle monolingue,modèle monolingue,単一言語モデル,単一言語モデル,単言語モデル,одноязычная модель,монолингвальная модель,одноязычная модель
2836,monolingual training,التدريب أحادي اللغة,التدريب أحادي اللغة,تدريب أحادي اللغة,单语培训,单语培训,单语训练,formation monolingue,- Entraînement monolingue,entraînement monolingue,モノリンガルトレーニング,単言語トレーニング (tangengo training),単言語訓練,одноязычное обучение,монолингвальное обучение,Обучение на одноязычных данных
2837,monotone,روتيني,L 2 → L 2 هو تقريب لعامل O إذا كان ≤ pmonotone ولديه الخاصية التي A(x، x) = (O(x)، O(x)) لجميع x ∈ L. تقريبيون هم داخليون في L c (أي يربطون L c إلى L c). ، 'f (S,متصاعدة,单调,单调,单调增加,monotone,monotone,monotone,単調,単調,単調増加,монотонный,монотонный,монотонный
2838,monotonic,رتيب,متزايد الاتجاه,متصاعد,单调的,单调,单调,monotone,monotone,monotone,単調な,単調増加,単調,монотонный,монотонный,монотонный
2839,monotonicity,الرتابة,الإتساق,تناسق,单调性,单调性,单调性,monotonie,monotonie,Monotonicité,単調性,単調増加性,単調性,монотонность,Монотонность,Монотонность
2840,morphological analysis,التحليل الصرفي,- معالجة تشكيلية,تحليل الصرفي,形态分析,形态学分析,形态学分析,analyse morphologique,- Analyse morphologique,analyse morphologique,形態素解析,形態素解析,形態素解析,морфологический анализ,морфологический анализ,морфологический анализ
2841,morphological analyzer,محلل مورفولوجي,محلل صرفي عربي,محلل صرفي,形态分析仪,形态分析器,形态分析器,analyseur morphologique,analyseur morphologique,analyseur morphologique,形態素解析器,形態素解析器 (keitaisho kaiseki-ki),形態素解析器,морфологический анализатор,морфологический анализатор,морфологический анализатор
2842,morphological feature,الميزة المورفولوجية,الميزة المورفولوجية,مِلامِحُ صَرْفِيَّة,形态特征,形态特征,形态学特征,caractéristique morphologique,caractéristique morphologique,caractéristique morphologique,形態的特徴,形態素的特徴,形態素的特徴,морфологическая особенность,морфологическая характеристика,морфологическая черта
2843,morphological information,المعلومات المورفولوجية,- معلومات مورفولوجية,معلومات صرفية,形态信息,形态信息,形态信息,informations morphologiques,- Information morphologique,informations morphologiques,形態情報,形態情報 (Keitai jōhō),形態論的情報,морфологическая информация,морфологическая информация,морфологическая информация
2844,morphological operation,العملية المورفولوجية,العمليات المورفولوجية,عملية تشكيلية,形态学运算,形态学操作,形态学运算,opération morphologique,- Opération morphologique,opération morphologique,形態学的操作,形態学的演算,形態学的操作,морфологическая операция,морфологическая операция,морфологическая операция
2845,morphological segmentation,التقسيم المورفولوجي,التقسيم المورفولوجي,تجزئة صرفية,形态分割,形态分割,形态分割,segmentation morphologique,- Segmentation morphologique,segmentation morphologique,形態学的セグメンテーション,形態的セグメンテーション (Keitaiteki Segumentēshon),形態素分割,морфологическая сегментация,морфологическая сегментация,морфологическая сегментация
2846,morphology,علم التشكل المورفولوجيا,الصورة الخارجية,تراكيب,形态学,形态学,形态学,morphologie,morphologie,morphologie,形態学,形態 (けいたい),形態論,морфология,морфология,морфология
2847,motion analysis,تحليل الحركة,تحليل الحركة,تحليل الحركة,运动分析,运动分析,运动分析,analyse de mouvement,- Analyse du mouvement,analyse du mouvement,動作解析,動き解析,動作解析,анализ движения,анализ движения,анализ движения
2848,motion estimation,تقدير الحركة,تقدير الحركة,تقدير الحركة,运动估计,运动估计,运动估计,estimation du mouvement,Estimation de mouvement,estimation du mouvement,動き推定,動き推定,動き推定,оценка движения,оценка движения,оценка движения
2849,motion matrix,مصفوفة الحركة,مصفوفة الحركة,حركة المصفوفة,运动矩阵,运动矩阵,运动矩阵,matrice de mouvement,matrice de mouvement,matrice de mouvement,モーションマトリックス,動きの行列,運動行列,матрица движения,матрица движения,матрица движения
2850,motion planning,تخطيط الحركة,تخطيط الحركة,التخطيط الحركي,运动规划,运动规划,运动规划,planification de mouvement,planification de mouvement,planification de mouvement,モーションプランニング,動作計画,動作計画,планирование движения,планирование движения,Планирование движения
2851,motion segmentation,تجزئة الحركة,- التقسيم الحركي,تقسيم الحركة,运动分割,运动分割,运动分割,segmentation de mouvement,segmentation de mouvement,segmentation des mouvements,モーションセグメンテーション,動きのセグメンテーション,動き分割,сегментация движения,сегментация движения,сегментация движения
2852,move average,التحرك المتوسط,- تحريك المتوسط,متوسط متحرك,移动平均线,移动平均,移动平均,moyenne mobile,moyenne mobile,moyenne mobile,移動平均,移動平均,移動平均,скользящее среднее,скользящее среднее,скользящее среднее
2853,multi-agent,وكيل متعدد,متعدد الوكلاء,متعدد الوكلاء,多代理,多智能体,多智能体,multi-agent,"""['Dans la Section 4, nous développons une nouvelle méthode de gradient de politique multi-agent pour aborder ce cas. Dans le reste de cette section, nous donnons quelques informations sur les méthodes de gradient de politique pour un seul agent (Sutton et al. 1999).', 'La plupart des applications précédentes de l'apprentissage par renforcement à la microgestion de StarCraft utilisent un contrôleur centralisé, avec accès à l'état complet et contrôle de toutes les unités, bien que l",multi-agents,マルチエージェント,マルチエージェント,複数エージェント,мультиагентный,мультиагентный,многоагентный
2854,multi-agent interaction,تفاعل متعدد الوكلاء,تفاعل العوامل المتعددة,تفاعل متعدد الوكلاء,多智能体交互,多智能体互动,多智能体交互,interaction multi-agents,Interaction multi-agent,interaction multi-agents,マルチエージェントのインタラクション,マルチエージェント相互作用,複数エージェント間の相互作用,мультиагентное взаимодействие,многоагентное взаимодействие,многоагентное взаимодействие
2855,multi-agent learning,التعلم متعدد الوكلاء,التعلم متعدد الوكلاء,تعلم متعدد الوكلاء,多智能体学习,多智能体学习,多智能体学习,apprentissage multi-agents,apprentissage multi-agent,apprentissage multi-agents,マルチエージェント学習,マルチエージェント学習 (multi-agent learning),多エージェント学習,многоагентное обучение,многоАгентное обучение,многоагентное обучение
2856,multi-agent reinforcement learning,التعلم المعزز متعدد الوكلاء,التعلم التعزيزي للوكلاء المتعددين,تعلم تعزيزي متعدد الوكلاء,多智能体强化学习,多智能体强化学习,多智能体强化学习,apprentissage par renforcement multi-agents,apprentissage par renforcement multi-agent,apprentissage par renforcement multi-agents,マルチエージェント強化学習,多エージェント強化学習,複数エージェント強化学習,многоагентное обучение с подкреплением,многопараметрическое обучение с подкреплением,многоагентное обучение с подкреплением
2857,multi-agent system,نظام متعدد الوكلاء,نظام وكلاء متعددين,نظام وكلاء متعدد,多智能体系统,多智能体系统,多智能体系统,système multi-agents,- Système multi-agent,système multi-agent,マルチエージェントシステム,多重エージェントシステム,マルチエージェントシステム,многоагентная система,мультиагентная система,многоагентная система
2858,multi-armed bandit,قطاع الطرق متعدد الأسلحة,اللص الذي له عدة ذراع,مشكلة الأذرع المتعددة,多臂强盗,多臂赌博机,多臂老虎机,bandit à plusieurs bras,bandit à plusieurs bras,bandit à bras multiples,多腕の盗賊,多腕バンディット,多腕バンディット,многорукий бандит,многорукий бандит,задача о многорукой бандитке
2859,multi-armed bandit problem,مشكلة قطاع الطرق متعدد الأسلحة,مشكلة السارق متعدد الذراعين,مشكلة القطاع المتعدد الأذرع,多臂老虎机问题,多臂老虎机问题,多臂赌博机问题,problème de bandit à plusieurs bras,problème du bandit manchot multi-bras,problème de bandit multi-bras,多腕盗賊問題,多腕バンディット問題,多腕バンディット問題,проблема многорукого бандита,Проблема многоруких бандитов.,проблема многорукого бандита
2860,multi-class,متعدد الطبقات,متعدد الفئات,متعدد الفئات,多类,多类 (duō lèi),多类别,multiclasse,multi-classe,multi-classe,マルチクラス,マルチクラス,多クラス,многоклассовый,многоклассовый,многоклассовый
2861,multi-class classification,تصنيف متعدد الطبقات,التصنيف متعدد الفئات,تصنيف متعدد الفئات,多类分类,多类分类 (duō lèi fēn lèi),多分类,classification multiclasse,classification multi-classe,classification multi-classes,マルチクラス分類,多クラス分類 (Multi-class classification),多クラス分類,многоклассовая классификация,многоклассовая классификация,Многоклассовая классификация
2862,multi-class logistic regression,الانحدار اللوجستي متعدد الطبقات,- التصنيف اللوجستي متعدد الفئات,انحدار لوجستي متعدد الفئات,多类逻辑回归,多类逻辑回归,多类逻辑回归,régression logistique multiclasse,Régression logistique multi-classe,régression logistique multi-classes,複数クラスのロジスティック回帰,マルチクラスロジスティック回帰 (Multi-class logistic regression),マルチクラスロジスティック回帰,многоклассовая логистическая регрессия,многоклассовая логистическая регрессия,многоклассовая логистическая регрессия
2863,multi-class problem,مشكلة متعددة الطبقات,مشكلة متعددة الفئات,مشكلة متعددة الفئات,多类问题,多类问题,多类别问题,problème multiclasse,problème à classes multiples,problème multi-classes,複数クラスの問題,マルチクラス問題 (multi-class 問題),多クラス問題,многоклассовая проблема,многоклассовая проблема,многоклассовая задача
2864,multi-classification,متعدد التصنيف,- تصنيف متعدد,تصنيف متعدد,多分类,多类分类,多分类,multi-classification,multi-classification,multi-classification,多分類,マルチクラス分類 (Maruchikurasu bunka),多クラス分類,мультиклассификация,многоклассовая классификация,многоклассовая классификация
2865,multi-document summarization,تلخيص متعدد المستندات,الملخص المتعدد للمستندات,تلخيص متعدد الوثائق,多文档摘要,多文档摘要,多文档摘要,synthèse multidocument,résumé multi-document,résumé multi-documents,複数の文書の要約,マルチドキュメント要約,多文書要約,обобщение нескольких документов,многодокументное резюмирование,многодокументное резюмирование
2866,multi-domain,متعدد المجال,متعدد المجالات,متعدد المجالات,多域,多领域,多领域,multi-domaine,multi-domain,multi-domaine,マルチドメイン,マルチドメイン,多領域,многодоменный,мульти-домен,многодоменный
2867,multi-head,متعدد الرؤوس,متعدد الرؤوس,متعدد الرؤوس,多头,"""在多头视角下，这种注意力为每个头生成不同的稀疏查询-键对，从而避免了严重的信息丢失。""",多头,multi-tête,multi-tête,multi-tête,マルチヘッド,マルチヘッド,複数ヘッド,многоголовочный,много-головой,многоголовой
2868,multi-head attention,اهتمام متعدد الرؤوس,- تركيز متعدد الرؤوس,الانتباه متعدد الرؤوس,多头注意力,多头注意力,多头注意力,attention multi-têtes,attention à plusieurs têtes,attention multi-tête,多頭注意,マルチヘッドアテンション,マルチヘッドアテンション,многоголовое внимание,многоголовое внимание,многоголовное внимание
2869,multi-head attention layer,طبقة انتباه متعددة الرؤوس,طبقة الانتباه متعددة الرؤوس,طبقة الانتباه متعددة الرؤوس,多头注意力层,多头注意力层,多头注意力层,couche d'attention multi-têtes,couche d'attention multi-têtes,couche d'attention multi-têtes,マルチヘッドアテンションレイヤー,マルチヘッドアテンションレイヤー,多頭注目層,многоголовый слой внимания,много-головной слой внимания,слой многоголовного внимания
2870,multi-head self-attention,الاهتمام الذاتي متعدد الرؤوس,- الانتباه الذاتي متعدد الرؤوس,اهتمام ذاتي متعدد الرؤوس,多头自注意力,多头自注意力,多头自注意力机制,auto-attention multi-tête,auto-attention à têtes multiples,attention multi-tête auto-référentielle,多頭の自己注意,マルチヘッド自己注意,多頭自己注目機構,многоголовый самообслуживание,многоголовое самовнимание,многоголовное самовнимание
2871,multi-head self-attention mechanism,آلية الاهتمام الذاتي متعددة الرؤوس,آلية اهتمام الذات برؤوس متعددة,آلية الانتباه الذاتي متعدد الرؤوس,多头自注意力机制,多头自注意机制,多头自注意力机制,mécanisme d'auto-attention multi-têtes,mécanisme d'auto-attention à têtes multiples,mécanisme d'auto-attention multi-têtes,マルチヘッドセルフアテンションメカニズム,マルチヘッド自己注意メカニズム,複数ヘッドセルフアテンションメカニズム,многоголовочный механизм самообслуживания,механизм самовнимания с многоголовым вниманием,механизм многоголовочного самовнимания
2872,multi-head self-attention module,وحدة الاهتمام الذاتي متعددة الرؤوس,وحدة الانتباه الذاتي متعددة الرؤوس,وحدة الانتباه الذاتي متعددة الرؤوس,多头自注意力模块,多头自注意力模块,多头自注意力模块,module d'auto-attention multi-têtes,module d'auto-attention à têtes multiples,module d'auto-attention multi-têtes,マルチヘッドセルフアテンションモジュール,マルチヘッド自己注意モジュール,複数ヘッド自己注目モジュール,многоголовочный модуль самообслуживания,модуль многоголовкового самовнимания,Модуль многоголовного самовнимания
2873,multi-headed self-attention,الاهتمام الذاتي متعدد الرؤوس,التركيز الذاتي متعدد الرؤوس,الانتباه الذاتي متعدد الرؤوس,多头自注意力,多头自注意力,多头自注意力,auto-attention à plusieurs têtes,auto-attention à plusieurs têtes,attention multi-têtes,多頭の自己注意,マルチヘッドセルフアテンション,複数ヘッド自己注目,многоглавое внимание к себе,Многоголовое самовнимание,многоголовое самовнимание
2874,multi-label,متعدد التسمية,- متعددة التسميات,متعدد التسميات,多标签,多标签,多标记,multi-étiquette,multi-étiquette,multi-étiquette,マルチラベル,マルチラベル,複数ラベル,мульти-лейбл,мультиэтикетка,многометочный
2875,multi-label classification,تصنيف متعدد العلامات,التصنيف متعدد العلامات,تصنيف متعدد الملصقات,多标签分类,多标签分类,多标签分类,classification multi-étiquettes,classification multi-étiquettes,classification multi-étiquettes,マルチラベル分類,マルチラベル分類,多ラベル分類,классификация по нескольким меткам,Многоклассовая классификация,Многоклассовая классификация
2876,multi-label classification loss,فقدان تصنيف متعدد التسمية,- تحديد فقدان التصنيف متعدد العلامات,خسارة التصنيف متعدد التسميات,多标签分类损失,多标签分类损失,多标签分类损失,perte de classification multi-étiquettes,perte de classification multi-étiquette,perte de classification multi-étiquettes,マルチラベル分類損失,マルチラベル分類損失,多ラベル分類損失,потеря классификации по нескольким меткам,многозначительная потеря классификации,потери при многоклассовой классификации
2877,multi-label classifier,مصنف متعدد العلامات,مصنف متعدد العلامات,مُصنف متعدد البنود,多标签分类器,多标签分类器,多标签分类器,classificateur multi-étiquettes,classificateur multi-étiquettes,classifieur multi-étiquettes,マルチラベル分類子,マルチラベル分類器,複数ラベル分類器,классификатор с несколькими метками,многометочный классификатор,многометочный классификатор
2878,multi-label datum,مسند متعدد التسمية,بيانات متعددة العلامات,بيانات متعددة الوسوم,多标签数据,多标签数据,多标签数据,donnée multi-étiquette,donnée multi-étiquette,donnée multi-étiquette,マルチラベルデータム,マルチラベルデータ,データ多重ラベル,данные с несколькими метками,многометкая информация,многометочные данные
2879,multi-label learning,التعلم متعدد العلامات,التعلم متعدد العلامات,تعلم متعدد التصنيفات,多标签学习,多标签学习,多标签学习,apprentissage multi-étiquettes,apprentissage multi-étiquettes,apprentissage multi-étiquettes,マルチラベル学習,マルチラベル学習,多ラベル学習,обучение по нескольким меткам,многоклассовое обучение,многоклассовое обучение
2880,multi-label text classification,تصنيف النص متعدد التسمية,تصنيف نصوص متعدد العلامات,تصنيف نصوص متعدد التصنيفات,多标签文本分类,多标签文本分类,多标签文本分类,classification de texte multi-étiquettes,classification de texte multi-étiquettes,classification de texte multi-étiquettes,複数ラベルのテキスト分類,マルチラベルテキスト分類 (Multi-label text classification),多ラベルテキスト分類,классификация текста с несколькими метками,многозначная классификация текста,многоклассовая классификация текста
2881,multi-layer neural network,شبكة عصبية متعددة الطبقات,شبكة عصبية متعددة الطبقات,شبكة عصبية متعددة الطبقات,多层神经网络,多层神经网络,多层神经网络,réseau neuronal multicouche,réseau neuronal à couches multiples,réseau neuronal multicouche,多層ニューラルネットワーク,多層ニューラルネットワーク,多層ニューラルネットワーク,многослойная нейронная сеть,многослойная нейронная сеть,многослойная нейронная сеть
2882,multi-layer perceptron,متعدد الطبقات المستقبلات,الشبكة العصبية متعددة الطبقات,متعدد الطبقات المُدرك,多层感知器,多层感知器,多层感知器,perceptron multicouche,perceptron multicouche,perceptron multicouche,多層パーセプトロン,マルチレイヤーパーセプトロン,多層パーセプトロン,многослойный перцептрон,Многослойный персептрон,многослойный перцептрон
2883,multi-modal,متعدد الوسائط,متعدد الوسائط,متعدد الوسائط,多式联运,多模态,多模态,multimodal,"""['L'apprentissage prompt est d'abord proposé en traitement du langage naturel (NLP), dans l'espoir d'adapter des modèles pré-entraînés visuel-langage à diverses tâches en aval. Récemment, l'idée de prompt a été transférée à certaines tâches multi-modales (Shen et al. 2022). CoOp (Zhou et al.', 'Nous décrivons ensuite la procédure de mise en correspondance de la",multimodal,マルチモーダル,マルチモーダル,マルチモーダル,мультимодальный,мультимодальный,многомодальный
2884,multi-modal input,إدخال متعدد الوسائط,الإدخال متعدد الوسائط,مدخلات متعددة الوسائط,多模态输入,多模态输入,多模态输入,entrée multimodale,entrée multi-modale,entrées multimodales,マルチモーダル入力,マルチモーダル入力,マルチモーダル入力,мультимодальный ввод,мультимодальный вход,многомодальный ввод
2885,multi-modal learning,التعلم متعدد الوسائط,التعلم متعدد الوسائط,التعلم متعدد الوسائط,多模式学习,多模态学习,多模态学习,apprentissage multimodal,apprentissage multi-modal,apprentissage multimodal,マルチモーダル学習,マルチモーダルラーニング,多モダル学習,мультимодальное обучение,мультимодальное обучение,многомодальное обучение
2886,multi-modal model,نموذج متعدد الوسائط,نموذج متعدد الوسائط,نموذج متعدد الوسائط,多模态模型,多模型 (multi-modal model),多模态模型,modèle multimodal,modèle multi-modal,modèle multimodal,マルチモーダルモデル,マルチモーダルモデル,多様なモダリティを統合したモデル,мультимодальная модель,мультимодельная модель,многомодельная модель
2887,multi-object detection,الكشف عن كائنات متعددة,الكشف عن عدة أجسام,الكشف متعدد الكائنات,多目标检测,多目标检测,多目标检测,détection multi-objets,détection multi-objets,détection multi-objets,複数の物体の検出,多物体検出,複数オブジェクト検出,обнаружение нескольких объектов,многокомпонентное обнаружение,обнаружение нескольких объектов
2888,multi-objective optimization,التحسين متعدد الأهداف,أمثلة لتعريف العديد من الأهداف,تحسين متعدد الأهداف,多目标优化,多目标优化,多目标优化,optimisation multi-objectifs,optimisation multi-objectif,optimisation multi-objectif,多目的最適化,多目的最適化 (tamokuteki saitekika),多目的最適化,многокритериальная оптимизация,многокритериальная оптимизация,многоцелевая оптимизация
2889,multi-scale,متعدد النطاق,- المقياس المتعدد,متعدد المقاييس,多尺度,多尺度,多尺度,multi-échelle,multi-échelle,multi-échelle,マルチスケール,マルチスケール,多スケール,многомасштабный,мульти-масштабный,многомасштабный
2890,multi-scale architecture,العمارة متعددة النطاق,الهندسة المعمارية متعددة المقاييس,معمارية متعددة المقاييس,多尺度架构,多尺度架构,多尺度架构,architecture multi-échelle,architecture multi-échelle,architecture multi-échelle,マルチスケールアーキテクチャ,マルチスケールアーキテクチャ,マルチスケールアーキテクチャ,многомасштабная архитектура,многоуровневая архитектура,многомасштабная архитектура
2891,multi-scale training,التدريب متعدد النطاق,التدريب متعدد المقاييس,تدريب متعدد المقاييس,多尺度训练,多尺度训练,多尺度训练,formation multi-échelle,entraînement multi-échelle,entraînement multi-échelle,マルチスケールトレーニング,マルチスケールトレーニング,多尺度学習,многомасштабное обучение,многомасштабное обучение,обучение на нескольких масштабах
2892,multi-task,متعددة المهام,متعدد المهام,متعدد المهام,多任务,多任务 (duō rènwù),多任务,multitâche,multi-tâche,multi-tâche,マルチタスク,マルチタスク,複数タスク,многозадачность,мультизадачность,многозадачный
2893,multi-task fine-tuning,ضبط متعدد المهام,ضبط مهام متعددة,التدريب الدقيق متعدد المهام,多任务微调,多任务微调,多任务微调,réglage fin multi-tâches,affinage multi-tâches,ajustement fin multi-tâche,マルチタスクの微調整,マルチタスクファインチューニング,複数タスク微調整,многозадачная точная настройка,многозадачная настройка fein-tuning,многозадачная доводка
2894,multi-task learning,التعلم متعدد المهام,التعلم المتعدد المهام,التعلم متعدد المهام,多任务学习,多任务学习,多任务学习,apprentissage multi-tâches,apprentissage multitâche,apprentissage multi-tâche,マルチタスク学習,マルチタスク学習 (Multi-Task Learning),多タスク学習,многозадачное обучение,многозадачное обучение,многозадачное обучение
2895,multi-task model,نموذج متعدد المهام,نموذج متعدد المهام,نموذج متعدد المهام,多任务模型,多任务模型,多任务模型,modèle multitâche,modèle multi-tâches,modèle multi-tâche,マルチタスクモデル,マルチタスクモデル,複数タスクモデル,многозадачная модель,модель многозадачности,Многозадачная модель
2896,multi-task regression,الانحدار متعدد المهام,- التعدد الاستدادي,انحدار متعدد المهام,多任务回归,多任务回归,多任务回归,régression multitâche,régression multi-tâches,régression multi-tâche,マルチタスク回帰,マルチタスク回帰,多タスク回帰,многозадачная регрессия,многозадачная регрессия,многозадачная регрессия
2897,multi-task setting,إعداد المهام المتعددة,البيئة متعددة المهام,إعداد متعدد المهام,多任务设置,多任务设置,多任务设置,réglage multi-tâches,contexte multi-tâches,Cadre multi-tâche,マルチタスク設定,マルチタスク設定,複数タスク設定,настройка многозадачности,многозадачная среда,многозадачная настройка
2898,multi-view,عرض متعدد,زاوية متعددة,متعدد الآراء,多视图,多视角,多视图,multi-vue,multi-vue,multi-vue,マルチビュー,マルチビュー,複数の視点,мультипросмотр,многозрительный,многовидовой
2899,multi-view datum,مسند متعدد المشاهدات,المعطيات متعددة الرؤى,بيانات متعددة الآراء,多视图数据,多视角数据,多视图数据,données multi-vues,donnée multi-vue,donnée multi-vues,マルチビューデータム,マルチビューデータ,複数ビューデータ,многовидовая база данных,многозрительный набор данных,многовидовые данные
2900,multi-view geometry,هندسة متعددة العرض,هندسة الرؤية المتعددة,هندسة المشاهد المتعددة,多视角几何,多视图几何,多视几何,géométrie multi-vues,géométrie multi-vue,géométrie multi-vue,マルチビュージオメトリ,マルチビュー幾何学 (maruchi byū kikagaku),多視点幾何学,многовидовая геометрия,многозрительная геометрия,геометрия многих видов
2901,multi-view learning,التعلم متعدد المشاهدات,التعلم من وجهات نظر متعددة,التعلم متعدد المشاهدات,多视角学习,多视角学习,多视图学习,apprentissage multi-vues,apprentissage multi-vue,apprentissage multi-vues,多視点学習,マルチビューラーニング,複数視点学習,многопросмотровое обучение,многовидовое обучение,многовидовое обучение
2902,multi-view stereo,ستيريو متعدد الرؤية,تصوير متعدد الرؤية,نظام التصوير المتعدد المشاهد,多视图立体,多视角立体视觉,多视角立体视觉,stéréo multi-vues,stéréo multi-vues,stéréo multi-vues,マルチビューステレオ,マルチビューステレオ,複数視点ステレオ,многопросмотровое стерео,многопозиционная стереоскопия,стерео с многих видов
2903,multi-view system,نظام متعدد المشاهدة,نظام متعدد المناظر,نظام متعدد المشاهد,多视图系统,多视角系统,多视图系统,système multi-vues,système multi-vues,système multi-vues,マルチビューシステム,マルチビューシステム,多視点システム,многопросмотровая система,многозрительная система,многовидовая система
2904,multiclass classifier,مصنف متعدد الطبقات,مصنف متعدد الفئات,مُصَنِّف متعدد الفئات,多类分类器,多类分类器 (multiclass classifier),多分类分类器,classificateur multiclasse,classificateur multiclasse,classificateur multiclasse,マルチクラス分類子,マルチクラス分類器 (multiclass classifier),多クラス分類器,многоклассовый классификатор,многоклассовый классификатор,многоклассовый классификатор
2905,multiclass hinge loss,فقدان المفصلة متعددة الطبقات,الخسارة المتعددة الفئات بوابة,خسارة الفجوة متعددة الفئات,多类铰链损失,多类别合页损失,多类别铰链损失,perte de charnière multiclasse,perte de charnière multiclasse,perte hinge multiclasse,マルチクラスヒンジ損失,マルチクラスヒンジ損失 (multiclass hinge loss),多クラスヒンジロス,многоклассовая потеря шарнира,многоклассовая функция потерь шарнира,многоклассная штрафная функция промаха
2906,multiclass model,نموذج متعدد الطبقات,نموذج متعدد الفئات,نموذج متعدد الفئات,多类模型,多类模型,多类模型,modèle multiclasse,modèle multiclasse,modèle multiclasse,マルチクラスモデル,マルチクラスモデル (multiclass model),マルチクラスモデル,многоклассовая модель,многоклассовая модель,многоклассовая модель
2907,multiclass object detection,كشف كائن متعدد الفئات,الكشف عن الكائنات متعددة الفئات,الكشف عن كائنات متعددة الفئات,多类目标检测,多类物体检测 (multiclass object detection),多类目标检测,détection d'objets multiclasses,détection d'objets multiclasse,détection d'objets multi-classes,マルチクラスオブジェクト検出,マルチクラス物体検出 (multiclass object detection),マルチクラスオブジェクト検出,обнаружение многоклассовых объектов,обнаружение многоклассовых объектов,многоклассовое обнаружение объектов
2908,multidimensional quality metric,مقياس الجودة متعدد الأبعاد,مقياس جودة متعدد الأبعاد,"مقياس جودة متعدد الأبعاد

MQM",多维质量指标,多维质量度量,"多维质量指标

MQM",métrique de qualité multidimensionnelle,métrique de qualité multidimensionnelle,métrique de qualité multidimensionnelle,多次元の品質指標,多次元品質メトリック,多次元品質指標,многомерный показатель качества,многомерная метрика качества,многомерный показатель качества
2909,multidimensional scaling,التحجيم متعدد الأبعاد,التحجيم متعدد الأبعاد,التدرج متعدد الأبعاد,多维尺度,多维尺度分析,多维尺度分析,Échelle multidimensionnelle,échelle multidimensionnelle,l'analyse des proximités,多次元スケーリング,多次元尺度構成 (Multidimensional Scaling),多次元尺度構成法,многомерное масштабирование,Многомерное шкалирование,многомерное шкалирование
2910,multilingual embedding,التضمين متعدد اللغات,تضمين متعدد اللغات,ترميز متعدد اللغات,多语言嵌入,多语言嵌入,多语种嵌入,intégration multilingue,incorporation multilingue,plongement multilingue,多言語の埋め込み,マルチリンガル・エンベッディング,多言語埋め込み,многоязычное встраивание,мультиязычные вложения,многоязычное встраивание
2911,multilingual language model,نموذج متعدد اللغات,- موديل لغوي متعدد اللغات,نموذج لغة متعدد اللغات,多语言语言模型,多语言语言模型,多语种语言模型,modèle de langage multilingue,modèle de langage multilingue,modèle de langue multilingue,多言語言語モデル,多言語言語モデル,多言語言語モデル,многоязычная языковая модель,многоязычная языковая модель,Многоязычная языковая модель
2912,multilingual model,نموذج متعدد اللغات,نموذج متعدد اللغات,نموذج متعدد اللغات,多语言模型,多语言模型,多语言模型,modèle multilingue,modèle multilingue,modèle multilingue,多言語モデル,多言語モデル,多言語モデル,многоязычная модель,мультиязычная модель,многоязычная модель
2913,multilingual representation,تمثيل متعدد اللغات,التمثيل متعدد اللغات,تمثيل متعدد اللغات,多语言表示,多语言表示,多语言表征,représentation multilingue,représentation multilingue,représentation multilingue,多言語表現,多言語表現,多言語表現,многоязычное представительство,мультиязычное представление,многоязычное представление
2914,multilingual training,تدريب متعدد اللغات,التدريب متعدد اللغات,تدريب متعدد اللغات,多语言培训,多语种训练,多语言训练,formation multilingue,formation multilingue,entraînement multilingue,多言語研修,多言語トレーニング,多言語学習,многоязычное обучение,многоязычное обучение,многоязычное обучение
2915,multilinguality,التعددية اللغوية,- التعددية اللغوية,تعدد اللغات,多语言能力,多语性,多语种性 (multilinguality),multilinguisme,multilinguisme,multilingualité,多言語性,多言語性,多言語性,многоязычие,мультиязычность,многоязычность
2916,multimodal task,مهمة متعددة الوسائط,مهام متعددة الوسائط,مهمة متعددة الأنماط,多模态任务,多模态任务,多模态任务,tâche multimodale,tâche multimodale,tâche multimodale,マルチモーダルタスク,マルチモーダルタスク (Maruchimōdaru tasuku),マルチモーダルタスク,мультимодальная задача,мультимодальная задача,многомодальная задача
2917,multinomial distribution,توزيع متعدد الحدود,التوزيع العديدي,التوزيع المتعدد الحدود,多项分布,多项分布,多项分布,distribution multinomiale,- Distribution multinomiale,distribution multinomiale,多項分布,多項分布,多項分布,полиномиальное распределение,многомерное распределение,многономиальное распределение
2918,multinomial model,نموذج متعدد الحدود,نموذج متعدد القيم,نموذج متعدد الحدود,多项式模型,多项式模型,多项分布模型,modèle multinomial,modèle multinomial,modèle multinomial,多項モデル,多項モデル,多項モデル,полиномиальная модель,мультиномиальная модель,многомерная модель
2919,multiple Choice,متعدد الخيارات,اختيار متعدد,اختيار متعدد,多项选择,多选题,多项选择,choix multiple,Choix multiple,Choix multiple,複数の選択肢,"""['the discontinuous Multiple Choice Grade ; metric choice can be used to induce emergent abilities in a novel domain ( vision ) in diverse architectures and tasks . Caballero et al.']""",複数選択,большой выбор,множественный выбор,Множественный выбор
2920,multiple kernel learning,تعلم نواة متعددة,تعلم النواة المتعددة,تعلم الأنوية المتعددة,多核学习,多核学习,多核学习,apprentissage de plusieurs noyaux,apprentissage de noyaux multiples,apprentissage à noyaux multiples,複数のカーネル学習,複数カーネル学習 (multiple kernel learning),多核学習,множественное обучение ядра,множественное обучение ядер,множественное ядерное обучение
2921,multiple linear regression,الانحدار الخطي المتعدد,"""['تثير ملاءمة نماذج بسيطة مثل التحويل الخطي المتعدد لمجموعات بيانات كبيرة أسئلة بحثية مثيرة. وتشمل هذه الأسئلة الاستعمال والتنبؤ (على سبيل المثال، كيفية",انحدار خطي متعدد,多元线性回归,多元线性回归,多元线性回归,la régression linéaire multiple,régression linéaire multiple,régression linéaire multiple,重線形回帰,多重線形回帰 (たじゅうせんけいかいき),重回帰分析,множественная линейная регрессия,множественная линейная регрессия,множественная линейная регрессия
2922,multiscale modeling,النمذجة متعددة النطاقات,النمذجة متعددة المقاييس,نمذجة متعددة النطاقات,多尺度建模,多尺度建模,多尺度建模,modélisation multi-échelle,modélisation multi-échelle,modélisation multi-échelle,マルチスケールモデリング,マルチスケールモデリング,多重スケールモデリング,многомасштабное моделирование,многошкальное моделирование,моделирование на нескольких масштабах
2923,multiset,multiset,مجموعة متعددة,متعدد المجموعات,多重集合,多重集,多重集,multiensemble,multiset,multi-ensemble,マルチセット,マルチセット,多重集合,мультимножество,мультимножество,мультимножество
2924,multitask training,التدريب على المهام المتعددة,التدريب على المهام المتعددة,تدريب متعدد المهام,多任务训练,多任务训练,多任务训练,formation multitâche,entraînement multitâche,apprentissage multitâche,マルチタスクトレーニング,マルチタスクトレーニング (Multitask Training),複数タスク学習,многозадачное обучение,многозадачное обучение,многозадачное обучение
2925,multivariate,متعدد المتغيرات,متعدد المتغيرات,متعدد المتغيرات,多变量,- 多变量 (duō biànliàng),多元变量,multivarié,multivarié,à variables multiples,多変量,"""['表現学習では、現実世界の観測 x（例：画像や動画）が2段階の生成プロセスによって生成されるとしばしば仮定されています。まず、多変量の潜在ランダム変数 z が分布 P(z) からサンプリングされます。', 'ただし、事前ソース数 d z が大き",多変量,многомерный,многомерный,многомерный
2926,multivariate Gaussian,غاوسي متعدد المتغيرات,- توزيع غوسي متعدد المتغيرات,اعتدالي متعدد المتغيرات,多元高斯,多元高斯,多元高斯,gaussienne multivariée,Gaussienne multivariée,gaussienne multivariée,多変量ガウス,多変量ガウス,多変量ガウス分布,многомерный гауссиан,многомерное Гауссовское,многомерный гауссовский
2927,multivariate gaussian distribution,توزيع غاوسي متعدد المتغيرات,التوزيع الجاوسي متعدد المتغيرات,التوزيع الغاوسي متعدد المتغيرات,多元高斯分布,多变量高斯分布,多元高斯分布,distribution gaussienne multivariée,- Distribution gaussienne multivariée,distribution gaussienne multivariée,多変量ガウス分布,多変量ガウス分布,多変量ガウス分布,многомерное распределение Гаусса,многомерное гауссовское распределение,многомерное нормальное распределение
2928,multivariate normal,متعدد المتغيرات عادي,"""['وعلاوة على ذلك، في هذه الحالة الخاصة، يتقارب الخوارزمية 3 نحو المتوسط الأمامي الدقيق لـ ب لأن الأمامي هو متعدد المتغيرات الطبيعي، وبالتالي المتوسط الأم",توزيع طبيعي متعدد المتغيرات,多元正态分布,多元正态,多元正态分布,multivarié normal,normale multivariée,normale multivariée,多変量正規,多変量正規分布,多変量正規分布,многомерный нормальный,многомерное нормальное,многомерное нормальное распределение
2929,multivariate normal distribution,التوزيع الطبيعي متعدد المتغيرات,التوزيع الطبيعي متعدد المتغيرات,التوزيع الطبيعي المتعدد المتغيرات,多元正态分布,多元正态分布,多元正态分布,distribution normale multivariée,distribution normale multivariée,distribution normale multivariée,多変量正規分布,多変量正規分布,多変量正規分布,многомерное нормальное распределение,многомерное нормальное распределение,многомерное нормальное распределение
2930,multivariate time series,سلسلة زمنية متعددة المتغيرات,سلسلة زمنية متعددة المتغيرات,السلاسل الزمنية متعددة المتغيرات,多元时间序列,多元时间序列,多元时间序列,série chronologique multivariée,série temporelle multivariée,série temporelle multivariée,多変量時系列,多変量時系列,多変量時系列,многомерный временной ряд,многомерный временной ряд,многомерный временной ряд
2931,mutex,كائن المزامنة,مشبك (mutex),مُتَعَدِّدُ الاستبعاد المتبادل,互斥体,- 互斥(mutex),互斥集,mutex,mutex,verrou,ミューテックス,ミューテックス,相互排他ロック,мьютекс,мьютекс,взаимоисключение
2932,mutexe,com.mutexe,ميوتكس (mutex),منافرات,互斥体,互斥(mutexe),互斥量,mutex,mutexes,verrou mutexe,ミューテックス,ミューテックス,相互排他ロック,мьютекс,мьютексы,Мьютекс
2933,mutual Information,المعلومات المتبادلة,المعلومات المتبادلة,المعلومات المتبادلة,相互信息,互信息,互信息,Informations mutuelles,Information Mutuelle,Information mutuelle,相互情報,相互情報量 (そうごじょうほうりょう),相互情報量,взаимная информация,Взаимная информация,Взаимная информация
2934,mutual entropy,الانتروبيا المتبادلة,التفاعل الشائع,تناظر متبادل,互熵,互熵,互信息,entropie mutuelle,- Entropie mutuelle,entropie mutuelle,相互エントロピー,相互エントロピー,相互エントロピー,взаимная энтропия,взаимная энтропия,взаимная энтропия
2935,n-good list,قائمة جيدة,قائمة أفضل n,قائمة أفضل n,n-好清单,n-好列表,n-best列表,n-bonne liste,"""['L'ensemble des phrases considérées est calculé par une version appropriée étendue de l'algorithme de recherche utilisé (Och et al., 1999) calculant une liste approximative des meilleures traductions n. Contrairement à la reconnaissance automatique de la parole, nous n'avons pas une phrase de référence, mais il existe un certain nombre de phrases de référence.', 'Par exemple, même si nous doublons la taille de la liste des meilleurs n à 100, les performances n'aug",liste des n-meilleures hypothèses,良いものリスト,n-ベストリスト,n-best候補リスト,н-хороший список,n-хороший список,список n-лучших
2936,n-gram,ن جرام,n-جرام,N-gram,n-gram,n-gram,N元语法,n-gramme,n-gram,n-gramme,Nグラム,n-gram,n-gramの直訳は「n-gram」,н-грамм,"""[""Мы определяем 'грязный' пример как тот, который имеет любое n-граммное перекрытие с любым обучающим документом, а 'чистый' пример как тот, который не имеет столкновений. Тестовые и валидационные разбивки имели схожие уровни загрязнения, несмотря на то, что некоторые",n-грамма
2937,n-gram feature,ميزة ن جرام,السمة n-gram,ميزة ن-جرام,n 元语法特征,n-gram特征,n-gram特征,fonctionnalité n-gramme,fonction n-gramme,caractéristique n-gramme,Nグラム機能,n-gramフィーチャ,n-gramフィーチャ,функция n-граммы,n-грамм функция,Признак n-граммы
2938,n-gram language model,نموذج لغة n-gram,نموذج لغوي n-جرام,نموذج لغة ن-جرام,n-gram语言模型,n-gram语言模型,n-元语言模型,modèle de langage n-gram,modèle de langage n-gramme,modèle de langage n-gram,N-gram言語モデル,n-gram言語モデル,n-gram言語モデル,n-граммная языковая модель,n-граммная языковая модель,n-грамная языковая модель
2939,n-gram model,نموذج ن جرام,- التحليل النغرامي,نموذج ن-جرام,n-gram模型,n-gram模型,n-gram模型,modèle n-gramme,modèle n-gramme,modèle de n-grammes,Nグラムモデル,n-gramモデル,n-gramモデル,n-граммная модель,n-граммная модель,модель n-грамм
2940,n-step return,العودة ن الخطوة,- تقدير العائد على n خطوات,عوائد n-خطوة,n步返回,n步回报,n步回报,retour en n étapes,rendu n-étapes,retour sur n pas,nステップリターン,nステップリターン,n-ステップリターン,n-шаговый возврат,n-шаговое вознаграждение,n-шаговое вознаграждение
2941,naive Bayes model,نموذج بايز الساذج,نموذج بايز الساذج,نموذج بايز السَّاذج,朴素贝叶斯模型,朴素贝叶斯模型,朴素贝叶斯模型,modèle naïf de Bayes,modèle de Bayes naïf,modèle naïf bayésien,単純ベイズモデル,単純ベイズモデル,単純ベイズモデル,наивная модель Байеса,Модель наивного байеса,наивная байесовская модель
2942,name entity,كيان الاسم,كيانات مسماة,كيان اسم,名称实体,命名实体,命名实体,nom de l'entité,entité nommée,entité nommée,名前エンティティ,固有名詞,固有名詞,имя объекта,именованная сущность,сущность названия
2943,name entity recognition,التعرف على كيان الاسم,التعرف على الكيانات المسماة,استرجاع الكيانات المسماة,名称实体识别,命名实体识别,命名实体识别,reconnaissance d'entité de nom,Reconnaissance d'entités nommées,reconnaissance d'entités nommées,名前エンティティの認識,固有名詞認識,固有表現認識,распознавание сущности имени,распознавание именованных сущностей,распознавание именованных сущностей
2944,name entity recognizer,أداة التعرف على كيان الاسم,معرف الكيانات المسماة,معرف الكيانات المسماة,名称实体识别器,命名实体识别器,命名实体识别器,outil de reconnaissance d'entité de nom,Reconnaissance d'entités nommées,reconnaisseur d'entités nommées,名前エンティティ認識装置,固有名詞認識器 (name entity recognizer),固有名詞認識器,Распознаватель именованных объектов,распознавание именованных сущностей,распознаватель именованных сущностей
2945,natural image statistic,إحصائيات الصور الطبيعية,الإحصاءات الطبيعية للصورة,إحصائيات الصورة الطبيعية,自然图像统计,自然图像统计,自然图像统计,statistiques d'images naturelles,statistique d'image naturelle,statistiques d'images naturelles,自然画像の統計,自然画像統計,自然画像統計,статистика естественных изображений,естественная статистика изображений,статистика натуральных изображений
2946,natural language,لغة طبيعية,اللغة الطبيعية,لغة طبيعية,自然语言,自然语言,自然语言,langage naturel,langue naturelle,langage naturel,自然言語,自然言語,自然言語,естественный язык,естественный язык,естественный язык
2947,natural language generation,توليد اللغة الطبيعية,توليد اللغة الطبيعية,توليد اللغة الطبيعية,自然语言生成,自然语言生成 (Natural Language Generation),自然语言生成,génération de langage naturel,génération de langage naturel,génération de langue naturelle,自然言語の生成,自然言語生成 (しぜんげんごせいせい),自然言語生成,генерация естественного языка,генерация естественного языка,генерация естественного языка
2948,natural language inference,استنتاج اللغة الطبيعية,الاستدلال اللغوي الطبيعي,استنتاج اللغة الطبيعية,自然语言推理,自然语言推理,自然语言推理,inférence en langage naturel,inférence de langage naturel,inférence sur le langage naturel,自然言語推論,自然言語推論 (Natural Language Inference),自然言語推論,вывод на естественном языке,естественное языковое умозаключение,вывод на естественном языке
2949,natural language processing,معالجة اللغة الطبيعية,معالجة اللغة الطبيعية,معالجة اللغة الطبيعية,自然语言处理,自然语言处理,自然语言处理,traitement du langage naturel,traitement automatique du langage naturel,traitement du langage naturel,自然言語処理,自然言語処理 (しぜんげんごしょり),自然言語処理,обработка естественного языка,обработка естественного языка,Обработка естественного языка
2950,natural language query,استعلام اللغة الطبيعية,الاستعلام باللغة الطبيعية,استعلام لغة طبيعية,自然语言查询,自然语言查询,自然语言查询,requête en langage naturel,requête en langage naturel,requête en langage naturel,自然言語クエリ,自然言語クエリ,自然言語クエリ,запрос на естественном языке,естественный языковой запрос,естественно-языковой запрос
2951,natural language understanding,فهم اللغة الطبيعية,فهم اللغة الطبيعية,فهم اللغة الطبيعية,自然语言理解,自然语言理解,自然语言理解,compréhension du langage naturel,compréhension du langage naturel,compréhension du langage naturel,自然言語理解,自然言語理解,自然言語理解,понимание естественного языка,естественное понимание языка,понимание естественного языка
2952,natural logic,المنطق الطبيعي,المنطق الطبيعي,المنطق الطبيعي,自然逻辑,自然逻辑,自然逻辑,logique naturelle,logique naturelle,logique naturelle,自然な論理,自然論理 (shizen ronri),自然論理,естественная логика,естественная логика,естественная логика
2953,natural logic inference,الاستدلال المنطقي الطبيعي,الاستدلال المنطقي الطبيعي,استنتاج المنطق الطبيعي,自然逻辑推理,自然逻辑推理,自然逻辑推理,inférence de logique naturelle,inférence logique naturelle,inférence logique naturelle,自然論理推論,自然論理推論 (shizen ronri suiron),自然論理推論,естественный логический вывод,естественное логическое выводление,вывод естественной логики
2954,natural parameter,المعلمة الطبيعية,المعلمة الطبيعية,ضابط طبيعي,自然参数,自然参数,自然参数,paramètre naturel,paramètre naturel,paramètre naturel,自然パラメータ,自然パラメータ,自然母数,натуральный параметр,естественный параметр,естественный параметр
2955,natural question,سؤال طبيعي,أسئلة طبيعية,سؤال طبيعي,自然问题,自然问题,自然问题,question naturelle,question naturelle,question naturelle,当然の疑問,自然言語質問 (Natural Questions),自然な質問,естественный вопрос,естественный вопрос,естественный вопрос
2956,naïve Bayes,ساذج بايز,"""يتضمن نماذج التصنيف شبكات عصبية عميقة مثل RoBERTa (Guo et al. ، 2023) ، أو خوارزميات أكثر تقليدية مثل الانحدار اللوجستي ، وآلات الدعم الناعمة ، والبيز الساذج ،",بايز البسيط,朴素贝叶斯,朴素贝叶斯,朴素贝叶斯,Bayes naïf,Bayes naïf,bayésien naïf,ナイーブ・ベイズ,素朴ベイズ,ナイーブベイズ,наивный Байес,наивный Байес,наивный байесовский классификатор
2957,near-optimality,شبه الأمثل,- التقرب من الأمثلية,قرب المثالية,接近最优,接近最优,近似最优性,quasi-optimalité,quasi-optimalité,Quasi-optimalité,最適に近い,近最適性,近最適性,почти оптимальность,близкое оптимальное решение,близость к оптимальности
2958,nearest neighbor classifier,أقرب مصنف الجيران,المصنف الأقرب جارًا,مُصنِّف أقرب جار,最近邻分类器,最近邻分类器,最近邻分类器,classificateur du voisin le plus proche,Classifieur de plus proche voisin,classificateur des plus proches voisins,最近傍分類子,最近傍分類器 (nearest neighbor classifier),最近傍分類器,классификатор ближайшего соседа,классификатор ближайшего соседа,ближайший соседний классификатор
2959,nearest neighbor search,أقرب بحث الجيران,البحث عن أقرب جار,البحث عن أقرب جار,最近邻搜索,最近邻搜索,最近邻搜索,recherche du voisin le plus proche,recherche du voisin le plus proche,recherche du plus proche voisin,最近傍検索,最近傍探索 (kin'in hōsaku),最近傍探索,поиск ближайшего соседа,поиск ближайшего соседа,ближайший поиск соседа
2960,nearest-neighbor algorithm,خوارزمية الجار الأقرب,- التحليل الخوارزمي لأقرب الجيران,خوارزمية الجار الأقرب,最近邻算法,最近邻算法,近邻算法,algorithme du plus proche voisin,- Algorithme du plus proche voisin,algorithme des plus proches voisins,最近傍アルゴリズム,最近傍アルゴリズム (saikinbou arugorizumu),最近隣アルゴリズム,алгоритм ближайшего соседа,алгоритм ближайшего соседа,алгоритм ближайшего соседа
2961,negation,النفي,النفي,نفي,否定,否定,否定,négation,négation,négation,否定,否定 (ひてい),否定,отрицание,отрицание,отрицание
2962,negative log-likelihood,احتمال السجل السلبي,سالب سجل الاحتمالية,سالب اللوغاريتم الأرجحي,负对数似然,负对数似然,负对数似然,log-vraisemblance négative,log-vraisemblance négative,vraisemblance négative,負の対数尤度,負の対数尤度,負の対数尤度,отрицательное логарифмическое правдоподобие,Отрицательная логарифмическая функция правдоподобия,отрицательная логарифмическая правдоподобность
2963,negative pair,زوج سلبي,أزواج سلبية,زوج سلبي,负对,负对,负样本对,paire négative,paire négative,paire négative,マイナスペア,ネガティブペア,負の組,отрицательная пара,негативная пара,отрицательные пары
2964,negative sample,عينة سلبية,عينة سلبية,عينات سلبية,负样本,负样本 (fù yàng běn),负样本,échantillon négatif,échantillon négatif,échantillon négatif,ネガティブサンプル,ネガティブサンプル,負例,отрицательный образец,отрицательная выборка,отрицательный образец
2965,negative transfer,نقل سلبي,- التحويل السلبي,نقل سلبي,负迁移,负迁移,负面迁移,transfert négatif,transfert négatif,transfert négatif,負の転送,ネガティブ転送,負の転移,отрицательный трансфер,негативный перенос,негативный перенос
2966,neighborhood function,وظيفة الجوار,وظيفة الجوار,دالة الجوار,邻域函数,邻域函数,邻域函数,fonction de quartier,- Fonction de voisinage,fonction de voisinage,近隣関数,近傍関数 (きんぼうかんすう),近傍関数,функция соседства,функция окрестности,функция окрестности
2967,neighborhood system,نظام الحي,نظام الجوار,نظام الجيرة,邻里系统,邻域系统,邻域系统,système de quartier,système de voisinage,système de voisinage,近隣システム,- 近傍システム (きんぼうシステム),近傍システム,система соседства,система соседства,система окрестностей
2968,net,شبكة,الشبكة,شبكة,网,网络 (wǎngluò),神经网络,filet,réseau,réseau,ネット,ネット,ネット,сеть,сеть,сеть
2969,network,شبكة,شبكة,شبكة,网络,网络,网络,réseau,- Réseau,réseau,通信網,ネットワーク,ネットワーク,сеть,- Сеть,сеть
2970,network architecture,هندسة الشبكات,بنية الشبكة,معمارية الشبكة,网络架构,网络架构,网络架构,Architecture de réseau,architecture du réseau,architecture réseau,ネットワークアーキテクチャ,ネットワークアーキテクチャ,ネットワークアーキテクチャ,сетевая архитектура,- Сетевая архитектура,архитектура сети
2971,network feature,ميزة الشبكة,ميزة الشبكة,ميزة الشبكة,网络功能,网络特征,网络特征,fonctionnalité réseau,- Caractéristique du réseau,caractéristique de réseau,ネットワーク機能,ネットワーク特徴,ネットワーク特徴量,сетевая функция,сетевая особенность,Сетевая особенность
2972,network parameter,معلمة الشبكة,معلمات الشبكة,معامل الشبكة,网络参数,网络参数,网络参数,paramètre réseau,paramètre de réseau,paramètre réseau,ネットワークパラメータ,ネットワークパラメータ,ネットワークパラメータ,параметр сети,параметры сети,сетевой параметр
2973,network structure,هيكل الشبكة,هيكل الشبكة,بنية الشبكة,网络结构,网络结构,网络结构,structure du réseau,- Structure du réseau,structure du réseau,ネットワーク構造,ネットワーク構造,ネットワーク構造,сетевая структура,структура сети,структура сети
2974,network topology,طوبولوجيا الشبكة,التوبولوجيا الشبكية,شبكة طوبولوجيا,网络拓扑结构,网络拓扑结构,网络拓扑结构,topologie du réseau,topologie du réseau,topologie de réseau,ネットワークトポロジー,ネットワークトポロジー,ネットワークトポロジー,топология сети,- Сетевая топология,сетевая топология
2975,network weight,وزن الشبكة,وزن الشبكة,وزن الشبكة,网络权重,网络权重,网络权重,poids du réseau,poids du réseau,poids du réseau,ネットワークの重み,ネットワークの重み,ネットワーク重み,вес сети,веса сети,сетевой вес
2976,neural activity,النشاط العصبي,النشاط العصبي,نشاط عصبي,神经活动,神经活动,神经活动,activité neuronale,- Activité neuronale,activité neuronale,神経活動,神経活動 (しんけいかつどう),神経活動,нейронная активность,нейронная активность,нервная активность
2977,neural approach,النهج العصبي,النهج العصبي,نهج عصبي,神经方法,神经方法,神经网络方法,approche neuronale,Approche neurale,approche neuronale,神経的アプローチ,ニューラルアプローチ (neural approach),神経アプローチ,нейронный подход,нейронный подход,нейронный подход
2978,neural architecture,العمارة العصبية,الهندسة العصبية,البنية العصبية,神经结构,神经架构,神经网络架构,architecture neuronale,architecture neuronale,architecture neuronale,ニューラルアーキテクチャ,ニューラルアーキテクチャ,ニューラルアーキテクチャ,нейронная архитектура,нейронная архитектура,нейронная архитектура
2979,neural architecture search,بحث عن العمارة العصبية,بحث هندسة الشبكات العصبية,البحث عن البنية العصبية,神经架构搜索,神经架构搜索,神经架构搜索,recherche d'architecture neuronale,Recherche d'architecture neuronale,Recherche d'architecture neuronale,ニューラルアーキテクチャの検索,ニューラルアーキテクチャサーチ (Neural Architecture Search),ニューラルアーキテクチャ探索,поиск нейронной архитектуры,поиск нейронной архитектуры,поиск нейронной архитектуры
2980,neural embedding,التضمين العصبي,تضمين عصبي,تضمين عصبي,神经嵌入,神经嵌入,神经嵌入,intégration neuronale,incorporation neuronale,projection neuronale,ニューラル埋め込み,ニューラル埋め込み,神経埋め込み,нейронное встраивание,нейронная вложенность,нейронное встраивание
2981,neural generation model,نموذج الجيل العصبي,نموذج توليد عصبي,نموذج توليد عصبي,神经生成模型,神经生成模型,神经生成模型,modèle de génération neuronale,- Modèle de génération neuronale,modèle de génération neuronale,神経生成モデル,ニューラル生成モデル (nyu-ralu seisei moderu),神経世代モデル,модель нейронного поколения,модель генерации нейронов,модель нейронной генерации
2982,neural implicit representation,التمثيل الضمني العصبي,التمثيل الضمني العصبي,نمذجة عصبية ضمنية,神经隐式表征,神经隐式表示,神经隐式表示,représentation neuronale implicite,représentation implicite neuronale,représentation implicite neuronale,ニューラル暗黙的表現,ニューラル暗黙的表現,神経内在表現,нейронное неявное представление,нейронное неявное представление,Нейронное неявное представление
2983,neural language model,نموذج اللغة العصبية,نموذج لغوي عصبي,نموذج لغوي عصبي,神经语言模型,神经语言模型,神经语言模型,modèle de langage neuronal,- Modèle de langage neuronal,modèle neuronal de langage,神経言語モデル,ニューラル言語モデル,ニューラル言語モデル,модель нейронного языка,нейронная языковая модель,нейросетевая языковая модель
2984,neural machine translation,الترجمة الآلية العصبية,ترجمة آلية عصبية,الترجمة الآلية العصبية,神经机器翻译,神经机器翻译,神经机器翻译,traduction automatique neuronale,traduction neuronale automatique,traduction neuronale,ニューラル機械翻訳,ニューラル機械翻訳 (Neural Machine Translation),神経機械翻訳,нейронный машинный перевод,нейронный машинный перевод,нейронный машинный перевод
2985,neural machinery,الآلات العصبية,آليات عصبية,الآلية العصبية,神经机器,神经机制,神经网络机器,machinerie neuronale,machinerie neuronale,machinerie neuronale,神経機械,ニューラル機構,神経機構,нейронная машина,нейронная аппаратура,нейронная техника
2986,neural mapping,رسم الخرائط العصبية,التصوير العصبي,خرائط عصبية,神经映射,神经映射,神经映射,cartographie neuronale,cartographie neuronale,cartographie neuronale,ニューラルマッピング,ニューラルマッピング,神経マッピング,нейронное картирование,нейронное отображение,нейронное отображение
2987,neural method,الطريقة العصبية,طرق عصبية,طريقة عصبونية,神经法,神经方法,神经网络方法,méthode neuronale,méthode neuronale,méthode neuronale,ニューラルメソッド,ニューラルメソッド,ニューラル手法,нейронный метод,нейросетевые методы,нейронный метод
2988,neural model,النموذج العصبي,النموذج العصبي,نموذج عصبي,神经模型,神经模型,神经模型,modèle neuronal,- Modèle neuronal,modèle neuronal,神経モデル,ニューラルモデル,ニューラルモデル,нейронная модель,нейронная модель,нейронная модель
2989,neural module,الوحدة العصبية,وحدة عصبية,شبكات الوحدات العصبية,神经模块,神经模块 (neural module),神经模块,module neuronal,module neuronal,module neuronal,ニューラルモジュール,ニューラルモジュール,神経モジュール,нейронный модуль,нейронный модуль,Нейронный модуль
2990,neural net,الشبكة العصبية,الشبكة العصبية,شبكة عصبية,神经网络,神经网络,神经网络,réseau neuronal,réseau neuronal,réseau de neurones,ニューラルネット,ニューラルネット,ニューラルネット,нейронная сеть,нейронная сеть,нейронная сеть
2991,neural network architecture,بنية الشبكات العصبية,بنية الشبكة العصبونية,معمارية الشبكة العصبية,神经网络架构,神经网络架构,神经网络架构,architecture de réseau neuronal,- Architecture du réseau neuronal,architecture de réseau de neurones,ニューラルネットワークアーキテクチャ,ニューラルネットワークアーキテクチャ,神経ネットワーク アーキテクチャ,архитектура нейронной сети,архитектура нейронной сети,нейросетевая архитектура
2992,neural network classifier,مصنف الشبكة العصبية,مصنف الشبكة العصبية,صنف الشبكة العصبية,神经网络分类器,神经网络分类器,神经网络分类器,classificateur de réseau neuronal,classificateur de réseau neuronal,classifieur de réseau neuronal,ニューラルネットワーク分類器,ニューラルネットワーク分類器,ニューラルネットワークの分類器,классификатор нейронной сети,нейронная сеть классификатор,классификатор нейронной сети
2993,neural network language model,نموذج لغة الشبكة العصبية,نموذج اللغة لشبكة الأعصاب,نموذج لغة الشبكة العصبية,神经网络语言模型,神经网络语言模型 (neural network language model),神经网络语言模型,modèle de langage de réseau neuronal,- Modèle de langue de réseau de neurones,modèle de langage de réseau de neurones,ニューラルネットワーク言語モデル,ニューラルネットワーク言語モデル,神経網言語モデル,языковая модель нейронной сети,нейронная сеть языковой модели,нейросетевая языковая модель
2994,neural network layer,طبقة الشبكة العصبية,طبقة الشبكة العصبية,شبكة عصبية طبقة,神经网络层,神经网络层,神经网络层,couche de réseau neuronal,- Couche de réseau neuronal,couche de réseau de neurones,ニューラルネットワーク層,ニューラルネットワーク層,ニューラルネットワーク層,слой нейронной сети,слои нейронных сетей,слой нейронной сети
2995,neural network model,نموذج الشبكة العصبية,نموذج الشبكة العصبية,نموذج الشبكة العصبية,神经网络模型,神经网络模型,神经网络模型,modèle de réseau neuronal,modèle de réseau neuronal,modèle de réseau neuronal,ニューラルネットワークモデル,ニューラルネットワークモデル,神経ネットワークモデル,модель нейронной сети,модель нейронной сети,модель нейронной сети
2996,neural operator,المشغل العصبي,العامل العصبي,متعدد البوابات العصبي,神经算子,神经算子,神经算子,opérateur neuronal,- Opérateur neuronal,opérateur neuronal,神経演算子,ニューラルオペレータ,ニューラル演算子,нейронный оператор,нейронный оператор,нейронный оператор
2997,neural parser,المحلل العصبي,محلل عصبي,محلل عصبي,神经解析器,神经分析器,神经网络语法分析器,analyseur neuronal,analyseur neural,analyseur neuronal,ニューラルパーサー,神経パーサー,神経パーサー,нейронный парсер,нейронный парсер,нейронный парсер
2998,neural radiance field,مجال الإشعاع العصبي,حقل إشعاع العصبية,حقل الإشعاع العصبي,神经辐射场,神经辐射场,神经辐射场,champ de rayonnement neuronal,champ de radiance neuronale,champ de radiance neuronale,神経放射フィールド,ニューラル輝度場,神経放射輝度場,нейронное поле излучения,нейронное поле радиации,нейронное поле излучения
2999,neural renderer,العارض العصبي,محاكي عصبي,محرر عصبي,神经渲染器,神经渲染器,神经渲染器,moteur de rendu neuronal,rendu neuronal,Rendu neuronal,ニューラルレンダラー,ニューラルレンダラー (neural renderer),神経レンダラー,нейронный рендерер,нейронный рендерер,нейронный рендерер
3000,neural rendering,التجسيد العصبي,التقديم العصبي,تصوير عصبي,神经渲染,神经渲染 (neural rendering),神经渲染,rendu neuronal,rendu neuronal,rendu neuronal,ニューラルレンダリング,ニューラルレンダリング,ニューラルレンダリング,нейронный рендеринг,нейронный рендеринг,нейросетевая визуализация
3001,neural representation,التمثيل العصبي,التمثيل العصبي,التمثيل العصبي,神经表征,神经表示,神经表征,représentation neuronale,représentation neuronale,représentation neuronale,神経表現,ニューラル表現 (nyu-raru hyougen),ニューラル表現,нейронное представление,нейронное представление,нейронное представление
3002,neural retrieval,الاسترجاع العصبي,استرجاع عصبي,استرجاع عصبي,神经检索,神经检索,神经检索,récupération neuronale,récupération neuronale,récupération neuronale,神経検索,ニューラル検索,神経検索,нейронное извлечение,нейронный поиск,нейронный поиск
3003,neural scaling law,قانون القياس العصبي,قانون مقياس الشبكة العصبية,قانون تحجيم الشبكات العصبية,神经标度定律,神经缩放定律,神经缩放定律,loi d'échelle neuronale,loi d'échelle neuronale,loi d'échelle neuronale,ニューラルスケーリングの法則,ニューラルスケーリング法則,ニューラルスケーリング則,нейронный закон масштабирования,законы масштабирования нейронов,закон масштабирования нейронных сетей
3004,neural scene representation,تمثيل المشهد العصبي,التمثيل العصبي للمشهد,تمثيل مشهد عصبي,神经场景表示,神经场景表示,神经场景表示,représentation de la scène neuronale,représentation de scène neuronale,représentation neuronale de scène,ニューラルシーン表現,ニューラルシーン表現,神経場面表現,представление нейронной сцены,нейронное представление сцены,нейронное представление сцены
3005,neural sequence model,نموذج التسلسل العصبي,نموذج تسلسل عصبي,نموذج التسلسل العصبي,神经序列模型,神经序列模型,神经序列模型,modèle de séquence neuronale,modèle de séquence neuronale,modèle de séquence neuronale,神経配列モデル,ニューラルシーケンスモデル,神経系列モデル,модель нейронной последовательности,нейронная последовательностная модель,нейросетевая последовательностная модель
3006,neural text generation,توليد النص العصبي,تكوين النصوص العصبية,توليد النص العصبي,神经文本生成,神经文本生成,神经文本生成,génération de texte neuronal,génération de texte neuronale,génération de texte neuronale,ニューラルテキスト生成,ニューラルテキスト生成 (neural text generation),神経テキスト生成,нейронная генерация текста,генерация текста с использованием нейронных сетей,генерация текста нейросетями
3007,neural volume,الحجم العصبي,حجم عصبي,حجم عصبي,神经体积,神经体积 (Neural Volume),"神经体积

NV

NV+WCE",volume neuronal,volume neural,volume neuronal,神経ボリューム,ニューラルボリューム,ニューラルボリューム,нейронный объем,нейронный объем,нейронный объем
3008,neural volumetric representation,التمثيل الحجمي العصبي,التمثيل الحجمي العصبي,تمثيل عصبي حجمي,神经体积表征,神经体积表示,神经体积表示,représentation volumétrique neuronale,représentation volumétrique neuronale,représentation volumétrique neuronale,神経体積表現,ニューラルボリューメトリック表現,神経体積表現,нейронное объемное представление,нейронное объемное представление,нейронное объемное представление
3009,neural word embedding,تضمين الكلمات العصبية,تضمين كلمات عصبية,انغراس كلمات عصبية,神经词嵌入,神经词嵌入,神经词嵌入,intégration de mots neuronaux,incorporation de mots neuronaux,plongement de mots neuronaux,ニューラルワード埋め込み,ニューラルワード埋め込み,単語の神経埋め込み,нейронное встраивание слов,нейронные векторные представления слов,нейронные словарные вложения
3010,neuro-symbolic system,النظام الرمزي العصبي,نظام عصبي رمزي,نظام عصبي رمزي,神经符号系统,神经符号系统,神经符号系统,système neuro-symbolique,système neuro-symbolique,système neuro-symbolique,神経象徴システム,ニューロシンボリックシステム,神経記号システム,нервно-символическая система,нейросимволическая система,Нейросимволическая система
3011,neuron,الخلايا العصبية,خلية عصبية,خلية عصبية,神经元,神经元,神经元,neurone,neurone,neurone,ニューロン,ニューロン,ニューロン,нейрон,нейрон,нейрон
3012,next sentence prediction,التنبؤ الجملة التالية,التنبؤ بالجملة القادمة,تنبؤ الجملة التالية,下一句话预测,下一句预测 (next sentence prediction),下一句预测,prédiction de la phrase suivante,prédiction de la phrase suivante,prédiction de la phrase suivante,次の文の予測,次の文予測 (next sentence prediction),次の文予測,предсказание следующего предложения,предсказание следующего предложения,предсказание следующего предложения
3013,next token prediction,التنبؤ بالرمز التالي,التنبؤ بالرمز التالي,التنبؤ بالكلمة التالية,下一个令牌预测,下一个标记预测,下一个标记预测,prochaine prédiction de jeton,prédiction du jeton suivant,prédiction du prochain jeton,次のトークンの予測,次のトークン予測,次のトークン予測,следующий прогноз токена,прогнозирование следующего токена,следующее предсказание токена
3014,nmod,nmod,nmod,تبعية اسمية,纳米莫德,nmod,nmod的翻译是名词性修饰语,nmod,nmod,complément nominal,nmod,nmod,名詞修飾成分,нмод,nmod,nmod (no translation provided since it's an abbreviation)
3015,no-regret algorithm,خوارزمية لا تندم,خوارزمية بدون ندم,خوارزمية بدون ندم,无悔算法,无悔算法 (no-regret algorithm),无后悔算法,algorithme sans regret,algorithme sans regret,algorithme sans regret,後悔しないアルゴリズム,後悔のないアルゴリズム (no-regret algorithm),後悔のないアルゴリズム,беспроигрышный алгоритм,алгоритм без сожалений,алгоритм без сожалений
3016,no-regret dynamic,ديناميكية لا تندم,- تطورات بدون ندم,ديناميكية بدون ندم,无悔动态,无悔动态,无后悔动态,dynamique sans regret,dynamique sans regret,dynamique sans regret,後悔しないダイナミック,ノーリグレット・ダイナミクス,後悔のない動的,беспроигрышная динамика,динамика без сожалений,динамика без сожалений
3017,no-regret learning algorithm,خوارزمية التعلم بلا ندم,خوارزمية تعلم بدون ندم,خوارزمية التعلم بدون ندم,无悔学习算法,无悔学习算法 (no-regret learning algorithm),无悔学习算法,algorithme d'apprentissage sans regret,algorithme d'apprentissage sans regret,algorithme d'apprentissage sans regret,後悔のない学習アルゴリズム,後悔なし学習アルゴリズム (no-regret learning algorithm),後悔なし学習アルゴリズム,алгоритм обучения без сожалений,алгоритм обучения без сожаления,алгоритм обучения без сожалений
3018,node,العقدة,عقدة,عقدة,节点,节点,节点,nœud,nœud,nœud,ノード,ノード,ノード,узел,узел,узел
3019,node attribute,سمة العقدة,سمة العقدة,- صفة العقدة,节点属性,节点属性,节点属性,attribut de nœud,attribut de nœud,attribut de nœud,ノード属性,ノード属性,ノード属性,атрибут узла,атрибут узла,узел атрибут
3020,node classification,تصنيف العقدة,تصنيف العقدة,تصنيف العقدة,节点分类,节点分类,节点分类,classification des nœuds,Classification de nœuds,classification des nœuds,ノードの分類,ノード分類 (Nodo Bunrui),ノード分類,классификация узлов,классификация узлов,классификация узлов
3021,node degree,درجة العقدة,درجة العقدة,درجة العقدة,节点度,节点度,节点度数,degré de nœud,degré du nœud,degré des nœuds,ノード次数,ノード次数,ノード次数,степень узла,степень узла,узел степени
3022,node embedding,تضمين العقدة,تضمين العقدة,تضمين العقدة,节点嵌入,节点嵌入,节点嵌入,intégration de nœuds,incorporation de noeuds,plongement de nœuds,ノードの埋め込み,ノード埋め込み,ノード埋め込み,встраивание узла,вложение узла,векторное представление узла
3023,node feature,ميزة العقدة,سمة العقدة,ميزة العقدة,节点特征,节点特征,节点特征,fonctionnalité de nœud,caractéristique du nœud,caractéristique de noeud,ノード機能,ノード特徴,ノード特徴,особенность узла,признак узла,признак узла
3024,node feature matrix,مصفوفة ميزات العقدة,مصفوفة ميزة العقدة,مصفوفة سمات العقدة,节点特征矩阵,节点特征矩阵,节点特征矩阵,matrice des caractéristiques du nœud,- Matrice des caractéristiques des nœuds,matrice de caractéristiques des nœuds,ノード特徴マトリックス,ノード特徴行列,ノード特徴行列,матрица признаков узла,матрица признаков узлов,матрица признаков узлов
3025,node label,تسمية العقدة,تسمية العقدة,نُقطة البيان,节点标签,节点标签 (node label),节点标签,étiquette de nœud,étiquette de nœud,nœud étiquette,ノードラベル,ノードラベル,ノードラベル,метка узла,метка узла,узел метка
3026,node representation,تمثيل العقدة,تمثيل العقدة,تمثيل العقدة,节点表示,节点表示,节点表示,représentation des nœuds,représentation du nœud,représentation des nœuds,ノード表現,ノード表現,ノード表現,представление узла,представление узла,узловое представление
3027,node set,مجموعة العقدة,مجموعة العقدة,مجموعة العقد,节点集,节点集,节点集合,ensemble de nœuds,ensemble de nœuds,ensemble de nœuds,ノードセット,ノードセット,ノード集合,набор узлов,набор узлов,множество узлов
3028,node-disjoint path,مسار العقدة المنفصلة,مسارات متفرعة من العقد,مسار مُنفصل العُقد,节点不相交路径,节点不相交路径,无公共节点路径,chemin nœud-disjoint,chemin de noeud-disjoint,chemin sans nœud commun,ノードに共通でないパス,ノード非連結パス,ノード非共有パス,"путь, не пересекающийся с узлами",узлово-раздельный путь,узел-несмежный путь
3029,noise distribution,توزيع الضوضاء,توزيع الضوضاء,توزيع الضوضاء,噪声分布,噪声分布,噪声分布,répartition du bruit,- Distribution de bruit,distribution de bruit,ノイズ分布,ノイズ分布,ノイズ分布,распределение шума,шумовое распределение,распределение шума
3030,noise level,مستوى الضوضاء,مستوى الضجيج,مستوى الضجيج,噪音水平,噪音水平,噪声水平,niveau de bruit,niveau de bruit,niveau de bruit,騒音レベル,ノイズレベル,ノイズレベル,уровень шума,уровень шума,уровень шума
3031,noise model,نموذج الضوضاء,نموذج الضوضاء,نموذج الضوضاء,噪声模型,噪音模型,噪声模型,modèle de bruit,modèle de bruit,modèle de bruit,ノイズモデル,ノイズモデル,ノイズモデル,шумовая модель,модель шума,модель шума
3032,noise schedule,جدول الضوضاء,جدول الضوضاء,جدول الضوضاء,噪音表,噪音时间表,噪声时间表,horaire de bruit,programme de bruit,calendrier de bruit,騒音スケジュール,ノイズスケジュール (Noizu Sukedjuru),ノイズスケジュール,график шума,расписание шума,расписание шума
3033,noise-contrastive estimation,تقدير الضوضاء المتناقضة,تقدير التباين الضجيجي,"تقدير التباين الضوضائي

NCE",噪声对比估计,噪声对比估计,"噪声对比估计

NCE",estimation contrastée du bruit,estimation contrastive du bruit,estimation contrastive de bruit,ノイズ対比推定,ノイズ対比推定 (noise-contrastive estimation),"ノイズ対比推定

NCE",шумоконтрастная оценка,Шумо-контрастная оценка (NCE),оценка контрастирующего шума
3034,noisy channel,قناة صاخبة,قناة ذات ضجيج,قناة ضوضائية,嘈杂的通道,噪声信道,有噪音信道,canal bruyant,canal bruyant,canal bruité,ノイズの多いチャンネル,ノイジー・チャンネル,雑音チャネル,шумный канал,шумовой канал,шумный канал
3035,nominal mention,ذكر اسمي,ذكر مسمى,ذِكْر اسْمِي,名义提及,名义提及,名词性提及,mention nominale,- Mention nominale,mention nominale,名目上の言及,"""名詞の言及と固有名詞の言及に重みを付けた総合得点でエンティティをランク付けします。もしエンティティが名詞や代名詞の言及しかない場合、その重要度スコアを下げて、名前の言及がある他のエンティティよりも下位にランク付けされます。各文",名詞句言及,номинальное упоминание,именное упоминание,именная группа
3036,non-convex objective,هدف غير محدب,الهدف غير المحدب,هدف غير محدب,非凸目标,非凸目标,非凸目标函数,objectif non convexe,objectif non-convexe,objectif non convexe,非凸目的,非凸目的,非凸目的関数,невыпуклая цель,невыпуклая цель,невыпуклая целевая функция
3037,non-convex optimization,الأمثل غير محدب,تحسين غير محدب,"تحسين غير محدب

NCO",非凸优化,非凸优化 (non-convex optimization),非凸优化,optimisation non convexe,optimisation non convexe,"optimisation non convexe

NCO",非凸最適化,非凸最適化 (non-convex optimization),非凸最適化,невыпуклая оптимизация,неконвексная оптимизация,оптимизация невыпуклых функций
3038,non-convex problem,مشكلة غير محدبة,مشكلة غير محدبة,مشكلة غير محدبة,非凸问题,非凸问题,非凸问题,problème non convexe,problème non-convexe,problème non convexe,非凸問題,非凸問題 (ひきょくもんだい),非凸問題,невыпуклая задача,неконвексная задача,неравновесная проблема
3039,non-convexity,عدم التحدب,- التعرجية غير المقوسة,عدم التقعر,非凸性,非凸性,非凸性,non-convexité,non-convexité,non-convexité,非凸性,非凸性,非凸性,невыпуклость,невыпуклость,Невыпуклость
3040,non-euclidean space,الفضاء غير الإقليدي,المساحة غير الأقليدية,فضاء لا إقليدي,非欧空间,非欧几里得空间,非欧几里得空间,espace non euclidien,- Espace non-euclidien,espace non euclidien,非ユークリッド空間,非ユークリッド空間,非ユークリッド空間,неевклидово пространство,нееуклидово пространство,неевклидово пространство
3041,non-linear least square,المربعات الصغرى غير الخطية,- تقريب الأقليات غير الخطية,المربعات الصغرى غير الخطية,非线性最小二乘法,非线性最小二乘算法,非线性最小二乘,moindre carré non linéaire,moindres carrés non linéaires,moindres carrés non linéaires,非線形最小二乗,非線形最小二乗法 (non-linear least squares),非線形最小二乗法,нелинейный метод наименьших квадратов,нелинейный метод наименьших квадратов,неlинейные наименьшие квадраты
3042,non-linear optimization,التحسين غير الخطي,التحسين غير الخطي,تحسين غير خطي,非线性优化,非线性优化,非线性优化,optimisation non linéaire,optimisation non linéaire,optimisation non linéaire,非線形最適化,非線形最適化 (hisenkei saitekika),非線形最適化,нелинейная оптимизация,нелинейная оптимизация,нелинейная оптимизация
3043,non-linearity,غير الخطية,غير خطية,عدم خطية,非线性,非线性,非线性,non-linéarité,non-linéarité,non-linéarité,非線形性,非線形性,非線形性,нелинейность,нелинейность,нелинейность
3044,non-local feature,ميزة غير محلية,السمة غير المحلية,ميزة غير محلية,非局部特征,非局部特征,非局部特征,fonctionnalité non locale,caractéristique non-locale,caractéristique non locale,非ローカル機能,非局所特徴,非局所的な特徴,нелокальный объект,нелокальная особенность,неместные признаки
3045,non-markov process,عملية غير ماركوف,عملية غير ماركوفية,عملية غير ماركوفية,非马尔可夫过程,非马尔可夫过程,非马尔可夫过程,processus non markovien,processus non-markovien,processus non markovien,非マルコフ過程,非マルコフ過程,非マルコフ過程,немарковский процесс,немарковский процесс,немарковский процесс
3046,non-max suppression,قمع غير الحد الأقصى,- تثبيط غير قصوى,عدم القصوى القمع,非极大值抑制,非极大值抑制,非最大值抑制,suppression non maximale,"""['Plutôt que de recourir à un post-traitement pour nettoyer les détections, notre modèle apprend des paramètres de suppression de non-max optimaux et des seuils de détection pour chaque classe. Le système résultant surpasse les résultats publiés sur l'ensemble de données de détection d'objets PAS-CAL VOC 2007.', 'Pour garantir une comparaison équitable, toutes les expériences utilisent les mêmes caractéristiques d'entrée et dét",suppression des non-maximums,非最大抑制,非最大抑制,非最大抑制,немаксимальное подавление,не-максимальное подавление,нахождение максимумов
3047,non-maxima suppression,قمع غير الحد الأقصى,قمع القيم الغير قصوى,كبت القيم غير القصوى,非极大值抑制,非极大值抑制,非极大值抑制,suppression non maximale,suppression des non-maxima,suppression des non-maxima,非最大抑制,非最大値抑制,非最大値抑制,немаксимальное подавление,снижение не максимума,подавление немаксимумов
3048,non-maximal suppression,قمع غير الحد الأقصى,القمع غير القصوى,ازالة الحدود غير القصوى,非极大值抑制,非极大值抑制 (non-maximal suppression),非极大值抑制,suppression non maximale,suppression non maximale,suppression non-maximale,非最大抑制,"""['エッジ検出の精度は、3つの標準的な指標を使用して評価されます：固定された輪郭閾値（ODS）、画像ごとの最適閾値（OIS）、および平均精度（AP）。私たちはエッジマップに標準的な非最大値抑制技",非最大抑制,немаксимальное подавление,немаксимальное подавление,Невычитающее подавление
3049,non-maximum suppression,قمع غير الحد الأقصى,القمع غير الأقصى,تثبيط غير الأقصى,非极大值抑制,非极大值抑制,非极大值抑制,suppression non maximale,suppression du non-maximum,suppression des non-maximaux,非最大抑制,非最大抑制 (NMS),非最大抑制,немаксимальное подавление,подавление немаксимумов,Неопределенное подавление
3050,non-negative matrix factorization,تحليل المصفوفة غير السالبة,عاملة المصفوفة غير السالبة,تجزئة المصفوفة غير السالبة,非负矩阵分解,非负矩阵分解 (non-negative matrix factorization),非负矩阵分解,factorisation matricielle non négative,factorisation de matrice non-négative,factorisation de matrice non négative,非負行列因数分解,非負値行列因子分解 (NMF),非負値行列因子分解,неотрицательная матричная факторизация,неположительное матричное разложение,неотрицательное матричное разложение
3051,non-parametric setting,الإعداد غير المعلمي,- تحديد الإعداد غير القياسي,إعداد لا معلمي,非参数设置,非参数设置,非参数设置,réglage non paramétrique,cadre non paramétrique,réglages non paramétriques,ノンパラメトリック設定,非パラメトリック設定,非パラメトリック設定,непараметрическая настройка,непараметрические настройки,непараметрическая установка
3052,non-projective parsing,التحليل غير الإسقاطي,- تحليل غير مشروعة,التحليل غير الإسقاطي,非投影解析,非投射解析,非投射句法分析,analyse non projective,analyse non projective,analyse non-projective,非射影解析,非射影構文解析 (ひしゃえいこうぶんかいせき),非射影構文解析,непроективный синтаксический анализ,непроективный синтаксический анализ,непроективный синтаксический анализ
3053,non-submodular energy,الطاقة غير النموذجية,طاقة غير قابلة للتحديد الفرعي,طاقة غير متحت الأقسام,非子模能量,非次模能量,非子模能量,énergie non-submodulaire,énergie non-sous-modulaire,énergie non sous-modulaire,非サブモジュール型エネルギー,非劣加法エネルギー,非サブモジュラー・エネルギー,несубмодульная энергия,несубмодулярная энергия,неподмодульная энергия
3054,non-tree model,نموذج غير شجرة,نموذج غير شجري,نموذج غير شجري,非树模型,非树模型,非树模型,modèle non arborescent,modèle non-arborescent,modèle non-arborescent,非ツリーモデル,非木構造モデル,非木構造モデル,недревесная модель,модель без дерева,Нетревьевая модель
3055,nonconvex function,وظيفة غير محدبة,وظيفة غير محدبة,دالة غير محدبة,非凸函数,非凸函数,非凸函数,fonction non convexe,fonction non convexe,fonction non convexe,非凸関数,非凸関数 (ひきょくかんすう),非凸関数,невыпуклая функция,невыпуклая функция,нелинейная функция
3056,nonlinear optimisation,التحسين غير الخطي,التحسين غير الخطي,تحسين غير خطي,非线性优化,非线性优化 (nonlinear optimisation),非线性优化,optimisation non linéaire,- Optimization non linéaire,optimisation non linéaire,非線形最適化,非線形最適化 (Hissenkei Saitekika),非線形最適化,нелинейная оптимизация,нелинейная оптимизация,нелинейная оптимизация
3057,nonmonotonic reasoning,المنطق غير الرتيب,الاستدلال غير الزاحف,الاستدلال غير التصاعدي,非单调推理,非单调推理,非单调推理,raisonnement non monotone,raisonnement non monotone,raisonnement non monotone,非単調な推論,非単調推論,非単調推論,немонотонное рассуждение,немонотонное рассуждение,нечеткое рассуждение
3058,nonterminal symbol,رمز غير طرفي,الرمز غير المحدد,رمز غير طرفي,非终结符,非终结符,非终结符号,symbole non terminal,symbole non terminal,symbole non terminal,非終端記号,非終端記号,非終端記号,нетерминальный символ,нетерминальный символ,нетерминальный символ
3059,norm,معيار,المعيار,معيار,规范,范数,范数,norme,norme,norme,標準,ノルム,ノルム,норма,норма,норма
3060,normal,طبيعي,- تصحيح,مُعتاد,普通的,法线 (normal),法向量,normale,normale,normales,普通,"""['Figure 7 visualizes point cloud, normal, and final surface reconstruction for one of the objects, an electrical kettle with rough-specular reflectance. We observe that our reconstruction procedure produces a point cloud that closely matches the shape of the object, including accurate normals on its front surface.', 'Notice that although there are only two rigid motions, the scene contains three different homographies, each one associated with each one of the visible planar structures. Furthermore, notice that the top side of the cube and the checkerboard have approximately the same normals.', 'We render the Ne",法線,нормальный,нормаль,нормали
3061,normal distribution,التوزيع الطبيعي,التوزيع الطبيعي,توزيع طبيعي,正态分布,正态分布,正态分布,distribution normale,distribution normale,distribution normale,正規分布,正規分布 (せいきぶんぷ),正規分布,нормальное распределение,нормальное распределение,нормального распределения
3062,normal form,الشكل العادي,الشكل العادي,الصيغة العادية,正常形式,正规形式,标准形式,forme normale,forme normale,forme normale,通常形,正規形 (seikikei),正規形,нормальная форма,нормальная форма,нормальная форма
3063,normal vector,ناقلات الطبيعي,المُتَجَه الطبيعي,المتجه العمودي,法向量,法线向量,法向量,vecteur normal,vecteur normal,vecteur normal,法線ベクトル,法線ベクトル,法線ベクトル,нормальный вектор,нормальный вектор,нормальный вектор
3064,normal-form game,لعبة ذات شكل عادي,لعبة الشكل الطبيعي,لعبة شكل عادي,正规形式博弈,标准形式博弈,正常型博弈,jeu de forme normale,jeu en forme normale,jeu sous forme normale,正規形のゲーム,標準形ゲーム (hyōjunkei gēmu),正規形ゲーム,игра в нормальной форме,нормально-формальная игра,игра в нормальной форме
3065,normalisation,تطبيع,- التطبيع,تطبيع,正常化,归一化,归一化,normalisation,normalisation,normalisation,正規化,正規化 (seikika),正規化,нормализация,нормализация,нормализация
3066,normalization,تطبيع,التطبيع,ترجيز,正常化,标准化,归一化,normalisation,normalisation,normalisation,正規化,正規化 (seikika),正規化,нормализация,нормализация,нормализация
3067,normalization constant,ثابت التطبيع,الثابتة التطبيعية,ثابت التّرميز,归一化常数,规范化常数 (normalization constant),归一化常量,constante de normalisation,constante de normalisation,constante de normalisation,正規化定数,正規化定数,正規化定数,константа нормализации,нормализующая константа,нормализационная константа
3068,normalization factor,عامل التطبيع,عامل التطبيع,عامل التطبيع,归一化因子,标准化因子 (normalization factor),归一化因子,facteur de normalisation,facteur de normalisation,facteur de normalisation,正規化係数,正規化因子 (seikika inshi),正規化係数,коэффициент нормализации,коэффициент нормализации,нормализационный фактор
3069,normalization function,وظيفة التطبيع,"= 1 Z(d) exp i λ i,c F i,c (d, c) , \n حيث Z(d) هي وظيفة التطبيع.', 'حيث θ هي معلمات وظي",وظيفة التطبيع,归一化函数,归一化函数,归一化函数,fonction de normalisation,fonction de normalisation,fonction de normalisation,正規化関数,正規化関数,正規化関数,функция нормализации,функция нормализации,нормализующая функция
3070,normalization layer,طبقة التطبيع,طبقة التطبيع,طبقة التحييد,归一化层,规范化层,归一化层,couche de normalisation,couche de normalisation,couche de normalisation,正規化層,正規化層,正規化層,слой нормализации,нормализационный слой,слой нормализации
3071,normalization method,طريقة التطبيع,طريقة التطبيع,طريقة التقنين,归一化法,规范化方法 (Normalization method),标准化方法,méthode de normalisation,méthode de normalisation,méthode de normalisation,正規化方法,正規化方法 (seikika houhou),正規化手法,метод нормализации,метод нормализации,метод нормализации
3072,normalization strategy,استراتيجية التطبيع,استراتيجية التطبيع,إستراتيجية التطبيع,正常化策略,归一化策略,归一化策略,stratégie de normalisation,stratégie de normalisation,stratégie de normalisation,正規化戦略,正規化戦略 (seikika senryaku),正規化戦略,стратегия нормализации,стратегия нормализации,стратегия нормализации
3073,normalize,تطبيع,تطبيع,تقنين,正常化,标准化,标准化,normaliser,normaliser,normaliser,ノーマライズ,正規化 (seikika),正規化する,нормализовать,нормализовать,нормализовать
3074,normalize cross correlation,تطبيع الارتباط المتبادل,التقاطع المعياري الموحّد,تحييد الارتباط المتقاطع,标准化互相关,归一化交叉相关 (normalized cross correlation),归一化互相关,normaliser la corrélation croisée,corrélation croisée normalisée,corrélation croisée normalisée,相互相関を正規化する,正規化相互相関 (Seikika sōgo sōkan),正規化相互相関,нормализовать взаимную корреляцию,нормализованная кросс-корреляция,нормализованная взаимная корреляция
3075,normalize cut,تطبيع قطع,القص الطبيعي,قِطْعَةٌ مُعَيَّرَة,标准化切割,规范化切分,归一化切割,normaliser la coupe,découpe normalisée,coupe normalisée,カットを正規化する,正規化カット (seikika katto),正規化カット,нормализовать разрез,нормализованный разрез,нормализованный разрез
3076,normalize cut algorithm,تطبيع خوارزمية القطع,- تسوية خوارزمية القطع الموحد.,الخوارزمية القطعية المعيارية,归一化切割算法,标准化切割算法,正常化切割算法,normaliser l'algorithme de coupe,algorithme de découpe normalisée,algorithme de coupure normalisée,正規化カットアルゴリズム,正規化カットアルゴリズム (seikika katto arugorizumu),正規化カット アルゴリズム,нормализовать алгоритм резки,алгоритм нормализованного разреза,алгоритм нормализованного разреза
3077,normalize edit distance,مسافة التحرير الطبيعية,مسافة التحرير المعيارية,تطبيع مسافة التعديل,标准化编辑距离,规范化编辑距离,标准化编辑距离,distance d'édition normalisée,- Distance d'édition normalisée,distance d'édition normalisée,正規化された編集距離,正規化編集距離 (seikika henshū kyori),編集距離の正規化,нормализованное расстояние редактирования,нормализованное редактирование расстояния,нормализованное редакционное расстояние
3078,normalize factor,عامل التطبيع,عامل التوحيد,عامل التطبيع,归一化因子,归一化因子,归一化因子,facteur de normalisation,facteur de normalisation,facteur de normalisation,正規化係数,正規化因子 (seikika inshi),正規化係数,нормализующий коэффициент,нормализующий фактор,нормализующий фактор
3079,normalize flow,تطبيع التدفق,تدفق تقييم الإنتروبيا الموحد,تعميم التدفق,标准化流程,归一化流,归一化流,normaliser le flux,flux de normalisation,Normalisation de flux,流れを正規化する,正規化フロー (seikika furō),正規化フロー,нормализовать поток,нормализующий поток (НП),нормализующий поток
3080,noun phrase,إسم العبارة,عبارة الاسم,عبارة اسمية,名词短语,名词短语 (Noun Phrase),名词短语,phrase nominale,syntagme nominal,groupe nominal,名詞句,名詞句,名詞句,словосочетание,существительная фраза,именная группа
3081,novel view synthesis,توليف عرض رواية,تخليق رؤية جديدة,توليد منظر جديد,新颖的视图合成,新视图合成,新视图合成,nouvelle synthèse de vues,synthèse de vue nouvelle,synthèse de nouvelles vues,斬新な視点の合成,新しい視点合成,新規ビュー合成,синтез новых взглядов,синтез нового вида,синтез новых видов
3082,nsubj,nsubj,nsubj,فاعل,恩苏吉,主语,主语,nsubj,"⟨ → , nsubj⟩.', 'L'évitement déclaré de l'UD de toute référence à l'AAD est mis en œuvre de manière",Sujet grammatical,nsubj,nsubj,主語,nsubj,подлежащее,подлежащее
3083,nsubjpass,nsubjpass,nsubjpass,نفعول به باسيف,主题密码,主动主语,被动主语,nsubjpass,nsubjpass,Complément d'objet passif,nsubjpass,受身主語,受動主語,nsubjpass,подлежащее в страдательном залоге,дополнениепассив
3084,nuclear norm,القاعدة النووية,الطبيعي النووي,معيار النواة,核规范,核范数,核范数,norme nucléaire,norme nucléaire,norme nucléaire,核の規範,核ノルム,ヌクレアノルム,ядерная норма,ядерная норма,ядерная норма
3085,nuclear norm relaxation,استرخاء القواعد النووية,الاسترخاء بالقيمة النووية,معيار النواة المرن,核规范松弛,核范数放松,核范数松弛,assouplissement de la norme nucléaire,relaxation de la norme nucléaire,relaxation de la norme nucléaire,核規範緩和,核ノルム緩和 (kaku norumu kanwa),核ノルム緩和,релаксация ядерной нормы,релаксация ядерной нормы,ядерная нормная релаксация
3086,nucleus sampling,أخذ العينات النووية,عينة نواة,عيِّنة النواة,细胞核取样,核取样,核采样,échantillonnage du noyau,échantillonnage de noyau,échantillonnage du noyau,核サンプリング,核サンプリング,核サンプリング,отбор проб ядра,сэмплирование ядра,выборка ядра
3087,null distribution,التوزيع الفارغ,التوزيع الفارغ,التوزيع الصفري,零分布,零分布,零分布,distribution nulle,distribution nulle,distribution nulle,ヌル分布,ヌル分布,ゼロ分布,нулевое распределение,нулевое распределение,нулевое распределение
3088,null space,مساحة فارغة,المساحة الفارغة,الفضاء المعدوم,零空间,空间nullptr,空间,espace nul,espace nul,noyau,ヌルスペース,ヌル空間,ゼロ空間,нулевое пространство,нулевое пространство,пространство нулей
3089,numerical linear algebra,الجبر الخطي العددي,جبر خطي عددي,نظرية الحسابات الخطية الرقمية,数值线性代数,数值线性代数,数值线性代数,algèbre linéaire numérique,algèbre linéaire numérique,algèbre linéaire numérique,数値線形代数,数値線形代数学,数値線形代数,числовая линейная алгебра,численная линейная алгебра,численная линейная алгебра
3090,object bounding box,مربع محيط الكائن,صندوق تحديد الكائنات,مربع تحديد الكائن,物体边界框,目标边界框,物体边界框,cadre de délimitation d'un objet,boîte de délimitation d'objet,boîte englobante d'objet,オブジェクト境界ボックス,オブジェクト境界ボックス,オブジェクトの境界ボックス,ограничивающая рамка объекта,область ограничивающего прямоугольника,рамка объекта
3091,object categorization,تصنيف الكائنات,تصنيف الكائنات,تصنيف الأجسام,对象分类,目标分类,目标分类,catégorisation d'objets,Catégorisation d'objets,catégorisation d'objets,オブジェクトの分類,オブジェクトのカテゴリー分類 (object categorization),オブジェクト分類,категоризация объектов,категоризация объектов,категоризация объектов
3092,object category,فئة الكائن,فئة الكائنات,فئة الكائن,对象类别,物体类别,对象类别,catégorie d'objet,catégorie d'objet,catégorie d'objet,オブジェクトカテゴリ,オブジェクトカテゴリ,オブジェクトカテゴリ,категория объекта,категория объектов,категория объектов
3093,object category recognition,التعرف على فئة الكائن,تعرف الفئة الكائنية,التعرف على فئة الكائن,物体类别识别,物体类别识别,物体类别识别,reconnaissance de catégorie d'objet,Reconnaissance de catégorie d'objet,reconnaissance de catégories d'objets,オブジェクトカテゴリの認識,物体カテゴリ認識,物体カテゴリ認識,распознавание категорий объектов,распознавание категорий объектов,распознавание категории объектов
3094,object class,فئة الكائن,فئة الكائنات,فئة الكائن,对象类,对象类,目标类别,classe d'objet,classe d'objet,classe d'objet,オブジェクトクラス,オブジェクトクラス,オブジェクトクラス,класс объекта,класс объектов,класс объектов
3095,object classification,تصنيف الكائنات,تصنيف الكائنات,تصنيف الكائنات,对象分类,物体分类,目标分类,classement des objets,classification d'objets,classification d'objets,オブジェクトの分類,オブジェクト分類 (object classification),オブジェクト分類,классификация объектов,классификация объектов,классификация объектов
3096,object detection,كشف الكائن,كشف الأجسام,الكشف عن الكائنات,物体检测,目标检测,目标检测,détection d'objet,détection d'objets,détection d'objets,物体検出,物体検出,物体検出,обнаружение объектов,обнаружение объектов,обнаружение объектов
3097,object detector,كاشف الكائن,مكتشف الكائنات,كاشف الكائن,物体探测器,目标检测器 (Object Detector),物体检测器,détecteur d'objet,détecteur d'objets,détecteur d'objets,物体検出器,オブジェクト検出器 (obujekuto kenshutsuki),オブジェクト検出器,детектор объектов,детектор объектов,детектор объектов
3098,object domain,مجال الكائن,نطاق الكائنات,نطاق الكائنات,对象域,对象域,对象域,domaine d'objet,- Domaine d'objet,domaine d'objets,オブジェクトドメイン,オブジェクト領域 (object domain),オブジェクト領域,объектная область,область объектов,Предметная область
3099,object embedding,تضمين الكائن,تضمين الكائنات,تضمين الكائن,对象嵌入,物体嵌入,物体嵌入,incorporation d'objet,incorporation d'objet,Intégration d'objet,オブジェクトの埋め込み,オブジェクト埋め込み,オブジェクト埋め込み,встраивание объектов,вектор вложения объекта,объектное встраивание
3100,object instance segmentation,تجزئة مثيل الكائن,تقسيم مثيلات الكائنات,تقطيع الكائن المفرد,对象实例分割,目标实例分割,目标实例分割,segmentation des instances d'objet,segmentation d'instance d'objet,segmentation d'instances d'objets,オブジェクトインスタンスのセグメンテーション,オブジェクトインスタンスセグメンテーション,オブジェクトインスタンスセグメンテーション,сегментация экземпляра объекта,сегментация экземпляров объекта,сегментация экземпляров объектов
3101,object localization,توطين الكائن,تحديد الكائنات,تحديد مكان الكائن,物体定位,目标定位,物体定位,localisation d'objets,localisation d'objet,localisation d'objets,オブジェクトのローカリゼーション,オブジェクトの位置特定 (Obujekuto no ichi tokutei),オブジェクトの局在化 (objekuto no kyokusokuoka),локализация объекта,локализация объекта,Локализация объектов
3102,object model,نموذج الكائن,نموذج الكائنات,نموذج الكائن,对象模型,物体模型,对象模型,modèle objet,modèle d'objet,modèle d'objet,オブジェクトモデル,オブジェクトモデル (obujekuto moderu),オブジェクトモデル,объектная модель,модель объекта,модель объекта
3103,object proposal,اقتراح الكائن,اقتراح الكائنات,حَرح الكائن,对象提案,目标提案,对象建议,proposition d'objet,proposition d'objet,proposition d'objet,オブジェクトの提案,オブジェクト提案 (Obujekuto teian),オブジェクト提案 (obujekuto teian),объектное предложение,предложение объекта,предложение объекта
3104,object recognition,التعرف على الأشياء,التعرف على الكائنات,تمييز الأشياء,物体识别,物体识别,物体识别,reconnaissance d'objets,reconnaissance d'objet,reconnaissance d'objets,物体認識,オブジェクト認識 (obujekuto ninshiki),物体認識,распознавание объектов,распознавание объектов,объектное распознавание
3105,object segmentation,تجزئة الكائن,تقسيم الكائنات,تقطيع الكائن,对象分割,目标分割,目标分割,segmentation d'objet,segmentation d'objet,segmentation d'objets,オブジェクトのセグメンテーション,物体セグメンテーション,オブジェクトセグメンテーション,сегментация объектов,сегментация объектов,сегментация объектов
3106,object tracking,تتبع الكائن,تتبع الكائنات,تتبع الكائن,物体追踪,目标追踪,目标跟踪,suivi d'objet,suivi d'objet,suivi d'objet,オブジェクト追跡,オブジェクトトラッキング,物体追跡,отслеживание объектов,отслеживание объектов,отслеживание объектов
3107,objective function,دالة الهدف,دالة الهدف,وظيفة الهدف,目标函数,目标函数,目标函数,fonction objectif,fonction objectif,fonction objective,目的関数,目的関数 (mokuteki kansu),目的関数,целевая функция,объективная функция,целевая функция
3108,objective value,القيمة الموضوعية,قيمة الموضوعية,قيمة الهدف,客观价值,客观值,目标值,valeur objective,- Valeur objectif,valeur objectif,客観的な価値,目的関数値 (mokuteki kansuuchii),目的関数値,объективная ценность,целевое значение,целевое значение
3109,objectness,الموضوعية,موضوعية,علامة الواقعية,客观性,对象性,目标性,objectivité,objectivité,indice d'objet,客観性,オブジェクトネス,オブジェクトネス,объектность,объектность,объектность
3110,observation function,وظيفة المراقبة,وظيفة المراقبة,دالة المراقبة,观察功能,观测函数,观测函数,fonction d'observation,fonction d'observation,fonction d'observation,観測機能,観測関数 (Kansoku Kansu),観測関数,функция наблюдения,функция наблюдения,функция наблюдения
3111,observation model,نموذج المراقبة,نموذج الملاحظة,نموذج المراقبة,观察模型,观测模型 (Guāncè móxíng),观测模型,modèle d'observation,modèle d'observation,modèle d'observation,観測モデル,観測モデル (Kansoku Moderu),観測モデル,модель наблюдения,модель наблюдения,модель наблюдения
3112,observation space,مساحة المراقبة,مساحة الملاحظة,فضاء المراقبة,观察空间,观测空间,观测空间,espace d'observation,espace d'observation,espace d'observation,観察スペース,観測空間,観測空間,пространство наблюдения,пространство наблюдений,пространство наблюдений
3113,observational datum,مسند الرصد,بيانات مشاهدية,بيانات مُلاحَظة,观测数据,观测数据,观测数据,données d'observation,donnée observationnelle,donnée observationnelle,観測データ,観察データ,観測データ (kansoku dēta),данные наблюдений,наблюдательные данные,данные наблюдений
3114,occlusion handling,معالجة الانسداد,معالجة التظليل,معالجة الاحتجاب,遮挡处理,遮挡处理,遮挡处理,gestion des occlusions,gestion de l'occlusion,gestion des occultations,オクルージョン処理,オクルージョンハンドリング,遮蔽処理,обработка окклюзии,обработка заслонения,обработка окклюзий
3115,occlusion reasoning,منطق الانسداد,التفكير في الإغلاق,استنتاج الإخفاء,遮挡推理,遮挡推理,遮挡推理,raisonnement d'occlusion,Raisonnement sur l'occlusion,raisonnement sur les occultations,オクルージョン推論,遮蔽推論,遮蔽推論,рассуждения об окклюзии,рассуждение об окклюзии,рассуждение об окклюзии
3116,occupancy grid,شبكة الإشغال,شبكة الاحتلال,شبكة الإشغال,占用网格,占据栅格,占用栅格,grille d'occupation,grille d'occupation,grille d'occupation,占有グリッド,占有グリッド,占有グリッド,сетка занятости,сетка занятости,сетка занятости
3117,occupancy map,خريطة الإشغال,- تصوير احتلالية,نقشة الاحتلال,占用地图,占用地图,占用率图,carte d'occupation,carte d'occupation,carte d'occupation,占有マップ,占有マップ,占有マップ,карта занятости,карта занятости,карта занятости
3118,occupancy measure,قياس الإشغال,قياس الاحتلال,مقياس الإشغال,占用率测量,占用度量,占用度量,mesure d'occupation,mesure d'occupation,mesure d'occupation,占有率測定,占有尺度（occupancy measure）,占有度,мера занятости,мера занятости,мера занятости
3119,odometry,قياس المسافات,المسافة المقطوعة,طرق قياس المسافة المقطوعة,里程计,里程计,里程计,odométrie,odometrie,odométrie,オドメトリ,オドメトリ (Odometori),オドメトリ,одометрия,Одометрия,одометрия
3120,off-diagonal element,عنصر خارج قطري,العنصر خارج القطرية,عنصر خارج القطر الرئيسي,非对角元素,非对角元素,非对角线元素,élément hors diagonale,élément hors diagonale,Élément hors-diagonale,非対角要素,オフ・ダイアゴナル要素,対角外成分,недиагональный элемент,внедиагональный элемент,Внедиагональный элемент
3121,off-policy,خارج السياسة,يمكننا تعيين q(x,خارج السياسة,政策外,离线策略 (off-policy),非策略,hors politique,hors politique,hors-politique,ポリシー外,オフポリシー,オフポリシー,вне политики,вне политики,off-policy - внеполитическая
3122,offline algorithm,خوارزمية غير متصلة بالإنترنت,خوارزمية غير متصلة,خوارزمية لاخطية,离线算法,离线算法 (offline algorithm),离线算法,algorithme hors ligne,algorithme hors ligne,algorithme hors ligne,オフラインアルゴリズム,- オフラインアルゴリズム (offline algorithm),オフラインアルゴリズム,автономный алгоритм,алгоритм в автономном режиме,алгоритм оффлайн
3123,offline learning,التعلم دون اتصال بالإنترنت,التعلم خارج الاتصال,التعلم غير المتصل,线下学习,离线学习,离线学习,apprentissage hors ligne,apprentissage hors ligne,apprentissage hors ligne,オフライン学習,オフライン学習 (offline learning),オフラインラーニング,оффлайн обучение,обучение в оффлайн-режиме,обучение в автономном режиме
3124,on-policy,على السياسة,- تصليح السياسة,السياسة الحالية,在政策,在政策上,同策略,sur la politique,sur-politique,sur-politique,ポリシーに従って,オンポリシー,オンポリシー,политика,на политике,на политике
3125,one-against-all reduction,تخفيض واحد ضد الجميع,التقليص من واحد ضد الجميع,تقليل واحد ضد الجميع,一对一减少,一对所有减少,一对全减,réduction un contre tous,réduction un-contre-tous,réduction un-contre-tous,一対全員の削減,一対すべての削減 (one-against-all reduction),1対残り変換,сокращение один против всех,один-против-всех уменьшение,один-против-всех сведение
3126,one-hot encode,ترميز واحد ساخن,ترميز واحد-ساخن,ترميز الاحادي,独热编码,单热编码,一热编码,encodage à chaud,encodage one-hot,encoder à chaud unique,ワンホットエンコード,ワンホットエンコード (one-hot encode),ワンホットエンコーディング,горячее кодирование,однозначно кодирован,одно-горячее кодирование
3127,one-hot representation,تمثيل واحد ساخن,التمثيل الساخن الوحيد,واحد-الساخن التمثيل,独热表示法,一热表示,一次热编码,représentation unique,représentation one-hot,représentation one-hot,ワンホット表現,ワンホット表現,one-hotベクトル表現,горячее представление,одномерное представление,одно-горячее представление
3128,one-hot vector,ناقل واحد ساخن,- التصور الفردي,متجه ثنائي الحالة,单一热向量,一热向量,一热向量,vecteur chaud,vecteur one-hot,vecteur one-hot,ワンホットベクトル,ワンホットベクトル,ワンホットベクトル,горячий вектор,one-hot вектор,один горячий вектор
3129,one-shot learning,التعلم بضربة واحدة,تعلم بنمط الفحص الواحد,التعلم من مثال واحد,一次性学习,一次性学习,一次性学习,apprentissage ponctuel,apprentissage en un coup,apprentissage à partir d'un seul exemple,ワンショット学習,ワンショット学習,一回学習,однократное обучение,однократное обучение,одноразовое обучение
3130,one-shot setting,إعداد طلقة واحدة,- تكوين لقطة واحدة,إعداد نموذج واحد,一次性设置,一次性设置,单次设置,réglage unique,configuration en un seul coup,réglage à un coup,ワンショット設定,ワンショット設定,単回設定,однократная настройка,однократная настройка,одноразовый сеттинг
3131,one-stage detector,كاشف مرحلة واحدة,مكتشف مرحلة واحدة,كاشف مرحلة واحدة,一级探测器,一阶段检测器,单阶段检测器,détecteur à un étage,détecteur à un seul étage,détecteur en une étape,1段検出器,ワンステージ検出器 (ワンステージディテクター),ワンステージ検出器,одноступенчатый детектор,одноступенчатый детектор,однофазный детектор
3132,one-versus-all,واحد مقابل الجميع,واحد ضد الجميع,واحد-ضد-الجميع,一对一,一对所有 (One-versus-all),一对余,un contre tous,un-contre-tous,un-contre-tous,一対全員,一対全,一対残り,один против всех,один-против-всех,один против всех
3133,online algorithm,خوارزمية على الانترنت,خوارزمية على الإنترنت,خوارزمية عبر الإنترنت,在线算法,在线算法,在线算法,algorithme en ligne,algorithme en ligne,algorithme en ligne,オンラインアルゴリズム,オンラインアルゴリズム (onrain arugorizumu),オンラインアルゴリズム,онлайн-алгоритм,онлайн-алгоритм,алгоритм онлайн
3134,online convex optimization,تحسين محدب عبر الإنترنت,- التحسين التكاملي عبر الإنترنت,التحسين المحدب عبر الإنترنت,在线凸优化,在线凸优化,在线凸优化,optimisation convexe en ligne,- Optimization convexe en ligne,optimisation convexe en ligne,オンライン凸最適化,オンライン凸最適化,オンラインコンベックス最適化,онлайн-выпуклая оптимизация,онлайн выпуклая оптимизация,онлайн-выпуклая оптимизация
3135,online gradient descent,نزول التدرج على الانترنت,الانحدار الشامل عبر الإنترنت,تدرج التدرج عبر الإنترنت,在线梯度下降,在线梯度下降,在线梯度下降,descente de pente en ligne,descente de gradient en ligne,descente de gradient en ligne,オンライン勾配降下法,オンライン勾配降下 (Online gradient descent),オンライングラディエント降下法,онлайн градиентный спуск,онлайн градиентный спуск,онлайн-градиентный спуск
3136,online learning,تعليم على الانترنت,التعلم عبر الإنترنت,تَعَلُّم مُبَاشِر,在线学习,在线学习,在线学习,apprentissage en ligne,apprentissage en ligne,apprentissage en ligne,オンライン学習,オンライン学習 (onrain gakushū),オンライン学習,онлайн обучение,онлайн-обучение,онлайн-обучение
3137,online learning algorithm,خوارزمية التعلم عبر الإنترنت,خوارزمية التعلم عبر الإنترنت,خوارزمية التعلم عبر الإنترنت,在线学习算法,在线学习算法 (Online Learning Algorithm),在线学习算法,algorithme d'apprentissage en ligne,algorithme d'apprentissage en ligne,algorithme d'apprentissage en ligne,オンライン学習アルゴリズム,オンライン学習アルゴリズム,オンラインラーニングアルゴリズム,алгоритм онлайн-обучения,алгоритм обучения в реальном времени,онлайн-алгоритм обучения
3138,online learning method,طريقة التعلم عبر الإنترنت,طريقة التعلم عبر الإنترنت,طريقة التعلم عبر الإنترنت,在线学习方法,在线学习方法,在线学习方法,méthode d'apprentissage en ligne,- Méthode d'apprentissage en ligne,méthode d'apprentissage en ligne,オンライン学習法,オンライン学習手法,オンラインラーニング手法,метод онлайн-обучения,метод онлайн-обучения,онлайн-метод обучения
3139,online learning theory,نظرية التعلم عبر الإنترنت,نظرية التعلم عبر الإنترنت,نظرية التعلم عبر الإنترنت,在线学习理论,在线学习理论 (Online Learning Theory),在线学习理论,théorie de l'apprentissage en ligne,théorie de l'apprentissage en ligne,théorie de l'apprentissage en ligne,オンライン学習理論,オンライン学習理論 (Onrain gakushū riron),オンラインラーニング理論,теория онлайн-обучения,теория онлайн-обучения,теория онлайн-обучения
3140,ontology,علم الوجود,الأونتولوجيا,تصنيف,本体论,本体论,本体论,ontologie,ontologie,ontologie,オントロジー,オントロジー,存在論,онтология,онтология,онтология
3141,ontology language,لغة الأنطولوجيا,لغة الأونتولوجيا,ﻟﻐﺔ ﺍﻟﺄﻧﻄﻮﻟﻮﺟﻴﺎ,本体语言,本体语言 (ontology language),本体语言,langage d'ontologie,langage d'ontologie,langage d'ontologie,オントロジー言語,オントロジー言語 (Ontorogi gengo),オントロジー言語,язык онтологий,язык онтологии,онтологический язык
3142,ontology-mediate query,الاستعلام الأنطولوجي الوسيط,استعلامات ميدانية أونتولوجية,استعلامات وساطة الأنطولوجيا,本体中介查询,本体中介查询 (ontology-mediated query),本体论调解查询,requête intermédiaire d'ontologie,requête médiée par ontologie,Requête à médiation ontologique,オントロジー仲介クエリ,オントロジー中心クエリ (OMQ),オントロジー媒介クエリ,"запрос, опосредованный онтологией",онтология-ориентированный запрос,онтологически-опосредованный запрос
3143,open information extraction,فتح استخراج المعلومات,استخراج المعلومات المفتوحة,استخراج المعلومات المفتوحة,开放信息提取,开放信息提取,开放信息抽取,extraction d'informations ouverte,extraction ouverte d'informations,extraction d'informations ouverte,オープンな情報抽出,オープン情報抽出,オープン情報抽出,открытое извлечение информации,открытое извлечение информации,открытое извлечение информации
3144,open set,مجموعة مفتوحة,- تجمع مفتوح,مجموعة مفتوحة,开集,开放集,开集,ensemble ouvert,Ensemble ouvert,ensemble ouvert,オープンセット,オープンセット,オープン集合,открытый набор,открытое множество,открытое множество
3145,open-ended text generation,توليد نص مفتوح,إنتاج نصوص غير محدودة,توليد نصي مفتوح النهاية,开放式文本生成,开放式文本生成,开放式文本生成,génération de texte ouvert,génération de texte ouverte,génération de texte ouvert,無制限のテキスト生成,オープンエンドテキスト生成,自由文生成,генерация открытого текста,Открытая генерация текста,генерация открытого текста
3146,open-loop,حلقة مفتوحة,- تحكم مفتوح,نظام مفتوح,开环,"""['目前，系统还以开环方式执行基元，但我们希望将来能使用反应性控制以在线适应滑动或不精确。'，'实验结果直接比较了我们提出的闭环AM系统与开环方法。在开环制造过程中，通过手动引入正面或负面缺陷来创建有缺陷的零部件，并通过应用我们的闭环方法修复手动",开环,boucle ouverte,en boucle ouverte,boucle ouverte,オープンループ,- オープンループ,オープンループ,открытый цикл,открытый цикл,разомкнутый контур
3147,operator norm,قاعدة المشغل,المعيار المشغل,معيار المعامل,操作员规范,算子范数,算子范数,norme de l'opérateur,norme de l'opérateur,norme d'opérateur,演算子ノルム,オペレーターノルム,オペレーター・ノルム,норма оператора,норма оператора,норма оператора
3148,operator sequence,تسلسل المشغل,تسلسل المشغل,تسلسل العمليات,运算符序列,操作者序列,运算符序列,séquence d'opérateurs,séquence d'opérateur,séquence d'opérateurs,演算子シーケンス,オペレーターのシーケンス,オペレータシーケンス,последовательность операторов,последовательность операторов,Последовательность операторов
3149,optical character recognition,التعرف الضوئي على الحروف,التعرف الضوئي على الشخصيات,التعرف الضوئي على الحروف,光学字符识别,光学字符识别,光学字符识别,reconnaissance optique de caractères,reconnaissance optique de caractères,reconnaissance optique de caractères,光学式文字認識,光学文字認識 (Kougaku Moji Ninshiki),光学文字認識,оптическое распознавание символов,Оптическое распознавание символов,оптическое распознавание символов
3150,optical flow,تدفق البصر,تدفق بصري,التدفق البصري,光流,光流,光流,flux optique,flux optique,flux optique,オプティカルフロー,光流,光流,оптический поток,оптический поток,оптический поток
3151,optical flow estimation,تقدير التدفق البصري,تقدير تدفق الضوء البصري,تقدير التدفق البصري,光流估计,光流估计,光流估计,estimation du flux optique,estimation du flux optique,estimation du flot optique,オプティカルフロー推定,オプティカルフロー推定,光流推定,оценка оптического потока,оценка оптического потока,оценка оптического потока
3152,optimal control theory,نظرية التحكم الأمثل,نظرية التحكم الأمثل,نظرية التحكم الأمثل,最优控制理论,最优控制理论,最优控制理论,théorie du contrôle optimal,- Théorie du contrôle optimal,théorie du contrôle optimal,最適制御理論,最適制御理論 (さいてきせいぎょりろん),最適制御理論,теория оптимального управления,теория оптимального управления,теория оптимального управления
3153,optimal experimental design,التصميم التجريبي الأمثل,تصميم تجريبي مثالي,تصميم التجربة الأمثل,最优实验设计,最佳实验设计 (Optimal Experimental Design),最优实验设计,plan expérimental optimal,conception expérimentale optimale,Conception expérimentale optimale,最適な実験計画,最適実験計画 (sai-tek jikken keikaku),最適実験設計,оптимальная схема эксперимента,оптимальное экспериментальное проектирование,Оптимальное проектирование экспериментов
3154,optimal policy,السياسة المثلى,السياسة الأمثل,السياسة المثلى,最优策略,最优策略,最优策略,politique optimale,politique optimale,politique optimale,最適な政策,最適ポリシー (さいてきポリシー),最適ポリシー,оптимальная политика,оптимальная стратегия,оптимальная политика
3155,optimal solution,حل مثالي,الحل الأمثل,الحل الأمثل,最优解,最优解,最优解,solution optimale,- Solution optimale,solution optimale,最適解,最適解,最適解,Оптимальное решение,оптимальное решение,оптимальное решение
3156,optimality,الأمثلية,الأمثلية,الحالة المثلى,最优性,最优性,最优性,optimalité,optimalité,optimalité,最適性,最適性,最適性,оптимальность,оптимальность,оптимальность
3157,optimality condition,حالة الأمثلية,شرط التميزية الأمثلية,شرط الأمثلية,最优性条件,最优性条件,最优性条件,condition d'optimalité,- Condition d'optimalité,condition d'optimalité,最適条件,最適条件,最適性条件,условие оптимальности,условие оптимальности,условие оптимальности
3158,optimisation,تحسين,التحسين,تحسين,优化,优化 (yōuhuà),优化,optimisation,optimisation,optimisation,最適化,最適化 (さいてきか),最適化,оптимизация,оптимизация,оптимизация
3159,optimisation problem,مشكلة التحسين,مشكلة التحسين,مشكلة تحسين,最优化问题,优化问题,优化问题,problème d'optimisation,problème d'optimisation,problème d'optimisation,最適化問題,最適化問題 (さいてきかもんだい),最適化問題,проблема оптимизации,оптимизационная задача,оптимизационная задача
3160,optimiser,محسن,محسن الأداء,محسِّن,优化器,优化器,优化器,optimiseur,optimiseur,optimiseur,オプティマイザー,最適化プログラム,最適化手法,оптимизатор,оптимизатор,оптимизатор
3161,optimization,تحسين,التحسين,تحسين,优化,优化,优化,optimisation,optimisation,optimisation,最適化,最適化 (さいてきか),最適化,оптимизация,оптимизация,оптимизация
3162,optimization algorithm,خوارزمية التحسين,خوارزمية تحسين,خوارزمية تحسين,优化算法,优化算法,优化算法,algorithme d'optimisation,algorithme d'optimisation,algorithme d'optimisation,最適化アルゴリズム,最適化アルゴリズム (さいてきかアルゴリズム),最適化アルゴリズム,алгоритм оптимизации,алгоритм оптимизации,алгоритм оптимизации
3163,optimization framework,إطار التحسين,إطار التحسين,إطار عمل التحسين,优化框架,优化框架,优化框架,cadre d'optimisation,cadre d'optimisation,Cadre d'optimisation,最適化フレームワーク,最適化フレームワーク (さいてきかフレームワーク),最適化フレームワーク,система оптимизации,оптимизационная структура,структура оптимизации
3164,optimization function,وظيفة التحسين,وظيفة التحسين,وظيفة التحسين,优化函数,优化函数,优化函数,fonction d'optimisation,- Fonction d'optimisation,fonction d'optimisation,最適化機能,最適化関数 (さいてきかかんすう),最適化関数,функция оптимизации,оптимизационная функция,оптимизационная функция
3165,optimization method,طريقة التحسين,أسلوب الأمثلية,طريقة التحسين,优化方法,优化方法 (Optimization Method),优化方法,méthode d'optimisation,- Méthode d'optimisation,méthode d'optimisation,最適化手法,最適化手法 (さいてきかしゅほう),最適化手法,метод оптимизации,метод оптимизации,оптимизационный метод
3166,optimization objective,الهدف الأمثل,الهدف من الأمثلية,هدف التحسين,优化目标,优化目标,优化目标,objectif d'optimisation,objectif d'optimisation,objectif d'optimisation,最適化目標,最適化目的 (さいてきかもく),最適化目的関数,цель оптимизации,цель оптимизации,цель оптимизации
3167,optimization problem,مشكلة التحسين,مشكلة التحسين,مسألة التحسين,最优化问题,优化问题,优化问题,problème d'optimisation,Problème d'optimisation,problème d'optimisation,最適化問題,最適化問題 (saitekika mondai),最適化問題,проблема оптимизации,Проблема оптимизации,задача оптимизации
3168,optimization procedure,إجراء التحسين,إجراءات التحسين,إجراءات التحسين,优化程序,优化程序,优化过程,procédure d'optimisation,procédure d'optimisation,procédure d'optimisation,最適化手順,最適化手順 (さいてきかしゅじゅん),最適化手順,процедура оптимизации,процедура оптимизации,процедура оптимизации
3169,optimization step,خطوة التحسين,خطوة الأمثلية,خطوة تحسين,优化步骤,优化步骤,优化步骤,étape d'optimisation,étape d'optimisation,Pas d'optimisation,最適化ステップ,最適化ステップ (saitekika suteppu),最適化ステップ,шаг оптимизации,оптимизационный шаг,оптимизационный шаг
3170,optimization theory,نظرية التحسين,نظرية الأمثلية,نظرية التحسين,最优化理论,优化理论,优化理论,théorie de l'optimisation,théorie de l'optimisation,théorie de l'optimisation,最適化理論,最適化理論 (さいてきかりろん),最適化理論,теория оптимизации,теория оптимизации,теория оптимизации
3171,optimizer,محسن,محسن الأداء,مُحسِّن,优化器,优化器 (Optimizer),优化器,optimiseur,- Optimiseur,optimiseur,オプティマイザ,最適化手法 (saiteki-ka shuhou),最適化アルゴリズム,оптимизатор,оптимизатор,оптимизатор
3172,option,خيار,خيارات,خيار,选项,选项 (xuǎnxiàng),选项,option,option,option,オプション,オプション,オプション,вариант,опция,опция
3173,oracle,وحي,العراف,دليل,甲骨文,神谕程序,神谕,oracle,oracle,oracle,オラクル,オラクル,神示,оракул,оракул,оракул
3174,oracle policy,سياسة أوراكل,سياسة أوراقل,سياسة المعلم,甲骨文政策,预言策略,神谕策略,politique d'oracle,politique de l'oracle,politique oracle,オラクルポリシー,オラクルポリシー,オラクルポリシー,политика оракула,оракуловская политика,оракульная политика
3175,ordinal embedding,التضمين الترتيبي,تضمين ترتيبي,تضمين الترتيبي,序数嵌入,序数嵌入,序数嵌入,incorporation ordinale,incorporation ordinale,plongement ordinal,序数埋め込み,順序埋め込み,順序埋め込み,порядковое вложение,ординальное вложение,порядковое вложение
3176,ordinal regression,الانحدار الترتيبي,- تصنيف تسلسلي,الانحدار الرتبي,序数回归,序数回归,有序回归,régression ordinale,régression ordinale,régression ordinale,順序回帰,順序回帰,順序回帰,порядковая регрессия,порядковая регрессия,порядковая регрессия
3177,orientation loss,فقدان التوجه,فقدان التوجيه,خسارة التوجيه,方向损失,方向丢失 (orientation loss),方向损失,perte d'orientation,perte d'orientation,perte d'orientation,配向損失,"""['方向損失(""no R o "")を取り除くと、法線とレンダリングが著しく劣化し、密度フィールドの法線に直接方向損失を適用し、それらを使用して反射方向を計算すると、性能も低下します。', '(2022)余分な空間の充填を防ぐために。カ",方向損失,потеря ориентации,Потеря ориентации,потеря ориентации
3178,orthogonal basis,أساس متعامد,قاعدة متعامدة,قاعدة متعامدة,正交基,正交基,正交基,base orthogonale,- Base orthogonale,base orthogonale,直交基底,直交基底,直交基底,ортогональный базис,ортогональный базис,ортогональный базис
3179,orthogonal matrix,مصفوفة متعامدة,مصفوفة متعامدة,مصفوفة متعامدة,正交矩阵,正交矩阵 (orthogonal matrix),正交矩阵,matrice orthogonale,matrice orthogonale,matrice orthogonale,直交行列,直交行列,正規直交行列,ортогональная матрица,ортогональная матрица,ортогональная матрица
3180,orthogonal projection matrix,مصفوفة الإسقاط المتعامد,- المصفوفة العرضية المتعامدة,مصفوفة الإسقاط المتعامد,正交投影矩阵,正交投影矩阵,正交投影矩阵,matrice de projection orthogonale,- Matrice de projection orthogonale,matrice de projection orthogonale,直交射影行列,直交射影行列 (chokkou shaei gyouretsu),正射影行列,матрица ортогональной проекции,ортогональная проекционная матрица,ортогональная проекционная матрица
3181,orthographic camera model,نموذج الكاميرا الإملائية,نموذج الكاميرا الأورثوغرافية,نموذج كاميرا أرثوغرافية,正交相机模型,正交相机模型,正交相机模型,modèle de caméra orthographique,modèle de caméra orthographique,modèle de caméra orthographique,正投影カメラモデル,正投影カメラモデル,正射影カメラモデル,модель ортогональной камеры,ортографическая камера модель,Ортографическая камерная модель
3182,orthographic projection,الإسقاط الهجائي,الإسقاط الأرثوغرافي,إسقاط متعامد,正投影,正交投影,正交投影,projection orthographique,projection orthographique,projection orthographique,正投影,正射投影 (seisha tōei),直行投影,ортографическая проекция,Ортографическая проекция,ортографическая проекция
3183,orthonormal decomposition,التحلل المتعامد,التحليل الأورثونورمي,تحليل متعامد قياسي,正交分解,正交标准分解,正交分解,décomposition orthonormale,décomposition orthonormale,décomposition orthonormée,正規直交分解,直交分解,正規直交分解,ортонормированное разложение,ортонормальное разложение,ортонормальное разложение
3184,orthonormal matrix,مصفوفة متعامدة,المصفوفة الأورثونورمال,مصفوفة متعامدة ومتعامدة,正交矩阵,正交矩阵,正交矩阵,matrice orthonormée,- Matrice orthogonale,matrice orthonormale,正規直交行列,直交行列 (chokkou gyoretsu),直交正規化行列,ортонормированная матрица,ортонормальная матрица,ортонормированная матрица
3185,orthonormal row,صف متعامد,صف طبيعي قائم,صفوف متعامدة ومتساوية الطول,正交行,正交规范行,标准正交行,rangée orthonormée,rang orthonormé,rangée orthonormale,正規直交行,直交正規行,正規直交行,ортонормированный ряд,ортонормированный ряд,ортонормальная строка
3186,orthonormality,التطبيع,"""نستطيع بعد ذلك تطبيق خاصية الدوال الذاتية على التكامل الداخلي وتعميم الدوال الذاتية على النتيجة الناتجة، مما يؤدي إلى، cov(u m , u k ) = λ k φ k (x)φ m (x)p(x)dx = λ k δ m,k . با",تعامد,正交性,正交规范性,正交规范性,orthonormalité,orthonormalité,orthonormalité,正規直交性,直交正規性 (chokkō seikisei),正規直交性,ортонормированность,Ортонормальность,ортонормальность
3187,out-of-distribution,خارج التوزيع,- توزيع خارجي من النطاق,تَوْزِيع خارِجِي,分布外,超出分布,外分布,hors distribution,hors de la distribution,hors distribution,配布されていない,分布外,分布外 (bunpu-gai),вышедший из продажи,вне распределения,вне распределения
3188,out-of-domain,خارج النطاق,خارج نطاق النطاق,خارج النطاق,域外,领域外,领域外,hors domaine,hors-domaine,hors-domaine,ドメイン外,ドメイン外,文脈外の,вне домена,вне области,вне области
3189,out-of-domain evaluation,التقييم خارج النطاق,تقييم خارج نطاق المجال,تقييم خارج النطاق,域外评估,域外评估,跨域评估,évaluation hors domaine,évaluation hors domaine,évaluation hors-domaine,ドメイン外の評価,ドメイン外評価,異種領域評価,внедоменная оценка,оценка вне области (out-of-domain evaluation),оценка вне домена
3190,outli exposure,التعرض الخارجي,- تعرض للقيم الشاذة,التعرض للشواذ,外部暴露,异常暴露,异常暴露,exposition aux contours,exposition aux valeurs aberrantes,exposition aux valeurs aberrantes,アウトリ露出,外れ値暴露,外れ値露出,превысить экспозицию,выявление выбросов,обработка выбросов
3191,outli rejection,رفض مطلق,رفض القيم الشاذة,رفض المتطرفات,异常拒绝,异常值排除,异常值拒绝,rejet des contours,rejet des valeurs aberrantes,Rejet de valeurs aberrantes,異常拒否,異常値除去 (Outlier rejection),外れ値除去,перевешивает отказ,отбрасывание выбросов,сброс выбросов
3192,outlier,ناشز,قيم متفردة,قيم متطرفة,异常值,异常值,异常值,valeur aberrante,valeur aberrante,valeur aberrante,外れ値,外れ値 (sotodarechi),外れ値,выброс,выброс,выброс
3193,outlier detection,الكشف الخارجي,كشف القيم الشاذة,اكتشاف القيم الشاذة,异常值检测,异常检测,异常值检测,détection des valeurs aberrantes,détection des valeurs aberrantes,détection de valeurs aberrantes,外れ値の検出,外れ値検出 (sotodare kenshutsu),外れ値検出,обнаружение выбросов,выявление выбросов,обнаружение выбросов
3194,output,انتاج,الإخراج,مخرج,输出,输出,输出,sortir,sortie,sortie,出力,出力,出力,выход,вывод,выход
3195,output gate,بوابة الإخراج,البوابة الناتجة,بوابة الإخراج,输出门,输出门,输出门,porte de sortie,porte de sortie,porte de sortie,出力ゲート,出力ゲート (output gate),出力ゲート,выходные ворота,выходные ворота,выходной вентиль
3196,output layer,طبقة الإخراج,الطبقة الناتجة,طبقة الإخراج,输出层,输出层,输出层,couche de sortie,couche de sortie,couche de sortie,出力層,出力層,出力層,выходной слой,выходной слой,выходной слой
3197,output space,مساحة الإخراج,المساحة الناتجة,مساحة الإخراج,输出空间,输出空间,输出空间,espace de sortie,- Espace de sortie,espace de sortie,出力スペース,出力空間,出力空間,выходное пространство,пространство вывода,пространство выходов
3198,output token,رمز الإخراج,- مخرج الرمز,رمز إخراج,输出令牌,输出标记 (output token),输出符号,jeton de sortie,jeton de sortie,jeton de sortie,出力トークン,出力トークン,出力トークン,выходной токен,"- Output token
- Выходной токен",токен вывода
3199,output vector,ناقلات الإخراج,متجه الناتج,ناتج المتجه,输出向量,输出向量 (output vector),输出向量,vecteur de sortie,vecteur de sortie,vecteur de sortie,出力ベクトル,出力ベクトル,出力ベクトル,выходной вектор,вектор вывода,вектор выхода
3200,output vocabulary,مفردات الإخراج,مفردات الإخراج,مفردات الإخراج,输出词汇,输出词汇量,输出词汇表,vocabulaire de sortie,vocabulaire de sortie,vocabulaire de sortie,語彙をアウトプットする,出力語彙,出力語彙,выходной словарь,выходной словарь,выходной словарь
3201,over-fit,الإفراط في الملاءمة,التجاوز في التدريب,مفرط التعلم,过拟合,过拟合,过度拟合,sur-ajustement,surajustement,sur-apprentissage,オーバーフィット,過学習 (kagakushū),オーバーフィッティング,слишком приспособленный,переобучение,переобучение
3202,over-segmentation,الإفراط في التجزئة,التجزئة الزائدة,تجزئة مفرطة,过度分割,过分分割,过度分割,sur-segmentation,sur-segmentation,sur-segmentation,過剰な分割,過剰分割 (kajo bunkatsu),過剰分割,чрезмерная сегментация,пересегментация,чрезмерная сегментация
3203,over-smooth,أكثر من السلس,- تنعيم زائد,تجانس المفرط,过于平滑,过度平滑,过度平滑,trop lisse,sur-lissage,sur-lissage,滑らかすぎる,オーバースムージング,過剰平滑化,слишком гладкий,переусаживание,чрезмерное сглаживание
3204,paired t-test,اختبار t المقترن,اختبار تي المقابل (paired t-test),اختبار (ت) المقترن,配对t检验,成对 t 检验,配对 t 检验,test t apparié,test t apparié,test t apparié,対応のある t 検定,対応のある t検定,対応のある t 検定,парный t-критерий,- Парный t-тест,парный t-критерий
3205,pairwise,الزوجي,- مُتَزَامِنَين,زوجيًا,成对的,"""['实际上，关注模块还提供了关于一对一残基相互作用重要性的可解释性，如附录I所示。'，'具体而言，对对应关系的搜索被视为一个超图匹配问题，使用高阶约束而不是以前方法中使用的一元或一对一的约束：基于局部图像描述的一阶方法（例如）容易受",成对,par paires,en paire,par paires,ペアごと,ペアワイズ (pairwise),二項間の,попарно,попарный,попарно
3206,pairwise classifier,المصنف الزوجي,مصنف زوجي,مُصَنِّفٌ زوجيٌّ,成对分类器,一对一分类器,成对分类器,classificateur par paire,classificateur par paire,classificateur par paires,ペアワイズ分類子,ペアワイズ分類器,対応付け分類器,попарный классификатор,парный классификатор,парный классификатор
3207,pairwise clique,زمرة زوجية,صحيفة زوجية,مجموعة زوجية,成对集团,"""在完全连接的两两团CRF模型中，G是X上的完全图，CG是所有一元和两元团的集合。""",两两团,clique par paires,clique en paire,clique par paires,ペアワイズクリーク,ペアワイズ・クリーク,対の素性関係,попарная клика,попарный клик,парные клики
3208,pairwise comparison,وأنا أتفق مع المشاركات السابقة,المقارنة زوجية,مقارنة زوجية,成对比较,"""['集体多标签分类器（CML）（Ghamrawi和McCallum，2005）采用最大熵原则处理多标签数据，通过将标签相关性编码为约束条件。Zhang和Zhou（2007）采用k最近邻技术处理多标签数据。Fürnkranz等人（2008）通过利用两两比较来对标签进行排名。'，'换句话说，",成对比较,Comparaison par paire,comparaison par paire,comparaison par paires,ペアごとの比較,ペアワイズ比較 (pairwise comparison),対比較,парное сравнение,попарное сравнение,попарное сравнение
3209,pairwise constraint,القيد الزوجي,القيد المزدوج,قيود ثنائية,成对约束,配对约束,成对约束,contrainte par paire,Contrainte par paire,contrainte par paires,ペアごとの制約,ペア制約,ペアワイズ制約,попарное ограничение,Парные ограничения,попарное ограничение
3210,pairwise flow,التدفق الزوجي,تدفق زوجي,التدفق الثنائي,成对流,成对流量 (pairwise flow),成对流动,flux par paires,flux par paires,flux par paires,ペアワイズフロー,ペアワイズフロー,ペアワイズフロー,парный поток,- Парные потоки,попарный поток
3211,pairwise learning,التعلم الزوجي,التعلم التدريجي من الزوجية,تعلم الأزواج المتقابلة,成对学习,一对一学习,成对学习,apprentissage par paires,apprentissage par paires,apprentissage par paires,ペアワイズ学習,ペアワイズ学習 (pairwise learning),対応学習,парное обучение,попарное обучение,попарное обучение
3212,pairwise potential,الإمكانات الزوجية,الطاقة المزدوجة,إمكانات ثنائية,成对势,成对势能,成对势能,potentiel par paire,potentiel par paire,potentiel par paires,ペアワイズポテンシャル,ペアワイズポテンシャル,ペア間ポテンシャル,парный потенциал,потенциал попарных взаимодействий,парный потенциал
3213,pairwise word similarity,تشابه الكلمات الزوجية,تشابه الكلمات زوجيًا,التشابه الزوجي للكلمات,成对词相似度,一对一词语相似度,成对词相似性,similarité de mots par paires,similarité de mots par paire,similarité par paires de mots,ペアごとの単語の類似性,ペアワイズ単語類似度,単語ペア類似度,попарное сходство слов,попарная схожесть слов,Парная схожесть слов
3214,panoptic segmentation,تجزئة بانوبتيك,- تقسيم شامل,التجزئة الشاملة,全景分割,全景分割 (panoptic segmentation),全景分割,segmentation panoptique,segmentation panoptique,segmentation panoptique,パノプティックセグメンテーション,パノプティック・セグメンテーション,パノプティックセグメンテーション,паноптическая сегментация,паноптическая сегментация,панорамная сегментация
3215,parallel corpora,الهيئات الموازية,- مجموعات النصوص المتوازية,مجاميع نصية موازية,平行语料库,- 平行语料库,平行语料库,corpus parallèles,corpus parallèles,corpus parallèles,パラレルコーパス,平行コーパス,並列コーパス,параллельные корпуса,параллельные корпуса,параллельные корпуса
3216,parallel corpus,الجسم الموازي,مجموعة موازية,متوازي المدونة,平行语料库,平行语料库,平行语料库,corpus parallèle,- Corpus parallèle,corpus parallèle,対訳コーパス,パラレルコーパス,並列コーパス,параллельный корпус,параллельный корпус,параллельный корпус
3217,parallel datum,مسند موازي,- توازي البيانات,بيانات متوازية,平行基准,并行数据 (parallel data),并行语料,référence parallèle,donnée parallèle,données parallèles,平行データム,並列データ,並列データ,параллельная база данных,параллельные данные,параллельные данные
3218,parameter,معامل,معامل,معامل,范围,参数 (páraméter),参数,paramètre,paramètre,paramètre,パラメータ,パラメータ,パラメータ,параметр,параметр,параметр
3219,parameter count,عدد المعلمات,عدد المعلمات,شرح عدد البارامترات,参数个数,参数数量,参数数量,nombre de paramètres,- Nombre de paramètres,nombre de paramètres,パラメータ数,パラメータ数,パラメータ数,количество параметров,количество параметров,параметрического счета
3220,parameter estimation,تقدير المعلمة,تقدير المعلمة,تقدير المعلمات,参数估计,参数估计,参数估计,estimation des paramètres,estimation des paramètres,estimation des paramètres,パラメータ推定,パラメータ推定,パラメータ推定,оценка параметров,оценка параметров,параметрическая оценка
3221,parameter learning,تعلم المعلمة,تعلم المعلمة,تعلم المعاملات,参数学习,参数学习,参数学习,apprentissage des paramètres,apprentissage des paramètres,apprentissage des paramètres,パラメータ学習,パラメータ学習,パラメータ学習,обучение параметрам,обучение параметров,обучение параметров
3222,parameter matrix,مصفوفة المعلمة,مصفوفة المعلمات,مصفوفة المعاملات,参数矩阵,参数矩阵,参数矩阵,matrice de paramètres,matrice de paramètres,matrice de paramètres,パラメータマトリックス,パラメータ行列 (parameter matrix),パラメータ行列,матрица параметров,матрица параметров,матрица параметров
3223,parameter model,نموذج المعلمة,نموذج معلمة,نموذج المعلمات,参数模型,参数模型,参数模型,modèle de paramètres,modèle de paramètres,modèle paramétrique,パラメータモデル,パラメータモデル,パラメータモデル,модель параметров,параметрическая модель,модель параметров
3224,parameter regularization,تنظيم المعلمة,تنظيم المعلمة,ضبط المُعامِلات,参数正则化,参数正则化,参数正则化,régularisation des paramètres,régularisation des paramètres,régularisation des paramètres,パラメータの正規化,パラメータの正則化 (Parameter regularization),パラメータ正則化,регуляризация параметров,регуляризация параметров,регуляризация параметров
3225,parameter sharing,مشاركة المعلمة,مشاركة المعلمة,مشاركة المعلمات,参数共享,参数共享,参数共享,partage de paramètres,partage de paramètres,partage des paramètres,パラメータの共有,パラメータ共有,パラメータ共有,совместное использование параметров,параметрное совместное использование,разделение параметров
3226,parameter size,حجم المعلمة,حجم المعلمة,حجم المعلمة,参数大小,参数大小,参数大小,taille du paramètre,- Taille des paramètres,Taille des paramètres,パラメータのサイズ,パラメーターサイズ,パラメータサイズ,размер параметра,размер параметра,размер параметра
3227,parameter space,مساحة المعلمة,المجال المعلمي,مجال المعاملات,参数空间,参数空间,参数空间,espace de paramètres,espace des paramètres,espace des paramètres,パラメータ空間,パラメータ空間 (Parameter Kūkan),パラメータ空間,пространство параметров,пространство параметров,пространство параметров
3228,parameter tuning,ضبط المعلمة,ضبط المعلمة,ضبط المعاملات,参数调整,参数调整,参数调优,réglage des paramètres,réglage des paramètres,réglage des paramètres,パラメータチューニング,パラメーター調整,パラメータ調整,настройка параметров,настройка параметров,Настройка параметров
3229,parameter tying,ربط المعلمة,ربط المعلمة,تربيط المعاملات,参数绑定,参数绑定,参数绑定,liaison de paramètres,liaison de paramètres,liage des paramètres,パラメータの紐付け,パラメータ結合,パラメータ束縛,привязка параметров,- Параметрическое связывание,параметр связывания
3230,parameter update,تحديث المعلمة,تحديث المعلمة,تحديث المعلمات,参数更新,参数更新,参数更新,mise à jour des paramètres,mise à jour des paramètres,mise à jour des paramètres,パラメータの更新,パラメータ更新,パラメータ更新,обновление параметра,обновление параметров,обновление параметров
3231,parameter vector,ناقلات المعلمة,- تكامل المعاملات,متجه المعلمات,参数向量,参数向量,参数向量,vecteur de paramètres,vecteur de paramètres,vecteur de paramètres,パラメータベクトル,パラメーターベクトル,パラメータベクトル,вектор параметров,- Параметрический вектор,вектор параметров
3232,parameter-efficient fine-tuning,ضبط كفاءة المعلمة,ضبط دقائق كفءة للمعلمة,ضبط دقيق فعال للمعاملات,参数有效的微调,参数高效微调,参数高效微调,réglage fin et efficace des paramètres,ajustement fin efficace en termes de paramètres,ajustement fin des paramètres efficace,パラメータ効率の良い微調整,パラメータ効率的な微調整,パラメータ効率的微調整,точная настройка с эффективным использованием параметров,параметроэффективная донастройка,эффективная тонкая настройка параметров
3233,parameterisation,تحديد المعلمات,التعيينات العامة,ترميز المعلمة,参数化,参数化,参数化,paramétrage,paramétrisation,paramétrisation,パラメータ化,パラメータ化,パラメータ化,параметризация,параметризация,параметризация
3234,parameterization,تحديد المعلمات,المعلمة,معاملة,参数化,参数化,参数化,paramétrage,paramétrisation,paramétrage,パラメータ化,パラメータ化,パラメータ化,параметризация,параметризация,параметризация
3235,parameterize model,نموذج المعلمة,نموذج معلم بالمعلم,نموذج موميتر,参数化模型,参数化模型,参数化模型,paramétrer le modèle,modéliser les paramètres,modèle paramétré,モデルをパラメータ化する,パラメータ化モデル (Parameterized Model),パラメータ化モデル,параметризовать модель,параметризованная модель,параметризованная модель
3236,parametric,حدودي,معلماتي,بارامتري,参数,参数化,参数化的,paramétrique,paramétrique,paramétrique,パラメトリック,パラメトリック,パラメトリック,параметрический,параметрический,параметрический
3237,parametric family,عائلة بارامترية,عائلة بارامترية,عائلة حدودية,参数族,参数族,参数族,famille paramétrique,- Famille paramétrique,famille paramétrique,パラメトリック ファミリ,パラメトリックファミリー,パラメトリックファミリー,параметрическое семейство,параметрическое семейство,параметрическое семейство
3238,parametric knowledge,المعرفة البارامترية,المعرفة المعلميةgetParametric Knowledge,المعرفة المعلمية,参数知识,参数化知识,参数化知识,connaissance paramétrique,connaissance paramétrique,connaissance paramétrique,パラメトリック知識,パラメトリック知識 (Parametorikku chishiki),パラメトリック知識,параметрические знания,параметрический знак,параметрические знания
3239,parametric model,النموذج البارامترى,- تحليل معلماتي,نموذج معلمي,参数模型,参数模型,参数模型,modèle paramétrique,modèle paramétrique,modèle paramétrique,パラメトリックモデル,パラメトリックモデル,パラメトリックモデル,параметрическая модель,параметрическая модель,параметрическая модель
3240,parametrization,المعلمات,- تعدد القيم المعلمة,تعريف المعلمات,参数化,参数化,参数化,paramétrage,paramétrisation,paramétrisation,パラメータ化,パラメータ化,パラメータ化,параметризация,параметризация,параметризация
3241,paraphrase,شرح النص,إعادة صياغة,تصريف,释义,释义,近义词,paraphrase,paraphrase,paraphrase,言い換える,"""最初に、ほとんどのRTE問題は、推論の形態に依存しており、NatLogはそれに対処するように設計されていません。 2番目に、ほとんどのRTE問題では、前提と仮説の間の編集距離が比較的大きいです。ここで、類似性",言い換え,парафраз,перефразирование,парафраз
3242,paraphrase generation,جيل إعادة صياغة,إنشاء إعادة صياغة,توليد الصياغات المترادفة,释义生成,释义生成,释义生成,génération de paraphrase,génération de paraphrases,génération de paraphrases,言い換えの生成,言い換え生成,言い換え生成,генерация перефразирования,- Поколение перефразирования,генерация парафраз
3243,paraphrase generator,مولد إعادة صياغة,مولد إعادة الصياغة,مولد إعادة الصياغة,释义生成器,释义生成器,释义生成器,générateur de paraphrase,générateur de paraphrases,générateur de paraphrases,言い換えジェネレーター,言い換えジェネレータ,言い換え生成器,генератор парафразов,генератор перефразирования,генератор перефразирования
3244,paraphrase identification,تحديد إعادة الصياغة,تحديد إعادة الصياغة,تحديد إعادة الصياغة,释义识别,释义识别,句子重述识别,identification paraphrase,identification de paraphrase,identification de la paraphrase,言い換えの識別,言い換えの識別 (Iigae no shikibetsu),言い換え識別,идентификация перефразирования,идентификация парафразов,идентификация парафраз
3245,paraphrase model,نموذج إعادة صياغة,نموذج إعادة الصياغة,نموذج إعادة الصياغة,释义模型,释义模型,文本重述模型,modèle de paraphrase,modèle de paraphrase,modèle de paraphrase,言い換えモデル,パラフレーズモデル,言い換えモデル,модель перефразирования,модель перефразирования,модель перефразирования
3246,parent node,عقدة الأم,العقدة الأصلية,العقدة الأصل,父节点,父节点,父节点,nœud parent,nœud parent,nœud parent,親ノード,親ノード (oyako nod),親ノード,родительский узел,родительский узел,родительский узел
3247,pareto optimal,باريتو الأمثل,باريتو أمثلية,أمثل حسب باريتو,帕累托最优,帕累托最优,帕累托最优,pareto optimal,optimal de Pareto,Pareto optimal,パレート最適,"""「しかし、初期データが多い（α tot が大きい）場合には、より積極的に剪定（fが小さい）することで、削減されたデータセットサイズα pruneの関数としてのパレート最適なテストエラーを達成でき、少なくとも指数的なスケーリング則を示す（図1A",パレート最適,оптимум по Парето,Парето-оптимальный,Парето-оптимальный
3248,pareto optimality,باريتو الأمثل,"""['تعريف 6.2 (fPO [Barman et al.، 2018]). يُقال إن التوزيع A يرضي الأمثلية الباريتو الجزئية (fPO) إذا لم يكن يهيمن عليه أي توزيع جزئي. كما لاحظ Barman et al. [2018]",الكفاءة البارتو,帕累托最优,帕累托最优,帕累托最优性,optimalité de Pareto,optimalité de Pareto,optimalité de Pareto,パレート最適性,パレート最適性,パレート最適性,оптимальность по Парето,оптимальность Парето,Парето-оптимальность
3249,pareto-efficient,كفاءة باريتو,فعال باريتو,- كفؤ باريتو,帕累托有效,帕累托有效,帕累托有效,Pareto-efficace,Pareto-efficace,pareto-optimal,パレート効率,パレート効率的,パレート最適,эффективный по Парето,Парето-эффективный,Парето-эффективный
3250,parse,تحليل,- تحليل,تحليل,解析,解析,解析,analyser,analyse syntaxique,analyser,解析する,解析,構文解析,анализировать,разбор,разбор
3251,parse accuracy,دقة التحليل,دقة التحليل,دقة التحليل,解析准确度,解析准确率,解析准确率,analyser la précision,précision d'analyse,précision de l'analyse syntaxique,解析精度,解析精度,構文解析精度,точность анализа,точность разбора,точность разбора
3252,parse algorithm,خوارزمية التحليل,خوارزمية تحليلية,خوارزمية تحليل,解析算法,解析算法,解析算法,analyser l'algorithme,algorithme d'analyse syntaxique,algorithme d'analyse syntaxique,解析アルゴリズム,解析アルゴリズム,構文解析アルゴリズム,алгоритм анализа,алгоритм синтаксического разбора,алгоритм разбора
3253,parse chart,تحليل الرسم البياني,- تحليل الجدول,رسم بناء الجمل,解析图,解析图,解析图表,analyser le graphique,tableau d'analyse,Tableau d'analyse syntaxique,解析チャート,パースチャート (paasuchāto),構文解析チャート,диаграмма анализа,таблица синтаксического анализа,диаграмма разбора
3254,parse forest,غابة التحليل,غابة تحليلية,غابة التّحليل,解析森林,解析森林,解析森林,analyser la forêt,forêt d'analyse,forêt d'analyses syntaxiques,解析の森,パースフォレスト,構文解析木構造,Разобрать лес,лес разбора,лесонабор
3255,parse model,نموذج التحليل,نموذج التحليل النحوي,نموذج التحليل,解析模型,解析模型,解析模型,analyser le modèle,modèle d'analyse syntaxique,modèle d'analyse syntaxique,モデルを解析する,解析モデル (kaiseki moderu),構文解析モデル,модель анализа,модель синтаксического анализа,разборная модель
3256,parse performance,تحليل الأداء,أداء تحليل البيانات,أداء التحليل,解析性能,解析性能,解析性能,analyser les performances,performance d'analyse syntaxique,performance d'analyse syntaxique,解析パフォーマンス,パース性能,構文解析性能,производительность синтаксического анализа,производительность синтаксического анализа,Разбор производительности
3257,parse score,تحليل النتيجة,نقطة تحليلية,درجة التحليل,解析分数,解析得分,解析分数,analyser le score,score d'analyse,score d'analyse syntaxique,解析スコア,パーススコア,構文解析スコア,оценка анализа,оценка анализа,оценка разбора
3258,parse structure,هيكل التحليل,الهيكل التحليلي,بُنْيَة التَّحْليلِ,解析结构,解析结构,语法分析结构,analyser la structure,- Structure d'analyse,structure de l'analyse,構造を解析する,構文解析,構文構造,структура синтаксического анализа,структура разбора,синтаксическая структура
3259,parse tree,تحليل شجرة,شجرة تحليلية,شجرة التحليل,解析树,- 解析树,语法树,analyser l'arbre,arbre d'analyse,arbre syntaxique,解析ツリー,解析木,構文木,дерево разбора,дерево синтаксического анализа,дерево разбора
3260,parser,محلل,محلل,محلل,解析器,解析器,语法分析器,analyseur,analyseur,analyseur,パーサー,パーサー,構文解析器,парсер,парсер,анализатор
3261,part of speech,جزء من الكلام,جزء من الكلام,الجزء الكلام,词类,词性,词性,partie du discours,partie du discours,partie du discours,品詞,品詞 (hinshi),品詞,часть речи,Часть речи,часть речи
3262,part of speech tag,جزء من علامة الكلام,علامة جزء من الكلام,شِفْرَة الكَلام,词性标签,词性标记,词性标注,partie du discours,étiquette de partie du discours,étiquette de partie du discours,品詞タグ,品詞タグ,品詞タグ,часть речевого тега,тег части речи,часть речи
3263,part of speech tagger,جزء من علامة الكلام,جزء من تاجر الكلمات,جهاز وسم أجزاء الكلام,词性标注器,词性标注器,词性标注器,marqueur de parties du discours,étiqueteur de parties du discours,étiqueteur morphosyntaxique,品詞タグ付け,品詞タガー,part of speech tagger = 品詞タガー,часть речи,теггер части речи,часть речи тэггер
3264,partial assignment,مهمة جزئية,التعيين الجزئي,تفويض جزئي,部分赋值,部分赋值,部分赋值,cession partielle,assignation partielle,affectation partielle,部分的な割り当て,部分割り当て,部分代入,частичное присвоение,частичное присваивание,частичное присваивание
3265,partial derivation,اشتقاق جزئي,الاشتقاق الجزئي,اشتقاق جزئي,偏导数,部分推导,部分推导,dérivée partielle,dérivation partielle,dérivation partielle,偏導関数,部分導出,部分導出,частная производная,частичное выведение,частичное вывод
3266,partial evaluation,التقييم الجزئي,التقييم الجزئي,تقييم جزئي,部分评价,部分评估,部分求值,évaluation partielle,évaluation partielle,évaluation partielle,部分的な評価,部分評価,部分評価,частичная оценка,- Частичная оценка,частичная оценка
3267,partial observability,إمكانية الملاحظة الجزئية,- تحقق جزئي,عدم الملاحظة الجزئية,部分可观察性,部分可观测性,部分可观察性,observabilité partielle,observabilité partielle,observabilité partielle,部分的な可観測性,部分観測,部分的観測可能性,частичная наблюдаемость,частичная наблюдаемость,частичная наблюдаемость
3268,partial order,طلب جزئى,ترتيب جزئي,ترتيب جزئي,偏序,偏序,偏序,commande partielle,ordre partiel,ordre partiel,半順序,部分順序,部分順序,частичный порядок,частичный порядок,частичный порядок
3269,partially observable Markov decision process,عملية اتخاذ قرار ماركوف يمكن ملاحظتها جزئيا,"""['نحن نقوم بتشكيل إعداد اقتناء الطعام لفترة طويلة من خلال النظر في وكيل يتفاعل في عملية اتخاذ القرارات ماركوف الجزئية المرئية لفترة",نموذج مارkov للقرارات الجزئية الملاحظة,部分可观察马尔可夫决策过程,部分可观测马尔可夫决策过程 (POMDP),部分可观测马尔可夫决策过程,processus de décision de Markov partiellement observable,Processus de décision markovien partiellement observable,processus décisionnel de Markov partiellement observable,部分的に観察可能なマルコフ決定プロセス,部分観測マルコフ決定過程,部分観測マルコフ決定過程,частично наблюдаемый марковский процесс принятия решений,Частично наблюдаемый марковский процесс принятия решений (POMDP),частично наблюдаемый марковский процесс принятия решений
3270,particle filter,مصفي الجسيمات,مُرشِّح الجسيمات,مرشح الجسيمات,颗粒过滤器,粒子滤波器,粒子滤波器,filtre à particule,filtre à particules,filtre à particules,粒子フィルター,パーティクルフィルタ,粒子フィルタ,фильтр твердых частиц,фильтр частиц,фильтр частиц
3271,partition,تقسيم,تقسيم,تقسيم,分割,分区,划分,cloison,partition,partition,パーティション,パーティション (pa-tishon),分割,раздел,разбиение,разбиение
3272,partition function,وظيفة التقسيم,دالة التقسيم,دالة التقسيم,配分函数,- 分区函数,配分函数,fonction de partition,- Fonction de partition,fonction de partition,パーティション関数,分配関数,分割関数,функция разделения,функция разбиения,функция разбиения
3273,parzen window,نافذة بارزين,- تقدير نافذة بارزين,نافذة بارزن,帕森窗,帕尔森窗,帕尔森窗口 (Parzen window),fenêtre parzen,fenêtre de Parzen,fenêtre de Parzen,パルツェンの窓,パーゼン窓,パーゼン窓,окно парзена,- Парзеновское окно,парзеновское окно
3274,patch,رقعة,جُزء,شريحة,修补,"""['对于这个网格中的每个行i和列j中的补丁x i,j，我们预测在下面的行中最多K个补丁x i+K,j，跳过第一个重叠的补丁x i+1,j。'，'在预处理得到的实值输出的情况下，z是一个图像子区域或补丁，可视为强度函数I z (r)。正",图像块,correctif,patch,dalle,パッチ,パッチ,パッチ,пластырь,патч,патч
3275,path integration,تكامل المسار,التكامل المساري,تكامل المسار,路径整合,路径积分,路径积分,intégration de chemin,intégration de chemin,intégration de chemin,パスの統合,パス積分 (pasu sekibun),経路積分,интеграция путей,интеграция пути,интеграция пути
3276,path planning,تخطيط المسار,تخطيط المسارات,تخطيط المسار,路径规划,路径规划,路径规划,Planification de trajectoire,planification de trajectoire,planification de trajectoire,パスの計画,パスプランニング (path planning),経路計画,планирование пути,планирование пути,планирование пути
3277,pattern profile,الملف الشخصي للنمط,ملف نمط النمط,نمط الملف الشخصي,图案轮廓,模式剖析,模式概况,profil de modèle,profil de motif,profil de motif,パターンプロファイル,パターンプロファイル (patān purofairu),パターンプロファイル,профиль узора,профиль шаблонов,шаблон профиля
3278,pattern recognition,التعرف على الأنماط,التعرف على الأنماط,التعرف على الأنماط,模式识别,模式识别,模式识别,la reconnaissance de formes,reconnaissance de motifs,reconnaissance de formes,パターン認識,パターン認識,パターン認識,распознавание образов,распознавание образов,распознавание образов
3279,pattern summarization,تلخيص النمط,تلخيص الأنماط,تلخيص الأنماط,模式总结,模式摘要,模式总结,résumé du modèle,résumé des motifs,résumé de motifs,パターンの要約,"""['データベースD = {t1, t2, . . . , tn}から抽出されたパターンF = {α1, α2, . . . , αm}が与えられた場合、パターンの要約はパターンセットFに基づいてK個のパターンプロファイルを見つけることです。','私たちの知識の",パターン要約,обобщение шаблонов,суммаризация шаблонов,обобщение шаблонов
3280,pattern-verbalizer pair,زوج النمط اللفظي,زوج جامع-نمط,زوج من نمط-صياغة,模式-语言器对,模式-语言化器对,模式-说明符对,paire modèle-verbaliseur,paire modèle-verbalisateur,paire modèle-verbalisateur,パターンとバーバライザーのペア,パターン-言語化ペア (PVP),パターン-言語化ペア,пара шаблон-вербализатор,пара шаблон-высказывание,шаблон-вербализатор пара
3281,payoff function,وظيفة الدفع,وظيفة العائدية,دالة المكافأة,收益函数,支付函数,收益函数,fonction de paiement,fonction de gain,fonction de paiement,ペイオフ関数,報酬関数 (ほうしゅう かんすう),報酬関数,функция выигрыша,функция выигрыша,функция выигрыша
3282,payoff matrix,مكافأة مصفوفة,مصفوفة العوائد,مصفوفة المكافأة,收益矩阵,收益矩阵,回报矩阵,matrice de gains,matrice de gains,matrice des gains,利得マトリックス,支払い行列 (shiharai gyōretsu),支払い行列,платежная матрица,матрица выплат,матрица выигрышей
3283,pedestrian detection,كشف المشاة,الكشف عن المشاة,الكشف عن المشاة,行人检测,行人检测,行人检测,détection des piétons,détection des piétons,détection de piétons,歩行者検知,歩行者検知 (ほこうしゃけんち),歩行者検出,обнаружение пешеходов,детекция пешеходов,распознавание пешеходов
3284,penalty function,وظيفة العقوبة,وظيفة العقوبة,دالة الجزاء,惩罚函数,惩罚函数 (penalty function),惩罚函数,fonction de pénalité,fonction de pénalité,fonction de pénalité,ペナルティ関数,罰則関数 (bokusoku kansu),罰則関数,штрафная функция,функция штрафов,функция штрафа
3285,penalty parameter,معلمة العقوبة,معامل العقوبة,معامل الجزاء,惩罚参数,惩罚参数,惩罚参数,paramètre de pénalité,paramètre de pénalité,paramètre de pénalité,ペナルティパラメータ,罰則パラメータ,罰則パラメータ,параметр штрафа,параметр штрафа,Штрафной параметр
3286,penalty term,مصطلح عقوبة,مصطلح العقوبة,مصطلح العقوبة,处罚期限,惩罚项,惩罚项,durée de la pénalité,terme de pénalité,terme de pénalité,罰則期間,罰則項,ペナルティ項,срок наказания,термин штрафной член,штрафной член
3287,per-pixel,لكل بكسل,لكل بكسل,تعبير مقابل للبكسل,每个像素,- 逐像素,每像素,par pixel,par pixel,par pixel,ピクセルごと,"""['我々は、ピクセル毎のクラスバランシングウェイトβを導入します。インデックスjは画像Xの画像空間次元全体を対象とします。そして、このクラスバランシングウェイトをエッジと非エッジの間の不均衡を簡単にオフセットするための方法として使用します。', '各ビデオ",ピクセル単位で,попиксельный,"""['Мы представляем вес балансировки класса β на основе термина на пиксель. Индекс j относится к пространственным измерениям изображения X. Затем мы используем этот вес балансировки класса как простой способ компенсации дисбаланса между краем и не-краем.', 'Из каждого виде",для каждого пикселя
3288,perception,تصور,الإدراك,الإدراك,洞察力,感知,感知,perception,perception,perception,感知,認識 (Ninshiki),知覚,восприятие,восприятие,восприятие
3289,perceptron algorithm,خوارزمية الإدراك الحسي,خوارزمية البرسيبترون,خوارزمية المدرِك,感知器算法,感知器算法,感知机算法,algorithme perceptron,algorithme du perceptron,algorithme de perceptron,パーセプトロンアルゴリズム,パーセプトロンアルゴリズム,パーセプトロンアルゴリズム,алгоритм перцептрона,алгоритм перцептрона,перцептронный алгоритм
3290,perceptual feature,الميزة الإدراكية,سمة إدراكية,ميزة إدراكية,知觉特征,感知特征 (perceptual feature),感知特征,caractéristique perceptuelle,caractéristique perceptuelle,caractéristique perceptuelle,知覚機能,知覚特徴 (ちかくと),知覚特徴,особенность восприятия,восприимчивые особенности,перцептивная особенность
3291,perceptual loss,فقدان الإدراك,فقدان الإدراك,خسارة إدراكية,知觉丧失,感知损失,感知损失,perte de perception,perte de la perception,perte perceptuelle,知覚の喪失,知覚損失 (chikaku sonshitsu),知覚損失,потеря восприятия,перцептивная потеря,потери восприятия
3292,perfect matching,مطابقة مثالية,- تطابق مثالي,مُطابَقَة تامَّة,完美搭配,完美匹配,完美匹配,correspondance parfaite,appariement parfait,couplage parfait,完璧なマッチング,完全マッチング,完全マッチング,идеальное соответствие,идеальное сопоставление,полное сопоставление
3293,performance difference lemma,فرق الأداء ليما,- تحتوي قضية الأداء المتباين,قرينة الفرق في الأداء,性能差异引理,性能差异引理,绩效差异引理,lemme de différence de performance,lemme de différence de performance,lemme de différence de performance,性能差の補題,性能差異補題,パフォーマンス差レンマ,Лемма о разнице в производительности,лемма о разнице в производительности,Лемма о разнице производительности
3294,permutation,التقليب,تصفيق,ترتيب,排列,排列,排列,permutation,permutation,permutation,順列,置換,置換,перестановка,перестановка,перестановка
3295,permutation invariance,ثبات التقليب,عدم التغير بالترتيب,تعميم عدم التغير,排列不变性,置换不变性,排列不变性,invariance par permutation,invariance par permutation,invariance par permutation,順列不変性,順列不変性 (Junretsu fuhen-sei),置換不変性,инвариантность перестановок,инвариантность перестановки,инвариантность перестановки
3296,permutation matrix,مصفوفة التقليب,مصفوفة التبديل,مصفوفة التبديل,置换矩阵,置换矩阵,置换矩阵,matrice de permutation,matrice de permutation,matrice de permutation,順列行列,順列行列 (junretsu gyōretsu),置換行列,матрица перестановок,матрица перестановки,матрица перестановки
3297,permutation test,اختبار التقليب,اختبار التصاعد,اختبار التبديل,排列检验,排列检验,置换检验,essai de permutation,test de permutation,test de permutation,順列テスト,置換検定,置換検定,тест на перестановку,тест перестановки,Тест перестановки
3298,permutohedral lattice,شعرية permutohedra,الشبكة الثلاثية البديلة,شبكة متعددة الأوجه,置换面体晶格,排列六面体格点,排列四面体格子,réseau permutoédrique,treillis permutoédral,Treillis permuatohédrique,順六面体格子,ペルムトヒーダル格子,多面体格子,пермутоэдрическая решетка,пермутационная решетка,Решетка Перматоэдра
3299,perplexity,الحيرة,الارتباك,حَيْرة,困惑,困惑度,困惑度,perplexité,perplexité,perplexité,困惑,複雑さ,混乱,недоумение,затруднительность,запутанность
3300,perplexity score,درجة الحيرة,نقاط الإرباك,درجة الحيرة,困惑度分数,困惑分数,困惑度分数,score de perplexité,- Score de perplexité,score de perplexité,困惑スコア,パープレキシティースコア (Perplexity score),混乱スコア,оценка недоумения,оценка недоуменности,оценка сложности
3301,perspective projection,منظور الإسقاط,التصوير النظوري,التقاط المنظور,透视投影,透视投影,透视投影,projection en perspective,projection en perspective,projection en perspective,透視投影,透視投影,遠近法射影,перспективная проекция,перспективная проекция,перспективная проекция
3302,perspective projection matrix,مصفوفة إسقاط المنظور,مصفوفة الإسقاط النظري من منظور المرء,مصفوفة إسقاط المنظور,透视投影矩阵,透视投影矩阵,透视投影矩阵,matrice de projection en perspective,matrice de projection en perspective,matrice de projection perspective,透視投影行列,透視投影行列,遠近投影行列,матрица перспективной проекции,матрица перспективной проекции,перспективная проекционная матрица
3303,perturbation,اضطراب,اضطراب,اضطراب,扰动,"""[""通过对给定输入进行检查，可以确保在l p (1)-范数（其中1是l p -范数球的半径）范围内没有扰动可以改变模型的预测结果。"", '使用这种攻击，即使我们只在一个示例被错误分类10次中的10次时才认为攻击成功，我们也可以实现100%的有针对性攻击成功率，并将分类器的",扰动,perturbation,perturbation,perturbation,摂動,摂動,摂動,возмущение,возмущение,возмущение
3304,perturbation analysis,تحليل الاضطراب,تحليل الاضطرابات,تحليل الاضطراب,扰动分析,扰动分析,扰动分析,analyse des perturbations,- Analyse de perturbation,analyse des perturbations,摂動解析,摂動解析 (Sekidou kaiseki),摂動解析,анализ возмущений,анализ возмущений,анализ возмущений
3305,perturbation variance,تباين الاضطراب,تباين الاضطراب,تغاير الاضطراب,扰动方差,扰动方差,扰动方差,variance de perturbation,- Variance de perturbation,variance de perturbation,摂動分散,乱れ分散,摂動分散 (shoudobunsan),дисперсия возмущения,вариация возмущения,возмущение дисперсия
3306,phase retrieval,استرجاع المرحلة,استرداد المرحلة,استرجاع الطور,相位检索,相位恢复,相位恢复,récupération de phase,récupération de phase,restitution de phase,位相回復,位相回復,位相復元,фазовый поиск,фазовое восстановление,восстановление фазы
3307,phoneme,صوت,صوتية,وحدة صوتية,音素,音位,音素,phonème,phonème,phonème,音素,音素,音素,фонема,фонема,фонема
3308,phoneme segmentation,تجزئة الصوت,تقسيم الصوتيات,تجزئة الفونيم,音素分割,音素分割 (phoneme segmentation),音素分割,segmentation des phonèmes,segmentation des phonèmes,segmentation des phonèmes,音素のセグメンテーション,音素分割 (onso bunkatsu),音素セグメンテーション,сегментация фонем,сегментация фонем,фонемная сегментация
3309,photoconsistency,الاتساق الضوئي,تماسك الصورة,توافق الضوء,光一致性,"""['本文中的数据项是一个标准的光一致性项，形式为\n E photo (D) = x N i=1 f I π i (x, D(x)) − I 0 (x), V i x (2) \n'， '其中E photo 测量了在像素(x, y)处的光一致性偏差，E texture测量了周围纹理块的先验可能性。根据",光照一致性,photocohérence,photoconsistance,photocohérence,光一貫性,写真整合性 (shashin seigousei),写真一貫性,фотоконсистенция,фотоконсистентность,фотопостоянство
3310,photometric consistency,الاتساق الضوئي,الاتساق الضوئي,اتساق القياس الضوئي,光度一致性,光度一致性,光度一致性,cohérence photométrique,cohérence photométrique,cohérence photométrique,測光の一貫性,光度一貫性 (koudo ikanssei),写真測定の一貫性,фотометрическая консистенция,фотометрическая согласованность,фотометрическая согласованность
3311,photometric error,خطأ ضوئي,"""['بدءًا من تقدير أولي Φ، لكل خطوة زمنية t نقوم أولاً بإستخراج الشبكة المثلثية ∂Ω t L وتقليل الخطأ الفوتومتري E. نستخدم معدلات E لتعريف حقل التدفق ك",خطأ فوتومتري,光度误差,光度误差,光度误差,erreur photométrique,erreur photométrique,erreur photométrique,測光誤差,光度誤差 (koudo gosa),光度誤差,фотометрическая ошибка,фотометрическая ошибка,фотометрическая ошибка
3312,photometric loss,الخسارة الضوئية,الخسارة الضوئية,الخسارة الفوتومترية,光度损失,光度损失,光度损失,perte photométrique,perte photométrique,perte photométrique,測光損失,光度損失 (koudo sonshitsu),光度損失,фотометрические потери,фотометрический убыток,фотометрическая потеря
3313,photometric stereo,ستيريو الضوئية,"""['إنه أيضًا عامل رئيسي يمنع استخدام تقنيات الضوء المنظم بشكل أوسع، التي تفترض في الغالب نقل الضوء المباشر أو منخفض التردد (على سبيل المثال، المسح بالليزر ثل",استيريو فوتومتري,光度立体,"""['它也是阻碍结构光技术更广泛应用的一个重要因素，这些技术在很大程度上假设直接或低频光传输（例如3D激光扫描[3,4]、主动三角测量[5,6]和光度立体[7]）。',
'所有这些线索都在计算机视觉领域得",光度立体测量,stéréo photométrique,stéréophotométrique,stéréophotométrie,測光ステレオ,フォトメトリックステレオ,光度立体法,фотометрическое стерео,фотометрическая стереофотосъемка,фотометрическая стереосъемка
3314,phrase structure tree,شجرة هيكل العبارة,شجرة بنية العبارة,شجرة بنية العبارة,短语结构树,短语结构树,短语结构树,arbre de structure de phrase,arbre de structure de phrase,arbre syntaxique,フレーズ構造ツリー,フレーズ構造木 (Phrase Structure Tree),句構造木,Дерево структуры фраз,дерево структуры фраз,древовидная структура фразы
3315,phrase table,جدول العبارات,جدول العبارات,‫جدول العبارات‬,短语表,短语表,短语表,tableau d'expressions,- Table de phrases,table de traductions,フレーズテーブル,フレーズテーブル,フレーズテーブル,таблица фраз,таблица фраз,таблица фраз
3316,piecewise linear,خطية قطعة,قطعي الخطية,خطي متقطع,分段线性,分段线性,分段线性,linéaire par morceaux,linéaire par morceaux,linéaire par morceaux,区分的線形,区分線形,分数線形,кусочно-линейный,кусочно-линейный,кусочно-линейный
3317,piecewise planar,مستو قطعة,مستويات مكونة,مجزأ مستوي,分段平面,分段平面,分段平面的,plan par morceaux,planaire morcelé,par morceaux planaires,区分的平面,"""['我々は、ピクセルレベルに戻り、ピクセルをセグメントに割り当て直すことで、スーパーピクセルの離散化に起因するアーティファクトを除去することでこれに対処します。また、セグメントおよびピクセルレベルで明示的な遮蔽推論を",部分的平面,кусочно-плоский,кусочно-плоский,кусочно-плоский
3318,pipeline,خط انابيب,الأنبوبية,النظام المتسلسل,管道,管道,流程,pipeline,pipeline,pipeline → pipeline,パイプライン,パイプライン,パイプライン,трубопровод,конвейер,конвейер
3319,pixel,بكسل,بيكسل,بكسل,像素,像素,像素,pixels,pixel,pixel,ピクセル,ピクセル,ピクセル,пиксель,- Пиксель,пиксель
3320,pixel labeling,وضع العلامات بكسل,وسم البكسل,وصم البكسل,像素标记,像素标记,像素标注,étiquetage des pixels,étiquetage de pixels,Étiquetage de pixel,ピクセルのラベリング,ピクセルラベリング,ピクセルラベリング,маркировка пикселей,маркировка пикселей,разметка пикселей
3321,pixel-level,على مستوى البكسل,- تسمية بالبكسل,مستوى البكسل,像素级,像素级,像素级,au niveau du pixel,niveau de pixel,niveau des pixels,ピクセルレベル,ピクセルレベル,ピクセルレベル,уровень пикселей,уровень пикселя,пиксельный уровень
3322,pixel-wise,من حيث البكسل,بالأبعاد بيكسلية,حسب النقطة,逐像素,像素级,像素级别的,au niveau des pixels,pixel-par-pixel,par pixel,ピクセル単位で,ピクセル単位,ピクセル単位,попиксельно,пиксель-в-пиксель (pixel-wise),пиксельно
3323,place recognition,التعرف على المكان,التعرف على المكان,تعرف المكان,地点识别,地点识别,场景识别,reconnaissance de lieu,reconnaissance des lieux,reconnaissance de lieux,場所の認識,場所認識 (basho ninshiki),場所認識,признание места,"""['Более того, обычно они ограничены небольшими средами и низким уровнем шума лазерных сканирований. На более крупном масштабе методы распознавания мест локализуют [2,11,16,24] или категоризируют [22,23,27] изображение",распознавание местоположения
3324,placeholder,العنصر النائب,مكان حجز,عنصر نائب,占位符,占位符,占位符,espace réservé,espace réservé,marqueur de position,プレースホルダー,プレースホルダー,プレースホルダー,заполнитель,заполнитель,заполнитель
3325,planning,تخطيط,التخطيط,التخطيط,规划,规划 (guīhuà),规划,planification,planification,planification,計画,計画 (けいかく),計画,планирование,- Планирование,планирование
3326,planning problem,مشكلة التخطيط,مشكلة التخطيط,مشكلة التخطيط,规划问题,规划问题,规划问题,problème de planification,problème de planification,problème de planification,計画の問題,計画問題 (けいかくもんだい),計画問題,проблема планирования,проблема планирования,задача планирования
3327,planning task,مهمة التخطيط,مهمة التخطيط,مهمة تخطيط,规划任务,计划任务,规划任务,tâche de planification,Tâche de planification,tâche de planification,計画タスク,計画タスク,計画問題,задача планирования,планирование задачи,задача планирования
3328,platt scaling,تحجيم بلات,"""بينما تقترب من الهدف، تنتج طريقتنا دائمًا ثقة أعلى في الهدف الصحيح مع انخفاض التباين. جربنا argmax وتسوية بلات [17] لأداء التنبؤ متعدد الفئات مع MMED؛ أعطى",صحيح مقياس Platt,普拉特缩放,Platt缩放,Platt缩放,mise à l'échelle plat,mise à l'échelle de Platt,Mise à l'échelle de Platt,プラットスケーリング,プラットスケーリング (platt scaling),プラットスケーリング,Платт-масштабирование,масштабирование Платта,Масштабирование Платта
3329,plug-in estimator,مقدر المكونات,مقدر مكون إضافي,مقدر مُدخَل,插件估计器,插件估计器,插值估计量,estimateur plug-in,estimateur plug-in,estimateur plug-in,プラグイン推定ツール,プラグイン推定器,プラグイン推定量,подключаемый модуль оценки,подключаемый оценщик,вставной оценщик
3330,pobj,com.pobj,كائن المرفوض,مفعول به للجار,普吉,宾语 (pobj),介词宾语,pobj,pobj,objet de préposition,ポルノ,pobj,前置目的語,побж,pobj,прямое дополнение
3331,point cloud,سحابة نقطة,سحابة النقاط,سحابة النقاط,点云,点云,点云,nuage de points,nuage de points,nuage de points,点群,ポイントクラウド,点群,облако точек,облако точек,облако точек
3332,point correspondence,مراسلات النقطة,مطابقة النقاط,نقاط التوافق,点对应,点对应,点对应关系,correspondance ponctuelle,- Correspondance de points,correspondance de points,ポイント対応,ポイント対応,点対応,точечное соответствие,соответствие точек,точка соответствия
3333,point estimate,تقدير النقطة,التقدير النقطي,تقدير نقطي,点估计,点估计,点估计,estimation ponctuelle,estimation ponctuelle,Estimation ponctuelle,ポイント推定,ポイント推定,点推定,точечная оценка,точечная оценка,точечная оценка
3334,point match,مباراة نقطة,مطابقة النقاط,مطابقة نقطة,点赛,点匹配,点匹配,match de points,correspondance de points,correspondance de points,ポイントマッチ,ポイントマッチ,点の対応付け,матч по очкам,точечное сопоставление,точка соответствия
3335,pointwise,بشكل نقطي,نقطيّا,ابشكل نقطي,逐点,逐点的,逐点,ponctuellement,ponctuel,dépendant du point,点的に,"""['選好を表現する  ポイント単位または分布選好を表現するには、分布は制約() メソッドをサポートします。これは、特徴ϕ i (x)とその対応するモーメントμ i のリストを与えられると、制約を尊重しながら元のモデルから最小限に逸",点ごと,точечно,поэлементно,точечно
3336,pointwise Mutual Information,معلومات متبادلة نقطية,معلومات التبادل المتبادل نقطيًا,المعلومات المتبادلة النقطية,逐点互信息,点对点互信息,点互信息,Information mutuelle ponctuelle,Information mutuelle ponctuelle,Information Mutuelle Ponctuelle,点ごとの相互情報,点ごとの相互情報量,相互情報量,точечная взаимная информация,Точечная взаимная информация,взаимная информация по точкам
3337,pointwise multiplication,الضرب نقطيا,الضرب النقطي,تضرب نقطي,逐点乘法,逐点乘积,逐点相乘,multiplication ponctuelle,multiplication ponctuelle,multiplication ponctuelle,点ごとの乗算,点ごとの乗算,要素積,поточечное умножение,поэлементное умножение,точечное умножение
3338,poisson distribution,توزيع السم,التوزيع البواسون,توزيع بواسون,泊松分布,泊松分布,泊松分布,distribution de poissons,distribution de Poisson,distribution de Poisson,ポアソン分布,ポアソン分布,ポアソン分布,распределение Пуассона,распределение Пуассона,распределение Пуассона
3339,poisson point process,عملية نقطة بواسون,عملية نقطية بواسون,عملية نقطة بواسون,泊松点过程,泊松点过程,泊松点过程,processus de point de poisson,processus de points de Poisson,processus de Poisson ponctuel,ポアソン点プロセス,ポアソン点過程,ポアソン点過程,процесс точки Пуассона,Пуассоновский точечный процесс,Пуассоновский точечный процесс
3340,poisson random variable,بواسون متغير عشوائي,متغير عشوائي بواسون,متغير عشوائي بواسوني,泊松随机变量,泊松随机变量,泊松随机变量,variable aléatoire poisson,variable aléatoire de Poisson,variable aléatoire de Poisson,ポアソン確率変数,ポアソン確率変数,ポアソン確率変数,случайная величина Пуассона,- Пуассоновская случайная величина,случайная величина Пуассона
3341,poisson rate,معدل بواسون,معدل بواسون,معدل بواسون,泊松率,泊松速率,泊松率,taux de poisson,taux de Poisson,taux de Poisson,ポアソン率,ポアソン率,ポアソン率,коэффициент Пуассона,Пуассоновская скорость,вероятность Пуассона
3342,policy,سياسة,سياسة,سياسة,政策,政策,策略,politique,politique,politique,ポリシー,ポリシー,方針,политика,политика,политика
3343,policy class,فئة السياسة,صنف السياسة,فئة السياسات,政策类,策略类,策略类,classe de politique,classe de politique,classe de politiques,ポリシークラス,方針クラス,方針クラス,класс политики,класс политики,класс политик
3344,policy distribution,توزيع السياسات,توزيع السياسة,توزيع السياسة,政策分配,政策分配,策略分布,répartition des politiques,distribution de politique,distribution de politique,ポリシーの配布,ポリシー分布,方策分布,распределение политики,распределение стратегии,распределение политики
3345,policy entropy,انتروبيا السياسة,الشمولية السياسية,سعة السياسة,政策熵,策略熵,策略熵,entropie politique,- Entropie de politique,entropie de la politique,ポリシーのエントロピー,ポリシーエントロピー,方策エントロピー,политическая энтропия,энтропия политики,политропия
3346,policy evaluation,تقييم السياسات,تقييم السياسات,تقييم السياسة,政策评估,政策评估 (policy evaluation),策略评估,évaluation des politiques,évaluation de politique,évaluation de la politique,政策評価,方針評価 (policy evaluation),方策評価,оценка политики,оценка политики,оценка политики
3347,policy gradient,التدرج السياسي,التدرج السياسي,تدرج السياسة,政策梯度,策略梯度 (policy gradient),策略梯度,gradient politique,gradient de politique,gradient de politique,政策の勾配,方策勾配 (policy gradient),方針勾配,политический градиент,градиент политики,градиент политики
3348,policy gradient algorithm,خوارزمية تدرج السياسة,- تقنية تدرج السياسة,خوارزمية درجة السياسة,策略梯度算法,政策梯度算法,策略梯度算法,algorithme de gradient politique,algorithme de gradient de politique,algorithme de gradient de politique,ポリシー勾配アルゴリズム,ポリシーグラディエントアルゴリズム (porishī guradianto arugorizumu),方策勾配アルゴリズム,алгоритм градиента политики,алгоритм градиента политики,алгоритм градиента политики
3349,policy gradient estimator,مقدر تدرج السياسة,مقدر تدرج السياسات الفرعية,مقدر درجة السياسة,策略梯度估计器,策略梯度估计器 (policy gradient estimator),策略梯度估计器,estimateur de gradient politique,estimateur de gradient de politique,estimateur de gradient de politique,ポリシー勾配推定器,方策勾配推定子,ポリシー勾配推定器,оценщик градиента политики,оценщик градиента политики,оценщик градиента политики
3350,policy gradient method,طريقة التدرج في السياسة,طريقة التدرج السياسية,طريقة تدرج السياسة,政策梯度法,政策梯度方法 (policy gradient method),策略梯度方法,méthode du gradient politique,méthode de gradient de politique,méthode de gradient de politique,ポリシー勾配法,ポリシーグラディエント法,方策勾配法,метод политического градиента,метод градиента политики,метод градиента политики
3351,policy gradient theorem,نظرية التدرج السياسي,نظرية تدرج السياسات,نظرية تدرج السياسة,政策梯度定理,策略梯度定理 (policy gradient theorem),策略梯度定理,théorème du gradient politique,théorème du gradient de la politique,théorème du gradient de politique,政策勾配定理,ポリシーグラディエント定理,方策勾配定理,теорема о политическом градиенте,теорема градиента политики,теорема градиента политики
3352,policy improvement,تحسين السياسات,تحسين السياسة,تحسين السياسة,政策改进,政策改进,策略改进,amélioration des politiques,amélioration de la politique,amélioration de la politique,政策改善,ポリシー改善,方策改善,улучшение политики,улучшение политики,улучшение политики
3353,policy iteration,تكرار السياسة,عملية التدريب على السياسات,تَكْرار السِّياسَة,策略迭代,政策迭代,策略迭代,itération de politique,itération de la politique,itération de politique,ポリシーの反復,ポリシーイテレーション,ポリシー反復,итерация политики,политика итерации,итерация политики
3354,policy learning,تعلم السياسات,تعلم السياسات,تعلم السياسات,政策学习,政策学习 (policy learning),策略学习,apprentissage politique,apprentissage de politique,apprentissage de politique,政策学習,ポリシー学習 (ポリシーがくしゅう),方策学習,изучение политики,обучение политике,обучение политике
3355,policy network,شبكة السياسة,شبكة السياسات,شبكة السياسة,政策网络,策略网络 (policy network),策略网络,réseau politique,- Réseau de politiques,réseau de politique,政策ネットワーク,ポリシーネットワーク (polishīnettowāku),ポリシーネットワーク,политическая сеть,"""['Мы обучаем сеть стратегии, зависящую от языка, которая принимает на вход необработанные пиксели и предсказывает дискретное управление. Стратегия обучается с использованием алгоритма PPO на наградах MINECLIP. В каждом эпизоде агенту предлагается языковая цель, и",сеть политик
3356,policy optimization,تحسين السياسة,أمثلة على تحسين السياسات,تحسين السياسة,政策优化,政策优化,策略优化,optimisation des politiques,optimisation de politique,optimisation des politiques,ポリシーの最適化,方針最適化,方策最適化,оптимизация политики,оптимизация политики,оптимизация политики
3357,policy parameter,معلمة السياسة,معلمات السياسة,معامل السياسة,策略参数,政策参数,策略参数,paramètre de stratégie,paramètre de politique,paramètres de politique,ポリシーパラメータ,ポリシーパラメータ,ポリシーパラメーター,параметр политики,параметр политики,параметр политики
3358,policy representation,تمثيل السياسة,تمثيل السياسة,تمثيل السياسة,政策代表,政策表示,策略表示,représentation politique,représentation de la politique,Représentation des politiques,政策の表明,方針表現,方策表現,политическое представительство,представление политики,Представление политики
3359,policy sketch,رسم السياسة,المخطط السياسي,رسم السياسة,政策草图,政策草案 (policy sketch),策略草图,esquisse de politique,ébauche de politique,ébauche de politique,政策スケッチ,方針スケッチ,方針概要,очерк политики,эскиз политики,эскиз политики
3360,policy space,مساحة السياسة,مساحة السياسة,فضاء السياسة,政策空间,政策空间,策略空间,espace politique,espace des politiques,espace des politiques,政策空間,ポリシースペース,方針空間,политическое пространство,пространство стратегий,пространство политик
3361,polygon mesh,شبكة مضلعة,شبكة مضلعات,شبكة مضلعات,多边形网格,多边形网格,多边形网格,maillage polygonal,maillage de polygones,maillage polygonal,ポリゴンメッシュ,ポリゴンメッシュ,ポリゴンメッシュ,полигональная сетка,многоугольная сетка,Полигональная сетка
3362,polylog,polylog,متعدد اللوغاريتمات,شرطية متعددة الحدود,多对数,多对数,多对数函数,polylogue,polylog,polylogk,ポリログ,ポリログ,ポリログ,полилог,"""['σ p = 1 √ dpolylog(k) и γ ≤ 1 k ) p∈[P ] | v j, , ξ p | ≤ O(σ p • s + γk √ d • P ) O(σ p • P ) \n', 'Теперь, для каждого (X, y) ∈ D s , с вероятностью не менее 1 − e −Ω(log 2 k) , пусть = (X), мы имеем (см. У",полилог
3363,polylogarithmic,متعدد اللوغاريتمي,مضاد اللوغاريتمية,ذو لوغاريتمات متعددة,多对数,多对数级的,多对数因子,polylogarithmique,polylogarithmique,polylogarithmique,多対数,多対数的 (tataisū-teki),多重対数的,полилогарифмический,полилогарифмический,полилогарифмическим
3364,polynomial,متعدد الحدود,- متعددة الحدود,متعدد حدود,多项式,多项式,多项式,polynôme,polynôme,polynôme,多項式,- 多項式,多項式,полиномиальный,"""['Шаг 1 требует экспоненциальное (многочлен в данных) время и не увеличивает максимальный размер правила. Таким образом, Шаг 2 является недетерминированным экспоненциальным (многочлен в данных), а Шаг 3 требует экспоненциального (многочлен в данных) времени для решения системы л",многочлен
3365,polynomial delay,تأخير متعدد الحدود,التأخير الجبري,تأخير متعدد الحدود,多项式延迟,多项式延迟,多项式延迟,retard polynomial,retard polynomial,retard polynomial,多項式遅延,多項式遅延 (tansū chien),多項式遅延,полиномиальная задержка,полиномиальная задержка,полиномиальная задержка
3366,polynomial kernel,نواة متعددة الحدود,نواة متعددة الحدود,نواة حدودية,多项式核,多项式核,多项式核,noyau polynomial,noyau polynomial,noyau polynomial,多項式カーネル,多項式カーネル,多項式カーネル,полиномиальное ядро,полиномиальное ядро,ядро многочлена
3367,polynomial time,وقت البولينمال,(1) إن مشكلتنا صعبة NP في تقديرها بدقة ترتيبية تكون أقل من O(|T | 1−ε ) لأي ε > 0 في زمن متعدد الحدود؛ (2) يكون قي,زمن متعدد الحدود,多项式时间,多项式时间,多项式时间,Temps polynomial,temps polynomial,temps polynomial,多項式時間,多項式時間,多項式時間 (たげんしじかん),полиномиальное время,полиномиальное время,полиномиальное время
3368,polynomial time algorithm,خوارزمية زمنية متعددة الحدود,خوارزمية زمنية متعددة,خوارزمية بدرجة كثيرة حدود الزمن,多项式时间算法,多项式时间算法,多项式时间算法,algorithme de temps polynomial,algorithme en temps polynomial,algorithme en temps polynomial,多項式時間アルゴリズム,多項式時間アルゴリズム (たこうしきじかんアルゴリズム),多項式時間アルゴリズム,алгоритм с полиномиальным временем,алгоритм полиномиального времени,алгоритм полиномиального времени
3369,pool-base active learning,التعلم النشط القائم على التجمع,التعلم النشط القائم على التجميعات,التعلم النشط القائم على الخزانة,基于池的主动学习,基于池的主动学习 (pool-base active learning),基于池的主动学习,apprentissage actif en pool,Apprentissage actif basé sur le pool,apprentissage actif par échantillonnage,プールベースのアクティブラーニング,プールベースアクティブラーニング,プールベースアクティブラーニング,активное обучение в бассейне,пул-базовое активное обучение,Активное обучение на основе пула
3370,pooling layer,طبقة التجميع,الطبقة الاستدعاء,طبقة التجميع,池化层,汇聚层,池化层,couche de regroupement,- Couche de mise en commun,couche de pooling,プーリング層,プーリング層,プーリング層,слой объединения,пул-слои,слой агрегирования
3371,pooling operation,عملية التجميع,عملية التجميع,عملية التجميع,池化操作,池化操作,池化操作,opération de mutualisation,opération de regroupement,opération de poolage,プーリング操作,プーリング操作,プーリング操作,операция объединения,- Пулинг операция,операция пулинга
3372,pose estimation,تقدير الموقف,تقدير الوضعية,تقدير الوضعية,姿态估计,姿态估计,姿态估计,estimation de la pose,estimation de la pose,estimation de la pose,姿勢推定,ポーズ推定,姿勢推定,оценка позы,оценка позы,оценка позы
3373,pose parameter,المعلمة تشكل,معلمات الوضع,معلمات الوضع,位姿参数,姿态参数,姿态参数,paramètre de pose,paramètre de pose,paramètres de pose,ポーズパラメータ,姿勢パラメータ (shisei parameta),ポーズパラメータ,параметр позы,параметр позы,параметры позы
3374,pose prior,تشكل قبل,الموقف الأولي,قيد الوضعية,先摆姿势,姿势先验,姿态先验,poser avant,prior de pose,a priori de pose,前のポーズ,ポーズ事前確率,姿勢事前分布,позировать перед,приоритет позы,позная предпосылка
3375,pose space,مساحة تشكل,مساحة وضعية,فضاء الوضعية,姿势空间,姿态空间,姿态空间,espace de pose,- Espace de pose,espace de poses,ポーズスペース,姿勢空間 (しせいくうかん),姿勢空間,позировать пространство,пространство позы,пространство позиций
3376,position bias,انحياز الموقف,الانحياز الوظيفي,تحيز الموضع,位置偏差,位置偏差,位置偏差,biais de position,biais de position,biais de position,位置バイアス,位置バイアス,位置バイアス,предвзятость позиции,смещение позиции,смещение позиции
3377,position embedding,تضمين الموقف,تضمين الموقع,موضع التضمين,位置嵌入,位置嵌入,位置嵌入,intégration de position,intégration de position,position intégrée,位置の埋め込み,位置エンベッディング,位置埋め込み,встраивание позиции,позиционное вложение,позиционное встраивание
3378,positional bias,التحيز الموضعي,الانحياز الموضعي,تحيز المواقع,位置偏差,位置偏见,位置偏差,biais de position,biais de positionnement,biais positionnel,位置の偏り,位置バイアス,位置バイアス,позиционная предвзятость,позиционный биас,позиционная предвзятость
3379,positional embedding,التضمين الموضعي,التضمين الموضعي,تضمين موضعي,位置嵌入,位置嵌入,位置嵌入,intégration positionnelle,incrustation de position,encastrement positionnel,位置埋め込み,位置の埋め込み (いちのうめこみ),位置埋め込み,позиционное вложение,позиционное вложение,позиционное встраивание
3380,positional encoding,الترميز الموضعي,ترميز المواقع,ترميز موضعي,位置编码,位置编码,位置编码,codage positionnel,encodage de position,codage de position,位置エンコーディング,位置符号化 (いち ふごうか),位置エンコーディング,позиционное кодирование,позиционное кодирование,позиционное кодирование
3381,positive definite,إيجابية محددة,إيجابي محدد,موجب محدد,正定,正定,正定,définie positive,définie positive,définie positive,正定値,正定値 (sei teitei),正定値,положительно определенный,положительно определенный (PD),положительно определенный
3382,positive pair,زوج إيجابي,زوج إيجابي,زوج إيجابي,正对,正向配对,正对偶,paire positive,paire positive,paires positives,ポジティブペア,ポジティブペア (positive pair),正サンプル対,положительная пара,позитивная пара,положительные пары
3383,positive semidefinite,إيجابية شبه محددة,نصف الإيجابيات,متسامح موجب,正半定,正半定量,半正定,semi-défini positif,positif semi-défini,semi-défini positif,正の半定値,"""['さらに、類似行列Wtが正定値である場合、αD \n − 1 2 t WtD − 1 2 t + βXt−1X T t−1も正定値であるため、D − 1 2 t WtD − 1 2 t \n とXt−1X T t−1はともに正定値であるからです。', 'この再定式化",正値半等式,положительный полуопределенный,положительно полуопределенный,положительно полуопределенный
3384,positive semidefinite kernel,نواة شبه محددة إيجابية,نواة نصف معينة إيجابية,نواة شبه محددة موجبة,正半定核,正半定核,正半正定核,noyau semi-défini positif,noyau semi-défini positif,Noyau semi-défini positif,正の半定値カーネル,正定値カーネル,正定値カーネル,положительное полуопределенное ядро,положительное полуопределенное ядро,положительно полуопределенное ядро
3385,positive semidefinite matrix,مصفوفة شبه محددة إيجابية,مصفوفة نصف معرفة موجبة,مصفوفة شبه محددة موجبة,半正定矩阵,半正定矩阵,正半正定矩阵,matrice semi-définie positive,matrice semi-définie positive,matrice semi-définie positive,正の半定値行列,正定値行列 (seitei-chi gyōretsu),正値半正定行列,положительная полуопределенная матрица,положительная полуопределенная матрица,положительно полуопределённая матрица
3386,post-editing,ما بعد التحرير,مراجعة ما بعد التحرير,التحرير اللاحق,后期编辑,后处理,人工后编辑,post-édition,post-édition,post-édition,ポストエディット,ポスト編集,事後編集,постредактирование,постредактирование,пост-редактирование
3387,post-hoc,ما بعد المخصص,ما بعد الفعلية,بعدي,事后,后验,事后的,post-hoc,post-hoc,post-hoc,事後的な,ポストホック,事後的な,постфактум,пост-хок,экспост
3388,post-hoc analysis,آخر تحليل خاص,التحليل ما بعد التجربة,تحليل لاحق,事后分析,事后分析,事后分析,analyse post-hoc,analyse post-hoc,analyse a posteriori,事後分析,事後分析,事後分析,апостериорный анализ,пост-хок анализ,Постанализ
3389,post-processing,المعالجة البعدية,- التصحيح اللاحق,معالجة لاحقة,后期处理,后处理,后处理,post-traitement,post-traitement,post-traitement,後処理,ポストプロセッシング,後処理,Постобработка,постобработка,постобработка
3390,posterior,الخلفي,التوزيع الشرطي,لاحقة,后部,后验,后验,postérieur,postérieur,postérieure,後部,事後分布,事後分布,задний,постериорный,апостериорный
3391,posterior approximation,التقريب الخلفي,التقريب الخلفي,تقريب اللاحق,后验近似,后验逼近,后验近似,approximation postérieure,approximation postérieure,approximation postérieure,事後近似,事後近似 (jigou kinji),事後近似,апостериорное приближение,постериорное приближение,аппроксимация апостериорного распределения
3392,posterior density,الكثافة الخلفية,كثافة الاحتمال الشرطي,كثافة لاحقة,后密度,后验密度,后验密度,densité postérieure,densité postérieure,densité a posteriori,事後密度,事後密度,事後密度,задняя плотность,плотность апостериорного распределения,апостериорная плотность
3393,posterior distribution,التوزيع الخلفي,التوزيع الخلفي,التوزيع البعدي,后验分布,后验式,后验分布,répartition postérieure,- Distribution postérieure,distribution a posteriori,事後分布,事後分布,事後分布,заднее распределение,апостериорное распределение,распределение апостериорной вероятности
3394,posterior entropy,الانتروبيا الخلفية,الانحباس الخلفي,عدم التأكد اللاحق,后验熵,后验熵,后验熵,entropie postérieure,Entropie postérieure,entropie a posteriori,事後エントロピー,事後エントロピー,事後エントロピー,задняя энтропия,постериорная энтропия,апостериорная энтропия
3395,posterior estimation,التقدير الخلفي,التقدير الخلفي,التقدير البعدي,后验估计,后验估计,后验估计,estimation a posteriori,estimation a posteriori,estimation a posteriori,事後推定,事後推定 (jigo su tei),事後推定,апостериорная оценка,оценка апостериорного распределения,апостериорная оценка
3396,posterior inference,الاستدلال الخلفي,الاستدلال اللاحق,الاستدلال البعدي,后验推理,后验推断,后验推理,inférence postérieure,inférence postérieure,inférence a posteriori,事後推論,事後推論,事後推論,апостериорный вывод,"""['В последующих разделах мы расширяем классические модели состояний пространства для спецификации статистической модели эволюции темы. Затем мы разрабатываем эффективные приближенные методы апостериорного вывода для определения развивающихся тем из последовательной коллекции документов.', 'Э",апостериорный вывод
3397,posterior mean,يعني الخلفي,المتوسط الخلفي,وسيط بعدي,后验平均值,后验均值,后验均值,moyenne postérieure,moyenne a posteriori,moyenne a posteriori,事後平均,事後平均,事後平均,апостериорное среднее,апостериорное среднее,задний среднее значение
3398,posterior mean function,وظيفة الوسط الخلفي,الدالة الوسطى اللاحقة,وظيفة المتوسط اللاحق,后验平均函数,后验均值函数,后验均值函数,fonction moyenne postérieure,fonction de moyenne postérieure,fonction moyenne a posteriori,事後平均関数,事後平均関数 (jigou heikin kansuu),事後平均関数,апостериорная средняя функция,функция апостериорной оценки среднего,функция апостериорного среднего
3399,posterior probability,الاحتمال المعاكس,الاحتمال الشرطي,احتمالية لاحقة,后验概率,后验概率,后验概率,probabilité postérieure,probabilité a posteriori,probabilité a posteriori,事後確率,事後確率,事後確率,апостериорная вероятность,апостериорная вероятность,вероятность апостериори
3400,posterior probability distribution,توزيع الاحتمال الخلفي,التوزيع الاحتمالي الخلفي,التوزيع الاحتمالي اللاحق,后验概率分布,后验概率分布,后验概率分布,distribution de probabilité a posteriori,- Distribution de probabilité postérieure,distribution de probabilité a posteriori,事後確率分布,事後確率分布,事後確率分布,апостериорное распределение вероятностей,апостериорное распределение вероятностей,апостериорное распределение вероятностей
3401,posterior sample,العينة الخلفية,عينات ما بعدية,عينة لاحقة,后样本,后验样本,后验样本,échantillon postérieur,échantillon postérieur,échantillon a posteriori,後部サンプル,事後サンプル,事後サンプル,задний образец,последующая выборка,послевероятностная выборка
3402,posterior variance,التباين الخلفي,التباين الخلفي,تباين لاحق,后验方差,后验方差,后验方差,variance postérieure,- Variance postérieure,variance postérieure,事後分散,事後分散,事後分散,апостериорная дисперсия,постериорная дисперсия,дисперсия апостериорного распределения
3403,potential function,وظيفة محتملة,دالة الإمكانية,دالة إمكانية,势函数,潜在函数,势函数,fonction potentielle,fonction de potentiel,fonction potentielle,ポテンシャル関数,潜在関数,ポテンシャル関数,потенциальная функция,функция потенциала,потенциальная функция
3404,potential heuristic,ارشادي محتمل,مؤشر إشاري محتمل,ابتكار إرشادي محتمل,潜在的启发式,潜在启发式,潜在启发式,heuristique potentielle,heuristique potentielle,heuristique potentielle,潜在的なヒューリスティック,潜在ヒューリスティック,潜在的ヒューリスティック,потенциальная эвристика,потенциальный эвристический,потенциальная эвристика
3405,power iteration method,طريقة تكرار الطاقة,طريقة التكرار القوة,طريقة التكرار القوة,幂迭代法,幂迭代方法,幂迭代法,méthode d'itération de puissance,méthode d'itération de puissance,méthode de l'itération de la puissance,べき乗反復法,べき乗反復法,冪乗反復法,метод итерации мощности,метод итерации мощности,метод степенных итераций
3406,power law distribution,توزيع قانون القوى,توزيع قوة القانون,توزيع القانون الأسي,幂律分布,幂律分布,幂律分布,distribution de la loi de puissance,- Distribution en loi de puissance,loi de puissance,べき乗則分布,べき乗則分布,累積分布則,степенное распределение,распределение степеней (power law distribution),степенное распределение
3407,power method,طريقة الطاقة,طريقة الطاقة,طريقة القوة,幂法,幂方法,幂法,méthode de puissance,méthode de puissance,méthode de la puissance itérative,べき乗法,パワーメソッド (power method),冪乗法,энергетический метод,метод силой,метод степенных итераций
3408,pre-logit,تسجيل مسبق,ما قبل السجلات,قبل-اللوجيت,预逻辑,预处理前逻辑 (pre-logit),前逻辑值,pré-logit,pré-logits,pré-logits,プレロジット,プレログイット,前段ロジット,предлогит,предлогит,доверительные значения
3409,pre-processing,المعالجة المسبقة,المعالجة المسبقة,معالجة أولية,预处理,- 预处理,预处理,prétraitement,prétraitement,pré-traitement,前処理,「残念ながら、どの機能がまれになるかは事前にわかりません。 プリプロセスデータを使用してまれな機能を削除することは、オンライン設定では問題があります：データの追加読み取りおよび書き込みは非常に高価です。そして、いくつかの機能,前処理,предварительная обработка,предварительная обработка,предобработка
3410,pre-terminals,المحطات المسبقة,المحطات القبلية,مسبقات,预终端,预终端,预终结符,pré-terminaux,pré-terminaux,pré-terminaux,プレターミナル,予備端子,前終端記号,предтерминалы,предварительные терминалы,предтерминалы
3411,pre-train,تدريب مسبق,- ما قبل التدريب,تدريب مسبق,预训练,预训练,预训练,pré-entraînement,pré-entraînement,pré-entraîner,事前トレーニング,事前学習 (じぜんがくしゅう),事前学習,предварительная тренировка,предварительное обучение,предобучение
3412,pre-train parameter,معلمة ما قبل التدريب,- تعديل المعلمة مسبقًا,معلمات مسبقة التدريب,预训练参数,预训练参数,预训练参数,paramètre de pré-entraînement,paramètre pré-entraîné,paramètre pré-entraîné,事前トレーニングパラメータ,事前学習パラメータ,事前学習パラメータ,параметр перед поездкой,предварительно обученные параметры,предварительно обученный параметр
3413,pre-trained checkpoint,نقطة تفتيش مدربة مسبقا,نقطة فحص معدة مسبقًا,نقطة الالتقاط المدربة مسبقًا,预训练检查点,预训练检查点,预训练检查点,point de contrôle pré-entraîné,point de contrôle pré-entraîné,point de contrôle pré-entraîné,事前に訓練されたチェックポイント,事前学習済みチェックポイント,事前学習済みチェックポイント,предварительно обученный контрольно-пропускной пункт,предварительный контрольная точка,предварительно обученная контрольная точка
3414,pre-trained embedding,التضمين المدربين مسبقًا,التضمين المدرب مسبقًا,تضمين مسبق التدريب,预训练嵌入,预训练嵌入,预训练词嵌入,intégration pré-entraînée,embedding pré-entraîné,embeddings pré-entraînés,事前トレーニングされた埋め込み,事前学習埋め込み,予め学習された埋め込み,предварительно обученное внедрение,предварительно обученные вложения,предварительно обученное вложение
3415,pre-trained language model,نموذج اللغة المدربة مسبقا,نموذج لغوي مدرب مسبقا,نموذج لغوي مُسبق التدريب,预训练语言模型,预训练语言模型 (PLM),预训练语言模型,modèle de langage pré-entraîné,modèle de langue pré-entraîné,modèle de langage pré-entraîné,事前トレーニングされた言語モデル,事前学習済み言語モデル (PLM),事前トレーニング済み言語モデル,предварительно обученная языковая модель,предварительно обученная языковая модель,предобученная языковая модель
3416,pre-trained model,نموذج تم تدريبه مسبقًا,نموذج مُعد مُسبقًا,نموذج مسبق التدريب,预训练模型,预训练模型,预训练模型,modèle pré-entraîné,modèle pré-entraîné,modèle pré-entraîné,事前トレーニングされたモデル,事前学習済みモデル,事前学習済みモデル,предварительно обученная модель,предобученная модель,предобученная модель
3417,pre-trained weight,الوزن المدرب مسبقا,الأوزان المُعدة مُسبقا,أوزان مسبقة التدريب,预训练重量,预训练权重,预训练权重,poids pré-entraîné,poids pré-entraînés,poids pré-entraînés,事前に訓練された体重,事前学習重み (じぜんがくしゅう おもみ),事前学習重み,предварительно тренированный вес,"веса, предварительно обученные",предобученные веса
3418,pre-training corpus,هيئة ما قبل التدريب,المجموعة التدريبية الأولية,مدونة التدريب المسبق,预训练语料库,预训练语料库,预训练语料,corpus de pré-formation,- Corpus de pré-entraînement,corpus d'apprentissage préalable,トレーニング前コーパス,事前学習コーパス,事前学習コーパス,предтренировочный корпус,корпус предварительного обучения,корпус предварительного обучения
3419,pre-training datum,بيانات ما قبل التدريب,البيانات التمهيدية للتدريب,بيانة التدريب المسبق,预训练数据,预训练数据,预训练数据,données de pré-entraînement,donnée de pré-entraînement,donnée d'apprentissage préalable,事前トレーニングデータ,事前学習データ,事前学習データ,данные перед тренировкой,предварительные данные обучения,предварительно обученные данные
3420,pre-training objective,هدف ما قبل التدريب,هدف التدريب المسبق,هدف التدريب المسبق,预训练目标,预训练目标,预训练目标,objectif de pré-formation,objectif de pré-entraînement,objectif d'apprentissage préalable,トレーニング前の目標,"""['これは、ディープラーニング全般でよく見られるエンコーダーデコーダーアーキテクチャの振る舞いに似ている可能性がありますが、事前学習目的を通じてモノリシックアーキテクチャ内で学習されます。したがって、線形プローブを使用して生成",事前学習目的,цель предварительной подготовки,предварительная цель обучения,предварительная цель обучения
3421,pre-training task,مهمة ما قبل التدريب,مهمة التدريب المسبق,مهمة التدريب المسبق,预训练任务,预训练任务,预训练任务,tâche de pré-formation,tâche de pré-entraînement,tâche de pré-entraînement,事前トレーニングタスク,事前学習タスク (jizen gakushu task),事前学習タスク,предтренировочное задание,предварительная задача обучения,задача предварительного обучения
3422,precision,دقة,الدقة,دقة,精确,精准度,精确率,précision,- Précision,précision,精度,精度,精度,точность,Точность,точность
3423,precision matrix,مصفوفة الدقة,مصفوفة الدقة,مصفوفة الدقة,精度矩阵,精度矩阵,精度矩阵,matrice de précision,- Matrice de précision,matrice de précision,精密マトリックス,精度行列 (seido koubetsu),精密行列,прецизионная матрица,матрица точности,матрица точности
3424,precision-at-10,الدقة عند 10,الدقة في المرتبة ١٠ (P@10),الدقة-عند-10,精度为 10,精度@10 (P@10),前10位精确度,précision à 10,précision-à-10,précision-à-10,精度-at-10,精度@10,上位10件における精度,точность до 10,Точность-при-10 (P@10),точность-при-10
3425,precision-recall curve,منحنى الاسترجاع الدقيق,المنحنى التحليلي للدقة والاستحضار,منحنى الدقة والاسترجاع,精确率-召回率曲线,精确度-召回率曲线,精确率-召回率曲线,courbe précision-rappel,Courbe précision-rappel,Courbe précision-rappel,適合率-再現率曲線,適合率-再現率曲線,精度-再現率曲線,кривая точного отзыва,Кривая точности-полноты,кривая точности-полноты
3426,precision-recall graph,رسم بياني للاستدعاء الدقيق,رسم بياني للدقة والاستدعاء,منحنى الدقة والاسترجاع,精确率-召回率图,精确率-召回率图,精确率-召回率图,graphique de rappel de précision,- Graphique précision-rappel,courbe précision-rappel,適合率と再現率のグラフ,適合率-再現率グラフ,適合率再現率グラフ,график точного отзыва,график точности-полноты,кривая точности-полноты
3427,precondition,شرط مسبق,الشرط المسبق,شرط مسبق,前提,先决条件 (precondition),前置条件,condition préalable,précondition,précondition,前提条件,前提条件 (ぜんじじょうけん),前提条件,предварительное условие,предусловие,предусловие
3428,preconditioner,شرط مسبق,مسبق الشرط,مُعامِل التَّهيئة المُسبَقة,预条件子,预处理器,预条件器,préconditionneur,préconditionneur,préconditionneur,プレコンディショナー,事前処理器,前処理子,предобуславливатель,предварительная обработка,Предобусловливатель
3429,predicate,فاعل,- المحدد,مُحْمُول,谓词,述词,谓词,prédicat,prédicat,prédicat,述語,述部,述語,предикат,предикат,предикат
3430,predicate logic,المنطق المسند,منطق العامل,منطق الحمول,谓词逻辑,谓词逻辑,谓词逻辑,prédis la logique,logique des prédicats,logique des prédicats,述語論理,述語論理,項述理論,логика предикатов,предикативное исчисление,логика предикатов
3431,predicate symbol,رمز المسند,رمز الخاصية,رمز المحمول,谓词符号,谓词符号,谓词符号,symbole de prédicat,- Terme du prédicat,symbole prédicatif,述語記号,述語記号,述語記号,предикатный символ,Символ предиката,предикатный символ
3432,predicate-argument relation,العلاقة بين المسند والوسيطة,العلاقة الفعلية-المؤثرية,علاقة الموضوع-الحُجة,谓词-论元关系,谓语-论元关系,谓项-论元关系,relation prédicat-argument,- Relation prédicat-argument,relation prédicat-argument,述語と引数の関係,述語-項関係 (jutsugo-kou kankei),項目-項構造関係,отношение предикат-аргумент,отношение предикат-аргумент,отношение предикат-аргумент
3433,predicate-argument structure,هيكل الوسيطة المسند,"""['The task of paraphrasing usually consists of paraphrase pattern generation and paraphrase identification. Paraphrase pattern generation is to automatically extract semantically equivalent patterns (Lin and Pantel, 2001;Bhagat and Ravichandran, 2008) or sentences (Barzilay and Lee, 2003). Paraphrase identification is to identify whether two given sentences are a paraphrase of each other. The methods proposed so far formalized the problem as classification and used various types of features such",البنية الحجة-المحمول,谓词-论元结构,谓词论元结构,谓词论元结构,structure prédicat-argument,- Structure prédicat-argument,structure prédicat-argument,述語と引数の構造,述語-項構造,述語論項構造,структура предикат-аргумент,структура предиката-аргумент,структура предикат-аргумент
3434,prediction,تنبؤ,التنبؤ,التنبؤ,预言,预测,预测,prédiction,prédiction,prédiction,予測,予測 (よそく),予測,прогноз,прогноз,предсказание
3435,prediction accuracy,دقة التنبؤ,دقة التنبؤ,دقة التنبؤ,预测准确度,预测准确性,预测精度,précision des prédictions,précision de prédiction,précision de la prédiction,予測精度,予測精度 (Yosoku Seido),予測精度,точность прогноза,точность прогнозирования,точность предсказания
3436,prediction entropy,الانتروبيا التنبؤ,الترابط التنبؤي,عدم اليقين التنبؤي,预测熵,预测熵,预测熵,entropie de prédiction,entropie de prédiction,entropie de prédiction,予測エントロピー,予測エントロピー (PE),予測エントロピー,энтропия предсказания,Энтропия предсказаний,энтропия предсказания
3437,prediction error,خطأ في التنبؤ,خطأ التنبؤ,خطأ التنبؤ,预测误差,预测误差,预测误差,erreur de prédiction,erreur de prédiction,erreur de prédiction,予測誤差,予測誤差,予測誤差,ошибка прогноза,ошибка прогноза,ошибка предсказания
3438,prediction head,رئيس التنبؤ,رأس التنبؤ,رأس التنبؤ,预测头,预测头,预测头,tête de prédiction,- Tête de prédiction,tête de prédiction,予測ヘッド,予測ヘッド,予測ヘッド,голова предсказания,предсказательная голова,предсказывающая головка
3439,prediction invariance,ثبات التنبؤ,الثبات التنبؤي,ثبات التنبؤ,预测不变性,预测不变性,预测不变性,invariance de prédiction,invariance de prédiction,invariance des prédictions,予測の不変性,予測不変性,予測の不変性,инвариантность предсказания,предсказание инвариантности,Инвариантность прогноза
3440,prediction model,نموذج التنبؤ,نموذج التنبؤ,نموذج التنبؤ,预测模型,预测模型,预测模型,modèle de prédiction,modèle de prédiction,modèle prédictif,予測モデル,予測モデル (よそくモデル),予測モデル,модель прогнозирования,модель прогнозирования,модель прогнозирования
3441,prediction network,شبكة التنبؤ,شبكة التنبؤ,شبكة التنبؤ,预测网络,预测网络,预测网络,réseau de prédiction,réseau de prédiction,réseau de prédiction,予測ネットワーク,予測ネットワーク (yosoku nettowaku),予測ネットワーク,сеть прогнозирования,сеть прогнозирования,сеть предсказания
3442,prediction variance,تباين التنبؤ,- تباين التنبؤ,تباين التنبؤ,预测方差,预测方差,预测方差,variance de prédiction,variance de prédiction,variance de prédiction,予測の分散,予測分散 (yosoku bunsan),予測分散,дисперсия прогноза,прогнозная дисперсия,дисперсия предсказаний
3443,predictive coding,الترميز التنبؤي,الترميز التنبؤي,الترميز التنبؤي,预测编码,预测编码,预测编码,codage prédictif,codage prédictif,codage prédictif,予測コーディング,予測符号化,予測符号化,прогнозирующее кодирование,прогностическое кодирование,предиктивное кодирование
3444,predictive distribution,التوزيع التنبؤي,التوزيع التنبؤي,التوزيع التنبؤي,预测分布,预测分布,预测分布,distribution prédictive,distribution prédictive,distribution prédictive,予測分布,予測分布 (Yosoku Bunsan),予測分布,прогнозируемое распределение,предсказательное распределение,прогнозное распределение
3445,predictive likelihood,الاحتمالية التنبؤية,الاحتمالية التنبؤية,الاحتمال التنبؤي,预测可能性,预测可能性,预测可能性,vraisemblance prédictive,probabilité prédictive,vraisemblance prédictive,予測可能性,予測尤度 (yosoku yudo),予測尤度,прогнозируемая вероятность,предсказательная вероятность,предсказательная правдоподобность
3446,predictive model,النموذج التنبؤي,نموذج تنبؤي,نموذج تنبؤي,预测模型,预测模型,预测模型,modèle prédictif,Modèle prédictif,modèle prédictif,予測モデル,予測モデル (Yosoku moderu),予測モデル,прогнозная модель,предсказательная модель,предиктивная модель
3447,predictive performance,الأداء التنبؤي,الأداء التنبؤي,الأداء التنبؤي,预测性能,预测性能,预测性能,performances prédictives,- Performance prédictive,performance prédictive,予測パフォーマンス,予測性能 (Yosoku seino),予測性能,прогнозирующая производительность,Прогностическая производительность,прогностические способности
3448,predictor,متنبئ,المتنبئ,متنبئ,预测器,预测器,预测器,prédicteur,prédicteur,prédicteur,予測子,予測子,予測子,предсказатель,"""['Пусть β c,a ∈ [ln ε low , 0] будет значением параметра предсказателя для контекста c для метки a ребра. Затем предсказание контекста c определяется как \n', 'В этой статье мы впервые пытаемся проанализировать поведение неточной тренировки SSL и эмпирические эффекты нескольких",предиктор
3449,prefix,بادئة,بادئة,سابقة,字首,前缀 (qiánzhui4),前缀,préfixe,préfixe,préfixe,接頭語,接頭辞 (prefix),前缶,префикс,префикс,префикс
3450,prefix sum,مجموع البادئة,مجموع البادئة,مجموع البادئة,前缀和,前缀和,前缀和,somme de préfixe,somme préfixe,somme partielle,プレフィックスの合計,接頭込み,前方部分和,префиксная сумма,префиксная сумма,префиксная сумма
3451,prefix tree,شجرة البادئة,شجرة البادئة,شجرة البادئات,前缀树,前缀树,前缀树,arbre de préfixes,- Arbre de préfixe,arbre préfixe,プレフィックスツリー,接頭辞木 (setsumonoki),接頭辞木,дерево префиксов,префиксное дерево,префиксное дерево
3452,preimage,preimage,الصورة الأصلية,مصدر الصورة,原像,原像,原象,préimage,préimage,préimage,プリ画像,先像,前画像,прообраз,предобразование,прообраз
3453,prepositional phrase,عبارة الجر,عبارة حروف جر,جملة حرف جر,介词短语,介词短语 (prepositional phrase),介词短语,préposition,- Expression prépositionnelle,groupe prépositionnel,前置詞句,前置詞句,前置詞句,предложная фраза,предложный оборот,предложная фраза
3454,preprocessing phase,مرحلة ما قبل المعالجة,مرحلة المعالجة المسبقة,مرحلة المعالجة المسبقة,预处理阶段,预处理阶段,预处理阶段,phase de prétraitement,- Phase de prétraitement,phase de prétraitement,前処理フェーズ,前処理フェーズ (zenshori fēzu),前処理段階,этап предварительной обработки,фаза предварительной обработки,фаза предобработки
3455,presence penalty,عقوبة الحضور,عقوبة الوجود,عقوبة الحضور,存在惩罚,存在惩罚,存在惩罚度,pénalité de présence,pénalité de présence,pénalité de présence,プレゼンスペナルティ,存在ペナルティ,存在ペナルティ,штраф за присутствие,пенальти за наличие,штраф присутствия
3456,pretrained multilingual model,نموذج متعدد اللغات تم تدريبه مسبقًا,النموذج متعدد اللغات المدرب مسبقا,نموذج متعدد اللغات المسبق التدريب,预训练多语言模型,预训练多语言模型,预训练多语言模型,modèle multilingue pré-entraîné,modèle pré-entraîné multilingue,modèle multilingue pré-entraîné,事前トレーニングされた多言語モデル,事前に学習された多言語モデル,事前学習済み多言語モデル,предварительно обученная многоязычная модель,предварительно обученная мультиязычная модель,предобученная многоязычная модель
3457,primal objective function,وظيفة الهدف الأولية,دالة الهدف الأصلية,وظيفة الهدف الأساسية,原始目标函数,原始目标函数,原始目标函数,fonction objectif primordiale,fonction objectif primaire,fonction objectif primale,主目的関数,原始目的関数,原始目的関数,первичная целевая функция,первоначальная целевая функция,целевая функция
3458,primal optimization,التحسين البدائي,التحسين الأولي,تحسين أساسي,原始优化,原始优化,原始优化,optimisation primaire,optimisation primaire,optimisation primale,一次最適化,プライマル最適化,原始最適化,первичная оптимизация,прямая оптимизация,прямая оптимизация
3459,primal problem,مشكلة بدائية,المشكلة الأساسية,المشكلة الأولية,主要问题,原始问题,原始问题,problème primordial,problème primal,problème primaire,根本的な問題,原始問題,原問題,основная проблема,первичная проблема,первоначальная задача
3460,primal variable,المتغير البدائي,المتغيرات الأولية,متغيرات أساسية,原始变量,原始变量,原变量,variable primordiale,variable primaire,variable primale,主変数,原始変数 (genshi hensu),素変数,основная переменная,первичная переменная,Исходные переменные
3461,primal-dual algorithm,خوارزمية أولية مزدوجة,الخوارزمية الابتدائية-الثنائية,خوارزمية الأولي-المزدوجة,原对偶算法,原始-对偶算法,原对偶算法,algorithme primal-dual,algorithme primal-dual,algorithme primal-dual,主双対アルゴリズム,プライマル・デュアルアルゴリズム,双対アルゴリズム,первично-двойственный алгоритм,примитивно-двойной алгоритм,алгоритм прима-дуала
3462,primal-dual method,الطريقة الأولية المزدوجة,الأسلوب الأولي-ثنائي,طريقة الأصلية المقترنة,原对偶法,原始对偶法,原对偶法,méthode primale-duale,méthode primal-dual,méthode primale-duale,主双対法,一次-双対法 (ichiji-sotai-ho),原双対法,первично-двойственный метод,примитивно-дуальный метод,метод прямо-двойственный
3463,primitive,بدائية,- مبدئي,بدائية,原始,- 原始形状,基元,primitif,primitif,primitives,原生的,"""['これらの平面と凸面は、ネットワークによって学習された重みによって定義されます。最先端の方法と比較して、BSP-Netによって生成されたメッシュは、同じ数の原始体が使用された場合、特に鋭い幾何学的詳細を備えた優れた視覚的品質",基本形状,примитивный,примитивы,примитивы
3464,principal component,المكون الرئيسي,العناصر الرئيسية,مكونات رئيسية,主成分,主成分,主成分,composant principal,composante principale,composante principale,主成分,主成分 (shuseki),主成分,главный компонент,главная компонента,главная компонента
3465,principal component analysis,تحليل المكونات الرئيسية,تحليل المكونات الرئيسية,تحليل المركبات الأساسية,主成分分析,主成分分析 (PCA),主成分分析,analyse des composants principaux,analyse en composantes principales,Analyse en composantes principales,主成分分析,主成分分析,主成分分析,Анализ главных компонентов,анализ главных компонент,анализ главных компонентов
3466,prior distribution,التوزيع المسبق,التوزيع السابق,التوزيع المسبق,先验分布,先验分布,先验分布,distribution préalable,- Distribution a priori,distribution a priori,事前配布,事前分布,事前分布,предварительное распространение,априорное распределение,априорное распределение
3467,prior hyperparameter,المعلمة المفرطة السابقة,معاملات سابقة,معامل سابق,先验超参数,先验超参数,先验超参数,hyperparamètre antérieur,"""['généralisation dans la pratique ! Dans la Figure 5(c), nous avons vu que cette corrélation peut être corrigée en optimisant la précision du prior, mais en général, il n'y a pas de recette pour déterminer combien d'hyperparamètres de prior nous devrions optimiser pour garantir une corrélation positive.', 'la borne s'applique à chaque modèle individuel simultanément. Même si le logarithme peut augmenter lentement en fonction du nombre de modèles",hyperparamètre a priori,前のハイパーパラメータ,事前ハイパーパラメータ,事前ハイパーパラメータ,предшествующий гиперпараметр,параметры регуляризации,предварительный гиперпараметр
3468,prior knowledge,علم مسبق,المعرفة السابقة,معرفة سابقة,先验知识,先验知识,先验知识,connaissance préalable,connaissance antérieure,connaissances préalables,事前知識,事前知識 (じぜんちしき),事前知識,предварительные знания,- Предварительные знания,Предварительные знания
3469,prior mean,يعني السابق,المتوسط السابق,المتوسط المسبق,先验平均值,先验均值 (prior mean),先验均值,moyenne antérieure,moyenne antérieure,moyenne a priori,事前平均,事前平均,事前平均値,априорное среднее,приорное матожидание,предварительное среднее
3470,prior probability,احتمال مسبق,احتمالية سابقة,احتمالية مسبقة,先验概率,先验概率,先验概率,probabilité a priori,probabilité a priori,probabilité antérieure,事前確率,事前確率,事前確率,априорная вероятность,априорная вероятность,предварительная вероятность
3471,prior probability distribution,التوزيع الاحتمالي السابق,توزيع الاحتمالية السابقة,التوزيع الاحتمالي المسبق,先验概率分布,先验概率分布,先验概率分布,distribution de probabilité a priori,- Distribution de probabilité a priori,distribution de probabilité a priori,事前確率分布,事前確率分布,事前確率分布,априорное распределение вероятностей,априорное вероятностное распределение,априорное распределение вероятностей
3472,prior variance,التباين السابق,- التباين السابق,تباين مسبق,先验方差,先验方差,先验方差,écart antérieur,variance antérieure,variance a priori,以前の差異,事前分散,事前分散,предшествующее отклонение,априорная дисперсия,предварительная дисперсия
3473,priority queue,طابور الأولوية,طابور أولويات,قائمة الأولويات,优先队列,优先队列,优先队列,File d'attente de priorité,file de priorité,file d'attente prioritaire,優先キュー,優先度付きキュー,優先順位付きキュー,приоритетная очередь,приоритетная очередь,очередь с приоритетом
3474,privacy budget,ميزانية الخصوصية,ميزان الخصوصية,ميزانية الخصوصية,隐私预算,隐私预算,隐私预算,budget de confidentialité,budget de confidentialité,budget de confidentialité,プライバシーの予算,プライバシーバジェット,プライバシー予算,бюджет конфиденциальности,бюджет конфиденциальности,бюджет конфиденциальности
3475,privacy-preserve data mining,الحفاظ على الخصوصية واستخراج البيانات,تعدين البيانات الذي يحافظ على الخصوصية,تعدين البيانات الحافظ للخصوصية,隐私保护数据挖掘,隐私保护数据挖掘,隐私保护数据挖掘,exploration de données préservant la confidentialité,minage de données préservant la confidentialité,exploration de données préservant la confidentialité,プライバシー保護データマイニング,プライバシー保護データマイニング,プライバシー保護データマイニング,интеллектуальный анализ данных с сохранением конфиденциальности,защита конфиденциальности при добыче данных,сохраняющая конфиденциальность данных интеллектуальная добыча данных
3476,probabilistic context-free grammar,قواعد احتمالية خالية من السياق,قواعد النحو الاحتمالية الخالية من السياق,قواعد الجملة الاحتمالية المجردة من السياق,概率上下文无关语法,概率上下文无关文法,概率无关上下文文法,grammaire probabiliste hors contexte,grammaire probabiliste sans contexte,grammaire hors-contexte probabiliste,確率的文脈自由文法,確率的文脈自由文法,確率文脈自由文法,вероятностная контекстно-свободная грамматика,вероятностная контекстно-свободная грамматика,вероятностная контекстно-свободная грамматика
3477,probabilistic distribution,التوزيع الاحتمالي,التوزيع الاحتمالي,توزيع احتمالي,概率分布,概率分布,概率分布,distribution probabiliste,- Distribution probabiliste,distribution probabiliste,確率分布,確率分布 (Kakuritsu Bunsan),確率分布,вероятностное распределение,вероятностное распределение,Вероятностное распределение
3478,probabilistic formulation,صياغة احتمالية,الصياغة الاحتمالية,صياغة احتمالية,概率表述,概率形式化,概率形式化,formulation probabiliste,formulation probabiliste,formulation probabiliste,確率的定式化,確率的形式化,確率的定式化,вероятностная формулировка,вероятностная формулировка,вероятностная формулировка
3479,probabilistic framework,الإطار الاحتمالي,- إطار احتمالي,إطار احتمالي,概率框架,概率框架,概率框架,cadre probabiliste,- Cadre probabiliste,cadre probabiliste,確率的枠組み,確率的フレームワーク,確率的フレームワーク,вероятностная основа,вероятностная структура,вероятностная структура
3480,probabilistic generative model,النموذج التوليدي الاحتمالي,نموذج توليدي احتمالي,نموذج توليدي احتمالي,概率生成模型,概率生成模型,概率生成模型,modèle génératif probabiliste,modèle génératif probabiliste,modèle génératif probabiliste,確率的生成モデル,確率的生成モデル,確率生成モデル,вероятностная генеративная модель,вероятностная генеративная модель,вероятностная генеративная модель
3481,probabilistic graphical model,النموذج الرسومي الاحتمالي,- تصور النموذج الرسومي الاحتمالي,نموذج رسمي احتمالي,概率图模型,概率图模型,概率图模型,modèle graphique probabiliste,modèle graphique probabiliste,modèle graphique probabiliste,確率的グラフィカルモデル,確率的グラフモデル (kakuritsuteki gurafu moderu),確率的グラフィカルモデル,вероятностная графическая модель,вероятностная графическая модель,вероятностная графическая модель
3482,probabilistic inference,الاستدلال الاحتمالي,الاستدلال الاحتمالي,استنتاج احتمالي,概率推理,概率推断,概率推理,inférence probabiliste,inférence probabiliste,inférence probabiliste,確率的推論,確率推論 (Kakuritsu suiron),確率的推論,вероятностный вывод,вероятностный вывод,вероятностный вывод
3483,probabilistic logic,المنطق الاحتمالي,المنطق الاحتمالي,تنطيق احتمالي,概率逻辑,概率逻辑,概率逻辑,logique probabiliste,logique probabiliste,logique probabiliste,確率論的論理,確率論的論理,確率論理,вероятностная логика,вероятностный логикой,вероятностная логика
3484,probabilistic method,الطريقة الاحتمالية,الطريقة الاحتمالية,طريقة احتمالية,概率方法,概率方法,概率方法,méthode probabiliste,- Méthode probabiliste,méthode probabiliste,確率的手法,確率的手法,確率的手法,вероятностный метод,вероятностный метод,Вероятностный метод
3485,probabilistic model,النموذج الاحتمالي,النموذج الاحتمالي,نموذج احتمالي,概率模型,概率模型,概率模型,modèle probabiliste,modèle probabiliste,modèle probabiliste,確率モデル,確率モデル,確率モデル,вероятностная модель,вероятностная модель,вероятностная модель
3486,probabilistic relational model,النموذج العلائقي الاحتمالي,نموذج احتمالي علاقاتي,نموذج علائقي احتمالي,概率关系模型,概率关系模型 (Probabilistic Relational Model),概率关系模型,modèle relationnel probabiliste,- Modèle relationnel probabiliste,modèle relationnel probabiliste,確率的関係モデル,確率的関係モデル,確率的関係モデル,вероятностная реляционная модель,вероятностная реляционная модель,вероятностная реляционная модель
3487,probabilistic representation,التمثيل الاحتمالي,التمثيل الاحتمالي,تمثيل احتمالي,概率表示,概率表示,概率表示,représentation probabiliste,- Représentation probabiliste,représentation probabiliste,確率的表現,確率的表現,確率的表現,вероятностное представление,вероятностное представление,вероятностное представление
3488,probabilistic semantic,الدلالية الاحتمالية,إحتمالي رمزي,دلالات احتمالية,概率语义,概率语义,概率语义,sémantique probabiliste,sémantique probabiliste,sémantique probabiliste,確率的意味論,確率的意味論,確率的意味論,вероятностная семантика,вероятностная семантика,вероятностная семантика
3489,probabilistic topic modeling,النمذجة الموضوعية الاحتمالية,نمذجة المواضيع الاحتمالية,نمذجة المواضيع الاحتمالية,概率主题建模,概率主题建模,概率主题模型,modélisation thématique probabiliste,modélisation probabiliste des sujets,modélisation probabiliste de sujets,確率的トピックモデリング,確率的トピックモデリング(AI),確率的トピックモデリング,вероятностное тематическое моделирование,вероятностное тематическое моделирование,вероятностное тематическое моделирование
3490,probabilistic tree,الشجرة الاحتمالية,شجرة احتمالية,شجرة احتمالية,概率树,概率树,概率树,arbre probabiliste,arbre probabiliste,arbre probabiliste,確率ツリー,確率的木,確率的木,вероятностное дерево,Вероятностное дерево,древовидная вероятностная модель
3491,probability density,كثافة الاحتمال,كثافة الاحتمال,كثافة الاحتمال,概率密度,概率密度,概率密度,densité de probabilité,densité de probabilité,densité de probabilité,確率密度,確率密度,確率密度,плотность вероятности,плотность вероятности,плотность вероятности
3492,probability density function,دالة الكثافة الاحتمالية,دالة كثافة الاحتمال,دالة الكثافة الاحتمالية,概率密度函数,概率密度函数,概率密度函数,fonction de densité de probabilité,fonction de densité de probabilité,Fonction de densité de probabilité,確率密度関数,確率密度関数,"確率密度関数

PDF",функция плотности вероятности,функция плотности вероятности,"функция плотности вероятности

PDF"
3493,probability distribution,توزيع الاحتمالات,توزيع الاحتمالات,توزيع احتمالي,概率分布,概率分布,概率分布,distribution de probabilité,distribution de probabilité,distribution de probabilité,確率分布,確率分布,確率分布,распределение вероятностей,вероятностное распределение,распределение вероятностей
3494,probability flow,تدفق الاحتمال,تدفق الاحتمالية,تدفق الاحتمالية,概率流,概率流,概率流,flux de probabilité,flux de probabilité,flux de probabilité,確率の流れ,確率フロー,確率フロー,вероятностный поток,поток вероятности,вероятностный поток
3495,probability map,خريطة الاحتمالية,خريطة الاحتمالية,خريطة الاحتمالات,概率图,概率地图 (Probability map),概率图,carte de probabilité,carte de probabilité,carte de probabilité,確率マップ,確率マップ (kakuritsu mappu),確率マップ,карта вероятностей,карта вероятности,карта вероятностей
3496,probability mass,كتلة الاحتمال,الكتلة الاحتمالية,كتلة الاحتمال,概率质量,概率质量,概率质量,masse de probabilité,masse de probabilité,masse de probabilité,確率質量,確率質量,確率質量,вероятностная масса,вероятностная масса,вероятностная масса
3497,probability mass function,دالة الكتلة الاحتمالية,دالة كتلة الاحتمالية,وظيفة الكتلة الاحتمالية,概率质量函数,概率质量函数,质量函数,fonction de masse,- Fonction de masse de probabilité,fonction de masse de probabilité,確率質量関数,確率質量関数,確率質量関数,функция массы вероятности,функция массы вероятностей,функция массы вероятности
3498,probability matrix,مصفوفة الاحتمالية,مصفوفة الاحتمالات,مصفوفة احتمالية,概率矩阵,概率矩阵,概率矩阵,matrice de probabilité,- Matrice de probabilité,matrice de probabilité,確率行列,確率行列,確率行列,матрица вероятностей,вероятностная матрица,матрица вероятностей
3499,probability measure,قياس الاحتمالية,قياس الاحتمالية,مقياس الاحتمال,概率测度,概率测度,概率度量,mesure de probabilité,mesure de probabilité,mesure de probabilité,確率測定,確率測度 (Kakuritsu Sokudo),確率測度,вероятностная мера,мера вероятности,мера вероятности
3500,probability model,نموذج الاحتمالية,نموذج احتمالية,نموذج احتمالي,概率模型,概率模型,概率模型,modèle de probabilité,modèle de probabilité,modèle de probabilité,確率モデル,確率モデル (kakuritsu moderu),確率モデル,вероятностная модель,модель вероятности,вероятностная модель
3501,probability multiset,احتمال متعدد,المجموعة الاحتمالية المتعددة,تعدد الاحتمالات,概率多重集,概率多重集,概率多重集,multiensemble de probabilité,multisete de probabilité,multiensemble de probabilités,確率マルチセット,確率マルチセット,確率マルチセット,вероятностное мультимножество,вероятностный мультимножество,мультимножество вероятностей
3502,probability simplex,احتمال بسيط,المحدد الاحتمالي,البسيط الاحتمالي,概率单纯形,概率单纯形,概率单纯形,simplexe de probabilité,simplexe de probabilité,simplexe de probabilité,確率単体,確率シンプレックス,確率シンプレックス,вероятностный симплекс,вероятностный симплекс,вероятностный симплекс
3503,probability space,مساحة الاحتمال,المساحة الاحتمالية,فضاء الاحتمال,概率空间,概率空间 (probability space),概率空间,espace de probabilité,espace de probabilité,espace probabiliste,確率空間,確率空間 (kakuritsu kūkan),確率空間,вероятностное пространство,пространство вероятностей,вероятностное пространство
3504,probability threshold,عتبة الاحتمال,- التحويلة الاحتمالية,عتبة الاحتمال,概率阈值,概率阈值,概率阈值,seuil de probabilité,Seuil de probabilité,seuil de probabilité,確率のしきい値,確率しきい値,確率閾値,порог вероятности,порог вероятности,порог вероятности
3505,probability transition matrix,مصفوفة الانتقال الاحتمالية,مصفوفة انتقال الاحتمالية,مصفوفة الانتقال الاحتمالية,概率转移矩阵,概率转移矩阵,概率转移矩阵,matrice de transition de probabilité,matrice de transition de probabilité,matrice de transition de probabilité,確率遷移行列,確率遷移行列,確率遷移行列,матрица вероятностного перехода,матрица вероятности перехода,матрица переходных вероятностей
3506,probability vector,ناقل الاحتمال,متجه احتمالية,متجه الاحتمال,概率向量,概率向量,概率向量,vecteur de probabilité,- Vector de probabilité,vecteur de probabilité,確率ベクトル,確率ベクトル,確率ベクトル,вектор вероятности,вектор вероятностей,вектор вероятностей
3507,probe classifier,مصنف التحقيق,مصنف الاستطلاع,مُصنِّف الاستقصاء,探针分类器,探测分类器,探测分类器,classificateur de sonde,classificateur de sondage,classificateur de sonde,プローブ分類子,プローブ分類器,プローブ分類器,классификатор зондов,классификатор зондирования,классификатор зондирования
3508,problem space,مساحة المشكلة,المجال المشكلة,فضاء المشكلة,问题空间,问题空间,问题空间,espace problématique,espace de problème,espace de problème,問題スペース,問題空間 (もんだいくうかん),問題空間,проблемное пространство,пространство проблем,пространство задачи
3509,product distribution,توزيع المنتج,توزيع المنتجات,توزيع المنتج,产品分销,产品分布,乘积分布,distribution de produits,- Distribution de produit,distribution des produits,製品の流通,製品分布,生成物分布,распространение продукции,производное распределение,Распределение произведения
3510,product-of-expert,منتج من الخبراء,ناتج الخبراء,منتج الخبراء,专家产品,专家乘积,专家乘积,produit d'expert,produit-d'expert,produit d'experts,専門家の製品,"""['パラメータ付きのコンテキストモデルについて説明し、専門家の積を使用するときにそれらがうまく機能することが期待できる理由を説明します（セクション4）、次にこのパラメータ設定でLTS損失関数が凸であることを示し（セクション5",専門家の積,экспертный продукт,product-of-expert,продукт-экспертов
3511,program induction,تحريض البرنامج,- تحريض البرنامج,استنتاج البرنامج,节目介绍,程序归纳,程序归纳,initiation au programme,induction de programme,induction de programme,プログラムの導入,プログラム導出,プログラム誘導,вводная программа,индукция программы,индукция программ
3512,projection algorithm,خوارزمية الإسقاط,خوارزمية الإسقاط,خوارزمية التصويب,投影算法,投影算法,投影算法,algorithme de projection,algorithme de projection,algorithme de projection,投影アルゴリズム,射影アルゴリズム (Shaei Arugorizumu),射影アルゴリズム,алгоритм проецирования,алгоритм проекции,алгоритм проецирования
3513,projection layer,طبقة الإسقاط,طبقة الإسقاط,طبقة الإسقاط,投影层,投影层,投影层,couche de projection,couche de projection,couche de projection,投影層,プロジェクション層 (Projection Layer),射影層,проекционный слой,слой проекции,проекционный слой
3514,projection matrix,مصفوفة الإسقاط,مصفوفة الإسقاط,مصفوفة الإسقاط,投影矩阵,投影矩阵,投影矩阵,matrice de projection,matrice de projection,matrice de projection,射影行列,投影行列,投影行列,матрица проекции,матрица проекции,проекционная матрица
3515,projection operator,عامل الإسقاط,مشغل الإسقاط,عامل الإسقاط,投影算子,投影算子,投影算子,opérateur de projection,opérateur de projection,opérateur de projection,射影演算子,射影演算子 (しゃえいえんざ),射影演算子,оператор проектирования,оператор проекции,проекционный оператор
3516,projection step,خطوة الإسقاط,خطوة الإسقاط,خطوة الإسقاط,投影步骤,投影步骤,投影步骤,étape de projection,étape de projection,étape de projection,投影ステップ,投影ステップ (touei suteppu),投影ステップ,шаг проекции,шаг проекции,шаг проекции
3517,projective camera,كاميرا إسقاطية,كاميرا إسقاطية,كاميرا إسقاطية,投影相机,透视相机,透视相机,caméra projective,caméra projective,caméra projective,投影カメラ,射影カメラ,射影カメラ,проекционная камера,проекционная камера,проективная камера
3518,projective dependency parsing,تحليل التبعية الإسقاطية,تحليل التبعية الاعتمادي المشروعية,تحليل البنية العميقة الإسقاطي,投影依存分析,投影依存分析,投射依存句法分析,analyse des dépendances projectives,analyse de dépendance projective,analyse en dépendances projectives,射影依存関係の解析,射影依存解析,射影依存構文解析,анализ проективных зависимостей,проективный синтаксический анализ,проективный анализ синтаксических зависимостей
3519,projective dependency tree,شجرة التبعية الإسقاطية,شجرة الاعتماد المشروعة,شجرة اعتماد إسقاطية,投影依赖树,投影依存树,投射依存树,arbre de dépendance projectif,arbre de dépendance projectif,arbre de dépendance projectif,射影依存関係ツリー,射影依存木 (shayou izonboku),射影依存木,проективное дерево зависимостей,проекционное дерево зависимостей,древовидная зависимость
3520,projective parsing,التحليل الإسقاطي,التحليل الإسقاطي,تحليل انسيابي,投影解析,投影式分析,投射式解析,analyse projective,analyse projective,analyse par projection,射影解析,投射構文解析 (projective parsing),射影的構文解析,проективный анализ,проективный анализ,проективный синтаксический анализ
3521,projective transformation,التحول الإسقاطي,- التحويل المشروعي,تحويل إسقاطي,投影变换,射影变换 (projective transformation),射影变换,transformation projective,transformation projective,transformation projective,射影変換,射影変換 (shaei hendo),射影変換,проективная трансформация,проективное преобразование,проективное преобразование
3522,prompt,اِسْتَدْعَى,المحفز,تعليمة,迅速的,提示,提示,rapide,indication,invite,プロンプト,プロンプト,プロンプト,быстрый,подсказка,промпт
3523,prompt engineering,الهندسة السريعة,هندسة الاستدراك,هندسة النداءات,及时工程,提示工程,提示工程,ingénierie rapide,ingénierie de prompt,ingénierie des invites,迅速なエンジニアリング,プロンプトエンジニアリング,プロンプトエンジニアリング,оперативное проектирование,инженерия подсказок,Проектирование промптов
3524,prompt learning,التعلم السريع,التعلم السريع,تعلم التلميحات,及时学习,提示学习,prompt 学习,apprentissage rapide,apprentissage prompt,apprentissage par amorce,迅速な学習,プロンプト学習,プロンプト学習,быстрое обучение,обучение по подсказке,обучение с подсказками
3525,prompt tuning,ضبط سريع,ضبط الاستدعاءات,ضبط التعليمة البادئة,及时调整,提示调整,提示调优,réglage rapide,accord prompt,réglage du prompt,プロンプトチューニング,プロンプトチューニング,プロンプトチューニング,оперативная настройка,- Пошаговая настройка,настройка подсказок
3526,pronoun resolution,قرار الضمائر,حل الضمير,كَشْف الضَّمائِر,代词解析,代词消解,代词消解,résolution de pronom,résolution des pronoms,résolution de pronoms,代名詞の解決,代名詞解決 (pronoun resolution),pronoun代名詞解決,местоимение разрешение,разрешение местоимений,сопоставление местоимений
3527,proof complexity,تعقيد الإثبات,التعقيد الإثباتي,تعقيد البرهان,证明复杂性,证明复杂度,证明复杂性,complexité de la preuve,complexité de la preuve,complexité des preuves,証明の複雑さ,証明複雑性,証明複雑性,сложность доказательства,сложность доказательства,доказательная сложность
3528,proof number,رقم الإثبات,رقم الإثبات,رقم البرهان,证明号码,证明数,证明数,numéro de preuve,numéro de preuve,nombre de preuve,証明番号,証明数,証明番号,номер доказательства,число доказательства,доказательное число
3529,proof tree,شجرة برهان,شجرة الإثبات,شجرة البرهان,证明树,证明树 (Zhèngmíng shù),证明树,arbre de preuve,- Arbre de preuve,arbre de preuve,証拠の木,証明木 (shoumei ki),証明木,дерево доказательств,дерево доказательств,Дерево доказательства
3530,propensity score,درجة الميل,نقطة الاتجاهية,نقاط الميل,倾向得分,倾向得分,倾向评分,score de propension,score de propension,score de propension,傾向スコア,傾向スコア,適合スコア,оценка склонности,предрасположенность к событию,Оценка склонности
3531,proposal distribution,توزيع الاقتراح,توزيع الاقتراحات,توزيع الاقتراح,提案分发,提案分布,建议分布,distribution des propositions,- Distribution de proposition,distribution de proposition,企画書配布,提案分布,提案分布,распространение предложений,распределение предложений,распределение предложений
3532,proposal probability,احتمال الاقتراح,احتمالية الاقتراحات,احتمالية الاقتراح,提案概率,提案概率,建议概率,probabilité de proposition,probabilité de proposition,probabilité de proposition,プロポーズの確率,提案確率,提案確率,вероятность предложения,вероятность предложения,предложение вероятности
3533,proposition,اقتراح,- تقديمية,مقولة,主张,命题,命题,proposition,proposition,proposition,命題,"""['提案3.1によって予測された通り、range-SOAP（グレー）とequal-SOAP（カラー）の表現力には明確な分離があります。良いポリシーをほぼ最適に近づけ、悪いポリシーよりも優れたものにする報酬関数を見つけることができるケ",命題,предложение,предложение,предложение
3534,propositional,اقتراحي,الاقتراحية,قضوي,命题性的,命题的,命题的,propositionnel,propositionnel,logique propositionnelle,提案的な,"""井上（1992）は、SOL-解決を使用して説明と主要な含意を生成するために、命題的および一階の文脈で考慮した。彼は、空の集合から始めて、理論から節を段階的に処理する戦略を提案した。ただし、可能な大きな中間結果があるため",命題的,пропозициональный,пропозициональный,пропозициональный
3535,propositional formula,صيغة مقترحة,صيغة اقتراحية,صيغة منطقية,命题公式,命题公式,命题公式,formule propositionnelle,formule propositionnelle,formule propositionnelle,命題式,命題論理式,命題論理式,пропозициональная формула,Пропозициональная формула,пропозициональная формула
3536,propositional language,لغة مقترحة,لغة اقتراحية,لغة القضية,命题语言,命题语言,命题语言,langage propositionnel,langage propositionnel,langage propositionnel,命題言語,命題言語,命題言語,пропозициональный язык,пропозициональный язык,языкпропозициональный
3537,propositional logic,المنطق الاقتراحي,منطق اقتراحي,منطق القضايا,命题逻辑,命题逻辑,命题逻辑,logique propositionnelle,logique propositionnelle,logique propositionnelle,命題論理,"""『比較すると、割り当てが命題論理の式のモデルであるか、非選言ロジックプログラムの解答セットであるかを確認することは効率的に行うことができます。』『最近、 ""ループ式""を使用して完全性を拡張する作業が行われており、",命題論理,логика высказываний,предикативная логика,логика высказываний
3538,propositional variable,المتغير المقترح,متغير اقتراحي,متغير قضوي,命题变量,命题变量,命题变量,variable propositionnelle,variable propositionnelle,variable propositionnelle,命題変数,命題変数,命題変数,пропозициональная переменная,пропозициональная переменная,пропозициональная переменная
3539,protected attribute,السمة المحمية,السمة المحمية,سمة محمية,受保护的属性,受保护属性,受保护属性,attribut protégé,attribut protégé,attribut protégé,保護された属性,保護属性 (ほごぞくせい),保護された属性,защищенный атрибут,защищенный атрибут,защищенный атрибут
3540,protein folding,البروتين للطي,طي البروتين,طي البروتين,蛋白质折叠,蛋白质折叠,蛋白质折叠,repliement des protéines,repliement des protéines,repliement des protéines,タンパク質の折り畳み,タンパク質の折りたたみ,タンパク質折りたたみ,сворачивание белка,складывание белков,сворачивание белков
3541,prototype embedding,تضمين النموذج الأولي,تضمين النموذج الأولي,تضمين النموذج الأولي,原型嵌入,原型嵌入,原型嵌入,intégration de prototype,intégration de prototype,Embedding de prototype,プロトタイプの埋め込み,プロトタイプ埋め込み (Prototype embedding),プロトタイプ埋め込み,внедрение прототипа,встраивание прототипов,прототипное встраивание
3542,proximal operator,المشغل القريب,مشغل المتقارب,مشغل قريب,近端算子,近端算子,接近算子,opérateur proximal,opérateur proximal,opérateur proximal,近位演算子,近位作用素,近接演算子,проксимальный оператор,проксимальный оператор,приближенный оператор
3543,proximal policy optimization,تحسين السياسة القريبة,التحسين التدريجي للسياسات القريبة,تحسين سياسة القرب,近端策略优化,近端策略优化 (Proximal Policy Optimization),"近端策略优化

PPO",optimisation de la politique proximale,optimisation de politique proximale,"Optimisation de politique proximale

PPO",近接ポリシーの最適化,近接方策最適化,近接ポリシー最適化,оптимизация проксимальной политики,Проксимальная оптимизация политики,Оптимизация приближенной политики
3544,pruning algorithm,خوارزمية التقليم,- تركيب خوارزمية,خوارزمية التقليم,剪枝算法,修剪算法,修剪算法,algorithme d'élagage,algorithme d'élagage,algorithme d'élagage,枝刈りアルゴリズム,剪定アルゴリズム (Sentee Arugorizumu),剪定アルゴリズム,алгоритм обрезки,алгоритм обрезки,алгоритм обрезки
3545,pseudo-inverse,معكوس زائف,الشبه العكسي,معكوس كاذب,伪逆,伪逆,伪逆,pseudo-inverse,pseudo-inverse,pseudo-inverse inverse,擬似逆,疑似逆,擬似逆行列,псевдообратный,псевдообратный,псевдообратная
3546,pure strategy,استراتيجية نقية,استراتيجية نقية,نظرية نقية,纯策略,纯策略,纯策略,stratégie pure,stratégie pure,Stratégie pure,純粋な戦略,- 純粋戦略 (junsui senryaku),純粋戦略,чистая стратегия,чистая стратегия,чистая стратегия
3547,pyramid level,مستوى الهرم,مستوى الهرم,مستوى الهرم,金字塔级别,金字塔层级 (pyramid level),金字塔层级,niveau de la pyramide,niveau de pyramide,niveau pyramidal,ピラミッドレベル,ピラミッドレベル,錐体レベル,уровень пирамиды,уровень пирамиды,уровень пирамиды
3548,q function,وظيفة ف,دالة Q,دالة Q,q 函数,Q函数,行为价值函数,fonction q,fonction Q,fonction Q,q関数,q 関数,Q関数,q-функция,q-функция,функция Q
3549,q value,قيمة ف,قيمة Q,قيمة ك,q值,q 值,q值,valeur q,q valeur,valeur q,q値,q値,Q値,значение q,q значение,q значение
3550,q-learning,س-التعلم,تعلم كيو,تعلم-ق,q-学习,Q-学习,q-学习,q-apprentissage,q-learning,apprentissage par renforcement Q,Qラーニング,Q学習,Q学習,q-обучение,q-обучение,обучение с подкреплением
3551,q-network,شبكة س,شبكة Q,شبكة-Q,q-网络,Q网络,q-网络,réseau q,réseau Q,réseau-Q,qネットワーク,Qネットワーク,q-ネットワーク,q-сеть,q-сеть,сеть Q
3552,quadratic assignment problem,مشكلة التعيين التربيعي,مشكلة التعيين التربيعية,مشكلة التعيين التربيعي,二次分配问题,二次分配问题,二次指派问题,problème d'affectation quadratique,Problème d'affectation quadratique,problème d'affectation quadratique,二次代入問題,二次割り当て問題,二次割り当て問題,квадратичная задача о назначениях,квадратная проблема назначения,квадратичная задача о назначениях
3553,quadratic loss,الخسارة التربيعية,الخسارة التربيعية,خسارة تربيعية,二次损失,二次损失,二次损失,perte quadratique,- Perte quadratique,perte quadratique,二次損失,二乗損失 (nijou sonshitsu),二次損失関数,квадратичная потеря,квадратичная потеря,квадратичная потеря
3554,quadratic program,برنامج تربيعي,برنامج تربيعي,برنامج تربيعي,二次规划,二次规划 (quadratic program),二次规划问题,programme quadratique,programme quadratique,programme quadratique,二次計画法,二次計画 (niji keikaku),二次計画問題,квадратичная программа,квадратичная программа,квадратичная программа
3555,quadratic regularizer,منظم تربيعي,المُنظّم التربيعي,مُنَظِّم تُربيعي,二次正则化器,二次正则化项,二次正则化项,régularisateur quadratique,régulariseur quadratique,régularisateur quadratique,二次正則化子,二次正則化項,二次正則化項,квадратичный регуляризатор,квадратичный регуляризатор,квадратичный регуляризатор
3556,quality estimation,تقدير الجودة,تقدير الجودة,تقدير الجودة,质量评估,质量估计,质量估计,estimation de la qualité,Estimation de qualité,estimation de la qualité,品質の見積もり,品質推定,品質推定,оценка качества,оценка качества,оценка качества
3557,quantal response equilibrium,توازن الاستجابة الكمية,توازن الاستجابة الكمية,توازن الاستجابة الكمية,量子响应平衡,量子响应均衡,量子响应平衡,équilibre de réponse quantique,- Équilibre de réponse quantale,équilibre de réponse quantale,量子応答の平衡,量子応答均衡 (Quantal Response Equilibrium),量子応答均衡,квантовое равновесие ответа,квантовое равновесие реакции,квантовое уравновешивание реакций
3558,quantified variable,المتغير الكمي,المتغير المقيَّد,متغير مُكَمّم,量化变量,量化变量,量化变量,variable quantifiée,- Variable quantifiée,variables quantifiées,定量化された変数,量子化された変数,量化変数,количественная переменная,квантифицированные переменные,переменная квантификации
3559,quantifier,محدد الكمية,"""['صيغة منطقية من الدرجة الأولى لغة طبيعية مع كميّ D (غير) N 1 الذين هم (ليسوا) (a) N 2 / A 1 هو/هي (ليس) (a) N 3 / A 2 ∀x.', 'لهذا الغرض، لأي مصطلح وضعية σ، نحدد",كمية,量词,量词,量词,quantificateur,quantificateur,quantificateur,数量詞,量化子,量化詞,квантификатор,квантификатор,квантор
3560,quantile,الكمية,"""['في تجاربنا ، قمنا بتعيين m = n = 1000 ، σ 2 p = 10 واستخرجنا مجموعتين من العينات العشوائية المستقلة من Q. يتم تقدير توزيع T mn باستخدام تقنية البوتستراب على هذه العينات (",كميّة,分位数,分位数,quantile,quantile,quantile,quantile,分位数,分位数,- 量化値 (ryōka-chi),квантиль,квантиль,квантиль
3561,quantization,توضيح,"""['نماذج اللغة المدربة مسبقًا \n في هذا القسم، نظهر أنه من الصعب تدريب نموذج توليد مسبق منخفض البت باستخدام النهج التقليدي للتقنين مباشرةً. قبل الانغماس في التفاصيل،",تكميم,量化,量化 (liàng huà),量化,quantification,quantification,quantification,量子化,量子化 (Ryōshika),量子化,квантование,Квантование,квантование
3562,quantization function,وظيفة التكمية,وظيفة التكميم,دالة التكميم,量化函数,量化函数,量化函数,fonction de quantification,fonction de quantification,fonction de quantification,量子化機能,量子化関数,量子化関数,функция квантования,квантовая функция,функция квантования
3563,quantizer,المكمم,كوانتايزر,مُكَمِّم,量化器,量化器,量化器,quantificateur,quantificateur,quantifieur,量子化器,量子化器,量子化器,квантователь,квантователь,квантизатор
3564,quasi-Newton method,طريقة شبه نيوتن,الطريقة كوازي نيوتن,طريقة شبه نيوتن,拟牛顿法,拟牛顿法,类牛顿法,méthode quasi-Newton,méthode quasi-Newton,méthode de quasi-Newton,準ニュートン法,クワジニュートン法,準ニュートン法,квазиньютоновский метод,квази-Ньютоновский метод,квази-ньютоновский метод
3565,quaternion,رباعي,"""تقترح نحن التوزيع الزائد المركزي الزاوي (ACG) كالاقتراح بالنسبة لتعريف رباعية للاتجاه ثلاثي الأبعاد، الذي يمكن تمثيله بواسطة متجه 4D وحدة l. دعم توزيع ACG",كواترنيون,四元数,四元数,四元数,quaternion,quaternion,quaternion,四元数,四元数,四元数,кватернион,кватернион,кватернион
3566,query,استفسار,- تحقيق,استفسار,询问,"""['使用最大乘积半环，然后计算通过不同分支（跳过连接，键，值和查询）的顶级梯度路径，用于（a）句子的主语，（b）句子的吸引子，和（c）句子的所有标记。 模型。'，'输入进一步在自注意力机制内在键，值和查询之间分支（请参阅图3进行说明）。'，",查询,requête,requêtes,requête,クエリ,If q ∈ queries P (x,クエリ,запрос,"""['Используя полукольцо max-product, мы затем вычисляем верхний градиентный путь через различные ветви (пропускное соединение, ключи, значения и запросы) для (a) субъекта предложения, (b) аттракторов предложения и (c) всех токенов предложения. Модель.', 'Далее вход разветвляется в м",запрос
3567,query answer,إجابة الاستعلام,إجابة الاستعلام,استعلام الإجابة,查询答案,查询答案,查询回答,réponse à la requête,- Réponse à la requête,réponse à la requête,クエリの回答,クエリ回答 (Query Answer),クエリ回答,ответ на запрос,ответ на запрос,запрос на ответ
3568,query complexity,تعقيد الاستعلام,تعقيد الاستعلامات,تعقيد الاستعلام,查询复杂度,查询复杂度,查询复杂度,complexité des requêtes,complexité de requête,complexité de requête,クエリの複雑さ,クエリ複雑度 (query complexity),クエリ複雑性,сложность запроса,сложность запроса,сложность запросов
3569,query context,سياق الاستعلام,سياق الاستعلام,سياق الاستعلام,查询上下文,查询上下文,查询上下文,contexte de requête,contexte de requête,contexte de requête,クエリコンテキスト,クエリコンテキスト,クエリコンテクスト (query context),контекст запроса,контекст запроса,запросный контекст
3570,query embedding,تضمين الاستعلام,تضمين الاستعلام,تضمين الاستعلام,查询嵌入,查询嵌入,查询嵌入,intégration de requêtes,requête d'encodage,représentation vectorielle de la requête,クエリの埋め込み,クエリ埋め込み (query embedding),クエリ埋め込み,внедрение запроса,встроенный запрос,встраивание запроса
3571,query expansion,توسيع الاستعلام,توسيع الاستعلام,توسيع الاستعلام,查询扩展,查询扩展,查询扩展,extension de requête,expansion de requête,expansion de requête,クエリ拡張,クエリの拡張 (Query Expansion),クエリ展開,расширение запроса,расширение запроса,расширение запроса
3572,query image,صورة الاستعلام,صورة الاستعلام,صورة الاستعلام,查询图像,查询图像,查询图像,image de requête,image de requête,image requête,クエリ画像,クエリ画像,クエリ画像,запрос изображения,изображение запроса,запросное изображение
3573,query language,لغة الاستعلام,لغة الاستعلامات,لغة الاستعلام,查询语言,查询语言,查询语言,langage de requête,langage de requête,langage de requête,クエリ言語,クエリ言語 (kueri gengo),クエリ言語,язык запросов,язык запросов,язык запросов
3574,query phase,مرحلة الاستعلام,المرحلة الاستعلامية,مرحلة الاستعلام,查询阶段,查询阶段,查询阶段,phase de requête,- Phase de requête,phase d'interrogation,クエリフェーズ,クエリフェーズ,クエリフェーズ,этап запроса,фаза запроса,фаза запроса
3575,query point,نقطة الاستعلام,نقطة الاستعلام,نقطة الاستعلام,查询点,查询点,查询点,point de requête,Point de requête,point d'interrogation,クエリポイント,クエリポイント,クエリ点,точка запроса,Точка запроса,запрашиваемая точка
3576,query processing,معالجة الاستعلام,معالجة الاستعلامات,معالجة الاستعلام,查询处理,查询处理,查询处理,traitement des requêtes,traitement des requêtes,traitement des requêtes,クエリ処理,クエリ処理,クエリ処理,обработка запросов,обработка запросов,обработка запросов
3577,query reformulation,إعادة صياغة الاستعلام,إعادة صياغة الاستعلامات,تحوير الاستعلام,查询重构,查询重构,查询重构,reformulation de requête,reformulation de requête,reformulation de la requête,クエリの再定式化,クエリの再構築,クエリ改訂,переформулировка запроса,реформулирование запроса,переформулирование запроса
3578,query representation,تمثيل الاستعلام,تمثيل الاستعلامات,تمثيل الاستعلام,查询表示,查询表示,查询表示,représentation de requête,- Représentation de requête,représentation de la requête,クエリ表現,クエリ表現,クエリ表現,представление запроса,представление запроса,запрос представления
3579,query strategy,استراتيجية الاستعلام,استراتيجية الاستعلام,استراتيجية الاستعلام,查询策略,查询策略,查询策略,stratégie de requête,stratégie de requête,stratégie d'interrogation,クエリ戦略,クエリ戦略 (query strategy),クエリ戦略,стратегия запроса,стратегия запроса,стратегия запроса
3580,query time,وقت الاستعلام,وقت الاستعلام,وقت الاستعلام,查询时间,查询时间,查询时间,heure de la requête,temps de requête,temps d'interrogation,クエリ時間,クエリ時間 (Query Time),クエリ時間,время запроса,время запроса,Время запроса
3581,query vector,ناقلات الاستعلام,متجه الاستعلام,متجه الاستعلام,查询向量,查询向量,查询向量,vecteur de requête,vecteur de requête,vecteur de requête,クエリベクトル,クエリベクトル (query vector),クエリベクトル,вектор запроса,вектор запроса,вектор запроса
3582,query-document pair,زوج مستند الاستعلام,زوج الاستعلام والمستند,زوج استعلام-مستند,查询-文档对,查询-文档对,查询-文档对,paire requête-document,paire requête-document,paire requête-document,クエリとドキュメントのペア,クエリドキュメントペア,クエリ-文書ペア,пара запрос-документ,запрос-документная пара,запрос-документ пары
3583,question answer,جواب السؤال,السؤال والجواب,الاجابة على الاسئلة,问题回答,问题回答,问答,Question Réponse,Question Réponse,question réponse,質疑応答,質問回答,質問回答,вопрос ответ,вопрос-ответ,вопрос-ответ
3584,r-precision,ص الدقة,- التقدم النسبي,دقة-ر,r-精度,R-精度,"R-Precision 的中文译文是 ""R-查准率""。",r-précision,précision R,R-Précision,r精度,R-プレシジョン,R-Precision (アール-プレシジョン),r-точность,R-точность,точность-R
3585,rademacher complexity,تعقيد rademacher,التعقيد الراديماخر,تعقيد رادماخر,拉德马赫复杂度,雷德马赫复杂性,拉德马赫复杂度,complexité rademacher,complexité de Rademacher,complexité de Rademacher,ラデマッハの複雑さ,ラデマッハー複雑度,ラデマッハ複雑性,сложность Радемахера,сложность радемахера,сложность радемахера
3586,radiance field,مجال التألق,حقل السطوع,حقول الإشعاع,辐射场,辐射场,辐射场,champ de rayonnement,champ de radiance,champ de radiance,ラディアンスフィールド,放射フィールド (Housha Fiirudo),放射輝度場,поле излучения,поле радиации,поле излучения
3587,random crop,المحاصيل العشوائية,- تقاطع عشوائي,قطع عشوائي,随机裁剪,随机裁剪,随机裁剪,récolte aléatoire,recadrage aléatoire,crop aléatoire,ランダムな収穫,ランダムクロップ,ランダムクロップ,случайный урожай,случайное обрезание,случайная обрезка
3588,random feature,ميزة عشوائية,الميزات العشوائية,ميزة عشوائية,随机特征,随机特征,随机特征,fonctionnalité aléatoire,caractéristique aléatoire,caractéristique aléatoire,ランダムな特徴,ランダムな特徴,ランダム特徴量,случайная особенность,случайный признак,случайный признак
3589,random forest classifier,مصنف الغابات العشوائية,التصنيف العشوائي للغابات (Random Forest Classifier),حصائي الغابات العشوائية,随机森林分类器,随机森林分类器,随机森林分类器,classificateur de forêt aléatoire,classificateur de forêt aléatoire,classificateur de forêt aléatoire,ランダムフォレスト分類器,ランダムフォレスト分類器,ランダムフォレスト分類器,случайный классификатор леса,случайный лес классификатор,случайный лесной классификатор
3590,random matrix theory,نظرية المصفوفة العشوائية,نظرية المصفوفات العشوائية,نظرية المصفوفات العشوائية,随机矩阵理论,随机矩阵理论,随机矩阵理论,théorie des matrices aléatoires,Théorie des matrices aléatoires,théorie des matrices aléatoires,ランダム行列理論,ランダム行列理論,ランダム行列理論,теория случайных матриц,теория случайных матриц,теория случайных матриц
3591,random policy,سياسة عشوائية,السياسة العشوائية,سياسة عشوائية,随机策略,随机策略,随机策略,politique aléatoire,politique aléatoire,politique aléatoire,ランダムポリシー,ランダムポリシー,ランダムポリシー,случайная политика,случайная политика,случайная политика
3592,random projection,الإسقاط العشوائي,الإسقاط العشوائي,تصوير عشوائي,随机投影,随机投影,随机投影,projection aléatoire,projection aléatoire,projection aléatoire,ランダムな投影,ランダム射影 (random projection),ランダム射影,случайная проекция,случайное проецирование,случайная проекция
3593,random projection algorithm,خوارزمية الإسقاط العشوائي,خوارزمية الإسقاط العشوائي,خوارزمية التصوير العشوائي,随机投影算法,随机投影算法,随机投影算法,algorithme de projection aléatoire,algorithme de projection aléatoire,algorithme de projection aléatoire,ランダム投影アルゴリズム,ランダム射影アルゴリズム (random projection algorithm),ランダム射影アルゴリズム,алгоритм случайной проекции,алгоритм случайной проекции,алгоритм случайной проекции
3594,random sampling,أخذ عينات عشوائية,- تعيين عشوائي,عينة عشوائية,随机抽样,随机抽样,随机采样,échantillonnage aléatoire,échantillonnage aléatoire,échantillonnage aléatoire,無作為抽出,ランダムサンプリング,ランダムサンプリング,случайная выборка,случайная выборка,случайная выборка
3595,random seed,البذور عشوائي,البذرة العشوائية,بذرة عشوائية,随机种子,随机种子,随机种子,graine aléatoire,graine aléatoire,graine aléatoire,ランダムシード,ランダムシード,乱数シード,случайное зерно,случайное зерно,случайный начальный вектор
3596,random variable,متغير عشوائي,المتغير العشوائي,متغير عشوائي,随机变量,随机变量,随机变量,Variable aléatoire,variable aléatoire,variable aléatoire,確率変数,ランダム変数,確率変数,случайная переменная,случайная величина,случайная переменная
3597,random vector,ناقلات عشوائية,متجه عشوائي,متجه عشوائي,随机向量,随机向量,随机向量,vecteur aléatoire,vecteur aléatoire,vecteur aléatoire,ランダムなベクトル,ランダムベクトル (random vector),ランダム ベクトル,случайный вектор,- Случайный вектор,случайный вектор
3598,random walk model,نموذج المشي العشوائي,نموذج المشي العشوائي,نموذج المشي العشوائي,随机游走模型,随机游走模型,随机游走模型,modèle de marche aléatoire,modèle de marche aléatoire,modèle de marche aléatoire,ランダムウォークモデル,ランダムウォークモデル,ランダムウォークモデル,модель случайного блуждания,модель случайного блуждания,модель случайного блуждания
3599,randomization,العشوائية,- التعشيش العشوائي,تعشية,随机化,随机化,随机化,randomisation,- Randomisation,randomisation,ランダム化,ランダム化,ランダム化,рандомизация,рандомизация,рандомизация
3600,randomized algorithm,خوارزمية عشوائية,الخوارزمية العشوائية,خوارزمية عشوائية,随机算法,随机算法 (Randomized Algorithm),随机算法,algorithme randomisé,algorithme aléatoire,algorithme aléatoire,ランダム化されたアルゴリズム,ランダム化アルゴリズム (Randamukaa Arugorizumu),ランダム化アルゴリズム,рандомизированный алгоритм,случайный алгоритм,рандомизированный алгоритм
3601,randomized smoothing,تجانس عشوائي,تنعيم عشوائي,تصفية عشوائية,随机平滑,随机平滑,随机平滑化,lissage aléatoire,lissage aléatoire,lissage aléatoire,ランダム化された平滑化,ランダム化スムージング,ランダム化スムージング,рандомизированное сглаживание,случайное сглаживание,случайное сглаживание
3602,range query,استعلام النطاق,استعلام نطاق,استعلام النطاق,范围查询,范围查询,范围查询,requête de plage,requête de plage,requête de plage,範囲クエリ,範囲クエリ,範囲問い合わせ,запрос диапазона,диапазонный запрос,Запрос диапазона
3603,rank,رتبة,الترتيب,رتبة,秩,排名,排名,rang,"""['Dans ce cas, nous codons l'ensemble des éléments dans le morceau en écrivant son vecteur caractéristique en uj bits. Les opérations Access et NextGEQ peuvent être réduites aux opérations standard Rank et Select sur les vecteurs de bits; leur implémentation est décrite en détail dans [23].', 'X = [x 1 , • • • , x n , x n+1 ] . Étant donné un ensemble {u 1 , • • • , u n }, le",rang,ランク,ランク,順位,классифицировать,ранг,ранг
3604,rank model,نموذج الرتبة,نموذج الترتيب,نموذج الترتيب,等级模型,排名模型,排名模型,modèle de classement,modèle de classement,modèle de classement,ランクモデル,ランクモデル (rank model),ランク・モデル,ранговая модель,модель ранжирования,модель ранжирования
3605,rank-one update,تحديث المرتبة الأولى,التحديث من الرتبة الواحدة,تحديث الرتبة واحدة,一级更新,秩一更新,秩一更新,mise à jour de premier rang,mise à jour de rang un,mise à jour de rang un,ランクワンアップデート,ランクワン更新,階数1の更新,обновление первого ранга,ранг-один обновление,ранг-одно обновление
3606,ranking algorithm,خوارزمية الترتيب,- ترتيب الخوارزمية,خوارزمية الترتيب,排名算法,排名算法,排序算法,algorithme de classement,algorithme de classement,algorithme de classement,ランキングアルゴリズム,ランキングアルゴリズム (Ranking Algorithm),ランキングアルゴリズム,алгоритм ранжирования,алгоритм ранжирования,Алгоритм ранжирования
3607,ranking function,وظيفة الترتيب,دالة التصنيف,دالة الترتيب,排名功能,排名函数,排序函数,fonction de classement,Fonction de classement,fonction de classement,ランキング機能,ランキング関数 (Ranking function),ランキング関数,функция ранжирования,функция ранжирования,ранжирующая функция
3608,reachable state,حالة يمكن الوصول إليها,الحالة التي يمكن الوصول إليها,الحالة الممكن الوصول إليها,可达状态,可达状态 (reachable state),可达状态,état accessible,état accessible,état accessible,到達可能な状態,到達可能な状態,到達可能状態,достижимое состояние,достижимое состояние,достижимое состояние
3609,reading comprehension,قراءة الفهم,الفهم القراءة,فهم القراءة,阅读理解,阅读理解,阅读理解,compréhension écrite,compréhension de lecture,compréhension de lecture,読解,読解力,読解,Понимание прочитанного,Чтение понимания,понимание текста
3610,readout function,وظيفة القراءة,وظيفة القراءة,دالة القراءة,读出功能,读出函数,读出函数,fonction de lecture,fonction de lecture,fonction de lecture,読み出し機能,読み出し関数,読み出し関数,функция считывания,функция считывания,функция считывания
3611,recall,يتذكر,استدعاء,استرجاع,记起,召回率,召回率,rappel,"""['où L N CP est la perte obtenue à partir de la tâche de prédiction du caractère suivant et L aux est la perte auxiliaire décrite précédemment, nous utilisons λ = 1 20 dans nos expériences. La tâche auxiliaire d'extraction de la pile est évaluée en calculant les métriques de Précision et de Rappel pour chaque élément de la pile.', 'Notre approche offre une précision plus élevée que d'autres appro",rappel,想起,再現率,再現率,отзывать,"""['где L N CP - это потери, полученные из задачи прогнозирования следующего символа, и L aux - вспомогательные потери, описанные ранее, и мы используем λ = 1 20 в наших экспериментах. Вспомогательная задача извлечения стека оценивается путем вычисления метрик точ",напоминание
3612,receiver operating characteristic curve,منحنى خاصية التشغيل المتلقي,"It is recommended to keep the term ""Receiver Operating Characteristic Curve"" as is to avoid confusion.",منحنى خصائص التشغيل للمستقبل,接受者操作特征曲线,接收者操作特征曲线,受试者工作特征曲线,courbe caractéristique de fonctionnement du récepteur,Courbe de caractéristique de fonctionnement du récepteur,courbe caractéristique de fonctionnement du récepteur,受信機動作特性曲線,受信者動作特性曲線,"受信機動作特性曲線 (じゅしんきどうさくとくせいきょくせん)

ROC Curve",кривая рабочей характеристики приемника,Кривая характеристики операционной характеристики приемника (ROC-кривая),характеристическая кривая работы приемника
3613,receptive field,الحقل قابل للعدوي,- الحقل الاستقبالي,حقل استقبالي,感受野,接受域,感受野,champ receptif,champ réceptif,champ récepteur,受容野,受容野,受容野,рецептивное поле,рецептивное поле,рецептивное поле
3614,recognition,تعرُّف,التعرف,تمييز,认出,识别,识别,reconnaissance,- Recognition,reconnaissance,認識,認識 (にんしき),認識,признание,распознавание,распознавание
3615,recognition model,نموذج الاعتراف,نموذج التعرف,نموذج التعرف,识别模型,识别模型,识别模型,modèle de reconnaissance,modèle de reconnaissance,modèle de reconnaissance,認識モデル,認識モデル (Ninshiki Moderu),認識モデル,модель распознавания,модель распознавания,модель распознавания
3616,recognize textual entailment,التعرف على المضمون النصي,الاعتراف بالاستنتاج النصي,التعرف على الاستلزام النصي,识别文本蕴涵,识别文本蕴涵,识别文本蕴含关系,reconnaître les implications textuelles,reconnaissance d'implication textuelle,reconnaître l'implication textuelle,テキストの含意を認識する,"""['RTE（Dagan、Glickman、およびMagnini 2006;Bar-Haimら2006;Giampiccoloら2007;Bentivogliら2009）は、年次テキスト含意チャレンジのシリーズから来ている。SST-2（Socherら2013）スタンフォード感情ツリーバンクは、与えられた文章の極性",テキスト推論を認識する,распознавать текстовые следствия,Распознавание текстуальной вместимости,распознавание текстовой импликации
3617,recommendation algorithm,خوارزمية التوصية,خوارزمية التوصيات,خوارزمية التوصية,推荐算法,推荐算法,推荐算法,algorithme de recommandation,algorithme de recommandation,algorithme de recommandation,推奨アルゴリズム,推薦アルゴリズム (suisen arugorizumu),推薦アルゴリズム,алгоритм рекомендаций,алгоритм рекомендаций,алгоритм рекомендации
3618,recommendation model,نموذج التوصية,نموذج التوصية,نموذج التوصية,推荐模型,推荐模型 (recommendation model),推荐模型,modèle de recommandation,- Modèle de recommandation,modèle de recommandation,推奨モデル,- 推薦モデル (suisen moderu),推薦モデル,рекомендательная модель,модель рекомендаций,Модель рекомендаций
3619,recommendation system,نظام التوصية,نظام التوصيات,نظام التوصيات,推荐系统,推荐系统,推荐系统,système de recommandation,système de recommandation,système de recommandation,推薦制度,推薦システム (suisen shisutemu),推薦システム,система рекомендаций,система рекомендаций,Система рекомендаций
3620,recommender,الموصي,منظومة التوصيات,نظام التوصية,推荐人,推荐器,推荐系统,recommandateur,recommandeur,systeme de recommandation,推薦者,レコメンダー,おすすめシステム,рекомендатель,"""['В данной статье мы изучаем проблему смягчения путей радикализации с использованием графового подхода. В частности, мы моделируем набор рекомендаций рекомендателя ""что посмотреть дальше"" как ориентированный граф , где узлы соответствуют элементам контента, связи - р",рекомендатель
3621,recommender system,نظام التوصية,نظام التوصيات,نظام التوصية,推荐系统,推荐系统,推荐系统,système de recommandation,système de recommandation,système de recommandation,推薦システム,おすすめシステム (osusume shisutemu),推薦システム,рекомендательная система,Система рекомендаций,система рекомендаций
3622,reconstruction algorithm,خوارزمية إعادة الإعمار,خوارزمية إعادة البناء,خوارزمية إعادة البناء,重建算法,重建算法,重建算法,algorithme de reconstruction,algorithme de reconstruction,algorithme de reconstruction,再構成アルゴリズム,再構築アルゴリズム (saikoukaku arugorizumu),再構成アルゴリズム,алгоритм реконструкции,алгоритм восстановления,алгоритм восстановления
3623,reconstruction error,خطأ في إعادة الإعمار,خطأ إعادة الإعمار,خطأ إعادة البناء,重构误差,重建误差,重建误差,erreur de reconstruction,erreur de reconstruction,erreur de reconstruction,再構成エラー,再構成誤差 (saikousei gosa),復元誤差,ошибка реконструкции,ошибка реконструкции,ошибка восстановления
3624,reconstruction loss,خسارة إعادة الإعمار,الخسارة في إعادة البناء,فقدان إعادة البناء,重建损失,重建损失,重建损失,perte de reconstruction,perte de reconstruction,perte de reconstruction,復興損失,再構築損失 (saikouchiku sonshitsu),再構築損失,потери на реконструкцию,потеря восстановления,потери реконструкции
3625,recovery algorithm,خوارزمية الاسترداد,خوارزمية الاسترداد,خوارزمية الاسترداد,恢复算法,恢复算法,恢复算法,algorithme de récupération,algorithme de récupération,Algorithme de récupération,回復アルゴリズム,回復アルゴリズム (kaifuku arugorizumu),復元アルゴリズム,алгоритм восстановления,алгоритм восстановления,алгоритм восстановления
3626,rectify linear unit,تصحيح الوحدة الخطية,وحدة خطية معدلة,وحدة خطية معتدلة,校正线性单元,修正线性单元,整流线性单元,rectifier l'unité linéaire,- Unité linéaire rectifiée,unité linéaire rectifiée,リニアユニットを修正する,線形ユニットを修正,整流線形ユニット,исправить линейную единицу,выпрямленный линейный блок,линейная выпрямляющая функция
3627,rectify stereo pair,تصحيح زوج الاستريو,تصحيح زوج ستيريو,تصحيح زوج مجسم,校正立体声对,校正立体对,校正立体对,rectifier la paire stéréo,paire stéréo rectifiée,paire stéréo rectifiée,ステレオペアを修正する,正規化されたステレオペア,矯正された立体ペア,исправить стереопару,Прямой стереопара,выпрямить стереопару
3628,recurrent,متكرر,- تناوبية,متكرر,经常性的,循环的,循环的,récurrent,récurrent,récurrent,再発する,再発性 (さいはつせい),再帰,повторяющийся,рекуррентный,рекуррентная
3629,recurrent architecture,العمارة المتكررة,الهندسة المعمارية العودية,البنية المتكررة,循环架构,循环架构,循环架构,architecture récurrente,- Architecture récurrente,architecture récurrente,リカレントアーキテクチャ,再帰的なアーキテクチャ,再帰的アーキテクチャ,рекуррентная архитектура,рекуррентная архитектура,рекуррентная архитектура
3630,recurrent autoencoder,التشفير التلقائي المتكرر,المشفر الذاتي العائد,محول ذاتي متكرر,循环自动编码器,循环自编码器,循环自编码器,auto-encodeur récurrent,autoencodeur récurrent,auto-encodeur récurrent,反復オートエンコーダ,再帰オートエンコーダ (saiki ootoenkooda),再帰自己エンコーダ,рекуррентный автокодировщик,рекуррентный автоэнкодер,рекуррентный автокодировщик
3631,recurrent connection,اتصال متكرر,الاتصال العائد,ربط متكرر,循环连接,重复连接,循环连接,connexion récurrente,connexion récurrente,connexion récurrente,反復接続,再帰接続,再帰接続,рекуррентное соединение,рекуррентное соединение,соединение с обратными связями
3632,recurrent dynamic,ديناميكية متكررة,الديناميات المتكررة,ديناميكيات متكررة,循环动态,循环动态,循环动力学,dynamique récurrente,dynamique récurrente,dynamique récurrente,反復的な動的,繰り返し動的,再発的動力学,повторяющаяся динамика,рекуррентная динамика,рекуррентная динамика
3633,recurrent layer,طبقة متكررة,الطبقة العائدة,طبقة متكررة,循环层,循环层,循环层,couche récurrente,couche récurrente,couche récurrente,リカレント層,再発層,再帰層,повторяющийся слой,рекуррентный слой,рекуррентный слой
3634,recurrent model,نموذج متكرر,النموذج المتكرر,نموذج متكرر,循环模型,循环模型,循环模型,modèle récurrent,modèle récurrent,modèle récurrent,リカレントモデル,再帰モデル,再帰モデル,рекуррентная модель,рекуррентная модель,рекуррентная модель
3635,recurrent network,الشبكة المتكررة,شبكة متكررة,شبكة متكررة,循环网络,循环网络,循环网络,réseau récurrent,réseau récurrent,réseau récurrent,リカレントネットワーク,再帰ネットワーク,再帰ネットワーク,рекуррентная сеть,рекуррентная сеть,рекуррентная сеть
3636,recurrent state,حالة متكررة,الحالة المتكررة,حالة متكررة,复发状态,- 术语：循环状态,循环状态,état récurrent,état récurrent,état récurrent,再発状態,再発状態,再帰状態,рецидивирующее состояние,рекуррентное состояние,рекуррентное состояние
3637,recursion,العودية,التكرار,تكرار,递归,递归,递归,récursivité,récursivité,récursion,再帰,再帰 (saiki),再帰,рекурсия,рекурсия,рекурсия
3638,recursive call,مكالمة متكررة,- تسمية مستدعية,دعوة متكررة,递归调用,递归调用,递归调用,appel récursif,Appel récursif,appel récursif,再帰呼び出し,再帰呼び出し,再帰呼び出し,рекурсивный вызов,- Рекурсивный вызов,Рекурсивный вызов
3639,recursive neural model,النموذج العصبي العودي,نموذج عصبي تكراري,نموذج عصبي تراجعي,递归神经模型,递归神经模型,递归神经模型,modèle neuronal récursif,modèle neuronal récursif,modèle neuronal récursif,再帰的ニューラル モデル,再帰ニューラルモデル (saiki nyūraru moderu),再帰的ニューラルモデル,рекурсивная нейронная модель,рекурсивная нейронная модель,рекурсивная нейронная модель
3640,recursive neural network,الشبكة العصبية العودية,شبكة عصبية تكرارية,شبكة عصبية متكررة,递归神经网络,递归神经网络,递归神经网络,réseau neuronal récursif,- Réseau neuronal récursif,réseau neuronal récursif,再帰的ニューラル ネットワーク,再帰ニューラルネットワーク,再帰ニューラルネットワーク,рекурсивная нейронная сеть,рекурсивная нейронная сеть,рекуррентная нейронная сеть
3641,reference distribution,التوزيع المرجعي,التوزيع المرجعي,التوزيع المرجعي,参考分布,参考分布,参考分布,distribution de référence,distribution de référence,distribution de référence,参照分布,参照分布 (さんしょうぶんぷ),参照分布,эталонное распределение,опорное распределение,опорное распределение
3642,reference resolution,القرار المرجعي,حل المراجعة,حل الإشارات,参考分辨率,"""['这种模式发生在需要实时处理的交互式环境中，例如在对话中进行语流不连贯检测或参考解析（Hough和Schlangen，2015年；Kennington和Schlangen，2017年）以及同时翻译（Cho和Esipova，2016年；Arivazhagan等，2020年；Sen等，2023年）。', '诸如“一个地址”之类的",指代解析,résolution de référence,résolution de référence,résolution des références,基準解像度,参照解析,参照解決,эталонное разрешение,разрешение ссылок,разрешение референции
3643,reference text,النص المرجعي,نص المرجعية,نص مرجعي,参考文本,参考文本,参考文本,texte de référence,texte de référence,texte de référence,参考テキスト,参照テキスト,リファレンステキスト,справочный текст,справочный текст,Эталонный текст
3644,reference-base metric,مقياس القاعدة المرجعية,المقياس المرجعي الأساسي,مقياس قائم على المرجع,参考基准度量,基于参考的度量,基于参考译文的指标,métrique de base de référence,métrique basée sur la référence,métrique basée sur la référence,参照ベースのメトリック,参照ベースメトリック,参照ベースの指標,эталонная метрика,метрика на основе ссылок,метрика на основе эталонного перевода
3645,refinement network,شبكة الصقل,شبكة التحسين,شبكة التحسين,细化网络,细化网络,细化网络,réseau de raffinement,réseau de raffinement,réseau d'affinage,リファインメントネットワーク,リファインメントネットワーク,精緻化ネットワーク,нефтеперерабатывающая сеть,сеть улучшения,сеть уточнения
3646,regression,تراجع,- تحوّلية,انحدار,回归,回归,回归,régression,régression,régression,回帰,"""['我々はかなり良い結果を出した回帰サポートベクターマシン（SVM）を訓練しました。予測された値と実際の発生との相関は、クロスバリデーション実験では約0.94です。ただし、特定の閾値を超える値を予測するため",回帰 (kaiki),регресс,регрессия,регрессия
3647,regression analysis,تحليل الانحدار,- تحليل الانحدار,تحليل الانحدار,回归分析,回归分析,回归分析,analyse de régression,analyse de régression,analyse de régression,回帰分析,回帰分析 (かいきぶんせき),回帰分析,регрессивный анализ,регрессионный анализ,регрессионный анализ
3648,regression coefficient,معامل الانحدار,معامل الانحدار,معامل الانحدار,回归系数,回归系数,回归系数,Coefficient de régression,coefficient de régression,coefficient de régression,回帰係数,回帰係数,回帰係数,коэффициент регрессии,коэффициент регрессии,регрессионный коэффициент
3649,regression function,وظيفة الانحدار,دالة الانحدار,دالة الانحدار,回归函数,回归函数,回归函数,fonction de régression,fonction de régression,fonction de régression,回帰関数,回帰関数 (kaiki kansu),回帰関数,функция регрессии,функция регрессии,функция регрессии
3650,regression model,نموذج الانحدار,نموذج الانحدار,نموذج الانحدار,回归模型,回归模型,回归模型,Modèle de régression,modèle de régression,modèle de régression,回帰モデル,回帰モデル (kaiki moderu),回帰モデル,регрессионная модель,модель регрессии,Регрессионная модель
3651,regression problem,مشكلة الانحدار,مشكلة الانحدار,مشكلة الانحدار,回归问题,回归问题,回归问题,problème de régression,problème de régression,problème de régression,回帰問題,回帰問題 (kaiki mondai),回帰問題,проблема регрессии,проблема регрессии,задача регрессии
3652,regression task,مهمة الانحدار,مهمة الانحدار,مهمة الانحدار,回归任务,回归任务 (regression task),回归任务,tâche de régression,tâche de régression,tâche de régression,回帰タスク,回帰タスク,回帰タスク,задача регрессии,задача регрессии,Задача регрессии
3653,regression tree,شجرة الانحدار,شجرة الانحدار,شجرة الانحدار,回归树,回归树 (regression tree),回归树,arbre de régression,arbre de régression,arbre de régression,回帰木,回帰木 (kaiki ki),回帰木,дерево регрессии,регрессионное дерево,дерево регрессии
3654,regressor,تراجع,مُعيد الانحدار,مُقَدِّر,回归量,回归器,回归器,régresseur,régresseur,régresseur,リグレッサー,回帰器,回帰子,регрессор,регрессор,регрессор
3655,regret bind,ربط الأسف,حد الندم,مقيد الندم,后悔绑定,后悔绑定,遗憾约束,regretter lier,limite de regret,attache de regret,後悔の束縛,後悔バインド,後悔束縛,сожаление связывает,привязка к сожалению,связывание сожалений
3656,regret matching,مطابقة الندم,تطابق الندم,مطابقة الندم,后悔匹配,后悔匹配,后悔匹配,regretter la correspondance,appariement des regrets,Appariement des regrets,マッチングを後悔,後悔マッチング,後悔マッチング,сожаление о совпадении,регрет-сопоставление,сопоставление сожалений
3657,regret minimization,التقليل من الندم,تقليل الندم,تقليل الندم,遗憾最小化,后悔最小化,最小遗憾,minimiser les regrets,minimisation des regrets,minimisation du regret,後悔の最小化,後悔最小化,後悔最小化,минимизация сожаления,минимизация сожалений,минимизация сожаления
3658,regret minimization algorithm,خوارزمية التقليل من الندم,خوارزمية تقليل الندم,خوارزمية تقليل الندم,遗憾最小化算法,后悔最小化算法,最小遗憾算法,algorithme de minimisation des regrets,algorithme de minimisation du regret,algorithme de minimisation du regret,後悔最小化アルゴリズム,後悔最小化アルゴリズム (Kōkai saishōka arugorizumu),後悔最小化アルゴリズム,алгоритм минимизации сожалений,алгоритм минимизации сожалений,Алгоритм минимизации сожалений
3659,regret minimizer,الأسف التقليل,مقلل الندم,مُقلِّل الندم,后悔最小化,后悔最小化器,后悔最小化器,minimiseur de regret,minimisateur de regret,minimiseur de regret,後悔を最小限に抑える,後悔最小化器 (koukai saishouka-ki),後悔最小化器,минимизатор сожалений,минимизатор сожаления,минимизатор сожалений
3660,regular expression,تعبير عادي,- التعبير العادي,تعبير منتظم,正则表达式,正则表达式,正则表达式,expression régulière,- Expression régulière,expression régulière,正規表現,正規表現,正規表現,регулярное выражение,Регулярное выражение,регулярное выражение
3661,regularisation,التنظيم,- تنظيمية,تنظيم,正则化,正规化,正则化,régularisation,régularisation,régularisation,正則化,正則化,正則化,регуляризация,регуляризация,регуляризация
3662,regularization,التنظيم,التحديد,تنظيم,正则化,正则化,正则化,régularisation,régularisation,régularisation,正則化,正則化 (seisokuka),正規化,регуляризация,регуляризация,регуляризация
3663,regularization constant,ثابت التنظيم,ثابت التنظيم,ثابت التنظيم,正则化常数,正则化常数,正则化常数,constante de régularisation,constante de régularisation,constante de régularisation,正則化定数,正則化定数 (seisokuka teisuu),正規化定数,константа регуляризации,константа регуляризации,константа регуляризации
3664,regularization function,وظيفة التنظيم,وظيفة التنظيمية,دالة التنظيم,正则化函数,正规化函数,正则化函数,fonction de régularisation,fonction de régularisation,fonction de régularisation,正則化関数,正則化関数 (seisokuka kansu),正則化関数,функция регуляризации,регуляризационная функция,функция регуляризации
3665,regularization loss,فقدان التنظيم,الخسارة المنتظمة,خسارة التنظيم,正则化损失,正则化损失,正则化损失,perte de régularisation,perte de régularisation,perte de régularisation,正則化損失,正則化損失 (seisokuka sonshitsu),正則化損失,потеря от регуляризации,функция регуляризации,потеря регуляризации
3666,regularization parameter,معلمة التنظيم,معامل التنظيم,معامل التنظيم,正则化参数,正规化参数,正则化参数,paramètre de régularisation,paramètre de régularisation,paramètre de régularisation,正則化パラメータ,正規化パラメータ,正則化パラメータ,параметр регуляризации,параметр регуляризации,параметр регуляризации
3667,regularization path,مسار التنظيم,مسار التنظيم,مسار التنظيم,正则化路径,正则化路径,正则化路径,chemin de régularisation,chemin de régularisation,chemin de régularisation,正則化パス,正則化パス,正則化パス,путь регуляризации,регуляризационный путь,путь регуляризации
3668,regularization penalty,عقوبة التنظيم,عقوبة التنظيمية,عقوبة التنظيم,正则化惩罚,正则化惩罚,正则化惩罚,pénalité de régularisation,pénalité de régularisation,pénalité de régularisation,正則化ペナルティ,正則化ペナルティ,正則化ペナルティ,штраф за регуляризацию,регуляризующее штрафное воздействие,штраф регуляризации
3669,regularization strength,قوة التنظيم,قوة التنظيمية,قوة التنظيم,正则化强度,正则化强度,正则化强度,force de régularisation,force de régularisation,force de régularisation,正則化の強さ,正則化強度,正則化強度,сила регуляризации,сила регуляризации,сила регуляризации
3670,regularization term,مصطلح التسوية,مصطلح التنظيم,مُصطَلَح التَّنظيم,正则化项,正则化项,正则化项,terme de régularisation,terme de régularisation,terme de régularisation,正則化項,正則化項,正則化項,срок регуляризации,термин регуляризации,регуляризационный член
3671,regularization weight,وزن التنظيم,وزن التنظيمية,وزن التنظیم,正则化权重,正则化权重,正则化权重,poids de régularisation,poids de régularisation,poids de régularisation,正則化の重み,正則化重み (seisokuka omomi),正則化重み,вес регуляризации,вес регуляризации,вес регуляризации
3672,regularization-base method,طريقة قاعدة التنظيم,الطرق المعتمدة على التنظيم,طريقة قائمة على التنظيم,基于正则化的方法,正则化基础方法 (Regularization-Based Methods),基于正则化的方法,méthode basée sur la régularisation,méthode basée sur la régularisation,méthode basée sur la régularisation,正則化ベースのメソッド,正則化ベースの方法,正則化ベース手法,метод на основе регуляризации,методы на основе регуляризации,метод на основе регуляризации
3673,regularizer,منظم,المنظم - الضبطية,مُنَظِّم,正则化器,正则化器,正则化项,régularisateur,régulariseur,régularisateur,レギュラライザー,正則化項,正則化項,регуляризатор,регуляризатор,регуляризатор
3674,reinforcement Learning,تعزيز التعلم,تعلم التعزيز,التعزيز التعلمي,强化学习,强化学习,强化学习,apprentissage par renforcement,Apprentissage par renforcement,apprentissage par renforcement,強化学習,強化学習,強化学習,обучение с подкреплением,Обучение с подкреплением,обучение с подкреплением
3675,reinforcement learning algorithm,خوارزمية التعلم المعزز,خوارزمية تعلم التعزيز,خوارزمية التعلم التعزيزي,强化学习算法,强化学习算法,强化学习算法,algorithme d'apprentissage par renforcement,algorithme d'apprentissage par renforcement,Algorithme d'apprentissage par renforcement,強化学習アルゴリズム,強化学習アルゴリズム (Kyōka gakushū arugorizumu),強化学習アルゴリズム,алгоритм обучения с подкреплением,алгоритм обучения с подкреплением,алгоритм обучения с подкреплением
3676,rejection sampling,أخذ عينات الرفض,- تحديد العينات,عينة الرفض,拒绝抽样,拒绝抽样,拒绝采样,échantillonnage de rejet,méthode de rejet,échantillonnage par rejet,拒絶サンプリング,棄却サンプリング,棄却サンプリング,отбраковочная выборка,"""['Практики традиционно используют схемы выборки [MacKay, 2003] для приближения апостериорных распределений. Метод отбора и различные методы МСМК являются обычным выбором. Преимущество методов МСМК заключается в их теоретических гарантиях",отбор отбрасыванием
3677,relation extraction,استخراج العلاقة,استخراج العلاقة,استخراج العلاقات,关系抽取,关系抽取,关系提取,extraction de relations,extraction de relation,extraction de relations,関係抽出,関係抽出 (kankei shushutsu),関係抽出,извлечение отношений,извлечение отношений,извлечение отношений
3678,relation type,نوع العلاقة,نوع العلاقة,نوع العلاقة,关系类型,关系类型,关系类型,type de relation,type de relation,type de relation,関係タイプ,- 関係タイプ (kankei taipu),関係タイプ,тип отношения,тип отношения,тип отношения
3679,relational tuple,صف علائقي,صفيف علاقات,نائمة علائقية,关系元组,关系元组,关系元组,tuple relationnel,tuple relationnel,n-uplet relationnel,リレーショナルタプル,関係タプル,関係タプル,реляционный кортеж,реляционный кортеж,реляционное отношение
3680,relative entropy,الانتروبيا النسبية,الانحراف النسبي,الإنتروبيا النسبية,相对熵,相对熵,相对熵,entropie relative,entropie relative,entropie relative,相対エントロピー,相対エントロピー,相対エントロピー,относительная энтропия,Относительная энтропия,относительная энтропия
3681,relative positional embedding,التضمين الموضعي النسبي,تضمين موضعي نسبي,"التضمين الموضعي النسبي

ALiBi",相对位置嵌入,相对位置嵌入,相对位置嵌入,intégration positionnelle relative,incrustation positionnelle relative,Plongement positionnel relatif,相対位置埋め込み,相対的な位置埋め込み,相対位置埋め込み,относительное позиционное вложение,относительное позиционное вложение,относительное позиционное встраивание
3682,relevance score,درجة الصلة,نقطة الصلة,درجة الصلة,相关性得分,相关性评分,相关性分数,score de pertinence,- Score de pertinence,score de pertinence,関連性スコア,関連スコア,関連スコア,оценка релевантности,Оценка релевантности,оценка релевантности
3683,render network,تقديم الشبكة,شبكة التجسيد,شبكة التصوير,渲染网络,渲染网络,渲染网络,réseau de rendu,réseau de rendu,rendu réseau,レンダリングネットワーク,レンダリングネットワーク,レンダリングネットワーク,сеть рендеринга,сеть рендеринга,сеть визуализации
3684,renormalization,إعادة التطبيع,إعادة التطبيع,إعادة ترميز,重整化,重新标定,重归一化,renormalisation,renormalisation,renormalisation,繰り込み,レノーマライゼーション,正規化,перенормировка,ренормализация,перенормировка
3685,reparameterization,إعادة المعلمة,إعادة تعيين المعلمات,إعادة ترميز,重新参数化,重新参数化,重参数化,reparamétrage,reparamétrisation,reparamétrisation,再パラメータ化,再パラメータ化,再パラメータ化,репараметризация,репараметризация,Перепараметризация
3686,reparameterization trick,خدعة إعادة المعلمة,الخدعة التكييفية,حيلة إعادة البرمجة,重新参数化技巧,重参数化技巧,重参数化技巧,astuce de reparamétrage,astuce de reparamétrisation,Tour de reparamétrisation,再パラメータ化のトリック,再パラメータ化トリック,再パラメータ化トリック,трюк с перепараметризацией,трюк репараметризации,Трюк репараметризации
3687,replay buffer,إعادة تشغيل المخزن المؤقت,المخزون التكراري,ذاكرة تخزين مؤقتة,重播缓冲区,重放缓冲区,经验回放缓冲区,tampon de relecture,tampon de répétition,tampon de relecture,リプレイバッファ,リプレイバッファ (replay buffer),再生バッファ,буфер воспроизведения,буфер воспроизведения,буфер воспроизведения
3688,replay memory,إعادة تشغيل الذاكرة,ذاكرة الإعادة,ذاكرة إعادة التشغيل,重播记忆,重播记忆,重放回放记忆体,rejouer la mémoire,mémoire de répétition,mémoire de rejeu,記憶を再生する,リプレイメモリ,リプレイメモリ,Воспроизведение памяти,память повтора,буфер воспроизведения
3689,representation,التمثيل,التمثيل,تمثيل,表示,表示 (representation),表示,représentation,représentation,représentation,表現,表現 (hyougen),表現,представление,представление,представление
3690,representation learning,تعلم التمثيل,تعلم التمثيل,تعلم التمثيل,表征学习,表征学习,表征学习,apprentissage des représentations,apprentissage de la représentation,apprentissage de représentation,表現学習,表現学習,表現学習,обучение представлению,обучение представлению,обучение представлений
3691,representation matrix,مصفوفة التمثيل,مصفوفة التمثيل,مصفوفة التمثيل,表示矩阵,表示矩阵,表示矩阵,matrice de représentation,matrice de représentation,matrice de représentation,表現行列,表現行列 (hyōgen gyōretsu),表現行列,матрица представления,матрица представления,матрица представления
3692,representation space,مساحة التمثيل,مساحة التمثيل,مساحة التمثيل,表示空间,表征空间,表示空间,espace de représentation,- Espace de représentation,espace de représentation,表現空間,表現空間,表現空間,пространство представления,пространство представлений,пространство представления
3693,representation vector,ناقلات التمثيل,متجه التمثيل,مُتجه التمثيل,表示向量,表示向量,表征向量,vecteur de représentation,vecteur de représentation,vecteur de représentation,表現ベクトル,表現ベクトル,表現ベクトル,вектор представления,вектор представления,вектор представления
3694,representer theorem,نظرية الممثل,نظرية ممثل البيان,نظرية المُمثل,表示定理,表现者定理,再现定理,théorème des représentants,théorème du représentant,Théorème du représentant,代表定理,リプレゼンター定理,再現定理,теорема о представителе,теорема представителя,теорема представителя
3695,reproduce kernel hilbert space,إعادة إنتاج مساحة نواة هيلبرت,مساحة هيلبرت النواة المُنتَجة,فضاء هيلبرت للإنتاج النووي,重现内核希尔伯特空间,再现核希尔伯特空间 (Reproduce Kernel Hilbert Space),再生核希尔伯特空间,reproduire l'espace Hilbert du noyau,espace de Hilbert à noyau reproducteur,espace de Hilbert à noyau reproduisant,カーネル・ヒルベルト空間を再現する,再生カーネルヒルベルト空間 (Saisei Kāneru Hiruberuto Kūkan),再生カーネル ヒルベルト 空間,воспроизвести гильбертово пространство ядра,воспроизводящее ядро гильбертового пространства (RKHS),ядерное воспроизводящее гильбертово пространство
3696,reproduce property,إعادة إنتاج الممتلكات,خاصية التكرار,خاصية التكرار,再现财产,再现性质,再现性质,reproduire la propriété,propriété de reproduction,propriété de reproduction,財産を再現する,再生特性,再生性能,воспроизводить собственность,свойство воспроизведения,воспроизводящее свойство
3697,reprojection,إعادة الإسقاط,إعادة الإسقاط,إعادة التصوير,重投影,重新投影 (reprojection),重投影,reprojection,reprojeter,reprojection,再投影,再投影 (さいとうえい),再投影,перепроецирование,репроекция,перепроецирование
3698,reprojection error,خطأ في الاستنساخ,خطأ إعادة الإسقاط,خطأ إعادة الإسقاط,重投影误差,重投影误差,重投影误差,erreur de reprojection,erreur de reprojection,erreur de reprojection,再投影エラー,再投影誤差 (さいとうしゃごさ),再投影誤差,ошибка перепроецирования,ошибка повторного проецирования,ошибка репроекции
3699,reranker,معيد الترتيب,إعادة التصنيف,إعادة الترتيب,重新排序,重排序器 (reranker),重排器,reclasseur,reranker,réordonnanceur,リランカー,再ランカー,再ランキング器,реранкер,переподборщик,перераспределитель
3700,reranking model,نموذج إعادة الترتيب,نموذج إعادة الترتيب,نموذج إعادة الترتيب,重新排序模型,重新排序模型 (reranking model),重排序模型,modèle de reclassement,modèle de réarrangement,modèle de reclassement,再ランキングモデル,再ランキングモデル,再ランキングモデル,модель реранжирования,модель повторного ранжирования,модель переранжирования
3701,reranking parser,إعادة ترتيب المحلل اللغوي,محلل إعادة التصنيف,محلل إعادة الترتيب,重新排序解析器,重新排序解析器,重排序分析器,analyseur de reclassement,analyseur de réordonnancement,analyseur de reclassement,再ランキングパーサー,再順位付けパーサ,再ランキングパーサー,парсер переранжирования,переранжировка парсера,переранжировщик синтаксических деревьев
3702,reservoir sampling,أخذ عينات من الخزان,عينة الخزان,حصر العينات,水库取样,水库抽样,蓄水池采样,échantillonnage du réservoir,échantillonnage de réservoir,échantillonnage par réservoir,貯留層のサンプリング,リザーバーサンプリング,レザボア・サンプリング,отбор проб пласта,выборка из резервуара,резервное выборка
3703,residual block,كتلة المتبقية,كتلة باقيه,كتلة متبقية,残差块,残差块,残差块,bloc résiduel,- Bloc résiduel,bloc résiduel,残留ブロック,残余ブロック,残差ブロック,остаточный блок,остаточный блок,остаточный блок
3704,residual branch,فرع المتبقية,الفرع الباقي,الفرع المتبقي,剩余分支,残差分支,残差分支,branche résiduelle,branche résiduelle,branche résiduelle,残りの枝,残余ブランチ,残余分岐,остаточная ветвь,остаточная ветвь,Остаточная ветвь
3705,residual connection,اتصال المتبقية,"""[""(7)، يتم تكبير D t ds إلى حجم 1/4 من B. نقوم بإضافة D t ds مع إدخال الكتلة F t−1 كتوصيل باقي، ويتم تمرير الميزة الناتجة F t إلى الكتلة التالية. التراكم على مستوى الحالة. يمث",اتصال متبقي,剩余连接,残差连接,残差连接,connexion résiduelle,connexion résiduelle,connexion résiduelle,残りの接続,残留接続,残余接続,остаточное соединение,остаточное соединение,остаточное соединение
3706,residual error,الخطأ المتبقي,الخطأ الباقي,الخطأ المتبقي,残差,剩余误差,残差误差,erreur résiduelle,erreur résiduelle,erreur résiduelle,残留誤差,残差エラー (zansa era),残差誤差,остаточная ошибка,остаточная ошибка,остаточная ошибка
3707,residual function,الوظيفة المتبقية,الدالة المتبقية,دالة المتبقية,残差函数,剩余函数,残差函数,fonction résiduelle,fonction résiduelle,fonction résiduelle,残差関数,残留関数,残差関数,остаточная функция,остаточная функция,остаточная функция
3708,residual graph,الرسم البياني المتبقي,الرسم البياني المتبقي,رسم متبقي,残差图,残留图,残余图,graphique résiduel,graphe résiduel,graphe résiduel,残差グラフ,残余グラフ,残余グラフ,остаточный граф,остаточный граф,Остаточный граф
3709,residual learning,التعلم المتبقي,التعلم الباقي,التعلم المتبقي,剩余学习,剩余学习,残差学习,apprentissage résiduel,apprentissage résiduel,apprentissage résiduel,残余学習,残余学習,残差学習,остаточное обучение,остаточное обучение,остаточное обучение
3710,residual network,الشبكة المتبقية,شبكة بقايا,شبكة متبقية,残差网络,残差网络,残差网络,réseau résiduel,réseau résiduel,réseau résiduel,残余ネットワーク,残差ネットワーク,残差ネットワーク,остаточная сеть,остаточная сеть,остаточная сеть
3711,restricted isometry property,خاصية متساوي القياس المقيدة,خاصية العزل الضيق,خاصية التشوه المقيد,受限等距性质,受限等距性质,限制等距性质,propriété d'isométrie restreinte,propriété d'isométrie restreinte,Propriété d'isométrie restreinte,制限されたアイソメトリ プロパティ,制限等加性性,制限等距離性条件,свойство ограниченной изометрии,свойство ограниченной изометрии,свойство ограниченной изометрии
3712,retrieval,استرجاع,- التعريف,استرجاع,恢复,检索,检索,récupération,récupération,récupération,検索,取得,検索,поиск,извлечение,извлечение
3713,retrieval function,وظيفة الاسترجاع,وظيفة الاسترجاع,وظيفة الاسترجاع,检索功能,检索函数 (retrieval function),检索函数,fonction de récupération,fonction de récupération,fonction de récupération,検索機能,検索関数,検索関数,функция поиска,функция поиска,функция извлечения
3714,retrieval method,طريقة الاسترجاع,طريقة الاسترجاع,طريقة الاسترجاع,检索方法,检索方法,检索方法,méthode de récupération,Méthode de récupération,méthode de récupération,検索方法,検索方法,検索手法,метод поиска,метод извлечения,метод извлечения
3715,retrieval model,نموذج الاسترجاع,نموذج الاسترداد,نموذج الاسترجاع,检索模型,检索模型,检索模型,modèle de récupération,modèle de recherche,modèle de récupération,検索モデル,検索モデル,検索モデル,поисковая модель,модель поиска,модель извлечения
3716,retrieval system,نظام الاسترجاع,نظام الاسترجاع,نظام استرجاع,检索系统,检索系统,检索系统,système de récupération,système de récupération,système de récupération,検索システム,情報検索システム,検索システム,поисковая система,система поиска,Система поиска
3717,retrieval-augment generation,توليد زيادة الاسترجاع,تعظيم الاسترجاع والتوليد,إنشاء مدعم باسترجاع,检索增强生成,检索增强生成,检索增强生成,génération de récupération et d'augmentation,génération augmentée par récupération,génération augmentée par récupération,検索拡張生成,検索増強生成 (Retrieval-Augmented Generation),検索拡張生成,генерация поискового дополнения,увеличение поиска и генерации,генерация с поиском и дополнением
3718,reverse-mode,الوضع العكسي,وضع العكس,وضع معاكس,反向模式,逆向模式,反向传播模式,mode inverse,mode inverse,mode de rétropropagation,リバースモード,逆モード,逆モード,реверсивный режим,обратный режим,обратный режим
3719,reward,جائزة,مكافأة,مكافأة,报酬,奖励,奖励,récompense,- Récompense,récompense,褒美,報酬 (ほうしゅう),報酬,награда,- Вознаграждение,награда
3720,reward function,وظيفة المكافأة,وظيفة المكافأة,دالة المكافأة,奖励函数,奖励函数,奖励函数,fonction de récompense,fonction de récompense,fonction de récompense,報酬関数,報酬関数 (ほうしゅう かんすう),報酬関数,функция вознаграждения,функция вознаграждения,функция вознаграждения
3721,reward model,نموذج المكافأة,نموذج المكافأة,نموذج المكافأة,奖励模式,奖励模型,奖赏模型,modèle de récompense,modèle de récompense,modèle de récompense,報酬モデル,報酬モデル (ほうしゅうモデル),報酬モデル,модель вознаграждения,модель вознаграждения,модель вознаграждения
3722,reward shaping,تشكيل المكافأة,تشكيل المكافأة,تشكيل المكافأة,奖励塑造,奖励塑造,奖励塑形,façonnage des récompenses,mise en forme de la récompense,façonnement de la récompense,報酬の形成,報酬整形 (Reward Shaping),報酬成形,формирование вознаграждения,формирование вознаграждения,формирование награды
3723,reward signal,إشارة المكافأة,إشارة المكافأة,إشارة المكافأة,奖励信号,奖励信号,奖赏信号,signal de récompense,- Signal de récompense,signal de récompense,報酬信号,報酬信号 (reward signal),報酬信号,сигнал вознаграждения,сигнал вознаграждения,сигнал вознаграждения
3724,reward-maximize policy,سياسة تعظيم المكافأة,سياسة تعظيم الجوائز,سياسة تعظيم المكافأة,奖励最大化政策,奖励最大化策略,最大化奖励策略,politique de maximisation des récompenses,politique de maximisation de la récompense,Politique de maximisation de la récompense,報酬最大化政策,報酬を最大化する方策,報酬最大化ポリシー,политика максимизации вознаграждения,политика максимизации вознаграждения,Политика максимизации вознаграждения
3725,rhetorical structure theory,نظرية البنية البلاغية,نظرية البنية البلاغية,نظرية البنية الخطابية,修辞结构理论,修辞结构理论,修辞结构理论,théorie de la structure rhétorique,théorie de la structure rhétorique,théorie de la structure rhétorique,レトリック構造理論,- 翻訳された用語：修辞構造理論,修辞構造理論,теория риторической структуры,теория риторической структуры,теория риторической структуры
3726,ridge regression,انحدار ريدج,- تحليل الانحدار العامودي,إنحدار الحافة,岭回归,岭回归,岭回归,régression de crête,régression ridge,régression ridge,リッジ回帰,リッジ回帰,リッジ回帰,регрессия гребня,Ридж-регрессия,Гребневая регрессия
3727,ridge regularization,تنظيم التلال,- تسوية الظهرية,تنظيم الحافة,岭正则化,岭正则化,岭回归,régularisation des crêtes,régularisation de crête,régularisation ridge,リッジの正則化,リッジ正則化 (Ridge regularization),リッジ正則化,регуляризация гребней,регуляризация гребня,гребневая регуляризация
3728,riemannian geometry,الهندسة الريمانية,الهندسة الريمانية,هندسة ريمانية,黎曼几何,黎曼几何学,黎曼几何,géométrie riemannienne,géométrie riemannienne,géométrie riemannienne,リーマン幾何学,リーマン幾何学,リーマン幾何学,риманова геометрия,Геометрия Римана,риманова геометрия
3729,riemannian gradient,التدرج الريماني,المدرج الريماني,متدرج ريماني,黎曼梯度,黎曼梯度,黎曼梯度,gradient riemannien,gradient riemannien,gradient riemannien,リーマン勾配,リーマン勾配,リーマン勾配,римановский градиент,Римановский градиент,риманово градиент
3730,riemannian manifold,مشعب ريماني,"- التصنيف المنطيدي
- سطح ريماني المتداول",متضائية رايمان,黎曼流形,黎曼流形,黎曼流形,variété riemannienne,variété riemannienne,variété riemannienne,リーマン多様体,リーマン多様体,リーマン多様体,риманово многообразие,риеманов многообразие,риманово многообразие
3731,right-to-left model,نموذج من اليمين إلى اليسار,النموذج من اليمين إلى اليسار,نموذج من اليمين إلى اليسار,从右到左模型,右至左模型 (right-to-left model),从右向左模型,modèle de droite à gauche,modèle de droite à gauche,modèle de droite à gauche,右から左へのモデル,右から左モデル,右から左のモデル,модель справа налево,R2L (право налево модель),модель справа налево
3732,rigid body transformation,تحول الجسم الصلب,تحويل الجسم الصلب,تحويل جسم جامد,刚体变换,刚体变换,刚体变换,transformation du corps rigide,transformation de corps rigide,transformation rigide,剛体変換,剛体変換 (ごうたいへんかん),剛体変換,трансформация твердого тела,жесткое телоперемещение,преобразование твердого тела
3733,rigid transformation,تحول جامد,التحويل الصلب,تحويل صلب,刚性变换,刚性变换,刚体变换,transformation rigide,transformation rigide,transformation rigide,剛体変換,剛体変換,剛体変換,жесткое преобразование,жесткое преобразование,жесткое преобразование
3734,risk minimization,التقليل من المخاطر,تقليل المخاطر,تقليل المخاطر,风险最小化,风险最小化,风险最小化,minimisation des risques,minimisation du risque,minimisation du risque,リスクの最小化,リスク最小化,リスク最小化,минимизация риска,минимизация риска,минимизация риска
3735,roberta-large,روبرتا كبيرة,روبرتا-كبير,روبرتا الكبيرة,罗伯塔大,roberta-large,roberta-large 的汉语翻译是 roberta大型模型,roberta-large,roberta-large,roberta-large,ロバータ・ラージ,roberta-large,roberta-largeモデル,Роберта-большая,roberta-large,Робер-большой
3736,robotic,الروبوتية,روبوتية,روبوتي,机器人,机器人 (jīqìrén),机器人的,robotique,robotique,robotique,ロボットの,ロボティック,ロボット工学,роботизированный,робототехника,робототехника
3737,robust optimization,التحسين القوي,التحسين القوي,الأمثلية المتينة,鲁棒优化,鲁棒优化,鲁棒优化,optimisation robuste,optimisation robuste,optimisation robuste,堅牢な最適化,堅牢最適化,頑健最適化,надежная оптимизация,устойчивая оптимизация,робастная оптимизация
3738,robust risk,خطر قوي,المخاطر الصلبة,المخاطرة القوية,稳健的风险,鲁棒风险,稳健风险,risque robuste,risque robuste,risque robuste,堅牢なリスク,強固リスク,ロバストリスク,надежный риск,устойчивый риск,устойчивый риск
3739,robustness,المتانة,الصلابة,متانة,鲁棒性,鲁棒性,鲁棒性,robustesse,robustesse,robustesse,堅牢性,頑健性 (Ganken-sei),頑健性,надежность,устойчивость,устойчивость
3740,role assertion,تأكيد الدور,تأكيد الدور,تأكيد الدور,角色主张,角色断言,角色断言,affirmation du rôle,assertion de rôle,assertion de rôle,役割の主張,役割主張,役割アサーション,утверждение роли,роль утверждения,утверждение роли
3741,role atom,ذرة الدور,ذرة دورية,ذرة العلاقة,角色原子,角色原子,角色原子,rôle de l'atome,rôle atomique,atome de rôle,役割原子,役割原子 (yakuwari genshi),役割原子,Ролевой атом,рольовый атом,атом роли
3742,role classification,تصنيف الدور,تصنيف الأدوار,تصنيف الأدوار,角色分类,角色分类,角色分类,classification des rôles,classification des rôles,Classification des rôles,役割分類,役割分類,役割分類,классификация ролей,классификация ролей,ролевая классификация
3743,role name,اسم الدور,اسم الدور,اسم الدور,角色名称,角色名称,角色名称,nom de rôle,nom de rôle,nom de rôle,ロール名,役割名,役割名,имя роли,"""['ABox - это набор утверждений о концептах A(a) и утверждениях ролей r(a, b), где A - это имя концепта, r - имя роли, а a, b - имена индивидуумов. Мы используем ind(A) для обозначения множества всех имен индивидуумов, которые встречаются в А.', 'Пусть C",имя роли
3744,roll-out policy,سياسة النشر,سياسة النشر,سياسة الانتشار,推出政策,推出政策,展开策略,politique de déploiement,politique de déploiement,politique de roll-out,ロールアウトポリシー,- ロールアウトポリシー,ロールアウトポリシー,политика развертывания,политика развертывания,политика ролаута
3745,rollout,طرح,- التنفيذ,فتح,推出,滚动,对历史轨迹,dérouler,déploiement,déploiement,ロールアウトする,ロールアウト,ロールアウト,посадочная дистанция,процесс обучения,развертывание
3746,rollout length,طول الطرح,طول النشر,طول الفرش,展开长度,滚动长度,推出长度,longueur de déploiement,- Longueur du déploiement,longueur de déroulement,ロールアウトの長さ,- ロールアウト長,ロールアウト長さ,длина выката,длина прокрутки,Длина развёртывания
3747,root mean square error,جذر متوسط ​​مربع الخطأ,خطأ المربع الجذري المتوسط,جذر متوسط مربع الخطأ,根均方误差,均方根误差 (RMSE),均方根误差,erreur quadratique moyenne,erreur quadratique moyenne de la racine (RMSE),erreur quadratique moyenne,二乗平均平方根誤差,平均二乗誤差,二乗平均平方根誤差,Средняя квадратическая ошибка,Среднеквадратичная ошибка,среднеквадратичная ошибка
3748,root node,عقدة الجذر,- تركيز الجذر,العقدة الجذر,根节点,根节点,根节点,Noeud principal,nœud racine,nœud racine,ルートノード,ルートノード,根ノード,корневой узел,корневой узел,корневой узел
3749,rotation angle,زاوية الدوران,زاوية الدوران,زاوية الدوران,旋转角度,旋转角度,旋转角度,angle de rotation,angle de rotation,angle de rotation,回転角度,回転角,回転角度,угол поворота,угл поворота,угол поворота
3750,rotation invariance,ثبات الدوران,عدم التغير مع الدوران,تماثل الدوران,旋转不变性,旋转不变性,旋转不变性,invariance de rotation,invariance à la rotation,invariance par rotation,回転不変性,回転不変性 (Kaiten fuhansei),回転不変性,инвариантность вращения,инвариантность к вращению,инвариантность к вращению
3751,rotation matrix,مصفوفة الدوران,مصفوفة دوران,مصفوفة الدوران,旋转矩阵,旋转矩阵,旋转矩阵,matrice de rotation,matrice de rotation,matrice de rotation,回転行列,回転行列 (kaiten gyōretsu),回転行列,матрица вращения,матрицы поворота,матрица вращения
3752,route Transformer,محول الطريق,محول التوجيه,مُحوّل المُسارات,路线变压器,路由变压器,路由Transformer,Transformateur d'itinéraire,route Transformer,Transformateur de routage,ルートトランス,ルーティングトランスフォーマー,ルーティングTransformer,маршрут Трансформатор,Трансформатор маршрутов,Маршрутизирующий Трансформер
3753,row vector,ناقلات التوالي,متجه الصف,ناقل صفي,行向量,行向量,行向量,vecteur de ligne,Vecteur ligne,vecteur ligne,行ベクトル,行ベクトル,行ベクトル,вектор-строка,строковый вектор,вектор-строка
3754,rule body,هيئة القاعدة,جسم القاعدة,جسم القاعدة,规则体,规则体,规则体,corps de règles,corps de règle,corps de règle,ルール本体,ルール本体,ルール本体,орган правила,тело правила,правило тела
3755,runtime complexity,تعقيد وقت التشغيل,التعقيد الزمني للتشغيل,تعقيد الوقت التشغيلي,运行时复杂度,运行时复杂度,运行时复杂度,complexité d'exécution,complexité d'exécution,complexité de temps d'exécution,実行時の複雑さ,ランタイム複雑さ,実行時の複雑さ,сложность времени выполнения,сложность времени выполнения,временная сложность
3756,s node,عقدة,عقدة S,عقدة S,s节点,S 节点,句子节点 (S node),nœud,nœud S,nœud S,のノード,Sノード,S ノード,узел,узел S,узел S
3757,saddle-point problem,مشكلة نقطة السرج,مشكلة نقطة التعادل,مشكلة النقطة السرجية,鞍点问题,鞍点问题,鞍点问题,problème de point de selle,problème du point de selle,problème du point de selle,鞍点問題,サドルポイント問題,鞍点問題,проблема седловой точки,Проблема седловой точки,проблема седловой точки
3758,saliency,بروز,بروزية,البروز,显着性,显著性,显著性,saillance,saillance,saillance,顕著性,注目度,顕著性,значимость,выразительность,Значимость
3759,saliency map,خريطة البروز,خريطة البارزية,خريطة الأهمية,显着图,显著性地图,显着性图像,carte de saillance,carte de saillance,carte de saillance,顕著性マップ,焦点マップ,重要度マップ,карта значимости,карта выдачи (saliency map),карта выделения
3760,sample complexity,تعقيد العينة,تعقيد العينة,تعقيد العينة,样本复杂度,样本复杂度,样本复杂度,complexité de l'échantillon,complexité de l'échantillon,complexité en échantillons,サンプルの複雑さ,サンプルの複雑さ,サンプル複雑度,сложность выборки,объем выборки,сложность выборки
3761,sample complexity bind,ربط تعقيد العينة,القيد الخاص بتعقيد العينات,حد تعقيد العينة,样本复杂度绑定,样本复杂性约束,样本复杂度界,liaison de complexité d'échantillon,contrainte de complexité d'échantillonnage,borne de complexité d'échantillonnage,サンプルの複雑さのバインド,サンプル複雑性バインド,サンプル複雑度の束縛,выборочная привязка сложности,предел сложности выборки,Связь между сложностью выборки
3762,sample covariance matrix,عينة مصفوفة التغاير,مصفوفة تباين العينة,مصفوفة التغاير العينية,样本协方差矩阵,样本协方差矩阵,样本协方差矩阵,exemple de matrice de covariance,- Matrice de covariance d'échantillon,matrice de covariance empirique,サンプル共分散行列,サンプル共分散行列 (sanpuru kyoubunsan gyouretsu),サンプル共分散行列,выборочная ковариационная матрица,матрица выборочной ковариации,матрица выборочной ковариации
3763,sample efficiency,كفاءة العينة,فاعلية العينة,كفاءة العينة,样品效率,样本效率,样本效率,efficacité de l'échantillon,efficacité de l'échantillonnage,efficacité d'échantillonnage,サンプル効率,サンプル効率,サンプル効率,эффективность выборки,эффективность выборки,эффективность выборки
3764,sample selection,اختيار عينة,اختيار العينة,اختيار العينة,样本选择,样本选择,样本选择,selection d'Echantillon,sélection d'échantillon,sélection d'échantillons,サンプルの選択,サンプル選択 (sanpuru sentaku),サンプル選択,Выбор образца,выборка образцов,выборка образцов
3765,sample space,فضاء العينة,مساحة العينة,مجال العينة,样本空间,样本空间,样本空间,espace d'échantillon,espace d'échantillonnage,espace d'échantillonnage,サンプル空間,サンプル空間,サンプル空間,пространство выборки,пространство выборки,пространство выборки
3766,sample variance,تباين العينة,تباين العينة,تباين العينة,样本方差,样本方差,样本方差,variance de l'échantillon,variance de l'échantillon,variance d'échantillon,サンプル分散,標本分散,サンプル分散,выборочная дисперсия,дисперсия выборки,выборочная дисперсия
3767,sample-efficient,كفاءة العينة,كفاءة العينة,كفاءة العينات,样品效率高,样本高效,样本高效,efficace pour les échantillons,efficace en termes d'échantillonnage,efficace en échantillons,サンプル効率が高い,サンプル効率的,サンプル効率的,эффективный по выборке,эффективный по образцу,эффективное по выборке
3768,sampler,أخذ العينات,عينات,مُعايِن,采样器,采样器 (sampler),采样器,échantillonneur,échantillonneur,échantillonneur,サンプラー,- サンプラー,サンプラー,пробоотборник,сэмплер,сэмплер
3769,sampling algorithm,خوارزمية أخذ العينات,خوارزمية العينة,خوارزمية أخذ العينات,采样算法,抽样算法,采样算法,algorithme d'échantillonnage,algorithme d'échantillonnage,algorithme d'échantillonnage,サンプリングアルゴリズム,サンプリングアルゴリズム (sampling algorithm),サンプリングアルゴリズム,алгоритм выборки,алгоритм выборки,алгоритм выборки
3770,sampling-base inference,الاستدلال على قاعدة العينات,استنتاج قائم على العينات,استدلال قائم على أخذ العينات,采样基推断,基于抽样的推断,基于采样的推理,inférence de base d'échantillonnage,inférence à base d'échantillonnage,inférence par échantillonnage,サンプリングベースの推論,サンプリングベース推論,サンプリングベース推論,вывод на основе выборки,выборочное выводирование,вывод на основе выборки
3771,satisfiability,الرضا,"""في كل حالة يتم إضافة قيد يحافظ على قابلية الرضا بشكل عام، ولكن يقيد محلل الحلول للعثور (في الأفضل) على شاهد واحد فقط من كل فئة معادلة من الحلول- الأمل هو أن هذا سي",تلبية الشروط,可满足性,可满足性,满足性,satisfiabilité,satisfiabilité,satisfiabilité,満足性,証明可能性,充足可能性,выполнимость,удовлетворимость,выполнимость
3772,satisfiability problem,مشكلة الرضا,مشكلة القابلية للرضا,مشكلة الإشباع,可满足性问题,满足性问题,可满足性问题,problème de satisfiabilité,problème de satisfiabilité,problème de satisfiabilité,充足可能性問題,充足可能性問題,充足可能性問題,проблема выполнимости,Проблема выполнимости,проблема выполнимости
3773,scalability,قابلية التوسع,قابلية التوسعية,قابلية التوسع,可扩展性,可伸缩性,可扩展性,évolutivité,- Scalabilité,extensibilité,スケーラビリティ,スケーラビリティ (sukeerabiriti),拡張性,масштабируемость,Масштабируемость,Масштабируемость
3774,scalar,العددية,مقياس,منفرد,标量,标量,标量,scalaire,scalaire,scalaire,スカラー,スカラー,スカラー,скаляр,скаляр,скаляр
3775,scalar product,المنتج العددي,منتج الزمنية,ناتج ضرب عددي,标量积,标量积,标量积,produit scalaire,produit scalaire,produit scalaire,スカラー積,スカラー積,スカラー積,скалярное произведение,скалярное произведение,скалярное произведение
3776,scalarization,تصعيد,توجيه السكالار,تدرج,标量化,标量化,标量化,scalarisation,scalarisation,linéarisation,スカラー化,スカラー化,スカラリゼーション,скаляризация,скаляризация,скаляризация
3777,scale dot-product attention,مقياس الاهتمام بالمنتج النقطي,"""يتمثل السبب في ذلك في أن كل رمز علامة استعلام يتم استنتاجه كمزيج مرجح من رموز العلامة الداعمة v، بناءً على التشابه بين رموز الصورة الاستعلام والدعم","المقصود بالمصطلح ""الانتباه بضرب النقطة المُقاس"" في هذا السياق.",尺度点积注意力,缩放点积注意力,缩放点积注意力,attention aux produits scalaires,attention à produit scalaire mis à l'échelle,attention par produit scalaire,ドット積の注意をスケールする,スケールドット積注意 (sukēru dottsu seki chūi),スケール内積注目,масштабировать внимание скалярного произведения,масштабное внимание скалярного произведения,масштабированное скалярное произведение внимания
3778,scale factor,عامل المقياس,عامل التحجيم,عامل التحجيم,比例因子,比例因子,缩放因子,facteur d'échelle,Facteur d'échelle,facteur d'échelle,スケールファクター,スケールファクター,スケーリング係数,масштаб,Масштабный коэффициент,масштабный коэффициент
3779,scale invariance,ثبات المقياس,التحليل المقياسي,ثبات المقياس,尺度不变性,尺度不变性,尺度不变性,invariance d'échelle,invariance d'échelle,invariance d'échelle,スケール不変性,尺度不変性 (sukudo fuhen-sei),尺度不変性,масштабная инвариантность,инвариантность масштаба,масштабно-инвариантный
3780,scale parameter,معلمة المقياس,معامل المقياس,معامل التدرج,尺度参数,比例参数,尺度参数,paramètre d'échelle,paramètre d'échelle,paramètre d'échelle,スケールパラメータ,スケールパラメータ,スケールパラメーター,параметр масштаба,Параметр масштаба,параметр масштаба
3781,scaled dot-product,تحجيم المنتج النقطي,منتج النقطة المُقيَّسة,ناتج الضرب النقطي المقياس,缩放点积,缩放的点积,缩放点积,produit scalaire mis à l'échelle,produit scalaire mis à l'échelle,produit scalaire,スケーリングされたドット積,スケーリングされた内積,スケールドット積,масштабированное скалярное произведение,масштабированное скалярное произведение,масштабированное скалярное произведение
3782,scan window detector,كاشف نافذة المسح,مكتشف نافذة المسح,كاشف نافذة المسح,扫描窗探测器,扫描窗口检测器,滑窗检测器,détecteur de fenêtre de numérisation,détecteur de fenêtre de balayage,détecteur à fenêtre de balayage,スキャンウィンドウ検出器,スキャン窓検出器 (scan window detector),スキャンウィンドウ検出器,детектор окна сканирования,детектор сканирующего окна,сканирующий оконный детектор
3783,scene category,فئة المشهد,فئة المشهد,فئة المشهد,场景类别,场景类别 (Chǎngjǐng lèibié),场景类别,catégorie de scène,catégorie de scène,catégorie de scène,シーンカテゴリー,シーンカテゴリ,シーンカテゴリー,категория сцены,категория сцены,категория сцены
3784,scene classification,تصنيف المشهد,تصنيف المشاهد,تصنيف المشهد,场景分类,场景分类,场景分类,classement des scènes,classification de scène,classification de scène,シーン分類,シーン分類 (Scene Classification),シーン分類,классификация сцен,классификация сцен,классификация сцен
3785,scene classifier,مصنف المشهد,مصنف المشاهد,مُصَنِّف المشهد,场景分类器,场景分类器,场景分类器,classificateur de scène,classificateur de scène,classificateur de scènes,シーン分類子,シーン分類器 (Scene classifier),シーンクラス分類器,классификатор сцен,классификатор сцен,классификатор сцен
3786,scene flow,تدفق المشهد,تدفق المشهد,تدفق المشهد,场景流,场景流,场景流,déroulement de la scène,flux de scène,flot de scène,シーンの流れ,シーンフロー (scene flow),シーンフロー,поток сцены,поток сцены,поток сцены
3787,scene flow estimation,تقدير تدفق المشهد,تقدير تدفق المشهد,تقدير تدفق المشهد,场景流量估计,场景流估计 (scene flow estimation),场景流估计,estimation du flux de la scène,estimation du flux de scène,estimation du flot de scène,シーンフローの推定,シーンフロー推定,シーンフロー推定,оценка потока сцены,оценка потока сцены,оценка потока сцены
3788,scene geometry,هندسة المشهد,هندسة المشهد,هندسة المشهد,场景几何,场景几何,场景几何,géométrie de la scène,géométrie de la scène,géométrie de la scène,シーンジオメトリ,シーンの幾何学 (Scene geometry),シーンジオメトリー,геометрия сцены,геометрия сцены,геометрия сцены
3789,scene graph,الرسم البياني للمشهد,رسم بياني للمشهد,رسم المشهد,场景图,场景图,场景图,graphique de scène,graphe de scène,graphe de scène,シーングラフ,シーングラフ (scene graph),シーングラフ,граф сцены,граф сцены,граф сцены
3790,scene parsing,تحليل المشهد,تحليل المشهد,تحليل المشهد,场景解析,场景解析,场景解析,analyse de scène,analyse de scène,analyse de scène,シーン解析,シーン解析 (Scene parsing),シーンパージング,разбор сцены,разбор сцены,семантическое разбиение сцены
3791,scene recognition,التعرف على المشهد,تعرف المشهد,التعرف على المشهد,场景识别,场景识别,场景识别,reconnaissance de scène,reconnaissance de scène,reconnaissance de scène,シーン認識,シーン認識 (Scene recognition),場面認識,распознавание сцены,распознавание сцен,распознавание сцены
3792,scene reconstruction,إعادة بناء المشهد,إعادة بناء المشهد,استعادة المشهد,场景重建,场景重建,场景重建,reconstitution de scène,reconstitution de scène,reconstruction de la scène,シーンの再構成,シーン再構築,シーン復元,реконструкция сцены,восстановление сцены,воссоздание сцены
3793,scene representation,تمثيل المشهد,تمثيل المشهد,تمثيل المشهد,场景表征,场景表示,场景表示,représentation de la scène,représentation de scène,représentation de scène,シーン表現,シーン表現,シーン表現,представление сцены,представление сцены,представление сцены
3794,scene understanding,فهم المشهد,فهم السياقات,فهم المشهد,场景理解,场景理解,场景理解,compréhension de la scène,compréhension de scène,compréhension de la scène,場面理解,シーン理解,シーン理解,понимание сцены,понимание сцены,понимание сцены
3795,schedule sampling,جدول أخذ العينات,التعيين الزمني,جدولة المعاينة,安排抽样,安排采样,定时采样,planifier l'échantillonnage,échantillonnage planifié,échantillonnage programmé,サンプリングをスケジュールする,スケジュールサンプリング,スケジュールサンプリング,выборка по расписанию,расписание выборки,выборка по расписанию
3796,scheduler,جدولة,جدولة,جدولة,调度程序,调度程序 (scheduler),调度器,planificateur,planificateur,ordonnanceur,スケジューラ,スケジューラ (scheduler),スケジューラ,планировщик,планировщик,планировщик
3797,schema item,عنصر المخطط,عنصر مخطط,البند المعرفي,模式项,模式项目,模式单元,élément de schéma,élément de schéma,élément de schéma,スキーマ項目,スキーマアイテム,スキーマアイテム,элемент схемы,схемный элемент,элемент схемы
3798,score function,وظيفة النتيجة,وظيفة النقاط,دالة النقاط,得分函数,评分函数,评分函数,fonction de score,fonction de score,fonction de score,スコア関数,スコア関数,スコア関数,функция оценки,функция оценки,функция оценки
3799,score matching,مطابقة النتيجة,مطابقة النقاط,مطابقة النقاط,分数匹配,得分匹配,评分匹配,correspondance des scores,appariement de score,appariement de scores,スコアマッチング,スコアマッチング,スコア マッチング,сопоставление очков,сопоставление оценки,балльное сопоставление
3800,score vector,ناقلات النتيجة,متجه النقاط,متجه النقاط,分数向量,得分向量,分数向量,vecteur de score,vecteur de score,vecteur de scores,スコアベクトル,スコアベクトル (score vector),スコアベクトル,вектор очков,вектор оценок,вектор оценок
3801,score-base model,نموذج قاعدة النتيجة,نموذج قائم على النقاط,نموذج قائم على الدرجات,基于分数的模型,基于分数的模型,基于分数的模型,modèle de base de score,modèle basé sur le score,modèle basé sur un score,スコアベースモデル,スコアベースモデル (score-base model),スコアベースモデル,оценочная модель,модель на основе оценок,модель на основе оценок
3802,scoring function,وظيفة التهديف,وظيفة التسجيل,دالة التقييم,评分函数,评分函数,评分函数,fonction de notation,fonction de notation,fonction de score,スコアリング機能,スコアリング関数 (Sukōringu kansū),スコアリング関数,функция оценки,функция оценки,функция оценивания
3803,search algorithm,خوارزمية البحث,خوارزمية البحث,خوارزمية البحث,搜索算法,搜索算法,搜索算法,algorithme de recherche,algorithme de recherche,algorithme de recherche,検索アルゴリズム,探索アルゴリズム (Tansaku Arugorizumu),探索アルゴリズム,алгоритм поиска,алгоритм поиска,поисковый алгоритм
3804,search problem,مشكلة البحث,مشكلة البحث,مشكلة البحث,搜索问题,搜索问题,搜索问题,problème de recherche,problème de recherche,problème de recherche,検索問題,探索問題 (さくさくもんだい),探索問題,проблема поиска,проблема поиска,проблема поиска
3805,search procedure,إجراء البحث,إجراء البحث,إجراء البحث,搜寻程序,搜索过程,搜索过程,procédure de recherche,procédure de recherche,procédure de recherche,検索手順,サーチ手順 (saachi tedo),探索手順,процедура поиска,процедура поиска,процедура поиска
3806,search space,مساحة البحث,المساحة البحثية,فضاء البحث,搜索空间,搜索空间,搜索空间,espace de recherche,espace de recherche,espace de recherche,サーチスペース,探索空間 (Tansaku Kukan),探索空間,пространство поиска,пространство поиска,пространство поиска
3807,search tree,شجرة البحث,شجرة البحث,شجرة البحث,搜索树,搜索树,搜索树,arbre de recherche,arbre de recherche,arbre de recherche,検索ツリー,探索木,探索木,дерево поиска,дерево поиска,поисковое дерево
3808,second order,الدرجة الثانية,النظام الثاني,ثاني الرتبة,二阶,二阶,二阶,deuxième ordre,- Deuxième ordre,ordre deux,二次注文,二次,二次の,второго порядка,второго порядка,второго порядка
3809,second order statistic,إحصائية الدرجة الثانية,الإحصائيات من الدرجة الثانية,إحصاء الرتبة الثانية,二阶统计量,二阶统计量,二阶统计量,statistique de second ordre,statistique du second ordre,statistique du second ordre,二次統計,二次統計量,2次統計量,статистика второго порядка,вторичная статистика,статистика второго порядка
3810,second-order optimization,التحسين من الدرجة الثانية,تحسين من الدرجة الثانية,تحسين من الدرجة الثانية,二阶优化,二阶优化 (Second-order optimization),二阶优化,optimisation du second ordre,optimisation d'ordre deux,optimisation de second ordre,二次最適化,二次最適化 (nijō saitekika),2次最適化,оптимизация второго порядка,Оптимизация второго порядка,вторичная оптимизация
3811,second-order potential,إمكانات الدرجة الثانية,الإمكانيات من الدرجة الثانية,مؤثرات الترتيب الثاني,二阶势,二阶势能,二阶势能,potentiel de second ordre,- Potentiel de deuxième ordre,potentiels d'ordre deux,二次ポテンシャル,二次ポテンシャル,二次ポテンシャル,потенциал второго порядка,вторичный потенциал,потенциалы второго порядка
3812,segmentation,التجزئة,التقسيم,تقسيم,分割,分词,分割,segmentation,segmentation,segmentation,セグメンテーション,セグメンテーション,セグメント化,сегментация,сегментация,сегментация
3813,segmentation algorithm,خوارزمية التجزئة,خوارزمية التقسيم,خوارزمية التجزئة,分割算法,分割算法,分割算法,algorithme de segmentation,algorithme de segmentation,algorithme de segmentation,セグメンテーションアルゴリズム,セグメンテーションアルゴリズム (Segumēshon arugorizumu),セグメンテーション アルゴリズム,алгоритм сегментации,алгоритм сегментации,алгоритм сегментации
3814,segmentation map,خريطة التقسيم,خريطة التقسيم,خريطة التقسيم,分割图,分割地图 (segmentation map),分割图,carte de segmentation,carte de segmentation,carte de segmentation,セグメンテーションマップ,セグメンテーションマップ (Segumēshon Mappu),セグメンテーション・マップ,карта сегментации,карта сегментации,Карта сегментации
3815,segmentation mask,قناع التقسيم,قناع التقسيم,قناع التجزئة,分割掩模,分割遮罩,分割掩码,masque de segmentation,masque de segmentation,masque de segmentation,セグメンテーションマスク,セグメンテーションマスク,セグメンテーションマスク,маска сегментации,маска сегментации,маска сегментации
3816,selection bias,تحيز الاختيار,الانحياز في الاختيارات,حيز الانتقاء,选择偏差,选择偏倚,选择偏差,biais de séléction,biais de sélection,Biais de sélection,選択バイアス,選択バイアス (sentaku baisu),選択バイアス,критерий отбора,смещение выборки,предвзятость отбора
3817,selectional preference,تفضيل اختياري,تفضيلات الاختيار,ميزات اختيار التفضيلات,选择偏好,选择偏好,选择偏好,préférence de sélection,préférence de sélection,préférence sélectionnelle,選択の好み,選好性,選択的選好性,избирательное предпочтение,предпочтение выбора,селективное предпочтение
3818,self-attention,الاهتمام الذاتي,تركيز الانتباه الذاتي,الانتباه الذاتي,自我关注,自注意力,自注意力,attention personnelle,auto-attention,auto-attention,自意識,"""['我々は、ソース、長さ、バージョン番号のバランスを取った150,000の短い記事バージョンをサンプリングします。タスク3：更新方法は？ バージョンvの各文について、次のいずれかを予測します。 (1) 文自体を使用したモデルのアーキテクチャ図。我々のタ",自己注目,внимание к себе,самовнимание,самовнимание
3819,self-attention head,رئيس الاهتمام الذاتي,رأس الانتباه الذاتي,رأس الانتباه الذاتي (self-attention head),自注意力头,自我关注头,自注意力头,tête d'auto-attention,tête d'auto-attention,tête d'auto-attention,自意識の頭,自己注意ヘッド,自己注目ヘッド,голова внимания к себе,само-внимательная голова,головка самовнимания
3820,self-attention layer,طبقة الاهتمام الذاتي,طبقة الانتباه الذاتي,طبقة الانتباه الذاتي,自注意力层,自注意力层,自注意力层,couche d'auto-attention,couche d'auto-attention,couche d'auto-attention,自意識層,自己注意層,自己注目層,слой самообслуживания,самовнимание слой,слой самовнимания
3821,self-attention matrix,مصفوفة الاهتمام الذاتي,مصفوفة الانتباه الذاتي,مصفوفة الانتباه الذاتي (self-attention matrix),自注意力矩阵,自注意力矩阵,自注意力矩阵,matrice d'auto-attention,- Matrix d'auto-attention,matrice d'auto-attention,自己注意マトリックス,自己注意行列 (じこちゅういぎょうれつ),自己注目行列,матрица внимания к себе,матрица самовнимания,матрица самовнимания
3822,self-attention mechanism,آلية الاهتمام الذاتي,آلية الانتباه الذاتي,آلية الانتباه الذاتي,自注意力机制,自注意机制,自注意力机制,mécanisme d'auto-attention,mécanisme d'auto-attention,mécanisme d'auto-attention,自己注意のメカニズム,自己注意メカニズム,自己注目メカニズム,механизм самообслуживания,механизм самовнимания,механизм самовнимания
3823,self-attention model,نموذج الاهتمام الذاتي,نموذج الانتباه الذاتي,نموذج الانتباه الذاتي,自注意力模型,自注意力模型,自注意力模型,modèle d'auto-attention,modèle d'auto-attention,modèle à auto-attention,自己注意モデル,自己注意モデル,自己注目モデル,модель внимания к себе,Модель самовнимания,Модель самовнимания
3824,self-attention module,وحدة الاهتمام الذاتي,وحدة الانتباه الذاتي,وحدة الانتباه الذاتي,自注意力模块,自注意力模块,自注意力模块,module d'auto-attention,module d'auto-attention,module d'auto-attention,自己注意モジュール,自己注意モジュール,自己注目モジュール,модуль самообслуживания,модуль самовнимания,модуль самовнимания
3825,self-learning,التعلم الذاتي,التعلم الذاتي,التعلم الذاتي,自学,自学习,自学习,auto-apprentissage,auto-apprentissage,auto-apprentissage,自己学習,自己学習,自己学習,самообучение,Самообучение,самообучение
3826,self-loop,حلقة ذاتية,حلقة ذاتية,حلقة ذاتية,自循环,自循环,自环,auto-boucle,boucle auto-entrelacée,boucle d'auto-rétroaction,自己ループ,自己ループ,自己ループ,самоцикл,самопетля,петля самосовмещения
3827,self-play,اللعب الذاتي,- تلعب ذاتيًا,اللعب الذاتي,自玩,自我博弈,自我对弈,jeu personnel,auto-jeu,auto-jeu,セルフプレイ,自己対戦,自己対戦,самостоятельная игра,"""['Начиная с политики и ценовой сети, случайно инициализированной с нуля, играется большое количество самоигр, и равновесные политики и улучшенные 1-ступенчатые оценки стоимости, вычисленные на каждом ходу из поиска равновесия, добавляются в буф",самоигра
3828,self-supervise learning,التعلم الخاضع للإشراف الذاتي,- تعلم الإشراف الذاتي,التعلم الذاتي الإشراف,自我监督学习,自我监督学习,自监督学习,apprentissage auto-supervisé,apprentissage auto-supervisé,apprentissage auto-supervisé,自己教師あり学習,"""['自己学習（SSL）は、有用な表現を学習するための強力な手法として登場しています。','画像表現の自己学習（SSL）は、過去数年間で著しい進歩を示しています。']""",自己監督学習,самостоятельное обучение,"Yuandong Tian <yuandong@fb.com>.', 'Самообучение (SSL) представлений изображения показало значительный прогресс за последние несколько лет ( Chen et al. , 2020a ; Chen et al.",самоконтролируемое обучение
3829,self-supervise method,طريقة الإشراف الذاتي,طريقة التدريب الذاتي,طريقة الإشراف الذاتي,自监督法,自监督方法,自监督方法,méthode auto-supervisée,méthode d'auto-supervision,méthode d'auto-supervision,自己監視型メソッド,自己教示法,自己教師付き方法,самоконтролируемый метод,метод самонаблюдения,метод самоконтроля
3830,self-supervise model,نموذج الإشراف الذاتي,نموذج تدريب ذاتي,نموذج مراقبة ذاتية,自监督模型,自监督模型 (self-supervise model),自监督模型,modèle auto-supervisé,modèle auto-supervisé,modèle auto-supervisé,自己教師ありモデル,自己監督モデル (じこかんとくモデル),自己教師付きモデル,модель с самоконтролем,самообучаемая модель,Модель самонаблюдения
3831,self-supervise representation learning,تعلم التمثيل الخاضع للإشراف الذاتي,تعلم التمثيل الذاتي للتمثيل,التعلم التمثيلي الذاتي الإشراف,自监督表征学习,自监督表示学习,自监督表征学习,apprentissage des représentations auto-supervisé,apprentissage de la représentation autosupervisé,apprentissage de représentation auto-supervisé,自己教師あり表現学習,自己監督表現学習 (じこかんとくひょうげんがくしゅう),自己監督表現学習,самостоятельное обучение представлению,Самоспонсированное обучение представлению,самообучаемое обучение представлений
3832,self-supervise signal,إشارة ذاتية الإشراف,إشارة تدريبية ذاتية الرقابة,إشارة الإشراف الذاتي,自监督信号,自监督信号,自监督信号,signal auto-supervisé,signal auto-supervisé,signal auto-supervisé,自己監視信号,自己監督信号 (jiko kanshi shingo),自己監視信号,самоконтролируемый сигнал,самообучающий сигнал,сигнал самоконтроля
3833,self-supervise training,التدريب الخاضع للإشراف الذاتي,التدريب الذاتي المراقب,تدريب الإشراف الذاتي,自我监督训练,自监督训练,自监督训练,formation auto-supervisée,entraînement auto-supervisé,apprentissage auto-supervisé,自己指導型トレーニング,自己教師付きトレーニング (jiko kyoshifu ki torēningu),自己教師あり学習,обучение под самоконтролем,самообучаемое обучение,самонаблюдаемое обучение
3834,self-supervision,الإشراف الذاتي,الإشراف الذاتي,الإشراف الذاتي,自我监督,自我监督,自监督,auto-surveillance,auto-supervision,auto-supervision,自己監視,自己監督,自己教師付き学習,самоконтроль,"""Наш вклад заключается в том, что мы вводим программирование задач как эффективный способ для специалистов в области сокращения затрат на аннотацию и кодирование структурных знаний. Мы разработали новый метод обучения эффективного представления траектории с использованием самоконтроля и программного надзора.""",самонаблюдение
3835,self-training,تدريب ذاتي,التدريب الذاتي,التدريب الذاتي,自我训练,自训练,自训练,Auto entrainement,auto-formation,auto-formation,自主トレーニング,自己学習,自己学習,самообучение,Самообучение,самообучение
3836,semantic alignment,المحاذاة الدلالية,المحاذاة الدلالية,التوافق الدلالي,语义对齐,语义对齐,语义对齐,alignement sémantique,alignement sémantique,alignement sémantique,セマンティックアラインメント,意味的アラインメント,意味的整列,семантическое выравнивание,семантическая выравнивание,семантическое совмещение
3837,semantic analysis,التحليل الدلالي,تحليل معنوي,التحليل الدلالي,语义分析,语义分析,语义分析,analyse sémantique,- Analyse sémantique,analyse sémantique,意味解析,意味解析,意味解析,семантический анализ,семантический анализ,семантический анализ
3838,semantic annotation,الشرح الدلالي,تعليق دلالي,التعليق الدلالي,语义标注,语义标注,语义注释,annotation sémantique,annotation sémantique,annotation sémantique,意味論的な注釈,意味注釈,意味的アノテーション,смысловая аннотация,семантическая аннотация,семантическая аннотация
3839,semantic category,الفئة الدلالية,- تصنيف دلالي,فئة دلالية,语义范畴,语义类别,语义类别,catégorie sémantique,- Catégorie sémantique,catégorie sémantique,セマンティックカテゴリ,セマンティックカテゴリ,意味カテゴリー,семантическая категория,семантическая категория,семантическая категория
3840,semantic class,الطبقة الدلالية,الصنف الدلالي,فئة دلالية,语义类,语义类,语义类别,classe sémantique,classe sémantique,classe sémantique,セマンティッククラス,セマンティッククラス,セマンティック分類,семантический класс,семантический класс,семантический класс
3841,semantic constraint,القيد الدلالي,القيد الدلالي,ضوابط دلالية,语义约束,语义约束,语义约束,contrainte sémantique,Contrainte sémantique,contrainte sémantique,意味的制約,意味制約,意味的制約,семантическое ограничение,семантическое ограничение,семантическое ограничение
3842,semantic distance,المسافة الدلالية,المسافة الدلالية,المسافة الدلالية,语义距离,语义距离,语义距离,distance sémantique,distance sémantique,distance sémantique,意味的距離,意味距離,意味的距離,смысловая дистанция,семантическое расстояние,семантическое расстояние
3843,semantic encoder,التشفير الدلالي,مُشفر المَعنى,ترميز الدلالة,语义编码器,语义编码器 (semantic encoder),语义编码器,encodeur sémantique,encodeur sémantique,encodeur sémantique,セマンティックエンコーダ,セマンティックエンコーダー,意味エンコーダ,семантический кодер,семантический кодировщик,семантический кодировщик
3844,semantic equivalence,التكافؤ الدلالي,المكافئ الدلالي,التكافؤ الدلالي,语义对等,语义等效,语义等价性,équivalence sémantique,équivalence sémantique,équivalence sémantique,意味上の同等性,意味的同等性,意味的同値性,семантическая эквивалентность,"Киддон и Домингос (2015) определяют теорию семантического эквивалента в терминах симметрий набора предложений естественного языка, а Гордон и др. (2020) предлагают мод",семантическая эквивалентность
3845,semantic feature,الميزة الدلالية,ميزة دلالية,ميزة دلالية,语义特征,语义特征,语义特征,caractéristique sémantique,caractéristique sémantique,caractéristique sémantique,セマンティック機能,意味的特徴,意味的特徴,смысловая особенность,семантическая особенность,семантический признак
3846,semantic graph,الرسم البياني الدلالي,رسم بياني دلالي,الرسم البياني الدلالي,语义图,语义图,语义图,graphe sémantique,graphe sémantique,graphe sémantique,セマンティックグラフ,セマンティックグラフ,意味グラフ,семантический граф,семантический граф,семантический граф
3847,semantic information,المعلومات الدلالية,معلومات دلالية,المعلومات الدلالية,语义信息,语义信息,语义信息,informations sémantiques,- Information sémantique,informations sémantiques,意味情報,意味情報,意味情報,смысловая информация,семантическая информация,семантическая информация
3848,semantic interpretation,التفسير الدلالي,التفسير الدلالي,تفسير دلالي,语义解释,语义解释,语义解释,interprétation sémantique,interprétation sémantique,interprétation sémantique,意味解釈,"""しかし、この論文でオンライン意味解析と言及するとき、実際にはオンライン意味解釈 - プログラムへの解析とそのプログラムの実行を指します。アルゴリズムは早い段階で実行を開始します。PLOWエージェントアーキテクチャの高レベルビューは",意味解釈,смысловая интерпретация,семантическая интерпретация,семантическая интерпретация
3849,semantic label,التسمية الدلالية,تسمية دلالية,وصف دلالي,语义标签,语义标签,语义标签,étiquette sémantique,étiquette sémantique,Étiquette sémantique,セマンティックラベル,意味ラベル,セマンティックラベル,семантическая метка,семантическая метка,семантическая метка
3850,semantic memory,الذاكرة الدلالية,ذاكرة دلالية,الذاكرة الدلالية,语义记忆,"""['灵感来自Collins和Loftus（1975年）对人类语义记忆的经典作品，我们使用词汇联想数据构建一个连接相关词汇的网络，并使用从这个网络上定义的随机行走导出的更密集的分布来建模语义相似性，类似于Katz指数（Katz，1953年）。'，'当它收到一个响",语义记忆,mémoire sémantique,mémoire sémantique,mémoire sémantique,意味記憶,セマンティックメモリ (semantic memory),意味記憶,семантическая память,семантическая память,семантическая память
3851,semantic model,النموذج الدلالي,نموذج دلالي,نموذج دلالي,语义模型,语义模型,语义模型,modèle sémantique,- Modèle sémantique,modèle sémantique,セマンティックモデル,意味モデル,意味モデル,семантическая модель,семантическая модель,семантическая модель
3852,semantic network,الشبكة الدلالية,شبكة دلالية,شبكة دلالية,语义网络,语义网络,语义网络,réseau sémantique,- Réseau sémantique,réseau sémantique,セマンティックネットワーク,意味ネットワーク (いみネットワーク),意味ネットワーク,семантическая сеть,семантическая сеть,семантическая сеть
3853,semantic object,كائن الدلالي,كائنات دلالية,كائن دلالي,语义对象,语义对象,语义对象,objet sémantique,objet sémantique,objet sémantique,セマンティックオブジェクト,セマンティックオブジェクト,意味的オブジェクト,смысловой объект,семантический объект,семантический объект
3854,semantic operator,المشغل الدلالي,المشغل الدلالي,مُعامِل دلالي,语义运算符,语义运算符,语义运算符,opérateur sémantique,opérateur sémantique,opérateur sémantique,意味演算子,意味演算子,意味論的演算子,семантический оператор,семантический оператор,семантический оператор
3855,semantic parse,التحليل الدلالي,التحليل الدلالي,تحليل دلالي,语义解析,语义解析,语义分析,analyse sémantique,analyse sémantique,analyse sémantique,セマンティック解析,セマンティックパース,意味解析,семантический анализ,"""['Затем мы описываем модель макета p(z|x; θ ). Сначала мы используем фиксированный синтаксический анализ для создания небольшого набора кандидатских макетов, аналогично тому, как семантическая грамматика генерирует кандидатские семантич",семантический парсинг
3856,semantic parser,المحلل الدلالي,محلل دلالي,مُحلِّل دلالي,语义解析器,语义解析器,语义解析器,analyseur sémantique,analyseur sémantique,analyseur sémantique,セマンティックパーサー,意味解析器,意味解析器,семантический парсер,семантический парсер,семантический парсер
3857,semantic priming,فتيلة الدلالية,التحفيز الدلالي,التهيئة الدلالية,语义启动,语义启动,语义启动,amorçage sémantique,amorçage sémantique,amorçage sémantique,セマンティックプライミング,意味プライミング,意味的プライミング,семантическая подготовка,семантическое влияние,семантическая преднастройка
3858,semantic relation,العلاقة الدلالية,العلاقة الدلالية,العلاقة الدلالية,语义关系,语义关系,语义关系,relation sémantique,- Relation sémantique,relation sémantique,意味関係,意味関係 (いみかんけい),意味関係,смысловое отношение,семантические отношения,семантическое отношение
3859,semantic representation,التمثيل الدلالي,التمثيل الدلالي,تمثيل دلالي,语义表示,"""['通过静态图注意机制对帖子中检索到的图进行编码，以增强帖子的语义表示，从而有助于理解帖子。动态图注意机制会仔细阅读知识图和每个图中的三元组，然后利用图和三元组中的语义信息进行更好的响应生成。'，'另一方面，我们认为语言知识是",语义表示,représentation sémantique,représentation sémantique,représentation sémantique,意味表現,意味的表現,意味表現,семантическое представление,семантическое представление,семантическое представление
3860,semantic role,الدور الدلالي,الدور الدلالي,الدور الدلالي,语义角色,语义角色,语义角色,rôle sémantique,rôle sémantique,rôle sémantique,意味論的な役割,意味役割,意味役割,смысловая роль,семантическая роль,семантическая роль
3861,semantic role label,تسمية الدور الدلالي,تسمية دور دلالي,دور دلالي,语义角色标签,语义角色标签,语义角色标注,étiquette de rôle sémantique,étiquette de rôle sémantique,rôle sémantique,セマンティックロールラベル,意味役割ラベル,意味役割ラベル,семантическая ролевая метка,семантическая роль (метка),семантическая ролевая метка
3862,semantic search,البحث الدلالي,البحث الدلالي,بحث دلالي,语义搜索,语义搜索,语义搜索,recherche sémantique,recherche sémantique,recherche sémantique,セマンティック検索,意味検索 (imii kensaku),セマンティック検索,семантический поиск,семантический поиск,поиск по семантике
3863,semantic segmentation,تجزئة الدلالية,التقسيم الدلالي,التجزئة الدلالية,语义分割,语义分割,语义分割,segmentation sémantique,segmentation sémantique,segmentation sémantique,セマンティックセグメンテーション,セマンティックセグメンテーション,意味的セグメンテーション,семантическая сегментация,семантическая сегментация,семантическая сегментация
3864,semantic similarity,التشابه الدلالي,التشابه الدلالي,تشابه دلالي,语义相似度,语义相似度,语义相似性,similarité sémantique,similarité sémantique,similarité sémantique,意味上の類似性,意味の類似性,意味的類似性,смысловое сходство,семантическая схожесть,семантическое сходство
3865,semantic similarity measure,قياس التشابه الدلالي,قياس التشابه الدلالي,مقياس التشابه الدلالي,语义相似度度量,语义相似度度量,语义相似度度量,mesure de similarité sémantique,- Mesure de similarité sémantique,mesure de similarité sémantique,意味的類似性の尺度,意味類似度尺度,意味的類似度尺度,мера семантического сходства,мера семантической схожести,мера семантического сходства
3866,semantic space,الفضاء الدلالي,المسافة الدلالية,فضاء دلالي,语义空间,语义空间,语义空间,espace sémantique,espace sémantique,espace sémantique,意味空間,意味空間 (Imi Kūkan),セマンティックスペース,смысловое пространство,семантическое пространство,семантическое пространство
3867,semantic structure,البنية الدلالية,البنية الدلالية,البنية الدلالية,语义结构,语义结构,语义结构,structure sémantique,structure sémantique,structure sémantique,意味構造,意味構造,意味構造,смысловая структура,семантическая структура,семантическая структура
3868,semantic symbol,الرمز الدلالي,رمز دلالي,رمز دلالي,语义符号,语义符号,语义符号,symbole sémantique,symbole sémantique,symbole sémantique,意味記号,意味記号,意味記号,смысловой символ,семантический символ,семантический символ
3869,semantic textual similarity,التشابه النصي الدلالي,المماثلة النصية الدلالية,التشابه النصي الدلالي,语义文本相似度,语义文本相似度,语义文本相似性,similarité textuelle sémantique,Similarité textuelle sémantique,similarité textuelle sémantique,意味的なテキストの類似性,意味テキスト類似度,意味的文書類似性,смысловое текстовое сходство,семантическая текстовая схожесть,семантическое текстовое сходство
3870,semantic unit,الوحدة الدلالية,وحدة دلالية,وحدة دلالية,语义单位,语义单元 (semantic unit),语义单元,unité sémantique,- Unité sémantique,unité sémantique,意味単位,意味単位,意味単位,смысловая единица,семантическая единица,семантическая единица
3871,semantic vector,ناقلات الدلالية,متجه دلالي,متجه دلالي,语义向量,语义向量,语义向量,vecteur sémantique,vecteur sémantique,vecteur sémantique,意味ベクトル,セマンティックベクトル,セマンティックベクトル,семантический вектор,семантический вектор,семантический вектор
3872,semantic vector space,مساحة المتجهات الدلالية,المساحة الناقلة الدلالية,فضاء المتجهات الدلالي,语义向量空间,语义向量空间 (semantic vector space),语义向量空间,espace vectoriel sémantique,- Espace vectoriel sémantique,espace vectoriel sémantique,意味ベクトル空間,意味ベクトル空間,意味ベクトル空間,семантическое векторное пространство,- Семантическое векторное пространство,семантическое векторное пространство
3873,semi-Markov,شبه ماركوف,شبه ماركوف,سيمي ماركوف,半马尔可夫,半马尔科夫,半马尔可夫,semi-markovien,semi-Markov,semi-Markov,セミマルコフ,セミマルコフ,半マルコフ,полумарковский,полумарковский,полумарковский
3874,semi-definite programming,برمجة شبه محددة,البرمجة شبه العينية,برمجة شبه محددة,半定规划,半定规划,半正定规划,programmation semi-définie,programmation semi-définie,programmation semi-définie,半確定プログラミング,半定数プログラミング (han-teisuu puroguramingu),半正定値計画,полуопределенное программирование,Полуопределенное программирование,полуопределенное программирование
3875,semi-supervised clustering,التجمعات شبه الخاضعة للإشراف,تجميع شبه مشرفة,التجميع شبه المُراقب,半监督聚类,半监督聚类,半监督聚类,clustering semi-supervisé,regroupement semi-supervisé,regroupement semi-supervisé,半教師ありクラスタリング,半教師付きクラスタリング,半教師あり クラスタリング,полуконтролируемая кластеризация,Полу-надзорная кластеризация,полунадзорная кластеризация
3876,semi-supervised learning,التعلم شبه الخاضع للإشراف,التعلم شبه المراقب,التعلم شبه المُراقَب,半监督学习,半监督学习,半监督学习,apprentissage semi-supervisé,Apprentissage semi-supervisé,apprentissage semi-supervisé,半教師あり学習,半教師あり学習,半教師あり学習,полуконтролируемое обучение,Полу-надзорное обучение,полунаблюдаемое обучение
3877,semi-supervision,شبه إشراف,شبه المراقبة,الإشراف الشبه كلي,半监督,半监督,半监督,semi-supervision,semi-supervision,semi-supervision supervisée partielle,半監督,半教師あり学習,半教師あり学習,полунадзор,полу-наблюдение,полунадзор
3878,semidefinite program,برنامج شبه محدد,برنامج شبه محدد,برنامج شبه معرف,半定规划,半定规划,半正定规划,programme semi-défini,programme semi-défini,programme semi-défini positif,半期限付きプログラム,半定値計画,準正定値計画,полуопределенная программа,Полуопределенная программа,полудефинитная программа
3879,sense disambiguation,توضيح المعنى,توضيح المعنى,تمييز المعنى,意义消歧,"""在表2中，我们比较了我们的算法和基准的义消岐精度。在这里，我们度量了在每个算法找到正确下义词的所有示例中的义消岐精度；我们的义消岐精度计算为c1 / (c1 + c2)。[27] 使用WordNet进行义消岐和查询扩展，取得了合理的性能提升。然而",词义消歧,sens de l'homonymie,désambiguïsation de sens,désambiguïsation sémantique,曖昧さ回避,意味の曖昧さ解消 (Imi no aimai-sa kaisho),単語曖昧性解消,смысловое значение,разрешение смысла,снятие неоднозначности
3880,sensitive attribute,سمة حساسة,السمة الحساسة,سِمَة حَسّاسَة,敏感属性,敏感属性 (sensitive attribute),敏感属性,attribut sensible,attribut sensible,attribut sensible,敏感な属性,敏感属性,機微な属性,чувствительный атрибут,чувствительный атрибут,конфиденциальный атрибут
3881,sensitivity analysis,تحليل الحساسية,تحليل الحساسية,تحليل الحساسية,敏感性分析,敏感性分析,敏感性分析,analyse de sensibilité,Analyse de sensibilité,analyse de sensibilité,感度分析,感度解析,感度分析,Анализ чувствительности,анализ чувствительности,анализ чувствительности
3882,sentence classification,تصنيف الجملة,تصنيف الجمل,تصنيف الجملة,句子分类,句子分类,句子分类,classification des phrases,Classification de phrase,classification de phrases,文の分類,文の分類,文分類,классификация предложений,классификация предложений,классификация предложений
3883,sentence compression,ضغط الجملة,ضغط الجملة,تضغيط الجملة,句子压缩,句子压缩,句子压缩,compression de phrases,compression de phrase,compression de phrases,文章圧縮,文章の圧縮,文の圧縮,сжатие предложений,сжатие предложения,сжатие предложений
3884,sentence embedding,تضمين الجملة,تضمين الجملة,تضمين الجملة,句子嵌入,句子嵌入,句向量,intégration de phrases,embedding de phrase,plongement de phrase,文の埋め込み,文の埋め込み,文埋め込み,встраивание предложений,вложение предложения,вложение предложения
3885,sentence encoder,التشفير الجملة,مُشفر الجملة,مشفر الجمل,句子编码器,句子编码器,句子编码器,encodeur de phrase,encodeur de phrases,encodeur de phrase,センテンスエンコーダ,文章エンコーダ,文エンコーダー,кодировщик предложений,энкодер предложений,энкодер предложений
3886,sentence representation,تمثيل الجملة,تمثيل الجملة,تمثيل الجملة,句子表示,句子表示,句子表征,représentation de la phrase,représentation de phrase,représentation de phrases,文章表現,文章表現,文の表現,представление предложения,представление предложения,представление предложения
3887,sentence segmentation,تجزئة الجملة,تقسيم الجمل,تقطيع الجُمل,句子切分,句子分割,句子分割,segmentation des phrases,segmentation de phrase,segmentation des phrases,文の分割,文章セグメンテーション (bunsho segumenteeshon),文区切り,сегментация предложений,сегментация предложений,сегментация предложений
3888,sentence vector,ناقلات الجملة,- تجهيز الجُملة,متجه الجملة,句子向量,句向量,句向量,vecteur de phrase,vecteur de phrase,vecteur phrastique,文ベクトル,文章ベクトル (bunsho bekutoru),文ベクトル,вектор предложения,вектор предложения,векторы предложений
3889,sentence-level,مستوى الجملة,مستوى الجملة,على مستوى الجملة,句子级,句级,句级,au niveau de la phrase,niveau de phrase,au niveau de la phrase,文レベル,文レベル,文レベル,уровень предложения,уровень предложения,на уровне предложений
3890,sentence-level classification,التصنيف على مستوى الجملة,التصنيف على مستوى الجملة,تصنيف على مستوى الجملة,句子级分类,句子级分类,句级分类,classification au niveau de la phrase,Classification au niveau de la phrase,classification au niveau de la phrase,文レベルの分類,文章レベルの分類,文レベルの分類,классификация на уровне предложений,классификация на уровне предложения,классификация на уровне предложения
3891,sentence-level representation,التمثيل على مستوى الجملة,تمثيل على مستوى الجملة,تمثيل مستوى الجملة,句子级表示,句子级表示,句级表示,représentation au niveau de la phrase,représentation au niveau de la phrase,représentation au niveau de la phrase,文レベルの表現,文章レベル表現,文レベル表現,представление на уровне предложения,представление на уровне предложения,векторное представление предложения
3892,sentence-piece,قطعة الجملة,"""لتوسيع المفردات XLM-R ، نستخدم قطعة الجمل (كودو وريتشاردسون ، 2018) مع نموذج لغة unigram (كودو ، 2018) لتدريب فاصل كلمات بحجم مفردات 250 ألف على Glot500-c. نقوم بأ",قطعة جملة,句子片段,句子片段,句子分词,morceau de phrase,morceau de phrase,pièce de phrase,文の一部,「['私たちは以下の質問に答えるためにさらに実験を行います：1）ベースラインがより良い語彙を持つ強力なアプローチを打ち負かすことができるか；2）VOLTは、Sentence-Pieceのような最近の語彙ソリューションを打ち負かすことができるか；3,文区分,часть предложения,Sentence-Piece,кусок-предложения
3893,sentiment analysis,تحليل المشاعر,تحليل المشاعر,تحليل المشاعر,情绪分析,情感分析,情感分析,analyse des sentiments,analyse des sentiments,analyse de sentiment,感情分析,感情分析,感情分析,анализ настроений,анализ тональности,анализ настроений
3894,sentiment analysis model,نموذج تحليل المشاعر,نموذج تحليل المشاعر,نموذج تحليل المشاعر,情感分析模型,情感分析模型,情感分析模型,modèle d'analyse des sentiments,modèle d'analyse de sentiment,modèle d'analyse de sentiments,感情分析モデル,感情分析モデル,感情分析モデル,модель анализа настроений,модель анализа тональности,модель анализа тональности
3895,sentiment classification,تصنيف المشاعر,تصنيف المشاعر,تصنيف المشاعر,情感分类,情感分类,情感分类,classification des sentiments,Classification des sentiments,classification des sentiments,感情の分類,感情分類,感情分類,классификация настроений,классификация настроения,классификация настроений
3896,sentiment classifier,مصنف المشاعر,مصنف المشاعر,مُصنِّف المشاعر,情感分类器,情感分类器,情绪分类器,classificateur de sentiments,Classificateur de sentiment,classificateur de sentiments,感情分類子,感情分類器 (Kanjou Bunrui-ki),感情分類器,классификатор настроений,классификатор тональности,классификатор настроений
3897,sentiment detection,كشف المشاعر,الكشف عن المشاعر,كشف المشاعر,情绪检测,情感检测,情感检测,détection des sentiments,détection de sentiment,détection de sentiments,感情検出,感情検出,感情検出,обнаружение настроений,обнаружение настроения,обнаружение настроения
3898,sentiment transfer,نقل المشاعر,نقل المشاعر,نقل المشاعر,情感传递,情感转移,情感转移,transfert de sentiments,transfert de sentiment,transfert de sentiment,感情移入,感情転送 (Kanjou Tensou),感情転移,передача настроений,передача настроения,передача настроения
3899,separation oracle,أوراكل الانفصال,محكم الفصل,مفوض الفصل,分离预言机,分割神谕,分离预言机,oracle de séparation,oracle de séparation,oracle de séparation,分離の神託,分離オラクル,分離オラクル,оракул разделения,оракул разделения,разделяющий оракул
3900,separation parameter,معلمة الفصل,معامل الفصل,مُعامل الفصل,分离参数,分割参数,分离参数,paramètre de séparation,paramètre de séparation,paramètre de séparation,分離パラメータ,分離パラメータ,分離パラメータ,параметр разделения,параметр разделения,разделительный параметр
3901,separator token,رمز الفاصل,رمز فاصل,رمز الفصل,分隔符标记,分隔符令牌,分隔符标记,jeton séparateur,jeton séparateur,jeton séparateur,区切り文字トークン,セパレータトークン,区切り記号,токен-разделитель,токен-разделитель,токен-разделитель
3902,seq2seq model,نموذج seq2seq,نموذج seq2seq,نموذج التتابع إلى التتابع,序列到序列模型,seq2seq模型,seq2seq模型,modèle seq2seq,modèle seq2seq,modèle seq2seq,seq2seq モデル,seq2seq モデル,seq2seqモデル,модель seq2seq,модель seq2seq,модель последовательность-к-последовательности
3903,sequence,تسلسل,تسلسل,تسلسل,顺序,序列,序列,séquence,séquence,séquence,順序,シーケンス,系列,последовательность,последовательность,последовательность
3904,sequence alignment,محاذاة التسلسل,توافق التسلسلات,محاذاة التسلسل,序列比对,序列比对,序列对准,alignement de séquence,Alignement de séquences,alignement de séquences,配列アラインメント,シーケンスアライメント (sequence alignment),シーケンスアライメント,выравнивание последовательностей,Выравнивание последовательностей,выравнивание последовательностей
3905,sequence classification,تصنيف التسلسل,تصنيف التسلسل,تصنيف التسلسل,序列分类,序列分类,序列分类,classification des séquences,classification de séquence,classification de séquence,配列の分類,シーケンス分類,シーケンス分類,классификация последовательностей,классификация последовательности,Классификация последовательностей
3906,sequence database,قاعدة بيانات التسلسل,قاعدة بيانات التسلسل,قاعدة بيانات التسلسل,序列数据库,序列数据库,序列数据库,base de données de séquences,- Base de données de séquences,base de données de séquences,配列データベース,シーケンスデータベース,シーケンスデータベース,база данных последовательностей,база данных последовательностей,последовательная база данных
3907,sequence generation,توليد التسلسل,إنشاء تسلسل,توليد التسلسل,序列生成,序列生成,序列生成,génération de séquence,génération de séquence,génération de séquences,シーケンスの生成,シーケンス生成,シーケンス生成,генерация последовательности,генерация последовательности,генерация последовательности
3908,sequence labeling,وضع العلامات التسلسلية,تسمية التسلسل,وَسْم التسلسُل,序列标记,序列标记,序列标注,étiquetage de séquence,étiquetage de séquence,étiquetage de séquence,配列のラベリング,シーケンスラベリング,シーケンスラベリング,маркировка последовательностей,маркировка последовательности,разметка последовательностей
3909,sequence labeling model,نموذج وضع العلامات التسلسلية,نموذج تسمية التسلسلات,نموذج ترميز التسلسل,序列标记模型,序列标注模型,序列标注模型,modèle d'étiquetage de séquence,modèle d'étiquetage de séquence,modèle d'étiquetage de séquence,配列ラベリングモデル,シーケンスラベリングモデル,シーケンスラベリングモデル,модель маркировки последовательностей,модель маркировки последовательности,модель разметки последовательностей
3910,sequence length,طول التسلسل,طول التسلسل,طول التسلسل,序列长度,序列长度,序列长度,longueur de la séquence,longueur de séquence,longueur de séquence,シーケンスの長さ,シーケンス長,系列長さ,длина последовательности,длина последовательности,длина последовательности
3911,sequence model,نموذج التسلسل,نموذج تسلسلي,نموذج المتسلسلة,序列模型,序列模型,序列模型,modèle de séquence,- Modèle de séquence,modèle de séquence,シーケンスモデル,シーケンスモデル (sequence model),系列モデル,модель последовательности,модель последовательности,модель последовательности
3912,sequence prediction,التنبؤ بالتسلسل,التنبؤ بالتسلسل,التنبؤ بالتسلسل,序列预测,序列预测,序列预测,prédiction de séquence,prédiction de séquence,prédiction de séquence,配列予測,シーケンス予測 (shīkensu yosoku),系列予測,предсказание последовательности,предсказание последовательности,Предсказание последовательности
3913,sequence tagging,علامات التسلسل,تسمية التسلسل,تصنيف المتتاليات,序列标记,序列标注,序列标注,marquage de séquence,étiquetage de séquences,annotation de séquence,シーケンスのタグ付け,シーケンスタグ付け,系列タグ付け,маркировка последовательности,маркировка последовательности,разметка последовательности
3914,sequence transduction,نقل التسلسل,تحويل التسلسلات,تحويل التسلسل,序列转导,序列转导,序列转换,transduction de séquence,transduction de séquence,transduction de séquence,配列伝達,シーケンス変換 (sequence transduction),シーケンス変換,трансдукция последовательности,последовательное преобразование,последовательное преобразование
3915,sequence-to-sequence,تسلسل إلى تسلسل,التسلسل إلى التسلسل,متتالية-إلى-متتالية,序列到序列,序列到序列,序列到序列,séquence à séquence,séquence à séquence,séquence-à-séquence,シーケンスからシーケンスへ,シーケンス対シーケンス,シーケンスツーシーケンス,последовательность к последовательности,последовательность-к-последовательности,последовательность-к-последовательности
3916,sequence-to-sequence architecture,بنية التسلسل إلى التسلسل,البنية التسلسلية إلى البنية التسلسلية,هندسة المتتابعات إلى المتتابعات,序列到序列架构,序列到序列架构,序列到序列架构,architecture séquence à séquence,architecture séquence à séquence,architecture de séquence à séquence,シーケンスツーシーケンスアーキテクチャ,シーケンス・トゥ・シーケンスのアーキテクチャ,シーケンス・ツー・シーケンス・アーキテクチャ,последовательная архитектура,архитектура последовательности к последовательности,архитектура последовательность-к-последовательности
3917,sequence-to-sequence generation,توليد تسلسل إلى تسلسل,التسلسل الى تسلسل التوليد,ولادة متتابعة للمتتاليات,序列到序列生成,序列到序列生成,序列到序列生成,génération séquence à séquence,génération de séquence à séquence,séquence-à-séquence,シーケンス間の生成,シーケンス対シーケンス生成,シーケンスツーシーケンス生成,генерация последовательности к последовательности,генерация последовательности-последовательности,последовательность к последовательности генерации
3918,sequence-to-sequence model,نموذج تسلسل إلى تسلسل,النموذج التسلسلي إلى التسلسل,نموذج تسلسل إلى تسلسل,序列到序列模型,序列到序列模型,序列到序列模型,modèle séquence à séquence,modèle de séquence à séquence,modèle de séquence à séquence,シーケンス間モデル,シーケンス対シーケンスモデル,シーケンスツーシーケンスモデル,модель последовательности к последовательности,модель последовательности к последовательности,модель последовательность к последовательности
3919,sequence-to-sequence transduction,تحويل تسلسل إلى تسلسل,التحويل من تسلسل إلى تسلسل,نقل ترميز متتابعة إلى متتابعة,序列到序列转导,序列到序列转导,序列到序列转导,transduction séquence à séquence,transduction de séquence à séquence,transduction séquence à séquence,配列間変換,シーケンス対シーケンス変換,シーケンス間変換,трансдукция из последовательности в последовательность,последовательность-в-последовательность трансдукция,Последовательно-последовательное преобразование
3920,sequential datum,مسند متسلسل,بيانات تتابعية,بيانات متتابعة,顺序数据,顺序数据,序列数据,donnée séquentielle,donnée séquentielle,donnée séquentielle,連続データム,連続データ,直列データ,последовательные данные,последовательные данные,последовательные данные
3921,sequential decision making,اتخاذ القرار بشكل تسلسلي,اتخاذ القرارات التسلسلية,صنع القرار المتسلسل,顺序决策,顺序决策-making,顺序决策,prise de décision séquentielle,- Décision séquentielle,prise de décision séquentielle,逐次的な意思決定,"""これらのシステムは、段階的な構文解析と連続意思決定の理解を改善するのに役立ち、その基礎となる計算手法は他の段階的な文脈の分析に役立つかもしれません。"", ""我々は、エージェントが離散的な時間ステップで環",逐次的意思決定,последовательное принятие решений,- Последовательное принятие решений,последовательное принятие решений
3922,sequential decision-making process,عملية صنع القرار التسلسلية,العملية التقريرية لاتخاذ القرارات,عملية صنع القرار التسلسلية,顺序决策过程,顺序决策过程,顺序决策过程,processus décisionnel séquentiel,Processus de prise de décision séquentielle,processus de prise de décision séquentielle,一連の意思決定プロセス,連続的意思決定プロセス,逐次的な意思決定プロセス,последовательный процесс принятия решений,Последовательный процесс принятия решений,процесс последовательного принятия решений
3923,sequential sampler,أخذ العينات متسلسل,المرشح التسلسلي,متعاقب المعايّن,顺序采样器,顺序采样器,顺序采样器,échantillonneur séquentiel,échantillonneur séquentiel,échantillonneur séquentiel,シーケンシャルサンプラー,連続サンプラー,順次サンプラー,последовательный сэмплер,последовательный сэмплер,последовательный сэмплер
3924,sequential tagging,وضع العلامات التسلسلية,الوسم التسلسلي,الوسم التسلسلي,顺序标记,顺序标记,序列标注,marquage séquentiel,étiquetage séquentiel,étiquetage séquentiel,順次タグ付け,順次タギング,順次タグ付け,последовательная маркировка,последовательная разметка,последовательное присвоение тегов
3925,set cover problem,تعيين مشكلة الغطاء,مشكلة تغطية المجموعة,مشكلة تغطية المجموعة,设置封面问题,集合覆盖问题,集合覆盖问题,problème de couverture,problème de couverture d'ensemble,problème de couverture d'ensemble,セットカバーの問題,セットカバー問題,集合被覆問題,установить проблему с обложкой,Проблема покрытия множеством,проблема покрытия множеств
3926,set function,تعيين وظيفة,دالة مجموعة,دالة المجموعة,设置功能,集合函数,集合函数,définir la fonction,fonction d'ensemble,fonction d'ensemble,セット関数,集合関数,セット関数,установить функцию,множественная функция,функция множества
3927,shallow network,شبكة ضحلة,شبكة ضحلة,شبكة ضحلة,浅层网络,浅层网络,浅层网络,réseau peu profond,réseau peu profond,réseau peu profond,浅いネットワーク,浅いネットワーク,浅い網,мелкая сеть,неглубокая сеть,Неглубокая сеть
3928,shape matching,مطابقة الشكل,تطابق الأشكال,مطابقة الأشكال,形状匹配,形状匹配,形状匹配,correspondance de forme,correspondance de forme,mise en correspondance de formes,形状一致,形状マッチング,形状マッチング,соответствие формы,сопоставление форм,сопоставление форм
3929,shape prior,الشكل قبل,قبلي الشكل,المعلم المسبق للشكل,先验形状,形状先验,形状先验,forme avant,forme a priori,a priori de forme,事前に形状を整える,形状事前情報 (Keijou Jizen Jouhou),形状事前確率,форма до,априорное знание о форме,форма априори
3930,shift invariant,تحول ثابت,التغيير ثابت,ثابت تحت الإزاحة,移位不变式,平移不变,平移不变,invariant de décalage,invariant par translation,invariant par translation,シフト不変,シフト不変,シフト不変,сдвиговый инвариант,- Сдвиг-инвариантный,инвариантный к сдвигу
3931,shift reduce parser,التحول تقليل المحلل,محلل تحويل-تقليص القيم,محلل نقل-تقليص,移位归约解析器,移位-归约分析器,移位归约分析器,décalage réduire l'analyseur,analyseur à décalage-réduction,analyseur par déplacement-réduction,シフトリデュースパーサー,シフトリデュースパーサ (shift reduce parser),シフト縮約パーサー,парсер сдвига и уменьшения,парсер сдвига-свёртки,анализатор со сдвигом и редукцией
3932,short path,طريق قصير,المسار القصير,طريق قصير,短路径,最短路径,最短路径,chemin court,Chemin court,chemin le plus court,短い道,- 短経路 (Tanshōro),最短経路,короткий путь,кратчайший путь,короткий путь
3933,short path algorithm,خوارزمية المسار القصير,خوارزمية المسار القصير,خوارزمية المسار الأقصر,短路径算法,短路径算法,最短路径算法,algorithme de chemin court,algorithme du plus court chemin,algorithme du plus court chemin,ショートパスアルゴリズム,短経路アルゴリズム (tankerotsu arugorizumu),最短経路アルゴリズム,алгоритм короткого пути,алгоритм кратчайшего пути,алгоритм кратчайшего пути
3934,short path kernel,نواة المسار القصير,نواة المسار الأقصر,نواة المسار القصير,短路径内核,最短路径核,最短路径核,noyau à chemin court,noyau de chemin le plus court,noyau de plus court chemin,ショートパスカーネル,最短経路カーネル (shortest path kernel),最短経路カーネル,ядро короткого пути,ядро кратчайшего пути,Ядро кратчайшего пути
3935,short path length,طول المسار القصير,طول المسار القصير,طول المسار القصير,短路径长度,最短路径长度 (shortest path length),短路径长度,chemin court,longueur de chemin courte,longueur du plus court chemin,短い経路長,- 短経路長 (たんけいろちょう),最短経路長,короткая длина пути,короткая длина пути,короткая длина пути
3936,siamese architecture,العمارة السيامية,الهندسة الثنائية,هندسة توأمية,暹罗建筑,连体架构,孪生架构,architecture siamoise,architecture siamoise,architecture siamoise,シャム建築,シャムアーキテクチャ,シャムアーキテクチャ,Сиамская архитектура,сиамская архитектура,архитектура сиамских близнецов
3937,siamese network,شبكة سيامية,شبكة سيامية,شبكة سيامية,连体网络,联合网络,孪生网络,réseau siamois,réseau siamois,réseau siamois,シャムネットワーク,シャムネットワーク,相姿ネットワーク,сиамская сеть,сиамская сеть,сиамская сеть
3938,sibling model,نموذج الأخوة,نموذج الأخوة,نموذج شقيق,兄弟姐妹模型,兄弟模型,兄弟模型,modèle frère ou sœur,"""['Par exemple, la définition de σ 1 = FIRST et σ t>1 = REST correspond à des modèles de premier ordre, tandis que la définition de σ 1 = NULL et σ t>1 = x t−1 correspond à des modèles frères (Eisner, 2000; McDonald et al., 2005; McDonald and Pereira, 2006).', 'Cette section décrit une classe particulière de modèles, les modèles frères ; la section suivante décrit un algorithme de dé",modèle de frère,兄弟モデル,兄弟モデル,兄弟モデル,родственная модель,модель близнецов,родственная модель
3939,sigmoid,السيني,سيغمويد,منحنى سجموئيد,乙状结肠,Sigmoid函数,sigmoid函数,sigmoïde,sigmoïde,sigmoïde,シグモイド,シグモイド,シグモイド関数,сигмовидная,Сигмоид,сигмоидная функция
3940,sigmoid activation,تفعيل السيني,التنشيط السيغموي,نشاط سيجمويد,乙状结肠激活,Sigmoid激活,sigmoid激活函数,activation sigmoïde,activation sigmoïde,fonction d'activation sigmoïde,シグモイド活性化,シグモイド活性化,シグモイド活性化関数,активация сигмовидной кишки,сигмоидная активация,сигмоидальная активация
3941,sigmoid activation function,وظيفة التنشيط السيني,وظيفة النشاط التسلسليsigmoid,دالة التنشيط السيجمويدية,乙状结肠激活函数,sigmoid激活函数,逻辑斯蒂函数,fonction d'activation sigmoïde,fonction d'activation sigmoïde,fonction d'activation sigmoïde,シグモイド活性化関数,シグモイド活性化関数 (shigumoido kasseika kansu),シグモイド活性化関数,функция активации сигмовидной кишки,сигмоидная функция активации,Сигмоидная функция активации
3942,sigmoid function,وظيفة السيني,وظيفة سيغمويد,دالة السجمويد,乙状结肠函数,Sigmoid函数,Sigmoid函数,fonction sigmoïde,fonction sigmoïde,fonction sigmoïde,シグモイド関数,シグモイド関数 (sigmoid function),シグモイド関数,сигмовидная функция,Сигмоидная функция,сигмоидная функция
3943,signal-to-noise ratio,إشارة إلى نسبة الضوضاء,نسبة الإشارة إلى الضوضاء,نسبة الإشارة إلى الضوضاء,信噪比,信噪比,信噪比,rapport signal sur bruit,rapport signal sur bruit,rapport signal sur bruit,信号対雑音比,信号対雑音比,信号対雑音比,отношение сигнал шум,отношение сигнал/шум,отношение сигнала к шуму
3944,sim,سيم,"""['إذا كانت sim(c(α), c(β)) > sim(c(α), c(δ)), نقول أن p β أكثر تشابهاً معنوياً مع p α من p δ بالنسبة لـ.', 'تُعرَّف خسارة التنظيم للاستعلام q للخطوة الفك التشفيرية i على النحو التالي",تَشْبِيه,模拟,相似度,相似度,sim,sim,simulation,シム,類似度,シム,сим,sim,симуляция
3945,similarity function,وظيفة التشابه,وظيفة التشابه,دالة التشابه,相似函数,相似性函数,相似性函数,fonction de similarité,fonction de similarité,fonction de similarité,類似度関数,類似関数 (ruijikan),類似度関数,функция сходства,функция сходства,функция сходства
3946,similarity graph,الرسم البياني للتشابه,الرسم البياني للتشابه,شَبَكَة التَّشَابُه,相似图,相似性图,相似性图谱,graphique de similarité,- Graph de similarité,graphe de similarité,類似度グラフ,類似度グラフ (るいじどぐらふ),類似グラフ,график сходства,граф сходства,граф подобия
3947,similarity matrix,مصفوفة التشابه,مصفوفة الشبه,مصفوفة التشابه,相似度矩阵,相似性矩阵,相似性矩阵,matrice de similarité,matrice de similarité,matrice de similarité,類似度行列,類似度行列,類似性行列,матрица сходства,матрица сходства,матрица подобия
3948,similarity measure,قياس التشابه,مقياس التشابه,مقياس التشابه,相似性度量,相似性度量,相似度量,mesure de similarité,mesure de similarité,mesure de similarité,類似性の尺度,類似度尺度,類似度尺度,мера сходства,мера сходства,мера сходства
3949,similarity metric,مقياس التشابه,مقياس الشبه,مقياس التشابه,相似度度量,相似度度量,相似性度量,métrique de similarité,- Metric de similarité,métrique de similarité,類似性メトリック,類似度メトリック,類似度尺度,показатель сходства,метрика сходства,метрика сходства
3950,similarity score,درجة التشابه,نقطة الشبهية,نقطة التشابه,相似度得分,相似度分数,相似度评分,score de similarité,- Score de similarité,Score de similarité,類似性スコア,類似スコア,類似性スコア,показатель сходства,оценка сходства,Показатель сходства
3951,similarity search,بحث التشابه,البحث عن التشابه,البحث عن التشابه,相似性搜索,相似度搜索,相似性搜索,recherche de similarité,recherche de similarité,recherche de similarité,類似性検索,類似検索 (ruijiken-saku),類似度検索,поиск сходства,поиск похожести,поиск схожих
3952,simplicial complex,مجمع مبسط,المجمع البسيطي,مجموعة بسيطة,单纯复形,单纯复合物,单纯复形,complexe simplicial,complexe simplicial,complexe simplicial,単純な複合体,単体複体,単体複体,симплициальный комплекс,симплициальный комплекс,симплициальный комплекс
3953,simulated annealing,محاكاة الصلب,التبريد المحاكي,تلدين المحاكاة,模拟退火,模拟退火,模拟退火,recuit simulé,recuit simulé,recuit simulé,焼き鈍し法,シミュレーテッドアニーリング,シミュレーテッドアニーリング,имитация отжига,имитационное отжигание,имитация отжига
3954,single task learning,التعلم بمهمة واحدة,التعلم من المهام الفردية,التعلم ذو المهمة الواحدة,单任务学习,单任务学习,单任务学习,apprentissage en une seule tâche,apprentissage à tâche unique,Apprentissage monotâche,シングルタスク学習,シングルタスク学習 (single task learning),単一タスク学習,обучение одной задаче,обучение с одной задачей,обучение на одной задаче
3955,single-label classification,تصنيف تسمية واحدة,تصنيف بتسمية واحدة,تصنيف الملصق الفردي,单标签分类,单标签分类,单标签分类,classification à étiquette unique,Classification à étiquette unique,classification mono-étiquette,単一ラベル分類,単一ラベル分類 (single-label classification),単一ラベル分類,классификация по одной метке,одноклассовая классификация,Классификация с одним меткой
3956,single-view data,بيانات عرض واحد,بيانات عرض واحد,بيانات منظور واحد,单视图数据,单视图数据,单视数据,données à vue unique,données à vue unique,données à vue unique,シングルビューデータ,単一視点データ,単一ビューデータ,данные одного представления,одновидовые данные,Данные с единственным видом
3957,singleton,مفردة,مفرد,وحيد,单例,单例,单个实体,singleton,singleton,singulier,シングルトン,シングルトン,シングルトン,синглтон,одиночка,одиночка
3958,singular value,قيمة مفردة,قيمة مفردة,القيمة المفردة,奇异值,奇异值,奇异值,valeur singulière,valeur singulière,valeur singulière,特異値,特異値,単独値,единственное значение,сингулярное значение,сингулярное значение
3959,singular value decomposition,تحليل القيمة المفردة,تفكيك قيمة مفردة,تحليل القيم المنفردة,奇异值分解,奇异值分解,奇异值分解,décomposition en valeurs singulières,Décomposition en valeurs singulières,décomposition en valeurs singulières,特異値分解,特異値分解,特異値分解,разложение по сингулярным значениям,Сингулярное разложение значений,сингулярное разложение
3960,singular vector,ناقلات المفرد,المتجه الفردي,متجه منفرد,奇异向量,奇异向量 (singular vector),奇异向量,vecteur singulier,vecteur singulier,vecteur singulier,特異ベクトル,特異ベクトル (toku i bekutoru),特異ベクトル,вектор единственного числа,сингулярный вектор,сингулярный вектор
3961,skip connection,تخطي الاتصال,اتصال تخطي,اتصال تخطي,跳过连接,跳连线,跳跃连接,ignorer la connexion,connexion directe,connexion résiduelle,接続をスキップする,スキップ接続 (skip connection),スキップ接続,пропустить соединение,пропускное соединение,пропускное соединение
3962,skip-gram,تخطي جرام,نموذج الذاكرة القافزة,تجاوز الكلمة,跳语法,skip-gram 跳字模型,跳元模型,sauter-gramme,skip-gram,n-gramme sauté,スキップグラム,スキップグラム,スキップグラム,пропуск грамма,пропуск-грамма,пропуск слова
3963,skip-gram model,نموذج تخطي جرام,نموذج skip-gram,نموذج تخطي الكلمة,跳语法模型,跳字模型,跳元模型,modèle sauter-gramme,modèle skip-gram,modèle skip-gram,スキップグラムモデル,skip-gram モデル,スキップグラムモデル,модель пропуска грамма,модель skip-грам,модель скип-грамм
3964,slack variable,متغير الركود,متغير فارغ,متغير فراغ,松弛变量,松弛变量,松弛变量,variable de jeu,"""['où ŷ i −y i 1 est le nombre d'arcs non appariés entre les deux arbres, et ξ i est une variable d'écart non négative. Les contraintes servent à séparer l'arbre en or des autres alternatives dans Y(x i ) avec une marge qui augmente avec la distance.', 'Notre classifieur est ensuite formulé comme ℱ(x ) = arg max {w ⋅x }, où w est un vecteur de poids pour la sous-classe",variable d'écart,スラック変数,スラック変数 (surakku hensū),スラック変数,слабая переменная,слак-переменная,переменная-слэк
3965,slide window,نافذة الشريحة,نافذة منزلقة,نافذة منزلقة,滑动窗口,滑动窗口,滑动窗口,fenêtre coulissante,fenêtre coulissante,fenêtre glissante,スライドウィンドウ,スライドウィンドウ,スライディングウィンドウ,слайд-окно,скользящее окно,скользящее окно
3966,slide window classifier,مصنف نافذة الشريحة,مصنف نافذة الانزلاق,تصنيف نافذة منزلقة,滑动窗口分类器,滑动窗口分类器,滑动窗口分类器,classificateur de fenêtre coulissante,Classificateur de fenêtre coulissante,Classifieur par fenêtre glissante,スライドウィンドウ分類器,スライドウィンドウ分類器,スライディングウィンドウ分類器,классификатор слайд-окна,скользящий оконный классификатор,скользящий оконный классификатор
3967,slot,فتحة,فتحة,فتحة,投币口,槽值,槽,fente,fente,emplacement,スロット,- スロット,スロット,слот,слот,слот
3968,slot filling,ملء الفتحة,ملء الفتحة,ملء الفراغات,槽填充,槽填充,槽填充,remplissage des fentes,remplissage de slot,remplissage de créneau,スロット充填,スロット補充,スロット充填,заполнение слота,заполнение слотов,заполнение слотов
3969,slot value,قيمة الفتحة,قيمة الفتحة,قيمة الفرعية,槽位值,槽值,槽值,valeur de l'emplacement,- Valeur de fente,valeur de créneau,スロット値,スロット値,スロット値,значение слота,значение слота,значение слота
3970,slot-value pair,زوج من قيمة الفتحة,زوج قيمة الفتحة,شريحة - زوج القيمة,槽值对,插槽-值对,槽位-值对,paire valeur-emplacement,paire slot-valeur,paires attribut-valeur,スロット値のペア,スロット値ペア,スロット値ペア,пара слот-значение,пара «слот-значение»,пара слот-значение
3971,smoothing parameter,معلمة التنعيم,معامل التنعيم,معامل التمهيد,平滑参数,平滑参数,平滑参数,paramètre de lissage,- Paramètre de lissage,paramètre de lissage,スムージングパラメータ,スムージングパラメータ,平滑化パラメータ,параметр сглаживания,параметр сглаживания,Параметр сглаживания
3972,smoothness term,مصطلح نعومة,مصطلح النعومة,شَرْط اللُّيُونَة,平滑项,平滑项,平滑项,terme de douceur,- Terme de régularité,terme de régularité,滑らかさの項,滑らかさ項,スムーズネス項,термин гладкости,термин плавности,гладкость
3973,social bias,التحيز الاجتماعي,الانحياز الاجتماعي,التحيز الاجتماعي,社会偏见,社会偏见,社会偏见,préjugé social,biais social,biais social,社会的偏見,社会的偏見,社会的偏見,социальная предвзятость,социальный предвзятость,социальная предвзятость
3974,social network analysis,تحليل الشبكة الاجتماعية,تحليل شبكات التواصل الاجتماعي,تحليل الشبكات الاجتماعية,社交网络分析,社交网络分析,社会网络分析,analyse des réseaux sociaux,- Analyse des réseaux sociaux,analyse des réseaux sociaux,ソーシャルネットワーク分析,ソーシャルネットワーク分析 (Social Network Analysis),ソーシャル・ネットワーク分析,анализ социальных сетей,анализ социальной сети,анализ социальных сетей
3975,soft margin,هامش ناعم,هامش ناعم,هامش لين,软边距,软间隔,松弛边界,marge douce,marge souple,marge souple,ソフトマージン,ソフトマージン,ソフトマージン (soft margin),мягкая маржа,мягкий зазор,мягкий отступ
3976,softmax activation,تفعيل سوفت ماكس,تنشيط سوفتماكس,تنشيط softmax,Softmax激活,softmax 激活函数,softmax激活函数,activation softmax,- Activation softmax,activation softmax,ソフトマックスのアクティベーション,ソフトマックス活性化,ソフトマックス活性化関数,активация softmax,активация softmax,функция активации softmax
3977,softmax activation function,وظيفة تفعيل سوفت ماكس,وظيفة التنشيط الناعمة القريبة من الماخوذة,وظيفة التنشيط softmax,Softmax激活函数,softmax 激活函数,softmax激活函数,fonction d'activation softmax,fonction d'activation softmax,fonction d'activation softmax,ソフトマックス活性化関数,ソフトマックス活性化関数,ソフトマックス活性化関数,функция активации softmax,функция активации softmax,функция активации softmax
3978,softmax classifier,المصنف softmax,مصنف softmax,مصنف السوفت ماكس,Softmax分类器,softmax分类器,软最大分类器,classificateur softmax,classificateur softmax,classifieur softmax,ソフトマックス分類器,ソフトマックス分類器,ソフトマックス分類器,классификатор softmax,классификатор softmax,классификатор softmax
3979,softmax distribution,توزيع سوفت ماكس,التوزيع الناعم,توزيع softmax,软最大分布,Softmax分布,softmax分布,distribution softmax,distribution softmax,Distribution softmax,ソフトマックス分布,ソフトマックス分布,ソフトマックス分布,мягкое максимальное распределение,распределение softmax,распределение сумм
3980,softmax function,وظيفة سوفت ماكس,وظيفة السوفتماكس,دالة التليين,软最大函数,softmax函数,softmax函数,fonction softmax,fonction softmax,fonction softmax,ソフトマックス関数,ソフトマックス関数,ソフトマックス関数,функция softmax,функция softmax,функция softmax
3981,softmax layer,طبقة سوفت ماكس,الطبقة الناعمة,طبقة الـ softmax,Softmax层,Softmax 层,软最大化层,couche softmax,- Couche softmax,couche softmax,ソフトマックス層,ソフトマックス層,ソフトマックス層,слой softmax,слой softmax,слой софтмакс
3982,softmax loss,خسارة سوفت ماكس,فقدان softmax,خسارة الناعمة القصوى,软最大损失,softmax损失,软最大化损失,perte softmax,perte softmax,perte softmax,ソフトマックス損失,ソフトマックス損失,ソフトマックス損失,софтмакс потеря,функция потерь softmax,функция потерь softmax
3983,softplus,com.softplus,وظيفة softplus,لين-زائد,软加,softplus - 软正函数,平滑修正线性单元函数,softplus,softplus,plusdoux,ソフトプラス,ソフトプラス,ソフトプラス関数,софтплюс,сигмоида,сумма логарифмов
3984,softplus activation,تفعيل سوفت بلس,التنشيط الناعم,تنشيط softplus,软加激活,softplus激活,软正切激活函数,activation softplus,activation softplus,activation softplus,ソフトプラスのアクティベーション,ソフトプラス活性化,ソフトプラス活性化関数,активация софтплюс,активация Softplus,активация софтплюс
3985,softplus function,وظيفة سوفت بلس,وظيفة السوفت بلس,دالة النعومة الإضافية,软加功能,软加函数,柔和正函数 (softplus function),fonction softplus,fonction softplus,fonction softplus,ソフトプラス機能,ソフトプラス関数,ソフトプラス関数,функция софтплюс,функция с логарифмическим прибавлением,Функция softplus
3986,solution space,مساحة الحل,المجال الحلول,فضاء الحلول,解空间,解空间,解空间,espace de solutions,espace de solution,espace de solutions,ソリューションスペース,解空間,解空間,пространство решений,пространство решений,пространство решений
3987,solver,حلالا,محلل الحلول,حل,求解器,求解器,解算器,solveur,solveur,solveur,ソルバー,ソルバー,ソルバー,решатель,солвер,решатель
3988,source domain,المجال المصدر,مجال المصدر,المجال المصدري,源域,源域,源域,domaine source,domaine source,domaine source,ソースドメイン,ソースドメイン,入力ドメイン,исходный домен,домен источника,источник домена
3989,source model,نموذج المصدر,نموذج المصدر,نموذج المصدر,源模型,源模型,源模型,modèle source,modèle source,modèle source,ソースモデル,元モデル (gen model),ソースモデル,исходная модель,модель источника,исходная модель
3990,source node,عقدة المصدر,عقدة المصدر,عقدة المصدر,源节点,源节点,源节点,nœud source,- Node source,nœud source,ソースノード,ソースノード,入力ノード,исходный узел,исходный узел,Исходный узел
3991,source sequence,تسلسل المصدر,التسلسل المصدري,المصدر التسلسلي,源序列,源序列,源序列,séquence source,séquence source,séquence source,ソースシーケンス,ソースシーケンス,入力シーケンス,исходная последовательность,исходная последовательность,исходная последовательность
3992,source token,رمز المصدر,مفتاح المصدر,كلمة المصدر,源令牌,源标记,源词元,jeton source,jeton source,jeton source,ソーストークン,ソーストークン (source token),ソーストークン,токен источника,исходный токен,исходный токен
3993,source word,كلمة المصدر,كلمة المصدر,كلمة المصدر,源词,源词,源词,mot source,mot source,mot source,ソースワード,ソース語,ソースワード,исходное слово,исходное слово,исходное слово
3994,space carving,نحت الفضاء,نحت الفضاء,نحت الفضاء,空间雕刻,空间雕刻,空间雕刻,sculpture spatiale,sculpture spatiale,sculpture d'espace,空間彫刻,スペースカービング,空間彫刻,космическая резьба,пространственная резьба,вырезание пространства
3995,space complexity,تعقيد الفضاء,تعقيد المساحة,تعقيد المساحة,空间复杂度,空间复杂度,空间复杂度,complexité de l'espace,complexité de l'espace,Complexité spatiale,空間の複雑さ,スペース複雑性 (supēsu fukuzatsusei),空間複雑度,космическая сложность,Пространственная сложность,пространственная сложность
3996,space partitioning,تقسيم الفضاء,تجزئة الفضاء,تجزئة الفضاء,空间划分,空间划分,空间划分,partitionnement de l'espace,partitionnement d'espace,partitionnement de l'espace,空間の仕切り,空間分割,空間分割,разделение пространства,разделение пространства,разбиение пространства
3997,spam detection,كشف البريد العشوائي,الكشف عن البريد العشوائي,كشف البريد العشوائي,垃圾邮件检测,垃圾邮件检测,垃圾邮件检测,détection de spam,détection de spam,détection des pourriels,スパム検出,スパム検出,迷惑メール検出,обнаружение спама,спам-фильтрация,Обнаружение спама
3998,spam filtering,تصفية البريد العشوائي,تصفية البريد المزعج,فرز البريد العشوائي,垃圾邮件过滤,垃圾邮件过滤,垃圾邮件过滤,filtrage anti-spam,Filtrage des spams,Filtrage des pourriels,スパムフィルタリング,スパムフィルタリング,スパムフィルタリング,фильтрация спама,фильтрация спама,фильтрация спама
3999,span,فترة,المدى,مدى,跨度,跨度,张量,portée,espace vectoriel,portée,スパン,スパン,スパン,охватывать,спан,прогиб
4000,sparse,متناثر,"""['تم اختبار هذه التكوينات الستة باستخدام الإسقاطات العشوائية الثلاثة المذكورة في القسم السابق (أي، غاوسية، متناثرة، وثنائية، معتمدة على G و S و B على التوالي)، مما أسفر ع",نادر,疏,稀疏,稀疏,clairsemé,Epars,épars,まばらな,スパース,疎,редкий,разреженный,разреженный
4001,sparse Transformer,محول متناثر,المحول النائي,متحول قليل الكثافة,稀疏变压器,稀疏Transformer,稀疏Transformer,Transformateur clairsemé,transformer épars,Transformeur creux,スパーストランスフォーマー,スパース トランスフォーマー (sparse Transformer),疎Transformer,разреженный трансформатор,Разреженный трансформер,Разреженный преобразователь
4002,sparse approximation,تقريب متناثر,تقريب خفيّ,تقريب متفرق,稀疏近似,稀疏逼近,稀疏近似,approximation clairsemée,- Approximation parcimonieuse,approximation parcimonieuse,スパース近似,疎な近似 (Sparse approximation),疎近似,разреженное приближение,Разреженная аппроксимация,разреженное приближение
4003,sparse attention,اهتمام متفرق,الانتباه الضعيف,انتباه متناثر,注意力稀疏,稀疏注意力,稀疏注意力,peu d'attention,attention clairsemée,attention éparse,まばらな注意力,スパースアテンション,疎な注意力,мало внимания,- Разреженное внимание,разреженное внимание
4004,sparse attention pattern,نمط الاهتمام المتناثر,نمط تركيز متناثر,نمط الانتباه المتفرق,稀疏注意力模式,稀疏注意力模式,稀疏注意力模式,modèle d'attention clairsemé,motif d'attention clairsemé,motif d'attention éparse,まばらな注意パターン,疎な注意パターン,疎な注意のパターン,нехватка внимания,разреженный шаблон внимания,разреженный шаблон внимания
4005,sparse graph,رسم بياني متفرق,الرسم البياني الخالي من العقد,رسم بياني متفرق,稀疏图,稀疏图,稀疏图,graphique clairsemé,- Graphes épars,graphe creux,スパースグラフ,疎なグラフ (Sparse Graph),疎グラフ,разреженный граф,разреженный граф,разреженный граф
4006,sparse matrix,مصفوفة متفرقة,مصفوفة متناثرة,مصفوفة متفرقة,稀疏矩阵,稀疏矩阵,稀疏矩阵,matrice clairsemée,matrice éparses,matrice creuse,スパース行列,疎行列,疎行列,разреженная матрица,разреженная матрица,разреженная матрица
4007,sparse model,نموذج متناثر,- التصميم النحيف,نموذج قليل الكثافة,稀疏模型,稀疏模型,稀疏模型,modèle clairsemé,modèle clairsemé,modèle épars,スパースモデル,"Sparse Model
スパースモデル",疎モデル,разреженная модель,- Разреженная модель,разреженная модель
4008,sparse reconstruction,إعادة بناء متفرقة,الإعادة القليلة,إعادة البناء الضئيل,稀疏重建,稀疏重建,稀疏重建,reconstruction clairsemée,reconstruction parcimonieuse,reconstruction éparse,まばらな再構成,疎な再構築,疎再構築,скудная реконструкция,Разреженная реконструкция,разреженная реконструкция
4009,sparse recovery,انتعاش متناثر,استعادة فقيرة,مُستَرْجِع قَلِيل,稀疏恢复,稀疏恢复,稀疏恢复,récupération clairsemée,récupération parcimonieuse,récupération parcimonieuse,まばらな回復,疎な回復,疎回復,редкое восстановление,разреженное восстановление,редкое восстановление
4010,sparse representation,تمثيل متناثر,التمثيل النادر.,تمثيل متقطع,稀疏表示,稀疏表示,稀疏表示,représentation clairsemée,représentation clairsemée,représentation parcimonieuse,スパース表現,スパース表現,疎な表現,редкое представительство,- Разреженное представление,редкое представление
4011,sparse sampling,أخذ عينات متفرقة,- التعيين الضئيل,أخذ عينات متناثرة,稀疏采样,稀疏采样,稀疏采样,échantillonnage clairsemé,échantillonnage épars,échantillonnage éparse,スパースサンプリング,希薄サンプリング,疎サンプリング,разреженная выборка,разреженная выборка,редкое выборочное наблюдение
4012,sparse vector,ناقلات متفرقة,متجه متناثر,متجه متناثر,稀疏向量,稀疏向量,稀疏向量,vecteur clairsemé,vecteur clairsemé,vecteur creux,スパースベクトル,疎ベクトル (そベクトル),疎ベクトル,разреженный вектор,- Разреженный вектор,разреженный вектор
4013,sparsification,التشتت,تخفيض الكثافة,تخفيف الكثافة,稀疏化,稀疏化,稀疏化,sparsification,éparsification,éparsification,スパース化,スパーシフィケーション (supaashifikeshon),希少化,разреженность,разрежение,разрежение
4014,sparsity,متناثرة,التباعد,نُدرة,稀疏性,稀疏性,稀疏性,rareté,éparsité,parcimonie,まばらさ,スパース性 (supaasusei),疎性,редкость,разреженность,разреженность
4015,sparsity level,مستوى التناثر,مستوى الانتشارية,مستوى التخفيف,稀疏度,稀疏度水平,稀疏水平,niveau de rareté,niveau de parcimonie,niveau de parcimonie,まばらさレベル,スパース度,疎密度レベル,уровень разреженности,Уровень разреженности,уровень разреженности
4016,sparsity regularization,تنظيم التناثر,التنظيم القليلية,تنظيم الخشونة,稀疏正则化,稀疏正则化,稀疏正则化,régularisation de parcimonie,régularisation de la parcimonie,régularisation de parcimonie,スパース正則化,スパース性正則化,疎性正規化,регуляризация разреженности,Регуляризация разреженности,регуляризация редкости
4017,spatial domain,نطاق المكاني,المجال المكاني,المجال المكاني,空间域,空间域,空间域,domaine spatial,- Domaine spatial,domaine spatial,空間ドメイン,空間領域 (くうかん りょういき),空間領域,пространственная область,пространственная область,пространственная область
4018,spatial gradient,التدرج المكاني,الميل المكاني,تدرج مكاني,空间梯度,空间梯度 (spatial gradient),空间梯度,gradient spatial,gradient spatial,gradient spatial,空間勾配,空間勾配 (Kūkan kōsai),空間勾配,пространственный градиент,Спатиальный градиент,пространственный градиент
4019,spatial pooling,التجميع المكاني,التجميع المكاني,تجميع مكاني,空间池化,空间池化,空间池化,mutualisation spatiale,regroupement spatial,mise en commun spatiale,空間プーリング,空間プーリング,ディーププーリング,пространственное объединение,пространственное объединение,объединение пространственных областей
4020,spatial pyramid,الهرم المكاني,الهرم الفضائي,هرم مكاني,空间金字塔,空间金字塔,空间金字塔,pyramide spatiale,pyramide spatiale,pyramide spatiale,空間ピラミッド,空間ピラミッド,空間ピラミッド,пространственная пирамида,пространственная пирамида,пространственная пирамида
4021,speak dialogue system,التحدث بنظام الحوار,نظام حوار متكلم,نظام محادثة صوتية,说话对话系统,口语对话系统,口语对话系统,parler du système de dialogue,"""La génération de langage naturel (NLG) fournit une grande partie de la personnalité d'un système de dialogue parlé (SDS), et elle a un impact significatif sur l'impression de l'utilisateur du système. Comme indiqué dans Stent et al."", 'Nous avons développé de manière itérative et déployé un système de dialogue parlé multimodal, multiparti dans une clinique de la mémoire d'un hôpital. Ce SDS est incarné par le robot social ARI, ce qui",système de dialogue parlé,スピーキングダイアログシステム,話す対話システム (hanasu taido shisutemu),音声対話システム,говорить диалоговая система,система разговорного диалога,система разговорного диалога
4022,spearman correlation,علاقة سبيرمان,الترابط سبيرمان,ارتباط سبيرمان,斯皮尔曼相关性,斯皮尔曼相关性,斯皮尔曼相关系数,corrélation de lancier,corrélation de Spearman,corrélation de Spearman,スピアマンの相関関係,スピアマン相関,スピアマン相関係数,корреляция Спирмена,коэффициент корреляции Спирмена,корреляция по Спирмену
4023,spearman rank correlation,ارتباط رتبة سبيرمان,- الترابط الرتبي لسبيرمان,معامل ارتباط رتب سبيرمان,斯皮尔曼等级相关,斯皮尔曼等级相关性,斯皮尔曼等级相关系数,corrélation de rang de lancier,corrélation de rang de Spearman,corrélation des rangs de Spearman,スピアマンのランク相関,スピアマンの順位相関,スピアマンの順位相関,корреляция рангов копейщика,Корреляция Спирмена(rank),Ранговая корреляция Спирмена
4024,special token,رمز خاص,- توكن خاص,رمز خاص,特殊令牌,特殊标记 (special token),特殊标记,jeton spécial,jeton spécial,Jeton spécial,特別なトークン,特殊トークン (Tokushu tōkun),特殊トークン,специальный жетон,особый токен,специальный токен
4025,spectral algorithm,الخوارزمية الطيفية,خوارزمية طيفية,خوارزمية الطيف,谱算法,谱算法,光谱算法,algorithme spectral,algorithme spectral,algorithme spectral,スペクトルアルゴリズム,スペクトルアルゴリズム (spectrum algorithm),スペクトル法,спектральный алгоритм,спектральный алгоритм,спектральный алгоритм
4026,spectral clustering,التجمع الطيفي,التجميع الطيفي,تجميع طيفي,谱聚类,谱聚类,谱聚类,regroupement spectral,regroupement spectral,regroupement spectral,スペクトルクラスタリング,スペクトルクラスタリング,スペクトル クラスタリング,спектральная кластеризация,спектральная кластеризация,спектральная кластеризация
4027,spectral decomposition,التحلل الطيفي,تحليل طيفي,تحليل طيفي,谱分解,谱分解,光谱分解,décomposition spectrale,décomposition spectrale,décomposition spectrale,スペクトル分解,スペクトル分解,スペクトル分解,спектральное разложение,спектральное разложение,спектральное разложение
4028,spectral embedding,التضمين الطيفي,التضمين الطيفي,تضمين طيفي,光谱嵌入,光谱嵌入,光谱嵌入,intégration spectrale,incorporation spectrale,plongement spectral,スペクトルの埋め込み,スペクトル埋め込み,スペクトル埋め込み,спектральное вложение,спектральное вложение,спектральное вложение
4029,spectral gap,الفجوة الطيفية,الفجوة الطيفية,الفجوة الطيفية,光谱间隙,光谱间隙,光谱间隙,écart spectral,écart spectral,écart spectral,スペクトルギャップ,スペクトルギャップ,スペクトルギャップ,спектральная щель,спектральный зазор,спектральный разрыв
4030,spectral learning,التعلم الطيفي,التعلم الطيفي,التعلم الطيفي,光谱学习,谱学习 (Spectral Learning),谱学习,apprentissage spectral,apprentissage spectral,apprentissage spectral,スペクトル学習,スペクトル学習 (Spectral Learning),スペクトル学習,спектральное обучение,спектральное обучение,спектральное обучение
4031,spectral matching,المطابقة الطيفية,المطابقة الطيفية,مطابقة الطيف,光谱匹配,光谱匹配,光谱匹配,correspondance spectrale,correspondance spectrale,mise en correspondance spectrale,スペクトルマッチング,スペクトルマッチング,スペクトル マッチング,спектральное согласование,спектральное сопоставление,спектральное соответствие
4032,spectral method,الطريقة الطيفية,الطريقة الطيفية,طريقة طيفية,光谱法,光谱方法,光谱法,méthode spectrale,- Méthode spectrale,méthode spectrale,スペクトル法,スペクトル法 (Supekutoru-ho),スペクトル法,спектральный метод,спектральный метод,спектральный метод
4033,spectral norm,القاعدة الطيفية,المعيار الطيفي,المعيار الطيفي,谱范数,光谱范数,谱范数,norme spectrale,- Norme spectrale,norme spectrale,スペクトルノルム,スペクトルノルム,スペクトル行列ノルム,спектральная норма,спектральная норма,спектральная норма
4034,spectral property,خاصية طيفية,الخصائص الطيفية,خصائص طيفية,光谱特性,光谱特性,光谱性质,propriété spectrale,Propriété spectrale,propriété spectrale,スペクトル特性,スペクトル特性 (Supekutoru Tokusei),スペクトル特性,спектральное свойство,спектральные свойства,спектральное свойство
4035,spectrogram,مخطط طيفي,- تحليل الطيف,مخطط الطيف,频谱图,频谱图,声谱图,spectrogramme,spectrogramme,spectrogramme,スペクトログラム,スペクトログラム,スペクトログラム,спектрограмма,спектрограмма,спектрограмма
4036,speech recognition,التعرف على الكلام,التعرف على الكلام,التعرف على الكلام,语音识别,语音识别,语音识别,reconnaissance de la parole,reconnaissance vocale,reconnaissance vocale,音声認識,音声認識,音声認識,распознавание речи,распознавание речи,распознавание речи
4037,speech recognizer,أداة التعرف على الكلام,معترف بالكلام,معرف الكلام,语音识别器,语音识别器,语音识别器,reconnaissance vocale,reconnaisseur de discours,reconnaisseur vocal,音声認識装置,音声認識器 (Onsei Ninshiki-ki),音声認識器,распознаватель речи,распознаватель речи,распознаватель речи
4038,speech synthesis model,نموذج تركيب الكلام,نموذج توليد الكلام,نموذج توليد الكلام,语音合成模型,语音合成模型,语音合成模型,modèle de synthèse vocale,modèle de synthèse vocale,modèle de synthèse vocale,音声合成モデル,音声合成モデル (onsei gousei moderu),音声合成モデル,модель синтеза речи,модель синтеза речи,Модель синтеза речи
4039,speech synthesizer,مركب الكلام,جهاز تركيب الكلام,مُولِّد الكَلام البَشَري,语音合成器,语音合成器,语音合成器,synthétiseur vocal,synthétiseur vocal,synthétiseur vocal,音声合成装置,音声合成器,音声合成器,синтезатор речи,речевой синтезатор,синтезатор речи
4040,spurious correlation,علاقة زائفة,الترابط الزائف,ارتباط زائف,虚假相关性,虚假相关,伪相关,corrélation parasite,corrélation fallacieuse,corrélation factice,擬似相関,誤った相関,偽の相関関係,ложная корреляция,Ложная корреляция,ложная корреляция
4041,square euclidean distance,المسافة الإقليدية المربعة,المسافة الأوروبية المربعة,مسافة إقليدية مربعة,平方欧氏距离,欧几里德距离的平方,平方欧几里德距离,distance euclidienne carrée,distance euclidienne au carré,distance euclidienne au carré,二乗ユークリッド距離,二乗ユークリッド距離,二乗ユークリッド距離,квадратное евклидово расстояние,квадрат евклидового расстояния,квадрат евклидова расстояния
4042,squared error loss,خسارة الخطأ التربيعي,خسارة مربعة للخطأ,خسارة مربع الخطأ,平方误差损失,平方误差损失,平方误差损失,perte d'erreur quadratique,perte d'erreur quadratique,perte d'erreur quadratique,二乗誤差損失,二乗誤差損失,二乗誤差損失,квадратичная ошибка потери,квадратичная ошибка потерь,квадратичная ошибка потерь
4043,stable model,نموذج مستقر,النموذج المستقر,نموذج مستقر,稳定模型,稳定模型,稳定模型,modèle stable,modèle stable,modèle stable,安定したモデル,安定モデル (antei moderu),安定モデル,стабильная модель,устойчивая модель,стабильная модель
4044,stable model semantic,نموذج دلالي مستقر,النموذج الثابت الدلالي,دلالات النموذج المستقر,稳定的模型语义,稳定模型语义,稳定模型语义,sémantique du modèle stable,sémantique du modèle stable,sémantique des modèles stables,安定したモデルのセマンティクス,安定モデル意味論,安定モデルセマンティクス,стабильная семантика модели,семантика устойчивой модели,Семантика стабильной модели
4045,stance detection,كشف الموقف,كشف الموقف,كشف الموقف,姿态检测,立场检测,立场检测,détection de position,détection de positionnement,détection de position,スタンス検出,スタンス検出,スタンス検出,обнаружение позиции,обнаружение позиции,обнаружение позиции
4046,standard normal distribution,التوزيع القياسي,التوزيع الطبيعي القياسي,توزيع طبيعي قياسي,标准正态分布,标准正态分布,标准正态分布,distribution normale standard,distribution normale standard,distribution normale standard,標準正規分布,標準正規分布 (Standard Normal Distribution),標準正規分布,стандартное нормальное распределение,стандартное нормальное распределение,стандартное нормальное распределение
4047,start token,رمز البداية,رمز البداية,رمز البدء,启动令牌,起始标记,开始标记,jeton de démarrage,jeton de départ,jeton de départ,開始トークン,開始トークン (kaishi tōkun),開始トークン,стартовый токен,стартовый токен,Начальный токен
4048,state,ولاية,الحالة,حالة,状态,状态,状态,État,état,état,州,状態 (joutai),状態,состояние,состояние,состояние
4049,state action pair,زوج عمل الدولة,- توصيف حالة وإجراء,زوج الحالة والإجراء,状态动作对,状态动作对,状态动作对,paire d'actions d'état,paire état-action,paire état-action,状態アクションのペア,状態アクションペア (jōtai akushon pea),状態行動ペア,пара действий состояния,пара состояние-действие,пара состояние-действие
4050,state distribution,توزيع الدولة,توزيع الحالة,توزيع الحالة,状态分布,状态分布,状态分布,répartition de l'état,- Distribution d'état,distribution des états,状態分布,状態分布,状態分布,государственное распределение,распределение состояний,распределение состояний
4051,state estimation,تقدير الدولة,تقدير الحالة,تقدير الحالة,状态估计,状态估计,状态估计,estimation de l'état,estimation d'état,estimation d'état,状態推定,状態推定 (joutai suitei),状態推定,государственная оценка,оценка состояния,оценка состояния
4052,state machine,آلة الدولة,آلة حالة,آلة الحالات,状态机,状态机,有限状态机,machine à états,machine à états,Automate à états,ステートマシン,状態機械 (じょうたいきかい),ステートマシン,Государственный аппарат,конечный автомат,автомат с конечным числом состояний
4053,state matrix,مصفوفة الحالة,مصفوفة الحالة,مصفوفة الحالة,状态矩阵,状态矩阵,状态矩阵,matrice d'état,matrice d'état,matrice d'état,状態行列,状態行列 (joutai gyōretsu),状態行列,матрица состояний,матрица состояний,матрица состояния
4054,state of the art algorithm,حالة من الخوارزمية الفنية,خوارزمية حديثة,خوارزمية متطورة,最先进的算法,最先进算法,最先进算法,algorithme de pointe,algorithme de pointe,algorithme de pointe,最先端のアルゴリズム,最先端アルゴリズム,最先端のアルゴリズム,современный алгоритм,алгоритм передовой технологии,алгоритм на передовом рубеже
4055,state representation,تمثيل الدولة,تمثيل الحالة,تمثيل الحالة,国家代表,状态表示,状态表示,représentation de l'État,représentation de l'état,représentation d'état,状態表現,状態表現,状態表現,государственное представительство,представление состояния,представление состояния
4056,state sequence,تسلسل الدولة,تسلسل الحالة,متابعة الحالة,状态序列,状态序列,状态序列,séquence d'états,séquence d'états,séquence d'états,状態シーケンス,状態シーケンス,ステート系列,последовательность состояний,последовательность состояний,последовательность состояний
4057,state space,مساحة الدولة,- مساحة الحالة,فضاء الحالة,状态空间,状态空间,状态空间,territoire de l'État,espace d'états,espace d'états,状態空間,状態空間,状態空間,государственное пространство,пространство состояний,пространство состояний
4058,state trajectory,مسار الدولة,مسار الحالة,مسار الحالة,状态轨迹,状态轨迹,状态轨迹,trajectoire de l'état,Trajectoire d'état,Trajectoire d'état,状態の軌跡,状態軌跡 (joutai kiseki),状態軌跡,государственная траектория,траектория состояния,траектория состояний
4059,state transition,انتقال الدولة,- تحول الحالة,انتقال الحالة,状态转换,状态转移,状态转移,transition d'état,transition d'état,transition d'état,状態遷移,状態遷移 (じょうたいせんい),状態遷移,переход состояния,переход состояний,переход состояния
4060,state transition function,وظيفة انتقال الدولة,وظيفة انتقال الحالة,دالة انتقال الحالة,状态转换函数,状态转移函数,状态转移函数,fonction de transition d'état,fonction de transition d'état,fonction de transition d'état,状態遷移関数,状態遷移関数,状態遷移関数,функция перехода состояний,функция перехода состояния,функция перехода состояний
4061,state transition matrix,مصفوفة انتقال الدولة,مصفوفة انتقال الحالة,مصفوفة انتقال الحالة,状态转移矩阵,状态转移矩阵,状态转移矩阵,matrice de transition d'état,- Matrice de transition d'état,matrice de transition d'état,状態遷移行列,状態遷移行列,状態遷移行列,матрица перехода состояний,матрица перехода состояний,матрица переходов состояний
4062,state transition model,نموذج انتقال الدولة,نموذج انتقال الحالة,نموذج انتقال الحالة,状态转换模型,状态转移模型,状态转移模型,modèle de transition d'état,- Modèle de transition d'état,modèle de transition d'états,状態遷移モデル,状態遷移モデル (jōtai sen'i moderu),状態遷移モデル,модель перехода состояний,модель перехода состояний,модель переходов состояний
4063,state transition probability,احتمال انتقال الدولة,احتمال انتقال الحالة,احتمالية انتقال الحالة,状态转移概率,状态转移概率,状态转移概率,probabilité de transition d'état,- Probabilité de transition d'état,probabilité de transition d'état,状態遷移確率,状態遷移確率 (jōtai sen'i kakuritsu),状態遷移確率,вероятность перехода состояний,вероятность перехода состояния,вероятность перехода состояния
4064,state value function,وظيفة قيمة الدولة,دالة قيمة الحالة,وظيفة قيمة الحالة,状态值函数,状态值函数,状态值函数,fonction de valeur d'état,fonction de valeur d'état,fonction de valeur d'état,状態値関数,状態価値関数 (joutai kachikana kinou),状態価値関数,функция значения состояния,функция значений состояния,функция ценности состояния
4065,state variable,المتغير الحكومي,متغير الحالة,متغير الحالة,状态变量,状态变量,状态变量,état variable,variable d'état,variable d'état,状態変数,状態変数 (じょうたいへんすう),状態変数,переменная состояния,переменная состояния,переменная состояния
4066,state vector,ناقلات الدولة,متجه الحالة,متجه الحالة,状态向量,状态向量,状态向量,vecteur d'état,vecteur d'état,vecteur d'état,状態ベクトル,状態ベクトル,状態ベクトル,вектор состояния,вектор состояния,вектор состояния
4067,state-action distribution,توزيع إجراءات الدولة,توزيع الحالة-العملية,توزيع الحالة-الإجراء,状态-动作分布,状态-动作分布,状态-动作分布,distribution état-action,- Distribution état-action,distribution état-action,ステートアクションの分布,状態-行動分布,状態行動分布,распределение действий государства,распределение состояний-действий,распределение состояние-действие
4068,state-action space,مساحة عمل الدولة,المجال الحالة-العملية,فضاء الحالة-الإجراء,状态-动作空间,状态-动作空间,状态-动作空间,espace état-action,- Espace état-action,espace état-action,状態行動空間,状態行動空間 (joutai koudou kuukan),状態行動空間,пространство действий государства,пространство состояния-действия,пространство состояний-действий
4069,state-action value,قيمة تصرفات الدولة,قيمة الحالة-الإجراء,قيمة الحالة والعمل,状态-动作值,状态-动作值,状态行为值,valeur état-action,valeur état-action,valeur état-action,状態アクション値,状態-行動価値 (State-action value),状態行動価値,ценность действий государства,значение состояния-действия,ценность состояния-действия
4070,state-action value function,وظيفة قيمة عمل الدولة,دالة قيمة الحالة-الإجراء (State-Action Value Function),دالة قيمة الحالة-العمل,状态-动作值函数,状态动作值函数,状态-动作值函数,fonction de valeur état-action,- Fonction de valeur état-action,fonction de valeur d'état-action (Q),状態行動価値関数,状態行動価値関数 (state-action value function),状態行動価値関数,функция значения состояния-действия,функция ценности состояния-действия,функция ценности состояние-действие
4071,state-of-the-art,مثال رائع من الفن,- الحاليّ المتقدم,أحدث التقنيات,最先进的,最先进的,最先进的,état de l'art,- État de l'art,à la pointe de la technologie,最先端の,最先端,最先端,уровень развития,современное состояние искусства,передовой
4072,state-of-the-art baseline,أحدث خط الأساس,المعيار الأساسي الأحدث,أحدث الأساليب المرجعية العادية,最先进的基线,最先进基准,最先进基准,base de référence à la pointe de la technologie,référence de pointe,ligne de base de pointe,最先端のベースライン,最先端のベースライン,最新のベースライン,современная базовая линия,современный базовый уровень,передовая базовая модель
4073,state-of-the-art method,طريقة حديثة,أفضل الطرق الحديثة,طريقة متطورة,最先进的方法,最先进方法,最先进方法,méthode de pointe,méthode de pointe,méthode de pointe,最先端の手法,最先端の手法,最先端の手法,современный метод,современный метод,передовой метод
4074,state-of-the-art model,نموذج على أحدث طراز,النموذج المتطور,نموذج متقدم,最先进的模型,最先进模型,最先进模型,modèle à la pointe de la technologie,- Modèle de pointe,modèle à la pointe de la technologie,最先端のモデル,最先端モデル,最先端モデル,современная модель,модель нового поколения,передовая модель
4075,state-of-the-art system,نظام على أحدث طراز,نظام حديث الطراز,نظام متطور,最先进的系统,最先進系統,最先进系统,système de pointe,système de pointe,système de pointe,最先端のシステム,最先端システム,最先端システム,современная система,системы новейшего поколения,система передового уровня
4076,static analysis,تحليل ثابت,التحليل الثابت,تحليل ثابت,静态分析,静态分析,静态分析,analyse statique,- Analyse statique,analyse statique,静的解析,静的解析 (せいてきかいせき),静的解析,статический анализ,статический анализ,статический анализ
4077,stationarity,ساكنة,- تثبيتية,ثبات,平稳性,"""在平稳性假设下，对于像素i，NLmeans算法在观察到其邻域后收敛到i的条件期望。 在这种情况下，平稳性条件可以说是随着图像尺寸的增长，我们可以为图像的所有细节找到许多相似的补丁。'未来的工作可能会考虑平稳性的作用",平稳性,stationnarité,stationnarité,stationnarité,定常性,定常性,定常性,стационарность,стационарность,стационарность
4078,stationary distribution,توزيع ثابت,التوزيع الثابت,توزيع ثابت,平稳分布,静态分布,稳态分布,distribution stationnaire,- Distribution stationnaire,distribution stationnaire,定常分布,定常分布,定常分布,стационарное распределение,стационарное распределение,стационарное распределение
4079,stationary kernel,نواة ثابتة,نواة ثابتة,نواة ثابتة,固定核,平稳核,平稳核,noyau stationnaire,noyau stationnaire,noyau stationnaire,固定カーネル,定常カーネル,定常カーネル,стационарное ядро,стационарное ядро,стационарные ядра
4080,stationary policy,سياسة ثابتة,سياسة ثابتة,سياسة ثابتة,固定政策,固定策略,静态策略,politique stationnaire,Politique stationnaire,politique stationnaire,固定政策,定常方策,定常ポリシー,стационарная политика,стационарная стратегия,Стационарная политика
4081,statistical analysis,تحليل احصائي,تحليل إحصائي,تحليل إحصائي,统计分析,统计分析,统计分析,analyses statistiques,- Analyse statistique,analyse statistique,統計分析,統計分析 (Toukei Bunseki),統計解析,статистический анализ,статистический анализ,статистический анализ
4082,statistical independence,الاستقلال الإحصائي,الاستقلال الإحصائي,الاستقلال الإحصائي,统计独立性,统计独立性,统计独立性,indépendance statistique,indépendance statistique,indépendance statistique,統計的独立性,統計的独立性,統計的独立性,статистическая независимость,статистическая независимость,статистическая независимость
4083,statistical learning,التعلم الإحصائي,التعلم الإحصائي,التعلم الإحصائي,统计学习,统计学习,统计学习,apprentissage statistique,apprentissage statistique,apprentissage statistique,統計学習,統計学習,統計的学習,статистическое обучение,статистическое обучение,статистическое обучение
4084,statistical learning algorithm,خوارزمية التعلم الإحصائي,خوارزمية التعلم الإحصائي,خوارزمية التعلم الإحصائي,统计学习算法,统计学习算法,统计学习算法,algorithme d'apprentissage statistique,algorithme d'apprentissage statistique,algorithme d'apprentissage statistique,統計学習アルゴリズム,統計的学習アルゴリズム,統計的学習アルゴリズム,статистический алгоритм обучения,статистический алгоритм обучения,алгоритм статистического обучения
4085,statistical learning theory,نظرية التعلم الإحصائي,نظرية التعلم الإحصائي,نظرية التعلم الإحصائي,统计学习理论,统计学习理论,统计学习理论,théorie de l'apprentissage statistique,- Théorie de l'apprentissage statistique,théorie de l'apprentissage statistique,統計的学習理論,統計学習理論 (とうけいがくしゅうりろん),統計的学習理論,статистическая теория обучения,- Статистическая теория обучения,статистическая теория обучения
4086,statistical machine translation,الترجمة الآلية الإحصائية,ترجمة الآلة الإحصائية,ترجمة آلية إحصائية,统计机器翻译,统计机器翻译,统计机器翻译,traduction automatique statistique,traduction automatique statistique,traduction automatique statistique,統計的機械翻訳,統計的機械翻訳,統計的機械翻訳,статистический машинный перевод,статистический машинный перевод,статистический машинный перевод
4087,statistical machine translation system,نظام الترجمة الآلية الإحصائية,نظام ترجمة آلية إحصائية,نظام الترجمة الآلية الإحصائية,统计机器翻译系统,统计机器翻译系统,统计机器翻译系统,système de traduction automatique statistique,système de traduction automatique statistique,Système de traduction automatique statistique,統計的機械翻訳システム,統計的機械翻訳システム,統計的機械翻訳システム,статистическая система машинного перевода,статистическая система машинного перевода,Статистическая система машинного перевода
4088,statistical measure,قياس إحصائي,- تدابير إحصائية,مقياس إحصائي,统计测量,统计量,统计量,mesure statistique,- Mesure statistique,mesure statistique,統計的尺度,統計的な尺度,統計的尺度,статистическая мера,- Статистический показатель,статистической меры
4089,statistical model,النموذج الإحصائي,النموذج الإحصائي,نموذج إحصائي,统计模型,统计模型,统计模型,modèle statistique,- Modèle statistique,modèle statistique,統計モデル,統計モデル,統計モデル,статистическая модель,статистическая модель,статистическая модель
4090,statistical translation model,نموذج الترجمة الإحصائية,نموذج الترجمة الإحصائي,نموذج الترجمة الإحصائية,统计翻译模型,统计翻译模型,统计翻译模型,modèle de traduction statistique,Modèle de traduction statistique,modèle de traduction statistique,統計的翻訳モデル,統計的翻訳モデル,統計的翻訳モデル,статистическая модель перевода,статистическая модель перевода,Статистическая модель перевода
4091,steep descent,منحدر شديد,الانحدار الشديد,اِنْحِدار حاد,陡峭的下降,陡峭下降,陡峭下降,descente raide,descente raide,descente abrupte,急な下り,急降下,勾配降下,крутой спуск,крутой спуск,крутой спуск
4092,steerable filter,مرشح قابل للتوجيه,مرشح قابل للتوجيه,مرشح قابل للتوجيه,可控滤波器,可定向滤波器 (steerable filter),可控滤波器,filtre orientable,filtre orientable,filtre orientable,操作可能なフィルター,ステアリング可能フィルタ (steerable filter),操縦可能フィルタ,управляемый фильтр,ручной фильтр,Направляемый фильтр
4093,stemmer,ستيمر,"- التقليم
- المنحوتة",مجذر,词干分析器,词干提取器,词干提取器,égrappoir,stemmer,Stemmatiseur,ステマー,ステマー,語幹切り詞,стеммер,стеммер,стеммер
4094,stereo algorithm,خوارزمية ستيريو,خوارزمية ستيريو,خوارزمية تصوير ثلاثي الأبعاد,立体算法,立体算法,立体视觉算法,algorithme stéréo,algorithme stéréo,algorithme stéréo,ステレオアルゴリズム,ステレオアルゴリズム,ステレオアルゴリズム,стерео алгоритм,алгоритм стереозрения,стереоалгоритм
4095,stereo benchmark,معيار ستيريو,معيار الاستريو,مقياس المقارنة الاستريو,立体声基准,立体基准,立体基准测试,référence stéréo,référentiel stéréo,critère d'évaluation stéréo,ステレオベンチマーク,ステレオベンチマーク,ステレオベンチマーク,стерео тест,стерео бенчмарк,стереоизмерительный эталон
4096,stereo disparity,التباين ستيريو,"""في سياق التشوه الاستريو وتدفق الضوء البصري، فإن النمذجة الصريحة للانقطاعات من خلال التقسيم أو صياغات قائمة على الطبقات لها تاريخ طويل وحظيت مؤخرًا باهت",تباعد مجسم,立体视差,立体视差,双目视差,disparité stéréo,disparité stéréoscopique,décalage stéréo,ステレオ視差,ステレオ視差,立体視差,стерео неравенство,стереодиспария,стереоскопическая диспаратность
4097,stereo image,صورة ستيريو,صورة ستيريو,صورة ثلاثية الأبعاد,立体图像,立体影像,立体影像,image stéréo,image stéréo,image stéréo,ステレオ画像,ステレオ画像,ステレオ画像,стереоизображение,стереоизображения,стереоизображение
4098,stereo matching,مطابقة ستيريو,تطابق الصور الاستريو,مُطابَقَة المَجْسَم,立体匹配,立体匹配,立体匹配,correspondance stéréo,appariement stéréo,appariement stéréo,ステレオマッチング,ステレオマッチング,ステレオマッチング,стерео согласование,стереосопоставление,стереосопоставление
4099,stereo pair,زوج ستيريو,زوج ستيريو,زوج مجسم,立体声对,立体对,立体对,paire stéréo,paire stéréo,paire stéréo,ステレオペア,ステレオペア,ステレオペア,стереопара,стереопара,стереопара
4100,stereo reconstruction,إعادة بناء ستيريو,إعادة إنشاء ثلاثية الأبعاد,إعادة بناء المجسم,立体重建,立体重建,立体重建,reconstruction stéréo,reconstruction stéréo,reconstruction stéréoscopique,ステレオ再構成,ステレオ再構築,ステレオ復元,стереореконструкция,стерео реконструкция,стереореконструкция
4101,stereo vision,رؤية ستيريو,رؤية ستيريو,رؤية مجسمة,立体视觉,立体视觉,双目视觉,vision stéréo,- Vision stéréoscopique,vision stéréoscopique,ステレオビジョン,ステレオビジョン,ステレオビジョン,стереозрение,стереозрение,бинокулярное зрение
4102,stochastic algorithm,خوارزمية عشوائية,- المفوض العشوائي,الخوارزمية العشوائية,随机算法,随机算法,随机算法,algorithme stochastique,algorithme stochastique,algorithme stochastique,確率的アルゴリズム,確率的アルゴリズム (kakuritsuteki arugorizumu),確率的アルゴリズム,стохастический алгоритм,стохастический алгоритм,стохастический алгоритм
4103,stochastic approximation,التقريب العشوائي,- التقريب الاحصائي,تقريب عشوائي,随机近似,随机逼近,随机逼近,approximation stochastique,approximation stochastique,approximation stochastique,確率的近似,確率的近似法,ストカスティック近似,стохастическая аппроксимация,стохастическое приближение,стохастическое приближение
4104,stochastic depth,عمق عشوائي,العمق الاحتمالي,عمق عشوائي,随机深度,随机深度,随机深度,profondeur stochastique,profondeur stochastique,profondeur stochastique,確率的深さ,確率的深さ,確率的深さ,стохастическая глубина,стохастическая глубина,случайная глубина
4105,stochastic differential equation,المعادلة التفاضلية العشوائية,معادلة تفاضلية عشوائية,معادلة تفاضلية عشوائية,随机微分方程,随机微分方程,随机微分方程,équation différentielle stochastique,Équation différentielle stochastique,équation différentielle stochastique,確率微分方程式,確率微分方程式 (stochastic differential equation),確率微分方程式,стохастическое дифференциальное уравнение,Стохастическое дифференциальное уравнение,стохастическое дифференциальное уравнение
4106,stochastic dynamic,ديناميكية عشوائية,ديناميكيات عشوائية,حركية عشوائية,随机动态,随机动力学,随机动力学,dynamique stochastique,dynamique stochastique,dynamique stochastique,確率的ダイナミック,確率的動的,確率ダイナミクス,стохастическая динамика,стохастическая динамика,стохастическая динамика
4107,stochastic environment,البيئة العشوائية,البيئة العشوائية,بيئة عشوائية,随机环境,随机环境,随机环境,environnement stochastique,- Environnement stochastique,environnement stochastique,確率的環境,確率環境 (Kakuritsu Kankyou),確率的環境,стохастическая среда,- Стохастическая среда,стохастическая среда
4108,stochastic game,لعبة عشوائية,لعبة احتمالية,لعبة عشوائية,随机博弈,随机博弈 (stochastic game),随机博弈,jeu stochastique,jeu stochastique,jeu stochastique,確率的ゲーム,確率ゲーム,確率ゲーム,стохастическая игра,стохастическая игра,Стохастическая игра
4109,stochastic gradient,التدرج العشوائي,- تدفق متقطع,تدرج عشوائي,随机梯度,随机梯度,随机梯度,gradient stochastique,gradient stochastique,gradient stochastique,確率的勾配,確率勾配,確率的勾配,стохастический градиент,стохастический градиент,стохастический градиент
4110,stochastic gradient algorithm,خوارزمية التدرج العشوائي,- تحليل تدرج متغير,ﺧﻮﺍﺮﺰﻤﻴﺔ ﺍﻟﺘﺪﺮﺝ ﺍﻟﻌﺸﻮﺍﺋﻲ,随机梯度算法,随机梯度算法,随机梯度算法,algorithme de gradient stochastique,algorithme de gradient stochastique,algorithme de gradient stochastique,確率的勾配アルゴリズム,確率的勾配アルゴリズム,ストカスティックグラディエントアルゴリズム,алгоритм стохастического градиента,стохастический градиентный алгоритм,стохастический градиентный алгоритм
4111,stochastic gradient ascent,صعود التدرج العشوائي,الصعود التدريجي العشوائي,تصاعد المتدرج العشوائي,随机梯度上升,随机梯度上升,随机梯度上升法,ascension du gradient stochastique,ascension du gradient stochastique,ascension de gradient stochastique,確率的勾配上昇,確率的勾配上昇 (stochastic gradient ascent),確率的勾配上昇法,стохастический градиентный подъем,стохастический градиентный подъем,наращивание стохастического градиента
4112,stochastic gradient descent,نزول التدرج العشوائي,الانحدار التدريجي العشوائي,الانحدار التدريجي العشوائي (stochastic gradient descent),随机梯度下降,随机梯度下降 (SGD),随机梯度下降,descente de gradient stochastique,descente de gradient stochastique,descente de gradient stochastique,確率的勾配降下法,確率的勾配降下法,確率的勾配降下法,стохастический градиентный спуск,Стохастический градиентный спуск,стохастический градиентный спуск
4113,stochastic gradient method,طريقة التدرج العشوائي,الأسلوب التدرجي العشوائي,طريقة التدرج العشوائي,随机梯度法,随机梯度方法,随机梯度方法,méthode du gradient stochastique,- Méthode du gradient stochastique,méthode de gradient stochastique,確率的勾配法,確率勾配法,ストカスティック勾配法,метод стохастического градиента,стохастический метод градиентного спуска,метод стохастического градиента
4114,stochastic grammar,القواعد العشوائية,قواعد اللغة العشوائية,قواعد احتمالية,随机语法,随机语法,随机语法,grammaire stochastique,grammaire stochastique,grammaire stochastique,確率文法,確率文法 (kakuritsu bunpou),確率文法,стохастическая грамматика,стохастическая грамматика,стохастическая грамматика
4115,stochastic matrix,مصفوفة عشوائية,- المصفوفة الاحتمالية,مصفوفة عشوائية,随机矩阵,随机矩阵,随机矩阵,matrice stochastique,matrice stochastique,matrice stochastique,確率行列,確率行列 (kakuritsu gyouretsu),確率行列,стохастическая матрица,стохастическая матрица,стохастическая матрица
4116,stochastic model,النموذج العشوائي,النموذج الاحصائي,نموذج عشوائي,随机模型,随机模型,随机模型,modèle stochastique,- Modèle stochastique,modèle stochastique,確率モデル,確率モデル (kakuritsu moderu),確率モデル,стохастическая модель,стохастическая модель,стохастическая модель
4117,stochastic objective,الهدف العشوائي,الهدف العشوائي,هدف عشوائي,随机目标,随机目标 (stochastic objective),随机目标函数,objectif stochastique,objectif stochastique,objectif stochastique,確率的目標,"""['確率的な目的を最小化する問題を考えてみましょう、min θ F (θ) = min θ E w f (θ, w)。強化学習（RL）の多くのアルゴリズムの中心には、勾配 ∇F のゼロ次の推定があります（Sutton et al., 2000; Schulman et al., 2017）。'、'",確率的目的関数,стохастическая цель,стохастическая цель,стохастическая цель
4118,stochastic optimization,التحسين العشوائي,التحسين العشوائي,تحسين عشوائي,随机优化,随机优化,随机优化,optimisation stochastique,optimisation stochastique,optimisation stochastique,確率的最適化,確率的最適化,確率的最適化,стохастическая оптимизация,стохастическая оптимизация,стохастическая оптимизация
4119,stochastic policy,السياسة العشوائية,- التصرف العشوائي,سياسة عشوائية,随机政策,随机策略,随机策略,politique stochastique,politique stochastique,politique stochastique,確率的政策,確率的方策,確率的ポリシー,стохастическая политика,стохастическая стратегия,стохастическая политика
4120,stochastic process,عملية العشوائية,عملية تكهنية,عملية عشوائية,随机过程,随机过程,随机过程,processus stochastique,processus stochastique,processus stochastique,確率過程,確率プロセス,確率過程,случайный процесс,стохастический процесс,стохастический процесс
4121,stochastic sampling,أخذ العينات العشوائية,العينات العشوائية,العينات العشوائية,随机抽样,随机采样,随机采样,échantillonnage stochastique,échantillonnage stochastique,échantillonnage stochastique,確率的サンプリング,確率的サンプリング,確率的サンプリング,стохастическая выборка,стохастическая выборка,стохастическое сэмплирование
4122,stochastic search algorithm,خوارزمية البحث العشوائية,خوارزمية البحث الاحتمالية,خوارزمية البحث العشوائية,随机搜索算法,随机搜索算法,随机搜索算法,algorithme de recherche stochastique,algorithme de recherche stochastique,algorithme de recherche stochastique,確率的検索アルゴリズム,確率的探索アルゴリズム (kakuritsuteki tansaku arugorizumu),確率的探索アルゴリズム,алгоритм стохастического поиска,Cтохастический алгоритм поиска,стохастический поисковый алгоритм
4123,stochastic subgradient descent,النسب التدرجي العشوائي,"""هذا الهدف مقعد وغير قابل للتفاضل بسبب الحد الأقصى بداخل t. نحن نحسن استخدام الانحدار الفرعي المتعشى (Shalev-Shwartz et al.، 2007). الانحدار الفر",هبوط التدرج العشوائي الجزئي,随机次梯度下降,随机次梯度下降,随机次梯度下降,descente stochastique du sous-gradient,Descente de sous-gradient stochastique,descente de sous-gradient stochastique,確率的勾配降下法,確率勾配降下法,確率的部分勾配降下法,стохастический субградиентный спуск,стохастический метод субградиента,метод стохастического субградиентного спуска
4124,stochastic transition matrix,مصفوفة الانتقال العشوائية,مصفوفة الانتقال الاحتمالية العشوائية,مصفوفة انتقال عشوائية,随机转移矩阵,随机转移矩阵,随机转移矩阵,matrice de transition stochastique,- Matrice de transition stochastique,matrice de transition stochastique,確率的遷移行列,確率遷移行列,確率的遷移行列,стохастическая матрица перехода,- Стохастическая матрица переходов,матрица вероятностных переходов
4125,stochastic variational inference,الاستدلال التبايني العشوائي,التقدير التقاربي الاحتمالي العشوائي,الاستدلال التباينيّ العشوائيّ,随机变分推理,随机变分推断,随机变分推断,inférence variationnelle stochastique,inférence variationnelle stochastique,Inférence variationnelle stochastique,確率的変分推論,確率変分推論 (Stochastic variational inference),確率的変分推論,стохастический вариационный вывод,стохастическое вариационное выводление,стохастическое вариационное вычисление
4126,stochasticity,العشوائية,العشوائية,عشوائية,随机性,随机性,随机性,stochasticité,stochasticité,stochasticité,確率性,確率性,確率性,стохастичность,стохастичность,стохастичность
4127,stop word,كلمة توقف,- توقف الكلمة,كلمة توقف,停用词,停用词,停用词,mot vide,mot vide,Mot vide,ストップワード,ストップワード,停止語,стоп-слово,стоп-слово,остановочное слово
4128,stop-gradient,توقف التدرج,- توقف التدرج,توقف تدرج,停止梯度,停梯度 (stop-gradient),停止梯度传播,arrêt du dégradé,stop-gradient,stop-gradient,停止勾配,ストップ勾配,勾配停止,стоп-градиент,stop-gradient,остановка градиента
4129,stop-gradient operation,عملية توقف التدرج,عملية توقيف التدرج,عملية إيقاف التدرج,停止梯度操作,停梯度操作,停止梯度操作,fonctionnement à gradient d'arrêt,opération d'arrêt du gradient,opération de stop-gradient,停止勾配操作,勾配停止操作,勾配停止操作 (こうばいていしそうさ),стоп-градиентная операция,операция остановки градиента,операция остановки градиента
4130,stopping condition,حالة التوقف,شرط التوقف,شرط التوقف,停止条件,停止条件,终止条件,condition d'arrêt,condition d'arrêt,condition d'arrêt,停止条件,停止条件,停止条件,условие остановки,условие остановки,условие остановки
4131,stopping criterion,معيار التوقف,معيار الإيقاف,معيار التوقف,停止标准,停止准则,停止准则,critère d'arrêt,critère d'arrêt,critère d'arrêt,停止基準,停止基準,停止基準,критерий остановки,критерий остановки,критерий остановки
4132,story cloze test,اختبار إغلاق القصة,اختبار قصة الإغلاق,اختبار إغلاق القصة,故事完形填空测试,故事闭合测试,故事完形测试,test de clôture de l'histoire,test de cloze d'histoire,test de clôture d'histoire,ストーリークローズテスト,ストーリークローズテスト,ストーリー空所補充テスト,тест на закрытие истории,тест на закрытие истории,тест завершения истории
4133,stratified sampling,اخذ العينات الطبقية,العينة التصنيفية,توزيع طبقي,分层抽样,分层抽样,分层抽样,échantillonnage stratifié,- Échantillonnage stratifié,échantillonnage stratifié,層化抽出法,層別抽出,層化サンプリング,стратифицированная выборка,стратифицированная выборка,выборка по стратам
4134,streaming algorithm,خوارزمية التدفق,- تسلسل الخوارزمية,خوارزمية البث,流式算法,流式算法,数据流算法,algorithme de diffusion en continu,algorithme de streaming,algorithme en flux,ストリーミングアルゴリズム,ストリーミングアルゴリズム (sutorimingu arugorizumu),ストリーミングアルゴリズム,алгоритм потоковой передачи,потоковый алгоритм,потоковый алгоритм
4135,streaming datum,مسند التدفق,البيانات المتدفقة,البيانات المتدفقة,流数据,流式数据,流数据,données de diffusion en continu,donnée en continu,données en flux,ストリーミングデータ,ストリーミングデータ,ストリーミングデータ,потоковые данные,поточные данные,потоковые данные
4136,streaming model,نموذج التدفق,النموذج التدفقي,نموذج البث,流式传输模型,流式模型,流模型,modèle de diffusion en continu,- Modèle de streaming,modèle de flux,ストリーミングモデル,ストリーミングモデル,ストリーミングモデル,потоковая модель,потоковая модель,потоковая модель
4137,stride,خطوة,"""نقوم ببناء هرم ذو 4 طبقات {C 1 ، C 2 ، C 3 ، C 4} عن طريق تجميع البُعدَين الأخيرين من حجم الترابط باستخدام أحجام أنوية 1 و 2 و 4 و 8 وخطوة مكافئة (الشكل",خطوة,跨步,步幅,步长,foulée,"Nous construisons une pyramide à 4 couches {C 1 , C 2 , C 3 , C 4 } en regroupant les deux dernières dimensions du volume de corrélation avec des tailles de noyau de 1, 2, 4 et 8 et une stride équivalente (Figure 2). Ainsi, le volume C k a des dimensions \n', 'Tout d'abord, parce que nous attendons des sorties secondaires",pas,ストライド,ストライド,ストライド,шагать,шаг,шаг
4138,string kernel metric,متري نواة السلسلة,مقياس نواة سلسلة,مقياس نواة السلسلة,字符串核度量,字符串核度量,字符串核度量,métrique du noyau de chaîne,métrique du noyau de chaîne,noyau de chaînes de caractères,文字列カーネルメトリック,文字列カーネルメトリック,文字列カーネル尺度,метрика ядра строки,метрика строкового ядра,Метрика ядра строк
4139,structural learning,التعلم الهيكلي,التعلم الهيكلي,التعلم البنيوي,结构性学习,结构学习,结构学习,apprentissage structurel,apprentissage structurel,apprentissage structurel,構造学習,構造学習 (こうぞうがくしゅう),構造学習,структурное обучение,структурное обучение,структурное обучение
4140,structural risk minimization,التقليل من المخاطر الهيكلية,تقليل المخاطر الهيكلية,تقليل المخاطر الهيكلية,结构性风险最小化,结构风险最小化,结构风险最小化,minimisation des risques structurels,minimisation du risque structurel,minimisation du risque structurel,構造的リスクの最小化,構造リスク最小化,構造リスク最小化,минимизация структурных рисков,структурная минимизация риска,минимизация структурного риска
4141,structure from motion,هيكل من الحركة,الهيكل من الحركة,البنية من الحركة,运动结构,运动结构,运动重建结构,structure à partir du mouvement,structure à partir du mouvement,structure par mouvement,動きから見る構造,動きからの構造,動きからの構造復元,структура из движения,структура из движения,Структура по движению
4142,structure learning,التعلم الهيكلي,تعلم الهيكلية,تعلم البنية,结构学习,结构学习,结构学习,apprentissage des structures,apprentissage de la structure,apprentissage de structure,構造学習,構造学習 (こうぞうがくしゅう),構造学習,структурное обучение,обучение структуре,структурное обучение
4143,structured datum,مسند منظم,بيانات منظمة,بيانات منظمة,结构化数据,结构化数据,结构化数据,donnée structurée,donnée structurée,donnée structurée,構造化データ,構造化されたデータ,構造化されたデータ,структурированные данные,структурированные данные,структурированные данные
4144,structured output,الإخراج منظم,الناتج المنظم,مُخرَج مُهيكَل,结构化输出,结构化输出,结构化输出,sortie structurée,sortie structurée,sortie structurée,構造化された出力,構造化された出力,構造化された出力,структурированный вывод,структурированный вывод,структурированный вывод
4145,structured perceptron,الإدراك الحسي المنظم,المقترن المنظم,المتسلسل المنظم,结构化感知器,结构感知器,结构感知器,perceptron structuré,perceptron structuré,perceptron structuré,構造化パーセプトロン,構造化パーセプトロン,構造化パーセプトロン,структурированный персептрон,структурированный персептрон,структурированный перцептрон
4146,structured prediction,التنبؤ المنظم,التنبؤ المنظم,التنبؤ المنظم,结构化预测,结构化预测,结构化预测,prédiction structurée,prédiction structurée,prédiction structurée,構造化された予測,構造化予測,構造予測,структурированное предсказание,структурированное предсказание,структурированное предсказание
4147,structured prediction model,نموذج التنبؤ المنظم,نموذج التنبؤ المهيكل,نموذج التنبؤ المهيكل,结构化预测模型,结构化预测模型,结构化预测模型,modèle de prédiction structuré,modèle de prédiction structurée,modèle de prédiction structurée,構造化予測モデル,構造化予測モデル (Kouzouka Yokoku Moderu),構造予測モデル,модель структурированного прогнозирования,структурированная модель предсказаний,модель структурного прогнозирования
4148,structured prediction problem,مشكلة التنبؤ المنظم,مشكلة التنبؤ المهيكل,مشكلة التنبؤ المنظم,结构化预测问题,结构化预测问题,结构化预测问题,problème de prédiction structuré,problème de prédiction structurée,problème de prédiction structurée,構造化された予測問題,構造化予測問題,構造的予測問題,проблема структурированного прогнозирования,проблема структурированного прогнозирования,структурная задача предсказания
4149,structured support vector machine,آلة ناقلات الدعم المنظم,آلة الدعم بنمط مهيكلة,آلة دعم متجه منظمة,结构化支持向量机,结构化支持向量机,结构化支持向量机,machine à vecteurs de support structuré,machine à vecteurs de support structurée,machine à vecteurs de support structurée,構造化サポートベクターマシン,構造化サポートベクターマシン,構造化サポートベクターマシン,машина структурированных опорных векторов,структурированная машина опорных векторов,Машина опорных векторов со структурированным выходом
4150,student model,نموذج الطالب,- تعميم الطالب,نموذج طالب,学生模型,学生模型,学生模型,modèle étudiant,modèle d'élève,modèle étudiant,学生モデル,生徒モデル,生徒モデル,студенческая модель,модель студента,ученическая модель
4151,style transfer,نقل النمط,نقل الأسلوب,نقل الأسلوب,风格转移,风格转移,风格迁移,transfert de style,transfert de style,transfert de style,スタイル転送,スタイル転送 (sutairu tensei),スタイル転写,перенос стиля,передача стиля,перенос стиля
4152,sub-gradient,التدرج الفرعي,الشعاع الفرعي,تدرج جزئي,次梯度,子梯度,次梯度,sous-dégradé,sous-gradient,sous-gradient,サブ勾配,サブグラディエント,部分勾配,субградиент,субградиент,под-градиент
4153,sub-gradient descent,هبوط التدرج الفرعي,الانحدار الفرعي,هبوط تحت المتجه,次梯度下降,亚梯度下降 (Sub-gradient Descent),次梯度下降法,descente en sous-pente,descente de sous-gradient,descente par sous-gradient,準勾配降下法,"""['この論文では、Eq. (1) を解決するために、単純な確率的サブ勾配降下アルゴリズムであるペガソスと呼ばれるものを説明し、分析します。各反復で、ランダムに1つのトレーニング例が選択され、目的のサ",部分勾配降下法,субградиентный спуск,подградиентный спуск,спуск по субградиенту
4154,sub-networks,الشبكات الفرعية,الشبكات الفرعية,شبكات فرعية,子网络,子网络,子网络,sous-réseaux,sous-réseaux,sous-réseaux,サブネットワーク,サブネットワーク,サブネットワーク,подсети,подсети,подсети
4155,sub-population,مجموعة فرعية,- تحت-مجتمعات,فرعية-السكان,亚群,子群体,子群体,sous-population,sous-population,sous-population,部分母集団,サブ集団,サブ集団,подгруппа населения,под-популяция,Подпопуляция
4156,sub-word,كلمة فرعية,- تحليل جزئي,كلمة مجزأة,子词,亚词,子词,sous-mot,sous-mot,sous-mot,サブワード,サブワード,部分語,подслово,подслово,подслов
4157,sub-word tokenization,ترميز الكلمات الفرعية,تفكيك الكلمات الفرعية,تقطيع الكلمات الفرعية,子词标记化,子词记号化,子词分词,tokenisation de sous-mots,tokenisation de sous-mots,tokenisation sous-lexicale,サブワードのトークン化,サブワードトークン化,部分語トークン化,токенизация подслов,субсловная токенизация,сегментация по подсловам
4158,subgame,لعبة فرعية,- تحت لعبة,لعبة فرعية,子游戏,子博弈,子博弈,sous-jeu,sous-jeu,sous-jeu,サブゲーム,サブゲーム,部分ゲーム,подигра,подигра,подигра
4159,subgradient method,طريقة فرعية,الطريقة الفرعية للمد الصادفية,طريقة التدرج الجزئي,次梯度法,次梯度法,次梯度法,méthode du sous-gradient,- Méthode de sous-gradient,méthode du sous-gradient,勾配法,サブグラディエント法 (subgradient method),下降勾配法,субградиентный метод,метод субградиента,метод субградиента
4160,subgraph isomorphism,تماثل الرسم البياني الفرعي,تطابق الرسم البياني الفرعي,تماثل التفرع الفرعي,子图同构,子图同构,子图同构,isomorphisme de sous-graphe,isomorphisme de sous-graphe,isomorphisme de sous-graphe,部分グラフ同型性,サブグラフ同型化,部分グラフ同型,изоморфизм подграфов,изоморфизм подграфа,изоморфизм подграфа
4161,subgraph selection,اختيار الرسم البياني الفرعي,- التحديد الفرعي للرسم البياني,اختيار الفرعي,子图选择,子图选择,子图选择,sélection de sous-graphe,sélection de sous-graphes,sélection de sous-graphe,部分グラフの選択,サブグラフ選択,サブグラフ選択,выбор подграфа,выбор подграфа,подграф выбор
4162,submatrice,مصفوفة فرعية,مصفوفة جزئية,مصفوفة فرعية,子矩阵,子矩阵,子矩阵,sous-matrice,sous-matrice,sous-matrice,部分行列,サブ行列 (subu gyouretsu),部分行列,подматрица,Подматрица,подматрица
4163,submatrix,مصفوفة فرعية,مصفوفة فرعية,مصفوفة فرعية,子矩阵,子矩阵,子矩阵,sous-matrice,sous-matrice,sous-matrice,部分行列,サブ行列,部分行列,подматрица,подматрица,подматрица
4164,submodular,وحدات فرعية,تحت النموذجية,تابع فرعي,子模块,子模函数,次调和的,sous-modulaire,sous-modulaire,sous-modulaire,サブモジュール式,サブモジュラー,部分加法的,субмодульный,субмодулярный,субмодулярный
4165,submodular function,وظيفة تحت وحدات,دالة فرعية قابلة للتعديل,دالة تحت متجمعة,子模函数,子模函数,次调函数,fonction sous-modulaire,fonction sous-modulaire,fonction sous-modulaire,サブモジュール関数,サブモジュラー関数,部分加法関数,субмодульная функция,субмодулярная функция,субмодулярная функция
4166,submodular function optimization,تحسين وظيفة submodular,"- تحسين وظيفة الوظيفة الفرعية
- تحسين وظيفة الوظيفة الفرعية",تحسين دالة دون مودولية,子模函数优化,子模函数优化,次模函数优化,optimisation des fonctions sous-modulaires,Optimisation de fonction sous-modulaire,optimisation de fonctions sousmodulaires,部分モジュラー関数の最適化,部分モジュール関数最適化 (ぶぶんモジュール かんすう さいてきか),部分加法関数最適化,оптимизация субмодульной функции,оптимизация подмодульной функции,оптимизация субмодулярных функций
4167,submodular influence function,وظيفة التأثير تحت المعيارية,وظيفة التأثير الجزئي النمائية,دالة التأثير دون المُجمَّع,子模影响函数,子模影响函数,次模型影响函数,fonction d'influence sous-modulaire,fonction d'influence submodulaire,fonction d'influence sous-modulaire,サブモジュール影響関数,サブモジュラー影響関数,部分加法的な影響関数,субмодульная функция влияния,субмодулярная функция влияния,субмодулярная функция влияния
4168,submodular optimization,التحسين دون المعياري,أمثلة على الخوارزميات الفرعية التحسينية,تحسين تحت المجموعي,子模块优化,子模优化,子模最优化,optimisation sous-modulaire,optimisation sous-modulaire,optimisation sous-modulaire,サブモジュール最適化,サブモジュラー最適化,部分加法的最適化,субмодульная оптимизация,оптимизация субмодулярных функций,оптимизация субмодулярная
4169,submodular polyhedron,متعدد السطوح تحت الوحدات,"""إذا تمثلت المشكلة في تحسين على مستوى الفرعية ، فيمكن تعبيرها ثم عن طريق تحسين على متعدد الأضلاع الفرعي (الذي يعتبر فرعيًا في مجموعة ف",شكل متعدد الشرائح متناسب جزئياً,次模多面体,子模多面体,次调和多面体,polyèdre submodulaire,polyèdre sous-modulaire,polyèdre submodulaire,サブモジュール多面体,サブモジュラーポリエドロン,準モジュラー多面体,субмодульный многогранник,подмодулярный многогранник,Субмодулярный многогранник
4170,submodular set function,وظيفة مجموعة فرعية,دالة مجموعة فرعية قابلة للتعويض,دالة تجميع جزئية,子模集函数,子模集函数,次模集合函数,fonction d'ensemble sous-modulaire,fonction de sous-ensembles submodulaire,fonction d'ensemble sousmodulaire,サブモジュラー集合関数,部分モジュラー集合関数 (ぶぶんもじゅらーしゅうごうかんすう),部分加法集合関数,субмодульная функция множества,субмодулярная функция множества,субмодулярная функция множеств
4171,submodularity,نمطية فرعية,الإنحدار الفرعي,تناذرية الجزئية,子模块性,子模性,次调性,sous-modularité,sous-modularité,sous-modularité,サブモジュール性,部分可処理性,部分加法性,субмодульность,субмодулярность,субмодулярность
4172,subnetwork,شبكة فرعية,- تحت شبكة,شبكة فرعية,子网,子网络,子网络,sous-réseau,sous-réseau,sous-réseau,サブネットワーク,サブネットワーク,サブネットワーク,подсеть,подсеть,подсеть
4173,suboptimal,دون المستوى الأمثل,غير مثلى,نظير الأمثل,次优的,次优,次优的,sous-optimal,sous-optimal,sous-optimal,最適ではない,サブオプティマル,非最適な,неоптимальный,неоптимальный,неоптимальный
4174,subpixel,بكسل فرعي,تحديد النقطة الفرعية,جزء من البكسل,子像素,子像素,亚像素,sous-pixel,"""['Le graphique montre que non seulement le deuxième ordre prioritaire fonctionne mieux à tous les seuils d'erreur, mais aussi que sa performance s'améliore plus que le premier ordre prioritaire aux seuils de haute précision, par rapport aux autres algorithmes, ce qui indique une amélioration de la précision subpixel. Cette performance de Middlebury.', 'L'alignement direct optimise les différences d'intensité des pixels en définissant implicitement les correspondances à travers le mouvement et la gé",sous-pixel,サブピクセル,サブピクセル,サブピクセル,субпиксель,"""['График показывает, что второй приоритет высшего порядка не только работает лучше на всех порогах ошибок, но также его производительность улучшается сильнее, чем у приоритета первого порядка при высоких порогах точности по сравнению с другими алгоритмами, что указывает на улучшенную",подпиксельная точность
4175,subsample,عينة فرعية,عينة فرعية,عينة فرعية,子样本,子样本,子样本,sous-échantillon,sous-échantillon,sous-échantillon,サブサンプル,サブサンプル,サブサンプリング,подвыборка,подвыборка,подвыборка
4176,subsampling factor,عامل المعاينة,عامل تحتالعينية,عامل أخذ العينات الفرعية,二次采样因子,子采样因子,下采样因子,facteur de sous-échantillonnage,- Facteur de sous-échantillonnage,facteur de sous-échantillonnage,サブサンプリング係数,サブサンプリングファクター (subsampling factor),サブサンプリング係数,коэффициент субдискретизации,коэффициент субдискретизации,Фактор дискретизации
4177,subspace learning,تعلم الفضاء الجزئي,تعلم الفضاء الفرعي,تعلم الفضاء الفرعي,子空间学习,子空间学习,子空间学习,apprentissage du sous-espace,apprentissage de sous-espaces,Apprentissage de sous-espace,亜空間学習,サブスペース学習 (subsapce learning),部分空間学習,обучение подпространству,обучение подпространства,поднаучение
4178,subspace method,طريقة الفضاء الجزئي,طريقة الفضاء الفرعي,طريقة الفراغ الجزئي,子空间法,子空间方法,子空间方法,méthode du sous-espace,- Méthode des sous-espaces,méthode de sous-espace,部分空間法,サブスペース法,部分空間法,метод подпространства,метод подпространства,метод подпространства
4179,subspace projection,الإسقاط الفضاء الجزئي,إسقاط الفراغ الفرعي,تقليص الفراغ الفرعي,子空间投影,子空间投影,子空间投影,projection sous-spatiale,projection de sous-espace,projection dans un sous-espace,部分空間投影,部分空間射影,部分空間射影,проекция подпространства,проекция подпространства,проекция на подпространство
4180,substitution,الاستبدال,الاستبدال,تَبْدِيل,代换,替换,替换,substitution,substitution,substitution,置換,置換,置換,замена,замещение,замена
4181,subsumption,الدمج,- التضمين,تحت الرعاية,包容,包含,概括,subsomption,"//www.w3.org/2004/OWL/ entre elles.', 'Nous introduisons les graphes de Hiérarchie et d'Exclusion (HEX), un nouveau formalisme qui capture les relations sémantiques entre deux étiquettes appliquées",subsomption,包摂,包含,包含関係,подчинение,включение,подчинение
4182,subsumption relation,علاقة الغمر,العلاقة التبعية,علاقة التحتية,包含关系,子类包含关系,包含关系,relation de subsomption,- Relation de subordination,relation de subsomption,包摂関係,包含関係 (Hōgai kankei),包含関係,отношение подчинения,отношение включения,отношение субсумпции
4183,subtree,شجرة فرعية,- تحت شجرة,شجرة فرعية,子树,子树,子树,sous-arbre,sous-arbre,sous-arbre,サブツリー,サブツリー,部分木,поддерево,поддерево,подграф
4184,subwindow,نافذة فرعية,نافذة فرعية,مربع فرعي,子窗口,子窗口,子窗口,sous-fenêtre,sous-fenêtre,fenêtre secondaire,サブウィンドウ,サブウィンドウ,サブウィンドウ,подокно,- Подоконник,подокно
4185,subword token,رمز الكلمة الفرعية,- توكنات فرعية,رموز الكلمات الفرعية,子词标记,子词标记,子词标记,jeton de sous-mot,jeton de sous-mot,jeton sous-mot,サブワードトークン,サブワードトークン,部分単語トークン,токен подслова,субтокен подслова,токен-подслов
4186,subword unit,وحدة الكلمات الفرعية,وحدة الكلمات الفرعية,وحدة الكلمة الجزئية,子字单元,子词单元,子词单元,unité de sous-mot,unité de sous-mot,unité de sous-mots,サブワードユニット,サブワードユニット,サブワード単位,единица подслова,подсловные единицы,подслово
4187,successor function,وظيفة لاحقة,دالة الخلفية,وظيفة الخلف,后继函数,后继函数,后继函数,fonction successeur,fonction successeur,fonction successeur,後継関数,後続関数,後継関数,функция-преемник,Функция-преемник,преемственная функция
4188,successor state,الدولة الخلف,الدولة الخلفية,الحالة الخلف,后继国,继承状态,后继状态,État successeur,État successeur,état successeur,後継国家,後継状態,後続状態,государство-преемник,последующее состояние,следующее состояние
4189,successor state axiom,بديهية الدولة الخلف,مبدأ حالة الخلفاء,مسلمة حالة الخلف,后继状态公理,继承状态公理 (successor state axiom),后继状态公理,axiome de l’État successeur,axiome de l'état successeur,axiome d'état successeur,後継国家の公理,後続状態公理 (successor state axiom),後継状態公理,аксиома государства-преемника,аксиома преемника состояния,аксиома преемственности состояния
4190,sufficient statistic,إحصائية كافية,الإحصائيّة الكافية,إحصائية كافية,充分的统计,充分统计量,充分统计量,statistique suffisante,statistique suffisante,statistique suffisante,十分な統計,十分統計量,十分統計量,достаточная статистика,достаточная статистика,достаточная статистика
4191,suffix tree,شجرة لاحقة,شجرة اللاحقات,شجرة اللاحقات,后缀树,后缀树,后缀树,arbre de suffixes,arbre de suffixes,arbre des suffixes,サフィックスツリー,サフィックスツリー,接尾辞木,суффиксное дерево,суффиксное дерево,суффиксное дерево
4192,summarization,تلخيص,- تلخيص,تلخيص,总结,摘要生成,摘要,récapitulation,résumé,résumé,要約,要約化,要約,обобщение,суммаризация,реферирование
4193,summarization algorithm,خوارزمية التلخيص,خوارزمية تلخيص,خوارزمية التلخيص,总结算法,摘要算法,摘要算法,algorithme de résumé,- Algorithme de résumé,algorithme de résumé,要約アルゴリズム,要約アルゴリズム (summarization algorithm),要約アルゴリズム,алгоритм суммирования,алгоритм суммаризации,алгоритм суммаризации
4194,summarization model,نموذج التلخيص,نموذج تلخيص,نموذج التلخيص,概括模型,总结模型,摘要模型,modèle de synthèse,- Modèle de résumé,modèle de résumé,要約モデル,要約モデル,要約モデル,модель обобщения,модель суммаризации,модель обобщения
4195,summarization system,نظام التلخيص,نظام تلخيص,نظام التلخيص,总结系统,摘要系统,摘要系统,système de synthèse,système de résumé,système de résumé,要約システム,要約システム,要約システム,система обобщения,система резюмирования,система суммаризации
4196,super-pixel,سوبر بكسل,سوبر بيكسل,البكسل الفائق,超像素,超像素,超像素,super-pixel,super-pixel,super-pixel,スーパーピクセル,スーパーピクセル,スーパーピクセル,суперпиксель,супер-пиксель,сверхпиксель
4197,super-resolution,فائقة الدقة,الدقة الفائقة,محاكاة واقعية فائقة الدقة,超分辨率,超分辨率,超分辨率,super-résolution,super-résolution,super-résolution,超解像度,超解像度,超解像度,супер-разрешение,супер-разрешение,сверхразрешение
4198,supergradient,التدرج الفائق,الفائق السراحي,سوبرجراديان,超梯度,超梯度,超梯度,supergradient,supergradient,supergradient,超勾配,スーパーグラディエント (su-pa-guradiento),超勾配,суперградиент,суперградиент,сверхградиент
4199,supertag,supertag,"""['تظهر جداول النتائج التحليلية على مجموعة الاختبار. تتيح لنا الميزات العالمية تحسين نموذج ترميز فائق بمقدار 0.6 في F1. نستخدم الميزات العالمية، ولكن الفك تشفيرنا",سوبرتاج,超级标签,超标签,超级标签,super-étiquette,supertag,superétiquette,スーパータグ,スーパータグ,スーパータグ,супертег,"""['В таблице 2 показаны результаты синтаксического анализа на тестовом наборе данных. Наши глобальные функции позволяют нам улучшить модель супертегов на 0,6 F1. Мы используем глобальные функции, однако наш оптимальный декодинг приводит к улучшению на 0,",супертег
4200,supervise classification,التصنيف الخاضع للإشراف,التصنيف المشرف,تصنيف موجه,监督分类,监督分类,监督分类,classement supervisé,Classification supervisée,classification supervisée,教師付き分類,監視分類,監視分類,контролируемая классификация,надзорная классификация,наблюдаемая классификация
4201,supervise classification model,الإشراف على نموذج التصنيف,نموذج تصنيف مشرف,نموذج التصنيف الإشرافي,监督分类模型,监督分类模型,监督分类模型,superviser le modèle de classification,modèle de classification supervisée,modèle de classification supervisée,分類モデルを監視する,監督分類モデル (Kansoku Buncyuu Moderu),教師あり分類モデル,контролировать модель классификации,модель с учителем классификации,модель контролируемой классификации
4202,supervise classifier,الإشراف على المصنف,مصنف مراقب,مُصنِّف مُراقَب,监督分类器,监督分类器,有监督分类器,superviser le classificateur,classificateur supervisé,classificateur supervisé,分類子を監視する,監督分類器,教師あり分類器,контролировать классификатор,наблюдаемый классификатор,классификатор с учителем
4203,supervise contrastive learning,الإشراف على التعلم المتباين,التعلم التبايني المشروف,تعلم تباينيّ موجّه,监督对比学习,监督对比学习,监督对比学习,superviser l’apprentissage contrastif,apprentissage contrastif supervisé,apprentissage contrastif supervisé,対照的な学習を監督する,監督対比学習,監督対照学習,контролировать контрастное обучение,надзорное контрастное обучение,контролируемое контрастное обучение
4204,supervise datum,الإشراف على المسند,البيانات المراقبة,بيانات موجهة,监督数据,监督数据,有监督数据,superviser les données,données supervisées,donnée supervisée,データムを監視する,監督データ,教師データ,контролировать датум,наблюдаемые данные,данные с учителем
4205,supervise finetuning,ضبط دقيق تحت الإشراف,الضبط النهائي المشرف,ضَبْطٌ نَاعِمٌ مُشْرَفٌ عَلَيْهِ,监督微调,监督微调,监督微调,réglage fin supervisé,affinage supervisé,réglage fin supervisé,監視付き微調整,監督ファインチューニング,監督細調整,контролируемая тонкая настройка,"""['Мы используем Codex с небольшим обучением с подсказками и LLaMA-7B после надзорного дообучения на эталонных пошаговых решениях (обозначается как LLaMA+ft). Мы случайным образом выбираем 50 сгенерированных попыток с неправильными ответами и внимательно",контролируемая подстройка
4206,supervise learning,التعلم تحت الإشراف,التعلم الإشرافي,التعلم الموجه,监督学习,监督学习,监督学习,enseignement supervisé,apprentissage supervisé,apprentissage supervisé,教師あり学習,教師付き学習,教師あり学習,контролируемое обучение,Обучение с учителем,Обучение с учителем
4207,supervise manner,طريقة الإشراف,بطريقة مشرفة,الإشراف الطريقة,监督方式,监督方式,监督方式,superviser la manière,manière supervisée,manière supervisée,マナーを監督する,監督された方法 (Kansoku sareta houhou),監視的な方式,контролировать манеру,"""['Мы обучаем нашу модель предсказания глубины на наборе данных Mannequin-Challenge надзорным способом, то есть, путем регрессии к глубине, сгенерированной конвейером MVS. Одним из ключевых вопросов является то, как структурировать вход в сеть, чтобы обучение про",контролируемый способ
4208,supervise method,طريقة الإشراف,الطريقة المشروعة,طريقة الإشراف,监督法,监督方法,监督方法,méthode de supervision,méthode supervisée,méthode supervisée,監視方法,監視メソッド,教師あり手法,метод надзора,- Supervised метод,Метод наблюдения
4209,supervise model,نموذج الإشراف,النموذج المراقب,نموذج إشرافي,监督模型,监督模型,监督模型,superviser le modèle,modèle supervisé,modèle supervisé,モデル監修,監督モデル (kanshoku moderu),教師付きモデル,контролировать модель,модель с учителем,Обучаемая модель
4210,supervise multi-task learning,الإشراف على التعلم متعدد المهام,التعلم التعددي المهام المشروف,التعلم المتعدد المهام الموجه,监督多任务学习,监督多任务学习,监督多任务学习,superviser l’apprentissage multitâche,apprentissage multi-tâches supervisé,apprentissage multi-tâche supervisé,マルチタスク学習を監督する,監督付きマルチタスク学習,監視マルチタスク学習,контролировать многозадачное обучение,наблюдаемое многозадачное обучение,Наблюдаемое многозадачное обучение
4211,supervise setting,الإشراف على الإعداد,الإعداد التشريفي,إعداد الإشراف,监督设置,监督设置,监督设置,superviser le réglage,cadre supervisé,paramètres supervisés,設定を監視する,監督設定 (Kanshoku settei),監視設定,контролировать настройку,наблюдаемая настройка,контролируемая установка
4212,supervise system,نظام الإشراف,- التنظيم المراقب,نظام إشرافي,监督制度,监督系统,监督系统,superviser le système,système supervisé,système supervisé,監視システム,監督システム (Kanshoku shisutemu),監視システム,система надзора,надзорная система,система с учителем
4213,supervise training,الإشراف على التدريب,التدريب المشروف,الإشراف على التدريب,监督培训,监督训练 (Supervised Training),监督训练,superviser la formation,formation supervisée,l'entraînement supervisé,トレーニングを監督する,監督学習,教師あり学習,контролировать обучение,наблюдаемое обучение,контролировать обучение
4214,support,يدعم,- تعداد الوثائق,دَعْم,支持,"""['让我们用试验权重引起的分布q表示。我们接着计算q的一个封闭形式表达。q的支持和dP+的支持相同，因为只有从dP+中抽样的文档被分配了一个未归一化的试验权重。'，'由于大频繁项集的子集数量爆炸式增长，仅挖掘封闭频",支持集,soutien,support,support,サポート,サポート,サポート,поддерживать,опора,носитель
4215,support set,مجموعة الدعم,مجموعة الدعم,مجموعة الدعم,支撑套,支持集,支持集合,ensemble de supports,ensemble de support,ensemble d'entraînement,サポートセット,サポートセット (sapōto setto),サポートセット,набор поддержки,набор опорных данных,набор поддержки
4216,support threshold,عتبة الدعم,- مستوى الدعم,نسبة الدعم,支持门槛,支持阈值,支持度阈值,seuil de prise en charge,seuil de support,seuil de support,サポートしきい値,サポート閾値,サポートしきい値,порог поддержки,порог поддержки,порог поддержки
4217,support vector,ناقلات الدعم,متجه الدعم,مُتجه الدعم,支持向量,支持向量,支持向量,vecteur de soutien,vecteur de support,vecteur de support,サポートベクトル,サポートベクトル,サポートベクトル,опорный вектор,опорный вектор,векторы опоры
4218,surface normal,السطح عادي,الطبيعيات السطحية,السطح العمودي,表面法线,表面法线 (surface normal),表面法向量,surface normale,normale de surface,normale de surface,表面法線,表面法線,表面法線,поверхность нормальная,нормаль к поверхности,поверхностная нормаль
4219,surface normal estimator,مقدر السطح الطبيعي,مُقَدِّرُ الضَّوْرَةِ السَّطْحِيَّة,مقدر العامودي السطحي,表面法线估计器,表面法线估计器,表面法向量估计器,estimateur de normale de surface,estimateur de normale de surface,Estimateur de normale de surface,表面法線推定器,表面法線推定器,表面法線推定器,оценка нормали поверхности,оценщик нормали поверхности,Оценщик нормалей поверхности
4220,surface normal prediction,التنبؤ الطبيعي السطحي,تنبؤ بالسطح العادي,توقع الضوء السطحي,表面法线预测,表面法线预测,表面法向量预测,prédiction de la normale à la surface,prédiction de la normale de surface,prédiction des normales de surface,表面法線予測,表面法線予測,表面法線予測,прогноз нормалей поверхности,предсказание нормализованной поверхности,предсказание нормали поверхности
4221,surface realization,تحقيق السطح,التجسيد السطحي,تحقيق السطح,表面实现,表层实现,表层实现,réalisation de surfaces,réalisation de surface,réalisation de surface,表面実現,表層実現,表層実現,реализация поверхности,поверхностная реализация,поверхностная реализация
4222,surrogate,بديل,بديل,مُحاكي,代理人,替代物,替代品,substitut,"R → R pour w 2 ≤ 1.', 'Comme c'est le cas en classification (Zhang, 2004; Bartlett et al., 2006), nous considérons donc un substitut borné ϕ à minimiser à",substitut,代理,"R → Rはw 2 ≤ 1のときに凸関数です。', '分類でも行われているように(Zhang, 200",代理,суррогатная мать,"R → R для w 2 ≤ 1.', 'Как это делается в классификации (Zhang, 2004",суррогат
4223,surrogate function,وظيفة بديلة,وظيفة بديلة,دالة بديلة,代理函数,替代函数,替代函数,fonction de substitution,fonction de substitution,fonction de substitution,サロゲート関数,- 置き換え関数,代用関数,суррогатная функция,суррогатная функция,вспомогательная функция
4224,surrogate loss,خسارة بديلة,الخسارة البديلة,خسارة بديلة,替代损失,替代损失,替代损失,perte de substitution,perte de substitution,perte surrogate,代理損失,代理損失 (surrogate loss),代理損失,суррогатная потеря,заменительная потеря,потерь-заменителей
4225,surrogate loss function,وظيفة الخسارة البديلة,دالة الخسارة البديلة,دالة الخسارة البديلة,替代损失函数,替代损失函数,替代损失函数,fonction de perte de substitution,- Fonction de perte substitutive,fonction de perte de substitution,代理損失関数,置換損失関数 (Surrogate Loss Function),代替損失関数,суррогатная функция потерь,заменяющая функция потерь,Суррогатная функция потерь
4226,surrogate model,نموذج بديل,- تعمل بديلا,نموذج بديل,替代模型,替代模型,代理模型,modèle de substitution,modèle de substitution,modèle substitut,サロゲートモデル,代理モデル,代理モデル,суррогатная модель,суррогатная модель,заместительная модель
4227,symbol grounding problem,مشكلة التأريض الرمز,مشكلة تأصيل الرموز,مشكلة ترسيخ الرمز,符号接地问题,符号接地问题,符号接地问题,problème de mise à la terre du symbole,problème d'ancrage des symboles,problème de l'ancrage des symboles,シンボル接地の問題,シンボルグラウンディング問題 (Symbol Grounding Problem),記号接地問題,проблема с заземлением символа,проблема символьной обоснованности,проблема обоснования символов
4228,symbolic representation,التمثيل الرمزي,التمثيل الرمزي,تمثيل رمزي,符号表示,符号表示,符号表示,représentation symbolique,représentation symbolique,représentation symbolique,象徴的な表現,"""しかし、子供たちは象徴的な入力を受け取りません。象徴的表現は、聴覚や視覚のような高度に変動し、ノイズが多く、情報豊富な知覚信号から推測される抽象化の一形態です。""、「私たちは、明示的な象徴的表現として入",記号的表現,символическое представление,символическое представление,символическое представление
4229,symmetric matrix,مصفوفة متماثلة,مصفوفة متناظرة,مصفوفة متناظرة,对称矩阵,对称矩阵,对称矩阵,matrice symétrique,matrice symétrique,matrice symétrique,対称行列,対称行列 (taishougyouretsu),対称行列,симметричная матрица,симметрическая матрица,симметричная матрица
4230,symmetric positive semidefinite matrix,مصفوفة شبه محددة إيجابية متماثلة,مصفوفة متناظرة نصف معينة إيجابية,مصفوفة متناظرة موجبة شبه معرفة,对称正半定矩阵,对称半正定矩阵,对称正半正定矩阵,matrice semi-définie positive symétrique,matrice symétrique positive semi-définie,matrice symétrique semidéfinie positive,対称正定値行列,対称正定値行列 (taishou seitei kouretsu),対称正値半正定行列,симметричная положительная полуопределенная матрица,симметричная положительно полуопределенная матрица,симметричная положительно полуопределенная матрица
4231,symmetrization,التماثل,التناظرية,تناظر,对称化,对称化,对称化,symétrisation,symétrisation,symmétrisation,対称化,対称化 (Taisōka),対称化,симметризация,симметризация,симметризация
4232,synchronous context-free grammar,قواعد متزامنة خالية من السياق,نحو بدون سياق متزامن,ذات قواعد محوية حرة متزامنة,同步上下文无关语法,同步上下文无关文法,同步无上下文文法,grammaire synchrone sans contexte,grammaire synchrone sans contexte,grammaire synchrone hors-contexte,同期文脈自由文法,同期文脈自由文法,同期コンテキストフリー文法,синхронная контекстно-свободная грамматика,- Синхронная контекстно-свободная грамматика,синхронная контекстно-свободная грамматика
4233,synonymy,مرادف,مرادفية,مترادفات,同义词,同义词关系,同义性,synonymie,synonymie,polysémie,同義語,同義語 (どうぎご),同義性,синонимия,синонимия,синонимия
4234,synset,com.synset,- تعريف مجموعة الكلمات,مجموعة الترادف,同义词集,同义词集,同义词集,synset,synset,Synset,シンセット,同義語セット,同義語集合,синсет,синсет,синсет
4235,syntactic analysis,التحليل النحوي,التحليل النحوي,تحليل تركيبي,句法分析,句法分析,句法分析,analyse syntaxique,- Analyse syntaxique,analyse syntaxique,構文解析,構文解析,構文解析,синтаксический анализ,синтаксический анализ,синтаксический анализ
4236,syntactic category,الفئة النحوية,فئة تركيبية,الفئة النحوية,句法范畴,句法类别,语法范畴,catégorie syntaxique,catégorie syntaxique,catégorie syntaxique,構文カテゴリ,構文カテゴリ,統語範疇,синтаксическая категория,синтаксическая категория,синтаксическая категория
4237,syntactic constraint,القيد النحوي,- محددات تركيبية,تقييد تركيبي,句法约束,句法约束,语法约束,contrainte syntaxique,contrainte syntaxique,contrainte syntaxique,構文上の制約,構文制約 (Koumpon Seiyaku),統語的制約,синтаксическое ограничение,синтаксическое ограничение,синтаксические ограничения
4238,syntactic dependency,التبعية النحوية,الاعتماد النحوي,الاعتماد النحوي,句法依存,句法依赖,句法依赖关系,dépendance syntaxique,dépendance syntaxique,dépendance syntaxique,構文上の依存関係,"""['We also share the parameters of lower layers in our model to predict POS tags and predicates. Following , we focus on the end-toend setting, where predicates must be predicted on-the-fly. Since we also train our model to predict syntactic dependencies, it is beneficial to give the model knowledge of POS information.', ""To incorporate syntax, one self-attention head is trained to attend to each token's syntactic parent, allowing the model to use this attention head as an oracle for syntactic dependencies. We introduce this syntactically-informed self-attention (",統語的依存関係,синтаксическая зависимость,синтаксическая зависимость,синтаксическая зависимость
4239,syntactic dependency parsing,تحليل التبعية النحوية,تحليل التركيب النحوي الاعتمادي,تحليل الاعتماد النحوي التركيبي,句法依存分析,句法依存分析,句法依赖分析,analyse des dépendances syntaxiques,- Analyse syntaxique des dépendances,analyse syntaxique par dépendances,構文依存関係の解析,構文依存解析,構文的依存関係解析,синтаксический анализ зависимостей,синтаксический анализ зависимостей,синтаксический анализ зависимостей
4240,syntactic dependency tree,شجرة التبعية النحوية,شجرة التبعية الصرفية,شجرة الاعتماد النحوي,句法依存树,句法依赖树,句法依赖树,arbre de dépendance syntaxique,arbre de dépendance syntaxique,arbre de dépendances syntaxiques,構文依存関係ツリー,構文依存木 (Kōbun izon ki),統語的依存木,дерево синтаксических зависимостей,синтаксическое дерево зависимостей,синтаксическое дерево зависимостей
4241,syntactic feature,الميزة النحوية,السمة النحوية,ميزة تركيبية,句法特征,句法特征,语法特征,caractéristique syntaxique,caractéristique syntaxique,fonctionnalité syntaxique,構文上の特徴,構文的特徴,構文的特徴,синтаксическая особенность,синтаксическая характеристика,синтаксическая особенность
4242,syntactic information,المعلومات النحوية,- المعلومات الصرفية,معلومات تركيبية,句法信息,句法信息,句法信息,informations syntaxiques,- Information syntaxique,informations syntaxiques,構文情報,構文情報 (Kōbun jōhō),構文情報,синтаксическая информация,синтаксическая информация,синтаксическая информация
4243,syntactic parse,التحليل النحوي,تحليل تركيبيsyntaxباستخدام تحليل,تحليل تركيبي,句法分析,句法分析,句法分析,analyse syntaxique,analyse syntaxique,analyse syntaxique,構文解析,構文解析 (koumon kaiseki),構文解析,синтаксический анализ,синтаксический анализ,синтаксический разбор
4244,syntactic parser,محلل نحوي,محلل تركيبة سينتاكسية,محلل تركيبي,句法分析器,句法分析器,句法分析器,analyseur syntaxique,analyseur syntaxique,analyseur syntaxique,構文パーサー,構文パーサ (koubun pa-sa),構文解析器,синтаксический парсер,синтаксический анализатор,синтаксический парсер
4245,syntactic regularity,الانتظام النحوي,الانتظام النحوي,انتظام نحوي,句法规律性,句法规律,句法规律性,régularité syntaxique,régularité syntaxique,régularité syntaxique,構文上の規則性,構文規則性,構文的規則性,синтаксическая регулярность,синтаксическая регулярность,синтаксическая регулярность
4246,syntactic representation,التمثيل النحوي,- التمثيل النحوي,تمثيل تركيبي,句法表征,句法表示,句法表示,représentation syntaxique,représentation syntaxique,représentation syntaxique,構文表現,"""['まず、均質な表現は、ダウンストリームコンポーネントのために一貫したクロス言語分析を必要とするマルチリンガル言語技術にとって重要です。第二に、一貫した構文表現は、教師なし（Klein and Manning、2004）またはクロス言語構",構文表現,синтаксическое представление,синтаксическое представление,синтаксическое представление
4247,syntactic similarity,التشابه النحوي,التشابه الصرفي,تشابه تركيبي,句法相似性,句法相似度,句法相似性,similarité syntaxique,similarité syntaxique,similarité syntaxique,構文の類似性,統語的類似性,構文的類似性,синтаксическое сходство,синтаксическая сходство,синтаксическое сходство
4248,syntactic structure,البنية النحوية,الهيكل النحوي,البنية النحوية,句法结构,句法结构,句法结构,structure syntaxique,structure syntaxique,structure syntaxique,構文構造,構文構造 (Kōbun kōzō),統語構造,синтаксическая структура,синтаксическая структура,синтаксическая структура
4249,syntactic tree,شجرة نحوية,الشجرة النحوية,شجرة تركيبية,句法树,句法树,句法树,arbre syntaxique,arbre syntaxique,arbre syntaxique,構文ツリー,構文木 (Koumokug),構文木,синтаксическое дерево,синтаксическое дерево,синтаксическое дерево
4250,syntax,بناء الجملة,الصرفية,قواعد,句法,语法,语法,syntaxe,syntaxe,syntaxe,構文,- 統語論 (Tōgolun),構文,синтаксис,синтаксис,синтаксис
4251,syntax tree,شجرة بناء الجملة,شجرة بناء الجملة,شجرة القواعد,语法树,句法树 (syntax tree),语法树,arbre syntaxique,arbre de syntaxe,arbre syntaxique,構文ツリー,構文木 (こうぶんぎ),構文木,синтаксическое дерево,синтаксическое дерево,синтаксическое дерево
4252,synthetic dataset,مجموعة البيانات الاصطناعية,المجموعة البيانات الاصطناعية,بيانات صناعية,综合数据集,合成数据集,合成数据集,ensemble de données synthétiques,ensemble de données synthétique,ensemble de données synthétiques,合成データセット,合成データセット,合成データセット,синтетический набор данных,синтетический набор данных,синтетический датасет
4253,system identification,تحديد النظام,تحديد النظام,تحديد النظام,系统识别,系统辨识,系统识别,identification du système,identification de système,identification des systèmes,システムの識別,システム同定,システム同定,идентификация системы,идентификация системы,идентификация системы
4254,t-test,اختبار t,اختبار تي,اختبار t,t检验,t检验,学生t检验,test t,t-test,test t,t検定,t検定,t検定,t-тест,t-тест,t-критерий
4255,t5 model,نموذج t5,نموذج T5,نموذج t5,t5型号,T5模型,T5模型,modèle t5,modèle T5,modèle T5,t5モデル,T5モデル,T5モデル,модель т5,T5 модель,Модель T5
4256,t5-base,قاعدة t5,تي 5-قاعدة,t5-base,t5碱基,T5基础,t5-base,base t5,t5-base,t5-base,t5ベース,"""['これらのデータセットはさまざまなタスク、異なるタイプおよび指示バイアスのレベル（Tab. 1）、サイズ（§B）が異なります。DROPを除くすべてのデータセットについて、T5-baseおよびT5-large（Raffel et al., 2020）、BART-baseおよびBART-large（Lewis et al.,",t5-base,t5-база,t5-base,t5-base
4257,t5-base model,نموذج قاعدة t5,نموذج t5-base,نموذج T5 الأساسي,t5 基础型号,T5基础模型,T5-base 模型,modèle à base t5,modèle de base T5,modèle t5-base,t5ベースモデル,T5-baseモデル,T5-baseモデル,базовая модель t5,Модель t5-base,Модель t5-base
4258,t5-large model,نموذج t5 كبير,- التعلم العميق t5-النموذج الكبير,نموذج t5-large,t5-大型号,T5-large 模型,t5-large模型,t5-grand modèle,modèle T5-large,modèle t5-large,t5-大型モデル,T5-large モデル,t5-large モデル,t5-большая модель,модель t5-large,t5-large модель
4259,tag recommendation,توصية العلامة,توصية العلامة,توصية العلامات,标签推荐,标签推荐,标签推荐,recommandation de balise,recommandation de tag,recommandation d'étiquettes,タグの推奨,タグ推薦 (tag recommendation),タグ推薦,рекомендация тега,рекомендация тегов,рекомендация тегов
4260,tag sequence,تسلسل العلامة,تسلسل العلامة,تتابع العلامات,标签序列,标签序列,标记序列,séquence de balises,séquence de balises,séquence d'étiquettes,タグ配列,タグシーケンス,タグ系列,последовательность тегов,последовательность тегов,последовательность тегов
4261,tagger,tagger,معرِّف,مُصنِّف,标记者,标记器,标注器,tagueur,étiqueteur,étiqueteur,タガー,タガー,タガー,тагер,теггер,тэггер
4262,tagset,tagset,مجموعة العلامات,مجموعة الوسوم,标签集,标签集,词性标记集,jeu de balises,ensemble d'étiquettes,ensemble de balises,タグセット,タグセット,タグセット,набор тегов,набор тегов,набор тегов
4263,tail entity,كيان الذيل,كيان الذيل,الكيان الذيلي,尾部实体,尾实体,尾实体,entité de queue,- Entité de queue,entité de queue,末尾エンティティ,テイルエンティティ,対象エンティティ,хвостовая сущность,хвостовое существо,хвостовая сущность
4264,tangent space,مساحة الظل,المساحة المماسة,فضاء الملامس,切线空间,切空间,切线空间,espace tangent,espace tangent,espace tangent,接空間,接線空間 (Sessensuu),接線空間,касательное пространство,касательное пространство,касательное пространство
4265,tanh activation function,وظيفة تفعيل تانه,وظيفة التنش المنشطة,دالة التنشيط tanh,tanh 激活函数,双曲正切激活函数 (tanh activation function),tanh激活函数,fonction d'activation tanh,fonction d'activation tanh,fonction d'activation tanh,Tanh活性化関数,tanh活性化関数,tanhアクティベーション関数,функция активации Тана,функция активации tanh,Функция активации тангенса гиперболического
4266,target,هدف,هدف,هدف,目标,目标,目标,cible,cible,cible,目標,ターゲット,ターゲット,цель,- Цель,цель
4267,target classifier,المصنف المستهدف,مصنف الهدف,هدف المصنف,目标分类器,目标分类器 (target classifier),目标分类器,classificateur cible,classificateur cible,classificateur cible,ターゲット分類子,ターゲット識別器 (target classifier),ターゲット分類器,целевой классификатор,целевой классификатор,целевой классификатор
4268,target distribution,التوزيع المستهدف,التوزيع المستهدف,التوزيع المستهدف,目标分布,目标分布,目标分布,distribution cible,- Distribution cible,distribution cible,ターゲット分布,ターゲット分布,目標分布,целевое распределение,- Целевое распределение,целевое распределение
4269,target domain,المجال المستهدف,المجال المستهدف,المجال المستهدف,目标域,目标领域,目标域,domaine cible,domaine cible,domaine cible,ターゲットドメイン,ターゲットドメイン,ターゲトドメイン,целевой домен,целевая область,целевая область
4270,target function,وظيفة الهدف,الدالة المستهدفة,دالة الهدف,目标函数,目标函数,目标函数,fonction cible,fonction cible,fonction cible,ターゲット関数,目標関数 (もくひょうかんすう),目標関数,целевая функция,целевая функция,целевая функция
4271,target instance,مثيل الهدف,الحالة المستهدفة,هدف المثيل,目标实例,目标实例,目标实例,instance cible,instance cible,Instance cible,ターゲットインスタンス,ターゲットインスタンス,ターゲットインスタンス,целевой экземпляр,целевой экземпляр,целевой экземпляр
4272,target model,نموذج الهدف,نموذج الهدف,نموذج الهدف,目标模型,目标模型,目标模型,modèle cible,modèle cible,modèle cible,対象機種,ターゲットモデル,ターゲットモデル,целевая модель,целевая модель,целевая модель
4273,target network,الشبكة المستهدفة,شبكة الهدف,الشبكة المستهدفة,目标网络,目标网络,目标网络,réseau cible,réseau cible,réseau cible,ターゲットネットワーク,ターゲットネットワーク,ターゲットネットワーク,целевая сеть,сеть целевых значений,целевая сеть
4274,target node,العقدة المستهدفة,العقد المستهدف,العقدة المستهدفة,目标节点,目标节点,目标节点,nœud cible,- Node cible,nœud cible,ターゲットノード,ターゲットノード,目標ノード,целевой узел,- Пункт назначения,целевой узел
4275,target policy,سياسة الهدف,سياسة الهدف,سياسة الهدف,目标政策,目标策略,目标策略,politique cible,politique cible,politique cible,目標政策,目標方針 (mokuhyou houshin),目標方針,целевая политика,Целевая стратегия,целевая политика
4276,target sentence,الجملة المستهدفة,الجملة الهدفية,جملة الهدف,目标句,目标句,目标句子,phrase cible,phrase cible,phrase cible,ターゲットセンテンス,目標文,ターゲット文,целевое предложение,целевое предложение,целевое предложение
4277,target sequence,تسلسل الهدف,التسلسل الهدف,تسلسل الهدف,目标序列,目标序列,目标序列,séquence cible,séquence cible,séquence cible,ターゲット配列,目標シーケンス (mokuhyou shiikensu),ターゲットシーケンス,целевая последовательность,целевая последовательность,целевая последовательность
4278,target task,المهمة المستهدفة,المهمة المستهدفة,الهدف المهمة,目标任务,目标任务,目标任务,tâche cible,tâche cible,tâche cible,ターゲットタスク,目標タスク,ターゲットタスク,целевая задача,целевая задача,Целевая задача
4279,target token,رمز الهدف,رمز الهدف,الهدف المرموز,目标代币,目标标记,目标词元,jeton cible,jeton cible,jeton cible,ターゲットトークン,ターゲットトークン,対象トークン,целевой токен,целевой токен,целевой токен
4280,target variable,المتغير المستهدف,متغير الهدف,متغير الهدف,目标变量,目标变量,目标变量,variable cible,- Variable cible,variable cible,ターゲット変数,ターゲット変数,ターゲット変数,целевая переменная,целевая переменная,Целевая переменная
4281,target vector,ناقلات الهدف,متجه الهدف,متجه الهدف,目标向量,目标向量 (mùbiāo xiàngliàng),目标向量,vecteur cible,vecteur cible,vecteur cible,ターゲットベクトル,目標ベクトル (mokuteki becutoru),ターゲットベクトル,целевой вектор,целевой вектор,целевой вектор
4282,target vocabulary,المفردات المستهدفة,المفردات المستهدفة,المفردات المستهدفة,目标词汇,目标词汇,目标词汇,vocabulaire cible,vocabulaire cible,vocabulaire cible,ターゲット語彙,対象語彙,ターゲット語彙,целевой словарный запас,целевая лексика,целевой словарь
4283,target word,كلمة الهدف,كلمة الهدف,الكلمة المستهدفة,目标词,目标词,目标词,mot cible,mot cible,mot cible,対象の単語,対象語 (たいしょうご),対象単語,целевое слово,целевое слово,целевое слово
4284,target-to-source model,نموذج الهدف إلى المصدر,النموذج الهدف-المصدر,نموذج من الهدف إلى المصدر,目标到源模型,目标到源模型,目标到源语言模型,modèle cible-source,modèle cible-source,modèle cible-vers-source,ターゲットからソースへのモデル,ターゲット対ソースモデル (target-to-source モデル),ターゲットから元言語へのモデル,модель «цель-источник»,модель цели-источника,модель целевой на исходный язык
4285,task,مهمة,مهمة,مهمة,任务,任务,任务,tâche,tâche,tâche,タスク,タスク,タスク,задача,задача,задача
4286,task adaptation,التكيف المهمة,تكييف المهمة,تكيف المهمة,任务适应,任务适应,任务适应,adaptation des tâches,- Adaptation de tâche,Adaptation à la tâche,タスクの適応,タスク適応 (Task Adaptation),タスク適応,адаптация задачи,адаптация задачи,адаптация задач
4287,task model,نموذج المهمة,نموذج المهمة,نموذج المهمة,任务模型,任务模型,任务模型,modèle de tâche,modèle de tâche,modèle de tâche,タスクモデル,タスクモデル,タスクモデル,модель задачи,модель задачи,задачная модель
4288,task-orient dialog system,نظام الحوار الموجه نحو المهام,نظام حوار موجه نحو المهمة,نظام حوار موجه للمهام,面向任务的对话系统,任务导向对话系统,面向任务的对话系统,système de dialogue orienté tâches,système de dialogue orienté tâche,système de dialogue orienté tâche,タスク指向の対話システム,タスク指向型対話システム,タスク指向型対話システム,целенаправленная диалоговая система,"система диалога, ориентированная на задачи","Система диалогов, ориентированная на задачи"
4289,task-orient dialogue system,نظام الحوار الموجه نحو المهام,نظام حوار موجه نحو المهمة,نظام حوار موجه نحو المهمة,任务导向的对话系统,任务导向对话系统 (task-orient dialogue system),面向任务对话系统,système de dialogue axé sur les tâches,système de dialogue orienté tâche,système de dialogue orienté tâche,タスク指向の対話システム,タスク指向型ダイアログシステム,タスク指向対話システム,целенаправленная диалоговая система,"система диалога, ориентированная на задачи","диалоговая система, ориентированная на задачи"
4290,task-specific model,نموذج خاص بالمهمة,النموذج الخاص بالمهمة,نموذج محدد المهمة,特定任务模型,任务特定模型,任务特定模型,modèle spécifique à une tâche,modèle spécifique à la tâche,modèle spécifique à la tâche,タスク固有のモデル,タスク固有モデル,タスク固有モデル,модель для конкретной задачи,"модель, специфическая для задачи",модель для конкретной задачи
4291,taxonomy,التصنيف,تصنيفية,تصنيف,分类,分类学,分类法,taxonomie,taxonomie,taxonomie,分類学,分類学 (ぶんるいがく),分類法,таксономия,таксономия,таксономия
4292,teacher forcing,إجبار المعلم,تدريس قوة,قصر المعلم,老师强迫,老师强迫,教师强制,enseignant forçant,enseignement forcé,forçage par l'enseignant,先生が強制する,先生強制,教師強制,учитель заставляет,принуждение учителя,Принудительное обучение
4293,teacher network,شبكة المعلمين,شبكة المعلم,شبكة المعلم,教师网,教师网络,教师网络,réseau d'enseignants,réseau enseignant,réseau enseignant,教師ネットワーク,教師ネットワーク,教師ネットワーク,сеть учителей,учительская сеть,учительская сеть
4294,temperature parameter,معلمة درجة الحرارة,معلم درجة الحرارة,معامل الحرارة,温度参数,温度参数,温度参数,paramètre de température,paramètre de température,paramètre de température,温度パラメータ,温度パラメータ (Ondo Parameta),温度パラメータ,температурный параметр,параметр температуры,температурный параметр
4295,temperature scaling,تحجيم درجة الحرارة,معايرة درجة الحرارة,تضخيم درجة الحرارة,温标,温度缩放,温度缩放,échelle de température,étalonnage de la température,La mise à l'échelle de température,温度スケーリング,温度スケーリング (Ondo Sukēringu),温度スケーリング,масштабирование температуры,шкалирование температуры,масштабирование температуры
4296,template,نموذج,القالب,قالب,模板,模板,模板,modèle,modèle,modèle,テンプレート,テンプレート,テンプレート,шаблон,шаблон,шаблон
4297,template model,نموذج القالب,نموذج قالب,نموذج القالب,模板模型,模板模型,模板模型,modèle de modèle,modèle de gabarit,modèle de template,テンプレートモデル,テンプレートモデル,テンプレートモデル,шаблонная модель,модель-шаблон,шаблонная модель
4298,template-matching,مطابقة النموذج,القالب المطابق,مطابقة القالب,模板匹配,模板匹配,模板匹配,correspondance de modèle,correspondance de modèle,mise en correspondance de modèles,テンプレートマッチング,テンプレートマッチング,テンプレート一致法,соответствие шаблону,сопоставление шаблонов,сопоставлению шаблонов
4299,temporal derivative,مشتق زمني,المشتقة الزمنية,الاشتقاق الزمني,时间导数,时间导数,时间导数,dérivée temporelle,dérivée temporelle,dérivée temporelle,時間導関数,時間導関数 (jikan doudakansuu),時間微分,временная производная,временная производная,временная производная
4300,temporal difference,الفرق الزمني,الفرق الزمني,فرق زمني,时间差异,时间差异 (Temporal Difference),时间差分,différence temporelle,Différence temporelle,différence temporelle,時間差,時間差 (jikansa),時間差,временная разница,временная разница,временная разница
4301,temporal difference learning,تعلم الفرق الزمني,تعلم الفروق الزمنية,التعلم بالاختلاف الزمني,时间差异学习,时间差异学习,时序差分学习,apprentissage des différences temporelles,apprentissage par différence temporelle,apprentissage par différence temporelle,時間差学習,時差学習 (jisa gakushū),時間差学習,обучение временной разнице,обучение на основе временных различий,Метод временных разностей
4302,temporal drift,الانجراف الزمني,التحول الزمني,تحيز زمني,时间漂移,时间漂移,时间漂移,dérive temporelle,dérive temporelle,dérive temporelle,時間的ドリフト,時間ドリフト,時間的ドリフト,временной дрейф,- Temporal drift - Временной дрейф,временной дрейф
4303,temporal fusion,الانصهار الزمني,الانصهار الزمني,اندماج زمني,时间融合,时间融合,时间融合,fusion temporelle,fusion temporelle,fusion temporelle,時間的融合,時間融合,時間的融合,временное слияние,- Временное слияние,временное объединение
4304,temporal locality,محلة زمنية,القرب الزمني,الحميمية الزمنية,时间局部性,时间局部性 (Temporal Locality),时间局部性,localité temporelle,localité temporelle,localité temporelle,時間的局所性,時間的局所性,時間局所性,временная местность,Временная локальность,временная локальность
4305,temporal logic,المنطق الزمني,منطق زماني,المنطق الزمني,时间逻辑,时间逻辑,时序逻辑,logique temporelle,logique temporelle,logique temporelle,時相論理,時間論理 (じかんろんり),時相論理,временная логика,временная логика,временная логика
4306,temporal reasoning,المنطق الزمني,الاستدلال الزماني,الاستدلال الزمني,时间推理,时间推理,时序推理,raisonnement temporel,Raisonnement temporel,raisonnement temporel,時間的推論,時間的推論,時間的推論,временное рассуждение,временное рассуждение,временное рассуждение
4307,temporal variable,متغير زمني,المتغير الزمني,متغير زمني,时间变量,时间变量,时间变量,variable temporelle,variable temporelle,variable temporelle,時間変数,時間変数 (じかんへんすう),時間変数,временная переменная,временная переменная,временная переменная
4308,tensor,الموتر,المُجَانِب (Tensor),مُتَجَّه,张量,张量 (tensor),张量,tenseur,tenseur,tenseur,テンソル,テンソル,テンソル,тензор,тензор,тензор
4309,tensor decomposition,تحلل الموتر,تحليل التناضح,تفكيك التانسور,张量分解,张量分解,张量分解,décomposition tensorielle,- Décomposition de tenseur,décomposition de tenseur,テンソル分解,テンソル分解,テンソル分解,тензорное разложение,Тензорное разложение,тензорное разложение
4310,tensor factorization,تحليل الموتر,تعويض التناظر,تجزئة المتجهة,张量分解,张量分解,张量分解,factorisation tensorielle,factorisation de tenseur,Factorisation tensorielle,テンソル因数分解,テンソル因子分解,テンソル分解,тензорная факторизация,- Тензорное разложение,тензорная факторизация
4311,tensor field,مجال الموتر,حقل تنسور,حقل التانسور,张量场,张量场,张量场,champ tenseur,Champ tensoriel,champ tensoriel,テンソル場,テンソル場 (tensor field),テンソル場,тензорное поле,тензорное поле,тензорное поле
4312,tensor product,منتج الموتر,ناتج التنسور,ضرب الأتر,张量积,张量积,张量积,produit tenseur,produit tensoriel,produit tensoriel,テンソル積,テンソル積,テンソル積,тензорное произведение,тензорное произведение,тензорное произведение
4313,term frequency,تردد المصطلح,تردد المصطلح,ترددية المصطلح,术语频率,术语频率 (Term Frequency),词频,fréquence du terme,fréquence des termes,fréquence de terme,期間の頻度,用語の頻度 (term frequency),単語頻度,частота термина,частота терминов,частота слова
4314,terminal node,العقدة الطرفية,نقطة نهائية,نقطة نهائية,终端节点,终端节点,终端节点,nœud terminal,nœud terminal,nœud terminal,ターミナルノード,終端ノード (shūtan nōdo),ターミナルノード,терминальный узел,Терминальный узел,терминальный узел
4315,terminal state,الحالة النهائية,الحالة النهائية,الحالة النهائية,终端状态,终止状态,终止状态,état terminal,état terminal,état terminal,端末状態,終了状態 (shūryō jōtai),終端状態,терминальное состояние,терминальное состояние,конечное состояние
4316,termination condition,حالة الإنهاء,شرط الإنهاء,شرط الإنهاء,终止条件,终止条件,终止条件,condition de résiliation,Condition d'arrêt,condition d'arrêt,終了条件,終了条件,終了条件,условие завершения,условие завершения,Условие завершения
4317,termination criterion,معيار الإنهاء,معيار الإنهاء,معيار الإنهاء,终止标准,终止准则,终止准则,critère de terminaison,critère d'arrêt,critère d'arrêt,終了基準,終了基準,終了基準,критерий завершения,критерий остановки,критерий завершения
4318,test accuracy,دقة الاختبار,دقة الاختبار,دقة الاختبار,测试准确度,测试准确度,测试准确率,précision des tests,Précision du test,précision de test,テストの精度,テスト精度,テスト正解率,точность теста,- Точность теста,точность проверки
4319,test dataset,مجموعة بيانات الاختبار,مجموعة بيانات الاختبار,مجموعة البيانات الاختبارية,测试数据集,测试数据集,测试数据集,ensemble de données de test,ensemble de données de test,ensemble de test,テストデータセット,テストデータセット,テストデータセット,тестовый набор данных,тестовый набор данных,тестовый набор данных
4320,test datum,مسند الاختبار,بيانات الاختبار,معطيات الاختبار,测试数据,测试数据,测试数据,donnée d'essai,donnée de test,donnée de test,テストデータム,テストデータ,テストデータ,данные испытания,тестовые данные,тестовые данные
4321,test domain,مجال الاختبار,مجال الاختبارات,نطاق الاختبار,测试域,测试领域,测试域,domaine de test,domaine de test,domaine de test,テストドメイン,テストドメイン,テストドメイン,тестовый домен,тестовая область,тестовая область
4322,test error,خطأ في الاختبار,- تسخير الخطأ,خطأ الاختبار,测试错误,测试错误,测试误差,erreur de test,erreur de test,erreur de test,テストエラー,テストエラー,テストエラー,ошибка теста,ошибка тестирования,ошибка тестирования
4323,test loss,خسارة الاختبار,الخسارة في الاختبارات,خسارة الاختبار,测试损失,测试损失,测试损失,perte d'essai,perte de test,perte de test,テスト損失,テスト損失 (Tesuto sonshitsu),テストロス,потеря теста,потери на тесте,потеря на тестовых данных
4324,test set,مجموعة الاختبار,مجموعة الاختبارات,مجموعة الاختبار,测试集,测试集,测试集,ensemble d'essai,ensemble de test,ensemble de test,テストセット,テストセット (tesuto setto),テストセット,тестовый набор,тестовый набор данных,тестовый набор
4325,test split,تقسيم الاختبار,- تقسيم الاختبار,تقسيم الاختبار,测试分割,测试拆分,测试集分割,fractionnement des tests,test split,partition de test,テスト分割,- テスト分割,テストデータセット,тестовый сплит,тестовое разделение,тестовый раздел
4326,test time,وقت الاختبار,وقت الاختبار,وقت الاختبار,测试时间,测试时间,测试时间,temps de test,- Temps de test,temps d'inférence,試験時間,- テスト時,テスト時,время испытания,время тестирования,время тестирования
4327,testing set,مجموعة الاختبار,مجموعة الاختبار,مجموعة الاختبار,测试集,测试集,测试集,ensemble de test,- Ensemble de test,ensemble de test,テストセット,テストセット,テストセット,набор для тестирования,тестовый набор,набор для тестирования
4328,text categorization,تصنيف النص,تصنيف النصوص,تصنيف النصوص,文本分类,文本分类,文本分类,catégorisation de texte,catégorisation de texte,catégorisation de texte,テキストの分類,テキスト分類 (Text Classification),テキスト分類,категоризация текста,категоризация текста,категоризация текста
4329,text classification,تصنيف النص,تصنيف النصوص,تصنيف النص,文本分类,文本分类,文本分类,classement du texte,Classification de texte,classification de texte,テキスト分類,テキスト分類,テキスト分類,классификация текста,классификация текста,классификация текста
4330,text corpus,مجموعة النص,المحفوظة النصية,مجموعة نصوص,文本语料库,文本语料库,文本语料库,corpus de texte,corpus de texte,corpus textuel,テキストコーパス,テキストコーパス,テキストコーパス,текстовый корпус,текстовый корпус,текстовый корпус
4331,text embedding,تضمين النص,التضمين النصي,تضمين النص,文本嵌入,文本嵌入,文本嵌入,intégration de texte,texte intégré,intégration textuelle,テキストの埋め込み,テキスト埋め込み (text embedding),テキスト埋め込み,встраивание текста,текстовое вложение,текстовое вложение
4332,text encoder,تشفير النص,مُشفر النصوص,مُشفِّر النص,文本编码器,文本编码器,文本编码器,encodeur de texte,encodeur de texte,encodeur de texte,テキストエンコーダ,テキストエンコーダ,テキストエンコーダー,текстовый кодер,текстовый кодировщик,кодировщик текста
4333,text generation,توليد النص,تكوين النصوص,توليد النص,文本生成,文本生成,文本生成,génération de texte,génération de texte,génération de texte,テキストの生成,テキスト生成 (text generation),テキスト生成,генерация текста,генерация текста,генерация текста
4334,text generation model,نموذج توليد النص,نموذج توليد النصوص,نموذج توليد النص,文本生成模型,文本生成模型,文本生成模型,modèle de génération de texte,modèle de génération de texte,modèle de génération de texte,テキスト生成モデル,テキスト生成モデル (text generation model),テキスト生成モデル,модель генерации текста,модель генерации текста,модель генерации текста
4335,text mining,تحليل النصوص,تنقيب النصوص,استخراج النصوص,文本挖掘,文本挖掘 (wénběn wājié),文本挖掘,exploration de texte,fouille de texte,exploration de textes,テキストマイニング,テキストマイニング,テキストマイニング,анализ текста,текстовый анализ,извлечение текста
4336,text segmentation,تجزئة النص,تقسيم النصوص,تقسيم النص,文本分割,文本分割,文本分割,segmentation du texte,segmentation de texte,segmentation de texte,テキストのセグメンテーション,テキストセグメンテーション,テキスト分割,сегментация текста,сегментация текста,сегментация текста
4337,text simplification,تبسيط النص,تبسيط النصوص,تبسيط النص,文本简化,文本简化,文本简化,simplification du texte,simplification de texte,simplification de texte,テキストの簡略化,テキストの簡略化,テキスト単純化,упрощение текста,упрощение текста,упрощение текста
4338,text summarization,تلخيص النص,ملخص النصوص,تلخيص النص,文本摘要,文本摘要化,文本摘要,résumé du texte,résumé de texte,Résumé de texte,テキストの要約,テキスト要約 (Text Summarization),テキスト要約,обобщение текста,сжатие текста,Реферирование текста
4339,text-davinci-002,نص دافينشي-002,نص-دافنشي-002,نص-دافنشي-002,文本-​​达芬奇-002,文本达芬奇-002,text-davinci-002,texte-davinci-002,texte-davinci-002,text-davinci-002,テキスト-ダヴィンチ-002,テキストダヴィンチ002,テキストデイビンチ002,текст-давинчи-002,текст-давинчи-002,текст-давинчи-002
4340,text-davinci-003,النص دافينشي-003,نص-دافنشي-003,نص-دافنشي-003,文本-​​达芬奇-003,文本大文豪-003,text-davinci-003,texte-davinci-003,texte-davinci-003,text-davinci-003,テキスト-ダヴィンチ-003,テキストダビンチ003,text-davinci-003,текст-давинчи-003,текст-да Винчи-003,text-davinci-003
4341,text-to-image diffusion model,نموذج نشر النص إلى الصورة,نموذج انتشار النص إلى الصورة,نموذج انتشار النص إلى الصورة,文本到图像的扩散模型,文本到图像扩散模型,文本到图像扩散模型,modèle de diffusion texte-image,modèle de diffusion texte-image,modèle de diffusion texte-vers-image,テキストから画像への拡散モデル,テキストから画像への拡散モデル,テキストから画像への拡散モデル,модель диффузии текста в изображение,модель диффузии текста в изображение,текстово-изобразительная диффузионная модель
4342,text-to-image generation,توليد النص إلى الصورة,إنشاء صور من النصوص,ولادة الصور من النص,文本到图像的生成,文本到图像生成,文本到图像生成,génération de texte en image,génération de texte en image,génération de texte en image,テキストから画像への生成,テキストから画像生成 (text-to-image generation),テキストから画像生成,генерация текста в изображение,генерация текста в изображение,текст-в-изображение генерация
4343,text-to-image model,نموذج تحويل النص إلى صورة,نموذج النص إلى الصورة,نموذج النص إلى صورة,文本到图像模型,文本到图像模型,文本到图像模型,modèle texte-image,- Modèle texte-image,modèle texte-à-image,テキストから画像へのモデル,テキストから画像へのモデル,テキストから画像への変換モデル,модель преобразования текста в изображение,модель текста к изображению,модель текст-в-изображение
4344,text-to-image synthesis,تركيب النص إلى الصورة,توليد الصور من النصوص,توليد الصور من النص,文本到图像合成,文本到图像合成,文本到图像合成,synthèse texte-image,- Synthèse texte-image,synthèse de texte en image,テキストと画像の合成,テキストから画像への合成,テキストから画像合成,синтез текста в изображение,Синтез текста в изображение,синтез текста в изображение
4345,text-to-text transfer transformer,محول نقل النص إلى النص,نقل النص إلى نص - المحول النقلية,محول نقل النص إلى النص,文本到文本传输转换器,文本到文本转换变压器,文本到文本转换transformer,transformateur de transfert de texte en texte,Transformateur de transfert de texte à texte,transformateur de transfert de texte à texte,テキスト間転送トランスフォーマー,テキスト間転送トランスフォーマー,テキストからテキストへの転移トランスフォーマー,преобразователь передачи текста в текст,текст-к-текст трансформер,текст-на-текст трансформатор
4346,textual entailment,المضمون النصي,- التزام نصي,تضمين نصي,文本蕴含,文本蕴涵,文本蕴含,implication textuelle,entailment textuel,implication textuelle,テキストの含意,"""['彼らは、入力文の意味をより正確に表現することができるOpen IEのネストされた表現を提供する（2016）。彼らのシステムNESTIEは、テキストの含意に関するデータセットをブートストラッピングして、n-ary関係のバイナリおよびネストされたトリプル表現",文章の含意関係,текстовое следствие,текстовое следование,текстовое следование
4347,tf-idf,tf-idf,تردد/التراكيب النمطية للتردد,تف-آي دي إف,tf-idf,tf-idf,tf-idf,tf-idf,tf-idf,tf-idf,tf-idf,tf-idf,"tf-idf に対する日本語訳は ""単語文書行列""です。",tf-idf,tf-idf,tf-idf - tf-idf
4348,threat model,نموذج التهديد,نموذج التهديدات,نموذج التهديد,威胁模型,威胁模型,威胁模型,modèle de menace,modèle de menace,modèle de menace,脅威モデル,脅威モデル,脅威モデル,модель угроз,модель угроз,модель угрозы
4349,threshold,عتبة,عتبة,حد عتبة,临界点,阈值,阈值,seuil,seuil,seuil,しきい値,閾値,閾値,порог,- Порог,порог
4350,threshold function,وظيفة العتبة,وظيفة الحدودية,دالة العتبة,阈值函数,阈值函数,阈值函数,fonction de seuil,fonction de seuil,fonction de seuil,閾値関数,閾値関数 (けいちかんすう),閾値関数,пороговая функция,функция порога,Пороговая функция
4351,threshold parameter,معلمة العتبة,معلم الحدود,معامل العتبة,阈值参数,门限参数,阈值参数,paramètre de seuil,paramètre de seuil,paramètre de seuil,しきい値パラメータ,閾値パラメータ,しきい値パラメータ,пороговый параметр,пороговый параметр,порог
4352,threshold policy,سياسة العتبة,سياسة العتبة,سياسة العتبة,门槛政策,阈值策略,阈值策略,politique de seuil,politique de seuil,politique de seuil,しきい値ポリシー,しきい値方針,閾値ポリシー,пороговая политика,пороговая политика,пороговая политика
4353,time complexity,تعقيد الوقت,التعقيد الزمني,تعقيد الوقت,时间复杂度,时间复杂度,时间复杂度,complexité temporelle,complexité temporelle,complexité temporelle,時間の複雑さ,時間計算量,時間計算量,временная сложность,сложность по времени,временная сложность
4354,time series,السلاسل الزمنية,سلسلة زمنية,السلاسل الزمنية,时间序列,时间序列,时间序列,des séries chronologiques,série temporelle,série chronologique,時系列,時系列,時系列,Временные ряды,временные ряды,временной ряд
4355,time series analysis,تحليل السلاسل الزمنية,تحليل السلاسل الزمنية,تحليل السلاسل الزمنية,时间序列分析,时间序列分析,时间序列分析,Analyse des séries chronologiques,- Analyse de séries temporelles,analyse des séries temporelles,時系列分析,時系列分析 (jikeiretsu bunseki),時系列分析,анализ временных рядов,анализ временных рядов,анализ временных рядов
4356,time series forecasting,التنبؤ بالسلاسل الزمنية,التنبؤ بسلاسل الزمنية,التنبؤ بالسلاسل الزمنية,时间序列预测,时间序列预测,时间序列预测,prévision de séries chronologiques,Prévision de séries temporelles,prévision de séries chronologiques,時系列予測,タイムシリーズ予測,時系列予測,прогнозирование временных рядов,прогнозирование временных рядов,прогнозирование временных рядов
4357,time step,خطوة زمنية,خطوة زمنية,خطوة زمنية,时间步长,时间步长,时间步长,pas de temps,pas de temps,pas de temps,タイムステップ,タイムステップ,時刻ステップ,шаг времени,шаг времени,шаг времени
4358,time-series datum,مسند السلاسل الزمنية,بيانات سلسلة الزمن,بيانة السلسلة الزمنية,时间序列数据,时间序列数据,时间序列数据,données de séries chronologiques,donnée de série temporelle,donnée de série chronologique,時系列データ,- 時系列データ,時系列データ,данные временного ряда,данные временных рядов,данные временного ряда
4359,time-series model,نموذج السلاسل الزمنية,نموذج السلاسل الزمنية,نموذج السلاسل الزمنية,时间序列模型,时间序列模型,时序模型,modèle de série chronologique,modèle de séries temporelles,modèle de séries chronologiques,時系列モデル,時系列モデル (じけいれつモデル),時系列モデル,модель временных рядов,модель временного ряда,модель временных рядов
4360,time/space complexity,تعقيد الزمان/المكان,التعقيد الزمني / المكاني,تعقيد الوقت/المساحة,时间/空间复杂度,时间/空间复杂度,时间/空间复杂度,complexité temps/espace,complexité en temps/espace,complexité temps/espace,時間と空間の複雑さ,時間/空間複雑度,時間/空間複雑度,сложность времени/пространства,временно-пространственная сложность,временная/пространственная сложность
4361,token,رمز مميز,- توكن,ضميم,代币,令牌,词元,jeton,jeton,jeton,トークン,トークン,トークン,жетон,токен,токен
4362,token classification,تصنيف رمزي,تصنيف الرمزيات,تصنيف الرموز المميزة,代币分类,- 术语：标记分类,标记分类,classification des jetons,classification de jetons,classification de jetons,トークンの分類,トークン分類 (Tokun Bunka),トークン分類,классификация токенов,классификация токенов,классификация токенов
4363,token embedding,تضمين الرمز المميز,تضمين الرمزية,تضمين الرمز,令牌嵌入,Token嵌入,标记嵌入,intégration de jetons,jeton d'incrustation,Plongement de jeton,トークンの埋め込み,トークン埋め込み (Token embedding),トークン埋め込み,встраивание токена,токен вложение,вложение токена
4364,token frequency,تردد رمزي,تردد العلامة,ترددات الرموز,令牌频率,令牌频率,词元频率,fréquence du jeton,fréquence du jeton,fréquence de jeton,トークンの頻度,トークン頻度,トークン頻度,частота токена,частота токенов,Частота токена
4365,token length,طول الرمز المميز,طول الرمز,طول الرمز,令牌长度,标记长度,标记长度,longueur du jeton,longueur du jeton,longueur des jetons,トークンの長さ,トークン長,トークン長,длина токена,длина маркера,длина токена
4366,token representation,تمثيل رمزي,تمثيل الرمز,تمثيل الرمز,代币表示,标记表示,符号表示,représentation symbolique,représentation de jeton,représentation de jeton,トークン表現,トークン表現 (トークンひょうげん),トークン表現,представление токена,представление токена,токенное представление
4367,token sequence,تسلسل رمزي,تسلسل الرموز,تسلسل الكلمات المفتاحية,令牌序列,标记序列,词元序列,séquence de jetons,séquence de jetons,séquence de jetons,トークンシーケンス,トークンシーケンス,トークン系列,последовательность токенов,последовательность токенов,последовательность токенов
4368,token space,مساحة رمزية,- التصنيف الفضائي,فضاء الرموز,代币空间,令牌空间,标记空间,espace de jeton,- Espace de jetons,espace de jetons,トークンスペース,トークン空間,トークン空間,пространство для токенов,пространство маркеров,пространство токенов
4369,token vector,ناقلات رمزية,متجه الرمز,متجه الرموز,标记向量,令牌向量,词元向量,vecteur de jeton,vecteur de jeton,vecteur de jetons,トークンベクトル,トークンベクトル,トークンベクトル,вектор жетона,вектор токена,векторное представление токена
4370,token vocabulary,المفردات الرمزية,مفردات الرموز,مفردات الرموز,记号词汇,token 词汇,词元词汇表,vocabulaire symbolique,vocabulaire de jeton,Vocabulaire de jetons,トークンの語彙,トークン語彙,トークン語彙,токен словарь,словарь токенов,словарь токенов
4371,token-level,مستوى الرمز المميز,مستوى الرمز,مستوى الرمز المميز,代币级别,"""['与Mimno和Blei（2011）一样，我们正在寻找违反Pr（w | k）= Pr（w | d，k）假设的情况。吉布斯抽样算法通常以采样状态的形式保留令牌级信息，但基于EM的算法通常仅保留文档-主题分布θd和主题-词分布φk。'，'",词元级别,au niveau du jeton,niveau du jeton,niveau de jetons,トークンレベル,トークンレベル,トークンレベル,уровень токена,уровень токена,на уровне токенов
4372,token-level attention,الاهتمام على مستوى الرمز,تركيز المستوى الرمزي,انتباه مستوى الرمز المميز,令牌级注意力,"""在我们的方法背后，存在一个简单的观察，即我们可以将递归神经网络所专注的词级注意力与在句子级信号上训练的任何在词级定义的度量相关联。""、“我们进一步通过消蚀研究和分析BERT在辩论中的词级注意力以及GPolS的图注意力机制来分析这些。",词元级注意力,attention au niveau du jeton,attention au niveau du jeton,attention au niveau des tokens,トークンレベルの注目,"""['私たちのアプローチの背後には、再発コネクショニストニューラルネットワークによって訓練された場合でも、トークンレベルの注意が単語レベルで定義された任意の測定と相関することができるという単純な観察があります",トークンレベルの注目,внимание на уровне токена,внимание на уровне токенов,токенизированное внимание
4373,token-level feature,ميزة على مستوى الرمز المميز,- تمييز عنصر الرمز,ميزة على مستوى الرموز,代币级特征,令牌级特征,词元级特征,fonctionnalité au niveau du jeton,caractéristique au niveau du jeton,Caractéristique au niveau des jetons,トークンレベルの機能,トークンレベルの特徴,トークンレベルの特徴,функция уровня токена,функция на уровне токена,Признак на уровне токена
4374,tokenisation,الترميز,الرمزنة,تفريق,代币化,词条化,分词,tokenisation,tokenisation,tokenisation,トークン化,トークン化,トークン化,токенизация,токенизация,токенизация
4375,tokenization,الترميز,توكينة,تشفير,代币化,"""[""这些类存储其对应模型的词汇标记到索引映射，并根据模型的特定分词过程处理输入序列的编码和解码。实现的分词器如图2（右）所示。""，""我们使用SMOR形态分割工具（Schmid等，2004; Faaß等，2010）来检测不表示简单名词组合的情况。我们排除",分词化,tokenisation,tokenisation,tokenisation,トークン化,トークン化 (とーくんか),トークン化,токенизация,токенизация,токенизация
4376,tokenization scheme,مخطط الترميز,مخطط الترميز,نظام التفريغ,代币化方案,词条化方案,词元化方案,schéma de tokenisation,schéma de tokenisation,schéma de tokenisation,トークン化スキーム,トークナイゼーションスキーム,トークン化方式,схема токенизации,схема токенизации,схема токенизации
4377,tokenizer,رمز مميز,- مقسم النصوص,معالج الكلمات,分词器,分词器 (tokenizer),分词器,tokeniseur,tokenizer,tokeniseur,トークナイザー,トークナイザー,トークナイザー,токенизатор,токенизатор,токенизатор
4378,top-1 accuracy,أعلى 1 دقة,دقة المرتبة الأولى,دقة الترتيب الأول,top-1 准确率,top-1 精度,前1准确率,précision de premier ordre,précision top-1,précision top-1,トップ1の精度,top-1 正解率,トップ1精度,точность топ-1,top-1 точность,точность-1
4379,top-down segmentation,التقسيم من أعلى إلى أسفل,التجزئة من الأعلى لأسفل,التجزئة من الأعلى إلى الأسفل,自上而下的细分,自上而下的分割,自上而下分割,segmentation descendante,segmentation top-down,segmentation descendante,トップダウンのセグメンテーション,トップダウンセグメンテーション,上位からの分割,сегментация сверху вниз,сверху-вниз сегментация,сегментация сверху вниз
4380,top-k,أعلى ك,أعلى-k,أفضل ك,前k个,top-k,前k个,top-k,"""['Ensuite, à chaque étape, nous échantillonnons le jeton suivant avec la distribution rescalée dans l'Équation 2. Nous appliquons bottom-k pour les premières N étapes de la génération avant de revenir à top-k et top-p. Bottom-k tend à générer des paraphrases avec une similarité textuelle inférieure.', 'Notez que nous utilisons toujours la combinaison d'échantillonnage top-k et top-p pour générer des échantillons plus faciles",meilleurs-k,トップ-k,上位-k,トップk,топ-к,топ-k,лучшие k
4381,top-k sampling,أخذ العينات أعلى ك,عينيات أعلى - k,أخذ أعلى k,前k个采样,top-k采样,前k个采样,échantillonnage top-k,échantillonnage top-k,échantillonnage top-k,トップ K サンプリング,トップkサンプリング,トップkサンプリング,топ-к выборка,top-k сэмплинг,Отбор топ-k
4382,top-p sampling,أخذ العينات من أعلى ف,- التحديد الأعلى-بي (top-p sampling),أخذ العينات العليا-p,前p采样,顶p抽样,顶端-p采样,échantillonnage top-p,échantillonnage top-p,échantillonnage top-p,トップレベルのサンプリング,トップpサンプリング,トップpサンプリング,топ-п выборка,выборка по верхней границе p,выборка top-p
4383,topic assignment,مهمة الموضوع,تعيين الموضوعات,موضوع تعيين,主题分配,主题分配 (Topic Assignment),主题分配,assignation de sujet,attribution de sujet,assignation de sujet,トピックの割り当て,トピック割り当て,トピック割り当て,задание темы,- Тема назначения,тематическое присвоение
4384,topic classification,تصنيف الموضوع,تصنيف الموضوعات,تصنيف المواضيع,主题分类,主题分类 (zhǔtí fēnlèi),主题分类,classement des sujets,- Classification de sujet,classification de sujets,トピックの分類,トピック分類 (Topic Classification),トピック分類,классификация тем,классификация темы,классификация тем
4385,topic detection and tracking,كشف الموضوع وتتبعه,الكشف وتتبع المواضيع,الكشف عن المواضيع وتعقبها,主题检测和跟踪,主题检测和跟踪,"主题检测和跟踪 (Topic Detection and Tracking, TDT)",détection et suivi de sujets,détection et suivi des sujets,détection et suivi de sujets,トピックの検出と追跡,トピック検出とトラッキング,トピック検出および追跡,обнаружение и отслеживание тем,обнаружение и отслеживание тематики,выявление и отслеживание тем
4386,topic distribution,توزيع الموضوع,توزيع المواضيع,توزيع الموضوع,话题分布,主题分布,主题分布,répartition des sujets,distribution de sujet,distribution des sujets,トピック配信,トピック分布,トピック分布,распределение тем,распределение темы,распределение тем
4387,topic model,نموذج الموضوع,نموذج الموضوع,نموذج الموضوع,主题模型,主题模型,主题模型,modèle de sujet,modèle de sujet,modèle de sujet,トピックモデル,トピックモデル,トピックモデル,тематическая модель,модель темы,тематическая модель
4388,topic proportion,نسبة الموضوع,نسبة المواضيع,نسبة الموضوع,主题比例,主题比例,主题比例,proportion de sujets,- Proportion de sujet,proportion des sujets,トピックの割合,トピック比率,トピック比率,пропорция темы,пропорция темы,тема пропорции
4389,topic weight,وزن الموضوع,وزن الموضوع,موضوع الوزن,主题权重,主题权重,主题权重,poids du sujet,poids du sujet,poids de sujet,トピックの重み,トピックの重み,トピック重み,вес темы,вес темы,вес темы
4390,total variation,الاختلاف الكلي,التباين الكلي,مجموع الاختلاف,总变异,总变差,全变分,variation totale,- Variation totale,variation totale,トータルバリエーション,総変動,全変動量,общее изменение,общая вариация,полное варьирование
4391,total variation distance,مسافة التباين الكلية,مسافة التباين الكلي,مسافة التغاير الكلي,总变异距离,总变差距离,全变分距离,distance de variation totale,- Distance de variation totale,distance en variation totale,総変動距離,全変動距離,全変動距離,общее расстояние изменения,расстояние общей вариации,полная вариационная дистанция
4392,toxicity detection,كشف السمية,الكشف عن السمية,اكتشاف السُميّة,毒性检测,毒性检测,毒性检测,détection de toxicité,détection de toxicité,détection de toxicité,毒性検出,毒性検出,有害性検出,обнаружение токсичности,определение токсичности,обнаружение токсичности
4393,trace norm,تتبع القاعدة,الطُّرْيقة الّتي تُقَاس بها المَسار,معيار الأثر,迹范数,迹范数,迹范数,tracer la norme,norme de trace,norme de trace,トレースノルム,トレースノルム (trace norm),トレースノルム,норма следа,следовая норма,следовая норма
4394,tracking algorithm,خوارزمية التتبع,- تتبع الخوارزمية,خوارزمية التتبع,跟踪算法,跟踪算法 (tracking algorithm),跟踪算法,algorithme de suivi,Algorithme de suivi,algorithme de suivi,追跡アルゴリズム,トラッキングアルゴリズム,トラッキングアルゴリズム,алгоритм отслеживания,алгоритм отслеживания,алгоритм отслеживания
4395,train,يدرب,التدريب,تدريب,火车,训练,训练,former,entraîner,entraîner,電車,学習 (gakushuu),学習,тренироваться,обучение,обучить
4396,train / test / dev split,تدريب / اختبار / تقسيم التطوير,- تقسيم البيانات إلى مجموعات التدريب / الاختبار / التطوير,تقسيم التدريب / الاختبار / التطوير,训练/测试/开发拆分,训练/测试/验证集拆分,训练/测试/开发划分,former / tester / diviser les développeurs,répartition entraînement / test / validation,séparation entraînement / test / dev,トレーニング / テスト / 開発の分割,トレーニング / テスト / 開発分割,訓練/テスト/開発分割,разделение поездов/тестов/разработчиков,разделение на обучающую / тестовую / валидационную выборки,разбивка на обучающий / тестовый / отладочный набор
4397,train set,مجموعة القطار,مجموعة التدريب,مجموعة التدريب,动车组,训练集,训练集,rame,- Ensemble d'entraînement,ensemble d'entraînement,列車セット,トレーニングセット,訓練データセット,поезд,train set - набор обучающих данных,обучающий набор
4398,train-test split,تقسيم اختبار القطار,التقسيم بين التدريب والاختبار,تقسيم التدريب والاختبار,训练-测试分离,训练-测试分割,训练测试划分,répartition train-test,répartition entraînement-test,séparation apprentissage-test,トレーニングとテストの分割,トレーニングテスト分割,訓練テストデータ分割,сплит поезд-тест,разделение выборки на обучающую и тестовую,разделение на обучающую и тестовую выборки
4399,train/test,تدريب / اختبار,- تدريب/اختبار,تدريب / اختبار,训练/测试,- 训练/测试,训练/测试,former/tester,entraînement/test,données d'entraînement/données de test,トレーニング/テスト,- 訓練 / テスト,訓練/テスト,поезд/тест,обучение/тестирование,обучение/тестирование
4400,trainable parameter,المعلمة القابلة للتدريب,المعلمة القابلة للتدريب,معامل قابل للتدريب,可训练参数,可训练参数,可训练参数,paramètre pouvant être entraîné,paramètre entraînable,paramètre entraînable,トレーニング可能なパラメータ,訓練可能なパラメータ,訓練可能なパラメータ,обучаемый параметр,обучаемый параметр,обучаемый параметр
4401,trainable weight,الوزن القابل للتدريب,الوزن القابل للتدريب,أوزان قابلة للتدريب,可训练重量,可训练权重 (trainable weight),可训练权重,poids entraînable,poids entraînables,poids entraînable,トレーニング可能な体重,訓練可能な重み (kunren kanōna omomi),訓練可能な重み,тренируемый вес,обучаемые веса,обучаемый вес
4402,training accuracy,دقة التدريب,دقة التدريب,دقة التدريب,训练准确度,- 训练准确率,训练准确率,précision de l'entraînement,précision d'entraînement,précision d'entraînement,トレーニングの精度,トレーニング精度 (Training Accuracy),訓練精度,точность тренировки,точность обучения,точность обучения
4403,training algorithm,خوارزمية التدريب,خوارزمية التدريب,خوارزمية التدريب,训练算法,训练算法,训练算法,algorithme de formation,algorithme d'entraînement,algorithme d'entraînement,トレーニングアルゴリズム,訓練アルゴリズム (kunren arugorizumu),訓練アルゴリズム,алгоритм обучения,алгоритм обучения,Алгоритм обучения
4404,training batch,دفعة تدريبية,دفعة التدريب,دفعة التدريب,训练批次,训练批次,训练批次,lot de formation,lot d'entraînement,lot d'entraînement,トレーニングバッチ,- 訓練バッチ,トレーニングバッチ,обучающая партия,обучающий пакет,партия обучения
4405,training corpora,التدريب الجسدي,مجموعات تدريبية,مجموعات التدريب,训练语料库,训练语料库,训练语料库,corpus de formation,corpus d'entraînement,corpus d'entraînement,トレーニングコーパス,訓練コーパス,学習コーパス,учебные корпуса,тренировочные корпуса,корпуса обучающих данных
4406,training corpus,هيئة التدريب,مجموعة تدريبية,جسم التدريب,训练语料库,训练语料库,训练语料库,corpus de formation,- Corpus d'entraînement,corpus d'entraînement,トレーニングコーパス,訓練コーパス,訓練コーパス,учебный корпус,Обучающий корпус,обучающий корпус
4407,training dataset,مجموعة بيانات التدريب,مجموعة بيانات التدريب,مجموعة البيانات التدريبية,训练数据集,训练数据集,训练数据集,ensemble de données de formation,jeu de données d'entraînement,ensemble de données d'entraînement,トレーニングデータセット,トレーニングデータセット,訓練データセット,набор обучающих данных,набор данных для обучения,обучающая выборка
4408,training datum,مسند التدريب,- تصحيح البيانات التدريبية,تدريبية بيانات,训练数据,训练数据,训练数据样本,données de formation,donnée d'entraînement,donnée d'entraînement,トレーニングデータ,訓練データ,学習データ,данные обучения,обучающий набор данных,тренировочное данное
4409,training distribution,توزيع التدريب,توزيع التدريب,توزيع التدريب,培训分布,训练数据分布,训练分布,répartition des formations,distribution d'entraînement,distribution d'entraînement,トレーニングの配布,トレーニング分布,訓練分布,распределение обучения,распределение обучения,распределение обучающих данных
4410,training dynamic,ديناميكية التدريب,الديناميكية التدريبية,دينامية التدريب,培训动态,训练动态,训练动力学,dynamique de formation,dynamique d'entraînement,Dynamique d'entraînement,ダイナミックなトレーニング,トレーニングダイナミクス (training dynamics),訓練ダイナミクス,динамика тренировок,обучение динамика,динамика обучения
4411,training epoch,عصر التدريب,دورة تدريبية,دورة تدريب,训练时期,训练周期,训练轮次,époque de formation,époque d'entraînement,époque d'entraînement,トレーニングエポック,訓練エポック (くんれんエポック),訓練エポック,эпоха обучения,эпоха обучения,эпоха обучения
4412,training error,خطأ في التدريب,خطأ التدريب,خطأ التدريب,训练误差,训练误差 (training error),训练误差,erreur de formation,erreur d'entraînement,erreur d'entraînement,トレーニングエラー,トレーニングエラー (training error),訓練誤差,ошибка обучения,ошибка обучения,ошибка обучения
4413,training example,مثال التدريب,مثال تدريب,مثال تدريبي,训练例子,训练示例,训练样本,exemple de formation,exemple d'entraînement,exemple d'entraînement,トレーニング例,トレーニング例,訓練例,пример обучения,пример обучающей выборки,пример обучения
4414,training loss,خسارة التدريب,- تكلفة التدريب,خسارة التدريب,训练损失,训练损失,训练损失,perte d'entraînement,perte d'entraînement,perte d'entraînement,トレーニングロス,トレーニング損失 (training loss),訓練損失,потеря тренировки,потеря обучения,ущерб обучения
4415,training objective,هدف التدريب,هدف التدريب,هدف التدريب,培训目标,训练目标,训练目标,objectif de formation,objectif d'entraînement,objectif d'entraînement,トレーニングの目的,訓練目的 (くんれんもくてき),学習目的,цель обучения,цель обучения,цель обучения
4416,training phase,مرحلة التدريب,مرحلة التدريب,مرحلة التدريب,训练阶段,训练阶段,训练阶段,phase de formation,- Phase d'entraînement,phase d'entraînement,トレーニング段階,トレーニングフェーズ,訓練フェーズ,этап обучения,этап обучения,этап обучения
4417,training procedure,إجراءات التدريب,- إجراء التدريب,إجراء التدريب,训练程序,训练程序,训练过程,procédure de formation,procédure d'entraînement,procédure d'entraînement,トレーニング手順,訓練手順 (くんれんしゅじゅん),訓練手順,процедура обучения,- Тренировочная процедура,процедура обучения
4418,training process,عملية التدريب,عملية التدريب,عملية التدريب,训练过程,训练过程,训练过程,processus de formation,processus d'entraînement,processus d'entraînement,トレーニングプロセス,トレーニングプロセス,学習過程,тренировочный процесс,процесс обучения,процесс обучения
4419,training sample,عينة تدريبية,عينة تدريبية,عينة التدريب,训练样本,训练样本,训练样本,échantillon de formation,échantillon d'entraînement,échantillon d'entraînement,トレーニングサンプル,トレーニングサンプル,訓練サンプル,обучающая выборка,эталон обучения,обучающий образец
4420,training set,عدة التدريبات,مجموعة التدريب,مجموعة التدريب,训练集,"""['下面我们展示网站s的更高准确性与训练集中具有相同标签t ∈ S same 的站点之间的更高相似性相关联，为我们的假设提供了证据。'，'对于评估集中的每个站点s，我们计算其相对于训练集中每个不同站点t的距离，然后将其最小距离与具",训练集,ensemble d'entraînement,Ensemble d'entraînement,ensemble d'entraînement,トレーニングセット,トレーニングセット,訓練データセット,Обучающий набор,набор обучающих данных,тренировочный набор
4421,training stability,استقرار التدريب,استقرار التدريب,استقرار التدريب,训练稳定性,训练稳定性,训练稳定性,stabilité de l'entraînement,- Stabilité de l'entraînement,stabilité d'entraînement,トレーニングの安定性,トレーニングの安定性,訓練の安定性,стабильность тренировок,стабильность обучения,стабильность обучения
4422,training step,خطوة التدريب,خطوة التدريب,خطوة التدريب,训练步骤,训练步骤,训练步数,étape de formation,étape d'entraînement,étape d'entraînement,トレーニングステップ,トレーニングステップ,訓練ステップ,этап обучения,шаг обучения,шаг обучения
4423,training task,مهمة التدريب,مهمة التدريب,تدريب المهمة,训练任务,训练任务,训练任务,tâche de formation,- Tâche d'entraînement,tâche d'entraînement,トレーニングタスク,トレーニングタスク,訓練タスク,обучающее задание,обучающая задача,тренировочная задача
4424,training time,وقت التدريب,وقت التدريب,وقت التدريب,训练时间,训练时间,训练时间,temps de formation,- Temps d'entraînement,temps d'entraînement,トレーニングの時間,トレーニング時間 (Toreningu jikan),訓練時間,Тренировочное время,время обучения,время обучения
4425,training token,رمز التدريب,رمز التدريب,رموز التدريب,训练令牌,训练标记,训练标记,jeton de formation,jeton d'entraînement,jeton d'entraînement,トレーニングトークン,トレーニングトークン,学習トークン,жетон обучения,тренировочный токен,токен обучения
4426,trajectory forecasting,التنبؤ بالمسار,التنبؤ بالمسارات,التنبؤ بالمسار,轨迹预测,轨迹预测,轨迹预测,prévision de trajectoire,- Trajectoire prévisionnelle,trajectoire prévisionnelle,軌道予測,軌道予測,軌跡予測,прогнозирование траектории,прогнозирование траектории,траекторное прогнозирование
4427,trajectory optimization,تحسين المسار,أمثلة لتحسين المسارات,تحسين المسار,轨迹优化,轨迹优化,轨迹优化,optimisation de trajectoire,optimisation de trajectoire,optimisation de trajectoire,軌道の最適化,軌道最適化,軌道最適化,оптимизация траектории,- Траекторная оптимизация,оптимизация траектории
4428,transaction database,قاعدة بيانات المعاملات,قاعدة بيانات المعاملات,قاعدة بيانات المعاملات,交易数据库,交易数据库,交易数据库,base de données des transactions,Base de données transactionnelle,base de données de transactions,トランザクションデータベース,トランザクションデータベース (TBD),トランザクションデータベース,база данных транзакций,база данных транзакций,база транзакций
4429,transductive learning,التعلم الانتقالي,التعلم النقلي,التعلم التفاعلي,转导式学习,迁移学习,直推学习,apprentissage transductif,apprentissage transductif,apprentissage transductif,変換学習,直接学習 (chokusetsu gakushū),転移学習,трансдуктивное обучение,трансдуктивное обучение,трансдуктивное обучение
4430,transfer function,وظيفة النقل,وظيفة النقل,وظيفة التحويل,转换功能,传递函数,转移函数,fonction de transfert,fonction de transfert,fonction de transfert,伝達関数,転送関数 (Transfer Function),伝達関数,функция передачи,функция передачи,перенос функции
4431,transfer learning,نقل التعلم,تعلم النقل,التعلم النقلي,迁移学习,迁移学习,迁移学习,apprentissage par transfert,apprentissage par transfert,apprentissage par transfert,転移学習,転移学習 (てんいがくしゅう),転移学習,трансферное обучение,передача обучения,Перенос обучения
4432,transformation function,وظيفة التحويل,وظيفة التحويل,وظيفة التحويل,变换函数,变换函数,转换函数,fonction de transformation,fonction de transformation,fonction de transformation,変換関数,変換関数 (henkan kansū),変換関数,функция преобразования,функция преобразования,Функция преобразования
4433,transformation matrix,مصفوفة التحول,مصفوفة التحويل,مصفوفة التحويل,变换矩阵,变换矩阵,变换矩阵,matrice de transformation,matrice de transformation,matrice de transformation,変換行列,変換行列 (へんかんぎょうれつ),変換行列,матрица преобразования,матрица преобразования,матрица преобразования
4434,transformer architecture,هندسة المحولات,بنية المحولات,بِنية المُحَوِّل,变压器架构,变压器架构,转换器架构,architecture du transformateur,architecture de transformateur,architecture transformeur,変圧器のアーキテクチャ,Transformer アーキテクチャ,トランスフォーマーアーキテクチャ,Трансформаторная архитектура,архитектура трансформатора,архитектура трансформера
4435,transformer block,كتلة المحولات,مكون تحويلي - Transformer block,كتلة المحول,变压器块,Transformer 模块,转换器块,bloc transformateur,- Bloc transformateur,bloc transformateur,変圧器ブロック,トランスフォーマーブロック,トランスフォーマブロック,трансформаторный блок,блок трансформатора,блок трансформера
4436,transformer decoder,فك المحولات,مفكك تحويلي,مُفكِّر الترجمة,变压器解码器,转换器解码器,转换器解码器,décodeur de transformateur,décodeur Transformer,décodeur de transformeur,変圧器デコーダ,トランスフォーマーデコーダー (Transformer decoder),トランスフォーマデコーダ,трансформаторный декодер,трансформер-декодер,Декодер трансформатора
4437,transformer encoder,التشفير المحولات,مُشفر تَحويلي,مشفّر المحوّل,变压器编码器,Transformer编码器,变换器编码器,encodeur de transformateur,encodeur Transformer,encodeur de transformateur,変圧器エンコーダ,トランスフォーマーエンコーダー,トランスフォーマーエンコーダー,трансформаторный энкодер,трансформер-кодировщик,кодер трансформатора
4438,transformer language model,نموذج لغة المحولات,نموذج لغة المحولات,نموذج لغة المحول,变压器语言模型,变压器语言模型,转换器语言模型,modèle de langage de transformateur,modèle de langue transformateur,modèle de langage transformateur,トランスフォーマー言語モデル,トランスフォーマーランゲージモデル (transformer language model),トランスフォーマー言語モデル,языковая модель трансформера,модель языка трансформатор,модель языка трансформера
4439,transformer layer,طبقة المحولات,- التحويلة الطبقة,طبقة المحول,变压器层,变压器层,转换器层,couche de transformateur,couche de transformation,couche de transformateur,変圧器層,トランスフォーマーレイヤー,トランスフォーマー層,трансформаторный слой,трансформерный слой,слой трансформера
4440,transformer model,نموذج المحولات,نموذج المحولات,نموذج المحول,变压器型号,变形器模型,转换器模型,modèle de transformateur,- Modèle transformateur,Modèle transformateur,変圧器モデル,トランスフォーマーモデル,トランスフォーマーモデル,модель трансформера,модель трансформера,модель трансформера
4441,transformer variant,البديل المحول,المتغيرات المحولة,متغير المحول,变压器变体,变压器变体,变体转换器,variante de transformateur,variante de transformateur,variante de transformeur,変圧器のバリエーション,transformerバリアント,トランスフォーマー変種,вариант трансформера,варианты трансформатора,вариант трансформера
4442,transformer-base architecture,بنية قاعدة المحولات,الهندسة المعمارية القائمة على المحولات,هندسة القاعدة المحولة,基于变压器的架构,基于Transformer的架构,基于transformer的架构,architecture à base de transformateur,- Architecture basée sur un transformateur,architecture à base de transformateur,トランスベースのアーキテクチャ,トランスフォーマー基盤アーキテクチャ,トランスフォーマベースアーキテクチャ,Трансформаторная архитектура,архитектура на основе трансформатора,архитектура на базе трансформеров
4443,transformer-base language model,نموذج اللغة القائم على المحولات,نموذج لغة معتمد على المحولات,نموذج لغة مرتكز على تحويل,基于 Transformer 的语言模型,transformer基础语言模型,基于Transformer的语言模型,modèle de langage basé sur un transformateur,modèle de langage basé sur les transformers,modèle de langage à base de transformers,トランスフォーマーベースの言語モデル,- Transformerベース言語モデル,トランスフォーマベースの言語モデル,языковая модель на основе преобразователя,модель языка на основе трансформера,языковая модель на основе трансформера
4444,transformer-base model,نموذج قاعدة المحولات,نموذج قائم على المحولات,نموذج قائم على المحول,变压器基础模型,基于Transformer的模型,基于Transformer的模型,modèle à base de transformateur,modèle basé sur un transformateur,modèle basé sur le transformateur,トランスベースモデル,"""[""トランスフォーマーベースのモデルのハイパーパラメータの調整は行っていません。元のモデルから公開されたハイパーパラメータを使用しました。• 各手法の平均実行時間：平均して、各モデル推論実験は各例に対",トランスフォーマーベースモデル,модель на базе трансформера,модель на основе трансформера,модель на основе трансформера
4445,transformer-like,مثل المحولات,"""في هذا العمل، قمنا بدراسة وحدات خلط الرموز المبسطة لهندسة الترميز المشابهة للمحول، مما أسفر عن عدة إسهامات. أولاً، أظهرنا أن عمليات الخلط البسيطة والخطية،",التحويلات على غرار المحولات,类似变压器,变压器类,类transformer,semblable à un transformateur,semblable à un transformateur,transformeur-similaire,トランスフォーマーっぽい,- Transformerライク,トランスフォーマー様,трансформерный,похожий на трансформатор,трансформерно-подобный
4446,transition distribution,توزيع التحول,التوزيع الانتقالي,توزيع الانتقال,转移分布,过渡分布,过渡分布,distribution de transition,distribution de transition,distribution de transition,遷移分布,遷移分布 (sentei bunpu),遷移分布,переходное распределение,распределение перехода,распределение переходов
4447,transition dynamic,ديناميكية التحول,الديناميكية الانتقالية,حركية الانتقال,过渡动态,转移动态,转移动力学,dynamique de transition,dynamique de transition,dynamique de transition,ダイナミックな遷移,遷移ダイナミクス (senshi dainamikusu),遷移ダイナミクス,динамика перехода,динамика перехода (transition dynamic),динамика переходов
4448,transition function,وظيفة الانتقال,وظيفة الانتقال,دالة الانتقال,转换函数,过渡函数 (transition function),状态转移函数,fonction de transition,fonction de transition,fonction de transition,遷移関数,遷移関数,遷移関数,функция перехода,функция перехода,функция перехода
4449,transition graph,الرسم البياني الانتقالي,الرسم البياني للانتقالات,Ø±Ø³Ù Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„,转移图,过渡图,转移图,graphique de transition,graphe de transition,graphe de transition,遷移グラフ,遷移グラフ,遷移グラフ,граф перехода,граф переходов,ÐÐ¸Ð°Ð³ÑÐ°Ð¼Ð¼Ð° Ð¿ÐµÑÐµÑ�Ð¾Ð´Ð¾Ð²
4450,transition kernel,نواة الانتقال,نواة الانتقال,نواة الانتقال,过渡核,转移核,转移核,noyau de transition,noyau de transition,noyau de transition,移行カーネル,遷移カーネル,遷移カーネル,переходное ядро,переходное ядро,ядро перехода
4451,transition matrix,مصفوفة الانتقال,مصفوفة الانتقالات,مصفوفة الانتقال,转移矩阵,转移矩阵,转移矩阵,matrice de transition,- Matrice de transition,matrice de transition,遷移行列,遷移行列,遷移行列,матрица перехода,матрица перехода,матрица переходов
4452,transition model,نموذج التحول,النموذج الانتقالي,نموذج الانتقال,过渡模型,过渡模型,转移模型,modèle de transition,modèle de transition,modèle de transition,移行モデル,遷移モデル (senshi moderu),遷移モデル,переходная модель,модель перехода,модель перехода
4453,transition probability,احتمالية الانتقال,احتمالية التحول,احتمالية الانتقال,转移概率,过渡概率,转移概率,probabilité de transition,probabilité de transition,probabilité de transition,遷移確率,遷移確率 (Sen'i Kakuritsu),遷移確率,вероятность перехода,вероятность перехода,вероятность перехода
4454,transition probability model,نموذج احتمالية الانتقال,نموذج احتمالية الانتقال,نموذج احتمالية الانتقال,转移概率模型,转移概率模型,转移概率模型,modèle de probabilité de transition,modèle de probabilité de transition,modèle de probabilité de transition,遷移確率モデル,遷移確率モデル,遷移確率モデル,вероятностная модель перехода,модель вероятности перехода,модель вероятности перехода
4455,transition system,نظام انتقالي,نظام الانتقالات,نظام الانتقال,过渡系统,过渡系统,过渡系统,système de transition,système de transition,système de transition,移行システム,遷移システム,遷移システム,переходная система,Система перехода,система переходов
4456,transition-base dependency parsing,تحليل التبعية لقاعدة الانتقال,تحليل التبعية القائم على الانتقالات,تحليل الاعتمادية بالانتقال الأساسي,基于转换的依存分析,基于转移的依存分析,基于转移的依存句法分析,analyse des dépendances de base de transition,Analyse de dépendance basée sur les transitions,analyse en dépendances par transitions,遷移ベースの依存関係の解析,トランジションベースの依存構文解析 (transition-based dependency parsing),遷移ベースの依存構造解析,анализ зависимостей на базе перехода,парсинг зависимостей на основе перехода,переходный синтаксический анализ с зависимостями
4457,transition-base model,نموذج قاعدة التحول,نموذج قاعدة الانتقال,نموذج الانتقال-القاعدي,转换基础模型,过渡基模型,基于转移的模型,modèle de base de transition,modèle basé sur la transition,modèle à base de transition,移行ベースモデル,遷移ベースモデル,遷移ベースモデル,базовая модель перехода,модель на основе переходов,Переходная модель
4458,transition-base parser,محلل قاعدة الانتقال,محلل قائم على الانتقالات,محلل قائم على الانتقال,基于转换的解析器,基于转移的解析器,基于转移的解析器,analyseur de base de transition,analyseur à base de transition,analyseur par transitions,遷移ベースのパーサー,遷移ベースのパーサー (senni-bēsu no pāsā),遷移ベースパーサー,парсер базы перехода,парсер на основе переходов,переходно-основной парсер
4459,transition-base parsing,تحليل قاعدة الانتقال,تحليل قائم على الانتقالات,تحويل القواعد القائم على الانتقال,转换基础解析,转移基解析,基于转移的句法分析,analyse de base de transition,analyse en fonction de la transition,analyse par transitions,遷移ベースの解析,遷移ベースの解析,遷移ベースの構文解析,анализ базы перехода,транзитивное синтаксическое анализирование,Синтаксический анализ на основе переходов
4460,transitive closure,إغلاق متعد,الإغلاق النقلي,الإغلاق الانتقالي,传递闭包,传递闭包,传递闭包,fermeture transitive,fermeture transitive,fermeture transitive,推移閉包,推移閉包 (Transitive Closure),推移閉包,транзитивное замыкание,транзитивное замыкание,транзитивное замыкание
4461,transitive relation,علاقة انتقالية,العلاقة النقلية,علاقة تراتبية,传递关系,"""['我们要求 (一个切割平面证明) O ⪯ 必须定义一个前序关系，即一个自反和传递关系。添加新的约束 C 将是有效的，只要我们保证保留一些 f-极小解，这个解也是关于 ⪯ 最小的。'，'为了证明 (ii)，我们将 I 中的每个非简单角色 R 解释为 R J 和 R",传递关系,relation transitive,- Relation transitive,relation transitive,推移的な関係,推移的関係 (suiten-teki kankei),推移関係,транзитивное отношение,транзитивное отношение,переходное отношение
4462,translation invariance,ثبات الترجمة,التعويض الازدواجي,تعميم الانتقال,平移不变性,平移不变性,平移不变性,invariance de traduction,invariance à la translation,invariance par translation,翻訳の不変性,翻訳不変性 (honyaku fuhensei),平移不変性,трансляционная инвариантность,инвариантность перевода,инвариантность к переносу
4463,translation model,نموذج الترجمة,- ترجمة النموذج,ترجمة نموذج,翻译模型,翻译模型 (translation model),翻译模型,modèle de traduction,modèle de traduction,modèle de traduction,翻訳モデル,翻訳モデル,翻訳モデル,модель перевода,модель перевода,модель перевода
4464,translation system,نظام الترجمة,نظام الترجمة,نظام الترجمة,翻译系统,翻译系统,翻译系统,système de traduction,Système de traduction,système de traduction,翻訳システム,翻訳システム,翻訳システム,система перевода,система перевода,система машинного перевода
4465,translation vector,ناقلات الترجمة,- ترجمة الناقل (translation vector),ناقِل الترجمة,翻译向量,平移向量,平移向量,vecteur de traduction,vecteur de translation,vecteur de translation,翻訳ベクトル,- 翻訳ベクトル (honyaku bekutoru),並進ベクトル,вектор перевода,вектор смещения,вектор перемещения
4466,transliteration,حرفي,الترجمة,نقل,音译,音译 (transliteration),音译,translitération,translittération,transcription,音訳,転写,音訳,транслитерация,транслитерация,транслитерация
4467,transpose,تبديل موضع,المعكوس,عَكْس,转置,"""['尽管算法的推导假定数据无噪声，但该算法旨在处理中等噪声，我们将很快指出。符号。令z为R K或C K中的向量，z的转置为z T。', '当每个类别的可靠性另外由整体可靠性（通过方程（2）计算）补充时，我们计算C n 为：\n",转置,transposer,transposer,transposée,転置,転置,転置,транспонировать,транспонировать,транспонирование
4468,transposition table,جدول التحويل,جدول التبديل,جدول التبادل,换位表,置换表,转置表,tableau de transposition,table de transposition,Table de transposition,移調テーブル,転置表,転置表,таблица транспонирования,таблица транспозиции,транспозиционная таблица
4469,travel salesman problem,مشكلة بائع السفر,مشكلة بائع السفر,مشكلة البائع المتجول,旅行推销员问题,旅行推销员问题,旅行推销员问题,problème de vendeur de voyages,Problème du voyageur de commerce,Problème du voyageur de commerce,旅行セールスマン問題,巡回セールスマン問題,旅行販売員問題,проблема с продавцом туристических услуг,Проблема коммивояжера,задача коммивояжера
4470,tree data structure,هيكل بيانات الشجرة,هيكل بيانات شجري,هيكل بيانات شجري,树形数据结构,树数据结构,树形数据结构,structure de données arborescente,- Structure de données arborescente,structure de données arborescente,ツリーデータ構造,木構造データ,木構造データ,древовидная структура данных,дерево структуры данных,дерево данных
4471,tree decomposition,تحلل الشجرة,تحلل الشجرة,تفكيك الشجرة,树分解,树分解,树分解,décomposition des arbres,décomposition arborescente,décomposition arborescente,ツリーの分解,木分解,木分解,разложение дерева,декомпозиция дерева,декомпозиция дерева
4472,tree depth,عمق الشجرة,عمق الشجرة,عمق الشجرة,树深度,树深度,树深度,profondeur de l'arbre,- Profondeur de l'arbre,profondeur de l'arbre,木の深さ,木の深さ,木の深さ,глубина дерева,глубина дерева,глубина дерева
4473,tree ensemble,فرقة الشجرة,تجميع الأشجار,تجميع الأشجار,树群,树集成,树集成,ensemble d'arbres,ensemble d'arbres,ensemble d'arbres,ツリーアンサンブル,木のアンサンブル,木構造アンサンブル,ансамбль деревьев,ансамбль деревьев,набор деревьев
4474,tree search,بحث الشجرة,بحث الشجرة,بحث الشجرة,树搜索,树搜索,树搜索,recherche dans l'arborescence,recherche arborescente,recherche arborescente,樹木探索,木検索 (ki kensaku),木探索,поиск по дереву,дерево поиска,дерево поиска
4475,tree structure,هيكل الشجرة,هيكل شجري,شجرة هيكلية,树结构,树结构,树形结构,arborescence,structure arborescente,structure arborescente,ツリー構造,木構造,木構造,древовидная структура,структура дерева,древовидная структура
4476,tree width,عرض الشجرة,عرض الشجرة,عرض الشجرة,树宽,树宽,树宽,largeur de l'arbre,largeur de l'arbre,largeur d'arbre,木の幅,木幅,木の幅,ширина дерева,ширина дерева,ширина дерева
4477,tree-base model,نموذج قاعدة الشجرة,نموذج مبني على شجرة,نموذج شجري الأساس,树基模型,基于树模型,基于树的模型,modèle arborescent,modèle basé sur un arbre,modèle arborescent,ツリーベースモデル,木構造モデル (ki kouzou moderu),木構造ベースモデル,древовидная модель,модель на основе дерева,Модель на основе деревьев
4478,treebank annotation,شرح ضفة الشجرة,تعليقات شجرة النصوص,ترميز البنك الشجري,树库注释,树库标注,树库标注,annotation du banc d'arbres,annotation de corpus arboré,annotation de treebank,ツリーバンクの注釈,木構造アノテーション (treebank annotation),構文木銀行アノテーション,аннотация древовидного дерева,аннотация деревьевных банков,аннотация трибанка
4479,tri-gram,ثلاثي جرام,- تراي-جرام,مثلاثي,三连词,三元组,三元模型,trigramme,tri-gramme,tri-gramme,トリグラム,トライグラム,トリグラム,триграмма,триграмма,триграмма
4480,triangle inequality,عدم المساواة المثلث,- التباين المثلثي,نظرية عدم المساواة المثلثية,三角不等式,三角不等式,三角不等式,inégalité triangulaire,- Inégalité triangulaire,inégalité triangulaire,三角不等式,三角不等式,三角不等式,неравенство треугольника,- Треугольное неравенство,треугольное неравенство
4481,trifocal tensor,موتر ثلاثي البؤرة,تنسرثل ثلاثي,دالة ثلاثية المحاور,三焦点张量,三焦张量,三焦张量,tenseur trifocal,tenseur trifocal,tenseur trifocal,三重焦点テンソル,三焦点テンソル (Sanjōten Tensor),三焦点テンソル,трифокальный тензор,трифокальный тензор,трёхфокальный тензор
4482,trigger model,نموذج الزناد,نموذج التنشيط,نموذج الاستدعاء,触发模型,触发模型,触发模型,modèle de déclenchement,modèle de déclenchement,modèle de déclenchement,トリガーモデル,トリガーモデル,発火モデル,триггерная модель,модель триггера,срабатывающая модель
4483,trigram language model,نموذج لغة التريجرام,نموذج لغة ثلاثية الأبعاد,نموذج لغة الثلاثية,三元语言模型,三元语言模型,三元语言模型,modèle de langage trigramme,modèle de langage trigramme,modèle de langage trigramme,トライグラム言語モデル,trigram言語モデル,3グラム言語モデル,языковая модель триграммы,триграммная языковая модель,модель триграммного языка
4484,trigram model,نموذج تريجرام,نموذج ثلاثي الكلمات,نموذج الثلاثي,三字模型,三元模型,三元模型,modèle de trigramme,modèle de trigramme,modèle trigramme,トライグラムモデル,三連モデル,3グラムモデル,модель триграммы,триграммная модель,Модель триграмм
4485,trilinear interpolation,الاستيفاء ثلاثي الخطوط,التداخل الثلاثي الأبعاد,التربيع الخطي الثلاثي,三线性插值,三线性插值,三线性插值,interpolation trilinéaire,interpolation trilinéaire,interpolation trilinéaire,三重線形補間,三線形補間 (trilinear interpolation),三次線形補間,трилинейная интерполяция,трилинейная интерполяция,Трилинейная интерполяция
4486,trimap,com.trimap,ترايماب,صورة الخريطة الثلاثية,三图,三通道图,三元图,trimape,"""['En particulier, le cas difficile du détourage d'images naturelles, qui ne pose aucune restriction sur l'arrière-plan, a reçu beaucoup d'attention de la recherche. Reconnaissant que le problème est intrinsèquement sous-déterminé, toutes les méthodes existantes exigent que l'utilisateur fournisse des contraintes supplémentaires sous la forme d'un trimap [2,14,4] ou d'un ensemble de traits de pinceau [16,7,5].', 'Une fois",carte à trois zones,トライマップ,トリマップ,トリマップ,тримап,траймап,трёхкарта
4487,triple,ثلاثية,ثلاثيات,ثلاثي,三倍,三元组,三元组,tripler,"""['Un mécanisme d'attention graphique statique code les graphiques récupérés pour un message afin d'augmenter la représentation sémantique du message, ce qui peut aider à comprendre le message. Un mécanisme d'attention graphique dynamique lit attentivement les graphiques de connaissances et les triplets de chaque graphique, puis utilise les informations sémantiques des graphiques et des triplets pour une meilleure génération de réponses.', 'ConceptNet construit des triplets en utilisant des arêtes ét",triple,トリプル,トリプル,三つ組,тройной,тройки,тройки
4488,triplet,ثلاثية,ثلاثي,ثلاثية,三联体,三元组,三元组,triolet,triplet,triplet,三つ子,"""['We also would like to compare to alternative approaches able to learn directly from triplets (without embedding as a first step). However, to the best of our knowledge, TripletBoost is the only method able to do classification using only passively obtained triplets.', 'Additionally, encoding both the head event and the tail event with the pretrained language model successfully takes advantage of semantic information. Problem Formulation Given a CSKG G = ( N , V ) , where N is the set of nodes and V is the set of edges , we consider a single training instance as a",三つ組,триплет,"""['Мы также хотели бы сравнить с альтернативными подходами, способными обучаться напрямую на тройках (без встраивания как первого шага). Однако, насколько нам известно, TripletBoost - единственный метод, способный классифицировать, используя только пассивно полученные тройки.', 'Кроме т",трипле́т
4489,triplet loss,خسارة ثلاثية,خسارة الثلاثيات,خسارة الثلاثي,三重态损失,三元损失,三元组损失,perte de triplet,perte de triplet,perte de triplet,トリプレットロス,"""['Wohlhart and Lepetit (2015) introduced a CNN-based descriptor learning approach using a triplet loss that minimizes/maximizes the Euclidean distance between similar/dissimilar object orientations. In addition, the distance between different objects is maximized. Although mixing in synthetic data, the training also relies on pose-annotated sensor data.', 'We use the code provided by the authors of [47]. 13 We train a 4-dimensional feature representation of the hidden states for for 200 epochs using the triplet loss of [47",トリプレット損失,тройная потеря,потеря триады,потрипотерь
4490,true positive rate,معدل إيجابي حقيقي,معدل الإيجابيات الصحيحة,معدل الإيجابية الحقيقي,真阳性率,真正率,真正正例率,taux de vrais positifs,taux de vrais positifs,taux de vrais positifs,真陽性率,真陽性率 (shin-yousei-ritsu),真陽性率,истинно положительный показатель,- Правильная положительная оценка,коэффициент истинно-положительных случаев
4491,truth assignment,مهمة الحقيقة,تخصيص الحقيقة,تعيين القيم الصدقية,真值分配,真值赋值,真值赋值,mission de vérité,attribution de vérité,attribution de vérité,真実の割り当て,真理値割当,真理値割り当て,назначение истины,назначение истины,присвоение значений истинности
4492,tuple,مترابطة بيانية,صفّ,حُزْمَة,元组,元组,元组,tuple,tuple,tuple,タプル,タプル,タプル,кортеж,кортеж,кортеж
4493,tuplex,توبليكس,الزوجية,تبلكس,双联体,元组 (tuplex),元组,tuplex,tuplex,tuplex,ツープレックス,タプレックス,タプレックス,дуплекс,туплекс,кортеж
4494,ture machine,آلة تلح,آلة تورنج,آلة تورنج,真正的机器,图灵机,图灵机,machine à coudre,machine de Turing,machine de Turing,マシン,チューリングマシン,チューリングマシン,тюрная машина,машина Тьюринга,машина Тьюринга
4495,turing reduction,تخفيض تورينج,التقليص تورينغ,اختزال تيورنج,图灵约简,图灵约简,图灵归约,réduction de Turing,- Réduction de Turing,réduction de Turing,チューリングリダクション,チューリング還元,チューリング還元,сокращение Тьюринга,тердинговское сокращение,туринговское сведение
4496,turing test,اختبار تورينج,- التحقق من تورنغ,اختبار تورنغ,图灵测试,图灵测试,图灵测试,test de Turing,test de Turing,test de Turing,チューリングテスト,チューリング・テスト,チューリングテスト,тест Тьюринга,тест Тьюринга,тест Тьюринга
4497,two-class classification,تصنيف من فئتين,التصنيف الثنائي,تصنيف ثنائي الفئة,二类分类,两类分类,二分类,classement en deux classes,classification à deux classes,classification binaire,2クラス分類,2クラス分類 (にクラスぶんるい),二値分類,двухклассовая классификация,двухклассовая классификация,бинарная классификация
4498,two-player zero-sum game,لعبة لاعبين محصلتها صفر,لعبة صفرية الفائدة بلاعبين,لعبة صفرية المجموع بين لاعبين اثنين,两人零和博弈,二人零和博弈,两人零和博弈,jeu à somme nulle à deux joueurs,jeu à somme nulle à deux joueurs,jeu à somme nulle à deux joueurs,2人プレイのゼロサムゲーム,二人零和ゲーム,2人ゼロ和ゲーム,игра для двух игроков с нулевой суммой,двухигровая игра с нулевой суммой,двухсторонняя игра с нулевой суммой
4499,type embedding,اكتب التضمين,تضمين النوع,تضمين النوع,类型嵌入,类型嵌入,类型嵌入,intégration de type,intégration de type,Plongement typologique,型の埋め込み,タイプ埋め込み (Type embedding),型埋め込み,встраивание типа,типовое вложение,разновидность встраивания
4500,u-statistic,u-إحصائية,معيار يوستاتيستيك,إحصائية-يو,u统计量,U-统计量,U型统计量,u-statistique,U-statistique,statistique-U,u 統計,U-統計量,U統計量,u-статистика,U-статистика,U-статистика
4501,unary atom,الذرة الأحادية,ذرة أحادية,ذرة أحادية,一元原子,一元原子,一元原子,atome unaire,atome unaire,atome unaire,単項原子,単項アトム,単項原子,унарный атом,унарный атом,унарный атом
4502,unary constraint,القيد الأحادي,قيد أحادي,قيد أحادي,一元约束,一元约束,一元约束,contrainte unaire,contrainte unaire,contrainte unaire,単項制約,単項制約 (tanko seiyaku),単一制約,унарное ограничение,унитарное ограничение,унарное ограничение
4503,unary feature,الميزة الأحادية,ميزة أحادية,ميزة أحادية,一元特征,一元特征,单元特征,caractéristique unaire,caractéristique unaire,caractéristique unaire,単項特徴,単項特徴,単一特徴量,унарная функция,унарная характеристика,унарная характеристика
4504,unary potential,الإمكانات الأحادية,المحتمل الأحادي,وحيد القوة,一元势,一元势能,一元势,potentiel unaire,potentiel unaire,potentiel unaire,単項ポテンシャル,単項ポテンシャル,ユナリポテンシャル,унарный потенциал,Унарный потенциал,унарный потенциал
4505,unary predicate,المسند الأحادي,مفترض أحادي,مِصْدَاق أُحَادِي,一元谓词,一元谓词,一元谓词,prédicat unaire,prédicat unaire,prédicat unaire,単項述語,一項述語 (unary predicate),単項述語,унарный предикат,унарный предикат,унарный предикат
4506,unary production,الإنتاج الأحادي,الإنتاج الأحادي,إنتاج أحادي,一元产生式,一元生成,单元规则,production unaire,production unaire,production unaire,単項生成,一項式生成,単項生成規則,унарное производство,унитарное производство,унарное правило
4507,unbiased estimate,تقدير غير متحيز,تقدير غير متحيز,تقدير غير متحيز,无偏估计,无偏估计,无偏估计,estimation impartiale,estimation impartiale,estimation non biaisée,不偏推定,"""['私たちは、短い、切り詰められたアンロールを使用してバイアスのない勾配推定法を紹介します。これをPersistent Evolution Strategies（PES）と呼びます。PESでは、部分的なアンロールごとに外部パラメータが経験した摂動を蓄積します。これは、通常のESとは",不偏推定値,несмещенная оценка,непредвзятая оценка,неискаженная оценка
4508,unbiased estimator,مقدر غير متحيز,مقدر غير متحيز,مقدر غير متحيز,无偏估计量,无偏估计器,无偏估计量,estimateur sans biais,estimateur non biaisé,estimateur sans biais,不偏推定量,不偏推定量,偏りのない推定量,несмещенная оценка,неискаженный оценщик,непредвзятая оценка
4509,uncertainty,ريبة,عدم اليقين,عدم اليقين,不确定,不确定性,不确定性,incertitude,incertitude,incertitude,不確実性,不確実性 (fukakusei),不確実性,неопределенность,неопределенность,неопределенность
4510,uncertainty measure,قياس عدم اليقين,مقياس عدم اليقين,مقياس عدم اليقين,不确定性测度,不确定性度量,不确定性度量,mesure d'incertitude,Mesure d'incertitude,Mesure d'incertitude,不確実性の尺度,不確実性尺度,不確実性尺度,мера неопределенности,мера неопределенности,неопределенность
4511,uncertainty modeling,نمذجة عدم اليقين,نمذجة الغموض,نمذجة عدم اليقين,不确定性建模,不确定性建模,不确定性建模,modélisation de l'incertitude,modélisation de l'incertitude,modélisation de l'incertitude,不確実性モデリング,不確実性モデリング (Fukakujitsusei Moderingu),不確実性モデリング,моделирование неопределенности,моделирование неопределенности,моделирование неопределенности
4512,uncertainty sampling,أخذ عينات من عدم اليقين,عينة الشكوك,اختيار العينات القائم على عدم اليقين,不确定性抽样,不确定性采样,不确定性采样,échantillonnage d'incertitude,échantillonnage d'incertitude,échantillonnage d'incertitude,不確実性サンプリング,不確実性サンプリング (fukakusei-sa sanpuringu),不確実性サンプリング,выборка по неопределенности,сэмплирование неопределенности,выборка неопределенности
4513,undirected graph,رسم بياني غير موجه,رسم بياني غير موجه,رسم بياني غير موجه,无向图,"""['一个无向图由一组节点和一组边组成，每个边都是节点对{u,v}中无序的。', '每次爬取都包含超过10亿个不同的网络图边。无向连接组件。在下一组实验中，我们将网络图视为无向图，并找到无向组件的大小。', '我们将Ω表示为一个无向图(V，E)，每个单词类型都有一个",无向图,graphe non orienté,graphe non orienté,graphe non orienté,無向グラフ,無向グラフ,無向グラフ,неориентированный граф,ненаправленный граф,неориентированный граф
4514,undirected graphical model,نموذج رسومي غير موجه,النموذج الرسمي غير الموجه,نموذج رسومي غير موجه,无向图模型,无向图模型,无向图形模型,modèle graphique non orienté,modèle graphique non-dirigé,modèle graphique non orienté,無向グラフィカルモデル,非指向性グラフィカルモデル,無向グラフィカルモデル,неориентированная графическая модель,ненаправленная графическая модель,неориентированная графическая модель
4515,uniform convergence,التقارب الموحد,- تقارب موحد,تقارب موحد,一致收敛,一致收敛,一致收敛,convergence uniforme,convergence uniforme,convergence uniforme,一様収束,一様収束 (いちゅうしゅうそく),一様収束,равномерная сходимость,однородная сходимость,равномерная сходимость
4516,uniform distribution,توزيع موحد,التوزيع المتساوي,توزيع متجانس,均匀分布,均匀分布,均匀分布,distribution uniforme,- Distribution uniforme,distribution uniforme,一様分布,一様分布,一様分布,равномерное распределение,равномерное распределение,равномерное распределение
4517,uniform information density hypothesis,فرضية كثافة المعلومات الموحدة,فرضية كثافة المعلومات الموحدة,"فرضية كثافة المعلومات المتجانسة

UID (uniform information density hypothesis)",均匀信息密度假说,信息密度均匀假设,均匀信息密度假说,hypothèse de densité d'information uniforme,- Hypothèse de densité d'information uniforme,hypothèse de densité uniforme de l'information,均一情報密度仮説,均一情報密度仮説,一様情報密度仮説,гипотеза равномерной плотности информации,гипотеза равномерной плотности информации,гипотеза равномерной информационной плотности
4518,uniform sampling,أخذ العينات موحدة,- توزيع موحد,أخذ عينات موحدة,均匀抽样,均匀抽样,均匀采样,échantillonnage uniforme,échantillonnage uniforme,échantillonnage uniforme,均一サンプリング,一様サンプリング (uniform sampling),一様サンプリング,равномерная выборка,равномерная выборка,равномерная выборка
4519,unigram count,عدد يونيجرام,عدد الوحدات,عدد المفردات,一元词计数,一元计数,一元模型计数,nombre d'unigrammes,comptage unigramme,Compte unigramme,ユニグラム数,ユニグラムカウント,単語出現回数,количество униграмм,количество униграмм,подсчет униграмм
4520,unigram distribution,توزيع يونيجرام,توزيع الوحدة,توزيع أحادي الكلمات,一元分布,单字分布,一元模型分布,distribution d'unigrammes,- Distribution unigram,distribution unigramme,ユニグラム分布,一語分布 (ichigo bunpu),一文字単位の分布,униграммное распределение,униграммное распределение,распределение униграмм
4521,unigram language model,نموذج لغة يونيجرام,- تصميم لغوي أحادي الكلمة,نموذج لغة أحادي الكلمة,一元语言模型,unigram 语言模型,一元语言模型,modèle de langage unigramme,modèle de langue unigramme,modèle de langue unigramme,ユニグラム言語モデル,ユニグラム言語モデル,単語言語モデル,языковая модель униграммы,униграммная языковая модель,Модель униграммного языка
4522,unigram model,نموذج يونيجرام,- تصميم النموذج الأحادي,نموذج أحادي الكلمة,一元模型,unigram模型,一元模型,modèle unigramme,modèle unigramme,modèle unigramme,ユニグラムモデル,ユニグラムモデル,単語モデル,модель униграммы,униграммная модель,модель униграммы
4523,union bind,ربط الاتحاد,الربط الموحّد,ربط الاتحاد,联合绑定,联合限制,联合边界,liaison syndicale,liaison d'union,union bound,ユニオンバインド,和集合バインド,和束縛,связывание союза,связывание объединения,объединенная оценка
4524,union of conjunctive query,اتحاد الاستعلام الملتحمة,اتحاد الاستعلام المشترك,اتحاد استعلام تلازمي,连接查询的并集,UCQ联合查询,连接查询并集,union de requête conjonctive,union de requête conjonctive,union de requêtes conjonctives,接続クエリの結合,共通クエリの結合,結合条件付き問合せの和,объединение конъюнктивного запроса,объединение конъюнктивных запросов,объединение конъюнктивных запросов
4525,unit propagation,انتشار الوحدة,انتشار الوحدة,انتشار الوحدة,单位传播,单元传播 (unit propagation),单位传播,propagation unitaire,propagation d'unité,propagation unitaire,ユニットの伝播,単位伝搬,単位伝播,распространение единицы,пропагация единичных единиц,распространение единичного присваивания
4526,unit sphere,مجال الوحدة,كرة وحدة,الكرة الوحدة,单位球体,单位球,单位球面,sphère unitaire,sphère unité,sphère unité,単位球,単位球,単位球,единичная сфера,единичная сфера,единичная сфера
4527,universal approximation,التقريب العالمي,تقريب عالمي,تقريب عالمي,万能近似,通用逼近,通用近似,approximation universelle,approximation universelle,Approximation universelle,普遍的な近似,普遍的近似 (fuhenteki kinji),ユニバーサル近似能力,универсальное приближение,универсальная аппроксимация,универсальная аппроксимация
4528,universal approximator,تقريب عالمي,المُقرب العالمي,مُقارِب شامل,万能逼近器,通用逼近器,通用逼近器,approximateur universel,approximator universel,approximateur universel,ユニバーサル近似器,ユニバーサル近似器,万能近似関数,универсальный аппроксиматор,универсальный аппроксиматор,универсальный аппроксиматор
4529,universal model,نموذج عالمي,النموذج العالمي,نموذج عالمي,通用模型,通用模型,通用模型,modèle universel,modèle universel,modèle universel,ユニバーサルモデル,ユニバーサルモデル,汎用モデル,универсальная модель,универсальная модель,универсальная модель
4530,unlabeled datum,مسند غير مسمى,البيانات غير المعلمة,بيانات غير موسومة,未标记数据,未标记的数据,未标注数据,donnée sans étiquette,donnée non étiquetée,données non étiquetées,ラベルのないデータム,未ラベルのデータ,データなし,немаркированные данные,неразмеченные данные,неразмеченные данные
4531,unlexicalized grammar,القواعد غير المعجمية,قواعد اللغة غير الموجودة في القاموس,قواعد نحوية غير معجمية,非词汇化语法,非词汇化语法,无词汇语法,grammaire non lexicalisée,grammaire non lexicale,grammaires non lexicalisées,語彙化されていない文法,非レキシカライズされた文法 (hi-rekishikaraizusareta bunpou),非語彙化文法,нелексикализованная грамматика,неликсикализованная грамматика,неупорядоченная грамматика
4532,unnormalized probability,احتمال غير طبيعي,الاحتمال غير المعياري,احتمال غير معياري,非标准化概率,未归一化概率,未标准化概率,probabilité non normalisée,probabilité non normalisée,probabilité non normalisée,非正規化確率,非正規化確率,非正規化確率,ненормированная вероятность,ненормализованная вероятность,ненормализованная вероятность
4533,unsolvability,عدم القدرة على الحل,- التعذر,غير قابلية الحل,不可解性,不可解性,不可解性,insolvabilité,impossibilité de résolution,indécidabilité,解決不可能性,- 不可解性,解けない性質,неразрешимость,неразрешимость,непреодолимость
4534,unsupervised algorithm,خوارزمية غير خاضعة للرقابة,- تحليل البيانات بدون إشراف,خوارزمية غير مراقبة,无监督算法,无监督算法,无监督算法,algorithme non supervisé,algorithme non supervisé,algorithme non supervisé,教師なしアルゴリズム,教師なしアルゴリズム,教師なし学習アルゴリズム,неконтролируемый алгоритм,неконтролируемый алгоритм,неконтролируемый алгоритм
4535,unsupervised approach,نهج غير خاضعة للرقابة,- تقنية غير موجهة,نهج غير موجّه,无监督方法,- 无监督方法,无监督方法,approche non supervisée,- Approche non supervisée,approche non supervisée,教師なしアプローチ,非監督アプローチ,教師なしアプローチ,неконтролируемый подход,неконтролируемый подход,неконтролируемый подход
4536,unsupervised classification,تصنيف غير خاضع للرقابة,التصنيف غير المراقب,تصنيف غير موجه,无监督分类,无监督分类,无监督分类,classification non supervisée,classification non supervisée,classification non supervisée,教師なし分類,教師なし分類 (unsupervised classification),教師なし分類 (kyōshinarashi bunrui),неконтролируемая классификация,ненадзорная классификация,несупервизированная классификация
4537,unsupervised clustering,التجمعات غير الخاضعة للرقابة,تجميع غير مراقب,تجميع غير مُراقب,无监督聚类,无监督聚类,无监督聚类,clustering non supervisé,clustering non supervisé,regroupement non supervisé,教師なしクラスタリング,非監督型クラスタリング (hikanshukata kurasutaringu),教師なしクラスタリング,неконтролируемая кластеризация,неконтролируемая кластеризация,несупервизированная кластеризация
4538,unsupervised datum,مسند غير خاضعة للرقابة,- تحديد البيانات غير المراقبة,بيانات غير مُشرف عليها,无监督数据,无监督数据,无监督数据,donnée non supervisée,donnée non supervisée,donnée non supervisée,教師なしデータム,監督されていないデータ,教師なしデータ,неконтролируемые данные,ненадзорные данные,несупервизорное данное
4539,unsupervised discovery,اكتشاف غير خاضع للرقابة,اكتشاف غير موجه,اكتشاف غير مراقب,无监督发现,无监督发现,无监督发现,découverte non supervisée,découverte non supervisée,découverte non supervisée,監視されていない発見,非監督学習発見,無監視発見,неконтролируемое открытие,"""['Например, SRN, которые видели только объекты с постоянного расстояния, способны безупречно воспроизводить крупные планы этих объектов. Мы оцениваем SRN на различных сложных задачах компьютерного зрения в 3D, включая синтез нового вида, реконструкцию",неконтролируемое обнаружение
4540,unsupervised disentanglement,تفكك غير خاضعة للرقابة,- التمزيق غير المراقب,فك الترابط غير الموجه,无监督解开,非监督解缠 (unsupervised disentanglement),无监督解纥,démêlage sans surveillance,désenchevêtrement non supervisé,désembrouillage non supervisé,監視されていない解きほぐし,監督されていない分離,教師なし解体,неконтролируемое распутывание,"""['Мы также обнаружили, что неуправляемое разделение является свойством нашей модели, которое проявляется уже в самом начале обучения (рис. 6). Обратите внимание, как наша модель синтезирует отдельные объекты, прежде чем расходовать ресурсы на представление фона.', 'Посколь",несупервизорное разделение
4541,unsupervised domain adaptation,التكيف مع المجال غير الخاضع للرقابة,التكيف مجال غير مراقب,التكيف غير المُشرَف للمجال,无监督域适应,无监督领域自适应,无监督域适应,adaptation de domaine non supervisée,adaptation de domaine non supervisée,adaptation de domaine non supervisée,教師なしドメイン適応,非監督ドメイン適応,教師なし領域適応,неконтролируемая адаптация домена,необученная доменная адаптация,неконтролируемая адаптация доменов
4542,unsupervised feature learning,ميزة التعلم غير الخاضعة للرقابة,تعلم الميزات غير المراقبة,تعلم المميزات غير الخاضعة للإشراف,无监督特征学习,非监督特征学习,无监督特征学习,apprentissage de fonctionnalités non supervisé,apprentissage des caractéristiques non supervisé,apprentissage non supervisé de caractéristiques,教師なし特徴学習,"""['SPNの識別的トレーニングを画像分類ベンチマークに適用しました。 CIFAR-10とSTL-10はディープネットワークや非監督学習のための標準データセットです。どちらも10クラスの小さな画像データセットです。私たちは",教師なし特徴学習,неконтролируемое обучение функциям,неконтролируемое обучение признакам,Неконтролируемое обучение признаков
4543,unsupervised image segmentation,تجزئة الصورة غير الخاضعة للرقابة,التقسيم الصوري غير المراقب,تجزئة الصورة غير الموجهة,无监督图像分割,无监督图像分割,无监督图像分割,segmentation d'images non supervisée,segmentation d'image non supervisée,segmentation d'image non supervisée,教師なし画像セグメンテーション,非監督画像セグメンテーション,教師なし画像セグメンテーション,неконтролируемая сегментация изображений,ненадзорная сегментация изображения,несупервизированная сегментация изображения
4544,unsupervised learning,تعليم غير مشرف عليه,التعلم غير الموجه,التعلم غير المُراقب,无监督学习,无监督学习,无监督学习,apprentissage non supervisé,apprentissage non supervisé,apprentissage non supervisé,教師なし学習,教師なし学習,教師なし学習,обучение без присмотра,ненадзорное обучение,ненадзорное обучение
4545,unsupervised method,طريقة غير خاضعة للرقابة,طريقة غير مراقبة,طريقة غير مُراقبة,无监督方法,无监督方法,无监督方法,méthode non supervisée,méthode non supervisée,méthode non supervisée,教師なしメソッド,教師なし手法 (Unsupervised Method),教師なし手法,неконтролируемый метод,"""['И мы разрабатываем эффективный механизм аугментации данных, который обеспечивает устойчивость трансформации, рассматривая предсказание обычных образцов как псевдо-истину для регуляризации предсказания аугментированных образцов. Экспериментальные результаты на наборе данных DTU показ",метод без учителя
4546,unsupervised model,نموذج غير خاضع للرقابة,النموذج غير المراقب,نموذج غير مُراقب,无监督模型,无监督模型,无监督模型,modèle non supervisé,- Modèle non supervisé,modèle non supervisé,教師なしモデル,教師なしモデル,教師なしモデル,неконтролируемая модель,ненадзорная модель,ненадзорная модель
4547,unsupervised morphological segmentation,التجزئة المورفولوجية غير الخاضعة للرقابة,التقسيم الصوري غير المشروف,تجزئة صرفية غير مُراقَبة,无监督形态分割,无监督形态分割,无监督形态分割,segmentation morphologique non supervisée,segmentation morphologique non supervisée,segmentation morphologique non supervisée,教師なし形態学的セグメンテーション,非監督形態的分割,未監視形態論的分割,неконтролируемая морфологическая сегментация,неконтролируемая морфологическая сегментация,несупервизорная морфологическая сегментация
4548,unsupervised parsing,تحليل غير خاضعة للرقابة,التحليل غير المشروف,تحليل غير موجه,无监督解析,非监督解析,无监督句法分析,analyse non supervisée,analyse non supervisée,analyse non supervisée,教師なし解析,無監督構文解析,無監視構文解析,неконтролируемый анализ,ненадзорный синтаксический анализ,неконтролируемый синтаксический анализ
4549,unsupervised pre-training,التدريب المسبق غير الخاضع للرقابة,التدريب التمهيدي غير المراقب,تدريب أولي غير مُشرف,无监督预训练,无监督预训练,无监督预训练,pré-formation non supervisée,pré-entraînement non supervisé,pré-entraînement non supervisé,教師なしの事前トレーニング,教師なし事前学習,無監視事前学習,предварительная тренировка без присмотра,ненадзорное предварительное обучение,неконтролируемое предварительное обучение
4550,unsupervised representation,تمثيل غير خاضع للرقابة,التمثيل غير المراقب,تمثيل غير مُشرف,无监督代表,无监督表示,无监督表征,représentation non supervisée,représentation non supervisée,représentation non supervisée,教師なし表現,教師なし表現,教師なし表現,неконтролируемое представительство,ненадзорное представление,неконтролируемое представление
4551,unsupervised representation learning,تعلم التمثيل غير الخاضع للرقابة,تعلم التمثيل غير المراقب,التعلم التمثيلي غير الخاضع للإشراف,无监督表征学习,无监督表示学习,无监督表示学习,apprentissage des représentations non supervisé,apprentissage non supervisé de la représentation,apprentissage non supervisé de représentation,教師なし表現学習,教師なし表現学習 (Unsupervised Representation Learning),教師なし表現学習,обучение представлению без учителя,обучение представлений без учителя,ненадзорное обучение представлений
4552,unsupervised segmentation,تجزئة غير خاضعة للرقابة,التقسيم غير المراقب,التقطيع غير الخاضع للإشراف,无监督分割,非监督分割,无监督分割,segmentation non supervisée,segmentation non supervisée,segmentation non supervisée,教師なしセグメンテーション,"""機械翻訳のための非教師あり分割手法を提案し、アラビア語-英語および中国語-英語翻訳タスクの実験を行った。モデルは既存の単言語分割モデルを組み込むことができ、特定の",無監視分割,неконтролируемая сегментация,неконтролируемая сегментация,несупервизированная сегментация
4553,unsupervised system,نظام غير خاضع للرقابة,نظامٌ غير مشروف,نظام غير مُراقَب,无监督系统,无监督系统,无监督系统,système non supervisé,- Système non supervisé,système non supervisé,監視されていないシステム,非監督学習システム,教師なしシステム,неконтролируемая система,необучаемая система,несупервизированная система
4554,unsupervised word clustering,مجموعات الكلمات غير الخاضعة للرقابة,تجميع الكلمات بدون إشراف,تجميع الكلمات غير المُراقَب,无监督词聚类,无监督词聚类 (Unsupervised Word Clustering),无监督词聚类,regroupement de mots non supervisé,clustering de mots non supervisé,regroupement non supervisé de mots,教師なし単語クラスタリング,非監督学習単語クラスタリング,教師なし単語クラスタリング,неконтролируемая кластеризация слов,неконтролируемая кластеризация слов,несупервизорный кластеринг слов
4555,unweighted graph,الرسم البياني غير المرجح,unweighted graph,رَسْم بَيَانيّ غَيْرُ مُوَزَّن,未加权图,非加权图,无权图,graphique non pondéré,- Graph non pondéré,graphe non pondéré,重み付けされていないグラフ,重み付けされていないグラフ,無加重グラフ,невзвешенный график,невзвешенный граф,невзвешенный граф
4556,update function,وظيفة التحديث,وظيفة التحديث,وظيفة التحديث,更新功能,更新函数,更新函数,fonction de mise à jour,fonction de mise à jour,fonction de mise à jour,アップデート機能,更新関数,更新関数,функция обновления,функция обновления,функция обновления
4557,update rule,قاعدة التحديث,قاعدة التحديث,قاعدة التحديث,更新规则,更新规则,更新规则,mettre à jour la règle,règle de mise à jour,règle de mise à jour,更新ルール,更新規則 (koushin kisoku),更新規則,правило обновления,правило обновления,правило обновления
4558,user embedding,تضمين المستخدم,تضمين المستخدم,تضمين المستخدم,用户嵌入,用户嵌入,用户嵌入,intégration d'utilisateur,incorporation de l'utilisateur,représentation vectorielle de l'utilisateur,ユーザー埋め込み,ユーザー埋め込み,ユーザー埋め込み,пользовательское внедрение,встраивание пользователя,пользовательское вложение
4559,user utterance,كلام المستخدم,تعبير المستخدم,عبارة المستخدم,用户话语,用户话语,用户语句,énoncé de l'utilisateur,énoncé de l'utilisateur,énoncé de l'utilisateur,ユーザーの発話,ユーザ発話,ユーザ発話,высказывание пользователя,пользовательская реплика,пользовательское высказывание
4560,user-item matrix,مصفوفة عنصر المستخدم,مصفوفة المستخدمين والعناصر,مصفوفة المستخدم-العنصر,用户-项目矩阵,用户-物品矩阵,用户-物品矩阵,matrice d'éléments utilisateur,matrice utilisateur-élément,matrice utilisateur-article,ユーザーアイテムマトリックス,ユーザー-アイテム行列,ユーザー・アイテム行列,матрица пользовательских элементов,матрица пользователь-элемент,матрица пользователь-элемент
4561,utility,جدوى,الفائدة,منفعة,公用事业,效用,效用,utilitaire,utilité,utilité,ユーティリティ,効用 (kouyō),効用,полезность,полезность,полезность
4562,utility function,وظيفة المنفعة,وظيفة فائدة,دالة المنفعة,实用功能,效用函数,效用函数,fonction d'utilité,fonction d'utilité,fonction d'utilité,効用関数,ユーティリティ関数,効用関数,вспомогательная функция,функция полезности,функция полезности
4563,utterance,الكلام,تعبير,جُملة,发声,话语,发言,énonciation,énoncé,Énoncé,発言,発話,発話,высказывание,высказывание,фраза
4564,utterance encoder,تشفير الكلام,مُشفر الكلام,مترجم الجملة,语音编码器,话语编码器,话语编码器,encodeur d'énoncé,codeur d'énoncés,encodeur d'énoncés,発話エンコーダ,発話エンコーダ,発話エンコーダ,кодировщик высказываний,кодировщик высказывания,Кодировщик высказываний
4565,validation,تصديق,التحقق,تحقق,验证,验证,验证集,validation,validation,validation,検証,検証 (けんしょう),検証,Проверка,валидация,проверочный набор
4566,validation accuracy,دقة التحقق,دقة التحقق من الصحة,دقة التحقق,验证准确性,验证准确率,验证准确率,précision de la validation,précision de validation,précision de validation,検証精度,検証精度 (kensho seido),検証精度,точность проверки,точность валидации,точность проверки
4567,validation dataset,مجموعة بيانات التحقق من الصحة,مجموعة بيانات التحقق,مجموعة البيانات المعتمدة,验证数据集,验证数据集,验证数据集,ensemble de données de validation,- Dataset de validation,ensemble de validation,検証データセット,検証データセット,検証データセット,набор данных проверки,набор данных для валидации,набор данных для проверки
4568,validation datum,تاريخ التحقق من الصحة,بيانات التحقق من الصحة,بيانات التحقق,验证数据,验证数据,验证数据,donnée de validation,donnée de validation,donnée de validation,検証データ,検証データ,検証データ,данные проверки,валидационные данные,данные валидации
4569,validation loss,فقدان التحقق من الصحة,خسارة التحقق,خسارة التحقق,验证损失,验证损失,验证损失,perte de validation,perte de validation,perte de validation,検証損失,検証損失,検証損失,потеря проверки,потеря валидации,потери валидации
4570,validation performance,أداء التحقق من الصحة,أداء التحقق من الصحة,أداء التحقق,验证性能,验证性能,验证性能,performances de validation,performance de validation,performance de validation,検証パフォーマンス,検証パフォーマンス,検証パフォーマンス,производительность проверки,проверка производительности,производительность на проверочных данных
4571,validation set,مجموعة التحقق من الصحة,مجموعة التحقق من الصحة,مجموعة التحقق,验证集,验证集,验证集,ensemble de validation,- Ensemble de validation,ensemble de validation,検証セット,検証セット,検証セット,набор проверки,набор валидации,Проверочный набор данных
4572,validation split,تقسيم التحقق من الصحة,الجزء المخصص للتحقق من الصحة,التقسيم التحقّقي,验证分割,验证分割,验证集,fractionnement de validation,fraction de validation,partition de validation,検証分割,検証用分割,検証スプリット,разделение проверки,валидационное разделение,валидационная выборка
4573,value estimate,تقدير القيمة,تقدير القيمة,تقدير القيمة,价值估计,值估计,价值估计,estimation de la valeur,estimation de la valeur,estimation de valeur,価値の推定,値の推定 (Atai no Soutei),"価値推定

VE",оценка стоимости,оценка значения,оценка значения
4574,value function,وظيفة القيمة,دالة القيمة,دالة القيمة,价值函数,值函数,价值函数,fonction de valeur,fonction de valeur,fonction de valeur,値関数,価値関数 (kachi kansu),価値関数,функция значения,функция ценности,функция ценности
4575,value function approximation,تقريب دالة القيمة,تقريب دالة القيمة,وظيفة تقريب القيمة,值函数近似,值函数逼近,值函数近似,approximation de la fonction valeur,approximation de la fonction de valeur,approximation de la fonction de valeur,値関数の近似,価値関数の近似 (kachi kansu no kinji),価値関数近似,аппроксимация функции стоимости,аппроксимация функции ценности,Аппроксимация функции ценности
4576,value iteration,تكرار القيمة,التدوير القيمي,تكرار القيمة,价值迭代,数值迭代,价值迭代,itération de valeur,itération de valeur,itération de valeur,価値の反復,値反復,価値反復法,итерация значения,итерация значений,итерация значений
4577,value iteration algorithm,خوارزمية تكرار القيمة,خوارزمية التكرار القيمة,خوارزمية التكرار القيمة,值迭代算法,值迭代算法,值迭代算法,algorithme d'itération de valeur,algorithme d'itération de la valeur,algorithme d'itération de valeur,値反復アルゴリズム,価値反復アルゴリズム,価値反復アルゴリズム,алгоритм итерации значений,алгоритм итерации значений,алгоритм итерации ценности
4578,value network,شبكه قيمه,شبكة القيمة,شبكة القيمة,价值网络,数值网络 (value network),价值网络,réseau de valeur,- Réseau de valeurs,réseau de valeurs,バリューネットワーク,価値ネットワーク,価値ネットワーク,сеть создания ценности,сеть значений,сеть оценки
4579,value-base reinforcement learning,التعلم المعزز القائم على القيمة,تعلم تعزيزي قائم على القيم,تعلم التعزيز القائم على القيمة,基于价值的强化学习,值基强化学习,基于价值的强化学习,apprentissage par renforcement des valeurs,apprentissage par renforcement basé sur la valeur,apprentissage par renforcement basé sur les valeurs,価値ベースの強化学習,価値ベース強化学習,価値基底強化学習,обучение с подкреплением на основе ценностей,алгоритм обучения с подкреплением на основе ценности,обучение с подкреплением на основе ценности
4580,vanilla Transformer,محول الفانيليا,تحويلة فانيلا,محول تقليدي,香草变压器,普通Transformer,普通Transformer,Transformateur vanille,transformateur vanille,Transformateur standard,バニラトランスフォーマー,バニラ トランスフォーマー,標準Transformer,ванильный трансформер,ванильный Трансформер,базовый Transformer
4581,vanishing gradient,التدرج التلاشي,التراجع التدريجي,تضاؤل التدرج,梯度消失,梯度消失,梯度消失,dégradé qui disparaît,gradient qui disparait,gradient d'évanouissement,消失勾配,勾配消失,勾配消失,исчезающий градиент,исчезающий градиент,исчезающий градиент
4582,vanishing gradient problem,اختفاء مشكلة التدرج,مشكلة تلاشي التدرج,مشكلة التلاشي التدريجي للمتدرج,梯度消失问题,梯度消失问题,梯度消失问题,problème de gradient qui disparaît,problème du gradient qui disparaît,problème du gradient évanescent,勾配消失問題,消失勾配問題,勾配消失問題,проблема исчезающего градиента,проблема исчезающего градиента,проблема исчезающего градиента
4583,variable assignment,مهمة متغيرة,التعيين المتغير,تعيين متغير,变量赋值,变量赋值,变量赋值,affectation de variables,affectation de variable,affectation de variable,変数の代入,変数割り当て,変数割り当て,присвоение переменной,присвоение переменных,присваивание переменной
4584,variable selection,اختيار متغير,- تحديد المتغيرات,اختيار المتغيرات,变量选择,变量选择,变量选择,sélection de variables,sélection de variables,sélection de variables,変数の選択,変数選択,変数選択,выбор переменной,выбор переменных,выбор переменных
4585,variance reduction,تقليل التباين,- تقليل التباين,تقليل التباين,方差减少,方差缩减,方差缩减,réduction de l'écart,réduction de la variance,réduction de la variance,分散の削減,分散削減,分散低減,уменьшение дисперсии,уменьшение дисперсии,дисперсионное уменьшение
4586,variance regularization,تنظيم التباين,التنظيم المتغير,تنظيم التباين,方差正则化,方差正则化,方差正则化,régularisation des écarts,régularisation de la variance,régularisation de la variance,分散の正則化,分散正規化,バリアンス正則化,регуляризация дисперсии,регуляризация разброса,регуляризация дисперсии
4587,variational Bayes,بايز المتغيرة,البايز المتغيرية,بايز التفاوتي,变分贝叶斯,变分贝叶斯,变分贝叶斯,Bayes variationnel,inférence bayésienne variationnelle,Bayes variationnel,変分ベイズ,変分ベイズ,変分ベイズ,вариационный Байес,Вариационный Байес,вариационный байесовский
4588,variational approach,النهج المتغير,النهج التغيري,المقاربة التباينية,变分法,变分方法,变分方法,approche variationnelle,Approche variationnelle,approche variationnelle,変分的アプローチ,変分法 (へんぶんほう),変分アプローチ,вариационный подход,вариационный подход,вариационный подход
4589,variational approximation,تقريب التباين,التقريب التغيري,التقريب التغايري,变分近似,变分逼近,变分近似,approximation variationnelle,approximation variationnelle,approximation variationnelle,変分近似,変分近似 (henbun kinji),変分近似,вариационное приближение,вариационное приближение,вариационное приближение
4590,variational autoencoder,التشفير التلقائي المتغير,مُشفر التباين,المُرَمِّز الذاتي التغَيُّري,变分自动编码器,变分自动编码器,变分自编码器,auto-encodeur variationnel,"""['L'autoencodeur profond possède un encodeur avec des dimensions cachées de [500, 300, 100] et un décodeur avec des dimensions cachées de [100, 300, 500]. La sortie possède une sigmoïde et nous utilisons une perte d'entropie croisée sigmoïde pour la prédiction L. Autoencodeur variationnel. Nous utilisons une architecture décrite dans Higgins et al. (2017a) (Tableau 2).',",codeur automatique variationnel,変分オートエンコーダ,変分オートエンコーダ,変分オートエンコーダ,вариационный автоэнкодер,вариационный автоэнкодер,Вариационный автоэнкодер
4591,variational bind,الارتباط المتغير,- تقييد تفاعلي,رباط متغير,变分绑定,变分绑定,变分边界,liaison variationnelle,borne variationnelle,borne variationnelle,変分バインド,変分バインド,変分束縛,вариационная привязка,вариационная связка,вариационная связь
4592,variational distribution,التوزيع المتغير,التوزيع التحويلي,توزيع تغيري,变分分布,变分分布,变分分布,distribution variationnelle,distribution variationnelle,distribution variationnelle,変分分布,変分分布,変分分布,вариационное распределение,вариационное распределение,вариационное распределение
4593,variational formulation,صياغة متباينة,صياغة تفاضلية,تصور متغير,变分公式,变分形式,变分形式,formulation variationnelle,formulation variationnelle,formulation variationnelle,変分定式化,変分形式,変分形式,вариационная формулировка,вариационная формулировка,вариационная формулировка
4594,variational framework,إطار متغير,إطار تغيري,إطار تباين,变分框架,变分框架,变分框架,cadre variationnel,cadre variationnel,cadre variationnel,変分フレームワーク,変分フレームワーク,変分フレームワーク,вариационная структура,вариационная структура,вариационная модель
4595,variational inference,الاستدلال المتغير,الاستدلال التغيري,الاستدلال التباينيّ,变分推理,变分推断,变分推断,inférence variationnelle,inférence variationnelle,inférence variationnelle,変分推論,変分推論 (henbun suiron),変分推論,вариационный вывод,вариационный вывод,вариационный вывод
4596,variational low bound,الحد الأدنى المتغير,الحد السفلي المتغير,الحد الأدنى للتباين,变分下界,变分下界,变分下界,borne inférieure variationnelle,borne inférieure variationnelle,borne inférieure variationnelle,変分下限,変分下限 bound,変分下限,вариационная нижняя граница,вариационная нижняя граница,функция нижней границы
4597,variational method,طريقة التباين,الطريقة التغيرية,طريقة التفاوت,变分法,变分方法 (Biàn Fēn Fāngfǎ),变分方法,méthode variationnelle,méthode variationnelle,méthode variationnelle,変分法,変分法 (へんぶんほう),変分法,вариационный метод,вариационный метод,вариационный метод
4598,variational model,نموذج متغير,النموذج التغيري,نموذج تحوري,变分模型,变分模型,变分模型,modèle variationnel,modèle variationnel,modèle variationnel,変分モデル,変分モデル (henbun moderu),変分モデル,вариационная модель,вариационная модель,вариационная модель
4599,variational objective,الهدف المتغير,الموضوع المتغير,هدف التغاير,变分目标,变分目标,变分目标函数,objectif variationnel,objectif variationnel,Objectif variationnel,変分目標,変分目的 (へんぶんもくてき),変分目的関数,вариационная цель,вариационный объект,вариационная цель
4600,variational parameter,المعلمة المتغيرة,- تعميم المعلمة,معامل متغير,变分参数,变分参数,变分参数,paramètre variationnel,paramètre variationnel,paramètre variationnel,変分パラメータ,変分パラメータ,変分パラメータ,вариационный параметр,вариационный параметр,Вариационный параметр
4601,variational posterior,الخلفي المتغير,المؤشر الخلفي التفاضلي,المقترب البعدي التباينّي,变分后验,变分后验,变分后验分布,postérieur variationnel,postérieur variationnel,distribution postérieure variationnelle,変分事後,変分事後分布,変分事後分布,вариационный задний,Вариационное апостериорное,вариационное апостериорное распределение
4602,vector,المتجه,متجه,متجه,向量,矢量,向量,vecteur,vecteur,vecteur,ベクター,ベクトル,ベクトル,вектор,вектор,вектор
4603,vector arithmetic,ناقلات الحسابية,حساب النواقل,حسابيات المتجهات,向量算术,向量算术,向量算术,arithmétique vectorielle,arithmétique vectorielle,arithmétique vectorielle,ベクトル演算,ベクトル演算,ベクトル演算,векторная арифметика,векторная арифметика,векторная арифметика
4604,vector concatenation,تسلسل ناقلات,- توصيل الفيكتورات,ضم المتجهات,向量串联,矢量连接,向量拼接,concaténation de vecteurs,concaténation de vecteurs,concaténation de vecteurs,ベクトル連結,ベクトル連結 (vector concatenation),ベクトル連結,векторная конкатенация,конкатенация векторов,Конкатенация векторов
4605,vector embedding,تضمين ناقلات,تضمين الفيكتور,تضمين متجهي,向量嵌入,向量嵌入,向量嵌入,intégration vectorielle,incorporation de vecteurs,plongement vectoriel,ベクトル埋め込み,ベクトル埋め込み,ベクトル埋め込み,векторное встраивание,векторное вложение,векторное вложение
4606,vector field,حقل شعاعي,حقل نوعي,حقل متجهي,矢量场,矢量场,矢量场,champ de vecteur,champ de vecteurs,champ vectoriel,ベクトルフィールド,ベクトル場,ベクトル場,векторное поле,векторное поле,векторное поле
4607,vector graphic,رسم المتجهات,- تصوير بياني بيكتوري (vector graphic),رسوم متجهية,矢量图形,矢量图形,矢量图形,graphique vectoriel,graphique vectoriel,graphique vectoriel,ベクターグラフィック,ベクターグラフィックス,ベクトルグラフィック,векторная графика,векторная графика,векторная графика
4608,vector normalization,التطبيع ناقلات,تطبيع الاتجاهات,تطبيع المتجه,向量归一化,向量归一化,向量归一化,normalisation vectorielle,normalisation de vecteur,normalisation vectorielle,ベクトル正規化,ベクトル正規化,ベクトル正規化,векторная нормализация,векторная нормализация,векторная нормализация
4609,vector quantization,تكميم المتجهات,تكميم الناقل,ترميز المتجه,矢量量化,矢量量化,向量量化,quantification vectorielle,quantification de vecteur,quantification vectorielle,ベクトル量子化,ベクトル量子化,ベクトル量子化,векторное квантование,векторное квантование,векторное квантование
4610,vector representation,تمثيل المتجهات,التمثيل الاتجاهي,مصفوفة تمثيلية,矢量表示,向量表示,向量表示,représentation vectorielle,représentation vectorielle,représentation vectorielle,ベクトル表現,ベクトル表現 (bekutoru hyougen),ベクトル表現,векторное представление,векторное представление,векторное представление
4611,vector space,مساحة المتجهات,مساحة الناقل,فضاء متجهي,向量空间,矢量空间,向量空间,espace vectoriel,espace vectoriel,espace vectoriel,ベクトル空間,ベクトル空間,ベクトル空間,векторное пространство,векторное пространство,векторное пространство
4612,vector space embedding,تضمين الفضاء ناقلات,تضمين المساحة الناقلة,تضمين فضاء المتجهات,向量空间嵌入,向量空间嵌入,向量空间嵌入,intégration d'espace vectoriel,plongement d'espace vectoriel,plongement dans un espace vectoriel,ベクトル空間埋め込み,ベクトル空間埋め込み (vector space embedding),ベクトル空間埋め込み,встраивание векторного пространства,векторное пространство встраивания,векторное пространство вложений
4613,vector space model,نموذج الفضاء المتجه,نموذج المساحة الناقلة,نموذج الفضاء المتجه,向量空间模型,向量空间模型,向量空间模型,modèle spatial vectoriel,- Modèle d'espace vectoriel,modèle d'espace vectoriel,ベクトル空間モデル,ベクトル空間モデル,ベクトル空間モデル,векторная космическая модель,модель векторного пространства,модель векторного пространства
4614,vector space representation,تمثيل الفضاء المتجه,تمثيل مساحة الناقل,تمثيل فضاء المتجهات,向量空间表示,向量空间表示,向量空间表示,représentation de l'espace vectoriel,Représentation de l'espace vectoriel,représentation dans un espace vectoriel,ベクトル空間表現,ベクトル空間表現,ベクトル空間表現,векторное пространственное представление,Представление векторного пространства,векторное пространственное представление
4615,vector-valued function,دالة ذات قيمة متجهة,دالة متجهية,دالة متجه القيمة,向量值函数,矢量值函数,向量值函数,fonction à valeur vectorielle,fonction à valeurs vectorielles,fonction à valeurs vectorielles,ベクトル値関数,ベクトル値関数,ベクトル値関数,векторная функция,вектор-значеная функция,векторнозначная функция
4616,vectorization,ناقلات,عملية التجهيز إلى متجهات,تفريق,矢量化,矢量化 (Vectorization),矢量化,vectorisation,vectorisation,vectorisation,ベクトル化,ベクトル化 (bekutorika),ベクトル化,векторизация,векторизация,векторизация
4617,vectorization operator,عامل المتجهات,مشغل التجزيز الصفي,معامل التجهيز vec,向量化算子,矢量化操作符,矢量化算子,opérateur de vectorisation,- Opérateur de vectorisation,opérateur de vectorisation,ベクトル化演算子,ベクトル化演算子 (bekutorika enzanshi),ベクトル化演算子,оператор векторизации,оператор векторизации,оператор векторизации
4618,vectorize,com.vectorize,تتجهبلية,تحويل إلى متجهات,矢量化,矢量化,矢量化,vectoriser,vectoriser,vectoriser,ベクトル化,ベクトル化,ベクトル化する,векторизовать,векторизовать,векторизовать
4619,verbalizer,لفظي,المتحدث,مُصَرِّح,言语者,口头表达者,转换器,verbalisateur,verbaliseur,anaphoriseur,言語化者,- 翻訳された用語：発話者,言語化器,вербализатор,вербализатор,Вербализатор
4620,vertex label,تسمية قمة الرأس,تسمية الفقرة,وَصْفُ الرُّؤُوس,顶点标签,顶点标签,顶点标签,étiquette de sommet,étiquette de sommet,étiquette de sommet,頂点ラベル,頂点ラベル,頂点ラベル,метка вершины,Метка вершины,Метка вершины
4621,vertex set,مجموعة قمة الرأس,مجموعة الرؤوس,مجموعة القمم,顶点集,顶点集,顶点集,ensemble de sommets,"n] des paires (i, j) des arêtes dirigées v i → v j .', 'Le composant clé dans l'algorithme DSS-WL est la politique de génération de graphe π qui doit maintenir la symétrie,",ensemble de sommets,頂点セット,頂点集合,頂点集合,набор вершин,множество вершин,множество вершин
4622,victim model,نموذج الضحية,نموذج الضحية,نموذج الضحية,受害者模型,受害模型 (Victim Model),受害者模型,modèle de victime,modèle de victime,modèle victime,被害者モデル,被害モデル (Higai moderu),被害者モデル,модель жертвы,модель жертвы,модель жертвы
4623,view synthesis,عرض التوليف,تخليق الرؤية,تركيب المشهد,视图综合,视图合成,视图合成,voir la synthèse,synthèse de vue,synthèse de vues,ビューの合成,ビュー合成 (View Synthesis),視点合成,просмотреть синтез,синтез вида,синтез изображения
4624,virtual camera,الكاميرا الافتراضية,كاميرا افتراضية,كاميرا افتراضية,虚拟相机,虚拟摄像头,虚拟相机,caméra virtuelle,caméra virtuelle,Caméra virtuelle,仮想カメラ,仮想カメラ,バーチャルカメラ,виртуальная камера,виртуальная камера,виртуальная камера
4625,vision Transformer,محول الرؤية,محول الرؤية,محول الرؤية,视觉变压器,视觉变压器,视觉Transformer,Transformateur de vision,vision Transformer,Transformateur de vision,ビジョントランスフォーマー,ビジョン トランスフォーマー (Vision Transformer),ビジョン Transformer,видение Трансформатор,Визионный трансформер,Трансформер зрения
4626,vision model,نموذج الرؤية,نموذج الرؤية,نموذج الرؤية,视觉模型,视觉模型,视觉模型,modèle de vision,modèle de vision,modèle de vision,ビジョンモデル,ビジョンモデル,視覚モデル,модель видения,модель зрения,модель зрения
4627,vision system,نظام الرؤية,نظام رؤية,نظام الرؤية,视觉系统,视觉系统,视觉系统,système de vision,- Système de vision,système de vision,ビジョンシステム,ビジョンシステム,ビジョンシステム,система технического зрения,система зрения,система зрения
4628,vision-language model,نموذج لغة الرؤية,نموذج لغة الرؤية,نموذج بصري-لغوي,视觉语言模型,视觉语言模型,视觉语言模型,modèle vision-langage,modèle vision-langage,modèle vision-langage,視覚言語モデル,ビジョン言語モデル,ビジョン言語モデル,модель языка видения,модель видео-язык,модель зрения и языка
4629,visual attention,الاهتمام البصري,الانتباه البصري,إدراك بصري,视觉注意力,视觉注意力,视觉注意力,attention visuelle,attention visuelle,attention visuelle,視覚的注意,視覚的注意,視覚的注意力,визуальное внимание,визуальное внимание,визуальное внимание
4630,visual attribute,السمة البصرية,الصفة البصرية,صفة بصرية,视觉属性,视觉属性,视觉属性,attribut visuel,attribut visuel,attribut visuel,視覚属性,視覚属性,視覚的属性,визуальный атрибут,визуальный атрибут,визуальный атрибут
4631,visual context,السياق البصري,السياق البصري,تضمين بصري,视觉语境,视觉语境,视觉环境,contexte visuel,contexte visuel,contexte visuel,視覚的なコンテキスト,ビジュアルコンテキスト,視覚的コンテキスト,визуальный контекст,визуальный контекст,визуальный контекст
4632,visual cortex,القشرة البصرية,قشرة بصرية,القشرة البصرية,视觉皮层,视觉皮质,视觉皮层,cortex visuel,cortex visuel,cortex visuel,視覚野,視覚野,視覚野,зрительная кора,визуальная кора,Зрительная кора
4633,visual feature,ميزة بصرية,السمة البصرية,الميزة البصرية,视觉特征,视觉特征,视觉特征,élément visuel,caractéristique visuelle,caractéristique visuelle,視覚的な特徴,視覚的特徴,視覚特徴,визуальная особенность,- Визуальные характеристики,визуальный признак
4634,visual grounding,التأريض البصري,الإرتباط المرئي,التأصيل البصري,视觉接地,视觉基础 (Visual Grounding),视觉理解,mise à la terre visuelle,ancrage visuel,ancrage visuel,視覚的なグラウンディング,- 視覚的な基礎付け (shikaku-tekina kisodzuke),視覚的アンカリング,визуальное заземление,визуальное закрепление,визуальная привязка
4635,visual hull,بدن البصرية,الهيكل البصري,الجُرم البصري,视觉船体,视觉外壳,视锥,coque visuelle,enveloppe visuelle,enveloppe visuelle,ビジュアルハル,ビジュアルハル,ビジュアル・ハル,визуальный корпус,визуальный корпус,визуальная оболочка
4636,visual localization,التوطين البصري,التموضع البصري,تحديد المواقع البصري,视觉定位,视觉定位 (Visual Localization),视觉定位,localisation visuelle,localisation visuelle,localisation visuelle,視覚的な位置特定,視覚位置特定 (shikaku ichi tokutei),視覚的位置特定,визуальная локализация,визуальная локализация,визуальная локализация
4637,visual odometry,قياس المسافة البصرية,- تقدير حركة الرؤية,المسيرة البصرية,视觉里程计,视觉里程计,视觉里程计,odométrie visuelle,odometry visuelle,odométrie visuelle,ビジュアルオドメトリ,視覚オドメトリ (shikaku odometori),視覚的オドメトリ,визуальная одометрия,визуальная одометрия,визуальная одометрия
4638,visual question answering,الإجابة على السؤال البصري,الإجابة على الأسئلة البصرية,الإجابة على الأسئلة البصرية (VQA),视觉问答,视觉问答,视觉问答,réponse visuelle aux questions,réponse aux questions visuelles,réponse aux questions visuelles,視覚的な質問応答,ビジュアル質問応答 (Visual Question Answering),視覚質問応答,визуальный ответ на вопрос,визуальное вопросно-ответное взаимодействие,визуальные вопросно-ответные системы
4639,visual recognition system,نظام التعرف البصري,النظام البصري للتعرف,نظام التعرف البصري,视觉识别系统,视觉识别系统,视觉识别系统,système de reconnaissance visuelle,système de reconnaissance visuelle,système de reconnaissance visuelle,視覚認識システム,視覚認識システム,視覚認識システム,система визуального распознавания,система визуального распознавания,система визуального распознавания
4640,viterbi decoding,فك تشفير فيتربي,فك تشفير فيتيربي,شفرة فيتربي,维特比解码,维特比解码,维特比解码,décodage de Viterbi,décodage de Viterbi,décodage de Viterbi,ビタビ復号化,ヴィタビ復号化,ビタビ復号化,расшифровка Витерби,декодирование Витерби,витербиевское декодирование
4641,vocabulary,مفردات,مفردات,مفردات,词汇,词汇量,词汇表,vocabulaire,vocabulaire,vocabulaire,語彙,"""['For the En→De translation task, sentences are encoded using bytepair encoding (BPE) (Sennrich et al., 2016) with 37k merging operations for both source and target languages, which have vocabularies of 39418 and 40274 tokens respectively. We limit the length of sentences in the training datasets to 50 words for Zh→En and 128 subwords for En→De.', ')) codes with 60K merge operations to build two vocabularies comprising 47K Chinese sub-words and 30K",語彙,словарный запас,словарь,словарь
4642,vocabulary size,حجم المفردات,حجم المفردات,حجم القاموس,词汇量,词汇量,词汇量,taille du vocabulaire,Taille du vocabulaire,taille du vocabulaire,語彙サイズ,語彙サイズ (goi saizu),語彙サイズ,размер словарного запаса,размер словаря,размер словаря
4643,vocoder,مشفر صوتي,فوكودر,مُحَوِّل صوتي,声码器,声码器,声码器,vocodeur,vocodeur,Codeur vocal,ボコーダ,ボコーダー,ボコーダー,вокодер,вокодер,Вокодер
4644,volume rendering,تمثيل الصوت,عرض الحجم,تصوير حجمي,体绘制,体积渲染,体渲染,rendu volumique,rendu de volume,rendu volumétrique,ボリュームレンダリング,ボリュームレンダリング,ボリュームレンダリング,объемный рендеринг,объемная визуализация,объёмная визуализация
4645,von Mises-Fisher distribution,توزيع فون ميزس-فيشر,توزيع فون ميزس-فيشر,توزيع فون ميسس-فيشر,冯·米塞斯·费舍尔分布,冯·米斯-费舍尔分布,冯米塞斯-菲舍尔分布,Distribution de von Mises-Fisher,distribution de von Mises-Fisher,distribution de von Mises-Fisher,フォン・ミーゼス・フィッシャー分布,フォン・ミーゼス=フィッシャー分布,フォンミーゼスフィッシャー分布,Распределение фон Мизеса-Фишера,распределение фишера фон Мизеса,распределение фон Мизеса-Фишера
4646,voting rule,قاعدة التصويت,قاعدة التصويت,قاعدة التصويت,投票规则,投票规则,投票规则,règle de vote,règle de vote,règle de vote,投票ルール,投票ルール,投票規則,правило голосования,правило голосования,Правило голосования
4647,voxel,فوكسل,- تقريب الحجم (Voxel),فقرة,体素,体素,体素,voxel,voxel,voxel,ボクセル,ボクセル,ボクセル,воксельный,воксель,воксель
4648,voxel grid,شبكة فوكسل,شبكة بكسلاتية,شبكة فوكسل,体素网格,体素网格,体素栅格,grille de voxels,grille de voxels,grille de voxels,ボクセルグリッド,ボクセルグリッド,ボクセルグリッド,воксельная сетка,воксельная сетка,Воксельная сетка
4649,voxel grid representation,تمثيل شبكة فوكسل,تمثيل الشبكة الثلاثية الأبعاد من الفوكسلات,تمثيل شبكة الكتل الحجمية,体素网格表示,体素网格表示,体素网格表示,représentation en grille de voxels,représentation en grille de voxels,représentation par grille de voxels,ボクセルグリッド表現,ボクセルグリッド表現,ボクセルグリッド表現,представление воксельной сетки,сеточное представление вокселей,представление в виде воксельной сетки
4650,voxel occupancy,إشغال فوكسل,احتلال الفوكسل,احتلال الفوكسل,体素占据,体素占用,体元占用,occupation du voxel,occupation du voxel,occupation de voxels,ボクセル占有率,ボクセル占有,ボクセル占有,занятость воксела,заполнение вокселей,занятость вокселей
4651,voxel representation,تمثيل فوكسل,تمثيل الـ فوكسيلات,تمثيل مجسم,体素表示,体素表示,体元表示,représentation voxelique,- Représentation en voxel,représentation voxel,ボクセル表現,ボクセル表現,ボクセル表現,воксельное представление,воксельное представление,вокселизированное представление
4652,voxel-base representation,تمثيل قاعدة فوكسل,تمثيل على أساس فوكسلات,تمثيل قائم على البكسل المجسم,基于体素的表示,基于体素的表示,体素表示,représentation à base de voxel,"""['PIFu [70] régresse une représentation de surface implicite qui aligne localement les pixels sur le contexte global de l'objet 3D correspondant. Contrairement aux représentations basées sur les voxels, cette représentation implicite par pixel est plus efficace en termes de mémoire. Ces approches n'ont pas encore été démontrées pour généraliser efficacement aux fortes articulations.', 'Henzler et al. [32] apprennent des représentations basées sur les vox",représentation basée sur des voxels,ボクセルベースの表現,ボクセルベース表現,ボクセルベース表現,представление на основе вокселей,воксельное представление,представление на основе воксельных данных
4653,warp function,وظيفة الاعوجاج,وظيفة التشويه,وظيفة الانحناء,扭曲函数,变形函数,扭曲函数,fonction de déformation,fonction de déformation,fonction de déformation,ワープ機能,ワープ関数,歪み関数,функция деформации,функция искривления,функция искажения
4654,wav2vec,wav2vec,واڤ تو فيك,مُحوِّل الموجة إلى متجه (wav2vec),wav2vec,wav2vec,wav2vec,wav2vec,wav2vec,wav2vec,wav2vec,wav2vec,wav2vecのまま,wav2vec,wav2vec,wav2vec
4655,wavelet,موجة مائية,موجة صغيرة,موجة دوبيتز,小波,小波,小波,ondelette,ondelette,ondelettte,ウェーブレット,ウェーブレット,ウェーブレット,вейвлет,вейвлет,волна
4656,wavelet transform,تحول موجية,تحويل الموجات الدقيقة,تحويل موجي,小波变换,小波变换 (wavelet transform),小波变换,transformée en ondelettes,transformée en ondelettes,Transformation en ondelettes,ウェーブレット変換,ウェーブレット変換 (Wavelet変換),ウェーブレット変換,вейвлет-преобразование,вейвлет-преобразование,вейвлет-преобразование
4657,weak classifier,مصنف ضعيف,مصنف ضعيف,مصنف ضعيف,弱分类器,弱分类器,弱分类器,classificateur faible,classifieur faible,classifieur faible,弱分類器,弱分類器,弱識別器,слабый классификатор,слабый классификатор,слабый классификатор
4658,weak learner,المتعلم الضعيف,التعلم الضعيف,ضعيف التعلم,弱学习者,弱学习器,弱学习器,apprenant faible,apprenant faible,apprenant faible,弱い学習者,弱学習器 (jakugakushūki),弱学習器,слабый ученик,Слабый учитель,слабый обучающий алгоритм
4659,weak learning,التعلم الضعيف,التعلم الضعيف,تعلم ضعيف,学习薄弱,弱学习,弱学习,faible apprentissage,apprentissage faible,apprentissage faible,弱い学習,弱学習 (Jakugakushū),弱学習,слабое обучение,слабое обучение,Слабое обучение
4660,weak learning assumption,افتراض التعلم الضعيف,- تقديم الفرضية الضعيفة للتعلم,ضعيف الافتراض التعلم,弱学习假设,弱学习假设,弱学习假设,hypothèse d'apprentissage faible,hypothèse d'apprentissage faible,apprentissage faible,弱い学習仮定,弱学習の仮定,弱学習仮定,слабое предположение об обучении,слабое предположение о обучении,слабое допущение обучения
4661,weak supervision,إشراف ضعيف,التوجيه الضعيف,الإشراف الضعيف,监管薄弱,弱监督,弱监督,surveillance faible,supervision faible,supervision faible,弱い監督,"""['弱い監督は、音声と視覚を言語理解を学ぶための弱い監督のソースとして使用します；言い換えると、視覚認識に基づく音声信号からの言語習得を実装します。'、'弱い監督では、我々はノイズ分布 D n からサ",弱教師あり学習,слабый надзор,Слабое обучение,слабый надзор
4662,weakly supervise,مراقبة ضعيفة,"""['للعمل المستقبلي، نأمل في استخدام تقنيات مماثلة لتقسيم الصور بإشراف ضعيف. كما نخطط لتحسين نتائج الكشف باستخدام استراتيجيات مطابقة أقوى لتعيين علامات ضعي",تدريب ضعيف,弱监督,弱监督 (ruò jiāndū),弱监督学习,superviser faiblement,faiblement supervisé,supervisé de manière faible,弱く監督する,弱く監督する,弱教師あり,слабо контролировать,слабоуправляемый,Слабо контролируемый
4663,weakly supervise learning,التعلم الخاضع للإشراف الضعيف,التعلم التوجيهي الضعيف,التعلم تحت إشراف ضعيف,弱监督学习,弱监督学习,弱监督学习,apprentissage faiblement supervisé,apprentissage supervisé faiblement,apprentissage faiblement supervisé,弱教師学習,弱く教師付き学習 (WSL),弱教師あり学習,слабо контролируемое обучение,слабо контролируемое обучение,Обучение с неполным контролем
4664,web graph,الرسم البياني على شبكة الإنترنت,الرسم البياني للويب,شبكة الوِب,网络图,网络图,网络图,graphique Web,graphe web,graphe du Web,ウェブグラフ,ウェブグラフ,ウェブグラフ,веб-график,веб-граф,веб-граф
4665,weight,وزن,وزن,وزن,重量,权重,权重,poids,poids,poids,重さ,重み,重み (omomi),масса,вес,вес
4666,weight average,متوسط ​​الوزن,المتوسط الوزني,وزن المتوسط,平均体重,加权平均,加权平均,poids moyen,moyenne pondérée,moyenne pondérée,体重平均,重み付き平均,加重平均,средний вес,Средний вес,вес среднее значение
4667,weight decay,اضمحلال الوزن,التحلل الوزني,انحلال الوزن,重量衰减,权重衰减,权重衰减,perte de poids,décroissance du poids,décroissance du poids,体重減少,重み減衰 (omomi gensai),重み減衰,снижение веса,весовое затухание,затухание веса
4668,weight direct graph,الوزن الرسم البياني المباشر,الرسم البياني الموجه الوزني,رسم موجه موزون,权重直接图,带权重有向图,加权有向图,graphique direct du poids,graphe dirigé pondéré,graphe pondéré orienté,重量直接グラフ,重み付き有向グラフ,重み付き有向グラフ,прямой график веса,взвешенный направленный граф,взвешенный ориентированный граф
4669,weight graph,الرسم البياني للوزن,رسم وزني,رسم البيان الموزون,体重图,权重图,加权图,graphique de poids,graphe pondéré,graphe pondéré,重量グラフ,重み付きグラフ,重み付きグラフ,график веса,взвешенный граф,взвешенный граф
4670,weight initialization,تهيئة الوزن,- تهيئة الأوزان,تهيئة الأوزان,权重初始化,权重初始化,权重初始化,initialisation du poids,initialisation des poids,initialisation des poids,重みの初期化,重みの初期化 (omomi no shoki-ka),重み初期化,инициализация веса,инициализация весов,инициализация весов
4671,weight matrix,مصفوفة الوزن,مصفوفة الأوزان,مصفوفة الأوزان,权重矩阵,权重矩阵,权重矩阵,matrice de poids,- Matrice de poids,matrice de poids,重み行列,重み行列,重み行列,весовая матрица,матрица весов,матрица весов
4672,weight parameter,معلمة الوزن,معامل الوزن,وزن المعلمة,重量参数,权重参数,权重参数,paramètre de poids,paramètre de poids,paramètre de pondération,重みパラメータ,重みパラメータ (omomi parameta),重みパラメータ,весовой параметр,весовой параметр,весовой параметр
4673,weight regularization,تنظيم الوزن,- التنظيم الوزني,وزن التنظيم,权重正则化,权重正则化,权重正则化,régularisation du poids,régularisation des poids,régularisation des poids,重みの正規化,重み正則化,重み正則化 (juumisei kikazuka),регуляризация веса,регуляризация весов,регуляризация весов
4674,weight sum,مجموع الوزن,مجموع الوزن,مجموع موزون,重量总和,权重和,加权和,somme de poids,somme pondérée,somme pondérée,重量合計,重み付け和,重み付き和,весовая сумма,сумма весов,взвешенная сумма
4675,weight tensor,موتر الوزن,Tensor الوزن,شريحة الأوزان,重量张量,权重张量,权重张量,tenseur de poids,tenseur de poids,tenseur de pondération,重みテンソル,重みテンソル (omomi tensor),重み行列,тензор веса,тензор весов,тензор весов
4676,weight update,تحديث الوزن,تحديث الوزن,تحديث الأوزان,体重更新,权重更新,权重更新,mise à jour du poids,- Mise à jour du poids,mise à jour des poids,体重の更新,重み更新,重み更新,обновление веса,обновление весов,обновление весов
4677,weight vector,ناقلات الوزن,متجه الوزن,ناقل الأوزان,权重向量,权重向量,权重向量,vecteur de poids,vecteur de poids,vecteur de poids,重みベクトル,重みベクトル,重み係数ベクトル,вектор веса,вектор весов,вектор весов
4678,weight-sharing,تقاسم الوزن,التقاسم الوزني,تشارك الأوزان,重量分担,权重共享,权重共享,partage de poids,partage de poids,partage de poids,体重共有,重み共有,重み共有,распределение веса,совместное использование весов,Разделение весов
4679,weighted adjacency matrix,مصفوفة الجوار المرجحة,مصفوفة الجوار المزودة بالأوزان,مصفوفة الجوار الموزونة,加权邻接矩阵,加权邻接矩阵,加权邻接矩阵,matrice de contiguïté pondérée,- Matrice d'adjacence pondérée,matrice d'adjacence pondérée,重み付けされた隣接行列,重み付き隣接行列 (juumitsuki rinsetsu kouretsu),重み付き隣接行列,взвешенная матрица смежности,взвешенная матрица смежности,матрица весовых смежностей
4680,weighting function,وظيفة الترجيح,وظيفة تقديم الوزن,دالة الترجيح,加权函数,权重函数,加权函数,fonction de pondération,fonction de pondération,fonction de pondération,重み付け関数,重み付け関数,重み付け関数,весовая функция,функция взвешивания,Весовая функция
4681,white-box,صندوق أبيض,صندوق أبيض,صندوق أبيض,白盒,"""['先前的研究考虑在白盒和黑盒威胁模型中的对抗示例。在本文中，我们考虑设计用于白盒环境的防御措施，即对抗者完全可以访问神经网络分类器（架构和权重）和防御措施，但不能访问测试时的随机性（只能",白盒子,boîte blanche,boîte blanche,boîte blanche,白い箱,ホワイトボックス,ホワイトボックス,белая коробка,белый ящик,белый ящик
4682,white-box attack,هجوم الصندوق الأبيض,هجوم مربع أبيض,هجوم صندوق أبيض,白盒攻击,白盒攻击,白盒攻击,attaque en boîte blanche,attaque boîte blanche,attaque boîte blanche,ホワイトボックス攻撃,ホワイトボックス攻撃,ホワイトボックス攻撃,атака белого ящика,"белый ящик, нападение",атака с открытым исходным кодом
4683,window size,بحجم النافذه,حجم النافذة,حجم النافذة,窗口大小,窗口大小,窗口大小,la taille de la fenêtre,- Taille de la fenêtre,taille de la fenêtre,ウィンドウサイズ,ウィンドウサイズ (Window Size),ウィンドウサイズ,размер окна,размер окна,размер окна
4684,within-class variance,التباين داخل الطبقة,التباين داخل الصنف,التباين داخل الفئة,类内方差,类内方差,类内方差,écart au sein d'une classe,- Variance intra-classe,variance intra-classe,クラス内分散,クラス内分散,クラス内分散,внутриклассовая дисперсия,внутриклассовая дисперсия,внутриклассовая дисперсия
4685,word alignment,محاذاة الكلمة,محاذاة الكلمات,مُواءَمَةُ الكَلِمَات,单词对齐,词对齐,词对齐,alignement des mots,Alignement de mots,alignement de mots,単語の配置,単語アライメント,単語アライメント,выравнивание слов,выравнивание слов,выравнивание слов
4686,word dropout,تسرب الكلمة,التنقيص من الكلمات,حذف الكلمات,词丢失,词语丢弃,词丢弃,abandon de mot,abandon de mot,omission de mots,単語のドロップアウト,単語ドロップアウト,単語ドロップアウト,выпадение слова,"""['Мы также применяем отсев слов (Иер и др., 2015) к входным отрезкам, удаляя слова из вычисления среднего вектора в Уравнении 1 с вероятностью 0,5.', 'Кроме того, для увеличения обобщения модели и имитации ситуации с отсутствием слов в словаре используется отс",выпадение слов
4687,word embedding,تضمين الكلمة,تضمين الكلمة,ترميز الكلمات,词嵌入,词嵌入,词嵌入,intégration de mots,incorporation de mots,plongement de mots,単語の埋め込み,ワード埋め込み,単語埋め込み,встраивание слов,векторное представление слов,векторное представление слов
4688,word embedding model,نموذج تضمين الكلمات,نموذج تضمين الكلمات,نموذج ترميز الكلمات,词嵌入模型,词嵌入模型 (word embedding model),词嵌入模型,modèle d'intégration de mots,- Modèle d'incorporation de mots,modèle de plongements lexicaux,単語埋め込みモデル,ワード埋め込みモデル,単語埋め込みモデル,модель встраивания слов,модель встраивания слов,модель векторного представления слов
4689,word mover's distance,المسافة المحركة للكلمة,مسافة محرك الكلمات,مسافة ناقل الكلمة,词移动者的距离,词移距离,词移距离,distance du moteur de mots,distance du conducteur de mot,distance de déplacement de mots,言葉の移動距離,ワードムーバー距離,単語移動距離,расстояние перемещения слова,расстояние между словами,расстояние переносчика слов
4690,word representation,تمثيل الكلمة,تمثيل الكلمة,تمثيل الكلمات,词表示,词表示,词表示,représentation des mots,représentation de mots,représentation de mot,単語表現,単語表現 (tango hyougen),単語表現,представление слова,представление слов,слово-представление
4691,word segmentation,تجزئة الكلمة,تقسيم الكلمات,تقطيع الكلمات,分词,词语分割,分词,segmentation des mots,segmentation de mots,segmentation de mots,単語の分割,単語分割 (tango bunkatsu),単語分割,сегментация слов,сегментация слов,сегментация слов
4692,word sense disambiguation,توضيح معنى الكلمة,توضيح معنى الكلمة,تمييز معنى الكلمة,词义消歧,词义消歧,词义消歧,homonymie du sens des mots,désambiguïsation de sens de mot,désambiguïsation du sens des mots,語感の曖昧さ回避,単語意味の曖昧さ解消,単語曖昧性解消,определение смысла слова,разрешение многозначности значения слов,разрешение неоднозначности слова
4693,word similarity,تشابه الكلمة,تشابه الكلمات,تشابه الكلمات,词的相似度,词语相似度,词相似度,similitude de mots,similarité des mots,similarité des mots,単語の類似性,単語の類似度,単語の類似性,сходство слов,сходство слов,сходство слов
4694,word surprisal,كلمة مفاجأة,- التفاجئ الكلمة,درجة تفاجؤ الكلمة,词令人惊讶,词语惊异,词惊喜值,mot surprise,surprisal de mot,surprise des mots,驚きという言葉,単語驚き (tango odoroki),単語の驚異度,слово сюрприз,удивление словом,слогословная неожиданность
4695,word token,رمز الكلمة,رمز الكلمة,وحدة كلمة,词标记,词标签,词元,jeton de mot,jeton de mot,jeton de mot,単語トークン,単語トークン,単語トークン,токен слова,словесный токен,токен слова
4696,word vector,ناقلات الكلمة,متجه الكلمة,متجه الكلمة,词向量,词向量,词向量,vecteur de mot,vecteur de mots,vecteur de mots,単語ベクトル,単語ベクトル (tango becutoru),単語ベクトル,вектор слова,"""['Для всех моделей мы используем dev-набор и кросс-валидацию по регуляризации весов, размеру вектора слов, а также скорости обучения и размеру мини-пакета для AdaGrad. Оптимальная производительность для всех моделей достигается при размерах вектора слов от 25 до 35 измерений и размерах пакета от 20",вектор слова
4697,word vector representation,تمثيل ناقلات الكلمة,تمثيل الكلمات بالمتجهات,تمثيل متجه الكلمة,词向量表示,词向量表示,词向量表示,représentation vectorielle de mots,représentation vectorielle de mots,représentation vectorielle des mots,単語ベクトル表現,単語ベクトル表現 (Tango Bekutoru Hyōgen),単語ベクトル表現,векторное представление слова,представление вектора слов,векторное представление слов
4698,word-align corpus,مجموعة محاذاة الكلمات,مجموعة الكلمات المُحاذية,جسم محاذاة الكلمات,词对齐语料库,对齐词库,词对齐语料库,corpus d'alignement de mots,corpus aligné par mot,corpus aligné au niveau des mots,単語整列コーパス,単語アラインメントコーパス,単語アラインコーパス,выравнивание по словам корпуса,корпус с выравниванием слов,корпус выровненных по словам
4699,word-level,على مستوى الكلمة,مستوى الكلمة,على مستوى الكلمات,字级,单词级别,单词级别,au niveau des mots,au niveau des mots,au niveau des mots,単語レベル,単語レベル,単語レベル,уровень слова,"""['В целом OpenKiwi превосходит deepQuest для всех задач на уровне слов и уровне предложения, и достигает лучших результатов для всех задач на уровне слов.', 'Оба метода комбинирования предложений и фраз могут генерировать лучшие списки, которые также могут быть использованы в качестве новых системных выходов на уровне",на уровне слов
4700,word-level vocabulary,المفردات على مستوى الكلمة,مفردات على مستوى الكلمات,قاموس مستوى الكلمة,词级词汇,词级词汇量,词级词汇表,vocabulaire au niveau des mots,vocabulaire au niveau des mots,vocabulaire au niveau des mots,単語レベルの語彙,単語レベルの語彙,単語レベルの語彙,словарный запас на уровне слов,словарь на уровне слов,словарь на уровне слов
4701,word2vec embedding,تضمين word2vec,تضمين word2vec,تضمين word2vec,word2vec 嵌入,词向量嵌入,word2vec 嵌入,intégration word2vec,incrustation word2vec,représentation word2vec,word2vec埋め込み,word2vec埋め込み,word2vecエンベディング,встраивание word2vec,встроенные word2vec,word2vec вложения
4702,world state,الدولة العالمية,حالة العالم,حالة العالم,世界状态,世界状态,世界状态,état mondial,état du monde,état du monde,世界状態,世界状態 (sekai joutai),世界状態,мировое государство,мировое состояние,состояние мира
4703,z-score,z-score,نقطة Z,درجة المعيارية,z 分数,z-分数,标准分数,score z,z-score,Score z,Zスコア,Zスコア,z-スコア,z-оценка,z-оценка,Значение Z
4704,zero-one loss,خسارة صفر واحد,خسارة صفر واحد,خسارة صفر واحد,零一损失,零一损失,0-1损失,perte zéro un,perte zéro-un,perte zéro-un,ゼロワン損失,ゼロワン損失,ゼロワンロス,потеря ноль-единица,нулевой потери-единицы,потери нуля-единицы
4705,zero-shot classification,تصنيف صفر طلقة,صنف بدون تصنيف,تصنيف الصفر اطلاق,零样本分类,零热门分类,零次分类,classement zéro tir,Classification sans entraînement,classification zéro coup,ゼロショット分類,ゼロショット分類,ゼロショット分類,классификация с нулевым выстрелом,нулевая классификация (zero-shot classification),классификация без предварительной подготовки
4706,zero-shot cross-lingual setting,الإعداد عبر اللغات بدون طلقة,"- صياغة عبر لغات الآخر
- الإعداد عبر اللغات بدون تدريب",إعداد متعدد اللغات من دون تدريب,零样本跨语言设置,零-shot 跨语言设置,零射手跨语言设置,réglage multilingue zéro-shot,réglage zéro-shot cross-lingual,paramètre interlingue à tir tendu,ゼロショットのクロスリンガル設定,ゼロショットクロスリンガル設定,ゼロショット言語横断設定,нулевая межъязыковая настройка,нулевая кросс-язычная среда без обучения,нулевой трансъязычный режим
4707,zero-shot generalization,تعميم صفر النار,التعميم الفائق بدون تدريب,التعميم الصفري,零样本泛化,零-shot泛化,零次泛化,généralisation du tir zéro,généralisation zéro-shot,généralisation zéro-coup,ゼロショットの一般化,ゼロショット汎化,ゼロショット汎化能力,обобщение с нулевым выстрелом,нулевая обобщающая способность,обобщение с нулевым выстрелом
4708,zero-shot learning,التعلم بدون طلقة,التعلم بدون مشهد,التعلم الصفري,零样本学习,零样本学习,零次学习,apprentissage sans tir,apprentissage sans étiquette,Apprentissage par transfert,ゼロショット学習,ゼロショット学習,ゼロショット学習,обучение с нулевым выстрелом,нулевое обучение с нулевым обучением,обучение с нулевым выстрелом
4709,zero-shot prediction,التنبؤ بالطلقة الصفرية,التنبؤ بصفر الإطلاق,التنبؤ بدون تدريب,零样本预测,零次预测,零次预测,prédiction du tir zéro,prédiction sans apprentissage,prédiction sans exemple,ゼロショット予測,ゼロショット予測,ゼロショット予測,прогноз с нулевым шансом,предсказание с нулевой разметкой,предсказание без предварительного обучения
4710,zero-shot prompting,المطالبة بالطلقة الصفرية,"""['على نحو بسيط، نستكشف تحفيز بدون توجيه مع GPT-J في مهمة تلخيص و 2 تحفيز مع Pythia-2.8B في مهمة الحوار.', 'ومع ذلك، نعترف بأن هذا هو واحد من بين العو",استدعاء من دون إعطاء مثال,零样本提示,零次提示 (zero-shot prompting),零示例提示,invite de tir zéro,sollicitation zéro-shot,promptage zéro tirée,ゼロショットプロンプト,ゼロショットプロンプティング,ゼロショットプロンプト,подсказка с нулевым выстрелом,нулевая генерация подсказок,нулевое-прямое подсказывание
4711,zero-shot reasoning,المنطق الصفري,الاستدلال بدون تدريب,استدلال بدون بيانات,零样本推理,零射推理,零次推理,raisonnement sans tir,Raisonnement sans entraînement,raisonnement zero-shot,ゼロショット推論,ゼロショット推論,ゼロショット推論,рассуждения с нулевым шансом,- Нулевое рассуждение,рассуждение с нулевым выстрелом
4712,zero-shot setting,إعداد صفر النار,"""['• وصفة ملموسة للتعلم من هذه الرسومات ، مبنية على عائلة عامة من التمثيلات العميقة المتعددة الوحدات وهدف تدريب الممثل-الحكام متعدد المهام. الهيكل القابل للتط",إعداد الصفر,零次设置,零样本设置,零次设置,réglage zéro tir,configuration de zéro tireur,paramètre de transfert,ゼロショット設定,ゼロショット設定,ゼロショット設定,настройка нулевого выстрела,нулевая настройка,"Режим ""с нуля"""
4713,zero-shot transfer,نقل صفر النار,- تحويل بدون تدريب,نقل صفري الإطلاق,零次转移,零射传递,零次迁移,transfert sans tir,transfert sans apprentissage,transfert zéro coup,ゼロショット転送,ゼロショット転送,ゼロショット転移,передача с нулевым выстрелом,нулевой передача,Перенос без предварительного обучения
4714,zero-shot transfer learning,تعلم النقل بدون طلقة,التعلم النقلي بدون تدريب,التعلم النقلي للكلمات المفتاحية,零样本迁移学习,零样本迁移学习,零次迁移学习,apprentissage par transfert zéro,transfert d'apprentissage sans tirage au sort,apprentissage par transfert zéro-tir,ゼロショット転移学習,zero-shot転移学習,ゼロショット転移学習,обучение с нулевым переносом,нулевое обучение с переносом,обучение с нулевым переносом
4715,zipf,com.zipf,زيبف,قانون زيف,齐夫,Zipf定律,齐普夫分布,zipf,Zipf,loi de Zipf,ジップ,ジップフ,ジップの法則,молния,Зипф,закон Ципфа
4716,zipf distribution,توزيع zipf,توزيع زيبف,توزيع زيف,zipf 发行版,Zipf分布,拉普拉斯分布,distribution zipf,distribution de Zipf,distribution de Zipf,zipf ディストリビューション,ジップ分布,ジップ分布,zipf-дистрибутив,распределение Ципфа,распределение Ципфа
4717,zipf's law,قانون zipf,قانون زيبف,قانون زيبف,齐夫定律,Zipf定律,齐夫定律,la loi de zipf,Loi de Zipf,Loi de Zipf,ジップの法則,ジップフの法則,ジプフの法則,закон Зипфа,закон Ципфа,Закон Ципфа
