,Unnamed: 0,word,gold,exact_match_ratio,prediction_count,prediction_ratio,gold_human
0,0,10-fold cross validation,10分割交差検証,0.8,10,"[{'word': '10分割交差検証', 'ratio': 0.8}, {'word': '10回クロス検証', 'ratio': 0.1}, {'word': '10 分割相互検証', 'ratio': 0.1}]",10分割交差検証
1,1,1D convolution,1次元畳み込み,0.8,10,"[{'word': '1次元畳み込み', 'ratio': 0.8}, {'word': '1次元コンボリューション', 'ratio': 0.1}, {'word': '1Dコンボリューション', 'ratio': 0.1}]",1次元畳み込み
2,2,2 norm,2ノルム,0.8,10,"[{'word': '2ノルム', 'ratio': 0.8}, {'word': '2規範', 'ratio': 0.1}, {'word': '2 ノルム', 'ratio': 0.1}]",2ノルム
3,3,2D convolution,2D畳み込み,0.0,10,"[{'word': '2次元畳み込み', 'ratio': 0.8}, {'word': '2次元コンボリューション', 'ratio': 0.1}, {'word': '2Dコンボリューション', 'ratio': 0.1}]",2次元畳み込み
4,4,2D image,2次元画像,0.8,10,"[{'word': '2次元画像', 'ratio': 0.8}, {'word': '2D画像', 'ratio': 0.2}]",2次元画像
5,5,2D image synthesis,2次元画像合成,0.1,10,"[{'word': '2D画像合成', 'ratio': 0.9}, {'word': '2次元画像合成', 'ratio': 0.1}]",2D画像合成
6,6,2D-3D correspondence,2次元-3次元対応,0.1,10,"[{'word': '2D-3D対応', 'ratio': 0.9}, {'word': '2次元-3次元対応', 'ratio': 0.1}]",2D-3D対応
7,7,3D bounding box,3次元バウンディングボックス,0.0,10,"[{'word': '3Dバウンディングボックス', 'ratio': 0.8}, {'word': '3D バウンディング ボックス', 'ratio': 0.1}, {'word': '3次元境界箱', 'ratio': 0.1}]",3Dバウンディングボックス
8,8,3D computer vision,3次元コンピュータビジョン,0.0,10,"[{'word': '3Dコンピュータビジョン', 'ratio': 0.9}, {'word': '3次元コンピューター視覚', 'ratio': 0.1}]",3Dコンピュータビジョン
9,9,3D convolutional network,3次元畳み込みネットワーク,0.2,10,"[{'word': '3D畳み込みネットワーク', 'ratio': 0.8}, {'word': '3次元畳み込みネットワーク', 'ratio': 0.2}]",3D畳み込みネットワーク
10,10,3D geometry,3次元ジオメトリ,0.0,10,"[{'word': '3Dジオメトリ', 'ratio': 0.6}, {'word': '3D幾何学', 'ratio': 0.2}, {'word': '3D ジオメトリ', 'ratio': 0.1}, {'word': '3次元幾何学', 'ratio': 0.1}]",3Dジオメトリ
11,12,3D localization,3次元位置推定,0.0,10,"[{'word': '3D位置特定', 'ratio': 0.5}, {'word': '3Dローカリゼーション', 'ratio': 0.2}, {'word': '3Dローカライズ', 'ratio': 0.1}, {'word': '3D ローカリゼーション', 'ratio': 0.1}, {'word': '3次元ローカライゼーション', 'ratio': 0.1}]",3D位置特定
12,13,3D mesh,3次元メッシュ,0.1,10,"[{'word': '3Dメッシュ', 'ratio': 0.9}, {'word': '3次元メッシュ', 'ratio': 0.1}]",3Dメッシュ
13,14,3D model,3Dモデル,0.9,10,"[{'word': '3Dモデル', 'ratio': 0.9}, {'word': '3次元モデル', 'ratio': 0.1}]",3Dモデル
14,15,3D object detection,3次元物体検出,0.0,10,"[{'word': '3Dオブジェクト検出', 'ratio': 0.7}, {'word': '3D物体検出', 'ratio': 0.3}]",3Dオブジェクト検出
15,16,3D point,3次元点,0.0,10,"[{'word': '3Dポイント', 'ratio': 1.0}]",3Dポイント
16,17,3D point cloud,3D点群,0.2,10,"[{'word': '3Dポイントクラウド', 'ratio': 0.8}, {'word': '3D点群', 'ratio': 0.2}]",3Dポイントクラウド
17,18,3D pose,3次元ポーズ,0.0,10,"[{'word': '3Dポーズ', 'ratio': 1.0}]",3Dポーズ
18,19,3D reconstruction,3D再構築,0.4,10,"[{'word': '3D再構成', 'ratio': 0.6}, {'word': '3D再構築', 'ratio': 0.4}]",3D再構成
19,20,3D scene,3次元シーン,0.0,10,"[{'word': '3Dシーン', 'ratio': 1.0}]",3Dシーン
20,22,3D structure,3次元構造,0.0,10,"[{'word': '3D構造', 'ratio': 1.0}]",3D構造
21,23,5-fold cross validation,5分割交差検証,0.8,10,"[{'word': '5分割交差検証', 'ratio': 0.8}, {'word': '5回クロス検証', 'ratio': 0.1}, {'word': '5 分割相互検証', 'ratio': 0.1}]",5分割交差検証
22,24,A * algorithm,A*アルゴリズム,0.8,10,"[{'word': 'A*アルゴリズム', 'ratio': 0.8}, {'word': 'アルゴリズム', 'ratio': 0.1}, {'word': '* アルゴリズム', 'ratio': 0.1}]",A*アルゴリズム
23,25,A/B test,A/Bテスト,0.7,10,"[{'word': 'A/Bテスト', 'ratio': 0.7}, {'word': 'A/B テスト', 'ratio': 0.3}]",A/Bテスト
24,26,A2C,A2C,0.7,10,"[{'word': 'A2C', 'ratio': 0.7}, {'word': '彼は生きていた', 'ratio': 0.2}, {'word': 'エーツーシー', 'ratio': 0.1}]",A2C
25,27,Ablation study,アブレーション研究,0.2,10,"[{'word': 'アブレーションスタディ', 'ratio': 0.7}, {'word': 'アブレーション研究', 'ratio': 0.2}, {'word': 'アブレーションスタディー', 'ratio': 0.1}]",アブレーションスタディ
26,28,Accuracy,精度,0.9,10,"[{'word': '精度', 'ratio': 0.9}, {'word': '正確さ', 'ratio': 0.1}]",精度
27,29,Active learning,アクティブラーニング,0.9,10,"[{'word': 'アクティブラーニング', 'ratio': 0.9}, {'word': 'アクティブ・ラーニング', 'ratio': 0.1}]",アクティブラーニング
28,30,Adafactor,アダファクタ,0.0,10,"[{'word': 'アダファクター', 'ratio': 1.0}]",アダファクター
29,31,Adam,アダム,0.7,10,"[{'word': 'アダム', 'ratio': 0.7}, {'word': 'Adam', 'ratio': 0.3}]",アダム
30,32,Adam algorithm,アダムアルゴリズム,0.5,10,"[{'word': 'アダムアルゴリズム', 'ratio': 0.5}, {'word': 'Adamアルゴリズム', 'ratio': 0.3}, {'word': 'アダム・アルゴリズム', 'ratio': 0.1}, {'word': 'アルゴリズム', 'ratio': 0.1}]",アダムアルゴリズム
31,35,Adam optimization algorithm,Adamの最適化アルゴリズム,0.0,10,"[{'word': 'アダム最適化アルゴリズム', 'ratio': 0.5}, {'word': 'Adam最適化アルゴリズム', 'ratio': 0.3}, {'word': 'Adam 最適化アルゴリズム', 'ratio': 0.1}, {'word': '最適化アルゴリズム', 'ratio': 0.1}]",アダム最適化アルゴリズム
32,37,Adapter,アダプター,0.3,10,"[{'word': 'アダプタ', 'ratio': 0.7}, {'word': 'アダプター', 'ratio': 0.3}]",アダプタ
33,38,Algorithm,アルゴリズム,1.0,10,"[{'word': 'アルゴリズム', 'ratio': 1.0}]",アルゴリズム
34,39,Answer Set Programming,回答集合プログラミング,0.0,10,"[{'word': 'アンサーセットプログラミング', 'ratio': 0.6}, {'word': 'アンサセットプログラミング', 'ratio': 0.2}, {'word': 'アンサーセット・プログラミング', 'ratio': 0.1}, {'word': '解答セットのプログラミング', 'ratio': 0.1}]",アンサーセットプログラミング
35,40,Apriori,アプリオリ,1.0,10,"[{'word': 'アプリオリ', 'ratio': 1.0}]",アプリオリ
36,41,Apriori algorithm,アプリオリ・アルゴリズム,0.1,10,"[{'word': 'アプリオリアルゴリズム', 'ratio': 0.9}, {'word': 'アプリオリ・アルゴリズム', 'ratio': 0.1}]",アプリオリアルゴリズム
37,42,Arcade Learning Environment,アーケード学習環境,0.9,10,"[{'word': 'アーケード学習環境', 'ratio': 0.9}, {'word': 'アーケードの学習環境', 'ratio': 0.1}]",アーケード学習環境
38,43,Artificial Intelligence,人工知能,1.0,10,"[{'word': '人工知能', 'ratio': 1.0}]",人工知能
39,44,Attention,アテンション,0.1,10,"[{'word': '注意', 'ratio': 0.7}, {'word': '注意機構', 'ratio': 0.2}, {'word': 'アテンション', 'ratio': 0.1}]",注意
40,45,Autoencoder,自己エンコーダ,0.0,10,"[{'word': 'オートエンコーダ', 'ratio': 0.9}, {'word': '自己符号化器', 'ratio': 0.1}]",オートエンコーダ
41,46,Automatic Speech Recognition,自動音声認識,0.9,10,"[{'word': '自動音声認識', 'ratio': 0.9}, {'word': '自動語音認識', 'ratio': 0.1}]",自動音声認識
42,47,Autonomous Systems,自律システム,0.9,10,"[{'word': '自律システム', 'ratio': 0.9}, {'word': '自動化システム', 'ratio': 0.1}]",自律システム
43,49,Average Precision,平均精度,0.3,10,"[{'word': '平均適合率', 'ratio': 0.7}, {'word': '平均精度', 'ratio': 0.3}]",平均適合率
44,51,B-spline,B-スプライン,0.0,10,"[{'word': 'Bスプライン', 'ratio': 0.8}, {'word': 'B スプライン', 'ratio': 0.2}]",Bスプライン
45,52,Backbone,バックボーン (backbone),0.0,10,"[{'word': 'バックボーン', 'ratio': 1.0}]",バックボーン
46,53,Backpropagation,バックプロパゲーション,0.5,10,"[{'word': '逆伝播', 'ratio': 0.5}, {'word': 'バックプロパゲーション', 'ratio': 0.5}]",逆伝播
47,54,Baseline,ベースライン,1.0,10,"[{'word': 'ベースライン', 'ratio': 1.0}]",ベースライン
48,56,Batch Normalization,バッチ正規化,0.8,10,"[{'word': 'バッチ正規化', 'ratio': 0.8}, {'word': 'バッチ・ノーマライゼーション', 'ratio': 0.2}]",バッチ正規化
49,58,Bayes,ベイズ,1.0,10,"[{'word': 'ベイズ', 'ratio': 1.0}]",ベイズ
50,59,Bayes classifier,ベイズ分類器,1.0,10,"[{'word': 'ベイズ分類器', 'ratio': 1.0}]",ベイズ分類器
51,60,Bayes factor,ベイズ因子,0.9,10,"[{'word': 'ベイズ因子', 'ratio': 0.9}, {'word': 'ベイズ係数', 'ratio': 0.1}]",ベイズ因子
52,61,Bayes formula,ベイズの定理,0.3,10,"[{'word': 'ベイズの公式', 'ratio': 0.7}, {'word': 'ベイズの定理', 'ratio': 0.3}]",ベイズの公式
53,62,Bayes net,ベイズネット,1.0,10,"[{'word': 'ベイズネット', 'ratio': 1.0}]",ベイズネット
54,63,Bayes optimal classifier,ベイズ最適分類器,0.9,10,"[{'word': 'ベイズ最適分類器', 'ratio': 0.9}, {'word': 'ベイズ最適クラスифイア', 'ratio': 0.1}]",ベイズ最適分類器
55,64,Bayes risk,ベイズリスク,1.0,10,"[{'word': 'ベイズリスク', 'ratio': 1.0}]",ベイズリスク
56,65,Bayes risk decoding,ベイズリスク復号化,0.0,10,"[{'word': 'ベイズリスクデコーディング', 'ratio': 0.8}, {'word': 'ガンベル分布', 'ratio': 0.1}, {'word': 'ベイズリスクデコード', 'ratio': 0.1}]",ベイズリスクデコーディング
57,67,Bayes theorem,ベイズの定理,1.0,10,"[{'word': 'ベイズの定理', 'ratio': 1.0}]",ベイズの定理
58,68,Bayes-Nash equilibrium,ベイズ・ナッシュ均衡,0.6,10,"[{'word': 'ベイズ・ナッシュ均衡', 'ratio': 0.6}, {'word': 'ベイズ-ナッシュ均衡', 'ratio': 0.3}, {'word': 'ベイズ＝ナッシュ均衡', 'ratio': 0.1}]",ベイズ・ナッシュ均衡
59,69,Bayesian Information Criterion,ベイズ情報量基準,0.6,10,"[{'word': 'ベイズ情報量基準', 'ratio': 0.6}, {'word': 'ベイズ情報基準', 'ratio': 0.2}, {'word': 'Bayesian Information Criterion', 'ratio': 0.1}, {'word': 'ベイズ情報 критериум', 'ratio': 0.1}]",ベイズ情報量基準
60,70,Bayesian Network,ベイジアンネットワーク,0.6,10,"[{'word': 'ベイジアンネットワーク', 'ratio': 0.6}, {'word': 'ベイズネットワーク', 'ratio': 0.3}, {'word': 'ゲームツリー', 'ratio': 0.1}]",ベイジアンネットワーク
61,71,Bayesian active learning,ベイズ的能動学習,0.0,10,"[{'word': 'ベイジアンアクティブラーニング', 'ratio': 0.5}, {'word': 'ベイズアクティブラーニング', 'ratio': 0.2}, {'word': 'ベイズ型能動学習', 'ratio': 0.2}, {'word': 'ベイズ的アクティブラーニング', 'ratio': 0.1}]",ベイジアンアクティブラーニング
62,72,Bayesian analysis,ベイズ解析,0.1,10,"[{'word': 'ベイジアン分析', 'ratio': 0.5}, {'word': 'ベイズ分析', 'ratio': 0.4}, {'word': 'ベイズ解析', 'ratio': 0.1}]",ベイジアン分析
63,74,Bayesian clustering,ベイズクラスタリング,0.5,10,"[{'word': 'ベイズクラスタリング', 'ratio': 0.5}, {'word': 'ベイジアンクラスタリング', 'ratio': 0.5}]",ベイズクラスタリング
64,75,Bayesian decision,ベイズ決定,0.2,10,"[{'word': 'ベイズ的決定', 'ratio': 0.7}, {'word': 'ベイズ決定', 'ratio': 0.2}, {'word': 'ベイズ的意思決定', 'ratio': 0.1}]",ベイズ的決定
65,76,Bayesian deep learning,ベイズ深層学習,0.7,10,"[{'word': 'ベイズ深層学習', 'ratio': 0.7}, {'word': 'ベイズ型ディープラーニング', 'ratio': 0.1}, {'word': 'ベイジアンディープラーニング', 'ratio': 0.1}, {'word': 'ベイズ的ディープラーニング', 'ratio': 0.1}]",ベイズ深層学習
66,77,Bayesian evidence,ベイズ証拠,0.5,10,"[{'word': 'ベイズ証拠', 'ratio': 0.5}, {'word': 'ベイズ的証拠', 'ratio': 0.4}, {'word': 'ベイズの証拠', 'ratio': 0.1}]",ベイズ証拠
67,78,Bayesian framework,ベイズ的枠組み,0.2,10,"[{'word': 'ベイズフレームワーク', 'ratio': 0.5}, {'word': 'ベイズ的枠組み', 'ratio': 0.2}, {'word': 'ベイズのフレームワーク', 'ratio': 0.1}, {'word': 'ベイジアンフレームワーク', 'ratio': 0.1}, {'word': 'ベイズ的フレームワーク', 'ratio': 0.1}]",ベイズフレームワーク
68,79,Bayesian game,ベイジアンゲーム,0.0,10,"[{'word': 'ベイズゲーム', 'ratio': 0.8}, {'word': 'ベイジアン ゲーム', 'ratio': 0.1}, {'word': 'ベイズ的ゲーム', 'ratio': 0.1}]",ベイズゲーム
69,80,Bayesian inference,ベイズ推論,1.0,10,"[{'word': 'ベイズ推論', 'ratio': 1.0}]",ベイズ推論
70,81,Bayesian learning,ベイズ学習,1.0,10,"[{'word': 'ベイズ学習', 'ratio': 1.0}]",ベイズ学習
71,82,Bayesian method,ベイズ法,0.8,10,"[{'word': 'ベイズ法', 'ratio': 0.8}, {'word': 'ベイズ手法', 'ratio': 0.2}]",ベイズ法
72,83,Bayesian model,ベイズモデル,1.0,10,"[{'word': 'ベイズモデル', 'ratio': 1.0}]",ベイズモデル
73,84,Bayesian optimization,ベイズ最適化,1.0,10,"[{'word': 'ベイズ最適化', 'ratio': 1.0}]",ベイズ最適化
74,85,Bayesian perspective,ベイズ的観点,0.1,10,"[{'word': 'ベイズ的視点', 'ratio': 0.7}, {'word': 'ベイズの視点', 'ratio': 0.1}, {'word': 'ベイズ的な視点', 'ratio': 0.1}, {'word': 'ベイズ的観点', 'ratio': 0.1}]",ベイズ的視点
75,86,Bayesian probabilistic model,ベイズ確率モデル,0.5,10,"[{'word': 'ベイズ確率モデル', 'ratio': 0.5}, {'word': 'ベイズ的確率モデル', 'ratio': 0.5}]",ベイズ確率モデル
76,87,Bayesian update,ベイズ更新,0.7,10,"[{'word': 'ベイズ更新', 'ratio': 0.7}, {'word': 'ベイズ・アップデート', 'ratio': 0.1}, {'word': 'ベイズ的更新', 'ratio': 0.1}, {'word': 'ベイズ的アップデート', 'ratio': 0.1}]",ベイズ更新
77,88,Beam Search,ビーム探索,0.0,10,"[{'word': 'ビームサーチ', 'ratio': 0.9}, {'word': 'ビーム検索', 'ratio': 0.1}]",ビームサーチ
78,90,Bellman,ベルマン,1.0,10,"[{'word': 'ベルマン', 'ratio': 1.0}]",ベルマン
79,91,Bellman backup,ベルマンバックアップ,1.0,10,"[{'word': 'ベルマンバックアップ', 'ratio': 1.0}]",ベルマンバックアップ
80,92,Bellman equation,ベルマン方程式,1.0,10,"[{'word': 'ベルマン方程式', 'ratio': 1.0}]",ベルマン方程式
81,93,Bellman error,ベルマン誤差,0.9,10,"[{'word': 'ベルマン誤差', 'ratio': 0.9}, {'word': 'ベルマンエラー', 'ratio': 0.1}]",ベルマン誤差
82,94,Bellman operator,ベルマン演算子,0.9,10,"[{'word': 'ベルマン演算子', 'ratio': 0.9}, {'word': 'ベルマンオペレーター', 'ratio': 0.1}]",ベルマン演算子
83,96,Berkeley segmentation dataset,バークレー分割データセット,0.0,10,"[{'word': 'バークレーセグメンテーションデータセット', 'ratio': 0.7}, {'word': 'バークレーのセグメンテーション データセット', 'ratio': 0.2}, {'word': 'バークレー・セグメンテーションデータセット', 'ratio': 0.1}]",バークレーセグメンテーションデータセット
84,97,Bernoulli,ベルヌーイ,1.0,10,"[{'word': 'ベルヌーイ', 'ratio': 1.0}]",ベルヌーイ
85,98,Bernoulli distribution,ベルヌーイ分布,1.0,10,"[{'word': 'ベルヌーイ分布', 'ratio': 1.0}]",ベルヌーイ分布
86,99,Bernoulli likelihood,ベルヌーイ尤度,1.0,10,"[{'word': 'ベルヌーイ尤度', 'ratio': 1.0}]",ベルヌーイ尤度
87,101,Bernoulli sampling,ベルヌーイサンプリング,1.0,10,"[{'word': 'ベルヌーイサンプリング', 'ratio': 1.0}]",ベルヌーイサンプリング
88,102,Bernoulli trial,ベルヌーイ試行,0.8,10,"[{'word': 'ベルヌーイ試行', 'ratio': 0.8}, {'word': 'ベルヌーイ裁判', 'ratio': 0.2}]",ベルヌーイ試行
89,103,Bernoulli variable,ベルヌーイ変数,1.0,10,"[{'word': 'ベルヌーイ変数', 'ratio': 1.0}]",ベルヌーイ変数
90,104,Bernstein's inequality,ベルンシュタインの不等式,0.0,10,"[{'word': 'バーンスタインの不等式', 'ratio': 0.6}, {'word': 'バーンシュタインの不等式', 'ratio': 0.3}, {'word': 'バーンシュタ', 'ratio': 0.1}]",バーンスタインの不等式
91,105,Beta distribution,ベータ分布,1.0,10,"[{'word': 'ベータ分布', 'ratio': 1.0}]",ベータ分布
92,107,Bhattacharyya coefficient,バタチャリヤ係数,0.6,10,"[{'word': 'バタチャリヤ係数', 'ratio': 0.6}, {'word': 'バッタチャリヤ係数', 'ratio': 0.3}, {'word': 'バッタチャリーヤ係数', 'ratio': 0.1}]",バタチャリヤ係数
93,108,Binomial distribution,二項分布,1.0,10,"[{'word': '二項分布', 'ratio': 1.0}]",二項分布
94,109,Bloom filter,ブルームフィルタ,0.6,10,"[{'word': 'ブルームフィルタ', 'ratio': 0.6}, {'word': 'ブルームフィルター', 'ratio': 0.4}]",ブルームフィルタ
95,110,Boltzmann distribution,ボルツマン分布,1.0,10,"[{'word': 'ボルツマン分布', 'ratio': 1.0}]",ボルツマン分布
96,111,Boltzmann exploration,ボルツマン探索,0.8,10,"[{'word': 'ボルツマン探索', 'ratio': 0.8}, {'word': 'ボルツマン探査', 'ratio': 0.2}]",ボルツマン探索
97,112,Bonferroni correction,ボンフェローニ補正,1.0,10,"[{'word': 'ボンフェローニ補正', 'ratio': 1.0}]",ボンフェローニ補正
98,113,Boolean formula,ブール式,0.9,10,"[{'word': 'ブール式', 'ratio': 0.9}, {'word': 'ブール論理式', 'ratio': 0.1}]",ブール式
99,114,Boolean function,論理関数,0.0,10,"[{'word': 'ブール関数', 'ratio': 1.0}]",ブール関数
100,115,Boolean variable,ブール変数,1.0,10,"[{'word': 'ブール変数', 'ratio': 1.0}]",ブール変数
101,119,Bregman divergence,ブレグマン・ダイバージェンス,0.1,10,"[{'word': 'ブレグマン発散', 'ratio': 0.6}, {'word': 'ブレグマンダイバージェンス', 'ratio': 0.2}, {'word': 'ブレグマン・ダイバージェンス', 'ratio': 0.1}, {'word': 'ブレグマン分岐', 'ratio': 0.1}]",ブレグマン発散
102,120,Bregman's method,ブレグマン法,0.9,10,"[{'word': 'ブレグマン法', 'ratio': 0.9}, {'word': 'ブレグマンの方法', 'ratio': 0.1}]",ブレグマン法
103,121,Bundle adjustment,バンドル調整,1.0,10,"[{'word': 'バンドル調整', 'ratio': 1.0}]",バンドル調整
104,122,Byte-Pair Encoding,バイトペアエンコーディング,1.0,10,"[{'word': 'バイトペアエンコーディング', 'ratio': 1.0}]",バイトペアエンコーディング
105,124,Canny detector,キャニー検出器,0.8,10,"[{'word': 'キャニー検出器', 'ratio': 0.8}, {'word': '探知機', 'ratio': 0.2}]",キャニー検出器
106,125,Canny edge detector,キャニーエッジ検出器,1.0,10,"[{'word': 'キャニーエッジ検出器', 'ratio': 1.0}]",キャニーエッジ検出器
107,126,Categorical distribution,カテゴリカル分布,0.2,10,"[{'word': 'カテゴリ分布', 'ratio': 0.6}, {'word': 'カテゴリー分布', 'ratio': 0.2}, {'word': 'カテゴリカル分布', 'ratio': 0.2}]",カテゴリ分布
108,128,Charniak parser,チャーニアク構文解析器,0.0,10,"[{'word': 'チャーニアックパーサー', 'ratio': 0.6}, {'word': 'チャーニャックパーサー', 'ratio': 0.2}, {'word': 'シャルニアック・パーサー', 'ratio': 0.1}, {'word': 'シャーニアックパーサー', 'ratio': 0.1}]",チャーニアックパーサー
109,129,Chebyshev acceleration,チェビシェフ加速,1.0,10,"[{'word': 'チェビシェフ加速', 'ratio': 1.0}]",チェビシェフ加速
110,130,Chebyshev polynomial,チェビシェフ多項式,1.0,10,"[{'word': 'チェビシェフ多項式', 'ratio': 1.0}]",チェビシェフ多項式
111,132,Cholesky decomposition,コレスキー分解,1.0,10,"[{'word': 'コレスキー分解', 'ratio': 1.0}]",コレスキー分解
112,133,Cholesky factor,コレスキー因子,1.0,10,"[{'word': 'コレスキー因子', 'ratio': 1.0}]",コレスキー因子
113,134,Cholesky factorization,コレスキー分解,0.3,10,"[{'word': 'コレスキー因子分解', 'ratio': 0.6}, {'word': 'コレスキー分解', 'ratio': 0.3}, {'word': 'コレスキー因数分解', 'ratio': 0.1}]",コレスキー因子分解
114,135,Chomsky normal form,チョムスキー標準形,0.8,10,"[{'word': 'チョムスキー標準形', 'ratio': 0.8}, {'word': 'チョムスキー正規形', 'ratio': 0.2}]",チョムスキー標準形
115,138,Classifier,分類器,0.7,10,"[{'word': '分類器', 'ratio': 0.7}, {'word': 'クラシファイア', 'ratio': 0.1}, {'word': '分類子', 'ratio': 0.1}, {'word': 'クラッサー', 'ratio': 0.1}]",分類器
116,139,Cohen's kappa,コーエンのカッパ,0.9,10,"[{'word': 'コーエンのカッパ', 'ratio': 0.9}, {'word': 'コーヘンのカッパ', 'ratio': 0.1}]",コーエンのカッパ
117,140,Cohen's kappa coefficient,コーヘンのカッパ係数,0.0,9,"[{'word': 'コーエンのカッパ係数', 'ratio': 0.8888888888888888}, {'word': 'コーエン・カッパ係数', 'ratio': 0.1111111111111111}]",コーエンのカッパ係数
118,141,Cohen's κ,コーヘンのカッパ係数,0.0,10,"[{'word': 'コーエンのκ', 'ratio': 0.9}, {'word': 'コーエン・κ', 'ratio': 0.1}]",コーエンのκ
119,143,Commonsense Reasoning,常識推論,0.7,10,"[{'word': '常識推論', 'ratio': 0.7}, {'word': '常識的な推論', 'ratio': 0.2}, {'word': '共通感覚の推論', 'ratio': 0.1}]",常識推論
120,144,Compositionality,構成性,0.3,10,"[{'word': '合成性', 'ratio': 0.5}, {'word': '構成性', 'ratio': 0.3}, {'word': 'コンポジション', 'ratio': 0.1}, {'word': '組成性', 'ratio': 0.1}]",合成性
121,145,Compressed sensing,圧縮センシング,1.0,10,"[{'word': '圧縮センシング', 'ratio': 1.0}]",圧縮センシング
122,146,Computational linguistic,計算言語学,1.0,10,"[{'word': '計算言語学', 'ratio': 1.0}]",計算言語学
123,147,Computer Vision,コンピュータビジョン,0.8,10,"[{'word': 'コンピュータビジョン', 'ratio': 0.8}, {'word': 'コンピュータ・ビジョン', 'ratio': 0.1}, {'word': 'コンピューター・ビジョン', 'ratio': 0.1}]",コンピュータビジョン
124,148,Condition 1,条件1,0.8,10,"[{'word': '条件1', 'ratio': 0.8}, {'word': '条件', 'ratio': 0.1}, {'word': '条件 1', 'ratio': 0.1}]",条件1
125,149,Conditional Generation,条件付き生成,0.6,10,"[{'word': '条件付き生成', 'ratio': 0.6}, {'word': '条件生成', 'ratio': 0.3}, {'word': '条件付きジェネレーション', 'ratio': 0.1}]",条件付き生成
126,150,Conditional Random Field,条件付き確率場,0.0,10,"[{'word': '条件付きランダムフィールド', 'ratio': 1.0}]",条件付きランダムフィールド
127,152,Contrastive Learning,対照学習,0.7,10,"[{'word': '対照学習', 'ratio': 0.7}, {'word': 'コントラスト学習', 'ratio': 0.2}, {'word': '対比学習', 'ratio': 0.1}]",対照学習
128,153,Convolution,畳み込み,0.8,10,"[{'word': '畳み込み', 'ratio': 0.8}, {'word': 'コンボリューション', 'ratio': 0.2}]",畳み込み
129,155,Coreset,コアセット,1.0,10,"[{'word': 'コアセット', 'ratio': 1.0}]",コアセット
130,156,Corpora,コーパス,0.9,10,"[{'word': 'コーパス', 'ratio': 0.9}, {'word': 'コーパス群', 'ratio': 0.1}]",コーパス
131,157,Corpus,コーパス,1.0,10,"[{'word': 'コーパス', 'ratio': 1.0}]",コーパス
132,158,Cosine Similarity,コサイン類似度,1.0,10,"[{'word': 'コサイン類似度', 'ratio': 1.0}]",コサイン類似度
133,159,Cosine distance,コサイン距離,1.0,10,"[{'word': 'コサイン距離', 'ratio': 1.0}]",コサイン距離
134,160,Counterfactual Regret Minimization,反事実的後悔最小化 (CFR),0.0,10,"[{'word': '反事実的後悔最小化', 'ratio': 0.6}, {'word': '反実仮想後悔最小化', 'ratio': 0.2}, {'word': '反実仮想悔恨最小化', 'ratio': 0.2}]",反事実的後悔最小化
135,161,Covariance,共分散,1.0,10,"[{'word': '共分散', 'ratio': 1.0}]",共分散
136,162,Cross Entropy Loss,交差エントロピー損失,0.0,10,"[{'word': 'クロスエントロピー損失', 'ratio': 0.8}, {'word': 'クロス・エントロピー損失', 'ratio': 0.2}]",クロスエントロピー損失
137,163,Data Augmentation,データ拡張,0.8,10,"[{'word': 'データ拡張', 'ratio': 0.8}, {'word': 'データ補強', 'ratio': 0.2}]",データ拡張
138,164,Datalog,データログ,0.9,10,"[{'word': 'データログ', 'ratio': 0.9}, {'word': 'コンピュータ科学者', 'ratio': 0.1}]",データログ
139,166,Dataset,データセット,0.9,10,"[{'word': 'データセット', 'ratio': 0.9}, {'word': 'データ集合', 'ratio': 0.1}]",データセット
140,167,Decentralized optimization,分散最適化,0.5,10,"[{'word': '分散最適化', 'ratio': 0.5}, {'word': '非中央集権最適化', 'ratio': 0.2}, {'word': '分散型の最適化', 'ratio': 0.1}, {'word': '非集中最適化', 'ratio': 0.1}, {'word': '分散型最適化', 'ratio': 0.1}]",分散最適化
141,168,Decision Transformer,"""決定Transformer""",0.0,10,"[{'word': 'デシジョントランスフォーマー', 'ratio': 0.7}, {'word': '意思決定トランスフォーマー', 'ratio': 0.1}, {'word': '決定トランス', 'ratio': 0.1}, {'word': 'ディシジョントランスフォーマー', 'ratio': 0.1}]",デシジョントランスフォーマー
142,169,Decoder,デコーダー,0.8,10,"[{'word': 'デコーダー', 'ratio': 0.8}, {'word': 'デコーダ', 'ratio': 0.2}]",デコーダー
143,171,Decomposable Attention Model,分解可能な注意モデル,0.4,10,"[{'word': '分解可能注意モデル', 'ratio': 0.5}, {'word': '分解可能な注意モデル', 'ratio': 0.4}, {'word': '分解可能アテンションモデル', 'ratio': 0.1}]",分解可能注意モデル
144,172,Deep Belief Network,ディープ・ビリーフ・ネットワーク,0.2,10,"[{'word': '深層信念ネットワーク', 'ratio': 0.7}, {'word': 'ディープ・ビリーフ・ネットワーク', 'ratio': 0.2}, {'word': 'ディープビリーフネットワーク', 'ratio': 0.1}]",深層信念ネットワーク
145,173,Deep Learning,深層学習,0.7,10,"[{'word': '深層学習', 'ratio': 0.7}, {'word': 'ディープラーニング', 'ratio': 0.3}]",深層学習
146,175,Denoising Autoencoder,デノイジングオートエンコーダー,0.0,10,"[{'word': 'デノイジングオートエンコーダ', 'ratio': 0.5}, {'word': '雑音除去オートエンコーダ', 'ratio': 0.2}, {'word': 'ノイズ除去オートエンコーダー', 'ratio': 0.2}, {'word': 'ノイズ除去自己符号伝送', 'ratio': 0.1}]",デノイジングオートエンコーダ
147,176,Detectron,Detectron,0.1,10,"[{'word': 'ディテクトロン', 'ratio': 0.8}, {'word': 'Detectron', 'ratio': 0.1}, {'word': '検出ロボット', 'ratio': 0.1}]",ディテクトロン
148,177,Determinantal Point process,決定的点過程,0.0,10,"[{'word': '行列式点過程', 'ratio': 0.5}, {'word': '決定点プロセス', 'ratio': 0.2}, {'word': '行列式ポイントプロセス', 'ratio': 0.1}, {'word': '決定行列点過程', 'ratio': 0.1}, {'word': '決定則点過程', 'ratio': 0.1}]",行列式点過程
149,178,Dialogue State Tracking,ダイアログ状態追跡,0.5,10,"[{'word': 'ダイアログ状態追跡', 'ratio': 0.5}, {'word': '対話状態のトラッキング', 'ratio': 0.2}, {'word': '対話状態追跡', 'ratio': 0.2}, {'word': '会話状態追跡', 'ratio': 0.1}]",ダイアログ状態追跡
150,179,Dice coefficient,ダイス係数,0.7,10,"[{'word': 'ダイス係数', 'ratio': 0.7}, {'word': 'サイコロ係数', 'ratio': 0.2}, {'word': 'ディチェ係数', 'ratio': 0.1}]",ダイス係数
151,180,Dice loss,ダイス損失,0.6,10,"[{'word': 'ダイス損失', 'ratio': 0.6}, {'word': 'サイコロ負け', 'ratio': 0.2}, {'word': 'ダイスロス', 'ratio': 0.1}, {'word': 'ディチェ損失', 'ratio': 0.1}]",ダイス損失
152,181,Dijkstra's algorithm,ダイクストラのアルゴリズム,0.5,10,"[{'word': 'ダイクストラのアルゴリズム', 'ratio': 0.5}, {'word': 'ダイクストラ・アルゴリズム', 'ratio': 0.2}, {'word': 'ダイクストラアルゴリズム', 'ratio': 0.2}, {'word': 'ディクシュタのアルゴリズム', 'ratio': 0.1}]",ダイクストラのアルゴリズム
153,182,Dirac distribution,ディラック分布,1.0,10,"[{'word': 'ディラック分布', 'ratio': 1.0}]",ディラック分布
154,183,Dirac measure,ディラック測度,0.8,10,"[{'word': 'ディラック測度', 'ratio': 0.8}, {'word': 'ディラックの測度', 'ratio': 0.2}]",ディラック測度
155,184,Dirichlet,ディリクレ分布,0.0,10,"[{'word': 'ディリクレ', 'ratio': 0.9}, {'word': 'ディリケルト', 'ratio': 0.1}]",ディリクレ
156,185,Dirichlet Process,ディリクレ過程,0.9,10,"[{'word': 'ディリクレ過程', 'ratio': 0.9}, {'word': 'ディリケルトプロセス', 'ratio': 0.1}]",ディリクレ過程
157,186,Dirichlet distribution,ディリクレ分布,0.9,10,"[{'word': 'ディリクレ分布', 'ratio': 0.9}, {'word': 'ディリケルト分布', 'ratio': 0.1}]",ディリクレ分布
158,187,Dirichlet prior,ディリクレ事前分布,0.8,10,"[{'word': 'ディリクレ事前分布', 'ratio': 0.8}, {'word': 'ディリクレ事前分', 'ratio': 0.1}, {'word': 'ディリケルト事前分布', 'ratio': 0.1}]",ディリクレ事前分布
159,188,Discretization,離散化,1.0,10,"[{'word': '離散化', 'ratio': 1.0}]",離散化
160,191,Domain Adaptation,ドメイン適応,0.9,10,"[{'word': 'ドメイン適応', 'ratio': 0.9}, {'word': 'ドメインアダプテーション', 'ratio': 0.1}]",ドメイン適応
161,192,Dropout,ドロップアウト,1.0,10,"[{'word': 'ドロップアウト', 'ratio': 1.0}]",ドロップアウト
162,193,Dropout distribution,ドロップアウト分布,1.0,10,"[{'word': 'ドロップアウト分布', 'ratio': 1.0}]",ドロップアウト分布
163,194,Dynamic Programming,動的計画法,0.7,10,"[{'word': '動的計画法', 'ratio': 0.7}, {'word': 'ダイナミック・プログラミング', 'ratio': 0.2}, {'word': 'ドロップアウト分布', 'ratio': 0.1}]",動的計画法
164,195,E-step,Eステップ,1.0,10,"[{'word': 'Eステップ', 'ratio': 1.0}]",Eステップ
165,196,Elastic Net,エラスティックネット,0.8,10,"[{'word': 'エラスティックネット', 'ratio': 0.8}, {'word': 'エラスティック・ネット', 'ratio': 0.2}]",エラスティックネット
166,197,Electra,Electra,0.2,10,"[{'word': 'エレクトラ', 'ratio': 0.8}, {'word': 'Electra', 'ratio': 0.2}]",エレクトラ
167,198,Encoder,エンコーダー,0.2,10,"[{'word': 'エンコーダ', 'ratio': 0.8}, {'word': 'エンコーダー', 'ratio': 0.2}]",エンコーダ
168,199,Encoder-Decoder,エンコーダー・デコーダー,0.2,10,"[{'word': 'エンコーダ・デコーダ', 'ratio': 0.7}, {'word': 'エンコーダー・デコーダー', 'ratio': 0.2}, {'word': 'エンコーダ-デコーダ', 'ratio': 0.1}]",エンコーダ・デコーダ
169,200,Entity Linking,エンティティリンキング,0.0,10,"[{'word': 'エンティティリンク', 'ratio': 0.8}, {'word': 'エンティティ・リンク', 'ratio': 0.2}]",エンティティリンク
170,201,Entropy,エントロピー,1.0,10,"[{'word': 'エントロピー', 'ratio': 1.0}]",エントロピー
171,203,Euclidean,ユークリッド距離,0.0,10,"[{'word': 'ユークリッド', 'ratio': 1.0}]",ユークリッド
172,204,Euclidean distance,ユークリッド距離,1.0,10,"[{'word': 'ユークリッド距離', 'ratio': 1.0}]",ユークリッド距離
173,205,Euclidean divergence,ユークリッド発散,0.4,10,"[{'word': 'ユークリッドダイバージェンス', 'ratio': 0.5}, {'word': 'ユークリッド発散', 'ratio': 0.4}, {'word': 'ユークリッド散逸', 'ratio': 0.1}]",ユークリッドダイバージェンス
174,206,Euclidean loss,ユークリッドロス,0.2,10,"[{'word': 'ユークリッド損失', 'ratio': 0.8}, {'word': 'ユークリッドロス', 'ratio': 0.2}]",ユークリッド損失
175,207,Euclidean norm,ユークリッドノルム,0.9,10,"[{'word': 'ユークリッドノルム', 'ratio': 0.9}, {'word': 'ユークリッド・ノルム', 'ratio': 0.1}]",ユークリッドノルム
176,208,Euclidean plane,ユークリッド平面,1.0,10,"[{'word': 'ユークリッド平面', 'ratio': 1.0}]",ユークリッド平面
177,209,Euclidean projection,ユークリッド射影,0.8,10,"[{'word': 'ユークリッド射影', 'ratio': 0.8}, {'word': 'ユークリッド投影', 'ratio': 0.2}]",ユークリッド射影
178,210,Euclidean space,ユークリッド空間,1.0,10,"[{'word': 'ユークリッド空間', 'ratio': 1.0}]",ユークリッド空間
179,211,Euclidean transformation,ユークリッド変換,1.0,10,"[{'word': 'ユークリッド変換', 'ratio': 1.0}]",ユークリッド変換
180,212,Euler angle,オイラー角,1.0,10,"[{'word': 'オイラー角', 'ratio': 1.0}]",オイラー角
181,213,Euler step,オイラーステップ,0.5,10,"[{'word': 'オイラーステップ', 'ratio': 0.5}, {'word': 'オイラー法', 'ratio': 0.4}, {'word': 'オイラー手法', 'ratio': 0.1}]",オイラーステップ
182,214,Exact Match,完全一致,0.9,10,"[{'word': '完全一致', 'ratio': 0.9}, {'word': '正確な一致', 'ratio': 0.1}]",完全一致
183,215,Expectation Maximization,期待値最大化,0.8,10,"[{'word': '期待値最大化', 'ratio': 0.8}, {'word': '期待の最大化', 'ratio': 0.2}]",期待値最大化
184,216,Expectation Maximization algorithm,期待値最大化アルゴリズム,1.0,10,"[{'word': '期待値最大化アルゴリズム', 'ratio': 1.0}]",期待値最大化アルゴリズム
185,217,Exponential distribution,指数分布,1.0,10,"[{'word': '指数分布', 'ratio': 1.0}]",指数分布
186,218,Extended Kalman Filter,拡張カルマンフィルター,0.5,10,"[{'word': '拡張カルマンフィルター', 'ratio': 0.5}, {'word': '拡張カルマンフィルタ', 'ratio': 0.5}]",拡張カルマンフィルター
187,219,F-measure,F-測定,0.0,10,"[{'word': 'F値', 'ratio': 0.9}, {'word': 'Fメジャー', 'ratio': 0.1}]",F値
188,220,F-score,F値,0.0,10,"[{'word': 'Fスコア', 'ratio': 1.0}]",Fスコア
189,221,F1 measure,F1 メジャー,0.0,10,"[{'word': 'F1スコア', 'ratio': 0.5}, {'word': 'F1値', 'ratio': 0.3}, {'word': 'F1メジャー', 'ratio': 0.1}, {'word': 'F1測定', 'ratio': 0.1}]",F1スコア
190,222,F1 metric,F1指標,0.0,10,"[{'word': 'F1メトリック', 'ratio': 0.7}, {'word': 'F1メトリクス', 'ratio': 0.1}, {'word': 'F1 メトリック', 'ratio': 0.1}, {'word': 'F1スコア', 'ratio': 0.1}]",F1メトリック
191,223,F1 score,F1スコア,0.8,10,"[{'word': 'F1スコア', 'ratio': 0.8}, {'word': 'F1メトリック', 'ratio': 0.1}, {'word': 'F1 スコア', 'ratio': 0.1}]",F1スコア
192,224,Fairseq,Fairseq,0.2,10,"[{'word': 'フェアセク', 'ratio': 0.6}, {'word': 'Fairseq', 'ratio': 0.2}, {'word': 'フェアセック', 'ratio': 0.1}, {'word': 'フェアシーク', 'ratio': 0.1}]",フェアセク
193,225,Fano's inequality,ファノの不等式,1.0,10,"[{'word': 'ファノの不等式', 'ratio': 1.0}]",ファノの不等式
194,226,Fast Fourier Transform,高速フーリエ変換,1.0,10,"[{'word': '高速フーリエ変換', 'ratio': 1.0}]",高速フーリエ変換
195,227,Feature Pyramid Network,特徴ピラミッドネットワーク (FPN),0.0,10,"[{'word': '特徴ピラミッドネットワーク', 'ratio': 0.8}, {'word': 'フィーチャー・ピラミッド・ネットワーク', 'ratio': 0.2}]",特徴ピラミッドネットワーク
196,228,Federated Learning,連合学習 (れんごうがくしゅう),0.0,10,"[{'word': 'フェデレーテッドラーニング', 'ratio': 0.7}, {'word': 'フェデレーテッド・ラーニング', 'ratio': 0.2}, {'word': '分散学習', 'ratio': 0.1}]",フェデレーテッドラーニング
197,229,Fisher information matrix,フィッシャー情報行列,1.0,10,"[{'word': 'フィッシャー情報行列', 'ratio': 1.0}]",フィッシャー情報行列
198,230,Fisher score,フィッシャースコア,1.0,10,"[{'word': 'フィッシャースコア', 'ratio': 1.0}]",フィッシャースコア
199,231,Fleiss' kappa,フリース・カッパ,0.0,10,"[{'word': 'フレイスのカッパ', 'ratio': 0.5}, {'word': 'フライスのカッパ', 'ratio': 0.3}, {'word': 'フライスの河童', 'ratio': 0.1}, {'word': 'フレイスカッパ', 'ratio': 0.1}]",フレイスのカッパ
200,233,Focal Loss,焦点損失,0.2,10,"[{'word': 'フォーカルロス', 'ratio': 0.8}, {'word': '焦点損失', 'ratio': 0.2}]",フォーカルロス
201,234,Fokker-Planck equation,フォッカー・プランク方程式,0.7,10,"[{'word': 'フォッカー・プランク方程式', 'ratio': 0.7}, {'word': 'フォッカー-プランク方程式', 'ratio': 0.3}]",フォッカー・プランク方程式
202,235,Fourier Transform,フーリエ変換,1.0,10,"[{'word': 'フーリエ変換', 'ratio': 1.0}]",フーリエ変換
203,236,Fourier basis function,フーリエ基底関数,1.0,10,"[{'word': 'フーリエ基底関数', 'ratio': 1.0}]",フーリエ基底関数
204,237,Fourier coefficient,フーリエ係数,1.0,10,"[{'word': 'フーリエ係数', 'ratio': 1.0}]",フーリエ係数
205,238,Fourier feature,フーリエ特徴量,0.1,10,"[{'word': 'フーリエ特徴', 'ratio': 0.8}, {'word': 'フーリエ機能', 'ratio': 0.1}, {'word': 'フーリエ特徴量', 'ratio': 0.1}]",フーリエ特徴
206,239,Fourier frequency,フーリエ周波数,1.0,10,"[{'word': 'フーリエ周波数', 'ratio': 1.0}]",フーリエ周波数
207,240,Frobenius Norm,フロベニウスノルム,0.8,10,"[{'word': 'フロベニウスノルム', 'ratio': 0.8}, {'word': 'フロベニウス・ノルム', 'ratio': 0.2}]",フロベニウスノルム
208,241,Frobenius inner product,フロベニウス内積,0.9,10,"[{'word': 'フロベニウス内積', 'ratio': 0.9}, {'word': 'フロベニウスの内積', 'ratio': 0.1}]",フロベニウス内積
209,242,Fréchet,フレシェ分布,0.0,10,"[{'word': 'フレーシェ', 'ratio': 0.6}, {'word': 'フレシェ', 'ratio': 0.4}]",フレーシェ
210,243,Gamma distribution,ガンマ分布,0.9,10,"[{'word': 'ガンマ分布', 'ratio': 0.9}, {'word': 'GPT ガンマ分布', 'ratio': 0.1}]",ガンマ分布
211,244,Gamma prior,ガンマ事前分布,0.8,10,"[{'word': 'ガンマ事前分布', 'ratio': 0.8}, {'word': 'ガンマ前置法', 'ratio': 0.2}]",ガンマ事前分布
212,245,Gauss-Newton algorithm,ガウス・ニュートン法,0.5,10,"[{'word': 'ガウス・ニュートン法', 'ratio': 0.5}, {'word': 'ガウス-ニュートンアルゴリズム', 'ratio': 0.2}, {'word': 'ガウス・ニュートン・アルゴリズム', 'ratio': 0.1}, {'word': 'ガウスニュートンアルゴリズム', 'ratio': 0.1}, {'word': 'ガウス＝ニュートン法', 'ratio': 0.1}]",ガウス・ニュートン法
213,246,Gauss-Seidel method,ガウス・ザイデル法,0.6,10,"[{'word': 'ガウス・ザイデル法', 'ratio': 0.6}, {'word': 'ガウス-サイデル法', 'ratio': 0.1}, {'word': 'ガウス・サイデル法', 'ratio': 0.1}, {'word': 'ガウス＝サイデル法', 'ratio': 0.1}, {'word': 'ガウス-ザイデル法', 'ratio': 0.1}]",ガウス・ザイデル法
214,247,Gaussian Mixture Model,ガウス混合モデル,0.9,10,"[{'word': 'ガウス混合モデル', 'ratio': 0.9}, {'word': '混合ガウスモデル', 'ratio': 0.1}]",ガウス混合モデル
215,248,Gaussian Process,ガウス過程,1.0,10,"[{'word': 'ガウス過程', 'ratio': 1.0}]",ガウス過程
216,249,Gaussian blur,ガウスぼかし,1.0,10,"[{'word': 'ガウスぼかし', 'ratio': 1.0}]",ガウスぼかし
217,250,Gaussian complexity,ガウス複雑度,0.1,10,"[{'word': 'ガウス複雑性', 'ratio': 0.5}, {'word': 'ガウスの複雑さ', 'ratio': 0.2}, {'word': 'ガウスの複雑性', 'ratio': 0.2}, {'word': 'ガウス複雑度', 'ratio': 0.1}]",ガウス複雑性
218,251,Gaussian component,ガウス成分,1.0,10,"[{'word': 'ガウス成分', 'ratio': 1.0}]",ガウス成分
219,253,Gaussian density,ガウス密度,1.0,10,"[{'word': 'ガウス密度', 'ratio': 1.0}]",ガウス密度
220,254,Gaussian distribution,正規分布,0.0,10,"[{'word': 'ガウス分布', 'ratio': 1.0}]",ガウス分布
221,255,Gaussian elimination,ガウス消去法,0.7,10,"[{'word': 'ガウス消去法', 'ratio': 0.7}, {'word': 'ガウス消去', 'ratio': 0.2}, {'word': 'ガウスの消去法', 'ratio': 0.1}]",ガウス消去法
222,256,Gaussian filter,ガウシアンフィルタ,0.0,10,"[{'word': 'ガウスフィルタ', 'ratio': 0.8}, {'word': 'ガウシアンフィルター', 'ratio': 0.2}]",ガウスフィルタ
223,257,Gaussian function,ガウス関数,1.0,10,"[{'word': 'ガウス関数', 'ratio': 1.0}]",ガウス関数
224,258,Gaussian initialization,ガウス初期化,1.0,10,"[{'word': 'ガウス初期化', 'ratio': 1.0}]",ガウス初期化
225,259,Gaussian kernel,ガウスカーネル,0.8,10,"[{'word': 'ガウスカーネル', 'ratio': 0.8}, {'word': 'ガウシアンカーネル', 'ratio': 0.2}]",ガウスカーネル
226,260,Gaussian likelihood,ガウス尤度,0.9,10,"[{'word': 'ガウス尤度', 'ratio': 0.9}, {'word': 'ガウスの尤度', 'ratio': 0.1}]",ガウス尤度
227,261,Gaussian matrix,ガウス行列,0.3,10,"[{'word': 'ガウスマトリックス', 'ratio': 0.7}, {'word': 'ガウス行列', 'ratio': 0.3}]",ガウスマトリックス
228,262,Gaussian mixture,ガウス混合,1.0,10,"[{'word': 'ガウス混合', 'ratio': 1.0}]",ガウス混合
229,263,Gaussian model,ガウスモデル,1.0,10,"[{'word': 'ガウスモデル', 'ratio': 1.0}]",ガウスモデル
230,264,Gaussian noise,ガウス雑音,0.2,10,"[{'word': 'ガウスノイズ', 'ratio': 0.8}, {'word': 'ガウス雑音', 'ratio': 0.2}]",ガウスノイズ
231,265,Gaussian prior,ガウス事前分布,1.0,10,"[{'word': 'ガウス事前分布', 'ratio': 1.0}]",ガウス事前分布
232,266,Gaussian process model,ガウス過程モデル,1.0,10,"[{'word': 'ガウス過程モデル', 'ratio': 1.0}]",ガウス過程モデル
233,267,Gaussian process regression,ガウス過程回帰,1.0,10,"[{'word': 'ガウス過程回帰', 'ratio': 1.0}]",ガウス過程回帰
234,268,Gaussian random variable,ガウスランダム変数,0.3,10,"[{'word': 'ガウス確率変数', 'ratio': 0.5}, {'word': 'ガウスランダム変数', 'ratio': 0.3}, {'word': 'ガウス乱数変数', 'ratio': 0.1}, {'word': 'ガウス乱数', 'ratio': 0.1}]",ガウス確率変数
235,269,Gaussian smoothing,ガウス平滑化,1.0,10,"[{'word': 'ガウス平滑化', 'ratio': 1.0}]",ガウス平滑化
236,270,Gaussian variable,ガウス変数,1.0,10,"[{'word': 'ガウス変数', 'ratio': 1.0}]",ガウス変数
237,271,Gaussian weight,ガウス重み,0.8,10,"[{'word': 'ガウス重み', 'ratio': 0.8}, {'word': 'ガウシアン・ウェイト', 'ratio': 0.2}]",ガウス重み
238,273,Generative Adversarial Networks,敵対的生成ネットワーク,0.6,10,"[{'word': '敵対的生成ネットワーク', 'ratio': 0.6}, {'word': '生成的逆数ネットワーク', 'ratio': 0.2}, {'word': '生成的敵対ネットワーク', 'ratio': 0.1}, {'word': '生成的対抗ネットワーク', 'ratio': 0.1}]",敵対的生成ネットワーク
239,274,Generative Model,生成モデル,0.9,10,"[{'word': '生成モデル', 'ratio': 0.9}, {'word': 'ジェネレーティブモデル', 'ratio': 0.1}]",生成モデル
240,275,Generator,ジェネレータ,0.2,10,"[{'word': 'ジェネレーター', 'ratio': 0.8}, {'word': 'ジェネレータ', 'ratio': 0.2}]",ジェネレーター
241,276,Genetic algorithm,遺伝的アルゴリズム,1.0,10,"[{'word': '遺伝的アルゴリズム', 'ratio': 1.0}]",遺伝的アルゴリズム
242,277,Gensim,Gensim,0.1,10,"[{'word': 'ゲン', 'ratio': 0.7}, {'word': 'ゲンシム', 'ratio': 0.1}, {'word': 'ジンズィム', 'ratio': 0.1}, {'word': 'Gensim', 'ratio': 0.1}]",ゲン
243,278,Gibbs Sampling,ギブス・サンプリング,0.2,10,"[{'word': 'ギブスサンプリング', 'ratio': 0.7}, {'word': 'ギブス・サンプリング', 'ratio': 0.2}, {'word': 'ジブズサンプリング', 'ratio': 0.1}]",ギブスサンプリング
244,279,Gibbs iteration,ギブス・イテレーション,0.0,10,"[{'word': 'ギブス反復', 'ratio': 0.6}, {'word': 'ギブズの反復', 'ratio': 0.2}, {'word': 'ギブス', 'ratio': 0.1}, {'word': 'ジブズイテレーション', 'ratio': 0.1}]",ギブス反復
245,280,Gibbs sampler,ギブスサンプラー,0.6,10,"[{'word': 'ギブスサンプラー', 'ratio': 0.6}, {'word': 'ギブスサンプリング', 'ratio': 0.3}, {'word': 'ギブス・サンプラー', 'ratio': 0.1}]",ギブスサンプラー
246,281,Gini coefficient,ジニ係数,1.0,10,"[{'word': 'ジニ係数', 'ratio': 1.0}]",ジニ係数
247,282,Good-Turing estimate,グッド・チューリング推定,0.9,10,"[{'word': 'グッド・チューリング推定', 'ratio': 0.9}, {'word': 'チューリング推定', 'ratio': 0.1}]",グッド・チューリング推定
248,283,GoogLeNet,GoogLeNet,0.5,10,"[{'word': 'グーグルネット', 'ratio': 0.5}, {'word': 'GoogLeNet', 'ratio': 0.5}]",グーグルネット
249,284,Gradient,勾配,0.9,10,"[{'word': '勾配', 'ratio': 0.9}, {'word': 'グラデーション', 'ratio': 0.1}]",勾配
250,285,Gradient descent,勾配降下法,0.9,10,"[{'word': '勾配降下法', 'ratio': 0.9}, {'word': '勾配降下', 'ratio': 0.1}]",勾配降下法
251,286,Gram matrix,グラム行列,1.0,10,"[{'word': 'グラム行列', 'ratio': 1.0}]",グラム行列
252,287,Graph,グラフ,1.0,10,"[{'word': 'グラフ', 'ratio': 1.0}]",グラフ
253,288,Graph Neural Networks,グラフニューラルネットワーク (GNNs),0.0,10,"[{'word': 'グラフニューラルネットワーク', 'ratio': 0.9}, {'word': 'グラフ・ニューラル・ネットワーク', 'ratio': 0.1}]",グラフニューラルネットワーク
254,289,Graph Transformer,グラフ トランスフォーマー,0.0,10,"[{'word': 'グラフトランスフォーマー', 'ratio': 0.9}, {'word': 'グラフ・トランスフォーマー', 'ratio': 0.1}]",グラフトランスフォーマー
255,290,Greedy,貪欲法,0.5,10,"[{'word': '貪欲法', 'ratio': 0.5}, {'word': 'グリーディ', 'ratio': 0.2}, {'word': 'よく深い', 'ratio': 0.2}, {'word': '貪欲な', 'ratio': 0.1}]",貪欲法
256,291,Ground Truth,正解データ,0.2,10,"[{'word': 'グラウンドトゥルース', 'ratio': 0.7}, {'word': '正解データ', 'ratio': 0.2}, {'word': '基準値', 'ratio': 0.1}]",グラウンドトゥルース
257,292,Gröbner basis,グレブナー基底,0.5,10,"[{'word': 'グレブナー基底', 'ratio': 0.5}, {'word': 'グレブナー基地', 'ratio': 0.2}, {'word': 'グローバー基底', 'ratio': 0.2}, {'word': 'グローバナー基底', 'ratio': 0.1}]",グレブナー基底
258,293,Gumbel,ガンベル,1.0,10,"[{'word': 'ガンベル', 'ratio': 1.0}]",ガンベル
259,294,Gumbel distribution,ガンベル分布,1.0,10,"[{'word': 'ガンベル分布', 'ratio': 1.0}]",ガンベル分布
260,295,Gumbel noise,ガンベルノイズ,1.0,10,"[{'word': 'ガンベルノイズ', 'ratio': 1.0}]",ガンベルノイズ
261,296,Gumbel-softmax distribution,ガンベル-ソフトマックス分布,0.0,10,"[{'word': 'ガンベルソフトマックス分布', 'ratio': 0.7}, {'word': 'ガンベル・ソフトマックス分布', 'ratio': 0.3}]",ガンベルソフトマックス分布
262,297,Haar wavelet,ハール・ウェーブレット,0.2,10,"[{'word': 'ハールウェーブレット', 'ratio': 0.8}, {'word': 'ハール・ウェーブレット', 'ratio': 0.2}]",ハールウェーブレット
263,298,Hadamard matrix,アダマール行列,0.1,10,"[{'word': 'ハダマード行列', 'ratio': 0.7}, {'word': 'ハダマール行列', 'ratio': 0.2}, {'word': 'アダマール行列', 'ratio': 0.1}]",ハダマード行列
264,299,Hadamard product,ハダマード積,0.7,10,"[{'word': 'ハダマード積', 'ratio': 0.7}, {'word': 'ハダマール積', 'ratio': 0.2}, {'word': 'アダマール積', 'ratio': 0.1}]",ハダマード積
265,300,Hamiltonian Monte Carlo,ハミルトニアンモンテカルロ,0.2,10,"[{'word': 'ハミルトンモンテカルロ', 'ratio': 0.6}, {'word': 'ハミルトニアンモンテカルロ', 'ratio': 0.2}, {'word': 'ハミルトニアン・モンテカルロ', 'ratio': 0.1}, {'word': 'ハミルトニアン モンテカルロ法', 'ratio': 0.1}]",ハミルトンモンテカルロ
266,301,Hamming distance,ハミング距離,1.0,10,"[{'word': 'ハミング距離', 'ratio': 1.0}]",ハミング距離
267,302,Hamming loss,ハミング損失,0.9,10,"[{'word': 'ハミング損失', 'ratio': 0.9}, {'word': 'ハミングロス', 'ratio': 0.1}]",ハミング損失
268,303,Hankel matrix,ハンケル行列,1.0,10,"[{'word': 'ハンケル行列', 'ratio': 1.0}]",ハンケル行列
269,304,Hausdorff distance,ハウスドルフ距離,1.0,10,"[{'word': 'ハウスドルフ距離', 'ratio': 1.0}]",ハウスドルフ距離
270,305,Hedge algorithm,ヘッジアルゴリズム,0.9,10,"[{'word': 'ヘッジアルゴリズム', 'ratio': 0.9}, {'word': 'エッジアルゴリズム', 'ratio': 0.1}]",ヘッジアルゴリズム
271,306,Hellinger distance,ヘリンガー距離,0.4,10,"[{'word': 'ヘリング距離', 'ratio': 0.5}, {'word': 'ヘリンガー距離', 'ratio': 0.4}, {'word': 'ヘルンガー距離', 'ratio': 0.1}]",ヘリング距離
272,307,Helmholtz machine,ヘルムホルツマシン,0.8,10,"[{'word': 'ヘルムホルツマシン', 'ratio': 0.8}, {'word': 'ヘルムホルツ・マシン', 'ratio': 0.2}]",ヘルムホルツマシン
273,308,Hessian matrix,ヘシアン行列,0.2,10,"[{'word': 'ヘッセ行列', 'ratio': 0.5}, {'word': 'ヘシアン行列', 'ratio': 0.2}, {'word': 'ヘッシアン行列', 'ratio': 0.2}, {'word': 'ヘッセン行列', 'ratio': 0.1}]",ヘッセ行列
274,309,Hessian-vector product,ヘシアン・ベクトル積,0.2,10,"[{'word': 'ヘッセ行列-ベクトル積', 'ratio': 0.6}, {'word': 'ヘシアン・ベクトル積', 'ratio': 0.2}, {'word': 'ヘッセ行列ベクトル積', 'ratio': 0.1}, {'word': 'ヘッシアンベクトル積', 'ratio': 0.1}]",ヘッセ行列-ベクトル積
275,310,Hidden Markov Model,隠れマルコフモデル,1.0,10,"[{'word': '隠れマルコフモデル', 'ratio': 1.0}]",隠れマルコフモデル
276,311,Hiero system,Hiero システム,0.0,10,"[{'word': 'ヒエロシステム', 'ratio': 0.7}, {'word': 'ヒーローシステム', 'ratio': 0.2}, {'word': 'ハイエロシステム', 'ratio': 0.1}]",ヒエロシステム
277,312,Hodge decomposition,ホッジ分解,1.0,10,"[{'word': 'ホッジ分解', 'ratio': 1.0}]",ホッジ分解
278,314,Homography,同形写像,0.0,10,"[{'word': 'ホモグラフィ', 'ratio': 0.6}, {'word': 'ホモグラフィー', 'ratio': 0.4}]",ホモグラフィ
279,315,Horn theory,ホーン理論,1.0,10,"[{'word': 'ホーン理論', 'ratio': 1.0}]",ホーン理論
280,316,HowTo100M,HowTo100M,0.8,10,"[{'word': 'HowTo100M', 'ratio': 0.8}, {'word': 'ハウツー100M', 'ratio': 0.2}]",HowTo100M
281,319,Hungarian loss,ハンガリアン損失,0.5,10,"[{'word': 'ハンガリアン損失', 'ratio': 0.5}, {'word': 'ハンガリアンロス', 'ratio': 0.3}, {'word': 'ハンガリー敗戦', 'ratio': 0.1}, {'word': 'ハンガリーの敗戦', 'ratio': 0.1}]",ハンガリアン損失
282,320,Hyper-parameter,ハイパーパラメータ,0.9,10,"[{'word': 'ハイパーパラメータ', 'ratio': 0.9}, {'word': 'ハイパーパラメーター', 'ratio': 0.1}]",ハイパーパラメータ
283,321,Hyperband,ハイパーバンド,1.0,10,"[{'word': 'ハイパーバンド', 'ratio': 1.0}]",ハイパーバンド
284,322,Hyperparameter search,ハイパーパラメータ探索,0.7,10,"[{'word': 'ハイパーパラメータ探索', 'ratio': 0.7}, {'word': 'ハイパーパラメータ検索', 'ratio': 0.3}]",ハイパーパラメータ探索
285,323,Imitation Learning,模倣学習,1.0,10,"[{'word': '模倣学習', 'ratio': 1.0}]",模倣学習
286,324,In-context Learning,コンテキスト内学習,0.5,10,"[{'word': 'コンテキスト内学習', 'ratio': 0.5}, {'word': 'インコンテキスト・ラーニング', 'ratio': 0.1}, {'word': 'コンテキスト学習', 'ratio': 0.1}, {'word': '文脈内学習', 'ratio': 0.1}, {'word': '状況に応じた学習', 'ratio': 0.1}, {'word': 'インコンテキスト学習', 'ratio': 0.1}]",コンテキスト内学習
287,325,Inception network,Inception ネットワーク,0.0,10,"[{'word': 'インセプションネットワーク', 'ratio': 0.9}, {'word': 'インセプション・ネットワーク', 'ratio': 0.1}]",インセプションネットワーク
288,326,Independent Cascade,独立カスケード,0.9,10,"[{'word': '独立カスケード', 'ratio': 0.9}, {'word': '独立したカスケード', 'ratio': 0.1}]",独立カスケード
289,327,Independent Cascade Model,独立カスケードモデル,0.9,10,"[{'word': '独立カスケードモデル', 'ratio': 0.9}, {'word': '独立したカスケードモデル', 'ratio': 0.1}]",独立カスケードモデル
290,328,Independent Component Analysis,独立成分分析,1.0,10,"[{'word': '独立成分分析', 'ratio': 1.0}]",独立成分分析
291,329,Influence Maximization,影響最大化,0.6,10,"[{'word': '影響最大化', 'ratio': 0.6}, {'word': '影響力の最大化', 'ratio': 0.2}, {'word': '独立成分分析', 'ratio': 0.1}, {'word': '影響力最大化', 'ratio': 0.1}]",影響最大化
292,330,Information Extraction,情報抽出,1.0,10,"[{'word': '情報抽出', 'ratio': 1.0}]",情報抽出
293,331,Information Retrieval,情報検索,1.0,10,"[{'word': '情報検索', 'ratio': 1.0}]",情報検索
294,332,Informer model,インフォーマー・モデル (informa modoru),0.0,10,"[{'word': 'インフォーマーモデル', 'ratio': 1.0}]",インフォーマーモデル
295,333,Input space,入力空間,0.8,10,"[{'word': '入力空間', 'ratio': 0.8}, {'word': '入力スペース', 'ratio': 0.2}]",入力空間
296,334,Inside-Outside algorithm,インサイド・アウトサイドアルゴリズム,0.8,10,"[{'word': 'インサイド・アウトサイドアルゴリズム', 'ratio': 0.8}, {'word': 'インサイド-アウトサイド・アルゴリズム', 'ratio': 0.2}]",インサイド・アウトサイドアルゴリズム
297,335,Instance Normalization,インスタンス正規化,0.8,10,"[{'word': 'インスタンス正規化', 'ratio': 0.8}, {'word': 'インスタンスの正規化', 'ratio': 0.2}]",インスタンス正規化
298,336,Inverse Reinforcement Learning,逆強化学習,1.0,10,"[{'word': '逆強化学習', 'ratio': 1.0}]",逆強化学習
299,337,Ising model,イジングモデル,0.9,10,"[{'word': 'イジングモデル', 'ratio': 0.9}, {'word': 'イジングモデルアイバーソンブラケット', 'ratio': 0.1}]",イジングモデル
300,338,Iverson bracket,アイバーソン括弧,0.0,10,"[{'word': 'アイバーソンブラケット', 'ratio': 0.7}, {'word': 'アイバーソン・ブラケット', 'ratio': 0.1}, {'word': 'アイヴァーソンブラケット', 'ratio': 0.1}, {'word': 'アイバーソンのブラケット', 'ratio': 0.1}]",アイバーソンブラケット
301,339,Jaccard,ジャカード,0.4,10,"[{'word': 'ジャッカード', 'ratio': 0.6}, {'word': 'ジャカード', 'ratio': 0.4}]",ジャッカード
302,340,Jaccard index,ジャッカード指数,0.5,10,"[{'word': 'ジャッカード指数', 'ratio': 0.5}, {'word': 'ジャカード指数', 'ratio': 0.3}, {'word': 'ジャッカード', 'ratio': 0.1}, {'word': 'ジャカードインデックス', 'ratio': 0.1}]",ジャッカード指数
303,341,Jaccard similarity,ジャッカード類似度,0.6,10,"[{'word': 'ジャッカード類似度', 'ratio': 0.6}, {'word': 'ジャカード類似度', 'ratio': 0.2}, {'word': 'ジャカード類似性', 'ratio': 0.1}, {'word': 'ジャカードの類似性', 'ratio': 0.1}]",ジャッカード類似度
304,342,Jaccard similarity coefficient,ジャカード類似係数,0.1,10,"[{'word': 'ジャッカード類似係数', 'ratio': 0.5}, {'word': 'ジャッカール類似係数', 'ratio': 0.2}, {'word': 'ジャカード類似度係数', 'ratio': 0.1}, {'word': 'ジャッカード類似度係数', 'ratio': 0.1}, {'word': 'ジャカード類似係数', 'ratio': 0.1}]",ジャッカード類似係数
305,343,Jacobian matrix,ヤコビアン行列,0.3,10,"[{'word': 'ヤコビ行列', 'ratio': 0.7}, {'word': 'ヤコビアン行列', 'ratio': 0.3}]",ヤコビ行列
306,344,Jensen's inequality,ジェンセンの不等式,0.2,10,"[{'word': 'ヤンセンの不等式', 'ratio': 0.7}, {'word': 'ジェンセンの不等式', 'ratio': 0.2}, {'word': 'イェンセンの不等式', 'ratio': 0.1}]",ヤンセンの不等式
307,345,Jensen-Shannon,ジェンセン・シャノン,0.4,10,"[{'word': 'ヤンセン・シャノン', 'ratio': 0.6}, {'word': 'ジェンセン・シャノン', 'ratio': 0.4}]",ヤンセン・シャノン
308,346,Jensen-Shannon Divergence,ジェンセン-シャノン発散度,0.0,10,"[{'word': 'ヤンセン・シャノン発散', 'ratio': 0.6}, {'word': 'ジェンセン・シャノン・ダイバージェンス', 'ratio': 0.1}, {'word': 'ジェンセンとシャノンのダイバージェンス', 'ratio': 0.1}, {'word': 'ジェンセン・シャノン divergence', 'ratio': 0.1}, {'word': 'ジェンセン・シャノン発散', 'ratio': 0.1}]",ヤンセン・シャノン発散
309,347,K-L divergence,K-L ダイバージェンス,0.1,10,"[{'word': 'K-Lダイバージェンス', 'ratio': 0.9}, {'word': 'K-L ダイバージェンス', 'ratio': 0.1}]",K-Lダイバージェンス
310,348,K-Means,k平均法,0.0,10,"[{'word': 'K-平均法', 'ratio': 0.7}, {'word': 'K平均法', 'ratio': 0.1}, {'word': 'K平均', 'ratio': 0.1}, {'word': 'K 平均法', 'ratio': 0.1}]",K-平均法
311,349,K-Means clustering,k-平均クラスタリング,0.0,10,"[{'word': 'K-平均クラスタリング', 'ratio': 0.8}, {'word': 'K平均法クラスタリング', 'ratio': 0.1}, {'word': 'K-Means クラスタリング', 'ratio': 0.1}]",K-平均クラスタリング
312,350,K-means algorithm,"""k-平均アルゴリズム""",0.0,10,"[{'word': 'K-平均アルゴリズム', 'ratio': 0.7}, {'word': 'K平均法アルゴリズム', 'ratio': 0.1}, {'word': 'K平均アルゴリズム', 'ratio': 0.1}, {'word': 'K 平均法アルゴリズム', 'ratio': 0.1}]",K-平均アルゴリズム
313,351,Kalman filter,カルマンフィルター,0.5,10,"[{'word': 'カルマンフィルタ', 'ratio': 0.5}, {'word': 'カルマンフィルター', 'ratio': 0.5}]",カルマンフィルタ
314,352,Kendall's τ,ケンダルのτ,0.2,10,"[{'word': 'ケンドールのτ', 'ratio': 0.7}, {'word': 'ケンダルのτ', 'ratio': 0.2}, {'word': 'ケンデールのτ', 'ratio': 0.1}]",ケンドールのτ
315,353,Keras,Keras,0.1,10,"[{'word': '難しい', 'ratio': 0.6}, {'word': 'ケラス', 'ratio': 0.2}, {'word': '難しいV', 'ratio': 0.1}, {'word': 'Keras', 'ratio': 0.1}]",難しい
316,354,Kernel,カーネル,1.0,10,"[{'word': 'カーネル', 'ratio': 1.0}]",カーネル
317,355,Kernel function,カーネル関数,1.0,10,"[{'word': 'カーネル関数', 'ratio': 1.0}]",カーネル関数
318,356,Kleene closure,クリーン閉包,0.2,10,"[{'word': 'クレーネ閉包', 'ratio': 0.5}, {'word': 'クリーン閉包', 'ratio': 0.2}, {'word': 'クリーン・クロージャー', 'ratio': 0.2}, {'word': 'クリーンクロージャ', 'ratio': 0.1}]",クレーネ閉包
319,358,Knowledge Base,知識ベース,0.7,10,"[{'word': '知識ベース', 'ratio': 0.7}, {'word': 'ナレッジ・ベース', 'ratio': 0.2}, {'word': 'ナレッジベース', 'ratio': 0.1}]",知識ベース
320,359,Knowledge Distillation,知識蒸留,0.7,10,"[{'word': '知識蒸留', 'ratio': 0.7}, {'word': '知識の蒸留', 'ratio': 0.2}, {'word': 'ナレッジディスティレーション', 'ratio': 0.1}]",知識蒸留
321,360,Knowledge Graph,知識グラフ,0.7,10,"[{'word': '知識グラフ', 'ratio': 0.7}, {'word': 'ナレッジグラフ', 'ratio': 0.3}]",知識グラフ
322,361,Kolmogorov-Smirnov test,コルモゴロフ・スミルノフ検定,0.7,10,"[{'word': 'コルモゴロフ・スミルノフ検定', 'ratio': 0.7}, {'word': 'コルモゴロフ–スミルノフ検定', 'ratio': 0.2}, {'word': 'コルモゴロフ-スミルノフ検定', 'ratio': 0.1}]",コルモゴロフ・スミルノフ検定
323,362,Krippendorff's α,クリッペンドルフのα,0.9,10,"[{'word': 'クリッペンドルフのα', 'ratio': 0.9}, {'word': 'クリッペンドルフ', 'ratio': 0.1}]",クリッペンドルフのα
324,363,Kronecker delta,クロネッカー・デルタ,0.1,10,"[{'word': 'クロネッカーのデルタ', 'ratio': 0.7}, {'word': 'クロネッカー・デルタ', 'ratio': 0.1}, {'word': 'クロネッカーデルタ', 'ratio': 0.1}, {'word': 'クロネッカーδ', 'ratio': 0.1}]",クロネッカーのデルタ
325,364,Kronecker product,クロネッカー積,0.9,10,"[{'word': 'クロネッカー積', 'ratio': 0.9}, {'word': 'クロネッカープロダクト', 'ratio': 0.1}]",クロネッカー積
326,366,L 1 -norm,L1ノルム,0.8,10,"[{'word': 'L1ノルム', 'ratio': 0.8}, {'word': 'L 1 -ノルム', 'ratio': 0.2}]",L1ノルム
327,367,L 1 distance,L1距離,0.9,10,"[{'word': 'L1距離', 'ratio': 0.9}, {'word': 'L 1距離', 'ratio': 0.1}]",L1距離
328,368,L 2 -norm,L2ノルム,0.8,10,"[{'word': 'L2ノルム', 'ratio': 0.8}, {'word': 'L 2 -ノルム', 'ratio': 0.2}]",L2ノルム
329,369,L 2 distance,L2距離,0.9,10,"[{'word': 'L2距離', 'ratio': 0.9}, {'word': 'L 2距離', 'ratio': 0.1}]",L2距離
330,370,L 2 loss,L 2損失,0.0,10,"[{'word': 'L2損失', 'ratio': 0.9}, {'word': 'L 2敗', 'ratio': 0.1}]",L2損失
331,371,L 2 regularization,L2正則化,0.7,10,"[{'word': 'L2正則化', 'ratio': 0.7}, {'word': 'L 2 正則化', 'ratio': 0.2}, {'word': 'L2規則化', 'ratio': 0.1}]",L2正則化
332,372,L ∞ norm,L ∞ ノルム,0.0,10,"[{'word': 'L∞ノルム', 'ratio': 1.0}]",L∞ノルム
333,373,L1 bound,L1バインド,0.0,10,"[{'word': 'L1バウンド', 'ratio': 0.7}, {'word': 'L1境界', 'ratio': 0.2}, {'word': 'L1の境界', 'ratio': 0.1}]",L1バウンド
334,374,L1 difference,L1 差異,0.0,10,"[{'word': 'L1差', 'ratio': 0.7}, {'word': 'L1差分', 'ratio': 0.2}, {'word': 'L1の差異', 'ratio': 0.1}]",L1差
335,375,L1 loss,L1損失,0.9,10,"[{'word': 'L1損失', 'ratio': 0.9}, {'word': 'L1の損失', 'ratio': 0.1}]",L1損失
336,376,L1 penalty,L1 ペナルティ,0.2,10,"[{'word': 'L1ペナルティ', 'ratio': 0.8}, {'word': 'L1 ペナルティ', 'ratio': 0.2}]",L1ペナルティ
337,377,L1 regularization,L1 正則化,0.2,10,"[{'word': 'L1正則化', 'ratio': 0.8}, {'word': 'L1 正則化', 'ratio': 0.2}]",L1正則化
338,378,L1 term,L1項,0.8,10,"[{'word': 'L1項', 'ratio': 0.8}, {'word': 'L1 ターム', 'ratio': 0.2}]",L1項
339,379,L2 error,L2誤差,0.8,10,"[{'word': 'L2誤差', 'ratio': 0.8}, {'word': 'L2エラー', 'ratio': 0.2}]",L2誤差
340,380,L2 regularisation,L2正則化,0.8,10,"[{'word': 'L2正則化', 'ratio': 0.8}, {'word': 'L2 正則化', 'ratio': 0.2}]",L2正則化
341,382,L2 weight decay,L2 重み減衰,0.1,10,"[{'word': 'L2重み減衰', 'ratio': 0.5}, {'word': 'L2ウェイト減衰', 'ratio': 0.3}, {'word': 'L2 weight decay', 'ratio': 0.1}, {'word': 'L2 重み減衰', 'ratio': 0.1}]",L2重み減衰
342,383,L2-normalization,L2正規化,0.8,10,"[{'word': 'L2正規化', 'ratio': 0.8}, {'word': 'L2 正規化', 'ratio': 0.2}]",L2正規化
343,384,Lagrange multiplier,ラグランジュ乗数,0.9,10,"[{'word': 'ラグランジュ乗数', 'ratio': 0.9}, {'word': 'ラグランジュ乗算', 'ratio': 0.1}]",ラグランジュ乗数
344,385,Lagrangian duality,ラグランジュ双対性,0.5,10,"[{'word': 'ラグランジュ双対性', 'ratio': 0.5}, {'word': 'ラグランジアン双対性', 'ratio': 0.2}, {'word': 'ラグランジュの双対性', 'ratio': 0.1}, {'word': 'ラグランジュのduality', 'ratio': 0.1}, {'word': 'ラグランジアン二重性', 'ratio': 0.1}]",ラグランジュ双対性
345,386,Lagrangian multiplier,ラグランジュの未定乗数,0.0,10,"[{'word': 'ラグランジュ乗数', 'ratio': 0.6}, {'word': 'ラグランジアン乗数', 'ratio': 0.3}, {'word': 'ラグランジュのMultiplier', 'ratio': 0.1}]",ラグランジュ乗数
346,387,Lagrangian relaxation,ラグランジュ緩和,0.6,10,"[{'word': 'ラグランジュ緩和', 'ratio': 0.6}, {'word': 'ラグランジアン緩和', 'ratio': 0.3}, {'word': 'ラグランジュのrelaxation', 'ratio': 0.1}]",ラグランジュ緩和
347,390,Langevin dynamic,ランジュバン動力学,0.5,10,"[{'word': 'ランジュバン動力学', 'ratio': 0.5}, {'word': 'ランジュバン ダイナミック', 'ratio': 0.2}, {'word': 'ランダイナミクス', 'ratio': 0.1}, {'word': 'ランダウィン動力学', 'ratio': 0.1}, {'word': 'ランダムダイナミクス', 'ratio': 0.1}]",ランジュバン動力学
348,391,Language Model,言語モデル,1.0,10,"[{'word': '言語モデル', 'ratio': 1.0}]",言語モデル
349,392,Language Modeling Toolkit,言語モデリングツールキット,0.3,10,"[{'word': '言語モデルツールキット', 'ratio': 0.7}, {'word': '言語モデリングツールキット', 'ratio': 0.3}]",言語モデルツールキット
350,393,Laplace approximation,ラプラス近似,1.0,10,"[{'word': 'ラプラス近似', 'ratio': 1.0}]",ラプラス近似
351,394,Laplace distribution,ラプラス分布,1.0,10,"[{'word': 'ラプラス分布', 'ratio': 1.0}]",ラプラス分布
352,395,Laplace noise,ラプラスノイズ,1.0,10,"[{'word': 'ラプラスノイズ', 'ratio': 1.0}]",ラプラスノイズ
353,396,Laplace smoothing,ラプラス平滑化,0.6,10,"[{'word': 'ラプラス平滑化', 'ratio': 0.6}, {'word': 'ラプラススムージング', 'ratio': 0.2}, {'word': 'ラプラス smothing', 'ratio': 0.1}, {'word': 'ラプラスノイズ', 'ratio': 0.1}]",ラプラス平滑化
354,398,Laplacian distribution,ラプラス分布,0.8,10,"[{'word': 'ラプラス分布', 'ratio': 0.8}, {'word': 'ラプラシアン分布', 'ratio': 0.2}]",ラプラス分布
355,399,Laplacian matrix,ラプラシアン行列,0.2,10,"[{'word': 'ラプラス行列', 'ratio': 0.8}, {'word': 'ラプラシアン行列', 'ratio': 0.2}]",ラプラス行列
356,401,Lasso,ラッソ,0.8,10,"[{'word': 'ラッソ', 'ratio': 0.8}, {'word': '投げ縄', 'ratio': 0.2}]",ラッソ
357,402,Lasso penalty,ラッソペナルティ,0.8,10,"[{'word': 'ラッソペナルティ', 'ratio': 0.8}, {'word': 'ラッソーペナルティ', 'ratio': 0.2}]",ラッソペナルティ
358,403,Latent Dirichlet Allocation,潜在ディリクレ配分,0.6,10,"[{'word': '潜在ディリクレ配分', 'ratio': 0.6}, {'word': '潜在ディリクレ割り当て', 'ratio': 0.2}, {'word': '潜在ディリヘルト・アロケーション', 'ratio': 0.1}, {'word': '潜在的ディリクレ配分', 'ratio': 0.1}]",潜在ディリクレ配分
359,404,Latent Semantic Analysis,潜在意味解析,0.8,10,"[{'word': '潜在意味解析', 'ratio': 0.8}, {'word': '潜在的意味解析', 'ratio': 0.1}, {'word': '潜在的意味分析', 'ratio': 0.1}]",潜在意味解析
360,405,Layer Normalization,層正規化,0.0,10,"[{'word': 'レイヤー正規化', 'ratio': 0.5}, {'word': 'レイヤーノーマライゼーション', 'ratio': 0.2}, {'word': 'レイヤーの正規化', 'ratio': 0.2}, {'word': 'レイヤー normalize', 'ratio': 0.1}]",レイヤー正規化
361,406,Learning Rate,学習率,1.0,10,"[{'word': '学習率', 'ratio': 1.0}]",学習率
362,407,Lemma,補題,0.7,10,"[{'word': '補題', 'ratio': 0.7}, {'word': 'レンマ', 'ratio': 0.2}, {'word': 'лемマ', 'ratio': 0.1}]",補題
363,409,Levenshtein distance,レーベンシュタイン距離,0.8,10,"[{'word': 'レーベンシュタイン距離', 'ratio': 0.8}, {'word': 'レーヴェンシュタイン距離', 'ratio': 0.2}]",レーベンシュタイン距離
364,410,Levenshtein edit distance,レーベンシュタイン編集距離,0.7,10,"[{'word': 'レーベンシュタイン編集距離', 'ratio': 0.7}, {'word': 'レーヴェンシュタイン距離', 'ratio': 0.1}, {'word': '自然ルヴェンシュタイン編集距離', 'ratio': 0.1}, {'word': 'レビンシュタイン距離', 'ratio': 0.1}]",レーベンシュタイン編集距離
365,412,Libratus,リブラタス,0.2,10,"[{'word': 'リブラトゥス', 'ratio': 0.6}, {'word': 'リブラタス', 'ratio': 0.2}, {'word': '天秤座', 'ratio': 0.1}, {'word': 'ライブラタス', 'ratio': 0.1}]",リブラトゥス
366,413,Lie algebra,リー代数,0.9,10,"[{'word': 'リー代数', 'ratio': 0.9}, {'word': 'リー環', 'ratio': 0.1}]",リー代数
367,414,Lifelong Learning,生涯学習,0.8,10,"[{'word': '生涯学習', 'ratio': 0.8}, {'word': '終身学習', 'ratio': 0.1}, {'word': '終生学習', 'ratio': 0.1}]",生涯学習
368,415,Likert scale,リッカート尺度,0.5,10,"[{'word': 'リッカート尺度', 'ratio': 0.5}, {'word': 'リッカートスケール', 'ratio': 0.5}]",リッカート尺度
369,416,Linear Regression,線形回帰,1.0,10,"[{'word': '線形回帰', 'ratio': 1.0}]",線形回帰
370,417,Linear Threshold,線形閾値,0.7,10,"[{'word': '線形閾値', 'ratio': 0.7}, {'word': '線形しきい値', 'ratio': 0.2}, {'word': 'リニアしきい値', 'ratio': 0.1}]",線形閾値
371,418,Linear Threshold Model,線形しきい値モデル,0.2,10,"[{'word': '線形閾値モデル', 'ratio': 0.8}, {'word': '線形しきい値モデル', 'ratio': 0.2}]",線形閾値モデル
372,420,Linformer,リンフォーマー,1.0,10,"[{'word': 'リンフォーマー', 'ratio': 1.0}]",リンフォーマー
373,421,Lipschitz,リプシッツ条件,0.0,10,"[{'word': 'リプシッツ', 'ratio': 1.0}]",リプシッツ
374,422,Lipschitz constant,リプシッツ定数,1.0,10,"[{'word': 'リプシッツ定数', 'ratio': 1.0}]",リプシッツ定数
375,423,Lipschitz continuity,リプシッツ連続性,0.8,10,"[{'word': 'リプシッツ連続性', 'ratio': 0.8}, {'word': 'リプシッツ連続', 'ratio': 0.2}]",リプシッツ連続性
376,424,Lipschitz continuous,リプシッツ連続,1.0,10,"[{'word': 'リプシッツ連続', 'ratio': 1.0}]",リプシッツ連続
377,425,Lipschitz function,リプシッツ関数,1.0,10,"[{'word': 'リプシッツ関数', 'ratio': 1.0}]",リプシッツ関数
378,426,Lipschitzness,リプシッツ性,1.0,10,"[{'word': 'リプシッツ性', 'ratio': 1.0}]",リプシッツ性
379,429,Logistic Regression,ロジスティック回帰,1.0,10,"[{'word': 'ロジスティック回帰', 'ratio': 1.0}]",ロジスティック回帰
380,430,Longformer,ロングフォーマー,1.0,10,"[{'word': 'ロングフォーマー', 'ratio': 1.0}]",ロングフォーマー
381,432,Lyapunov function,リャプノフ関数,0.7,10,"[{'word': 'リャプノフ関数', 'ratio': 0.7}, {'word': 'リアプノフ関数', 'ratio': 0.3}]",リャプノフ関数
382,433,M-estimation,M推定法,0.0,10,"[{'word': 'M推定', 'ratio': 0.8}, {'word': 'M 推定', 'ratio': 0.2}]",M推定
383,434,M-step,Mステップ,1.0,10,"[{'word': 'Mステップ', 'ratio': 1.0}]",Mステップ
384,435,Machine Comprehension,機械理解,0.8,10,"[{'word': '機械理解', 'ratio': 0.8}, {'word': '機械読解', 'ratio': 0.2}]",機械理解
385,436,Machine Learning,機械学習,1.0,10,"[{'word': '機械学習', 'ratio': 1.0}]",機械学習
386,437,Machine Learning Repository,機械学習リポジトリ,0.9,10,"[{'word': '機械学習リポジトリ', 'ratio': 0.9}, {'word': 'UCI機械学習リポジトリ', 'ratio': 0.1}]",機械学習リポジトリ
387,439,Machine Translation,機械翻訳,0.9,10,"[{'word': '機械翻訳', 'ratio': 0.9}, {'word': '機械読解', 'ratio': 0.1}]",機械翻訳
388,440,Mahalanobis distance,マハラノビス距離,1.0,10,"[{'word': 'マハラノビス距離', 'ratio': 1.0}]",マハラノビス距離
389,441,Mahalanobis distance function,マハラノビス距離関数,1.0,10,"[{'word': 'マハラノビス距離関数', 'ratio': 1.0}]",マハラノビス距離関数
390,442,Mahalanobis matrix,マハラノビス行列,1.0,10,"[{'word': 'マハラノビス行列', 'ratio': 1.0}]",マハラノビス行列
391,443,Mahalanobis metric,マハラノビス距離尺度,0.0,10,"[{'word': 'マハラノビス距離', 'ratio': 0.8}, {'word': 'マハラノビスメトリック', 'ratio': 0.1}, {'word': 'マハラノビス指標', 'ratio': 0.1}]",マハラノビス距離
392,444,Manhattan distance,マンハッタン距離,0.9,10,"[{'word': 'マンハッタン距離', 'ratio': 0.9}, {'word': 'マンハッタンの距離', 'ratio': 0.1}]",マンハッタン距離
393,445,Marching Cubes,マーチングキューブ,0.9,10,"[{'word': 'マーチングキューブ', 'ratio': 0.9}, {'word': 'マーチング・キューブ', 'ratio': 0.1}]",マーチングキューブ
394,446,Markov,マルコフ,1.0,10,"[{'word': 'マルコフ', 'ratio': 1.0}]",マルコフ
395,447,Markov Chain,マルコフ連鎖,0.9,10,"[{'word': 'マルコフ連鎖', 'ratio': 0.9}, {'word': 'マルコフ鎖', 'ratio': 0.1}]",マルコフ連鎖
396,448,Markov Chain Monte Carlo,マルコフ連鎖モンテカルロ法,0.6,10,"[{'word': 'マルコフ連鎖モンテカルロ法', 'ratio': 0.6}, {'word': 'マルコフ連鎖モンテカルロ', 'ratio': 0.3}, {'word': 'マルコフ鎖モンテカルロ', 'ratio': 0.1}]",マルコフ連鎖モンテカルロ法
397,449,Markov Decision Process,マルコフ決定過程,0.9,10,"[{'word': 'マルコフ決定過程', 'ratio': 0.9}, {'word': 'マルコフ決定プロセス', 'ratio': 0.1}]",マルコフ決定過程
398,450,Markov Random Field,マルコフ確率場,0.3,10,"[{'word': 'マルコフランダムフィールド', 'ratio': 0.6}, {'word': 'マルコフ確率場', 'ratio': 0.3}, {'word': 'マルコフ乱れ場', 'ratio': 0.1}]",マルコフランダムフィールド
399,451,Markov assumption,マルコフ仮定,0.9,10,"[{'word': 'マルコフ仮定', 'ratio': 0.9}, {'word': 'マルコフの仮定', 'ratio': 0.1}]",マルコフ仮定
400,452,Markov blanket,マルコフブランケット,1.0,10,"[{'word': 'マルコフブランケット', 'ratio': 1.0}]",マルコフブランケット
401,453,Markov chain model,マルコフ連鎖モデル,1.0,10,"[{'word': 'マルコフ連鎖モデル', 'ratio': 1.0}]",マルコフ連鎖モデル
402,454,Markov game,マルコフゲーム,1.0,10,"[{'word': 'マルコフゲーム', 'ratio': 1.0}]",マルコフゲーム
403,455,Markov kernel,マルコフ核,0.0,10,"[{'word': 'マルコフカーネル', 'ratio': 1.0}]",マルコフカーネル
404,456,Markov logic,マルコフ論理,0.7,10,"[{'word': 'マルコフ論理', 'ratio': 0.7}, {'word': 'マルコフロジック', 'ratio': 0.3}]",マルコフ論理
405,457,Markov logic network,マルコフ論理ネットワーク,1.0,10,"[{'word': 'マルコフ論理ネットワーク', 'ratio': 1.0}]",マルコフ論理ネットワーク
406,458,Markov model,マルコフモデル,1.0,10,"[{'word': 'マルコフモデル', 'ratio': 1.0}]",マルコフモデル
407,459,Markov network,マルコフネットワーク,0.9,10,"[{'word': 'マルコフネットワーク', 'ratio': 0.9}, {'word': 'マルコフ・ネットワーク', 'ratio': 0.1}]",マルコフネットワーク
408,460,Markov process,マルコフ過程,1.0,10,"[{'word': 'マルコフ過程', 'ratio': 1.0}]",マルコフ過程
409,461,Markov property,マルコフ性,0.8,10,"[{'word': 'マルコフ性', 'ratio': 0.8}, {'word': 'マルコフ特性', 'ratio': 0.2}]",マルコフ性
410,462,Markov state,マルコフ状態,0.9,10,"[{'word': 'マルコフ状態', 'ratio': 0.9}, {'word': 'マルコフ州', 'ratio': 0.1}]",マルコフ状態
411,463,Markov transition,マルコフ遷移,1.0,10,"[{'word': 'マルコフ遷移', 'ratio': 1.0}]",マルコフ遷移
412,464,Markov transition matrix,マルコフ遷移行列,1.0,10,"[{'word': 'マルコフ遷移行列', 'ratio': 1.0}]",マルコフ遷移行列
413,465,Markov's inequality,マルコフの不等式,1.0,10,"[{'word': 'マルコフの不等式', 'ratio': 1.0}]",マルコフの不等式
414,466,MatConvNet,MatConvNet,0.9,10,"[{'word': 'MatConvNet', 'ratio': 0.9}, {'word': 'MatConvネット', 'ratio': 0.1}]",MatConvNet
415,467,Matching Network,マッチングネットワーク,0.9,10,"[{'word': 'マッチングネットワーク', 'ratio': 0.9}, {'word': 'マッチング・ネットワーク', 'ratio': 0.1}]",マッチングネットワーク
416,468,Matrix Completion,行列完成,0.1,10,"[{'word': '行列補完', 'ratio': 0.7}, {'word': 'マトリックス完成', 'ratio': 0.1}, {'word': 'マトリックスの完成', 'ratio': 0.1}, {'word': '行列完成', 'ratio': 0.1}]",行列補完
417,471,Maximum Likelihood,最尤推定,0.0,10,"[{'word': '最大尤度', 'ratio': 0.7}, {'word': '最尤法', 'ratio': 0.3}]",最大尤度
418,473,Mechanical Turk,メカニカルターク,0.6,10,"[{'word': 'メカニカルターク', 'ratio': 0.6}, {'word': 'メカニカル・ターク', 'ratio': 0.3}, {'word': 'マシナルターボ', 'ratio': 0.1}]",メカニカルターク
419,474,Meta-learning,メタラーニング,0.1,10,"[{'word': 'メタ学習', 'ratio': 0.9}, {'word': 'メタラーニング', 'ratio': 0.1}]",メタ学習
420,475,Metropolis Hastings,メトロポリス・ヘイスティングス法,0.0,10,"[{'word': 'メトロポリス・ヘイスティングス', 'ratio': 0.9}, {'word': 'メトロポリスハステンズ', 'ratio': 0.1}]",メトロポリス・ヘイスティングス
421,476,Metropolis algorithm,メトロポリス法,0.1,10,"[{'word': 'メトロポリスアルゴリズム', 'ratio': 0.7}, {'word': 'メトロポリス・アルゴリズム', 'ratio': 0.2}, {'word': 'メトロポリス法', 'ratio': 0.1}]",メトロポリスアルゴリズム
422,477,Metropolis method,メトロポリス法,0.6,10,"[{'word': 'メトロポリス法', 'ratio': 0.6}, {'word': 'メトロポリスメソッド', 'ratio': 0.4}]",メトロポリス法
423,478,Metropolis-Hasting,メトロポリス・ヘイスティング法,0.0,10,"[{'word': 'メトロポリス・ヘイスティングス', 'ratio': 0.6}, {'word': 'メトロポリス・ヘイスティング', 'ratio': 0.2}, {'word': 'メトロポリス＝ヘイスティング', 'ratio': 0.1}, {'word': 'メトロポリス-ヘイスティングス', 'ratio': 0.1}]",メトロポリス・ヘイスティングス
424,479,Metropolis-Hastings acceptance ratio,メトロポリス・ヘイスティングス受容比,0.5,10,"[{'word': 'メトロポリス・ヘイスティングス受容比', 'ratio': 0.5}, {'word': 'メトロポリス・ヘイスティングスのアクセプタンス比', 'ratio': 0.2}, {'word': 'メトロポリス・ヘイスティング受容比', 'ratio': 0.1}, {'word': 'メトロポリス-ヘイスティングス受容比', 'ratio': 0.1}, {'word': 'GATXUWWYDFFHN4SK64F6H3X6UVUCRGMR6BXJ4JAPT2MMG5QI5VRQLQNE', 'ratio': 0.1}]",メトロポリス・ヘイスティングス受容比
425,480,Metropolis-Hastings algorithm,メトロポリス・ヘイスティングス・アルゴリズム,0.0,10,"[{'word': 'メトロポリス・ヘイスティングスアルゴリズム', 'ratio': 0.6}, {'word': 'メトロポリス・ヘイスティングス法', 'ratio': 0.2}, {'word': 'メトロポリス・ヘイスティングアルゴリズム', 'ratio': 0.1}, {'word': 'メトロポリス-ヘイスティングスアルゴリズム', 'ratio': 0.1}]",メトロポリス・ヘイスティングスアルゴリズム
426,481,Metropolis-Hastings sampler,メトロポリス・ヘイスティングスサンプラー,0.7,10,"[{'word': 'メトロポリス・ヘイスティングスサンプラー', 'ratio': 0.7}, {'word': 'メトロポリス・ヘイスティングス・サンプラー', 'ratio': 0.1}, {'word': 'メトロポリス - ヘイスティングスのサンプラー', 'ratio': 0.1}, {'word': 'メトロポリス-ハスタリングサンプラー', 'ratio': 0.1}]",メトロポリス・ヘイスティングスサンプラー
427,483,Model,モデル,1.0,10,"[{'word': 'モデル', 'ratio': 1.0}]",モデル
428,484,Monotonicity,単調性,0.9,10,"[{'word': '単調性', 'ratio': 0.9}, {'word': '一様性', 'ratio': 0.1}]",単調性
429,485,Monte Carlo,モンテカルロ法,0.0,10,"[{'word': 'モンテカルロ', 'ratio': 1.0}]",モンテカルロ
430,486,Monte Carlo Dropout,モンテカルロドロップアウト,0.7,10,"[{'word': 'モンテカルロドロップアウト', 'ratio': 0.7}, {'word': 'モンテカルロ・ドロップアウト', 'ratio': 0.2}, {'word': 'モンテカルロドロップアウ', 'ratio': 0.1}]",モンテカルロドロップアウト
431,487,Monte Carlo Tree Search,モンテカルロ木探索,1.0,10,"[{'word': 'モンテカルロ木探索', 'ratio': 1.0}]",モンテカルロ木探索
432,488,Monte Carlo algorithm,モンテカルロアルゴリズム,0.8,10,"[{'word': 'モンテカルロアルゴリズム', 'ratio': 0.8}, {'word': 'モンテカルロ・アルゴリズム', 'ratio': 0.2}]",モンテカルロアルゴリズム
433,489,Monte Carlo approximation,モンテカルロ近似,1.0,10,"[{'word': 'モンテカルロ近似', 'ratio': 1.0}]",モンテカルロ近似
434,490,Monte Carlo estimate,モンテカルロ推定,0.9,10,"[{'word': 'モンテカルロ推定', 'ratio': 0.9}, {'word': 'モンテカルロ推定量', 'ratio': 0.1}]",モンテカルロ推定
435,491,Monte Carlo estimation,モンテカルロ推定,0.8,10,"[{'word': 'モンテカルロ推定', 'ratio': 0.8}, {'word': 'モンテカルロ推定法', 'ratio': 0.2}]",モンテカルロ推定
436,492,Monte Carlo estimator,モンテカルロ推定量,0.4,10,"[{'word': 'モンテカルロ推定器', 'ratio': 0.6}, {'word': 'モンテカルロ推定量', 'ratio': 0.4}]",モンテカルロ推定器
437,493,Monte Carlo method,モンテカルロ法,1.0,10,"[{'word': 'モンテカルロ法', 'ratio': 1.0}]",モンテカルロ法
438,494,Monte Carlo sample,モンテカルロサンプル,0.8,10,"[{'word': 'モンテカルロサンプル', 'ratio': 0.8}, {'word': 'モンテカルロ・サンプル', 'ratio': 0.2}]",モンテカルロサンプル
439,495,Monte Carlo search,モンテカルロ探索,0.7,10,"[{'word': 'モンテカルロ探索', 'ratio': 0.7}, {'word': 'モンテカルロ・サーチ', 'ratio': 0.2}, {'word': 'モンテカルロ検索', 'ratio': 0.1}]",モンテカルロ探索
440,496,Monte Carlo simulation,モンテカルロシミュレーション,0.8,10,"[{'word': 'モンテカルロシミュレーション', 'ratio': 0.8}, {'word': 'モンテカルロ・シミュレーション', 'ratio': 0.2}]",モンテカルロシミュレーション
441,497,Monte-Carlo return,モンテカルロリターン,0.8,10,"[{'word': 'モンテカルロリターン', 'ratio': 0.8}, {'word': 'モンテカルロ帰着', 'ratio': 0.2}]",モンテカルロリターン
442,498,Moore-Penrose pseudo-inverse,ムーア・ペンローズ疑似逆行列,0.0,10,"[{'word': 'ムーア・ペンローズ擬似逆行列', 'ratio': 0.6}, {'word': 'ムーア・ペンローズ擬似インバース', 'ratio': 0.2}, {'word': 'モア＝ペンローズ半正逆行列', 'ratio': 0.1}, {'word': 'ムーア・ペンローズ擬似逆行列さらにさらに', 'ratio': 0.1}]",ムーア・ペンローズ擬似逆行列
443,499,Morfessor,モルフェッサー,0.8,10,"[{'word': 'モルフェッサー', 'ratio': 0.8}, {'word': 'モーフェッサー', 'ratio': 0.2}]",モルフェッサー
444,500,Multi-Task Learning,多タスク学習,0.0,10,"[{'word': 'マルチタスク学習', 'ratio': 1.0}]",マルチタスク学習
445,501,Multidimensional Quality metric,多次元品質メトリック,0.0,10,"[{'word': '多次元品質指標', 'ratio': 1.0}]",多次元品質指標
446,502,Multidimensional Scaling,多次元尺度構成法,0.0,10,"[{'word': '多次元尺度法', 'ratio': 0.8}, {'word': '多次元スケーリング', 'ratio': 0.2}]",多次元尺度法
447,503,Multiple Choice,複数選択,0.2,10,"[{'word': '多肢選択', 'ratio': 0.5}, {'word': '複数選択', 'ratio': 0.2}, {'word': '選択肢', 'ratio': 0.2}, {'word': 'マルチプル・チョイス', 'ratio': 0.1}]",多肢選択
448,504,Mutual Information,相互情報量,0.8,10,"[{'word': '相互情報量', 'ratio': 0.8}, {'word': '相互情報', 'ratio': 0.2}]",相互情報量
449,505,N-gram,Nグラム,0.2,10,"[{'word': 'N-グラム', 'ratio': 0.7}, {'word': 'Nグラム', 'ratio': 0.2}, {'word': 'エヌグラム', 'ratio': 0.1}]",N-グラム
450,506,Nadaraya-Watson estimator,ナダラヤ・ワトソン推定量,0.6,10,"[{'word': 'ナダラヤ・ワトソン推定量', 'ratio': 0.6}, {'word': 'ナダラヤ-ワトソン推定量', 'ratio': 0.3}, {'word': 'ナダラヤ–ワトソン推定量', 'ratio': 0.1}]",ナダラヤ・ワトソン推定量
451,507,Naive Bayes,単純ベイズ,0.0,10,"[{'word': 'ナイーブベイズ', 'ratio': 0.8}, {'word': 'ナイーブ・ベイズ', 'ratio': 0.2}]",ナイーブベイズ
452,508,Naive Bayes classifier,ナイーブベイズ分類器,0.8,10,"[{'word': 'ナイーブベイズ分類器', 'ratio': 0.8}, {'word': 'ナイーブ・ベイズ分類器', 'ratio': 0.2}]",ナイーブベイズ分類器
453,509,Named Entity Recognition,固有表現認識,0.5,10,"[{'word': '固有表現認識', 'ratio': 0.5}, {'word': '固有表現抽出', 'ratio': 0.3}, {'word': '名前付きエンティティ認識', 'ratio': 0.2}]",固有表現認識
454,510,Nash equilibria,ナッシュ均衡,1.0,10,"[{'word': 'ナッシュ均衡', 'ratio': 1.0}]",ナッシュ均衡
455,511,Nash welfare,ナッシュ厚生,0.0,10,"[{'word': 'ナッシュ福祉', 'ratio': 0.9}, {'word': 'ナッシュウェルフェア', 'ratio': 0.1}]",ナッシュ福祉
456,512,Natural Language Generation,自然言語生成,1.0,10,"[{'word': '自然言語生成', 'ratio': 1.0}]",自然言語生成
457,513,Natural Language Inference,自然言語推論,1.0,10,"[{'word': '自然言語推論', 'ratio': 1.0}]",自然言語推論
458,514,Natural Language Processing,自然言語処理,1.0,10,"[{'word': '自然言語処理', 'ratio': 1.0}]",自然言語処理
459,515,Natural Language Understanding,自然言語理解,1.0,10,"[{'word': '自然言語理解', 'ratio': 1.0}]",自然言語理解
460,517,Naïve Bayes,素朴ベイズ,0.0,10,"[{'word': 'ナイーブベイズ', 'ratio': 0.8}, {'word': 'ナイーブ・ベイズ', 'ratio': 0.2}]",ナイーブベイズ
461,518,Nearest Neighbor,最近傍,0.3,10,"[{'word': '最近傍法', 'ratio': 0.5}, {'word': '最近傍', 'ratio': 0.3}, {'word': '最も近い隣人', 'ratio': 0.1}, {'word': '最近隣', 'ratio': 0.1}]",最近傍法
462,520,Neural Information Processing Systems,ニューラル情報処理システム,0.3,10,"[{'word': '神経情報処理システム', 'ratio': 0.7}, {'word': 'ニューラル情報処理システム', 'ratio': 0.3}]",神経情報処理システム
463,521,Neural Machine Translation,神経機械翻訳,0.0,10,"[{'word': 'ニューラル機械翻訳', 'ratio': 1.0}]",ニューラル機械翻訳
464,522,Neural Network,ニューラルネットワーク,1.0,10,"[{'word': 'ニューラルネットワーク', 'ratio': 1.0}]",ニューラルネットワーク
465,523,Neural Radiance field,ニューラル輝度場,0.0,10,"[{'word': 'ニューラル放射場', 'ratio': 0.6}, {'word': 'ニューラル・ラディアンス・フィールド', 'ratio': 0.2}, {'word': 'ニューラルラジアンスフィールド', 'ratio': 0.1}, {'word': 'ニューラルラディアンスフィールド', 'ratio': 0.1}]",ニューラル放射場
466,524,Neural volume,ニューラルボリューム,0.8,10,"[{'word': 'ニューラルボリューム', 'ratio': 0.8}, {'word': '神経体積', 'ratio': 0.2}]",ニューラルボリューム
467,525,Newton method,ニュートン法,1.0,10,"[{'word': 'ニュートン法', 'ratio': 1.0}]",ニュートン法
468,526,Newton's method,ニュートン法,0.8,10,"[{'word': 'ニュートン法', 'ratio': 0.8}, {'word': 'ニュートンの方法', 'ratio': 0.2}]",ニュートン法
469,527,Nom-Bank,Nomバンク,0.0,10,"[{'word': 'ノンバンク', 'ratio': 0.6}, {'word': 'ノムバンク', 'ratio': 0.3}, {'word': 'ノームバンク', 'ratio': 0.1}]",ノンバンク
470,528,Non-maximum suppression,非最大抑制,0.8,10,"[{'word': '非最大抑制', 'ratio': 0.8}, {'word': '非最大限の抑制', 'ratio': 0.2}]",非最大抑制
471,529,Normalization,正規化,0.8,10,"[{'word': '正規化', 'ratio': 0.8}, {'word': 'ノーマライゼーション', 'ratio': 0.2}]",正規化
472,531,Nyström approximation,ナイストレム近似,0.0,10,"[{'word': 'ニューストローム近似', 'ratio': 0.7}, {'word': 'ニュストレム近似', 'ratio': 0.2}, {'word': 'ニーストローム近似', 'ratio': 0.1}]",ニューストローム近似
473,532,Object Localization,オブジェクトのローカリゼーション,0.0,10,"[{'word': '物体位置特定', 'ratio': 0.5}, {'word': 'オブジェクトローカリゼーション', 'ratio': 0.3}, {'word': 'オブジェクトのローカライズ', 'ratio': 0.2}]",物体位置特定
474,533,Object detection,物体検出,0.7,10,"[{'word': '物体検出', 'ratio': 0.7}, {'word': 'オブジェクト検出', 'ratio': 0.3}]",物体検出
475,534,Open Information Extraction,オープン情報抽出,1.0,10,"[{'word': 'オープン情報抽出', 'ratio': 1.0}]",オープン情報抽出
476,535,Optimization Problem,最適化問題,1.0,10,"[{'word': '最適化問題', 'ratio': 1.0}]",最適化問題
477,537,Pareto dominated,パレート優位,0.0,10,"[{'word': 'パレート支配', 'ratio': 0.7}, {'word': 'パレート優越', 'ratio': 0.2}, {'word': 'パレート優勢', 'ratio': 0.1}]",パレート支配
478,538,Pareto frontier,パレートフロンティア,0.9,10,"[{'word': 'パレートフロンティア', 'ratio': 0.9}, {'word': 'パレート・フロンティア', 'ratio': 0.1}]",パレートフロンティア
479,539,Pareto optimal,パレート最適,1.0,10,"[{'word': 'パレート最適', 'ratio': 1.0}]",パレート最適
480,540,Pareto optimality,パレート最適性,1.0,10,"[{'word': 'パレート最適性', 'ratio': 1.0}]",パレート最適性
481,541,Pareto-efficient,パレート最適,0.0,10,"[{'word': 'パレート効率的', 'ratio': 0.8}, {'word': 'パレート効率', 'ratio': 0.2}]",パレート効率的
482,542,Partially Observable Markov Decision Process,部分観測マルコフ決定過程,0.5,10,"[{'word': '部分観測マルコフ決定過程', 'ratio': 0.5}, {'word': '部分可観測マルコフ決定過程', 'ratio': 0.3}, {'word': '部分観測可能マルコフ決定過程', 'ratio': 0.1}, {'word': '部分的に観察可能なマルコフ決定プロセス', 'ratio': 0.1}]",部分観測マルコフ決定過程
483,543,Parzen window,パーゼン窓,0.0,10,"[{'word': 'パルゼンウィンドウ', 'ratio': 0.9}, {'word': 'パルツェンの窓', 'ratio': 0.1}]",パルゼンウィンドウ
484,544,Pearson correlation,ピアソン相関係数,0.0,10,"[{'word': 'ピアソンの相関', 'ratio': 0.6}, {'word': 'ピアソン相関', 'ratio': 0.4}]",ピアソンの相関
485,545,Pearson correlation coefficient,ピアソンの相関係数,0.6,10,"[{'word': 'ピアソンの相関係数', 'ratio': 0.6}, {'word': 'ピアソン相関係数', 'ratio': 0.4}]",ピアソンの相関係数
486,546,Pearson's correlation,ピアソンの相関,0.9,10,"[{'word': 'ピアソンの相関', 'ratio': 0.9}, {'word': 'ピアソンの相関関係', 'ratio': 0.1}]",ピアソンの相関
487,547,Pearson's correlation coefficient,ピアソンの相関係数,1.0,10,"[{'word': 'ピアソンの相関係数', 'ratio': 1.0}]",ピアソンの相関係数
488,548,Pearson's r,ピアソンのr,0.9,10,"[{'word': 'ピアソンのr', 'ratio': 0.9}, {'word': 'ピアソンの r', 'ratio': 0.1}]",ピアソンのr
489,549,Pearson's r correlation,ピアソンの相関係数,0.1,10,"[{'word': 'ピアソンのr相関', 'ratio': 0.9}, {'word': 'ピアソンの相関係数', 'ratio': 0.1}]",ピアソンのr相関
490,550,Penn English Treebank,ペン英語ツリーバンク,0.1,10,"[{'word': 'ペン・イングリッシュ・ツリーバンク', 'ratio': 0.9}, {'word': 'ペン英語ツリーバンク', 'ratio': 0.1}]",ペン・イングリッシュ・ツリーバンク
491,552,Perceptron,パーセプトロン,1.0,10,"[{'word': 'パーセプトロン', 'ratio': 1.0}]",パーセプトロン
492,553,Perplexity,複雑さ,0.0,10,"[{'word': 'パープレキシティ', 'ratio': 0.7}, {'word': '当惑', 'ratio': 0.2}, {'word': 'パーセプトロン', 'ratio': 0.1}]",パープレキシティ
493,554,Perron-Frobenius theorem,ペロン・フロベニウス定理,0.7,10,"[{'word': 'ペロン・フロベニウス定理', 'ratio': 0.7}, {'word': 'ペロン・フロベニウスの定理', 'ratio': 0.2}, {'word': 'ペロン-フロベニウス定理', 'ratio': 0.1}]",ペロン・フロベニウス定理
494,555,Pinsker's inequality,ピンスカーの不等式,1.0,10,"[{'word': 'ピンスカーの不等式', 'ratio': 1.0}]",ピンスカーの不等式
495,556,Pitman-Yor Process,ピットマン・ヨア過程,0.0,10,"[{'word': 'ピットマン・ヨール過程', 'ratio': 0.6}, {'word': 'ピットマン・ヨー・プロセス', 'ratio': 0.2}, {'word': 'ピットマン・ヨー過程', 'ratio': 0.1}, {'word': 'ピットマン-ヨール過程', 'ratio': 0.1}]",ピットマン・ヨール過程
496,557,Platt scaling,プラットスケーリング,0.8,10,"[{'word': 'プラットスケーリング', 'ratio': 0.8}, {'word': 'プラット・スケーリング', 'ratio': 0.2}]",プラットスケーリング
497,558,Pointwise Mutual Information,点ごとの相互情報量,0.0,10,"[{'word': 'ポイントワイズ相互情報量', 'ratio': 0.5}, {'word': 'ポイントワイズ相互情報', 'ratio': 0.3}, {'word': '点対称相互情報量', 'ratio': 0.1}, {'word': '点対相互情報量', 'ratio': 0.1}]",ポイントワイズ相互情報量
498,559,Poisson distribution,ポアソン分布,0.9,10,"[{'word': 'ポアソン分布', 'ratio': 0.9}, {'word': '魚の分布', 'ratio': 0.1}]",ポアソン分布
499,560,Poisson matting,ポワソンマッティング,0.0,10,"[{'word': 'ポアソンマッティング', 'ratio': 0.8}, {'word': 'ポアソンマット', 'ratio': 0.2}]",ポアソンマッティング
500,561,Poisson model,ポアソンモデル,0.9,10,"[{'word': 'ポアソンモデル', 'ratio': 0.9}, {'word': '魚モデル', 'ratio': 0.1}]",ポアソンモデル
501,562,Poisson point process,ポアソン点過程,1.0,10,"[{'word': 'ポアソン点過程', 'ratio': 1.0}]",ポアソン点過程
502,563,Poisson process,ポアソン過程,1.0,10,"[{'word': 'ポアソン過程', 'ratio': 1.0}]",ポアソン過程
503,564,Poisson random variable,ポアソン確率変数,0.2,10,"[{'word': 'ポアソンランダム変数', 'ratio': 0.6}, {'word': 'ポアソン乱数変数', 'ratio': 0.2}, {'word': 'ポアソン確率変数', 'ratio': 0.2}]",ポアソンランダム変数
504,565,Poisson rate,ポアソン率,0.7,10,"[{'word': 'ポアソン率', 'ratio': 0.7}, {'word': 'ポアソンレート', 'ratio': 0.1}, {'word': '脾臓の魚', 'ratio': 0.1}, {'word': 'ポアソン発生率', 'ratio': 0.1}]",ポアソン率
505,566,Poisson regression,ポアソン回帰,1.0,10,"[{'word': 'ポアソン回帰', 'ratio': 1.0}]",ポアソン回帰
506,567,Poisson sampling,ポアソン抽出,0.0,10,"[{'word': 'ポアソンサンプリング', 'ratio': 0.9}, {'word': 'ポアソン・サンプリング', 'ratio': 0.1}]",ポアソンサンプリング
507,568,Potts model,ポッツモデル,1.0,10,"[{'word': 'ポッツモデル', 'ratio': 1.0}]",ポッツモデル
508,569,Precision,Precision,0.0,10,"[{'word': '精度', 'ratio': 0.8}, {'word': '精密', 'ratio': 0.2}]",精度
509,570,Principal Component Analysis,主成分分析,1.0,10,"[{'word': '主成分分析', 'ratio': 1.0}]",主成分分析
510,571,Prop-Bank,プロップバンク,1.0,10,"[{'word': 'プロップバンク', 'ratio': 1.0}]",プロップバンク
511,572,Proposition,命題,1.0,10,"[{'word': '命題', 'ratio': 1.0}]",命題
512,573,Proximal Policy Optimization,近接方策最適化,0.6,10,"[{'word': '近接方策最適化', 'ratio': 0.6}, {'word': 'プロキシマル・ポリシーの最適化', 'ratio': 0.2}, {'word': '近接ポリシー最適化', 'ratio': 0.1}, {'word': '近端政策最適化', 'ratio': 0.1}]",近接方策最適化
513,574,Py-Torch,PyTorch,0.5,10,"[{'word': 'PyTorch', 'ratio': 0.5}, {'word': 'パイトーチ', 'ratio': 0.3}, {'word': 'パイ・トーチ', 'ratio': 0.2}]",PyTorch
514,575,Q function,Q関数,1.0,10,"[{'word': 'Q関数', 'ratio': 1.0}]",Q関数
515,576,Q value,Q値,1.0,10,"[{'word': 'Q値', 'ratio': 1.0}]",Q値
516,577,Q-learning,Q学習,0.8,10,"[{'word': 'Q学習', 'ratio': 0.8}, {'word': 'Qラーニング', 'ratio': 0.2}]",Q学習
517,578,Q-network,Qネットワーク,1.0,10,"[{'word': 'Qネットワーク', 'ratio': 1.0}]",Qネットワーク
518,579,Quality Estimation,品質推定,0.7,10,"[{'word': '品質推定', 'ratio': 0.7}, {'word': '品質評価', 'ratio': 0.3}]",品質推定
519,580,Query expansion,クエリ拡張,0.8,10,"[{'word': 'クエリ拡張', 'ratio': 0.8}, {'word': 'クエリー拡張', 'ratio': 0.2}]",クエリ拡張
520,581,Question Answering,質問回答,0.0,10,"[{'word': '質問応答', 'ratio': 0.8}, {'word': '質疑応答', 'ratio': 0.2}]",質問応答
521,582,R-Precision,R-プレシジョン,0.0,10,"[{'word': 'R-精度', 'ratio': 1.0}]",R-精度
522,586,Random Forest,ランダムフォレスト,1.0,10,"[{'word': 'ランダムフォレスト', 'ratio': 1.0}]",ランダムフォレスト
523,587,Random Forest classifier,ランダムフォレスト分類器,1.0,10,"[{'word': 'ランダムフォレスト分類器', 'ratio': 1.0}]",ランダムフォレスト分類器
524,588,Rank,ランク,0.6,10,"[{'word': 'ランク', 'ratio': 0.6}, {'word': '順位', 'ratio': 0.4}]",ランク
525,589,Rao-Blackwellization,ラオ・ブラックウェル化法,0.0,10,"[{'word': 'ラオ-ブラックウェル化', 'ratio': 0.5}, {'word': 'ラオ・ブラックウェル化', 'ratio': 0.4}, {'word': 'ラオ＝ブラックウェル化', 'ratio': 0.1}]",ラオ-ブラックウェル化
526,590,Reading Comprehension,読解,0.1,10,"[{'word': '読解力', 'ratio': 0.9}, {'word': '読解', 'ratio': 0.1}]",読解力
527,591,Recall,再現率,0.5,10,"[{'word': '再現率', 'ratio': 0.5}, {'word': 'リコール', 'ratio': 0.5}]",再現率
528,592,Receiver Operating Characteristic Curve,受信者動作特性曲線,0.6,10,"[{'word': '受信者動作特性曲線', 'ratio': 0.6}, {'word': '受信者操作特性曲線', 'ratio': 0.4}]",受信者動作特性曲線
529,594,Recurrent Neural Network,再帰ニューラルネットワーク,0.0,10,"[{'word': '再帰型ニューラルネットワーク', 'ratio': 0.6}, {'word': 'リカレント・ニューラル・ネットワーク', 'ratio': 0.2}, {'word': '再帰神経ネットワーク', 'ratio': 0.2}]",再帰型ニューラルネットワーク
530,595,Recurrent layer,再帰層,0.8,10,"[{'word': '再帰層', 'ratio': 0.8}, {'word': 'リカレント層', 'ratio': 0.2}]",再帰層
531,596,Reformer,リフォーマー (Reformer),0.0,10,"[{'word': 'リフォーマー', 'ratio': 1.0}]",リフォーマー
532,597,Regression,回帰,1.0,10,"[{'word': '回帰', 'ratio': 1.0}]",回帰
533,598,Regressor,回帰器,0.6,10,"[{'word': '回帰器', 'ratio': 0.6}, {'word': 'レグレッサー', 'ratio': 0.2}, {'word': '回帰子', 'ratio': 0.1}, {'word': '回帰係数', 'ratio': 0.1}]",回帰器
534,599,Reinforcement Learning,強化学習,1.0,10,"[{'word': '強化学習', 'ratio': 1.0}]",強化学習
535,601,ResNeXt,ResNeXt,0.2,10,"[{'word': 'レスネクスト', 'ratio': 0.8}, {'word': 'ResNeXt', 'ratio': 0.2}]",レスネクスト
536,603,Reward Function,報酬関数,0.8,10,"[{'word': '報酬関数', 'ratio': 0.8}, {'word': '報酬機能', 'ratio': 0.2}]",報酬関数
537,604,Rhetorical Structure Theory,修辞構造理論,0.8,10,"[{'word': '修辞構造理論', 'ratio': 0.8}, {'word': '修辞構造論', 'ratio': 0.1}, {'word': 'レトリック構造理論', 'ratio': 0.1}]",修辞構造理論
538,605,Ridge regression,リッジ回帰,1.0,10,"[{'word': 'リッジ回帰', 'ratio': 1.0}]",リッジ回帰
539,606,Riemannian geometry,リーマン幾何学,1.0,10,"[{'word': 'リーマン幾何学', 'ratio': 1.0}]",リーマン幾何学
540,607,Riemannian gradient,リーマン勾配,0.9,10,"[{'word': 'リーマン勾配', 'ratio': 0.9}, {'word': 'リーマン微分', 'ratio': 0.1}]",リーマン勾配
541,608,Riemannian manifold,リーマン多様体,1.0,10,"[{'word': 'リーマン多様体', 'ratio': 1.0}]",リーマン多様体
542,610,Routing Transformer,ルーティングトランスフォーマー,0.8,10,"[{'word': 'ルーティングトランスフォーマー', 'ratio': 0.8}, {'word': 'ルーティング・トランス', 'ratio': 0.2}]",ルーティングトランスフォーマー
543,613,Rényi entropy,レニーエントロピー,0.0,10,"[{'word': 'レンyiエントロピー', 'ratio': 0.6}, {'word': 'レニ・エントロピー', 'ratio': 0.2}, {'word': 'レーニィ エントロピー', 'ratio': 0.1}, {'word': 'レーニ・エントロピー', 'ratio': 0.1}]",レンyiエントロピー
544,614,S node,Sノード,0.9,10,"[{'word': 'Sノード', 'ratio': 0.9}, {'word': 'S ノード', 'ratio': 0.1}]",Sノード
545,615,S-expression,S式,0.7,10,"[{'word': 'S式', 'ratio': 0.7}, {'word': 'S表現', 'ratio': 0.2}, {'word': 'S 式表現', 'ratio': 0.1}]",S式
546,617,Scikit-learn,Scikit-learn,0.8,10,"[{'word': 'Scikit-learn', 'ratio': 0.8}, {'word': 'スキキット学習', 'ratio': 0.1}, {'word': 'Scikit-Learn', 'ratio': 0.1}]",Scikit-learn
547,619,Self-supervised learning,自己教師あり学習,0.8,10,"[{'word': '自己教師あり学習', 'ratio': 0.8}, {'word': '自己教師型学習', 'ratio': 0.1}, {'word': 'セルフスーパーバイズド学習', 'ratio': 0.1}]",自己教師あり学習
548,620,Semantic Scholar,セマンティック・スカラー,0.6,10,"[{'word': 'セマンティック・スカラー', 'ratio': 0.6}, {'word': 'セマンティックスカラー', 'ratio': 0.2}, {'word': '意味学者', 'ratio': 0.1}, {'word': 'セメンティック・シューラー', 'ratio': 0.1}]",セマンティック・スカラー
549,621,Semantic Web,セマンティック・ウェブ,0.3,10,"[{'word': 'セマンティックウェブ', 'ratio': 0.6}, {'word': 'セマンティック・ウェブ', 'ratio': 0.3}, {'word': 'セメンティック・ウェブ', 'ratio': 0.1}]",セマンティックウェブ
550,623,Sentiment Analysis,感情分析,0.7,10,"[{'word': '感情分析', 'ratio': 0.7}, {'word': 'センチメント分析', 'ratio': 0.3}]",感情分析
551,624,Seq2Seq,系列から系列へのモデル,0.0,10,"[{'word': 'シーケンス 2 シーケンス', 'ratio': 0.6}, {'word': 'Seq2Seq', 'ratio': 0.2}, {'word': 'セック2セック', 'ratio': 0.2}]",シーケンス 2 シーケンス
552,625,Set Cover,集合被覆問題,0.0,10,"[{'word': 'セットカバー', 'ratio': 0.8}, {'word': '集合被覆', 'ratio': 0.1}, {'word': '集合カバー', 'ratio': 0.1}]",セットカバー
553,626,Shannon entropy,シャノンエントロピー,0.8,10,"[{'word': 'シャノンエントロピー', 'ratio': 0.8}, {'word': 'シャノン・エントロピー', 'ratio': 0.2}]",シャノンエントロピー
554,627,Sherman-Morrison formula,シャーマン・モリソンの公式,0.8,10,"[{'word': 'シャーマン・モリソンの公式', 'ratio': 0.8}, {'word': 'シューマン・モリソンの公式', 'ratio': 0.1}, {'word': 'シャーマン・モリソン式', 'ratio': 0.1}]",シャーマン・モリソンの公式
555,628,Sherman-Morrison-Woodbury formula,シャーマン・モリソン・ウッドベリー公式,0.0,10,"[{'word': 'シャーマン・モリソン・ウッドベリーの公式', 'ratio': 0.7}, {'word': 'シャーマン-モリソン-ウッドベリー式', 'ratio': 0.1}, {'word': 'シューマン・モリソン・ウッドバリーの公式', 'ratio': 0.1}, {'word': 'シャーマン・モリソン・ウッドベリー式', 'ratio': 0.1}]",シャーマン・モリソン・ウッドベリーの公式
556,630,Siamese network,"""相姿ネットワーク""",0.0,10,"[{'word': 'シャムネットワーク', 'ratio': 0.7}, {'word': 'シャム・ネットワーク', 'ratio': 0.1}, {'word': 'シャミーズネットワーク', 'ratio': 0.1}, {'word': 'シャム双子ネットワーク', 'ratio': 0.1}]",シャムネットワーク
557,631,Sigmoid,シグモイド関数,0.0,10,"[{'word': 'シグモイド', 'ratio': 1.0}]",シグモイド
558,632,Sigmoid function,シグモイド関数,0.9,10,"[{'word': 'シグモイド関数', 'ratio': 0.9}, {'word': 'シグモイド機能', 'ratio': 0.1}]",シグモイド関数
559,633,Singular Value Decomposition,特異値分解,1.0,10,"[{'word': '特異値分解', 'ratio': 1.0}]",特異値分解
560,634,Sinkhorn algorithm,シンクホーンアルゴリズム,0.7,10,"[{'word': 'シンクホーンアルゴリズム', 'ratio': 0.7}, {'word': 'シンクホルンアルゴリズム', 'ratio': 0.1}, {'word': 'シンコーン・アルゴリズム', 'ratio': 0.1}, {'word': 'シンコーンアルゴリズム', 'ratio': 0.1}]",シンクホーンアルゴリズム
561,635,Softmax layer,ソフトマックス層,1.0,10,"[{'word': 'ソフトマックス層', 'ratio': 1.0}]",ソフトマックス層
562,636,Sparse,スパース,0.8,10,"[{'word': 'スパース', 'ratio': 0.8}, {'word': '疎', 'ratio': 0.2}]",スパース
563,637,Sparse Transformer,疎Transformer,0.0,10,"[{'word': 'スパーストランスフォーマー', 'ratio': 0.8}, {'word': 'スパース・トランスフォーマー', 'ratio': 0.2}]",スパーストランスフォーマー
564,638,Sparse reconstruction,疎再構築,0.2,10,"[{'word': 'スパース再構成', 'ratio': 0.8}, {'word': '疎再構築', 'ratio': 0.2}]",スパース再構成
565,639,Sparsemax,スパースマックス,0.9,10,"[{'word': 'スパースマックス', 'ratio': 0.9}, {'word': 'スパース再構成', 'ratio': 0.1}]",スパースマックス
566,640,Spearman correlation,スピアマン相関係数,0.0,10,"[{'word': 'スピアマン相関', 'ratio': 0.9}, {'word': 'スピアマンの相関', 'ratio': 0.1}]",スピアマン相関
567,641,Spearman rank correlation,スピアマンの順位相関,0.1,10,"[{'word': 'スピアマン順位相関', 'ratio': 0.8}, {'word': 'スピアマンランク相関', 'ratio': 0.1}, {'word': 'スピアマンの順位相関', 'ratio': 0.1}]",スピアマン順位相関
568,642,Spearman's correlation,スピアマンの相関係数,0.0,10,"[{'word': 'スピアマンの相関', 'ratio': 1.0}]",スピアマンの相関
569,643,Spearman's correlation coefficient,スピアマンの順位相関係数,0.0,10,"[{'word': 'スピアマンの相関係数', 'ratio': 1.0}]",スピアマンの相関係数
570,644,Spearman's rank correlation coefficient,スピアマンの順位相関係数,0.5,10,"[{'word': 'スピアマンの順位相関係数', 'ratio': 0.5}, {'word': 'スピアマン順位相関係数', 'ratio': 0.4}, {'word': 'スピアマンのランク相関係数', 'ratio': 0.1}]",スピアマンの順位相関係数
571,645,Squared Exponential kernel,二乗指数カーネル,0.9,10,"[{'word': '二乗指数カーネル', 'ratio': 0.9}, {'word': '平方指数_kernel', 'ratio': 0.1}]",二乗指数カーネル
572,646,Stanford Parser,スタンフォードパーサー,0.7,10,"[{'word': 'スタンフォードパーサー', 'ratio': 0.7}, {'word': 'スタンフォード・パーサー', 'ratio': 0.2}, {'word': 'スタンフォード解析器', 'ratio': 0.1}]",スタンフォードパーサー
573,647,Stanford Question Answering Dataset,スタンフォード質問回答データセット (SQuAD),0.0,10,"[{'word': 'スタンフォード質問応答データセット', 'ratio': 0.9}, {'word': 'スタンフォードクエスチョン・アナサー・データセット', 'ratio': 0.1}]",スタンフォード質問応答データセット
574,648,Stanford Sentiment Treebank,スタンフォード感情ツリーバンク,0.7,10,"[{'word': 'スタンフォード感情ツリーバンク', 'ratio': 0.7}, {'word': 'スタンフォード感傷ツリーバンク', 'ratio': 0.2}, {'word': 'スタンフォード・センチメント・トリーンク', 'ratio': 0.1}]",スタンフォード感情ツリーバンク
575,649,Stanford dependency,スタンフォード依存関係,0.7,10,"[{'word': 'スタンフォード依存関係', 'ratio': 0.7}, {'word': 'スタンフォード依存', 'ratio': 0.2}, {'word': 'スタンフォード・デペンデンシー', 'ratio': 0.1}]",スタンフォード依存関係
576,650,Stanford dependency framework,スタンフォード依存関係フレームワーク,0.7,10,"[{'word': 'スタンフォード依存関係フレームワーク', 'ratio': 0.7}, {'word': 'スタンフォード依存フレームワーク', 'ratio': 0.2}, {'word': 'スタンフォード・デペンデンシー・フレームワーク', 'ratio': 0.1}]",スタンフォード依存関係フレームワーク
577,651,Stanford dependency parser,スタンフォード依存構文解析器,0.6,10,"[{'word': 'スタンフォード依存構文解析器', 'ratio': 0.6}, {'word': 'スタンフォード依存関係解析器', 'ratio': 0.2}, {'word': 'スタンフォード依存関係パーサー', 'ratio': 0.2}]",スタンフォード依存構文解析器
578,652,State-of-the-art,最先端の,0.0,10,"[{'word': '最先端', 'ratio': 1.0}]",最先端
579,653,Statistical Machine Translation,統計的機械翻訳,1.0,10,"[{'word': '統計的機械翻訳', 'ratio': 1.0}]",統計的機械翻訳
580,654,Stochastic Gradient Descent,確率的勾配降下法,1.0,10,"[{'word': '確率的勾配降下法', 'ratio': 1.0}]",確率的勾配降下法
581,655,Story Cloze Test,ストーリー空所補充テスト,0.0,10,"[{'word': 'ストーリークローズテスト', 'ratio': 0.5}, {'word': 'ストーリークローステスト', 'ratio': 0.3}, {'word': 'ストーリー・クローズ・テスト', 'ratio': 0.2}]",ストーリークローズテスト
582,656,Structure from motion,動きからの構造,0.9,10,"[{'word': '動きからの構造', 'ratio': 0.9}, {'word': '動きから見る構造', 'ratio': 0.1}]",動きからの構造
583,657,Subgraph,部分グラフ,0.4,10,"[{'word': 'サブグラフ', 'ratio': 0.5}, {'word': '部分グラフ', 'ratio': 0.4}, {'word': '部グラフ', 'ratio': 0.1}]",サブグラフ
584,658,Submodularity,部分加法性,0.0,10,"[{'word': 'サブモジュラリティ', 'ratio': 0.8}, {'word': '劣モジュラリティ', 'ratio': 0.1}, {'word': 'サブモジュール性', 'ratio': 0.1}]",サブモジュラリティ
585,659,Support Vector Machine,サポートベクターマシン,1.0,10,"[{'word': 'サポートベクターマシン', 'ratio': 1.0}]",サポートベクターマシン
586,660,Swin-S,スウィンS,0.7,10,"[{'word': 'スウィンS', 'ratio': 0.7}, {'word': 'Swin-S', 'ratio': 0.3}]",スウィンS
587,661,T5 model,T5モデル,1.0,10,"[{'word': 'T5モデル', 'ratio': 1.0}]",T5モデル
588,662,T5-11B,T5-11B,1.0,10,"[{'word': 'T5-11B', 'ratio': 1.0}]",T5-11B
589,663,T5-11B model,T5-11bモデル,0.0,10,"[{'word': 'T5-11Bモデル', 'ratio': 1.0}]",T5-11Bモデル
590,664,T5-Large,T5-Large,0.5,10,"[{'word': 'T5-ラージ', 'ratio': 0.5}, {'word': 'T5-Large', 'ratio': 0.5}]",T5-ラージ
591,665,T5-base,t5ベース,0.0,10,"[{'word': 'T5ベース', 'ratio': 0.5}, {'word': 'T5-base', 'ratio': 0.5}]",T5ベース
592,666,T5-base model,T5-baseモデル,0.5,10,"[{'word': 'T5ベースモデル', 'ratio': 0.5}, {'word': 'T5-baseモデル', 'ratio': 0.5}]",T5ベースモデル
593,667,T5-large model,T5-large モデル,0.0,10,"[{'word': 'T5-largeモデル', 'ratio': 0.5}, {'word': 'T5-ラージモデル', 'ratio': 0.3}, {'word': 'T5-大型モデル', 'ratio': 0.1}, {'word': 'T5ラージモデル', 'ratio': 0.1}]",T5-largeモデル
594,669,Taylor approximation,テイラー近似,0.9,10,"[{'word': 'テイラー近似', 'ratio': 0.9}, {'word': 'テイラーアプロキシメーション', 'ratio': 0.1}]",テイラー近似
595,670,Tensor,テンソル,1.0,10,"[{'word': 'テンソル', 'ratio': 1.0}]",テンソル
596,671,Text Classification,テキスト分類,0.8,10,"[{'word': 'テキスト分類', 'ratio': 0.8}, {'word': 'テキストの分類', 'ratio': 0.2}]",テキスト分類
597,672,Text Summarization,テキスト要約,0.7,10,"[{'word': 'テキスト要約', 'ratio': 0.7}, {'word': 'テキストの要約', 'ratio': 0.2}, {'word': 'テキストサマリーシステム', 'ratio': 0.1}]",テキスト要約
598,674,Theano,Theano,0.2,10,"[{'word': 'テアノ', 'ratio': 0.8}, {'word': 'Theano', 'ratio': 0.2}]",テアノ
599,675,Toeplitz matrix,トープリッツ行列,0.3,10,"[{'word': 'トプリッツ行列', 'ratio': 0.5}, {'word': 'トープリッツ行列', 'ratio': 0.3}, {'word': 'トーラス行列', 'ratio': 0.1}, {'word': 'トーリッツ行列', 'ratio': 0.1}]",トプリッツ行列
600,676,Token,トークン,1.0,10,"[{'word': 'トークン', 'ratio': 1.0}]",トークン
601,677,Topic Detection and Tracking,トピック検出および追跡,0.0,10,"[{'word': 'トピック検出と追跡', 'ratio': 0.8}, {'word': 'トピックの検出と追跡', 'ratio': 0.2}]",トピック検出と追跡
602,678,Transfer learning,転移学習,0.8,10,"[{'word': '転移学習', 'ratio': 0.8}, {'word': 'トランスファー学習', 'ratio': 0.2}]",転移学習
603,679,Transformer,トランスフォーマー,0.8,10,"[{'word': 'トランスフォーマー', 'ratio': 0.8}, {'word': '変圧器', 'ratio': 0.2}]",トランスフォーマー
604,680,Transformer architecture,"""Transformer アーキテクチャ""",0.0,10,"[{'word': 'トランスフォーマーアーキテクチャ', 'ratio': 0.7}, {'word': 'アーキテクチャを変革する', 'ratio': 0.1}, {'word': '変圧器のアーキテクチャ', 'ratio': 0.1}, {'word': 'トランスフォーマー・アーキテクチャ', 'ratio': 0.1}]",トランスフォーマーアーキテクチャ
605,681,Transformer block,トランスフォーマーブロック,0.8,10,"[{'word': 'トランスフォーマーブロック', 'ratio': 0.8}, {'word': 'トランスブロック', 'ratio': 0.1}, {'word': 'トランスフォーマー・ブロック', 'ratio': 0.1}]",トランスフォーマーブロック
606,682,Transformer decoder,トランスフォーマーデコーダー (Transformer decoder),0.0,10,"[{'word': 'トランスフォーマーデコーダ', 'ratio': 0.7}, {'word': '変換デコード', 'ratio': 0.1}, {'word': 'トランスデコーダ', 'ratio': 0.1}, {'word': 'トランスフォーマー・デコーダ', 'ratio': 0.1}]",トランスフォーマーデコーダ
607,683,Transformer encoder,トランスフォーマーエンコーダー,0.0,10,"[{'word': 'トランスフォーマーエンコーダ', 'ratio': 0.7}, {'word': '変換エンコード', 'ratio': 0.1}, {'word': 'トランスエンコーダ', 'ratio': 0.1}, {'word': 'トランスフォーマー・エンコーダ', 'ratio': 0.1}]",トランスフォーマーエンコーダ
608,684,Transformer model,トランスフォーマーモデル,0.7,10,"[{'word': 'トランスフォーマーモデル', 'ratio': 0.7}, {'word': 'モデルの変換', 'ratio': 0.1}, {'word': '変圧器モデル', 'ratio': 0.1}, {'word': 'トランスフォーマー・モデル', 'ratio': 0.1}]",トランスフォーマーモデル
609,685,Transformer-based language model,トランスフォーマーベースの言語モデル,0.5,10,"[{'word': 'トランスフォーマーベースの言語モデル', 'ratio': 0.5}, {'word': '変換器ベースの言語モデル', 'ratio': 0.2}, {'word': 'トランスフォーマー 기반言語モデル', 'ratio': 0.1}, {'word': 'トランスフォーマー基盤の言語モデル', 'ratio': 0.1}, {'word': 'Transformerベースの言語モデル', 'ratio': 0.1}]",トランスフォーマーベースの言語モデル
610,686,Transformer-based model,トランスフォーマーベースモデル,0.0,10,"[{'word': 'トランスフォーマーベースのモデル', 'ratio': 0.5}, {'word': 'トランスベースのモデル', 'ratio': 0.2}, {'word': 'トランスフォーマー ベースのモデル', 'ratio': 0.1}, {'word': 'トランスフォーマー基盤のモデル', 'ratio': 0.1}, {'word': 'TYgCKfUweBRJ2dA4RGuKJuW3dsDwp7Tbit', 'ratio': 0.1}]",トランスフォーマーベースのモデル
611,688,Traveling Salesman Problem,巡回セールスマン問題,0.8,10,"[{'word': '巡回セールスマン問題', 'ratio': 0.8}, {'word': '旅行セールスマンの質問', 'ratio': 0.1}, {'word': '旅行販売問題', 'ratio': 0.1}]",巡回セールスマン問題
612,690,Triggering Model,発火モデル,0.0,10,"[{'word': 'トリガーモデル', 'ratio': 0.7}, {'word': 'トリガリングモデル', 'ratio': 0.2}, {'word': 'トリガーモデルタッカー分解', 'ratio': 0.1}]",トリガーモデル
613,691,Tucker decomposition,タッカー分解,0.9,10,"[{'word': 'タッカー分解', 'ratio': 0.9}, {'word': 'タッカ分解', 'ratio': 0.1}]",タッカー分解
614,692,Turing Test,チューリングテスト,1.0,10,"[{'word': 'チューリングテスト', 'ratio': 1.0}]",チューリングテスト
615,693,Turing machine,チューリングマシン,0.8,10,"[{'word': 'チューリングマシン', 'ratio': 0.8}, {'word': 'チューリング機械', 'ratio': 0.2}]",チューリングマシン
616,694,Turing reduction,チューリング還元,0.8,10,"[{'word': 'チューリング還元', 'ratio': 0.8}, {'word': 'チューリング・リダクション', 'ratio': 0.2}]",チューリング還元
617,695,U-statistic,U統計量,0.9,10,"[{'word': 'U統計量', 'ratio': 0.9}, {'word': '統計量', 'ratio': 0.1}]",U統計量
618,696,Unigram,ユニグラム,1.0,10,"[{'word': 'ユニグラム', 'ratio': 1.0}]",ユニグラム
619,697,Universal dependency,ユニバーサル依存関係,0.6,10,"[{'word': 'ユニバーサル依存関係', 'ratio': 0.6}, {'word': '普遍的な依存関係', 'ratio': 0.2}, {'word': '普遍的依存関係', 'ratio': 0.1}, {'word': 'ユニバーサル依存性', 'ratio': 0.1}]",ユニバーサル依存関係
620,698,Upper Confidence Bound,上側信頼境界 (UCB),0.0,10,"[{'word': '上限信頼区間', 'ratio': 1.0}]",上限信頼区間
621,700,Variational Autoencoder,変分オートエンコーダ,0.9,10,"[{'word': '変分オートエンコーダ', 'ratio': 0.9}, {'word': '可変的な自己符号化器', 'ratio': 0.1}]",変分オートエンコーダ
622,701,Vertex Cover,頂点被覆,0.7,10,"[{'word': '頂点被覆', 'ratio': 0.7}, {'word': 'バーテックス カバー', 'ratio': 0.2}, {'word': '頂点カバー', 'ratio': 0.1}]",頂点被覆
623,702,Vision Transformer,ビジョントランスフォーマー,0.8,10,"[{'word': 'ビジョントランスフォーマー', 'ratio': 0.8}, {'word': 'ヴィジョン・トランスフォーマー', 'ratio': 0.2}]",ビジョントランスフォーマー
624,703,Visual Question Answering,ビジュアル質問応答 (Visual Question Answering),0.0,10,"[{'word': 'ビジュアル質問応答', 'ratio': 0.6}, {'word': '視覚的質問応答', 'ratio': 0.3}, {'word': '視覚質問応答', 'ratio': 0.1}]",ビジュアル質問応答
625,704,Viterbi,ヴィタービ,0.0,10,"[{'word': 'ビタビ', 'ratio': 0.6}, {'word': 'ビタービアルゴリズム', 'ratio': 0.2}, {'word': 'ヴィタビ', 'ratio': 0.1}, {'word': 'ヴィタービアルゴリズム', 'ratio': 0.1}]",ビタビ
626,705,Viterbi algorithm,ヴィタビアルゴリズム (Viterbi algorithm),0.0,10,"[{'word': 'ビタビアルゴリズム', 'ratio': 0.6}, {'word': 'ビタービアルゴリズム', 'ratio': 0.1}, {'word': 'ヴィタービアルゴリズム', 'ratio': 0.1}, {'word': 'ヴィタビアルゴリズム', 'ratio': 0.1}, {'word': 'Viterbiアルゴリズム', 'ratio': 0.1}]",ビタビアルゴリズム
627,707,Wasserstein distance,ワッサーシュタイン距離,0.2,10,"[{'word': 'ワッサースタイン距離', 'ratio': 0.8}, {'word': 'ワッサーシュタイン距離', 'ratio': 0.2}]",ワッサースタイン距離
628,708,Weibull,ワイブル分布,0.1,10,"[{'word': 'ワイブル', 'ratio': 0.9}, {'word': 'ワイブル分布', 'ratio': 0.1}]",ワイブル
629,710,Wiener process,ウィーナー過程,0.8,10,"[{'word': 'ウィーナー過程', 'ratio': 0.8}, {'word': 'ウィンナ・プロセス', 'ratio': 0.2}]",ウィーナー過程
630,712,Winograd Schema,ウィノグラード・スキーマ,0.3,10,"[{'word': 'ウィノグラードスキーマ', 'ratio': 0.7}, {'word': 'ウィノグラード・スキーマ', 'ratio': 0.3}]",ウィノグラードスキーマ
631,713,Winograd Schema Challenge,ウィノグラード・スキーマ・チャレンジ,0.3,10,"[{'word': 'ウィノグラードスキーマチャレンジ', 'ratio': 0.7}, {'word': 'ウィノグラード・スキーマ・チャレンジ', 'ratio': 0.3}]",ウィノグラードスキーマチャレンジ
632,714,Winogrande,ウィノグランデ,0.7,10,"[{'word': 'ウィノグランデ', 'ratio': 0.7}, {'word': 'ウィノグランド', 'ratio': 0.2}, {'word': 'Winogrande', 'ratio': 0.1}]",ウィノグランデ
633,715,Woodbury matrix identity,ウッドベリー行列恒等式,0.5,10,"[{'word': 'ウッドベリー行列恒等式', 'ratio': 0.5}, {'word': 'ウッドベリー行列の同一性', 'ratio': 0.2}, {'word': 'ウッドベリー行列の恒等式', 'ratio': 0.2}, {'word': 'ウッドブリー行列恒等式', 'ratio': 0.1}]",ウッドベリー行列恒等式
634,716,Word Mover's Distance,ワードムーバー距離,0.6,10,"[{'word': 'ワードムーバー距離', 'ratio': 0.6}, {'word': 'ワードムーバーズ距離', 'ratio': 0.2}, {'word': '言葉の移動距離', 'ratio': 0.2}]",ワードムーバー距離
635,717,Word2Vec,Word2Vec,0.7,10,"[{'word': 'Word2Vec', 'ratio': 0.7}, {'word': 'ワード2ベック', 'ratio': 0.2}, {'word': 'ワード2ベク', 'ratio': 0.1}]",Word2Vec
636,718,Z-score,Zスコア,1.0,10,"[{'word': 'Zスコア', 'ratio': 1.0}]",Zスコア
637,719,Zipf,ジップフ,0.5,10,"[{'word': 'ジップフ', 'ratio': 0.5}, {'word': 'ジップ', 'ratio': 0.4}, {'word': 'ジフ', 'ratio': 0.1}]",ジップフ
638,720,Zipf distribution,ジップ分布,0.4,10,"[{'word': 'ジップフ分布', 'ratio': 0.5}, {'word': 'ジップ分布', 'ratio': 0.4}, {'word': 'ジフ分布', 'ratio': 0.1}]",ジップフ分布
639,721,Zipf's law,ジプフの法則,0.0,10,"[{'word': 'ジップフの法則', 'ratio': 0.5}, {'word': 'ジップの法則', 'ratio': 0.4}, {'word': 'ジフの法則', 'ratio': 0.1}]",ジップフの法則
640,723,ablation analysis,"""消融解析 (shōmyō kaiseki)""",0.0,10,"[{'word': 'アブレーション分析', 'ratio': 1.0}]",アブレーション分析
641,724,ablation experiment,アブレーション実験,1.0,10,"[{'word': 'アブレーション実験', 'ratio': 1.0}]",アブレーション実験
642,725,abstraction,抽象化,0.9,10,"[{'word': '抽象化', 'ratio': 0.9}, {'word': '抽象', 'ratio': 0.1}]",抽象化
643,726,abstraction heuristic,抽象化ヒューリスティック,0.3,10,"[{'word': '抽象ヒューリスティック', 'ratio': 0.7}, {'word': '抽象化ヒューリスティック', 'ratio': 0.3}]",抽象ヒューリスティック
644,727,abstractive summarization,抽象的要約,1.0,10,"[{'word': '抽象的要約', 'ratio': 1.0}]",抽象的要約
645,728,accelerated gradient descent,加速勾配降下法,0.8,10,"[{'word': '加速勾配降下法', 'ratio': 0.8}, {'word': '加速勾配降下', 'ratio': 0.2}]",加速勾配降下法
646,729,acceptance function,受理関数,0.0,10,"[{'word': '受容関数', 'ratio': 0.7}, {'word': 'アクセプタンス機能', 'ratio': 0.2}, {'word': '受け入れ関数', 'ratio': 0.1}]",受容関数
647,730,acceptance probability,受容確率,0.7,10,"[{'word': '受容確率', 'ratio': 0.7}, {'word': '受入確率', 'ratio': 0.2}, {'word': '受け入れ確率', 'ratio': 0.1}]",受容確率
648,731,accumulated error,累積誤差,0.6,10,"[{'word': '累積誤差', 'ratio': 0.6}, {'word': '累積エラー', 'ratio': 0.2}, {'word': '蓄積誤差', 'ratio': 0.2}]",累積誤差
649,732,acoustic feature,音響特徴量,0.1,10,"[{'word': '音響特徴', 'ratio': 0.7}, {'word': 'アコースティック機能', 'ratio': 0.2}, {'word': '音響特徴量', 'ratio': 0.1}]",音響特徴
650,733,acoustic model,音響モデル,1.0,10,"[{'word': '音響モデル', 'ratio': 1.0}]",音響モデル
651,734,acquisition function,取得関数,0.3,10,"[{'word': '獲得関数', 'ratio': 0.5}, {'word': '取得関数', 'ratio': 0.3}, {'word': 'アクイジション機能', 'ratio': 0.2}]",獲得関数
652,735,action classification,行動分類,0.4,10,"[{'word': 'アクション分類', 'ratio': 0.6}, {'word': '行動分類', 'ratio': 0.4}]",アクション分類
653,737,action recognition,行動認識,0.4,10,"[{'word': 'アクション認識', 'ratio': 0.6}, {'word': '行動認識', 'ratio': 0.4}]",アクション認識
654,738,action sequence,行動シーケンス,0.4,10,"[{'word': 'アクションシーケンス', 'ratio': 0.6}, {'word': '行動シーケンス', 'ratio': 0.4}]",アクションシーケンス
655,739,action set,行動集合,0.2,10,"[{'word': 'アクションセット', 'ratio': 0.6}, {'word': '行動集合', 'ratio': 0.2}, {'word': '行動セット', 'ratio': 0.2}]",アクションセット
656,743,activation,活性化,1.0,10,"[{'word': '活性化', 'ratio': 1.0}]",活性化
657,744,activation function,活性化関数,1.0,10,"[{'word': '活性化関数', 'ratio': 1.0}]",活性化関数
658,745,activation matrix,活性化行列,1.0,10,"[{'word': '活性化行列', 'ratio': 1.0}]",活性化行列
659,746,activation vector,活性化ベクトル,1.0,10,"[{'word': '活性化ベクトル', 'ratio': 1.0}]",活性化ベクトル
660,747,active learning loop,アクティブラーニングループ,0.8,10,"[{'word': 'アクティブラーニングループ', 'ratio': 0.8}, {'word': 'アクティブ・ラーニング・ループ', 'ratio': 0.2}]",アクティブラーニングループ
661,748,active set,アクティブセット,1.0,10,"[{'word': 'アクティブセット', 'ratio': 1.0}]",アクティブセット
662,749,activity detection,活動検出,0.8,10,"[{'word': '活動検出', 'ratio': 0.8}, {'word': 'アクティビティ検出', 'ratio': 0.2}]",活動検出
663,750,activity recognition,行動認識,0.0,10,"[{'word': '活動認識', 'ratio': 0.8}, {'word': 'アクティビティ認識', 'ratio': 0.1}, {'word': 'アクティビティの認識', 'ratio': 0.1}]",活動認識
664,751,actor,アクター,0.6,10,"[{'word': 'アクター', 'ratio': 0.6}, {'word': 'エージェント', 'ratio': 0.2}, {'word': '俳優', 'ratio': 0.2}]",アクター
665,752,actor critic algorithm,- アクター批評家アルゴリズム,0.0,10,"[{'word': 'アクター・クリティックアルゴリズム', 'ratio': 0.7}, {'word': '俳優評論家アルゴリズム', 'ratio': 0.1}, {'word': '俳優批評家アルゴリズム', 'ratio': 0.1}, {'word': 'アクター-クリティックアルゴリズム', 'ratio': 0.1}]",アクター・クリティックアルゴリズム
666,753,actor network,アクターネットワーク,0.9,10,"[{'word': 'アクターネットワーク', 'ratio': 0.9}, {'word': '俳優ネットワーク', 'ratio': 0.1}]",アクターネットワーク
667,754,actor-critic framework,アクター・クリティックフレームワーク,0.7,10,"[{'word': 'アクター・クリティックフレームワーク', 'ratio': 0.7}, {'word': '行為者批判的枠組み', 'ratio': 0.1}, {'word': '俳優と批評家の枠組み', 'ratio': 0.1}, {'word': 'アクター-クリティックフレームワーク', 'ratio': 0.1}]",アクター・クリティックフレームワーク
668,757,adaptive boosting algorithm,適応的ブースティングアルゴリズム,0.0,10,"[{'word': 'アダプティブブースティングアルゴリズム', 'ratio': 0.5}, {'word': '適応ブースティングアルゴリズム', 'ratio': 0.4}, {'word': '適応ブースティング・アルゴリズム', 'ratio': 0.1}]",アダプティブブースティングアルゴリズム
669,761,adjacency,隣接,0.4,10,"[{'word': '隣接性', 'ratio': 0.6}, {'word': '隣接', 'ratio': 0.4}]",隣接性
670,762,adjacency matrix,隣接行列,1.0,10,"[{'word': '隣接行列', 'ratio': 1.0}]",隣接行列
671,763,advantage function,優位関数,0.0,10,"[{'word': 'アドバンテージ関数', 'ratio': 0.8}, {'word': 'アドバンテージ機能', 'ratio': 0.1}, {'word': '利点関数', 'ratio': 0.1}]",アドバンテージ関数
672,764,advcl,副修飾節,0.0,10,"[{'word': '副詞節', 'ratio': 0.5}, {'word': 'えんきん', 'ratio': 0.2}, {'word': '副文節', 'ratio': 0.1}, {'word': '副文', 'ratio': 0.1}, {'word': '副節句', 'ratio': 0.1}]",副詞節
673,765,adversarial attack,対抗攻撃,0.0,10,"[{'word': '敵対的攻撃', 'ratio': 1.0}]",敵対的攻撃
674,766,adversarial dataset,敵対的データセット,1.0,10,"[{'word': '敵対的データセット', 'ratio': 1.0}]",敵対的データセット
675,767,adversarial example,敵対的例,0.6,10,"[{'word': '敵対的例', 'ratio': 0.6}, {'word': '敵対的事例', 'ratio': 0.1}, {'word': '敵対的データセット', 'ratio': 0.1}, {'word': '敵対的な例', 'ratio': 0.1}, {'word': '敵対的サンプル', 'ratio': 0.1}]",敵対的例
676,768,adversarial filtering,対抗的フィルタリング,0.0,10,"[{'word': '敵対的フィルタリング', 'ratio': 1.0}]",敵対的フィルタリング
677,769,adversarial input,敵対的な入力,0.0,10,"[{'word': '敵対的入力', 'ratio': 1.0}]",敵対的入力
678,770,adversarial learning,対抗的学習 (Taikōteki gakushū),0.0,10,"[{'word': '敵対的学習', 'ratio': 1.0}]",敵対的学習
679,771,adversarial loss,対抗損失,0.0,10,"[{'word': '敵対的損失', 'ratio': 0.8}, {'word': '敵失', 'ratio': 0.2}]",敵対的損失
680,772,adversarial network,対抗ネットワーク,0.0,10,"[{'word': '敵対的ネットワーク', 'ratio': 1.0}]",敵対的ネットワーク
681,773,adversarial perturbation,敵対的な摂動,0.0,10,"[{'word': '敵対的摂動', 'ratio': 1.0}]",敵対的摂動
682,774,adversarial prompt,敵対的プロンプト,0.8,10,"[{'word': '敵対的プロンプト', 'ratio': 0.8}, {'word': 'アドバーシアルプロンプト', 'ratio': 0.1}, {'word': '敵対的なプロンプト', 'ratio': 0.1}]",敵対的プロンプト
683,775,adversarial robustness,"""敵対的な堅牢性""",0.0,10,"[{'word': '敵対的ロバスト性', 'ratio': 0.6}, {'word': '敵対的堅牢性', 'ratio': 0.2}, {'word': '敵対的頑健性', 'ratio': 0.1}, {'word': '敵対的な堅牢性', 'ratio': 0.1}]",敵対的ロバスト性
684,776,adversarial training,"- Translated term: ""敵対的トレーニング""",0.0,10,"[{'word': '敵対的訓練', 'ratio': 0.6}, {'word': '敵対的トレーニング', 'ratio': 0.3}, {'word': '敵対的学習', 'ratio': 0.1}]",敵対的訓練
685,777,adversary,敵対者,0.7,10,"[{'word': '敵対者', 'ratio': 0.7}, {'word': '敵', 'ratio': 0.3}]",敵対者
686,778,advmod,advmod,0.8,10,"[{'word': 'advmod', 'ratio': 0.8}, {'word': 'アドモッド', 'ratio': 0.1}, {'word': '副詞修飾', 'ratio': 0.1}]",advmod
687,779,affine,アフィン,0.8,10,"[{'word': 'アフィン', 'ratio': 0.8}, {'word': '洗練された', 'ratio': 0.1}, {'word': '有理変換', 'ratio': 0.1}]",アフィン
688,780,affine transform,アフィン変換,0.9,10,"[{'word': 'アフィン変換', 'ratio': 0.9}, {'word': '有理変換', 'ratio': 0.1}]",アフィン変換
689,781,affine transformation,アフィン変換,0.9,10,"[{'word': 'アフィン変換', 'ratio': 0.9}, {'word': '有理変換', 'ratio': 0.1}]",アフィン変換
690,782,affinity matrix,アフィニティ行列,0.5,10,"[{'word': 'アフィニティ行列', 'ratio': 0.5}, {'word': 'アフィニティーマトリックス', 'ratio': 0.1}, {'word': 'アフィニティマトリックス', 'ratio': 0.1}, {'word': '類似度行列', 'ratio': 0.1}, {'word': '親和性マトリックス', 'ratio': 0.1}, {'word': '親和行列', 'ratio': 0.1}]",アフィニティ行列
691,783,affine subspace,アフィン部分空間,0.8888888888888888,9,"[{'word': 'アフィン部分空間', 'ratio': 0.8888888888888888}, {'word': '有理合同空間', 'ratio': 0.1111111111111111}]",アフィン部分空間
692,785,agent architecture,エージェントアーキテクチャ,1.0,10,"[{'word': 'エージェントアーキテクチャ', 'ratio': 1.0}]",エージェントアーキテクチャ
693,786,agent learning,エージェント学習,1.0,10,"[{'word': 'エージェント学習', 'ratio': 1.0}]",エージェント学習
694,787,agent policy,エージェントポリシー,0.7,10,"[{'word': 'エージェントポリシー', 'ratio': 0.7}, {'word': '代理店ポリシー', 'ratio': 0.2}, {'word': 'エージェント方針', 'ratio': 0.1}]",エージェントポリシー
695,788,agent's policy,エージェントの方針,0.1,10,"[{'word': 'エージェントのポリシー', 'ratio': 0.7}, {'word': '代理店の方針', 'ratio': 0.2}, {'word': 'エージェントの方針', 'ratio': 0.1}]",エージェントのポリシー
696,789,agent-based model,エージェントベースモデル,0.9,10,"[{'word': 'エージェントベースモデル', 'ratio': 0.9}, {'word': '後悔の最小化', 'ratio': 0.1}]",エージェントベースモデル
697,790,aggregate function,集約関数,0.8,10,"[{'word': '集約関数', 'ratio': 0.8}, {'word': '集約機能', 'ratio': 0.1}, {'word': '集計関数', 'ratio': 0.1}]",集約関数
698,791,aggregation,集約,0.8,10,"[{'word': '集約', 'ratio': 0.8}, {'word': 'アグリゲイション', 'ratio': 0.1}, {'word': '集計', 'ratio': 0.1}]",集約
699,792,aggregation function,集約関数,0.8,10,"[{'word': '集約関数', 'ratio': 0.8}, {'word': 'しゅうけいかんすう', 'ratio': 0.1}, {'word': '集計関数', 'ratio': 0.1}]",集約関数
700,794,algorithm class,アルゴリズムクラス,0.9,10,"[{'word': 'アルゴリズムクラス', 'ratio': 0.9}, {'word': 'アルゴリズムクラ', 'ratio': 0.1}]",アルゴリズムクラス
701,795,algorithm design,アルゴリズム設計,1.0,10,"[{'word': 'アルゴリズム設計', 'ratio': 1.0}]",アルゴリズム設計
702,796,algorithmic approach,アルゴリズム的アプローチ,0.7,10,"[{'word': 'アルゴリズム的アプローチ', 'ratio': 0.7}, {'word': 'アルゴリズミックアプローチ', 'ratio': 0.2}, {'word': 'アルゴリズムアプローチ', 'ratio': 0.1}]",アルゴリズム的アプローチ
703,799,algorithmic stability,アルゴリズムの安定性,0.5,10,"[{'word': 'アルゴリズムの安定性', 'ratio': 0.5}, {'word': 'アルゴリズム的安定性', 'ratio': 0.3}, {'word': 'アルゴリズミックスタビリティ', 'ratio': 0.1}, {'word': 'アルゴリズミック安定性', 'ratio': 0.1}]",アルゴリズムの安定性
704,800,alias table,エイリアステーブル,0.8,10,"[{'word': 'エイリアステーブル', 'ratio': 0.8}, {'word': '別名テーブル', 'ratio': 0.2}]",エイリアステーブル
705,801,alignment algorithm,整列アルゴリズム,0.0,10,"[{'word': 'アライメントアルゴリズム', 'ratio': 0.6}, {'word': 'アラインメントアルゴリズム', 'ratio': 0.4}]",アライメントアルゴリズム
706,802,alignment model,アライメントモデル,0.8,10,"[{'word': 'アライメントモデル', 'ratio': 0.8}, {'word': 'アラインメントモデル', 'ratio': 0.1}, {'word': 'alignment モデル', 'ratio': 0.1}]",アライメントモデル
707,803,alpha compositing,アルファ合成,1.0,10,"[{'word': 'アルファ合成', 'ratio': 1.0}]",アルファ合成
708,804,alphabet size,アルファベットのサイズ,0.1,10,"[{'word': 'アルファベットサイズ', 'ratio': 0.9}, {'word': 'アルファベットのサイズ', 'ratio': 0.1}]",アルファベットサイズ
709,805,alternating least square,交互最小二乗法,0.9,10,"[{'word': '交互最小二乗法', 'ratio': 0.9}, {'word': '交互最小二乗', 'ratio': 0.1}]",交互最小二乗法
710,806,alternating minimization,交互最小化,0.9,10,"[{'word': '交互最小化', 'ratio': 0.9}, {'word': '交互最適化', 'ratio': 0.1}]",交互最小化
711,807,ambient space,環境空間,0.2,10,"[{'word': '周囲空間', 'ratio': 0.7}, {'word': '環境空間', 'ratio': 0.2}, {'word': 'アンビエント空間', 'ratio': 0.1}]",周囲空間
712,808,anaphora resolution,照応解析,0.0,10,"[{'word': '指示詞解決', 'ratio': 0.7}, {'word': '照応解決', 'ratio': 0.2}, {'word': 'アナフォラ解決', 'ratio': 0.1}]",指示詞解決
713,810,ancestral sampling,祖先サンプリング,0.9,10,"[{'word': '祖先サンプリング', 'ratio': 0.9}, {'word': '祖先のサンプリング', 'ratio': 0.1}]",祖先サンプリング
714,811,anchor,アンカー,1.0,10,"[{'word': 'アンカー', 'ratio': 1.0}]",アンカー
715,812,anchor box,アンカーボックス,1.0,10,"[{'word': 'アンカーボックス', 'ratio': 1.0}]",アンカーボックス
716,813,annotated corpus,注釈付きコーパス,0.9,10,"[{'word': '注釈付きコーパス', 'ratio': 0.9}, {'word': 'アノテーション済みコーパス', 'ratio': 0.1}]",注釈付きコーパス
717,814,annotated datum,注釈付きデータ,0.5,10,"[{'word': '注釈付きデータ', 'ratio': 0.5}, {'word': '注釈付きデータム', 'ratio': 0.2}, {'word': '注釈データ', 'ratio': 0.2}, {'word': 'アノテーション済みデータ', 'ratio': 0.1}]",注釈付きデータ
718,815,annotation,アノテーション,0.5,20,"[{'word': '注釈', 'ratio': 0.8}, {'word': 'アノテーション', 'ratio': 0.2}]",注釈
719,816,annotation artifact,アノテーション人為物,0.0,10,"[{'word': '注釈アーティファクト', 'ratio': 0.8}, {'word': 'アノテーションアーティファクト', 'ratio': 0.2}]",注釈アーティファクト
720,817,annotation projection,アノテーション投影,0.2,10,"[{'word': '注釈投影', 'ratio': 0.6}, {'word': 'アノテーション投影', 'ratio': 0.2}, {'word': '注釈プロジェクション', 'ratio': 0.2}]",注釈投影
721,818,annotator,アノテータ,0.0,10,"[{'word': 'アノテーター', 'ratio': 0.7}, {'word': '注釈者', 'ratio': 0.3}]",アノテーター
722,820,anomaly detection,異常検出,0.2,10,"[{'word': '異常検知', 'ratio': 0.8}, {'word': '異常検出', 'ratio': 0.2}]",異常検知
723,821,anomaly score,異常スコア,0.8,10,"[{'word': '異常スコア', 'ratio': 0.8}, {'word': 'アノマリースコア', 'ratio': 0.2}]",異常スコア
724,822,answer set,解答集合,0.6,10,"[{'word': '解答集合', 'ratio': 0.6}, {'word': 'アンサーセット', 'ratio': 0.3}, {'word': '解答セット', 'ratio': 0.1}]",解答集合
725,823,answer set solver,解答セットソルバー,0.2,10,"[{'word': '解答集合ソルバー', 'ratio': 0.6}, {'word': '解答セットソルバー', 'ratio': 0.2}, {'word': 'アンサーセットソルバー', 'ratio': 0.2}]",解答集合ソルバー
726,825,answer variable,回答変数,0.2,10,"[{'word': '解答変数', 'ratio': 0.5}, {'word': '回答変数', 'ratio': 0.2}, {'word': '答え変数', 'ratio': 0.2}, {'word': '答えの変数', 'ratio': 0.1}]",解答変数
727,826,antecedent,前件,0.6,10,"[{'word': '前件', 'ratio': 0.6}, {'word': '前提', 'ratio': 0.2}, {'word': '先行詞', 'ratio': 0.2}]",前件
728,829,aperture problem,アパーチャ問題,0.6,10,"[{'word': 'アパーチャ問題', 'ratio': 0.6}, {'word': '絞り問題', 'ratio': 0.2}, {'word': 'アプチュア問題', 'ratio': 0.1}, {'word': '開口問題', 'ratio': 0.1}]",アパーチャ問題
729,830,appearance model,外観モデル,1.0,10,"[{'word': '外観モデル', 'ratio': 1.0}]",外観モデル
730,832,approximate inference,近似推論,0.9,10,"[{'word': '近似推論', 'ratio': 0.9}, {'word': '近似推定', 'ratio': 0.1}]",近似推論
731,833,approximate inference algorithm,近似推論アルゴリズム,0.9,10,"[{'word': '近似推論アルゴリズム', 'ratio': 0.9}, {'word': '近似推定アルゴリズム', 'ratio': 0.1}]",近似推論アルゴリズム
732,834,approximate posterior,近似事後分布,0.6,10,"[{'word': '近似事後分布', 'ratio': 0.6}, {'word': '近似ポストリア', 'ratio': 0.2}, {'word': '近似後分布', 'ratio': 0.1}, {'word': '近似後ISTRIBUTION', 'ratio': 0.1}]",近似事後分布
733,835,approximate posterior distribution,近似事後分布,0.7,10,"[{'word': '近似事後分布', 'ratio': 0.7}, {'word': '近似後分布', 'ratio': 0.2}, {'word': '近似後方分布', 'ratio': 0.1}]",近似事後分布
734,836,approximate similarity search,近似類似検索,0.8,10,"[{'word': '近似類似検索', 'ratio': 0.8}, {'word': '近似類似性検索', 'ratio': 0.1}, {'word': '近似類似探索', 'ratio': 0.1}]",近似類似検索
735,837,approximation,近似,0.9,10,"[{'word': '近似', 'ratio': 0.9}, {'word': '近似値', 'ratio': 0.1}]",近似
736,838,approximation algorithm,近似アルゴリズム,1.0,10,"[{'word': '近似アルゴリズム', 'ratio': 1.0}]",近似アルゴリズム
737,839,approximation bound,"""近似束縛""",0.0,10,"[{'word': '近似境界', 'ratio': 0.8}, {'word': '近似限界', 'ratio': 0.2}]",近似境界
738,840,approximation error,近似誤差,1.0,10,"[{'word': '近似誤差', 'ratio': 1.0}]",近似誤差
739,841,approximation factor,近似係数,0.5,10,"[{'word': '近似因子', 'ratio': 0.5}, {'word': '近似係数', 'ratio': 0.5}]",近似因子
740,842,approximation guarantee,近似保証,0.8,10,"[{'word': '近似保証', 'ratio': 0.8}, {'word': '近似値保証', 'ratio': 0.2}]",近似保証
741,843,approximation ratio,近似比,0.8,10,"[{'word': '近似比', 'ratio': 0.8}, {'word': '近似率', 'ratio': 0.1}, {'word': '近似比率', 'ratio': 0.1}]",近似比
742,844,approximator,近似器,0.8,10,"[{'word': '近似器', 'ratio': 0.8}, {'word': '近似値', 'ratio': 0.2}]",近似器
743,845,arc-factored model,アークファクターモデル,0.1,10,"[{'word': 'アーク因子モデル', 'ratio': 0.7}, {'word': 'アークファクタモデル', 'ratio': 0.2}, {'word': 'アークファクターモデル', 'ratio': 0.1}]",アーク因子モデル
744,847,architecture,アーキテクチャ,0.8,10,"[{'word': 'アーキテクチャ', 'ratio': 0.8}, {'word': '建築', 'ratio': 0.2}]",アーキテクチャ
745,848,architecture search,アーキテクチャ検索,0.2,10,"[{'word': 'アーキテクチャ探索', 'ratio': 0.6}, {'word': 'アーキテクチャ検索', 'ratio': 0.2}, {'word': '建築検索', 'ratio': 0.2}]",アーキテクチャ探索
746,851,argument,引数,0.8,10,"[{'word': '引数', 'ratio': 0.8}, {'word': '議論', 'ratio': 0.1}, {'word': '口論', 'ratio': 0.1}]",引数
747,852,argument identification,引数の識別,0.1,10,"[{'word': '引数の特定', 'ratio': 0.5}, {'word': '引数識別', 'ratio': 0.2}, {'word': '引数特定', 'ratio': 0.2}, {'word': '引数の識別', 'ratio': 0.1}]",引数の特定
748,853,argument relation,論証関係,0.0,10,"[{'word': '引数関係', 'ratio': 1.0}]",引数関係
749,854,argument structure,項構造,0.0,10,"[{'word': '引数構造', 'ratio': 0.9}, {'word': '引数の構造', 'ratio': 0.1}]",引数構造
750,855,arity,引数数,0.0,10,"[{'word': 'アリティ', 'ratio': 0.7}, {'word': '順序', 'ratio': 0.2}, {'word': '値の数', 'ratio': 0.1}]",アリティ
751,856,artificial agent,人工エージェント,0.9,10,"[{'word': '人工エージェント', 'ratio': 0.9}, {'word': 'じんこうざい', 'ratio': 0.1}]",人工エージェント
752,857,artificial intelligence system,人工知能システム,1.0,10,"[{'word': '人工知能システム', 'ratio': 1.0}]",人工知能システム
753,858,artificial neural network,人工ニューラルネットワーク,1.0,10,"[{'word': '人工ニューラルネットワーク', 'ratio': 1.0}]",人工ニューラルネットワーク
754,859,assignment problem,割り当て問題,0.6,10,"[{'word': '割り当て問題', 'ratio': 0.6}, {'word': '割当問題', 'ratio': 0.3}, {'word': '代入問題', 'ratio': 0.1}]",割り当て問題
755,860,association rule,結合規則 (けつごうきそく),0.0,10,"[{'word': 'アソシエーションルール', 'ratio': 0.9}, {'word': '相関ルール', 'ratio': 0.1}]",アソシエーションルール
756,861,association rule mining,関連ルールマイニング,0.0,10,"[{'word': 'アソシエーションルールマイニング', 'ratio': 0.8}, {'word': 'アソシエーションルール・マイニング', 'ratio': 0.1}, {'word': '相関ルールマイニング', 'ratio': 0.1}]",アソシエーションルールマイニング
757,862,asymmetric transformation,非対称変換,1.0,10,"[{'word': '非対称変換', 'ratio': 1.0}]",非対称変換
758,863,asymptotic bias,漸近的なバイアス,0.0,10,"[{'word': '漸近バイアス', 'ratio': 1.0}]",漸近バイアス
759,864,asymptotic notation,漸近記法,0.3,10,"[{'word': '漸近表記', 'ratio': 0.6}, {'word': '漸近記法', 'ratio': 0.3}, {'word': '漸近表記法', 'ratio': 0.1}]",漸近表記
760,865,asymptotic variance,漸近分散,1.0,10,"[{'word': '漸近分散', 'ratio': 1.0}]",漸近分散
761,866,attack success rate,攻撃成功率,1.0,10,"[{'word': '攻撃成功率', 'ratio': 1.0}]",攻撃成功率
762,869,attention head,アテンションヘッド (Atenshon Heddo),0.0,10,"[{'word': 'アテンションヘッド', 'ratio': 0.5}, {'word': '注意ヘッド', 'ratio': 0.4}, {'word': '注意頭', 'ratio': 0.1}]",アテンションヘッド
763,871,attention map,アテンションマップ,0.6,10,"[{'word': 'アテンションマップ', 'ratio': 0.6}, {'word': '注意マップ', 'ratio': 0.4}]",アテンションマップ
764,872,attention mask,アテンションマスク,0.9,10,"[{'word': 'アテンションマスク', 'ratio': 0.9}, {'word': '注意マスク', 'ratio': 0.1}]",アテンションマスク
765,873,attention matrix,注意行列,0.0,10,"[{'word': 'アテンション行列', 'ratio': 0.5}, {'word': 'アテンションマトリックス', 'ratio': 0.4}, {'word': 'アテンション・マトリックス', 'ratio': 0.1}]",アテンション行列
766,874,attention mechanism,注意機構,0.0,10,"[{'word': 'アテンションメカニズム', 'ratio': 0.8}, {'word': 'アテンション・メカニズム', 'ratio': 0.1}, {'word': '注意メカニズム', 'ratio': 0.1}]",アテンションメカニズム
767,875,attention model,注意モデル,0.0,10,"[{'word': 'アテンションモデル', 'ratio': 0.9}, {'word': '注目モデル', 'ratio': 0.1}]",アテンションモデル
768,876,attention module,注意モジュール,0.1,10,"[{'word': 'アテンションモジュール', 'ratio': 0.9}, {'word': '注意モジュール', 'ratio': 0.1}]",アテンションモジュール
769,877,attention operation,注意操作,0.3,10,"[{'word': 'アテンション操作', 'ratio': 0.5}, {'word': '注意操作', 'ratio': 0.3}, {'word': 'アテンション・オペレーション', 'ratio': 0.2}]",アテンション操作
770,878,attention pattern,アテンションパターン,0.7,10,"[{'word': 'アテンションパターン', 'ratio': 0.7}, {'word': '注意パターン', 'ratio': 0.3}]",アテンションパターン
771,879,attention score,注意スコア,0.3,10,"[{'word': 'アテンションスコア', 'ratio': 0.7}, {'word': '注意スコア', 'ratio': 0.3}]",アテンションスコア
772,880,attention value,注目値,0.0,10,"[{'word': 'アテンション値', 'ratio': 0.5}, {'word': '注意値', 'ratio': 0.3}, {'word': 'アテンション・バリュー', 'ratio': 0.2}]",アテンション値
773,883,attribute,属性,1.0,10,"[{'word': '属性', 'ratio': 1.0}]",属性
774,884,attribution,帰属,1.0,10,"[{'word': '帰属', 'ratio': 1.0}]",帰属
775,886,augmented state space,拡張状態空間,1.0,10,"[{'word': '拡張状態空間', 'ratio': 1.0}]",拡張状態空間
776,887,auto-regressive language model,自己回帰言語モデル,0.7,10,"[{'word': '自己回帰言語モデル', 'ratio': 0.7}, {'word': '自己回帰型言語モデル', 'ratio': 0.2}, {'word': '自回帰言語モデル', 'ratio': 0.1}]",自己回帰言語モデル
777,888,auto-regressive model,自己回帰モデル,0.9,10,"[{'word': '自己回帰モデル', 'ratio': 0.9}, {'word': '自回帰モデル', 'ratio': 0.1}]",自己回帰モデル
778,889,auto-regressive process,自己回帰過程,0.9,10,"[{'word': '自己回帰過程', 'ratio': 0.9}, {'word': '自回帰過程', 'ratio': 0.1}]",自己回帰過程
779,890,autocalibration,自動校正,0.0,10,"[{'word': '自動キャリブレーション', 'ratio': 0.6}, {'word': 'オートキャリブレーション', 'ratio': 0.4}]",自動キャリブレーション
780,891,autocorrelation,自己相関,1.0,10,"[{'word': '自己相関', 'ratio': 1.0}]",自己相関
781,892,autodiff,自動微分,0.8,10,"[{'word': '自動微分', 'ratio': 0.8}, {'word': 'オートディフ', 'ratio': 0.2}]",自動微分
782,893,automata,オートマトン,0.7,10,"[{'word': 'オートマトン', 'ratio': 0.7}, {'word': 'オートマタ', 'ratio': 0.3}]",オートマトン
783,894,automated mechanism design,自動メカニズム設計,0.5,10,"[{'word': '自動メカニズム設計', 'ratio': 0.5}, {'word': '自動化メカニズム設計', 'ratio': 0.3}, {'word': '自動機構設計', 'ratio': 0.2}]",自動メカニズム設計
784,895,automatic differentiation,自動微分,0.9,10,"[{'word': '自動微分', 'ratio': 0.9}, {'word': '自動差別化', 'ratio': 0.1}]",自動微分
785,896,automatic evaluation,自動評価,1.0,10,"[{'word': '自動評価', 'ratio': 1.0}]",自動評価
786,899,autonomous agent,自律エージェント,0.7,10,"[{'word': '自律エージェント', 'ratio': 0.7}, {'word': 'じりつエージェント', 'ratio': 0.2}, {'word': '自律系エージェント', 'ratio': 0.1}]",自律エージェント
787,901,autoregressive decoder,自己回帰デコーダ,0.6,10,"[{'word': '自己回帰デコーダ', 'ratio': 0.6}, {'word': '自回帰デコーダ', 'ratio': 0.2}, {'word': '自己回帰デコーダー', 'ratio': 0.2}]",自己回帰デコーダ
788,902,autoregressive generation,自己回帰生成,0.6,10,"[{'word': '自己回帰生成', 'ratio': 0.6}, {'word': '自回帰生成', 'ratio': 0.2}, {'word': '自己回帰世代', 'ratio': 0.2}]",自己回帰生成
789,903,auxiliary classifier,補助分類器,1.0,10,"[{'word': '補助分類器', 'ratio': 1.0}]",補助分類器
790,904,auxiliary loss,補助損失,0.8,10,"[{'word': '補助損失', 'ratio': 0.8}, {'word': '補助ロス', 'ratio': 0.2}]",補助損失
791,905,auxiliary task,補助タスク,0.8,10,"[{'word': '補助タスク', 'ratio': 0.8}, {'word': '補助業務', 'ratio': 0.2}]",補助タスク
792,906,auxiliary variable,補助変数,1.0,10,"[{'word': '補助変数', 'ratio': 1.0}]",補助変数
793,907,auxillary loss,補助損失,0.7,10,"[{'word': '補助損失', 'ratio': 0.7}, {'word': '補助ロス', 'ratio': 0.2}, {'word': '補助的な損失', 'ratio': 0.1}]",補助損失
794,908,average loss,平均損失,1.0,9,"[{'word': '平均損失', 'ratio': 1.0}]",平均損失
795,909,averaged perceptron,平均パーセプトロン,0.7777777777777778,9,"[{'word': '平均パーセプトロン', 'ratio': 0.7777777777777778}, {'word': '平均化パーセプトロン', 'ratio': 0.2222222222222222}]",平均パーセプトロン
796,910,averaged perceptron algorithm,平均パーセプトロンアルゴリズム,0.7777777777777778,9,"[{'word': '平均パーセプトロンアルゴリズム', 'ratio': 0.7777777777777778}, {'word': '平均化パーセプトロンアルゴリズム', 'ratio': 0.2222222222222222}]",平均パーセプトロンアルゴリズム
797,912,back-off strategy,バックオフ戦略,0.8888888888888888,9,"[{'word': 'バックオフ戦略', 'ratio': 0.8888888888888888}, {'word': '後退戦略', 'ratio': 0.1111111111111111}]",バックオフ戦略
798,913,back-propagate,逆伝播,0.4,10,"[{'word': 'バックプロパゲート', 'ratio': 0.6}, {'word': '逆伝播', 'ratio': 0.4}]",バックプロパゲート
799,915,back-propagation algorithm,バックプロパゲーションアルゴリズム,0.6,10,"[{'word': 'バックプロパゲーションアルゴリズム', 'ratio': 0.6}, {'word': '逆伝播アルゴリズム', 'ratio': 0.4}]",バックプロパゲーションアルゴリズム
800,916,back-translation,逆翻訳,0.3,10,"[{'word': 'バックトランスレーション', 'ratio': 0.6}, {'word': '逆翻訳', 'ratio': 0.3}, {'word': 'バックプロパゲーションアルゴリズム', 'ratio': 0.1}]",バックトランスレーション
801,917,backbone model,基幹モデル,0.0,10,"[{'word': 'バックボーンモデル', 'ratio': 1.0}]",バックボーンモデル
802,918,backbone network,基幹ネットワーク,0.0,9,"[{'word': 'バックボーンネットワーク', 'ratio': 0.8888888888888888}, {'word': '背骨ネットワーク', 'ratio': 0.1111111111111111}]",バックボーンネットワーク
803,919,backdoor,バックドア,1.0,9,"[{'word': 'バックドア', 'ratio': 1.0}]",バックドア
804,920,backdoor adjustment,裏口調整,0.0,9,"[{'word': 'バックドア調整', 'ratio': 1.0}]",バックドア調整
805,921,backdoor attack,バックドア攻撃,1.0,9,"[{'word': 'バックドア攻撃', 'ratio': 1.0}]",バックドア攻撃
806,922,backdoor sample,バックドアサンプル,0.7777777777777778,9,"[{'word': 'バックドアサンプル', 'ratio': 0.7777777777777778}, {'word': 'バックドア・サンプル', 'ratio': 0.2222222222222222}]",バックドアサンプル
807,923,background model,背景モデル,0.8,10,"[{'word': '背景モデル', 'ratio': 0.8}, {'word': 'バックグラウンドモデルの', 'ratio': 0.1}, {'word': 'バックグラウンドモデル', 'ratio': 0.1}]",背景モデル
808,924,background subtraction,背景差分,0.7,10,"[{'word': '背景差分', 'ratio': 0.7}, {'word': 'バックグラウンド減算', 'ratio': 0.2}, {'word': 'バックグラウンド差分', 'ratio': 0.1}]",背景差分
809,925,backoff model,バックオフモデル,1.0,10,"[{'word': 'バックオフモデル', 'ratio': 1.0}]",バックオフモデル
810,926,backpointer,バックポインタ,1.0,10,"[{'word': 'バックポインタ', 'ratio': 1.0}]",バックポインタ
811,927,backprojection,逆投影,0.1,10,"[{'word': 'バックプロジェクション', 'ratio': 0.7}, {'word': 'backprojection', 'ratio': 0.1}, {'word': '逆投影', 'ratio': 0.1}, {'word': 'バック投影', 'ratio': 0.1}]",バックプロジェクション
812,928,backprop,逆伝播,0.0,10,"[{'word': 'バックプロップ', 'ratio': 0.7}, {'word': 'バックプロパゲーション', 'ratio': 0.2}, {'word': 'バックドロップ', 'ratio': 0.1}]",バックプロップ
813,929,backtracking line search,後戻り線探索,0.0,10,"[{'word': 'バックトラッキングラインサーチ', 'ratio': 0.6}, {'word': 'バックトラッキング線形探索', 'ratio': 0.1}, {'word': 'バックトラック行探索', 'ratio': 0.1}, {'word': '遡行ライン検索', 'ratio': 0.1}, {'word': 'バックトラッキング・ラインサーチ', 'ratio': 0.1}]",バックトラッキングラインサーチ
814,930,backward pass,逆伝播,0.0,10,"[{'word': 'バックワードパス', 'ratio': 0.8}, {'word': 'バックパス', 'ratio': 0.1}, {'word': 'バックワード・パス', 'ratio': 0.1}]",バックワードパス
815,935,bandit,バンディット,0.8,10,"[{'word': 'バンディット', 'ratio': 0.8}, {'word': '盗賊', 'ratio': 0.2}]",バンディット
816,936,bandit feedback,バンディットフィードバック,0.8,10,"[{'word': 'バンディットフィードバック', 'ratio': 0.8}, {'word': '盗賊のフィードバック', 'ratio': 0.2}]",バンディットフィードバック
817,937,bandit learning,バンディット学習,0.8,10,"[{'word': 'バンディット学習', 'ratio': 0.8}, {'word': '盗賊の学習', 'ratio': 0.2}]",バンディット学習
818,938,bandwidth parameter,帯域幅パラメータ,0.5555555555555556,9,"[{'word': '帯域幅パラメータ', 'ratio': 0.5555555555555556}, {'word': 'バンド幅パラメータ', 'ratio': 0.4444444444444444}]",帯域幅パラメータ
819,939,bart-base,"""bart-base""",0.0,9,"[{'word': 'バートベース', 'ratio': 0.6666666666666666}, {'word': 'bart-base', 'ratio': 0.3333333333333333}]",バートベース
820,940,bart-large,bart-large,0.3333333333333333,9,"[{'word': 'バート大', 'ratio': 0.5555555555555556}, {'word': 'bart-large', 'ratio': 0.3333333333333333}, {'word': 'バート', 'ratio': 0.1111111111111111}]",バート大
821,946,baseline algorithm,ベースラインアルゴリズム,1.0,10,"[{'word': 'ベースラインアルゴリズム', 'ratio': 1.0}]",ベースラインアルゴリズム
822,947,baseline method,ベースライン手法,0.7,10,"[{'word': 'ベースライン手法', 'ratio': 0.7}, {'word': 'ベースラインメソッド', 'ratio': 0.2}, {'word': 'ベースライン法', 'ratio': 0.1}]",ベースライン手法
823,948,baseline model,ベースラインモデル,0.8888888888888888,9,"[{'word': 'ベースラインモデル', 'ratio': 0.8888888888888888}, {'word': '基準モデル', 'ratio': 0.1111111111111111}]",ベースラインモデル
824,949,baseline parser,ベースラインパーサー,0.6666666666666666,9,"[{'word': 'ベースラインパーサー', 'ratio': 0.6666666666666666}, {'word': 'ベースラインパーサ', 'ratio': 0.2222222222222222}, {'word': '基準パーサー', 'ratio': 0.1111111111111111}]",ベースラインパーサー
825,950,baseline policy,ベースラインポリシー,0.6666666666666666,9,"[{'word': 'ベースラインポリシー', 'ratio': 0.6666666666666666}, {'word': '基本方針', 'ratio': 0.2222222222222222}, {'word': '基準ポリシー', 'ratio': 0.1111111111111111}]",ベースラインポリシー
826,951,baseline system,ベースラインシステム,0.8888888888888888,9,"[{'word': 'ベースラインシステム', 'ratio': 0.8888888888888888}, {'word': '基準システム', 'ratio': 0.1111111111111111}]",ベースラインシステム
827,952,basis function,基底関数,1.0,10,"[{'word': '基底関数', 'ratio': 1.0}]",基底関数
828,953,basis vector,ベーシスベクトル,0.0,10,"[{'word': '基底ベクトル', 'ratio': 1.0}]",基底ベクトル
829,954,batch algorithm,バッチアルゴリズム,0.9,10,"[{'word': 'バッチアルゴリズム', 'ratio': 0.9}, {'word': 'バッチ アルゴリズム', 'ratio': 0.1}]",バッチアルゴリズム
830,955,batch dimension,バッチ次元,0.8,10,"[{'word': 'バッチ次元', 'ratio': 0.8}, {'word': 'バッチ寸法', 'ratio': 0.1}, {'word': 'バッチディメンション', 'ratio': 0.1}]",バッチ次元
831,956,batch element,バッチ要素,0.9,10,"[{'word': 'バッチ要素', 'ratio': 0.9}, {'word': 'バッチ要素  Copy', 'ratio': 0.1}]",バッチ要素
832,957,batch learning,バッチ学習,1.0,10,"[{'word': 'バッチ学習', 'ratio': 1.0}]",バッチ学習
833,958,batch mode,バッチモード,0.9,10,"[{'word': 'バッチモード', 'ratio': 0.9}, {'word': '一括モード', 'ratio': 0.1}]",バッチモード
834,959,batch optimization,バッチ最適化,0.9,10,"[{'word': 'バッチ最適化', 'ratio': 0.9}, {'word': 'バッチの最適化', 'ratio': 0.1}]",バッチ最適化
835,960,batch processing,バッチ処理,1.0,10,"[{'word': 'バッチ処理', 'ratio': 1.0}]",バッチ処理
836,961,batch setting,バッチ設定,0.8,10,"[{'word': 'バッチ設定', 'ratio': 0.8}, {'word': '一括設定', 'ratio': 0.2}]",バッチ設定
837,962,batch training,バッチトレーニング,1.0,10,"[{'word': 'バッチトレーニング', 'ratio': 1.0}]",バッチトレーニング
838,963,beam search algorithm,ビームサーチアルゴリズム,0.8,10,"[{'word': 'ビームサーチアルゴリズム', 'ratio': 0.8}, {'word': 'ビーム探索アルゴリズム', 'ratio': 0.2}]",ビームサーチアルゴリズム
839,964,beam search decoding,ビーム探索デコーディング,0.0,10,"[{'word': 'ビームサーチデコーディング', 'ratio': 1.0}]",ビームサーチデコーディング
840,965,beam search decoding algorithm,ビームサーチデコーディングアルゴリズム,0.9,10,"[{'word': 'ビームサーチデコーディングアルゴリズム', 'ratio': 0.9}, {'word': 'ビームサーチデコードアルゴリズム', 'ratio': 0.1}]",ビームサーチデコーディングアルゴリズム
841,966,beam size,ビームサイズ,1.0,10,"[{'word': 'ビームサイズ', 'ratio': 1.0}]",ビームサイズ
842,967,beam width,ビーム幅,1.0,10,"[{'word': 'ビーム幅', 'ratio': 1.0}]",ビーム幅
843,968,behavior cloning,行動クローニング,0.2,10,"[{'word': '行動クローン', 'ratio': 0.8}, {'word': '行動クローニング', 'ratio': 0.2}]",行動クローン
844,969,behavior policy,振る舞いポリシー,0.0,10,"[{'word': '行動方針', 'ratio': 0.6}, {'word': '行動ポリシー', 'ratio': 0.3}, {'word': '行動方策', 'ratio': 0.1}]",行動方針
845,970,belief state,信念状態,0.8,10,"[{'word': '信念状態', 'ratio': 0.8}, {'word': '信仰状態', 'ratio': 0.2}]",信念状態
846,971,benchmark,ベンチマーク,1.0,10,"[{'word': 'ベンチマーク', 'ratio': 1.0}]",ベンチマーク
847,972,benchmark dataset,ベンチマークデータセット,0.7777777777777778,9,"[{'word': 'ベンチマークデータセット', 'ratio': 0.7777777777777778}, {'word': 'ベンチマーク・データセット', 'ratio': 0.2222222222222222}]",ベンチマークデータセット
848,973,benchmark task,ベンチマークタスク,1.0,9,"[{'word': 'ベンチマークタスク', 'ratio': 1.0}]",ベンチマークタスク
849,974,best-first search,優良優先探索,0.0,9,"[{'word': '最良優先探索', 'ratio': 0.5555555555555556}, {'word': 'ベストファースト探索', 'ratio': 0.2222222222222222}, {'word': 'ベスト・ファースト・サーチ', 'ratio': 0.2222222222222222}]",最良優先探索
850,975,best-first search algorithm,良い最初の探索アルゴリズム,0.0,9,"[{'word': '最良優先探索アルゴリズム', 'ratio': 0.5555555555555556}, {'word': 'ベストファースト探索アルゴリズム', 'ratio': 0.2222222222222222}, {'word': '最優先探索アルゴリズム', 'ratio': 0.2222222222222222}]",最良優先探索アルゴリズム
851,976,beta1,ベータ1,0.8888888888888888,9,"[{'word': 'ベータ1', 'ratio': 0.8888888888888888}, {'word': 'beta1', 'ratio': 0.1111111111111111}]",ベータ1
852,977,between-class variance,クラス間分散,0.8,10,"[{'word': 'クラス間分散', 'ratio': 0.8}, {'word': 'クラス間の差異', 'ratio': 0.1}, {'word': 'Kaihyō Kyōjaku Fushō', 'ratio': 0.1}]",クラス間分散
853,979,bi-gram,バイグラム,0.9,10,"[{'word': 'バイグラム', 'ratio': 0.9}, {'word': 'Bi-Guramu', 'ratio': 0.1}]",バイグラム
854,981,bias,バイアス,0.9,10,"[{'word': 'バイアス', 'ratio': 0.9}, {'word': 'Heiasei', 'ratio': 0.1}]",バイアス
855,983,bias parameter,バイアスパラメータ,0.8,10,"[{'word': 'バイアスパラメータ', 'ratio': 0.8}, {'word': 'バイアス・パラメータ', 'ratio': 0.1}, {'word': 'バイアスパラメーター', 'ratio': 0.1}]",バイアスパラメータ
856,984,bias term,バイアス項,0.6,10,"[{'word': 'バイアス項', 'ratio': 0.6}, {'word': 'バイアステーム', 'ratio': 0.2}, {'word': 'バイアス用語', 'ratio': 0.1}, {'word': 'バイアステルム', 'ratio': 0.1}]",バイアス項
857,985,bias vector,バイアスベクトル,1.0,10,"[{'word': 'バイアスベクトル', 'ratio': 1.0}]",バイアスベクトル
858,989,bicubic interpolation,双三次補間,0.0,9,"[{'word': 'バイキュービック補間', 'ratio': 1.0}]",バイキュービック補間
859,990,bidirectional,双方向性,0.4444444444444444,18,"[{'word': '双方向', 'ratio': 0.9444444444444444}, {'word': 'Bidirectional', 'ratio': 0.05555555555555555}]",双方向
860,991,bidirectional Transformer,双方向Transformer,0.0,9,"[{'word': '双方向トランスフォーマー', 'ratio': 0.6666666666666666}, {'word': '双方向トランス', 'ratio': 0.2222222222222222}, {'word': 'Bidirectional トランスフォーマー', 'ratio': 0.1111111111111111}]",双方向トランスフォーマー
861,992,bidirectional encoder,双方向エンコーダ,0.5555555555555556,9,"[{'word': '双方向エンコーダ', 'ratio': 0.5555555555555556}, {'word': '双方向エンコーダー', 'ratio': 0.3333333333333333}, {'word': 'Bidirectional エンコーダー', 'ratio': 0.1111111111111111}]",双方向エンコーダ
862,993,bidirectional heuristic search,双方向ヒューリスティック探索,0.6666666666666666,9,"[{'word': '双方向ヒューリスティック探索', 'ratio': 0.6666666666666666}, {'word': '双方向ヒューリスティック検索', 'ratio': 0.1111111111111111}, {'word': 'bidirectional heuristic search', 'ratio': 0.1111111111111111}, {'word': 'Bidirectional ヒューリスティック検索', 'ratio': 0.1111111111111111}]",双方向ヒューリスティック探索
863,994,bidirectional model,双方向モデル,0.8888888888888888,9,"[{'word': '双方向モデル', 'ratio': 0.8888888888888888}, {'word': 'Bidirectional モデル', 'ratio': 0.1111111111111111}]",双方向モデル
864,995,bidirectional search,双方向探索,0.7777777777777778,9,"[{'word': '双方向探索', 'ratio': 0.7777777777777778}, {'word': '双方向検索', 'ratio': 0.2222222222222222}]",双方向探索
865,996,bidirectionality,双方向性,0.8888888888888888,9,"[{'word': '双方向性', 'ratio': 0.8888888888888888}, {'word': '双方向', 'ratio': 0.1111111111111111}]",双方向性
866,997,big-O notation,ビッグオー表記,0.2222222222222222,9,"[{'word': 'ビッグオー記法', 'ratio': 0.7777777777777778}, {'word': 'ビッグオー表記', 'ratio': 0.2222222222222222}]",ビッグオー記法
867,999,bigram language model,バイグラム言語モデル,0.6666666666666666,9,"[{'word': 'バイグラム言語モデル', 'ratio': 0.6666666666666666}, {'word': 'ビグラム言語モデル', 'ratio': 0.3333333333333333}]",バイグラム言語モデル
868,1000,bijective function,全単射関数,0.6,10,"[{'word': '全単射関数', 'ratio': 0.6}, {'word': '射影関数', 'ratio': 0.1}, {'word': 'Ichi-to-Ichi Kanryō Hōshoku', 'ratio': 0.1}, {'word': '一対一対応関数', 'ratio': 0.1}, {'word': '双射関数', 'ratio': 0.1}]",全単射関数
869,1001,bijective mapping,全単射写像,0.5,10,"[{'word': '全単射写像', 'ratio': 0.5}, {'word': '両射影写像', 'ratio': 0.1}, {'word': '全単射マッピング', 'ratio': 0.1}, {'word': 'Ichi-to-Ichi Kanryō Hōtei', 'ratio': 0.1}, {'word': '一対一対応写像', 'ratio': 0.1}, {'word': '双射写像', 'ratio': 0.1}]",全単射写像
870,1003,bilinear,双線形,0.3,10,"[{'word': 'バイリニア', 'ratio': 0.5}, {'word': '双線形', 'ratio': 0.3}, {'word': '双線型', 'ratio': 0.1}, {'word': 'Baireinaru', 'ratio': 0.1}]",バイリニア
871,1004,bilinear form,双一次形式,0.1,10,"[{'word': 'バイリニア形式', 'ratio': 0.5}, {'word': '双線形形式', 'ratio': 0.3}, {'word': '双一次形式', 'ratio': 0.1}, {'word': 'Baireinaru Fōmu', 'ratio': 0.1}]",バイリニア形式
872,1005,bilinear interpolation,バイリニア補間,0.6666666666666666,9,"[{'word': 'バイリニア補間', 'ratio': 0.6666666666666666}, {'word': '二次元補間', 'ratio': 0.1111111111111111}, {'word': '線形補間', 'ratio': 0.1111111111111111}, {'word': '双線形補間', 'ratio': 0.1111111111111111}]",バイリニア補間
873,1006,bilinear model,バイリニアモデル,0.6666666666666666,9,"[{'word': 'バイリニアモデル', 'ratio': 0.6666666666666666}, {'word': '二次モデル', 'ratio': 0.1111111111111111}, {'word': '線形モデル', 'ratio': 0.1111111111111111}, {'word': '双線形モデル', 'ratio': 0.1111111111111111}]",バイリニアモデル
874,1007,bilingual model,双言語モデル,0.1111111111111111,9,"[{'word': 'バイリンガルモデル', 'ratio': 0.8888888888888888}, {'word': '双言語モデル', 'ratio': 0.1111111111111111}]",バイリンガルモデル
875,1008,binarization,二値化,0.5555555555555556,9,"[{'word': '二値化', 'ratio': 0.5555555555555556}, {'word': 'バイナリゼーション', 'ratio': 0.3333333333333333}, {'word': 'ビナリゼーション', 'ratio': 0.1111111111111111}]",二値化
876,1010,binary classification,二値分類 (nibun bunrui),0.0,10,"[{'word': 'バイナリ分類', 'ratio': 0.6}, {'word': '二項分類', 'ratio': 0.3}, {'word': '二値分類', 'ratio': 0.1}]",バイナリ分類
877,1011,binary classification head,バイナリ分類ヘッド,0.6,10,"[{'word': 'バイナリ分類ヘッド', 'ratio': 0.6}, {'word': '二項分類ヘッド', 'ratio': 0.3}, {'word': '二値分類ヘッド', 'ratio': 0.1}]",バイナリ分類ヘッド
878,1012,binary classification problem,二項分類問題,0.3,10,"[{'word': 'バイナリ分類問題', 'ratio': 0.5}, {'word': '二項分類問題', 'ratio': 0.3}, {'word': 'にしんぶんるいもんだい', 'ratio': 0.1}, {'word': '二値分類問題', 'ratio': 0.1}]",バイナリ分類問題
879,1013,binary classification task,二項分類タスク,0.3,10,"[{'word': 'バイナリ分類タスク', 'ratio': 0.6}, {'word': '二項分類タスク', 'ratio': 0.3}, {'word': '二値分類タスク', 'ratio': 0.1}]",バイナリ分類タスク
880,1014,binary classifier,2値分類器,0.0,9,"[{'word': 'バイナリ分類器', 'ratio': 0.6666666666666666}, {'word': 'バイナリ分類子', 'ratio': 0.1111111111111111}, {'word': 'バイナリ分類器放射ベクトル', 'ratio': 0.1111111111111111}, {'word': '値分類器', 'ratio': 0.1111111111111111}]",バイナリ分類器
881,1015,binary constraint,2値制約,0.0,9,"[{'word': 'バイナリ制約', 'ratio': 0.8888888888888888}, {'word': '値制約', 'ratio': 0.1111111111111111}]",バイナリ制約
882,1016,binary cross entropy,2値クロスエントロピー,0.0,9,"[{'word': 'バイナリ交差エントロピー', 'ratio': 0.6666666666666666}, {'word': 'バイナリクロスエントロピー', 'ratio': 0.2222222222222222}, {'word': '値クロスエントロピ', 'ratio': 0.1111111111111111}]",バイナリ交差エントロピー
883,1017,binary cross-entropy loss,バイナリクロスエントロピー損失,0.2222222222222222,9,"[{'word': 'バイナリ交差エントロピー損失', 'ratio': 0.6666666666666666}, {'word': 'バイナリクロスエントロピー損失', 'ratio': 0.2222222222222222}, {'word': '値クロスエントロピー損失', 'ratio': 0.1111111111111111}]",バイナリ交差エントロピー損失
884,1018,binary decision tree,バイナリ決定木,0.6666666666666666,9,"[{'word': 'バイナリ決定木', 'ratio': 0.6666666666666666}, {'word': '二分決定木', 'ratio': 0.2222222222222222}, {'word': '値決定木', 'ratio': 0.1111111111111111}]",バイナリ決定木
885,1019,binary feature,2値特徴,0.0,10,"[{'word': 'バイナリ特徴', 'ratio': 0.7}, {'word': 'バイナリ機能', 'ratio': 0.2}, {'word': 'バイナリ特徴量', 'ratio': 0.1}]",バイナリ特徴
886,1020,binary label,2値ラベル,0.0,10,"[{'word': 'バイナリラベル', 'ratio': 1.0}]",バイナリラベル
887,1021,binary matrix,2値行列,0.0,10,"[{'word': 'バイナリ行列', 'ratio': 0.9}, {'word': 'バイナリマトリックス', 'ratio': 0.1}]",バイナリ行列
888,1022,binary predicate,二項述語,0.1,10,"[{'word': 'バイナリ述語', 'ratio': 0.9}, {'word': '二項述語', 'ratio': 0.1}]",バイナリ述語
889,1023,binary relation,二項関係,0.2,10,"[{'word': 'バイナリ関係', 'ratio': 0.8}, {'word': '二項関係', 'ratio': 0.2}]",バイナリ関係
890,1024,binary search,二分探索,0.6,10,"[{'word': '二分探索', 'ratio': 0.6}, {'word': 'バイナリサーチ', 'ratio': 0.3}, {'word': 'バイナリーセarch', 'ratio': 0.1}]",二分探索
891,1025,binary segmentation,二値セグメンテーション,0.5,10,"[{'word': '二値セグメンテーション', 'ratio': 0.5}, {'word': 'バイナリセグメンテーション', 'ratio': 0.3}, {'word': 'バイナリーセグメンテーション', 'ratio': 0.1}, {'word': '二値セグメンテーショ', 'ratio': 0.1}]",二値セグメンテーション
892,1026,binary tree,二分木,0.6,10,"[{'word': '二分木', 'ratio': 0.6}, {'word': '二進木', 'ratio': 0.2}, {'word': 'バイナリツリー', 'ratio': 0.1}, {'word': 'バイナリーツリー', 'ratio': 0.1}]",二分木
893,1027,binary variable,二値変数,0.5,10,"[{'word': '二値変数', 'ratio': 0.5}, {'word': 'バイナリ変数', 'ratio': 0.3}, {'word': '二分木', 'ratio': 0.1}, {'word': 'バイナリーヴァリアブル', 'ratio': 0.1}]",二値変数
894,1028,binary vector,バイナリーベクトル,0.0,10,"[{'word': '二値ベクトル', 'ratio': 0.6}, {'word': 'バイナリベクトル', 'ratio': 0.3}, {'word': 'バイナリーヴェクター', 'ratio': 0.1}]",二値ベクトル
895,1029,bioinformatic,バイオインフォマティクス,0.6666666666666666,9,"[{'word': 'バイオインフォマティクス', 'ratio': 0.6666666666666666}, {'word': 'バイオインフォマティック', 'ratio': 0.2222222222222222}, {'word': 'Baioinformatikku', 'ratio': 0.1111111111111111}]",バイオインフォマティクス
896,1032,bipartite graph,二部グラフ,0.6666666666666666,9,"[{'word': '二部グラフ', 'ratio': 0.6666666666666666}, {'word': 'にこうグラフ', 'ratio': 0.2222222222222222}, {'word': 'Bipātīto Gurafu', 'ratio': 0.1111111111111111}]",二部グラフ
897,1033,bipartite matching,二部グラフマッチング,0.0,9,"[{'word': '二部マッチング', 'ratio': 0.8888888888888888}, {'word': 'Bipātīto Matchingu', 'ratio': 0.1111111111111111}]",二部マッチング
898,1034,bipartite structure,二部構造,0.7,10,"[{'word': '二部構造', 'ratio': 0.7}, {'word': 'にれんしきこうぞう', 'ratio': 0.2}, {'word': '二部グラフ構造', 'ratio': 0.1}]",二部構造
899,1036,bisection method,二分法,1.0,10,"[{'word': '二分法', 'ratio': 1.0}]",二分法
900,1038,bitext,対訳コーパス,0.0,10,"[{'word': 'バイテキスト', 'ratio': 0.6}, {'word': 'バイトテキスト', 'ratio': 0.2}, {'word': 'ビテキスト', 'ratio': 0.1}, {'word': '対訳', 'ratio': 0.1}]",バイテキスト
901,1039,bitvector,ビットベクトル,0.3,10,"[{'word': 'ビットベクター', 'ratio': 0.6}, {'word': 'ビットベクトル', 'ratio': 0.3}, {'word': 'ビットベクタ', 'ratio': 0.1}]",ビットベクター
902,1040,black-box,ブラックボックス,1.0,10,"[{'word': 'ブラックボックス', 'ratio': 1.0}]",ブラックボックス
903,1041,black-box model,ブラックボックスモデル,1.0,10,"[{'word': 'ブラックボックスモデル', 'ratio': 1.0}]",ブラックボックスモデル
904,1042,block coordinate descent,ブロック座標降下法,0.7,10,"[{'word': 'ブロック座標降下法', 'ratio': 0.7}, {'word': 'ブロック座標降下', 'ratio': 0.3}]",ブロック座標降下法
905,1043,block matrix,ブロック行列,1.0,10,"[{'word': 'ブロック行列', 'ratio': 1.0}]",ブロック行列
906,1044,block-diagonal matrix,ブロック対角行列,1.0,9,"[{'word': 'ブロック対角行列', 'ratio': 1.0}]",ブロック対角行列
907,1045,blur kernel,ぼけカーネル,0.0,9,"[{'word': 'ブラーカーネル', 'ratio': 0.5555555555555556}, {'word': 'ぼかしカーネル', 'ratio': 0.2222222222222222}, {'word': 'ブラー核', 'ratio': 0.1111111111111111}, {'word': 'ブルーケルン', 'ratio': 0.1111111111111111}]",ブラーカーネル
908,1046,boosting algorithm,強化アルゴリズム,0.0,9,"[{'word': 'ブースティングアルゴリズム', 'ratio': 0.8888888888888888}, {'word': 'ブースティング・アルゴリズム', 'ratio': 0.1111111111111111}]",ブースティングアルゴリズム
909,1047,boosting approach,勾配ブースト法,0.0,9,"[{'word': 'ブースティングアプローチ', 'ratio': 0.6666666666666666}, {'word': 'ブースト・アプローチ', 'ratio': 0.1111111111111111}, {'word': 'ブーストアプローチ', 'ratio': 0.1111111111111111}, {'word': 'ブースティング手法', 'ratio': 0.1111111111111111}]",ブースティングアプローチ
910,1048,bootstrap learning,ブートストラップ学習,1.0,9,"[{'word': 'ブートストラップ学習', 'ratio': 1.0}]",ブートストラップ学習
911,1050,bootstrap sample,ブートストラップサンプル,0.7777777777777778,9,"[{'word': 'ブートストラップサンプル', 'ratio': 0.7777777777777778}, {'word': 'ブートストラップ標本', 'ratio': 0.2222222222222222}]",ブートストラップサンプル
912,1051,bottleneck,ボトルネック,1.0,9,"[{'word': 'ボトルネック', 'ratio': 1.0}]",ボトルネック
913,1052,bottleneck layer,ボトルネック層,1.0,9,"[{'word': 'ボトルネック層', 'ratio': 1.0}]",ボトルネック層
914,1053,bottom-up,下位から上への,0.0,9,"[{'word': 'ボトムアップ', 'ratio': 1.0}]",ボトムアップ
915,1054,bottom-up learning,下位から上への学習,0.0,9,"[{'word': 'ボトムアップ学習', 'ratio': 1.0}]",ボトムアップ学習
916,1055,bottom-up module,下位モジュール,0.0,9,"[{'word': 'ボトムアップモジュール', 'ratio': 1.0}]",ボトムアップモジュール
917,1056,bottom-up parsing,ボトムアップ構文解析,0.5555555555555556,9,"[{'word': 'ボトムアップ構文解析', 'ratio': 0.5555555555555556}, {'word': 'ボトムアップ解析', 'ratio': 0.2222222222222222}, {'word': 'ボトムアップパーシング', 'ratio': 0.1111111111111111}, {'word': 'ボトムアップパース', 'ratio': 0.1111111111111111}]",ボトムアップ構文解析
918,1059,bounding box,境界ボックス,0.1,10,"[{'word': 'バウンディングボックス', 'ratio': 0.8}, {'word': '境界ボックス', 'ratio': 0.1}, {'word': 'ボウンディングボックス', 'ratio': 0.1}]",バウンディングボックス
919,1060,bounding box detection,バウンディングボックス検出,0.8,10,"[{'word': 'バウンディングボックス検出', 'ratio': 0.8}, {'word': '境界ボックスの検出', 'ratio': 0.1}, {'word': 'ボウンディングボックス検出', 'ratio': 0.1}]",バウンディングボックス検出
920,1061,bounding box regression,境界ボックス回帰,0.1,10,"[{'word': 'バウンディングボックス回帰', 'ratio': 0.7}, {'word': 'バウンディングボックス検出', 'ratio': 0.1}, {'word': '境界ボックス回帰', 'ratio': 0.1}, {'word': 'ボウンディングボックス回帰', 'ratio': 0.1}]",バウンディングボックス回帰
921,1062,bounding box regressor,バウンディングボックス回帰器,0.8,10,"[{'word': 'バウンディングボックス回帰器', 'ratio': 0.8}, {'word': '境界ボックスリグレッサー', 'ratio': 0.1}, {'word': 'ボウンディングボックス回帰器', 'ratio': 0.1}]",バウンディングボックス回帰器
922,1064,branching factor,分岐因子,0.2222222222222222,9,"[{'word': '分岐係数', 'ratio': 0.7777777777777778}, {'word': '分岐因子', 'ratio': 0.2222222222222222}]",分岐係数
923,1065,breadth-first order,幅優先順,0.1111111111111111,9,"[{'word': '幅優先順序', 'ratio': 0.7777777777777778}, {'word': '幅優先順位', 'ratio': 0.1111111111111111}, {'word': '幅優先順', 'ratio': 0.1111111111111111}]",幅優先順序
924,1066,breadth-first search,幅優先探索,0.8888888888888888,9,"[{'word': '幅優先探索', 'ratio': 0.8888888888888888}, {'word': '幅優先検索', 'ratio': 0.1111111111111111}]",幅優先探索
925,1068,burn-in,バーンイン,0.8888888888888888,9,"[{'word': 'バーンイン', 'ratio': 0.8888888888888888}, {'word': '焼き付き', 'ratio': 0.1111111111111111}]",バーンイン
926,1069,calculus of variation,変分法,0.8888888888888888,9,"[{'word': '変分法', 'ratio': 0.8888888888888888}, {'word': '方程変分法', 'ratio': 0.1111111111111111}]",変分法
927,1070,calibration,校正,0.1111111111111111,9,"[{'word': 'キャリブレーション', 'ratio': 0.5555555555555556}, {'word': '較正', 'ratio': 0.2222222222222222}, {'word': 'カリブレーション', 'ratio': 0.1111111111111111}, {'word': '校正', 'ratio': 0.1111111111111111}]",キャリブレーション
928,1072,camera calibration,カメラキャリブレーション,0.6666666666666666,9,"[{'word': 'カメラキャリブレーション', 'ratio': 0.6666666666666666}, {'word': 'カメラのキャリブレーション', 'ratio': 0.2222222222222222}, {'word': 'カメラカリブレーション', 'ratio': 0.1111111111111111}]",カメラキャリブレーション
929,1073,camera intrinsic,カメラ内部パラメータ,0.5555555555555556,9,"[{'word': 'カメラ内部パラメータ', 'ratio': 0.5555555555555556}, {'word': 'カメラ固有の', 'ratio': 0.2222222222222222}, {'word': 'カメライントリンシック', 'ratio': 0.1111111111111111}, {'word': 'カメラ内部パラメーター', 'ratio': 0.1111111111111111}]",カメラ内部パラメータ
930,1074,camera matrix,カメラ行列,0.7777777777777778,9,"[{'word': 'カメラ行列', 'ratio': 0.7777777777777778}, {'word': 'カメラマトリックス', 'ratio': 0.2222222222222222}]",カメラ行列
931,1075,camera parameter,カメラパラメータ,0.8888888888888888,9,"[{'word': 'カメラパラメータ', 'ratio': 0.8888888888888888}, {'word': 'カメラパラメーター', 'ratio': 0.1111111111111111}]",カメラパラメータ
932,1076,camera pose estimation,カメラの姿勢推定,0.1111111111111111,9,"[{'word': 'カメラポーズ推定', 'ratio': 0.7777777777777778}, {'word': 'カメラの姿勢推定', 'ratio': 0.1111111111111111}, {'word': 'カメラ姿勢推定', 'ratio': 0.1111111111111111}]",カメラポーズ推定
933,1077,candidate generation,候補生成,0.7777777777777778,9,"[{'word': '候補生成', 'ratio': 0.7777777777777778}, {'word': '候補世代', 'ratio': 0.1111111111111111}, {'word': '候補者の世代', 'ratio': 0.1111111111111111}]",候補生成
934,1078,candidate set,候補セット,0.7777777777777778,9,"[{'word': '候補セット', 'ratio': 0.7777777777777778}, {'word': '候補集合', 'ratio': 0.2222222222222222}]",候補セット
935,1079,canonical basis,正準基底,0.0,9,"[{'word': '標準基底', 'ratio': 0.7777777777777778}, {'word': '基準', 'ratio': 0.2222222222222222}]",標準基底
936,1080,canonical correlation analysis,正準相関分析,0.3333333333333333,9,"[{'word': '標準相関分析', 'ratio': 0.6666666666666666}, {'word': '正準相関分析', 'ratio': 0.3333333333333333}]",標準相関分析
937,1081,canonical form,正規形,0.0,9,"[{'word': '標準形', 'ratio': 0.6666666666666666}, {'word': '基準形', 'ratio': 0.2222222222222222}, {'word': '正準形', 'ratio': 0.1111111111111111}]",標準形
938,1082,canonical frame,正準フレーム,0.1111111111111111,9,"[{'word': '標準フレーム', 'ratio': 0.6666666666666666}, {'word': '基準形', 'ratio': 0.1111111111111111}, {'word': 'カノニカルフレーム', 'ratio': 0.1111111111111111}, {'word': '正準フレーム', 'ratio': 0.1111111111111111}]",標準フレーム
939,1083,canonical space,カノニカル空間,0.0,9,"[{'word': '標準空間', 'ratio': 0.6666666666666666}, {'word': '正準空間', 'ratio': 0.3333333333333333}]",標準空間
940,1084,canonicalization,正準化,0.2,10,"[{'word': '標準化', 'ratio': 0.5}, {'word': '正準化', 'ratio': 0.2}, {'word': '正規化', 'ratio': 0.2}, {'word': 'Shinchō Kanzen-ka', 'ratio': 0.1}]",標準化
941,1085,capsule network,カプセルネットワーク,0.9,10,"[{'word': 'カプセルネットワーク', 'ratio': 0.9}, {'word': 'Kappusu Nettowaku', 'ratio': 0.1}]",カプセルネットワーク
942,1087,cardinality constraint,基数制約,0.4,10,"[{'word': 'カーディナリティ制約', 'ratio': 0.5}, {'word': '基数制約', 'ratio': 0.4}, {'word': 'Kōdai-teki Jōkei-ryoku Shūen', 'ratio': 0.1}]",カーディナリティ制約
943,1088,cascade model,連鎖モデル,0.0,10,"[{'word': 'カスケードモデル', 'ratio': 1.0}]",カスケードモデル
944,1089,catastrophic forgetting,壊滅的な忘却,0.1,10,"[{'word': '壊滅的忘却', 'ratio': 0.5}, {'word': '破滅的忘却', 'ratio': 0.1}, {'word': 'カタストロフィックフォゲッティング', 'ratio': 0.1}, {'word': '壊滅的な忘却', 'ratio': 0.1}, {'word': '突然の忘却', 'ratio': 0.1}, {'word': '猛烈な忘却', 'ratio': 0.1}]",壊滅的忘却
945,1090,categorial grammar,範疇文法,0.1,10,"[{'word': 'カテゴリカル文法', 'ratio': 0.5}, {'word': '類型文法', 'ratio': 0.2}, {'word': 'カテゴリ文法', 'ratio': 0.1}, {'word': '範疇文法', 'ratio': 0.1}, {'word': 'カテゴリアル文法', 'ratio': 0.1}]",カテゴリカル文法
946,1091,categorical cross-entropy,カテゴリカル交差エントロピー,0.7,10,"[{'word': 'カテゴリカル交差エントロピー', 'ratio': 0.7}, {'word': 'カテゴリカルクロスエントロピー', 'ratio': 0.3}]",カテゴリカル交差エントロピー
947,1092,categorical feature,カテゴリ変数,0.0,10,"[{'word': 'カテゴリカル特徴', 'ratio': 0.9}, {'word': 'カテゴリ特徴', 'ratio': 0.1}]",カテゴリカル特徴
948,1093,causal effect,因果効果,0.7777777777777778,9,"[{'word': '因果効果', 'ratio': 0.7777777777777778}, {'word': 'げんいんこうか', 'ratio': 0.1111111111111111}, {'word': '因果関係', 'ratio': 0.1111111111111111}]",因果効果
949,1094,causal effect estimation,因果効果推定,0.7777777777777778,9,"[{'word': '因果効果推定', 'ratio': 0.7777777777777778}, {'word': '因果効果の推定', 'ratio': 0.1111111111111111}, {'word': '因果関係の推定', 'ratio': 0.1111111111111111}]",因果効果推定
950,1095,causal entropy,因果エントロピー,0.8888888888888888,9,"[{'word': '因果エントロピー', 'ratio': 0.8888888888888888}, {'word': '因果的エントロピー', 'ratio': 0.1111111111111111}]",因果エントロピー
951,1096,causal graph,因果関係グラフ,0.1111111111111111,9,"[{'word': '因果グラフ', 'ratio': 0.8888888888888888}, {'word': '因果関係グラフ', 'ratio': 0.1111111111111111}]",因果グラフ
952,1097,causal inference,因果推論,1.0,9,"[{'word': '因果推論', 'ratio': 1.0}]",因果推論
953,1098,causal intervention,因果介入,0.5555555555555556,9,"[{'word': '因果介入', 'ratio': 0.5555555555555556}, {'word': '因果的介入', 'ratio': 0.4444444444444444}]",因果介入
954,1099,causal language model,因果言語モデル,1.0,9,"[{'word': '因果言語モデル', 'ratio': 1.0}]",因果言語モデル
955,1100,causal model,因果モデル,1.0,9,"[{'word': '因果モデル', 'ratio': 1.0}]",因果モデル
956,1101,causal reasoning,因果推論,1.0,9,"[{'word': '因果推論', 'ratio': 1.0}]",因果推論
957,1102,causal rule,因果的なルール,0.0,9,"[{'word': '因果ルール', 'ratio': 0.7777777777777778}, {'word': '因果律', 'ratio': 0.2222222222222222}]",因果ルール
958,1103,causal theory,因果理論,0.7777777777777778,9,"[{'word': '因果理論', 'ratio': 0.7777777777777778}, {'word': '因果論', 'ratio': 0.2222222222222222}]",因果理論
959,1104,cell state,セル状態,0.7777777777777778,9,"[{'word': 'セル状態', 'ratio': 0.7777777777777778}, {'word': 'セルステート', 'ratio': 0.2222222222222222}]",セル状態
960,1106,center of projection,射影中心,0.0,9,"[{'word': '投影中心', 'ratio': 0.8888888888888888}, {'word': '投影中心中心性測定', 'ratio': 0.1111111111111111}]",投影中心
961,1107,centrality measure,中心性尺度,0.1111111111111111,9,"[{'word': '中心性測定', 'ratio': 0.5555555555555556}, {'word': '中心性の尺度', 'ratio': 0.2222222222222222}, {'word': '中心性尺度', 'ratio': 0.1111111111111111}, {'word': '中心性指標', 'ratio': 0.1111111111111111}]",中心性測定
962,1108,centroid,重心,0.3,10,"[{'word': 'セントロイド', 'ratio': 0.7}, {'word': '重心', 'ratio': 0.3}]",セントロイド
963,1109,chain rule,連鎖法則,0.0,10,"[{'word': '連鎖律', 'ratio': 0.5}, {'word': 'チェーンルール', 'ratio': 0.4}, {'word': '連鎖ルール', 'ratio': 0.1}]",連鎖律
964,1110,change of basis,基底の変換,0.2,10,"[{'word': '基底の変更', 'ratio': 0.5}, {'word': '基底の変換', 'ratio': 0.2}, {'word': '根拠変更', 'ratio': 0.1}, {'word': '根拠の変更', 'ratio': 0.1}, {'word': '基底変換', 'ratio': 0.1}]",基底の変更
965,1111,character embedding,文字埋め込み,0.7,10,"[{'word': '文字埋め込み', 'ratio': 0.7}, {'word': 'キャラクター埋め込み', 'ratio': 0.2}, {'word': '文字の埋め込み', 'ratio': 0.1}]",文字埋め込み
966,1112,character n-gram,文字n-gram,0.1,10,"[{'word': '文字n-グラム', 'ratio': 0.6}, {'word': 'キャラクターn-グラム', 'ratio': 0.2}, {'word': '文字Nグラム', 'ratio': 0.1}, {'word': '文字n-gram', 'ratio': 0.1}]",文字n-グラム
967,1113,characteristic function,特性関数,0.6666666666666666,9,"[{'word': '特性関数', 'ratio': 0.6666666666666666}, {'word': '特徴関数', 'ratio': 0.2222222222222222}, {'word': '特徴的な機能', 'ratio': 0.1111111111111111}]",特性関数
968,1114,characteristic polynomial,固有多項式,0.0,9,"[{'word': '特性多項式', 'ratio': 0.8888888888888888}, {'word': '特徴多項式', 'ratio': 0.1111111111111111}]",特性多項式
969,1115,characteristic vector,特性ベクトル,0.6666666666666666,9,"[{'word': '特性ベクトル', 'ratio': 0.6666666666666666}, {'word': '固有ベクトル', 'ratio': 0.2222222222222222}, {'word': '特徴ベクトル', 'ratio': 0.1111111111111111}]",特性ベクトル
970,1116,chart parser,チャートパーサー,0.8888888888888888,9,"[{'word': 'チャートパーサー', 'ratio': 0.8888888888888888}, {'word': 'チャート解析器', 'ratio': 0.1111111111111111}]",チャートパーサー
971,1117,chart parsing,チャート解析,0.5555555555555556,9,"[{'word': 'チャート解析', 'ratio': 0.5555555555555556}, {'word': 'チャートパーシング', 'ratio': 0.2222222222222222}, {'word': 'チャート構文解析', 'ratio': 0.1111111111111111}, {'word': 'チャートの解析', 'ratio': 0.1111111111111111}]",チャート解析
972,1118,chatbot,チャットボット,1.0,10,"[{'word': 'チャットボット', 'ratio': 1.0}]",チャットボット
973,1119,checkpoint,チェックポイント,0.7,10,"[{'word': 'チェックポイント', 'ratio': 0.7}, {'word': '検問所', 'ratio': 0.2}, {'word': 'チャットボット', 'ratio': 0.1}]",チェックポイント
974,1120,chemoinformatic,化学情報学,0.0,10,"[{'word': 'ケモインフォマティクス', 'ratio': 0.8}, {'word': 'ケモインフォマティック', 'ratio': 0.2}]",ケモインフォマティクス
975,1121,chi-square distribution,カイ二乗分布,0.9,10,"[{'word': 'カイ二乗分布', 'ratio': 0.9}, {'word': 'カイー二乗分布', 'ratio': 0.1}]",カイ二乗分布
976,1122,chi-square test,カイ二乗検定,0.8,10,"[{'word': 'カイ二乗検定', 'ratio': 0.8}, {'word': '二乗検定', 'ratio': 0.1}, {'word': 'カイー二乗検定', 'ratio': 0.1}]",カイ二乗検定
977,1123,child node,子ノード,1.0,10,"[{'word': '子ノード', 'ratio': 1.0}]",子ノード
978,1124,chromosome,染色体,0.9,10,"[{'word': '染色体', 'ratio': 0.9}, {'word': '染色体チャンクサイズ', 'ratio': 0.1}]",染色体
979,1125,chunk size,チャンクサイズ,1.0,10,"[{'word': 'チャンクサイズ', 'ratio': 1.0}]",チャンクサイズ
980,1126,citation network,引用ネットワーク,1.0,10,"[{'word': '引用ネットワーク', 'ratio': 1.0}]",引用ネットワーク
981,1127,class,クラス,1.0,10,"[{'word': 'クラス', 'ratio': 1.0}]",クラス
982,1128,class balance,クラスバランス,0.8,10,"[{'word': 'クラスバランス', 'ratio': 0.8}, {'word': 'class balance', 'ratio': 0.1}, {'word': 'クラスのバランス', 'ratio': 0.1}]",クラスバランス
983,1129,class distribution,クラス分布,0.8,10,"[{'word': 'クラス分布', 'ratio': 0.8}, {'word': 'クラスの分布', 'ratio': 0.2}]",クラス分布
984,1130,class imbalance,クラスの不均衡,0.0,10,"[{'word': 'クラス不均衡', 'ratio': 0.8}, {'word': '階級の不均衡', 'ratio': 0.2}]",クラス不均衡
985,1131,class label,クラスラベル,1.0,10,"[{'word': 'クラスラベル', 'ratio': 1.0}]",クラスラベル
986,1132,class prior,クラス事前確率,0.2,10,"[{'word': 'クラス事前分布', 'ratio': 0.6}, {'word': 'クラス事前確率', 'ratio': 0.2}, {'word': '前のクラス', 'ratio': 0.2}]",クラス事前分布
987,1133,classical planning,古典的計画,0.2,10,"[{'word': '古典計画', 'ratio': 0.6}, {'word': '古典的計画', 'ratio': 0.2}, {'word': 'classical planning', 'ratio': 0.1}, {'word': '古典的プランニング', 'ratio': 0.1}]",古典計画
988,1134,classification,分類,1.0,20,"[{'word': '分類', 'ratio': 1.0}]",分類
989,1135,classification accuracy,分類精度,1.0,10,"[{'word': '分類精度', 'ratio': 1.0}]",分類精度
990,1136,classification algorithm,分類アルゴリズム,1.0,10,"[{'word': '分類アルゴリズム', 'ratio': 1.0}]",分類アルゴリズム
991,1137,classification approach,分類アプローチ,0.9,10,"[{'word': '分類アプローチ', 'ratio': 0.9}, {'word': 'Suhshikureishon Appurōchi', 'ratio': 0.1}]",分類アプローチ
992,1138,classification error,分類誤差,0.7,10,"[{'word': '分類誤差', 'ratio': 0.7}, {'word': '分類エラー', 'ratio': 0.2}, {'word': 'Suhshikureishon Airea', 'ratio': 0.1}]",分類誤差
993,1139,classification head,分類ヘッド,0.8,10,"[{'word': '分類ヘッド', 'ratio': 0.8}, {'word': '分類責任者', 'ratio': 0.1}, {'word': 'Suhshikureishon Heddo', 'ratio': 0.1}]",分類ヘッド
994,1140,classification loss,分類損失,0.9,10,"[{'word': '分類損失', 'ratio': 0.9}, {'word': 'Suhshikureishon Rosu', 'ratio': 0.1}]",分類損失
995,1141,classification margin,分類マージン,0.9,10,"[{'word': '分類マージン', 'ratio': 0.9}, {'word': 'Suhshikureishon Mājinn', 'ratio': 0.1}]",分類マージン
996,1142,classification method,分類手法 (ぶんるいしゅほう),0.0,10,"[{'word': '分類手法', 'ratio': 0.6}, {'word': '分類方法', 'ratio': 0.4}]",分類手法
997,1143,classification metric,分類指標,0.8,10,"[{'word': '分類指標', 'ratio': 0.8}, {'word': '分類メトリック', 'ratio': 0.2}]",分類指標
998,1144,classification model,分類モデル,1.0,10,"[{'word': '分類モデル', 'ratio': 1.0}]",分類モデル
999,1145,classification network,分類ネットワーク,1.0,10,"[{'word': '分類ネットワーク', 'ratio': 1.0}]",分類ネットワーク
1000,1146,classification objective,分類目的,1.0,10,"[{'word': '分類目的', 'ratio': 1.0}]",分類目的
1001,1147,classification problem,分類問題,1.0,9,"[{'word': '分類問題', 'ratio': 1.0}]",分類問題
1002,1148,classification score,分類スコア,1.0,9,"[{'word': '分類スコア', 'ratio': 1.0}]",分類スコア
1003,1149,classification task,分類タスク,0.8888888888888888,9,"[{'word': '分類タスク', 'ratio': 0.8888888888888888}, {'word': '分類作業', 'ratio': 0.1111111111111111}]",分類タスク
1004,1150,classification token,分類トークン,1.0,9,"[{'word': '分類トークン', 'ratio': 1.0}]",分類トークン
1005,1151,clause learning,節学習,0.5,10,"[{'word': '節学習', 'ratio': 0.5}, {'word': 'クローズ学習', 'ratio': 0.3}, {'word': '文節学習', 'ratio': 0.1}, {'word': 'クロースラーニング', 'ratio': 0.1}]",節学習
1006,1152,click model,クリックモデル,0.9,10,"[{'word': 'クリックモデル', 'ratio': 0.9}, {'word': 'モデルをクリック', 'ratio': 0.1}]",クリックモデル
1007,1153,clip range,クリップ範囲,0.9,10,"[{'word': 'クリップ範囲', 'ratio': 0.9}, {'word': 'クリップレンジ', 'ratio': 0.1}]",クリップ範囲
1008,1154,clipping factor,クリッピング係数,0.5,10,"[{'word': 'クリッピング係数', 'ratio': 0.5}, {'word': 'クリッピングファクター', 'ratio': 0.3}, {'word': 'リッピングファクター', 'ratio': 0.1}, {'word': 'カメラ行列', 'ratio': 0.1}]",クリッピング係数
1009,1155,clipping threshold,切り捨て閾値,0.0,10,"[{'word': 'クリッピング閾値', 'ratio': 0.6}, {'word': 'クリッピングしきい値', 'ratio': 0.2}, {'word': 'クリップしきい値', 'ratio': 0.1}, {'word': 'カメラパラメータ', 'ratio': 0.1}]",クリッピング閾値
1010,1156,clique potential,クリークポテンシャル,0.6,10,"[{'word': 'クリークポテンシャル', 'ratio': 0.6}, {'word': '同人ポテンシャル', 'ratio': 0.1}, {'word': '派閥の可能性', 'ratio': 0.1}, {'word': 'クリッピング閾値', 'ratio': 0.1}, {'word': 'カメラポーズ推定', 'ratio': 0.1}]",クリークポテンシャル
1011,1157,closed frequent itemset,閉じた頻出アイテムセット,0.5,10,"[{'word': '閉じた頻出アイテムセット', 'ratio': 0.5}, {'word': '閉じた頻出項目集合', 'ratio': 0.1}, {'word': '閉じられた頻繁なアイテムセット', 'ratio': 0.1}, {'word': 'クロージャー頻繁なアイテムセット', 'ratio': 0.1}, {'word': '候補生成', 'ratio': 0.1}, {'word': '閉じた頻出アイテム集合', 'ratio': 0.1}]",閉じた頻出アイテムセット
1012,1158,closed-book model,クローズドブックモデル,0.7,10,"[{'word': 'クローズドブックモデル', 'ratio': 0.7}, {'word': 'クローズド・ブック・モデル', 'ratio': 0.1}, {'word': 'クロージャー頻繁なアイテムセット', 'ratio': 0.1}, {'word': '候補セット', 'ratio': 0.1}]",クローズドブックモデル
1013,1160,cloze prompt,クローズプロンプト (cloze prompt),0.0,10,"[{'word': 'クロースプロンプト', 'ratio': 0.5}, {'word': 'クローズプロンプト', 'ratio': 0.2}, {'word': 'プロンプトを閉じる', 'ratio': 0.1}, {'word': 'クローチェプロンプト', 'ratio': 0.1}, {'word': 'kuroze purontto', 'ratio': 0.1}]",クロースプロンプト
1014,1161,cloze task,"""穴埋め課題 (cloze task)""",0.0,10,"[{'word': 'クロースタスク', 'ratio': 0.5}, {'word': 'クローズタスク', 'ratio': 0.2}, {'word': 'タスクを閉じる', 'ratio': 0.1}, {'word': '小テスト', 'ratio': 0.1}, {'word': 'kuroze tasuku', 'ratio': 0.1}]",クロースタスク
1015,1162,cluster assignment,クラスター割り当て,0.2,10,"[{'word': 'クラスタ割り当て', 'ratio': 0.6}, {'word': 'クラスター割り当て', 'ratio': 0.2}, {'word': 'クラスタの割り当て', 'ratio': 0.1}, {'word': 'kurasutā sēnpu', 'ratio': 0.1}]",クラスタ割り当て
1016,1163,cluster center,クラスタ中心,0.5,10,"[{'word': 'クラスタ中心', 'ratio': 0.5}, {'word': 'クラスターセンター', 'ratio': 0.2}, {'word': 'クラスター中心', 'ratio': 0.2}, {'word': 'kurasutā sēnpu', 'ratio': 0.1}]",クラスタ中心
1017,1165,cluster feature,クラスタ特徴,0.6,10,"[{'word': 'クラスタ特徴', 'ratio': 0.6}, {'word': 'クラスタ機能', 'ratio': 0.2}, {'word': 'クラスター特徴', 'ratio': 0.2}]",クラスタ特徴
1018,1166,cluster label,クラスターラベル,0.2,10,"[{'word': 'クラスタラベル', 'ratio': 0.8}, {'word': 'クラスターラベル', 'ratio': 0.2}]",クラスタラベル
1019,1167,cluster size,クラスターサイズ,0.2,10,"[{'word': 'クラスタサイズ', 'ratio': 0.8}, {'word': 'クラスターサイズ', 'ratio': 0.2}]",クラスタサイズ
1020,1168,clustering algorithm,クラスタリングアルゴリズム,1.0,10,"[{'word': 'クラスタリングアルゴリズム', 'ratio': 1.0}]",クラスタリングアルゴリズム
1021,1169,clustering criterion,クラスター基準,0.0,9,"[{'word': 'クラスタリング基準', 'ratio': 1.0}]",クラスタリング基準
1022,1170,clustering method,クラスタリング手法,0.8888888888888888,9,"[{'word': 'クラスタリング手法', 'ratio': 0.8888888888888888}, {'word': 'クラスタリング法', 'ratio': 0.1111111111111111}]",クラスタリング手法
1023,1171,clustering problem,クラスター問題,0.0,9,"[{'word': 'クラスタリング問題', 'ratio': 0.8888888888888888}, {'word': 'クラスタリング手法', 'ratio': 0.1111111111111111}]",クラスタリング問題
1024,1172,co-occurrence,共起,1.0,9,"[{'word': '共起', 'ratio': 1.0}]",共起
1025,1173,co-occurrence matrix,共起行列,1.0,9,"[{'word': '共起行列', 'ratio': 1.0}]",共起行列
1026,1174,co-occurrence statistic,共起統計,1.0,10,"[{'word': '共起統計', 'ratio': 1.0}]",共起統計
1027,1175,co-reference,共同参照,0.2,10,"[{'word': '共参照', 'ratio': 0.7}, {'word': '共同参照', 'ratio': 0.2}, {'word': 'コア参照', 'ratio': 0.1}]",共参照
1028,1177,coarse correlated equilibria,粗い相関均衡,0.5,10,"[{'word': '粗い相関均衡', 'ratio': 0.5}, {'word': '粗相関平衡', 'ratio': 0.2}, {'word': '粗い相關均衡', 'ratio': 0.1}, {'word': '粗い相関平衡', 'ratio': 0.1}, {'word': '粗大相関均衡', 'ratio': 0.1}]",粗い相関均衡
1029,1178,coarse correlated equilibrium,粗い相関均衡,0.5,10,"[{'word': '粗い相関均衡', 'ratio': 0.5}, {'word': '粗相関平衡', 'ratio': 0.2}, {'word': '粗い相關均衡', 'ratio': 0.1}, {'word': '粗い相関平衡', 'ratio': 0.1}, {'word': '粗大相関均衡', 'ratio': 0.1}]",粗い相関均衡
1030,1179,coarse layer,粗層,0.2,10,"[{'word': '粗い層', 'ratio': 0.5}, {'word': '粗層', 'ratio': 0.2}, {'word': 'コース層', 'ratio': 0.2}, {'word': '粗い層粗いから細かい', 'ratio': 0.1}]",粗い層
1031,1184,codebook,コードブック,0.9,10,"[{'word': 'コードブック', 'ratio': 0.9}, {'word': '暗号帳', 'ratio': 0.1}]",コードブック
1032,1185,codomain,対値域,0.0,10,"[{'word': 'コドメイン', 'ratio': 0.6}, {'word': '値域', 'ratio': 0.3}, {'word': 'コードドメイン', 'ratio': 0.1}]",コドメイン
1033,1186,coefficient matrix,係数行列,1.0,10,"[{'word': '係数行列', 'ratio': 1.0}]",係数行列
1034,1187,cognitive model,認知モデル,1.0,10,"[{'word': '認知モデル', 'ratio': 1.0}]",認知モデル
1035,1188,cognitive science,認知科学,1.0,10,"[{'word': '認知科学', 'ratio': 1.0}]",認知科学
1036,1189,cold start,コールドスタート,1.0,10,"[{'word': 'コールドスタート', 'ratio': 1.0}]",コールドスタート
1037,1190,collaborative filtering,協調フィルタリング,1.0,10,"[{'word': '協調フィルタリング', 'ratio': 1.0}]",協調フィルタリング
1038,1191,collaborative learning,協同学習,0.1,10,"[{'word': '協調学習', 'ratio': 0.8}, {'word': '共同学習', 'ratio': 0.1}, {'word': '協同学習', 'ratio': 0.1}]",協調学習
1039,1192,collective inference,集合的推論,0.1,10,"[{'word': '集団推論', 'ratio': 0.9}, {'word': '集合的推論', 'ratio': 0.1}]",集団推論
1040,1193,color channel,カラーチャンネル,0.7,10,"[{'word': 'カラーチャンネル', 'ratio': 0.7}, {'word': 'カラー チャンネル', 'ratio': 0.2}, {'word': 'カラー チャネル', 'ratio': 0.1}]",カラーチャンネル
1041,1194,color constancy,色恒常性,0.5,10,"[{'word': '色恒常性', 'ratio': 0.5}, {'word': '色の恒常性', 'ratio': 0.4}, {'word': '色保存', 'ratio': 0.1}]",色恒常性
1042,1196,column space,列空間,0.8,10,"[{'word': '列空間', 'ratio': 0.8}, {'word': '段間', 'ratio': 0.2}]",列空間
1043,1197,column vector,列ベクトル,1.0,10,"[{'word': '列ベクトル', 'ratio': 1.0}]",列ベクトル
1044,1198,combinator,組み合わせ子 (kumiawaseko),0.0,10,"[{'word': 'コンビネータ', 'ratio': 0.5}, {'word': '組み合わせ子', 'ratio': 0.4}, {'word': 'コンビネーター', 'ratio': 0.1}]",コンビネータ
1045,1199,combinatorial explosion,組み合わせ爆発,0.5,10,"[{'word': '組み合わせ爆発', 'ratio': 0.5}, {'word': '組合せ爆発', 'ratio': 0.3}, {'word': '組合爆発', 'ratio': 0.2}]",組み合わせ爆発
1046,1200,combinatorial optimization,組合せ最適化,0.3,10,"[{'word': '組み合わせ最適化', 'ratio': 0.5}, {'word': '組合せ最適化', 'ratio': 0.3}, {'word': '組合最適化', 'ratio': 0.2}]",組み合わせ最適化
1047,1202,commonsense inference,常識推論,0.8,10,"[{'word': '常識推論', 'ratio': 0.8}, {'word': 'ナンセンス推論', 'ratio': 0.1}, {'word': '常識的な推論', 'ratio': 0.1}]",常識推論
1048,1203,commonsense knowledge,常識知識,0.8,10,"[{'word': '常識知識', 'ratio': 0.8}, {'word': '常識的知識', 'ratio': 0.1}, {'word': '常識的な知識', 'ratio': 0.1}]",常識知識
1049,1204,commonsense knowledge graph,常識知識グラフ,0.8888888888888888,9,"[{'word': '常識知識グラフ', 'ratio': 0.8888888888888888}, {'word': '俗知識グラフ', 'ratio': 0.1111111111111111}]",常識知識グラフ
1050,1206,communication graph,通信グラフ,0.6666666666666666,9,"[{'word': '通信グラフ', 'ratio': 0.6666666666666666}, {'word': 'コミュニケーショングラフ', 'ratio': 0.3333333333333333}]",通信グラフ
1051,1207,compatibility function,互換性関数,0.6666666666666666,9,"[{'word': '互換性関数', 'ratio': 0.6666666666666666}, {'word': '互換性機能', 'ratio': 0.1111111111111111}, {'word': '互換機能', 'ratio': 0.1111111111111111}, {'word': '適合性関数', 'ratio': 0.1111111111111111}]",互換性関数
1052,1208,compatibility graph,互換性グラフ,0.9,10,"[{'word': '互換性グラフ', 'ratio': 0.9}, {'word': '適合性グラフ', 'ratio': 0.1}]",互換性グラフ
1053,1209,competitive ratio,競合比,0.0,10,"[{'word': '競争比', 'ratio': 0.5}, {'word': '競争比率', 'ratio': 0.3}, {'word': '競争率', 'ratio': 0.1}, {'word': '競争力', 'ratio': 0.1}]",競争比
1054,1210,composition function,合成関数,0.6,10,"[{'word': '合成関数', 'ratio': 0.6}, {'word': 'コンポジション機能', 'ratio': 0.1}, {'word': '合成機能', 'ratio': 0.1}, {'word': '組成関数', 'ratio': 0.1}, {'word': '構成関数', 'ratio': 0.1}]",合成関数
1055,1212,compositional semantic,構成的意味論,0.3,10,"[{'word': '合成意味論', 'ratio': 0.5}, {'word': '構成的意味論', 'ratio': 0.3}, {'word': '合成的意味論', 'ratio': 0.1}, {'word': '組成的意味論', 'ratio': 0.1}]",合成意味論
1056,1213,compressive sensing,圧縮センシング,0.8888888888888888,9,"[{'word': '圧縮センシング', 'ratio': 0.8888888888888888}, {'word': '圧縮感知', 'ratio': 0.1111111111111111}]",圧縮センシング
1057,1215,computation graph,計算グラフ,1.0,9,"[{'word': '計算グラフ', 'ratio': 1.0}]",計算グラフ
1058,1216,computational argumentation,計算論証,0.2,10,"[{'word': '計算的議論', 'ratio': 0.5}, {'word': '計算論証', 'ratio': 0.2}, {'word': '計算論的論証', 'ratio': 0.1}, {'word': '計算的論証', 'ratio': 0.1}, {'word': '計算論的議論', 'ratio': 0.1}]",計算的議論
1059,1217,computational budget,計算リソース,0.0,10,"[{'word': '計算予算', 'ratio': 0.9}, {'word': '計算的予算', 'ratio': 0.1}]",計算予算
1060,1219,computational experiment,計算実験,1.0,10,"[{'word': '計算実験', 'ratio': 1.0}]",計算実験
1061,1220,computational graph,計算グラフ,1.0,10,"[{'word': '計算グラフ', 'ratio': 1.0}]",計算グラフ
1062,1221,computational model,計算モデル,1.0,10,"[{'word': '計算モデル', 'ratio': 1.0}]",計算モデル
1063,1222,compute budget,計算予算,0.8,10,"[{'word': '計算予算', 'ratio': 0.8}, {'word': '予算を計算する', 'ratio': 0.2}]",計算予算
1064,1223,computer vision model,"""コンピュータビジョンモデル""",0.0,10,"[{'word': 'コンピュータビジョンモデル', 'ratio': 0.9}, {'word': 'コンピュータービジョンモデル', 'ratio': 0.1}]",コンピュータビジョンモデル
1065,1224,concatenation,連結,0.5,20,"[{'word': '連結', 'ratio': 0.95}, {'word': '調和', 'ratio': 0.05}]",連結
1066,1225,concatenation operation,連結操作,0.7,10,"[{'word': '連結操作', 'ratio': 0.7}, {'word': '連結演算', 'ratio': 0.2}, {'word': '調和操作', 'ratio': 0.1}]",連結操作
1067,1226,concentration inequality,集中不等式,0.7,10,"[{'word': '集中不等式', 'ratio': 0.7}, {'word': '集中の不平等', 'ratio': 0.2}, {'word': '濃縮不等式', 'ratio': 0.1}]",集中不等式
1068,1227,concentration parameter,濃度パラメータ,0.0,10,"[{'word': '集中パラメータ', 'ratio': 0.7}, {'word': '濃度パラメーター', 'ratio': 0.2}, {'word': '濃縮パラメーター', 'ratio': 0.1}]",集中パラメータ
1069,1228,concept,概念,0.8,10,"[{'word': '概念', 'ratio': 0.8}, {'word': 'コンセプト', 'ratio': 0.2}]",概念
1070,1230,concept atom,概念原子,0.8,10,"[{'word': '概念原子', 'ratio': 0.8}, {'word': '概念アトム', 'ratio': 0.2}]",概念原子
1071,1231,concept class,概念クラス,0.8,10,"[{'word': '概念クラス', 'ratio': 0.8}, {'word': 'コンセプトクラス', 'ratio': 0.2}]",概念クラス
1072,1232,concept drift,概念ドリフト,0.6,10,"[{'word': '概念ドリフト', 'ratio': 0.6}, {'word': 'コンセプトドリフト', 'ratio': 0.2}, {'word': '概念漂流', 'ratio': 0.1}, {'word': 'コンセプト・ドリフト', 'ratio': 0.1}]",概念ドリフト
1073,1233,concept inclusion,概念包含,0.8,10,"[{'word': '概念包含', 'ratio': 0.8}, {'word': 'コンセプト・インクルージョン', 'ratio': 0.1}, {'word': 'コンセプトの包含', 'ratio': 0.1}]",概念包含
1074,1234,concept name,概念名,0.8,10,"[{'word': '概念名', 'ratio': 0.8}, {'word': 'コンセプト名', 'ratio': 0.2}]",概念名
1075,1235,condition number,条件数,0.8,10,"[{'word': '条件数', 'ratio': 0.8}, {'word': '条件番号', 'ratio': 0.2}]",条件数
1076,1236,conditional computation,条件付き計算,0.7,10,"[{'word': '条件付き計算', 'ratio': 0.7}, {'word': 'じょうけんけいさん', 'ratio': 0.1}, {'word': '条件付き計算条件付き計算', 'ratio': 0.1}, {'word': '件付き計算', 'ratio': 0.1}]",条件付き計算
1077,1237,conditional density,条件付き密度,0.9,10,"[{'word': '条件付き密度', 'ratio': 0.9}, {'word': '条件密度', 'ratio': 0.1}]",条件付き密度
1078,1238,conditional distribution,条件付き分布,1.0,10,"[{'word': '条件付き分布', 'ratio': 1.0}]",条件付き分布
1079,1239,conditional effect,条件付き効果,0.6,10,"[{'word': '条件付き効果', 'ratio': 0.6}, {'word': '条件効果', 'ratio': 0.3}, {'word': '条件的効果', 'ratio': 0.1}]",条件付き効果
1080,1240,conditional entropy,条件付きエントロピー,0.6,10,"[{'word': '条件付きエントロピー', 'ratio': 0.6}, {'word': '条件エントロピー', 'ratio': 0.4}]",条件付きエントロピー
1081,1241,conditional expectation,条件付き期待値,0.5,10,"[{'word': '条件付き期待値', 'ratio': 0.5}, {'word': '条件期待値', 'ratio': 0.2}, {'word': '条件付き期待', 'ratio': 0.2}, {'word': '条件の期待値', 'ratio': 0.1}]",条件付き期待値
1082,1242,conditional gradient,条件付き勾配,0.5,10,"[{'word': '条件付き勾配', 'ratio': 0.5}, {'word': '条件勾配', 'ratio': 0.3}, {'word': '条件付きグラデーション', 'ratio': 0.2}]",条件付き勾配
1083,1243,conditional independence,条件付き独立性,0.2,10,"[{'word': '条件付き独立', 'ratio': 0.5}, {'word': '条件付き独立性', 'ratio': 0.2}, {'word': '条件独立性', 'ratio': 0.1}, {'word': '条件的独立性', 'ratio': 0.1}, {'word': '条件独立', 'ratio': 0.1}]",条件付き独立
1084,1244,conditional independency,条件付き独立性,0.8,10,"[{'word': '条件付き独立性', 'ratio': 0.8}, {'word': '条件付きの独立性', 'ratio': 0.1}, {'word': '条件独立性', 'ratio': 0.1}]",条件付き独立性
1085,1245,conditional likelihood,条件付き尤度,0.9,10,"[{'word': '条件付き尤度', 'ratio': 0.9}, {'word': '条件尤度', 'ratio': 0.1}]",条件付き尤度
1086,1246,conditional log likelihood,条件付き対数尤度,0.9,10,"[{'word': '条件付き対数尤度', 'ratio': 0.9}, {'word': '条件対数尤度', 'ratio': 0.1}]",条件付き対数尤度
1087,1247,conditional log probability,条件付き対数確率,0.9,10,"[{'word': '条件付き対数確率', 'ratio': 0.9}, {'word': '条件対数確率', 'ratio': 0.1}]",条件付き対数確率
1088,1248,conditional maximum entropy,条件付き最大エントロピー,0.9,10,"[{'word': '条件付き最大エントロピー', 'ratio': 0.9}, {'word': '条件最大энтропー', 'ratio': 0.1}]",条件付き最大エントロピー
1089,1249,conditional model,条件付きモデル,1.0,10,"[{'word': '条件付きモデル', 'ratio': 1.0}]",条件付きモデル
1090,1250,conditional probability,条件付き確率,1.0,10,"[{'word': '条件付き確率', 'ratio': 1.0}]",条件付き確率
1091,1251,conditional probability distribution,条件付き確率分布,1.0,10,"[{'word': '条件付き確率分布', 'ratio': 1.0}]",条件付き確率分布
1092,1252,conditional sampling,条件付きサンプリング,1.0,10,"[{'word': '条件付きサンプリング', 'ratio': 1.0}]",条件付きサンプリング
1093,1253,conditional text generation,条件付きテキスト生成,0.8,10,"[{'word': '条件付きテキスト生成', 'ratio': 0.8}, {'word': '条件付きテキストの生成', 'ratio': 0.2}]",条件付きテキスト生成
1094,1254,conditioning,条件づけ (jōkenzuke),0.0,10,"[{'word': '条件付け', 'ratio': 0.8}, {'word': 'コンディショニング', 'ratio': 0.2}]",条件付け
1095,1255,conditioning vector,条件付けベクトル,0.0,10,"[{'word': '条件ベクトル', 'ratio': 0.9}, {'word': 'コンディショニングベクトル', 'ratio': 0.1}]",条件ベクトル
1096,1256,confidence,信頼度,0.8,10,"[{'word': '信頼度', 'ratio': 0.8}, {'word': '信頼', 'ratio': 0.1}, {'word': '自信', 'ratio': 0.1}]",信頼度
1097,1258,confidence interval,信頼区間,0.9,10,"[{'word': '信頼区間', 'ratio': 0.9}, {'word': '信頼限界', 'ratio': 0.1}]",信頼区間
1098,1259,confidence map,信頼度マップ,0.8888888888888888,9,"[{'word': '信頼度マップ', 'ratio': 0.8888888888888888}, {'word': '確信地図', 'ratio': 0.1111111111111111}]",信頼度マップ
1099,1260,confidence score,信頼度スコア,0.6666666666666666,9,"[{'word': '信頼度スコア', 'ratio': 0.6666666666666666}, {'word': '信頼度', 'ratio': 0.1111111111111111}, {'word': '信頼スコア', 'ratio': 0.1111111111111111}, {'word': '確信スコア', 'ratio': 0.1111111111111111}]",信頼度スコア
1100,1261,confidence threshold,信頼度閾値,0.6666666666666666,9,"[{'word': '信頼度閾値', 'ratio': 0.6666666666666666}, {'word': '信頼閾値', 'ratio': 0.1111111111111111}, {'word': '信頼度のしきい値', 'ratio': 0.1111111111111111}, {'word': '確信閾値', 'ratio': 0.1111111111111111}]",信頼度閾値
1101,1262,configuration,構成,0.8888888888888888,9,"[{'word': '構成', 'ratio': 0.8888888888888888}, {'word': '設定', 'ratio': 0.1111111111111111}]",構成
1102,1263,confusion matrix,混同行列,0.8888888888888888,9,"[{'word': '混同行列', 'ratio': 0.8888888888888888}, {'word': '混乱行列', 'ratio': 0.1111111111111111}]",混同行列
1103,1264,confusion network,混同ネットワーク,0.0,9,"[{'word': '混乱ネットワーク', 'ratio': 0.8888888888888888}, {'word': '混同行列', 'ratio': 0.1111111111111111}]",混乱ネットワーク
1104,1265,conjugate gradient,共役勾配,0.7777777777777778,9,"[{'word': '共役勾配', 'ratio': 0.7777777777777778}, {'word': '共役勾配法', 'ratio': 0.2222222222222222}]",共役勾配
1105,1266,conjugate gradient descent,共役勾配降下法,1.0,9,"[{'word': '共役勾配降下法', 'ratio': 1.0}]",共役勾配降下法
1106,1267,conjugate gradient method,共役勾配法,1.0,9,"[{'word': '共役勾配法', 'ratio': 1.0}]",共役勾配法
1107,1269,conjunctive normal form,連言標準形,0.5555555555555556,9,"[{'word': '連言標準形', 'ratio': 0.5555555555555556}, {'word': '乗法標準形', 'ratio': 0.1111111111111111}, {'word': '結合標準形', 'ratio': 0.1111111111111111}, {'word': '接続標準形', 'ratio': 0.1111111111111111}, {'word': '論理積標準形', 'ratio': 0.1111111111111111}]",連言標準形
1108,1270,conjunctive query,接続クエリ,0.2222222222222222,9,"[{'word': '連言クエリ', 'ratio': 0.5555555555555556}, {'word': '接続クエリ', 'ratio': 0.2222222222222222}, {'word': '結合クエリ', 'ratio': 0.1111111111111111}, {'word': '論理積クエリ', 'ratio': 0.1111111111111111}]",連言クエリ
1109,1271,connected component,連結成分,0.7777777777777778,9,"[{'word': '連結成分', 'ratio': 0.7777777777777778}, {'word': '連結コンポーネント', 'ratio': 0.1111111111111111}, {'word': '接続コンポーネント', 'ratio': 0.1111111111111111}]",連結成分
1110,1272,connectionist model,接続主義モデル,0.3333333333333333,9,"[{'word': 'コネクショニストモデル', 'ratio': 0.5555555555555556}, {'word': '接続主義モデル', 'ratio': 0.3333333333333333}, {'word': 'コネクショニスト・モデル', 'ratio': 0.1111111111111111}]",コネクショニストモデル
1111,1273,connectivity matrix,接続行列,0.6666666666666666,9,"[{'word': '接続行列', 'ratio': 0.6666666666666666}, {'word': '接続性マトリックス', 'ratio': 0.2222222222222222}, {'word': 'コネクティビティ行列', 'ratio': 0.1111111111111111}]",接続行列
1112,1274,consensus network decoding,コンセンサスネットワークデコーディング,0.7,10,"[{'word': 'コンセンサスネットワークデコーディング', 'ratio': 0.7}, {'word': 'コンセンサスネットワーク解読', 'ratio': 0.1}, {'word': 'コンセンサスネットワークのデコーディング', 'ratio': 0.1}, {'word': 'オントロジー言語', 'ratio': 0.1}]",コンセンサスネットワークデコーディング
1113,1275,consequent,後件,0.1,10,"[{'word': '結果', 'ratio': 0.6}, {'word': '結果部', 'ratio': 0.1}, {'word': '後件', 'ratio': 0.1}, {'word': '結果としての', 'ratio': 0.1}, {'word': 'オントロジー媒介クエリ', 'ratio': 0.1}]",結果
1114,1277,constellation model,星座モデル,0.4,10,"[{'word': 'コンステレーションモデル', 'ratio': 0.5}, {'word': '星座モデル', 'ratio': 0.4}, {'word': 'オープンエンドのテキスト生成', 'ratio': 0.1}]",コンステレーションモデル
1115,1281,constituent parsing,構成素解析,0.5,10,"[{'word': '構成素解析', 'ratio': 0.5}, {'word': '構文解析', 'ratio': 0.3}, {'word': '構成要素解析', 'ratio': 0.1}, {'word': '句構造解析', 'ratio': 0.1}]",構成素解析
1116,1282,constituent structure,構成構造,0.2,10,"[{'word': '構成素構造', 'ratio': 0.5}, {'word': 'こうせいそこうぞう', 'ratio': 0.2}, {'word': '構成構造', 'ratio': 0.2}, {'word': '構成要素構造', 'ratio': 0.1}]",構成素構造
1117,1283,constrained beam search,制約付きビーム探索,0.1,10,"[{'word': '制約付きビームサーチ', 'ratio': 0.6}, {'word': '拘束ビーム探索', 'ratio': 0.2}, {'word': '制約ビーム検索', 'ratio': 0.1}, {'word': '制約付きビーム探索', 'ratio': 0.1}]",制約付きビームサーチ
1118,1284,constrained decoding,制約付きデコーディング,0.7,10,"[{'word': '制約付きデコーディング', 'ratio': 0.7}, {'word': '制約付き復号', 'ratio': 0.2}, {'word': '制約デコーディング', 'ratio': 0.1}]",制約付きデコーディング
1119,1285,constrained optimization,制約付き最適化,0.6,10,"[{'word': '制約付き最適化', 'ratio': 0.6}, {'word': '条件付き最適化', 'ratio': 0.2}, {'word': '制約最適化', 'ratio': 0.2}]",制約付き最適化
1120,1286,constrained optimization problem,制約付き最適化問題,0.8,10,"[{'word': '制約付き最適化問題', 'ratio': 0.8}, {'word': '制約最適化問題', 'ratio': 0.2}]",制約付き最適化問題
1121,1287,constraint,制約,0.75,20,"[{'word': '制約', 'ratio': 0.75}, {'word': '制約条件', 'ratio': 0.2}, {'word': '情報が不足しています）', 'ratio': 0.05}]",制約
1122,1288,constraint generation,制約生成,0.8888888888888888,9,"[{'word': '制約生成', 'ratio': 0.8888888888888888}, {'word': '制約の生成', 'ratio': 0.1111111111111111}]",制約生成
1123,1289,constraint programming,制約プログラミング,1.0,9,"[{'word': '制約プログラミング', 'ratio': 1.0}]",制約プログラミング
1124,1290,constraint propagation,制約伝播,0.6666666666666666,9,"[{'word': '制約伝播', 'ratio': 0.6666666666666666}, {'word': '制約伝搬', 'ratio': 0.2222222222222222}, {'word': '制約の伝播', 'ratio': 0.1111111111111111}]",制約伝播
1125,1291,constraint satisfaction,制約充足問題,0.0,9,"[{'word': '制約充足', 'ratio': 0.7777777777777778}, {'word': '制約満足度', 'ratio': 0.1111111111111111}, {'word': '制約満足', 'ratio': 0.1111111111111111}]",制約充足
1126,1292,constraint satisfaction problem,制約充足問題,0.8888888888888888,9,"[{'word': '制約充足問題', 'ratio': 0.8888888888888888}, {'word': '制約満足問題', 'ratio': 0.1111111111111111}]",制約充足問題
1127,1293,constraint set,制約条件集合,0.0,10,"[{'word': '制約集合', 'ratio': 0.9}, {'word': '制約セット', 'ratio': 0.1}]",制約集合
1128,1294,content model,コンテンツモデル,1.0,10,"[{'word': 'コンテンツモデル', 'ratio': 1.0}]",コンテンツモデル
1129,1295,content selection,コンテンツ選択,0.9,10,"[{'word': 'コンテンツ選択', 'ratio': 0.9}, {'word': 'コンテンツの選択', 'ratio': 0.1}]",コンテンツ選択
1130,1296,context encoder,コンテキストエンコーダ,0.9,10,"[{'word': 'コンテキストエンコーダ', 'ratio': 0.9}, {'word': 'コンテキストエンコーダー', 'ratio': 0.1}]",コンテキストエンコーダ
1131,1297,context free grammar,コンテキストフリー文法,0.0,10,"[{'word': '文脈自由文法', 'ratio': 0.7}, {'word': 'コンテキスト自由文法', 'ratio': 0.3}]",文脈自由文法
1132,1298,context model,コンテキストモデル,0.6,10,"[{'word': 'コンテキストモデル', 'ratio': 0.6}, {'word': '文脈モデル', 'ratio': 0.3}, {'word': '文脈自由文法', 'ratio': 0.1}]",コンテキストモデル
1133,1299,context vector,コンテクストベクトル,0.0,10,"[{'word': 'コンテキストベクトル', 'ratio': 0.5}, {'word': '文脈ベクトル', 'ratio': 0.3}, {'word': 'コンテキストベクター', 'ratio': 0.2}]",コンテキストベクトル
1134,1300,context window,コンテキストウィンドウ,0.7,10,"[{'word': 'コンテキストウィンドウ', 'ratio': 0.7}, {'word': '文脈ウィンドウ', 'ratio': 0.3}]",コンテキストウィンドウ
1135,1301,context-free language,文脈自由言語,0.7,10,"[{'word': '文脈自由言語', 'ratio': 0.7}, {'word': 'コンテキストフリー言語', 'ratio': 0.2}, {'word': 'コンテキスト自由言語', 'ratio': 0.1}]",文脈自由言語
1136,1302,contextual embedding,文脈埋め込み,0.5555555555555556,9,"[{'word': '文脈埋め込み', 'ratio': 0.5555555555555556}, {'word': '文脈的埋め込み', 'ratio': 0.2222222222222222}, {'word': 'コンテキスト埋め込み', 'ratio': 0.2222222222222222}]",文脈埋め込み
1137,1303,contextual feature,文脈特徴,0.5555555555555556,9,"[{'word': '文脈特徴', 'ratio': 0.5555555555555556}, {'word': 'コンテキスト機能', 'ratio': 0.2222222222222222}, {'word': 'コンテキスト特徴', 'ratio': 0.2222222222222222}]",文脈特徴
1138,1304,contextual information,文脈情報,0.7777777777777778,9,"[{'word': '文脈情報', 'ratio': 0.7777777777777778}, {'word': 'コンテキスト情報', 'ratio': 0.2222222222222222}]",文脈情報
1139,1305,contextual model,文脈モデル (Contextual Model),0.0,9,"[{'word': '文脈モデル', 'ratio': 0.7777777777777778}, {'word': 'コンテキストモデル', 'ratio': 0.2222222222222222}]",文脈モデル
1140,1310,contextualized representation,文脈化された表現,0.4,10,"[{'word': 'コンテキスト化された表現', 'ratio': 0.5}, {'word': '文脈化された表現', 'ratio': 0.4}, {'word': '文脈化表現', 'ratio': 0.1}]",コンテキスト化された表現
1141,1311,contextualized word vector,文脈化単語ベクトル,0.2,10,"[{'word': 'コンテキスト化された単語ベクトル', 'ratio': 0.5}, {'word': '文脈化された単語ベクトル', 'ratio': 0.3}, {'word': '文脈化単語ベクトル', 'ratio': 0.2}]",コンテキスト化された単語ベクトル
1142,1312,contingency table,分割表,0.2,10,"[{'word': 'クロス集計表', 'ratio': 0.6}, {'word': 'コンティンジェンシーテーブル', 'ratio': 0.2}, {'word': '分割表', 'ratio': 0.2}]",クロス集計表
1143,1313,continual learning,継続学習,0.3,10,"[{'word': '継続的学習', 'ratio': 0.5}, {'word': '継続学習', 'ratio': 0.3}, {'word': '継続的な学習', 'ratio': 0.1}, {'word': '連続学習', 'ratio': 0.1}]",継続的学習
1144,1314,continuous normalizing flow,連続正規化フロー (CNF),0.0,10,"[{'word': '連続正規化フロー', 'ratio': 0.5}, {'word': '連続的正規化フロー', 'ratio': 0.2}, {'word': '継続的正規化フロー', 'ratio': 0.2}, {'word': '連続ノーマライジングフロー', 'ratio': 0.1}]",連続正規化フロー
1145,1315,contrastive approach,対照的アプローチ,0.5,10,"[{'word': '対照的アプローチ', 'ratio': 0.5}, {'word': '対照的なアプローチ', 'ratio': 0.2}, {'word': 'コントラストアプローチ', 'ratio': 0.2}, {'word': '対比学習', 'ratio': 0.1}]",対照的アプローチ
1146,1316,contrastive fine-tuning,対照的な微調整,0.0,10,"[{'word': '対照的ファインチューニング', 'ratio': 0.5}, {'word': 'コントラストの微調整', 'ratio': 0.2}, {'word': 'コントラスト微調整', 'ratio': 0.2}, {'word': '対比フィネチューニング', 'ratio': 0.1}]",対照的ファインチューニング
1147,1320,controllable text generation,制御可能なテキスト生成,0.9,10,"[{'word': '制御可能なテキスト生成', 'ratio': 0.9}, {'word': '制御テキスト生成', 'ratio': 0.1}]",制御可能なテキスト生成
1148,1321,conv layer,畳み込み層,0.7,10,"[{'word': '畳み込み層', 'ratio': 0.7}, {'word': 'コンブ層', 'ratio': 0.2}, {'word': '畳み込みレイヤー', 'ratio': 0.1}]",畳み込み層
1149,1322,convergence,収束,0.8,10,"[{'word': '収束', 'ratio': 0.8}, {'word': 'コンバージェンス', 'ratio': 0.2}]",収束
1150,1323,convergence analysis,収束解析,0.8,10,"[{'word': '収束解析', 'ratio': 0.8}, {'word': 'コンバージェンス分析', 'ratio': 0.2}]",収束解析
1151,1324,convergence bound,収束境界,0.7,10,"[{'word': '収束境界', 'ratio': 0.7}, {'word': '収束界', 'ratio': 0.2}, {'word': '収束バウンド', 'ratio': 0.1}]",収束境界
1152,1325,convergence criterion,収束基準,0.9,10,"[{'word': '収束基準', 'ratio': 0.9}, {'word': 'Seika Kijun', 'ratio': 0.1}]",収束基準
1153,1326,convergence rate,収束率,0.3,10,"[{'word': '収束速度', 'ratio': 0.6}, {'word': '収束率', 'ratio': 0.3}, {'word': 'Seika Ryōdō', 'ratio': 0.1}]",収束速度
1154,1327,convergence time,収束時間,0.9,10,"[{'word': '収束時間', 'ratio': 0.9}, {'word': 'Seika Jikan', 'ratio': 0.1}]",収束時間
1155,1328,conversation history,会話履歴,0.8,10,"[{'word': '会話履歴', 'ratio': 0.8}, {'word': '収束時間', 'ratio': 0.1}, {'word': 'Kaidan Rekishi', 'ratio': 0.1}]",会話履歴
1156,1331,convex,凸,0.8888888888888888,9,"[{'word': '凸', 'ratio': 0.8888888888888888}, {'word': '凸型', 'ratio': 0.1111111111111111}]",凸
1157,1332,convex combination,凸結合,0.7777777777777778,9,"[{'word': '凸結合', 'ratio': 0.7777777777777778}, {'word': 'コンベックス・コンビネーション', 'ratio': 0.1111111111111111}, {'word': '凸組み合わせ', 'ratio': 0.1111111111111111}]",凸結合
1158,1333,convex conjugate,凸共役,1.0,9,"[{'word': '凸共役', 'ratio': 1.0}]",凸共役
1159,1334,convex constraint,凸制約,0.8,10,"[{'word': '凸制約', 'ratio': 0.8}, {'word': 'とつせいやくじょうけん', 'ratio': 0.1}, {'word': '凸型拘束', 'ratio': 0.1}]",凸制約
1160,1335,convex decomposition,凸分解,1.0,10,"[{'word': '凸分解', 'ratio': 1.0}]",凸分解
1161,1336,convex function,凸関数,1.0,10,"[{'word': '凸関数', 'ratio': 1.0}]",凸関数
1162,1337,convex hull,凸包,0.9,10,"[{'word': '凸包', 'ratio': 0.9}, {'word': 'とつはん', 'ratio': 0.1}]",凸包
1163,1338,convex loss,凸損失,0.7777777777777778,9,"[{'word': '凸損失', 'ratio': 0.7777777777777778}, {'word': '凸損', 'ratio': 0.2222222222222222}]",凸損失
1164,1339,convex objective,凸目的関数,0.5,10,"[{'word': '凸目的関数', 'ratio': 0.5}, {'word': '凸目的', 'ratio': 0.4}, {'word': '凸型対物レンズ', 'ratio': 0.1}]",凸目的関数
1165,1340,convex objective function,凸目的関数,1.0,10,"[{'word': '凸目的関数', 'ratio': 1.0}]",凸目的関数
1166,1341,convex optimization,凸最適化,1.0,10,"[{'word': '凸最適化', 'ratio': 1.0}]",凸最適化
1167,1342,convex optimization problem,凸最適化問題,1.0,10,"[{'word': '凸最適化問題', 'ratio': 1.0}]",凸最適化問題
1168,1343,convex problem,凸問題,1.0,10,"[{'word': '凸問題', 'ratio': 1.0}]",凸問題
1169,1347,convex relaxation,凸緩和,1.0,10,"[{'word': '凸緩和', 'ratio': 1.0}]",凸緩和
1170,1348,convex risk minimization,凸リスク最小化,1.0,10,"[{'word': '凸リスク最小化', 'ratio': 1.0}]",凸リスク最小化
1171,1349,convex set,凸集合,0.9,10,"[{'word': '凸集合', 'ratio': 0.9}, {'word': '凸セット', 'ratio': 0.1}]",凸集合
1172,1351,convex-concave,凸凹,0.9,10,"[{'word': '凸凹', 'ratio': 0.9}, {'word': '凹凸', 'ratio': 0.1}]",凸凹
1173,1352,convexity,凸性,0.8,10,"[{'word': '凸性', 'ratio': 0.8}, {'word': 'とつえん', 'ratio': 0.1}, {'word': '凸状', 'ratio': 0.1}]",凸性
1174,1353,convolution kernel,畳み込みカーネル,0.9,10,"[{'word': '畳み込みカーネル', 'ratio': 0.9}, {'word': 'コンボリューションカーネル', 'ratio': 0.1}]",畳み込みカーネル
1175,1354,convolution layer,畳み込み層,0.9,10,"[{'word': '畳み込み層', 'ratio': 0.9}, {'word': 'onvolution レイヤー', 'ratio': 0.1}]",畳み込み層
1176,1355,convolution neural network,畳み込みニューラルネットワーク,0.9,10,"[{'word': '畳み込みニューラルネットワーク', 'ratio': 0.9}, {'word': 'Convolutional ニューラル ネットワーク', 'ratio': 0.1}]",畳み込みニューラルネットワーク
1177,1356,convolution operation,畳み込み演算,0.7,10,"[{'word': '畳み込み演算', 'ratio': 0.7}, {'word': '畳み込み操作', 'ratio': 0.2}, {'word': 'Convolution オペレーション', 'ratio': 0.1}]",畳み込み演算
1178,1357,convolution operator,畳み込み演算子,0.9,10,"[{'word': '畳み込み演算子', 'ratio': 0.9}, {'word': 'Convolution オペレーション', 'ratio': 0.1}]",畳み込み演算子
1179,1358,convolutional,畳み込み,0.2,10,"[{'word': '畳み込みの', 'ratio': 0.5}, {'word': '畳み込み型', 'ratio': 0.2}, {'word': '畳み込み', 'ratio': 0.2}, {'word': 'Convolutional', 'ratio': 0.1}]",畳み込みの
1180,1359,convolutional architecture,畳み込みアーキテクチャ,0.9,10,"[{'word': '畳み込みアーキテクチャ', 'ratio': 0.9}, {'word': 'Konbyūshon Kōsō', 'ratio': 0.1}]",畳み込みアーキテクチャ
1181,1360,convolutional block,畳み込みブロック,0.9,10,"[{'word': '畳み込みブロック', 'ratio': 0.9}, {'word': 'Konbyūshon Buroku', 'ratio': 0.1}]",畳み込みブロック
1182,1361,convolutional decoder,畳み込みデコーダー,0.0,10,"[{'word': '畳み込みデコーダ', 'ratio': 0.9}, {'word': 'Konbyūshon Dekodā', 'ratio': 0.1}]",畳み込みデコーダ
1183,1362,convolutional encoder,畳み込みエンコーダ,0.8,10,"[{'word': '畳み込みエンコーダ', 'ratio': 0.8}, {'word': '畳み込み符号化器', 'ratio': 0.1}, {'word': 'Konbyūshon Enkodā', 'ratio': 0.1}]",畳み込みエンコーダ
1184,1363,convolutional feature,畳み込み特徴量,0.0,10,"[{'word': '畳み込み特徴', 'ratio': 0.9}, {'word': 'Konbyūshon Fiyāchā', 'ratio': 0.1}]",畳み込み特徴
1185,1364,convolutional filter,畳み込みフィルタ,0.6,10,"[{'word': '畳み込みフィルタ', 'ratio': 0.6}, {'word': '畳み込みフィルター', 'ratio': 0.4}]",畳み込みフィルタ
1186,1365,convolutional kernel,畳み込み核,0.0,10,"[{'word': '畳み込みカーネル', 'ratio': 1.0}]",畳み込みカーネル
1187,1366,convolutional layer,畳み込み層,0.9,10,"[{'word': '畳み込み層', 'ratio': 0.9}, {'word': '畳み込みレイヤー', 'ratio': 0.1}]",畳み込み層
1188,1367,convolutional network,畳み込みネットワーク,1.0,10,"[{'word': '畳み込みネットワーク', 'ratio': 1.0}]",畳み込みネットワーク
1189,1368,convolutional neural net,畳み込みニューラルネット,1.0,10,"[{'word': '畳み込みニューラルネット', 'ratio': 1.0}]",畳み込みニューラルネット
1190,1369,convolutional neural network,畳み込みニューラルネットワーク,0.8888888888888888,9,"[{'word': '畳み込みニューラルネットワーク', 'ratio': 0.8888888888888888}, {'word': '畳み込みニューラル ネットワーク', 'ratio': 0.1111111111111111}]",畳み込みニューラルネットワーク
1191,1370,convolutional representation,畳み込み表現,1.0,9,"[{'word': '畳み込み表現', 'ratio': 1.0}]",畳み込み表現
1192,1371,cooling schedule,冷却スケジュール,0.8888888888888888,9,"[{'word': '冷却スケジュール', 'ratio': 0.8888888888888888}, {'word': 'クーリングスケジュール', 'ratio': 0.1111111111111111}]",冷却スケジュール
1193,1372,coordinate ascent,座標上昇法,0.6666666666666666,9,"[{'word': '座標上昇法', 'ratio': 0.6666666666666666}, {'word': '座標上昇', 'ratio': 0.3333333333333333}]",座標上昇法
1194,1373,coordinate descent,座標降下法,0.6666666666666666,9,"[{'word': '座標降下法', 'ratio': 0.6666666666666666}, {'word': '座標降下', 'ratio': 0.3333333333333333}]",座標降下法
1195,1375,coordinate frame,座標系,0.4,10,"[{'word': '座標フレーム', 'ratio': 0.5}, {'word': '座標系', 'ratio': 0.4}, {'word': 'Kōordinate Furemu', 'ratio': 0.1}]",座標フレーム
1196,1376,copy mechanism,コピーメカニズム,0.2,10,"[{'word': 'コピー機構', 'ratio': 0.7}, {'word': 'コピーメカニズム', 'ratio': 0.2}, {'word': 'Kōpiri Mekanismu', 'ratio': 0.1}]",コピー機構
1197,1377,core tensor,コアテンソル,0.9,10,"[{'word': 'コアテンソル', 'ratio': 0.9}, {'word': 'Koa Tenzā', 'ratio': 0.1}]",コアテンソル
1198,1380,coreference resolution model,共参照解決モデル,0.5,10,"[{'word': '共参照解決モデル', 'ratio': 0.5}, {'word': 'コアリファレンス解決モデル', 'ratio': 0.3}, {'word': '核参照解決モデル', 'ratio': 0.2}]",共参照解決モデル
1199,1381,coreference resolution system,共参照解決システム,0.5,10,"[{'word': '共参照解決システム', 'ratio': 0.5}, {'word': 'コアリファレンス解決システム', 'ratio': 0.3}, {'word': 'コアレファレンス解決システム', 'ratio': 0.2}]",共参照解決システム
1200,1383,correlated equilibria,相関均衡,0.4,10,"[{'word': '相関平衡', 'ratio': 0.5}, {'word': '相関均衡', 'ratio': 0.4}, {'word': 'Korereitā Ekuiburi', 'ratio': 0.1}]",相関平衡
1201,1384,correlated equilibrium,相関均衡,0.5,10,"[{'word': '相関均衡', 'ratio': 0.5}, {'word': '相関平衡', 'ratio': 0.4}, {'word': 'Korereitā Ekuibiru', 'ratio': 0.1}]",相関均衡
1202,1385,correlation coefficient,相関係数,0.9,10,"[{'word': '相関係数', 'ratio': 0.9}, {'word': 'Korereishon Kokusei', 'ratio': 0.1}]",相関係数
1203,1386,correspondence matrix,対応行列,1.0,10,"[{'word': '対応行列', 'ratio': 1.0}]",対応行列
1204,1387,cosine,コサイン,0.85,20,"[{'word': 'コサイン', 'ratio': 0.85}, {'word': '余弦', 'ratio': 0.15}]",コサイン
1205,1388,cosine decay,コサイン減衰,0.9,10,"[{'word': 'コサイン減衰', 'ratio': 0.9}, {'word': '余弦減衰', 'ratio': 0.1}]",コサイン減衰
1206,1389,cosine decay schedule,コサイン減衰スケジュール,0.9,10,"[{'word': 'コサイン減衰スケジュール', 'ratio': 0.9}, {'word': '余弦減衰スケジュール', 'ratio': 0.1}]",コサイン減衰スケジュール
1207,1390,cosine learning rate schedule,コサイン学習率スケジュール,0.9,10,"[{'word': 'コサイン学習率スケジュール', 'ratio': 0.9}, {'word': '余弦学習率スケジュール', 'ratio': 0.1}]",コサイン学習率スケジュール
1208,1392,cosine schedule,コサインスケジュール,0.9,10,"[{'word': 'コサインスケジュール', 'ratio': 0.9}, {'word': '余弦スケジュール', 'ratio': 0.1}]",コサインスケジュール
1209,1393,cosine similarity measure,コサイン類似度尺度,0.1111111111111111,9,"[{'word': 'コサイン類似度測定', 'ratio': 0.7777777777777778}, {'word': '最近傍アルゴリズム', 'ratio': 0.1111111111111111}, {'word': 'コサイン類似度尺度', 'ratio': 0.1111111111111111}]",コサイン類似度測定
1210,1394,cost function,コスト関数,1.0,9,"[{'word': 'コスト関数', 'ratio': 1.0}]",コスト関数
1211,1395,cost vector,コストベクトル,1.0,9,"[{'word': 'コストベクトル', 'ratio': 1.0}]",コストベクトル
1212,1396,cost volume,コスト体積,0.0,9,"[{'word': 'コストボリューム', 'ratio': 1.0}]",コストボリューム
1213,1397,cost-sensitive learning,コスト感知学習,0.0,9,"[{'word': 'コスト感度学習', 'ratio': 0.5555555555555556}, {'word': 'コスト重視学習', 'ratio': 0.2222222222222222}, {'word': 'コスト感受性学習', 'ratio': 0.1111111111111111}, {'word': 'コスト感応型学習', 'ratio': 0.1111111111111111}]",コスト感度学習
1214,1398,counterexample,反例,0.9,10,"[{'word': '反例', 'ratio': 0.9}, {'word': '対例', 'ratio': 0.1}]",反例
1215,1399,counterfactual datum,対事実データ,0.0,10,"[{'word': '反実仮想データ', 'ratio': 0.6}, {'word': '反事実データ', 'ratio': 0.3}, {'word': '偽事実データ', 'ratio': 0.1}]",反実仮想データ
1216,1400,counterfactual example,反実仮想例,0.6,10,"[{'word': '反実仮想例', 'ratio': 0.6}, {'word': '反事実例', 'ratio': 0.2}, {'word': '偽事実例', 'ratio': 0.1}, {'word': '反事実の例', 'ratio': 0.1}]",反実仮想例
1217,1403,covariance function,共分散関数,0.9,10,"[{'word': '共分散関数', 'ratio': 0.9}, {'word': 'Kōgan Kanren Hōshō', 'ratio': 0.1}]",共分散関数
1218,1404,covariance kernel,共分散カーネル,0.9,10,"[{'word': '共分散カーネル', 'ratio': 0.9}, {'word': 'Kōgan Kanren Kōrura', 'ratio': 0.1}]",共分散カーネル
1219,1405,covariance matrix,共分散行列,0.9,10,"[{'word': '共分散行列', 'ratio': 0.9}, {'word': 'Kōgan Kanren Bākusu', 'ratio': 0.1}]",共分散行列
1220,1406,covariance model,共分散モデル,0.9,10,"[{'word': '共分散モデル', 'ratio': 0.9}, {'word': 'Kōgan Kanren Modelu', 'ratio': 0.1}]",共分散モデル
1221,1407,covariance operator,共分散演算子,0.7777777777777778,9,"[{'word': '共分散演算子', 'ratio': 0.7777777777777778}, {'word': '共分散作用素', 'ratio': 0.1111111111111111}, {'word': '調和オペレーター', 'ratio': 0.1111111111111111}]",共分散演算子
1222,1408,covariance parameter,共分散パラメータ,0.8888888888888888,9,"[{'word': '共分散パラメータ', 'ratio': 0.8888888888888888}, {'word': '調和パラメーター', 'ratio': 0.1111111111111111}]",共分散パラメータ
1223,1409,covariance structure,共分散構造,0.8888888888888888,9,"[{'word': '共分散構造', 'ratio': 0.8888888888888888}, {'word': '調和構造', 'ratio': 0.1111111111111111}]",共分散構造
1224,1411,covariate,共変量,0.8888888888888888,9,"[{'word': '共変量', 'ratio': 0.8888888888888888}, {'word': '共変微分', 'ratio': 0.1111111111111111}]",共変量
1225,1412,covariate shift,共変量シフト,0.9,10,"[{'word': '共変量シフト', 'ratio': 0.9}, {'word': 'Kokusaiteki Shifuto', 'ratio': 0.1}]",共変量シフト
1226,1413,credit assignment,クレジット割り当て,0.6,10,"[{'word': 'クレジット割り当て', 'ratio': 0.6}, {'word': '報酬割り当て', 'ratio': 0.1}, {'word': '単位の割り当て', 'ratio': 0.1}, {'word': 'Kurieddo Shinsen', 'ratio': 0.1}, {'word': 'クレジット割当て', 'ratio': 0.1}]",クレジット割り当て
1227,1414,credit assignment problem,クレジット割り当て問題,0.5,10,"[{'word': 'クレジット割り当て問題', 'ratio': 0.5}, {'word': '報酬割り当て問題', 'ratio': 0.1}, {'word': '単位割り当て問題', 'ratio': 0.1}, {'word': '単位の割り当ての問題', 'ratio': 0.1}, {'word': 'Kurieddo Shinsen Mondai', 'ratio': 0.1}, {'word': 'クレジット割当て問題', 'ratio': 0.1}]",クレジット割り当て問題
1228,1415,criterion,基準,0.9,10,"[{'word': '基準', 'ratio': 0.9}, {'word': 'Kuriterion', 'ratio': 0.1}]",基準
1229,1416,critic,評価者,0.0,10,"[{'word': 'クリティック', 'ratio': 0.5}, {'word': '批評家', 'ratio': 0.2}, {'word': '評論家', 'ratio': 0.2}, {'word': 'Kirikku', 'ratio': 0.1}]",クリティック
1230,1417,critic loss,クリティック損失 (critic loss),0.0,9,"[{'word': 'クリティック損失', 'ratio': 0.6666666666666666}, {'word': '評論家ロス', 'ratio': 0.2222222222222222}, {'word': '批評家損失', 'ratio': 0.1111111111111111}]",クリティック損失
1231,1418,critic network,評価者ネットワーク,0.0,9,"[{'word': 'クリティックネットワーク', 'ratio': 0.6666666666666666}, {'word': '評論家ネットワーク', 'ratio': 0.2222222222222222}, {'word': '批評家ネットワーク', 'ratio': 0.1111111111111111}]",クリティックネットワーク
1232,1419,cross attention,クロスアテンション,1.0,9,"[{'word': 'クロスアテンション', 'ratio': 1.0}]",クロスアテンション
1233,1420,cross entropy,交差エントロピー,0.0,9,"[{'word': 'クロスエントロピー', 'ratio': 1.0}]",クロスエントロピー
1234,1421,cross entropy error,交差エントロピー誤差,0.0,9,"[{'word': 'クロスエントロピー誤差', 'ratio': 1.0}]",クロスエントロピー誤差
1235,1423,cross-attention layer,相互注目層,0.0,10,"[{'word': 'クロスアテンション層', 'ratio': 0.8}, {'word': 'クロスアテンションレイヤー', 'ratio': 0.2}]",クロスアテンション層
1236,1424,cross-attention module,クロスアテンションモジュール,0.9,10,"[{'word': 'クロスアテンションモジュール', 'ratio': 0.9}, {'word': 'クロスアテンション・モジュール', 'ratio': 0.1}]",クロスアテンションモジュール
1237,1425,cross-correlation,クロス相関 (Kurosu Sōkan),0.0,10,"[{'word': '相互相関', 'ratio': 0.8}, {'word': 'クロス相関', 'ratio': 0.1}, {'word': 'クロスコリレーション', 'ratio': 0.1}]",相互相関
1238,1426,cross-entropy loss function,交差エントロピー損失関数,0.3,10,"[{'word': 'クロスエントロピー損失関数', 'ratio': 0.7}, {'word': '交差エントロピー損失関数', 'ratio': 0.3}]",クロスエントロピー損失関数
1239,1427,cross-entropy objective,交差エントロピー目的関数,0.0,10,"[{'word': 'クロスエントロピー目的', 'ratio': 0.6}, {'word': '交差エントロピー目的', 'ratio': 0.1}, {'word': 'クロスエントロピーの目的', 'ratio': 0.1}, {'word': 'クロスエントロピー目標', 'ratio': 0.1}, {'word': 'クロスエントロピー目的関数', 'ratio': 0.1}]",クロスエントロピー目的
1240,1428,cross-lingual benchmark,言語横断ベンチマーク,0.0,10,"[{'word': 'クロスリンガルベンチマーク', 'ratio': 0.9}, {'word': '言語を超えたベンチマーク', 'ratio': 0.1}]",クロスリンガルベンチマーク
1241,1429,cross-lingual embedding,クロスリンガル埋め込み,0.8,10,"[{'word': 'クロスリンガル埋め込み', 'ratio': 0.8}, {'word': 'クロスリンガルエンベッディング', 'ratio': 0.1}, {'word': '言語を越えた埋め込み', 'ratio': 0.1}]",クロスリンガル埋め込み
1242,1430,cross-lingual feature,言語横断的特徴,0.0,10,"[{'word': 'クロスリンガル特徴', 'ratio': 0.8}, {'word': 'クロスリンガル機能', 'ratio': 0.2}]",クロスリンガル特徴
1243,1431,cross-lingual knowledge transfer,言語横断知識転移,0.0,10,"[{'word': 'クロスリンガル知識転送', 'ratio': 0.6}, {'word': 'クロスリンガル知識移転', 'ratio': 0.3}, {'word': '言語を超えた知識の伝達', 'ratio': 0.1}]",クロスリンガル知識転送
1244,1432,cross-lingual model,言語横断モデル,0.1,10,"[{'word': 'クロスリンガルモデル', 'ratio': 0.9}, {'word': '言語横断モデル', 'ratio': 0.1}]",クロスリンガルモデル
1245,1433,cross-lingual representation,クロスリンガル表現,0.8,10,"[{'word': 'クロスリンガル表現', 'ratio': 0.8}, {'word': '言語を超えた表現', 'ratio': 0.1}, {'word': '言語横断表現', 'ratio': 0.1}]",クロスリンガル表現
1246,1434,cross-lingual transfer,言語横断転移,0.0,10,"[{'word': 'クロスリンガルトランスファー', 'ratio': 0.5}, {'word': 'クロスリンガル転送', 'ratio': 0.2}, {'word': 'クロスリンガル・トランスファー', 'ratio': 0.1}, {'word': '言語を越えた転送', 'ratio': 0.1}, {'word': '言語横断転送', 'ratio': 0.1}]",クロスリンガルトランスファー
1247,1435,cross-modal,クロスモーダル,1.0,10,"[{'word': 'クロスモーダル', 'ratio': 1.0}]",クロスモーダル
1248,1436,cross-validating,クロスバリデーション,0.6,10,"[{'word': 'クロスバリデーション', 'ratio': 0.6}, {'word': '交差検証', 'ratio': 0.2}, {'word': 'こうさけんてい', 'ratio': 0.1}, {'word': '相互検証', 'ratio': 0.1}]",クロスバリデーション
1249,1437,cumulant generating function,累積生成関数,0.6,10,"[{'word': '累積生成関数', 'ratio': 0.6}, {'word': 'キュムラント生成関数', 'ratio': 0.3}, {'word': '縮約生成関数', 'ratio': 0.1}]",累積生成関数
1250,1438,cumulative density function,累積分布関数,0.0,10,"[{'word': '累積密度関数', 'ratio': 1.0}]",累積密度関数
1251,1439,cumulative distribution function,累積分布関数,1.0,10,"[{'word': '累積分布関数', 'ratio': 1.0}]",累積分布関数
1252,1440,cumulative regret,累積後悔,0.9,10,"[{'word': '累積後悔', 'ratio': 0.9}, {'word': '累積悔恨', 'ratio': 0.1}]",累積後悔
1253,1441,cumulative reward,累積報酬,1.0,10,"[{'word': '累積報酬', 'ratio': 1.0}]",累積報酬
1254,1442,curriculum learning,カリキュラム学習,1.0,9,"[{'word': 'カリキュラム学習', 'ratio': 1.0}]",カリキュラム学習
1255,1443,curse of dimensionality,次元の呪い,1.0,9,"[{'word': '次元の呪い', 'ratio': 1.0}]",次元の呪い
1256,1444,cutting plane,切断平面,0.1111111111111111,9,"[{'word': 'カッティングプレーン', 'ratio': 0.6666666666666666}, {'word': '切断機', 'ratio': 0.1111111111111111}, {'word': '切断平面', 'ratio': 0.1111111111111111}, {'word': '切断面', 'ratio': 0.1111111111111111}]",カッティングプレーン
1257,1445,cutting plane algorithm,切断平面アルゴリズム,0.1111111111111111,9,"[{'word': 'カッティングプレーンアルゴリズム', 'ratio': 0.6666666666666666}, {'word': '切断面アルゴリズム', 'ratio': 0.2222222222222222}, {'word': '切断平面アルゴリズム', 'ratio': 0.1111111111111111}]",カッティングプレーンアルゴリズム
1258,1446,cutting plane method,切断平面法,0.1111111111111111,9,"[{'word': 'カッティングプレーン法', 'ratio': 0.6666666666666666}, {'word': 'カッティングプレーン方式', 'ratio': 0.1111111111111111}, {'word': '切断平面法', 'ratio': 0.1111111111111111}, {'word': '切断面法', 'ratio': 0.1111111111111111}]",カッティングプレーン法
1259,1447,cycle consistency,循環一貫性,0.0,10,"[{'word': 'サイクル一貫性', 'ratio': 0.5}, {'word': 'サイクル整合性', 'ratio': 0.3}, {'word': 'サイクルの一貫性', 'ratio': 0.1}, {'word': 'サイクル一致', 'ratio': 0.1}]",サイクル一貫性
1260,1449,cycle inequality,環不等式,0.0,10,"[{'word': 'サイクル不等式', 'ratio': 0.8}, {'word': 'サイクル不平等', 'ratio': 0.1}, {'word': 'サイクルの不平等', 'ratio': 0.1}]",サイクル不等式
1261,1450,d-separation,d-分離,0.7,10,"[{'word': 'd-分離', 'ratio': 0.7}, {'word': 'd分離', 'ratio': 0.2}, {'word': 'dセパレーション', 'ratio': 0.1}]",d-分離
1262,1451,d_model,dモデル,0.1,10,"[{'word': 'd_model', 'ratio': 0.8}, {'word': 'dモデル', 'ratio': 0.1}, {'word': 'd_モデル', 'ratio': 0.1}]",d_model
1263,1452,data distribution,データ分布,0.8,10,"[{'word': 'データ分布', 'ratio': 0.8}, {'word': 'データ配布', 'ratio': 0.1}, {'word': 'データ配信', 'ratio': 0.1}]",データ分布
1264,1453,data imbalance,データ不均衡,0.5,10,"[{'word': 'データの不均衡', 'ratio': 0.5}, {'word': 'データ不均衡', 'ratio': 0.5}]",データの不均衡
1265,1454,data manifold,データ多様体,0.8,10,"[{'word': 'データ多様体', 'ratio': 0.8}, {'word': 'データマニホールド', 'ratio': 0.2}]",データ多様体
1266,1455,data mining,データマイニング,1.0,10,"[{'word': 'データマイニング', 'ratio': 1.0}]",データマイニング
1267,1456,data point,データポイント,1.0,10,"[{'word': 'データポイント', 'ratio': 1.0}]",データポイント
1268,1457,data processing inequality,データ処理の不等式,0.0,10,"[{'word': 'データ処理不等式', 'ratio': 0.8}, {'word': 'データ処理の不平等', 'ratio': 0.2}]",データ処理不等式
1269,1458,data sparseness,データの希薄性,0.7,10,"[{'word': 'データの希薄性', 'ratio': 0.7}, {'word': 'データのスパース性', 'ratio': 0.1}, {'word': 'データのまばらさ', 'ratio': 0.1}, {'word': 'データの疎性', 'ratio': 0.1}]",データの希薄性
1270,1459,data sparsity,データ疎性,0.0,10,"[{'word': 'データの疎性', 'ratio': 0.5}, {'word': 'データの希薄性', 'ratio': 0.2}, {'word': 'データのスパース性', 'ratio': 0.1}, {'word': 'データスパース性', 'ratio': 0.1}, {'word': 'データの希少性', 'ratio': 0.1}]",データの疎性
1271,1460,data structure,データ構造,1.0,10,"[{'word': 'データ構造', 'ratio': 1.0}]",データ構造
1272,1461,data vector,データベクトル,0.8,10,"[{'word': 'データベクトル', 'ratio': 0.8}, {'word': 'データベクター', 'ratio': 0.2}]",データベクトル
1273,1462,data-to-text generation,データからテキスト生成,0.6,10,"[{'word': 'データからテキスト生成', 'ratio': 0.6}, {'word': 'データからテキストへの生成', 'ratio': 0.2}, {'word': 'データからテキストへの変換', 'ratio': 0.1}, {'word': 'テキスト生成', 'ratio': 0.1}]",データからテキスト生成
1274,1463,dataset augmentation,データセット拡張,0.7,10,"[{'word': 'データセット拡張', 'ratio': 0.7}, {'word': 'データセットの拡張', 'ratio': 0.2}, {'word': 'データセット増加', 'ratio': 0.1}]",データセット拡張
1275,1464,dataset bias,データセットのバイアス,0.0,10,"[{'word': 'データセットバイアス', 'ratio': 0.9}, {'word': 'データセットの偏り', 'ratio': 0.1}]",データセットバイアス
1276,1465,dataset size,データセットサイズ,0.7,10,"[{'word': 'データセットサイズ', 'ratio': 0.7}, {'word': 'データセットのサイズ', 'ratio': 0.3}]",データセットサイズ
1277,1466,datasheet,データシート,1.0,10,"[{'word': 'データシート', 'ratio': 1.0}]",データシート
1278,1467,datum bias,データの偏り,0.0,10,"[{'word': 'データバイアス', 'ratio': 0.8}, {'word': 'データムバイアス', 'ratio': 0.1}, {'word': 'datumバイアス', 'ratio': 0.1}]",データバイアス
1279,1468,datum clustering,データクラスタリング,0.8,10,"[{'word': 'データクラスタリング', 'ratio': 0.8}, {'word': 'データ・クラスタリング', 'ratio': 0.1}, {'word': 'データムクラスタリング', 'ratio': 0.1}]",データクラスタリング
1280,1469,datum contamination,データ汚染,0.9,10,"[{'word': 'データ汚染', 'ratio': 0.9}, {'word': 'データム汚染', 'ratio': 0.1}]",データ汚染
1281,1471,datum fidelity,"- Term: ""データの忠実度""",0.0,10,"[{'word': 'データ忠実度', 'ratio': 0.6}, {'word': 'データの忠実度', 'ratio': 0.1}, {'word': 'データム忠実度', 'ratio': 0.1}, {'word': 'データ忠実性', 'ratio': 0.1}, {'word': 'データ適合性', 'ratio': 0.1}]",データ忠実度
1282,1472,datum filtering,データのフィルタリング,0.0,10,"[{'word': 'データフィルタリング', 'ratio': 0.8}, {'word': 'データ・フィルタリング', 'ratio': 0.1}, {'word': '日付フィルタリング', 'ratio': 0.1}]",データフィルタリング
1283,1473,datum generative process,データ生成プロセス,0.9,10,"[{'word': 'データ生成プロセス', 'ratio': 0.9}, {'word': 'データム生成プロセス', 'ratio': 0.1}]",データ生成プロセス
1284,1474,datum matrix,データ行列,0.7,10,"[{'word': 'データ行列', 'ratio': 0.7}, {'word': 'データマトリックス', 'ratio': 0.3}]",データ行列
1285,1475,datum mining algorithm,データマイニングアルゴリズム,0.8,10,"[{'word': 'データマイニングアルゴリズム', 'ratio': 0.8}, {'word': 'datum mining algorithm', 'ratio': 0.1}, {'word': 'データマイニング・アルゴリズム', 'ratio': 0.1}]",データマイニングアルゴリズム
1286,1476,datum parallelism,データ並列,0.0,10,"[{'word': 'データ並列性', 'ratio': 0.6}, {'word': '基準平行度', 'ratio': 0.2}, {'word': 'データ並列化', 'ratio': 0.1}, {'word': 'データ並列処理', 'ratio': 0.1}]",データ並列性
1287,1477,datum perturbation,データ撹乱,0.0,10,"[{'word': 'データ摂動', 'ratio': 0.9}, {'word': 'データパーテンション', 'ratio': 0.1}]",データ摂動
1288,1478,davinci,ダ・ヴィンチ,0.0,10,"[{'word': 'ダヴィンチ', 'ratio': 0.9}, {'word': 'ダビンチ', 'ratio': 0.1}]",ダヴィンチ
1289,1479,decay parameter,減衰パラメータ,0.8,10,"[{'word': '減衰パラメータ', 'ratio': 0.8}, {'word': 'ディケイパラメーター', 'ratio': 0.2}]",減衰パラメータ
1290,1480,decentralized algorithm,分散型アルゴリズム,0.8,10,"[{'word': '分散型アルゴリズム', 'ratio': 0.8}, {'word': '分散アルゴリズム', 'ratio': 0.2}]",分散型アルゴリズム
1291,1481,decision boundary,決定境界,1.0,10,"[{'word': '決定境界', 'ratio': 1.0}]",決定境界
1292,1482,decision function,決定関数,1.0,10,"[{'word': '決定関数', 'ratio': 1.0}]",決定関数
1293,1483,decision node,決定ノード,0.9,10,"[{'word': '決定ノード', 'ratio': 0.9}, {'word': '決定ノード決定ノード', 'ratio': 0.1}]",決定ノード
1294,1486,decision rule,決定規則,0.1,10,"[{'word': '決定ルール', 'ratio': 0.5}, {'word': '意思決定ルール', 'ratio': 0.2}, {'word': '決定規則', 'ratio': 0.1}, {'word': '決策ルール', 'ratio': 0.1}, {'word': '判定ルール', 'ratio': 0.1}]",決定ルール
1295,1487,decision space,決定空間,0.5,10,"[{'word': '決定空間', 'ratio': 0.5}, {'word': '意思決定空間', 'ratio': 0.3}, {'word': '意思決定スペース', 'ratio': 0.1}, {'word': '決策空間', 'ratio': 0.1}]",決定空間
1296,1488,decision stumps,決定スタンプ,0.5,10,"[{'word': '決定スタンプ', 'ratio': 0.5}, {'word': '決定打', 'ratio': 0.1}, {'word': '意思決定スタンプ', 'ratio': 0.1}, {'word': '決断の切り株', 'ratio': 0.1}, {'word': '決裁の木', 'ratio': 0.1}, {'word': '決定切り株', 'ratio': 0.1}]",決定スタンプ
1297,1489,decision theory,意思決定理論,0.5,10,"[{'word': '意思決定理論', 'ratio': 0.5}, {'word': '決定理論', 'ratio': 0.4}, {'word': '決定論', 'ratio': 0.1}]",意思決定理論
1298,1490,decision tree,決定木,1.0,10,"[{'word': '決定木', 'ratio': 1.0}]",決定木
1299,1491,decision variable,決定変数,0.9,10,"[{'word': '決定変数', 'ratio': 0.9}, {'word': '意思決定変数', 'ratio': 0.1}]",決定変数
1300,1492,decoder hidden state,デコーダー隠れ状態,0.2,10,"[{'word': 'デコーダ隠れ状態', 'ratio': 0.5}, {'word': 'デコーダの隠れ状態', 'ratio': 0.3}, {'word': 'デコーダー隠れ状態', 'ratio': 0.2}]",デコーダ隠れ状態
1301,1493,decoder layer,デコーダーレイヤー,0.3,10,"[{'word': 'デコーダ層', 'ratio': 0.5}, {'word': 'デコーダーレイヤー', 'ratio': 0.3}, {'word': 'デコーダー層', 'ratio': 0.2}]",デコーダ層
1302,1494,decoder network,デコーダーネットワーク,0.4,10,"[{'word': 'デコーダネットワーク', 'ratio': 0.6}, {'word': 'デコーダーネットワーク', 'ratio': 0.4}]",デコーダネットワーク
1303,1495,decoder output,デコーダー出力,0.5,10,"[{'word': 'デコーダ出力', 'ratio': 0.5}, {'word': 'デコーダー出力', 'ratio': 0.5}]",デコーダ出力
1304,1496,decoder state,デコーダー状態,0.4,10,"[{'word': 'デコーダ状態', 'ratio': 0.5}, {'word': 'デコーダー状態', 'ratio': 0.4}, {'word': 'デコーダの状態', 'ratio': 0.1}]",デコーダ状態
1305,1498,decoding algorithm,復号アルゴリズム,0.1,10,"[{'word': 'デコーディングアルゴリズム', 'ratio': 0.7}, {'word': '復号アルゴリズム', 'ratio': 0.1}, {'word': 'デコードアルゴリズム', 'ratio': 0.1}, {'word': '認識アルゴリズム', 'ratio': 0.1}]",デコーディングアルゴリズム
1306,1499,decoding problem,復号問題,0.0,10,"[{'word': 'デコーディング問題', 'ratio': 0.7}, {'word': '解読問題', 'ratio': 0.1}, {'word': 'デコードの問題', 'ratio': 0.1}, {'word': '認識問題', 'ratio': 0.1}]",デコーディング問題
1307,1500,decoding step,デコーディングステップ,0.8,10,"[{'word': 'デコーディングステップ', 'ratio': 0.8}, {'word': 'デコードステップ', 'ratio': 0.1}, {'word': '認識ステップ', 'ratio': 0.1}]",デコーディングステップ
1308,1501,decoding strategy,デコード戦略,0.1,10,"[{'word': 'デコーディング戦略', 'ratio': 0.7}, {'word': '解読戦略', 'ratio': 0.1}, {'word': 'デコード戦略', 'ratio': 0.1}, {'word': '認識戦略', 'ratio': 0.1}]",デコーディング戦略
1309,1502,decomposition,分解,1.0,10,"[{'word': '分解', 'ratio': 1.0}]",分解
1310,1503,decomposition method,分解法,0.7,10,"[{'word': '分解法', 'ratio': 0.7}, {'word': '分解方法', 'ratio': 0.1}, {'word': '→分解方法', 'ratio': 0.1}, {'word': '分解手法', 'ratio': 0.1}]",分解法
1311,1504,deconvolution,逆畳み込み,0.3,10,"[{'word': 'デコンボリューション', 'ratio': 0.5}, {'word': '逆畳み込み', 'ratio': 0.3}, {'word': 'デコンヴォルーション', 'ratio': 0.1}, {'word': 'デコボリューション', 'ratio': 0.1}]",デコンボリューション
1312,1505,deconvolution layer,デコンボリューション層,0.5,10,"[{'word': 'デコンボリューション層', 'ratio': 0.5}, {'word': '逆畳み込み層', 'ratio': 0.3}, {'word': 'デコンヴォルーション層', 'ratio': 0.1}, {'word': 'デコボリューション層', 'ratio': 0.1}]",デコンボリューション層
1313,1508,deep Q-network,深層Qネットワーク,0.3,10,"[{'word': 'ディープQネットワーク', 'ratio': 0.5}, {'word': '深層Qネットワーク', 'ratio': 0.3}, {'word': 'ディープ Q ネットワーク', 'ratio': 0.1}, {'word': '深層 Qネットワーク', 'ratio': 0.1}]",ディープQネットワーク
1314,1509,deep architecture,深層アーキテクチャ,0.4,10,"[{'word': 'ディープアーキテクチャ', 'ratio': 0.6}, {'word': '深層アーキテクチャ', 'ratio': 0.4}]",ディープアーキテクチャ
1315,1510,deep convolutional network,深層畳み込みネットワーク,0.5,10,"[{'word': '深層畳み込みネットワーク', 'ratio': 0.5}, {'word': 'ディープ畳み込みネットワーク', 'ratio': 0.4}, {'word': '深い畳み込みネットワーク', 'ratio': 0.1}]",深層畳み込みネットワーク
1316,1511,deep convolutional neural network,深層畳み込みニューラルネットワーク,0.5,10,"[{'word': '深層畳み込みニューラルネットワーク', 'ratio': 0.5}, {'word': 'ディープ畳み込みニューラルネットワーク', 'ratio': 0.4}, {'word': 'ディープ畳み込みニューラル ネットワーク', 'ratio': 0.1}]",深層畳み込みニューラルネットワーク
1317,1512,deep feature,深層特徴量,0.0,10,"[{'word': '深層特徴', 'ratio': 0.5}, {'word': 'ディープ特徴', 'ratio': 0.2}, {'word': '深い機能', 'ratio': 0.2}, {'word': '深い特徴', 'ratio': 0.1}]",深層特徴
1318,1513,deep generative model,深層生成モデル,0.6,10,"[{'word': '深層生成モデル', 'ratio': 0.6}, {'word': 'ディープ生成モデル', 'ratio': 0.2}, {'word': '深い生成モデル', 'ratio': 0.2}]",深層生成モデル
1319,1514,deep layer,深層,0.6,10,"[{'word': '深層', 'ratio': 0.6}, {'word': '深い層', 'ratio': 0.1}, {'word': 'ディープレイヤー', 'ratio': 0.1}, {'word': '深層層', 'ratio': 0.1}, {'word': 'ディープ生成モデル', 'ratio': 0.1}]",深層
1320,1515,deep learning architecture,ディープラーニングアーキテクチャ,0.2,10,"[{'word': '深層学習アーキテクチャ', 'ratio': 0.7}, {'word': 'ディープラーニングアーキテクチャ', 'ratio': 0.2}, {'word': '深層学習アーキテクチャー', 'ratio': 0.1}]",深層学習アーキテクチャ
1321,1516,deep learning framework,ディープラーニングフレームワーク,0.2,10,"[{'word': '深層学習フレームワーク', 'ratio': 0.8}, {'word': 'ディープラーニングフレームワーク', 'ratio': 0.2}]",深層学習フレームワーク
1322,1517,deep learning model,深層学習モデル,0.8888888888888888,9,"[{'word': '深層学習モデル', 'ratio': 0.8888888888888888}, {'word': 'ディープラーニングモデル', 'ratio': 0.1111111111111111}]",深層学習モデル
1323,1518,deep learning system,ディープラーニングシステム,0.1111111111111111,9,"[{'word': '深層学習システム', 'ratio': 0.8888888888888888}, {'word': 'ディープラーニングシステム', 'ratio': 0.1111111111111111}]",深層学習システム
1324,1519,deep model,深層モデル,0.6666666666666666,9,"[{'word': '深層モデル', 'ratio': 0.6666666666666666}, {'word': 'ディープモデル', 'ratio': 0.3333333333333333}]",深層モデル
1325,1521,deep network,深層ネットワーク,0.6666666666666666,9,"[{'word': '深層ネットワーク', 'ratio': 0.6666666666666666}, {'word': 'ディープネットワーク', 'ratio': 0.3333333333333333}]",深層ネットワーク
1326,1522,deep network architecture,深層ネットワークアーキテクチャ,0.6,10,"[{'word': '深層ネットワークアーキテクチャ', 'ratio': 0.6}, {'word': 'ディープネットワークアーキテクチャ', 'ratio': 0.3}, {'word': 'ディープ・ネットワーク・アーキテクチャ', 'ratio': 0.1}]",深層ネットワークアーキテクチャ
1327,1523,deep neural model,深層ニューラルモデル,0.6,10,"[{'word': '深層ニューラルモデル', 'ratio': 0.6}, {'word': 'ディープニューラルモデル', 'ratio': 0.4}]",深層ニューラルモデル
1328,1524,deep neural net,深層ニューラルネット,0.6,10,"[{'word': '深層ニューラルネット', 'ratio': 0.6}, {'word': 'ディープニューラルネット', 'ratio': 0.4}]",深層ニューラルネット
1329,1525,deep neural network,深層ニューラルネットワーク,0.5,10,"[{'word': '深層ニューラルネットワーク', 'ratio': 0.5}, {'word': 'ディープニューラルネットワーク', 'ratio': 0.4}, {'word': '深層ニューラルネット', 'ratio': 0.1}]",深層ニューラルネットワーク
1330,1526,deep reinforcement learning,深層強化学習,0.7,10,"[{'word': '深層強化学習', 'ratio': 0.7}, {'word': 'ディープ強化学習', 'ratio': 0.2}, {'word': '深層ニューラルネット', 'ratio': 0.1}]",深層強化学習
1331,1529,default logic,デフォルト論理,0.7,10,"[{'word': 'デフォルト論理', 'ratio': 0.7}, {'word': 'ディープスーパービジョンネット', 'ratio': 0.1}, {'word': 'デフォルトロジック', 'ratio': 0.1}, {'word': 'デフォルトのロジック', 'ratio': 0.1}]",デフォルト論理
1332,1530,deformable template,変形可能なテンプレート,0.1,10,"[{'word': '変形テンプレート', 'ratio': 0.5}, {'word': '変形可能テンプレート', 'ratio': 0.1}, {'word': 'デフォーマブルテンプレート', 'ratio': 0.1}, {'word': '形可能テンプレート', 'ratio': 0.1}, {'word': '変形可能なテンプレート', 'ratio': 0.1}, {'word': '可変形テンプレート', 'ratio': 0.1}]",変形テンプレート
1333,1531,deformation field,変形場,0.8,10,"[{'word': '変形場', 'ratio': 0.8}, {'word': '変形フィールド', 'ratio': 0.1}, {'word': '歪みフィールド', 'ratio': 0.1}]",変形場
1334,1533,delayed reward,遅延報酬,0.8888888888888888,9,"[{'word': '遅延報酬', 'ratio': 0.8888888888888888}, {'word': '遅れた報酬', 'ratio': 0.1111111111111111}]",遅延報酬
1335,1535,delta kernel,デルタカーネル,1.0,9,"[{'word': 'デルタカーネル', 'ratio': 1.0}]",デルタカーネル
1336,1537,denoiser,"""デノイザー""",0.0,9,"[{'word': 'デノイザー', 'ratio': 0.7777777777777778}, {'word': 'ノイズ除去器', 'ratio': 0.2222222222222222}]",デノイザー
1337,1538,denoising diffusion probabilistic model,デノイズ拡散確率モデル,0.0,9,"[{'word': 'デノイジング拡散確率モデル', 'ratio': 0.5555555555555556}, {'word': 'ノイズ拡散確率モデル', 'ratio': 0.2222222222222222}, {'word': 'ノイズ除去拡散確率モデル', 'ratio': 0.2222222222222222}]",デノイジング拡散確率モデル
1338,1539,denoising network,雑音除去ネットワーク,0.0,9,"[{'word': 'デノイジングネットワーク', 'ratio': 0.5555555555555556}, {'word': 'ノイズ除去ネットワーク', 'ratio': 0.4444444444444444}]",デノイジングネットワーク
1339,1540,denoising objective,ノイズ除去目標,0.0,9,"[{'word': 'デノイジング目的', 'ratio': 0.5555555555555556}, {'word': 'ノイズ除去目的', 'ratio': 0.4444444444444444}]",デノイジング目的
1340,1541,denoising process,雑音除去処理,0.0,9,"[{'word': 'デノイジングプロセス', 'ratio': 0.5555555555555556}, {'word': 'ノイズ除去処理', 'ratio': 0.2222222222222222}, {'word': 'ノイズ除去プロセス', 'ratio': 0.2222222222222222}]",デノイジングプロセス
1341,1542,denoising score matching,デノイズスコアマッチング,0.0,10,"[{'word': 'デノイジングスコアマッチング', 'ratio': 0.5}, {'word': 'ノイズ除去スコアマッチング', 'ratio': 0.5}]",デノイジングスコアマッチング
1342,1543,denoising score matching loss,スコアマッチング損失の雑音除去,0.0,10,"[{'word': 'ノイズ除去スコアマッチング損失', 'ratio': 0.5}, {'word': 'デノイジングスコアマッチング損失', 'ratio': 0.4}, {'word': 'デノイジングスコアマッチングロス', 'ratio': 0.1}]",ノイズ除去スコアマッチング損失
1343,1545,dense,密な,0.6,10,"[{'word': '密な', 'ratio': 0.6}, {'word': '濃い', 'ratio': 0.1}, {'word': '密集', 'ratio': 0.1}, {'word': '細密', 'ratio': 0.1}, {'word': '密', 'ratio': 0.1}]",密な
1344,1546,dense attention,密な注意,0.1,10,"[{'word': '密なアテンション', 'ratio': 0.6}, {'word': '注目度', 'ratio': 0.1}, {'word': '集中的な注意', 'ratio': 0.1}, {'word': '細密注意', 'ratio': 0.1}, {'word': '密な注意', 'ratio': 0.1}]",密なアテンション
1345,1547,dense depth map,密な深度マップ,0.6,10,"[{'word': '密な深度マップ', 'ratio': 0.6}, {'word': '高密度深度マップ', 'ratio': 0.2}, {'word': 'デプスマップ', 'ratio': 0.1}, {'word': '密集深度マップ', 'ratio': 0.1}]",密な深度マップ
1346,1548,dense feature,密な特徴量,0.1,10,"[{'word': '密な特徴', 'ratio': 0.5}, {'word': '高密度特徴', 'ratio': 0.2}, {'word': 'ディープ・フィーチャー', 'ratio': 0.1}, {'word': '密集特徴', 'ratio': 0.1}, {'word': '密な特徴量', 'ratio': 0.1}]",密な特徴
1347,1549,dense layer,密層,0.0,10,"[{'word': '密な層', 'ratio': 0.5}, {'word': '全結合層', 'ratio': 0.2}, {'word': 'みつそう', 'ratio': 0.1}, {'word': '緻密な層', 'ratio': 0.1}, {'word': '密集層', 'ratio': 0.1}]",密な層
1348,1551,dense network,密なネットワーク,0.5,10,"[{'word': '密なネットワーク', 'ratio': 0.5}, {'word': '高密度ネットワーク', 'ratio': 0.2}, {'word': '密集したネットワーク', 'ratio': 0.1}, {'word': '密集ネットワーク', 'ratio': 0.1}, {'word': '密ネットワーク', 'ratio': 0.1}]",密なネットワーク
1349,1552,dense prediction,密な予測,0.5,10,"[{'word': '密な予測', 'ratio': 0.5}, {'word': '密集予測', 'ratio': 0.2}, {'word': '密予測', 'ratio': 0.1}, {'word': 'デンス予測', 'ratio': 0.1}, {'word': '高密度予測', 'ratio': 0.1}]",密な予測
1350,1553,dense representation,密な表現,0.6,10,"[{'word': '密な表現', 'ratio': 0.6}, {'word': '密集表現', 'ratio': 0.2}, {'word': 'デンス表現', 'ratio': 0.1}, {'word': '高密度表現', 'ratio': 0.1}]",密な表現
1351,1555,density estimate,密度推定,1.0,10,"[{'word': '密度推定', 'ratio': 1.0}]",密度推定
1352,1556,density estimation,密度推定,0.6,10,"[{'word': '密度推定', 'ratio': 0.6}, {'word': '密度推定法', 'ratio': 0.4}]",密度推定
1353,1557,density estimator,密度推定器,0.9,10,"[{'word': '密度推定器', 'ratio': 0.9}, {'word': '密度推定量', 'ratio': 0.1}]",密度推定器
1354,1558,density field,密度場,0.9,10,"[{'word': '密度場', 'ratio': 0.9}, {'word': '密度フィールド', 'ratio': 0.1}]",密度場
1355,1559,density function,密度関数,1.0,10,"[{'word': '密度関数', 'ratio': 1.0}]",密度関数
1356,1560,density gradient,密度勾配,1.0,10,"[{'word': '密度勾配', 'ratio': 1.0}]",密度勾配
1357,1561,density ratio,密度比,0.9,10,"[{'word': '密度比', 'ratio': 0.9}, {'word': '密度比率', 'ratio': 0.1}]",密度比
1358,1563,dependency arc,依存アーク,0.1,10,"[{'word': '依存関係アーク', 'ratio': 0.6}, {'word': '依存性アーク', 'ratio': 0.2}, {'word': '従属アーク', 'ratio': 0.1}, {'word': '依存アーク', 'ratio': 0.1}]",依存関係アーク
1359,1564,dependency feature,依存特徴,0.1,10,"[{'word': '依存関係特徴', 'ratio': 0.5}, {'word': '依存性特徴', 'ratio': 0.2}, {'word': '依存機能', 'ratio': 0.1}, {'word': '依存特徴', 'ratio': 0.1}, {'word': '依存関係機能', 'ratio': 0.1}]",依存関係特徴
1360,1565,dependency graph,依存グラフ,0.8,10,"[{'word': '依存グラフ', 'ratio': 0.8}, {'word': '依存関係グラフ', 'ratio': 0.2}]",依存グラフ
1361,1566,dependency label,依存関係ラベル,0.2,10,"[{'word': '依存ラベル', 'ratio': 0.8}, {'word': '依存関係ラベル', 'ratio': 0.2}]",依存ラベル
1362,1567,dependency model,依存性モデル,0.0,10,"[{'word': '依存モデル', 'ratio': 0.8}, {'word': '依存関係モデル', 'ratio': 0.2}]",依存モデル
1363,1568,dependency parse,依存構文解析,0.5,10,"[{'word': '依存構文解析', 'ratio': 0.5}, {'word': '依存解析', 'ratio': 0.3}, {'word': '依存関係の解析', 'ratio': 0.2}]",依存構文解析
1364,1569,dependency parse tree,依存構文解析木,0.5,10,"[{'word': '依存構文解析木', 'ratio': 0.5}, {'word': '依存解析木', 'ratio': 0.3}, {'word': '依存関係解析ツリー', 'ratio': 0.2}]",依存構文解析木
1365,1570,dependency parser,依存構文解析器,0.8,10,"[{'word': '依存構文解析器', 'ratio': 0.8}, {'word': '依存関係パーサー', 'ratio': 0.2}]",依存構文解析器
1366,1571,dependency parsing model,依存構文解析モデル,0.8,10,"[{'word': '依存構文解析モデル', 'ratio': 0.8}, {'word': '依存関係解析モデル', 'ratio': 0.2}]",依存構文解析モデル
1367,1572,dependency path,依存関係パス,0.0,10,"[{'word': '依存経路', 'ratio': 0.6}, {'word': '依存パス', 'ratio': 0.3}, {'word': '依存関係のパス', 'ratio': 0.1}]",依存経路
1368,1573,dependency relation,依存関係,0.9,10,"[{'word': '依存関係', 'ratio': 0.9}, {'word': '従属関係', 'ratio': 0.1}]",依存関係
1369,1574,dependency representation,依存関係表現,0.0,10,"[{'word': '依存表現', 'ratio': 0.8}, {'word': '従属表現', 'ratio': 0.1}, {'word': '依存関係の表現', 'ratio': 0.1}]",依存表現
1370,1575,dependency structure,依存構造,0.7777777777777778,9,"[{'word': '依存構造', 'ratio': 0.7777777777777778}, {'word': '従属構造', 'ratio': 0.1111111111111111}, {'word': '依存関係構造', 'ratio': 0.1111111111111111}]",依存構造
1371,1576,dependency tree,依存木,0.6666666666666666,9,"[{'word': '依存木', 'ratio': 0.6666666666666666}, {'word': '従属木', 'ratio': 0.1111111111111111}, {'word': '依存関係ツリー', 'ratio': 0.1111111111111111}, {'word': '依存関係木', 'ratio': 0.1111111111111111}]",依存木
1372,1578,dependent variable,従属変数,0.8888888888888888,9,"[{'word': '従属変数', 'ratio': 0.8888888888888888}, {'word': '次元変数', 'ratio': 0.1111111111111111}]",従属変数
1373,1579,depth estimation,深度推定,0.8888888888888888,9,"[{'word': '深度推定', 'ratio': 0.8888888888888888}, {'word': '深さの推定', 'ratio': 0.1111111111111111}]",深度推定
1374,1580,depth estimator,深さ推定器,0.1,10,"[{'word': '深度推定器', 'ratio': 0.8}, {'word': '奥行き推定器', 'ratio': 0.1}, {'word': '深さ推定器', 'ratio': 0.1}]",深度推定器
1375,1581,depth image,深度画像,0.9,10,"[{'word': '深度画像', 'ratio': 0.9}, {'word': '奥行き画像', 'ratio': 0.1}]",深度画像
1376,1582,depth map,奥行きマップ,0.0,10,"[{'word': '深度マップ', 'ratio': 0.9}, {'word': '深度画像', 'ratio': 0.1}]",深度マップ
1377,1583,depth prediction,深度予測,0.9,10,"[{'word': '深度予測', 'ratio': 0.9}, {'word': 'depth prediction', 'ratio': 0.1}]",深度予測
1378,1584,depth-first search,深さ優先探索,0.8,10,"[{'word': '深さ優先探索', 'ratio': 0.8}, {'word': '深さ優先検索', 'ratio': 0.1}, {'word': '深度探索', 'ratio': 0.1}]",深さ優先探索
1379,1585,description logic,記述論理,0.5,10,"[{'word': '記述論理', 'ratio': 0.5}, {'word': '説明論理', 'ratio': 0.3}, {'word': '記述ロジック', 'ratio': 0.1}, {'word': '説明ロジック', 'ratio': 0.1}]",記述論理
1380,1586,descriptor,記述子,0.4,10,"[{'word': 'ディスクリプタ', 'ratio': 0.6}, {'word': '記述子', 'ratio': 0.4}]",ディスクリプタ
1381,1587,design matrix,設計行列,0.3,10,"[{'word': 'デザイン行列', 'ratio': 0.5}, {'word': '設計行列', 'ratio': 0.3}, {'word': 'デザインマトリックス', 'ratio': 0.2}]",デザイン行列
1382,1589,det,行列式,0.8,10,"[{'word': '行列式', 'ratio': 0.8}, {'word': 'デット', 'ratio': 0.1}, {'word': 'の', 'ratio': 0.1}]",行列式
1383,1590,detection,検出,1.0,20,"[{'word': '検出', 'ratio': 1.0}]",検出
1384,1591,detection algorithm,検出アルゴリズム,1.0,10,"[{'word': '検出アルゴリズム', 'ratio': 1.0}]",検出アルゴリズム
1385,1592,detection model,検出モデル,1.0,10,"[{'word': '検出モデル', 'ratio': 1.0}]",検出モデル
1386,1593,detection score,検出スコア,1.0,10,"[{'word': '検出スコア', 'ratio': 1.0}]",検出スコア
1387,1594,detection window,検出ウィンドウ,1.0,10,"[{'word': '検出ウィンドウ', 'ratio': 1.0}]",検出ウィンドウ
1388,1595,detector,検出器,1.0,10,"[{'word': '検出器', 'ratio': 1.0}]",検出器
1389,1596,deterministic algorithm,決定論的アルゴリズム,1.0,10,"[{'word': '決定論的アルゴリズム', 'ratio': 1.0}]",決定論的アルゴリズム
1390,1597,deterministic annealing,決定論的アニーリング,0.6,10,"[{'word': '決定論的アニーリング', 'ratio': 0.6}, {'word': '決定的アニーリング', 'ratio': 0.3}, {'word': '決定論的annealing', 'ratio': 0.1}]",決定論的アニーリング
1391,1598,deterministic automaton,確定的オートマトン,0.0,10,"[{'word': '決定論的オートマトン', 'ratio': 0.8}, {'word': '決定論的自動機  Copy', 'ratio': 0.1}, {'word': '決定的オートマトン', 'ratio': 0.1}]",決定論的オートマトン
1392,1599,deterministic baseline,決定論的ベースライン,0.8,10,"[{'word': '決定論的ベースライン', 'ratio': 0.8}, {'word': '決定的なベースライン', 'ratio': 0.1}, {'word': '決定論的基準', 'ratio': 0.1}]",決定論的ベースライン
1393,1600,deterministic finite automaton,確定性有限オートマトン (DFA),0.0,10,"[{'word': '決定論的有限オートマトン', 'ratio': 0.7}, {'word': '決定性有限オートマトン', 'ratio': 0.3}]",決定論的有限オートマトン
1394,1601,deterministic policy,確定的ポリシー,0.0,10,"[{'word': '決定論的ポリシー', 'ratio': 0.8}, {'word': '決定的な政策', 'ratio': 0.1}, {'word': '決定論的政策', 'ratio': 0.1}]",決定論的ポリシー
1395,1602,deterministic rule,決定論的ルール,0.8,10,"[{'word': '決定論的ルール', 'ratio': 0.8}, {'word': '決定的な規則', 'ratio': 0.1}, {'word': '決定論的規則', 'ratio': 0.1}]",決定論的ルール
1396,1603,dev set,評価用データセット,0.0,10,"[{'word': '開発セット', 'ratio': 0.7}, {'word': '検証セット', 'ratio': 0.1}, {'word': 'デバッグセット', 'ratio': 0.1}, {'word': '検証データセット', 'ratio': 0.1}]",開発セット
1397,1604,development set,開発セット,1.0,10,"[{'word': '開発セット', 'ratio': 1.0}]",開発セット
1398,1605,diagonal matrix,対角行列,1.0,10,"[{'word': '対角行列', 'ratio': 1.0}]",対角行列
1399,1606,dialog system,対話システム,0.4,10,"[{'word': 'ダイアログシステム', 'ratio': 0.6}, {'word': '対話システム', 'ratio': 0.4}]",ダイアログシステム
1400,1607,dialogue act,対話行為,0.6,10,"[{'word': '対話行為', 'ratio': 0.6}, {'word': 'ダイアログ行為', 'ratio': 0.2}, {'word': 'ダイアログアクト', 'ratio': 0.1}, {'word': '会話行為', 'ratio': 0.1}]",対話行為
1401,1612,dialogue state,対話状態,0.5,10,"[{'word': '対話状態', 'ratio': 0.5}, {'word': 'ダイアログ状態', 'ratio': 0.4}, {'word': '会話状態', 'ratio': 0.1}]",対話状態
1402,1614,dialogue system,対話システム,0.7,10,"[{'word': '対話システム', 'ratio': 0.7}, {'word': 'ダイアログシステム', 'ratio': 0.2}, {'word': '会話システム', 'ratio': 0.1}]",対話システム
1403,1615,dialogue turn,対話ターン,0.6,10,"[{'word': '対話ターン', 'ratio': 0.6}, {'word': 'ダイアログターン', 'ratio': 0.3}, {'word': '会話ターン', 'ratio': 0.1}]",対話ターン
1404,1616,dictionary learning,辞書学習,1.0,10,"[{'word': '辞書学習', 'ratio': 1.0}]",辞書学習
1405,1617,dictionary matrix,辞書行列,1.0,10,"[{'word': '辞書行列', 'ratio': 1.0}]",辞書行列
1406,1618,diffeomorphism,微分同相写像,0.2,10,"[{'word': '微分同相', 'ratio': 0.5}, {'word': '微分同相写像', 'ratio': 0.2}, {'word': '差動', 'ratio': 0.1}, {'word': '微分同型射', 'ratio': 0.1}, {'word': '微分同相変換', 'ratio': 0.1}]",微分同相
1407,1619,differentiable function,微分可能関数,0.9,10,"[{'word': '微分可能関数', 'ratio': 0.9}, {'word': '微分可能な関数', 'ratio': 0.1}]",微分可能関数
1408,1620,differentiable renderer,微分可能なレンダラー,0.1,10,"[{'word': '微分可能レンダラー', 'ratio': 0.9}, {'word': '微分可能なレンダラー', 'ratio': 0.1}]",微分可能レンダラー
1409,1621,differentiable rendering,微分可能なレンダリング,0.1,10,"[{'word': '微分可能レンダリング', 'ratio': 0.9}, {'word': '微分可能なレンダリング', 'ratio': 0.1}]",微分可能レンダリング
1410,1622,differentiable rendering function,微分可能なレンダリング関数,0.0,10,"[{'word': '微分可能レンダリング関数', 'ratio': 1.0}]",微分可能レンダリング関数
1411,1623,differential entropy,微分エントロピー,0.9,10,"[{'word': '微分エントロピー', 'ratio': 0.9}, {'word': '差分энтропی', 'ratio': 0.1}]",微分エントロピー
1412,1624,differential privacy,差分プライバシー,0.8,10,"[{'word': '差分プライバシー', 'ratio': 0.8}, {'word': '微分プライバシー', 'ratio': 0.2}]",差分プライバシー
1413,1625,diffusion matrix,拡散行列,0.8,10,"[{'word': '拡散行列', 'ratio': 0.8}, {'word': '拡散マトリックス', 'ratio': 0.2}]",拡散行列
1414,1626,diffusion model,拡散モデル,0.8,10,"[{'word': '拡散モデル', 'ratio': 0.8}, {'word': '普及モデル', 'ratio': 0.2}]",拡散モデル
1415,1627,diffusion tensor,拡散テンソル,0.9,10,"[{'word': '拡散テンソル', 'ratio': 0.9}, {'word': 'テンソル拡散', 'ratio': 0.1}]",拡散テンソル
1416,1628,digamma function,ディガンマ関数,1.0,10,"[{'word': 'ディガンマ関数', 'ratio': 1.0}]",ディガンマ関数
1417,1629,digit classification,数字分類,0.9,10,"[{'word': '数字分類', 'ratio': 0.9}, {'word': '桁分類', 'ratio': 0.1}]",数字分類
1418,1630,dilated convolution,希釈畳み込み,0.0,10,"[{'word': '拡張畳み込み', 'ratio': 0.5}, {'word': '膨張畳み込み', 'ratio': 0.4}, {'word': '指数畳み込み', 'ratio': 0.1}]",拡張畳み込み
1419,1631,dilation,膨張,0.8,10,"[{'word': '膨張', 'ratio': 0.8}, {'word': 'ダイレーション', 'ratio': 0.1}, {'word': '拡張', 'ratio': 0.1}]",膨張
1420,1632,dim,次元,0.8,10,"[{'word': '次元', 'ratio': 0.8}, {'word': '朦朧', 'ratio': 0.1}, {'word': '薄暗い', 'ratio': 0.1}]",次元
1421,1633,dimension,次元,0.7,10,"[{'word': '次元', 'ratio': 0.7}, {'word': '寸法', 'ratio': 0.3}]",次元
1422,1634,dimension reduction,次元削減,0.8,10,"[{'word': '次元削減', 'ratio': 0.8}, {'word': 'ディメンション・リダクション', 'ratio': 0.1}, {'word': '寸法削減', 'ratio': 0.1}]",次元削減
1423,1635,dimensional vector,次元ベクトル,1.0,10,"[{'word': '次元ベクトル', 'ratio': 1.0}]",次元ベクトル
1424,1636,dimensionality,次元数,0.6,10,"[{'word': '次元数', 'ratio': 0.6}, {'word': '次元性', 'ratio': 0.3}, {'word': 'ディメンショナリティ', 'ratio': 0.1}]",次元数
1425,1637,dimensionality reduction,次元削減,1.0,10,"[{'word': '次元削減', 'ratio': 1.0}]",次元削減
1426,1638,directed acyclic graph,非循環有向グラフ,0.0,10,"[{'word': '有向非巡回グラフ', 'ratio': 0.7}, {'word': '有向非循環グラフ', 'ratio': 0.3}]",有向非巡回グラフ
1427,1639,directed edge,直接エッジ,0.0,10,"[{'word': '有向辺', 'ratio': 0.7}, {'word': '有向端', 'ratio': 0.2}, {'word': '有向エッジ', 'ratio': 0.1}]",有向辺
1428,1640,directed graph,直接グラフ,0.0,10,"[{'word': '有向グラフ', 'ratio': 1.0}]",有向グラフ
1429,1641,directed graphical model,直接グラフィカルモデル,0.0,10,"[{'word': '有向グラフィカルモデル', 'ratio': 0.9}, {'word': '有向グラフィカルモデリング', 'ratio': 0.1}]",有向グラフィカルモデル
1430,1642,directed tree,直接木,0.0,10,"[{'word': '有向木', 'ratio': 1.0}]",有向木
1431,1644,discount factor,割引率,0.6,10,"[{'word': '割引率', 'ratio': 0.6}, {'word': '割引係数', 'ratio': 0.4}]",割引率
1432,1645,discount parameter,割引パラメータ,0.8,10,"[{'word': '割引パラメータ', 'ratio': 0.8}, {'word': 'discount parameter', 'ratio': 0.1}, {'word': '割引パラメーター', 'ratio': 0.1}]",割引パラメータ
1433,1646,discounted cumulative reward,割引累積報酬,0.8,10,"[{'word': '割引累積報酬', 'ratio': 0.8}, {'word': '割引された累積報酬', 'ratio': 0.2}]",割引累積報酬
1434,1647,discounted return,割引リターン,0.6,10,"[{'word': '割引リターン', 'ratio': 0.6}, {'word': '割引返品', 'ratio': 0.2}, {'word': '割引返済', 'ratio': 0.1}, {'word': '割引収益', 'ratio': 0.1}]",割引リターン
1435,1648,discounted reward,割引報酬,0.8,10,"[{'word': '割引報酬', 'ratio': 0.8}, {'word': '割引特典', 'ratio': 0.2}]",割引報酬
1436,1649,discounted state distribution,割引状態分布,0.9,10,"[{'word': '割引状態分布', 'ratio': 0.9}, {'word': '割引状態の分布', 'ratio': 0.1}]",割引状態分布
1437,1650,discrete distribution,離散分布,0.9,10,"[{'word': '離散分布', 'ratio': 0.9}, {'word': '離散分布割引状態分布', 'ratio': 0.1}]",離散分布
1438,1651,discrete graphical model,離散グラフィカルモデル,0.9,10,"[{'word': '離散グラフィカルモデル', 'ratio': 0.9}, {'word': '離散グラフモデル', 'ratio': 0.1}]",離散グラフィカルモデル
1439,1652,discrete random variable,離散確率変数,1.0,10,"[{'word': '離散確率変数', 'ratio': 1.0}]",離散確率変数
1440,1653,discriminant analysis,識別分析 (shikibetsu bunseki),0.0,10,"[{'word': '判別分析', 'ratio': 1.0}]",判別分析
1441,1654,discriminant function,判別関数,1.0,10,"[{'word': '判別関数', 'ratio': 1.0}]",判別関数
1442,1655,discriminative,判別,0.0,10,"[{'word': '判別的', 'ratio': 0.6}, {'word': '識別的', 'ratio': 0.2}, {'word': '差別的', 'ratio': 0.1}, {'word': '差別的な', 'ratio': 0.1}]",判別的
1443,1656,discriminative approach,識別的アプローチ,0.2,10,"[{'word': '判別的アプローチ', 'ratio': 0.5}, {'word': '識別的アプローチ', 'ratio': 0.2}, {'word': '差別的アプローチ', 'ratio': 0.1}, {'word': '差別的なアプローチ', 'ratio': 0.1}, {'word': '判別アプローチ', 'ratio': 0.1}]",判別的アプローチ
1444,1659,discriminative model,識別モデル,0.6,10,"[{'word': '識別モデル', 'ratio': 0.6}, {'word': '判別モデル', 'ratio': 0.3}, {'word': '区別型モデル', 'ratio': 0.1}]",識別モデル
1445,1662,disentangle,属性を解きほぐす (zokuhogu),0.0,10,"[{'word': '解きほぐす', 'ratio': 0.5}, {'word': '分離する', 'ratio': 0.4}, {'word': 'もつれを解く', 'ratio': 0.1}]",解きほぐす
1446,1664,disparity estimation,視差推定,0.5,10,"[{'word': '視差推定', 'ratio': 0.5}, {'word': '不一致推定', 'ratio': 0.2}, {'word': '格差推定', 'ratio': 0.1}, {'word': '差異推定', 'ratio': 0.1}, {'word': '奥行き推定', 'ratio': 0.1}]",視差推定
1447,1665,disparity map,視差マップ,0.6,10,"[{'word': '視差マップ', 'ratio': 0.6}, {'word': '不一致マップ', 'ratio': 0.2}, {'word': '格差マップ', 'ratio': 0.1}, {'word': '奥行きマップ', 'ratio': 0.1}]",視差マップ
1448,1666,distance function,距離関数,1.0,10,"[{'word': '距離関数', 'ratio': 1.0}]",距離関数
1449,1667,distance matrix,距離行列,1.0,10,"[{'word': '距離行列', 'ratio': 1.0}]",距離行列
1450,1668,distance measure,距離尺度,0.2,10,"[{'word': '距離測定', 'ratio': 0.6}, {'word': '距離尺度', 'ratio': 0.2}, {'word': '距離測度', 'ratio': 0.1}, {'word': '距離の尺度', 'ratio': 0.1}]",距離測定
1451,1669,distance metric,距離尺度,0.6,10,"[{'word': '距離尺度', 'ratio': 0.6}, {'word': '距離メトリック', 'ratio': 0.3}, {'word': '距離計測', 'ratio': 0.1}]",距離尺度
1452,1670,distance transform,距離変換,1.0,10,"[{'word': '距離変換', 'ratio': 1.0}]",距離変換
1453,1671,distant supervision,遠隔監視,0.9,10,"[{'word': '遠隔監視', 'ratio': 0.9}, {'word': '遠隔指導', 'ratio': 0.1}]",遠隔監視
1454,1672,distillation,蒸留,0.9,10,"[{'word': '蒸留', 'ratio': 0.9}, {'word': 'DISTILLATION', 'ratio': 0.1}]",蒸留
1455,1673,distributed information retrieval,分散情報検索,0.9,10,"[{'word': '分散情報検索', 'ratio': 0.9}, {'word': '分散型情報検索', 'ratio': 0.1}]",分散情報検索
1456,1674,distributed learning,分散学習,1.0,10,"[{'word': '分散学習', 'ratio': 1.0}]",分散学習
1457,1675,distributed learning system,分散学習システム,1.0,10,"[{'word': '分散学習システム', 'ratio': 1.0}]",分散学習システム
1458,1676,distributed representation,分散表現,0.9,10,"[{'word': '分散表現', 'ratio': 0.9}, {'word': '分布表現', 'ratio': 0.1}]",分散表現
1459,1677,distribution shift,分布シフト,0.9,10,"[{'word': '分布シフト', 'ratio': 0.9}, {'word': '分布の変化', 'ratio': 0.1}]",分布シフト
1460,1678,distribution vector,分布ベクトル,1.0,10,"[{'word': '分布ベクトル', 'ratio': 1.0}]",分布ベクトル
1461,1679,distributional,分布的,0.8,10,"[{'word': '分布的', 'ratio': 0.8}, {'word': 'ぶんぷ', 'ratio': 0.1}, {'word': '分布的な', 'ratio': 0.1}]",分布的
1462,1680,distributional feature,分布特徴,0.0,10,"[{'word': '分布的特徴', 'ratio': 0.8}, {'word': '分布の特徴', 'ratio': 0.1}, {'word': '配信機能', 'ratio': 0.1}]",分布的特徴
1463,1681,distributional hypothesis,分布仮説,1.0,10,"[{'word': '分布仮説', 'ratio': 1.0}]",分布仮説
1464,1682,distributional model,分布モデル,1.0,10,"[{'word': '分布モデル', 'ratio': 1.0}]",分布モデル
1465,1683,distributional representation,分布表現,1.0,10,"[{'word': '分布表現', 'ratio': 1.0}]",分布表現
1466,1685,distributional semantic model,分布意味論モデル,0.5,10,"[{'word': '分布意味論モデル', 'ratio': 0.5}, {'word': '配分意味論モデル', 'ratio': 0.2}, {'word': '分布意味モデル', 'ratio': 0.1}, {'word': '分散意味論モデル', 'ratio': 0.1}, {'word': '分布的意味論モデル', 'ratio': 0.1}]",分布意味論モデル
1467,1686,distributional similarity,分布的類似性,0.1,10,"[{'word': '分布類似性', 'ratio': 0.6}, {'word': '配分類似性', 'ratio': 0.2}, {'word': '分布の類似性', 'ratio': 0.1}, {'word': '分布的類似性', 'ratio': 0.1}]",分布類似性
1468,1689,divergence operator,発散演算子,0.3,10,"[{'word': 'ダイバージェンス演算子', 'ratio': 0.6}, {'word': '発散演算子', 'ratio': 0.3}, {'word': 'divergence 演算子', 'ratio': 0.1}]",ダイバージェンス演算子
1469,1690,diversity score,多様性スコア,0.9,10,"[{'word': '多様性スコア', 'ratio': 0.9}, {'word': 'ダイバーシティスコア', 'ratio': 0.1}]",多様性スコア
1470,1692,document,文書,0.25,20,"[{'word': '文書', 'ratio': 0.5}, {'word': 'ドキュメント', 'ratio': 0.45}, {'word': '書類', 'ratio': 0.05}]",文書
1471,1693,document classification,文書分類,0.5,10,"[{'word': '文書分類', 'ratio': 0.5}, {'word': 'ドキュメント分類', 'ratio': 0.4}, {'word': 'document classification', 'ratio': 0.1}]",文書分類
1472,1694,document clustering,文書クラスタリング,0.5,10,"[{'word': '文書クラスタリング', 'ratio': 0.5}, {'word': 'ドキュメントクラスタリング', 'ratio': 0.4}, {'word': 'ドキュメントのクラスタリング', 'ratio': 0.1}]",文書クラスタリング
1473,1695,document corpus,文書コーパス,0.6,10,"[{'word': '文書コーパス', 'ratio': 0.6}, {'word': 'ドキュメントコーパス', 'ratio': 0.4}]",文書コーパス
1474,1696,document retrieval,文書検索,0.5,10,"[{'word': '文書検索', 'ratio': 0.5}, {'word': 'ドキュメント検索', 'ratio': 0.4}, {'word': '文書の検索', 'ratio': 0.1}]",文書検索
1475,1697,document summarization,文書要約,0.7,10,"[{'word': '文書要約', 'ratio': 0.7}, {'word': '文書の要約', 'ratio': 0.1}, {'word': 'ドキュメントサマリゼーション', 'ratio': 0.1}, {'word': 'ドキュメント要約', 'ratio': 0.1}]",文書要約
1476,1698,document vector,文書ベクトル,0.6,10,"[{'word': '文書ベクトル', 'ratio': 0.6}, {'word': 'ドキュメントベクトル', 'ratio': 0.3}, {'word': '文書ベクター', 'ratio': 0.1}]",文書ベクトル
1477,1699,document-level,ドキュメントレベル,0.3,10,"[{'word': '文書レベル', 'ratio': 0.7}, {'word': 'ドキュメントレベル', 'ratio': 0.3}]",文書レベル
1478,1701,domain,ドメイン,1.0,20,"[{'word': 'ドメイン', 'ratio': 1.0}]",ドメイン
1479,1702,domain element,ドメイン要素,1.0,10,"[{'word': 'ドメイン要素', 'ratio': 1.0}]",ドメイン要素
1480,1703,domain gap,ドメインギャップ,0.9,10,"[{'word': 'ドメインギャップ', 'ratio': 0.9}, {'word': 'ドメイングラフ', 'ratio': 0.1}]",ドメインギャップ
1481,1704,domain generalization,ドメイン汎化,0.0,10,"[{'word': 'ドメイン一般化', 'ratio': 0.8}, {'word': '領域一般化', 'ratio': 0.1}, {'word': 'ドメインの一般化', 'ratio': 0.1}]",ドメイン一般化
1482,1705,domain knowledge,ドメイン知識,0.9,10,"[{'word': 'ドメイン知識', 'ratio': 0.9}, {'word': '領域知識', 'ratio': 0.1}]",ドメイン知識
1483,1706,domain mismatch,ドメインミスマッチ,0.7,10,"[{'word': 'ドメインミスマッチ', 'ratio': 0.7}, {'word': 'ドメイン不一致', 'ratio': 0.2}, {'word': 'ドメインの不一致', 'ratio': 0.1}]",ドメインミスマッチ
1484,1707,domain ontology,ドメインオントロジー,1.0,10,"[{'word': 'ドメインオントロジー', 'ratio': 1.0}]",ドメインオントロジー
1485,1708,domain shift,ドメインシフト,1.0,10,"[{'word': 'ドメインシフト', 'ratio': 1.0}]",ドメインシフト
1486,1709,domain transfer,ドメイン移管,0.1,10,"[{'word': 'ドメイン転送', 'ratio': 0.9}, {'word': 'ドメイン移管', 'ratio': 0.1}]",ドメイン転送
1487,1710,domain-specific,ドメイン固有の,0.1,10,"[{'word': 'ドメイン固有', 'ratio': 0.5}, {'word': 'ドメイン特化型', 'ratio': 0.3}, {'word': 'ドメイン固有の', 'ratio': 0.1}, {'word': 'ドメイン特異的', 'ratio': 0.1}]",ドメイン固有
1488,1711,dot product,内積,0.4,10,"[{'word': 'ドット積', 'ratio': 0.6}, {'word': '内積', 'ratio': 0.4}]",ドット積
1489,1713,down-sampling,ダウンサンプリング,1.0,10,"[{'word': 'ダウンサンプリング', 'ratio': 1.0}]",ダウンサンプリング
1490,1714,down-sampling layer,ダウンサンプリング層,1.0,10,"[{'word': 'ダウンサンプリング層', 'ratio': 1.0}]",ダウンサンプリング層
1491,1715,downsampling block,ダウンサンプリングブロック,1.0,10,"[{'word': 'ダウンサンプリングブロック', 'ratio': 1.0}]",ダウンサンプリングブロック
1492,1716,downsampling factor,ダウンサンプリング係数,0.8,10,"[{'word': 'ダウンサンプリング係数', 'ratio': 0.8}, {'word': 'ダウンサンプリングファクター', 'ratio': 0.2}]",ダウンサンプリング係数
1493,1717,downsampling layer,ダウンサンプリング層,1.0,10,"[{'word': 'ダウンサンプリング層', 'ratio': 1.0}]",ダウンサンプリング層
1494,1718,downstream dataset,下流データセット,0.3,10,"[{'word': 'ダウンストリームデータセット', 'ratio': 0.6}, {'word': '下流データセット', 'ratio': 0.3}, {'word': '下流のデータセット', 'ratio': 0.1}]",ダウンストリームデータセット
1495,1719,downstream model,ダウンストリームモデル,0.5,10,"[{'word': 'ダウンストリームモデル', 'ratio': 0.5}, {'word': '下流モデル', 'ratio': 0.5}]",ダウンストリームモデル
1496,1721,downstream task,下流タスク,0.4,10,"[{'word': 'ダウンストリームタスク', 'ratio': 0.5}, {'word': '下流タスク', 'ratio': 0.4}, {'word': '下流性能', 'ratio': 0.1}]",ダウンストリームタスク
1497,1722,dropout layer,ドロップアウト層,0.9,10,"[{'word': 'ドロップアウト層', 'ratio': 0.9}, {'word': 'ドロップアウトレイヤ', 'ratio': 0.1}]",ドロップアウト層
1498,1723,dropout probability,ドロップアウト確率,0.9,10,"[{'word': 'ドロップアウト確率', 'ratio': 0.9}, {'word': 'ドロップアウトの確率', 'ratio': 0.1}]",ドロップアウト確率
1499,1724,dropout rate,ドロップアウト率,0.8,10,"[{'word': 'ドロップアウト率', 'ratio': 0.8}, {'word': '退学率', 'ratio': 0.1}, {'word': '中退率', 'ratio': 0.1}]",ドロップアウト率
1500,1726,dual decomposition,二重分解,0.8,10,"[{'word': '二重分解', 'ratio': 0.8}, {'word': '二元分解', 'ratio': 0.1}, {'word': '双対分解', 'ratio': 0.1}]",二重分解
1501,1727,dual encoder model,デュアルエンコーダーモデル,0.3,10,"[{'word': '二重エンコーダーモデル', 'ratio': 0.5}, {'word': 'デュアルエンコーダーモデル', 'ratio': 0.3}, {'word': '二重エンコーダモデル', 'ratio': 0.1}, {'word': '双対エンコーダモデル', 'ratio': 0.1}]",二重エンコーダーモデル
1502,1728,dual norm,双対ノルム,0.8,10,"[{'word': '双対ノルム', 'ratio': 0.8}, {'word': 'デュアルノルム', 'ratio': 0.1}, {'word': '二重規範', 'ratio': 0.1}]",双対ノルム
1503,1729,dual objective,二重目的,0.1,10,"[{'word': '双対目的', 'ratio': 0.5}, {'word': '双対目的関数', 'ratio': 0.3}, {'word': '二重目的', 'ratio': 0.1}, {'word': '二重の目的', 'ratio': 0.1}]",双対目的
1504,1730,dual optimization problem,双対最適化問題,0.8,10,"[{'word': '双対最適化問題', 'ratio': 0.8}, {'word': '二重最適化問題', 'ratio': 0.2}]",双対最適化問題
1505,1731,dual parameter,二重パラメータ,0.0,10,"[{'word': '双対パラメータ', 'ratio': 0.8}, {'word': 'デュアルパラメータ', 'ratio': 0.2}]",双対パラメータ
1506,1732,dual problem,双対問題,0.8,10,"[{'word': '双対問題', 'ratio': 0.8}, {'word': '二重問題', 'ratio': 0.1}, {'word': '二重の問題', 'ratio': 0.1}]",双対問題
1507,1733,dual program,デュアルプログラム,0.2,10,"[{'word': '双対プログラム', 'ratio': 0.6}, {'word': 'デュアルプログラム', 'ratio': 0.2}, {'word': '双対計画', 'ratio': 0.1}, {'word': '二重問題', 'ratio': 0.1}]",双対プログラム
1508,1734,dual solution,双対解,0.7,10,"[{'word': '双対解', 'ratio': 0.7}, {'word': 'デュアルソリューション', 'ratio': 0.2}, {'word': '二重解', 'ratio': 0.1}]",双対解
1509,1735,dual variable,双対変数,0.7,10,"[{'word': '双対変数', 'ratio': 0.7}, {'word': '二重変数', 'ratio': 0.2}, {'word': 'デュアル変数', 'ratio': 0.1}]",双対変数
1510,1736,duality gap,双対ギャップ,0.7,10,"[{'word': '双対ギャップ', 'ratio': 0.7}, {'word': 'デュアリティ・ギャップ', 'ratio': 0.1}, {'word': '二元性のギャップ', 'ratio': 0.1}, {'word': '二重性ギャップ', 'ratio': 0.1}]",双対ギャップ
1511,1737,dynamic Bayesian network,動的ベイジアンネットワーク,0.7,10,"[{'word': '動的ベイジアンネットワーク', 'ratio': 0.7}, {'word': '動的ベイズネットワーク', 'ratio': 0.3}]",動的ベイジアンネットワーク
1512,1738,dynamic model,動的モデル,0.9,10,"[{'word': '動的モデル', 'ratio': 0.9}, {'word': 'ダイナミックモデル', 'ratio': 0.1}]",動的モデル
1513,1739,dynamic programming algorithm,動的プログラミングアルゴリズム,0.5,10,"[{'word': '動的プログラミングアルゴリズム', 'ratio': 0.5}, {'word': '動的計画法アルゴリズム', 'ratio': 0.4}, {'word': '動的計画アルゴリズム', 'ratio': 0.1}]",動的プログラミングアルゴリズム
1514,1741,dynamical model,動力学モデル,0.0,10,"[{'word': '動的モデル', 'ratio': 0.8}, {'word': '力学モデル', 'ratio': 0.2}]",動的モデル
1515,1742,dynamical system,"""動力学系""",0.0,10,"[{'word': '動的システム', 'ratio': 0.8}, {'word': '力学系', 'ratio': 0.1}, {'word': '動的系chantment', 'ratio': 0.1}]",動的システム
1516,1743,early fusion,アーリーフュージョン (early fusion),0.0,10,"[{'word': '早期融合', 'ratio': 0.6}, {'word': '初期融合', 'ratio': 0.2}, {'word': 'アーリーフュージョン', 'ratio': 0.2}]",早期融合
1517,1744,early stopping,早期停止,0.6,10,"[{'word': '早期停止', 'ratio': 0.6}, {'word': 'アーリーストッピング', 'ratio': 0.3}, {'word': '初期融合', 'ratio': 0.1}]",早期停止
1518,1745,earth-mover distance,地球移動距離,0.2,10,"[{'word': 'アースムーバー距離', 'ratio': 0.5}, {'word': '地球移動距離', 'ratio': 0.2}, {'word': '土工距離', 'ratio': 0.1}, {'word': '対地距離', 'ratio': 0.1}, {'word': '地球運動距離', 'ratio': 0.1}]",アースムーバー距離
1519,1746,edge detection,エッジ検出,0.9,10,"[{'word': 'エッジ検出', 'ratio': 0.9}, {'word': 'エッジ検出エッジ特徴', 'ratio': 0.1}]",エッジ検出
1520,1747,edge feature,エッジ特徴,0.8,10,"[{'word': 'エッジ特徴', 'ratio': 0.8}, {'word': 'エッジフィーチャ', 'ratio': 0.1}, {'word': 'エッジ機能', 'ratio': 0.1}]",エッジ特徴
1521,1748,edge label,エッジラベル,0.8,10,"[{'word': 'エッジラベル', 'ratio': 0.8}, {'word': '辺ラベル', 'ratio': 0.2}]",エッジラベル
1522,1749,edge prediction,エッジ予測,0.8,10,"[{'word': 'エッジ予測', 'ratio': 0.8}, {'word': '辺予測', 'ratio': 0.2}]",エッジ予測
1523,1750,edge set,エッジセット,0.2,10,"[{'word': 'エッジ集合', 'ratio': 0.6}, {'word': 'エッジセット', 'ratio': 0.2}, {'word': '辺集合', 'ratio': 0.2}]",エッジ集合
1524,1751,edge weight,エッジの重み,0.1,10,"[{'word': 'エッジ重み', 'ratio': 0.6}, {'word': '辺の重み', 'ratio': 0.2}, {'word': 'エッジウェイト', 'ratio': 0.1}, {'word': 'エッジの重み', 'ratio': 0.1}]",エッジ重み
1525,1752,edit distance,編集距離,0.8,10,"[{'word': '編集距離', 'ratio': 0.8}, {'word': '距離を編集する', 'ratio': 0.1}, {'word': 'エディット・ディスタンス', 'ratio': 0.1}]",編集距離
1526,1753,effective receptive field,有効受容野,0.5,10,"[{'word': '有効受容野', 'ratio': 0.5}, {'word': '効果的受容野', 'ratio': 0.3}, {'word': '効力受容野', 'ratio': 0.1}, {'word': '効果的受容領域', 'ratio': 0.1}]",有効受容野
1527,1754,ego-motion,自車運動,0.0,10,"[{'word': '自己運動', 'ratio': 0.7}, {'word': 'エゴモーション', 'ratio': 0.3}]",自己運動
1528,1755,eigen-decomposition,固有値分解,0.1,10,"[{'word': '固有分解', 'ratio': 0.8}, {'word': '特異値分解', 'ratio': 0.1}, {'word': '固有値分解', 'ratio': 0.1}]",固有分解
1529,1756,eigenbasis,固有ベクトル基底,0.0,10,"[{'word': '固有基底', 'ratio': 0.8}, {'word': '固有基準', 'ratio': 0.1}, {'word': '特異値基底', 'ratio': 0.1}]",固有基底
1530,1757,eigendecay,固有減衰,0.8,10,"[{'word': '固有減衰', 'ratio': 0.8}, {'word': '超新星爆発', 'ratio': 0.1}, {'word': '固有値減衰', 'ratio': 0.1}]",固有減衰
1531,1758,eigenfunction,固有関数,0.9,10,"[{'word': '固有関数', 'ratio': 0.9}, {'word': '\\固有関数', 'ratio': 0.1}]",固有関数
1532,1759,eigenspace,固有空間,1.0,10,"[{'word': '固有空間', 'ratio': 1.0}]",固有空間
1533,1760,eigenspectrum,固有スペクトル,1.0,10,"[{'word': '固有スペクトル', 'ratio': 1.0}]",固有スペクトル
1534,1761,eigenvalue,固有値,1.0,10,"[{'word': '固有値', 'ratio': 1.0}]",固有値
1535,1762,eigenvalue decomposition,固有値分解,1.0,10,"[{'word': '固有値分解', 'ratio': 1.0}]",固有値分解
1536,1763,eigenvector,固有ベクトル,0.9,10,"[{'word': '固有ベクトル', 'ratio': 0.9}, {'word': '共役ベクトル', 'ratio': 0.1}]",固有ベクトル
1537,1765,element-wise,要素ごと,0.7,10,"[{'word': '要素ごと', 'ratio': 0.7}, {'word': '要素ごとの', 'ratio': 0.1}, {'word': '要素別', 'ratio': 0.1}, {'word': '要素wise', 'ratio': 0.1}]",要素ごと
1538,1766,element-wise multiplication,要素ごとの乗算,0.9,10,"[{'word': '要素ごとの乗算', 'ratio': 0.9}, {'word': '要素wise乗算', 'ratio': 0.1}]",要素ごとの乗算
1539,1767,element-wise product,要素ごとの積,0.8,10,"[{'word': '要素ごとの積', 'ratio': 0.8}, {'word': '要素別積', 'ratio': 0.2}]",要素ごとの積
1540,1768,elementary tree,基本木,0.8,10,"[{'word': '基本木', 'ratio': 0.8}, {'word': '初等木', 'ratio': 0.2}]",基本木
1541,1769,eligibility trace,適格性トレース,0.7,10,"[{'word': '適格性トレース', 'ratio': 0.7}, {'word': 'エリジビリティー・トレース', 'ratio': 0.2}, {'word': '有資格トレース有資格トレース', 'ratio': 0.1}]",適格性トレース
1542,1770,embedded deformation graph,埋め込み変形グラフ,0.8,10,"[{'word': '埋め込み変形グラフ', 'ratio': 0.8}, {'word': '埋め込まれた変形グラフ', 'ratio': 0.2}]",埋め込み変形グラフ
1543,1771,embedding dimension,埋め込み次元,0.8,10,"[{'word': '埋め込み次元', 'ratio': 0.8}, {'word': '埋め込み寸法', 'ratio': 0.2}]",埋め込み次元
1544,1773,embedding feature,埋め込み特徴量,0.0,10,"[{'word': '埋め込み特徴', 'ratio': 0.8}, {'word': '埋め込み機能', 'ratio': 0.2}]",埋め込み特徴
1545,1774,embedding layer,埋め込み層,0.9,10,"[{'word': '埋め込み層', 'ratio': 0.9}, {'word': '埋め込みレイヤー', 'ratio': 0.1}]",埋め込み層
1546,1775,embedding matrix,埋め込みマトリックス,0.0,10,"[{'word': '埋め込み行列', 'ratio': 1.0}]",埋め込み行列
1547,1776,embedding model,埋め込みモデル,1.0,10,"[{'word': '埋め込みモデル', 'ratio': 1.0}]",埋め込みモデル
1548,1777,embedding parameter,埋め込みパラメータ,0.9,10,"[{'word': '埋め込みパラメータ', 'ratio': 0.9}, {'word': '埋め込みパラメーター', 'ratio': 0.1}]",埋め込みパラメータ
1549,1778,embedding size,埋め込みサイズ,1.0,10,"[{'word': '埋め込みサイズ', 'ratio': 1.0}]",埋め込みサイズ
1550,1779,embedding space,埋め込み空間,1.0,10,"[{'word': '埋め込み空間', 'ratio': 1.0}]",埋め込み空間
1551,1780,embedding vector,埋め込みベクトル,1.0,10,"[{'word': '埋め込みベクトル', 'ratio': 1.0}]",埋め込みベクトル
1552,1781,embedding-based metric,埋め込みベースメトリック,0.0,10,"[{'word': '埋め込みベースのメトリック', 'ratio': 1.0}]",埋め込みベースのメトリック
1553,1782,embodied agent,体現エージェント,0.0,10,"[{'word': '具現化されたエージェント', 'ratio': 0.8}, {'word': '具現化エージェント', 'ratio': 0.2}]",具現化されたエージェント
1554,1784,emotion classification,感情分類,0.9,10,"[{'word': '感情分類', 'ratio': 0.9}, {'word': '感情の分類', 'ratio': 0.1}]",感情分類
1555,1785,empirical Bayes,経験的ベイズ,1.0,10,"[{'word': '経験的ベイズ', 'ratio': 1.0}]",経験的ベイズ
1556,1786,empirical distribution,経験分布,0.5,10,"[{'word': '経験的分布', 'ratio': 0.5}, {'word': '経験分布', 'ratio': 0.5}]",経験的分布
1557,1787,empirical estimate,経験的推定,0.7,10,"[{'word': '経験的推定', 'ratio': 0.7}, {'word': '実証的推定値', 'ratio': 0.2}, {'word': '経験的推定値', 'ratio': 0.1}]",経験的推定
1558,1788,empirical estimator,経験的推定子 (けいけんてきすいていし),0.0,10,"[{'word': '経験的推定量', 'ratio': 1.0}]",経験的推定量
1559,1789,empirical frequency,経験的頻度,0.8,10,"[{'word': '経験的頻度', 'ratio': 0.8}, {'word': '経験頻度', 'ratio': 0.2}]",経験的頻度
1560,1790,empirical loss,経験的損失,0.9,10,"[{'word': '経験的損失', 'ratio': 0.9}, {'word': '実験的損失', 'ratio': 0.1}]",経験的損失
1561,1791,empirical mean,経験的平均,0.8,10,"[{'word': '経験的平均', 'ratio': 0.8}, {'word': '経験平均', 'ratio': 0.1}, {'word': 'empirical平均', 'ratio': 0.1}]",経験的平均
1562,1792,empirical measure,経験的尺度,0.1,10,"[{'word': '経験的測度', 'ratio': 0.7}, {'word': '経験則', 'ratio': 0.1}, {'word': '経験的尺度', 'ratio': 0.1}, {'word': 'empirical測度', 'ratio': 0.1}]",経験的測度
1563,1793,empirical minimizer,経験的最小化ツール,0.1,10,"[{'word': '経験的最小化器', 'ratio': 0.7}, {'word': '経験的最小化', 'ratio': 0.1}, {'word': '経験的最小化ツール', 'ratio': 0.1}, {'word': 'empirical最小値', 'ratio': 0.1}]",経験的最小化器
1564,1794,empirical process theory,経験過程理論,0.0,10,"[{'word': '経験的プロセス理論', 'ratio': 0.5}, {'word': '経験的過程理論', 'ratio': 0.3}, {'word': '経験過程論', 'ratio': 0.1}, {'word': 'empirical過程理論', 'ratio': 0.1}]",経験的プロセス理論
1565,1795,empirical risk,経験的リスク,0.7,10,"[{'word': '経験的リスク', 'ratio': 0.7}, {'word': '経験リスク', 'ratio': 0.3}]",経験的リスク
1566,1796,empirical risk minimization,経験的リスク最小化,0.6,10,"[{'word': '経験的リスク最小化', 'ratio': 0.6}, {'word': '経験リスク最小化', 'ratio': 0.3}, {'word': '経験的なリスクの最小化', 'ratio': 0.1}]",経験的リスク最小化
1567,1797,empirical risk minimizer,経験的リスク最小化器,0.5,10,"[{'word': '経験的リスク最小化器', 'ratio': 0.5}, {'word': '経験リスク最小化器', 'ratio': 0.3}, {'word': '経験的リスク最小化装置', 'ratio': 0.1}, {'word': '経験的リスク最小化ツール', 'ratio': 0.1}]",経験的リスク最小化器
1568,1798,empirical variance,経験的分散,0.6,10,"[{'word': '経験的分散', 'ratio': 0.6}, {'word': '経験分散', 'ratio': 0.3}, {'word': '経験的な差異', 'ratio': 0.1}]",経験的分散
1569,1799,emulator,シミュレータ,0.0,10,"[{'word': 'エミュレーター', 'ratio': 0.8}, {'word': 'エミュレータ', 'ratio': 0.2}]",エミュレーター
1570,1800,encoder layer,エンコーダー層,0.0,10,"[{'word': 'エンコーダ層', 'ratio': 0.7}, {'word': 'エンコーダレイヤー', 'ratio': 0.1}, {'word': 'エンコーダレイヤ', 'ratio': 0.1}, {'word': 'エンコーダーレイヤー', 'ratio': 0.1}]",エンコーダ層
1571,1801,encoder model,エンコーダーモデル,0.2,10,"[{'word': 'エンコーダモデル', 'ratio': 0.8}, {'word': 'エンコーダーモデル', 'ratio': 0.2}]",エンコーダモデル
1572,1802,encoder network,エンコーダーネットワーク,0.2,10,"[{'word': 'エンコーダネットワーク', 'ratio': 0.8}, {'word': 'エンコーダーネットワーク', 'ratio': 0.2}]",エンコーダネットワーク
1573,1803,encoder states,エンコーダー状態,0.0,10,"[{'word': 'エンコーダ状態', 'ratio': 0.9}, {'word': 'エンコーダの状態', 'ratio': 0.1}]",エンコーダ状態
1574,1804,encoder-decoder architecture,エンコーダーデコーダーアーキテクチャ,0.0,10,"[{'word': 'エンコーダ・デコーダアーキテクチャ', 'ratio': 0.5}, {'word': 'エンコーダ・デコーダ・アーキテクチャ', 'ratio': 0.2}, {'word': 'エンコーダデコーダアーキテクチャ', 'ratio': 0.1}, {'word': 'エンコーダデコーダーアーキテクチャ', 'ratio': 0.1}, {'word': 'エンコーダ-デコーダアーキテクチャ', 'ratio': 0.1}]",エンコーダ・デコーダアーキテクチャ
1575,1805,encoder-decoder framework,エンコーダデコーダ枠組み,0.0,10,"[{'word': 'エンコーダ・デコーダフレームワーク', 'ratio': 0.5}, {'word': 'エンコーダー・デコーダー・フレームワーク', 'ratio': 0.2}, {'word': 'エンコーダデコーダフレームワーク', 'ratio': 0.1}, {'word': 'エンコーダデコーダーフレームワーク', 'ratio': 0.1}, {'word': 'エンコーダ-デコーダフレームワーク', 'ratio': 0.1}]",エンコーダ・デコーダフレームワーク
1576,1806,encoder-decoder model,エンコーダデコーダモデル,0.1,10,"[{'word': 'エンコーダ・デコーダモデル', 'ratio': 0.5}, {'word': 'エンコーダー・デコーダー・モデル', 'ratio': 0.2}, {'word': 'エンコーダデコーダモデル', 'ratio': 0.1}, {'word': 'エンコーダデコーダーモデル', 'ratio': 0.1}, {'word': 'エンコーダ-デコーダモデル', 'ratio': 0.1}]",エンコーダ・デコーダモデル
1577,1807,end-of-sequence token,系列終了トークン,0.0,10,"[{'word': 'シーケンス終了トークン', 'ratio': 0.7}, {'word': '終了トークン', 'ratio': 0.2}, {'word': 'シークエンスの終端トークン', 'ratio': 0.1}]",シーケンス終了トークン
1578,1808,end-to-end learning,エンドツーエンド学習,0.8,10,"[{'word': 'エンドツーエンド学習', 'ratio': 0.8}, {'word': 'エンド・ツー・エンド・ラーニング', 'ratio': 0.1}, {'word': 'エンドツーエンドの学習', 'ratio': 0.1}]",エンドツーエンド学習
1579,1809,end-to-end model,エンドツーエンドモデル,0.8,10,"[{'word': 'エンドツーエンドモデル', 'ratio': 0.8}, {'word': 'エンド・ツー・エンド・モデル', 'ratio': 0.1}, {'word': 'エンドツーエンドモデルエンドツーエンドニューラルモデル', 'ratio': 0.1}]",エンドツーエンドモデル
1580,1810,end-to-end neural model,エンドツーエンドニューラルモデル,0.8,10,"[{'word': 'エンドツーエンドニューラルモデル', 'ratio': 0.8}, {'word': 'エンド・ツー・エンド・ニューラル・モデル', 'ratio': 0.1}, {'word': 'エンドツーエンドのニューラル モデル', 'ratio': 0.1}]",エンドツーエンドニューラルモデル
1581,1811,end-to-end pipeline,エンドツーエンドパイプライン,0.8,10,"[{'word': 'エンドツーエンドパイプライン', 'ratio': 0.8}, {'word': 'エンド・ツー・エンド・パイプライン', 'ratio': 0.1}, {'word': 'エンドツーエンドのパイプライン', 'ratio': 0.1}]",エンドツーエンドパイプライン
1582,1812,end-to-end system,エンド・トゥ・エンド・システム,0.0,10,"[{'word': 'エンドツーエンドシステム', 'ratio': 0.9}, {'word': 'エンド・ツー・エンド・システム', 'ratio': 0.1}]",エンドツーエンドシステム
1583,1813,end-to-end training,エンドツーエンドのトレーニング,0.1,10,"[{'word': 'エンドツーエンドトレーニング', 'ratio': 0.8}, {'word': 'エンド・ツー・エンド・トレーニング', 'ratio': 0.1}, {'word': 'エンドツーエンドのトレーニング', 'ratio': 0.1}]",エンドツーエンドトレーニング
1584,1814,energy function,エネルギー関数,1.0,10,"[{'word': 'エネルギー関数', 'ratio': 1.0}]",エネルギー関数
1585,1815,energy minimization,エネルギー最小化,0.9,10,"[{'word': 'エネルギー最小化', 'ratio': 0.9}, {'word': 'エネルギーの最小化', 'ratio': 0.1}]",エネルギー最小化
1586,1816,energy minimization framework,エネルギー最小化フレームワーク,0.9,10,"[{'word': 'エネルギー最小化フレームワーク', 'ratio': 0.9}, {'word': 'エネルギー最小化の枠組み', 'ratio': 0.1}]",エネルギー最小化フレームワーク
1587,1817,energy minimization problem,エネルギー最小化問題,0.9,10,"[{'word': 'エネルギー最小化問題', 'ratio': 0.9}, {'word': 'エネルギーミニ ミザ 問題', 'ratio': 0.1}]",エネルギー最小化問題
1588,1818,ensemble classification,アンサンブル分類,1.0,10,"[{'word': 'アンサンブル分類', 'ratio': 1.0}]",アンサンブル分類
1589,1819,ensemble classifier,アンサンブル分類器,0.9,10,"[{'word': 'アンサンブル分類器', 'ratio': 0.9}, {'word': 'アンサンブルクラッサー', 'ratio': 0.1}]",アンサンブル分類器
1590,1820,ensemble learning,アンサンブル学習,1.0,10,"[{'word': 'アンサンブル学習', 'ratio': 1.0}]",アンサンブル学習
1591,1821,ensemble method,アンサンブル手法,0.2,10,"[{'word': 'アンサンブル法', 'ratio': 0.8}, {'word': 'アンサンブル手法', 'ratio': 0.2}]",アンサンブル法
1592,1822,ensemble model,アンサンブルモデル,0.9,10,"[{'word': 'アンサンブルモデル', 'ratio': 0.9}, {'word': 'モデルセット', 'ratio': 0.1}]",アンサンブルモデル
1593,1823,ensemble of classifier,分類器のアンサンブル,0.9,10,"[{'word': '分類器のアンサンブル', 'ratio': 0.9}, {'word': 'クラスифイアのアンサンブル', 'ratio': 0.1}]",分類器のアンサンブル
1594,1824,ensemble size,アンサンブルサイズ,0.9,10,"[{'word': 'アンサンブルサイズ', 'ratio': 0.9}, {'word': 'セットサイズ', 'ratio': 0.1}]",アンサンブルサイズ
1595,1825,entail,含意する,0.7,10,"[{'word': '含意する', 'ratio': 0.7}, {'word': '伴う', 'ratio': 0.2}, {'word': '含意', 'ratio': 0.1}]",含意する
1596,1828,entity,エンティティ,1.0,20,"[{'word': 'エンティティ', 'ratio': 1.0}]",エンティティ
1597,1830,entity description,エンティティ記述,0.6,10,"[{'word': 'エンティティ記述', 'ratio': 0.6}, {'word': 'エンティティの説明', 'ratio': 0.3}, {'word': 'エンティティの記述', 'ratio': 0.1}]",エンティティ記述
1598,1831,entity detection,エンティティ検出,0.8,10,"[{'word': 'エンティティ検出', 'ratio': 0.8}, {'word': 'エンティティの検出', 'ratio': 0.2}]",エンティティ検出
1599,1832,entity embedding,エンティティ埋め込み,0.8,10,"[{'word': 'エンティティ埋め込み', 'ratio': 0.8}, {'word': 'エンティティの埋め込み', 'ratio': 0.2}]",エンティティ埋め込み
1600,1833,entity extraction,エンティティ抽出,0.8,10,"[{'word': 'エンティティ抽出', 'ratio': 0.8}, {'word': 'エンティティの抽出', 'ratio': 0.2}]",エンティティ抽出
1601,1834,entity linker,エンティティリンカー,0.5,10,"[{'word': 'エンティティリンカー', 'ratio': 0.5}, {'word': 'エンティティリンク', 'ratio': 0.4}, {'word': 'エンティティリンカ', 'ratio': 0.1}]",エンティティリンカー
1602,1836,entity recognition,エンティティ認識,0.9,10,"[{'word': 'エンティティ認識', 'ratio': 0.9}, {'word': 'エンティティの認識', 'ratio': 0.1}]",エンティティ認識
1603,1837,entity representation,エンティティ表現,0.9,10,"[{'word': 'エンティティ表現', 'ratio': 0.9}, {'word': '実体表現', 'ratio': 0.1}]",エンティティ表現
1604,1838,entity resolution,エンティティ解決,0.8,10,"[{'word': 'エンティティ解決', 'ratio': 0.8}, {'word': '実体解決', 'ratio': 0.1}, {'word': 'エンティティの解決', 'ratio': 0.1}]",エンティティ解決
1605,1839,entity set,エンティティ集合,0.1,10,"[{'word': 'エンティティセット', 'ratio': 0.8}, {'word': 'エンティティ集合', 'ratio': 0.1}, {'word': 'エンティティ セット', 'ratio': 0.1}]",エンティティセット
1606,1840,entity type,エンティティの種別,0.0,10,"[{'word': 'エンティティタイプ', 'ratio': 0.9}, {'word': 'エンティティ タイプ', 'ratio': 0.1}]",エンティティタイプ
1607,1841,entropy estimation,エントロピー推定,0.9,10,"[{'word': 'エントロピー推定', 'ratio': 0.9}, {'word': 'エントロピーの推定', 'ratio': 0.1}]",エントロピー推定
1608,1842,entropy function,エントロピー関数,1.0,10,"[{'word': 'エントロピー関数', 'ratio': 1.0}]",エントロピー関数
1609,1843,entropy loss,エントロピー損失,0.9,10,"[{'word': 'エントロピー損失', 'ratio': 0.9}, {'word': 'エントロピーの損失', 'ratio': 0.1}]",エントロピー損失
1610,1844,entropy regularization,エントロピー正則化,0.9,10,"[{'word': 'エントロピー正則化', 'ratio': 0.9}, {'word': 'エントロピー規制', 'ratio': 0.1}]",エントロピー正則化
1611,1845,enumeration algorithm,列挙アルゴリズム,1.0,10,"[{'word': '列挙アルゴリズム', 'ratio': 1.0}]",列挙アルゴリズム
1612,1848,epipolar constraint,視線束拘束条件,0.0,10,"[{'word': 'エピポーラ制約', 'ratio': 0.9}, {'word': '双眼同時運動制約', 'ratio': 0.1}]",エピポーラ制約
1613,1849,epipolar geometry,エピポーラ幾何学,0.7,10,"[{'word': 'エピポーラ幾何学', 'ratio': 0.7}, {'word': 'エピポーラ幾何', 'ratio': 0.3}]",エピポーラ幾何学
1614,1850,epipolar line,エピポーラ線,1.0,10,"[{'word': 'エピポーラ線', 'ratio': 1.0}]",エピポーラ線
1615,1851,epipole,エピポール,0.9,10,"[{'word': 'エピポール', 'ratio': 0.9}, {'word': 'epipole', 'ratio': 0.1}]",エピポール
1616,1854,epoch,エポック,1.0,10,"[{'word': 'エポック', 'ratio': 1.0}]",エポック
1617,1857,equivalence query,等価クエリ,0.1,10,"[{'word': '同値クエリ', 'ratio': 0.6}, {'word': '等価クエリ', 'ratio': 0.1}, {'word': '同等クエリ', 'ratio': 0.1}, {'word': '等価性クエリ', 'ratio': 0.1}, {'word': '類同問い合わせ', 'ratio': 0.1}]",同値クエリ
1618,1858,equivariance,同変性,0.5,10,"[{'word': '同変性', 'ratio': 0.5}, {'word': '等変性', 'ratio': 0.3}, {'word': 'へんりょう', 'ratio': 0.1}, {'word': '等分散性', 'ratio': 0.1}]",同変性
1619,1859,equivariant,等変,0.5,10,"[{'word': '等変', 'ratio': 0.5}, {'word': '同変', 'ratio': 0.2}, {'word': 'へんりょう', 'ratio': 0.1}, {'word': '等価', 'ratio': 0.1}, {'word': 'エクイバリアント', 'ratio': 0.1}]",等変
1620,1860,error,エラー,0.4,10,"[{'word': '誤差', 'ratio': 0.5}, {'word': 'エラー', 'ratio': 0.4}, {'word': '誤り', 'ratio': 0.1}]",誤差
1621,1863,error function,誤差関数,0.7,10,"[{'word': '誤差関数', 'ratio': 0.7}, {'word': 'エラー機能', 'ratio': 0.1}, {'word': 'エラー関数', 'ratio': 0.1}, {'word': '誤り関数', 'ratio': 0.1}]",誤差関数
1622,1864,error probability,誤り確率,0.1,10,"[{'word': '誤差確率', 'ratio': 0.6}, {'word': 'エラー確率', 'ratio': 0.1}, {'word': '誤り確率', 'ratio': 0.1}, {'word': 'エラーの確率', 'ratio': 0.1}, {'word': 'Erua Pobaburiiti', 'ratio': 0.1}]",誤差確率
1623,1865,error rate,誤り率 (あやまりりつ),0.0,10,"[{'word': '誤差率', 'ratio': 0.6}, {'word': 'エラーレート', 'ratio': 0.1}, {'word': '誤り率', 'ratio': 0.1}, {'word': 'エラー率', 'ratio': 0.1}, {'word': 'Erua Rēto', 'ratio': 0.1}]",誤差率
1624,1866,error tolerance,誤差許容度,0.3,10,"[{'word': '誤差許容', 'ratio': 0.5}, {'word': '誤差許容度', 'ratio': 0.3}, {'word': '誤差公差', 'ratio': 0.1}, {'word': 'Erua Toransu', 'ratio': 0.1}]",誤差許容
1625,1867,estimation error,推定誤差,0.9,10,"[{'word': '推定誤差', 'ratio': 0.9}, {'word': 'Sutesumashon Erua', 'ratio': 0.1}]",推定誤差
1626,1868,estimator,推定量,0.7,10,"[{'word': '推定量', 'ratio': 0.7}, {'word': '推定器', 'ratio': 0.1}, {'word': '推定者', 'ratio': 0.1}, {'word': 'Esutīmāta', 'ratio': 0.1}]",推定量
1627,1869,evaluation function,評価関数,1.0,10,"[{'word': '評価関数', 'ratio': 1.0}]",評価関数
1628,1870,evaluation metric,評価メトリック,0.0,10,"[{'word': '評価指標', 'ratio': 1.0}]",評価指標
1629,1871,evaluation set,評価セット,1.0,10,"[{'word': '評価セット', 'ratio': 1.0}]",評価セット
1630,1872,event calculus,イベント微積分,0.2222222222222222,9,"[{'word': 'イベント計算', 'ratio': 0.5555555555555556}, {'word': 'イベント微積分', 'ratio': 0.2222222222222222}, {'word': '事象計算', 'ratio': 0.1111111111111111}, {'word': 'イベントカレクルス', 'ratio': 0.1111111111111111}]",イベント計算
1631,1874,event detection,イベント検出,1.0,9,"[{'word': 'イベント検出', 'ratio': 1.0}]",イベント検出
1632,1875,event extraction,イベント抽出,1.0,9,"[{'word': 'イベント抽出', 'ratio': 1.0}]",イベント抽出
1633,1877,evidence maximization,証拠最大化,1.0,10,"[{'word': '証拠最大化', 'ratio': 1.0}]",証拠最大化
1634,1879,excess loss,過剰損失,0.4,10,"[{'word': '超過損失', 'ratio': 0.6}, {'word': '過剰損失', 'ratio': 0.4}]",超過損失
1635,1880,exchangeability,交換可能性,0.8,10,"[{'word': '交換可能性', 'ratio': 0.8}, {'word': '交換性', 'ratio': 0.2}]",交換可能性
1636,1881,existential quantifier,存在量化子,0.8,10,"[{'word': '存在量化子', 'ratio': 0.8}, {'word': '実存量化詞', 'ratio': 0.2}]",存在量化子
1637,1882,expected loss,期待損失,0.7777777777777778,9,"[{'word': '期待損失', 'ratio': 0.7777777777777778}, {'word': '予想損失', 'ratio': 0.2222222222222222}]",期待損失
1638,1883,expected reward,期待報酬,1.0,9,"[{'word': '期待報酬', 'ratio': 1.0}]",期待報酬
1639,1884,expected utility,期待効用,1.0,9,"[{'word': '期待効用', 'ratio': 1.0}]",期待効用
1640,1885,experience replay,経験再生,0.6666666666666666,9,"[{'word': '経験再生', 'ratio': 0.6666666666666666}, {'word': '体験リプレイ', 'ratio': 0.1111111111111111}, {'word': 'エクスペリエンス・リプレイ', 'ratio': 0.1111111111111111}, {'word': '経験リプレイ', 'ratio': 0.1111111111111111}]",経験再生
1641,1889,exploitability,搾取可能性,0.1111111111111111,9,"[{'word': '利用可能性', 'ratio': 0.5555555555555556}, {'word': 'エクスプロイト性', 'ratio': 0.2222222222222222}, {'word': '弱点化可能性', 'ratio': 0.1111111111111111}, {'word': '搾取可能性', 'ratio': 0.1111111111111111}]",利用可能性
1642,1890,exploration rate,探索率,0.7777777777777778,9,"[{'word': '探索率', 'ratio': 0.7777777777777778}, {'word': '探検率', 'ratio': 0.2222222222222222}]",探索率
1643,1891,exploratory data analysis,探索的データ分析,0.8,10,"[{'word': '探索的データ分析', 'ratio': 0.8}, {'word': 'Tōgō Jōhō Bunseki', 'ratio': 0.1}, {'word': '探索的データ解析', 'ratio': 0.1}]",探索的データ分析
1644,1892,exponential complexity,指数関数的複雑さ,0.0,10,"[{'word': '指数的複雑性', 'ratio': 0.8}, {'word': '指数関数的な複雑さ', 'ratio': 0.1}, {'word': 'Konkyū Sekijou', 'ratio': 0.1}]",指数的複雑性
1645,1893,exponential decay,指数減衰,0.0,10,"[{'word': '指数関数的減衰', 'ratio': 0.7}, {'word': '指数的減衰', 'ratio': 0.2}, {'word': 'Konkyū Kako', 'ratio': 0.1}]",指数関数的減衰
1646,1895,exponential loss,指数損失,0.6,10,"[{'word': '指数損失', 'ratio': 0.6}, {'word': '指数関数的損失', 'ratio': 0.2}, {'word': '指数的損失', 'ratio': 0.1}, {'word': 'Konkyū Riseru', 'ratio': 0.1}]",指数損失
1647,1896,exponential map,指数写像,0.7777777777777778,9,"[{'word': '指数写像', 'ratio': 0.7777777777777778}, {'word': '指数マップ', 'ratio': 0.2222222222222222}]",指数写像
1648,1897,exponential moving average,指数移動平均,1.0,9,"[{'word': '指数移動平均', 'ratio': 1.0}]",指数移動平均
1649,1898,exposure bias,暴露バイアス,0.0,9,"[{'word': 'エクスポージャーバイアス', 'ratio': 0.5555555555555556}, {'word': '露出バイアス', 'ratio': 0.4444444444444444}]",エクスポージャーバイアス
1650,1900,extractive question answering,抽出型質問応答,0.6,10,"[{'word': '抽出型質問応答', 'ratio': 0.6}, {'word': '抽出的な質問応答', 'ratio': 0.2}, {'word': '抽出的質問応答', 'ratio': 0.2}]",抽出型質問応答
1651,1901,extractive summarization,抽出的要約,0.2,10,"[{'word': '抽出型要約', 'ratio': 0.6}, {'word': '抽出的な要約', 'ratio': 0.2}, {'word': '抽出的要約', 'ratio': 0.2}]",抽出型要約
1652,1902,extractor,抽出器,0.35,20,"[{'word': '抽出器', 'ratio': 0.75}, {'word': '分離機', 'ratio': 0.2}, {'word': '抽出器抽出器', 'ratio': 0.05}]",抽出器
1653,1904,face detection,顔検出,1.0,10,"[{'word': '顔検出', 'ratio': 1.0}]",顔検出
1654,1905,face detector,顔検出器,1.0,10,"[{'word': '顔検出器', 'ratio': 1.0}]",顔検出器
1655,1906,face recognition,顔認識,1.0,10,"[{'word': '顔認識', 'ratio': 1.0}]",顔認識
1656,1907,facial landmark,顔ランドマーク,0.0,10,"[{'word': '顔のランドマーク', 'ratio': 1.0}]",顔のランドマーク
1657,1908,facial recognition,顔認識,1.0,10,"[{'word': '顔認識', 'ratio': 1.0}]",顔認識
1658,1909,fact verification,事実検証,0.2,10,"[{'word': '事実確認', 'ratio': 0.8}, {'word': '事実検証', 'ratio': 0.2}]",事実確認
1659,1910,factor analysis,因子分析,1.0,10,"[{'word': '因子分析', 'ratio': 1.0}]",因子分析
1660,1911,factor graph,因子グラフ,0.4,10,"[{'word': 'ファクターグラフ', 'ratio': 0.5}, {'word': '因子グラフ', 'ratio': 0.4}, {'word': '係数グラフ', 'ratio': 0.1}]",ファクターグラフ
1661,1912,factor matrix,因子行列,0.6,10,"[{'word': '因子行列', 'ratio': 0.6}, {'word': 'ファクターマトリックス', 'ratio': 0.4}]",因子行列
1662,1913,factor of variation,変動要因,0.2,10,"[{'word': '変動因子', 'ratio': 0.5}, {'word': '変動要因', 'ratio': 0.2}, {'word': '変動係数', 'ratio': 0.1}, {'word': '変動因子因子分解', 'ratio': 0.1}, {'word': '変異要因', 'ratio': 0.1}]",変動因子
1663,1914,factorization,因子分解,0.6,10,"[{'word': '因子分解', 'ratio': 0.6}, {'word': '因数分解', 'ratio': 0.3}, {'word': '分解', 'ratio': 0.1}]",因子分解
1664,1915,factorization algorithm,因数分解アルゴリズム,0.4,10,"[{'word': '因子分解アルゴリズム', 'ratio': 0.6}, {'word': '因数分解アルゴリズム', 'ratio': 0.4}]",因子分解アルゴリズム
1665,1916,factorization method,因子分解法,0.5555555555555556,9,"[{'word': '因子分解法', 'ratio': 0.5555555555555556}, {'word': '因数分解法', 'ratio': 0.2222222222222222}, {'word': '行列分解法', 'ratio': 0.1111111111111111}, {'word': '分解法', 'ratio': 0.1111111111111111}]",因子分解法
1666,1917,failure probability,失敗確率,0.8,10,"[{'word': '失敗確率', 'ratio': 0.8}, {'word': '故障確率', 'ratio': 0.1}, {'word': 'Fēsharu Robureshabiti', 'ratio': 0.1}]",失敗確率
1667,1918,fairness criterion,公平性基準,0.7,10,"[{'word': '公平性基準', 'ratio': 0.7}, {'word': '公正基準', 'ratio': 0.1}, {'word': '公平性の基準', 'ratio': 0.1}, {'word': 'Faireshsu Kiterion', 'ratio': 0.1}]",公平性基準
1668,1919,fairness loss,公平性損失,0.7,10,"[{'word': '公平性損失', 'ratio': 0.7}, {'word': '公正損失', 'ratio': 0.1}, {'word': '公平性の喪失', 'ratio': 0.1}, {'word': 'Faireshsu Rosu', 'ratio': 0.1}]",公平性損失
1669,1920,fairness notion,公平性概念,0.3,10,"[{'word': '公平性の概念', 'ratio': 0.5}, {'word': '公平性概念', 'ratio': 0.3}, {'word': '公正観念', 'ratio': 0.1}, {'word': 'Faireshsu Nōjion', 'ratio': 0.1}]",公平性の概念
1670,1921,faithfulness score,忠実度スコア,0.7,10,"[{'word': '忠実度スコア', 'ratio': 0.7}, {'word': '忠誠度', 'ratio': 0.1}, {'word': '信頼性スコア', 'ratio': 0.1}, {'word': '忠実性スコア', 'ratio': 0.1}]",忠実度スコア
1671,1922,false negative,偽陰性,0.9,10,"[{'word': '偽陰性', 'ratio': 0.9}, {'word': '誤陰性', 'ratio': 0.1}]",偽陰性
1672,1923,false negative rate,偽陰性率,0.9,10,"[{'word': '偽陰性率', 'ratio': 0.9}, {'word': '誤陰性率', 'ratio': 0.1}]",偽陰性率
1673,1924,false positive rate,偽陽性率,0.9,10,"[{'word': '偽陽性率', 'ratio': 0.9}, {'word': '誤陽性率', 'ratio': 0.1}]",偽陽性率
1674,1925,fanout,ファンアウト,0.9,10,"[{'word': 'ファンアウト', 'ratio': 0.9}, {'word': 'ファノウト', 'ratio': 0.1}]",ファンアウト
1675,1926,fc layer,全結合層,0.6,10,"[{'word': '全結合層', 'ratio': 0.6}, {'word': 'fc層', 'ratio': 0.2}, {'word': 'フルコネクション層', 'ratio': 0.1}, {'word': 'FC層', 'ratio': 0.1}]",全結合層
1676,1928,feature,特徴量,0.4,10,"[{'word': '特徴', 'ratio': 0.6}, {'word': '特徴量', 'ratio': 0.4}]",特徴
1677,1929,feature channel,特徴チャネル,0.5,10,"[{'word': '特徴チャネル', 'ratio': 0.5}, {'word': '特徴チャンネル', 'ratio': 0.2}, {'word': 'フィーチャー・チャンネル', 'ratio': 0.1}, {'word': '特徴', 'ratio': 0.1}, {'word': '特集チャンネル', 'ratio': 0.1}]",特徴チャネル
1678,1930,feature correspondence,特徴対応,0.8,10,"[{'word': '特徴対応', 'ratio': 0.8}, {'word': '特集', 'ratio': 0.1}, {'word': '機能対応', 'ratio': 0.1}]",特徴対応
1679,1931,feature count,特徴量の個数,0.0,10,"[{'word': '特徴量カウント', 'ratio': 0.5}, {'word': '特徴数', 'ratio': 0.3}, {'word': '特徴カウント', 'ratio': 0.1}, {'word': 'フィーチャー数', 'ratio': 0.1}]",特徴量カウント
1680,1932,feature descriptor,特徴記述子,0.9,10,"[{'word': '特徴記述子', 'ratio': 0.9}, {'word': '機能記述子', 'ratio': 0.1}]",特徴記述子
1681,1933,feature detection,特徴検出,1.0,10,"[{'word': '特徴検出', 'ratio': 1.0}]",特徴検出
1682,1934,feature detector,特徴検出器,1.0,10,"[{'word': '特徴検出器', 'ratio': 1.0}]",特徴検出器
1683,1935,feature dimension,特徴次元,0.8,10,"[{'word': '特徴次元', 'ratio': 0.8}, {'word': 'フィーチャー寸法', 'ratio': 0.1}, {'word': '機能の寸法', 'ratio': 0.1}]",特徴次元
1684,1937,feature embedding,特徴埋め込み,0.8,10,"[{'word': '特徴埋め込み', 'ratio': 0.8}, {'word': '機能の埋め込み', 'ratio': 0.2}]",特徴埋め込み
1685,1938,feature encoder,特徴エンコーダ,0.8,10,"[{'word': '特徴エンコーダ', 'ratio': 0.8}, {'word': '機能エンコーダ', 'ratio': 0.2}]",特徴エンコーダ
1686,1939,feature engineering,特徴エンジニアリング,0.8,10,"[{'word': '特徴エンジニアリング', 'ratio': 0.8}, {'word': '特徴量エンジニアリング', 'ratio': 0.1}, {'word': '特徴工学', 'ratio': 0.1}]",特徴エンジニアリング
1687,1940,feature extraction,特徴抽出,1.0,10,"[{'word': '特徴抽出', 'ratio': 1.0}]",特徴抽出
1688,1941,feature extractor,特徴抽出器,1.0,9,"[{'word': '特徴抽出器', 'ratio': 1.0}]",特徴抽出器
1689,1942,feature function,特徴関数,0.7777777777777778,9,"[{'word': '特徴関数', 'ratio': 0.7777777777777778}, {'word': 'フィーチャー機能', 'ratio': 0.1111111111111111}, {'word': 'feature function', 'ratio': 0.1111111111111111}]",特徴関数
1690,1943,feature hashing,特徴ハッシュ,0.2222222222222222,9,"[{'word': '特徴ハッシング', 'ratio': 0.6666666666666666}, {'word': '特徴ハッシュ', 'ratio': 0.2222222222222222}, {'word': 'フィーチャー・ハッシュ', 'ratio': 0.1111111111111111}]",特徴ハッシング
1691,1944,feature hierarchy,特徴階層,0.7777777777777778,9,"[{'word': '特徴階層', 'ratio': 0.7777777777777778}, {'word': '機能階層', 'ratio': 0.2222222222222222}]",特徴階層
1692,1945,feature map,特徴マップ,0.7777777777777778,9,"[{'word': '特徴マップ', 'ratio': 0.7777777777777778}, {'word': 'feature map', 'ratio': 0.1111111111111111}, {'word': '機能マップ', 'ratio': 0.1111111111111111}]",特徴マップ
1693,1946,feature mapping function,特徴写像関数,0.0,10,"[{'word': '特徴マッピング関数', 'ratio': 0.8}, {'word': 'フィーチャーマッピング機能', 'ratio': 0.1}, {'word': 'Feyāru Mappingu Funkushon', 'ratio': 0.1}]",特徴マッピング関数
1694,1947,feature matching,特徴マッチング,0.7,10,"[{'word': '特徴マッチング', 'ratio': 0.7}, {'word': 'フィーチャーマッチング', 'ratio': 0.1}, {'word': 'Feyāru Matchingu', 'ratio': 0.1}, {'word': '特徴一致', 'ratio': 0.1}]",特徴マッチング
1695,1948,feature matrix,特徴マトリックス,0.1,10,"[{'word': '特徴行列', 'ratio': 0.8}, {'word': '特徴マトリックス', 'ratio': 0.1}, {'word': 'Feyāru Matsurī', 'ratio': 0.1}]",特徴行列
1696,1949,feature model,特徴モデル,0.7,10,"[{'word': '特徴モデル', 'ratio': 0.7}, {'word': '機能モデル', 'ratio': 0.1}, {'word': 'フィーチャーモデル', 'ratio': 0.1}, {'word': 'Feyāru Moderu', 'ratio': 0.1}]",特徴モデル
1697,1950,feature normalization,特徴正規化,0.8,10,"[{'word': '特徴正規化', 'ratio': 0.8}, {'word': '特徴の正規化', 'ratio': 0.1}, {'word': 'Feyāru Nōmarizeshon', 'ratio': 0.1}]",特徴正規化
1698,1951,feature point,特徴点,0.9,10,"[{'word': '特徴点', 'ratio': 0.9}, {'word': 'Fīyā Ponto', 'ratio': 0.1}]",特徴点
1699,1952,feature pyramid,特徴ピラミッド,0.7,10,"[{'word': '特徴ピラミッド', 'ratio': 0.7}, {'word': 'フィーチャーピラミッド', 'ratio': 0.1}, {'word': '機能ピラミッド', 'ratio': 0.1}, {'word': 'Fīyā Piramida', 'ratio': 0.1}]",特徴ピラミッド
1700,1953,feature representation,特徴表現,0.8,10,"[{'word': '特徴表現', 'ratio': 0.8}, {'word': 'フィーチャー表現', 'ratio': 0.1}, {'word': 'Fīyā Dōshi', 'ratio': 0.1}]",特徴表現
1701,1954,feature representation learning,特徴表現学習,0.9,10,"[{'word': '特徴表現学習', 'ratio': 0.9}, {'word': 'Fīyā Dōshi Gaku', 'ratio': 0.1}]",特徴表現学習
1702,1955,feature selection,特徴選択,0.8888888888888888,9,"[{'word': '特徴選択', 'ratio': 0.8888888888888888}, {'word': '機能の選択', 'ratio': 0.1111111111111111}]",特徴選択
1703,1956,feature selector,特徴選択器,0.7777777777777778,9,"[{'word': '特徴選択器', 'ratio': 0.7777777777777778}, {'word': 'フィーチャー・セレクター', 'ratio': 0.1111111111111111}, {'word': '機能セレクター', 'ratio': 0.1111111111111111}]",特徴選択器
1704,1957,feature set,特徴セット (Tokuchō setto),0.0,9,"[{'word': '特徴セット', 'ratio': 0.7777777777777778}, {'word': 'フィーチャーセット', 'ratio': 0.1111111111111111}, {'word': '機能セット', 'ratio': 0.1111111111111111}]",特徴セット
1705,1958,feature space,特徴空間,1.0,9,"[{'word': '特徴空間', 'ratio': 1.0}]",特徴空間
1706,1959,feature template,特徴テンプレート,0.7777777777777778,9,"[{'word': '特徴テンプレート', 'ratio': 0.7777777777777778}, {'word': '機能テンプレート', 'ratio': 0.1111111111111111}, {'word': 'フィーチャーテンプレート', 'ratio': 0.1111111111111111}]",特徴テンプレート
1707,1960,feature vector,特徴ベクトル,1.0,9,"[{'word': '特徴ベクトル', 'ratio': 1.0}]",特徴ベクトル
1708,1961,feature weight,特徴量の重み,0.2,10,"[{'word': '特徴重み', 'ratio': 0.5}, {'word': '特徴量の重み', 'ratio': 0.2}, {'word': '機能重量', 'ratio': 0.1}, {'word': '特徴の重み', 'ratio': 0.1}, {'word': '特徴量重み', 'ratio': 0.1}]",特徴重み
1709,1962,featurization,特徴化,0.7,10,"[{'word': '特徴化', 'ratio': 0.7}, {'word': '特徴量化', 'ratio': 0.2}, {'word': 'フィーチャライゼーション', 'ratio': 0.1}]",特徴化
1710,1964,feed forward,フィードフォワード,1.0,10,"[{'word': 'フィードフォワード', 'ratio': 1.0}]",フィードフォワード
1711,1965,feed forward network,フィードフォワードネットワーク,1.0,9,"[{'word': 'フィードフォワードネットワーク', 'ratio': 1.0}]",フィードフォワードネットワーク
1712,1966,feed forward neural network,前向き神経回路網,0.0,9,"[{'word': 'フィードフォワードニューラルネットワーク', 'ratio': 1.0}]",フィードフォワードニューラルネットワーク
1713,1967,feed-forward layer,順伝播層,0.0,9,"[{'word': 'フィードフォワード層', 'ratio': 0.8888888888888888}, {'word': 'フィードフォワードレイヤー', 'ratio': 0.1111111111111111}]",フィードフォワード層
1714,1968,feedback loop,フィードバックループ,1.0,9,"[{'word': 'フィードバックループ', 'ratio': 1.0}]",フィードバックループ
1715,1969,few shot learning,少数ショット学習,0.5555555555555556,9,"[{'word': '少数ショット学習', 'ratio': 0.5555555555555556}, {'word': '数発学習', 'ratio': 0.2222222222222222}, {'word': 'フェッシュットラーニング', 'ratio': 0.1111111111111111}, {'word': 'フューシャット学習', 'ratio': 0.1111111111111111}]",少数ショット学習
1716,1975,few-shot setting,少数ショット設定,0.8,10,"[{'word': '少数ショット設定', 'ratio': 0.8}, {'word': '数発設定', 'ratio': 0.2}]",少数ショット設定
1717,1976,filter bank,フィルタバンク,0.7,10,"[{'word': 'フィルタバンク', 'ratio': 0.7}, {'word': 'フィルターバンク', 'ratio': 0.3}]",フィルタバンク
1718,1977,filter weight,フィルタ重み,0.7,10,"[{'word': 'フィルタ重み', 'ratio': 0.7}, {'word': 'フィルター重量', 'ratio': 0.2}, {'word': 'フィルターウェイト', 'ratio': 0.1}]",フィルタ重み
1719,1979,fine-tune,ファインチューニング,0.2,10,"[{'word': '微調整', 'ratio': 0.8}, {'word': 'ファインチューニング', 'ratio': 0.2}]",微調整
1720,1981,finite horizon,有限時間ホライズン,0.0,9,"[{'word': '有限ホライズン', 'ratio': 0.6666666666666666}, {'word': '有限の地平線', 'ratio': 0.2222222222222222}, {'word': '有限ホライゾン', 'ratio': 0.1111111111111111}]",有限ホライズン
1721,1982,finite-state automata,有限状態オートマトン,0.8888888888888888,9,"[{'word': '有限状態オートマトン', 'ratio': 0.8888888888888888}, {'word': '有限状態機械', 'ratio': 0.1111111111111111}]",有限状態オートマトン
1722,1983,first order method,一次法,0.7777777777777778,9,"[{'word': '一次法', 'ratio': 0.7777777777777778}, {'word': '一階方法', 'ratio': 0.1111111111111111}, {'word': '一階法', 'ratio': 0.1111111111111111}]",一次法
1723,1984,first-order,一階,0.6,10,"[{'word': '一階', 'ratio': 0.6}, {'word': '一次', 'ratio': 0.3}, {'word': '階', 'ratio': 0.1}]",一階
1724,1985,first-order language,一階述語言語 (ikkai jutugo gengo),0.0,10,"[{'word': '一階言語', 'ratio': 0.7}, {'word': '一次言語', 'ratio': 0.2}, {'word': '階言語', 'ratio': 0.1}]",一階言語
1725,1986,first-order logic,1階述語論理,0.0,10,"[{'word': '一階論理', 'ratio': 0.7}, {'word': '一次論理', 'ratio': 0.2}, {'word': '階論理', 'ratio': 0.1}]",一階論理
1726,1987,first-order model,一次モデル,0.3,10,"[{'word': '一階モデル', 'ratio': 0.6}, {'word': '一次モデル', 'ratio': 0.3}, {'word': '階モデル', 'ratio': 0.1}]",一階モデル
1727,1988,first-order parsing,一次構文解析,0.2,10,"[{'word': '一階構文解析', 'ratio': 0.6}, {'word': '一次構文解析', 'ratio': 0.2}, {'word': '一次解析', 'ratio': 0.1}, {'word': '階構文解析', 'ratio': 0.1}]",一階構文解析
1728,1989,fitness function,適応度関数,0.5,10,"[{'word': '適応度関数', 'ratio': 0.5}, {'word': 'フィットネス関数', 'ratio': 0.2}, {'word': '適合関数', 'ratio': 0.2}, {'word': 'フィットネス機能', 'ratio': 0.1}]",適応度関数
1729,1991,fixed point,固定点,0.7,10,"[{'word': '固定点', 'ratio': 0.7}, {'word': '不動点', 'ratio': 0.2}, {'word': '定点', 'ratio': 0.1}]",固定点
1730,1993,fixed-point iteration,固定点反復,0.5,10,"[{'word': '固定点反復', 'ratio': 0.5}, {'word': '不動点反復', 'ratio': 0.2}, {'word': '固定点反復法', 'ratio': 0.1}, {'word': '固定小数点の反復', 'ratio': 0.1}, {'word': '固定小数点反復', 'ratio': 0.1}]",固定点反復
1731,1995,float16,float16,0.4,10,"[{'word': 'フロート16', 'ratio': 0.6}, {'word': 'float16', 'ratio': 0.4}]",フロート16
1732,1996,float32,float32,0.4,10,"[{'word': 'フロート32', 'ratio': 0.6}, {'word': 'float32', 'ratio': 0.4}]",フロート32
1733,1997,flow field,流れ場,0.7,10,"[{'word': '流れ場', 'ratio': 0.7}, {'word': 'フローフィールド', 'ratio': 0.2}, {'word': '流量場', 'ratio': 0.1}]",流れ場
1734,1998,flow model,フローモデル,0.6,10,"[{'word': 'フローモデル', 'ratio': 0.6}, {'word': '流れモデル', 'ratio': 0.3}, {'word': '流量モデル', 'ratio': 0.1}]",フローモデル
1735,2000,forecasting,予測,0.9,10,"[{'word': '予測', 'ratio': 0.9}, {'word': '予測する', 'ratio': 0.1}]",予測
1736,2001,foreground segmentation,前景セグメンテーション,0.7,10,"[{'word': '前景セグメンテーション', 'ratio': 0.7}, {'word': 'フォアグラウンドセグメンテーション', 'ratio': 0.1}, {'word': '前景のセグメンテーション', 'ratio': 0.1}, {'word': '前景分割', 'ratio': 0.1}]",前景セグメンテーション
1737,2002,forget gate,忘却ゲート,0.5,10,"[{'word': '忘却ゲート', 'ratio': 0.5}, {'word': 'フォゲート', 'ratio': 0.2}, {'word': 'フォゲットゲート', 'ratio': 0.1}, {'word': 'フェットゲート', 'ratio': 0.1}, {'word': '忘れた門', 'ratio': 0.1}]",忘却ゲート
1738,2005,forward pass,順伝播,0.0,9,"[{'word': 'フォワードパス', 'ratio': 0.6666666666666666}, {'word': '前方パス', 'ratio': 0.2222222222222222}, {'word': '前向きパス', 'ratio': 0.1111111111111111}]",フォワードパス
1739,2009,foundation model,基盤モデル,0.7777777777777778,9,"[{'word': '基盤モデル', 'ratio': 0.7777777777777778}, {'word': '基礎モデル', 'ratio': 0.2222222222222222}]",基盤モデル
1740,2011,fp16,FP16,0.0,9,"[{'word': 'fp16', 'ratio': 0.6666666666666666}, {'word': 'エフピー16', 'ratio': 0.2222222222222222}, {'word': '半精度浮動小数点数', 'ratio': 0.1111111111111111}]",fp16
1741,2012,fp32,FP32,0.0,9,"[{'word': 'fp32', 'ratio': 0.6666666666666666}, {'word': '単精度浮動小数点数', 'ratio': 0.1111111111111111}, {'word': 'エフピー32', 'ratio': 0.1111111111111111}, {'word': 'エフピーさんじゅうに', 'ratio': 0.1111111111111111}]",fp32
1742,2014,frame,フレーム,1.0,10,"[{'word': 'フレーム', 'ratio': 1.0}]",フレーム
1743,2015,free variable,自由変数,1.0,10,"[{'word': '自由変数', 'ratio': 1.0}]",自由変数
1744,2016,frequency penalty,頻度ペナルティ,0.8,10,"[{'word': '頻度ペナルティ', 'ratio': 0.8}, {'word': '周波数ペナルティ', 'ratio': 0.2}]",頻度ペナルティ
1745,2017,frequency vector,頻度ベクトル,0.8,10,"[{'word': '頻度ベクトル', 'ratio': 0.8}, {'word': '周波数ベクトル', 'ratio': 0.2}]",頻度ベクトル
1746,2020,frequent pattern,頻出パターン,1.0,9,"[{'word': '頻出パターン', 'ratio': 1.0}]",頻出パターン
1747,2021,frequent pattern mining,頻出パターンマイニング,1.0,9,"[{'word': '頻出パターンマイニング', 'ratio': 1.0}]",頻出パターンマイニング
1748,2022,fully connected graph,完全結合グラフ,0.0,9,"[{'word': '完全連結グラフ', 'ratio': 0.6666666666666666}, {'word': '完全に接続されたグラフ', 'ratio': 0.3333333333333333}]",完全連結グラフ
1749,2026,fully convolutional network,完全畳み込みネットワーク,0.7,10,"[{'word': '完全畳み込みネットワーク', 'ratio': 0.7}, {'word': '全畳み込みネットワーク', 'ratio': 0.1}, {'word': '完全な畳み込みネットワーク', 'ratio': 0.1}, {'word': 'Shōketsu-teki Konvūshonaru Nettowaku', 'ratio': 0.1}]",完全畳み込みネットワーク
1750,2027,fully convolutional neural network,フルコンボリューショナルニューラルネットワーク,0.0,10,"[{'word': '完全畳み込みニューラルネットワーク', 'ratio': 0.7}, {'word': '全畳み込みニューラルネットワーク', 'ratio': 0.1}, {'word': '完全畳み込みニューラル ネットワーク', 'ratio': 0.1}, {'word': 'Shōketsu-teki Konvūshonaru Neruā Nettowaku', 'ratio': 0.1}]",完全畳み込みニューラルネットワーク
1751,2028,fully-supervised model,完全教師ありモデル,0.8,10,"[{'word': '完全教師ありモデル', 'ratio': 0.8}, {'word': '完全監視モデル', 'ratio': 0.1}, {'word': 'Shūhensei-teki Model', 'ratio': 0.1}]",完全教師ありモデル
1752,2029,function approximation,関数近似,1.0,9,"[{'word': '関数近似', 'ratio': 1.0}]",関数近似
1753,2030,function approximator,関数近似器,1.0,9,"[{'word': '関数近似器', 'ratio': 1.0}]",関数近似器
1754,2031,function class,関数クラス,1.0,9,"[{'word': '関数クラス', 'ratio': 1.0}]",関数クラス
1755,2032,function space,関数空間,0.8888888888888888,9,"[{'word': '関数空間', 'ratio': 0.8888888888888888}, {'word': 'ファンクションスペース', 'ratio': 0.1111111111111111}]",関数空間
1756,2034,fundamental matrix,基本行列,0.7777777777777778,9,"[{'word': '基本行列', 'ratio': 0.7777777777777778}, {'word': '基底行列', 'ratio': 0.1111111111111111}, {'word': '基礎行列', 'ratio': 0.1111111111111111}]",基本行列
1757,2035,fusion module,融合モジュール,1.0,9,"[{'word': '融合モジュール', 'ratio': 1.0}]",融合モジュール
1758,2036,fuzzy matching,あいまい一致,0.0,9,"[{'word': 'ファジーマッチング', 'ratio': 0.8888888888888888}, {'word': 'フザー・マッチング', 'ratio': 0.1111111111111111}]",ファジーマッチング
1759,2037,g-value,g値,0.8888888888888888,9,"[{'word': 'g値', 'ratio': 0.8888888888888888}, {'word': 'グラム値', 'ratio': 0.1111111111111111}]",g値
1760,2038,game tree,ゲーム木,0.0,9,"[{'word': 'ゲームツリー', 'ratio': 1.0}]",ゲームツリー
1761,2039,game-theoretic analysis,ゲーム理論分析,0.2,10,"[{'word': 'ゲーム理論的分析', 'ratio': 0.7}, {'word': 'ゲーム理論分析', 'ratio': 0.2}, {'word': 'Sakuban-teki Bunseki', 'ratio': 0.1}]",ゲーム理論的分析
1762,2040,gate,ゲート,0.8,10,"[{'word': 'ゲート', 'ratio': 0.8}, {'word': 'Gēto', 'ratio': 0.1}, {'word': 'ゲーム理論的分析', 'ratio': 0.1}]",ゲート
1763,2041,gating function,ゲーティング関数,0.7,10,"[{'word': 'ゲーティング関数', 'ratio': 0.7}, {'word': 'ゲート機能', 'ratio': 0.2}, {'word': 'Gēto Funksyon', 'ratio': 0.1}]",ゲーティング関数
1764,2042,generalisation,一般化,0.9,10,"[{'word': '一般化', 'ratio': 0.9}, {'word': 'Sōgōshō', 'ratio': 0.1}]",一般化
1765,2043,generalization,一般化能力,0.4736842105263157,19,"[{'word': '一般化', 'ratio': 0.9473684210526315}, {'word': 'Sōgōshō', 'ratio': 0.05263157894736842}]",一般化
1766,2044,generalization ability,汎化能力,0.2222222222222222,9,"[{'word': '一般化能力', 'ratio': 0.7777777777777778}, {'word': '汎化能力', 'ratio': 0.2222222222222222}]",一般化能力
1767,2045,generalization bound,一般化限界,0.0,9,"[{'word': '一般化境界', 'ratio': 0.7777777777777778}, {'word': '汎化境界', 'ratio': 0.2222222222222222}]",一般化境界
1768,2046,generalization error,汎化誤差,0.2222222222222222,9,"[{'word': '一般化誤差', 'ratio': 0.7777777777777778}, {'word': '汎化誤差', 'ratio': 0.2222222222222222}]",一般化誤差
1769,2047,generalization gap,一般化ギャップ,0.7777777777777778,9,"[{'word': '一般化ギャップ', 'ratio': 0.7777777777777778}, {'word': '汎化ギャップ', 'ratio': 0.2222222222222222}]",一般化ギャップ
1770,2048,generalization guarantee,一般化保証,1.0,10,"[{'word': '一般化保証', 'ratio': 1.0}]",一般化保証
1771,2049,generalization performance,一般化性能,0.8,10,"[{'word': '一般化性能', 'ratio': 0.8}, {'word': '汎化性能', 'ratio': 0.1}, {'word': '一般化パフォーマンス', 'ratio': 0.1}]",一般化性能
1772,2050,generalized eigenvector,一般化固有ベクトル,1.0,10,"[{'word': '一般化固有ベクトル', 'ratio': 1.0}]",一般化固有ベクトル
1773,2051,generalized linear mixed model,一般化線形混合モデル,1.0,10,"[{'word': '一般化線形混合モデル', 'ratio': 1.0}]",一般化線形混合モデル
1774,2052,generalized linear model,一般化線形モデル,1.0,10,"[{'word': '一般化線形モデル', 'ratio': 1.0}]",一般化線形モデル
1775,2053,generation model,生成モデル,0.8,10,"[{'word': '生成モデル', 'ratio': 0.8}, {'word': '世代モデル', 'ratio': 0.2}]",生成モデル
1776,2054,generative,生成的,0.6,10,"[{'word': '生成的', 'ratio': 0.6}, {'word': 'ジェネレーティブ', 'ratio': 0.1}, {'word': 'ジェネレイティブ', 'ratio': 0.1}, {'word': '生成的な', 'ratio': 0.1}, {'word': 'Sōsei-teki', 'ratio': 0.1}]",生成的
1777,2056,generative approach,生成的アプローチ,0.6,10,"[{'word': '生成的アプローチ', 'ratio': 0.6}, {'word': 'ジェネレーティブアプローチ', 'ratio': 0.1}, {'word': 'ジェネレーティブ・アプローチ', 'ratio': 0.1}, {'word': '生成的なアプローチ', 'ratio': 0.1}, {'word': 'Sōsei-teki Sesshoku-hō', 'ratio': 0.1}]",生成的アプローチ
1778,2057,generative network,ジェネレーティブネットワーク,0.1,10,"[{'word': '生成ネットワーク', 'ratio': 0.5}, {'word': '生成的ネットワーク', 'ratio': 0.3}, {'word': 'ジェネレーティブネットワーク', 'ratio': 0.1}, {'word': 'Sōsei-teki Nettowaku', 'ratio': 0.1}]",生成ネットワーク
1779,2059,generative pre-training,生成事前学習,0.0,9,"[{'word': '生成的事前学習', 'ratio': 0.7777777777777778}, {'word': '生成的事前訓練', 'ratio': 0.1111111111111111}, {'word': '生成的な事前トレーニング', 'ratio': 0.1111111111111111}]",生成的事前学習
1780,2060,generative probabilistic model,生成確率モデル,0.4444444444444444,9,"[{'word': '生成的確率モデル', 'ratio': 0.5555555555555556}, {'word': '生成確率モデル', 'ratio': 0.4444444444444444}]",生成的確率モデル
1781,2061,generative process,生成過程,0.8888888888888888,9,"[{'word': '生成過程', 'ratio': 0.8888888888888888}, {'word': '生成プロセス', 'ratio': 0.1111111111111111}]",生成過程
1782,2066,geometric consistency,幾何学的一貫性,0.1111111111111111,9,"[{'word': '幾何的一貫性', 'ratio': 0.6666666666666666}, {'word': '幾何学的整合性', 'ratio': 0.1111111111111111}, {'word': '幾何学的一貫性', 'ratio': 0.1111111111111111}, {'word': '幾何学的一致性', 'ratio': 0.1111111111111111}]",幾何的一貫性
1783,2067,geometric distribution,幾何分布,0.7777777777777778,9,"[{'word': '幾何分布', 'ratio': 0.7777777777777778}, {'word': '幾何学的分布', 'ratio': 0.2222222222222222}]",幾何分布
1784,2069,geometric transformation,幾何変換,0.7777777777777778,9,"[{'word': '幾何変換', 'ratio': 0.7777777777777778}, {'word': '幾何学変換', 'ratio': 0.1111111111111111}, {'word': '幾何学的変換', 'ratio': 0.1111111111111111}]",幾何変換
1785,2070,geometry processing,幾何処理,0.7777777777777778,9,"[{'word': '幾何処理', 'ratio': 0.7777777777777778}, {'word': 'ジオメトリ処理', 'ratio': 0.2222222222222222}]",幾何処理
1786,2071,gibb distribution,ギブス分布,0.7777777777777778,9,"[{'word': 'ギブス分布', 'ratio': 0.7777777777777778}, {'word': 'ギブ・ディストリビューション', 'ratio': 0.1111111111111111}, {'word': 'ギブ分布', 'ratio': 0.1111111111111111}]",ギブス分布
1787,2072,gist descriptor,要点記述子,0.1111111111111111,9,"[{'word': 'ジスト記述子', 'ratio': 0.6666666666666666}, {'word': '概要記述子', 'ratio': 0.1111111111111111}, {'word': 'ギスト記述子', 'ratio': 0.1111111111111111}, {'word': '要点記述子', 'ratio': 0.1111111111111111}]",ジスト記述子
1788,2073,global average pooling,グローバル平均プーリング,0.8888888888888888,9,"[{'word': 'グローバル平均プーリング', 'ratio': 0.8888888888888888}, {'word': '世界的な平均プーリング', 'ratio': 0.1111111111111111}]",グローバル平均プーリング
1789,2074,global average pooling layer,グローバル平均プーリング層,0.9,10,"[{'word': 'グローバル平均プーリング層', 'ratio': 0.9}, {'word': 'グローバル平均プーリングレイヤー', 'ratio': 0.1}]",グローバル平均プーリング層
1790,2075,global coordinate frame,全体座標系,0.0,10,"[{'word': 'グローバル座標系', 'ratio': 0.7}, {'word': 'グローバル座標フレーム', 'ratio': 0.3}]",グローバル座標系
1791,2076,global illumination,グローバル照明,0.2,10,"[{'word': 'グローバルイルミネーション', 'ratio': 0.7}, {'word': 'グローバル照明', 'ratio': 0.2}, {'word': '全体照明', 'ratio': 0.1}]",グローバルイルミネーション
1792,2077,global minima,グローバル最小値,0.7,10,"[{'word': 'グローバル最小値', 'ratio': 0.7}, {'word': 'グローバルミニマム', 'ratio': 0.1}, {'word': 'グローバルミニマ', 'ratio': 0.1}, {'word': '大域的最小値', 'ratio': 0.1}]",グローバル最小値
1793,2078,global minimum,グローバル最小値,0.8,10,"[{'word': 'グローバル最小値', 'ratio': 0.8}, {'word': 'グローバルミニマム', 'ratio': 0.2}]",グローバル最小値
1794,2079,global model,グローバルモデル,0.8888888888888888,9,"[{'word': 'グローバルモデル', 'ratio': 0.8888888888888888}, {'word': '全体モデル', 'ratio': 0.1111111111111111}]",グローバルモデル
1795,2081,global optima,グローバル最適解,0.7777777777777778,9,"[{'word': 'グローバル最適解', 'ratio': 0.7777777777777778}, {'word': 'グローバルオプティマ', 'ratio': 0.2222222222222222}]",グローバル最適解
1796,2082,global optimization,グローバル最適化,0.8888888888888888,9,"[{'word': 'グローバル最適化', 'ratio': 0.8888888888888888}, {'word': '全体最適化', 'ratio': 0.1111111111111111}]",グローバル最適化
1797,2084,global pooling,グローバルプーリング,0.9,10,"[{'word': 'グローバルプーリング', 'ratio': 0.9}, {'word': 'グローバル・プーリング', 'ratio': 0.1}]",グローバルプーリング
1798,2085,global reward,グローバル報酬,1.0,10,"[{'word': 'グローバル報酬', 'ratio': 1.0}]",グローバル報酬
1799,2086,goal state,目標状態,0.6,10,"[{'word': '目標状態', 'ratio': 0.6}, {'word': 'ゴール状態', 'ratio': 0.4}]",目標状態
1800,2087,gold label,正解ラベル,0.1,10,"[{'word': 'ゴールドラベル', 'ratio': 0.9}, {'word': '正解ラベル', 'ratio': 0.1}]",ゴールドラベル
1801,2088,gold parse,正解の構文解析,0.0,10,"[{'word': 'ゴールドパース', 'ratio': 0.9}, {'word': '正解構文', 'ratio': 0.1}]",ゴールドパース
1802,2089,gossip algorithm,ゴシップアルゴリズム,1.0,9,"[{'word': 'ゴシップアルゴリズム', 'ratio': 1.0}]",ゴシップアルゴリズム
1803,2090,gradient accumulation,勾配蓄積,0.6666666666666666,9,"[{'word': '勾配蓄積', 'ratio': 0.6666666666666666}, {'word': '勾配集積', 'ratio': 0.2222222222222222}, {'word': '勾配累積', 'ratio': 0.1111111111111111}]",勾配蓄積
1804,2091,gradient accumulation step,勾配累積ステップ,0.3333333333333333,9,"[{'word': '勾配蓄積ステップ', 'ratio': 0.6666666666666666}, {'word': '勾配累積ステップ', 'ratio': 0.3333333333333333}]",勾配蓄積ステップ
1805,2092,gradient ascent,勾配上昇法,0.1111111111111111,9,"[{'word': '勾配上昇', 'ratio': 0.8888888888888888}, {'word': '勾配上昇法', 'ratio': 0.1111111111111111}]",勾配上昇
1806,2094,gradient clipping,勾配クリッピング,0.6666666666666666,9,"[{'word': '勾配クリッピング', 'ratio': 0.6666666666666666}, {'word': 'グラデーションクリッピング', 'ratio': 0.2222222222222222}, {'word': 'Guradian Kippingu', 'ratio': 0.1111111111111111}]",勾配クリッピング
1807,2095,gradient computation,勾配計算,0.8888888888888888,9,"[{'word': '勾配計算', 'ratio': 0.8888888888888888}, {'word': 'Guradian Keisanki', 'ratio': 0.1111111111111111}]",勾配計算
1808,2096,gradient descent algorithm,勾配降下法,0.1111111111111111,9,"[{'word': '勾配降下アルゴリズム', 'ratio': 0.6666666666666666}, {'word': '勾配降下法', 'ratio': 0.1111111111111111}, {'word': '勾配降下法アルゴリズム', 'ratio': 0.1111111111111111}, {'word': 'Guradian Desento Sōgō', 'ratio': 0.1111111111111111}]",勾配降下アルゴリズム
1809,2097,gradient estimate,勾配推定,0.8888888888888888,9,"[{'word': '勾配推定', 'ratio': 0.8888888888888888}, {'word': 'Guradian Setsugaku', 'ratio': 0.1111111111111111}]",勾配推定
1810,2098,gradient estimation,勾配推定,0.9,10,"[{'word': '勾配推定', 'ratio': 0.9}, {'word': 'グラデーション推定', 'ratio': 0.1}]",勾配推定
1811,2099,gradient estimator,勾配推定器,0.9,10,"[{'word': '勾配推定器', 'ratio': 0.9}, {'word': 'グラデーション推定器', 'ratio': 0.1}]",勾配推定器
1812,2100,gradient explosion,勾配爆発,1.0,10,"[{'word': '勾配爆発', 'ratio': 1.0}]",勾配爆発
1813,2101,gradient flow,勾配フロー,0.5,10,"[{'word': '勾配フロー', 'ratio': 0.5}, {'word': '勾配の流れ', 'ratio': 0.3}, {'word': '勾配流', 'ratio': 0.2}]",勾配フロー
1814,2102,gradient information,勾配情報,1.0,10,"[{'word': '勾配情報', 'ratio': 1.0}]",勾配情報
1815,2103,gradient method,勾配法,1.0,10,"[{'word': '勾配法', 'ratio': 1.0}]",勾配法
1816,2104,gradient norm,勾配ノルム,1.0,10,"[{'word': '勾配ノルム', 'ratio': 1.0}]",勾配ノルム
1817,2105,gradient operator,勾配演算子,1.0,10,"[{'word': '勾配演算子', 'ratio': 1.0}]",勾配演算子
1818,2106,gradient penalty,勾配ペナルティ,1.0,10,"[{'word': '勾配ペナルティ', 'ratio': 1.0}]",勾配ペナルティ
1819,2107,gradient signal,勾配シグナル,0.0,10,"[{'word': '勾配信号', 'ratio': 1.0}]",勾配信号
1820,2108,gradient step,勾配ステップ,0.9,10,"[{'word': '勾配ステップ', 'ratio': 0.9}, {'word': 'グラデーションステップ', 'ratio': 0.1}]",勾配ステップ
1821,2109,gradient term,勾配項,1.0,10,"[{'word': '勾配項', 'ratio': 1.0}]",勾配項
1822,2110,gradient update,勾配更新,0.8,10,"[{'word': '勾配更新', 'ratio': 0.8}, {'word': 'グラデーション・アップデート', 'ratio': 0.1}, {'word': 'グラデーションの更新', 'ratio': 0.1}]",勾配更新
1823,2111,gradient variance,勾配の分散,0.0,10,"[{'word': '勾配分散', 'ratio': 1.0}]",勾配分散
1824,2112,gradient vector,勾配ベクトル,1.0,10,"[{'word': '勾配ベクトル', 'ratio': 1.0}]",勾配ベクトル
1825,2113,gradient-based approach,勾配ベースのアプローチ,0.9,10,"[{'word': '勾配ベースのアプローチ', 'ratio': 0.9}, {'word': '勾配に基づくアプローチ', 'ratio': 0.1}]",勾配ベースのアプローチ
1826,2114,gradient-based learning,勾配ベース学習,0.0,10,"[{'word': '勾配ベースの学習', 'ratio': 0.9}, {'word': '勾配に基づく学習', 'ratio': 0.1}]",勾配ベースの学習
1827,2115,gradient-based method,勾配ベース法,0.0,10,"[{'word': '勾配ベースの手法', 'ratio': 0.5}, {'word': '勾配ベースの方法', 'ratio': 0.3}, {'word': '勾配法', 'ratio': 0.1}, {'word': '勾配に基づく手法', 'ratio': 0.1}]",勾配ベースの手法
1828,2116,gradient-based optimization,勾配ベースの最適化,0.9,10,"[{'word': '勾配ベースの最適化', 'ratio': 0.9}, {'word': '勾配に基づく最適化', 'ratio': 0.1}]",勾配ベースの最適化
1829,2118,grammar induction,"""文法誘導""",0.0,9,"[{'word': '文法誘導', 'ratio': 0.5555555555555556}, {'word': '文法導入', 'ratio': 0.3333333333333333}, {'word': '文法生成', 'ratio': 0.1111111111111111}]",文法誘導
1830,2120,grandparent dependency,祖父母依存,0.1111111111111111,9,"[{'word': '祖父母依存関係', 'ratio': 0.5555555555555556}, {'word': '祖父母の依存関係', 'ratio': 0.2222222222222222}, {'word': '祖父依存関係', 'ratio': 0.1111111111111111}, {'word': '祖父母依存', 'ratio': 0.1111111111111111}]",祖父母依存関係
1831,2121,graph Laplacian,グラフラプラシアン,0.7777777777777778,9,"[{'word': 'グラフラプラシアン', 'ratio': 0.7777777777777778}, {'word': 'グラフ・ラプラシアン', 'ratio': 0.1111111111111111}, {'word': 'ラプラシアングラフ', 'ratio': 0.1111111111111111}]",グラフラプラシアン
1832,2122,graph Laplacian matrix,グラフのラプラシアン行列,0.1111111111111111,9,"[{'word': 'グラフラプラシアン行列', 'ratio': 0.7777777777777778}, {'word': 'グラフ・ラプラシアン行列', 'ratio': 0.1111111111111111}, {'word': 'グラフのラプラシアン行列', 'ratio': 0.1111111111111111}]",グラフラプラシアン行列
1833,2123,graph adjacency matrix,グラフ隣接行列,1.0,9,"[{'word': 'グラフ隣接行列', 'ratio': 1.0}]",グラフ隣接行列
1834,2124,graph attention,グラフアテンション,0.7777777777777778,9,"[{'word': 'グラフアテンション', 'ratio': 0.7777777777777778}, {'word': 'グラフ注目度', 'ratio': 0.1111111111111111}, {'word': 'グラフの注意', 'ratio': 0.1111111111111111}]",グラフアテンション
1835,2125,graph attention mechanism,グラフ注意メカニズム (Graph Attention Mechanism),0.0,10,"[{'word': 'グラフ注意機構', 'ratio': 0.5}, {'word': 'グラフ注意メカニズム', 'ratio': 0.2}, {'word': 'グラフ注目メカニズム', 'ratio': 0.1}, {'word': 'グラフアテンションメカニズム', 'ratio': 0.1}, {'word': 'グラフアテンション機構', 'ratio': 0.1}]",グラフ注意機構
1836,2126,graph attention network,グラフアテンションネットワーク,0.2,10,"[{'word': 'グラフ注意ネットワーク', 'ratio': 0.7}, {'word': 'グラフアテンションネットワーク', 'ratio': 0.2}, {'word': 'グラフ・アテンション・ネットワーク', 'ratio': 0.1}]",グラフ注意ネットワーク
1837,2127,graph classification,グラフ分類,0.9,10,"[{'word': 'グラフ分類', 'ratio': 0.9}, {'word': 'グラフの分類', 'ratio': 0.1}]",グラフ分類
1838,2128,graph clustering,グラフクラスタリング,1.0,10,"[{'word': 'グラフクラスタリング', 'ratio': 1.0}]",グラフクラスタリング
1839,2129,graph construction,グラフ構築,0.9,10,"[{'word': 'グラフ構築', 'ratio': 0.9}, {'word': 'グラフ構造', 'ratio': 0.1}]",グラフ構築
1840,2130,graph contrastive learning,グラフ対照学習,0.3,10,"[{'word': 'グラフ対比学習', 'ratio': 0.6}, {'word': 'グラフ対照学習', 'ratio': 0.3}, {'word': 'グラフコントラスト学習', 'ratio': 0.1}]",グラフ対比学習
1841,2131,graph convolution,グラフ畳み込み,0.9,10,"[{'word': 'グラフ畳み込み', 'ratio': 0.9}, {'word': 'グラフの畳み込み', 'ratio': 0.1}]",グラフ畳み込み
1842,2132,graph convolution network,グラフ畳み込みネットワーク,1.0,10,"[{'word': 'グラフ畳み込みネットワーク', 'ratio': 1.0}]",グラフ畳み込みネットワーク
1843,2133,graph convolutional network,グラフ畳み込みネットワーク,1.0,10,"[{'word': 'グラフ畳み込みネットワーク', 'ratio': 1.0}]",グラフ畳み込みネットワーク
1844,2134,graph cut,グラフカット,1.0,10,"[{'word': 'グラフカット', 'ratio': 1.0}]",グラフカット
1845,2135,graph cut algorithm,グラフカットアルゴリズム,1.0,10,"[{'word': 'グラフカットアルゴリズム', 'ratio': 1.0}]",グラフカットアルゴリズム
1846,2136,graph dataset,グラフデータセット,1.0,10,"[{'word': 'グラフデータセット', 'ratio': 1.0}]",グラフデータセット
1847,2137,graph datum,グラフデータ,1.0,10,"[{'word': 'グラフデータ', 'ratio': 1.0}]",グラフデータ
1848,2138,graph diameter,グラフ直径,1.0,10,"[{'word': 'グラフ直径', 'ratio': 1.0}]",グラフ直径
1849,2139,graph embedding,グラフ埋め込み,0.9,10,"[{'word': 'グラフ埋め込み', 'ratio': 0.9}, {'word': 'グラフエンコード', 'ratio': 0.1}]",グラフ埋め込み
1850,2140,graph generator,グラフ生成器,0.6666666666666666,9,"[{'word': 'グラフ生成器', 'ratio': 0.6666666666666666}, {'word': 'グラフジェネレータ', 'ratio': 0.1111111111111111}, {'word': 'グラフジェネレーター', 'ratio': 0.1111111111111111}, {'word': 'Gurafu Ginetā', 'ratio': 0.1111111111111111}]",グラフ生成器
1851,2141,graph isomorphism,グラフ同型性,0.6666666666666666,9,"[{'word': 'グラフ同型性', 'ratio': 0.6666666666666666}, {'word': 'グラフ同型', 'ratio': 0.1111111111111111}, {'word': 'グラフの同型性', 'ratio': 0.1111111111111111}, {'word': 'Gurafu Isomorfizumabu', 'ratio': 0.1111111111111111}]",グラフ同型性
1852,2142,graph kernel,グラフカーネル,0.8888888888888888,9,"[{'word': 'グラフカーネル', 'ratio': 0.8888888888888888}, {'word': 'Gurafu Kernalu', 'ratio': 0.1111111111111111}]",グラフカーネル
1853,2143,graph learning,グラフ事前学習,0.0,9,"[{'word': 'グラフ学習', 'ratio': 0.8888888888888888}, {'word': 'Gurafu Riningu', 'ratio': 0.1111111111111111}]",グラフ学習
1854,2144,graph matching,グラフマッチング,0.8888888888888888,9,"[{'word': 'グラフマッチング', 'ratio': 0.8888888888888888}, {'word': 'Gurafu Matschin', 'ratio': 0.1111111111111111}]",グラフマッチング
1855,2145,graph mining,グラフマイニング,1.0,10,"[{'word': 'グラフマイニング', 'ratio': 1.0}]",グラフマイニング
1856,2146,graph model,グラフモデル,1.0,10,"[{'word': 'グラフモデル', 'ratio': 1.0}]",グラフモデル
1857,2147,graph neural network,グラフニューラルネットワーク,0.9,10,"[{'word': 'グラフニューラルネットワーク', 'ratio': 0.9}, {'word': 'グラフ・ニューラル・ネットワーク', 'ratio': 0.1}]",グラフニューラルネットワーク
1858,2148,graph node,グラフノード,1.0,10,"[{'word': 'グラフノード', 'ratio': 1.0}]",グラフノード
1859,2149,graph partitioning,グラフ分割,1.0,10,"[{'word': 'グラフ分割', 'ratio': 1.0}]",グラフ分割
1860,2150,graph pattern,グラフパターン,1.0,9,"[{'word': 'グラフパターン', 'ratio': 1.0}]",グラフパターン
1861,2151,graph representation,グラフ表現,1.0,9,"[{'word': 'グラフ表現', 'ratio': 1.0}]",グラフ表現
1862,2152,graph sampling,グラフサンプリング,1.0,9,"[{'word': 'グラフサンプリング', 'ratio': 1.0}]",グラフサンプリング
1863,2153,graph structure,グラフ構造,1.0,9,"[{'word': 'グラフ構造', 'ratio': 1.0}]",グラフ構造
1864,2154,graph theory,グラフ理論,1.0,9,"[{'word': 'グラフ理論', 'ratio': 1.0}]",グラフ理論
1865,2155,graph topology,グラフトポロジー,1.0,10,"[{'word': 'グラフトポロジー', 'ratio': 1.0}]",グラフトポロジー
1866,2156,graph traversal,グラフ走査,0.2,10,"[{'word': 'グラフトラバーサル', 'ratio': 0.7}, {'word': 'グラフ走査', 'ratio': 0.2}, {'word': 'グラフ遍歴', 'ratio': 0.1}]",グラフトラバーサル
1867,2157,graph-based approach,グラフベースのアプローチ,0.8,10,"[{'word': 'グラフベースのアプローチ', 'ratio': 0.8}, {'word': 'グラフ・ベース・アプローチ', 'ratio': 0.2}]",グラフベースのアプローチ
1868,2158,graph-based dependency parsing,グラフベース依存構造解析,0.0,10,"[{'word': 'グラフベースの依存構文解析', 'ratio': 0.5}, {'word': 'グラフベースの依存関係解析', 'ratio': 0.3}, {'word': 'グラフベースの依存解析', 'ratio': 0.1}, {'word': 'グラフベースの依存構造解析', 'ratio': 0.1}]",グラフベースの依存構文解析
1869,2159,graph-based learning,グラフベース学習,0.2,10,"[{'word': 'グラフベースの学習', 'ratio': 0.8}, {'word': 'グラフベース学習', 'ratio': 0.2}]",グラフベースの学習
1870,2160,graph-based method,グラフベース法,0.0,10,"[{'word': 'グラフベースの手法', 'ratio': 0.6}, {'word': 'グラフ法', 'ratio': 0.2}, {'word': 'グラフベースメソッド', 'ratio': 0.1}, {'word': 'グラフベース手法', 'ratio': 0.1}]",グラフベースの手法
1871,2161,graph-based model,グラフベースモデル,0.4,10,"[{'word': 'グラフベースのモデル', 'ratio': 0.6}, {'word': 'グラフベースモデル', 'ratio': 0.4}]",グラフベースのモデル
1872,2162,graph-based representation,グラフベース表現,0.4,10,"[{'word': 'グラフベースの表現', 'ratio': 0.6}, {'word': 'グラフベース表現', 'ratio': 0.4}]",グラフベースの表現
1873,2163,graph-level task,グラフレベルのタスク,0.6,10,"[{'word': 'グラフレベルのタスク', 'ratio': 0.6}, {'word': 'グラフレベル・タスク', 'ratio': 0.2}, {'word': 'グラフレベルトスク', 'ratio': 0.1}, {'word': 'グラフレベルタスク', 'ratio': 0.1}]",グラフレベルのタスク
1874,2164,graphical model,グラフィカルモデル,0.9,10,"[{'word': 'グラフィカルモデル', 'ratio': 0.9}, {'word': 'グラフィカル・モード', 'ratio': 0.1}]",グラフィカルモデル
1875,2165,graphlet,グラフレット,1.0,9,"[{'word': 'グラフレット', 'ratio': 1.0}]",グラフレット
1876,2166,graphlet kernel,グラフレットカーネル,1.0,9,"[{'word': 'グラフレットカーネル', 'ratio': 1.0}]",グラフレットカーネル
1877,2167,greedy algorithm,貪欲なアルゴリズム,0.0,9,"[{'word': '貪欲アルゴリズム', 'ratio': 0.7777777777777778}, {'word': '欲張りアルゴリズム', 'ratio': 0.2222222222222222}]",貪欲アルゴリズム
1878,2168,greedy approach,貪欲法,0.0,9,"[{'word': '貪欲アプローチ', 'ratio': 0.6666666666666666}, {'word': '貪欲なアプローチ', 'ratio': 0.1111111111111111}, {'word': '貪欲手法', 'ratio': 0.1111111111111111}, {'word': '欲張りアルゴリズム', 'ratio': 0.1111111111111111}]",貪欲アプローチ
1879,2170,greedy inference,貪欲推論,0.5,10,"[{'word': '貪欲推論', 'ratio': 0.5}, {'word': 'グリーディ推論', 'ratio': 0.2}, {'word': '貪欲な推論', 'ratio': 0.2}, {'word': '贅沢推論', 'ratio': 0.1}]",貪欲推論
1880,2172,greedy method,貪欲法,0.5,10,"[{'word': '貪欲法', 'ratio': 0.5}, {'word': 'グリーディ法', 'ratio': 0.2}, {'word': '貪欲な方法', 'ratio': 0.2}, {'word': '贅沢法', 'ratio': 0.1}]",貪欲法
1881,2175,greedy search,貪欲探索,0.6666666666666666,9,"[{'word': '貪欲探索', 'ratio': 0.6666666666666666}, {'word': '貪欲な探索', 'ratio': 0.2222222222222222}, {'word': '貪欲な検索', 'ratio': 0.1111111111111111}]",貪欲探索
1882,2176,greedy strategy,貪欲戦略,0.6666666666666666,9,"[{'word': '貪欲戦略', 'ratio': 0.6666666666666666}, {'word': '貪欲な戦略', 'ratio': 0.2222222222222222}, {'word': '強欲戦略', 'ratio': 0.1111111111111111}]",貪欲戦略
1883,2177,grid cell,グリッド細胞,0.5555555555555556,9,"[{'word': 'グリッド細胞', 'ratio': 0.5555555555555556}, {'word': 'グリッドセル', 'ratio': 0.4444444444444444}]",グリッド細胞
1884,2178,grid search,グリッドサーチ,0.7777777777777778,9,"[{'word': 'グリッドサーチ', 'ratio': 0.7777777777777778}, {'word': 'グリッド検索', 'ratio': 0.2222222222222222}]",グリッドサーチ
1885,2179,grid-world,グリッドワールド,1.0,10,"[{'word': 'グリッドワールド', 'ratio': 1.0}]",グリッドワールド
1886,2180,ground atom,グラウンドアトム,0.7,10,"[{'word': 'グラウンドアトム', 'ratio': 0.7}, {'word': '基底原子', 'ratio': 0.2}, {'word': '基本原子', 'ratio': 0.1}]",グラウンドアトム
1887,2181,ground set,基底集合,0.1,10,"[{'word': 'グラウンドセット', 'ratio': 0.7}, {'word': '基底集合', 'ratio': 0.1}, {'word': 'グランドセット', 'ratio': 0.1}, {'word': '基本集合', 'ratio': 0.1}]",グラウンドセット
1888,2183,ground-truth box,正解ボックス,0.3,10,"[{'word': 'グラウンドトゥルースボックス', 'ratio': 0.5}, {'word': '正解ボックス', 'ratio': 0.3}, {'word': '真実の箱', 'ratio': 0.1}, {'word': '真のボックス', 'ratio': 0.1}]",グラウンドトゥルースボックス
1889,2186,group normalization,グループ正規化,0.7777777777777778,9,"[{'word': 'グループ正規化', 'ratio': 0.7777777777777778}, {'word': 'グループの正規化', 'ratio': 0.1111111111111111}, {'word': 'Gurūpō Norumēshon', 'ratio': 0.1111111111111111}]",グループ正規化
1890,2187,group sparsity,グループ疎性,0.0,9,"[{'word': 'グループスパース性', 'ratio': 0.6666666666666666}, {'word': 'グループスパーシティ', 'ratio': 0.1111111111111111}, {'word': 'グループの疎性', 'ratio': 0.1111111111111111}, {'word': 'Gurūpō Sukarītī', 'ratio': 0.1111111111111111}]",グループスパース性
1891,2188,half-space,半空間,0.8888888888888888,9,"[{'word': '半空間', 'ratio': 0.8888888888888888}, {'word': '半角スペース', 'ratio': 0.1111111111111111}]",半空間
1892,2189,hand pose estimation,手の姿勢推定,0.1111111111111111,9,"[{'word': '手のポーズ推定', 'ratio': 0.8888888888888888}, {'word': '手の姿勢推定', 'ratio': 0.1111111111111111}]",手のポーズ推定
1893,2190,hard attention,ハードアテンション,0.7777777777777778,9,"[{'word': 'ハードアテンション', 'ratio': 0.7777777777777778}, {'word': '厳しい目', 'ratio': 0.1111111111111111}, {'word': '厳しい注意', 'ratio': 0.1111111111111111}]",ハードアテンション
1894,2191,hash,ハッシュ,1.0,9,"[{'word': 'ハッシュ', 'ratio': 1.0}]",ハッシュ
1895,2192,hash function,ハッシュ関数,1.0,9,"[{'word': 'ハッシュ関数', 'ratio': 1.0}]",ハッシュ関数
1896,2193,hash table,ハッシュテーブル,1.0,10,"[{'word': 'ハッシュテーブル', 'ratio': 1.0}]",ハッシュテーブル
1897,2194,hashing algorithm,ハッシュアルゴリズム,0.3,10,"[{'word': 'ハッシングアルゴリズム', 'ratio': 0.5}, {'word': 'ハッシュアルゴリズム', 'ratio': 0.3}, {'word': 'ハッシュ化アルゴリズム', 'ratio': 0.2}]",ハッシングアルゴリズム
1898,2195,hate speech classifier,差別的発言分類器,0.0,10,"[{'word': 'ヘイトスピーチ分類器', 'ratio': 1.0}]",ヘイトスピーチ分類器
1899,2196,hate speech detection,憎悪表現検出,0.0,10,"[{'word': 'ヘイトスピーチ検出', 'ratio': 0.8}, {'word': 'ヘイトスピーチの検出', 'ratio': 0.2}]",ヘイトスピーチ検出
1900,2197,head entity,主体エンティティ,0.0,10,"[{'word': 'ヘッドエンティティ', 'ratio': 0.8}, {'word': '主語エンティティ', 'ratio': 0.2}]",ヘッドエンティティ
1901,2198,head word,中心語,0.0,10,"[{'word': '見出し語', 'ratio': 0.6}, {'word': '主語', 'ratio': 0.2}, {'word': 'ヘッドワード', 'ratio': 0.1}, {'word': 'Heddo Wōdo', 'ratio': 0.1}]",見出し語
1902,2199,heap structure,ヒープ構造,0.9,10,"[{'word': 'ヒープ構造', 'ratio': 0.9}, {'word': 'Heppu Kōzō)', 'ratio': 0.1}]",ヒープ構造
1903,2200,heatmap,ヒートマップ,0.9,10,"[{'word': 'ヒートマップ', 'ratio': 0.9}, {'word': 'Hīto Mapu', 'ratio': 0.1}]",ヒートマップ
1904,2202,heuristic algorithm,ヒューリスティックアルゴリズム,0.8,10,"[{'word': 'ヒューリスティックアルゴリズム', 'ratio': 0.8}, {'word': '発見的アルゴリズム', 'ratio': 0.2}]",ヒューリスティックアルゴリズム
1905,2203,heuristic function,ヒューリスティック関数,0.8,10,"[{'word': 'ヒューリスティック関数', 'ratio': 0.8}, {'word': '発見的機能', 'ratio': 0.2}]",ヒューリスティック関数
1906,2204,heuristic search,発見的探索,0.2,10,"[{'word': 'ヒューリスティック探索', 'ratio': 0.8}, {'word': '発見的探索', 'ratio': 0.2}]",ヒューリスティック探索
1907,2205,heuristic search algorithm,ヒューリスティック探索アルゴリズム,0.8,10,"[{'word': 'ヒューリスティック探索アルゴリズム', 'ratio': 0.8}, {'word': '発見的探索アルゴリズム', 'ratio': 0.1}, {'word': '発見的探索', 'ratio': 0.1}]",ヒューリスティック探索アルゴリズム
1908,2206,heuristic value,ヒューリスティック値,0.8,10,"[{'word': 'ヒューリスティック値', 'ratio': 0.8}, {'word': '発見的価値', 'ratio': 0.2}]",ヒューリスティック値
1909,2207,hidden dimension,"""隠れた次元 (kakureta jigen)""",0.0,10,"[{'word': '隠れ次元', 'ratio': 0.8}, {'word': '隠された次元', 'ratio': 0.2}]",隠れ次元
1910,2209,hidden dimensionality,隠れ次元数,0.5,10,"[{'word': '隠れ次元数', 'ratio': 0.5}, {'word': '隠れ次元性', 'ratio': 0.3}, {'word': '隠れた次元性', 'ratio': 0.1}, {'word': '隠れた次元', 'ratio': 0.1}]",隠れ次元数
1911,2210,hidden embedding,潜在埋め込み,0.0,10,"[{'word': '隠れ埋め込み', 'ratio': 0.8}, {'word': '隠し埋め込み', 'ratio': 0.2}]",隠れ埋め込み
1912,2211,hidden feature,"""隠れた特徴""",0.0,10,"[{'word': '隠れ特徴', 'ratio': 0.8}, {'word': '隠し機能', 'ratio': 0.1}, {'word': '隠れた機能', 'ratio': 0.1}]",隠れ特徴
1913,2212,hidden layer,隠れ層,1.0,10,"[{'word': '隠れ層', 'ratio': 1.0}]",隠れ層
1914,2213,hidden representation,隠れ表現,0.8,10,"[{'word': '隠れ表現', 'ratio': 0.8}, {'word': '隠し表現', 'ratio': 0.2}]",隠れ表現
1915,2214,hidden size,隠れ層サイズ,0.0,10,"[{'word': '隠れサイズ', 'ratio': 0.8}, {'word': '隠しサイズ', 'ratio': 0.2}]",隠れサイズ
1916,2215,hidden state,隠れ状態,0.8,10,"[{'word': '隠れ状態', 'ratio': 0.8}, {'word': '隠された状態', 'ratio': 0.2}]",隠れ状態
1917,2216,hidden state dimension,隠れ状態次元,0.5,10,"[{'word': '隠れ状態次元', 'ratio': 0.5}, {'word': 'かくれた状態の次元', 'ratio': 0.2}, {'word': '隠れ状態の次元', 'ratio': 0.2}, {'word': '隠れ状態ディメンション', 'ratio': 0.1}]",隠れ状態次元
1918,2217,hidden state representation,隠れ状態表現,0.8,10,"[{'word': '隠れ状態表現', 'ratio': 0.8}, {'word': '隠れた状態の表現', 'ratio': 0.2}]",隠れ状態表現
1919,2218,hidden state vector,隠れ状態ベクトル,1.0,10,"[{'word': '隠れ状態ベクトル', 'ratio': 1.0}]",隠れ状態ベクトル
1920,2219,hidden unit,隠れユニット,0.8,10,"[{'word': '隠れユニット', 'ratio': 0.8}, {'word': '隠しユニット', 'ratio': 0.2}]",隠れユニット
1921,2220,hidden variable,潜在変数,0.0,10,"[{'word': '隠れ変数', 'ratio': 0.8}, {'word': '隠し変数', 'ratio': 0.2}]",隠れ変数
1922,2221,hierarchical agglomerative clustering,階層的凝集クラスタリング,0.9,10,"[{'word': '階層的凝集クラスタリング', 'ratio': 0.9}, {'word': '階層的凝縮クラスタリング', 'ratio': 0.1}]",階層的凝集クラスタリング
1923,2222,hierarchical clustering,階層的クラスタリング,0.5,10,"[{'word': '階層的クラスタリング', 'ratio': 0.5}, {'word': '階層クラスタリング', 'ratio': 0.5}]",階層的クラスタリング
1924,2223,hierarchical decoder,階層的デコーダ,0.1,10,"[{'word': '階層デコーダ', 'ratio': 0.6}, {'word': '階層型デコーダ', 'ratio': 0.2}, {'word': '階層的デコーダー', 'ratio': 0.1}, {'word': '階層的デコーダ', 'ratio': 0.1}]",階層デコーダ
1925,2224,hierarchical feature,階層的特徴,1.0,10,"[{'word': '階層的特徴', 'ratio': 1.0}]",階層的特徴
1926,2225,hierarchical inference,階層推論,0.3,10,"[{'word': '階層的推論', 'ratio': 0.7}, {'word': '階層推論', 'ratio': 0.3}]",階層的推論
1927,2226,hierarchical method,階層的手法,0.9,10,"[{'word': '階層的手法', 'ratio': 0.9}, {'word': '階層的方法', 'ratio': 0.1}]",階層的手法
1928,2227,hierarchical model,階層モデル,1.0,9,"[{'word': '階層モデル', 'ratio': 1.0}]",階層モデル
1929,2228,hierarchical reinforcement learning,階層強化学習,0.5555555555555556,9,"[{'word': '階層強化学習', 'ratio': 0.5555555555555556}, {'word': '階層的強化学習', 'ratio': 0.3333333333333333}, {'word': '階層型強化学習', 'ratio': 0.1111111111111111}]",階層強化学習
1930,2229,hierarchical representation,階層表現,0.3333333333333333,9,"[{'word': '階層的表現', 'ratio': 0.6666666666666666}, {'word': '階層表現', 'ratio': 0.3333333333333333}]",階層的表現
1931,2230,hierarchical structure,階層構造,1.0,9,"[{'word': '階層構造', 'ratio': 1.0}]",階層構造
1932,2231,hierarchical topic model,階層的トピックモデル,0.4444444444444444,9,"[{'word': '階層トピックモデル', 'ratio': 0.5555555555555556}, {'word': '階層的トピックモデル', 'ratio': 0.4444444444444444}]",階層トピックモデル
1933,2232,hierarchy,階層構造,0.0,10,"[{'word': '階層', 'ratio': 0.9}, {'word': 'ヒエラルキー', 'ratio': 0.1}]",階層
1934,2233,high-dimensional datum,高次元データ,1.0,10,"[{'word': '高次元データ', 'ratio': 1.0}]",高次元データ
1935,2234,high-dimensional space,高次元空間,1.0,10,"[{'word': '高次元空間', 'ratio': 1.0}]",高次元空間
1936,2235,high-dimensionality,高次元性,0.9,10,"[{'word': '高次元性', 'ratio': 0.9}, {'word': '高次元', 'ratio': 0.1}]",高次元性
1937,2236,higher-order feature,高次特徴,0.5,10,"[{'word': '高次特徴', 'ratio': 0.5}, {'word': '高次の特徴', 'ratio': 0.2}, {'word': '高次機能', 'ratio': 0.1}, {'word': '高次元特徴', 'ratio': 0.1}, {'word': '高階特徴', 'ratio': 0.1}]",高次特徴
1938,2237,higher-order model,高次モデル,0.9,10,"[{'word': '高次モデル', 'ratio': 0.9}, {'word': '高次元モデル', 'ratio': 0.1}]",高次モデル
1939,2238,hill-climbing,山登り法,0.1,10,"[{'word': 'ヒルクライミング', 'ratio': 0.6}, {'word': 'ヒルクライム', 'ratio': 0.3}, {'word': '山登り法', 'ratio': 0.1}]",ヒルクライミング
1940,2239,hinge loss,ヒンジ損失,1.0,10,"[{'word': 'ヒンジ損失', 'ratio': 1.0}]",ヒンジ損失
1941,2240,hinge loss function,ヒンジ損失関数,1.0,10,"[{'word': 'ヒンジ損失関数', 'ratio': 1.0}]",ヒンジ損失関数
1942,2241,histogram of oriented gradient,方向勾配のヒストグラム,0.1,10,"[{'word': '勾配方向ヒストグラム', 'ratio': 0.7}, {'word': '方向勾配のヒストグラム', 'ratio': 0.1}, {'word': '方位勾配のアイソグラム', 'ratio': 0.1}, {'word': 'ヒンジ損失関数', 'ratio': 0.1}]",勾配方向ヒストグラム
1943,2242,homogeneous coordinate,同次座標,0.8,10,"[{'word': '同次座標', 'ratio': 0.8}, {'word': '均一座標', 'ratio': 0.1}, {'word': '均質座標', 'ratio': 0.1}]",同次座標
1944,2243,homographie,射影変換,0.1,10,"[{'word': 'ホモグラフィ', 'ratio': 0.6}, {'word': 'ホモグラフィー', 'ratio': 0.1}, {'word': '同音異義語', 'ratio': 0.1}, {'word': '等角写像', 'ratio': 0.1}, {'word': '射影変換', 'ratio': 0.1}]",ホモグラフィ
1945,2244,homography matrix,同次写像行列,0.0,10,"[{'word': 'ホモグラフィ行列', 'ratio': 0.6}, {'word': 'オモグラフィー行列', 'ratio': 0.1}, {'word': 'ホモグラフィー行列', 'ratio': 0.1}, {'word': '等角写像行列', 'ratio': 0.1}, {'word': '射影変換行列', 'ratio': 0.1}]",ホモグラフィ行列
1946,2247,human pose,人体姿勢,0.1,10,"[{'word': '人間のポーズ', 'ratio': 0.6}, {'word': '人体のポーズ', 'ratio': 0.2}, {'word': 'ヒューマンポーズ', 'ratio': 0.1}, {'word': '人体姿勢', 'ratio': 0.1}]",人間のポーズ
1947,2248,human pose estimation,人間のポーズ推定 (ningen no pōzu suitei),0.0,10,"[{'word': '人間のポーズ推定', 'ratio': 0.5}, {'word': '人体ポーズ推定', 'ratio': 0.1}, {'word': '人間の姿勢推定', 'ratio': 0.1}, {'word': '人体ポーズの推定', 'ratio': 0.1}, {'word': '人体姿勢推定', 'ratio': 0.1}, {'word': '人間ポーズ推定', 'ratio': 0.1}]",人間のポーズ推定
1948,2251,human-machine interaction,人機インタラクション,0.0,10,"[{'word': '人間-機械インタラクション', 'ratio': 0.6}, {'word': 'ヒューマンマシンインタラクション', 'ratio': 0.2}, {'word': '人間-機械相互作用', 'ratio': 0.1}, {'word': '人間と機械の相互作用', 'ratio': 0.1}]",人間-機械インタラクション
1949,2252,hybrid model,ハイブリッドモデル,1.0,10,"[{'word': 'ハイブリッドモデル', 'ratio': 1.0}]",ハイブリッドモデル
1950,2253,hyper-graph,ハイパーグラフ,1.0,10,"[{'word': 'ハイパーグラフ', 'ratio': 1.0}]",ハイパーグラフ
1951,2254,hyper-parameter tuning,ハイパーパラメータチューニング,0.2,10,"[{'word': 'ハイパーパラメータ調整', 'ratio': 0.6}, {'word': 'ハイパー・パラメーター・チューニング', 'ratio': 0.2}, {'word': 'ハイパーパラメータチューニング', 'ratio': 0.2}]",ハイパーパラメータ調整
1952,2255,hyperbolic space,ハイパボリック空間,0.0,10,"[{'word': '双曲空間', 'ratio': 0.8}, {'word': '双曲面空間', 'ratio': 0.1}, {'word': 'ハイパーボリック空間', 'ratio': 0.1}]",双曲空間
1953,2256,hyperedge,超過辺,0.0,10,"[{'word': 'ハイパーエッジ', 'ratio': 0.6}, {'word': 'ハイパエッジ', 'ratio': 0.2}, {'word': 'ハイパーダージ', 'ratio': 0.2}]",ハイパーエッジ
1954,2257,hypernym,上位語,0.6,10,"[{'word': '上位語', 'ratio': 0.6}, {'word': 'ハイパーニム', 'ratio': 0.3}, {'word': 'ヒポニム', 'ratio': 0.1}]",上位語
1955,2258,hypernymy,上位語関係,0.1,10,"[{'word': '上位語性', 'ratio': 0.5}, {'word': 'ハイパーニミー', 'ratio': 0.2}, {'word': '上位語関係', 'ratio': 0.1}, {'word': 'ハイパーニム', 'ratio': 0.1}, {'word': 'ヒポニミー', 'ratio': 0.1}]",上位語性
1956,2259,hyperparameter optimization,ハイパーパラメータの最適化,0.0,10,"[{'word': 'ハイパーパラメータ最適化', 'ratio': 1.0}]",ハイパーパラメータ最適化
1957,2260,hyperparameter selection,ハイパーパラメータ選択,1.0,10,"[{'word': 'ハイパーパラメータ選択', 'ratio': 1.0}]",ハイパーパラメータ選択
1958,2261,hyperparameter setting,ハイパーパラメータ設定,0.9,10,"[{'word': 'ハイパーパラメータ設定', 'ratio': 0.9}, {'word': 'ハイパーパラメーター設定', 'ratio': 0.1}]",ハイパーパラメータ設定
1959,2262,hyperparameter space,ハイパーパラメータ空間,0.9,10,"[{'word': 'ハイパーパラメータ空間', 'ratio': 0.9}, {'word': 'ハイパーパラメーター空間', 'ratio': 0.1}]",ハイパーパラメータ空間
1960,2263,hyperplane,超平面,0.3,10,"[{'word': 'ハイパープレーン', 'ratio': 0.6}, {'word': '超平面', 'ratio': 0.3}, {'word': 'ヘイプライン', 'ratio': 0.1}]",ハイパープレーン
1961,2264,hyperprior,"""ハイパープライオール""",0.0,10,"[{'word': 'ハイパープライヤー', 'ratio': 0.5}, {'word': 'ハイパープライヤ', 'ratio': 0.2}, {'word': 'ハイパープリオール', 'ratio': 0.1}, {'word': 'ハイパープリア', 'ratio': 0.1}, {'word': 'ハイパープリアー', 'ratio': 0.1}]",ハイパープライヤー
1962,2265,hyponym,下位語,0.7,10,"[{'word': '下位語', 'ratio': 0.7}, {'word': 'ハイポニム', 'ratio': 0.1}, {'word': '下名', 'ratio': 0.1}, {'word': 'ひょうonym', 'ratio': 0.1}]",下位語
1963,2267,hypothesis class,仮説クラス,0.9,10,"[{'word': '仮説クラス', 'ratio': 0.9}, {'word': '論理クラス', 'ratio': 0.1}]",仮説クラス
1964,2268,hypothesis set,仮説集合,0.7,10,"[{'word': '仮説集合', 'ratio': 0.7}, {'word': '仮説セット', 'ratio': 0.2}, {'word': '論理集合', 'ratio': 0.1}]",仮説集合
1965,2269,hypothesis space,仮説空間,0.9,10,"[{'word': '仮説空間', 'ratio': 0.9}, {'word': '論理空間', 'ratio': 0.1}]",仮説空間
1966,2270,hypothesis test,仮説検定,0.9,10,"[{'word': '仮説検定', 'ratio': 0.9}, {'word': '論理検定', 'ratio': 0.1}]",仮説検定
1967,2271,i.i.d,独立同分布,0.5,10,"[{'word': '独立同分布', 'ratio': 0.5}, {'word': '同時独立同分布', 'ratio': 0.1}, {'word': 'i.i.d.', 'ratio': 0.1}, {'word': 'アイ・アイ・ディ', 'ratio': 0.1}, {'word': 'アイ・アイ・ディー', 'ratio': 0.1}, {'word': 'データベクトル', 'ratio': 0.1}]",独立同分布
1968,2273,idempotent,冪等性,0.1,10,"[{'word': '冪等', 'ratio': 0.5}, {'word': 'べきべき', 'ratio': 0.2}, {'word': '幂等', 'ratio': 0.1}, {'word': '冪等性', 'ratio': 0.1}, {'word': 'データセット', 'ratio': 0.1}]",冪等
1969,2275,identity mapping,同一マッピング,0.0,10,"[{'word': '同一写像', 'ratio': 0.5}, {'word': 'アイデンティティマッピング', 'ratio': 0.2}, {'word': '恒等写像', 'ratio': 0.1}, {'word': '単位写像', 'ratio': 0.1}, {'word': 'イデンティティーマッピング', 'ratio': 0.1}]",同一写像
1970,2276,identity matrix,単位行列,0.9,10,"[{'word': '単位行列', 'ratio': 0.9}, {'word': 'アイデンティティーマトリックス', 'ratio': 0.1}]",単位行列
1971,2277,identity transformation,同一変換,0.5,10,"[{'word': '同一変換', 'ratio': 0.5}, {'word': '恒等変換', 'ratio': 0.1}, {'word': '同一性変換', 'ratio': 0.1}, {'word': '単位変換', 'ratio': 0.1}, {'word': 'アイデンティティ変換', 'ratio': 0.1}, {'word': 'イデンティティートランスフォーメーション', 'ratio': 0.1}]",同一変換
1972,2278,image analysis,画像解析,0.6,10,"[{'word': '画像解析', 'ratio': 0.6}, {'word': '画像分析', 'ratio': 0.3}, {'word': 'イメージ・アナリシス', 'ratio': 0.1}]",画像解析
1973,2280,image classification,画像分類,1.0,10,"[{'word': '画像分類', 'ratio': 1.0}]",画像分類
1974,2281,image compression,画像圧縮,1.0,10,"[{'word': '画像圧縮', 'ratio': 1.0}]",画像圧縮
1975,2282,image denoising,画像ノイズ除去,0.6,10,"[{'word': '画像ノイズ除去', 'ratio': 0.6}, {'word': '画像のノイズ除去', 'ratio': 0.3}, {'word': 'イメージデノイズ', 'ratio': 0.1}]",画像ノイズ除去
1976,2283,image diffusion model,画像拡散モデル,0.9,10,"[{'word': '画像拡散モデル', 'ratio': 0.9}, {'word': 'イメージディフュージョンモデル', 'ratio': 0.1}]",画像拡散モデル
1977,2284,image embedding,画像埋め込み,0.9,10,"[{'word': '画像埋め込み', 'ratio': 0.9}, {'word': '画像の埋め込み', 'ratio': 0.1}]",画像埋め込み
1978,2285,image encoder,画像エンコーダ,0.9,10,"[{'word': '画像エンコーダ', 'ratio': 0.9}, {'word': 'イメージエンコーダ', 'ratio': 0.1}]",画像エンコーダ
1979,2286,image feature,画像特徴,0.8,10,"[{'word': '画像特徴', 'ratio': 0.8}, {'word': 'イメージ機能', 'ratio': 0.1}, {'word': '画像の特徴', 'ratio': 0.1}]",画像特徴
1980,2287,image generation,画像生成,0.9,10,"[{'word': '画像生成', 'ratio': 0.9}, {'word': 'イメージ生成', 'ratio': 0.1}]",画像生成
1981,2288,image inpainting,画像インペインティング,0.3,10,"[{'word': '画像修復', 'ratio': 0.6}, {'word': '画像インペインティング', 'ratio': 0.3}, {'word': 'インペインティング', 'ratio': 0.1}]",画像修復
1982,2289,image patch,画像パッチ,0.9,10,"[{'word': '画像パッチ', 'ratio': 0.9}, {'word': 'イメージパッチ', 'ratio': 0.1}]",画像パッチ
1983,2290,image plane,画像平面,0.8,10,"[{'word': '画像平面', 'ratio': 0.8}, {'word': 'イメージプレーン', 'ratio': 0.2}]",画像平面
1984,2291,image processing,画像処理,1.0,10,"[{'word': '画像処理', 'ratio': 1.0}]",画像処理
1985,2292,image pyramid,画像ピラミッド,0.9,10,"[{'word': '画像ピラミッド', 'ratio': 0.9}, {'word': 'イメージ・ピラミッド', 'ratio': 0.1}]",画像ピラミッド
1986,2293,image recognition,画像認識,1.0,10,"[{'word': '画像認識', 'ratio': 1.0}]",画像認識
1987,2294,image representation,画像表現,1.0,10,"[{'word': '画像表現', 'ratio': 1.0}]",画像表現
1988,2295,image restoration,画像修復,0.3,10,"[{'word': '画像復元', 'ratio': 0.7}, {'word': '画像修復', 'ratio': 0.3}]",画像復元
1989,2296,image segmentation,画像セグメンテーション,0.8,10,"[{'word': '画像セグメンテーション', 'ratio': 0.8}, {'word': '画像分割', 'ratio': 0.1}, {'word': '画像のセグメンテーション', 'ratio': 0.1}]",画像セグメンテーション
1990,2297,image super-resolution,画像超解像度,0.0,10,"[{'word': '画像超解像', 'ratio': 0.9}, {'word': '画像の超解像度', 'ratio': 0.1}]",画像超解像
1991,2298,image synthesis,画像合成,1.0,10,"[{'word': '画像合成', 'ratio': 1.0}]",画像合成
1992,2300,image-based rendering,画像ベースレンダリング,0.0,9,"[{'word': '画像ベースのレンダリング', 'ratio': 0.8888888888888888}, {'word': 'Ejimujieno Renaderingu', 'ratio': 0.1111111111111111}]",画像ベースのレンダリング
1993,2304,imperfect information,不完全情報,0.7777777777777778,9,"[{'word': '不完全情報', 'ratio': 0.7777777777777778}, {'word': '不完全な情報', 'ratio': 0.2222222222222222}]",不完全情報
1994,2309,importance sampling,重要度サンプリング,0.3,10,"[{'word': '重要サンプリング', 'ratio': 0.5}, {'word': '重要度サンプリング', 'ratio': 0.3}, {'word': '重要度のサンプリング', 'ratio': 0.1}, {'word': '重みサンプリング', 'ratio': 0.1}]",重要サンプリング
1995,2311,importance weight,重み付け係数,0.0,10,"[{'word': '重要度重み', 'ratio': 0.7}, {'word': '重要度', 'ratio': 0.1}, {'word': '重要度の重み', 'ratio': 0.1}, {'word': '重み', 'ratio': 0.1}]",重要度重み
1996,2312,in-context demonstration,コンテキスト内のデモンストレーション,0.1,10,"[{'word': 'コンテキスト内デモンストレーション', 'ratio': 0.5}, {'word': '文脈内デモンストレーション', 'ratio': 0.2}, {'word': 'インコンテクスト・デモンストレーション', 'ratio': 0.1}, {'word': 'コンテキスト内のデモンストレーション', 'ratio': 0.1}, {'word': 'コンテキストデモンストレーション', 'ratio': 0.1}]",コンテキスト内デモンストレーション
1997,2313,in-context example,コンテクスト例,0.0,10,"[{'word': 'コンテキスト内例', 'ratio': 0.5}, {'word': '文脈内例', 'ratio': 0.1}, {'word': '文脈内例示', 'ratio': 0.1}, {'word': 'インコンテキストの例', 'ratio': 0.1}, {'word': 'コンテキスト内の例', 'ratio': 0.1}, {'word': 'コンテキスト例', 'ratio': 0.1}]",コンテキスト内例
1998,2315,in-degree distribution,入次数分布,0.7,10,"[{'word': '入次数分布', 'ratio': 0.7}, {'word': 'イン度分布', 'ratio': 0.1}, {'word': '度数分布', 'ratio': 0.1}, {'word': '内次数分布', 'ratio': 0.1}]",入次数分布
1999,2317,in-domain,ドメイン内,0.8,10,"[{'word': 'ドメイン内', 'ratio': 0.8}, {'word': 'インドメイン', 'ratio': 0.2}]",ドメイン内
2000,2318,in-domain text,分野内テキスト,0.0,10,"[{'word': 'ドメイン内テキスト', 'ratio': 0.8}, {'word': 'インドメインテキスト', 'ratio': 0.2}]",ドメイン内テキスト
2001,2321,inception score,インセプションスコア,0.9,10,"[{'word': 'インセプションスコア', 'ratio': 0.9}, {'word': 'インセプション・スコア', 'ratio': 0.1}]",インセプションスコア
2002,2322,incremental learning,インクリメンタルラーニング (incremental learning),0.0,10,"[{'word': '増分学習', 'ratio': 0.6}, {'word': 'インクリメンタルラーニング', 'ratio': 0.2}, {'word': 'インクリメンタル学習', 'ratio': 0.1}, {'word': '段階的な学習', 'ratio': 0.1}]",増分学習
2003,2323,incremental parsing,インクリメンタル解析,0.1,10,"[{'word': '増分構文解析', 'ratio': 0.5}, {'word': 'インクリメンタルパース', 'ratio': 0.1}, {'word': 'ンクリメンタル構文解析', 'ratio': 0.1}, {'word': 'インクリメンタル解析', 'ratio': 0.1}, {'word': '増分解析', 'ratio': 0.1}, {'word': 'インクリメンタルパーシング', 'ratio': 0.1}]",増分構文解析
2004,2324,independent set,独立集合,1.0,9,"[{'word': '独立集合', 'ratio': 1.0}]",独立集合
2005,2325,independent variable,独立変数,0.8888888888888888,9,"[{'word': '独立変数', 'ratio': 0.8888888888888888}, {'word': '独立変数指標行列', 'ratio': 0.1111111111111111}]",独立変数
2006,2329,induced subgraph,誘導部分グラフ (Induced Subgraph),0.0,9,"[{'word': '誘導部分グラフ', 'ratio': 0.7777777777777778}, {'word': '引き起こされた部分グラフ', 'ratio': 0.1111111111111111}, {'word': '生成部分グラフ', 'ratio': 0.1111111111111111}]",誘導部分グラフ
2007,2330,inducing variable,誘導変数,0.6666666666666666,9,"[{'word': '誘導変数', 'ratio': 0.6666666666666666}, {'word': '誘発変数', 'ratio': 0.1111111111111111}, {'word': '引き起こし変数', 'ratio': 0.1111111111111111}, {'word': '生成変数', 'ratio': 0.1111111111111111}]",誘導変数
2008,2331,induction hypothesis,帰納仮説,1.0,9,"[{'word': '帰納仮説', 'ratio': 1.0}]",帰納仮説
2009,2332,inductive bias,帰納バイアス,0.1111111111111111,9,"[{'word': '帰納的バイアス', 'ratio': 0.6666666666666666}, {'word': '誘導バイアス', 'ratio': 0.2222222222222222}, {'word': '帰納バイアス', 'ratio': 0.1111111111111111}]",帰納的バイアス
2010,2333,inductive learning,帰納的学習,0.7777777777777778,9,"[{'word': '帰納的学習', 'ratio': 0.7777777777777778}, {'word': '帰納学習', 'ratio': 0.2222222222222222}]",帰納的学習
2011,2334,inf,inf,0.0,10,"[{'word': 'インフ', 'ratio': 0.6}, {'word': '下限', 'ratio': 0.2}, {'word': '無限', 'ratio': 0.1}, {'word': '極小', 'ratio': 0.1}]",インフ
2012,2335,inference,推論,1.0,20,"[{'word': '推論', 'ratio': 1.0}]",推論
2013,2336,inference algorithm,推論アルゴリズム,1.0,10,"[{'word': '推論アルゴリズム', 'ratio': 1.0}]",推論アルゴリズム
2014,2337,inference machinery,推論機構,0.8,10,"[{'word': '推論機構', 'ratio': 0.8}, {'word': '推論機械', 'ratio': 0.2}]",推論機構
2015,2338,inference method,推論方法,0.3333333333333333,9,"[{'word': '推論手法', 'ratio': 0.5555555555555556}, {'word': '推論方法', 'ratio': 0.3333333333333333}, {'word': '推論法', 'ratio': 0.1111111111111111}]",推論手法
2016,2339,inference problem,推論問題,1.0,9,"[{'word': '推論問題', 'ratio': 1.0}]",推論問題
2017,2340,inference procedure,推論手順,0.3333333333333333,9,"[{'word': '推論手続き', 'ratio': 0.6666666666666666}, {'word': '推論手順', 'ratio': 0.3333333333333333}]",推論手続き
2018,2341,inference process,推論プロセス,0.8888888888888888,9,"[{'word': '推論プロセス', 'ratio': 0.8888888888888888}, {'word': '推論過程', 'ratio': 0.1111111111111111}]",推論プロセス
2019,2342,inference rule,推論規則,0.6666666666666666,9,"[{'word': '推論規則', 'ratio': 0.6666666666666666}, {'word': '推論ルール', 'ratio': 0.3333333333333333}]",推論規則
2020,2343,inference stage,推論段階,0.9,10,"[{'word': '推論段階', 'ratio': 0.9}, {'word': '推論ステージ', 'ratio': 0.1}]",推論段階
2021,2344,inference task,推論タスク,1.0,10,"[{'word': '推論タスク', 'ratio': 1.0}]",推論タスク
2022,2345,inference time,推論時間,0.6,10,"[{'word': '推論時間', 'ratio': 0.6}, {'word': '推論時', 'ratio': 0.4}]",推論時間
2023,2346,infinite-horizon,無限時間視野,0.0,10,"[{'word': '無限ホライズン', 'ratio': 0.7}, {'word': '無限地平', 'ratio': 0.1}, {'word': '無限の地平線', 'ratio': 0.1}, {'word': '無限時間ホライズン', 'ratio': 0.1}]",無限ホライズン
2024,2347,influence diagram,影響図,0.6,10,"[{'word': '影響図', 'ratio': 0.6}, {'word': 'インフルエンスダイアグラム', 'ratio': 0.2}, {'word': '影響ダイアグラム', 'ratio': 0.2}]",影響図
2025,2348,influence function,影響関数,0.9,10,"[{'word': '影響関数', 'ratio': 0.9}, {'word': '影響機能', 'ratio': 0.1}]",影響関数
2026,2349,information bottleneck,情報ボトルネック,0.9,10,"[{'word': '情報ボトルネック', 'ratio': 0.9}, {'word': '情報のボトルネック', 'ratio': 0.1}]",情報ボトルネック
2027,2350,information content,情報量,0.8,10,"[{'word': '情報量', 'ratio': 0.8}, {'word': '情報内容', 'ratio': 0.2}]",情報量
2028,2351,information gain,情報利得,0.6,10,"[{'word': '情報利得', 'ratio': 0.6}, {'word': '情報ゲイン', 'ratio': 0.3}, {'word': '情報獲得', 'ratio': 0.1}]",情報利得
2029,2352,information retrieval system,情報検索システム,1.0,9,"[{'word': '情報検索システム', 'ratio': 1.0}]",情報検索システム
2030,2353,information set,情報集合,0.5555555555555556,9,"[{'word': '情報集合', 'ratio': 0.5555555555555556}, {'word': '情報セット', 'ratio': 0.4444444444444444}]",情報集合
2031,2354,information theoretic,情報理論的な,0.0,9,"[{'word': '情報理論的', 'ratio': 0.7777777777777778}, {'word': '情報理論', 'ratio': 0.2222222222222222}]",情報理論的
2032,2355,information theoretic measure,情報理論的尺度,0.7777777777777778,9,"[{'word': '情報理論的尺度', 'ratio': 0.7777777777777778}, {'word': '情報理論的指標', 'ratio': 0.1111111111111111}, {'word': '情報理論的測定', 'ratio': 0.1111111111111111}]",情報理論的尺度
2033,2356,infoset,情報集合,0.0,9,"[{'word': 'インフォセット', 'ratio': 0.6666666666666666}, {'word': '情報セット', 'ratio': 0.2222222222222222}, {'word': 'インフォセッ', 'ratio': 0.1111111111111111}]",インフォセット
2034,2357,inhomogeneous Poisson process,不均一ポアソン過程,1.0,10,"[{'word': '不均一ポアソン過程', 'ratio': 1.0}]",不均一ポアソン過程
2035,2358,initial distribution,初期分布,0.8,10,"[{'word': '初期分布', 'ratio': 0.8}, {'word': '初期配布', 'ratio': 0.2}]",初期分布
2036,2359,initial state,初期状態,1.0,10,"[{'word': '初期状態', 'ratio': 1.0}]",初期状態
2037,2360,initial state distribution,初期状態分布,1.0,10,"[{'word': '初期状態分布', 'ratio': 1.0}]",初期状態分布
2038,2361,initialization,初期化,1.0,10,"[{'word': '初期化', 'ratio': 1.0}]",初期化
2039,2362,injective function,単射関数,0.9,10,"[{'word': '単射関数', 'ratio': 0.9}, {'word': '注入関数', 'ratio': 0.1}]",単射関数
2040,2364,inner layer,内部層,0.6,10,"[{'word': '内部層', 'ratio': 0.6}, {'word': '内層', 'ratio': 0.4}]",内部層
2041,2365,inner loop,内部ループ,0.6,10,"[{'word': '内部ループ', 'ratio': 0.6}, {'word': '内ループ', 'ratio': 0.2}, {'word': 'インナーループ', 'ratio': 0.1}, {'word': '内側のループ', 'ratio': 0.1}]",内部ループ
2042,2366,inner node,内部ノード,0.9,10,"[{'word': '内部ノード', 'ratio': 0.9}, {'word': 'インナーノード', 'ratio': 0.1}]",内部ノード
2043,2367,inner product,内積,0.7777777777777778,9,"[{'word': '内積', 'ratio': 0.7777777777777778}, {'word': 'ないせき', 'ratio': 0.2222222222222222}]",内積
2044,2368,input,入力,1.0,18,"[{'word': '入力', 'ratio': 1.0}]",入力
2045,2369,input context,入力コンテキスト,0.875,8,"[{'word': '入力コンテキスト', 'ratio': 0.875}, {'word': '入力', 'ratio': 0.125}]",入力コンテキスト
2046,2370,input datum,入力データ,1.0,9,"[{'word': '入力データ', 'ratio': 1.0}]",入力データ
2047,2371,input embedding,入力埋め込み,1.0,10,"[{'word': '入力埋め込み', 'ratio': 1.0}]",入力埋め込み
2048,2372,input feature,入力特徴,0.7,10,"[{'word': '入力特徴', 'ratio': 0.7}, {'word': '入力機能', 'ratio': 0.2}, {'word': '入力特徴量', 'ratio': 0.1}]",入力特徴
2049,2373,input feature vector,入力特徴ベクトル,1.0,10,"[{'word': '入力特徴ベクトル', 'ratio': 1.0}]",入力特徴ベクトル
2050,2374,input filter,入力フィルタ,0.7,10,"[{'word': '入力フィルタ', 'ratio': 0.7}, {'word': '入力フィルター', 'ratio': 0.3}]",入力フィルタ
2051,2375,input formula,入力式,0.8,10,"[{'word': '入力式', 'ratio': 0.8}, {'word': '入力フィルタ', 'ratio': 0.1}, {'word': '入力Formula', 'ratio': 0.1}]",入力式
2052,2376,input gate,入力ゲート,1.0,10,"[{'word': '入力ゲート', 'ratio': 1.0}]",入力ゲート
2053,2377,input graph,入力グラフ,1.0,10,"[{'word': '入力グラフ', 'ratio': 1.0}]",入力グラフ
2054,2378,input image,入力画像,1.0,10,"[{'word': '入力画像', 'ratio': 1.0}]",入力画像
2055,2379,input layer,入力層,1.0,10,"[{'word': '入力層', 'ratio': 1.0}]",入力層
2056,2380,input length,入力長さ,0.1,10,"[{'word': '入力長', 'ratio': 0.9}, {'word': '入力長さ', 'ratio': 0.1}]",入力長
2057,2381,input matrix,入力行列,1.0,10,"[{'word': '入力行列', 'ratio': 1.0}]",入力行列
2058,2382,input point,入力点,0.8,10,"[{'word': '入力点', 'ratio': 0.8}, {'word': '入力ポイント', 'ratio': 0.2}]",入力点
2059,2383,input position,入力位置,1.0,10,"[{'word': '入力位置', 'ratio': 1.0}]",入力位置
2060,2384,input representation,入力表現,0.9,10,"[{'word': '入力表現', 'ratio': 0.9}, {'word': 'V入力表', 'ratio': 0.1}]",入力表現
2061,2385,input resolution,入力解像度,0.8,10,"[{'word': '入力解像度', 'ratio': 0.8}, {'word': '入力分解能', 'ratio': 0.2}]",入力解像度
2062,2386,input sequence,入力シーケンス,0.8,10,"[{'word': '入力シーケンス', 'ratio': 0.8}, {'word': '入力列', 'ratio': 0.1}, {'word': '入力系列', 'ratio': 0.1}]",入力シーケンス
2063,2387,input tensor,入力テンソル,1.0,10,"[{'word': '入力テンソル', 'ratio': 1.0}]",入力テンソル
2064,2388,input text,入力テキスト,1.0,10,"[{'word': '入力テキスト', 'ratio': 1.0}]",入力テキスト
2065,2389,input token,入力トークン,0.9,10,"[{'word': '入力トークン', 'ratio': 0.9}, {'word': '入力トークン入力ベクトル', 'ratio': 0.1}]",入力トークン
2066,2390,input vector,入力ベクトル,0.9,10,"[{'word': '入力ベクトル', 'ratio': 0.9}, {'word': '入力ベクター', 'ratio': 0.1}]",入力ベクトル
2067,2391,input-output pair,入力-出力ペア,0.7,10,"[{'word': '入力-出力ペア', 'ratio': 0.7}, {'word': '入出力ペア', 'ratio': 0.2}, {'word': '入力出力ペア', 'ratio': 0.1}]",入力-出力ペア
2068,2392,instance,インスタンス,1.0,10,"[{'word': 'インスタンス', 'ratio': 1.0}]",インスタンス
2069,2393,instance level,インスタンスレベル,1.0,10,"[{'word': 'インスタンスレベル', 'ratio': 1.0}]",インスタンスレベル
2070,2394,instance segmentation,インスタンスセグメンテーション,0.8,10,"[{'word': 'インスタンスセグメンテーション', 'ratio': 0.8}, {'word': 'インスタンス分割', 'ratio': 0.2}]",インスタンスセグメンテーション
2071,2395,instance selection,インスタンス選択,1.0,10,"[{'word': 'インスタンス選択', 'ratio': 1.0}]",インスタンス選択
2072,2396,instance space,インスタンス空間,0.9,10,"[{'word': 'インスタンス空間', 'ratio': 0.9}, {'word': 'インスタンススペース', 'ratio': 0.1}]",インスタンス空間
2073,2397,instruction tuning,インストラクションチューニング,0.5,10,"[{'word': 'インストラクションチューニング', 'ratio': 0.5}, {'word': 'インストラクション調整', 'ratio': 0.1}, {'word': 'インストラクション・チューニング', 'ratio': 0.1}, {'word': '指示調整', 'ratio': 0.1}, {'word': '命令チューニング', 'ratio': 0.1}, {'word': '指示チューニング', 'ratio': 0.1}]",インストラクションチューニング
2074,2398,integer linear program,整数線形計画問題,0.0,10,"[{'word': '整数線形プログラム', 'ratio': 0.5}, {'word': '整数線形計画', 'ratio': 0.3}, {'word': '整数線形計画法', 'ratio': 0.2}]",整数線形プログラム
2075,2399,integer program,整数計画問題,0.0,10,"[{'word': '整数プログラム', 'ratio': 0.7}, {'word': '整数計画', 'ratio': 0.2}, {'word': '整数計画法', 'ratio': 0.1}]",整数プログラム
2076,2400,integral image,積分画像,0.9,10,"[{'word': '積分画像', 'ratio': 0.9}, {'word': 'インテグラルイメージ', 'ratio': 0.1}]",積分画像
2077,2401,integral operator,積分作用素,0.1,10,"[{'word': '積分演算子', 'ratio': 0.8}, {'word': '整数演算子', 'ratio': 0.1}, {'word': '積分作用素', 'ratio': 0.1}]",積分演算子
2078,2402,integral probability metric,積分確率メトリック,0.3,10,"[{'word': '積分確率距離', 'ratio': 0.5}, {'word': '積分確率メトリック', 'ratio': 0.3}, {'word': '積分確率計量', 'ratio': 0.2}]",積分確率距離
2079,2403,integrity constraint,整合性制約,1.0,10,"[{'word': '整合性制約', 'ratio': 1.0}]",整合性制約
2080,2404,intelligent agent,知的エージェント,0.0,10,"[{'word': '知能エージェント', 'ratio': 0.7}, {'word': 'インテリジェントエージェント', 'ratio': 0.3}]",知能エージェント
2081,2405,intensity function,強度関数,0.9,10,"[{'word': '強度関数', 'ratio': 0.9}, {'word': 'インテンシティ機能', 'ratio': 0.1}]",強度関数
2082,2406,intent,意図,0.9,10,"[{'word': '意図', 'ratio': 0.9}, {'word': '趣旨', 'ratio': 0.1}]",意図
2083,2408,interaction matrix,相互作用行列,0.8,10,"[{'word': '相互作用行列', 'ratio': 0.8}, {'word': 'インタラクションマトリックス', 'ratio': 0.1}, {'word': 'インタラクション行列', 'ratio': 0.1}]",相互作用行列
2084,2409,interest point,関心点,0.1,10,"[{'word': '特徴点', 'ratio': 0.8}, {'word': '注目ポイント', 'ratio': 0.1}, {'word': '関心点', 'ratio': 0.1}]",特徴点
2085,2410,interior point method,内点法,1.0,10,"[{'word': '内点法', 'ratio': 1.0}]",内点法
2086,2411,intermediate layer,中間層,1.0,10,"[{'word': '中間層', 'ratio': 1.0}]",中間層
2087,2412,intermediate representation,中間表現,1.0,10,"[{'word': '中間表現', 'ratio': 1.0}]",中間表現
2088,2413,internal edge,内部エッジ,0.6,10,"[{'word': '内部エッジ', 'ratio': 0.6}, {'word': '内部辺', 'ratio': 0.4}]",内部エッジ
2089,2414,internal node,内部ノード,1.0,10,"[{'word': '内部ノード', 'ratio': 1.0}]",内部ノード
2090,2415,internal regret,内部後悔,0.6,10,"[{'word': '内部後悔', 'ratio': 0.6}, {'word': '内心の後悔', 'ratio': 0.1}, {'word': '内なる後悔', 'ratio': 0.1}, {'word': '内部の後悔', 'ratio': 0.1}, {'word': '内部悔恨', 'ratio': 0.1}]",内部後悔
2091,2416,internal representation,内部表現,1.0,9,"[{'word': '内部表現', 'ratio': 1.0}]",内部表現
2092,2417,internal state,内部状態,1.0,9,"[{'word': '内部状態', 'ratio': 1.0}]",内部状態
2093,2418,interpolation,補間,0.8888888888888888,9,"[{'word': '補間', 'ratio': 0.8888888888888888}, {'word': 'インテリアポリエーション', 'ratio': 0.1111111111111111}]",補間
2094,2419,interpretability,解釈可能性,0.4210526315789473,19,"[{'word': '解釈可能性', 'ratio': 0.8421052631578947}, {'word': '可解釈性', 'ratio': 0.10526315789473684}, {'word': '解釈性', 'ratio': 0.05263157894736842}]",解釈可能性
2095,2420,interpretation function,解釈関数,0.8,10,"[{'word': '解釈関数', 'ratio': 0.8}, {'word': '解釈機能', 'ratio': 0.2}]",解釈関数
2096,2422,interval estimate,区間推定,0.8,10,"[{'word': '区間推定', 'ratio': 0.8}, {'word': '推定間隔', 'ratio': 0.1}, {'word': '間隔の推定', 'ratio': 0.1}]",区間推定
2097,2424,intrinsic,内部パラメータ,0.0,9,"[{'word': '内因性', 'ratio': 0.6666666666666666}, {'word': '内在的', 'ratio': 0.1111111111111111}, {'word': '本質的な', 'ratio': 0.1111111111111111}, {'word': '内的', 'ratio': 0.1111111111111111}]",内因性
2098,2425,intrinsic camera parameter,内部カメラパラメータ,0.0,9,"[{'word': '内因性カメラパラメータ', 'ratio': 0.6666666666666666}, {'word': 'カメラ固有パラメータ', 'ratio': 0.1111111111111111}, {'word': '固有のカメラパラメータ', 'ratio': 0.1111111111111111}, {'word': '内的カメラパラメータ', 'ratio': 0.1111111111111111}]",内因性カメラパラメータ
2099,2431,inverse document frequency,逆文書頻度,1.0,10,"[{'word': '逆文書頻度', 'ratio': 1.0}]",逆文書頻度
2100,2432,inverse dynamic model,逆動力学モデル,0.5,10,"[{'word': '逆動力学モデル', 'ratio': 0.5}, {'word': '逆動的モデル', 'ratio': 0.5}]",逆動力学モデル
2101,2433,inverse problem,逆問題,1.0,10,"[{'word': '逆問題', 'ratio': 1.0}]",逆問題
2102,2434,inverse rendering,逆レンダリング,1.0,10,"[{'word': '逆レンダリング', 'ratio': 1.0}]",逆レンダリング
2103,2435,inverse role,逆の役割,0.1,10,"[{'word': '逆役割', 'ratio': 0.8}, {'word': '逆役', 'ratio': 0.1}, {'word': '逆の役割', 'ratio': 0.1}]",逆役割
2104,2436,inverse square root learning rate schedule,逆平方根学習率スケジュール,0.9,10,"[{'word': '逆平方根学習率スケジュール', 'ratio': 0.9}, {'word': '逆数平方根学習率スケジュール', 'ratio': 0.1}]",逆平方根学習率スケジュール
2105,2437,inverse square root learning rate scheduler,逆平方根学習率スケジューラ,0.9,10,"[{'word': '逆平方根学習率スケジューラ', 'ratio': 0.9}, {'word': '逆数平方根学習率スケジューラ', 'ratio': 0.1}]",逆平方根学習率スケジューラ
2106,2438,inverse transform sampling,逆変換サンプリング,1.0,10,"[{'word': '逆変換サンプリング', 'ratio': 1.0}]",逆変換サンプリング
2107,2439,inverted index,逆インデックス,0.8,10,"[{'word': '逆インデックス', 'ratio': 0.8}, {'word': '転置インデックス', 'ratio': 0.2}]",逆インデックス
2108,2440,inverted list,逆リスト,0.8,10,"[{'word': '逆リスト', 'ratio': 0.8}, {'word': '逆転置リスト', 'ratio': 0.1}, {'word': '逆転リスト', 'ratio': 0.1}]",逆リスト
2109,2441,invertible map,可逆写像,0.8,10,"[{'word': '可逆写像', 'ratio': 0.8}, {'word': '反転可能な地図', 'ratio': 0.2}]",可逆写像
2110,2442,invertible matrix,可逆行列,1.0,10,"[{'word': '可逆行列', 'ratio': 1.0}]",可逆行列
2111,2444,iso-surface extraction,等値面抽出,0.8,10,"[{'word': '等値面抽出', 'ratio': 0.8}, {'word': 'アイソサーフェス抽出', 'ratio': 0.1}, {'word': 'アイソシューフェース抽出', 'ratio': 0.1}]",等値面抽出
2112,2446,itemset,アイテムセット,1.0,10,"[{'word': 'アイテムセット', 'ratio': 1.0}]",アイテムセット
2113,2448,iterated conditional mode,繰り返し条件付きモード (ICM),0.0,10,"[{'word': '反復条件付きモード', 'ratio': 0.5}, {'word': '繰り返し条件モード', 'ratio': 0.2}, {'word': '繰り返し条件付きモード', 'ratio': 0.2}, {'word': '条件付き反復モード', 'ratio': 0.1}]",反復条件付きモード
2114,2449,iteration,反復,0.5,10,"[{'word': '反復', 'ratio': 0.5}, {'word': 'イテレーション', 'ratio': 0.3}, {'word': '繰り返し', 'ratio': 0.2}]",反復
2115,2451,iteration counter,繰り返し回数,0.0,10,"[{'word': '反復カウンタ', 'ratio': 0.5}, {'word': 'イテレーションカウンタ', 'ratio': 0.3}, {'word': '繰り返しカウンタ', 'ratio': 0.2}]",反復カウンタ
2116,2452,iterative algorithm,反復アルゴリズム,0.9,10,"[{'word': '反復アルゴリズム', 'ratio': 0.9}, {'word': '繰り返しアルゴリズム', 'ratio': 0.1}]",反復アルゴリズム
2117,2453,iterative deepening,反復深化探索,0.0,9,"[{'word': '反復深化', 'ratio': 0.7777777777777778}, {'word': '反復的な深化', 'ratio': 0.1111111111111111}, {'word': '逐次深化', 'ratio': 0.1111111111111111}]",反復深化
2118,2454,iterative optimization,反復最適化,1.0,9,"[{'word': '反復最適化', 'ratio': 1.0}]",反復最適化
2119,2455,iterative optimization algorithm,反復最適化アルゴリズム,1.0,9,"[{'word': '反復最適化アルゴリズム', 'ratio': 1.0}]",反復最適化アルゴリズム
2120,2456,iterative training algorithm,反復トレーニングアルゴリズム,0.4444444444444444,9,"[{'word': '反復訓練アルゴリズム', 'ratio': 0.5555555555555556}, {'word': '反復トレーニングアルゴリズム', 'ratio': 0.4444444444444444}]",反復訓練アルゴリズム
2121,2458,joint density,同時密度,0.5,10,"[{'word': '同時密度', 'ratio': 0.5}, {'word': '接合密度', 'ratio': 0.2}, {'word': '結合密度', 'ratio': 0.2}, {'word': '同時確率密度', 'ratio': 0.1}]",同時密度
2122,2459,joint distribution,同時分布,0.6,10,"[{'word': '同時分布', 'ratio': 0.6}, {'word': '結合分布', 'ratio': 0.2}, {'word': '共同分布', 'ratio': 0.1}, {'word': '共同配布', 'ratio': 0.1}]",同時分布
2123,2460,joint embedding space,共同埋め込み空間,0.0,10,"[{'word': '同時埋め込み空間', 'ratio': 0.5}, {'word': '結合埋め込み空間', 'ratio': 0.3}, {'word': '関節包埋空間', 'ratio': 0.1}, {'word': '共通埋め込み空間', 'ratio': 0.1}]",同時埋め込み空間
2124,2461,joint encoding,共同符号化,0.0,10,"[{'word': '同時エンコーディング', 'ratio': 0.5}, {'word': '結合エンコーディング', 'ratio': 0.2}, {'word': '共同エンコーディング', 'ratio': 0.1}, {'word': 'ジョイントエンコーディング', 'ratio': 0.1}, {'word': '共通符号化', 'ratio': 0.1}]",同時エンコーディング
2125,2462,joint entropy,結合エントロピー,0.3,10,"[{'word': '同時エントロピー', 'ratio': 0.5}, {'word': '結合エントロピー', 'ratio': 0.3}, {'word': '共同エントロピー', 'ratio': 0.1}, {'word': '同時エントロピ', 'ratio': 0.1}]",同時エントロピー
2126,2467,joint model,結合モデル,0.2,10,"[{'word': 'ジョイントモデル', 'ratio': 0.5}, {'word': '結合モデル', 'ratio': 0.2}, {'word': '統合モデル', 'ratio': 0.2}, {'word': '共同モデル', 'ratio': 0.1}]",ジョイントモデル
2127,2468,joint policy,共同方針,0.3,10,"[{'word': 'ジョイントポリシー', 'ratio': 0.6}, {'word': '共同方針', 'ratio': 0.3}, {'word': '共同政策', 'ratio': 0.1}]",ジョイントポリシー
2128,2474,junction tree,接続木,0.1,10,"[{'word': 'ジャンクションツリー', 'ratio': 0.5}, {'word': 'ジャンクション・ツリー', 'ratio': 0.3}, {'word': 'ジャンクショントリー', 'ratio': 0.1}, {'word': '接続木', 'ratio': 0.1}]",ジャンクションツリー
2129,2475,junction tree algorithm,結合木アルゴリズム,0.0,10,"[{'word': 'ジャンクションツリーアルゴリズム', 'ratio': 0.5}, {'word': 'ジャンクション・ツリー・アルゴリズム', 'ratio': 0.3}, {'word': 'ジャンクショントリーアルゴリズム', 'ratio': 0.1}, {'word': '接続木アルゴリズム', 'ratio': 0.1}]",ジャンクションツリーアルゴリズム
2130,2477,k-Center,k中心,0.0,10,"[{'word': 'kセンター', 'ratio': 0.6}, {'word': 'k-センター', 'ratio': 0.4}]",kセンター
2131,2483,k-nearest neighbor,k最近傍,0.0,10,"[{'word': 'k最近傍法', 'ratio': 0.5}, {'word': 'k近傍法', 'ratio': 0.2}, {'word': 'k-最近傍', 'ratio': 0.1}, {'word': 'k最近隣', 'ratio': 0.1}, {'word': 'k-最近傍法', 'ratio': 0.1}]",k最近傍法
2132,2484,k-nearest neighbor classifier,k近傍分類器,0.2,10,"[{'word': 'k最近傍分類器', 'ratio': 0.6}, {'word': 'k近傍分類器', 'ratio': 0.2}, {'word': '最近傍クラス分類器', 'ratio': 0.1}, {'word': 'k-最近傍分類器', 'ratio': 0.1}]",k最近傍分類器
2133,2485,k-nearest neighbor graph,k近傍グラフ,0.2,10,"[{'word': 'k最近傍グラフ', 'ratio': 0.6}, {'word': 'k近傍グラフ', 'ratio': 0.2}, {'word': '最近傍グラフ', 'ratio': 0.1}, {'word': 'k-最近傍グラフ', 'ratio': 0.1}]",k最近傍グラフ
2134,2486,kernel approximation,カーネル近似,1.0,10,"[{'word': 'カーネル近似', 'ratio': 1.0}]",カーネル近似
2135,2487,kernel bandwidth,カーネル帯域幅,0.5,10,"[{'word': 'カーネルバンド幅', 'ratio': 0.5}, {'word': 'カーネル帯域幅', 'ratio': 0.5}]",カーネルバンド幅
2136,2488,kernel classifier,カーネル分類器,0.8,10,"[{'word': 'カーネル分類器', 'ratio': 0.8}, {'word': 'カーネル分類子', 'ratio': 0.1}, {'word': '核分類器', 'ratio': 0.1}]",カーネル分類器
2137,2489,kernel density,カーネル密度推定,0.0,10,"[{'word': 'カーネル密度', 'ratio': 0.9}, {'word': '核密度', 'ratio': 0.1}]",カーネル密度
2138,2490,kernel density estimate,カーネル密度推定,0.6666666666666666,9,"[{'word': 'カーネル密度推定', 'ratio': 0.6666666666666666}, {'word': 'カーネル密度の推定', 'ratio': 0.1111111111111111}, {'word': '核密度推定', 'ratio': 0.1111111111111111}, {'word': 'カーネル密度推定値', 'ratio': 0.1111111111111111}]",カーネル密度推定
2139,2491,kernel density estimation,カーネル密度推定,0.3,10,"[{'word': 'カーネル密度推定法', 'ratio': 0.5}, {'word': 'カーネル密度推定', 'ratio': 0.3}, {'word': 'カーネル密度の推定', 'ratio': 0.1}, {'word': '核密度推定', 'ratio': 0.1}]",カーネル密度推定法
2140,2492,kernel evaluation,カーネル評価,0.9,10,"[{'word': 'カーネル評価', 'ratio': 0.9}, {'word': '核評価', 'ratio': 0.1}]",カーネル評価
2141,2493,kernel learning,カーネル学習,1.0,10,"[{'word': 'カーネル学習', 'ratio': 1.0}]",カーネル学習
2142,2494,kernel learning problem,カーネル学習問題,0.7,10,"[{'word': 'カーネル学習問題', 'ratio': 0.7}, {'word': 'カーネル学習の問題', 'ratio': 0.2}, {'word': 'カーネル学習', 'ratio': 0.1}]",カーネル学習問題
2143,2495,kernel machine,カーネルマシン,1.0,10,"[{'word': 'カーネルマシン', 'ratio': 1.0}]",カーネルマシン
2144,2496,kernel matrix,カーネル行列,0.8,10,"[{'word': 'カーネル行列', 'ratio': 0.8}, {'word': 'カーネルマトリックス', 'ratio': 0.2}]",カーネル行列
2145,2497,kernel method,カーネル法,0.8,10,"[{'word': 'カーネル法', 'ratio': 0.8}, {'word': 'カーネルメソッド', 'ratio': 0.2}]",カーネル法
2146,2498,kernel operation,カーネル演算,0.0,10,"[{'word': 'カーネル操作', 'ratio': 1.0}]",カーネル操作
2147,2499,kernel operator,カーネル演算子,1.0,10,"[{'word': 'カーネル演算子', 'ratio': 1.0}]",カーネル演算子
2148,2500,kernel parameter,カーネルパラメータ,1.0,10,"[{'word': 'カーネルパラメータ', 'ratio': 1.0}]",カーネルパラメータ
2149,2501,kernel regression,カーネル回帰,1.0,10,"[{'word': 'カーネル回帰', 'ratio': 1.0}]",カーネル回帰
2150,2502,kernel ridge regression,カーネルリッジ回帰,0.8,10,"[{'word': 'カーネルリッジ回帰', 'ratio': 0.8}, {'word': 'カーネル・リッジ回帰', 'ratio': 0.2}]",カーネルリッジ回帰
2151,2503,kernel size,カーネルサイズ,1.0,10,"[{'word': 'カーネルサイズ', 'ratio': 1.0}]",カーネルサイズ
2152,2504,kernel smoothing,カーネル平滑化,0.2,10,"[{'word': 'カーネルスムージング', 'ratio': 0.6}, {'word': 'カーネル・スムージング', 'ratio': 0.2}, {'word': 'カーネル平滑化', 'ratio': 0.2}]",カーネルスムージング
2153,2505,kernel space,カーネル空間,0.9,10,"[{'word': 'カーネル空間', 'ratio': 0.9}, {'word': 'カーネルスペース', 'ratio': 0.1}]",カーネル空間
2154,2506,kernel spectrum,カーネルスペクトル,0.9,10,"[{'word': 'カーネルスペクトル', 'ratio': 0.9}, {'word': 'カーネル・スペクトラム', 'ratio': 0.1}]",カーネルスペクトル
2155,2507,kernel trick,カーネルトリック,0.9,10,"[{'word': 'カーネルトリック', 'ratio': 0.9}, {'word': 'カーネル・トリック', 'ratio': 0.1}]",カーネルトリック
2156,2508,kernel value,カーネル値,1.0,10,"[{'word': 'カーネル値', 'ratio': 1.0}]",カーネル値
2157,2509,kernel weight,カーネル重み (カーネルじゅうみ),0.0,10,"[{'word': 'カーネル重み', 'ratio': 0.8}, {'word': '穀粒重量', 'ratio': 0.1}, {'word': 'カーネル重量', 'ratio': 0.1}]",カーネル重み
2158,2510,kernel width,カーネル幅,1.0,10,"[{'word': 'カーネル幅', 'ratio': 1.0}]",カーネル幅
2159,2511,kernel-based classification,カーネルベース分類,0.1,10,"[{'word': 'カーネルベースの分類', 'ratio': 0.9}, {'word': 'カーネルベース分類', 'ratio': 0.1}]",カーネルベースの分類
2160,2512,key,キー,0.9,10,"[{'word': 'キー', 'ratio': 0.9}, {'word': '鍵', 'ratio': 0.1}]",キー
2161,2513,keypoint,キーポイント,1.0,10,"[{'word': 'キーポイント', 'ratio': 1.0}]",キーポイント
2162,2514,keypoint detection,重要ポイント検出,0.0,10,"[{'word': 'キーポイント検出', 'ratio': 0.8}, {'word': '検出キーポイント', 'ratio': 0.1}, {'word': 'キーポイント検', 'ratio': 0.1}]",キーポイント検出
2163,2515,keypoint detector,キーポイント検出器,1.0,10,"[{'word': 'キーポイント検出器', 'ratio': 1.0}]",キーポイント検出器
2164,2516,keypoint location,特徴点位置,0.0,10,"[{'word': 'キーポイント位置', 'ratio': 0.8}, {'word': 'キーポイント・ロケーション', 'ratio': 0.1}, {'word': 'キーポイントの位置', 'ratio': 0.1}]",キーポイント位置
2165,2517,keypoint match,キーポイントマッチ,0.6,10,"[{'word': 'キーポイントマッチ', 'ratio': 0.6}, {'word': 'キーポイント一致', 'ratio': 0.1}, {'word': 'キーポイント・マッチ', 'ratio': 0.1}, {'word': 'キーポイントの一致', 'ratio': 0.1}, {'word': 'キーポイント対応', 'ratio': 0.1}]",キーポイントマッチ
2166,2518,knapsack problem,ナップサック問題,0.8,10,"[{'word': 'ナップサック問題', 'ratio': 0.8}, {'word': 'ナップザック問題', 'ratio': 0.2}]",ナップサック問題
2167,2519,knowledge compilation,知識コンパイル,0.8,10,"[{'word': '知識コンパイル', 'ratio': 0.8}, {'word': 'ナレッジ・コンピレーション', 'ratio': 0.2}]",知識コンパイル
2168,2520,knowledge element,知識要素,1.0,10,"[{'word': '知識要素', 'ratio': 1.0}]",知識要素
2169,2521,knowledge graph completion,知識グラフ補完,0.8,10,"[{'word': '知識グラフ補完', 'ratio': 0.8}, {'word': '知識グラフの完成', 'ratio': 0.2}]",知識グラフ補完
2170,2522,knowledge representation,知識表現,1.0,10,"[{'word': '知識表現', 'ratio': 1.0}]",知識表現
2171,2523,knowledge transfer,知識転移,0.0,10,"[{'word': '知識転送', 'ratio': 0.8}, {'word': '知識移転', 'ratio': 0.1}, {'word': '知識の伝達', 'ratio': 0.1}]",知識転送
2172,2524,label,ラベル,1.0,10,"[{'word': 'ラベル', 'ratio': 1.0}]",ラベル
2173,2525,label distribution,ラベル分布,0.8,10,"[{'word': 'ラベル分布', 'ratio': 0.8}, {'word': 'ラベル配布', 'ratio': 0.2}]",ラベル分布
2174,2526,label embedding,ラベル埋め込み,0.9,10,"[{'word': 'ラベル埋め込み', 'ratio': 0.9}, {'word': 'ラベルの埋め込み', 'ratio': 0.1}]",ラベル埋め込み
2175,2527,label noise,ラベルノイズ,1.0,10,"[{'word': 'ラベルノイズ', 'ratio': 1.0}]",ラベルノイズ
2176,2528,label sequence,ラベルシーケンス,0.8,10,"[{'word': 'ラベルシーケンス', 'ratio': 0.8}, {'word': 'ラベル列', 'ratio': 0.1}, {'word': 'ラベル系列', 'ratio': 0.1}]",ラベルシーケンス
2177,2529,label smoothing,ラベル平滑化,0.0,10,"[{'word': 'ラベルスムージング', 'ratio': 0.7}, {'word': 'ラベルのスムージング', 'ratio': 0.2}, {'word': 'ラベル smothing', 'ratio': 0.1}]",ラベルスムージング
2178,2530,label space,ラベル空間,0.8,10,"[{'word': 'ラベル空間', 'ratio': 0.8}, {'word': 'ラベルスペース', 'ratio': 0.2}]",ラベル空間
2179,2531,label token,ラベルトークン,1.0,10,"[{'word': 'ラベルトークン', 'ratio': 1.0}]",ラベルトークン
2180,2532,label vector,ラベルベクトル,1.0,10,"[{'word': 'ラベルベクトル', 'ratio': 1.0}]",ラベルベクトル
2181,2533,labeled datum,ラベル付きデータ,0.6,10,"[{'word': 'ラベル付きデータ', 'ratio': 0.6}, {'word': 'ラベル付けされたデータ', 'ratio': 0.2}, {'word': 'ラベル付きデータム', 'ratio': 0.2}]",ラベル付きデータ
2182,2534,labeled example,ラベル例,0.0,10,"[{'word': 'ラベル付き例', 'ratio': 0.5}, {'word': 'ラベル付けされた例', 'ratio': 0.3}, {'word': 'ラベルの例', 'ratio': 0.1}, {'word': 'ラベル付きの例', 'ratio': 0.1}]",ラベル付き例
2183,2535,labeled graph,ラベル付きグラフ,0.8,10,"[{'word': 'ラベル付きグラフ', 'ratio': 0.8}, {'word': 'ラベル付けされたグラフ', 'ratio': 0.2}]",ラベル付きグラフ
2184,2536,labeled training datum,ラベル付きトレーニングデータ,0.7,10,"[{'word': 'ラベル付きトレーニングデータ', 'ratio': 0.7}, {'word': 'ラベル付き訓練データ', 'ratio': 0.2}, {'word': 'ラベル付き学習データ', 'ratio': 0.1}]",ラベル付きトレーニングデータ
2185,2537,lambda calculus,ラムダ計算,1.0,10,"[{'word': 'ラムダ計算', 'ratio': 1.0}]",ラムダ計算
2186,2538,landmark,特徴点,0.0,10,"[{'word': 'ランドマーク', 'ratio': 1.0}]",ランドマーク
2187,2539,landmark point,ランドマークポイント,0.8,10,"[{'word': 'ランドマークポイント', 'ratio': 0.8}, {'word': 'ランドマーク点', 'ratio': 0.2}]",ランドマークポイント
2188,2540,language drift,言語ドリフト,0.2,10,"[{'word': '言語の漂流', 'ratio': 0.5}, {'word': '言語ドリフト', 'ratio': 0.2}, {'word': '言語漂流', 'ratio': 0.1}, {'word': '言語漂移', 'ratio': 0.1}, {'word': '言語の偏移', 'ratio': 0.1}]",言語の漂流
2189,2541,language encoder,言語エンコーダー,0.2,10,"[{'word': '言語エンコーダ', 'ratio': 0.8}, {'word': '言語エンコーダー', 'ratio': 0.2}]",言語エンコーダ
2190,2542,language generation,言語生成,0.9,10,"[{'word': '言語生成', 'ratio': 0.9}, {'word': '言語の生成', 'ratio': 0.1}]",言語生成
2191,2543,language generation model,言語生成モデル,1.0,10,"[{'word': '言語生成モデル', 'ratio': 1.0}]",言語生成モデル
2192,2544,language identification,言語識別,0.8,10,"[{'word': '言語識別', 'ratio': 0.8}, {'word': '言語の識別', 'ratio': 0.1}, {'word': '言語生成モデル', 'ratio': 0.1}]",言語識別
2193,2545,language model pre-training,言語モデルの事前学習,0.7,10,"[{'word': '言語モデルの事前学習', 'ratio': 0.7}, {'word': '言語モデルの事前トレーニング', 'ratio': 0.2}, {'word': '言語モデル前期学習', 'ratio': 0.1}]",言語モデルの事前学習
2194,2546,language pair,言語ペア,0.9,10,"[{'word': '言語ペア', 'ratio': 0.9}, {'word': '言語対', 'ratio': 0.1}]",言語ペア
2195,2547,language representation,言語表現,1.0,10,"[{'word': '言語表現', 'ratio': 1.0}]",言語表現
2196,2548,language transfer,言語転移,0.0,10,"[{'word': '言語転送', 'ratio': 0.7}, {'word': '言語伝達', 'ratio': 0.2}, {'word': '言語移転', 'ratio': 0.1}]",言語転送
2197,2549,language understanding,言語理解,1.0,10,"[{'word': '言語理解', 'ratio': 1.0}]",言語理解
2198,2550,large language model,大規模言語モデル,0.8,10,"[{'word': '大規模言語モデル', 'ratio': 0.8}, {'word': '大型言語モデル', 'ratio': 0.1}, {'word': '大規模な言語モデル', 'ratio': 0.1}]",大規模言語モデル
2199,2552,latent code,潜在コード,1.0,10,"[{'word': '潜在コード', 'ratio': 1.0}]",潜在コード
2200,2553,latent dimension,潜在次元,1.0,10,"[{'word': '潜在次元', 'ratio': 1.0}]",潜在次元
2201,2554,latent distribution,潜在分布,1.0,10,"[{'word': '潜在分布', 'ratio': 1.0}]",潜在分布
2202,2555,latent dynamic model,潜在動的モデル,1.0,10,"[{'word': '潜在動的モデル', 'ratio': 1.0}]",潜在動的モデル
2203,2556,latent embedding,潜在埋め込み,1.0,10,"[{'word': '潜在埋め込み', 'ratio': 1.0}]",潜在埋め込み
2204,2557,latent factor,潜在因子,1.0,10,"[{'word': '潜在因子', 'ratio': 1.0}]",潜在因子
2205,2558,latent feature,潜在特徴,0.9,10,"[{'word': '潜在特徴', 'ratio': 0.9}, {'word': '潜在的特徴', 'ratio': 0.1}]",潜在特徴
2206,2559,latent function,潜在関数,1.0,10,"[{'word': '潜在関数', 'ratio': 1.0}]",潜在関数
2207,2560,latent group,潜在グループ,0.6,10,"[{'word': '潜在グループ', 'ratio': 0.6}, {'word': '潜在群', 'ratio': 0.4}]",潜在グループ
2208,2561,latent parameter,潜在パラメータ,1.0,10,"[{'word': '潜在パラメータ', 'ratio': 1.0}]",潜在パラメータ
2209,2562,latent representation,潜在表現,1.0,10,"[{'word': '潜在表現', 'ratio': 1.0}]",潜在表現
2210,2563,latent reward function,潜在報酬関数,1.0,10,"[{'word': '潜在報酬関数', 'ratio': 1.0}]",潜在報酬関数
2211,2564,latent semantic,潜在的意味,0.0,10,"[{'word': '潜在意味', 'ratio': 0.9}, {'word': '潜在セマンティクス', 'ratio': 0.1}]",潜在意味
2212,2565,latent space,潜在空間,0.8,10,"[{'word': '潜在空間', 'ratio': 0.8}, {'word': 'せんざいくうげき', 'ratio': 0.2}]",潜在空間
2213,2566,latent state,潜在状態,1.0,10,"[{'word': '潜在状態', 'ratio': 1.0}]",潜在状態
2214,2567,latent topic,潜在トピック,1.0,10,"[{'word': '潜在トピック', 'ratio': 1.0}]",潜在トピック
2215,2568,latent variable,潜在変数,1.0,10,"[{'word': '潜在変数', 'ratio': 1.0}]",潜在変数
2216,2569,latent variable model,潜在変数モデル,1.0,10,"[{'word': '潜在変数モデル', 'ratio': 1.0}]",潜在変数モデル
2217,2570,latent vector,潜在ベクトル,1.0,10,"[{'word': '潜在ベクトル', 'ratio': 1.0}]",潜在ベクトル
2218,2571,layer,レイヤー,0.5,10,"[{'word': 'レイヤー', 'ratio': 0.5}, {'word': '層', 'ratio': 0.5}]",レイヤー
2219,2572,layer activation,層活性化,0.1,10,"[{'word': 'レイヤー活性化', 'ratio': 0.5}, {'word': '層の活性化', 'ratio': 0.2}, {'word': 'レイヤーの活性化', 'ratio': 0.2}, {'word': '層活性化', 'ratio': 0.1}]",レイヤー活性化
2220,2574,lazy grounding,遅延グラウンディング,0.1,10,"[{'word': 'レイジーグラウンディング', 'ratio': 0.5}, {'word': '遅延基盤化', 'ratio': 0.2}, {'word': '怠惰な接地', 'ratio': 0.2}, {'word': '遅延グラウンディング', 'ratio': 0.1}]",レイジーグラウンディング
2221,2575,leaf node,葉ノード,0.2,10,"[{'word': 'リーフノード', 'ratio': 0.8}, {'word': '葉ノード', 'ratio': 0.2}]",リーフノード
2222,2576,learnability,学習可能性,0.8,10,"[{'word': '学習可能性', 'ratio': 0.8}, {'word': '学習性', 'ratio': 0.2}]",学習可能性
2223,2577,learnable parameter,学習可能なパラメータ,0.5,10,"[{'word': '学習可能なパラメータ', 'ratio': 0.5}, {'word': '学習可能パラメータ', 'ratio': 0.5}]",学習可能なパラメータ
2224,2578,learnable vector,学習可能なベクトル,0.1,10,"[{'word': '学習可能ベクトル', 'ratio': 0.9}, {'word': '学習可能なベクトル', 'ratio': 0.1}]",学習可能ベクトル
2225,2579,learned model,モデルを学習する,0.0,10,"[{'word': '学習モデル', 'ratio': 0.5}, {'word': '学習済みモデル', 'ratio': 0.5}]",学習モデル
2226,2580,learned representation,表現を学習する,0.0,10,"[{'word': '学習された表現', 'ratio': 0.6}, {'word': '学習表現', 'ratio': 0.4}]",学習された表現
2227,2581,learner,学習者,1.0,10,"[{'word': '学習者', 'ratio': 1.0}]",学習者
2228,2582,learning agent,学習エージェント,1.0,10,"[{'word': '学習エージェント', 'ratio': 1.0}]",学習エージェント
2229,2583,learning algorithm,学習アルゴリズム,1.0,10,"[{'word': '学習アルゴリズム', 'ratio': 1.0}]",学習アルゴリズム
2230,2584,learning method,学習方法,0.6,10,"[{'word': '学習方法', 'ratio': 0.6}, {'word': '学習手法', 'ratio': 0.4}]",学習方法
2231,2585,learning paradigm,学習パラダイム,1.0,10,"[{'word': '学習パラダイム', 'ratio': 1.0}]",学習パラダイム
2232,2586,learning problem,学習問題,1.0,10,"[{'word': '学習問題', 'ratio': 1.0}]",学習問題
2233,2587,learning rate decay,学習率減衰,0.9,10,"[{'word': '学習率減衰', 'ratio': 0.9}, {'word': '学習率の減衰', 'ratio': 0.1}]",学習率減衰
2234,2588,learning rate decay schedule,学習率減衰スケジュール,1.0,10,"[{'word': '学習率減衰スケジュール', 'ratio': 1.0}]",学習率減衰スケジュール
2235,2589,learning rate schedule,学習率スケジュール,0.8,10,"[{'word': '学習率スケジュール', 'ratio': 0.8}, {'word': 'ラーニング・レート・スケジュール', 'ratio': 0.2}]",学習率スケジュール
2236,2590,learning rate scheduler,学習率スケジューラ,1.0,10,"[{'word': '学習率スケジューラ', 'ratio': 1.0}]",学習率スケジューラ
2237,2591,learning rate warmup,学習率ウォームアップ,0.8,10,"[{'word': '学習率ウォームアップ', 'ratio': 0.8}, {'word': 'ラーニング・レート・ウォームアップ', 'ratio': 0.2}]",学習率ウォームアップ
2238,2592,learning-to-rank algorithm,順位付け学習アルゴリズム,0.0,10,"[{'word': 'ランキング学習アルゴリズム', 'ratio': 0.5}, {'word': '学習ランキングアルゴリズム', 'ratio': 0.2}, {'word': 'ランク付け学習アルゴリズム', 'ratio': 0.2}, {'word': '学習順位付けアルゴリズム', 'ratio': 0.1}]",ランキング学習アルゴリズム
2239,2593,least square,最小二乗法,0.8,10,"[{'word': '最小二乗法', 'ratio': 0.8}, {'word': '最小二乗', 'ratio': 0.2}]",最小二乗法
2240,2594,least square criterion,最小二乗基準,1.0,10,"[{'word': '最小二乗基準', 'ratio': 1.0}]",最小二乗基準
2241,2595,least square minimization,最小二乗法,0.0,10,"[{'word': '最小二乗最適化', 'ratio': 0.6}, {'word': '最小二乗最小化', 'ratio': 0.3}, {'word': '最小二乗法による最適化', 'ratio': 0.1}]",最小二乗最適化
2242,2596,least square problem,最小二乗問題,1.0,10,"[{'word': '最小二乗問題', 'ratio': 1.0}]",最小二乗問題
2243,2597,least square regression,最小二乗回帰,1.0,10,"[{'word': '最小二乗回帰', 'ratio': 1.0}]",最小二乗回帰
2244,2598,least square solution,最小二乗解,1.0,10,"[{'word': '最小二乗解', 'ratio': 1.0}]",最小二乗解
2245,2600,left-to-right model,左から右のモデル,0.0,10,"[{'word': '左から右へのモデル', 'ratio': 0.6}, {'word': '左から右モデル', 'ratio': 0.3}, {'word': '一つ除外法', 'ratio': 0.1}]",左から右へのモデル
2246,2602,length normalization,長さ正規化,0.8,10,"[{'word': '長さ正規化', 'ratio': 0.8}, {'word': '長さの正規化', 'ratio': 0.2}]",長さ正規化
2247,2603,length penalty,長さペナルティ,1.0,10,"[{'word': '長さペナルティ', 'ratio': 1.0}]",長さペナルティ
2248,2604,lexeme,語彙素,0.3,10,"[{'word': 'レキシーム', 'ratio': 0.5}, {'word': '語彙素', 'ratio': 0.3}, {'word': '語彙項', 'ratio': 0.1}, {'word': '語素', 'ratio': 0.1}]",レキシーム
2249,2605,lexical acquisition,語彙獲得,0.5,10,"[{'word': '語彙獲得', 'ratio': 0.5}, {'word': 'レキシカル獲得', 'ratio': 0.2}, {'word': '語彙習得', 'ratio': 0.1}, {'word': '語彙の獲得', 'ratio': 0.1}, {'word': '語彙的習得', 'ratio': 0.1}]",語彙獲得
2250,2606,lexical acquisition algorithm,語彙獲得アルゴリズム,0.9,10,"[{'word': '語彙獲得アルゴリズム', 'ratio': 0.9}, {'word': '語彙取得アルゴリズム', 'ratio': 0.1}]",語彙獲得アルゴリズム
2251,2608,lexical entry,語彙項目,0.3,10,"[{'word': '語彙エントリ', 'ratio': 0.6}, {'word': '語彙項目', 'ratio': 0.3}, {'word': '語彙エントリー', 'ratio': 0.1}]",語彙エントリ
2252,2610,lexical feature,語彙的特徴,0.2,10,"[{'word': '語彙特徴', 'ratio': 0.6}, {'word': '字句の特徴', 'ratio': 0.2}, {'word': '語彙的特徴', 'ratio': 0.2}]",語彙特徴
2253,2612,lexical item,語彙項目,0.8,10,"[{'word': '語彙項目', 'ratio': 0.8}, {'word': '字句項目', 'ratio': 0.1}, {'word': '語彙項', 'ratio': 0.1}]",語彙項目
2254,2613,lexical knowledge,語彙知識,1.0,10,"[{'word': '語彙知識', 'ratio': 1.0}]",語彙知識
2255,2614,lexical model,語彙モデル,1.0,10,"[{'word': '語彙モデル', 'ratio': 1.0}]",語彙モデル
2256,2616,lexicalization,語彙化,0.9,10,"[{'word': '語彙化', 'ratio': 0.9}, {'word': 'レキシカル化', 'ratio': 0.1}]",語彙化
2257,2617,lexicalized grammar,語彙化された文法,0.2,10,"[{'word': '語彙化文法', 'ratio': 0.7}, {'word': '語彙化された文法', 'ratio': 0.2}, {'word': 'レキシカル化文法', 'ratio': 0.1}]",語彙化文法
2258,2619,lexicon,語彙,0.1,10,"[{'word': '辞書', 'ratio': 0.8}, {'word': 'レキシコン', 'ratio': 0.1}, {'word': '語彙', 'ratio': 0.1}]",辞書
2259,2620,lexicon induction,語彙誘導,0.3,10,"[{'word': '辞書誘導', 'ratio': 0.5}, {'word': '語彙誘導', 'ratio': 0.3}, {'word': 'レキシコン導入', 'ratio': 0.1}, {'word': '辞書導入', 'ratio': 0.1}]",辞書誘導
2260,2621,light field,光場,0.2,10,"[{'word': 'ライトフィールド', 'ratio': 0.7}, {'word': '光場', 'ratio': 0.2}, {'word': '軽野砲', 'ratio': 0.1}]",ライトフィールド
2261,2622,light field interpolation,光場補間,0.2,10,"[{'word': 'ライトフィールド補間', 'ratio': 0.8}, {'word': '光場補間', 'ratio': 0.2}]",ライトフィールド補間
2262,2623,likelihood function,尤度関数,1.0,10,"[{'word': '尤度関数', 'ratio': 1.0}]",尤度関数
2263,2624,likelihood ratio test,尤度比検定,1.0,10,"[{'word': '尤度比検定', 'ratio': 1.0}]",尤度比検定
2264,2625,likelihood score,尤度スコア,0.9,10,"[{'word': '尤度スコア', 'ratio': 0.9}, {'word': '可能性スコア', 'ratio': 0.1}]",尤度スコア
2265,2626,line search,ラインサーチ,0.2,10,"[{'word': '線形探索', 'ratio': 0.5}, {'word': 'ラインサーチ', 'ratio': 0.2}, {'word': 'ライン検索', 'ratio': 0.2}, {'word': '線探索', 'ratio': 0.1}]",線形探索
2266,2627,linear activation function,線形活性化関数,1.0,10,"[{'word': '線形活性化関数', 'ratio': 1.0}]",線形活性化関数
2267,2628,linear algebra,線形代数,1.0,10,"[{'word': '線形代数', 'ratio': 1.0}]",線形代数
2268,2629,linear classification,線形分類,1.0,10,"[{'word': '線形分類', 'ratio': 1.0}]",線形分類
2269,2630,linear classification layer,線形分類層,1.0,10,"[{'word': '線形分類層', 'ratio': 1.0}]",線形分類層
2270,2631,linear classifier,線形分類器,1.0,10,"[{'word': '線形分類器', 'ratio': 1.0}]",線形分類器
2271,2632,linear combination,線形結合,1.0,10,"[{'word': '線形結合', 'ratio': 1.0}]",線形結合
2272,2633,linear complexity,線形計算量,0.1,10,"[{'word': '線形複雑性', 'ratio': 0.7}, {'word': 'せんけいふくざつせい', 'ratio': 0.2}, {'word': '線形計算量', 'ratio': 0.1}]",線形複雑性
2273,2634,linear constraint,線形制約,1.0,10,"[{'word': '線形制約', 'ratio': 1.0}]",線形制約
2274,2635,linear decay,線形減衰,1.0,10,"[{'word': '線形減衰', 'ratio': 1.0}]",線形減衰
2275,2636,linear decoder,線形デコーダ,0.8,10,"[{'word': '線形デコーダ', 'ratio': 0.8}, {'word': 'リニアデコーダ', 'ratio': 0.2}]",線形デコーダ
2276,2637,linear discriminant analysis,線形判別分析,0.9,10,"[{'word': '線形判別分析', 'ratio': 0.9}, {'word': '線形分類分析', 'ratio': 0.1}]",線形判別分析
2277,2638,linear equation,線形方程式,0.8,10,"[{'word': '線形方程式', 'ratio': 0.8}, {'word': '一次方程式', 'ratio': 0.2}]",線形方程式
2278,2639,linear evaluation,線形評価,1.0,10,"[{'word': '線形評価', 'ratio': 1.0}]",線形評価
2279,2640,linear function,線形関数,0.8,10,"[{'word': '線形関数', 'ratio': 0.8}, {'word': '一次関数', 'ratio': 0.2}]",線形関数
2280,2641,linear function approximation,線形関数近似,0.8,10,"[{'word': '線形関数近似', 'ratio': 0.8}, {'word': '一次関数近似', 'ratio': 0.2}]",線形関数近似
2281,2642,linear inequality,線形不等式,1.0,10,"[{'word': '線形不等式', 'ratio': 1.0}]",線形不等式
2282,2643,linear interpolation,線形補間,1.0,10,"[{'word': '線形補間', 'ratio': 1.0}]",線形補間
2283,2644,linear kernel,線形カーネル,1.0,10,"[{'word': '線形カーネル', 'ratio': 1.0}]",線形カーネル
2284,2645,linear layer,線形層,1.0,10,"[{'word': '線形層', 'ratio': 1.0}]",線形層
2285,2646,linear learning rate decay,線形学習率減衰,0.9,10,"[{'word': '線形学習率減衰', 'ratio': 0.9}, {'word': '学習率の線形減衰', 'ratio': 0.1}]",線形学習率減衰
2286,2647,linear learning rate schedule,線形学習率スケジュール,0.9,10,"[{'word': '線形学習率スケジュール', 'ratio': 0.9}, {'word': '線形学習速度スケジュール', 'ratio': 0.1}]",線形学習率スケジュール
2287,2648,linear map,線形写像,0.8,10,"[{'word': '線形写像', 'ratio': 0.8}, {'word': '線形マップ', 'ratio': 0.2}]",線形写像
2288,2649,linear model,線形モデル,1.0,10,"[{'word': '線形モデル', 'ratio': 1.0}]",線形モデル
2289,2650,linear predictor,線形予測器,0.4,10,"[{'word': '線形予測子', 'ratio': 0.6}, {'word': '線形予測器', 'ratio': 0.4}]",線形予測子
2290,2651,linear probe,線形プローブ,0.8,10,"[{'word': '線形プローブ', 'ratio': 0.8}, {'word': 'リニアプローブ', 'ratio': 0.2}]",線形プローブ
2291,2654,linear projection,線形射影,0.7,10,"[{'word': '線形射影', 'ratio': 0.7}, {'word': '直線投影', 'ratio': 0.2}, {'word': '線形投影', 'ratio': 0.1}]",線形射影
2292,2655,linear regression model,線形回帰モデル,1.0,10,"[{'word': '線形回帰モデル', 'ratio': 1.0}]",線形回帰モデル
2293,2656,linear regressor,線形回帰器,0.8,10,"[{'word': '線形回帰器', 'ratio': 0.8}, {'word': '線形回帰変数', 'ratio': 0.2}]",線形回帰器
2294,2657,linear scaling,線形スケーリング,1.0,10,"[{'word': '線形スケーリング', 'ratio': 1.0}]",線形スケーリング
2295,2658,linear scheduler,線形スケジューラ,0.6,10,"[{'word': '線形スケジューラ', 'ratio': 0.6}, {'word': '線形スケジューラー', 'ratio': 0.2}, {'word': 'リニアスケジューラ', 'ratio': 0.2}]",線形スケジューラ
2296,2659,linear separability,線形可分性,0.3,10,"[{'word': '線形分離可能性', 'ratio': 0.5}, {'word': '線形可分性', 'ratio': 0.3}, {'word': '線形分離性', 'ratio': 0.2}]",線形分離可能性
2297,2660,linear system,線形システム,0.8,10,"[{'word': '線形システム', 'ratio': 0.8}, {'word': '線形系', 'ratio': 0.2}]",線形システム
2298,2661,linear transform,線形変換,1.0,10,"[{'word': '線形変換', 'ratio': 1.0}]",線形変換
2299,2662,linear transformation,線形変換,0.9,10,"[{'word': '線形変換', 'ratio': 0.9}, {'word': '一次変換', 'ratio': 0.1}]",線形変換
2300,2663,linear transformation matrix,線形変換行列,1.0,10,"[{'word': '線形変換行列', 'ratio': 1.0}]",線形変換行列
2301,2664,linear warm-up,線形ウォームアップ,0.8,10,"[{'word': '線形ウォームアップ', 'ratio': 0.8}, {'word': 'リニアウォームアップ', 'ratio': 0.1}, {'word': '線形ウォーミングアップ', 'ratio': 0.1}]",線形ウォームアップ
2302,2666,linear-quadratic regulator,線形二次レギュレータ,0.7,10,"[{'word': '線形二次レギュレータ', 'ratio': 0.7}, {'word': '線形二次制御器', 'ratio': 0.2}, {'word': '一次二次レギュレータ', 'ratio': 0.1}]",線形二次レギュレータ
2303,2667,linearization,線形化,1.0,10,"[{'word': '線形化', 'ratio': 1.0}]",線形化
2304,2668,link function,リンク関数,0.8,10,"[{'word': 'リンク関数', 'ratio': 0.8}, {'word': 'リンク機能', 'ratio': 0.2}]",リンク関数
2305,2669,link prediction,リンク予測,1.0,10,"[{'word': 'リンク予測', 'ratio': 1.0}]",リンク予測
2306,2670,local basis function,局所基底関数,0.4,10,"[{'word': 'ローカル基底関数', 'ratio': 0.6}, {'word': '局所基底関数', 'ratio': 0.4}]",ローカル基底関数
2307,2671,local coherence,ローカル一貫性,0.1,10,"[{'word': 'ローカルコヒーレンス', 'ratio': 0.6}, {'word': '局所的コヒーレンス', 'ratio': 0.1}, {'word': 'ローカル一貫性', 'ratio': 0.1}, {'word': '局所的一致性', 'ratio': 0.1}, {'word': 'ローカル整合性', 'ratio': 0.1}]",ローカルコヒーレンス
2308,2672,local context,局所的コンテキスト,0.0,10,"[{'word': 'ローカルコンテキスト', 'ratio': 0.9}, {'word': '局所コンテキスト', 'ratio': 0.1}]",ローカルコンテキスト
2309,2673,local coordinate frame,ローカル座標系,0.6,10,"[{'word': 'ローカル座標系', 'ratio': 0.6}, {'word': 'ローカル座標フレーム', 'ratio': 0.3}, {'word': '局所座標系', 'ratio': 0.1}]",ローカル座標系
2310,2674,local feature,局所的特徴,0.2,10,"[{'word': 'ローカル特徴', 'ratio': 0.7}, {'word': '局所的特徴', 'ratio': 0.2}, {'word': '局所特徴', 'ratio': 0.1}]",ローカル特徴
2311,2675,local geometry,局所幾何 (Kyokusho Kikai),0.0,10,"[{'word': 'ローカルジオメトリ', 'ratio': 0.8}, {'word': '局所幾何学', 'ratio': 0.1}, {'word': 'ローカル幾何', 'ratio': 0.1}]",ローカルジオメトリ
2312,2676,local image feature,局所画像特徴,0.1,10,"[{'word': 'ローカル画像特徴', 'ratio': 0.7}, {'word': 'ローカル画像機能', 'ratio': 0.2}, {'word': '局所画像特徴', 'ratio': 0.1}]",ローカル画像特徴
2313,2682,local model,ローカルモデル,1.0,10,"[{'word': 'ローカルモデル', 'ratio': 1.0}]",ローカルモデル
2314,2685,local parameter,ローカルパラメータ,1.0,10,"[{'word': 'ローカルパラメータ', 'ratio': 1.0}]",ローカルパラメータ
2315,2686,local search,局所探索,0.1,10,"[{'word': 'ローカルサーチ', 'ratio': 0.6}, {'word': 'ローカル検索', 'ratio': 0.2}, {'word': '局所探索', 'ratio': 0.1}, {'word': 'ローカル探索', 'ratio': 0.1}]",ローカルサーチ
2316,2687,local search method,局所探索法,0.5,10,"[{'word': '局所探索法', 'ratio': 0.5}, {'word': 'ローカルサーチ法', 'ratio': 0.4}, {'word': 'ローカル検索方法', 'ratio': 0.1}]",局所探索法
2317,2688,local variable,ローカル変数,1.0,10,"[{'word': 'ローカル変数', 'ratio': 1.0}]",ローカル変数
2318,2689,local window,ローカルウィンドウ,1.0,10,"[{'word': 'ローカルウィンドウ', 'ratio': 1.0}]",ローカルウィンドウ
2319,2691,localization,局所化,0.0,10,"[{'word': 'ローカリゼーション', 'ratio': 0.8}, {'word': '位置特定', 'ratio': 0.1}, {'word': 'ローカライゼーション', 'ratio': 0.1}]",ローカリゼーション
2320,2692,location parameter,位置パラメータ,0.5,10,"[{'word': '位置パラメータ', 'ratio': 0.5}, {'word': '位相パラメータ', 'ratio': 0.2}, {'word': '場所パラメータ', 'ratio': 0.2}, {'word': '位置パラメーター', 'ratio': 0.1}]",位置パラメータ
2321,2693,log,対数,0.7,10,"[{'word': '対数', 'ratio': 0.7}, {'word': 'ログ', 'ratio': 0.2}, {'word': '寄与', 'ratio': 0.1}]",対数
2322,2694,log likelihood,対数尤度,0.8,10,"[{'word': '対数尤度', 'ratio': 0.8}, {'word': 'ログ', 'ratio': 0.1}, {'word': '寄与度', 'ratio': 0.1}]",対数尤度
2323,2695,log loss,ログ損失,0.0,10,"[{'word': '対数損失', 'ratio': 0.8}, {'word': 'ログの損失', 'ratio': 0.1}, {'word': '寄与度損失', 'ratio': 0.1}]",対数損失
2324,2696,log marginal likelihood,対数周辺尤度,0.8,10,"[{'word': '対数周辺尤度', 'ratio': 0.8}, {'word': '対数限界尤度', 'ratio': 0.1}, {'word': '寄与度対数尤度', 'ratio': 0.1}]",対数周辺尤度
2325,2697,log p,ログp,0.5,10,"[{'word': 'ログp', 'ratio': 0.5}, {'word': '対数p', 'ratio': 0.2}, {'word': '対数 p', 'ratio': 0.1}, {'word': 'log p', 'ratio': 0.1}, {'word': 'ログ確率', 'ratio': 0.1}]",ログp
2326,2698,log partition function,対数パーティション関数,0.0,10,"[{'word': '対数分配関数', 'ratio': 0.7}, {'word': 'ログパーティション機能', 'ratio': 0.2}, {'word': 'ログ分配関数', 'ratio': 0.1}]",対数分配関数
2327,2700,log probability,ログ確率,0.1,10,"[{'word': '対数確率', 'ratio': 0.9}, {'word': 'ログ確率', 'ratio': 0.1}]",対数確率
2328,2701,log-likelihood function,対数尤度関数,1.0,10,"[{'word': '対数尤度関数', 'ratio': 1.0}]",対数尤度関数
2329,2702,log-likelihood loss,対数尤度損失,1.0,10,"[{'word': '対数尤度損失', 'ratio': 1.0}]",対数尤度損失
2330,2703,log-likelihood ratio,対数尤度比,0.9,10,"[{'word': '対数尤度比', 'ratio': 0.9}, {'word': '対数尤度損失', 'ratio': 0.1}]",対数尤度比
2331,2704,log-linear model,対数線形モデル,1.0,10,"[{'word': '対数線形モデル', 'ratio': 1.0}]",対数線形モデル
2332,2705,log-linear translation model,対数線形翻訳モデル,1.0,10,"[{'word': '対数線形翻訳モデル', 'ratio': 1.0}]",対数線形翻訳モデル
2333,2706,log-log plot,log-log プロット,0.0,10,"[{'word': '対数-対数プロット', 'ratio': 0.6}, {'word': '対数プロット', 'ratio': 0.2}, {'word': '対数対数プロット', 'ratio': 0.2}]",対数-対数プロット
2334,2707,log-normal distribution,対数正規分布,1.0,10,"[{'word': '対数正規分布', 'ratio': 1.0}]",対数正規分布
2335,2708,log-odd score,対数オッズスコア,0.8,10,"[{'word': '対数オッズスコア', 'ratio': 0.8}, {'word': '対数得点', 'ratio': 0.1}, {'word': '対数奇数スコア', 'ratio': 0.1}]",対数オッズスコア
2336,2709,log-prob,対数確率,0.8,10,"[{'word': '対数確率', 'ratio': 0.8}, {'word': 'ログプロブ', 'ratio': 0.2}]",対数確率
2337,2710,log-sum-exp,ログ-サム-エクスポネンシャル,0.0,10,"[{'word': '対数和指数', 'ratio': 0.8}, {'word': '対数和-指数', 'ratio': 0.1}, {'word': '対数和式', 'ratio': 0.1}]",対数和指数
2338,2711,logical connective,論理結合子,0.0,10,"[{'word': '論理接続詞', 'ratio': 0.8}, {'word': 'ろんりけつごうし', 'ratio': 0.1}, {'word': '論理接続子', 'ratio': 0.1}]",論理接続詞
2339,2712,logical form,論理形式,0.9,10,"[{'word': '論理形式', 'ratio': 0.9}, {'word': '論理形態', 'ratio': 0.1}]",論理形式
2340,2713,logistic function,ロジスティック関数,0.9,10,"[{'word': 'ロジスティック関数', 'ratio': 0.9}, {'word': 'ロジスティック損失', 'ratio': 0.1}]",ロジスティック関数
2341,2714,logistic loss,ロジスティック損失,0.9,10,"[{'word': 'ロジスティック損失', 'ratio': 0.9}, {'word': '物流損失', 'ratio': 0.1}]",ロジスティック損失
2342,2715,logistic regression classifier,ロジスティック回帰分類器,1.0,10,"[{'word': 'ロジスティック回帰分類器', 'ratio': 1.0}]",ロジスティック回帰分類器
2343,2716,logistic regression model,ロジスティック回帰モデル,1.0,10,"[{'word': 'ロジスティック回帰モデル', 'ratio': 1.0}]",ロジスティック回帰モデル
2344,2717,logit,ロジット,1.0,10,"[{'word': 'ロジット', 'ratio': 1.0}]",ロジット
2345,2718,logit model,ロジットモデル,1.0,10,"[{'word': 'ロジットモデル', 'ratio': 1.0}]",ロジットモデル
2346,2719,long-range dependency,長距離依存性,0.8,10,"[{'word': '長距離依存性', 'ratio': 0.8}, {'word': 'ロングレンジ依存', 'ratio': 0.1}, {'word': '長距離依存', 'ratio': 0.1}]",長距離依存性
2347,2720,lookup table,検索テーブル,0.0,10,"[{'word': 'ルックアップテーブル', 'ratio': 1.0}]",ルックアップテーブル
2348,2721,loop closure,ループクロージャ,0.1,10,"[{'word': 'ループクローズure', 'ratio': 0.5}, {'word': 'ループクロージャー', 'ratio': 0.2}, {'word': 'ループうーん', 'ratio': 0.1}, {'word': 'ループクロージャ', 'ratio': 0.1}, {'word': 'ループクローズャー', 'ratio': 0.1}]",ループクローズure
2349,2723,loss,損失,1.0,10,"[{'word': '損失', 'ratio': 1.0}]",損失
2350,2724,loss distribution,損失分布,0.8,10,"[{'word': '損失分布', 'ratio': 0.8}, {'word': '損失の分配', 'ratio': 0.2}]",損失分布
2351,2725,loss function,損失関数,1.0,10,"[{'word': '損失関数', 'ratio': 1.0}]",損失関数
2352,2727,loss minimization,損失最小化,0.7,10,"[{'word': '損失最小化', 'ratio': 0.7}, {'word': '損失の最小化', 'ratio': 0.2}, {'word': 'ロス最小化', 'ratio': 0.1}]",損失最小化
2353,2728,loss term,損失項,0.7,10,"[{'word': '損失項', 'ratio': 0.7}, {'word': '損失期間', 'ratio': 0.2}, {'word': 'ロスターン', 'ratio': 0.1}]",損失項
2354,2729,lossy compression,損失圧縮,0.1,10,"[{'word': '非可逆圧縮', 'ratio': 0.6}, {'word': '有損圧縮', 'ratio': 0.2}, {'word': 'ロスレス圧縮', 'ratio': 0.1}, {'word': '損失圧縮', 'ratio': 0.1}]",非可逆圧縮
2355,2731,low rank,低ランク,0.8,10,"[{'word': '低ランク', 'ratio': 0.8}, {'word': '宝くじ仮説', 'ratio': 0.1}, {'word': '下位', 'ratio': 0.1}]",低ランク
2356,2732,low rank approximation,低ランク近似,0.9,10,"[{'word': '低ランク近似', 'ratio': 0.9}, {'word': '低ランク近似値', 'ratio': 0.1}]",低ランク近似
2357,2734,low-dimensional embedding,低次元埋め込み,1.0,10,"[{'word': '低次元埋め込み', 'ratio': 1.0}]",低次元埋め込み
2358,2735,low-dimensional representation,低次元表現,1.0,10,"[{'word': '低次元表現', 'ratio': 1.0}]",低次元表現
2359,2736,low-pass filter,低域通過フィルタ,0.0,10,"[{'word': 'ローパスフィルター', 'ratio': 0.8}, {'word': 'ローパスフィルタ', 'ratio': 0.2}]",ローパスフィルター
2360,2737,low-rank factorization,低ランク分解,0.2,10,"[{'word': '低ランク因子分解', 'ratio': 0.8}, {'word': '低ランク分解', 'ratio': 0.2}]",低ランク因子分解
2361,2738,low-rank matrix approximation,低ランク行列近似,1.0,10,"[{'word': '低ランク行列近似', 'ratio': 1.0}]",低ランク行列近似
2362,2739,lower bound,下限値,0.0,10,"[{'word': '下限', 'ratio': 0.8}, {'word': '下界', 'ratio': 0.2}]",下限
2363,2741,mT5,mT5,0.8,10,"[{'word': 'mT5', 'ratio': 0.8}, {'word': 'ミオ', 'ratio': 0.1}, {'word': 'メートルT5', 'ratio': 0.1}]",mT5
2364,2742,machine learning algorithm,機械学習アルゴリズム,1.0,10,"[{'word': '機械学習アルゴリズム', 'ratio': 1.0}]",機械学習アルゴリズム
2365,2743,machine learning classifier,機械学習分類器,1.0,10,"[{'word': '機械学習分類器', 'ratio': 1.0}]",機械学習分類器
2366,2744,machine learning model,機械学習モデル,1.0,10,"[{'word': '機械学習モデル', 'ratio': 1.0}]",機械学習モデル
2367,2745,machine learning system,機械学習システム,0.9,10,"[{'word': '機械学習システム', 'ratio': 0.9}, {'word': '機械学習モデル', 'ratio': 0.1}]",機械学習システム
2368,2746,machine reading,機械読解,0.8,10,"[{'word': '機械読解', 'ratio': 0.8}, {'word': '機械読書', 'ratio': 0.1}, {'word': '機械読み取り', 'ratio': 0.1}]",機械読解
2369,2747,machine translation model,機械翻訳モデル,1.0,10,"[{'word': '機械翻訳モデル', 'ratio': 1.0}]",機械翻訳モデル
2370,2748,machine translation system,機械翻訳システム,1.0,10,"[{'word': '機械翻訳システム', 'ratio': 1.0}]",機械翻訳システム
2371,2749,machine vision,マシンビジョン,0.3,10,"[{'word': '機械視覚', 'ratio': 0.7}, {'word': 'マシンビジョン', 'ratio': 0.3}]",機械視覚
2372,2750,machine-generated text,機械生成テキスト,0.8,10,"[{'word': '機械生成テキスト', 'ratio': 0.8}, {'word': '機械生成されたテキスト', 'ratio': 0.1}, {'word': '生成されたテキスト', 'ratio': 0.1}]",機械生成テキスト
2373,2752,macro-F1,マクロ-F1,0.0,10,"[{'word': 'マクロF1', 'ratio': 1.0}]",マクロF1
2374,2753,macro-action,マクロアクション,0.8,10,"[{'word': 'マクロアクション', 'ratio': 0.8}, {'word': 'マクロ動作', 'ratio': 0.2}]",マクロアクション
2375,2754,macro-average,マクロ平均,1.0,10,"[{'word': 'マクロ平均', 'ratio': 1.0}]",マクロ平均
2376,2755,majority voting,過半数決,0.0,10,"[{'word': '多数決', 'ratio': 0.9}, {'word': '過半数投票', 'ratio': 0.1}]",多数決
2377,2756,manifold,多様体,0.5,10,"[{'word': '多様体', 'ratio': 0.5}, {'word': 'マニフォールド', 'ratio': 0.3}, {'word': 'マニホールド', 'ratio': 0.2}]",多様体
2378,2757,manifold hypothesis,多様体仮説,0.6,10,"[{'word': '多様体仮説', 'ratio': 0.6}, {'word': 'マニフォールド仮説', 'ratio': 0.4}]",多様体仮説
2379,2762,margin parameter,マージンパラメータ,0.9,10,"[{'word': 'マージンパラメータ', 'ratio': 0.9}, {'word': 'マージンパラメーター', 'ratio': 0.1}]",マージンパラメータ
2380,2763,marginal density,周辺密度,0.7,10,"[{'word': '周辺密度', 'ratio': 0.7}, {'word': '限界密度', 'ratio': 0.2}, {'word': '边縁密度', 'ratio': 0.1}]",周辺密度
2381,2764,marginal distribution,余部分布,0.0,10,"[{'word': '周辺分布', 'ratio': 0.7}, {'word': '限界分布', 'ratio': 0.2}, {'word': '辺縁分布', 'ratio': 0.1}]",周辺分布
2382,2765,marginal inference,マージナル推論,0.0,10,"[{'word': '周辺推論', 'ratio': 0.7}, {'word': '限界推論', 'ratio': 0.2}, {'word': '辺縁推断', 'ratio': 0.1}]",周辺推論
2383,2766,marginal likelihood,周辺尤度,0.7,10,"[{'word': '周辺尤度', 'ratio': 0.7}, {'word': '限界尤度', 'ratio': 0.2}, {'word': 'マージナル尤度', 'ratio': 0.1}]",周辺尤度
2384,2767,marginal log-likelihood,周辺対数尤度,0.7,10,"[{'word': '周辺対数尤度', 'ratio': 0.7}, {'word': '限界対数尤度', 'ratio': 0.2}, {'word': 'マージナル対数尤度', 'ratio': 0.1}]",周辺対数尤度
2385,2768,marginal polytope,マージナルポリトープ,0.0,10,"[{'word': '周辺多面体', 'ratio': 0.5}, {'word': '周辺ポリトープ', 'ratio': 0.2}, {'word': '限界ポリトープ', 'ratio': 0.2}, {'word': 'マージナル多角形', 'ratio': 0.1}]",周辺多面体
2386,2769,marginal probability,マージナル確率,0.1,10,"[{'word': '周辺確率', 'ratio': 0.9}, {'word': 'マージナル確率', 'ratio': 0.1}]",周辺確率
2387,2770,marginalization,周辺化,0.9,10,"[{'word': '周辺化', 'ratio': 0.9}, {'word': 'マージナリゼーション', 'ratio': 0.1}]",周辺化
2388,2771,mask,マスク,1.0,10,"[{'word': 'マスク', 'ratio': 1.0}]",マスク
2389,2772,mask token,マスクトークン,1.0,10,"[{'word': 'マスクトークン', 'ratio': 1.0}]",マスクトークン
2390,2773,mask vector,マスクベクトル,0.7,10,"[{'word': 'マスクベクトル', 'ratio': 0.7}, {'word': 'マスクベクター', 'ratio': 0.3}]",マスクベクトル
2391,2774,masked input,マスク入力,0.1,10,"[{'word': 'マスクされた入力', 'ratio': 0.9}, {'word': 'マスク入力', 'ratio': 0.1}]",マスクされた入力
2392,2775,masked language model,マスクされた言語モデル (MLM),0.0,10,"[{'word': 'マスク言語モデル', 'ratio': 0.6}, {'word': 'マスク付き言語モデル', 'ratio': 0.3}, {'word': 'マスクされた言語モデル', 'ratio': 0.1}]",マスク言語モデル
2393,2776,masked token,マスクされたトークン,0.2,10,"[{'word': 'マスクトークン', 'ratio': 0.6}, {'word': 'マスク付きトークン', 'ratio': 0.2}, {'word': 'マスクされたトークン', 'ratio': 0.2}]",マスクトークン
2394,2777,masking function,マスキング関数,0.7,10,"[{'word': 'マスキング関数', 'ratio': 0.7}, {'word': 'マスキング機能', 'ratio': 0.3}]",マスキング関数
2395,2778,matching algorithm,マッチングアルゴリズム,1.0,10,"[{'word': 'マッチングアルゴリズム', 'ratio': 1.0}]",マッチングアルゴリズム
2396,2779,matching loss,マッチング損失,0.4,10,"[{'word': 'マッチングロス', 'ratio': 0.6}, {'word': 'マッチング損失', 'ratio': 0.4}]",マッチングロス
2397,2780,matrix,行列,0.7,10,"[{'word': '行列', 'ratio': 0.7}, {'word': 'マトリックス', 'ratio': 0.3}]",行列
2398,2781,matrix approximation,行列近似,0.9,10,"[{'word': '行列近似', 'ratio': 0.9}, {'word': 'ローカル画像機能', 'ratio': 0.1}]",行列近似
2399,2782,matrix decomposition,行列分解,1.0,10,"[{'word': '行列分解', 'ratio': 1.0}]",行列分解
2400,2783,matrix form,行列形式,0.8,10,"[{'word': '行列形式', 'ratio': 0.8}, {'word': 'マトリックス形式', 'ratio': 0.1}, {'word': '行列表現', 'ratio': 0.1}]",行列形式
2401,2784,matrix inversion,行列の逆行列,0.0,10,"[{'word': '行列逆行列', 'ratio': 0.6}, {'word': '逆行列', 'ratio': 0.2}, {'word': '行列逆算', 'ratio': 0.1}, {'word': '行列の逆演算', 'ratio': 0.1}]",行列逆行列
2402,2785,matrix multiplication,行列積,0.2,10,"[{'word': '行列乗算', 'ratio': 0.5}, {'word': '行列積', 'ratio': 0.2}, {'word': '行列の乗算', 'ratio': 0.2}, {'word': '行列の積', 'ratio': 0.1}]",行列乗算
2403,2786,matrix norm,行列ノルム,1.0,10,"[{'word': '行列ノルム', 'ratio': 1.0}]",行列ノルム
2404,2787,matrix sketching,行列スケッチング,0.6,10,"[{'word': '行列スケッチング', 'ratio': 0.6}, {'word': '行列スケッチ', 'ratio': 0.2}, {'word': 'マトリックススケッチ', 'ratio': 0.2}]",行列スケッチング
2405,2788,matrix vector product,行列ベクトル積,1.0,10,"[{'word': '行列ベクトル積', 'ratio': 1.0}]",行列ベクトル積
2406,2789,matrix-vector multiplication,行列ベクトル積,0.0,10,"[{'word': '行列-ベクトル乗算', 'ratio': 0.5}, {'word': '行列とベクトルの乗算', 'ratio': 0.2}, {'word': '行列-ベクトル積', 'ratio': 0.1}, {'word': '行列ベクトル乗算', 'ratio': 0.1}, {'word': '行列ベクトルの乗算', 'ratio': 0.1}]",行列-ベクトル乗算
2407,2790,matroid,マトロイド,0.6,10,"[{'word': 'マトロイド', 'ratio': 0.6}, {'word': 'マイトロイド', 'ratio': 0.4}]",マトロイド
2408,2791,matroid constraint,マトロイド制約,0.3,10,"[{'word': 'マイトロイド制約', 'ratio': 0.7}, {'word': 'マトロイド制約', 'ratio': 0.3}]",マイトロイド制約
2409,2792,max norm,最大ノルム,1.0,10,"[{'word': '最大ノルム', 'ratio': 1.0}]",最大ノルム
2410,2793,max pooling,最大プーリング,0.7,10,"[{'word': '最大プーリング', 'ratio': 0.7}, {'word': 'マックス・プーリング', 'ratio': 0.2}, {'word': '最大プール', 'ratio': 0.1}]",最大プーリング
2411,2794,max-margin,最大マージン,0.8,10,"[{'word': '最大マージン', 'ratio': 0.8}, {'word': 'マックスマージン', 'ratio': 0.2}]",最大マージン
2412,2795,max-margin learning,最大マージン学習,0.8,10,"[{'word': '最大マージン学習', 'ratio': 0.8}, {'word': 'マックスマージン学習', 'ratio': 0.2}]",最大マージン学習
2413,2797,max-pooling layer,max-poolingレイヤー,0.0,10,"[{'word': '最大プーリング層', 'ratio': 0.6}, {'word': 'マックスプーリング層', 'ratio': 0.4}]",最大プーリング層
2414,2798,max-product semiring,最大積半環,0.8,10,"[{'word': '最大積半環', 'ratio': 0.8}, {'word': 'マックスプロダクト半環', 'ratio': 0.1}, {'word': 'マックス積半環', 'ratio': 0.1}]",最大積半環
2415,2799,maximal clique,最大クリーク,0.8,10,"[{'word': '最大クリーク', 'ratio': 0.8}, {'word': '最大閥', 'ratio': 0.2}]",最大クリーク
2416,2800,maximal frequent itemset,最大頻出アイテムセット,0.3,10,"[{'word': '最大頻出アイテム集合', 'ratio': 0.5}, {'word': '最大頻出アイテムセット', 'ratio': 0.3}, {'word': '最大頻出項目集合', 'ratio': 0.2}]",最大頻出アイテム集合
2417,2801,maximal frequent pattern,最大頻出パターン,1.0,10,"[{'word': '最大頻出パターン', 'ratio': 1.0}]",最大頻出パターン
2418,2802,maximization problem,最大化問題,1.0,10,"[{'word': '最大化問題', 'ratio': 1.0}]",最大化問題
2419,2803,maximum a posteriori,最大事後確率解,0.0,10,"[{'word': '最大事後確率', 'ratio': 0.5}, {'word': '最大事後推定', 'ratio': 0.2}, {'word': '最大事後', 'ratio': 0.2}, {'word': '事後最大', 'ratio': 0.1}]",最大事後確率
2420,2805,maximum clique,最大クリーク,0.8,10,"[{'word': '最大クリーク', 'ratio': 0.8}, {'word': '最大閥', 'ratio': 0.2}]",最大クリーク
2421,2806,maximum entropy,最大エントロピー,1.0,10,"[{'word': '最大エントロピー', 'ratio': 1.0}]",最大エントロピー
2422,2807,maximum entropy model,最大エントロピーモデル,1.0,10,"[{'word': '最大エントロピーモデル', 'ratio': 1.0}]",最大エントロピーモデル
2423,2808,maximum entropy principle,最大エントロピー原理,0.9,10,"[{'word': '最大エントロピー原理', 'ratio': 0.9}, {'word': '最大エントロピーの原理', 'ratio': 0.1}]",最大エントロピー原理
2424,2809,maximum flow,最大フロー,0.4,10,"[{'word': '最大流量', 'ratio': 0.5}, {'word': '最大フロー', 'ratio': 0.4}, {'word': '最大流', 'ratio': 0.1}]",最大流量
2425,2810,maximum likelihood estimate,最尤推定,0.8,10,"[{'word': '最尤推定', 'ratio': 0.8}, {'word': '最尤推定値', 'ratio': 0.1}, {'word': '最大尤度推定', 'ratio': 0.1}]",最尤推定
2426,2811,maximum likelihood estimation,最尤推定,0.4,10,"[{'word': '最大尤度推定', 'ratio': 0.5}, {'word': '最尤推定', 'ratio': 0.4}, {'word': '最尤法', 'ratio': 0.1}]",最大尤度推定
2427,2813,maximum likelihood learning,最尤学習,0.4,10,"[{'word': '最大尤度学習', 'ratio': 0.5}, {'word': '最尤学習', 'ratio': 0.4}, {'word': '最尤法', 'ratio': 0.1}]",最大尤度学習
2428,2814,maximum mean discrepancy,最大平均不一致,0.2,10,"[{'word': '最大平均差', 'ratio': 0.6}, {'word': '最大平均不一致', 'ratio': 0.2}, {'word': '最大平均逸脱', 'ratio': 0.1}, {'word': '最大平均偏差', 'ratio': 0.1}]",最大平均差
2429,2815,mean average precision,平均適合率,0.1,10,"[{'word': '平均平均精度', 'ratio': 0.6}, {'word': '平均平均適合率', 'ratio': 0.3}, {'word': '平均適合率', 'ratio': 0.1}]",平均平均精度
2430,2816,mean field,平均場,0.7,10,"[{'word': '平均場', 'ratio': 0.7}, {'word': '平均野', 'ratio': 0.1}, {'word': '平均フィールド', 'ratio': 0.1}, {'word': 'Mīn Fīrudo', 'ratio': 0.1}]",平均場
2431,2817,mean function,平均関数,0.9,10,"[{'word': '平均関数', 'ratio': 0.9}, {'word': 'Mīn Funkushon', 'ratio': 0.1}]",平均関数
2432,2818,mean pooling,平均プーリング,0.9,10,"[{'word': '平均プーリング', 'ratio': 0.9}, {'word': 'Mīn Pōruingu', 'ratio': 0.1}]",平均プーリング
2433,2820,mean shape,平均形状,0.8,10,"[{'word': '平均形状', 'ratio': 0.8}, {'word': '平均的な形状', 'ratio': 0.1}, {'word': 'Mīn Shēpu', 'ratio': 0.1}]",平均形状
2434,2821,mean square error,平均二乗誤差,1.0,10,"[{'word': '平均二乗誤差', 'ratio': 1.0}]",平均二乗誤差
2435,2822,mean vector,平均ベクトル,0.9,10,"[{'word': '平均ベクトル', 'ratio': 0.9}, {'word': 'mean vector', 'ratio': 0.1}]",平均ベクトル
2436,2823,mean-field approximation,平均場近似,1.0,10,"[{'word': '平均場近似', 'ratio': 1.0}]",平均場近似
2437,2824,measurable space,可測空間,0.5,10,"[{'word': '可測空間', 'ratio': 0.5}, {'word': '測度空間', 'ratio': 0.3}, {'word': '測定可能空間', 'ratio': 0.1}, {'word': '測定可能な空間', 'ratio': 0.1}]",可測空間
2438,2825,measurement matrix,計測行列,0.2,10,"[{'word': '測定行列', 'ratio': 0.7}, {'word': '計測行列', 'ratio': 0.2}, {'word': '測定マトリックス', 'ratio': 0.1}]",測定行列
2439,2826,measurement noise,測定ノイズ,0.8,10,"[{'word': '測定ノイズ', 'ratio': 0.8}, {'word': '計測ノイズ', 'ratio': 0.2}]",測定ノイズ
2440,2828,medoid,メドイド,0.9,10,"[{'word': 'メドイド', 'ratio': 0.9}, {'word': 'メド', 'ratio': 0.1}]",メドイド
2441,2829,membership inference attack,メンバーシップ推論攻撃,0.6,10,"[{'word': 'メンバーシップ推論攻撃', 'ratio': 0.6}, {'word': 'メンバーシップ推測攻撃', 'ratio': 0.4}]",メンバーシップ推論攻撃
2442,2830,membership query,所属クエリ,0.0,9,"[{'word': 'メンバーシップクエリ', 'ratio': 0.6666666666666666}, {'word': 'メンバーシップのクエリ', 'ratio': 0.2222222222222222}, {'word': '会員クエリー', 'ratio': 0.1111111111111111}]",メンバーシップクエリ
2443,2832,memory capacity,メモリ容量,0.8888888888888888,9,"[{'word': 'メモリ容量', 'ratio': 0.8888888888888888}, {'word': 'メモリー・キャパシティ', 'ratio': 0.1111111111111111}]",メモリ容量
2444,2833,memory cell,メモリセル,0.6666666666666666,9,"[{'word': 'メモリセル', 'ratio': 0.6666666666666666}, {'word': 'メモリーセル', 'ratio': 0.2222222222222222}, {'word': 'メモリー・セル', 'ratio': 0.1111111111111111}]",メモリセル
2445,2835,mention detection,言及の検出,0.1,10,"[{'word': 'メンション検出', 'ratio': 0.6}, {'word': '言及検出', 'ratio': 0.2}, {'word': '言及の検出', 'ratio': 0.1}, {'word': '名詞検出', 'ratio': 0.1}]",メンション検出
2446,2836,meronymy,部分全体関係,0.0,10,"[{'word': '部分関係', 'ratio': 0.7}, {'word': '部分語関係', 'ratio': 0.1}, {'word': 'メロニー', 'ratio': 0.1}, {'word': 'メロニミー', 'ratio': 0.1}]",部分関係
2447,2837,message passing,メッセージパッシング,0.7,10,"[{'word': 'メッセージパッシング', 'ratio': 0.7}, {'word': 'メッセージ伝達', 'ratio': 0.2}, {'word': 'メッセージ伝播', 'ratio': 0.1}]",メッセージパッシング
2448,2838,message passing algorithm,メッセージ渡しアルゴリズム,0.0,10,"[{'word': 'メッセージパッシングアルゴリズム', 'ratio': 0.7}, {'word': 'メッセージ伝達アルゴリズム', 'ratio': 0.2}, {'word': 'メッセージ伝播アルゴリズム', 'ratio': 0.1}]",メッセージパッシングアルゴリズム
2449,2839,meta,メタ,1.0,10,"[{'word': 'メタ', 'ratio': 1.0}]",メタ
2450,2840,meta-algorithm,メタアルゴリズム,1.0,10,"[{'word': 'メタアルゴリズム', 'ratio': 1.0}]",メタアルゴリズム
2451,2841,meta-classifier,メタ分類器,0.9,10,"[{'word': 'メタ分類器', 'ratio': 0.9}, {'word': 'メタ分類子', 'ratio': 0.1}]",メタ分類器
2452,2842,meta-dataset,メタデータセット,0.9,10,"[{'word': 'メタデータセット', 'ratio': 0.9}, {'word': 'メタ・データセット', 'ratio': 0.1}]",メタデータセット
2453,2843,meta-evaluation,メタ評価,1.0,10,"[{'word': 'メタ評価', 'ratio': 1.0}]",メタ評価
2454,2844,meta-learn,メタ学習,0.8,10,"[{'word': 'メタ学習', 'ratio': 0.8}, {'word': 'メタラーニング', 'ratio': 0.1}, {'word': 'メタ学習する', 'ratio': 0.1}]",メタ学習
2455,2845,meta-learner,メタ学習者,0.6,10,"[{'word': 'メタ学習者', 'ratio': 0.6}, {'word': 'メタラーナー', 'ratio': 0.4}]",メタ学習者
2456,2846,meta-loss,メタ損失,0.6,10,"[{'word': 'メタ損失', 'ratio': 0.6}, {'word': 'メタロス', 'ratio': 0.4}]",メタ損失
2457,2847,meta-parameter,メタパラメータ,1.0,10,"[{'word': 'メタパラメータ', 'ratio': 1.0}]",メタパラメータ
2458,2848,meta-testing,メタテスト,0.8,10,"[{'word': 'メタテスト', 'ratio': 0.8}, {'word': 'メタテスティング', 'ratio': 0.2}]",メタテスト
2459,2849,meta-training,メタトレーニング,1.0,10,"[{'word': 'メタトレーニング', 'ratio': 1.0}]",メタトレーニング
2460,2850,metadata,メタデータ,1.0,9,"[{'word': 'メタデータ', 'ratio': 1.0}]",メタデータ
2461,2851,metric learning,メトリック学習,0.7777777777777778,9,"[{'word': 'メトリック学習', 'ratio': 0.7777777777777778}, {'word': '計量学習', 'ratio': 0.1111111111111111}, {'word': '指標の学習', 'ratio': 0.1111111111111111}]",メトリック学習
2462,2852,metric learning algorithm,メトリック学習アルゴリズム,0.8888888888888888,9,"[{'word': 'メトリック学習アルゴリズム', 'ratio': 0.8888888888888888}, {'word': 'メトリクス学習アルゴリズム', 'ratio': 0.1111111111111111}]",メトリック学習アルゴリズム
2463,2853,metric score,メトリックスコア,0.8,10,"[{'word': 'メトリックスコア', 'ratio': 0.8}, {'word': 'Metricu Sukōru', 'ratio': 0.1}, {'word': '評価指標スコア', 'ratio': 0.1}]",メトリックスコア
2464,2854,metric space,メトリック空間,0.5,10,"[{'word': 'メトリック空間', 'ratio': 0.5}, {'word': 'メートル空間', 'ratio': 0.2}, {'word': '距離空間', 'ratio': 0.2}, {'word': 'Metricu Supēsu', 'ratio': 0.1}]",メトリック空間
2465,2855,micro-average,マイクロ平均,0.7,10,"[{'word': 'マイクロ平均', 'ratio': 0.7}, {'word': 'ミクロ平均', 'ratio': 0.2}, {'word': 'Maikuro Averiji', 'ratio': 0.1}]",マイクロ平均
2466,2856,microarray datum,マイクロアレイデータ,0.9,10,"[{'word': 'マイクロアレイデータ', 'ratio': 0.9}, {'word': '(Maikuro Yārei Jūtai', 'ratio': 0.1}]",マイクロアレイデータ
2467,2857,mini-batch,ミニバッチ,0.8888888888888888,9,"[{'word': 'ミニバッチ', 'ratio': 0.8888888888888888}, {'word': 'kohin-chu baichu', 'ratio': 0.1111111111111111}]",ミニバッチ
2468,2858,mini-batch size,ミニバッチサイズ,0.8888888888888888,9,"[{'word': 'ミニバッチサイズ', 'ratio': 0.8888888888888888}, {'word': 'kohin-chu saizu', 'ratio': 0.1111111111111111}]",ミニバッチサイズ
2469,2859,mini-batch training,ミニバッチ学習,0.1111111111111111,9,"[{'word': 'ミニバッチトレーニング', 'ratio': 0.7777777777777778}, {'word': 'ミニバッチ学習', 'ratio': 0.1111111111111111}, {'word': ', kohin-chu toraningu', 'ratio': 0.1111111111111111}]",ミニバッチトレーニング
2470,2861,minimax,最小最大,0.0,9,"[{'word': 'ミニマックス', 'ratio': 0.8888888888888888}, {'word': 'minima-maksima', 'ratio': 0.1111111111111111}]",ミニマックス
2471,2862,minimax game,ミニマックスゲーム,1.0,10,"[{'word': 'ミニマックスゲーム', 'ratio': 1.0}]",ミニマックスゲーム
2472,2863,minimax optimization problem,最小最大最適化問題,0.0,10,"[{'word': 'ミニマックス最適化問題', 'ratio': 0.8}, {'word': '最小最適化問題', 'ratio': 0.2}]",ミニマックス最適化問題
2473,2864,minimax problem,最小最大問題,0.0,10,"[{'word': 'ミニマックス問題', 'ratio': 0.8}, {'word': '最小公倍数問題', 'ratio': 0.2}]",ミニマックス問題
2474,2865,minimization problem,最小化問題,0.6,10,"[{'word': '最小化問題', 'ratio': 0.6}, {'word': '最適化問題', 'ratio': 0.4}]",最小化問題
2475,2867,minimum baye risk decoding,最小ベイズリスク復号化,0.0,9,"[{'word': '最小ベイズリスクデコーディング', 'ratio': 0.7777777777777778}, {'word': '最小ベイリスク解読', 'ratio': 0.1111111111111111}, {'word': '最小限のベイリスクデコード', 'ratio': 0.1111111111111111}]",最小ベイズリスクデコーディング
2476,2868,minimum cut,最小カット,0.8888888888888888,9,"[{'word': '最小カット', 'ratio': 0.8888888888888888}, {'word': 'ミニマムカット', 'ratio': 0.1111111111111111}]",最小カット
2477,2869,minimum description length,最小記述長,0.8888888888888888,9,"[{'word': '最小記述長', 'ratio': 0.8888888888888888}, {'word': '最小の説明長', 'ratio': 0.1111111111111111}]",最小記述長
2478,2870,minimum support,最小サポート,0.5555555555555556,9,"[{'word': '最小サポート', 'ratio': 0.5555555555555556}, {'word': '最小支持度', 'ratio': 0.2222222222222222}, {'word': 'ミニマムサポート', 'ratio': 0.1111111111111111}, {'word': '最低限のサポート', 'ratio': 0.1111111111111111}]",最小サポート
2479,2871,mirror descent,ミラーディセント,0.2222222222222222,9,"[{'word': 'ミラー降下', 'ratio': 0.5555555555555556}, {'word': 'ミラーディセント', 'ratio': 0.2222222222222222}, {'word': 'ミラー降下法', 'ratio': 0.2222222222222222}]",ミラー降下
2480,2872,misclassification error,誤分類エラー,0.2,10,"[{'word': '誤分類誤差', 'ratio': 0.8}, {'word': '誤分類エラー', 'ratio': 0.2}]",誤分類誤差
2481,2873,misclassification loss,誤分類損失,1.0,10,"[{'word': '誤分類損失', 'ratio': 1.0}]",誤分類損失
2482,2874,misinformation detection,偽情報検出,0.3,10,"[{'word': '誤情報検出', 'ratio': 0.5}, {'word': '偽情報検出', 'ratio': 0.3}, {'word': '誤った情報の検出', 'ratio': 0.1}, {'word': '誤報検出', 'ratio': 0.1}]",誤情報検出
2483,2875,mixed integer programming,"""混合整数計画法""",0.0,10,"[{'word': '混合整数計画法', 'ratio': 0.6}, {'word': '整数混合計画法', 'ratio': 0.2}, {'word': '混合整数プログラミング', 'ratio': 0.1}, {'word': '整数混合最適化', 'ratio': 0.1}]",混合整数計画法
2484,2876,mixed precision,混合精度,1.0,10,"[{'word': '混合精度', 'ratio': 1.0}]",混合精度
2485,2877,mixed precision training,混合精度トレーニング,1.0,10,"[{'word': '混合精度トレーニング', 'ratio': 1.0}]",混合精度トレーニング
2486,2878,mixed strategy,混合戦略,1.0,10,"[{'word': '混合戦略', 'ratio': 1.0}]",混合戦略
2487,2879,mixed-integer program,混合整数計画プログラム,0.0,10,"[{'word': '混合整数プログラム', 'ratio': 0.8}, {'word': '混合整数計画', 'ratio': 0.2}]",混合整数プログラム
2488,2880,mixing matrix,混合行列,0.9,10,"[{'word': '混合行列', 'ratio': 0.9}, {'word': '混合マトリックス', 'ratio': 0.1}]",混合行列
2489,2881,mixing time,混合時間,0.6,10,"[{'word': '混合時間', 'ratio': 0.6}, {'word': 'ミキシング時間', 'ratio': 0.3}, {'word': 'ミキシングタイム', 'ratio': 0.1}]",混合時間
2490,2882,mixing weight,混合重み,0.6,10,"[{'word': '混合重み', 'ratio': 0.6}, {'word': 'ミキシングウェイト', 'ratio': 0.3}, {'word': 'ミキシング重み', 'ratio': 0.1}]",混合重み
2491,2883,mixture component,混合成分,0.8,10,"[{'word': '混合成分', 'ratio': 0.8}, {'word': 'ミキサー成分', 'ratio': 0.1}, {'word': 'ミクスチャーコンポーネント', 'ratio': 0.1}]",混合成分
2492,2884,mixture distribution,混合分布,0.8,10,"[{'word': '混合分布', 'ratio': 0.8}, {'word': 'ミキシング分布', 'ratio': 0.1}, {'word': 'ミクスチャー分布', 'ratio': 0.1}]",混合分布
2493,2885,mixture model,混合モデル,0.8,10,"[{'word': '混合モデル', 'ratio': 0.8}, {'word': 'ミキシングモデル', 'ratio': 0.1}, {'word': 'ミクスチャーモデル', 'ratio': 0.1}]",混合モデル
2494,2887,mixture weight,混合重み,0.8,10,"[{'word': '混合重み', 'ratio': 0.8}, {'word': '混合重量', 'ratio': 0.2}]",混合重み
2495,2888,mocap,モーションキャプチャ,0.7,10,"[{'word': 'モーションキャプチャ', 'ratio': 0.7}, {'word': 'モカプ', 'ratio': 0.2}, {'word': 'モーションキャプチャー', 'ratio': 0.1}]",モーションキャプチャ
2496,2889,modality,モダリティ,1.0,10,"[{'word': 'モダリティ', 'ratio': 1.0}]",モダリティ
2497,2890,mode,モード,1.0,10,"[{'word': 'モード', 'ratio': 1.0}]",モード
2498,2891,mode collapse,モード崩壊,0.9,10,"[{'word': 'モード崩壊', 'ratio': 0.9}, {'word': 'モードカラム', 'ratio': 0.1}]",モード崩壊
2499,2892,model M,モデルM,0.3,10,"[{'word': 'モデル M', 'ratio': 0.7}, {'word': 'モデルM', 'ratio': 0.3}]",モデル M
2500,2893,model accuracy,モデルの精度,0.2,10,"[{'word': 'モデル精度', 'ratio': 0.8}, {'word': 'モデルの精度', 'ratio': 0.2}]",モデル精度
2501,2894,model architecture,モデルアーキテクチャ,0.9,10,"[{'word': 'モデルアーキテクチャ', 'ratio': 0.9}, {'word': 'モデル・アーキテクチャ', 'ratio': 0.1}]",モデルアーキテクチャ
2502,2895,model averaging,モデル平均化,0.9,10,"[{'word': 'モデル平均化', 'ratio': 0.9}, {'word': 'モデルの平均化', 'ratio': 0.1}]",モデル平均化
2503,2896,model bias,モデルバイアス,1.0,10,"[{'word': 'モデルバイアス', 'ratio': 1.0}]",モデルバイアス
2504,2897,model capacity,モデル容量,1.0,10,"[{'word': 'モデル容量', 'ratio': 1.0}]",モデル容量
2505,2898,model card,モデルカード,1.0,10,"[{'word': 'モデルカード', 'ratio': 1.0}]",モデルカード
2506,2899,model checking,モデル検査,0.6,10,"[{'word': 'モデル検査', 'ratio': 0.6}, {'word': 'モデルチェック', 'ratio': 0.3}, {'word': 'モデル検証', 'ratio': 0.1}]",モデル検査
2507,2900,model class,モデルクラス,1.0,9,"[{'word': 'モデルクラス', 'ratio': 1.0}]",モデルクラス
2508,2901,model comparison,モデル比較,0.8888888888888888,9,"[{'word': 'モデル比較', 'ratio': 0.8888888888888888}, {'word': 'モデルの比較', 'ratio': 0.1111111111111111}]",モデル比較
2509,2903,model compression,モデル圧縮,1.0,9,"[{'word': 'モデル圧縮', 'ratio': 1.0}]",モデル圧縮
2510,2904,model convergence,モデル収束,0.7777777777777778,9,"[{'word': 'モデル収束', 'ratio': 0.7777777777777778}, {'word': 'モデルの収束', 'ratio': 0.2222222222222222}]",モデル収束
2511,2905,model development,モデル開発,1.0,9,"[{'word': 'モデル開発', 'ratio': 1.0}]",モデル開発
2512,2906,model distillation,モデル蒸留,1.0,9,"[{'word': 'モデル蒸留', 'ratio': 1.0}]",モデル蒸留
2513,2907,model distribution,モデル分布,0.8888888888888888,9,"[{'word': 'モデル分布', 'ratio': 0.8888888888888888}, {'word': 'モデルの配布', 'ratio': 0.1111111111111111}]",モデル分布
2514,2908,model estimation,モデル推定,1.0,9,"[{'word': 'モデル推定', 'ratio': 1.0}]",モデル推定
2515,2909,model evaluation,モデル評価,0.8888888888888888,9,"[{'word': 'モデル評価', 'ratio': 0.8888888888888888}, {'word': 'モデルの評価', 'ratio': 0.1111111111111111}]",モデル評価
2516,2910,model family,モデルファミリー,1.0,10,"[{'word': 'モデルファミリー', 'ratio': 1.0}]",モデルファミリー
2517,2912,model generalization,モデルの一般化能力,0.0,10,"[{'word': 'モデルの一般化', 'ratio': 0.5}, {'word': 'モデル一般化', 'ratio': 0.4}, {'word': 'モデルの汎化', 'ratio': 0.1}]",モデルの一般化
2518,2913,model hyperparameter,モデルのハイパーパラメータ,0.4,10,"[{'word': 'モデルハイパーパラメータ', 'ratio': 0.6}, {'word': 'モデルのハイパーパラメータ', 'ratio': 0.4}]",モデルハイパーパラメータ
2519,2914,model inference,モデル推論,1.0,10,"[{'word': 'モデル推論', 'ratio': 1.0}]",モデル推論
2520,2915,model initialization,モデル初期化,0.7777777777777778,9,"[{'word': 'モデル初期化', 'ratio': 0.7777777777777778}, {'word': 'モデルの初期化', 'ratio': 0.2222222222222222}]",モデル初期化
2521,2917,model interpretation,モデル解釈,0.6666666666666666,9,"[{'word': 'モデル解釈', 'ratio': 0.6666666666666666}, {'word': 'モデルの解釈', 'ratio': 0.3333333333333333}]",モデル解釈
2522,2918,model layer,モデル層,0.6666666666666666,9,"[{'word': 'モデル層', 'ratio': 0.6666666666666666}, {'word': 'モデルレイヤー', 'ratio': 0.2222222222222222}, {'word': 'モデルの解釈', 'ratio': 0.1111111111111111}]",モデル層
2523,2919,model output,モデル出力,0.7777777777777778,9,"[{'word': 'モデル出力', 'ratio': 0.7777777777777778}, {'word': 'モデルの出力', 'ratio': 0.2222222222222222}]",モデル出力
2524,2920,model parallelism,モデル並列化,0.0,9,"[{'word': 'モデル並列性', 'ratio': 0.7777777777777778}, {'word': 'モデル並列処理', 'ratio': 0.1111111111111111}, {'word': 'モデルの並列性', 'ratio': 0.1111111111111111}]",モデル並列性
2525,2921,model parameter,モデルパラメータ,0.8888888888888888,9,"[{'word': 'モデルパラメータ', 'ratio': 0.8888888888888888}, {'word': 'モデルパラメーター', 'ratio': 0.1111111111111111}]",モデルパラメータ
2526,2922,model performance,モデルの性能,0.0,9,"[{'word': 'モデル性能', 'ratio': 0.7777777777777778}, {'word': '模範演技', 'ratio': 0.1111111111111111}, {'word': 'モデルのパフォーマンス', 'ratio': 0.1111111111111111}]",モデル性能
2527,2923,model precision,モデル精度,0.8888888888888888,9,"[{'word': 'モデル精度', 'ratio': 0.8888888888888888}, {'word': 'モデルの精度', 'ratio': 0.1111111111111111}]",モデル精度
2528,2924,model prediction,モデル予測,1.0,9,"[{'word': 'モデル予測', 'ratio': 1.0}]",モデル予測
2529,2925,model predictive control,モデル予測制御,1.0,10,"[{'word': 'モデル予測制御', 'ratio': 1.0}]",モデル予測制御
2530,2926,model representation,モデル表現,1.0,10,"[{'word': 'モデル表現', 'ratio': 1.0}]",モデル表現
2531,2927,model robustness,モデルの堅牢性,0.5,10,"[{'word': 'モデルの堅牢性', 'ratio': 0.5}, {'word': 'モデルの頑健性', 'ratio': 0.2}, {'word': 'モデルのロバスト性', 'ratio': 0.1}, {'word': 'モデルロバストネス', 'ratio': 0.1}, {'word': 'モデルロバスト性', 'ratio': 0.1}]",モデルの堅牢性
2532,2928,model score,モデルスコア,0.9,10,"[{'word': 'モデルスコア', 'ratio': 0.9}, {'word': 'モデルの頑健性', 'ratio': 0.1}]",モデルスコア
2533,2929,model selection,モデル選択,0.8,10,"[{'word': 'モデル選択', 'ratio': 0.8}, {'word': 'モデルの選択', 'ratio': 0.2}]",モデル選択
2534,2930,model size,モデルサイズ,1.0,10,"[{'word': 'モデルサイズ', 'ratio': 1.0}]",モデルサイズ
2535,2931,model specification,モデル仕様,1.0,10,"[{'word': 'モデル仕様', 'ratio': 1.0}]",モデル仕様
2536,2932,model structure,モデル構造,1.0,10,"[{'word': 'モデル構造', 'ratio': 1.0}]",モデル構造
2537,2933,model training,モデル学習,0.1,10,"[{'word': 'モデル訓練', 'ratio': 0.7}, {'word': 'モデルトレーニング', 'ratio': 0.2}, {'word': 'モデル学習', 'ratio': 0.1}]",モデル訓練
2538,2934,model update,モデル更新,0.8,10,"[{'word': 'モデル更新', 'ratio': 0.8}, {'word': 'モデル・アップデート', 'ratio': 0.1}, {'word': 'モデルのアップデート', 'ratio': 0.1}]",モデル更新
2539,2936,model weight,モデルの重み,0.6,10,"[{'word': 'モデルの重み', 'ratio': 0.6}, {'word': 'モデル重み', 'ratio': 0.2}, {'word': 'モデル重量', 'ratio': 0.1}, {'word': 'モデルの重量', 'ratio': 0.1}]",モデルの重み
2540,2937,model's parameter,モデルのパラメータ,1.0,10,"[{'word': 'モデルのパラメータ', 'ratio': 1.0}]",モデルのパラメータ
2541,2938,model-based approach,モデルベースのアプローチ,0.9,10,"[{'word': 'モデルベースのアプローチ', 'ratio': 0.9}, {'word': 'モデルベースアプローチ', 'ratio': 0.1}]",モデルベースのアプローチ
2542,2939,model-based reinforcement learning,モデルベースの強化学習,0.8,10,"[{'word': 'モデルベースの強化学習', 'ratio': 0.8}, {'word': 'モデルベース強化学習', 'ratio': 0.2}]",モデルベースの強化学習
2543,2940,model-free approach,モデルフリーアプローチ,0.7777777777777778,9,"[{'word': 'モデルフリーアプローチ', 'ratio': 0.7777777777777778}, {'word': 'モデルフリーのアプローチ', 'ratio': 0.1111111111111111}, {'word': 'Mōdorui-Furi Appurōchi', 'ratio': 0.1111111111111111}]",モデルフリーアプローチ
2544,2941,modular,モジュラー,0.7777777777777778,9,"[{'word': 'モジュラー', 'ratio': 0.7777777777777778}, {'word': 'モジュラ', 'ratio': 0.1111111111111111}, {'word': 'Mōdoruaru', 'ratio': 0.1111111111111111}]",モジュラー
2545,2942,modular architecture,モジュラーアーキテクチャ,0.7777777777777778,9,"[{'word': 'モジュラーアーキテクチャ', 'ratio': 0.7777777777777778}, {'word': 'モジュール式アーキテクチャ', 'ratio': 0.1111111111111111}, {'word': 'Mōdoruaru Kōsō', 'ratio': 0.1111111111111111}]",モジュラーアーキテクチャ
2546,2943,module,モジュール,0.8888888888888888,9,"[{'word': 'モジュール', 'ratio': 0.8888888888888888}, {'word': 'Mōdoru', 'ratio': 0.1111111111111111}]",モジュール
2547,2944,moment matching,モーメントマッチング,1.0,10,"[{'word': 'モーメントマッチング', 'ratio': 1.0}]",モーメントマッチング
2548,2945,momentum,モメンタム,0.2,10,"[{'word': 'モーメンタム', 'ratio': 0.8}, {'word': 'モメンタム', 'ratio': 0.2}]",モーメンタム
2549,2949,monocular,単眼,0.6666666666666666,9,"[{'word': '単眼', 'ratio': 0.6666666666666666}, {'word': '単眼の', 'ratio': 0.2222222222222222}, {'word': 'モノキュラー', 'ratio': 0.1111111111111111}]",単眼
2550,2950,monocular reconstruction,単眼再構成,0.7777777777777778,9,"[{'word': '単眼再構成', 'ratio': 0.7777777777777778}, {'word': 'モノキュラー再構成', 'ratio': 0.1111111111111111}, {'word': '単眼再構築', 'ratio': 0.1111111111111111}]",単眼再構成
2551,2951,monolingual baseline,単言語ベースライン,0.6666666666666666,9,"[{'word': '単言語ベースライン', 'ratio': 0.6666666666666666}, {'word': 'モノリンガルベースライン', 'ratio': 0.2222222222222222}, {'word': '単一言語ベースライン', 'ratio': 0.1111111111111111}]",単言語ベースライン
2552,2952,monolingual corpora,単言語コーパス,0.6666666666666666,9,"[{'word': '単言語コーパス', 'ratio': 0.6666666666666666}, {'word': '単一言語コーパス', 'ratio': 0.2222222222222222}, {'word': 'モノリンガルコーパス', 'ratio': 0.1111111111111111}]",単言語コーパス
2553,2953,monolingual corpus,単言語コーパス,0.5,10,"[{'word': '単言語コーパス', 'ratio': 0.5}, {'word': '単一言語コーパス', 'ratio': 0.2}, {'word': 'モノリンガルコーパス', 'ratio': 0.2}, {'word': '一言語コーパス', 'ratio': 0.1}]",単言語コーパス
2554,2954,monolingual dataset,単一言語データセット,0.1,10,"[{'word': '単言語データセット', 'ratio': 0.5}, {'word': 'モノリンガルデータセット', 'ratio': 0.3}, {'word': '単一言語データセット', 'ratio': 0.1}, {'word': '一言語データセット', 'ratio': 0.1}]",単言語データセット
2555,2955,monolingual datum,単一言語データ,0.2,10,"[{'word': '単言語データ', 'ratio': 0.5}, {'word': '単一言語データ', 'ratio': 0.2}, {'word': 'モノリンガルデータ', 'ratio': 0.2}, {'word': '一言語データ', 'ratio': 0.1}]",単言語データ
2556,2956,monolingual embedding,単言語埋め込み,0.5,10,"[{'word': '単言語埋め込み', 'ratio': 0.5}, {'word': 'モノリンガル埋め込み', 'ratio': 0.2}, {'word': '単一言語の埋め込み', 'ratio': 0.1}, {'word': 'モノリンガルエンベッディング', 'ratio': 0.1}, {'word': '一言語Embedding', 'ratio': 0.1}]",単言語埋め込み
2557,2957,monolingual model,単言語モデル,0.5,10,"[{'word': '単言語モデル', 'ratio': 0.5}, {'word': 'モノリンガルモデル', 'ratio': 0.3}, {'word': '単一言語モデル', 'ratio': 0.1}, {'word': '一言語モデルの', 'ratio': 0.1}]",単言語モデル
2558,2959,monotone,単調増加,0.0,10,"[{'word': '単調', 'ratio': 0.8}, {'word': 'モノトーン', 'ratio': 0.2}]",単調
2559,2961,morphological analysis,形態素解析,0.9,10,"[{'word': '形態素解析', 'ratio': 0.9}, {'word': '形態学的分析', 'ratio': 0.1}]",形態素解析
2560,2962,morphological analyzer,形態素解析器,0.6,10,"[{'word': '形態素解析器', 'ratio': 0.6}, {'word': '形態素アナライザー', 'ratio': 0.4}]",形態素解析器
2561,2964,morphological information,形態論的情報,0.0,10,"[{'word': '形態素情報', 'ratio': 0.8}, {'word': '形態学的情報', 'ratio': 0.1}, {'word': '形態情報', 'ratio': 0.1}]",形態素情報
2562,2965,morphological operation,形態学的演算,0.0,10,"[{'word': '形態素操作', 'ratio': 0.8}, {'word': '形態論的操作', 'ratio': 0.1}, {'word': '形態学的操作', 'ratio': 0.1}]",形態素操作
2563,2966,morphological segmentation,形態素分割,0.3,10,"[{'word': '形態素セグメンテーション', 'ratio': 0.5}, {'word': '形態素分割', 'ratio': 0.3}, {'word': '形態論的セグメンテーション', 'ratio': 0.2}]",形態素セグメンテーション
2564,2967,morphology,形態論,0.2,10,"[{'word': '形態学', 'ratio': 0.7}, {'word': '形態論', 'ratio': 0.2}, {'word': '形態', 'ratio': 0.1}]",形態学
2565,2968,motion analysis,動作解析,0.2,10,"[{'word': '運動解析', 'ratio': 0.5}, {'word': '動作分析', 'ratio': 0.2}, {'word': '動作解析', 'ratio': 0.2}, {'word': '動きの解析', 'ratio': 0.1}]",運動解析
2566,2969,motion estimation,動き推定,0.0,10,"[{'word': '動作推定', 'ratio': 0.6}, {'word': '運動推定', 'ratio': 0.3}, {'word': '動きの推定', 'ratio': 0.1}]",動作推定
2567,2973,moving average,移動平均,0.8888888888888888,9,"[{'word': '移動平均', 'ratio': 0.8888888888888888}, {'word': 'izzu furikei', 'ratio': 0.1111111111111111}]",移動平均
2568,2974,multi-agent,複数エージェント,0.0,10,"[{'word': 'マルチエージェント', 'ratio': 1.0}]",マルチエージェント
2569,2975,multi-agent interaction,マルチエージェント相互作用,0.5,10,"[{'word': 'マルチエージェント相互作用', 'ratio': 0.5}, {'word': 'マルチエージェントインタラクション', 'ratio': 0.2}, {'word': 'ルチエージェント相互作用', 'ratio': 0.1}, {'word': 'マルチエージェントのインタラクション', 'ratio': 0.1}, {'word': 'マルチエージェント間相互作用', 'ratio': 0.1}]",マルチエージェント相互作用
2570,2976,multi-agent learning,多エージェント学習,0.0,10,"[{'word': 'マルチエージェント学習', 'ratio': 1.0}]",マルチエージェント学習
2571,2977,multi-agent reinforcement learning,多エージェント強化学習,0.0,10,"[{'word': 'マルチエージェント強化学習', 'ratio': 1.0}]",マルチエージェント強化学習
2572,2978,multi-agent system,マルチエージェントシステム,0.9,10,"[{'word': 'マルチエージェントシステム', 'ratio': 0.9}, {'word': 'マルチエージェント系', 'ratio': 0.1}]",マルチエージェントシステム
2573,2979,multi-armed bandit,多腕バンディット,0.2,10,"[{'word': 'マルチアームバンディット', 'ratio': 0.6}, {'word': '多腕バンディット', 'ratio': 0.2}, {'word': '多腕賊', 'ratio': 0.1}, {'word': '多腕の盗賊', 'ratio': 0.1}]",マルチアームバンディット
2574,2980,multi-armed bandit problem,多腕バンディット問題,0.3,10,"[{'word': 'マルチアームバンディット問題', 'ratio': 0.6}, {'word': '多腕バンディット問題', 'ratio': 0.3}, {'word': '多腕盗賊問題', 'ratio': 0.1}]",マルチアームバンディット問題
2575,2981,multi-class,多クラス,0.1,10,"[{'word': 'マルチクラス', 'ratio': 0.9}, {'word': '多クラス', 'ratio': 0.1}]",マルチクラス
2576,2982,multi-class classification,多クラス分類,0.1,10,"[{'word': 'マルチクラス分類', 'ratio': 0.9}, {'word': '多クラス分類', 'ratio': 0.1}]",マルチクラス分類
2577,2983,multi-class logistic regression,マルチクラスロジスティック回帰,0.7,10,"[{'word': 'マルチクラスロジスティック回帰', 'ratio': 0.7}, {'word': 'マルチクラス・ロジスティック回帰', 'ratio': 0.1}, {'word': '多クラスロジスティック回帰', 'ratio': 0.1}, {'word': '複数クラスのロジスティック回帰', 'ratio': 0.1}]",マルチクラスロジスティック回帰
2578,2984,multi-class problem,多クラス問題,0.8,10,"[{'word': '多クラス問題', 'ratio': 0.8}, {'word': 'マルチクラス問題', 'ratio': 0.2}]",多クラス問題
2579,2985,multi-classification,多クラス分類,0.6,10,"[{'word': '多クラス分類', 'ratio': 0.6}, {'word': 'マルチ分類', 'ratio': 0.2}, {'word': '多重分類', 'ratio': 0.2}]",多クラス分類
2580,2986,multi-document summarization,多文書要約,0.5,10,"[{'word': '多文書要約', 'ratio': 0.5}, {'word': 'マルチドキュメント要約', 'ratio': 0.2}, {'word': '複数文書の要約', 'ratio': 0.2}, {'word': '複数文書要約', 'ratio': 0.1}]",多文書要約
2581,2988,multi-head,複数ヘッド,0.0,10,"[{'word': 'マルチヘッド', 'ratio': 0.9}, {'word': 'ルチヘッド', 'ratio': 0.1}]",マルチヘッド
2582,2989,multi-head attention,マルチヘッドアテンション,0.7777777777777778,9,"[{'word': 'マルチヘッドアテンション', 'ratio': 0.7777777777777778}, {'word': '多頭注意', 'ratio': 0.2222222222222222}]",マルチヘッドアテンション
2583,2990,multi-head attention layer,多頭注目層,0.0,9,"[{'word': 'マルチヘッドアテンション層', 'ratio': 0.6666666666666666}, {'word': 'マルチヘッド・アテンション・レイヤー', 'ratio': 0.1111111111111111}, {'word': 'マルチヘッドアテンションレイヤー', 'ratio': 0.1111111111111111}, {'word': '多頭注意レイヤー', 'ratio': 0.1111111111111111}]",マルチヘッドアテンション層
2584,2994,multi-headed self-attention,マルチヘッドセルフアテンション,0.0,10,"[{'word': 'マルチヘッド自己注意', 'ratio': 0.6}, {'word': '多頭自戒', 'ratio': 0.1}, {'word': '多頭自己注意機構', 'ratio': 0.1}, {'word': '多頭の自己注意', 'ratio': 0.1}, {'word': 'Jibun Shu no Jiteki Chūkan', 'ratio': 0.1}]",マルチヘッド自己注意
2585,2995,multi-label,複数ラベル,0.0,10,"[{'word': 'マルチラベル', 'ratio': 0.9}, {'word': 'Tappu Ruiebu', 'ratio': 0.1}]",マルチラベル
2586,2996,multi-label classification,多ラベル分類,0.0,10,"[{'word': 'マルチラベル分類', 'ratio': 0.9}, {'word': 'Tappu Ruiebu Bunseki', 'ratio': 0.1}]",マルチラベル分類
2587,2997,multi-label classification loss,多ラベル分類損失,0.0,10,"[{'word': 'マルチラベル分類損失', 'ratio': 0.7}, {'word': 'マルチラベル分類ロス', 'ratio': 0.1}, {'word': 'マルチラベル分類の損失', 'ratio': 0.1}, {'word': 'Tappu Ruiebu Bunseki Riseru', 'ratio': 0.1}]",マルチラベル分類損失
2588,2998,multi-label classifier,マルチラベル分類器,0.8,10,"[{'word': 'マルチラベル分類器', 'ratio': 0.8}, {'word': 'マルチラベル分類子', 'ratio': 0.1}, {'word': 'Tappu Ruiebu Bunseki Kari', 'ratio': 0.1}]",マルチラベル分類器
2589,2999,multi-label datum,マルチラベルデータ,0.6,10,"[{'word': 'マルチラベルデータ', 'ratio': 0.6}, {'word': 'マルチラベル・データム', 'ratio': 0.1}, {'word': 'マルチラベルデータム', 'ratio': 0.1}, {'word': 'マルチラベル データ', 'ratio': 0.1}, {'word': '多ラベルデータ', 'ratio': 0.1}]",マルチラベルデータ
2590,3000,multi-label learning,多ラベル学習,0.1,10,"[{'word': 'マルチラベル学習', 'ratio': 0.8}, {'word': 'マルチラベル 学習', 'ratio': 0.1}, {'word': '多ラベル学習', 'ratio': 0.1}]",マルチラベル学習
2591,3001,multi-label text classification,多ラベルテキスト分類,0.1,10,"[{'word': 'マルチラベルテキスト分類', 'ratio': 0.7}, {'word': '複数ラベルのテキスト分類', 'ratio': 0.1}, {'word': 'マルチラベル テキスト分類', 'ratio': 0.1}, {'word': '多ラベルテキスト分類', 'ratio': 0.1}]",マルチラベルテキスト分類
2592,3002,multi-layer neural network,多層ニューラルネットワーク,0.8,10,"[{'word': '多層ニューラルネットワーク', 'ratio': 0.8}, {'word': '多層神経ネットワーク', 'ratio': 0.1}, {'word': 'マルチレイヤーニューラルネットワーク', 'ratio': 0.1}]",多層ニューラルネットワーク
2593,3003,multi-layer perceptron,多層パーセプトロン,0.9,10,"[{'word': '多層パーセプトロン', 'ratio': 0.9}, {'word': 'マルチレイヤーパセプトロン', 'ratio': 0.1}]",多層パーセプトロン
2594,3004,multi-modal,マルチモーダル,1.0,9,"[{'word': 'マルチモーダル', 'ratio': 1.0}]",マルチモーダル
2595,3005,multi-modal input,マルチモーダル入力,1.0,9,"[{'word': 'マルチモーダル入力', 'ratio': 1.0}]",マルチモーダル入力
2596,3006,multi-modal learning,多モダル学習,0.0,9,"[{'word': 'マルチモーダル学習', 'ratio': 1.0}]",マルチモーダル学習
2597,3007,multi-modal model,多様なモダリティを統合したモデル,0.0,9,"[{'word': 'マルチモーダルモデル', 'ratio': 1.0}]",マルチモーダルモデル
2598,3008,multi-object detection,多物体検出,0.0,9,"[{'word': 'マルチオブジェクト検出', 'ratio': 0.7777777777777778}, {'word': '複数の物体の検出', 'ratio': 0.2222222222222222}]",マルチオブジェクト検出
2599,3009,multi-objective optimization,多目的最適化,0.8,10,"[{'word': '多目的最適化', 'ratio': 0.8}, {'word': '複数目的最適化', 'ratio': 0.1}, {'word': 'マルチオブジェクト最適化', 'ratio': 0.1}]",多目的最適化
2600,3010,multi-scale,多スケール,0.1,10,"[{'word': 'マルチスケール', 'ratio': 0.9}, {'word': '多スケール', 'ratio': 0.1}]",マルチスケール
2601,3011,multi-scale architecture,マルチスケールアーキテクチャ,0.9,10,"[{'word': 'マルチスケールアーキテクチャ', 'ratio': 0.9}, {'word': '多スケールアーキテクチャ', 'ratio': 0.1}]",マルチスケールアーキテクチャ
2602,3012,multi-scale training,多尺度学習,0.0,10,"[{'word': 'マルチスケールトレーニング', 'ratio': 0.7}, {'word': 'マルチスケール訓練', 'ratio': 0.2}, {'word': '多スケールトレーニング', 'ratio': 0.1}]",マルチスケールトレーニング
2603,3013,multi-task,マルチタスク,1.0,10,"[{'word': 'マルチタスク', 'ratio': 1.0}]",マルチタスク
2604,3014,multi-task fine-tuning,複数タスク微調整,0.0,10,"[{'word': 'マルチタスク微調整', 'ratio': 0.7}, {'word': 'マルチタスクファインチューニング', 'ratio': 0.2}, {'word': 'マルチタスクの微調整', 'ratio': 0.1}]",マルチタスク微調整
2605,3015,multi-task model,複数タスクモデル,0.0,10,"[{'word': 'マルチタスクモデル', 'ratio': 1.0}]",マルチタスクモデル
2606,3016,multi-task regression,多タスク回帰,0.0,10,"[{'word': 'マルチタスク回帰', 'ratio': 1.0}]",マルチタスク回帰
2607,3017,multi-task setting,複数タスク設定,0.0,10,"[{'word': 'マルチタスク設定', 'ratio': 1.0}]",マルチタスク設定
2608,3018,multi-view,複数の視点,0.0,10,"[{'word': 'マルチビュー', 'ratio': 1.0}]",マルチビュー
2609,3021,multi-view learning,マルチビューラーニング,0.0,10,"[{'word': 'マルチビュー学習', 'ratio': 0.9}, {'word': 'マルチビュー・ラーニング', 'ratio': 0.1}]",マルチビュー学習
2610,3022,multi-view stereo,複数視点ステレオ,0.0,10,"[{'word': 'マルチビュー・ステレオ', 'ratio': 0.5}, {'word': 'マルチビュー立体視', 'ratio': 0.2}, {'word': 'マルチビューステレオ', 'ratio': 0.2}, {'word': 'マルチビュー ステレオ', 'ratio': 0.1}]",マルチビュー・ステレオ
2611,3023,multi-view system,多視点システム,0.0,10,"[{'word': 'マルチビューシステム', 'ratio': 0.6}, {'word': 'マルチビューモデル', 'ratio': 0.2}, {'word': 'マルチビュー・システム', 'ratio': 0.1}, {'word': 'マルチビュー システム', 'ratio': 0.1}]",マルチビューシステム
2612,3024,multiclass classifier,多クラス分類器,0.3,10,"[{'word': 'マルチクラス分類器', 'ratio': 0.5}, {'word': '多クラス分類器', 'ratio': 0.3}, {'word': 'マルチクラス分類子', 'ratio': 0.2}]",マルチクラス分類器
2613,3025,multiclass hinge loss,多クラスヒンジロス,0.0,10,"[{'word': 'マルチクラスヒンジ損失', 'ratio': 0.7}, {'word': '多クラスヒンジ損失', 'ratio': 0.3}]",マルチクラスヒンジ損失
2614,3026,multiclass model,マルチクラスモデル,0.7,10,"[{'word': 'マルチクラスモデル', 'ratio': 0.7}, {'word': '多クラスモデル', 'ratio': 0.3}]",マルチクラスモデル
2615,3028,multilingual embedding,多言語埋め込み,0.7777777777777778,9,"[{'word': '多言語埋め込み', 'ratio': 0.7777777777777778}, {'word': 'テンソル因数分解', 'ratio': 0.1111111111111111}, {'word': '多言語エンベッディング', 'ratio': 0.1111111111111111}]",多言語埋め込み
2616,3029,multilingual language model,多言語言語モデル,0.2222222222222222,9,"[{'word': '多言語モデル', 'ratio': 0.7777777777777778}, {'word': '多言語言語モデル', 'ratio': 0.2222222222222222}]",多言語モデル
2617,3030,multilingual model,多言語モデル,1.0,9,"[{'word': '多言語モデル', 'ratio': 1.0}]",多言語モデル
2618,3031,multilingual representation,多言語表現,1.0,9,"[{'word': '多言語表現', 'ratio': 1.0}]",多言語表現
2619,3032,multilingual training,多言語トレーニング,0.6666666666666666,9,"[{'word': '多言語トレーニング', 'ratio': 0.6666666666666666}, {'word': '多言語訓練', 'ratio': 0.2222222222222222}, {'word': '多言語研修', 'ratio': 0.1111111111111111}]",多言語トレーニング
2620,3033,multilinguality,多言語性,1.0,10,"[{'word': '多言語性', 'ratio': 1.0}]",多言語性
2621,3034,multimodal task,マルチモーダルタスク,0.6,10,"[{'word': 'マルチモーダルタスク', 'ratio': 0.6}, {'word': 'マルチモーダル課題', 'ratio': 0.2}, {'word': '複数モードタスク', 'ratio': 0.1}, {'word': '多モーダルタスク', 'ratio': 0.1}]",マルチモーダルタスク
2622,3035,multinomial distribution,多項分布,1.0,10,"[{'word': '多項分布', 'ratio': 1.0}]",多項分布
2623,3036,multinomial model,多項モデル,1.0,10,"[{'word': '多項モデル', 'ratio': 1.0}]",多項モデル
2624,3039,multiscale modeling,多重スケールモデリング,0.0,9,"[{'word': 'マルチスケールモデリング', 'ratio': 1.0}]",マルチスケールモデリング
2625,3040,multiset,多重集合,0.5555555555555556,9,"[{'word': '多重集合', 'ratio': 0.5555555555555556}, {'word': 'マルチセット', 'ratio': 0.3333333333333333}, {'word': '多集合', 'ratio': 0.1111111111111111}]",多重集合
2626,3041,multitask training,複数タスク学習,0.0,9,"[{'word': 'マルチタスクトレーニング', 'ratio': 0.5555555555555556}, {'word': 'マルチタスク学習', 'ratio': 0.3333333333333333}, {'word': 'マルチタスク訓練', 'ratio': 0.1111111111111111}]",マルチタスクトレーニング
2627,3042,multivariate,多変量,1.0,9,"[{'word': '多変量', 'ratio': 1.0}]",多変量
2628,3043,multivariate Gaussian,多変量ガウス分布,0.4444444444444444,9,"[{'word': '多変量ガウス', 'ratio': 0.5555555555555556}, {'word': '多変量ガウス分布', 'ratio': 0.4444444444444444}]",多変量ガウス
2629,3044,multivariate Gaussian distribution,多変量ガウス分布,1.0,9,"[{'word': '多変量ガウス分布', 'ratio': 1.0}]",多変量ガウス分布
2630,3045,multivariate normal,多変量正規分布,0.5555555555555556,9,"[{'word': '多変量正規分布', 'ratio': 0.5555555555555556}, {'word': '多変量正規', 'ratio': 0.4444444444444444}]",多変量正規分布
2631,3046,multivariate normal distribution,多変量正規分布,1.0,9,"[{'word': '多変量正規分布', 'ratio': 1.0}]",多変量正規分布
2632,3047,multivariate time series,多変量時系列,1.0,9,"[{'word': '多変量時系列', 'ratio': 1.0}]",多変量時系列
2633,3048,mutex,相互排他ロック,0.0,9,"[{'word': 'ミューテックス', 'ratio': 1.0}]",ミューテックス
2634,3049,mutexe,相互排他ロック,0.0,9,"[{'word': 'ミューテックス', 'ratio': 0.8888888888888888}, {'word': 'タクシーの中で', 'ratio': 0.1111111111111111}]",ミューテックス
2635,3050,mutual entropy,相互エントロピー,1.0,9,"[{'word': '相互エントロピー', 'ratio': 1.0}]",相互エントロピー
2636,3052,n-gram feature,n-gramフィーチャ,0.0,10,"[{'word': 'n-グラム特徴', 'ratio': 0.8}, {'word': 'n-gram特徴', 'ratio': 0.1}, {'word': 'Nグラム機能', 'ratio': 0.1}]",n-グラム特徴
2637,3053,n-gram language model,n-gram言語モデル,0.1,10,"[{'word': 'n-グラム言語モデル', 'ratio': 0.8}, {'word': 'n-gram言語モデル', 'ratio': 0.1}, {'word': 'N-gram言語モデル', 'ratio': 0.1}]",n-グラム言語モデル
2638,3054,n-gram model,n-gramモデル,0.1,10,"[{'word': 'n-グラムモデル', 'ratio': 0.8}, {'word': 'n-gramモデル', 'ratio': 0.1}, {'word': 'Nグラムモデル', 'ratio': 0.1}]",n-グラムモデル
2639,3055,n-step returns,nステップリターン,0.7,10,"[{'word': 'nステップリターン', 'ratio': 0.7}, {'word': 'n-ステップリターン', 'ratio': 0.2}, {'word': 'n-ステップ報酬', 'ratio': 0.1}]",nステップリターン
2640,3056,naive Bayes model,単純ベイズモデル,0.1,10,"[{'word': 'ナイーブベイズモデル', 'ratio': 0.9}, {'word': '単純ベイズモデル', 'ratio': 0.1}]",ナイーブベイズモデル
2641,3057,named entity,固有名詞,0.0,10,"[{'word': '名前付きエンティティ', 'ratio': 0.5}, {'word': '固有表現', 'ratio': 0.3}, {'word': '名前付き実体', 'ratio': 0.2}]",名前付きエンティティ
2642,3058,named entity recognizer,固有名詞認識器,0.0,10,"[{'word': '名前付きエンティティ認識器', 'ratio': 0.5}, {'word': '固有表現認識器', 'ratio': 0.3}, {'word': '名前指定実体認識器', 'ratio': 0.2}]",名前付きエンティティ認識器
2643,3059,natural image statistic,自然画像統計,1.0,10,"[{'word': '自然画像統計', 'ratio': 1.0}]",自然画像統計
2644,3060,natural language,自然言語,1.0,10,"[{'word': '自然言語', 'ratio': 1.0}]",自然言語
2645,3061,natural language query,自然言語クエリ,1.0,10,"[{'word': '自然言語クエリ', 'ratio': 1.0}]",自然言語クエリ
2646,3062,natural logic,自然論理,0.8,10,"[{'word': '自然論理', 'ratio': 0.8}, {'word': 'しぜんろんりがく', 'ratio': 0.1}, {'word': '自然な論理', 'ratio': 0.1}]",自然論理
2647,3063,natural logic inference,自然論理推論,1.0,10,"[{'word': '自然論理推論', 'ratio': 1.0}]",自然論理推論
2648,3064,natural parameter,自然母数,0.0,9,"[{'word': '自然パラメータ', 'ratio': 0.7777777777777778}, {'word': 'ナチュラルパラメーター', 'ratio': 0.2222222222222222}]",自然パラメータ
2649,3065,near-optimality,最適に近い,0.2222222222222222,9,"[{'word': '近似最適性', 'ratio': 0.7777777777777778}, {'word': '最適に近い', 'ratio': 0.2222222222222222}]",近似最適性
2650,3066,nearest neighbor classifier,最近傍分類器,1.0,9,"[{'word': '最近傍分類器', 'ratio': 1.0}]",最近傍分類器
2651,3067,nearest neighbor search,最近傍探索,1.0,9,"[{'word': '最近傍探索', 'ratio': 1.0}]",最近傍探索
2652,3068,nearest-neighbor algorithm,最近傍アルゴリズム,1.0,9,"[{'word': '最近傍アルゴリズム', 'ratio': 1.0}]",最近傍アルゴリズム
2653,3069,negation,否定,1.0,10,"[{'word': '否定', 'ratio': 1.0}]",否定
2654,3070,negative log-likelihood,負の対数尤度,0.9,10,"[{'word': '負の対数尤度', 'ratio': 0.9}, {'word': 'ネガティブログライクリア', 'ratio': 0.1}]",負の対数尤度
2655,3071,negative pair,ネガティブペア,0.2,10,"[{'word': '負のペア', 'ratio': 0.5}, {'word': 'ネガティブペア', 'ratio': 0.2}, {'word': 'マイナスペア', 'ratio': 0.2}, {'word': 'ネガティブなペア', 'ratio': 0.1}]",負のペア
2656,3072,negative sample,負例,0.0,10,"[{'word': 'ネガティブサンプル', 'ratio': 0.5}, {'word': '負のサンプル', 'ratio': 0.5}]",ネガティブサンプル
2657,3073,negative transfer,負の転移,0.1,10,"[{'word': '負の転送', 'ratio': 0.5}, {'word': 'ネガティブ転送', 'ratio': 0.2}, {'word': 'ネガティブトランスファー', 'ratio': 0.1}, {'word': 'ネガティブ転移', 'ratio': 0.1}, {'word': '負の転移', 'ratio': 0.1}]",負の転送
2658,3074,neighborhood function,近傍関数,0.2,10,"[{'word': '隣接関数', 'ratio': 0.5}, {'word': '近隣関数', 'ratio': 0.2}, {'word': '近傍関数', 'ratio': 0.2}, {'word': '地域関数', 'ratio': 0.1}]",隣接関数
2659,3076,net,ネット,1.0,10,"[{'word': 'ネット', 'ratio': 1.0}]",ネット
2660,3077,network,ネットワーク,1.0,10,"[{'word': 'ネットワーク', 'ratio': 1.0}]",ネットワーク
2661,3078,network architecture,ネットワークアーキテクチャ,1.0,10,"[{'word': 'ネットワークアーキテクチャ', 'ratio': 1.0}]",ネットワークアーキテクチャ
2662,3080,network parameter,ネットワークパラメータ,0.8888888888888888,9,"[{'word': 'ネットワークパラメータ', 'ratio': 0.8888888888888888}, {'word': 'ネットワークのパラメーター', 'ratio': 0.1111111111111111}]",ネットワークパラメータ
2663,3081,network structure,ネットワーク構造,0.8888888888888888,9,"[{'word': 'ネットワーク構造', 'ratio': 0.8888888888888888}, {'word': 'ネットワークの構造', 'ratio': 0.1111111111111111}]",ネットワーク構造
2664,3082,network topology,ネットワークトポロジー,0.7777777777777778,9,"[{'word': 'ネットワークトポロジー', 'ratio': 0.7777777777777778}, {'word': 'ネットワーク・トポロジー', 'ratio': 0.1111111111111111}, {'word': 'ネットワークのトポロジー', 'ratio': 0.1111111111111111}]",ネットワークトポロジー
2665,3083,network weight,ネットワーク重み,0.6666666666666666,9,"[{'word': 'ネットワーク重み', 'ratio': 0.6666666666666666}, {'word': 'ネットワークの重み', 'ratio': 0.2222222222222222}, {'word': 'ネットワークウェイト', 'ratio': 0.1111111111111111}]",ネットワーク重み
2666,3084,neural activity,神経活動,1.0,10,"[{'word': '神経活動', 'ratio': 1.0}]",神経活動
2667,3086,neural architecture,ニューラルアーキテクチャ,0.5,10,"[{'word': 'ニューラルアーキテクチャ', 'ratio': 0.5}, {'word': '神経アーキテクチャ', 'ratio': 0.2}, {'word': '神経構造', 'ratio': 0.2}, {'word': 'ニューラル・アーキテクチャ', 'ratio': 0.1}]",ニューラルアーキテクチャ
2668,3088,neural embedding,神経埋め込み,0.0,10,"[{'word': 'ニューラル埋め込み', 'ratio': 0.7}, {'word': 'ニューラル・エンベッディング', 'ratio': 0.2}, {'word': 'ニューラルエンコーディング', 'ratio': 0.1}]",ニューラル埋め込み
2669,3089,neural generation model,ニューラル生成モデル (nyu-ralu seisei moderu),0.0,10,"[{'word': 'ニューラル生成モデル', 'ratio': 0.8}, {'word': '神経生成モデル', 'ratio': 0.2}]",ニューラル生成モデル
2670,3090,neural implicit representation,神経内在表現,0.0,10,"[{'word': 'ニューラル暗黙的表現', 'ratio': 0.5}, {'word': 'ニューラル暗黙表現', 'ratio': 0.3}, {'word': '神経暗黙表現', 'ratio': 0.2}]",ニューラル暗黙的表現
2671,3091,neural language model,ニューラル言語モデル,1.0,10,"[{'word': 'ニューラル言語モデル', 'ratio': 1.0}]",ニューラル言語モデル
2672,3092,neural machinery,ニューラル機構,0.7,10,"[{'word': 'ニューラル機構', 'ratio': 0.7}, {'word': 'ニューラル・マシナリー', 'ratio': 0.2}, {'word': 'ニューラル機械', 'ratio': 0.1}]",ニューラル機構
2673,3093,neural mapping,神経マッピング,0.0,10,"[{'word': 'ニューラルマッピング', 'ratio': 0.8}, {'word': '神経写像', 'ratio': 0.2}]",ニューラルマッピング
2674,3094,neural method,ニューラル手法,0.3,10,"[{'word': 'ニューラルメソッド', 'ratio': 0.5}, {'word': 'ニューラル手法', 'ratio': 0.3}, {'word': 'ニューラル方式', 'ratio': 0.2}]",ニューラルメソッド
2675,3095,neural model,ニューラルモデル,0.8,10,"[{'word': 'ニューラルモデル', 'ratio': 0.8}, {'word': 'ニューラル・モデル', 'ratio': 0.2}]",ニューラルモデル
2676,3096,neural module,神経モジュール,0.0,10,"[{'word': 'ニューラルモジュール', 'ratio': 0.8}, {'word': 'ニューラル・モジュール', 'ratio': 0.2}]",ニューラルモジュール
2677,3097,neural net,ニューラルネット,1.0,10,"[{'word': 'ニューラルネット', 'ratio': 1.0}]",ニューラルネット
2678,3098,neural network architecture,神経ネットワーク アーキテクチャ,0.0,10,"[{'word': 'ニューラルネットワークアーキテクチャ', 'ratio': 1.0}]",ニューラルネットワークアーキテクチャ
2679,3099,neural network classifier,ニューラルネットワーク分類器,1.0,10,"[{'word': 'ニューラルネットワーク分類器', 'ratio': 1.0}]",ニューラルネットワーク分類器
2680,3100,neural network language model,神経網言語モデル,0.0,10,"[{'word': 'ニューラルネットワーク言語モデル', 'ratio': 1.0}]",ニューラルネットワーク言語モデル
2681,3101,neural network layer,ニューラルネットワーク層,0.9,10,"[{'word': 'ニューラルネットワーク層', 'ratio': 0.9}, {'word': 'ニューラルネットワークレイヤー', 'ratio': 0.1}]",ニューラルネットワーク層
2682,3102,neural network model,神経ネットワークモデル,0.0,10,"[{'word': 'ニューラルネットワークモデル', 'ratio': 1.0}]",ニューラルネットワークモデル
2683,3103,neural operator,ニューラル演算子,0.1,10,"[{'word': 'ニューラルオペレーター', 'ratio': 0.7}, {'word': '神経演算子', 'ratio': 0.2}, {'word': 'ニューラル演算子', 'ratio': 0.1}]",ニューラルオペレーター
2684,3104,neural parser,神経パーサー,0.0,10,"[{'word': 'ニューラルパーサー', 'ratio': 0.9}, {'word': 'ニューラルパーサ', 'ratio': 0.1}]",ニューラルパーサー
2685,3105,neural renderer,神経レンダラー,0.0,10,"[{'word': 'ニューラルレンダラー', 'ratio': 1.0}]",ニューラルレンダラー
2686,3106,neural rendering,ニューラルレンダリング,1.0,10,"[{'word': 'ニューラルレンダリング', 'ratio': 1.0}]",ニューラルレンダリング
2687,3107,neural representation,ニューラル表現,0.8,10,"[{'word': 'ニューラル表現', 'ratio': 0.8}, {'word': '神経表現', 'ratio': 0.2}]",ニューラル表現
2688,3110,neural scene representation,神経場面表現,0.0,10,"[{'word': 'ニューラルシーン表現', 'ratio': 0.9}, {'word': 'しんけいシーンひょうげん', 'ratio': 0.1}]",ニューラルシーン表現
2689,3112,neural text generation,"""神経テキスト生成""",0.0,10,"[{'word': 'ニューラルテキスト生成', 'ratio': 0.8}, {'word': 'ニューラル・テキスト生成', 'ratio': 0.1}, {'word': 'ニューラルトキスト生成', 'ratio': 0.1}]",ニューラルテキスト生成
2690,3113,neural volumetric representation,ニューラルボリューメトリック表現,0.0,10,"[{'word': 'ニューラル体積表現', 'ratio': 0.6}, {'word': '神経体積表現', 'ratio': 0.3}, {'word': 'ニューラルボリュメトリック表現', 'ratio': 0.1}]",ニューラル体積表現
2691,3116,neuron,ニューロン,1.0,10,"[{'word': 'ニューロン', 'ratio': 1.0}]",ニューロン
2692,3117,next sentence prediction,次の文予測,0.2222222222222222,9,"[{'word': '次文予測', 'ratio': 0.6666666666666666}, {'word': '次の文予測', 'ratio': 0.2222222222222222}, {'word': '次の文の予測', 'ratio': 0.1111111111111111}]",次文予測
2693,3118,next token prediction,次のトークン予測,0.3333333333333333,9,"[{'word': '次トークン予測', 'ratio': 0.5555555555555556}, {'word': '次のトークン予測', 'ratio': 0.3333333333333333}, {'word': '次のトークンの予測', 'ratio': 0.1111111111111111}]",次トークン予測
2694,3120,no-regret algorithm,後悔しないアルゴリズム,0.2222222222222222,9,"[{'word': 'ノーリグレットアルゴリズム', 'ratio': 0.5555555555555556}, {'word': '後悔しないアルゴリズム', 'ratio': 0.2222222222222222}, {'word': 'ノー・レジェルトアルゴリズム', 'ratio': 0.1111111111111111}, {'word': '後悔なしアルゴリズム', 'ratio': 0.1111111111111111}]",ノーリグレットアルゴリズム
2695,3123,node,ノード,0.9,10,"[{'word': 'ノード', 'ratio': 0.9}, {'word': 'Nōdo', 'ratio': 0.1}]",ノード
2696,3124,node attribute,ノード属性,0.9,10,"[{'word': 'ノード属性', 'ratio': 0.9}, {'word': 'Nōdo Buryūtibu', 'ratio': 0.1}]",ノード属性
2697,3125,node classification,ノード分類,0.8,10,"[{'word': 'ノード分類', 'ratio': 0.8}, {'word': 'ノードの分類', 'ratio': 0.1}, {'word': 'Nōdo Saibunka', 'ratio': 0.1}]",ノード分類
2698,3126,node degree,ノード次数,0.4,10,"[{'word': 'ノードの次数', 'ratio': 0.5}, {'word': 'ノード次数', 'ratio': 0.4}, {'word': 'ノード度', 'ratio': 0.1}]",ノードの次数
2699,3127,node embedding,ノード埋め込み,0.9,10,"[{'word': 'ノード埋め込み', 'ratio': 0.9}, {'word': 'ノードの埋め込み', 'ratio': 0.1}]",ノード埋め込み
2700,3128,node feature,ノード特徴,0.8,10,"[{'word': 'ノード特徴', 'ratio': 0.8}, {'word': 'ノード機能', 'ratio': 0.2}]",ノード特徴
2701,3129,node feature matrix,ノード特徴行列,0.9,10,"[{'word': 'ノード特徴行列', 'ratio': 0.9}, {'word': 'ノード特徴マトリックス', 'ratio': 0.1}]",ノード特徴行列
2702,3130,node label,ノードラベル,1.0,10,"[{'word': 'ノードラベル', 'ratio': 1.0}]",ノードラベル
2703,3131,node representation,ノード表現,1.0,10,"[{'word': 'ノード表現', 'ratio': 1.0}]",ノード表現
2704,3132,node set,ノード集合,0.8,10,"[{'word': 'ノード集合', 'ratio': 0.8}, {'word': 'ノードセット', 'ratio': 0.2}]",ノード集合
2705,3134,noise distribution,ノイズ分布,1.0,10,"[{'word': 'ノイズ分布', 'ratio': 1.0}]",ノイズ分布
2706,3135,noise level,ノイズレベル,0.8,10,"[{'word': 'ノイズレベル', 'ratio': 0.8}, {'word': '騒音レベル', 'ratio': 0.2}]",ノイズレベル
2707,3136,noise model,ノイズモデル,1.0,10,"[{'word': 'ノイズモデル', 'ratio': 1.0}]",ノイズモデル
2708,3137,noise schedule,ノイズスケジュール,0.8,10,"[{'word': 'ノイズスケジュール', 'ratio': 0.8}, {'word': '騒音スケジュール', 'ratio': 0.2}]",ノイズスケジュール
2709,3138,noise-contrastive estimation,ノイズ対比推定,0.7,10,"[{'word': 'ノイズ対比推定', 'ratio': 0.7}, {'word': 'ノイズコントラスト推定', 'ratio': 0.3}]",ノイズ対比推定
2710,3140,nominal mention,名詞句言及,0.0,10,"[{'word': '名詞的言及', 'ratio': 0.5}, {'word': '名義的言及', 'ratio': 0.2}, {'word': '言及', 'ratio': 0.1}, {'word': 'Fujinō Menushon', 'ratio': 0.1}, {'word': '名詞の言及', 'ratio': 0.1}]",名詞的言及
2711,3141,non-Euclidean space,非ユークリッド空間,0.9,10,"[{'word': '非ユークリッド空間', 'ratio': 0.9}, {'word': 'Nan-Eu-Kurīdeianu Supēsu', 'ratio': 0.1}]",非ユークリッド空間
2712,3142,non-Markov process,非マルコフ過程,0.8,10,"[{'word': '非マルコフ過程', 'ratio': 0.8}, {'word': 'ひマルコフかてい', 'ratio': 0.1}, {'word': 'Nan-Markovu Purosesu', 'ratio': 0.1}]",非マルコフ過程
2713,3143,non-convex objective,非凸目的関数,0.5,10,"[{'word': '非凸目的関数', 'ratio': 0.5}, {'word': '非凸目的', 'ratio': 0.4}, {'word': 'Nan-Fukakusu Obiektibu', 'ratio': 0.1}]",非凸目的関数
2714,3144,non-convex optimization,非凸最適化,0.9,10,"[{'word': '非凸最適化', 'ratio': 0.9}, {'word': 'Nan-Fukakusu Ōptimizaishon', 'ratio': 0.1}]",非凸最適化
2715,3145,non-convex problem,非凸問題,1.0,10,"[{'word': '非凸問題', 'ratio': 1.0}]",非凸問題
2716,3146,non-convexity,非凸性,0.8,10,"[{'word': '非凸性', 'ratio': 0.8}, {'word': '非凸', 'ratio': 0.2}]",非凸性
2717,3147,non-linear least square,非線形最小二乗法,0.8,10,"[{'word': '非線形最小二乗法', 'ratio': 0.8}, {'word': '非線形最小二乗', 'ratio': 0.2}]",非線形最小二乗法
2718,3148,non-linear optimization,非線形最適化,1.0,10,"[{'word': '非線形最適化', 'ratio': 1.0}]",非線形最適化
2719,3149,non-linearity,非線形性,0.8,10,"[{'word': '非線形性', 'ratio': 0.8}, {'word': '非直線性', 'ratio': 0.2}]",非線形性
2720,3150,non-local feature,非局所特徴,0.8,10,"[{'word': '非局所特徴', 'ratio': 0.8}, {'word': '非局所的機能', 'ratio': 0.1}, {'word': '非ローカル機能', 'ratio': 0.1}]",非局所特徴
2721,3151,non-max suppression,非最大抑制,1.0,10,"[{'word': '非最大抑制', 'ratio': 1.0}]",非最大抑制
2722,3152,non-maxima suppression,非最大抑制,0.2,10,"[{'word': '非最大値抑制', 'ratio': 0.7}, {'word': '非最大抑制', 'ratio': 0.2}, {'word': '非最大圧縮', 'ratio': 0.1}]",非最大値抑制
2723,3153,non-maximal suppression,非最大抑制,0.8,10,"[{'word': '非最大抑制', 'ratio': 0.8}, {'word': '非最大化抑制', 'ratio': 0.1}, {'word': '非極大抑制', 'ratio': 0.1}]",非最大抑制
2724,3155,non-parametric setting,非パラメトリック設定,0.3,10,"[{'word': 'ノンパラメトリック設定', 'ratio': 0.7}, {'word': '非パラメトリック設定', 'ratio': 0.3}]",ノンパラメトリック設定
2725,3159,nonconvex function,非凸関数,0.8,10,"[{'word': '非凸関数', 'ratio': 0.8}, {'word': 'ノンコンベックス関数', 'ratio': 0.2}]",非凸関数
2726,3160,nonlinear optimisation,非線形最適化,1.0,9,"[{'word': '非線形最適化', 'ratio': 1.0}]",非線形最適化
2727,3161,nonmonotonic reasoning,非単調推論,0.8888888888888888,9,"[{'word': '非単調推論', 'ratio': 0.8888888888888888}, {'word': '非単調な推論', 'ratio': 0.1111111111111111}]",非単調推論
2728,3162,nonterminal symbol,非終端記号,0.8888888888888888,9,"[{'word': '非終端記号', 'ratio': 0.8888888888888888}, {'word': '非端末記号', 'ratio': 0.1111111111111111}]",非終端記号
2729,3163,norm,ノルム,0.7777777777777778,9,"[{'word': 'ノルム', 'ratio': 0.7777777777777778}, {'word': '規範', 'ratio': 0.1111111111111111}, {'word': '標準', 'ratio': 0.1111111111111111}]",ノルム
2730,3164,normal,法線,0.7777777777777778,9,"[{'word': '法線', 'ratio': 0.7777777777777778}, {'word': '通常', 'ratio': 0.1111111111111111}, {'word': '普通', 'ratio': 0.1111111111111111}]",法線
2731,3165,normal distribution,正規分布,0.8888888888888888,9,"[{'word': '正規分布', 'ratio': 0.8888888888888888}, {'word': '通常分布', 'ratio': 0.1111111111111111}]",正規分布
2732,3166,normal form,正規形,0.6666666666666666,9,"[{'word': '正規形', 'ratio': 0.6666666666666666}, {'word': '標準形', 'ratio': 0.2222222222222222}, {'word': '通常形', 'ratio': 0.1111111111111111}]",正規形
2733,3167,normal vector,法線ベクトル,0.8888888888888888,9,"[{'word': '法線ベクトル', 'ratio': 0.8888888888888888}, {'word': '通常ベクトル', 'ratio': 0.1111111111111111}]",法線ベクトル
2734,3168,normal-form game,標準形ゲーム,0.2222222222222222,9,"[{'word': '正規形ゲーム', 'ratio': 0.6666666666666666}, {'word': '標準形ゲーム', 'ratio': 0.2222222222222222}, {'word': '正規形のゲーム', 'ratio': 0.1111111111111111}]",正規形ゲーム
2735,3169,normalisation,正規化,0.8888888888888888,9,"[{'word': '正規化', 'ratio': 0.8888888888888888}, {'word': '標準化', 'ratio': 0.1111111111111111}]",正規化
2736,3170,normalization constant,正規化定数,0.9,10,"[{'word': '正規化定数', 'ratio': 0.9}, {'word': '規正定数', 'ratio': 0.1}]",正規化定数
2737,3171,normalization factor,正規化因子 (seikika inshi),0.0,10,"[{'word': '正規化因子', 'ratio': 0.6}, {'word': '正規化係数', 'ratio': 0.3}, {'word': '規正因子', 'ratio': 0.1}]",正規化因子
2738,3172,normalization function,正規化関数,0.7,10,"[{'word': '正規化関数', 'ratio': 0.7}, {'word': '正規化機能', 'ratio': 0.2}, {'word': '規正関数', 'ratio': 0.1}]",正規化関数
2739,3173,normalization layer,正規化層,0.7,10,"[{'word': '正規化層', 'ratio': 0.7}, {'word': '正規化レイヤ', 'ratio': 0.2}, {'word': '規正層', 'ratio': 0.1}]",正規化層
2740,3174,normalization method,正規化方法,0.0,10,"[{'word': '正規化手法', 'ratio': 0.7}, {'word': '正規化法', 'ratio': 0.2}, {'word': '規正方法', 'ratio': 0.1}]",正規化手法
2741,3175,normalization strategy,正規化戦略,0.7777777777777778,9,"[{'word': '正規化戦略', 'ratio': 0.7777777777777778}, {'word': 'ノーマライゼーション戦略', 'ratio': 0.2222222222222222}]",正規化戦略
2742,3176,normalize,正規化,0.1111111111111111,9,"[{'word': '正規化する', 'ratio': 0.6666666666666666}, {'word': 'ノーマライズ', 'ratio': 0.2222222222222222}, {'word': '正規化', 'ratio': 0.1111111111111111}]",正規化する
2743,3177,normalized cross correlation,正規化相互相関,0.2222222222222222,9,"[{'word': '正規化相関', 'ratio': 0.5555555555555556}, {'word': '正規化交差相関', 'ratio': 0.2222222222222222}, {'word': '正規化相互相関', 'ratio': 0.2222222222222222}]",正規化相関
2744,3178,normalized cut,正規化カット,1.0,9,"[{'word': '正規化カット', 'ratio': 1.0}]",正規化カット
2745,3179,normalized cut algorithm,正規化カットアルゴリズム,0.7777777777777778,9,"[{'word': '正規化カットアルゴリズム', 'ratio': 0.7777777777777778}, {'word': '正規化カット・アルゴリズム', 'ratio': 0.2222222222222222}]",正規化カットアルゴリズム
2746,3180,normalized edit distance,正規化された編集距離,0.1,10,"[{'word': '正規化編集距離', 'ratio': 0.9}, {'word': '正規化された編集距離', 'ratio': 0.1}]",正規化編集距離
2747,3181,normalizing factor,正規化係数,0.3,10,"[{'word': '正規化因子', 'ratio': 0.7}, {'word': '正規化係数', 'ratio': 0.3}]",正規化因子
2748,3182,normalizing flow,正規化フロー,0.8,10,"[{'word': '正規化フロー', 'ratio': 0.8}, {'word': 'ノーマライジング・フロー', 'ratio': 0.1}, {'word': '流れを正規化する', 'ratio': 0.1}]",正規化フロー
2749,3183,noun phrase,名詞句,1.0,10,"[{'word': '名詞句', 'ratio': 1.0}]",名詞句
2750,3184,novel view synthesis,新規ビュー合成,0.0,10,"[{'word': '新しい視点合成', 'ratio': 0.5}, {'word': '新規視点合成', 'ratio': 0.3}, {'word': '斬新な視点の合成', 'ratio': 0.2}]",新しい視点合成
2751,3185,nsubj,主語,0.8,10,"[{'word': '主語', 'ratio': 0.8}, {'word': '部分名', 'ratio': 0.1}, {'word': 'nsubj', 'ratio': 0.1}]",主語
2752,3186,nsubjpass,受動主語,0.6,10,"[{'word': '受動主語', 'ratio': 0.6}, {'word': 'サブパス', 'ratio': 0.1}, {'word': 'nsubjpass', 'ratio': 0.1}, {'word': '受動態の主語', 'ratio': 0.1}, {'word': '受動態主語', 'ratio': 0.1}]",受動主語
2753,3187,nuclear norm,核ノルム,0.8,10,"[{'word': '核ノルム', 'ratio': 0.8}, {'word': '核の規範', 'ratio': 0.1}, {'word': 'nuclear norm', 'ratio': 0.1}]",核ノルム
2754,3188,nuclear norm relaxation,核ノルム緩和,0.8888888888888888,9,"[{'word': '核ノルム緩和', 'ratio': 0.8888888888888888}, {'word': 'ノルム緩和', 'ratio': 0.1111111111111111}]",核ノルム緩和
2755,3190,null space,ゼロ空間,0.0,9,"[{'word': '零空間', 'ratio': 0.5555555555555556}, {'word': 'ヌルスペース', 'ratio': 0.2222222222222222}, {'word': '核空間', 'ratio': 0.1111111111111111}, {'word': 'null空間', 'ratio': 0.1111111111111111}]",零空間
2756,3191,numerical linear algebra,数値線形代数,1.0,9,"[{'word': '数値線形代数', 'ratio': 1.0}]",数値線形代数
2757,3196,object class,オブジェクトクラス,0.6,10,"[{'word': 'オブジェクトクラス', 'ratio': 0.6}, {'word': '物体クラス', 'ratio': 0.4}]",オブジェクトクラス
2758,3197,object classification,オブジェクト分類,0.2,10,"[{'word': '物体分類', 'ratio': 0.6}, {'word': 'オブジェクト分類', 'ratio': 0.2}, {'word': 'オブジェクトの分類', 'ratio': 0.2}]",物体分類
2759,3198,object detector,オブジェクト検出器,0.2,10,"[{'word': '物体検出器', 'ratio': 0.8}, {'word': 'オブジェクト検出器', 'ratio': 0.2}]",物体検出器
2760,3200,object embedding,オブジェクト埋め込み,0.3,10,"[{'word': '物体埋め込み', 'ratio': 0.5}, {'word': 'オブジェクト埋め込み', 'ratio': 0.3}, {'word': 'オブジェクトの埋め込み', 'ratio': 0.2}]",物体埋め込み
2761,3201,object instance segmentation,オブジェクトインスタンスのセグメンテーション,0.2,10,"[{'word': '物体インスタンスセグメンテーション', 'ratio': 0.6}, {'word': 'オブジェクトインスタンスセグメンテーション', 'ratio': 0.2}, {'word': 'オブジェクトインスタンスのセグメンテーション', 'ratio': 0.2}]",物体インスタンスセグメンテーション
2762,3202,object model,オブジェクトモデル,1.0,10,"[{'word': 'オブジェクトモデル', 'ratio': 1.0}]",オブジェクトモデル
2763,3203,object proposal,オブジェクト提案,0.8,10,"[{'word': 'オブジェクト提案', 'ratio': 0.8}, {'word': 'オブジェクトの提案', 'ratio': 0.2}]",オブジェクト提案
2764,3204,object recognition,物体認識,0.1,10,"[{'word': 'オブジェクト認識', 'ratio': 0.9}, {'word': '物体認識', 'ratio': 0.1}]",オブジェクト認識
2765,3205,object segmentation,物体セグメンテーション,0.0,10,"[{'word': 'オブジェクトセグメンテーション', 'ratio': 0.8}, {'word': 'オブジェクトのセグメンテーション', 'ratio': 0.2}]",オブジェクトセグメンテーション
2766,3206,object tracking,物体追跡,0.0,10,"[{'word': 'オブジェクト追跡', 'ratio': 0.7}, {'word': 'オブジェクトトラッキング', 'ratio': 0.3}]",オブジェクト追跡
2767,3207,objective function,目的関数,1.0,10,"[{'word': '目的関数', 'ratio': 1.0}]",目的関数
2768,3208,objective value,目的関数値,0.0,10,"[{'word': '目的値', 'ratio': 0.8}, {'word': '客観的な価値', 'ratio': 0.2}]",目的値
2769,3210,observation function,観測関数,0.8,10,"[{'word': '観測関数', 'ratio': 0.8}, {'word': '観測機能', 'ratio': 0.2}]",観測関数
2770,3211,observation model,観測モデル,1.0,10,"[{'word': '観測モデル', 'ratio': 1.0}]",観測モデル
2771,3212,observation space,観測空間,0.8,10,"[{'word': '観測空間', 'ratio': 0.8}, {'word': '観測スペース', 'ratio': 0.1}, {'word': '観察スペース', 'ratio': 0.1}]",観測空間
2772,3213,observational datum,観測データ,1.0,10,"[{'word': '観測データ', 'ratio': 1.0}]",観測データ
2773,3216,occupancy grid,占有グリッド,0.9,10,"[{'word': '占有グリッド', 'ratio': 0.9}, {'word': 'オキュペンシーグリッド', 'ratio': 0.1}]",占有グリッド
2774,3217,occupancy map,占有マップ,0.9,10,"[{'word': '占有マップ', 'ratio': 0.9}, {'word': 'Seihi Zōhyō', 'ratio': 0.1}]",占有マップ
2775,3218,occupancy measure,占有度,0.0,9,"[{'word': '占有測度', 'ratio': 0.6666666666666666}, {'word': '占有率測定', 'ratio': 0.1111111111111111}, {'word': '占有測定', 'ratio': 0.1111111111111111}, {'word': '占有率の測定', 'ratio': 0.1111111111111111}]",占有測度
2776,3219,odometry,オドメトリ,0.9,10,"[{'word': 'オドメトリ', 'ratio': 0.9}, {'word': 'Odometori', 'ratio': 0.1}]",オドメトリ
2777,3220,off-diagonal element,非対角要素,0.8,10,"[{'word': '非対角要素', 'ratio': 0.8}, {'word': 'Kakko Kaisan Tansu', 'ratio': 0.1}, {'word': '対角外要素', 'ratio': 0.1}]",非対角要素
2778,3221,off-policy,オフポリシー,0.7,10,"[{'word': 'オフポリシー', 'ratio': 0.7}, {'word': 'ポリシー外', 'ratio': 0.2}, {'word': 'Ofu Seisaku', 'ratio': 0.1}]",オフポリシー
2779,3222,offline algorithm,オフラインアルゴリズム,1.0,9,"[{'word': 'オフラインアルゴリズム', 'ratio': 1.0}]",オフラインアルゴリズム
2780,3223,offline learning,オフライン学習,1.0,9,"[{'word': 'オフライン学習', 'ratio': 1.0}]",オフライン学習
2781,3224,on-policy,オンポリシー,0.8888888888888888,9,"[{'word': 'オンポリシー', 'ratio': 0.8888888888888888}, {'word': 'ポリシーに従って', 'ratio': 0.1111111111111111}]",オンポリシー
2782,3226,one-hot encoded,ワンホットエンコード,0.5555555555555556,9,"[{'word': 'ワンホットエンコード', 'ratio': 0.5555555555555556}, {'word': 'ワンホットエンコーディング', 'ratio': 0.2222222222222222}, {'word': 'ワンホットエンコーディ', 'ratio': 0.1111111111111111}, {'word': 'ワンホットエンコードされた', 'ratio': 0.1111111111111111}]",ワンホットエンコード
2783,3227,one-hot representation,ワンホット表現,0.7,10,"[{'word': 'ワンホット表現', 'ratio': 0.7}, {'word': 'ワンショット表現', 'ratio': 0.2}, {'word': 'Ichi-Atsu Hyōshiki', 'ratio': 0.1}]",ワンホット表現
2784,3228,one-hot vector,ワンホットベクトル,0.7,10,"[{'word': 'ワンホットベクトル', 'ratio': 0.7}, {'word': 'ワンホットベクター', 'ratio': 0.2}, {'word': 'Ichi-Atsu Buresu', 'ratio': 0.1}]",ワンホットベクトル
2785,3229,one-shot learning,ワンショット学習,0.7,10,"[{'word': 'ワンショット学習', 'ratio': 0.7}, {'word': '単発学習', 'ratio': 0.2}, {'word': 'Ichi-Shot Reningu', 'ratio': 0.1}]",ワンショット学習
2786,3230,one-shot setting,単回設定,0.0,10,"[{'word': 'ワンショット設定', 'ratio': 0.7}, {'word': '単発設定', 'ratio': 0.2}, {'word': 'Ichi-Shot Settingu', 'ratio': 0.1}]",ワンショット設定
2787,3231,one-stage detector,ワンステージ検出器,0.7,10,"[{'word': 'ワンステージ検出器', 'ratio': 0.7}, {'word': 'ワンステージディテクター', 'ratio': 0.2}, {'word': 'Ichi-Stēji Detektā', 'ratio': 0.1}]",ワンステージ検出器
2788,3233,online algorithm,オンラインアルゴリズム,0.8,10,"[{'word': 'オンラインアルゴリズム', 'ratio': 0.8}, {'word': 'オンライン・アルゴリズム', 'ratio': 0.2}]",オンラインアルゴリズム
2789,3234,online convex optimization,オンラインコンベックス最適化,0.0,10,"[{'word': 'オンライン凸最適化', 'ratio': 1.0}]",オンライン凸最適化
2790,3235,online gradient descent,オンライングラディエント降下法,0.0,10,"[{'word': 'オンライン勾配降下法', 'ratio': 0.7}, {'word': 'オンライン勾配降下', 'ratio': 0.3}]",オンライン勾配降下法
2791,3236,online learning,オンライン学習,1.0,10,"[{'word': 'オンライン学習', 'ratio': 1.0}]",オンライン学習
2792,3237,online learning algorithm,オンライン学習アルゴリズム,1.0,10,"[{'word': 'オンライン学習アルゴリズム', 'ratio': 1.0}]",オンライン学習アルゴリズム
2793,3238,online learning method,オンライン学習法,0.3,10,"[{'word': 'オンライン学習手法', 'ratio': 0.7}, {'word': 'オンライン学習法', 'ratio': 0.3}]",オンライン学習手法
2794,3239,online learning theory,オンライン学習理論,1.0,10,"[{'word': 'オンライン学習理論', 'ratio': 1.0}]",オンライン学習理論
2795,3240,ontology,存在論,0.0,10,"[{'word': 'オントロジー', 'ratio': 1.0}]",オントロジー
2796,3241,ontology language,オントロジー言語,1.0,10,"[{'word': 'オントロジー言語', 'ratio': 1.0}]",オントロジー言語
2797,3242,ontology-mediated query,オントロジー媒介クエリ,0.8,10,"[{'word': 'オントロジー媒介クエリ', 'ratio': 0.8}, {'word': 'オントロジーを介したクエリー', 'ratio': 0.1}, {'word': 'オントロジーを介したクエリ...', 'ratio': 0.1}]",オントロジー媒介クエリ
2798,3243,open set,オープンセット,0.2,10,"[{'word': '開集合', 'ratio': 0.8}, {'word': 'オープンセット', 'ratio': 0.2}]",開集合
2799,3244,open-ended text generation,オープンエンドテキスト生成,0.2,10,"[{'word': 'オープンエンドのテキスト生成', 'ratio': 0.6}, {'word': 'オープンエンドテキスト生成', 'ratio': 0.2}, {'word': '自由形式テキスト生成', 'ratio': 0.1}, {'word': '無制限のテキスト生成', 'ratio': 0.1}]",オープンエンドのテキスト生成
2800,3245,open-loop,オープンループ,0.9,10,"[{'word': 'オープンループ', 'ratio': 0.9}, {'word': '開ループ', 'ratio': 0.1}]",オープンループ
2801,3246,operator norm,演算子ノルム,0.9,10,"[{'word': '演算子ノルム', 'ratio': 0.9}, {'word': '作用素ノルム', 'ratio': 0.1}]",演算子ノルム
2802,3247,operator sequence,演算子シーケンス,0.2,10,"[{'word': '演算子列', 'ratio': 0.6}, {'word': '演算子シーケンス', 'ratio': 0.2}, {'word': '演算子系列', 'ratio': 0.1}, {'word': '作用素列', 'ratio': 0.1}]",演算子列
2803,3248,optical character recognition,光学文字認識,0.8,10,"[{'word': '光学文字認識', 'ratio': 0.8}, {'word': '光学式文字認識', 'ratio': 0.2}]",光学文字認識
2804,3249,optical flow,光流,0.0,10,"[{'word': '光学フロー', 'ratio': 0.6}, {'word': 'オプティカルフロー', 'ratio': 0.3}, {'word': '光フロー', 'ratio': 0.1}]",光学フロー
2805,3250,optical flow estimation,光流推定,0.0,10,"[{'word': '光学フロー推定', 'ratio': 0.6}, {'word': 'オプティカルフロー推定', 'ratio': 0.3}, {'word': '光フロー推定', 'ratio': 0.1}]",光学フロー推定
2806,3251,optimal control theory,最適制御理論,0.9,10,"[{'word': '最適制御理論', 'ratio': 0.9}, {'word': 'Saiseiteki Kanryō Riron', 'ratio': 0.1}]",最適制御理論
2807,3252,optimal experimental design,最適実験設計,0.1111111111111111,9,"[{'word': '最適実験デザイン', 'ratio': 0.5555555555555556}, {'word': '最適実験計画', 'ratio': 0.3333333333333333}, {'word': '最適実験設計', 'ratio': 0.1111111111111111}]",最適実験デザイン
2808,3254,optimal solution,最適解,0.9,10,"[{'word': '最適解', 'ratio': 0.9}, {'word': 'Saiseiteki Kaiken', 'ratio': 0.1}]",最適解
2809,3255,optimality,最適性,0.9,10,"[{'word': '最適性', 'ratio': 0.9}, {'word': 'Saiseiteki', 'ratio': 0.1}]",最適性
2810,3256,optimality condition,最適性条件,0.7777777777777778,9,"[{'word': '最適性条件', 'ratio': 0.7777777777777778}, {'word': '最適条件', 'ratio': 0.2222222222222222}]",最適性条件
2811,3257,optimisation,最適化,1.0,9,"[{'word': '最適化', 'ratio': 1.0}]",最適化
2812,3258,optimisation problem,最適化問題,1.0,9,"[{'word': '最適化問題', 'ratio': 1.0}]",最適化問題
2813,3259,optimiser,最適化手法,0.6666666666666666,9,"[{'word': '最適化手法', 'ratio': 0.6666666666666666}, {'word': '最適化する', 'ratio': 0.2222222222222222}, {'word': '最適化アルゴリズム', 'ratio': 0.1111111111111111}]",最適化手法
2814,3260,optimization,最適化,1.0,9,"[{'word': '最適化', 'ratio': 1.0}]",最適化
2815,3261,optimization algorithm,最適化アルゴリズム,1.0,10,"[{'word': '最適化アルゴリズム', 'ratio': 1.0}]",最適化アルゴリズム
2816,3262,optimization framework,最適化フレームワーク,1.0,10,"[{'word': '最適化フレームワーク', 'ratio': 1.0}]",最適化フレームワーク
2817,3263,optimization function,最適化関数,0.9,10,"[{'word': '最適化関数', 'ratio': 0.9}, {'word': '最適化機能', 'ratio': 0.1}]",最適化関数
2818,3264,optimization method,最適化手法,0.9,10,"[{'word': '最適化手法', 'ratio': 0.9}, {'word': '最適化方法', 'ratio': 0.1}]",最適化手法
2819,3265,optimization objective,最適化目的関数,0.0,10,"[{'word': '最適化目的', 'ratio': 0.6}, {'word': '最適化目標', 'ratio': 0.3}, {'word': '最適化の目標', 'ratio': 0.1}]",最適化目的
2820,3266,optimization procedure,最適化手順,0.6,10,"[{'word': '最適化手順', 'ratio': 0.6}, {'word': '最適化手続き', 'ratio': 0.2}, {'word': '最適化手法', 'ratio': 0.2}]",最適化手順
2821,3267,optimization step,最適化ステップ,1.0,10,"[{'word': '最適化ステップ', 'ratio': 1.0}]",最適化ステップ
2822,3268,optimization theory,最適化理論,1.0,10,"[{'word': '最適化理論', 'ratio': 1.0}]",最適化理論
2823,3269,optimizer,最適化手法 (saiteki-ka shuhou),0.0,10,"[{'word': 'オプティマイザ', 'ratio': 0.6}, {'word': '最適化器', 'ratio': 0.4}]",オプティマイザ
2824,3270,option,オプション,1.0,10,"[{'word': 'オプション', 'ratio': 1.0}]",オプション
2825,3271,oracle,神示,0.0,20,"[{'word': 'オラクル', 'ratio': 0.9}, {'word': '神託', 'ratio': 0.1}]",オラクル
2826,3272,oracle policy,オラクルポリシー,0.9,10,"[{'word': 'オラクルポリシー', 'ratio': 0.9}, {'word': 'オラクル ポリシー', 'ratio': 0.1}]",オラクルポリシー
2827,3273,ordinal embedding,順序埋め込み,0.9,10,"[{'word': '順序埋め込み', 'ratio': 0.9}, {'word': '序数埋め込み', 'ratio': 0.1}]",順序埋め込み
2828,3274,ordinal regression,順序回帰,1.0,10,"[{'word': '順序回帰', 'ratio': 1.0}]",順序回帰
2829,3276,orthogonal basis,直交基底,0.7,10,"[{'word': '直交基底', 'ratio': 0.7}, {'word': '正交基底', 'ratio': 0.2}, {'word': '正規直交基底', 'ratio': 0.1}]",直交基底
2830,3277,orthogonal matrix,正規直交行列,0.1,10,"[{'word': '直交行列', 'ratio': 0.7}, {'word': '正交行列', 'ratio': 0.2}, {'word': '正規直交行列', 'ratio': 0.1}]",直交行列
2831,3278,orthogonal projection matrix,正射影行列,0.0,10,"[{'word': '直交射影行列', 'ratio': 0.7}, {'word': '正規直交射影行列', 'ratio': 0.1}, {'word': '正交投影行列', 'ratio': 0.1}, {'word': '正交射影行列', 'ratio': 0.1}]",直交射影行列
2832,3281,orthonormal decomposition,正規直交分解,0.8,10,"[{'word': '正規直交分解', 'ratio': 0.8}, {'word': '直交分解', 'ratio': 0.2}]",正規直交分解
2833,3282,orthonormal matrix,直交正規化行列,0.0,10,"[{'word': '正規直交行列', 'ratio': 0.8}, {'word': '直交行列', 'ratio': 0.2}]",正規直交行列
2834,3283,orthonormal row,直交正規行,0.0,10,"[{'word': '正規直交行', 'ratio': 0.7}, {'word': '直交行', 'ratio': 0.2}, {'word': '正規直交列', 'ratio': 0.1}]",正規直交行
2835,3284,orthonormality,直交正規性 (chokkō seikisei),0.0,10,"[{'word': '正規直交性', 'ratio': 0.7}, {'word': '直交性', 'ratio': 0.3}]",正規直交性
2836,3285,out-of-distribution,分布外,0.7,10,"[{'word': '分布外', 'ratio': 0.7}, {'word': 'アウト・オブ・ディストリビューション', 'ratio': 0.2}, {'word': '外れ値分布外', 'ratio': 0.1}]",分布外
2837,3286,out-of-domain,文脈外の,0.0,10,"[{'word': 'ドメイン外', 'ratio': 0.8}, {'word': 'アウトオブドメイン', 'ratio': 0.2}]",ドメイン外
2838,3287,out-of-domain evaluation,ドメイン外評価,0.8,10,"[{'word': 'ドメイン外評価', 'ratio': 0.8}, {'word': '領域外評価', 'ratio': 0.2}]",ドメイン外評価
2839,3288,outlier,外れ値,0.8,10,"[{'word': '外れ値', 'ratio': 0.8}, {'word': 'アウトライヤー', 'ratio': 0.2}]",外れ値
2840,3289,outlier detection,外れ値検出,0.6,10,"[{'word': '外れ値検出', 'ratio': 0.6}, {'word': 'アウトライヤー検出', 'ratio': 0.2}, {'word': '異常値検出', 'ratio': 0.2}]",外れ値検出
2841,3292,output,出力,1.0,10,"[{'word': '出力', 'ratio': 1.0}]",出力
2842,3293,output gate,出力ゲート,1.0,10,"[{'word': '出力ゲート', 'ratio': 1.0}]",出力ゲート
2843,3294,output layer,出力層,1.0,10,"[{'word': '出力層', 'ratio': 1.0}]",出力層
2844,3295,output space,出力空間,0.8,10,"[{'word': '出力空間', 'ratio': 0.8}, {'word': '出力スペース', 'ratio': 0.2}]",出力空間
2845,3296,output token,出力トークン,1.0,10,"[{'word': '出力トークン', 'ratio': 1.0}]",出力トークン
2846,3297,output vector,出力ベクトル,0.9,10,"[{'word': '出力ベクトル', 'ratio': 0.9}, {'word': '出力ベクター', 'ratio': 0.1}]",出力ベクトル
2847,3298,output vocabulary,出力語彙,1.0,10,"[{'word': '出力語彙', 'ratio': 1.0}]",出力語彙
2848,3300,over-segmentation,過剰分割,0.0,10,"[{'word': '過剰セグメンテーション', 'ratio': 0.7}, {'word': 'オーバーセグメンテーション', 'ratio': 0.3}]",過剰セグメンテーション
2849,3301,over-smoothing,過剰平滑化,0.6,10,"[{'word': '過剰平滑化', 'ratio': 0.6}, {'word': 'オーバー・スムージング', 'ratio': 0.2}, {'word': 'オーバースMOOTHING', 'ratio': 0.1}, {'word': '過度の平滑化', 'ratio': 0.1}]",過剰平滑化
2850,3303,pairwise,ペアワイズ (pairwise),0.0,19,"[{'word': 'ペアワイズ', 'ratio': 0.6842105263157895}, {'word': '対', 'ratio': 0.15789473684210525}, {'word': '対の', 'ratio': 0.10526315789473684}, {'word': 'ペアごと', 'ratio': 0.05263157894736842}]",ペアワイズ
2851,3308,pairwise flow,ペアワイズフロー,0.9,10,"[{'word': 'ペアワイズフロー', 'ratio': 0.9}, {'word': 'Furē Pēru', 'ratio': 0.1}]",ペアワイズフロー
2852,3309,pairwise learning,ペアワイズ学習,0.9,10,"[{'word': 'ペアワイズ学習', 'ratio': 0.9}, {'word': 'Pāiwaī Renningu', 'ratio': 0.1}]",ペアワイズ学習
2853,3310,pairwise potential,ペア間ポテンシャル,0.0,10,"[{'word': 'ペアワイズポテンシャル', 'ratio': 0.9}, {'word': 'Pāiwaī Pōtensharu', 'ratio': 0.1}]",ペアワイズポテンシャル
2854,3312,panoptic segmentation,パノプティックセグメンテーション,0.6,10,"[{'word': 'パノプティックセグメンテーション', 'ratio': 0.6}, {'word': '全体的セグメンテーション', 'ratio': 0.2}, {'word': 'パノプティック・セグメンテーション', 'ratio': 0.1}, {'word': 'Panōtikku Sementoreshon', 'ratio': 0.1}]",パノプティックセグメンテーション
2855,3313,parallel corpora,並列コーパス,0.5,10,"[{'word': '並列コーパス', 'ratio': 0.5}, {'word': 'パラレルコーパス', 'ratio': 0.2}, {'word': '並行コーパス', 'ratio': 0.2}, {'word': '対訳コーパス', 'ratio': 0.1}]",並列コーパス
2856,3316,parameter,パラメータ,0.8,20,"[{'word': 'パラメータ', 'ratio': 0.8}, {'word': 'パラメーター', 'ratio': 0.15}, {'word': 'パラメーターパラメーター', 'ratio': 0.05}]",パラメータ
2857,3317,parameter count,パラメータ数,0.8,10,"[{'word': 'パラメータ数', 'ratio': 0.8}, {'word': 'パラメーター数', 'ratio': 0.2}]",パラメータ数
2858,3318,parameter estimation,パラメータ推定,0.8,10,"[{'word': 'パラメータ推定', 'ratio': 0.8}, {'word': 'パラメーター推定', 'ratio': 0.2}]",パラメータ推定
2859,3319,parameter learning,パラメータ学習,0.8,10,"[{'word': 'パラメータ学習', 'ratio': 0.8}, {'word': 'パラメーター学習', 'ratio': 0.2}]",パラメータ学習
2860,3320,parameter matrix,パラメータ行列,0.9,10,"[{'word': 'パラメータ行列', 'ratio': 0.9}, {'word': 'パラメーター行列', 'ratio': 0.1}]",パラメータ行列
2861,3321,parameter model,パラメータモデル,0.9,10,"[{'word': 'パラメータモデル', 'ratio': 0.9}, {'word': 'パラメーターモデル', 'ratio': 0.1}]",パラメータモデル
2862,3322,parameter regularization,パラメータ正則化,0.9,10,"[{'word': 'パラメータ正則化', 'ratio': 0.9}, {'word': 'パラメーター規正化', 'ratio': 0.1}]",パラメータ正則化
2863,3323,parameter sharing,パラメータ共有,0.9,10,"[{'word': 'パラメータ共有', 'ratio': 0.9}, {'word': 'パラメーター共有', 'ratio': 0.1}]",パラメータ共有
2864,3324,parameter size,パラメータサイズ,0.9,10,"[{'word': 'パラメータサイズ', 'ratio': 0.9}, {'word': 'パラメーターサイズ', 'ratio': 0.1}]",パラメータサイズ
2865,3325,parameter space,パラメータ空間,1.0,9,"[{'word': 'パラメータ空間', 'ratio': 1.0}]",パラメータ空間
2866,3326,parameter tuning,パラメータ調整,0.7777777777777778,9,"[{'word': 'パラメータ調整', 'ratio': 0.7777777777777778}, {'word': 'パラメーターチューニング', 'ratio': 0.1111111111111111}, {'word': 'パラメータチューニング', 'ratio': 0.1111111111111111}]",パラメータ調整
2867,3328,parameter update,パラメータ更新,0.8888888888888888,9,"[{'word': 'パラメータ更新', 'ratio': 0.8888888888888888}, {'word': 'パラメータの更新', 'ratio': 0.1111111111111111}]",パラメータ更新
2868,3329,parameter vector,パラメータベクトル,1.0,9,"[{'word': 'パラメータベクトル', 'ratio': 1.0}]",パラメータベクトル
2869,3330,parameter-efficient fine-tuning,パラメータ効率的な微調整,0.0,10,"[{'word': 'パラメータ効率の良いファインチューニング', 'ratio': 0.6}, {'word': 'パラメータ効率的微調整', 'ratio': 0.1}, {'word': 'パラメータ効率の良い微調整', 'ratio': 0.1}, {'word': 'パラメータ効率の高い微調整', 'ratio': 0.1}, {'word': 'パラメータ効率的ファインチューニング', 'ratio': 0.1}]",パラメータ効率の良いファインチューニング
2870,3331,parameterisation,パラメータ化,0.8,10,"[{'word': 'パラメータ化', 'ratio': 0.8}, {'word': 'パラメタリゼーション', 'ratio': 0.1}, {'word': 'パラメトリゼーション', 'ratio': 0.1}]",パラメータ化
2871,3332,parameterization,パラメータ化,0.8,10,"[{'word': 'パラメータ化', 'ratio': 0.8}, {'word': 'パラメタリゼーション', 'ratio': 0.1}, {'word': 'パラメトリゼーション', 'ratio': 0.1}]",パラメータ化
2872,3333,parameterized model,パラメータ化モデル,0.7,10,"[{'word': 'パラメータ化モデル', 'ratio': 0.7}, {'word': 'パラメタライズド・モデル', 'ratio': 0.1}, {'word': 'パラメータモデル', 'ratio': 0.1}, {'word': 'パラメータ化されたモデル', 'ratio': 0.1}]",パラメータ化モデル
2873,3334,parametric,パラメトリック,1.0,10,"[{'word': 'パラメトリック', 'ratio': 1.0}]",パラメトリック
2874,3335,parametric family,パラメトリックファミリー,0.8,10,"[{'word': 'パラメトリックファミリー', 'ratio': 0.8}, {'word': 'パラメトリック ファミリ', 'ratio': 0.2}]",パラメトリックファミリー
2875,3336,parametric knowledge,パラメトリック知識,1.0,10,"[{'word': 'パラメトリック知識', 'ratio': 1.0}]",パラメトリック知識
2876,3337,parametric model,パラメトリックモデル,1.0,10,"[{'word': 'パラメトリックモデル', 'ratio': 1.0}]",パラメトリックモデル
2877,3338,parametrization,パラメータ化,0.9,10,"[{'word': 'パラメータ化', 'ratio': 0.9}, {'word': 'パラメトリゼーション', 'ratio': 0.1}]",パラメータ化
2878,3339,paraphrase,言い換え,0.2,10,"[{'word': 'パラフレーズ', 'ratio': 0.6}, {'word': '言い換える', 'ratio': 0.2}, {'word': '言い換え', 'ratio': 0.2}]",パラフレーズ
2879,3340,paraphrase generation,言い換え生成,0.2,10,"[{'word': 'パラフレーズ生成', 'ratio': 0.7}, {'word': '言い換え生成', 'ratio': 0.2}, {'word': '言い換えの生成', 'ratio': 0.1}]",パラフレーズ生成
2880,3341,paraphrase generator,言い換え生成器,0.2,10,"[{'word': 'パラフレーズ生成器', 'ratio': 0.5}, {'word': '言い換え生成器', 'ratio': 0.2}, {'word': 'パラフレーズジェネレータ', 'ratio': 0.1}, {'word': '言い換えジェネレーター', 'ratio': 0.1}, {'word': 'パラフレーズジェネレーター', 'ratio': 0.1}]",パラフレーズ生成器
2881,3342,paraphrase identification,言い換え識別,0.2,10,"[{'word': 'パラフレーズ識別', 'ratio': 0.5}, {'word': 'パラフレーズ同定', 'ratio': 0.2}, {'word': '言い換え識別', 'ratio': 0.2}, {'word': '言い換えの識別', 'ratio': 0.1}]",パラフレーズ識別
2882,3343,paraphrase model,言い換えモデル,0.3,10,"[{'word': 'パラフレーズモデル', 'ratio': 0.7}, {'word': '言い換えモデル', 'ratio': 0.3}]",パラフレーズモデル
2883,3344,parent node,親ノード,1.0,10,"[{'word': '親ノード', 'ratio': 1.0}]",親ノード
2884,3346,parse chart,構文解析チャート,0.3,10,"[{'word': '解析チャート', 'ratio': 0.5}, {'word': '構文解析チャート', 'ratio': 0.3}, {'word': 'パースチャート', 'ratio': 0.2}]",解析チャート
2885,3348,parse score,構文解析スコア,0.3,10,"[{'word': '解析スコア', 'ratio': 0.5}, {'word': '構文解析スコア', 'ratio': 0.3}, {'word': 'パーススコア', 'ratio': 0.2}]",解析スコア
2886,3350,parse tree,構文木,0.5,10,"[{'word': '構文木', 'ratio': 0.5}, {'word': '解析木', 'ratio': 0.3}, {'word': '解析ツリー', 'ratio': 0.1}, {'word': 'パースツリー', 'ratio': 0.1}]",構文木
2887,3351,parser,構文解析器,0.35,20,"[{'word': 'パーサー', 'ratio': 0.7}, {'word': 'パーサ', 'ratio': 0.2}, {'word': '解析器', 'ratio': 0.1}]",パーサー
2888,3352,parsing accuracy,構文解析精度,0.6,10,"[{'word': '構文解析精度', 'ratio': 0.6}, {'word': 'パース精度', 'ratio': 0.3}, {'word': '解析精度', 'ratio': 0.1}]",構文解析精度
2889,3353,parsing algorithm,構文解析アルゴリズム,0.6,10,"[{'word': '構文解析アルゴリズム', 'ratio': 0.6}, {'word': '解析アルゴリズム', 'ratio': 0.3}, {'word': 'パーシングアルゴリズム', 'ratio': 0.1}]",構文解析アルゴリズム
2890,3354,parsing model,構文解析モデル,0.6,10,"[{'word': '構文解析モデル', 'ratio': 0.6}, {'word': '解析モデル', 'ratio': 0.3}, {'word': 'パーシングモデル', 'ratio': 0.1}]",構文解析モデル
2891,3355,parsing performance,構文解析性能,0.5,10,"[{'word': '構文解析性能', 'ratio': 0.5}, {'word': '解析性能', 'ratio': 0.2}, {'word': 'パーシング性能', 'ratio': 0.1}, {'word': '解析パフォーマンス', 'ratio': 0.1}, {'word': 'パース性能', 'ratio': 0.1}]",構文解析性能
2892,3356,part of speech,品詞,1.0,10,"[{'word': '品詞', 'ratio': 1.0}]",品詞
2893,3357,part of speech tag,品詞タグ,1.0,10,"[{'word': '品詞タグ', 'ratio': 1.0}]",品詞タグ
2894,3358,part of speech tagger,品詞タガー,0.0,10,"[{'word': '品詞タグ付け器', 'ratio': 0.7}, {'word': 'Letter n-gram', 'ratio': 0.1}, {'word': '品詞タグ付け', 'ratio': 0.1}, {'word': 'Wagaku Bungo Tagger', 'ratio': 0.1}]",品詞タグ付け器
2895,3359,partial assignment,部分割り当て,0.6,10,"[{'word': '部分割り当て', 'ratio': 0.6}, {'word': '部分割当て', 'ratio': 0.2}, {'word': '部分的な代入', 'ratio': 0.1}, {'word': 'Junkan Anshin', 'ratio': 0.1}]",部分割り当て
2896,3361,partial evaluation,部分評価,0.8,10,"[{'word': '部分評価', 'ratio': 0.8}, {'word': '部分的な評価', 'ratio': 0.1}, {'word': 'Junkan Hyōka', 'ratio': 0.1}]",部分評価
2897,3362,partial observability,部分的観測可能性,0.0,10,"[{'word': '部分可観測性', 'ratio': 0.5}, {'word': '部分観測性', 'ratio': 0.2}, {'word': '部分観測可能性', 'ratio': 0.1}, {'word': '部分的な可観測性', 'ratio': 0.1}, {'word': 'Junkan Kanri', 'ratio': 0.1}]",部分可観測性
2898,3363,partial order,半順序,0.1,10,"[{'word': '部分順序', 'ratio': 0.8}, {'word': 'パーシャルオーダー', 'ratio': 0.1}, {'word': '半順序', 'ratio': 0.1}]",部分順序
2899,3365,partition,分割,0.8,10,"[{'word': '分割', 'ratio': 0.8}, {'word': 'パーティション', 'ratio': 0.2}]",分割
2900,3366,partition function,分配関数,0.8,10,"[{'word': '分配関数', 'ratio': 0.8}, {'word': 'パーティション関数', 'ratio': 0.2}]",分配関数
2901,3367,patch,パッチ,1.0,10,"[{'word': 'パッチ', 'ratio': 1.0}]",パッチ
2902,3369,path planning,経路計画,0.5,10,"[{'word': '経路計画', 'ratio': 0.5}, {'word': 'パスプランニング', 'ratio': 0.2}, {'word': 'パス・プランニング', 'ratio': 0.1}, {'word': 'パス計画', 'ratio': 0.1}, {'word': 'パスの計画', 'ratio': 0.1}]",経路計画
2903,3370,pattern profile,パターンプロファイル,1.0,10,"[{'word': 'パターンプロファイル', 'ratio': 1.0}]",パターンプロファイル
2904,3371,pattern recognition,パターン認識,1.0,10,"[{'word': 'パターン認識', 'ratio': 1.0}]",パターン認識
2905,3374,payoff function,報酬関数,0.1,10,"[{'word': 'ペイオフ関数', 'ratio': 0.8}, {'word': '支払い関数', 'ratio': 0.1}, {'word': '報酬関数', 'ratio': 0.1}]",ペイオフ関数
2906,3375,payoff matrix,支払い行列,0.1,10,"[{'word': 'ペイオフ行列', 'ratio': 0.7}, {'word': '支払い行列', 'ratio': 0.1}, {'word': '利得行列', 'ratio': 0.1}, {'word': '報酬関数', 'ratio': 0.1}]",ペイオフ行列
2907,3376,pedestrian detection,歩行者検出,0.8,10,"[{'word': '歩行者検出', 'ratio': 0.8}, {'word': '歩行者検知', 'ratio': 0.2}]",歩行者検出
2908,3377,penalty function,罰則関数,0.0,10,"[{'word': 'ペナルティ関数', 'ratio': 0.9}, {'word': '罰関数', 'ratio': 0.1}]",ペナルティ関数
2909,3378,penalty parameter,罰則パラメータ,0.0,10,"[{'word': 'ペナルティパラメータ', 'ratio': 0.9}, {'word': 'ペナルティパラメーター', 'ratio': 0.1}]",ペナルティパラメータ
2910,3379,penalty term,罰則項,0.0,10,"[{'word': 'ペナルティ項', 'ratio': 0.8}, {'word': '罰則期間', 'ratio': 0.1}, {'word': '違約金', 'ratio': 0.1}]",ペナルティ項
2911,3381,perception,認識 (Ninshiki),0.0,10,"[{'word': '知覚', 'ratio': 0.7}, {'word': '認識', 'ratio': 0.1}, {'word': '感知', 'ratio': 0.1}, {'word': '感覚', 'ratio': 0.1}]",知覚
2912,3382,perceptron algorithm,パーセプトロンアルゴリズム,1.0,10,"[{'word': 'パーセプトロンアルゴリズム', 'ratio': 1.0}]",パーセプトロンアルゴリズム
2913,3383,perceptual feature,知覚特徴,0.2222222222222222,9,"[{'word': '知覚的特徴', 'ratio': 0.5555555555555556}, {'word': '知覚特徴', 'ratio': 0.2222222222222222}, {'word': '知覚機能', 'ratio': 0.2222222222222222}]",知覚的特徴
2914,3385,perfect matching,完全マッチング,0.7777777777777778,9,"[{'word': '完全マッチング', 'ratio': 0.7777777777777778}, {'word': '完全一致', 'ratio': 0.1111111111111111}, {'word': '完璧なマッチング', 'ratio': 0.1111111111111111}]",完全マッチング
2915,3387,permutation,置換,0.2222222222222222,9,"[{'word': '順列', 'ratio': 0.5555555555555556}, {'word': '置換', 'ratio': 0.2222222222222222}, {'word': '並べ替え', 'ratio': 0.1111111111111111}, {'word': '排列', 'ratio': 0.1111111111111111}]",順列
2916,3388,permutation invariance,置換不変性,0.2,10,"[{'word': '順列不変性', 'ratio': 0.5}, {'word': '置換不変性', 'ratio': 0.2}, {'word': '順序不変性', 'ratio': 0.2}, {'word': 'パーミュテーション不変性', 'ratio': 0.1}]",順列不変性
2917,3389,permutation matrix,置換行列,0.2,10,"[{'word': '順列行列', 'ratio': 0.6}, {'word': '置換行列', 'ratio': 0.2}, {'word': 'パーミュテーション行列', 'ratio': 0.1}, {'word': '順序行列', 'ratio': 0.1}]",順列行列
2918,3393,perspective projection,遠近法射影,0.0,10,"[{'word': '透視投影', 'ratio': 0.5}, {'word': 'パースペクティブ投影', 'ratio': 0.2}, {'word': '視点投影', 'ratio': 0.1}, {'word': '遠近投影', 'ratio': 0.1}, {'word': 'kankei seiseki', 'ratio': 0.1}]",透視投影
2919,3394,perspective projection matrix,遠近投影行列,0.1,10,"[{'word': '透視投影行列', 'ratio': 0.5}, {'word': 'パースペクティブ投影行列', 'ratio': 0.2}, {'word': '視点投影行列', 'ratio': 0.1}, {'word': '遠近投影行列', 'ratio': 0.1}, {'word': 'kankei seiseki hatsuden matrix', 'ratio': 0.1}]",透視投影行列
2920,3395,perturbation,摂動,0.7,10,"[{'word': '摂動', 'ratio': 0.7}, {'word': '撹乱', 'ratio': 0.1}, {'word': 'henshin', 'ratio': 0.1}, {'word': '摺動', 'ratio': 0.1}]",摂動
2921,3397,perturbation variance,摂動分散,0.7,10,"[{'word': '摂動分散', 'ratio': 0.7}, {'word': '擾乱分散', 'ratio': 0.3}]",摂動分散
2922,3399,phoneme,音素,1.0,10,"[{'word': '音素', 'ratio': 1.0}]",音素
2923,3400,phoneme segmentation,音素セグメンテーション,0.6,10,"[{'word': '音素セグメンテーション', 'ratio': 0.6}, {'word': '音素分割', 'ratio': 0.4}]",音素セグメンテーション
2924,3402,photometric consistency,光度一貫性 (koudo ikanssei),0.0,10,"[{'word': '光度的一貫性', 'ratio': 0.5}, {'word': '光学的一貫性', 'ratio': 0.3}, {'word': '測光の一貫性', 'ratio': 0.1}, {'word': 'フォトメトリックコンシステンシー', 'ratio': 0.1}]",光度的一貫性
2925,3403,photometric error,光度誤差,0.5,10,"[{'word': '光度誤差', 'ratio': 0.5}, {'word': '光学的誤差', 'ratio': 0.3}, {'word': '測光誤差', 'ratio': 0.2}]",光度誤差
2926,3404,photometric loss,光度損失,0.5,10,"[{'word': '光度損失', 'ratio': 0.5}, {'word': '光学的損失', 'ratio': 0.3}, {'word': '測光損失', 'ratio': 0.1}, {'word': '光量損失', 'ratio': 0.1}]",光度損失
2927,3405,photometric stereo,光度立体法,0.0,10,"[{'word': '光度ステレオ', 'ratio': 0.5}, {'word': '光学的ステレオ', 'ratio': 0.2}, {'word': '測光ステレオ', 'ratio': 0.1}, {'word': '光学ステレオ', 'ratio': 0.1}, {'word': 'フォトメトリックステレオ', 'ratio': 0.1}]",光度ステレオ
2928,3407,phrase table,フレーズテーブル,0.9,10,"[{'word': 'フレーズテーブル', 'ratio': 0.9}, {'word': 'トレーニング / テスト / 調整割', 'ratio': 0.1}]",フレーズテーブル
2929,3410,pipeline,パイプライン,0.8888888888888888,9,"[{'word': 'パイプライン', 'ratio': 0.8888888888888888}, {'word': 'トレーニング/テスト', 'ratio': 0.1111111111111111}]",パイプライン
2930,3411,pixel,ピクセル,1.0,10,"[{'word': 'ピクセル', 'ratio': 1.0}]",ピクセル
2931,3412,pixel labeling,ピクセルラベリング,0.9,10,"[{'word': 'ピクセルラベリング', 'ratio': 0.9}, {'word': 'ピクセルのラベリング', 'ratio': 0.1}]",ピクセルラベリング
2932,3413,pixel-level,ピクセルレベル,1.0,10,"[{'word': 'ピクセルレベル', 'ratio': 1.0}]",ピクセルレベル
2933,3414,pixel-wise,ピクセル単位で,0.1,10,"[{'word': 'ピクセル単位', 'ratio': 0.9}, {'word': 'ピクセル単位で', 'ratio': 0.1}]",ピクセル単位
2934,3415,place recognition,場所認識,0.9,10,"[{'word': '場所認識', 'ratio': 0.9}, {'word': '場所の認識', 'ratio': 0.1}]",場所認識
2935,3416,placeholder,プレースホルダー,1.0,10,"[{'word': 'プレースホルダー', 'ratio': 1.0}]",プレースホルダー
2936,3417,planning,計画,1.0,10,"[{'word': '計画', 'ratio': 1.0}]",計画
2937,3418,planning problem,計画問題,0.8,10,"[{'word': '計画問題', 'ratio': 0.8}, {'word': '計画の問題', 'ratio': 0.2}]",計画問題
2938,3419,planning task,計画問題,0.0,10,"[{'word': '計画タスク', 'ratio': 1.0}]",計画タスク
2939,3420,plug-in estimator,プラグイン推定器,0.0,10,"[{'word': 'プラグイン推定量', 'ratio': 0.8}, {'word': 'プラグイン推定ツール', 'ratio': 0.2}]",プラグイン推定量
2940,3422,point cloud,点群,0.6,10,"[{'word': '点群', 'ratio': 0.6}, {'word': 'ポイントクラウド', 'ratio': 0.3}, {'word': '3Dポイントクラウド', 'ratio': 0.1}]",点群
2941,3424,point estimate,点推定,0.5,10,"[{'word': '点推定', 'ratio': 0.5}, {'word': 'ポイント推定', 'ratio': 0.4}, {'word': '推定点', 'ratio': 0.1}]",点推定
2942,3425,point match,点の対応付け,0.0,10,"[{'word': 'ポイントマッチ', 'ratio': 0.5}, {'word': '点一致', 'ratio': 0.2}, {'word': '点マッチ', 'ratio': 0.2}, {'word': 'ポイントのマッチング', 'ratio': 0.1}]",ポイントマッチ
2943,3427,pointwise multiplication,要素積,0.0,10,"[{'word': '点ごとの乗算', 'ratio': 0.6}, {'word': 'ポイントワイズ乗算', 'ratio': 0.2}, {'word': 'べき乗算', 'ratio': 0.1}, {'word': '点ごとの積', 'ratio': 0.1}]",点ごとの乗算
2944,3429,policy class,ポリシークラス,0.5,10,"[{'word': 'ポリシークラス', 'ratio': 0.5}, {'word': '方策クラス', 'ratio': 0.4}, {'word': '方針クラス', 'ratio': 0.1}]",ポリシークラス
2945,3431,policy entropy,方策エントロピー,0.3,10,"[{'word': 'ポリシーエントロピー', 'ratio': 0.5}, {'word': '方策エントロピー', 'ratio': 0.3}, {'word': '政策エントロピー', 'ratio': 0.1}, {'word': 'ポリシーのエントロピー', 'ratio': 0.1}]",ポリシーエントロピー
2946,3432,policy evaluation,方策評価,0.3,10,"[{'word': 'ポリシー評価', 'ratio': 0.5}, {'word': '方策評価', 'ratio': 0.3}, {'word': '政策評価', 'ratio': 0.2}]",ポリシー評価
2947,3434,policy gradient algorithm,方策勾配アルゴリズム,0.3,10,"[{'word': 'ポリシー勾配アルゴリズム', 'ratio': 0.5}, {'word': '方策勾配アルゴリズム', 'ratio': 0.3}, {'word': 'ポリシーグラデントアルゴリズム', 'ratio': 0.1}, {'word': '政策勾配アルゴリズム', 'ratio': 0.1}]",ポリシー勾配アルゴリズム
2948,3435,policy gradient estimator,方策勾配推定子,0.0,10,"[{'word': 'ポリシー勾配推定器', 'ratio': 0.5}, {'word': '方策勾配推定器', 'ratio': 0.2}, {'word': 'ポリシーグラデント推定器', 'ratio': 0.1}, {'word': '政策勾配推定量', 'ratio': 0.1}, {'word': '方策勾配推定量', 'ratio': 0.1}]",ポリシー勾配推定器
2949,3436,policy gradient method,方策勾配法,0.0,10,"[{'word': 'ポリシー勾配法', 'ratio': 0.9}, {'word': '政策勾配法', 'ratio': 0.1}]",ポリシー勾配法
2950,3437,policy gradient theorem,方策勾配定理,0.0,10,"[{'word': 'ポリシー勾配定理', 'ratio': 0.8}, {'word': '政策勾配の定理', 'ratio': 0.1}, {'word': '政策勾配定理', 'ratio': 0.1}]",ポリシー勾配定理
2951,3438,policy improvement,方策改善,0.0,10,"[{'word': 'ポリシー改善', 'ratio': 0.8}, {'word': '政策改善', 'ratio': 0.2}]",ポリシー改善
2952,3439,policy iteration,ポリシーイテレーション,0.0,10,"[{'word': 'ポリシー反復', 'ratio': 0.7}, {'word': '政策の反復', 'ratio': 0.1}, {'word': 'ポリシーの反復', 'ratio': 0.1}, {'word': 'ポリシー反復法', 'ratio': 0.1}]",ポリシー反復
2953,3440,policy learning,"""方策学習""",0.0,10,"[{'word': 'ポリシー学習', 'ratio': 0.8}, {'word': '政策学習', 'ratio': 0.2}]",ポリシー学習
2954,3441,policy network,ポリシーネットワーク,0.8,10,"[{'word': 'ポリシーネットワーク', 'ratio': 0.8}, {'word': '政策ネットワーク', 'ratio': 0.2}]",ポリシーネットワーク
2955,3442,policy optimization,方策最適化,0.0,10,"[{'word': 'ポリシー最適化', 'ratio': 0.8}, {'word': 'ポリシーの最適化', 'ratio': 0.2}]",ポリシー最適化
2956,3443,policy parameter,ポリシーパラメータ,1.0,10,"[{'word': 'ポリシーパラメータ', 'ratio': 1.0}]",ポリシーパラメータ
2957,3444,policy representation,方策表現,0.0,10,"[{'word': 'ポリシー表現', 'ratio': 0.8}, {'word': '政策の表明', 'ratio': 0.2}]",ポリシー表現
2958,3445,policy sketch,方針スケッチ,0.0,10,"[{'word': 'ポリシースケッチ', 'ratio': 0.8}, {'word': '政策スケッチ', 'ratio': 0.2}]",ポリシースケッチ
2959,3446,policy space,ポリシースペース,0.7,10,"[{'word': 'ポリシースペース', 'ratio': 0.7}, {'word': '政策空間', 'ratio': 0.2}, {'word': 'ポリシー空間', 'ratio': 0.1}]",ポリシースペース
2960,3447,polygon mesh,ポリゴンメッシュ,1.0,10,"[{'word': 'ポリゴンメッシュ', 'ratio': 1.0}]",ポリゴンメッシュ
2961,3448,polylog,ポリログ,1.0,10,"[{'word': 'ポリログ', 'ratio': 1.0}]",ポリログ
2962,3450,polynomial,多項式,0.9,10,"[{'word': '多項式', 'ratio': 0.9}, {'word': '多項式多項式', 'ratio': 0.1}]",多項式
2963,3451,polynomial delay,多項式遅延,1.0,10,"[{'word': '多項式遅延', 'ratio': 1.0}]",多項式遅延
2964,3452,polynomial kernel,多項式カーネル,1.0,10,"[{'word': '多項式カーネル', 'ratio': 1.0}]",多項式カーネル
2965,3453,polynomial time,多項式時間,1.0,10,"[{'word': '多項式時間', 'ratio': 1.0}]",多項式時間
2966,3454,polynomial time algorithm,多項式時間アルゴリズム,1.0,10,"[{'word': '多項式時間アルゴリズム', 'ratio': 1.0}]",多項式時間アルゴリズム
2967,3455,pool-based active learning,プールベースのアクティブラーニング,0.8,10,"[{'word': 'プールベースのアクティブラーニング', 'ratio': 0.8}, {'word': 'プールベースのアクティブ・ラーニング', 'ratio': 0.1}, {'word': 'プールベース・アクティブラーニング', 'ratio': 0.1}]",プールベースのアクティブラーニング
2968,3456,pooling layer,プーリング層,0.8,10,"[{'word': 'プーリング層', 'ratio': 0.8}, {'word': 'プール層', 'ratio': 0.1}, {'word': 'プールレイヤー', 'ratio': 0.1}]",プーリング層
2969,3457,pooling operation,プーリング操作,0.8,10,"[{'word': 'プーリング操作', 'ratio': 0.8}, {'word': 'プール操作', 'ratio': 0.1}, {'word': 'ポーズ推定', 'ratio': 0.1}]",プーリング操作
2970,3458,pose estimation,姿勢推定,0.3,10,"[{'word': 'ポーズ推定', 'ratio': 0.6}, {'word': '姿勢推定', 'ratio': 0.3}, {'word': '設置見積もり', 'ratio': 0.1}]",ポーズ推定
2971,3459,pose parameter,姿勢パラメータ,0.2,10,"[{'word': 'ポーズパラメータ', 'ratio': 0.7}, {'word': '姿勢パラメータ', 'ratio': 0.2}, {'word': 'ポーズパラメーター', 'ratio': 0.1}]",ポーズパラメータ
2972,3461,pose space,姿勢空間,0.0,10,"[{'word': 'ポーズ空間', 'ratio': 0.8}, {'word': 'ポーズスペース', 'ratio': 0.2}]",ポーズ空間
2973,3462,position bias,位置バイアス,0.8,10,"[{'word': '位置バイアス', 'ratio': 0.8}, {'word': 'ポジションバイアス', 'ratio': 0.2}]",位置バイアス
2974,3463,position embedding,位置エンベッディング,0.0,10,"[{'word': '位置埋め込み', 'ratio': 0.8}, {'word': '位置の埋め込み', 'ratio': 0.1}, {'word': 'ポジションエンベディング', 'ratio': 0.1}]",位置埋め込み
2975,3464,positional bias,位置バイアス,0.1,10,"[{'word': 'ポジショナルバイアス', 'ratio': 0.6}, {'word': '位置的バイアス', 'ratio': 0.1}, {'word': 'ポジション・バイアス', 'ratio': 0.1}, {'word': '位置の偏り', 'ratio': 0.1}, {'word': '位置バイアス', 'ratio': 0.1}]",ポジショナルバイアス
2976,3465,positional embedding,位置埋め込み,0.3,10,"[{'word': 'ポジショナル埋め込み', 'ratio': 0.5}, {'word': '位置埋め込み', 'ratio': 0.3}, {'word': '位置的埋め込み', 'ratio': 0.1}, {'word': 'ポジショナルエンベディング', 'ratio': 0.1}]",ポジショナル埋め込み
2977,3466,positional encoding,位置エンコーディング,0.9,10,"[{'word': '位置エンコーディング', 'ratio': 0.9}, {'word': '位相エンコーディング', 'ratio': 0.1}]",位置エンコーディング
2978,3467,positive definite,正定値,1.0,10,"[{'word': '正定値', 'ratio': 1.0}]",正定値
2979,3468,positive pair,正サンプル対,0.0,10,"[{'word': '正のペア', 'ratio': 0.7}, {'word': '正の対', 'ratio': 0.1}, {'word': 'ポジティブ・ペア', 'ratio': 0.1}, {'word': 'ポジティブペア', 'ratio': 0.1}]",正のペア
2980,3469,positive semidefinite,正の半定値,0.1,10,"[{'word': '正半定値', 'ratio': 0.8}, {'word': '正半正定値', 'ratio': 0.1}, {'word': '正の半定値', 'ratio': 0.1}]",正半定値
2981,3470,positive semidefinite kernel,正の半定値カーネル,0.1,10,"[{'word': '正半定値カーネル', 'ratio': 0.8}, {'word': '正半正定値カーネル', 'ratio': 0.1}, {'word': '正の半定値カーネル', 'ratio': 0.1}]",正半定値カーネル
2982,3472,post-editing,事後編集,0.0,10,"[{'word': 'ポストエディティング', 'ratio': 0.7}, {'word': 'ポスト編集', 'ratio': 0.2}, {'word': 'ポストエディット', 'ratio': 0.1}]",ポストエディティング
2983,3473,post-hoc,事後的な,0.1,10,"[{'word': 'ポストホック', 'ratio': 0.7}, {'word': '事後的な', 'ratio': 0.1}, {'word': 'ポスト facto', 'ratio': 0.1}, {'word': '事後', 'ratio': 0.1}]",ポストホック
2984,3474,post-hoc analysis,事後分析,0.3,10,"[{'word': 'ポストホック分析', 'ratio': 0.6}, {'word': '事後分析', 'ratio': 0.3}, {'word': 'ポスト facto 分析', 'ratio': 0.1}]",ポストホック分析
2985,3475,post-processing,後処理,0.3,10,"[{'word': 'ポストプロセッシング', 'ratio': 0.6}, {'word': '後処理', 'ratio': 0.3}, {'word': 'ポスト処理', 'ratio': 0.1}]",ポストプロセッシング
2986,3477,posterior approximation,事後近似,0.9,10,"[{'word': '事後近似', 'ratio': 0.9}, {'word': '後続的近似', 'ratio': 0.1}]",事後近似
2987,3478,posterior density,事後密度,0.9,10,"[{'word': '事後密度', 'ratio': 0.9}, {'word': '後続的密度', 'ratio': 0.1}]",事後密度
2988,3479,posterior distribution,事後分布,0.9,10,"[{'word': '事後分布', 'ratio': 0.9}, {'word': '後続的分布', 'ratio': 0.1}]",事後分布
2989,3480,posterior entropy,事後エントロピー,0.8,10,"[{'word': '事後エントロピー', 'ratio': 0.8}, {'word': '事後分布', 'ratio': 0.1}, {'word': '後続的エントロピー', 'ratio': 0.1}]",事後エントロピー
2990,3481,posterior estimation,事後推定,0.9,10,"[{'word': '事後推定', 'ratio': 0.9}, {'word': '後続推定', 'ratio': 0.1}]",事後推定
2991,3482,posterior inference,事後推論,0.9,10,"[{'word': '事後推論', 'ratio': 0.9}, {'word': '後続推定法', 'ratio': 0.1}]",事後推論
2992,3483,posterior mean,事後平均,0.9,10,"[{'word': '事後平均', 'ratio': 0.9}, {'word': '後続平均', 'ratio': 0.1}]",事後平均
2993,3484,posterior mean function,事後平均関数,0.9,10,"[{'word': '事後平均関数', 'ratio': 0.9}, {'word': '後続平均関数', 'ratio': 0.1}]",事後平均関数
2994,3485,posterior probability,事後確率,0.9,10,"[{'word': '事後確率', 'ratio': 0.9}, {'word': '後続確率', 'ratio': 0.1}]",事後確率
2995,3486,posterior probability distribution,事後確率分布,1.0,9,"[{'word': '事後確率分布', 'ratio': 1.0}]",事後確率分布
2996,3487,posterior sample,事後サンプル,1.0,9,"[{'word': '事後サンプル', 'ratio': 1.0}]",事後サンプル
2997,3488,posterior variance,事後分散,1.0,9,"[{'word': '事後分散', 'ratio': 1.0}]",事後分散
2998,3489,potential function,ポテンシャル関数,0.7777777777777778,9,"[{'word': 'ポテンシャル関数', 'ratio': 0.7777777777777778}, {'word': 'ポテンシャル機能', 'ratio': 0.2222222222222222}]",ポテンシャル関数
2999,3490,potential heuristic,潜在ヒューリスティック,0.0,9,"[{'word': 'ポテンシャルヒューリスティック', 'ratio': 0.7777777777777778}, {'word': '潜在的ヒューリスティック', 'ratio': 0.2222222222222222}]",ポテンシャルヒューリスティック
3000,3493,power method,パワーメソッド (power method),0.0,10,"[{'word': 'パワー法', 'ratio': 0.6}, {'word': 'べき乗法', 'ratio': 0.2}, {'word': 'パワーの法', 'ratio': 0.1}, {'word': '冪法', 'ratio': 0.1}]",パワー法
3001,3494,pre-logit,前段ロジット,0.0,10,"[{'word': 'プレロジット', 'ratio': 0.8}, {'word': '前対数', 'ratio': 0.1}, {'word': '前ロジット', 'ratio': 0.1}]",プレロジット
3002,3495,pre-processing,前処理,1.0,10,"[{'word': '前処理', 'ratio': 1.0}]",前処理
3003,3501,pre-trained model,事前学習済みモデル,0.2,10,"[{'word': '事前学習モデル', 'ratio': 0.5}, {'word': '事前学習済みモデル', 'ratio': 0.2}, {'word': '学習済みモデル', 'ratio': 0.1}, {'word': 'プレトレーニングモデル', 'ratio': 0.1}, {'word': '事前トレーニングされたモデル', 'ratio': 0.1}]",事前学習モデル
3004,3504,pre-training corpus,事前学習コーパス,0.8,10,"[{'word': '事前学習コーパス', 'ratio': 0.8}, {'word': 'プレトレーニングコーパス', 'ratio': 0.1}, {'word': 'トレーニング前コーパス', 'ratio': 0.1}]",事前学習コーパス
3005,3505,pre-training datum,事前学習データ,0.7,10,"[{'word': '事前学習データ', 'ratio': 0.7}, {'word': '事前トレーニングデータ', 'ratio': 0.2}, {'word': 'プレトレーニングデータ', 'ratio': 0.1}]",事前学習データ
3006,3507,pre-training task,事前学習タスク,0.5,10,"[{'word': '事前学習タスク', 'ratio': 0.5}, {'word': 'プレトレーニングタスク', 'ratio': 0.3}, {'word': '事前トレーニングタスク', 'ratio': 0.1}, {'word': '事前訓練タスク', 'ratio': 0.1}]",事前学習タスク
3007,3508,precision matrix,精度行列,0.9,10,"[{'word': '精度行列', 'ratio': 0.9}, {'word': '精密マトリックス', 'ratio': 0.1}]",精度行列
3008,3510,precision-recall curve,精度-再現率曲線,0.7,10,"[{'word': '精度-再現率曲線', 'ratio': 0.7}, {'word': '適合率-再現率曲線', 'ratio': 0.2}, {'word': '精度再現曲線', 'ratio': 0.1}]",精度-再現率曲線
3009,3511,precision-recall graph,適合率-再現率グラフ,0.1,10,"[{'word': '精度-再現率グラフ', 'ratio': 0.7}, {'word': 'プレシジョンリコールグラフ', 'ratio': 0.1}, {'word': '適合率-再現率グラフ', 'ratio': 0.1}, {'word': '適合率と再現率のグラフ', 'ratio': 0.1}]",精度-再現率グラフ
3010,3512,precondition,前提条件,1.0,10,"[{'word': '前提条件', 'ratio': 1.0}]",前提条件
3011,3513,preconditioner,事前処理器,0.0,10,"[{'word': '前処理器', 'ratio': 0.6}, {'word': 'プリコンディショナー', 'ratio': 0.1}, {'word': 'プレコンディショナー', 'ratio': 0.1}, {'word': '前提条件器', 'ratio': 0.1}, {'word': '前処理行列', 'ratio': 0.1}]",前処理器
3012,3514,predicate,述語,0.6,20,"[{'word': '述語', 'ratio': 0.6}, {'word': '命題', 'ratio': 0.4}]",述語
3013,3515,predicate logic,述語論理,0.5,10,"[{'word': '述語論理', 'ratio': 0.5}, {'word': '命題論理', 'ratio': 0.5}]",述語論理
3014,3516,predicate symbol,述語記号,0.5,10,"[{'word': '述語記号', 'ratio': 0.5}, {'word': '命題記号', 'ratio': 0.5}]",述語記号
3015,3517,predicate-argument relation,述語と引数の関係,0.1,10,"[{'word': '命題-引数関係', 'ratio': 0.5}, {'word': '述語-引数関係', 'ratio': 0.3}, {'word': '述語引数関係', 'ratio': 0.1}, {'word': '述語と引数の関係', 'ratio': 0.1}]",命題-引数関係
3016,3518,predicate-argument structure,述語論項構造,0.0,10,"[{'word': '命題-引数構造', 'ratio': 0.5}, {'word': '述語-引数構造', 'ratio': 0.4}, {'word': '述語と引数の構造', 'ratio': 0.1}]",命題-引数構造
3017,3519,prediction,予測,1.0,20,"[{'word': '予測', 'ratio': 1.0}]",予測
3018,3520,prediction accuracy,予測精度,1.0,10,"[{'word': '予測精度', 'ratio': 1.0}]",予測精度
3019,3521,prediction entropy,予測エントロピー,0.9,10,"[{'word': '予測エントロピー', 'ratio': 0.9}, {'word': '予測エントロピ', 'ratio': 0.1}]",予測エントロピー
3020,3522,prediction error,予測誤差,1.0,10,"[{'word': '予測誤差', 'ratio': 1.0}]",予測誤差
3021,3523,prediction head,予測ヘッド,1.0,10,"[{'word': '予測ヘッド', 'ratio': 1.0}]",予測ヘッド
3022,3524,prediction invariance,予測不変性,0.8,10,"[{'word': '予測不変性', 'ratio': 0.8}, {'word': '予測の不変性', 'ratio': 0.2}]",予測不変性
3023,3525,prediction model,予測モデル,1.0,10,"[{'word': '予測モデル', 'ratio': 1.0}]",予測モデル
3024,3526,prediction network,予測ネットワーク,1.0,10,"[{'word': '予測ネットワーク', 'ratio': 1.0}]",予測ネットワーク
3025,3527,prediction variance,予測分散,0.8,10,"[{'word': '予測分散', 'ratio': 0.8}, {'word': '予測の分散', 'ratio': 0.2}]",予測分散
3026,3528,predictive coding,予測符号化,0.3,10,"[{'word': '予測コーディング', 'ratio': 0.7}, {'word': '予測符号化', 'ratio': 0.3}]",予測コーディング
3027,3529,predictive distribution,予測分布,1.0,10,"[{'word': '予測分布', 'ratio': 1.0}]",予測分布
3028,3530,predictive likelihood,予測尤度,0.9,10,"[{'word': '予測尤度', 'ratio': 0.9}, {'word': '予測の有効度', 'ratio': 0.1}]",予測尤度
3029,3531,predictive model,予測モデル,1.0,10,"[{'word': '予測モデル', 'ratio': 1.0}]",予測モデル
3030,3532,predictive performance,予測性能,1.0,10,"[{'word': '予測性能', 'ratio': 1.0}]",予測性能
3031,3533,predictor,予測子,0.3,10,"[{'word': '予測器', 'ratio': 0.6}, {'word': '予測子', 'ratio': 0.3}, {'word': '預言者', 'ratio': 0.1}]",予測器
3032,3534,prefix,接頭辞 (prefix),0.0,10,"[{'word': '接頭辞', 'ratio': 0.5}, {'word': 'プレフィックス', 'ratio': 0.4}, {'word': '接頭語', 'ratio': 0.1}]",接頭辞
3033,3536,prefix tree,接頭辞木,0.5,10,"[{'word': '接頭辞木', 'ratio': 0.5}, {'word': 'プレフィックスツリー', 'ratio': 0.3}, {'word': '接頭辞ツリー', 'ratio': 0.1}, {'word': 'プレフィックス・ツリー', 'ratio': 0.1}]",接頭辞木
3034,3537,preimage,先像,0.0,10,"[{'word': '逆像', 'ratio': 0.6}, {'word': 'プレイメージ', 'ratio': 0.1}, {'word': '前画像', 'ratio': 0.1}, {'word': '前像', 'ratio': 0.1}, {'word': 'プリ画像', 'ratio': 0.1}]",逆像
3035,3538,prepositional phrase,前置詞句,1.0,10,"[{'word': '前置詞句', 'ratio': 1.0}]",前置詞句
3036,3539,preprocessing phase,前処理段階,0.2,10,"[{'word': '前処理フェーズ', 'ratio': 0.8}, {'word': '前処理段階', 'ratio': 0.2}]",前処理フェーズ
3037,3540,presence penalty,存在ペナルティ,0.8,10,"[{'word': '存在ペナルティ', 'ratio': 0.8}, {'word': 'けっきん', 'ratio': 0.1}, {'word': 'プレゼンスペナルティ', 'ratio': 0.1}]",存在ペナルティ
3038,3541,pretrained multilingual model,事前学習済み多言語モデル,0.9,10,"[{'word': '事前学習済み多言語モデル', 'ratio': 0.9}, {'word': '多言語モデル', 'ratio': 0.1}]",事前学習済み多言語モデル
3039,3542,primal objective function,原始目的関数,0.0,10,"[{'word': 'プライマル目的関数', 'ratio': 0.6}, {'word': '主目的関数', 'ratio': 0.2}, {'word': '主問題目的関数', 'ratio': 0.2}]",プライマル目的関数
3040,3543,primal optimization,プライマル最適化,0.6,10,"[{'word': 'プライマル最適化', 'ratio': 0.6}, {'word': '一次最適化', 'ratio': 0.2}, {'word': '主最適化', 'ratio': 0.2}]",プライマル最適化
3041,3544,primal problem,原始問題,0.0,10,"[{'word': 'プライマル問題', 'ratio': 0.6}, {'word': '根本的な問題', 'ratio': 0.2}, {'word': '主問題', 'ratio': 0.2}]",プライマル問題
3042,3545,primal variable,原始変数 (genshi hensu),0.0,10,"[{'word': 'プライマル変数', 'ratio': 0.9}, {'word': '原因変数', 'ratio': 0.1}]",プライマル変数
3043,3546,primal-dual algorithm,プライマル・デュアルアルゴリズム,0.6,10,"[{'word': 'プライマル・デュアルアルゴリズム', 'ratio': 0.6}, {'word': 'プライマルデュアルアルゴリズム', 'ratio': 0.2}, {'word': 'プライマル-デュアルアルゴリズム', 'ratio': 0.1}, {'word': '原始-ダブル アルゴリズム', 'ratio': 0.1}]",プライマル・デュアルアルゴリズム
3044,3547,primal-dual method,一次-双対法 (ichiji-sotai-ho),0.0,10,"[{'word': 'プライマル・デュアル法', 'ratio': 0.6}, {'word': 'プライマルデュアル法', 'ratio': 0.2}, {'word': 'プライマル-デュアル法', 'ratio': 0.1}, {'word': '原始-ダブル メソッド', 'ratio': 0.1}]",プライマル・デュアル法
3045,3548,primitive,基本形状,0.0,10,"[{'word': 'プリミティブ', 'ratio': 0.9}, {'word': '原始要素', 'ratio': 0.1}]",プリミティブ
3046,3549,principal component,主成分,0.9,10,"[{'word': '主成分', 'ratio': 0.9}, {'word': '主要成分', 'ratio': 0.1}]",主成分
3047,3550,prior distribution,事前分布,0.9,10,"[{'word': '事前分布', 'ratio': 0.9}, {'word': '事前配布', 'ratio': 0.1}]",事前分布
3048,3551,prior hyperparameter,事前ハイパーパラメータ,0.9,10,"[{'word': '事前ハイパーパラメータ', 'ratio': 0.9}, {'word': '前のハイパーパラメータ', 'ratio': 0.1}]",事前ハイパーパラメータ
3049,3552,prior knowledge,事前知識,0.9,10,"[{'word': '事前知識', 'ratio': 0.9}, {'word': '予備知識', 'ratio': 0.1}]",事前知識
3050,3553,prior mean,事前平均値,0.0,10,"[{'word': '事前平均', 'ratio': 1.0}]",事前平均
3051,3554,prior probability,事前確率,1.0,10,"[{'word': '事前確率', 'ratio': 1.0}]",事前確率
3052,3555,prior probability distribution,事前確率分布,1.0,10,"[{'word': '事前確率分布', 'ratio': 1.0}]",事前確率分布
3053,3556,prior variance,事前分散,0.8,10,"[{'word': '事前分散', 'ratio': 0.8}, {'word': '以前の差異', 'ratio': 0.2}]",事前分散
3054,3557,priority queue,優先度付きキュー,0.1,10,"[{'word': '優先キュー', 'ratio': 0.5}, {'word': '優先度キュー', 'ratio': 0.4}, {'word': '優先度付きキュー', 'ratio': 0.1}]",優先キュー
3055,3558,privacy budget,プライバシー予算,0.2,10,"[{'word': 'プライバシーバジェット', 'ratio': 0.6}, {'word': 'プライバシーの予算', 'ratio': 0.2}, {'word': 'プライバシー予算', 'ratio': 0.2}]",プライバシーバジェット
3056,3559,privacy-preserving data mining,プライバシー保護データマイニング,0.8,10,"[{'word': 'プライバシー保護データマイニング', 'ratio': 0.8}, {'word': 'プライバシーを保護するデータマイニング', 'ratio': 0.2}]",プライバシー保護データマイニング
3057,3560,probabilistic context-free grammar,確率的文脈自由文法,0.8,10,"[{'word': '確率的文脈自由文法', 'ratio': 0.8}, {'word': '確率文脈自由文法', 'ratio': 0.2}]",確率的文脈自由文法
3058,3561,probabilistic distribution,確率分布,1.0,10,"[{'word': '確率分布', 'ratio': 1.0}]",確率分布
3059,3562,probabilistic formulation,確率的定式化,1.0,10,"[{'word': '確率的定式化', 'ratio': 1.0}]",確率的定式化
3060,3563,probabilistic framework,確率的枠組み,0.5,10,"[{'word': '確率的枠組み', 'ratio': 0.5}, {'word': '確率的フレームワーク', 'ratio': 0.5}]",確率的枠組み
3061,3564,probabilistic generative model,確率生成モデル,0.0,10,"[{'word': '確率的生成モデル', 'ratio': 1.0}]",確率的生成モデル
3062,3565,probabilistic graphical model,確率的グラフィカルモデル,0.9,10,"[{'word': '確率的グラフィカルモデル', 'ratio': 0.9}, {'word': '確率グラフィカルモデール', 'ratio': 0.1}]",確率的グラフィカルモデル
3063,3566,probabilistic inference,確率的推論,1.0,10,"[{'word': '確率的推論', 'ratio': 1.0}]",確率的推論
3064,3568,probabilistic method,確率的手法,0.5,10,"[{'word': '確率的手法', 'ratio': 0.5}, {'word': '確率的方法', 'ratio': 0.5}]",確率的手法
3065,3569,probabilistic model,確率モデル,0.7,10,"[{'word': '確率モデル', 'ratio': 0.7}, {'word': '確率的モデル', 'ratio': 0.3}]",確率モデル
3066,3570,probabilistic relational model,確率的関係モデル,1.0,10,"[{'word': '確率的関係モデル', 'ratio': 1.0}]",確率的関係モデル
3067,3571,probabilistic representation,確率的表現,1.0,10,"[{'word': '確率的表現', 'ratio': 1.0}]",確率的表現
3068,3572,probabilistic semantic,確率的意味論,1.0,10,"[{'word': '確率的意味論', 'ratio': 1.0}]",確率的意味論
3069,3573,probabilistic topic modeling,確率的トピックモデリング,0.3,10,"[{'word': '確率的トピックモデル', 'ratio': 0.7}, {'word': '確率的トピックモデリング', 'ratio': 0.3}]",確率的トピックモデル
3070,3574,probabilistic tree,確率的木,0.7,10,"[{'word': '確率的木', 'ratio': 0.7}, {'word': '確率ツリー', 'ratio': 0.2}, {'word': '確率的木構造', 'ratio': 0.1}]",確率的木
3071,3575,probability density,確率密度,1.0,10,"[{'word': '確率密度', 'ratio': 1.0}]",確率密度
3072,3576,probability density function,確率密度関数,1.0,10,"[{'word': '確率密度関数', 'ratio': 1.0}]",確率密度関数
3073,3577,probability distribution,確率分布,1.0,10,"[{'word': '確率分布', 'ratio': 1.0}]",確率分布
3074,3578,probability flow,確率フロー,0.7,10,"[{'word': '確率フロー', 'ratio': 0.7}, {'word': '確率の流れ', 'ratio': 0.2}, {'word': '確率流', 'ratio': 0.1}]",確率フロー
3075,3579,probability map,確率マップ,0.8,10,"[{'word': '確率マップ', 'ratio': 0.8}, {'word': '確率地図', 'ratio': 0.2}]",確率マップ
3076,3580,probability mass,確率質量,1.0,10,"[{'word': '確率質量', 'ratio': 1.0}]",確率質量
3077,3581,probability mass function,確率質量関数,1.0,10,"[{'word': '確率質量関数', 'ratio': 1.0}]",確率質量関数
3078,3582,probability matrix,確率行列,1.0,10,"[{'word': '確率行列', 'ratio': 1.0}]",確率行列
3079,3583,probability measure,確率測度,0.8,10,"[{'word': '確率測度', 'ratio': 0.8}, {'word': '確率の尺度', 'ratio': 0.2}]",確率測度
3080,3584,probability model,確率モデル,1.0,10,"[{'word': '確率モデル', 'ratio': 1.0}]",確率モデル
3081,3585,probability multiset,確率マルチセット,0.1,10,"[{'word': '確率多集合', 'ratio': 0.5}, {'word': '確率多重集合', 'ratio': 0.4}, {'word': '確率マルチセット', 'ratio': 0.1}]",確率多集合
3082,3586,probability simplex,確率シンプレックス,0.2,10,"[{'word': '確率単体', 'ratio': 0.7}, {'word': '確率シンプレックス', 'ratio': 0.2}, {'word': '確率単極面', 'ratio': 0.1}]",確率単体
3083,3587,probability space,確率空間,1.0,10,"[{'word': '確率空間', 'ratio': 1.0}]",確率空間
3084,3588,probability threshold,確率閾値,0.8,10,"[{'word': '確率閾値', 'ratio': 0.8}, {'word': '確率しきい値', 'ratio': 0.1}, {'word': '確率のしきい値', 'ratio': 0.1}]",確率閾値
3085,3589,probability transition matrix,確率遷移行列,1.0,10,"[{'word': '確率遷移行列', 'ratio': 1.0}]",確率遷移行列
3086,3590,probability vector,確率ベクトル,1.0,10,"[{'word': '確率ベクトル', 'ratio': 1.0}]",確率ベクトル
3087,3591,probing classifier,プローブ分類器,0.0,10,"[{'word': 'プロービング分類器', 'ratio': 0.8}, {'word': '精査分類子', 'ratio': 0.2}]",プロービング分類器
3088,3592,problem space,問題空間,0.8,10,"[{'word': '問題空間', 'ratio': 0.8}, {'word': '問題スペース', 'ratio': 0.2}]",問題空間
3089,3593,product distribution,生成物分布,0.0,10,"[{'word': '積分布', 'ratio': 0.7}, {'word': '製品の流通', 'ratio': 0.2}, {'word': '積の分布', 'ratio': 0.1}]",積分布
3090,3594,product-of-expert,専門家の積,0.2,10,"[{'word': 'エキスパートの積', 'ratio': 0.6}, {'word': '専門家の積', 'ratio': 0.2}, {'word': 'エキスパート商品', 'ratio': 0.1}, {'word': '専門家の製品', 'ratio': 0.1}]",エキスパートの積
3091,3595,program induction,プログラム誘導,0.5,10,"[{'word': 'プログラム誘導', 'ratio': 0.5}, {'word': 'プログラム帰納', 'ratio': 0.3}, {'word': 'プログラム導入', 'ratio': 0.1}, {'word': 'プログラムの導入', 'ratio': 0.1}]",プログラム誘導
3092,3596,projection algorithm,射影アルゴリズム,0.7,10,"[{'word': '射影アルゴリズム', 'ratio': 0.7}, {'word': '投影アルゴリズム', 'ratio': 0.3}]",射影アルゴリズム
3093,3597,projection layer,射影層,0.7,10,"[{'word': '射影層', 'ratio': 0.7}, {'word': '投影層', 'ratio': 0.2}, {'word': '投影レイヤ', 'ratio': 0.1}]",射影層
3094,3598,projection matrix,投影行列,0.2,10,"[{'word': '射影行列', 'ratio': 0.8}, {'word': '投影行列', 'ratio': 0.2}]",射影行列
3095,3599,projection operator,射影演算子,0.7,10,"[{'word': '射影演算子', 'ratio': 0.7}, {'word': '投影演算子', 'ratio': 0.3}]",射影演算子
3096,3600,projection step,投影ステップ,0.3,10,"[{'word': '射影ステップ', 'ratio': 0.7}, {'word': '投影ステップ', 'ratio': 0.3}]",射影ステップ
3097,3601,projective camera,射影カメラ,0.7,10,"[{'word': '射影カメラ', 'ratio': 0.7}, {'word': '投影カメラ', 'ratio': 0.3}]",射影カメラ
3098,3602,projective dependency parsing,射影依存構文解析,0.7,10,"[{'word': '射影依存構文解析', 'ratio': 0.7}, {'word': '投影従属解析', 'ratio': 0.2}, {'word': '投影依存構文解析', 'ratio': 0.1}]",射影依存構文解析
3099,3603,projective dependency tree,射影依存木,0.7,10,"[{'word': '射影依存木', 'ratio': 0.7}, {'word': '投影従属木', 'ratio': 0.2}, {'word': '投影依存木', 'ratio': 0.1}]",射影依存木
3100,3605,projective transformation,射影変換,0.8,10,"[{'word': '射影変換', 'ratio': 0.8}, {'word': '投影変換', 'ratio': 0.2}]",射影変換
3101,3606,prompt,プロンプト,0.9,10,"[{'word': 'プロンプト', 'ratio': 0.9}, {'word': '迅速', 'ratio': 0.1}]",プロンプト
3102,3607,prompt engineering,プロンプトエンジニアリング,0.7,10,"[{'word': 'プロンプトエンジニアリング', 'ratio': 0.7}, {'word': '迅速なエンジニアリング', 'ratio': 0.2}, {'word': 'ロンプトエンジニアリング', 'ratio': 0.1}]",プロンプトエンジニアリング
3103,3608,prompt learning,プロンプト学習,0.7,10,"[{'word': 'プロンプト学習', 'ratio': 0.7}, {'word': '速習', 'ratio': 0.1}, {'word': '迅速な学習', 'ratio': 0.1}, {'word': 'プロンプトラーニング', 'ratio': 0.1}]",プロンプト学習
3104,3609,prompt tuning,プロンプトチューニング,0.5,10,"[{'word': 'プロンプトチューニング', 'ratio': 0.5}, {'word': 'プロンプト調整', 'ratio': 0.5}]",プロンプトチューニング
3105,3610,pronoun resolution,代名詞解決,0.8,10,"[{'word': '代名詞解決', 'ratio': 0.8}, {'word': '代名詞の解決', 'ratio': 0.2}]",代名詞解決
3106,3611,proof complexity,証明複雑性,0.0,10,"[{'word': '証明の複雑性', 'ratio': 0.7}, {'word': '証明の複雑さ', 'ratio': 0.3}]",証明の複雑性
3107,3612,proof number,証明数,0.6,10,"[{'word': '証明数', 'ratio': 0.6}, {'word': '証明番号', 'ratio': 0.4}]",証明数
3108,3613,proof tree,証明木,0.8,10,"[{'word': '証明木', 'ratio': 0.8}, {'word': '証明の木', 'ratio': 0.1}, {'word': '証拠の木', 'ratio': 0.1}]",証明木
3109,3614,propensity score,傾向スコア,1.0,10,"[{'word': '傾向スコア', 'ratio': 1.0}]",傾向スコア
3110,3615,proposal distribution,提案分布,0.8,10,"[{'word': '提案分布', 'ratio': 0.8}, {'word': '企画書配布', 'ratio': 0.2}]",提案分布
3111,3616,proposal probability,提案確率,0.8,10,"[{'word': '提案確率', 'ratio': 0.8}, {'word': 'プロポーズの確率', 'ratio': 0.2}]",提案確率
3112,3617,propositional,命題的,0.2,10,"[{'word': '命題の', 'ratio': 0.6}, {'word': '命題', 'ratio': 0.2}, {'word': '命題的', 'ratio': 0.2}]",命題の
3113,3618,propositional formula,命題論理式,0.0,10,"[{'word': '命題式', 'ratio': 1.0}]",命題式
3114,3619,propositional language,命題言語,1.0,10,"[{'word': '命題言語', 'ratio': 1.0}]",命題言語
3115,3620,propositional logic,命題論理,1.0,10,"[{'word': '命題論理', 'ratio': 1.0}]",命題論理
3116,3621,propositional variable,命題変数,1.0,10,"[{'word': '命題変数', 'ratio': 1.0}]",命題変数
3117,3622,protected attribute,保護された属性,0.1,10,"[{'word': '保護属性', 'ratio': 0.7}, {'word': 'プロテクト属性', 'ratio': 0.2}, {'word': '保護された属性', 'ratio': 0.1}]",保護属性
3118,3623,protein folding,"""タンパク質の折りたたみ""",0.0,10,"[{'word': 'タンパク質折りたたみ', 'ratio': 0.5}, {'word': 'タンパク質の折りたたみ', 'ratio': 0.2}, {'word': 'タンパク質の折り畳み', 'ratio': 0.2}, {'word': 'タンパク質の折りたた', 'ratio': 0.1}]",タンパク質折りたたみ
3119,3624,prototype embedding,プロトタイプ埋め込み,1.0,10,"[{'word': 'プロトタイプ埋め込み', 'ratio': 1.0}]",プロトタイプ埋め込み
3120,3626,pruning algorithm,剪定アルゴリズム,0.2,10,"[{'word': 'プルーニングアルゴリズム', 'ratio': 0.6}, {'word': '枝刈りアルゴリズム', 'ratio': 0.2}, {'word': '剪定アルゴリズム', 'ratio': 0.2}]",プルーニングアルゴリズム
3121,3627,pseudo-inverse,擬似逆,0.0,10,"[{'word': '擬似逆行列', 'ratio': 0.7}, {'word': '擬似インバース', 'ratio': 0.2}, {'word': '疑似逆行列', 'ratio': 0.1}]",擬似逆行列
3122,3628,pure strategy,純粋戦略,0.2,10,"[{'word': '純戦略', 'ratio': 0.8}, {'word': '純粋戦略', 'ratio': 0.2}]",純戦略
3123,3629,pyramid level,ピラミッドレベル,0.9,10,"[{'word': 'ピラミッドレベル', 'ratio': 0.9}, {'word': 'ピラミッド級', 'ratio': 0.1}]",ピラミッドレベル
3124,3630,quadratic assignment problem,二次割り当て問題,0.7,10,"[{'word': '二次割り当て問題', 'ratio': 0.7}, {'word': '二次割当問題', 'ratio': 0.2}, {'word': '二次配列問題', 'ratio': 0.1}]",二次割り当て問題
3125,3631,quadratic loss,二乗損失,0.0,10,"[{'word': '二次損失', 'ratio': 1.0}]",二次損失
3126,3632,quadratic program,二次計画問題,0.2,10,"[{'word': '二次計画', 'ratio': 0.6}, {'word': '二次計画問題', 'ratio': 0.2}, {'word': '二次プログラム', 'ratio': 0.1}, {'word': '二次計画法', 'ratio': 0.1}]",二次計画
3127,3633,quadratic regularizer,二次正則化項,0.5,10,"[{'word': '二次正則化項', 'ratio': 0.5}, {'word': '二次正則化子', 'ratio': 0.3}, {'word': 'にじせいそくか', 'ratio': 0.1}, {'word': '二次正則化', 'ratio': 0.1}]",二次正則化項
3128,3635,quantified variable,量化変数,0.0,10,"[{'word': '定量変数', 'ratio': 0.8}, {'word': '定量化変数', 'ratio': 0.1}, {'word': '定量化された変数', 'ratio': 0.1}]",定量変数
3129,3636,quantifier,量化子,0.7,10,"[{'word': '量化子', 'ratio': 0.7}, {'word': '量記号', 'ratio': 0.1}, {'word': '量指定子', 'ratio': 0.1}, {'word': '限定子', 'ratio': 0.1}]",量化子
3130,3637,quantile,分位数,1.0,10,"[{'word': '分位数', 'ratio': 1.0}]",分位数
3131,3638,quantization,量子化,0.8,10,"[{'word': '量子化', 'ratio': 0.8}, {'word': '定量化', 'ratio': 0.2}]",量子化
3132,3639,quantization function,量子化関数,0.8,10,"[{'word': '量子化関数', 'ratio': 0.8}, {'word': '量子化機能', 'ratio': 0.1}, {'word': '定量化関数', 'ratio': 0.1}]",量子化関数
3133,3640,quantizer,量子化器,0.9,10,"[{'word': '量子化器', 'ratio': 0.9}, {'word': '定量化器', 'ratio': 0.1}]",量子化器
3134,3641,quasi-Newton method,準ニュートン法,0.5,10,"[{'word': '準ニュートン法', 'ratio': 0.5}, {'word': '擬似ニュートン法', 'ratio': 0.4}, {'word': '擬ニュートン法', 'ratio': 0.1}]",準ニュートン法
3135,3642,quaternion,四元数,0.7,10,"[{'word': '四元数', 'ratio': 0.7}, {'word': 'クォータニオン', 'ratio': 0.3}]",四元数
3136,3643,query,クエリ,0.45,20,"[{'word': 'クエリ', 'ratio': 0.9}, {'word': 'クエリー', 'ratio': 0.1}]",クエリ
3137,3644,query answering,クエリ回答,0.0,10,"[{'word': 'クエリ応答', 'ratio': 1.0}]",クエリ応答
3138,3646,query context,クエリコンテキスト,1.0,10,"[{'word': 'クエリコンテキスト', 'ratio': 1.0}]",クエリコンテキスト
3139,3647,query embedding,クエリ埋め込み,1.0,10,"[{'word': 'クエリ埋め込み', 'ratio': 1.0}]",クエリ埋め込み
3140,3648,query image,クエリ画像,1.0,10,"[{'word': 'クエリ画像', 'ratio': 1.0}]",クエリ画像
3141,3649,query language,クエリ言語,0.8,10,"[{'word': 'クエリ言語', 'ratio': 0.8}, {'word': '問合せ言語', 'ratio': 0.2}]",クエリ言語
3142,3650,query phase,クエリフェーズ,1.0,10,"[{'word': 'クエリフェーズ', 'ratio': 1.0}]",クエリフェーズ
3143,3651,query point,クエリ点,0.0,10,"[{'word': 'クエリポイント', 'ratio': 0.8}, {'word': 'クエリーポイント', 'ratio': 0.2}]",クエリポイント
3144,3652,query processing,クエリ処理,1.0,10,"[{'word': 'クエリ処理', 'ratio': 1.0}]",クエリ処理
3145,3653,query reformulation,クエリの再定式化,0.2,10,"[{'word': 'クエリ再構成', 'ratio': 0.5}, {'word': 'クエリ再定式化', 'ratio': 0.3}, {'word': 'クエリの再定式化', 'ratio': 0.2}]",クエリ再構成
3146,3654,query representation,クエリ表現,1.0,10,"[{'word': 'クエリ表現', 'ratio': 1.0}]",クエリ表現
3147,3655,query strategy,クエリ戦略,1.0,10,"[{'word': 'クエリ戦略', 'ratio': 1.0}]",クエリ戦略
3148,3656,query time,クエリ時間,1.0,9,"[{'word': 'クエリ時間', 'ratio': 1.0}]",クエリ時間
3149,3657,query vector,クエリベクトル,0.7,10,"[{'word': 'クエリベクトル', 'ratio': 0.7}, {'word': '問合せベクトル', 'ratio': 0.2}, {'word': 'クエリベクター', 'ratio': 0.1}]",クエリベクトル
3150,3658,query-document pair,クエリとドキュメントのペア,0.2,10,"[{'word': 'クエリ-ドキュメントペア', 'ratio': 0.6}, {'word': 'クエリとドキュメントのペア', 'ratio': 0.2}, {'word': 'クエリ・ドキュメントペア', 'ratio': 0.2}]",クエリ-ドキュメントペア
3151,3659,radiance field,放射輝度場,0.5,10,"[{'word': '放射輝度場', 'ratio': 0.5}, {'word': '輝点', 'ratio': 0.2}, {'word': '放射場', 'ratio': 0.2}, {'word': '放射輝度フィールド', 'ratio': 0.1}]",放射輝度場
3152,3660,random crop,ランダムクロップ,0.8,10,"[{'word': 'ランダムクロップ', 'ratio': 0.8}, {'word': '乱作', 'ratio': 0.1}, {'word': 'ランダムな収穫', 'ratio': 0.1}]",ランダムクロップ
3153,3661,random feature,ランダム特徴量,0.0,10,"[{'word': 'ランダム特徴', 'ratio': 0.8}, {'word': 'ランダム機能', 'ratio': 0.1}, {'word': 'ランダムな特徴', 'ratio': 0.1}]",ランダム特徴
3154,3662,random matrix theory,ランダム行列理論,0.9,10,"[{'word': 'ランダム行列理論', 'ratio': 0.9}, {'word': '確率行列理論', 'ratio': 0.1}]",ランダム行列理論
3155,3663,random policy,ランダムポリシー,1.0,10,"[{'word': 'ランダムポリシー', 'ratio': 1.0}]",ランダムポリシー
3156,3664,random projection,ランダム射影,0.7,10,"[{'word': 'ランダム射影', 'ratio': 0.7}, {'word': 'ランダム投影', 'ratio': 0.2}, {'word': 'ランダムな投影', 'ratio': 0.1}]",ランダム射影
3157,3665,random projection algorithm,ランダム射影アルゴリズム,0.5,10,"[{'word': 'ランダム射影アルゴリズム', 'ratio': 0.5}, {'word': 'ランダム投影アルゴリズム', 'ratio': 0.3}, {'word': 'ランダム投影法', 'ratio': 0.1}, {'word': 'ランダムプロジェクションアルゴリズム', 'ratio': 0.1}]",ランダム射影アルゴリズム
3158,3666,random sampling,ランダムサンプリング,0.9,10,"[{'word': 'ランダムサンプリング', 'ratio': 0.9}, {'word': '無作為抽出', 'ratio': 0.1}]",ランダムサンプリング
3159,3667,random seed,乱数シード,0.0,10,"[{'word': 'ランダムシード', 'ratio': 1.0}]",ランダムシード
3160,3668,random variable,確率変数,0.5,10,"[{'word': 'ランダム変数', 'ratio': 0.5}, {'word': '確率変数', 'ratio': 0.5}]",ランダム変数
3161,3669,random vector,ランダムなベクトル,0.1,10,"[{'word': 'ランダムベクトル', 'ratio': 0.9}, {'word': 'ランダムなベクトル', 'ratio': 0.1}]",ランダムベクトル
3162,3670,random walk model,ランダムウォークモデル,1.0,10,"[{'word': 'ランダムウォークモデル', 'ratio': 1.0}]",ランダムウォークモデル
3163,3671,randomization,ランダム化,0.9,10,"[{'word': 'ランダム化', 'ratio': 0.9}, {'word': '無作為化', 'ratio': 0.1}]",ランダム化
3164,3672,randomized algorithm,ランダム化アルゴリズム,0.8,10,"[{'word': 'ランダム化アルゴリズム', 'ratio': 0.8}, {'word': 'ランダム化されたアルゴリズム', 'ratio': 0.2}]",ランダム化アルゴリズム
3165,3673,randomized smoothing,ランダム化スムージング,0.7,10,"[{'word': 'ランダム化スムージング', 'ratio': 0.7}, {'word': 'ランダムスムージング', 'ratio': 0.1}, {'word': 'ランダム化された平滑化', 'ratio': 0.1}, {'word': 'ランダム化されたスムージング', 'ratio': 0.1}]",ランダム化スムージング
3166,3674,range query,範囲クエリ,0.8,10,"[{'word': '範囲クエリ', 'ratio': 0.8}, {'word': 'レンジクエリ', 'ratio': 0.1}, {'word': 'レンジクエリー', 'ratio': 0.1}]",範囲クエリ
3167,3675,rank-one update,階数1の更新,0.0,10,"[{'word': 'ランク1更新', 'ratio': 0.5}, {'word': 'ランクワン更新', 'ratio': 0.1}, {'word': '依存関係解析ツリー', 'ratio': 0.1}, {'word': 'ランクワンアップデート', 'ratio': 0.1}, {'word': 'ランクワンアップ', 'ratio': 0.1}, {'word': 'ランク１更新', 'ratio': 0.1}]",ランク1更新
3168,3676,ranking algorithm,ランキングアルゴリズム,1.0,10,"[{'word': 'ランキングアルゴリズム', 'ratio': 1.0}]",ランキングアルゴリズム
3169,3677,ranking function,ランキング関数,0.8,10,"[{'word': 'ランキング関数', 'ratio': 0.8}, {'word': 'ランキング機能', 'ratio': 0.2}]",ランキング関数
3170,3678,ranking model,ランクモデル,0.0,10,"[{'word': 'ランキングモデル', 'ratio': 1.0}]",ランキングモデル
3171,3679,reachable state,到達可能状態,0.7,10,"[{'word': '到達可能状態', 'ratio': 0.7}, {'word': '到達可能な状態', 'ratio': 0.2}, {'word': '達成可能状態', 'ratio': 0.1}]",到達可能状態
3172,3680,readout function,読み出し関数,0.7,10,"[{'word': '読み出し関数', 'ratio': 0.7}, {'word': '読み出し機能', 'ratio': 0.2}, {'word': 'リードアウト関数', 'ratio': 0.1}]",読み出し関数
3173,3681,receptive field,受容野,0.7,10,"[{'word': '受容野', 'ratio': 0.7}, {'word': '感受野', 'ratio': 0.2}, {'word': '受容領域', 'ratio': 0.1}]",受容野
3174,3682,recognition,認識,0.9,10,"[{'word': '認識', 'ratio': 0.9}, {'word': '識別', 'ratio': 0.1}]",認識
3175,3683,recognition model,認識モデル,1.0,10,"[{'word': '認識モデル', 'ratio': 1.0}]",認識モデル
3176,3684,recommendation algorithm,推薦アルゴリズム,0.7,10,"[{'word': '推薦アルゴリズム', 'ratio': 0.7}, {'word': 'レコメンデーションアルゴリズム', 'ratio': 0.2}, {'word': '推奨アルゴリズム', 'ratio': 0.1}]",推薦アルゴリズム
3177,3685,recommendation model,推薦モデル,0.7,10,"[{'word': '推薦モデル', 'ratio': 0.7}, {'word': 'レコメンデーションモデル', 'ratio': 0.2}, {'word': '推奨モデル', 'ratio': 0.1}]",推薦モデル
3178,3686,recommendation system,推薦システム,0.5,10,"[{'word': '推薦システム', 'ratio': 0.5}, {'word': 'レコメンデーションシステム', 'ratio': 0.4}, {'word': '推奨システム', 'ratio': 0.1}]",推薦システム
3179,3687,recommender,レコメンダー,0.8,10,"[{'word': 'レコメンダー', 'ratio': 0.8}, {'word': '推薦者', 'ratio': 0.2}]",レコメンダー
3180,3688,recommender system,推薦システム,0.2,10,"[{'word': 'レコメンダーシステム', 'ratio': 0.8}, {'word': '推薦システム', 'ratio': 0.2}]",レコメンダーシステム
3181,3689,reconstruction algorithm,再構成アルゴリズム,0.8,10,"[{'word': '再構成アルゴリズム', 'ratio': 0.8}, {'word': '復元アルゴリズム', 'ratio': 0.1}, {'word': '再構築アルゴリズム', 'ratio': 0.1}]",再構成アルゴリズム
3182,3690,reconstruction error,再構成誤差 (saikousei gosa),0.0,10,"[{'word': '再構成誤差', 'ratio': 0.6}, {'word': '再構成エラー', 'ratio': 0.2}, {'word': '復元誤差', 'ratio': 0.1}, {'word': '再構築誤差', 'ratio': 0.1}]",再構成誤差
3183,3691,reconstruction loss,再構築損失,0.1,10,"[{'word': '再構成損失', 'ratio': 0.6}, {'word': '再建損', 'ratio': 0.1}, {'word': '復興損失', 'ratio': 0.1}, {'word': '復元損失', 'ratio': 0.1}, {'word': '再構築損失', 'ratio': 0.1}]",再構成損失
3184,3692,recovery algorithm,復元アルゴリズム,0.6,10,"[{'word': '復元アルゴリズム', 'ratio': 0.6}, {'word': '回復アルゴリズム', 'ratio': 0.3}, {'word': 'recovery algorithm', 'ratio': 0.1}]",復元アルゴリズム
3185,3693,rectified linear unit,整流線形ユニット,0.6,10,"[{'word': '整流線形ユニット', 'ratio': 0.6}, {'word': '整流リニアユニット', 'ratio': 0.2}, {'word': '整流線形単位', 'ratio': 0.1}, {'word': '修正線形ユニット', 'ratio': 0.1}]",整流線形ユニット
3186,3694,rectified stereo pair,正規化されたステレオペア,0.0,10,"[{'word': '整流ステレオペア', 'ratio': 0.6}, {'word': '整流ステレオ・ペア', 'ratio': 0.2}, {'word': '整流されたステレオペア', 'ratio': 0.1}, {'word': '修正ステレオペア', 'ratio': 0.1}]",整流ステレオペア
3187,3695,recurrent,再帰,0.0,10,"[{'word': '再帰的', 'ratio': 0.8}, {'word': 'リカレント', 'ratio': 0.2}]",再帰的
3188,3696,recurrent architecture,再帰的アーキテクチャ,0.6,10,"[{'word': '再帰的アーキテクチャ', 'ratio': 0.6}, {'word': 'リカレント・アーキテクチャ', 'ratio': 0.2}, {'word': '再帰型アーキテクチャ', 'ratio': 0.2}]",再帰的アーキテクチャ
3189,3697,recurrent autoencoder,再帰オートエンコーダ,0.0,10,"[{'word': '再帰的オートエンコーダ', 'ratio': 0.6}, {'word': 'リカレントオートエンコーダ', 'ratio': 0.2}, {'word': '再帰型オートエンコーダ', 'ratio': 0.2}]",再帰的オートエンコーダ
3190,3698,recurrent connection,再帰接続,0.7,10,"[{'word': '再帰接続', 'ratio': 0.7}, {'word': '反復接続', 'ratio': 0.2}, {'word': '再帰的接続', 'ratio': 0.1}]",再帰接続
3191,3700,recurrent model,再帰モデル,0.8,10,"[{'word': '再帰モデル', 'ratio': 0.8}, {'word': 'リカレントモデル', 'ratio': 0.2}]",再帰モデル
3192,3701,recurrent network,再帰ネットワーク,0.8,10,"[{'word': '再帰ネットワーク', 'ratio': 0.8}, {'word': 'リカレントネットワーク', 'ratio': 0.2}]",再帰ネットワーク
3193,3702,recurrent state,再帰状態,0.8,10,"[{'word': '再帰状態', 'ratio': 0.8}, {'word': '再発状態', 'ratio': 0.2}]",再帰状態
3194,3703,recursion,再帰,0.9,10,"[{'word': '再帰', 'ratio': 0.9}, {'word': '回帰', 'ratio': 0.1}]",再帰
3195,3704,recursive call,再帰呼び出し,1.0,10,"[{'word': '再帰呼び出し', 'ratio': 1.0}]",再帰呼び出し
3196,3705,recursive neural model,再帰的ニューラルモデル,0.2,10,"[{'word': '再帰ニューラルモデル', 'ratio': 0.5}, {'word': '再帰的ニューラルモデル', 'ratio': 0.2}, {'word': '再帰神経モデル', 'ratio': 0.2}, {'word': '再帰的ニューラル モデル', 'ratio': 0.1}]",再帰ニューラルモデル
3197,3706,recursive neural network,再帰ニューラルネットワーク,0.5,10,"[{'word': '再帰ニューラルネットワーク', 'ratio': 0.5}, {'word': '再帰的ニューラルネットワーク', 'ratio': 0.3}, {'word': '再帰的ニューラル ネットワーク', 'ratio': 0.1}, {'word': '再帰神経ネットワーク', 'ratio': 0.1}]",再帰ニューラルネットワーク
3198,3707,reference distribution,参照分布,0.9,10,"[{'word': '参照分布', 'ratio': 0.9}, {'word': '基準分布', 'ratio': 0.1}]",参照分布
3199,3708,reference resolution,参照解決,0.7,10,"[{'word': '参照解決', 'ratio': 0.7}, {'word': '基準分解能', 'ratio': 0.1}, {'word': '基準解像度', 'ratio': 0.1}, {'word': '参考解決', 'ratio': 0.1}]",参照解決
3200,3709,reference text,参照テキスト,0.9,10,"[{'word': '参照テキスト', 'ratio': 0.9}, {'word': '参考テキスト', 'ratio': 0.1}]",参照テキスト
3201,3710,reference-based metric,参照ベースメトリック,0.0,10,"[{'word': '参照ベースのメトリック', 'ratio': 0.5}, {'word': '参照ベースの指標', 'ratio': 0.3}, {'word': '参照に基づくメトリック', 'ratio': 0.1}, {'word': '参照ベース指標', 'ratio': 0.1}]",参照ベースのメトリック
3202,3712,regression analysis,回帰分析,0.9,10,"[{'word': '回帰分析', 'ratio': 0.9}, {'word': 'クラスターセンター', 'ratio': 0.1}]",回帰分析
3203,3713,regression coefficient,回帰係数,1.0,10,"[{'word': '回帰係数', 'ratio': 1.0}]",回帰係数
3204,3714,regression function,回帰関数,1.0,10,"[{'word': '回帰関数', 'ratio': 1.0}]",回帰関数
3205,3715,regression model,回帰モデル,1.0,10,"[{'word': '回帰モデル', 'ratio': 1.0}]",回帰モデル
3206,3716,regression problem,回帰問題,1.0,10,"[{'word': '回帰問題', 'ratio': 1.0}]",回帰問題
3207,3717,regression task,回帰タスク,0.8,10,"[{'word': '回帰タスク', 'ratio': 0.8}, {'word': '回帰課題', 'ratio': 0.1}, {'word': '回帰タスク 回帰タスク', 'ratio': 0.1}]",回帰タスク
3208,3718,regression tree,回帰木,0.9,10,"[{'word': '回帰木', 'ratio': 0.9}, {'word': '回帰ツリー', 'ratio': 0.1}]",回帰木
3209,3719,regret bound,後悔束縛,0.0,9,"[{'word': '後悔境界', 'ratio': 0.6666666666666666}, {'word': 'リグレットバウンド', 'ratio': 0.1111111111111111}, {'word': '後悔の束縛', 'ratio': 0.1111111111111111}, {'word': '後悔の限界', 'ratio': 0.1111111111111111}]",後悔境界
3210,3720,regret matching,後悔マッチング,0.8,10,"[{'word': '後悔マッチング', 'ratio': 0.8}, {'word': 'マッチングを後悔', 'ratio': 0.1}, {'word': '後悔の一致', 'ratio': 0.1}]",後悔マッチング
3211,3721,regret minimization,後悔最小化,0.8,10,"[{'word': '後悔最小化', 'ratio': 0.8}, {'word': '後悔の最小化', 'ratio': 0.2}]",後悔最小化
3212,3722,regret minimization algorithm,後悔最小化アルゴリズム,0.9,10,"[{'word': '後悔最小化アルゴリズム', 'ratio': 0.9}, {'word': 'レグレット最小化アルゴリズム', 'ratio': 0.1}]",後悔最小化アルゴリズム
3213,3723,regret minimizer,後悔最小化器,0.6,10,"[{'word': '後悔最小化器', 'ratio': 0.6}, {'word': '後悔を最小限に抑える', 'ratio': 0.2}, {'word': 'レグレット最小化器', 'ratio': 0.1}, {'word': '後悔最小化装置', 'ratio': 0.1}]",後悔最小化器
3214,3724,regular expression,正規表現,1.0,10,"[{'word': '正規表現', 'ratio': 1.0}]",正規表現
3215,3725,regularisation,正則化,1.0,10,"[{'word': '正則化', 'ratio': 1.0}]",正則化
3216,3726,regularization,正則化,0.9,10,"[{'word': '正則化', 'ratio': 0.9}, {'word': '正規化', 'ratio': 0.1}]",正則化
3217,3727,regularization constant,正則化定数,1.0,10,"[{'word': '正則化定数', 'ratio': 1.0}]",正則化定数
3218,3728,regularization function,正則化関数,1.0,10,"[{'word': '正則化関数', 'ratio': 1.0}]",正則化関数
3219,3729,regularization loss,正則化損失,1.0,10,"[{'word': '正則化損失', 'ratio': 1.0}]",正則化損失
3220,3730,regularization parameter,正則化パラメータ,1.0,10,"[{'word': '正則化パラメータ', 'ratio': 1.0}]",正則化パラメータ
3221,3731,regularization path,正則化パス,0.9,10,"[{'word': '正則化パス', 'ratio': 0.9}, {'word': '正則化経路', 'ratio': 0.1}]",正則化パス
3222,3732,regularization penalty,正則化ペナルティ,0.9,10,"[{'word': '正則化ペナルティ', 'ratio': 0.9}, {'word': '規則化ペナルティ', 'ratio': 0.1}]",正則化ペナルティ
3223,3733,regularization strength,正則化強度,0.7,10,"[{'word': '正則化強度', 'ratio': 0.7}, {'word': '正則化の強さ', 'ratio': 0.2}, {'word': '規則化強度', 'ratio': 0.1}]",正則化強度
3224,3734,regularization term,正則化項,0.9,10,"[{'word': '正則化項', 'ratio': 0.9}, {'word': '規則化項', 'ratio': 0.1}]",正則化項
3225,3735,regularization weight,正則化重み,0.7,10,"[{'word': '正則化重み', 'ratio': 0.7}, {'word': '正則化の重み', 'ratio': 0.2}, {'word': '規則化重み', 'ratio': 0.1}]",正則化重み
3226,3736,regularization-based method,正則化ベースの方法,0.0,10,"[{'word': '正則化ベースの手法', 'ratio': 0.7}, {'word': '正則化に基づく方法', 'ratio': 0.2}, {'word': '規則化ベースのメソッド', 'ratio': 0.1}]",正則化ベースの手法
3227,3737,regularizer,正則化項,0.6,10,"[{'word': '正則化項', 'ratio': 0.6}, {'word': 'レギュレーター', 'ratio': 0.1}, {'word': '正則化者', 'ratio': 0.1}, {'word': 'レギュラライザー', 'ratio': 0.1}, {'word': '正則化器', 'ratio': 0.1}]",正則化項
3228,3738,reinforcement learning algorithm,強化学習アルゴリズム,1.0,10,"[{'word': '強化学習アルゴリズム', 'ratio': 1.0}]",強化学習アルゴリズム
3229,3739,relation extraction,関係抽出,1.0,10,"[{'word': '関係抽出', 'ratio': 1.0}]",関係抽出
3230,3740,relation type,関係タイプ,1.0,10,"[{'word': '関係タイプ', 'ratio': 1.0}]",関係タイプ
3231,3741,relational tuple,関係タプル,0.8,10,"[{'word': '関係タプル', 'ratio': 0.8}, {'word': 'リレーショナルタプル', 'ratio': 0.1}, {'word': '関係tuple', 'ratio': 0.1}]",関係タプル
3232,3742,relative entropy,相対エントロピー,1.0,10,"[{'word': '相対エントロピー', 'ratio': 1.0}]",相対エントロピー
3233,3743,relative positional embedding,相対位置埋め込み,1.0,10,"[{'word': '相対位置埋め込み', 'ratio': 1.0}]",相対位置埋め込み
3234,3744,relevance score,関連性スコア,0.4,10,"[{'word': '関連スコア', 'ratio': 0.6}, {'word': '関連性スコア', 'ratio': 0.4}]",関連スコア
3235,3745,rendering network,レンダリングネットワーク,1.0,10,"[{'word': 'レンダリングネットワーク', 'ratio': 1.0}]",レンダリングネットワーク
3236,3746,renormalization,正規化,0.1,10,"[{'word': '再正規化', 'ratio': 0.7}, {'word': '繰り込み', 'ratio': 0.2}, {'word': '正規化', 'ratio': 0.1}]",再正規化
3237,3747,reparameterization,再パラメータ化,1.0,10,"[{'word': '再パラメータ化', 'ratio': 1.0}]",再パラメータ化
3238,3748,reparameterization trick,再パラメータ化トリック,0.8,10,"[{'word': '再パラメータ化トリック', 'ratio': 0.8}, {'word': 'パラメタ化し直すトリック', 'ratio': 0.2}]",再パラメータ化トリック
3239,3749,replay buffer,リプレイバッファ,0.8,10,"[{'word': 'リプレイバッファ', 'ratio': 0.8}, {'word': '再生バッファ', 'ratio': 0.2}]",リプレイバッファ
3240,3750,replay memory,リプレイメモリ,0.7,10,"[{'word': 'リプレイメモリ', 'ratio': 0.7}, {'word': 'リプレーメモリー', 'ratio': 0.2}, {'word': '再生メモリー', 'ratio': 0.1}]",リプレイメモリ
3241,3751,representation,表現,1.0,19,"[{'word': '表現', 'ratio': 1.0}]",表現
3242,3752,representation learning,表現学習,0.9,10,"[{'word': '表現学習', 'ratio': 0.9}, {'word': '表現トレーニング', 'ratio': 0.1}]",表現学習
3243,3753,representation matrix,表現行列,0.9,10,"[{'word': '表現行列', 'ratio': 0.9}, {'word': 'マトリックスを表示する', 'ratio': 0.1}]",表現行列
3244,3754,representation space,表現空間,1.0,10,"[{'word': '表現空間', 'ratio': 1.0}]",表現空間
3245,3755,representation vector,表現ベクトル,1.0,10,"[{'word': '表現ベクトル', 'ratio': 1.0}]",表現ベクトル
3246,3756,representer theorem,リプレゼンター定理,0.0,10,"[{'word': '表現者定理', 'ratio': 0.7}, {'word': '表現定理', 'ratio': 0.2}, {'word': '代表者定理', 'ratio': 0.1}]",表現者定理
3247,3757,reproducing kernel Hilbert space,再生カーネルヒルベルト空間,0.2,10,"[{'word': '再生核ヒルベルト空間', 'ratio': 0.6}, {'word': '再生カーネルヒルベルト空間', 'ratio': 0.2}, {'word': 'カーネルヒルベルト空間の再現', 'ratio': 0.1}, {'word': '再現カーネル・ヒルベルト空間', 'ratio': 0.1}]",再生核ヒルベルト空間
3248,3759,reprojection,再投影,0.8,10,"[{'word': '再投影', 'ratio': 0.8}, {'word': 'リプロジェクション', 'ratio': 0.2}]",再投影
3249,3760,reprojection error,再投影誤差,0.8,10,"[{'word': '再投影誤差', 'ratio': 0.8}, {'word': '再投影エラー', 'ratio': 0.2}]",再投影誤差
3250,3764,reservoir sampling,リザーバーサンプリング,0.1,10,"[{'word': 'リザーバサンプリング', 'ratio': 0.7}, {'word': '貯水池サンプリング', 'ratio': 0.2}, {'word': 'リザーバーサンプリング', 'ratio': 0.1}]",リザーバサンプリング
3251,3765,residual block,残差ブロック,1.0,10,"[{'word': '残差ブロック', 'ratio': 1.0}]",残差ブロック
3252,3766,residual branch,残余ブランチ,0.0,10,"[{'word': '残差ブランチ', 'ratio': 0.7}, {'word': '残留ブランチ', 'ratio': 0.2}, {'word': '残差分岐', 'ratio': 0.1}]",残差ブランチ
3253,3767,residual connection,残留接続,0.2,10,"[{'word': '残差接続', 'ratio': 0.8}, {'word': '残留接続', 'ratio': 0.2}]",残差接続
3254,3768,residual error,残差誤差,0.8,10,"[{'word': '残差誤差', 'ratio': 0.8}, {'word': '残留誤差', 'ratio': 0.2}]",残差誤差
3255,3769,residual function,残差関数,0.8,10,"[{'word': '残差関数', 'ratio': 0.8}, {'word': '残留関数', 'ratio': 0.2}]",残差関数
3256,3770,residual graph,残差グラフ,0.9,10,"[{'word': '残差グラフ', 'ratio': 0.9}, {'word': '残余グラフ', 'ratio': 0.1}]",残差グラフ
3257,3771,residual learning,残差学習,0.8,10,"[{'word': '残差学習', 'ratio': 0.8}, {'word': '残留学習', 'ratio': 0.2}]",残差学習
3258,3772,residual network,残差ネットワーク,0.8,10,"[{'word': '残差ネットワーク', 'ratio': 0.8}, {'word': '残留ネットワーク', 'ratio': 0.2}]",残差ネットワーク
3259,3774,retrieval,取得,0.0,20,"[{'word': '検索', 'ratio': 0.8}, {'word': '回収', 'ratio': 0.2}]",検索
3260,3775,retrieval function,検索関数,0.8,10,"[{'word': '検索関数', 'ratio': 0.8}, {'word': '検索機能', 'ratio': 0.2}]",検索関数
3261,3776,retrieval method,検索手法,0.6,10,"[{'word': '検索手法', 'ratio': 0.6}, {'word': '検索方法', 'ratio': 0.4}]",検索手法
3262,3777,retrieval model,検索モデル,1.0,10,"[{'word': '検索モデル', 'ratio': 1.0}]",検索モデル
3263,3778,retrieval system,情報検索システム,0.0,10,"[{'word': '検索システム', 'ratio': 1.0}]",検索システム
3264,3779,reverse-mode,逆モード,0.6,10,"[{'word': '逆モード', 'ratio': 0.6}, {'word': '逆伝播モード', 'ratio': 0.2}, {'word': 'リバースモード', 'ratio': 0.2}]",逆モード
3265,3780,reward,報酬,0.9,10,"[{'word': '報酬', 'ratio': 0.9}, {'word': '褒美', 'ratio': 0.1}]",報酬
3266,3781,reward model,報酬モデル,1.0,10,"[{'word': '報酬モデル', 'ratio': 1.0}]",報酬モデル
3267,3782,reward shaping,報酬成形,0.0,10,"[{'word': '報酬シェーピング', 'ratio': 0.5}, {'word': '報酬形成', 'ratio': 0.2}, {'word': '報酬の形成', 'ratio': 0.1}, {'word': '報酬形状付け', 'ratio': 0.1}, {'word': '報酬整形', 'ratio': 0.1}]",報酬シェーピング
3268,3783,reward signal,報酬信号,0.9,10,"[{'word': '報酬信号', 'ratio': 0.9}, {'word': '報奨信号', 'ratio': 0.1}]",報酬信号
3269,3784,reward-maximizing policy,報酬を最大化する方策,0.0,9,"[{'word': '報酬最大化ポリシー', 'ratio': 0.6666666666666666}, {'word': '報酬最大化政策', 'ratio': 0.2222222222222222}, {'word': '報酬最大化方針', 'ratio': 0.1111111111111111}]",報酬最大化ポリシー
3270,3785,ridge regularization,リッジ正則化,1.0,9,"[{'word': 'リッジ正則化', 'ratio': 1.0}]",リッジ正則化
3271,3786,right-to-left model,右から左のモデル,0.1111111111111111,9,"[{'word': '右から左へのモデル', 'ratio': 0.5555555555555556}, {'word': '右から左モデル', 'ratio': 0.3333333333333333}, {'word': '右から左のモデル', 'ratio': 0.1111111111111111}]",右から左へのモデル
3272,3787,rigid body transformation,剛体変換,1.0,9,"[{'word': '剛体変換', 'ratio': 1.0}]",剛体変換
3273,3788,rigid transformation,剛体変換,0.7777777777777778,9,"[{'word': '剛体変換', 'ratio': 0.7777777777777778}, {'word': '厳密変換', 'ratio': 0.2222222222222222}]",剛体変換
3274,3789,risk minimization,リスク最小化,0.8888888888888888,9,"[{'word': 'リスク最小化', 'ratio': 0.8888888888888888}, {'word': 'リスクの最小化', 'ratio': 0.1111111111111111}]",リスク最小化
3275,3790,roberta-large,roberta-large,0.2222222222222222,9,"[{'word': 'ロバータ・ラージ', 'ratio': 0.5555555555555556}, {'word': 'roberta-large', 'ratio': 0.2222222222222222}, {'word': 'ロベルタ・ラージ', 'ratio': 0.1111111111111111}, {'word': 'RoBERTa-large', 'ratio': 0.1111111111111111}]",ロバータ・ラージ
3276,3791,robotic,ロボット工学,0.0,9,"[{'word': 'ロボティクス', 'ratio': 0.6666666666666666}, {'word': '無機質', 'ratio': 0.1111111111111111}, {'word': 'ロボットの', 'ratio': 0.1111111111111111}, {'word': 'ロボティック', 'ratio': 0.1111111111111111}]",ロボティクス
3277,3792,robust optimization,頑健最適化,0.0,9,"[{'word': 'ロバスト最適化', 'ratio': 0.8888888888888888}, {'word': '堅牢な最適化', 'ratio': 0.1111111111111111}]",ロバスト最適化
3278,3793,robust risk,ロバストリスク,0.8888888888888888,9,"[{'word': 'ロバストリスク', 'ratio': 0.8888888888888888}, {'word': '堅牢なリスク', 'ratio': 0.1111111111111111}]",ロバストリスク
3279,3797,role classification,役割分類,0.5,10,"[{'word': '役割分類', 'ratio': 0.5}, {'word': 'ロール分類', 'ratio': 0.4}, {'word': 'Rōru Bunrui', 'ratio': 0.1}]",役割分類
3280,3798,role name,役割名,0.5,10,"[{'word': 'ロール名', 'ratio': 0.5}, {'word': '役割名', 'ratio': 0.5}]",ロール名
3281,3799,roll-out policy,ロールアウトポリシー,0.8,10,"[{'word': 'ロールアウトポリシー', 'ratio': 0.8}, {'word': '展開方針', 'ratio': 0.2}]",ロールアウトポリシー
3282,3800,rollout,ロールアウト,1.0,10,"[{'word': 'ロールアウト', 'ratio': 1.0}]",ロールアウト
3283,3801,rollout length,ロールアウト長,0.8,10,"[{'word': 'ロールアウト長', 'ratio': 0.8}, {'word': 'ロールアウトの長さ', 'ratio': 0.2}]",ロールアウト長
3284,3802,root mean square error,二乗平均平方根誤差,0.9,10,"[{'word': '二乗平均平方根誤差', 'ratio': 0.9}, {'word': '平均二乗誤差', 'ratio': 0.1}]",二乗平均平方根誤差
3285,3803,root node,根ノード,0.1111111111111111,9,"[{'word': 'ルートノード', 'ratio': 0.8888888888888888}, {'word': '根ノード', 'ratio': 0.1111111111111111}]",ルートノード
3286,3804,rotation angle,回転角度,0.1111111111111111,9,"[{'word': '回転角', 'ratio': 0.8888888888888888}, {'word': '回転角度', 'ratio': 0.1111111111111111}]",回転角
3287,3805,rotation invariance,回転不変性,1.0,9,"[{'word': '回転不変性', 'ratio': 1.0}]",回転不変性
3288,3806,rotation matrix,回転行列,1.0,9,"[{'word': '回転行列', 'ratio': 1.0}]",回転行列
3289,3807,row vector,行ベクトル,1.0,9,"[{'word': '行ベクトル', 'ratio': 1.0}]",行ベクトル
3290,3808,rule body,ルール本体,0.5,10,"[{'word': 'ルール本体', 'ratio': 0.5}, {'word': 'ルールボディ', 'ratio': 0.4}, {'word': 'ルール本文', 'ratio': 0.1}]",ルール本体
3291,3810,saddle-point problem,鞍点問題,0.2,10,"[{'word': 'サドルポイント問題', 'ratio': 0.6}, {'word': '鞍点問題', 'ratio': 0.2}, {'word': '鞍点の問題', 'ratio': 0.1}, {'word': 'サドル点問題', 'ratio': 0.1}]",サドルポイント問題
3292,3811,saliency,顕著性,0.9,10,"[{'word': '顕著性', 'ratio': 0.9}, {'word': 'セレナシー', 'ratio': 0.1}]",顕著性
3293,3812,saliency map,顕著性マップ,0.9,10,"[{'word': '顕著性マップ', 'ratio': 0.9}, {'word': 'セレナシーマップ', 'ratio': 0.1}]",顕著性マップ
3294,3815,sample covariance matrix,サンプル共分散行列,0.9,10,"[{'word': 'サンプル共分散行列', 'ratio': 0.9}, {'word': '標本共分散行列', 'ratio': 0.1}]",サンプル共分散行列
3295,3816,sample efficiency,サンプル効率,1.0,10,"[{'word': 'サンプル効率', 'ratio': 1.0}]",サンプル効率
3296,3817,sample selection,サンプル選択,0.9,10,"[{'word': 'サンプル選択', 'ratio': 0.9}, {'word': 'サンプルの選択', 'ratio': 0.1}]",サンプル選択
3297,3818,sample space,サンプル空間,0.2222222222222222,9,"[{'word': '標本空間', 'ratio': 0.6666666666666666}, {'word': 'サンプル空間', 'ratio': 0.2222222222222222}, {'word': 'サンプルスペース', 'ratio': 0.1111111111111111}]",標本空間
3298,3819,sample variance,標本分散,0.5555555555555556,9,"[{'word': '標本分散', 'ratio': 0.5555555555555556}, {'word': 'サンプル分散', 'ratio': 0.3333333333333333}, {'word': '標本不偏分散', 'ratio': 0.1111111111111111}]",標本分散
3299,3820,sample-efficient,サンプル効率的,0.1111111111111111,9,"[{'word': '標本効率的', 'ratio': 0.5555555555555556}, {'word': 'サンプル効率', 'ratio': 0.2222222222222222}, {'word': 'サンプル効率的', 'ratio': 0.1111111111111111}, {'word': 'サンプル効率が高い', 'ratio': 0.1111111111111111}]",標本効率的
3300,3821,sampler,サンプラー,1.0,9,"[{'word': 'サンプラー', 'ratio': 1.0}]",サンプラー
3301,3822,sampling algorithm,サンプリングアルゴリズム,1.0,9,"[{'word': 'サンプリングアルゴリズム', 'ratio': 1.0}]",サンプリングアルゴリズム
3302,3823,sampling-based inference,サンプリングベース推論,0.1111111111111111,9,"[{'word': 'サンプリングベースの推論', 'ratio': 0.5555555555555556}, {'word': 'サンプリングに基づく推論', 'ratio': 0.2222222222222222}, {'word': 'サンプリングベースの推定', 'ratio': 0.1111111111111111}, {'word': 'サンプリングベース推論', 'ratio': 0.1111111111111111}]",サンプリングベースの推論
3303,3826,scalability,拡張性,0.0,9,"[{'word': 'スケーラビリティ', 'ratio': 1.0}]",スケーラビリティ
3304,3827,scalar,スカラー,1.0,9,"[{'word': 'スカラー', 'ratio': 1.0}]",スカラー
3305,3828,scalar product,スカラー積,1.0,9,"[{'word': 'スカラー積', 'ratio': 1.0}]",スカラー積
3306,3829,scalarization,スカラリゼーション,0.1111111111111111,9,"[{'word': 'スカラー化', 'ratio': 0.8888888888888888}, {'word': 'スカラリゼーション', 'ratio': 0.1111111111111111}]",スカラー化
3307,3830,scale invariance,尺度不変性,0.0,9,"[{'word': 'スケール不変性', 'ratio': 1.0}]",スケール不変性
3308,3831,scale parameter,スケールパラメーター,0.0,9,"[{'word': 'スケールパラメータ', 'ratio': 1.0}]",スケールパラメータ
3309,3834,scaling factor,スケーリング係数,0.2,10,"[{'word': 'スケーリングファクター', 'ratio': 0.7}, {'word': 'スケーリング係数', 'ratio': 0.2}, {'word': '倍率', 'ratio': 0.1}]",スケーリングファクター
3310,3836,scene category,シーンカテゴリ,0.7,10,"[{'word': 'シーンカテゴリ', 'ratio': 0.7}, {'word': 'シーンカテゴリー', 'ratio': 0.3}]",シーンカテゴリ
3311,3837,scene classification,シーン分類,1.0,10,"[{'word': 'シーン分類', 'ratio': 1.0}]",シーン分類
3312,3838,scene classifier,シーン分類器 (Scene classifier),0.0,9,"[{'word': 'シーン分類器', 'ratio': 0.6666666666666666}, {'word': 'シーンクラシファイア', 'ratio': 0.1111111111111111}, {'word': 'シーン分類子', 'ratio': 0.1111111111111111}, {'word': 'Sēn Klassifikā', 'ratio': 0.1111111111111111}]",シーン分類器
3313,3839,scene flow,シーンフロー,0.6666666666666666,9,"[{'word': 'シーンフロー', 'ratio': 0.6666666666666666}, {'word': 'シーンの流れ', 'ratio': 0.2222222222222222}, {'word': 'Sēn Furō', 'ratio': 0.1111111111111111}]",シーンフロー
3314,3840,scene flow estimation,シーンフロー推定,0.7777777777777778,9,"[{'word': 'シーンフロー推定', 'ratio': 0.7777777777777778}, {'word': 'シーンフローの推定', 'ratio': 0.1111111111111111}, {'word': 'Sēn Furō Setsugyō', 'ratio': 0.1111111111111111}]",シーンフロー推定
3315,3841,scene geometry,シーンジオメトリー,0.0,9,"[{'word': 'シーンジオメトリ', 'ratio': 0.6666666666666666}, {'word': 'シーン幾何学', 'ratio': 0.1111111111111111}, {'word': 'シーンのジオメトリ', 'ratio': 0.1111111111111111}, {'word': 'Sēn Gijuri', 'ratio': 0.1111111111111111}]",シーンジオメトリ
3316,3842,scene graph,シーングラフ,0.8888888888888888,9,"[{'word': 'シーングラフ', 'ratio': 0.8888888888888888}, {'word': 'Sēn Gurofu', 'ratio': 0.1111111111111111}]",シーングラフ
3317,3843,scene parsing,シーン解析,0.7,10,"[{'word': 'シーン解析', 'ratio': 0.7}, {'word': 'シーンパースィング', 'ratio': 0.1}, {'word': 'シーンパース', 'ratio': 0.1}, {'word': 'シーンパーシング', 'ratio': 0.1}]",シーン解析
3318,3844,scene recognition,場面認識,0.0,10,"[{'word': 'シーン認識', 'ratio': 1.0}]",シーン認識
3319,3845,scene reconstruction,シーン再構築,0.5,10,"[{'word': 'シーン再構築', 'ratio': 0.5}, {'word': 'シーン再構成', 'ratio': 0.2}, {'word': 'シーンの再構成', 'ratio': 0.1}, {'word': '場面再構成', 'ratio': 0.1}, {'word': 'シーン復元', 'ratio': 0.1}]",シーン再構築
3320,3846,scene representation,シーン表現,1.0,10,"[{'word': 'シーン表現', 'ratio': 1.0}]",シーン表現
3321,3847,scene understanding,シーン理解,0.8,10,"[{'word': 'シーン理解', 'ratio': 0.8}, {'word': '場面理解', 'ratio': 0.1}, {'word': '情景把握', 'ratio': 0.1}]",シーン理解
3322,3848,scheduled sampling,スケジュールサンプリング,0.8,10,"[{'word': 'スケジュールサンプリング', 'ratio': 0.8}, {'word': '定期サンプリング', 'ratio': 0.1}, {'word': '計画されたサンプリング', 'ratio': 0.1}]",スケジュールサンプリング
3323,3849,scheduler,スケジューラ,0.5,10,"[{'word': 'スケジューラ', 'ratio': 0.5}, {'word': 'スケジューラー', 'ratio': 0.5}]",スケジューラ
3324,3850,schema item,スキーマ項目,0.8,10,"[{'word': 'スキーマ項目', 'ratio': 0.8}, {'word': 'スキーマ項', 'ratio': 0.1}, {'word': 'スキーマアイテム', 'ratio': 0.1}]",スキーマ項目
3325,3851,score function,スコア関数,0.9,10,"[{'word': 'スコア関数', 'ratio': 0.9}, {'word': 'スコア機能', 'ratio': 0.1}]",スコア関数
3326,3852,score matching,スコアマッチング,1.0,10,"[{'word': 'スコアマッチング', 'ratio': 1.0}]",スコアマッチング
3327,3853,score vector,スコアベクトル,0.9,10,"[{'word': 'スコアベクトル', 'ratio': 0.9}, {'word': 'Sakuru Vekutā', 'ratio': 0.1}]",スコアベクトル
3328,3854,score-based model,スコアベースモデル,0.7,10,"[{'word': 'スコアベースモデル', 'ratio': 0.7}, {'word': 'スコアベース・モデル', 'ratio': 0.1}, {'word': 'スコアベースのモデル', 'ratio': 0.1}, {'word': 'Sakuru Kaihatsu Modeoru', 'ratio': 0.1}]",スコアベースモデル
3329,3855,scoring function,スコアリング関数,0.7,10,"[{'word': 'スコアリング関数', 'ratio': 0.7}, {'word': '採点機能', 'ratio': 0.1}, {'word': 'スコアリング機能', 'ratio': 0.1}, {'word': 'Sakuringu Fankushon', 'ratio': 0.1}]",スコアリング関数
3330,3856,search algorithm,探索アルゴリズム,0.0,10,"[{'word': '検索アルゴリズム', 'ratio': 0.9}, {'word': '(Sāchi Sōgō', 'ratio': 0.1}]",検索アルゴリズム
3331,3857,search problem,探索問題,0.7777777777777778,9,"[{'word': '探索問題', 'ratio': 0.7777777777777778}, {'word': '検索問題', 'ratio': 0.2222222222222222}]",探索問題
3332,3858,search procedure,探索手順,0.1111111111111111,9,"[{'word': '探索手続き', 'ratio': 0.5555555555555556}, {'word': '検索手順', 'ratio': 0.2222222222222222}, {'word': '調査手順', 'ratio': 0.1111111111111111}, {'word': '探索手順', 'ratio': 0.1111111111111111}]",探索手続き
3333,3859,search space,探索空間,0.7777777777777778,9,"[{'word': '探索空間', 'ratio': 0.7777777777777778}, {'word': 'サーチスペース', 'ratio': 0.1111111111111111}, {'word': '検索手順', 'ratio': 0.1111111111111111}]",探索空間
3334,3860,search tree,探索木,0.6666666666666666,9,"[{'word': '探索木', 'ratio': 0.6666666666666666}, {'word': '検索ツリー', 'ratio': 0.2222222222222222}, {'word': 'サーチツリー', 'ratio': 0.1111111111111111}]",探索木
3335,3862,second order statistic,二次統計量,0.6,10,"[{'word': '二次統計量', 'ratio': 0.6}, {'word': '第二次統計量', 'ratio': 0.2}, {'word': '二次統計', 'ratio': 0.1}, {'word': '2次統計量', 'ratio': 0.1}]",二次統計量
3336,3863,second-order optimization,二次最適化,0.8,10,"[{'word': '二次最適化', 'ratio': 0.8}, {'word': '第二次最適化', 'ratio': 0.1}, {'word': '2階最適化', 'ratio': 0.1}]",二次最適化
3337,3864,second-order potential,二次ポテンシャル,0.8,10,"[{'word': '二次ポテンシャル', 'ratio': 0.8}, {'word': '第二次ポテンシャル', 'ratio': 0.1}, {'word': '2階ポテンシャル', 'ratio': 0.1}]",二次ポテンシャル
3338,3865,segmentation,セグメンテーション,1.0,10,"[{'word': 'セグメンテーション', 'ratio': 1.0}]",セグメンテーション
3339,3866,segmentation algorithm,セグメンテーションアルゴリズム,0.9,10,"[{'word': 'セグメンテーションアルゴリズム', 'ratio': 0.9}, {'word': 'セグメンテーション・アルゴリズム', 'ratio': 0.1}]",セグメンテーションアルゴリズム
3340,3867,segmentation map,セグメンテーションマップ,1.0,9,"[{'word': 'セグメンテーションマップ', 'ratio': 1.0}]",セグメンテーションマップ
3341,3868,segmentation mask,セグメンテーションマスク,1.0,9,"[{'word': 'セグメンテーションマスク', 'ratio': 1.0}]",セグメンテーションマスク
3342,3869,selection bias,選択バイアス,0.8888888888888888,9,"[{'word': '選択バイアス', 'ratio': 0.8888888888888888}, {'word': 'セレクションバイアス', 'ratio': 0.1111111111111111}]",選択バイアス
3343,3871,self-attention head,自己注意ヘッド,0.2222222222222222,9,"[{'word': 'セルフアテンションヘッド', 'ratio': 0.6666666666666666}, {'word': '自己注意ヘッド', 'ratio': 0.2222222222222222}, {'word': '自意識の頭', 'ratio': 0.1111111111111111}]",セルフアテンションヘッド
3344,3872,self-attention layer,自己注意層,0.3,10,"[{'word': 'セルフアテンション層', 'ratio': 0.6}, {'word': '自己注意層', 'ratio': 0.3}, {'word': '自意識層', 'ratio': 0.1}]",セルフアテンション層
3345,3873,self-attention matrix,自己注意行列 (じこちゅういぎょうれつ),0.0,10,"[{'word': 'セルフアテンション行列', 'ratio': 0.6}, {'word': '自己注意行列', 'ratio': 0.2}, {'word': '自己注意マトリックス', 'ratio': 0.2}]",セルフアテンション行列
3346,3875,self-attention model,自己注意モデル,0.4,10,"[{'word': 'セルフアテンションモデル', 'ratio': 0.6}, {'word': '自己注意モデル', 'ratio': 0.4}]",セルフアテンションモデル
3347,3876,self-attention module,自己注意モジュール,0.4,10,"[{'word': 'セルフアテンションモジュール', 'ratio': 0.6}, {'word': '自己注意モジュール', 'ratio': 0.4}]",セルフアテンションモジュール
3348,3877,self-learning,自己学習,0.6,10,"[{'word': '自己学習', 'ratio': 0.6}, {'word': 'セルフラーニング', 'ratio': 0.4}]",自己学習
3349,3878,self-loop,自己ループ,0.8,10,"[{'word': '自己ループ', 'ratio': 0.8}, {'word': 'セルフループ', 'ratio': 0.2}]",自己ループ
3350,3879,self-play,自己対戦,0.6,10,"[{'word': '自己対戦', 'ratio': 0.6}, {'word': 'セルフプレイ', 'ratio': 0.2}, {'word': 'セルフプレー', 'ratio': 0.2}]",自己対戦
3351,3880,self-supervised method,自己教師付き方法,0.0,10,"[{'word': '自己教師あり手法', 'ratio': 0.5}, {'word': '自己教師あり', 'ratio': 0.2}, {'word': 'セルフスーパーバイズ法', 'ratio': 0.1}, {'word': 'セルフスーパーバイズド法', 'ratio': 0.1}, {'word': '自己教師型方法', 'ratio': 0.1}]",自己教師あり手法
3352,3881,self-supervised model,自己教師ありモデル,0.7,10,"[{'word': '自己教師ありモデル', 'ratio': 0.7}, {'word': 'セルフスーパーバイズモデル', 'ratio': 0.1}, {'word': 'セルフスーパーバイズドモデル', 'ratio': 0.1}, {'word': '自己教師型モデル', 'ratio': 0.1}]",自己教師ありモデル
3353,3882,self-supervised representation learning,自己教師あり表現学習,0.7777777777777778,9,"[{'word': '自己教師あり表現学習', 'ratio': 0.7777777777777778}, {'word': '自己教師付き表現学習', 'ratio': 0.1111111111111111}, {'word': '自己教師型表現学習', 'ratio': 0.1111111111111111}]",自己教師あり表現学習
3354,3883,self-supervised signal,自己監督信号,0.0,9,"[{'word': '自己教師あり信号', 'ratio': 0.5555555555555556}, {'word': '自己教師信号', 'ratio': 0.2222222222222222}, {'word': '自己監視信号', 'ratio': 0.1111111111111111}, {'word': '自己教師付き信号', 'ratio': 0.1111111111111111}]",自己教師あり信号
3355,3888,semantic analysis,意味解析,0.4,10,"[{'word': 'セマンティック分析', 'ratio': 0.5}, {'word': '意味解析', 'ratio': 0.4}, {'word': '意味的分析', 'ratio': 0.1}]",セマンティック分析
3356,3890,semantic category,意味カテゴリー,0.0,10,"[{'word': 'セマンティックカテゴリ', 'ratio': 0.5}, {'word': 'セマンティックカテゴリー', 'ratio': 0.2}, {'word': '意味的カテゴリ', 'ratio': 0.1}, {'word': '意味範疇', 'ratio': 0.1}, {'word': '意味カテゴリ', 'ratio': 0.1}]",セマンティックカテゴリ
3357,3891,semantic class,セマンティック分類,0.0,10,"[{'word': 'セマンティッククラス', 'ratio': 0.7}, {'word': '意味クラス', 'ratio': 0.2}, {'word': '意味的クラス', 'ratio': 0.1}]",セマンティッククラス
3358,3892,semantic constraint,意味的制約,0.5555555555555556,9,"[{'word': '意味的制約', 'ratio': 0.5555555555555556}, {'word': '意味上の制約', 'ratio': 0.2222222222222222}, {'word': 'セマンティック制約', 'ratio': 0.1111111111111111}, {'word': '意味制約', 'ratio': 0.1111111111111111}]",意味的制約
3359,3893,semantic distance,意味的距離,0.5555555555555556,9,"[{'word': '意味的距離', 'ratio': 0.5555555555555556}, {'word': 'セマンティック距離', 'ratio': 0.2222222222222222}, {'word': '意味距離', 'ratio': 0.2222222222222222}]",意味的距離
3360,3895,semantic equivalence,意味的同値性,0.0,9,"[{'word': '意味的同等性', 'ratio': 0.6666666666666666}, {'word': 'いみどうけい', 'ratio': 0.2222222222222222}, {'word': 'セマンティック同値', 'ratio': 0.1111111111111111}]",意味的同等性
3361,3896,semantic feature,意味的特徴,0.5555555555555556,9,"[{'word': '意味的特徴', 'ratio': 0.5555555555555556}, {'word': '意味機能', 'ratio': 0.2222222222222222}, {'word': 'セマンティック特徴', 'ratio': 0.1111111111111111}, {'word': '意味特徴', 'ratio': 0.1111111111111111}]",意味的特徴
3362,3897,semantic graph,意味グラフ,0.2,10,"[{'word': 'セマンティックグラフ', 'ratio': 0.6}, {'word': '意味論的グラフ', 'ratio': 0.2}, {'word': '意味グラフ', 'ratio': 0.2}]",セマンティックグラフ
3363,3898,semantic information,意味情報,0.3,10,"[{'word': 'セマンティック情報', 'ratio': 0.5}, {'word': '意味情報', 'ratio': 0.3}, {'word': '説明情報', 'ratio': 0.1}, {'word': '意味論的情報', 'ratio': 0.1}]",セマンティック情報
3364,3899,semantic interpretation,意味解釈,0.2,10,"[{'word': 'セマンティック解釈', 'ratio': 0.5}, {'word': '意味論的解釈', 'ratio': 0.2}, {'word': '意味解釈', 'ratio': 0.2}, {'word': '説明解釈', 'ratio': 0.1}]",セマンティック解釈
3365,3900,semantic label,意味ラベル,0.2,10,"[{'word': 'セマンティックラベル', 'ratio': 0.6}, {'word': '意味ラベル', 'ratio': 0.2}, {'word': '説明ラベル', 'ratio': 0.1}, {'word': '意味論的ラベル', 'ratio': 0.1}]",セマンティックラベル
3366,3901,semantic memory,意味記憶,0.3,10,"[{'word': 'セマンティックメモリ', 'ratio': 0.5}, {'word': '意味記憶', 'ratio': 0.3}, {'word': '説明記憶', 'ratio': 0.1}, {'word': '意味論的記憶', 'ratio': 0.1}]",セマンティックメモリ
3367,3902,semantic model,意味モデル,0.2222222222222222,9,"[{'word': 'セマンティックモデル', 'ratio': 0.6666666666666666}, {'word': '意味モデル', 'ratio': 0.2222222222222222}, {'word': '意味論モデル', 'ratio': 0.1111111111111111}]",セマンティックモデル
3368,3903,semantic network,意味ネットワーク,0.1111111111111111,9,"[{'word': 'セマンティックネットワーク', 'ratio': 0.7777777777777778}, {'word': '意味ネットワーク', 'ratio': 0.1111111111111111}, {'word': '意味論ネットワーク', 'ratio': 0.1111111111111111}]",セマンティックネットワーク
3369,3904,semantic object,意味的オブジェクト,0.0,9,"[{'word': 'セマンティックオブジェクト', 'ratio': 0.6666666666666666}, {'word': '意味オブジェクト', 'ratio': 0.2222222222222222}, {'word': '意味論的オブジェクト', 'ratio': 0.1111111111111111}]",セマンティックオブジェクト
3370,3908,semantic priming,意味プライミング,0.1,10,"[{'word': 'セマンティックプライミング', 'ratio': 0.8}, {'word': '意味的プライミング', 'ratio': 0.1}, {'word': '意味プライミング', 'ratio': 0.1}]",セマンティックプライミング
3371,3909,semantic relation,意味関係,0.1,10,"[{'word': 'セマンティック関係', 'ratio': 0.6}, {'word': '意味的関係', 'ratio': 0.2}, {'word': 'いみかんけい', 'ratio': 0.1}, {'word': '意味関係', 'ratio': 0.1}]",セマンティック関係
3372,3910,semantic representation,意味表現,0.3,10,"[{'word': 'セマンティック表現', 'ratio': 0.6}, {'word': '意味表現', 'ratio': 0.3}, {'word': '意味的表現', 'ratio': 0.1}]",セマンティック表現
3373,3911,semantic role,意味役割,0.2,10,"[{'word': 'セマンティックロール', 'ratio': 0.6}, {'word': '意味役割', 'ratio': 0.2}, {'word': '意味論的な役割', 'ratio': 0.1}, {'word': '意味的役割', 'ratio': 0.1}]",セマンティックロール
3374,3912,semantic role label,意味役割ラベル,0.8,10,"[{'word': '意味役割ラベル', 'ratio': 0.8}, {'word': 'セマンティックロールラベル', 'ratio': 0.2}]",意味役割ラベル
3375,3913,semantic search,セマンティック検索,0.6,10,"[{'word': 'セマンティック検索', 'ratio': 0.6}, {'word': 'セマンティックサーチ', 'ratio': 0.3}, {'word': '意味検索', 'ratio': 0.1}]",セマンティック検索
3376,3914,semantic segmentation,意味的セグメンテーション,0.0,10,"[{'word': 'セマンティックセグメンテーション', 'ratio': 1.0}]",セマンティックセグメンテーション
3377,3917,semantic space,意味空間,0.7,10,"[{'word': '意味空間', 'ratio': 0.7}, {'word': 'セマンティック空間', 'ratio': 0.2}, {'word': 'セマンティックスペース', 'ratio': 0.1}]",意味空間
3378,3918,semantic structure,意味構造,0.7,10,"[{'word': '意味構造', 'ratio': 0.7}, {'word': 'セマンティック構造', 'ratio': 0.3}]",意味構造
3379,3919,semantic symbol,意味記号,0.6,10,"[{'word': '意味記号', 'ratio': 0.6}, {'word': 'セマンティックシンボル', 'ratio': 0.3}, {'word': '意味シンボル', 'ratio': 0.1}]",意味記号
3380,3920,semantic textual similarity,意味的なテキストの類似性,0.0,10,"[{'word': '意味的テキスト類似性', 'ratio': 0.6}, {'word': 'セマンティックテキスト類似性', 'ratio': 0.2}, {'word': 'セマンティックテキスト類似度', 'ratio': 0.1}, {'word': '意味テキスト類似性', 'ratio': 0.1}]",意味的テキスト類似性
3381,3921,semantic unit,意味単位,0.6,10,"[{'word': '意味単位', 'ratio': 0.6}, {'word': 'セマンティック単位', 'ratio': 0.2}, {'word': 'セマンティックユニット', 'ratio': 0.1}, {'word': '意味ユニット', 'ratio': 0.1}]",意味単位
3382,3922,semantic vector,セマンティックベクトル,0.3,10,"[{'word': '意味ベクトル', 'ratio': 0.6}, {'word': 'セマンティックベクトル', 'ratio': 0.3}, {'word': 'セマンティックベクター', 'ratio': 0.1}]",意味ベクトル
3383,3923,semantic vector space,意味ベクトル空間,0.6,10,"[{'word': '意味ベクトル空間', 'ratio': 0.6}, {'word': 'セマンティックベクトル空間', 'ratio': 0.3}, {'word': 'セマンティックベクタースペース', 'ratio': 0.1}]",意味ベクトル空間
3384,3926,semi-supervised clustering,半教師ありクラスタリング,0.8888888888888888,9,"[{'word': '半教師ありクラスタリング', 'ratio': 0.8888888888888888}, {'word': '半教師付きクラスタリング', 'ratio': 0.1111111111111111}]",半教師ありクラスタリング
3385,3927,semi-supervised learning,半教師あり学習,0.8888888888888888,9,"[{'word': '半教師あり学習', 'ratio': 0.8888888888888888}, {'word': '半教師付き学習', 'ratio': 0.1111111111111111}]",半教師あり学習
3386,3928,semi-supervision,半教師あり学習,0.0,9,"[{'word': '半教師あり', 'ratio': 0.5555555555555556}, {'word': '半監督', 'ratio': 0.2222222222222222}, {'word': '半教師化', 'ratio': 0.1111111111111111}, {'word': '半教師', 'ratio': 0.1111111111111111}]",半教師あり
3387,3929,semidefinite program,半定値計画,0.0,9,"[{'word': '半正定値プログラム', 'ratio': 0.7777777777777778}, {'word': '半定義プログラム', 'ratio': 0.1111111111111111}, {'word': '半定理プログラム', 'ratio': 0.1111111111111111}]",半正定値プログラム
3388,3930,sense disambiguation,曖昧さ回避,0.1,10,"[{'word': '意味の曖昧さ解消', 'ratio': 0.6}, {'word': '意味の曖昧性解消', 'ratio': 0.2}, {'word': 'センス曖昧さ回避', 'ratio': 0.1}, {'word': '曖昧さ回避', 'ratio': 0.1}]",意味の曖昧さ解消
3389,3932,sensitivity analysis,感度分析,1.0,10,"[{'word': '感度分析', 'ratio': 1.0}]",感度分析
3390,3933,sentence classification,文分類,0.5,10,"[{'word': '文分類', 'ratio': 0.5}, {'word': '文の分類', 'ratio': 0.4}, {'word': '文節分類', 'ratio': 0.1}]",文分類
3391,3934,sentence compression,文章圧縮,0.1,10,"[{'word': '文圧縮', 'ratio': 0.5}, {'word': '文の圧縮', 'ratio': 0.3}, {'word': '文章圧縮', 'ratio': 0.1}, {'word': '文節圧縮', 'ratio': 0.1}]",文圧縮
3392,3935,sentence embedding,文埋め込み,0.5,10,"[{'word': '文埋め込み', 'ratio': 0.5}, {'word': '文の埋め込み', 'ratio': 0.3}, {'word': 'センテンスエンベッディング', 'ratio': 0.1}, {'word': '文節埋め込み', 'ratio': 0.1}]",文埋め込み
3393,3937,sentence representation,文の表現,0.2,10,"[{'word': '文表現', 'ratio': 0.5}, {'word': '文章表現', 'ratio': 0.2}, {'word': '文の表現', 'ratio': 0.2}, {'word': '文節表現', 'ratio': 0.1}]",文表現
3394,3939,sentence vector,文ベクトル,0.9,10,"[{'word': '文ベクトル', 'ratio': 0.9}, {'word': '文節ベクター', 'ratio': 0.1}]",文ベクトル
3395,3940,sentence-level,文レベル,0.9,10,"[{'word': '文レベル', 'ratio': 0.9}, {'word': '文節レベル', 'ratio': 0.1}]",文レベル
3396,3941,sentence-level classification,文章レベルの分類,0.0,10,"[{'word': '文レベル分類', 'ratio': 0.8}, {'word': '文レベルの分類', 'ratio': 0.1}, {'word': '文節分類', 'ratio': 0.1}]",文レベル分類
3397,3942,sentence-level representation,文レベル表現,0.7,10,"[{'word': '文レベル表現', 'ratio': 0.7}, {'word': '文レベルの表現', 'ratio': 0.1}, {'word': '文節表現', 'ratio': 0.1}, {'word': '文レベル分類', 'ratio': 0.1}]",文レベル表現
3398,3943,sentiment analysis model,感情分析モデル,0.8888888888888888,9,"[{'word': '感情分析モデル', 'ratio': 0.8888888888888888}, {'word': 'センチメント分析モデル', 'ratio': 0.1111111111111111}]",感情分析モデル
3399,3944,sentiment classification,感情分類,0.7777777777777778,9,"[{'word': '感情分類', 'ratio': 0.7777777777777778}, {'word': 'センチメント分類', 'ratio': 0.1111111111111111}, {'word': '感情の分類', 'ratio': 0.1111111111111111}]",感情分類
3400,3945,sentiment classifier,感情分類器,0.7777777777777778,9,"[{'word': '感情分類器', 'ratio': 0.7777777777777778}, {'word': 'センチメント分類器', 'ratio': 0.1111111111111111}, {'word': '感情分類子', 'ratio': 0.1111111111111111}]",感情分類器
3401,3946,sentiment detection,感情検出,0.9,10,"[{'word': '感情検出', 'ratio': 0.9}, {'word': 'センチメント検出', 'ratio': 0.1}]",感情検出
3402,3947,sentiment transfer,感情転移,0.2,10,"[{'word': '感情転送', 'ratio': 0.5}, {'word': '感情移入', 'ratio': 0.2}, {'word': '感情転移', 'ratio': 0.2}, {'word': '感情移転', 'ratio': 0.1}]",感情転送
3403,3948,separation oracle,分離オラクル,0.6,10,"[{'word': '分離オラクル', 'ratio': 0.6}, {'word': 'セパレーションオラクル', 'ratio': 0.2}, {'word': 'ぶんりのおみくじ', 'ratio': 0.1}, {'word': '分離の神託', 'ratio': 0.1}]",分離オラクル
3404,3949,separation parameter,分離パラメータ,0.8,10,"[{'word': '分離パラメータ', 'ratio': 0.8}, {'word': 'セパレーションパラメータ', 'ratio': 0.2}]",分離パラメータ
3405,3950,separator token,セパレータトークン,0.7,10,"[{'word': 'セパレータトークン', 'ratio': 0.7}, {'word': '区切りトークン', 'ratio': 0.2}, {'word': 'セパレータートークン', 'ratio': 0.1}]",セパレータトークン
3406,3952,sequence,シーケンス,0.8888888888888888,18,"[{'word': 'シーケンス', 'ratio': 0.8888888888888888}, {'word': '順序', 'ratio': 0.1111111111111111}]",シーケンス
3407,3953,sequence alignment,シーケンスアライメント,0.5555555555555556,9,"[{'word': 'シーケンスアライメント', 'ratio': 0.5555555555555556}, {'word': '配列アラインメント', 'ratio': 0.2222222222222222}, {'word': 'シーケンスのアライメント', 'ratio': 0.1111111111111111}, {'word': 'シーケンスアラインメント', 'ratio': 0.1111111111111111}]",シーケンスアライメント
3408,3954,sequence classification,シーケンス分類,0.5,10,"[{'word': 'シーケンス分類', 'ratio': 0.5}, {'word': '系列分類', 'ratio': 0.2}, {'word': '配列の分類', 'ratio': 0.1}, {'word': 'シーケンス', 'ratio': 0.1}, {'word': '列の分類', 'ratio': 0.1}]",シーケンス分類
3409,3956,sequence generation,シーケンス生成,0.5,10,"[{'word': 'シーケンス生成', 'ratio': 0.5}, {'word': '系列生成', 'ratio': 0.2}, {'word': 'シーケンスの生成', 'ratio': 0.1}, {'word': 'シーケンシャル意思決定', 'ratio': 0.1}, {'word': '列生成', 'ratio': 0.1}]",シーケンス生成
3410,3957,sequence labeling,シーケンスラベリング,0.5,10,"[{'word': 'シーケンスラベリング', 'ratio': 0.5}, {'word': '系列ラベリング', 'ratio': 0.2}, {'word': '配列のラベリング', 'ratio': 0.1}, {'word': 'シーケンシャル意思決定プロセス', 'ratio': 0.1}, {'word': '列ラベリング', 'ratio': 0.1}]",シーケンスラベリング
3411,3959,sequence length,シーケンス長,0.7,10,"[{'word': 'シーケンス長', 'ratio': 0.7}, {'word': 'シーケンスの長さ', 'ratio': 0.2}, {'word': '列の長さ', 'ratio': 0.1}]",シーケンス長
3412,3960,sequence model,系列モデル,0.1,10,"[{'word': 'シーケンスモデル', 'ratio': 0.9}, {'word': '系列モデル', 'ratio': 0.1}]",シーケンスモデル
3413,3961,sequence prediction,シーケンス予測 (shīkensu yosoku),0.0,10,"[{'word': 'シーケンス予測', 'ratio': 0.7}, {'word': '配列予測', 'ratio': 0.2}, {'word': '系列予測', 'ratio': 0.1}]",シーケンス予測
3414,3962,sequence tagging,系列タグ付け,0.1,10,"[{'word': 'シーケンスタギング', 'ratio': 0.6}, {'word': 'シーケンスタグ付け', 'ratio': 0.2}, {'word': 'シーケンスのタグ付け', 'ratio': 0.1}, {'word': '系列タグ付け', 'ratio': 0.1}]",シーケンスタギング
3415,3963,sequence transduction,シーケンス変換,0.0,10,"[{'word': 'シーケンストランスダクション', 'ratio': 0.6}, {'word': '配列導入', 'ratio': 0.1}, {'word': '配列伝達', 'ratio': 0.1}, {'word': 'シーケンストランスデューション', 'ratio': 0.1}, {'word': '系列変換', 'ratio': 0.1}]",シーケンストランスダクション
3416,3964,sequence-to-sequence,シーケンスツーシーケンス,0.0,10,"[{'word': 'シーケンス・ツー・シーケンス', 'ratio': 0.7}, {'word': 'シーケンス間', 'ratio': 0.2}, {'word': 'シーケンス間変換', 'ratio': 0.1}]",シーケンス・ツー・シーケンス
3417,3965,sequence-to-sequence architecture,シーケンス・ツー・シーケンス・アーキテクチャ,0.0,10,"[{'word': 'シーケンス・ツー・シーケンスアーキテクチャ', 'ratio': 0.7}, {'word': 'シーケンス間アーキテクチャ', 'ratio': 0.2}, {'word': 'シーケンス間変換アーキテクチャ', 'ratio': 0.1}]",シーケンス・ツー・シーケンスアーキテクチャ
3418,3966,sequence-to-sequence generation,シーケンス対シーケンス生成,0.0,10,"[{'word': 'シーケンス・ツー・シーケンス生成', 'ratio': 0.7}, {'word': 'シーケンス間生成', 'ratio': 0.3}]",シーケンス・ツー・シーケンス生成
3419,3967,sequence-to-sequence model,シーケンス対シーケンスモデル,0.0,10,"[{'word': 'シーケンス・ツー・シーケンスモデル', 'ratio': 0.7}, {'word': '配列間モデル', 'ratio': 0.2}, {'word': 'シーケンス間モデル', 'ratio': 0.1}]",シーケンス・ツー・シーケンスモデル
3420,3968,sequence-to-sequence transduction,シーケンス対シーケンス変換,0.0,10,"[{'word': 'シーケンス・ツー・シーケンストランスダクション', 'ratio': 0.5}, {'word': 'シーケンス・ツー・シーケンス変換', 'ratio': 0.2}, {'word': '配列間トランスダクション', 'ratio': 0.2}, {'word': 'シーケンス間伝達', 'ratio': 0.1}]",シーケンス・ツー・シーケンストランスダクション
3421,3975,set function,集合関数,0.5,10,"[{'word': '集合関数', 'ratio': 0.5}, {'word': 'セット関数', 'ratio': 0.4}, {'word': 'セット機能', 'ratio': 0.1}]",集合関数
3422,3976,shallow network,浅いネットワーク,0.8,10,"[{'word': '浅いネットワーク', 'ratio': 0.8}, {'word': '浅層ネットワーク', 'ratio': 0.2}]",浅いネットワーク
3423,3977,shape matching,形状マッチング,0.7,10,"[{'word': '形状マッチング', 'ratio': 0.7}, {'word': 'シェイプマッチング', 'ratio': 0.1}, {'word': '形状一致', 'ratio': 0.1}, {'word': 'シェイプ・マッチング', 'ratio': 0.1}]",形状マッチング
3424,3978,shape prior,形状事前確率,0.0,10,"[{'word': '形状事前情報', 'ratio': 0.5}, {'word': '形状事前分布', 'ratio': 0.2}, {'word': '形状先行', 'ratio': 0.2}, {'word': '形状事前知識', 'ratio': 0.1}]",形状事前情報
3425,3979,shift invariant,シフト不変,0.9,10,"[{'word': 'シフト不変', 'ratio': 0.9}, {'word': '平行移動不変', 'ratio': 0.1}]",シフト不変
3426,3981,shortest path,最短経路,1.0,10,"[{'word': '最短経路', 'ratio': 1.0}]",最短経路
3427,3982,shortest path algorithm,最短経路アルゴリズム,0.6666666666666666,9,"[{'word': '最短経路アルゴリズム', 'ratio': 0.6666666666666666}, {'word': '最短パスアルゴリズム', 'ratio': 0.3333333333333333}]",最短経路アルゴリズム
3428,3983,shortest path kernel,最短経路カーネル,0.6666666666666666,9,"[{'word': '最短経路カーネル', 'ratio': 0.6666666666666666}, {'word': '最短パスカーネル', 'ratio': 0.3333333333333333}]",最短経路カーネル
3429,3984,shortest path length,最短経路長,0.8888888888888888,9,"[{'word': '最短経路長', 'ratio': 0.8888888888888888}, {'word': '最短パス長', 'ratio': 0.1111111111111111}]",最短経路長
3430,3985,sibling model,兄弟モデル,0.5555555555555556,9,"[{'word': '兄弟モデル', 'ratio': 0.5555555555555556}, {'word': '姉妹モデル', 'ratio': 0.2222222222222222}, {'word': 'ブリングモデル', 'ratio': 0.1111111111111111}, {'word': 'シブリングモデル', 'ratio': 0.1111111111111111}]",兄弟モデル
3431,3986,sigmoid activation,シグモイド活性化関数,0.0,9,"[{'word': 'シグモイド活性化', 'ratio': 0.8888888888888888}, {'word': 'シグモイドアクティベーション', 'ratio': 0.1111111111111111}]",シグモイド活性化
3432,3987,sigmoid activation function,シグモイド活性化関数,1.0,10,"[{'word': 'シグモイド活性化関数', 'ratio': 1.0}]",シグモイド活性化関数
3433,3988,signal-to-noise ratio,信号対雑音比,0.9,10,"[{'word': '信号対雑音比', 'ratio': 0.9}, {'word': '信号雑音比', 'ratio': 0.1}]",信号対雑音比
3434,3989,sim,類似度,0.8,10,"[{'word': '類似度', 'ratio': 0.8}, {'word': 'シム', 'ratio': 0.2}]",類似度
3435,3990,similarity function,類似度関数,0.9,10,"[{'word': '類似度関数', 'ratio': 0.9}, {'word': '類似関数', 'ratio': 0.1}]",類似度関数
3436,3995,similarity score,類似性スコア,0.6666666666666666,9,"[{'word': '類似性スコア', 'ratio': 0.6666666666666666}, {'word': '類似度スコア', 'ratio': 0.2222222222222222}, {'word': 'Kijutsu Shohaku', 'ratio': 0.1111111111111111}]",類似性スコア
3437,3996,similarity search,類似検索,0.7777777777777778,9,"[{'word': '類似検索', 'ratio': 0.7777777777777778}, {'word': '類似性検索', 'ratio': 0.2222222222222222}]",類似検索
3438,3998,simulated annealing,シミュレーテッドアニーリング,1.0,9,"[{'word': 'シミュレーテッドアニーリング', 'ratio': 1.0}]",シミュレーテッドアニーリング
3439,3999,single task learning,単一タスク学習,0.7777777777777778,9,"[{'word': '単一タスク学習', 'ratio': 0.7777777777777778}, {'word': 'シングルタスク学習', 'ratio': 0.2222222222222222}]",単一タスク学習
3440,4000,single-label classification,単一ラベル分類,0.9,10,"[{'word': '単一ラベル分類', 'ratio': 0.9}, {'word': '一-label 分類', 'ratio': 0.1}]",単一ラベル分類
3441,4001,single-view data,単一視点データ,0.0,10,"[{'word': '単一ビューデータ', 'ratio': 0.6}, {'word': 'シングルビューデータ', 'ratio': 0.2}, {'word': '単視データ', 'ratio': 0.1}, {'word': '単一ビューのデータ', 'ratio': 0.1}]",単一ビューデータ
3442,4002,singleton,シングルトン,0.7,10,"[{'word': 'シングルトン', 'ratio': 0.7}, {'word': '単体', 'ratio': 0.1}, {'word': '単項集合', 'ratio': 0.1}, {'word': '単一要素', 'ratio': 0.1}]",シングルトン
3443,4003,singular value,特異値,0.9,10,"[{'word': '特異値', 'ratio': 0.9}, {'word': 'singular値', 'ratio': 0.1}]",特異値
3444,4004,singular vector,特異ベクトル,0.9,10,"[{'word': '特異ベクトル', 'ratio': 0.9}, {'word': 'singularベクトル', 'ratio': 0.1}]",特異ベクトル
3445,4005,skip connection,スキップ接続,0.8888888888888888,9,"[{'word': 'スキップ接続', 'ratio': 0.8888888888888888}, {'word': '接続をスキップする', 'ratio': 0.1111111111111111}]",スキップ接続
3446,4006,skip-gram,スキップグラム,1.0,9,"[{'word': 'スキップグラム', 'ratio': 1.0}]",スキップグラム
3447,4007,skip-gram model,スキップグラムモデル,1.0,9,"[{'word': 'スキップグラムモデル', 'ratio': 1.0}]",スキップグラムモデル
3448,4008,slack variable,スラック変数,1.0,9,"[{'word': 'スラック変数', 'ratio': 1.0}]",スラック変数
3449,4009,sliding window,スライディングウィンドウ,0.7777777777777778,9,"[{'word': 'スライディングウィンドウ', 'ratio': 0.7777777777777778}, {'word': 'スライディングウインドー', 'ratio': 0.1111111111111111}, {'word': '引き違い窓', 'ratio': 0.1111111111111111}]",スライディングウィンドウ
3450,4010,sliding window classifier,スライディングウィンドウ分類器,0.7777777777777778,9,"[{'word': 'スライディングウィンドウ分類器', 'ratio': 0.7777777777777778}, {'word': 'スライディング ウィンドウ分類器', 'ratio': 0.1111111111111111}, {'word': 'Soridori Jūdo Klassifikā', 'ratio': 0.1111111111111111}]",スライディングウィンドウ分類器
3451,4011,slot,スロット,0.8888888888888888,9,"[{'word': 'スロット', 'ratio': 0.8888888888888888}, {'word': 'Suro', 'ratio': 0.1111111111111111}]",スロット
3452,4012,slot filling,スロット充填,0.8888888888888888,9,"[{'word': 'スロット充填', 'ratio': 0.8888888888888888}, {'word': 'Suro Teian', 'ratio': 0.1111111111111111}]",スロット充填
3453,4013,slot value,スロット値,0.8888888888888888,9,"[{'word': 'スロット値', 'ratio': 0.8888888888888888}, {'word': 'Suro Bāru', 'ratio': 0.1111111111111111}]",スロット値
3454,4014,slot-value pair,スロット値ペア,0.2222222222222222,9,"[{'word': 'スロット-値ペア', 'ratio': 0.5555555555555556}, {'word': 'スロット値ペア', 'ratio': 0.2222222222222222}, {'word': 'スロット値のペア', 'ratio': 0.1111111111111111}, {'word': 'Suro-Bāru Pāi', 'ratio': 0.1111111111111111}]",スロット-値ペア
3455,4015,smoothing parameter,平滑化パラメータ,0.3333333333333333,9,"[{'word': 'スムージングパラメータ', 'ratio': 0.5555555555555556}, {'word': '平滑化パラメータ', 'ratio': 0.3333333333333333}, {'word': 'スムージングパラメーター', 'ratio': 0.1111111111111111}]",スムージングパラメータ
3456,4017,social bias,社会的偏見,0.2222222222222222,9,"[{'word': '社会的バイアス', 'ratio': 0.6666666666666666}, {'word': '社会的偏見', 'ratio': 0.2222222222222222}, {'word': '社会バイアス', 'ratio': 0.1111111111111111}]",社会的バイアス
3457,4018,social network analysis,ソーシャルネットワーク分析,0.6666666666666666,9,"[{'word': 'ソーシャルネットワーク分析', 'ratio': 0.6666666666666666}, {'word': '社会ネットワーク分析', 'ratio': 0.2222222222222222}, {'word': '社会ネットワーク解析', 'ratio': 0.1111111111111111}]",ソーシャルネットワーク分析
3458,4019,soft margin,ソフトマージン,1.0,9,"[{'word': 'ソフトマージン', 'ratio': 1.0}]",ソフトマージン
3459,4020,softmax activation,ソフトマックス活性化,1.0,9,"[{'word': 'ソフトマックス活性化', 'ratio': 1.0}]",ソフトマックス活性化
3460,4021,softmax activation function,ソフトマックス活性化関数,1.0,9,"[{'word': 'ソフトマックス活性化関数', 'ratio': 1.0}]",ソフトマックス活性化関数
3461,4022,softmax classifier,ソフトマックス分類器,1.0,9,"[{'word': 'ソフトマックス分類器', 'ratio': 1.0}]",ソフトマックス分類器
3462,4023,softmax distribution,ソフトマックス分布,1.0,9,"[{'word': 'ソフトマックス分布', 'ratio': 1.0}]",ソフトマックス分布
3463,4024,softmax function,ソフトマックス関数,1.0,9,"[{'word': 'ソフトマックス関数', 'ratio': 1.0}]",ソフトマックス関数
3464,4025,softmax loss,ソフトマックス損失,0.7777777777777778,9,"[{'word': 'ソフトマックス損失', 'ratio': 0.7777777777777778}, {'word': 'ソフトマックス・ロス', 'ratio': 0.2222222222222222}]",ソフトマックス損失
3465,4026,softplus,ソフトプラス関数,0.0,9,"[{'word': 'ソフトプラス', 'ratio': 1.0}]",ソフトプラス
3466,4027,softplus activation,ソフトプラス活性化関数,0.0,9,"[{'word': 'ソフトプラス活性化', 'ratio': 0.6666666666666666}, {'word': 'ソフトプラス起動', 'ratio': 0.2222222222222222}, {'word': 'ソフトプラスアクティベーション', 'ratio': 0.1111111111111111}]",ソフトプラス活性化
3467,4028,softplus function,ソフトプラス関数,0.6666666666666666,9,"[{'word': 'ソフトプラス関数', 'ratio': 0.6666666666666666}, {'word': 'ソフトプラス機能', 'ratio': 0.2222222222222222}, {'word': 'Sofutopurusu Funkushon', 'ratio': 0.1111111111111111}]",ソフトプラス関数
3468,4029,solution space,解空間,0.6666666666666666,9,"[{'word': '解空間', 'ratio': 0.6666666666666666}, {'word': '溶解空間', 'ratio': 0.1111111111111111}, {'word': 'ソリューションスペース', 'ratio': 0.1111111111111111}, {'word': 'Sōrūshippusuvu', 'ratio': 0.1111111111111111}]",解空間
3469,4030,solver,ソルバー,0.8888888888888888,9,"[{'word': 'ソルバー', 'ratio': 0.8888888888888888}, {'word': 'Soribā', 'ratio': 0.1111111111111111}]",ソルバー
3470,4031,source domain,ソースドメイン,0.8888888888888888,9,"[{'word': 'ソースドメイン', 'ratio': 0.8888888888888888}, {'word': 'Sāsu Domaín', 'ratio': 0.1111111111111111}]",ソースドメイン
3471,4032,source model,元モデル,0.0,10,"[{'word': 'ソースモデル', 'ratio': 1.0}]",ソースモデル
3472,4033,source node,入力ノード,0.0,10,"[{'word': 'ソースノード', 'ratio': 1.0}]",ソースノード
3473,4034,source sequence,入力シーケンス,0.0,10,"[{'word': 'ソースシーケンス', 'ratio': 1.0}]",ソースシーケンス
3474,4035,source token,ソーストークン,1.0,10,"[{'word': 'ソーストークン', 'ratio': 1.0}]",ソーストークン
3475,4036,source word,ソース語,0.0,10,"[{'word': 'ソースワード', 'ratio': 0.9}, {'word': '原語', 'ratio': 0.1}]",ソースワード
3476,4037,space carving,スペースカービング,0.7,10,"[{'word': 'スペースカービング', 'ratio': 0.7}, {'word': '空間彫刻', 'ratio': 0.2}, {'word': '空間切り取り', 'ratio': 0.1}]",スペースカービング
3477,4039,space partitioning,空間分割,0.8,10,"[{'word': '空間分割', 'ratio': 0.8}, {'word': 'スペース・パーティション', 'ratio': 0.2}]",空間分割
3478,4040,spam detection,迷惑メール検出,0.0,10,"[{'word': 'スパム検出', 'ratio': 1.0}]",スパム検出
3479,4041,spam filtering,スパムフィルタリング,1.0,10,"[{'word': 'スパムフィルタリング', 'ratio': 1.0}]",スパムフィルタリング
3480,4042,span,スパン,0.7777777777777778,9,"[{'word': 'スパン', 'ratio': 0.7777777777777778}, {'word': '張り', 'ratio': 0.1111111111111111}, {'word': '線形包', 'ratio': 0.1111111111111111}]",スパン
3481,4043,sparse approximation,疎近似,0.5555555555555556,9,"[{'word': '疎近似', 'ratio': 0.5555555555555556}, {'word': 'スパース近似', 'ratio': 0.4444444444444444}]",疎近似
3482,4046,sparse graph,疎なグラフ (Sparse Graph),0.0,10,"[{'word': '疎グラフ', 'ratio': 0.6}, {'word': 'スパースグラフ', 'ratio': 0.3}, {'word': '希薄グラフ', 'ratio': 0.1}]",疎グラフ
3483,4047,sparse matrix,疎行列,0.6,10,"[{'word': '疎行列', 'ratio': 0.6}, {'word': 'スパース行列', 'ratio': 0.2}, {'word': 'スパースマトリックス', 'ratio': 0.1}, {'word': '希薄行列', 'ratio': 0.1}]",疎行列
3484,4048,sparse model,疎モデル,0.3,10,"[{'word': 'スパースモデル', 'ratio': 0.5}, {'word': '疎モデル', 'ratio': 0.3}, {'word': '疎モデル疎復元', 'ratio': 0.1}, {'word': '希薄モデル', 'ratio': 0.1}]",スパースモデル
3485,4051,sparse sampling,疎サンプリング,0.2222222222222222,9,"[{'word': 'スパースサンプリング', 'ratio': 0.7777777777777778}, {'word': '疎サンプリング', 'ratio': 0.2222222222222222}]",スパースサンプリング
3486,4052,sparse vector,疎ベクトル,0.2222222222222222,9,"[{'word': 'スパースベクトル', 'ratio': 0.5555555555555556}, {'word': '疎ベクトル', 'ratio': 0.2222222222222222}, {'word': 'スパースベクター', 'ratio': 0.2222222222222222}]",スパースベクトル
3487,4056,sparsity regularization,疎性正規化,0.0,10,"[{'word': 'スパース性正則化', 'ratio': 0.6}, {'word': 'スパース正則化', 'ratio': 0.2}, {'word': 'スパーシティ正則化', 'ratio': 0.1}, {'word': 'スパーシティ規則化', 'ratio': 0.1}]",スパース性正則化
3488,4057,spatial domain,空間領域,0.5,10,"[{'word': '空間領域', 'ratio': 0.5}, {'word': '空間ドメイン', 'ratio': 0.5}]",空間領域
3489,4058,spatial gradient,空間勾配,1.0,10,"[{'word': '空間勾配', 'ratio': 1.0}]",空間勾配
3490,4059,spatial pooling,空間プーリング,0.9,10,"[{'word': '空間プーリング', 'ratio': 0.9}, {'word': '空間プール', 'ratio': 0.1}]",空間プーリング
3491,4060,spatial pyramid,空間ピラミッド,1.0,9,"[{'word': '空間ピラミッド', 'ratio': 1.0}]",空間ピラミッド
3492,4061,special token,特殊トークン,0.6666666666666666,9,"[{'word': '特殊トークン', 'ratio': 0.6666666666666666}, {'word': '特別トークン', 'ratio': 0.2222222222222222}, {'word': '特別なトークン', 'ratio': 0.1111111111111111}]",特殊トークン
3493,4062,spectral algorithm,スペクトルアルゴリズム,1.0,9,"[{'word': 'スペクトルアルゴリズム', 'ratio': 1.0}]",スペクトルアルゴリズム
3494,4063,spectral clustering,スペクトルクラスタリング,1.0,9,"[{'word': 'スペクトルクラスタリング', 'ratio': 1.0}]",スペクトルクラスタリング
3495,4064,spectral decomposition,スペクトル分解,1.0,9,"[{'word': 'スペクトル分解', 'ratio': 1.0}]",スペクトル分解
3496,4065,spectral embedding,スペクトル埋め込み,1.0,10,"[{'word': 'スペクトル埋め込み', 'ratio': 1.0}]",スペクトル埋め込み
3497,4066,spectral gap,スペクトルギャップ,1.0,10,"[{'word': 'スペクトルギャップ', 'ratio': 1.0}]",スペクトルギャップ
3498,4067,spectral learning,スペクトル学習,1.0,10,"[{'word': 'スペクトル学習', 'ratio': 1.0}]",スペクトル学習
3499,4068,spectral matching,スペクトルマッチング,1.0,10,"[{'word': 'スペクトルマッチング', 'ratio': 1.0}]",スペクトルマッチング
3500,4069,spectral method,スペクトル法,1.0,10,"[{'word': 'スペクトル法', 'ratio': 1.0}]",スペクトル法
3501,4070,spectral norm,スペクトル行列ノルム,0.0,10,"[{'word': 'スペクトルノルム', 'ratio': 1.0}]",スペクトルノルム
3502,4071,spectral property,スペクトル特性,0.9,10,"[{'word': 'スペクトル特性', 'ratio': 0.9}, {'word': 'スペクトル性質', 'ratio': 0.1}]",スペクトル特性
3503,4072,spectrogram,スペクトログラム,1.0,10,"[{'word': 'スペクトログラム', 'ratio': 1.0}]",スペクトログラム
3504,4073,speech recognition,音声認識,1.0,10,"[{'word': '音声認識', 'ratio': 1.0}]",音声認識
3505,4074,speech recognizer,音声認識器,0.7,10,"[{'word': '音声認識器', 'ratio': 0.7}, {'word': '音声認識装置', 'ratio': 0.2}, {'word': '音声認識装', 'ratio': 0.1}]",音声認識器
3506,4075,speech synthesis model,音声合成モデル,1.0,10,"[{'word': '音声合成モデル', 'ratio': 1.0}]",音声合成モデル
3507,4076,speech synthesizer,音声合成器,0.8,10,"[{'word': '音声合成器', 'ratio': 0.8}, {'word': '音声合成装置', 'ratio': 0.2}]",音声合成器
3508,4077,spoken dialogue system,音声対話システム,1.0,10,"[{'word': '音声対話システム', 'ratio': 1.0}]",音声対話システム
3509,4078,spurious correlation,誤った相関,0.0,10,"[{'word': '偽相関', 'ratio': 0.5}, {'word': '疑似相関', 'ratio': 0.2}, {'word': '虚偽の相関', 'ratio': 0.1}, {'word': 'ホワイトボックス', 'ratio': 0.1}, {'word': '擬似相関', 'ratio': 0.1}]",偽相関
3510,4079,squared Euclidean distance,二乗ユークリッド距離,0.8,10,"[{'word': '二乗ユークリッド距離', 'ratio': 0.8}, {'word': 'ユークリッド二乗距離', 'ratio': 0.2}]",二乗ユークリッド距離
3511,4080,squared error loss,二乗誤差損失,1.0,10,"[{'word': '二乗誤差損失', 'ratio': 1.0}]",二乗誤差損失
3512,4081,stable model,安定モデル,0.8,10,"[{'word': '安定モデル', 'ratio': 0.8}, {'word': '安定したモデル', 'ratio': 0.2}]",安定モデル
3513,4083,stance detection,スタンス検出,0.6,10,"[{'word': 'スタンス検出', 'ratio': 0.6}, {'word': '立場検出', 'ratio': 0.4}]",スタンス検出
3514,4084,standard normal distribution,標準正規分布,1.0,10,"[{'word': '標準正規分布', 'ratio': 1.0}]",標準正規分布
3515,4085,start token,開始トークン,0.6,10,"[{'word': '開始トークン', 'ratio': 0.6}, {'word': 'スタートトークン', 'ratio': 0.4}]",開始トークン
3516,4086,state,状態,1.0,10,"[{'word': '状態', 'ratio': 1.0}]",状態
3517,4088,state distribution,状態分布,1.0,9,"[{'word': '状態分布', 'ratio': 1.0}]",状態分布
3518,4089,state estimation,状態推定,1.0,9,"[{'word': '状態推定', 'ratio': 1.0}]",状態推定
3519,4090,state machine,ステートマシン,0.1111111111111111,9,"[{'word': '状態機械', 'ratio': 0.5555555555555556}, {'word': '状態遷移機械', 'ratio': 0.2222222222222222}, {'word': '状態マシン', 'ratio': 0.1111111111111111}, {'word': 'ステートマシン', 'ratio': 0.1111111111111111}]",状態機械
3520,4091,state matrix,状態行列,1.0,9,"[{'word': '状態行列', 'ratio': 1.0}]",状態行列
3521,4092,state of the art algorithm,最先端のアルゴリズム,0.1111111111111111,9,"[{'word': '最先端アルゴリズム', 'ratio': 0.8888888888888888}, {'word': '最先端のアルゴリズム', 'ratio': 0.1111111111111111}]",最先端アルゴリズム
3522,4093,state representation,状態表現,0.9,10,"[{'word': '状態表現', 'ratio': 0.9}, {'word': '国家代表', 'ratio': 0.1}]",状態表現
3523,4094,state sequence,状態シーケンス,0.3,10,"[{'word': '状態列', 'ratio': 0.5}, {'word': '状態シーケンス', 'ratio': 0.3}, {'word': '状態系列', 'ratio': 0.2}]",状態列
3524,4095,state space,状態空間,1.0,10,"[{'word': '状態空間', 'ratio': 1.0}]",状態空間
3525,4096,state trajectory,状態軌跡,0.5,10,"[{'word': '状態軌跡', 'ratio': 0.5}, {'word': '状態軌道', 'ratio': 0.3}, {'word': '状態の軌跡', 'ratio': 0.1}, {'word': '状態トラジェクトリー', 'ratio': 0.1}]",状態軌跡
3526,4097,state transition,状態遷移,0.9,10,"[{'word': '状態遷移', 'ratio': 0.9}, {'word': '状態移行', 'ratio': 0.1}]",状態遷移
3527,4098,state transition function,状態遷移関数,0.9,10,"[{'word': '状態遷移関数', 'ratio': 0.9}, {'word': '状態移行関数', 'ratio': 0.1}]",状態遷移関数
3528,4099,state transition matrix,状態遷移行列,0.9,10,"[{'word': '状態遷移行列', 'ratio': 0.9}, {'word': '状態移行行列', 'ratio': 0.1}]",状態遷移行列
3529,4100,state transition model,状態遷移モデル,0.9,10,"[{'word': '状態遷移モデル', 'ratio': 0.9}, {'word': '状態移行モデル', 'ratio': 0.1}]",状態遷移モデル
3530,4101,state transition probability,状態遷移確率,0.8,10,"[{'word': '状態遷移確率', 'ratio': 0.8}, {'word': '状態遷移確率状態価値関数', 'ratio': 0.1}, {'word': '状態移行確率', 'ratio': 0.1}]",状態遷移確率
3531,4102,state value function,状態価値関数,0.7,10,"[{'word': '状態価値関数', 'ratio': 0.7}, {'word': '状態値関数', 'ratio': 0.2}, {'word': '状態価関数', 'ratio': 0.1}]",状態価値関数
3532,4103,state variable,状態変数,0.9,10,"[{'word': '状態変数', 'ratio': 0.9}, {'word': 'Jōtai Hyōji', 'ratio': 0.1}]",状態変数
3533,4104,state vector,状態ベクトル,0.9,10,"[{'word': '状態ベクトル', 'ratio': 0.9}, {'word': 'Jōtai Bektō', 'ratio': 0.1}]",状態ベクトル
3534,4105,state-action distribution,状態-行動分布,0.7,10,"[{'word': '状態-行動分布', 'ratio': 0.7}, {'word': 'ステートアクションの分布', 'ratio': 0.2}, {'word': 'Jōtai Kōdō Bunkatsu', 'ratio': 0.1}]",状態-行動分布
3535,4106,state-action space,状態行動空間,0.2,10,"[{'word': '状態-行動空間', 'ratio': 0.7}, {'word': '状態行動空間', 'ratio': 0.2}, {'word': 'Jōtai Kōdō Kūkan', 'ratio': 0.1}]",状態-行動空間
3536,4107,state-action value,状態行動価値,0.0,10,"[{'word': '状態-行動価値', 'ratio': 0.6}, {'word': '状態アクション値', 'ratio': 0.2}, {'word': '状態-行動値', 'ratio': 0.1}, {'word': 'Jōtai Kōdō Kyaku', 'ratio': 0.1}]",状態-行動価値
3537,4108,state-action value function,状態行動価値関数,0.2,10,"[{'word': '状態-行動価値関数', 'ratio': 0.7}, {'word': '状態行動価値関数', 'ratio': 0.2}, {'word': 'ステート・アクション値関数', 'ratio': 0.1}]",状態-行動価値関数
3538,4109,state-of-the-art baseline,最新のベースライン,0.0,10,"[{'word': '最先端のベースライン', 'ratio': 0.7}, {'word': '最先端ベースライン', 'ratio': 0.2}, {'word': '最先端基準ライン', 'ratio': 0.1}]",最先端のベースライン
3539,4110,state-of-the-art method,最先端の手法,0.7,10,"[{'word': '最先端の手法', 'ratio': 0.7}, {'word': '最先端手法', 'ratio': 0.2}, {'word': '最先端の方法', 'ratio': 0.1}]",最先端の手法
3540,4111,state-of-the-art model,最先端モデル,0.2,10,"[{'word': '最先端のモデル', 'ratio': 0.7}, {'word': '最先端モデル', 'ratio': 0.2}, {'word': '最新モデル', 'ratio': 0.1}]",最先端のモデル
3541,4112,state-of-the-art system,最先端システム,0.3,10,"[{'word': '最先端のシステム', 'ratio': 0.7}, {'word': '最先端システム', 'ratio': 0.3}]",最先端のシステム
3542,4113,static analysis,静的解析,0.9,10,"[{'word': '静的解析', 'ratio': 0.9}, {'word': 'スタティック・アナリシス', 'ratio': 0.1}]",静的解析
3543,4114,stationarity,定常性,0.9,10,"[{'word': '定常性', 'ratio': 0.9}, {'word': 'ステーショナリティ', 'ratio': 0.1}]",定常性
3544,4115,stationary distribution,定常分布,0.9,10,"[{'word': '定常分布', 'ratio': 0.9}, {'word': 'ステーショナリー分布', 'ratio': 0.1}]",定常分布
3545,4116,stationary kernel,定常カーネル,0.8,10,"[{'word': '定常カーネル', 'ratio': 0.8}, {'word': '固定カーネル', 'ratio': 0.1}, {'word': 'ステーショナリー・カーネル', 'ratio': 0.1}]",定常カーネル
3546,4118,statistical analysis,統計分析,0.8,10,"[{'word': '統計分析', 'ratio': 0.8}, {'word': '統計解析', 'ratio': 0.2}]",統計分析
3547,4119,statistical independence,統計的独立性,1.0,10,"[{'word': '統計的独立性', 'ratio': 1.0}]",統計的独立性
3548,4120,statistical learning,統計的学習,0.5,10,"[{'word': '統計学習', 'ratio': 0.5}, {'word': '統計的学習', 'ratio': 0.5}]",統計学習
3549,4121,statistical learning algorithm,統計的学習アルゴリズム,0.6,10,"[{'word': '統計的学習アルゴリズム', 'ratio': 0.6}, {'word': '統計学習アルゴリズム', 'ratio': 0.4}]",統計的学習アルゴリズム
3550,4122,statistical learning theory,統計的学習理論,0.9,10,"[{'word': '統計的学習理論', 'ratio': 0.9}, {'word': '統計学的学習理論', 'ratio': 0.1}]",統計的学習理論
3551,4123,statistical machine translation system,統計的機械翻訳システム,0.9,10,"[{'word': '統計的機械翻訳システム', 'ratio': 0.9}, {'word': '統計機械翻訳システム', 'ratio': 0.1}]",統計的機械翻訳システム
3552,4124,statistical measure,統計的尺度,0.7,10,"[{'word': '統計的尺度', 'ratio': 0.7}, {'word': '統計的指標', 'ratio': 0.2}, {'word': '統計的測度', 'ratio': 0.1}]",統計的尺度
3553,4125,statistical model,統計モデル,0.8,10,"[{'word': '統計モデル', 'ratio': 0.8}, {'word': '統計モデル 統計モデル', 'ratio': 0.1}, {'word': '統計的モデル', 'ratio': 0.1}]",統計モデル
3554,4126,statistical translation model,統計的翻訳モデル,0.7,10,"[{'word': '統計的翻訳モデル', 'ratio': 0.7}, {'word': '統計翻訳モデル', 'ratio': 0.3}]",統計的翻訳モデル
3555,4127,steepest descent,勾配降下,0.0,10,"[{'word': '最急降下法', 'ratio': 0.8}, {'word': '最急降下', 'ratio': 0.2}]",最急降下法
3556,4129,stemmer,語幹切り詞,0.0,10,"[{'word': 'ステミング器', 'ratio': 0.5}, {'word': 'ステマー', 'ratio': 0.3}, {'word': 'ステミングツール', 'ratio': 0.1}, {'word': '投票', 'ratio': 0.1}]",ステミング器
3557,4130,stereo algorithm,ステレオアルゴリズム,1.0,10,"[{'word': 'ステレオアルゴリズム', 'ratio': 1.0}]",ステレオアルゴリズム
3558,4131,stereo benchmark,ステレオベンチマーク,0.9,10,"[{'word': 'ステレオベンチマーク', 'ratio': 0.9}, {'word': 'ステレオ・ベンチマーク', 'ratio': 0.1}]",ステレオベンチマーク
3559,4132,stereo disparity,立体視差,0.0,10,"[{'word': 'ステレオ視差', 'ratio': 0.9}, {'word': 'ステレオ格差', 'ratio': 0.1}]",ステレオ視差
3560,4133,stereo image,ステレオ画像,0.9,10,"[{'word': 'ステレオ画像', 'ratio': 0.9}, {'word': 'ステレオイメージ', 'ratio': 0.1}]",ステレオ画像
3561,4134,stereo matching,ステレオマッチング,0.9,10,"[{'word': 'ステレオマッチング', 'ratio': 0.9}, {'word': 'ステレオ・マッチング', 'ratio': 0.1}]",ステレオマッチング
3562,4135,stereo pair,ステレオペア,1.0,10,"[{'word': 'ステレオペア', 'ratio': 1.0}]",ステレオペア
3563,4136,stereo reconstruction,ステレオ再構成,0.6,10,"[{'word': 'ステレオ再構成', 'ratio': 0.6}, {'word': 'ステレオ再構築', 'ratio': 0.4}]",ステレオ再構成
3564,4138,stochastic algorithm,確率的アルゴリズム,1.0,9,"[{'word': '確率的アルゴリズム', 'ratio': 1.0}]",確率的アルゴリズム
3565,4139,stochastic approximation,確率的近似法,0.0,9,"[{'word': '確率的近似', 'ratio': 0.8888888888888888}, {'word': '確率近似', 'ratio': 0.1111111111111111}]",確率的近似
3566,4140,stochastic depth,確率的深さ,0.8888888888888888,9,"[{'word': '確率的深さ', 'ratio': 0.8888888888888888}, {'word': '確率的深度', 'ratio': 0.1111111111111111}]",確率的深さ
3567,4141,stochastic differential equation,確率微分方程式,0.8888888888888888,9,"[{'word': '確率微分方程式', 'ratio': 0.8888888888888888}, {'word': '確率的微分方程式', 'ratio': 0.1111111111111111}]",確率微分方程式
3568,4144,stochastic game,確率ゲーム,0.6666666666666666,9,"[{'word': '確率ゲーム', 'ratio': 0.6666666666666666}, {'word': '確率的ゲーム', 'ratio': 0.2222222222222222}, {'word': ', kashikantoku gēmu', 'ratio': 0.1111111111111111}]",確率ゲーム
3569,4145,stochastic gradient,確率的勾配,0.3333333333333333,9,"[{'word': '確率勾配', 'ratio': 0.5555555555555556}, {'word': '確率的勾配', 'ratio': 0.3333333333333333}, {'word': ', kashikantoku nagasa', 'ratio': 0.1111111111111111}]",確率勾配
3570,4146,stochastic gradient algorithm,ストカスティックグラディエントアルゴリズム,0.0,9,"[{'word': '確率的勾配アルゴリズム', 'ratio': 0.5555555555555556}, {'word': '確率勾配アルゴリズム', 'ratio': 0.3333333333333333}, {'word': ', kashikantoku nagasa sōgō', 'ratio': 0.1111111111111111}]",確率的勾配アルゴリズム
3571,4147,stochastic gradient ascent,確率的勾配上昇法,0.8,10,"[{'word': '確率的勾配上昇法', 'ratio': 0.8}, {'word': '確率的勾配上昇', 'ratio': 0.2}]",確率的勾配上昇法
3572,4148,stochastic gradient method,ストカスティック勾配法,0.0,10,"[{'word': '確率的勾配法', 'ratio': 0.9}, {'word': '確率勾配法', 'ratio': 0.1}]",確率的勾配法
3573,4149,stochastic grammar,確率文法,1.0,10,"[{'word': '確率文法', 'ratio': 1.0}]",確率文法
3574,4150,stochastic matrix,確率行列,1.0,10,"[{'word': '確率行列', 'ratio': 1.0}]",確率行列
3575,4151,stochastic model,確率モデル,1.0,10,"[{'word': '確率モデル', 'ratio': 1.0}]",確率モデル
3576,4152,stochastic objective,確率的目的関数,0.6,10,"[{'word': '確率的目的関数', 'ratio': 0.6}, {'word': '確率的目的', 'ratio': 0.2}, {'word': '確率目的関数', 'ratio': 0.2}]",確率的目的関数
3577,4153,stochastic optimization,確率的最適化,0.8,10,"[{'word': '確率的最適化', 'ratio': 0.8}, {'word': '確率最適化', 'ratio': 0.2}]",確率的最適化
3578,4154,stochastic policy,確率的方策,0.0,10,"[{'word': '確率的ポリシー', 'ratio': 0.5}, {'word': '確率政策', 'ratio': 0.2}, {'word': '確率方策', 'ratio': 0.2}, {'word': '確率的方針', 'ratio': 0.1}]",確率的ポリシー
3579,4155,stochastic process,確率過程,1.0,10,"[{'word': '確率過程', 'ratio': 1.0}]",確率過程
3580,4156,stochastic sampling,確率的サンプリング,1.0,10,"[{'word': '確率的サンプリング', 'ratio': 1.0}]",確率的サンプリング
3581,4157,stochastic search algorithm,確率的探索アルゴリズム,0.8,10,"[{'word': '確率的探索アルゴリズム', 'ratio': 0.8}, {'word': '確率的検索アルゴリズム', 'ratio': 0.1}, {'word': 'ストコスティック検索アルゴリズム', 'ratio': 0.1}]",確率的探索アルゴリズム
3582,4158,stochastic subgradient descent,確率的部分勾配降下法,0.0,10,"[{'word': '確率的サブグラディエント降下法', 'ratio': 0.7}, {'word': '確率的勾配下降法', 'ratio': 0.1}, {'word': '確率的勾配降下法', 'ratio': 0.1}, {'word': 'ストコスティックサブグラデント降下法', 'ratio': 0.1}]",確率的サブグラディエント降下法
3583,4159,stochastic transition matrix,確率遷移行列,0.3,10,"[{'word': '確率的遷移行列', 'ratio': 0.6}, {'word': '確率遷移行列', 'ratio': 0.3}, {'word': 'ストコスティック移行行列', 'ratio': 0.1}]",確率的遷移行列
3584,4160,stochastic variational inference,確率的変分推論,0.9,10,"[{'word': '確率的変分推論', 'ratio': 0.9}, {'word': 'ストコスティック変分推定', 'ratio': 0.1}]",確率的変分推論
3585,4161,stochasticity,確率性,0.8,10,"[{'word': '確率性', 'ratio': 0.8}, {'word': 'かくりつせい', 'ratio': 0.1}, {'word': 'ストコスティシティ', 'ratio': 0.1}]",確率性
3586,4162,stop word,停止語,0.0,9,"[{'word': 'ストップワード', 'ratio': 0.7777777777777778}, {'word': 'とまれことば', 'ratio': 0.2222222222222222}]",ストップワード
3587,4165,stopping condition,停止条件,1.0,9,"[{'word': '停止条件', 'ratio': 1.0}]",停止条件
3588,4166,stopping criterion,停止基準,1.0,9,"[{'word': '停止基準', 'ratio': 1.0}]",停止基準
3589,4167,stratified sampling,層化サンプリング,0.6,10,"[{'word': '層化サンプリング', 'ratio': 0.6}, {'word': '層化抽出', 'ratio': 0.2}, {'word': '層化抽样', 'ratio': 0.1}, {'word': '層別抽出', 'ratio': 0.1}]",層化サンプリング
3590,4168,streaming algorithm,ストリーミングアルゴリズム,1.0,10,"[{'word': 'ストリーミングアルゴリズム', 'ratio': 1.0}]",ストリーミングアルゴリズム
3591,4169,streaming datum,ストリーミングデータ,1.0,10,"[{'word': 'ストリーミングデータ', 'ratio': 1.0}]",ストリーミングデータ
3592,4170,streaming model,ストリーミングモデル,0.9,10,"[{'word': 'ストリーミングモデル', 'ratio': 0.9}, {'word': 'ストリーミングモデルストライド', 'ratio': 0.1}]",ストリーミングモデル
3593,4171,stride,ストライド,1.0,10,"[{'word': 'ストライド', 'ratio': 1.0}]",ストライド
3594,4173,structural learning,構造学習,0.9,10,"[{'word': '構造学習', 'ratio': 0.9}, {'word': '構造的学習', 'ratio': 0.1}]",構造学習
3595,4174,structural risk minimization,構造リスク最小化,0.6,10,"[{'word': '構造リスク最小化', 'ratio': 0.6}, {'word': '構造的リスクの最小化', 'ratio': 0.2}, {'word': '構造的リスク最小化', 'ratio': 0.2}]",構造リスク最小化
3596,4175,structure learning,構造学習,1.0,10,"[{'word': '構造学習', 'ratio': 1.0}]",構造学習
3597,4176,structured datum,構造化されたデータ,0.0,10,"[{'word': '構造化データ', 'ratio': 0.9}, {'word': '構造化されたデータム', 'ratio': 0.1}]",構造化データ
3598,4177,structured output,構造化された出力,0.1,10,"[{'word': '構造化出力', 'ratio': 0.9}, {'word': '構造化された出力', 'ratio': 0.1}]",構造化出力
3599,4178,structured perceptron,構造化パーセプトロン,0.9,10,"[{'word': '構造化パーセプトロン', 'ratio': 0.9}, {'word': '構造化されたパーセプトロン', 'ratio': 0.1}]",構造化パーセプトロン
3600,4179,structured prediction,構造予測,0.0,10,"[{'word': '構造化予測', 'ratio': 0.9}, {'word': '構造化された予測', 'ratio': 0.1}]",構造化予測
3601,4180,structured prediction model,構造化予測モデル,0.5555555555555556,9,"[{'word': '構造化予測モデル', 'ratio': 0.5555555555555556}, {'word': '構造的予測モデル', 'ratio': 0.3333333333333333}, {'word': 'Kaku-sei Yoku-sei Model', 'ratio': 0.1111111111111111}]",構造化予測モデル
3602,4182,structured support vector machine,構造化サポートベクターマシン,0.5555555555555556,9,"[{'word': '構造化サポートベクターマシン', 'ratio': 0.5555555555555556}, {'word': '構造的サポートベクターマシン', 'ratio': 0.3333333333333333}, {'word': 'Kaku-sei Shien Sōshin Mēkusu', 'ratio': 0.1111111111111111}]",構造化サポートベクターマシン
3603,4184,style transfer,スタイル転写,0.0,9,"[{'word': 'スタイル転送', 'ratio': 0.7777777777777778}, {'word': 'スタイル・トランスファー', 'ratio': 0.1111111111111111}, {'word': 'Sutorai Toransufā', 'ratio': 0.1111111111111111}]",スタイル転送
3604,4185,sub-gradient,サブグラディエント,0.6,10,"[{'word': 'サブグラディエント', 'ratio': 0.6}, {'word': 'サブ勾配', 'ratio': 0.3}, {'word': 'サブグラデイント', 'ratio': 0.1}]",サブグラディエント
3605,4186,sub-gradient descent,部分勾配降下法,0.0,10,"[{'word': 'サブグラディエント降下法', 'ratio': 0.5}, {'word': 'サブ勾配降下法', 'ratio': 0.2}, {'word': '亜勾配降下', 'ratio': 0.1}, {'word': '準勾配降下法', 'ratio': 0.1}, {'word': 'サブグラデイント降下', 'ratio': 0.1}]",サブグラディエント降下法
3606,4187,sub-networks,サブネットワーク,1.0,10,"[{'word': 'サブネットワーク', 'ratio': 1.0}]",サブネットワーク
3607,4188,sub-population,サブ集団,0.1,10,"[{'word': 'サブポピュレーション', 'ratio': 0.7}, {'word': '亜集団', 'ratio': 0.1}, {'word': '部分母集団', 'ratio': 0.1}, {'word': 'サブ集団', 'ratio': 0.1}]",サブポピュレーション
3608,4189,sub-word,部分語,0.0,10,"[{'word': 'サブワード', 'ratio': 1.0}]",サブワード
3609,4190,sub-word tokenization,部分語トークン化,0.0,10,"[{'word': 'サブワードトークナイゼーション', 'ratio': 0.6}, {'word': 'サブワードトークン化', 'ratio': 0.2}, {'word': 'サブワード・トークナイゼーション', 'ratio': 0.1}, {'word': 'サブワードのトークン化', 'ratio': 0.1}]",サブワードトークナイゼーション
3610,4191,subgame,部分ゲーム,0.0,10,"[{'word': 'サブゲーム', 'ratio': 1.0}]",サブゲーム
3611,4192,subgradient method,勾配法,0.1,10,"[{'word': 'サブグラディエント法', 'ratio': 0.6}, {'word': 'サブグラデント法', 'ratio': 0.3}, {'word': '勾配法', 'ratio': 0.1}]",サブグラディエント法
3612,4194,subgraph selection,サブグラフ選択,0.7,10,"[{'word': 'サブグラフ選択', 'ratio': 0.7}, {'word': '部分グラフ選択', 'ratio': 0.2}, {'word': '部分グラフの選択', 'ratio': 0.1}]",サブグラフ選択
3613,4196,submatrix,部分行列,0.4444444444444444,9,"[{'word': 'サブマトリックス', 'ratio': 0.5555555555555556}, {'word': '部分行列', 'ratio': 0.4444444444444444}]",サブマトリックス
3614,4197,submodular,サブモジュラー,0.5555555555555556,9,"[{'word': 'サブモジュラー', 'ratio': 0.5555555555555556}, {'word': 'サブモジュラ', 'ratio': 0.2222222222222222}, {'word': 'サブモジュール式', 'ratio': 0.2222222222222222}]",サブモジュラー
3615,4198,submodular function,サブモジュラー関数,0.5555555555555556,9,"[{'word': 'サブモジュラー関数', 'ratio': 0.5555555555555556}, {'word': 'サブモジュラ関数', 'ratio': 0.2222222222222222}, {'word': 'サブモジュール関数', 'ratio': 0.2222222222222222}]",サブモジュラー関数
3616,4199,submodular function optimization,部分モジュラー関数の最適化,0.2222222222222222,9,"[{'word': 'サブモジュラー関数最適化', 'ratio': 0.5555555555555556}, {'word': 'サブモジュラ関数最適化', 'ratio': 0.2222222222222222}, {'word': '部分モジュラー関数の最適化', 'ratio': 0.2222222222222222}]",サブモジュラー関数最適化
3617,4204,subnetwork,サブネットワーク,1.0,9,"[{'word': 'サブネットワーク', 'ratio': 1.0}]",サブネットワーク
3618,4205,suboptimal,非最適な,0.0,10,"[{'word': '最適でない', 'ratio': 0.5}, {'word': 'サブオプティマル', 'ratio': 0.2}, {'word': '最適ではない', 'ratio': 0.2}, {'word': '非最適', 'ratio': 0.1}]",最適でない
3619,4206,subpixel,サブピクセル,1.0,10,"[{'word': 'サブピクセル', 'ratio': 1.0}]",サブピクセル
3620,4207,subsample,サブサンプル,1.0,10,"[{'word': 'サブサンプル', 'ratio': 1.0}]",サブサンプル
3621,4208,subsampling factor,サブサンプリング係数,0.6,10,"[{'word': 'サブサンプリング係数', 'ratio': 0.6}, {'word': 'サブサンプリングファクター', 'ratio': 0.4}]",サブサンプリング係数
3622,4209,subspace learning,サブスペース学習 (subspace learning),0.0,10,"[{'word': 'サブスペース学習', 'ratio': 0.8}, {'word': '亜空間学習', 'ratio': 0.2}]",サブスペース学習
3623,4210,subspace method,サブスペース法,0.5,10,"[{'word': 'サブスペース法', 'ratio': 0.5}, {'word': '部分空間法', 'ratio': 0.4}, {'word': '部分空間', 'ratio': 0.1}]",サブスペース法
3624,4212,substitution,置換,0.8,10,"[{'word': '置換', 'ratio': 0.8}, {'word': '代入', 'ratio': 0.2}]",置換
3625,4214,subsumption relation,包含関係,0.4,10,"[{'word': '包摂関係', 'ratio': 0.5}, {'word': '包含関係', 'ratio': 0.4}, {'word': '含ubesubsumption関係', 'ratio': 0.1}]",包摂関係
3626,4215,subtree,部分木,0.6666666666666666,9,"[{'word': '部分木', 'ratio': 0.6666666666666666}, {'word': 'サブツリー', 'ratio': 0.3333333333333333}]",部分木
3627,4216,subwindow,サブウィンドウ,0.8888888888888888,9,"[{'word': 'サブウィンドウ', 'ratio': 0.8888888888888888}, {'word': 'ブウィンドウ', 'ratio': 0.1111111111111111}]",サブウィンドウ
3628,4217,subword token,部分単語トークン,0.0,9,"[{'word': 'サブワードトークン', 'ratio': 0.7777777777777778}, {'word': 'サブワード字句', 'ratio': 0.2222222222222222}]",サブワードトークン
3629,4219,successor function,後続関数,0.3333333333333333,9,"[{'word': '後継関数', 'ratio': 0.6666666666666666}, {'word': '後続関数', 'ratio': 0.3333333333333333}]",後継関数
3630,4222,sufficient statistic,十分統計量,0.6666666666666666,9,"[{'word': '十分統計量', 'ratio': 0.6666666666666666}, {'word': '十分性統計', 'ratio': 0.1111111111111111}, {'word': '完全統計量', 'ratio': 0.1111111111111111}, {'word': '有効統計量', 'ratio': 0.1111111111111111}]",十分統計量
3631,4224,summarization,要約,1.0,20,"[{'word': '要約', 'ratio': 1.0}]",要約
3632,4225,summarization algorithm,要約アルゴリズム,1.0,10,"[{'word': '要約アルゴリズム', 'ratio': 1.0}]",要約アルゴリズム
3633,4226,summarization model,要約モデル,1.0,10,"[{'word': '要約モデル', 'ratio': 1.0}]",要約モデル
3634,4227,summarization system,要約システム,1.0,10,"[{'word': '要約システム', 'ratio': 1.0}]",要約システム
3635,4228,super-pixel,スーパーピクセル,0.6,10,"[{'word': 'スーパーピクセル', 'ratio': 0.6}, {'word': 'スーパー画素', 'ratio': 0.4}]",スーパーピクセル
3636,4229,super-resolution,超解像度,0.4,10,"[{'word': '超解像', 'ratio': 0.6}, {'word': '超解像度', 'ratio': 0.4}]",超解像
3637,4230,supergradient,超勾配,0.1,10,"[{'word': 'スーパー勾配', 'ratio': 0.5}, {'word': 'スーパーグラディエント', 'ratio': 0.2}, {'word': 'スーパーワード', 'ratio': 0.1}, {'word': '超勾配', 'ratio': 0.1}, {'word': 'スーパ―勾配', 'ratio': 0.1}]",スーパー勾配
3638,4231,supertag,スーパータグ,1.0,10,"[{'word': 'スーパータグ', 'ratio': 1.0}]",スーパータグ
3639,4232,supervised classification,教師付き分類,0.2222222222222222,9,"[{'word': '教師あり分類', 'ratio': 0.6666666666666666}, {'word': '教師付き分類', 'ratio': 0.2222222222222222}, {'word': 'Shidō Saiseki', 'ratio': 0.1111111111111111}]",教師あり分類
3640,4233,supervised classification model,教師あり分類モデル,0.8888888888888888,9,"[{'word': '教師あり分類モデル', 'ratio': 0.8888888888888888}, {'word': 'Shidō Saiseki Model', 'ratio': 0.1111111111111111}]",教師あり分類モデル
3641,4234,supervised classifier,教師あり分類器,0.7777777777777778,9,"[{'word': '教師あり分類器', 'ratio': 0.7777777777777778}, {'word': '教師あり分類子', 'ratio': 0.1111111111111111}, {'word': 'Shidō Fukumu Kari', 'ratio': 0.1111111111111111}]",教師あり分類器
3642,4236,supervised datum,教師データ,0.0,9,"[{'word': '教師ありデータ', 'ratio': 0.5555555555555556}, {'word': '監視されたデータム', 'ratio': 0.1111111111111111}, {'word': '監修データ', 'ratio': 0.1111111111111111}, {'word': '教師付きデータム', 'ratio': 0.1111111111111111}, {'word': 'Shidō Shireki', 'ratio': 0.1111111111111111}]",教師ありデータ
3643,4237,supervised finetuning,監督ファインチューニング,0.0,9,"[{'word': '教師ありファインチューニング', 'ratio': 0.6666666666666666}, {'word': '監視付き微調整', 'ratio': 0.2222222222222222}, {'word': '教師付きファインチューニング', 'ratio': 0.1111111111111111}]",教師ありファインチューニング
3644,4238,supervised learning,教師あり学習,0.8888888888888888,9,"[{'word': '教師あり学習', 'ratio': 0.8888888888888888}, {'word': '教師付き学習', 'ratio': 0.1111111111111111}]",教師あり学習
3645,4239,supervised manner,"- Term: ""監督された方法 (Kansoku sareta houhou)""",0.0,9,"[{'word': '教師ありの方法', 'ratio': 0.5555555555555556}, {'word': '教師ありの方法で', 'ratio': 0.2222222222222222}, {'word': '監視付き', 'ratio': 0.1111111111111111}, {'word': '監視された方法', 'ratio': 0.1111111111111111}]",教師ありの方法
3646,4240,supervised method,教師あり手法,0.7777777777777778,9,"[{'word': '教師あり手法', 'ratio': 0.7777777777777778}, {'word': '教師あり方式', 'ratio': 0.1111111111111111}, {'word': '教師付きメソッド', 'ratio': 0.1111111111111111}]",教師あり手法
3647,4241,supervised model,教師付きモデル,0.0,9,"[{'word': '教師ありモデル', 'ratio': 1.0}]",教師ありモデル
3648,4242,supervised multi-task learning,監督付きマルチタスク学習,0.0,10,"[{'word': '教師ありマルチタスク学習', 'ratio': 0.7}, {'word': 'サupervised マルチタスク学習', 'ratio': 0.1}, {'word': '教師あり多タスク学習', 'ratio': 0.1}, {'word': '教 supervised マルチタスク学習', 'ratio': 0.1}]",教師ありマルチタスク学習
3649,4243,supervised setting,監視設定,0.1,10,"[{'word': '教師あり設定', 'ratio': 0.6}, {'word': '監視付きセッティング', 'ratio': 0.1}, {'word': '監視設定', 'ratio': 0.1}, {'word': 'サupervised 環境', 'ratio': 0.1}, {'word': '教 supervised 設定', 'ratio': 0.1}]",教師あり設定
3650,4244,supervised system,監督システム (Kanshoku shisutemu),0.0,10,"[{'word': '教師ありシステム', 'ratio': 0.6}, {'word': '管理システム', 'ratio': 0.1}, {'word': '監視対象システム', 'ratio': 0.1}, {'word': 'サupervised システム', 'ratio': 0.1}, {'word': '教 supervised システム', 'ratio': 0.1}]",教師ありシステム
3651,4246,support,サポート,1.0,10,"[{'word': 'サポート', 'ratio': 1.0}]",サポート
3652,4247,support set,サポートセット,1.0,10,"[{'word': 'サポートセット', 'ratio': 1.0}]",サポートセット
3653,4248,support threshold,サポート閾値,0.8,10,"[{'word': 'サポート閾値', 'ratio': 0.8}, {'word': 'サポートしきい値', 'ratio': 0.2}]",サポート閾値
3654,4249,support vector,サポートベクトル,0.6,10,"[{'word': 'サポートベクトル', 'ratio': 0.6}, {'word': 'サポートベクター', 'ratio': 0.4}]",サポートベクトル
3655,4250,surface normal,表面法線,0.7,10,"[{'word': '表面法線', 'ratio': 0.7}, {'word': 'サーフェスノーマル', 'ratio': 0.2}, {'word': 'サーフェス法線', 'ratio': 0.1}]",表面法線
3656,4251,surface normal estimator,表面法線推定器,0.7,10,"[{'word': '表面法線推定器', 'ratio': 0.7}, {'word': 'サーフェスノーマル推定器', 'ratio': 0.2}, {'word': 'サーフェス法線推定器', 'ratio': 0.1}]",表面法線推定器
3657,4252,surface normal prediction,表面法線予測,0.6,10,"[{'word': '表面法線予測', 'ratio': 0.6}, {'word': 'サーフェス法線予測', 'ratio': 0.2}, {'word': 'サーフェスノーマル予測', 'ratio': 0.2}]",表面法線予測
3658,4253,surface realization,表層実現,0.0,10,"[{'word': '表面実現', 'ratio': 0.7}, {'word': 'サーフェス実現', 'ratio': 0.2}, {'word': 'サーフェスリアリゼーション', 'ratio': 0.1}]",表面実現
3659,4255,surrogate function,代用関数,0.2,10,"[{'word': '代理関数', 'ratio': 0.5}, {'word': '代用関数', 'ratio': 0.2}, {'word': 'サロゲート関数', 'ratio': 0.2}, {'word': 'サージェート関数', 'ratio': 0.1}]",代理関数
3660,4256,surrogate loss,代理損失,0.5,10,"[{'word': '代理損失', 'ratio': 0.5}, {'word': '代理喪失', 'ratio': 0.2}, {'word': 'サロゲート損失', 'ratio': 0.2}, {'word': 'サージェートロス', 'ratio': 0.1}]",代理損失
3661,4257,surrogate loss function,代替損失関数,0.1,10,"[{'word': '代理損失関数', 'ratio': 0.9}, {'word': '代替損失関数', 'ratio': 0.1}]",代理損失関数
3662,4258,surrogate model,代理モデル,0.7,10,"[{'word': '代理モデル', 'ratio': 0.7}, {'word': 'サロゲートモデル', 'ratio': 0.2}, {'word': '代替モデル', 'ratio': 0.1}]",代理モデル
3663,4259,symbol grounding problem,記号接地問題,0.0,10,"[{'word': 'シンボルグラウンディング問題', 'ratio': 0.6}, {'word': 'シンボル基盤問題', 'ratio': 0.2}, {'word': 'シンボルの接地問題', 'ratio': 0.1}, {'word': 'シンボル接地の問題', 'ratio': 0.1}]",シンボルグラウンディング問題
3664,4260,symbolic representation,記号的表現,0.1,10,"[{'word': 'シンボリック表現', 'ratio': 0.6}, {'word': '記号的表現', 'ratio': 0.1}, {'word': '象徴的表現', 'ratio': 0.1}, {'word': '記号表現', 'ratio': 0.1}, {'word': '象徴的な表現', 'ratio': 0.1}]",シンボリック表現
3665,4261,symmetric matrix,対称行列,1.0,10,"[{'word': '対称行列', 'ratio': 1.0}]",対称行列
3666,4263,symmetrization,対称化,1.0,9,"[{'word': '対称化', 'ratio': 1.0}]",対称化
3667,4264,synchronous context-free grammar,同期コンテキストフリー文法,0.0,9,"[{'word': '同期文脈自由文法', 'ratio': 0.5555555555555556}, {'word': '同期自由文法', 'ratio': 0.2222222222222222}, {'word': '同期非文脈自由文法', 'ratio': 0.1111111111111111}, {'word': '同期型文脈自由文法', 'ratio': 0.1111111111111111}]",同期文脈自由文法
3668,4265,synonymy,同義語,0.1111111111111111,9,"[{'word': '同義性', 'ratio': 0.6666666666666666}, {'word': '同義関係', 'ratio': 0.2222222222222222}, {'word': '同義語', 'ratio': 0.1111111111111111}]",同義性
3669,4267,syntactic analysis,構文解析,0.7777777777777778,9,"[{'word': '構文解析', 'ratio': 0.7777777777777778}, {'word': '統語解析', 'ratio': 0.1111111111111111}, {'word': 'Sintakutikku Bunseki', 'ratio': 0.1111111111111111}]",構文解析
3670,4269,syntactic constraint,構文上の制約,0.0,9,"[{'word': '構文制約', 'ratio': 0.5555555555555556}, {'word': '構文的制約', 'ratio': 0.2222222222222222}, {'word': '統語的制約', 'ratio': 0.1111111111111111}, {'word': '(Sintakutikku Jōken', 'ratio': 0.1111111111111111}]",構文制約
3671,4270,syntactic dependency,統語的依存関係,0.125,8,"[{'word': '構文依存', 'ratio': 0.625}, {'word': '統語的依存関係', 'ratio': 0.125}, {'word': '構文的依存関係', 'ratio': 0.125}, {'word': '構文依存関係', 'ratio': 0.125}]",構文依存
3672,4271,syntactic dependency parsing,構文依存解析,0.6666666666666666,9,"[{'word': '構文依存解析', 'ratio': 0.6666666666666666}, {'word': '構文従属解析', 'ratio': 0.2222222222222222}, {'word': '統語的依存構文解析', 'ratio': 0.1111111111111111}]",構文依存解析
3673,4272,syntactic dependency tree,構文依存木 (Kōbun izon ki),0.0,9,"[{'word': '構文依存木', 'ratio': 0.6666666666666666}, {'word': '構文従属木', 'ratio': 0.2222222222222222}, {'word': '統語的依存ツリー', 'ratio': 0.1111111111111111}]",構文依存木
3674,4274,syntactic information,構文情報,0.8888888888888888,9,"[{'word': '構文情報', 'ratio': 0.8888888888888888}, {'word': '統語的情報', 'ratio': 0.1111111111111111}]",構文情報
3675,4275,syntactic parse,構文解析,0.8888888888888888,9,"[{'word': '構文解析', 'ratio': 0.8888888888888888}, {'word': '統語的解析', 'ratio': 0.1111111111111111}]",構文解析
3676,4276,syntactic parser,構文解析器,0.9,10,"[{'word': '構文解析器', 'ratio': 0.9}, {'word': '統語解析器', 'ratio': 0.1}]",構文解析器
3677,4277,syntactic regularity,構文的規則性,0.6,10,"[{'word': '構文的規則性', 'ratio': 0.6}, {'word': '統語的規則性', 'ratio': 0.3}, {'word': '構文規則性', 'ratio': 0.1}]",構文的規則性
3678,4278,syntactic representation,構文表現,0.6,10,"[{'word': '構文表現', 'ratio': 0.6}, {'word': '構文的表現', 'ratio': 0.3}, {'word': '統語的表現', 'ratio': 0.1}]",構文表現
3679,4279,syntactic similarity,統語的類似性,0.3,10,"[{'word': '構文的類似性', 'ratio': 0.7}, {'word': '統語的類似性', 'ratio': 0.3}]",構文的類似性
3680,4280,syntactic structure,統語構造,0.2,10,"[{'word': '構文構造', 'ratio': 0.5}, {'word': '統語構造', 'ratio': 0.2}, {'word': '構文的構造', 'ratio': 0.2}, {'word': '統語的構造', 'ratio': 0.1}]",構文構造
3681,4281,syntactic tree,構文木,0.8,10,"[{'word': '構文木', 'ratio': 0.8}, {'word': '統語木', 'ratio': 0.2}]",構文木
3682,4282,syntax,統語論,0.0,20,"[{'word': '構文', 'ratio': 1.0}]",構文
3683,4283,syntax tree,構文木,1.0,10,"[{'word': '構文木', 'ratio': 1.0}]",構文木
3684,4284,synthetic dataset,合成データセット,1.0,10,"[{'word': '合成データセット', 'ratio': 1.0}]",合成データセット
3685,4285,system identification,システム同定,0.6666666666666666,9,"[{'word': 'システム同定', 'ratio': 0.6666666666666666}, {'word': 'オブジェクト検出器', 'ratio': 0.1111111111111111}, {'word': 'システム識別', 'ratio': 0.1111111111111111}, {'word': 'システムの識別', 'ratio': 0.1111111111111111}]",システム同定
3686,4286,t-test,t検定,0.8888888888888888,9,"[{'word': 't検定', 'ratio': 0.8888888888888888}, {'word': 'オブジェクト埋め込み', 'ratio': 0.1111111111111111}]",t検定
3687,4287,tag recommendation,タグ推薦,0.6666666666666666,9,"[{'word': 'タグ推薦', 'ratio': 0.6666666666666666}, {'word': 'オブジェクトインスタンスセグメンテーション', 'ratio': 0.1111111111111111}, {'word': 'タグの推奨', 'ratio': 0.1111111111111111}, {'word': 'タグ推奨', 'ratio': 0.1111111111111111}]",タグ推薦
3688,4288,tag sequence,タグシーケンス,0.5,10,"[{'word': 'タグシーケンス', 'ratio': 0.5}, {'word': 'タグ列', 'ratio': 0.3}, {'word': 'タグ配列', 'ratio': 0.1}, {'word': 'タグ系列', 'ratio': 0.1}]",タグシーケンス
3689,4289,tagger,タガー,0.5,20,"[{'word': 'タガー', 'ratio': 1.0}]",タガー
3690,4290,tagset,タグセット,1.0,10,"[{'word': 'タグセット', 'ratio': 1.0}]",タグセット
3691,4294,target,ターゲット,0.65,20,"[{'word': 'ターゲット', 'ratio': 0.65}, {'word': '目標', 'ratio': 0.25}, {'word': 'オブジェクトセグメンテーション', 'ratio': 0.05}, {'word': 'オブジェクト追跡', 'ratio': 0.05}]",ターゲット
3692,4295,target classifier,ターゲット分類器,0.8,10,"[{'word': 'ターゲット分類器', 'ratio': 0.8}, {'word': '確率的サンプリング', 'ratio': 0.1}, {'word': 'ターゲット分類子', 'ratio': 0.1}]",ターゲット分類器
3693,4296,target distribution,目標分布,0.0,10,"[{'word': 'ターゲット分布', 'ratio': 0.9}, {'word': '目標配分', 'ratio': 0.1}]",ターゲット分布
3694,4297,target domain,ターゲットドメイン,1.0,10,"[{'word': 'ターゲットドメイン', 'ratio': 1.0}]",ターゲットドメイン
3695,4298,target function,目標関数,0.0,10,"[{'word': 'ターゲット関数', 'ratio': 0.9}, {'word': 'アージェット機能', 'ratio': 0.1}]",ターゲット関数
3696,4299,target instance,ターゲットインスタンス,1.0,10,"[{'word': 'ターゲットインスタンス', 'ratio': 1.0}]",ターゲットインスタンス
3697,4300,target model,ターゲットモデル,0.8,10,"[{'word': 'ターゲットモデル', 'ratio': 0.8}, {'word': '対象機種', 'ratio': 0.2}]",ターゲットモデル
3698,4301,target network,ターゲットネットワーク,1.0,10,"[{'word': 'ターゲットネットワーク', 'ratio': 1.0}]",ターゲットネットワーク
3699,4302,target node,目標ノード,0.0,10,"[{'word': 'ターゲットノード', 'ratio': 1.0}]",ターゲットノード
3700,4303,target policy,目標方針,0.0,10,"[{'word': 'ターゲットポリシー', 'ratio': 0.8}, {'word': '目標政策', 'ratio': 0.2}]",ターゲットポリシー
3701,4304,target sentence,ターゲット文,0.8,10,"[{'word': 'ターゲット文', 'ratio': 0.8}, {'word': 'ターゲットセンテンス', 'ratio': 0.2}]",ターゲット文
3702,4305,target sequence,ターゲットシーケンス,0.6,10,"[{'word': 'ターゲットシーケンス', 'ratio': 0.6}, {'word': '目標シーケンス', 'ratio': 0.3}, {'word': 'ターゲット配列', 'ratio': 0.1}]",ターゲットシーケンス
3703,4306,target task,目標タスク,0.3,10,"[{'word': 'ターゲットタスク', 'ratio': 0.6}, {'word': '目標タスク', 'ratio': 0.3}, {'word': '対象業務', 'ratio': 0.1}]",ターゲットタスク
3704,4307,target token,対象トークン,0.0,10,"[{'word': 'ターゲットトークン', 'ratio': 0.7}, {'word': '目標トークン', 'ratio': 0.3}]",ターゲットトークン
3705,4308,target variable,ターゲット変数,0.7,10,"[{'word': 'ターゲット変数', 'ratio': 0.7}, {'word': '目標変数', 'ratio': 0.3}]",ターゲット変数
3706,4309,target vector,目標ベクトル,0.3,10,"[{'word': 'ターゲットベクトル', 'ratio': 0.7}, {'word': '目標ベクトル', 'ratio': 0.3}]",ターゲットベクトル
3707,4310,target vocabulary,対象語彙,0.3,10,"[{'word': 'ターゲット語彙', 'ratio': 0.7}, {'word': '対象語彙', 'ratio': 0.3}]",ターゲット語彙
3708,4312,target-to-source model,ターゲットからソースへのモデル,0.6,10,"[{'word': 'ターゲットからソースへのモデル', 'ratio': 0.6}, {'word': 'ターゲットからソースモデル', 'ratio': 0.2}, {'word': '対象からソースへのモデル', 'ratio': 0.1}, {'word': 'ソース方言モデルのターゲット', 'ratio': 0.1}]",ターゲットからソースへのモデル
3709,4313,task,タスク,1.0,20,"[{'word': 'タスク', 'ratio': 1.0}]",タスク
3710,4314,task adaptation,タスク適応,0.8,10,"[{'word': 'タスク適応', 'ratio': 0.8}, {'word': '課題適応', 'ratio': 0.1}, {'word': 'タスクの適応', 'ratio': 0.1}]",タスク適応
3711,4315,task model,タスクモデル,1.0,10,"[{'word': 'タスクモデル', 'ratio': 1.0}]",タスクモデル
3712,4316,task-oriented dialog system,タスク指向型対話システム,0.1,10,"[{'word': 'タスク指向対話システム', 'ratio': 0.7}, {'word': 'タスク指向型ダイアログシステム', 'ratio': 0.1}, {'word': 'タスク指向型対話システム', 'ratio': 0.1}, {'word': 'タスク指向の対話システム', 'ratio': 0.1}]",タスク指向対話システム
3713,4317,task-oriented dialogue system,タスク指向対話システム,0.3,10,"[{'word': 'タスク指向ダイアログシステム', 'ratio': 0.5}, {'word': 'タスク指向対話システム', 'ratio': 0.3}, {'word': 'タスク指向型対話システム', 'ratio': 0.1}, {'word': 'タスク指向の対話システム', 'ratio': 0.1}]",タスク指向ダイアログシステム
3714,4318,task-specific model,タスク固有モデル,0.1,10,"[{'word': 'タスク特化モデル', 'ratio': 0.5}, {'word': 'タスク特化型モデル', 'ratio': 0.3}, {'word': 'タスク固有モデル', 'ratio': 0.1}, {'word': 'タスク固有のモデル', 'ratio': 0.1}]",タスク特化モデル
3715,4320,teacher forcing,教師強制,0.5555555555555556,9,"[{'word': '教師強制', 'ratio': 0.5555555555555556}, {'word': 'ティーチャーフォース', 'ratio': 0.2222222222222222}, {'word': '強引な先生', 'ratio': 0.1111111111111111}, {'word': '先生が強制する', 'ratio': 0.1111111111111111}]",教師強制
3716,4321,teacher network,教師ネットワーク,0.7777777777777778,9,"[{'word': '教師ネットワーク', 'ratio': 0.7777777777777778}, {'word': 'ティーチャーネットワーク', 'ratio': 0.1111111111111111}, {'word': '教員ネットワーク', 'ratio': 0.1111111111111111}]",教師ネットワーク
3717,4322,temperature parameter,温度パラメータ,0.8888888888888888,9,"[{'word': '温度パラメータ', 'ratio': 0.8888888888888888}, {'word': '温度パラメーター', 'ratio': 0.1111111111111111}]",温度パラメータ
3718,4323,temperature scaling,温度スケーリング,1.0,10,"[{'word': '温度スケーリング', 'ratio': 1.0}]",温度スケーリング
3719,4324,template,テンプレート,1.0,10,"[{'word': 'テンプレート', 'ratio': 1.0}]",テンプレート
3720,4325,template model,テンプレートモデル,1.0,10,"[{'word': 'テンプレートモデル', 'ratio': 1.0}]",テンプレートモデル
3721,4326,template-matching,テンプレートマッチング,1.0,10,"[{'word': 'テンプレートマッチング', 'ratio': 1.0}]",テンプレートマッチング
3722,4327,temporal derivative,時間微分,0.7,10,"[{'word': '時間微分', 'ratio': 0.7}, {'word': '時間導関数', 'ratio': 0.2}, {'word': '時間的導関数', 'ratio': 0.1}]",時間微分
3723,4328,temporal difference,時間差,1.0,9,"[{'word': '時間差', 'ratio': 1.0}]",時間差
3724,4329,temporal difference learning,時間差学習,1.0,9,"[{'word': '時間差学習', 'ratio': 1.0}]",時間差学習
3725,4330,temporal drift,時間的ドリフト,0.5555555555555556,9,"[{'word': '時間的ドリフト', 'ratio': 0.5555555555555556}, {'word': '時間的漂流', 'ratio': 0.1111111111111111}, {'word': '時間的漂移', 'ratio': 0.1111111111111111}, {'word': '時間的変動', 'ratio': 0.1111111111111111}, {'word': '時間のずれ', 'ratio': 0.1111111111111111}]",時間的ドリフト
3726,4331,temporal fusion,時間的融合,0.8888888888888888,9,"[{'word': '時間的融合', 'ratio': 0.8888888888888888}, {'word': '時間融合', 'ratio': 0.1111111111111111}]",時間的融合
3727,4332,temporal locality,時間的局所性,0.8888888888888888,9,"[{'word': '時間的局所性', 'ratio': 0.8888888888888888}, {'word': '時間的地域性', 'ratio': 0.1111111111111111}]",時間的局所性
3728,4333,temporal logic,時相論理,0.1,10,"[{'word': '時間論理', 'ratio': 0.6}, {'word': '時相論理', 'ratio': 0.1}, {'word': '時間論理学', 'ratio': 0.1}, {'word': '時制論理', 'ratio': 0.1}, {'word': '時系列論理', 'ratio': 0.1}]",時間論理
3729,4334,temporal reasoning,時間的推論,0.3,10,"[{'word': '時間推論', 'ratio': 0.5}, {'word': '時間的推論', 'ratio': 0.3}, {'word': '時制推論', 'ratio': 0.1}, {'word': '時系列推論', 'ratio': 0.1}]",時間推論
3730,4335,temporal variable,時間変数,0.8,10,"[{'word': '時間変数', 'ratio': 0.8}, {'word': '時制変数', 'ratio': 0.1}, {'word': '時系列変数', 'ratio': 0.1}]",時間変数
3731,4336,tensor decomposition,テンソル分解,1.0,10,"[{'word': 'テンソル分解', 'ratio': 1.0}]",テンソル分解
3732,4337,tensor factorization,テンソル因子分解,0.8,10,"[{'word': 'テンソル因子分解', 'ratio': 0.8}, {'word': 'テンソル因数分解', 'ratio': 0.2}]",テンソル因子分解
3733,4338,tensor field,テンソル場,1.0,10,"[{'word': 'テンソル場', 'ratio': 1.0}]",テンソル場
3734,4339,tensor product,テンソル積,1.0,10,"[{'word': 'テンソル積', 'ratio': 1.0}]",テンソル積
3735,4340,term frequency,用語の頻度 (term frequency),0.0,10,"[{'word': '用語頻度', 'ratio': 0.6}, {'word': '頻度', 'ratio': 0.2}, {'word': '期間の頻度', 'ratio': 0.1}, {'word': '頻出語', 'ratio': 0.1}]",用語頻度
3736,4341,terminal node,終端ノード (shūtan nōdo),0.0,10,"[{'word': '終端ノード', 'ratio': 0.9}, {'word': 'ターミナルノード', 'ratio': 0.1}]",終端ノード
3737,4342,terminal state,終了状態 (shūryō jōtai),0.0,10,"[{'word': '終端状態', 'ratio': 0.9}, {'word': '端末状態', 'ratio': 0.1}]",終端状態
3738,4343,termination condition,終了条件,1.0,9,"[{'word': '終了条件', 'ratio': 1.0}]",終了条件
3739,4344,termination criterion,終了基準,1.0,9,"[{'word': '終了基準', 'ratio': 1.0}]",終了基準
3740,4345,test accuracy,テスト精度,0.7777777777777778,9,"[{'word': 'テスト精度', 'ratio': 0.7777777777777778}, {'word': '検査精度', 'ratio': 0.1111111111111111}, {'word': 'テストの精度', 'ratio': 0.1111111111111111}]",テスト精度
3741,4346,test dataset,テストデータセット,1.0,9,"[{'word': 'テストデータセット', 'ratio': 1.0}]",テストデータセット
3742,4347,test datum,テストデータ,0.8,10,"[{'word': 'テストデータ', 'ratio': 0.8}, {'word': '試験データ', 'ratio': 0.1}, {'word': '試験日', 'ratio': 0.1}]",テストデータ
3743,4348,test domain,テストドメイン,1.0,10,"[{'word': 'テストドメイン', 'ratio': 1.0}]",テストドメイン
3744,4349,test error,テストエラー,0.4,10,"[{'word': 'テスト誤差', 'ratio': 0.5}, {'word': 'テストエラー', 'ratio': 0.4}, {'word': 'テスト誤り', 'ratio': 0.1}]",テスト誤差
3745,4350,test loss,テスト損失,0.5,10,"[{'word': 'テスト損失', 'ratio': 0.5}, {'word': 'テストロス', 'ratio': 0.4}, {'word': '試験損失', 'ratio': 0.1}]",テスト損失
3746,4351,test set,テストセット,1.0,10,"[{'word': 'テストセット', 'ratio': 1.0}]",テストセット
3747,4352,test split,テスト分割,0.7,10,"[{'word': 'テスト分割', 'ratio': 0.7}, {'word': 'テストスプリット', 'ratio': 0.2}, {'word': 'テストデータ分割', 'ratio': 0.1}]",テスト分割
3748,4353,test time,- テスト時,0.0,10,"[{'word': 'テスト時', 'ratio': 0.8}, {'word': '試験時間', 'ratio': 0.2}]",テスト時
3749,4354,testing set,テストセット,1.0,10,"[{'word': 'テストセット', 'ratio': 1.0}]",テストセット
3750,4355,text categorization,テキスト分類,0.9,10,"[{'word': 'テキスト分類', 'ratio': 0.9}, {'word': 'テキストの分類', 'ratio': 0.1}]",テキスト分類
3751,4356,text corpus,テキストコーパス,1.0,10,"[{'word': 'テキストコーパス', 'ratio': 1.0}]",テキストコーパス
3752,4357,text embedding,テキスト埋め込み,0.8,10,"[{'word': 'テキスト埋め込み', 'ratio': 0.8}, {'word': 'テキストの埋め込み', 'ratio': 0.1}, {'word': 'テキストエンコーディング', 'ratio': 0.1}]",テキスト埋め込み
3753,4358,text encoder,テキストエンコーダー,0.1,10,"[{'word': 'テキストエンコーダ', 'ratio': 0.9}, {'word': 'テキストエンコーダー', 'ratio': 0.1}]",テキストエンコーダ
3754,4359,text generation,テキスト生成,0.9,10,"[{'word': 'テキスト生成', 'ratio': 0.9}, {'word': 'テキストの生成', 'ratio': 0.1}]",テキスト生成
3755,4360,text generation model,テキスト生成モデル,1.0,10,"[{'word': 'テキスト生成モデル', 'ratio': 1.0}]",テキスト生成モデル
3756,4361,text mining,テキストマイニング,0.9,10,"[{'word': 'テキストマイニング', 'ratio': 0.9}, {'word': 'テキスト・マイニング', 'ratio': 0.1}]",テキストマイニング
3757,4362,text segmentation,テキスト分割,0.0,10,"[{'word': 'テキストセグメンテーション', 'ratio': 0.7}, {'word': 'テキストのセグメンテーション', 'ratio': 0.2}, {'word': 'テキスト・セグメンテーション', 'ratio': 0.1}]",テキストセグメンテーション
3758,4363,text simplification,テキスト単純化,0.0,10,"[{'word': 'テキスト簡略化', 'ratio': 0.5}, {'word': 'テキスト簡素化', 'ratio': 0.2}, {'word': 'テキストの簡略化', 'ratio': 0.2}, {'word': 'テキスト・シンプリフィケーション', 'ratio': 0.1}]",テキスト簡略化
3759,4364,text-davinci-002,テキスト-ダヴィンチ-002,0.7,10,"[{'word': 'テキスト-ダヴィンチ-002', 'ratio': 0.7}, {'word': 'text-davinci-002', 'ratio': 0.2}, {'word': 'テキスト・ダビンチ・002', 'ratio': 0.1}]",テキスト-ダヴィンチ-002
3760,4365,text-davinci-003,テキスト-ダヴィンチ-003,0.7,10,"[{'word': 'テキスト-ダヴィンチ-003', 'ratio': 0.7}, {'word': 'text-davinci-003', 'ratio': 0.2}, {'word': 'テキスト・ダビンチ・003', 'ratio': 0.1}]",テキスト-ダヴィンチ-003
3761,4366,text-to-image diffusion model,テキストから画像への拡散モデル,0.8,10,"[{'word': 'テキストから画像への拡散モデル', 'ratio': 0.8}, {'word': 'テキスト画像拡散モデル', 'ratio': 0.2}]",テキストから画像への拡散モデル
3762,4368,text-to-image model,テキストから画像への変換モデル,0.0,10,"[{'word': 'テキストから画像モデル', 'ratio': 0.5}, {'word': 'テキストから画像のモデル', 'ratio': 0.2}, {'word': 'テキスト画像モデル', 'ratio': 0.2}, {'word': 'テキストから画像へのモデル', 'ratio': 0.1}]",テキストから画像モデル
3763,4370,textual entailment,文章の含意関係,0.0,10,"[{'word': 'テキスト含意', 'ratio': 0.5}, {'word': 'テキスト的含意', 'ratio': 0.2}, {'word': '文言の内包', 'ratio': 0.2}, {'word': 'テキスト包含', 'ratio': 0.1}]",テキスト含意
3764,4371,tf-idf,tf-idf,0.8,10,"[{'word': 'tf-idf', 'ratio': 0.8}, {'word': 'ティーエフアイディーエフ', 'ratio': 0.2}]",tf-idf
3765,4372,threat model,脅威モデル,1.0,10,"[{'word': '脅威モデル', 'ratio': 1.0}]",脅威モデル
3766,4373,threshold,閾値,1.0,10,"[{'word': '閾値', 'ratio': 1.0}]",閾値
3767,4374,threshold function,閾値関数,0.8,10,"[{'word': '閾値関数', 'ratio': 0.8}, {'word': 'しきい値関数', 'ratio': 0.2}]",閾値関数
3768,4375,threshold parameter,閾値パラメータ,0.8,10,"[{'word': '閾値パラメータ', 'ratio': 0.8}, {'word': 'しきい値パラメータ', 'ratio': 0.1}, {'word': '線形分離性', 'ratio': 0.1}]",閾値パラメータ
3769,4376,threshold policy,しきい値方針,0.0,10,"[{'word': '閾値ポリシー', 'ratio': 0.8}, {'word': '閾値政策', 'ratio': 0.1}, {'word': 'しきい値ポリシー', 'ratio': 0.1}]",閾値ポリシー
3770,4377,time complexity,時間計算量,0.6,10,"[{'word': '時間計算量', 'ratio': 0.6}, {'word': '時間の複雑さ', 'ratio': 0.2}, {'word': '計算量', 'ratio': 0.1}, {'word': '時間的複雑度', 'ratio': 0.1}]",時間計算量
3771,4378,time series,時系列,1.0,10,"[{'word': '時系列', 'ratio': 1.0}]",時系列
3772,4379,time series analysis,時系列分析,0.8,10,"[{'word': '時系列分析', 'ratio': 0.8}, {'word': 'time series analysis', 'ratio': 0.1}, {'word': '時系列解析', 'ratio': 0.1}]",時系列分析
3773,4380,time series forecasting,時系列予測,1.0,10,"[{'word': '時系列予測', 'ratio': 1.0}]",時系列予測
3774,4381,time step,時刻ステップ,0.0,10,"[{'word': '時間ステップ', 'ratio': 0.6}, {'word': 'タイムステップ', 'ratio': 0.2}, {'word': '時刻', 'ratio': 0.2}]",時間ステップ
3775,4382,time-series datum,時系列データ,1.0,10,"[{'word': '時系列データ', 'ratio': 1.0}]",時系列データ
3776,4383,time-series model,時系列モデル,1.0,10,"[{'word': '時系列モデル', 'ratio': 1.0}]",時系列モデル
3777,4385,token classification,トークン分類,1.0,10,"[{'word': 'トークン分類', 'ratio': 1.0}]",トークン分類
3778,4386,token embedding,トークン埋め込み,0.9,10,"[{'word': 'トークン埋め込み', 'ratio': 0.9}, {'word': 'トークン Embedding', 'ratio': 0.1}]",トークン埋め込み
3779,4387,token frequency,トークン頻度,1.0,10,"[{'word': 'トークン頻度', 'ratio': 1.0}]",トークン頻度
3780,4388,token length,トークン長,0.8,10,"[{'word': 'トークン長', 'ratio': 0.8}, {'word': 'トークン長さ', 'ratio': 0.1}, {'word': 'トークンの長さ', 'ratio': 0.1}]",トークン長
3781,4389,token representation,トークン表現,1.0,9,"[{'word': 'トークン表現', 'ratio': 1.0}]",トークン表現
3782,4390,token sequence,トークン系列,0.0,9,"[{'word': 'トークン列', 'ratio': 0.7777777777777778}, {'word': 'トークンシーケンス', 'ratio': 0.2222222222222222}]",トークン列
3783,4391,token space,トークン空間,0.0,9,"[{'word': 'トークンスペース', 'ratio': 1.0}]",トークンスペース
3784,4392,token vector,トークンベクトル,0.8888888888888888,9,"[{'word': 'トークンベクトル', 'ratio': 0.8888888888888888}, {'word': 'トークン・ベクトル', 'ratio': 0.1111111111111111}]",トークンベクトル
3785,4393,token vocabulary,トークン語彙,0.8888888888888888,9,"[{'word': 'トークン語彙', 'ratio': 0.8888888888888888}, {'word': 'トークンの語彙', 'ratio': 0.1111111111111111}]",トークン語彙
3786,4394,token-level,トークンレベル,0.8,10,"[{'word': 'トークンレベル', 'ratio': 0.8}, {'word': 'トークン・レベル', 'ratio': 0.1}, {'word': 'トークン レベル', 'ratio': 0.1}]",トークンレベル
3787,4396,token-level feature,トークンレベルの特徴,0.5,10,"[{'word': 'トークンレベルの特徴', 'ratio': 0.5}, {'word': 'トークンレベル特徴', 'ratio': 0.2}, {'word': 'トークンレベル機能', 'ratio': 0.1}, {'word': 'トークンレベルの機能', 'ratio': 0.1}, {'word': 'トークン レベルの注意', 'ratio': 0.1}]",トークンレベルの特徴
3788,4397,tokenisation,トークン化,0.9,10,"[{'word': 'トークン化', 'ratio': 0.9}, {'word': 'トークナイゼーション', 'ratio': 0.1}]",トークン化
3789,4398,tokenization,トークン化,1.0,20,"[{'word': 'トークン化', 'ratio': 1.0}]",トークン化
3790,4399,tokenization scheme,トークン化方式,0.0,10,"[{'word': 'トークン化スキーム', 'ratio': 1.0}]",トークン化スキーム
3791,4400,tokenizer,トークナイザー,0.9,10,"[{'word': 'トークナイザー', 'ratio': 0.9}, {'word': 'トークナイザ', 'ratio': 0.1}]",トークナイザー
3792,4401,top-1 accuracy,top-1 正解率,0.0,10,"[{'word': 'トップ1精度', 'ratio': 0.5}, {'word': 'トップ1の精度', 'ratio': 0.2}, {'word': 'トップ-1 精度', 'ratio': 0.2}, {'word': 'トップ-1精度', 'ratio': 0.1}]",トップ1精度
3793,4402,top-down segmentation,トップダウンのセグメンテーション,0.1111111111111111,9,"[{'word': 'トップダウンセグメンテーション', 'ratio': 0.7777777777777778}, {'word': 'トップダウン・セグメンテーション', 'ratio': 0.1111111111111111}, {'word': 'トップダウンのセグメンテーション', 'ratio': 0.1111111111111111}]",トップダウンセグメンテーション
3794,4404,top-k sampling,トップkサンプリング,0.5555555555555556,9,"[{'word': 'トップkサンプリング', 'ratio': 0.5555555555555556}, {'word': 'トップ-kサンプリング', 'ratio': 0.2222222222222222}, {'word': 'トップ K サンプリング', 'ratio': 0.1111111111111111}, {'word': 'トップ-k サンプリング', 'ratio': 0.1111111111111111}]",トップkサンプリング
3795,4406,topic assignment,トピック割り当て,0.8888888888888888,9,"[{'word': 'トピック割り当て', 'ratio': 0.8888888888888888}, {'word': 'トピックの割り当て', 'ratio': 0.1111111111111111}]",トピック割り当て
3796,4407,topic classification,トピック分類,0.9,10,"[{'word': 'トピック分類', 'ratio': 0.9}, {'word': 'トピックの分類', 'ratio': 0.1}]",トピック分類
3797,4408,topic distribution,トピック分布,0.9,10,"[{'word': 'トピック分布', 'ratio': 0.9}, {'word': 'トピック配信', 'ratio': 0.1}]",トピック分布
3798,4409,topic model,トピックモデル,1.0,10,"[{'word': 'トピックモデル', 'ratio': 1.0}]",トピックモデル
3799,4410,topic proportion,トピック比率,0.5,10,"[{'word': 'トピック比率', 'ratio': 0.5}, {'word': 'トピック割合', 'ratio': 0.3}, {'word': 'トピックの割合', 'ratio': 0.2}]",トピック比率
3800,4411,topic weight,トピックの重み,0.2,10,"[{'word': 'トピック重み', 'ratio': 0.6}, {'word': 'トピックウェイト', 'ratio': 0.2}, {'word': 'トピックの重み', 'ratio': 0.2}]",トピック重み
3801,4412,total variation,総変動,0.1,10,"[{'word': '全変動', 'ratio': 0.6}, {'word': 'トータル・バリエーション', 'ratio': 0.2}, {'word': '総変動', 'ratio': 0.1}, {'word': '変化', 'ratio': 0.1}]",全変動
3802,4413,total variation distance,全変動距離,0.8,10,"[{'word': '全変動距離', 'ratio': 0.8}, {'word': '総変動距離', 'ratio': 0.1}, {'word': '総変化距離', 'ratio': 0.1}]",全変動距離
3803,4414,toxicity detection,有害性検出,0.3333333333333333,9,"[{'word': '毒性検出', 'ratio': 0.6666666666666666}, {'word': '有害性検出', 'ratio': 0.3333333333333333}]",毒性検出
3804,4415,trace norm,トレースノルム,0.9,10,"[{'word': 'トレースノルム', 'ratio': 0.9}, {'word': 'trace ノルム', 'ratio': 0.1}]",トレースノルム
3805,4416,tracking algorithm,トラッキングアルゴリズム,0.6,10,"[{'word': 'トラッキングアルゴリズム', 'ratio': 0.6}, {'word': 'トラッキング・アルゴリズム', 'ratio': 0.2}, {'word': 'トラッキング アルゴリズム', 'ratio': 0.1}, {'word': '追跡アルゴリズム', 'ratio': 0.1}]",トラッキングアルゴリズム
3806,4417,train,学習,0.5,10,"[{'word': '学習', 'ratio': 0.5}, {'word': '訓練', 'ratio': 0.2}, {'word': '電車', 'ratio': 0.2}, {'word': 'トレーニング', 'ratio': 0.1}]",学習
3807,4419,train set,トレーニングセット,0.1,10,"[{'word': '学習セット', 'ratio': 0.5}, {'word': '訓練セット', 'ratio': 0.2}, {'word': '電車セット', 'ratio': 0.1}, {'word': '列車セット', 'ratio': 0.1}, {'word': 'トレーニングセット', 'ratio': 0.1}]",学習セット
3808,4421,train/test,訓練/テスト,0.2,10,"[{'word': '学習/テスト', 'ratio': 0.5}, {'word': '訓練/テスト', 'ratio': 0.2}, {'word': 'トレーニング／テスト', 'ratio': 0.1}, {'word': 'train/test', 'ratio': 0.1}, {'word': 'トレーニング/テスト', 'ratio': 0.1}]",学習/テスト
3809,4422,trainable parameter,訓練可能なパラメータ,0.0,9,"[{'word': '学習可能なパラメータ', 'ratio': 0.5555555555555556}, {'word': '学習可能パラメータ', 'ratio': 0.3333333333333333}, {'word': 'トレーニング可能なパラメータ', 'ratio': 0.1111111111111111}]",学習可能なパラメータ
3810,4423,trainable weight,訓練可能な重み,0.0,9,"[{'word': '学習可能な重み', 'ratio': 0.5555555555555556}, {'word': '学習可能重み', 'ratio': 0.2222222222222222}, {'word': 'トレーニング可能体重', 'ratio': 0.1111111111111111}, {'word': 'トレーニング可能な体重', 'ratio': 0.1111111111111111}]",学習可能な重み
3811,4424,training accuracy,訓練精度,0.1111111111111111,9,"[{'word': '学習精度', 'ratio': 0.6666666666666666}, {'word': '訓練精度', 'ratio': 0.1111111111111111}, {'word': 'トレーニングの精度', 'ratio': 0.1111111111111111}, {'word': 'トレーニング精度', 'ratio': 0.1111111111111111}]",学習精度
3812,4425,training algorithm,訓練アルゴリズム,0.0,9,"[{'word': '学習アルゴリズム', 'ratio': 0.6666666666666666}, {'word': 'トレーニングアルゴリズム', 'ratio': 0.3333333333333333}]",学習アルゴリズム
3813,4426,training batch,トレーニングバッチ,0.9,10,"[{'word': 'トレーニングバッチ', 'ratio': 0.9}, {'word': '訓練バッチ', 'ratio': 0.1}]",トレーニングバッチ
3814,4427,training corpora,学習コーパス,0.0,10,"[{'word': 'トレーニングコーパス', 'ratio': 0.9}, {'word': '訓練コーパス', 'ratio': 0.1}]",トレーニングコーパス
3815,4428,training corpus,訓練コーパス,0.1,10,"[{'word': 'トレーニングコーパス', 'ratio': 0.7}, {'word': '学習用コーパス', 'ratio': 0.2}, {'word': '訓練コーパス', 'ratio': 0.1}]",トレーニングコーパス
3816,4429,training dataset,訓練データセット,0.1,10,"[{'word': 'トレーニングデータセット', 'ratio': 0.8}, {'word': 'レーニングデータセット', 'ratio': 0.1}, {'word': '訓練データセット', 'ratio': 0.1}]",トレーニングデータセット
3817,4430,training datum,訓練データ,0.1,10,"[{'word': 'トレーニングデータ', 'ratio': 0.9}, {'word': '訓練データ', 'ratio': 0.1}]",トレーニングデータ
3818,4433,training epoch,訓練エポック (くんれんエポック),0.0,10,"[{'word': 'トレーニングエポック', 'ratio': 0.5}, {'word': '学習エポック', 'ratio': 0.4}, {'word': '訓練エポック', 'ratio': 0.1}]",トレーニングエポック
3819,4435,training example,訓練例,0.1,10,"[{'word': 'トレーニング例', 'ratio': 0.5}, {'word': '学習例', 'ratio': 0.4}, {'word': '訓練例', 'ratio': 0.1}]",トレーニング例
3820,4438,training phase,トレーニングフェーズ,0.5,10,"[{'word': 'トレーニングフェーズ', 'ratio': 0.5}, {'word': '訓練フェーズ', 'ratio': 0.2}, {'word': 'トレーニング段階', 'ratio': 0.2}, {'word': '学習フェーズ', 'ratio': 0.1}]",トレーニングフェーズ
3821,4439,training procedure,訓練手順,0.0,10,"[{'word': 'トレーニング手順', 'ratio': 0.5}, {'word': '訓練手続き', 'ratio': 0.2}, {'word': 'トレーニング方法', 'ratio': 0.2}, {'word': '学習手順', 'ratio': 0.1}]",トレーニング手順
3822,4440,training process,学習過程,0.0,10,"[{'word': 'トレーニングプロセス', 'ratio': 0.7}, {'word': '訓練プロセス', 'ratio': 0.2}, {'word': '学習プロセス', 'ratio': 0.1}]",トレーニングプロセス
3823,4441,training sample,訓練サンプル,0.2,10,"[{'word': 'トレーニングサンプル', 'ratio': 0.6}, {'word': '学習サンプル', 'ratio': 0.2}, {'word': '訓練サンプル', 'ratio': 0.2}]",トレーニングサンプル
3824,4442,training set,訓練データセット,0.0,10,"[{'word': 'トレーニングセット', 'ratio': 0.6}, {'word': '訓練セット', 'ratio': 0.2}, {'word': '訓練セッ', 'ratio': 0.1}, {'word': '学習セット', 'ratio': 0.1}]",トレーニングセット
3825,4443,training stability,訓練の安定性,0.1,10,"[{'word': 'トレーニングの安定性', 'ratio': 0.5}, {'word': '学習安定性', 'ratio': 0.2}, {'word': '訓練安定性', 'ratio': 0.1}, {'word': '訓練の安定性', 'ratio': 0.1}, {'word': 'トレーニング安定性', 'ratio': 0.1}]",トレーニングの安定性
3826,4444,training step,訓練ステップ,0.2,10,"[{'word': 'トレーニングステップ', 'ratio': 0.6}, {'word': '訓練ステップ', 'ratio': 0.2}, {'word': '学習ステッ', 'ratio': 0.1}, {'word': '学習ステップ', 'ratio': 0.1}]",トレーニングステップ
3827,4445,training task,訓練タスク,0.2,10,"[{'word': 'トレーニングタスク', 'ratio': 0.5}, {'word': '学習タスク', 'ratio': 0.2}, {'word': '訓練タスク', 'ratio': 0.2}, {'word': 'トレーニング課題', 'ratio': 0.1}]",トレーニングタスク
3828,4446,training time,訓練時間,0.1,10,"[{'word': '学習時間', 'ratio': 0.5}, {'word': 'トレーニング時間', 'ratio': 0.4}, {'word': '訓練時間', 'ratio': 0.1}]",学習時間
3829,4447,training token,学習トークン,0.5,10,"[{'word': '学習トークン', 'ratio': 0.5}, {'word': 'トレーニングトークン', 'ratio': 0.4}, {'word': '訓練トークン', 'ratio': 0.1}]",学習トークン
3830,4448,trajectory forecasting,軌跡予測,0.0,10,"[{'word': '軌道予測', 'ratio': 1.0}]",軌道予測
3831,4449,trajectory optimization,軌道最適化,0.8,10,"[{'word': '軌道最適化', 'ratio': 0.8}, {'word': '軌道の最適化', 'ratio': 0.2}]",軌道最適化
3832,4450,transaction database,トランザクションデータベース,0.9,10,"[{'word': 'トランザクションデータベース', 'ratio': 0.9}, {'word': '取引データベース', 'ratio': 0.1}]",トランザクションデータベース
3833,4451,transductive learning,転移学習,0.2,10,"[{'word': 'トランスダクティブ学習', 'ratio': 0.5}, {'word': '転移学習', 'ratio': 0.2}, {'word': '変換学習', 'ratio': 0.2}, {'word': '伝播学習', 'ratio': 0.1}]",トランスダクティブ学習
3834,4452,transfer function,伝達関数,0.3,10,"[{'word': '転送関数', 'ratio': 0.7}, {'word': '伝達関数', 'ratio': 0.3}]",転送関数
3835,4453,transformation function,変換関数,1.0,10,"[{'word': '変換関数', 'ratio': 1.0}]",変換関数
3836,4454,transformation matrix,変換行列,1.0,10,"[{'word': '変換行列', 'ratio': 1.0}]",変換行列
3837,4455,transformer language model,トランスフォーマー言語モデル,0.9,10,"[{'word': 'トランスフォーマー言語モデル', 'ratio': 0.9}, {'word': 'トランスフォーマ言語モデル', 'ratio': 0.1}]",トランスフォーマー言語モデル
3838,4456,transformer layer,トランスフォーマー層,0.5,10,"[{'word': 'トランスフォーマー層', 'ratio': 0.5}, {'word': 'トランスフォーマーレイヤー', 'ratio': 0.3}, {'word': '変圧器層', 'ratio': 0.2}]",トランスフォーマー層
3839,4458,transformer-based architecture,トランスフォーマー基盤アーキテクチャ,0.1,10,"[{'word': 'トランスフォーマーベースのアーキテクチャ', 'ratio': 0.5}, {'word': 'トランスフォーマーに基づくアーキテクチャ', 'ratio': 0.2}, {'word': 'トランスベースのアーキテクチャ', 'ratio': 0.2}, {'word': 'トランスフォーマー基盤アーキテクチャ', 'ratio': 0.1}]",トランスフォーマーベースのアーキテクチャ
3840,4459,transition distribution,遷移分布,1.0,10,"[{'word': '遷移分布', 'ratio': 1.0}]",遷移分布
3841,4460,transition dynamic,遷移ダイナミクス,0.7,10,"[{'word': '遷移ダイナミクス', 'ratio': 0.7}, {'word': 'トランジション・ダイナミック', 'ratio': 0.1}, {'word': 'ダイナミックな遷移', 'ratio': 0.1}, {'word': '遷移動態', 'ratio': 0.1}]",遷移ダイナミクス
3842,4461,transition function,遷移関数,1.0,10,"[{'word': '遷移関数', 'ratio': 1.0}]",遷移関数
3843,4462,transition graph,遷移グラフ,1.0,10,"[{'word': '遷移グラフ', 'ratio': 1.0}]",遷移グラフ
3844,4463,transition kernel,遷移カーネル,0.9,10,"[{'word': '遷移カーネル', 'ratio': 0.9}, {'word': '移行カーネル', 'ratio': 0.1}]",遷移カーネル
3845,4464,transition matrix,遷移行列,0.9,10,"[{'word': '遷移行列', 'ratio': 0.9}, {'word': '移行行列', 'ratio': 0.1}]",遷移行列
3846,4465,transition model,遷移モデル,0.9,10,"[{'word': '遷移モデル', 'ratio': 0.9}, {'word': '移行モデル', 'ratio': 0.1}]",遷移モデル
3847,4466,transition probability,遷移確率,0.9,10,"[{'word': '遷移確率', 'ratio': 0.9}, {'word': '移行確率', 'ratio': 0.1}]",遷移確率
3848,4467,transition probability model,遷移確率モデル,0.9,10,"[{'word': '遷移確率モデル', 'ratio': 0.9}, {'word': '移行確率モデル', 'ratio': 0.1}]",遷移確率モデル
3849,4468,transition system,遷移システム,0.7,10,"[{'word': '遷移システム', 'ratio': 0.7}, {'word': '移行システム', 'ratio': 0.2}, {'word': '移行系', 'ratio': 0.1}]",遷移システム
3850,4469,transition-based dependency parsing,遷移ベースの依存関係の解析,0.1,10,"[{'word': '遷移ベースの依存構文解析', 'ratio': 0.6}, {'word': '移行ベースの依存構文解析', 'ratio': 0.1}, {'word': '遷移ベースの依存関係解析', 'ratio': 0.1}, {'word': '遷移ベースの依存関係の解析', 'ratio': 0.1}, {'word': '遷移ベースの依存構造解析', 'ratio': 0.1}]",遷移ベースの依存構文解析
3851,4470,transition-based model,遷移ベースモデル,0.1,10,"[{'word': '遷移ベースのモデル', 'ratio': 0.8}, {'word': '移行ベースのモデル', 'ratio': 0.1}, {'word': '遷移ベースモデル', 'ratio': 0.1}]",遷移ベースのモデル
3852,4471,transition-based parser,遷移ベースパーサー,0.0,10,"[{'word': '遷移ベースのパーサー', 'ratio': 0.7}, {'word': '遷移ベースの構文解析器', 'ratio': 0.2}, {'word': '移行ベースのパーサー', 'ratio': 0.1}]",遷移ベースのパーサー
3853,4472,transition-based parsing,遷移ベースの構文解析,0.4,10,"[{'word': '遷移ベースの解析', 'ratio': 0.5}, {'word': '遷移ベースの構文解析', 'ratio': 0.4}, {'word': '移行ベースの構文解析', 'ratio': 0.1}]",遷移ベースの解析
3854,4473,transitive closure,推移閉包,0.9,10,"[{'word': '推移閉包', 'ratio': 0.9}, {'word': '推移的閉鎖', 'ratio': 0.1}]",推移閉包
3855,4474,transitive relation,推移的関係,0.3,10,"[{'word': '推移関係', 'ratio': 0.6}, {'word': '推移的関係', 'ratio': 0.3}, {'word': '推移的な関係', 'ratio': 0.1}]",推移関係
3856,4475,translation invariance,平移不変性,0.0,10,"[{'word': '翻訳不変性', 'ratio': 0.8}, {'word': 'translation invariance', 'ratio': 0.1}, {'word': '翻訳の不変性', 'ratio': 0.1}]",翻訳不変性
3857,4476,translation model,翻訳モデル,1.0,10,"[{'word': '翻訳モデル', 'ratio': 1.0}]",翻訳モデル
3858,4477,translation system,翻訳システム,1.0,10,"[{'word': '翻訳システム', 'ratio': 1.0}]",翻訳システム
3859,4478,translation vector,並進ベクトル,0.1,10,"[{'word': '平行移動ベクトル', 'ratio': 0.6}, {'word': '翻訳ベクトル', 'ratio': 0.2}, {'word': '変換ベクトル', 'ratio': 0.1}, {'word': '並進ベクトル', 'ratio': 0.1}]",平行移動ベクトル
3860,4479,transliteration,転写,0.0,10,"[{'word': '音訳', 'ratio': 0.6}, {'word': '音写', 'ratio': 0.4}]",音訳
3861,4480,transpose,転置,0.9,10,"[{'word': '転置', 'ratio': 0.9}, {'word': '転置行列', 'ratio': 0.1}]",転置
3862,4481,transposition table,転置表,0.2,10,"[{'word': '転置テーブル', 'ratio': 0.5}, {'word': '転置表', 'ratio': 0.2}, {'word': '移項表', 'ratio': 0.1}, {'word': '移調テーブル', 'ratio': 0.1}, {'word': '置換表', 'ratio': 0.1}]",転置テーブル
3863,4483,tree decomposition,木分解,0.7,10,"[{'word': '木分解', 'ratio': 0.7}, {'word': 'ツリーデコモジション', 'ratio': 0.1}, {'word': 'ツリー分解', 'ratio': 0.1}, {'word': 'ツリーの分解', 'ratio': 0.1}]",木分解
3864,4484,tree depth,木の深さ,0.8,10,"[{'word': '木の深さ', 'ratio': 0.8}, {'word': 'ツリーの深さ', 'ratio': 0.1}, {'word': '木深さ', 'ratio': 0.1}]",木の深さ
3865,4485,tree ensemble,木構造アンサンブル,0.0,10,"[{'word': '木のアンサンブル', 'ratio': 0.7}, {'word': 'ツリーアンサンブル', 'ratio': 0.3}]",木のアンサンブル
3866,4486,tree search,木探索,0.7,10,"[{'word': '木探索', 'ratio': 0.7}, {'word': 'ツリーサーチ', 'ratio': 0.2}, {'word': '樹木探索', 'ratio': 0.1}]",木探索
3867,4487,tree structure,木構造,0.2,10,"[{'word': 'ツリー構造', 'ratio': 0.8}, {'word': '木構造', 'ratio': 0.2}]",ツリー構造
3868,4488,tree width,木幅,0.2,10,"[{'word': 'ツリー幅', 'ratio': 0.6}, {'word': '木の幅', 'ratio': 0.2}, {'word': '木幅', 'ratio': 0.2}]",ツリー幅
3869,4489,tree-based model,木構造モデル (ki kouzou moderu),0.0,10,"[{'word': 'ツリーベースモデル', 'ratio': 0.6}, {'word': 'ツリーベースのモデル', 'ratio': 0.2}, {'word': '木ベースモデル', 'ratio': 0.2}]",ツリーベースモデル
3870,4491,tri-gram,トリグラム,0.2,10,"[{'word': 'トライグラム', 'ratio': 0.6}, {'word': 'トリグラム', 'ratio': 0.2}, {'word': '三-グラム', 'ratio': 0.1}, {'word': '三グラム', 'ratio': 0.1}]",トライグラム
3871,4492,triangle inequality,三角不等式,0.9,10,"[{'word': '三角不等式', 'ratio': 0.9}, {'word': '接続クエリの結合', 'ratio': 0.1}]",三角不等式
3872,4493,trifocal tensor,三焦点テンソル,0.8,10,"[{'word': '三焦点テンソル', 'ratio': 0.8}, {'word': 'トリフォーカルテンソル', 'ratio': 0.1}, {'word': '三重焦点テンソル', 'ratio': 0.1}]",三焦点テンソル
3873,4497,trimap,トリマップ,0.6,10,"[{'word': 'トリマップ', 'ratio': 0.6}, {'word': 'トライマップ', 'ratio': 0.2}, {'word': 'トリム', 'ratio': 0.2}]",トリマップ
3874,4498,triple,三つ組,0.0,10,"[{'word': 'トリプル', 'ratio': 1.0}]",トリプル
3875,4499,triplet,三つ組,0.0,10,"[{'word': 'トリプレット', 'ratio': 0.8}, {'word': '三連符', 'ratio': 0.2}]",トリプレット
3876,4500,triplet loss,トリプレット損失,0.6,10,"[{'word': 'トリプレット損失', 'ratio': 0.6}, {'word': '三つ子ロス', 'ratio': 0.2}, {'word': 'トリプルロス', 'ratio': 0.1}, {'word': 'トリプレットロス', 'ratio': 0.1}]",トリプレット損失
3877,4501,true positive rate,真陽性率,1.0,10,"[{'word': '真陽性率', 'ratio': 1.0}]",真陽性率
3878,4502,truth assignment,真理値割り当て,0.1,10,"[{'word': '真理割り当て', 'ratio': 0.7}, {'word': '真実課題', 'ratio': 0.2}, {'word': '真理値割り当て', 'ratio': 0.1}]",真理割り当て
3879,4503,tuple,タプル,0.9,10,"[{'word': 'タプル', 'ratio': 0.9}, {'word': '組', 'ratio': 0.1}]",タプル
3880,4504,tuplex,タプレックス,0.0,10,"[{'word': 'タプルックス', 'ratio': 0.5}, {'word': '二重', 'ratio': 0.2}, {'word': 'タプルペア', 'ratio': 0.2}, {'word': 'タプル展開', 'ratio': 0.1}]",タプルックス
3881,4505,two-class classification,二値分類,0.0,9,"[{'word': '二クラス分類', 'ratio': 0.7777777777777778}, {'word': 'にるいぶんるい', 'ratio': 0.2222222222222222}]",二クラス分類
3882,4506,two-player zero-sum game,二人零和ゲーム,0.4,10,"[{'word': '二人プレイヤーゼロサムゲーム', 'ratio': 0.6}, {'word': '二人零和ゲーム', 'ratio': 0.4}]",二人プレイヤーゼロサムゲーム
3883,4507,type embedding,型埋め込み,0.3,10,"[{'word': 'タイプ埋め込み', 'ratio': 0.6}, {'word': '型埋め込み', 'ratio': 0.3}, {'word': '型の埋め込み', 'ratio': 0.1}]",タイプ埋め込み
3884,4508,unary atom,単項アトム,0.0,10,"[{'word': '単項原子', 'ratio': 1.0}]",単項原子
3885,4509,unary constraint,単項制約,0.9,10,"[{'word': '単項制約', 'ratio': 0.9}, {'word': '単項制約条件', 'ratio': 0.1}]",単項制約
3886,4510,unary feature,単一特徴量,0.0,10,"[{'word': '単項特徴', 'ratio': 0.8}, {'word': '単項機能', 'ratio': 0.1}, {'word': '単項特徴量', 'ratio': 0.1}]",単項特徴
3887,4511,unary potential,単項ポテンシャル,1.0,10,"[{'word': '単項ポテンシャル', 'ratio': 1.0}]",単項ポテンシャル
3888,4512,unary predicate,一項述語 (unary predicate),0.0,10,"[{'word': '単項述語', 'ratio': 1.0}]",単項述語
3889,4513,unary production,単項生成規則,0.1,10,"[{'word': '単項生成', 'ratio': 0.7}, {'word': '単項生産', 'ratio': 0.1}, {'word': '単項生成規則', 'ratio': 0.1}, {'word': '単項規則', 'ratio': 0.1}]",単項生成
3890,4516,uncertainty,不確実性,1.0,10,"[{'word': '不確実性', 'ratio': 1.0}]",不確実性
3891,4517,uncertainty measure,不確実性尺度,0.1,10,"[{'word': '不確実性測定', 'ratio': 0.6}, {'word': '不確実性の尺度', 'ratio': 0.2}, {'word': '不確実性尺度', 'ratio': 0.1}, {'word': '不確実性モデリング', 'ratio': 0.1}]",不確実性測定
3892,4518,uncertainty modeling,不確実性モデリング,0.6,10,"[{'word': '不確実性モデリング', 'ratio': 0.6}, {'word': '不確実性モデル化', 'ratio': 0.4}]",不確実性モデリング
3893,4519,uncertainty sampling,不確実性サンプリング,1.0,10,"[{'word': '不確実性サンプリング', 'ratio': 1.0}]",不確実性サンプリング
3894,4520,undirected graph,無向グラフ,1.0,10,"[{'word': '無向グラフ', 'ratio': 1.0}]",無向グラフ
3895,4521,undirected graphical model,無向グラフィカルモデル,0.8,10,"[{'word': '無向グラフィカルモデル', 'ratio': 0.8}, {'word': '無向グラフモデル', 'ratio': 0.2}]",無向グラフィカルモデル
3896,4522,uniform convergence,一様収束,1.0,10,"[{'word': '一様収束', 'ratio': 1.0}]",一様収束
3897,4523,uniform distribution,一様分布,1.0,10,"[{'word': '一様分布', 'ratio': 1.0}]",一様分布
3898,4524,uniform information density hypothesis,一様情報密度仮説,0.9,10,"[{'word': '一様情報密度仮説', 'ratio': 0.9}, {'word': '均一情報密度仮説', 'ratio': 0.1}]",一様情報密度仮説
3899,4525,uniform sampling,一様サンプリング,0.9,10,"[{'word': '一様サンプリング', 'ratio': 0.9}, {'word': '均一サンプリング', 'ratio': 0.1}]",一様サンプリング
3900,4526,unigram counts,単語出現回数,0.0,10,"[{'word': 'ユニグラムカウント', 'ratio': 1.0}]",ユニグラムカウント
3901,4527,unigram distribution,ユニグラム分布,0.9,10,"[{'word': 'ユニグラム分布', 'ratio': 0.9}, {'word': '単語分布', 'ratio': 0.1}]",ユニグラム分布
3902,4528,unigram language model,単語言語モデル,0.0,10,"[{'word': 'ユニグラム言語モデル', 'ratio': 0.9}, {'word': '単語モデル', 'ratio': 0.1}]",ユニグラム言語モデル
3903,4529,unigram model,単語モデル,0.1,10,"[{'word': 'ユニグラムモデル', 'ratio': 0.9}, {'word': '単語モデル', 'ratio': 0.1}]",ユニグラムモデル
3904,4531,union of conjunctive query,結合条件付き問合せの和,0.0,10,"[{'word': '結合クエリの和', 'ratio': 0.5}, {'word': '接続クエリの結合', 'ratio': 0.2}, {'word': '連言クエリの和', 'ratio': 0.2}, {'word': '結合クエリのユニオン', 'ratio': 0.1}]",結合クエリの和
3905,4532,unit propagation,単位伝播,0.5,10,"[{'word': '単位伝播', 'ratio': 0.5}, {'word': 'ユニット伝播', 'ratio': 0.3}, {'word': '単位伝搬', 'ratio': 0.1}, {'word': 'ユニットの伝播', 'ratio': 0.1}]",単位伝播
3906,4533,unit sphere,単位球,0.9,10,"[{'word': '単位球', 'ratio': 0.9}, {'word': '単位球面', 'ratio': 0.1}]",単位球
3907,4535,universal approximator,万能近似関数,0.0,10,"[{'word': '普遍近似器', 'ratio': 0.5}, {'word': 'ユニバーサル近似器', 'ratio': 0.4}, {'word': 'ユニバーサル近似値', 'ratio': 0.1}]",普遍近似器
3908,4536,universal model,汎用モデル,0.0,10,"[{'word': 'ユニバーサルモデル', 'ratio': 0.5}, {'word': '普遍モデル', 'ratio': 0.5}]",ユニバーサルモデル
3909,4537,unlabeled datum,未ラベルのデータ,0.0,10,"[{'word': 'ラベルなしデータ', 'ratio': 0.5}, {'word': '未ラベルデータ', 'ratio': 0.1}, {'word': '無印データム', 'ratio': 0.1}, {'word': 'ラベルのないデータム', 'ratio': 0.1}, {'word': 'ラベル未付与データ', 'ratio': 0.1}, {'word': 'ラベルのないデータ', 'ratio': 0.1}]",ラベルなしデータ
3910,4538,unlexicalized grammar,非語彙化文法,0.5,10,"[{'word': '非語彙化文法', 'ratio': 0.5}, {'word': '非辞書化文法', 'ratio': 0.2}, {'word': '単文法', 'ratio': 0.1}, {'word': '非詞彙化文法', 'ratio': 0.1}, {'word': '語彙化されていない文法', 'ratio': 0.1}]",非語彙化文法
3911,4539,unnormalized probability,非正規化確率,0.9,10,"[{'word': '非正規化確率', 'ratio': 0.9}, {'word': '正規化されていない確率', 'ratio': 0.1}]",非正規化確率
3912,4541,unsupervised algorithm,教師なし学習アルゴリズム,0.0,10,"[{'word': '教師なしアルゴリズム', 'ratio': 0.9}, {'word': '非監視アルゴリズム', 'ratio': 0.1}]",教師なしアルゴリズム
3913,4542,unsupervised approach,非監督アプローチ,0.0,10,"[{'word': '教師なしアプローチ', 'ratio': 0.9}, {'word': '非監視アプローチ', 'ratio': 0.1}]",教師なしアプローチ
3914,4543,unsupervised classification,教師なし分類,0.9,10,"[{'word': '教師なし分類', 'ratio': 0.9}, {'word': '非監視分類', 'ratio': 0.1}]",教師なし分類
3915,4544,unsupervised clustering,教師なしクラスタリング,0.9,10,"[{'word': '教師なしクラスタリング', 'ratio': 0.9}, {'word': '非監視クラスタリング', 'ratio': 0.1}]",教師なしクラスタリング
3916,4545,unsupervised datum,教師なしデータ,0.8,10,"[{'word': '教師なしデータ', 'ratio': 0.8}, {'word': '教師なしデータム', 'ratio': 0.1}, {'word': '非監督的datum', 'ratio': 0.1}]",教師なしデータ
3917,4546,unsupervised discovery,無監視発見,0.0,10,"[{'word': '教師なし発見', 'ratio': 0.8}, {'word': '監視なしの発見', 'ratio': 0.1}, {'word': '非監督的発見', 'ratio': 0.1}]",教師なし発見
3918,4548,unsupervised domain adaptation,教師なしドメイン適応,0.8,10,"[{'word': '教師なしドメイン適応', 'ratio': 0.8}, {'word': '教師なし領域適応', 'ratio': 0.1}, {'word': '非監督的なドメインアダプテーション', 'ratio': 0.1}]",教師なしドメイン適応
3919,4549,unsupervised feature learning,教師なし特徴学習,0.9,10,"[{'word': '教師なし特徴学習', 'ratio': 0.9}, {'word': '非監督的特徴学習', 'ratio': 0.1}]",教師なし特徴学習
3920,4550,unsupervised image segmentation,教師なし画像セグメンテーション,0.7,10,"[{'word': '教師なし画像セグメンテーション', 'ratio': 0.7}, {'word': '非監視画像セグメンテーション', 'ratio': 0.1}, {'word': '教師なし画像分割', 'ratio': 0.1}, {'word': '未教師画像分割', 'ratio': 0.1}]",教師なし画像セグメンテーション
3921,4551,unsupervised learning,教師なし学習,0.8,10,"[{'word': '教師なし学習', 'ratio': 0.8}, {'word': '非監視学習', 'ratio': 0.1}, {'word': '未教師学習', 'ratio': 0.1}]",教師なし学習
3922,4552,unsupervised method,教師なし手法,0.6,10,"[{'word': '教師なし手法', 'ratio': 0.6}, {'word': '非監視手法', 'ratio': 0.1}, {'word': '教師なし法', 'ratio': 0.1}, {'word': '教師なしメソッド', 'ratio': 0.1}, {'word': '未教師法', 'ratio': 0.1}]",教師なし手法
3923,4553,unsupervised model,教師なしモデル,0.8,10,"[{'word': '教師なしモデル', 'ratio': 0.8}, {'word': '非監視モデル', 'ratio': 0.1}, {'word': '未教師モデル', 'ratio': 0.1}]",教師なしモデル
3924,4554,unsupervised morphological segmentation,非監督形態的分割,0.0,10,"[{'word': '教師なし形態素セグメンテーション', 'ratio': 0.6}, {'word': '非監視形態素セグメンテーション', 'ratio': 0.1}, {'word': '教師なしモルフォロジーセグメンテーション', 'ratio': 0.1}, {'word': '教師なし形態学的セグメンテーション', 'ratio': 0.1}, {'word': '未教師形態的分割', 'ratio': 0.1}]",教師なし形態素セグメンテーション
3925,4557,unsupervised representation,教師なし表現,0.6,10,"[{'word': '教師なし表現', 'ratio': 0.6}, {'word': '無監督表現', 'ratio': 0.2}, {'word': '非監督的表現', 'ratio': 0.1}, {'word': '非監視表現', 'ratio': 0.1}]",教師なし表現
3926,4558,unsupervised representation learning,教師なし表現学習,0.6,10,"[{'word': '教師なし表現学習', 'ratio': 0.6}, {'word': '無監督表現学習', 'ratio': 0.2}, {'word': '非監督的表現学習', 'ratio': 0.1}, {'word': '非監視表現学習', 'ratio': 0.1}]",教師なし表現学習
3927,4559,unsupervised segmentation,無監視分割,0.0,10,"[{'word': '教師なしセグメンテーション', 'ratio': 0.5}, {'word': '無監督セグメンテーション', 'ratio': 0.2}, {'word': '非監督的セグメンテーション', 'ratio': 0.1}, {'word': '非監視セグメンテーション', 'ratio': 0.1}, {'word': '教師なし分割', 'ratio': 0.1}]",教師なしセグメンテーション
3928,4560,unsupervised system,- Term: 教師なしシステム,0.0,10,"[{'word': '教師なしシステム', 'ratio': 0.8}, {'word': '監視されていないシステム', 'ratio': 0.1}, {'word': '非監視システム', 'ratio': 0.1}]",教師なしシステム
3929,4561,unsupervised word clustering,教師なし単語クラスタリング,0.9,10,"[{'word': '教師なし単語クラスタリング', 'ratio': 0.9}, {'word': '非監視単語クラスタリング', 'ratio': 0.1}]",教師なし単語クラスタリング
3930,4562,unweighted graph,無加重グラフ,0.0,10,"[{'word': '無重みグラフ', 'ratio': 0.5}, {'word': '無重量グラフ', 'ratio': 0.1}, {'word': '重みなしグラフ', 'ratio': 0.1}, {'word': '重み付けされていないグラフ', 'ratio': 0.1}, {'word': '非加重グラフ', 'ratio': 0.1}, {'word': '非重み付きグラフ', 'ratio': 0.1}]",無重みグラフ
3931,4563,update function,更新関数,0.8,10,"[{'word': '更新関数', 'ratio': 0.8}, {'word': '更新機能', 'ratio': 0.1}, {'word': 'アップデート機能', 'ratio': 0.1}]",更新関数
3932,4564,update rule,更新ルール,0.7,10,"[{'word': '更新ルール', 'ratio': 0.7}, {'word': '更新規則', 'ratio': 0.3}]",更新ルール
3933,4565,user embedding,ユーザー埋め込み,1.0,10,"[{'word': 'ユーザー埋め込み', 'ratio': 1.0}]",ユーザー埋め込み
3934,4566,user utterance,ユーザ発話,0.1,10,"[{'word': 'ユーザー発話', 'ratio': 0.7}, {'word': 'ユーザー発話ユーザー発話', 'ratio': 0.1}, {'word': 'ユーザーの発話', 'ratio': 0.1}, {'word': 'ユーザ発話', 'ratio': 0.1}]",ユーザー発話
3935,4567,user-item matrix,ユーザー・アイテム行列,0.0,10,"[{'word': 'ユーザーアイテム行列', 'ratio': 0.7}, {'word': 'ユーザーアイテムマトリックス', 'ratio': 0.1}, {'word': 'ユーザー項目マトリックス', 'ratio': 0.1}, {'word': 'ユーザー-アイテム行列', 'ratio': 0.1}]",ユーザーアイテム行列
3936,4568,utility,効用,0.3,10,"[{'word': 'ユーティリティ', 'ratio': 0.6}, {'word': '効用', 'ratio': 0.3}, {'word': '効', 'ratio': 0.1}]",ユーティリティ
3937,4569,utility function,効用関数,1.0,10,"[{'word': '効用関数', 'ratio': 1.0}]",効用関数
3938,4570,utterance,発話,0.9,20,"[{'word': '発話', 'ratio': 0.9}, {'word': '発言', 'ratio': 0.1}]",発話
3939,4571,utterance encoder,発話エンコーダ,1.0,10,"[{'word': '発話エンコーダ', 'ratio': 1.0}]",発話エンコーダ
3940,4572,validation,検証,0.9,10,"[{'word': '検証', 'ratio': 0.9}, {'word': 'バリデーション', 'ratio': 0.1}]",検証
3941,4573,validation accuracy,検証精度,1.0,10,"[{'word': '検証精度', 'ratio': 1.0}]",検証精度
3942,4574,validation dataset,検証データセット,1.0,10,"[{'word': '検証データセット', 'ratio': 1.0}]",検証データセット
3943,4575,validation datum,検証データ,0.9,10,"[{'word': '検証データ', 'ratio': 0.9}, {'word': 'バリデーションデータ', 'ratio': 0.1}]",検証データ
3944,4576,validation loss,検証損失,1.0,10,"[{'word': '検証損失', 'ratio': 1.0}]",検証損失
3945,4577,validation performance,検証パフォーマンス,0.2,10,"[{'word': '検証性能', 'ratio': 0.6}, {'word': 'バリデーション性能', 'ratio': 0.2}, {'word': '検証パフォーマンス', 'ratio': 0.2}]",検証性能
3946,4578,validation set,検証セット,0.8,10,"[{'word': '検証セット', 'ratio': 0.8}, {'word': 'バリデーションセット', 'ratio': 0.2}]",検証セット
3947,4579,validation split,検証用分割,0.0,10,"[{'word': '検証分割', 'ratio': 0.8}, {'word': 'バリデーション分割', 'ratio': 0.1}, {'word': 'バリデーションスプリット', 'ratio': 0.1}]",検証分割
3948,4580,value estimate,価値の推定,0.2,10,"[{'word': '価値推定', 'ratio': 0.6}, {'word': '値の推定', 'ratio': 0.2}, {'word': '価値の推定', 'ratio': 0.2}]",価値推定
3949,4581,value function,価値関数,0.7,10,"[{'word': '価値関数', 'ratio': 0.7}, {'word': '値関数', 'ratio': 0.3}]",価値関数
3950,4582,value function approximation,価値関数近似,0.5,10,"[{'word': '価値関数近似', 'ratio': 0.5}, {'word': '値関数近似', 'ratio': 0.2}, {'word': '値関数の近似', 'ratio': 0.2}, {'word': '値関数アプロキシメーション', 'ratio': 0.1}]",価値関数近似
3951,4583,value iteration,価値反復法,0.0,10,"[{'word': '価値反復', 'ratio': 0.5}, {'word': '値反復', 'ratio': 0.2}, {'word': '値の反復', 'ratio': 0.2}, {'word': '値反復法', 'ratio': 0.1}]",価値反復
3952,4584,value iteration algorithm,価値反復アルゴリズム,0.5,10,"[{'word': '値反復アルゴリズム', 'ratio': 0.5}, {'word': '価値反復アルゴリズム', 'ratio': 0.5}]",値反復アルゴリズム
3953,4585,value network,価値ネットワーク,0.5,10,"[{'word': '価値ネットワーク', 'ratio': 0.5}, {'word': '値ネットワーク', 'ratio': 0.3}, {'word': 'バリューネットワーク', 'ratio': 0.2}]",価値ネットワーク
3954,4586,value-based reinforcement learning,価値ベースの強化学習,0.7,10,"[{'word': '価値ベースの強化学習', 'ratio': 0.7}, {'word': '値ベースの強化学習', 'ratio': 0.2}, {'word': '価値基盤の強化学習', 'ratio': 0.1}]",価値ベースの強化学習
3955,4587,vanilla Transformer,標準Transformer,0.0,10,"[{'word': 'バニラトランスフォーマー', 'ratio': 0.6}, {'word': 'バニラ・トランスフォーマー', 'ratio': 0.2}, {'word': 'バニラ・トランス', 'ratio': 0.1}, {'word': 'ベーシックなトランスフォーマー', 'ratio': 0.1}]",バニラトランスフォーマー
3956,4588,vanishing gradient,勾配消失,0.1,10,"[{'word': '消失勾配', 'ratio': 0.8}, {'word': '消失グラデーション', 'ratio': 0.1}, {'word': '勾配消失', 'ratio': 0.1}]",消失勾配
3957,4589,vanishing gradient problem,勾配消失問題,0.2,10,"[{'word': '消失勾配問題', 'ratio': 0.8}, {'word': '勾配消失問題', 'ratio': 0.2}]",消失勾配問題
3958,4590,variable assignment,変数割り当て,0.8,10,"[{'word': '変数割り当て', 'ratio': 0.8}, {'word': '変数代入', 'ratio': 0.1}, {'word': '変数の代入', 'ratio': 0.1}]",変数割り当て
3959,4591,variable selection,変数選択,0.9,10,"[{'word': '変数選択', 'ratio': 0.9}, {'word': '変数の選択', 'ratio': 0.1}]",変数選択
3960,4592,variance reduction,分散削減,0.8,10,"[{'word': '分散削減', 'ratio': 0.8}, {'word': '分散の削減', 'ratio': 0.2}]",分散削減
3961,4593,variance regularization,分散の正則化,0.2,10,"[{'word': '分散正則化', 'ratio': 0.8}, {'word': '分散の正則化', 'ratio': 0.2}]",分散正則化
3962,4594,variational Bayes,変分ベイズ,1.0,10,"[{'word': '変分ベイズ', 'ratio': 1.0}]",変分ベイズ
3963,4595,variational approach,変分的アプローチ,0.2,10,"[{'word': '変分アプローチ', 'ratio': 0.8}, {'word': '変分的アプローチ', 'ratio': 0.2}]",変分アプローチ
3964,4596,variational approximation,変分近似,1.0,10,"[{'word': '変分近似', 'ratio': 1.0}]",変分近似
3965,4597,variational bound,変分束縛,0.0,10,"[{'word': '変分境界', 'ratio': 0.8}, {'word': '変分限界', 'ratio': 0.2}]",変分境界
3966,4598,variational distribution,変分分布,1.0,10,"[{'word': '変分分布', 'ratio': 1.0}]",変分分布
3967,4599,variational formulation,変分定式化,1.0,10,"[{'word': '変分定式化', 'ratio': 1.0}]",変分定式化
3968,4600,variational framework,変分フレームワーク,1.0,10,"[{'word': '変分フレームワーク', 'ratio': 1.0}]",変分フレームワーク
3969,4601,variational inference,変分推論,1.0,10,"[{'word': '変分推論', 'ratio': 1.0}]",変分推論
3970,4602,variational lower bound,変分下限,0.7,10,"[{'word': '変分下限', 'ratio': 0.7}, {'word': '変分下界', 'ratio': 0.2}, {'word': '可変的な下界', 'ratio': 0.1}]",変分下限
3971,4603,variational method,変分法,0.9,10,"[{'word': '変分法', 'ratio': 0.9}, {'word': '可変的な方法', 'ratio': 0.1}]",変分法
3972,4604,variational model,変分モデル,0.9,10,"[{'word': '変分モデル', 'ratio': 0.9}, {'word': '可変的なモデル', 'ratio': 0.1}]",変分モデル
3973,4605,variational objective,変分目的関数,0.4,10,"[{'word': '変分目的', 'ratio': 0.5}, {'word': '変分目的関数', 'ratio': 0.4}, {'word': '可変的な目的関数', 'ratio': 0.1}]",変分目的
3974,4606,variational parameter,変分パラメータ,0.9,10,"[{'word': '変分パラメータ', 'ratio': 0.9}, {'word': '可変的なパラメーター', 'ratio': 0.1}]",変分パラメータ
3975,4608,vector,ベクトル,0.8,20,"[{'word': 'ベクトル', 'ratio': 0.8}, {'word': 'ベクター', 'ratio': 0.2}]",ベクトル
3976,4609,vector arithmetic,ベクトル演算,0.8,10,"[{'word': 'ベクトル演算', 'ratio': 0.8}, {'word': 'ベクトル算術', 'ratio': 0.2}]",ベクトル演算
3977,4610,vector concatenation,ベクトル連結,0.8,10,"[{'word': 'ベクトル連結', 'ratio': 0.8}, {'word': 'ベクトル結合', 'ratio': 0.1}, {'word': 'ベクトルの連結', 'ratio': 0.1}]",ベクトル連結
3978,4611,vector embedding,ベクトル埋め込み,1.0,10,"[{'word': 'ベクトル埋め込み', 'ratio': 1.0}]",ベクトル埋め込み
3979,4612,vector field,ベクトル場,1.0,10,"[{'word': 'ベクトル場', 'ratio': 1.0}]",ベクトル場
3980,4613,vector graphic,ベクターグラフィック,0.2,10,"[{'word': 'ベクトルグラフィック', 'ratio': 0.8}, {'word': 'ベクターグラフィック', 'ratio': 0.2}]",ベクトルグラフィック
3981,4614,vector normalization,ベクトル正規化,1.0,10,"[{'word': 'ベクトル正規化', 'ratio': 1.0}]",ベクトル正規化
3982,4615,vector quantization,ベクトル量子化,1.0,10,"[{'word': 'ベクトル量子化', 'ratio': 1.0}]",ベクトル量子化
3983,4616,vector representation,ベクトル表現,1.0,10,"[{'word': 'ベクトル表現', 'ratio': 1.0}]",ベクトル表現
3984,4617,vector space,ベクトル空間,1.0,10,"[{'word': 'ベクトル空間', 'ratio': 1.0}]",ベクトル空間
3985,4618,vector space embedding,ベクトル空間埋め込み,0.9,10,"[{'word': 'ベクトル空間埋め込み', 'ratio': 0.9}, {'word': 'ベクトル空間エンコーディング', 'ratio': 0.1}]",ベクトル空間埋め込み
3986,4619,vector space model,ベクトル空間モデル,1.0,9,"[{'word': 'ベクトル空間モデル', 'ratio': 1.0}]",ベクトル空間モデル
3987,4620,vector space representation,ベクトル空間表現,0.9,10,"[{'word': 'ベクトル空間表現', 'ratio': 0.9}, {'word': 'ベクトル表現', 'ratio': 0.1}]",ベクトル空間表現
3988,4621,vector-valued function,ベクトル値関数,1.0,10,"[{'word': 'ベクトル値関数', 'ratio': 1.0}]",ベクトル値関数
3989,4622,vectorization,ベクトル化,1.0,10,"[{'word': 'ベクトル化', 'ratio': 1.0}]",ベクトル化
3990,4623,vectorization operator,ベクトル化演算子,1.0,10,"[{'word': 'ベクトル化演算子', 'ratio': 1.0}]",ベクトル化演算子
3991,4624,vectorize,ベクトル化,0.1,10,"[{'word': 'ベクトル化する', 'ratio': 0.8}, {'word': 'ベクタライズ', 'ratio': 0.1}, {'word': 'ベクトル化', 'ratio': 0.1}]",ベクトル化する
3992,4626,vertex label,頂点ラベル,1.0,10,"[{'word': '頂点ラベル', 'ratio': 1.0}]",頂点ラベル
3993,4627,vertex set,頂点集合,1.0,10,"[{'word': '頂点集合', 'ratio': 1.0}]",頂点集合
3994,4628,victim model,被害者モデル,0.8,10,"[{'word': '被害者モデル', 'ratio': 0.8}, {'word': 'ビクティムモデル', 'ratio': 0.1}, {'word': '被害モデル', 'ratio': 0.1}]",被害者モデル
3995,4629,view synthesis,視点合成,0.5,10,"[{'word': '視点合成', 'ratio': 0.5}, {'word': 'ビュー合成', 'ratio': 0.3}, {'word': 'ビューシンセシス', 'ratio': 0.1}, {'word': 'ビューの合成', 'ratio': 0.1}]",視点合成
3996,4630,virtual camera,仮想カメラ,0.7,10,"[{'word': '仮想カメラ', 'ratio': 0.7}, {'word': 'バーチャルカメラ', 'ratio': 0.3}]",仮想カメラ
3997,4631,vision model,視覚モデル,0.1,10,"[{'word': 'ビジョンモデル', 'ratio': 0.9}, {'word': '視覚モデル', 'ratio': 0.1}]",ビジョンモデル
3998,4632,vision system,ビジョンシステム,0.9,10,"[{'word': 'ビジョンシステム', 'ratio': 0.9}, {'word': '視覚システム', 'ratio': 0.1}]",ビジョンシステム
3999,4634,visual attention,視覚的注意力,0.0,10,"[{'word': '視覚的注意', 'ratio': 1.0}]",視覚的注意
4000,4635,visual attribute,視覚的属性,0.4,10,"[{'word': '視覚属性', 'ratio': 0.6}, {'word': '視覚的属性', 'ratio': 0.4}]",視覚属性
4001,4636,visual context,視覚的コンテキスト,0.0,10,"[{'word': '視覚的文脈', 'ratio': 0.8}, {'word': '視覚的なコンテキスト', 'ratio': 0.1}, {'word': 'ビジュアルコンテキスト', 'ratio': 0.1}]",視覚的文脈
4002,4637,visual cortex,視覚野,0.7,10,"[{'word': '視覚野', 'ratio': 0.7}, {'word': '視覚皮質', 'ratio': 0.3}]",視覚野
4003,4638,visual feature,視覚的特徴,0.3,10,"[{'word': '視覚特徴', 'ratio': 0.5}, {'word': '視覚的特徴', 'ratio': 0.3}, {'word': 'ビジュアル機能', 'ratio': 0.2}]",視覚特徴
4004,4639,visual grounding,視覚的なグラウンディング,0.0,10,"[{'word': '視覚的基盤', 'ratio': 0.6}, {'word': '視覚的グラウンディング', 'ratio': 0.2}, {'word': 'ビジュアルグラウンディング', 'ratio': 0.2}]",視覚的基盤
4005,4642,visual odometry,視覚オドメトリ,0.5,10,"[{'word': '視覚オドメトリ', 'ratio': 0.5}, {'word': 'ビジュアルオドメトリ', 'ratio': 0.3}, {'word': '視覚オドメトリー', 'ratio': 0.2}]",視覚オドメトリ
4006,4643,visual recognition system,視覚認識システム,1.0,10,"[{'word': '視覚認識システム', 'ratio': 1.0}]",視覚認識システム
4007,4644,vocabulary,語彙,0.9,20,"[{'word': '語彙', 'ratio': 0.9}, {'word': '単語表', 'ratio': 0.1}]",語彙
4008,4645,vocabulary size,語彙サイズ,0.9,10,"[{'word': '語彙サイズ', 'ratio': 0.9}, {'word': '単語表サイズ', 'ratio': 0.1}]",語彙サイズ
4009,4646,vocoder,ボコーダー,0.9,10,"[{'word': 'ボコーダー', 'ratio': 0.9}, {'word': 'ボコーダ', 'ratio': 0.1}]",ボコーダー
4010,4647,volume rendering,ボリュームレンダリング,1.0,10,"[{'word': 'ボリュームレンダリング', 'ratio': 1.0}]",ボリュームレンダリング
4011,4649,voting rule,投票規則,0.2,10,"[{'word': '投票ルール', 'ratio': 0.8}, {'word': '投票規則', 'ratio': 0.2}]",投票ルール
4012,4650,voxel,ボクセル,1.0,10,"[{'word': 'ボクセル', 'ratio': 1.0}]",ボクセル
4013,4651,voxel grid,ボクセルグリッド,1.0,10,"[{'word': 'ボクセルグリッド', 'ratio': 1.0}]",ボクセルグリッド
4014,4652,voxel grid representation,ボクセルグリッド表現,1.0,10,"[{'word': 'ボクセルグリッド表現', 'ratio': 1.0}]",ボクセルグリッド表現
4015,4653,voxel occupancy,ボクセル占有率,0.2,10,"[{'word': 'ボクセル占有', 'ratio': 0.8}, {'word': 'ボクセル占有率', 'ratio': 0.2}]",ボクセル占有
4016,4654,voxel representation,ボクセル表現,1.0,10,"[{'word': 'ボクセル表現', 'ratio': 1.0}]",ボクセル表現
4017,4655,voxel-based representation,ボクセルベース表現,0.0,10,"[{'word': 'ボクセルベースの表現', 'ratio': 1.0}]",ボクセルベースの表現
4018,4656,warp function,ワープ関数,0.8,10,"[{'word': 'ワープ関数', 'ratio': 0.8}, {'word': 'ワープ機能', 'ratio': 0.2}]",ワープ関数
4019,4657,wav2vec,wav2vec,1.0,10,"[{'word': 'wav2vec', 'ratio': 1.0}]",wav2vec
4020,4658,wavelet,ウェーブレット,0.9,10,"[{'word': 'ウェーブレット', 'ratio': 0.9}, {'word': 'ウェーブレッ', 'ratio': 0.1}]",ウェーブレット
4021,4659,wavelet transform,ウェーブレット変換,1.0,10,"[{'word': 'ウェーブレット変換', 'ratio': 1.0}]",ウェーブレット変換
4022,4660,weak classifier,弱分類器,0.9,10,"[{'word': '弱分類器', 'ratio': 0.9}, {'word': '弱い分類器', 'ratio': 0.1}]",弱分類器
4023,4662,weak learning,弱学習,0.4,10,"[{'word': '弱い学習', 'ratio': 0.5}, {'word': '弱学習', 'ratio': 0.4}, {'word': '弱学', 'ratio': 0.1}]",弱い学習
4024,4666,weakly supervised learning,弱教師学習,0.0,10,"[{'word': '弱教師あり学習', 'ratio': 0.6}, {'word': '弱い教師あり学習', 'ratio': 0.3}, {'word': '弱教師付き学習', 'ratio': 0.1}]",弱教師あり学習
4025,4667,web graph,ウェブグラフ,1.0,10,"[{'word': 'ウェブグラフ', 'ratio': 1.0}]",ウェブグラフ
4026,4668,weight,重み,0.8,10,"[{'word': '重み', 'ratio': 0.8}, {'word': '重量', 'ratio': 0.1}, {'word': '重さ', 'ratio': 0.1}]",重み
4027,4669,weight decay,重み減衰,0.8,10,"[{'word': '重み減衰', 'ratio': 0.8}, {'word': '荷重減衰', 'ratio': 0.1}, {'word': '体重減少', 'ratio': 0.1}]",重み減衰
4028,4670,weight initialization,重み初期化,0.8,10,"[{'word': '重み初期化', 'ratio': 0.8}, {'word': 'ウエイト初期化', 'ratio': 0.1}, {'word': '重みの初期化', 'ratio': 0.1}]",重み初期化
4029,4671,weight matrix,重み行列,1.0,10,"[{'word': '重み行列', 'ratio': 1.0}]",重み行列
4030,4672,weight parameter,重みパラメータ,1.0,10,"[{'word': '重みパラメータ', 'ratio': 1.0}]",重みパラメータ
4031,4673,weight regularization,重み正則化,0.9,10,"[{'word': '重み正則化', 'ratio': 0.9}, {'word': '重みの正規化', 'ratio': 0.1}]",重み正則化
4032,4674,weight tensor,重みテンソル,0.9,10,"[{'word': '重みテンソル', 'ratio': 0.9}, {'word': '重み正則化', 'ratio': 0.1}]",重みテンソル
4033,4675,weight update,重み更新,0.8,10,"[{'word': '重み更新', 'ratio': 0.8}, {'word': '体重更新', 'ratio': 0.1}, {'word': '体重の更新', 'ratio': 0.1}]",重み更新
4034,4676,weight vector,重みベクトル,1.0,10,"[{'word': '重みベクトル', 'ratio': 1.0}]",重みベクトル
4035,4677,weight-sharing,重み共有,0.8,10,"[{'word': '重み共有', 'ratio': 0.8}, {'word': '体重共有', 'ratio': 0.2}]",重み共有
4036,4678,weighted adjacency matrix,重み付き隣接行列,0.8,10,"[{'word': '重み付き隣接行列', 'ratio': 0.8}, {'word': '重み付けされた隣接行列', 'ratio': 0.2}]",重み付き隣接行列
4037,4679,weighted average,加重平均,0.2,10,"[{'word': '重み付き平均', 'ratio': 0.8}, {'word': '加重平均', 'ratio': 0.2}]",重み付き平均
4038,4680,weighted directed graph,重み付き有向グラフ,0.8,10,"[{'word': '重み付き有向グラフ', 'ratio': 0.8}, {'word': '加重有向グラフ', 'ratio': 0.2}]",重み付き有向グラフ
4039,4681,weighted graph,重み付きグラフ,0.5,10,"[{'word': '加重グラフ', 'ratio': 0.5}, {'word': '重み付きグラフ', 'ratio': 0.5}]",加重グラフ
4040,4682,weighted sum,重み付き和,0.4,10,"[{'word': '加重和', 'ratio': 0.6}, {'word': '重み付き和', 'ratio': 0.4}]",加重和
4041,4683,weighting function,重み付け関数,1.0,10,"[{'word': '重み付け関数', 'ratio': 1.0}]",重み付け関数
4042,4684,white-box,ホワイトボックス,0.9,10,"[{'word': 'ホワイトボックス', 'ratio': 0.9}, {'word': '白箱', 'ratio': 0.1}]",ホワイトボックス
4043,4685,white-box attack,ホワイトボックス攻撃,1.0,10,"[{'word': 'ホワイトボックス攻撃', 'ratio': 1.0}]",ホワイトボックス攻撃
4044,4686,window size,ウィンドウサイズ,1.0,10,"[{'word': 'ウィンドウサイズ', 'ratio': 1.0}]",ウィンドウサイズ
4045,4687,within-class variance,クラス内分散,1.0,10,"[{'word': 'クラス内分散', 'ratio': 1.0}]",クラス内分散
4046,4688,word alignment,単語アライメント,0.5,10,"[{'word': '単語アライメント', 'ratio': 0.5}, {'word': '単語アラインメント', 'ratio': 0.3}, {'word': 'ワードアライメント', 'ratio': 0.1}, {'word': '単語の配置', 'ratio': 0.1}]",単語アライメント
4047,4689,word dropout,単語ドロップアウト,0.5,10,"[{'word': '単語ドロップアウト', 'ratio': 0.5}, {'word': 'ワードドロップアウト', 'ratio': 0.3}, {'word': 'ワード・ドロップアウト', 'ratio': 0.2}]",単語ドロップアウト
4048,4690,word embedding,ワード埋め込み,0.3,10,"[{'word': '単語埋め込み', 'ratio': 0.5}, {'word': 'ワード埋め込み', 'ratio': 0.3}, {'word': '単語の埋め込み', 'ratio': 0.2}]",単語埋め込み
4049,4691,word embedding model,ワード埋め込みモデル,0.3,10,"[{'word': '単語埋め込みモデル', 'ratio': 0.7}, {'word': 'ワード埋め込みモデル', 'ratio': 0.3}]",単語埋め込みモデル
4050,4692,word representation,単語表現,0.7,10,"[{'word': '単語表現', 'ratio': 0.7}, {'word': 'ワード表現', 'ratio': 0.3}]",単語表現
4051,4693,word segmentation,単語分割,0.8,10,"[{'word': '単語分割', 'ratio': 0.8}, {'word': 'ワードセグメンテーション', 'ratio': 0.1}, {'word': 'ワード分割', 'ratio': 0.1}]",単語分割
4052,4697,word token,単語トークン,0.6666666666666666,9,"[{'word': '単語トークン', 'ratio': 0.6666666666666666}, {'word': '語トークン', 'ratio': 0.2222222222222222}, {'word': '単語字句', 'ratio': 0.1111111111111111}]",単語トークン
4053,4698,word vector,単語ベクトル,0.6666666666666666,9,"[{'word': '単語ベクトル', 'ratio': 0.6666666666666666}, {'word': '語ベクトル', 'ratio': 0.2222222222222222}, {'word': 'ワードベクトル', 'ratio': 0.1111111111111111}]",単語ベクトル
4054,4699,word vector representation,単語ベクトル表現,0.9,10,"[{'word': '単語ベクトル表現', 'ratio': 0.9}, {'word': 'ワードベクトル表現', 'ratio': 0.1}]",単語ベクトル表現
4055,4701,word-level,単語レベル,0.9,10,"[{'word': '単語レベル', 'ratio': 0.9}, {'word': '単語レベルの', 'ratio': 0.1}]",単語レベル
4056,4702,word-level vocabulary,単語レベルの語彙,1.0,10,"[{'word': '単語レベルの語彙', 'ratio': 1.0}]",単語レベルの語彙
4057,4703,word2vec embedding,word2vecエンベディング,0.0,9,"[{'word': 'word2vec埋め込み', 'ratio': 0.6666666666666666}, {'word': 'word2vec 埋め込み', 'ratio': 0.2222222222222222}, {'word': 'ワード2ベック   埋め込み', 'ratio': 0.1111111111111111}]",word2vec埋め込み
4058,4704,world state,世界状態,0.6666666666666666,9,"[{'word': '世界状態', 'ratio': 0.6666666666666666}, {'word': '世界の状態', 'ratio': 0.3333333333333333}]",世界状態
4059,4705,worst case,最悪ケース,0.1111111111111111,9,"[{'word': '最悪の場合', 'ratio': 0.7777777777777778}, {'word': '最悪のケース', 'ratio': 0.1111111111111111}, {'word': '最悪ケース', 'ratio': 0.1111111111111111}]",最悪の場合
4060,4706,worst-case regret,最悪ケースの後悔,0.5555555555555556,9,"[{'word': '最悪ケースの後悔', 'ratio': 0.5555555555555556}, {'word': '最悪の後悔', 'ratio': 0.3333333333333333}, {'word': '最悪の場合の後悔', 'ratio': 0.1111111111111111}]",最悪ケースの後悔
4061,4708,zero-shot classification,ゼロショット分類,1.0,10,"[{'word': 'ゼロショット分類', 'ratio': 1.0}]",ゼロショット分類
4062,4709,zero-shot cross-lingual setting,ゼロショット言語横断設定,0.0,10,"[{'word': 'ゼロショットクロスリンガル設定', 'ratio': 0.6}, {'word': 'ゼロショットのクロスリンガル設定', 'ratio': 0.2}, {'word': 'ゼロショット跨言語設定', 'ratio': 0.1}, {'word': 'ゼロショットクロス言語設定', 'ratio': 0.1}]",ゼロショットクロスリンガル設定
4063,4710,zero-shot generalization,ゼロショット汎化,0.1,10,"[{'word': 'ゼロショット一般化', 'ratio': 0.9}, {'word': 'ゼロショット汎化', 'ratio': 0.1}]",ゼロショット一般化
4064,4711,zero-shot learning,ゼロショット学習,0.8888888888888888,9,"[{'word': 'ゼロショット学習', 'ratio': 0.8888888888888888}, {'word': '射点学習', 'ratio': 0.1111111111111111}]",ゼロショット学習
4065,4712,zero-shot prediction,ゼロショット予測,0.8888888888888888,9,"[{'word': 'ゼロショット予測', 'ratio': 0.8888888888888888}, {'word': '射点予測', 'ratio': 0.1111111111111111}]",ゼロショット予測
4066,4713,zero-shot prompting,ゼロショットプロンプティング,0.6666666666666666,9,"[{'word': 'ゼロショットプロンプティング', 'ratio': 0.6666666666666666}, {'word': 'ゼロショット・プロンプティング', 'ratio': 0.1111111111111111}, {'word': 'ゼロショットプロンプト', 'ratio': 0.1111111111111111}, {'word': '射点プログラミング', 'ratio': 0.1111111111111111}]",ゼロショットプロンプティング
4067,4714,zero-shot reasoning,ゼロショット推論,0.7777777777777778,9,"[{'word': 'ゼロショット推論', 'ratio': 0.7777777777777778}, {'word': 'ゼロショット推理', 'ratio': 0.1111111111111111}, {'word': '射点推理', 'ratio': 0.1111111111111111}]",ゼロショット推論
4068,4715,zero-shot setting,ゼロショット設定,0.8888888888888888,9,"[{'word': 'ゼロショット設定', 'ratio': 0.8888888888888888}, {'word': '射点設定', 'ratio': 0.1111111111111111}]",ゼロショット設定
4069,4716,zero-shot transfer,ゼロショット転移,0.0,5,"[{'word': 'ゼロショット転送', 'ratio': 0.6}, {'word': 'ゼロショット・トランスファー', 'ratio': 0.2}, {'word': 'ポアソン分布', 'ratio': 0.2}]",ゼロショット転送
