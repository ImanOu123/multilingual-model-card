{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2215629/2555542648.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/ubuntu/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor\n",
    "from transformers import SeamlessM4TModel\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/hf-seamless-m4t-Large\", use_fast=False, force_download=True)\n",
    "model = SeamlessM4TModel.from_pretrained(\"facebook/hf-seamless-m4t-Large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "src = \"Inspired by the success in NLP, embodied agent research [29,11,94,23] has seen a surge in adoption of the large-scale pre-training paradigm. The recent advances can be roughly divided into 4 categories. 1) Novel agent architecture: Decision Transformer [19,58,144] applies the powerful self-attention models to sequential decision making.\"\n",
    "tgt = \"受到NLP的成功启发,体现代理研究 [29,11,94,23] 已经看到大规模预训练范式的采用激增. 最近的进步可以大致分为4个类别. 1) 新型代理架构:决策变换器 [19,58,144] 应用强大的自我注意模型来进行顺序决策.\"\n",
    "\n",
    "seamless_lang_dict = {\n",
    "    \"Arabic\": \"arb\",\n",
    "    \"Chinese\": \"cmn\",\n",
    "    \"English\": \"eng\",\n",
    "    \"French\": \"fra\",\n",
    "    \"Japanese\": \"jpn\",\n",
    "    \"Russian\": \"rus\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.672 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Keyword arguments {'add_special_tokens': False} not recognized.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "sent_src, sent_tgt = src.split(), jieba.cut(tgt, cut_all=False)\n",
    "token_src, token_tgt = [processor.tokenizer.tokenize(word) for word in sent_src], [processor.tokenizer.tokenize(word) for word in sent_tgt]\n",
    "wid_src, wid_tgt = [processor.tokenizer.convert_tokens_to_ids(x) for x in token_src], [processor.tokenizer.convert_tokens_to_ids(x) for x in token_tgt]\n",
    "ids_src, ids_tgt = processor.tokenizer.prepare_for_model(list(itertools.chain(*wid_src)), return_tensors='pt', model_max_length=processor.tokenizer.model_max_length, truncation=True)['input_ids'], processor.tokenizer.prepare_for_model(list(itertools.chain(*wid_tgt)), return_tensors='pt', truncation=True, model_max_length=processor.tokenizer.model_max_length)['input_ids']\n",
    "sub2word_map_src = []\n",
    "for i, word_list in enumerate(token_src):\n",
    "  sub2word_map_src += [i for x in word_list]\n",
    "sub2word_map_tgt = []\n",
    "for i, word_list in enumerate(token_tgt):\n",
    "  sub2word_map_tgt += [i for x in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This calls the same method `forward` as `SeamlessM4TForTextToText` and `SeamlessM4TForSpeechToText`depending on the input modality. If you want to generate speech, use the `generate` method.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m   out_src \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids_src\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m2\u001b[39m][align_layer][\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m   out_tgt \u001b[38;5;241m=\u001b[39m model(ids_tgt\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m2\u001b[39m][align_layer][\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      9\u001b[0m   dot_prod \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(out_src, out_tgt\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmmc/lib/python3.10/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:4103\u001b[0m, in \u001b[0;36mSeamlessM4TModel.forward\u001b[0;34m(self, input_ids, input_features, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   4098\u001b[0m     encoder_attention_mask \u001b[38;5;241m=\u001b[39m _compute_new_attention_mask(\n\u001b[1;32m   4099\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m], seq_lens\u001b[38;5;241m=\u001b[39msub_sampled_lengths\n\u001b[1;32m   4100\u001b[0m     )\n\u001b[1;32m   4102\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 4103\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_decoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4104\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4109\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4110\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4112\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4116\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(decoder_outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   4118\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmmc/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmmc/lib/python3.10/site-packages/transformers/models/seamless_m4t/modeling_seamless_m4t.py:1935\u001b[0m, in \u001b[0;36mSeamlessM4TDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1933\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m inputs_embeds[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either decoder_input_ids or decoder_inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;66;03m# past_key_values_length\u001b[39;00m\n\u001b[1;32m   1938\u001b[0m past_key_values_length \u001b[38;5;241m=\u001b[39m past_key_values[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "# alignment\n",
    "align_layer = 8\n",
    "threshold = 1e-3\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  out_src = model(ids_src.unsqueeze(0), output_hidden_states=True)[2][align_layer][0, 1:-1]\n",
    "  out_tgt = model(ids_tgt.unsqueeze(0), output_hidden_states=True)[2][align_layer][0, 1:-1]\n",
    "\n",
    "  dot_prod = torch.matmul(out_src, out_tgt.transpose(-1, -2))\n",
    "\n",
    "  softmax_srctgt = torch.nn.Softmax(dim=-1)(dot_prod)\n",
    "  softmax_tgtsrc = torch.nn.Softmax(dim=-2)(dot_prod)\n",
    "\n",
    "  softmax_inter = (softmax_srctgt > threshold)*(softmax_tgtsrc > threshold)\n",
    "\n",
    "align_subwords = torch.nonzero(softmax_inter, as_tuple=False)\n",
    "align_words = set()\n",
    "for i, j in align_subwords:\n",
    "  align_words.add( (sub2word_map_src[i], sub2word_map_tgt[j]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This calls the same method `forward` as `SeamlessM4TForTextToText` and `SeamlessM4TForSpeechToText`depending on the input modality. If you want to generate speech, use the `generate` method.\n"
     ]
    }
   ],
   "source": [
    "from transformers import SeamlessM4TPreTrainedModel\n",
    "\n",
    "text_decoder_input_ids = None\n",
    "tgt_lang=seamless_lang_dict['Chinese']\n",
    "# overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.\n",
    "if tgt_lang is not None:\n",
    "    # tgt_lang gets priority over decoder input ids\n",
    "    text_tgt_lang_id = model.generation_config.text_decoder_lang_to_code_id.get(tgt_lang)\n",
    "    text_decoder_input_ids = torch.tensor([[text_tgt_lang_id]] * 1).to(model.device)\n",
    "tmp = model(input_ids = ids_src.unsqueeze(0), decoder_input_ids = text_decoder_input_ids, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state', 'encoder_hidden_states', 'encoder_attentions'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  4.9665,   0.0387,  -1.3188,  ..., -17.2500,  12.2500,  16.5000]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 16.7873,   3.9872,   0.5610,  ..., -13.7077,  11.3955,  18.0485]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 22.2562,  11.6295,   3.8558,  ..., -24.7709,   5.1860,  14.1023]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[27.6290, 22.7810,  2.6495,  ..., -4.8424,  5.9881, 12.5329]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[28.2655,  2.1479, 21.5410,  ..., -8.8447, -5.6392,  0.8634]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 27.9577, -18.5634,  16.0729,  ...,  -0.6811,  -9.6785,   1.6732]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[34.2803, -9.0215,  3.6110,  ..., 12.6973, -8.0849,  3.3641]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[  7.0729, -36.1400,   3.7265,  ...,  22.2282,   8.5002,   6.6390]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[  2.7952, -49.4387,  -2.5552,  ...,  24.9252,   3.3260,  -4.5877]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[  9.1147, -75.7577,  -7.5837,  ...,  58.9246,   9.4788, -28.7606]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[  19.8087, -102.3986,   -9.8482,  ...,   47.9398,    5.5176,\n",
       "            -15.9993]]], grad_fn=<AddBackward0>),\n",
       " tensor([[[  38.1005, -105.3547,  -31.7673,  ...,   70.4732,   -0.7224,\n",
       "              7.6675]]], grad_fn=<AddBackward0>),\n",
       " tensor([[[ 62.8046, -85.3882,  10.2621,  ...,  85.2479,   6.0982,  -4.8870]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 58.3093, -87.2213,  20.4489,  ...,  92.8699,  28.4076,  33.7088]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[  77.6186, -104.3620,   52.6979,  ...,  151.0595,   81.6770,\n",
       "             21.1863]]], grad_fn=<AddBackward0>),\n",
       " tensor([[[ 57.3063, -77.5667,  93.9017,  ..., 181.2927, 112.3260, -28.8750]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 29.3564, -86.4421, 104.9798,  ..., 170.0719, 146.7454, -52.2828]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 15.6129, -72.5974, 115.7959,  ..., 164.0750, 148.6132, -94.3734]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 32.5264, -46.0496,  99.4249,  ..., 173.8399, 222.3525, -87.9100]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 17.3451,   4.1302,  87.1977,  ..., 215.4267, 259.1890, -91.1390]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 44.6645,  19.2726,  71.2715,  ..., 202.2281, 227.2287, -36.2387]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 35.1099,  13.6720,  24.8087,  ..., 209.8593, 175.6220, -10.9501]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[  8.2526, -25.5467,  58.3383,  ..., 235.1826, 206.0030, -34.4207]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 11.1068, -65.1426,  25.4473,  ..., 239.9110, 211.2227,   8.0869]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.2732, -0.0474, -0.2862,  ...,  0.1743,  0.0293,  0.0586]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[2]\n",
    "# difference: this is an encoder-decoder model; graham's is an encoder-only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special_tokens': False} not recognized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[256022,  68133,  53302,    983,    321,  22858,     70,    118,  83310,\n",
       "         247681,  16782,   2909,     61,  23514,  47418,  73458,   5201, 215346,\n",
       "         247736,   4118, 247717,   6128,   4015,  14490,     10, 229134,     70,\n",
       "         161998,    290,    321,  48396, 247711,  42854,    525,    615, 247711,\n",
       "           6297,   3868, 130434, 247673, 247676,   1078,  59264,  68798,   1518,\n",
       "           3559,    488,   2783,   6662,   1613, 236671,  15333,    378, 219343,\n",
       "         247676,  25634, 214120,  23514, 186284, 247813,  10201,  14260,  15327,\n",
       "          43463,    665,  97999, 247780,   5070,   7979,   9452,   8192,  35369,\n",
       "            321, 179626,  28093, 247711, 214867, 136970,    243,  94168,  74078,\n",
       "          79056,  70685, 247676,      3,      0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__eng__',\n",
       " 'Insp',\n",
       " 'ired',\n",
       " 'by',\n",
       " 'the',\n",
       " 'success',\n",
       " 'in',\n",
       " 'N',\n",
       " 'LP',\n",
       " ',',\n",
       " 'emb',\n",
       " 'odi',\n",
       " 'ed',\n",
       " 'agent',\n",
       " 'research',\n",
       " '[2',\n",
       " '9,',\n",
       " '11,',\n",
       " '9',\n",
       " '4,',\n",
       " '2',\n",
       " '3]',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'a',\n",
       " 'surge',\n",
       " 'in',\n",
       " 'adoption',\n",
       " 'of',\n",
       " 'the',\n",
       " 'large',\n",
       " '-',\n",
       " 'sc',\n",
       " 'ale',\n",
       " 'pre',\n",
       " '-',\n",
       " 'tra',\n",
       " 'ining',\n",
       " 'paradig',\n",
       " 'm',\n",
       " '.',\n",
       " 'The',\n",
       " 'recent',\n",
       " 'advan',\n",
       " 'ces',\n",
       " 'can',\n",
       " 'be',\n",
       " 'ro',\n",
       " 'ugh',\n",
       " 'ly',\n",
       " 'divided',\n",
       " 'into',\n",
       " '4',\n",
       " 'categories',\n",
       " '.',\n",
       " '1)',\n",
       " 'Novel',\n",
       " 'agent',\n",
       " 'architecture',\n",
       " ':',\n",
       " 'Dec',\n",
       " 'ision',\n",
       " 'Trans',\n",
       " 'former',\n",
       " '[',\n",
       " '19,',\n",
       " '5',\n",
       " '8,',\n",
       " '14',\n",
       " '4]',\n",
       " 'app',\n",
       " 'lies',\n",
       " 'the',\n",
       " 'powerful',\n",
       " 'self',\n",
       " '-',\n",
       " 'attention',\n",
       " 'models',\n",
       " 'to',\n",
       " 'sequ',\n",
       " 'ential',\n",
       " 'decision',\n",
       " 'making',\n",
       " '.',\n",
       " '</s>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
