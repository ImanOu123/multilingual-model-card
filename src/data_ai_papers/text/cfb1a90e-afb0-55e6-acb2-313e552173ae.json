{"title": "Discriminative Non-blind Deblurring", "authors": "Uwe Schmidt; Carsten Rother; Sebastian Nowozin; Jeremy Jancsary; Stefan Roth", "pub_date": "", "abstract": "Non-blind deblurring is an integral component of blind approaches for removing image blur due to camera shake. Even though learning-based deblurring methods exist, they have been limited to the generative case and are computationally expensive. To this date, manually-defined models are thus most widely used, though limiting the attained restoration quality. We address this gap by proposing a discriminative approach for non-blind deblurring. One key challenge is that the blur kernel in use at test time is not known in advance. To address this, we analyze existing approaches that use half-quadratic regularization. From this analysis, we derive a discriminative model cascade for image deblurring. Our cascade model consists of a Gaussian CRF at each stage, based on the recently introduced regression tree fields. We train our model by loss minimization and use synthetically generated blur kernels to generate training data. Our experiments show that the proposed approach is efficient and yields state-of-the-art restoration quality on images corrupted with synthetic and real blur.", "sections": [{"heading": "Introduction", "text": "Image blur (e.g., camera shake) is one of the main sources of image corruption in digital photography and hard to undo. Image deblurring has thus been an active area of research, starting with the pioneering work of Lucy [21] and Richardson [23]. Recent work has predominantly focused on blind deblurring, particularly on estimating the blur from images (stationary and non-stationary). However, relatively little attention has been paid to non-blind deblurring, that is, restoring the image given known or estimated image blur. Yet, this is an important problem since most blind deblurring approaches separate the problem into blur estimation and non-blind deblurring (theoretically justified by Levin et al. [20]). To this date, most approaches rely on the classical Lucy-Richardson algorithm as non-blind deblurring component [e.g., 8], or use manually-defined image priors formulated as Markov random fields (MRFs) with sparse, i.e. non-Gaussian, potential functions [17,18,30]. Learning-based approaches have been restricted to gener-atively trained models [25], but have found limited adoption due to computational challenges in inference. This is in contrast to image denoising, where discriminative approaches have been used extensively [2,4,14,27], and are often characterized by state-of-the-art restoration performance combined with low computational effort.\nIn this paper we introduce a discriminative non-blind image deblurring approach for arbitrary photographic input images and arbitrary blurs. To the best of our knowledge, this is the first time discriminative deblurring has been attempted. Our model is discriminatively trained by minimizing an application-specific loss function (here, PSNR) on a training set. In this paper we assume stationary image blur, i.e. the observed image is the result of convolving the unknown original image with a blur kernel (+ noise), but our approach is not limited to this setup and can be extended to non-uniform image blurs.\nIn a discriminative approach, a number of challenges have to be overcome. Since it is in general not feasible to train a specialized model for every image blur, it is necessary to train a model that outputs a deblurred image given an arbitrary input image and blur kernel. We address this by effectively parametrizing our discriminative model with the blur kernel. The difficulty here is that the image distortion is only known at test time. We address this using a model cascade based on regression tree fields [15], which first predicts a relatively crude estimate that removes dominant image blur and is refined further in later stages. Moreover, sufficient training data must be available, but realistic image blurs are scarce [16,20]. We use synthetically generated blur kernels to overcome this limitation.\nWe further make the following contributions: (1) We analyze commonly used half-quadratic regularization [11,12] with sparse image priors, and show how our formulation naturally arises as a generalization; (2) we train our model with realistic, but synthetically generated blur kernels and experimentally demonstrate that a model trained in such a way generalizes to unseen real blur kernels; (3) we demonstrate state-of-the-art performance on a synthetically blurred test set [25] and on two realistic data sets for camera shake [16,19]. While previous non-blind deblurring approaches have for the most part either been very fast but with inferior performance, or slow but with high-quality results [e.g. 25], our approach delivers state-of-the-art deblurring performance with an efficient inference method that allows deblurring even higher-resolution images.", "publication_ref": ["b20", "b22", "b16", "b17", "b29", "b24", "b1", "b3", "b13", "b26", "b14", "b15", "b19", "b10", "b11", "b24", "b15", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Generalizing Half-quadratic Regularization", "text": "To motivate our discriminative approach and understand its connections to the existing literature, it is beneficial to recall half-quadratic regularizers [5,11,12] and their relation to recent image restoration approaches 1 . In image deblurring, denoising and other restoration applications, sparse image priors are frequently used for regularization [e.g. 17,18,24]. Typically, they model an image x through the response of linear filters f j (e.g., horizontal and vertical image derivatives), which induce overlapping cliques c \u2208 C j in the corresponding Markov random field (MRF) prior:\np(x) \u221d j c\u2208C j \u03c1 j (f T j x (c) ).(1)\nA sparse (non-Gaussian) potential function \u03c1 j models the filter response of f j to the clique pixels x (c) .\nThe image corruption process is often modeled by specifying a Gaussian likelihood p(y|x) = N (y; Kx, \u03c3 2 I) for the observed, corrupted image y. In the case of non-blind deconvolution, we have Kx = k \u2297 x, where K is the blur matrix that corresponds to convolving the image with a blur kernel k. The image noise is assumed to be pixelindependent additive white Gaussian noise with variance \u03c3 2 . Using Bayes' theorem, one obtains the posterior distribution over the restored image as p(x|y) \u221d p(y|x) \u2022 p(x).\nThe principle of half-quadratic regularization [5,11,12] is to ease inference (e.g., MAP estimation) by introducing (independent) auxiliary/latent variables z jc for each filter and image clique, such that the prior is retained by performing an operation \u2208 {max, sup, , , . . .} that eliminates the auxiliary variables:\np(x) \u221d z p(x, z) \u221d j c\u2208C j z jc \u03c6 j (f T j x (c) , z jc ).(2)\nThere are two choices for the form of \u03c6 j : the multiplicative form \u03c6 j (u, z) = exp \u2212 1 2 u 2 z \u2212 \u03c8 m (z) [11] and the additive form \u03c6 j (u, z) = exp \u2212b(u \u2212 z) 2 \u2212 \u03c8 a (z) [12] . In either case, \u03c8 m (z) respectively \u03c8 a (z) are chosen such that \u03c1 j (u) = z \u03c6 j (u, z) (see example in Fig. 1). The name stems from the fact that the energy of \u03c6 j (u, z) is quadratic in u but not in z. This further implies that for a fixed setting of z the distribution p(x|z) = N (x; \u03bc x|z , \u03a3 x|z ) is jointly Gaussian. When combined with a Gaussian likelihood, we obtain a Gaussian posterior for a fixed setting of z:\np(x|y, z) \u221d N (y; Kx, \u03c3 2 I) \u2022 N (x; \u03bc x|z , \u03a3 x|z ) \u221d N (x; \u03bc x|y,z , \u03a3 x|y,z ).(3)\nThe benefit of this is that MAP estimation can now be carried out on the augmented posterior p(x, z|y) with a variational EM algorithm [cf . 22] that alternates between maximizing p(x|y, z) and using p(z|x, y) to update the auxiliary variables based on the operation . Maximizing p(x|y, z) w.r.t. x amounts to computing \u03bc x|y,z , which requires solving a sparse linear equation system. Updating z based on p(z|y, x) is easy, since all z jc are independent:\np(z|x, y) \u221d j c\u2208C j p(z jc |x, y)(4)\np(z jc |x, y) \u221d \u03c6 j (f T j x (c) , z jc ).\nBy using the fact that a wide variety of robust (sparse) potentials \u03c1 j can be expressed (or approximated) by taking the supremum over the auxiliary variables z [3], one can reformulate the majority of sparse image priors in this way. Levin et al. [18] and Krishnan and Fergus [17] have employed this principle for efficient image deblurring. Note that MRF image priors based on Gaussian scale mixtures (GSMs) [29] can also be interpreted as an instance of halfquadratic regularization in which = (or = for infinite GSMs). This has been used by Schmidt et al. [25] for deblurring with sampling-based inference, which alternates between sampling from p(x|y, z) and p(z|x, y).", "publication_ref": ["b4", "b10", "b11", "b0", "b16", "b17", "b23", "b4", "b10", "b11", "b10", "b11", "b2", "b17", "b16", "b28", "b24"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Discriminative alternative", "text": "To see how classical half-quadratic regularization can be connected to a discriminative approach, it is instructive to consider what happens during the last inference iteration. Once the final set of latent variables z * has been determined from Eq. (5), the output image x * is inferred by maximizing p(x|y, z * ) from Eq. (3). This distribution is nothing but an anisotropic (or inhomogeneous) Gaussian random field, whose mean and covariance depend on y and z * . Therefore \u03bc x|y,z * and \u03a3 x|y,z * are the mean and covariance parameters of a multivariate normal distribution defined on the whole image, chosen through z * so as to hopefully lead to good deblurring results. The value of z * depends on the specific choice of potential functions \u03c1 j and their half-quadratic inference approximations \u03c6 j (Eq. (5)).\nIt is now natural to ask whether we can instead directly regress the Gaussian random field parameters from the input image. To this end we can regress a precision matrix \u0398(y) and a vector \u03b8(y), and set \u03bc := [\u0398(y)] \u22121 \u03b8 and \u03a3 := [\u0398(y)] \u22121 . Then the mean \u03bc and the covariance \u03a3 are learned functions of the observed image y. There are three potential advantages: First, we avoid the expensive iterative computation of the half-quadratic optimization. Second, we can regress the parameters discriminatively in order to optimize a given performance measure, such as PSNR. Third, we are no longer constrained to the form of Eq. ( 5) so that we can now use an expressive regression model on the input image. That is, we are not restricting 2 the resulting model compared to Eq. (3); in fact, we can potentially learn a more expressive model.\nWe arrived at this model from a novel analysis of the half-quadratic approximation, but predicting the means and covariances of a Gaussian model has been done before: Gaussian conditional random fields, first proposed by Tappen et al. [27], have led to competitive results in image denoising. A recent extension we will build on are the regression tree fields (RTF) by Jancsary et al. [14,15].\nImage deblurring. Non-blind image deblurring is more difficult than image denoising, and it might be difficult to directly regress suitable model parameters. To illustrate this difficulty, let us assume that f j are first-order derivative filters. Then, in the generative approach one can think of z jc as modulating pairwise potentials: reducing smoothness constraints in case of large image derivatives of the output image x, and imposing smoothness otherwise. In other words, in the generative approach z determines the local model of the restored image x. Both x and z are iteratively refined via half-quadratic inference. In a discriminative model we have access only to the corrupted image y in order to determine suitable local models.\nBut in the case of deblurring, the image content in y is shifted and combined with other parts of the image, depending on a blur kernel that is different for each image. This makes the choice of local models difficult. We believe this is one of the reasons why discriminative non-blind deblurring approaches had not been attempted before.\nx (i +1) z (i ) x (i -1)\nx (i ) z (i +1) \u2297fj Eq. ( 5)\n(i +1 ) \u0398 , (i +1 ) \u03b8 x (i -1) x (i ) x (i +1)", "publication_ref": ["b26", "b13", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Regression", "text": "Fi lte r ba nk\n\u03b8 (i ) (i ) \u0398 , Figure 2. Standard half-quadratic vs. discriminative cascade.\nIn a standard half-quadratic approach (top), each z jc can only be updated via Eq. ( 5) based on the filter response f T j x (c) of the pixels in the local clique (small white circles, only one filtered image f j \u2297 x shown). In the proposed discriminative cascade (bottom), one can use arbitrary features of the image over larger areas (large white circles) to find model parameters \u0398 (i) and \u03b8 (i) via regression. At each stage, the functions \u0398 (i) and \u03b8 (i) depend on y through features, such as filter bank responses, image intensities, and also depend on all x (i) from previous iterations (not shown).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Discriminative model cascade", "text": "To build a discriminative model for deblurring, we draw inspiration from the iterative refinement of z in halfquadratic regularization. We start with an educated guess of the Gaussian model parameters, regressed from the input image, to obtain a restored image x (1) , which is less corrupted than the original input image. We can then use this as an intermediate result to help regress refined Gaussian model parameters, in order to obtain a better restored image x (2) , etc., effectively obtaining a cascade of refined models. Note that this is a general approach that is not only applicable to image deblurring. Image denoising and other restoration tasks may also benefit from such a model cascade and repeated refinement of the auxiliary variables; we do not consider this here, however.\nA key advantage of a discriminative approach for predicting model parameters \u0398 (i) , \u03b8 (i) at the i th stage is its flexibility. As discussed above, a standard generative halfquadratic approach updates each z jc only based on the local clique of the current estimate of the restored image (cf . Eq. ( 5)). In a discriminative approach, we can regress the parameters based on arbitrary local and global properties of the input image as well as the current estimate of the re-stored image (see Fig. 2 for an illustration). Consequently, we can expect to obtain better estimates in fewer iterations, compared to a non-discriminative approach.\nOther related work. This iterative procedure can also be linked with earlier ideas about iterative refinement. The idea of auto-context [28] is to use the same probabilistic model multiple times in sequence, where each model receives as input the observed image and the output of the previous model in the sequence. The proposed discriminative cascade is also related to the active random field [2], which is a multi-stage approach for image denoising that is trained discriminatively. The key difference is that each stage in [2] corresponds to a gradient descent iteration of the model energy, whereas we use full discriminative prediction.", "publication_ref": ["b0", "b1", "b27", "b1", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Gaussian CRF for Deblurring", "text": "As we have seen, a discriminative alternative to halfquadratic MAP estimation is conceptually attractive, but also challenging due to the need of regressing local image models from the blurred input image y. To address this challenge we propose a novel Gaussian CRF p(x|y, K) for non-blind image deblurring. One challenge in devising such a model is that we cannot train a different model for every blur matrix K; this difficulty may in fact be the reason why no such approach exists to date. To see how this can be circumvented, we can take inspiration from generative approaches to deblurring and see how the Gaussian blur likelihood p(y|x, K) contributes to the posterior distribution when assuming a Gaussian prior:\np(x|y, K) \u221d p(y|x, K) \u2022 p(x) \u221d N (y; Kx, I/\u03b1) \u2022 N (x; \u0398 \u22121 \u03b8, \u0398 \u22121 ) \u221d N x; (\u03b1K T K) \u22121 \u03b1K T y, (\u03b1K T K) \u22121 \u2022 N (x; \u0398 \u22121 \u03b8, \u0398 \u22121 ) \u221d N x; (\u0398 + \u03b1K T K) \u22121 (\u03b8 + \u03b1K T y), (6) (\u0398 + \u03b1K T K) \u22121 ,\nwhere \u03b1 = 1/\u03c3 2 relates to the noise level, \u0398 is the precision of the Gaussian prior, and \u03b8 relates to its mean. We can now define a Gaussian CRF in which the model parameters \u0398 and \u03b8 are not fixed, but regressed from the input image, i.e. \u0398 \u2261 \u0398(y) and \u03b8 \u2261 \u03b8(y) are functions of y. Note that the CRF is parameterized by a fixed blur K as in Eq. (6); the blur is not used as an input feature to the regressor.\nPlease note that for the problem of image denoising, i.e. K = I, explicitly incorporating a component related to the likelihood as described above is not necessary, since its contribution can be learned by the regression function. However, for deblurring this is not feasible, and it is crucial to incorporate a blur component into the model to adapt to arbitrary blurs.\nOnce we have determined the parameters via regression, we can obtain a deblurred image as the MAP estimate, which can be derived in closed form as the mean of the Gaussian CRF, arg max\nx p(x|y, K) = (\u0398(y) + \u03b1K T K) \u22121 (\u03b8(y) + \u03b1K T y), (7) and can be computed by solving a sparse linear system.", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "Regression tree field", "text": "To make our approach concrete, we need to specify the regression functions \u0398(y) and \u03b8(y). To that end, we draw on the recently proposed regression tree field (RTF) model by Jancsary et al. [14,15]. RTFs have shown excellent results in image restoration applications, such as image denoising, inpainting, and colorization.\nIn general, RTFs take the form of a Gaussian CRF in which a non-linear regressor is used to specify the local model parameters. Specifically, regression trees are used, where each leaf stores an individual linear regressor that determines a local potential. Since any Gaussian CRF can be decomposed into factors relating no more than two pixels, our posterior density attains the following form:\np(x|y, K) \u221d N (y; Kx, I/\u03b1) \u2022 J+1 j=1 c\u2208C j \u03c6 j (x (c) , y) (8) \u03c6 j (x (c) , y) \u221d exp \u2212 1 2 x T (c) \u0398 j c (y)x (c) + x T (c) \u03b8 j c (y) ,\nwhere C j denotes all pairs of neighboring pixels in the j th of J possible spatial configurations. Concretely, we use 8and 24-neighborhoods depending on the stage in our prediction cascade, i.e. J = 4 and J = 12, respectively (due to spatial symmetries). Additionally, at each stage, we employ a single unary potential \u03c6 J+1 (x (c) , y), where C J+1 is simply the set of all individual pixels. We extend these previous RTF-based approaches to our setting by (a) incorporating the blur likelihood for non-blind image deblurring into the prediction as outlined in Eqs. ( 6) and (7), and (b) by assembling multiple RTFs into a model cascade that iteratively refines the prediction (see Sec. 3.3).\nNote that the RTF generalizes the Gaussian CRF of Tappen et al. [27] in two ways: First, the potentials of an RTF are non-linearly dependent on the input image via non-parametric regression trees. Second, the model parameters of arbitrary pairwise Gaussian potentials (with full mean and covariance) are regressed from the input image, whereas [27] restrict their parameterization to diagonal weighting of filter responses.", "publication_ref": ["b13", "b14", "b6", "b26", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "Training", "text": "While probabilistic training is possible [15], we here follow [14] and learn the regressors using loss-based train- ing, in particular, such that the peak signal-to-noise ratio (PSNR) is maximized. All parameters of the model, including the split functions in the tree and the linear regressors in the leaves, are chosen to maximize PSNR.\nDiscriminative training necessitates a sufficient amount of training data to ensure generalization. Since capturing image pairs of blurred and clean images is difficult, one possible avenue is to synthesize training data by blurring clean images with realistic blurs. Unfortunately, existing databases [16,20] only supply a relatively limited number of blur kernels, and moreover serve also for testing. Hence the model should not be trained on these. We address this problem by generating realistic-looking blur kernels by sampling random 3D trajectories using a simple linear motion model; the obtained trajectories are projected and rasterized to random square kernel sizes in the range from 5 \u00d7 5 up to 27 \u00d7 27 pixels (see Fig. 3). While it would of course be possible to create even more realistic kernels through more accurate models of camera shake motion 3 , we find that these synthetic kernels already allow to generalize well to unseen real blur (cf . Sec. 4). We synthetically generate blurred images by convolving each clean image with an artificially generated blur kernel, and subsequently add pixel-independent Gaussian noise (using standard deviations \u03c3 = 2.55 or 0.5, see experiments in Sec. 4). We use crops of 128 \u00d7 128 pixels from the training portion of the Berkeley segmentation dataset [1] as ground truth images.", "publication_ref": ["b14", "b13", "b15", "b19", "b2", "b0"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "RTF prediction cascade", "text": "As argued in Sec. 2, it is difficult to directly regress good local image models from the blurred input image. Therefore, we employ a cascade of RTF models, where each subsequent model stage uses the output of all previous models as features for the regression (see Fig. 4 for an illustration).\nWe train the first stage of the cascade with minimal conditioning on the input image to avoid overfitting. The parameters of the unary and pairwise potentials are only linearly regressed from the pixels in the respective cliques (plus a constant pseudo-input); we do not use a regression tree. We further use an 8-connected graph structure, resulting in one unary and four pairwise potentials (horizontal, vertical, and two diagonals). We train this model with 200 pairs of blurred and clean images, which is ample since there are only few model parameters. This model will be referred to as RTF 1 .", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "(y,K)", "text": "RTF1 x (1) RTF2 x (2) RTF3 x (3) Filter bank Filter bank While we do not expect excellent results from RTF 1 , it is able to remove the dominant blur from the input image (cf . Sec. 4 and Fig. 6) and makes it much easier for subsequent RTF stages to regress good potentials for the CRF. Besides the blurred input image, the second stage, RTF 2 , thus uses the output of RTF 1 as input feature. Additionally, we evaluate a filter bank on the output of RTF 1 to obtain more expressive features. In doing so we follow [14], which obtained improved results in image denoising using the output of a filter bank as input to the regressor. However, we use a different filter bank here, the 16 generatively trained 5 \u00d7 5 filters from the recent Fields-of-Experts model of [10]; we found these filters to outperform other filter banks we have tried, including those used in [14] 4 .\nWe use all these features for the split tests in the regression tree (non-linear regression), as well as for the linear potential parameter regressor that is stored in each leaf of the tree. We choose regression trees of depth 7. All subsequent model stages, i.e. RTF 3 , RTF 4 , etc., take as features the outputs from all previous stages, where the filter bank is always only evaluated on the directly preceding model output. Please see Fig. 4 for a schematic. Starting with RTF 2 , the Gaussian CRF at each layer uses a 24-connected graph structure, i.e. each pixel is connected to all others in a 5 \u00d7 5 neighborhood. Due to the increased amount of model parameters, we train RTF 2 and each subsequent stage with 500 training images, randomly cropped from the training portion of the Berkeley segmentation dataset [1] and blurred with randomly chosen artificial blur kernels (different at each stage).\nAn interesting property of our model cascade is that it yields a deblurred image after every stage, not only at the end. Even if a deep cascade was trained, at test time we can trade off computational resources versus quality of the deblurred image by stopping after a certain stage (cf . Fig. 6; see [9] for a similar approach applied to segmentation).", "publication_ref": ["b0", "b1", "b2", "b13", "b9", "b13", "b3", "b0", "b8"], "figure_ref": ["fig_4", "fig_2", "fig_4"], "table_ref": []}, {"heading": "Experiments", "text": "To demonstrate the performance of our approach, we apply it to three challenging datasets, specifically to highlight individual benefits. First, we analyze the performance in standard conditions for non-blind deblurring, i.e. when training and testing is carried out with perfect blur kernels. Second, we evaluate the generalization ability of our ap-  1. Average PSNR (dB) on 64 images from [25] for two noise levels. Left half reproduced from [25] for ease of comparison.\nproach by training the model to deal with imperfect blur kernels. This is important for blind deblurring, where the estimated blur kernels mostly contain some errors. Third, we demonstrate the applicability to realistic higher-resolution images. Please note that images and kernels are always kept strictly separate for training and testing in all experiments.\nStandard conditions. We trained a six-stage RTF prediction cascade as described in Sec. 3 and evaluate all stages individually on 64 test images taken from [25]. Training images have been blurred synthetically with 1% additive white Gaussian noise (\u03c3 = 2.55); test images with both \u03c3 = 2.55 and a higher noise level of \u03c3 = 7.65. While we used artifical blur kernels to generate our training data, the test images from [25] have been created with the realistic kernels from [20]. The blur kernels used for deblurring are slightly perturbed from the ground truth to mimic kernel estimation errors, but the perturbation is somewhat minor here. We compare our average PSNR performance to all methods that were evaluated in [25]. The results in Tab. 1 show that we achieve state-of-the-art performance that is on par with the high-quality sampling-based approach of Schmidt et al. [25] at \u03c3 = 2.55, and even outperforms it at \u03c3 = 7.65 despite not being trained for this noise level (only \u03b1 was adapted, see Eq. ( 6)). As we shall discuss below, our approach is many times faster, however. At the noise level our model is trained for (2.55), we strongly outperform the efficient half-quadratic regularization approach of Krishnan and Fergus [17] by over 1.5dB, and the popular method of Levin et al. [18] by 0.6dB. The clear performance gains at the higher noise level demonstrate our model's noise generalization. We further notice that the weakly conditional first stage (RTF 1 ) leads only to modest performance levels here; RTF 2 and RTF 3 boost the performance substantially further. Later stages lead to additional gains, but less so. Aside from the raw numbers, it is noteworthy that our model is able to preserve small details, while at the same time reconstructing smooth areas well (see Fig. 5 for an example). Note that this is not the case for the approaches tested in [25].\nThis demonstrates that when testing (and training) is done with the correct (i.e. ground truth) blur kernels, as usual for non-blind deblurring, our approach achieves excellent results. Another important point is that even though our model has been trained on artificially generated blur kernels (Fig. 3), it apparently generalizes well to real blurs.\nAdaptation to kernel estimation errors. Blind deblurring approaches often produce kernel estimates with substantial errors, which can cause ringing artifacts in the restored image [cf . 31]. Hence, it is important to evaluate and adapt our model to this realistic scenario. To train our model for this task, we experimented with adding noise to the ground truth kernels and also used estimated kernels for training. We consider the data of Levin et al. [19] as a benchmark, which provides several kernel estimates besides blurred and ground truth images for 32 test instances, as well as deblurring results with the various kernel estimates. Since the amount of noise in these blurred images is significantly lower than in the benchmark of [25], we only added Gaussian noise with \u03c3 = 0.5 to our training images. We evaluate average PSNR performance over all 32 images (using code by [19] to account for translations in kernel estimates) instead of error ratios as in [19], since we are not interested in the quality of the estimated kernels itself, but rather the final restoration performance given the estimated kernels.\nThe results in Tab. 2 show that training with ground truth kernels leads to subpar performance when kernels estimates are used at test time. Adding noise to the ground truth kernels for training leads to improved results of RTF 1 with estimated kernels at test time, but performance of our second stage model RTF 2 already deteriorates; hence those noisy kernels are not an ideal proxy for real kernel estimates. However, we achieve superior results by training our model with a mix of perfect and estimated kernels (obtained with the method of Xu and Jia [30]), i.e. for half of the synthetically blurred training images we use an estimated kernel instead of the ground truth kernel 5 . Compared to the deblurred images from [19] (which used the  [19]. All kernels used for testing are from the benchmark set [19], except for those in the two rightmost columns: we derived the noisy ground truth (GT) kernels from the provided GT kernels, and estimated kernels with [30]. The last row shows the average performance of deblurring results provided by [19] (using the non-blind approach of [18]). For the kernel estimates of [19] (4 th column), we used the \"free energy with diagonal covariance approximation\" algorithm in the filter domain.\nnon-blind approach of [18]), we achieve substantial performance improvements for deblurring with estimated kernels of up to 0.72dB (for kernels from [8]). Furthermore, it is interesting to note that the first stage of our model already achieves good performance; this is presumably due to the much reduced amount of noise in this benchmark 7 .\nRuntime. The computational demand of our method is comparable to the half-quadratic approach of [18], but uses this computational budget more effectively due to its discriminative nature (cf . Sec. 2 and Fig. 2). Also note that the tree-based regressor is very efficient. As a result, we achieve state-of-the-art performance on par with the best result of [25], but much faster: about 2 seconds per image in Tab. 1 (all six model stages combined) compared to 4 minutes for [25]. For the benchmark in Tab. 2 with larger images, we require around 3 seconds for each model stage.\nRealistic higher-resolution images. We consider the recent benchmark for camera shake by K\u00f6hler et al. [16] to demonstrate results on realistic higher-resolution images; these images may substantially violate our model's stationary blur and Gaussian noise assumptions (which can deteriorate performance [cf . 7,26]). The benchmark consists of 4 color images of size 800 \u00d7 800 pixels blurred by 12 different real camera motions, yielding 48 images in total.\nThe overall best performing blind deblurring approach in this benchmark is the one by Xu and Jia [30] despite making a stationary blur assumption, i.e. the same blur kernel is used in all parts of the image. We use the provided kernel estimates by [30] from the benchmark dataset, but with our non-blind method to obtain the deblurred image (treating color channels R, G, and B independently). Tab. 3 shows that performance (evaluated using the provided code) can substantially be improved by using our RTF 2 model instead of their non-blind step (which is related to [17]). While Xu  [30] in the benchmark of K\u00f6hler et al. [16] for each combination of 4 test images and 12 blur kernels. We use the provided blur kernel estimates of [30] with our RTF 2 model for non-blind deblurring. We can improve the performance in 43 of 48 test instances, on average about 0.41dB. Figure 7. Deblurring example from the benchmark of [16] (cf . Tab.\n3), showing the result of our RTF 2 model (right) given the blurred image (left) and the kernel estimates by [30].\nand Jia's non-blind step is inherently faster, it does lead to substantially worse results, here on average 0.41dB. Fig. 7 shows an example of a deblurred image. Note that the RTF 2 model used here is the same as in Tab. 2, i.e. trained with a mix of ground truth and estimated kernels (using [30]), and additive Gaussian noise with \u03c3 = 0.5. ", "publication_ref": ["b24", "b24", "b24", "b24", "b19", "b24", "b24", "b16", "b17", "b24", "b18", "b24", "b18", "b18", "b29", "b4", "b18", "b18", "b18", "b29", "b18", "b17", "b18", "b17", "b7", "b6", "b17", "b24", "b24", "b15", "b6", "b25", "b29", "b29", "b16", "b29", "b15", "b29", "b15", "b29", "b29"], "figure_ref": ["fig_3", "fig_1"], "table_ref": []}, {"heading": "Summary and Conclusions", "text": "From a novel analysis of common half-quadratic regularization, we introduced -to the best of our knowledgethe first discriminative non-blind deblurring method. Our proposed cascade model is based on regression tree fields at each stage, which are trained by loss minimization on training data generated with synthesized blur kernels. We demonstrated state-of-the art performance on three challenging benchmarks, including robustness to kernel estimation errors in the context of blind deblurring. Our approach is not limited to image deblurring and can readily be extended to other image restoration applications in the future.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Acknowledgements. We thank Pushmeet Kohli for discussions and Stephan Richter for help in preparation of Fig. 2. Parts of this work have been done when Uwe Schmidt interned at Microsoft Research Cambridge, UK. Funding is partly provided by Microsoft Research through its PhD Scholarship Programme.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Contour detection and hierarchical image segmentation", "journal": "TPAMI", "year": "2011", "authors": "P Arbelaez; M Maire; C Fowlkes; J Malik"}, {"ref_id": "b1", "title": "Learning real-time MRF inference for image denoising", "journal": "", "year": "2009", "authors": "A Barbu"}, {"ref_id": "b2", "title": "On the unification of line processes, outlier rejection, and robust statistics with applications in early vision", "journal": "IJCV", "year": "1996", "authors": "M J Black; A Rangarajan"}, {"ref_id": "b3", "title": "Image denoising: Can plain neural networks compete with BM3D", "journal": "", "year": "2012", "authors": "H C Burger; C J Schuler; S Harmeling"}, {"ref_id": "b4", "title": "Two deterministic half-quadratic regularization algorithms for computed imaging", "journal": "", "year": "1994", "authors": "P Charbonnier; L Blanc-F\u00e9raud; G Aubert; M Barlaud"}, {"ref_id": "b5", "title": "Fast motion deblurring", "journal": "ACM T. Graphics", "year": "2009", "authors": "S Cho; S Lee"}, {"ref_id": "b6", "title": "Handling outliers in non-blind image deconvolution", "journal": "", "year": "2011", "authors": "S Cho; J Wang; S Lee"}, {"ref_id": "b7", "title": "Freeman. Removing camera shake from a single photograph", "journal": "ACM T. Graphics", "year": "2006", "authors": "R Fergus; B Singh; A Hertzmann; S T Roweis; W "}, {"ref_id": "b8", "title": "As time goes by-anytime semantic segmentation with iterative context forests", "journal": "", "year": "", "authors": "B Fr\u00f6hlich; E Rodner; J Denzler"}, {"ref_id": "b9", "title": "How well do filter-based MRFs model natural images?", "journal": "", "year": "", "authors": "Q Gao; S Roth"}, {"ref_id": "b10", "title": "Constrained restoration and the recovery of discontinuities", "journal": "TPAMI", "year": "1992", "authors": "D Geman; G Reynolds"}, {"ref_id": "b11", "title": "Nonlinear image recovery with halfquadratic regularization", "journal": "IEEE TIP", "year": "1995", "authors": "D Geman; C Yang"}, {"ref_id": "b12", "title": "A fast learning algorithm for deep belief nets", "journal": "Neural Comput", "year": "2006", "authors": "G A Hinton; S Osindero; Y.-W Teh"}, {"ref_id": "b13", "title": "Loss-specific training of nonparametric image restoration models: A new state of the art", "journal": "", "year": "2012", "authors": "J Jancsary; S Nowozin; C Rother"}, {"ref_id": "b14", "title": "Regression tree fields -an efficient, non-parametric approach to image labeling problems", "journal": "", "year": "2012", "authors": "J Jancsary; S Nowozin; T Sharp; C Rother"}, {"ref_id": "b15", "title": "Recording and playback of camera shake: Benchmarking blind deconvolution with a real-world database", "journal": "", "year": "2012", "authors": "R K\u00f6hler; M Hirsch; B Mohler; B Sch\u00f6lkopf; S Harmeling"}, {"ref_id": "b16", "title": "Fast image deconvolution using hyper-Laplacian priors", "journal": "", "year": "2009", "authors": "D Krishnan; R Fergus"}, {"ref_id": "b17", "title": "Image and depth from a conventional camera with a coded aperture", "journal": "ACM T. Graphics", "year": "2007", "authors": "A Levin; R Fergus; F Durand; W T Freeman"}, {"ref_id": "b18", "title": "Efficient marginal likelihood optimization in blind deconvolution", "journal": "", "year": "2011", "authors": "A Levin; Y Weiss; F Durand; W T Freeman"}, {"ref_id": "b19", "title": "Understanding and evaluating blind deconvolution algorithms", "journal": "", "year": "2009", "authors": "A Levin; Y Weiss; F Durand; W T Freeman"}, {"ref_id": "b20", "title": "An iterative technique for the rectification of observed distributions", "journal": "The Astronom. Journal", "year": "1974", "authors": "L B Lucy"}, {"ref_id": "b21", "title": "Variational EM algorithms for non-Gaussian latent variable models", "journal": "", "year": "2005", "authors": "J A Palmer; D P Wipf; K Kreutz-Delgado; B D Rao"}, {"ref_id": "b22", "title": "Bayesian-based iterative method of image restoration", "journal": "J. Opt. Soc. America", "year": "1972", "authors": "W Richardson"}, {"ref_id": "b23", "title": "Fields of experts", "journal": "IJCV", "year": "2009", "authors": "S Roth; M J Black"}, {"ref_id": "b24", "title": "Bayesian deblurring with integrated noise estimation", "journal": "", "year": "2011", "authors": "U Schmidt; K Schelten; S Roth"}, {"ref_id": "b25", "title": "Motion-aware noise filtering for deblurring of noisy and blurry images", "journal": "", "year": "2012", "authors": "Y.-W Tai; S Lin"}, {"ref_id": "b26", "title": "Learning Gaussian conditional random fields for low-level vision", "journal": "", "year": "2007", "authors": "M Tappen; C Liu; E H Adelson; W T Freeman"}, {"ref_id": "b27", "title": "Auto-context and its application to high-level vision tasks", "journal": "", "year": "2008", "authors": "Z Tu"}, {"ref_id": "b28", "title": "Scale mixtures of Gaussians and the statistics of natural images", "journal": "", "year": "1999", "authors": "M J Wainwright; E P Simoncelli"}, {"ref_id": "b29", "title": "Two-phase kernel estimation for robust motion deblurring", "journal": "", "year": "2010", "authors": "L Xu; J Jia"}, {"ref_id": "b30", "title": "Progressive inter-scale and intra-scale non-blind image deconvolution", "journal": "ACM T. Graphics", "year": "2008", "authors": "L Yuan; J Sun; L Quan; H.-Y Shum"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 .1Figure 1. Half-quadratic representation of a sparse potential. Hyper-Laplacian \u03c1(u) = exp(\u2212|u| \u03b3 ) (dashed, black), where \u03c1(u) = sup z \u03c6(u, z), and \u03c6(u, z) = exp(\u2212 1 2 u 2 z \u2212 \u03c8 m (z)) (solid, red) with \u03c8 m (z) = (1 \u2212 \u03b3/2) \u2022 (z/\u03b3) \u03b3 \u03b3\u22122 and \u03b3 = 2/3.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 3 .3Figure 3. Examples of artificially generated blur kernels.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 4 .4Figure 4. RTF prediction cascade. Only three stages are shown.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 5 .5Figure 5. Deblurring example (cropped). Qualitative comparison with the high-quality approach of [25] (3 \u00d7 3 FoE, MMSE estimation). Our approach (b) reconstructs smooth and textured areas well, exhibits fewer artifacts, and is many times faster. Best viewed zoomed in on screen.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 6 .6Figure 6. Deblurring example at different model stages. The first stage RTF 1 removes dominant blur from the image (c), but artifacts remain. The second stage RTF 2 (d) substantially improves upon this result quantitatively and qualitatively. Further model stages continue to suppress noise and refine image details (e). The left sides of (c-e) show a closeup view of image details on the respective right sides. The blur kernel is shown at the upper left of (b), scaled and resized for better visualization. Best viewed on screen.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Method 2.55 7.65 Stage 2.55 7.65 Lucy-Richardson [21, 23] 25.38 21.85 RTF 1 26.33 24.23 Krishnan and Fergus [17] 26.97 24.91 RTF 2 28.21 25.54 Levin et al. [18] 28.03 25.36 RTF 3 28.50 25.75 5 \u00d7 5 FoE (MAP) [24] 28.44 25.66 RTF 4 28.58 25.81 Pairw. MRF (MMSE) [25] 28.24 25.63 RTF 5 28.65 25.87 3 \u00d7 3 FoE (MMSE) [25] 28.66 25.68 RTF 6 28.67 25.89", "figure_data": "Table"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Method Kernels for trainingKernels for testing GTLevin et al.[19] Cho and Lee[6] Fergus et al.[8] Noisy GT Xu and Jia[30] Average results (PSNR in dB) on 32 images from", "figure_data": "RTF 1GT32.7629.4128.2927.8626.6729.04RTF 2GT33.8129.5227.7627.8426.5228.29RTF 1Noisy GT32.0829.7329.3628.4928.6930.25RTF 2Noisy GT30.5129.0328.7527.5830.3429.56RTF 1Mix of GT & [30]32.9029.9029.3328.6328.1030.30RTF 2Mix of GT & [30]33.9730.4029.7329.1028.0730.84[18]-32.7330.0529.71 628.38--"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Performance gain (PSNR in dB) over the results of Xu and Jia", "figure_data": "Image 1 Image 2 Image 3 Image 4Kernel 1+0.44+0.54+1.05+0.76Kernel 2+0.44+0.27+0.38+0.46Kernel 3+0.02+0.03+0.39\u22120.26Kernel 4+0.31+0.30+0.61+0.27Kernel 5+0.61+0.44+0.64+0.05Kernel 6+0.40+0.41+1.03+0.48Kernel 7+0.24+0.55+0.45+0.31Kernel 8+0.76+0.56+2.17+1.73Kernel 9+0.35\u22120.09+0.02+0.23Kernel 10+0.19\u22120.55+0.25+0.29Kernel 11\u22120.19\u22120.43+0.46+0.09Kernel 12+0.76+0.04+0.66+0.64"}], "formulas": [{"formula_id": "formula_0", "formula_text": "p(x) \u221d j c\u2208C j \u03c1 j (f T j x (c) ).(1)", "formula_coordinates": [2.0, 121.36, 285.16, 175.19, 23.44]}, {"formula_id": "formula_1", "formula_text": "p(x) \u221d z p(x, z) \u221d j c\u2208C j z jc \u03c6 j (f T j x (c) , z jc ).(2)", "formula_coordinates": [2.0, 102.8, 539.18, 193.75, 49.01]}, {"formula_id": "formula_2", "formula_text": "p(x|y, z) \u221d N (y; Kx, \u03c3 2 I) \u2022 N (x; \u03bc x|z , \u03a3 x|z ) \u221d N (x; \u03bc x|y,z , \u03a3 x|y,z ).(3)", "formula_coordinates": [2.0, 331.23, 260.15, 221.64, 30.35]}, {"formula_id": "formula_3", "formula_text": "p(z|x, y) \u221d j c\u2208C j p(z jc |x, y)(4)", "formula_coordinates": [2.0, 372.5, 405.28, 180.36, 21.84]}, {"formula_id": "formula_5", "formula_text": "x (i +1) z (i ) x (i -1)", "formula_coordinates": [3.0, 316.24, 162.63, 236.07, 12.67]}, {"formula_id": "formula_6", "formula_text": "(i +1 ) \u0398 , (i +1 ) \u03b8 x (i -1) x (i ) x (i +1)", "formula_coordinates": [3.0, 315.67, 275.93, 236.03, 13.76]}, {"formula_id": "formula_7", "formula_text": "\u03b8 (i ) (i ) \u0398 , Figure 2. Standard half-quadratic vs. discriminative cascade.", "formula_coordinates": [3.0, 314.63, 275.93, 238.62, 31.2]}, {"formula_id": "formula_8", "formula_text": "p(x|y, K) \u221d p(y|x, K) \u2022 p(x) \u221d N (y; Kx, I/\u03b1) \u2022 N (x; \u0398 \u22121 \u03b8, \u0398 \u22121 ) \u221d N x; (\u03b1K T K) \u22121 \u03b1K T y, (\u03b1K T K) \u22121 \u2022 N (x; \u0398 \u22121 \u03b8, \u0398 \u22121 ) \u221d N x; (\u0398 + \u03b1K T K) \u22121 (\u03b8 + \u03b1K T y), (6) (\u0398 + \u03b1K T K) \u22121 ,", "formula_coordinates": [4.0, 68.97, 445.47, 227.58, 92.79]}, {"formula_id": "formula_9", "formula_text": "p(x|y, K) \u221d N (y; Kx, I/\u03b1) \u2022 J+1 j=1 c\u2208C j \u03c6 j (x (c) , y) (8) \u03c6 j (x (c) , y) \u221d exp \u2212 1 2 x T (c) \u0398 j c (y)x (c) + x T (c) \u03b8 j c (y) ,", "formula_coordinates": [4.0, 322.5, 360.53, 230.64, 60.88]}], "doi": "10.1109/CVPR.2013.84"}