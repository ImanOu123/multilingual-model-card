{"title": "Discrete Chebyshev Classifiers", "authors": "Elad Eban; Amir Globerson", "pub_date": "", "abstract": "In large scale learning problems it is often easy to collect simple statistics of the data, but hard or impractical to store all the original data. A key question in this setting is how to construct classifiers based on such partial information. One traditional approach to the problem has been to use maximum entropy arguments to induce a complete distribution on variables from statistics. However, this approach essentially makes conditional independence assumptions about the distribution, and furthermore does not optimize prediction loss. Here we present a framework for discriminative learning given a set of statistics. Specifically, we address the case where all variables are discrete and we have access to various marginals. Our approach minimizes the worst case hinge loss in this case, which upper bounds the generalization error. We show that for certain sets of statistics the problem is tractable, and in the general case can be approximated using MAP LP relaxations. Empirical results show that the method is competitive with other approaches that use the same input.", "sections": [{"heading": "Introduction", "text": "Many machine learning algorithms operate on labeled datasets where a set of data points x and their labels y are provided. However, it is not always realistic to assume such data can be gathered and stored in this form. For example, in medical informatics we often wish to perform diagnostic prediction based on information about the patients (e.g., results of blood tests, personal history etc). Obtaining complete data instances for this case may be impossible due to privacy concerns. However, it may be easier to obtain Thus, it is of interest to learn classifiers based on partial or aggregated information. Here we focus on the important case where features x 1 , . . . , x n are discrete and categorical. A natural summary statistic in this case is low order marginals such as p(x i , y) or p(x i , x j , y). These can be estimated reliably given small amounts of data. The question is then how to use these to build a classifier of y for a complete instance x 1 , . . . , x n .\nThe challenge in the above scenario is that we only have partial information about the true joint distribution p(x 1 , . . . , x n , y). Namely, its first and second order marginals. A common approach in this case is to assume that the true distribution is the one with maximum entropy subject to these marginal constraints. For first order marginals this results in the popular Naive Bayes classifier, whereas for second order it results in Tree Augmented Naive Bayes (Friedman et al., 1997). However, these approaches do not try to optimize prediction error. They implicitly make conditional independence assumptions about the joint distribution and then use this joint distribution for prediction.\nHere we take a strictly discriminative approach to the above problem. Given a set of observed marginals \u00b5 we consider the set of distributions P(\u00b5) that agree with these marginals. The assumption is that the true distribution is in this set. 1 We want to predict y from x using some classification function.\nOur goal is to find a classifier which has minimal worst case error. The classifier that solves this minimax problem will be robust in the sense that it obtains the best error possible under our uncertainty about the true distribution.\nThe above problem is generally hard to solve (Bertsimas and Sethuraman, 2000). The first difficulty is handling the zero-one loss. Here we use the usual approach of replacing it with a surrogate loss, which we choose to be the hinge loss. We show that this replacement results in a 2-approximation of the zero-one loss (see Section 4). However, the problem still seems daunting to optimize due to the maximization over all possible distributions in P(\u00b5). Surprisingly, we show that this problem is in fact tractable, as long as the set of pairwise variables in the marginals x i , x j correspond to a tree graph. When the graph is not a tree, we show how the commonly used MAP LP relaxation can be employed, resulting in an upper bound on the original minimax problem.\nWe call our approach Discrete Chebyshev Classifier (DCC), since as in Chebyshev bounds, , it considers worst case behavior under first and second order moment constraints. Empirical comparisons to baselines that use the same statistical information demonstrate that DCC are competitive on the majority of datasets considered.", "publication_ref": ["b11", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "The DCC Optimization Problem", "text": "We begin by defining the minimax optimization problem we set out to solve.\nConsider classification problems with n discrete features corresponding to the vector random variable X = [X 1 , . . . , X n ]. Assume that each X i can take d i values so that X i \u2208 {1, . . . , d i }. The set of possible values of X will be denoted by X . Similarly, let the discrete variable Y denote the label of X, and denote the domain of Y by Y.\nOur focus is on predicting Y from X. Typically one considers a parametric form for such predictors. However, at this point we assume that it can be arbitrary. In Section 2.3 we show that the optimal minimax predictor does in fact have a certain parametric form. For now, we assume that the predictor is defined via a function f (x, y) : X , Y \u2192 R where the predicted label is given by:\ny(x; f ) = arg max y f (x, y).\n(1)\nNote that any prediction function can be expressed this way, and thus the learner has full expressive power. It will turn out in Section 2.3 that the optimal function has a simple parametric form, due to the fact that it needs to be minimax optimal.\nFor a given function f and a pair x, y the zero-one loss incurred by predicting y from x using f is:\nzo (f, x, y) = I y = arg max y f (x, y) . (2\n)\nSince this loss is not convex, we switch to a surrogate convex loss. Specifically, we use the multiclass hinge loss (e.g., see Crammer and Singer, 2002) defined as:\nh (f, x, y) = max z\u2208Y f (x, z) \u2212 f (x, y) + I [z = y] . (3)\nGiven that x, y are generated via a distribution p(x, y), the expected loss of f is:\nE p [l(f, x, y)] = x,y p(x, y)l(f, x, y). (4\n)\nAs mentioned earlier, we consider the setting where we are given marginal distributions over pairs of variables X i , X j and the label variable Y . Each such distribution will be denoted by \u00b5 ij (x i , x j , y) in what follows. Furthermore, we assume we have these for a set of pairs E which form a tree. The tree assumption might seem restrictive, and we will remove it in Section 5. Thus, our input is the set \u00b5 of marginals:\n\u00b5 = { \u00b5 ij (x i , x j , y) : (i, j) \u2208 E } .(5)\nDefine P(\u00b5) as the set of all probability distributions over (X, Y ) that agree with the marginals \u00b5. Namely:\nP(\u00b5) = {p \u2208 \u2206 : p(x i , x j , y) = \u00b5 ij (x i , x j , y) \u2200(i, j) \u2208 E}(6)\nwhere p(x i , x j , y) is the marginal distribution of p on the corresponding variables, and \u2206 is the set of valid distributions on X 1 , . . . , X n (i.e., p(x 1 , . . . , x n ) is nonnegative and normalizes to one).", "publication_ref": ["b8"], "figure_ref": [], "table_ref": []}, {"heading": "The Minimax Problem", "text": "We would like to find the optimal classifier f given that the true distribution is in P(\u00b5) (as noted earlier, this can be relaxed by using for instance, box constraints around \u00b5). Since no additional information about the underlying distribution is provided, we consider the worst case error of f with respect to any distribution in P(\u00b5), which is given by:\nWCE(f, \u00b5) = max p\u2208P(\u00b5) E p [ zo (f, x, y)] .(7)\nWCE(f, \u00b5) is a Chebyshev type bound, since out of all probability distributions over (X, Y ) with specific moments \u00b5, it provides the one that maximizes the mass in a particular subset of X (i.e., the x where f errs).\nIt is then natural to seek an f that minimizes WCE(f, \u00b5) specifically, to solve:\nDCC(\u00b5) = min f WCE(f, \u00b5)(8)\nwhere DCC stands for \"Discrete Chebyshev Classifier\". Due to the hardness of optimizing the zero-one loss we consider a variant of the above where the zero-one loss in WCE is replaced with the hinge loss. Namely:\nWCE h (f, \u00b5) = max p\u2208P(\u00b5) y\u2208Y,x\u2208X p(x, y) h (f, x, y) . (9)\nAnd similarly:\nDCC h (\u00b5) = min f WCE h (f, \u00b5). (10\n)\nThis type of relaxation is common and easily yields an upper bound on the original function. Somewhat surprisingly, in Section 4 we show a tighter connection between the problems -DCC h (\u00b5) is a 2-approximation of DCC(\u00b5).\nThe optimization problem DCC h (\u00b5) still seems daunting due to two key difficulties:\n\u2022 The function f is over |X ||Y| variables, which is exponential in n.\n\u2022 The worst case error, WCE h , involves maximization over all distributions p(x, y). Again, these would require |X ||Y| variables to describe.\nIn what follows we show how these difficulties can be overcome via careful analysis of the optimization problem, use of convex duality, and MAP LP relaxations. The main result is Theorem 2.3 where we present a tractable convex optimization problem equivalent to DCC h (\u00b5). Theorem 3.1 then provides an unconstrained formulation of the problem.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Dual of WCE h", "text": "Begin by rewriting WCE h in its dual form. Since WCE h is a linear program (LP) in variables p(x, y), it has a dual LP with the same value. The dual variables in this case are \u03bd ij (x i , x j , y) for all ij \u2208 E and x i , x j , y. Thus, they can be viewed as local functions on pairs of features and y.\nUsing a standard Lagrangian duality transformation we obtain the following dual:\nWCE h (f, \u00b5) = min \u03bd \u03bd \u2022 \u00b5 s.t. \u03bd(x, y) \u2265 h (f, x, y) \u2200x \u2208 X , y \u2208 Y (11\n)\nwhere we use the following notation:\n\u03bd(x, y) = ij\u2208E \u03bd ij (x i , x j , y) \u03bd \u2022 \u00b5 = ij\u2208E,xi,xj \u03bd ij (x i , x j , y)\u00b5 ij (x i , x j , y).\nThe dual in Eq. ( 11) has a nice interpretation. The function \u03bd(x, y) can be thought of as an energy function over x and y which decomposes according to the set of edges E, and constrained to be pointwise greater than the loss l h (f, x, y). Using this observation, and since for any distribution p \u2208 P(\u00b5), E p [\u03bd(x, y)] = \u03bd \u2022\u00b5, it follows that \u03bd \u2022\u00b5 indeed upper bounds the expected hinge loss for any possible \u03bd.\nBy switching to the dual we have not made the problem simpler, since now instead of exponentially many variables as in Eq. ( 7) we have exponentially many constraints. These however can be dealt with efficiently, as we show in Section 2.4. Another advantage is that DCC h now becomes a minimization problem (rather than minmax):\nDCC h (\u00b5) = min f,\u03bd \u03bd \u2022 \u00b5 s.t. \u03bd(x, y) \u2265 h (f, x, y) \u2200x \u2208 X , y \u2208 Y.(12)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Simple Form for the Optimal Classifier", "text": "Here we show that there exists an optimal f * which can be described using much fewer variables. Furthermore, this f * can be determined via the set of dual parameters \u03bd defined earlier.\nTheorem 2.1. The DCC h problem can be expressed as:\nmin \u03bd \u03bd \u2022 \u00b5 s.t. \u03bd(x, z) + \u03bd(x, y) \u2212 2 \u2022 I [y = z] \u2265 0 \u2200 x,y,z .(13)\nProof. We start with the DCC h problem in Eq. (12). Since f does not appear in the objective (only in the constraints), it can be moved to the constraints in the following way:\nDCC h (\u00b5) = min \u03bd \u03bd \u2022 \u00b5 s.t. \u2203f \u2200x, y : \u03bd(x, y) \u2265 h (f, x, y).(14)\nIf we write the constraints explicitly using the hinge loss definition we get that there should exist a f such that:\n\u2200x, y \u03bd(x, y) \u2265 max z f (x, z) \u2212 f (x, y) + I [y = z]\nor equivalently:\n\u2200x, y, z \u03bd(x, y) \u2265 f (x, z) \u2212 f (x, y) + I [y = z] .\nSince each pair y, z appears twice with any given x we regroup the inequalities to get:\n\u03bd(x, y) \u2212 I [y = z] \u2265 f (x, z) \u2212 f (x, y) \u2265 \u2212\u03bd(x, z) + I [y = z] .(15)\nWe claim that for a given \u03bd there exists a function f satisfying the above if and only if:\n\u03bd(x, y)\u2212I [y = z] \u2265 \u2212\u03bd(x, z)+I [y = z] \u2200x, y, z. (16)\nIt is immediate that Eq. (15) implies Eq. (16). To see the converse, we define f (x, y) = \u2212 1 2 \u03bd(x, y) and therefore:\nf (x, z) \u2212 f (x, y) = 1 2 (\u03bd(x, y) \u2212 \u03bd(x, z)) = \u03bd(x,y)\u2212I[y =z]\u2212\u03bd(x,z)+I[y =z] 2 (17)\nwhich is exactly the mid point between the required lower and upper bounds on f (x, z) \u2212 f (x, y) from Eq. (15). This shows the equivalence between the constraints of Eq. (13) and Eq. ( 14), and hence the equivalence between the problems.\nThe above theorem directly implies that the form of the optimal f * is given by the following corollary.\nCorollary 2.2. Denote by \u03bd * the minimizer of Eq. ( 13), the DCC h classifier f * (from Eq. ( 10)) is given by: 18)\nf * (x, y) = \u2212 1 2 \u03bd(x, y) = \u2212 1 2 ij\u2208E \u03bd * ij (x i , x j , y). (", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Efficient DCC Optimization", "text": "In order to be able to solve the DCC h problem as formulated in Eq. ( 13), one must still deal with the exponential number of constraints. Define:\nh \u03bd (x, y, z) = \u03bd(x, z) + \u03bd(x, y) \u2212 2 \u2022 I [y = z] .\nThen the constraint of Eq. ( 13) can be written as:\nmin x,y,z h \u03bd (x, y, z) \u2265 0. (19\n)\nThe key property to note is that the function h decomposes as a sum over factors depending on (x i , x j , y, z) and (y, z). In other words, it can be viewed as an energy function of a graphical model with these hyper edges. The complexity of checking the constraints is thus equivalent to the complexity of calculating the MAP assignment of the corresponding model.\nIf the edges ij \u2208 E are arbitrary, the above problem is as hard as general MAP problems (NP hard). However, since we assumed that E is tree structured, the graphical model corresponding to h has tree width of 3 and can be minimized efficiently (e.g., using the junction tree algorithm. See Koller and Friedman, 2009).\nAt this point we have shown that for a given \u03bd, the feasibility of the DCC h constraints in Eq. ( 19) can be checked efficiently. Thus, the DCC h problem is in fact polynomial time tractable since one can use methods such as ellipsoid or cutting plane (Bertsekas, 1995). While we could theoretically solve the problem this way, these methods do not scale well. We thus turn to further simplify the problem.\nA different way to solve Eq. ( 19) is to realize that it can be expressed as a linear program. There is a rich body of work on LP relaxations for the MAP problem, and their various relaxations (e.g., see Wainwright and Jordan, 2003;Werner, 1993;Globerson and Jaakkola, 2008;Sontag et al., 2011). In our case, such an LP would have as variables the following fourth and second order distributions \u03b1 ij (x i , x j , y, z) and \u03c4 (y, z), and the constraints would be that these distributions agree on the variables in their overlap. It is easy to see that constructing this LP in the standard way will result in the exact MAP since these are the cliques in the junction tree of the model.\nWe can now take the dual of the above MAP LP. The dual variables in this case will be denoted by \u03b4 ij (x j ) and \u03b3 ij (y, z). The dual objective g \u03bd (\u03b4, \u03b3) is given by:\ng \u03bd (\u03b4, \u03b3) = max \u03b4,\u03b3 ij min xi,xj y,z {\u03bd ij (x i , x j , y) + \u03bd ij (x i , x j , z) \u2212\u03b4 ij (x j , y, z) \u2212 \u03b4 ji (x i , y, z) \u2212 \u03b3 ij (y, z)} + i min xi,y,z \uf8f1 \uf8f2 \uf8f3 j\u2208N (i) \u03b4 ji (x i , y, z) \uf8fc \uf8fd \uf8fe + min y,z \uf8f1 \uf8f2 \uf8f3 \u22122 \u2022 I [y = z] + ij\u2208E \u03b3 ij (y, z) \uf8fc \uf8fd \uf8fe (20)\nFrom strong duality we then have:\nmin x,y,z h \u03bd (x, y, z) = max \u03b4,\u03b3 g \u03bd (\u03b4, \u03b3). (21\n)\nFinally, by plugging the dual into Eq. ( 13) we have that DCC can be expressed as an optimization problem with polynomially many constraints and variables, as stated below.\nTheorem 2.3. The DCC h problem is equivalent to:\nmin \u03bd,\u03b4,\u03b3 \u03bd \u2022 \u00b5 s.t. g \u03bd (\u03b4, \u03b3) \u2265 0. (22\n)\nProof. After substituting Eq. (21) into Eq. (13) we get:\nmin \u03bd \u03bd \u2022 \u00b5 s.t. max \u03b4,\u03b3 g \u03bd (\u03b4, \u03b3) \u2265 0. (23\n)\nNow we only need to notice that \u03b4, \u03b3 can be maximized over outside the constraints, since it suffices to find a single assignment to those such that g \u03bd (\u03b4, \u03b3) \u2265 0 for the constraint to hold. The result follows.\nThe above problem has polynomially many constraints and variables, and is convex. Thus it can be solved using generic convex optimization tools. However, solving this problem with off-the-shelf optimization methods does not scale well. Next, we derive an unconstrained version of the problem which can be solved by scalable accelerated methods.", "publication_ref": ["b16", "b3", "b26", "b27", "b12", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Unconstrained Optimization of DCC h", "text": "Here we provide another equivalent form of DCC h but one which is unconstrained, and can thus be solved using scalable accelerated methods, such as FISTA (Beck and Teboulle, 2009). The unconstrained problem is presented in the following result.\nTheorem 3.1. The following unconstrained problem is equivalent to DCC h :\nmin \u03bd,\u03b4,\u03b3 \u03bd \u2022 \u00b5 \u2212 1 2 max \u03b4,\u03b3 g \u03bd (\u03b4, \u03b3). (24\n)\nProof. We start by writing the Lagrangian of DCC h in Eq. ( 13) :\nL(\u03bb, \u03bd) = \u03bd \u2022 \u00b5 \u2212 \u03bb min x\u2208X z,y\u2208Y h \u03bd (x, y, z) . (25\n)\nDenote by \u03bd \u03c9 the uniform assignment to the \u03bd variables (i.e., all \u03bd ij (x i , x j , y) = \u03c9). Then some algebra gives\nL(\u03bb, \u03bd \u03c9 ) = \u03c9|E|(1 \u2212 2\u03bb) + 2\u03bb(26)\ntherefore we have: 27) which is clearly equal to \u2212\u221e for \u03bb = 1 2 . We conclude that the optimal \u03bb value is 1 2 and the result follows from the fact we can replace h with g.\nDCC(\u00b5) \u2264 max \u03bb min \u03c9 \u03c9|E|(1 \u2212 2\u03bb) + 2\u03bb(\nTo run FISTA (Beck and Teboulle, 2009) on Eq. ( 24) we can smooth it using Nesterov's smoothing approach (Nesterov, 2005) and then apply FISTA since the gradients are easy to compute.", "publication_ref": ["b0", "b0", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "A 2-Approximation of DCC", "text": "The hinge loss is commonly used as a convex upper bound surrogate for the zero-one loss. However, in the general case no further approximation guarantees can be provided. For the DCC problem it in fact turns out that replacing zeroone loss with hinge loss results in a factor 2 approximation, as stated next. Proof. The upper bound follows from the fact that hinge loss upper bounds the zero-one loss. To show the lower bound, begin by applying the Sion Minimax Theorem (Sion, 1957) to the definition of DCC h (using the convexity of the hinge loss wrt f , and linearity wrt to p):\nmin f max p\u2208P(\u00b5) E p [ h (f, x, y)] = max p\u2208P(\u00b5) min f E p [ h (f, x, y)] .\n(28) For any p, it holds that: 2\nmin f E p [ h (f, x, y)] \u2264 min f : f (x,y)\u2208{0,1} E p [ h (f, x, y)] .\n(29) For predictor functions f with outputs in {0, 1} the hinge loss is always exactly twice the error probability. Therefore, as claimed:\nDCC h (\u00b5) \u2264 2 max p\u2208P(\u00b5) min f E p [ zo (f, x, y)] \u2264 2DCC(\u00b5).\nWhere the second inequality follows from weak min-max bounds.", "publication_ref": ["b23"], "figure_ref": [], "table_ref": []}, {"heading": "Relaxing the Tree Assumption", "text": "Thus far we assumed that the set of observed marginals correspond to a tree graph. This resulted in a tractable form for the DCC h problem. However, the tree assumption may be too restrictive in many cases, both because there is often no natural tree structure, and because learning the optimal tree (as in the Chow Liu procedure used in TAN) seems hard for our objective. Finally, the tree assumption limits the number of statistics we can consider to n \u2212 1.\nFortunately, the MAP LP relaxation approach used for handling the constraint Eq. (19) in Section 2.4 can easily be generalized to non-tree graphs. In fact, it is one of the most common approximation methods for MAP inference in general graphs (e.g., see Komodakis et al., 2011). Thus, if E is not a tree graph, we basically employ exactly the same procedure as described above. The only difference from the tree case is that Eq. (22) will no longer be equal to the original DCC h but instead it will upper bound it. 3 In our experiments we tried both the tree approach and the general graph approach. See Section 8 for further details.", "publication_ref": ["b17"], "figure_ref": [], "table_ref": []}, {"heading": "Other Applications", "text": "The DCC framework can be applied to other machine learning settings. In what follows we consider four different scenarios of interest.\nConditional DCC: In some settings it is of interest to consider errors conditioned on Y , as in type I and II errors in hypothesis testing. A minimax approach in this setting was described in Lanckriet et al. (2003) for second order moments on continuous variables. DCC can easily be extended to this setting, resulting in similar optimization problems to those derived here.\nSemi-Supervised DCC: In many real world applications it is easy to collect a large volume of unlabeled data, but labeled data is harder to obtain. In this context DCC can naturally be extended by assuming statistics only on the variables x. For example, assume we only have enough labeled data to estimate \u00b5 i (x i , y) (but not enough for \u00b5 ij (x i , x j , y) marginals). However, we may easily estimate marginals such as \u00b5 ij (x i , x j ) from unlabeled data. Using our framework it is straightforward to formulate a WCE problem for this set of marginals. It is expected to considerably restrict the set of distributions which we maximize over, and thus make the minimax setting less conservative.\nDiscrete Chebyshev Bounds: The Chebyshev bound, or Chebyshev inequality is a simple yet extremely useful theorem in probability: For any real random variable, X, with expectation \u00b5 and finite non-zero variance \u03c3 2 , and for any > 0.\nP [(|X \u2212 \u00b5| \u2265 )] \u2264 \u03c3 2 2 .\nMany generalizations of these inequalities are known (e.g., Marshall and Olkin, 1960;Bertsimas and Popescu, 2005;Vandenberghe et al., 2007). However, they all deal with continuous distributions.\nWe define the Discrete Chebyshev inequality in a similar way: Given a set of marginals over X , and a function f : X \u2192 R we wish to bound the following probability:\nmax p\u2208P(\u00b5) P p [f (x) \u2265 0] .(30)\nUsing the same line of reasoning that we used to simplify WCE we can bound the above probability by\nmin \u03bd \u03bd \u2022 \u00b5 s.t. ij \u03bd ij (x i , x j ) \u2265 max{0, 1 + f (x)} (31)\nwhich can be computed if f decomposes.\nWCE as a Regularizer: Since WCE h (f, \u00b5) is a bound on generalization performance of the predictor f , it makes sense to use it as a regularizer. Given a dataset with several fully observed examples as well as only statistics \u00b5 for the entire data, we may optimize an objective that is a sum of a hinge loss on the labeled examples and WCE h (f, \u00b5). This will combine two different estimates of generalization error, thus effectively leveraging the two data sources.", "publication_ref": ["b18", "b20", "b4", "b25"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "The idea of using expected values is common in generative models for prediction, but has seen much fewer applications in discriminative approaches. One exception is the Minimax Probabilistic Machine (MPM) (Lanckriet et al., 2003) which solves a robust classification problem for the case of first and second order moments. The derivation in (Lanckriet et al., 2003) relies on Chebyshev type bounds that upper bound the probabilities of certain events subject to constraints (e.g., see Vandenberghe et al., 2007). However, these apply to continuous spaces, as opposed to the discrete case we consider here. Indeed, a key contribution of the current paper is to consider such bounds and their approximation for discrete graphical models.\nInformation theoretic measures such as entropy and mutual information have also been used in the context of learning with partial information. As mentioned earlier, maximum entropy is a classic approach to the problem. Interestingly, it may also be interpreted as minimax optimal but under a different (non-discriminative) loss function (Gr\u00fcnwald and Dawid, 2004). Another related approach is the minimum mutual information (MinMI) method (Globerson and Tishby, 2004). It minimizes I(X; Y ) under marginal constraints as we have here, but is hard to compute even for the case of singleton marginals.\nThe notion of statistical queries (Kearns, 1998) is also related to our setting. However, in these works the queries used by the learner are chosen from a much larger family than what we use. This is also true for the more restricted correlational queries (Bshouty and Feldman, 2002) where one receives expected values E p [f (X 1 , . . . , X n )Y ] and f can be any function. This setting is thus still considerably less constrained than ours.\nThere are also minimax approaches which do not consider expected values, but rather seek minimax robustness with respect to perturbations of data points. For example, one may want to minimize prediction error subject to a data point being allowed to move within some prescribed radius. Such settings have been studied for different perturbations, often resulting in SVM like optimization methods (e.g., see Xu et al., 2009;Livni et al., 2012). Note that these approaches however require the full dataset and thus do not operate in our restricted input setting.\nFinally, robust optimization approaches are quite common in both optimization (Ben-Tal and Nemirovski, 1998) and statistics (Berger, 1985) but in a context different from what is considered here.", "publication_ref": ["b18", "b18", "b25", "b14", "b13", "b15", "b6", "b28", "b19", "b1", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "Here we evaluate our method and other baselines on both synthetic and real world datasets.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Toy Problem", "text": "We first provide a scenario where generative methods fail and DCC succeeds. We considered two generative (maximum entropy based) baselines: Naive Bayes (NB) and Tree Augmented Naive Bayes (TAN) (Friedman et al., 1997). The data was generated such that it will violate the conditional independence assumptions of both the NB and TAN approaches. We used a distribution over a label y and n = 2k + 11 binary variables. The distribution corresponds to the Bayesian network shown in Figure 1a, with parameters defined as follows:\n\u2022 p(Y = 1) = 1 2\n\u2022 p(S = Y ) = 0.9, so that S, Y are strongly correlated.\n\u2022 p(W i = Y ) = 0.6, so that W i , Y are weakly correlated.\n\u2022 C i = W 1 i.e. the C i 's are identical to W 1\n\u2022 D i = W ji1 \u2295W ji2 i.e. D i is determined by its parents.\nEach D i has a randomly chosen pair of parents.\nThe features x are all the 2k +11 non-label variables. It can be seen that they do not satisfy the conditional assumption of either NB or TAN. Each synthetic trial contained 5,000 examples divided equally between train and test sets. The results reported are the average over 10 random generations of the data. Figure 1b shows the average classification error of the different algorithms for different numbers of variables. As the number of variables increases, the advantage of DCC over NB and TAN is apparent. This experiment illustrates the poor performance of models with implicit assumptions when the assumptions do not hold.", "publication_ref": ["b11"], "figure_ref": ["fig_1", "fig_1"], "table_ref": []}, {"heading": "Comparing Marginal Based Learners", "text": "We tested the DCC classifier scheme on 12 classification datasets from the UCI repository, nine of them are binary and the other three are multiclass classification tasks. In several datasets there are continuous features, in these cases we used only the discrete features (this follows the setup and datasets used in Globerson and Tishby, 2004). The input to the algorithms was marginals of the form \u00b5 ij (x i , x j , y) for all possible pairs of features; the marginals were computed from a train set, and the performance of the resulting classifier was evaluated on a test set. The error rates reported in Table 1 are the average of 5 partitions into train and test sets.\nThe error rate of DCC was compared to three baseline algorithms which take marginal distributions as inputs: NB, TAN, and Minimax Probabilistic Machine (MPM) (Lanckriet et al., 2003 MPM assumes the underlying distribution is continuous.\nIn addition to the vanilla version of DCC we also examined a greedy algorithm which we denote gDCC. This greedy version starts with an empty set of edges E and at each step adds the edge which minimizes the DCC error bound until a spanning tree structure is reached.\nIn Table 1 the error rates of the compared algorithms are presented. The best performing algorithm on each dataset is shown in boldface. As can be seen, our approaches (either DCC or gDCC) outperform the competing algorithms on 10 out of 12 datasets. To conclude, our approach achieves better or comparable performance on most datasets examined.", "publication_ref": ["b13", "b18"], "figure_ref": [], "table_ref": ["tab_0", "tab_0"]}, {"heading": "Learning with Missing Features", "text": "One of the motivations of DCC is to learn in scenarios where not all features are available, but pairwise statistics can be estimated. Here we simulate this setting by repeating the experiments in the previous section while \"hiding\" 25% of the features of each train example. The following baselines are used for comparison:\n\u2022 Replacing each missing feature with its mean in the training data (i.e., imputation) and running SVM on the resulting full observations.\n\u2022 Chechik et al. (2008) propose a variant of SVM for learning with missing features, by an appropriate rescaling of the margin. Their algorithms have two versions: avg-w and geom, both of which are evaluated here.\n\u2022 Running DCC on the set of single and pairwise statistics collected from the data. Since these may  not be consistent (e.g., \u00b5(x 1 |y) might be different when marginalizing \u00b5(x 1 , x 2 |y) and \u00b5(x 1 , x 3 |y)) we project those on the pairwise consistency constraints (also known as the local polytope). We use 1 as the projection metric. 4 Results are shown in Table 2. It can be seen that DCC outperforms the other methods on the majority of the datasets.\nW 1 W 2 W 10 C 1 C k D k D 1 Y S", "publication_ref": ["b7"], "figure_ref": [], "table_ref": ["tab_1"]}, {"heading": "Discussion", "text": "The DCC approach is motivated by learning settings where complete observations are unavailable. Instead, access to certain statistics of the data is provided. A minimax approach is very natural in this setting, and yields the DCC objective. A well known limitation of minimax methods is that they assume a worst case adversary and may thus learn classifiers that are suboptimal for the true distributions that generated the data. To alleviate this shortcoming, one must impose additional constraints on the adversaries.\n4 See Ravikumar et al. (2010) for other projection schemes.\nThe DCC approach takes a large step in this direction by limiting the support of the adversarial distribution to only integral assignments. This is in contrast to methods like MPM where the adversarial distribution has unconstrained support on the reals. Indeed, our experiments show that DCC outperforms MPM in the majority of the cases, presumably because of our less pessimistic approach.\nHere we considered a deterministic classifier which always returns the same y for a given x. However, in the minimax setting the optimal strategy is actually stochastic. It would thus be interesting to study the stochastic variant of the DCC problem. Another advantage of the stochastic case is that the zero one loss is linear in the classifier distribution, possibly leading to efficient algorithms.\nThe DCC approach has several natural and interesting extensions. For example, we alluded to the possibility of using it in a semi supervised manner. Another exciting extension is to the structured output prediction setting.\nConsider for example a part of speech tagging problem, and assume we have access to the statistics of consecutive parts of speech, and those of words and their part of speech. How can these be combined to build discriminative minimax structured output predictors?\nFinally, we would like to consider other forms of robust prediction losses. As an example, consider minimizing the regret of the classifier (e.g., see Eldar et al., 2004) rather than its worst case loss. This will effectively reduce the strength of the minimax adversary and may result in improved performance. However, it remains to be seen whether it can be solved efficiently as in the minimax case considered here.", "publication_ref": ["b22", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Acknowledgments: We thank Shai Shalev-Shwartz, Roi Livni and Yoav Wald for fruitful comments and discussions. This research is funded by the ISF Centers of Excellence grant 1789/11. Elad Eban was partially funded by an IBM PhD fellowship.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "A fast iterative shrinkagethresholding algorithm for linear inverse problems", "journal": "SIAM Journal on Imaging Sciences", "year": "2009", "authors": "A Beck; M Teboulle"}, {"ref_id": "b1", "title": "Robust convex optimization", "journal": "Math. Oper. Res", "year": "1998", "authors": "A Ben-Tal; A Nemirovski"}, {"ref_id": "b2", "title": "Statistical Decision Theory and Bayesian Analysis", "journal": "Springer", "year": "1985", "authors": "J Berger"}, {"ref_id": "b3", "title": "Nonlinear Programming", "journal": "Athena Scientific", "year": "1995", "authors": "D P Bertsekas"}, {"ref_id": "b4", "title": "Optimal inequalities in probability theory: A convex optimization approach", "journal": "SIAM Journal on Optimization", "year": "2005", "authors": "D Bertsimas; I Popescu"}, {"ref_id": "b5", "title": "Moment problems and semidefinite optimization", "journal": "Springer", "year": "2000", "authors": "D Bertsimas; J Sethuraman"}, {"ref_id": "b6", "title": "On using extended statistical queries to avoid membership queries", "journal": "JMLR", "year": "2002", "authors": "N H Bshouty; V Feldman"}, {"ref_id": "b7", "title": "Max-margin classification of data with absent features", "journal": "JMLR", "year": "2008", "authors": "G Chechik; G Heitz; G Elidan; P Abbeel; D Koller"}, {"ref_id": "b8", "title": "On the algorithmic implementation of multiclass kernel-based vector machines", "journal": "JMLR", "year": "2002", "authors": "K Crammer; Y Singer"}, {"ref_id": "b9", "title": "Maximum entropy density estimation with generalized regularization and an application to species distribution modeling", "journal": "JMLR", "year": "2007", "authors": "M Dud\u00edk; S J Phillips; R E Schapire"}, {"ref_id": "b10", "title": "Linear minimax regret estimation of deterministic parameters with bounded data uncertainties. Signal Processing", "journal": "IEEE Trans. on", "year": "2004", "authors": "Y C Eldar; A Ben-Tal; A Nemirovski"}, {"ref_id": "b11", "title": "Bayesian network classifiers", "journal": "Machine learning", "year": "1997", "authors": "N Friedman; D Geiger; M Goldszmidt"}, {"ref_id": "b12", "title": "Fixing max-product: Convergent message passing algorithms for MAP LPrelaxations", "journal": "MIT Press", "year": "2008", "authors": "A Globerson; T Jaakkola"}, {"ref_id": "b13", "title": "The minimum information principle in discriminative learning", "journal": "", "year": "2004", "authors": "A Globerson; N Tishby"}, {"ref_id": "b14", "title": "Game theory, maximum entropy, minimum discrepancy and robust bayesian decision theory", "journal": "Annals of Statistics", "year": "2004", "authors": "P D Gr\u00fcnwald; A P Dawid"}, {"ref_id": "b15", "title": "Efficient noise-tolerant learning from statistical queries", "journal": "Journal of the ACM", "year": "1998", "authors": "M Kearns"}, {"ref_id": "b16", "title": "Probabilistic Graphical Models: Principles and Techniques", "journal": "MIT Press", "year": "2009", "authors": "D Koller; N Friedman"}, {"ref_id": "b17", "title": "MRF energy minimization and beyond via dual decomposition. Pattern Analysis and Machine Intelligence", "journal": "IEEE Transactions on", "year": "2011", "authors": "N Komodakis; N Paragios; G Tziritas"}, {"ref_id": "b18", "title": "A robust minimax approach to classification", "journal": "JMLR", "year": "2003", "authors": "G R Lanckriet; L E Ghaoui; C Bhattacharyya; M I Jordan"}, {"ref_id": "b19", "title": "A simple geometric interpretation of svm using stochastic adversaries", "journal": "", "year": "2012", "authors": "R Livni; K Crammer; A Globerson"}, {"ref_id": "b20", "title": "Multivariate Chebyshev inequalities", "journal": "The Annals of Mathematical Statistics", "year": "1960", "authors": "A W Marshall; I Olkin"}, {"ref_id": "b21", "title": "Smooth minimization of non-smooth functions", "journal": "Math. Prog", "year": "2005", "authors": "Y Nesterov"}, {"ref_id": "b22", "title": "Message-passing for graph-structured linear programs: Proximal methods and rounding schemes", "journal": "JMLR", "year": "2010", "authors": "P Ravikumar; A Agarwal; M J Wainwright"}, {"ref_id": "b23", "title": "General Minimax Theorems. United States Air Force", "journal": "Office of Scientific Research", "year": "1957", "authors": "M Sion"}, {"ref_id": "b24", "title": "Introduction to dual decomposition for inference", "journal": "MIT Press", "year": "2011", "authors": "D Sontag; A Globerson; T Jaakkola"}, {"ref_id": "b25", "title": "Generalized chebyshev bounds via semidefinite programming", "journal": "SIAM Rev", "year": "2007", "authors": "L Vandenberghe; S Boyd; K Comanor"}, {"ref_id": "b26", "title": "Graphical models, exponential families and variational inference", "journal": "", "year": "2003", "authors": "M Wainwright; M Jordan"}, {"ref_id": "b27", "title": "A linear programming approach to max-sum problem: A review", "journal": "IEEE Trans. on Pattern Analysis and Machine Intelligence", "year": "1993", "authors": "T Werner"}, {"ref_id": "b28", "title": "Robustness and regularization of support vector machines", "journal": "JMLR", "year": "2009", "authors": "H Xu; C Caramanis; S Mannor"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Lemma 4.1. 1 2 DCC h (\u00b5) \u2264 DCC(\u00b5) \u2264 DCC h (\u00b5).", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 1 .1Figure 1. Evaluation over synthetic data. (a) The Bayesian network from which the data was drawn. (b) Error rate of competing algorithms as a function of the number of variables. NB: green circles, TAN: blue squares, DCC: red triangles.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Performance (in % error) on test data for real-world discrete classification datasets.", "figure_data": "). MPM minimizes an objectivefunction similar to DCC, with the crucial difference that"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Performance (in % error) on noisy data, 25% of training features where erased. Only datasets with noticeable difference between algorithms are presented. avg-w, geom are the algorithms fromChechik et al. (2008), to run SVM we filled the missing values with the mean value of the feature.", "figure_data": "DatasetDCC avg-w geom SVMbcd27293031credit15161919heart-disease27252020hepatitis19232922kr-vs-kp10131313lymphography22212618promoters12131312votes4977Best Performance6013"}], "formulas": [{"formula_id": "formula_0", "formula_text": "y(x; f ) = arg max y f (x, y).", "formula_coordinates": [2.0, 117.07, 570.45, 110.75, 15.19]}, {"formula_id": "formula_1", "formula_text": "zo (f, x, y) = I y = arg max y f (x, y) . (2", "formula_coordinates": [2.0, 93.68, 703.11, 191.89, 15.63]}, {"formula_id": "formula_2", "formula_text": ")", "formula_coordinates": [2.0, 285.57, 704.09, 3.87, 8.64]}, {"formula_id": "formula_3", "formula_text": "h (f, x, y) = max z\u2208Y f (x, z) \u2212 f (x, y) + I [z = y] . (3)", "formula_coordinates": [2.0, 322.54, 114.09, 218.9, 15.64]}, {"formula_id": "formula_4", "formula_text": "E p [l(f, x, y)] = x,y p(x, y)l(f, x, y). (4", "formula_coordinates": [2.0, 348.47, 173.59, 189.1, 20.28]}, {"formula_id": "formula_5", "formula_text": ")", "formula_coordinates": [2.0, 537.57, 174.57, 3.87, 8.64]}, {"formula_id": "formula_6", "formula_text": "\u00b5 = { \u00b5 ij (x i , x j , y) : (i, j) \u2208 E } .(5)", "formula_coordinates": [2.0, 353.61, 308.18, 187.83, 10.71]}, {"formula_id": "formula_7", "formula_text": "P(\u00b5) = {p \u2208 \u2206 : p(x i , x j , y) = \u00b5 ij (x i , x j , y) \u2200(i, j) \u2208 E}(6)", "formula_coordinates": [2.0, 307.44, 367.38, 241.06, 21.58]}, {"formula_id": "formula_8", "formula_text": "WCE(f, \u00b5) = max p\u2208P(\u00b5) E p [ zo (f, x, y)] .(7)", "formula_coordinates": [2.0, 346.31, 554.63, 195.13, 16.11]}, {"formula_id": "formula_9", "formula_text": "DCC(\u00b5) = min f WCE(f, \u00b5)(8)", "formula_coordinates": [2.0, 369.13, 670.3, 172.31, 15.72]}, {"formula_id": "formula_10", "formula_text": "WCE h (f, \u00b5) = max p\u2208P(\u00b5) y\u2208Y,x\u2208X p(x, y) h (f, x, y) . (9)", "formula_coordinates": [3.0, 63.52, 102.93, 225.92, 21.12]}, {"formula_id": "formula_11", "formula_text": "DCC h (\u00b5) = min f WCE h (f, \u00b5). (10", "formula_coordinates": [3.0, 110.58, 152.55, 174.71, 15.72]}, {"formula_id": "formula_12", "formula_text": ")", "formula_coordinates": [3.0, 285.29, 153.53, 4.15, 8.64]}, {"formula_id": "formula_13", "formula_text": "WCE h (f, \u00b5) = min \u03bd \u03bd \u2022 \u00b5 s.t. \u03bd(x, y) \u2265 h (f, x, y) \u2200x \u2208 X , y \u2208 Y (11", "formula_coordinates": [3.0, 60.45, 570.55, 224.85, 30.04]}, {"formula_id": "formula_14", "formula_text": ")", "formula_coordinates": [3.0, 285.29, 581.3, 4.15, 8.64]}, {"formula_id": "formula_15", "formula_text": "\u03bd(x, y) = ij\u2208E \u03bd ij (x i , x j , y) \u03bd \u2022 \u00b5 = ij\u2208E,xi,xj \u03bd ij (x i , x j , y)\u00b5 ij (x i , x j , y).", "formula_coordinates": [3.0, 77.02, 630.49, 190.84, 49.82]}, {"formula_id": "formula_16", "formula_text": "DCC h (\u00b5) = min f,\u03bd \u03bd \u2022 \u00b5 s.t. \u03bd(x, y) \u2265 h (f, x, y) \u2200x \u2208 X , y \u2208 Y.(12)", "formula_coordinates": [3.0, 317.79, 216.45, 223.65, 43.78]}, {"formula_id": "formula_17", "formula_text": "min \u03bd \u03bd \u2022 \u00b5 s.t. \u03bd(x, z) + \u03bd(x, y) \u2212 2 \u2022 I [y = z] \u2265 0 \u2200 x,y,z .(13)", "formula_coordinates": [3.0, 319.29, 369.57, 222.15, 32.96]}, {"formula_id": "formula_18", "formula_text": "DCC h (\u00b5) = min \u03bd \u03bd \u2022 \u00b5 s.t. \u2203f \u2200x, y : \u03bd(x, y) \u2265 h (f, x, y).(14)", "formula_coordinates": [3.0, 330.64, 463.08, 210.81, 22.66]}, {"formula_id": "formula_19", "formula_text": "\u2200x, y \u03bd(x, y) \u2265 max z f (x, z) \u2212 f (x, y) + I [y = z]", "formula_coordinates": [3.0, 317.6, 530.01, 213.68, 15.19]}, {"formula_id": "formula_20", "formula_text": "\u2200x, y, z \u03bd(x, y) \u2265 f (x, z) \u2212 f (x, y) + I [y = z] .", "formula_coordinates": [3.0, 320.74, 576.43, 207.41, 9.96]}, {"formula_id": "formula_21", "formula_text": "\u03bd(x, y) \u2212 I [y = z] \u2265 f (x, z) \u2212 f (x, y) \u2265 \u2212\u03bd(x, z) + I [y = z] .(15)", "formula_coordinates": [3.0, 325.35, 631.56, 216.09, 24.91]}, {"formula_id": "formula_22", "formula_text": "\u03bd(x, y)\u2212I [y = z] \u2265 \u2212\u03bd(x, z)+I [y = z] \u2200x, y, z. (16)", "formula_coordinates": [3.0, 312.42, 707.59, 229.02, 9.96]}, {"formula_id": "formula_23", "formula_text": "f (x, z) \u2212 f (x, y) = 1 2 (\u03bd(x, y) \u2212 \u03bd(x, z)) = \u03bd(x,y)\u2212I[y =z]\u2212\u03bd(x,z)+I[y =z] 2 (17)", "formula_coordinates": [4.0, 65.63, 102.16, 223.81, 31.97]}, {"formula_id": "formula_24", "formula_text": "f * (x, y) = \u2212 1 2 \u03bd(x, y) = \u2212 1 2 ij\u2208E \u03bd * ij (x i , x j , y). (", "formula_coordinates": [4.0, 65.78, 280.27, 211.21, 27.19]}, {"formula_id": "formula_25", "formula_text": "h \u03bd (x, y, z) = \u03bd(x, z) + \u03bd(x, y) \u2212 2 \u2022 I [y = z] .", "formula_coordinates": [4.0, 76.08, 387.93, 192.72, 10.71]}, {"formula_id": "formula_26", "formula_text": "min x,y,z h \u03bd (x, y, z) \u2265 0. (19", "formula_coordinates": [4.0, 130.33, 430.8, 154.97, 14.8]}, {"formula_id": "formula_27", "formula_text": ")", "formula_coordinates": [4.0, 285.29, 431.79, 4.15, 8.64]}, {"formula_id": "formula_28", "formula_text": "g \u03bd (\u03b4, \u03b3) = max \u03b4,\u03b3 ij min xi,xj y,z {\u03bd ij (x i , x j , y) + \u03bd ij (x i , x j , z) \u2212\u03b4 ij (x j , y, z) \u2212 \u03b4 ji (x i , y, z) \u2212 \u03b3 ij (y, z)} + i min xi,y,z \uf8f1 \uf8f2 \uf8f3 j\u2208N (i) \u03b4 ji (x i , y, z) \uf8fc \uf8fd \uf8fe + min y,z \uf8f1 \uf8f2 \uf8f3 \u22122 \u2022 I [y = z] + ij\u2208E \u03b3 ij (y, z) \uf8fc \uf8fd \uf8fe (20)", "formula_coordinates": [4.0, 312.55, 267.39, 228.89, 128.74]}, {"formula_id": "formula_29", "formula_text": "min x,y,z h \u03bd (x, y, z) = max \u03b4,\u03b3 g \u03bd (\u03b4, \u03b3). (21", "formula_coordinates": [4.0, 358.79, 436.18, 178.5, 15.72]}, {"formula_id": "formula_30", "formula_text": ")", "formula_coordinates": [4.0, 537.29, 437.16, 4.15, 8.64]}, {"formula_id": "formula_31", "formula_text": "min \u03bd,\u03b4,\u03b3 \u03bd \u2022 \u00b5 s.t. g \u03bd (\u03b4, \u03b3) \u2265 0. (22", "formula_coordinates": [4.0, 384.61, 536.52, 152.68, 27.93]}, {"formula_id": "formula_32", "formula_text": ")", "formula_coordinates": [4.0, 537.29, 546.22, 4.15, 8.64]}, {"formula_id": "formula_33", "formula_text": "min \u03bd \u03bd \u2022 \u00b5 s.t. max \u03b4,\u03b3 g \u03bd (\u03b4, \u03b3) \u2265 0. (23", "formula_coordinates": [4.0, 366.68, 600.51, 170.62, 22.66]}, {"formula_id": "formula_34", "formula_text": ")", "formula_coordinates": [4.0, 537.29, 607.58, 4.15, 8.64]}, {"formula_id": "formula_35", "formula_text": "min \u03bd,\u03b4,\u03b3 \u03bd \u2022 \u00b5 \u2212 1 2 max \u03b4,\u03b3 g \u03bd (\u03b4, \u03b3). (24", "formula_coordinates": [5.0, 116.31, 260.53, 168.98, 17.4]}, {"formula_id": "formula_36", "formula_text": ")", "formula_coordinates": [5.0, 285.29, 263.2, 4.15, 8.64]}, {"formula_id": "formula_37", "formula_text": "L(\u03bb, \u03bd) = \u03bd \u2022 \u00b5 \u2212 \u03bb min x\u2208X z,y\u2208Y h \u03bd (x, y, z) . (25", "formula_coordinates": [5.0, 71.48, 330.78, 213.81, 15.64]}, {"formula_id": "formula_38", "formula_text": ")", "formula_coordinates": [5.0, 285.29, 331.76, 4.15, 8.64]}, {"formula_id": "formula_39", "formula_text": "L(\u03bb, \u03bd \u03c9 ) = \u03c9|E|(1 \u2212 2\u03bb) + 2\u03bb(26)", "formula_coordinates": [5.0, 108.41, 390.3, 181.03, 11.83]}, {"formula_id": "formula_40", "formula_text": "DCC(\u00b5) \u2264 max \u03bb min \u03c9 \u03c9|E|(1 \u2212 2\u03bb) + 2\u03bb(", "formula_coordinates": [5.0, 90.54, 442.02, 186.46, 15.72]}, {"formula_id": "formula_41", "formula_text": "min f max p\u2208P(\u00b5) E p [ h (f, x, y)] = max p\u2208P(\u00b5) min f E p [ h (f, x, y)] .", "formula_coordinates": [5.0, 307.84, 116.31, 233.2, 16.11]}, {"formula_id": "formula_42", "formula_text": "min f E p [ h (f, x, y)] \u2264 min f : f (x,y)\u2208{0,1} E p [ h (f, x, y)] .", "formula_coordinates": [5.0, 316.91, 168.54, 215.07, 16.1]}, {"formula_id": "formula_43", "formula_text": "DCC h (\u00b5) \u2264 2 max p\u2208P(\u00b5) min f E p [ zo (f, x, y)] \u2264 2DCC(\u00b5).", "formula_coordinates": [5.0, 312.46, 244.67, 223.96, 16.1]}, {"formula_id": "formula_44", "formula_text": "P [(|X \u2212 \u00b5| \u2265 )] \u2264 \u03c3 2 2 .", "formula_coordinates": [6.0, 122.41, 342.45, 100.07, 21.28]}, {"formula_id": "formula_45", "formula_text": "max p\u2208P(\u00b5) P p [f (x) \u2265 0] .(30)", "formula_coordinates": [6.0, 128.06, 465.94, 161.38, 16.11]}, {"formula_id": "formula_46", "formula_text": "min \u03bd \u03bd \u2022 \u00b5 s.t. ij \u03bd ij (x i , x j ) \u2265 max{0, 1 + f (x)} (31)", "formula_coordinates": [6.0, 62.48, 522.79, 226.96, 20.97]}, {"formula_id": "formula_47", "formula_text": "W 1 W 2 W 10 C 1 C k D k D 1 Y S", "formula_coordinates": [8.0, 139.45, 96.28, 157.61, 79.01]}], "doi": ""}