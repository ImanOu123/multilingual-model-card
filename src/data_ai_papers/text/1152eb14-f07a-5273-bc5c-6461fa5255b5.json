{"title": "Commonsense Knowledge Aware Conversation Generation with Graph Attention", "authors": "Hao Zhou; Tom Young; Minlie Huang; Haizhou Zhao; Jingfang Xu; Xiaoyan Zhu", "pub_date": "", "abstract": "Commonsense knowledge is vital to many natural language processing tasks. In this paper, we present a novel open-domain conversation generation model to demonstrate how large-scale commonsense knowledge can facilitate language understanding and generation. Given a user post, the model retrieves relevant knowledge graphs from a knowledge base and then encodes the graphs with a static graph attention mechanism, which augments the semantic information of the post and thus supports better understanding of the post. Then, during word generation, the model attentively reads the retrieved knowledge graphs and the knowledge triples within each graph to facilitate better generation through a dynamic graph attention mechanism. This is the first attempt that uses large-scale commonsense knowledge in conversation generation. Furthermore, unlike existing models that use knowledge triples (entities) separately and independently, our model treats each knowledge graph as a whole, which encodes more structured, connected semantic information in the graphs. Experiments show that the proposed model can generate more appropriate and informative responses than stateof-the-art baselines.", "sections": [{"heading": "Introduction", "text": "Semantic understanding, particularly when facilitated by commonsense knowledge or world facts, is essential to many natural language processing tasks Lin et al., 2017], and undoubtedly, it is a key factor to the success of dialogue or conversational systems, as conversational interaction is a semantic activity [Eggins and Slade, 2005]. In open-domain conversational systems, commonsense knowledge is important for establishing effective interactions, since socially shared commonsense knowledge is the set of background information people intended to know and use during conversation [Minsky, 1991;Markov\u00e1 et al., 2007;Speer and Havasi, 2012;Souto, 2015]. Some prior studies have been conducted to introduce external knowledge in conversation generation [Han et al., 2015;Ghazvininejad et al., 2017;Zhu et al., 2017]. The knowledge used in these models is either unstructured texts [Ghazvininejad et al., 2017] or domain-specific knowledge triples [Zhu et al., 2017]. Therefore, such models face with two issues when they are applied to open-domain, open-topic conversation generation. First, they are highly dependent on the quality of unstructured texts or limited by the small-scale, domain-specific knowledge. Second, they usually make use of knowledge triples (entities) separately and independently, instead of treating knowledge triples as a whole in a graph. Thus, they are unable to represent the semantics of a graph via linked entities and relations.\nTo address the two issues, we propose a commonsense knowledge aware conversational model (CCM) to facilitate language understanding and generation in open-domain conversational systems. We use a large-scale commonsense knowledge [Speer and Havasi, 2012] to help understand the background information of a given post, and to facilitate response generation with such knowledge. The model retrieves a few knowledge graphs for each post and then use the graphs to respond more informatively and appropriately, as shown in Figure 1. To fully leverage the retrieved graphs in conversation generation, two novel graph attention mechanisms are designed. A static graph attention mechanism encodes the retrieved graphs for a post to augment the semantic representation of the post, which can help understand the post.\nA dynamic graph attention mechanism attentively reads the knowledge graphs and the triples in each graph, and then uses the semantic information from the graphs and triples for better response generation. In summary, this paper makes the following contributions:\n\u2022 This work is the first attempt that uses large-scale commonsense knowledge in neural conversation generation. Supported by such knowledge, our model can understand the dialogue better and thus respond more appropriately and informatively.\n\u2022 Instead of treating knowledge triples (or entities) separately and independently, we devise static and dynamic graph attention mechanisms to treat the knowledge triples as a graph, from which we can better interpret the semantics of an entity from its neighboring entities and relations.", "publication_ref": ["b1", "b0", "b3", "b2", "b3", "b0", "b5", "b5", "b3"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Related Work", "text": "Open-domain Conversational Models Recently, sequence-to-sequence models [Sutskever et al., 2014;Bahdanau et al., 2014] have been successfully applied to large-scale conversation generation, including neural responding machine [Shang et al., 2015], hierarchical recurrent models [Serban et al., 2015], and many others [Sordoni et al., 2015]. These models developed various techniques to improve the content quality of generated responses, including diversity promotion Shao et al., 2017], considering additional information [Xing et al., 2017;Mou et al., 2016], and handling unknown words [Gu et al., 2016]. However, generic or meaningless responses are still commonly seen in these models due to the inability of good understanding of the user input or other context.", "publication_ref": ["b3", "b0", "b3", "b3", "b3", "b3", "b5", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Unstructured Texts Enhanced Conversational Models", "text": "Several studies incorporated unstructured texts as external knowledge into conversation generation [Ghazvininejad et al., 2017;Long et al., 2017]. [Ghazvininejad et al., 2017] used memory network which stores unstructured texts to improve conversation generation. [Long et al., 2017] applied a convolutional neural network to extract knowledge from unstructured texts to generate multi-turn conversations. However, these models largely depend on the quality of unstructured texts, which may introduce noise in conversation generation if the texts are irrelevant.", "publication_ref": ["b2", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Structured Knowledge Enhanced Conversational Models", "text": "There exist some models that introduced high-quality structured knowledge for conversation generation [Han et al., 2015;Zhu et al., 2017;.  incorporated a structured domain-specific knowledge base into conversation generation with a recall-gate mechanism. [Zhu et al., 2017] presented an end-to-end knowledge grounded conversational model using a copy network [Gu et al., 2016]. However, these studies are somehow limited by the small domain-specific knowledge base, making them not applicable for open-domain, open-topic conversation generation. By contrast, our model applies a large-scale commonsense knowledge base to facilitate both the understanding of a post and the generation of a response, with novel graph attention mechanisms.\n3 Commonsense Conversational Model", "publication_ref": ["b0", "b5", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Background: Encoder-decoder Framework", "text": "First of all, we introduce a general encoder-decoder framework which is based on sequence-to-sequence (seq2seq) learning [Sutskever et al., 2014]. The encoder represents a post sequence X = x 1 x 2 \u2022 \u2022 \u2022 x n with hidden representations\nH = h 1 h 2 \u2022 \u2022 \u2022 h n 1\n, which is briefly defined as below:\nh t = GRU(h t\u22121 , e(x t )),(1)\nwhere e(x t ) is the embedding of the word x t , and GRU is gated recurrent unit [Cho et al., 2014]. The decoder takes as input a context vector c t and the embedding of a previously decoded word e(y t\u22121 ), and updates its state s t using another GRU:\ns t = GRU(s t\u22121 , [c t\u22121 ; e(y t\u22121 )]),(2)\nwhere [c t\u22121 ; e(y t\u22121 )] is the concatenation of the two vectors, serving as input to the GRU network. The context vector c t\u22121 is an attentive read of H, which is a weighted sum of the encoder's hidden states as c t\u22121 = n k=1 \u03b1 t\u22121 k h k , and \u03b1 t\u22121 k measures the relevance between state s t\u22121 and hidden state h k . Refer to [Bahdanau et al., 2014] for more details.\nThe decoder generates a token by sampling from the output probability distribution which can be computed as follows:\ny t \u223c o t = P (y t | y <t , c t ) = softmax(W o s t ).(3)\nwhere y <t = y 1 y 2 \u2022 \u2022 \u2022 y t\u22121 , the words already generated.", "publication_ref": ["b3", "b0", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Task Definition and Overview", "text": "Our problem is formulated as follows: Given a post X = x 1 x 2 \u2022 \u2022 \u2022 x n and some commonsense knowledge graphs\nG = {g 1 , g 2 , \u2022 \u2022 \u2022 , g N G }, the goal is to generate a proper response Y = y 1 y 2 \u2022 \u2022 \u2022 y m .\nEssentially, the model estimates the probability: P (Y |X, G) = m t=1 P (y t |y <t , X, G). The graphs are retrieved from a knowledge base using the words in a post as queries, and each word corresponds to a graph in G 2 . Each graph consists of a set of triples g i = {\u03c4 1 , \u03c4 2 , \u2022 \u2022 \u2022 , \u03c4 Ng i } and each triple (head entity, relation, tail entity) is denoted as \u03c4 = (h, r, t).\nWe adopt TransE [Bordes et al., 2013] to represent the entities and relations in the knowledge base. In order to bridge the representation gap between knowledge base and unstructured conversational texts, we adopt a MLP for the purpose: a knowledge triple \u03c4 is represented by k = (h, r, t) = MLP(TransE(h, r, t)), where h/r/t are the transformed TransE embeddings for h/r/t respectively.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Decoder Encoder", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Attention", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Knowledge Interpreter", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Knowledge", "text": "Aware Generator", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Static Graph Attention", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Dynamic Graph Attention", "text": "Knowledge Graph The overview of our commonsense conversational model (CCM) is presented in Figure 2. The knowledge interpreter takes as input a post\nX = x 1 x 2 \u2022 \u2022 \u2022 x n and retrieved knowl- edge graphs G = {g 1 , g 2 , \u2022 \u2022 \u2022 , g N G }\nto obtain knowledgeaware representations at each word position, by concatenating a word vector and its corresponding knowledge graph vector. A knowledge graph vector represents a knowledge graph for the corresponding word in X through a static graph attention mechanism. The knowledge aware generator generates a response Y = y 1 y 2 \u2022 \u2022 \u2022 y m with our dynamic graph attention mechanism. At each decoding position, it attentively reads the retrieved graphs and the entities in each graph, and then generates a generic word in the vocabulary or an entity in the knowledge graphs. The entity is selected by attending on the graphs and the triples within each graph. Figure 3: Knowledge interpreter concatenates a word vector and the graph vector of the corresponding retrieved graph. In this example, word rays (also key entity) corresponds to the first graph, and sunlight to the second one. Each graph is represented by a graph vector.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Knowledge Interpreter", "text": "A key entity is an entity which occurs in the post.\nThe knowledge interpreter is designed to facilitate the understanding of a post. It augments the semantics of a word by including the corresponding graph vector for the word, as shown in Figure 3. The knowledge interpreter uses each word x t in a post as the key entity to retrieve a graph g i = {\u03c4 1 , \u03c4 2 , \u2022 \u2022 \u2022 , \u03c4 Ng i } (the yellow parts) from the entire commonsense knowledge base. Each retrieved graph consists of a key entity (the red dots), its neighboring entities (the blue dots) and relations between entities. For common words (e.g., of) which match no entity in the commonsense knowledge graph, a knowledge graph that contains a special symbol Not A Fact (the grey dots) is used. Then, the knowledge interpreter computes the graph vector g i of the retrieved graph using the static graph attention mechanism. After concatenating the word vector w(x t ) and the knowledge graph vector g i , the concatenated vector e(x t ) = [w(x t ); g i ] is obtained and fed to the GRU cell of the encoder (see Eq. 1).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Static Graph Attention", "text": "The static graph attention mechanism is designed to generate a representation for a retrieved knowledge graph, inspired by [Velickovic et al., 2017]. The major difference to [Velickovic et al., 2017] lies in that our graph attention encodes more structured semantic information by considering not only all nodes in a graph but also relations between nodes.\nThe static graph attention generates a static representation for a graph, which will be used to augment the semantics of a word in a post.\nFormally, the static graph attention mechanism takes as input the knowledge triple vectors K(g i ) = {k 1 , k 2 , \u2022 \u2022 \u2022 , k Ng i } in the retrieved knowledge graph g i , to produce a graph vector g i as follows:\ng i = Ng i n=1 \u03b1 s n [h n ; t n ],(4)\n\u03b1 s n = exp(\u03b2 s n ) Ng i j=1 exp(\u03b2 s j ) ,(5)\n\u03b2 s n = (W r r n ) tanh(W h h n + W t t n ),(6)\nwhere (h n , r n , t n ) = k n , W h , W r , W t are weight matrices for head entities, relations, and tail entities, respectively. The attention weight measures the association of a relation r n to a head entity h n and a tail entity t n . Essentially, a graph vector g i is a weighted sum of the head and tail vectors [h n ; t n ] of the triples contained in the graph.  The knowledge aware generator is designed to generate a response through making full use of the retrieved knowledge graphs, as shown in Figure 4. The knowledge aware generator plays two roles: 1) attentively reading the retrieved graphs to obtain a graph-aware context vector, and using the vector to update the decoder's state; 2) adaptively choosing a generic word or an entity from the retrieved graphs for word generation.Formally, the decoder updates its state as follows:", "publication_ref": [], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Knowledge Aware Generator", "text": "s t+1 = GRU(s t , [c t ; c g t ; c k t ; e(y t )]),(7)\ne(y t ) = [w(y t ); k j ],(8)\nwhere e(y t ) is the concatenation of the word vector w(y t ) and the previous knowledge triple vector k j from which the previous word (y t ) is selected, c t is the context vector as used in Eq. 2, c g t and c k t are context vectors attended on knowledge graph vectors {g 1 , g 2 , \u2022 \u2022 \u2022 , g N G } and knowledge triple vectors\n{K(g 1 ), K(g 2 ), \u2022 \u2022 \u2022 , K(g N G )} respectively.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Dynamic Graph Attention", "text": "The dynamic graph attention mechanism is a hierarchical, top-down process. It first attentively reads all the knowledge graphs and then attentively reads all the triples in each graph for final word generation. Given the decoder state s t , it first attends on the knowledge graph vectors {g 1 , g 2 , \u2022 \u2022 \u2022 , g N G } to compute the probability of using of each graph g i , which is defined as below:\nc g t = N G i=1 \u03b1 g ti g i ,(9)\n\u03b1 g ti = exp(\u03b2 g ti ) N G j=1 exp(\u03b2 g tj ) ,(10)\n\u03b2 g ti = V b tanh(W b s t + U b g i ),(11)\nwhere V b /W b /U b are parameters, and \u03b1 g ti is the probability of choosing knowledge graph g i at step t. The graph context vector c g t is a weighted sum of the graph vectors, and the weight measures the association between the decoder's state s t and a graph vector g i .\nThe model then attends on the knowledge triple vectors K(g i ) = {k 1 , k 2 , \u2022 \u2022 \u2022 , k Ng i } within each graph g i to calculate the probability of selecting a triple for word generation, formally as follows:\nc k t = N G i=1 Ng i j=1 \u03b1 g ti \u03b1 k tj k j ,(12)\n\u03b1 k tj = exp(\u03b2 k tj ) Ng i n=1 exp(\u03b2 k tn ) ,(13)\n\u03b2 k tj = k j W c s t ,(14)\nwhere \u03b2 k tj can be viewed as the similarity between each knowledge triple vector k j and the decoder state s t , \u03b1 k tj is the probability of choosing triple \u03c4 j from all triples in graph g i at step t.\nFinally, the knowledge aware generator selects a generic word or an entity word 3 with the following distributions:\na t = [s t ; c t ; c g t ; c k t ],(15)\n\u03b3 t = sigmoid(V o a t ),(16)\nP c (y t = w c ) = softmax(W o a t ), (17\n)\nP e (y t = w e ) = \u03b1 g ti \u03b1 k tj , (18\n)\ny t \u223c o t = P (y t ) = (1 \u2212 \u03b3t)Pg(yt = wc) \u03b3tPe(yt = we) ,(19)\nwhere \u03b3 t \u2208 [0, 1] is a scalar to balance the choice between an entity word w e and a generic word w c , P c /P e is the distribution over generic/entity words respectively. The final distribution P (y t ) is a concatenation of two distributions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Loss Function", "text": "The loss function is cross entropy between the predicted token distribution o t and the reference distribution p t in the training corpus. Additionally, we apply supervised signals on the knowledge aware generator layer to teacher-force the selection of an entity or a generic word. The loss on one sample < X, Y >\n(X = x 1 x 2 \u2022 \u2022 \u2022 x n , Y = y 1 y 2 \u2022 \u2022 \u2022 y m ) is defined as: L(\u03b8) = \u2212 m t=1 p t log(o t )\u2212 m t=1 (q t log(\u03b3 t )+(1\u2212q t )log(1\u2212\u03b3 t )),(20)\nwhere \u03b3 t is the probability of selecting an entity word or a generic word, and q t \u2208 {0, 1} is the true choice of an entity word or a generic word in Y . The second term is used to supervise the probability of selecting an entity word or a generic word.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Dataset", "text": "Commonsense Knowledge Base ConceptNet 4 is used as the commonsense knowledge base. It contains not only world facts such as \"Paris is the capital of France\" that are constantly true, but also informal relations between common concepts that are part of daily knowledge such as \"A dog is a pet\". This feature is desirable in our experiments, because the ability to recognize the informal relations between common concepts is necessary in the open-domain conversation setting. For simplicity, we removed triples containing multi-word entities, and 120,850 triples were retained with 21,471 entities and 44 relations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Commonsense Conversation Dataset", "text": "We adopted 10M reddit single-round dialogs from the site 5 . Since we target at using commonsense knowledge to facilitate language understanding and generation, we filtered the original corpus with the knowledge triples. If a post-response pair can not be connected by any triple (that is, one entity appears in the post and the other in the response), the pair will be removed. The statistics can be seen in Table 1.\nWe randomly sampled 10,000 pairs for validation. To test how commonsense knowledge can help understand common or rare concepts in a post, we constructed four test sets: highfrequency pairs in which each post has all top 25% frequent words, medium-frequency pairs where each post contains at least one word whose frequency is within the range of 25%-75%, low-frequency pairs within the range of 75%-100%, and OOV pairs where each post contains out-of-vocabulary words. Each test set has 5,000 pairs randomly sampled from the dataset 6 .  cells for each layer and they do not share parameters. The word embedding size is set to 300. The vocabulary size is limited to 30,000. We used TransE [Bordes et al., 2013] to obtain entity and relation representations. The embedding size of entities and relations is set to 100. We used the Adam optimizer with a mini-batch size of 100. The learning rate is 0.0001. The models were ran at most 20 epoches, and the training stage of each model took about a week on a Titan X GPU machine. Our code is available at: https://github.com/tuxchow/ccm.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Implementation Details", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Baselines", "text": "We chose several suitable baselines:\n\u2022 A seq2seq model ( Seq2Seq) [Sutskever et al., 2014], which is widely used in open-domain conversational systems. \u2022 A knowledge-grounded model (MemNet) adapted from [Ghazvininejad et al., 2017], where the memory units store TransE embeddings of knowledge triples. \u2022 A copy network (CopyNet) model [Zhu et al., 2017], which copies a word from knowledge triples or generates a word from the vocabulary.", "publication_ref": ["b3", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Automatic Evaluation", "text": "Metrics: We adopted perplexity [Serban et al., 2015] to evaluate the model at the content level (whether the content is grammatical and relevant in topic). We also calculated the number of entities per response to measure the model's ability to select the concepts from the commonsense knowledge base in generation. This metric is denoted by entity score.\nResults: As shown in Table 2, CCM obtains the lowest perplexity on all the test sets, indicating that CCM can understand users' posts better and generate more grammatical responses. Moreover, CCM selects the most entities from the commonsense knowledge among the models during generation, demonstrating that commonsense knowledge can truly facilitate response generation. More interestingly, commonsense knowledge is more frequently used by CCM in low-frequency posts than in highfrequency ones (entity score: 1.196 vs. 1.156 ). This is in line with our intuition that rare concepts need more background knowledge to understand and respond. For the perplexity, the score for high-frequency posts is lower than low-frequency ones (35.36 vs. 40.67) since the probabilities for the common words can be more sufficiently trained.", "publication_ref": ["b3"], "figure_ref": [], "table_ref": ["tab_5"]}, {"heading": "Manual Evaluation", "text": "We resorted to a crowdsourcing service, Amazon Mechanical Turk, for manual annotation. 400 posts were randomly sampled for manual annotation. We conducted pair-wise comparison between the response generated by CCM and the one by   ). The score is the percentage that CCM wins its competitor after removing \"Tie\" pairs. CCM is significantly better (sign test, p-value < 0.005 ) than all the baselines on all the test sets.\na baseline for the same post. In total, there are 1,200 pairs since we have three baselines. For each response pair, seven judges were hired to give a preference between the two responses, in terms of the following two metrics. Tie was allowed. Notice that system identifiers were masked during annotation. Metrics: We defined two metrics: appropriateness at the content level (whether the response is appropriate in grammar, topic, and logic); and informativeness at the knowledge level (whether the response provides new information and knowledge in addition to the post). Annotation Statistics: We calculated the agreements to measure inter-rater consistency. For appropriateness, the percentage of the pairs that at least 4 judges gave the same label (4/7 agreement) amounts to 96.3%, and the percentage for at least 5/7 agreement is 60.2%. For informativeness, the percentage for at least 4/7 agreement is 90.4% and that for at least 5/7 agreement is 55.1%. Results: The results are shown in Table 3. The score is the percentage that CCM wins a baseline after removing \"Tie\" pairs. CCM outperforms all the baselines significantly in terms of both metrics (sign test, p-value < 0.005) on all the test sets. Furthermore, CCM has about 60% chances to win the strongest baseline, CopyNet, which makes use of knowledge triples (entities) separately and independently. This demonstrates the effectiveness of our graph attention mechanisms.\nNoticeably, the probabilities that CCM wins Seq2Seq on the OOV dataset are remarkably higher than those on the high-frequency dataset (0.673 vs. 0.605 in appropriateness, and 0.716 vs. 0.656 in informativeness). This further indicates that commonsense knowledge is more useful in understanding rare concepts in post since Seq2Seq has no ability to use such knowledge. For MemNet and CopyNet, we did not observe such differences because the two baselines have the ability of using knowledge more or less.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_6"]}, {"heading": "Case Study", "text": "A sample conversation is shown in Table 4. The red-colored word \"breakable\" in the post is an entity word in the knowl-  edge base as well as an out-of-vocabulary word for all the models. Without the access to commonsense knowledge, the Seq2Seq model is unable to understand the post because of the out-of-vocabulary word, \"breakable\", thereby generating OOV words. MemNet can generate some meaningful words as it reads the triple embeddings in its memory, but still outputs OOV. CopyNet can read and copy words from knowledge triples. However, CopyNet generated fewer entity words than ours (see Table 2), as it only deals with separate knowledge triples. Instead, CCM treats the knowledge graph as a whole and encodes more structured, connected information via linked entities and relations. It thus generates more reasonable responses through better use of knowledge. This simple example shows that CCM can generate more appropriate and informative responses than the baselines.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_8", "tab_5"]}, {"heading": "Conclusion and Future Work", "text": "In this paper, we present a commonsense knowledge aware conversational model (CCM) to demonstrate how commonsense knowledge can facilitate language understanding and generation in open-domain conversational systems. Automatic and manual evaluation show that CCM can generate more appropriate and informative responses than state-of-theart baselines.\nAs future work, our graph attention mechanisms may inspire other tasks to use commonsense knowledge.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "This work was partly supported by the National Science Foundation of China under grant No.61272227/61332007 and the National Basic Research Program (973 Program) under grant No. 2013CB329403.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "journal": "Equinox Publishing Ltd", "year": "1702", "authors": "[ References;  Bahdanau"}, {"ref_id": "b1", "title": "Reasoning with heterogeneous knowledge for commonsense machine comprehension", "journal": "", "year": "2017", "authors": ""}, {"ref_id": "b2", "title": "Ivana Markov\u00e1, Per Linell, Mich\u00e8le Grossen, and Anne Salazar Orvig. Dialogue in focus groups: Exploring socially shared knowledge", "journal": "Equinox publishing", "year": "2007", "authors": ""}, {"ref_id": "b3", "title": "Patr\u00edcia Cristina Nascimento Souto. Creating knowledge with and from the differences: the required dialogicality and dialogical competences", "journal": "Arantxa Casanova", "year": "1991", "authors": "; Minsky ; Marvin Minsky;  Mou"}, {"ref_id": "b4", "title": "Conditional generative adversarial networks for commonsense machine comprehension", "journal": "", "year": "2017", "authors": ""}, {"ref_id": "b5", "title": "Incorporating loosestructured knowledge into conversation modeling via recall-gate lstm", "journal": "", "year": "2017", "authors": ""}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: (Better viewed in color) Two response examples by our model (the first line) and Seq2Seq (second) with/without considering commonsense knowledge, respectively.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Overview of CCM.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 4 :4Figure4: Knowledge aware generator dynamically attends on the graphs (the pink graph is mostly attended) . It then attentively reads the triples in each graph to estimate the probability of selecting a triple, where the triple's neighboring entity (purple dots/words) is used for word generation.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Statistics of the dataset and the knowledge base.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_4", "figure_caption": ".717 42.41 0.713 47.25 0.740 48.61 0.721 49.96 0.669 MemNet 46.85 0.761 41.93 0.764 47.32 0.788 48.86 0.760 49.52 0.706", "figure_data": "ModelOverall ppx. ent.High Freq. ppx. ent.Medium Freq. ppx. ent.Low Freq. ppx. ent.ppx.OOV ent.Seq2Seq 47.02 0CopyNet 40.27 0.9636.26 0.9140.99 0.9742.09 0.9642.24 0.96CCM39.18 1.180 35.36 1.156 39.64 1.191 40.67 1.196 40.87 1.162"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Automatic evaluation with perplexity (ppx.), and entity score (ent.).", "figure_data": "ModelOverall app. inf.High Freq. app. inf.Medium Freq. app. inf.Low Freq. app. inf.app.OOV inf.CCM vs. Seq2Seq 0.616 0.662 0.605 0.656 0.549 0.624 0.636 0.650 0.673 0.716CCM vs. MemNet 0.602 0.647 0.593 0.656 0.566 0.640 0.622 0.635 0.626 0.657CCM vs. CopyNet 0.600 0.640 0.606 0.669 0.586 0.619 0.610 0.633 0.596 0.640"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Manual evaluation with appropriateness (app.), and informativeness (inf.", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Sample responses generated by all the models.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "H = h 1 h 2 \u2022 \u2022 \u2022 h n 1", "formula_coordinates": [2.0, 315.0, 418.65, 76.64, 11.0]}, {"formula_id": "formula_1", "formula_text": "h t = GRU(h t\u22121 , e(x t )),(1)", "formula_coordinates": [2.0, 382.85, 438.35, 175.15, 9.68]}, {"formula_id": "formula_2", "formula_text": "s t = GRU(s t\u22121 , [c t\u22121 ; e(y t\u22121 )]),(2)", "formula_coordinates": [2.0, 365.12, 519.15, 192.88, 9.68]}, {"formula_id": "formula_3", "formula_text": "y t \u223c o t = P (y t | y <t , c t ) = softmax(W o s t ).(3)", "formula_coordinates": [2.0, 371.89, 632.83, 186.11, 23.63]}, {"formula_id": "formula_4", "formula_text": "G = {g 1 , g 2 , \u2022 \u2022 \u2022 , g N G }, the goal is to generate a proper response Y = y 1 y 2 \u2022 \u2022 \u2022 y m .", "formula_coordinates": [3.0, 54.0, 85.68, 243.0, 31.57]}, {"formula_id": "formula_5", "formula_text": "X = x 1 x 2 \u2022 \u2022 \u2022 x n and retrieved knowl- edge graphs G = {g 1 , g 2 , \u2022 \u2022 \u2022 , g N G }", "formula_coordinates": [3.0, 54.0, 551.81, 243.0, 21.23]}, {"formula_id": "formula_6", "formula_text": "g i = Ng i n=1 \u03b1 s n [h n ; t n ],(4)", "formula_coordinates": [4.0, 89.46, 71.79, 207.54, 31.92]}, {"formula_id": "formula_7", "formula_text": "\u03b1 s n = exp(\u03b2 s n ) Ng i j=1 exp(\u03b2 s j ) ,(5)", "formula_coordinates": [4.0, 86.41, 106.43, 210.59, 28.95]}, {"formula_id": "formula_8", "formula_text": "\u03b2 s n = (W r r n ) tanh(W h h n + W t t n ),(6)", "formula_coordinates": [4.0, 87.15, 139.45, 209.85, 12.69]}, {"formula_id": "formula_9", "formula_text": "s t+1 = GRU(s t , [c t ; c g t ; c k t ; e(y t )]),(7)", "formula_coordinates": [4.0, 93.42, 556.56, 203.58, 13.37]}, {"formula_id": "formula_10", "formula_text": "e(y t ) = [w(y t ); k j ],(8)", "formula_coordinates": [4.0, 90.65, 573.23, 206.35, 9.68]}, {"formula_id": "formula_11", "formula_text": "{K(g 1 ), K(g 2 ), \u2022 \u2022 \u2022 , K(g N G )} respectively.", "formula_coordinates": [4.0, 54.0, 655.77, 180.43, 10.3]}, {"formula_id": "formula_12", "formula_text": "c g t = N G i=1 \u03b1 g ti g i ,(9)", "formula_coordinates": [4.0, 365.33, 126.37, 192.67, 30.44]}, {"formula_id": "formula_13", "formula_text": "\u03b1 g ti = exp(\u03b2 g ti ) N G j=1 exp(\u03b2 g tj ) ,(10)", "formula_coordinates": [4.0, 362.38, 158.68, 195.62, 29.31]}, {"formula_id": "formula_14", "formula_text": "\u03b2 g ti = V b tanh(W b s t + U b g i ),(11)", "formula_coordinates": [4.0, 363.12, 191.38, 194.88, 13.68]}, {"formula_id": "formula_15", "formula_text": "c k t = N G i=1 Ng i j=1 \u03b1 g ti \u03b1 k tj k j ,(12)", "formula_coordinates": [4.0, 382.93, 323.75, 175.08, 32.04]}, {"formula_id": "formula_16", "formula_text": "\u03b1 k tj = exp(\u03b2 k tj ) Ng i n=1 exp(\u03b2 k tn ) ,(13)", "formula_coordinates": [4.0, 379.36, 360.85, 178.64, 29.92]}, {"formula_id": "formula_17", "formula_text": "\u03b2 k tj = k j W c s t ,(14)", "formula_coordinates": [4.0, 380.1, 393.49, 177.9, 12.69]}, {"formula_id": "formula_18", "formula_text": "a t = [s t ; c t ; c g t ; c k t ],(15)", "formula_coordinates": [4.0, 400.73, 496.48, 157.27, 13.37]}, {"formula_id": "formula_19", "formula_text": "\u03b3 t = sigmoid(V o a t ),(16)", "formula_coordinates": [4.0, 401.88, 514.88, 156.12, 9.68]}, {"formula_id": "formula_20", "formula_text": "P c (y t = w c ) = softmax(W o a t ), (17", "formula_coordinates": [4.0, 359.48, 528.83, 194.37, 9.68]}, {"formula_id": "formula_21", "formula_text": ")", "formula_coordinates": [4.0, 553.85, 529.18, 4.15, 8.64]}, {"formula_id": "formula_22", "formula_text": "P e (y t = w e ) = \u03b1 g ti \u03b1 k tj , (18", "formula_coordinates": [4.0, 359.04, 541.55, 194.81, 13.68]}, {"formula_id": "formula_23", "formula_text": ")", "formula_coordinates": [4.0, 553.85, 544.61, 4.15, 8.64]}, {"formula_id": "formula_24", "formula_text": "y t \u223c o t = P (y t ) = (1 \u2212 \u03b3t)Pg(yt = wc) \u03b3tPe(yt = we) ,(19)", "formula_coordinates": [4.0, 342.33, 560.25, 215.67, 20.81]}, {"formula_id": "formula_25", "formula_text": "(X = x 1 x 2 \u2022 \u2022 \u2022 x n , Y = y 1 y 2 \u2022 \u2022 \u2022 y m ) is defined as: L(\u03b8) = \u2212 m t=1 p t log(o t )\u2212 m t=1 (q t log(\u03b3 t )+(1\u2212q t )log(1\u2212\u03b3 t )),(20)", "formula_coordinates": [5.0, 54.0, 90.03, 245.75, 64.75]}], "doi": ""}