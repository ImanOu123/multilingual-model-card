{"title": "A Theory of Refractive and Specular 3D Shape by Light-Path Triangulation", "authors": "Kiriakos N Kutulakos; Eron Steger", "pub_date": "", "abstract": "We investigate the feasibility of reconstructing an arbitrarily-shaped specular scene (refractive or mirror-like) from one or more viewpoints. By reducing shape recovery to the problem of reconstructing individual 3D light paths that cross the image plane, we obtain three key results. First, we show how to compute the depth map of a specular scene from a single viewpoint, when the scene redirects incoming light just once. Second, for scenes where incoming light undergoes two refractions or reflections, we show that three viewpoints are sufficient to enable reconstruction in the general case. Third, we show that it is impossible to reconstruct individual light paths when light is redirected more than twice. Our analysis assumes that, for every point on the image plane, we know at least one 3D point on its light path. This leads to reconstruction algorithms that rely on an \"environment matting\" procedure to establish pixel-to-point correspondences along a light path. Preliminary results for a variety of scenes (mirror, glass, etc) are also presented.", "sections": [{"heading": "Introduction", "text": "The reconstruction of general specular scenes, either refractive or mirror-like, is one of the few remaining open problems in visual reconstruction. Examples include scenes that contain glass objects, mirrors, or liquids, where refraction and specular reflection dominate the image formation process. Such scenes cannot be reconstructed by laser scanners or by 3D reconstruction algorithms designed for objects that scatter incident light (e.g., [1][2][3]). Reconstructing such scenes, on the other hand, could have implications in many disciplines, including graphics [4,5], optics [6,7], 3-D scanning [8,9], and fluid modeling [10].\nSpecular objects do not have an \"appearance\" of their own-they simply distort the appearance of other objects nearby, creating an indirect view of the original objects. Unlike perspective images, where 3D points project along straight lines, indirect views are created by light that travels along a piecewise-linear light path (Figure 1). The complexity of this projection process and the difficulty of inverting it has brought about new image-based techniques, such as environment matting [4,5,11], that side-step 3D reconstruction altogether. Instead of computing shape, they compute the shape's effect on appearance-all they recover is a function that maps points on a pattern placed near the scene to pixels in the pattern's distorted, indirect view.\nIn this paper, we investigate the reconstruction of such scenes with an approach that seeks to invert the indirect pro- jection process. Despite the problem's apparent intractability in the general case, it is possible to characterize the class of reconstructible scenes and to develop simple reconstruction algorithms for some important cases. In particular, our work considers three questions:\n\u2022 suppose we are given a function that maps each point in the image to a 3D \"reference point\" that indirectly projects to it; can we recover the point's light path? \u2022 if so, under what conditions?\n\u2022 how do we design reconstruction algorithms that do not impose any a priori constraints on the shape of the unknown specular scene? Little is known about how to address these questions in the general case, although specialized reconstruction algorithms for a few cases have been developed. The earliest algorithms come from multi-media photogrammetry [12,13], where the scene is assumed to have a known parametric form. These approaches solve a generalized structure-frommotion problem that takes into account refractions and reflections caused by parametric surfaces with a few known degrees of freedom (e.g., underwater objects viewed from above a planar sea surface). An algorithm along these lines was recently proposed by Ben Ezra and Nayar [14] for reconstructing glass objects modeled as super-ellipsoids. Knowledge of a scene's low-order parametric form implies that these techniques cannot be used for reconstructing objects with fine detail or with a complicated, unknown shape.\nMost computer vision research on the topic has followed a \"shape-from-distortion\" approach for reconstructing either mirrors [9,15] or liquids [16][17][18]. In this approach, 3D shape is recovered by analyzing the distortion of a known pattern placed near the specular surface. Unfortunately it is impossible, in general, to reconstruct the 3D shape of an unknown specular scene from just one image. This has prompted a variety of assumptions, including approximate planarity [17][18][19], surface smoothness [15], integrability [9], and special optics [10,16,20]. These approaches are restricted to the simplest forms of indirect viewing, where light bounces at most once before reaching the camera (e.g., by reflecting off a mirror or refracting once through the air-water boundary). Moreover, research on reconstructing glass objects has relied on either a silhouette-based approach [4], where an object's specular properties are not exploited for reconstruction, or on analyzing the polarization of light specularly reflected from their surface [21]. Unfortunately, silhouette-based approaches are limited to recovering a visual hull approximation and polarization-based analysis is difficult when transmission, rather than specular reflection, dominates image formation.\nOur goal is to develop a general framework for analyzing specular scenes that does not impose a priori assumptions on the shape of their surfaces or the nature of their media (e.g., opaque or transparent). To achieve this, we formulate the reconstruction of individual light paths as a geometric constraint satisfaction problem that generalizes the familiar notion of triangulation to the case of indirect projection.\nOur approach can be thought of as complementing two lines of recent work. Research on environment matting and generalized imaging models [5,22,23] represents an arrangement of cameras, mirrors and lenses as an abstract function that maps 3D points or 3D rays to points on the image plane. These techniques focus on computing this function and treat the arrangement itself as an unknown \"black box.\" In contrast, here we assume that this function is known and study the problem of reconstructing the arrangement. Work on specular stereo [24][25][26][27] relies on a twocamera configuration or a moving observer to reconstruct a mirror-like object. These algorithms solve the light path reconstruction problem for one specific case; our framework leads to several generalizations, including a stronger twoview result [28] that enables reconstruction of a refractive scene even when its refractive index is unknown.\nOn the theoretical side, our work has five key contributions. First, we provide a unified analysis of refractive and mirror-like scenes, leading to algorithms that work for both problems. Second, we characterize the set of reconstructible scenes in a way that depends only on the number of vertices along a light path. As such, our results apply to any specific scene geometry that produces paths of a given length. Third, we identify a very simple algorithm for computing the depth map of a mirror surface from one viewpoint. The algorithm relies on knowledge of a function that maps each image point to two known reference points along its light path and places no restrictions on shape, except that light must bounce exactly once before reaching the camera. Fourth, we establish the most general class of scenes that can be reconstructed using an efficient, stereolike algorithm: these are scenes where light bounces twice before reaching the camera. To our knowledge, this problem, which requires three viewpoints to solve it, has not been previously analyzed. Fifth, we show that, while efficient algorithms may not exist for scenes with light paths of length K \u2265 3, there is enough information in 3(K \u2212 1) viewpoints to reduce shape ambiguities to a discrete set.\nWhile our emphasis here is on the underlying theory, we present preliminary results on real scenes, both refractive and mirror-like. These results have several implications. First, they show that we can reconstruct mirror surfaces with a technique whose accuracy is bounded by the calibration accuracy of a single stationary camera and by the accuracy of environment matting (which can be very high using well-known techniques [5,29]). Second, it is possible to reconstruct each point on a specular 3D scene (mirror, liquid, glass) independently of all other points. This allows reconstruction of scenes with fine surface detail and/or discontinuities. Third, we can compute a separate depth and a separate normal for each surface point; this is unlike typical stereo or laser-scanning techniques (which compute a pointset that must be differentiated to get normals) or photometric stereo (which computes a normal map that must be integrated to obtain depth). As such, our algorithms yield richer 3D data for inferring an object's unknown shape [3,30].", "publication_ref": ["b0", "b1", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b9", "b3", "b4", "b10", "b11", "b12", "b13", "b8", "b14", "b15", "b16", "b17", "b16", "b17", "b18", "b14", "b8", "b9", "b15", "b19", "b3", "b20", "b4", "b21", "b22", "b23", "b24", "b25", "b26", "b27", "b4", "b28", "b2", "b29"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Light-Path Triangulation", "text": "Perspective projection requires that every 3D point projects to an image along a straight line. When the scene is composed of refractive or mirror-like objects, this linear projection model is not valid anymore. Here we extend this model by studying indirect projections of 3D points. Informally, indirect projection occurs anytime a point is viewed indirectly, via one or more specular surfaces.\nConsider a scene that is viewed from one or more known viewpoints and contains one or more objects of unknown shape. We assume that each object is a volume composed of a homogeneous medium (opaque or transparent) and whose surface is smooth, i.e., it does not contain surface irregularities that scatter the incident light. In this case, the propagation of light through the scene is characterized by three basic processes [31,32]-specular reflection at an object's surface, specular transmission (i.e., refraction) at the surface of a transparent object, and linear propagation within an object's interior and through empty space.\nGiven an arbitrary 3D point p, a known viewpoint c, and a known image plane, the point's projection is determined by the 3D path(s) that light would trace in order to reach that viewpoint (Figure 2). We use the term light path to refer to such a path. If a light path exists, it will be a piecewiselinear curve between p and c whose vertices, if any, will always lie on the surface of some object in the scene. The number of vertices along a path is therefore equal to the number of surfaces it intersects. In general, there may be more than one light path connecting a 3D point to a viewpoint, or there may be none at all. 1 We say that point q is an indirect projection of p if there is a light path between p and c that crosses the image plane at q. The dark gray region denotes a mirror-like object and the light gray region a transparent object. Here, the light path from p intersects three surfaces before reaching point q on the image plane, and therefore has three vertices, v1, v2 and v3, and four rays.\nIn light-path triangulation, the coordinates of c, q and p are known and the goal is to determine the coordinates and normals of the vertices. By convention, we order vertices and rays along a path according to the direction of light travel.", "publication_ref": ["b30", "b31", "b0"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "The Light-Path Triangulation Problem", "text": "Suppose the specular scene is viewed from N known viewpoints. We assume that for every point on the associated image planes there is a unique light path that describes light propagation toward that point. 2 Furthermore, suppose we are given a function which tells us, for every such point, the 3D coordinates of M \"reference points\" that project to that point indirectly (Figure 3). Now, suppose we choose a point q on one of the image planes and assign it a \"depth\" value, i.e., a hypothetical distance to the last vertex along its light path. Under what conditions can we decide unambiguously the correctness of this depth? Our goal is to answer this question in the general case, i.e., for smooth scenes of arbitrary shape, N \u2265 1 viewpoints, M \u2265 1 known reference points, and light paths with K \u2265 1 vertices. To simplify our exposition, we assume without loss of generality that all light paths have the same number, K, of vertices and that this number is known.\nWhen we assign a depth d to a point on the image plane, we define the 3D position of one specular point, v d , along the ray through the selected image point. If that depth is correct, v d would redirect light toward all N viewpoints in a way that is consistent with the laws of refraction and reflection, as well as the known function that maps image points to reference points. Specifically, light would travel along N distinct light paths whose last vertex is v d (Figure 3). These paths define a graph, that we call the light network for depth d. The network connects the N perspective projections of v d to their corresponding reference points.", "publication_ref": ["b1"], "figure_ref": ["fig_2", "fig_2"], "table_ref": []}, {"heading": "Definition 1 (Consistent Light Network)", "text": "The light network for depth d is consistent if we can assign a normal to v d and 3D coordinates and normals to its other vertices so that the resulting light paths are consistent with the laws of reflection and refraction.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Definition 2 ( N, K, M -Triangulation) Assigns a depth d to a", "text": "given image point so that the resulting light network is consistent.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Definition 3 (Tractability)", "text": "A triangulation problem is tractable for a given image point if its solution space is a 0-dimensional manifold, i.e., it is a collection of isolated depth values. Intuitively, the minimum M and N needed to make triangulation tractable for a given path length K indicate the problem's intrinsic difficulty. We use the term light-path triangulation to refer to the entire family of N, K, Mtriangulation problems.\nc v d q p1 pM \u2022 \u2022 \u2022 d \u2022 \u2022 \u2022 | {z } N viewpoints | {z } K-vertex paths | {z } M reference points\nLight-path triangulation differs from traditional stereo triangulation in three important ways. First, unlike stereo where at least two viewpoints are needed for reconstruction, tractable light-path triangulation is possible even with just one viewpoint (Section 3.1). Second, unlike stereo where a single point is reconstructed from a pair of intersecting 3D rays, here we must reconstruct the 3D coordinates of all N (K \u2212 1) + 1 points in a light network, to guarantee consistency. Third, while stereo triangulation does not provide surface normal information, light-path triangulation reconstructs normals as well. Hence, even though it is harder to solve, light-path triangulation yields richer scene descriptions than stereo both in terms of density (i.e., number of reconstructed points) and content (i.e., points and normals).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Basic Properties of a Light Path", "text": "In principle, it is always possible to express a light-path triangulation problem as a system of non-linear equations that govern light propagation through the scene. Rather than study the analytical form of those equations, which can be quite complex, we take a geometric approach. In particular, we express N, K, M -triangulation as a geometric constraint satisfaction problem whose solution space depends on just three properties (Figure 4): Note that all three properties hold for reflected and for refracted light. As a result, our analysis does not distinguish between these two different types of light propagation, making our theoretical results applicable to scenes with mirrorlike or refractive objects, or both. While not previously used for reconstruction, the Double-Correspondence Property has been noted in the context of environment matting [5] and camera calibration [22]. Here, it highlights a fundamental difference between light-path triangulations where two or more reference points are known per image point (M \u2265 2) versus just one (M = 1): two or more reference points provide complete information about the 3D ray along which light propagates before it enters the scene, which is impossible to get from just one reference point. This distinction is especially important in interpreting the results of our analysis.", "publication_ref": ["b4", "b21"], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Tractable Light-Path Triangulations", "text": "Our main theoretical result is an enumeration of all tractable light-path triangulation problems (Figure 5): Theorem 1 The only tractable N, K, M -triangulations are shown in the tables below:\nOne reference point (M = 1)\nK = 1 K = 2 K \u2265 3 N = 1 N \u2265 2 \u00d7 Two or more reference points (M \u2265 2) K = 1 K = 2 K \u2265 3 N = 1 \u00d7 N = 2 \u00d7 N = 3 \u00d7 N \u2265 4 \u00d7 \u00d7\nwhere ' ' marks tractable problems where the scene is either known to be a mirror or its refractive index is known; '\u00d7' marks tractable problems where the refractive index (or whether it is a mirror) is unknown; and blanks correspond to intractable cases.\nWe obtain this result through a case-by-case analysis in which the three properties of Section 2.2 are applied to the above cases. Proofs for the cases of 1, 1, 2 -triangulation and 3, 2, 2 -triangulation are given in Sections 3.1 and 3.2, respectively. Each of these proofs is constructive and leads directly to a reconstruction algorithm. See [28] for a detailed investigation of a third case, 2, 1, 1 -triangulation, which includes a proof, algorithmic details, and experimental results on reconstructing dynamic surfaces of liquids.\nTheorem 1 can be interpreted both as a negative and as a positive result. On the negative side, it tells us that lightpath triangulation quickly becomes intractable for scenes where a light path intersects many surfaces. Moreover, our capabilities are severely limited when M = 1, i.e., when one known reference point projects to each image point.\nOn the positive side, the theorem identifies three nontrivial cases that are tractable: (1) reconstructing a mirror from just one viewpoint; (2) reconstructing a refractive surface with an unknown refractive index from two viewpoints; and (3) using three viewpoints to reconstruct scenes that refract or reflect light twice.", "publication_ref": ["b27"], "figure_ref": ["fig_5"], "table_ref": []}, {"heading": "Mirrors: One Viewpoint, Two Reference Points", "text": "Proposition 1 1, 1, 2 -triangulation is tractable.\nProof: Let c be a known viewpoint and let q be a point on the (known) image plane whose light path has exactly one vertex v (Figures 4 and 5a). Moreover, suppose that we know two distinct reference points, p1, p2, that indirectly project to q. Finally, suppose that we do not know the scene's refractive index or whether it is a mirror.\nThe proof follows trivially from that fact that under these conditions, both rays on the light path of q are known. Specifically, the last ray is defined by the known points c and q. Moreover, the Double-Correspondence Property tells us that the first ray on its path passes through p1 and p2. These two rays will intersect at exactly one point, which must correspond to the location of vertex v. The unique depth solution is given by\nd = (p1 \u2212 c) \u00d7 d in d out \u00d7 d in (1)\nwhere d in and d out are the unit vectors in the direction of the path's two rays. 4 QED While the algorithm implied by the proof of Proposition 1 is very simple, we are not aware of prior work that uses it for reconstructing specular scenes. 5 ", "publication_ref": ["b3", "b4"], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Glass: Three Viewpoints, Two Reference Points", "text": "Proposition 2 3, 2, 2 -triangulation is tractable for almost all points on a generic surface with known refractive index. Proof: The proof uses two basic intuitions: (1) the set of all depth and normal assignments consistent with a single viewpoint forms a 2D \"constraint surface;\" and (2) the common intersection of three such surfaces (i.e., one for each viewpoint) will in general be a set of isolated points. In the following, we develop a constructive proof that formalizes these intuitions. For concreteness, assume that the \"true\" light path of every image point contains two refractive vertices (Figure 5c). Paths where one or both of their vertices are reflective can be treated in an identical way.\nn n n n 1 n 2 n 3 v d v d v d v 1 v 2 v 3(\nTo prove the proposition we use two facts. First, since M = 2, we know two rays on the light path of every image point (Figure 6a). Second, for scenes bounded by a generic (i.e., nondegenerate) surface [35], the light path of almost every pixel, in a measure-theoretic sense, will be non-planar, i.e., the first and last ray of a light path will not lie on the same plane, and therefore these rays will not intersect. This is because the planarity of a light path is not a stable [34] property-almost any infinitesimal surface deformation, change in viewpoint or change in the position of pixel q will invalidate it. Now let q be an arbitrary image point, let l1, l2, l3 be the first, middle, and last ray along its light path, respectively, and let d be a hypothetical depth value assigned to q. We show that in general only isolated d-values can define a consistent light network.\nSince l1 is the first ray on the light path of q, it contains the first vertex of q's path. Moreover, since this ray is known, there is a one-degree-of-freedom ambiguity in the position of this vertex. We can therefore parameterize its position with a parameter \u03b4 \u2208 (\u2212\u221e, \u221e). For a given d, each \u03b4-value defines a unique position, v \u03b4 , for the path's first vertex and, consequently, a unique light path for q. In that path, light initially propagates along l1, is refracted at v \u03b4 and then at v d , and finally reaches q. From the Deflection Property, only one normal at v d can redirect light according to that path. Hence, it is possible to map every pair (d, \u03b4) to a normal, n d\u03b4 . Moreover, since l1 and l3 do not intersect in general, this mapping is a diffeomorphism for almost every q. Note that we can compute n d\u03b4 for any d and \u03b4 because we know l1 and l3. Now let q be the perspective projection of point v d in the second viewpoint, and let l 1 and l 3 be the first and last ray on its light path, respectively (Figure 6b). Rays l 1 and l 3 will also not intersect in general. Given a normal n d\u03b4 and ray l 3 , the Deflection Property tells us that there is a unique ray, l 2 , that (1) passes through v d and (2) causes light propagating along l 2 to be refracted toward q . This ray is completely determined by v d , n d\u03b4 , the second viewpoint, and the image point q . In particular, there is no geometric constraint between rays l 1 and l 2 . It follows that these rays will be in general position, i.e., they will not intersect for an arbitrary choice of d and \u03b4 and will not form a light path. Hence, such a choice does not produce a light network for q.\nFor a given d, there is only an isolated set of \u03b4-values that cause rays l 1 and l 2 to intersect. To see this, note that as \u03b4 varies over the interval (\u2212\u221e, \u221e), ray l 2 traces a ruled surface whose shape has no relation to ray l 1 . Since in general a ray and a surface will only have isolated intersection points [34], and since l 1 and l 2 intersect precisely at those points, it follows that for every d there is only a discrete set, \u2206 d , of \u03b4-values that produce a light path through q .\nFinally, consider the projection, q , of v d in the third viewpoint (Figure 6c). For a given d, the normals that produce light paths for the first two viewpoints are given by the set {n d\u03b4 | \u03b4 \u2208 \u2206 d }. For every normal in this set there is a unique ray, l 2 , that passes through point v d and forces light propagating along l 2 to be refracted toward pixel q . Since the set of normals is discrete, these rays form a discrete family. Moreover, since this family of rays has no relation to ray l 1 and since rays in general position have no common intersections, it follows that l 1 and l 2 will only intersect for an isolated set of d-values. Beyond showing that it is possible to reconstruct general doubly-refracting and doubly-reflecting scenes, our proof suggests a reconstruction algorithm: it tells us that we can reconstruct all four vertices and normals in the light network of a pixel q by conducting a 2D search in (d, \u03b4)-space. The search is for a pair (d, \u03b4) that forces intersection both of rays l 1 , l 2 in Figure 6b and rays l 1 , l 2 in Figure 6c.\nQED q q n d\u03b4 n d\u03b4 n d\u03b4 v d v d v d v d v \u03b4 v \u03b4 v \u03b4 l 3 l 2 l 1 l 3 l 2 l 1 q l 3 l 2 l 1 q l 4 l 4 l 3 l 2 l 1 n d n v v \u03b4 (a) (b)(c)", "publication_ref": ["b34", "b33", "b33"], "figure_ref": ["fig_5", "fig_6", "fig_6", "fig_6", "fig_6", "fig_6"], "table_ref": []}, {"heading": "The Limits of Light-Path Triangulation", "text": "We now prove that light-path triangulation cannot reconstruct general scenes that redirect light more than twice. Proposition 3 N, 3, 2 -triangulation is intractable.\nProof: It suffices to prove the proposition for the case where the scene is refractive with a known refractive index and is viewed from N > 1 viewpoints. Let d be a hypothetical depth value at q, and let n d be an arbitrarily-chosen normal for vertex v d (Figure 6d). Given the projection q of v d in the i-th viewpoint, we will assign coordinates and normals to all remaining vertices on its light path in a way that is consistent with the laws of refraction.\nWe use the same terminology as in the proof of Proposition 2. For a given d and n d , there is only one ray, l 3 , that can refract light toward image point q (Figure 6d). The second vertex, v, on q 's light path will lie on that ray. Choose an arbitrary location on the ray for that vertex. To fully define a light path for q, we now need to specify its first vertex. This vertex must lie on the known ray l 1 . As in the proof of Proposition 2, the 3D position, v \u03b4 , of this vertex can be parameterized by a single parameter \u03b4. Choose an arbitrary value of \u03b4 to fix the location of that vertex as well. Now, the Deflection Property tells us that there is a unique normal that will redirect light from l 2 toward l 3 at v. Similarly, there is a unique normal that will redirect light from l 1 toward l 2 at v \u03b4 . Hence, we have found an assignment of 3D coordinates and normals for all path vertices that produces a light path for q . Since we were able to do this for an arbitrary value of the depth d, the triangulation problem's solution space is dense in R. QED", "publication_ref": [], "figure_ref": ["fig_6", "fig_6"], "table_ref": []}, {"heading": "The Power of Global Shape Recovery", "text": "The fact that light-path triangulation is intractable for scenes with long light paths does not necessarily mean that reconstruction of such scenes is hopeless. Intuitively, lightpath triangulation operates at a completely local level-for any two points on the same image plane, it attempts to reconstruct the associated light networks independently of each other. So what if we had a procedure that reasoned about multiple light networks simultaneously? Here we briefly sketch a partial answer to this question: we show that a sufficiently large collection of viewpoints does contain enough information to reduce shape ambiguities to a discrete set. Although this existence result does not point to any algorithms, it does suggest that, with enough images, we can test with reasonable confidence the validity of a hypothesized 3D scene model: Proposition 4 Given an arrangement of viewpoints for which there is a constant K such that (1) every scene point is intersected by at least 3(K \u2212 1) light paths of length \u2264 K and (2) the first and last ray of all these paths is known, the location of each scene point is constrained to a 0-dimensional solution manifold.\nIntuitively, Proposition 4 gives us a lower bound on the number of viewpoints we need for shape verification: for light paths of maximum length K, each scene point must project indirectly to least 3(K \u2212 1) viewpoints. We prove this result inductively, using Proposition 2 both as the base case and for proving the inductive step. See [36,37] for details.", "publication_ref": ["b35", "b36"], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Results", "text": "We used a 720 \u00d7 484-pixel Sony DXC-9000 video camera for image acquisition and a DELL LCD display for displaying reference patterns. To calibrate the camera with respect to the plane of the LCD display, we used the Matlab Calibration Toolbox [29], and used an environment matting procedure [5] to find the correspondence between image pixels and pixels on the display. The display was then translated by a known amount and the procedure was repeated, giving us two known 3D reference points per image pixel. Reconstructing mirrors by 1, 1, 2 -triangulation We used the arrangement in Figures 1a and 5a. A key feature of 1, 1, 2 -triangulation is that reconstruction accuracy largely depends on the accuracy of camera calibration, not on the shape of the object being reconstructed. We therefore concentrated on evaluating the accuracy of the depths and normals computed individually for each pixel, with an object whose ground-truth shape was known very accurately: a 130\u00d7230mm front-surface mirror with 1 4 -wavelength flatness. To determine the mirror's plane, we digitized several points on it with a FaroArm Gold touch probe, whose single-point measurement accuracy is \u00b10.05mm, and then fit a plane through these points. The mirror was placed about 1.5m away from the camera.\nTo compute the depth d at a pixel, we simply intersected the first and last ray along its light path (see Eq. (1)). The bisector of these rays gave us the surface normal. This computation was done at each of 301,082 pixels in the image, giving us an equal number of 3D position and normal measurements. No smoothing or post-processing was applied. The RMS distance of the reconstructed 3D points from the ground-truth plane was 0.644mm, equivalent to a single-point accuracy of roughly 99.96% of the camera-to-object distance. To assess the accuracy of reconstructed normals, we measured the angle between each computed normal and the ground-truth normal; the mean error was 0.182 degrees, showing that single-point orientation measurements were also highly accurate. We emphasize that these accuracies were obtained without using any information about the scene's shape and without combining measurements from multiple pixels. Reconstructing liquids by 2, 1, 1 -triangulation See [28].", "publication_ref": ["b28", "b4", "b0", "b27"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Reconstructing glass objects by 3, 2, 2 -triangulation", "text": "We used the arrangement in Figure 7 and Figure 5c. Since this triangulation requires three or more viewpoints, we place objects on a turntable between the LCD and the camera and compute the correspondence between image pixels and pixels on the display for each object rotation. The camera was tilted slightly upwards so that optical rays converging to an object point are not coplanar.\nOne of our test objects, a diamond-shaped glass orna-ment, is shown in Figure 7. The object's many planar facets, which produce complex light paths, its surface discontinuities, and its sharp, protruding tip make reconstruction especially challenging. We used five viewpoints, at \u00b120, \u00b110 and 0-degree rotations. The object extended about 4cm in depth, roughly 1m away from the camera. To reconstruct it, we used all available views and solved a 5, 2, 2triangulation problem independently for every pixel in the 0-degree viewpoint. For each such pixel, our implementation performed a search in (d, \u03b4)-space for a pair of values that produce a valid light path for all viewpoints (Section 3.2 and Figures 6a-c). These values were then refined in a nonlinear optimization stage. Since the light network of a pixel contains six vertices, the algorithm reconstructs six points and six normals per pixel-one on the object's front surface and seven more on the back (Figure 3). Importantly, since we use more viewpoints than the minimum three required, the reconstruction is over-constrained and allows estimation of the object's refractive index, which was found to be 1.53. Figure 7 shows reconstruction results for the object's front surface. The maps for the normals' slant and tilt angles suggest that the object's surface orientation was highly consistent across different pixels within a facet, even though light paths for different pixels were reconstructed completely independently, and no smoothing or post-processing was applied. Because of this independence, normals were reconstructed accurately even near the diamond's tip, where the surface is highly degenerate. Also observe that, as a side-effect, we obtain an automatic segmentation of the scene into smooth segments. This is because image-to-LCD correspondences cannot be established at the precise location of a normal discontinuity and, hence, those pixels were not reconstructed. To further assess the precision of the reconstruction we measured the consistency of normals and depths within each planar facet. These quantitative measurements are shown in the table of Figure 7. They show that individually-reconstructed normals are consistent to within a few degrees, while depth measurements, which seem to produce a noisier map, show deviations on the order of 0.1 to 0.2% of the object-to-camera distance. These results, which confirm our basic theory, suggest that it is possible to recover detailed shape information for refractive objects without any knowledge of their shape, and despite the complexity of image formation.", "publication_ref": [], "figure_ref": ["fig_5", "fig_6", "fig_2"], "table_ref": []}, {"heading": "Concluding Remarks", "text": "While our experimental results are promising, many practical questions remain open. These include (1) how to best compute correspondences between reference points and pixels, (2) how to reconcile point and normal measurements, and (3) how to find the optimal depth at a pixel. Finally, our theoretical analysis can be thought of as a \"worstcase\" scenario for reconstruction, where no constraints are placed on nearby scene points. Since real scenes exhibit spatial coherence, it might be possible to incorporate this constraint into an algorithm that remains tractable even for scenes that refract light more than twice.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "This work was supported in part by the National Science Foundation under Grant No. IRI-9875628, by the Natural Sciences and Engineering Research Council of Canada under the RGPIN and PGS-M programs, by a fellowship from the Alfred P. Sloan Foundation, by an Ontario Premier's Research Excellence Award and by Microsoft Research. The authors would also like to thank Chris Trendall for his implementation of 2, 1, 1 -triangulation, as well as Kurt Akeley, Steven Lin, Allan Jepson, Aaron Hertzmann and the anonymous reviewers for their many helpful comments on versions of this manuscript.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": " ", "text": "[37,\n38]\n \nfor examples).\nNormal maps: Gray-scale values correspond to the slant or tilt angle of each reconstructed normal. Depth map: Gray-scale values are mapped to the range indicated (white=near, black=far). Surfel views: For each pixel, we render a shiny square patch centered on the reconstructed 3D point and oriented along the reconstructed normal. Facet measurements: The average normal for each facet was computed by averaging the reconstructed normal for all pixels in the facet's footprint. The best-fit plane was computed by fitting a plane to the reconstructed depths at those pixels using least squares.", "publication_ref": ["b36", "b37"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Complete dense stereovision using level set methods", "journal": "", "year": "", "authors": "O Faugeras; R Keriven"}, {"ref_id": "b1", "title": "Shape and materials by example: A photometric stereo approach", "journal": "", "year": "", "authors": "A Hertzman; S M Seitz"}, {"ref_id": "b2", "title": "Helmholz stereopsis: Expoiting reciprocity for surface reconstruction", "journal": "", "year": "", "authors": "T Zickler; P N Belhumeur; D J Kriegman"}, {"ref_id": "b3", "title": "Acquisition and rendering of transparent and refractive objects", "journal": "", "year": "2002", "authors": "W Matusik; H Pfister; R Ziegler; A Ngan; L Mcmillan"}, {"ref_id": "b4", "title": "Environment matting and compositing", "journal": "", "year": "", "authors": "D Zongker; D Werner; B Curless; D Salesin"}, {"ref_id": "b5", "title": "New laser rangefinder for threedimensional shape measurement of specular objects", "journal": "Optical Engineering", "year": "2001", "authors": "M Baba; K Ohtani; M Imai"}, {"ref_id": "b6", "title": "Reconstructing curved surfaces from specular reflection patterns using spline surface fitting of normals", "journal": "", "year": "", "authors": "M Halstead; B Barsky; S Klein; R Mandell"}, {"ref_id": "b7", "title": "Acquiring a complete 3d model from specular motion under the illumination of circular-shaped light sources", "journal": "", "year": "2000", "authors": "J Y Zheng; A Murata"}, {"ref_id": "b8", "title": "3D acquisition of mirroring objects", "journal": "", "year": "2003", "authors": "M Tarini; H P A Lensch; M Goesele; H.-P Seidel"}, {"ref_id": "b9", "title": "Measuring the two-dimensional structure of a wavy water surface optically: A surface gradient detector", "journal": "", "year": "1994", "authors": "X Zhang; C S Cox"}, {"ref_id": "b10", "title": "On refractive optical flow", "journal": "", "year": "", "authors": "S Agarwal; S Mallick; D Kriegman; S Belongie"}, {"ref_id": "b11", "title": "Reconstruction of the underwater object", "journal": "Photogrammetric Engineering", "year": "1971", "authors": "J H\u00f6hle"}, {"ref_id": "b12", "title": "New developments in multimedia photogrammetry", "journal": "Wichmann Verlag", "year": "1995", "authors": "H.-G Maas"}, {"ref_id": "b13", "title": "What does motion reveal about transparency?", "journal": "", "year": "", "authors": "M Ben-Ezra; S Nayar"}, {"ref_id": "b14", "title": "Local analysis for 3d reconstruction of specular surfaces -part ii", "journal": "", "year": "", "authors": "S Savarese; P Perona"}, {"ref_id": "b15", "title": "Two-dimensional optical measurement of wave slope", "journal": "Applied Optics", "year": "1983", "authors": "W Keller; B Gotwols"}, {"ref_id": "b16", "title": "Imaging of short ocean wind waves: a critical theoretical review", "journal": "", "year": "1994", "authors": "B J\u00e4hne; J Klinke; S Waas"}, {"ref_id": "b17", "title": "Surface shape reconstruction of an undulating transparent object", "journal": "", "year": "", "authors": "H Murase"}, {"ref_id": "b18", "title": "Determining surface orientations of specular surfaces by using the photometric stereo method", "journal": "", "year": "1981", "authors": "K Ikeuchi"}, {"ref_id": "b19", "title": "A novel approach for texture shape recovery", "journal": "", "year": "", "authors": "J Wang; K J Dana"}, {"ref_id": "b20", "title": "Transparent surface modeling from a pair of polarization images", "journal": "", "year": "2004", "authors": "D Miyazaki; M Kagesawa; K Ikeuchi"}, {"ref_id": "b21", "title": "A general imaging model and a method for finding its parameters", "journal": "", "year": "", "authors": "M Grossberg; S Nayar"}, {"ref_id": "b22", "title": "Two view discrete and differential constraints for generalized imaging systems", "journal": "", "year": "2002", "authors": "R Pless"}, {"ref_id": "b23", "title": "Structured highlight inspection of specular surfaces", "journal": "", "year": "1988", "authors": "A Sanderson; L Weiss; S Nayar"}, {"ref_id": "b24", "title": "Voxel carving for specular surfaces", "journal": "", "year": "", "authors": "T Bonfort; P Sturm"}, {"ref_id": "b25", "title": "Specular stereo", "journal": "", "year": "", "authors": "A Blake"}, {"ref_id": "b26", "title": "A theory of specular surface geometry", "journal": "", "year": "", "authors": "M Oren; S K Nayar"}, {"ref_id": "b27", "title": "Dynamic refraction stereo", "journal": "", "year": "", "authors": "N Morris; K N Kutulakos"}, {"ref_id": "b28", "title": "MATLAB camera calibration toolbox", "journal": "", "year": "", "authors": "J.-Y Bouguet"}, {"ref_id": "b29", "title": "Efficiently combining positions and normals for precise 3d geometry", "journal": "", "year": "", "authors": "D Nehab; S Rusinkiewicz; J Davis; R Ramamoorthi"}, {"ref_id": "b30", "title": "Principles of Digital Image Synthesis", "journal": "Morgan Kaufmann", "year": "1995", "authors": "A S Glassner"}, {"ref_id": "b31", "title": "Surface reflection: Physical and geometrical perspectives", "journal": "", "year": "1991", "authors": "S Nayar; K Ikeuchi; T Kanade"}, {"ref_id": "b32", "title": "Planar catadioptric stereo: geometry and calibration", "journal": "", "year": "", "authors": "J Gluckman; S Nayar"}, {"ref_id": "b33", "title": "", "journal": "Prentice-Hall", "year": "1974", "authors": "V Guillemin; A Pollack; Differential Topology"}, {"ref_id": "b34", "title": "The structure of twodimensional scalar fields with applications to vision", "journal": "Biological Cybernetics", "year": "1979", "authors": "J J Koendering; A J Van Doorn"}, {"ref_id": "b35", "title": "A theory of specular and refractive shape by light-path triangulation", "journal": "", "year": "", "authors": "K N Kutulakos; E Steger"}, {"ref_id": "b36", "title": "", "journal": "", "year": "", "authors": "K N Kutulakos"}, {"ref_id": "b37", "title": "ICCV'05 Proceedings CDROM", "journal": "", "year": "", "authors": ""}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 .1Figure 1. Viewing a known reference point indirectly via (a) an opaque specular scene (a mirror) and (b) a transparent specular scene (a volume of water).", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 .2Figure 2.An example light path. The dark gray region denotes a mirror-like object and the light gray region a transparent object. Here, the light path from p intersects three surfaces before reaching point q on the image plane, and therefore has three vertices, v1, v2 and v3, and four rays. In light-path triangulation, the coordinates of c, q and p are known and the goal is to determine the coordinates and normals of the vertices. By convention, we order vertices and rays along a path according to the direction of light travel.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 .3Figure 3. Basic geometry of N, K, M -triangulation.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "\u2022 3 \u20223Planarity Property: Light propagation at a vertex always occurs on a single plane that contains the surface normal. That is, the vectors n, d in and d out are always coplanar.\u2022 Deflection Property: If we know the refractive index and know any two of vectors n, d in , d out , we can determine uniquely the third vector. Moreover, this relation is a local diffeomorphism. Double-Correspondence Property: If we are given two distinct reference points that project indirectly to the same image point, the first ray on the image point's light path must be the line that passes through both reference points.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 .4Figure 4. Visualizing the three properties of a light path.Vectors n, d in , d out are always coplanar. In specular reflection, shown above, the angle between n and d in is always equal to that of n and d out . In specular transmission, Snell's law states that the ratio of sines of these angles is equal to the relative index of refraction[31]. Hence, knowing one angle allows us to determine the other in both cases.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 5 .5The basic tractable light-path triangulation problems. Similarly-colored rays are on the same light path. The unknown vertices and normals are indicated along each path. (a) 1, 1, 2 -triangulation. (b) 2, 1, 1 -triangulation. (c) 3, 2, 2 -triangulation.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "(d) Figure 6 .6(a)-(c) Path geometries in proof of Proposition 2. (a) Light path of an image point q in the first viewpoint. The arrow indicates the direction of incoming light. Rays l1 and l3 are known but l2 is not. The shaded plane is the plane of rays l2 and l3 and always contains the surface normal, n d\u03b4 . Generically, this plane will not contain ray l1. (b) Light path of q in the second viewpoint, for a given value of d and \u03b4. The path in (a) is also shown. Rays l 1 and l 3 are known. Ray l 2 is uniquely determined by l 3 and n d\u03b4 . For arbitrary d and \u03b4, the rays l 1 and l 2 will not intersect. The dark-shaded plane is the plane of l 2 and l 3 . (c) Light path of q in the third viewpoint. (d) Path geometries in proof for Proposition 3.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "c v d q p1 pM \u2022 \u2022 \u2022 d \u2022 \u2022 \u2022 | {z } N viewpoints | {z } K-vertex paths | {z } M reference points", "formula_coordinates": [3.0, 319.8, 82.33, 224.36, 92.78]}, {"formula_id": "formula_1", "formula_text": "K = 1 K = 2 K \u2265 3 N = 1 N \u2265 2 \u00d7 Two or more reference points (M \u2265 2) K = 1 K = 2 K \u2265 3 N = 1 \u00d7 N = 2 \u00d7 N = 3 \u00d7 N \u2265 4 \u00d7 \u00d7", "formula_coordinates": [4.0, 68.43, 532.16, 192.0, 99.44]}, {"formula_id": "formula_2", "formula_text": "d = (p1 \u2212 c) \u00d7 d in d out \u00d7 d in (1)", "formula_coordinates": [4.0, 384.16, 471.55, 160.95, 22.42]}, {"formula_id": "formula_3", "formula_text": "n n n n 1 n 2 n 3 v d v d v d v 1 v 2 v 3(", "formula_coordinates": [5.0, 108.72, 97.25, 381.3, 63.35]}, {"formula_id": "formula_4", "formula_text": "QED q q n d\u03b4 n d\u03b4 n d\u03b4 v d v d v d v d v \u03b4 v \u03b4 v \u03b4 l 3 l 2 l 1 l 3 l 2 l 1 q l 3 l 2 l 1 q l 4 l 4 l 3 l 2 l 1 n d n v v \u03b4 (a) (b)(c)", "formula_coordinates": [5.0, 304.59, 315.45, 236.56, 240.49]}], "doi": ""}