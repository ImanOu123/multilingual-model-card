{"title": "Efficient Optimization for Rank-based Loss Functions", "authors": "Pritish Mohapatra; Michal Rol\u00ednek; C V Jawahar; Vladimir Kolmogorov; M Pawan Kumar; Iiit Hyderabad", "pub_date": "2018-02-28", "abstract": "The accuracy of information retrieval systems is often measured using complex loss functions such as the average precision (AP)  or the normalized discounted cumulative gain (NDCG). Given a set of positive and negative samples, the parameters of a retrieval system can be estimated by minimizing these loss functions. However, the non-differentiability and non-decomposability of these loss functions does not allow for simple gradient based optimization algorithms. This issue is generally circumvented by either optimizing a structured hinge-loss upper bound to the loss function or by using asymptotic methods like the direct-loss minimization framework. Yet, the high computational complexity of loss-augmented inference, which is necessary for both the frameworks, prohibits its use in large training data sets. To alleviate this deficiency, we present a novel quicksort flavored algorithm for a large class of non-decomposable loss functions. We provide a complete characterization of the loss functions that are amenable to our algorithm, and show that it includes both AP and NDCG based loss functions. Furthermore, we prove that no comparison based algorithm can improve upon the computational complexity of our approach asymptotically. We demonstrate the effectiveness of our approach in the context of optimizing the structured hinge loss upper bound of AP and NDCG loss for learning models for a variety of vision tasks. We show that our approach provides significantly better results than simpler decomposable loss functions, while requiring a comparable training time.", "sections": [{"heading": "Introduction", "text": "Information retrieval systems require us to rank a set of samples according to their relevance to a query. The risk of the predicted ranking is measured by a user-specified loss function. Several intuitive loss functions have been proposed in the literature. These include simple decomposable losses (that is, loss functions that decompose over each training sample) such as 0-1 loss [16,20] and the area under the ROC curve [1,11], as well as the more complex nondecomposable losses (that is, loss functions that depend on the entire training data set) such as the average precision (AP) [5,27] and the normalized discounted cumulative gain (NDCG) [6].\nWhen learning a retrieval system, one can use a training objective that is agnostic to the risk, such as in the case of LambdaMART [4]. In this work, we focus on approaches that explicitly take into account the loss function used to measure the risk. Such approaches can use any one of the many machine learning frameworks such as structured support vector machines (SSVM) [24,25], deep neural networks [23], decision forests [14], or boosting [21]. To estimate the parameters of the framework, they employ a training objective that is closely related to the empirical risk computed over a large training data set. Specifically, it is common practice to employ either a structured hinge upper bound to the loss function [6,27], or an asymptotic alternative such as direct loss minimization [10,22].\nThe feasibility of both the structured hinge loss and the direct loss minimization approach depends on the computational efficiency of the loss-augmented inference procedure. When the loss function is decomposable, the lossaugmented inference problem can be solved efficiently by independently considering each training sample. However, for non-decomposable loss functions, it presents a hard computational challenge. For example, given a training data set with P positive (relevant to the query) and N negative (not relevant to the query) samples, the best known algorithms for loss-augmented inference for AP and NDCG loss functions have a complexity of O(P N + N log N ) [6,27]. Since the number of negative samples N can be very large in practice, this prohibits their use on large data sets.\nIn order to address the computational challenge of nondecomposable loss functions such as those based on AP and NDCG, we make three contributions. First, we characterize a large class of ranking based loss functions that are amenable to a novel quicksort flavored optimization algorithm for the corresponding loss-augmented inference problem. We refer to the class of loss functions as QS-suitable. Second, we show that the AP and the NDCG loss functions are QS-suitable, which allows us to reduce the complexity of the corresponding loss-augmented inference to O(N log P ). Third, we prove that there cannot exist a comparison based method for loss-augmented inference that can provide a better asymptotic complexity than our quicksort flavored approach. It is worth noting that our work is complementary to previous algorithms that have been proposed for the AP based loss functions [18]. Specifically, while the method of [18] cannot improve the asymptotic complexity of our loss-augmented inference algorithm, it can be used to reduce the runtime of a subroutine.\nFor the sake of clarity, we limit our discussion to the structured hinge loss upper bound to the loss function. However, as our main contribution is to speed-up lossaugmented inference, it is equally applicable to direct loss minimization. We demonstrate the efficacy of our approach on the challenging problems of action recognition, object detection and image classification, using publicly available data sets. Rather surprisingly, we show that in case of some models, parameter learning by optimizing complex non-decomposable AP and NDCG loss functions can be carried out faster than by optimizing simple decomposable 0-1 loss. Specifically, while each loss-augmented inference call is more expensive for AP and NDCG loss functions, it can take fewer calls in practice to estimate the parameters of the corresponding model.", "publication_ref": ["b15", "b19", "b0", "b10", "b4", "b26", "b5", "b3", "b23", "b24", "b22", "b13", "b20", "b5", "b26", "b9", "b21", "b5", "b26", "b17", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Background", "text": "We begin by providing a brief description of a general retrieval framework that employs a rank-based loss function, hereby referred to as the ranking framework. Note that this framework is the same as or generalizes the ones employed in previous works [6,12,18,22,27]. The two specific instantiations of the ranking framework that are of interest to us employ the average precision (AP) loss and the normalized discounted cumulative gain (NDCG) loss respectively. A detailed description of the two aforementioned loss functions is provided in the subsequent subsection.", "publication_ref": ["b5", "b11", "b17", "b21", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "The Ranking Framework", "text": "Input. The input to this framework is a set of n samples, which we denote by X = {x i , i = 1, . . . , n}. For example, each sample can represent an image and a bounding box of a person present in the image. In addition, we are also provided with a query, which in our example could represent an action such as 'jumping'. Each sample can either belong to the positive class (that is, the sample is relevant to the query) or the negative class (that is, the sample is not relevant to the query). For example, if the query represents the action 'jumping' then a sample is positive if the corresponding person is performing the jumping action, and negative otherwise. The set of positive and the negative samples are denoted by P and N respectively. which we assume are provided during training, but are not known during testing.\nOutput. Given a query and a set of n samples X, the desired output of the framework is a ranking of the samples according to their relevance to the query. This is often represented by a ranking matrix R \u2208 {\u22121, 0, 1} n\u00d7n such that R x,y = 1 if x is ranked higher than y, -1 if x is ranked lower than y and 0 if x and y are ranked the same. In other words, the matrix R is an anti-symmetric that represents the relative ranking of a pair of samples.\nGiven the sets P and N during training, we construct a ground truth ranking matrix R * , which ranks each positive sample above all the negative samples. Formally, the ground truth ranking matrix R * is defined such that R *\nx,y = 1 if x \u2208 P and y \u2208 N , -1 if x \u2208 N and y \u2208 P, and 0 if x, y \u2208 P or x, y \u2208 N . Note that the ground truth ranking matrix only defines a partial ordering on the samples since R * i,j = 0 for all pairs of positive and negative samples. We will refer to rankings where no two samples are ranked equally as proper rankings. Without loss of generality, we will treat all rankings other than the ground truth one as a proper ranking by breaking ties arbitrarily.\nDiscriminant Function. Given an input set of samples X, the discriminant function F (X, R; w) provides a score for any candidate ranking R. Here, the term w refers to the parameters of the discriminant function. We assume that the discriminant function is piecewise differentiable with respect to its parameters w. One popular example of the discriminant function used throughout the ranking literature is the following:\nF (X, R; w) = 1 |P| |N | x\u2208P y\u2208N R x,y (\u03c6(x; w)\u2212\u03c6(y; w)).\n(1) Here, \u03c6(x; w) is the score of an individual sample, which can be provided by a structured SVM or a deep neural network with parameters w.\nPrediction. Given a discriminant function F (X, R; w) with parameters w, the ranking of an input set of samples X is predicted by maximizing the score, that is, by solving the following optimization problem:\nR(w) = argmax R F (X, R; w). (2\n)\nThe special form of the discriminant function in equation (1) enables us to efficiently obtain the predicted ranking R(w) by sorting the samples in descending order of their individual scores \u03c6(x; w). We refer the reader to [12,27] for details.\nParameter Estimation. We now turn towards estimating the parameters of our model given input samples X, together with their classification into positive and negative sets P and N respectively. To this end, we minimize the risk of prediction computed using a user-specified loss function \u2206(R * , R(w)), where R * is the ground truth ranking that is determined by P and N and R(w) is the predicted ranking as shown in equation (2). We estimate the parameters of our model as\nw * = min w E[\u2206(R * , R(w))].(3)\nIn the above equation, the expectation is taken with respect to the data distribution.\nOptimization for Parameter Estimation. For many intuitive rank based loss functions such as AP loss and NDCG loss, owing to their non-differentiability and nondecomposability, problem (3) can be difficult to solve using simple gradient based methods. One popular approach is to modify problem (3) to instead minimize a structured hinge loss upper bound to the user-specified loss. We refer the reader to [27] for further details about this approach.\nFormally, the model parameters can now be obtained by solving the following problem:\nw * = min w E[J(w)](4)\nJ(w) = max R \u2206(R * , R) + F (X, R; w) \u2212 F (X, R * ; w)\nThe function J(w) in problem ( 4) is continuous and piecewise differentiable, and is amenable to gradient based optimization. The semi-gradient 1 of J(w) takes the following form:\n\u2207 w J(w) = \u2207 w F (X,R; w) \u2212 \u2207 w F (X, R * ; w), (5) with,R = argmax R \u2206(R * , R) + F (X, R; w).\nBorrowing terminology from the structured prediction literature [13,27], we callR the most violating ranking and problem (6) as the loss-augmented inference problem. An efficient procedure for loss-augmented inference is key to solving problem (4). While we focus on using loss-augmented inference for estimating the semi-gradient, it can also be used as the cutting plane [13] and the conditional gradient of the dual of problem (4). In addition to this, loss-augmented inference is also required for solving problem (3) using the direct loss minimization framework [22].", "publication_ref": ["b11", "b26", "b1", "b26", "b4", "b12", "b26", "b12", "b3", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Loss Functions", "text": "While solving problem ( 6) is non-trivial, especially for non-decomposable loss functions, the method we propose in this paper allows for an efficient loss-augmented inference procedure for such complex loss functions. For our discussion, we focus on two specific non-decomposable loss functions. The first is the average precision (AP) loss, which is very popular in the computer vision community as evidenced by its use in the various challenges of PASCAL VOC [8]. The second is the normalized discounted cumulative gain (NDCG) loss, which is very popular in the information retrieval community [6].\nNotation. In order to specify the loss functions, and our efficient algorithms for problem (4), it would be helpful to introduce some additional notation. We define ind(x) to be the index of a sample x according to the ranking R. Note that the notation does not explicitly depend on R as the ranking will always be clear from context. If x \u2208 P (that is, for a positive sample), we define ind + (x) as the index of x in the total order of positive samples induced by R. For example, if x is the highest ranked positive sample then ind + (x) = 1 even though ind(x) need not necessarily be 1 (in the case where some negative samples are ranked higher than x). For a negative sample x \u2208 N , we define ind \u2212 (x) analogously: ind \u2212 (x) is the index of x in the total order of negative samples induced by R. AP Loss. Using the above notation, we can now concisely define the average precision (AP) loss of a proper ranking R given the ground truth ranking R * as follows:\n\u2206 AP (R * , R) = 1 \u2212 1 |P| x\u2208P ind + (x) ind(x) .\nFor example, consider an input X = {x 1 , \u2022 \u2022 \u2022 , x 8 } where x i \u2208 P for 1 \u2264 i \u2264 4, and x i \u2208 N for 5 \u2264 i \u2264 8, that is, the first 4 samples are positive while the last 4 samples are negative. If the proper ranking R induces the order\n(x 1 , x 3 , x 8 , x 4 , x 5 , x 2 , x 6 , x 7 ),(7)\nthen, \u2206 AP (R * , R) = 1\u2212 1 4\n1 1 + 2 2 + 3 4 + 4 6 \u2248 0.146. NDCG Loss. We define a discount 2 D(i) = 1/ log 2 (1+i) for all i = 1, \u2022 \u2022 \u2022 , |N | + |P|.\nThis allows us to obtain a loss function based on the normalized discounted cumulative gain as\n\u2206 N DCG (R * , R) = 1 \u2212 x\u2208P D(ind(x)) |P| i=1 D(i)\n.\nFor example, consider the aforementioned input where the first four samples are positive and the last four samples are negative. For the ranking R that induces the order (7), we can compute\n\u2206 N DCG (R, R) = 1 \u2212 1 + log \u22121 2 3 + log \u22121 2 5 + log \u22121 2 7 1 + log \u22121 2 3 + log \u22121 2 4 + log \u22121 2 5 \u2248 0.056.\nBoth AP loss and NDCG loss are functions of the entire dataset and are not decomposable onto individual samples.", "publication_ref": ["b7", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Quicksort Flavored Optimization", "text": "In order to estimate the parameters w in the ranking framework by solving problem (4), we need to compute the semi-gradient of J(w). To this end, given the current estimate of parameters w, as well as a set of samples X, we are interested in obtaining the most violated ranking by solving problem (6). At first glance, the problem seems to require us to obtain a ranking matrixR. However, it turns out that we do not explicitly require a ranking matrix.\nIn more detail, our algorithm uses an intermediate representation of the ranking using the notion of interleaving ranks. Given a ranking R and a negative sample x, the interleaving rank rank(x) is defined as one plus the number of positive samples preceding x in R. Note that, similar to our notation for ind(\u2022), ind + (\u2022) and ind \u2212 (\u2022), we have dropped the dependency of rank(\u2022) on R as the ranking matrix would be clear from context. The interleaving rank of all the samples does not specify the total ordering of all the samples according to R as it ignores the relative ranking of the positive samples among themselves, and the relative ranking of the negative samples among themselves. However, as will be seen shortly, for a large class of ranking based loss functions, interleaving ranks corresponding to the most violating ranking are sufficient to compute the semi-gradient as in equation (5).\nIn the rest of the section, we discuss the class of loss functions that are amenable to a quicksort flavored algorithm, which we call QS-suitable loss functions. We then describe and analyze our quicksort flavored approach for finding the interleaving rank in some detail. For brevity and simplicity of exposition, in the following sub-section, we restrict our discussion to the properties of QS-suitable loss functions that are necessary for an intuitive explanation of our algorithm. For a thorough discussion on the characterization and properties of QS-suitable loss functions, we refer the interested reader to the full version of the paper [19].", "publication_ref": ["b5", "b4", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "QS-Suitable Loss Functions", "text": "As discussed earlier, many popular rank-based loss functions happen to be non-decomposable. That is, they can not be additively decomposed onto individual samples. However, it turns out that a wide class of such nondecomposable loss functions can be instead additively decomposed onto the negative samples. Formally, for some functions \u03b4 j : {1, . . . , |P| + 1} \u2192 R for j = 1, . . . , |N |, for a proper ranking R one can write\n\u2206(R * , R) = x\u2208N \u03b4 ind \u2212 (x) (rank(x)).\nWe will call this the negative-decomposability property.\nFurther, many of those rank-based loss functions do not depend on the relative order of positive or negative samples among themselves. Rather, the loss for a ranking R, \u2206(R * , R), depends only on the interleaving rank of positive and negative samples corresponding to R. We will call this the interleaving-dependence property.\nAs will be evident later in the section, the above properties in a loss function allows for an efficient quicksort flavored divide and conquer algorithm to solve the loss augmented problem. We formally define the class of loss functions that allow for such a quicksort flavored algorithm as QS-suitable loss functions. The following proposition establishes the usefulness for such a characterization. Proposition 1 Both \u2206 AP and \u2206 N DCG are QS-suitable.\nThe proof of the above proposition is provided in Appendix (supplementary). Having established that both the AP and the NDCG loss are QS-suitable, the rest of the section will deal with a general QS-suitable loss function. A reader who is interested in employing another loss function need only check whether the required conditions are satisfied in order to use our approach.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Key Observations for QS-Suitable Loss", "text": "Before describing our algorithm in detail, we first provide some key observations which enable efficient optimization for QS-suitable loss functions. To this end, let us define an array\n{s + i } |P| i=1 of", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "positive sample scores and an array {s", "text": "\u2212 i } |N |\ni=1 of negative sample scores. Furthermore, for purely notational purposes, let {s * i } be the array {s \u2212 i } sorted in descending order. For j \u2208 {1, . . . |N |} we denote the index of s \u2212 j in {s * i } as j * . With the above notation, we describe some key observations regarding QS-suitable loss functions. Their proofs are for most part straightforward generalizations of results that appeared in [18,27] in the context of the AP loss and can be found in Appendix (Supplementary). Using the interleaving-dependence property of QS-suitable loss functions and structure of the discriminant function as defined in equation (1), we can make the following observation.\nObservation 1 An optimal solutionR of problem (6) would have positive samples appearing in the descending order of their scores s + i and also the negative samples appearing in descending order of their scores s \u2212 i . Now, in order to find the optimal rankingR, it would seem natural to sort the arrays {s + i } and {s \u2212 i } in descending order and then find the optimal interleaving ranks rank(x) for all x \u2208 N . However, we are aiming for complexity below O(|N | log |N |), therefore we can not afford to sort the negative scores. On the other hand, since |P| << |N |, we are allowed to sort the array of positive scores {s + i }. Let opt i be the optimal interleaving rank for the negative sample with the i th rank in the sorted list {s * i } and opt = {opt i |j = 1, . . . , |N |} be the optimal interleaving rank vector. A certain subtle monotonicity property QSsuitable loss functions (see Supplementary) and the structure of the discriminant function given in (1) gives us the opportunity to compute the interleaving rank for each negative sample independently. However, we actually need not do this computation for all the |N | negative samples. This is because, since the interleaving rank for any negative sample can only belong to [1, |P| + 1] and |P| << |N |, many of the negative samples would have the same interleaving rank. This fact can be leveraged to improve the efficiency of the algorithm for finding opt by making use of the following observation. Observation 2 If i < j, then opt i \u2264 opt j . Knowing that opt i = opt j for some i < j, we can conclude that opt i = opt k = opt j for each i < k < j. This provides a cheap way to compute some parts of the vector opt if an appropriate sequence is followed for computing the interleaving ranks. Even without access to the fully sorted set {s * j }, we can still find s * j , the j-highest element in {s \u2212 i }, for a fixed j, in O(|N |) time. This would lead to an O(|P| |N |) algorithm but we may at each step modify {s \u2212 i } slowly introducing the correct order. This will make the future searches for s * j more efficient.", "publication_ref": ["b17", "b26", "b5", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Divide and Conquer", "text": "Algorithm 1 describes the main steps of our approach. Briefly, we begin by detecting s * |N |/2 that is the median score among the negative samples. We use this to compute opt |N |/2 . Given opt |N |/2 , we know that for all j <\n|N | /2, opt j \u2208 [1, opt |N |/2 ] and for all j > |N | /2, opt j \u2208 [opt |N |/2 , |P| + 1]\n. This observation allows us to employ a divide-and-conquer recursive approach.\nIn more detail, we use two classical linear time array manipulating procedures MEDIAN and SELECT. The first one outputs the index of the median element. The second one takes as its input an index of a particular element x. It rearranges the array such that x separates higher-ranked elements from lower-ranked elements (in some total order). Using the two aforementioned procedures in conjunction with the divide-and-conquer strategy allows us to compute Algorithm 1: Recursive procedure for finding all interleaving ranks.\nDescription: The function finds optimal interleaving rank for all i \u2208 [\u2113 \u2212 , r \u2212 ] given that (i) array s \u2212 is partially sorted, namely Find opt m by trying all options in [\u2113\nMAX(s \u2212 [1 . . . \u2113 \u2212 \u2212 1]) \u2264 MIN(s \u2212 [\u2113 \u2212 . . . r \u2212 ]) and MAX(s \u2212 [\u2113 \u2212 . . . r \u2212 ]) \u2264 MIN(s \u2212 [r \u2212 + 1 . . . |N |]); (ii) optimal interleaving ranks for i \u2208 [\u2113 \u2212 , r \u2212 ] lie in the interval [\u2113 + , r + ]. 1 function OptRanks(int \u2113 \u2212 , int r \u2212 , int \u2113 + , int r + ) 2 if \u2113 + = r + then 3 set opt i = \u2113 + for each i \u2208 [\u2113 \u2212 ,\n+ , r + ] 8 if \u2113 \u2212 < m then OptRanks(\u2113 \u2212 , m\u22121, \u2113 + , opt m ) 9 if m < r \u2212 then OptRanks(m+1, r \u2212 , opt m , r + )\nthe entire interleaving rank vector opt and this in turn allows us to compute the semi-gradient \u2207 w J(w), as in equation (5), efficiently. Figure 1 provides an illustrative example of our dividedand-conquer strategy. Here, |N | = 11 and |P| = 2. We assume that the optimal interleaving rank vector opt is [1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3]. Let us now go through the procedure in which Algorithm 1 computes this optimal interleaving rank vector. Before starting the recursive procedure, we only sort the positive samples according to their scores and do not sort the negative samples. To start with, we call OptRanks(1, 11, 1, 3). We find the negative sample with the median score (6 th highest in this case) and compute its optimal interleaving rank opt 6 to be 2. In the next step of the recursion, we make the following calls: OptRanks(1, 5, 1, 2) and OptRanks(7, 11, 2, 3). These calls compute opt 3 and opt 9 to be 2. In the next set of recursion calls however, the calls OptRanks(4, 5, 2, 2) and OptRanks(7, 8, 2, 2), get terminated in step 4 of Algorithm 1 and opt j for j = 4, 5, 7, 8 are assigned without any additional computation. We then continue this procedure recursively for progressively smaller intervals as described in Algorithm 1. Leveraging the fact stated in observation 2, our algorithm has to explicitly compute the interleaving rank for only 6 (shown in square brackets) out of the 11 negative samples. In a typical real data set, which is skewed more in favor of the negative samples, the expected number of negative samples for which is the interleaving rank has to be explicitly computed is far less than |N |. In contrast, the algorithm proposed by Yue et al.\nin [2] [2] [2] [2] [2] [2] 2 2 [2] 2 2 [2] [3] [1] [2] [2] 2 2 [2] 2 2 [2] [3] 3\nFigure 1. Example illustrating the path followed by the quick sort flavored recursive algorithm while computing the interleaving rank vector opt. Row correspond to the status of opt at selected time steps. [27] first sorts the entire negative set in descending order of their scores and explicitly computes the interleaving rank for each of the |N | negative samples.", "publication_ref": ["b26"], "figure_ref": [], "table_ref": []}, {"heading": "Computational Complexity", "text": "The computational complexity of the divide-andconquer strategy to estimate the output of problem (6), is given by the following theorem.  [27] and [18]), it also provides an asymptotic lower bound for comparison based algorithms. However, it does not rule out the possibility of improving the constants hidden within the asymptotic notation for a given loss function. For example, as mentioned earlier, one can exploit the additional structure of the AP loss, as presented in [18], to further speed-up our algorithm.", "publication_ref": ["b5", "b26", "b17", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "We demonstrate the efficacy of our approach on three vision tasks with increasing level of complexity. First, we use the simple experimental setup of doing action classification on the PASCAL VOC 2011 data set using a shallow model. This experimental set up allow us to thoroughly analyze the performance of our method as well as the baselines by varying the sample set sizes. Second, we apply our method to a large scale experiment of doing object detection on the PASCAL VOC 2007 data set using a shallow model. This demonstrates that our approach can be used in conjunction with a large data set consisting of millions of samples. Finally, we demonstrate the effectiveness of our method for layer wise training of a deep network on the task of image classification using the CIFAR-10 data set.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Action Classification", "text": "Data set. We use the PASCAL VOC 2011 [8] action classification data set for our experiments. This data set consists of 4846 images, which include 10 different action classes. The data set is divided into two parts: 3347 'trainval' person bounding boxes and 3363 'test' person bounding boxes. We use the 'trainval' bounding boxes for training since their ground-truth action classes are known. We evaluate the accuracy of the different models on the 'test' bounding boxes using the PASCAL evaluation server.\nModel. We use structured SVM models as discriminant functions and use the standard poselet [17] activation features to define the sample feature for each person bounding box. The feature vector consists of 2400 action poselet activations and 4 object detection scores. We refer the reader to [17] for details regarding the feature vector.\nMethods. We show the effectiveness of our method in optimizing both AP loss and NDCG loss to learn the model parameters. Specifically, we report the computational time for the loss-augmented inference evaluations. For AP loss, we compare our method (referred to as AP QS) with the lossaugmented inference procedure described in [27] (referred to as AP). For NDCG loss, we compare our method (referred to as NDCG QS) with the loss-augmented inference procedure described in [6] (referred to as NDCG). We also report results for loss-augmented inference evaluations when using the simple decomposable 0-1 loss function (referred to as 0-1). The hyperparameters involved are fixed using 5fold cross-validation on the 'trainval' set.\nResults. When we minimize AP loss on the training set to learn the model parameters, we get a mean AP of 51.196 on the test set. In comparison, minimizing 0-1 loss to learn model parameters leads to a mean AP value of 47.934 on the test set. Similarly, minimizing NDCG loss for parameter learning gives a superior mean NDCG value of 85.521 on the test set, compared to that of 84.3823 when using 0-1 loss. The AP and NDCG values obtained on the test set for individual action classes can be found in the supplementary material. This clearly demonstrates the usefulness of directly using rank based loss functions like AP loss and NDCG loss for learning model parameters, instead of using simple decomposable loss functions like 0-1 loss as surrogates.\nThe time required for the loss augmented inference eval-  Total computation time for multiple calls to loss augmented inference during model training, when the number of total, negative and positive samples are varied. Here, 0-1, AP and AP QS correspond to loss augmented inference procedures for 0-1 loss, for AP loss using [27] and for AP loss using our method respectively. It can be seen that our method scales really well with respect to sample set sizes and takes computational time that is comparable to what is required for simpler 0-1 decomposable loss. Here, 0-1, NDCG and NDCG QS correspond to loss augmented inference procedures for 0-1 loss, for NDCG loss using [6] and for NDCG loss using our method respectively. As can be seen, our approach scales elegantly with respect to sample set sizes and is comparable to the simpler 0-1 decomposable loss in terms of computation time.\nuations, while optimizing the different loss functions for learning model parameters, are shown in Table 1. It can be seen that using our method (AP QS, NDCG QS) leads to reduction in computational time by a factor of more than 10, when compared to the methods proposed in [27] and [6] for AP loss and NDCG loss respectively. For AP loss, the method proposed in [18] takes computational time of 0.0985 sec for loss augmented inference. Note that, this method is specific to AP loss, but our more general method is still around 3 times faster. It can also be observed that although the computational time for each call to loss-augmented inference for 0-1 loss is slightly less than that for AP loss and NDCG loss (Table 2), in some cases we observe that we required more calls to optimize the 0-1 loss. As a result, in those cases training using 0-1 loss is slower than training using AP or NDCG loss with our proposed method.\nIn order to understand the effect of the size and composition of the data set on our approaches, we perform 3 experiments with variable number of samples for the action class phoning. First, we vary the total number of samples while fixing the positive to negative ratio to 1 : 10. Second, we vary the number of negative samples while fixing the number of positive samples to 227. Third, we vary the number of positive samples while fixing the number of negative samples to 200. As can be seen in Fig. 2 and Fig. 3, the time required for loss-augmented inference is significantly lower using our approach for both AP and NDCG loss.", "publication_ref": ["b7", "b16", "b16", "b26", "b5", "b26", "b5", "b26", "b5", "b17"], "figure_ref": ["fig_2", "fig_3"], "table_ref": ["tab_1"]}, {"heading": "Object Detection", "text": "Data set. We use the PASCAL VOC 2007 [8] object detection data set, which consists of a total of 9963 images. The data set is divided into a 'trainval' set of 5011 images and a 'test' set of 4952 images. All the images are labeled to indicate the presence or absence of the instances of 20 different object categories. In addition, we are also provided with tight bounding boxes around the object instances, which we ignore during training and testing. Instead, we treat the location of the objects as a latent variable. In order to reduce the latent variable space, we use the selective-search algorithm [26] in its fast mode, which generates an average of 2000 candidate windows per image. This results in a training set size of approximately 10 million bounding boxes.\nModel. For each candidate window, we use a feature representation that is extracted from a trained Convolutional Neural Network (CNN). Specifically, we pass the image as input to the CNN and use the activation vector of the penultimate layer of the CNN as the feature vector. Inspired by the R-CNN pipeline of Girshick et al. [9], we use the CNN that is trained on the ImageNet data set [7], by rescaling each candidate window to a fixed size of 224 \u00d7 224. The length of the resulting feature vector is 4096. However, in contrast to [9], we do not assume ground-truth bounding boxes to be available for training images. We instead optimize AP loss in a weakly supervised framework to learn the parameters of the SVM based object detectors for the 20 object categories.\nMethods. We use our approach to learn the parameters of latent AP-SVMs [2] for each object category. In our experiments, we fix the hyperparameters using 5-fold crossvalidation. During testing, we evaluate each candidate window generated by selective search and use non-maxima suppression to prune highly overlapping detections.\nResults. For this task of weakly supervised object detection, using AP loss for learning model parameters leads to a mean test AP of 36.616 which is significantly better than the 29.4995 obtained using 0-1 loss. The AP values obtained on the test set by the detectors for each object class can be found in the supplementary material. These results establish the usefulness of optimizing AP loss for learning the object detectors. On the other hand, optimizing AP loss for this task places high computational demands due to the size of the data set (5011 'trainval' images) as well as the latent space (2000 candidate windows per image) amounting to around 10 million bounding boxes. We show that using our method for loss-augmented inference (LAI) leads to significant saving in computational time. During training, the total time taken for LAI, averaged over all the 20 classes, was 0.5214 sec for our method which is an order of magnitude better than the 7.623 sec taken by the algorithm proposed in [27]. Thus, using our efficient quicksort flavored algorithm can be critical when optimizing non-decomposable loss functions like AP loss for large scale data sets.", "publication_ref": ["b7", "b25", "b8", "b6", "b8", "b1", "b26"], "figure_ref": [], "table_ref": []}, {"heading": "Image Classification", "text": "Data set. We use the CIFAR-10 data set [15], which consists of a total of 60,000 images of size 32 \u00d7 32 pixels. Each image belongs to one of 10 specified classes. The data set is divided into a 'trainval' set of 50,000 images and a 'test' set of 10,000 images. From the 50,000 'trainval' images, we use 45,000 for training and 5,000 for validation. For our experiments, all the images are centered and normalized.\nModel. We use a deep neural network as our classification model. Specifically, we use a piecewise linear convolutional neural network (PL-CNN) as proposed in [3]. We follow the same framework as [3] for experiments on the CIFAR-10 data set and use a PL-CNN architecture comprising 6 convolutional layers and an SVM last layer. For all our experiments, we use a network that is pre-trained using softmax and cross-entropy loss.\nMethods. We learn the weights of the PL-CNN by optimizing AP loss and NDCG loss for the training data set. For comparison, we also report results for parameter learning using the simple decomposable 0-1 loss. We use the layerwise optimization algorithm called LW-SVM, proposed in [3], for optimizing the different loss functions with respect to the network weights. Following the training regime used in [3], we warm start the optimization with a few epochs of Adadelta [28] before running the layer wise optimization. The LW-SVM algorithm involves solving a structured SVM problem for one layer at a time. This requires tens of thousands of calls to loss augmented inference and having a efficient procedure is therefore critical for scalability. We compare our method for loss-augmented inference with the methods described in [27] and [6], for AP loss and NDCG loss respectively.\nResults. We get a better mean AP of 85.28 on the test set when we directly optimize AP loss for learning network weights compared to that of 84.22 for 0-1 loss. Similarly, directly optimizing NDCG loss leads to a better mean NDCG of 96.14 on the test set compared to 95.31 for 0-1 loss. This establishes the usefulness of optimizing non-decomposable loss functions like the AP loss and NDCG loss. The LW-SVM algorithm involves very high number of calls to the loss augmented inference procedure. In light of this, the efficient method for loss augmented inference proposed in this paper leads to significant reduction in total training time. When optimizing the AP loss, using our method leads to a total training time of 1.589 hrs compared to that of 1.974 hrs for the algorithm proposed in [27]. Similarly, when optimizing NDCG loss, our method leads to a total training time of 1.632 hrs, which is significantly better than the 2.217 hrs taken for training when using the method proposed in [6]. This indicates that using our method helps the layerwise training procedure scale much better.", "publication_ref": ["b14", "b2", "b2", "b2", "b2", "b27", "b26", "b5", "b26", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Discussion", "text": "We provided a characterization of ranking based loss functions that are amenable to a quicksort based optimization algorithm for the loss augmented inference problem. We proved that the our algorithm provides a better computational complexity than the state of the art methods for AP and NDCG loss functions and also established that the complexity of our algorithm cannot be improved upon asymptotically by any comparison based method. We empirically demonstrated the efficacy of our approach on challenging real world vision problems. In future, we would like to explore extending our approach to other ranking based non-decomposable loss functions like those based on the Fmeasure or the mean reciprocal rank.\nwhere C = |P| i=1 D(i). Indeed, one can check that\n\u2206(R * , R) = 1 \u2212 x\u2208P D(ind(x)) |P| i=1 D(i) = 1 C |P| i=1 D(i) \u2212 x\u2208P D(ind + (x) + rank(x) \u2212 1) = 1 C x\u2208N D(ind \u2212 (x)+rank(x)\u22121)\u2212D(|P|+ind \u2212 (x)) = x\u2208N \u03b4 ind \u2212 (x) (rank(x))\nas desired. As for (C2) and (C3), let us realize that\n\u03b4 j (i + 1) \u2212 \u03b4 j (i) = 1 C (D(i + j) \u2212 D(i + j \u2212 1)) .\nThen (C3) becomes trivial and checking (C2) reduces to\nD(i + j + 1) + D(i + j \u2212 1) \u2265 2D(i + j)\nwhich follows from convexity of the function D.\nProposition 4 \u2206 AP is QS-suitable.\nProof. Regarding (C1), the functions \u03b4 j were already identified in [27] as\n\u03b4 j (i) = 1 |P| |P| k=i j j + k \u2212 j \u2212 1 j + k \u2212 1 so after writing \u03b4 j (i + 1) \u2212 \u03b4 j (i) = j \u2212 1 j + i \u2212 1 \u2212 j j + i\nwe again have (C3) for free and (C2) reduces to\n2g i (j) \u2265 g i (j \u2212 1) + g i (j + 1), where g i (x) = x\nx+i , and the conclusion follows from concavity of g i (x) for x > 0.", "publication_ref": ["b26"], "figure_ref": [], "table_ref": []}, {"heading": "Computational Complexity", "text": "Now is the time to establish the computational complexity of Algorithm 1 as well as the afore-mentioned matching lower bound. efficiency. Outside running Algorithm 1, the entire computation also consists of preprocessing (sorting positive samples by their scores) and post processing (computing the output from vector opt). These subroutines have only one non-linear complexity term -O(|P| log |P|) coming from the sorting. Therefore, it remains to establish the complexity of Algorithm 1 as O(|N | log |P| + |P| log |N |).\nTo this end, let us denote n = r \u2212 \u2212 \u2113 \u2212 + 1 and p = r + \u2212 \u2113 + + 1, and set T neg (n, p), T pos (n, p) as the total time spent traversing the arrays of negative and positive sample scores, respectively, including recursive calls. The negative score array is traversed in the MEDIAN and SE-LECT procedures and the positive scores are traversed when searching for opt m . The latter has by complexity O(p), due to Observation 3(c), whose assumption are always satisfied during the run of the algorithm.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proposition 6", "text": "The runtimes T neg (n, p) and T pos (n, p) satisfy the following recursive inequalities Proof. The recursive inequalities follow from inspection of Algorithm 1. As for the \"aggregated\" inequalities, we proceed in both cases by induction. For the first inequality the base step is trivial for high enough constant C \u2032 and for the inductive step we may write\nT neg (n, p) \u2264 Cn + T neg (n/2, p 1 ) + T neg (n/2, p 2 ) for some p 1 + p 2 = p + 1, T pos (n, p) \u2264 Cp + T pos (n/2, p 1 ) + T pos (n/2, p 2 ) for some p 1 + p 2 = p + 1, T neg (n, 1) \u2264 Cn, T neg (1, p) = 0, T pos (n, 1) = 0, T pos (1, p) \u2264 Cp\nT neg (n, p) \u2264 Cn + T neg (n/2, p 1 ) + T neg (n/2, p 2 ) \u2264 Cn + 1 2 C \u2032 n log(1 + p 1 ) + 1 2 C \u2032 n log(1 + p 2 ) = C \u2032 n C C \u2032 + log (1 + p 1 )(1 + p 2 ) \u2264 C \u2032 n log(p 1 + p 2 ) = C \u2032 n log(1 + p)\nwhere in the last inequality we used that\n1 + (1 + p 1 )(1 + p 2 ) \u2264 (p 1 + p 2 ) 2\nfor integers p 1 , p 2 with p 1 +p 2 = p+1 \u2265 3. That makes the last inequality true for sufficiently high C \u2032 (not depending on n and p).\nThe proof of the second inequality is an easier variation on the previous technique.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Lower Bound on Complexity", "text": "In order to prove the matching lower bound (among comparison-based algorithms), we intend to use the classical information theoretical argument: There are many possible outputs and from each comparison we receive one bit of information, therefore we need \"many\" comparison to shatter all output options. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Remaining proofs", "text": "Throughout the text we omitted several proofs, mostly because they are straightforward generalizations of what already appeared in [27] and [6]. For the sake of completeness, we present them here.\nProof of Observation 1 (of main text) : Let R be any optimal solution. We check that F (X, R; w) increases if we swap two samples x, y \u2208 P in R with ind(x) < ind(y) and \u03c6(x; w) < \u03c6(y; w) (it boils down to ac + bd > ad + bc for a > b \u2265 0 and c > d \u2265 0). Since similar argument applies for negative samples, we can conclude that R already has both negative and positive samples sorted decreasingly. Otherwise, one could perform swaps in R that would increase the value of the objective, a contradiction with the optimality of R.\nProof of Observation 2 (of main text) : Recall that opt j is the highest rank with maximal value of the corresponding f j \u2032 . It suffices to prove that for i j+1 = max argmax f j+1 and i j = max argmax f j , we have i j+1 \u2265 i j . Since by Observation 3 functions f j inherit property (C2), we can compare the discrete derivatives of f j and f j+1 , all left to do is to formalize the discrete analogue of what seems intuitive for continuous functions. Assume i j+1 < i j . Then since\nf j+1 (i j ) \u2212 f j+1 (i j+1 ) = ij \u22121 i=ij+1 f j+1 (i + 1) \u2212 f j+1 (i) \u2265 ij \u22121 i=ij+1 f j (i + 1) \u2212 f j (i) = f j (i j ) \u2212 f j (i j+1 ) \u2265 0,\nwe obtain that i j \u2208 argmax f j+1 and as i j > i j+1 = max argmax f j+1 and we reached the expected contradiction.", "publication_ref": ["b26", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Lemma 8", "text": "The objective function F (X, R; w) decomposes into contributions of negative and positive samples as follows: In particular, assuming already that {s + i } is sorted, and that R is induced by a vector of interleaving ranks r, one has\nF (X, R; w) = 1 |P| |N | x\u2208P y\u2208N\nF (X, R; w) = |P| i=1 c + i s + i + |N | j=1 c \u2212 j s * j ,\nwhere\nc + i = |N | + 2 \u2212 2r + i |P| |N | , c \u2212 j = |P| + 2 \u2212 2r j |P| |N | .\nHere r + i stands for the interleaving rank of the i-th positive sample, which can be computed as r\n+ i = 1 + |{j : r j \u2264 i}|.\nProof. This is straightforward to verify with a short computation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proof of Observation 3:", "text": "We slightly modify the decomposition from Lemma 8 in order to incorporate the array {s + i }:\nF (X, R; w) = y\u2208N c(y)\u03c6(y; w) + x\u2208P R x,y \u03c6(x; w) = 1 |N | |P| |N | j=1 \uf8eb \uf8ed (|P|+2\u22122r j )s * j +2 rj\u22121 i=1 s + i \u2212 |P| i=1 s + i \uf8f6 \uf8f8 .\nThis, in combination with (C1), defines the functions f j for j = 1, . . . , |N |. As for the condition (C2), we have\nf j (i + 1) \u2212 f j (i) = 2(s + i \u2212 s * j ) |N | |P| + \u03b4 j (i + 1) \u2212 \u03b4 j (i),\nwhere, let us be reminded, {s * j } is the sorted array of scores of negative samples. After writing analogous equality for j + 1 and using that (C2) holds for functions \u03b4 j , we can check that the desired inequality\nf j+1 (i + 1) \u2212 f j+1 (i) \u2265 f j (i + 1) \u2212 f j (i)\nfollows from s * j+1 \u2264 s * j . Note that for computing the argmax f j (i) it is sufficient to compute all discrete derivatives (i.e. all the differences f j (i + 1) \u2212 f j (i)); the actual values of f j are in fact not needed. For \u03b4 j we know that one such evaluation is constant time and for f j this is also the case since we assumed to have access to s * j .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "NDCG and Discount Functions", "text": "Chakrabarti et al. [6] use a slightly modified definition of the discount D(\u2022) as However, with the above definition of a discount, it is possible to obtain a corner-case where their proof of correctness of the greedy algorithm is not valid (specifically, there exists a counter-example for Fact 3.4 of [6]). For the greedy algorithm to be correct, it turns out that the convexity of D(i) is essential.\nD(i) = 1 1 \u2264 i \u2264 2 1/ log 2 (i) i > 2 .\nRemark 1 Observation 2 is not true for \u2206 N DCG with function D(i) taken as\nD(i) = 1 1 \u2264 i \u2264 2 1/ log 2 (i) i > 2 .\nProof. Consider negative samples x 1 and x 2 and a positive sample x 3 with scores s 1 = 3\u03b5, s 2 = \u03b5, s 3 = 5\u03b5, where \u03b5 > 0 is small. Note that the NDCG loss of a ranking R reduces to \u2206 N DCG (R * , R) = 1 \u2212 D(ind(x 3 )) where we used the fact that D(1) = 1.\nThe decomposition \u2206 N DCG (R * , R) = \u03b4 1 (r 1 ) + \u03b4 2 (r 2 ) holds if we set Hence opt 1 = 2 > 1 = opt 2 , a contradiction. ", "publication_ref": ["b5", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Additional Experimental Results", "text": "For the action classification experiments on the PASCAL VOC 2011 data set, we report the performance of models trained by optimizing 0-1 loss as well as AP loss in Table 3. Specifically, we report the AP on the test set for each of the 10 action classes. Similarly, we also report the performance of models trained by optimizing 0-1 loss as well as NDCG loss, in terms of NDCG on the test set in Table 4.\nFor our object detection experiments, we report the detection AP in Table 5 for all the 20 object categories obtained by models trained using 0-1 loss as well as AP loss. For all object categories other than 'bottle', AP loss based training does better than that with 0-1 loss. For 15 of the 20 object categories, we get statistically significant improvement with AP loss trained models compared to those trained using 0-1 loss (using paired t-test with p-value less than 0.05). While optimizing AP loss for learning gives an overall improvement of 7.12% compared to when using 0-1 loss, for 5 classes it gives an improvement of more than 10%. The bottom 2 classes with the least improvement obtained by AP loss based training, 'chair' and 'bottle' seem to be difficult object categories to detect, with detectors registering very low detection APs. In conjunction with the overall superior performance of AP loss for learning model parameters, the efficient method proposed by this paper makes a good case for optimizing AP loss rather than 0-1 loss for tasks like object detection.  ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_4", "tab_5", "tab_2"]}, {"heading": "Appendix", "text": "The supplementary material is organized as follows. In Section 1, we give a full definition of QS-suitable loss functions and in Section 2 we justify the correctness of Algorithm 1. Section 3 contains proofs of QS-suitability of AP and NDCG losses and Section 4 establishes worst-case complexity of Algorithm 1 as well as a matching lower-bound on the complexity of solving Problem (6). Several remaining proofs are delegated to Section 5 and we use Section 6 for certain clarifications regarding previous use of NDCG in the literature. Finally, we report some additional experimental results in Section 7.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": []}, {"heading": "Complete characterization of QS-Suitable Loss Functions", "text": "A proper loss function \u2206 = \u2206(R * , R) is called QSsuitable if it meets the following three conditions.\n(C1) Negative decomposability with interleaving dependence. There are functions \u03b4 j : {1, . . . , |P| + 1} \u2192 R for j = 1, . . . , |N | such that for a proper ranking R one can write\n(C2) j-monotonicity of discrete derivative. For every 1 \u2264 j < |N | and 1 \u2264 i \u2264 |P| we have\n(C3) Fast evaluation of discrete derivative. For any j \u2208 {1, . . . , |N |} and i \u2208 {1, . . . , |P|}, can the value \u03b4 j (i + 1) \u2212 \u03b4 j (i) be computed in constant time.\nFrom (C1), we can see that the loss function depends only on the interleaving ranks of the negative samples. More accurately, it depends on the vector r = (r 1 , . . . , r |N | ) where r i is the interleaving rank of the i-th most relevant negative sample (i.e. with the i-th highest score).\nAnother way to interpret this type of dependence is by looking at the \u00b1-pattern of a ranking which can be obtained as follows. Given a proper ranking R (in the form of a permutation of samples), it is the pattern obtained by replacing each positive sample with a \"+\" symbol and each negative sample with a \"\u2212\" symbol. It is easy to see that the \u00b1pattern uniquely determines the vector r and vice versa and thus (C1) also implies dependence on the \u00b1-pattern.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Justification of Algorithm 1", "text": "First key point is that the entire objective function (6) inherits properties (C1) and (C2).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Observation 3 The following holds:", "text": "(a) There are functions f j : {1, . . . , |P| + 1} \u2192 R for j = 1, . . . , |N | such that the objective function in ( 6) can be written as\nwhere r j is the interleaving rank of the negative sample x with ind \u2212 (x) = j.\n(b) The functions f j inherit property (C2). More precisely, for every 1 \u2264 j < |N | and 1 \u2264 i \u2264 |P| we have\n(c) We can compute argmax l\u2264i\u2264r f j (i) in O(r \u2212 l) time if we are provided access to the sorted array {s + i } and to the score of the negative sample x with ind \u2212 (x) = j.\nAs a result, solving Problem (6) reduces to computing the optimal interleaving ranks (or the optimal vector r from the remark above) 3 .\nThe next vital point is that these interleaving ranks can be optimized independently. This is however not obvious. One certainly can maximize each f j but the resulting vector r may not induce any ranking -its entries may not be monotone.\nBut as a matter of fact, this does not happen and Observation 2 from the main text gives the precise guarantee. This \"correctness of greedy maximization\" hinges upon condition (C2) as will also be demonstrated with a counterexample given later in Section 6.\nAll in all, it suffices to compute the vector opt in which opt j = max argmax f j (the maximum ensures that ties are broken consistently) as is done in the main text of the paper.", "publication_ref": ["b2"], "figure_ref": [], "table_ref": []}, {"heading": "Properties of \u2206 AP and \u2206 N DCG", "text": "In this place, let us prove the aforementioned properties of \u2206 AP and \u2206 N DCG .\nProposition 3 \u2206 N DCG is QS-suitable.\nProof. As for (C1), let us first verify that the functions \u03b4 j can be set as \u03b4 j (i) = 1 C (D(i + j \u2212 1) \u2212 D(|P| + j)) ,", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Automatic combination of multiple ranked retrieval systems", "journal": "", "year": "1994", "authors": "B Bartell; G Cottrell; R Belew"}, {"ref_id": "b1", "title": "Optimizing average precision using weakly supervised data", "journal": "", "year": "2014", "authors": "A Behl; C V Jawahar; M P Kumar"}, {"ref_id": "b2", "title": "Trusting SVM for piecewise linear CNNs", "journal": "", "year": "2017", "authors": "L Berrada; A Zisserman; M P Kumar"}, {"ref_id": "b3", "title": "Learning to rank with nonsmooth cost functions", "journal": "", "year": "2007", "authors": "C Burges; R Ragno; Q V Le"}, {"ref_id": "b4", "title": "Ensemble selection from libraries of models", "journal": "ACM", "year": "2004", "authors": "R Caruana; A Niculescu-Mizil; G Crew; A Ksikes"}, {"ref_id": "b5", "title": "Structured learning for non-smooth ranking losses", "journal": "", "year": "2008", "authors": "S Chakrabarti; R Khanna; U Sawant; C Bhattacharyya"}, {"ref_id": "b6", "title": "Imagenet: A large-scale hierarchical image database", "journal": "", "year": "2009", "authors": "J Deng; W Dong; R Socher; L.-J Li; K Li; L Fei-Fei"}, {"ref_id": "b7", "title": "The PASCAL visual object classes (VOC) challenge. IJCV", "journal": "", "year": "2010", "authors": "M Everingham; L Van Gool; C Williams; J Winn; A Zisserman"}, {"ref_id": "b8", "title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "journal": "", "year": "2014", "authors": "R Girshick; J Donahue; T Darrell; J Malik"}, {"ref_id": "b9", "title": "Direct loss minimization for structured prediction", "journal": "", "year": "2010", "authors": "T Hazan; J Keshet; D Mcallester"}, {"ref_id": "b10", "title": "Optimising area under the ROC curve using gradient descent", "journal": "ACM", "year": "2004", "authors": "A Herschtal; B Raskutti"}, {"ref_id": "b11", "title": "A support vector method for multivariate performance measures", "journal": "", "year": "2005", "authors": "T Joachims"}, {"ref_id": "b12", "title": "Cutting-plane training for structural SVMs", "journal": "JMLR", "year": "2009", "authors": "T Joachims; T Finley; C Yu"}, {"ref_id": "b13", "title": "Minimizing structural risk on decision tree classification", "journal": "Springer", "year": "2006", "authors": "D Kim"}, {"ref_id": "b14", "title": "Learning multiple layers of features from tiny images", "journal": "", "year": "", "authors": "A Krizhevsky"}, {"ref_id": "b15", "title": "Support vector machines for classification in nonstandard situations", "journal": "Machine learning", "year": "2002", "authors": "Y Lin; Y Lee; G Wahba"}, {"ref_id": "b16", "title": "Action recognition from a distributed representation of pose and appearance", "journal": "", "year": "2011", "authors": "S Maji; L Bourdev; J Malik"}, {"ref_id": "b17", "title": "Efficient optimization for average precision SVM", "journal": "", "year": "2007", "authors": "P Mohapatra; C V Jawahar; M P Kumar"}, {"ref_id": "b18", "title": "Efficient optimization for rank-based loss functions", "journal": "", "year": "", "authors": "P Mohapatra; M Rolinek; C Jawahar; V Kolmogorov; M Kumar"}, {"ref_id": "b19", "title": "Combining statistical learning with a knowledge-based approach: a case study in intensive care monitoring", "journal": "", "year": "1999", "authors": "K Morik; P Brockhausen; T Joachims"}, {"ref_id": "b20", "title": "Totally corrective boosting for regularized risk minimization", "journal": "", "year": "2010", "authors": "C Shen; H Li; N Barnes"}, {"ref_id": "b21", "title": "Training deep neural networks via direct loss minimization", "journal": "", "year": "2016", "authors": "Y Song; A Schwing; R Zemel; R Urtasun"}, {"ref_id": "b22", "title": "Deep neural networks for object detection", "journal": "", "year": "2013", "authors": "C Szegedy; A Toshev; D Erhan"}, {"ref_id": "b23", "title": "Max-margin Markov networks", "journal": "", "year": "2003", "authors": "B Taskar; C Guestrin; D Koller"}, {"ref_id": "b24", "title": "Support vector machine learning for interdependent and structured output spaces", "journal": "", "year": "2004", "authors": "I Tsochantaridis; T Hofmann; Y Altun; T Joachims"}, {"ref_id": "b25", "title": "Selective search for object recognition", "journal": "IJCV", "year": "2013", "authors": "J Uijlings; K Van De Sande; T Gevers; A Smeulders"}, {"ref_id": "b26", "title": "A support vector method for optimizing average precision", "journal": "", "year": "2007", "authors": "Y Yue; T Finley; F Radlinski; T Joachims"}, {"ref_id": "b27", "title": "ADADELTA: an adaptive learning rate method", "journal": "", "year": "2012", "authors": "M Zeiler"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "For example, if array s \u2212 contains six scores [a b 4.5 6 1 c] then Median(3, 5) would return 3 (the index of score 4.5), while calling Select(3, 3, 5) would rearrange the array to [a b 1 4.5 6 c] and return 4 (the new index of 4.5). The SE-LECT procedure is a subroutine of the classical QUICKSORT algorithm.", "figure_data": ""}, {"figure_label": "456", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "r \u2212 ] and return 4 end 5 m 6 m456= Median(\u2113 \u2212 , r \u2212 ) \u22b2 gives the index of the median score in a subarray of s \u2212 = Select(m, \u2113 \u2212 , r \u2212 ) \u22b2 splits the subarray by s = s \u2212 [m], returns the new index of s 7", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 .2Figure2. Total computation time for multiple calls to loss augmented inference during model training, when the number of total, negative and positive samples are varied. Here, 0-1, AP and AP QS correspond to loss augmented inference procedures for 0-1 loss, for AP loss using[27] and for AP loss using our method respectively. It can be seen that our method scales really well with respect to sample set sizes and takes computational time that is comparable to what is required for simpler 0-1 decomposable loss.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 .3Figure 3. Total computation time for multiple calls to loss augmented inference during model training, when the number of total, negative and positive samples are varied. Here, 0-1, NDCG and NDCG QS correspond to loss augmented inference procedures for 0-1 loss, for NDCG loss using[6] and for NDCG loss using our method respectively. As can be seen, our approach scales elegantly with respect to sample set sizes and is comparable to the simpler 0-1 decomposable loss in terms of computation time.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "for a suitable constant C. These inequalities imply T neg (n, p) \u2264 C \u2032 n log(1 + p) and T pos (n, p) \u2264 C \u2032 (p \u2212 1) log(1 + n) for another constant C \u2032 . Thus the running time of Algorithm 1, where p = |P| + 1, n = |N |, is O(|N | log |P| + |P| log |N |).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Rx,y (\u03c6(x; w) \u2212 \u03c6(y; w)) = x\u2208P c(x)\u03c6(x; w) + y\u2208N c(y)\u03c6(y; w), where c(x) = |N | + 2\u22122rank(x) |P| |N | , c(y) = |P| + 2\u22122rank(y) |P| |N | .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Forthe resulting NDCG loss, a greedy algorithm is proposed for solving the loss augmented inference problem. This algorithm achieves the runtime of O(|N | |P| + |N | log |N |). The authors also suggest to use a cut-off k in the definition of discount D(i), setting D(i) = 0 for i \u2265 k. With this simplification they achieved a reduced complexity of O((|N | + |P|) log(|P| + |N |) + k 2 ).", "figure_data": ""}, {"figure_label": "11213112311212", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "\u03b4 1 ( 1 ) 2 (s 1 \u2212 s 3 ) + \u03b4 1 ( 1 ) = \u2212\u03b5 < \u03b5 = 1 2 (s 3 \u2212 s 1 ) + \u03b4 1 ( 2 ) = f 1 2 \u221211213112311212= \u03b4 2 (1) = 0, \u03b4 2 (1) = D(2) \u2212 D(3), \u03b4 1 (2) = D(1) \u2212 D(2) = 0and (possibly by looking at the proof of Observation 3) we also find values of f 1 and f 2 asf 1 (1) = 1 s 3 ) + \u03b4 2 (1) = \u22122\u03b5 + D(2) \u2212 D(3) > 2\u03b5 = 1 2 (s 3 \u2212 s 2 ) + \u03b4 2 (2) = f 2 (2).", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Theorem 2 If \u2206 is QS-suitable, then the task (6) can be solved in time O(|N | log |P| + |P| log |P| + |P| log |N |), which in the most common case |N | > |P| reduces to O(|N | log |P|) and any comparison-based algorithm would require \u2126(|N | log |P|) operations.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "", "figure_data": "0-1APAP QSNDCGNDCG QS0.06940.71540.06256.80190.0473Table 1. Total computation time (in seconds) when using the differ-ent methods, for multiple calls to loss augmented inference duringmodel training. The reported time is averaged over the trainingfor all the action classes.0-1APAP QSNDCGNDCG QS0.48\u00b10.0316.29\u00b10.181.48\u00b10.3971.07\u00b11.570.55\u00b10.11"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "If \u2206 is QS-suitable, then the Problem (6) can be solved in time O(|N | log |P|+|P| log |P|+|P| log |N |), which in the most common case |N | > |P| reduces to O(|N | log |P|).", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Since the negative samples are unsorted on the input and the scores are arbitrary, every possible mapping from {1, . . . , |N |} to {1, . . . , |P| + 1} may induce the (unique) optimal assignment of interleaving ranks. There are (|P| + 1) |N | possibilities to be distinguished and each comparison has only two possible outcomes. Therefore we need log 2 (|P| + 1)", "figure_data": "Proposition 7 Let \u2206 be a loss function. Then anycomparison-based algorithm for Problem (6) requires\u2126(|N | log |P|) operations.Proof."}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Performance of classification models trained by optimizing 0-1 loss and AP loss, in terms of AP on the test set for the different action classes of PASCAL VOC 2011 action dataset.", "figure_data": "Object class0-1 loss AP lossJumping52.580 55.230Phoning32.090 32.630Playing instrument 35.210 41.180Reading27.410 26.600Riding bike72.240 81.060Running73.090 76.850Taking photo21.880 25.980Using computer30.620 32.050Walking54.400 57.090Riding horse79.820 83.290"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Performance of classification models trained by optimizing 0-1 loss and NDCG loss, in terms of NDCG on the test set for the different action classes of PASCAL VOC 2011 action dataset. We conduct 5-fold cross-validation and report the mean NDCG over the five validation sets.", "figure_data": "Object class0-1 loss NDCG lossJumping86.40987.895Phoning73.13476.733Playing instrument 81.53383.666Reading74.52875.588Riding bike94.92895.958Running93.76693.776Taking photo74.05876.701Using computer79.51878.276Walking89.78989.742Riding horse96.16096.875Object category 0-1 loss AP lossAeroplane46.6048.18Bicycle48.5361.45Bird33.3136.73Boat15.2319.66Bottle6.101.01Bus37.0149.51Car61.2866.78Cat38.1240.77Chair2.713.23Cow21.0638.52Dining-table14.2039.53Dog33.5536.25Horse46.1453.86Motorbike29.9734.81Person29.5830.41Potted-plant21.2723.03Sheep11.6532.20Sofa36.6642.03Train29.7137.10TV-monitor27.3137.26"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Performance of detection models trained by optimizing 0-1 loss and AP loss, in terms of AP on the test set for the different object categories of PASCAL VOC 2007 test set.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "F (X, R; w) = 1 |P| |N | x\u2208P y\u2208N R x,y (\u03c6(x; w)\u2212\u03c6(y; w)).", "formula_coordinates": [2.0, 308.88, 518.37, 238.68, 27.47]}, {"formula_id": "formula_1", "formula_text": "R(w) = argmax R F (X, R; w). (2", "formula_coordinates": [2.0, 364.44, 654.57, 176.89, 17.27]}, {"formula_id": "formula_2", "formula_text": ")", "formula_coordinates": [2.0, 541.33, 655.31, 3.91, 8.91]}, {"formula_id": "formula_3", "formula_text": "w * = min w E[\u2206(R * , R(w))].(3)", "formula_coordinates": [3.0, 109.32, 212.35, 177.2, 16.93]}, {"formula_id": "formula_4", "formula_text": "w * = min w E[J(w)](4)", "formula_coordinates": [3.0, 131.76, 394.75, 154.76, 16.93]}, {"formula_id": "formula_6", "formula_text": "\u2206 AP (R * , R) = 1 \u2212 1 |P| x\u2208P ind + (x) ind(x) .", "formula_coordinates": [3.0, 346.56, 437.57, 160.8, 28.82]}, {"formula_id": "formula_7", "formula_text": "(x 1 , x 3 , x 8 , x 4 , x 5 , x 2 , x 6 , x 7 ),(7)", "formula_coordinates": [3.0, 364.2, 524.61, 181.04, 10.65]}, {"formula_id": "formula_8", "formula_text": "1 1 + 2 2 + 3 4 + 4 6 \u2248 0.146. NDCG Loss. We define a discount 2 D(i) = 1/ log 2 (1+i) for all i = 1, \u2022 \u2022 \u2022 , |N | + |P|.", "formula_coordinates": [3.0, 308.88, 544.17, 236.4, 56.04]}, {"formula_id": "formula_9", "formula_text": "\u2206 N DCG (R * , R) = 1 \u2212 x\u2208P D(ind(x)) |P| i=1 D(i)", "formula_coordinates": [3.0, 337.92, 620.85, 174.14, 28.77]}, {"formula_id": "formula_10", "formula_text": "\u2206 N DCG (R, R) = 1 \u2212 1 + log \u22121 2 3 + log \u22121 2 5 + log \u22121 2 7 1 + log \u22121 2 3 + log \u22121 2 4 + log \u22121 2 5 \u2248 0.056.", "formula_coordinates": [4.0, 50.16, 99.19, 229.44, 39.86]}, {"formula_id": "formula_11", "formula_text": "\u2206(R * , R) = x\u2208N \u03b4 ind \u2212 (x) (rank(x)).", "formula_coordinates": [4.0, 349.8, 102.07, 154.2, 22.93]}, {"formula_id": "formula_12", "formula_text": "{s + i } |P| i=1 of", "formula_coordinates": [4.0, 385.92, 460.99, 46.52, 15.24]}, {"formula_id": "formula_13", "formula_text": "\u2212 i } |N |", "formula_coordinates": [4.0, 354.36, 475.27, 23.96, 15.12]}, {"formula_id": "formula_14", "formula_text": "|N | /2, opt j \u2208 [1, opt |N |/2 ] and for all j > |N | /2, opt j \u2208 [opt |N |/2 , |P| + 1]", "formula_coordinates": [5.0, 50.16, 500.0, 236.37, 35.26]}, {"formula_id": "formula_15", "formula_text": "MAX(s \u2212 [1 . . . \u2113 \u2212 \u2212 1]) \u2264 MIN(s \u2212 [\u2113 \u2212 . . . r \u2212 ]) and MAX(s \u2212 [\u2113 \u2212 . . . r \u2212 ]) \u2264 MIN(s \u2212 [r \u2212 + 1 . . . |N |]); (ii) optimal interleaving ranks for i \u2208 [\u2113 \u2212 , r \u2212 ] lie in the interval [\u2113 + , r + ]. 1 function OptRanks(int \u2113 \u2212 , int r \u2212 , int \u2113 + , int r + ) 2 if \u2113 + = r + then 3 set opt i = \u2113 + for each i \u2208 [\u2113 \u2212 ,", "formula_coordinates": [5.0, 312.24, 137.23, 214.86, 87.0]}, {"formula_id": "formula_16", "formula_text": "+ , r + ] 8 if \u2113 \u2212 < m then OptRanks(\u2113 \u2212 , m\u22121, \u2113 + , opt m ) 9 if m < r \u2212 then OptRanks(m+1, r \u2212 , opt m , r + )", "formula_coordinates": [5.0, 312.36, 283.85, 224.48, 36.01]}, {"formula_id": "formula_17", "formula_text": "in [2] [2] [2] [2] [2] [2] 2 2 [2] 2 2 [2] [3] [1] [2] [2] 2 2 [2] 2 2 [2] [3] 3", "formula_coordinates": [5.0, 537.36, 704.27, 7.74, 8.91]}, {"formula_id": "formula_18", "formula_text": "\u2206(R * , R) = 1 \u2212 x\u2208P D(ind(x)) |P| i=1 D(i) = 1 C |P| i=1 D(i) \u2212 x\u2208P D(ind + (x) + rank(x) \u2212 1) = 1 C x\u2208N D(ind \u2212 (x)+rank(x)\u22121)\u2212D(|P|+ind \u2212 (x)) = x\u2208N \u03b4 ind \u2212 (x) (rank(x))", "formula_coordinates": [10.0, 54.24, 95.23, 227.91, 139.45]}, {"formula_id": "formula_19", "formula_text": "\u03b4 j (i + 1) \u2212 \u03b4 j (i) = 1 C (D(i + j) \u2212 D(i + j \u2212 1)) .", "formula_coordinates": [10.0, 63.84, 265.41, 208.8, 23.52]}, {"formula_id": "formula_20", "formula_text": "D(i + j + 1) + D(i + j \u2212 1) \u2265 2D(i + j)", "formula_coordinates": [10.0, 81.0, 319.64, 174.51, 10.21]}, {"formula_id": "formula_21", "formula_text": "\u03b4 j (i) = 1 |P| |P| k=i j j + k \u2212 j \u2212 1 j + k \u2212 1 so after writing \u03b4 j (i + 1) \u2212 \u03b4 j (i) = j \u2212 1 j + i \u2212 1 \u2212 j j + i", "formula_coordinates": [10.0, 50.16, 422.35, 195.31, 86.54]}, {"formula_id": "formula_22", "formula_text": "2g i (j) \u2265 g i (j \u2212 1) + g i (j + 1), where g i (x) = x", "formula_coordinates": [10.0, 50.16, 541.52, 182.64, 33.34]}, {"formula_id": "formula_23", "formula_text": "T neg (n, p) \u2264 Cn + T neg (n/2, p 1 ) + T neg (n/2, p 2 ) for some p 1 + p 2 = p + 1, T pos (n, p) \u2264 Cp + T pos (n/2, p 1 ) + T pos (n/2, p 2 ) for some p 1 + p 2 = p + 1, T neg (n, 1) \u2264 Cn, T neg (1, p) = 0, T pos (n, 1) = 0, T pos (1, p) \u2264 Cp", "formula_coordinates": [10.0, 309.0, 299.72, 236.04, 85.66]}, {"formula_id": "formula_24", "formula_text": "T neg (n, p) \u2264 Cn + T neg (n/2, p 1 ) + T neg (n/2, p 2 ) \u2264 Cn + 1 2 C \u2032 n log(1 + p 1 ) + 1 2 C \u2032 n log(1 + p 2 ) = C \u2032 n C C \u2032 + log (1 + p 1 )(1 + p 2 ) \u2264 C \u2032 n log(p 1 + p 2 ) = C \u2032 n log(1 + p)", "formula_coordinates": [10.0, 308.88, 536.36, 239.55, 78.7]}, {"formula_id": "formula_25", "formula_text": "1 + (1 + p 1 )(1 + p 2 ) \u2264 (p 1 + p 2 ) 2", "formula_coordinates": [10.0, 355.68, 636.77, 142.09, 12.49]}, {"formula_id": "formula_26", "formula_text": "f j+1 (i j ) \u2212 f j+1 (i j+1 ) = ij \u22121 i=ij+1 f j+1 (i + 1) \u2212 f j+1 (i) \u2265 ij \u22121 i=ij+1 f j (i + 1) \u2212 f j (i) = f j (i j ) \u2212 f j (i j+1 ) \u2265 0,", "formula_coordinates": [11.0, 316.8, 92.95, 220.35, 87.12]}, {"formula_id": "formula_27", "formula_text": "F (X, R; w) = 1 |P| |N | x\u2208P y\u2208N", "formula_coordinates": [11.0, 308.88, 278.25, 131.8, 27.47]}, {"formula_id": "formula_28", "formula_text": "F (X, R; w) = |P| i=1 c + i s + i + |N | j=1 c \u2212 j s * j ,", "formula_coordinates": [11.0, 350.52, 432.91, 152.88, 32.28]}, {"formula_id": "formula_29", "formula_text": "c + i = |N | + 2 \u2212 2r + i |P| |N | , c \u2212 j = |P| + 2 \u2212 2r j |P| |N | .", "formula_coordinates": [11.0, 328.2, 489.53, 197.64, 25.6]}, {"formula_id": "formula_30", "formula_text": "+ i = 1 + |{j : r j \u2264 i}|.", "formula_coordinates": [11.0, 452.76, 537.05, 92.49, 13.93]}, {"formula_id": "formula_31", "formula_text": "F (X, R; w) = y\u2208N c(y)\u03c6(y; w) + x\u2208P R x,y \u03c6(x; w) = 1 |N | |P| |N | j=1 \uf8eb \uf8ed (|P|+2\u22122r j )s * j +2 rj\u22121 i=1 s + i \u2212 |P| i=1 s + i \uf8f6 \uf8f8 .", "formula_coordinates": [11.0, 312.0, 624.45, 229.92, 84.58]}, {"formula_id": "formula_32", "formula_text": "f j (i + 1) \u2212 f j (i) = 2(s + i \u2212 s * j ) |N | |P| + \u03b4 j (i + 1) \u2212 \u03b4 j (i),", "formula_coordinates": [12.0, 60.84, 105.77, 214.8, 26.68]}, {"formula_id": "formula_33", "formula_text": "f j+1 (i + 1) \u2212 f j+1 (i) \u2265 f j (i + 1) \u2212 f j (i)", "formula_coordinates": [12.0, 81.72, 199.64, 173.07, 10.9]}, {"formula_id": "formula_34", "formula_text": "D(i) = 1 1 \u2264 i \u2264 2 1/ log 2 (i) i > 2 .", "formula_coordinates": [12.0, 89.88, 370.64, 156.72, 26.26]}, {"formula_id": "formula_35", "formula_text": "D(i) = 1 1 \u2264 i \u2264 2 1/ log 2 (i) i > 2 .", "formula_coordinates": [12.0, 89.88, 607.16, 156.72, 26.26]}], "doi": ""}