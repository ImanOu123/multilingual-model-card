{"title": "Learning Causal Effects on Hypergraphs", "authors": "Jing Ma; Mengting Wan; Longqi Yang; Jundong Li; Brent Hecht; Jaime Teevan", "pub_date": "2022-07-07", "abstract": "Hypergraphs provide an effective abstraction for modeling multiway group interactions among nodes, where each hyperedge can connect any number of nodes. Different from most existing studies which leverage statistical dependencies, we study hypergraphs from the perspective of causality. Specifically, in this paper, we focus on the problem of individual treatment effect (ITE) estimation on hypergraphs, aiming to estimate how much an intervention (e.g., wearing face covering) would causally affect an outcome (e.g., COVID-19 infection) of each individual node. Existing works on ITE estimation either assume that the outcome on one individual should not be influenced by the treatment assignments on other individuals (i.e., no interference), or assume the interference only exists between pairs of connected individuals in an ordinary graph. We argue that these assumptions can be unrealistic on real-world hypergraphs, where higher-order interference can affect the ultimate ITE estimations due to the presence of group interactions. In this work, we investigate high-order interference modeling, and propose a new causality learning framework powered by hypergraph neural networks. Extensive experiments on real-world hypergraphs verify the superiority of our framework over existing baselines.", "sections": [{"heading": "WhatsApp or WeChat, and workplace interactions on Microsoft", "text": "Teams or Slack channels. Although the conventional pairwise graph definition covers a vast number of applications (e.g., person-toperson physical contact networks or social networks [10]), it fails to capture the complete information of these group interactions (where each interaction may involve more than two individuals) [5,13,44]. The notion of the hypergraph can thus be introduced to address this limitation. Consider a hypergraph example that individuals are connected via in-person social events, each gathering event can be represented as a hyperedge (Fig. 1a). Each hyperedge can connect an arbitrary number of individuals, in contrast to an ordinary edge which connects exactly two nodes (Fig. 1b). While many studies have been devoted to utilizing such a generalized hypergraph structure to facilitate machine learning tasks [5,13,44,52], the majority were still executed at the statistical correlation level, e.g., predicting the COVID-19 infection risk on each individual (node) by capturing the correlations between one's demographic information (node features), in-person group gathering history (hypergraph structure) and the infection outcomes (node labels). A critical limitation here is the lack of causality, which is particularly important for understanding the impact of a policy intervention (e.g., wearing face covering) on an outcome of interest (e.g., COVID-19 infection). For individuals connected as in Fig. 1a, one may ask \"how would each individual's face covering practice (treatment) causally influence their infection risk (outcome)?\" Such a causal inference task requires constructing the counterfactual state of the same individual by holding all other possible factors constant except the treatment variable of interest. This is a particularly hard problem on hypergraph data, since the outcome of each individual is not only affected by their own confounding factors (e.g., one's health conditions and vaccine status) but also interfered by other individuals on the hypergraph (e.g., face covering practice of other individuals who may physically contact the target individual through a gathering event).\nIn this paper, we focus on learning causal effects on hypergraphs. We are specifically interested in estimating the individual treatment effect (ITE) under hypergraph interference from observational data. Our study is motivated by the following gaps: (i) Empirical constraints of randomized experiments. One of the most reliable approaches for treatment effect estimation is randomized controlled trials (RCTs). Nevertheless, running RCTs is often expensive, impractical, even unethical [15], and they are especially difficult on graphs due to the dependencies among connected nodes [39]. (ii) High-order interference on hypergraphs. Our work focuses on the problem of ITE estimation, which aims to estimate the causal effect of a certain treatment (e.g., face covering practice) on an outcome (e.g., COVID-19 infection) for each individual. The classic ITE estimation is based on the Stable Unit Treatment Value (SUTVA) assumption [14,36] that there is no interference [20,37] (i.e., spillover effect) among instances (also referred to as units in causal inference literature). That means the outcomes for any instance are not influenced by the treatment assignment of other instances. This assumption can be impractical in the real-world, thus resulting in flawed causal effect estimations, especially on graphs where the interference among instances are ubiquitous [1,47,50]. There have been many efforts addressing this problem [3,6,21,25,28,37,39,49], but most assume the interference only exists in a pairwise way on ordinary graphs (as shown in Fig. 1b). This pairwise interference notion is insufficient to characterize the high-order interference that exists on hypergraphs. As shown in Fig. 1c, within a gathering event (hyperedge) between 1 , 2 and 3 , an individual's ( 1 ) infection outcome can be affected by the first-order interference from other individuals ( 2 \u2192 1 and 3 \u2192 1 ) as well as the highorder interference from the interactions among other individuals (the interaction between 2 and 3 may also act on influencing the exposure of the virus to 1 ; consequently, 1 's infection risk can be affected by this second-order interaction effect, i.e., 2 \u00d7 3 \u2192 1 ). Notice that the number of such high-order interference items grows combinatorially as the size of a hyperedge increases, leading to a significant information gap between the original hypergraph and the projected pairwise ordinary graph (which accounts for the first-order interference only). This demands techniques capable of modeling high-order interference, but to the best of our knowledge, very little work has been done in this area.\nIn this paper, we propose a novel framework-Causal Inference under Spillover Effects in Hypergraphs (HyperSCI )-to model high-order interference. At a high-level, this framework controls for the confounders and models high-order interference based on representation learning, then estimates the outcomes based on the learned representations. More specifically: (i) Controlling for Confounders. Our framework is based on the widely accepted unconfoundedness assumption [33], i.e., the confounders are contained in the observed features. With this assumption, we leverage representation learning techniques to capture and control for confounders from the features of each individual. Note as shown in previous works [34], the discrepancy between confounder distributions in the treatment group and the control group can lead to biases in causal effect estimations. Therefore, we also propose to use a representation balancing technique to mitigate the discrepancy between these two distributions. (ii) Modeling High-order Interference.\nModeling high-order relationships can be challenging due to the complexity of enumerating multi-way interactions among nodes within each hyperedge. Historically, one may need to simplify the original hypergraph and approximate it through a series of projected ordinary graphs [48]. This obstacle is fortunately unblocked by the recent advances of hypergraph neural networks [5,44]. We extend this line of techniques to model interference by learning interference representations for each node. To learn the interference representations, the learned confounder representations and the treatment assignment are propagated via hypergraph convolution and attention operations. (iii) Outcome Prediction. Based on the learned representations of confounders and interference, we predict the potential outcomes corresponding to different treatment assignments for each individual. Overall, the main contributions of this work can be summarized as follows:\n\u2022 We formalize the problem of ITE estimation under high-order interference on hypergraphs. To the best of our knowledge, it is the first work for this problem. \u2022 We propose a novel framework HyperSCI for the studied problem. HyperSCI models confounders and high-order interference via representation learning and hypergraph neural networks. \u2022 We validate the effectiveness of the proposed framework through extensive experiments and provide in-depth analysis on how it acts on different nodes and hyperedges.", "publication_ref": ["b9", "b4", "b12", "b43", "b4", "b12", "b43", "b51", "b14", "b38", "b13", "b35", "b19", "b36", "b0", "b46", "b49", "b2", "b5", "b20", "b24", "b27", "b36", "b38", "b48", "b32", "b33", "b47", "b4", "b43"], "figure_ref": ["fig_2", "fig_2", "fig_2", "fig_2", "fig_2"], "table_ref": []}, {"heading": "PROBLEM DEFINITION AND ANALYSIS", "text": "We provide the formal problem definition and a brief theoretical analysis of our studied problem in this section. A notation table is provided in Appendix A.\nDefinition 2.1. Suppose a set of individuals V = { } =1 are connected via hyperedges E = {e } =1 , together these form a hypergraph H = {V, E} with nodes and hyperedges, where each hyperedge can connect an arbitrary number of nodes.\nThe observational data on this hypergraph can be denoted as {X, H, T, Y}, where X = {x } =1 , T = { } =1 and Y = { } =1 represent node features, treatment assignments, and observed outcomes, respectively. H = {\u210e , } \u2208 R \u00d7 is an incidence matrix which describes the hypergraph structure of H . \u210e , = 1 if node is in hyperedge , otherwise \u210e , = 0. For ease of discussion, we consider the treatment assignment for each node as a binary variable in this study (i.e., \u2208 {0, 1}), but our work can be extended to non-binary categorical variables and continuous variables. Definition 2.2. The potential outcome [33] of the instance (denoted by 1 or 0 ) is defined as the realized value of outcome for instance under the treatment value = 1 or = 0. These potential outcomes can be instantiated via a transformation = \u03a6 ( , , \u2212 , \u2212 , ). \u03a6 can be regarded as a (non-deterministic) function to output potential outcomes, which takes each node's treatment assignment, node features, the information (treatment assignments and node features) of other nodes on the hypergraph, and the hypergraph structure as input 1 , i.e., = \u03a6 ( , x , T \u2212 , X \u2212 , H), where the subscript \u2212 denotes all other nodes on H except .\nGiven the above preliminaries, we are ready to provide the formal definition of individual treatment effect on hypergraphs. Definition 2.3. For each node on the hypergraph H , the individual treatment effect (ITE) is defined by the difference between potential outcomes corresponding to = 1 and = 0:\n(x , T \u2212 , X \u2212 , H) = E[ 1 \u2212 0 | = x , \u2212 = T \u2212 , \u2212 = X \u2212 , = H] = E[\u03a6 (1, x , T \u2212 , X \u2212 , H) \u2212 \u03a6 (0, x , T \u2212 , X \u2212 , H)].(1)\nWe clarify that the ITE in this paper is actually defined in the form of conditional average treatment effect (CATE), similar as [17,28]. The expectation is taken over the potential outcome (output of \u03a6 ) of the instances with same node features x and \"environmental information\" (hypergraph structure H, other nodes' features X \u2212 and treatments T \u2212 ). The distribution of the output of \u03a6 is equivalent to the conditional distribution of the potential outcome conditioned on the parameters in \u03a6 with fixed values. For notation simplicity, we also denote = (x , T \u2212 , X \u2212 , H) in this paper. Meanwhile, we introduce the notion of spillover effect in this work to assess the level of interference on hypergraphs. Definition 2.4. The spillover effect of node under its treatment and other nodes' treatment assignment T \u2212 on the hypergraph H is defined as:\n= E[\u03a6 ( , x , T \u2212 , X \u2212 , H) \u2212 \u03a6 ( , x , 0, X \u2212 , H)].(2)\nIn this paper, given the observed data {X, H, T, Y}, we aim to estimate the ITE defined in Eq. 1 for each node in H with the existence of high-order interference defined in Eq. 2.", "publication_ref": ["b32", "b16", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "Theoretical Analysis", "text": "With the above definitions, we show that the ITE can be identifiable from the observational data under the following two assumptions.\nSimilar as the assumptions in other works of causal inference under network interference [28], for each individual, we assume there exists a summary function capable of characterizing all the \"environmental\" information related to this node on the hypergraph. Suppose there is a summary function SMR(\u2022): for each node , SMR(\u2022) takes the hypergraph structure H, the treatment assignment of other nodes T \u2212 and the features of these nodes X \u2212 as input, then maps them into a vector o :\no = SMR(H, T \u2212 , X \u2212 ).(3)\nWe use , , to denote the random variables for the hypergraph structure, features, and treatment assignment for any node. Then our first assumption can be formalized as below.\nAssumption 1. (Expressiveness of summary function) For any node , any values of , \u2212 , and \u2212 , if the output of summary function o is determined, then the value of the potential outcomes 1 and 0 with feature x are also determined.\nOur second assumption extends the unconfoundedness assumption [33] to the hypergraph interference setting. That is we assume conditioned on the above summary function, the observed features can capture all possible confounders. Assumption 2. (Unconfoundedness) For any node , given the node features, the potential outcomes are independent with the treatment assignment and summary of neighbors, i.e., 1 , 0 \u22a5 \u22a5 , | .\nBased on the above assumptions, the identification of the expectation of potential outcomes 1 and 0 can be proved (here we take 1 as an example):\nE[ 1 | = 1, = x , \u2212 = T \u2212 , \u2212 = X \u2212 , = H](4)\n( )\n=E[\u03a6 ( = 1, = x , \u2212 = T \u2212 , \u2212 = X \u2212 , = H)](5)\n( )\n=E[\u03a6 ( = 1, = x , = o )](6)\n( )\n=E[\u03a6 ( = 1, = x , = o )| = x ](7)\n( )\n=E[\u03a6 ( = 1, = x , = o )| = x , = 1, = o ] (8) ( ) =E[ | = x , = 1, = o ].(9)\nHere, the equation ( ) is based on the definition of potential outcome in this setting; ( ) is inferred from Assumption (1); ( ) is a straightforward derivation; ( ) is based on Assumption (2); and ( ) is based on the widely used consistency assumption [33]. Based on the above proof for the identification of potential outcomes, the identification of ITE can be straightforwardly derived.", "publication_ref": ["b27", "b32", "b0", "b32"], "figure_ref": [], "table_ref": []}, {"heading": "THE PROPOSED FRAMEWORK", "text": "Inspired by the previous theoretical analysis, we propose a novel framework HyperSCI to address the studied problem. This framework contains three components: confounder representation learning, interference modeling, and outcome prediction. Holistically, we aim to learn an expressive transformation to summarize high-order interferences (Assumption 1), then take the interference representation, the confounder representation as well as the treatment assignment to estimate the expected potential outcome (Assumption 2). The illustration of HyperSCI is shown in Fig. 2.", "publication_ref": [], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Confounder Representation Learning", "text": "We first encode the node features x into a latent space via a multilayer perceptron (MLP) module, i.e., z = MLP(x ). This results in a set of representations Z = {z } =1 , which is expected to capture all potential confounders, so the model can mitigate the confounding biases by controlling for the learned representation z .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Hypergraph module", "text": "! \" ! # \u00d7 P P ! # ! $ ! % \u00d7 ! $ ! \" ! # ! $ ! % P \u00d7 ! & \" ! & # Hypergraph Convolution $ # $ % $ $ $ \" Hyperedge representation % # MLP Confounder Representation Learning ' ( # Interference Modeling % % % $ % \" ! # ! % ! $ ! \" Concat (! ) , $ ) )\nOutcome Prediction  \n% \" % # % $ % % P \u00d7 \u00d7 P P \u00d7 Node (control) ! \" ! # ! $ ! % P Hypergraph module $ # $ % $ $ $ \" Representation balancing & ' # & ' + Attention \u00d7 P \u00d7 P P \u00d7 \u00d7 ! # P \u00d7 $ # P P \u00d7 ! # ! \" ! $ ! % ! $ \u00d7 Interference representation ( ),, \" ( ),, #\n! \" ! # \u00d7 P P ! # ! $ ! % \u00d7 ! $ ! \" ! # ! $ ! % P \u00d7 ! & \" ! & # Hypergraph Convolution $ # $ % $ $ $ \" Hyperedge representation % # MLP Confounder Representation Learning ' ( # Interference Modeling % % % $ % \" ! # ! % ! $ ! \" Concat (! ) , $ ) )\nOutcome Prediction  Representation Balancing. Note a discrepancy may exist between the distributions of confounder representation Z in the treatment group and the control group, incurring biases in causal effect estimation, as shown in [34,46]. To minimize this discrepancy, we leverage the representation balancing technique by adding a discrepancy penalty to the loss function, where this discrepancy penalty can be calculated with any distribution distance metrics. In our implementation, we use the Wasserstein-1 distance [34] between the representation distributions of treatment group and control group.\n% \" % # % $ % % P \u00d7 \u00d7 P P \u00d7 Node (control) ! \" ! # ! $ ! % P Hypergraph module $ # $ % $ $ $ \" Representation balancing & ' # & ' + Attention \u00d7 P \u00d7 P P \u00d7 \u00d7 ! # P \u00d7 $ # P P \u00d7 ! # ! \" ! $ ! % ! $ \u00d7 Interference representation ( ),,\" ( ),,#", "publication_ref": ["b33", "b45", "b33"], "figure_ref": [], "table_ref": []}, {"heading": "Interference Modeling", "text": "In this interference modeling component, we take the confounder representation (Z), the treatment assignment (T), and the relational information on the hypergraph (H = {\u210e , }) as input, to capture the high-order interference for each individual. More specifically, we learn a transformation function \u03a8(\u2022) through a hypergraph module to generate the interference representations (p ) for each node , i.e., p = \u03a8(Z, H, T \u2212 , ). As shown in Fig. 3, this module is implemented with a hypergraph convolutional network [5,44] and a hypergraph attention mechanism [5,11,52], where the convolutional operator forms the skeleton of interference from hyperedges, and the attention operator enhances this mechanism by allowing flexible node contributions to each hyperedge.\nLearning interference representations. To learn the representations which encode the interference in the hypergraph for each node, we propagate the treatment assignment and confounder representations with a hypergraph convoluntional layer. We first introduce a vanilla Laplacian matrix for the hypergraph H :\nL = D \u22121/2 HB \u22121 H \u22a4 D \u22121/2 . (10\n)\nHere D \u2208 R \u00d7 is a diagonal matrix where each element represents the node degree (i.e., =1 \u210e , ). B \u2208 R \u00d7 is another diagonal matrix, where each element is the size of each hyperedge ( =1 \u210e , ).\nThen we can define the hypergraph convolution operator as:\nP ( +1) = LeakyReLU LP ( ) W ( +1) ,(11)\nwhere P ( ) represents the representations from the -th layer in the hypergraph module. We feed the first layer with the previous confounder representation masked by the treatment assignment, i.e., p (0) = * z , where * denotes element-wise multiplication.\nW ( +1) \u2208 R ( ) \u00d7 ( +1)\nis the parameter matrix in the ( +1)-th layer, where ( ) and ( +1) refer to the dimensionality of the interference representations in the -th and ( +1)-th layers, respectively.\nModeling interference with different significance. Although the above convolution layer can pass interferences through hyperedges, it does not provide much flexibility to account for the significance of interference for different nodes through different hyperedges. In the aforementioned COVID-19 example, intuitively, those individuals who are active in certain group gathering events are more likely to influence or be influenced by others in these groups. To better capture this intrinsic relationship between nodes and hyperedges on a hypergraph, we leverage a hypergraph attention mechanism [5,11,52] to learn attention weights for each node and the corresponding hyperedges that contain this node.\nMore specifically, we compute a representation for each hyperedge ( ) by aggregating across its associated nodes (N ): z = Agg({z | \u2208 N }). Here, Agg(\u2022) can be any aggregation functions (e.g., the mean aggregation). For each node and its associated hyperedge , the attention score between a node and a hyperedge can be calculated as:\n, = exp( (sim(z W , z W ))) \u2208E exp( (sim(z W , z W ))) ,(12)\nwhere (\u2022) is a non-linear activation function, E denotes the set of hyperedges associated with the node . Here we use W to denote a parameter matrix to compute the node-hyperedge attention. sim(\u2022) is a similarity function, which can be implemented as:\nsim(x , x ) = a \u22a4 [x \u2225x ],(13)\nwhere a is a weight vector, [\u2022\u2225\u2022] is a concatenation operation.\nThen we use the attention scores to model the interference with different significance. Specifically, we replace the original incidence matrix H in Eq. 10 with an enhanced matrix H = { \u210e , }, where \u210e , = , \u210e , . In this way, the interference from different nodes on the same hyperedge can be assigned with different importance weights, indicating different levels of contribution for interference modeling. We denote the final representations from the last convolution layer as P = {p } =1 and expect it to capture the high-order interference for each node.\nRepresentation Balancing. Similar to the coufounder representation learning module, we calculate a discrepancy penalty to reflect the difference between the distributions of interference representations in treatment and control groups. We sum up these two discrepancy penalties together to compute a representation balancing loss, denoted by L .", "publication_ref": ["b4", "b43", "b4", "b10", "b51", "b4", "b10", "b51"], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Outcome Prediction", "text": "With the confounder representation z and the interference representation p , we model the potential outcomes as:\n1 = 1 ([z \u2225p ]), 0 = 0 ([z \u2225p ]),(14)\nwhere 1 (\u2022) and 0 (\u2022) are learnable functions to predict the potential outcome w.r.t. = 1 and = 0. We implement 1 (\u2022) and 0 (\u2022) with two MLP modules. Then the prediction for the observed outcome is obtained by = . We optimize the model to minimize the following loss function:\nL = \u2211\ufe01 =1 ( \u2212 ) 2 + L + \u2225\u0398\u2225 2 ,(15)\nwhere the first term is the standard mean squared error, L is the representation balancing loss, \u0398 represents the parameters in this neural network model. and are two hyperparameters which control the weights for the representation balancing loss and the parameter regularization term. The ITE for each instance can be estimated as: = 1 \u2212 0 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Discussion", "text": "Here we revisit some implicit assumptions in the proposed framework. First, we assume that the interference for each node comes from its neighbors through the hypergraph structure. Here, the interference from neighbors that are multiple hops away can also be captured by stacking more hypergraph convoluntional layers. Second, for simplicity, we assume that the interference for each node only comes from other nodes with non-zero treatment assignment. Third, we assume that the representations of nodes in the same hyperedge are similar in the latent space. Besides, following [5], we assume that the representations of hyperedges are homogeneous with node representations. Nevertheless, we should still mention that this proposed framework is general and extendable, where the above assumptions can be further relaxed by enriching the hypergraph processing module.", "publication_ref": ["b4"], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "It is typically very hard to obtain the ground-truth counterfactual data as only one of the two potential outcomes can be obtained in the observational data. Hence, in this section, we follow a standard practice to evaluate the proposed framework and the alternative approaches on three semi-synthetic datasets. We aim to leverage as much real-world information as possible in the simulated environment. Our datasets are all based on real-world hypergraph data and we retain the treatment allocations as well as node features (covariates) if they are available. We simulate the outcome generation process to assess the true individual treatment effect (ITE), which eventually allows us to evaluate the performance of the ITE estimation from different causal inference approaches.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Dataset and Simulation", "text": "We obtain the semi-synthetic data based on two publicly available hypergraph datasets (Contact [7,29], Goodreads [40,41]) and one large-scale proprietary web application dataset (Microsoft Teams). We do not account for the temporal information of each hyperedge in our experiments and leave this as a future research direction instead. In all three datasets, we discard extremely large hyperedges and keep those with no more than 50 nodes only. 2 4.1.1 Outcome Simulation. Given the treatment allocations T, node features X, and the hypergraph structure H, the potential outcome of an individual can be simulated via\n= ,0 (x ) + individual treatment effect (ITE) ( , x ) + (T, X, H) hypergraph spillover effect + ,(16)\nwhere ,0 (x ) describes the outcome of instance when = 0 and without network interference, (\u2022) calculates the ITE of each instance, (\u2022) calculates the spillover effect, and denotes the random noise from a Gaussian distribution N (0, 1). We specify ,0 (x ) as a linear transformation of x :\n,0 = w 0 x ,(17)\nwhere w 0 \u223c N (0, I), w 0 \u2208 R . Then we control the individual treatment effect ( ( , x )) and the hypergraph spillover effect ( (T, X, H)) under two different settings:\n(1) Linear.\n( , x ) = w 1 x + if = 1 0 if = 0 (18)\nHere w 1 \u2208 R , and each element in w 1 follows a Gaussian distribution. We generate as:\n(T, X, H) = 1 |E | \u2211\ufe01 \u2208E \u2032 ( 1 |N | \u2211\ufe01 \u2208N \u00d7 ( , x )).(19)\nHere, \u2032 (\u2022) is a function on the aggregation over each hyperedge. We implement it with an identity function by default. (2) Quadratic.\n( , x ) = x \u22a4 W x + if = 1 0 if = 0 (20\n)\nHere W \u2208 R \u00d7 , and each element in W follows a Gaussian distribution. We generate as:\n(T, X, H) = 1 |E | \u2211\ufe01 \u2208E \u2032 ( 1 |N | 2 (T * X )W (T * X ) \u22a4 ). (21)\nHere X and T are the feature matrix and treatment assignment of nodes contained in hyperedge , respectively. Here * denotes element-wise multiplication.\n4.1.2 Dataset Details. We follow the above process to generate potential outcomes on all three datasets. Additional details about each dataset are provided as the follows.\nContact. This dataset collects interactions recorded by wearable sensors among students at a high school [7,29], and includes 327 nodes and 7,818 hyperedges. Each node represents a person, and each hyperedge stands for a group of individuals are in close physical proximity to each other. This contact hypergraph data allows us to simulate a hypothetical question: \"how does one's face covering practice (treatment) causally affect their infection risk of an infectious disease (outcome)?\". In each group contact, one may bring the virus to the surrounding environment, and thus affect other people's infection risk. Due to the lack of detailed information about each individual, apart from the potential outcome, we also generate the treatment ( ) and the covariates (x ) as the follows:\nx \u223c N (0, I), \u223c (sigmoid(x v )),(22)\nwhere I is an \u00d7 identity matrix, here we set = 50. v is adimensional vector where each element inside follows a Gaussian distribution. Eventually about 50% \u223c 60% of the nodes are treated ( = 1) in our experiments.\nGoodReads. This dataset collects book information from the book review website GoodReads 3 , including the book title, authors, descriptions, reviews, and ratings [40,41]. We take each book in the Children category as an instance. The bag-of-words of the book descriptions are used as the covariates of each book. Each hyperedge corresponds to each author and all books sharing the same author are in the same hyperedge. The real-world book ratings are considered as treatment assignments: for each node , we define = 1 if the rating score is larger than 3 and = 0 otherwise. We aim to study the causal effect of the rating score on the sales of each book. The ratings of each author's books can establish this author's overall reputation, and thus influence the sales of other books from the same author. The final processed dataset includes 57,031 nodes (where 40% are treated) and 12,709 hyperedges. Note each book may have more than one author, and each author may have published multiple books.\nMicrosoft Teams. We sampled 91,391 anonymized employees of a multinational technology company and collected their aggregated telemetry data on Microsoft Teams 4 . Microsoft Teams is a workplace communication platform where users are allowed to create a group space (i.e., \"team\" or \"channel\") to enable public communication within each group. We are interested in how a user's usage of these group spaces causally affects their productivity. We process the treatment assignment into binary values by taking it as 1 if the employee has sent out at least one message in any of these group spaces during the first week of March, 2021; otherwise the treatment is assigned as 0. Each group space can be regarded as a hyperedge, where information can be shared via group discussions thus one's activeness on this platform may affect other individuals' outcomes in the same group. Employee demographics (e.g., office location, job description, work experience) were leveraged as the covariates. ", "publication_ref": ["b6", "b28", "b39", "b40", "b1", "b6", "b28", "b39", "b40", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "\u221a", "text": ") [18] and Mean Absolute Error (\n) [42]. These metrics can be defined as follows:\n\u221a = 1 \u2211\ufe01 \u2208 [ ] ( \u2212 ) 2 , = | 1 \u2211\ufe01 \u2208 [ ] \u2212 1 \u2211\ufe01 \u2208 [ ] |.(", "publication_ref": ["b17", "b41"], "figure_ref": [], "table_ref": []}, {"heading": "23) Lower", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "\u221a", "text": "or indicates better causal effect estimations.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Baselines.", "text": "To investigate the effectiveness of our framework, we compare it with multiple state-of-the-art ITE estimation baselines. These baselines can be divided into the following categories:\n\u2022 No graph. We compare the estimation results with traditional methods which do not consider graph data and spillover effects. These methods include outcome regression which is implemented by linear regression (LR), counterfactual regression (CFR [34]), causal effect variational autoencoder (CEVAE [27]). By comparing the proposed framework to these methods, we evaluate the effectiveness of modeling interference for ITE estimation.\n\u2022 No spillover effect in ordinary graphs. Although assuming no spillover effect exists, the network deconfounder (Netdeconf) [17] captures latent confounders for ITE estimation by utilizing the network structure among instances.\n\u2022 Spillover effect in ordinary graphs. We compare our framework with other ITE estimation baselines which can handle the pairwise spillover effect on ordinary graphs: a node representation learning based method [28] estimates ITE under network interference, including two variants: (a) GNN + HSIC, which is based on graph neural network [30] and Hilbert Schmidt independence criterion (HSIC) [16], and (b) GCN + HSIC, which is based on GCN [24].\nTo utilize the baselines which handle ordinary graphs, we project the original hypergraph H to an ordinary graph G = {V, E } by setting ( , ) \u2208 E if and are contained in at least one common hyperedge in H . By comparing Hyper-SCI to the above baselines, we are able to evaluate the benefits of modeling high-order interferences on the original hypergraph.", "publication_ref": ["b33", "b26", "b16", "b27", "b29", "b15", "b23"], "figure_ref": [], "table_ref": []}, {"heading": "Setup.", "text": "We randomly partition all datasets into 60%-20%-20% training/validation/test splits. All the results are averaged over ten repeated executions. Unless otherwise specified, we set the hyperparameters as = 0.001, = 1.0, = 1.0, = 0.01, the dimension for confounder representation and interference representation both as 64. We use ReLU as the activation function, and use an Adam optimizer. By default, the interference modeling component contains one hypergraph convolutional layer.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "ITE Estimation Performance", "text": "We include the results for the ITE estimation task in Table 1. From this table we observe that the proposed framework outperforms all the baselines under both linear and quadratic outcome simulation settings. We attribute these results to the fact that HyperSCI utilizes the relational information in hypergraph to model the highorder interference, and thus mitigates the influence of the spillover effect on ITE estimation performance. Compared with other baselines, the methods which incorporate the pairwise network interference (GCN-HSIC and GNN-HSIC), as well as Netdeconf which utilizes the network structure for ITE estimation, perform better than those baselines which do not take advantage of the relational information (LR, CEVAE, CFR).\nWe also vary the hyperparameter ( ) which controls the significance of hypergraph spillover effect in the outcome simulation and report the ITE estimation results in Fig. 4. As increases, i.e., the outcome is more heavily influenced by interference, larger performance gains can be observed from the proposed framework (HyperSCI) against baselines. This observation further validates the effectiveness of our framework in modeling the interference for enhancing the performance of ITE estimation.", "publication_ref": [], "figure_ref": ["fig_5"], "table_ref": ["tab_2"]}, {"heading": "Ablation Study", "text": "To investigate the effectiveness of different components in the proposed framework, we conduct ablation studies by considering the following variants: 1) we apply the proposed model HyperSCI on the projected graph (in a hypergraph structure) (denoted as Hy-perSCI-P); 2) we replace the hypergraph neural network module    with a graph neural network module with the same number of layers, and then apply it on the projected graph (in an original graph structure) (HyperSCI-G). Notice that although both evaluated on the projected graph, HyperSCI-G handles ordinary graphs with its graph neural network module, while HyperSCI-P handles hypergraphs with its hypergraph neural network module; 3) we remove the balancing techniques in the framework (HyperSCI-NB).\nThe ITE estimation results are reported in Fig. 5, where we notice significant performance gaps between HyperSCI-P/HyperSCI-G and HyperSCI, which imply the effectiveness of modeling the high-order relationships on hypergraphs. We also observe the ITE estimation performance degrades after removing the representation balancing modules, which indicates the effectiveness of the representation balancing techniques on mitigating the biases of ITE estimations.", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "A Closer Look at High-Order Interference", "text": "In addition to the overall ITE estimation performance, we take a closer look at high-order interference. We investigate how the proposed framework responds to hyperedges with difference sizes. More specifically, we remove the hyperedges with size larger than , denote the modified hypergraph as H ( ) , and vary the value of . In Fig 6, we compare the ITE estimation performance of the proposed framework HyperSCI with its variant on the projected ordinary graph HyperSCI-G. We observe that: 1) When = 2 (hyperedge size \u2264 2), the performance of HyperSCI-G is close to HyperSCI. Because when = 2, graph convolution can be regarded as a special case of hypergraph convolution with small differences in the graph Laplacian matrix (as illustrated in [5]). Empirically this leads to a minor performance difference between HyperSCI-G and HyperSCI; 2) When increases, the performance of ITE estimation from both methods are gradually improved, but such an improvement becomes less significant when is larger. Besides, we notice HyperSCI consistently outperforms HyperSCI-G and such a difference becomes larger as increases, indicating its efficacy on modeling high-order interference especially on large hyperedges.", "publication_ref": ["b4"], "figure_ref": ["fig_8"], "table_ref": []}, {"heading": "Sensitivity Analysis", "text": "To evaluate the robustness of the proposed framework, we present the ITE estimation performance of HyperSCI under different settings of model hyper-parameters in Fig. 7. More specifically, we vary the value of the balancing weight from {0.0001, 0.001, 0.01, 0.1}, and vary the representation dimension from {16, 32, 64, 128}. We also vary the number of attention head from {1, 2, 3, 4}, then change the parameter of regularization weight from {0.0001, 0.001, 0.01, 0.1}. As can be observed, our framework is generally robust to different hyper-parameter settings, but proper fine-tuning of these hyperparameters is still beneficial for the ITE estimation performance.", "publication_ref": [], "figure_ref": ["fig_9"], "table_ref": []}, {"heading": "RELATED WORK", "text": "Causal studies under network interference. There have been many causal studies [3,6,9,21,25,28,37,39,49] which address the existence of network interference. These works mainly include the following categories: (i) Random assignment strategy under interference [3,6,12,21,39]. These works focus on experimental studies under interference (without SUTVA assumption). In some studies [23], strong interference is assumed to exist within each group while there is no interference across different groups; (ii) Causal effect estimation on observational data with interference [2,28,32,38]. Different from the experimental studies which can design assignment strategy, another line of works (and also our work) assume interferences exist across individuals in the observational data. They relax the SUTVA assumption and define the potential outcome with a function that takes the instance covariates and treatment assignment of each individual and other interacted individuals as input. Among them, Rakesh et al. [32] propose a Linked Causal Variational Autoencoder (LCVA) framework to estimate the causal effect of a treatment on an outcome with the existence of interference between pairs of instances. Different from these works that focus on pairwise spillover effects, Ma et al. [28] consider the spillover effect in network structure, and propose a graph neural network (GNN) [24] based framework for causal effect estimation under network interference. However, these works are still limited in pairs of individuals or ordinary graphs and lack consideration of high-order interference. Another line of studies is bipartite causal inference [31,53]. Traditionally, bipartite causal inference involves two types of units: interventional/outcome units. Interventional units are assigned with treatments, and outcomes are observed from outcome units. Although this setup is different from ours, considering that there is a node-hyperedge bipartite corresponding to each hypergraph (and ordinary graph), thus the two modeling approaches (bipartite and hypergraph) are conceptually similar. Nevertheless, we argue hypergraph is a more appropriate framing in many scenarios since: i) hypergraph does not require instantiating edges as additional nodes, or treating these two kinds of nodes differently, thus more computationally efficient; ii) hypergraph has the potential to be more convenient and efficient when generalizing to new hyperedges, while bipartite needs to generate both new nodes for the new hyperedges and their associated new edges.\nHypergraph algorithms and neural networks. To process hypergraph structures for downstream tasks, a line of works simplify the hypergraph structure by taking abstract representations of complicated multi-way interactions [7,26,43,45,51]. Other works directly tackle the original hypergraph structure [4,8,13,19,35,44]. Recently, numerous works have studied on hypergraph neural networks [5,44]. Feng el al. [13] propose hypergraph neural networks (HGNN) framework to encode high-order data correlation in a hypergraph structure. A hyperedge convolution operation is designed for representation learning. Bai et al. [5] introduce two end-to-end trainable operators hypergraph convolution and hypergraph attention to learn node representations in hypergraphs. Yadati et al. [44] develop a self-attention based hypergraph neural network Hyper-SAGNN, which is applicable to homogeneous or heterogeneous hypergraphs with variable hyperedge sizes. Jiang et al. [22] propose a dynamic hypergraph neural network (DHGNN) which can dynamically update hypergraph structure on each layer.", "publication_ref": ["b2", "b5", "b8", "b20", "b24", "b27", "b36", "b38", "b48", "b2", "b5", "b11", "b20", "b38", "b22", "b1", "b27", "b31", "b37", "b31", "b27", "b23", "b30", "b52", "b6", "b25", "b42", "b44", "b50", "b3", "b7", "b12", "b18", "b34", "b43", "b4", "b43", "b12", "b4", "b43", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "CONCLUSION", "text": "In this paper, we study an important research problem of individual treatment effect estimation with the existence of high-order interference on hypergraphs. We identify and analyze the influence of high-order interference in causal effect estimation. To address this problem, we propose a novel framework HyperSCI, which estimates the ITEs based on representation learning. More specifically, HyperSCI learns the representation of confounders, models the high-order interference with a hypergraph neural network module, then predicts the potential outcomes for each instance with the learned representations. We conduct extensive experiments to evaluate the proposed framework, where the results consistently validate the effectiveness of HyperSCI in ITE estimation under different interference scenarios.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A NOTATION TABLE", "text": "We use Table 2 to list the most important notations used in this paper. variables for all the nodes except the -th node the spillover effect of the -th node SMR(\u2022) summary function O, o the environment information of the -th node Z, z confounder representations of all nodes/the -th node \u03a8(\u2022) interference representation learner 1 (\u2022), 0 (\u2022) potential outcome prediction functions P, p interference representations of all nodes/the -th node ( ) the ratio of the treatment assignment of the -node in its neighborhood", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "B MORE EXPERIMENTAL RESULTS B.1 ITE Estimation Performance under Different Settings on All the Datasets", "text": "In this section, we show the ITE estimation performance under different settings (including the linear and quadratic settings with among {1.0, 3.0, 5.0}) on all the datasets in Fig. 9. We can observe that the proposed HyperSCI consistently outperforms the baselines under different settings on all the datasets. The superiority of our framework against baselines becomes more obvious when is larger (i.e., the interference is stronger), because our framework can better handle the interference in the hypergraph.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B.2 Case Studies", "text": "We further conduct case studies to investigate how the proposed method acts on individuals in responding to their neighboring nodes (i.e., the size of one's neighborhood and the homophily of treatment assignments within one's neighborhood). The neighborhood of is defined as the set of nodes which are connected with via any hyperedges, i.e., N = \u2208 E { \u2208 N }. The homophily of treatment assignment is defined as the ratio of neighboring nodes which share the same treatment assignment as oneself, i.e., ( )\n= \u2208N 1( = ) |N |\n. In Fig. 8a, we show the difference between the ITE estimation results made with the original hypergraph and with the projected graph, w.r.t. N and ( ). Overall, we see larger divergences on individuals with a larger neighborhood size but less agreement with their neighbors in terms of treatment assignments. In Fig. 8b, we further showcase the insights by presenting several representative children books on the GoodReads dataset. For example, the author of \"Peter Pan\" had not published many works but these books all received good rating scores, leading to a \"consistent\" reputation of the author. Therefore, the outcome of the book \"Peter Pan\" is less impacted by the high-order interference among its neighbors. On the other hand, the high rating score of the book \"Oddhopper Opera\" differs from most of its neighbors, leading to a mixed reputation of the author. In this case, the potential outcome is more likely to be affected by the high-order interference on the hypergraph. ", "publication_ref": [], "figure_ref": ["fig_10", "fig_10"], "table_ref": []}], "references": [{"ref_id": "b0", "title": "The moderating role of commitment on the spillover effect of marketing communications", "journal": "Journal of Marketing research", "year": "2001", "authors": "Rohini Ahluwalia; Robert E Rao Unnava;  Burnkrant"}, {"ref_id": "b1", "title": "Inferring network effects from observational data", "journal": "", "year": "2016", "authors": "David Arbour; Dan Garant; David Jensen"}, {"ref_id": "b2", "title": "Estimating average causal effects under general interference, with application to a social network experiment", "journal": "The Annals of Applied Statistics", "year": "2017", "authors": "M Peter; Cyrus Aronow;  Samii"}, {"ref_id": "b3", "title": "Exploiting relational information in social networks using geometric deep learning on hypergraphs", "journal": "", "year": "2018", "authors": "Devanshu Arya; Marcel Worring"}, {"ref_id": "b4", "title": "Hypergraph convolution and hypergraph attention", "journal": "Pattern Recognition", "year": "2021", "authors": "Song Bai; Feihu Zhang; Philip Hs Torr"}, {"ref_id": "b5", "title": "Analyzing two-stage experiments in the presence of interference", "journal": "J. Amer. Statist. Assoc", "year": "2018", "authors": "Guillaume Basse; Avi Feller"}, {"ref_id": "b6", "title": "Simplicial closure and higher-order link prediction", "journal": "Proceedings of the National Academy of Sciences", "year": "2018", "authors": "Rediet Austin R Benson;  Abebe; T Michael; Ali Schaub; Jon Jadbabaie;  Kleinberg"}, {"ref_id": "b7", "title": "Sequences of sets", "journal": "", "year": "2018", "authors": "Ravi Austin R Benson; Andrew Kumar;  Tomkins"}, {"ref_id": "b8", "title": "Causal inference under interference and network uncertainty", "journal": "", "year": "2020", "authors": "Rohit Bhattacharya; Daniel Malinsky; Ilya Shpitser"}, {"ref_id": "b9", "title": "", "journal": "", "year": "2013", "authors": "Ulrik Brandes; C Linton; Dorothea Freeman;  Wagner"}, {"ref_id": "b10", "title": "Be more with less: Hypergraph attention networks for inductive text classification", "journal": "", "year": "2020", "authors": "Kaize Ding; Jianling Wang; Jundong Li; Dingcheng Li; Huan Liu"}, {"ref_id": "b11", "title": "Minimizing interference and selection bias in network experiment design", "journal": "", "year": "2020", "authors": "Zahra Fatemi; Elena Zheleva"}, {"ref_id": "b12", "title": "Hypergraph neural networks", "journal": "", "year": "2019", "authors": "Yifan Feng; Haoxuan You; Zizhao Zhang; Rongrong Ji; Yue Gao"}, {"ref_id": "b13", "title": "Design of experiments", "journal": "Br Med J", "year": "1936", "authors": "Ronald Aylmer Fisher"}, {"ref_id": "b14", "title": "Ethical issues in pragmatic randomized controlled trials: a review of the recent literature identifies gaps in ethical argumentation", "journal": "BMC Medical Ethics", "year": "2018", "authors": "Cory E Goldstein; Charles Weijer; Jamie C Brehaut; A Dean; Jeremy M Fergusson; Austin R Grimshaw; Monica Horn;  Taljaard"}, {"ref_id": "b15", "title": "Measuring statistical dependence with Hilbert-Schmidt norms", "journal": "Springer", "year": "2005", "authors": "Arthur Gretton; Olivier Bousquet; Alex Smola; Bernhard Sch\u00f6lkopf"}, {"ref_id": "b16", "title": "Learning individual causal effects from networked observational data", "journal": "", "year": "2020", "authors": "Ruocheng Guo; Jundong Li; Huan Liu"}, {"ref_id": "b17", "title": "Bayesian nonparametric modeling for causal inference", "journal": "Journal of Computational and Graphical Statistics", "year": "2011", "authors": "L Jennifer;  Hill"}, {"ref_id": "b18", "title": "Scalable hypergraph learning and processing", "journal": "IEEE", "year": "2015", "authors": "Jin Huang; Rui Zhang; Jeffrey Xu Yu"}, {"ref_id": "b19", "title": "Toward causal inference with interference", "journal": "J. Amer. Statist. Assoc", "year": "2008", "authors": "G Michael; M Hudgens;  Elizabeth Halloran"}, {"ref_id": "b20", "title": "Causal inference with interference and noncompliance in two-stage randomized experiments", "journal": "J. Amer. Statist. Assoc", "year": "2020", "authors": "Kosuke Imai; Zhichao Jiang; Anup Malani"}, {"ref_id": "b21", "title": "Dynamic Hypergraph Neural Networks", "journal": "", "year": "2019", "authors": "Jianwen Jiang; Yuxuan Wei; Yifan Feng; Jingxuan Cao; Yue Gao"}, {"ref_id": "b22", "title": "Network experimentation at scale", "journal": "", "year": "2021", "authors": "Brian Karrer; Liang Shi; Monica Bhole; Matt Goldman; Tyrone Palmer; Charlie Gelman; Mikael Konutgan; Feng Sun"}, {"ref_id": "b23", "title": "Semi-supervised classification with graph convolutional networks", "journal": "", "year": "2016", "authors": "N Thomas; Max Kipf;  Welling"}, {"ref_id": "b24", "title": "Online controlled experiments at large scale", "journal": "", "year": "2013", "authors": "Ron Kohavi; Alex Deng; Brian Frasca; Toby Walker; Ya Xu; Nils Pohlmann"}, {"ref_id": "b25", "title": "Link prediction in social networks based on hypergraph", "journal": "", "year": "2013", "authors": "Dong Li; Zhiming Xu; Sheng Li; Xin Sun"}, {"ref_id": "b26", "title": "Causal effect inference with deep latent-variable models", "journal": "", "year": "2017", "authors": "Christos Louizos; Uri Shalit; M Joris; David Mooij; Richard Sontag; Max Zemel;  Welling"}, {"ref_id": "b27", "title": "Causal Inference under Networked Interference and Intervention Policy Enhancement", "journal": "", "year": "2021", "authors": "Yunpu Ma; Volker Tresp"}, {"ref_id": "b28", "title": "Contact patterns in a high school: a comparison between data collected using wearable sensors, contact diaries and friendship surveys", "journal": "PloS one", "year": "2015", "authors": "Rossana Mastrandrea; Julie Fournet; Alain Barrat"}, {"ref_id": "b29", "title": "Weisfeiler and leman go neural: Higher-order graph neural networks", "journal": "", "year": "2019", "authors": "Christopher Morris; Martin Ritzert; Matthias Fey; L William; Jan Eric Hamilton; Gaurav Lenssen; Martin Rattan;  Grohe"}, {"ref_id": "b30", "title": "Variance reduction in bipartite experiments through correlation clustering", "journal": "", "year": "2019", "authors": "Jean Pouget-Abadie; Kevin Aydin; Warren Schudy; Kay Brodersen; Vahab Mirrokni"}, {"ref_id": "b31", "title": "Linked causal variational autoencoder for inferring paired spillover effects", "journal": "", "year": "2018", "authors": "Vineeth Rakesh; Ruocheng Guo; Raha Moraffah; Nitin Agarwal; Huan Liu"}, {"ref_id": "b32", "title": "Randomization analysis of experimental data: The Fisher randomization test comment", "journal": "J. Amer. Statist. Assoc", "year": "1980", "authors": " Donald B Rubin"}, {"ref_id": "b33", "title": "Estimating individual treatment effect: generalization bounds and algorithms", "journal": "", "year": "2017", "authors": "Uri Shalit; D Fredrik; David Johansson;  Sontag"}, {"ref_id": "b34", "title": "Predicting multi-actor collaborations using hypergraphs", "journal": "", "year": "2014", "authors": "Ankit Sharma; Jaideep Srivastava; Abhishek Chandra"}, {"ref_id": "b35", "title": "On the application of probability theory to agricultural experiments. Essay on principles. Section 9", "journal": "Statist. Sci", "year": "1990", "authors": "Jerzy Splawa-Neyman; M Dorota; T P Dabrowska;  Speed"}, {"ref_id": "b36", "title": "On causal inference in the presence of interference", "journal": "Statistical methods in medical research", "year": "2012", "authors": " Eric J Tchetgen Tchetgen; J Tyler;  Vanderweele"}, {"ref_id": "b37", "title": "Auto-gcomputation of causal effects on a network", "journal": "J. Amer. Statist. Assoc", "year": "2021", "authors": "Isabel R Eric J Tchetgen Tchetgen; Ilya Fulcher;  Shpitser"}, {"ref_id": "b38", "title": "Graph cluster randomization: Network exposure to multiple universes", "journal": "", "year": "2013", "authors": "Johan Ugander; Brian Karrer; Lars Backstrom; Jon Kleinberg"}, {"ref_id": "b39", "title": "Item recommendation on monotonic behavior chains", "journal": "", "year": "2018", "authors": "Mengting Wan; Julian Mcauley"}, {"ref_id": "b40", "title": "Fine-Grained Spoiler Detection from Large-Scale Review Corpora", "journal": "", "year": "2019", "authors": "Mengting Wan; Rishabh Misra; Ndapandula Nakashole; Julian Mcauley"}, {"ref_id": "b41", "title": "Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance", "journal": "Climate research", "year": "2005", "authors": "J Cort; Kenji Willmott;  Matsuura"}, {"ref_id": "b42", "title": "Hyperlink prediction in hypernetworks using latent social features", "journal": "Springer", "year": "2013", "authors": "Ye Xu; Dan Rockmore; Adam M Kleinbaum"}, {"ref_id": "b43", "title": "Hypergcn: Hypergraph convolutional networks for semisupervised classification", "journal": "arXiv preprint", "year": "2018", "authors": "Naganand Yadati; Madhav Nimishakavi; Prateek Yadav; Anand Louis; Partha Talukdar"}, {"ref_id": "b44", "title": "Link prediction in hypergraphs using graph convolutional networks", "journal": "", "year": "2018", "authors": "Naganand Yadati; Vikram Nitin; Madhav Nimishakavi; Prateek Yadav; Anand Louis; Partha Talukdar"}, {"ref_id": "b45", "title": "Representation learning for treatment effect estimation from observational data", "journal": "Advances in Neural Information Processing Systems", "year": "2018", "authors": "Liuyi Yao; Sheng Li; Yaliang Li; Mengdi Huai; Jing Gao; Aidong Zhang"}, {"ref_id": "b46", "title": "Geographic and network neighbors: Spillover effects of telecommunications infrastructure", "journal": "Journal of Regional Science", "year": "2002", "authors": "Serdar Yilmaz; E Kingley; Mustafa Haynes;  Dinc"}, {"ref_id": "b47", "title": "How Much and When Do We Need Higher-order Information in Hypergraphs? A Case Study on Hyperedge Prediction", "journal": "", "year": "2020", "authors": "Hyungseok Se-Eun Yoon; Kijung Song; Yung Shin;  Yi"}, {"ref_id": "b48", "title": "Causal Network Motifs: Identifying Heterogeneous Spillover Effects in A/B Tests", "journal": "", "year": "2021", "authors": "Yuan Yuan; Kristen Altenburger; Farshad Kooti"}, {"ref_id": "b49", "title": "Exploration on the spatial spillover effect of infrastructure network on urbanization: A case study in Wuhan urban agglomeration", "journal": "Sustainable Cities and Society", "year": "2019", "authors": "Chen Zeng; Yan Song; Dawei Cai; Peiying Hu; Huatai Cui; Jing Yang; Hongxia Zhang"}, {"ref_id": "b50", "title": "Beyond link prediction: Predicting hyperlinks in adjacency space", "journal": "", "year": "2018", "authors": "Muhan Zhang; Zhicheng Cui; Shali Jiang; Yixin Chen"}, {"ref_id": "b51", "title": "Hyper-SAGNN: a self-attention based graph neural network for hypergraphs", "journal": "", "year": "2019", "authors": "Ruochi Zhang; Yuesong Zou; Jian Ma"}, {"ref_id": "b52", "title": "Bipartite causal inference with interference", "journal": "Statistical science: a review journal of the Institute of Mathematical Statistics", "year": "2021", "authors": "M Corwin; Georgia Zigler;  Papadogeorgou"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "First, second, and third-order interferences with 1 .", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 1 :1Figure 1: (a) An illustrative example of group interactions on a hypergraph, where each circle represents a hyperedge (group); (b) An ordinary graph projected from this hypergraph; (c) Illustration of interferences with 1 from its neighbors on the hypergraph. Note interference on (b) is pairwise (first-order only) while higher-order interference exists on the original hypergraph (a).", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 2 :2Figure 2: An illustration of the proposed framework HyperSCI, which includes three key components: confounder representation learning, interference modeling, and outcome prediction. Hypergraph module", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 3 :3Figure 3: A detailed illustration of the hypergraph module in the interference modeling component of HyperSCI. Here we use the node 1 (highlighted in yellow) as an example.Representation Balancing. Note a discrepancy may exist between the distributions of confounder representation Z in the treatment group and the control group, incurring biases in causal effect estimation, as shown in[34,46]. To minimize this discrepancy, we leverage the representation balancing technique by adding a discrepancy penalty to the loss function, where this discrepancy penalty can be calculated with any distribution distance metrics. In our implementation, we use the Wasserstein-1 distance[34] between the representation distributions of treatment group and control group.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 4 :4Figure 4: Comparison of the performance of ITE estimation under different values of in linear setting on GoodReads.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 5 :5Figure 5: Ablation studies of different variants of our framework HyperSCI. Results (mean and standard error) are reported under the linear setting but similar patterns can be found under the quadratic setting and on all datasets.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 6 :6Figure 6: ITE estimation performance of HyperSCI / Hyper-SCI-G on hypergraphs with hyperedge size no more than .", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 7 :7Figure 7: ITE estimation performance (mean and standard error) of the proposed framework HyperSCI under different parameters or model structures on GoodReads dataset.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 8 :8Figure 8: (a) Heatmap: the difference between ITE estimations with hypergraph and with projected ordinary graph on GoodReads. Nodes are divided into 6 \u00d7 6 grids w.r.t. their number of neighbors |N | and the homophily of treatment assignment ( ). (b) Case studies of representative books.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "ITE estimation performance (mean \u00b1 standard error). \"CT\", \"GR\" and \"MS\" stand for Contact,GoodReads  and Microsoft Teams datasets, respectively. \u00b10.04 9.11 \u00b10.09 38.22 \u00b10.77 20.28 \u00b10.38 CEVAE 22.88 \u00b11.07 8.29 \u00b10.69 35.28 \u00b10.75 18.22 \u00b10.76 CFR 24.04 \u00b10.75 7.17 \u00b10.43 32.24 \u00b11.01 17.28 \u00b10.75 Netdeconf 10.22 \u00b10.47 4.29 \u00b10.13 21.23 \u00b10.72 11.39 \u00b10.74 GNN-HSIC 7.42 \u00b10.39 2.06 \u00b10.03 16.28 \u00b10.24 7.28 \u00b10.39 GCN-HSIC 7.28 \u00b10.44 2.08 \u00b10.04 14.23 \u00b10.20 6.27 \u00b10.15 HyperSCI 3.45 \u00b10.27 1.39 \u00b10.03 9.20 \u00b10.09 2.24 \u00b10.07 GR LR 23.01 \u00b10.04 13.42 \u00b10.12 48.56 \u00b11.02 31.19 \u00b10.47 CEVAE 22.69 \u00b10.03 12.49 \u00b10.06 45.21 \u00b13.10 29.22 \u00b10.44 CFR 20.30 \u00b10.03 13.21 \u00b10.09 41.72 \u00b10.72 26.28 \u00b10.43 Netdeconf 18.39 \u00b10.19 12.20 \u00b10.03 35.18 \u00b10.78 21.20 \u00b10.76 GNN-HSIC 17.20 \u00b10.23 12.18 \u00b10.13 27.22 \u00b10.78 16.87 \u00b10.47 GCN-HSIC 16.01 \u00b10.20 12.06 \u00b10.15 25.42 \u00b10.76 16.28 \u00b10.76 HyperSCI 15.68 \u00b10.21 11.81 \u00b10.15 19.23 \u00b10.44 13.33 \u00b10.27 MS LR 22.80 \u00b10.64 21.41\u00b1 0.74 414.17 \u00b13.94 192.80 \u00b12.97 CEVAE 19.36 \u00b10.80 8.63 \u00b10.78 315.01 \u00b12.53 188.47 \u00b14.27 CFR 25.23 \u00b10.01 18.28 \u00b10.02 392.56 \u00b14.33 189.75 \u00b14.80 Netdeconf 11.11 \u00b10.01 9.22 \u00b10.03 241.02 \u00b12.32 147.29 \u00b11.04 GNN-HSIC 9.38 \u00b10.44 6.91 \u00b10.38 114.28 \u00b13.62 81.21 \u00b12.53 GCN-HSIC 8.27 \u00b10.41 6.60 \u00b10.48 109.57 \u00b13.85 77.75 \u00b13.93 HyperSCI 5.13 \u00b10.56 4.46 \u00b10.61 81.08 \u00b10.37 74.41 \u00b10.42 4.2 Experiment Settings 4.2.1 Metrics. We evaluate the performance of causal effect estimation through two standard metrics, including Rooted Precision in Estimation of Heterogeneous Effect (", "figure_data": "Data Method\u221aLinear\u221aQuadraticCT LR25.41"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Notation.", "figure_data": "NotationDefinitionHhypergraphV, Ethe set of nodes/hyperedgesHhypergraph structure matrixthe number of nodesthe number of hyperedgesNthe set of neighboring nodes for the -th nodeNthe set of nodes on the hyperedgeEthe set of hyperedges which contains the -th nodeX, xfeatures of all nodes/the -th nodeT,treatment assignment of all nodes/the -th nodeY,observed outcome of all nodes/the -th node1 , 0potential outcomes of the -th node\u03a6 (\u2022)potential outcome function,true/predicted ITE for the -th node,true/predicted outcome for the -th node(\u2022) \u2212"}], "formulas": [{"formula_id": "formula_0", "formula_text": "(x , T \u2212 , X \u2212 , H) = E[ 1 \u2212 0 | = x , \u2212 = T \u2212 , \u2212 = X \u2212 , = H] = E[\u03a6 (1, x , T \u2212 , X \u2212 , H) \u2212 \u03a6 (0, x , T \u2212 , X \u2212 , H)].(1)", "formula_coordinates": [3.0, 58.31, 268.52, 246.02, 32.0]}, {"formula_id": "formula_1", "formula_text": "= E[\u03a6 ( , x , T \u2212 , X \u2212 , H) \u2212 \u03a6 ( , x , 0, X \u2212 , H)].(2)", "formula_coordinates": [3.0, 88.38, 473.56, 205.67, 9.18]}, {"formula_id": "formula_2", "formula_text": "o = SMR(H, T \u2212 , X \u2212 ).(3)", "formula_coordinates": [3.0, 133.54, 661.21, 160.5, 8.79]}, {"formula_id": "formula_3", "formula_text": "E[ 1 | = 1, = x , \u2212 = T \u2212 , \u2212 = X \u2212 , = H](4)", "formula_coordinates": [3.0, 342.43, 314.66, 215.77, 9.46]}, {"formula_id": "formula_4", "formula_text": "=E[\u03a6 ( = 1, = x , \u2212 = T \u2212 , \u2212 = X \u2212 , = H)](5)", "formula_coordinates": [3.0, 327.64, 334.45, 230.56, 8.79]}, {"formula_id": "formula_5", "formula_text": "=E[\u03a6 ( = 1, = x , = o )](6)", "formula_coordinates": [3.0, 327.64, 353.56, 230.56, 8.4]}, {"formula_id": "formula_6", "formula_text": "=E[\u03a6 ( = 1, = x , = o )| = x ](7)", "formula_coordinates": [3.0, 327.64, 372.68, 230.56, 8.4]}, {"formula_id": "formula_7", "formula_text": "=E[\u03a6 ( = 1, = x , = o )| = x , = 1, = o ] (8) ( ) =E[ | = x , = 1, = o ].(9)", "formula_coordinates": [3.0, 327.64, 391.8, 230.56, 27.52]}, {"formula_id": "formula_8", "formula_text": "! \" ! # \u00d7 P P ! # ! $ ! % \u00d7 ! $ ! \" ! # ! $ ! % P \u00d7 ! & \" ! & # Hypergraph Convolution $ # $ % $ $ $ \" Hyperedge representation % # MLP Confounder Representation Learning ' ( # Interference Modeling % % % $ % \" ! # ! % ! $ ! \" Concat (! ) , $ ) )", "formula_coordinates": [4.0, 70.27, 92.59, 397.12, 205.7]}, {"formula_id": "formula_9", "formula_text": "% \" % # % $ % % P \u00d7 \u00d7 P P \u00d7 Node (control) ! \" ! # ! $ ! % P Hypergraph module $ # $ % $ $ $ \" Representation balancing & ' # & ' + Attention \u00d7 P \u00d7 P P \u00d7 \u00d7 ! # P \u00d7 $ # P P \u00d7 ! # ! \" ! $ ! % ! $ \u00d7 Interference representation ( ),, \" ( ),, #", "formula_coordinates": [4.0, 59.18, 92.03, 483.1, 203.66]}, {"formula_id": "formula_10", "formula_text": "! \" ! # \u00d7 P P ! # ! $ ! % \u00d7 ! $ ! \" ! # ! $ ! % P \u00d7 ! & \" ! & # Hypergraph Convolution $ # $ % $ $ $ \" Hyperedge representation % # MLP Confounder Representation Learning ' ( # Interference Modeling % % % $ % \" ! # ! % ! $ ! \" Concat (! ) , $ ) )", "formula_coordinates": [4.0, 58.26, 101.18, 394.83, 193.84]}, {"formula_id": "formula_11", "formula_text": "% \" % # % $ % % P \u00d7 \u00d7 P P \u00d7 Node (control) ! \" ! # ! $ ! % P Hypergraph module $ # $ % $ $ $ \" Representation balancing & ' # & ' + Attention \u00d7 P \u00d7 P P \u00d7 \u00d7 ! # P \u00d7 $ # P P \u00d7 ! # ! \" ! $ ! % ! $ \u00d7 Interference representation ( ),,\" ( ),,#", "formula_coordinates": [4.0, 47.24, 100.66, 480.31, 191.92]}, {"formula_id": "formula_12", "formula_text": "L = D \u22121/2 HB \u22121 H \u22a4 D \u22121/2 . (10", "formula_coordinates": [4.0, 127.1, 658.73, 163.53, 10.91]}, {"formula_id": "formula_13", "formula_text": ")", "formula_coordinates": [4.0, 290.62, 663.51, 3.42, 4.09]}, {"formula_id": "formula_14", "formula_text": "P ( +1) = LeakyReLU LP ( ) W ( +1) ,(11)", "formula_coordinates": [4.0, 372.13, 228.37, 186.07, 10.91]}, {"formula_id": "formula_15", "formula_text": "W ( +1) \u2208 R ( ) \u00d7 ( +1)", "formula_coordinates": [4.0, 317.51, 297.15, 74.86, 12.01]}, {"formula_id": "formula_16", "formula_text": ", = exp( (sim(z W , z W ))) \u2208E exp( (sim(z W , z W ))) ,(12)", "formula_coordinates": [4.0, 369.54, 528.83, 188.66, 21.81]}, {"formula_id": "formula_17", "formula_text": "sim(x , x ) = a \u22a4 [x \u2225x ],(13)", "formula_coordinates": [4.0, 393.22, 604.23, 164.99, 10.91]}, {"formula_id": "formula_18", "formula_text": "1 = 1 ([z \u2225p ]), 0 = 0 ([z \u2225p ]),(14)", "formula_coordinates": [5.0, 115.83, 230.2, 178.22, 8.59]}, {"formula_id": "formula_19", "formula_text": "L = \u2211\ufe01 =1 ( \u2212 ) 2 + L + \u2225\u0398\u2225 2 ,(15)", "formula_coordinates": [5.0, 111.45, 309.17, 182.59, 21.5]}, {"formula_id": "formula_20", "formula_text": "= ,0 (x ) + individual treatment effect (ITE) ( , x ) + (T, X, H) hypergraph spillover effect + ,(16)", "formula_coordinates": [5.0, 366.16, 262.47, 192.04, 38.66]}, {"formula_id": "formula_21", "formula_text": ",0 = w 0 x ,(17)", "formula_coordinates": [5.0, 423.72, 369.64, 134.48, 8.16]}, {"formula_id": "formula_22", "formula_text": "( , x ) = w 1 x + if = 1 0 if = 0 (18)", "formula_coordinates": [5.0, 387.35, 438.43, 170.85, 21.62]}, {"formula_id": "formula_23", "formula_text": "(T, X, H) = 1 |E | \u2211\ufe01 \u2208E \u2032 ( 1 |N | \u2211\ufe01 \u2208N \u00d7 ( , x )).(19)", "formula_coordinates": [5.0, 343.56, 498.95, 214.64, 22.22]}, {"formula_id": "formula_24", "formula_text": "( , x ) = x \u22a4 W x + if = 1 0 if = 0 (20", "formula_coordinates": [5.0, 380.84, 566.4, 173.94, 24.13]}, {"formula_id": "formula_25", "formula_text": ")", "formula_coordinates": [5.0, 554.78, 578.41, 3.42, 4.09]}, {"formula_id": "formula_26", "formula_text": "(T, X, H) = 1 |E | \u2211\ufe01 \u2208E \u2032 ( 1 |N | 2 (T * X )W (T * X ) \u22a4 ). (21)", "formula_coordinates": [5.0, 332.15, 630.36, 226.05, 22.22]}, {"formula_id": "formula_27", "formula_text": "x \u223c N (0, I), \u223c (sigmoid(x v )),(22)", "formula_coordinates": [6.0, 104.94, 262.45, 189.11, 8.4]}, {"formula_id": "formula_28", "formula_text": "\u221a = 1 \u2211\ufe01 \u2208 [ ] ( \u2212 ) 2 , = | 1 \u2211\ufe01 \u2208 [ ] \u2212 1 \u2211\ufe01 \u2208 [ ] |.(", "formula_coordinates": [6.0, 323.68, 430.62, 228.64, 34.13]}, {"formula_id": "formula_29", "formula_text": "= \u2208N 1( = ) |N |", "formula_coordinates": [10.0, 237.52, 683.88, 54.2, 15.99]}], "doi": "10.1145/3534678.3539299"}