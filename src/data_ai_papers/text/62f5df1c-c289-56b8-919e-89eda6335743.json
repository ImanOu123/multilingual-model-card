{"title": "Recognition of Affect, Judgment, and Appreciation in Text", "authors": "Alena Neviarouskaya; Helmut Prendinger; Mitsuru Ishizuka", "pub_date": "", "abstract": "The main task we address in our research is classification of text using fine-grained attitude labels. The developed @AM system relies on the compositionality principle and a novel approach based on the rules elaborated for semantically distinct verb classes. The evaluation of our method on 1000 sentences, that describe personal experiences, showed promising results: average accuracy on the finegrained level (14 labels) was 62%, on the middle level (7 labels) -71%, and on the top level (3 labels) -88%.", "sections": [{"heading": "Introduction and Related Work", "text": "With rapidly growing online sources aimed at encouraging and stimulating people's discussions concerning personal, public or social issues (news, blogs, discussion forums, etc.), there is a great need in development of a computational tool for the analysis of people's attitudes. According to the Appraisal Theory (Martin and White, 2005), attitude types define the specifics of appraisal being expressed: affect (personal emotional state), judgment (social or ethical appraisal of other's behaviour), and appreciation (evaluation of phenomena).\nTo analyse contextual sentiment of a phrase or a sentence, rule-based approaches (Nasukawa and Yi, 2003;Moilanen and Pulman, 2007;Subrahmanian and Reforgiato, 2008), a machinelearning method using not only lexical but also syntactic features (Wilson et al., 2005), and a model of integration of machine learning approach with compositional semantics (Choi and Cardie, 2008) were proposed. With the aim to recognize fine-grained emotions from text on the level of distinct sentences, researchers have employed a keyword spotting technique (Chuang and Wu, 2004;Strapparava et al., 2007), a technique calculating emotion scores using Pointwise Mutual Information (PMI) (Kozareva et al., 2007), an approach inspired by common-sense knowledge (Liu et al., 2003), rule-based linguistic approaches (Boucouvalas, 2003;Chaumartin, 2007), machine-learning methods (Alm, 2008;Aman and Szpakowicz, 2008;Strapparava and Mihalcea, 2008), and an ensemble based multilabel classification technique (Bhowmick et al., 2009). Early attempts to focus on distinct attitude types in the task of attitude analysis were made by Taboada and Grieve (2004), who determined a potential value of adjectives for affect, judgement and appreciation by calculating the PMI with the pronoun-copular pairs 'I was (affect)', 'He was (judgement)', and 'It was (appreciation)', and Whitelaw et al. (2005), who used a machine learning technique (SVM) with finegrained semantic distinctions in features (attitude type, orientation) in combination with \"bag of words\" to classify movie reviews. However, the concentration only on adjectives expressing appraisal and their modifiers greatly narrows the potential of the Whitelaw et al. (2005) approach.\nIn this paper we introduce our system @AM (ATtitude Analysis Model), which (1) classifies sentences according to the fine-grained attitude labels (nine affect categories (Izard, 1971): 'anger', 'disgust', 'fear', 'guilt', 'interest', 'joy', 'sadness', 'shame', 'surprise'; four polarity labels for judgment and appreciation: 'POS jud ', 'NEG jud', 'POS app', 'NEG app'; and 'neutral'); (2) assigns the strength of the attitude; and\n(3) determines the level of confidence, with which the attitude is expressed. @AM relies on a compositionality principle and a novel approach based on the rules elaborated for semantically distinct verb classes.", "publication_ref": ["b13", "b16", "b15", "b20", "b23", "b5", "b6", "b19", "b11", "b12", "b3", "b4", "b0", "b1", "b18", "b2", "b21", "b22", "b22", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Lexicon for Attitide Analysis", "text": "We built a lexicon for attitude analysis that includes: (1) attitude-conveying terms; (2) modifiers; (3) \"functional\" words; and (4) modal operators.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Core of Lexicon", "text": "As a core of lexicon for attitude analysis, we employ an Affect database and extended version of the SentiFul database developed by Neviarouskaya et al. (2009). The affective features of each emotion-related word are encoded using nine emotion labels ('anger', 'disgust', 'fear', 'guilt', 'interest', 'joy', 'sadness', 'shame', and 'surprise') and corresponding emotion intensities that range from 0.0 to 1.0. The original version of SentiFul database, which contains sentimentconveying adjectives, adverbs, nouns, and verbs annotated by sentiment polarity, polarity scores and weights, was manually extended using attitude labels. Some examples of annotated attitude-conveying words are listed in Table 1. It is important to note here that some words may express different attitude types (affect, judgment, appreciation) depending on context; such lexical entries were annotated by all possible categories. ", "publication_ref": ["b17"], "figure_ref": [], "table_ref": []}, {"heading": "POS", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Modifiers and Functional Words", "text": "We collected 138 modifiers that have an impact on contextual attitude features of related words, phrases, or clauses. They include: 1. Adverbs of degree (e.g., 'significantly', 'slightly' etc.) and affirmation (e.g., 'absolutely', 'seemingly') that have an influence on the strength of the attitude of related words. Two annotators gave coefficients for intensity degree strengthening or weakening (from 0.0 to 2.0) to each adverb, and the result was averaged (e.g., coeff('slightly') = 0.2).\n2. Negation words (e.g., 'never', 'nothing' etc.) reversing the polarity of related statement.\n3. Adverbs of doubt (e.g., 'scarcely', 'hardly' etc.) and falseness (e.g., 'wrongly' etc.) reversing the polarity of related statement.\n4. Prepositions (e.g., 'without', 'despite' etc.) neutralizing the attitude of related words.\n5. Condition operators (e.g., 'if', 'even though' etc.) that neutralize the attitude of related words. We distinguish two types of \"functional\" words that influence contextual attitude and its strength:\n1. Intensifying adjectives (e.g., 'rising', 'rapidly-growing'), nouns (e.g., 'increase'), and verbs (e.g., 'to grow', 'to rocket') that increase the strength of attitude of related words.\n2. Reversing adjectives (e.g., 'reduced'), nouns (e.g., 'termination), and verbs (e.g., 'to decrease', 'to limit', 'to diminish'), which reverse the prior polarity of related words.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Modal Operators", "text": "Consideration of the modal operators in the tasks of opinion mining and attitude analysis is very important, as they indicate a degree of person's belief in the truth of the proposition, which is subjective in nature (Hoye, 1997). Modals are distinguished by their confidence level. We collected modal operators of two categories: modal verbs (13 verbs) and modal adverbs (61 adverbs). Three human annotators assigned the confidence level ranging from 0.0 to 1.0 to each modal verb and adverb; these ratings were averaged (e.g., conf('vaguely') = 0.17, conf('arguably') = 0.63, conf('would') = 0.8, conf('veritably') = 1.0).", "publication_ref": ["b8"], "figure_ref": [], "table_ref": []}, {"heading": "Compositionality Principle", "text": "Our algorithm for attitude classification is designed based on the compositionality principle, according to which we determine the attitudinal meaning of a sentence by composing the pieces that correspond to lexical units or other linguistic constituent types governed by the rules of polarity reversal, aggregation (fusion), propagation, domination, neutralization, and intensification, at various grammatical levels.\nPolarity reversal means that a phrase or statement containing an attitude-conveying term/phrase with prior positive polarity becomes negative, and vice versa.  ('reduced enthusiasm')). In the case of judgment and appreciation, the use of the polarity reversal rule is straightforward ('POS jud' <=> 'NEG jud', 'POS app' <=> 'NEG app'). However, it is not trivial to find pairs of opposite emotions in the case of a fine-grained classification, except for 'joy' and 'sadness'. Therefore, we assume that (1) the opposite emotion for three positive emotions, i.e. 'interest', 'joy', and 'surprise', is 'sadness' ('POS aff' => 'sadness'); and (2) the opposite emotion for six negative emotions, i.e. 'anger', 'disgust', 'fear', 'guilt', 'sadness', and 'shame', is 'joy' ('NEG aff' => 'joy').\nThe rules of aggregation (fusion) are as follows: (1) if polarities of attitude-conveying terms in adjective-noun, noun-noun, adverb-adjective, adverb-verb phrases have opposite directions, mixed polarity with dominant polarity of a premodifier is assigned to the phrase (e.g., POS('beautiful') & NEG('fight') => POSneg('beautiful fight'); NEG('shamelessly') & POS('celebrate') => NEG-pos('shamelessly celebrate')); otherwise (2) the resulting polarity is based on the equal polarities of terms, and the strength of attitude is measured as a maximum between polarity scores (intensities) of terms (max(score1,score2)).\nThe rule of propagation is useful, as proposed in (Nasukawa and Yi, 2003), for the task of the detection of local sentiments for given subjects. \"Propagation\" verbs propagate the sentiment towards the arguments; \"transfer\" verbs transmit sentiments among the arguments. The rule of propagation is applied when a verb of \"propagation\" or \"transfer\" type is used in a phrase/clause and sentiment of an argument that has prior neutral polarity needs to be investigated (e.g., PROP-POS('to admire') & 'his behaviour' => POS('his behaviour'); 'Mr.", "publication_ref": ["b16"], "figure_ref": [], "table_ref": []}, {"heading": "X' & TRANS('supports') & NEG('crime business')", "text": "=> NEG('Mr. X')).\nThe rules of domination are as follows: (1) if polarities of a verb (this rule is applied only for certain classes of verbs) and an object in a clause have opposite directions, the polarity of verb is prevailing (e.g., NEG('to deceive') & POS('hopes') => NEG('to deceive hopes')); (2) if compound sentence joints clauses using coordinate connector 'but', the attitude features of a clause following after the connector are dominant (e.g., 'NEG(It was hard to climb a mountain all night long), but POS(a magnificent view rewarded the traveler at the morning).' => POS(whole sentence)).\nThe rule of neutralization is applied when preposition-modifier or condition operator relate to the attitude-conveying statement (e.g., 'despite' & NEG('worries') => NEUT('despite worries')).\nThe rule of intensification means strengthening or weakening of the polarity score (intensity), and is applied when:\n1. adverb of degree or affirmation relates to attitude-conveying term (e.g., Pos_score('happy') < Pos_score('extremely happy')); 2. adjective or adverb is used in a comparative or superlative form (e.g., Neg_score('sad') < Neg_score('sadder') < Neg_score ('saddest')). Our method is capable of processing sentences of different complexity, including simple, compound, complex (with complement and relative clauses), and complex-compound sentences. We employ Connexor Machinese Syntax parser (http://www.connexor.eu/) that returns lemmas, parts of speech, dependency functions, syntactic function tags, and morphological tags. When handling the parser output, we represent the sentence as a set of primitive clauses. Each clause might include Subject formation, Verb formation and Object formation, each of which may consist of a main element (subject, verb, or object) and its attributives and complements. For the processing of complex or compound sentences, we build a so-called \"relation matrix\", which contains information about dependences (e.g., coordination, subordination, condition, contingency, etc.) between different clauses in a sentence. While applying the compositionality principle, we consecutively assign attitude fea-tures to words, phrases, formations, clauses, and finally, to the whole sentence.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Consideration of the Semantics of Verbs", "text": "All sentences must include a verb, because the verb tells us what action the subject is performing and object is receiving. In order to elaborate rules for attitude analysis based on the semantics of verbs, we investigated VerbNet (Kipper et al., 2007), the largest on-line verb lexicon that is organized into verb classes characterized by syntactic and semantic coherence among members of a class. Based on the thorough analysis of 270 first-level classes of VerbNet and their members, 73 verb classes (1) were found useful for the task of attitude analysis, and (2) were further classified into 22 classes differentiated by the role that members play in attitude analysis and by rules applied to them. Our classification is shown in Table 2.\nFor each of our verb classes, we developed set of rules that are applied to attitude analysis on the phrase/clause-level. Some verb classes (e.g., \"Psychological state or emotional reaction\", \"Judgment\", \"Bodily state and damage to the body\", \"Preservation\" etc.) include verbs annotated by attitude type, prior polarity orientation, and the strength of attitude. The attitude features of phrases that involve positively or negatively charged verbs from such classes are contextsensitive and are defined by means of rules designed for each of the class.\nAs an example, we provide short description and rules elaborated for the subclass \" Objectcentered (oriented)   In the majority of rules the strength of attitude is measured as a maximum between attitude scores (for example, the attitude conveyed by 'to suffer from grave illness' is stronger than that of 'to suffer from slight illness').\nIn contrast to the rules of \"Object-centered (oriented) emotional state\" subclass, which ignore attitude features of a subject in a sentence, the rules elaborated for the \"Subject-driven change in emotional state (trans.)\" disregard the attitude features of object, as in sentences involving members of this subclass object experiences emotion, and subject causes the emotional state. The Verb-Object rules for the \"Judgment\" subclasses, namely \"Positive judgment\" and \"Negative judgment\", are very close to those defined for the subclass \"Object-centered (oriented) emotional state\". However, Verb-PP rules have some specifics: for both positive and negative judgment verbs, we treat PP starting with 'for'/'of'/'as' the same way as object in Verb-Object rules. Verbs from classes \"Favorable attitude\" and \"Adverse (unfavorable) attitude\" have prior neutral polarity and positive or negative reinforcement, correspondingly, that means that they only impact on the polarity and strength of nonneutral phrase (object in a sentence written in active voice, or subject in a sentence written in passive voice, or PP in case of some verbs). The rules are: 1. If verb belongs to the \"Favorable attitude\" class and the polarity of phrase is not neutral, then the attitude score of the phrase is intensified (symbol '^' means intensification):  ', 'on', 'against', 'about', 'concerning', 'regarding', 'that', 'how' etc.;  In the last example, to measure the sentiment of PP, we apply rule for the verb 'end' from the \"Termination of activity\" class, which reverses the non-neutral polarity of subject (in intransitive use of verb) or object (in transitive use of verb). For example, the polarity of both sentences 'My whole enthusiasm and excitement disappear like a bubble touching a hot needle' and 'They discontinued helping children' is negative.\nS('They') & [V", "publication_ref": ["b10"], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Decision on Attitude Label", "text": "The decision on the most appropriate final label for the clause, in case @AM annotates it using different attitude types according to the words with multiple annotations (e.g., see word 'unfriendly' in Table 1) or based on the availability of the words conveying different attitude types, is made based on the analysis of:\n1) morphological tags of nominal heads and their premodifiers in the clause (e.g., first person pronoun, third person pronoun, demonstrative pronoun, nominative or genitive noun, etc.);\n2) the sequence of hypernymic semantic relations of a particular noun in WordNet (Miller, 1990), which allows to determine its conceptual domain (e.g., \"person, human being\", \"artifact\", \"event\", etc.);\n3) the annotations from the Stanford Named Entity Recognizer (Finkel et al. 2005) that labels PERSON, ORGANIZATION, and LOCATION entities. For ex., 'I feel highly unfriendly attitude towards me' conveys emotion ('NEG aff': 'sadness'), while 'The shop assistant's behavior was really unfriendly' and 'Plastic bags are environment unfriendly' express judgment ('NEG jud') and appreciation ('NEG app'), correspondingly.", "publication_ref": ["b14", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Evaluation", "text": "For the experiments, we used our own data set, as, to the best of our knowledge, there is no publicly available data set of sentences annotated by the fine-grained labels proposed in our work. In order to evaluate the performance of our algorithm, we created the data set of sentences extracted from personal stories about life experiences that were anonymously published on the Experience Project website (www.experienceproject.com), where people share personal experiences, thoughts, opinions, feelings, passions, and confessions through the network of personal stories. With over 4 million experiences accumulated (as of February 2010), Experience Project is a perfect source for researchers interested in studying different types of attitude expressed through text.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Data Set Description", "text": "For our experiment we extracted 1000 sentences 1 from various stories grouped by topics within 13 different categories, such as \"Arts and entertainment\", \"Current events\", \"Education\", \"Family and friends\", \"Health and wellness\", \"Relationships and romance\" and others, on the Experience Project website. Sentences were collected from 358 distinct topic groups, such as \"I still remember September 11\", \"I am intelligent but airheaded\", \"I think bullfighting is cruel\", \"I quit smoking\", \"I am a fashion victim\", \"I was adopted\" and others.\nWe considered three hierarchical levels of attitude labels in our experiment (see Figure 1). Three independent annotators labeled the sentences with one of 14 categories from the ALL level and a corresponding score (the strength or intensity value). These annotations were further interpreted using labels from the MID and the TOP levels. Fleiss' Kappa coefficient was used as a measure of reliability of human raters' annotations. The agreement coefficient on 1000 sentences was 0.53 on ALL level, 0.57 on MID level, and 0.73 on TOP level.\nOnly those sentences, on which at least two out of three human raters completely agreed, were included in the gold standards for our experiment. Three gold standards were created according to the hierarchy of attitude labels. Fleiss' Kappa coefficients are 0.62, 0.63, and 0.74 on ALL, MID, and TOP levels, correspondingly. Table 3 shows the distributions of labels in the gold standards. Table 3. Label distributions in gold standards.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "The results of a simple method selecting the attitude label with the maximum intensity from the annotations of sentence tokens found in the database were considered as the baseline. After processing each sentence from the data set by the baseline method and our @AM system, we measured averaged accuracy, precision, recall, and F-score for each label in ALL, MID, and TOP levels. The results are shown in Table 4.\nAs seen from the obtained results, our algorithm performed with high accuracy significantly surpassing the baselines in all levels of attitude hierarchy, thus demonstrating the contribution of the sentence parsing and our hand-crafted rules to the reliable recognition of attitude from text. Two-tailed t-tests with significance level of 0.05 showed that the differences in accuracy between the baseline method and our @AM system are statistically significant (p<0.001) in fine-grained as well as coarse-grained classifications.\nIn the case of fine-grained attitude recognition (ALL level), the highest precision was obtained for 'shame' (0.923) and 'NEG jud' (0.889), while the highest recall was received for 'sadness' (0.917) and 'joy' (0.905) emotions at the cost of low precision (0.528 and 0.439, correspondingly). The algorithm performed with the worst results in recognition of 'NEG app' and 'neutral'.\nThe analysis of a confusion matrix for the ALL level revealed the following top confusions of our system: (1) 'anger', 'fear', 'guilt', 'shame', 'NEG jud', 'NEG app' and 'neutral' were predominantly incorrectly predicted as 'sadness' (for ex., @AM resulted in 'sadness' for the sentence 'I know we have several months left before the election, but I am already sick and tired of seeing the ads on TV', while human annotations were 'anger'/'anger'/'disgust'); (2) 'interest', 'POS jud' and 'POS app' were mostly confused with 'joy' by our algorithm (e.g., @AM classified the sentence 'It's one of those life changing artifacts that we must have in order to have happier, healthier lives' as 'joy'(-ful), while human annotations were 'POS app'/'POS app'/'interest').\nOur system achieved high precision for all categories on the MID level ( These results indicate that affect sensing is easier than recognition of judgment or appreciation from text. TOP level results (Table 4) show that our algorithm classifies sentences that convey positive or negative sentiment with high accuracy (92% and 91%, correspondingly). On the other hand, 'neutral' sentences still pose a challenge. The analysis of errors revealed that system requires common sense or additional context to deal with sentences like 'All through my life I've felt like I'm second fiddle' (gold standard: 'sadness'; @AM: 'neutral') or 'For me every minute on my horse is alike an hour in heaven!' (gold standard: 'joy'; @AM: 'neutral').\nWe also evaluated the system performance with regard to attitude intensity estimation. The percentage of attitude-conveying sentences (not considering neutral ones), on which the result of our system conformed to the fine-grained gold standard (ALL level), according to the measured distance between intensities given by human raters (averaged values) and those obtained by our system is shown in Table 5. As seen from the table, our system achieved satisfactory results in estimation of the strength of attitude expressed through text.  ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_7", "tab_7", "tab_8"]}, {"heading": "Conclusions", "text": "In this paper we introduced @AM, which is so far, to the best of our knowledge, the only system classifying sentences using fine-grained attitude types, and extensively dealing with the semantics of verbs in attitude analysis. Our composition approach broadens the coverage of sentences with complex contextual attitude. The evaluation results indicate that @AM achieved reliable results in the task of textual attitude analysis. The limitations include dependency on lexicon and on accuracy of the parser. The primary objective for the future research is to develop a method for the extraction of reasons behind the expressed attitude.  ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Affect in Text and Speech. PhD Dissertation", "journal": "", "year": "2008", "authors": "Cecilia O Alm"}, {"ref_id": "b1", "title": "Using Roget's Thesaurus for Fine-Grained Emotion Recognition", "journal": "", "year": "2008", "authors": "Saima Aman; Stan Szpakowicz"}, {"ref_id": "b2", "title": "Reader Perspective Emotion Analysis in Text through Ensemble based Multi-Label Classification Framework", "journal": "Computer and Information Science", "year": "2009", "authors": "Plaban K Bhowmick; Anupam Basu; Pabitra Mitra"}, {"ref_id": "b3", "title": "Real Time Text-to-Emotion Engine for Expressive Internet Communications. Being There: Concepts, Effects and Measurement of User Presence in Synthetic Environments", "journal": "Ios Press", "year": "2003", "authors": "Anthony C Boucouvalas"}, {"ref_id": "b4", "title": "UPAR7: A Knowledge-based System for Headline Sentiment Tagging", "journal": "", "year": "2007", "authors": "Francois-Regis Chaumartin"}, {"ref_id": "b5", "title": "Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis", "journal": "", "year": "2008", "authors": "Yejin Choi; Claire Cardie"}, {"ref_id": "b6", "title": "Multimodal Emotion Recognition from Speech and Text", "journal": "", "year": "2004", "authors": "Ze-Jing Chuang; Chung-Hsien Wu"}, {"ref_id": "b7", "title": "Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling", "journal": "", "year": "2005", "authors": "Jenny R Finkel; Trond Grenager; Christopher Manning"}, {"ref_id": "b8", "title": "Adverbs and Modality in English", "journal": "Addison Wesley Longman Inc", "year": "1997", "authors": "Leo Hoye"}, {"ref_id": "b9", "title": "The Face of Emotion", "journal": "Appleton-Century-Crofts", "year": "1971", "authors": "Carroll E Izard"}, {"ref_id": "b10", "title": "A Large-scale Classification of English Verbs. Language Resources and Evaluation", "journal": "", "year": "2007", "authors": "Karin Kipper; Anna Korhonen; Neville Ryant; Martha Palmer"}, {"ref_id": "b11", "title": "UA-ZBSA: A Headline Emotion Classification through Web Information", "journal": "", "year": "2007", "authors": "Zornitsa Kozareva; Borja Navarro; Sonia Vazquez; Andres Montoyo; A "}, {"ref_id": "b12", "title": "A Model of Textual Affect Sensing Using Real-World Knowledge", "journal": "", "year": "2003", "authors": "Hugo Liu; Henry Lieberman; Ted Selker"}, {"ref_id": "b13", "title": "The Language of Evaluation: Appraisal in English", "journal": "Palgrave", "year": "2005", "authors": "James R Martin; Peter R R White"}, {"ref_id": "b14", "title": "WordNet: An On-line Lexical Database", "journal": "International Journal of Lexicography, Special Issue", "year": "1990", "authors": "George A Miller"}, {"ref_id": "b15", "title": "Sentiment Composition", "journal": "", "year": "2007", "authors": "Karo Moilanen; Stephen Pulman"}, {"ref_id": "b16", "title": "Sentiment Analysis: Capturing Favorability using Natural Language Processing", "journal": "", "year": "2003", "authors": "Tetsuya Nasukawa; Jeonghee Yi"}, {"ref_id": "b17", "title": "SentiFul: Generating a Reliable Lexicon for Sentiment Analysis", "journal": "IEEE", "year": "2009", "authors": "Alena Neviarouskaya; Helmut Prendinger; Mitsuru Ishizuka"}, {"ref_id": "b18", "title": "Learning to Identify Emotions in Text", "journal": "", "year": "2008", "authors": "Carlo Strapparava; Rada Mihalcea"}, {"ref_id": "b19", "title": "Dances with Words", "journal": "", "year": "2007", "authors": "Carlo Strapparava; Alessandro Valitutti; Oliviero Stock"}, {"ref_id": "b20", "title": "AVA: Adjective-Verb-Adverb Combinations for Sentiment Analysis. Intelligent Systems", "journal": "IEEE", "year": "2008", "authors": "V S Subrahmanian; Diego Reforgiato"}, {"ref_id": "b21", "title": "Analyzing Appraisal Automatically", "journal": "", "year": "2004", "authors": "Maite Taboada; Jack Grieve"}, {"ref_id": "b22", "title": "Using Appraisal Groups for Sentiment Analysis", "journal": "", "year": "2005", "authors": "Casey Whitelaw; Navendu Garg; Shlomo Argamon"}, {"ref_id": "b23", "title": "Recognizing Contextual Polarity in Phraselevel Sentiment Analysis", "journal": "", "year": "2005", "authors": "Theresa Wilson; Janyce Wiebe; Paul Hoffmann"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "For example (due to limitation of space, here and below we provide only some cases): S('Classical music') & V+('calmed') & O-('disobedient child') => interior: 'POS aff'; exterior: 'POS app'. S-('Fatal consequences of GM food intake') & V-('frighten') & O('me') => interior: 'NEG aff'; exterior: 'NEG app'.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "For example: S('He') & V-('blamed') & O+('innocent person') => interior: 'NEG jud'; exterior: 'NEG jud'. S('They') & V-('punished') & O('him') & PP-('for his misdeed') => interior: 'NEG jud'; exterior: 'POS jud'.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Object-centered (oriented)  emotional state (adore) 1.2 Subject-driven change in emotional state (trans.) (charm, inspire, bother) 1.3 Subject-driven change in emotional state (intrans.) (appeal to, grate on)", "figure_data": "Verb class (verb samples)1 Psychological state or emotional reaction1.1 2 Judgment2.1 Positive judgment (bless, honor)2.2 Negative judgment (blame, punish)3 Favorable attitude (accept, allow, tolerate)4 Adverse (unfavorable) attitude (discourage, forbid)5 Favorable or adverse calibratable changes of state(grow, decline)6 Verbs of removing6.1 Verbs of removing with neutral charge (delete)6.2 Verbs of removing with negative charge (expel)6.3 Verbs of removing with positive charge (evacuate)7 Negatively charged change of state (break, crush)8 Bodily state and damage to the body (sicken, injure)9 Aspectual verbs9.1 Initiation, continuation of activity, and sustaining(begin, continue, maintain)9.2 Termination of activity (quit, finish)10 Preservation (defend, insure)11 Verbs of destruction and killing (damage, poison)12 Disappearance (disappear, die)13 Limitation and subjugation (confine, restrict)14 Assistance (succor, help)15 Obtaining (win, earn)16 Communication indicator/reinforcement of attitude(guess, complain, deny)17 Verbs of leaving (abandon, desert)18 Changes in social status or condition (canonize)19 Success and failure19.1 Success (succeed, manage)19.2 Failure (fail, flub)20 Emotional nonverbal expression (smile, weep)21 Social interaction (marry, divorce)22 Transmitting verbs (supply, provide)emotional state\".Features: subject experiences emotions towardssome stimulus; verb prior polarity: positive ornegative; context-sensitive.Verb-Object rules (subject is ignored):1. \"Interior perspective\" (subject's inner emotionstate or attitude):S & V+('admires') & O+('his brave heart')=> (fusion, max(V_score,O_score)) => 'POSaff'.S & V+('admires') & O-('mafia leader') =>(verb valence dominance, V_score) => 'POSaff'.S & V-('disdains') & O+('his honesty') =>(verb valence dominance, V_score) => 'NEGaff'."}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Verb classes for attitude analysis.", "figure_data": "S & V-('disdains') & O-('criminal activities')=> (fusion, max(V_score,O_score)) => 'NEGaff'.2. \"Exterior perspective\" (social/ethical judg-ment):S & V+('admires') & O+('his brave heart')=> (fusion, max(V_score,O_score)) => 'POSjud'.S & V+('admires') & O-('mafia leader') =>(verb valence reversal, max(V_score,O_score))=> 'NEG jud'.S & V-('disdains') & O+('his honesty') =>(verbvalencedominance,max(V_score,O_score)) => 'NEG jud'.S & V-('disdains') & O-('criminal activities')=>(verbvalencereversal,max(V_score,O_score)) => 'POS jud'."}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "", "figure_data": "), with the"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Results on intensity.", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Results of the evaluation of performance of the baseline method and @AM system.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "S('They') & [V", "formula_coordinates": [5.0, 314.92, 278.83, 70.0, 9.57]}], "doi": ""}