{"title": "Certified Dominance and Symmetry Breaking for Combinatorial Optimisation", "authors": "Bart Bogaerts; Stephan Gocht; Ciaran Mccreesh; Jakob Nordstr\u00f6m", "pub_date": "2023-08-16", "abstract": "Symmetry and dominance breaking can be crucial for solving hard combinatorial search and optimisation problems, but the correctness of these techniques sometimes relies on subtle arguments. For this reason, it is desirable to produce efficient, machine-verifiable certificates that solutions have been computed correctly. Building on the cutting planes proof system, we develop a certification method for optimisation problems in which symmetry and dominance breaking is easily expressible. Our experimental evaluation demonstrates that we can efficiently verify fully general symmetry breaking in Boolean satisfiability (SAT) solving, thus providing, for the first time, a unified method to certify a range of advanced SAT techniques that also includes cardinality and parity (XOR) reasoning. In addition, we apply our method to maximum clique solving and constraint programming as a proof of concept that the approach applies to a wider range of combinatorial problems. 1. https://theconversation.com/what-problems-will-ai-solve-in-future-an-old-britishgameshow-can-help-explain-49080", "sections": [{"heading": "Introduction", "text": "Symmetries pose a challenge when solving hard combinatorial problems. As an illustration of this, consider the Crystal Maze puzzle 1 shown in Figure 1, which is often used in introductory constraint modelling courses. A human modeller might notice that the puzzle is the same after flipping vertically, and could introduce the constraint A < G to eliminate this symmetry. Or, they may notice that flipping horizontally induces a symmetry, which could be broken with A < B. Alternatively, they might spot that the values are symmetrical, and that we can interchange 1 and 8, 2 and 7, and so on; this can be eliminated by saying that A \u2264 4. In each case a constraint is being added that preserves satisfiability overall, but that restricts a solver to finding (ideally) just one witness from each equivalence class of solutions-the hope is that this will improve solver performance. However, although we may be reasonably sure that any of these three constraints is correct individually, are combinations of these constraints valid simultaneously? What if we had said F < C instead And what if we could use numbers more than once? Getting symmetry elimination constraints right can be error-prone even for experienced modellers. And when dealing with larger problems with many constraints and interacting symmetries it can be hard to tell whether a problem instance is genuinely unsatisfiable, or was made so by an incorrectly added symmetry breaking constraint. Despite these difficulties, symmetry elimination using both manual and automatic techniques has been key to many successes across modern combinatorial optimisation paradigms such as constraint programming (CP) (Garcia de la Banda, Stuckey, Van Hentenryck, & Wallace, 2014), Boolean satisfiability (SAT) solving (Sakallah, 2021), and mixed-integer programming (MIP) (Achterberg & Wunderling, 2013). As these optimisation technologies are increasingly being used for high-value and life-affecting decision-making processes, it becomes vital that we can trust their outputs-and unfortunately, current solvers do not always produce correct answers (Brummayer, Lonsing, & Biere, 2010;Cook, Koch, Steffy, & Wolter, 2013;Akg\u00fcn, Gent, Jefferson, Miguel, & Nightingale, 2018;Gillard, Schaus, & Deville, 2019;Bogaerts, McCreesh, & Nordstr\u00f6m, 2022).\nThe most promising way to address this problem of correctness appears to be to use certification, or proof logging, where a solver must produce an efficiently machine-verifiable certificate that the answer to the problem was computed correctly (Alkassar, B\u00f6hme, Mehlhorn, Rizkallah, & Schweitzer, 2011;McConnell, Mehlhorn, N\u00e4her, & Schweitzer, 2011). This approach has been successfully used in the SAT community, which has developed numerous proof logging formats such as RUP (Goldberg & Novikov, 2003), TraceCheck (Biere, 2006), DRAT (Heule, Hunt Jr., & Wetzler, 2013a, 2013bWetzler, Heule, & Hunt Jr., 2014), GRIT (Cruz-Filipe, Marques-Silva, & Schneider-Kamp, 2017b), and LRAT (Cruz-Filipe, Heule, Hunt Jr., Kaufmann, & Schneider-Kamp, 2017a). However, currently used methods work only for decision problems, and do not support the full range of SAT solving techniques, let alone CP and MIP solving. As a case in point, there is no efficient proof logging for symmetry breaking, except for limited cases with small symmetries which can interact only in simple ways (Heule, Hunt Jr., & Wetzler, 2015). Tchinda and Djam\u00e9gni (2020) recently proposed a proof logging method DSRUP for symmetric learning of variants of derived clauses, but this format does not support symmetry breaking (in the sense just discussed) and is also inherently unable to support pre-and inprocessing techniques, which are crucial in state-of-the-art SAT solvers.", "publication_ref": ["b34", "b63", "b0", "b16", "b24", "b1", "b37", "b15", "b2", "b58", "b43", "b10", "b45", "b46", "b71", "b26", "b47", "b65"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Our Contribution", "text": "In this work, we develop a proof logging method for optimisation problems-i.e., problems where we are given both a formula F and an objective function f to be optimised by some assignment satisfying F -that can deal with dominance, a generalization of symmetry. Dominance breaking starts from the observation that we can strengthen F by imposing an additional constraint C if every solution of F that does not satisfy C is dominated by another solution of F . This technique is used in many fields of combinatorial optimisation (Walsh, 2006(Walsh, , 2012Gent, Petrie, & Puget, 2006;McCreesh & Prosser, 2016;Jouglet & Carlier, 2011;Gebser, Kaminski, & Schaub, 2011;Bulh\u00f5es, Sadykov, & Uchoa, 2018;Hoogeboom, Dullaert, Lai, & Vigo, 2020;Baptiste & Pape, 1997;Demeulemeester & Herroelen, 2002). And even if we are given just a decision problem for a formula F , we can still use this framework by inventing an objective function minimizing the lexicographic order of assignments, and then do symmetry breaking by adding dominance constraints with respect to this order.\nThe core idea to make our method produce efficiently verifiable proofs is to have it present an explicit construction of a dominating solution, so that a verifier can check that this construction strictly improves the objective value and preserves satisfaction of F . This constructed solution might itself be dominated, and hence not satisfy C, but since the objective value decreases with every application of the construction, we can be sure, without performing the repeated process, that it would be guaranteed to eventually terminate. Importantly, verifying the correctness of adding such a constraint C does not require the construction of an actual assignment satisfying C, and can be performed efficiently even when multiple constraints are to be added. This resolves a practical issue with earlier approaches like that of Heule et al. (2015). Such approaches struggle with large or overlapping symmetries, because adding a new symmetry breaking constraint might make it necessary to re-break previously added constraints, and to understand precisely how the different symmetries interact in order to be able to do so. With our method, we never need to revisit previously broken symmetries.\nIn addition, although we do not develop this direction in the current paper, it should also be noted that a quite intriguing feature of our method is that we could break symmetries of a problem with respect to a higher-order representation in pseudo-Boolean form in a provably correct way, even if the encoding in the conjunctive normal form (CNF) used by SAT solvers is not symmetric. If the solver is given a problem in pseudo-Boolean representation, then it could add symmetry breaking constraints based on this pseudo-Boolean representation, then translate the PB representation to CNF in a certified way (Gocht, Martins, Nordstr\u00f6m, & Oertel, 2022), and finally produce a proof that the combination of all of these constraints is a valid encoding of the original problem. Following preliminaries in Section 2, we describe in full detail in Section 3 our dominance-based method of reasoning and prove that it is sound.\nWe have developed a proof format and verifier for this proof logging method by extending the tool VeriPB (Elffers, Gocht, McCreesh, & Nordstr\u00f6m, 2020;Gocht & Nordstr\u00f6m, 2021;Gocht, McCreesh, & Nordstr\u00f6m, 2020b;Gocht, McBride, McCreesh, Nordstr\u00f6m, Prosser, & Trimble, 2020a) with dominance reasoning. The pseudo-Boolean constraints and cutting planes proof system (Cook, Coullard, & Tur\u00e1n, 1987) used by VeriPB turn out to be quite convenient to express and reason with dominance constraints, and moreover also make it possible to certify cardinality and parity (XOR) reasoning (Gocht & Nordstr\u00f6m, 2021), two other advanced SAT solving techniques which previous proof logging methods have not been able to support efficiently.\nAfter introducing the proof system that we have developed as the foundation of our proof logging method, we exhibit three applications that have not previously admitted efficient certification, and demonstrate that our new method can support simple, practical proof logging in each case. 2 First, in Section 4, we demonstrate that, by enhancing the BreakID tool for SAT solving (Devriendt, Bogaerts, Bruynooghe, & Denecker, 2016) with VeriPB proof logging, we can cover the entire solving toolchain when symmetries are involved. We show in full generality, and for the first time, that proof logging is practical by running experiments on SAT competition benchmarks. Second, in Section 5, we revisit the Crystal Maze example and describe a tool that provides proof logging for the kind of symmetry breaking constraints discussed above. Third, in Section 6, we discuss how adding a rule for deriving dominance breaking constraints can be used to support vertex domination reasoning in a maximum clique solver. We conclude the paper proper with a brief discussion of future research directions in Section 7. Appendix A contains a worked-out example of proof logging for symmetry breaking.", "publication_ref": ["b69", "b70", "b36", "b59", "b51", "b35", "b17", "b49", "b4", "b28", "b47", "b38", "b33", "b42", "b40", "b39", "b23", "b42", "b30"], "figure_ref": [], "table_ref": []}, {"heading": "Publication History", "text": "An extended abstract of this paper was presented at the 36th AAAI Conference on Artificial Intelligence (Bogaerts, Gocht, McCreesh, & Nordstr\u00f6m, 2022a). The current manuscript extends the previous work with full proofs of all formal claims, and includes a more detailed exposition of the proof system and proof logging applications.", "publication_ref": ["b12"], "figure_ref": [], "table_ref": []}, {"heading": "Preliminaries", "text": "Let us start with a brief review of some standard material, referring the reader to, e.g., Buss and Nordstr\u00f6m (2021) for more details. A literal \u2113 over a Boolean variable x is x itself or its negation x = 1 \u2212 x, where variables take values 0 (false) or 1 (true). A pseudo-Boolean (PB) constraint is a 0-1 linear inequality\nC . = i a i \u2113 i \u2265 A ,(1)\nwhere a i and A are integers (and . = denotes syntactic equality). We can assume without loss of generality that pseudo-Boolean constraints are normalized ; i.e., that all literals \u2113 i are over distinct variables and that the coefficients a i and the degree (of falsity) A are nonnegative, but most of the time we will not need this. Instead, we will write PB constraints in more relaxed form as i a i \u2113 i \u2265 A + j b j \u2113 j or i a i \u2113 i \u2264 A + j b j \u2113 j when convenient, or even use equality i a i \u2113 i = A as syntactic sugar for the pair of inequalities i a i \u2113 i \u2265 A and i \u2212a i \u2113 i \u2265 \u2212A, assuming that all constraints are implicitly normalized if needed.\nThe negation \u00acC of the constraint C in ( 1) is (the normalized form of)\n\u00acC . = i \u2212 a i \u2113 i \u2265 \u2212A + 1 .(2)\nA pseudo-Boolean formula is a conjunction F . = j C j of PB constraints, which we can also think of as the set j {C j } of constraints in the formula, choosing whichever viewpoint seems most convenient. Note that a (disjunctive) clause \u2113 1 \u2228 \u2022 \u2022 \u2022 \u2228 \u2113 k is equivalent to the pseudo-Boolean constraint \u2113 1 + \u2022 \u2022 \u2022 + \u2113 k \u2265 1, so formulas in conjunctive normal form (CNF) are special cases of PB formulas.\nA (partial) assignment is a (partial) function from variables to {0, 1}. A partial assignment is also referred to as a restriction. A substitution (or affine restriction) can also map variables to literals. We extend an assignment or substitution \u03c1 from variables to literals in the natural way by respecting the meaning of negation, and for literals \u2113 over variables x not in the domain of \u03c1, denoted x \u0338 \u2208 dom(\u03c1), we use the convention \u03c1(\u2113) = \u2113. (That is, we can consider all assignments and substitution to be total, but to be the identity outside of their specified domains. Strictly speaking, we also require that all substitutions be defined on the truth constants {0, 1} and be the identity on these constants.) We sometimes write x \u2192 b when \u03c1(x) = b, for b a literal or truth value, to specify parts of \u03c1 or when \u03c1 is clear from context.\nWe write \u03c1 \u2022 \u03c9 to denote the composed substitution resulting from applying first \u03c9 and then \u03c1, i.e., \u03c1 \u2022 \u03c9(x) = \u03c1(\u03c9(x)). As an example, for\n\u03c9 = {x 1 \u2192 0, x 3 \u2192 x 4 , x 4 \u2192 x 3 } and \u03c1 = {x 1 \u2192 1, x 2 \u2192 1, x 3 \u2192 0, x 4 \u2192 0} we have \u03c1 \u2022 \u03c9 = {x 1 \u2192 0, x 2 \u2192 1, x 3 \u2192 1, x 4 \u2192 0}.\nApplying \u03c9 to a constraint C as in (1) yields the restricted constraint\nC\u21be \u03c9 . = i a i \u03c9(\u2113 i ) \u2265 A ,(3)\nsubstituting literals or values as specified by \u03c9. For a formula F we define F\u21be \u03c9 . = j C j \u21be \u03c9 . Since we will sometimes have to make fairly elaborate use of substitutions, let us discuss some further notational conventions. If F is a formula over variables \u20d7 x = {x 1 , . . . , x m }, we can write F (\u20d7 x) when we want to stress the set of variables over which F is defined. For a substitution \u03c9 with domain (contained in) \u20d7 x, the notation F \u20d7 x\u21be \u03c9 is understood to be a synonym of F\u21be \u03c9 . For the same formula F and \u20d7 y = {y 1 , . . . , y m }, the notation F (\u20d7 y) is syntactic sugar for F\u21be \u03c9 with \u03c9 denoting the substitution (implicitly) defined by \u03c9(x i ) = y i for i = 1, . . . , n. Finally, for a formula G = G(\u20d7 x, \u20d7 y) over \u20d7 x \u222a \u20d7 y and substitutions \u03b1 and \u03b2 defined on \u20d7 z = {z 1 , . . . , z n } (either of which could be the identity), the notation G(\u20d7 z\u21be \u03b1 , \u20d7 z\u21be \u03b2 ) should be understood as G\u21be \u03c9 for \u03c9 defined by \u03c9(\nx i ) = \u03b1(z i ) and \u03c9(y i ) = \u03b2(z i ) for i = 1, . . . , n. The (normalized) constraint C in (1) is satisfied by \u03c1 if \u03c1(\u2113 i )=1 a i \u2265 A. A pseudo- Boolean formula F is satisfied by \u03c1 if all constraints in it are, in which case it is satisfiable.\nIf there is no satisfying assignment, F is unsatisfiable. Two formulas are equisatisfiable if they are both satisfiable or both unsatisfiable. In this paper, we also consider optimisation problems, where in addition to F we are given an integer linear objective function f . = i w i \u2113 i and the task is to find an assignment that satisfies F and minimizes f . (To deal with maximization problems we can just negate the objective function.)\nCutting planes (Cook et al., 1987) is a method for iteratively deriving constraints C from a pseudo-Boolean formula F . We write F \u22a2 C for any constraint C derivable as follows. Any axiom constraint C \u2208 F is trivially derivable, as is any literal axiom \u2113 \u2265 0. If F \u22a2 C and F \u22a2 D, then any positive integer linear combination of C and D is derivable. Finally, from a constraint in normalized form i a i \u2113 i \u2265 A we can use division by a positive integer d to derive i \u2308a i /d\u2309\u2113 i \u2265 \u2308A/d\u2309, dividing and rounding up the degree and coefficients. For a set of pseudo-Boolean constraints F \u2032 we write F \u22a2 F \u2032 if F \u22a2 C for all C \u2208 F \u2032 .\nFor pseudo-Boolean formulas F , F \u2032 and constraints C, C \u2032 , we say that F implies or models C, denoted F |= C, if any assignment satisfying F also satisfies C, and write\nF |= F \u2032 if F |= C \u2032 for all C \u2032 \u2208 F \u2032 .\nIt is easy to see that if F \u22a2 F \u2032 then F |= F \u2032 , and so F and F \u2227 F \u2032 are equisatisfiable. A piece of non-standard terminology that will be convenient for us is that we will say that a constraint C literal-axiom-implies another constraint C \u2032 if C \u2032 can be derived from C using only addition of literal axioms \u2113 \u2265 0.\nAn assignment \u03c1 falsifies or violates the constraint C if the restricted constraint C\u21be \u03c1 can not be satisfied. For the normalized constraint C in (1), this is the case if \u03c1(\u2113 i )\u0338 =0 a i < A.\nA constraint C unit propagates the literal \u2113 under \u03c1 if if C\u21be \u03c1 cannot be satisfied unless \u2113 \u2192 1. During unit propagation on F under \u03c1, the assignment \u03c1 is extended iteratively by any propagated literals until an assignment \u03c1 \u2032 is reached under which no constraint in F is propagating, or until \u03c1 \u2032 violates some constraint C \u2208 F . The latter scenario is referred to as a conflict. Using the generalization of reverse unit propagation clauses (Goldberg & Novikov, 2003) to pseudo-Boolean constraints by Elffers et al. (2020), we say that F implies C by reverse unit propagation (RUP), and that C is a RUP constraint with respect to F , if F \u2227 \u00acC unit propagates to conflict under the empty assignment. If C is a RUP constraint with respect to F , then it can be proven that there is also a derivation F \u22a2 C. More generally, it can be shown that F \u22a2 C if and only if F \u2227 \u00acC \u22a2 \u22a5, where \u22a5 is a shorthand for the trivially false constraint 0 \u2265 1. Therefore, we will extend the notation and write F \u22a2 C also when C is derivable from F by RUP or by contradiction. It is worth noting here again that, as shown in (2), the negation of any pseudo-Boolean constraint can also be expressed syntactically as a pseudo-Boolean constraint-this fact will be convenient in what follows.", "publication_ref": ["b18", "b23", "b43", "b33"], "figure_ref": [], "table_ref": []}, {"heading": "A Proof System for Dominance Breaking", "text": "We proceed to develop our formal proof system for verifying dominance breaking, which we have implemented on top of the tool VeriPB as developed in the sequence of papers (Elffers et al., 2020;Gocht et al., 2020bGocht et al., , 2020aGocht & Nordstr\u00f6m, 2021). We remark that for applications it is absolutely crucial not only that the proof system be sound, but that all proofs be efficiently machine-verifiable. There are significant challenges involved in making proof logging and verification efficient, but in this section we mostly ignore these more applied aspects of our work and focus on the theoretical underpinnings.\nOur foundation is the cutting planes proof system described in Section 2. However, in a proof in our system for (F, f ), where f is a linear objective function to be minimized under the pseudo-Boolean formula F (or where f . = 0 for decision problems), we also allow strengthening F by adding constraints C that are not implied by the formula. Pragmatically, adding such non-implied constraints C should be in order as long as we keep some optimal solution, i.e., a satisfying assignment to F that minimizes f , which we will refer to as an f -minimal solution for F . We will formalize this idea by allowing the use of an additional pseudo-Boolean formula O \u2aaf (\u20d7 u, \u20d7 v) that, together with an ordered set of variables \u20d7 z, defines a relation \u03b1 \u2aaf \u03b2 to hold between assignments \u03b1 and \u03b2 if O \u2aaf (\u20d7 z\u21be \u03b1 , \u20d7 z\u21be \u03b2 ) evaluates to true. We require (a cutting planes proof) that O \u2aaf is such that this defines a preorder, i.e., a reflexive and transitive relation. Adding new constraints C will be valid as long as we guarantee to preserve some f -minimal solution that is also minimal with respect to \u2aaf. In other words, the preorder \u2aaf can be combined with the objective function f to define a preorder \u2aaf f on assignments by \u03b1 \u2aaf f \u03b2 if \u03b1 \u2aaf \u03b2 and f\u21be \u03b1 \u2264 f\u21be \u03b2 ,\nand we require that all derivation steps in the proof should preserve some solution that is minimal with respect to \u2aaf f . The preorder defined by O \u2aaf (\u20d7 u, \u20d7 v) will only become important once we introduce our new dominance-based strengthening rule later in this section. For simplicity, up until that point the reader can assume that the pseudo-Boolean formula is O \u22a4 . = \u2205 inducing the trivial preorder relating all assignments, though all proofs presented below work in full generality for the orders that will be introduced later.\nA proof for (F, f ) in our proof system consists of a sequence of proof configurations (C , D, O \u2aaf , \u20d7 z, v), where \u2022 C is a set of pseudo-Boolean core constraints;\n\u2022 D is another set of pseudo-Boolean derived constraints;\n\u2022 O \u2aaf is a pseudo-Boolean formula encoding a preorder and \u20d7 z a set of literals on which this preorder will be applied; and\n\u2022 v is the best value found so far for f .\nThe initial configuration is (F, \u2205, O \u22a4 , \u2205, \u221e). The distinction between C and D is only relevant when a nontrivial preorder is used; we will elaborate on this when discussing the dominance-based strengthening rule. The intended relation between f and v is that if v < \u221e, then there exists a solution \u03b1 satisfying F such that f\u21be \u03b1 \u2264 v, and in this case the proof can make use of the constraint f \u2264 v \u2212 1 in the search for better solutions. As long as the optimal solution has not been found, it should hold that f -minimal solutions for C \u222a D have the same objective value as f -minimal solutions for F . The precise relation is formalized in the notion of (F, f )-valid configurations, which we will define next. In some cases, it will be convenient to also have a less stringent notion of weak (F, f )-validity, which holds even if constraints have been removed from the original formula. Jumping ahead a bit, what this means is that proofs preserving weak (F, f )-validity can only be used to show that no solutions better than a given value exist, while proofs preserving (F, f )-validity can establish that the optimal value equals a certain value.\nDefinition 1. A configuration (C , D, O \u2aaf , \u20d7 z, v) is weakly (F, f )-valid if the following con- ditions hold: 1. For every v \u2032 < v, it holds that if F \u222a {f \u2264 v \u2032 } is satisfiable, then C \u222a {f \u2264 v \u2032 } is satisfiable. 2. For every total assignment \u03c1 satisfying the constraints C \u222a {f \u2264 v \u2212 1}, there exists a total assignment \u03c1 \u2032 \u2aaf f \u03c1 satisfying C \u222a D \u222a {f \u2264 v \u2212 1},\nwhere \u2aaf f is the relation defined in (4).\nThe configuration (C , D, O \u2aaf , \u20d7 z, v) is (F, f )-valid if in addition the following conditions hold:\n3. If v < \u221e, then F \u222a {f \u2264 v} is satisfiable. 4. For every v \u2032 < v, it holds that if C \u222a {f \u2264 v \u2032 } is satisfiable, then F \u222a {f \u2264 v \u2032 } is satisfiable.\nWhen we present the derivation rules in our proof system below, we will show that (F, f )-validity is an invariant of the proof system, i.e., that it is preserved by all derivation rules. For the deletion rule, which can remove constraints in the input formula, we will present a version of the rule that only preserves weak (F, f )-validity. This alternative rule is introduced for pragmatic reasons to support proof logging for SAT solvers. In such a setting, deletions can be treated in a more relaxed fashion, since the generated proofs are only used to establish unsatisfiability.\nTo see why Definition 1 is relevant, note that items 1, 2, and 4 together imply that if the configuration (C , D, O \u2aaf , \u20d7 z, v) is such that v is not yet the value of an optimal solution, then f -minimal solutions for F and C \u222a D have the same objective value, just as desired. A proof in our proof system ends when the configuration (\nC , D, O \u2aaf , \u20d7 z, v * ) is such that C \u222a D contains contradiction \u22a5 . = 0 \u2265 1.\nIf the resulting state is (F, f )-valid, either v * = \u221e and F is unsatisfiable, or v * is the optimal value (or v * = 0 for a satisfiable decision problem). If the resulting state is only weakly (F, f )-valid, we get slightly weaker conclusions. We collect the precise statements in two formal theorems.\nTheorem 2. Let F be a pseudo-Boolean formula and f an objective function. If the configuration (C , D, O \u2aaf , \u20d7 z, v * ) is weakly (F, f )-valid and is such that C \u222a D contains the contradictory constraint 0 \u2265 1, then it holds that \u2022 for any solution \u03b1 for F we have f\u21be \u03b1 \u2265 v * ;\n\u2022 in particular, if v * = \u221e, then F is unsatisfiable.\nProof. If F is satisfiable, then let \u03b1 be a satisfying assignment for F . If f\u21be \u03b1 < v * , then \u03b1 satisfies F \u222a {f \u2264 v * \u2212 1}. Hence, item 1 in Definition 1 says that there exists an \u03b1 \u2032 that satisfies C \u222a {f \u2264 v * \u2212 1} and item 2 then implies the existence of an \u03b1 \u2032\u2032 that satisfies C \u222a D \u222a {f \u2264 v * \u2212 1}. But this contradicts the assumption that the unsatisfiable constraint 0 \u2265 1 is in C \u222a D. It follows that f\u21be \u03b1 \u2265 v * , and that no satisfying assignments for F can exist if v * = \u221e.\nTheorem 3. Let F be a pseudo-Boolean formula and f an objective function. If the con-\nfiguration (C , D, O \u2aaf , \u20d7 z, v * ) is (F, f )-valid and is such that C \u222a D contains 0 \u2265 1, then \u2022 F is unsatisfiable if and only if v * = \u221e; and\n\u2022 if F is satisfiable, then there is an f -minimal solution \u03b1 for F with objective value f\u21be \u03b1 = v * .\nProof. By appealing to Theorem 2, we can conclude that if v * = \u221e, then F is unsatisfiable. If F is unsatisfiable, then we must have v * = \u221e due to item 3 in Definition 1. This establishes the first part of Theorem 3. For the second part, suppose that F is satisfiable. Then v * < \u221e by the preceding paragraph, and so by item 3 of Definition 1 there is a solution \u03b1 for F such that f\u21be \u03b1 \u2264 v * . But Theorem 2 says that for any solution \u03b1 for F it holds that f\u21be \u03b1 \u2265 v * . Hence, \u03b1 is an f -minimal solution for F with objective value f\u21be \u03b1 = v * as claimed.\nWe are now ready to give a formal description of the rules in our proof system and argue that these rules preserve (F, f )-validity (or, in the case of the alternative deletion rule, weak (F, f )-validity). The attentive reader might have noted that we did not use item 4 in Definition 1 in our proofs of Theorems 2 and 3, but this condition will be critical to argue that (F, f )-validity is an invariant of our proof system.", "publication_ref": ["b33", "b40", "b39", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Implicational Derivation Rule", "text": "If we can exhibit a derivation of the pseudo-Boolean constraint C from C \u222aD \u222a{f \u2264 v\u22121} in our (slightly extended) version of the cutting planes proof system as described in Section 2 (i.e., in formal notation, if C \u222a D \u222a {f \u2264 v \u2212 1} \u22a2 C), then we should be allowed to add the implied constraint C to our collection of derived constraints. Let us write this down as our first formal derivation rule.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Definition 4 (Implicational derivation rule", "text": "). If C \u222a D \u222a {f \u2264 v \u2212 1} \u22a2 C, then we can transition from the configuration (C , D, O \u2aaf , \u20d7 z, v) to the configuration (C , D \u222a {C}, O \u2aaf , \u20d7 z, v)\nby the implicational derivation rule. In this case, we will also say that C is derivable from (C , D, O \u2aaf , \u20d7 z, v) by the implicational derivation rule.\nThe implicational derivation rule preserves (F, f )-validity (and weak (F, f )-validity) since C \u222a D \u222a {f \u2264 v \u2212 1} |= C holds by soundness of the cutting planes proof system, but, more importantly, the cutting planes derivation provides a simple and efficient way for an algorithm to verify that this implication holds. This is a key feature of all rules in our proof system-not only are they sound, but the soundness of every rule application can be efficiently verified by checking a simple, syntactic object.\nWhen doing proof logging, the solver would need to specify by which sequence of cutting planes derivation rules C was obtained. For practical purposes, though, it greatly simplifies matters that in many cases the verifier can figure out the required proof details automatically, meaning that the proof logger can just state the desired constraint without any further information. One important example of this is when C is a reverse unit propagation (RUP) constraint with respect to C \u222a D \u222a {f \u2264 v \u2212 1}. Another case is when C is literal-axiom-implied by some other constraint.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Objective Bound Update Rule", "text": "The objective bound update rule allows improving the estimate of what value can be achieved for the objective function f . Definition 5 (Objective bound update rule). We say that we can transition from the configuration (C , D, O \u2aaf , \u20d7 z, v) to the configuration (C , D, O \u2aaf , \u20d7 z, v \u2032 ) by the objective bound update rule if there is an assignment \u03b1 satisfying C such that f\u21be \u03b1 = v \u2032 < v.\nWhen actually doing proof logging, the solver would specify such an assignment \u03b1, which would then be checked by the proof verifier (in our case VeriPB ).\nTo argue that this rule preserves (F, f )-validity (and weak (F, f )-validity), note that items 1, 2, and 4 are trivially satisfied. (For item 2, observe that whenever \u03c1 \u2032 \u2aaf f \u03c1 and \u03c1 satisfies {f \u2264 v \u2032 \u2212 1}, so does \u03c1 \u2032 .) Item 3 is satisfied after updating the objective bound since item 4 guarantees the existence of an \u03b1 \u2032 satisfying F with an objective value that is at least as good as v \u2032 .\nNote that we have no guarantee that \u03b1 itself will be a solution for F . However, although we will not emphasize this point here, it follows from our formal treatment below that the proof system guarantees that such a solution \u03b1 \u2032 for the original formula F can be efficiently reconstructed from the proof (where efficiency is measured in the size of the proof).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Redundance-Based Strengthening Rule", "text": "The redundance-based strengthening rule allows deriving a constraint C from C \u222a D even if C is not implied, provided that it can be shown that any assignment \u03b1 that satisfies C \u222aD can be transformed into another assignment \u03b1 \u2032 \u2aaf f \u03b1 that satisfies both C \u222a D and C (in case O \u2aaf = O \u22a4 , the condition \u03b1 \u2032 \u2aaf f \u03b1 just means that f\u21be \u03b1 \u2032 \u2264 f\u21be \u03b1 ). This rule is borrowed from Gocht and Nordstr\u00f6m (2021), who in turn rely heavily on Heule, Kiesl, and Biere (2017) and Buss and Thapen (2019). We extend this rule here from decision problems to optimization problems in the natural way.\nDefinition 6 (Redundance-based strengthening rule). If for a pseudo-Boolean constraint C there is a substitution \u03c9 such that\nC \u222a D \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 (C \u222a D \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) ,(5)\nthen we can transition from (C , D, O \u2aaf , \u20d7 z, v) to (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) by redundance-based strengthening, or just redundance for brevity. We refer to the substitution \u03c9 as the witness, and also say that C can be derived from (C , D, O \u2aaf , \u20d7 z, v) by redundance.\nIntuitively, (5) says that if some assignment \u03b1 satisfies C \u222a D but falsifies C, then the assignment \u03b1 \u2032 = \u03b1 \u2022 \u03c9 still satisfies C \u222a D and also satisfies C. In addition, the condition f\u21be \u03c9 \u2264 f ensures that \u03b1 \u2022 \u03c9 achieves an objective function value that is at least as good as that for \u03b1. This together with the constraints O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) guarantees that \u03b1 \u2032 \u2aaf f \u03b1. For proof logging purposes, the witness \u03c9 as well as any non-immediate cutting planes derivations of constraints on the right-hand side of (5) would have to be specified, but, e.g., all RUP constraints or literal-axiom-implied constraints can be left to the verifier to check.\nProposition 7. If we can transition from (C , D, O \u2aaf , \u20d7 z, v) to (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) by the redundance-based strengthening rule and (C , D, O \u2aaf , \u20d7 z, v) is [weakly] (F, f )-valid, then (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) is also [weakly] (F, f )-valid. Proof. First assume (C , D, O \u2aaf , \u20d7 z, v) is weakly (F, f )-valid. Item 1 in Definition 1 remains satisfied for (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) since F , v, and C are unchanged.\nFor item 2 we can recycle proofs of similar properties for decision problems (Heule et al., 2017;Buss & Thapen, 2019;Gocht & Nordstr\u00f6m, 2021). Consider a total assignment \u03c1 satisfying C \u222a {f \u2264 v \u2212 1}. Without loss of generality we can assume that \u03c1 also satisfies D (since (C , D, O \u2aaf , \u20d7 z, v) satisfies item 2 in Definition 1). We wish to construct an assignment \u03c1 \u2032 that satisfies the constraints C \u222a D \u222a {C} and also the condition \u03c1 \u2032 \u2aaf f \u03c1, which is to say that f\u21be \u03c1 \u2032 \u2264 f\u21be \u03c1 and O \u2aaf (\u20d7 z\u21be \u03c1 \u2032 , \u20d7 z\u21be \u03c1 ) should hold.\nIf \u03c1 satisfies C, then we use \u03c1 \u2032 = \u03c1 and all conditions are satisfied (recall that O \u2aaf induces a preorder, and hence a reflexive relation: for any \u03c1, O \u2aaf (\u20d7 z\u21be \u03c1 , \u20d7 z\u21be \u03c1 ) holds). Otherwise, choose \u03c1 \u2032 = \u03c1 \u2022 \u03c9. Since \u03c1 is total and does not satisfy C, it satisfies \u00acC. This means that \u03c1 satisfies C \u222a D \u222a \u00acC, and hence by (5) also\n(C \u222a D \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) .(6)\nClearly, for any constraint D, it holds that (D\u21be \u03c9 )\u21be \u03c1 = D\u21be \u03c1\u2022\u03c9 and thus if \u03c1 satisfies D\u21be \u03c9 , then \u03c1 \u2032 = \u03c1 \u2022 \u03c9 satisfies D. Therefore, \u03c1 \u2032 satisfies C \u222a D \u222a C. By the same reasoning, since \u03c1 satisfies f\u21be \u03c9 \u2264 f we have that f\u21be \u03c1\u2022\u03c9 = f\u21be \u03c1 \u2032 \u2264 f\u21be \u03c1 holds. Finally, the fact that \u03c1 satisfies O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) means that O \u2aaf (\u20d7 z\u21be \u03c1 \u2032 , \u20d7 z\u21be \u03c1 ) holds. This shows that item 2 holds for (C , D \u222a {C}, O \u2aaf , \u20d7 z, v), which concludes our proof that weak (F, f )-validity is preserved.\nTo see that also (F, f )-validity is preserved, it suffices to note that items 3 and 4 do not depend on D and hence are satisfied in (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) whenever they are satisfied in (C , D, O \u2aaf , \u20d7 z, v).", "publication_ref": ["b42", "b48", "b19", "b48", "b19", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Deletion Rules", "text": "An interesting property of the redundance rule introduced in Section 3.3 is that when the set of constraints in C \u222a D grows, it can get harder to derive new constraints, since every constraint D already in C \u222a D adds a new constraint D\u21be \u03c9 needing to be derived on the right-hand side of (5). For this reason, and also due to efficiency concerns during verification of proofs, we need to be able to delete previously derived constraints.\nDefinition 8 (Deletion rule). We can transition from\n(C , D, O \u2aaf , \u20d7 z, v) to (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) by the deletion rule if 1. D \u2032 \u2286 D and 2. C \u2032 = C or C \u2032 = C \\ {C} for some constraint C derivable via the redundance rule from (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v).\nThe last condition above perhaps seems slightly odd, but it is there since deleting arbitrary constraints could violate (F, f )-validity in two different ways. Firstly, it could allow finding better-than-optimal solutions. Secondly, and perhaps surprisingly, in combination with the dominance-based strengthening rule, which we will discuss below, arbitrary deletion is unsound, as it can turn satisfiable instances into unsatisfiable ones. We will discuss this further in Example 15 once we have introduced the dominance rule.\nProposition 9. If we can transition from (C , D, O \u2aaf , \u20d7 z, v) to (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) by the deletion rule and (C , D, O \u2aaf , \u20d7 z, v) is [weakly] (F, f )-valid, then (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) is also [weakly] (F, f )- valid. Proof. First assume that (C , D, O \u2aaf , \u20d7 z, v) is weakly (F, f )-valid. Item 1 in Definition 1 clearly remains satisfied for (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) since C \u2032 \u2286 C .\nTo prove that item 2 is satisfied after applying the deletion rule, let \u03b1 be any assignment that satisfies\nC \u2032 \u222a{f \u2264 v \u22121}. If C \u2032 = C , we find an \u03b1 \u2032 \u2aaf f \u03b1 that satisfies C \u2032 \u222a D \u2032 \u222a {f \u2264 v \u2212 1} using weak (F, f )-validity of the configuration (C , D, O \u2aaf , \u20d7 z, v\n). Hence, we can assume that C \u2032 = C \\ {C}. If \u03b1 satisfies C, this assignment satisfies all of C , and again the claim follows from weak (F, f )-validity of the configuration (C , D, O \u2aaf , \u20d7 z, v) before deletion. Assume therefore that \u03b1 does not satisfy C. Since C is derivable via redundance from (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v), it holds that\nC \u2032 \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 (C \u2032 \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z)(7)\nfor some witness \u03c9. We can use this witness to obtain an assignment\n\u03b1 \u2032\u2032 = \u03b1 \u2022 \u03c9 satisfying C = C \u2032 \u222a {C} such that f\u21be \u03b1 \u2032\u2032 \u2264 f\u21be \u03b1 \u2264 v \u2212 1, which shows that C \u222a {f \u2264 v \u2212 1} is satisfiable.\nAppealing to the weak (F, f )-validity of the configuration (C , D, O \u2aaf , \u20d7 z, v) before deletion, we then find an \u03b1 \u2032 with f\u21be\n\u03b1 \u2032 \u2264 v \u2212 1 that satisfies C \u222a D \u222a {f \u2264 v \u2212 1}.\nIn this way, we establish that item 2 in Definition 1 holds for the configuration (\nC \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) after deletion. Now assume that (C , D, O \u2aaf , \u20d7 z, v) is (F, f )-valid. Item 3 clearly remains satisfied for (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) since v is unchanged. We show that item 4 holds for (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v);\nthe proof is very similar to the proof of item 2 above. Starting from an assignment \u03b1 satisfying\nC \u2032 \u222a {f \u2264 v \u2032 } for some v \u2032 < v, we use \u03b1 to construct a satisfying assignment \u03b1 \u2032 for F \u222a {f \u2264 v \u2032 }. If C \u2032 = C , we get \u03b1 \u2032 from the (F, f )-validity of (C , D, O \u2aaf , \u20d7 z, v), so assume C \u2032 = C \\ {C}.\nIf \u03b1 satisfies C, the same assignment satisfies C , and again the claim follows from (F, f )-validity of the configuration before deletion. Assume therefore that \u03b1 does not\nsatisfy C. Since C is derivable via redundance from (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v), it holds that C \u2032 \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 (C \u2032 \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) .(8)\nFrom this we can construct an assignment \u03b1 \u2032\u2032 = \u03b1 \u2022 \u03c9 that satisfies C = C \u2032 \u222a {C} and is such that f\u21be\n\u03b1 \u2032\u2032 \u2264 f\u21be \u03b1 \u2264 v \u2032 , showing that C \u222a {f \u2264 v \u2032 } is satisfiable.\nAppealing to the (F, f )-validity of the configuration (C , D, O \u2aaf , \u20d7 z, v), we then find an \u03b1 \u2032 with f\u21be \u03b1 \u2032 \u2264 v \u2032 that satisfies F . This proves that item 4 holds for the configuration (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) after deletion.\nThe deletion rule in Definition 8 is more cumbersome than that in DRAT -style proof systems, in that deletions of constraints in the core set must be accompanied by proofs so that the validity of the deletions can be checked. When we want to highlight this property of the rule, we will refer to it as checked deletion. This property can make it more difficult to implement proof logging in a solver, and can also have negative effects on the time required for proof generation and proof verification. If we are only interested in certifying unsatisfiability of decision problem instances-which has traditionally been the case in Boolean satisfiability solving-then an alternative is to use a more liberal deletion rule that allows unrestricted deletion of constraints from the core set C provided that the derived set D is empty. When such an unchecked deletion rule is used, it is easy to see that unsatisfiable sets of constraints can turn satisfiable, and for optimisation problems spurious solutions can appear that yield better objective function values than are possible for the original input constraints. But proofs of unsatisfiability are still valid, as are lower bounds on the value of the objective function to be minimized. Phrased in the language of Definition 1, we are guaranteed to preserve weak (F, f )-validity, but not necessarily (F, f )-validity.\nDefinition 10 (Unchecked deletion rule). If C \u2032 \u2286 C , then we can transition from the configuration (C , D, O \u2aaf , \u20d7 z, v) to the configuration (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v) using the unchecked deletion rule.\nProposition 11. If (C , D, O \u2aaf , \u20d7 z, v\n) is a weakly (F, f )-valid configuration and we can transition from it to (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v) using unchecked deletion, then (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v) is also weakly (F, f )-valid.\nProof. Item 1 in Definition 1 is clearly maintained when transitioning to (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v) since the set of core constraints shrinks. As to item 2, it is trivially satisfied when the set of derived constraints is empty.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Transfer Rule", "text": "Constraints can always be moved from the derived set D to the core set C using the transfer rule.\nDefinition 12 (Transfer rule). We can transition from\n(C , D, O \u2aaf , \u20d7 z, v) to (C \u2032 , D, O \u2aaf , \u20d7 z, v) by the transfer rule if C \u2286 C \u2032 \u2286 C \u222a D.\nThis transfer rule clearly preserves (F, f )-validity (and weak (F, f )-validity). The transfer rule together with deletion allows replacing constraints in the original formula with stronger constraints. For example, assume that x + y \u2265 1 is in C and that we derive x \u2265 1. Then we can move x \u2265 1 from D to C and then delete\nx + y \u2265 1. The required redundance check {x \u2265 1, \u00ac(x + y \u2265 1)} \u22a2 \u22a5 is immediate.\nThe rules discussed so far in this section do not change O \u2aaf , and so any derivation using these rules only will operate with the trivial preorder O \u22a4 imposing no conditions. The proof system defined in terms of these rules is a straightforward extension of VeriPB as developed by Elffers et al. (2020), Gocht et al. (2020aGocht et al. ( , 2020b, Gocht and Nordstr\u00f6m (2021) to an optimisation setting. We next discuss the main contribution of this paper, namely the new dominance rule making use of the preorder encoding O \u2aaf .", "publication_ref": ["b33", "b39", "b40", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Dominance-Based Strengthening Rule", "text": "Any preorder \u2aaf induces a strict order \u227a defined by \u03b1 \u227a \u03b2 if \u03b1 \u2aaf \u03b2 and \u03b2 \u0338 \u2aaf \u03b1. (Note that if \u03b1 \u2aaf \u03b2 and \u03b2 \u2aaf \u03b1 both hold, this means that neither \u03b1 \u227a \u03b2 nor \u03b2 \u227a \u03b1 holds.) The relation \u227a f obtained in this way from the preorder (4) coincides with what Chu and Stuckey (2015) call a dominance relation in the context of constraint optimisation. Our dominance rule allows deriving a constraint C from C \u222a D even if C is not implied, similar to the redundance rule. However, for the dominance rule an assignment \u03b1 satisfying C \u222a D but falsifying C only needs to be mapped to an assignment \u03b1 \u2032 that satisfies C , but not necessarily D or C. On the other hand, the new assignment \u03b1 \u2032 should satisfy the strict inequality \u03b1 \u2032 \u227a f \u03b1 and not just \u03b1 \u2032 \u2aaf f \u03b1 as in the redundance rule. To show that this new dominance rule preserves (F, f )-validity, we will prove that it is possible to construct an assignment that satisfies C \u222a D \u222a {C} by iteratively applying the witness of the dominance rule, in combination with (F, f )-validity of the configuration before application of the dominance rule. As our base case, if \u03b1 \u2032 satisfies C \u222a D \u222a {C}, we are done. Otherwise, since \u03b1 \u2032 satisfies C , by (F, f )-validity we are guaranteed the existence of an assignment \u03b1 \u2032\u2032 satisfying C \u222a D for which \u03b1 \u2032\u2032 \u227a f \u03b1 \u2032 \u227a f \u03b1 holds. If \u03b1 \u2032\u2032 still does not satisfy C, we can repeat the argument. In this way, we get a strictly decreasing sequence (with respect to \u227a f ) of assignments. Since the set of possible assignments is finite, this sequence will eventually terminate.\nFormally, we can derive C by dominance-based strengthening given a substitution \u03c9 such that\nC \u222a D \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 C \u21be \u03c9 \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) \u222a \u00acO \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u222a {f\u21be \u03c9 \u2264 f } ,(9)\nwhere O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) and \u00acO \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) together state that \u03b1 \u2022 \u03c9 \u227a \u03b1 for any assignment \u03b1. A minor technical problem is that the pseudo-Boolean formula O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) may contain multiple constraints, so that the negation of it is no longer a PB formula. To get around this, we split ( 9) into two separate conditions and shift \u00acO \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) to the premise of the implication, which eliminates the negation. After this adjustment, the formal version of our dominance-based strengthening rule, or just dominance rule for brevity, can be stated as follows.\nDefinition 13 (Dominance-based strengthening rule). If for a pseudo-Boolean constraint C there is a witness substitution \u03c9 such that the conditions\nC \u222a D \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 C \u21be \u03c9 \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) \u222a {f\u21be \u03c9 \u2264 f } (10a) C \u222a D \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u222a O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u22a2 \u22a5 (10b)\nare satisfied, then we can transition from\n(C , D, O \u2aaf , \u20d7 z, v) to (C , D \u222a {C}, O \u2aaf , \u20d7 z, v\n) using dominance-based strengthening, or just dominance for brevity. In this case, we also say that C is derivable from (C , D, O \u2aaf , \u20d7 z, v) by dominance.\nJust as for the redundance rule, the witness \u03c9 as well as any non-immediate derivations would have to be specified in the proof log.\nProposition 14. If we can transition from (C , D, O \u2aaf , \u20d7 z, v) to (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) by the dominance-based strengthening rule and (C , D, O \u2aaf , \u20d7 z, v) is [weakly] (F, f )-valid, then (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) is also [weakly] (F, f )-valid.\nProof. Since F , C , and v are not affected in a transition using the dominance rule, items 1, 3, and 4 in Definition 1 hold for (C , D, O \u2aaf , \u20d7 z, v) if and only if they hold for (C , D\u222a{C}, O \u2aaf , \u20d7 z, v). Hence, we only need to prove that item 2 holds for (C , D \u222a {C}, O \u2aaf , \u20d7 z, v). Assume towards contradiction that it does not hold. Let S denote the set of total assignments \u03b1 that\n(1) satisfy C \u222a {f \u2264 v \u2212 1} and (2) admit no \u03b1 \u2032 \u2aaf f \u03b1 satisfying C \u222a D \u222a {C}.", "publication_ref": ["b21"], "figure_ref": [], "table_ref": []}, {"heading": "By our assumption, S is non-empty.", "text": "Let \u03b1 be some \u227a f -minimal assignment in S (since \u227a f is a strict order and S is finite, minimal elements of S exist). Since (C , D, O \u2aaf , \u20d7 z, v) is weakly (F, f )-valid, there exists some \u03b1 1 \u2aaf f \u03b1 that satisfies C \u222a D. We know that \u03b1 1 cannot satisfy C since \u03b1 \u2208 S. Hence, \u03b1 1 satisfies C \u222aD \u222a{\u00acC}. From (10a) it follows that \u03b1 1 satisfies O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z)\u222a{f\u21be \u03c9 \u2264 f } and thus that O \u2aaf (\u20d7 z\u21be \u03b1 1 \u2022\u03c9 , \u20d7 z\u21be \u03b1 1 ) and f\u21be \u03b1 1 \u2022\u03c9 \u2264 f\u21be \u03b1 1 hold. In other words, \u03b1 1 \u2022 \u03c9 \u2aaf f \u03b1 1 . By (10b), it follows that \u03b1 1 does not satisfy O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ), i.e., O \u2aaf (\u20d7 z\u21be \u03b1 1 , \u20d7 z\u21be \u03b1 1 \u2022\u03c9 ) does not hold, and thus\n\u03b1 1 \u0338 \u2aaf f \u03b1 1 \u2022 \u03c9. Now let \u03b1 2 be \u03b1 1 \u2022 \u03c9. We showed that \u03b1 2 \u227a f \u03b1 1 \u2aaf f \u03b1. Furthermore, since \u03b1 1 satisfies C \u222a D \u222a {\u00acC}, (10a) yields that \u03b1 2 satisfies C . Thus \u03b1 2 satisfies C \u222a {f \u2264 v \u2212 1}.\nSince \u03b1 2 \u227a f \u03b1, and \u03b1 is a minimal element of S, it cannot be that \u03b1 2 \u2208 S. Thus, there must exist a \u03b1 \u2032 \u2aaf f \u03b1 2 that satisfies C \u222a D \u222a {C}. However, it also holds that \u03b1 \u2032 \u2aaf f \u03b1, and since \u03b1 \u2208 S this means that \u03b1 \u2032 cannot satisfy C \u222a D \u222a {C}. This yields a contradiction, thereby finishing our proof.\nWhen introducing the deletion rule, we already mentioned that deleting arbitrary constraints can be unsound in combination with dominance-based strengthening. We now illustrate this phenomenon.\nExample 15. Consider the formula F = {p \u2265 1} with objective f . = 0 and the configuration\n(C 1 = {p \u2265 1}, D 1 = {p \u2265 1}, O \u2aaf , {p}, \u221e) ,(11)\nwhere O \u2aaf (u, v) is defined as {v + u \u2265 1}. This configuration is (F, f )-valid and C \u222a D is satisfiable. If we were allowed to delete constraints arbitrarily from C , we could derive a configuration with C 2 = \u2205 and D 2 = {p \u2265 1}. However, now the dominance rule can derive C . = p \u2265 1, using the witness \u03c9 = {p \u2192 0}. To see that all conditions for applying dominance-based strengthening are indeed satisfied, we notice that (10a)-(10b) simplify to\n\u2205 \u222a {p \u2265 1} \u222a {p \u2265 1} \u22a2 \u2205 \u222a {p + 1 \u2265 1} \u222a \u2205 (12a) \u2205 \u222a {p \u2265 1} \u222a {p \u2265 1} \u222a {0 + p \u2265 1} \u22a2 \u22a5 (12b)\nand both of these derivations are immediate (e.g., by reverse unit propagation). This means that we can derive a third configuration with C 3 = \u2205 and D 3 = {p \u2265 1, p \u2265 1}, from which we immediately get contradiction 0 \u2265 1 by adding the two constraints in D 3 , although the formula F that we started with is satisfiable.\nRemark 16. The unchecked deletion rule introduced in Definition 10 requires that the derived set D be empty. Example 15 gives the motivation for this, highlighting the complex interplay between dominance-based strengthening and deletion of constraints. However, in the special case where the pre-order is the trivial order O \u22a4 , the dominance rule can only be used to derive implied constraints. In this case, we could in principle weaken the condition for unchecked deletion to also allow transitioning from\n(C , D, O \u22a4 , \u20d7 z, v) to any configura- tion (C \u2032 , D, O \u22a4 , \u20d7 z, v) whenever C \u2032 \u2286 C .\nAllowing such a further relaxation of the deletion rule might be especially useful if one does not want to make a distinction between core and derived constraints in proof logging applications such as SAT solving. However, if we would want to extend the unchecked deletion rule to cover also this case, then such unchecked deletion transitions would no longer preserve weak validity. In addition, our invariant would need to be extended with a special case stating that item 2 in Definition 1 should hold only if O \u2aaf is nontrivial. For reasons of mathematical elegance, we chose not to adopt such a specially tailored version of the unchecked deletion rule in the current paper. We would like to point out, however, that such a version of unchecked deletion has been implemented in the formally verified pseudo-Boolean proof checker used in the SAT Competition 2023 (Bogaerts, McCreesh, Myreen, Nordstr\u00f6m, Oertel, & Tan, 2023).", "publication_ref": ["b14"], "figure_ref": [], "table_ref": []}, {"heading": "Preorder Encodings", "text": "As mentioned before, O \u2aaf is shorthand for a pseudo-Boolean formula O \u2aaf (\u20d7 u, \u20d7 v) over two sets of placeholder variables \u20d7 u = {u 1 , . . . , u n } and \u20d7 v = {v 1 , . . . , v n } of equal size, which should also match the size of \u20d7 z in the configuration. To use O \u2aaf in a proof, it is required to show that this formula encodes a preorder. This is done by providing (in a proof preamble) cutting planes derivations establishing\n\u2205 \u22a2 O \u2aaf (\u20d7 u, \u20d7 u) (13a) O \u2aaf (\u20d7 u, \u20d7 v) \u222a O \u2aaf (\u20d7 v, \u20d7 w) \u22a2 O \u2aaf (\u20d7 u, \u20d7 w) (13b)\nwhere (13a) formalizes reflexivity and ( 13b) transitivity (and where notation like O \u2aaf (\u20d7 v, \u20d7 w) is shorthand for applying to O \u2aaf (\u20d7 u, \u20d7 v) the substitution \u03c9 that maps u i to v i and v i to w i , as discussed in Section 2). These two conditions guarantee that the relation \u2aaf defined by \u03b1 \u2aaf \u03b2 if O \u2aaf (\u20d7 z\u21be \u03b1 , \u20d7 z\u21be \u03b2 ) forms a preorder on the set of assignments.\nBy way of example, to encode the lexicographic order\nu 1 u 2 . . . u n \u2aaf lex v 1 v 2 . . . v n , we can use a single constraint O \u2aaf lex (\u20d7 u, \u20d7 v) . = n i=1 2 n\u2212i \u2022 (v i \u2212 u i ) \u2265 0 . (14\n)\nReflexivity is vacuously true since O \u2aaf lex (\u20d7 u, \u20d7 u) . = 0 \u2265 0, and transitivity also follows easily since adding\nO \u2aaf lex (\u20d7 u, \u20d7 v) and O \u2aaf lex (\u20d7 v, \u20d7 w) yields O \u2aaf lex (\u20d7 u, \u20d7 w) (\nwhere we tacitly assume that the constraint resulting from this addition is implicitly simplified by collecting like terms, performing any cancellations, and shifting any constants to the right-hand side of the inequality, as mentioned in Section 2).\nA potential concern with encodings such as ( 14) is that coefficients can become very large as the number of variables in the order grows. It is perfectly possible to address this by allowing order encodings using auxiliary variables in addition to \u20d7 u and \u20d7 v. We have chosen not to develop the theory for this in the current paper, however, since we feel that it would make the exposition significantly more complicated without providing a commensurate gain in terms of scientific contributions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Order Change Rule", "text": "The final proof rule that we need is a rule for introducing a nontrivial order, and it turns out that it can also be convenient to be able to use different orders at different points in the proof. Switching orders is possible, but to maintain soundness it is important to first clear the set D (after transferring the constraints we want to keep to C using the transfer rule in Section 3.5). The reason for this is simple: if we allow arbitrary order changes, then item 2 of weak (F, f )-validity would no longer hold, and we could potentially derive contradiction even from satisfiable formulas. However, when D = \u2205 the condition in item 2 is trivially true.\nDefinition 17 (Order change rule). Provided that O \u2aaf 2 has been established to be a preorder over 2\u2022n variables (by proofs of (13a) and (13b) with explicit cutting planes derivations) and provided that \u20d7 z 2 is a list of n variables, we say that we can transition from the configuration\n(C , \u2205, O \u2aaf 1 , \u20d7 z 1 , v) to the configuration (C , \u2205, O \u2aaf 2 , \u20d7 z 2 , v\n) by the order change rule.\nAs explained above, it is clear that this rule preserves (F, f )-validity (and weak (F, f )validity).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Concluding Remarks on the Proof System for Dominance Breaking", "text": "This concludes the presentation of our proof system, which we have defined in two slightly different flavours with different conditions for the deletion rule. In case we use the version with unchecked deletion, each rule in the proof system has been shown to preserve weak (F, f )-validity, where as in the version with (standard) deletion each derivation rule has been shown to preserve (F, f )-validity. The initial configuration is clearly (F, f )-valid. Therefore, by Theorem 2 our proof system is sound: whenever we can derive a configuration (C , D, O \u2aaf , \u20d7 z, v) such that C \u222a D contains 0 \u2265 1, it holds that v is at least the value of f in any f -minimal solution for F (or, for a decision problem, we have v = \u221e only when F is unsatisfiable). If there are no applications of the unchecked deletion rule, then the final configuration is also (F, f )-valid, and hence by Theorem 3 it holds that v is exactly the value of f in any f -minimal solution for F (or, for a decision problem, we have v = \u221e if and only if F is unsatisfiable). As mentioned above, in this latter case the full sequence of proof configurations (C , D, O \u2aaf , \u20d7 z, v) together with annotations about the derivation stepsincluding, in particular, any witnesses \u03c9-contains all information needed to efficiently reconstruct such an f -minimal solution for F . It is also straightforward to show that our proof system is complete: after using the bound update rule to log an optimal solution v * , it follows from the implicational completeness of cutting planes that contradiction can be derived from\nF \u222a {f \u2264 v * \u2212 1}.\nBuilding on the ideas developed in this section, other variants of the proof system could be designed. For instance, we opted to define the relation\n\u2aaf f as \u03b1 \u2aaf f \u03b2 if \u03b1 \u2aaf \u03b2 and f\u21be \u03b1 \u2264 f\u21be \u03b2 ,(15)\nbut an alternative definition could be\n\u03b1 \u2aaf \u2032 f \u03b2 if f\u21be \u03b1 \u2264 f\u21be \u03b2 and if f\u21be \u03b1 = f\u21be \u03b2 then also \u03b1 \u2aaf \u03b2 . (16\n)\nWhat this says, essentially, is that we only compare assignments with respect to the order \u2aaf in case they have the same objective value. Combining this with the intuition that a witness \u03c9 for the redundance rule should map each assignment \u03b1 to an assignment that is at least as good (in terms of \u2aaf \u2032 f ) as \u03b1 would here then yield the conditions\nC \u222a D \u222a {\u00acC} \u22a2 (C \u222a D \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } and (17a) C \u222a D \u222a {\u00acC} \u222a {f\u21be \u03c9 = f } \u22a2 O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) (17b)\nfor the redundance-based strengthening rule instead of (5). It can be observed that this actually results in slightly weaker proof obligations on the right-hand side and thus a more generally applicable rule. Similarly, for the dominance rule, the witness should map each assignment \u03b1 to an assignment that is strictly better than \u03b1 (again, in terms of \u2aaf \u2032 f ). This requirement would be encoded by the conditions\nC \u222a D \u222a {\u00acC} \u22a2 C \u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } , (18a) C \u222a D \u222a {\u00acC} \u222a {f\u21be \u03c9 = f } \u22a2 O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) , and (18b) C \u222a D \u222a {\u00acC} \u222a {f\u21be \u03c9 = f } \u222a O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u22a2 \u22a5 (18c)\ninstead of (10a) and (10b). This again results in a slightly more generally applicable rule. All proofs of correctness go through with this slight modification of the proof system, and in fact would go through for any alternative to the order \u2aaf f , as long as the redundance and dominance rules are adapted accordingly. In this paper we opted for using \u2aaf f , prioritizing simplicity of exposition.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Symmetry Breaking in SAT Solvers", "text": "In this section we discuss the use of symmetry breaking in the context of Boolean satisfiability (SAT) solving and how our proof system can be used to provide efficiently verifiable proofs of correctness for symmetry breaking constraints. We also present results from a thorough empirical evaluation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Certified Symmetry Breaking with Dominance-Based Strengthening", "text": "Symmetry handling has a long and successful history in SAT solving, with a wide variety of techniques considered by, e.g., Aloul, Sakallah, and Markov (2006), Benhamou and Sa\u00efs (1994), Benhamou, Nabhani, Ostrowski, andSa\u00efdi (2010), Devriendt, Bogaerts, De Cat, Denecker, andMears (2012), Devriendt, Bogaerts, and Bruynooghe (2017), Metin, Baarir, and Kordon (2019), and by Sabharwal (2009). These techniques were used to great effect in, e.g., the 2013 and 2016 editions of the SAT competition, 3 where the SAT+UNSAT hard combinatorial track and the no-limit track, respectively, were won by solvers employing symmetry breaking techniques. However, it later turned out that the victory in 2013 was partly explained by a small parser bug in the symmetry breaking tool, which could result in the solver taking a shortcut and declaring a formula unsatisfiable before even starting to solve it. For reasons such as this, proof logging is now obligatory in the main track of the SAT competition. While it is hard to overemphasize the importance of this development, and the value proof logging has brought to the SAT community, it has unfortunately also meant that it has not been possible to use symmetry breaking in the SAT competition, since there has been no way of efficiently certifying the correctness of such reasoning in DRAT .\nWe will now explain how pseudo-Boolean reasoning with the dominance rule can provide proof logging for the static symmetry breaking techniques of Devriendt et al. (2016).\nLet \u03c3 be a permutation of the set of literals in a given CNF formula F (i.e., a bijection on the set of literals), extended to (sets of) clauses in the obvious way. We say that \u03c3 is a symmetry of F if it commutes with negation, i.e., \u03c3(\u2113) = \u03c3(\u2113), and preserves satisfaction of F , i.e., \u03b1 \u2022 \u03c3 satisfies F if and only if \u03b1 does. A syntactic symmetry in addition satisfies that \u03c3(F ) . = F\u21be \u03c3 . = F . As is standard in symmetry breaking, we will only consider syntactic symmetries.\nThe most common way of breaking symmetries is by adding lex-leader constraints (Crawford, Ginsberg, Luks, & Roy, 1996). We will write \u2aaf lex to denote the lexicographic order on assignments induced by the sequence of variables x 1 , . . . , x m , i.e., \u03b1 \u2aaf lex \u03b2 if \u03b1 = \u03b2 or if there is an i \u2264 m such that \u03b1(x j ) = \u03b2(x j ) for all j < i and \u03b1(x i ) < \u03b2(x i ). Given a set G of symmetries of F , a lex-leader constraint is a formula \u03c8 LL such that \u03b1 satisfies \u03c8 LL if and only if \u03b1 \u2aaf lex \u03b1 \u2022 \u03c3 for each \u03c3 \u2208 G. The actual choice of a set G of symmetries to break, as well as the choice of variables on which to define the lexicographic order, has a significant effect on the quality of the breaking constraints (Devriendt et al., 2016), but this is an orthogonal concern to the goals of the current paper, which is to show how to certify an encoding of lex-leader constraints using the dominance rule.\nLet {x i 1 , . . . , x in } be the support of \u03c3 (i.e., all variables x such that \u03c3(x) \u0338 = x), ordered so that i j \u2264 i k if and only if j \u2264 k. Then the constraints\ny 0 \u2265 1 (19a) y j\u22121 + x i j + \u03c3(x i j ) \u2265 1 1 \u2264 j \u2264 n (19b\n)\ny j + y j\u22121 \u2265 1 1 \u2264 j < n (19c\n)\ny j + \u03c3(x i j ) + x i j \u2265 1 1 \u2264 j < n (19d\n)\ny j + y j\u22121 + x i j \u2265 1 1 \u2264 j < n (19e\n)\ny j + y j\u22121 + \u03c3(x i j ) \u2265 1 1 \u2264 j < n (19f)\nform a lex-leader constraint for \u03c3 (for fresh variables y j ). The intuition behind this encoding is as follows: the variable y j is true precisely when \u03b1 and \u03b1 \u2022 \u03c3 are equal up to x i j (so y 0 is trivially true as claimed in (19a)). The constraint (19b) does the actual symmetry breaking: it states that if \u03b1 and \u03b1 \u2022 \u03c3 are equal up to x i j\u22121 , then x i j \u2264 \u03c3(x i j ) must hold.\nThe constraints (19c)-(19f) encode the definition of y j as y j\u22121 \u2227 (x i j \u2194 \u03c3(x i j )).\nTo derive the clausal constraints (19a)-(19f) in our proof system, assume that we have a configuration (C , D, O \u2aaf , \u20d7 x, v) where assignments are compared lexicographically on the subset of variables \u20d7 x = {x 1 , . . . , x m } according to O \u2aaf as defined in ( 14). Let \u03c3 be a syntactic symmetry of C (i.e., such that C \u21be \u03c3 . = C ) with support contained in \u20d7 x. As a first step, we use the dominance-based strengthening rule in Section 3.6 to derive the pseudo-Boolean constraint\nC LL . = m i=1 2 m\u2212i \u2022 (\u03c3(x i ) \u2212 x i ) \u2265 0 (20\n)\nexpressing that \u03c3(\u20d7 x) is greater than or equal to \u20d7 x. We emphasize that the constraint C LL only exists in the proof and is nothing that the SAT solver will see-since it only understands clauses-but this constraint will help us to construct efficient derivations of the clausal constraints that will be used by the solver to enforce symmetry breaking.\nTo see how the constraint C LL in (20) can be derived by the dominance rule, note first that in SAT solving we are dealing with decision problems, and so there is no need to worry about the trivial objective function f . = 0. Second, observe that we have\nO \u2aaf (\u20d7 x, \u20d7 x\u21be \u03c3 )\n. = {C LL }, According to Definition 13, we need to show that derivations as in (10a)-(10b) exist. To argue that (10a) holds, we note that \u00acC LL expresses that \u20d7 x is strictly larger than \u03c3(\u20d7 x), and hence this implies O \u2aaf (\u20d7 x\u21be \u03c3 , \u20d7 x). Since these are single pseudo-Boolean constraints, this is easily verifiable by literal-axiom implication. It is also easy to verify that (10b) is true, since we have both C LL and its negation among the premises on the left-hand side, and for any pseudo-Boolean constraint C it holds that adding C and \u00acC together yields 0 \u2265 1.\nOnce we have C LL as in (20), we can use this to obtain the constraints (19a)-(19f). Since all y j -variables are fresh, it is straightforward to derive all constraints (19a) and (19c)-(19f) using redundance-based strengthening as explained by Gocht and Nordstr\u00f6m (2021). It is important to note that in these derivations the witness substitutions only operate on the new, fresh y j -variables. Hence, we have \u20d7 x\u21be \u03c9 = \u20d7 x, and so O \u2aaf (\u20d7 x\u21be \u03c9 , \u20d7 x) holds by the reflexivity of O \u2aaf . A more interesting challenge is to derive the constraints (19b), and this is where we need C LL .\nRecall that our assumption is that the support of \u03c3 is {x i 1 , . . . , x in } with i j \u2264 i k if and only if j \u2264 k. Note first that for all variables x i that are not in the support of \u03c3, the difference \u03c3(\nx i ) \u2212 x i disappears since \u03c3(x i ) = x i . This means that the constraint C LL simplifies to n j=1 2 m\u2212i j \u2022 (\u03c3(x i j ) \u2212 x i j ) \u2265 0 ,(21)\nand this inequality can only hold if the contributions of the variables with the largest coefficient 2 m\u2212i 1 is non-negative. In other words, the constraint C LL implies that \u03c3(x i 1 ) \u2212 x i 1 \u2265 0, and this implication can be verified by reverse unit propagation (RUP). From this, in turn, we can obtain the constraint (19b) for j = 1 by literal-axiom implication.\nTo derive constraints (19b) for j > 1, let us introduce the notation\nC LL (0) . = C LL (22a) C LL (k) . = C LL (k \u2212 1) + 2 m\u2212i k \u2022 (19d [j = k])(22b)\nwhere\n(19d [j = k]) denotes substitution of j by k in (19d). Simplifying C LL (k) yields k j=1 2 m\u2212i j \u2022 y j + n j=k+1 2 m\u2212i j \u2022 (\u03c3(x i j ) \u2212 x i j ) \u2265 0 ,(23)\nwhich, when combined with all constraints (19c), directly entails the constraint (19b) with j = k. To see this, note that if y k is false, then (19b) is trivially true for j = k + 1. On the other hand, if y k is true, then so are all the preceding y j -variables, and the dominant contribution in C LL (k) is from \u03c3(x i k ) \u2212 x i k , which implies (19b) for j = k analogously to the case for j = 1.\nIt is important to note here that the order used for the dominance-based strengthening is fixed at the beginning and remains the same for all symmetries \u03c3 \u2208 G to be broken. Since constraints are added only to the derived set D, dominance rule applications for different symmetries will not interfere with each other. Furthermore, in contrast to the approach of Heule et al. (2015), handling a symmetry once is enough to guarantee complete breaking. In Appendix A we include a complete worked-out example of symmetry breaking in VeriPB syntax together with explanations of how the proof logging syntax matches rules in our proof system.", "publication_ref": ["b3", "b7", "b6", "b31", "b29", "b60", "b62", "b30", "b25", "b30", "b42", "b47"], "figure_ref": [], "table_ref": []}, {"heading": "Relation to DRAT -Style Symmetry Breaking", "text": "As discussed in the introduction, it is currently not known whether general symmetry breaking can be certified efficiently using DRAT proof logging. Previous work on symmetry breaking with DRAT (Heule et al., 2015) is limited to special cases of simple symmetries. To compare and contrast this with our work, let us describe the method of Heule et al. (2015) in our language (which is easily done, since the RAT rule is a special case of our redundance-based strengthening rule), and explain the difficulties in extending this to a general symmetry breaking method.\nRedundance-based strengthening can easily deal with a single simple symmetry \u03c3 that swaps two variables, say x i and x j (with j > i). In this case, the constraint C LL in (20) simplifies to\nx j \u2212 x i \u2265 0 ,\nwhich can be derived with a single application of the redundance rule with the symmetry \u03c3 serving as the witness. However, this approach no longer works when several symmetries need to be broken at the same time, or when we need to deal with more complex symmetries. When multiple symmetries that swap two variables are involved, the second symmetry cannot necessarily be broken in the way described above, since the witness for the second symmetry might invalidate the symmetry breaking constraint for the first symmetry (which has been added to the set of core constraints, and so will appear as one of the proof obligations on the right-hand side in ( 5)). If there are two symmetries \u03c3 1 and \u03c3 2 that share a variable, then these symmetries might need to be applied three times in order to obtain a lexicographically minimal assignment. While this makes the proof logging more complicated, it is still possible to deal with this scenario in DRAT proof logging by making use of a sorting network encoding as explained by Heule et al. (2015).\nA more serious problem is when the symmetries to be broken are more complex than just swaps of a single pair of variables. For the case of involutions \u03c3 (i.e., where \u03c3 is its own inverse), some steps towards a solution have been taken (Heule et al., 2015, Conjecture 1). But already a symmetry \u03c3 that is a cyclic shift of three variables (i.e., such that \u03c3(x) = y, \u03c3(y) = z, and \u03c3(z) = x) brings us beyond what DRAT -based proof logging symmetry breaking is currently able to handle. The obstacle that arises here is that we do not know in advance whether the permutation \u03c3 should be applied once or twice to an assignment \u03b1 to get the lexicographically smallest assignment in the orbit of \u03b1 under \u03c3.\nThe beauty of the dominance-based strengthening rule is that it completely eliminates these problems. There is no requirement that our witness substitutions should generate minimal assignments-all that is needed is that the witnesses yield smaller assignments. And since the symmetry breaking constraints are all added to the derived set D, we do not need to worry about what previous symmetry breaking constraints might have been added when we are breaking the next symmetry. Instead, symmetry breaking constraints for different symmetries can be added independently of one another (for as long as the order remains unchanged).", "publication_ref": ["b47", "b47", "b47"], "figure_ref": [], "table_ref": []}, {"heading": "Extensions of Basic Symmetry Breaking", "text": "So far we have discussed the core ideas that underlie most modern symmetry breaking tools for SAT solving. The tool BreakID (Devriendt et al., 2016) extends these ideas further in a couple of ways. We now briefly discuss these extensions and how they are dealt with in our proof system.\nThe most important contribution of Devriendt et al. (2016) is detecting so-called row interchangeability. The goal of this optimization is to not just take an arbitrary set of generators of the symmetry group and an arbitrary lexicographic order, but to choose \"the right\" set of generators and \"the right\" variable order (with respect to which to define the lexicographic order). Devriendt et al. (2016) showed that for groups that exhibit a certain structure, breaking symmetries of a good set of generators using an appropriate order can guarantee that the entire symmetry group is broken completely. Since our proof logging techniques simply use the same lexicographic order as the symmetry breaking tool, and work for an arbitrary generator set, this automatically works with the techniques described above.\nAnother (optional) modification to the basic symmetry breaking techniques implemented in BreakID is the use of a more compact encoding, where the clauses (19c) and (19d) are omitted. Since our definition of C LL (k) uses these clauses, we cannot simply omit them in our proof. However, there are no restrictions on deletions from the derived set D. Therefore, we can first derive all the symmetry breaking constraints as described above, and then remove the superfluous clauses from D as soon as they are no longer needed for the proof logging derivations.\nNext, BreakID has an optimization based on stabilizer subgroups to detect a large number of binary clauses. Since these binary clauses are all clauses of the form (19b) with j = 1, the proof logging techniques described above could support also this optimization provided that we keep track of which symmetry is used for each such binary clause. However, BreakID currently does no such bookkeeping. While it is in principle possible to add this feature, we have not done so in this work.\nFinally, BreakID supports partial symmetry breaking. That is, instead of adding the constraints (19b)-(19f) for every j, this is only done for j < L with L a limit that can be chosen by the user. The reasoning behind this is that the larger j gets, the weaker the added breaking constraint is. By setting L = 100 and adding symmetry breaking clauses only for the L first variables, we add significantly fewer constraints while retaining most of the symmetry breaking power.\nSince we only need to do proof logging for the clauses that are actually added by BreakID, this optimization works out-of-the-box. However, there is an important caveat here: for benchmark formulas where there are large symmetries, e.g., symmetries permuting all the variables in the problem, a naive implementation of our proof logging technique will suffer from serious performance problems even when this optimisation is used. The reason is that in principle the order O \u2aaf is defined on all variables that are permuted by the symmetries. If there are many such variables, this order in itself can get huge (with the largest coefficient being of exponential magnitude measured in terms of the number of variables). Luckily, there is a simple solution to this problem: instead of defining the order on all variables that are permuted, we can use the set of variables on which we will actually do the symmetry breaking (which for each symmetry are the first L variables in its support). This is the approach implemented in our experimental evaluation.", "publication_ref": ["b30", "b30", "b30"], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Evaluation of SAT Symmetry Breaking", "text": "To validate our approach, we implemented pseudo-Boolean proof logging in the VeriPB proof format for the symmetry breaking method in BreakID, and modified Kissat 4 to output VeriPB -proofs (since the redundance rule is a generalization of the RAT rule, this required only purely syntactic changes). We employed the unchecked deletion rule in Definition 10 since the generated proofs are only used to certify unsatisfiability of decision problems and never to prove satisfiability.\nAmong the benchmark instances from all the SAT competitions between the years 2016 and 2020, we selected all instances in which at least one symmetry was detected; there were 1089 such instances in total. We performed our computational experiments on machines with dual Intel Xeon E5-2697A v4 processors with 512GBytes RAM and solid-state drives (SSD) running on the Ubuntu 20.04 operating system. We ran twenty instances in parallel on each machine, where we limited each instance to 16GBytes RAM. We used a timeout of 5,000 seconds for solving and 100,000 seconds for verification of the proofs produced during the solving process.\nFigure 2 shows the performance overhead for symmetry breaking, comparing for each instance the running time with and without proof logging. For most instances, the overhead is negligible (99% of instances are at most 32% slower). Figures 3 and 4 display the relationship between the time needed to generate a proof (both for SAT and UNSAT instances) and to verify the correctness of this proof. When considering symmetry breaking in isolation (i.e., not solving the instance completely, but only breaking the symmetries), as plotted in Figure 3, 1058 instances out of 1089 could be verified, 2 timed out, and 29 terminated due to running out of memory. 75% of the instances could be verified within 3.2 times the time required for symmetry breaking and 95% within a factor 20. The time needed for verification is thus considerably longer than the time required to generate the proofs, but still practical in the majority of cases. After symmetry breaking, 721 instances could be solved with the SAT solver (Figure 4) and we could verify 671 instances, while for 33 instances verification timed out and for 17 instances the verifier ran out of memory. Notably, 84 instances could only be solved by the SAT solver when symmetry breaking clauses were added, and out of these instances we could verify correctness for 81 instances. ", "publication_ref": [], "figure_ref": ["fig_1", "fig_2", "fig_2", "fig_3"], "table_ref": []}, {"heading": "Symmetries in Constraint Programming", "text": "In the general setting considered in constraint programming, we must deal with variables with larger (non-Boolean) domains and with rich constraints supported by propagation algorithms. One might think that a proof system based upon Boolean variables and linear inequalities would not be suitable for this larger class of problem. However, Elffers et al.\n(2020) showed how to use VeriPB for constraint satisfaction problems by first encoding variables and constraints in pseudo-Boolean form, and then constructing cutting planes proofs to certify the behaviour of the all-different propagator, and Gocht, McCreesh, and Nordstr\u00f6m (2022) later extended this to a wider range of CP constraints and propagators. Similarly, the work we present here can also be applied to constraint satisfaction and optimisation problems.\nRecall the list of symmetry breaking constraints proposed for the Crystal Maze puzzle in the introductory section. Given the difficulties in knowing which combinations of symmetry breaking constraints are valid, it would be desirable if these constraints could be introduced as part of a proof, rather than taken as part of the encoding of the original problem. This would give a modeller immediate feedback as to whether the constraints have been chosen correctly. Our cutting planes proof system enhanced with redundance-based strengthening and dominance-based strengthening rules is indeed powerful enough to express all three of the examples we presented in the introduction, and we have implemented a small tool which can write out the appropriate proof fragments certifying that this is so; this allows the entire Crystal Maze example to be verified with VeriPB .\nThe source code to run our tool for the Crystal Maze puzzle is located in the tools/ crystal-maze-solver directory of the code and data repository (Bogaerts et al., 2022b) associated to this paper. Full instructions for how to use the tool are given in the tools/ crystal-maze-solver/README.md file. Below we provide a summary of our work on this problem.\nWe modelled the Crystal Maze puzzle as a constraint satisfaction problem in the natural way: there is a decision variable for each circle, whose values are the possible numbers that can be taken, and an all-different constraint over all decision variables. We use a table constraint for each edge for simplicity. We also included symmetry elimination constraints.\nWe implemented this model inside a small proof-of-concept CP solver (which can be found in the file src/crystal_maze.cc) that we created for this paper. (Full proof logging for CP is an entire research program in its own right, which we do not at all claim to have carried out within the framework of this project-what we do claim, though, is that our contribution shows that symmetries do not stand in the way of this work.) When executed, the solver compiles this high level CP model to a pseudo-Boolean model, which it will output as crystal_maze.opb. This is done following the framework introduced by Elffers et al. ( 2020), but as well as using a one-hot (direct) encoding of CP decision variables to pseudo-Boolean variables, it additionally creates channelled greater-or-equal PB variables for each CP variable-value. We remark that the encoding of the table constraints also introduces additional auxiliary variables.\nAs the solver works on the problem, it produces a file crystal_maze.veripb that provides a proof that it has found all non-symmetric solutions. The proof log will contain reverse unit propagation (RUP) clauses that justify backtracking, as well as cutting planes derivations that prove the correctness of propagations by the all-different and table constraints. Once the solver has finished, the correctness of the solver output can be checked by feeding the two files crystal_maze.opb and crystal_maze.veripb to VeriPB .\nTo verify that the symmetry constraints introduced in the high-level model are actually valid, we can remove them from the pseudo-Boolean model in crystal_maze.opb and introduce them as part of the proof instead. We describe how to do this editing in README.md. We also include a script make-symmetries.py that will output the necessary proof fragment to reintroduce the symmetry constraints. The output of this script can be verified on top of the reduced pseudo-Boolean model using our modified version of VeriPB supporting the dominance-based strengthening rule, and this verification can be performed with or without the remainder of the proof-that is, we can verify both that the constraints introduced are valid (in that they do not alter the satisfiability of the model), and that they line up with the actual execution of the solver. Interestingly, although symmetries can be broken in different ways in high-level constraint programming models (including through lexicographic and value precedence constraints), when we encode the problem in pseudo-Boolean form these differences largely disappear, and after creating a suitable order we can easily re-use the SAT proof logging techniques for symmetry breaking that we discussed above. So, although a full proof-logging constraint solver does not yet exist, we can confidently claim that symmetry breaking should not block the road towards this goal. Gocht et al. (2020a) showed how VeriPB can be used to implement proof logging for a wide range of maximum clique algorithms, observing that the cutting planes proof system is rich enough to certify a rich variety of bound and inference functions used by various solvers (despite cutting planes not knowing what a graph or clique is). However, there is one clique-solving technique in the literature that is not amenable to cutting planes reasoning. In order to solve problem instances that arise from a distance-relaxed clique-finding problem, McCreesh and Prosser (2016) enhanced their maximum clique algorithm with a lazy global domination rule that works as follows. Suppose that the solver has constructed a candidate clique C and is considering to extend C by two vertices v and w, where the neighbourhood of v excluding w is a (non-strict) superset of the neighbourhood of w excluding v. Then if the solver first tries v and rejects it, there is no need to branch on w as well (since any clique including w could be exchanged for at least as good a clique including v).", "publication_ref": ["b41", "b13", "b39", "b59"], "figure_ref": [], "table_ref": []}, {"heading": "Lazy Global Domination in Maximum Clique Solving", "text": "In principle, it should be possible to introduce additional constraints certifying this kind of reasoning in advance using redundance-based strengthening, without the need for the full dominance breaking framework in Section 3 (with some technicalities involving consistent orderings for tiebreaking). However, due to the prohibitive cost of computing the full vertex dominance relation in advance, McCreesh and Prosser instead implement a form of lazy dominance detection, which only triggers following a backtrack. To provide proof logging for this, we cannot derive the constraints justifying global domination steps in the proof log in advance, but must instead be able to introduce vertex dominance constraints on the fly precisely when they are used. It is hard to see how to achieve this with the redundance rule, but it is possible using dominance-based strengthening. In what follows, we first present a pseudo-Boolean encoding of the maximum clique problem and then a high-level description of the max clique solver used. Afterwards, we discuss how to add certification to it with the redundance rule and the dominance rule.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The Maximum Clique Problem", "text": "Throughout this section we let G = (V, E) denote an undirected, unweighted graph without self-loops with vertices V and edges E. We write N(u) to denote the neighbours of a vertex u \u2208 V , i.e., the set of vertices N(u) = {w | (u, w) \u2208 E} that are adjacent to u in the graph, and define neighbours of sets of vertices in the natural way by taking unions N(U ) = u\u2208U N(u). We say that u dominates v if\nN(u) \\ {v} \u2287 N(v) \\ {u} (25)\nholds, which intuitively says that the neighbourhood of u is at least as large as that of v. It is straightforward to verify that this domination relation is transitive. When representing the maximum clique problem in pseudo-Boolean form, we overload notation and identify every vertex v \u2208 V with a Boolean variable, where v = 1 means that the vertex v is in the clique. The task is to maximize v\u2208V v under the constraints that all chosen vertices should be neighbours, but since, syntactically speaking, we require an objective function to be minimized, we obtain\nmin v\u2208V v (26a) v + w \u2265 1 [for all (v, w) \u2208 V 2 \\ E with v \u0338 = w] (26b)\nas the formal pseudo-Boolean specification of the problem.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "High-Level Description of the Max Clique Solver", "text": "At a high level, the maximum clique solver of McCreesh and Prosser (2016) before addition of vertex dominance breaking, works as described in Algorithm 1. The first call to the MaxCliqueSearch algorithm is with parameters G, V rem = V , C curr = \u2205, and C best = \u2205.\nAlgorithm 1: Max clique algorithm without dominance.\n1 MaxCliqueSearch(G, V rem , C curr , C best ) : 2 E rem \u2190 E(G) \u2229 (V rem \u00d7 V rem ); 3 G rem \u2190 (V rem , E rem ); 4 if |C curr | > |C best | then 5 C best \u2190 C curr ; 6 (S 1 , . . . , S m ) \u2190 colour classes in colouring of G rem ; 7 j \u2190 m; 8 while j \u2265 1 and |C curr | + j > |C best | do 9 for v \u2208 S j do 10 C best \u2190 MaxCliqueSearch(G, V rem \u2229 N(v), C curr \u222a {v}, C best ); 11 V rem \u2190 V rem \\ S j ; 12 j \u2190 j \u2212 1; 13 return C best ;\nWhen MaxCliqueSearch is called with a candidate clique C curr , the best solution so far C best , and a subset of vertices V rem , it considers the residual graph G rem = (V rem , E rem ) assumed to be defined on all vertices in V \\ C curr that are neighbours of all c \u2208 C curr . Thus, the set V rem contains all vertices to which C curr could possibly be extended. The algorithm produces a colouring of G rem (where as usual adjacent vertices are assigned a different colour), which we assume results in m disjoint colour classes (S 1 , . . . , S m ) such that V rem = m i=1 S i . It is clear that any clique extending C curr can contain at most one vertex from each colour class S i , since vertices of the same colour class are non-adjacent. The clique search algorithm now iterates over all colour classes in the order S m , S m\u22121 , . . . , S 1 . Whenever the clique is extended with a new vertex, a new recursive call to MaxCliqueSearch is made. Therefore, when we reach S j in the loop, we are considering the case when all vertices in S m , S m\u22121 , . . . , S j+1 have been rejected. For this reason, if the condition |C curr | + j > |C best | fails to hold, we know that the current clique candidate cannot possibly be extended to a clique that is larger than what we have already found in C best . At the end of the first call MaxCliqueSearch(G, V, C curr = \u2205, C best = \u2205), after completion of all recursive subcalls, the vertex set C best will be a clique of maximum size in G. A certifying version of essentially this algorithm with VeriPB proof logging was presented by Gocht et al. (2020a). It might be worth noting in this context that one quite interesting challenge is to certify the backtracking performed when the condition |C curr | + j > |C best | fails, and this is one place where the strength of the pseudo-Boolean reasoning in the cutting planes proof system is very helpful (as opposed to the clausal reasoning in, e.g., DRAT , where certifying this type of counting arguments is quite challenging).\nThe vertex dominance breaking of McCreesh and Prosser ( 2016) is based on the following observation: If the algorithm is about to consider v \u2208 S j in the innermost for loop on line 9 in Algorithm 1, but has previously considered a vertex u \u2208 m i=j S i that dominates v in the sense of ( 25), then it is safe to ignore v. This is so since if the algorithm would find a solution that includes v but not u, then we could swap u for v and obtain a solution that is at least as good.\nIn pseudo-Boolean notation, this type of reasoning could be enforced by adding the constraint u + v \u2265 1 to the formula, but there is no way this can be semantically derived from the constraints (26a) or the requirement to minimize (26b). Therefore, the proof logging method in (Gocht et al., 2020a) is inherently unable to deal with such constraints.\nIn general, the vertex dominance breaking as described above does not need to break ties consistently. By this we mean that if u and v dominate each other, in principle it might happen that in a given branch of the search tree, u is chosen to dominate v, while in another one, v is chosen to dominate u, simply because of the order in which nodes are considered.\nWhile in principle, it should be possible to adapt our proof logging methods to work in this case, the argument is subtle. Luckily, it turns out that in practical implementations, tie breaking only happens in a consistent manner.\nFact 18. In the vertex dominance breaking of McCreesh and Prosser (2016), there exists a total order \u227b G on the set V of vertices such that whenever v is ignored because u has previously been considered, u \u227b G v.\nMoreover, this order \u227b G is known before the algorithm starts: u \u227b G v holds if u has a larger degree than v, or in case they have the same degree but the identifier used to represent u internally is larger than that of v. To see that this order indeed guarantees consistent tie breaking, we provide some properties of the actual implementation of the algorithm. 5\n1. If u and v dominate each other and are not adjacent, then u and v are guaranteed to be in the same colouring class. If furthermore u \u227b G v, u is considered before v in the loop in Line 8 (due to the order in which this for loop iterates over the nodes).\n2. If u and v dominate each other, are adjacent, and satisfy u \u227b G v, then u is assigned a larger colouring class than v (due to the order in which the greedy colouring algorithm in Line 6 iterates over the nodes). Hence, also in this case u will be considered before v.\nIn what follows below, we will explain:\n\u2022 first, how the redundance rule introduced to VeriPB by Gocht and Nordstr\u00f6m (2021) could in principle be used to provide proof logging for vertex dominance breaking, although with potentially impractical overhead; and\n\u2022 then, how the dominance rule introduced in this paper can be used to resolve the practical problems in a very simple way.\nAn implementation for both techniques can be found in the code and data repository (Bogaerts et al., 2022b).", "publication_ref": ["b39", "b39", "b59", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "Vertex Dominance with the Redundance-Based Strengthening Rule", "text": "In order to provide proof logging for vertex dominance breaking using the redundance rule, we could in theory proceed as follows. First, we let the solver check the vertex dominance condition ( 25) for all pairs of vertices u, v in V . Before starting the solver, we add all pseudo-Boolean constraints for vertex dominance breaking using the redundance rule. For all u, v such that u dominates v and u \u227b G v, we derive the vertex dominance breaking constraint\nu + v \u2265 1 ,(27)\ndoing so in decreasing order for u with respect to \u227b G . Our witness for the redundance rule derivation of ( 27) will be \u03c9 = {u \u2192 v, v \u2192 u}, i.e., \u03c9 will simply swap the dominating and dominated vertices. Hence, the objective function ( 26a) is syntactically unchanged after substitution by \u03c9, and so the condition in ( 5) that the objective should not increase is always vacuously satisfied.\nWe need to argue that deriving the vertex dominance breaking constraints ( 27) is valid in our proof system. Towards this end, suppose we are in the middle of the process of adding such constraints and are currently considering u + v \u2265 1 for u dominating v and u \u227b G v. Let C \u222a D be the set of constraints in the current configuration. In order to add u + v \u2265 1, we need to show that\nC \u222a D \u222a {\u00ac(u + v \u2265 1)} (28a)\ncan be used to derive all constraints in\n(C \u222a D \u222a {u + v \u2265 1})\u21be \u03c9 (28b)\nby the cutting planes method (i.e., without any extension rules).\nStarting with the vertex dominance constraint being added, note that from the negated constraint\n\u00ac(u + v \u2265 1) . = u + v \u2265 2 in (28a) we immediately obtain u \u2265 1 (29a) v \u2265 1 (29b)\nas reverse unit propagation (RUP) constraints, meaning that the weaker pseudo-Boolean constraint (u + v \u2265 1)\u21be \u03c9 . = v + u \u2265 1 is also RUP with respect to the constraints in (28a). Consider next any non-edge constraints x + y \u2265 1 in (26b) in the original formula. Clearly, such constraints are only affected by \u03c9 if {u, v} \u2229 {x, y} \u0338 = \u2205; otherwise they are present in both (28a) and (28b) and there is nothing to prove. Any non-edge constraint v + y \u2265 1 containing v will after application of \u03c9 contain u, and will hence be RUP with respect to (29a) and hence also with respect to (28a). For non-edge constraints u + y \u2265 1 with y \u0338 = v, substitution by \u03c9 yields (u + y \u2265 1)\u21be \u03c9 . = v + y \u2265 1. Since by assumption u dominates v and y \u0338 = v is not a neighbour of u, it follows from (25) that y is not a neighbour of v either. Hence, the input formula in (28a) already contains the desired nonedge constraint v + y \u2265 1.\nIt remains to analyse what happens to vertex dominance breaking constraints\nx + y \u2265 1 (30)\nthat have already been added to D before the dominance breaking constraint u + v \u2265 1 that we are considering now. Again, such a constraint is only affected by \u03c9 if {u, v} \u2229 {x, y} \u0338 = \u2205; otherwise it is present in both (28a) and (28b). We obtain the following case analysis.\n1. x = u: In this case, (x + y \u2265 1)\u21be \u03c9 . = v + \u03c9(y) \u2265 1, which is RUP with respect to v \u2265 1 in (29b) and hence also with respect to (28a).\n2. x = v: This is impossible, since u \u227b G v and any dominance breaking constraints with v = x as the dominating vertex will be added only once we are done with u as per the description right below (27).\n3. y = u: In this case x dominates u. Since x \u227b G u, u \u227b G v, and u dominates v, by transitivity we have x \u227b G v and also that x dominates v. Hence, the breaking constraint x + v \u2265 1 has already been added to D. But since u \u0338 = x \u0338 = v, we see that our desired constraint is\n(x + u \u2265 1)\u21be \u03c9 . = x + v \u2265 1\n, which is precisely this previously added constraint.\n4. y = v: Here we see that the desired constraint (x + y \u2265 1)\u21be \u03c9 .\n= \u03c9(x) + u \u2265 1 is again RUP with respect to (28a). This concludes our proof that all vertex dominance breaking constraints that are consistent with our constructed linear order \u227b G can be added and certified by the redundance rule before the solvers starts searching for cliques. So all of this works perfectly fine in theory. The problem that rules out this approach in practice, however, is that the solver will not have the time to compute the dominance relation between vertices in advance, since this is far too costly and does not pay off in general. Instead the solver designed by McCreesh and Prosser (2016) will detect and apply vertex dominance relations on the fly during search. And from a proof logging perspective this is too late-during search, when C \u222aD will also contain constraints certifying any backtracking made, our proof logging approach above no longer works. The constraints added to the proof log to certify backtracking are no longer possible to derive when substituted by \u03c9 as in (28b), for the simple reason that they are not semantically implied by (28a). One possible way around this would be to run the solver twice-the first time to collect all information about what vertex dominance breaking will be applied, and then the second time to do the actual proof logging-but this seems like quite a cumbersome approach.\nWe deliberately discuss this problem in some detail here, because this is an example of an important and nontrivial challenge that shows up also in other settings when designing proof logging for other algorithms. It is not sufficient to just come up with a proof logging system that is strong enough in principle to certify the solver reasoning (which the redundance rule is for the clique solver with vertex dominance breaking, as shown above). It is also crucial that the solver have enough information available at the right time and can extract this information efficiently enough to actually be able to emit the required proof logging commands with low enough overhead. For constraint programming solvers, it is not seldom the case that the solver knows for sure that some variable should propagate to a value, because the domain has shrunk to a singleton, or that the search should backtrack because some variable domain is empty, but that the solver cannot reconstruct the detailed derivation steps required to certify this without incurring a massive overhead in running time (e.g., since the reasoning has been performed with bit-parallel logical operations). It is precisely for this reason that it is important that our proof system allow adding RUP constraints. This makes it possible for the solver to claim facts that it knows to be true, and that it knows can be easily verified, while leaving the work of actually producing a detailed proof to the proof checker.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Vertex Dominance with the Dominance-Based Strengthening Rule", "text": "Let us now discuss how the dominance rule can be used to provide proof logging for lazy global domination. As was the case for the redundance rule, we will make use of Fact 18. Before starting the proof logging, we use the order change rule to activate the lexicographic order on the the assignments to the vertices/variables induced by \u227b G .\nSuppose now that the solver is running and that the current candidate clique is C curr . The solver has an ordered list of unassigned candidate vertices that it is iterating over when considering how to enlarge this clique, and this list is defined by the colour classes (S m , S m\u22121 , . . . , S 1 ). (We note that this ordered list depends on C curr , and would be different for a different clique C \u2032 curr .) Suppose the next vertex in that list is v. Then when it is time to make the next decision on line 9 in Algorithm 1 about enlarging the clique, the solver enhanced with proof logging does the following:\n\u2022 If there exists a vertex u that has already been considered in the current iteration and that dominates v (and for which it hence holds that u \u227b G v), then the solver discards v by vertex dominance and adds the constraint u + v \u2265 1 by the dominance rule with witness \u03c9 = {u \u2192 v, v \u2192 u}. We will explain in detail below why this is possible.\n\u2022 Otherwise, the solver enlarges C curr with v and makes a recursive call.\nWhen the solver has explored all ways of enlarging C curr and is about to backtrack, here is what will happen on the proof logging side (where we refer to (Gocht et al., 2020a) for a more detailed description of how proof logging for backtracking CP solvers works in general):\n1. For every u that was explored in an enlarged clique C curr \u222a {u}, when backtracking the solver will already have added u + w\u2208Ccurr w \u2265 1 as a RUP constraint.\n2. The solver now inserts the explicit cutting planes derivation required to show that the inequality\n|C curr | + j > |C best | must hold.\n3. After this, the solver adds the claim that w\u2208Ccurr w \u2265 1 is a RUP constraint.\nWe need to argue why w\u2208Ccurr w \u2265 1 will be accepted as a RUP constraint, allowing the solver to backtrack. The RUP check for w\u2208Ccurr w \u2265 1 propagates w = 1 for all w \u2208 C curr . This in turn propagates u = 0 for all explored vertices u by the backtracking constraints for C curr \u222a {u} added in step 1. The vertex dominance breaking constraints then propagate v = 0 for all vertices v discarded because of vertex domination. At this point, the proof checker has the same information that the solver had when it detected that the colouring constraint forced backtracking. This means that the proof checker will unit propagate to contradiction, and so the backtracking constraint w\u2208Ccurr w \u2265 1 is accepted as a RUP constraint.\nWe still need to explain how and why the pseudo-Boolean dominance rule applications allow deriving the constraint u + v \u2265 1 in case u dominates v (and hence u \u227b G v). Recall that the order used in our proof is the lexicographic order induced by \u227b G . This means that if vertices/variables u and v are assigned by \u03b1 in such a way as to violate a dominance breaking constraint u + v \u2265 1, then \u03b1 \u2022 \u03c9 will flip u to 1 and v to 0 to produce a lexicographically smaller assignment (since v is considered before u in the lexicographic order).\nThe conditions for the dominance rule are that we have to exhibit proofs of (10a) and (10b). In this discussion, let us focus on (10a) which says that starting with the constraints\nC \u222a D \u222a {\u00ac(u + v \u2265 1)} (31a)\nand using only cutting planes rules, we should be able to derive\nC \u21be \u03c9 \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) \u222a {f\u21be \u03c9 \u2264 f } . (31b\n)\nNote first that our lexicographic order in fact does not in itself respect the objective function (26b). However, since \u03c9 just swaps two variables it leaves the objective syntactically unchanged, meaning that the inequality f\u21be \u03c9 \u2264 f in (10a) is seen to be trivially true.\nAs in our analysis of the redundance rule, from (31a) we obtain u \u2265 1 and v \u2265 1 as in ( 29a)-(29b), and O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) is easily verified to be RUP with respect to these constraints, since what the formula says after cancellation is precisely that v \u2265 u.\nIt remains to consider the pseudo-Boolean constraints in the solver constraint database C \u222a D. The crucial difference from the redundance rule is that we no longer have to worry about proving D\u21be \u03c9 in (31b)-we only need to show how to derive C \u21be \u03c9 . But this means that all we need to consider are the non-edge constraints in (26b). We already explained in our analysis for the redundance rule derivation that the fact that u dominates v means that for any non-edge constraints affected by \u03c9 their substituted versions are already there as input constraints or are easily seen to be RUP constraints. In addition to these non-edge constraints there might also be all kinds of interesting derived constraints in D, but the dominance rule says that we can ignore those constraints.\nFinally, although we skip the details here, it is not hard to argue analogously to what has been done above to show that \u00acC . = \u00ac(u + v \u2265 1) and O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) in (10b) together unit propagate to contradiction. This concludes our discussion of how to certify vertex dominance breaking in the maximum clique solver by McCreesh and Prosser (2016) using the pseudo-Boolean dominance rule introduced in this paper.", "publication_ref": ["b39"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion", "text": "In this paper, we introduce a method for showing the validity of constraints obtained by symmetry or dominance breaking by adding simple, machine-verifiable certificates of correctness. Using as our foundation the cutting planes method (Cook et al., 1987) for reasoning about pseudo-Boolean constraints (also known as 0-1 linear inequalities), and building on and extending the version of the VeriPB tool developed by Gocht and Nordstr\u00f6m (2021), we present a proof logging method in which symmetry and dominance breaking is easily expressible. Our method is a strict extension of DRAT (Heule et al., 2013a(Heule et al., , 2013bWetzler et al., 2014) and other similar methods earlier used for solver proof logging, which means that we can produce efficient proofs of validity for SAT solving with fully general symmetry breaking, and we provide a thorough evaluation showing that this approach is feasible in practice. Since VeriPB can also certify cardinality and parity (XOR) reasoning, we now have for the first time a unified proof logging method for SAT solvers using all of these enhanced solving methods. To demonstrate that our proof logging approach is not limited to Boolean satisfiability, in this work we also present applications to symmetry breaking in constraint programming and vertex domination in maximum clique solving.\nFrom a theoretical point of view, it would be interesting to understand better the power of the dominance-based strengthening rule. DRAT viewed as a proof system is closely related to extended resolution (Tseitin, 1968) in that these two proof systems have the same proof power up to polynomial factors (Kiesl, Rebola-Pardo, & Heule, 2018), and extended resolution, in turn, is polynomially equivalent to the extended Frege proof system (Cook & Reckhow, 1979), which is one of the strongest proof systems studied in proof complexity. However, there are indications that the cutting planes proof system equipped with the dominance-based strengthening rule might be strictly stronger than extended Frege (Ko lodziejczyk & Thapen, 2023).\nAnother question is whether such a strong derivation rule as dominance-based strengthening is necessary to generate efficient proofs of validity for general symmetry breaking constraints, or whether redundance-based strengthening is enough. To phrase this cleanly as a proof complexity problem, we can restrict our attention to decision problems and also fix the order to be lexicographic order over some set of variables \u20d7 x. Let us define cutting planes with symmetry breaking to be the cutting planes proof system extended with a rule that allows to derive the constraint \u20d7 x \u2aaf lex \u20d7 x\u21be \u03c3 for any symmetry \u03c3 of the input formula F . Now we can ask whether cutting planes with redundance-based strengthening efficiently simulates this cutting planes proof system with symmetry breaking. To the best of our understanding, this question is wide open.\nFrom a proof logging perspective, a natural next problem to investigate is whether our certification method is strong enough to capture other solving techniques such as those used for SAT-based optimisation in so-called MaxSAT solvers. A crucial component of several MaxSAT solving techniques is the translation of pseudo-Boolean constraints to CNF. This is used in linear SAT-UNSAT (LSU) solvers for adding the objective-improving constraints (e.g., Koshimura, Zhang, Fujita, & Hasegawa, 2012;Paxian & Becker, 2022), in core-guided solvers for reformulation of the objective function (e.g., Ignatiev, Morgado, & Marques-Silva, 2019), and in implicit hitting set solvers that make use of abstract cores (Berg, Bacchus, & Poole, 2020). While developing proof logging methods that can support the full range of modern MaxSAT solving techniques remains a formidable challenge, we want to point out that significant progress has been made of late. The proof system introduced by Gocht and Nordstr\u00f6m (2021) has been used to certify correctness of the translations of pseudo-Boolean constraints into CNF for a range of encodings , and quite similar ideas have been employed to design proof logging for an objective-improving solver for unweighted MaxSAT (Vandesande, De Wulf, & Bogaerts, 2022). Very recently, this has been extended also to state-of-the-art core-guided MaxSAT solvers (Berg, Bogaerts, Nordstr\u00f6m, Oertel, & Vandesande, 2023).\nAnother intriguing problem is how to design efficient proof logging for symmetric learning as explored by Devriendt et al. (2017). In contrast to the symmetry breaking techniques considered in the current paper, when using symmetric learning one can only derive constraints that are semantically implied by the input formula. However, if at some point the solver derives a constraint D, and if \u03c3 is a symmetry of the formula, then it is clear that the permuted constraint \u03c3(D) is also implied by the formula and so should be sound to derive in a single extra step.\nIf we wanted to argue formally about such symmetric learning, we could apply \u03c3 to the whole derivation leading up to D to get a proof that \u03c3(D) can be derived. Taking this observation one step further, if from the solver execution we can extract a subderivation \u03c0 showing that a constraint D is implied by constraints C 1 , . . . , C m , and if \u03c3(C 1 ), . . . , \u03c3(C m ) have also been derived, then it should be valid to use \u03c0 as a \"lemma\" to conclude \u03c3(D). The usefulness of such lemmas in the context of proof logging has been discussed by, e.g., Kraiczy and McCreesh (2021). The question, however, is whether such reasoning can be incorporated in the VeriPB framework with the current set of derivation rules in the proof system. One way of attempting to do this could of course be to add special rules for symmetric learning or lemmas, but this goes against the goal of keeping the proof logging system as simple as possible, so that derivations are obviously sound. As a case in point, it is worth noting that the naive way of adding such dedicated rules for symmetries or lemmas to our redundancebased strengthening and dominance-based strengthening rules would result in an unsound proof system.\nThe use of lemmas in proofs has been studied in the so-called substitution Frege proof system (Cook & Reckhow, 1979), and it has been shown that extended Frege has the same deductive strength as substitution Frege except possibly for a polynomial overhead in proof size (Kraj\u00ed\u010dek & Pudl\u00e1k, 1989). However, it is not clear whether such results can be scaled down from Frege systems to cutting planes, so that cutting planes with redundance-based strengthening can be made to simulate the usage of lemmas as described above, and whether such reasoning could be implemented efficiently enough in VeriPB to allow a formalization of reasoning with lemmas that would be feasible in practice.\nAs noted above, we have also shown in this work that our proof logging techniques can be used beyond SAT solving and SAT-based optimization for other combinatorial solving paradigms such as graph solving algorithms and constraint programming (CP), and Elffers et al. (2020) and  have made important contributions towards providing VeriPB -style proof logging for a full-blown CP solver. For mixed integer linear programming (MIP) solvers, Cheung, Gleixner, and Steffy (2017) and Eifler and Gleixner (2021) have also developed limited proof logging support (using another proof format), but this method still seems quite far from being able to support advanced MIP techniques. It would be very exciting if all of these different proof logging techniques could be strengthened to provide full proof logging support for state-of-the-art CP and MIP solvers.\nFinally, we want to point out that another important research direction in proof logging is to develop formally verified proof checkers, so that we can be sure when proof verification passes that this is not due to bugs in the proof checker but that the claimed result is guaranteed to be valid. Such verified checkers have been built for DRAT and other clausal proof logging systems (Cruz-Filipe et al., 2017b, 2017aLammich, 2020;Tan, Heule, & Myreen, 2021), and it would be highly desirable to obtain such tools for pseudo-Boolean proof logging with VeriPB as well. As a first step in this direction, a formally verified pseudo-Boolean proof checker for decision problems was recently submitted to and used in the SAT Competition 2023 (Bogaerts et al., 2023).\nWe present the symmetry breaking proof logging in the syntactic format used by VeriPB , so that the reader will be able to see what pseudo-Boolean proof files actually look like. To keep the example manageable, we consider a very small instance of the pigeonhole principle with only 4 pigeons and 3 pigeonholes. We encode the pigeonhole principle formula using variables p ij , with the intended interpretation that p ij is true if pigeon i resides in hole j. The input for the symmetry breaking preprocessor consists of a CNF formula which can be written in pseudo-Boolean form as \np\np 23 + p 43 \u2265 1 (C21) p 33 + p 43 \u2265 1 (C22)\nwhere constraints (C1)-(C4) represent that each pigeon resides in at least one hole, and constraints (C5)-(C22) enforce that each hole is occupied by at most one pigeon (by specifying for every pigeonhole and every pair of distinct pigeons that it cannot be the case that both of these pigeons reside in the hole). When VeriPB is used for SAT proof logging, the proof checker parses CNF formulas in the standard DIMACS format used by SAT solvers, but the CNF formula will be reprented internally in the proof checker as a set of pseudo-Boolean constraints as above.", "publication_ref": ["b23", "b42", "b45", "b46", "b71", "b67", "b52", "b22", "b54", "b53", "b61", "b50", "b8", "b42", "b68", "b9", "b29", "b55", "b22", "b56", "b33", "b20", "b32", "b27", "b26", "b57", "b64", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "A.1 Starting the Proof and Introducing the Order", "text": "A VeriPB proof starts with a proof header (stating which version of the proof system is used) and an instruction to load the input formula\nL1 pseudo -Boolean proof version 2.0 L2 f 22\nwhere the number 22 specifies the number of pseudo-Boolean constraints in the input. All constraints in the proof file will be numbered consecutively starting with the input constraints, and will be referred to in the derivations by these numbers.\nTo prepare for the symmetry breaking, BreakID then introduces a pre-order that compares two binary sequences in lexicographic order. This pre-order is defined by inserting the lines L3 pre_order exp22 fresh_right w1 w2 w3 w4 w5 w6 w7 w8 w9 w10 w11 w12\nL17 end L18 proof L19 proofgoal #1 L20 pol 1 2 + 3 + L21 qed -1 L22 qed L23 end L24 end\nin the proof file. The pre-order is named exp22 on Line 3, so that we can refer to it later in the proof. Lines 5 and 6 introduce placeholder names for the 2 \u00d7 12 variables used to define the order. Line 11 then provides the exponential encoding ( 14) of the claim that the sequence of variables u1, . . . , u12 is lexicographically smaller than or equal to v1, . . . , v12.\nTo prove that the pseudo-Boolean formula consisting of the single constraint on Line 11 defines a transitive relation, a third set of placeholder variables w1, . . . , w12 is declared on Line 16, and these variables are used in a formal derivation as specified in (13b) on page 1554 that O \u2aaf (\u20d7 u, \u20d7 v) and O \u2aaf (\u20d7 v, \u20d7 w) together imply O \u2aaf (\u20d7 u, \u20d7 w). The VeriPB tool has a certain preference for proofs by contradiction, however, so the way this is established is by showing that O \u2aaf (\u20d7 u, \u20d7 v) and O \u2aaf (\u20d7 v, \u20d7 w) together with the negation \u00acO \u2aaf (\u20d7 u, \u20d7 w) is contradictory (and if the order consistent of more than one PB constraint, one negates the constraints one by one and derives contradiction for every negated constraint. For the order on Line 11 we get the three constraints \nwhere we use the labels (T1)-(T3) to emphasize that these are not constraints learned in the proof system, but are temporary constraints, local to the proof of transitivity. Line 20 is an instruction in reverse polish notation to add the constraints (T1), (T2), and (T3) together, resulting (after simplification) in the constraint 0 \u2265 \u22121 .\n(T4)\nLine 21 then concludes the subproof, which is possible since the last derived constraint (which, using relative indexing, is what the number \u22121 refers to) is indeed a conflicting constraint. Note that in order to prove that the pseudo-Boolean constraint defines a preorder we also need to show that the relation it defines is reflexive, but for a simple order like the one in this example everything in the formula trivializes when you substitute the same variables for both the u-and the v-sequence, and so VeriPB can figure out that reflexivity holds by itself without the help of any written proof. The proof continues with the instruction L25 load_order exp22 p21 p22 p23 p11 p12 p13 p31 p32 p33 p41 p42 p43 which specifies that the order exp22 should be used and should be applied to all variables in the formula in the specified order. The reader might find slightly odd that in the order specified above all variables related to pigeon 2 are ordered before those referring to pigeon 1, followed by variables mentioning pigeons 3 and 4. In other words, in the lex-leader order, assignments are sorted with respect to pigeon 2 first. The reason for this seemingly strange choice is that the entire proof presented in this appendix is actually generated fully automatically by BreakID. This tool only takes a propositional logic formula as input, and has no information about high-level interpretations of what the different variables mean, or which ordering of these variables might seem more or less natural from the point of view of a human observer.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2 Logging the Breaking of a First Symmetry", "text": "Now that the order has been defined and has been proven to be an order, we can start adding symmetry breaking constraints to the proof log. The first symmetry that BreakID considers is \u03c0 := (p 11 p 43 )(p 12 p 42 )(p 13 p 41 )(p 21 p 23 )(p 31 p 33 ) ,\nwhich is the symmetry that simultaneously swaps pigeons 1 and 4 and pigeonholes 1 and 3. We remark that the questions of why BreakID chooses to break this particular symmetry, and how it finds the symmetry in the first place, are interesting and nontrivial questions, but they are not relevant for our work. This is so since we are not trying to construct new symmetry breaking tools, but to design proof logging methods to certify the correctness of the symmetry breaking constraints added by existing tools. From the point of view of proof logging, it is mostly irrelevant to dwell on the possible reasons why a specific symmetry was chosen, or how it was found. Instead, we can just take the symmetry as a given and focus on proof logging for the symmetry breaking constraints.\nAs explained in our discussion of symmetry breaking in Section 4, in order to break a given symmetry we first use the dominance rule to derive a pseudo-Boolean exponential encoding of a lex-leader by the proof lines L26 dom -1 p43 1 p11 -2 p42 2 p12 -4 p41 4 p13 -8 p33 8 p31 -32 p31 32 p33 \u2192 -64 p13 64 p41 -128 p12 128 p42 -256 p11 256 p43 -512 p23 512 p21 \u2192 -2048 p21 2048 p23 >= 0 ; p11 -> p43 p12 -> p42 p13 -> p41 p21 -> \u2192 p23 p23 -> p21 p31 -> p33 p33 -> p31 p41 -> p13 p42 -> p12 p43 -> \u2192 p11 ; begin\nL27 proofgoal #2 L28 pol -1 -2 + L29\nqed -1 which we will now discuss in more detail. Line 26 above says that the dominance rule should be used to derive (and add to the derived set D) the constraint (20), which expresses that the assignment to the variables should not become lexicographically smaller when the symmetry is applied. The variables related to pigeon 2 occur with the highest coefficients, since they were given the highest priority when the order was instantiated. Notice that the pseudo-Boolean constraint specified on Line 26 contains two occurrences of every variable. This is because the constraint has been generated automatically, and VeriPB will perform cancellations to simplify the constraint before storing it internally.\nAn application of the dominance rule needs to provide more information to VeriPB than just the constraint to be derived by dominance, however. The proof should also specify\n\u2022 the witness, which in this case is just the symmetry, written as a substitution at the end of Line 26, and\n\u2022 explicit derivations (subproofs) for all constraints (proof goals) where the proof checker cannot automatically figure out such a derivation-in this case, we have a single such proof goal that is taken care of on Lines 27-29.\nLet us discuss in more detail what subproofs are required. In order to apply the dominance rule to derive the constraint C using witness \u03c9, we need to establish that derivations\nC \u222a D \u222a {\u00acC} \u22a2 C \u21be \u03c9 \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) \u222a {f\u21be \u03c9 \u2264 f } (33a) C \u222a D \u222a {\u00acC} \u222a O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u22a2 \u22a5 (33b)\nexist. In the concrete case of the first symmetry breaking constraint for the formula consisting of the clauses (C1)-(C22), VeriPB will generate the following numbered list of derivations (or proof obligations) that it expects to see:\n1. C \u222a D \u222a {\u00acC} \u22a2 O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) 2. C \u222a D \u222a {\u00acC} \u222a O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u22a2 \u22a5 3. C \u222a D \u222a {\u00acC} \u22a2 f\u21be \u03c9 \u2264 f 4-25. C \u222a D \u222a {\u00acC} \u22a2 D for each D \u2208 C \u21be \u03c9 .\nExcept for the second proof obligation, all of them can be proved automatically. Perhaps the simplest case is the third obligation, which is trivial since we are dealing with a decision problem for which the objective function is the constant f = 0. And since \u03c9 is a syntactic symmetry of the set of core constraints C (which at this point is the CNF formula in the input), the proof obligations 4-25 are also trivial. is added to the derived set D. Once all proof obligations have been taken care of, the constraints (C23), (C24), and (C25) are automatically erased by the proof checker and can no longer be referred to without triggering an error, since they are only relevant for the derivations in the subproof. The inequality (C26) is a lex-leader constraint for the symmetry we are considering, but this constraint is nothing that the SAT solver knows about or can understand, since the solver only operates with disjunctive clauses. What happens next in the proof, therefore, is that the constraint (C26) is converted to a set of clauses on the form (19a)-(19f) that the solver can use for symmetry breaking.\nFirst, (19a) is added with the redundance rule with the instruction L30 red 1 y0 >= 1 ; y0 -> 1 which contains both the constraint y 0 \u2265 1 (C27)\nand the witness y 0 \u2192 1 to apply the redundance rule. All proof obligations are checked automatically by VeriPB .\nIn our chosen lexicographic order, the first variable is p 21 . Therefore, the first clause for symmetry breaking is\np 21 \u2228 \u03c0(p 21 ) . = p 21 \u2228 p 23 ,(35)\nwhich is a simplification of (19b), omitting the trivially true variable y 0 . This clause is implied by the constraint (C26), which can be seen by weakening away all other variables in it (i.e., adding literal axioms to cancel them). Instead of providing an explicit derivation, we can simply add the clause ( 35) it with the reverse unit propagation rule and let VeriPB figure out the details, which we do by inserting the line\nL31 rup 1 \u223cp21 1 p23 >= 1 ;\nthat derives the desired constraint\np 21 + p 23 \u2265 1 .(C28)\nNext, the fresh variable y 1 is introduced with four redundance rule applications L32 red 1 p23 1 \u223cy0 1 y1 >= 1 ; y1 -> 1 L33 red 1 \u223cp21 1 \u223cy0 1 y1 >= 1 ; y1 -> 1 L34 red 1 \u223cy1 1 y0 >= 1 ; y1 -> 0 L35 red 1 \u223cy1 1 \u223cp23 1 p21 >= 1 ; y1 -> 0 with witnesses mapping y 1 to either 0 or to 1, resulting in the constraints \np 23 + y 0 + y 1 \u2265 1 (C29\n)\np 21 + y 0 + y 1 \u2265 1 (C30) y 1 + y 0 \u2265 1 (C31)\nThe second line deletes (C26) from D since it will no longer be required.\nThe next variable in lexicographic order after p 21 is p 22 . However, since our symmetry \u03c0 maps p 22 to itself, no symmetry breaking clauses are added for it. The variable after that in the ordering is p 23 , which is mapped to p 21 , resulting in the (conditional on y 1 ) symmetry breaking constraint\ny 1 + p 23 + p 21 \u2265 1 (C34)\nobtained by adding the line L38 rup 1 \u223cy1 1 \u223cp23 1 p21 >= 1 ;\nto the proof. After this, the next fresh variable y 2 is introduced in the same way as y 1 using the redundance rule in the instructions L39 red 1 p21 1 \u223cy1 1 y2 >= 1 ; y2 -> 1 L40 red 1 \u223cp23 1 \u223cy1 1 y2 >= 1 ; y2 -> 1 L41 red 1 \u223cy2 1 y1 >= 1 ; y2 -> 0 L42 red 1 \u223cy2 1 \u223cp21 1 p23 >= 1 ; y2 -> 0 yielding the clauses\np 21 + y 1 + y 2 \u2265 1 (C35\n)\np 23 + y 1 + y 2 \u2265 1 (C36) y 1 + y 2 \u2265 1 (C37\n)\np 21 + p 23 + y 2 \u2265 1 (C38)\nAs before, our pseudo-Boolean symmetry breaking constraint is simplified with and the second instruction deletes constraint (C33). The next variable in our chosen order is p 11 . Since p 11 is mapped to p 43 , we want to have the symmetry breaking clause\np 11 + p 43 + y 2 \u2265 1 ,(C40)\nwhich can be derived by the proof line\nL45 rup 1 \u223cy2 1 \u223cp11 1 p43 >= 1 ;\nTo see that the clause (C40) indeed follows by reverse unit propagation, consider what happens if all literals in the clause are set to false. Whenever y 2 is true, so are y 1 and y 0 (by (C37) and ( C31)). If furthermore p 43 is false and p 11 is true, then (C39) simplifies to \nwhich can never be satisifed since the coefficients on the left only add up to 420. The process of introducing a new variable is the same as before, appending the constraints p 43 + y 2 + y 3 \u2265 1 (C41) This process continues in the same way for all variables in the lexicographic ordering that are not mapped to themselves, or stabilized, by \u03c0.\np 11 + y 2 + y 3 \u2265 1 (C42) y 2 + y 3 \u2265 1 (C43\n)\np", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.3 Logging the Breaking of More Symmetries", "text": "As the BreakID execution continues, more symmetries are detected and broken, and the corresponding symmetry breaking clauses are derived in the proof. The process is completely analogous to what is described above for the first symmetry. For our concrete toy example formula with 4 pigeons and 3 holes, BreakID next breaks the symmetries in the order listed (where, just to help decode the notation, the first of these symmetries swaps holes 1 and 2 and simultaneously swaps pigeons 2 and 3). It is crucial to note here that when we break later symmetries in this list, we do not have to worry about previously added symmetry breaking clauses. There is no interaction between the different symmetry breaking derivations, since all the symmetry breaking constraints are added to the derived set D, whereas the core set C containing the proof obligation for the dominance rule applications only consists of the symmetric input formula.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.4 Proof for the Preprocessed Formula", "text": "The symmetry breaking performed here only serves as a preprocessing step for the solving; it is not a complete proof leading to a contradiction. A revision of the VeriPB proof format used in the SAT Competition 2023 (Bogaerts et al., 2023), and currently under further development, will allow proofs for preprocessing steps, establishing that the formulas before and after preprocessing are equisatisfiable (or, for optimization problems, that the two formulas have the same optimal value for the objective function). Very briefly, the way a proof for preprocessing will work is that at the end of the proof all constraints to be output should be moved to the core set C , after which the derived set D is emptied. The constraints in C then constitute the output formula, which is guaranteed to be equisatisfiable to the input formula if all deletion steps are instances of checked deletion as described in Definition 8 in Section 3.4. We remark that this is quite similar to the concept of finalization.\nFor our toy example, in order to prove equisatisfiability of the formula after having added symmetry breaking clauses one should end the proof with the lines The intended semantics here is that Line 492 will move all the symmetry breaking clauses that have been derived to the core set C . Line 493 claims that the input and the set of constraints that is now in the core are equisatisfiable. At the time of writing, the public version of VeriPB does not yet support non-trivial output statements, (i.e., does not provide support for checking that the list of constraint identifiers are precisely the set of constraints in the core set at the of the proof), and only output NONE is supported in the version of VeriPB used in the SAT Competition 2023 (Bogaerts et al., 2023). However, support for outputting formulas at the end of the proof is currently being developed and is expected to be available in a not too distant future. Line 494 states that the output formula has 39 variables and 136 constraints and Line 495 lists the IDs of those 136 constraints. Finally, the conclusion line 496 states that neither satisfiability nor unsatisfiability can be concluded from this proof. More details about the intended format and semantics of the output section in VeriPB proofs can be found in the technical documentation for the SAT Competition 2023 (Bogaerts et al., 2023), but it should be emphasized again that these features of the proof checker are currently under development and minor changes could and should be expected on the way from the current tentative specification to the final finished product.", "publication_ref": ["b14", "b14", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "The authors gratefully acknowledge fruitful and stimulating discussions on proof logging with Jeremias Berg, Armin Biere, Jo Devriendt, Jan Elffers, Ambros Gleixner, Marijn Heule,", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Daniela Kaufmann, Daniel Le Berre, Matthew McIlree, Magnus Myreen, Yong Kiam Tan, James Trimble, and many other colleagues whom we have probably forgotten and to whom we apologize. We are also grateful to the anonymous AAAI and JAIR reviewers, whose comments helped us to improve the exposition considerably and also to fix some mistakes in the definitions.\nPart of this work was carried out while taking part in the semester program Satisfiability: Theory, Practice, and Beyond in the spring of 2021 at the Simons Institute for the Theory of Computing at UC Berkeley, and in the extended reunion of this semester program in the spring of 2023. This work has also benefited greatly from discussions during the Dagstuhl Seminars 22411 Theory and Practice of SAT and Combinatorial Solving and 23261 SAT Encodings and Beyond.\nStephan Gocht and Jakob Nordstr\u00f6m were supported by the Swedish Research Council grant 2016-00782, and Jakob Nordstr\u00f6m also received funding from the Independent Research Fund Denmark grant 9040-00389B. Ciaran McCreesh was supported by a Royal Academy of Engineering research fellowship. Bart Bogaerts was supported by Fonds Wetenschappelijk Onderzoek -Vlaanderen (project G0B2221N), by the Flemish Government (AI Research Program), and by TAILOR, a project funded by EU Horizon 2020 research and innovation programme under GA No 952215.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Appendix A. A Proof Logging Example for Symmetry Breaking", "text": "In this appendix, we present a fully worked-out example of symmetry breaking using the dominance-based strengthening rule for the well-known pigeonhole principle formulas claiming that n + 1 pigeons can be mapped to n pigeonholes in a one-to-one fashion. Haken (1985) showed that resolution proofs of unsatisfiability for such formulas requires a number of clauses that scales exponentially with n, and since conflict-driven clause learning SAT solvers can be seen to search for resolution proofs (Beame, Kautz, & Sabharwal, 2004), this means that solvers without enhanced reasoning methods will have to run for exponential time. However, since pigeonhole principle formulas are fully symmetric with respect to both pigeons and holes, it is possible to add symmetry breaking constraints encoding that without loss of generality pigeon 1 resides in hole 1, pigeon 2 resides in hole 2, et cetera, and once such symmetry breaking constraints have been added the problem becomes trivial.\nWhat we show in this appendix is how the BreakID tool can break pigeonhole principle symmetries in a fully automated fashion, and produce proofs of correctness for the symmetry breaking clauses that the proof checker will accept. The proofs for these clauses can then be concatenated with the SAT solver proof log (rewritten from DRAT to VeriPB -format) and fed to VeriPB to provide end-to-end verification for the whole solving process.", "publication_ref": ["b44", "b5"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Mixed integer programming: Analyzing 12 years of progress", "journal": "Springer", "year": "2013", "authors": "T Achterberg; R Wunderling"}, {"ref_id": "b1", "title": "Metamorphic testing of constraint solvers", "journal": "Springer", "year": "2018", "authors": "\u00d6 Akg\u00fcn; I P Gent; C Jefferson; I Miguel; P Nightingale"}, {"ref_id": "b2", "title": "An introduction to certifying algorithms. it -Information Technology Methoden und innovative Anwendungen der Informatik und Informationstechnik", "journal": "", "year": "2011", "authors": "E Alkassar; S B\u00f6hme; K Mehlhorn; C Rizkallah; P Schweitzer"}, {"ref_id": "b3", "title": "Efficient symmetry breaking for Boolean satisfiability", "journal": "IEEE Transactions on Computers", "year": "2006", "authors": "F A Aloul; K A Sakallah; I L Markov"}, {"ref_id": "b4", "title": "Constraint propagation and decomposition techniques for highly disjunctive and highly cumulative project scheduling problems", "journal": "Springer", "year": "1997", "authors": "P Baptiste; C L Pape"}, {"ref_id": "b5", "title": "Towards understanding and harnessing the potential of clause learning", "journal": "", "year": "2004", "authors": "P Beame; H Kautz; A Sabharwal"}, {"ref_id": "b6", "title": "Enhancing clause learning by symmetry in SAT solvers", "journal": "", "year": "2010", "authors": "B Benhamou; T Nabhani; R Ostrowski; M R Sa\u00efdi"}, {"ref_id": "b7", "title": "Tractability through symmetries in propositional calculus", "journal": "Journal of Automated Reasoning", "year": "1994", "authors": "B Benhamou; L Sa\u00efs"}, {"ref_id": "b8", "title": "Abstract cores in implicit hitting set MaxSat solving", "journal": "Springer", "year": "2020", "authors": "J Berg; F Bacchus; A Poole"}, {"ref_id": "b9", "title": "Certified core-guided maxsat solving", "journal": "", "year": "2023", "authors": "J Berg; B Bogaerts; J Nordstr\u00f6m; A Oertel; D Vandesande"}, {"ref_id": "b10", "title": "", "journal": "", "year": "2006", "authors": "A Biere"}, {"ref_id": "b11", "title": "Artificial Intelligence and Applications", "journal": "IOS Press", "year": "2021", "authors": "A Biere; M J H Heule;  Van Maaren"}, {"ref_id": "b12", "title": "Certified symmetry and dominance breaking for combinatorial optimisation", "journal": "", "year": "2022", "authors": "B Bogaerts; S Gocht; C Mccreesh; J Nordstr\u00f6m"}, {"ref_id": "b13", "title": "Certified symmetry and dominance breaking for combinatorial optimisation (code and data", "journal": "", "year": "2022", "authors": "B Bogaerts; S Gocht; C Mccreesh; J Nordstr\u00f6m"}, {"ref_id": "b14", "title": "Documentation of VeriPB and CakePB for the SAT competition 2023", "journal": "", "year": "2023", "authors": "B Bogaerts; C Mccreesh; M O Myreen; J Nordstr\u00f6m; A Oertel; Y K Tan"}, {"ref_id": "b15", "title": "Solving with provably correct results: Beyond satisfiability, and towards constraint programming", "journal": "", "year": "2022", "authors": "B Bogaerts; C Mccreesh; J Nordstr\u00f6m"}, {"ref_id": "b16", "title": "Automated testing and debugging of SAT and QBF solvers", "journal": "Springer", "year": "2010", "authors": "R Brummayer; F Lonsing; A Biere"}, {"ref_id": "b17", "title": "A branch-and-price algorithm for the minimum latency problem", "journal": "Computers & Operations Research", "year": "2018", "authors": "T Bulh\u00f5es; R Sadykov; E Uchoa"}, {"ref_id": "b18", "title": "Proof complexity and SAT solving", "journal": "", "year": "2021", "authors": "S R Buss; J Nordstr\u00f6m"}, {"ref_id": "b19", "title": "DRAT proofs, propagation redundancy, and extended resolution", "journal": "Springer", "year": "2019", "authors": "S R Buss; N Thapen"}, {"ref_id": "b20", "title": "Verifying integer programming results", "journal": "Springer", "year": "2017", "authors": "K K H Cheung; A M Gleixner; D E Steffy"}, {"ref_id": "b21", "title": "Dominance breaking constraints", "journal": "Constraints", "year": "2015", "authors": "G Chu; P J Stuckey"}, {"ref_id": "b22", "title": "The relative efficiency of propositional proof systems", "journal": "Journal of Symbolic Logic", "year": "1979", "authors": "S A Cook; R A Reckhow"}, {"ref_id": "b23", "title": "On the complexity of cutting-plane proofs", "journal": "Discrete Applied Mathematics", "year": "1987", "authors": "W Cook; C R Coullard; G Tur\u00e1n"}, {"ref_id": "b24", "title": "A hybrid branch-and-bound approach for exact rational mixed-integer programming", "journal": "Mathematical Programming Computation", "year": "2013", "authors": "W Cook; T Koch; D E Steffy; K Wolter"}, {"ref_id": "b25", "title": "Symmetry-breaking predicates for search problems", "journal": "", "year": "1996", "authors": "J M Crawford; M L Ginsberg; E M Luks; A Roy"}, {"ref_id": "b26", "title": "Efficient certified RAT verification", "journal": "Springer", "year": "2017", "authors": "L Cruz-Filipe; M J H Heule; W A Hunt; M Kaufmann; P Schneider-Kamp"}, {"ref_id": "b27", "title": "Efficient certified resolution proof checking", "journal": "Springer", "year": "2017", "authors": "L Cruz-Filipe; J P Marques-Silva; P Schneider-Kamp"}, {"ref_id": "b28", "title": "of International Series in Operations Research & Management Science", "journal": "Kluwer Academic Publishers", "year": "2002", "authors": "E L Demeulemeester; W S Herroelen"}, {"ref_id": "b29", "title": "Symmetric explanation learning: Effective dynamic symmetry handling for SAT", "journal": "Springer", "year": "2017", "authors": "J Devriendt; B Bogaerts; M Bruynooghe"}, {"ref_id": "b30", "title": "Improved static symmetry breaking for SAT", "journal": "Springer", "year": "2016", "authors": "J Devriendt; B Bogaerts; M Bruynooghe; M Denecker"}, {"ref_id": "b31", "title": "Symmetry propagation: Improved dynamic symmetry breaking in SAT", "journal": "", "year": "2012", "authors": "J Devriendt; B Bogaerts; B De Cat; M Denecker; C Mears"}, {"ref_id": "b32", "title": "A computational status update for exact rational mixed integer programming", "journal": "Springer", "year": "2021", "authors": "L Eifler; A Gleixner"}, {"ref_id": "b33", "title": "Justifying all differences using pseudo-Boolean reasoning", "journal": "", "year": "2020", "authors": "J Elffers; S Gocht; C Mccreesh; J Nordstr\u00f6m"}, {"ref_id": "b34", "title": "The future of optimization technology", "journal": "Constraints", "year": "2014", "authors": "Garcia De La Banda; M Stuckey; P J Van Hentenryck; P Wallace; M "}, {"ref_id": "b35", "title": "Complex optimization in answer set programming", "journal": "Theory and Practice of Logic Programming", "year": "2011", "authors": "M Gebser; R Kaminski; T Schaub"}, {"ref_id": "b36", "title": "of Foundations of Artificial Intelligence", "journal": "Elsevier", "year": "2006", "authors": "I P Gent; K E Petrie; J Puget"}, {"ref_id": "b37", "title": "SolverCheck: Declarative testing of constraints", "journal": "Springer", "year": "2019", "authors": "X Gillard; P Schaus; Y Deville"}, {"ref_id": "b38", "title": "Certified CNF translations for pseudo-Boolean solving", "journal": "", "year": "2022", "authors": "S Gocht; R Martins; J Nordstr\u00f6m; A Oertel"}, {"ref_id": "b39", "title": "Certifying solvers for clique and maximum common (connected) subgraph problems", "journal": "Springer", "year": "2020", "authors": "S Gocht; R Mcbride; C Mccreesh; J Nordstr\u00f6m; P Prosser; J Trimble"}, {"ref_id": "b40", "title": "Subgraph isomorphism meets cutting planes: Solving with certified solutions", "journal": "", "year": "2020", "authors": "S Gocht; C Mccreesh; J Nordstr\u00f6m"}, {"ref_id": "b41", "title": "An auditable constraint programming solver", "journal": "", "year": "2022", "authors": "S Gocht; C Mccreesh; J Nordstr\u00f6m"}, {"ref_id": "b42", "title": "Certifying parity reasoning efficiently using pseudo-Boolean proofs", "journal": "", "year": "2021", "authors": "S Gocht; J Nordstr\u00f6m"}, {"ref_id": "b43", "title": "Verification of proofs of unsatisfiability for CNF formulas", "journal": "", "year": "2003", "authors": "E Goldberg; Y Novikov"}, {"ref_id": "b44", "title": "The intractability of resolution", "journal": "Theoretical Computer Science", "year": "1985", "authors": "A Haken"}, {"ref_id": "b45", "title": "Trimming while checking clausal proofs", "journal": "", "year": "2013", "authors": "M J H Heule; W A Hunt; N Wetzler"}, {"ref_id": "b46", "title": "Verifying refutations with extended resolution", "journal": "Springer", "year": "2013", "authors": "M J H Heule; W A Hunt; N Wetzler"}, {"ref_id": "b47", "title": "Expressing symmetry breaking in DRAT proofs", "journal": "Springer", "year": "2015", "authors": "M J H Heule; W A Hunt; N Wetzler"}, {"ref_id": "b48", "title": "Short proofs without new variables", "journal": "Springer", "year": "2017", "authors": "M J H Heule; B Kiesl; A Biere"}, {"ref_id": "b49", "title": "Efficient neighborhood evaluations for the vehicle routing problem with multiple time windows", "journal": "Transportation Science", "year": "2020", "authors": "M Hoogeboom; W Dullaert; D Lai; D Vigo"}, {"ref_id": "b50", "title": "RC2: an Efficient MaxSAT Solver", "journal": "Journal on Satisfiability, Boolean Modeling and Computation", "year": "2019", "authors": "A Ignatiev; A Morgado; J Marques-Silva"}, {"ref_id": "b51", "title": "Dominance rules in combinatorial optimization problems", "journal": "European Journal of Operational Research", "year": "2011", "authors": "A Jouglet; J Carlier"}, {"ref_id": "b52", "title": "Extended resolution simulates DRAT", "journal": "Springer", "year": "2018", "authors": "B Kiesl; A Rebola-Pardo; M J H Heule"}, {"ref_id": "b53", "title": "QMaxSAT: A Partial Max-SAT Solver", "journal": "Journal on Satisfiability, Boolean Modeling and Computation", "year": "2012", "authors": "M Koshimura; T Zhang; H Fujita; R Hasegawa"}, {"ref_id": "b54", "title": "", "journal": "", "year": "2023", "authors": "L Ko Lodziejczyk; N Thapen"}, {"ref_id": "b55", "title": "Solving graph homomorphism and subgraph isomorphism problems faster through clique neighbourhood constraints", "journal": "", "year": "2021", "authors": "S Kraiczy; C Mccreesh"}, {"ref_id": "b56", "title": "Propositional proof systems, the consistency of first order theories and the complexity of computations", "journal": "Journal of Symbolic Logic", "year": "1989", "authors": "J Kraj\u00ed\u010dek; P Pudl\u00e1k"}, {"ref_id": "b57", "title": "Efficient verified (UN)SAT certificate checking", "journal": "Journal of Automated Reasoning", "year": "2017", "authors": "P Lammich"}, {"ref_id": "b58", "title": "Certifying algorithms", "journal": "Computer Science Review", "year": "2011", "authors": "R M Mcconnell; K Mehlhorn; S N\u00e4her; P Schweitzer"}, {"ref_id": "b59", "title": "Finding maximum k-cliques faster using lazy global domination", "journal": "", "year": "2016", "authors": "C Mccreesh; P Prosser"}, {"ref_id": "b60", "title": "Composing symmetry propagation and effective symmetry breaking for SAT solving", "journal": "Springer", "year": "2019", "authors": "H Metin; S Baarir; F Kordon"}, {"ref_id": "b61", "title": "Pacose: An iterative SAT-based MaxSAT solver", "journal": "", "year": "2022", "authors": "T Paxian; B Becker"}, {"ref_id": "b62", "title": "SymChaff: Exploiting symmetry in a structure-aware satisfiability solver", "journal": "", "year": "2009", "authors": "A Sabharwal"}, {"ref_id": "b63", "title": "Symmetry and satisfiability", "journal": "", "year": "2021", "authors": "K A Sakallah"}, {"ref_id": "b64", "title": "cake lpr: Verified propagation redundancy checking in CakeML", "journal": "Springer", "year": "2021", "authors": "Y K Tan; M J H Heule; M O Myreen"}, {"ref_id": "b65", "title": "On certifying the UNSAT result of dynamic symmetry-handling-based SAT solvers", "journal": "Constraints", "year": "2020", "authors": "R K Tchinda; C T Djam\u00e9gni"}, {"ref_id": "b66", "title": "An efficient branch-and-bound algorithm for finding a maximum clique with computational experiments", "journal": "J. Glob. Optim", "year": "2007", "authors": "E Tomita; T Kameda"}, {"ref_id": "b67", "title": "On the complexity of derivation in propositional calculus", "journal": "", "year": "1968", "authors": "G Tseitin"}, {"ref_id": "b68", "title": "QMaxSATpb: A certified MaxSAT solver", "journal": "Springer", "year": "2022", "authors": "D Vandesande; W De Wulf; B Bogaerts"}, {"ref_id": "b69", "title": "General symmetry breaking constraints", "journal": "Springer", "year": "2006", "authors": "T Walsh"}, {"ref_id": "b70", "title": "Symmetry breaking constraints: Recent results", "journal": "", "year": "2012", "authors": "T Walsh"}, {"ref_id": "b71", "title": "DRAT-trim: Efficient checking and trimming using expressive clausal proofs", "journal": "Springer", "year": "2014", "authors": "N Wetzler; M J H Heule; W A Hunt"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: The Crystal Maze puzzle. Place numbers 1 to 8 in the circles, with every circle getting a different number, so that adjacent circles do not have consecutive numbers.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Time required for symmetry breaking with and without proof logging.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Time for symmetry breaking with proof logging compared to verification time for the generated symmetry breaking constraints. Points to the right of the vertical dashed line indicate timeouts (left) and out of memory (right).", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 4 :4Figure 4: Time for symmetry breaking plus SAT solving (with proof logging) compared to verification time for the whole solving process. Points to the right of the vertical dashed line indicate timeouts (left) and out of memory (right).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "u3 u4 u5 u6 u7 u8 u9 u10 u11 u12 L6 right v1 v2 v3 v4 v5 v6 v7 v8 v9 v10 v11 v12", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "\u2212u 12 + v 12 \u2212 2u 11 + 2v 11 \u2212 4u 10 + 4v 10 \u2212 . . . \u2265 0 (T1) \u2212v 12 + w 12 \u2212 2v 11 + 2w 11 \u2212 4v 10 + 4w 10 \u2212 . . . \u2265 0 (T2) u 12 \u2212 w 12 + 2u 11 \u2212 2w 11 + 4u 10 \u2212 4w 10 + . . . \u2265 \u22121,", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Let us describe how the subproof for the second proof obligation on Lines 27-29 is checked by VeriPB . First, VeriPB makes available in the subproof the constraint \u00acC, which (after simplification) equals 255 \u2022 p 11 + 126 \u2022 p 12 + 60 \u2022 p 13 + 1536 \u2022 p 21 + 1536 \u2022 p 23 +24 \u2022 p 31 + 24 \u2022 p 33 + 60 \u2022 p 41 + 126 \u2022 p 42 + 255 \u2022 p 43 \u2265 2002 , (C23) giving this constraint the next available number 23 as constraint reference ID. Next, VeriPB makes available the constraint O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ), which, after simplification, equals 255 \u2022 p 11 + 126 \u2022 p 12 + 60 \u2022 p 13 + 1536 \u2022 p 21 + 1536 \u2022 p 23 +24 \u2022 p 31 + 24 \u2022 p 33 + 60 \u2022 p 41 + 126 \u2022 p 42 + 255 \u2022 p 43 \u2265 2001 .(C24)As explained above, all constraints are referred to by numbers, but as we have already seen VeriPB also allows relative indexing. Therefore, Line 28 simply states in reverse polish notation that the two most recently generated constraints (i.e.Line 29 ends the proof by giving the (relative) identifier of the contradicting constraint that was just derived. Finally, when this proof is finished and all other proof obligation have been automatically checked, the desired symmetry breaking constraint\u2212p 43 + 1 \u2022 p 11 \u2212 2 \u2022 p 42 + 2 \u2022 p12 \u2212 4 \u2022 p 41 + 4 \u2022 p 13 \u2212 8 \u2022 p 33 + 8 \u2022 p 31 \u221232 \u2022 p 31 + 32 \u2022 p 33 \u2212 64 \u2022 p 13 + 64 \u2022 p 41 \u2212 128 \u2022 p 12 + 128 \u2022 p 42 \u2212256 \u2022 p 11 + 256 \u2022 p 43 \u2212 512 \u2022 p 23 + 512 \u2022 p 21 \u2212 2048 \u2022 p 21 + 2048 \u2022 p 23 \u2265 0", "figure_data": ", (C24) and (C23)) should beadded, which yields the inequality255 + 126 + 60 + 1536 + 1536 + 24 + 24 + 60 + 126 + 255 \u2265 2002 + 2001(34)or, in simplified form,0 \u2265 1 ,(C25)which is contradictory. (C26)"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "y 1 + p 23 + p 21 \u2265 1 (C32) corresponding to the clauses (19c)-(19f). Before repeating this procedure for the next variable y 2 , we use the recently derived constraints to cancel out the dominant terms in constraint (C26) with the instructions L36 pol 26 32 2048 * + L37 del id 26 The first line above adds 2048 times (C32) to (C26), yielding 255 \u2022 p 11 + 126 \u2022 p 12 + 60 \u2022 p 13 + 512 \u2022 p 21 + 512 \u2022 p 23 +24 \u2022 p 31 + 24 \u2022 p 33 + 60 \u2022 p 41 + 126 \u2022 p 42 + 255 \u2022 p 43 + 2048 \u2022 y 1 \u2265 977 .", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "L43 pol 33 38 512 * + L44 del id 33 where the first instruction again cancels out the dominant terms in (C33), replacing them by a y-variable, to express a conditional symmetry breaking constraint, resulting in 255 \u2022 p 11 + 126 \u2022 p 12 + 60 \u2022 p 13 + 24 \u2022 p 31 + 24 \u2022 p 33 +60 \u2022 p 41 + 126 \u2022 p 42 + 255 \u2022 p 43 + 2048 \u2022 y 1 + 512 \u2022 y 2 \u2265 465 (C39)", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "11 + p 43 + y 3 \u2265 1 (C44) to the derived set D. The last constraint can then again be used to simplify (C39) with the instruction L46 pol 39 44 256 * + yielding the constraint p 11 + 126 \u2022 p 12 + 60 \u2022 p 13 + 24 \u2022 p 31 + 24 \u2022 p 33 + 60 \u2022 p 41 +126 \u2022 p 42 + p 43 + 2048 \u2022 y 1 + 512 \u2022 y 2 + 256 \u2022 y 3 \u2265 211 (C45)", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "(p 11 p 12 )(p 21 p 32 )(p 22 p 31 )(p 23 p 33 )(p 41 p 42 ) (37a) (p 21 p 11 )(p 22 p 12 )(p 23 p 13 ) (37b) (p 11 p 31 )(p 12 p 32 )(p 13 p 33 ) (37c) (p 31 p 41 )(p 32 p 42 )(p 33 p 43 ) (37d) (p 21 p 22 )(p 11 p 12 )(p 31 p 32 )(p 41 p 42 ) (37e) (p 22 p 23 )(p 12 p 13 )(p 32 p 33 )(p 42 p 43 ) (37f)", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "C . = i a i \u2113 i \u2265 A ,(1)", "formula_coordinates": [4.0, 262.85, 520.56, 259.15, 18.41]}, {"formula_id": "formula_1", "formula_text": "\u00acC . = i \u2212 a i \u2113 i \u2265 \u2212A + 1 .(2)", "formula_coordinates": [4.0, 238.91, 658.41, 283.09, 18.41]}, {"formula_id": "formula_2", "formula_text": "\u03c9 = {x 1 \u2192 0, x 3 \u2192 x 4 , x 4 \u2192 x 3 } and \u03c1 = {x 1 \u2192 1, x 2 \u2192 1, x 3 \u2192 0, x 4 \u2192 0} we have \u03c1 \u2022 \u03c9 = {x 1 \u2192 0, x 2 \u2192 1, x 3 \u2192 1, x 4 \u2192 0}.", "formula_coordinates": [5.0, 90.0, 312.99, 432.0, 24.18]}, {"formula_id": "formula_3", "formula_text": "C\u21be \u03c9 . = i a i \u03c9(\u2113 i ) \u2265 A ,(3)", "formula_coordinates": [5.0, 250.02, 361.15, 271.98, 18.41]}, {"formula_id": "formula_4", "formula_text": "x i ) = \u03b1(z i ) and \u03c9(y i ) = \u03b2(z i ) for i = 1, . . . , n. The (normalized) constraint C in (1) is satisfied by \u03c1 if \u03c1(\u2113 i )=1 a i \u2265 A. A pseudo- Boolean formula F is satisfied by \u03c1 if all constraints in it are, in which case it is satisfiable.", "formula_coordinates": [5.0, 90.0, 517.44, 432.0, 51.13]}, {"formula_id": "formula_5", "formula_text": "F |= F \u2032 if F |= C \u2032 for all C \u2032 \u2208 F \u2032 .", "formula_coordinates": [6.0, 90.0, 148.03, 163.45, 11.52]}, {"formula_id": "formula_7", "formula_text": "Definition 1. A configuration (C , D, O \u2aaf , \u20d7 z, v) is weakly (F, f )-valid if the following con- ditions hold: 1. For every v \u2032 < v, it holds that if F \u222a {f \u2264 v \u2032 } is satisfiable, then C \u222a {f \u2264 v \u2032 } is satisfiable. 2. For every total assignment \u03c1 satisfying the constraints C \u222a {f \u2264 v \u2212 1}, there exists a total assignment \u03c1 \u2032 \u2aaf f \u03c1 satisfying C \u222a D \u222a {f \u2264 v \u2212 1},", "formula_coordinates": [7.0, 90.0, 573.82, 432.01, 96.44]}, {"formula_id": "formula_8", "formula_text": "3. If v < \u221e, then F \u222a {f \u2264 v} is satisfiable. 4. For every v \u2032 < v, it holds that if C \u222a {f \u2264 v \u2032 } is satisfiable, then F \u222a {f \u2264 v \u2032 } is satisfiable.", "formula_coordinates": [8.0, 102.9, 94.37, 419.1, 45.44]}, {"formula_id": "formula_9", "formula_text": "C , D, O \u2aaf , \u20d7 z, v * ) is such that C \u222a D contains contradiction \u22a5 . = 0 \u2265 1.", "formula_coordinates": [8.0, 90.0, 285.83, 430.98, 25.07]}, {"formula_id": "formula_10", "formula_text": "figuration (C , D, O \u2aaf , \u20d7 z, v * ) is (F, f )-valid and is such that C \u222a D contains 0 \u2265 1, then \u2022 F is unsatisfiable if and only if v * = \u221e; and", "formula_coordinates": [8.0, 90.0, 559.3, 409.12, 34.17]}, {"formula_id": "formula_11", "formula_text": "). If C \u222a D \u222a {f \u2264 v \u2212 1} \u22a2 C, then we can transition from the configuration (C , D, O \u2aaf , \u20d7 z, v) to the configuration (C , D \u222a {C}, O \u2aaf , \u20d7 z, v)", "formula_coordinates": [9.0, 90.0, 315.45, 432.0, 24.37]}, {"formula_id": "formula_12", "formula_text": "C \u222a D \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 (C \u222a D \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) ,(5)", "formula_coordinates": [10.0, 131.86, 394.87, 390.14, 12.41]}, {"formula_id": "formula_13", "formula_text": "Proposition 7. If we can transition from (C , D, O \u2aaf , \u20d7 z, v) to (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) by the redundance-based strengthening rule and (C , D, O \u2aaf , \u20d7 z, v) is [weakly] (F, f )-valid, then (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) is also [weakly] (F, f )-valid. Proof. First assume (C , D, O \u2aaf , \u20d7 z, v) is weakly (F, f )-valid. Item 1 in Definition 1 remains satisfied for (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) since F , v, and C are unchanged.", "formula_coordinates": [10.0, 90.0, 576.28, 432.0, 75.25]}, {"formula_id": "formula_14", "formula_text": "(C \u222a D \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) .(6)", "formula_coordinates": [11.0, 207.3, 186.89, 314.7, 12.41]}, {"formula_id": "formula_15", "formula_text": "(C , D, O \u2aaf , \u20d7 z, v) to (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) by the deletion rule if 1. D \u2032 \u2286 D and 2. C \u2032 = C or C \u2032 = C \\ {C} for some constraint C derivable via the redundance rule from (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v).", "formula_coordinates": [11.0, 90.0, 429.58, 432.0, 85.62]}, {"formula_id": "formula_16", "formula_text": "Proposition 9. If we can transition from (C , D, O \u2aaf , \u20d7 z, v) to (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) by the deletion rule and (C , D, O \u2aaf , \u20d7 z, v) is [weakly] (F, f )-valid, then (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) is also [weakly] (F, f )- valid. Proof. First assume that (C , D, O \u2aaf , \u20d7 z, v) is weakly (F, f )-valid. Item 1 in Definition 1 clearly remains satisfied for (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) since C \u2032 \u2286 C .", "formula_coordinates": [11.0, 90.0, 616.29, 432.0, 76.2]}, {"formula_id": "formula_17", "formula_text": "C \u2032 \u222a{f \u2264 v \u22121}. If C \u2032 = C , we find an \u03b1 \u2032 \u2aaf f \u03b1 that satisfies C \u2032 \u222a D \u2032 \u222a {f \u2264 v \u2212 1} using weak (F, f )-validity of the configuration (C , D, O \u2aaf , \u20d7 z, v", "formula_coordinates": [11.0, 392.1, 693.46, 129.9, 12.13]}, {"formula_id": "formula_18", "formula_text": "C \u2032 \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 (C \u2032 \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z)(7)", "formula_coordinates": [12.0, 153.08, 168.83, 368.92, 14.72]}, {"formula_id": "formula_19", "formula_text": "\u03b1 \u2032\u2032 = \u03b1 \u2022 \u03c9 satisfying C = C \u2032 \u222a {C} such that f\u21be \u03b1 \u2032\u2032 \u2264 f\u21be \u03b1 \u2264 v \u2212 1, which shows that C \u222a {f \u2264 v \u2212 1} is satisfiable.", "formula_coordinates": [12.0, 90.0, 192.14, 432.0, 27.12]}, {"formula_id": "formula_20", "formula_text": "\u03b1 \u2032 \u2264 v \u2212 1 that satisfies C \u222a D \u222a {f \u2264 v \u2212 1}.", "formula_coordinates": [12.0, 223.01, 234.55, 233.32, 11.8]}, {"formula_id": "formula_21", "formula_text": "C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) after deletion. Now assume that (C , D, O \u2aaf , \u20d7 z, v) is (F, f )-valid. Item 3 clearly remains satisfied for (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v) since v is unchanged. We show that item 4 holds for (C \u2032 , D \u2032 , O \u2aaf , \u20d7 z, v);", "formula_coordinates": [12.0, 90.0, 246.33, 432.0, 53.23]}, {"formula_id": "formula_22", "formula_text": "C \u2032 \u222a {f \u2264 v \u2032 } for some v \u2032 < v, we use \u03b1 to construct a satisfying assignment \u03b1 \u2032 for F \u222a {f \u2264 v \u2032 }. If C \u2032 = C , we get \u03b1 \u2032 from the (F, f )-validity of (C , D, O \u2aaf , \u20d7 z, v), so assume C \u2032 = C \\ {C}.", "formula_coordinates": [12.0, 90.0, 314.08, 432.0, 39.23]}, {"formula_id": "formula_23", "formula_text": "satisfy C. Since C is derivable via redundance from (C \u2032 , \u2205, O \u2aaf , \u20d7 z, v), it holds that C \u2032 \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 (C \u2032 \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) .(8)", "formula_coordinates": [12.0, 90.0, 368.28, 432.0, 36.93]}, {"formula_id": "formula_24", "formula_text": "\u03b1 \u2032\u2032 \u2264 f\u21be \u03b1 \u2264 v \u2032 , showing that C \u222a {f \u2264 v \u2032 } is satisfiable.", "formula_coordinates": [12.0, 163.86, 427.35, 285.89, 13.57]}, {"formula_id": "formula_25", "formula_text": "Proposition 11. If (C , D, O \u2aaf , \u20d7 z, v", "formula_coordinates": [13.0, 90.0, 142.91, 166.11, 10.82]}, {"formula_id": "formula_26", "formula_text": "(C , D, O \u2aaf , \u20d7 z, v) to (C \u2032 , D, O \u2aaf , \u20d7 z, v) by the transfer rule if C \u2286 C \u2032 \u2286 C \u222a D.", "formula_coordinates": [13.0, 90.0, 299.4, 432.0, 25.68]}, {"formula_id": "formula_27", "formula_text": "x + y \u2265 1. The required redundance check {x \u2265 1, \u00ac(x + y \u2265 1)} \u22a2 \u22a5 is immediate.", "formula_coordinates": [13.0, 90.0, 377.17, 432.0, 23.12]}, {"formula_id": "formula_28", "formula_text": "C \u222a D \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 C \u21be \u03c9 \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) \u222a \u00acO \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u222a {f\u21be \u03c9 \u2264 f } ,(9)", "formula_coordinates": [14.0, 123.48, 186.78, 398.52, 11.8]}, {"formula_id": "formula_29", "formula_text": "C \u222a D \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u22a2 C \u21be \u03c9 \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) \u222a {f\u21be \u03c9 \u2264 f } (10a) C \u222a D \u222a {f \u2264 v \u2212 1} \u222a {\u00acC} \u222a O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u22a2 \u22a5 (10b)", "formula_coordinates": [14.0, 159.67, 354.1, 362.33, 28.34]}, {"formula_id": "formula_30", "formula_text": "(C , D, O \u2aaf , \u20d7 z, v) to (C , D \u222a {C}, O \u2aaf , \u20d7 z, v", "formula_coordinates": [14.0, 297.14, 395.4, 190.13, 10.82]}, {"formula_id": "formula_31", "formula_text": "Proposition 14. If we can transition from (C , D, O \u2aaf , \u20d7 z, v) to (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) by the dominance-based strengthening rule and (C , D, O \u2aaf , \u20d7 z, v) is [weakly] (F, f )-valid, then (C , D \u222a {C}, O \u2aaf , \u20d7 z, v) is also [weakly] (F, f )-valid.", "formula_coordinates": [14.0, 90.0, 481.76, 432.0, 37.92]}, {"formula_id": "formula_32", "formula_text": "(1) satisfy C \u222a {f \u2264 v \u2212 1} and (2) admit no \u03b1 \u2032 \u2aaf f \u03b1 satisfying C \u222a D \u222a {C}.", "formula_coordinates": [14.0, 90.0, 595.23, 220.47, 33.82]}, {"formula_id": "formula_33", "formula_text": "\u03b1 1 \u0338 \u2aaf f \u03b1 1 \u2022 \u03c9. Now let \u03b1 2 be \u03b1 1 \u2022 \u03c9. We showed that \u03b1 2 \u227a f \u03b1 1 \u2aaf f \u03b1. Furthermore, since \u03b1 1 satisfies C \u222a D \u222a {\u00acC}, (10a) yields that \u03b1 2 satisfies C . Thus \u03b1 2 satisfies C \u222a {f \u2264 v \u2212 1}.", "formula_coordinates": [15.0, 90.0, 121.47, 432.0, 24.18]}, {"formula_id": "formula_34", "formula_text": "(C 1 = {p \u2265 1}, D 1 = {p \u2265 1}, O \u2aaf , {p}, \u221e) ,(11)", "formula_coordinates": [15.0, 205.59, 276.0, 316.41, 10.82]}, {"formula_id": "formula_35", "formula_text": "\u2205 \u222a {p \u2265 1} \u222a {p \u2265 1} \u22a2 \u2205 \u222a {p + 1 \u2265 1} \u222a \u2205 (12a) \u2205 \u222a {p \u2265 1} \u222a {p \u2265 1} \u222a {0 + p \u2265 1} \u22a2 \u22a5 (12b)", "formula_coordinates": [15.0, 203.22, 369.73, 318.78, 26.11]}, {"formula_id": "formula_36", "formula_text": "(C , D, O \u22a4 , \u20d7 z, v) to any configura- tion (C \u2032 , D, O \u22a4 , \u20d7 z, v) whenever C \u2032 \u2286 C .", "formula_coordinates": [15.0, 90.0, 532.63, 432.0, 24.51]}, {"formula_id": "formula_37", "formula_text": "\u2205 \u22a2 O \u2aaf (\u20d7 u, \u20d7 u) (13a) O \u2aaf (\u20d7 u, \u20d7 v) \u222a O \u2aaf (\u20d7 v, \u20d7 w) \u22a2 O \u2aaf (\u20d7 u, \u20d7 w) (13b)", "formula_coordinates": [16.0, 232.96, 186.62, 289.04, 27.36]}, {"formula_id": "formula_38", "formula_text": "u 1 u 2 . . . u n \u2aaf lex v 1 v 2 . . . v n , we can use a single constraint O \u2aaf lex (\u20d7 u, \u20d7 v) . = n i=1 2 n\u2212i \u2022 (v i \u2212 u i ) \u2265 0 . (14", "formula_coordinates": [16.0, 90.0, 276.47, 432.0, 44.7]}, {"formula_id": "formula_39", "formula_text": ")", "formula_coordinates": [16.0, 517.15, 308.95, 4.85, 9.57]}, {"formula_id": "formula_40", "formula_text": "O \u2aaf lex (\u20d7 u, \u20d7 v) and O \u2aaf lex (\u20d7 v, \u20d7 w) yields O \u2aaf lex (\u20d7 u, \u20d7 w) (", "formula_coordinates": [16.0, 151.45, 341.25, 215.92, 11.84]}, {"formula_id": "formula_41", "formula_text": "(C , \u2205, O \u2aaf 1 , \u20d7 z 1 , v) to the configuration (C , \u2205, O \u2aaf 2 , \u20d7 z 2 , v", "formula_coordinates": [16.0, 90.0, 663.81, 247.15, 11.55]}, {"formula_id": "formula_42", "formula_text": "F \u222a {f \u2264 v * \u2212 1}.", "formula_coordinates": [17.0, 154.0, 342.17, 84.85, 11.52]}, {"formula_id": "formula_43", "formula_text": "\u2aaf f as \u03b1 \u2aaf f \u03b2 if \u03b1 \u2aaf \u03b2 and f\u21be \u03b1 \u2264 f\u21be \u03b2 ,(15)", "formula_coordinates": [17.0, 222.5, 371.32, 299.5, 36.44]}, {"formula_id": "formula_44", "formula_text": "\u03b1 \u2aaf \u2032 f \u03b2 if f\u21be \u03b1 \u2264 f\u21be \u03b2 and if f\u21be \u03b1 = f\u21be \u03b2 then also \u03b1 \u2aaf \u03b2 . (16", "formula_coordinates": [17.0, 168.8, 443.3, 348.36, 14.27]}, {"formula_id": "formula_45", "formula_text": ")", "formula_coordinates": [17.0, 517.15, 445.79, 4.85, 9.57]}, {"formula_id": "formula_46", "formula_text": "C \u222a D \u222a {\u00acC} \u22a2 (C \u222a D \u222a C)\u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } and (17a) C \u222a D \u222a {\u00acC} \u222a {f\u21be \u03c9 = f } \u22a2 O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) (17b)", "formula_coordinates": [17.0, 188.1, 537.7, 333.9, 28.34]}, {"formula_id": "formula_47", "formula_text": "C \u222a D \u222a {\u00acC} \u22a2 C \u21be \u03c9 \u222a {f\u21be \u03c9 \u2264 f } , (18a) C \u222a D \u222a {\u00acC} \u222a {f\u21be \u03c9 = f } \u22a2 O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) , and (18b) C \u222a D \u222a {\u00acC} \u222a {f\u21be \u03c9 = f } \u222a O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u22a2 \u22a5 (18c)", "formula_coordinates": [17.0, 196.53, 658.08, 325.47, 44.88]}, {"formula_id": "formula_48", "formula_text": "y 0 \u2265 1 (19a) y j\u22121 + x i j + \u03c3(x i j ) \u2265 1 1 \u2264 j \u2264 n (19b", "formula_coordinates": [19.0, 182.01, 185.39, 339.98, 28.15]}, {"formula_id": "formula_49", "formula_text": ")", "formula_coordinates": [19.0, 516.91, 201.92, 5.09, 9.57]}, {"formula_id": "formula_50", "formula_text": "y j + y j\u22121 \u2265 1 1 \u2264 j < n (19c", "formula_coordinates": [19.0, 182.01, 219.56, 335.14, 11.62]}, {"formula_id": "formula_51", "formula_text": ")", "formula_coordinates": [19.0, 517.15, 219.56, 4.85, 9.57]}, {"formula_id": "formula_52", "formula_text": "y j + \u03c3(x i j ) + x i j \u2265 1 1 \u2264 j < n (19d", "formula_coordinates": [19.0, 182.01, 238.08, 334.9, 11.62]}, {"formula_id": "formula_53", "formula_text": ")", "formula_coordinates": [19.0, 516.91, 238.08, 5.09, 9.57]}, {"formula_id": "formula_54", "formula_text": "y j + y j\u22121 + x i j \u2265 1 1 \u2264 j < n (19e", "formula_coordinates": [19.0, 182.01, 255.72, 335.14, 11.62]}, {"formula_id": "formula_55", "formula_text": ")", "formula_coordinates": [19.0, 517.15, 255.72, 4.85, 9.57]}, {"formula_id": "formula_56", "formula_text": "y j + y j\u22121 + \u03c3(x i j ) \u2265 1 1 \u2264 j < n (19f)", "formula_coordinates": [19.0, 182.01, 273.36, 339.99, 11.62]}, {"formula_id": "formula_57", "formula_text": "C LL . = m i=1 2 m\u2212i \u2022 (\u03c3(x i ) \u2212 x i ) \u2265 0 (20", "formula_coordinates": [19.0, 220.16, 439.48, 296.99, 18.41]}, {"formula_id": "formula_58", "formula_text": ")", "formula_coordinates": [19.0, 517.15, 445.67, 4.85, 9.57]}, {"formula_id": "formula_59", "formula_text": "O \u2aaf (\u20d7 x, \u20d7 x\u21be \u03c3 )", "formula_coordinates": [19.0, 90.0, 559.92, 51.14, 11.62]}, {"formula_id": "formula_60", "formula_text": "x i ) \u2212 x i disappears since \u03c3(x i ) = x i . This means that the constraint C LL simplifies to n j=1 2 m\u2212i j \u2022 (\u03c3(x i j ) \u2212 x i j ) \u2265 0 ,(21)", "formula_coordinates": [20.0, 90.0, 162.12, 432.0, 39.32]}, {"formula_id": "formula_61", "formula_text": "C LL (0) . = C LL (22a) C LL (k) . = C LL (k \u2212 1) + 2 m\u2212i k \u2022 (19d [j = k])(22b)", "formula_coordinates": [20.0, 200.33, 281.05, 321.68, 34.69]}, {"formula_id": "formula_62", "formula_text": "(19d [j = k]) denotes substitution of j by k in (19d). Simplifying C LL (k) yields k j=1 2 m\u2212i j \u2022 y j + n j=k+1 2 m\u2212i j \u2022 (\u03c3(x i j ) \u2212 x i j ) \u2265 0 ,(23)", "formula_coordinates": [20.0, 121.54, 329.1, 400.46, 36.26]}, {"formula_id": "formula_64", "formula_text": "N(u) \\ {v} \u2287 N(v) \\ {u} (25)", "formula_coordinates": [27.0, 247.84, 440.93, 274.16, 9.57]}, {"formula_id": "formula_65", "formula_text": "min v\u2208V v (26a) v + w \u2265 1 [for all (v, w) \u2208 V 2 \\ E with v \u0338 = w] (26b)", "formula_coordinates": [27.0, 158.71, 575.68, 363.29, 27.26]}, {"formula_id": "formula_66", "formula_text": "1 MaxCliqueSearch(G, V rem , C curr , C best ) : 2 E rem \u2190 E(G) \u2229 (V rem \u00d7 V rem ); 3 G rem \u2190 (V rem , E rem ); 4 if |C curr | > |C best | then 5 C best \u2190 C curr ; 6 (S 1 , . . . , S m ) \u2190 colour classes in colouring of G rem ; 7 j \u2190 m; 8 while j \u2265 1 and |C curr | + j > |C best | do 9 for v \u2208 S j do 10 C best \u2190 MaxCliqueSearch(G, V rem \u2229 N(v), C curr \u222a {v}, C best ); 11 V rem \u2190 V rem \\ S j ; 12 j \u2190 j \u2212 1; 13 return C best ;", "formula_coordinates": [28.0, 91.72, 113.03, 334.4, 185.95]}, {"formula_id": "formula_67", "formula_text": "u + v \u2265 1 ,(27)", "formula_coordinates": [30.0, 280.95, 194.97, 241.05, 9.57]}, {"formula_id": "formula_68", "formula_text": "C \u222a D \u222a {\u00ac(u + v \u2265 1)} (28a)", "formula_coordinates": [30.0, 248.63, 360.11, 273.37, 10.36]}, {"formula_id": "formula_69", "formula_text": "(C \u222a D \u222a {u + v \u2265 1})\u21be \u03c9 (28b)", "formula_coordinates": [30.0, 247.27, 407.59, 274.73, 12.41]}, {"formula_id": "formula_70", "formula_text": "\u00ac(u + v \u2265 1) . = u + v \u2265 2 in (28a) we immediately obtain u \u2265 1 (29a) v \u2265 1 (29b)", "formula_coordinates": [30.0, 141.3, 452.43, 380.7, 56.03]}, {"formula_id": "formula_71", "formula_text": "(x + u \u2265 1)\u21be \u03c9 . = x + v \u2265 1", "formula_coordinates": [31.0, 234.44, 264.5, 124.92, 18.41]}, {"formula_id": "formula_72", "formula_text": "|C curr | + j > |C best | must hold.", "formula_coordinates": [32.0, 167.88, 568.25, 146.41, 10.77]}, {"formula_id": "formula_73", "formula_text": "C \u222a D \u222a {\u00ac(u + v \u2265 1)} (31a)", "formula_coordinates": [33.0, 248.63, 244.64, 273.37, 10.36]}, {"formula_id": "formula_74", "formula_text": "C \u21be \u03c9 \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) \u222a {f\u21be \u03c9 \u2264 f } . (31b", "formula_coordinates": [33.0, 232.68, 291.01, 284.23, 11.8]}, {"formula_id": "formula_75", "formula_text": ")", "formula_coordinates": [33.0, 516.91, 291.2, 5.09, 9.57]}, {"formula_id": "formula_76", "formula_text": "p", "formula_coordinates": [37.0, 260.98, 221.24, 5.49, 9.57]}, {"formula_id": "formula_77", "formula_text": "p 23 + p 43 \u2265 1 (C21) p 33 + p 43 \u2265 1 (C22)", "formula_coordinates": [37.0, 288.77, 552.0, 233.23, 28.15]}, {"formula_id": "formula_78", "formula_text": "L1 pseudo -Boolean proof version 2.0 L2 f 22", "formula_coordinates": [38.0, 93.11, 152.74, 199.54, 18.43]}, {"formula_id": "formula_79", "formula_text": "L17 end L18 proof L19 proofgoal #1 L20 pol 1 2 + 3 + L21 qed -1 L22 qed L23 end L24 end", "formula_coordinates": [38.0, 88.88, 456.44, 141.88, 84.18]}, {"formula_id": "formula_82", "formula_text": "L27 proofgoal #2 L28 pol -1 -2 + L29", "formula_coordinates": [40.0, 88.88, 253.48, 107.98, 28.94]}, {"formula_id": "formula_83", "formula_text": "C \u222a D \u222a {\u00acC} \u22a2 C \u21be \u03c9 \u222a O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) \u222a {f\u21be \u03c9 \u2264 f } (33a) C \u222a D \u222a {\u00acC} \u222a O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u22a2 \u22a5 (33b)", "formula_coordinates": [40.0, 193.95, 580.7, 328.05, 28.34]}, {"formula_id": "formula_84", "formula_text": "1. C \u222a D \u222a {\u00acC} \u22a2 O \u2aaf (\u20d7 z\u21be \u03c9 , \u20d7 z) 2. C \u222a D \u222a {\u00acC} \u222a O \u2aaf (\u20d7 z, \u20d7 z\u21be \u03c9 ) \u22a2 \u22a5 3. C \u222a D \u222a {\u00acC} \u22a2 f\u21be \u03c9 \u2264 f 4-25. C \u222a D \u222a {\u00acC} \u22a2 D for each D \u2208 C \u21be \u03c9 .", "formula_coordinates": [40.0, 103.33, 672.22, 165.01, 34.81]}, {"formula_id": "formula_85", "formula_text": "p 21 \u2228 \u03c0(p 21 ) . = p 21 \u2228 p 23 ,(35)", "formula_coordinates": [42.0, 245.91, 200.01, 276.09, 17.8]}, {"formula_id": "formula_86", "formula_text": "L31 rup 1 \u223cp21 1 p23 >= 1 ;", "formula_coordinates": [42.0, 88.88, 302.83, 153.17, 8.11]}, {"formula_id": "formula_87", "formula_text": "p 21 + p 23 \u2265 1 .(C28)", "formula_coordinates": [42.0, 272.45, 349.71, 249.55, 11.62]}, {"formula_id": "formula_88", "formula_text": "p 23 + y 0 + y 1 \u2265 1 (C29", "formula_coordinates": [42.0, 267.35, 476.36, 249.19, 11.62]}, {"formula_id": "formula_89", "formula_text": ")", "formula_coordinates": [42.0, 516.54, 476.36, 5.45, 9.57]}, {"formula_id": "formula_90", "formula_text": "p 21 + y 0 + y 1 \u2265 1 (C30) y 1 + y 0 \u2265 1 (C31)", "formula_coordinates": [42.0, 267.35, 492.9, 254.65, 28.15]}, {"formula_id": "formula_92", "formula_text": "y 1 + p 23 + p 21 \u2265 1 (C34)", "formula_coordinates": [43.0, 262.98, 148.57, 259.02, 11.62]}, {"formula_id": "formula_93", "formula_text": "p 21 + y 1 + y 2 \u2265 1 (C35", "formula_coordinates": [43.0, 267.35, 326.49, 249.19, 11.62]}, {"formula_id": "formula_94", "formula_text": ")", "formula_coordinates": [43.0, 516.54, 326.49, 5.45, 9.57]}, {"formula_id": "formula_95", "formula_text": "p 23 + y 1 + y 2 \u2265 1 (C36) y 1 + y 2 \u2265 1 (C37", "formula_coordinates": [43.0, 267.35, 343.03, 254.65, 28.15]}, {"formula_id": "formula_96", "formula_text": ")", "formula_coordinates": [43.0, 516.54, 359.57, 5.45, 9.57]}, {"formula_id": "formula_97", "formula_text": "p 21 + p 23 + y 2 \u2265 1 (C38)", "formula_coordinates": [43.0, 262.98, 376.1, 259.02, 11.62]}, {"formula_id": "formula_98", "formula_text": "p 11 + p 43 + y 2 \u2265 1 ,(C40)", "formula_coordinates": [43.0, 260.55, 577.4, 261.45, 11.62]}, {"formula_id": "formula_99", "formula_text": "L45 rup 1 \u223cy2 1 \u223cp11 1 p43 >= 1 ;", "formula_coordinates": [43.0, 88.88, 622.89, 187.07, 8.12]}, {"formula_id": "formula_101", "formula_text": "p 11 + y 2 + y 3 \u2265 1 (C42) y 2 + y 3 \u2265 1 (C43", "formula_coordinates": [44.0, 267.35, 159.41, 254.65, 28.15]}, {"formula_id": "formula_102", "formula_text": ")", "formula_coordinates": [44.0, 516.54, 175.95, 5.45, 9.57]}, {"formula_id": "formula_103", "formula_text": "p", "formula_coordinates": [44.0, 262.98, 192.48, 5.49, 9.57]}], "doi": "10.5281/zenodo.6373986"}