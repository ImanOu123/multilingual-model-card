{"title": "Solving MultiClass Support Vector Machines with LaRank", "authors": "Antoine Bordes; Patrick Gallinari; Jason Weston", "pub_date": "", "abstract": "Optimization algorithms for large margin multiclass recognizers are often too costly to handle ambitious problems with structured outputs and exponential numbers of classes. Optimization algorithms that rely on the full gradient are not effective because, unlike the solution, the gradient is not sparse and is very large. The LaRank algorithm sidesteps this difficulty by relying on a randomized exploration inspired by the perceptron algorithm. We show that this approach is competitive with gradient based optimizers on simple multiclass problems. Furthermore, a single LaRank pass over the training examples delivers test error rates that are nearly as good as those of the final solution.", "sections": [{"heading": "Introduction", "text": "Much has been written about the recognition of multiple classes using large margin kernel machines such as support vector machines (SVMs). The most widely used approaches combine multiple binary classifiers separately trained using either the one-versus-all or one-versus-one scheme (e.g. Hsu & Lin, 2002). Alternative proposals (Weston & Watkins, 1998;Crammer & Singer, 2001) reformulate the large margin problem to directly address the multiclass problem. These algorithms are more expensive because they must simultaneously handle all the support vectors associated with different inter-class boundaries. Rigorous experiments (Hsu & Lin, 2002;Rifkin & Klautau, 2004) suggest that this higher cost does not translate into higher generalization performance.\nThe picture changes when one considers learning systems that predict structured outputs (e.g. Bak\u0131r et al., 2007). Instead of predicting a class label y for each pattern x, structured output systems produce complex discrete outputs such as a sequences, trees, or graphs. Since these potential outputs can be enumerated (in theory), these systems can be viewed as multiclass problems with a number of classes growing exponentially with the characteristic size of the output. Dealing with so many classes in a large margin classifier would be infeasible without smart factorizations that leverage the specific structure of the outputs (Taskar et al., 2005;Tsochantaridis et al., 2005). This is best achieved using a direct multiclass formulation because the factorization of the output space implies that all the classes are handled simultaneously. It is therefore important to reduce the computational cost of multiclass SVMs with a potentially large number of classes.\nMCSVM Crammer and Singer (2001) propose a multiclass formulation that we call partial ranking. The dual cost is a function of a n \u00d7 k matrix of Lagrange coefficients where n is the number of examples and k the number of classes. Each iteration of the MCSVM algorithm maximizes the restriction of the dual cost to a single row of the coefficient matrix. Successive rows are selected using the gradient of the cost function. Unlike the coefficients matrix, the gradient is not sparse. This approach is not feasible when the number of classes k grows exponentially, because the gradient becomes too large.\nSVMstruct Tsochantaridis et al. (2005) essentially use the same partial ranking formulation for the SVMstruct system. The clever cutting plane algorithm ensures convergence but only requires to store and compute a small part of the gradient. This crucial difference makes SVMstruct suitable for structured output problems with a large number of classes.\nKernel Perceptrons Online algorithms inspired by the perceptron (Collins, 2002;Crammer & Singer, 2003) can be interpreted as the successive solution of optimization subproblems restricted to coefficients associated with the current training example. There is no need to represent the gradient. The random ordering of the training examples drives the successive optimizations. Perceptrons provide surprisingly strong theoretical guarantees (Graepel et al., 2000). They run very quickly but provide inferior generalization performances in practice.\nLaRank This paper proposes LaRank, a stochastic learning algorithm that combines partial gradient information with the randomization arising from the sequence of training examples.\n\u2022 LaRank uses gradients as sparingly as SVMstruct and yet runs considerably faster. In fact, LaRank reaches an equivalent accuracy faster than algorithms that use the full gradient information.\n\u2022 LaRank generalizes better than perceptron-based algorithms. In fact, LaRank provides the performance of SVMstruct or MCSVM because it solves the same optimization problem.\n\u2022 LaRank achieves nearly optimal test error rates after a single pass over the randomly reordered training set. Therefore, LaRank offers the practicality of an online algorithm.\nThis paper first reviews and discusses the multiclass formulation of Crammer and Singer. Then it presents the LaRank algorithm, discusses its convergence, and reports experimental results on well known multiclass problems.", "publication_ref": ["b10", "b18", "b4", "b10", "b13", "b0", "b16", "b17", "b4", "b17", "b3", "b5", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "Multiclass Support Vector Machines", "text": "This section describes the partial ranking formulation of multiclass SVMs (Crammer & Singer, 2001). The presentation first follows (Tsochantaridis et al., 2005) then introduces a new parametrization of the dual program.", "publication_ref": ["b4", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Partial Ranking", "text": "We want to learn a function f that maps patterns x \u2208 X to discrete class labels y \u2208 Y. We introduce a discriminant function S(x, y) \u2208 R that measures the correctness of the association between pattern x and class label y. The optimal class label is then\nf (x) = arg max y\u2208Y S(x, y) .(1)\nWe assume that the discriminant function has the form S(x, y) = w, \u03a6(x, y)\nwhere \u03a6(x, y) maps the pair (x, y) into a suitable feature space endowed with the dot product \u2022, \u2022 . As usual with kernel machines, the feature mapping function \u03a6 is implicitly defined by the specification of a joint kernel function K(x, y,x,\u0233) = \u03a6(x, y), \u03a6(x,\u0233) .\n(2)\nConsider training patterns x 1 . . . x n \u2208 X and their class labels y 1 . . . y n \u2208 Y. For each pattern x i , we want to make sure that the score S(x i , y i ) of the correct association is greater than the scores S(x i , y), y = y i , of the incorrect associations. This amounts to enforcing a partial order relationship on the elements of X \u00d7 Y. This partial ranking can be expressed by constraints\n\u2200i = 1 . . . n \u2200y = y i w, \u03b4\u03a6 i (y i , y) \u2265 1\nwhere \u03b4\u03a6 i (y,\u0233) stands for \u03a6(x i , y) \u2212 \u03a6(x i ,\u0233).\nFollowing the standard SVM derivation, we introduce slack variables \u03be i to account for the potential violation of the constraints and optimize a combination of the norm of w and of the size of the slack variables.\nmin w 1 2 w, w + C n i=1 \u03be i (3) subject to \u2200i \u03be i \u2265 0 \u2200i \u2200y = y i w, \u03b4\u03a6 i (y i , y) \u2265 1 \u2212 \u03be i", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Dual Programs", "text": "The usual derivation leads to solving the following equivalent dual problem (Crammer & Singer, 2001;Tsochantaridis et al., 2005):\nmax \u03b1 X i,y =y i \u03b1 y i \u2212 1 2 X i,y =y i j,\u0233 =y j \u03b1 y i \u03b1\u0233 j \u03b4\u03a6i(yi, y), \u03b4\u03a6j(yj,\u0233) subject to 8 < : \u2200i \u2200y = yi \u03b1 y i \u2265 0 \u2200i X y =y i \u03b1 y i \u2264 C(4)\nThis problem has n(k \u2212 1) variables \u03b1 y i , y = y i corresponding to the constraints of (3). Once we have the solution, the discriminant function is\nS(x, y) = i,\u0233 =yi \u03b1\u0233 i \u03b4\u03a6 i (y i ,\u0233), \u03a6(x, y)\nThis dual problem can be considerably simplified by reparametrizing it with nk variables \u03b2 y i defined as\n\u03b2 y i = \uf8f1 \uf8f2 \uf8f3 \u2212\u03b1 y i if y = y i \u0233 =yi \u03b1\u0233 i otherwise (5)\nNote that only the \u03b2 yi i can be positive. Substituting in (4), and taking into account the relation y \u03b2 y i = 0, leads to a much simpler expression for the dual problem (the \u03b4\u03a6 i (. . . ) have disappeared.)\nmax \u03b2 X i \u03b2 y i i \u2212 1 2 X i,j,y,\u0233 \u03b2 y i \u03b2\u0233 j \u03a6(xi, y), \u03a6(xj,\u0233) subject to 8 > < > : \u2200i \u2200y = yi \u03b2 y i \u2264 0 \u2200i \u03b2 y i i \u2264 C \u2200i X y \u03b2 y i = 0 (6)\nThe discriminant function then becomes\nS(x, y) = i,\u0233 \u03b2\u0233 i \u03a6(x i ,\u0233), \u03a6(x, y)", "publication_ref": ["b4", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Kernel Factorization", "text": "In practice, smart factorizations of the joint kernel (2) are crucial to reduce the memory required to store or cache the kernel values. This paper focuses on simple multiclass problems whose kernel function (2) takes the form\n\u03a6(x, y), \u03a6(x,\u0233) = k(x,x) \u03b4(y,\u0233)\nwhere k(x,x) is a kernel defined on the patterns, and where \u03b4(y,\u0233) is 1 if y =\u0233 and 0 otherwise.\nThe dual problem (6) then becomes max \u03b2\nX i \u03b2 y i i \u2212 1 2 X i,j X y \u03b2 y i \u03b2 y j k(xi, xj) subject to 8 < : \u2200i \u2200y \u03b2 y i \u2264 C\u03b4(y, yi) \u2200i X y \u03b2 y i = 0 (7)\nand the discriminant function becomes\nS(x, y) = i \u03b2 y i k(x i , x)\nWhen there are only two classes, this reduces to the standard SVM solution (without equality constraint.)\nStructured output learning systems (Tsochantaridis et al., 2005) call for much more sophisticated factorizations of the joint kernel. For the sake of simplicity, we describe the LaRank algorithm in the context of the multiclass problem (7) which is the focus of this paper. Dealing with the general problem (6), or handling the variable margins suggested by Tsochantaridis et al. (2005), only requires minor changes.", "publication_ref": ["b17", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Optimization Algorithm", "text": "During the execution of the optimization algorithm, we call support vectors all pairs (x i , y) whose associated coefficient \u03b2 y i is non zero; we call support patterns all patterns x i that appear in a support vector.\nThe LaRank algorithm stores the following data:\n\u2022 The set S of the current support vectors.\n\u2022 The coefficients \u03b2 y i associated with the support vectors (x i , y) \u2208 S. This describes the solution since all the other \u03b2 coefficients are zero.\n\u2022 The derivatives g i (y) of the dual objective function with respect to the coefficients \u03b2 y i associated with the support vectors (x i , y) \u2208 S.\ng i (y) = \u03b4(y, y i ) \u2212 j \u03b2 y j k(x i , x j ) = \u03b4(y, y i ) \u2212 S(x i , y)(8)\nNote that we do not store or even compute the remaining coefficients of the gradient. In general, these missing derivatives are not zero because the gradient is not sparse.\nA naive implementation could simply precompute all the kernel values k(x i , x j ). This would be a waste of processing time because the location of the optimum depends only on the fraction of the kernel matrix that involves support patterns. Our code computes kernel values on demand and caches them in sets of the form\nE(y, j) = { k(x i , x j ) such that (x i , y) \u2208 S }.\nAlthough this cache stores several copies of the same kernel values, caching individual kernel values has a higher overhead.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Elementary", "text": "Step Problem (7) lends itself to a simple iterative algorithm whose elementary steps are inspired by the well known sequential minimal optimization (SMO) algorithm (Platt, 1999).\nAlgorithm 1 SmoStep(i, y + , y \u2212 ):\n1: Retrieve or compute gi(y+). 2: Retrieve or compute gi(y\u2212). and \u03b2\n3: Let \u03bb u = g i (y + )\u2212g i (y \u2212 ) 2 k(x i ,x i ) 4: Let \u03bb = max\u02d80, min( \u03bb u , C \u03b4(y+, yi) \u2212 \u03b2 y + i )5 : Update \u03b2 y + i \u2190 \u03b2 y + i + \u03bb and \u03b2 y \u2212 i \u2190 \u03b2 y \u2212 i \u2212 \u03bb 6: Update S\ny\u2212 i by opposite amounts, \u03b2 y+ i \u2190\u2212 \u03b2 y+ i + \u03bb \u03b2 y\u2212 i \u2190\u2212 \u03b2 y\u2212 i \u2212 \u03bb (9)\nwhere \u03bb \u2265 0 maximizes the dual objective function (7) subject to the constraints. This optimal value is easily computed by first calculating the unconstrained optimum\n\u03bb u = g i (y + ) \u2212 g i (y \u2212 ) 2 k(x i , x i ) (10)\nand then enforcing the constraints\n\u03bb = max 0, min( \u03bb u , C \u03b4(y + , y i ) \u2212 \u03b2 y+ i ) (11)\nFinally the stored derivatives g j (y) are updated to reflect the coefficient update. This is summarized in algorithm 1.", "publication_ref": ["b12"], "figure_ref": [], "table_ref": []}, {"heading": "Step Selection Strategies", "text": "Popular SVM solvers based on SMO select successive steps by choosing the pair of coefficients that defines the feasible search direction with the highest gradient. We cannot use this strategy because we have chosen to store only a small fraction of the gradient.\nStochastic algorithms inspired by the perceptron perform quite well by successively updating coefficients determined by randomly picking training patterns.\nFor instance, in a multiclass context, Taskar (2004, section 6.1) iterates over the randomly ordered patterns: for each pattern x i , he computes the scores S(x i , y) for all classes and runs SmoStep on the two most violating classes, that is, the classes that define the feasible search direction with the highest gradient.\nIn the context of binary classification,  observe that such perceptron-inspired updates lead to a slow optimization of the dual because the coefficients corresponding to the few support vectors are not updated often enough. They suggest to alternatively update the coefficient corresponding to a fresh random example and the coefficient corresponding to an example randomly chosen among the current support vectors. The related LaSVM algorithm  alternates steps exploiting a fresh random training example and steps exploiting current support vectors selected using the gradient.\nWe now extend this idea to the multiclass formulation.\nSince the multiclass problem has both support vectors and support patterns, we define three ways to select a triple (i, y + , y \u2212 ) for the elementary SmoStep.\nAlgorithm 2 ProcessNew(x i ):\n1: if xi is a support pattern then exit. 2: y+ \u2190 yi.\n3: y\u2212 \u2190 arg min y\u2208Y gi(y) 4: Perform SmoStep(i, y+, y\u2212)\n\u2022 ProcessNew (algorithm 2) operates on a pattern x i that is not a support pattern. It chooses the classes y + and y \u2212 that define the feasible direction with the highest gradient. Since all the Algorithm 3 ProcessOld:\n1: Randomly pick a support pattern xi. 2: y+ \u2190 arg max y\u2208Y gi(y) subject to \u03b2 y i < C \u03b4(y, yi) 3: y\u2212 \u2190 arg min y\u2208Y gi(y) 4: Perform SmoStep(i, y+, y\u2212) Algorithm 4 Optimize:\n1: Randomly pick a support pattern xi. 2: Let Yi = { y \u2208 Y such that (xi, y) \u2208 S } 3: y+ \u2190 arg max y\u2208Y i gi(y) subject to \u03b2 y i < C \u03b4(y, yi) 4: y\u2212 \u2190 arg min y\u2208Y i gi(y) 5: Perform SmoStep(i, y+, y\u2212) \u03b2 y i are zero, y + is always y i . Choosing of y \u2212 consists of finding arg max y S(x i , y) since equation (8) holds.\n\u2022 ProcessOld (algorithm 3) randomly picks a support pattern x i . It chooses the classes y + and y \u2212 that define the feasible direction with the highest gradient. The determination of y + mostly involves labels y such that \u03b2 y i < 0, for which the corresponding derivatives g i (y) are known. The determination of y \u2212 again consists of computing arg max y S(x i , y).\n\u2022 Optimize (algorithm 4) resembles ProcessOld but picks the classes y + and y \u2212 among those that correspond to existing support vectors (x i , y + ) and (x i , y \u2212 ). Using the gradient is fast because the relevant derivatives are already known and their number is moderate.\nThe ProcessNew operation is closely related to the perceptron algorithm. It can be interpreted as a stochastic gradient update for the minimization of the generalized margin loss (LeCun et al., 2007, \u00a72.2.3), with a step size adjusted according to the curvature of the dual (Hildreth, 1957). Crammer and Singer (2003) use a very similar approach for the MIRA algorithm.", "publication_ref": ["b9", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Adaptive Schedule", "text": "Previous works  simply alternate two step selection strategies according to a fixed schedule. They also report results suggesting that the optimal schedule is in fact datadependent.\nWe would like to select at each iteration an operation that causes a large increase of the dual in a small amount of time. For each operation type, LaRank maintains a running estimate of the average ratio of the dual increase over the duration. Running times are measured; dual increases are derived from the value of \u03bb computed during the elementary step.\nEach iteration of the LaRank algorithm (algorithm 5) end while 18: end loop randomly selects which operation to perform with a probability proportional to these estimates. Our implementation uses \u00b5 = 0.05. In order to facilitate timing, we treat sequences of ten Optimize as a single atomic operation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Correctness and Complexity", "text": "Let \u03bd 2 = max i {k(x i , x i )} and let \u03ba, \u03c4, \u03b7 be small positive tolerances. We assume that the algorithm implementation enforces the following properties:\n\u2022 SmoStep exits when g i (y + ) \u2212 g i (y \u2212 ) \u2264 \u03c4 .\n\u2022 Optimize and ProcessOld chooses y + among the y that satisfy \u03b2 y i \u2264 C \u03b4(y, y i ) \u2212 \u03ba. \u2022 LaRank makes sure that every operation has probability greater than \u03b7 to be selected at each iteration (see algorithm 5).\nWe refer to this as the (\u03ba, \u03c4, \u03b7)-algorithm.\nTheorem With probability 1, the (\u03ba, \u03c4, \u03b7)-algorithm reaches a \u03ba\u03c4 -approximate solution of problem (7), with no more than max{ 2\u03bd 2 nC \u03c4 2 , 2nC \u03ba\u03c4 } successful SmoSteps.\nProof Sketch The convergence is a consequence from theorem 18 from . To apply this theorem, we must prove that the directions defined by ( 9) form a witness family for the polytope defined by the constraints of problem (7). This is the case because this polytope is a product of n polytopes for which we can apply proposition 7 from . The number of iterations is then bounded using a technique similar to that of (Tsochantaridis et al., 2005). The complete proof will be given in an extended version of this paper.\nThe bound on the number of iterations is also a bound on the number of support vectors. It is linear in the number of examples and does not depend on the pos-sibly large number of classes.", "publication_ref": ["b17"], "figure_ref": [], "table_ref": []}, {"heading": "Stopping", "text": "Algorithm 5 does not specify a criterion for stopping its outer loop. Excellent results are obtained by performing just one or two outer loop iterations (epochs). We use the name LaRank\u00d71 to indicate that we perform a single epoch, that is to say, a single pass over the randomly ordered training examples.\nOther stopping criteria include exploiting the duality gap (Sch\u00f6lkopf & Smola, 2002, \u00a710.1.1) and monitoring the performance measured on a validation set. We use the name LaRankGap to indicate that we iterate algorithm 5 until the difference between the primal cost (3) and the dual cost (7) becomes smaller than C. However, computing the duality gap can become quite expensive.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "This section report experiments carried out on various multiclass pattern recognition problems. Although our approach is partly motivated by structured output problems, this work focuses on well understood multiclass tasks in order best characterize the algorithm behavior.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Setup", "text": "Experiments were carried out on four datasets briefly described in table 1. The LETTER and USPS datasets are available from the UCI repository. 1 The MNIST dataset 2 is a well known handwritten digit recognition benchmark. The INEX dataset contains scientific articles from 18 journals and proceedings of the IEEE. We use a flat TF/IDF feature space (see Denoyer & Gallinari, 2006 for further details).\nTable 1 also lists our choices for the parameter C and for the kernels k(x,x). These choices were made on the basis of past experience. We use the same parameters for all algorithms because we mostly compare algorithms that optimize the same criterion. The kernel cache size was 500MB for all experiments.", "publication_ref": ["b6"], "figure_ref": [], "table_ref": ["tab_1"]}, {"heading": "Comparing Optimizers", "text": "Table 2 (top half) compares three optimization algorithms for the same dual cost (7).\n\u2022 MCSVM (Crammer & Singer, 2001) uses the full gradient and therefore cannot be easily extended to handle structured output problems. We have used the MCSVM implementation distributed by the authors.   \u2022 SVMstruct (Tsochantaridis et al., 2005) targets structured output problems and therefore uses only a small fraction of the gradient. We have used the implementation distributed by the authors. The authors warn that this implementation has not been thoroughly optimized.\n\u2022 LaRankGap iterates algorithm 5 until the duality gap becomes smaller than parameter C. This algorithm only stores a small fraction of the gradient, comparable to that used by SVMstruct. We have implemented LaRank using an interpreted scripting language with a specialized C function for algorithm 1 (SmoStep).\nBoth SVMstruct and LaRankGap use small subsets of the gradient coefficients. Although these subsets have similar size, LaRankGap avoids the training time penalty experienced by SVMstruct.\nBoth SVMstruct and LaRank make heavy use of kernel values involving two support patterns. In contrast, MCSVM updates the complete gradient vector after each step and therefore uses the kernel matrix rows corresponding to support patterns. On our relatively small problems, this stronger memory requirement is more than compensated by the lower overhead of MCSVM's simpler cache structure. For each dataset, figure 1 shows the evolution of the test error with respect to the number of kernel calculations. The point marked LaRank\u00d71 corresponds to running a single LaRank epoch. The point marked LaRankGap corresponds to using the duality gap stopping criterion as explained in section 4.2. Figure 1 also reports results obtained with two popular online algorithms:", "publication_ref": ["b4", "b17"], "figure_ref": ["fig_1", "fig_1"], "table_ref": ["tab_2"]}, {"heading": "Comparing Online Learning Algorithms", "text": "\u2022 The points marked AvgPerceptron\u00d71 and AvgPerceptron\u00d710 respectively correspond to performing one and ten epochs of the average perceptron algorithm (Freund & Schapire, 1998;Collins, 2002). Multiple epochs of the averaged perceptron are very effective when the necessary kernel values fit in the cache (first row). Training time increases considerably when this is not the case (second row.) \u2022 The point marked MIRA corresponds to the online multiclass algorithm proposed by Crammer and Singer (2003). We have used the implementation provided by the authors as part of the MCSVM package. This algorithm computes more kernel values than AvgPerceptron\u00d71 because its solution contains more support patterns. Its performance seems sensitive to the choice of kernel: Crammer and Singer ( 2003) report substantially better results using the same code but different kernels.\nThese results indicate that performing single LaRank epoch is an attractive online learning algorithm. Although LaRank\u00d71 usually runs slower than AvgPerceptron\u00d71 or MIRA, it provides better and more predictable generalization performance.", "publication_ref": ["b7", "b3", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Comparing Optimization Strategies", "text": "Figure 2 shows the error rates and kernel calculations achieved when one restricts the set of operations chosen by algorithm 5. These results were obtained after a single pass on the USPS dataset.\nAs expected, using only the ProcessNew operation performs like MIRA. The average perceptron requires significantly less kernel calculations because its solution is much more sparse. However, it looses this initial sparsity when one performs several epochs (see figure 1.)\nEnabling ProcessOld and Optimize significantly reduces the test error. The best test error is achieved when all operations are enabled. The number of kernel calculations is also reduced because ProcessOld and Optimize often eliminate support patterns.", "publication_ref": [], "figure_ref": ["fig_2", "fig_1"], "table_ref": []}, {"heading": "Comparing ArgMax Calculations", "text": "The previous experiments measure the computational cost using training time and number of kernel calculations. Certain structured output problems use costly algorithms to find the class with the best score (1). The cost of this arg max calculation is partly related to the required number of new kernel values.\nThe average perceptron (and MIRA) performs one such arg max calculation for each example it processes. In contrast, LaRank performs one arg max calculation when processing a new example with ProcessNew, and also when running ProcessOld.\nTable 3 compares the number of arg max calculations for various algorithms and datasets. 3 The SVMstruct optimizer performs very well with this metric. The AvgPerceptron and LaRank are very competitive on a single epoch and become more costly when performing many epochs. One epoch is sufficient to reach good performance with LaRank. This is not the case for the AvgPerceptron.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "Conclusion", "text": "We have presented a large margin multiclass algorithm that uses gradients as sparingly as SVMstruct without experiencing the same training time penalty. LaRank can be considered an online algorithm because it nearly reaches its optimal performance in a single pass over the training examples. Under these conditions, LaRank achieves test error rates that are competitive with those of the full optimization, and significantly better than those achieved by perceptrons.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "Nicolas Usunier helped proving the theorem bound. Part of this work was funded by NSF grant CCR-0325463. Antoine Bordes was also supported by the DGA and by the Network of Excellence IST-2002-506778 PASCAL.   ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Predicting structured outputs", "journal": "MIT Press", "year": "2007", "authors": "G Bak\u0131r; T Hofmann; B Sch\u00f6lkopf; A J Smola; B Taskar"}, {"ref_id": "b1", "title": "The Huller: a simple and efficient online SVM", "journal": "Springer Verlag", "year": "2005", "authors": "A Bordes; L Bottou"}, {"ref_id": "b2", "title": "Fast kernel classifiers with online and active learning", "journal": "Journal of Machine Learning Research", "year": "2005", "authors": "A Bordes; S Ertekin; J Weston; L Bottou"}, {"ref_id": "b3", "title": "Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms", "journal": "Association for Computational Linguistics", "year": "2002", "authors": "M Collins"}, {"ref_id": "b4", "title": "On the algorithmic implementation of multiclass kernel-based vector machines", "journal": "Journal of Machine Learning Research", "year": "2001", "authors": "K Crammer; Y Singer"}, {"ref_id": "b5", "title": "Ultraconservative online algorithms for multiclass problems", "journal": "Journal of Machine Learning Research", "year": "2003", "authors": "K Crammer; Y Singer"}, {"ref_id": "b6", "title": "Advances in XML Information Retrieval and Evaluation, 5th International Workshop of the Initiative for the Evaluation of XML Retrieval", "journal": "", "year": "2006", "authors": "L Denoyer; P Gallinari"}, {"ref_id": "b7", "title": "Large margin classification using the perceptron algorithm", "journal": "Morgan Kaufmann", "year": "1998", "authors": "Y Freund; R E Schapire"}, {"ref_id": "b8", "title": "From margin to sparsity", "journal": "MIT Press", "year": "2000", "authors": "T Graepel; R Herbrich; R C Williamson"}, {"ref_id": "b9", "title": "A quadratic programming procedure", "journal": "Naval Research Logistics Quarterly", "year": "1957", "authors": "C Hildreth"}, {"ref_id": "b10", "title": "A comparison of methods for multi-class support vector machines", "journal": "IEEE Transactions on Neural Networks", "year": "2002", "authors": "C.-W Hsu; C.-J Lin"}, {"ref_id": "b11", "title": "A tutorial on energy-based learning", "journal": "", "year": "2007", "authors": "Y Lecun; S Chopra; R Hadsell; J Huangfu; M Ranzato;  Bak\u0131r"}, {"ref_id": "b12", "title": "Fast training of support vector machines using sequential minimal optimization", "journal": "MIT Press", "year": "1999", "authors": "J Platt"}, {"ref_id": "b13", "title": "In defense of one-vsall classification", "journal": "Journal of Machine Learning Research", "year": "2004", "authors": "R M Rifkin; A Klautau"}, {"ref_id": "b14", "title": "Learning with kernels", "journal": "MIT Press", "year": "2002", "authors": "B Sch\u00f6lkopf; A J Smola"}, {"ref_id": "b15", "title": "Learning structured prediction models: A large margin approach. Doctoral dissertation", "journal": "", "year": "2004", "authors": "B Taskar"}, {"ref_id": "b16", "title": "Learning structured prediction models: a large margin approach", "journal": "", "year": "2005", "authors": "B Taskar; V Chatalbashev; D Koller; C Guestrin"}, {"ref_id": "b17", "title": "Large margin methods for structured and interdependent output variables", "journal": "Journal of Machine Learning Research", "year": "2005", "authors": "I Tsochantaridis; T Joachims; T Hofmann; Y Altun"}, {"ref_id": "b18", "title": "Multi-class support vector machines", "journal": "", "year": "1998", "authors": "J Weston; C Watkins"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "gradients: \u2200j s.t. (xj, y+) \u2208 S, gj(y+) \u2190 gj(y+) + \u03bb k(xi, xj) \u2200j s.t. (xj, y\u2212) \u2208 S, gj(y\u2212) \u2190 gj(y\u2212) \u2212 \u03bb k(xi, xj)Each iteration starts with the selection of one pattern x i and two classes y + and y \u2212 . The elementary step modifies the coefficients \u03b2 y+ i", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 1 .1Figure 1. Evolution of the test error as a function of the number of kernel calculations", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 .2Figure 2. Impact of the LaRank operations (USPS dataset).", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Datasets used for the experiments.", "figure_data": "Train Ex.Test Ex.ClassesFeaturesCk(x,x)LETTER160004000261610e \u22120.025 x\u2212x 2USPS729120071025610e \u22120.025 x\u2212x 2MNIST6000010000107801000e \u22120.005 x\u2212x 2INEX6053605418167295100x \u2022x"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Compared test error rates and training times. Not applicable because SVMstruct bypasses the cache when using linear kernels.", "figure_data": "LETTERUSPSMNISTINEXMCSVMTest error (%)2.424.241.4426.26(stores the full gradient)Dual55485373718235204Training time (sec.)12006025000520Kernels (\u00d710 6 )24151.2690832.9SVMstructTest error (%)2.404.381.4026.25(stores partial gradient)Dual54955283730235631Training time (sec.)23000630026500014500Kernels (\u00d710 6 )20831063.3158076n/a  \u2020LaRankGapTest error (%)2.404.381.4426.25(stores partial gradient)Dual54625183718235183Training time (sec.)2900175820001050Kernels (\u00d710 6 )15613.7476919.3LaRank\u00d71Test error (%)2.804.251.4127.20(online)Dual52265033608214224Training time (sec.)9408530000300Kernels (\u00d710 6 )559.439917.2\u2020 LETTERUSPSMNISTINEX"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": "(bottom half) also reports the results obtainedwith a single LaRank epoch (LaRank\u00d71). This sin-gle pass over the training examples is sufficient tonearly reach the optimal performance. This resultis understandable because (i) online perceptrons offerstrong theoretical guarantees after a single pass overthe training examples, and (ii) LaRank drives the opti-mization process by replicating the randomization thathappens in the perceptron."}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Numbers of arg max (in thousands).", "figure_data": "LETTERUSPSMNISTINEXAvgPerceptron\u00d71167606AvgPerceptron\u00d7101607360060LaRank\u00d711902520028LaRankGap55086202073SVMstruct1415655978"}], "formulas": [{"formula_id": "formula_0", "formula_text": "f (x) = arg max y\u2208Y S(x, y) .(1)", "formula_coordinates": [2.0, 120.23, 663.25, 169.22, 16.52]}, {"formula_id": "formula_1", "formula_text": "\u2200i = 1 . . . n \u2200y = y i w, \u03b4\u03a6 i (y i , y) \u2265 1", "formula_coordinates": [2.0, 337.37, 248.2, 174.14, 9.65]}, {"formula_id": "formula_2", "formula_text": "min w 1 2 w, w + C n i=1 \u03be i (3) subject to \u2200i \u03be i \u2265 0 \u2200i \u2200y = y i w, \u03b4\u03a6 i (y i , y) \u2265 1 \u2212 \u03be i", "formula_coordinates": [2.0, 315.24, 336.14, 226.21, 62.74]}, {"formula_id": "formula_3", "formula_text": "max \u03b1 X i,y =y i \u03b1 y i \u2212 1 2 X i,y =y i j,\u0233 =y j \u03b1 y i \u03b1\u0233 j \u03b4\u03a6i(yi, y), \u03b4\u03a6j(yj,\u0233) subject to 8 < : \u2200i \u2200y = yi \u03b1 y i \u2265 0 \u2200i X y =y i \u03b1 y i \u2264 C(4)", "formula_coordinates": [2.0, 317.33, 466.06, 224.11, 64.76]}, {"formula_id": "formula_4", "formula_text": "S(x, y) = i,\u0233 =yi \u03b1\u0233 i \u03b4\u03a6 i (y i ,\u0233), \u03a6(x, y)", "formula_coordinates": [2.0, 342.54, 587.32, 159.93, 20.14]}, {"formula_id": "formula_5", "formula_text": "\u03b2 y i = \uf8f1 \uf8f2 \uf8f3 \u2212\u03b1 y i if y = y i \u0233 =yi \u03b1\u0233 i otherwise (5)", "formula_coordinates": [2.0, 361.58, 648.05, 179.86, 36.85]}, {"formula_id": "formula_6", "formula_text": "max \u03b2 X i \u03b2 y i i \u2212 1 2 X i,j,y,\u0233 \u03b2 y i \u03b2\u0233 j \u03a6(xi, y), \u03a6(xj,\u0233) subject to 8 > < > : \u2200i \u2200y = yi \u03b2 y i \u2264 0 \u2200i \u03b2 y i i \u2264 C \u2200i X y \u03b2 y i = 0 (6)", "formula_coordinates": [3.0, 71.93, 99.46, 217.52, 64.97]}, {"formula_id": "formula_7", "formula_text": "S(x, y) = i,\u0233 \u03b2\u0233 i \u03a6(x i ,\u0233), \u03a6(x, y)", "formula_coordinates": [3.0, 98.52, 197.38, 143.98, 19.91]}, {"formula_id": "formula_8", "formula_text": "\u03a6(x, y), \u03a6(x,\u0233) = k(x,x) \u03b4(y,\u0233)", "formula_coordinates": [3.0, 103.91, 319.19, 140.95, 8.74]}, {"formula_id": "formula_9", "formula_text": "X i \u03b2 y i i \u2212 1 2 X i,j X y \u03b2 y i \u03b2 y j k(xi, xj) subject to 8 < : \u2200i \u2200y \u03b2 y i \u2264 C\u03b4(y, yi) \u2200i X y \u03b2 y i = 0 (7)", "formula_coordinates": [3.0, 93.97, 387.56, 195.47, 55.44]}, {"formula_id": "formula_10", "formula_text": "S(x, y) = i \u03b2 y i k(x i , x)", "formula_coordinates": [3.0, 120.1, 473.5, 104.68, 22.66]}, {"formula_id": "formula_11", "formula_text": "g i (y) = \u03b4(y, y i ) \u2212 j \u03b2 y j k(x i , x j ) = \u03b4(y, y i ) \u2212 S(x i , y)(8)", "formula_coordinates": [3.0, 349.31, 168.44, 192.13, 24.9]}, {"formula_id": "formula_12", "formula_text": "E(y, j) = { k(x i , x j ) such that (x i , y) \u2208 S }.", "formula_coordinates": [3.0, 327.88, 341.47, 193.13, 9.65]}, {"formula_id": "formula_13", "formula_text": "3: Let \u03bb u = g i (y + )\u2212g i (y \u2212 ) 2 k(x i ,x i ) 4: Let \u03bb = max\u02d80, min( \u03bb u , C \u03b4(y+, yi) \u2212 \u03b2 y + i )5 : Update \u03b2 y + i \u2190 \u03b2 y + i + \u03bb and \u03b2 y \u2212 i \u2190 \u03b2 y \u2212 i \u2212 \u03bb 6: Update S", "formula_coordinates": [3.0, 312.23, 519.61, 379.87, 47.04]}, {"formula_id": "formula_14", "formula_text": "y\u2212 i by opposite amounts, \u03b2 y+ i \u2190\u2212 \u03b2 y+ i + \u03bb \u03b2 y\u2212 i \u2190\u2212 \u03b2 y\u2212 i \u2212 \u03bb (9)", "formula_coordinates": [3.0, 307.44, 637.03, 234.0, 50.94]}, {"formula_id": "formula_15", "formula_text": "\u03bb u = g i (y + ) \u2212 g i (y \u2212 ) 2 k(x i , x i ) (10)", "formula_coordinates": [4.0, 125.63, 92.28, 163.81, 23.23]}, {"formula_id": "formula_16", "formula_text": "\u03bb = max 0, min( \u03bb u , C \u03b4(y + , y i ) \u2212 \u03b2 y+ i ) (11)", "formula_coordinates": [4.0, 70.65, 138.36, 218.79, 14.15]}, {"formula_id": "formula_17", "formula_text": "\u2022 SmoStep exits when g i (y + ) \u2212 g i (y \u2212 ) \u2264 \u03c4 .", "formula_coordinates": [5.0, 65.4, 419.96, 194.28, 9.65]}], "doi": ""}