{"title": "Globally Optimal Affine and Metric Upgrades in Stratified Autocalibration", "authors": "Manmohan Chandraker; Sameer Agarwal; David Kriegman; Serge Belongie", "pub_date": "", "abstract": "We present a practical, stratified autocalibration algorithm with theoretical guarantees of global optimality. Given a projective reconstruction, the first stage of the algorithm upgrades it to affine by estimating the position of the plane at infinity. The plane at infinity is computed by globally minimizing a least squares formulation of the modulus constraints. In the second stage, the algorithm upgrades this affine reconstruction to a metric one by globally minimizing the infinite homography relation to compute the dual image of the absolute conic (DIAC). The positive semidefiniteness of the DIAC is explicitly enforced as part of the optimization process, rather than as a post-processing step. For each stage, we construct and minimize tight convex relaxations of the highly non-convex objective functions in a branch and bound optimization framework. We exploit the problem structure to restrict the search space for the DIAC and the plane at infinity to a small, fixed number of branching dimensions, independent of the number of views. Experimental evidence of the accuracy, speed and scalability of our algorithm is presented on synthetic and real data. MATLAB code for the implementation is made available to the community.", "sections": [{"heading": "Introduction", "text": "This paper proposes practical algorithms that provably solve well-known formulations for both affine and metric upgrade stages of stratified autocalibration to their global minimum.\nThe affine upgrade, which is arguably the more difficult step in autocalibration, is succintly computable by estimating the position of the plane at infinity in a projective reconstruction, for instance, by solving the modulus constraints [19]. Previous approaches to minimizing the modulus constraints for several views rely on local, descent-based methods with random reinitializations. These methods are not guaranteed to perform well for such non-convex problems. Moreover, in our experience, a highly accurate estimate of the plane at infinity is imperative to obtain a usable metric reconstruction.\nThe metric upgrade step involves estimating the intrinsic parameters of the cameras, which is commonly approached by estimating the dual image of the absolute conic (DIAC).\nA variety of linear methods exist towards this end, however, they are known to perform poorly in the presence of noise [10]. Perhaps more significantly, most methods a posteriori impose the positive semidefiniteness of the DIAC, which might lead to a spurious calibration. Thus, it is important to impose the positive semidefiniteness of the DIAC within the optimization, not as a post-processing step. This paper proposes global minimization algorithms for both stages of stratified autocalibration that furnish theoretical certificates of optimality. That is, they return a solution at most away from the global minimum, for arbitrarily small . Our solution approach relies on constructing efficiently minimizable, tight convex relaxations to non-convex programs, using them in a branch and bound framework [13,27].\nA crucial concern in branch and bound algorithms is the exponential dependence of the worst case time complexity on the number of branching dimensions. In this paper, we exploit the inherent problem structure to restrict our branching dimensions to a small, fixed, view-independent number, which allows our algorithms to scale gracefully with an increase in the number of views.\nA significant drawback of local methods is that they critically depend on the quality of a heuristic intialization. We use chirality constraints derived from the scene to compute a theoretically correct initial search space for the plane at infinity, within which we are guaranteed to find the global minimum [8,9]. Our initial region for the metric upgrade is intuitively specifiable as conditions on the intrinsic parameters and can be wide enough to include any practical cases.\nWhile we provide a unified framework for a global solution to stratified autocalibration, in several ways, our constructions are general enough to find application in domains beyond multiple view geometry.\nIn summary, our main contributions are the following:\n\u2022 Highly accurate recovery of the plane at infinity in a projective reconstruction by global minimization of the modulus constraints.\n\u2022 Highly accurate estimation of the DIAC by globally solving the infinite homography relation.\n\u2022 A general exposition on novel convexification methods for global optimization of non-convex programs.\nThe outline of the rest of the paper is as follows. Section 2 describes background relevant to autocalibration and Section 3 outlines the related prior work. Section 4 is a brief overview of branch and bound algorithms. Sections 5 and 6 describe our global optimization algorithms for estimating the DIAC and the plane at infinity respectively. Section 7 presents experiments on synthetic and real data and Section 8 concludes with a discussion of further extensions.", "publication_ref": ["b18", "b9", "b12", "b26", "b7", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "Background", "text": "Unless stated otherwise, we will denote 3D world points X by homogeneous 4-vectors and 2D image points x by homogeneous 3-vectors. Given the images of n points in m views, a projective reconstruction {P, X} computes the Euclidean scene {P i ,X j } up to a 4 \u00d7 4 homography:\nP i =P i H \u22121 , X j = HX j .\nA camera matrix is denoted by K[R|t] where K is an upper triangular matrix that encodes the intrinsic parameters and (R, t) constitute exterior orientation. A more detailed discussion of the material in this section can be found in [10].", "publication_ref": ["b9"], "figure_ref": [], "table_ref": []}, {"heading": "The Infinite Homography Relation", "text": "We can always perform the projective reconstruction such that P 1 = [I|0]. Let the first world camera be P\n1 = K 1 [I|0]. Then H has the form H = K 1 0 \u2212p K 1 1 (1)\nwhere \u03c0 \u221e = (p, 1) is the location to which the plane at infinity moves in the projective reconstruction from its canonical position (0, 0, 0, 1) . The aim of autocalibration is to recover the plane at infinity and the intrinsic parameters.\nLet P i = [A i |a i ] where A i is 3 \u00d7 3 and a i is a 3 \u00d7 1 vector. Let P i = K i [R i |t i ].\nThen, for the case of constant intrinsic parameters (K i = K), we have\n\u03c9 * = (A i \u2212 a i p )\u03c9 * (A i \u2212 a i p )(2)\nwhere \u03c9 * = KK denotes the dual image of the absolute conic (DIAC). Equality here is up to a scale factor. Since\nH i \u221e = (A i \u2212 a i p )\nis precisely the homography induced between the views P 1 = [I|0] and P i = [A i |a i ] by the plane at infinity (p, 1) , it is called the infinite homography.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Modulus Constraints", "text": "Noting that the infinite homography is conjugate to a rotation matrix and must have eigenvalues of equal moduli, one can relate the roots of its characteristic polynomial\ndet(\u03bbI \u2212 (A i \u2212 a i p )) = \u03bb 3 \u2212 \u03b1 i \u03bb 2 + \u03b2 i \u03bb \u2212 \u03b3 i . (3)\nto derive the so called modulus constraint [19]:\n\u03b3 i \u03b1 3 i = \u03b2 3 i ,(4)\nwhere \u03b1 i , \u03b2 i , \u03b3 i are affine functions of the coordinates {p 1 , p 2 , p 3 } of the plane at infinity. Three views suffice to restrict the solution space to a 4 3 = 64 possibilities (actually 21, see [23]), which can in theory be extracted using continuation methods.", "publication_ref": ["b18", "b22"], "figure_ref": [], "table_ref": []}, {"heading": "Chirality bounds on plane at infinity", "text": "Chirality constraints demand that the reconstructed scene points lie in front of the camera. While a general projective transformation may result in the plane at infinity splitting the scene, a quasi-affine transformation is one that preserves the convex hull of the scene points X and camera centers C. A transformation H q that upgrades a projective reconstruction to quasi-affine can be computed by solving the so-called chiral inequalities. A subsequent affine centering, H a , guarantees that the plane at infinity in the centered quasi-affine frame, v = (H a H q ) \u2212 \u03c0 \u221e , cannot pass through the origin. So it can be parametrized as (v 1 , v 2 , v 3 , 1) and bounds on v i in the centered quasi-affine frame can be computed by solving six linear programs:\nmin / max v i s.t. X q j v > 0, C q k v > 0,(5)\nwhere X q j and C q k are points and camera centers in the quasiaffine frame, j = 1, . . . , n and k = 1, . . . , m. We refer the reader to [8,18] for a thorough treatment of the subject.", "publication_ref": ["b7", "b17"], "figure_ref": [], "table_ref": []}, {"heading": "Previous work", "text": "Approaches to autocalibration [6] can be broadly classified as direct and stratified. Direct methods seek to compute a metric reconstruction by estimating the absolute conic. This is encoded conveniently in the dual quadric formulation of autocalibration [12,28], whereby an eigenvalue decomposition of the estimated dual quadric yields the homography that relates the projective reconstruction to Euclidean. Linear methods [20] as well as more elaborate SQP based optimization approaches [28] have been proposed to estimate the dual quadric, but perform poorly with noisy data. Methods such as [16] which are based on the Kruppa equations (or the fundamental matrix), are known to suffer from additional ambiguities [25].\nThis work primarily deals with a stratified approach to autocalibration [19]. It is well-established in literature that, in the absence of prior information about the scene, estimating the plane at infinity represents the most significant challenge in autocalibration [9]. The modulus constraints [19] propose a necessary condition for the coordinates of the plane at infinity. Local minimization techniques are used in [19] to minimize a noisy overdetermined system in the multi-view case.\nAn alternate approach to estimating the plane at infinity exploits the chirality constraints. The algorithm in [9] computes bounds on the plane at infinity and a brute force search is used to recover \u03c0 \u221e within this region. It is argued in [18] that it might be advantageous to use camera centers alone when using chirality constraints.\nSeveral linear methods exist for estimating the DIAC [10] for the metric upgrade, but they do not enforce its positive semidefiniteness. The only work the authors are aware of which explicitly deals with this issue is [2], which is formulated under the assumption of known principal point and zero skew. The interested reader is refered to [10] and the references therein for a more detailed overview of literature relevant to autocalibration.\nOf late, there has been significant activity towards developing globally optimal algorithms for various problems in computer vision. The theory of convex LMI relaxations [15] is used in [14] to find global solutions to several optimization problems in multiview geometry, while [5] discusses a direct method for autocalibration using the same techniques. Triangulation and resectioning are solved with a certificate of optimality using convex relaxation techniques for fractional programs in [1]. An interval analysis based branch and bound method for autocalibration is proposed in [7], however the fundamental matrix based formulation does not scale well beyond a small number of views.", "publication_ref": ["b5", "b11", "b27", "b19", "b27", "b15", "b24", "b18", "b8", "b18", "b18", "b8", "b17", "b9", "b1", "b9", "b14", "b13", "b4", "b0", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Branch and bound theory", "text": "Branch and bound algorithms are non-heuristic methods for global optimization in nonconvex problems [13]. They maintain a provable upper and/or lower bound on the (globally) optimal objective value and terminate with a certificate proving that the solution is -suboptimal (that is, within of the global optimum), for arbitrarily small .\nConsider a multivariate, nonconvex, scalar-valued objective function f (x), for which we seek a global minimum over a rectangle Q 0 . Branch and bound algorithms require an auxiliary function f lb (Q) which for every region Q \u2286 Q 0 , satisfies two properties. One, the value of f lb (Q) is always less than or equal to the minimum value f min (Q) of f (x) for x \u2208 Q. Two, if |Q| denotes the size along the largest dimension, then for every sequence of rectangles Q k such that |Q\nk | \u2192 0, f lb (Q k ) \u2192 f min (Q k ) uniformly.\nComputing the value of f lb (Q) is referred to as bounding, while choosing and subdividing a rectangle is called branching. The choice of the rectangle picked for refinement and the actual subdivision itself are essentially heuristic. We consider the rectangle with the smallest minimum of f lb as the most promising to contain the global minimum and subdivide it into k = 2 rectangles along the largest dimension.\nA key consideration when designing bounding functions is the ease with which they can be estimated . So, it is desirable to design f lb (Q) as the solution of a convex optimization problem for which efficient solvers exist [4]. In the next two sections, we present branch and bound algorithms based on two such constructions.\nAlthough guaranteed to find the global optimum (or a point arbitrarily close to it), the worst case complexity of a branch and bound algorithm is exponential. While this may initially appear to be discouraging, we will show in our experiments that exploiting problem structure leads to fast convergence rates in practice.", "publication_ref": ["b12", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Globally optimal metric upgrade", "text": "For ease of exposition, we will first describe the metric upgrade step, that is, assume that the affine upgrade has already been performed. The problem of finding the plane at infinity for the affine upgrade is deferred to the next section.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Problem Formulation", "text": "Recall that when the camera intrinsic parameters are held constant, the DIAC satisifes the infinite homography rela-\ntions \u03c9 * = H i \u221e \u03c9 * H i \u221e , i = 1, \u2022 \u2022 \u2022 , m.\nBoth \u03c9 * and H i \u221e are homogeneous quantities, so we must account for the scale in the above relation before it can be used to search for the optimal DIAC.\nA necessary condition for the matrix \u03c9 * to be interpreted as \u03c9 * = KK is that \u03c9 * 33 = 1. Thus, we fix the scale in the infinite homography relation by demanding that both the matrices on the left and the right hand side of the relation have their (3, 3) entry equal to 1. To this end, we introduce additional variables \u03bb i and pose the minimization problem:\narg min \u03c9 * ,\u03bbi i \u03c9 * \u2212 \u03bb i H i \u221e \u03c9 * H i \u221e 2 F (6) s.t. \u03c9 * 33 = 1, \u03bb i h i 3 \u03c9 * h i 3 = 1, \u03c9 * 0, \u03c9 * \u2208 D\nHere, h i 3 denotes the third row of the 3 \u00d7 3 infinite homography H i \u221e and D is some initial convex region within which the individual entries of \u03c9 * lie.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Convex Relaxation", "text": "As discussed in Section 4, the success of a branch and bound algorithm critically depends on the quality of underestimators as well as the efficiency of their minimization. In this section, we construct a high quality convex relaxation of (6) that underestimates its minimum.\nWe begin by introducing a new set of variables \u03bd i = \u03bb i \u03c9 * . Here each matrix \u03bd i is a symmetric 3 \u00d7 3 matrix with entries \u03bd ijk = \u03bb i \u03c9 * jk . Also let us assume that the domain D is given in the form of bounds [l jk , u jk ] on the five unknown symmetric entries \u03c9 * jk of \u03c9 * . Then ( 6) can be re-written as arg min\n\u03c9 * ,\u03bdi,\u03bbi i \u03c9 * \u2212 H i \u221e \u03bd i H i \u221e 2 F (7) s.t. \u03bd ijk = \u03bb i \u03c9 * jk , \u03bb i h i 3 \u03c9 * h i 3 = 1 \u03c9 * 0, \u03c9 * 33 = 1, l jk \u2264 \u03c9 * jk \u2264 u jk\nThe non-convexity in the above optimization problem has been reduced to the bilinear equality constraints \u03bd ijk = \u03bb i \u03c9 * jk and \u03bb i h i 3 \u03c9 * h i 3 = 1. Given bounds on the entries of \u03c9 * , a relaxation of ( 7) is obtained by replacing the constraint \u03bb i h i 3 \u03c9 * h i 3 = 1 by a pair of linear inequalities of the form L i \u2264 \u03bb i \u2264 U i , where L i and U i are computed by simply inverting the bounds on h i 3 \u03c9 * h i 3 . Thus, the lower bound L i can be computed as the reciprocal of the result of the maximization problem:\nmax \u03c9 * h i 3 \u03c9 * h i 3 (8) s.t. \u03c9 * 33 = 1, \u03c9 * 0, l jk \u2264 \u03c9 * jk \u2264 u jk\nThe upper bound U i can be computed similarly by computing the reciprocal of the minimizer of the above. The relaxed optimization problem can now be stated as:\narg min \u03c9 * ,\u03bdi,\u03bbi i \u03c9 * \u2212 H i \u221e \u03bd i H i \u221e 2 F (9) s.t. \u03bd ijk = \u03bb i \u03c9 * jk , \u03c9 * 0, \u03c9 * 33 = 1 l jk \u2264 \u03c9 * jk \u2264 u jk , L i \u2264 \u03bb i \u2264 U i\nIn effect, the above ensures that the introduction of an additional view does not translate into an increase in the dimensionality of our search space. Instead, the cost is limited to solving a small SDP to compute bounds on \u03bb i , while the number of branching dimensions remains equal to number of unknowns in \u03c9 * , irrespective of the number of views.\nAppendix A.2 discusses the synthesis of convex relaxations of bilinear equalities, which allows us to replace each bilinear equality by a set of linear inequalities. Using them, a convex relaxation of the above optimization problem can be stated as arg min\n\u03c9 * ,\u03bdi,\u03bbi i \u03c9 * \u2212 H i \u221e \u03bd i H i \u221e 2 F (10) s.t. \u03bd ijk \u2264 U i \u03c9 * jk + l jk \u03bb i \u2212 U i l jk \u03bd ijk \u2264 L i \u03c9 * jk + u jk \u03bb i \u2212 L i u jk \u03bd ijk \u2265 L i \u03c9 * jk + l jk \u03bb i \u2212 L i l jk \u03bd ijk \u2265 U i \u03c9 * jk + u jk \u03bb i \u2212 U i u jk l jk \u2264 \u03c9 * jk \u2264 u jk , L i \u2264 \u03bb i \u2264 U i \u03c9 * 33 = 1, \u03c9 * 0\nThe objective function of the above optimization problem is convex quadratic. The constraint set includes linear inequalities and a positive semidefiniteness constraint. Such problems can be efficiently solved to their global optimum using interior point methods and a number of software packages exist for doing so. We use SeDuMi in this paper [24]. The user of the algorithm specifies valid ranges for the entries of the calibration matrix K. From this input, we derive intervals [l jk , u jk ] for the entries \u03c9 * jk of the matrix \u03c9 * using the rules of interval arithmetic [17].\n6 Global estimation of plane at infinity", "publication_ref": ["b23", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "Problem Formulation", "text": "Given more than the minimal number of views and in the presence of noise, the modulus constraints must be solved in a least squares sense. Previous work [19] has attempted to estimate of the plane at infinity by minimizing i (\u03b3 i \u03b1 3 i \u2212\u03b2 3 i ) 2 , using non-linear local minimization techniques. This cost function is a polynomial and some recent work in computer vision [14,5] exploits LMI relaxations to achieve global optimality in polynomial programs. However, this is a degree 8 polynomial in three variables, which is far beyond what present-day solvers [11,22] can handle. We instead consider the equivalent formulation:\nmin p1,p2,p3 i (\u03b3 1/3 i \u03b1 i \u2212 \u03b2 i ) 2 (11)", "publication_ref": ["b18", "b13", "b4", "b10", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Convex Relaxation", "text": "As an illustration of higher-level concepts, we show construction of convex underestimators for the non-convex objective in (11). The actual objective we minimize incorporates chirality bounds and is derived in Section 6.3. Let us suppose it is possible to derive a convex underestimator conv (\u03b3 i 1/3 \u03b1 i ) and concave overestimator\nconc (\u03b3 i 1/3 \u03b1 i ) for \u03b3 1/3 i \u03b1 i .\nThen the following convex optimization problem underestimates the solution to (11).\nmin p1,p2,p3 i (s i \u2212 \u03b2 i ) 2 (12) s.t. conv (\u03b3 i 1/3 \u03b1 i ) \u2264 s i \u2264 conc (\u03b3 i 1/3 \u03b1 i )\nAs shown in Appendix A.3, our convex and concave relaxations are piecewise linear and representable using a small set of linear inequalities. Thus the above optimization problem is a convex quadratic program that can be solved using a QP or an SOCP solver. Given bounds on {p 1 , p 2 , p 3 }, a branch and bound algorithm can now be used to obtain a global minimum to the modulus constraints. All that remains to be shown is that it is possible to estimate an initial region which bounds the coordinates of \u03c0 \u221e .", "publication_ref": ["b10", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "Incorporating the bounds on \u03c0 \u221e", "text": "One way to derive bounds on the coordinates of the plane at infinity is by using the chirality conditions overviewed in Section 2.3. Let v be the plane at infinity in the centered quasi-affine frame, where v = (v 1 , v 2 , v 3 , 1) , so that we can find bounds on each v i . However, the modulus constraints require that the first metric camera be of the form K [I|0] and the first projective camera have the form [I|0], which might not be satisfiable in a centered quasi-affine frame, in general. Thus, we need to use the bounds derived in the centered quasi-affine frame within the modulus constraints for the original projective frame.\nThe centered quasi-affine reconstruction differs from the projective one by a transformation H qa = H a H q , where H q takes the projective frame to some quasi-affine frame and H a is the affine centering in that quasi-affine frame. Let h i be the i-th column of H qa , then we have p i = h i v/h 4 v. Recall that, for the j-th view, \u03b1 j , \u03b2 j and \u03b3 j are affine expressions in p 1 , p 2 and p 3 [19]. Then, for instance,\n\u03b1 j = \u03b1 j1 p 1 + \u03b1 j2 p 2 + \u03b1 j3 p 3 + \u03b1 j4 = a j (v) d(v) ,(13)\nwhere\na j (v) = \u03b1 j1 h 1 v + \u03b1 j2 h 2 v + \u03b1 j3 h 3 v + \u03b1 j4 h 4 v and d(v) = h 4 v. Similary, let \u03b2 j = b j (v) d(v) , \u03b3 j = c j (v) d(v)(14)\nwhere a j (v), b j (v), c j (v), d(v) are linear functions of v. In the following, for the sake of brevity, we will drop the reference to v and just use a j , b j , c j , d. Now the optimization problem (11) can be rewritten as\nmin v1,v2,v3 j c 1/3 j a j \u2212 d 1/3 b j 2 d 8/3 , s.t. l i \u2264 v i \u2264 u i (15)\nIntroducing new scalar variables for some of the non-linear terms, the above is equivalent to\nmin v1,v2,v3 r (16) s.t. re \u2265 j (f j \u2212 g j ) 2 , l i \u2264 v i \u2264 u i f j = c 1/3 j a j , g j = d 1/3 b j , e = d 8/3\nAs we did for the case of the metric upgrade, we have reduced the non-convexity in the above optimization problem to a set of equality constraints. The quadratic inequality constraint is convex and is known as a rotated cone [4]. Given bounds on v i , it is easy to calculate bounds on a j , b j , c j , d, by solving eight linear programs in three variables. Given these bounds, we can construct convex and concave envelopes of the non-linear functions, and use them to construct the following convex program that underestimates the minimum of the above problem.\nmin v1,v2,v3 r (17) s.t. re \u2265 j (f j \u2212 g j ) 2 , j = 1, . . . , m conv c 1/3 j a j \u2264 f j \u2264 conc c 1/3 j a j conv d 1/3 b j \u2264 g j \u2264 conc d 1/3 b j e \u2264 conc (d 8/3 ), l i \u2264 v i \u2264 u i\nNotice that the convex envelope of d 8/3 is not needed. Since ( 17) is a minimization problem, e always takes its maximum possible value and does not require a lower bound. Following Appendix A, our convex relaxation in (17) consists of a linear objective subject to linear and SOCP constraints, which can be efficiently minimized [24]. A branch and bound algorithm can now be used to obtain an estimate of {v 1 , v 2 , v 3 }, which globally minimizes the modulus constraints. Thereafter, the plane at infinity in the projective frame can be recovered as \u03c0 \u221e = H qa v, which completes the projective to affine upgrade.", "publication_ref": ["b18", "b3", "b23"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "In this section, we will describe the experimental evaluation of our algorithms using synthetic and real data.\nFor evaluating performance metrics, we simulated a scene where 100 3D points are randomly generated in a cube with sides of length 20, centered at the origin and a varying number of cameras are randomly placed at a nominal distance of 40 units. Zero mean, Gaussian noise of varying standard deviation is added to the image coordinates. A projective transformation is applied to the scene with a known, randomly generated plane at infinity and the ground truth intrinsic calibration matrix is identity.\nFor various numbers of cameras and noise levels, errors in the estimation of the plane at infinity and the intrinsic parameters are tabulated in Table 1. The following metrics are defined for evaluation:\n\u2206p = 3 i=1 (p i /p 0 i \u2212 1) 2 , \u2206f = f 1 + f 2 f 0 1 + f 0 2 \u2212 1 \u2206uv = (|u| + |v|) \u2212 (|u 0 | + |v 0 |) /2, \u2206s = |s \u2212 s 0 |\nwhere p i are estimated coordinates of the plane at infinity, f 1 , f 2 represents the two focal lengths, (u, v) stands for the principal point and s for the skew. p 0 i , f 0 1 , f 0 2 , u 0 , v 0 and s 0 are the corresponding ground truth quantities.\nThe accuracy of the algorithm is evident from the very low error rates obtained for reasonable noise levels. It is interesting that the algorithm performs quite well even for noise as high as 1%. In general, the accuracy improves as expected when a greater number of cameras are used.\nThe column \u03c0 \u221e (1) in Table 1 reports the number of branch and bound iterations using the algorithm described in 6.3. However, an additional optimization is possible: we can refine the value of the feasible point f (q * ) using a gradient descent method within the rectangle that contains it. This does not compromise optimality, but allows the value of the current best estimate to be lower than the value corresponding to the minimum of the lower bounding function. The number of iterations with this refinement is tabulated under \u03c0 \u221e (2). The error metrics reported are computed using the refined algorithm, however, since both algorithms are run with the same very stringent tolerance ( = 1e \u2212 7), the solutions obtained are comparable. The number of iterations for the DIAC estimation (with no refinement) are tabulated under \u03c9 * . The metric upgrade setup was performed with = 1e \u2212 5.\nTypical time for each iteration of branch and bound is a few seconds on a Pentium IV, 1 GHz computer with 1GB of RAM. For 0.5% noise, each iteration of \u03c0 \u221e estimation takes about 4 seconds for 10 views and 14 seconds for 40 views. The corresponding times are 8 and 32 seconds for \u03c9 * estimation. Our code is unoptimized MATLAB with an off-the-shelf SDP solver [24], so these timings should be understood only as rough qualitative indicators.\nWhile the metrics above are intuitive for evaluating the intrinsic parameters, it is not readily evident how \u2206p must be interpreted. Towards that end, we perform a set of experiments, inspired by [19], where three mutually orthogonal 5 \u00d7 5 grids are observed by varying numbers of randomly placed cameras. Noise ranging from 0.1 to 1% is added to the image coordinates. Parallelism of the various grid lines is evaluated for the affine upgrade, while orthogonality and parallelism are measured in the metric reconstruction. The results are tabulated in Table 2\n(b).\nAgain, we observe that the algorithm achieves very good accuracy for reasonable noise and performs quite well even for 1% noise. With just 5 cameras, it is quite likely for the configuration to be ill-conditioned or degenerate, which causes the algorithm to break down in some cases.\nTo demonstrate performance on real data, we consider images of marker targets on two orthogonal walls (Figure 2(a)). Using image correspondences from detected corners, we perform a projective reconstruction using the projective factorization algorithm [26] followed by bundle adjustment. The normalization procedure and exact implementation follows the description in [10].\nBounds on the plane at infinity are computed using chirality (5) . The plane at infinity and DIAC are estimated using our algorithm. While ground truth measurements for the scene are not available, we can indirectly infer some observable properties.\n.\nThe coplanarity of the individual targets is indicated by the ratio of the first eigenvalue of the covariance matrix of their points to the sum of eigenvalues. This ratio is measured to be 3.1 \u00d7 10 \u22126 , 4.1 \u00d7 10 \u22125 , 6.2 \u00d7 10 \u22125 and 4.1 \u00d7 10 \u22124 for the four polygonal targets. The angle between the normals to the planes represented by two targets on the adjacent walls is 88.1 \u2022 in our metric reconstruction. The same angle is measured as 89.8 \u2022 in a reconstruction using [21]. The precise ground truth angle between the targets is unknown.\nAll the results that we have reported are for the raw output of our algorithm. In practice, a few iterations of bundle adjustment following our algorithms might be used to achieve a slightly better estimate.", "publication_ref": ["b23", "b18", "b25", "b9", "b4", "b20"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusions and further discussions", "text": "In this paper, we have presented globally minimal solutions to the affine and metric stages of stratified autocalibration. Although our cost function is algebraic, this is the first work that provides optimality guarantees for a scalable stratified autocalibration. We hope the methods presented here will be of use elsewhere in computer vision too.\nSeveral important extensions to the methods introduced in this paper can be envisaged. For instance, an L 1 -norm formulation will allow us to use an LP solver for the affine upgrade, making it possible to solve larger problems faster. Another important direction to pursue is the development of alternate bounding techniques for the plane at infinity besides chirality, which will allow us to use the simpler relaxation presented in Section 6.2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "The authors would like to thank Fredrik Kahl for several helpful discussions and providing data for the experiment with real images. We thank Marc Pollefeys for sharing the implementation of [21]. Manmohan   ", "publication_ref": ["b20"], "figure_ref": [], "table_ref": []}, {"heading": "A Convex and Concave Relaxations", "text": "In this appendix, we briefly describe the convex and concave relaxations of the intermediate non-linear terms that were relaxed as part of the various convex relaxations in the main text. In each instance, the variables x and y take values in the intervals [x l , x u ] and [y l , y u ], respectively.\nA.1 Functions of the form f (x) = x 8/3 The function x 8/3 is convex, and thus the line joining (x l , x   Error in affine and metric properties for three synthetically generated, mutually orthogonal planar grids. The table reports angular deviations from parallelism and orthogonality, measured in degrees. All quantities reported are averaged over 100 trials.\nthus the relaxation is given by\nA. \nA.3 Functions of the form f (x, y) = x 1/3 y\nWe now consider the construction of the convex relaxation for a bivariate function f (x, y) = x 1/3 y. Case 1: [x l > 0 or x u < 0] Suppose x l > 0, then f (x, y) is concave in x and convex in y. It can be shown [27] that the convex envelope for f (x, y) is given by\nNoting that f (x, y) = x 1/3 y, substituting y p = (1 \u2212 \u03bb)y a and simplifying results in the following convex relaxation:\nA concave relaxation for x 1/3 y can be constructed by considering the negative of the convex envelope of x 1/3 (\u2212y).", "publication_ref": ["b26"], "figure_ref": [], "table_ref": []}, {"heading": "This leads to", "text": "For the case when x u < 0, we observe that a convex relaxation for x 1/3 y is given by the negative of the concave relaxation of t 1/3 y, where t = \u2212x. Appropriate manipulation of (21) gives us the convex and concave envelopes for this case too.\nThe function x 1/3 is convex for x < 0 and concave for x > 0. The derivation in (21) depends critically on the convexity of x 1/3 over its domain, and thus, cannot be used for the case when x l \u2264 0 \u2264 x u . So instead of a one step relaxation, we will instead consider the two equality constraints t = x 1/3 , z = ty and relax each of them individually. Once we have the relaxation for t = x 1/3 , we can then apply the bilinear relaxation to z = ty.\nTo construct a concave overestimator for x 1/3 , we note that the line tangent to the curve x 1/3 and passing through (x l , x 1/3 l ) will always overestimate the curve. This line is given by t = (4x \u2212 x l )/3(\u2212x l ) 2/3 . Further, we can show that the point of tangency is (\u2212x l /8, \u2212x 1/3 l /2). Now if \u2212x l /8 < x u , then another line which upper bounds x 1/3 is the line passing through x l and tangent at (x u , x\nu . Thus, the overestimator for t = x 1/3 is given by the minimum of these two lines.\nFurther, when \u2212x l /8 \u2265 x u , we can get a better concave overestimator as simply the line passing through (x l , x ", "publication_ref": ["b20", "b20"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Practical global optimization for multiview geometry", "journal": "", "year": "2006", "authors": "S Agarwal; M Chandraker; F Kahl; S Belongie; D Kriegman"}, {"ref_id": "b1", "title": "On automatic determination of varying focal lengths using semidefinite programming", "journal": "", "year": "2004", "authors": "M "}, {"ref_id": "b2", "title": "Jointly constrained biconvex programming", "journal": "Math. Oper. Res", "year": "1983", "authors": "F ; J Falk"}, {"ref_id": "b3", "title": "Convex Optimization", "journal": "Cambridge University Press", "year": "2004", "authors": "S Boyd; L Vandenberghe"}, {"ref_id": "b4", "title": "Autocalibration via rank-constrained estimation of the absolute quadric", "journal": "", "year": "2007", "authors": "M Chandraker; S Agarwal; F Kahl; D Nist\u00e9r; D Kriegman"}, {"ref_id": "b5", "title": "Camera selfcalibration: Theory and experiments", "journal": "", "year": "1992", "authors": "O Faugeras; Q.-T Luong; S Maybank"}, {"ref_id": "b6", "title": "Globally convergent autocalibration using interval analysis", "journal": "PAMI", "year": "2004", "authors": "A Fusiello; A Benedetti; M Farenzena; A Busti"}, {"ref_id": "b7", "title": "", "journal": "Chirality. IJCV", "year": "1998", "authors": "R I Hartley"}, {"ref_id": "b8", "title": "Camera calibration and the search for infinity", "journal": "", "year": "1999", "authors": "R I Hartley; E Hayman; L De Agapito; I Reid"}, {"ref_id": "b9", "title": "Multiple View Geometry in Computer Vision", "journal": "Cambridge University Press", "year": "2004", "authors": "R I Hartley; A Zisserman"}, {"ref_id": "b10", "title": "GloptiPoly: Global optimization over polynomials with Matlab and SeDuMi", "journal": "ACM Trans. Math. Soft", "year": "2003", "authors": "D Henrion; J B Lasserre"}, {"ref_id": "b11", "title": "Euclidean reconstruction from constant intrinsic parameters", "journal": "", "year": "1996", "authors": "A Heyden; K \u00c5str\u00f6m"}, {"ref_id": "b12", "title": "Global Optimization: Deterministic Approaches", "journal": "Springer Verlag", "year": "2006", "authors": "R Horst; H Tuy"}, {"ref_id": "b13", "title": "Globally optimal estimates for geometric reconstruction problems", "journal": "", "year": "2005", "authors": "F Kahl; D Henrion"}, {"ref_id": "b14", "title": "Global optimization with polynomials and the problem of moments", "journal": "SIOPT", "year": "2001", "authors": "J B Lasserre"}, {"ref_id": "b15", "title": "Metric self calibration from screwtransform manifolds", "journal": "", "year": "2001", "authors": "R Manning; C Dyer"}, {"ref_id": "b16", "title": "Interval Analysis", "journal": "Prentice-Hall", "year": "1966", "authors": "R E Moore"}, {"ref_id": "b17", "title": "Untwisting a projective reconstruction", "journal": "IJCV", "year": "2004", "authors": "D Nist\u00e9r"}, {"ref_id": "b18", "title": "Stratified self-calibration with the modulus constraint", "journal": "PAMI", "year": "1999", "authors": "M Pollefeys; L V Gool"}, {"ref_id": "b19", "title": "Self-calibration and metric reconstruction in spite of varying and unknown internal camera parameters", "journal": "", "year": "1998", "authors": "M Pollefeys; R Koch; L Van Gool"}, {"ref_id": "b20", "title": "Surviving dominant planes in uncalibrated structure and motion recovery", "journal": "", "year": "2002", "authors": "M Pollefeys; F Verbiest; L J V Gool"}, {"ref_id": "b21", "title": "Introducing SOSTOOLS: a general purpose sum of squares programming solver", "journal": "", "year": "2002", "authors": "S Prajna; A Papachristodoulou; P Parrilo"}, {"ref_id": "b22", "title": "Direct solution of modulus constraints", "journal": "", "year": "2000", "authors": "F Schaffalitzky"}, {"ref_id": "b23", "title": "Using SeDuMi 1.02, a Matlab toolbox for optimization over symmetric cones", "journal": "Opt. Meth. and Soft", "year": "1999", "authors": "J Sturm"}, {"ref_id": "b24", "title": "A case against Kruppa's equations for camera self-calibration", "journal": "PAMI", "year": "2000", "authors": "P Sturm"}, {"ref_id": "b25", "title": "A factorization based algorithm for multi-image projective structure and motion", "journal": "", "year": "1996", "authors": "P Sturm; B Triggs"}, {"ref_id": "b26", "title": "Convex extensions and envelopes of lower semi-continuous functions", "journal": "Math. Prog", "year": "2002", "authors": "M Tawarmalani; N Sahinidis"}, {"ref_id": "b27", "title": "Autocalibration and the absolute quadric", "journal": "", "year": "1997", "authors": "B Triggs"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Focal lengths are assumed to lie in the interval [500, 1500], principal point within [250, 450] \u00d7 [185, 385] (image size is 697 \u00d7 573) and skew [\u22120.1, 0.1]", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "P i =P i H \u22121 , X j = HX j .", "formula_coordinates": [2.0, 117.16, 348.19, 102.16, 11.72]}, {"formula_id": "formula_1", "formula_text": "1 = K 1 [I|0]. Then H has the form H = K 1 0 \u2212p K 1 1 (1)", "formula_coordinates": [2.0, 49.8, 463.65, 238.3, 55.47]}, {"formula_id": "formula_2", "formula_text": "Let P i = [A i |a i ] where A i is 3 \u00d7 3 and a i is a 3 \u00d7 1 vector. Let P i = K i [R i |t i ].", "formula_coordinates": [2.0, 50.11, 583.84, 237.99, 21.64]}, {"formula_id": "formula_3", "formula_text": "\u03c9 * = (A i \u2212 a i p )\u03c9 * (A i \u2212 a i p )(2)", "formula_coordinates": [2.0, 96.65, 630.0, 189.72, 11.72]}, {"formula_id": "formula_4", "formula_text": "H i \u221e = (A i \u2212 a i p )", "formula_coordinates": [2.0, 50.11, 678.71, 80.98, 12.19]}, {"formula_id": "formula_5", "formula_text": "det(\u03bbI \u2212 (A i \u2212 a i p )) = \u03bb 3 \u2212 \u03b1 i \u03bb 2 + \u03b2 i \u03bb \u2212 \u03b3 i . (3)", "formula_coordinates": [2.0, 320.52, 134.75, 224.6, 11.72]}, {"formula_id": "formula_6", "formula_text": "\u03b3 i \u03b1 3 i = \u03b2 3 i ,(4)", "formula_coordinates": [2.0, 403.97, 179.35, 141.14, 12.69]}, {"formula_id": "formula_7", "formula_text": "min / max v i s.t. X q j v > 0, C q k v > 0,(5)", "formula_coordinates": [2.0, 325.25, 449.32, 219.86, 13.91]}, {"formula_id": "formula_8", "formula_text": "k | \u2192 0, f lb (Q k ) \u2192 f min (Q k ) uniformly.", "formula_coordinates": [3.0, 78.19, 667.8, 160.89, 9.81]}, {"formula_id": "formula_9", "formula_text": "tions \u03c9 * = H i \u221e \u03c9 * H i \u221e , i = 1, \u2022 \u2022 \u2022 , m.", "formula_coordinates": [3.0, 308.86, 382.68, 151.47, 12.19]}, {"formula_id": "formula_10", "formula_text": "arg min \u03c9 * ,\u03bbi i \u03c9 * \u2212 \u03bb i H i \u221e \u03c9 * H i \u221e 2 F (6) s.t. \u03c9 * 33 = 1, \u03bb i h i 3 \u03c9 * h i 3 = 1, \u03c9 * 0, \u03c9 * \u2208 D", "formula_coordinates": [3.0, 314.69, 512.71, 230.42, 40.01]}, {"formula_id": "formula_11", "formula_text": "\u03c9 * ,\u03bdi,\u03bbi i \u03c9 * \u2212 H i \u221e \u03bd i H i \u221e 2 F (7) s.t. \u03bd ijk = \u03bb i \u03c9 * jk , \u03bb i h i 3 \u03c9 * h i 3 = 1 \u03c9 * 0, \u03c9 * 33 = 1, l jk \u2264 \u03c9 * jk \u2264 u jk", "formula_coordinates": [4.0, 84.65, 107.19, 201.71, 58.56]}, {"formula_id": "formula_12", "formula_text": "max \u03c9 * h i 3 \u03c9 * h i 3 (8) s.t. \u03c9 * 33 = 1, \u03c9 * 0, l jk \u2264 \u03c9 * jk \u2264 u jk", "formula_coordinates": [4.0, 82.29, 293.08, 204.08, 32.02]}, {"formula_id": "formula_13", "formula_text": "arg min \u03c9 * ,\u03bdi,\u03bbi i \u03c9 * \u2212 H i \u221e \u03bd i H i \u221e 2 F (9) s.t. \u03bd ijk = \u03bb i \u03c9 * jk , \u03c9 * 0, \u03c9 * 33 = 1 l jk \u2264 \u03c9 * jk \u2264 u jk , L i \u2264 \u03bb i \u2264 U i", "formula_coordinates": [4.0, 75.79, 376.77, 210.58, 56.35]}, {"formula_id": "formula_14", "formula_text": "\u03c9 * ,\u03bdi,\u03bbi i \u03c9 * \u2212 H i \u221e \u03bd i H i \u221e 2 F (10) s.t. \u03bd ijk \u2264 U i \u03c9 * jk + l jk \u03bb i \u2212 U i l jk \u03bd ijk \u2264 L i \u03c9 * jk + u jk \u03bb i \u2212 L i u jk \u03bd ijk \u2265 L i \u03c9 * jk + l jk \u03bb i \u2212 L i l jk \u03bd ijk \u2265 U i \u03c9 * jk + u jk \u03bb i \u2212 U i u jk l jk \u2264 \u03c9 * jk \u2264 u jk , L i \u2264 \u03bb i \u2264 U i \u03c9 * 33 = 1, \u03c9 * 0", "formula_coordinates": [4.0, 91.45, 590.19, 194.91, 121.04]}, {"formula_id": "formula_15", "formula_text": "min p1,p2,p3 i (\u03b3 1/3 i \u03b1 i \u2212 \u03b2 i ) 2 (11)", "formula_coordinates": [4.0, 372.86, 383.22, 172.25, 23.05]}, {"formula_id": "formula_16", "formula_text": "conc (\u03b3 i 1/3 \u03b1 i ) for \u03b3 1/3 i \u03b1 i .", "formula_coordinates": [4.0, 308.86, 507.18, 106.48, 14.07]}, {"formula_id": "formula_17", "formula_text": "min p1,p2,p3 i (s i \u2212 \u03b2 i ) 2 (12) s.t. conv (\u03b3 i 1/3 \u03b1 i ) \u2264 s i \u2264 conc (\u03b3 i 1/3 \u03b1 i )", "formula_coordinates": [4.0, 329.73, 544.88, 215.39, 37.8]}, {"formula_id": "formula_18", "formula_text": "\u03b1 j = \u03b1 j1 p 1 + \u03b1 j2 p 2 + \u03b1 j3 p 3 + \u03b1 j4 = a j (v) d(v) ,(13)", "formula_coordinates": [5.0, 65.51, 313.59, 220.85, 22.31]}, {"formula_id": "formula_19", "formula_text": "a j (v) = \u03b1 j1 h 1 v + \u03b1 j2 h 2 v + \u03b1 j3 h 3 v + \u03b1 j4 h 4 v and d(v) = h 4 v. Similary, let \u03b2 j = b j (v) d(v) , \u03b3 j = c j (v) d(v)(14)", "formula_coordinates": [5.0, 50.11, 348.76, 236.39, 54.95]}, {"formula_id": "formula_20", "formula_text": "min v1,v2,v3 j c 1/3 j a j \u2212 d 1/3 b j 2 d 8/3 , s.t. l i \u2264 v i \u2264 u i (15)", "formula_coordinates": [5.0, 55.36, 470.87, 231.0, 33.06]}, {"formula_id": "formula_21", "formula_text": "min v1,v2,v3 r (16) s.t. re \u2265 j (f j \u2212 g j ) 2 , l i \u2264 v i \u2264 u i f j = c 1/3 j a j , g j = d 1/3 b j , e = d 8/3", "formula_coordinates": [5.0, 75.53, 547.59, 210.83, 62.21]}, {"formula_id": "formula_22", "formula_text": "min v1,v2,v3 r (17) s.t. re \u2265 j (f j \u2212 g j ) 2 , j = 1, . . . , m conv c 1/3 j a j \u2264 f j \u2264 conc c 1/3 j a j conv d 1/3 b j \u2264 g j \u2264 conc d 1/3 b j e \u2264 conc (d 8/3 ), l i \u2264 v i \u2264 u i", "formula_coordinates": [5.0, 328.54, 109.04, 216.58, 103.7]}, {"formula_id": "formula_23", "formula_text": "\u2206p = 3 i=1 (p i /p 0 i \u2212 1) 2 , \u2206f = f 1 + f 2 f 0 1 + f 0 2 \u2212 1 \u2206uv = (|u| + |v|) \u2212 (|u 0 | + |v 0 |) /2, \u2206s = |s \u2212 s 0 |", "formula_coordinates": [5.0, 313.09, 573.13, 227.79, 46.14]}, {"formula_id": "formula_24", "formula_text": "(b).", "formula_coordinates": [6.0, 170.52, 497.59, 15.27, 8.64]}], "doi": ""}