{"title": "A Demonstration of Compositional, Hierarchical Interactive Task Learning", "authors": "Aaron Mininger; John E Laird", "pub_date": "", "abstract": "We present a demonstration of the interactive task learning agent Rosie, where it learns the task of patrolling a simulated barracks environment through situated natural language instruction. In doing so, it builds a sizable task hierarchy composed of both innate and learned tasks, tasks formulated as achieving a goal or following a procedure, tasks with conditional branches and loops, and involving communicative and mental actions. Rosie is implemented in the Soar cognitive architecture, and represents tasks using a declarative task network which it compiles into procedural rules through chunking. This is key to allowing it to learn from a single training episode and generalize quickly.", "sections": [{"heading": "Introduction", "text": "As general-purpose, interactive learning robots become more capable and prevalent, it should be possible to direct, customize, and extend them without expert programming or hundreds of demonstrations. Research interactive task learning (ITL) (Gluck and Laird 2019) seeks to develop AI agents that learn new tasks through online interaction.\nRosie is an agent that learns new tasks and using one-shot Situated Interactive Instruction (SII). The instructor and the agent are situated in a shared environment, engaged in bidirectional interaction, and communication via natural language instruction. Language enables a skilled instructor to provide the agent with precise learning goals as well as curated, high quality situation-specific task instructions. In this demonstration, we show Rosie learning online a complex, embodied task, called interior guard, in a simulated barracks environment from a single training episode.\nRosie is developed within the Soar cognitive architecture (Laird 2012). Soar contains a symbolic working memory, a metric spatial memory, procedural and declarative long term memories, and several learning mechanisms, which support perception, communication, hierarchical planning and decision making, metacognition, and learning. Rosie uses SII to learn many different types of knowledge, including perceptual features and spatial relationships (Mohan et al. 2012), hierarchical state-based concepts (Kirk and Laird 2019), games and puzzles (Kirk and Laird 2016), hierarchical goal-Copyright \u00a9 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. based tasks (Mohan and Laird 2014), and hierarchical procedural tasks (Mininger and Laird 2018). Interior guard is the most complex and longest task Rosie has learned, including deep hierarchies of procedural and goal-based subtasks that include navigation, communication, and mental operations.", "publication_ref": ["b4", "b7", "b15", "b6", "b5", "b14", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "Learning from human instruction goes back to SHRDLU (Winograd 1972), and work by Crangle and Suppes (1994), who developed foundational ideas about the notion of an instructable robot that learns tasks from instruction. However, even today there are few examples of such agents.\nSeveral approaches involve learning blocks-world style tasks in a tabletop setting, Frasca et al. (2018), Suddrey et al. (2016), She and Chai (2017), that do not involve the complexity of interior guard. Work by Mohseni-Kabir et al. (2019) combines learning a simple hierarchical task networks (HTN) with learning action primitives for a simulated tire rotation task. However, the language is limited and the HTN does not support reuse or generalization. ITL work has also been done with software agents, such as PLOW (Allen et al. 2007) and SUGILITE (Li, Mitchell, and Myers 2020).\nThere has been work involving learning tasks with a mobile robot. For example, Meri\u00e7li et al. (2013) teach a mobile robotic agent tasks such as getting coffee and following landmarks. However, the task learning is not compositional and has limited generalization. A similar agent from Gemignani, Bastianelli, and Nardi (2015) can learn parameterized procedures, but not hierarchical tasks.  ", "publication_ref": ["b19", "b1", "b2", "b18", "b17", "b16", "b0", "b8", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "Agent Overview", "text": "Rosie is a fully integrated end-to-end agent that performs perceptual processing and sends motor commands (Mininger and Laird 2019) in both real-world and simulated domains. Dialog is through a chat interface, with Rosie taking the initiative to ask questions. When it receives a response, it parses the language using the current context, grounding referents as appropriate (Lindes et al. 2017). The result is a precise, semantic structure, that Rosie then interprets within the current context. For new tasks, Rosie creates and stores a Task Concept Network (TCN) in semantic memory. It contains the task arguments, subtasks, and goal graph, as well as their connections. The goal graph is a directed graph consisting of subgoal nodes that include desired state predicates (e.g., the plate is in the sink) or a subtask to perform (e.g., inspect the messhall). Executing a task involves interpreting the nodes and control information in the TCN, which can involve following a procedure (including conditionals and loops), a learned policy, or planning. As the agent processes the TCN knowledge, it learns rules that avoid interpretation and perform the processing directly. When a task or subtask is complete, the agent learns a statebased policy for future performance derived from a retrospective analysis of its behavior. As shown above, learned tasks in Rosie are truly compositional, so it can build up hierarchical tasks from previously learned subtasks.", "publication_ref": ["b13", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "Interior Guard Demo", "text": "This demo occurs in a simulated, multi-room barracks environment (Figure 1) that supports realistic navigation. Actions involving objects are discrete and the perception involves error-free object detection and classification. The agent starts with knowledge of objects, people, locations, navigation, and simple actions. However, it has no specific knowledge related to guarding or patrolling.\nThe agent first learns three major tasks (Figure 2). It learns to inspect a room, with particular instructions given depending on the type of room. For a sentry post, it ensures that both a fire extinguisher and sentry are present. However, for the mess hall, it learns to store condiments and clean up plates, and for the motor pool, to lock vehicles. The agent also learns how to raise a fire alarm by pulling the alarm and reporting the location to the commanding officer (CO). Then it learns the overall guard task, where it asks the CO the name of the relieving officer, then repeats a patrol route until it sees that person. The full training scenario takes 17 minutes to teach and involves 224 individual tasks. After this instruction sequence, the agent is told to perform the guard task, with some variation. This final scenario takes 28 minutes and involves 389 individual tasks, which the agent accomplishes without asking any additional questions.\nFigure 3 shows the full learned task hierarchy, with the learned tasks in the blue shaded rectangles. In addition to being a larger in scope than related work, it demonstrates several distinguishing capabilities, referenced by their letters in the figure. First, tasks can be represented as achieving a set of goal predicates (G) or following a procedure (P). For example, the goal of storing a condiment is that the condiment is in the fridge and the fridge is closed. Second, tasks can include branches (B) in the goal graph that represent conditional subtasks or goals, as well as loops (L). For example, the agent only fetches a fire extinguisher when inspecting a sentry post and if there is no fire extinguisher present. Third, tasks can involving communicative (C) and mental (M) actions. For example, the agent learns to ask who the relieving officer is, then remembers the answer for later use. A key contribution of this work is that the agent learns and uses a unified representation that enables it to compose all different types of tasks within the same hierarchy. Some limitations include restrictions on the language, and the amount of variation possible in a particular task; a focus of future work.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Plow: A collaborative task learning agent", "journal": "", "year": "2007", "authors": "J Allen; N Chambers; G Ferguson; L Galescu; H Jung; M Swift; W Taysom"}, {"ref_id": "b1", "title": "Language and learning for robots", "journal": "", "year": "1994", "authors": "C Crangle; P Suppes"}, {"ref_id": "b2", "title": "One-shot interaction learning from natural language instruction and demonstration", "journal": "", "year": "2018", "authors": "T Frasca; B Oosterveld; E Krause; M Scheutz"}, {"ref_id": "b3", "title": "Teaching robots parametrized executable plans through spoken interaction", "journal": "", "year": "2015", "authors": "G Gemignani; E Bastianelli; D Nardi"}, {"ref_id": "b4", "title": "Interactive Task Learning: Humans, Robots, and Agents Acquiring New Tasks Through Natural Interactions", "journal": "MIT Press", "year": "2019", "authors": "K A Gluck; J E Laird"}, {"ref_id": "b5", "title": "Learning general and efficient representations of novel games through interactive instruction", "journal": "", "year": "2016", "authors": "J R Kirk; J E Laird"}, {"ref_id": "b6", "title": "Learning hierarchical symbolic representations to support interactive task learning and knowledge transfer", "journal": "AAAI Press", "year": "2019", "authors": "J R Kirk; J E Laird"}, {"ref_id": "b7", "title": "The Soar cognitive architecture", "journal": "MIT Press", "year": "2012", "authors": "J Laird"}, {"ref_id": "b8", "title": "Interactive Task Learning from GUI-Grounded Natural Language Instructions and Demonstrations", "journal": "", "year": "2020", "authors": "T J Li; .-J Mitchell; T Myers; B "}, {"ref_id": "b9", "title": "Annual Meeting of the Association for Computational Linguistics: System Demonstrations", "journal": "", "year": "", "authors": ""}, {"ref_id": "b10", "title": "Grounding language for interactive task learning", "journal": "", "year": "2017", "authors": "P Lindes; A Mininger; J R Kirk; J E Laird"}, {"ref_id": "b11", "title": "An interactive approach for situated task teaching through verbal instructions", "journal": "", "year": "2013", "authors": "C Meri\u00e7li; S D Klee; J Paparian; M Veloso"}, {"ref_id": "b12", "title": "Interactively learning a blend of goal-based and procedural tasks", "journal": "", "year": "2018", "authors": "A Mininger; J E Laird"}, {"ref_id": "b13", "title": "Using Domain Knowledge to Correct Anchoring Errors in a Cognitive Architecture", "journal": "", "year": "2019", "authors": "A Mininger; J E Laird"}, {"ref_id": "b14", "title": "Learning Goal-Oriented Hierarchical Tasks from Situated Interactive Instruction", "journal": "", "year": "2014", "authors": "S Mohan; J E Laird"}, {"ref_id": "b15", "title": "Acquiring grounded representations of words with situated interactive instruction", "journal": "", "year": "2012", "authors": "S Mohan; A H Mininger; J R Kirk; J E Laird"}, {"ref_id": "b16", "title": "Simultaneous learning of hierarchy and primitives for complex robot tasks", "journal": "Autonomous Robots", "year": "2019", "authors": "A Mohseni-Kabir; C Li; V Wu; D Miller; B Hylak; S Chernova; D Berenson; C Sidner; C Rich"}, {"ref_id": "b17", "title": "Interactive Learning of Grounded Verb Semantics towards Human-Robot Communication", "journal": "", "year": "2017", "authors": "L She; J Chai"}, {"ref_id": "b18", "title": "Teaching robots generalizable hierarchical tasks through natural language instruction", "journal": "IEEE Robotics and Automation Letters", "year": "2016", "authors": "G Suddrey; C Lehnert; M Eich; F Maire; J Roberts"}, {"ref_id": "b19", "title": "Understanding natural language. Cognitive psychology", "journal": "", "year": "1972", "authors": "T Winograd"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: The simulated barracks environment.", "figure_data": ""}, {"figure_label": "23", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :Figure 3 :23Figure 2: Instructions used to teach the three main tasks, Rosie's dialog is omitted.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Inspect the eastern SP. Go to the eastern SP. If the lightswitch is off, then turn the lightswitch on. If you are in a SP and an FE is not present, then fetch a FE from the supply room. If you are in a SP, then ensure a sentry is present. If the current location is empty, then turn off the lightswitch. Go to the eastern hallway. Turn on the alarm. Say \"There is a fire.\" to the CO. Describe the emergency location.CO: Commanding Officer Guard the barracks. Ask \"Who is my relieving officer?\" Remember the answer as the relieving officer. Repeat the following tasks until the relieving officer is present. Inspect the messhall. Inspect the eastern SP. Inspect the motorpool. Repeat.", "figure_data": "Raise a fire-alarm.Remember the current locationas the emergency location.SP: Sentry PostFE: Fire Extinguisher"}], "formulas": [], "doi": ""}