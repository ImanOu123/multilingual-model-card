{"title": "Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment", "authors": "Eshaan Tanwar; Subhabrata Dutta; Manish Borthakur; Tanmoy Chakraborty", "pub_date": "", "abstract": "In-context learning (ICL) unfolds as large language models become capable of inferring test labels conditioned on a few labeled samples without any gradient update. ICL-enabled large language models provide a promising step forward toward bypassing recurrent annotation costs in a low-resource setting. Yet, only a handful of past studies have explored ICL in a cross-lingual setting, in which the need for transferring label-knowledge from a high-resource language to a low-resource one is immensely crucial. To bridge the gap, we provide the first in-depth analysis of ICL for cross-lingual text classification. We find that the prevalent mode of selecting random inputlabel pairs to construct the prompt-context is severely limited in the case of cross-lingual ICL, primarily due to the lack of alignment in the input as well as the output spaces. To mitigate this, we propose a novel prompt construction strategy -Cross-lingual In-context Source-Target Alignment (X-InSTA). With an injected coherence in the semantics of the input examples and a task-based alignment across the source and target languages, X-InSTA is able to outperform random prompt selection by a large margin across three different tasks using 44 different cross-lingual pairs. Review: cannot operate this without using 2 hands. doesnt that defeat the point of using it in the .. ... Review: they were nice but too big. Rating: Review: So unhappy with these! Hold no charge and stopped working after a few,Probably ... ... Review: Failed on first day of use. It worked fine for a while, maybe 30 minutes of intermittent us Examen: Bonjour, En fait, j'ai un probleme avec cette commande. Certaines pieces manquent. Je vous joins la photo du syst\u00e8me apr\u00e8s montage. Les 2 pieces bleues en plastique a fixer aux extr\u00e9mit\u00e9s des bras tournants n'ont pas \u00e9t\u00e9 livrees dans le colis. Pourriez vous me les faire parvenir. Salutations. Loic Menez \u00c9valuation: Review: Piece of junk! It comes in a million little pieces with no instructions on how to put together. T... ... Review: I don't know... I received had a cracked plastic piece Review: cannot operate this without using 2 hands. doesnt that defeat the point of using it in the... ... Review: they were nice but too big. Rating:.. In French bad means mal and good means bien. Examen: j ai commenc\u00e9 a \u00e9crire correctement puis au bout de 10 lignes l'encre commence a sortir difficilement je suis tr\u00e8s d\u00e9\u00e7u de la qualit\u00e9 de ces recharges je ne pense pas que ce soit des recharges mont banc malgr\u00e9 l'emballage.....je vais faire une r\u00e9clamation \u00c9valuation: Review: cannot operate this without using 2 hands. doesnt that defeat the point of using it in the... ... Review: they were nice but too big. Rating:.. In French bad means mal and good means bien.", "sections": [{"heading": "Introduction", "text": "The emergence of large-scale, pretrained, Transformer-based language models (LLMs) has marked the commencement of an avant-garde era in NLP. Departing from the traditional methods of neural language learning with temporally separated training-testing phases for downstream tasks, pretrained LLMs have shown the ability to infer labels from test inputs conditioned on the training data within a single pass. This is known as In-context learning -an LLM is prompted ET and SD contributed equally. ET and SD designed the experiments. ET and MB ran the experiments. SD and TC wrote the paper. TC mentored the project.\nwith a few input-output pairs from the training data (commonly referred to as demonstrations) followed by the test input; for generative tasks (summarization, text-to-code, chain-of-thought reasoning, etc.) the LLM is then required to produce an output; for classification tasks, the probabilities of the next tokens predicted by the LLM are mapped to the label space. All of this is done without updating the parameters of the LLM. In-context learning is particularly promising for two different aspects. Firstly, it reduces the need for task-specific training data, and thus, the cost of human annotation. Secondly, while the LLM was trained in a compute-intensive environment, the removal of the need for task-specific gradientbased weight updates can significantly reduce the carbon footprint of automated NLP/NLU since the inference-time compute-necessity is orders of magnitude smaller than that of the training/finetuning phases.\nMultiple recent advancements have been proposed to optimize the ICL ability of the LLMs (Lin et al., 2021;Chowdhery et al., 2022;Liu et al., 2022;Zhang et al., 2021).\nChallenges in cross-lingual ICL: Given that there is an order-of-magnitude discrepancy in the availability of annotated data in a high-resource language vs. a low-resource one, the ability to learn from the high-resource source context to solve tasks in low-resource targets sounds enticing. Yet, the application of ICL in a cross-lingual setting remains largely unexplored. Previous attempts at multilingual ICL (Zhang et al., 2021;Winata et al., 2021) use randomly selected input-label pairs to construct the prompt-context. This limits the ability of an LLM to infer from the context. As Xie et al. (2022) suggested, ICL emerges as the ability to infer target labels from the pretraining distribution conditioned upon the context; each input-label pair in the prompt-context are, in turn, sampled from the prompt token distribution. Theoretically, Review: Great pen set. I love the colors and the writing is very smooth. A few of the pens I received were broken upon... ... ..arrived cracked and broken. a very bad experience..... In French bad means mal and good means bien.", "publication_ref": ["b24", "b5", "b13", "b28", "b28", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Input", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Random:", "text": "Semantic aligned: Task aligned:\nSemantic aligned:", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Input", "text": "Task aligned:", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Input", "text": "Examen: Apr\u00e8s seulement une petite semaine d'utilisation ou une vingtaine d'heure, en plus utilisation peu intensive la carte a subitement d\u00e9cider de ne plus fonctionner. Ayant retrouver plusieurs commentaires pr\u00e9sentant le m\u00eame probl\u00e8me le d\u00e9faut doit donc \u00eatre r\u00e9current je d\u00e9conseille vivement d'acheter cette carte sur amazon. \u00c9valuation:", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "1). 2). 3).", "text": "Task and Semanticaligned: Figure 1: Working example of different ICL prompts explored in this work. In example #1, randomly selecting the prompt examples fails as it prompts irrelevant contradictions, whereas semantic alignment succeeds as it makes the context with similar reviews. In example #2, semantic alignment fails; it extracts demonstrations about 'multiple pieces', but these are not helpful for the LLM, whereas a simple task aligner works. In the last example, it is a combination of semantic and task alignments that works.\nthe expected prediction error decreases as the number of examples in the prompt increases. However, such infinitely long prompts are practically infeasible to attain. Xie et al. (2022) imposed that a distinguishability of the prompt-concept, shared across the prompt-examples, from all other possible concepts is essential for an optimal predictor. A random sampling of prompt examples is unlikely to construct a prompt with distinguishable concepts. Furthermore, given (x i , y i ) and (x i+1 , y i+1 ) as two consecutive input-label pairs in the promptcontext, the transition probability from y i to x i+1 is a low-probability one under the pretraining distribution (Xie et al., 2022). The transition becomes even more improbable if we are to simply append a test example to the prompt-context of a different language. Consider the following example of ICL prompting for cross-lingual sentiment classification:\n1. That movie was good. Positive 2. Depression is the new pandemic. Negative 3. Ella lo est\u00e1 haciendo bien ?\nThe text segments are concatenated from left-toright and top-to-bottom; therefore, two English input-label pairs are followed by a Spanish test input. There are irremovable, token-level lowprobability transitions from the labels to the next input sentences. On top of this, we have three completely unrelated sentences juxtaposed together with an abrupt change in language. Intuitively, it is less likely for an LLM to be able to map the third input to its correct label, positiva (positive in Spanish) following the very much convoluted patterns presented in English.\nProposed approach: We seek to develop prompt-design strategies for ICL in a cross-lingual setting that can overcome the foregoing challenges. A two-way alignment of the source and target examples is proposed. We start with injecting semantic coherence into the prompt-context by selecting similar examples; this aligns the labeled demonstrations as well as the test inputs to share a set of common concepts. Next, we seek to enforce an alignment of task-level signals across languages. We introduce manually-designed task-specific mappings from the source language to the target language, thereby providing the LLM with a 'natural' transition from the former to the latter. Together, these two approaches constitute our proposed prompts-selection strategy, X-InSTA (Crosslingual In-context Source-Target Alignment, see Figure 1 for working examples). X-InSTA shows a staggering 18% relative improvement over random prompt selection averaged across three different text classification tasks in multiple different languages with English being the source language. Careful perturbations to these alignment methods disclose the importance of label space structure induced by LLMs for cross-lingual ICL.\nOur contributions are summarized below 1 : 1. We propose X-InSTA, a novel method of aligning prompt examples in a cross-lingual scenario. To the best of our knowledge, this is the first at-tempt to push prompt design techniques for ICL in cross-lingual settings beyond the trivial strategy of random example selection. 2. We present the first, in-depth analysis of the role of semantic similarity between prompt examples for cross-lingual ICL. 3. A novel concept of task-based prompt alignment is presented. We show its efficacy with 44 different source-target language pairs and empirically relate this to the underlying structures of multilingual representations of the LLM.", "publication_ref": ["b25", "b25"], "figure_ref": [], "table_ref": []}, {"heading": "Prompting Techniques", "text": "In this section, we lay out a step-by-step approach to aligning semantic coherence and taskbased signals across source-target examples for ICL prompts.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Prelimineries", "text": "Let D s = {(x i\ns , y i s )} i be a monolingual labeled dataset in language s, realized as a collection of input examples and their labels, x i s \u2208 X s and y i s \u2208 Y s , respectively. Here Y s is the natural language label space in language s. We have another collection of input examples, D t = {x i t } i , with examples in language t. One can define a crosslingual text classification task with source and target languages being s and t in the following manner. First, we select k input-label pairs from D s to construct the prompt-context, C:\nC = x 1 s \u2295 y 1 s \u2295 [sep] \u2295 \u2022 \u2022 \u2022 x k s \u2295 y k s (1)\nwhere [sep] denotes a separator token (e.g., newlines), and \u2295 denotes the concatenation operator. The problem of in-context prediction then translates to inferring the label y t \u2208 Y t , where Y t is the natural language label space in language t corresponding to the test input x t \u2208 D t conditioned on the prompt-context C, as follows:\ny t = argmax y\u2208Yt p(y|C \u2295 x t )\ni.e., we select the maximum probability label in the target label space generated by the model as the token next to the test input x t appended to the context C. The source and target label spaces, Y s and Y t , share a one-to-one mapping among each other in terms of translation from s to t.\nOne of the most widely-used methods of constructing the context C, which we will henceforth call random prompting, is to randomly select (x i s , y i s ) from D s and concatenate together. We explore this method in our analysis, and it serves as a baseline for our experiments.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Semantic Alignment", "text": "Chang et al. (2022) showed that multilingual models encode these languages in a shared embedding space, while still preserving several languagesensitive semantic information. Despite the language difference between source and target inputs, x s and x t , it is then likely that their semantic similarities will be reflected in their hidden representations constructed by LLM. Therefore, we hypothesize that choosing semantically similar examples to construct the prompt-context would help the model do in-context inference. That is, if e t is the embedding of the target and e s that of the source, the higher the similarity score between them, the better sentence x s will serve as a demonstration for the target sentence x t .\nInspired by Liu et al. (2022), we extract prompt examples directly dependent on the test input distribution. Here we utilize multilingual sentencetransformers (Reimers and Gurevych, 2020) to extract the sentence embedding of the test input x t \u2208 D t and the source inputs X s . Based on the cosine similarity between the target input x j t and source inputs x j s \u2208 X s , we then extract the top k demonstrations (see Algorithm 1). While the target input and the demonstration differ in language, we hypothesize that by pairing semantically similar context demonstration and input sentence, the LLM would be able to improve its reasoning ability and subsequently, the final task performance (see Table 11 in Appendix D for examples of such aligned demonstrations).", "publication_ref": ["b13", "b20"], "figure_ref": [], "table_ref": ["tab_1"]}, {"heading": "Algorithm 1: Semantic Alignment", "text": "Input: An unlabeled target sentence xt, source data Ds, multilingual sentence encoder, \u03b8, and number of samples to extract k.\nProcedure: et \u2190 \u03b8(xt) for x s \u2208 Ds do e i s \u2190 \u03b8(x i s ) si \u2190 e t .e i s ||e t || 2 ||e i s || 2 end Select top k sentences based on si C \u2190 x 1 s \u2295 y 1 s \u2295 [sep] \u2295 \u2022 \u2022 \u2022 x k s \u2295 y k s yt = argmax y\u2208Y t p(y|C \u2295 xt)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Task-based Alignment", "text": "Despite the semantic coherence enforced within the prompt-context via the previously mentioned method, the source and target label spaces, Y s and Y t , remain superficially disconnected. For fine-tuning, techniques like meta-learning (Nooralahzadeh et al., 2020), and adapters (Parovi\u0107 et al., 2022) have been used to bridge this gap. For in-context prompting in which context matters the most, we propose to do so by adding a manually designed statement that gives the LLM task-specific information like target language and target label space.\nTask-based alignment is done by appending a manually-designed statement, called task aligner to context. This aligner is supposed to inform the LLM about the mapping from the source label space Y s to the target label space Y t . We do task alignment by first manually creating D l = {L s,t } for a given task and source-target language pairs s and t as a collection of statements in the source language that emphasizes what the target label and language are. For example, when the source is English and the target is Spanish, \"In Espa\u00f1ola bad means malo and good means bueno\" will be the said task aligner that gives the information that the target language is Espa\u00f1ola (Spanish) and the target labels are malo and bueno (bad and good, respectively). Next, we construct the prompt-context by randomly selecting k source language examples, followed by the task aligner from this source-target pair from D l (see Algorithm 2). For more examples of task-aligned prompt design, please refer to Tables 11 and 12 in Appendix D.", "publication_ref": ["b16", "b17"], "figure_ref": [], "table_ref": ["tab_1"]}, {"heading": "Algorithm 2: Task Alignment", "text": "Input: An unlabeled target sentence xt, source dataset Ds, aligner Ls,t and number of samples to extract k. Procedure:\nRandomly select k sentences from Ds C \u2190 x 1 s \u2295 y 1 s \u2295 [sep] \u2295 \u2022 \u2022 \u2022 x k s \u2295 y k s C \u2190 C \u2295 Ls,t yt = argmax y\u2208Y t p(y|C \u2295 xt)", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "X-InSTA", "text": "We finally move on to our proposed method X-InSTA that combines semantic alignment with the task-based one. It first selects source examples from D s with top-k similarity scores as mentioned in Section 2.2. Additionally, we select taskaligners from D l depending on the source and target languages and the task. Finally, we construct the prompt context by concatenating the selected examples followed by the task-aligner. The final  label inference can be described as\ny t = argmax y\u2208Yt p(y|x 1 s \u2295 y 1 s \u2022 \u2022 \u2022 x k s \u2295 y k s \u2295 L s,t \u2295 x t )\nwhere sim(x i s , x t ) \u2265 sim(x i+1 s , x t ), and L s,t \u2208 D l is the task aligner for source and target languages s and t, respectively for the given task.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Results and Analysis", "text": "We experiment on three datasets -Multilingual Amazon Reviews Corpus (MARC) (Keung et al., 2020), Cross-language sentiment classification (CLS) (Prettenhofer and Stein, 2010), and Hat-Eval (Basile et al., 2019), spanning over twelve language-task pairs and totalling 44 cross-lingual setups (refer to Appendix A for further description of the datasets). The results on MARC, CLS and HatEval are shown in Tables 1, 2, and 3, respectively. For our main experiments, we make use of   larity prompting, even though it is not dynamically varying with input sentences. The improvement is 18% in CLS, 8% in HatEval, and 15% in MARC, in terms of macro F1 scores averaged over different language pairs. However, some languages like German in MARC and English in HatEval produce nearrandom predictions in all the set-ups we experimented with. This might be due to the model's inability to perform ICL on these tasks in a crosslingual manner for these languages. Previous studies observed such phenomena in monolingual ICL (Webson and Pavlick, 2022;Lin et al., 2021); crosslingual ICL has its added nuances that make it even more difficult.\nWe also see a performance drop in the case of Mandarin in MARC (Table 1) while adding a task aligner. We investigate the performance drop and near-random results of German further.\nX-InSTA: This prompting mechanism inherits both the benefits of semantic and task-based prompting, hence giving the best results in most language pairs. But similar to task-based alignment, X-InSTA also performs badly on some target languages. The improvement is 23% on MARC, 22% on CLS, and 14% on HatEval. We also note that no specific language can be used as the best source language.", "publication_ref": ["b18", "b23", "b24"], "figure_ref": [], "table_ref": ["tab_1", "tab_1"]}, {"heading": "Why does Task Alignment Work?", "text": "Next, we seek to validate the performance boost achieved via task-based aligners along with an attempt to explain the drop in performance with Mandarin and German. We vary the task aligner and   note its effect on the output. We do so in five different variations along with the original method (see Table 12 in Appendix D for detailed examples of each scenario):\n1. No aligner prompt added: Same as random prompting. 2. Making the label space uniform: Across all source-target setups, we set the source-label distribution as output for the target too, reducing the need for task alignment. 3. Only language information: Only giving the language information to LLM, without providing any further label information. An example of such an aligner would be 'The following post is in French language', in a case when the source is English, and the target is French. 4. Providing aligner but of a third unrelated language: We set the aligner of a third language. For example 'In Spanish bad means malo and good means bueno.', in a case when the source is English and the target is French. 5. Incorrect aligner: Making the aligner incorrect corresponding to the label space. For example 'In French bad means bien and good means mal.', in a case when the source is English and the target is French. It's all about the label information: In Table 4, we note the importance of label space information. Providing the model with language information does improve the performance; however, the improvement is minuscule compared to the improvement achieved via task aligners. This label information, even when of an unrelated third language, still helps the model predict better. This might be due to the fact that the model looks more rigorously at label space for inference. Therefore, this showcases the importance of labelling information while going cross-lingual.\nWhy drop in some languages? It is noteworthy that in Table 4, the task aligner works best for all target languages except for German and Mandarin. Both of these languages give the best results in uniform label space, i.e., when y t is made the same as y s . This points to the inability of the LLM to align the label space of different source languages to these target languages. In making the label space uniform, we lose certain language-specific signals, but this may also be seen as a way of reducing task alignment. Only for German and Mandarin do we see this trade-off as beneficial; in all other cases, the loss of language-specific features of y t leads to a drop in performance.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_1", "tab_6", "tab_6"]}, {"heading": "Role of semantic alignment", "text": "To understand the role of semantic alignment, we ran an experiment in which instead of choosing k nearest neighbor of x t , we chose the most dissimilar sentences. Table 5 shows that there is a sharp decrease in performance as compared to random prompting for all languages, with German as an exception. The average fall is 8% whereas using semantic alignment gives a gain of 10% w.r.t. random prompting.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_7"]}, {"heading": "Automated aligner generation", "text": "We also expand our analyses to automatically generate the aligner using mT5 (Xue et al., 2021). It is trained using a span generation task using sentences like 'Paris <MASK> France'. The mT5 model is trained to fill the mask token by generating spans like 'is capital of'. In our usage, mT5 will fill the <MASK> between the input target test x t , and prompt context C in the source language to align the semantics of both. We summarize our   6: Comparing the performance of automated aligners generated by mT5 with the rest of the methods in terms of macro-F1. We use English as the source language for all three tasks in this experiment.\nprocedure for automatic alignment generation in Algorithm 3. \nC \u2190 x 1 s \u2295 y 1 s \u2295 [sep] \u2295 \u2022 \u2022 \u2022 x k s \u2295 y k s L \u2190 mT 5(C \u2295 [M ASK] \u2295 xt),\nwhere L is the generated span\nC \u2190 C \u2295 L yt = argmax y\u2208Y t p(y|C \u2295 xt)\nDue to the computational cost of generating the intermediate prompt for each source-target input pair, we experiment with English as the only source language in all three datasets. Table 6 summarizes the results of using an automated aligner. We note that the automated aligner leads to better results than random prompting, and delivers results competitive to semantic prompting in some languages. However, it fails to incorporate any task-specific signals, therefore failing to beat task-based alignment. One can note the limitations of this approach in terms of the different pretraining distributions of the in-context learner and the aligner generator (XGLM and mT5, respectively, in this scenario). The hypothesized role of the aligner was to construct a 'natural' transition from the source context to the target input for a particular task. Since mT5 generates these aligners independently without any access to the pretraining distribution of XGLM, the disparity manifests with sub-optimal results.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Error Analysis", "text": "We present four examples in Table 7, highlighting the four major errors we notice while using X-InSTA, stemming from the following factors: 1. Static task-aligner: In example #1, slurs are used by all the posts. In the context examples, they are being used as hate speech; whereas in the target, it is not directed at any individual and thereby, should not be identified as hate speech. However, the model labels it otherwise. Here, the apparent semantic similarity is misdirecting the model, and the static nature of the task aligners is not able to guide it to understand the nuances of the task. 2. Cultural differences: None of the alignment methods introduces common knowledge or cultural knowledge in the prompt. To classify the tweet in example #2, one must have a grasp of hate focused on migration. 3. Input length: Both the context prompt and the input sentence are just too long in example #3. In this case, no matter how better we design the aligner, we cannot fit it within the maximum input length of 1024 tokens. One cannot keep on increasing the max-length to accommodate this pitfall, as that might lead to higher computation costs. A possible solution can be found in the direction of Transformer architectures suitable for longer input sequences. 4. Lack of human-like commonsense: In example #4, alignment of the semantics and the task constructed a good prompt, but the model predicted it wrongly by getting confused by the sarcasm in the first demonstration. To bridge this pitfall, we need to bring more knowledge of humor or commonsense to make the model understand what is obvious to us.\nIt should be noted that the majority of these errors are stemming from the incapability of the LLM itself. Advancements in language model designs may lead to betterment in future models.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Related Works", "text": "In-context learning (ICL): Brown et al. (2020) introduced a new approach, called in-context fewshot learning using the GPT-3 model. Subsequent efforts have been made to enhance the effectiveness of ICL. Hendrycks et al. (2020)  </s> Review: The mice loved them & are holes in the bags to get to the inside product. Rating: bad Review: Product bag was smashed and bag was spilled out in box. Rating: bad Review: The product came in and the spoons are already cracked and broken. Rating: bad Review: Item received was broken, with product leaking out and all over the jar. Rating: bad </s> In French bad means mal and good means bien.</s> Examen: Produit bien re\u00e7u mais pastilles a l'int\u00e9rieur des sachets en miettes et un sachet craqu\u00e9. \u00c9valuation: bien Table 7: Error analysis of X-InSTA. Four examples represent the major error characteristics (discussed in Section 3.5).\nWe omit most of the text in the test input of the 3rd example as it was too long.\npredictions have been implemented to optimize the input prompt (Liu et al., 2022;Zhang et al., 2021;Zhao et al., 2021). These efforts have primarily been directed toward improving the performance of ICL in a monolingual setting. Multilingual models: Recent studies on multilingual tasks have focused on creating multilingual versions of popular pre-trained language models. These include mBERT (Devlin et al., 2018), mBART , XLM-R (Conneau et al., 2020), and mT5 (Xue et al., 2020), which are derived from models like BERT (Devlin et al., 2018), BART , RoBERTa , and T5 (Raffel et al., 2019), respectively. However, fine-tuning these large models for each task is infeasible due to computational limitations. While ICL has been attempted for cross-lingual downstream tasks, these methods only involve random sampling of demonstrations for prompt construction (Zhang et al., 2021;Winata et al., 2021). Shi et al. (2022) addressed the problem of crosslingual text-to-sql conversion using ICL. However, their method relies on translating the input text in the source language to the target language before generating the corresponding SQL code. Agrawal et al. (2022) demonstrated the effects of similar example selection in a few-shot machine translation setting which is much similar to our proposed semantic alignment. To the best of our knowledge, there is no study on optimizing prompts for crosslingual NLP tasks using ICL.", "publication_ref": ["b3", "b13", "b28", "b29", "b7", "b6", "b7", "b19", "b28", "b24", "b21", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion", "text": "In this work, we described the first-ever attempt in the direction of cross-lingual prompt design for in-context learning. We found that a random selection of labeled training examples to construct the prompt-context limits the capability of a multilingual LLM to infer target labels. Instead, aligning the semantics as well as the task-specific textual signals across the source and the target language inputs in the prompt demonstrates superior performance in cross-lingual text classification.\nBased on these findings, we introduced X-InSTA, a novel method of in-context prompt design for cross-lingual text classification. X-InSTA improves upon random prompt selection substantially across multiple different cross-lingual tasks.\nWe found that the dynamicity of similarity-based example selection is able to guide the LLM to learn better in-context predictors irrespective of the language pair under consideration. On the other hand, language pairs with proper alignment in the label space get more out of the task-based alignment. These findings may serve as paving stones toward better cross-lingual ICL methods that incorporate an automated, dynamic transition from the source to target distributions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Limitations", "text": "Since this work relies on the in-context learning ability of large language models, the challenges associated with computational resources to load an LLM ensue. Due to resource constraints, we could not use larger or commercially available LLMs to validate if the advantages of X-InSTA translate to those models as well.\nAs we observed in Section 3.5, the static nature of the aligners poses a limitation on X-InSTA. Moreover, these aligners are manually designed. Therefore, task-specific, trial-and-error style manual intervention is needed. We believe a better understanding of the pretraining distribution of the multilingual LLMs can pave the way toward better automated alignment methods.\nThere are multiple shortcomings of monolingual ICL that entail its cross-lingual counterpart and X-InSTA does not address them; issues like knowledge hallucination, limited common-sense reasoning, inconsistency in retrieving factual associations, etc.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Ethics statement", "text": "Our proposed method, X-InSTA, delivers improvements in cross-lingual in-context learning. Since in-context learning ability is emergent in language models over billion parameters in size, this can cause potential discrimination in the usage of these methods based on the availability of access to computational resources. Research groups with limited access to computational resources will be handicapped while resourceful groups will be able to investigate and advance the future directions of this research.\nWe did not use any private or sensitive information throughout this research. However, if any private information was leaked to an LLM during the pretraining stage, X-InSTA does not provide any privacy filtration. Therefore, privacy concerns of the underlying model can potentially manifest with the outputs provided by X-InSTA.\nAs we dissected the erroneous predictions in Section 3.5, the lack of knowledge of cultural differences among different languages is a serious challenge within the LLM and this limits the performance of X-InSTA. Therefore, any potential deployment of our proposed method should be done under the lens of such considerations. This is even more delicate in case tasks like hate-speech classification which was one of the tasks that we explored in this work. Wrongfully identifying a hate speech as non-hate or vice versa in a low-resource target language based on culturally different language usage cues present in the prompt-context in a high-resource languages is a possibility; this may lead to unwarranted cultural appropriation and/or undemocratic gatekeeping.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Dataset Details", "text": "Multilingual Amazon Reviews Corpus: MARC (Keung et al., 2020) is a large-scale multilingual corpus of Amazon reviews of customers. The corpus consists of six distinct languages -German, English, Spanish, French, Japanese, and Mandarin. Each language has a training set of size 200K that we use for selecting our demonstrations and a test set of 40, 000 reviews classified as positive or negative.\nCross-language sentiment classification: CLS (Prettenhofer and Stein, 2010) is a multilingual corpus of four languages -German, English, French, and Japanese. It consists of reviews on DVD, music, and books, with a training set and a test set of 2, 000 sentences for each language classified into negative and positive.\nHateval: HatEval (Basile et al., 2019) consists of two languages -English and Spanish, classified into hate or non-hate. The test set contains 3, 000 posts for English and 1, 600 for Spanish, with the training set size being 5, 000 for Spanish and 10, 000 for English.", "publication_ref": ["b18"], "figure_ref": [], "table_ref": []}, {"heading": "B Model Variants", "text": "We experiment with multiple different LMs in their base versions (i.e., random prompting) to gauge their ability, namely XGLM 7.5B, XGLM 1.7B, and Bloom 7.1B.  ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Hyperparameters", "text": "All codes were written using PyTorch. We used the Huggingface repository for loading the LLM and sentence transformer for extracting semantic similarity. Sklearn was used for calculating the F1 score.   As there is variation only in the aligner and none in the demonstration of the context prompt, the demonstrations are shortened. In the examples, English serves as the source language while Spanish is the target language. Hence, Y t is {malo, bueno} and Y s is {bad, good}. In the second row, the labels are colored in red to highlight that we have made Y t the same as Y s , i.e., for the input example we will label based on the label space {bad, good}, therefore, making the label space uniform.\nIn the fourth row, the aligner of a third unrelated language is given (French in this case).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?\nNo response.\nB4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? No response.\nB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? No response.\nB6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be.\nNo response.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Did you run computational experiments?", "text": "Section 3.\nC1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? Appendix A\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Incontext examples selection for machine translation", "journal": "", "year": "2022", "authors": "Sweta Agrawal; Chunting Zhou; Mike Lewis; Luke Zettlemoyer; Marjan Ghazvininejad"}, {"ref_id": "b1", "title": "", "journal": "", "year": "", "authors": "Valerio Basile; Cristina Bosco; Elisabetta Fersini; Debora Nozza; Viviana Patti; Francisco Manuel Rangel Pardo; Paolo Rosso; Manuela Sanguinetti"}, {"ref_id": "b2", "title": "SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter", "journal": "Minneapolis", "year": "", "authors": ""}, {"ref_id": "b3", "title": "Language models are few-shot learners", "journal": "", "year": "2020", "authors": "Tom Brown; Benjamin Mann; Nick Ryder; Melanie Subbiah; Jared D Kaplan; Prafulla Dhariwal; Arvind Neelakantan; Pranav Shyam; Girish Sastry; Amanda Askell"}, {"ref_id": "b4", "title": "The geometry of multilingual language model representations", "journal": "", "year": "2022", "authors": "A Tyler; Zhuowen Chang; Benjamin K Tu;  Bergen"}, {"ref_id": "b5", "title": "Palm: Scaling language modeling with pathways", "journal": "", "year": "2022", "authors": "Aakanksha Chowdhery; Sharan Narang; Jacob Devlin; Maarten Bosma; Gaurav Mishra; Adam Roberts; Paul Barham;  Hyung Won; Charles Chung; Sebastian Sutton;  Gehrmann"}, {"ref_id": "b6", "title": "Unsupervised cross-lingual representation learning at scale", "journal": "", "year": "2020", "authors": "Alexis Conneau; Kartikay Khandelwal; Naman Goyal; Vishrav Chaudhary; Guillaume Wenzek; Francisco Guzm\u00e1n; Edouard Grave; Myle Ott; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b7", "title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2018", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"ref_id": "b8", "title": "Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. Measuring massive multitask language understanding", "journal": "", "year": "", "authors": "Dan Hendrycks; Collin Burns; Steven Basart; Andy Zou"}, {"ref_id": "b9", "title": "2020. The multilingual Amazon reviews corpus", "journal": "Online. Association for Computational Linguistics", "year": "", "authors": "Phillip Keung; Yichao Lu; Gy\u00f6rgy Szarvas; Noah A Smith"}, {"ref_id": "b10", "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension", "journal": "", "year": "2020", "authors": "Mike Lewis; Yinhan Liu; Naman Goyal; Marjan Ghazvininejad; Abdelrahman Mohamed; Omer Levy; Veselin Stoyanov; Luke Zettlemoyer"}, {"ref_id": "b11", "title": "Dimitris Papailiopoulos, and Samet Oymak. 2023. Transformers as algorithms: Generalization and implicit model selection in in-context learning", "journal": "", "year": "", "authors": "Yingcong Li; Emrullah Ildiz"}, {"ref_id": "b12", "title": "Jingfei Du, et al. 2021. Few-shot learning with multilingual language models", "journal": "", "year": "", "authors": "Todor Xi Victoria Lin; Mikel Mihaylov; Tianlu Artetxe; Shuohui Wang; Daniel Chen; Myle Simig; Naman Ott; Shruti Goyal;  Bhosale"}, {"ref_id": "b13", "title": "What makes good in-context examples for GPT-3?", "journal": "", "year": "2022", "authors": "Jiachang Liu; Dinghan Shen; Yizhe Zhang; Bill Dolan; Lawrence Carin; Weizhu Chen"}, {"ref_id": "b14", "title": "Multilingual denoising pretraining for neural machine translation", "journal": "", "year": "2020", "authors": "Yinhan Liu; Jiatao Gu; Naman Goyal; Xian Li; Sergey Edunov; Marjan Ghazvininejad; Mike Lewis; Luke Zettlemoyer"}, {"ref_id": "b15", "title": "", "journal": "", "year": "2019", "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b16", "title": "Zero-shot cross-lingual transfer with meta learning", "journal": "", "year": "2020", "authors": "Farhad Nooralahzadeh; Giannis Bekoulis; Johannes Bjerva; Isabelle Augenstein"}, {"ref_id": "b17", "title": "BAD-X: Bilingual adapters improve zero-shot cross-lingual transfer", "journal": "Association for Computational Linguistics", "year": "2022", "authors": "Marinela Parovi\u0107; Goran Glava\u0161; Ivan Vuli\u0107; Anna Korhonen"}, {"ref_id": "b18", "title": "Crosslanguage text classification using structural correspondence learning", "journal": "", "year": "2010", "authors": "Peter Prettenhofer; Benno Stein"}, {"ref_id": "b19", "title": "Exploring the limits of transfer learning with a unified text-to", "journal": "", "year": "2019", "authors": "Colin Raffel; Noam Shazeer; Adam Roberts; Katherine Lee; Sharan Narang; Michael Matena; Yanqi Zhou; Wei Li; Peter J Liu"}, {"ref_id": "b20", "title": "Making monolingual sentence embeddings multilingual using knowledge distillation", "journal": "", "year": "2020", "authors": "Nils Reimers; Iryna Gurevych"}, {"ref_id": "b21", "title": "Xricl: Cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-sql semantic parsing", "journal": "", "year": "2022", "authors": "Peng Shi; Rui Zhang; He Bai; Jimmy Lin"}, {"ref_id": "b22", "title": "Transformers learn in-context by gradient descent", "journal": "", "year": "2022", "authors": "Eyvind Johannes Von Oswald; Ettore Niklasson; Jo\u00e3o Randazzo; Alexander Sacramento; Andrey Mordvintsev; Max Zhmoginov;  Vladymyrov"}, {"ref_id": "b23", "title": "Do promptbased models really understand the meaning of their prompts?", "journal": "Association for Computational Linguistics", "year": "2022", "authors": "Albert Webson; Ellie Pavlick"}, {"ref_id": "b24", "title": "Language models are few-shot multilingual learners", "journal": "Association for Computational Linguistics", "year": "2021", "authors": "Andrea Genta Indra Winata; Zhaojiang Madotto; Rosanne Lin; Jason Liu; Pascale Yosinski;  Fung"}, {"ref_id": "b25", "title": "An explanation of in-context learning as implicit bayesian inference", "journal": "", "year": "2022-04-25", "authors": "Sang Michael Xie; Aditi Raghunathan; Percy Liang; Tengyu Ma"}, {"ref_id": "b26", "title": "", "journal": "", "year": "", "authors": "Linting Xue; Noah Constant; Adam Roberts; Mihir Kale; Rami Al-Rfou; Aditya Siddhant; Aditya Barua"}, {"ref_id": "b27", "title": "Aditya Barua, and Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer", "journal": "Association for Computational Linguistics", "year": "", "authors": "Linting Xue; Noah Constant; Adam Roberts; Mihir Kale; Rami Al-Rfou; Aditya Siddhant"}, {"ref_id": "b28", "title": "Differentiable prompt makes pre-trained language models better few-shot learners", "journal": "", "year": "2021", "authors": "Ningyu Zhang; Luoqiu Li; Xiang Chen; Shumin Deng; Zhen Bi; Chuanqi Tan; Fei Huang; Huajun Chen"}, {"ref_id": "b29", "title": "Calibrate before use: Improving few-shot performance of language models", "journal": "", "year": "2021", "authors": "Tony Z Zhao; Eric Wallace; Shi Feng; Dan Klein; Sameer Singh"}, {"ref_id": "b30", "title": "error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run", "journal": "", "year": "", "authors": ""}, {"ref_id": "b31", "title": "for preprocessing, for normalization, or for evaluation", "journal": "", "year": "", "authors": " Nltk;  Spacy;  Rouge"}, {"ref_id": "b32", "title": "crowdworkers) or research with human participants? Left blank", "journal": "", "year": "", "authors": ""}, {"ref_id": "b33", "title": "Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators", "journal": "", "year": "", "authors": " D1"}, {"ref_id": "b34", "title": "crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic", "journal": "", "year": "", "authors": ""}, {"ref_id": "b35", "title": "Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?", "journal": "", "year": "", "authors": " D3"}, {"ref_id": "b36", "title": "Was the data collection protocol approved (or determined exempt) by an ethics review board? No response", "journal": "", "year": "", "authors": " D4"}, {"ref_id": "b37", "title": "Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? No response", "journal": "", "year": "", "authors": " D5"}], "figures": [{"figure_label": "3", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Algorithm 3 :3Task Alignment Input: An unlabeled target sentence xt, source data set Ds, multilingual-T5, mT 5, multilingual LLM, M and number of samples to extract k. Procedure: Randomly select k sentences from Ds", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Multiple recent studies have sought to explain the emergence of ICL by assigning different roles to the LLM. Xie et al. (2022) provided the notion of LLMs doing Bayesian inference conditioned upon the prompt context to predict the test label. Our work is much in line with this hypothetical model since alignment over the semantics and the taskbased signals across languages are motivated by the quest for better alignment between the prompt and the pretraining distribution and warranting a shared, distinguishable concept as Xie et al. (2022) argued. Additionally, von Oswald et al. (2022) sought to identify LLMs doing gradient-descent as meta-optimizers while learning in context. Li et al. (2023) described ICL as implicit model selection.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Macro-F1 scores for different prompting techniques on the MARC dataset (source and target languages are abbreviated as SRC and TAR, respectively). Improvement across all six languages can be observed once we introduce semantic alignment. X-InSTA outperforms rest of the methods on 4 out of 6 languages.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "Macro F1 scores on the CLS dataset.XGLM (Lin et al., 2021)  7.5 billion variant. We experiment with various models with random prompting and select XGLM 7.5B for its performance superiority on various tasks (refer to Table8in Appendix B). For further details on the experimental setup, please refer to Appendix C and Table10for the language abbreviations used.", "figure_data": "3.1 Comparing Alignment TechniquesSemantic Alignment: The improvement intro-duced by semantic alignment of the prompt-contextover randomly-selected source examples is eminentin Tables 1, 2, and 3. On the MARC dataset, weobserve a 14% improvement in macro F1 scoresaveraged across different languages. This observa-tion is consistent across all target-source pairs onother datasets as well -a gain of 10% on Hateval,and 6% on CLS. This improvement over randomexample selection is consistent across all languagepairs (except English-to-German in CLS) consid-ered in this experiment. This is particularly note-worthy and one might lead to the conclusion thatdynamically selecting prompt examples based onsemantic similarity aligns the LLM to become abetter in-context learner irrespective of the task andthe languages.Task-based Alignment: Just by adding a task aligner, we not only outperform random promptsbut also bring substantial improvements for simi-"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Macro F1 scores on the HatEval dataset.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_5", "figure_caption": ".633 0.731 0.557 0.499 0.462 Uniform label space 0.441 0.570 0.493 0.414 0.483 0.594 Task alignment by language information only 0.346 0.645 0.733 0.575 0.543 0.508 Task alignment via third language 0.345 0.687 0.755 0.673 0.601 0.423 Incorrect task alignment 0.338 0.665 0.787 0.647 0.544 0.339 Task Alignment 0.338 0.722 0.830 0.758 0.730 0.335", "figure_data": "Setup Random promptTarget languagede 0.345 0enesfrjazh"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Understanding how task alignment works. Average F1-Macro across all source-target pairs on MARC.", "figure_data": "Target Non-Semantic Setup Random Semanticde 0.524 0.602 0.495 0.631 en fr ja 0.531 0.561 0.453 0.515 0.531 0.621 0.543 0.697"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Dissecting the role of semantic alignment; we present macro-F1 scores corresponding to different prompting techniques on the CLS dataset for each source language averaged over all target languages.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_10", "figure_caption": ": @anne_theriault @hels Shut up cunt bitch whore Is hatefull? yes Post: @okaayythen bitch ass whore ass motherfucker Is hatefull? yes Post: @KoiyaThePerv bitch ass hoe Is hatefull? yes Post: @nonracialnigger Wow shut up you whore Is hatefull? yes In Spanish no hate means no odio and yes means si odio secte qui met au pinacle le sacrifice de la vie des siens...TO LONG CONTEXT....bon signifie good Review: In the end, it appears ......THE POST IS TOO LONG.....", "figure_data": "# PromptInputOutput1.correo: @Viplajo @blondeputicorn c\u00e1l-late era una historia de amor hijo de puta Es odioso?yes2.correo: @diegovftbau REENCUENTRO LA PUTA MADRE, DISFRUTALO MUCHO, LO RE MERECES AMIGA Es odioso? no correo: @AlejoIgoa @igoaftbau BIAN LA PUTA MADRE TE LO MERECES MAS QUE A NADIE Es odioso? no correo: @ansecas C\u00c1LLATE LESBIANA HIJA DE PUTA QUE EST\u00c1 AH\u00cd T\u00da HIJO BORT Es odioso? si En English no odio significa no hate y si odio significa yes hate si correo: @Isranutrof CALLATE PUTA! MIS JOJOS VUELVEEEEN Es odioso?Post: Arrest them and DEPORT THEM ALL!!!!#BuildThatWall Is hateful?no3.</s> Examen: Bravo \u00e0 Nicolas Jacquette pour avoir r\u00e9ussi \u00e0 quitter l'enfer d'une the problem certain priests Rating: than for the individual transgressions ofgood4.evaluated thebreadth and depth of model understanding to de-termine its weaknesses and strengths. Techniquessuch as selecting semantically-similar examples,using differentiable soft prompts for backpropaga-tion, and adjusting prompts to eliminate bias in"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "contains the performance of these models on a subset of the test data used (namely, CLS and HatEval with English as the source language). As we can see, XGLM 7.5B appears to outperform other models by a significant margin on multiple different tasks, and therefore, is used for the rest of the experiments.", "figure_data": "Model xglm-1.7B Target xglm-7.5B bloom-7.1BCLS fr 0.711 0.382 0.395 de ja 0.682 0.412 0.609 0.33 0.355 0.508HatEval es 0.370 0.435 0.373"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_12", "figure_caption": "Comparing the performance of different variants of multilingual generative models on random prompting. We use English as the source language in all the experiments.", "figure_data": ""}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_13", "figure_caption": "describes values of different hyperparameters and compute resources used.", "figure_data": "D MiscellaneousD.1 Language CodeRefer to Table 10 for this information.D.2 Prompt ExamplesWe show a few example prompts (demonstrationsand test input) in Table 11. Additionally, in Ta-ble 12, we demonstrate a few examples of differenttask-aligners used for the analysis in Section 3.2."}, {"figure_label": "11", "figure_type": "table", "figure_id": "tab_14", "figure_caption": "Examples of prompts for MARC. In all examples, the source is English while the target is Spanish. Blue text marks the task aligner. The value of k is 2 in these examples.", "figure_data": "Prompting Method Random Prompt Uniform Label Space Language Information Only Third language aligner Task AlignmentPrompt </s> Review: cannot operate this with-out using 2 hands.... For the price, you won't find anything better right now. Rating: good</s> Review: they were nice but too big. Rating: good </s> Review: cannot operate this with-out using 2 hands....For the price, you won't find anything better right now. Rating: good</s> Review: they were nice but too big. Rating: good </s> Review: cannot operate this with-out using 2 hands....For the price, you won't find anything better right now. Rating: good</s> Review: they were nice but too big. Rating: good</s> The following post is in Espa\u00f1ola </s> </s> Review: cannot operate this with-out using 2 hands....For the price, you won't find anything better right now. Rating: good</s> Review: they were nice but too big. Rating: good</s> In French bad means mal and good means bien.</s> </s> Review: cannot operate this with-out using 2 hands....For the price, you won't find anything better right now. Rating: good</s> Review: they were nice but too big. Rating: good </s> In means malo.</s> Espa\u00f1ola bad means bueno and goodInput Revisar: no me llego el articulo me lo mando por correos normal sin seguimiento y nunca me llego tota un desastre Clasificaci\u00f3n: Revisar: no me llego el articulo me lo mando por correos normal sin seguimiento y nunca me llego tota un desastre Clasificaci\u00f3n: Revisar: no me llego el articulo me lo mando por correos normal sin seguimiento y nunca me llego tota un desastre Clasificaci\u00f3n: Revisar: no me llego el articulo me lo mando por correos normal sin seguimiento y nunca me llego tota un desastre Clasificaci\u00f3n: Revisar: no me llego el articulo me lo mando por correos normal sin desastre Clasificaci\u00f3n: seguimiento y nunca me llego tota unOutput malo/bueno bad/good malo/bueno malo/bueno malo/bueno"}, {"figure_label": "12", "figure_type": "table", "figure_id": "tab_15", "figure_caption": "Examples of different types of task aligners. Blue text marks the task aligner.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "Let D s = {(x i", "formula_coordinates": [3.0, 70.86, 332.25, 69.74, 20.55]}, {"formula_id": "formula_1", "formula_text": "C = x 1 s \u2295 y 1 s \u2295 [sep] \u2295 \u2022 \u2022 \u2022 x k s \u2295 y k s (1)", "formula_coordinates": [3.0, 101.79, 491.5, 188.07, 20.96]}, {"formula_id": "formula_2", "formula_text": "y t = argmax y\u2208Yt p(y|C \u2295 x t )", "formula_coordinates": [3.0, 122.39, 623.15, 115.2, 19.83]}, {"formula_id": "formula_3", "formula_text": "Procedure: et \u2190 \u03b8(xt) for x s \u2208 Ds do e i s \u2190 \u03b8(x i s ) si \u2190 e t .e i s ||e t || 2 ||e i s || 2 end Select top k sentences based on si C \u2190 x 1 s \u2295 y 1 s \u2295 [sep] \u2295 \u2022 \u2022 \u2022 x k s \u2295 y k s yt = argmax y\u2208Y t p(y|C \u2295 xt)", "formula_coordinates": [3.0, 317.05, 614.79, 134.21, 95.33]}, {"formula_id": "formula_4", "formula_text": "Randomly select k sentences from Ds C \u2190 x 1 s \u2295 y 1 s \u2295 [sep] \u2295 \u2022 \u2022 \u2022 x k s \u2295 y k s C \u2190 C \u2295 Ls,t yt = argmax y\u2208Y t p(y|C \u2295 xt)", "formula_coordinates": [4.0, 81.77, 555.6, 185.0, 46.77]}, {"formula_id": "formula_5", "formula_text": "y t = argmax y\u2208Yt p(y|x 1 s \u2295 y 1 s \u2022 \u2022 \u2022 x k s \u2295 y k s \u2295 L s,t \u2295 x t )", "formula_coordinates": [4.0, 306.14, 537.24, 218.28, 21.86]}, {"formula_id": "formula_6", "formula_text": "C \u2190 x 1 s \u2295 y 1 s \u2295 [sep] \u2295 \u2022 \u2022 \u2022 x k s \u2295 y k s L \u2190 mT 5(C \u2295 [M ASK] \u2295 xt),", "formula_coordinates": [7.0, 81.77, 283.01, 134.21, 26.85]}, {"formula_id": "formula_7", "formula_text": "C \u2190 C \u2295 L yt = argmax y\u2208Y t p(y|C \u2295 xt)", "formula_coordinates": [7.0, 81.77, 314.23, 115.08, 25.52]}], "doi": "10.18653/v1/S19-2007"}