{"title": "Bayesian Active Learning for Posterior Estimation", "authors": "Kirthevasan Kandasamy; Jeff Schneider; Barnab\u00e1s P\u00f3czos", "pub_date": "", "abstract": "This paper studies active posterior estimation in a Bayesian setting when the likelihood is expensive to evaluate. Existing techniques for posterior estimation are based on generating samples representative of the posterior. Such methods do not consider efficiency in terms of likelihood evaluations. In order to be query efficient we treat posterior estimation in an active regression framework. We propose two myopic query strategies to choose where to evaluate the likelihood and implement them using Gaussian processes. Via experiments on a series of synthetic and real examples we demonstrate that our approach is significantly more query efficient than existing techniques and other heuristics for posterior estimation.", "sections": [{"heading": "Introduction", "text": "Computing the posterior distribution of parameters given observations is a central problem in statistics. We use the posterior distribution to make inferences about likely parameter values and estimate functionals of interest. For simple parametric models we may obtain the posterior in analytic form. In more complex models where the posterior is analytically intractable, we have to resort to approximation techniques. In some cases, we only have access to a black box which computes the likelihood for a given value of the parameters.\nOur goal is an efficient way to estimate posterior densities when calls to this black box are expensive. This work is motivated by applications in computational physics and cosmology. Several cosmological phenomena are characterized by the cosmological parameters (e.g. Hubble constant, dark energy fraction). Given observations, we wish to make inferences about the parameters. Physicists have developed simulation-based probability models of the Universe which can be used to compute the likelihood of cosmological parameters for a given observation. Figure 1 shows different scenarios to estimate / compute the likelihood. Many problems in scientific computing have a similar flavour. Expensive simulators in molecular mechanics, computational biology and neuroscience are used to model many scientific processes.\nOur contribution is to propose a query efficient method for estimating posterior densities when the likelihood function is expensive to evaluate. We adopt a Bayesian active regression approach on the log likelihood using the samples it has already computed. We refer to this approach as Bayesian Active Posterior Estimation (BAPE). We propose two myopic query strategies on the uncertainty regression model for sample selection. Our implementation uses Gaussian processes (GP) [Rasmussen and Williams, 2006] and we demonstrate the efficacy of the methods on multiple synthetic and real experiments.", "publication_ref": ["b22"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "Practitioners have conventionally used sampling schemes [MacKay, 2003] to approximate the posterior distributions. Rejection sampling and various MCMC methods are common choices. The advantage of MCMC approaches is their theoretical guarantees with large sample sets [Robert and Casella, 2005] and thus they are a good choice when likelihood evaluations are cheap. However, none of them is intended to be query efficient when evaluations are expensive. Some methods spend most of their computation evaluating point likelihoods and then discard the likelihood values after doing an acceptance test. This gives insight into the potential gains possible by retaining those likelihoods for use in regression. Despite such deficiencies, MCMC remains one of the most popular techniques for posterior estimation in experimental science [Foreman-Mackey et al., 2013;Parkinson et al., 2006;Landau and Binder, 2005;Liu, 2001].\nApproximate Bayesian computation (ABC) [Marin et al., 2012;Marjoram et al., 2003] is a method of last resort for estimating posteriors when a likelihood can not be computed. Unfortunately, it still requires the same generation of simulated data, which is expensive in our setup, and it does not address efficient selection of parameter values to be tested at all. Nested Sampling [Skilling, 2006] is a technique commonly used is Astrostatistics. Kernel Bayes' Rule [Fukumizu et al., 2014] is a non-parametric method of computing a posterior based on the embedding of probabilities in an RKHS. All these methods require sampling from a distribution and do not address the question of which samples to choose if generating them is expensive. The work in Bryan et al. [2006]  Given a parameter value \u03b8 the oracle produces several simulations X sim . The likelihood P (X obs |\u03b8) can then be estimated via a density estimate using X sim at the given \u03b8. (b): The oracle directly computes the likelihood using a physical model of the universe.\nactively learns level sets of an expensive function and derives confidence sets from the results. Gotovos et al. [2013] also actively learn level sets via a classification approach. Our work is more general since we estimate the entire posterior.\nOur methods draw inspiration from Gaussian Process based active learning methods such as Bayesian optimisation (BO) [Mockus and Mockus, 1991], Bayesian quadrature (BQ) [Osborne et al., 2012], active GP Regression (AGPR) [Seo et al., 2000] and several others [Srinivas et al., 2010;Gunter et al., 2014;Ma et al., 2014;Krause et al., 2008;Kandasamy et al., 2015]. These methods have a common modus operandi to determing the experiment \u03b8 t at time step t: Construct a utility function u t based on the posterior GP conditioned on the queries so far. Then maximize u t to determine \u03b8 t . u t (\u03b8) captures the value of performing an experiment at point \u03b8. Existing theoretical results [Golovin and Krause, 2011] justify such myopic strategies for homogeneous and stateless utility functions. Maximizing the typically multimodal u t is itself a hard problem. However, it is generally assumed that querying the function is more costly than this maximization [Brochu et al., 2010;Srinivas et al., 2010]. The key difference in such methods is essentially in the specification of u t to determine the next experiment. In our work, we adopt this strategy. We present two utility functions for active posterior estimation.", "publication_ref": ["b15", "b23", "b4", "b20", "b12", "b13", "b16", "b17", "b26", "b5", "b2", "b7", "b18", "b19", "b24", "b27", "b8", "b14", "b11", "b10", "b6", "b1", "b27"], "figure_ref": [], "table_ref": []}, {"heading": "Bayesian Posterior Estimation", "text": "Problem Setting: We formally define our posterior distribution estimation problem in a Bayesian framework. We have a bounded continuous parameter space \u0398 for the unknown parameters (e.g. cosmological constants). Let X obs denote our observations (e.g. signals from telescopes). For each \u03b8 \u2208 \u0398 we have the ability to query an oracle for the value of the likelihood L(\u03b8) = P (X obs |\u03b8), but these queries are expensive. Assuming a prior P \u03b8 (\u03b8) on \u0398, we have the posterior P \u03b8|X obs .\nP \u03b8|X obs (\u03b8|X obs ) = L(\u03b8)P \u03b8 (\u03b8) \u0398 L(\u03b8)P \u03b8 (\u03b8) = L(\u03b8)P \u03b8 (\u03b8) P (X obs )(1)\nWe wish to obtain an estimate P \u03b8|X obs of P \u03b8|X obs while minimizing our queries to the oracle. Some smoothness assumptions on the problem are warranted to make the problem tractable. In the Bayesian framework it is standard to assume that the function of interest is a sample from a Gaussian Process. In what follows we shall model the log joint probability of the cosmological parameters and the observations via a GP 1 . This is keeping in line with Adams et al. [2008] who use a similar prior for GP density sampling and similar smoothness assumptions in Srinivas et al. [2010].\nAssume that we have already queried the likelihood oracle at t \u2212 1 points, and for each query point \u03b8 i the oracle provided us with L i \u2248 P (X obs |\u03b8 i ) answers. Let\nA t\u22121 = {\u03b8 i , L i } t\u22121 i=1\ndenote the set of these input output pairs. We build our GP on B t\u22121 = {\u03b8 i , log(L i P \u03b8 (\u03b8 i ))} t\u22121 i=1 input output pairs. If g is a sample from this GP, then f = exp g/ exp g denotes a sample from the induced uncertainty model F \u03b8|X obs for the posterior P \u03b8|X obs . Finally, given any estimate P At (X obs , \u03b8) of the log joint probability, the estimate of the posterior distribution is,\nP At (\u03b8|X obs ) = exp P At (X obs , \u03b8) \u0398 exp P At (X obs , \u03b8)(2)\nAt time t, we wish to select the point \u03b8 t for the next experiment to evaluate the likelihood. We adopt a myopic strategy here by picking the point that maximizes a utility function.\nOur utility function needs to capture a measure of divergence D(\u2022 \u2022) between the densities. To construct this utility function, note that ideally we would like to select \u03b8 t to satisfy \u03b8 t = argmin \u03b8+\u2208\u0398 D( P \u03b8|X obs P At\u22121\u222a{(\u03b8+,L(\u03b8+))} ) (3)\nwhere P At\u22121\u222a{(\u03b8+,L(\u03b8+))} is our estimate of the posterior us-\ning A t\u22121 \u222a {(\u03b8 + , L(\u03b8 + ))}.\nObviously, this objective is not accessible in practice, since we know neither P \u03b8|X obs nor L(\u03b8 + ). As surrogates to this ideal objective in Equation ( 3), in the following subsections we propose two utility functions for determining the next point: Negative Expected Divergence (NED) and Exponentiated Variance (EV). The first, NED adopts a Bayesian decision theoretic approach akin to Settles [2010]. Here, we choose the point in \u0398 that yields the minimum expected divergence for the next estimate over the uncertainty model. Unfortunately, in our setting, the NED utility is computationally demanding. Therefore, we propose a cheaper alternative EV. In our experiments we found that both strategies performed equally well -so EV is computationally attractive. That said, some cosmological simulations are very expensive (taking several hours to a day) so NED is justified in such situations. We present our framework for BAPE using an appropriate utility function u t in Algorithm 1.\n(a)\n(b) (a) (b) (1) (2) (3) (4) (5) (c) (1) (a) (b) (3) (4)(5)\n(2) High variance in the low likelihood regions are squashed and low variances in the high likelihood regions are blown up. This is the key insight that inspires our methods. (c) and (d) are the true log joint probability and joint probability in blue. Assume that we have already queried at the brown crosses and let the red circles (a) and (b) be candidates. In BAPE we would be interested in querying (b) but not (a) . In AGPR we would be interested in both (a) and (b) whereas in BO we would be keen in neither.\n(d)", "publication_ref": ["b27", "b25"], "figure_ref": [], "table_ref": []}, {"heading": "Algorithm 1 Bayesian Active Posterior Estimation", "text": "Given: Input space \u0398, GP prior \u00b5 0 , k 0 .\nFor t = 1, 2, . . . do 1. \u03b8 t = argmax \u03b8t\u2208\u0398 u t (\u03b8) 2. L t \u2190 Query oracle at \u03b8 t .\n3. Obtain posterior conditioned on (\u03b8 i ,\nL i P \u03b8 (\u03b8 i )) t i=1", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Negative Expected Divergence (NED)", "text": "Equation 3 says that we should choose the point that results in the highest reduction in divergence if we knew the likelihood and the true posterior at that point. In NED, we choose the point with the highest expected reduction in divergence.\nFor this we first build uncertainty models for the value of the likelihood at \u03b8 + (L(\u03b8 + )) and the posterior (F \u03b8|X obs ). For the next evaluation we choose the point that minimizes the expected divergence between these models and the next estimate. Precisely,\nu NED t (\u03b8 + ) = \u2212E p+ E h D( h P A\u222a{(\u03b8+,p+)} m+1\n).\nHere p + is sampled from L A (\u03b8 + ),the uncertainty of the likelihood at \u03b8 + . The density h is sampled from F A\u222a{(\u03b8+,p+)} \u03b8|X obs , the uncertainty model of the posterior obtained by adding (\u03b8 + , p + ). P A\u222a{(\u03b8+,p+)} m+1 denotes the estimate of the posterior obtained by re-training the GP with (\u03b8 + , p + ) as the (m + 1) th point along with the m points already available. The first expectation above captures our uncertainty over L(\u03b8 + ) while the second captures our remaining uncertainty over P \u03b8|X obs after observing L(\u03b8 + ). Equation ( 4) says that you should minimize the expected divergence by looking one step ahead.\nThe expectations in the NED utility above are computationally intractable. They can only be approximated empirically by drawing samples and require numerical integration. For these reasons we propose an alternate utility function below.\nIn our experiments we found that both EV and NED performed equally well.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Exponentiated Variance (EV)", "text": "A common active learning heuristic is to choose the point that you are most uncertain about for the next experiment.\nAs before we use a GP on the log joint probability. At any given point in this GP we have an associated posterior variance of the GP. However, this variance corresponds to the uncertainty of the log joint probability whereas our objective is in learning the joint probability -which is a multiplicative factor away from the posterior. Therefore, unlike in usual GP active learning methods Seo et al. [2000], the variance of interest here is in the exponentiated GP. The posterior mean and variance at \u03b8 + of our log-joint GP are given by,\n\u00b5(\u03b8 + ) \u2206 = E F \u03b8|X obs log P (X obs , \u03b8 + ) = k(A, \u03b8 + ) k(A, A) \u22121 j (5) \u03c3 2 (\u03b8 + ) \u2206 = V F \u03b8|X obs log P (X obs , \u03b8 + ) = k(\u03b8 + , \u03b8 + ) \u2212 k(A, \u03b8 + ) k(A, A) \u22121 k(A, \u03b8 + )\nwhere k(A, A) \u2208 R m\u00d7m is the kernel matrix of A, k(A, \u03b8 + ) \u2208 R m is the kernel vector from \u03b8 + to A and j = (log\nL i P \u03b8 (\u03b8 i )) m i=1 \u2208 R m .\nBy observing that an exponentiated Gaussian is a log Normal distribution, the EV utility function is given by\nu EV t (\u03b8 + ) = V F \u03b8|X obs P (X obs , \u03b8 + ) = (6) exp(2\u00b5(\u03b8 + ) + \u03c3 2 (\u03b8 + ))(exp(\u03c3 2 (\u03b8 + )) \u2212 1)\nWe choose the point maximizing the above variance. Its important to distinguish our objective in this work from similar active learning literature in the GP framework. In BO, the objective is to find the maximum of a function. This means that once the active learner realises that it has found the mode of a function it has less incentive to explore around as it would not improve the current maximum values. For instance, consider the log joint probability in Figure 2(c) and the joint probability in Figure 2(d). We have shown the points where we have already queried at as brown crosses and the red circles (a) and (b) show possible candidates for the next query. In BO, the active learner would not be interested in (b) as, by virtue of points ( 3), ( 4), ( 5) it knows that (b) is not likely to be higher than (4). On the other hand, in BAPE we are keen on (b) as knowing it with precision will significantly affect our estimate of the posterior (Fig 2(d)). In particular to know the posterior well we will need to query at the neighborhood of modes and the heavy tails of a distribution. A BO utility is not interested in such queries. On the other extreme, in AGPR the objective is to learn the function uniformly well. This means in the same figures, AGPR will query point (a). However, given sufficient smoothness, the joint probability will be very low there due to exponentiation. Therefore, the BAPE active learner will not be interested in (a). As figures 2(a) and 2(b) indicate, while we model the log joint probability as a GP we are more interested in the uncertainty model of the posterior/ joint probability. Finally, as a special case for BQ, Osborne et al. [2012] consider evaluating the model evidence-i.e. the integral under the conditional. Their utility function uses approximations tailored to estimating the integral well. Note that our goal of estimating the posterior well is more difficult than estimating an integral under the conditional as the former implies the latter but not vice versa.", "publication_ref": ["b24", "b19"], "figure_ref": ["fig_1", "fig_1"], "table_ref": []}, {"heading": "Other Algorithms for Comparison", "text": "We list some potential alternatives for posterior estimation and describe them here. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "MCMC -Regression (MCMC-R):", "text": "Here, as in MCMC-DE we use a MH Chain to generate the samples. However, this time we regress on the queries (not samples) to estimate the posterior. We include this procedure since MCMC can be viewed as a heuristic to explore the parameter space in high likelihood regions. We show that a principled query strategy outperforms this heuristic.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Approximate Bayesian Computing (ABC):", "text": "There are several variants of ABC [Marjoram et al., 2003;Peters et al., 2012]. We compare with a basic form given in Marin et al. [2012]. At each iteration, we randomly sample \u03b8 from the prior and then sample an observation X sim from the likelihood. If d(X sim , X obs ) < we add \u03b8 to our collection.\nHere d(\u2022, \u2022) is some metric on a sufficient statistic of the observation and > 0 is a prespecified threshold. We perform a KDE on the collected samples to estimate the posterior. The performance of ABC depends on : As for MCMC-DE we choose by experimenting with different values and choosing the value which gives the best performance within the queries used. We compare with total number of parameter values proposed and not just those retained.", "publication_ref": ["b17", "b21", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "Uniform Random Samples (RAND):", "text": "Here, we evaluate the likelihood at points chosen uniformly on \u0398 and then regress on these points.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "We first look at a series of low and high dimensional synthetic and real astrophysical experiments. NED is only tested on low dimensional problems since empirical approximation and numerical integration is computationally expensive in high dimensions. Further, since the inner expectation in Equation ( 4) is expensive we approximate it using a one sample estimate. We use a squared exponential kernel in all our experiments. The bandwidth for the kernel was set to be 5n \u22121/d where n is the total number of queries and d is the dimension. This was following several kernel methods (such as kernel regression) which use a bandwidth on the order O(n et al., 2002]. Other kernel hyperparameters was set via cross validation every 20 iterations. In our experiments, EV slightly outperforms NED probably since the EV utility can be evaluated exactly while NED can only approximated. We omit most technical details of the experiments due to space constraints.\n\u2212c 1 c 2 +d ) [Gy\u00f6rfi", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Low Dimensional Synthetic Experiments:", "text": "To illustrate our methods we have two simple yet instructive experiments. In the first, the parameters space is \u0398 = (0, 1) equipped with a Beta(1.2, 1) prior. We draw \u03b8 from the prior, and then draw 500 samples from a Bernoulli(\u03b8 2 + (1 \u2212 \u03b8) 2 ) distribution: i.e. X obs \u2208 {0, 1} 500 . The ambiguity on the true value of \u03b8 creates a bimodal posterior. Figure 3(a) compares NED/EV against the other methods as a function of the number of queries. The second is a 2D problem with \u0398 = (0, 1) 2 . Here we artificially created a 3-modal log-joint posterior shown by green contours in Figure 3(c). Figure 3(b) compares all methods. As we artificially constructed the log likelihood ABC does not apply here. Figure 3(c) shows the points chosen by the NED query strategy in order. It shows that we have learned the high log joint probability regions well at the expense of being uncertain at low log joint probability areas. However, this does not affect the posterior significantly as they are very small after exponentiation. Our proposed methods outperform existing methods and other heuristics by orders of magnitude on these simple experiments.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Higher Dimensional Synthetic Datasets:", "text": "We test in d = 5 and 15 dimensions. We construct an artificial log likelihood so that the resulting posterior is mixture of 2 Gaussians centred at 0 and 1. We evaluate performance by the ability to estimate certain linear functionals. The exact value of these functionals can be evaluated analytically since we know the true posterior. We use a uniform prior. Our log-likelihood is, (\u03b8) = log(0.5 N (\u03b8; 0, 0.5\n\u221a dI) + 0.5 N (\u03b8; 1, 0.5 \u221a dI)). Our func- tionals are T 1 = E d i=1 X i , T 2 = E d i=1 X 2 i , T 3 = E d\u22121 i=1 X 2 i X i+1 and T 4 = E d\u22122 i=1 X i X i+1 X i+2 .\nFor MCMC-DE, we draw samples Z 1 , Z 2 , . . . from the true likelihood. To estimate T i = E\u03c6 i (X) we use the empirical esti-\nmator T i = 1/N k \u03c6 i (Z k ).\nFor EV , MCMC-R and RAND we first use the queried points to obtain an estimate of the loglikelihood by regressing on the likelihood values as explained before. Then we run an MCMC chain on this estimate to collect samples and use the empirical estimator for the functionals. Note that evaluating the estimate, unlike the likelihood, is cheap. ABC does not apply in this experiment. The results are shown in Figure 4. They demonstrate the superiority of our query strategy over the alternatives.", "publication_ref": [], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Type Ia Supernovae:", "text": "We use supernovae data for inference on 3 cosmological parameters: Hubble Constant (H 0 \u2208 (60, 80), Dark Matter Fraction \u2126 M \u2208 (0, 1) and Dark Energy Fraction \u2126 \u039b \u2208 (0, 1). The likelihood for the experiment is given by the Robertson-Walker metric which models the distance to a supernova given the parameters and the observed red-shift. The dataset is taken from Davis et al [2007]. The parameter space is taken to be \u0398 = (0, 1) 3 (For H 0 we map it to (60, 80) using an appropriate linear transform). We test NED/EV against MCMC-DE, ABC, MCMC-R, RAND and Emcee. For ABC, sampling from the likelihood is as expensive as computing the likelihood. Figure 5(a) compares all methods. Figure 5(b) shows the points queried by EV and the marginals of the true posterior. The KL for RAND decreases slowly since it accumulates points at the high likelihood region very slowly. MCMC-R performs poorly since it has only explored part of the high likelihood region. For NED/EV after an initial exploration phase after which the error shoots down.", "publication_ref": ["b3"], "figure_ref": ["fig_5", "fig_5"], "table_ref": []}, {"heading": "Luminous Red Galaxies:", "text": "Here we used data on Luminous Red Galaxies (LRGs) for inference on 8 cosmological parameters. We use software and data from Tegmark et al [2006]. Our parameter space is taken to be (0, 1) 8 by appropriately linear transforming the range of the variables. Each query takes about 4-5 seconds. In EV determining the next point takes about 0.5-1 seconds with \u2248 2000 points and about 10-15 seconds with \u2248 10000 points. In this regime, EV is wall clock time competitive with other methods. ABC does not apply in this experiment. Fig. 6a shows points queried by MCMC, RAND and EV projected on the first 2 dimensions. MCMC has several high likelihood points but its queries are focused on a small region of the space. RAND does not have many points at high likelihood regions. EV has explored the space fairly well and at the same time has several queries at high likelihood regions. Fig 6c shows the evaluated log likelihood at each query. It shows that as predicted EV first explores the space (high likelihood queries are sparse) and then exploits the high likelihood regions. Since ground truth is difficult to obtain for this experiment, we perform the following simple test. We queried 250, 000 points uniformly at random from the parameter space to form a test set. We then run EV, MCMC-R and RAND for up to 12, 000 queries to collect points and estimate the posterior. Performance is evaluated by the mean squared reconstruction error of the exponentiated log joint probabilities (joint probabilities). Figure 6b shows the results. The error for RAND and MCMC-R stay the same throughout since the problem is difficult and they did not have sufficient number of high likelihood points throughout the space.", "publication_ref": ["b28"], "figure_ref": ["fig_6", "fig_6", "fig_6"], "table_ref": []}, {"heading": "Conclusions", "text": "We proposed a framework for query efficient posterior estimation for expensive blackbox likelihood evaluations. Our methods use GPs and are based on popular ideas in Bayesian active learning. We demonstrate that our methods outperform natural alternatives in practice.\nNote that in Machine Learning it is uncommon to treat posterior estimation in a regression setting. This is probably since the estimate will depend on the intricacies of the regression algorithm. So if likelihood evaluations are inexpensive, MCMC seems a natural choice due to its theoretical guarantees in the large sample regime. However, our work demonstrates that when likelihood evaluations are expensive, such  for up to 1600 queries and up to 4 times as many for MCMC and ABC. For evaluation, KL was approximated via numeric integration on a (100) 3 grid. Note that MCMC and ABC require several queries before a nontrivial KL with the truth is obtained. All curves were obtained by averaging over 30 runs. (b): Projections of the points selected by EV (bottom row) and the marginal distributions (top row). The value of the log likelihood (y-axis) obtained at each query (x-axis) for the 3 methods. Observe that in EV, initially the high likelihood evaluations are sparse-indicating exploration, and then there are several high likelihood evaluations-indicating exploitation.\nas in scientific simulations, treating posterior estimation in an active regression framework enables us to be significantly query efficient.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Acknowledgement: This research was partly funded by DOE grant DESC0011114.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "The Gaussian Process Density Sampler. In NIPS", "journal": "", "year": "2008", "authors": "Ryan Prescott Adams; Iain Murray; David J C Mackay"}, {"ref_id": "b1", "title": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning", "journal": "CoRR", "year": "2010", "authors": "Eric Brochu; Vlad M Cora; Nando De Freitas"}, {"ref_id": "b2", "title": "Active learning for identifying function threshold boundaries", "journal": "MIT Press", "year": "2006", "authors": "Brent Bryan; Jeff Schneider; Robert Nichol; Christopher Miller; Christopher Genovese; Larry Wasserman"}, {"ref_id": "b3", "title": "Scrutinizing Exotic Cosmological Models Using ESSENCE Supernova Data Combined with Other Cosmological Probes", "journal": "The Astrophysical Journal", "year": "2007", "authors": "M Davis"}, {"ref_id": "b4", "title": "The MCMC Hammer", "journal": "", "year": "2013-01", "authors": "Daniel Foreman-Mackey; David W Hogg; Dustin Lang; Jonathan Goodman"}, {"ref_id": "b5", "title": "Kernel Bayes' Rule: Bayesian Inference with Positive Definite Kernels", "journal": "Journal of Machine Learning Research", "year": "2014", "authors": "Kenji Fukumizu; Le Song; Arthur Gretton"}, {"ref_id": "b6", "title": "Adaptive Submodularity: Theory and Applications in Active Learning and Stochastic Optimization", "journal": "Journal of Artificial Intelligence Research", "year": "2011", "authors": "Daniel Golovin; Andreas Krause"}, {"ref_id": "b7", "title": "Active Learning for Level Set Estimation", "journal": "", "year": "2013", "authors": "Alkis Gotovos; Nathalie Casati; Gregory Hitz; Andreas Krause"}, {"ref_id": "b8", "title": "Sampling for Inference in Probabilistic Models with Fast Bayesian Quadrature", "journal": "", "year": "2014", "authors": "Tom Gunter; Michael A Osborne; Roman Garnett; Philipp Hennig; Stephen J Roberts"}, {"ref_id": "b9", "title": "A Distribution Free Theory of Nonparametric Regression", "journal": "Springer Series in Statistics", "year": "2002", "authors": "L\u00e1szl\u00f3 Gy\u00f6rfi; Micael Kohler; Adam Krzyzak; Harro Walk"}, {"ref_id": "b10", "title": "High Dimensional Bayesian Optimisation and Bandits via Additive Models", "journal": "", "year": "2015", "authors": "Kirthevasan Kandasamy; Jeff Schneider; Barnab\u00e1s P\u00f3czos"}, {"ref_id": "b11", "title": "Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies", "journal": "J. Mach. Learn. Res", "year": "2008", "authors": "Andreas Krause; Ajit Singh; Carlos Guestrin"}, {"ref_id": "b12", "title": "A Guide to Monte Carlo Simulations in Statistical Physics", "journal": "Cambridge University Press", "year": "2005", "authors": "David Landau; Kurt Binder"}, {"ref_id": "b13", "title": "Monte Carlo strategies in Scientific computing", "journal": "Springer", "year": "2001", "authors": "S Jun;  Liu"}, {"ref_id": "b14", "title": "Active Area Search via Bayesian Quadrature", "journal": "", "year": "2014", "authors": "Yifei Ma; Roman Garnett; Jeff Schneider"}, {"ref_id": "b15", "title": "Information Theory, Inference, and Learning Algorithms", "journal": "Cambridge University Press", "year": "2003", "authors": "J C David;  Mackay"}, {"ref_id": "b16", "title": "Approximate Bayesian computational methods", "journal": "Statistics and Computing", "year": "2012", "authors": "Jean-Michel Marin; Pierre Pudlo; Christian P Robert; Robin J Ryder"}, {"ref_id": "b17", "title": "Markov Chain Monte Carlo without Likelihoods", "journal": "", "year": "2003", "authors": "Paul Marjoram; John Molitor; Vincent Plagnol; Simon Tavar\u00e9"}, {"ref_id": "b18", "title": "Bayesian approach to global optimization and application to multiobjective and constrained problems", "journal": "Journal of Optimization Theory and Applications", "year": "1991", "authors": "J B Mockus; L J Mockus"}, {"ref_id": "b19", "title": "Active Learning of Model Evidence Using Bayesian Quadrature", "journal": "", "year": "2012", "authors": "M Osborne; D Duvenaud; R Garnett; C Rasmussen; S Roberts; Z Ghahramani"}, {"ref_id": "b20", "title": "A Bayesian model selection analysis of WMAP3", "journal": "Physical Review", "year": "2006", "authors": "David Parkinson; Pia Mukherjee; Andrew R Liddle"}, {"ref_id": "b21", "title": "On sequential Monte Carlo, partial rejection control and approximate Bayesian computation", "journal": "Statistics and Computing", "year": "2012", "authors": "W Gareth; Y Peters; Scott A Fan;  Sisson"}, {"ref_id": "b22", "title": "Gaussian Processes for Machine Learning. Adaptative computation and machine learning series", "journal": "", "year": "2006", "authors": "C E Rasmussen; C K I Williams"}, {"ref_id": "b23", "title": "Monte Carlo Statistical Methods (Springer Texts in Statistics)", "journal": "Springer-Verlag New York, Inc", "year": "2005", "authors": "P Christian; George Robert;  Casella"}, {"ref_id": "b24", "title": "Gaussian Process Regression: Active Data Selection and Test Point Rejection", "journal": "", "year": "2000", "authors": "Sambu Seo; Marko Wallat; Thore Graepel; Klaus Obermayer"}, {"ref_id": "b25", "title": "Active Learning Literature Survey", "journal": "", "year": "2010", "authors": "Burr Settles"}, {"ref_id": "b26", "title": "Nested sampling for general Bayesian computation", "journal": "Bayesian Anal", "year": "2006", "authors": "John Skilling"}, {"ref_id": "b27", "title": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design", "journal": "", "year": "2010", "authors": "Niranjan Srinivas; Andreas Krause; Sham Kakade; Matthias Seeger"}, {"ref_id": "b28", "title": "Cosmological Constraints from the SDSS Luminous Red Galaxies", "journal": "Physical Review", "year": "2006-12", "authors": "M Tegmark"}], "figures": [{"figure_label": "151", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "IJCAI- 15 Figure 1 :151Figure 1: Illustrations of Cosmological Experiments. (a): Given a parameter value \u03b8 the oracle produces several simulations X sim . The", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: (a): Samples drawn from the GP uncertainty models in the log joint probability space. (b): The same samples after exponentiation.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "The exp(2\u00b5(\u03b8 + )) will squash high variances in the low likelihood regions and amplify low variances in the high likelihood regions (Fig 2(a), 2(b)).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3: (a), (b): A comparison of NED/EV against MCMC-DE, ABC, MCMC-R, RAND procedures for the 1D and 2D synthetic experiments respectively. The x-axis is the number of queries and the y-axis is the KL divergence between the truth and the estimate. All figures were obtained by averaging over 60 trials. (c): The 100 points chosen by NED for the 2D experiment in the order they were queried. The green contours are the true posterior. Initially the algorithm explores the space before focusing on the high likelihood regions.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 4 :4Figure 4: The first and second rows are for d = 5 and d = 15 and the 4 columns are for the functionals T1, T2, T3, T4 respectively. Thex-axis is the number of queries and the y-axis is | Ti \u2212 Ti|/|Ti|. We go up to 500 queries for d = 5 and 3200 queries for d = 15. All figures were obtained by averaging over 30 trials.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 5 :5Figure 5: (a): Comparison of NED/EV against MCMC-DE, ABC, Emcee, MCMC-R and RAND. For all regression methods we show results", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 6 :6Figure 6: (a): The projections of the first 6000 points selected by MCMC, RAND and EV on to the first 2 dimensions in cyan. The points shown in red are queries at high likelihood (log P > \u221250) points. (b): Comparison of EV against MCMC-R and RAND. We use up to 12000 queries for all methods. The y-axis is the mean squared reconstruction error. The curves were obtained by averaging over 16 runs. (c):The value of the log likelihood (y-axis) obtained at each query (x-axis) for the 3 methods. Observe that in EV, initially the high likelihood evaluations are sparse-indicating exploration, and then there are several high likelihood evaluations-indicating exploitation.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "P \u03b8|X obs (\u03b8|X obs ) = L(\u03b8)P \u03b8 (\u03b8) \u0398 L(\u03b8)P \u03b8 (\u03b8) = L(\u03b8)P \u03b8 (\u03b8) P (X obs )(1)", "formula_coordinates": [2.0, 69.74, 586.55, 227.26, 25.37]}, {"formula_id": "formula_1", "formula_text": "A t\u22121 = {\u03b8 i , L i } t\u22121 i=1", "formula_coordinates": [2.0, 476.55, 228.02, 80.95, 13.16]}, {"formula_id": "formula_2", "formula_text": "P At (\u03b8|X obs ) = exp P At (X obs , \u03b8) \u0398 exp P At (X obs , \u03b8)(2)", "formula_coordinates": [2.0, 357.62, 324.25, 200.38, 28.63]}, {"formula_id": "formula_3", "formula_text": "ing A t\u22121 \u222a {(\u03b8 + , L(\u03b8 + ))}.", "formula_coordinates": [2.0, 315.0, 469.59, 111.23, 9.65]}, {"formula_id": "formula_4", "formula_text": "(b) (a) (b) (1) (2) (3) (4) (5) (c) (1) (a) (b) (3) (4)(5)", "formula_coordinates": [3.0, 239.43, 58.57, 303.57, 99.47]}, {"formula_id": "formula_5", "formula_text": "(d)", "formula_coordinates": [3.0, 483.3, 150.27, 10.45, 7.77]}, {"formula_id": "formula_6", "formula_text": "L i P \u03b8 (\u03b8 i )) t i=1", "formula_coordinates": [3.0, 219.72, 280.37, 53.62, 12.33]}, {"formula_id": "formula_7", "formula_text": "u NED t (\u03b8 + ) = \u2212E p+ E h D( h P A\u222a{(\u03b8+,p+)} m+1", "formula_coordinates": [3.0, 83.24, 435.91, 175.73, 14.03]}, {"formula_id": "formula_9", "formula_text": "\u00b5(\u03b8 + ) \u2206 = E F \u03b8|X obs log P (X obs , \u03b8 + ) = k(A, \u03b8 + ) k(A, A) \u22121 j (5) \u03c3 2 (\u03b8 + ) \u2206 = V F \u03b8|X obs log P (X obs , \u03b8 + ) = k(\u03b8 + , \u03b8 + ) \u2212 k(A, \u03b8 + ) k(A, A) \u22121 k(A, \u03b8 + )", "formula_coordinates": [3.0, 345.22, 332.69, 212.78, 66.97]}, {"formula_id": "formula_10", "formula_text": "L i P \u03b8 (\u03b8 i )) m i=1 \u2208 R m .", "formula_coordinates": [3.0, 350.19, 431.49, 83.54, 12.33]}, {"formula_id": "formula_11", "formula_text": "u EV t (\u03b8 + ) = V F \u03b8|X obs P (X obs , \u03b8 + ) = (6) exp(2\u00b5(\u03b8 + ) + \u03c3 2 (\u03b8 + ))(exp(\u03c3 2 (\u03b8 + )) \u2212 1)", "formula_coordinates": [3.0, 345.99, 473.02, 212.01, 28.67]}, {"formula_id": "formula_12", "formula_text": "\u2212c 1 c 2 +d ) [Gy\u00f6rfi", "formula_coordinates": [4.0, 315.0, 314.92, 243.0, 25.23]}, {"formula_id": "formula_13", "formula_text": "\u221a dI) + 0.5 N (\u03b8; 1, 0.5 \u221a dI)). Our func- tionals are T 1 = E d i=1 X i , T 2 = E d i=1 X 2 i , T 3 = E d\u22121 i=1 X 2 i X i+1 and T 4 = E d\u22122 i=1 X i X i+1 X i+2 .", "formula_coordinates": [5.0, 54.0, 253.06, 243.01, 46.81]}, {"formula_id": "formula_14", "formula_text": "mator T i = 1/N k \u03c6 i (Z k ).", "formula_coordinates": [5.0, 54.0, 323.84, 116.25, 11.15]}], "doi": ""}