{"title": "Do Differentiable Simulators Give Better Policy Gradients?", "authors": "H J Terry Suh; Max Simchowitz; Kaiqing Zhang; Russ Tedrake", "pub_date": "", "abstract": "Differentiable simulators promise faster computation time for reinforcement learning by replacing zeroth-order gradient estimates of a stochastic objective with an estimate based on first-order gradients. However, it is yet unclear what factors decide the performance of the two estimators on complex landscapes that involve long-horizon planning and control on physical systems, despite the crucial relevance of this question for the utility of differentiable simulators. We show that characteristics of certain physical systems, such as stiffness or discontinuities, may compromise the efficacy of the first-order estimator, and analyze this phenomenon through the lens of bias and variance. We additionally propose an \u03b1-order gradient estimator, with \u03b1 \u2208 [0, 1], which correctly utilizes exact gradients to combine the efficiency of first-order estimates with the robustness of zeroorder methods. We demonstrate the pitfalls of traditional estimators and the advantages of the \u03b1-order estimator on some numerical examples.", "sections": [{"heading": "Introduction", "text": "Consider the problem of minimizing a stochastic objective,\nmin \u03b8 F (\u03b8) = min \u03b8 E w f (\u03b8, w).\nAt the heart of many algorithms for reinforcement learning (RL) lies zeroth-order estimation of the gradient \u2207F (Sutton et al., 2000;Schulman et al., 2017). Yet, in domains that deal with structured systems, such as linear control, physical simulation, or robotics, it is possible to obtain exact gradients of f , which can also be used to construct a firstorder estimate of \u2207F . The availability of both options begs Figure 1. Examples of simple optimization problems on physical systems. Goal is to: A. maximize y position of the ball after dropping. B. maximize distance thrown, with a wall that results in inelastic impact. C. maximize transferred angular momentum to the pivoting bar through collision. Second row: the original objective and the stochastic objective after randomized smoothing.\nthe question: given access to exact gradients of f , which estimator should we prefer?\nIn stochastic optimization, the theoretical benefits of using first-order estimates of \u2207F over zeroth-order ones have mainly been understood through the lens of variance and convergence rates (Ghadimi & Lan, 2013;Mahamed et al., 2020): the first-order estimator often (not always) results in much less variance compared to the zeroth-order one, which leads to faster convergence rates to a local minima of general nonconvex smooth objective functions.\nHowever, the landscape of RL objectives that involve longhorizon sequential decision making (e.g. policy optimization) is challenging to analyze, and convergence properties in these landscapes are relatively poorly understood, except for structured settings such as finite-state MDPs (Agarwal et al., 2020;Zhang et al., 2020) or linear control (Fazel et al., 2019;Bhandari & Russo, 2020). In particular, physical systems with contact, as we show in Figure 1, can display complex characteristics including nonlinearities, non-smoothness, and discontinuities (van der Schaft & Schumacher, 2000;Mason, 2001;Suh et al., 2021).\nNevertheless, lessons from convergence rate analysis tell us that there may be benefits to using the exact gradients even for these complex physical systems. Such ideas have been championed through the term \"differentiable simulation\", where forward simulation of physics is programmed arXiv:2202.00817v2 [cs.LG] 22 Aug 2022 in a manner that is consistent with automatic differentiation (Freeman et al., 2021;Hu et al., 2020;Tedrake, 2022;Werling et al., 2021;Geilinger et al., 2020;Howell et al., 2022), or computation of analytic derivatives (Carpentier et al., 2019). These methods have shown promising results in decreasing computation time compared to zeroth-order methods (Huang et al., 2021;Freeman et al., 2021;Gradu et al., 2021;Du et al., 2020;de Avila Belbute-Peres et al., 2018;Mora et al., 2021).\nExisting literature in differentiable simulation mainly focuses on the use of exact gradients for deterministic optimization. However, (Suh et al., 2021;Le Lidec et al., 2021) show that using exact gradients for a deterministic objective can lead to suboptimal behavior of certain systems due to their landscapes. In these systems, stochasticity can be used to regularize the landscapes with randomized smoothing (Duchi et al., 2015). We illustrate how the landscapes change upon injecting noise (Figure 1), and list some benefits of considering a surrogate stochastic objective.\n\u2022 Stochasticity smooths local minima. As noted in (Suh et al., 2021;Metz et al., 2021), stochasticity can alleviate some of the high-frequency local minima that deterministic gradients will be stuck on. For instance, the small discontinuity on the right side of Figure 1.B is filtered by Gaussian smoothing. \u2022 Stochasticity alleviates flat regions. In systems of Figure 1, the gradients in some of the regions can be completely flat. This stalls progress of gradient descent. The stochastic objective, however, still has non-zero gradient as some samples escape the flat regions and provide an informative direction of improvement. \u2022 Stochasticity encodes robustness. In Figure 1.C, following the gradient to increase the transferred momentum causes the ball to miss the pivot and land in a high-cost region. In contrast, the stochastic objective has a local minimum within the safe region, as the samples provide information about missing the pivot.\nThus, our work attempts to compare two versions of gradient estimators in the stochastic setting: the first-order estimator and the zeroth-order one. This setting rules out the case that zeroth-order estimates perform better simply because of stochasticity, and sets equal footing for the two methods.\nWhen f is continuous, these quantities both converge to the same quantity (\u2207F ) in expectation. We first show that even with continuous f , the first-order gradient estimate can result in more variance than the zeroth-order one due to the stiffness of dynamics or due to compounding of gradients in chaotic systems (Parmas et al., 2018;Metz et al., 2021).\nIn addition, we show that the assumption of continuous f can be violated in many relevant physical systems that are nearly/strictly discontinuous in the underlying landscape. These discontinuities are commonly caused by contact and geometrical constraints. We provide minimal examples to highlight specific challenges in Figure 1. These are not mere pathologies, but abstractions of more complicated examples that are rich with contact, such as robotic manipulation.\nWe show that the presence of such discontinuities causes the first-order gradient estimator to be biased, while the zerothorder one still remains unbiased under discontinuities. Furthermore, we show that stiff continuous approximations of discontinuities, even if asymptotically unbiased, can still suffer from what we call empirical bias under finite-sample settings. This results in a bias-variance tradeoff between the biased first-order estimator and the often high-variance, yet unbiased zeroth-order estimator. Intriguingly, we find that the bias-variance tradeoff in this setting manifests itself not through convergence rates, but through different local minima. This shows that the two estimators may fundamentally operate on different landscapes implicitly.\nThe presence of discontinuities need not indicate that we need to commit ourselves to uniformly using one of the estimators. Many physical systems are hybrid by nature (van der Schaft & Schumacher, 2000); they consist of smooth regions that are separated by manifolds of nonsmoothness or discontinuities. This suggests that we may be able to utilize the first-order estimates far away from these manifolds to obtain benefits of convergence rates, while switching to zeroth-order ones in the vicinity of discontinuities to obtain unbiased estimates.\nFor this purpose, we further attempt to answer the question: how can we then correctly utilize exact gradients of f for variance reduction when we know the objective is nearly discontinuous? Previous works show that the two estimators can be combined by interpolating based on empirical variance (Parmas et al., 2018;Metz et al., 2019;Mahamed et al., 2020). However, we show that in the presence of neardiscontinuities, selecting based on empirical variance alone can lead to highly inaccurate estimates of \u2207F , and propose a robustness constraint on the accuracy of the interpolated estimate to remedy this effect.\nContributions. We 1) shed light on some of the inherent problems of RL using differentiable simulators, and answer which gradient estimator can be more useful under different characteristics of underlying systems such as discontinuities, stiffness, and chaos; and 2) present the \u03b1-order gradient estimator, a robust interpolation strategy between the two gradient estimators that utilizes exact gradients without falling into the identified pitfalls of the previous methods.\nWe hope both contributions inspire algorithms for policy optimization using differentiable simulators, as well as design guidelines for new and existing simulators.", "publication_ref": ["b47", "b42", "b18", "b0", "b55", "b15", "b3", "b51", "b30", "b46", "b33", "b21", "b48", "b53", "b17", "b20", "b5", "b22", "b33", "b19", "b10", "b9", "b35", "b46", "b27", "b46", "b33", "b37", "b33", "b51", "b37", "b32"], "figure_ref": [], "table_ref": []}, {"heading": "Preliminaries", "text": "Notation. We denote the expectation of a random vector z as E[z], and its variance as\nVar[z] := E[ z \u2212 E[z] 2 ].\nExpectations are defined in almost-sure sense, so that the law of large numbers holds (see Appendix A.1 for details).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Setting.", "text": "We study a discrete-time, finite-horizon, continuous-state control problem with states x \u2208 R n , inputs u \u2208 R m , transition function \u03c6 : R n \u00d7 R m \u2192 R n , and horizon H \u2208 N. Given a sequence of costs c h : R n \u00d7 R m \u2192 R, a family of policies \u03c0 h : R n \u00d7 R d \u2192 R m parameterized by \u03b8 \u2208 R d , and a sequence of injected noise terms w 1:H \u2208 (R m ) H , we define the cost-to-go functions\nV h (x h , w h:H , \u03b8) = H h =h c h (x h , u h ), s.t. x h +1 = \u03c6(x h , u h ), u h = \u03c0(x h , \u03b8) + w h , h \u2265 h.\nOur aim is to minimize the policy optimization objective\nF (\u03b8) := E x1\u223c\u03c1 E w h i.i.d. \u223c p V 1 (x 1 , w 1:H , \u03b8), (1\n)\nwhere \u03c1 is a distribution over initial states x 1 , and w 1 , . . . , w H are independent and identically distributed according to some distribution p. In the main text, we make the following assumption on the distributions \u03c1 and p:\nAssumption 2.1. We assume that \u03c1 has finite moments, and that p = N (0, \u03c3 2 I n ) for some \u03c3 > 0.\nOur rationale for Gaussian p is that we view w 1:H as smoothing to regularize the optimization landscape (Duchi et al., 2011;Berahas et al., 2019). To simplify the main text, we take x 1 to be deterministic (\u03c1 is a dirac-delta), with general \u03c1 being addressed in the appendix. Settingw = w 1:H , p = N (0, \u03c3 2 I nH ), and f (\u03b8,w) = V 1 (x 1 ,w, \u03b8), we can express F (\u03b8) as a stochastic optimization problem, F (\u03b8) := Ew \u223cp f (\u03b8,w).\nTrajectory optimization. Our parametrization also includes open-loop trajectory optimization. Letting the policy parameters be an open-loop sequence of inputs \u03b8 = {\u03b8 h } H h=1 and having no feedback \u03c0(x h , \u03b8) = \u03b8 h , we optimize over sequence of inputs to be applied to the system.\nOne-step optimization. We illustrate some key ideas in the open-loop case where H = 1:\n\u03c0 : R d \u2192 R m is the identity function withw = w \u2208 R m , d = m and c : R m \u2192 R, F (\u03b8) = E w\u223cp f (\u03b8, w), f (\u03b8, w) = c(\u03b8 + w). (2)", "publication_ref": ["b11", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Gradient Estimators", "text": "In order to minimize F (\u03b8), we consider iterative optimization using stochastic estimators of its gradient \u2207F (\u03b8). We say a function \u03c8 : R d1 \u2192 R d2 has polynomial growth if there exist constants a, b such that, for all z \u2208 R d1 , \u03c8(z) \u2264 a(1 + z b ). The following assumption ensures these gradients are well-defined.\nAssumption 2.2. We assume that the policy \u03c0 is continuously differentiable everywhere, and the dynamics \u03c6, as well as the cost c h have polynomial growth.\nEven when the costs or dynamics are not differentiable, the expected cost F (\u03b8) is differentiable due to the smoothin\u1e21 w. \u2207F (\u03b8) is referred to as the policy gradient.\nZeroth-order estimator. The policy gradient can be estimated only using samples of the function values.\nDefinition 2.3. Given a single zeroth-order estimate of the policy gradient\u2207 [0] F i (\u03b8), we define the zeroth-order batched gradient (ZoBG)\u2207 [0] F (\u03b8) as the sample mean,\n\u2207 [0] Fi(\u03b8) := 1 \u03c3 2 V 1 (x 1 , w i 1:H , \u03b8) H h=1 D \u03b8 \u03c0(x i h , \u03b8) w i h \u2207 [0] F (\u03b8) := 1 N N i=1\u2207 [0] F i (\u03b8),\nwhere x i h is the state at time h of a trajectory induced by the noise w i 1:H , i is the index of the sample trajectory, and D \u03b8 \u03c0 is the Jacobian matrix \u2202\u03c0/\u2202\u03b8 \u2208 R m\u00d7d .\nThe hat notation denotes a per-sample Monte-Carlo estimate, and bar-notation a sample mean. The ZoBG is also referred to as the REINFORCE (Williams, 1992), score function, or the likelihood-ratio gradient.\nBaseline. In practice, a baseline term b is subtracted from V 1 (x 1 , w i 1:H , \u03b8) for variance reduction. We use the zeronoise rollout as the baseline b = V 1 (x 1 , 0 1:H , \u03b8) (Berahas et al., 2019):\n1 \u03c3 2 V1(x1, w i 1:H , \u03b8) \u2212 b H h=1 D \u03b8 \u03c0(x i h , \u03b8) w i h .\nFirst-order estimator. In differentiable simulators, the gradients of the dynamics \u03c6 and costs c h are available almost surely (i.e., with probability one). Hence, one may compute the exact gradient \u2207 \u03b8 V 1 (x 1 , w 1:H , \u03b8) by automatic differentiation and average them to estimate \u2207F (\u03b8).\nDefinition 2.4. Given a single first-order gradient esti-mate\u2207 [1] F i (\u03b8), we define the first-order batched gradient (FoBG) as the sample mean:\n\u2207 [1] Fi(\u03b8) := \u2207 \u03b8 V 1 (x 1 , w i 1:H , \u03b8) \u2207 [1] F (\u03b8) := 1 N N i=1\u2207 [1] F i (\u03b8).\nThe FoBG is also referred to as the reparametrization gradient (Kingma et al., 2015), or the pathwise derivative (Schulman et al., 2015). Finally, we define the empirical variance. Definition 2.5 (Empirical variance). For k \u2208 {0, 1}, we define the empirical variance b\u0177\n\u03c3 2 k = 1 N \u22121 N i=1 \u2207 [k] F i (\u03b8) \u2212\u2207 [k] F (\u03b8) 2 .", "publication_ref": ["b54", "b2", "b25", "b40"], "figure_ref": [], "table_ref": []}, {"heading": "Pitfalls of First-order Estimates", "text": "What are the cases for which we would prefer to use the ZoBG over the FoBG in policy optimization using differentiable simulators? Throughout this section, we analyze the performance of the two estimators through their bias and variance properties, and find pathologies where using the first-order estimator blindly results in worse performance.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Bias under discontinuities", "text": "Under standard regularity conditions, it is well-known that both estimators are unbiased estimators of the true gradient \u2207F (\u03b8). However, care must be taken to define these conditions precisely. Fortunately, the ZoBG is still unbiased under mild assumptions.\nLemma 3.1. Under Assumption 2.1 and Assumption 2.2, the ZoBG is an unbiased estimator of the stochastic objective.\nE[\u2207 [0] F (\u03b8)] = \u2207F (\u03b8).\nIn contrast, the FoBG requires strong continuity conditions in order to satisfy the requirement for unbiasedness. However, under Lipschitz continuity, it is indeed unbiased.\nLemma 3.2. Under Assumption 2.1 and Assumption 2.2, and if \u03c6(\u2022, \u2022) is locally Lipschitz and c h (\u2022, \u2022) is continuously differentiable, then\u2207 [1] F (\u03b8) is defined almost surely, and\nE[\u2207 [1] F (\u03b8)] = \u2207F (\u03b8).\nThe proofs and more rigorous statements of both lemmas are provided in Appendix A. Notice that Lemma 3.1 permits V h to have discontinuities (via discontinuities of c h and \u03c6), whereas Lemma 3.2 does not.\nBias of FoBG under discontinuities. The FoBG can fail when applied to discontinuous landscapes. We illustrate a simple case of biasedness through a counterexample. Example 3.3 (Heaviside). (Bangaru et al., 2021;Suh et al., 2021) Consider the Heaviside function,\nf (\u03b8, w) = H(\u03b8 + w), H(t) = 1 t \u2265 0 0 t < 0 ,\nwhose stochastic objective becomes the error function\nF (\u03b8) = E w [H(\u03b8 + w)] = erf(\u2212\u03b8; \u03c3 2 ),\nwhere erf(t; \u03c3 2 ) := \u221e t 1 \u221a 2\u03c0\u03c3 e \u2212x 2 /\u03c3 2 dx is the Gaussian tail integral. Defining the gradient of the Monte-Carlo objective H(\u03b8 + w) requires subtlety. It is common in physics to define \u2207 \u03b8 H(\u03b8 + w) = \u03b4(\u03b8 + w) as a diracdelta function, where integration is interpreted so that the fundamental theorem of calculus holds. This is irreconcilable with using expectation to define the integral, which presupposes that the law of large numbers hold. Indeed, since \u2207 \u03b8 H(\u03b8 + w) = 0 for all \u03b8 = \u2212w, we have E wi \u03b4(\u03b8 + w i ) = 0. Hence, the FoBG is biased, because the gradient of the stochastic objective at any \u03b8 is non-zero:\n\u2207 \u03b8 erf(\u2212\u03b8; \u03c3 2 ) = 1 \u221a 2\u03c0\u03c3 exp(\u2212(\u03b8 \u2212 w)/2\u03c3 2 ) = 0.\nIt is worth noting that the empirical variance of the FoBG estimator in this example is zero, since all the samples are identically zero. On the other hand, the ZoBG escapes this problem and provides an unbiased estimate, since it always takes finite intervals that include the integral of the delta. ", "publication_ref": ["b1", "b46"], "figure_ref": [], "table_ref": []}, {"heading": "The \"Empirical bias\" phenomenon", "text": "One might argue that strict discontinuity is simply an artifact of modeling choice in simulators; indeed, many simulators approximate discontinuous dynamics as a limit of continuous ones with growing Lipschitz constant (Geilinger et al., 2020;Elandt et al., 2019). In this section, we explain how this can lead to a phenomenon we call empirical bias, where the FoBG appears to have low empirical variance, but is still highly inaccurate; i.e. it \"looks\" biased when a finite number of samples are used. Through this phenomenon, we claim that performance degradation of first-order gradient estimates do not require strict discontinuity, but is also present in continuous, yet stiff approximations of discontinuities. 1 Definition 3.4 (Empirical bias). Let z be a vector-valued random variable with E[ z ] < \u221e. We say z has (\u03b2, \u2206, S)empirical bias if there is a random event E such that Pr\n[E] \u2265 1 \u2212 \u03b2, and E[z | E] \u2212 E[z] \u2265 \u2206, but z \u2212 E[z | E] \u2264 S almost surely on E.\nA paradigmatic example of empirical bias is a random scalar z which takes the value 0 with probability 1 \u2212 \u03b2, and 1 \u03b2 with probability \u03b2. Setting E = {z = 0}, we see E[z] = 1, E[z | E] = 0, and so z satisfies (\u03b2, 1, 0)-empirical bias. Note that Var[z] = 1/\u03b2 \u2212 1; in fact, small-\u03b2 empirical bias implies large variance more generally. Lemma 3.5. Suppose z has (\u03b2, \u2206, S)-empirical bias. Then\nVar[z] \u2265 \u2206 2 0 \u03b2 , where \u2206 0 := max{0, (1 \u2212 \u03b2)\u2206 \u2212 \u03b2 E[z] }.\nEmpirical bias naturally arises for discontinuities or stiff continuous approximations. We give two examples of common discontinuities that arise in differentiable simulation, that permit continuous approximations. Example 3.6 (Coulomb friction). The Coulomb model of friction is discontinuous in the relative tangential velocity between two bodies. In many simulators (Geilinger et al., 2020;Castro et al., 2020), it is common to consider a continuous approximation instead. We idealize such approximations through a piecewise linear relaxation of the Heaviside that is continuous, parametrized by the width of the middle linear region \u03bd (which corresponds to slip tolerance).\nH \u03bd (t) = 2t/\u03bd if |t| \u2264 \u03bd/2 H(t) else .\nIn practice, lower values of \u03bd lead to more realistic behavior in simulation (Tedrake, 2022), but this has adverse effects for empirical bias. Considering f \u03bd (\u03b8, w) =H \u03bd (\u03b8 + w), we have F \u03bd (\u03b8) = E w [H \u03bd (\u03b8 + w)] := erf(\u03bd/2 \u2212 \u03b8; \u03c3 2 ). In particular, setting c \u03c3 := 1 \u221a 2\u03c0\u03c3 , then at \u03b8 = \u03bd/2, \u2207F \u03bd (\u03b8) = c \u03c3 , whereas, with probability at least c \u03c3 \u03bd, \u2207f \u03bd (\u03b8, w) = 0. Hence, the FoBG has (c \u03c3 \u03bd, c \u03c3 , 0) empirical bias, and its variance scales with 1/\u03bd as \u03bd \u2192 0. The limiting \u03bd = 0 case, corresponding to the Coulomb model, is the Heaviside from Example 3.3, where the limit of high empirical bias, as well as variance, becomes biased in expectation (but, surprisingly, zero variance!). We empirically illustrate this effect in Figure 4. We also note that more complicated models of friction (e.g. that incorporates the Stribeck effect (Stribeck, 1903)) would suffer similar problems. Example 3.7. (Geometric Discontinuity). Discontinuity also comes from surface normals. We show this in Figure 3, where balls that collide with a rectangular geometry  create discontinuities. It is possible to make a continuous relaxation (Elandt et al., 2019) by considering smoother geometry, depicted by the addition of the dome in Figure 3. While this makes FoBG no longer biased asymptotically, the stiffness of the relaxation results in high empirical bias.", "publication_ref": ["b17", "b13", "b17", "b6", "b48", "b45", "b13"], "figure_ref": ["fig_2", "fig_1", "fig_1"], "table_ref": []}, {"heading": "High variance first-order estimates", "text": "Even in the absence of empirical bias, we present other cases in which FoBG suffers simply due to high variance.\nScenario 1: Persistent stiffness. When the dynamics are stiff 2 , such as contact models with stiff spring approxima-  tions (Hunt & Crossley, 1975), the high norm of the gradient can contribute to high variance of the FoBG. Example 3.8. (Pushing with stiff contact). We demonstrate this phenomenon through a simple 1D pushing example in Figure 5, where the ZoBG has lower variance than the FoBG as stiffness increases, until numerical semi-implicit integration becomes unstable under a fixed timestep.\nIn practice, lowering the timestep can alleviate the issue at the cost of more computation time. Less stiff formulations of contact dynamics (Stewart & Trinkle, 2000;Mirtich, 1996) also addresses this problem effectively.\nScenario 2: Chaos. As noted in (Metz et al., 2021), even if the gradient of the dynamics is small at every h, their compounding product can cause \u2207 \u03b8 V 1 to be large if the system is chaotic. Yet, in expectation, the gradient of the stochastic objective \u2207F = \u2207E[V 1 ] can be benign and wellbehaved (Lasota & Mackey, 1996). Example 3.9. (Chaos of double pendulum). We demonstrate this in Figure 6 for a classic chaotic system of the double pendulum. As the horizon of the trajectory increases, the variance of FoBG becomes higher than that of ZoBG.\nComparison to ZoBG. Compared to the pitfalls of FoBG, the ZoBG variance can be bounded as follows.\nLemma 3.10. If for all x andw, |V 1 (x,w, \u03b8)| \u2264 B V and D \u03b8 \u03c0(x, \u03b8) op \u2264 B \u03c0 , then Var[\u2207 [0] F (\u03b8)] = 1 N Var[\u2207 [0] F i (\u03b8)] \u2264 B 2 V B 2 \u03c0 N \u2022 Hn \u03c3 2 .\nWe refer to Appendix B.2 for proof. Lemma 3.10 is intended to provide a qualitative understanding of the zeroth-order variance: it scales with the horizon-dimension product Hn, but not the scale of the derivatives. On the other hand, the variance of FoBG does; when Hn\n\u03c3 2 Var[\u2207 [1] F (\u03b8)] = Var[\u2207 \u03b8 V (x 1 ,w, \u03b8)]\n, the ZoBG has higher variance.\nspring-like components, \u2207\u03c6 scales with the spring constant. Thus, the presence of a stiff spring leads to a stiff system.", "publication_ref": ["b23", "b44", "b34", "b33", "b26"], "figure_ref": ["fig_3", "fig_4"], "table_ref": []}, {"heading": "\u03b1-order Gradient Estimator", "text": "Previous examples give us insight on which landscapes are better fit for first-order estimates of policy gradient, and which are better fit for zeroth-order ones. As shown in Figure 7, even on a single policy optimization objective, it is best to adaptively switch between the first and zerothorder estimators depending on the local characteristics of the landscape. In this section, we propose a strategy to achieve this adaptively, interpolating between the two estimators to reap the benefits of both approaches simultaneously. Definition 4.1. Given \u03b1 \u2208 [0, 1], we define the alpha-order batched gradient (AoBG) as:\n\u2207 [\u03b1] F (\u03b8) = \u03b1\u2207 [1] F (\u03b8) + (1 \u2212 \u03b1)\u2207 [0] F (\u03b8).\nWhen interpolating, we use independent trajectories to gen-erate\u2207 [1] F (\u03b8) and\u2207 [0] F (\u03b8) (see Appendix C.1). We consider strategies for selecting \u03b1 in a local fashion, as a function of the observed sample, as detailed below.", "publication_ref": [], "figure_ref": ["fig_5"], "table_ref": []}, {"heading": "A robust interpolation protocol", "text": "A potential approach might be to select \u03b1 based on achieving minimum variance (Parmas et al., 2018;Metz et al., 2019), considering empirical variance as an estimate. However, in light of the empirical bias phenomenon detailed in Section 3 (or even actual bias in the presence of discontinuities), we see that the empirical variance is unreliable, and can lead to inaccurate estimates for our setting. For this reason, we consider an additional criterion of uniform accuracy: Definition 4.2 (Accuracy). \u03b1 is (\u03b3, \u03b4)-accurate if the bound on the error of AoBG is satisfied with probability \u03b4:\n\u2207 [\u03b1] F (\u03b8) \u2212 \u2207F (\u03b8) \u2264 \u03b3.(3)\nTo remedy the limitations of considering empirical variance in isolation, we propose an interpolation protocol that can satisfy an accuracy guarantee, while still attempting to minimize the variance.\nmin \u03b1\u2208[0,1] \u03b1 2\u03c32 1 + (1 \u2212 \u03b1) 2\u03c32 0 s.t. + \u03b1 \u2207 [1] F \u2212\u2207 [0] F B \u2264 \u03b3. (4\n)\nWe explain the terms in Eq (4) below in detail.\nObjective. Since we interpolate the FoBG and ZoBG using independent samples,\n\u03b1 2\u03c32 1 + (1 \u2212 \u03b1) 2\u03c32 0 is an unbiased estimate of N \u2022 Var[\u2207 [\u03b1] F (\u03b8)].\nThus, our objective is to choose \u03b1 to minimize this variance.\nConstraint. Our constraint serves to enforce accuracy. Since the FoBG is potentially biased, we use ZoBG as a surrogate of \u2207F (\u03b8). For this purpose, we use > 0 as a confidence bound on \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) from the obtained samples. When is a valid confidence bound that holds with probability \u03b4, we prove that our constraint in Eq (4) guarantees accuracy in Eq (3).\nLemma 4.3 (Robustness). Suppose that + \u03b1B \u2264 \u03b3 with probability \u03b4. Then, \u03b1 is (\u03b3, \u03b4)-accurate.\nProof. By repeated applications of the triangle inequality. See Appendix C.3 for a detailed proof.\nSpecifying the confidence > 0. We select > 0 based on a Bernstein vector concentration bound (Appendix C.4), which only requires a prior upper bound on the magnitude of the value function V 1 (\u2022) and gradients D \u03b8 \u03c0(\u2022, \u03b8). Asymptotic feasibility. Eq (4) is not feasible if > \u03b3, which would indicate that we simply do not have enough samples to guarantee (\u03b3, \u03b4)-accuracy. In this case, we choose to side on conservatism and fully use the ZoBG by setting \u03b1 = 0. Asymptotically, as the number of samples N \u2192 \u221e, the confidence interval \u03b5 \u2192 0, which implies that Eq (4) will always be feasible.\nFinally, we note that Eq (4) has a closed form solution, whose proof is provided in Appendix C.2.\nLemma 4.4. With \u03b3 = \u221e, the optimal \u03b1 is \u03b1 \u221e :=\u03c3 2 0 \u03c3 2 1 +\u03c3 2 0 . For finite \u03b3 \u2265 , Eq (4) is \u03b1 \u03b3 := \u03b1 \u221e if \u03b1 \u221e B \u2264 \u03b3 \u2212 \u03b5 \u03b3\u2212\u03b5 B otherwise .(5)\nWe give some qualitative characteristics of the solution:\n\u2022 If we are within constraint and\u03c3 2 0 \u03c3 2 1 , as we can expect from benign smooth systems, then \u03b1 \u2248 1, and we rely more on the FoBG.\n\u2022 In pathological cases where we are unbiased yet\u03c3 2 1 \u03c3 2 0 (e.g. stiffness and chaos), then \u03b1 \u2248 0. \u2022 If there is a large difference between the ZoBG and the FoBG such that B 0, we expect strict/empirical bias from discontinuities and tend towards using ZoBG.", "publication_ref": ["b37", "b32"], "figure_ref": [], "table_ref": []}, {"heading": "Landscape Analysis & Case Studies", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Landscape analysis on examples", "text": "Though we have characterized the bias-variance characteristics of different gradients, their convergence properties in landscapes of physical systems remain to be investigated. We visualize the performance of fixed-step gradient descent with the FoBG, ZoBG, and AoBG on examples of Figure 1.\nBall with wall. On the system of Figure 1.B, the FoBG fails to make progress at the region of flatness, while the ZoBG and AoBG successfully find the minima of the landscape (Figure 7). In addition, the interpolation scheme switches to prioritizing ZoBG near discontinuities, while using more information from FoBG far from discontinuities; as a result, the variance of AoBG is lower than that of ZoBG.\nAngular momentum transfer. Next, we show results for the momentum transfer system of Figure 1.C in Figure 7. Running gradient descent results in both the ZoBG and AoBG converging to the robust local minima of the solution. However, the bias of FoBG forces it off the cliff and the optimizer is unable to recover. Again, our interpolation scheme smoothly switches to prioritizing the ZoBG near the discontinuity, enabling it to stay within the safe region while maximizing the transferred momentum.\nBias-variance leads to different minima. Through these examples with discontinuities, we claim that the biasvariance characteristics of gradients in these landscapes not only lead to different convergence rates, but convergence to different minima. The same argument holds for nearly discontinuous landscapes that display high empirical bias. Both estimators are unbiased in expectation, and the high variance of FoBG should manifest itself in worse convergence rates. Yet, the high empirical bias in the finite-sample regime leads to low empirical variance and different minima, leading to performance that is indistinguishable from when the underlying landscape is truly discontinuous.\nCombined with the benefits of stochasticity in Section 1, we believe that this might explain why zero-order methods in RL are solving problems for physical systems where deterministic (even stochastic) first order methods have struggled.", "publication_ref": [], "figure_ref": ["fig_5", "fig_5"], "table_ref": []}, {"heading": "Policy optimization case studies", "text": "To validate our results on policy optimization problems with differentiable simulators, we compare the performance of different gradients on time-stepping simulations written in torch (Paszke et al., 2019). For all of our examples, we validate the correctness of the analytic gradients by comparing the values of FoBG and ZoBG on a one-step cost.\nTo empirically verify the various hypotheses made in this paper, we compare the performance of three gradient estimators: the FoBG and ZoBG, which uniformly utilizes first and zeroth-order gradients, and the AoBG, which utilizes our robust interpolation protocol.\nPushing: Trajectory optimization. We describe performance of gradients on the pushing (Figure 5) environment, where contact is modeled using the penalty method (i.e. stiff spring) with additional viscous damping on the velocities of the system. We use horizon of H = 200 to find the opti-mal force sequence of the first block to minimize distance between the second block and the goal position. Our results in Figure 8 show that for soft springs (k = 10), the FoBG outperforms the ZoBG, but stiffer springs (k = 1000) results in the ZoBG outperforming the FoBG. This confirms our hypothesis that the stiffness of contact models has direct correlations with the variance of the estimators, which in turn affects the convergence rate of optimization algorithms that use such estimators.\nIn addition, we note that the interpolated gradient AoBG is able to automatically choose between the two gradients that performs better by utilizing empirical variance as a statistical measure of performance.\nFriction: Trajectory Optimization. We describe performance of gradients on the friction (Figure 4) environment.\nAlthough the FoBG initially converges faster in this environment, it is unaware of the discontinuity that occurs when it slides off the box. As a result, the performance quickly degrades after few iterations. On the other hand, the AoBG and ZoBG successfully optimize the trajectory, with AoBG showing slightly faster convergence.\nTennis: Policy optimization. Next, we describe the performance of different gradients on a tennis environment (similar to breakout), where the paddle needs to bounce the ball to some desired target location. We use a linear feedback policy with d = 21 parameters, and horizon of H = 200. In order to correctly obtain analytic gradients, we use continuous event detection with the time of impact formulation (Hu et al., 2020). The results of running policy optimization is presented in Figure 8.\nWhile the ZoBG and the AoBG are successful in finding a policy that bounces the balls through different initial condi-tions, the FoBG suffers from the discontinuities of geometry, and still misses many of the balls. Furthermore, the AoBG still converges slightly faster than the ZoBG by utilizing first-order information.", "publication_ref": ["b38", "b21"], "figure_ref": ["fig_3", "fig_6", "fig_2", "fig_6"], "table_ref": []}, {"heading": "Discussion", "text": "In this section, we elaborate and discuss on some of the ramifications of our work.\nImpact on Computation Time. The convergence rate of gradient descent in stochastic optimization scales directly with the variance of the estimator (Ghadimi & Lan, 2013). For smooth and well-behaved landscapes, FoBG often converges faster since Var[\u2207 [1] F ] < Var[\u2207 [0] F ]. However, when there are discontinuities or near-discontinuities in the landscape, this promise no longer holds since gradient descent using FoBG might not converge due to bias. Indeed, Example 3.6 tells us that bias due to discontinuities can be interpreted as infinite variance. Under this interpretation, the convergence rate of gradient descent is ill-defined.\nIn practice; however, the computation cost of obtaining the gradient must be taken into consideration as well. Given the same number of samples N , the computation of FoBG is more costly than the ZoBG, as FoBG requires automatic differentiation through the computation graph while ZoBG simply requires evaluation. Thus, the benefits of convergence rates using the FoBG must justify the additional cost of computing them.\nImplicit time-stepping. In our work, we have mainly addressed two classes of simulation methods for contact. The first uses the penalty method (Geilinger et al., 2020;Tedrake, 2022), which approximates contact via stiff springs, and the second uses event detection (Hu et al., 2020), which explicitly computes time-of-impact for automatic differentiation.\nIn addition to the ones covered, we note a third class of simulators that rely on optimization-based implicit timestepping (Todorov et al., 2012;Coumans & Bai, 2016-2021Macklin et al., 2014;Pang, 2021;Howell et al., 2022), which can be made differentiable by sensitivity analysis (Boyd & Vandenberghe, 2004). These simulators suffer less from stiffness by considering more long-term behavior across each timestep; however, geometrical discontinuities can still remain problematic. We leave detailed empirical study using these simulators to future work. Analytic Smoothing. Randomized smoothing relies on smoothing out the policy objective via the process of noise injection and sampling. However, one can also resort to analytic smoothing, which finds analytically smooth approximation of the underlying dynamics \u03c6 (Huang et al., 2021;Howell et al., 2022). Modifying and smoothing \u03c6 directly also has the effect of smoothing the induced value function, though the resulting landscape will be different from the landscaped induced by appending noise to the policy output.\nHowever, even when \u03c6 can be analytically smoothed, Monte-Carlo sampling is still required for optimization across initial conditions \u03c1. For such settings, the findings of Section 3.2 is still highly relevant, as the performance of FoBG still suffers from the stiffness of the smoothed approximation of \u03c6. However, as many smoothing methods provide access to parameters that control the strength of smoothing, algorithms may be able to take a curriculum-learning approach where dynamics become more realistic, and less smooth, as more iterations are taken for policy search.", "publication_ref": ["b18", "b17", "b48", "b21", "b49", "b36", "b28", "b36", "b20", "b4", "b22", "b20"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Do differentiable simulators give better policy gradients?", "text": "We have shown that the answer depends intricately on the underlying characteristics of the physical systems. While Lipschitz continuous systems with reasonably bounded gradients may enjoy fast convergence given by the low variance of first-order estimators, using the gradients of differentiable simulators may hurt for problems that involve nearly/strictly discontinuous landscapes, stiff dynamics, or chaotic systems. Moreover, due to the empirical bias phenomenon, bias of first-order estimators in nearly/strictly discontinuous landscapes cannot be diagnosed from empirical variance alone. We believe that many challenging tasks that both RL and differentiable simulators try to address necessarily involve dealing with physical systems with such characteristics, such as those that are rich with contact. These limitations of using differentiable simulators for planning and control need to be addressed from both the design of simulator and algorithms: from the simulator side, we have shown that certain modeling decisions such as stiffness of contact dynamics can have significant underlying consequences in the performance of policy optimization that uses gradients from these simulators. From the algorithm side, we have shown we can automate the procedure of deciding which one to use online via interpolation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Supplementary Materials for \"Do Differentiable Simulators Give Better Policy Gradients\"", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A. Formal Expected Gradient Computations", "text": "This section establishes rigorous unbiasedness guarantees for the ZoBG (under general conditions) and of the FoBG (under more restrictive conditions). Specifically, Corollary A.12 provides a rigorous version of the ZoBG guarantee, Lemma 3.1, which is a special case of Proposition A.11 which holds for general, possibly non-Gaussian noise distributions. The FoBG estimator is addressed in Proposition A.15, which provides the rigorous statement of Lemma 3.2. We present a lengthy preliminaries section, Appendix A.1, to formalize the results that follow. We then follow with formal statements of the results, Appendix A.2, and defer proofs to Appendix A.3. The preliminaries below are requisites only for the results and proofs within this section, and are not needed in future appendices.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.1. Preliminaries", "text": "Throughout, \u2022 denotes the Euclidean norm of vectors. We begin by specifying our sense of expectations and derivatives, and then turn to other, less-standard preliminaries. To rigorously describe expectations of non-continuous functions and of derivatives of non-smooth functions, we start with some preliminaries from measure theory.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Lebesgue measurability.", "text": "For a background on measure theory, we direct the reader to (Stein & Shakarchi, 2009). Here, we recall a few definitions. We define the set of Lebesgue measurable sets L (R D ) as the collection of subset Z \u2282 R D for which the Lebesgue measure is well-defined. We let B(R D ) \u2282 L (R D ) be the collection of Borel measurable sets on R D . We say a mapping \u03a6 :\nR D \u2192 R D is Lebesgue measurable if for all Z \u2208 B(R D ), \u03a6 \u22121 (Z ) \u2208 L (R D ).\nWe say it is Borel measurable if, more strongly, it holds that \u03a6 \u22121 (Z ) \u2208 B(R D ). The composition of Borel measurable functions are Borel measurable, but the same is not true more generally for Lebesgue measurable functions. Throughout, all functions are assumed Borel measurable unless otherwise specified, so their compositions are also Borel measurable.\nMore generally, given a Lebesgue measurable set Z \u2282 R D , we define L (Z) as the set {Z \u2229Z :Z \u2208 L (R R d )}, and say a function\n\u03a6 : Z \u2192 R D is Lebesgue mearuable on its domain if for all Z \u2208 B(R D ), \u03a6 \u22121 (Z ) \u2208 L (R D ).\nLebesgue complete distribution. We consider probability distributions D on R D which assign probability to all Lebesgue measurable sets Z \u2282 R D : i.e., Pr z\u223cD [z \u2208 Z] is well defined. Note that these distribution do not need to have density with respect to the Lebesgue measure: indeed, continuous, discrete, and mixture of continuous and discrete distributions all can be defined to assign probabilities to all Lebesgue-measurable sets.\nWe say Z \u2282 R D is D-null if Pr z\u223cD [z \u2208 Z] = 0. We assume without loss of generality that D is complete, so that given a D-null Lebesgue measurable set Z, Pr z\u223cD [z \u2208 Z ] is well defined and equal to zero for all Z \u2282 Z. We call distributions which are complete and assign probability to all Lebesgue sets Lebesgue complete. We shall assume without comment that all distributions are Lebesgue complete.\nAlmost-everywhere functions and expectation. Given a Lebesgue complete distribution D on R D , we define expectation of a Lebesgue measurable \u03a6 : R D \u2192 R D in the standard way. We say a function \u03a6 is defined D-almost-surely if there exists a Lebesgue-measurable set Z \u2282 R D such that \u03a6 is a Lebesgue measurable as mapping Z \u2192 R D , and Z c = R D \\ Z is D-null. Given such a function \u03a6, we define its expectation\nE z\u223cD [\u03a6(z)] := E z\u223cD [\u03a6(z)], where\u03a6(z) = \u03a6(z) z \u2208 Z 0 otherwise. (6\n)\nOne can verify that\u03a6(z) is Lebesgue measurable. Note that this definition is independent of the choice of Z: if Z is another set witnessing the almost-sure definition of \u03a6, then the induced map\u03a6 defined by applying Eq (6) with Z is also Lebesgue measurable,\u03a6 =\u03a6 D-almost surely, so that the integrals coincide. Example A.1 (Heaviside, revisited). With definition in Eq (6), we see that the derivative of the example in Example 3.3 is 0 almost surely under w \u223c p; that is, the event on which the derivative of the Heaviside is both undefined has probability zero when w \u223c p, and outside this event, its derivative is identically zero.\nStated simply, we ignore values of \u03a6 defined outside the probability-one set Z. This definition has numerous advantages. For one, it satisfies the law of large numbers. That is,\n\u2022\nIf E z\u223cD \u03a6 (z) < \u221e, then for z (1) , . . . , z (N ) i.i.d. \u223c D, 1 N N i=1 \u03a6(z (i) ) converges to E[\u03a6(z)] in probability.\n\u2022 If E z\u223cD \u03a6 (z) 2 < \u221e, this convergence holds almost surely.\nFor further discussion, we direct the readers to a standard reference on probability theory (e.g. (\u00c7 inlar, 2011)).\nMultivariable derivative. We provide conditions under which the multivariable function F (\u03b8) : R d \u2192 R is differentiable. Formally, we say that a function \u03a6 : R d1 \u2192 R d1 is differentiable at a point z \u2208 R d if there exists a linear map D\u03a6(z) \u2208 R d2\u00d7d1 such that\nlim h \u21920 \u03a6(h + z) \u2212 \u03a6(z) h \u2212 D\u03a6(z) \u2022 h = 0.\nThe limit is defined in the sense of lim h \u21920 (\u2022) = lim t\u21920 sup h \u2264t (\u2022). Existence of a multivariable derivative slightly stronger that \u03a6(\u2022) having directional derivatives, and in particular, stronger than the existence of a gradient (see (Rudin et al., 1964, Chapter 9) for reference).\nFinite moments and polynomial growth.\nTo ensure all expectations are defined, we consider distributions for which all moments are finite. Definition A.2. We say that a (Lebesgue complete) distribution \u03c1 over a random variable z has finite moments if E z\u223c\u03c1 z a < \u221e for all a > 0.\nThe class of function which have finite expectations under distributions with finite moments are functions which have polynomial growth, in the following sense. Definition A.3. We say that a function \u03c8 : R d1 \u2192 R d2 has polynomial growth if there exists constants a, b > 0 such that \u03c8(x) \u2264 a(1 + z b ) for all z \u2208 R d . We say that a matrix (or tensor) valued function has polynomial growth if the vector-valued function corresponding to flattening its entries into a vector has polynomial growth (for matrices, this means \u03c8(z)\nF \u2264 a(1 + z b )).\nThe following lemma is clear.\nLemma A.4. Suppose \u03c1 is a distribution over variables x which has finite moments, and suppose g(x) has polynomial growth. Then E[g(x)] is well defined.\nA second useful (and straightforward to check) fact is that polynomial growth is preserved under marginalization.\nLemma A.5. Suppose \u03c1 is a distribution over variables x which has finite moments, and suppose g(z, x) has polynomial growth in its argument (z, x). Then z \u2192 E[g(z, x)] is well defined and has polynomial growth in z.\nLipschitz functions. To establish the unbiasedness of the FoBG for non-smooth functions, we invoke the Lipschitz continuity assumption. We say a function \u03a6 : R D \u2192 R D is locally-Lipschitz if, for every z \u2208 R D , there is a neighborhood a neighborhood U of z such that there exists an L > 0 such that for all z , z \u2208 U, \u03a6(z ) \u2212 \u03a6(z ) \u2264 L z \u2212 z . Locally Lipschitz functions are continuous, and thus Borel measurable.", "publication_ref": ["b43"], "figure_ref": [], "table_ref": []}, {"heading": "Lemma A.6 (Rademacher's Theorem). Every locally Lipschitz function", "text": "\u03c8 : R D \u2192 R is differentiable on a set of Z \u2282 R D such that Z c = R D \\ Z has Lebesgue measure zero.\nThe above result is standard (see, e.g. Ern & Guermond (2013, Chapter 2)).\nTo ensure convergence of integrals, we consider functions where the Lipschitz constant grows polynomially in the radius of the domain.\nDefinition A.7 (Polynomially Lipschitz). We say that\n\u2022 A function \u03c8(z) : R d1 \u2192 R d2 is polynomially-Lipschitz if there are constants a, b > 0 such that for all radii R \u2265 1 and all z, z \u2208 R d1 such that z , z \u2264 R, \u03c8(z) \u2212 \u03c8(z ) \u2264 aR b .\n\u2022 We say a function \u03c8(z; x) : R d1 \u00d7 R n \u2192 R d2 is parametrized-polynomially-Lipschitz if for all radii R \u2265 1 and all z, z \u2208 R d1 and x \u2208 R n such that z , z , x \u2264 R, \u03c8(z; x) \u2212 \u03c8(z ; x) \u2264 aR b .\nOne can check that polynomially Lipschitz functions are locally Lipschitz.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2. Formal results", "text": "We now state our formal results. Throughout, our smoothing noise w has distribution p which has the following form.\nAssumption A.8. The distribution p admits a density p(w) = e \u03b1\u2212\u03c8(w) , where (a) \u03c8(w) \u2265 a w \u2212 b for some constants a > 0 and b \u2208 R.\n(b) \u03c8 is twice differentiable everywhere, and \u2207 2 \u03c8(w) has polynomial growth.\nExample A.9 (Gaussian distribution). The cannonical example is the Gaussian distribution w \u223c N (0, \u03c3 2 I n ), where p(w) = 1 \u221a 2\u03c0\u03c3 exp( \u2212 w 2 2\u03c3 2 ). Here, \u03c8(w) = w 2 2\u03c3 2 , which has polynomial growth and, being quadratic, is twice differentiable. In addition,\n\u2207\u03c8(w) = w \u03c3 2 , E[\u2207\u03c8(w)] = 0. (7\n)\nZeroth-order unbiasedness. We now stipulate highly general conditions under which the zeroth-order estimator is unbiased. In the interest of generality, we allow time-varying policies and costs.\nDefinition A.10. We say that a tuple (\u03c1, p, \u03c6, c 1:H ; \u03c0 1:H ) is a benign planning problem if (a) \u03c1 has finite moments (b) p satisfies Assumption A.8, (c) the dynamics \u03c6(\u2022, \u2022) and costs c h (\u2022, \u2022) have polynomial growth (for all h \u2208 H), and (d), for each x \u2208 R n and h \u2208 [H], u \u2192 \u03c0 h (x, u) is twice-differentiable in u and its second-order derivative has polynomial growth in x. In addition, we assume \u03c6, c 1:H , \u03c0 1:H are all Borel measurable.\nWe consider the resulting stochastic optimization objective.\nF (\u03b8) = E x1\u223c\u03c1,w1:H \u223cp H [V 1 (x h , w 1:H , \u03b8)] s.t. x h+1 = \u03c6(x h , u h ), u h = \u03c0(x h , \u03b8) + w h .\nNote that we define the expectation jointly over E x1\u223c\u03c1,w1:H \u223cp H , so as not to assume Fubini's theorem holds (even though, under our assumptions, it does). Our first result is a rigorous statement of the unbiasedness of the zeroth-order estimator. Proposition A.11. Suppose that (\u03c1, p, \u03c6, c 1:H ; \u03c0 1:H ) is a benign planning problem. Then, the objective F (\u03b8) defined in Eq (1) is differentiable, and\n\u2207 \u03b8 F (\u03b8) = E x1\u223c\u03c1,w1:H \u223cp H H h=1 (D \u03b8 \u03c0 h (x h , \u03b8)) \u03c8(w h )V h (x h , w h:H , \u03b8) .\nIf, in addition E w\u223cp [\u2207\u03c8(w)] = 0, we also have\n\u2207 \u03b8 F (\u03b8) = E x1\u223c\u03c1,w1:H \u223cp H V 1 (x h , w 1:H , \u03b8) H h=1 (D \u03b8 \u03c0 h (x h , \u03b8)) \u03c8(w h ) .\nEq (7) yields the following corollary for Gaussian distributions, which recovers Lemma 3.1 in the main text. Corollary A.12. In the special case where p = N (0, \u03c3 2 I), we have\n\u2207 \u03b8 F (\u03b8) = 1 \u03c3 2 E x1\u223c\u03c1,w1:H \u223cp H V 1 (x h , w 1:H , \u03b8) H h=1 (D \u03b8 \u03c0 h (x h , \u03b8)) w h .\nFirst-order unbiasedness under Lipschitzness. Next, we turn to the formal result under Lipschitzness. We consider objectives which have the following additional assumptions: Definition A.13. We say that a tuple (\u03c1, p, \u03c6, c 1:H ; \u03c0 1:H ) is a benign Lipschitz planning problem if it is a benign planning problem, and in addition, (a) c h and \u03c0 h are everywhere-differentiable and their derivatives have polynomial growth, and (b) \u03c6 is polynomially Lipschitz.\nIn addition, we require one more technical condition which ensures measurability of the set on which the analytic gradients are defined. Definition A.14. We say that the distribution \u03c1 is decomposable if there exists a Lebesgue-measurable function \u00b5 : R n \u2192 R \u22650 and a countable set of atoms a 1 , a 2 , . . . , with weights \u03bd 1 , \u03bd 2 , . . . such that, for any X \u2282 R n ,\nPr x1\u223c\u03c1 [x 1 \u2208 X ] = X \u00b5(x 1 )dx 1 + i\u22651 a i \u03bd i .\nMore general conditions can be established, but we adopt the above for simplicity. We assume that the distribution over initial state x 1 \u223c \u03c1 satisfies decomposability, which in particular encompasses the deterministic distribution over initial states considered in the body of the paper. The following lemma formalizes Lemma 3.2.\nProposition A.15. Suppose that (\u03c1, p, \u03c6, c 1:H ; \u03c0 1:H ) is a benign Lipschitz planning problem. If \u03c1 is decomposable, then (a) For each \u03b8, there exists a set Lebesgue-measurable set Z \u2282 R n+mH such that Pr x1\u223c\u03c1,w1:H \u223cp H [(x 1 , w 1:H ) \u2208 Z] = 1 and \u03b8 \u2192\nV 1 (x 1 , w 1:H , \u03b8) is differentiable for all (x 1 , w 1:H ) \u2208 Z. (b) \u2207 \u03b8 F (\u03b8) = E x1\u223c\u03c1,w1:H \u223cp H [\u2207V 1 (x 1 , w 1:H , \u03b8)]\n, where expectations are taken in the sense of Eq (6).\nIf \u03c1 is not necessarilly decomposable, but for given \u03b8 \u2208 R D , the set {(x 1 , w 1:H ) : V 1 (x 1 , w 1:H , \u03b8) is differentiable} is Lebesgue measureable, then points (a) and (b) still hold. Example A.16 (Piecewise linear). As an example, piecewise linear, or piecewise-polynomial dynamics statisfy the conditions of the above proposition.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A.2.1. Separable functions", "text": "A key step in establishing the unbiasedness of the zeroth-order estimator for policy optimization is the special case of separable functions. We begin by stating guarantees for simple functions which the noise enters in the following separable fashion. Definition A.17 (Benign separability). We say that a function f (\u03b8, w) has benign separability if there exists an everywhere differentiable function g in (\u03b8) and a Lebesgue measurable function g out (\u2022) with polynomial growth such that f (\u03b8, w) = g out (g in (\u03b8) + w).\nA slightly more general version of the above definition is as follows.\nDefinition A.18. We say that a x-parameterized function function f (\u03b8, w; x) has parametrized benign separability if there exists Lebesgue-measure functions g out (\u2022; \u2022) and g in (\u2022; \u2022) such that g in (\u2022; \u2022) is differentiable for all x, and f (\u03b8, w; x) = g out (g in (\u03b8; x) + w; x), where (a) (z, x) \u2192 g out (z; x) has polynomial growth, (b) for each \u03b8, the mapping x \u2192 D \u03b8 g in (\u03b8; x) has polynomial growth, (z, x) \u2192 g out (z; x) has polynomial growth, and (c) for some 0 > 0, there is a functio\u00f1 g(x) with polynomial growth such that such that for all \u2206 : \u2206 \u2264 ,\ng in (\u03b8; x) \u2212 g in (\u03b8 + \u2206; x) \u2212 Dg in (\u03b8; x) \u2022 \u2206 \u2264 \u2206 2g (x).(8)\nWe note that Eq (8) is satisfied when g in (\u03b8; x) has a second derivative by having polynomial growth.\nThe following gives an expression for the derivative of separable functions. Note that we do not require g out (\u2022) to be differentiable, and depend only on the derivatives of \u03c8(w) = log p(w)+ const. from the density p, as well as the derivative of g in (\u03b8). The following statement establishes the well-known (Williams, 1992) computation at our level of generality.\nProposition A.19. Suppose that p satisfies Assumption A.8. Then, if f (\u03b8, w) is benign separable, then the expectation F (\u03b8) = E w\u223cp [f (\u03b8, w)] is well defined, differentiable, and has\n\u2207F (\u03b8) = E w\u223cp [Dg in (\u03b8) \u2207\u03c8(w) \u2022 f (\u03b8, w)].\nMore generally, if \u03c1 has finite moments and f (\u03b8, w; x) has benign parametrized separability, then (c) For any B > 0, there exists a function with polynomial growth such thatg(\u2022), for all \u2206 : \u2206 \u2264 B,\nF (\u03b8) = E x\u223c\u03c1,\n|p(w) \u2212 p(w + \u2206) \u2212 p(w) \u2212\u2207\u03c8(w), \u2206 | \u2264 \u2206 2 p(w) \u2022g(w). (d) Let g(\u2022, \u2022) : R m \u00d7 R n \u2192 R have polynomial growth. Then x \u2192 E w \u2207\u03c8(w) \u2022 g(w,\nx) is well defined and polynomial growth in x.\nProof. Since p(w) decays exponentially in w, p has finite moments. Thus, part (a) follows from Lemma A.4. Part (b) follows from the fundamental theorem of calculus:\n\u2207\u03c8(w) = 1 0 \u2207 2 \u03c8(tw) \u2022 wdt \u2264 \u2207\u03c8(0) + w max t\u2208[0,1] \u2207 2 \u03c8(tw) op ,\nthe upper bound on which has polynomial growth since \u2207 2 \u03c8(tw) op does.\nTo prove part (c), we have that since p(w) = e \u03b1\u2212\u03c8(w) for \u03c8 differentiable where the integral on the right hand side exists because \u03c8(w) and f (\u03b8, w) have polynomial growth. Simplying and dividing by \u03b8 \u2212 \u03b8 and substituting again\u2206 = g in (\u03b8) \u2212 g in (\u03b8 ),\nF (\u03b8) \u2212 F (\u03b8 ) \u2212 g in (\u03b8 ) \u2212 g in (\u03b8), E w [\u2207\u03c8(w) \u2022 f (\u03b8, w)] \u03b8 \u2212 \u03b8 \u2264 C w g in (\u03b8 ) \u2212 g in (\u03b8) 2 \u03b8 \u2212 \u03b8 .(9)\nThe result now follows from taking \u03b8 \u2212 \u03b8 \u2192 0 and using differentiability of g out (\u2022) concludes.\nParametrized case. Now consider the parametrized case, and define F (\u03b8; x) = E w\u223cp f (\u03b8, w; x). Then the analogue of Eq (10) holds pointwise for each x:\nF (\u03b8; x) \u2212 F (\u03b8 ; x) \u2212 g in (\u03b8 ; x) \u2212 g in (\u03b8; x), E w [\u2207\u03c8(w; x) \u2022 f (\u03b8, w; x)] \u03b8 \u2212 \u03b8 \u2264 C w g in (\u03b8 ; x) \u2212 g in (\u03b8; x) 2 \u03b8 \u2212 \u03b8 . (10\n)\nUsing Eq (8), the triangle inequality and Cauchy Schwartz, we obtain, for some integrable functiong with polynomial growth,\nF (\u03b8; x) \u2212 F (\u03b8 ; x) \u2212 Dg in (\u03b8; x)(\u03b8 \u2212 \u03b8), E w [\u2207\u03c8(w; x) \u2022 f (\u03b8, w; x)] \u03b8 \u2212 \u03b8 \u2264g(x) \u2022 \u03b8 \u2212 \u03b8 \u2022 E w \u2207\u03c8(w) \u2022 f (\u03b8, w; x) + C w g out (\u03b8 ; x) \u2212 g out (\u03b8; x) 2 \u03b8 \u2212 \u03b8 . \u2207 \u03b8 F (\u03b8) = \u2207 \u03b8 (E x\u223c\u03c1 [F (\u03b8; x)]) = E x\u223c\u03c1 [Dg in (\u03b8; x) E w\u223cp [\u2207 w \u03c8(w) \u2022 f (\u03b8, w; x)]] = E x\u223c\u03c1,w\u223cp [\u2207 \u03b8 Dg in (\u03b8; x) \u2207 w \u03c8(w) \u2022 f (\u03b8, w; x)]\nwhere in the last step, measurability and polynomial-growth conditions allow the application of Fubini's theorem.", "publication_ref": ["b54"], "figure_ref": [], "table_ref": []}, {"heading": "A.3.2. Proof of Proposition A.11", "text": "We prove a slightly different proof from that of the standard REINFORCE lemma to accommodate the fact that the state space is continuous, but the distribution over states may not have a density with respect to the Lebesgue measure. Instead, we adopt an approach based on the performance difference lemma (Kakade, 2003, Lemma 5.2.1).\nTo begin, define the expected cost to go function and expected costs\nV h (x h , \u03b8) = E wh:H i.i.d. \u223c p V (x h , w h:H , \u03b8) (a) V + h,\u03b8 (\u03b8 , w h ; x h ) =V h+1 (\u03c6(x h , \u03c0 h (x h , \u03b8 ) + w t ), \u03b8) (b.1) V + h,\u03b8 (\u03b8 ; x h ) = E wh\u223cp V + h (\u03b8 , w h ; x h , \u03b8). (b.2) c h (\u03b8, w h ; x h ) = c h (x h , \u03c0 h (x h , \u03b8) + w t ), (c.1) c h (\u03b8; x h ) = E wh\u223cp c h (\u03b8, w h ; x h ) (c.2)\nwhich describe (a) the expected cost-to-go under x h , \u03b8, and (b) the expected cost-to-go from the next stage h after starting in state x h , acting according to \u03b8 in stage h, and subsequently acting according to \u03b8, and (c) expected cost in state x h under policy \u03b8 and. By the well known performance-difference lemma, we have\nF (\u03b8) \u2212 F (\u03b8 ) (11) = E x1\u223c\u03c1 V 1 (x 1 , \u03b8) \u2212V 1 (x 1 , \u03b8 ) = H h=1 E \u03b8;h [ c h (\u03b8; x h ) \u2212c h (\u03b8 ; x h ) + V + h,\u03b8 (\u03b8; x h ) \u2212V + h,\u03b8 (\u03b8 ; x h ) ] = H h=1 E \u03b8;h E wh\u223cp [c h (\u03b8, w h ; x h ) \u2212 c h (\u03b8 , w h hx h )] + E xh\u223c\u03b8;h E wh\u223cp [V + h,\u03b8 (\u03b8, w h ; x h ) \u2212 V + h,\u03b8 (\u03b8 , w h ; x h )] = H h=1 (F h,\u03b8;c (\u03b8) \u2212 F h,\u03b8;c (\u03b8 )) + (F h,\u03b8;V (\u03b8) \u2212 F h,\u03b8;c (\u03b8 ))(12)\nwhere E \u03b8,h denotes expectations over x h under the dynamics\nx 1 \u223c \u03c1, x t+1 = \u03c6(x t , u t ), u t = \u03c0(x t , \u03b8) + w t ,\nand where we define\nF h,\u03b8;c (\u03b8 ) := E xh\u223c\u03b8;h E wh\u223cp c h (\u03b8 , w h ; x h )], F h,\u03b8;V (\u03b8 ) := E xh\u223c\u03b8;h E wh\u223cp V + h,\u03b8 (\u03b8 , w h | x h )].\nHence, if the functions F h,\u03b8;c (\u03b8 ) and F h,\u03b8;c (\u03b8 ) are differentiable at \u03b8 = \u03b8 for h = 1, 2, . . . , H, Eq (12) implies\n\u2207 \u03b8 F (\u03b8) = H h=1 \u2207 \u03b8 F h,\u03b8;c (\u03b8 ) + \u2207 \u03b8 F h,\u03b8;V (\u03b8 ) \u03b8 =\u03b8 .(13)\nWe establish differentiability and compute the derivatives by appealing to Proposition A.19. First, we establish a couple of useful claims.\nClaim A.21. The marginal distribution over x h under E h;\u03b8 has all moments.\nProof. Observe that the polynomial growth conditions on the dynamics map \u03c6(\u2022, \u2022) imply that as a function, x h = x h (x 1 , w 1:h\u22121 ), x h has polynomial growth in x h (x 1 , w 1:h\u22121 ). Thus, since the distributions over x 1 and w 1:h\u22121 have all moments, so does the distribution over x h .\nClaim A.22. The function \u03b8 \u2192 c h (\u03b8, w h ; x h ) = c h (x h , \u03c0(x h ; \u03b8) + w t ) satisfies benign parametrized separability.\nProof. Take g out (\u2022; x h ) = c h (x h , \u2022) and g in = \u03c0(x h , \u03b8). Since c h (\u2022, \u2022) has polynomial growth, the requisite growth condition on g out (\u2022, \u2022) holds. The polynomial growth in x of the second-order differentials of \u03b8 \u2192 \u03c0 h (x, \u03b8) implies that the first order differential of \u03b8 \u2192 \u03c0 h (x, \u03b8) has polynomial growth in x, and that g in also satisfies Eq (8) by Taylor's theorem. Hence, g out , g in satisfy the requisite conditions.\nClaim A.23. The function \u03b8 \u2192 V + h,\u03b80 (\u03b8, w h ; x h ) =V h+1 (\u03c6(x h , \u03c0 h (x h , \u03b8 ) + w t ), \u03b8 0 ) satisfies benign parametrized separability.\nProof. Take g out (u; x h ) =V h+1 (\u03c6(x h , u), \u03b8 0 ) and g in = \u03c0 h (x h , \u03b8). As shown in Claim A.22, g in satisifes the requisite conditions for benign parametrized separability. To conclude, it suffices to show that (u, x h ) \u2192 V h+1 (\u03c6(x h , u), \u03b8 0 ) has polynomial growth. By Lemma A.5, it suffices to show that (u, x h , w h+1:H ) \u2192 V h+1 (\u03c6(x h , u), w h+1:H \u03b8 0 ) has polynomial growth. This holds since we have\nV h+1 (\u03c6(x h , u), w h+1:H , \u03b8 0 ) = H i=h+1 c i (x i , \u03c0 h (x i , \u03b8 0 ) + w i , s.t. x i+1 = \u03c6(x i , \u03c0 h (x i , \u03b8 0 )) + w i .\nJust as in the proof of Claim A.21, x i , i > 1 have polynomial growth when viewed as functions of w h+1:H , x h and u (since the dynamics \u03c6) have polynomial growth. Since c i also have polynomial growth, we conclude V h+1 (\u03c6(x h , u), w h+1:H , \u03b8 0 ) must as well.\nThe above three claims allow us to invoke Proposition A.19, so that\n\u2207 \u03b8 F h,\u03b8;c (\u03b8 ) = E xh\u223c\u03b8;h E wh\u223cp D \u03b8 \u03c0 h (x h , \u03b8 ) \u2207\u03c8(w h )c h (\u03b8 , w h ; x h )] \u2207 \u03b8 F h,\u03b8;V (\u03b8 ) = E xh\u223c\u03b8;h E wh\u223cp D \u03b8 \u03c0 h (x h , \u03b8 ) \u2207\u03c8(w h ) \u2022 V + h,\u03b8 (\u03b8 , w h | x h ) .\nTherefore, from Eq (13), we conclude\n\u2207 \u03b8 F (\u03b8) = H h=1 E xh\u223c\u03b8;h E wh\u223cp D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) c h (\u03b8 , w h ; x h ) + V + h,\u03b8 (\u03b8, w h | x h ) ] .\nThus, the various polynomial growth conditions imply we can use Fubini's theorem (and the definition of V + h,\u03b8 ) , so that the above is equal to\n\u2207 \u03b8 F (\u03b8) = H h=1 E x1\u223c\u03c1 E w1:H \u223cp H [D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) (c h (x h , u h ) + V h+1 (x h , w h+1:H , \u03b8))]] = H h=1 E x1\u223c\u03c1 E w1:H \u223cp H [D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) \u2022 V h (x h , w h:H , \u03b8)]] = E x1\u223c\u03c1 E w1:H \u223cp H H h=1 D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) \u2022 V h (x h , w h:H , \u03b8) .\nThis completes the first part of the proof. Next, we simplify in the special case where E w\u223cp [\u2207\u03c8(w)] = 0. Observe that the last line of the above display is equal to\nE x1\u223c\u03c1 E w1:H \u223cp H H h=1 D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) \u2022 V 1 (x 1 , w 1:H , \u03b8) \u2212 E x1\u223c\u03c1 E w1:H \u223cp H H h=1 D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) \u2022 h\u22121 i=1 c i (x i , u i ) (b)\n, where in the last line, we use that\nV 1 (x 1 , w 1:H , \u03b8) = h\u22121 i=1 c i (x i , u i ) = V h (x h , w 1:H , \u03b8).\nIt suffices to show term (b) is zero. This follows since, for each i < h, we have\nE x1\u223c\u03c1 E w1:H \u223cp H [D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h )c i (x i , u i )] = E x1\u223c\u03c1 E w1:h\u22121\u223cp h\u22121 [D \u03b8 \u03c0 h (x h , \u03b8) c i (x i , u i )] \u2022 E wh\u223cp [\u2207\u03c8(w h )] = 0.\nHere, we used that w h is independent of x 1 , w 1:h\u22121 , and the assumption that E wh\u223cp [\u2207\u03c8(w h )] = 0.\nFirst, we establish almost-everywhere differentiability. Let\u03c6 h denote the transitions under noise w and policy \u03b8, defined as\u03c6 h (x, w, \u03b8) = \u03c6(x, \u03c0 h (x, \u03b8) + w).\nSet \u03a6 h to be their composition\n\u03a6 h (x 1 , w 1:h\u22121 , \u03b8) =\u03c6 h\u22121 (\u2022, w h , \u03b8) \u2022\u03c6 h\u22122 (\u2022, w h\u22121 , \u03b8) \u2022 \u2022 \u2022 \u2022 \u2022\u03c6 1 (x 1 , w 1 , \u03b8).\nNotice that x h = \u03a6 h (x 1 , w 1:h\u22121 , \u03b8), where x h is generated according to the dynamics x i+1 = \u03c6(x i , \u03c0 i (x i , \u03b8) + w i ). We now establish two key claims.\nClaim A.24. Fix (x 1 , w 1:H , \u03b8). If \u03b8 \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8 ) for all is differentiable at \u03b8 = \u03b8 for all h \u2208 [H], then \u03b8 \u2192 V 1 (x 1 , w 1:H , \u03b8 ) is differentiable at \u03b8 = \u03b8. Proof. Definingc h (x, \u03b8; w) = c h (x, \u03c0 h (x, \u03b8) + w), we have V 1 (x 1 , w 1:H , \u03b8) = H h=1c h (\u03a6 h (x 1 , w 1:h\u22121 , \u03b8), \u03b8; w h ).\nSince both c h (\u2022, \u2022) and \u03c0 h (\u2022, \u2022) are everywhere differentiable (jointly in their arguments), (x, \u03b8) \u2192 c h (x, \u03b8; w) is everywhere differentiable. Thus, under the assumptions of the claim, the composition \u03b8 \u2192\nc h (\u03a6 h (x 1 , w 1:h\u22121 , \u03b8 ), \u03b8 ; w h ) is differentiable at \u03b8 = \u03b8.\nThe next claim provides a sufficient condition for Claim A.24 to hold. Claim A.25. Fix (x 1 , w 1:H , \u03b8). Then if\nw 1:h\u22121 \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8) is differentiable at w 1:h\u22121 = w 1:h\u22121 for all h \u2208 [H], then \u03b8 \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8 ) is differentiable at \u03b8 = \u03b8 for all h \u2208 [H].\nProof. Fix x 1 , w 1:h\u22121 . Let \u03b4 \u2208 R d denote perturbations of \u03b8. It suffices to show that, for each h = 1, 2, . . . , H, the mapping \u03a8 h (\u03b4) := \u03a6 h (x 1 , w 1:h\u22121 , \u03b8 + \u03b4) is differenitable if \u03b4. By induction, it is straightforward to verify the identity\n\u03a8 h (\u03b4) := \u03a6 h (x 1 , w 1:h\u22121 , \u03b8 + \u03b4) = \u03a6 h (x 1 , w 1:h\u22121 +w 1:h (\u03b4)), \u03b8)(14)\nwhere we have defined the noise termw 1:h\u22121 (\u03b4) so as to transition from policy \u03b8 to policy \u03b8 + \u03b4:\nw i (\u03b4) = \u03c0 i (\u03a8 i (\u03b4), \u03b8 + \u03b4) \u2212 \u03c0 i (\u03a8 i (\u03b4), \u03b8). (15\n)\nWe now argue by induction on little h that if w\n1:i\u22121 \u2192 \u03a6 h (x 1 , w 1:i\u22121 , \u03b8) for all i \u2264 H, then \u03a8 i (\u03b4) is differen- tiable at \u03b4 = 0 for all i \u2264 h.\nFor h = 1, both maps are the constant map \u03a6 1 (\u2022, \u2022, x 1 ) = x 1 , so the result holds trivially. Now suppose the inductive hypothesis holds at some h \u2265 1. Then, since each \u03c0 i (\u2022, \u2022) is everywhere differentiable in its arguments, and since \u03a8 i (\u03b4) is differentiable at \u03b4 = 0 for all i \u2264 h by inductive hypothesis,w i (\u03b4) defined in Eq ( 15) is differentiable at \u03b4 = 0 for each i \u2264 h. Hence,w 1:h (\u03b4) is differentiable at \u03b4 = 0. Now, by assumption w 1:h \u2192 \u03a6 h+1 (x 1 , w 1:h , \u03b8) is differentiable at w 1:h = w 1:h . Therefore, at \u03b4 = 0, \u03a8 h (\u03b4) is given by the composition of two maps which are differentiable, and hence is differentiable.\nDefine the set W h (x 1 ) as the set of w 1:H \u2208 R mH such that the map w 1:H \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8) is differentiable (for simplicity, we augmented the map to be a function of all noises w 1:H ). Synthesizing Claims A.24 and A.25, we see that if w 1:H \u2208W(x\n1 ) := H h=1 W h (x 1 ), then \u03b8 \u2192 V 1 (x 1 , w 1:H , \u03b8 ) is differentiable at \u03b8 = \u03b8.\nNotice that, for any given x 1 , the above proof under decomposability shows that Z 0 (x 1 ) \u2287W(x 1 ), and thus the complement of Z 0 (x 1 ) in R mH has Lebesgue measure zero. Hence Pr w1:H \u223cp H [w 1:H \u2208 Z 0 (x 1 )] = 1, so that Pr Since the target lower bound increases as \u03b2 decreases, we may assume that Pr[E] = 1 \u2212 \u03b2 with equality (since choosing a small \u03b2 so that equality holds gives a larger variance lower bound). We begin Therefore,\n\u2206 \u2264 E[z | E] \u2212 E[z] = (1 \u2212 \u03b2) \u22121 E[zI{E}] \u2212 E[z] \u2264 (1 \u2212 \u03b2) \u22121 E[zI{E}] + (1 \u2212 \u03b2) \u22121 E[z] \u2212 E[z] \u2022 |1 \u2212 (1 \u2212 \u03b2) \u22121 | \u2264 (1 \u2212 \u03b2) \u22121 E[zI{E c }] \u2212 E[z] \u2022 |1 \u2212 (1 \u2212 \u03b2) \u22121 |.\nE[ z 2 ] \u2265 E[ z 2 I{E c }] = Pr[E c ] \u2022 E[ z 2 | E c ] \u2265 Pr[E c ] \u2022 E[z | E c ] 2 \u2265 \u03b2 \u2022 \u2206 2 0 \u03b2 2 = \u2206 2 0 \u03b2 .\nProof. Let X =\u2207 [1] F (\u03b8) and Y =\u2207 [1] F (\u03b8). Since the ZoBG and FoBG are assumed to use independent trajectories, X and Y are independent, and thus\nVar[\u03b1X + (1 \u2212 \u03b1)Y ] = E[ \u03b1(X \u2212 E[X]) + (1 \u2212 \u03b1)(Y \u2212 E[Y ]) 2 ] = \u03b1 2 E X \u2212 E[X] 2 + (1 \u2212 \u03b1) 2 E Y \u2212 E[Y ] 2 + \u03b1 E[ X \u2212 E[X], Y \u2212 E[Y ] ] =0 = \u03b1 2 Var[X] + (1 \u2212 \u03b1) 2 Var[Y ],\nwhich establishes the first equality. The second equality follows from decompsing each of X =\u2207 [1] F (\u03b8) and Y =\u2207 [1] F (\u03b8) as the empirical mean of N i.i.d random variables.\nThe following lemma justifies using \u03b1 2\u03c32 1 + (1 \u2212 \u03b1) 2\u03c32 2 as a proxy for the variance: Lemma C.3 (Empirical variance). For k = 0, 1, we have [k] ].\n1 N E[\u03c3 2 k ] = Var[\u2207\nThus, [\u03b1] ].\nE[ \u03b1 2\u03c32 1 + (1 \u2212 \u03b1) 2\u03c32 2 ] = N \u2022 Var[\u2207\nProof. The first part of the lemma follows from a standard unbiasedness computation for a sample variance (see, e.g. Wasserman (2004, Theorem 3.17) for the scalar case). The second part of the lemma follows from Lemma C.2.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.2. Closed-form for interpolation", "text": "Recall Lemma 4.4: With \u03b3 = \u221e, the optimal \u03b1 is \u03b1 \u221e := \u03c3 2 0 \u03c3 2 1 +\u03c3 2 0 . For finite \u03b3 \u2265 , Eq (4) is\n\u03b1 \u03b3 := \u03b1 \u221e if \u03b1 \u221e B \u2264 \u03b3 \u2212 \u03b5 \u03b3\u2212\u03b5 B\notherwise .\nProof. Intuitively, the objective is convex with a linear constraint, so meets its optimality either at the unconstrained minimum or at the constraint surface. This is implied by complementary slackness of the KKT conditions, since an optimal \u03b1 * satisfies:\n2\u03b1 * \u03c32 1 + 2(1 \u2212 \u03b1 * )\u03c3 2 0 + \u03bbB = 0 \u03bb( \u2212 \u03b3 + \u03b1 * B) = 0,\nwhere the first line is stationarity of the Lagrangian and the second line is complementary slackness. Clearly, either \u03bb = 0 and the minimum is met at the inverse-weighted solution of the variances, or the constraint is zero and we have \u03b1 * = (\u03b3 \u2212 )/B. We give a more detailed proof of Lemma 4.3 here.\n\u2207 [\u03b1] F (\u03b8) \u2212 \u2207F (\u03b8) = \u03b1\u2207 [1] F (\u03b8) + (1 \u2212 \u03b1)\u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) = \u03b1\u2207 [1] \nF (\u03b8) + (1 \u2212 \u03b1)\u2207 [0] F (\u03b8) \u2212 \u03b1\u2207F (\u03b8) \u2212 (1 \u2212 \u03b1)\u2207F (\u03b8) \u2264 (1 \u2212 \u03b1) \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) + \u03b1 \u2207 [1] F (\u03b8) \u2212 \u2207F (\u03b8) \u2264 (1 \u2212 \u03b1) \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) + \u03b1 \u2207 [1] F (\u03b8) \u2212\u2207 [0] F (\u03b8) + \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) \u2264 \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) + \u03b1 \u2207 [1] F (\u03b8) \u2212\u2207 [0] F (\u03b8) \u2264 + \u03b1 \u2207 [1] F (\u03b8) \u2212\u2207 [0] F (\u03b8) \u2264 \u03b3.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.4. Empirical Bernstein confidence", "text": "Here describe our confidence estimate based on the ZoBG. Recall that that ZoBG is\n\u2207 [0] F (\u03b8) = 1 N N i=1\u2207 [0] F i (\u03b8), where\u2207 [0] F i (\u03b8) N i=1 V 1 (x i 1 , w i 1:H , \u03b8) \u2022 H i=1 D \u03b8 \u03c0(x h , \u03b8) w h .\nOur estimate is based on the matrix Bernstein inequality due (see, e.g. (Tropp, 2015)) specified below. Lemma C.4 (Matrix Bernstein inequality). Let X 1 , . . . , X N be N i.i.d random d-dimensional random vectors with X 1 \u2212 E[X 1 ] \u2264 R almost surely, and\nE[ X 1 2 ] \u2264 \u03c3 2 . Then, Pr 1 N N i=1 X i \u2212 E[X] \u2265 t \u2264 (d + 1) exp \u2212N t 2 /2 \u03c3 2 + Rt/3\nHence, with probability, for any \u03b4 > 0,\nPr \uf8ee \uf8f0 1 N N i=1 X i \u2212 E[X] \u2265 2\u03c3 2 log d+1 \u03b4 N + 2R 3N log d + 1 \u03b4 \uf8f9 \uf8fb \u2264 1 \u2212 \u03b4.\nAs stated, Lemma C.4 does not apply to our setting because (a) the variance of each X i :=\u2207 [0] F i (\u03b8) is unknown, and (b) X i are not uniformly bounded (due to the Gaussian noise w i h being unbounded.) We address point (a) by replacing Var[X i ] with the following empirical upper bound\n\u03c3 2 0 := i \u2207 [0] F i (\u03b8) 2 \u2265\u03c3 2 0 .\nTo address point (b), we take R to be some educated guess on the problem using the gradient samples from the system (e.g. R = max i \u2207 [0] F i (\u03b8) \u2212\u2207 [0] F (\u03b8) ). In practice, since the confidence bound directly scales with R, and the user needs to set some threshold term \u03b3 on + \u03b1B, a guess on the scale of R is already decided by the user threshold \u03b3. Thus, rather than viewing R as a rigorous absolute bound on the max deviation that we have to compute, we interpret it as a hyperparameter balancing how much we should be cautious against an extreme deviation outside the events covered by the variance term. We find that this approach, while not entirely rigorous, performs well in simulation. The following remark sketches how a rigorous confidence interval could be derived.\nRemark C.5. For a statistically rigorous confidence interval, one would have to (a) control the error introduced by using an empirical estimate of the variance, and (b) control the non-boundedness of the X i vectors. The first point could be addressed by generalizing the empirical Bernstein inequality (Maurer & Pontil, 2009) (which slightly inflates the confidence intervals to accomodate fluctuations in empirical variance) to vector-valued random variables. Point (b) can be handled by a truncation argument, leveraging the light-tails of Gaussian vectors. Nevertheless, we find that our naive approach which substitutes in the empirical variance for the true variance and our choice of R has good performance in simulation, so we do not pursue more complicated machinery. In fact, we conjecture that a more rigorous concentration bound may be overly conservative and worse in experiments.", "publication_ref": ["b50", "b31"], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "This work was funded by Amazon PO 2D-06310236, Lincoln Laboratory/Air Force Contract No. FA8702-15-D-0001, Defense Science & Technology Agency No.DST00OECI20300823, NSF Award EFMA-1830901, and the Ocado Group. We would also like to thank the anonymous ICML reviewers for their valuable feedback on the manuscript.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Furthermore, define Z h as the set of (x 1 , w 1:H ) \u2208 R d+mH such that (x 1 , w 1:H ) \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8) is differentiable. Here, we've just added x 1 as a nuissance variable, so Claims A.24 and A.25 also imply that, on Z := H h=1 Z h , \u03b8 \u2192 V 1 (x 1 , w 1:H , \u03b8 ) is differentiable at \u03b8 = \u03b8. We invoke Rademacher's theorem. Since w 1:H \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8) is given by the composition of locally Lipschitz maps (note that differentiable maps are locally Lipschitz), Lemma A.6 implies that R mH \\ W h (x 1 ) has Lebesgue measure zero for each h, so that R mH \\W(x 1 ) has Lebesgue measure zero by a union bound for each fixed x 1 . Similarly, R d+mH \\Z has measure zero.\nProof under decomposability. Assume \u03c1 is decomposable with atoms a 1 , a 2 , . . . . Define the set\nThe set Z is Lebesgue measurable because it is the intersection of Lebesgue measurable sets. Moroever, by the above discussion, \u03b8 \u2192 V 1 (x 1 , w 1:H , \u03b8) is differentiable everywhere on Z. Lastly, one can verify by decomposability and the fact thatZ and W are the complement of Lebesgue measure-zero sets that Pr x1\u223c\u03c1,w1:H \u223c\u03c1 H [(x 1 , w 1:H ) \u2208 Z] = 1. This proves part (a).\nTo prove part (b), one can use the polynomial Lipschitz conditions to verify that \u2207 \u03b8 V 1 (x 1 , w 1:H , \u03b8), has polynomial growth wherever defined. Hence, its expectation (in the sense of Eq (6)) is well-defined. To prove part (b), one can verify that, via polynomial-Lipschitzness of the dynamics, policies and costs that the quotients satisfy\nHence, the quotients are uniformly integrable, and one can apply the dominate convergence theorem to show that, for any sequence \u03b4 n \u2192 0\nLet's consider that\u2207 [0] estimator with a single sample, and drop the superscript i. We accommodate the general case with x 1 \u223c \u03c1. Since Var[z] \u2264 E[ z 2 ] for any random vector z, we have\nSince inner products are symmetric, we may assume without loss of genearlity that h 1 < h 2 . Then, x h2 , x h1 and w h1 are all functions of x 1 and w 1:h2\u22121 ,whereas w 2 is independent of these. Hence, since E[w 2 ] = 0, the cross term vanishes. Thus, we are left with\nas needed.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C. Interpolation", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C.1. Bias and variance of the interpolated estimator", "text": "Here we describe the bias and variance of the interpolated estimator. The first is a straightforward consequence of linearity of expectation and the expectation computations in Eq (4). Lemma C.1 (Interpolated bias). Assuming the costs and dynamics satisfies the conditions of Lemma 3.1 (formally, Corollary A.12), then for all \u03b1 \u2208 [0, 1],\nIf in addition, the costs and dynamics satisfy the conditions of Lemma 3.2 (formally, Proposition A.15), then E[\u2207 [\u03b1] F (\u03b8)] = \u2207F (\u03b8). Lemma C.2 (Interpolated variance). Assume that\u2207 [1] F (\u03b8) and\u2207 [0] F (\u03b8) are constructed using two independent sets of N trajectories. Then We have that Var[\u2207 [\u03b1] F (\u03b8)] = \u03b1 2 Var[\u2207 [1] ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "On the theory of policy gradient methods: Optimality, approximation, and distribution shift", "journal": "", "year": "2020", "authors": "A Agarwal; S M Kakade; J D Lee; G Mahajan"}, {"ref_id": "b1", "title": "Systematically differentiating parametric discontinuities", "journal": "ACM Trans. Graph", "year": "2021-07", "authors": "S P Bangaru; J Michel; K Mu; G Bernstein; T.-M Li; J Ragan-Kelley"}, {"ref_id": "b2", "title": "A theoretical and empirical comparison of gradient approximations in derivative-free optimization", "journal": "arXiv: Optimization and Control", "year": "2019", "authors": "A S Berahas; L Cao; K Choromanski; K Scheinberg"}, {"ref_id": "b3", "title": "Global optimality guarantees for policy gradient methods", "journal": "", "year": "2020", "authors": "J Bhandari; D Russo"}, {"ref_id": "b4", "title": "Convex optimization. Cambridge university press", "journal": "", "year": "2004", "authors": "S Boyd; L Vandenberghe"}, {"ref_id": "b5", "title": "The pinocchio c++ library : A fast and flexible implementation of rigid body dynamics algorithms and their analytical derivatives", "journal": "", "year": "2019", "authors": "J Carpentier; G Saurel; G Buondonno; J Mirabel; F Lamiraux; O Stasse; N Mansard"}, {"ref_id": "b6", "title": "A transition-aware method for the simulation of compliant contact with regularized friction", "journal": "IEEE Robotics and Automation Letters", "year": "2020-04", "authors": "A M Castro; A Qu; N Kuppuswamy; A Alspach; M Sherman"}, {"ref_id": "b7", "title": "Probability and stochastics", "journal": "Springer", "year": "2011", "authors": "E \u00c7 Inlar"}, {"ref_id": "b8", "title": "Pybullet, a python module for physics simulation for games, robotics and machine learning", "journal": "", "year": "", "authors": "E Coumans; Y Bai"}, {"ref_id": "b9", "title": "End-to-end differentiable physics for learning and control", "journal": "Curran Associates, Inc", "year": "2018", "authors": "F De Avila Belbute-Peres; K Smith; K Allen; J Tenenbaum; J Z Kolter; S Bengio; H Wallach; H Larochelle; K Grauman; N Cesa-Bianchi; Garnett "}, {"ref_id": "b10", "title": "Deep differentiable deterministic policy gradients", "journal": "", "year": "2020", "authors": "T Du; Y Li; J Xu; A Spielberg; K Wu; D Rus; W Matusik;  D3{pg}"}, {"ref_id": "b11", "title": "Randomized smoothing for stochastic optimization", "journal": "SIAM Journal on Optimization", "year": "2011", "authors": "J Duchi; P Bartlett; M Wainwright"}, {"ref_id": "b12", "title": "Optimal rates for zero-order convex optimization: The power of two function evaluations", "journal": "IEEE Transactions on Information Theory", "year": "", "authors": "J Duchi; M Jordan; M Wainwright; A Wibisono"}, {"ref_id": "b13", "title": "A pressure field model for fast, robust approximation of net contact force and moment between nominally rigid objects. IROS", "journal": "", "year": "2019", "authors": "R Elandt; E Drumwright; M Sherman; A Ruina"}, {"ref_id": "b14", "title": "Theory and practice of finite elements", "journal": "Springer Science & Business Media", "year": "2013", "authors": "A Ern; J.-L Guermond"}, {"ref_id": "b15", "title": "Global convergence of policy gradient methods for the linear quadratic regulator", "journal": "", "year": "2019", "authors": "M Fazel; R Ge; S M Kakade; M Mesbahi"}, {"ref_id": "b16", "title": "Brax -a differentiable physics engine for large scale rigid body simulation", "journal": "", "year": "", "authors": "C D Freeman; E Frey; A Raichuk; S Girgin; I Mordatch; O Bachem"}, {"ref_id": "b17", "title": "Add: Analytically differentiable dynamics for multi-body systems with frictional contact", "journal": "", "year": "2020", "authors": "M Geilinger; D Hahn; J Zehnder; M B\u00e4cher; B Thomaszewski; Coros ; S "}, {"ref_id": "b18", "title": "Stochastic first-and zeroth-order methods for nonconvex stochastic programming", "journal": "SIAM Journal on Optimization", "year": "2013", "authors": "S Ghadimi; G Lan"}, {"ref_id": "b19", "title": "Deluca -a differentiable control library: Environments, methods, and benchmarking", "journal": "", "year": "2021", "authors": "P Gradu; J Hallman; D Suo; A Yu; N Agarwal; U Ghai; K Singh; C Zhang; A Majumdar; E Hazan"}, {"ref_id": "b20", "title": "A differentiable simulator for robotics", "journal": "", "year": "2022", "authors": "T A Howell; S L Cleac'h; J Z Kolter; M Schwager; Z Manchester;  Dojo"}, {"ref_id": "b21", "title": "Difftaichi: Differentiable programming for physical simulation", "journal": "ICLR", "year": "2020", "authors": "Y Hu; L Anderson; T.-M Li; Q Sun; N Carr; J Ragan-Kelley; Durand ; F "}, {"ref_id": "b22", "title": "Plasticinelab: A soft-body manipulation benchmark with differentiable physics", "journal": "", "year": "2021", "authors": "Z Huang; Y Hu; T Du; S Zhou; H Su; J B Tenenbaum; C Gan"}, {"ref_id": "b23", "title": "Coefficient of Restitution Interpreted as Damping in Vibroimpact", "journal": "Journal of Applied Mechanics", "year": "1975-06", "authors": "K H Hunt; F R E Crossley"}, {"ref_id": "b24", "title": "On the sample complexity of reinforcement learning", "journal": "", "year": "2003", "authors": "S M Kakade"}, {"ref_id": "b25", "title": "Variational dropout and the local reparameterization trick", "journal": "Curran Associates, Inc", "year": "2015", "authors": "D P Kingma; T Salimans; M Welling"}, {"ref_id": "b26", "title": "Stochastic Aspects of Dynamics", "journal": "Cambridge university press", "year": "1996", "authors": "A Lasota; M C Mackey; Fractals Chaos; Noise "}, {"ref_id": "b27", "title": "Leveraging Randomized Smoothing for Optimal Control of Nonsmooth Dynamical Systems. working paper or preprint", "journal": "", "year": "2021-12", "authors": "Le Lidec; Q Montaut; L Schmid; C Laptev; I Carpentier; J "}, {"ref_id": "b28", "title": "Unified particle physics for real-time applications", "journal": "ACM Trans. Graph", "year": "2014-07", "authors": "M Macklin; M M\u00fcller; N Chentanez; T.-Y Kim"}, {"ref_id": "b29", "title": "Monte carlo gradient estimation in machine learning", "journal": "Journal of Machine Learning Research", "year": "", "authors": "S Mahamed; M Rosca; M Figurnov; A Mnih"}, {"ref_id": "b30", "title": "Mechanics of Robotic Manipulation", "journal": "The MIT Press", "year": "2001-06", "authors": "M T Mason"}, {"ref_id": "b31", "title": "Empirical bernstein bounds and sample variance penalization", "journal": "", "year": "2009", "authors": "A Maurer; M Pontil"}, {"ref_id": "b32", "title": "Understanding and correcting pathologies in the training of learned optimizers", "journal": "PMLR", "year": "2019-06", "authors": "L Metz; N Maheswaranathan; J Nixon; D Freeman; J Sohl-Dickstein"}, {"ref_id": "b33", "title": "Gradients are not all you need", "journal": "", "year": "2021", "authors": "L Metz; C D Freeman; S S Schoenholz; T Kachman"}, {"ref_id": "b34", "title": "Impulse-Based Dynamic Simulation of Rigid Body Systems", "journal": "", "year": "1996", "authors": "B V Mirtich"}, {"ref_id": "b35", "title": "Pods: Policy optimization via differentiable simulation", "journal": "PMLR", "year": "2021-07", "authors": "M A Z Mora; M Peychev; S Ha; M Vechev; Coros ; S "}, {"ref_id": "b36", "title": "A convex quasistatic time-stepping scheme for rigid multibody systems with contact and friction", "journal": "", "year": "2021", "authors": "T Pang"}, {"ref_id": "b37", "title": "Flexible model-based policy search robust to the curse of chaos", "journal": "", "year": "2018-07", "authors": "P Parmas; C E Rasmussen; J Peters; K Doya;  Pipps"}, {"ref_id": "b38", "title": "An imperative style, high-performance deep learning library", "journal": "Curran Associates, Inc", "year": "2019", "authors": "A Paszke; S Gross; F Massa; A Lerer; J Bradbury; G Chanan; T Killeen; Z Lin; N Gimelshein; L Antiga; A Desmaison; A Kopf; E Yang; Z Devito; M Raison; A Tejani; S Chilamkurthy; B Steiner; L Fang; J Bai; S Chintala;  Pytorch"}, {"ref_id": "b39", "title": "Principles of mathematical analysis", "journal": "", "year": "1964", "authors": "W Rudin"}, {"ref_id": "b40", "title": "Gradient estimation using stochastic computation graphs", "journal": "Curran Associates, Inc", "year": "2015", "authors": "J Schulman; N Heess; T Weber; P Abbeel"}, {"ref_id": "b41", "title": "Do Differentiable Simulators Give Better Policy Gradients?", "journal": "", "year": "", "authors": ""}, {"ref_id": "b42", "title": "Proximal policy optimization algorithms", "journal": "", "year": "2017", "authors": "J Schulman; F Wolski; P Dhariwal; A Radford; O Klimov"}, {"ref_id": "b43", "title": "Real analysis", "journal": "Princeton University Press", "year": "2009", "authors": "E M Stein; R Shakarchi"}, {"ref_id": "b44", "title": "An implicit time-stepping scheme for rigid body dynamics with coulomb friction", "journal": "", "year": "2000-01", "authors": "D Stewart; J J Trinkle"}, {"ref_id": "b45", "title": "Die wesentlichen Eigenschaften der Gleitund Rollenlager. Mitteilungen\u00fcber Forschungsarbeiten auf dem Gebiete des Ingenieurwesens, insbesondere aus den Laboratorien der technischen Hochschulen", "journal": "Julius Springer", "year": "1903", "authors": "R Stribeck"}, {"ref_id": "b46", "title": "Bundled gradients through contact via randomized smoothing", "journal": "", "year": "2021", "authors": "H J T Suh; T Pang; R Tedrake"}, {"ref_id": "b47", "title": "Policy gradient methods for reinforcement learning with function approximation", "journal": "Adv. Neural Inf. Process. Syst", "year": "2000-02", "authors": "R Sutton; D Mcallester; S Singh; Y Mansour"}, {"ref_id": "b48", "title": "A planning, control, and analysis toolbox for nonlinear dynamical systems", "journal": "", "year": "2022", "authors": "R Tedrake;  Drake"}, {"ref_id": "b49", "title": "Mujoco: A physics engine for model-based control", "journal": "", "year": "2012", "authors": "E Todorov; T Erez; Y Tassa"}, {"ref_id": "b50", "title": "An introduction to matrix concentration inequalities. Foundations and Trends\u00ae in Machine Learning", "journal": "", "year": "2015", "authors": "J A Tropp"}, {"ref_id": "b51", "title": "An Introduction to Hybrid Dynamical Systems", "journal": "Springer Publishing Company", "year": "2000", "authors": "A Van Der Schaft; H Schumacher"}, {"ref_id": "b52", "title": "All of statistics: a concise course in statistical inference", "journal": "Springer", "year": "2004", "authors": "L Wasserman"}, {"ref_id": "b53", "title": "Fast and feature-complete differentiable physics for articulated rigid bodies with contact", "journal": "", "year": "2021", "authors": "K Werling; D Omens; J Lee; I Exarchos; C K Liu"}, {"ref_id": "b54", "title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "journal": "", "year": "1992-05-03", "authors": "R J Williams"}, {"ref_id": "b55", "title": "Global convergence of policy gradient methods to (almost) locally optimal policies", "journal": "", "year": "2020", "authors": "K Zhang; A Koppel; H Zhu; T Ba\u015far"}], "figures": [{"figure_label": "2", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 2 .2Figure 2. From left: heaviside objective f (\u03b8, w) and stochastic objective F (\u03b8), empirical values of the gradient estimates, and their empirical variance.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 3 .3Figure 3. Left: More detailed example of ball hitting the wall in Figure 1.B. Left: The green trajectories hit a rectangular wall, displaying discontinuities. Right: the pink trajectories collide with the dome on top, and show continuous but stiff behavior.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 4 .4Figure 4. Top column: illustration of the physical system and the relaxation of Coulomb friction. Bottom column: the values of estimators and their empirical variances depending on number of samples and slip tolerance. Values of FoBG are zero in low-sample regimes due to empirical bias. As \u03bd \u2192 0, the empirical variance of FoBG goes to zero, which shows as empty in the log-scale. Expected variance, however, blows up as it scales with 1/\u03bd.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 5 .5Figure 5. The variance of the gradient of V1, with running cost c h = x 2 h \u2212 x g 2 , with respect to input trajectory as spring constant k increases. Mass m and damping coefficient c are fixed.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 6 .6Figure6. Variance of the gradient of the terminal cost qH \u2212 q g 2 with respect to the initial position q1. As horizon grows through a chaotic system, the ZoBG dominates the FoBG.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 7 .7Figure 7. First Column: Ball with wall example. In the third row, the triangle is the initial point, and red/blue/green stars are the optimum achieved by FoBG, ZoBG, and AoBG respectively (blue and green stars overlap). Second column: Iteration vs. Cost plot of different gradients. Right columns: Same plot repeated for the Momentum Transfer example. Standard deviation plotted 10 fold for visualization.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 8 .8Figure8. 1st column: trajectory optimization on pushing example with different contact models. AoBG and FoBG overlaps in soft pushing example. 2nd column: trajectory optimization on friction contact, and policy optimization on the tennis example. 3rd / 4th column: Visualization of policy performance for tennis. Black dots correspond to initial positions and colored dots correspond to final position, while the shaded lines are visualizations of individual closed-loop trajectories across multiple initial conditions.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "w\u223cp [f (\u03b8, w; x)] satisfies \u2207F (\u03b8) = E x\u223c\u03c1,w\u223cp [Dg in (\u03b8) \u2207\u03c8(w) \u2022 f (\u03b8, w; x)]. A.3. Proofs A.3.1. Proof of Proposition A.19 Lemma A.20. Let p be the distribution of w satisfying Assumption A.8 (and, by abuse of notation, its density with respect to the Lebesgue measure). Then, the following statements are true (a) The distribution p has finite moments. In particular, for any function g(\u2022) : R m \u2192 R d with polynomial growth, E w\u223cp [ g(w) ] < \u221e. This only requires Assumption A.8 part (a). (b) \u2207\u03c8(w) has polynomial growth, and E[\u2207\u03c8(w)] = 0.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "\u2207p(w) = \u2212p(w) \u2022 \u2207\u03c8(w), \u2207 2 p(w) = p(w) \u2022 \u2207\u03c8(w)\u2207\u03c8(w) \u2212 \u2207 2 \u03c8(w) :=M (w).Note that, by part (b) and the map that \u2207 2 \u03c8(w) has polynomial growth, M (w) has polynomial growth. Therefore, for any bound B > 0, the functiong(w) := sup \u2206 \u2264B M (w + \u2206) has polynomial growth. Finally, by the intermediate value theorem and for any \u2206 : \u2206 \u2264 B,|p(w) \u2212 p(w + \u2206) \u2212 p(w) \u2207\u03c8(w), \u2206 | = |p(w) \u2212 p(w + \u2206) \u2212 \u2207p(w), \u2206 | \u2264 \u2206 2 p(w)M (w + t\u2206), for some t \u2208 [0, 1] \u2264 \u2206 2 p(w)g(w),as needed. Part (d) is a consequence of part (b) and Lemma A.5.Proof of Proposition A.19. Consider the non-parametric case. Since g out (\u2022) has polynomial growth, one can verify that w \u2192 f (\u03b8, w) has polynomial growth. Hence the expectation F (\u03b8) is well-defined by Lemma A.20, part (a). We now prove that F (\u03b8) is differentiable. Fix a \u03b8, and let \u03b8 \u2212 \u03b8 \u2264 .F (\u03b8) \u2212 F (\u03b8 ) = f (\u03b8, w) \u2212 f (\u03b8 , w) p(w)dw = g out (g in (\u03b8) + w) \u2212 g out (g in (\u03b8 ) + w) p(w)dw = g out (g in (\u03b8) + w w1 )p(w)dw \u2212 g out (g in (\u03b8 ) + w) w2 p(w)dw = g out (w 1 )p(w 1 \u2212 g in (\u03b8))dw 1 \u2212 g out (w 2 )p(w 2 \u2212 g in (\u03b8 ))dw 2 = p(w \u2212 g in (\u03b8)) \u2212 p(w \u2212 g in (\u03b8 )) \u2022 g out (w)dw = p(w) \u2212 p(w + g in (\u03b8) \u2212 g in (\u03b8 )) \u2022 g out (w + g in (\u03b8))dw = p(w) \u2212 p(w + g in (\u03b8) \u2212 g in (\u03b8 )) \u2022 f (\u03b8, w)dw = E w\u223cp p(w) \u2212 p(w + g in (\u03b8) \u2212 g in (\u03b8 )) p(w)\u2022 f (\u03b8, w) .Setting \u2206 = g in (\u03b8) \u2212 g in (\u03b8 ), Lemma A.20 implies that the remainder term enjoyes the following property.R(w) := p(w) \u2212 p(w + \u2206) \u2212 p(w) \u2212\u2207\u03c8(w), \u2206 satisifies |R(w)| \u2264 \u2206 2g (w)p(w), whereg(w) has polynomial growth, and thusg(w) \u2022 f (\u03b8, w) integrable under p. Thus, there exists a constant C w > 0 such that F (\u03b8) \u2212 F (\u03b8 ) \u2212 E w\u223cp [ \u2212\u2207\u03c8(w), \u2206 f (\u03b8, w)] \u2264 C w \u2206 2 ,", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "x\u223c\u03c1,w1:H \u223cp H [(x 1 , w 1:H ) \u2208 Z 0 ] = 0. This proves part (a). Part (b) follows by the same dominated convergence argument. B. Additional Proofs from Section 3 B.1. Proof of Lemma 3.5 Recall that empirical bias means there exists an event E such that E[z | E] \u2212 E[z] \u2265 \u2206, and Pr[E] \u2265 1 \u2212 \u03b2.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "c }] \u2265 \u2206 0 := max{0, (1 \u2212 \u03b2)\u2206 \u2212 \u03b2 E[z] }. And thus, since Pr[E c ] = \u03b2, E[z | E c ] \u2265 \u2206 0 \u03b2 .", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Do Differentiable Simulators Give Better Policy Gradients? C.3. Proof of Lemma 4.3", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "min \u03b8 F (\u03b8) = min \u03b8 E w f (\u03b8, w).", "formula_coordinates": [1.0, 112.31, 530.96, 120.27, 14.69]}, {"formula_id": "formula_1", "formula_text": "Var[z] := E[ z \u2212 E[z] 2 ].", "formula_coordinates": [3.0, 180.14, 98.04, 111.04, 10.87]}, {"formula_id": "formula_2", "formula_text": "V h (x h , w h:H , \u03b8) = H h =h c h (x h , u h ), s.t. x h +1 = \u03c6(x h , u h ), u h = \u03c0(x h , \u03b8) + w h , h \u2265 h.", "formula_coordinates": [3.0, 55.44, 232.72, 237.9, 27.56]}, {"formula_id": "formula_3", "formula_text": "F (\u03b8) := E x1\u223c\u03c1 E w h i.i.d. \u223c p V 1 (x 1 , w 1:H , \u03b8), (1", "formula_coordinates": [3.0, 88.06, 292.98, 197.51, 13.96]}, {"formula_id": "formula_4", "formula_text": ")", "formula_coordinates": [3.0, 285.57, 293.33, 3.87, 8.64]}, {"formula_id": "formula_5", "formula_text": "\u03c0 : R d \u2192 R m is the identity function withw = w \u2208 R m , d = m and c : R m \u2192 R, F (\u03b8) = E w\u223cp f (\u03b8, w), f (\u03b8, w) = c(\u03b8 + w). (2)", "formula_coordinates": [3.0, 55.44, 597.81, 234.35, 44.37]}, {"formula_id": "formula_6", "formula_text": "\u2207 [0] Fi(\u03b8) := 1 \u03c3 2 V 1 (x 1 , w i 1:H , \u03b8) H h=1 D \u03b8 \u03c0(x i h , \u03b8) w i h \u2207 [0] F (\u03b8) := 1 N N i=1\u2207 [0] F i (\u03b8),", "formula_coordinates": [3.0, 311.19, 272.49, 220.75, 48.74]}, {"formula_id": "formula_7", "formula_text": "1 \u03c3 2 V1(x1, w i 1:H , \u03b8) \u2212 b H h=1 D \u03b8 \u03c0(x i h , \u03b8) w i h .", "formula_coordinates": [3.0, 331.69, 489.27, 186.7, 27.03]}, {"formula_id": "formula_8", "formula_text": "\u2207 [1] Fi(\u03b8) := \u2207 \u03b8 V 1 (x 1 , w i 1:H , \u03b8) \u2207 [1] F (\u03b8) := 1 N N i=1\u2207 [1] F i (\u03b8).", "formula_coordinates": [3.0, 357.82, 636.36, 236.21, 31.01]}, {"formula_id": "formula_9", "formula_text": "\u03c3 2 k = 1 N \u22121 N i=1 \u2207 [k] F i (\u03b8) \u2212\u2207 [k] F (\u03b8) 2 .", "formula_coordinates": [4.0, 82.23, 101.63, 180.41, 14.56]}, {"formula_id": "formula_10", "formula_text": "E[\u2207 [0] F (\u03b8)] = \u2207F (\u03b8).", "formula_coordinates": [4.0, 124.08, 400.38, 96.72, 11.37]}, {"formula_id": "formula_11", "formula_text": "E[\u2207 [1] F (\u03b8)] = \u2207F (\u03b8).", "formula_coordinates": [4.0, 124.08, 515.22, 96.72, 11.37]}, {"formula_id": "formula_12", "formula_text": "f (\u03b8, w) = H(\u03b8 + w), H(t) = 1 t \u2265 0 0 t < 0 ,", "formula_coordinates": [4.0, 78.6, 689.01, 187.69, 23.08]}, {"formula_id": "formula_13", "formula_text": "F (\u03b8) = E w [H(\u03b8 + w)] = erf(\u2212\u03b8; \u03c3 2 ),", "formula_coordinates": [4.0, 343.46, 85.96, 161.96, 11.72]}, {"formula_id": "formula_14", "formula_text": "\u2207 \u03b8 erf(\u2212\u03b8; \u03c3 2 ) = 1 \u221a 2\u03c0\u03c3 exp(\u2212(\u03b8 \u2212 w)/2\u03c3 2 ) = 0.", "formula_coordinates": [4.0, 307.44, 239.18, 204.71, 14.6]}, {"formula_id": "formula_15", "formula_text": "[E] \u2265 1 \u2212 \u03b2, and E[z | E] \u2212 E[z] \u2265 \u2206, but z \u2212 E[z | E] \u2264 S almost surely on E.", "formula_coordinates": [4.0, 306.94, 655.37, 234.5, 32.87]}, {"formula_id": "formula_16", "formula_text": "Var[z] \u2265 \u2206 2 0 \u03b2 , where \u2206 0 := max{0, (1 \u2212 \u03b2)\u2206 \u2212 \u03b2 E[z] }.", "formula_coordinates": [5.0, 55.08, 155.96, 236.1, 16.26]}, {"formula_id": "formula_17", "formula_text": "H \u03bd (t) = 2t/\u03bd if |t| \u2264 \u03bd/2 H(t) else .", "formula_coordinates": [5.0, 106.98, 334.21, 130.92, 23.3]}, {"formula_id": "formula_18", "formula_text": "Lemma 3.10. If for all x andw, |V 1 (x,w, \u03b8)| \u2264 B V and D \u03b8 \u03c0(x, \u03b8) op \u2264 B \u03c0 , then Var[\u2207 [0] F (\u03b8)] = 1 N Var[\u2207 [0] F i (\u03b8)] \u2264 B 2 V B 2 \u03c0 N \u2022 Hn \u03c3 2 .", "formula_coordinates": [6.0, 55.44, 550.81, 234.0, 55.4]}, {"formula_id": "formula_19", "formula_text": "\u03c3 2 Var[\u2207 [1] F (\u03b8)] = Var[\u2207 \u03b8 V (x 1 ,w, \u03b8)]", "formula_coordinates": [6.0, 55.08, 666.58, 234.36, 23.18]}, {"formula_id": "formula_20", "formula_text": "\u2207 [\u03b1] F (\u03b8) = \u03b1\u2207 [1] F (\u03b8) + (1 \u2212 \u03b1)\u2207 [0] F (\u03b8).", "formula_coordinates": [6.0, 332.75, 232.84, 183.37, 10.81]}, {"formula_id": "formula_21", "formula_text": "\u2207 [\u03b1] F (\u03b8) \u2212 \u2207F (\u03b8) \u2264 \u03b3.(3)", "formula_coordinates": [6.0, 374.28, 485.48, 167.16, 11.48]}, {"formula_id": "formula_22", "formula_text": "min \u03b1\u2208[0,1] \u03b1 2\u03c32 1 + (1 \u2212 \u03b1) 2\u03c32 0 s.t. + \u03b1 \u2207 [1] F \u2212\u2207 [0] F B \u2264 \u03b3. (4", "formula_coordinates": [6.0, 347.61, 566.82, 189.96, 48.45]}, {"formula_id": "formula_23", "formula_text": ")", "formula_coordinates": [6.0, 537.57, 587.0, 3.87, 8.64]}, {"formula_id": "formula_24", "formula_text": "\u03b1 2\u03c32 1 + (1 \u2212 \u03b1) 2\u03c32 0 is an unbiased estimate of N \u2022 Var[\u2207 [\u03b1] F (\u03b8)].", "formula_coordinates": [6.0, 307.44, 652.88, 234.0, 22.49]}, {"formula_id": "formula_25", "formula_text": "Lemma 4.4. With \u03b3 = \u221e, the optimal \u03b1 is \u03b1 \u221e :=\u03c3 2 0 \u03c3 2 1 +\u03c3 2 0 . For finite \u03b3 \u2265 , Eq (4) is \u03b1 \u03b3 := \u03b1 \u221e if \u03b1 \u221e B \u2264 \u03b3 \u2212 \u03b5 \u03b3\u2212\u03b5 B otherwise .(5)", "formula_coordinates": [7.0, 54.83, 571.37, 236.35, 68.65]}, {"formula_id": "formula_26", "formula_text": "R D \u2192 R D is Lebesgue measurable if for all Z \u2208 B(R D ), \u03a6 \u22121 (Z ) \u2208 L (R D ).", "formula_coordinates": [13.0, 55.44, 468.15, 486.0, 25.28]}, {"formula_id": "formula_27", "formula_text": "\u03a6 : Z \u2192 R D is Lebesgue mearuable on its domain if for all Z \u2208 B(R D ), \u03a6 \u22121 (Z ) \u2208 L (R D ).", "formula_coordinates": [13.0, 55.44, 553.03, 486.0, 25.28]}, {"formula_id": "formula_28", "formula_text": "E z\u223cD [\u03a6(z)] := E z\u223cD [\u03a6(z)], where\u03a6(z) = \u03a6(z) z \u2208 Z 0 otherwise. (6", "formula_coordinates": [14.0, 149.73, 134.84, 387.45, 25.63]}, {"formula_id": "formula_29", "formula_text": ")", "formula_coordinates": [14.0, 537.18, 142.65, 4.26, 9.5]}, {"formula_id": "formula_30", "formula_text": "If E z\u223cD \u03a6 (z) < \u221e, then for z (1) , . . . , z (N ) i.i.d. \u223c D, 1 N N i=1 \u03a6(z (i) ) converges to E[\u03a6(z)] in probability.", "formula_coordinates": [14.0, 75.37, 306.17, 465.64, 16.95]}, {"formula_id": "formula_31", "formula_text": "lim h \u21920 \u03a6(h + z) \u2212 \u03a6(z) h \u2212 D\u03a6(z) \u2022 h = 0.", "formula_coordinates": [14.0, 201.68, 446.8, 197.75, 24.46]}, {"formula_id": "formula_32", "formula_text": "F \u2264 a(1 + z b )).", "formula_coordinates": [14.0, 198.64, 682.32, 80.6, 12.64]}, {"formula_id": "formula_33", "formula_text": "\u03c8 : R D \u2192 R is differentiable on a set of Z \u2282 R D such that Z c = R D \\ Z has Lebesgue measure zero.", "formula_coordinates": [15.0, 55.44, 241.36, 486.0, 25.29]}, {"formula_id": "formula_34", "formula_text": "\u2022 A function \u03c8(z) : R d1 \u2192 R d2 is polynomially-Lipschitz if there are constants a, b > 0 such that for all radii R \u2265 1 and all z, z \u2208 R d1 such that z , z \u2264 R, \u03c8(z) \u2212 \u03c8(z ) \u2264 aR b .", "formula_coordinates": [15.0, 66.55, 355.29, 474.89, 25.29]}, {"formula_id": "formula_35", "formula_text": "\u2207\u03c8(w) = w \u03c3 2 , E[\u2207\u03c8(w)] = 0. (7", "formula_coordinates": [15.0, 223.88, 647.66, 313.3, 24.46]}, {"formula_id": "formula_36", "formula_text": ")", "formula_coordinates": [15.0, 537.18, 655.39, 4.26, 9.5]}, {"formula_id": "formula_37", "formula_text": "F (\u03b8) = E x1\u223c\u03c1,w1:H \u223cp H [V 1 (x h , w 1:H , \u03b8)] s.t. x h+1 = \u03c6(x h , u h ), u h = \u03c0(x h , \u03b8) + w h .", "formula_coordinates": [16.0, 176.39, 154.0, 244.1, 26.95]}, {"formula_id": "formula_38", "formula_text": "\u2207 \u03b8 F (\u03b8) = E x1\u223c\u03c1,w1:H \u223cp H H h=1 (D \u03b8 \u03c0 h (x h , \u03b8)) \u03c8(w h )V h (x h , w h:H , \u03b8) .", "formula_coordinates": [16.0, 134.2, 269.57, 328.48, 34.08]}, {"formula_id": "formula_39", "formula_text": "\u2207 \u03b8 F (\u03b8) = E x1\u223c\u03c1,w1:H \u223cp H V 1 (x h , w 1:H , \u03b8) H h=1 (D \u03b8 \u03c0 h (x h , \u03b8)) \u03c8(w h ) .", "formula_coordinates": [16.0, 133.94, 335.85, 329.01, 34.08]}, {"formula_id": "formula_40", "formula_text": "\u2207 \u03b8 F (\u03b8) = 1 \u03c3 2 E x1\u223c\u03c1,w1:H \u223cp H V 1 (x h , w 1:H , \u03b8) H h=1 (D \u03b8 \u03c0 h (x h , \u03b8)) w h .", "formula_coordinates": [16.0, 135.05, 423.72, 326.77, 34.08]}, {"formula_id": "formula_41", "formula_text": "Pr x1\u223c\u03c1 [x 1 \u2208 X ] = X \u00b5(x 1 )dx 1 + i\u22651 a i \u03bd i .", "formula_coordinates": [16.0, 55.44, 615.42, 207.25, 12.89]}, {"formula_id": "formula_42", "formula_text": "V 1 (x 1 , w 1:H , \u03b8) is differentiable for all (x 1 , w 1:H ) \u2208 Z. (b) \u2207 \u03b8 F (\u03b8) = E x1\u223c\u03c1,w1:H \u223cp H [\u2207V 1 (x 1 , w 1:H , \u03b8)]", "formula_coordinates": [17.0, 57.61, 82.69, 478.2, 33.39]}, {"formula_id": "formula_43", "formula_text": "g in (\u03b8; x) \u2212 g in (\u03b8 + \u2206; x) \u2212 Dg in (\u03b8; x) \u2022 \u2206 \u2264 \u2206 2g (x).(8)", "formula_coordinates": [17.0, 170.95, 501.67, 370.49, 13.13]}, {"formula_id": "formula_44", "formula_text": "\u2207F (\u03b8) = E w\u223cp [Dg in (\u03b8) \u2207\u03c8(w) \u2022 f (\u03b8, w)].", "formula_coordinates": [17.0, 197.78, 646.87, 201.32, 10.67]}, {"formula_id": "formula_45", "formula_text": "F (\u03b8) = E x\u223c\u03c1,", "formula_coordinates": [17.0, 55.44, 670.68, 486.0, 23.78]}, {"formula_id": "formula_46", "formula_text": "|p(w) \u2212 p(w + \u2206) \u2212 p(w) \u2212\u2207\u03c8(w), \u2206 | \u2264 \u2206 2 p(w) \u2022g(w). (d) Let g(\u2022, \u2022) : R m \u00d7 R n \u2192 R have polynomial growth. Then x \u2192 E w \u2207\u03c8(w) \u2022 g(w,", "formula_coordinates": [18.0, 57.61, 262.78, 394.15, 47.41]}, {"formula_id": "formula_47", "formula_text": "\u2207\u03c8(w) = 1 0 \u2207 2 \u03c8(tw) \u2022 wdt \u2264 \u2207\u03c8(0) + w max t\u2208[0,1] \u2207 2 \u03c8(tw) op ,", "formula_coordinates": [18.0, 130.47, 387.26, 341.41, 28.69]}, {"formula_id": "formula_48", "formula_text": "F (\u03b8) \u2212 F (\u03b8 ) \u2212 g in (\u03b8 ) \u2212 g in (\u03b8), E w [\u2207\u03c8(w) \u2022 f (\u03b8, w)] \u03b8 \u2212 \u03b8 \u2264 C w g in (\u03b8 ) \u2212 g in (\u03b8) 2 \u03b8 \u2212 \u03b8 .(9)", "formula_coordinates": [19.0, 105.64, 459.38, 435.8, 26.56]}, {"formula_id": "formula_49", "formula_text": "F (\u03b8; x) \u2212 F (\u03b8 ; x) \u2212 g in (\u03b8 ; x) \u2212 g in (\u03b8; x), E w [\u2207\u03c8(w; x) \u2022 f (\u03b8, w; x)] \u03b8 \u2212 \u03b8 \u2264 C w g in (\u03b8 ; x) \u2212 g in (\u03b8; x) 2 \u03b8 \u2212 \u03b8 . (10", "formula_coordinates": [19.0, 60.29, 567.46, 482.2, 43.06]}, {"formula_id": "formula_50", "formula_text": ")", "formula_coordinates": [19.0, 536.88, 601.02, 4.56, 9.5]}, {"formula_id": "formula_51", "formula_text": "F (\u03b8; x) \u2212 F (\u03b8 ; x) \u2212 Dg in (\u03b8; x)(\u03b8 \u2212 \u03b8), E w [\u2207\u03c8(w; x) \u2022 f (\u03b8, w; x)] \u03b8 \u2212 \u03b8 \u2264g(x) \u2022 \u03b8 \u2212 \u03b8 \u2022 E w \u2207\u03c8(w) \u2022 f (\u03b8, w; x) + C w g out (\u03b8 ; x) \u2212 g out (\u03b8; x) 2 \u03b8 \u2212 \u03b8 . \u2207 \u03b8 F (\u03b8) = \u2207 \u03b8 (E x\u223c\u03c1 [F (\u03b8; x)]) = E x\u223c\u03c1 [Dg in (\u03b8; x) E w\u223cp [\u2207 w \u03c8(w) \u2022 f (\u03b8, w; x)]] = E x\u223c\u03c1,w\u223cp [\u2207 \u03b8 Dg in (\u03b8; x) \u2207 w \u03c8(w) \u2022 f (\u03b8, w; x)]", "formula_coordinates": [19.0, 113.26, 654.91, 377.02, 59.54]}, {"formula_id": "formula_52", "formula_text": "V h (x h , \u03b8) = E wh:H i.i.d. \u223c p V (x h , w h:H , \u03b8) (a) V + h,\u03b8 (\u03b8 , w h ; x h ) =V h+1 (\u03c6(x h , \u03c0 h (x h , \u03b8 ) + w t ), \u03b8) (b.1) V + h,\u03b8 (\u03b8 ; x h ) = E wh\u223cp V + h (\u03b8 , w h ; x h , \u03b8). (b.2) c h (\u03b8, w h ; x h ) = c h (x h , \u03c0 h (x h , \u03b8) + w t ), (c.1) c h (\u03b8; x h ) = E wh\u223cp c h (\u03b8, w h ; x h ) (c.2)", "formula_coordinates": [20.0, 181.5, 595.8, 652.35, 83.83]}, {"formula_id": "formula_53", "formula_text": "F (\u03b8) \u2212 F (\u03b8 ) (11) = E x1\u223c\u03c1 V 1 (x 1 , \u03b8) \u2212V 1 (x 1 , \u03b8 ) = H h=1 E \u03b8;h [ c h (\u03b8; x h ) \u2212c h (\u03b8 ; x h ) + V + h,\u03b8 (\u03b8; x h ) \u2212V + h,\u03b8 (\u03b8 ; x h ) ] = H h=1 E \u03b8;h E wh\u223cp [c h (\u03b8, w h ; x h ) \u2212 c h (\u03b8 , w h hx h )] + E xh\u223c\u03b8;h E wh\u223cp [V + h,\u03b8 (\u03b8, w h ; x h ) \u2212 V + h,\u03b8 (\u03b8 , w h ; x h )] = H h=1 (F h,\u03b8;c (\u03b8) \u2212 F h,\u03b8;c (\u03b8 )) + (F h,\u03b8;V (\u03b8) \u2212 F h,\u03b8;c (\u03b8 ))(12)", "formula_coordinates": [21.0, 62.85, 91.78, 478.59, 145.21]}, {"formula_id": "formula_54", "formula_text": "x 1 \u223c \u03c1, x t+1 = \u03c6(x t , u t ), u t = \u03c0(x t , \u03b8) + w t ,", "formula_coordinates": [21.0, 183.5, 268.85, 229.88, 10.67]}, {"formula_id": "formula_55", "formula_text": "F h,\u03b8;c (\u03b8 ) := E xh\u223c\u03b8;h E wh\u223cp c h (\u03b8 , w h ; x h )], F h,\u03b8;V (\u03b8 ) := E xh\u223c\u03b8;h E wh\u223cp V + h,\u03b8 (\u03b8 , w h | x h )].", "formula_coordinates": [21.0, 86.0, 310.71, 424.88, 15.11]}, {"formula_id": "formula_56", "formula_text": "\u2207 \u03b8 F (\u03b8) = H h=1 \u2207 \u03b8 F h,\u03b8;c (\u03b8 ) + \u2207 \u03b8 F h,\u03b8;V (\u03b8 ) \u03b8 =\u03b8 .(13)", "formula_coordinates": [21.0, 175.11, 371.39, 366.33, 34.08]}, {"formula_id": "formula_57", "formula_text": "V h+1 (\u03c6(x h , u), w h+1:H , \u03b8 0 ) = H i=h+1 c i (x i , \u03c0 h (x i , \u03b8 0 ) + w i , s.t. x i+1 = \u03c6(x i , \u03c0 h (x i , \u03b8 0 )) + w i .", "formula_coordinates": [22.0, 79.08, 91.98, 438.73, 34.08]}, {"formula_id": "formula_58", "formula_text": "\u2207 \u03b8 F h,\u03b8;c (\u03b8 ) = E xh\u223c\u03b8;h E wh\u223cp D \u03b8 \u03c0 h (x h , \u03b8 ) \u2207\u03c8(w h )c h (\u03b8 , w h ; x h )] \u2207 \u03b8 F h,\u03b8;V (\u03b8 ) = E xh\u223c\u03b8;h E wh\u223cp D \u03b8 \u03c0 h (x h , \u03b8 ) \u2207\u03c8(w h ) \u2022 V + h,\u03b8 (\u03b8 , w h | x h ) .", "formula_coordinates": [22.0, 120.93, 215.66, 355.02, 33.08]}, {"formula_id": "formula_59", "formula_text": "\u2207 \u03b8 F (\u03b8) = H h=1 E xh\u223c\u03b8;h E wh\u223cp D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) c h (\u03b8 , w h ; x h ) + V + h,\u03b8 (\u03b8, w h | x h ) ] .", "formula_coordinates": [22.0, 84.14, 284.71, 428.59, 34.08]}, {"formula_id": "formula_60", "formula_text": "\u2207 \u03b8 F (\u03b8) = H h=1 E x1\u223c\u03c1 E w1:H \u223cp H [D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) (c h (x h , u h ) + V h+1 (x h , w h+1:H , \u03b8))]] = H h=1 E x1\u223c\u03c1 E w1:H \u223cp H [D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) \u2022 V h (x h , w h:H , \u03b8)]] = E x1\u223c\u03c1 E w1:H \u223cp H H h=1 D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) \u2022 V h (x h , w h:H , \u03b8) .", "formula_coordinates": [22.0, 88.01, 367.33, 420.87, 111.5]}, {"formula_id": "formula_61", "formula_text": "E x1\u223c\u03c1 E w1:H \u223cp H H h=1 D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) \u2022 V 1 (x 1 , w 1:H , \u03b8) \u2212 E x1\u223c\u03c1 E w1:H \u223cp H H h=1 D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h ) \u2022 h\u22121 i=1 c i (x i , u i ) (b)", "formula_coordinates": [22.0, 133.9, 526.15, 310.98, 88.73]}, {"formula_id": "formula_62", "formula_text": "V 1 (x 1 , w 1:H , \u03b8) = h\u22121 i=1 c i (x i , u i ) = V h (x h , w 1:H , \u03b8).", "formula_coordinates": [22.0, 207.28, 628.0, 249.18, 15.29]}, {"formula_id": "formula_63", "formula_text": "E x1\u223c\u03c1 E w1:H \u223cp H [D \u03b8 \u03c0 h (x h , \u03b8) \u2207\u03c8(w h )c i (x i , u i )] = E x1\u223c\u03c1 E w1:h\u22121\u223cp h\u22121 [D \u03b8 \u03c0 h (x h , \u03b8) c i (x i , u i )] \u2022 E wh\u223cp [\u2207\u03c8(w h )] = 0.", "formula_coordinates": [22.0, 128.69, 667.8, 339.5, 27.14]}, {"formula_id": "formula_64", "formula_text": "\u03a6 h (x 1 , w 1:h\u22121 , \u03b8) =\u03c6 h\u22121 (\u2022, w h , \u03b8) \u2022\u03c6 h\u22122 (\u2022, w h\u22121 , \u03b8) \u2022 \u2022 \u2022 \u2022 \u2022\u03c6 1 (x 1 , w 1 , \u03b8).", "formula_coordinates": [23.0, 126.52, 176.1, 343.84, 10.81]}, {"formula_id": "formula_65", "formula_text": "Claim A.24. Fix (x 1 , w 1:H , \u03b8). If \u03b8 \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8 ) for all is differentiable at \u03b8 = \u03b8 for all h \u2208 [H], then \u03b8 \u2192 V 1 (x 1 , w 1:H , \u03b8 ) is differentiable at \u03b8 = \u03b8. Proof. Definingc h (x, \u03b8; w) = c h (x, \u03c0 h (x, \u03b8) + w), we have V 1 (x 1 , w 1:H , \u03b8) = H h=1c h (\u03a6 h (x 1 , w 1:h\u22121 , \u03b8), \u03b8; w h ).", "formula_coordinates": [23.0, 55.44, 228.28, 487.92, 94.78]}, {"formula_id": "formula_66", "formula_text": "c h (\u03a6 h (x 1 , w 1:h\u22121 , \u03b8 ), \u03b8 ; w h ) is differentiable at \u03b8 = \u03b8.", "formula_coordinates": [23.0, 55.44, 359.74, 253.88, 10.81]}, {"formula_id": "formula_67", "formula_text": "w 1:h\u22121 \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8) is differentiable at w 1:h\u22121 = w 1:h\u22121 for all h \u2208 [H], then \u03b8 \u2192 \u03a6 h (x 1 , w 1:h\u22121 , \u03b8 ) is differentiable at \u03b8 = \u03b8 for all h \u2208 [H].", "formula_coordinates": [23.0, 55.44, 402.57, 486.0, 23.96]}, {"formula_id": "formula_68", "formula_text": "\u03a8 h (\u03b4) := \u03a6 h (x 1 , w 1:h\u22121 , \u03b8 + \u03b4) = \u03a6 h (x 1 , w 1:h\u22121 +w 1:h (\u03b4)), \u03b8)(14)", "formula_coordinates": [23.0, 150.71, 490.34, 390.73, 10.81]}, {"formula_id": "formula_69", "formula_text": "w i (\u03b4) = \u03c0 i (\u03a8 i (\u03b4), \u03b8 + \u03b4) \u2212 \u03c0 i (\u03a8 i (\u03b4), \u03b8). (15", "formula_coordinates": [23.0, 203.87, 534.93, 333.01, 10.67]}, {"formula_id": "formula_70", "formula_text": ")", "formula_coordinates": [23.0, 536.88, 535.28, 4.56, 9.5]}, {"formula_id": "formula_71", "formula_text": "1:i\u22121 \u2192 \u03a6 h (x 1 , w 1:i\u22121 , \u03b8) for all i \u2264 H, then \u03a8 i (\u03b4) is differen- tiable at \u03b4 = 0 for all i \u2264 h.", "formula_coordinates": [23.0, 55.44, 557.22, 487.82, 23.0]}, {"formula_id": "formula_72", "formula_text": "1 ) := H h=1 W h (x 1 ), then \u03b8 \u2192 V 1 (x 1 , w 1:H , \u03b8 ) is differentiable at \u03b8 = \u03b8.", "formula_coordinates": [23.0, 175.5, 704.57, 334.62, 15.29]}, {"formula_id": "formula_73", "formula_text": "\u2206 \u2264 E[z | E] \u2212 E[z] = (1 \u2212 \u03b2) \u22121 E[zI{E}] \u2212 E[z] \u2264 (1 \u2212 \u03b2) \u22121 E[zI{E}] + (1 \u2212 \u03b2) \u22121 E[z] \u2212 E[z] \u2022 |1 \u2212 (1 \u2212 \u03b2) \u22121 | \u2264 (1 \u2212 \u03b2) \u22121 E[zI{E c }] \u2212 E[z] \u2022 |1 \u2212 (1 \u2212 \u03b2) \u22121 |.", "formula_coordinates": [25.0, 138.64, 318.88, 319.59, 62.9]}, {"formula_id": "formula_74", "formula_text": "E[ z 2 ] \u2265 E[ z 2 I{E c }] = Pr[E c ] \u2022 E[ z 2 | E c ] \u2265 Pr[E c ] \u2022 E[z | E c ] 2 \u2265 \u03b2 \u2022 \u2206 2 0 \u03b2 2 = \u2206 2 0 \u03b2 .", "formula_coordinates": [25.0, 228.32, 603.39, 140.24, 79.1]}, {"formula_id": "formula_75", "formula_text": "Var[\u03b1X + (1 \u2212 \u03b1)Y ] = E[ \u03b1(X \u2212 E[X]) + (1 \u2212 \u03b1)(Y \u2212 E[Y ]) 2 ] = \u03b1 2 E X \u2212 E[X] 2 + (1 \u2212 \u03b1) 2 E Y \u2212 E[Y ] 2 + \u03b1 E[ X \u2212 E[X], Y \u2212 E[Y ] ] =0 = \u03b1 2 Var[X] + (1 \u2212 \u03b1) 2 Var[Y ],", "formula_coordinates": [27.0, 71.36, 107.69, 454.17, 61.17]}, {"formula_id": "formula_76", "formula_text": "1 N E[\u03c3 2 k ] = Var[\u2207", "formula_coordinates": [27.0, 251.2, 285.71, 79.79, 24.43]}, {"formula_id": "formula_77", "formula_text": "E[ \u03b1 2\u03c32 1 + (1 \u2212 \u03b1) 2\u03c32 2 ] = N \u2022 Var[\u2207", "formula_coordinates": [27.0, 204.1, 348.35, 171.98, 14.19]}, {"formula_id": "formula_78", "formula_text": "\u03b1 \u03b3 := \u03b1 \u221e if \u03b1 \u221e B \u2264 \u03b3 \u2212 \u03b5 \u03b3\u2212\u03b5 B", "formula_coordinates": [27.0, 220.59, 527.19, 154.51, 28.54]}, {"formula_id": "formula_80", "formula_text": "2\u03b1 * \u03c32 1 + 2(1 \u2212 \u03b1 * )\u03c3 2 0 + \u03bbB = 0 \u03bb( \u2212 \u03b3 + \u03b1 * B) = 0,", "formula_coordinates": [27.0, 225.32, 635.21, 146.25, 28.2]}, {"formula_id": "formula_81", "formula_text": "F (\u03b8) + (1 \u2212 \u03b1)\u2207 [0] F (\u03b8) \u2212 \u03b1\u2207F (\u03b8) \u2212 (1 \u2212 \u03b1)\u2207F (\u03b8) \u2264 (1 \u2212 \u03b1) \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) + \u03b1 \u2207 [1] F (\u03b8) \u2212 \u2207F (\u03b8) \u2264 (1 \u2212 \u03b1) \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) + \u03b1 \u2207 [1] F (\u03b8) \u2212\u2207 [0] F (\u03b8) + \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) \u2264 \u2207 [0] F (\u03b8) \u2212 \u2207F (\u03b8) + \u03b1 \u2207 [1] F (\u03b8) \u2212\u2207 [0] F (\u03b8) \u2264 + \u03b1 \u2207 [1] F (\u03b8) \u2212\u2207 [0] F (\u03b8) \u2264 \u03b3.", "formula_coordinates": [28.0, 99.77, 151.07, 388.38, 107.15]}, {"formula_id": "formula_82", "formula_text": "\u2207 [0] F (\u03b8) = 1 N N i=1\u2207 [0] F i (\u03b8), where\u2207 [0] F i (\u03b8) N i=1 V 1 (x i 1 , w i 1:H , \u03b8) \u2022 H i=1 D \u03b8 \u03c0(x h , \u03b8) w h .", "formula_coordinates": [28.0, 79.99, 327.83, 436.91, 33.81]}, {"formula_id": "formula_83", "formula_text": "E[ X 1 2 ] \u2264 \u03c3 2 . Then, Pr 1 N N i=1 X i \u2212 E[X] \u2265 t \u2264 (d + 1) exp \u2212N t 2 /2 \u03c3 2 + Rt/3", "formula_coordinates": [28.0, 162.43, 397.04, 262.75, 55.52]}, {"formula_id": "formula_84", "formula_text": "Pr \uf8ee \uf8f0 1 N N i=1 X i \u2212 E[X] \u2265 2\u03c3 2 log d+1 \u03b4 N + 2R 3N log d + 1 \u03b4 \uf8f9 \uf8fb \u2264 1 \u2212 \u03b4.", "formula_coordinates": [28.0, 139.51, 479.56, 317.87, 37.13]}, {"formula_id": "formula_85", "formula_text": "\u03c3 2 0 := i \u2207 [0] F i (\u03b8) 2 \u2265\u03c3 2 0 .", "formula_coordinates": [28.0, 230.92, 582.61, 135.04, 24.89]}], "doi": "10.1145/3450626"}