{"title": "Learning Coordination Classifiers", "authors": "Yuhong Guo; Russell Greiner; Dale Schuurmans", "pub_date": "", "abstract": "We present a new approach to ensemble classification that requires learning only a single base classifier. The idea is to learn a classifier that simultaneously predicts pairs of test labels-as opposed to learning multiple predictors for single test labelsthen coordinating the assignment of individual labels by propagating beliefs on a graph over the data. We argue that the approach is statistically well motivated, even for independent identically distributed (iid) data. In fact, we present experimental results that show improvements in classification accuracy over single-example classifiers, across a range of iid data sets and over a set of base classifiers. Like boosting, the technique increases representational capacity while controlling variance through a principled form of classifier combination.", "sections": [{"heading": "Introduction", "text": "Supervised learning has been by far the most studied task in machine learning research. The problem is to take a finite set of observed training examples (x 1 , y 1 ), ..., (x n , y n ) and produce a classifier f : X \u2192 Y that achieves small misclassification error on subsequent test examples. Most research has tended to adopt a standard \"iid\" assumption that the training and test examples are independent and identically distributed. In fact, this assumption is fundamental to much of the theoretical research on the topic [Anthony and Bartlett, 1999] and also characterizes most standard learning methods-as exemplified by the fact that most machine learning methods classify each test pattern in isolation, independently of other test patterns.\nRecently, however, increasing attention has been paid to problems where the training and test labels are not independent, but instead strongly related. For example, in domains such as part of speech tagging and webpage classification, each word-tag or webpage-label depends on the tag or label of proximal words or webpages, in addition to just the features of the immediate word or webpage. Various forms of \"relational\" learning models have been developed to handle these kinds of problems over the last few years. A notable example is work on probabilistic relational models (PRMs), where the correlation between the class labels of different instances is explicitly represented in a directed graphical model [Getoor et al., 2001;2002]. Other approaches for learning multivariate classifiers include conditional random fields (CRFs) [Lafferty et al., 2001], relational Markov networks (RMNs) [Taskar et al., 2002], and maximum margin Markov networks (M3N) [Taskar et al., 2003]. All of these methods have led to substantial progress on learning classifiers that make dependent predictions of test labels that are explicitly related.\nAlthough learning multivariate predictors is an exciting problem, we nevertheless focus on the classical iid case in this paper. However, we demonstrate what we believe is a surprising and counterintuitive connection: that learning multivariate dependent predictions is a beneficial idea even in the iid setting. In particular, we develop a relational learning strategy that classifies test patterns by connecting their labels in a graphical model-hence correlating the subsequent predictions-even when it is explicitly assumed that all training and test examples are iid.\nBefore explaining the rationale behind our approach and explaining why dependent prediction still makes sense in the iid setting, we note that standard relational learning approaches, such as PRMs, CRFs, RMNs and M3Ns, do not naturally correlate predictions on iid data. That is, these techniques only consider label dependencies that are explicitly asserted to hold in the true underlying model of the domain. In the iid case, since no dependencies are asserted between test labels, these standard relational approaches reduce to singlelabel learning techniques, such as univariate logistic regression and support vector machines. However, what we are proposing is different: we intentionally add dependencies between test labels, even when all labels are explicitly assumed to be independent in the underlying data generation process. Surprisingly, we demonstrate that correlating predictions can still be advantageous.\nAfter introducing our basic approach below, we then motivate and justify our technique in three separate ways. First, we show that predicting correlated test labels is statistically justified in the iid setting, even when the independence assumptions are explicitly taken into account. In fact, we show that it is incorrect to conclude that a learned predictor can sufficiently treat test cases as independent simply because they come from an iid source. Second, we show that our proposed relational learning technique can be viewed as a natural generalization of similarity-based learning techniques.\nMoreover, it can also be viewed as a simple form of ensemble learning method that has some advantages over standard approaches. Third, we show empirically that our proposed method can achieve improvements in classification accuracy across a range of iid domains, for different base learning algorithms.", "publication_ref": ["b3", "b1", "b2", "b3", "b2", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Learning Coordinated Label Predictors", "text": "We begin by simply introducing our learning method, and then attempt to motivate it more thoroughly below. Initially, we will focus on using probabilistic classifiers (although we briefly consider an extension to nonprobabilistic classifiers in Section 5 below).\nIn the iid setting, the standard approach to probabilistic classification is to learn a univariate model P (y|x, \u03b8) that asserts a conditional probability distribution over a single classification variable y given an input pattern x, where \u03b8 represents the parameters of the model. Given such a representation, there are two key steps to building a univariate classifier: The first is to learn a specific predictive model P (y|x, \u03b8) given training data (x 1 , y 1 ), ..., (x n , y n ), based on using a principle such as maximum (conditional) likelihood or maximum a posteriori estimation. Then, given a set of test patterns x * 1 , ..., x * m , one classifies each x * i independently by computing the label\u0177 i that maximizes the estimated conditional probability,\u0177 i = arg max y P (y|x * i , \u03b8). Natural examples of this approach are learning naive Bayes classifiers [Friedman et al., 1997], logistic regression classifiers [Hastie et al., 2001], kernel logistic regression classifiers [Zhu and Hastie, 2001], sigmoid network classifiers [Neal, 1996], and Bayesian network classifiers [Greiner and Zhou, 2002].\nOur approach is different. Instead of learning a univariate classifier that predicts only a single label, we instead propose to learn a pairwise label classifier P (y i y j |x i x j , \u03c6) that takes an arbitrary pair of input patterns, x i and x j , and asserts a conditional joint distribution over the pair of labels y i and y j . For example, if there are two classes, say 0 and 1, then a pairwise classifier would assert the conditional probability of the four possible pair labelings (y i , y j ) \u2208 {(0, 0), (0, 1), (1, 0), (1, 1)} given the two input patterns x i and x j . In general the pairwise predictor does not assume that y i and y j are independent given x i and x j , even though they are indeed assumed to be independent in the true model (we present a justification of this in Section 3 below). We refer to a pairwise label classifier of this form as a \"coordination classifier\" to highlight the fact that it attempts to model any coordination that might appear between the labels y i and y j given the input patterns x i and x j . Given the alternative representation P (y i y j |x i x j , \u03c6) we next describe the two main processes of, first, training a coordination classifier from data, and then using it to label test patterns. (x 1 , y 1 ), ..., (x n , y n ) is given. First we construct a set of pairs from the set {(x i x j , y i y j )} and then supply these as a conventional training set for learning a predictive model P (y i y j |x i x j , \u03c6) from data. (In our experiments below we ignore duplicate pairs but otherwise include both orderings of each distinct pair to ensure that the learned model is symmetric.) Once the training data is constructed, the parameters of the model, \u03c6, can then be estimated in the same way as the univariate case, either by using a maximum (conditional) likelihood or maximum a posteriori estimation principle. For example, given a linear logistic representation for P (y i |x i , \u03b8), we use an analogous linear logistic representation for P (y i y j |x i x j , \u03c6) but over the joint feature space x i x j ; thus training the two models under the same estimation principle, but using different (although related) data sets.", "publication_ref": ["b1", "b3", "b6", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "Training a Coordination Classifier", "text": "A coordination model learned in this way will generally not make independent predictions of y i and y j , since the extended parameters \u03c6 are not constrained to enforce independence. 1 That is, we expect the model to learn to make dependent, coordinated predictions of the two labels from the corresponding input patterns. Interestingly, learning a coordination classifier has the advantage of potentially squaring the number of available training examples, even though this advantage is mitigated by subsampling and the increase in the complexity of the model being learned.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Classifying Test Data with Coordination", "text": "Given a coordination classifier, we require a principle for classifying individual test patterns x * . In fact, the problem of classifying test patterns becomes much more involved in this case. The approach we take is to consider the set of training examples (x 1 , y 1 ), ..., (x n , y n ) and test patterns x * 1 , ..., x * m as a whole. That is, rather than classify each test pattern x * i in isolation, we instead seek to classify test patterns in a dependent manner. To perform classification, we proceed in three stages reminiscent of conditional random fields: First, we construct a graph over the test and training labels. Once the graph has been constructed, we then use the learned coordination classifier P (y i y j |x i x j , \u03c6) to assign \"potentials\" to the possible labelings of each edge (y i , y j ). These potentials can then be used to define a Markov random field over test label assignments, thereby establishing a joint probability distribution over the labelings. Finally, we compute a joint labeling y * 1 , ..., y * m of the test examples that maximizes (or at least approximately maximizes) the joint label probability. We describe each of these three steps in more detail below.\nDefining the graph First, to construct the graph, we only consider edges that connect a pair of test labels (y * i , y * j ), or a test label and a training label (y * i , y j ). That is, after training we do not make any further use of edges between training labels.\nTo classify test patterns, the simplest approach, conceptually, is to consider the complete graph that connects each test label y * i to all other test and training labels. However, we have found that it is usually impractical to consider all m((m \u2212 1)/2 + n) test pairs (ignoring duplicate pairs). Therefore, we reduce the number of edges by adding a few restrictions. The natural alternatives we consider below are: (i) connecting each test label only to training labels (which, as we will see, is analogous to standard similarity and kernel based learning methods), (ii) connecting each test label only to other test labels (which, surprisingly, gives the best results in our experiments below), and (iii) connecting each test label to both training and test labels. To further reduce the overall number of edges, we then uniformly subsample edges, subject to these different restrictions.\nDefining the potentials Once a graph has been constructed, we then assign potentials to the configurations of each edge. There are two cases depending on whether the edge connects two test labels, or a test label and a training label.\nFor an edge that connects only two test labels, (y * i , y * j ), we simply assign the potential \u03c8(y * i , y * j ) = P (y * i y * j |x * i x * j , \u03c6) given by the learned coordination classifier.\nFor an edge that connects a test and a training label, (y * i , y j ), we assign a unit potential to the singleton node (y * i ) given by the conditional probability of y * i given y j . That is, we assign\n\u03c8 yj (y * i ) = P (y * i |y j , x * i x j , \u03c6) = P (y * i y j |x * i x j , \u03c6) y P (yy j |x * i x j , \u03c6)\nOnce a potential has been assigned to the singleton (y * i ) we then remove the edge (y * i , y j ) from the graph. Thus, the resulting graph only has edges between test labels, and possibly a combination of singleton potentials on nodes (y * i ) and pairwise potentials on edges (y * i , y * j ). Once all of the potentials have been assigned, we then define a joint probability distribution over node labelings in the same manner as a Markov random field, by taking the product form\nP (y * 1 , ..., y * m ) = 1 Z m i=1 \uf8ee \uf8f0 j \u03c8 y j (y * i ) \uf8f9 \uf8fb \uf8ee \uf8f0 j>i \u03c8(y * i , y * j ) \uf8f9 \uf8fb\nand normalizing by an appropriate constant Z.\nComputing the labeling Finally, given a joint probability distribution defined by the Markov random field, our goal is to compute the joint test pattern labeling that has maximum probability. (Since we are only interested in computing the maximum probability assignment, we can ignore the normalization constant above.) Depending on which edge model we use, there are different implications.\nFirst, assuming model (i) (test labels only connect to training labels), there are no pairwise potentials and the Markov random field becomes completely factored. In this case, computing the maximum probability assignment is easy and can be determined independently for each test pattern. Essentially, removing test-test edges reduces our technique to a classical method in which each test pattern is classified independently. Here the learned coordination model In an iid setting, the true test labels y 1 and y 2 are independent given the true conditional model. However, they are not independent given a learned estimate of the model.\nP (y * i y j |x * i x j , \u03c6\n) plays the role of a generalized similarity measure for classifying y * i in terms of (x 1 , y 1 ), ..., (x n , y n ). The only difference is that the coordination model is learned in an earlier training phase, rather than being fixed beforehand.\nThe remaining cases (ii) and (iii) are more difficult because they introduce edges between test labels, which causes the labels to become dependent. Surprisingly, we have found that exploiting test label dependence can actually improve classification accuracy, even when the test data is known to be iid. (This is one of the main points of the paper.) For these models, computing the maximum probability assignment is hard, because the graph can contain many loops. To cope with the problem of performing probabilistic inference in a complex graphical model, we use loopy belief propagation to efficiently compute an approximate solution [Murphy et al., 1999]. Below we find this gives adequate results.", "publication_ref": ["b3"], "figure_ref": [], "table_ref": []}, {"heading": "Rationale and Discussion", "text": "Before presenting our experimental results, it is important to explain the rationale behind our technique and suggest why coordinated classification even makes sense in an iid setting.\nGiven the assumption that the training and test data are independent, we are proposing to predict test labels by building a graph, asserting joint potentials over pairs of labels (from a learned coordination classifier), and using belief propagation to make dependent predictions. Why does it make sense to make dependent predictions of iid labels? It turns out that this approach is justified even when taking the independence assumptions into account. Figure 1 illustrates the basic argument. In a standard machine learning setting, it is indeed true that, given the correct model for generating iid data, the label y 1 for an input pattern x 1 is independent of the label y 2 for another pattern x 2 . However, note that this requires knowledge of the correct model (or at least its correct structure), which is rarely the case in classification learning. Instead, given only an estimate of the true model obtained from training data, y 1 and y 2 remain dependent, as Figure 1 clearly shows. That is, in the context of supervised learning it is generally the case that test labels are dependent given a learned model. In fact, it is obvious that supervised learning algorithms correlate the labels on the training data. Our observation is simply that the same principle can also be applied to test data.\nAlthough using a relational technique for an iid problem might still appear awkward, it has a well known precedent in machine learning research: transductive learning [Vapnik, 1998;Zhu et al., 2003]. In transduction, the learner knows the set of test patterns beforehand, and exploits this knowledge to make predictions that are ultimately dependent. In fact, this idea has been exploited in recent approaches to semisupervised learning using Markov random fields [Zhu et al., 2003]. What we are proposing is a general framework for extending standard probabilistic learning algorithms to be transductive in a similar fashion.\nOur method can be further motivated by noting that it is a natural extension of standard ideas in supervised iid classification. As observed, learning a coordination classifier P (y i y j |x i x j , \u03c6) is a natural generalization of learning methods that use a similarity measure k(\nx i , x j ) to classify test examples x * i based on similarities k(x * i , x 1 ), ..., k(x * i , x n )\nto the training patterns. In fact, this corresponds to our graph choice (i) above, which only connects test labels to training labels. Coordination classification extends the standard similarity based approach by first learning how patterns predict dependencies between the labels (using standard methods applied in a novel way), and then correlating test predictions over a graph. Although there has indeed been recent work on learning kernels for classification [Lanckriet et al., 2004], as well as transductive learning with kernels [Xu et al., 2004], thus far these formulations have remained hard to extend and apply in practice.\nAnother interesting view of coordination classification is that it is a novel form of ensemble method. That is, the label for a test pattern x * i is computed by a combination of votes from multiple predictors associated with different test (and training) patterns x ( * ) j . In fact, even remotely connected patterns can influence a classification via belief propagation.\nAs an ensemble method, coordination classification has some useful features. First, it only requires the training of a single base classifier P (y i y j |x i x j , \u03c6), rather than multiple base classifiers trained from perturbed data. Second, as with boosting and bagging, coordination classification increases the representational capacity of an original (univariate) classifier. That is, given a classifier representation for a single label P (y i |x i , \u03b8), as mentioned previously, a coordination classifier P (y i y j |x i x j , \u03c6) doubles the number of input features and squares the number of output classes. In addition, the prediction of a test label can, in principle, depend on all training and test patterns. Of course, simply increasing the representational capacity of a base classifier increases the risk of overfitting. However, the advantage of ensemble methods is that the resulting classifier, although more complex, is \"smoothed\" by a principled form of model combination, which helps avoid overfitting while exploiting added representational complexity. That is, the process of model combination can be used to reduce the variance of the learned predictor. In our case, we base our model combination principle on inference in a Markov random field. We will see below that, in fact, coordination classification is competitive as an ensemble technique.\nThe biggest drawback of coordination classification is the need to perform probabilistic inference (via loopy belief propagation) in order to label test instances. However, we have still found the method to be robust to approximations, like running only a single iteration of loopy belief propagation, or even just taking local votes or products.", "publication_ref": ["b7", "b7", "b3", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Results", "text": "We implemented the proposed coordination classification technique for a few different forms of probabilistic classifiers and using various standard iid data sets. Our intent was to determine whether the approach indeed had merit and was also robust to alterations in classifiers and data sets. Our experiments were conducted on standard two-class benchmark data sets from the UCI repository. The data sets used were: 1. australian, 2. breast, 3. chess, 4. cleve, 5. corral, 6. crx, 7. diabetes, 8. flare, 9. german, 10. glass2, 11. heart, 12. hepatitis, 13. mofn-3-7, 14. pima, and 15. vote. All of our experimental results were obtained by 5-fold cross validation, repeated 10 times for different randomizations of the graph structures. The tables and plots report averages of these results, with standard deviations included in the tables.\nTable 1 and Figure 2 show the results of our first experiment. In this case, we implemented a standard logistic regression model, using unaltered input features, to learn a base coordination classifier P (y i y j |x i x j , \u03c6). Classification was performed by running loopy belief propagation until the test labels stabilized (usually after 2 to 8 iterations). In the first experiment we used a graph over test labels only, to determine whether introducing label dependency would have any beneficial effect (see \"edge\" results). Here we subsampled test-test edges uniformly at random for an overall density of 18 edges per test example. Table 1 and Figure 2 show the resulting misclassification error obtained by coordination classification in comparison to learning a standard logistic regression model, P (y i |x i , \u03b8). Here we see a notable reduction in overall misclassification error (19%\u219216%), with a significant improvement on some data sets (Breast, -10%, Diabetes, -6%, MofN, -11%, Pima, -6%), and a minor increase on two data sets (Cleve, +1%, and Corral, +1%).\nTable 1 also compares the error of coordination classification to boosting the base logistic regression model P (y i |x i , \u03b8). Here we used 18 rounds of Adaboost [Freund and Schapire, 1996;1997], thereby combining approximately the same number of votes per test pattern as coordination classification. This experiment shows that as an ensemble method, coordination classification performs competitively in this case. An advantage of coordination classification is that it only needs to learn a single base classifier, as opposed to the multiple training episodes required by boosting. The need to run loopy belief propagation on the output labels is a disadvantage however.\nTo investigate the robustness of the method, we repeated the previous experiments using a different base classifier. Table 2 and Figure 3 show the results of an experiment using naive Bayes instead of logistic regression as the base classification method. Here the results are not as strong as the first case we tried, although they are still credible. Note that boosting obtains a few larger improvements, but also larger losses. Classification coordination appears to be fairly stable.      The above experiments were run using only edges between test labels. To compare to standard approaches for iid data, we repeated the experiments using only edges between test and training labels, hence decoupling the test labels and eliminating the need for belief propagation (as discussed in Section 2.2). In this case, test labels are predicted independently. Table 3 and Figure 4 (top) still show, however, that this approach generally improves the base logistic regression classifier P (y i |x i , \u03b8) (see \"node\" results). We conclude that correlating the test labels appears to be a beneficial idea, even in an iid setting. The marginal improvement of label dependence, although positive, might be secondary to the benefit of learning a similarity measure.\nAll of the previous results were obtained by subsampling edges at a density of 18 edges per test label. To test the sensitivity of our results to the edge density, we repeated the first experiment (test-test edges) using different edge densities. Figure 5 shows that the performance of coordination classification does not appear to be sensitive to edge density.\nFinally, we experimented with the combined edge approach (iii) which randomly mixed test-test edges and testtrain edges yielding the results of Table 3 and Figure 4 (bottom). The results in this case do not appear to surpass the performance of using test only edges (see \"mix\" results).", "publication_ref": ["b1", "b1"], "figure_ref": ["fig_3", "fig_3", "fig_5", "fig_7", "fig_8"], "table_ref": ["tab_0", "tab_0", "tab_0", "tab_2", "tab_2"]}, {"heading": "Extensions", "text": "All of our results so far have involved probabilistic classifiers whose output is a conditional distribution over the label y given the input pattern x. Of course, many of the most important classification learning technologies, such as decision trees and support vector machines do not naturally produce probabilistic classifications over the class label (although they can be extended in various ways to do this [Platt, 2000]). This raises the obvious question of generalizing our technique to consider nonprobabilistic classifiers.\nIt is always possible to extend a classification learning method to learn to predict label pairs (y i , y j ) given paired input patterns (x i , x j ). The difficulty is combining several paired predictions to render a sensible classification for a single test pattern. A convenient way to do this would be to convert the predicted outputs to nonnegative potentials over labelings. However, rather than do this, we tried the simpler alternative of combining pair classifications by a simple vote to classify a single test pattern x * i . This is a less powerful combination method than loopy belief propagation, but requires fewer extensions to existing methods to test the coordination classifier idea in these cases.\nTo test this simple idea, we conducted an experiment on the same UCI data using a neural network classifier. Specifically we used a feedforward neural network with one hidden layer and logistic activation functions. The base neural network used one output unit, whereas the pairwise neural network used four output units (two units to indicate the class of each of the two input vectors) and double the number of input units. In each case the number of hidden units was set to 20, subject to the constraint that (n in + n out ) \u00d7 n hidden \u2264 train size/2. We trained the networks to minimize cross entropy error using the quasi-Newton method from Netlab    Once a pairwise neural network classifier was learned, we classified test examples according to the previous \"edge\" model, again by building a random graph between test labels (using an average of 18 edges per test label as before), using the learned coordination neural network to make hard predictions for each edge, and then combining the edge predictions using a simple vote to classify each test example. Table 4 (\"edge\") and Figure 6 show the results of this experiment. Surprisingly, we still obtain a slight overall reduction in misclassification error over the base level neural network classifier, while again competing well against boosting.\nAlthough encouraging, our results are not as positive in every case. We also conducted a simple experiment with decision trees [Quinlan, 1993] as the base coordination classifier, once again combining these predictions with a simple vote to label specific test patterns. Unfortunately, we did not observe an overall improvement over the base decision tree classifier in this case; see Figure 7. This result suggests that a more powerful model combination idea might be required to achieve robust improvements more generally.", "publication_ref": ["b4", "b4"], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "Conclusion", "text": "We have proposed a novel classification learning strategy that coordinates the prediction of test labels on a graph over the data. The coordination classification idea can be used to extend any probabilistic classification approach quite naturally, and even seems to be applicable to nonprobabilistic techniques as well (although more research needs to be done).\nOne insight behind the technique is that making correlated predictions of test labels is justified, even advantageous, in the standard iid setting. This fact has often been overlooked in classification learning, therefore we believe it to be a point worth emphasizing. The ability to learn and predict coordinated test labels, combining them with probabilistic inference, provides a flexible new tool for improving classification accuracy on iid data.  One idea for future work that we are considering is to extend the notion of a pairwise edge classifier to a more general clique classifier. We are also investigating alternative principles for defining potentials on label pairs to see perhaps if there are other combination ideas that work more effectively. Finally, we are also investigating whether combining standard \"single node\" classifiers with our generalized \"edge\" predictors might lead to further accuracy improvements.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "Research supported by the Alberta Ingenuity Centre for Machine Learning, NSERC, MITACS, and the Canada Research Chairs program.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Neural Network Learning: Theoretical Foundations", "journal": "", "year": "1999", "authors": "Anthony ; Bartlett ; M Anthony; P Bartlett"}, {"ref_id": "b1", "title": "A decision-theoretic generalization of on-line learning and an application to boosting", "journal": "", "year": "1996", "authors": "Y Freund; R Schapire; Y Freund; R Schapire ; Friedman"}, {"ref_id": "b2", "title": "Structural extension to logistic regression: Discriminant parameter learning of belief net classifiers", "journal": "", "year": "2002", "authors": " Getoor"}, {"ref_id": "b3", "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "journal": "Springer", "year": "1996", "authors": " Hastie"}, {"ref_id": "b4", "title": "Discriminative probabilistic models for relational data", "journal": "Wiley", "year": "1993", "authors": "; J Platt; ; J Platt;  Quinlan;  Taskar"}, {"ref_id": "b5", "title": "Maximum margin clustering", "journal": "", "year": "2004", "authors": ""}, {"ref_id": "b6", "title": "Kernel logistic regression and the import vector machine", "journal": "", "year": "2001", "authors": "] J Hastie; T Zhu;  Hastie"}, {"ref_id": "b7", "title": "Semi-supervised learning using gaussian fields and harmonic functions", "journal": "", "year": "2003", "authors": ""}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Acoordination classifier doubles the number of input features and squares the number of output classes from an original univariate classifier. Despite the increase in model complexity, training a coordination classifier remains conceptually straightforward. Assume a standard training sample", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure1: In an iid setting, the true test labels y 1 and y 2 are independent given the true conditional model. However, they are not independent given a learned estimate of the model.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 2 :2Figure 2: A comparison of average misclassification error on UCI data sets using logistic regression. Top plot: base model versus boosted logistic regression. Bottom plot: base model versus \"edge\"-based coordination classification.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 3 :3Figure 3: A comparison of average misclassification error on UCI data sets using naive Bayes. Top plot: base model versus boosted naive Bayes. Bottom plot: base model versus \"edge\"-based coordination classification.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 4 :4Figure 4: Alternative comparison on UCI data using logistic regression. Top plot: base model versus \"node\"-based coordination classification. Bottom plot: base model versus a mix of \"edge\" and \"node\" based coordination classification.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 5 :5Figure 5: Average misclassification error of \"edge\"-based coordination classification using logistic regression, comparing different ratios of edges to the number of test patterns.", "figure_data": ""}, {"figure_label": "67", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Figure 6 :Figure 7 :67Figure 6: A comparison of average misclassification error on UCI data sets using a neural network. Top plot: base model versus boosted neural network. Bottom plot: base model versus \"edge\"-based coordination classification.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "A comparison of average misclassification error (%) on UCI data using logistic regression as a base model. \u2206 = average improvement over base. base boosted \u2206 \u00b1 std edge \u2206 \u00b1 std australian 15.1 14.5 -0.6\u00b1 0.4 14.2", "figure_data": "-0.9\u00b1 0.9"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "A comparison of average misclassification error (%) on UCI data using naive Bayes as a base model. \u2206 = average improvement over base.", "figure_data": "base boosted \u2206 \u00b1 std edge \u2206 \u00b1 stdaustralian 13.8 16.22.4\u00b1 1.6 14.20.4\u00b1 0.4breast2.65.02.4\u00b1 1.12.70.1\u00b1 0.1chess20.18.2 -11.9\u00b1 3.1 19.1-1.0\u00b1 0.6cleve16.3 17.00.7\u00b1 0.4 16.40.1\u00b1 0.2corral13.6 13.60\u00b1 5.5 14.20.6\u00b1 0.7crx14.6 16.62.0\u00b1 0.9 14.4-0.2\u00b1 0.2diabetes22.6 22.60\u00b1 0.0 22.60\u00b1 0.2flare16.8 16.7-0.1\u00b1 0.1 17.00.2\u00b1 0.4german25.5 26.30.8\u00b1 0.7 25.1-0.4\u00b1 0.6glass215.6 11.9-3.7\u00b1 1.2 13.9-1.7\u00b1 1.2heart15.9 17.01.1\u00b1 1.3 16.10.2\u00b1 0.2hepatitis13.8 15.01.2\u00b1 6.19.3-4.5\u00b1 1.2mofn-3-7 14.20.0 -14.2\u00b1 0.61.0 -13.2\u00b1 0.8pima21.8 21.7-0.1\u00b1 0.1 22.20.4\u00b1 0.4vote9.95.5-4.4\u00b1 1.89.8-0.1\u00b1 0.2average15.8 14.2-1.6\u00b1 1.6 14.5"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Alternative comparison of average error (%) on UCI data using logistic regression as a base model. \u2206 = average improvement over base. base node \u2206 \u00b1 std mix \u2206 \u00b1 std australian 15.1 14.1", "figure_data": "-1.0\u00b1 0.9 14.2 -0.9\u00b1 0.9breast14.53.8 -10.7\u00b1 2.43.8 -10.7\u00b1 2.5chess7.68.10.5\u00b1 0.37.90.3\u00b1 0.2cleve15.3 16.61.3\u00b1 1.3 16.81.5\u00b1 1.4corral8.8 11.22.4\u00b1 1.2 10.31.5\u00b1 0.8crx16.5 14.9-1.6\u00b1 0.8 14.7 -1.8\u00b1 0.9diabetes31.2 24.7-6.5\u00b1 1.3 24.9 -6.3\u00b1 1.3flare17.4 17.60.2\u00b1 1.2 17.80.4\u00b1 1.1german25.8 24.7-1.1\u00b1 0.9 24.8 -1.0\u00b1 0.9glass229.4 29.70.3\u00b1 5.0 29.40\u00b1 4.6heart16.3 15.7-0.6\u00b1 2.0 15.9 -0.4\u00b1 1.8hepatitis17.5 15.0-2.5\u00b1 3.4 14.0 -3.5\u00b1 2.8mofn-3-7 28.6 25.1-3.5\u00b1 0.2 23.6 -5.0\u00b1 0.4pima30.9 25.1-5.8\u00b1 0.8 24.5 -6.4\u00b1 1.0vote6.76.0-0.7\u00b1 0.85.9 -0.8\u00b1 0.7average18.8 16.8-2.0\u00b1 1.5 16.6 -2."}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "A comparison of average misclassification error (%) on UCI data using a neural network as a base model. \u2206 = average improvement over base. base boosted \u2206 \u00b1 std edge \u2206 \u00b1 std australian 19.3 16.5 -2.8\u00b1 0.7 15.4", "figure_data": "-3.9\u00b1 0.4"}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u03c8 yj (y * i ) = P (y * i |y j , x * i x j , \u03c6) = P (y * i y j |x * i x j , \u03c6) y P (yy j |x * i x j , \u03c6)", "formula_coordinates": [3.0, 55.29, 344.5, 239.21, 25.45]}, {"formula_id": "formula_1", "formula_text": "P (y * 1 , ..., y * m ) = 1 Z m i=1 \uf8ee \uf8f0 j \u03c8 y j (y * i ) \uf8f9 \uf8fb \uf8ee \uf8f0 j>i \u03c8(y * i , y * j ) \uf8f9 \uf8fb", "formula_coordinates": [3.0, 55.77, 481.03, 239.46, 35.87]}, {"formula_id": "formula_2", "formula_text": "P (y * i y j |x * i x j , \u03c6", "formula_coordinates": [3.0, 315.0, 229.32, 63.52, 11.5]}, {"formula_id": "formula_3", "formula_text": "x i , x j ) to classify test examples x * i based on similarities k(x * i , x 1 ), ..., k(x * i , x n )", "formula_coordinates": [4.0, 54.0, 223.57, 242.94, 22.45]}], "doi": ""}