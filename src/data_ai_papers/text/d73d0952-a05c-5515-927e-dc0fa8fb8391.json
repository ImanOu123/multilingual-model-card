{"title": "Semantic Taxonomy Induction from Heterogenous Evidence", "authors": "Rion Snow; Daniel Jurafsky; Andrew Y Ng", "pub_date": "", "abstract": "We propose a novel algorithm for inducing semantic taxonomies. Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns. By contrast, our algorithm flexibly incorporates evidence from multiple classifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a word's coordinate terms to help in determining its hypernyms, and vice versa. We apply our algorithm on the problem of sense-disambiguated noun hyponym acquisition, where we combine the predictions of hypernym and coordinate term classifiers with the knowledge in a preexisting semantic taxonomy (WordNet 2.1). We add 10, 000 novel synsets to WordNet 2.1 at 84% precision, a relative error reduction of 70% over a non-joint algorithm using the same component classifiers. Finally, we show that a taxonomy built using our algorithm shows a 23% relative F-score improvement over WordNet 2.1 on an independent testset of hypernym pairs.", "sections": [{"heading": "Introduction", "text": "The goal of capturing structured relational knowledge about lexical terms has been the motivating force underlying many projects in lexical acquisition, information extraction, and the construction of semantic taxonomies. Broad-coverage semantic taxonomies such as WordNet (Fellbaum, 1998) and CYC (Lenat, 1995) have been constructed by hand at great cost; while a crucial source of knowledge about the relations between words, these taxonomies still suffer from sparse coverage.\nMany algorithms with the potential for automatically extending lexical resources have been proposed, including work in lexical acquisition (Riloff and Shepherd, 1997;Roark and Charniak, 1998) and in discovering instances, named entities, and alternate glosses (Etzioni et al., 2005;Pas\u00e7a, 2005). Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hyponyms (Hearst, 1992), meronyms (Girju, 2003), synonyms (Lin et al., 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al., 2003). Such classifiers use hand-written or automaticallyinduced patterns like Such N P y as N P x or N P y like N P x to determine, for example that N P y is a hyponym of N P x (i.e., N P y IS-A N P x ). While such classifiers have achieved some degree of success, they frequently lack the global knowledge necessary to integrate their predictions into a complex taxonomy with multiple relations.\nPast work on semantic taxonomy induction includes the noun hypernym hierarchy created in (Caraballo, 2001), the part-whole taxonomies in (Girju, 2003), and a great deal of recent work described in (Buitelaar et al., 2005). Such work has typically either focused on only inferring small taxonomies over a single relation, or as in (Caraballo, 2001), has used evidence for multiple relations independently from one another, by for example first focusing strictly on inferring clusters of coordinate terms, and then by inferring hypernyms over those clusters.\nAnother major shortfall in previous techniques for taxonomy induction has been the inability to handle lexical ambiguity. Previous approaches have typically sidestepped the issue of polysemy altogether by making the assumption of only a single sense per word, and inferring taxonomies explicitly over words and not senses. Enforcing a false monosemy has the downside of making potentially erroneous inferences; for example, collapsing the polysemous term Bush into a single sense might lead one to infer by transitivity that a rose bush is a kind of U.S. president.\nOur approach simultaneously provides a solution to the problems of jointly considering evidence about multiple relationships as well as lexical ambiguity within a single probabilistic framework. The key contribution of this work is to offer a solution to two crucial problems in taxonomy in-duction and hyponym acquisition: the problem of combining heterogenous sources of evidence in a flexible way, and the problem of correctly identifying the appropriate word sense of each new word added to the taxonomy. 1", "publication_ref": ["b7", "b12", "b17", "b18", "b6", "b15", "b10", "b8", "b14", "b4", "b20", "b1", "b8", "b0", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "A Probabilistic Framework for Taxonomy Induction", "text": "In section 2.1 we introduce our definitions for taxonomies, relations, and the taxonomic constraints that enforce dependencies between relations; in section 2.2 we give a probabilistic model for defining the conditional probability of a set of relational evidence given a taxonomy; in section 2.3 we formulate a local search algorithm to find the taxonomy maximizing this conditional probability; and in section 2.4 we extend our framework to deal with lexical ambiguity.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Taxonomies, Relations, and Taxonomic Constraints", "text": "We define a taxonomy T as a set of pairwise relations R over some domain of objects D T . For example, the relations in WordNet include hypernymy, holonymy, verb entailment, and many others; the objects of WordNet between which these relations hold are its word senses or synsets. We define that each relation R \u2208 R is a set of ordered or unordered pairs of objects (i, j) \u2208 D T ; we define R ij \u2208 T if relationship R holds over objects (i, j) in T.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Relations for Hyponym Acquisition", "text": "For the case of hyponym acquisition, the objects in our taxonomy are WordNet synsets. In this paper we focus on two of the many possible relationships between senses: the hypernym relation and the coordinate term relation. We treat the hypernym or ISA relation as atomic; we use the notation H n ij if a sense j is the n-th ancestor of a sense i in the hypernym hierarchy. We will simply use H ij to indicate that j is an ancestor of i at some unspecified level. Two senses are typically considered to be \"coordinate terms\" or \"taxonomic sisters\" if they share an immediate parent in the hypernym hierarchy. We generalize this notion of siblinghood to state that two senses i and j are (m, n)-cousins if their closest least common subsumer (LCS) 2 is within exactly m and n links, respectively. 3 We use the notation C mn ij to denote that i and j are (m, n)-cousins. Thus coordinate terms are (1, 1)-cousins; technically the hypernym relation may also be seen as a specific case of this representation; an immediate parent in the hypernym hierarchy is a (1, 0)-cousin, and the k-th ancestor is a (k, 0)-cousin.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Taxonomic Constraints", "text": "A semantic taxonomy such as WordNet enforces certain taxonomic constraints which disallow particular taxonomies T. For example, the ISA transitivity constraint in WordNet requires that each synset inherits the hypernyms of its hypernym, and the part-inheritance constraint requires that each synset inherits the meronyms of its hypernyms.\nFor the case of hyponym acquisition we enforce the following two taxonomic constraints on the hypernym and (m, n)-cousin relations:\n1. ISA Transitivity:\nH m ij \u2227 H n jk \u21d2 H m+n ik .\n2. Definition of (m, n)-cousinhood:\nC mn ij \u21d4 \u2203k.k = LCS(i, j) \u2227 H m ik \u2227 H n jk .\nConstraint (1) requires that the each synset inherits the hypernyms of its direct hypernym; constraint (2) simply defines the (m, n)-cousin relation in terms of the atomic hypernym relation. The addition of any new hypernym relation to a preexisting taxonomy will usually necessitate the addition of a set of other novel relations as implied by the taxonomic constraints. We refer to the full set of novel relations implied by a new link R ij as I(R ij ); we discuss the efficient computation of the set of implied links for the purpose of hyponym acquisition in Section 3.4.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Probabilistic Formulation", "text": "We propose that the event R ij \u2208 T has some prior probability P (R ij \u2208 T), and P (R ij \u2208 T) + P (R ij \u2208 T) = 1. We define the probability of the taxonomy as a whole as the joint probability of its component relations; given a partition of all possible relations R = {A, B} where A \u2208 T and B \u2208 T, we define:\nP (T) = P (A \u2208 T, B \u2208 T).\nWe assume that we have some set of observed evidence E consisting of observed features over pairs of objects in some domain D E ; we'll begin with the assumption that our features are over pairs of words, and that the objects in the taxonomy also correspond directly to words. 4 Given a set of features E R ij \u2208 E, we assume we have some model for inferring P (R ij \u2208 T|E R ij ), i.e., the posterior probability of the event R ij \u2208 T given the corresponding evidence E R ij for that relation. For example, evidence for the hypernym relation E H ij might be the set of all observed lexico-syntactic patterns containing i and j in all sentences in some corpus.\nFor simplicity we make the following independence assumptions: first, we assume that each item of observed evidence E R ij is independent of all other observed evidence given the taxonomy T, i.e., P (E|T) = E R ij \u2208E P (E R ij |T). Further, we assume that each item of observed evidence E R ij depends on the taxonomy T only by way of the corresponding relation R ij , i.e.,\nP (E R ij |T) = P (E R ij |R ij \u2208 T) if R ij \u2208 T P (E R ij |R ij \u2208 T) if R ij \u2208 T\nFor example, if our evidence E H ij is a set of observed lexico-syntactic patterns indicative of hypernymy between two words i and j, we assume that whatever dependence the relations in T have on our observations may be explained entirely by dependence on the existence or non-existence of the single hypernym relation H(i, j).\nApplying these two independence assumptions we may express the conditional probability of our evidence given the taxonomy:\nP (E|T) = R ij \u2208T P (E R ij |R ij \u2208 T) \u2022 R ij \u2208T P (E R ij |R ij \u2208 T).\nRewriting the conditional probability in terms of our estimates of the posterior probabilities P (R ij |E R ij ) using Bayes Rule, we obtain:\nP (E|T) = R ij \u2208T P (R ij \u2208 T|E R ij )P (E R ij ) P (R ij \u2208 T) \u2022 R ij \u2208T P (R ij \u2208 T|E R ij )P (E R ij ) P (R ij \u2208 T)\n.\nWithin our model we define the goal of taxonomy induction to be to find the taxonomyT that maximizes the conditional probability of our observations E given the relationships of T, i.e., to findT = arg max T P (E|T).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Local Search Over Taxonomies", "text": "We propose a search algorithm for findingT for the case of hyponym acquisition. We assume we begin with some initial (possibly empty) taxonomy T. We restrict our consideration of possible new taxonomies to those created by the single operation ADD-RELATION(R ij , T), which adds the single relation R ij to T.\nWe define the multiplicative change \u2206 T (R ij ) to the conditional probability P (E|T) given the addition of a single relation R ij :\n\u2206 T (R ij ) = P (E|T )/P (E|T) = P (R ij \u2208 T|E R ij )P (E R ij ) P (R ij \u2208 T|E R ij )P (E R ij ) \u2022 P (R ij \u2208 T) P (R ij \u2208 T) = k \uf8eb \uf8ed P R ij \u2208 T|E R ij 1 \u2212 P R ij \u2208 T|E R ij \uf8f6 \uf8f8 .\nHere k is the inverse odds of the prior on the event R ij \u2208 T; we consider this to be a constant independent of i, j, and the taxonomy T.\nTo enforce the taxonomic constraints in T, for each application of the ADD-RELATION operator we must add all new relations in the implied set I(R ij ) not already in T. 5 Thus we define the multiplicative change of the full set of implied relations as the product over all new relations:\n\u2206 T (I(R ij )) = R\u2208I(R ij ) \u2206 T (R).\nThis definition leads to the following best-first search algorithm for hyponym acquisition, which at each iteration defines the new taxonomy as the union of the previous taxonomy T and the set of novel relations implied by the relation R ij that maximizes \u2206 T (I(R ij )) and thus maximizes the conditional probability of the evidence over all possible single relations:\nWHILE max R ij \u2208T \u2206 T (I(R ij )) > 1 T \u2190 T \u222a I(arg max R ij \u2208T \u2206 T (I(R ij ))).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Extending the Model to Manage Lexical Ambiguity", "text": "Since word senses are not directly observable, if the objects in the taxonomy are word senses (as in WordNet), we must extend our model to allow for a many-to-many mapping (e.g., a word-to-sense mapping) between D E and D T . For this setting we assume we know the function senses(i), mapping from the word i to all of i s possible corresponding senses. We assume that each set of word-pair evidence E R ij we possess is in fact sense-pair evidence E R kl for a specific pair of senses k 0 \u2208 senses(i), l 0 \u2208 senses(j). Further, we assume that a new relation between two words is probable only between the correct sense pair, i.e.:\nP (R kl |E R ij ) = 1{k = k 0 , l = l 0 } \u2022 P (R ij |E R ij ).\nWhen computing the conditional probability of a specific new relation R kl \u2208 I(R ab ), we assume that the relevant sense pair k 0 , l 0 is the one which maximizes the probability of the new relation, i.e. for k \u2208 senses(i), l \u2208 senses(j),\n(k 0 , l 0 ) = arg max k,l P (R kl \u2208 T|E R ij ).\nOur independence assumptions for this extension need only to be changed slightly; we now assume that the evidence E R ij depends on the taxonomy T via only a single relation between sensepairs R kl . Using this revised independence assumption the derivation for best-first search over taxonomies for hyponym acquisition remains unchanged. One side effect of this revised independence assumption is that the addition of the single \"sense-collapsed\" relation R kl in the taxonomy T will explain the evidence E R ij for the relation over words i and j now that such evidence has been revealed to concern only the specific senses k and l.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Extending WordNet", "text": "We demonstrate the ability of our model to use evidence from multiple relations to extend Word-Net with novel noun hyponyms. While in principle we could use any number of relations, for simplicity we consider two primary sources of evidence: the probability of two words in WordNet being in a hypernym relation, and the probability of two words in WordNet being in a coordinate relation.\nIn sections 3.1 and 3.2 we describe the construction of our hypernym and coordinate classifiers, respectively; in section 3.3 we outline the efficient algorithm we use to perform local search over hyponym-extended WordNets; and in section 3.4 we give an example of the implicit structure-based word sense disambiguation performed within our framework.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Hyponym Classification", "text": "Our classifier for the hypernym relation is derived from the \"hypernym-only\" classifier described in (Snow et al., 2005). The features used for predicting the hypernym relationship are obtained by parsing a large corpus of newswire and encyclopedia text with MINIPAR (Lin, 1998). From the resulting dependency trees the evidence E H ij for each word pair (i, j) is constructed; the evidence takes the form of a vector of counts of occurrences that each labeled syntactic dependency path was found as the shortest path connecting i and j in some dependency tree. ) is then trained using logistic regression, predicting the noun-pair hypernymy label from WordNet from the feature vector of lexico-syntactic patterns.\nThe hypernym classifier described above predicts the probability of the generalized hypernymancestor relation over words P (H ij |E H ij ). For the purposes of taxonomy induction, we would prefer an ancestor-distance specific set of classifiers over senses, i.e., for k \u2208 senses(i), l \u2208 senses(j), the set of classifiers estimating\n{P (H 1 kl |E H ij ), P (H 2 kl |E H ij ), . . . }.\nOne problem that arises from directly assigning the probability P (H n ij |E H ij ) \u221d P (H ij |E H ij ) for all n is the possibility of adding a novel hyponym to an overly-specific hypernym, which might still satisfy P (H n ij |E H ij ) for a very large n. In order to discourage unnecessary overspecification, we penalize each probability P (H k ij |E H ij ) by a factor \u03bb k\u22121 for some \u03bb < 1, and renormalize:\nP (H k ij |E H ij ) \u221d \u03bb k\u22121 P (H ij |E H ij ).\nIn our experiments we set \u03bb = 0.95.", "publication_ref": ["b19", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "(m, n)-cousin Classification", "text": "The classifier for learning coordinate terms relies on the notion of distributional similarity, i.e., the idea that two words with similar meanings will be used in similar contexts (Hindle, 1990). We extend this notion to suggest that words with similar meanings should be near each other in a semantic taxonomy, and in particular will likely share a hypernym as a near parent.\nOur classifier for (m, n)-cousins is derived from the algorithm and corpus given in (Ravichandran et al., 2005). In that work an efficient randomized algorithm is derived for computing clusters of similar nouns. We use a set of more than 1000 distinct clusters of English nouns collected by their algorithm over 70 million webpages 6 , with each noun i having a score representing its cosine similarity to the centroid c of the cluster to which it belongs, cos(\u03b8(i, c)).\nWe use the cluster scores of noun pairs as input to our own algorithm for predicting the (m, n)cousin relationship between the senses of two words i and j. If two words i and j appear in a cluster together, with cluster centroid c, we set our single coordinate input feature to be the minimum cluster score min(cos(\u03b8(i, c)), cos(\u03b8(j, c))), and zero otherwise. For each such noun pair feature, we construct a labeled training set of (m, n)cousin relation labels from WordNet 2.1. We define a noun pair (i, j) to be a \"known (m, n)cousin\" if for some senses k \u2208 senses(i), l \u2208 senses(j), C mn ij \u2208 WordNet; if more than one such relation exists, we assume the relation with smallest sum m + n, breaking ties by smallest absolute difference |m \u2212 n|. We consider all such labeled relationships from WordNet with 0 \u2264 m, n \u2264 7; pairs of words that have no corresponding pair of synsets connected in the hypernym hi-erarchy, or with min(m, n) > 7, are assigned to a single class C \u221e . Further, due to the symmetry of the similarity score, we merge each class C mn = C mn \u222a C nm ; this implies that the resulting classifier will predict, as expected given a symmetric input, P (C mn kl |E C ij ) = P (C nm kl |E C ij ). We find 333,473 noun synset pairs in our training set with similarity score greater than 0.15. We next apply softmax regression to learn a classifier that predicts P (C mn ij |E C ij ), predicting the Word-Net class labels from the single similarity score derived from the noun pair's cluster similarity.", "publication_ref": ["b11"], "figure_ref": [], "table_ref": []}, {"heading": "Details of our Implementation", "text": "Hyponym acquisition is among the simplest and most straightforward of the possible applications of our model; here we show how we efficiently implement our algorithm for this problem. First, we identify the set of all the word pairs (i, j) over which we have hypernym and/or coordinate evidence, and which might represent additions of a novel hyponym to the WordNet 2.1 taxonomy (i.e., that has a known noun hypernym and an unknown hyponym, or has a known noun coordinate term and an unknown coordinate term). This yields a list of 95,000 single links over threshold P (R ij ) > 0.12.\nFor each unknown hyponym i we may have several pieces of evidence; for example, for the unknown term continental we have 21 relevant pieces of hypernym evidence, with links to possible hypernyms {carrier, airline, unit, . . . }; and we have 5 pieces of coordinate evidence, with links to possible coordinate terms {airline, american eagle, airbus, . . . }.\nFor each proposed hypernym or coordinate link involved with the novel hyponym i, we compute the set of candidate hypernyms for i; in practice we consider all senses of the immediate hypernym j for each potential novel hypernym, and all senses of the coordinate term k and its first two hypernym ancestors for each potential coordinate.\nIn the continental example, from the 26 individual pieces of evidence over words we construct the set of 99 unique synsets that we will consider as possible hypernyms; these include the two senses of the word airline, the ten senses of the word carrier, and so forth.\nNext, we iterate through each of the possible hypernym synsets l under which we might add the new word i; for each synset l we com-pute the change in taxonomy score resulting from adding the implied relations I(H 1 il ) required by the taxonomic constraints of T. Since typically our set of all evidence involving i will be much smaller than the set of possible relations in I(H 1 il ), we may efficiently check whether, for each sense s \u2208 senses(w), for all words where we have some evidence E R iw , whether s participates in some relation with i in the set of implied relations I(H 1 il ). 7 If there is more than one sense s \u2208 senses(w), we add to I(H 1 il ) the single relationship R is that maximizes the taxonomy likelihood, i.e. arg max s\u2208senses(w) \u2206 T (R is ).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Hypernym Sense Disambiguation", "text": "A major strength of our model is its ability to correctly choose the sense of a hypernym to which to add a novel hyponym, despite collecting evidence over untagged word pairs. In our algorithm word sense disambiguation is an implicit side-effect of our algorithm; since our algorithm chooses to add the single link which, with its implied links, yields the most likely taxonomy, and since each distinct synset in WordNet has a different immediate neighborhood of relations, our algorithm simply disambiguates each node based on its surrounding structural information.\nAs an example of sense disambiguation in practice, consider our example of continental. Suppose we are iterating through each of the 99 possible synsets under which we might add continental as a hyponym, and we come to the synset airline#n#2 in WordNet 2.1, i.e. \"a commercial organization serving as a common carrier.\" In this case we will iterate through each piece of hypernym and coordinate evidence; we find that the relation H(continental, carrier) is satisfied with high probability for the specific synset carrier#n#5, the grandparent of airline#n#2; thus the factor \u2206 T (H 3 (continental, carrier#n#5)) is included in the factor of the set of implied relations\n\u2206 T I(H 1 (continental, airline#n#2)) .\nSuppose we instead evaluate the first synset of airline, i.e., airline#n#1, with the gloss \"a hose that carries air under pressure.\" For this synset none of the other 20 relationships directly implied by hypernym evidence or the 5 relationships implied by the coordinate ev-7 Checking whether or not R is \u2208 I(H 1 il ) may be efficiently computed by checking whether s is in the hypernym ancestors of l or if it shares a least common subsumer with l within 7 steps. idence are implied by adding the single link H 1 (continental,airline#n#1); thus the resulting change in the set of implied links given by the correct \"carrier\" sense of airline is much higher than that of the \"hose\" sense. In fact it is the largest of all the 99 considered hypernym links for continental; H 1 (continental, airline#n#2) is link #18,736 added to the taxonomy by our algorithm.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Evaluation", "text": "In order to evaluate our framework for taxonomy induction, we have applied hyponym acquisition to construct several distinct taxonomies, starting with the base of WordNet 2.1 and only adding novel noun hyponyms. Further, we have constructed taxonomies using a baseline algorithm, which uses the identical hypernym and coordinate classifiers used in our joint algorithm, but which does not combine the evidence of the classifiers.\nIn section 4.1 we describe our evaluation methodology; in sections 4.2 and 4.3 we analyze the fine-grained precision and disambiguation precision of our algorithm compared to the baseline; in section 4.4 we compare the coarse-grained precision of our links (motivated by categories defined by the WordNet supersenses) against the baseline algorithm and against an \"oracle\" for named entity recognition.\nFinally, in section 4.5 we evaluate the taxonomies inferred by our algorithm directly against the WordNet 2.1 taxonomy; we perform this evaluation by testing each taxonomy on a set of human judgments of hypernym and non-hypernym noun pairs sampled from newswire text.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Methodology", "text": "We evaluate the quality of our acquired hyponyms by direct judgment.\nIn four separate annotation sessions, two judges labeled {50,100,100,100} samples uniformly generated from the first {100,1000,10000,20000} single links added by our algorithm.\nFor the direct measure of fine-grained precision, we simply ask for each link H(X, Y ) added by the system, is X a Y ? In addition to the fine-grained precision, we give a coarse-grained evaluation, inspired by the idea of supersense-tagging in (Ciaramita and Johnson, 2003). The 26 supersenses used in WordNet 2.1 are listed in Table 1; we label a hyponym link as correct in the coarse-grained evaluation if the novel hyponym is placed under the appropriate supersense. This evaluation task    A single hyponym/hypernym pair is allowed to be simultaneously labeled 2 and 3.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "Fine-grained evaluation", "text": "Table 2 displays the results of our evaluation of fine-grained precision for the baseline non-joint algorithm (Base) and our joint algorithm (Joint), as well as the relative error reduction (ER) of our algorithm over the baseline. We use the minimum of the two judges' scores. Here we define fine-grained precision as c 1 /total. We see that our joint algorithm strongly outperforms the baseline, and has high precision for predicting novel hyponyms up to 10,000 links.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "Hypernym sense disambiguation", "text": "Also in Table 2 we compare the sense disambiguation precision of our algorithm and the baseline. Here we measure the precision of sense-disambiguation among all examples where each algorithm found a correct hyponym word; our calculation for disambiguation precision is c 1 / (c 1 + c 2 ). Again our joint algorithm outperforms the baseline algorithm at all levels of recall. Interestingly the baseline disambiguation precision improves with higher recall; this may   ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "Coarse-grained evaluation", "text": "We compute coarse-grained precision as (c 1 + c 3 )/total. Inferring the correct coarse-grained supersense of a novel hyponym can be viewed as a fine-grained (26-category) Named Entity Recognition task; our algorithm for taxonomy induction can thus be viewed as performing high-accuracy fine-grained NER. Here we compare against both the baseline non-joint algorithm as well as an \"oracle\" algorithm for Named Entity Recognition, which perfectly classifies the supersense of all nouns that fall under the four supersenses {person, group, location, quantity}, but works only for those supersenses. Table 3 shows the results of this coarse-grained evaluation. We see that the baseline non-joint algorithm has higher precision than the NER oracle as 10,000 and 20,000 links; however, both are significantly outperformed by our joint algorithm, which maintains high coarse-grained precision (92%) even at 20,000 links.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_5"]}, {"heading": "Comparison of inferred taxonomies and WordNet", "text": "For our final evaluation we compare our learned taxonomies directly against the currently existing hypernym links in WordNet 2.1. In order to compare taxonomies we use a hand-labeled test WN +10K +20K +30K +40K PRE 0.524 0.524 0.574 0.583 0.571 REC 0.165 0.165 0.203 0.211 0.211 F 0.251 0.251 0.300 0.309 0.307  (Snow et al., 2005)). We measured the performance of both our inferred taxonomies and WordNet against this test set. 8 The performance and comparison of the best WordNet classifier vs. our taxonomies is given in Table 4. Our best-performing inferred taxonomy on this test set is achieved after adding 30,000 novel hyponyms, achieving an 23% relative improvement in F-score over the WN2.1 classifier.", "publication_ref": ["b19", "b2"], "figure_ref": [], "table_ref": ["tab_6"]}, {"heading": "Conclusions", "text": "We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.\nOur probabilistic architecture also includes a new model for learning coordinate terms based on (m, n)-cousin classification. The model's ability to integrate heterogeneous evidence from different classifiers offers a solution to the key problem of choosing the correct word sense to which to attach a new hypernym.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "Thanks to Christiane Fellbaum, Rajat Raina, Bill  MacCartney, and   ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Ontology Learning from Text: Methods, Evaluation and Applications", "journal": "", "year": "2005", "authors": "P Buitelaar; P Cimiano; B Magnini"}, {"ref_id": "b1", "title": "Automatic Acquisition of a Hypernym-Labeled Noun Hierarchy from Text", "journal": "", "year": "2001", "authors": "S Caraballo"}, {"ref_id": "b2", "title": "We found that the WordNet 2.1 model achieving the highest F-score used only the first sense of each hyponym", "journal": "", "year": "", "authors": ""}, {"ref_id": "b3", "title": "Using LSA and Noun Coordination Information to Improve the Precision and Recall of Automatic Hyponymy Extraction", "journal": "", "year": "2003", "authors": "S Cederberg; D Widdows"}, {"ref_id": "b4", "title": "VerbOcean: Mining the Web for Fine-Grained Semantic Verb Relations", "journal": "", "year": "2004", "authors": "T Chklovski; P Pantel"}, {"ref_id": "b5", "title": "Supersense Tagging of Unknown Nouns in WordNet", "journal": "", "year": "2003", "authors": "M Ciaramita; M Johnson"}, {"ref_id": "b6", "title": "Unsupervised Named-Entity Extraction from the Web: An Experimental Study", "journal": "Artificial Intelligence", "year": "2005", "authors": "O Etzioni; M Cafarella; D Downey; A Popescu; T Shaked; S Soderland; D Weld; A Yates"}, {"ref_id": "b7", "title": "WordNet: An Electronic Lexical Database", "journal": "MIT Press", "year": "1998", "authors": "C Fellbaum"}, {"ref_id": "b8", "title": "Learning Semantic Constraints for the Automatic Discovery of Part-Whole Relations", "journal": "", "year": "2003", "authors": "R Girju; A Badulescu; D Moldovan"}, {"ref_id": "b9", "title": "Fine grained classification of named entities", "journal": "", "year": "2002", "authors": "M Fleischman; E Hovy"}, {"ref_id": "b10", "title": "Automatic Acquisition of Hyponyms from Large Text Corpora", "journal": "", "year": "1992", "authors": "M Hearst"}, {"ref_id": "b11", "title": "Noun classification from predicateargument structures", "journal": "", "year": "1990", "authors": "D Hindle"}, {"ref_id": "b12", "title": "CYC: A Large-Scale Investment in Knowledge Infrastructure", "journal": "Communications of the ACM", "year": "1995", "authors": "D Lenat"}, {"ref_id": "b13", "title": "Dependency-based Evaluation of MINI-PAR", "journal": "", "year": "1998", "authors": "D Lin"}, {"ref_id": "b14", "title": "Identifying Synonyms among Distributionally Similar Words", "journal": "", "year": "2003", "authors": "D Lin; S Zhao; L Qin; M Zhou"}, {"ref_id": "b15", "title": "Finding Instance Names and Alternative Glosses on the Web: WordNet Reloaded. CI-CLing", "journal": "", "year": "2005", "authors": "M Pas\u00e7a"}, {"ref_id": "b16", "title": "Randomized Algorithms and NLP: Using Locality Sensitive Hash Function for High Speed Noun Clustering", "journal": "", "year": "2002", "authors": "D Ravichandran; P Pantel; E Hovy"}, {"ref_id": "b17", "title": "A Corpus-Based Approach for Building Semantic Lexicons", "journal": "Proc EMNLP", "year": "1997", "authors": "E Riloff; J Shepherd"}, {"ref_id": "b18", "title": "Noun-phrase cooccurerence statistics for semi-automatic-semantic lexicon construction", "journal": "", "year": "1998", "authors": "B Roark; E Charniak"}, {"ref_id": "b19", "title": "Learning syntactic patterns for automatic hypernym discovery", "journal": "", "year": "2005", "authors": "R Snow; D Jurafsky; A Y Ng"}, {"ref_id": "b20", "title": "Combining independent modules to solve multiple-choice synonym and analogy problems", "journal": "", "year": "2003", "authors": "P Turney; M Littman; J Bigham; V Shnayder"}], "figures": [{"figure_label": "3", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "c 3 :3Incorrect hypernym, but correct supersense.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "c 4 :4Any other relation is considered incorrect.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "The labeled training set is constructed by labeling the collected feature vectors as positive \"known hypernym\" or negative \"known non-hypernym\" examples using WordNet 2.0; 49,922 feature vectors were labeled as positive training examples, and 800,828 noun pairs were labeled as negative training examples. The model for predicting P (H ij |E H ij", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "", "figure_data": ": The 26 WordNet supersensesis similar to a fine-grained Named Entity Recog-nition (Fleischman and Hovy, 2002) task with 26categories; for example, if our algorithm mistak-enly inserts a novel non-capital city under the hy-ponym state capital, it will inherit the correct su-persense location. Finally, we evaluate the abil-ity of our algorithm to correctly choose the ap-propriate sense of the hypernym under which anovel hyponym is being added. Our labelers cate-gorize each candidate sense-disambiguated hyper-nym synset suggested by our algorithm into thefollowing categories:c 1 : Correct sense-disambiguated hypernym.c 2 : Correct hypernym word, but incorrect sense ofthat word."}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Fine-grained and disambiguation precision and error reduction for hyponym acquisition", "figure_data": "# LinksNERBase Joint ER vs. ER vs.OracleNERBase1001.000.721.000%100%10000.690.680.9997%85%100000.450.690.9693%70%200000.540.690.9283%41%"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "", "figure_data": ": Coarse-grained precision and error reduc-tion vs. Non-joint baseline and NER Oraclebe attributed to the observation that the highest-confidence hypernyms predicted by individualclassifiers are likely to be polysemous, whereashypernyms of lower confidence are more fre-quently monosemous (and thus trivially easy todisambiguate)."}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Taxonomy hypernym classification vs. WordNet 2.1 on hand-labeled testset set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "H m ij \u2227 H n jk \u21d2 H m+n ik .", "formula_coordinates": [2.0, 378.55, 381.53, 97.81, 16.48]}, {"formula_id": "formula_1", "formula_text": "C mn ij \u21d4 \u2203k.k = LCS(i, j) \u2227 H m ik \u2227 H n jk .", "formula_coordinates": [2.0, 335.87, 431.49, 183.17, 15.65]}, {"formula_id": "formula_2", "formula_text": "P (T) = P (A \u2208 T, B \u2208 T).", "formula_coordinates": [3.0, 118.13, 139.89, 126.29, 11.46]}, {"formula_id": "formula_3", "formula_text": "P (E R ij |T) = P (E R ij |R ij \u2208 T) if R ij \u2208 T P (E R ij |R ij \u2208 T) if R ij \u2208 T", "formula_coordinates": [3.0, 77.04, 460.79, 202.29, 29.4]}, {"formula_id": "formula_4", "formula_text": "P (E|T) = R ij \u2208T P (E R ij |R ij \u2208 T) \u2022 R ij \u2208T P (E R ij |R ij \u2208 T).", "formula_coordinates": [3.0, 104.37, 644.25, 153.81, 59.25]}, {"formula_id": "formula_5", "formula_text": "P (E|T) = R ij \u2208T P (R ij \u2208 T|E R ij )P (E R ij ) P (R ij \u2208 T) \u2022 R ij \u2208T P (R ij \u2208 T|E R ij )P (E R ij ) P (R ij \u2208 T)", "formula_coordinates": [3.0, 322.14, 88.78, 184.59, 74.37]}, {"formula_id": "formula_6", "formula_text": "\u2206 T (R ij ) = P (E|T )/P (E|T) = P (R ij \u2208 T|E R ij )P (E R ij ) P (R ij \u2208 T|E R ij )P (E R ij ) \u2022 P (R ij \u2208 T) P (R ij \u2208 T) = k \uf8eb \uf8ed P R ij \u2208 T|E R ij 1 \u2212 P R ij \u2208 T|E R ij \uf8f6 \uf8f8 .", "formula_coordinates": [3.0, 322.71, 439.7, 186.48, 92.41]}, {"formula_id": "formula_7", "formula_text": "\u2206 T (I(R ij )) = R\u2208I(R ij ) \u2206 T (R).", "formula_coordinates": [3.0, 345.78, 679.47, 141.55, 25.49]}, {"formula_id": "formula_8", "formula_text": "WHILE max R ij \u2208T \u2206 T (I(R ij )) > 1 T \u2190 T \u222a I(arg max R ij \u2208T \u2206 T (I(R ij ))).", "formula_coordinates": [4.0, 85.5, 178.84, 191.81, 43.18]}, {"formula_id": "formula_9", "formula_text": "P (R kl |E R ij ) = 1{k = k 0 , l = l 0 } \u2022 P (R ij |E R ij ).", "formula_coordinates": [4.0, 78.02, 461.66, 206.51, 15.57]}, {"formula_id": "formula_10", "formula_text": "(k 0 , l 0 ) = arg max k,l P (R kl \u2208 T|E R ij ).", "formula_coordinates": [4.0, 100.92, 556.64, 160.72, 20.23]}, {"formula_id": "formula_11", "formula_text": "{P (H 1 kl |E H ij ), P (H 2 kl |E H ij ), . . . }.", "formula_coordinates": [4.0, 307.41, 752.36, 145.07, 15.64]}, {"formula_id": "formula_12", "formula_text": "P (H k ij |E H ij ) \u221d \u03bb k\u22121 P (H ij |E H ij ).", "formula_coordinates": [5.0, 72.14, 171.68, 149.75, 15.38]}, {"formula_id": "formula_13", "formula_text": "\u2206 T I(H 1 (continental, airline#n#2)) .", "formula_coordinates": [6.0, 96.09, 617.71, 172.8, 14.04]}], "doi": ""}