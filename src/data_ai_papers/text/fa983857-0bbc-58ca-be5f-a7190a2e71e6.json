{"title": "Building Structure into Local Search for SAT", "authors": "Duc Nghia Pham; John Thornton; Abdul Sattar", "pub_date": "", "abstract": "Local search procedures for solving satisfiability problems have attracted considerable attention since the development of GSAT in 1992. However, recent work indicates that for many real-world problems, complete search methods have the advantage, because modern heuristics are able to effectively exploit problem structure. Indeed, to develop a local search technique that can effectively deal with variable dependencies has been an open challenge since 1997. In this paper we show that local search techniques can effectively exploit information about problem structure producing significant improvements in performance on structured problem instances. Building on the earlier work of Ostrowski et al. we describe how information about variable dependencies can be built into a local search, so that only independent variables are considered for flipping. The cost effect of a flip is then dynamically calculated using a dependency lattice that models dependent variables using gates (specifically and, or and equivalence gates). The experimental study on hard structured benchmark problems demonstrates that our new approach significantly outperforms the previously reported best local search techniques.", "sections": [{"heading": "Introduction", "text": "A fundamental challenge facing local search researchers in the satisfiability (SAT) domain is the increasing scope and performance of complete search methods. While for most of the 1990s it was taken for granted that local search was the most practical method for solving large and complex real world satisfiability problems [Selman et al., 1992;Kautz and Selman, 1996;B\u00e9jar and Many\u00e0, 2000], the latest generation of complete SAT solvers have turned the tables, solving many structured problems that are beyond the reach of local search (e.g. [Zhang et al., 2001;E\u00e9n and Biere, 2005]). 1 So it is of 1 More information on the performance of complete search versus local search is available from the SAT competitions (http://www.satcompetition.org) basic importance to the area that local search techniques learn from the success of the newer complete methods.\nThe current research goes to the core of this problem by modelling problem structure within a local search procedure. This involves a two-part process: firstly problem structure must be recognized within the original problem representation (here we are considering satisfiability problems expressed in conjunctive normal form (CNF)). And secondly this structure must be represented within a local search procedure in such a way that the local neighbourhood of possible moves will only contain structure respecting flips.\nThe ideas behind this approach come from two sources. Firstly, there is the recent work on modelling constraint satisfaction problems (CSPs) as SAT problems . Here the presence of CSP multivalued variables is automatically detected in the clausal structure of a CNF problem. This information is then embedded within a local search in such a way that for each group of binary valued SAT variables corresponding to a single multivalued CSP variable, only one SAT variable will be true at any one time. This enforces that the underlying CSP variable is always instantiated with a single domain value. The SAT-based local search achieves this by doing a two-flip look-ahead whenever it encounters a literal associated with a CSP domain value. In effect this look-ahead turns off the current CSP domain value with one flip and turns on a new value with a second flip. A significant advantage of this approach (when encoding binary CSPs) is that the cost of such a double-flip equals the sum of the costs of the individual flips, because these flip pairs will never appear in the same conflict clause. For this reason, CSP structure exploiting algorithms can be easily embedded within an existing SAT local search architecture and add negligible processing overhead to an individual flip. As we shall see, more general structure exploiting approaches do cause interactions between literals within the same clauses, and so require more sophisticated flip cost calculation procedures.\nThe second source for the current research comes from Ostrowski et al. 's [2002] work on the extraction of gates from CNF encoded SAT problems. These gates represent relationships between SAT variables of the form y = f (x 1 , . . . , x n ) where f \u2208 {\u21d4, \u2227, \u2228} and y and x i are Boolean variables from the original problem. If such a gate is recognized, the value of y is determined by x 1 , . . . , x n , and can be removed. Ostrowski et al. used this method to simplify a range of struc-tured SAT benchmark problems, producing significant performance gains for their systematic DPLL solver. However, to the best of our knowledge, such structure exploiting approaches have not been applied in the local search domain.\nThe problem facing a local search approach to implementing gates is one of efficiency. Ostrowski et al.'s approach can detect independent variables whose values determine a set of dependent variables via clausal gate connections. Using this information, we can implement a local search that only flips the values of independent variables and then dynamically calculates the effects of these flips on the overall solution cost. However, a local search needs to know the flip cost of all candidate flips in advance of making a move. Generally this is achieved by maintaining a make cost and a break cost for each literal in the problem (i.e. the number of clauses that will become true if a literal is flipped and the number of clauses that will become false). These costs are then updated after each flip. A major advantage of a SAT local search is the speed with which these cost effects can be calculated (this is achieved using clever data structures that exploit the SAT CNF problem structure) [Tompkins and Hoos, 2004]. However, taking an approach that only flips independent variables renders the standard SAT local search architecture redundant. In this case, finding the potential cost of an independent variable flip requires us to solve a mini-SAT problem involving all the affected dependent variables and their associated clauses.\nThe rest of the paper is organized as follows: we first explain how the cost of flipping an independent variable in a local search can be efficiently calculated using a dependency lattice data structure. This structure models the various dependencies in the original problem and dynamically calculates which independent variables, when flipped, will cause a clause to change its truth value. Details of the construction and operation of this lattice are given in the next two sections. To evaluate the usefulness of this new approach, we conduct an empirical study that examines several of the structured SAT benchmarks that have proved to be the most difficult for local search in the past. Finally, we discuss the significance of our results and indicate some future directions of research.", "publication_ref": ["b3", "b1", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Gates and Dependencies", "text": "In the following discussion we shall broadly follow the terminology used in [Ostrowski et al., 2002]. Firstly, consider the following CNF formula:\n(\u00aca \u2228 b \u2228 c \u2228 d) \u2227 (a \u2228 \u00acb) \u2227 (a \u2228 \u00acc) \u2227 (a \u2228 \u00acd)\nHere, for the clauses to be satisfied, if b and c and d are all false then a must necessarily be false, otherwise a must necessarily be true. This is an example of an \"or\" gate, because the value of a is determined by truth value of (b \u2228 c \u2228 d) and can be represented as\na = \u2228(b, c, d)\nSimilarly, if we reverse the signs of the literals we get:\n(a \u2228 \u00acb \u2228 \u00acc \u2228 \u00acd) \u2227 (\u00aca \u2228 b) \u2227 (\u00aca \u2228 c) \u2227 (\u00aca \u2228 d)\nNow for the formula to be satisfied, if b and c and d are all true then a must necessarily be true, otherwise a must necessarily be false. This example of an \"and\" gate can be represented as a = \u2227(b, c, d)\nA third commonly occurring clausal structure is the \"equivalence\" gate (or \"xnor\" gate), illustrated as follows:\n(a \u2228 b \u2228 c) \u2227 (\u00aca \u2228 \u00acb \u2228 c) \u2227 (\u00aca \u2228 b \u2228 \u00acc) \u2227 (a \u2228 \u00acb \u2228 \u00acc)\nHere, in order to satisfy the formula, a will be true iff b and c are both true or both false, i.e. if they are equivalent, otherwise if b and c differ then a will be false. This can be represented as a =\u21d4 (b, c) Finally, an \"xor\" gate is the negation of an \"equivalence\" gate, illustrated as follows:\n(\u00aca \u2228 \u00acb \u2228 \u00acc) \u2227 (a \u2228 b \u2228 \u00acc) \u2227 (a \u2228 \u00acb \u2228 c) \u2227 (\u00aca \u2228 b \u2228 c)\nwhere a will only be false if b and c are equivalent. This can be represented as a = \u2295(b, c)\nIf an \"equivalence\" or an \"xor\" gate depends on more than two variables, then equivalence or difference is calculated in a pairwise fashion, i.e. if a =\u21d4 (b, c, d) and b and c are false, then b \u21d4 c is true, and if d is true, then d \u21d4 (b \u21d4 c) is true and therefore the gate is true. In general, we represent an \"xor\" gate as y = \u2295(x 1 , . . . , x n ), an \"equivalence\" gate as y =\u21d4 (x 1 , . . . , x n ), an \"or\" gate as y = \u2228(x 1 , . . . , x n ) and an \"and\" gate as y = \u2227(x 1 , . . . , x n ). Here y is the dependent variable because its value is determined by the independent variables x 1 , . . . , x n . For the sake of simplicity, we treat an \"xor\" gate (e.g. a = \u2295(b, c)) as a special case of an \"equivalence\" gate (e.g. \u00aca =\u21d4 (b, c)) in the rest of the paper.", "publication_ref": ["b4"], "figure_ref": [], "table_ref": []}, {"heading": "The Dependency Lattice", "text": "As Ostrowski et al. [2002] have already described, the process of recognizing gates in a CNF problem can be reduced to searching for the appropriate clausal structures during a preprocessing phase. This information can then be used to classify the dependent and independent variables. For a complete search method, this means the search space can immediately be reduced to only consider independent variable instantiations, as all dependent variable values can be automatically fixed by propagation.\nHowever, for a local search, there is no built-in propagation mechanism. In fact, a local search strategy precludes propagation because it deliberately allows inconsistent assignments to persist. To exploit the information inherent in dependent variable relationships requires us to remove them from the domain of \"free\" variables while still including their effect in the overall cost of a particular flip. To achieve this we have developed a dependency lattice data structure. This lattice is formed as a result of analyzing the original CNF problem into independent variables, and relationships between internal and external gates. Firstly, an independent variable is not simply a variable that determines the value of a dependent variable in a gate relationship, because such determining variables can in turn be determined in another gate. An independent variable is a variable that is never determined in any gate relationship. Secondly, an internal gate is any gate that can be recognized within the structure of the original CNF formula, and thirdly, an external gate is a gate where the dependent variable represents a clause from the original CNF formula that is not part of any internal gate. To clarify these concepts, consider the following CNF formula example:\n(\u00acg 1 \u2228 v 2 \u2228 v 3 ) \u2227 (g 1 \u2228 \u00acv 2 ) \u2227 (g 1 \u2228 \u00acv 3 )\u2227 (g 2 \u2228 \u00acv 3 \u2228 \u00acv 4 ) \u2227 (\u00acg 2 \u2228 v 3 ) \u2227 (\u00acg 2 \u2228 v 4 )\u2227 (g 3 \u2228 g 1 \u2228 g 2 ) \u2227 (\u00acg 3 \u2228 \u00acg 1 \u2228 g 2 )\u2227 (\u00acg 3 \u2228 g 1 \u2228 \u00acg 2 ) \u2227 (g 3 \u2228 \u00acg 1 \u2228 \u00acg 2 )\u2227 (v 1 \u2228 g 1 )\nwhich is equivalent to:\n(g 1 = \u2227(v 2 , v 3 )) \u2227 (g 2 = \u2228(v 3 , v 4 ))\u2227 (g 3 =\u21d4 (v 1 , v 2 )) \u2227 (c 1 = \u2228(v 1 , g 1 ))\nwhere c 1 is an additional variable that depends on the clause\n(v 1 \u2228 g 1 ) (i.e. if (v 1 \u2228 g 1 ) is true, c 1 is true, otherwise c 1 is false).\nIn general, each original CNF clause that is not subsumed within a gate dependency is represented by an additional variable, that then subsumes the clause in an external \"or\" gate dependency.\nHaving translated our original problem into a set of gates, we can now represent it as the dependency lattice in Figure 1: Here the original variables have become nodes in the lattice, such that nodes v 1 . . . v 4 correspond to the independent variables, nodes g 1 . . . g 3 to the internal gates and node c 1 to an external gate. In this form, a satisfying assignment to the original CNF formula is equivalent to an assignment of the independent variables such that all the c i external nodes evaluate to true. This result follows trivially from the structure of the lattice, which implements the structure of the internal gates and therefore ensures that all internal gate relationships are necessarily satisfied. When all the external nodes evaluate to true, this means all the remaining CNF clauses that were not subsumed as internal gates are true, and hence that a satisfying assignment has been found.\n{v 2 v 3 } 3 g { } } { 3 2 v v c g g v v v v\nThe purpose of the lattice is to embody the structure of gate dependencies in such a way that the cost of flipping an independent variable can be efficiently calculated. This is analogous to existing local search SAT solvers, except that existing solvers are only equipped to handle \"or\" gate dependencies.", "publication_ref": ["b4"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Calculating Flip Costs", "text": "To illustrate the process of cost calculation, we have instantiated the independent variables in Figure 1 as follows: v 1 \u2190 false, v 2 \u2190 false, v 3 \u2190 true and v 4 \u2190 false. Moving down the lattice from v 2 and v 3 to the \"and\" gate at node g 1 it follows that the values of v 2 and v 3 make this gate variable false. Similarly, moving down from v 3 and v 4 to g 2 we can see that the corresponding \"or\" gate variable is true. Then following down from the gates at g 1 and g 2 to the \"equivalence\" gate at g 3 we can see that this gate variable is false, and so on. In this way, the lattice reflects the necessary consequences of the independent variable instantiations on the rest of the problem.\nTo calculate the cost of flipping a particular independent variable v i we need to know how many external gate variables will become false and how many will become true as a result of the flip. This is achieved by storing at each gate node the set of independent variables that, if flipped, would cause the gate variable to change its truth value. For example, node g 1 stores the independent variable v 2 , signifying that if v 2 was flipped then g 1 would change from f alse to true. Similarly, g 2 can only become f alse if v 3 is flipped. Moving down the lattice, we can see that g 3 would become true if either g 1 or g 2 were to change values. As flipping v 2 will change the truth value of g 1 and flipping v 3 will change the truth value of g 2 , either of these flips will also change the truth value of g 3 , so g 3 inherits v 2 and v 3 into its variable set. Node c 1 similarly inherits v 1 and v 2 , as a change in either variable will make c 1 true.\nOnce we have the correct variable sets for each of the external gates we can read off the make cost and break cost for each independent variable simply by counting the number of times a variable appears in a false external gate (= make cost) and the number of times it appears in a true external gate (= break cost). So, in our example, both v 1 and v 2 have a make cost of one, with all other make and break costs equal to zero.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "The General Case", "text": "In realistic problems it can easily happen that the same independent variable appears in multiple branches leading to the same gate. To handle such cases we require more general definitions of how the variable sets for each gate type are composed.\nFirstly, if an \"and\" gate is true then all its parent nodes must be true, therefore any change in a parent node's truth value will also change the truth value of the gate. This means the gate's variable set (V ) should inherit the union of all the parent variable sets (P sets ), as follows:\nif true(AND) then V \u2190 \u222a(true(P sets ))\nAlternatively, if an \"and\" gate is f alse then only if all its parent nodes become true will the gate become true. This requires that all false parent nodes become true and no true parent node becomes f alse, as follows:\nif false(AND) then V \u2190 \u2229(false(P sets )) \\ \u222a(true(P sets ))\nThe rules for an \"or\" gate can be similarly defined in reverse:\nif false(OR) then V \u2190 \u222a(false(P sets )) if true(OR) then V \u2190 \u2229(true(P sets )) \\ \u222a(false(P sets )) For all \"equivalence\" gates with no more than two parents, only if the truth value of a single parent changes will the value of the gate change, as follows:\nV \u2190 \u222a(P sets ) \\ \u2229(P sets )\nIn general, an \"equivalence\" gate is true iff the count of its true parents has the same parity as the count of all its parents. As we did not discover any \"equivalence\" gates with more than two parents in our problem set, we did not implement the more-than-two-parent case.\nIn addition, we did find rare problem instances where a single variable was dependent on more than one gate. In these circumstances, we added an additional dependent variable for each extra gate and connected these variables to the first variable via additional \"equivalence\" gates.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Implementation", "text": "The motivation behind the dependency lattice is to develop an efficient method to update the make and break costs for the independent variables. Clearly there is a potential for the additional work of calculating flip costs using the lattice to outweigh the benefits of reducing the size of the search space (i.e. by eliminating dependent variables and internal gate clauses from the problem). Therefore it is of significance exactly how the lattice is updated. In our current implementation we do this by representing the total set of independent variables at each node using an n ind bit pattern, such that if the i th independent variable is in the variable set of a particular node, then the i th position of the bit pattern for that node will be set. Using this representation we can efficiently implement the set operations necessary to propagate the effects of flipping an independent variable through the lattice. This propagation starts when an independent variable has been selected for flipping. Beginning at the lattice node corresponding to this variable, the update works down the lattice to all the connected internal nodes. For example, if v 3 is flipped in Figure 1, then nodes g 1 and g 2 will be selected for update. The update process then performs the appropriate set operations on the parent variable sets to produce an updated variable set and truth value for the selected gate. If the truth value of a node and the contents of its variable set remain unchanged after an update then no further propagation is required from that node. Otherwise the process continues until it reaches the external nodes. Then, if an external node's variable set is changed, this updates the make and break costs of any affected independent variables and the process terminated.\nIf we follow the process of flipping v 2 in Figure 1, this will alter the variable set at g 1 from {v 2 } to {v 2 , v 3 } and change g 1 to true. As the variable set at g 1 has changed these effects are now propagated to the internal node g 3 which becomes true. Now we have a situation where both parents of g 3 share the same variable, i.e. g 1 now has {v 2 , v 3 } and g 2 has {v 3 }. In this case if v 3 were flipped then both parents of g 3 would change their truth value and still remain equivalent, leaving g 3 unchanged. Hence g 3 only inherits v 2 into its variable set. Finally, the external node c 1 changes its truth value to true and changes its variable set from {v 1 , v 2 } to {v 2 , v 3 }. This change then causes the make costs of v 1 and v 2 to be reduced by one and the break costs of v 2 and v 3 to be increased by one. The process terminates with all external nodes set to true, meaning that a satisfying solution has been found. This situation is illustrated in Figure 2: \n} 3 v 2 v { 3 v } 2 v { {v 2 v 3 } {T} {T} {T} {T} {F} {T} {F} {T} OR AND OR 1 2 3 4 1 2 1 v v v v g g c } { g 3", "publication_ref": [], "figure_ref": ["fig_0", "fig_0", "fig_1"], "table_ref": []}, {"heading": "Experimental Validation", "text": "In order to validate our approach to handling gate dependencies, we implemented a non-CNF version of AdaptNovelty + [Hoos, 2002] that operates on the new dependency lattice platform. We then evaluated the performance of this algorithm on a selection of SATLIB ssa7552, parity 16and 32-bit problems. 2 Table 1 firstly shows the effect of gate detection on the number of variables and clauses in the problem set, detailing the number of independent and dependent gates in the corresponding non-CNF dependency lattices and the total time taken for each conversion.\nWe then compared the performance of our new non-CNF AdaptNovelty + algorithm against the original CNF based variant by running the two algorithms 100 times each on the ssa7552 and par16 instances and 10 times each on the par32 instances. Table 2 shows the success rate, the average number of flips and time in seconds taken to solve these instances. Each run was timed out after 1 hour for the ssa7552 and par16 instances and after 24 hours for the par32 instances.\nAs shown in Table 2, the non-CNF version of AdaptNovelty + significantly outperforms its original CNF counterpart both in terms of flips and time. Indeed, the new non-CNF approach is at least 100 times better than the original CNF approach on these instances. In addition, this is the first time that a local search solver has managed to find solutions for all the parity 32-bit problems within 24 hours. The only other SLS method that can solve these problems is DLM2005 [Wah and Wu, 2005]. However, DLM could only solve the compacted par32-*-c instances, producing only 1 successful run out of 20 attempts and taking nearly 33 hours to find a solution.\nAs all else has been left unchanged between the two versions of AdaptNovelty + , we must conclude that the extraordinary performance gains are due to the successful recognition and exploitation of variable dependencies in the new non-CNF approach. As shown in Figure 3    fort to discover solutions that respect these dependencies. However, the cost of maintaining consistency between the newly discovered gates in our non-CNF approach is also significant. To measure this, we conducted an additional experiment using a set of bart FPGA problems that exhibit no dependency structure [Aloul et al., 2002]. Table 3 shows our non-CNF AdaptNovelty + solver to be more than 1, 000 times slower on these problems. However, this performance deficit can be partly explained by the initial cost of searching for gate dependencies in the original CNF representation, and hence will become less significant for problems where the solution time significantly exceeds the preprocessing time. We also used the built-in C++ set class to update the lattice which could be replaced by more efficient, special purpose data structures and operators. Finally, it would be trivial to implement a switch that automatically reverts to using a CNF based solver when the proportion of gate dependencies falls below a given threshold.", "publication_ref": ["b2", "b5", "b0"], "figure_ref": [], "table_ref": ["tab_1", "tab_2", "tab_2", "tab_3"]}, {"heading": "Conclusion", "text": "In conclusion, we have introduced a new dependency lattice platform that effectively maintains the consistency between independent and dependent variables (or gates) during the execution of a local search. Based on this platform, our new non-CNF version of AdaptNovelty + can solve many hard structured benchmark problems significantly faster than its original CNF based counterpart. In addition, this non-CNF AdaptNovelty + variant is the first local search solver able to reliably solve all five par32 instances within 24 hours. By exploiting variable dependencies within a local search and by solving the par32 problems we have also successfully addressed two of the \"Ten Challenges in Propositional Reasoning and Search\" (#2 and #6) presented in [Selman et al., 1997].\nIn future work, we expect that non-CNF implementations of the latest clause weighting local search solvers (such as PAWS [Thornton et al., 2004] and SAPS [Hutter et al., 2002]) will further extend the state-of-the-art in local search techniques. In fact, the extension of these solvers using our dependency lattice is very straightforward. Instead of counting the number of external dependent gates that will be made or broken if an independent gate is flipped, we simply sum the corresponding weights of the dependent gates.\nAnother future research direction is to develop new heuristics that further exploit the gate dependencies when selecting the next variable to flip. With these improvements, we expect that local search techniques will be able to match the performance of the state-of-the-art DPLL solvers on the more structured industrial benchmark problems.", "publication_ref": ["b5", "b2"], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Acknowledgments The authors would like to acknowledge the financial support of National ICT Australia (NICTA) and the Queensland government. NICTA is funded through the Australian Government's Backing Australia's Ability initiative and also through the Australian Research Council.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Solving difficult SAT instances in the presence of symmetry", "journal": "", "year": "2002", "authors": "Aloul "}, {"ref_id": "b1", "title": "Effective preprocessing in SAT through variable and clause elimination", "journal": "", "year": "2000", "authors": "Many\u00e0 ; Ramo\u00f3n B\u00e9jar; Felip Many\u00e0; ; Holger; H Hoos"}, {"ref_id": "b2", "title": "Scaling and probabilistic smoothing: Efficient dynamic local search for SAT", "journal": "", "year": "2002", "authors": " Hutter"}, {"ref_id": "b3", "title": "Pushing the envelope: Planning, propositional logic, and stochastic search", "journal": "", "year": "1996", "authors": "Selman ; Henry Kautz; Bart Selman"}, {"ref_id": "b4", "title": "SAT-based versus CSPbased constraint weighting for satisfiability", "journal": "", "year": "1992", "authors": "[ Ostrowski"}, {"ref_id": "b5", "title": "UBCSAT: An implementation and experimentation environment for SLS algorithms for SAT and MAX-SAT", "journal": "Conor Madigan", "year": "2004", "authors": "Thornton "}, {"ref_id": "b6", "title": "Efficient conflict driven learning in a Boolean satisfiability solver", "journal": "", "year": "2001", "authors": "Matthew Moskewicz; Sharad Malik"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: An example dependency lattice.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: A dependency lattice solution.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "", "figure_data": ": The effects of the gate extracting algorithm on thessa7552- *  and parity problems. This table shows the numberof \"fixed\", \"equivalence\" (#eq) and \"and/or\" gates extractedfrom each instance. The number of \"independent\" and \"exter-nal dependent\" gates of each processed non-CNF instance aredescribed in the table as #input and #output, respectively.CNF basednon-CNF basedProblem % solved#flips#seconds % solved #flips#secondsssa-03886% 180, 937, 822 838.790100% 2, 16915.131ssa-158100% 303, 377, 289 419.054100%4391.203ssa-15995% 118, 865, 143 499.300100%4601.396ssa-160100% 154, 646, 089 377.383100% 1, 2845.562par16-1100% 148, 475, 195 684.972100% 2, 4550.489par16-298% 331, 148, 102 788.312100% 2, 7240.570par16-3100% 381, 887, 299 801.501100% 1, 6400.320par16-4100% 79, 196, 974 779.877100% 3, 2170.626par16-5100% 390, 162, 552 604.379100% 7, 9381.630par32-10%n/a > 24h80%n/a 48, 194.033par32-20%n/a > 24h100%n/a 13, 204.536par32-30%n/a > 24h100%n/a 17, 766.822par32-40%n/a > 24h100%n/a 9, 487.728par32-50%n/a > 24h100%n/a 23, 212.755"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "The results of solving the ssa7552-* and parity problems using the CNF and non-CNF based versions of AdaptNovelty + . The #f lips and #seconds are the average number of flips and seconds taken to solve each instance. For the original AdaptNovelty + the #f lips values have been approximated as the flip counter maximum was exceeded.of the par8-1 instance is highly connected. Access to this extra knowledge enables the new solver to maintain the consistency of the dependent variables and hence to efficiently navigate the search space and find a solution. The structure of the variable dependencies is otherwise flattened out and hidden in the original CNF representation. This means that CNF based SLS solvers must expend considerable extra ef-Figure3: The dependency lattice of the par8-1 instance. In this graph, the independent gates are depicted as shaded rectangular boxes and the dependent \"equivalence\", \"and\" and \"or\" gates are represented as hexagon, house and inverse house shaped boxes, respectively. External dependent gates are also lightly shaded. A solid arrow outputs the gate value, while a dashed arrow outputs the negation of the gate value.", "figure_data": "CNF basednon-CNF basedProblem % solved #flips #seconds % solved #flips #secondsbart26100% 2160.001100% 2153.585bart27100% 2330.001100% 2284.537bart28100% 2220.001100% 2224.191bart29100% 2440.001100% 2495.602bart30100% 2660.001100% 2516.677"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "The results of solving the Aloul's bart FPGA problems using the CNF and non-CNF based versions of AdaptNovelty + . The #f lips and #seconds are the average number of flips and seconds taken to solve each instance.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "(\u00aca \u2228 b \u2228 c \u2228 d) \u2227 (a \u2228 \u00acb) \u2227 (a \u2228 \u00acc) \u2227 (a \u2228 \u00acd)", "formula_coordinates": [2.0, 72.6, 559.53, 205.72, 9.96]}, {"formula_id": "formula_1", "formula_text": "a = \u2228(b, c, d)", "formula_coordinates": [2.0, 147.72, 635.49, 55.6, 9.96]}, {"formula_id": "formula_2", "formula_text": "(a \u2228 \u00acb \u2228 \u00acc \u2228 \u00acd) \u2227 (\u00aca \u2228 b) \u2227 (\u00aca \u2228 c) \u2227 (\u00aca \u2228 d)", "formula_coordinates": [2.0, 66.0, 667.53, 219.03, 9.96]}, {"formula_id": "formula_3", "formula_text": "(a \u2228 b \u2228 c) \u2227 (\u00aca \u2228 \u00acb \u2228 c) \u2227 (\u00aca \u2228 b \u2228 \u00acc) \u2227 (a \u2228 \u00acb \u2228 \u00acc)", "formula_coordinates": [2.0, 315.0, 122.37, 242.91, 9.96]}, {"formula_id": "formula_4", "formula_text": "(\u00aca \u2228 \u00acb \u2228 \u00acc) \u2227 (a \u2228 b \u2228 \u00acc) \u2227 (a \u2228 \u00acb \u2228 c) \u2227 (\u00aca \u2228 b \u2228 c)", "formula_coordinates": [2.0, 315.0, 228.09, 243.04, 9.97]}, {"formula_id": "formula_5", "formula_text": "(\u00acg 1 \u2228 v 2 \u2228 v 3 ) \u2227 (g 1 \u2228 \u00acv 2 ) \u2227 (g 1 \u2228 \u00acv 3 )\u2227 (g 2 \u2228 \u00acv 3 \u2228 \u00acv 4 ) \u2227 (\u00acg 2 \u2228 v 3 ) \u2227 (\u00acg 2 \u2228 v 4 )\u2227 (g 3 \u2228 g 1 \u2228 g 2 ) \u2227 (\u00acg 3 \u2228 \u00acg 1 \u2228 g 2 )\u2227 (\u00acg 3 \u2228 g 1 \u2228 \u00acg 2 ) \u2227 (g 3 \u2228 \u00acg 1 \u2228 \u00acg 2 )\u2227 (v 1 \u2228 g 1 )", "formula_coordinates": [3.0, 81.6, 131.37, 187.73, 73.66]}, {"formula_id": "formula_6", "formula_text": "(g 1 = \u2227(v 2 , v 3 )) \u2227 (g 2 = \u2228(v 3 , v 4 ))\u2227 (g 3 =\u21d4 (v 1 , v 2 )) \u2227 (c 1 = \u2228(v 1 , g 1 ))", "formula_coordinates": [3.0, 99.0, 229.53, 152.92, 28.66]}, {"formula_id": "formula_7", "formula_text": "(v 1 \u2228 g 1 ) (i.e. if (v 1 \u2228 g 1 ) is true, c 1 is true, otherwise c 1 is false).", "formula_coordinates": [3.0, 54.0, 273.45, 243.04, 20.7]}, {"formula_id": "formula_8", "formula_text": "{v 2 v 3 } 3 g { } } { 3 2 v v c g g v v v v", "formula_coordinates": [3.0, 76.39, 367.79, 183.43, 104.14]}, {"formula_id": "formula_9", "formula_text": "} 3 v 2 v { 3 v } 2 v { {v 2 v 3 } {T} {T} {T} {T} {F} {T} {F} {T} OR AND OR 1 2 3 4 1 2 1 v v v v g g c } { g 3", "formula_coordinates": [4.0, 337.39, 138.71, 198.24, 104.14]}], "doi": ""}