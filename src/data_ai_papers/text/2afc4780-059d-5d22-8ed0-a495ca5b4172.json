{"title": "The Fast Bilateral Solver", "authors": "Jonathan T Barron; Ben Poole", "pub_date": "", "abstract": "We present the bilateral solver, a novel algorithm for edgeaware smoothing that combines the flexibility and speed of simple filtering approaches with the accuracy of domain-specific optimization algorithms. Our technique is capable of matching or improving upon state-of-the-art results on several different computer vision tasks (stereo, depth superresolution, colorization, and semantic segmentation) while being 10-1000\u00d7 faster than baseline techniques with comparable accuracy, and producing lower-error output than techniques with comparable runtimes. The bilateral solver is fast, robust, straightforward to generalize to new domains, and simple to integrate into deep learning pipelines.", "sections": [{"heading": "Introduction", "text": "Images of the natural world exhibit a useful prior -many scene properties (depth, color, object category, etc.) are correlated within smooth regions of an image, while differing across discontinuities in the image. Edge-aware smoothing techniques exploit this relationship to propagate signals of interest within, but not  across edges present in an image. Traditional approaches to edge-aware smoothing apply an image-dependent filter to a signal of interest. Examples of this include joint bilateral filtering [37,40] and upsampling [20], adaptive manifolds [12], the domain transform [11], the guided filter [17,16], MST-based filtering [41], and weighted median filtering [30,44]. These techniques are flexible and computationally efficient, but often insufficient for solving more challenging computer vision tasks. Difficult tasks often necessitate complex iterative inference or optimization procedures that encourage smoothness while maintaining fidelity with respect to some observation. Optimization algorithms of this nature have been used in global stereo [34], depth superresolution [10,19,24,26,29,32], colorization [25], and semantic segmentation [6,22,28,45]. These approaches are tailored to their specific task, and are generally computationally expensive. In this work we present an optimization algorithm that is 10-1000\u00d7 faster than existing domain-specific approaches with comparable accuracy, and produces higher-quality output than lightweight filtering techniques with comparable runtimes.\nOur algorithm is based on the work of Barron et al. [2], who presented the idea of using fast bilateral filtering techniques to solve optimization problems in \"bilateral-space\". This allows for some optimization problems with bilateral affinity terms to be solved quickly, and also guarantees that the solutions to those problems are \"bilateral-smooth\" -smooth within objects, but not smooth across edges. In this paper we present a new form of bilateral-space optimization which we call the bilateral solver, which efficiently solves a regularized least-squares optimization problem to produce an output that is bilateral-smooth and close to the input. This approach has a number of benefits:\nGeneral The bilateral solver is a single intuitive abstraction that can be applied to many different problems, while matching or beating the specialized state-of-the-art algorithms for each of these problems. It can be generalized to a variety of loss functions using standard techniques from M-estimation [14].\nDifferentiable Unlike other approaches for edge-aware smoothness which require a complicated and expensive \"unrolling\" to perform backpropagation [45], the backward pass through our solver is as simple and fast as the forward pass, allowing it to be easily incorporated into deep learning architectures.\nFast The bilateral solver is expressible as a linear least-squares optimization problem, unlike the non-linear optimization problem used in [2]. This enables a number of optimization improvements including a hierarchical preconditioner and initialization technique that hasten convergence, as well as efficient methods for solving multiple problems at once.", "publication_ref": ["b73", "b69", "b72", "b75", "b71"], "figure_ref": [], "table_ref": []}, {"heading": "Problem Formulation", "text": "We begin by presenting the objective and optimization techniques that make up our bilateral solver. Let us assume that we have some per-pixel input quantities t (the \"target\" value, see Figure 1a) and some per-pixel confidence of those quantities c (Figure 1c), both represented as vectorized images. Let us also assume that we have some \"reference\" image (Figure 1d), which is a normal RGB image. Our goal is to recover an \"output\" vector x (Figure 1b), which will resemble the input target where the confidence is large while being smooth and tightly aligned to edges in the reference image. We will accomplish this by constructing an optimization problem consisting of an image-dependent smoothness term that encourages x to be bilateral-smooth, and a data-fidelity term that minimizes the squared residual between x and the target t weighted by our confidence c:\nminimize x \u03bb 2 i,j\u0174 i,j (x i \u2212 x j ) 2 + i c i (x i \u2212 t i ) 2 (1)\nThe smoothness term in this optimization problem is built around an affinity matrix\u0174 , which is a bistochastized version of a bilateral affinity matrix W . Each element of the bilateral affinity matrix W i,j reflects the affinity between pixels i and j in the reference image in the YUV colorspace:\nW i,j = exp \u2212 [[p x i ,p y i ]\u2212[p x j ,p y j ] 2 2\u03c3 2 xy \u2212 (p l i \u2212p l j ) 2 2\u03c3 2 l \u2212 [p u i ,p v i ]\u2212[p u j ,p v j ] 2 2\u03c3 2 uv (2)\nWhere p i is a pixel in our reference image with a spatial position (p x i , p y i ) and color (p l i , p u i , p v i ) 1 . The \u03c3 xy , \u03c3 l , and \u03c3 uv parameters control the extent of the spatial, luma, and chroma support of the filter, respectively. This W matrix is commonly used in the bilateral filter [40], an edge-preserving filter that blurs within regions but not across edges by locally adapting the filter to the image content. There are techniques for speeding up bilateral filtering [1,5] which treat the filter as a \"splat/blur/slice\" procedure: pixel values are \"splatted\" onto a small set of vertices in a grid [2,5] or lattice [1] (a soft histogramming operation), then those vertex values are blurred, and then the filtered pixel values are produced via a \"slice\" (an interpolation) of the blurred vertex values. These splat/blur/slice filtering approaches all correspond to a compact and efficient factorization of W :\nW = S TB S(3)\nBarron et al. [2] built on this idea to allow for optimization problems to be \"splatted\" and solved in bilateral-space. They use a \"simplified\" bilateral grid and a technique for producing bistochastization matrices D n , D m that together give the the following equivalences:\nW = S T D \u22121 m D nB D n D \u22121 m S SS T = D m (4)\nThey also perform a variable substitution, which reformulates a high-dimensional pixel-space optimization problem in terms of the lower-dimensional bilateral-space vertices:\nx = S T y (5\n)\nWhere y is a small vector of values for each bilateral-space vertex, while x is a large vector of values for each pixel. With these tools we can not only reformulate our pixel-space loss function in Eq 1 in bilateral-space, but we can rewrite that bilateral-space loss function in a quadratic form:\nminimize y 1 2 y T Ay \u2212 b T y + c (6) A = \u03bb(D m \u2212 D nB D n ) + diag(Sc) b = S(c \u2022 t) c = 1 2 (c \u2022 t) T t\nwhere \u2022 is the Hadamard product. A derivation of this reformulation can be found in the supplement. While the optimization problem in Equation 1 is intractably expensive to solve naively, in this bilateral-space formulation optimization can be performed quickly. Minimizing that quadratic form is equivalent to solving a sparse linear system:\nAy = b (7)\nWe can produce a pixel-space solutionx by simply slicing the solution to that linear system:\nx = S T (A \u22121 b)(8)\nWith this we can describe our algorithm, which we will refer to as the \"bilateral solver.\" The input to the solver is a reference RGB image, a target image that contains noisy observed quantities which we wish to improve, and a confidence image. We construct a simplified bilateral grid from the reference image, which is bistochastized as in [2] (see the supplement for details), and with that we construct the A matrix and b vector described in Equation 6 which are used to solve the linear system in Equation 8 to produce an output image. If we have multiple target images (with the same reference and confidence images) then we can construct a larger linear system in which b has many columns, and solve for each channel simultaneously using the same A matrix. In this many-target case, if b is low rank then that property can be exploited to accelerate optimization, as we show in the supplement.\nOur pixel-space loss (Eq 1) resembles that of weighted least squares filtering [8,9,31], with one critical difference being our use of bilateral-space optimization which allows for efficient optimization even when using a large spatial support in the bilateral affinity, thereby improving the quality of our output and the speed of our algorithm. Our algorithm is similar to the optimization problem that underlies the stereo technique of [2], but with several advantages: Our approach reduces to a simple least-squares problem, which allows us to optimize using standard techniques (we use the preconditioned conjugate gradient algorithm of [36], see the supplement for details). This simple least-squares formulation also allows us to efficiently backpropagate through the solver (Section 3), allowing it to be integrated into deep learning pipelines. This formulation also improves the rate of convergence during optimization, provides guarantees on correctness, allows us to use advanced techniques for preconditioning and initialization (Section 4), and enables robust and multivariate generalizations of our solver (see the supplement).", "publication_ref": ["b0", "b0", "b0", "b74"], "figure_ref": ["fig_0", "fig_1", "fig_1", "fig_1"], "table_ref": []}, {"heading": "Backpropagation", "text": "Integrating any operation into a deep learning framework requires that it is possible to backpropagate through that operation. Backpropagating through global operators such as our bilateral solver is generally understood to be difficult, and is an active research area [18]. Unlike most global smoothing operators, our model is easy to backpropagate through by construction. Note that we do not mean backpropagating through a multiplication of a matrix inverse A \u22121 , which would simply be another multiplication by A \u22121 . Instead, we will backpropagate onto the A matrix used in the least-squares solve that underpins the bilateral solver, thereby allowing us to backpropagate through the bilateral solver itself.\nConsider the general problem of solving a linear system:\nAy = b (9)\nWhere A is an invertible square matrix, and y and b are vectors. We can solve for\u0177 as a simple least squares problem:\ny = A \u22121 b (10)\nLet us assume that A is symmetric in addition to being positive definite, which is true in our case. Now let us compute some loss with respect to our estimated vector g(\u0177), whose gradient will be \u2202g/\u2202\u0177. We would like to backpropagate that quantity onto A and b:\n\u2202 g \u2202 b = A \u22121 \u2202 g \u2202\u0177 \u2202 g \u2202 A = \u2212A \u22121 \u2202 g \u2202\u0177 \u0177 T = \u2212 \u2202 g \u2202 b\u0177 T (11\n)\nThis can be derived using the implicit function theorem. We see that backpropagating a gradient through a linear system only requires a single least-squares solve. The gradient of the loss with respect to the diagonal of A can be computed more efficiently:\n\u2202 g \u2202 diag(A) = \u2212 \u2202 g \u2202 b \u2022\u0177 (12)\nWe will use these observations to backpropagate through the bilateral solver. The bilateral solver takes some input target t and some input confidence c, and then constructs a linear system that gives us a bilateral-space solution\u0177, from which we can \"slice\" out a pixel-space solutionx.\ny = A \u22121 bx = S T\u0177 (13)\nNote that A and b are both functions of t and c, though they are not written as such. Let us assume that we have computed some loss f (x) and its gradient \u2202 f /\u2202x. Remember that the A matrix and b vector in our linear system are functions of some input signal t and some input confidence c. Using ( 11) we can compute the gradient of the loss with respect to the parameters of the linear system within the bilateral solver:\n\u2202 f \u2202 b = A \u22121 S \u2202 f \u2202x \u2202 f \u2202 diag(A) = \u2212 \u2202 f \u2202 b \u2022\u0177 (14)\nWe need only compute the gradient of the loss with respect to the diagonal of A as opposed to the entirety of A, because the off-diagonal elements of A do not depend on the input signal or confidence. We can now backpropagate the gradient of the loss f (x) onto the inputs of the bilateral solver:\n\u2202 f \u2202 t = c \u2022 S T \u2202 f \u2202 b \u2202 f \u2202 c = S T \u2202 f \u2202 diag(A) + S T \u2202 f \u2202 b \u2022 t (15\n)\nTo review, the bilateral solver can be viewed as a function which takes in a reference image, some input signal and a per-pixel confidence in that input signal, and produces some smoothed output: output \u2190 solver reference (target, confidence) (\nAnd we have shown how to backpropagate through the solver:\n(\u2207target, \u2207confidence) \u2190 backprop reference (\u2207output)\nBecause the computational cost of the backwards pass is dominated by the least squares solve necessary to compute \u2202 f /\u2202 b , computing the backward pass through the solver is no more costly than computing the forward pass. Contrast this with past approaches for using iterative optimization algorithms in deep learning architectures, which create a sequence of layers, one for each iteration in optimization [45]. The backward pass in these networks is a fixed function of the forward pass and so cannot adapt like the bilateral solver to the structure of the error gradient at the output. Furthermore, in these \"unrolled\" architectures, the output at each iteration (layer) must be stored during training, causing the memory requirement to grow linearly with the number of iterations. In the bilateral solver, the memory requirements are small and independent of the number of iterations, as we only need to store the bilateral-space output of the solver\u0177 during training. These properties make the bilateral solver an attractive option for deep learning architectures where speed and memory usage are important.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Preconditioning & Initialization", "text": "Optimization of the quadratic objective of the bilateral solver can be sped up with improved initialization and preconditioning. In the previous work of [2], the non-linear optimization used a hierarchical technique which lifted optimization into a pyramid space, using a bilateral variant of the image pyramid optimization approach of [3]. This approach cannot be used by our solver, as most linear solvers require a preconditioner where the input is of the same dimensionality as the output. Regardless, the approach of [2] is also suboptimal for our use case, as the simple linear structure of our system allows us to construct more accurate and effective preconditioning and initialization techniques.\nTo best explain our preconditioning and initialization techniques we must first present baselines techniques for both. We can extract the diagonal of our A matrix to construct a Jacobi preconditioner:\ndiag(A) = \u03bb diag (D m ) \u2212 diag(D n )B diag diag(D n ) + Sc\nThis is straightforward to compute, as D m and D n are diagonal matrices and B has a constant value along the diagonal denoted here asB diag . The Jacobi preconditioner is simply the inverse of the diagonal of A:\nM \u22121 jacobi (y) = diag(A) \u22121 y (18\n)\nWe can also initialize the state vector y in our optimization to the value which minimizes the data term in our loss, which has a closed form:\ny flat = S(c \u2022 t)/S(c)(19)\nThis preconditioner and initialization technique perform well, as can be seen in Figure 2. But we can improve upon these baseline techniques by constructing hierarchical generalizations of each. Hierarchical preconditioners have been studied extensively for image interpolation and optimization tasks. Unfortunately, techniques based on image pyramids [38] are not applicable to our task as our optimization occurs in a sparse 5dimensional bilateral-space. More sophisticated image-dependent or graph based techniques [21,23,39] are effective preconditioners, but in our experiments the cost of constructing the preconditioner greatly outweighs the savings provided by the improved conditioning. We will present a novel preconditioner which is similar in spirit to hierarchical basis functions [38] or push-pull interpolation [13], but adapted to our task using the bilateral pyramid techniques presented in [2]. Because of its bilateral nature, our preconditioner is inherently locally adapted and so resembles image-adapted preconditioners [23,39].\nWe will use the multiscale representation of bilateral-space presented in [2] to implement our hierarchical preconditioner. This gives us P (y) and P T (z), which construct a pyramid-space vector z from a bilateral-space vector y, and collapse z down to y respectively (see the supplement for details). To evaluate our preconditioner, we lift our bilateral-space vector into pyramid-space, apply an element-wise scaling of each pyramid coefficient, and then project back onto bilateral-space:\nM \u22121 hier (y) = P T z weight \u2022 P (1) \u2022 P (y) P (diag(A)) (20\n)\nFig. 2: Our loss during PCG for 20 4-megapixel images, with the loss for each image normalized to [0, 1] and with the 25th-75th percentiles plotted. We see that preconditioning is critical, and that our hierarchical (\"Pyr\") preconditioning and initialization techniques significantly improve performance over the naive Jacobi preconditioner and \"flat\" initialization. Note the non-linear y-axis and logarithmic x-axis.\nwhere the division is element-wise. M \u22121 hier (\u2022) includes an ad-hoc element-wise scaling:\nz weight = 1 if k = 0 \u03b1 \u2212(\u03b2+k) otherwise (21\n)\nThe pyramid-space scaling we use in Equation 20 is proportional to: 1) the number of bilateral-space vertices assigned to each pyramid-space coefficient (computed by lifting a vector of ones), 2) the inverse of the diagonal of the A matrix, computed by lifting and inverting the diagonal of the A matrix, and 3) an exponential weighting of each pyramid-space coefficient according to its level in the pyramid. This per-level scaling z weight is computed as a function of the level k of each coefficient, which allows us to prescribe the influence that each scale of the pyramid should have in the preconditioner. Note that as the coarser levels are weighed less (ie, as \u03b1 or \u03b2 increases) our preconditioner degenerates naturally to the Jacobi preconditioner. In all experiments we use (\u03b1 = 2, \u03b2 = 5) for the preconditioner. This same bilateral pyramid approach can be used to effectively initialize the state before optimization. Rather than simply taking the input target and using it as our initial state as was done in Equation 19, we perform a push-pull filter of that initial state with the pyramid according to the input confidence: Like our hierarchical preconditioner, this initialization degrades naturally to our non-hierarchical initialization in Eq. 19 as \u03b1 and \u03b2 increase. In all experiments we use (\u03b1 = 4, \u03b2 = 0) for initialization. See Figure 2 for a visualization of how our hierarchical preconditioning and initialization improve convergence during optimization, compared to the \"flat\" baseline algorithms. See Table 1 for a comparison of our runtime compared to [2], where we observe a substantial speedup with respect to the solver of [2]. Though the techniques presented here for efficient optimization and initialization are framed in terms of the forward pass through the solver, they all apply directly to the backward pass through the solver described in Section 3, and produce equivalent improvements in speed.\ny hier = P T z weight \u2022 P (S(c \u2022 t)) P (1) /P T z weight \u2022 P (S(c)) P (1) (22)", "publication_ref": [], "figure_ref": ["fig_8", "fig_8", "fig_8"], "table_ref": ["tab_0"]}, {"heading": "Applications", "text": "We evaluate our solver on a variety of applications: stereo, depth superresolution, image colorization, and semantic segmentation. Each of these tasks has been the focus of significant research, with specialized techniques having been developed for each problem. For some of these applications (semantic segmentation and stereo) our solver serves as a building block in a larger algorithm, while for others (colorization and depth superresolution) our solver is a complete algorithm. We will demonstrate that our bilateral solver produces results that are comparable to or better than the state-of-the-art for each problem, while being either 1-3 orders of magnitude faster. For those techniques with comparable runtimes, we will demonstrate that the bilateral solver produces higher quality output. Unless otherwise noted, all runtimes were benchmarked on a 2012 HP Z420 workstation (Intel Xeon CPU E5-1650, 3.20GHz, 32 GB RAM), and our algorithm is implemented in standard, single-threaded C++. As was done in [2], the output of our bilateral solver is post-processed by the domain transform [11] to smooth out the blocky artifacts introduced by the simplified bilateral grid, and the domain transform is included in all runtimes. For all results of each application we use the same implementation of the same algorithm with different parameters, which are noted in each sub-section. Parameters are: the spatial bandwidths of the bilateral grid (\u03c3 xy , \u03c3 l , \u03c3 uv ), the smoothness multiplier (\u03bb), the spatial and range bandwidths of the domain transform (\u03c3 xy , \u03c3 rgb ). Unless otherwise stated, the bilateral solver is run for 25 iterations of PCG.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Stereo", "text": "We first demonstrate the utility of the bilateral solver as a post-processing procedure for stereo algorithms. Because depth maps produced by stereo algorithms tend to have heavy-tailed noise distributions, we use a variant of our technique called the robust bilateral solver (RBS) with the Geman-McClure loss (described in the supplement). We applied the RBS to the output of the top-performing MC-CNN [43] algorithm on the Middlebury Stereo Benchmark V3 [43]. For comparison, we also evaluated against four other techniques which can or have been used to post-process the output of stereo algorithms. In Table 2 we see that the RBS cuts test-and training-set absolute and RMS errors in half while having little negative effect on the \"bad 1%\" error metric (the percent of pixels which whose disparities are wrong by more than 1). This improvement is smaller when we only consider non-occluded (NoOcc) as most state-of-the-art stereo algorithms already perform well in the absence of occlusions. The improvement provided by the RBS is more dramatic when the depth maps are visualized, as can be seen in Figure 1 and in the supplement. At submission time our technique achieved a lower test-set MAE and RMSE on the Middlebury benchmark than any published technique 2 .\nSee the supplement for a discussion of how our baseline comparison results were produced, an evaluation of our RBS and our baseline techniques on three additional contemporary stereo algorithms, the parameters settings used in this experiment, how we compute the initial confidence c for the RBS, and many visualizations.  ", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": ["tab_1"]}, {"heading": "Depth Superresolution", "text": "With the advent of consumer depth sensors, techniques have been proposed for upsampling noisy depth maps produced by these sensors using a high-resolution RGB reference image [10,19,24,26,29,32,4,27,31]. Other techniques have been developed for post-processing depth maps in other contexts [41, 30,35], and many general edge-aware upsampling or filtering techniques can be used for this task [20,11,17,16,44]. We present an extensive evaluation of the bilateral solver against these approaches for the depth superresolution task. Given a noisy input depth map and an RGB reference image, we resize the depth map to be the size of the reference image with bicubic interpolation and then apply the bilateral solver or one of our baseline techniques. The hyperparameters used by the solver for all experiments are:\n\u03c3 xy = 8, \u03c3 l = 4, \u03c3 uv = 3, \u03c3 xy = \u03c3 rgb = 16, \u03bb = 4 f \u22121/2\n(where f is the upsampling factor) and 15 iterations of PCG. Our confidence c is a Gaussian bump (\u03c3 = f /4) modeling the support of each low-resolution pixel in the upsampled image. To evaluate our model, we use the depth superresolution benchmark of [10] which is based on the Middlebury stereo dataset [34]. Our performance can be see in Table 3 and Figure 3, with more detailed results in the supplement. The bilateral solver produces the third-lowest error rate for this task, though the two better-performing tasks [24,26] use large amounts of external training data and so have an advantage over our technique, which uses no learning for this experiment. Our approach is 600\u00d7, 1200\u00d7, and 3000\u00d7 faster than the three most accurate techniques. The techniques with speeds comparable to or better than the bilateral solver [11,41,16,31] produce error rates that are 25-40% greater than our approach. The bilateral solver represents a effective combination of speed and accuracy, while requiring no training or learning. See the supplement for a more detailed table, a discussion of baselines and runtimes, and many visualizations.  (e) Guided Filter [16] (f) Ferstl et al. [10] (g) Li et al. [26] (h) Our results Fig. 3: Partial results for the depth superresolution task of [10], see the supplement for exhaustive visualizations.", "publication_ref": ["b69", "b72", "b75", "b70", "b74", "b73", "b69", "b74", "b69"], "figure_ref": ["fig_9", "fig_9"], "table_ref": ["tab_2"]}, {"heading": "Colorization", "text": "Colorization is the problem of introducing color to a grayscale image with a small amount of user input or outside information, for the purpose of improving blackand-white films or photographs. Levin et al. [25] presented an effective technique for this task by formulating and solving a specialized optimization problem. We can solve the same task using our bilateral solver: we use the grayscale image as the input reference image and the UV channels of the user-annotated scribbles as the input target images, with a confidence image that is 1 where the user has scribbled and 0 everywhere else. We then construct our final output by combining the grayscale image with our output UV images, and converting from YUV to  RGB. Our results can be seen in Figure 4, where we see that our output is nearly indistinguishable from that of [25]. The important distinction here is speed, as the approach of [25] take 80.99 seconds per megapixel while our approach takes 0.854 seconds per megapixel -a 95\u00d7 speedup. For all results our parameters are \u03c3 xy = \u03c3 l = \u03c3 uv = 4, \u03bb = 0.5, \u03c3 xy = 4, \u03c3 rgb = 8. More results can be see in the supplement.", "publication_ref": [], "figure_ref": ["fig_5"], "table_ref": []}, {"heading": "Semantic Segmentation", "text": "Semantic segmentation is the problem of assigning a category label to each pixel in an image. State-of-the-art approaches to semantic segmentation use large convolutional neural networks (CNNs) to map from pixels to labels [6,28]. The output of these CNNs is often smoothed across image boundaries, so recent approaches refine their output with a CRF ( [6,45]). These CRF-based approaches improve per-pixel labeling accuracy, but this accuracy comes at a computational cost: inference in a fully connected CRF on a 500 \u00d7 500 image can take up to a second (see  as input our bilateral solver can produce comparable edge-aware output (5d) to the DenseCRF [22] used in [6] (5c), while being 8\u00d7 faster.\noutputs of either the DeepLab or CRF-RNN model. As many class probability maps are zero across the entire image, the resulting b matrix in the bilateral solver is often low-rank, allowing us to solve a reduced linear system to recover the smoothed class probability maps (see the supplement). This approach produces nearly identical output, with a 5\u00d7 speedup on average. We applied our bilateral solver to the class probability maps using uniform confidence. The resulting discrete segmentations are more accurate and qualitatively smoother than the CNN outputs, despite our per-channel smoothing providing no explicit smoothness guarantees on the argmax of the filtered perclass probabilities (Table. 4, Figure 5). The bilateral solver is 8 \u2212 10\u00d7 faster than the CRF and CRF-RNN approaches when applied to the same inputs (Table 4). Although the bilateral solver performs slightly worse than the CRF-based approaches, its speed suggests that it may be a useful tool in contexts such as robotics and autonomous driving, where low latency is necessary.", "publication_ref": ["b71"], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "Conclusion", "text": "We have presented the bilateral solver, a flexible and fast technique for inducing edge-aware smoothness. We have demonstrated that the solver can produce or improve state-of-the-art results on a variety of different computer vision tasks, while being faster or more accurate than other approaches. Its speed and generality suggests that the bilateral solver is a useful tool in the construction of computer vision algorithms and deep learning pipelines. The Fast Bilateral Solver Supplement Jonathan T. Barron Ben Poole barron@google.com poole@cs.stanford.edu\nThis supplement provides additional details on the bilateral solver and its extensions in Sections 1-4, and a plethora of experiments and comparisons to prior work in Section 5. In Section 1 we derive the bilateral-space quadratic objective at the core of the bilateral solver. Section 2 details the bilateral-space pyramid representation used for faster initialization and preconditioning. Section 3 extends the bilateral solver to use a robust error function to cope with outliers. Section 4 improves the performance of the bilateral solver when applied to multiple output channels. Finally, in Section 5 we provide additional evaluation of the bilateral solver and extensively compare it to numerous existing and novel baseline techniques.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Derivation", "text": "In the main paper we presented an optimization problem where we solve for a per-pixel quantity x subject to a smoothness term that encourages x to be smooth and a data term that encourages x to resemble some observed input \"target\" quantities t proportionally to a per-pixel \"confidence\" c:\nminimize x \u03bb 2 i,j\u0174 i,j (x i \u2212 x j ) 2 + i c i (x i \u2212 t i ) 2 (1)\nWe can use the procedure detailed in Barron et al. [2] to reformulate the smoothness term into matrix/vector notation. The data term can be similarly reformulated:\ni c i (x i \u2212 t i ) 2 =(x \u2212 t) T diag(c)(x \u2212 t) (2) =x T diag(c)x \u2212 2x T diag(c)t + t T diag(c)t (3) =x T diag(c)x \u2212 2 (c \u2022 t) T x + (c \u2022 t) T t(4)\nCombining this reformulated data term with the reformulated smoothness term from [2] we get:\nminimize x x T \u03bb I \u2212\u0174 + diag(c) x \u2212 2(c \u2022 t) T x + (c \u2022 t) T t(5)\nUsing the bistochastization algorithm from [2], we can decompose\u0174 : \nW = S T D \u22121 m D nB D n D \u22121 m S(\nD n \u2190 diag(n) 7: D m \u2190 diag(m)\nThe bistochastization algorithm from [2] is reproduced in Algorithm 1.\nUsing the simplified bilateral grid of [2] gives us the following equivalence:\nSS T = D m (7)\nWe will use the same bilateral-space variable substitution as [2], by rewriting our optimization problem framed in terms of pixels x as an optimization in terms of bilateral-space vertices y:\nx = S T y(8)\nLet us perform this variable substitution and simplify the resulting expression using our known equivalences, first for the parts of Equation 5 which correspond to the smoothness term:\nx T I \u2212\u0174 x =x T I \u2212 S T D \u22121 m D nB D n D \u22121 m S x by Eq 6 =(S T y) T I \u2212 S T D \u22121 m D nB D n D \u22121 m S (S T y) by Eq 8 =y T SIS T \u2212 SS T D \u22121 m D nB D n D \u22121 m SS T y (9) =y T D m \u2212 D m D \u22121 m D nB D n D \u22121 m D m y by Eq 7 =y T D m \u2212 D nB D n y (10\n)\nAnd now, we will perform the variable substitution on the parts of Equation 5which correspond to the data term:\nx T diag(c)x \u2212 2(c \u2022 t) T x + (c \u2022 t) T t (11) =(S T y) T diag(c)(S T y) \u2212 2(c \u2022 t) T (S T y) + (c \u2022 t) T t by Eq 8 =y T (Sdiag(c)S T )y \u2212 2(S(c \u2022 t)) T y + (c \u2022 t) T t (12\n)\n=y T diag(Sc)y \u2212 2(S(c \u2022 t)) T y + (c \u2022 t) T t (13\n)\nCombining all of this we can rewrite Equation 5 in bilateral-space as follows:\nminimize y 1 2 y T \u03bb D m \u2212 D nB D n + diag(Sc) y \u2212 (S(c \u2022 t)) T y + 1 2 (c \u2022 t) T t (14\n)\nUnlike the non-linear optimization problem of [2], because we have a simple quadratic optimization problem we can rewrite it in standard form:\nminimize y 1 2 y T Ay \u2212 b T y + c (15) A = \u03bb(D m \u2212 D nB D n ) + diag(Sc) b = S(c \u2022 t) c = 1 2 (c \u2022 t) T t\nBy taking the derivative of this loss function and setting it to zero we see that minimizing that quadratic form is equivalent to solving the sparse linear system\nAy = b (16)\nWe will solve this optimization problem using the preconditioned conjugate gradient (PCG) algorithm, using the initialization and preconditioning tricks described in the paper. We use the PCG implementation described in Section B3 of [28], which is reproduced here in Algorithm 2. x // x such that A(x) \u2248 b Applying the hierarchical initialization and preconditioning techniques in the main paper requires that we have a multiscale representation of our simplified bilateral grid. As was done in [2], will use the same bilateral grid which was applied to image pixels to instead construct a bilateral grid on top of the vertex coordinates V , where V is an m by 5 matrix produced when constructing a bilateral grid from the input image (m is the number of vertices in the simplified bilateral grid, and 5 is the dimensionality of our XYLUV bilateral-space). From V we can construct a more coarse simplified bilateral grid by dividing the elements of V by 2 (an arbitrary scale factor), and then repeat that procedure to form a pyramid:\n1: i \u2190 0 2: r \u2190 b \u2212 A(x) 3: d \u2190 M \u22121 (r) 4: \u03bb new \u2190 r T d 5: while i < n do 6: q \u2190 A(d) 7: \u03b1 \u2190 \u03bb new d T q 8: x \u2190 x + \u03b1d 9: r \u2190 r \u2212 \u03b1q 10: s \u2190 M \u22121 (\nfor\nk = [0 : K \u2212 1] do V \u2190 V /2 (S k , V ) \u2190 simplified bilateral grid(V ) end for\nWhere K (the number of levels of the pyramid) is set such that the top of the pyramid contains just a single vertex. As was done in [2], we can use these K splat matrices to lift from some bilateral-space vector y into a pyramid-space:\nP (y) = [S K\u22121 . . . S 1 S 0 y, . . . , S 1 S 0 y, S 0 y, y](17)\nWe can transpose this pyramid operation, collapsing back down to bilateral-space:\nP T (z) = [S T 0 S T 1 . . . S T K\u22121 z, . . . , S T 0 S T 1 z, S T 0 z, z](18)\nWe compute P (y) and P T (z) efficiently from the bottom up and the top down, respectively, by reusing the information from the previous scale.", "publication_ref": ["b71"], "figure_ref": [], "table_ref": []}, {"heading": "Robustness", "text": "Though the quadratic data term of Equation 1 enables our fast least-squares formulation, it has the natural consequence that the bilateral solver is sensitive to outliers in the input target (unless those outliers have been assigned a low confidence). For some applications where the input target has non-Gaussian noise we may wish to be robust to outliers. We therefore present a robustified variant of our bilateral solver, that we will call the \"robust bilateral solver\" (RBS). The RBS minimizes the following loss:\nminimize x \u03bb 2 i,j\u0174 i,j (x i \u2212 x j ) 2 + i \u03c1(x i \u2212 t i )(19)\nWhere \u03c1(\u2022) is some robust error function. Unless \u03c1(\u2022) is defined as (weighted) squared-error like in Equation 1, the optimization problem in Equation 19does not have a closed-form solution. However, Equation 19 can be solved using iteratively reweighted least squares (IRLS) [3] by repeatedly linearizing the loss function around the current estimate of x and then solving a least-squares problem corresponding to that linearization. The linearized version of Equation 19 in IRLS takes on exactly the same form as Equation 1, where the \"confidence\" c is replaced by the \"weight\" generated during IRLS. Thus we can produce a robust bilateral solver by wrapping the standard bilateral solver in a loop, recomputing the weight at each iteration. The RBS can be used with any standard robust loss function that would be used for M-estimation. We use the Geman-McClure loss function [10], a smooth approximation to the 0 -norm, whose estimator \u03c1(\u2022) and corresponding weight in IRLS are:\n\u03c1(e i ) = e 2 i \u03c3 2 gm + e 2 i w(e i ) = 2\u03c3 2 gm (\u03c3 2 gm + e 2 i ) 2 (20)\nwhere \u03c3 gm is a scale parameter. Pseudocode for the RBS with this Geman-McClure loss can be found in Algorithm 3. :\ni \u2190 i + 1 7: end while\nBecause our loss function is non-convex and therefore sensitive to initialization, our RBS interface takes as input some initial confidence c init that is used in the first least-squares solve, and then overwritten by the IRLS weights in subsequent iterations. Because the IRLS / robust M-estimation loop of the RBS is sensitive to initialization, we can improve performance by setting the initial weights used in the IRLS loop c init to reflect some noise model computed from the input to the solver. In the case of our Middlebury stereo experiment, we construct this initial confidence according to the heuristic observation that accurate depth maps tend to have contiguous image regions with low-variance depths. To identify such regions we compute an edge-aware measure of depth variance on the input depth map Z using the recursive formulation of the domain transform [9], which is a simple and fast edge-aware filter. To see how we do this, let us first review the definition of variance:\nVar(x) = E[x 2 ] \u2212 (E[x]) 2 (21)\nWhere E is the expectation operator. Any (normalized) linear image filtering operation with non-negative weights can be thought of as computing some local expectation of the input image for every pixel. When coupled with an edge-aware image filtering operation such as the domain transform (DT), we can compute a local edge-aware variance V of our input depth map Z as follows:\nV = DT(Z 2 ) \u2212 (DT(Z)) 2 (22)\nWe initialize our input confidence by exponentiating this scaled, negated variance:\nc init = exp \u2212 V 2\u03c3 2 dt (23\n)\nOur parameters are tuned to maximize performance on the Middlebury training set: \u03c3 xy = \u03c3 rgb = 32, \u03c3 dt = 2. We additionally modify this initial confidence using the observation that the depth map at one side of an image of each stereo pair generally has a poorly estimated depth, as the true match for those pixels are often not present in the other image of the stereo pair. We address this by setting the leftmost 80 columns of c init to 0, thereby causing them to be initially ignored. See Figure 1 for a visualization of the initial confidence estimated using this procedure on one of the test-set depth maps from the Middlebury stereo benchmark v3. ", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Multiple Output Channels", "text": "The tasks which we apply our bilateral solver to consist of inputs with a single channel (depth, stereo, etc) or many channels (21, for our semantic segmentation benchmark). As mentioned previously, our model generalizes straightforwardly to problems with n-channel \"target\" inputs by simply decomposing into n independent optimization problems with the same A matrix and different b vectors. By concatenating these y and b vectors into matrices, this can be rewritten as one large linear system:\nAY = B (24\n)\nFor applications such as semantic segmentation this B matrix is often very wide, but also very low-rank -many object categories may have extremely low probabilities in the input, and some object categories may be strongly correlated.\nIn these cases we can produce a reduced linear system with fewer right-handsides by producing a low-rank approximation to B, solving the resulting linear system, and then expanding our low-rank solution back to input space. This can dramatically speed up convergence, often by an order of magnitude, as many semantic segmentation algorithms often only assign a non-trivial probability to a small fraction of object categories for any given scene. Our approach is similar to a simplified and approximate version of \"block\" conjugate gradient [23].\nWe use a rank-revealing QR factorization [5] to reduce our B matrix, which is often used for similar tasks due to its stability and speed.\nBP = QR (25\n)\nWhere P is a permutation matrix, Q is an orthonormal basis for the columns of B, and R is an upper triangular matrix. With this, let us construct a modified factorization of B:\nB = Q R (26\n)\nWhere we construct R by taking RP T and then shuffling the rows of the resulting matrix such the rows of R have non-increasing Euclidean norms. Q is Q where the columns of Q have also been shuffled. Let us define a vector m which is the \"mass\" (squared Euclidean norm) of each row of R :\nm i = j R 2 i,j(27)\nLet us define some tolerance , which is an upper bound on the residual tolerance fraction of B that we are willing to tolerate. We find the largest value of t such that:\ni<t i=0 m i \u2264 (1 \u2212 ) i m i(28)\nWith this we can drop the least important rows of R and columns of Q:\nQ \u2248 Q [:, 1 : t]R \u2248 (R P T )[1 : t, :](29)\nWe can useQ to solve the reduced linear system, and then multiply the solution to that linear system byR to approximate the solution to the original system:\nY = (A \u22121Q )R(30)\nIn our semantic segmentation experiment, For small values of = 0.01 the output from this approximate is often indistinguishable from exact solution, despite being \u2248 5\u00d7 faster on average.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "Here we present many additional results for the four tasks explored in the main paper, in the form of additional figures and expanded tables of results, as well as details regarding the evaluation of baseline techniques.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Stereo", "text": "In the paper we demonstrated the value of our robust bilateral solver as a post-processing procedure for stereo algorithms, using the Middlebury Stereo Benchmark V3 [26]. See Figures 2-6 for examples of test set images from the Middlebury dataset in which we post-process the output of the state-of-the-art MC-CNN stereo technique [31], which we obtained using the publicly available source accompanying the technique. See Figures 7 and 8 for additional results on training set images from the Middlebury dataset, where we evaluate against a wider selection of stereo algorithms. See Figures 9 and 10 for results in which we have post-processed the training-set output of those these top-performing stereo algorithms with baseline edge-aware filtering or depth-map enhancement techniques. We present these results on the training set because the Middlebury benchmark makes the training-set output of other stereo algorithms freely available, while obtaining test-set results requires the code or cooperation of the authors of each technique, or re-implementing these techniques. The depth maps corresponding to each baseline stereo technique were therefore downloaded from the Middlebury website. The output corresponding to each post-processing technique we compare against were produced by us, while taking care to tune all parameters to maximize performance on the Middlebury training set (the geometric mean of all 6 error metrics) for the MC-CNN output (these parameters are then used for all other stereo techniques). For complete transparency, we will detail the procedure used to produce each baseline results:\nTF This is the tree-filtering technique of Yang [29], which we ran ourselves using the publicly available code 1 . The parameter settings used in these experiments are \u03c3 r = 0.25 with nonlocal filtering, which experimentation showed to be the optimal parameter settings for this task.\nFGF This is our own Matlab implementation of the (color) fast guided filter [11], which we found to be faster than the implementation built into Matlab 2015, and significantly faster than the released code 2 while producing identical results. The parameters were tuned for this task, with a box filter size of 8, = 0.01 2 , and a subsampling factor of 4. WMF This is the weighted median filter approach of Ma et al. [21], which we ran using the publicly available code 3 . Because this technique was designed for a similar use case to its use here, we used the same parameter settings as were use in the paper: r = max(width, height), = 0.01 2 , followed by a median filter. DT This is the recursive formulation of the domain transform [9] with optimallytuned parameters for this task (\u03c3 r = 64, \u03c3 s = 32).\nFor all Middlebury experiments the parameters of our RBS were: \u03c3 xy = \u03c3 l = \u03c3 uv = 4, \u03bb = 0.25, \u03c3 xy = \u03c3 rgb = 4, \u03c3 gm = 1, (the scale of the Geman-McClure loss function) and we performed 32 iterations of IRLS.\nOn our test-set results, we present six error metrics for each image: bad-1% (the percent of pixels whose disparity is wrong by more than 1), MAE (the mean absolute error of the disparity map) and RMSE (the root mean squared error of each disparity map), for all pixels and for only non-occluded pixels. We generally see a reduction in the MAE and RMSE error metrics, usually by around 50%, and a relatively unchanged bad-1% metrics, which suggests that our solver has a substantial and positive impact on quality. This improvement is quite clear when visualizing the output depth maps, as shown in Figures 2-6, suggesting that the \"all or nothing\" bad-1% metric does not seem to correlate well with the visual quality of the depth map. Our error reduction is roughly consistent across all choices of stereo techniques used to produce the input depth maps to our algorithm (though for all post-processing technique the improvement is most significant for MC-CNN, as that is the environment in which parameters were tuned). The baseline depth post-processing techniques we evaluate against often do reduce some error measures, though all tend to increase the bad 1% error measure, and none produce as substantial a reduction of MAE and RMSE as our approach. The improvement of our approach over those baseline approaches is evident upon visual inspection, as can be seen in Figures 9 and 10. Our test-set errors were taken from the Middlebury website, while training-set errors were produced with our own evaluation code. We do not report runtime for this task, as the runtime of our technique and all baselines is dominated by the time taken by the MC-CNN technique common among all entries.", "publication_ref": ["b69", "b74", "b72"], "figure_ref": ["fig_8", "fig_0", "fig_8", "fig_0"], "table_ref": []}, {"heading": "Stereo-based Defocus", "text": "Though the primary focus of this work is the bilateral solver and not the \"defocus\" task of Barron et al. [2], we would be remiss to omit a comparison of our technique with the optimization technique presented in [2], given the similarities between the two techniques. The stereo algorithm of [2] performs brittle block-matching on a rectified stereo pair to produce, for each pixel, an interval (lower and upper values [l i , u i ] parametrizing an interval) of likely depths for that pixel. This data term appears to have been chosen for its efficacy, and because its simple piecewise-linear form allowed this pixel-space loss to be easily \"splatted\" into bilateral space to construct a convex (though non-linear) optimization problem. This data term is not compatible with our bilateral solver, and so we must convert it to the expected input: a per-pixel \"target\" value and \"confidence\" measure. We simply use the average of the upper and lower interval as the target and the exponentiated negative length of the interval as the confidence:\nt i = (l i + u i )/2 c i = exp(l i \u2212 u i ) (31)\nThis simple reparametrization combined with our bilateral solver produces an effective stereo technique for this \"defocus\" task, while being roughly 3.5\u00d7 faster than the already-efficient solver of [2]. See Figures 11 and 12 for a visualization of our performance relative to [2], using some of the stereo pairs from [2]. Though this is only a modest improvement over [2], it is reassuring that our generalpurpose bilateral solver not only applies to a host of problems in computer vision, but also performs at least as well as its much more specialized precursor technique.\nNote that [2] reported large errors on the Middlebury V2 dataset, while our technique can be used for both accurate depth maps and pleasing graphical effects.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Depth Superresolution", "text": "In Table 2 we present an expanded form of the depth superresolution results presented in the main paper, in which the task is broken down into its constituent images and scale factors, as was done in past work [8,16]. Our bilateral solver appears to be roughly the second or third most accurate technique, after [16] and sometimes [18]. But it should be noted that these top-performing techniques [14,16,18] are all dictionary-based techniques which are trained on a great deal of data, while our technique produces competitive results despite the simplicity of our model and our lack of training. What is perhaps the most important property of our model is its speed -our technique 600-3000\u00d7 faster than the three most accurate techniques, despite having comparable accuracy to all but [16]. Our performance is most competitive when the upsampling factor is large (16\u00d7) which is when the task is inherently most difficult. Additionally, those techniques with speeds comparable to or better than the bilateral solver [9,29,11,22] produce error rates that are 25-40% greater than our approach. The only techniques with significantly faster runtimes than the bilateral solver are standard image interpolation techniques (bilinear, bicubic, etc) which produce low-quality output, and our implementation of the domain transform [9] which is a highly-optimized, vectorized, and multi-threaded implementation, unlike our own technique and all other techniques we compare against. More conventional implementations of the domain transform appear to have runtimes comparable to our own, or that of the guided filter [12]. See Figures 13-15 for example output for this task.\nFor transparency and completeness we evaluated against as many applicable baseline techniques as was possible. This is difficult, as though many papers present results for denoising or upsampling different versions of the Middlebury dataset, there is not one standard benchmark which is universally adopted. To this end, we build upon the benchmarked used in [8], but augment it heavily. We inherit some results from past work [8,16] which is necessary due to the lack of publicly available source code for many techniques. This means that some runtimes are produced on other hardware platforms, and so these runtimes should be considered accordingly. Our own runtimes (indicated in Table 2 in white) were benchmarked on a 2012 HP Z420 workstation (Intel Xeon CPU E5-1650, 3.20GHz, 32 GB RAM), and our algorithm is implemented in standard, single-threaded C++. Runtimes highlighted with a color come from some other hardware platform other than our reference hardware. For clarity, we will now detail the experimental conditions of each baseline technique, both in terms of parameter settings and hardware environments. For all experiments in which we produced the model output, the parameters of each algorithm were tuned to minimize the average error on this task by starting with the baseline parameters in the publicly available code, and then performing coordinate descent on each parameter, halving and doubling each and taking the new parameter setting if the average error decreased. For all models in which the code was ran by us, the runtime reported is the median of the runtime over all images in the dataset, unless the model's runtime is resolution-dependent, in which case we report the geometric mean of the runtimes.\nTable 2: Performance on the depth superresolution task of [8]. We report rootmeans-squared error, as was done in [16], along with the geometric mean of those errors over the entire dataset. Times other than our own are indicated by colors: Green runtimes are from [8], blue runtimes are from [16], pink runtimes are from [20], and the teal runtime is from [21]. The beige runtimes were produced by us, but on a different, faster computer. Algorithms which use external training data are indicated with a dagger. K This is the technique presented in Lu & Forsyth 2015 [20]. The authors of [20] ran their own code on the task presented here on their own computer (with comparable specifications to our own) at our request, sent us the output, and reported their approximate runtime, which we report here. L This is the technique presented in Park et al. [24], which was used as a baseline algorithm in [8]. We did not run this code ourselves, and produced these error rates using the precomputed output from [8], which is why we do not have runtimes. M This is the recursive formulation of the domain transform [9] with optimallytuned parameters (\u03c3 r = 64, \u03c3 s = 8f ). We used our own highly optimized implementation of this code, implemented in Halide, with heavily parallelization and vectorization. This is unlike most other baselines and our own algorithm, which are single-threaded unoptimized code. N This is the weighted median filter of [21], which we ran ourselves using the publicly available code 7 . We found the color version of the code (which we used for its improved accuracy) to perform slowly, so the runtime we cite is taken by extrapolating from the quoted runtime for the CPU implementation of [21], (60ms per megapixel-disparity) on a comparable computer to ours, suggesting that runtime on this task would be \u223c 18 seconds per image (\u223c 200 disparities, \u223c 1.5 megapixels per image). The parameters were tuned for optimal performance on our task: filter size = 2 f (where f is the upsampling factor) and = 0.02 2 . O This is the implementation of the guided filter [12] which is built into the 2015 version of Matlab. The parameters were tuned for this task, \"Neighborhood-Size\" = 3 \u00d7 2 f , (where f is the upsampling factor) and \"DegreeOfSmoothing\" = 0.5. P This is the weighted median filter of [33], which we ran ourselves using the publicly available code 8 . Because the code was only available as a compiled windows binary, we were forced to use a different computer for this evaluation, and so the runtime is for a significantly faster computer than was used for our other evaluation: A dual-processor Xeon CPU-E5-2690 v3 2.6GHz with 64 GB of ram. The runtime should therefore be considered a lower bound on the actual runtime for the reference hardware. We used the default parameter settings provided with the reference code for our experiments, which we found to perform optimally for our benchmark. Q This is our own Matlab implementation of the (color) fast guided filter [11], which we found to be faster than the implementation built into Matlab 2015, and significantly faster than the released code 9 while producing identical results. The parameters were tuned for this task, with a box filter size of 2 f (where f is the upsampling factor), = 0.02 2 , and a subsampling of 2.\nOur experimentation suggests that the subsampling could be made more aggressive with little drop in accuracy, but because the algorithm requires that the filter size must be divisible by the subsampling factor, the most aggressive subsampling we could use for all upsampling factors was 2. From this we can assume that a 4\u00d7 speedup may be possible. R This is the technique presented in Yang [29], which we ran ourselves using the publicly available code 10 . Because the code was only available as a compiled windows binary, like in Model P this evaluation was performed on a different, faster workstation, and so the runtime should be considered a lower bound on the actual runtime for the reference hardware. The parameter settings used in these experiments are \u03c3 r = 2 (f \u22126) (where f is the upsampling factor) and nonlocal filtering, which experimentation showed to be the optimal parameter settings for this task. S This is the technique presented in Yang et al. [30], which was used as a baseline algorithm in [8]. We did not run this code ourselves, and produced these error rates using the precomputed output from [8], which is why we do not have runtimes. T This is the WLS model of Farbman et al. [7], which we ran ourselves using the publicly available code 11 , with the code was modified to use non-log color reference images. The parameter settings used in these experiments are \u03bb = 5000 \u00d7 2 (f \u22124) (where f is the upsampling factor) and \u03b1 = 2, which experimentation showed to be the optimal parameter settings for this task. U This model is standard joint bilateral upsampling [15] using a permutohedral lattice [1] with optimally-tuned parameters (\u03c3 rgb = 8, \u03c3 x = \u03c3 y = 8f , where f is the upsampling factor). These errors and runtimes were produced by us using a C++ implementation of the permutohedral lattice 12 . V These errors and runtimes were taken from the website 13 of [8]. Since the publication of this paper, it has been revealed that the error cited in the publication is MAE, not RMSE, so the errors in the paper are incorrect. For details, see the supplement 14 of [16]. W This is the technique of Li et al. [18], with errors and runtimes taken directly from [16]. X This is the technique of Kwon et al. [16], with errors and runtimes taken directly from [16]. We attempted to obtain the output depth maps or source code from [16], but the authors were unable to comply with our request, and so we are unable to present the results of [16] in our figures or perform a more detailed analysis of how well the algorithm performs, nor can we reproduce these results. Details on the lack of availability of the source and output from this model can be found on the project website 15 .", "publication_ref": ["b72", "b76", "b72", "b73", "b0"], "figure_ref": [], "table_ref": ["tab_1", "tab_1", "tab_1"]}, {"heading": "Colorization", "text": "See Figure 16 for a comparison of our technique on the colorization task, compared against Levin et al. [17]. The images and code from [17] were taken from the paper's website 16 , and were produced using the exact least-square solver presented in the paper for still image processing. Note that [17] also presents an approximate multigrid optimization which they use for colorizing videos, which is 6\u00d7 faster than their exact still image approach but presumably produces inexact results for the still image task. Several of the techniques we evaluate against for the depth super-resolution task can also be used for colorization, presumably with the same tradeoffs between accuracy and speed seen in that experiment. Since there is traditionally no ground-truth for this task, we do not present an exhaustive evaluation here.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Semantic Segmentation", "text": "See Figure 17 for additional examples of our bilateral solver and competing techniques applied to the semantic segmentation task. The bilateral solver produces more edge-aware results than CRF-based techniques on well-isolated objects.   [26] where our robust bilateral solver is used to improve the depth map predicted by the state-of-the-art MC-CNN technique [31]. On the top we have the depth map produced by [31] (with zoomed in regions) which is used as the target in our solver. On the bottom we have the output of our solver, where we see that quality is significantly improved. We report the error for each depth map in terms of the percent of pixels whose disparity is off by more than 1 (\"bad 1%\"), the mean-absolute-error of the disparity, and the root-mean-squared-error of the disparity.        [26] where our robust bilateral solver is used to improve the depth map predicted by four top-performing stereo algorithms. On the left we have the depth map produced by each stereo algorithm (with zoomed in regions) which is used as the target in our solver. On the right we have the output of our solver, where we see that quality is significantly improved.  [26] in the same format as Figure 7. Fig. 9: Results on the training set of the Middlebury Stereo Dataset V3 [26], in which we compare our robust bilateral solver against several baseline techniques for post-processing depth maps. Our model's output exhibits much higher quality than the input or any baseline, especially at the discontinuities shown in the cropped regions.     Fig. 12: Additional output for the stereo defocus task of [2], in the same format as Figure 11. (e) Chan et al. [4] (f) GF [12,8] (g) Min et al. [22] (h) \u2020 Lu [20] (i) Park et al. [24] (j) DT [9] (k) Ma et al. [21] (l) Zhang et al. [33] (m) FGF [11] (n) Yang 2015 [29] (o) Yang 2007 [30] (p) WLS [7] (q) JB [1,15] (r) Ferstl et al. [8] (s) \u2020 Liet al. [18] (t) BS (Ours)  (e) Chan et al. [4] (f) GF [12,8] (g) Min et al. [22] (h) \u2020 Lu [20] (i) Park et al. [24] (j) DT [9] (k) Ma et al. [21] (l) Zhang et al. [33] (m) FGF [11] (n) Yang 2015 [29] (o) Yang 2007 [30] (p) WLS [7] (q) JB [1,15] (r) Ferstl et al. [8] (s) \u2020 Liet al. [18] (t) BS (Ours) Fig. 14: More results for the depth superresolution task. (e) Chan et al. [4] (f) GF [12,8] (g) Min et al. [22] (h) \u2020 Lu [20] (i) Park et al. [24] (j) DT [9] (k) Ma et al. [21] (l) Zhang et al. [33] (m) FGF [11] (n) Yang 2015 [29] (o) Yang 2007 [30] (p) WLS [7] (q) JB [1,15] (r) Ferstl et al. [8] (s) \u2020 Liet al. [18] (t) BS (Ours) Fig. 15: More results for the depth superresolution task. Fig. 16: Results for the colorization task, using the images and scribbles from [17]. Our algorithm's output is nearly indistinguishable from that of [17], while being 95\u00d7 faster. ", "publication_ref": ["b69", "b74", "b74", "b69", "b69", "b69", "b76", "b72", "b73", "b0", "b76", "b72", "b73", "b0", "b76", "b72", "b73", "b0"], "figure_ref": ["fig_1", "fig_19", "fig_1", "fig_1", "fig_1", "fig_1", "fig_1"], "table_ref": []}, {"heading": "", "text": "A This is nearest-neighbor interpolation, and the reported runtime is that of the Matlab imresize() function on our workstation. B This is bicubic interpolation, and the reported runtime is that of the Matlab imresize() function on our workstation. C This is the technique of Kiechle et al. [14], with errors and runtimes taken directly from [16]. D This is bilinear interpolation, and the reported runtime is that of the Matlab imresize() function on our workstation. E This is the Joint Geodesic Upsampling technique of [19], which we ran ourselves using the publicly available code 4 . This technique performs poorly for this task, possibly because it assumes noise-free input. We used the default parameters of the code, which we found optimal for this task: interval = 3, \u03c3 = 0.5, \u03bb 1 = 10, \u03bb 2 = 1. F This is the Mutual-Structure technique of Shen et al. [27], which we ran ourselves using the publicly available code 5 . This technique performs poorly on this task, which appears to be due to the low-frequency nature of the depth-map noise inherent in this depth super-resolution task, unlike the highfrequency, per-pixel noise used in the experiments of [27]. The parameters were tuned for optimal performance on our task: I = 10 \u22125 , G = 2 \u00d7 10 \u22124 , \u03bb I = 1, \u03bb G = 4, 20 iterations, window size of 2. A more aggressive smoothing effect could be achieved using larger windows sizes which were a function of the upsampling factor, but these oversmoothed depths had significantly higher errors than was produced using these settings. G This is the technique presented in Diebel & Thrun [6], which was used as a baseline algorithm in [8]. We did not run this code ourselves, and produced these error rates using the precomputed output from [8], which is why we do not have runtimes. H This is an implementation of Chan et al. [4], which was used as a baseline algorithm in [8]. We did not run this code ourselves, and produced these error rates using the precomputed output from [8], and reproduced the runtime quoted in [8]. I This is presumably an implementation of the guided filter [12], which was used as a baseline algorithm in [8]. We did not run this code ourselves, and produced these error rates using the precomputed output from [8], and we took the runtime quoted in [8]. Because the quoted runtime seems unusually slow for the guided filter, we ran two of our own evaluations of the guided filter on this task (models O and Q) which produced lower errors rates and significantly faster runtimes. J This is the weighted least-squares approach of Min et al. [22], which we ran ourselves using publicly available code 6 . The parameters were tuned for optimal performance on our task: \u03c3 = 0.00125\u00d72 f (where f is the upsampling factor), \u03bb = 30 2 , iteration = 3, attenuation = 4.", "publication_ref": ["b70", "b70"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Fast high-dimensional filtering using the permutohedral lattice", "journal": "Eurographics", "year": "2010", "authors": "A Adams; J Baek; M A Davis"}, {"ref_id": "b1", "title": "Fast bilateral-space stereo for synthetic defocus", "journal": "CVPR", "year": "2015", "authors": "J T Barron; A Adams; Y Shih; C Hern\u00e1ndez"}, {"ref_id": "b2", "title": "Shape, illumination, and reflectance from shading", "journal": "TPAMI", "year": "2015", "authors": "J T Barron; J Malik"}, {"ref_id": "b3", "title": "A noise-aware filter for real-time depth upsampling", "journal": "ECCV Workshops", "year": "2008", "authors": "D Chan; H Buisman; C Theobalt; S Thrun"}, {"ref_id": "b4", "title": "Real-time edge-aware image processing with the bilateral grid", "journal": "SIGGRAPH", "year": "2007", "authors": "J Chen; S Paris; F Durand"}, {"ref_id": "b5", "title": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "journal": "ICLR", "year": "2015", "authors": "L C Chen; G Papandreou; I Kokkinos; K Murphy; A L Yuille"}, {"ref_id": "b6", "title": "An application of markov random fields to range sensing", "journal": "NIPS", "year": "2005", "authors": "J Diebel; S Thrun"}, {"ref_id": "b7", "title": "On the origin of the bilateral filter and ways to improve it", "journal": "", "year": "2002", "authors": "M Elad"}, {"ref_id": "b8", "title": "Edge-preserving decompositions for multi-scale tone and detail manipulation", "journal": "SIGGRAPH", "year": "2008", "authors": "Z Farbman; R Fattal; D Lischinski; R Szeliski"}, {"ref_id": "b9", "title": "Image guided depth upsampling using anisotropic total generalized variation", "journal": "ICCV", "year": "2013", "authors": "D Ferstl; C Reinbacher; R Ranftl; M Ruether; H Bischof"}, {"ref_id": "b10", "title": "Domain transform for edge-aware image and video processing", "journal": "SIGGRAPH", "year": "2011", "authors": "E S L Gastal; M M Oliveira"}, {"ref_id": "b11", "title": "Adaptive manifolds for real-time high-dimensional filtering", "journal": "SIGGRAPH", "year": "2012", "authors": "E S L Gastal; M M Oliveira"}, {"ref_id": "b12", "title": "The lumigraph. SIGGRAPH", "journal": "", "year": "1996", "authors": "S J Gortler; R Grzeszczuk; R Szeliski; M F Cohen"}, {"ref_id": "b13", "title": "Robust Statistics -The Approach Based on Influence Functions", "journal": "Wiley", "year": "1986", "authors": "F R Hampel; E M Ronchetti; P J Rousseeuw; W A Stahel"}, {"ref_id": "b14", "title": "Semantic contours from inverse detectors. ICCV", "journal": "", "year": "2011", "authors": "B Hariharan; P Arbelaez; L Bourdev; S Maji; J Malik"}, {"ref_id": "b15", "title": "Fast guided filter", "journal": "", "year": "2015", "authors": "K He; J Sun"}, {"ref_id": "b16", "title": "Guided image filtering. ECCV", "journal": "", "year": "2010", "authors": "K He; J Sun; X Tang"}, {"ref_id": "b17", "title": "Matrix backpropagation for deep networks with structured layers", "journal": "ICCV", "year": "2015", "authors": "C Ionescu; O Vantzos; C Sminchisescu"}, {"ref_id": "b18", "title": "A joint intensity and depth co-sparse analysis model for depth map super-resolution", "journal": "ICCV", "year": "2013", "authors": "M Kiechle; S Hawe; M Kleinsteuber"}, {"ref_id": "b19", "title": "Joint bilateral upsampling. SIGGRAPH", "journal": "", "year": "2007", "authors": "J Kopf; M F Cohen; D Lischinski; M Uyttendaele"}, {"ref_id": "b20", "title": "Combinatorial preconditioners and multilevel solvers for problems in computer vision and image processing", "journal": "CVIU", "year": "2011", "authors": "I Koutis; G L Miller; D Tolliver"}, {"ref_id": "b21", "title": "Efficient inference in fully connected crfs with gaussian edge potentials", "journal": "NIPS", "year": "2011", "authors": "P Kr\u00e4henb\u00fchl; V Koltun"}, {"ref_id": "b22", "title": "Efficient preconditioning of laplacian matrices for computer graphics", "journal": "SIGGRAPH", "year": "2013", "authors": "D Krishnan; R Fattal; R Szeliski"}, {"ref_id": "b23", "title": "Data-driven depth map refinement via multi-scale sparse representation", "journal": "CVPR", "year": "2015", "authors": "H Kwon; Y W Tai; S Lin"}, {"ref_id": "b24", "title": "Colorization using optimization. SIGGRAPH", "journal": "", "year": "2004", "authors": "A Levin; D Lischinski; Y Weiss"}, {"ref_id": "b25", "title": "Method Art Books Moebius Avg", "journal": "", "year": "", "authors": ""}, {"ref_id": "b26", "title": "A)", "journal": "", "year": "", "authors": ""}, {"ref_id": "b27", "title": "", "journal": "", "year": "", "authors": " C) \u2020kiechle"}, {"ref_id": "b28", "title": "", "journal": "", "year": "", "authors": "E) Liu"}, {"ref_id": "b29", "title": "", "journal": "", "year": "", "authors": "F) Shen"}, {"ref_id": "b30", "title": "", "journal": "", "year": "", "authors": " J) Min"}, {"ref_id": "b31", "title": "", "journal": "", "year": "", "authors": "K Forsyth"}, {"ref_id": "b32", "title": "", "journal": "", "year": "", "authors": "L) Park"}, {"ref_id": "b33", "title": "", "journal": "", "year": "", "authors": "N) Ma"}, {"ref_id": "b34", "title": "", "journal": "", "year": "", "authors": " O) Guidedfilter"}, {"ref_id": "b35", "title": "", "journal": "", "year": "", "authors": " Zhang"}, {"ref_id": "b36", "title": "", "journal": "", "year": "2015", "authors": "R) ; Yang "}, {"ref_id": "b37", "title": "", "journal": "", "year": "2007", "authors": "S) ; Yang "}, {"ref_id": "b38", "title": "", "journal": "", "year": "", "authors": " Farbman"}, {"ref_id": "b39", "title": "", "journal": "", "year": "", "authors": " V) Ferstl"}, {"ref_id": "b40", "title": "", "journal": "", "year": "", "authors": " W) \u2020li"}, {"ref_id": "b41", "title": "", "journal": "", "year": "", "authors": " X) \u2020kwon"}, {"ref_id": "b42", "title": "", "journal": "", "year": "", "authors": "Y) Bs"}, {"ref_id": "b43", "title": "", "journal": "", "year": "", "authors": " Mc-Cnn"}, {"ref_id": "b44", "title": "Fast high-dimensional filtering using the permutohedral lattice", "journal": "Eurographics", "year": "2010", "authors": "A Adams; J Baek; M A Davis"}, {"ref_id": "b45", "title": "Fast bilateral-space stereo for synthetic defocus", "journal": "CVPR", "year": "2015", "authors": "J T Barron; A Adams; Y Shih; C Hern\u00e1ndez"}, {"ref_id": "b46", "title": "The fitting of power series, meaning polynomials, illustrated on band-spectroscopic data", "journal": "Technometrics", "year": "1974", "authors": "A E Beaton; J W Tukey"}, {"ref_id": "b47", "title": "A noise-aware filter for real-time depth upsampling", "journal": "ECCV Workshops", "year": "2008", "authors": "D Chan; H Buisman; C Theobalt; S Thrun"}, {"ref_id": "b48", "title": "Rank revealing qr factorizations", "journal": "", "year": "1987", "authors": "T F Chan"}, {"ref_id": "b49", "title": "An application of markov random fields to range sensing", "journal": "NIPS", "year": "2005", "authors": "J Diebel; S Thrun"}, {"ref_id": "b50", "title": "Edge-preserving decompositions for multi-scale tone and detail manipulation", "journal": "SIGGRAPH", "year": "2008", "authors": "Z Farbman; R Fattal; D Lischinski; R Szeliski"}, {"ref_id": "b51", "title": "Image guided depth upsampling using anisotropic total generalized variation", "journal": "ICCV", "year": "2013", "authors": "D Ferstl; C Reinbacher; R Ranftl; M Ruether; H Bischof"}, {"ref_id": "b52", "title": "Domain transform for edge-aware image and video processing", "journal": "SIGGRAPH", "year": "2011", "authors": "E S L Gastal; M M Oliveira"}, {"ref_id": "b53", "title": "Statistical methods for tomographic image reconstruction", "journal": "Bull. Internat. Statist. Inst", "year": "1987", "authors": "S Geman; D E Mcclure"}, {"ref_id": "b54", "title": "Fast guided filter", "journal": "", "year": "2015", "authors": "K He; J Sun"}, {"ref_id": "b55", "title": "Guided image filtering. ECCV", "journal": "", "year": "2010", "authors": "K He; J Sun; X Tang"}, {"ref_id": "b56", "title": "Accurate and efficient stereo processing by semi-global matching and mutual information", "journal": "CVPR", "year": "2005", "authors": "H Hirschm\u00fcller"}, {"ref_id": "b57", "title": "A joint intensity and depth co-sparse analysis model for depth map super-resolution", "journal": "ICCV", "year": "2013", "authors": "M Kiechle; S Hawe; M Kleinsteuber"}, {"ref_id": "b58", "title": "Joint bilateral upsampling. SIGGRAPH", "journal": "", "year": "2007", "authors": "J Kopf; M F Cohen; D Lischinski; M Uyttendaele"}, {"ref_id": "b59", "title": "Data-driven depth map refinement via multi-scale sparse representation", "journal": "CVPR", "year": "2015", "authors": "H Kwon; Y W Tai; S Lin"}, {"ref_id": "b60", "title": "Colorization using optimization. SIGGRAPH", "journal": "", "year": "2004", "authors": "A Levin; D Lischinski; Y Weiss"}, {"ref_id": "b61", "title": "Joint example-based depth map super-resolution", "journal": "ICME", "year": "2012", "authors": "Y Li; T Xue; L Sun; J Liu"}, {"ref_id": "b62", "title": "Joint geodesic upsampling of depth images", "journal": "CVPR", "year": "2013", "authors": "M Y Liu; O Tuzel; Y Taguchi"}, {"ref_id": "b63", "title": "Sparse depth super resolution", "journal": "CVPR", "year": "2015", "authors": "J Lu; D Forsyth"}, {"ref_id": "b64", "title": "Constant time weighted median filtering for stereo matching and beyond. ICCV", "journal": "", "year": "2013", "authors": "Z Ma; K He; Y Wei; J Sun; E Wu"}, {"ref_id": "b65", "title": "Fast global image smoothing based on weighted least squares. Transactions on Image Processing", "journal": "", "year": "2014", "authors": "D Min; S Choi; J Lu; B Ham; K Sohn; M N Do"}, {"ref_id": "b66", "title": "The block conjugate gradient algorithm and related methods", "journal": "Linear Algebra and its applications", "year": "1980", "authors": "D P O'leary"}, {"ref_id": "b67", "title": "High quality depth map upsampling for 3d-tof cameras. ICCV", "journal": "", "year": "2011", "authors": "J Park; H Kim; Y W Tai; M S Brown; I Kweon"}, {"ref_id": "b68", "title": "Map disparity estimation using hidden markov trees. ICCV", "journal": "", "year": "2015", "authors": "E Psota; J Kowalczuk; M Mittek; L P\u00e9rez"}, {"ref_id": "b69", "title": "High-resolution stereo datasets with subpixel-accurate ground truth", "journal": "GCPR", "year": "2014", "authors": "D Scharstein; H Hirschm\u00fcller; Y Kitajima; G Krathwohl; N Nesic; X Wang; P Westling"}, {"ref_id": "b70", "title": "Mutual-structure for joint filtering. ICCV", "journal": "", "year": "2015", "authors": "X Shen; C Zhou; L Xu; J Jia"}, {"ref_id": "b71", "title": "An introduction to the conjugate gradient method without the agonizing pain", "journal": "", "year": "1994", "authors": "J R Shewchuk"}, {"ref_id": "b72", "title": "Stereo matching using tree filtering", "journal": "PAMI", "year": "2015", "authors": "Q Yang"}, {"ref_id": "b73", "title": "Spatial-depth super resolution for range images", "journal": "CVPR", "year": "2007", "authors": "Q Yang; R Yang; J Davis; D Nist\u00e9r"}, {"ref_id": "b74", "title": "Computing the stereo matching cost with a convolutional neural network", "journal": "CVPR", "year": "2015", "authors": "J Zbontar; Y Lecun"}, {"ref_id": "b75", "title": "Meshstereo: A global stereo model with mesh alignment regularization for view interpolation", "journal": "ICCV", "year": "2015", "authors": "C Zhang; Z Li; Y Chen; R Cai; H Chao; Y Rui"}, {"ref_id": "b76", "title": "100+ times faster weighted median filter (wmf). CVPR", "journal": "", "year": "2014", "authors": "Q Zhang; L Xu; J Jia"}], "figures": [{"figure_label": "a", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "( a )aInput (MAE = 6.00, RMSE = 38.8) (b) Output (MAE = 3.02, RMSE = 17.9) (c) Input Confidence (d) Input Reference", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Fig. 1 :1Fig.1:The bilateral solver can be used to improve depth maps. A depth map (a) from a state-of-the-art stereo method [43] is processed with our robust bilateral solver using a reference RGB image (d). Our output (b) is smooth with respect to the reference image, resulting in a 50% reduction in error.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "2http://vision.middlebury.edu/stereo/eval3/", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "(a) Input Image (b) True Depth (c) Input Depth (d) JBU[1,20]    ", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "(a) Input (b) Levin et al.[25] (c) Our results", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Fig. 4 :4Fig.4: Results for the user-assisted colorization task. Our bilateral solver produces comparable results to the technique of Levin et al.[25]  while being 95\u00d7 faster.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Fig. 5 :5Fig.5: Using the DeepLab CNN-based semantic segmentation algorithm[6]  (5b) as input our bilateral solver can produce comparable edge-aware output (5d) to the DenseCRF[22]  used in[6]  (5c), while being 8\u00d7 faster.", "figure_data": ""}, {"figure_label": "26", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "26 .26Li, Y., Xue, T., Sun, L., Liu, J.: Joint example-based depth map super-resolution. ICME (2012) 27. Liu, M.Y., Tuzel, O., Taguchi, Y.: Joint geodesic upsampling of depth images. CVPR (2013) 28. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. CVPR (2015) 29. Lu, J., Forsyth, D.: Sparse depth super resolution. CVPR (2015) 30. Ma, Z., He, K., Wei, Y., Sun, J., Wu, E.: Constant time weighted median filtering for stereo matching and beyond. ICCV (2013) 31. Min, D., Choi, S., Lu, J., Ham, B., Sohn, K., Do, M.N.: Fast global image smoothing based on weighted least squares. Transactions on Image Processing (2014) 32. Park, J., Kim, H., Tai, Y.W., Brown, M.S., Kweon, I.: High quality depth map upsampling for 3d-tof cameras. ICCV (2011) 33. Scharstein, D., Hirschm\u00fcller, H., Kitajima, Y., Krathwohl, G., Nesic, N., Wang, X., Westling, P.: High-resolution stereo datasets with subpixel-accurate ground truth. GCPR (2014) 34. Scharstein, D., Szeliski, R.: A taxonomy and evaluation of dense two-frame stereo correspondence algorithms. IJCV (2002) 35. Shen, X., Zhou, C., Xu, L., Jia, J.: Mutual-structure for joint filtering. ICCV (2015) 36. Shewchuk, J.R.: An introduction to the conjugate gradient method without the agonizing pain. Tech. rep., Carnegie Mellon University (1994) 37. Smith, S.M., Brady, J.M.: Susan -a new approach to low level image processing. IJCV (1997) 38. Szeliski, R.: Fast surface interpolation using hierarchical basis functions. TPAMI (1990) 39. Szeliski, R.: Locally adapted hierarchical basis preconditioning. SIGGRAPH (2006) 40. Tomasi, C., Manduchi, R.: Bilateral filtering for gray and color images. ICCV (1998) 41. Yang, Q.: Stereo matching using tree filtering. PAMI (2015) 42. Yang, Q., Yang, R., Davis, J., Nist\u00e9r, D.: Spatial-depth super resolution for range images. CVPR (2007) 43. Zbontar, J., LeCun, Y.: Computing the stereo matching cost with a convolutional neural network. CVPR (2015) 44. Zhang, Q., Xu, L., Jia, J.: 100+ times faster weighted median filter (wmf). CVPR (2014) 45. Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V., Su, Z., Du, D., Huang, C., Torr, P.: Conditional random fields as recurrent neural networks. ICCV (2015)", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Algorithm 22Preconditioned Conjugate Gradients, reproduced from [28] Input: A(\u2022) // A function which implements Ax b // The b vector in the linear system x // The initial value of the state x M \u22121 (\u2022) // A function which implements a preconditioner n // the number of iterations Output:", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Algorithm 33The Geman-McClure Robust Bilateral Solver Input: solve(\u2022) // The bilateral solver t // The input target vector c init // The input confidence vector \u03c3 gm // The scale parameter of our Geman-McClure function n // The number of IRLS iterations Output: x // x such that Equation 19 is minimized 1: c \u2190 c init 2: while i < n do 3:x \u2190 solve(t, c) 4: e \u2190 (x \u2212 t)", "figure_data": ""}, {"figure_label": "a1", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "( a )Fig. 1 :a1Fig.1: When processing the depth maps produced by other stereo algorithms, we first use an edge-aware variance estimation technique to produce initial confidence measures used by our robust bilateral solver. This procedure downweights contiguous image regions with inconsistent depths.", "figure_data": ""}, {"figure_label": "a", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "( a )aMC-CNN[31] bad 1% = 10.1 MAE = 1.69 RMSE = 9.60 (b) MC-CNN[31] + RBS bad 1% = 10.7 MAE = 1.63 RMSE = 8.72", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "Fig. 2 :2Fig.2: Results on the test set of the Middlebury Stereo Dataset V3[26] where our robust bilateral solver is used to improve the depth map predicted by the state-of-the-art MC-CNN technique[31]. On the top we have the depth map produced by[31] (with zoomed in regions) which is used as the target in our solver. On the bottom we have the output of our solver, where we see that quality is significantly improved. We report the error for each depth map in terms of the percent of pixels whose disparity is off by more than 1 (\"bad 1%\"), the mean-absolute-error of the disparity, and the root-mean-squared-error of the disparity.", "figure_data": ""}, {"figure_label": "a", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "( a )aMC-CNN[31] bad 1% = 23.4 MAE = 17.1 RMSE = 67.4 (b) MC-CNN[31] + RBS bad 1% = 24.4 MAE = 4.30 RMSE = 19.9", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "Fig. 3 :3Fig. 3: More results on the test set of the Middlebury Stereo Dataset V3 [26] in the same format as Figure 2.", "figure_data": ""}, {"figure_label": "a", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "( a )aMC-CNN[31] bad 1% = 25.0 MAE = 2.47 RMSE = 23.2 (b) MC-CNN[31] + RBS bad 1% = 27.1 MAE = 2.81 RMSE = 24.2", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "Fig. 4 :4Fig.4: More results on the test set of the Middlebury Stereo Dataset V3[26] in the same format as Figure2.", "figure_data": ""}, {"figure_label": "a95", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "( a ) 9 Fig. 5 :a95Fig.5: More results on the test set of the Middlebury Stereo Dataset V3[26] in the same format as Figure2.", "figure_data": ""}, {"figure_label": "a96", "figure_type": "figure", "figure_id": "fig_18", "figure_caption": "( a ) 9 Fig. 6 :a96Fig.6: More results on the test set of the Middlebury Stereo Dataset V3[26] in the same format as Figure2.", "figure_data": ""}, {"figure_label": "7", "figure_type": "figure", "figure_id": "fig_19", "figure_caption": "Fig. 7 :7Fig. 7: Results on the training set of the Middlebury Stereo Dataset V3[26] where our robust bilateral solver is used to improve the depth map predicted by four top-performing stereo algorithms. On the left we have the depth map produced by each stereo algorithm (with zoomed in regions) which is used as the target in our solver. On the right we have the output of our solver, where we see that quality is significantly improved.", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_20", "figure_caption": "Fig. 8 :8Fig. 8: More results on the training set of the Middlebury Stereo Dataset V3[26] in the same format as Figure7.", "figure_data": ""}, {"figure_label": "a", "figure_type": "figure", "figure_id": "fig_21", "figure_caption": "( a )aMC-CNN[31] (b) MC-CNN[31] + RBS (Ours) (c) MC-CNN[31] + TF [29] (d) MC-CNN[31] + WMF [21](e) MC-CNN[31] + FGF[11]   (f) MC-CNN[31] + DT[9]    ", "figure_data": ""}, {"figure_label": "a", "figure_type": "figure", "figure_id": "fig_22", "figure_caption": "( a )aMC-CNN[31] (b) MC-CNN[31] + RBS (Ours) (c) MC-CNN[31] + TF [29] (d) MC-CNN[31] + WMF [21](e) MC-CNN[31] + FGF[11]   (f) MC-CNN[31] + DT[9]    ", "figure_data": ""}, {"figure_label": "10", "figure_type": "figure", "figure_id": "fig_23", "figure_caption": "Fig. 10 :10Fig. 10: More results on the training set of the Middlebury Stereo Dataset V3[26] in the same format as Figure9.", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_25", "figure_caption": "Fig. 11 :11Fig.11: Given the reparametrized input into the solver of[2]  (b and c) our solver can produce depth maps and defocused renderings of a comparable quality to[2], while being 3.5\u00d7 faster.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_27", "figure_caption": "Liu et al.[19]   (d) Shen et al.[27] ", "figure_data": ""}, {"figure_label": "13", "figure_type": "figure", "figure_id": "fig_28", "figure_caption": "Fig. 13 :13Fig. 13: Results for the depth superresolution task. Algorithms are sorted according to their average error on this benchmark, from upper left to lower right. Algorithms which use external training data are indicated with a dagger.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_29", "figure_caption": "Liu et al.[19]   (d) Shen et al.[27] ", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_30", "figure_caption": "Liu et al.[19]   (d) Shen et al.[27] ", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_31", "figure_caption": "(a) Input (b) Levin et al.[17] (c) Our results", "figure_data": ""}, {"figure_label": "17", "figure_type": "figure", "figure_id": "fig_32", "figure_caption": "Fig. 17 :17Fig. 17: Additional semantic segmentation results on Pascal VOC12 validation images. FCN refers to the fully convolutional network component of the end-toend trained CRF-RNN model. While the CRF-augmented DeepLab model (top rows) and CRF-RNN model (bottom rows) perform best overall, the bilateral solver produces better results on isolated objects (second and third images) at a fraction of the cost.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Our approach's runtime has a lower mean and variance than that of[2]. Runtimes are from the same workstation, averaged over the 20 4-megapixel images used in[2]  for profiling. Time (ms) Algorithm Component Barron et al.[2]   ", "figure_data": "This Work"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Our robust bilateral solver significantly improves depth map quality the state-of-the-art MC-CNN[43] stereo algorithm on the Middlebury dataset V3[33].", "figure_data": "MethodAllNoOccbad 1% MAE RMSE bad 1% MAE RMSETest SetMC \u2212 CNN[43] MC \u2212 CNN[43]+RBS28.1 17.9 55.0 18.0 3.82 21.3 28.2 8.19 29.9 18.9 2.67 15.0Training SetMC-CNN[43]"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Performance on the depth superresolution task of[10]. Runtimes in gray were not computed on our reference hardware, and algorithms which use external training data are indicated with a dagger.", "figure_data": "Method Nearest Neighbor 7.26 Err Time (sec) 0.003 Bicubic 5.91 0.007  \u2020Kiechle et al.[19] 5.86 450 Bilinear 5.16 0.004 Liu et al. [27] 5.10 16.60 Shen et al. [35] 4.24 31.48 Diebel & Thrun [7] 3.98 \u2212 Chan et al.[4] 3.83 3.02 GuidedFilter[17,10] 3.76 23.89 Min et al. [31] 3.74 0.383  \u2020Lu & Forsyth[29] 3.69 20 Park et al.[32] 3.61 24.05 . . .. . . Domain Transform [11] Ma et al. [30] GuidedFilter(Matlab)[17] 3.47 0.434 3.56 0.021 3.49 18 Zhang et al. [44] 3.45 1.346 FastGuidedFilter[16] 3.41 0.225 Yang 2015 [41] 3.41 0.304 Yang et al. 2007 [42] 3.25 \u2212 Farbman et al. [9] 3.19 6.11 JBU [1,20] 3.14 1.98 Ferstl et al.[10] 2.93 140 2.56 700  \u2020Li et al.[26] 1.21 300  \u2020Kwon et al.[24] BS (Ours) 2.70 0.234"}, {"figure_label": "44", "figure_type": "table", "figure_id": "tab_3", "figure_caption": ". To evaluate whether the bilateral solver could improve the efficiency of semantic segmentation pipelines, we use it instead of the CRF component in two state-of-the-art models: DeepLab-LargeFOV[6]  and CRF-RNN [45]. The DeepLab model consists of a CNN trained on Pascal VOC12 and then augmented with a fixed dense CRF. The CRF-RNN model generalizes the CRF with a recurrent neural network, and trains this component jointly with the CNN on Pascal and MSCOCO. As the bilateral solver operates on real-valued inputs, it is not immediately clear how to map it onto the discrete optimization problem of the dense CRF. For each class, we compute the 21-channel class probability image from the CNN Semantic segmentation results and runtimes on Pascal VOC 2012 validation set. The bilateral solver improves performance over the CNN output while being substantially faster than the CRF-based approaches. \"Post\" is the time spent post-processing the CNN output, which is the dense CRF for DeepLab, and the generalized CRF-RNN component for CRF-RNN. FCN is the convolutional neural network component of the CRF-RNN model. * DeepLab-LargeFOV model from [6] trained on Pascal VOC 2012 training data augmented with data from [15]. \u2020 CRF-RNN model from [45] trained with additional MSCOCO data and evaluated on reduced Pascal validation set of 346 images.", "figure_data": "MethodIOU(%)Time (ms) CNN Post TotalDeepLab62.25  *58058DeepLab + CRF67.64  *58 918 976DeepLab + BS(Ours) 66.00  *58 111 169CNN69.60  \u2020 7150 715CRF \u2212 RNN CNN + BS(Ours)72.96  \u2020 715 2214 2929 70.68  \u2020 715 217 913"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "TB S // A splat-blur-splice decomposition of W Output: D n , D m // Matrices to bistochastize W", "figure_data": "Algorithm 1 Bilateral-space bistochastization, reproduced from [2] Input: W = S 1: m \u2190 S1 2: n \u2190 1 3: while not converged do 4: n \u2190 (n \u2022 m)/(Bn) 5: end while arXiv:1511.03296v2 [cs.CV] 22 Jul 2016 6:6)"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Our RBS improves depth map quality for a variety of state-of-the-art stereo algorithms on the Middlebury Stereo Dataset V3[26]. Test-set numbers were taken from the Middlebury website, while training-set numbers were produced by our own evaluation code.", "figure_data": "MethodAllNoOccbad 1% MAE RMSE bad 1% MAE RMSETest SetMC \u2212 CNN[31]"}], "formulas": [{"formula_id": "formula_0", "formula_text": "minimize x \u03bb 2 i,j\u0174 i,j (x i \u2212 x j ) 2 + i c i (x i \u2212 t i ) 2 (1)", "formula_coordinates": [3.0, 171.71, 149.04, 357.08, 35.7]}, {"formula_id": "formula_1", "formula_text": "W i,j = exp \u2212 [[p x i ,p y i ]\u2212[p x j ,p y j ] 2 2\u03c3 2 xy \u2212 (p l i \u2212p l j ) 2 2\u03c3 2 l \u2212 [p u i ,p v i ]\u2212[p u j ,p v j ] 2 2\u03c3 2 uv (2)", "formula_coordinates": [3.0, 98.62, 272.33, 430.17, 34.06]}, {"formula_id": "formula_2", "formula_text": "W = S TB S(3)", "formula_coordinates": [3.0, 272.71, 502.94, 256.08, 15.25]}, {"formula_id": "formula_3", "formula_text": "W = S T D \u22121 m D nB D n D \u22121 m S SS T = D m (4)", "formula_coordinates": [3.0, 185.77, 599.77, 343.02, 17.75]}, {"formula_id": "formula_4", "formula_text": "x = S T y (5", "formula_coordinates": [3.0, 281.26, 674.23, 242.06, 15.25]}, {"formula_id": "formula_5", "formula_text": ")", "formula_coordinates": [3.0, 523.32, 676.65, 5.47, 12.84]}, {"formula_id": "formula_6", "formula_text": "minimize y 1 2 y T Ay \u2212 b T y + c (6) A = \u03bb(D m \u2212 D nB D n ) + diag(Sc) b = S(c \u2022 t) c = 1 2 (c \u2022 t) T t", "formula_coordinates": [4.0, 110.42, 91.42, 418.37, 63.46]}, {"formula_id": "formula_7", "formula_text": "Ay = b (7)", "formula_coordinates": [4.0, 284.53, 252.7, 244.26, 12.84]}, {"formula_id": "formula_8", "formula_text": "x = S T (A \u22121 b)(8)", "formula_coordinates": [4.0, 253.08, 297.76, 275.7, 34.82]}, {"formula_id": "formula_9", "formula_text": "Ay = b (9)", "formula_coordinates": [5.0, 280.94, 247.87, 247.85, 12.84]}, {"formula_id": "formula_10", "formula_text": "y = A \u22121 b (10)", "formula_coordinates": [5.0, 274.05, 318.77, 254.74, 15.57]}, {"formula_id": "formula_11", "formula_text": "\u2202 g \u2202 b = A \u22121 \u2202 g \u2202\u0177 \u2202 g \u2202 A = \u2212A \u22121 \u2202 g \u2202\u0177 \u0177 T = \u2212 \u2202 g \u2202 b\u0177 T (11", "formula_coordinates": [5.0, 159.79, 424.18, 363.3, 31.29]}, {"formula_id": "formula_12", "formula_text": ")", "formula_coordinates": [5.0, 523.09, 432.86, 5.71, 12.84]}, {"formula_id": "formula_13", "formula_text": "\u2202 g \u2202 diag(A) = \u2212 \u2202 g \u2202 b \u2022\u0177 (12)", "formula_coordinates": [5.0, 252.82, 541.83, 275.97, 31.68]}, {"formula_id": "formula_14", "formula_text": "y = A \u22121 bx = S T\u0177 (13)", "formula_coordinates": [5.0, 233.65, 660.81, 295.15, 15.57]}, {"formula_id": "formula_15", "formula_text": "\u2202 f \u2202 b = A \u22121 S \u2202 f \u2202x \u2202 f \u2202 diag(A) = \u2212 \u2202 f \u2202 b \u2022\u0177 (14)", "formula_coordinates": [6.0, 180.58, 85.8, 348.21, 31.68]}, {"formula_id": "formula_16", "formula_text": "\u2202 f \u2202 t = c \u2022 S T \u2202 f \u2202 b \u2202 f \u2202 c = S T \u2202 f \u2202 diag(A) + S T \u2202 f \u2202 b \u2022 t (15", "formula_coordinates": [6.0, 134.61, 203.53, 388.47, 31.68]}, {"formula_id": "formula_17", "formula_text": ")", "formula_coordinates": [6.0, 523.09, 212.22, 5.71, 12.84]}, {"formula_id": "formula_20", "formula_text": "diag(A) = \u03bb diag (D m ) \u2212 diag(D n )B diag diag(D n ) + Sc", "formula_coordinates": [7.0, 157.57, 175.76, 296.86, 20.7]}, {"formula_id": "formula_21", "formula_text": "M \u22121 jacobi (y) = diag(A) \u22121 y (18", "formula_coordinates": [7.0, 235.6, 270.39, 287.48, 18.64]}, {"formula_id": "formula_22", "formula_text": ")", "formula_coordinates": [7.0, 523.09, 273.28, 5.71, 12.84]}, {"formula_id": "formula_23", "formula_text": "y flat = S(c \u2022 t)/S(c)(19)", "formula_coordinates": [7.0, 247.84, 355.45, 280.94, 22.27]}, {"formula_id": "formula_24", "formula_text": "M \u22121 hier (y) = P T z weight \u2022 P (1) \u2022 P (y) P (diag(A)) (20", "formula_coordinates": [7.0, 193.54, 724.03, 329.55, 30.65]}, {"formula_id": "formula_25", "formula_text": ")", "formula_coordinates": [7.0, 523.09, 733.04, 5.71, 12.84]}, {"formula_id": "formula_26", "formula_text": "z weight = 1 if k = 0 \u03b1 \u2212(\u03b2+k) otherwise (21", "formula_coordinates": [8.0, 217.69, 420.56, 305.39, 32.0]}, {"formula_id": "formula_27", "formula_text": ")", "formula_coordinates": [8.0, 523.09, 429.31, 5.71, 12.84]}, {"formula_id": "formula_28", "formula_text": "y hier = P T z weight \u2022 P (S(c \u2022 t)) P (1) /P T z weight \u2022 P (S(c)) P (1) (22)", "formula_coordinates": [8.0, 133.95, 724.03, 394.84, 30.65]}, {"formula_id": "formula_29", "formula_text": "\u03c3 xy = 8, \u03c3 l = 4, \u03c3 uv = 3, \u03c3 xy = \u03c3 rgb = 16, \u03bb = 4 f \u22121/2", "formula_coordinates": [11.0, 220.68, 222.79, 307.73, 17.57]}, {"formula_id": "formula_30", "formula_text": "minimize x \u03bb 2 i,j\u0174 i,j (x i \u2212 x j ) 2 + i c i (x i \u2212 t i ) 2 (1)", "formula_coordinates": [17.0, 171.71, 444.37, 357.08, 35.7]}, {"formula_id": "formula_31", "formula_text": "i c i (x i \u2212 t i ) 2 =(x \u2212 t) T diag(c)(x \u2212 t) (2) =x T diag(c)x \u2212 2x T diag(c)t + t T diag(c)t (3) =x T diag(c)x \u2212 2 (c \u2022 t) T x + (c \u2022 t) T t(4)", "formula_coordinates": [17.0, 153.92, 539.71, 374.87, 79.71]}, {"formula_id": "formula_32", "formula_text": "minimize x x T \u03bb I \u2212\u0174 + diag(c) x \u2212 2(c \u2022 t) T x + (c \u2022 t) T t(5)", "formula_coordinates": [17.0, 126.07, 671.73, 402.72, 24.36]}, {"formula_id": "formula_33", "formula_text": "W = S T D \u22121 m D nB D n D \u22121 m S(", "formula_coordinates": [17.0, 230.22, 736.12, 287.64, 17.75]}, {"formula_id": "formula_34", "formula_text": "D n \u2190 diag(n) 7: D m \u2190 diag(m)", "formula_coordinates": [18.0, 88.23, 199.14, 95.44, 34.16]}, {"formula_id": "formula_35", "formula_text": "SS T = D m (7)", "formula_coordinates": [18.0, 274.39, 297.41, 254.4, 16.21]}, {"formula_id": "formula_36", "formula_text": "x = S T y(8)", "formula_coordinates": [18.0, 281.26, 368.07, 247.53, 15.25]}, {"formula_id": "formula_37", "formula_text": "x T I \u2212\u0174 x =x T I \u2212 S T D \u22121 m D nB D n D \u22121 m S x by Eq 6 =(S T y) T I \u2212 S T D \u22121 m D nB D n D \u22121 m S (S T y) by Eq 8 =y T SIS T \u2212 SS T D \u22121 m D nB D n D \u22121 m SS T y (9) =y T D m \u2212 D m D \u22121 m D nB D n D \u22121 m D m y by Eq 7 =y T D m \u2212 D nB D n y (10", "formula_coordinates": [18.0, 119.5, 443.86, 409.3, 113.15]}, {"formula_id": "formula_38", "formula_text": ")", "formula_coordinates": [18.0, 523.09, 535.06, 5.71, 12.84]}, {"formula_id": "formula_39", "formula_text": "x T diag(c)x \u2212 2(c \u2022 t) T x + (c \u2022 t) T t (11) =(S T y) T diag(c)(S T y) \u2212 2(c \u2022 t) T (S T y) + (c \u2022 t) T t by Eq 8 =y T (Sdiag(c)S T )y \u2212 2(S(c \u2022 t)) T y + (c \u2022 t) T t (12", "formula_coordinates": [18.0, 138.89, 596.95, 389.9, 66.75]}, {"formula_id": "formula_40", "formula_text": ")", "formula_coordinates": [18.0, 523.09, 641.75, 5.71, 12.84]}, {"formula_id": "formula_41", "formula_text": "=y T diag(Sc)y \u2212 2(S(c \u2022 t)) T y + (c \u2022 t) T t (13", "formula_coordinates": [18.0, 138.89, 660.53, 384.19, 24.36]}, {"formula_id": "formula_42", "formula_text": ")", "formula_coordinates": [18.0, 523.09, 662.95, 5.71, 12.84]}, {"formula_id": "formula_43", "formula_text": "minimize y 1 2 y T \u03bb D m \u2212 D nB D n + diag(Sc) y \u2212 (S(c \u2022 t)) T y + 1 2 (c \u2022 t) T t (14", "formula_coordinates": [18.0, 86.34, 708.49, 439.31, 43.16]}, {"formula_id": "formula_44", "formula_text": ")", "formula_coordinates": [18.0, 523.09, 738.81, 5.71, 12.84]}, {"formula_id": "formula_45", "formula_text": "minimize y 1 2 y T Ay \u2212 b T y + c (15) A = \u03bb(D m \u2212 D nB D n ) + diag(Sc) b = S(c \u2022 t) c = 1 2 (c \u2022 t) T t", "formula_coordinates": [19.0, 110.42, 91.8, 418.37, 63.46]}, {"formula_id": "formula_46", "formula_text": "Ay = b (16)", "formula_coordinates": [19.0, 284.53, 218.29, 244.26, 12.84]}, {"formula_id": "formula_47", "formula_text": "1: i \u2190 0 2: r \u2190 b \u2212 A(x) 3: d \u2190 M \u22121 (r) 4: \u03bb new \u2190 r T d 5: while i < n do 6: q \u2190 A(d) 7: \u03b1 \u2190 \u03bb new d T q 8: x \u2190 x + \u03b1d 9: r \u2190 r \u2212 \u03b1q 10: s \u2190 M \u22121 (", "formula_coordinates": [19.0, 83.21, 490.62, 100.92, 147.12]}, {"formula_id": "formula_48", "formula_text": "k = [0 : K \u2212 1] do V \u2190 V /2 (S k , V ) \u2190 simplified bilateral grid(V ) end for", "formula_coordinates": [20.0, 96.05, 233.34, 231.09, 59.37]}, {"formula_id": "formula_49", "formula_text": "P (y) = [S K\u22121 . . . S 1 S 0 y, . . . , S 1 S 0 y, S 0 y, y](17)", "formula_coordinates": [20.0, 184.76, 356.25, 344.02, 13.8]}, {"formula_id": "formula_50", "formula_text": "P T (z) = [S T 0 S T 1 . . . S T K\u22121 z, . . . , S T 0 S T 1 z, S T 0 z, z](18)", "formula_coordinates": [20.0, 176.99, 409.04, 351.8, 17.46]}, {"formula_id": "formula_51", "formula_text": "minimize x \u03bb 2 i,j\u0174 i,j (x i \u2212 x j ) 2 + i \u03c1(x i \u2212 t i )(19)", "formula_coordinates": [20.0, 176.18, 642.63, 352.6, 35.7]}, {"formula_id": "formula_52", "formula_text": "\u03c1(e i ) = e 2 i \u03c3 2 gm + e 2 i w(e i ) = 2\u03c3 2 gm (\u03c3 2 gm + e 2 i ) 2 (20)", "formula_coordinates": [21.0, 187.13, 196.11, 341.66, 35.95]}, {"formula_id": "formula_53", "formula_text": "i \u2190 i + 1 7: end while", "formula_coordinates": [21.0, 88.23, 523.16, 80.02, 25.98]}, {"formula_id": "formula_54", "formula_text": "Var(x) = E[x 2 ] \u2212 (E[x]) 2 (21)", "formula_coordinates": [22.0, 238.05, 78.06, 290.74, 25.52]}, {"formula_id": "formula_55", "formula_text": "V = DT(Z 2 ) \u2212 (DT(Z)) 2 (22)", "formula_coordinates": [22.0, 233.87, 197.77, 294.92, 25.52]}, {"formula_id": "formula_56", "formula_text": "c init = exp \u2212 V 2\u03c3 2 dt (23", "formula_coordinates": [22.0, 246.69, 261.52, 276.39, 33.23]}, {"formula_id": "formula_57", "formula_text": ")", "formula_coordinates": [22.0, 523.09, 270.2, 5.71, 12.84]}, {"formula_id": "formula_58", "formula_text": "AY = B (24", "formula_coordinates": [23.0, 282.29, 194.42, 240.8, 12.84]}, {"formula_id": "formula_59", "formula_text": ")", "formula_coordinates": [23.0, 523.09, 194.42, 5.71, 12.84]}, {"formula_id": "formula_60", "formula_text": "BP = QR (25", "formula_coordinates": [23.0, 277.24, 416.11, 245.84, 12.84]}, {"formula_id": "formula_61", "formula_text": ")", "formula_coordinates": [23.0, 523.09, 416.11, 5.71, 12.84]}, {"formula_id": "formula_62", "formula_text": "B = Q R (26", "formula_coordinates": [23.0, 278.66, 488.44, 244.43, 12.84]}, {"formula_id": "formula_63", "formula_text": ")", "formula_coordinates": [23.0, 523.09, 488.44, 5.71, 12.84]}, {"formula_id": "formula_64", "formula_text": "m i = j R 2 i,j(27)", "formula_coordinates": [23.0, 266.56, 580.95, 262.23, 31.25]}, {"formula_id": "formula_65", "formula_text": "i<t i=0 m i \u2264 (1 \u2212 ) i m i(28)", "formula_coordinates": [23.0, 243.53, 666.48, 285.27, 40.18]}, {"formula_id": "formula_66", "formula_text": "Q \u2248 Q [:, 1 : t]R \u2248 (R P T )[1 : t, :](29)", "formula_coordinates": [23.0, 198.18, 736.4, 330.61, 24.36]}, {"formula_id": "formula_67", "formula_text": "Y = (A \u22121Q )R(30)", "formula_coordinates": [24.0, 265.6, 87.99, 263.19, 15.57]}, {"formula_id": "formula_68", "formula_text": "t i = (l i + u i )/2 c i = exp(l i \u2212 u i ) (31)", "formula_coordinates": [27.0, 205.06, 90.28, 323.74, 22.27]}], "doi": ""}