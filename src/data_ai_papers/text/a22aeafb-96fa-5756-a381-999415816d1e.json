{"title": "Bayesian Optimization in High Dimensions via Random Embeddings", "authors": "Ziyu Wang; Masrour Zoghi; Frank Hutter; David Matheson; Nando De Freitas", "pub_date": "", "abstract": "Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm configuration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identified its scaling to high dimensions as one of the holy grails of the field. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple and applies to domains with both categorical and continuous variables. The experiments demonstrate that REMBO can effectively solve high-dimensional problems, including automatic parameter configuration of a popular mixed integer linear programming solver.", "sections": [{"heading": "Introduction", "text": "Let f : X \u2192 R be a function on a compact subset X \u2286 R D . We address the following global optimization problem\nx = arg max x\u2208X f (x).\nWe are particularly interested in objective functions f that may satisfy one or more of the following criteria: they do not have a closed-form expression, are expensive to evaluate, do not have easily available derivatives, or are non-convex. We treat f as a blackbox function that only allows us to query its function value at arbitrary x \u2208 X . To address objectives of this challenging nature, we adopt the Bayesian optimization framework. There is a rich literature on Bayesian optimization, and we refer readers unfamiliar with the topic to more tutorial treatments Jones et al., 1998;Jones, 2001;Lizotte et al., 2011;Mo\u010dkus, 1994;Osborne et al., 2009] and recent theoretical results [Srinivas et al., 2010;.\nIn a nutshell, in order to optimize a blackbox function f , Bayesian optimization uses a prior distribution that captures our beliefs about the behavior of f , and updates this prior with sequentially acquired data. Specifically, it iterates the following phases: (1) use the prior to decide at which input x \u2208 X to query f next; (2) evaluate f (x); and (3) update the prior based on the new data x, f (x) . Step 1 uses a socalled acquisition function that quantifies the expected value of learning the value of f (x) for each x \u2208 X . Bayesian optimization methods differ in their choice of prior and their choice of this acquisition function.\nIn recent years, the artificial intelligence community has increasingly used Bayesian optimization; see for example [Martinez-Cantin et al., 2009;Srinivas et al., 2010;Hoffman et al., 2011;Lizotte et al., 2011;Azimi et al., 2012]. Despite many success stories, the approach is restricted to problems of moderate dimension, typically up to about 10; see for example the excellent and very recent overview in [Snoek et al., 2012]. Of course, for a great many problems this is all that is needed. However, to advance the state of the art, we need to scale Bayesian optimization to high-dimensional parameter spaces. This is a difficult problem: To ensure that a global optimum is found, we require good coverage of X , but as the dimensionality increases, the number of evaluations needed to cover X increases exponentially.\nFor linear bandits, Carpentier et al [2012] recently proposed a compressed sensing strategy to attack problems with a high degree of sparsity. Also recently, Chen et al [2012] made significant progress by introducing a two stage strategy for optimization and variable selection of high-dimensional GPs. In the first stage, sequential likelihood ratio tests with a couple of tuning parameters are used to select the relevant dimensions. This, however, requires the relevant dimensions to be axis-aligned with an ARD kernel. Chen et al provide empirical results only for synthetic examples (of up to 400 dimensions), but they provide key theoretical guarantees. Hutter et al [2011] used Bayesian optimization with random forests based on frequentist uncertainty estimates. Their method does not have theoretical guarantees for continuous optimization, but it achieved state-of-the-art performance for tuning up to 76 parameters of algorithms for solving combinatorial problems.\nMany researchers have noted that for certain classes of problems most dimensions do not change the objective function significantly; examples include hyper-parameter optimization for neural networks and deep belief networks [Bergstra and Bengio, 2012] and automatic configura- effective dimension: the vertical axis indicated with the word important on the right hand side figure. Hence, the 1-dimensional embedding includes the 2-dimensional function's optimizer. It is more efficient to search for the optimum along the 1-dimensional random embedding than in the original 2-dimensional space. tion of state-of-the-art algorithms for solving N P-hard problems . That is to say these problems have \"low effective dimensionality\". To take advantage of this property, [Bergstra and Bengio, 2012] proposed to simply use random search for optimization -the rationale being that points sampled uniformly at random in each dimension can densely cover each low-dimensional subspace. As such, random search can exploit low effective dimensionality without knowing which dimensions are important. In this paper, we exploit the same property, while still capitalizing on the strengths of Bayesian optimization. By combining randomization with Bayesian optimization, we are able to derive a new approach that outperforms each of the individual components.\nFigure 1 illustrates our approach in a nutshell. Assume we know that a given D = 2 dimensional black-box function f (x 1 , x 2 ) only has d = 1 important dimensions, but we do not know which of the two dimensions is the important one. We can then perform optimization in the embedded 1-dimensional subspace defined by x 1 = x 2 since this is guaranteed to include the optimum. This idea enables us to perform Bayesian optimization in a low-dimensional space to optimize a high-dimensional function with low intrinsic dimensionality. Importantly, it is not restricted to cases with axis-aligned intrinsic dimensions.", "publication_ref": ["b16", "b17", "b18", "b21", "b21", "b23", "b20", "b23", "b10", "b18", "b0", "b22", "b5", "b13", "b1", "b1"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Bayesian Optimization", "text": "Bayesian optimization has two ingredients that need to be specified: The prior and the acquisition function. In this work, we adopt GP priors. We review GPs very briefly and refer the interested reader to [Rasmussen and Williams, 2006]. A GP is a distribution over functions specified by its mean function m(\u2022) and covariance k(\u2022, \u2022). More specifically, given a set of points x 1:t , with x i \u2286 R D , we have f (x 1:t ) \u223c N (m(x 1:t ), K(x 1:t , x 1:t )), where K(x 1:t , x 1:t ) i,j = k(x i , x j ) serves as the covariance matrix. A common choice of k is the squared exponential function, but many other choices are possible depending on our degree of belief about the smoothness of the objective function.\nAn advantage of using GPs lies in their analytical tractability. In particular, given observations x 1:n with corresponding values f 1:t , where f i = f (x i ), and a new point x * , the joint distribution is given by:\nf 1:t f * \u223c N m(x 1:t ), K(x 1:t , x 1:t ) k(x 1:t , x * ) k(x * , x 1:t ) k(x * , x * ) .\nFor simplicity, we assume that m(x 1:t ) = 0. Using the Sherman-Morrison-Woodbury formula, one can easily arrive at the posterior predictive distribution:\nf * |D t , x * \u223c N (\u00b5(x * |D t ), \u03c3(x * |D t )),\nwith data D t = {x 1:t , f 1:t }, mean \u00b5(x * |D t ) = k(x * , x 1:t )K(x 1:t , x 1:t ) \u22121 f 1:t and variance \u03c3(x * |D t ) = k(x * , x * ) \u2212 k(x * , x 1:t )K(x 1:t , x 1:t ) \u22121 k(x 1:t , x * ). That is, we can compute the posterior predictive mean \u00b5(\u2022) and variance \u03c3(\u2022) exactly for any point x * . At each iteration of Bayesian optimization, one has to re-compute the predictive mean and variance. These two quantities are used to construct the second ingredient of Bayesian optimization: The acquisition function. In this work, we report results for the expected improvement acquisition function u(x|D t ) = E(max{0, f t+1 (x) \u2212 f (x + )}|D t ) [Mo\u010dkus, 1982;Bull, 2011]. In this definition, x + = arg max x\u2208{x1:t} f (x) is the element with the best objective value in the first t steps of the optimization process. The next query is: x t+1 = arg max x\u2208X u(x|D t ). Note that this utility favors the selection of points with high variance (points in regions not well explored) and points with high mean value (points worth exploiting). We also experimented with the UCB acquisition function [Srinivas et al., 2010; and found it to yield similar results. The optimization of the closed-form acquisition function can be carried out by off-the-shelf numerical optimization procedures. The Bayesian optimization procedure is shown in Algorithm 1.", "publication_ref": ["b21", "b20", "b4", "b23"], "figure_ref": [], "table_ref": []}, {"heading": "Algorithm 1 Bayesian Optimization", "text": "1: for t = 1, 2, . . . do", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "2:", "text": "Find x t+1 \u2208 R D by optimizing the acquisition function u: x t+1 = arg max x\u2208X u(x|D t ).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "3:", "text": "Augment the data D t+1 = {D t , (x t+1 , f (x t+1 ))} 4: end for 3 REMBO Before introducing our new algorithm and its theoretical properties, we need to define what we mean by effective dimensionality formally. Definition 1. A function f : R D \u2192 R is said to have effective dimensionality d e , with d e < D, if there exists a linear subspace T of dimension d e such that for all x \u2208 T \u2282 R D and\nx \u22a5 \u2208 T \u22a5 \u2282 R D , we have f (x) = f (x + x \u22a5 ) = f (x ),\nwhere T \u22a5 denotes the orthogonal complement of T . We call T the effective subspace of f and T \u22a5 the constant subspace.\nThis definition simply states that the function does not change along the coordinates x \u22a5 , and this is why we refer to T \u22a5 as the constant subspace. Given this definition, the following theorem shows that problems of low effective dimensionality can be solved via random embedding.\nTheorem 2. Assume we are given a function f : R D \u2192 R with effective dimensionality d e and a random matrix A \u2208 R D\u00d7d with independent entries sampled according to N (0, 1) and d \u2265 d e . Then, with probability 1, for any x \u2208 R D , there exists a y \u2208 R d such that f (x) = f (Ay).\nProof. Since f has effective dimensionality d e , there exists an effective subspace T \u2282 R D , such that rank(T ) = d e . Furthermore, any x \u2208 R D decomposes as x = x + x \u22a5 , where x \u2208 T and x \u22a5 \u2208 T \u22a5 . Hence, f (x) = f (x +x \u22a5 ) = f (x ). Therefore, without loss of generality, it will suffice to show that for all x \u2208 T , there exists a y \u2208 R d such that f (x ) = f (Ay).\nLet \u03a6 \u2208 R D\u00d7de be a matrix, whose columns form an orthonormal basis for T . Hence, for each x \u2208 T , there exists a c \u2208 R de such that x = \u03a6c. Let us for now assume that \u03a6 T A has rank d e . If \u03a6 T A has rank d e , there exists a y such that (\u03a6 T A)y = c. The orthogonal projection of Ay onto T is given by\n\u03a6\u03a6 T Ay = \u03a6c = x . Thus Ay = x + x for some x \u2208 T \u22a5 since x is the projection Ay onto T . Consequently, f (Ay) = f (x + x ) = f (x ).\nIt remains to show that, with probability one, the matrix \u03a6 T A has rank d e . Let A e \u2208 R D\u00d7de be a submatrix of A consisting of any d e columns of A, which are i.i.d. samples distributed according to N (0, I). Then, \u03a6 T a i are i.i.d. samples from N (0, \u03a6 T \u03a6) = N (0 de , I de\u00d7de ), and so we have \u03a6 T A e , when considered as an element of R d 2 e , is a sample from N (0\nd 2 e , I d 2 e \u00d7d 2 e\n). On the other hand, the set of singular matrices in R d 2 e has Lebesgue measure zero, since it is the zero set of a polynomial (i.e. the determinant function) and polynomial functions are Lebesgue measurable. Moreover, the Normal distribution is absolutely continuous with respect to the Lebesgue measure, so our matrix \u03a6 T A e is almost surely non-singular, which means that it has rank d e and so the same is true of \u03a6 T A, whose columns contain the columns of \u03a6 T A e .\nTheorem 2 says that given any x \u2208 R D and a random matrix A \u2208 R D\u00d7d , with probability 1, there is a point y \u2208 R d such that f (x) = f (Ay). This implies that for any optimizer x \u2208 R D , there is a point y \u2208 R d with f (x ) = f (Ay ). Therefore, instead of optimizing in the high dimensional space, we can optimize the function g(y) = f (Ay) in the lower dimensional space. This observation gives rise to our new algorithm Bayesian Optimization with Random Embedding (REMBO), described in Algorithm 2. REMBO first draws a random embedding (given by A) and then performs Bayesian optimization in this embedded space.\nAn important detail is how REMBO chooses the bounded region Y, inside which it performs Bayesian optimization. This is important because its effectiveness depends on the size of Y. Locating the optimum within Y is easier if Y is small, but if we set Y too small it may not actually contain the global optimizer (see Figure 2). In the following theorem, we show that we can choose Y in a way that only depends on the effective dimensionality d e such that the optimizer of the original problem is contained in the low-dimensional space Algorithm 2 REMBO: Bayesian Optimization with Random Embedding 1: Generate a random matrix A 2: Choose the set Y 3: for t = 1, 2, . . . do", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "4:", "text": "Find y t+1 \u2208 R d by optimizing the acquisition function u: y t+1 = arg max y\u2208Y u(y|D t ).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "5:", "text": "Augment the data D t+1 = {D t , (y t+1 , f (Ay t+1 )} 6:\nUpdate the kernel hyper-parameters. 7: end for \nd = 1 into D = 2.\nThe box illustrates the 2D constrained space X , while the thicker red line illustrates the 1D constrained space Y. Note that if Ay is outside X , it is projected onto X . The set Y must be chosen large enough so that the projection of its image, AY, onto the effective subspace (vertical axis in this diagram) covers the vertical side of the box. with constant probability. (If Ay is outside the box X , it is projected onto X .) Theorem 3. Suppose we want to optimize a function f : R D \u2192 R with effective dimension d e \u2264 d subject to the box constraint X \u2282 R D , where X is centered around 0. Let us denote one of the optimizers by x . Suppose further that the effective subspace T of f is such that T is the span of d e basis vectors. Let x \u2208 T \u2229 X be an optimizer of f inside T . If A is a D \u00d7 d random matrix with independent standard Gaussian entries, there exists an optimizer y \u2208 R d such that f (Ay ) = f (x ) and y 2 \u2264 \u221a de x 2 with probability at least 1 \u2212 . Proof. Since X is a box constraint, by projecting x to T we get x \u2208 T \u2229 X . Also, since x = x + x \u22a5 for some x \u22a5 \u2208 T \u22a5 , we have f (x ) = f (x ). Hence, x is an optimizer. By using the same argument as appeared in Theorem 2, it is easy to see that with probability 1 \u2200x \u2208 T \u2203y \u2208 R d such that Ay = x + x \u22a5 where x \u22a5 \u2208 T \u22a5 . Let \u03a6 be the matrix whose columns form a standard basis for T . Without loss of generality, we can assume that \u03a6 = [I de 0] T . Then, as shown in Proposition 2, there exists a y \u2208 R d such that \u03a6\u03a6 T Ay = x . Note that for each column of A, we have \u03a6\u03a6 T a i \u223c N 0, I de 0 0 0 .\nTherefore \u03a6\u03a6 T Ay = x is equivalent to By =x where B \u2208 R de\u00d7de is a random matrix with independent standard Gaussian entries andx is the vector that contains the first d e entries of x (the rest are 0's). By Theorem 3.4 of [Sankar et al., 2003], we have\nP B \u22121 2 \u2265 \u221a d e \u2264 .\nThus, with probability at least 1 \u2212 , y\n\u2264 B \u22121 2 x 2 = B \u22121 2 x 2 \u2264 \u221a de x 2 .\nTheorem 3 says that if the set X in the original space is a box constraint, then there exists an optimizer x \u2208 X that is d e -sparse such that with probability at least 1 \u2212 , y 2 \u2264 \u221a de x 2 where f (Ay ) = f (x ). If the box constraint is X = [\u22121, 1] D (which is always achievable through rescaling), we have with probability at least 1 \u2212 that\ny 2 \u2264 \u221a d e x 2 \u2264 \u221a d e d e .\nHence, to choose Y, we just have to make sure that the ball of radius d e / satisfies (0, de ) \u2286 Y. In most practical scenarios, we found that the optimizer does not fall on the boundary which implies that x 2 < d e . Thus setting Y too big may be unnecessarily wasteful. In all our experiments we set Y to be [\u2212\n\u221a d, \u221a d] d\n. Theorem 3 only guarantees that Y contains the optimum with probability at least 1 \u2212 ; with probability \u03b4 \u2264 the optimizer lies outside of Y. There are several ways to guard against this problem. One is to simply run REMBO multiple times with different independently drawn random embeddings. Since the probability of failure with each embedding is \u03b4, the probability of the optimizer not being included in the considered space of k independently drawn embeddings is \u03b4 k . Thus, the failure probability vanishes exponentially quickly in the number of REMBO runs, k. Note also that these independent runs can be trivially parallelized to harness the power of modern multi-core machines and large compute clusters.", "publication_ref": ["b22"], "figure_ref": [], "table_ref": []}, {"heading": "Choice of Kernel", "text": "We begin our discussion on kernels with the definition of the squared exponential kernel between two points, y (1) , y (2) , on Y \u2286 R d . Given a length scale r > 0, we define the corresponding squared exponential kernel as\nk d (y (1) , y (2) ) = exp \u2212 y (1) \u2212 y (2) 2 2 2 .\nIt is possible to work with two variants of this kernel. First, we can use k d (y 1 , y 2 ) as above. We refer to this kernel as the low-dimensional kernel. We can also adopt an implicitly defined high-dimensional kernel on X :\nk D (y (1) , y 2 ) = exp \u2212 p X (Ay (1) ) \u2212 p X (Ay (2) ) 2 2 2 ,\nwhere p X : R D \u2192 R D is the standard projection operator for our box-constraint: p X (y) = arg min z\u2208X z \u2212 y 2 ; see Figure 2.\nNote that when using the high-dimensional kernel, we are fitting the GP in D dimensions. However, the search space is no longer the box X , but it is instead given by the much smaller subspace {p X (Ay) : y \u2208 Y}. Importantly, in practice it is easier to maximize the acquisition function in this subspace. Our experiment on automatic algorithm configuration will show that indeed optimizing the acquisition function in low dimensions leads to significant gains of REMBO over standard Bayesian optimization.\nThe low-dimensional kernel has the benefit of only having to construct a GP in the space of intrinsic dimensionality d, whereas the high-dimensional kernel has to construct the GP in a space of extrinsic dimensionality D. However, the choice of kernel also depends on whether our variables are continuous, integer or categorical. The categorical case is important because we often encounter optimization problems that contain discrete choices. We define our kernel for categorical variables as:\nk D \u03bb (y (1) , y (2) ) = exp \u2212 \u03bb 2 g(s(Ay (1) ), s(Ay (2) )) 2 ,\nwhere y (1) , y (2) \u2208 Y \u2282 R d and g defines the distance between 2 vectors. The function s maps continuous vectors to discrete vectors. In more detail, s(x) first projects x to [\u22121, 1] D to generatex. For each dimensionx i ofx, s then mapsx i to the corresponding discrete parameters by scaling and rounding. In our experiments, following [Hutter, 2009], we defined g(\nx (1) , x (2) ) = |{i : x (1) i = x\n(2)\ni }| so as not to impose an artificial ordering between the values of categorical parameters. In essence, we measure the distance between two points in the low-dimensional space as the distance between their mappings in the high-dimensional space.\nOur demonstration of REMBO, in the domain of algorithm configuration, will use the high-dimensional kernel because the parameters in need of tuning are categorical. However, to provide the reader with a taste of the potential gains that the low-dimensional kernel could offer in continuous spaces, we will use a synthetic optimization problem. This synthetic example will also allow us to easily discuss different properties of the algorithm, including rotational invariance and dependency on d.\nFinally, when using the high-dimensional kernel, the regret bounds of [Srinivas et al., 2010;Bull, 2011; apply. For the low-dimensional case, we have derived regret bounds that only depend on the intrinsic dimensionality. For lack of space, these are covered in a longer technical report version of this paper [Wang et al., 2013]. ", "publication_ref": ["b15", "b23", "b4", "b25"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Bayesian Optimization in a Billion Dimensions", "text": "The experiments in this section employ a standard d e = 2dimensional benchmark function for Bayesian optimization, embedded in a D-dimensional space. That is, we add D \u2212 2 additional dimensions which do not affect the function at all. More precisely, the function whose optimum we seek is f (x 1:D ) = g(x i , x j ), where g is the Branin function (for its exact formula, see [Lizotte, 2008]) and where i and j are selected once using a random permutation. To measure the performance of each optimization method, we used the optimality gap: the difference of the best function value it found and the optimal function value. Table 1: Optimality gap for d e = 2-dimensional Branin function embedded in D = 25 dimensions, for REMBO variants using a total of 500 function evaluations. The variants differed in the internal dimensionality d and in the number of interleaved runs k (each such run was only allowed 500/k function evaluations). We show mean and standard deviations of the optimality gap achieved after 500 function evaluations.\nk d = 2 d = 4 d =\nWe evaluate REMBO using a fixed budget of 500 function evaluations that is spread across multiple interleaved runsfor example, when using k = 4 interleaved REMBO runs, each of them was only allowed 125 function evaluations. We study the choices of k and d by considering several combinations of these values. The results in Table 1 demonstrate that interleaved runs helped improve REMBO's performance. We note that in 13/50 REMBO runs, the global optimum was indeed not contained in the box Y REMBO searched with d = 2; this is the reason for the poor mean performance of REMBO with d = 2 and k = 1. However, the remaining 37 runs performed very well, and REMBO thus performed well when using multiple interleaved runs: with a failure rate of 13/50=0.26 per independent run, the failure rate using k = 4 interleaved runs is only 0.26 4 \u2248 0.005. One could easily achieve an arbitrarily small failure rate by using many independent parallel runs. Using a larger d is also effective in increasing the probability of the optimizer falling into REMBO's box Y but at the same time slows down REMBO's convergence (such that interleaving several short runs loses its effectiveness).\nNext, we compared REMBO to standard Bayesian optimization (BO) and to random search, for an extrinsic dimensionality of D = 25. Standard BO is well known to perform well in low dimensions, but to degrade above a tipping point of about 15-20 dimensions. Our results for D = 25 (see Figure 3, left) confirm that BO performed rather poorly just above this critical dimensionality (merely tying with random search). REMBO, on the other hand, still performed very well in 25 dimensions.\nOne important advantage of REMBO is that -in contrast to the approach of [Chen et al., 2012] -it does not require the effective dimension to be coordinate aligned. To demonstrate this fact empirically, we rotated the embedded Branin function by an orthogonal rotation matrix R \u2208 R D\u00d7D . That is, we replaced f (x) by f (Rx). Figure 3 (middle) shows that REMBO's performance is not affected by this rotation. Finally, since REMBO is independent of the extrinsic dimensionality D as long as the intrinsic dimensionality d e is small, it performed just as well in D = 1 000 000 000 dimensions (see Figure 3, right). To the best of our knowledge, the only other existing method that can be run in such high dimensionality is random search.\nFor reference, we also evaluated the method of [Chen et al., 2012] for these functions, confirming that it does not handle rotation gracefully: while it performed best in the non-rotated case for D = 25, it performed worst in the rotated case. It could not be used efficiently for more than D = 1, 000. Based on a Mann-Whitney U test with Bonferroni multipletest correction, all performance differences were statistically significant, except Random vs. standard BO.", "publication_ref": ["b19", "b6", "b6"], "figure_ref": ["fig_2", "fig_2", "fig_2"], "table_ref": []}, {"heading": "Automatic Configuration of a Mixed Integer Linear Programming Solver", "text": "State-of-the-art algorithms for solving hard computational problems tend to parameterize several design choices in order to allow a customization of the algorithm to new problem domains. Automated methods for algorithm configuration have recently demonstrated that substantial performance gains of state-of-the-art algorithms can be achieved in a fully automated fashion [Mo\u010dkus et al., 1999;Hutter et al., 2010;Vallati et al., 2011;Bergstra et al., 2011;Wang and de Freitas, 2011]. These successes have led to a paradigm shift in algorithm development towards the active design of highly param-Figure 4: Performance for configuration of lpsolve; we show the optimality gap lpsolve achieved with the configurations found by the various methods (lower is better). Top: a single run of each method; Bottom: performance with k = 4 interleaved runs. We plot means and 1/4 standard deviations over 20 repetitions of the experiment.\neterized frameworks that can be automatically customized to particular problem domains using optimization [Hoos, 2012;. It has recently been demonstrated that many algorithm configuration problems have low dimensionality . Here, we demonstrate that REMBO can exploit this low dimensionality even in the discrete spaces typically encountered in algorithm configuration. We use a configuration problem obtained from [Hutter et al., 2010], aiming to configure the 40 binary and 7 categorical parameters of lpsolve 1 , a popular mixed integer linear programming solver that has been downloaded over 40 000 times in the last year. The objective is to minimize the optimality gap lpsolve can obtain in a time limit of five seconds for a mixed integer programming (MIP) encoding of a wildlife corridor problem from computational sustainability [Gomes et al., 2008]. Algorithm configuration aims to improve performance for a representative set of problem instances, and effective methods need to solve two orthogonal problems: searching the parameter space effectively and deciding how many resources to spend in each evaluation (to trade off computational overhead and over-fitting). Our contribution is for the first of these problems; to focus on how effectively the different methods search the parameter space, we only consider configuration 1 http://lpsolve.sourceforge.net/ on a single problem instance (i.e., a deterministic blackbox optimization problem; further work is required to tackle general algorithm configuration problems with randomized algorithms and distributions of problem instances).\nDue to the discrete nature of this optimization problem, we could only apply REMBO using the high-dimensional kernel for categorical variables k D \u03bb (y (1) , y (2) ) described in Section 3.1. While we have not proven any theoretical guarantees for discrete optimization problems, REMBO appears to effectively exploit the low effective dimensionality of at least this particular optimization problem.\nFigure 4 (top) compares BO, REMBO, and the baseline random search against ParamILS (which was used for all configuration experiments in [Hutter et al., 2010]) and SMAC [Hutter et al., 2011]. ParamILS and SMAC were specifically designed for the configuration of algorithms with many discrete parameters and define the current state of the art for this problem. Nevertheless, here SMAC and our vanilla REMBO method performed best. Based on a Mann-Whitney U test with Bonferroni multiple-test correction, they both yielded statistically significantly better results than both Random and standard BO; no other performance differences were significant. The figure only shows REMBO with d = 5 to avoid clutter, but we did not optimize this parameter; the only other value we tried (d = 3) resulted in indistinguishable .\nAs in the synthetic experiment, REMBO's performance could be further improved by using multiple interleaved runs. However, it is known that multiple independent runs also benefit the other procedures, especially ParamILS [Hutter et al., 2012]. Thus, to be fair, we re-evaluated all approaches using interleaved runs. Figure 4 (bottom) shows that ParamILS and REMBO benefitted most from interleaving k = 4 runs. However, the statistical test results did not change, still showing that SMAC and REMBO outperformed Random and BO, with no other significant performance differences.", "publication_ref": ["b20", "b12", "b23", "b2", "b24", "b14", "b12", "b8", "b12", "b13", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion", "text": "This paper has shown that it is possible to use random embeddings in Bayesian optimization to optimize functions of high extrinsic dimensionality D, provided that they have low intrinsic dimensionality d e . The new algorithm, REMBO, only requires a simple modification of the original Bayesian optimization algorithm; namely multiplication by a random matrix. We confirmed REMBO's independence of D empirically by optimizing low-dimensional functions embedded in high dimensions. Finally, we demonstrated that REMBO achieves excellent performance for optimizing the 47 discrete parameters of a popular mixed integer programming solver, thereby providing further evidence for the observation (already put forward by Bergstra, Hutter and colleagues) that, for many problems of great practical interest, the number of important dimensions indeed appears to be much lower than their extrinsic dimensionality. Of course, we do not yet know how many practical optimization problems fall within the class of problems where REMBO applies. With time and the release of the code, we will find more evidence. For the time being, the success achieved in the examples presented in this paper is very encouraging.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Hybrid batch Bayesian optimization. In ICML", "journal": "", "year": "2012", "authors": "[ References;  Azimi"}, {"ref_id": "b1", "title": "Random search for hyper-parameter optimization", "journal": "JMLR", "year": "2012", "authors": " Bergstra; ] J Bengio; Y Bergstra;  Bengio"}, {"ref_id": "b2", "title": "Algorithms for hyper-parameter optimization", "journal": "", "year": "2011", "authors": "[ Bergstra"}, {"ref_id": "b3", "title": "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "journal": "", "year": "2009", "authors": "[ Bergstra"}, {"ref_id": "b4", "title": "Convergence rates of efficient global optimization algorithms", "journal": "JMLR", "year": "2011", "authors": "; A D Bull;  Bull"}, {"ref_id": "b5", "title": "Bandit theory meets compressed sensing for high dimensional stochastic linear bandit", "journal": "", "year": "2012", "authors": "Munos ; A Carpentier; R Carpentier;  Munos"}, {"ref_id": "b6", "title": "Joint optimization and variable selection of high-dimensional Gaussian processes", "journal": "", "year": "2012", "authors": "[ Chen"}, {"ref_id": "b7", "title": "Exponential regret bounds for Gaussian process bandits with deterministic observations", "journal": "", "year": "2012", "authors": " De Freitas"}, {"ref_id": "b8", "title": "Connections in networks: A hybrid approach", "journal": "", "year": "2008", "authors": " Gomes"}, {"ref_id": "b9", "title": "Completely derandomized self-adaptation in evolution strategies", "journal": "Evol. Comput", "year": "2001", "authors": "Ostermeier ; N Hansen; A Hansen;  Ostermeier"}, {"ref_id": "b10", "title": "Portfolio allocation for Bayesian optimization", "journal": "", "year": "2011", "authors": "[ Hoffman"}, {"ref_id": "b11", "title": "Programming by optimization", "journal": "Commun. ACM", "year": "2012", "authors": "; H H Hoos;  Hoos"}, {"ref_id": "b12", "title": "Automated configuration of mixed integer programming solvers", "journal": "", "year": "2010", "authors": "[ Hutter"}, {"ref_id": "b13", "title": "Sequential model-based optimization for general algorithm configuration", "journal": "", "year": "2011", "authors": "[ Hutter"}, {"ref_id": "b14", "title": "Identifying key algorithm parameters and instance features using forward selection", "journal": "", "year": "2012", "authors": "[ Hutter"}, {"ref_id": "b15", "title": "Automated Configuration of Algorithms for Solving Hard Computational Problems", "journal": "", "year": "2009", "authors": "; F Hutter;  Hutter"}, {"ref_id": "b16", "title": "Efficient global optimization of expensive black-box functions", "journal": "J. of Optimization Theory and Applications", "year": "1993", "authors": "[ Jones"}, {"ref_id": "b17", "title": "A taxonomy of global optimization methods based on response surfaces", "journal": "J. of Global Optimization", "year": "2001", "authors": "D R Jones"}, {"ref_id": "b18", "title": "An experimental methodology for response surface optimization methods", "journal": "J. of Global Optimization", "year": "2011", "authors": " Lizotte"}, {"ref_id": "b19", "title": "Practical Bayesian Optimization", "journal": "Canada", "year": "2008", "authors": "; D Lizotte;  Lizotte"}, {"ref_id": "b20", "title": "A Bayesian exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot", "journal": "Springer", "year": "1982", "authors": " Martinez-Cantin"}, {"ref_id": "b21", "title": "Application of Bayesian approach to numerical methods of global and stochastic optimization", "journal": "The MIT Press", "year": "1994", "authors": "; J Mo\u010dkus;  A Mo\u010dkus ; M; R Osborne; S J Garnett;  E Roberts ; C; C K I Rasmussen;  Williams"}, {"ref_id": "b22", "title": "Smoothed analysis of the condition numbers and growth factors of matrices. Arxiv preprint cs/0310022", "journal": "", "year": "2003", "authors": " Sankar"}, {"ref_id": "b23", "title": "Generating fast domain-optimized planners by automatically configuring a generic parameterised planner", "journal": "", "year": "2010", "authors": "Srinivas "}, {"ref_id": "b24", "title": "Predictive adaptation of hybrid Monte Carlo with Bayesian parametric bandits", "journal": "", "year": "2011", "authors": "; Z De Freitas; N Wang;  De Freitas"}, {"ref_id": "b25", "title": "Bayesian Optimization in a Billion Dimensions via Random Embeddings", "journal": "", "year": "2013-01", "authors": ""}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure1: This function in D=2 dimesions only has d=1 effective dimension: the vertical axis indicated with the word important on the right hand side figure. Hence, the 1-dimensional embedding includes the 2-dimensional function's optimizer. It is more efficient to search for the optimum along the 1-dimensional random embedding than in the original 2-dimensional space. tion of state-of-the-art algorithms for solving N P-hard problems. That is to say these problems have \"low effective dimensionality\". To take advantage of this property,[Bergstra and Bengio, 2012] proposed to simply use random search for optimization -the rationale being that points sampled uniformly at random in each dimension can densely cover each low-dimensional subspace. As such, random search can exploit low effective dimensionality without knowing which dimensions are important. In this paper, we exploit the same property, while still capitalizing on the strengths of Bayesian optimization. By combining randomization with Bayesian optimization, we are able to derive a new approach that outperforms each of the individual components.Figure1illustrates our approach in a nutshell. Assume we know that a given D = 2 dimensional black-box function f (x 1 , x 2 ) only has d = 1 important dimensions, but we do not know which of the two dimensions is the important one. We can then perform optimization in the embedded 1-dimensional subspace defined by x 1 = x 2 since this is guaranteed to include the optimum. This idea enables us to perform Bayesian optimization in a low-dimensional space to optimize a high-dimensional function with low intrinsic dimensionality. Importantly, it is not restricted to cases with axis-aligned intrinsic dimensions.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure2: Embedding from d = 1 into D = 2. The box illustrates the 2D constrained space X , while the thicker red line illustrates the 1D constrained space Y. Note that if Ay is outside X , it is projected onto X . The set Y must be chosen large enough so that the projection of its image, AY, onto the effective subspace (vertical axis in this diagram) covers the vertical side of the box.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Comparison of random search (RANDOM), Bayesian optimization (BO), method by [Chen et al., 2012] (HD BO), and REMBO. Left: D = 25 extrinsic dimensions; Middle: D = 25, with a rotated objective function; Right: D = 10 9 extrinsic dimensions. We plot means and 1/4 standard deviation confidence intervals of the optimality gap across 50 trials.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "x = arg max x\u2208X f (x).", "formula_coordinates": [1.0, 134.36, 495.41, 82.29, 16.55]}, {"formula_id": "formula_1", "formula_text": "f 1:t f * \u223c N m(x 1:t ), K(x 1:t , x 1:t ) k(x 1:t , x * ) k(x * , x 1:t ) k(x * , x * ) .", "formula_coordinates": [2.0, 330.38, 82.46, 217.51, 22.19]}, {"formula_id": "formula_2", "formula_text": "f * |D t , x * \u223c N (\u00b5(x * |D t ), \u03c3(x * |D t )),", "formula_coordinates": [2.0, 359.43, 146.73, 154.14, 11.72]}, {"formula_id": "formula_3", "formula_text": "x \u22a5 \u2208 T \u22a5 \u2282 R D , we have f (x) = f (x + x \u22a5 ) = f (x ),", "formula_coordinates": [2.0, 315.0, 614.08, 243.0, 11.23]}, {"formula_id": "formula_4", "formula_text": "\u03a6\u03a6 T Ay = \u03a6c = x . Thus Ay = x + x for some x \u2208 T \u22a5 since x is the projection Ay onto T . Consequently, f (Ay) = f (x + x ) = f (x ).", "formula_coordinates": [3.0, 54.0, 259.15, 243.0, 33.21]}, {"formula_id": "formula_5", "formula_text": "d 2 e , I d 2 e \u00d7d 2 e", "formula_coordinates": [3.0, 96.15, 367.64, 39.11, 11.56]}, {"formula_id": "formula_6", "formula_text": "d = 1 into D = 2.", "formula_coordinates": [3.0, 431.19, 333.99, 85.55, 8.96]}, {"formula_id": "formula_7", "formula_text": "P B \u22121 2 \u2265 \u221a d e \u2264 .", "formula_coordinates": [4.0, 122.96, 111.57, 105.08, 24.14]}, {"formula_id": "formula_8", "formula_text": "\u2264 B \u22121 2 x 2 = B \u22121 2 x 2 \u2264 \u221a de x 2 .", "formula_coordinates": [4.0, 58.98, 150.04, 238.02, 23.54]}, {"formula_id": "formula_9", "formula_text": "y 2 \u2264 \u221a d e x 2 \u2264 \u221a d e d e .", "formula_coordinates": [4.0, 109.73, 253.88, 136.51, 24.14]}, {"formula_id": "formula_10", "formula_text": "\u221a d, \u221a d] d", "formula_coordinates": [4.0, 76.41, 335.35, 38.32, 17.23]}, {"formula_id": "formula_11", "formula_text": "k d (y (1) , y (2) ) = exp \u2212 y (1) \u2212 y (2) 2 2 2 .", "formula_coordinates": [4.0, 87.53, 559.07, 175.94, 23.89]}, {"formula_id": "formula_12", "formula_text": "k D (y (1) , y 2 ) = exp \u2212 p X (Ay (1) ) \u2212 p X (Ay (2) ) 2 2 2 ,", "formula_coordinates": [4.0, 60.7, 640.06, 229.6, 23.89]}, {"formula_id": "formula_13", "formula_text": "k D \u03bb (y (1) , y (2) ) = exp \u2212 \u03bb 2 g(s(Ay (1) ), s(Ay (2) )) 2 ,", "formula_coordinates": [4.0, 325.68, 259.2, 221.64, 22.31]}, {"formula_id": "formula_14", "formula_text": "x (1) , x (2) ) = |{i : x (1) i = x", "formula_coordinates": [4.0, 372.36, 357.36, 116.76, 14.07]}, {"formula_id": "formula_15", "formula_text": "k d = 2 d = 4 d =", "formula_coordinates": [5.0, 81.98, 352.61, 166.16, 6.12]}], "doi": ""}