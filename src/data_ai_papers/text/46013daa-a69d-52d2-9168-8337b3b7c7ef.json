{"title": "When your Cousin has the Right Connections: Unsupervised Bilingual Lexicon Induction for Related Data-Imbalanced Languages", "authors": "Niyati Bafna; Cristina Espa\u00f1a-Bonet; Josef Van Genabith; Beno\u00eet Sagot; Rachel Bawden", "pub_date": "", "abstract": "Most existing approaches for unsupervised bilingual lexicon induction (BLI) depend on good quality static or contextual embeddings requiring large monolingual corpora for both languages. However, unsupervised BLI is most likely to be useful for low-resource languages (LRLs), where large datasets are not available. Often we are interested in building bilingual resources for LRLs against related high-resource languages (HRLs), resulting in severely imbalanced data settings for BLI. We first show that state-of-the-art BLI methods in the literature exhibit near-zero performance for severely data-imbalanced language pairs, indicating that these settings require more robust techniques. We then present a new method for unsupervised BLI between a related LRL and HRL that only requires inference on a masked language model of the HRL, and demonstrate its effectiveness on truly low-resource languages Bhojpuri and Magahi (with <5M monolingual tokens each), against Hindi. We further present experiments on (mid-resource) Marathi and Nepali to compare approach performances by resource range, and release our resulting lexicons for five low-resource Indic languages: Bhojpuri, Magahi, Awadhi, Braj, and Maithili, against Hindi.", "sections": [{"heading": "Introduction", "text": "Bilingual lexicons are a basic resource with varied uses, both in themselves, for dictionary building and language learning, as well as seeds for solving other problems in natural language processing (NLP), such as parsing (Zhao et al., 2009;Durrett et al., 2012) and word-to-word and unsupervised machine translation (Irvine and Callison-Burch, 2013;Thompson et al., 2019).\nWhile there is growing interest in unsupervised or minimally supervised bilingual lexicon induction (BLI), existing methods often depend on aligning monolingual word embedding spaces, assumed to be of good quality for both languages, and/or bilingual supervision (Artetxe et al., 2016(Artetxe et al., , 2017Conneau et al., 2018;Artetxe et al., 2018aArtetxe et al., ,b, 2019. However, extremely low-resource languages (LRLs) and dialects often lack good quality embeddings due to limited monolingual data, leading to very low or near-zero performance of alignment-based methods for these languages (Wada et al., 2019;Eder et al., 2021). This is the case for the under-researched Indic language continuum, which is the focus of this article (see Section 2 for a description of the linguistic setup in India that motivates our work). We work with five extremely low-resourced Indic languages, Bhojpuri (bho), Magahi mag), Awadhi (awa), Maithili (mai), and Braj (bra), which are closely related to higher-resourced Hindi, and which have extremely limited resources, in terms of training data (<5M tokens of monolingual data) and embeddings, and even evaluation data. We demonstrate that state-of-the-art, alignment-based methods perform poorly in these settings, and introduce a new method for unsupervised BLI that performs much better. We aim to design methods that work well in characteristic data-scarce conditions, as well as generate resources for further work in these languages.\nOur main contribution is a novel unsupervised BLI method to address the typical scenario of the LRLs of the Indic continuum, i.e. for extremely LRLs that share significant overlap with a closely related HRL. We suppose that a masked language model (MLM) such as monolingual BERT (Devlin et al., 2019) is available for the HRL and that we have some monolingual LRL sentences that contain unknown words. The method consists of building a lexicon iteratively by using the HRL MLM over LRL sentences to extract translation equivalents, and replacing learnt words in LRL sentences with HRL equivalents to make them more tractable for the HRL MLM for future unknown words (see Section 4).\nGiven the lack of existing gold lexicons for our target languages (a frequent scenario for extremely LRLs), we create silver lexicons for Bhojpuri and Magahi created from parallel data, unfortunately unavailable for Awadhi, Maithili, and Braj. We also perform control experiments on Marathi and Nepali, two medium-resource languages more distantly related to Hindi with available gold lexicons, and discuss the performance of canonical methods and our proposed method on these languages, shedding light on what strategies are appropriate for differently-resourced language pairs. Our experiments indicate that current state-of-the-art methods are not suitable for low-resourced dialects, and methods that account for the data imbalance in the language pair, such as ours, may be more successful. We release our code, our generated lexicons for all languages (to our knowledge the first to be publicly released for all languages except Bhojpuri), 1 and our created silver evaluation lexicons for Bhojpuri and Magahi. 2 See details of our released lexicons in Section 7.\nOur motivation and method, while relevant to the 40+ resource-scarce languages of the Indic language family and other Indian languages, are also relevant to other linguistic systems with similar circumstances, i.e. with a single high-or-medium resource language (usually a standard dialect), and several closely related dialects with lexical, morphological, and syntactic variation, written in the same script with or without orthographic standardization. This setup describes, for example, the Arabic continuum, the Turkic language continuum, and the German dialect system.", "publication_ref": ["b39", "b12", "b18", "b31", "b1", "b2", "b9", "b3", "b33", "b14", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "Linguistic Setup in India", "text": "India has around 15-22 languages that are mediumto-high-resource, such as Hindi, Marathi, and Tamil, but dozens of other languages and dialects that are extremely low-resourced, with very little monolingual data (<5M tokens), and no other resources, such as Marwadi, Tulu, Dogri, and Santhali. These languages are often closely related to at least one high-resource language (HRL), meaning that they share morphosyntactic properties as well as a high number of cognates (Jha, 2019;Mundotiya et al., 2021) (see Table 1 for examples). They often have no official status in the regions where they are spoken, and therefore do not have concerted funding efforts for data collection or research. Even when such efforts do exist, 3 the collected corpora are rarely of the magnitude at which static or contextual embeddings can be well-estimated. While the actual number of distinct dialects and languages spoken in India is contested, people self-reported 1 Although dedicated teams are working towards building resources for these languages (Mundotiya et al., 2021), these resources (including evaluation resources)\nhave not yet been made public as far as we know.\n2 Code and resources available here: https://gi thub.com/niyatibafna/BLI-for-Indic-langu ages.\n3 See https://data.ldcil.org/text. about 576 such \"mother tongue\" dialects in the latest census, 4 which were then grouped into around 121 languages. Only 22 of these languages have official status (i.e. they are either the official language of some state/union territory, or have national cultural significance), and are therefore accorded funds for the development of resources. Therefore, although some studies in the literature question the real use case for entirely unsupervised BLI , since it is \"easy\" to collect a small bilingual lexicon, we argue that situations such as these, where there is a large number of languages to build support for, and where efforts in data collection and annotation for individual languages are restricted by the availability of funds, do constitute genuine application scenarios for unsupervised BLI.\nFurthermore, we focus on a scenario where the two languages in question are closely related. This is because for most of the low-resource languages in the Indian context cited above, we can usually find a linguistic neighbour that is relatively well off, usually one of India's 22 scheduled languages. 5 In general, when building resources for a given lowresource dialect or language, it is likely that the standard variant of that dialect, or the HRL closest to it, will have large enough corpora available to build a good quality MLM. We target our efforts to these situations.", "publication_ref": ["b19", "b43", "b43"], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "Related Work", "text": "Recent years have seen interest in unsupervised BLI (Haghighi et al., 2008;Artetxe et al., 2016Artetxe et al., , 2017Conneau et al., 2018;Artetxe et al., 2018aArtetxe et al., ,b, 2019, allowing the possibility of BLI for LRLs. Most unsupervised approaches, notably MUSE (Conneau et al., 2018) and VecMap (Artetxe et al., 2016(Artetxe et al., , 2017(Artetxe et al., , 2018a are based on training static embeddings from large monolingual corpora (Mikolov et al., 2013;Bojanowski et al., 2017), and aligning the embeddings using linear or non-linear mappings, using an initial seed (Xing et al., 2015;Artetxe et al., 2016).\nRecent works have also looked at using contextual embeddings or BERT-based models (Peters et al., 2018;Devlin et al., 2019;Ruder et al., 2019) for BLI. Gonen et al. (2020) induce word-level trans-Meaning boy (nom) sister (nom) your (hon., fem. sing. obj) told (completive) (you) are going Hindi l@\u00e3kA: b@h@n a:pki: b@t \":a:ja:/ k@:h lija: d\u00fda: r@he: ho: Awadi l@\u00e3kA: b@hin a:p@n b@t \":a:v@t \" d\u00fda:t \" @ha:i Bhojpuri l@ika: b@hin a:p@n k@h@l d\u00fda:t \" ba: Magahi l@i:ka: b@hin @p@n k@h@lie: d\u00fda: h@i Maithili l@\u00e3kA: b@hin @ha:nk k@h@lhu n d\u00fda: r@h@l @\u00d9 h i Hindi Awadi Bhojpuri Magahi Maithili Meaning d\u00fda: r@he: ho: d\u00fda:t \" @ha:i d\u00fda:t \" ba: d\u00fda: h@i d\u00fda: r@h@l @\u00d9 h i (you) are going l@\u00e3kA: l@\u00e3kA: l@ika: l@i:ka: l@\u00e3kA: boy (nom.) b@t \":a:ja:/ k@:h lija: b@t \":a:v@t \" k@h@l k@h@lie: k@h@lhu n told (completive) a:pki: a:p@n a:p@n @p@n @ha:nk your (hon., fem. sing. obj) b@h@n b@hin b@hin b@hin b@hin sister    lations by directly prompting mBERT (Devlin et al., 2019). Yuan et al. (2020) present a human-in-theloop system for BLI in four low-resource languages, updating contextual embeddings with the help of annotations provided by a native speaker. Zhang et al. (2021) present CSCBLI, a method that uses a \"spring network\" to align non-isomorphic contextual embeddings, and interpolates them with static embeddings to estimate word similarities, showing superior results to other methods using contextual embeddings, notably BLISS (Patra et al., 2019). These approaches rely on parallel data or large monolingual corpora for good quality contextual embeddings. However, for low-resource languages, contextual embeddings from both monolingual and multilingual models are known to be unreliable (Wu and Dredze, 2020). Later works show the failings of the above approaches in low-resource settings (Adams et al., 2017;Kuriyozov et al., 2020;Chimalamarri et al., 2020;Eder et al., 2021) and propose alternative training strategies such as joint training of static embeddings (Woller et al., 2021;Bafna et al., 2022), and multilingual embeddings from LSTM-based models (Wada et al., 2019). However, these works either address a higher resource range (>15M tokens), use bilingual lexicons as seeds, or show low scores (\u224830 precision@5) for unsupervised BLI. In general, there is a paucity of attention given to setups where there is a severe resource imbalance between the two languages of the BLI pair, despite this being a very typical real-world scenario.", "publication_ref": ["b17", "b1", "b2", "b9", "b3", "b9", "b1", "b2", "b3", "b25", "b7", "b36", "b1", "b28", "b10", "b29", "b16", "b10", "b37", "b38", "b27", "b35", "b0", "b22", "b8", "b14", "b34", "b6", "b33"], "figure_ref": [], "table_ref": []}, {"heading": "Method", "text": "Our method is intended for a closely related HRL (source) and LRL (target) pair, written in the same script, and given that we can train or already have a good quality monolingual MLM for the HRL. The main idea is that if we mask an unknown word in the LRL sentence, feed the masked LRL sentence to the HRL MLM, and ask the HRL MLM to propose candidates for the masked LRL word, the HRL MLM should have access to enough contextual cues due to shared vocabulary and syntax to propose meaningful HRL candidates for the masked word. This potentially gives us translation equivalence between the original LRL word and the best scoring proposed HRL candidate. We proceed in an iterative manner, growing the lexicon from equivalents gained from each processed sentence, and using learned equivalents in the lexicon to replace known LRL words with HRL equivalents to process future sentences.\nStarting with an empty HRL-LRL bilingual lexicon, we perform the following steps to update our lexicon iteratively, explained in further detail below, and shown in Algorithm 1: (i) we choose an input, consisting of an LRL sentence, and a source LRL word occurring in it, (ii) we replace known words in the input sentence by HRL equivalents using the current state of the lexicon, in order to make the sentence more HRL-like, (iii) the resulting sentence is passed to the HRL MLM to obtain HRL candidate suggestions for the masked LRL word, (iv) we use a reranking heuristic to choose the best HRL candidate, if any, and (v) we update the lexicon if we have found a new equivalent pair.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Choosing (sentence, word) pairs to process", "text": "Intuitively, the chance of the HRL MLM giving accurate translation equivalents for the (LRL) word is higher if the LRL sentence is more easily \"comprehensible\" to the HRL MLM, or if the LRL sentence already has several HRL words in it. Therefore, we aim to first process words in sentences that have a higher concentration of known words, where known words are either shared vocabulary or words that are already in the current state of our lexicon. These words are replaced by their HRL equivalents before the sentence is passed to the HRL MLM. 6 We maintain a priority list of (sentence, word) pairs based on the percentage of known words in the sentence and update the list after every batch of sentences based on new learned translations. 7", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Reranking", "text": "The HRL MLM may propose valid candidates for the masked token that are not translation equivalents to the LRL source word; typically, there may be a wide range of reasonable possibilities for any masked word. Therefore, we rerank the returned HRL candidates based on orthographic closeness to the masked LRL word. Our use of orthographic closeness as the basis of our rerankers is motivated by the high percentage of orthographically similar cognates, borrowings, and spelling variants in the vocabulary of these languages with respect to each other (shown by Jha (2019) for Maithili and Hindi). Note that minimum normalized edit distance as a stand-alone approach, i.e. positing the orthographically closest HRL word as a translation equivalent for any LRL word, performs badly for various reasons (Bafna et al., 2022). We compare two rerankers, Basic and Rulebook.", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "Basic", "text": "In the Basic approach, we simply use normalized orthographic similarity (computed using Levenshtein distance) between the candidate and the original masked word. This reranker considers all character substitutions equally costly.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Rulebook", "text": "We may see from discovered cognate pairs that certain character transformations are very common (corresponding to regular sound change, or systematic differences in orthographic conventions), and so should be less costly than others. Similarly, different language pairs may have different preferences for cheap or costly character substitutions.\nIn the Rulebook variant, we use Bafna et al.'s (2022) iterative expectation-maximization (EM) method to learn a custom edit-distance matrix for 6 We mask whole words and accept single token responses (as the default) from the MLM. In practice, this does not pose a big problem, since the HRL MLM tokenizer has a large vocabulary size (52000): 86% and 81% in the Hindi side of the Bhojpuri and Magahi silver lexicons respectively are preserved as single tokens. We leave it to future work to handle multi-word terms.\n7 Specifically, the priority list is created from the (sentence, unk_word) pairs by first sorting them by the number of times each instance has previously been processed, and then by the percentage of other unknown words in the sentence, both in ascending order.\nthe source and target character sets. This custom edit-distance matrix is used as an orthographic reranker for our approach (lines 6-9 in Algorithm 1).\nThe idea of this reranker is to iteratively optimize character substitution probabilities from the source to target character set in \"known\", or hypothesized, cognate pairs, while simultaneously learning new cognate pairs by reranking candidates suggested by the HRL MLM, using the current state of the substitution probabilities. Setup Let \u03c7 s and \u03c7 t represent the sets of characters on the source (LRL) and target (HRL) sides, respectively. We define a scoring function, S(c i , c j ) that provides a score for replacing a character c i \u2208 \u03c7 s with c j \u2208 \u03c7 t . Insertions and deletions are considered special cases of replacement, where a null character is introduced or replaced. For a given source set character, S is modelled as a transformation probability distribution over \u03c7 t . Initially, the probabilities in S are assigned to favor self-transformations (typically set to 0.5), and the remaining probability mass is evenly distributed among other characters.\nAt any given iteration, we can calculate the score for a source-target character substitution, viewed as a conditional probability:\nS(c i , c j ) = C(c i , c j ) T (c i )(1)\nHere, C(a, b) is the number of times we have seen a \u2192 b, and T (a) is the total number of times we have seen a on the source side.\nEM Steps for Rulebook. 1) Expectation step. Given a list of top k candidates for a given source word s: for each candidate pair (s, t), we find Ops(s, t), which is the minimal list of the operations we need to perform to get from s to t. Each member in Ops is of the type (c i , c j ). Note that we also want to estimate S(a, a) \u2200 a, and so we also use a \"retain\" operation, for characters that remain the same. The score for the pair (s, t) is computed as:\n\u03b6(s, t) = \u2212 (a,b)\u2208Ops log(S(a, b)),(2)\nwhere the lower the \u03b6 the more probable it is that a pair is equivalent. For a given s, we can then always find the word that is the most probable equivalent as t best = argmin ti\u0338 =s (\u03b6(s, t i )) (line 6 in Algorithm 1). We then add (s, t best ) to our learned lexicon (line 8).\n2) Maximization step. We update the model parameters based on the newly identified equivalents in the previous step (line 9 in Algorithm 1). This is done by increasing the counts of all observed edit distance operations:\nC(a, b) := C(a, b) + 1 \u2200(a, b) \u2208 Ops(s, t) T (a) := T (a) + 1 \u2200(a, b) \u2208 Ops(s, t)\nWe disallow updates for s = t (i.e. identical words) in the training phase, to mitigate exploding selftransform probabilities.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Multiple passes over the input", "text": "Once all (sentence, word) pairs have been processed once (or n times), we reprocess them (for an (n + 1) th pass) in the hope of gaining more accurate translations, as previously unknown neighbour words may have been learned in the meantime.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Hyperparameters", "text": "We use a minimum normalized orthographic similarity threshold of 0.5 (see line 7 of Algorithm 1). This threshold was heuristically chosen. We set the maximum number of passes to 3, meaning that the algorithm terminates if all unknown words have been processed 3 times. We found in our initial experiments that the algorithm yields very few or no new words in further passes. This also serves as a terminating condition (line 1 in Algorithm 1).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Examples", "text": "We give examples of inputs and outputs of our method in Table 2, illustrating the outputs for Basic. As we see, the Hindi BERT is fairly good at giving reasonable Hindi candidates for the masked Bhojpuri, although, naturally, these candidates may not be equivalents of the masked word, as shown for the top candidates in rows 2 and 3. Applying reranking based on orthographic similarity solves this problem to a large extent, serving to identify translation equivalents from among given candidates. We also see an example (row 3) where replacing a Bhojpuri word with its Hindi equivalent in the input sentence helps the Hindi MLM to produce more reasonable Hindi candidates for the masked word.   ", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "Experimental Settings", "text": "Monolingual Data We use monolingual data from the LoResMT shared task (Ojha et al., 2020) for Bhojpuri and Magahi, and the VarDial 2018 shared task data (Zampieri et al., 2018) for Bhojpuri, Awadhi and Braj. For Bhojpuri, we additionally use the BHLTR project (Ojha, 2019). We use the BMM corpus (Mundotiya et al., 2021) and the Wordschatz Leipzig corpus (Goldhahn et al., 2012) for Maithili. For Marathi and Nepali, we use large-scale monolingual corpora made available by IndicCorp (Kakwani et al., 2020) and   Baselines We compare our approaches against semi-supervised VecMap approach with CSLS (Artetxe et al., 2018b,a), using identical words as seeds, with 300-dimensional fastText embed-dings (Bojanowski et al., 2017). 9 We also choose CSCBLI (Zhang et al., 2021) as a representative of methods using contextual representations, hypothesizing that the ensemble of static and contextual embeddings may perform better than VecMap. Finally, we report results for a trivial baseline ID, the identity function, representing vocabulary overlap.\nEvaluation Data Given the lack of gold lexicons between Hindi and our LRLs, we create silver lexicons instead from parallel data. We use FastAlign with GDFA (Dyer et al., 2013) to extract word alignments from existing gold Bhojpuri-Hindi and Magahi-Hindi parallel data (\u2248500 sentences per language) (Ojha, 2019). 10 We use the two best candidates per source word in the resulting silver lexicons as valid translations. 11 This yields 2,469 and 3,359 entries for Bhojpuri and Magahi respectively. We report the manually evaluated quality of the silver lexicons in the following paragraph. For Marathi and Nepali, we use existing gold parallel lexicons against Hindi, taken from IndoWordNet (Kakwani et al., 2020), manually aligned to the Hindi Word-Net. We obtain lexicons with 35,000 and 22,000 entries for Marathi and Nepali respectively.", "publication_ref": ["b45", "b46", "b44", "b43", "b40", "b41", "b7", "b38", "b13", "b44", "b40", "b41"], "figure_ref": [], "table_ref": []}, {"heading": "Manual Evaluation of Silver Lexicons", "text": "We perform a manual evaluation of our silver lexicons, in order to judge the credibility of the reported results for our methods for Bhojpuri and Magahi. We manually examine 150 entries in the automatically created Bhojpuri lexicon, and find that 90% of entries are satisfactory, i.e. they list accurate Hindi equivalents of Bhojpuri words. We observe a few general problems with the lexicon, and list representative examples in Table 3:\n\u2022 Missing common synonyms, e.g. in row 1 of Table 3. This kind of error results in underestimation of precision scores for all approaches.\n\u2022 Problems with correctly equating inflections, missing feminine inflections, e.g. row 2. A natural problem arising from differences in morphological systems of the source and target language is that inflected verbs can be difficult to match cross-lingually. This results in missing equivalents of a given inflected form. For example, while genderless verbs in Bhojpuri should ideally be listed with the corresponding masculine and feminine verbs in Hindi, we observe that they are often missing one gender inflection, usually the feminine one. Similarly, not all possible target inflectional variants of a source inflection are listed for each verb entry.\n\u2022 Multi-word equivalences lead to errors. For example, in row 3, the single-word Bhojpuri source verb has a noun-light verb complex equivalent in Hindi (consisting of two words, literally meaning \"sharing do\"), and the silver lexicon lists the light verb (\"do\") as the target translation. This is also observed in the case of other verb equivalences, where one of the languages using multiple tokens to express an inflection, leading to incorrect matches in the silver lexicon.\n\u2022 Miscellaneous errors. The lexicon contains some entirely incorrect equivalents (8.76%), due to word alignment errors, e.g. row 4.\nNote that we only mark entries as wrong if the listed equivalents are inaccurate, and so faults such as missing synonyms and inflections, which affected 7.33% of the sample we examined, are not represented in the error percentage reported.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_5", "tab_5"]}, {"heading": "Results and Discussion", "text": "We report precision@2 and accuracy on nonidentical predictions (NIA) in Table 5. 12 NIA is calculated by taking all non-identical predictions in the top 2 predictions per word, and reporting the percentage of those predictions that were marked correct by the evaluation lexicons. We report this metric because precision@2 may be inflated by \"easy\" identical word predictions.\nBaselines Table 6 provides examples of the performance of these approaches. VecMap performs well for Marathi: we provide examples where it predicts correct equivalents for rare words (row 8), noncognates (row 9), as well as frequent words (row 7). However, for Nepali, Bhojpuri, and Magahi, both VecMap and CSCBLI make seemingly random wrong predictions on almost all words (rows 1, 2, and 6), with near-zero performance, probably due to the low quality of static and contextual embeddings for the LRLs. CSCBLI also fails for Marathi, indicating that the Marathi contextual embeddings may still be of poor quality or that the approach may not generalize well to untested language pairs. While the failure of these baselines for Nepali is surprising, it can perhaps be explained by the fact that Nepali has about five times less data than Marathi, and less lexical overlap with Hindi.\nOur methods Our Basic and Rulebook approaches outperform ID by more than 20 accuracy points for all languages. Rulebook gains very little, if at all, over Basic, but Rulebook has an edge when it comes to predicting cognates with common sound correspondences (see row 5). We observe that these approaches are reasonably successful for Bhojpuri and Magahi on cognate verbs and common nouns, but fail on syntactic words and postpositions (row 3 for Basic), and may be confused by unrelated words with chance orthographic similarity even for common words (row 5 for Basic). Furthermore, these approaches often predict incorrect inflections of the correct verbal/noun stem (we count these predictions as wrong), as in rows 1 and 4. Although Basic and Rulebook perform with high accuracy for Marathi and Nepali, their NIA is extremely low, indicating that they serve mainly to identify or \"sieve\" out vocabulary overlap. We see that the candidates proposed by the Hindi MLM are often in fact Marathi/Nepali words, indicating that it has seen some Marathi/Nepali data (due to corpus contamination and/or code-mixing) and is capable of performing mask-filling for Marathi/Nepali.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_8", "tab_11"]}, {"heading": "Manual Evaluation of Generated Lexicons", "text": "We manually examine errors in the non-identical predictions of Basic, looking at 60 randomly chosen non-identical Bhojpuri predictions. 13 We find that 31.7% of predictions are correctly inflected equivalents, as opposed to 18.1% given by the NIA quantitative evaluation. The underestimation is caused by missing synonyms in the silver lexicon. Furthermore, 25% are incorrectly inflected cognates of the source word, and the rest are unrelated words.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "How useful is reranking by orthographic distance?", "text": "We also ran the Basic approach without reranking with orthographic distance, i.e. we simply pick the top candidate suggested by the HRL mask-filling model as an equivalent. This approach is clearly worse than the standard Basic approach bho mag mar nep Method P@2 NIA P@2 NIA P@2    ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Ethics Statement", "text": "Our work is driven by the motivation to boost NLP for severely under-resourced languages of the Indic language belt, as well as contribute a method that may be relevant to other language families with a similar linguistic and resource setup. Our method relies on the predictions of large language models for the highresource language and is therefore fallible to 5  5). However, this approach can still identify and capture identical vocabulary.\nVariants We experimented with minor variants of the Rulebook update mechanisms to see if they result in boosts to performance. We tried disallowing updates for the null character, since we found that a large probability mass iteratively accumulates in the null character (or for deletion). We also incorporated a change in the original algorithm, whereby we made updates to the custom edit distance matrix based on the optimal list of substitutions as per the current state of the edit distance matrix, rather than choosing a minimal length path at random (with each substitution counted as length 1) from the source to the target word when several exist. However, these variants result in very minor improvements or even slight degradations to performance, and we do not report these results.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_8"]}, {"heading": "Details of released lexicons", "text": "We make our bilingual lexicons publicly available under a CC BY-NC 4.0 license for Bhojpuri, Magahi, Awadhi, Braj, and Maithili, and also release our created silver evaluation lexicons for Bhojpuri and Magahi under the same license. These are the first publicly available bilingual lexicons all these languages except Bhojpuri, to the best of our knowledge. The sizes of the released lexicons for each target language are provided in Table 4. Note that while we also release our generated lexicons for Marathi and Nepali, large high quality gold bilingual lexicons already exist for these languages (see Section 5) and should be used instead of ours; we are mainly interested in creating resources for the low-resource languages.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_6"]}, {"heading": "Conclusion", "text": "We introduce a novel method for unsupervised BLI between a related LRL and HRL, which only requires a good quality MLM for the HRL. This addresses an important gap in the existing literature, which often relies on good quality embeddings for both languages. Our method shows superior performance on two low-resource languages from the Indic continuum, against near-zero performances of existing state-of-the-art methods. We perform control experiments for two more distantly related Indic languages, and release resulting bilingual lexicons for five truly low-resource Indic languages.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Limitations", "text": "The applicability of our method is restricted to low-resource languages that are related to a highresource language. As the Basic and Rulebook method are directly dependent on orthographic distance between translation pairs, they are only useful for identifying cognate equivalents, borrowings, or alternate spellings in the source and target language. We also clarify that our method is not intended for mid-to-high resourced language pairs (such as Marathi-Hindi), where canonical stateof-the-art methods such as VecMap work more robustly, specifically on non-identical word equivalents. Our method therefore has a specific (although important) target scenario, i.e. it is a simple method to build bilingual lexicons for severely underresourced languages leveraging the resources of a closely related high-resource language, given that state-of-the-art methods fail in these settings.\nNote that we also only deal in the entirely unsupervised scenario in keeping with typical conditions for our target languages (see Section 2), and leave it to future work to improve these methods with a little supervision from bilingual lexicons, possibly obtained from parallel data. Another limitation of our work is that we were not able to provide true native speaker evaluation for the resulting target language lexicons, instead providing evaluation by the first author (Hindi native speaker) relying on knowledge of shared cognates, the morphology of the target language, and inflection tables. We provide examples in Table 6 and Table 2, and release the automatically created as well as silver lexicons. Finally, our method is only capable of providing single token (HRL) matches to the masked (LRL) whole word. As discussed in Section 4, this problem does not affect the large majority of cases. We leave it to future work to extend our idea to handle multi-token words and multi-word expressions using, for example, spanfilling language models (Donahue et al., 2020).", "publication_ref": ["b11"], "figure_ref": [], "table_ref": ["tab_11", "tab_2"]}, {"heading": "Ethics Statement", "text": "Our work is driven by the aim to boost NLP for severely under-resourced languages of the Indic language belt, as well as contribute a method that may be relevant to other language families with a similar linguistic and resource setup. Our method relies on the predictions of language models for the high-resource language and is therefore fallible to general ethical issues with such models, including caste, religion, and gender biases shown to be exhibited by such models (Malik et al., 2022). bho mag P@1 P@3 P@5 P@1 P@3 P@5   ", "publication_ref": ["b24"], "figure_ref": [], "table_ref": []}, {"heading": "A. Additional Results", "text": "We report P@1,3,5 in Table 7 and NIA@1,3,5 in Table 8. We see that both Basic and Rulebook approaches do not benefit from considering more than 3 best answers. In general, we see the same relative trend as in Table 5.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_13", "tab_14", "tab_8"]}, {"heading": "Acknowledgements", "text": "This work was partly funded by the last two authors' chairs in the PRAIRIE institute funded by the French national agency ANR as part of the \"Investissements d'avenir\" programme under the reference ANR-19-P3IA-0001. First and second authors are supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -Project-ID 232722074-SFB 1102. Second and third authors are supported by the EU project LT-Bridge (GA952194).", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Cross-Lingual Word Embeddings for Low-Resource Language Modeling", "journal": "Association for Computational Linguistics", "year": "2017", "authors": "Oliver Adams; Adam Makarucha; Graham Neubig; Steven Bird; Trevor Cohn"}, {"ref_id": "b1", "title": "Learning Principled Bilingual Mappings of Word Embeddings While Preserving Monolingual Invariance", "journal": "Association for Computational Linguistics", "year": "2016", "authors": "Mikel Artetxe; Gorka Labaka; Eneko Agirre"}, {"ref_id": "b2", "title": "Learning Bilingual Word Embeddings with (Almost) No Bilingual Data", "journal": "Long Papers", "year": "2017", "authors": "Mikel Artetxe; Gorka Labaka; Eneko Agirre"}, {"ref_id": "b3", "title": "A Robust Self-Learning Method for Fully Unsupervised Cross-Lingual Mappings of Word Embeddings", "journal": "Long Papers", "year": "2018", "authors": "Mikel Artetxe; Gorka Labaka; Eneko Agirre"}, {"ref_id": "b4", "title": "Generalizing and Improving Bilingual Word Embedding Mappings with a Multi-Step Framework of Linear Transformations", "journal": "", "year": "2018", "authors": "Mikel Artetxe; Gorka Labaka; Eneko Agirre"}, {"ref_id": "b5", "title": "Bilingual Lexicon Induction through Unsupervised Machine Translation", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Mikel Artetxe; Gorka Labaka; Eneko Agirre"}, {"ref_id": "b6", "title": "Combining Noisy Semantic Signals with Orthographic Cues: Cognate Induction for the Indic Dialect Continuum", "journal": "", "year": "2022", "authors": "Niyati Bafna; Josef Van Genabith; Cristina Espa\u00f1a-Bonet; Zden\u011bk \u017dabokrtsk\u00fd"}, {"ref_id": "b7", "title": "Enriching Word Vectors with Subword Information", "journal": "Transactions of the Association for Computational Linguistics", "year": "2017", "authors": "Piotr Bojanowski; Edouard Grave; Armand Joulin; Tomas Mikolov"}, {"ref_id": "b8", "title": "Morphological Segmentation to Improve Crosslingual Word Embeddings for Low Resource Languages", "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing", "year": "2020", "authors": "Santwana Chimalamarri; Dinkar Sitaram; Ashritha Jain"}, {"ref_id": "b9", "title": "Word Translation Without Parallel Data", "journal": "", "year": "2018", "authors": "Alexis Conneau; Guillaume Lample; Marc'aurelio Ranzato; Ludovic Denoyer; Herv\u00e9 J\u00e9gou"}, {"ref_id": "b10", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "journal": "Long and Short Papers", "year": "2019", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"ref_id": "b11", "title": "Enabling language models to fill in the blanks", "journal": "", "year": "2020", "authors": "Chris Donahue; Mina Lee; Percy Liang"}, {"ref_id": "b12", "title": "Syntactic Transfer Using a Bilingual Lexicon", "journal": "Association for Computational Linguistics", "year": "2012", "authors": "Greg Durrett; Adam Pauls; Dan Klein"}, {"ref_id": "b13", "title": "A Simple, Fast, and Effective Reparameterization of IBM Model 2", "journal": "Association for Computational Linguistics", "year": "2013", "authors": "Chris Dyer; Victor Chahuneau; Noah A Smith"}, {"ref_id": "b14", "title": "Anchor-based Bilingual Word Embeddings for Low-Resource Languages", "journal": "Online. Association for Computational Linguistics", "year": "2021", "authors": "Tobias Eder; Viktor Hangya; Alexander Fraser"}, {"ref_id": "b15", "title": "Non-Linear Instance-Based Cross-Lingual Mapping for Non-Isomorphic Embedding Spaces", "journal": "", "year": "2020", "authors": "Goran Glava\u0161; Ivan Vuli\u0107"}, {"ref_id": "b16", "title": "It's not Greek to mBERT: Inducing Word-Level Translations from Multilingual BERT", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Shauli Hila Gonen; Yanai Ravfogel; Yoav Elazar;  Goldberg"}, {"ref_id": "b17", "title": "Learning Bilingual Lexicons from Monolingual Corpora", "journal": "Association for Computational Linguistics", "year": "2008", "authors": "Aria Haghighi; Percy Liang; Taylor Berg-Kirkpatrick; Dan Klein"}, {"ref_id": "b18", "title": "Combining Bilingual and Comparable Corpora for Low Resource Machine Translation", "journal": "", "year": "2013", "authors": "Ann Irvine; Chris Callison-Burch"}, {"ref_id": "b19", "title": "Exploring the Degree of Similarities between Hindi and Maithili Words from Glottochronological Perspective", "journal": "International Journal of Innovations in TESOL and Applied Linguistics", "year": "2019", "authors": "Jha Sanjay Kumar"}, {"ref_id": "b20", "title": "Pre-Trained BERT Transformer models for Devanagari based Hindi and Marathi Languages", "journal": "", "year": "", "authors": ""}, {"ref_id": "b21", "title": "Subhash Chandra Bose Gali, Vish Subramanian, and Partha Talukdar. 2021. MuRIL: Multilingual Representations for Indian Languages", "journal": "", "year": "", "authors": "Simran Khanuja; Diksha Bansal; Sarvesh Mehtani; Savya Khosla; Atreyee Dey; Balaji Gopalan; Dilip Kumar Margam; Pooja Aggarwal; Rajiv Teja Nagipogu; Shachi Dave; Shruti Gupta"}, {"ref_id": "b22", "title": "Cross-Lingual Word Embeddings for Turkic Languages", "journal": "European Language Resources Association", "year": "2020", "authors": "Elmurod Kuriyozov; Yerai Doval; Carlos G\u00f3mez-Rodr\u00edguez"}, {"ref_id": "b23", "title": "A Large Scale Nepali Text Corpus", "journal": "", "year": "2020", "authors": "Rabindra Lamsal"}, {"ref_id": "b24", "title": "Socially Aware Bias Measurements for Hindi Language Representations", "journal": "", "year": "2022", "authors": "Vijit Malik; Sunipa Dev; Akihiro Nishi; Nanyun Peng; Kai-Wei Chang"}, {"ref_id": "b25", "title": "Efficient Estimation of Word Representations in Vector Space", "journal": "", "year": "2013", "authors": "Tomas Mikolov; Kai Chen; Greg Corrado; Jeffrey Dean"}, {"ref_id": "b26", "title": "Linguistic Resources for Bhojpuri, Magahi, and Maithili: Statistics about Them, Their Similarity Estimates, and Baselines for Three Applications", "journal": "ACM Transactions on Asian and Low-Resource Language Information Processing", "year": "2021", "authors": "Rajesh Kumar Mundotiya; Manish Kumar Singh; Rahul Kapur; Swasti Mishra; Anil Kumar Singh"}, {"ref_id": "b27", "title": "Bilingual Lexicon Induction with Semisupervision in Non-Isometric Embedding Spaces", "journal": "", "year": "2019", "authors": "Barun Patra; Joel Ruben ; Antony Moniz; Sarthak Garg; Matthew R Gormley; Graham "}, {"ref_id": "b28", "title": "Deep Contextualized Word Representations", "journal": "Long Papers", "year": "2018", "authors": "Matthew E Peters; Mark Neumann; Mohit Iyyer; Matt Gardner; Christopher Clark; Kenton Lee; Luke Zettlemoyer"}, {"ref_id": "b29", "title": "A Survey of Cross-Lingual Word Embedding Models", "journal": "Journal of Artificial Intelligence Research", "year": "2019", "authors": "Sebastian Ruder; Ivan Vuli\u0107; Anders S\u00f8gaard"}, {"ref_id": "b30", "title": "On the Limitations of Unsupervised Bilingual Dictionary Induction", "journal": "Long Papers", "year": "2018", "authors": "Anders S\u00f8gaard; Sebastian Ruder; Ivan Vuli\u0107"}, {"ref_id": "b31", "title": "HABLex: Human Annotated Bilingual Lexicons for Experiments in Machine Translation", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Brian Thompson; Rebecca Knowles; Xuan Zhang; Huda Khayrallah; Kevin Duh; Philipp Koehn"}, {"ref_id": "b32", "title": "Do We Really Need Fully Unsupervised Cross-Lingual Embeddings?", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Ivan Vuli\u0107; Goran Glava\u0161; Roi Reichart; Anna Korhonen"}, {"ref_id": "b33", "title": "Unsupervised Multilingual Word Embedding with Limited Resources using Neural Language Models", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Takashi Wada; Tomoharu Iwata; Yuji Matsumoto"}, {"ref_id": "b34", "title": "Do Not Neglect Related Languages: The Case of Low-Resource Occitan Cross-Lingual Word Embeddings", "journal": "Association for Computational Linguistics", "year": "2021", "authors": "Lisa Woller; Viktor Hangya; Alexander Fraser"}, {"ref_id": "b35", "title": "Are All Languages Created Equal in Multilingual BERT?", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Shijie Wu; Mark Dredze"}, {"ref_id": "b36", "title": "Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation", "journal": "Association for Computational Linguistics", "year": "2015", "authors": "Chao Xing; Dong Wang; Chao Liu; Yiye Lin"}, {"ref_id": "b37", "title": "Interactive Refinement of Cross-Lingual Word Embeddings", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Michelle Yuan; Mozhi Zhang; Benjamin Van Durme; Leah Findlater; Jordan Boyd-Graber"}, {"ref_id": "b38", "title": "Combining Static Word Embeddings and Contextual Representations for Bilingual Lexicon Induction", "journal": "", "year": "2021", "authors": "Jinpeng Zhang; Baijun Ji; Nini Xiao; Xiangyu Duan; Min Zhang; Yangbin Shi; Weihua Luo"}, {"ref_id": "b39", "title": "Cross Language Dependency Parsing using a Bilingual Lexicon", "journal": "Association for Computational Linguistics", "year": "2009", "authors": "Hai Zhao; Yan Song; Chunyu Kit; Guodong Zhou"}, {"ref_id": "b40", "title": "Building Large Monolingual Dictionaries at the Leipzig Corpora Collection: From 100 to 200 Languages. European Language Resources Association (ELRA)", "journal": "", "year": "2012", "authors": "Dirk Language Resource References Goldhahn; Thomas Eckart; Uwe Quasthoff"}, {"ref_id": "b41", "title": "inlpsuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for Indian languages", "journal": "", "year": "2020", "authors": "Divyanshu Kakwani; Anoop Kunchukuttan;  Golla;  Satish;  Gokul; Avik Bhattacharyya; Mitesh Khapra; Pratyush Kumar"}, {"ref_id": "b42", "title": "A Large Scale Nepali Text Corpus", "journal": "", "year": "2020", "authors": "Rabindra Lamsal"}, {"ref_id": "b43", "title": "Linguistic Resources for", "journal": "", "year": "2021", "authors": "Rajesh Mundotiya;  Kumar; Manish Singh;  Kumar; Rahul Kapur;  Mishra;  Swasti; Anil Singh; ; Kumar; Magahi Bhojpuri; Maithili "}, {"ref_id": "b44", "title": "English-Bhojpuri SMT System: Insights from the Karaka Model", "journal": "", "year": "2019", "authors": "Atul Ojha;  Kr"}, {"ref_id": "b45", "title": "Findings of the LoResMT 2020 Shared Task on Zero-Shot for Low-Resource languages. Association for Computational Linguistics", "journal": "", "year": "2020", "authors": "Atul Ojha;  Kr; Valentin Malykh; Alina Karakanta;  Liu;  Chao-Hong"}, {"ref_id": "b46", "title": "Proceedings of the Fifth Workshop on NLP for Similar Languages, Varieties and Dialects", "journal": "Association for Computational Linguistics", "year": "2018", "authors": "Marcos Zampieri; Preslav Nakov; Nikola Ljube\u0161i\u0107; J\u00f6rg Tiedemann;  Malmasi;  Shervin; Ahmed Ali"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "large monolingual corpora for 177 good quality contextual embeddings. How-178 ever, for low-resource languages, contextual 179 embeddings from both monolingual and multi-180 lingual models are known to be unreliable (?). Later works show the failings of the above approaches in low-resource settings (????) and propose alternative training strategies such as joint training of static embeddings (??), and multilingual embeddings from LSTM-based models (?). However, these works either address a higher resource range (>15M tokens), use bilingual lexicons as seeds, or show low scores (\u2248 30 precision@5) for unsupervised", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Examples of cognates. Since the Devanagari script is phonetically transparent, phonetic similarity is visible both in IPA and in Devanagari (not shown).", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Examples of cognates. Since the Devanagari script is phonetically transparent, phonetic similarity is visible both in IPA and in Devanagari (not shown).", "figure_data": "Input and Output Examples for Bhojpuri1 Input Mask Correct Preds\u0909 \u093e\u0938 joy 'May your pilgrimage be filled with joy and spirituality.' \u0914\u0930 and \u0905 \u093e\u093f \u0915\u093e \u0938\u0947 spirituality-with [MASK] [MASK] \u0906\u092a\u0915\u0947 your \u0924\u0940\u0925\u0930\u094d \u092f\u093e\u0924\u094d\u0930\u093e pilgrimage \u0906\u0928\u0902 \u0926\u092e\u092f enjoyable \u092d\u0930\u0932 'filled' \u092d\u0930\u0940 \u092a\u093f\u0930\u092a\u0942 \u0923\u0930\u094d , replete, \u092d\u0930\u0940, filled, \u092f\u0941 , containing, \u092d\u0930\u092a\u0942 \u0930, filled-up, \u0938 prosperous\u0939\u094b\u0964 may-be2 Input Mask Correct Preds\u092a\u094d\u0930\u0927\u093e\u0928\u092e\u0902 \u0924\u094d\u0930\u0940 Prime Minister 'The Prime Minister praised the discussion and inputs made in the conference.' \u0938 \u0947 \u0932\u0928 conference \u092e\u0947\u0902 in \u092d\u0908\u0932 occurred \u093f\u0935\u091a\u093e\u0930-\u093f\u0935\u092e\u0936\u0930\u094d discussion \u0905\u0909\u0930 and \u0907\u0928\u092a\u0941 \u091f input \u092c\u0924\u0935\u0932\u093e \u0915\u0947 telling-of \u0924\u093e\u0930\u0940\u092b praise [MASK] [MASK] \u0915\u0907\u0932\u0928 'did' \u0915\u0940, \u0915\u0930\u0940 \u0915\u0930\u0947 , do-hypothetical, \u0915\u0930\u0940, did-fem, \u0915\u0940, did-fem, \u093f\u0915\u092f\u093e, did-masc, *\u0915\u0930\u0947 \u0932 -\u0964 .3 Input Mask Correct Preds New input \u0939\u092e\u0928\u0940 \u0915\u0947 \u0909\u0928 [MASK] \u092a\u0930 \u092c\u0939\u0941\u0924\u0947 \u0917\u0935\u0930\u094d \u092c\u093e \u0964 \u0939\u092e\u0928\u0940 \u0915\u0947 I/We \u0909 those [MASK] [MASK] \u092a\u0930 on \u092c\u0939\u0941\u0924\u0947 lots of \u0917\u0935\u0930\u094d pride 'I/We was/were very proud of those people.' \u092c\u093e was \u0964 . \u0932\u094b\u0917\u0928 'people' \u0932\u094b\u0917, \u0932\u094b\u0917\u094b\u0902 \u092c\u093e\u0924, thing, \u0915\u093e\u092e, work, \u0932\u095c\u0915\u0940, \u093f\u0926\u0928, day, \u0914\u0930\u0924 woman girl, Preds \u0938\u092c, all of (them), \u0932\u094b\u0917, people, \u0932\u094b\u0917\u094b\u0902, people, \u093f\u0926\u0928, day, \u0938\u092d\u0940 all of (them)"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Examples for our method. Input: Target language text with an unknown masked word, with an English gloss. top predictions made by the mask-filling model. We choose 5 representative examples here, although in our implementation we actually consider the top 30. The underlined prediction is the one that has the lowest normalized edit distance with the original target language word, and would therefore be chosen in the Basic approach as the top candidate. Green highlighted predictions are correct equivalents, even if not included in silver lexicon. Orange highlighted examples fit the mask but are not equivalents of the masked target word.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Types and examples of faults in the silver lexicon.", "figure_data": "Target #Tokens Lexicon Silver lexiconlang.sizesizeawa0.17M10462-bho3.09M219832469bra0.33M10760-mag3.16M307843359mai0.16M12069-mar*551.00M36929-nep*110.00M22037-"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "", "figure_data": ": Monolingual data sizes in tokens, andsizes of our released lexicons (created using ourmethod), and released silver lexicons (from paralleldata) for Bhojpuri and Magahi. *High-quality goldbilingual lexicons already exist for these languages."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "respectively. See Table4for monolingual data sizes.", "figure_data": "Model We use the MuRIL model and tokenizer(Khanuja et al., 2021) as our HRL MLM for Bho-jpuri, Magahi, Awadhi, Maithili and Braj; we usethe Hindi BERT and associated tokenizer given byJoshi (2023) for Marathi and Nepali. 8"}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "", "figure_data": "bhomagmarnepMethodP@2NIA P@2NIA P@2NIA P@2 NIABaselines ID VecMap+CSLS CSCBLI37.3 0.0 0.00.0 0.0 0.039.9 1.2 2.00.0 0.6 0.527.5 42.4 26.7 0.0 0.0 0.021.2 0.0 0.00 0.0 0.0OursBasic Rulebook61.0 18.1 61.5 15.1 65.4 65.2 18.8 80.9 17.4 80.62.8 87.6 1.72 87.68.2 6.0: Performance of the methods, given by Precision@2 (P@2) and accuracy of non-identicalpredictions (NIA)."}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "Performance of the methods as measured by Precision@2 (P@2) and the accuracy of non-identical predictions (NIA).", "figure_data": "# Lang WordCorrect BasicRulebookVecMapCSCBLI1 2 3 4 5 6 7 8 9bho mag mar\u0926\u0947 \u0916\u0924 (sees) \u093f\u092e\u0932\u0924 (meets) \u0907\u0939\u093e \u0901 (here) \u0921\u093e\u0932\u093d (puts) \u0938\u092c\u093e\u0932 (question) \u091a\u094b\u0930\u093e (steal) \u0925\u0902 \u0921\u0940 (cold) \u093f\u0915\u092e\u093e\u0928 (at least) \u0905\u0928\u093e\u0926\u0930 (disrespect) \u0905\u092a\u092e\u093e\u0928 \u0926\u0947 \u0916\u0924\u093e \u093f\u092e\u0932\u0924\u0947 \u092f\u0939\u093e \u0901 \u0921\u093e\u0932\u0924\u0940 \u0938\u0935\u093e\u0932 \u091a\u0941 \u0930\u093e \u0920\u0902 \u0921 \u0942 \u0928\u0924\u092e\u0926\u0947 \u0916 \u2020 \u093f\u092e\u0932\u0924\u0947 \u0907\u093f\u0924\u0939\u093e\u0938 (history) \u092f\u0939\u093e \u0901 \u0926\u0947 \u0916 \u2020 \u093f\u092e\u0932 \u2020 \u0921\u093e\u0932\u0947  \u2020 \u0921\u093e\u0932 \u2020 \u092c\u094b\u0932 (speak) \u0938\u0935\u093e\u0932 \u091a\u094b\u0930\u0940 \u2020(theft) \u091a\u094b\u0930 \u2020(thief) \u093f\u0926\u0939\u093e\u095c\u0947 (day) \u0905\u091f\u092a\u091f\u0947 (weird) \u092e\u0902 \u0924\u094d\u0930\u092e\u0941 (spellbound) \u0917\u093e (sing) \u0917\u093e (sing) \u0932\u0939\u0930\u0940 (wavy) \u0928\u091c\u093e\u0930\u093e (view) \u0924\u0941 \u0928\u0947 * \u092c\u0939\u0941\u0924\u094b\u0902 (many) \u093f\u0935\u0927\u093e\u093f\u092f\u0915\u093e* \u093f\u0935\u0927\u093e\u093f\u092f\u0915\u093e* \u093f\u0926\u0939\u093e\u095c\u0940 (day) \u0925\u0902 \u0921\u0940 \u0925\u0902 \u0921\u0940 \u0920\u0902 \u0921 \u094b\u093f\u0924 (light) \u093f\u0915\u092e\u093e\u0928 \u093f\u0915\u092e\u093e\u0928 \u0942 \u0928\u0924\u092e swift \u0905\u0928\u093e\u0926\u0930 \u0905\u0928\u093e\u0926\u0930 \u0905\u092a\u092e\u093e\u0928 \u091a\u093e\u092e\u0941 \u0902 \u0921\u0947 \u0930\u0940 (place name)"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Predictions made by different approaches. Meanings are provided for the first occurrence of the word. * indicates a non-word, \u2020indicates a prediction in the wrong inflectional/derivational form of the target.", "figure_data": "335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 351 352 353 354 355 356 357 358 359 360Limitations The applicability of our method is restricted to low-resource languages that are related to a high-resource language and show non-trivial lexical overlap with that language. As the Ba-sic and Rulebook method are directly depen-dant on orthographic distance between trans-lation pairs, they are also only useful for identi-fying cognate equivalents or alternate spellings in the source and target language. Further, we make it clear that our method is not intended for mid-to-high resourced language pairs (such as Marathi-Hindi), where canonical state-of-the-art methods such as VecMap indeed work more robustly, specifically on non-identical sion from bilingual lexicons, possibly obtained improve these methods with a little supervi-vised scenario, and leave it to future work to that we also only deal in the entirely unsuper-the-art methods fail in these settings. Note high-resource language, given that state-of-leveraging the resources of a closely related icons for severely under-resourced languages i.e. it is a simple method to build bilingual lex-specific (although important) target scenario, word equivalents. Our method therefore has afrom parallel data. Another limitation of our work is that we were not able to provide true native speaker evalua-tion for the resulting target language lexicons, instead providing evaluation by a Hindi native speaker relying on knowledge of shared cog-nates, the morphology of the target language, and inflection tables. We provide examples in Table 2 and Table 4, and release the automati-cally created as well as silver lexicons. Finally, our method is only capable of providing sin-gle token matches to the (masked) whole word. This is not a big problem, since the HRL MLM tokenizer has a large vocabulary size (52000) and is therefore likely to preserve most HRL words as single tokens; however, we leave it to future work to handle multi-word terms."}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "Predictions made by different approaches. Meanings are provided for the first occurrence of the word. * indicates a non-word and \u2020 a prediction in the wrong inflectional/derivational form of the target.", "figure_data": "(with reranking), performing at only 3.03% NIA forBhojpuri and 4.04% NIA for Magahi (approximately-15 and -14 percentage points compared to Basicfor Bhojpuri and Magahi respectively, as shown inTable"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_13", "figure_caption": "P@{1,3,5} for bho and mag.", "figure_data": "bhomagNIA@1 NIA@3 NIA@5 NIA@1 NIA@3 NIA@5VecMap+CSLS0000.60.60.6Basic23.717.117.127.218.418.2Rulebook20.214.414.523.11716.9"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_14", "figure_caption": "NIA@{1,3,5} for bho and mag.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "S(c i , c j ) = C(c i , c j ) T (c i )(1)", "formula_coordinates": [5.0, 137.72, 393.97, 153.21, 23.89]}, {"formula_id": "formula_1", "formula_text": "\u03b6(s, t) = \u2212 (a,b)\u2208Ops log(S(a, b)),(2)", "formula_coordinates": [5.0, 111.38, 600.4, 179.55, 21.44]}, {"formula_id": "formula_2", "formula_text": "C(a, b) := C(a, b) + 1 \u2200(a, b) \u2208 Ops(s, t) T (a) := T (a) + 1 \u2200(a, b) \u2208 Ops(s, t)", "formula_coordinates": [5.0, 90.72, 65.05, 417.84, 707.48]}], "doi": "10.18653/v1/D16-1250"}