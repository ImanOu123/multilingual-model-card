{"title": "Identifying the limits of transformers when performing model-checking with natural language", "authors": "Tharindu Madusanka; Ian Pratt-Hartmann; Riza Theresa Batista-Navarro", "pub_date": "", "abstract": "Can transformers learn to comprehend logical semantics in natural language? Although many strands of work on natural language inference have focussed on transformer models' ability to perform reasoning on text, the above question has not been answered adequately. This is primarily because the logical problems that have been studied in the context of natural language inference have their computational complexity vary with the logical and grammatical constructs within the sentences. As such, it is difficult to access whether the difference in accuracy is due to logical semantics or the difference in computational complexity. A problem that is much suited to address this issue is that of the model-checking problem, whose computational complexity remains constant (for fragments derived from first-order logic). However, the model-checking problem remains untouched in natural language inference research. Thus, we investigated the problem of model-checking with natural language to adequately answer the question of how the logical semantics of natural language affects transformers' performance 1 . Our results imply that the language fragment has a significant impact on the performance of transformer models. Furthermore, we hypothesise that a transformer model can at least partially understand the logical semantics in natural language but can not completely learn the rules governing the modelchecking algorithm.", "sections": [{"heading": "Introduction", "text": "Recent years have seen a surge of interest in the application of neural networks to the topic of natural language inference (Raffel et al., 2019;Lan et al., 2020;Yang et al., 2019), the central task of which is to recover information entailed by, but not explicitly stated in natural language texts Sinha et al., 2019;Geiger et al., 2018;Wang et al., 2021). This problem is of theoretical (as well as practical) interest because the ability to understand the logical consequences of natural language sentences is an essential part of what it is to understand the grammatical constructions and closed-class expressions they contain. More specifically, the ability of neural network models to recognize logical entailments is constitutive of their ability to understand the texts they are processing.\nIt is important to distinguish two strands of work in this area. The first focuses on entailment as defined by human-constructed datasets (Bowman et al., 2015;Williams et al., 2018), where the inferences depend on implicit background knowledge and have a probabilistic character. The second focuses on the recognition of formal logical entailments, for which data sets can be machinegenerated using existing symbolic reasoning techniques (Richardson et al., 2020;Richardson and Sabharwal, 2021;Geiger et al., 2018). This latter strand of work is particularly pertinent to the theoretical problem of whether neural network models can learn the logical semantics of natural language. Commonsense knowledge, human judgement and considerations of plausibility are consciously excluded.\nA logical problem of great theoretical interest that has not been studied in the context of natural language inference is the model-checking problem: given a formula \u03d5 and a structure A, determine whether \u03d5 is true in A (A |= \u03c8). The ability to perform model-checking is indicative of a grasp of the logical semantics of the expressions concerned. In the context of natural language inference, we are particularly interested in a variant of the modelchecking problem where the structure and the formula are interpreted in natural language. It is noteworthy to emphasise how the model-checking problem differs from other inference problems. In other logical reasoning problems such as satisfiability, computational complexity varies among multiple Figure 1: An instance of the model-checking problem, the domain of the structure is represented in D, and predicates are characterised by P. A formula can be valid or not according to the structure (the formula on the left is valid, while the one on the right is invalid). Corresponding natural language representations for both the structure and the formula are also presented. computational complexity classes (NLOGSPACE to NEXPTIME for fragments considered in this study) in language fragments of the finite variable space (Pratt-Hartmann and Third, 2006;Pratt-Hartmann, 2010). In contrast, in the model checking problem, the computational complexity remains in PTIME for any fragment in the finite variable space (given they are derived from first-order logic). Furthermore, inference in the model-checking problem is fairly straightforward, which has also been evident by low computational complexity. Hence, the model-checking problem provides an ideal problem to analyse how different logically significant words and grammatical constructs (semantics of logic in natural language) affect transformers' ability to reason, as the underlying computational complexity remains in PTIME.\nFigure 1 depicts an instance of the modelchecking problem, where the sentence \"Some actors love every scholar\" is True according to the structure presented, as the assignment of \"Hailee\" to the variable x makes the corresponding formula (\u2203x(actor(x) \u2227 \u2200y(scholar(y) \u21d2 love(x, y)))) T rue. However, when assessing the sentence \"All actors who are happy are scholars\", there is no assignment that makes the formula (\u2200x((actor(x) \u2227 happy(x)) \u21d2 scholar(x))) T rue according to the structure (the set of actors who are musicians is {Hailee}, which is not a subset of scholars', namely {Alan, Tony}).\nIn our analysis of transformers' capabilities in the model-checking problem, we ask two fundamental questions, (1) can transformers perform model-checking with natural language? (2) if so, can transformers understand the logical seman-tics of natural language: i.e. can transformers comprehend the semantics of distinctively logical words and grammatical concepts such as determiners, relative clauses and anaphora? To answer the above-mentioned questions, we construct a modelchecking dataset (FO 2 -MC dataset) utilising language fragments. Unlike the work by Richardson and Sabharwal (2021) and Geiger et al. (2018), whose work was limited to only one language fragment, we explore a varied set of fragments. The consideration of linguistic complexity of language fragments led us to ask an additional question: How does the linguistic complexity of the fragment affect the performance of the transformer model when performing model-checking with natural language?\nThe contributions of this paper are as follows: (1) To the best of our knowledge, we are the first to broaden natural language reasoning over formal theories to include model-checking with natural language; (2) We develop a novel algorithm for constructing a dataset for model-checking with natural language; (3) We investigate whether transformers can learn to understand the logical semantics of natural language; (4) In a first-of-its-kind study in rule reasoning, we include complex fragments such as anaphora and relative clauses with transitive verbs; and (5) We provide a systematic analysis of how the linguistic complexity of language fragments affects rule reasoning. son and Sabharwal, 2021;Richardson et al., 2020;Sinha et al., 2019;Geiger et al., 2018;McCoy et al., 2019;Betz et al., 2021). Moreover, it is also related to other research approaches that have been conducted on data synthesis for rule reasoning problems Weston et al., 2016;. However, our study is distinct from the above-mentioned work in two ways. Firstly, we focus on an unexplored problem space, modelchecking with natural language. Secondly, unlike the above literature, we explore multiple language fragments and provide a deconstruction of how the linguistic complexity of language fragments affects the performance of transformer models in a rule reasoning task.\nOur work can also be viewed as broadening the research conducted on training neural networks to perform algorithmic tasks, including learning to solve SAT problems (Selsam et al., 2019;Narodytska et al., 2020), propositional inference (Evans et al., 2018), semantic parsing (He and Choi, 2020;Kamath and Das, 2019), symbolic integration (Lample and Charton, 2020) and natural theorem proving (Weber et al., 2019;Minervini et al., 2020;Saha et al., 2020;Gontier et al., 2020). In our study, we aim to investigate the transformers' ability to emulate the algorithm governing the modelchecking problem and comprehend the logical semantics of natural language.\nWhen defining language fragments, we follow the definition set out by Pratt-Hartmann (Pratt-Hartmann, 2003, 2004Pratt-Hartmann and Third, 2006;Pratt-Hartmann and Moss, 2009), who described it more precisely as a subset of a language equipped with semantics that translates sentences into a formal system such as first-order logic. Moreover we employ their work on fragments of firstorder logic as the foundation when constructing the dataset. Notably, Pratt-Hartmann (2004) has investigated the complexity of fragments' first-order logic, and we limit our analysis in this paper to fragments that have been examined in that study. Moreover, we also closely follow the cognitive science literature on model-checking and quantifier verification (McMillan et al., 2005;Szymanik et al., 2013;Szymanik and Zajenkowski, 2010) when defining our experimental evaluation. It provides us with a baseline to compare results from transformer models with the empirical studies that have been conducted with humans.", "publication_ref": ["b23", "b11", "b39", "b28", "b5", "b33", "b1", "b37", "b24", "b25", "b5", "b22", "b20", "b25", "b5", "b24", "b28", "b5", "b14", "b0", "b36", "b27", "b17", "b4", "b7", "b8", "b10", "b34", "b16", "b26", "b18", "b19", "b22", "b21", "b19", "b15", "b29", "b30"], "figure_ref": [], "table_ref": []}, {"heading": "Data Construction", "text": "To decide whether transformer models can learn to understand logical semantics of natural language from formulae (sentences) and structures represented in natural language, we developed an algorithm (shown in Algorithm 1) to construct a balanced dataset designed to be free from trivial linguistic patterns that are easily exploitable. This section will outline the data construction methodology in detail.\nWe sample a set of words (Proper nouns PrN, nouns N, verbs Vb, adjectives Adj) from a predefined vocabulary (V \u2032 ) to form a list of words V. The proper nouns in V are used to define the domain D of the structure, while the nouns, verbs and adjectives are used for defining the set of predicates P.\nWhen generating sentences, we follow a template-based approach. A language template is a sentence of natural language with open-clause words replaced by schematic variables; for example, Some N 1 V is every N 2 . Through substitution of vocabulary items of the appropriate category, we can generate natural language sentences, i.e., Some artists admire every doctor. A simple way of defining a fragment of natural language (language fragment) is via a finite set of template sentences. For example, the classical syllogistic fragment can be defined as the sentences confirming the sentence schemata, All N 1 are N 2 , Some N 1 is N 2 , No N 1 are N 2 and Some N 1 are not N 2 . The formula template is a formula of first-order logic with non-logical symbols replaced by schematic variables; for example, \u2203x(N 1 (x) \u2227 \u2200N 2 (B(y) \u21d2 V (x, y))). An instance of that formula is the result of the substitution of non-logical symbols of the appropriate type for the schematic variables, i.e., \u2203x(artist(x) \u2227 \u2200y(doctor(y) \u21d2 admire(x, y))). A language template translates to schematic formulae in a natural way. For example, the classical syllogistic translates to the schematic formulae \u2200x(N 1 (x) \u21d2 \u00b1N 2 (x)) and \u2203x(N 1 (x)\u2227\u00b1N 2 (x)).\nLet \u03a6 L denote the set of first-order formula templates that can be translated to natural language templates L. Given a language fragment L and a vocabulary V, we can obtain a set of formulae \u03a6 L (V), such that \u03a6 L (V) is a fragment of first-order logic over the vocabulary V, i.e., \u03a6 L (V) only contains the vocabulary V. The first-order formula \u03d5 is selected from the \u03a6 L (V), and then the formula \u03d5 is translated to a natural language sentence s \u03d5 using a template L. A summary of the language fragments we used in our evaluation is provided in the next section.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Algorithm 1 Data Construction -Model-Checking with Natural Language", "text": "Input : Language Fragment L and its corresponding set of first order logic formulae templates \u03a6 L along with its equivalent natural language templates T L . Vocabulary V that contains Nouns(N), Adjectives(Adj), Verbs(Vb) and Proper nouns(PrN). Template T to convert structure to natural language. Maximum number of domain elements per datapoint n, and maximum number of predicates m Output : Model-checking dataset D\n1: D \u2190 {} 2: repeat 3: V \u2190 randomly select list of words where V \u2282 V \u2032 such that |{P rN }| \u2264 n and |{N \u222a Adj \u222a V b}| \u2264 m 4:\n\u03d5 \u2190 randomly generate first order formula using the set of first-order logic formulae \u03a6 L (V)\n5:\ns \u03d5 \u2190 converts \u03d5 to a natural language sentence using the template L A \u2190 generate structure randomly using the signature (vocabulary) V 10:\nif (\u2113 = T rue and A |= \u03d5) or (\u2113 = F alse and A \u0338 |= \u03d5) then 11:\ncorrect-structure-found \u2190 T rue 12:\nend if 13:\nuntil correct-structure-found 14:\nM A \u2190 converts A to a natural language using a template T\n15: D \u2190 D \u222a{M A , s \u03d5 , \u2113} 16: until stop condition is met\nThe label \u2113 is selected randomly from the set {T rue, F alse}. Once \u2113 and \u03d5 are defined, the structure A = (D, {P} A ) is generated, where D is the domain and P is the set of predicates and {P} A represents an interpretation of P in A and the signature of the structure is V. Assignment of each domain element to the P in the structure A is done randomly, such that for ev-ery domain element d i in D and predicate P i , prob(d i assign to P i ) = p 1 if P i is a unary predicate, and for every domain element d i , d j in D and predicate P i , prob((d i , d j ) assign to P i ) = p 2 if P i is a binary predicate. In our experimentation, we select p 1 = 0.5 and p 2 = 0.75 2 , so that for each predicate P i , |P A i | is a normal distribution with a mean of approximately |D| 2 , so the loop (in line 8-13) terminates within a reasonable time. We iteratively build structures randomly, and perform model-checking using a model-checker until a structure that meets the criteria defined by the label is found; i.e. if \u2113 = T rue, then the formula is T rue according to the structure, A |= \u03d5 and vice-versa. Once such structure is identified, it is converted into a paragraph in natural language, M A using a template T .\nAnother way to create a data point would be to generate A and \u03d5 and perform the validity check using a model-checker to acquire the label as opposed to pre-defining the label and iteratively constructing A to match the label. However, such an approach can introduce easily exploitable linguistic patterns such as having the label F alse for most sentences containing determiners all, every or no, or having label T rue for sentences containing determiners some or a.\nWhen constructing sentences, we make sure each predicate only appears once within a sentence. So sentences like every artist is an artist would not be generated. Furthermore, we also remove cases where no elements are assigned to a predicate P i and perform re-balancing, since they also introduced easily exploitable patterns. For example, the sentence \"every musician who is a actor is happy\" is trivially T rue if there are no musicians or actors.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Language fragments", "text": "A language fragment is defined as a language that is equipped with semantics that translates its sentences to a formal system, such as first-order logic. We defined our language fragments based on the work of Pratt-Hartmann (2004). Table 1 shows the language fragments used, along with an example for each fragment and the corresponding first-order formula. As indicated in the data construction algorithm, we employ a template-based approach when implementing both language fragments and their formal method representations. We limit our evaluations to fragments of first-order logic and bound", "publication_ref": ["b19"], "figure_ref": [], "table_ref": []}, {"heading": "Language Fragment Example", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Syllogistic", "text": "Every musician is a artist \u2200x(musician(x) \u21d2 artist(x)) Relational syllogistic (Re-Syl)\nAll teachers remember some engineer \u2200x(artist(x) \u21d2 \u2203y(engineer(y) \u2227 remember(x, y))) Relative clauses without transitive verbs (Rel)\nAll economists who are not happy are cynics \u2200x((economist(x) \u2227 \u00achappy(x) \u21d2 cynic(x)) Relative clauses with transitive verbs (Rel-TV)\nNo cynic like any scholar who is a expert \u2200x(cynic(x) \u21d2 \u2200y((scholar(y) \u2227 cynic(y)) \u21d2 \u00aclike(x, y))) Anaphora Some judge warns no juror who hate him \u2203x(judge(x) \u2227 \u2200y((juror(y) \u2227 hate(y, x)) \u21d2 \u00acwarn(x, y)))\nTable 1: Language fragments we utilised along with an example for each of them and its corresponding first-order logic formula.\nthe number of functions within a formula to have a maximum of four. We also limit the maximum number of quantifiers per formula to two, producing only unary or binary formulae. The rationale is to have natural sounding sentences. As outlined in the description of the template structure provided in Appendix A: Templates of Language Fragments, to address the ambiguity that can arise with anaphora or relative clauses, we bind the anaphora or relative clauses to the same element. For example, anaphora always refer to the first noun in the sentence. Even though we limit our data construction and evaluation to only these fragments, we emphasise that the data construction methodology and experimental evaluation we have conducted can be executed with any arbitrary fragment of natural language.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Boolean Coordinators", "text": "One interesting experiment is to evaluate how transformer models perform when Boolean coordinators are introduced to the sentences. To that end, we used Boolean coordinators ( (and), (or)) to combine sentences and create more difficult problem instances. The resultant first-order formula \u03a8 of such sentences can be formed by combining individual first-order formulae using either or . Model-checking is then performed on \u03a8 (is A |= \u03a8 or A \u0338 |= \u03a8?), and the condition in Algorithm 1 (line 11) is modified accordingly.\nThe natural language sentences are combined accordingly using the coordinating conjunctions and or or. We did not consider the case where and as well as or are present in the final sentence, since the order of operations cannot be enforced in natural language settings and hence would be am-biguous. We evaluated transformer models varying the number of coordinators k, where k = {0, 1, 2}, to investigate how incorporating Boolean coordinators affect the accuracy.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Setup", "text": "In this section, we describe the experiments we conducted in order to address our research questions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Problem definition", "text": "Formally the FO 2 -MC dataset can be defined as\n{(p (d) , \u2113 (d) )} |D| d\nwhere p (d) is an instance of the model-checking problem (concatenation of the structure M A and sentence s \u03d5 delimited by a separator SEP token), and \u2113 \u2208 {T rue, F alse} is the label. The task is to correctly predict the label \u2113, thereby reducing it to a binary classification problem.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Transformer models", "text": "To investigate the capabilities of transformers in model-checking with natural language, we performed experiments on the FO 2 -MC dataset using three prominent transformer architectures: BERT, RoBERTa and T5.\nBERT. Bidirectional Encoder Representations from Transformers or BERT (Devlin et al., 2018) use bi-directional conditioning in all of its network's layers to consider both the left and right context. BERT has become the standard transformer architecture and has been evaluated against many NLI datasets (Richardson et al., 2020;McCoy et al., 2019), hence we believe it provides a baseline for assessing the complexity of the task and difficulty of the FO 2 -MC dataset. We used the BERT-base (uncased) model with around 110M parameters.\nRoBERTa. Robustly Optimized BERT Pretraining Approach or RoBERTa  is based on the BERT architecture but trained in a more optimised manner. It has been used for rule reasoning tasks such as RuleTaker , and is considered as another baseline model in our experiments. We made use of the RoBERTa-base model which has around 125M parameters.\nT5. Following the work done by  and Richardson and Sabharwal (2021) on rule reasoning, we primarily centre our experiments around Text-to-Text Transfer Transformer or T5 models (Raffel et al., 2019). T5 frames all NLP tasks (e.g., classification, translation, semantic textual similarity) into a unified text-to-text format where both input and output are always strings; this is slightly different from BERT and RoBERTa which, when fine-tuned on classification tasks, output a class label. In our experiments, we employed two T5 models: T5-base with approximately 220M parameters and T5-large with approximately 700M parameters.\nIn experimenting with each of the three types of models above, we utilised the Huggingface library (Wolf et al., 2019). The transformer models are fine-tuned to predict the target label (T rue or F alse) by optimising for the binary cross-entropy loss over the targets using the Adam optimiser (Kingma and Ba, 2015). Since the dataset is balanced (i.e., both training and test data have approximately an equal number of samples labelled as T rue and F alse), we made use of accuracy as our evaluation metric.", "publication_ref": ["b3", "b24", "b14", "b25", "b23", "b38", "b9"], "figure_ref": [], "table_ref": []}, {"heading": "Proposed Dataset and Evaluation", "text": "To answer the question of whether transformers can perform model-checking with natural language, we trained transformer models, namely, T5, BERT and RoBERTa, using the FO 2 -MC dataset in the manner mentioned above. During data construction, we incorporated the same vocabulary as Richardson and Sabharwal (2021), with the addition of transitive verbs where the number of verbs is equivalent to the number of adjectives. The vocabulary contains approximately 2000 names (proper nouns), 156 nouns, 64 adjectives and 65 verbs. The names are used as the domain elements while nouns, adjectives and verbs form predicates, whereas verbs constitute binary predicates while the nouns and adjectives form unary predicates. Furthermore, when generating the model, we limited the number of domain elements to be less than 4 (|D| \u2264 4) and the number of predicates to be less than 8 (|P| \u2264 8). We trained transformer models using training instances that include sentences that belong to language fragments we introduced in Section 3.1, i.e., syllogistic, relational syllogistic (Re-Syl), relative clauses (Rel), relative clauses with transitive verbs (Rel-TV) and anaphora. In each case (for each language fragment), models were trained with 500K unique data points and evaluated against a heldout 100K test set (see Table 2). Moreover, we experimented with training the models (T5-base and T5-large) using a dataset that contains sentences belonging to all the fragments, so that we could investigate how simpler fragments help transformers understand the logical semantics of natural language of complex ones (see Table 3). The training set in this experiment comprises 500K unique data points with approximately 100K data points belonging to each language fragment. The results of this experiment, along with the results depicted in Table 2, also provide the answer to the question of how the linguistic complexity of the language fragment affects the performance of transformers in model-checking with natural language. To better understand model generalisation and scale invariance, we evaluated the transformer model (T5-large) on a held-out evaluation set whose structure contains more domain elements (see Table 4) or more predicates (see Table 5) than that of the training set. To comprehend how Boolean coordinators affect the accuracy of transformer models across different language fragments, we also trained and evaluated with data points whose sentences have Boolean coordinators in them.", "publication_ref": ["b25"], "figure_ref": [], "table_ref": ["tab_2", "tab_3", "tab_2", "tab_4"]}, {"heading": "Results and discussion", "text": "Transformer models can solve model-checking with natural language problems with satisfactory accuracy, given adequate training instances, as depicted in Table 2. For all language fragments, transformers manage to yield an accuracy of over 70%. It is also evident from Table 2 that there is no significant difference in performance between the considered transformer models.\nThe linguistic complexity of the language fragments that generate the sentence has a significant impact on the overall performance, as il-    lustrated in Tables 2 and 3. Transformers achieve near-perfect performance for fragments such as syllogistic and Rel. However, they only achieve a moderate level of accuracy for fragments such as Re-Syl, Rel-TV, and anaphora. The later-mentioned fragments have transitive verbs, which results in the respective structures containing binary relationships. It is harder to learn binary relationships as opposed to unary ones. Furthermore, the sentences in the fragments Re-Syl, Rel-TV, and anaphora can have two quantifiers, while the sentences in fragments syllogistic and Rel are restricted to only one. As depicted in Table 6, the number of quantifiers in the sentence influences the performance of the transformer models in solving model-checking problems. Sentences with two quantifiers are more difficult to decode than sentences with only one quantifier, as evidenced by cognitive studies on quantifier verification (Szymanik and Zajenkowski, 2010;Szymanik et al., 2013), which is also unsurprising. There is a difference between the accuracy of single quantifier sentences and the average accuracy of the syllogistic fragment and Rel fragment. This difference is due to single quantifier sentences belonging to other fragments, whose sentences include transitive verbs. According to the results in Table 6, only the number of quantifiers seems to affect the performance of the transformers, and not the exact quantifier used. Cognitive studies (Szymanik et al., 2013) suggest quantifiers themselves affect human performance on modelchecking problems, which is not evident here, implying human reasoning on language is somewhat different to what is occurring in transformer models.\nAnother linguistic property that seems to affect the performance of transformers is Boolean coordinators. The accuracy of transformer models decreases when Boolean coordinators are introduced to the sentences, as illustrated in Table 7. The difference in performance when the number of coordinators changes from 0 to 1 is higher than that of when it is increased from 1 to 2. However, the number of Boolean coordinators has a lower effect on accuracy compared to other linguistic properties such as the number of quantifiers.\nLearning the simple fragments enables transformers to learn complex ones, as depicted in Table 3. When training data contains sentences from all the language fragments, the performance of complex fragments such as anaphora is higher than if it only includes sentences of that respective fragment. Transformer models can learn to understand logically significant words such as determiners and grammatical constructs such as relative clauses more easily from simpler fragments than complex ones. So when learning the logical semantics of complex fragments, transformers can employ this knowledge. Hence, we can hy-  pothesise that transformers at least partially learn to understand the essence of logical semantics of natural language. Table 3 also indicates a substantial difference in performance between the T5-base model and the T5-large model. The T5-large model achieves an overall accuracy of 88.2% but only manages to achieve an accuracy of around 80% (Re-Syl:81.8%, Rel-TV: 82.3%, anaphora: 77.7%) for language fragments with transitive verbs. This accuracy level is lower than the accuracy that transformer models yielded in other rule reasoning benchmarks such as RuleTaker  and NLSat (Richardson and Sabharwal, 2021), which suggests that the FO 2 -MC dataset is a formidable linguistic reasoning benchmark.\nTransformer models exhibit limited generalisation and scale-invariance, as illustrated in Tables 4 and 5. Even if the number of predicates increases, the accuracy of the transformer model re-number of Boolean coordinators Accuracy k = 0 75.9 k = 1 70.7 k = 2 67.6 mains relatively unchanged (see Table 5). However, if the number of domain elements increases, the model performance drastically decreases (see Table 4). The reason could be that the attention mechanism in the transformer correctly identifies which areas in the structure to examine for a given sentence, but the transformer model still cannot emulate the model-checking algorithm properly. Moreover, the degradation in performance is relatively equivalent for all language fragments, suggesting that decrement is not correlated to the grammatical structure of the sentence. Hence, we can conjecture that transformers can learn to understand the logical semantics of natural language but still cannot learn to emulate the underlying model-checking algorithm.", "publication_ref": ["b30", "b29", "b29", "b25"], "figure_ref": [], "table_ref": ["tab_2", "tab_2", "tab_2", "tab_6", "tab_6", "tab_7", "tab_3", "tab_3", "tab_4"]}, {"heading": "Conclusion", "text": "We investigate the limits of transformers in an unexplored problem space of model-checking with natural language employing language fragments. We use five different language fragments and explore how linguistic complexity and other linguistic properties such as Boolean coordinators affect rule reasoning in transformer models. In a broader sense, our study is to determine whether transformer models can learn to understand the logical semantics of natural language and emulate the model-checking algorithm. We posit that transformers can learn logically significant words and grammatical constructs but fall short when learning the underlying algorithm. Moreover, different linguistic properties such as the language fragment, Boolean coordinators and the number of quantifiers have a notable impact on the learning ability of the transformers. Thus, an interesting future direction would be to investigate how these linguistic properties affect more complex reasoning tasks like natural language satisfiability.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Limitations", "text": "The results in our work closely follow the trends reported by prior work in the domain of identifying the limits of transformers in logical reasoning. Specifically, the transformers exhibit limited generalization beyond the underlying distribution in training data. However, due to the empirical nature of the study, it is not guaranteed that all other transformer-based models or other neural networks would exhibit the same pattern.\nMoreover, the study focuses on several language fragments with varying linguistic complexity such that one would be able to quantify the influence of linguistic properties on a logical reasoning problem. However, the fragments considered in this study are not the only language fragments in existence and, as such, would limit the comprehensiveness of the discussion, and there could be other fragments of language which behave differently when evaluated against transformer models.   ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Templates of Language Fragments", "text": "Tables 8, 9, 10, 11 and 12 contain templates for the syllogistic fragment, relational syllogistic fragment, relative clauses fragment (without transitive verbs), relative clauses (with transitive verbs), and anaphora respectively. Each table contains natural language templates that are employed to construct sentences and their corresponding first-order formulae. As mentioned in the methodology section, we build upon the vocabulary from Richardson and Sabharwal (2021). The set of determiners includes all, every, some, a and no, where every sentence type is converted to the most natural-sounding sentences; i.e. sentences such as every artist does not like every beekeeper would be translated into no artists like any beekeeper. Each sentence that is rendered using templates of the syllogistic fragment and relative clause (without transitive verbs) fragment would include exactly one quantifier, which would determine the determiner of the sentence. The templates of the relational syllogistic, relative clause (with transitive verbs) and anaphora could comprise either two quantifiers or one (if the sentence contains proper nouns, then it would have only one quantifier).", "publication_ref": ["b25"], "figure_ref": [], "table_ref": ["tab_9"]}, {"heading": "Sub-fragment", "text": "Natural Language Template First order logic formula with a quantifier D (non-)N 1 who is/are (not) (a) N 2 /A 1 is/are (not) (a) N 3 /A 2 \u2200x.(\u00b1N 1 (x) \u2227 \u00b1N 2 /A 1 (x) \u21d2 \u00b1N 3 /A 2 (x)) or \u2203x.(\u00b1N 1 (x) \u2227 \u00b1N 2 /A 1 (x) \u2227 \u00b1N 3 /A 2 (x))   \u2227 \u00b1 V 1 (x, y))) or \u2203x(\u00b1N 1 (x) \u2227 \u2200y(\u00b1N 2 (y) \u2227 \u00b1V 2 (y, x) \u21d2 \u00b1V 1 (x, y))) or \u2203x(\u00b1N 1 (x) \u2227 \u2203y(\u00b1N 2 (y) \u2227 \u00b1V 2 (y, x) \u2227 \u00b1 V 1 (x, y)))\nWith Proper nouns P (does not/do not) V 1 D (non-)N who (does not/do not)\nV 2 him/her \u2200x(\u00b1N (x) \u2227 \u00b1V 2 (x, P ) \u21d2 \u00b1V 1 (P, x)) or \u2203x(\u00b1N (x) \u2227 \u00b1V 2 (x, P ) \u2227 \u00b1V 1 (P, x) ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Thinking aloud: Dynamic context generation improves zero-shot reasoning performance of gpt-2", "journal": "", "year": "2021", "authors": "Gregor Betz; Kyle Richardson; Christian Voigt"}, {"ref_id": "b1", "title": "A large annotated corpus for learning natural language inference", "journal": "", "year": "2015", "authors": "R Samuel; Gabor Bowman; Christopher Angeli; Christopher D Potts;  Manning"}, {"ref_id": "b2", "title": "Transformers as soft reasoners over language", "journal": "", "year": "2021", "authors": "Peter Clark; Oyvind Tafjord; Kyle Richardson"}, {"ref_id": "b3", "title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "journal": "", "year": "2018", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"ref_id": "b4", "title": "Can neural networks understand logical entailment", "journal": "", "year": "2018", "authors": "Richard Evans; David Saxton; David Amos; Pushmeet Kohli; Edward Grefenstette"}, {"ref_id": "b5", "title": "Stress-testing neural models of natural language inference with multiply-quantified sentences", "journal": "", "year": "2018", "authors": "Atticus Geiger; Ignacio Cases; Lauri Karttunen; Christopher Potts"}, {"ref_id": "b6", "title": "Siva Reddy, and Chris Pal. 2020. Measuring systematic generalization in neural proof generation with transformers", "journal": "Advances in Neural Information Processing Systems", "year": "", "authors": "Nicolas Gontier; Koustuv Sinha"}, {"ref_id": "b7", "title": "Establishing Strong Baselines for the New Decade: Sequence Tagging, Syntactic and Semantic Parsing with BERT", "journal": "", "year": "2020", "authors": "Han He; Jinho D Choi"}, {"ref_id": "b8", "title": "A survey on semantic parsing", "journal": "", "year": "2019", "authors": "Aishwarya Kamath; Rajarshi Das"}, {"ref_id": "b9", "title": "Adam: A method for stochastic optimization", "journal": "", "year": "2015-05-07", "authors": "P Diederik; Jimmy Kingma;  Ba"}, {"ref_id": "b10", "title": "Deep learning for symbolic mathematics", "journal": "", "year": "2020", "authors": "Guillaume Lample; Fran\u00e7ois Charton"}, {"ref_id": "b11", "title": "Albert: A lite bert for self-supervised learning of language representations", "journal": "", "year": "2020", "authors": "Zhenzhong Lan; Mingda Chen; Sebastian Goodman; Kevin Gimpel; Piyush Sharma; Radu Soricut"}, {"ref_id": "b12", "title": "Reasoning over paragraph effects in situations", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Kevin Lin; Oyvind Tafjord; Peter Clark; Matt Gardner"}, {"ref_id": "b13", "title": "Roberta: A robustly optimized bert pretraining approach", "journal": "", "year": "2019", "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b14", "title": "Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Tom Mccoy; Ellie Pavlick; Tal Linzen"}, {"ref_id": "b15", "title": "Neural basis for generalized quantifier comprehension", "journal": "Neuropsychologia", "year": "2005", "authors": "Corey T Mcmillan; Robin Clark; Peachie Moore; Christian Devita; Murray Grossman"}, {"ref_id": "b16", "title": "Differentiable reasoning on large knowledge bases and natural language", "journal": "AAAI Press", "year": "2020-02-07", "authors": "Pasquale Minervini; Matko Bosnjak; Tim Rockt\u00e4schel; Sebastian Riedel; Edward Grefenstette"}, {"ref_id": "b17", "title": "In search for a sat-friendly binarized neural network architecture", "journal": "", "year": "2020", "authors": "Nina Narodytska; Hongce Zhang; Aarti Gupta; Toby Walsh"}, {"ref_id": "b18", "title": "A two-variable fragment of english", "journal": "Journal of Logic, Language and Information", "year": "2003", "authors": "Ian Pratt-Hartmann"}, {"ref_id": "b19", "title": "Fragments of language", "journal": "Journal of Logic, Language and Information", "year": "2004", "authors": "Ian Pratt-Hartmann"}, {"ref_id": "b20", "title": "Computational complexity in natural language. The handbook of computational linguistics and natural language processing", "journal": "", "year": "2010", "authors": "Ian Pratt-Hartmann"}, {"ref_id": "b21", "title": "Logics for the relational syllogistic", "journal": "", "year": "2009", "authors": "Ian Pratt; - Hartmann; Lawrence S Moss"}, {"ref_id": "b22", "title": "More fragments of language", "journal": "Notre Dame Journal of Formal Logic", "year": "2006", "authors": "Ian Pratt; - Hartmann; Allan Third"}, {"ref_id": "b23", "title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "journal": "", "year": "2019", "authors": "Colin Raffel; Noam Shazeer; Adam Roberts; Katherine Lee; Sharan Narang; Michael Matena; Yanqi Zhou; Wei Li; Peter J Liu"}, {"ref_id": "b24", "title": "Probing natural language inference models through semantic fragments", "journal": "", "year": "2020", "authors": "Kyle Richardson; Hai Hu; Lawrence Moss; Ashish Sabharwal"}, {"ref_id": "b25", "title": "Pushing the limits of rule reasoning in transformers through natural language satisfiability", "journal": "", "year": "2021", "authors": "Kyle Richardson; Ashish Sabharwal"}, {"ref_id": "b26", "title": "PRover: Proof generation for interpretable reasoning over rules", "journal": "Online. Association for Computational Linguistics", "year": "2020", "authors": "Swarnadeep Saha; Sayan Ghosh; Shashank Srivastava; Mohit Bansal"}, {"ref_id": "b27", "title": "Learning a sat solver from single-bit supervision", "journal": "", "year": "2019", "authors": "Daniel Selsam; Matthew Lamm; Benedikt B\u00fcnz; Percy Liang; Leonardo De Moura; David L Dill"}, {"ref_id": "b28", "title": "CLUTRR: A diagnostic benchmark for inductive reasoning from text", "journal": "", "year": "2019", "authors": "Koustuv Sinha; Shagun Sodhani; Jin Dong; Joelle Pineau; William L Hamilton"}, {"ref_id": "b29", "title": "Automata and complexity in multiple-quantifier sentence verification. Logic and Interactive RAtionality Yearbook", "journal": "", "year": "2012", "authors": "Jakub Szymanik; Shane Steinert-Threlkeld; Marcin Zajenkowski; Thomas F Icard Iii"}, {"ref_id": "b30", "title": "Comprehension of simple quantifiers: Empirical evaluation of a computational model", "journal": "Cognitive Science", "year": "2010", "authors": "Jakub Szymanik; Marcin Zajenkowski"}, {"ref_id": "b31", "title": "ProofWriter: Generating implications, proofs, and abductive statements over natural language", "journal": "Online. Association for Computational Linguistics", "year": "2021", "authors": "Oyvind Tafjord; Bhavana Dalvi; Peter Clark"}, {"ref_id": "b32", "title": "Quartz: An open-domain dataset of qualitative relationship questions", "journal": "Association for Computational Linguistics", "year": "2019", "authors": "Oyvind Tafjord; Matt Gardner; Kevin Lin; Peter Clark"}, {"ref_id": "b33", "title": "Entailment as few-shot learner", "journal": "", "year": "2021", "authors": "Sinong Wang; Han Fang; Madian Khabsa; Hanzi Mao; Hao Ma"}, {"ref_id": "b34", "title": "NLProlog: Reasoning with weak unification for question answering in natural language", "journal": "", "year": "2019", "authors": "Leon Weber; Pasquale Minervini; Jannes M\u00fcnchmeyer; Ulf Leser; Tim Rockt\u00e4schel"}, {"ref_id": "b35", "title": "Annual Meeting of the Association for Computational Linguistics", "journal": "Association for Computational Linguistics", "year": "", "authors": ""}, {"ref_id": "b36", "title": "Towards ai-complete question answering: A set of prerequisite toy tasks", "journal": "", "year": "2016-05-02", "authors": "Jason Weston; Antoine Bordes; Sumit Chopra; Tom\u00e1s Mikolov"}, {"ref_id": "b37", "title": "A broad-coverage challenge corpus for sentence understanding through inference", "journal": "Long Papers", "year": "2018", "authors": "Adina Williams; Nikita Nangia; Samuel Bowman"}, {"ref_id": "b38", "title": "Huggingface's transformers: State-ofthe-art natural language processing", "journal": "", "year": "2019", "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; R\u00e9mi Louf; Morgan Funtowicz"}, {"ref_id": "b39", "title": "Xlnet: Generalized autoregressive pretraining for language understanding", "journal": "", "year": "2019", "authors": "Zhilin Yang; Zihang Dai; Yiming Yang; Jaime Carbonell; R Russ; Quoc V Salakhutdinov;  Le"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "\u2200x(\u00b1N 1 (x) \u21d2 \u2200y((\u00b1N 2 (y) \u2227 \u00b1N 3 (y)) \u21d2 \u00b1V (x, y))) or \u2200x(\u00b1N 1 (x) \u21d2 \u2203y(\u00b1N 2 (y) \u2227 \u00b1N 3 (y) \u2227 \u00b1 V (x, y))) or \u2203x(\u00b1N 1 (x) \u2227 \u2200y((\u00b1N 2 (y) \u2227 \u00b1N 3 (y)) \u21d2 \u00b1V (x, y))) or \u2203x(\u00b1N 1 (x) \u2227 \u2203y(\u00b1N 2 (y) \u2227 \u00b1N 3 (y) \u2227 \u00b1 V (x, y)))with Proper nouns D (non-)N 1 who (does not/ do not) V P is/are (not) (a) N 2 \u2200x(\u00b1N 1 (x) \u2227 \u00b1V (x, P ) \u21d2 \u00b1N 2 (x) or \u2203x(\u00b1N 1 (x) \u2227 \u00b1V (x, P ) \u2227 \u00b1N 2 (x))", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Accuracy of transformer models (BERT, T5 and RoBERTa) across different language fragments.", "figure_data": "Model T5-base T5-largeAll 75.9 88.2Syllogistic 80.0 99.8Re-Syl 76.7 81.8Rel 74.8 99.3Rel-TV 74.2 82.3anaphora 73.6 77.7"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "The transformers are trained using a dataset that contains sentences belonging to all language fragments. The results are broken down into respective language fragments, and All indicates the overall (average) accuracy across the language fragments.", "figure_data": "Language Fragment Syllogistic 99.8 |D||D|+1 |D|+2 |D|+4 92.2 87.5 76.1Re-Syl81.867.663.255.6Rel99.390.484.273.3Rel-TV82.367.362.156.4anaphora77.765.061.149.9"}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "The accuracy of the T5-large model evalu-", "figure_data": "ated on out-of-scope data; the training instances have a maximum of 4 domain elements |D| \u2264 4 while the eval-uation set contains 5 (|D| + 1), 6 (|D| + 2), 8 (|D| + 4) domain elements, the number of predicates remains the same between train and evaluation sets."}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "The change in accuracy of the T5-large", "figure_data": "model across different quantifiers. The syllogistic and Rel fragments contain only one quantifier, while Re-Syl, Rel-TV, and anaphora fragments can have two quanti-fiers."}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "The accuracy of the T5-base model when trained and evaluated against problem instances that have Boolean coordinators. k denotes the number of Boolean coordinators in a sentence. Each sentence contains only one type of coordinator (either and or or), if any.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "\u00b1N 1 (x) \u21d2 \u00b1N 2 (x)) or \u2203x(\u00b1N 1 (x) \u2227 \u00b1N 2 (x))", "figure_data": "Sub-fragmentNatural Language TemplateFirst order logic formulawith a quantifierD (non-)N 1 is/are (not) (a) N 2\u2200x("}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "Templates for the syllogistic fragment, D denotes the determiner while N 1 and N 2 symbolise nouns.", "figure_data": "Sub-fragmentNatural Language TemplateFirst order logic formula\u2200x(\u00b1N 1 (x) \u21d2 \u2200y(\u00b1N 2 (x) \u21d2 \u00b1V (x, y))) ordual quantifiersD 1 (non-)N 1 (does not/do not) V D 2 (non-)N 2\u2200x(\u00b1N 1 (x) \u21d2 \u2203y(\u00b1N 2 (y) \u2227 \u00b1V (x, y))) or \u2203x(\u00b1N 1 (x) \u2227 \u2200y(\u00b1N 2 (x) \u21d2 \u00b1V (x, y))) orWith Proper nouns quantifier in the subjectD N (does not/do not) V P\u2203x(\u00b1N 1 (x) \u2227 \u2203y(\u00b1N 2 (x) \u2227 \u00b1V (x, y))) \u2200x(\u00b1N (x) \u21d2 \u00b1V (x, P )) or \u2203x(\u00b1N (x) \u2227 \u00b1V (x, P ))With Proper nouns quantifier in the objectP (does not/do not) V D N\u2200x(\u00b1N (x) \u21d2 \u00b1V (P, x)) or \u2203x(\u00b1N (x) \u2227 \u00b1V (P, x))"}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Templates for the relational syllogistic fragment, D 1 and D 2 denote determiners, P denotes Proper nouns and V represents the verb while N, N 1 and N 2 symbolise nouns.", "figure_data": ""}, {"figure_label": "10", "figure_type": "table", "figure_id": "tab_11", "figure_caption": "Templates for the relative clauses (without transitive verbs) fragment, D denotes the determiner and N 1 , N 2 and N 3 symbolise nouns while A 1 and A 2 represent adjectives.", "figure_data": "Sub-fragmentNatural Language TemplateFirst order logic formuladual quantifiers, relative clause in the subjectD 1 (non-)N 1 who (does not/ do not) V D 2 (non-)N 2 is/are (not) (a) N 3\u2200x(\u00b1N 1 (x) \u2227 \u2200y(\u00b1N 2 (y) \u21d2 \u00b1V (x, y)) \u21d2 \u00b1N 3 (x)) or \u2200x(\u00b1N 1 (x) \u2227 \u2203y(\u00b1N 2 (y) \u2227 \u00b1V (x, y)) \u21d2 \u00b1N 3 (x)) or \u2200x(\u00b1N 1 (x) \u2227 \u2200y(\u00b1N 2 (y) \u21d2 \u00b1V (x, y)) \u21d2 \u00b1N 3 (x)) or \u2200x(\u00b1N 1 (x) \u2227 \u2200y(\u00b1N 2 (y) \u21d2 \u00b1V (x, y)) \u21d2 \u00b1N 3 (x))dual quantifiers, relative clause in the objectD 1 (non-)N 1 (does not/do not) V D 2 (non-)N 2 who is/are (not) (a) N 3"}, {"figure_label": "11", "figure_type": "table", "figure_id": "tab_12", "figure_caption": "Templates for the relative clauses (with transitive verbs) fragment, D 1 and D 2 denote determiners, P denotes Proper nouns and V represents the verb while N 1 N 2 and N 3 symbolise nouns.\u00b1N 1 (x) \u21d2 \u2200y(\u00b1N 2 (y) \u2227 \u00b1V 2 (y, x) \u21d2 \u00b1V 1 (x, y))) or \u2200x(\u00b1N 1 (x) \u21d2 \u2203y(\u00b1N 2 (y) \u2227 \u00b1V 2 (y, x)", "figure_data": "Sub-fragmentNatural Language TemplateFirst order logic formuladual quantifiers/do not) V 2 him/her/them V 1 D 2 (non-)N 2 who (does not D 1 (non-)N 1 (does not/do not)\u2200x("}, {"figure_label": "12", "figure_type": "table", "figure_id": "tab_13", "figure_caption": "Templates for the relative clauses (with transitive verbs) fragment, D 1 and D 2 denote determiners, P denotes Proper nouns and V 1 and V 2 represent verbs while N, N 1 and N 2 symbolise nouns.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "1: D \u2190 {} 2: repeat 3: V \u2190 randomly select list of words where V \u2282 V \u2032 such that |{P rN }| \u2264 n and |{N \u222a Adj \u222a V b}| \u2264 m 4:", "formula_coordinates": [4.0, 76.97, 306.1, 212.16, 78.72]}, {"formula_id": "formula_1", "formula_text": "15: D \u2190 D \u222a{M A , s \u03d5 , \u2113} 16: until stop condition is met", "formula_coordinates": [4.0, 72.49, 616.12, 132.09, 27.35]}, {"formula_id": "formula_2", "formula_text": "{(p (d) , \u2113 (d) )} |D| d", "formula_coordinates": [5.0, 319.94, 436.23, 69.05, 22.43]}], "doi": "10.18653/v1/D15-1075"}