{"title": "Subset Approximation of Pareto Regions with Bi-objective A*", "authors": "Nicol\u00e1s Rivera; Jorge A Baier; Carlos Hern\u00e1ndez", "pub_date": "", "abstract": "In bi-objective search, we are given a graph in which each directed arc is associated with a pair of non-negative weights, and the objective is to find the Pareto-optimal solution set. Unfortunately, in many practical settings, this set is too large, and therefore its computation is very time-consuming. In addition, even though bi-objective search algorithms generate the Pareto set incrementally, they do so exhaustively. This means that early during search the solution set covered is not diverse, being concentrated in a small region. To address this issue, we present a new approach to subset approximation of the solution set, that can be used as the basis for an anytime bi-objective search algorithm. Our approach transforms the given task into a target bi-objective search task using two real parameters. For each particular parameter setting, the solutions to the target task is a subset of the solution set of the original task. Depending on the parameters used, the solution set of the target task may be computed very quickly. This allows us to obtain, in challenging road map benchmarks, a rich variety of solutions in times that may be orders of magnitude smaller than the time needed to compute the solution set. We show that by running the algorithm with an appropriate sequence of parameters, we obtain a growing sequence of solutions that converges to the full solution set. We prove that our approach is correct and that Bi-Objective A* prunes at least as many nodes when run over the target task.", "sections": [{"heading": "Introduction", "text": "In bi-objective search we are given a graph G in which each arc, and thus each path, is associated with a pair of nonnegative costs, which represent meaningful objective functions. For example, in transportation, one function could refer to the time required to traverse an edge while the other could refer to fuel consumption. To compare two paths, a dominance relation is used. Path \u03c0 1 dominates path \u03c0 2 if both components of the cost of \u03c0 1 are less than or equal to the respective components of the cost of \u03c0 2 and their costs are not equal. Given a start vertex and a goal vertex in G, the problem consists of finding a Pareto-optimal solution set which contains all paths from start to goal which are not dominated by another path from start to goal.\nBi-objective search is required for several real-world applications; notably in transportation and logistics when time Copyright c 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. and cost (e.g., fare) are minimized (e.g., Pallottino and Scutella 1998;Bronfman et al. 2015;M\u00fcller-Hannemann and Weihe 2006), or when time and risk are minimized for cycling (Ehrgott et al. 2012). Recently, it has also been used in AI problems like robot planning (Davoodi 2017) and multi-agent path finding (Ren, Rathinam, and Choset 2021).\nAn important hurdle to bi-objective search is the size of the solution set, which can be exponential on the size of the graph (Hansen 1980). As a consequence, bi-objective search algorithms may only compute a handful of solutions before running out of time. Worse even, because of the exhaustive nature of their search, such solutions may not represent the diversity of the solution set. To address this problem, approaches to approximating the solution set have been proposed. One line of work proposes algorithms that reduce high runtimes by computing a solution set with approximate solutions whose suboptimality is bounded (e.g., Warburton 1987;Perny and Spanjaard 2008;Goldin and Salzman 2021). Another less explored line of work computes subset approximations (e.g., Cohon 1978;Henig 1986), in which a subset of the solution set is computed. A limitation of the former approach is that even though approximate solutions may be faster to compute still a large number of solutions may have to be computed. The main limitation of the latter approach is that the maximum number of computable solutions is fixed and task-dependent. This does not allow returning more solutions if more search time is available.\nIn this paper we present a new approach to bi-objective subset approximation. Our approach transforms the original bi-objective search instance into another (target) bi-objective instance such that each solution to the target problem is a solution to the original problem. If a heuristic h is available for the original task our simple transformation is also applicable to the heuristic of the original problem, which allows solving the target task with existing bi-objective heuristic search algorithms. We prove that implicit to the target instance is a stricter dominance relation in the sense that a path \u03c0 in the target instance may dominate a path \u03c0 in the target instance while the converse is not necessarily true. To generate the transformed instance we use two real parameters, \u03b1 and \u03b2 in (0, 1]. By varying these parameters we obtain different subset approximations. When both parameters are equal to 1, we recover the original solution set.\nWhile the target problem can be solved with any bi-\nThe Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)\nobjective search algorithm, we test our approach by combining it with Bi-Objective A* (BOA*) (Hernndez et al. 2020), a recently proposed bi-objective heuristic search algorithm that was shown to outperform other algorithms as it scales better on large maps. We show that good synergy between the target problem(s) and BOA* exists; indeed, BOA* prunes more nodes as \u03b1 and \u03b2 decrease their values. Empirically, we use standard roadmap benchmarks to show that, depending on the chosen parameters, BOA* can compute about 10-20% of the solutions in about one order of magnitude less time. In addition, we show that the solutions obtained are, on average, very diverse. As such, our approach shows promise for applications in which a few optimal but diverse solutions are required quickly by end users.", "publication_ref": ["b11", "b0", "b10", "b4", "b3", "b14", "b6", "b15", "b12", "b5", "b2", "b7", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "Background 2.1 Notation", "text": "A bi-objective search graph is a triple (S, E, c), where S is a finite set of states, E \u2286 S \u00d7S is a finite set of directed edges, and c : E \u2192 R \u22650 \u00d7 R \u22650 is a non-negative cost function.\nFor each s \u2208 S we denote by Succ(s) = {t \u2208 S | (s, t) \u2208 E} the successors of state s. A path \u03c0 from s 1 to s n is a sequence of states s 1 , s 2 , . . . , s n such that (s i , s i+1 ) \u2208 E for all i \u2208 {1, . . . , n \u2212 1}.\nBoldface lower case letters indicate column vectors in R 2 . The first and second component of p are denoted by p 1 and p 2 , respectively. We consider standard addition and multiplication by scalar of vectors. We say that p q, iff p 1 \u2264 q 1 and p 2 \u2264 q 2 ; in addition, p \u227a q iff p q and p = q. We say that p dominates q when p \u227a q, and that p weakly dominates q when p q Given a path \u03c0 = s 1 , . . . , s n , its cost is given by n\u22121 i=1 c(s i , s i+1 ) and denoted by c(\u03c0). Path \u03c0 dominates path \u03c0 if and only if c(\u03c0) \u227a c(\u03c0 ).\nA bi-objective search instance is as a tuple (S, E, c, s 0 , s g ), where (S, E, c) is a search graph, s 0 and s g are, respectively, the start state and the goal state. A start-to-goal path is a path from s 0 to s g . The Pareto-optimal solution set, denoted by sols P , contains all start-to-goal paths that are not dominated by another one.\nBi-objective search algorithms exploit heuristic functions. The h-value of a state is given by a function h : S \u2192 R \u22650 \u00d7 R \u22650 . For every s \u2208 S, h(s) estimates the cost of a path from state s to the goal state s g . h is admissible if and only if for every state s, h(s) c(\u03c0), where \u03c0 is any path from s to s g . Similarly, h is consistent if and only if, first, h(s g ) = 0, and second, h(s) c(s, t) + h(t) for all (s, t) \u2208 E.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Bi-Objective A*", "text": "In this section we introduce Bi-Objective A* (BOA*) (Hernndez et al. 2020). BOA* is a recent algorithm for solving biobjective search instances, which was empirically shown to scale better to larger instances than other bi-objective search algorithms. One of the main advantages of BOA*, at least for our approach, is that it has the same algorithmic structure of A*, ensuring desirable theoretical properties (see for example Theorem 4 and Corollary 1 in Section Section 4.2 below).\nSimilar to A*, BOA* has a priority queue Open, which will allow us to decide which element shall be expanded in the implicit search tree. Open contain nodes, which shall not be confused with the states S. A state s is an element of S in the search graph (which may represent a city in a map), whereas a node x in Open contains a state s(x) \u2208 S and a parent node parent(x). Therefore, a node x represent the state s(x), and the path that goes from s 0 to s(x), which can be recovered by successive queries to parents nodes until we reach a node y with s(y) = s 0 which has parent(y) = null. We denote the path associated with node x by \u03c0 x . Additionally, each node contains g, h and f -values as in the standard A* algorithm, whoever, these are bivariate functions. g(x) is the cost of the path \u03c0 x , i.e, g(x) = c(\u03c0 x ), h(s(x)) is the heuristic value of state s(x) (recall the heuristic is defined on the set of states S), and f (x) = g(x) + h(s(x)).\nBOA* starts the algorithm by initializing Open, with a node associated with the initial state s 0 , which we sometimes refer to as the root node. The priority queue Open is sorted lexicographically with respect to the f -values of the nodes, meaning that we prefer elements with smaller value in the first component, break ties using the second component. BOA* iterates by extracting the best candidates from Open, and expanding them, potentially including new elements to Open. The main difference between BOA* and A* with a consistent heuristic are: i) since in BOA* there are several non-dominated optimal solutions, states s \u2208 S may appear in several nodes in the open list with different non-dominated values of f , ii) Since there are several nondominated start-to-goal paths that we are interested on, when BOA* extracts s g from Open, it does not return (and end the execution), since there may be other solutions. Finally, iii) BOA* prunes the search tree to avoid consideration of paths that are dominated by others. Pruning of a node may occur right after its generation (i.e. before inserting it into Open), or right after its extraction from Open. To check for domination, BOA* exploits the fact that the heuristics used are consistent and that the open list is ordered lexicographically by f -value. This implies that if a state is discovered by BOA* via several nodes, i.e. by different paths, the f 1values of such nodes are non-decreasing. This allows BOA* to implement dominance checks in constant time. Now we go over the details of BOA*. Algorithm 1 shows its pseudo-code. In the initialization (Lines 1-8), the priority queue Open consists of a node associated with state s 0 , with a g-value equal to 0, and an f -value given by its heuristic h(s 0 ). Such a node also has a parent pointer initialized to null to indicate that the path towards s 0 is empty. Later, in the code parent pointers are used to define paths towards each node. In its main loop (Lines 9-24), like standard A*, BOA* extracts a node from Open (Line 10), and then expands it (Lines 17-24). Unlike A*, when a new solution is found, BOA* does not return but stores the newly found solution in sols (Lines 14-16).\nAnother aspect distinguishing BOA* from A* is its pruning. BOA*'s pruning is constant-time and it is key to its performance. To do so, for each state s \u2208 S it keeps a g min 2 value, corresponding to the minimum g 2 -value of a path to s previously extracted from Open. Given that Open is sorted Algorithm 1: Bi-Objective A* (BOA*) Input : A search problem (S, E, c, s0, sg) and a consistent heuristic function h Output: A cost-unique Pareto-optimal solution set 1 sols \u2190 \u2205 2 for each s \u2208 S do \n3 g min 2 (s) \u2190 \u221e 4 x \u2190 new node with s(x) = s0 5 g(x) \u2190 (0, 0) 6 parent(x) \u2190 null 7 f (x) \u2190 h(\n(y) = t 19 g(y) \u2190 g(x) + c(s(x), t) 20 parent(y) \u2190 x 21 f (y) \u2190 g(y) + h(t) 22 if g2(y) \u2265 g min 2 (t) or f2(y) \u2265 g min 2 (sg) then 23 continue 24\nAdd y to Open 25 return sols lexicographically, each time a node x (associated to state s(x) \u2208 S) is extracted from Open, it is associated with a path whose g 1 -value is greater than or equal to the g 1 -value of any other path towards s(x) previously extracted. This allows to focus pruning after extraction only on the second dimension, g 2 . Indeed, if g 2 (x) \u2265 g min 2 (s(x)), it means node x is either dominated by a previously found path or it has the same cost of a previously extracted path to s(x). Thus, it is pruned in Line 11. The pruning condition of Line 11 is also made stronger by adding f 2 (x) \u2265 g min 2 (s g ), which if violated would mean that the current path is dominated by a path towards the goal which has been previously extracted from Open. An analogous pruning condition is considered in Line 22, whose objective is to prune dominated nodes before they are added to Open.", "publication_ref": ["b8"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work: Subset Approximation", "text": "Now we focus on the problem of finding a subset of solutions. A well-known (Cohon 1978;Henig 1986) simple approach to obtain a reduced subset of solutions consists of mapping our given bi-objective search task P = (S, E, c, s 0 , s g ) into a single-objective search problem P \u03b1 in which the (scalar) cost function is defined as c = \u03b1c 1 + (1 \u2212 \u03b1)c 2 , where \u03b1 \u2208 [0, 1]. An interesting property is that a solution to P \u03b1 belongs to the Pareto-optimal solution set.\nFigure 1: Black dots and blue dots represent a Paretooptimal set of solutions of a bi-objective search instance. The red lines represent lines of the form \u03b1x + (1 \u2212 \u03b1)y = K for three different values of K. When K = 0 the line crosses the origin, and by increasing K the line moves closer to the Pareto region until it hits it. Solving the problem P \u03b1 is equivalent to finding the minimum value K that makes the line tangent to the Pareto region. Only blue points can be found by using this method.\nTheorem 1 (Henig (1986)). Let P = (S, E, c, s 0 , s g ) be a bi-objective search task. Let \u03b1 \u2208 [0, 1] and let P \u03b1 be the single-objective problem (S, E, c, s 0 , s g ), where c = \u03b1c 1 + (1 \u2212 \u03b1)c 2 is a univariate cost function. If \u03c0 is a minimumcost path for P \u03b1 then \u03c0 \u2208 sols P .\nPerhaps the most interesting fact about this approach is its geometric interpretation. Indeed, finding a path with minimum cost given by \u03b1c 1 + (1 \u2212 \u03b1)c 2 can be interpreted as finding the smallest value K such that the line given by the equation \u03b1x + (1 \u2212 \u03b1)y = K contains a point in the Pareto set. In other words, finding a solution to P \u03b1 corresponds to finding a line parallel to \u03b1x + (1 \u2212 \u03b1)y = 1 which is tangent to the Pareto set. See Figure 1 for an illustration.\nTo find a subset of solutions one may try various values of \u03b1. But since the approach is limited to finding points which intersect with tangents to the solution set, it is limited to finding at most points in the convex hull of the solution set.", "publication_ref": ["b2", "b7", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Solution Subsets via Bi-Objective Search", "text": "In this section we describe our approach to obtain a subset of the Pareto-optimal solution set. The approach can be used along with any bi-objective search algorithm. Our idea is to map the problem P into another search problem P \u03b1,\u03b2 where \u03b1 and \u03b2 are two parameters that control the precision of our approximation.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "The problem P \u03b1,\u03b2", "text": "We shall assume that \u03b1, \u03b2 \u2208 (0, 1] with \u03b1 + \u03b2 > 1. To build P \u03b1,\u03b2 we define the matrix M \u03b1,\u03b2 given by: Essentially, P \u03b1,\u03b2 is the same problem as P but with its cost function multiplied by matrix M \u03b1,\u03b2 . This new instance P \u03b1,\u03b2 has two important properties. The first property is that it defines a dominance relation \u03b1,\u03b2 in which u is dominated by v if and only if 2 for a graphical representation of the new dominance relation and for a formal geometrical interpretation see Proposition 1 below). Notice that when \u03b1 = \u03b2 = 1 we recover the usual dominance relation. The second important property is that the solution set of P \u03b1,\u03b2 is contained in the solution set of P , as stated in Theorem 2 below. As a consequence, all solutions found when solving P \u03b1,\u03b2 can be reported as solution of P .\nM \u03b1,\u03b2 = \u03b1 1 \u2212 \u03b1 1 \u2212 \u03b2 \u03b2 ,\n\u03b1u 1 +(1\u2212\u03b1)u 2 \u2264 \u03b1v 1 +(1\u2212\u03b1)v 2 and (1 \u2212 \u03b2)u 1 + \u03b2u 2 \u2264 (1 \u2212 \u03b2)v 1 + \u03b2v 2 , and u = v, or much shorter, M \u03b1,\u03b2 u M \u03b1,\u03b2 v. (See Figure\nProposition 1. Let L 1 and L 2 be two lines defined by:\nL 1 : \u03b1x + (1 \u2212 \u03b1)y = \u03b1c 1 (\u03c0) + (1 \u2212 \u03b1)c 2 (\u03c0), (1) L 2 : (1 \u2212 \u03b2)x + \u03b2y = (1 \u2212 \u03b2)c 1 (\u03c0) + \u03b2c 2 (\u03c0). (2)\nLet \u03c0 and \u03c0 be two paths such that c(\u03c0) = c(\u03c0 ). Then \u03c0 \u227a \u03b1,\u03b2 \u03c0 iff c(\u03c0 ) is in the intersection of the semi-plane above L 1 and the semi-plane above L 2 . Theorem 2. Let P = (S, E, c, s 0 , s g ) be a bi-objective search instance and let P \u03b1,\u03b2 be defined as above with \u03b1, \u03b2 \u2208 (0, 1] and \u03b1 + \u03b2 > 1. Then sols P \u03b1,\u03b2 \u2286 sols P .\nTo focus our presentation on the main ideas, we defer all proofs to Section 7.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Using P \u03b1,\u03b2 with BOA*", "text": "Theorem 2 states that solutions to P \u03b1,\u03b2 are solutions to P , and thus we can search solutions on the former problem to find solutions of the latter. In this search we will show that this idea works particularly well in combination with BOA* because the way BOA* navigates the search tree allow us not only to get results like Theorem 2 but also results ensuring that BOA* solving P \u03b1,\u03b2 will prune strictly more than BOA* solving P .\nBefore analyzing BOA* on the problem P \u03b1,\u03b2 we need to recall that BOA* is a heuristic-search algorithm, and so we need to find an heuristic. We start by assuming that we already have a heuristic function h for the original problem P . Then, we can obtain a heuristic for the new problem by applying M \u03b1,\u03b2 to the original heuristic h. Henceforth, we denote by h \u03b1,\u03b2 the result of applying M \u03b1,\u03b2 to h, i.e. the bivariate function (\u03b1h 1 + (1 \u2212 \u03b1)h 2 , \u03b2h 1 + (1 \u2212 \u03b2)h 2 ). Similarly, we denote g \u03b1,\u03b2 , f \u03b1,\u03b2 , and c \u03b1,\u03b2 the results of applying M \u03b1,\u03b2 to g, f and c, respectively. Note that by linearity of matrix multiplication f \u03b1,\u03b2 = g \u03b1,\u03b2 + h \u03b1,\u03b2 Theorem 3. Let P be a search instance, and h be a heuristic function for P . Then (i) if h is admissible for P , then so is h \u03b1,\u03b2 for P \u03b1,\u03b2 , and (ii) if h is consistent for P , then so is h \u03b1,\u03b2 for P \u03b1,\u03b2 .\nAs previously mentioned, another important property is that BOA* performs more pruning on P \u03b1,\u03b2 than on the original problem P . To understand this notion precisely recall that the problem P \u03b1,\u03b2 have the same underlying graph structure, independently of the value of \u03b1 and \u03b2, and so they have the same search trees (with different edge-cost). In particular, all the problems P \u03b1,\u03b2 share the same set of paths from s 0 , and so, since every node x is uniquely characterized by the path \u03c0 x leading to it from s 0 , we conclude that node x can also appear in the other problem (with different value of f , g, and h) represented by the same path \u03c0 x . Therefore, we can refer to the same nodes for different problems P \u03b1,\u03b2 (using different \u03b1 and \u03b2) by means of the path leading to them, and so we can talk about the same nodes in different problems.\nTo distinguish between executions of BOA* on P or P \u03b1,\u03b2 , we write BOA*(P, h) and BOA*(P \u03b1,\u03b2 , h \u03b1,\u03b2 ) to make clear what problem is solved and what is the input heuristic.\nAdditionally, we index all possible nodes in the search trees (before any prunes) with a unique natural number, which is used as tie-breaking mechanism in case two nodes have exactly the same f value in Open (preferring the node with less index for extraction). This is done so extraction of nodes is consistent in different problems P \u03b1,\u03b2 . One way to implement this is to enumerate states in S, then we break fties between nodes x and y by comparing \u03c0 x and \u03c0 y , first by the number of states in the path, and if they have the same number of states we use the lexicographic order of the path given by the enumeration of the states in it.\nFinally, in the following results we say that a node z is directly pruned if such node satisfies the conditions of Line 22 or Line 11 in the respective query, and we say that a node z is pruned if z is directly pruned, or parent(z) is pruned (if parent(z) = null, then parent(z) is not pruned). Essentially, a vertex is pruned if it is directly pruned or a node in the backwards path to the root node is pruned. Theorem 4. Let \u03b1, \u03b2 \u2208 (0, 1] be such that \u03b1 + \u03b2 > 1. Let h be a consistent heuristic. Then, if node y is directly pruned in the execution of BOA*(P, h), we have that y is pruned in the execution of BOA*(P \u03b1,\u03b2 , h \u03b1,\u03b2 ), This theorem essentially tells us that after all the pruning performed in Line 22 and Line 11, the search tree of BOA*(P, h) contains the search tree (after prunes) of BOA*(P \u03b1,\u03b2 , h \u03b1,\u03b2 ) when h is consistent. This ensures that no more search is required in BOA*(P \u03b1,\u03b2 , h \u03b1,\u03b2 ), and indeed, in the experimental section we will see that these new instances take much less time to be solved compared with the original problem, even when \u03b1 and \u03b2 are very close to 1.\nCorollary 1. Let \u03b1 1 , \u03b1 2 , \u03b2 1 , \u03b2 2 \u2208 (0, 1] be such that 1 \u2264 \u03b1 1 + \u03b2 1 ,\nand \u03b1 1 \u2264 \u03b1 2 , and \u03b2 1 \u2264 \u03b2 2 . Also, suppose that h is a consistent heuristic for problem P . Then, if node y is directly pruned by BOA*(P \u03b12,\u03b22 , h \u03b12,\u03b22 ), we have that y is pruned in the execution of BOA*(P \u03b11,\u03b21 , h \u03b11,\u03b21 ).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Towards Anytime Bi-Objective Search", "text": "Our theoretical analysis implies that when using small values of \u03b1 and \u03b2 more pruning is performed, and thus we shall expect faster executions. As a consequence, we propose a simple approach leading to an anytime bi-objective search algorithm, which is used later in Section 6. The main idea is to solve the target task for an initial pair of values, e.g. \u03b1 = \u03b2 = 0.8, to then increase both parameters, and repeat until we reach \u03b1 = \u03b2 = 1.\nIn general, different values of \u03b1 and \u03b2 generate different solution sets, and the geometry of such sets depends not only on \u03b1 and \u03b2 but also on the geometry of the original frontier (when \u03b1 = \u03b2 = 1). Therefore, we are interested on measuring how many solutions of sols P are captured by P \u03b1,\u03b2 , and whether or not these solutions are well-distributed. For this, we consider three different instances of the FL benchmark set (described in Section 6), whose frontiers are illustrated in Figure 3. The heatmap of Figure 4 shows, as expected, that for larger values of \u03b1 and \u03b2 we cover more solutions, however, interestingly, increasing \u03b1 has a greater impact on the number of solutions. This may be a consequence of the fact that BOA* finds solutions in increasing c 1 order.\nRegarding the distribution of the solutions, we observe it strongly depends on the structure of the solution costs.\nFigure 3 shows the distribution of the solutions for some values of (\u03b1, \u03b2). We observe that for the instance on the left, where the frontier is more balanced, solutions are produced in an even way, even for small values of \u03b1 and \u03b2, whereas for the other two instances, the region of the solution set in which the first coordinate is small is not generated until the values of \u03b1 and \u03b2 equal to 1. This analysis illustrates that the way we vary \u03b1 and \u03b2 has an important impact on solution diversity. Moreover, how diverse the solution set is given specific \u03b1 and \u03b2 values is instance-specific. Below, in our experimental section, we use a general rule to increase \u03b1 and \u03b2 that, we show, generates diverse solutions on average. We leave the problem of devising a sequence of \u03b1-\u03b2 values for maximizing diversity at an instance level out of the scope of this paper.", "publication_ref": [], "figure_ref": ["fig_2", "fig_2"], "table_ref": []}, {"heading": "Experimental Evaluation", "text": "Our experimental evaluation had the objective of evaluating the performance of BOA* run over P \u03b1,\u03b2 using different (\u03b1, \u03b2) values over a large number of instances in several standard road maps.\nWe evaluated our approach, implemented in C, on maps of the 9th DIMACS Implementation Challenge: Shortest Path 1 ; specifically, 50 random instances for each of four USA road maps used by Machuca and Mandow (2012). We ran all experiments on a 3.80GHz Intel(R) Core(TM) i7-10700K CPU Linux machine with 64GB of RAM. The cost components represent travel distances (c 1 ) and times (c 2 ). The input heuristic h corresponds to the exact travel distances and times to the goal state, computed with Dijkstra's algorithm. Dividing the Pareto Frontier in Buckets To report the diversity of solutions, imagine that we divide the upper-right quadrant of the plane (i.e. when both coordinates are positive) into five slices by drawing rays starting at the origin forming 18, 36, 54, and 72 degrees with the x-axis. We call each 18-degree slice a \"bucket\". By counting how many so- ", "publication_ref": ["b9"], "figure_ref": [], "table_ref": []}, {"heading": "643063-593489", "text": "Figure 4: Heatmap for the three instances of the FL map. The color represents the solutions of P covered by P \u03b1,\u03b2 . In all instances we observe that increasing \u03b1 has much more impact in the region we find, and indeed, choosing \u03b2 = 1 while keeping a small value of \u03b1 does not increase much the number of solutions. The title of each figure indicates the start and goal node. lutions are in each bucket we obtain a measure of diversity of the solution set. However, to apply this idea it is necessary to adjust scales. Indeed each cost function may have a different scale and between different problems the solution sets may have different height and width 2 . Intuitively the objective is to \"scale\" the solution set such that its width and height are both equal to 1; as such, the extreme solutions are always (0, 1) and (1, 0). Now let (x, y) be a scaled solution cost and \u03b8 be the angle between the origin and (x, y). We count this solution in the bucket given by \u03b8.\nTable 1 reports our results for 50 random instances for each road map. In each run we consider the same value for \u03b1 and \u03b2. The table reports the total runtime in seconds required to compute the solution set for P \u03b1,\u03b2 for each (\u03b1, \u03b2) pair, and the percentage of solutions that appear in each bucket. In addition, the table reports the total number of solutions in each bucket. We have the following observations:\n\u2022 We obtain solutions that are diverse on average. The maximum percentage difference between two buckets is 13%, which is observed in the BAY map with \u03b1 = \u03b2 = 0.84\n\u2022 A reasonable number of solutions can be obtained very quickly. For example, around 10% of solutions are obtained in about one order of magnitude less time than that required to find all solutions.\n\u2022 When (\u03b1, \u03b2) values increase, the runtime increases and the number of solutions found in each bucket increases.\n\u2022 The relation between computation time and percentage of solutions does not appear to be proportional as one would expect. For example in the FL map we compute approximately 8% of the solutions in about 9.7/210.9 = 4.6% of the time that is needed to compute 100% of solutions. Likewise, to compute around 15% of the solu-\n2\nWhere one can imagine the width as the first component of the solution that has the largest first component, and the height can be defined analogously for the second component. tions we require 16.8/210.9 = 8% of the time required to compute 100% of the solutions.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_1"]}, {"heading": "Proofs", "text": "In this section we provide a proof for each of our theoretical results. We begin with a simple lemma that is used in different proofs across this section.\nLemma 1. Let \u03b1, \u03b2 \u2208 (0, 1], and v, u \u2208 R \u22650 \u00d7 R \u22650 . If v u, then M \u03b1,\u03b2 v M \u03b1,\u03b2 u\n, and the same holds if we replace \u2264 by \u227a.\nProof. We just prove the result for since for the other case the same proof works.\nNote that u 1 \u2212 v 1 \u2265 0 and\nu 2 \u2212 v 2 \u2265 0. Therefore \u03b1(u 1 \u2212 v 1 ) + (1 \u2212 \u03b1)(u 2 \u2212 v 2 ) \u2265 0, since \u03b1 > 0. Hence \u03b1v 1 + (1 \u2212 \u03b1)v 2 \u2264 \u03b1u 1 + (1 \u2212 \u03b1)u 2 .\nThe same applies if we replace \u03b1 by 1 \u2212 \u03b2, concluding the result. Now we are ready to prove Theorem 1.\nProof of Theorem 1. Assume \u03c0 \u2208 sols P . Since \u03c0 is a startto-goal path, there must be another path \u03c0 \u2208 sols P such that c(\u03c0 ) \u227a c(\u03c0), so Lemma 1 yields\n\u03b1c 1 (\u03c0 ) + (1 \u2212 \u03b1)c 2 (\u03c0 ) < \u03b1c 1 (\u03c0) + (1 \u2212 \u03b1)c 2 (\u03c0)\nimplying that \u03c0 is not a solution of P \u03b1 , a contradiction.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proof of Section 4.1.", "text": "Proof of Theorem 2. For a contradiction, assume that there is a path \u03c0 \u2208 sols P \u03b1,\u03b2 such that \u03c0 \u2208 sols P . Since \u03c0 is a start-to-goal path in P but not a solution, there must be startto-goal path \u03c0 such that c(\u03c0 ) \u227a c(\u03c0). Then by Lemma 1, we have that c \u03b1,\u03b2 (\u03c0 ) \u227a c \u03b1,\u03b2 (\u03c0) which contradicts the fact that \u03c0 \u2208 sols P \u03b1,\u03b2 .   Hernndez et al. 2020, Lemma 2)] The sequences of extracted nodes and of expanded nodes have monotonically non-decreasing f 1 -values. Lemma 3. Consider BOA*(P, h). Let y be a node such that it satisfies the condition of Line 11 or Line 22 during the execution of BOA*(P, h), i.e. y was directly pruned after removing it from the open list, or after expanding its parent (preventing y from being inserted in Open). Then there exists a node z such that s(y) = s(z) or s(z) = s g , and such that f (z) f (y)\nProof. We analyze the case that y is directly pruned in Line 22, as the case of Line 11 is essentially the same. Suppose that y is directly pruned in Line 22. If y is directly pruned because the first clause of the if statement, then let t = s(y) be the state associated to node y, and so we have that some node z with s(z) = t was expanded in Line 13 before y giving that current value of g min 2 (t), i.e. g 2 (y) \u2265 g 2 (z), and thus, f 2 (y) \u2265 f 2 (z) since s(y) = s(z) = t (as both nodes share the same heuristic value h(y)). Since node z was extracted before y, by Lemma 2, f 1 (z) \u2264 f 2 (y), concluding that f (z) f (y). If y is directly pruned because of the second clause of the if statement, the argument is the same but in this case s(z) = s g and so h(s(z)) = 0.\nProof of Theorem 4. We proceed by contradiction: suppose it exists a node y which is directly pruned in BOA*(P, h) in Line 11 or Line 22, but it is not pruned in BOA*(P \u03b1,\u03b2 , h \u03b1,\u03b2 ), i.e. y is included in the open list, and then extracted, and expanded in BOA*(P \u03b1,\u03b2 , h \u03b1,\u03b2 ).\nSince y is directly pruned in BOA*(P, h), by Lemma 3, there exists a node z such that s(y) = s(z) or s(z) = s g , and such that f (z) \u2264 f (y). By Lemma 1, f \u03b1,\u03b2 (z) \u227a f \u03b1,\u03b2 (y) or f \u03b1,\u03b2 (z) = f \u03b1,\u03b2 (y), and thus it has smaller (or equal) firstcoordinate in f \u03b1,\u03b2 . In case z and y have the same f -value, by the tie-breaking mechanism implemented z will be extracted before from Open than y, so we can assume that f \u03b1,\u03b2 (z) \u227a f \u03b1,\u03b2 (y). From now on, we shall focus on the behavior of node z in the execution of BOA*(P \u03b1,\u03b2 , h \u03b1,\u03b2 ). In the execution, node z either i) enters to the open list of BOA*(P \u03b1,\u03b2 , h \u03b1,\u03b2 ) and it is successfully removed (and expanded), or ii) not. If it does (case i), then node z is extracted and expanded before node y due to Lemma 2, and hence y will be directly pruned in Line 11 since we would have observed that z have smaller second-component value in g \u03b1,\u03b2 (z) (assuming y is not pruned before), hence y is pruned. If z is pruned in either Line 11 or Line 22 (case ii), then it was pruned due to another node x that was extracted from the open (i.e. BOA* read Line 13 with this node) and moreover f \u03b1,\u03b2 (x) f \u03b1,\u03b2 (z) \u227a f \u03b1,\u03b2 (y). Hence, x is extracted from Open before y, and thus y is pruned.\nProof of Corollary 1. Let \u03b1 and \u03b2 be defined as\n\u03b1 = \u03b1 1 + \u03b2 2 \u2212 1 \u03b1 2 + \u03b2 2 \u2212 1 and \u03b2 = \u03b2 1 + \u03b1 2 \u2212 1 \u03b1 2 + \u03b2 2 \u2212 1 ,\nand note that \u03b1, \u03b2 \u2208 (0, 1] and \u03b1 + \u03b2 > 1, due to the constrains on \u03b1 1 , \u03b1 2 , \u03b2 1 and \u03b2 2 . Then, a straightforward computation shows that M \u03b1,\u03b2 M \u03b12,\u03b22 = M \u03b11,\u03b21 . Now we can assume that P \u03b12,\u03b22 was the original problem, and that we are applying the transformation M \u03b1,\u03b2 to it, obtaining P \u03b11,\u03b21 . The result follows then from Theorem 4.", "publication_ref": ["b8"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusions and Future Work", "text": "We presented a new approach for generating subset approximations of Pareto-optimal solution sets. Our approach transforms the given task into another bi-objective task which solution set is a subset of the Pareto-optimal solution set. This allows us to obtain a diverse solution set containing around 10% of solutions in one order of magnitude less time than what is needed to compute the whole Pareto-optimal set.\nThere are many future directions for research. Search solutions on average are diverse but we know that an instance level a more fine-grained approach to set \u03b1 and \u03b2 is needed. Our approach also seems compatible with parallelization, which could yield very efficient anytime algorithms.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "Nicols Rivera was supported by ANID FONDECYT grant number 3210805. Jorge Baier and Carlos Hernndez are grateful to the Centro Nacional de Inteligencia Artificial CE-NIA, FB210017, BASAL, ANID.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "The maximin HAZMAT routing problem", "journal": "", "year": "2015", "authors": "A Bronfman; V Marianov; G Paredes-Belmar; A L\u00fcer-Villagra"}, {"ref_id": "b1", "title": "", "journal": "European Journal of Operational Research", "year": "", "authors": ""}, {"ref_id": "b2", "title": "Multiobjective Programming and Planning", "journal": "", "year": "1978", "authors": "J L Cohon"}, {"ref_id": "b3", "title": "Bi-objective path planning using deterministic algorithms", "journal": "Robotics and Autonomous Systems", "year": "2017", "authors": "M Davoodi"}, {"ref_id": "b4", "title": "A bi-objective cyclist route choice model. Transportation research part A: policy and practice", "journal": "", "year": "2012", "authors": "M Ehrgott; J Y Wang; A Raith; C Van Houtte"}, {"ref_id": "b5", "title": "Approximate Bi-Criteria Search by Efficient Representation of Subsets of the Pareto-Optimal Frontier", "journal": "AAAI Press", "year": "2021", "authors": "B Goldin; O Salzman; S Biundo; M Do; R Goldman; M Katz; Q Yang; Zhuo "}, {"ref_id": "b6", "title": "Bicriterion path problems", "journal": "Springer", "year": "1980", "authors": "P Hansen"}, {"ref_id": "b7", "title": "The shortest path problem with two objective functions", "journal": "European Journal of Operational Research", "year": "1986", "authors": "M I Henig"}, {"ref_id": "b8", "title": "A simple and fast bi-objective search algorithm", "journal": "", "year": "2020", "authors": "C Hernndez; W Yeoh; J Baier; H Zhang; L Suazo; S Koenig"}, {"ref_id": "b9", "title": "Multiobjective heuristic search in road maps", "journal": "Expert Systems with Applications", "year": "2012", "authors": "E Machuca; L Mandow"}, {"ref_id": "b10", "title": "On the cardinality of the Pareto set in bicriteria shortest path problems", "journal": "Annals of Operations Research", "year": "2006", "authors": "M M\u00fcller-Hannemann; K Weihe"}, {"ref_id": "b11", "title": "Shortest path algorithms in transportation models: classical and innovative aspects", "journal": "Springer", "year": "1998", "authors": "S Pallottino; M G Scutella"}, {"ref_id": "b12", "title": "Near Admissible Algorithms for Multiobjective Search", "journal": "", "year": "2008", "authors": "P Perny; O Spanjaard"}, {"ref_id": "b13", "title": "European Conference on Artificial Intelligence (ECAI)", "journal": "", "year": "", "authors": ""}, {"ref_id": "b14", "title": "Multi-objective Conflict-based Search for Multi-agent Path Finding", "journal": "", "year": "2021", "authors": "Z Ren; S Rathinam; H Choset"}, {"ref_id": "b15", "title": "Approximation of Pareto optima in multiple-objective, shortest-path problems. Operations Research", "journal": "", "year": "1987", "authors": "A Warburton"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "s0) 8 Initialize Open and add x to it 9 while Open = \u2205 do 10 Remove a node x from Open with the lexicographically smallest f -value 11 if g2(x) \u2265 g min 2 (s(x)) or f2(x) \u2265 g min 2 t \u2208 Succ(s(x)) do 18 y \u2190 new node with s", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: On the left we have the standard way to prune paths. Any path whose cost is inside the dotted region is pruned.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Pareto-optimal solutions of the three problems considered in our experiments. Reddish points are solutions that appear for small values of \u03b1 and \u03b2, whereas bluish points are solutions that only appear for large values. Recall that for increasing values of \u03b1 and \u03b2 solution sets grow. The title of each graph indicates the start and goal node. Values of c 1 and c 2 are in millions.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Results on 50 random instances for different road maps. In all these experiments we set \u03b1 = \u03b2. The table shows the \u03b1 (and \u03b2), and the total runtime to solve all the instances, and the percentage of solutions in each bucket.", "figure_data": "Proofs of Section 4.2 We omit the proof of Theorem 3 as it is a straightforward consequence of Lemma 1, and the definition of admissible and consistent. For the proof of The-orem 4 we require the following lemmas.Lemma 2. [("}], "formulas": [{"formula_id": "formula_0", "formula_text": "3 g min 2 (s) \u2190 \u221e 4 x \u2190 new node with s(x) = s0 5 g(x) \u2190 (0, 0) 6 parent(x) \u2190 null 7 f (x) \u2190 h(", "formula_coordinates": [3.0, 55.99, 121.7, 119.26, 55.05]}, {"formula_id": "formula_1", "formula_text": "(y) = t 19 g(y) \u2190 g(x) + c(s(x), t) 20 parent(y) \u2190 x 21 f (y) \u2190 g(y) + h(t) 22 if g2(y) \u2265 g min 2 (t) or f2(y) \u2265 g min 2 (sg) then 23 continue 24", "formula_coordinates": [3.0, 53.8, 298.62, 201.01, 73.68]}, {"formula_id": "formula_2", "formula_text": "M \u03b1,\u03b2 = \u03b1 1 \u2212 \u03b1 1 \u2212 \u03b2 \u03b2 ,", "formula_coordinates": [3.0, 382.84, 684.27, 111.8, 20.92]}, {"formula_id": "formula_3", "formula_text": "\u03b1u 1 +(1\u2212\u03b1)u 2 \u2264 \u03b1v 1 +(1\u2212\u03b1)v 2 and (1 \u2212 \u03b2)u 1 + \u03b2u 2 \u2264 (1 \u2212 \u03b2)v 1 + \u03b2v 2 , and u = v, or much shorter, M \u03b1,\u03b2 u M \u03b1,\u03b2 v. (See Figure", "formula_coordinates": [4.0, 54.0, 350.92, 238.5, 32.24]}, {"formula_id": "formula_4", "formula_text": "L 1 : \u03b1x + (1 \u2212 \u03b1)y = \u03b1c 1 (\u03c0) + (1 \u2212 \u03b1)c 2 (\u03c0), (1) L 2 : (1 \u2212 \u03b2)x + \u03b2y = (1 \u2212 \u03b2)c 1 (\u03c0) + \u03b2c 2 (\u03c0). (2)", "formula_coordinates": [4.0, 68.43, 482.14, 224.07, 26.0]}, {"formula_id": "formula_5", "formula_text": "Corollary 1. Let \u03b1 1 , \u03b1 2 , \u03b2 1 , \u03b2 2 \u2208 (0, 1] be such that 1 \u2264 \u03b1 1 + \u03b2 1 ,", "formula_coordinates": [5.0, 54.0, 369.64, 238.49, 23.37]}, {"formula_id": "formula_6", "formula_text": "2", "formula_coordinates": [6.0, 66.65, 672.74, 2.99, 7.2]}, {"formula_id": "formula_7", "formula_text": "Lemma 1. Let \u03b1, \u03b2 \u2208 (0, 1], and v, u \u2208 R \u22650 \u00d7 R \u22650 . If v u, then M \u03b1,\u03b2 v M \u03b1,\u03b2 u", "formula_coordinates": [6.0, 319.5, 388.71, 238.5, 23.37]}, {"formula_id": "formula_8", "formula_text": "u 2 \u2212 v 2 \u2265 0. Therefore \u03b1(u 1 \u2212 v 1 ) + (1 \u2212 \u03b1)(u 2 \u2212 v 2 ) \u2265 0, since \u03b1 > 0. Hence \u03b1v 1 + (1 \u2212 \u03b1)v 2 \u2264 \u03b1u 1 + (1 \u2212 \u03b1)u 2 .", "formula_coordinates": [6.0, 319.5, 456.28, 238.5, 33.97]}, {"formula_id": "formula_9", "formula_text": "\u03b1c 1 (\u03c0 ) + (1 \u2212 \u03b1)c 2 (\u03c0 ) < \u03b1c 1 (\u03c0) + (1 \u2212 \u03b1)c 2 (\u03c0)", "formula_coordinates": [6.0, 334.28, 576.91, 208.93, 10.32]}, {"formula_id": "formula_10", "formula_text": "\u03b1 = \u03b1 1 + \u03b2 2 \u2212 1 \u03b1 2 + \u03b2 2 \u2212 1 and \u03b2 = \u03b2 1 + \u03b1 2 \u2212 1 \u03b1 2 + \u03b2 2 \u2212 1 ,", "formula_coordinates": [7.0, 345.48, 455.98, 186.53, 23.89]}], "doi": ""}