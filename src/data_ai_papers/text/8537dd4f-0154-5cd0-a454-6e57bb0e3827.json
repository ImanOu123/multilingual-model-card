{"title": "Factorizing Personalized Markov Chains for Next-Basket Recommendation", "authors": "Steffen Rendle; Christoph Freudenthaler; Lars Schmidt-Thieme", "pub_date": "", "abstract": "Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over underlying Markov chains. That means for each user an own transition matrix is learned -thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model subsumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization.", "sections": [{"heading": "INTRODUCTION", "text": "A core technology of many recent websites are recommender systems. They are used for example to increase sales in e-commerce, clicking rates on websites or visitor satisfaction in general. In this paper, we deal with the problem setting where sequential basket data is given per user. An obvious example is an online shop where a user buys items (e.g. books or CDs). In these applications, usually several items are bought at the same time, i.e. we have a set/basket of items at one point of time. The target is now to recommend items to the user that he might want to buy in his next visit.\nRecommender systems based on a Markov chain (MC) model utilize such sequential data by predicting the users next action based on the last actions. Therefore a transition matrix is estimated that gives the probability of buying an item based on the last purchases of the user. The transition matrix of the MC models is assumed to be the same over all users. The personalization is made by applying the (general) transition matrix on the user's last actions. On the other hand, one of the most successful model classes are factorization methods (MF) based on matrix or tensor decomposition. The best approaches [3,4] for the 1M$ Netflix challenge 1 are based on this model class. Also on the ECML/PKDD discovery challenge 2 for tag recommendation, a factorization model based on tensor decomposition has outperformed the other approaches [8]. These models learn the general taste of the user disregarding sequential information. Both MF and MC have their advantages: MF uses all data to learn the general taste of the user whereas MC can capture sequence effects in time by using a nonpersonalized transition matrix, i.e. the transition matrix is learned over all data of all users.\nIn this paper, we present a model based on an underlying MC where the transitions are user-specific. We model a transition cube where each slice is a user-specific transition matrix of an underlying MC on the users basket history. With this personalization, we bring together both advantages of MC and MF: (1) the sequential data is captured by the transition matrix and (2) as all transition matrices are user-specific, the user-taste over all data is captured. Besides introducing personalized MCs, the central contribution of this work is the estimation of the transition tensor. Because of the sparsity of the data, it is not possible to get good estimates of the personalized transition matrices by using standard counting approaches (which are Maximum Likelihood Estimators) on a complete parametrization. Instead, we model the transition tensor by a factorization model. This allows to propagate information among similar users, similar items and similar transitions. By using a factorization model based on pairwise interactions, it is possible to deal with high sparsity. We show that this model subsumes both the MF model and the unpersonalized MC model. For learning the factorization parameters, the Bayesian Personalized Ranking (BPR) framework [7] is extended to basket data.\nIn our evaluation chapter, we apply our method to an anonymized real-world dataset of an e-commerce website. We show that our proposed method FPMC outperforms MF and MC.\nIn total the contributions are as follows:\n\u2022 We introduce personalized Markov chains relying on personalized transition matrices. This allows to capture both sequential effects and long term user-taste. We show that this is a generalization of both standard MC and MF models.\n\u2022 To deal with the sparsity for the estimation of transition probabilities, we introduce a factorization model that can be applied both to personalized and normal transition matrices. This factorization approach results in less parameters and due to generalization to a better quality than full parametrized models.\n\u2022 We empirically show that our model outperforms other state-of-the-art methods on sequential data.", "publication_ref": ["b2", "b3", "b0", "b7", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "RELATED WORK", "text": "Markov chains or recommender systems have been studied by several researchers. Zimdars et al. [10] describe a sequential recommender based on Markov chains. They investigate how to extract sequential patterns to learn the next state with a standard predictor -e.g. a decision tree. Mobasher et al. [5] use pattern mining methods to discover sequential patterns which are used for generating recommendations. Shani et al. [9] introduce a recommender based on Markov decision processes (MDP) and also a MC based recommender. To enhance the maximum likelihood estimates (MLE) of the MC transition graphs, they describe several heuristic approaches like clustering and skipping. Instead of improving the MLE estimates with heuristics, we use a factorization model that is learned for optimal ranking instead of transition MLE. In total, the main difference of our work to all the previous approaches is the use of personalized transition graphs which bring together the benefits of sequential, i.e. time-aware, MC with time-invariant user taste. Furthermore factorizing transition probabilities and optimizing the parameters for ranking is new.\nOn the other hand, most of the recommender systems do not take sequential patterns into account and recommend based on the whole user history. Besides a very large literature on rating prediction (i.e. regression) emerging from the Netflix contest (e.g. [3,4]), item recommendation from implicit feedback has started to get more into the focus [2,6,7]. Item recommendation is a harder prediction problem than rating prediction, as only positive observations are made and standard sparse regression and classification methods like the ones from the Netflix contest can not directly be applied. Three recent methods for item recommendation are based on the matrix factorization model that factorizes the matrix of user-item correlations. Both Hu et al. [2] and Pan and Scholz [6] optimize the factorization on user-item pairs (u, i) where observed pairs are treated as positive and nonobserved ones as negative. Hu et al. [2] use a least-square optimization where case weights are used for controlling the importance of observations. Pan and Scholz [6] also use case weights but with several optimization criteria like hinge-loss and least-square. Because non-observation of an item does not mean that the user does not want to select it in the future, Rendle et al. [7] take another optimization approach by learning over observation pairs (u, i, j), e.g. a user u prefers item i over item j. All these methods have been shown to outperform standard approaches like k-nearest-neighbour based on Pearson similarity. In this work, we will bring the advantages of these MF models together with MC models. ", "publication_ref": ["b9", "b4", "b8", "b2", "b3", "b1", "b5", "b6", "b1", "b5", "b1", "b5", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "ITEM RECOMMENDATION FROM SE-QUENTIAL SET DATA", "text": "Item recommendation is the task of suggesting a specific user a personalized list of items (e.g. products, songs). This can be seen as creating a personalized ranking on the items. Usually, recommender systems rely on statistical models that use the event history (e.g. purchases, listening) of users on items to generate recommendations. Time and thus sequential behavior is an important additional information that is tracked in almost any real-world application. Secondly, we consider the problem setting with set data -e.g. in online-shopping usually a basket of products is bought at the same time. In total, our setting is item recommendation from sequential set data. An example of such data can be found in figure 1.", "publication_ref": [], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Sequential vs. General Recommender", "text": "The most common approach to generate recommendations is to discard any sequential information and learn what items a user is typically interested in. On the other hand, recommendations of sequential methods (mostly relying on Markov chains) are based only on the last user events by learning what an arbitrary user buys next when he has bought a certain item in the recent past. Both methods have their strengths and disadvantages. Imagine a user that in general buys movies like 'Star Trek' and 'Star Wars'. In contrast to his usual buying behavior, he recently has purchased 'Titanic' and 'Dirty Dancing' to watch with his girlfriend. After that a MC based recommender of length 2 would only recommend movies like 'Notting Hill' and other romantic movies. In contrast, a global personalized recommender would correctly account for the general taste of the user and recommend also movies like 'Back To the Future', 'Alien' or other science fiction movies. But there are also examples where sequential recommenders have advantages: E.g. good recommendations for a user that has recently bought a digital camera are accessories that other users have bought after buying that camera -this is exactly what a Markov chain model does. Global personalized recommender would not adapt directly to the recent purchase (the digital camera) but would recommend items this user likes in general.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Formalization", "text": "Before describing our approach to solve this problem, we introduce the notation of this paper. Let U = {u1, . . . , u |U | } be a set of users and I = {i1, . . . , i |I| } a set of items. For each user u, a purchase history B u of his baskets is known:\nB u := (B u 1 , . . . B u tu\u22121 ) with B u t \u2286 I. The purchase history of all users is B := {B u 1 , . . . B u |U | }.\nGiven this history, the task is to recommend items to a user the next time t the user visits the shop. Note that we deal not with absolute time points (i.e. 1st January 2010) but with relative ones regarding a user, e.g. the first, second, etc. basket of a user. The item recommendation task can be formalized in creating a personal ranking <u,t\u2282 I 2 over all pairs of items for user u for his t-th basket. With this ranking, we can recommend the user the top n items.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "FACTORIZING PERSONALIZED MAR-KOV CHAINS (FPMC)", "text": "First, we introduce MC for sequential set data and extend this to personalized MCs. We discuss the weakness of Maximum Likelihood Estimates for the transition cubes. To solve this, we introduce factorized transition cubes where information among transitions is propagated. We conclude this section by combining both ideas into FPMCs.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Personalized Markov Chains for Sets", "text": "First, we describe how to model the unpersonalized MC for sets with a reasonable state space. Then we show how to estimate the parameters for this unpersonalized MC with the maximum likelihood estimator (MLE). Afterwards, the extension of both the model and the estimation to personalized MCs is simple. Finally, we will show the limitations of full parametrized transition graphs (i.e. one parameter per transition) and the MLE method for personalized Markov chains.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Markov Chains for Sets", "text": "In general, a Markov chain of order m is defined as\np(Xt = xt|Xt\u22121 = xt\u22121, . . . , Xt\u2212m = xt\u2212m)(1)\nwhere Xt, . . . , Xt m are random variables and xt\u2212m their realizations. In a recommender application without sets, the random variables are defined over I -i.e. realizations are single items i \u2208 I. But in our case, the variables are defined over P(I) as the realizations are whole baskets B and thus the size of the state space is 2 |I| . Obviously, defining a long chain over the whole state space is not feasible for sets. To handle this huge state space, we make two simplifications:\n(1) we use chains of length m = 1 and (2) the transition probabilities are simplified. An unpersonalized Markov chain of order m = 1 for the basket problem is:\np(Bt|Bt\u22121)(2)\nIn recommender scenarios without sets, usually longer chains (e.g. m = 3) are preferable [9] because a history with size m = 1 contains only one item. In our case with sets, even a chain with length m = 1 is reasonable because it relies already on many items (all items of the basket) -e.g. in the application of our evaluation there are about 10 items on average (see table 1). Markov chains of length m = 1 are described by their stochastic transition matrix A over the state space. In our case the state space over sets is P(I) and thus the dimensionality of the transition matrix would be 2 |I| \u00d72 |I| . Thus, instead of modeling transition over baskets, we model transitions over |I| binary variables that describe a set/ basket:\na l,i := p(i \u2208 Bt|l \u2208 Bt\u22121)(3)\nUsing this representation has the following implications:\n\u2022 The state space is now I and thus the size of the transition matrix A is |I| 2 -by factorization, we will later reduce the number of parameters needed to represent this space from |I| 2 to 2 k |I| where k is the number of latent dimensions used in the factorization model.\n\u2022 The elements of the state space are i \u2208 B which are binary variables, thus p(i \u2208 Bt|l \u2208 Bt\u22121)+p(i \u2208 Bt|l \u2208 Bt\u22121) = 1. Note that the transition matrix A is no longer stochastic, because P i\u2208I a l,i = 1. For item recommendation, we are interested in the probability of purchasing an item given the last basket of a user. This can be defined as the mean over all transition probabilities from purchases of the last basket to this item:\np(i \u2208 Bt|Bt\u22121) := 1 |Bt\u22121| X l\u2208B t\u22121 p(i \u2208 Bt|l \u2208 Bt\u22121) (4)\nAnd the full Markov chain over baskets can be expressed by:\np(Bt|Bt\u22121) \u221d Y i\u2208Bt p(i|Bt\u22121)(5)\nNote that we are looking for a ranked list of items and thus are not interested in the full Markov chain (eq. ( 5)), but in sortable single-item probabilities (eq. ( 4)).", "publication_ref": ["b8"], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "Estimation of Transition Probabilities", "text": "To make predictions using the Markov chain in eq. ( 4), the transition probabilities a l,i have to be estimated. The maximum likelihood estimator for a l,i given the data B is:\na l,i =p(i \u2208 Bt|l \u2208 Bt\u22121) =p (i \u2208 Bt \u2227 l \u2208 Bt\u22121) p(l \u2208 Bt\u22121) = = |{(Bt, Bt\u22121) : i \u2208 Bt \u2227 l \u2208 Bt\u22121}| |{(Bt, Bt\u22121) : l \u2208 Bt\u22121}|(6)\nFigure 2: Non-personalized Markov chain: The transition matrix contains the MLE estimates for the probability p(i \u2208 Bt|l \u2208 Bt\u22121) using the data of figure 1. The column # states how many observations were used to estimate this transition. In this example, the users 1 and 2 as well as 3 and 4 share a similar taste for items a, c and items c, e respectively. Thus, one would expect to find d before b in the recommendation list for user 4, but the MC would recommend b as best unknown item.\nAn example for non-personalized MLE can be seen in figure 2. Here, the buying history for the four users of figure 1 are translated into transitions A of eq. ( 4). The transition matrix can then be applied to predict which items should be recommended given the last basket. E.g. for user 4, the probabilities would be: As the user has already bought item c and e, the best recommendation of unknown items would be b and then a. Looking only at the items this and similar users have bought in the past, one would expect, that item d might be a better recommendation.", "publication_ref": [], "figure_ref": ["fig_0", "fig_0"], "table_ref": []}, {"heading": "Personalized Markov Chains for Sets", "text": "Until now, the MC has been defined unpersonalized, i.e. independently of the user. Next, we extend this to a personalized MC per user:\np(B u t |B u t\u22121 )(7)\nAgain, we represent each MC by the transitions over items, but now user-specific:\na u,l,i := p(i \u2208 B u t |l \u2208 B u t\u22121 )(8)\nAnd thus also the prediction depends only on the user's transitions:\np(i \u2208 B u t |B u t\u22121 ) := 1 |B u t\u22121 | X l\u2208B u t\u22121 p(i \u2208 B u t |l \u2208 B u t\u22121 ) (9)\nAlso MLE can be applied analogously but now the transitions for user u are only estimated from his history B uthat means u is not a free variable anymore:\na u,l,i =p(i \u2208 B u t |l \u2208 B u t\u22121 ) =p (i \u2208 B u t \u2227 l \u2208 B u t\u22121 ) p(l \u2208 B u t\u22121 ) = |{(B u t , B u t\u22121 ) : i \u2208 B u t \u2227 l \u2208 B u t\u22121 }| |{(B u t , B u t\u22121 ) : l \u2208 B u t\u22121 }|(10)\nThat means for each user we have an own transition matrix A u which in total gives a transition tensor A \u2208 [0, 1] |U |\u00d7|I|\u00d7|I| .\nFigure (3) shows the personalized transition matrix of our example. Many of the parameters cannot be estimated because there is no observation in the data. Also the transitions that are estimated are based only on a small number of observations that means they are unreliable. At first glance, using personalized MCs seems to be unreasonable. We will discuss next what are the reasons for the poor estimations and show how to fix it.", "publication_ref": ["b2"], "figure_ref": [], "table_ref": []}, {"heading": "Limitations of MLE and Full Parametrization", "text": "The problem of unreliable transition probabilities both for unpersonalized and even more for personalized MCs lies in the fact that they work with a full parametrized transition graph (e.g. matrix and tensor respectively) and the way of parameter estimation. Full parametrization means we have |I| 2 and |U | |I| 2 respectively independent parameters for describing the transitions. Note that MLE estimates each transition parameter a l,i independently from the others, i.e. none of the cooccurrences (l, i) will contribute to another transition probability estimator (l, j) but only to p(i \u2208 Bt|l \u2208 Bt\u22121). This is even worse for personalized MCs as a triple (u, l, i) does not contribute to the estimate of (u \u2032 , l, i). In addition, the important properties of MLE (e.g. Gaussian distribution, unbiased estimator, minimal variance under all unbiased estimators) only exist in asymptotic theory. In cases of less data they suffer from underfitting. Since in our scenario the data is extremely sparse, Maximum Likelihood Estimators easily fail.\nTo get more reliable estimates for the transitions, we factorize the transition cube which breaks the independence of the parameters and the estimation. This way, each transition is influenced by similar users, similar items and similar transitions because information propagates through this model. In our evaluation, we show that this way (1) better transition graphs than MLE can be generated for the nonpersonalized setting and (2) that personalized MCs outperform both non-personalized factorized MC and non-personalized full parametrized MLE MCs.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Factorizing Transition Graphs", "text": "In the following, we will derive a factorization model for the transition cube A. That means we model the unobserved transition tensor A by a low rank approximation\u00c2. The advantage of this approach over a full parametrization is that it can handle sparsity and generalizes to unobserved \n(i \u2208 B u t |l \u2208 B u t\u22121 )\n. Entries with ? are missing values as there is no data to estimate the probabilities. Obviously, estimating the personalized transition matrices directly results in very poor transitions as each estimate is not reliable. This problem will be solved later by factorizing the transitions. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Factorization of the Transition Cube", "text": "A general linear factorization model for estimating the tensor A is the Tucker Decomposition (TD):\nA := C \u00d7U V U \u00d7L V L \u00d7I V I (11\n)\nwhere C is a core tensor and V U is the feature matrix for the users, V L is the feature matrix for the items in the last transition (outgoing nodes) and V I is the feature matrix for the items to predict (ingoing nodes). They have the following structure:\nC \u2208 R k U ,k L ,k I , V U \u2208 R |U |\u00d7k U , (12\n)\nV L \u2208 R |I|\u00d7k L , V I \u2208 R |I|\u00d7k I (13\n)\nwith the factorization dimensions kU , kL and kI . The Tucker Decomposition subsumes other factorization models like the Canonical Decomposition (CD) aka parallel factor analysis (PARAFAC). The parallel factor model assumes a diagonal core tensor, i.e.\nc fu,f i ,f j = ( 1, if fu = fi = fj 0, else(14)\nwith equal factorization dimensionality: kU = kL = kI .\nAs the observed transitions for A are very sparse, we use a special case of CD that models pairwise interactions:\na u,l,i := v U,I u , v I,U i + v I,L i , v L,I l + v U,L u , v L,U l (15)\nor equivalently:\na u,l,i := k U,I X f =1 v U,I u,f v I,U i,f + k I,L X f =1 v I,L i,f v L,I l,f + k U,L X f =1 v U,L u,f v L,U l,f(16)\nThis model directly models the pairwise interaction between all three modes of the tensor, i.e. between U and I, U and J as well as J and I. In total for each mode (i.e. user U, item I, item J), we have two factorization matrizes:\n1. For the interaction between U and I: V U,I \u2208 R |U |\u00d7k U,I modelling the user features and V I,U \u2208 R |I|\u00d7k U,I for the last item i.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "2.", "text": "For the interaction between I and L: V I,L \u2208 R |I|\u00d7k I,L for the next item i and V L,I \u2208 R |I|\u00d7k I,L for the last item l.\n3. For the interaction between U and L: V U,L \u2208 R |U |\u00d7k U,L for the user features and V L,U \u2208 R |I|\u00d7k U,L for the features of the last item l.\nAn advantage of this model over TD is that the prediction and learning complexity is much lower than for TD [8]. Furthermore even though TD and PARAFAC subsume the pairwise interaction model, with standard regularization estimation procedures have problems identifying such a model [8].\nIn section 5 we describe how to optimize the model parameters (factorization matrices) for item recommendation.", "publication_ref": ["b7", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Factorization of the Transition Matrix", "text": "The proposed model for factorizing transition cubes can also be applied to estimate a transition matrix A (see formula (3)) for cases where no personalization of the transition graph is desired. By skipping the user-interactions in equation (15), a factorization model for normal transition graphs is obtained:\u00e2\nl,i := v I,L i , v L,I l (17)\nAlso the parameter estimation method in section 5 can be used for optimizing the factorization matrices.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Summary of FPMC", "text": "Bringing together the personalized set MC (eq. 9) with the factorized transition cube (eq. 15) results in the factorized personalized Markov chain (FPMC):\np(i \u2208 B u t |B u t\u22121 ) = 1 |B u t\u22121 | X l\u2208B u t\u22121 p(i \u2208 B u t |l \u2208 B u t\u22121 ) (18)\nWe model p(i \u2208 B u t |l \u2208 B u t\u22121 ) with the factorization cub\u00ea A:p\n(i \u2208 B u t |B u t\u22121 ) = 1 |B u t\u22121 | X l\u2208B u t\u22121\u00e2 u,l,i = 1 |B u t\u22121 | X l\u2208B u t\u22121 ( v U,I u , v I,U i + v I,L i , v L,I l + v U,L u , v L,U l ) (19)\nAnd as the factorization (U, I) is independent of l, we can remove it from the sum:\np(i \u2208 B u t |B u t\u22121 ) = v U,I u , v I,U i + 1 |B u t\u22121 | X l\u2208B u t\u22121 \" v I,L i , v L,I l + v U,L u , v L,U l \"(20)\nIn the next section, we apply this model to the task of item recommendation. We will show that in this case, the model can be simplified even more because the interaction between U and L vanishes.\nBesides better generalization of factorization models compared to a full parametrized transition cube, a further advantage is that less parameters are needed. Instead of |U | \u2022 |I| 2 parameters in a full parametrized cube or |I| 2 in a full parametrized matrix, the factorization model only needs 2 \u2022 kI,L \u2022 |I| parameters for the non-personalized model and 2 \u2022 kI,L \u2022 |I| + kU,I \u2022 (|U | + |I|) parameters for the personalized model. This is especially important for applications with a high number of items where a full parametrization with |I| 2 parameters might not be feasible.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "ITEM RECOMMENDATION FROM SE-QUENTIAL SET DATA WITH FPMC", "text": "So far, a factorization model for personalized Markov chains has been introduced. In the following, we will apply this model to the task of item recommendation. That means, the model parameters should be optimized for ranking. First, we derive S-BPR which is a general optimization criterion for item recommendation from sequential set data. This optimization criterion is not limited to our FPMC model and can be applied also to other models like kNN or standard MF. Secondly, we apply S-BPR to FPMC and show how the model can be simplified in the case of item recommendation using S-BPR. Afterwards we present a stochastic gradient descent learning algorithm based on bootstrap sampling for optimizing the model parameters with S-BPR.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Optimization Criterion S-BPR", "text": "As described in section (3), the goal of item recommendation from sequential basket data is to derive a ranking >u,t over the items. To model the ranking, we assume there is an estimatorx : U \u00d7 T \u00d7 I \u2192 R -e.g. the buying probability of the personalized Markov Chain -which is used to define the ranking: i >u,t j :\u21d4xu,t,i > Rxu,t,j\nAs > R is a total order on (a closed subset of) the real numbers R, also >u,t will be a total order. Thusxu,t,i is able to generate a personalized ranking 3 for a specific time t on the items I.\nNext, we derive the sequential BPR (S-BPR) optimization criterion analogously to the general BPR approach [7]. The best ranking >u,t\u2282 I 2 for user u at time t can be formalized as:\np(\u0398| >u,t) \u221d p(>u,t |\u0398) p(\u0398)\nwhere \u0398 are the model parameters -in our case the param-\neters are \u0398 = {V U,I , V I,U , V L,I , V I,L , V U,L , V L,U }.\nAssuming independence of baskets and users, this leads to the maximum a posterior (MAP) estimator of the model parameters:\nargmax \u0398 Y u\u2208U Y Bt\u2208B u p(>u,t |\u0398) p(\u0398)(22)\nExpanding >u,t for all item-pairs (i, j) \u2208 I 2 and using the same assumptions as in [7], the probability of p(>u,t |\u0398) can be rewritten as:\nY u\u2208U Y Bt\u2208B u Y i\u2208Bt Y j \u2208Bt p(i >u,t j|\u0398)(23)\nNext we use the model definition of eq. (21) to express p(i >u,t j|\u0398):\np(i >u,t j|\u0398) = p(xu,t,i > Rxu,t,j | \u0398) (24) = p(xu,t,i \u2212xu,t,j > R 0 | \u0398) (25)\nThe \u0398 can be skipped as they are the model parameters for x -i.e.x =x(\u0398). And we define p(z > 0) := \u03c3(z) = 1 1+e \u2212z using the logistic function \u03c3:\np(i >u,t j|\u0398) = \u03c3(xu,t,i \u2212xu,t,j)(26)\nFurthermore, we assume Gaussian priors on the model parameters: \u03b8 \u223c N (0, 1 \u03bb \u03b8 ).\nIn total this leads to the MAP-estimator for sequential BPR:\nargmax \u0398 ln p(>u,t |\u0398) p(\u0398) = argmax \u0398 ln Y u\u2208U Y Bt\u2208B u Y i\u2208Bt Y j \u2208Bt \u03c3(xu,t,i \u2212xu,t,j)p(\u0398) = argmax \u0398 X u\u2208U X Bt\u2208B u X i\u2208Bt X j \u2208Bt ln \u03c3(xu,t,i \u2212xu,t,j) \u2212 \u03bb\u0398||\u0398|| 2 F (27)\nwhere \u03bb\u0398 is the regularization constant corresponding to \u03c3\u0398.", "publication_ref": ["b6", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Item Recommendation with FPMC", "text": "For item recommendation with FPMC, we expressx by the FPMC model and apply S-BPR. We will show that one of the pairwise effects of FPMC vanishes which leads to a more compact model.\nFirst, we use FPMC to expressx:\nx \u2032 u,t,i :=p(i \u2208 B u t |B u t\u22121 ) = v U,I u , v I,U i + 1 |B u t\u22121 | X l\u2208B u t\u22121 \" v I,L i , v L,I l + v U,L u , v L,U l \"\nLemma 1 (Invariance of (U,L) decomposition). For ranking of items and optimization with S-BPR, the FPMC model is invariant to the (U,L) decomposition, i.e.x \u2032 is invariant tox with:\nxu,t,i := v U,I u , v I,U i + 1 |B u t\u22121 | X l\u2208B u t\u22121 v I,L i , v L,I l (28)\nProof. Let > \u2032 be the ranking generated byx \u2032 and > the ranking ofx according to eq. (21). Two things have to be shown: (1) both models (x \u2032 andx) lead to the same ranking and (2) learning both models with S-BPR leads to the same parameters \u0398. Both proofs rely on the fact that: \u2200u, t, i, j :x \u2032 u,t,i \u2212x \u2032 u,t,j =xu,t,i \u2212xu,t,j\nThis holds because the additional term P\nl\u2208B u t\u22121 v U,L u , v L,U l inx \u2032 u,t,\n\u2022 is independent of i and j given u and t and thus vanishes on subtraction. Now it is easy to show the equivalence of the rankings for all u, t, i, j:\n(i > \u2032 u,t j) \u21d4 (x \u2032 u,t,i > Rx \u2032 u,t,j ) \u21d4 (x \u2032 u,t,i \u2212x \u2032 u,t,j > R 0) eq.29 \u21d4 (xu,t,i \u2212xu,t,j > R 0) \u21d4 (xu,t,i > Rxu,t,j \u21d4 i >u,t j) (2)\nThe equivalence of model parameters under S-BPR optimization (eq. ( 27)) follows directly from eq. (29).\nThus for item recommendation with FPMC the simpler model x from eq. (28) should be used.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Expressiveness", "text": "Next, we will show the analogies of the simplified FPMC model to standard matrix factorization (MF) and a factorized Markov chain (FMC). First, we will recollect the definitions of MF and FMC. In our notation, the standard Matrix factorization model for item recommendation [2,6,7] is:\nx MF u,t,i = v U,I u , v I,U i (30)\nwherex is independent of the sequential behaviour, i.e. independent of t.\nFactorizing an unpersonalized Markov chain using equation ( 4) and (17) leads to:\nx FMC u,t,i := 1 |Bt\u22121| X l\u2208B t\u22121 v I,L i , v L,I l (31)\nThus FPMC (eq. (28)) is a linear combination of both models:\nx FPMC u,t,i =x MF u,t,i +x FMC u,t,i(32)\nThis means FPMC can generalizes both models: By setting the factorization dimensionality of (U,I) to zero (kU,I = 0) a pure FMC is obtained and analogously setting kI,L = 0 leads to a pure MF model. It is important to note, that even though the model equation for FPMC in the case of item recommendation can be expressed by a combination of a MF and a FMC model, it is different from a simple ensemble of a single MF with a single FMC model because in our case the model parameters are learned jointly. Thus the learned model parameters jointly represent the personalized Markov chain instead of just pure user-item interactions and a global MC. This gets more obvious in the general case of FPMC where the model equation cannot be expressed by a linear combination of MC and FMC. Examples are (1) optimizing for another objective criterion (e.g. least-square) where the (U, L) decomposition cannot be dropped because here the invariance to the objective (Lemma 1) does not hold like in S-BPR. And (2) using another factorization model for A in FPMC than pairwise interaction (e.g. PARAFAC or TD) also leads to a different model equation even for item recommendation with S-BPR.", "publication_ref": ["b1", "b5", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Learning Algorithm", "text": "Next, we adapt the BPR-learning algorithm to S-BPR and apply it to FPMC. As FPMC subsumes MF and FMC, both of these models can also be optimized for S-BPR with the provided algorithm.\nTrying to optimize S-BPR directly is time consuming, because the number of (u, t, i, j) quadruples is huge, i.e. O(|S| |I|) where S := {(u, t, i)|u \u2208 U, B u t \u2208 B u , i \u2208 B u t }. Thus standard gradient descent and also basket-wise stochastic gradient descent methods will converge very slowly (see [7] for more details) and are not applicable for problems of reasonable size. Instead, we follow [7,8] and draw the quadruples independently by bootstrapping and perform stochastic gradient descent on these bootstrap samples. This learning method has been shown to be efficient for two related problem classes: standard item recommendation [7] and tag recommendation [8].\nThe complete algorithm is shown in figure 5. In each iteration a quadruple (u, t, i, j) is drawn consisting of an item i in the basket B u t of user u at time t and an item j that is not in this basket. Then gradient descent on S-BPR using this quadruple is performed. The gradients of S-BPR with respect to a model parameter \u03b8 and a given (u, t, i, j) are:\n\u2202 \u2202\u03b8`l n \u03c3(xu,t,i \u2212xu,t,j) \u2212 \u03bb \u03b8 \u03b8 2= (1 \u2212 \u03c3(xu,t,i \u2212xu,t,j)) \u2202 \u2202\u03b8 (xu,t,i \u2212xu,t,j) \u2212 2 \u03bb \u03b8 \u03b8 1: procedure LearnSBPR-FPMC(S) 2: draw V U,I , V I,U , V I,L , V L,I from N (0, \u03c3 2 ) 3: repeat 4:\ndraw (u, t, i) uniformly from S 5: draw j uniformly from (I \\ B u t ) 6:\n\u03b4 \u2190 (1 \u2212 \u03c3(xu,t,i \u2212xu,t,j)) 7:\nfor f \u2208 {1, . . . , kU,I } do\n8: v U,I u,f \u2190 v U,I u,f + \u03b1 \" \u03b4 (v I,U i,f \u2212 v I,U j,f ) \u2212 \u03bbU,I v U,I u,f \" 9: v I,U i,f \u2190 v I,U i,f + \u03b1 \" \u03b4 v U,I u,f \u2212 \u03bbI,U v I,U i,f \" 10: v I,U j,f \u2190 v I,U j,f + \u03b1 \" \u2212\u03b4 v U,I u,f \u2212 \u03bbI,U v I,U j,f\"\n11: end for 12:\n\u03b7 \u2190 1\n|B u t\u22121 | P l\u2208B u t\u22121 v L,I l,f\n13: for f \u2208 {1, . . . , kI,L} do\n14: v I,L i,f \u2190 v I,L i,f + \u03b1 \" \u03b4 \u03b7 \u2212 \u03bbI,L v I,L i,f \" 15: v I,L j,f \u2190 v I,L j,f + \u03b1 \" \u2212\u03b4 \u03b7 \u2212 \u03bbI,L v I,L j,f \" 16: for l \u2208 B u t\u22121 do 17: v L,I l,f \u2190 v L,I l,f + \u03b1 \" \u03b4 v I,L i,f \u2212v I,L j,f |B u t\u22121 |\n\u2212 \u03bbL,I v L,I l,f \u00ab 18: end for 19:\nend for 20:\nuntil convergence 21: return V U,I , V I,U , V I,L , V L,I 22: end procedure \n\u2202 \u2202v I,U i,f (xu,t,i \u2212xu,t,j) = v U,I u,f \u2202 \u2202v I,U j,f (xu,t,i \u2212xu,t,j) = \u2212v U,I u,f \u2202 \u2202v L,I l,f (xu,t,i \u2212xu,t,j) = 1 |B u t\u22121 | (v I,L i,f \u2212 v I,L j,f ) \u2202 \u2202v I,L i,f (xu,t,i \u2212xu,t,j) = 1 |B u t\u22121 | X l\u2208B u t\u22121 v L,I l,f \u2202 \u2202v I,L j,f (xu,t,i \u2212xu,t,j) = \u2212 1 |B u t\u22121 | X l\u2208B u t\u22121 v L,I l,f\nThe complexity of the algorithm is O(#it (kU,I + kI,L |B|)) where |B| the average basket size in B and #it is the number of iterations.", "publication_ref": ["b6", "b6", "b7", "b6", "b7"], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "EVALUATION", "text": "We empirically compare the recommender quality of our proposed factorized MC methods (factorized personalized Markov chain FPMC and factorized Markov chain FMC) to non-factorized Markov chain ('MC dense'), matrix factorization (MF) and the most-popular baseline (MP) -i.e. ranking all items by how often they have been bought in the past. Note that this comparison includes the strong baseline method BPR-MF [7]. As MF (kI,L = 0) and FMC (kU,I = 0) are a special case of FPMC, we use the FPMC learning algorithm for all three methods.", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "Dataset", "text": "We evaluate our recommender on anonymized purchase data of an online drug store 4 . The dataset we used is a 10core subset, i.e. every user bought in total at least 10 items ( P B\u2208B u |B|) > 10 and vice versa each item was bought by at least 10 users. The statistics of the dataset can be found in table 1. We also created a dense subset of the 10-core dataset to study the effect of sparsity on the methods.", "publication_ref": ["b3"], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "Evaluation Metrics", "text": "We evaluated by splitting the dataset S into two non overlapping sets: a training set 5 Strain and a testing set Stest. This split is done by putting the last basket for each user into Stest and the remaining ones into Strain. The recommenders were trained on Strain and then the performance on Stest is measured. We removed those users from the evaluation that have bought less then 10 different items in the past (i.e. Strain). Secondly, for each user we removed all items from the test baskets (and the corresponding predictions) that this user has already bought in the past -this is because we want to recommend to the user items that are new/ unknown to him. Note that this makes the prediction task much harder and explains the low f-measure of all methods in figure 6. Otherwise just rerecommending already bought items would be a simple but very successful strategy for non-durable products in drug stores like toothbrushes or cleaner. However, this is not the task of recommender systems because they should help the user to discover new things.\nThe quality is measured for each user u on the basket Bu in the test dataset. Therefore we rank all items with our methods and letru : I \u2194 {1, . . . , |I|} be the (bijective) mapping from an item i to its (predicted) rank. We use the following quality measures to evaluate the estimated ranking against the actual bought items:\n\u2022 Half-life-utility (HLU) aka 'Breese score' [1]: HLU(B,ru) := 100\nP |I| r=1 \u03b4(r \u22121 u (r) \u2208 B) 2 \u2212 r\u22121 \u03b1\u22121 P |B| r=1 2 \u2212 r\u22121 \u03b1\u22121\nWhere we set the half-life parameter \u03b1 to 5. We report the average HLU over all test baskets.\n\u2022 Precision and recall of the top-N list:\nT op(ru, N ) := {r \u22121 u (1), . . . ,r \u22121 u (N )} Prec(B,ru, N ) := |Top(ru, N ) \u2229 B| N Rec(B,ru, N ) := |Top(ru, N ) \u2229 B| |B|\nWe report the f-measure (harmonic mean) over the average precision and average recall over all test baskets using top-5 list.  ", "publication_ref": ["b4", "b0"], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "Results", "text": "In figure 6 you can see the quality on the sparse and dense online-shopping dataset. For the factorization methods we run each method with kU,I = kI,L \u2208 {8, 16, 32, 64, 128} factorization dimension. The x-axis of the diagrams reflects this increasing dimensionality. As expected all methods outperform the most-popular baseline clearly on both datasets and all quality measures. Secondly, with reasonable factorization dimensions (e.g. 32) all the factorization methods outperform the standard MC method. And in total, the factorized personalized MC (FPMC) outperforms all other methods.", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "MC vs. FMC", "text": "First, we want to discuss the advantage of factorization over a dense transition model by comparing MC with nonpersonalized FMC. The results indicate that learning a factorized transition matrix leads to better estimates than usual counting schemes. Factorization has two advantages (1) it can densify a sparse transition matrix and (2) it prevents overfitting of the estimates by using a low-rank approximation. The sparseness of the transition matrix estimated by counting schemes can be seen in table 2. In the dense setting also the transition matrix is filled in 88% whereas on the sparse dataset this drops to 12%. Comparing the quality on the sparse and dense setting in figure 6, one can see that the advantages of FMC over MC are much higher in the sparse setting than in the dense one. But even in the dense setting where also MC's transition matrix is almost completely filled, FMC outperforms MC because the factorization prevents overfitting by using less parameters.", "publication_ref": [], "figure_ref": ["fig_6"], "table_ref": []}, {"heading": "MF vs. FMC vs. FPMC", "text": "Comparing the factorized Markov chain with the matrix factorization, one can see that in the dense setting MF seems to outperform MC whereas in the sparse one MC is superior. The reason could be that in the dense setting there is much more information per user, thus the MF method using all the users purchase information has advantages over the MC model that only relies on the last purchases. And the other way around, MC has advantages on the sparse dataset. FPMC that combines the advantages of both methods outperforms them on both datasets.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "CONCLUSION", "text": "In this paper, we have introduced a recommender method based on personalized Markov chains over sequential set data. Instead of using the same transition matrix for all users, this method uses an individual transition matrix for each user which in total results in a transition cube. As direct estimation (e.g. by Maximum Likelihood) over a full parametrized transition cube leads to very poor estimates, we introduce a factorization model that gives a low-rank approximation to the transition cube. The advantages of this approach is that each transition is influenced by transitions of similar users, similar items and similar transitions. Thus the quality of the final transition graph is much higher than that of a full parametrized model. Secondly, we apply factorized personalized Markov chains (FPMC) to the task of item recommendation with sequential set data by extending the BPR framework [7]. Additionally, we show that FPMC subsumes the popular matrix factorization model and a nonpersonalized factorized Markov chain. Due to the expressiveness of FPMC it combines the advantages of both the state-of-the-art global personalized approach (MF) and the sequential MC method. Empirically, we show on real-world data that FPMC outperforms MF, FMC and normal MC both on sparse and dense data.  ", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "We would like to thank Artus Krohn-Grimberghe for preparing the data set. Steffen Rendle is supported by a research fellowship of the Japan Society for the Promotion of Science (JSPS). This work is partially co-funded through the European Commission FP7 project MyMedia (www.mymediaproject.org) under the grant agreement no.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "215006.", "text": "This work is co-funded by the European Regional Development Fund project LEFOS (www.ismll.uni-hildesheim.de) under the grant agreement no. 62700.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Empirical analysis of predictive algorithms for collaborative filtering", "journal": "Morgan Kaufmann", "year": "1998", "authors": "J S Breese; D Heckerman; C Kadie"}, {"ref_id": "b1", "title": "Collaborative filtering for implicit feedback datasets", "journal": "", "year": "2008", "authors": "Y Hu; Y Koren; C Volinsky"}, {"ref_id": "b2", "title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model", "journal": "ACM", "year": "2008", "authors": "Y Koren"}, {"ref_id": "b3", "title": "Collaborative filtering with temporal dynamics", "journal": "ACM", "year": "2009", "authors": "Y Koren"}, {"ref_id": "b4", "title": "Using sequential and non-sequential patterns in predictive web usage mining tasks", "journal": "IEEE Computer Society", "year": "2002", "authors": "B Mobasher; H Dai; T Luo; M Nakagawa"}, {"ref_id": "b5", "title": "Mind the gaps: weighting the unknown in large-scale one-class collaborative filtering", "journal": "ACM", "year": "2009", "authors": "R Pan; M Scholz"}, {"ref_id": "b6", "title": "BPR: Bayesian personalized ranking from implicit feedback", "journal": "", "year": "2009", "authors": "S Rendle; C Freudenthaler; Z Gantner; L Schmidt-Thieme"}, {"ref_id": "b7", "title": "Pairwise interaction tensor factorization for personalized tag recommendation", "journal": "ACM", "year": "2010", "authors": "S Rendle; L Schmidt-Thieme"}, {"ref_id": "b8", "title": "An mdp-based recommender system", "journal": "Journal of Machine Learning Research", "year": "2005", "authors": "G Shani; D Heckerman; R I Brafman"}, {"ref_id": "b9", "title": "Using temporal data for making recommendations", "journal": "Morgan Kaufmann Publishers Inc", "year": "2001", "authors": "A Zimdars; D M Chickering; C Meek"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Sequential basket data with four users and five items {a, b, c, d, e}. The task is to recommend items at time t given a basket history Bt\u22121, Bt\u22122, . . ..", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "p(a \u2208 Bt|{c, e}) = 0.5(0.3 + 0.0) = 0.15 p(b \u2208 Bt|{c, e}) = 0.5(0.7 + 0.0) = 0.35 p(c \u2208 Bt|{c, e}) = 0.5(0.3 + 0.0) = 0.15 p(d \u2208 Bt|{c, e}) = 0.5(0.0 + 0.0) = 0.00 p(e \u2208 Bt|{c, e}) = 0.5(0.3 + 1.0) = 0.65", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Personalized Markov chains: For each user an individual transition matrix is given. The transition matrices contain the MLE estimates for the probability p(i \u2208 B u t |l \u2208 B u t\u22121 ). Entries with ? are missing values as there is no data to estimate the probabilities. Obviously, estimating the personalized transition matrices directly results in very poor transitions as each estimate is not reliable. This problem will be solved later by factorizing the transitions.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 4 :4Figure 4: Personalized transition cube: Stacking all transition matrices of the individual users leads to a transition cube. Instead of a fully parametrized cube which is very sparse, a factored cube is used to generate better transition estimates.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 5 :5Figure 5: Optimizing FPMC for S-BPR with learning rate \u03b1 and regularization parameters \u03bbU,I , \u03bbI,U , \u03bbI,L, \u03bbL,I .", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 6 :6Figure 6: Comparison of factorized personalized Markov chains (FPMC) to a factorized Markov chain (FMC), matrix factorization (MF) [7], a standard dense Markov chain (MC dense) learned with Maximum Likelihood and the baseline 'most-popular'. The factorization dimensionality is increased from 8 to 128.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Characteristics of the datasets in our experiments in terms of number of users, items, baskets and triples (u, i, t) where t is the sequential time of the basket. The dense dataset is a subset of the sparse one containing the 10,000 users with most purchases and the 1000 most purchased items. dataset users |U | items |I| baskets avg. basket size avg. baskets per user", "figure_data": "triples"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "Properties of the MC transition matrix estimated by the counting scheme. For the sparse dataset, only 12% of the entries of the transition matrix are non-zero and non-missing. For the dense subset, 88% are filled.We report the average AUC over all test baskets.The runtime of model training linearly depends on the number of features. With our implementation, training of the largest models (k = 128) took about 4 hours for MF, 31 hours for FMC and 34 hours for FPMC on the larger (sparse) dataset.", "figure_data": "datasettotalmissing valuesnon-zerozeroDrug store 10-core (sparse) 51,552,400 (100%) 1,041,100 (2.0%) 6,234,371 (12.1 %) 44,276,929 (85.9%)Drug store (dense)1,004.004 (100%)0 (0.0%)889,419 (88.6 %)114,585 (11.4%)\u2022 Area under the ROC curve:AUC(B,ru) :=1 |B| \u2022 |I \\ B|i\u2208B Xj\u2208I\\B X\u03b4(ru(i) <ru(j))"}], "formulas": [{"formula_id": "formula_0", "formula_text": "B u := (B u 1 , . . . B u tu\u22121 ) with B u t \u2286 I. The purchase history of all users is B := {B u 1 , . . . B u |U | }.", "formula_coordinates": [3.0, 53.76, 296.75, 239.11, 20.73]}, {"formula_id": "formula_1", "formula_text": "p(Xt = xt|Xt\u22121 = xt\u22121, . . . , Xt\u2212m = xt\u2212m)(1)", "formula_coordinates": [3.0, 86.52, 683.28, 206.4, 8.97]}, {"formula_id": "formula_2", "formula_text": "p(Bt|Bt\u22121)(2)", "formula_coordinates": [3.0, 414.12, 168.12, 141.83, 8.97]}, {"formula_id": "formula_3", "formula_text": "a l,i := p(i \u2208 Bt|l \u2208 Bt\u22121)(3)", "formula_coordinates": [3.0, 386.04, 326.52, 169.92, 9.02]}, {"formula_id": "formula_4", "formula_text": "p(i \u2208 Bt|Bt\u22121) := 1 |Bt\u22121| X l\u2208B t\u22121 p(i \u2208 Bt|l \u2208 Bt\u22121) (4)", "formula_coordinates": [3.0, 329.52, 508.68, 226.44, 25.39]}, {"formula_id": "formula_5", "formula_text": "p(Bt|Bt\u22121) \u221d Y i\u2208Bt p(i|Bt\u22121)(5)", "formula_coordinates": [3.0, 380.4, 556.15, 175.55, 20.71]}, {"formula_id": "formula_6", "formula_text": "a l,i =p(i \u2208 Bt|l \u2208 Bt\u22121) =p (i \u2208 Bt \u2227 l \u2208 Bt\u22121) p(l \u2208 Bt\u22121) = = |{(Bt, Bt\u22121) : i \u2208 Bt \u2227 l \u2208 Bt\u22121}| |{(Bt, Bt\u22121) : l \u2208 Bt\u22121}|(6)", "formula_coordinates": [3.0, 334.8, 671.64, 221.16, 45.69]}, {"formula_id": "formula_7", "formula_text": "p(B u t |B u t\u22121 )(7)", "formula_coordinates": [4.0, 150.12, 491.51, 142.79, 11.31]}, {"formula_id": "formula_8", "formula_text": "a u,l,i := p(i \u2208 B u t |l \u2208 B u t\u22121 )(8)", "formula_coordinates": [4.0, 118.68, 534.59, 174.24, 11.31]}, {"formula_id": "formula_9", "formula_text": "p(i \u2208 B u t |B u t\u22121 ) := 1 |B u t\u22121 | X l\u2208B u t\u22121 p(i \u2208 B u t |l \u2208 B u t\u22121 ) (9)", "formula_coordinates": [4.0, 64.44, 575.88, 228.48, 26.59]}, {"formula_id": "formula_10", "formula_text": "a u,l,i =p(i \u2208 B u t |l \u2208 B u t\u22121 ) =p (i \u2208 B u t \u2227 l \u2208 B u t\u22121 ) p(l \u2208 B u t\u22121 ) = |{(B u t , B u t\u22121 ) : i \u2208 B u t \u2227 l \u2208 B u t\u22121 }| |{(B u t , B u t\u22121 ) : l \u2208 B u t\u22121 }|(10)", "formula_coordinates": [4.0, 71.4, 644.63, 254.47, 49.47]}, {"formula_id": "formula_11", "formula_text": "(i \u2208 B u t |l \u2208 B u t\u22121 )", "formula_coordinates": [5.0, 320.97, 261.59, 72.42, 10.83]}, {"formula_id": "formula_12", "formula_text": "A := C \u00d7U V U \u00d7L V L \u00d7I V I (11", "formula_coordinates": [5.0, 115.56, 587.99, 173.28, 10.77]}, {"formula_id": "formula_13", "formula_text": ")", "formula_coordinates": [5.0, 288.84, 589.8, 4.08, 8.97]}, {"formula_id": "formula_14", "formula_text": "C \u2208 R k U ,k L ,k I , V U \u2208 R |U |\u00d7k U , (12", "formula_coordinates": [5.0, 109.2, 665.48, 179.64, 11.05]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [5.0, 288.84, 667.56, 4.08, 8.97]}, {"formula_id": "formula_16", "formula_text": "V L \u2208 R |I|\u00d7k L , V I \u2208 R |I|\u00d7k I (13", "formula_coordinates": [5.0, 117.84, 681.44, 171.0, 11.05]}, {"formula_id": "formula_17", "formula_text": ")", "formula_coordinates": [5.0, 288.84, 683.52, 4.08, 8.97]}, {"formula_id": "formula_18", "formula_text": "c fu,f i ,f j = ( 1, if fu = fi = fj 0, else(14)", "formula_coordinates": [5.0, 372.84, 361.03, 183.0, 24.49]}, {"formula_id": "formula_19", "formula_text": "a u,l,i := v U,I u , v I,U i + v I,L i , v L,I l + v U,L u , v L,U l (15)", "formula_coordinates": [5.0, 332.04, 431.63, 223.8, 12.27]}, {"formula_id": "formula_20", "formula_text": "a u,l,i := k U,I X f =1 v U,I u,f v I,U i,f + k I,L X f =1 v I,L i,f v L,I l,f + k U,L X f =1 v U,L u,f v L,U l,f(16)", "formula_coordinates": [5.0, 326.76, 470.75, 229.08, 40.29]}, {"formula_id": "formula_21", "formula_text": "l,i := v I,L i , v L,I l (17)", "formula_coordinates": [6.0, 142.44, 195.71, 150.48, 12.27]}, {"formula_id": "formula_22", "formula_text": "p(i \u2208 B u t |B u t\u22121 ) = 1 |B u t\u22121 | X l\u2208B u t\u22121 p(i \u2208 B u t |l \u2208 B u t\u22121 ) (18)", "formula_coordinates": [6.0, 63.48, 289.44, 229.44, 26.59]}, {"formula_id": "formula_23", "formula_text": "(i \u2208 B u t |B u t\u22121 ) = 1 |B u t\u22121 | X l\u2208B u t\u22121\u00e2 u,l,i = 1 |B u t\u22121 | X l\u2208B u t\u22121 ( v U,I u , v I,U i + v I,L i , v L,I l + v U,L u , v L,U l ) (19)", "formula_coordinates": [6.0, 68.4, 350.04, 224.52, 73.94]}, {"formula_id": "formula_24", "formula_text": "p(i \u2208 B u t |B u t\u22121 ) = v U,I u , v I,U i + 1 |B u t\u22121 | X l\u2208B u t\u22121 \" v I,L i , v L,I l + v U,L u , v L,U l \"(20)", "formula_coordinates": [6.0, 63.72, 456.59, 229.2, 41.23]}, {"formula_id": "formula_26", "formula_text": "p(\u0398| >u,t) \u221d p(>u,t |\u0398) p(\u0398)", "formula_coordinates": [6.0, 378.72, 368.04, 115.43, 8.97]}, {"formula_id": "formula_27", "formula_text": "eters are \u0398 = {V U,I , V I,U , V L,I , V I,L , V U,L , V L,U }.", "formula_coordinates": [6.0, 316.8, 396.23, 206.56, 10.29]}, {"formula_id": "formula_28", "formula_text": "argmax \u0398 Y u\u2208U Y Bt\u2208B u p(>u,t |\u0398) p(\u0398)(22)", "formula_coordinates": [6.0, 368.88, 447.55, 186.96, 20.59]}, {"formula_id": "formula_29", "formula_text": "Y u\u2208U Y Bt\u2208B u Y i\u2208Bt Y j \u2208Bt p(i >u,t j|\u0398)(23)", "formula_coordinates": [6.0, 371.52, 517.27, 184.32, 20.99]}, {"formula_id": "formula_30", "formula_text": "p(i >u,t j|\u0398) = p(xu,t,i > Rxu,t,j | \u0398) (24) = p(xu,t,i \u2212xu,t,j > R 0 | \u0398) (25)", "formula_coordinates": [6.0, 355.2, 578.04, 200.64, 22.74]}, {"formula_id": "formula_31", "formula_text": "p(i >u,t j|\u0398) = \u03c3(xu,t,i \u2212xu,t,j)(26)", "formula_coordinates": [6.0, 372.0, 650.64, 183.84, 8.97]}, {"formula_id": "formula_32", "formula_text": "argmax \u0398 ln p(>u,t |\u0398) p(\u0398) = argmax \u0398 ln Y u\u2208U Y Bt\u2208B u Y i\u2208Bt Y j \u2208Bt \u03c3(xu,t,i \u2212xu,t,j)p(\u0398) = argmax \u0398 X u\u2208U X Bt\u2208B u X i\u2208Bt X j \u2208Bt ln \u03c3(xu,t,i \u2212xu,t,j) \u2212 \u03bb\u0398||\u0398|| 2 F (27)", "formula_coordinates": [7.0, 53.76, 84.0, 239.16, 77.97]}, {"formula_id": "formula_33", "formula_text": "x \u2032 u,t,i :=p(i \u2208 B u t |B u t\u22121 ) = v U,I u , v I,U i + 1 |B u t\u22121 | X l\u2208B u t\u22121 \" v I,L i , v L,I l + v U,L u , v L,U l \"", "formula_coordinates": [7.0, 56.4, 260.12, 229.91, 41.62]}, {"formula_id": "formula_34", "formula_text": "xu,t,i := v U,I u , v I,U i + 1 |B u t\u22121 | X l\u2208B u t\u22121 v I,L i , v L,I l (28)", "formula_coordinates": [7.0, 70.92, 354.96, 222.0, 26.59]}, {"formula_id": "formula_36", "formula_text": "l\u2208B u t\u22121 v U,L u , v L,U l inx \u2032 u,t,", "formula_coordinates": [7.0, 53.76, 464.51, 234.45, 25.47]}, {"formula_id": "formula_37", "formula_text": "(i > \u2032 u,t j) \u21d4 (x \u2032 u,t,i > Rx \u2032 u,t,j ) \u21d4 (x \u2032 u,t,i \u2212x \u2032 u,t,j > R 0) eq.29 \u21d4 (xu,t,i \u2212xu,t,j > R 0) \u21d4 (xu,t,i > Rxu,t,j \u21d4 i >u,t j) (2)", "formula_coordinates": [7.0, 53.76, 515.84, 233.99, 45.0]}, {"formula_id": "formula_38", "formula_text": "x MF u,t,i = v U,I u , v I,U i (30)", "formula_coordinates": [7.0, 134.88, 681.83, 158.04, 12.03]}, {"formula_id": "formula_39", "formula_text": "x FMC u,t,i := 1 |Bt\u22121| X l\u2208B t\u22121 v I,L i , v L,I l (31)", "formula_coordinates": [7.0, 369.0, 89.52, 186.84, 25.39]}, {"formula_id": "formula_40", "formula_text": "x FPMC u,t,i =x MF u,t,i +x FMC u,t,i(32)", "formula_coordinates": [7.0, 379.45, 140.04, 176.39, 32.9]}, {"formula_id": "formula_41", "formula_text": "\u2202 \u2202\u03b8`l n \u03c3(xu,t,i \u2212xu,t,j) \u2212 \u03bb \u03b8 \u03b8 2= (1 \u2212 \u03c3(xu,t,i \u2212xu,t,j)) \u2202 \u2202\u03b8 (xu,t,i \u2212xu,t,j) \u2212 2 \u03bb \u03b8 \u03b8 1: procedure LearnSBPR-FPMC(S) 2: draw V U,I , V I,U , V I,L , V L,I from N (0, \u03c3 2 ) 3: repeat 4:", "formula_coordinates": [7.0, 343.31, 676.86, 238.72, 42.44]}, {"formula_id": "formula_42", "formula_text": "8: v U,I u,f \u2190 v U,I u,f + \u03b1 \" \u03b4 (v I,U i,f \u2212 v I,U j,f ) \u2212 \u03bbU,I v U,I u,f \" 9: v I,U i,f \u2190 v I,U i,f + \u03b1 \" \u03b4 v U,I u,f \u2212 \u03bbI,U v I,U i,f \" 10: v I,U j,f \u2190 v I,U j,f + \u03b1 \" \u2212\u03b4 v U,I u,f \u2212 \u03bbI,U v I,U j,f\"", "formula_coordinates": [8.0, 53.76, 126.43, 237.58, 48.43]}, {"formula_id": "formula_43", "formula_text": "|B u t\u22121 | P l\u2208B u t\u22121 v L,I l,f", "formula_coordinates": [8.0, 118.2, 185.99, 77.08, 14.95]}, {"formula_id": "formula_44", "formula_text": "14: v I,L i,f \u2190 v I,L i,f + \u03b1 \" \u03b4 \u03b7 \u2212 \u03bbI,L v I,L i,f \" 15: v I,L j,f \u2190 v I,L j,f + \u03b1 \" \u2212\u03b4 \u03b7 \u2212 \u03bbI,L v I,L j,f \" 16: for l \u2208 B u t\u22121 do 17: v L,I l,f \u2190 v L,I l,f + \u03b1 \" \u03b4 v I,L i,f \u2212v I,L j,f |B u t\u22121 |", "formula_coordinates": [8.0, 53.76, 211.75, 198.71, 63.59]}, {"formula_id": "formula_45", "formula_text": "\u2202 \u2202v I,U i,f (xu,t,i \u2212xu,t,j) = v U,I u,f \u2202 \u2202v I,U j,f (xu,t,i \u2212xu,t,j) = \u2212v U,I u,f \u2202 \u2202v L,I l,f (xu,t,i \u2212xu,t,j) = 1 |B u t\u22121 | (v I,L i,f \u2212 v I,L j,f ) \u2202 \u2202v I,L i,f (xu,t,i \u2212xu,t,j) = 1 |B u t\u22121 | X l\u2208B u t\u22121 v L,I l,f \u2202 \u2202v I,L j,f (xu,t,i \u2212xu,t,j) = \u2212 1 |B u t\u22121 | X l\u2208B u t\u22121 v L,I l,f", "formula_coordinates": [8.0, 86.88, 431.22, 173.75, 138.72]}, {"formula_id": "formula_46", "formula_text": "P |I| r=1 \u03b4(r \u22121 u (r) \u2208 B) 2 \u2212 r\u22121 \u03b1\u22121 P |B| r=1 2 \u2212 r\u22121 \u03b1\u22121", "formula_coordinates": [8.0, 431.88, 486.09, 107.31, 30.41]}, {"formula_id": "formula_47", "formula_text": "T op(ru, N ) := {r \u22121 u (1), . . . ,r \u22121 u (N )} Prec(B,ru, N ) := |Top(ru, N ) \u2229 B| N Rec(B,ru, N ) := |Top(ru, N ) \u2229 B| |B|", "formula_coordinates": [8.0, 368.28, 572.96, 158.57, 59.4]}], "doi": ""}