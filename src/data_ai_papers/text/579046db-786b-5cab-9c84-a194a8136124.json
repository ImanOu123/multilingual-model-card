{"title": "Scalable Influence Estimation in Continuous-Time Diffusion Networks", "authors": "Nan Du; Le Song; Manuel Gomez-Rodriguez; Hongyuan Zha", "pub_date": "", "abstract": "If a piece of information is released from a media site, can we predict whether it may spread to one million web pages, in a month ? This influence estimation problem is very challenging since both the time-sensitive nature of the task and the requirement of scalability need to be addressed simultaneously. In this paper, we propose a randomized algorithm for influence estimation in continuous-time diffusion networks. Our algorithm can estimate the influence of every node in a network with |V| nodes and |E| edges to an accuracy of using n = O(1/ 2 ) randomizations and up to logarithmic factors O(n|E|+n|V|) computations. When used as a subroutine in a greedy influence maximization approach, our proposed algorithm is guaranteed to find a set of C nodes with the influence of at least (1 \u2212 1/e) OPT \u22122C , where OPT is the optimal value. Experiments on both synthetic and real-world data show that the proposed algorithm can easily scale up to networks of millions of nodes while significantly improves over previous state-of-the-arts in terms of the accuracy of the estimated influence and the quality of the selected nodes in maximizing the influence.", "sections": [{"heading": "Introduction", "text": "Motivated by applications in viral marketing [1], researchers have been studying the influence maximization problem: find a set of nodes whose initial adoptions of certain idea or product can trigger, in a time window, the largest expected number of follow-ups. For this purpose, it is essential to accurately and efficiently estimate the number of follow-ups of an arbitrary set of source nodes within the given time window. This is a challenging problem for that we need first accurately model the timing information in cascade data and then design a scalable algorithm to deal with large real-world networks. Most previous work in the literature tackled the influence estimation and maximization problems for infinite time window [1,2,3,4,5,6]. However, in most cases, influence must be estimated or maximized up to a given time, i.e., a finite time window must be considered [7]. For example, a marketer would like to have her advertisement viewed by a million people in one month, rather than in one hundred years. Such time-sensitive requirement renders those algorithms which only consider static information, such as network topologies, inappropriate in this context.\nA sequence of recent work has argued that modeling cascade data and information diffusion using continuous-time diffusion networks can provide significantly more accurate models than discretetime models [8,9,10,11,12,13,14,15]. There is a twofold rationale behind this modeling choice. First, since follow-ups occur asynchronously, continuous variables seem more appropriate to represent them. Artificially discretizing the time axis into bins introduces additional tuning parameters, like the bin size, which are not easy to choose optimally. Second, discrete time models can only describe transmission times which obey an exponential density, and hence can be too restricted to capture the rich temporal dynamics in the data. Extensive experimental comparisons on both synthetic and real world data showed that continuous-time models yield significant improvement in settings such as recovering hidden diffusion network structures from cascade data [8,10] and predicting the timings of future events [9,14].\nHowever, estimating and maximizing influence based on continuous-time diffusion models also entail many challenges. First, the influence estimation problem in this setting is a difficult graphical model inference problem, i.e., computing the marginal density of continuous variables in loopy graphical models. The exact answer can be computed only for very special cases. For example, Gomez-Rodriguez et al. [7] have shown that the problem can be solved exactly when the transmission functions are exponential densities, by using continuous time Markov processes theory. However, the computational complexity of such approach, in general, scales exponentially with the size and density of the network. Moreover, extending the approach to deal with arbitrary transmission functions would require additional nontrivial approximations which would increase even more the computational complexity. Second, it is unclear how to scale up influence estimation and maximization algorithms based on continuous-time diffusion models to millions of nodes. Especially in the maximization case, even a naive sampling algorithm for approximate inference is not scalable: n sampling rounds need to be carried out for each node to estimate the influence, which results in an overall O(n|V||E|) algorithm. Thus, our goal is to design a scalable algorithm which can perform influence estimation and maximization in this regime of networks with millions of nodes.\nIn particular, we propose CONTINEST (Continous-Time Influence Estimation), a scalable randomized algorithm for influence estimation in a continuous-time diffusion network with heterogeneous edge transmission functions. The key idea of the algorithm is to view the problem from the perspective of graphical model inference, and reduces the problem to a neighborhood estimation problem in graphs. Our algorithm can estimate the influence of every node in a network with |V| nodes and |E| edges to an accuracy of using n = O(1/ 2 ) randomizations and up to logarithmic factors O(n|E| + n|V|) computations. When used as a subroutine in a greedy influence maximization algorithm, our proposed algorithm is guaranteed to find a set of nodes with an influence of at least (1 \u2212 1/e) OPT \u22122C , where OPT is the optimal value. Finally, we validate CONTINEST on both influence estimation and maximization problems over large synthetic and real world datasets. In terms of influence estimation, CONTINEST is much closer to the true influence and much faster than other state-of-the-art methods. With respect to the influence maximization, CONTINEST allows us to find a set of sources with greater influence than other state-of-the-art methods.", "publication_ref": ["b0", "b0", "b1", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b9", "b10", "b11", "b12", "b13", "b14", "b7", "b9", "b8", "b13", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Continuous-Time Diffusion Networks", "text": "First, we revisit the continuous-time generative model for cascade data in social networks introduced in [10]. The model associates each edge j \u2192 i with a transmission function, f ji (\u03c4 ji ), a density over time, in contrast to previous discrete-time models which associate each edge with a fixed infection probability [1]. Moreover, it also differs from discrete-time models in the sense that events in a cascade are not generated iteratively in rounds, but event timings are sampled directly from the transmission function in the continuous-time model. Continuous-Time Independent Cascade Model. Given a directed contact network, G = (V, E), we use a continuous-time independent cascade model for modeling a diffusion process [10]. The process begins with a set of infected source nodes, A, initially adopting certain contagion (idea, meme or product) at time zero. The contagion is transmitted from the sources along their out-going edges to their direct neighbors. Each transmission through an edge entails a random spreading time, \u03c4 , drawn from a density over time, f ji (\u03c4 ). We assume transmission times are independent and possibly distributed differently across edges. Then, the infected neighbors transmit the contagion to their respective neighbors, and the process continues. We assume that an infected node remains infected for the entire diffusion process. Thus, if a node i is infected by multiple neighbors, only the neighbor that first infects node i will be the true parent. As a result, although the contact network can be an arbitrary directed network, each cascade (a vector of event timing information from the spread of a contagion) induces a Directed Acyclic Graph (DAG).\nHeterogeneous Transmission Functions. Formally, the transmission function f ji (t i |t j ) for directed edge j \u2192 i is the conditional density of node i getting infected at time t i given that node j was infected at time t j . We assume it is shift invariant: f ji (t i |t j ) = f ji (\u03c4 ji ), where \u03c4 ji := t i \u2212 t j , and nonnegative: f ji (\u03c4 ji ) = 0 if \u03c4 ji < 0. Both parametric transmission functions, such as the exponential and Rayleigh function [10,16], and nonparametric function [8] can be used and estimated from cascade data (see Appendix A for more details).\nShortest-Path property. The independent cascade model has a useful property we will use later: given a sample of transmission times of all edges, the time t i taken to infect a node i is the length of the shortest path in G from the sources to node i, where the edge weights correspond to the associated transmission times.", "publication_ref": ["b9", "b0", "b9", "b9", "b15", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Graphical Model Perspectives for Continuous-Time Diffusion Networks", "text": "The continuous-time independent cascade model is essentially a directed graphical model for a set of dependent random variables, the infection times t i of the nodes, where the conditional independence structure is supported on the contact network G (see Appendix B for more details). More formally, the joint density of {t i } i\u2208V can be expressed as\np ({t i } i\u2208V ) = i\u2208V p (t i |{t j } j\u2208\u03c0i ) ,(1)\nwhere \u03c0 i denotes the set of parents of node i in a cascade-induced DAG, and p(t i |{t j } j\u2208\u03c0i ) is the conditional density of infection t i at node i given the infection times of its parents.\nInstead of directly modeling the infection times t i , we can focus on the set of mutually independent random transmission times \u03c4 ji = t i \u2212 t j . Interestingly, by switching from a node-centric view to an edge-centric view, we obtain a fully factorized joint density of the set of transmission times\np {\u03c4 ji } (j,i)\u2208E = (j,i)\u2208E f ji (\u03c4 ji ),(2)\nBased on the Shortest-Path property of the independent cascade model, each variable t i can be viewed as a transformation from the collection of variables {\u03c4 ji } (j,i)\u2208E .\nMore specifically, let Q i be the collection of directed paths in G from the source nodes to node i, where each path q \u2208 Q i contains a sequence of directed edges (j, l). Assuming all source nodes are infected at zero time, then we obtain variable t i via\nt i = g i {\u03c4 ji } (j,i)\u2208E := min q\u2208Qi (j,l)\u2208q \u03c4 jl ,(3)\nwhere the transformation g i (\u2022) is the value of the shortest-path minimization. As a special case, we can now compute the probability of node i infected before T using a set of independent variables:\nPr {t i \u2264 T } = Pr g i {\u03c4 ji } (j,i)\u2208E \u2264 T . (4\n)\nThe significance of the relation is that it allows us to transform a problem involving a sequence of dependent variables {t i } i\u2208V to one with independent variables {\u03c4 ji } (j,i)\u2208E . Furthermore, the two perspectives are connected via the shortest path algorithm in weighted directed graph, a standard well-studied operation in graph analysis.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Influence Estimation Problem in Continuous-Time Diffusion Networks", "text": "Intuitively, given a time window, the wider the spread of infection, the more influential the set of sources. We adopt the definition of influence as the average number of infected nodes given a set of source nodes and a time window, as in previous work [7]. More formally, consider a set of C source nodes A \u2286 V which gets infected at time zero, then, given a time window T , a node i is infected in the time window if t i \u2264 T . The expected number of infected nodes (or the influence) given the set of transmission functions {f ji } (j,i)\u2208E can be computed as\n\u03c3(A, T ) = E i\u2208V I {t i \u2264 T } = i\u2208V E [I {t i \u2264 T }] = i\u2208V Pr {t i \u2264 T } ,(5)\nwhere I {\u2022} is the indicator function and the expectation is taken over the the set of dependent variables {t i } i\u2208V .\nEssentially, the influence estimation problem in Eq. ( 5) is an inference problem for graphical models, where the probability of event t i \u2264 T given sources in A can be obtained by summing out the possible configuration of other variables {t j } j =i . That is\nPr{t i \u2264 T } = \u221e 0 \u2022 \u2022 \u2022 T ti=0 \u2022 \u2022 \u2022 \u221e 0 j\u2208V p t j |{t l } l\u2208\u03c0j j\u2208V dt j ,(6)\nwhich is, in general, a very challenging problem. First, the corresponding directed graphical models can contain nodes with high in-degree and high out-degree. For example, in Twitter, a user can follow dozens of other users, and another user can have hundreds of \"followees\". The tree-width corresponding to this directed graphical model can be very high, and we need to perform integration for functions involving many continuous variables. Second, the integral in general can not be eval-uated analytically for heterogeneous transmission functions, which means that we need to resort to numerical integration by discretizing the domain [0, \u221e). If we use N level of discretization for each variable, we would need to enumerate O(N |\u03c0i| ) entries, exponential in the number of parents.\nOnly in very special cases, can one derive the closed-form equation for computing Pr{t i \u2264 T } [7]. However, without further heuristic approximation, the computational complexity of the algorithm is exponential in the size and density of the network. The intrinsic complexity of the problem entails the utilization of approximation algorithms, such as mean field algorithms or message passing algorithms.We will design an efficient randomized (or sampling) algorithm in the next section.", "publication_ref": ["b6", "b6"], "figure_ref": [], "table_ref": []}, {"heading": "Efficient Influence Estimation in Continuous-Time Diffusion Networks", "text": "Our first key observation is that we can transform the influence estimation problem in Eq. ( 5) into a problem with independent variables. Using relation in Eq. ( 4), we have\n\u03c3(A, T ) = i\u2208V Pr g i {\u03c4 ji } (j,i)\u2208E \u2264 T = E i\u2208V I g i {\u03c4 ji } (j,i)\u2208E \u2264 T , (7)\nwhere the expectation is with respect to the set of independent variables {\u03c4 ji } (j,i)\u2208E . This equivalent formulation suggests a naive sampling (NS) algorithm for approximating \u03c3(A, T ): draw n samples of {\u03c4 ji } (j,i)\u2208E , run a shortest path algorithm for each sample, and finally average the results (see Appendix C for more details). However, this naive sampling approach has a computational complexity of O(nC|V||E| + nC|V| 2 log |V|) due to the repeated calling of the shortest path algorithm. This is quadratic to the network size, and hence not scalable to millions of nodes.\nOur second key observation is that for each sample {\u03c4 ji } (j,i)\u2208E , we are only interested in the neighborhood size of the source nodes, i.e., the summation i\u2208V I {\u2022} in Eq. ( 7), rather than in the individual shortest paths. Fortunately, the neighborhood size estimation problem has been studied in the theoretical computer science literature. Here, we adapt a very efficient randomized algorithm by Cohen [17] to our influence estimation problem. This randomized algorithm has a computational complexity of O(|E| log |V| + |V| log 2 |V|) and it estimates the neighborhood sizes for all possible single source node locations. Since it needs to run once for each sample of {\u03c4 ji } (j,i)\u2208E , we obtain an overall influence estimation algorithm with O(n|E| log |V| + n|V| log 2 |V|) computation, nearly linear in network size. Next we will revisit Cohen's algorithm for neighborhood estimation.", "publication_ref": ["b16"], "figure_ref": [], "table_ref": []}, {"heading": "Randomized Algorithm for Single-Source Neighborhood Size Estimation", "text": "Given a fixed set of edge transmission times {\u03c4 ji } (j,i)\u2208E and a source node s, infected at time 0, the neighborhood N (s, T ) of a source node s given a time window T is the set of nodes within distance T from s, i.e.,\nN (s, T ) = i g i {\u03c4 ji } (j,i)\u2208E \u2264 T, i \u2208 V .(8)\nInstead of estimating N (s, T ) directly, the algorithm will assign an exponentially distributed random label r i to each network node i. Then, it makes use of the fact that the minimum of a set of exponential random variables {r i } i\u2208N (s,T ) will also be a exponential random variable, but with its parameter equals to the number of variables. That is if each r i \u223c exp(\u2212r i ), then the smallest label within distance T from source s, r * := min i\u2208N (s,T ) r i , will distribute as r * \u223c exp {\u2212|N (s, T )|r * }. Suppose we randomize over the labeling m times, and obtain m such least labels, {r u * } m u=1 . Then the neighborhood size can be estimated as\n|N (s, T )| \u2248 m \u2212 1 m u=1 r u * .(9)\nwhich is shown to be an unbiased estimator of |N (s, T )| [17]. This is an interesting relation since it allows us to transform the counting problem in (8) to a problem of finding the minimum random label r * . The key question is whether we can compute the least label r * efficiently, given random labels {r i } i\u2208V and any source node s.\nCohen [17] designed a modified Dijkstra's algorithm (Algorithm 1) to construct a data structure r * (s), called least label list, for each node s to support such query. Essentially, the algorithm starts with the node i with the smallest label r i , and then it traverses in breadth-first search fashion along the reverse direction of the graph edges to find all reachable nodes. For each reachable node s, the distance d * between i and s, and r i are added to the end of r * (s). Then the algorithm moves to the node i with the second smallest label r i , and similarly find all reachable nodes. For each reachable node s, the algorithm will compare the current distance d * between i and s with the last recorded distance in r * (s). If the current distance is smaller, then the current d * and r i are added to the end of r * (s). Then the algorithm move to the node with the third smallest label and so on. The algorithm is summarized in Algorithm 1 in Appendix D.\nAlgorithm 1 returns a list r * (s) per node s \u2208 V, which contains information about distance to the smallest reachable labels from s. In particular, each list contains pairs of distance and random labels, (d, r), and these pairs are ordered as\n\u221e > d (1) > d (2) > . . . > d (|r * (s)|) = 0 (10) r (1) < r (2) < . . . < r (|r * (s)|) ,(11)\nwhere {\u2022} (l) denotes the l-th element in the list. (see Appendix D for an example). If we want to query the smallest reachable random label r * for a given source s and a time T , we only need to perform a binary search on the list for node s: r * = r (l) , where Then the expected time for querying r * is O(log log |V|) using binary search. Since we need to generate m set of random labels and run Algorithm 1 m times, the overall computational complexity for estimating the single-source neighborhood size for all s \u2208 V is O(m|E| log |V| + m|V| log 2 |V| + m|V| log log |V|). For large scale network, and when m min{|V|, |E|}, this randomized algorithm can be much more efficient than approaches based on directly calculating the shortest paths.\nd (l\u22121) > T \u2265 d (l) .(12", "publication_ref": ["b16", "b7", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "Constructing Estimation for Multiple-Source Neighborhood Size", "text": "When we have a set of sources, A, its neighborhood is the union of the neighborhoods of its constituent sources\nN (A, T ) = i\u2208A N (i, T ). (13\n)\nThis is true because each source independently infects its downstream nodes. Furthermore, to calculate the least label list r * corresponding to N (A, T ), we can simply reuse the least label list r * (i) of each individual source i \u2208 A. More formally, r * = min i\u2208A min j\u2208N (i,T ) r j ,\nwhere the inner minimization can be carried out by querying r * (i). Similarly, after we obtain m samples of r * , we can estimate |N (A, T )| using Eq. (9). Importantly, very little additional work is needed when we want to calculate r * for a set of sources A, and we can reuse work done for a single source. This is very different from a naive sampling approach where the sampling process needs to be done completely anew if we increase the source set. In contrast, using the randomized algorithm, only an additional constant-time minimization over |A| numbers is needed.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Overall Algorithm", "text": "So far, we have achieved efficient neighborhood size estimation of |N (A, T )| with respect to a given set of transmission times {\u03c4 ji } (j,i)\u2208E . Next, we will estimate the influence by averaging over multiple sets of samples for {\u03c4 ji } (j,i)\u2208E . More specifically, the relation from ( 7)\n\u03c3(A, T ) = E {\u03c4ji} (j,i)\u2208E [|N (A, T )|] = E {\u03c4ji} E {r 1 ,...,r m }|{\u03c4ji} m \u2212 1 m u=1 r u * ,(15)\nsuggests the following overall algorithm Continuous-Time Influence Estimation (CONTINEST):\n1. Sample n sets of random transmission times {\u03c4 l ij } (j,i)\u2208E \u223c (j,i)\u2208E f ji (\u03c4 ji ) 2. Given a set of {\u03c4 l ij } (j,i)\u2208E , sample m sets of random labels\n{r u i } i\u2208V \u223c i\u2208V exp(\u2212r i ) 3. Estimate \u03c3(A, T ) by sample averages \u03c3(A, T ) \u2248 1 n n l=1 (m \u2212 1)/ m u l =1 r u l *\nImportantly, the number of random labels, m, does not need to be very large. Since the estimator for |N (A, T )| is unbiased [17], essentially the outer-loop of averaging over n samples of random transmission times further reduces the variance of the estimator in a rate of O(1/n). In practice, we can use a very small m (e.g., 5 or 10) and still achieve good results, which is also confirmed by our later experiments. Compared to [2], the novel application of Cohen's algorithm arises for estimating influence for multiple sources, which drastically reduces the computation by cleverly using the least-label list from single source. Moreover, we have the following theoretical guarantee (see Appendix E for proof) Theorem 1 Draw the following number of samples for the set of random transmission times\nn C\u039b 2 log 2|V| \u03b4 (16\n)\nwhere \u039b := max The theorem indicates that the minimum number of samples, n, needed to achieve certain accuracy is related to the actual size of the influence \u03c3(A, T ), and the variance of the neighborhood size |N (A, T )| over the random draw of samples. The number of random labels, m, drawn in the inner loop of the algorithm will monotonically decrease the dependency of n on \u03c3(A, T ). It suffices to draw a small number of random labels, as long as the value of \u03c3(A, T ) 2 /(m \u2212 2) matches that of V ar(|N (A, T )|). Another implication is that influence at larger time window T is harder to estimate, since \u03c3(A, T ) will generally be larger and hence require more random labels.", "publication_ref": ["b16", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Influence Maximization", "text": "Once we know how to estimate the influence \u03c3(A, T ) for any A \u2286 V and time window T efficiently, we can use them in finding the optimal set of C source nodes A * \u2286 V such that the expected number of infected nodes in G is maximized at T . That is, we seek to solve,\nA * = argmax |A| C \u03c3(A, T ),(17)\nwhere set A is the variable. The above optimization problem is NP-hard in general. By construction, \u03c3(A, T ) is a non-negative, monotonic nondecreasing function in the set of source nodes, and it can be shown that \u03c3(A, T ) satisfies a diminishing returns property called submodularity [7].\nA well-known approximation algorithm to maximize monotonic submodular functions is the greedy algorithm. It adds nodes to the source node set A sequentially. In step k, it adds the node i which maximizes the marginal gain \u03c3(A k\u22121 \u222a {i}; T ) \u2212 \u03c3(A k\u22121 ; T ). The greedy algorithm finds a source node set which achieves at least a constant fraction (1 \u2212 1/e) of the optimal [18]. Moreover, lazy evaluation [5] can be employed to reduce the required number of marginal gains per iteration. By using our influence estimation algorithm in each iteration of the greedy algorithm, we gain the following additional benefits:\nFirst, at each iteration k, we do not need to rerun the full influence estimation algorithm (section 5.2). We just need to store the least label list r * (i) for each node i \u2208 V computed for a single source, which requires expected storage size of O(|V| log |V|) overall.\nSecond, our influence estimation algorithm can be easily parallelized. Its two nested sampling loops can be parallelized in a straightforward way since the variables are independent of each other. However, in practice, we use a small number of random labels, and m n. Thus we only need to parallelize the sampling for the set of random transmission times {\u03c4 ji }. The storage of the least element lists can also be distributed. However, by using our randomized algorithm for influence estimation, we also introduce a sampling error to the greedy algorithm due to the approximation of the influence \u03c3(A, T ). Fortunately, the greedy algorithm is tolerant to such sampling noise, and a well-known result provides a guarantee for this case (following an argument in [19,Th. 7.9]):\nTheorem 2 Suppose the influence \u03c3(A, T ) for all A with |A| \u2264 C are estimated uniformly with error and confidence 1 \u2212 \u03b4, the greedy algorithm returns a set of sources A such that \u03c3( A, T ) \u2265 (1 \u2212 1/e)OP T \u2212 2C with probability at least 1 \u2212 \u03b4. ", "publication_ref": ["b6", "b17", "b4", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "We evaluate the accuracy of the estimated influence given by CONTINEST and investigate the performance of influence maximization on synthetic and real networks. We show that our approach significantly outperforms the state-of-the-art methods in terms of both speed and solution quality.\nSynthetic network generation. We generate three types of Kronecker networks [20]: (i) coreperiphery networks (parameter matrix: [0.9 0.5; 0.5 0.3]), which mimic the information diffusion traces in real world networks [21], (ii) random networks ([0.5 0.5; 0.5 0.5]), typically used in physics and graph theory [22] and (iii) hierarchical networks ([0.9 0.1; 0.1 0.9]) [10].\nNext, we assign a pairwise transmission function for every directed edge in each type of network and set its parameters at random. In our experiments, we use the Weibull distribution [16],\nf (t; \u03b1, \u03b2) = \u03b2 \u03b1 t \u03b1 \u03b2\u22121 e \u2212(t/\u03b1) \u03b2 , t 0,\nwhere \u03b1 > 0 is a scale parameter and \u03b2 > 0 is a shape parameter. The Weibull distribution (Wbl) has often been used to model lifetime events in survival analysis, providing more flexibility than an exponential distribution [16]. We choose \u03b1 and \u03b2 from 0 to 10 uniformly at random for each edge in order to have heterogeneous temporal dynamics. Finally, for each type of Kronecker network, we generate 10 sample networks, each of which has different \u03b1 and \u03b2 chosen for every edge.\nAccuracy of the estimated influence. To the best of our knowledge, there is no analytical solution to the influence estimation given Weibull transmission function. Therefore, we compare CON-TINEST with Naive Sampling (NS) approach (see Appendix C) by considering the highest degree node in a network as the source, and draw 1,000,000 samples for NS to obtain near ground truth. Figures 1(a) compares CONTINEST with the ground truth provided by NS at different time window T , from 0.1 to 10 in corre-periphery networks. For CONTINEST, we generate up to 10,000 random samples (or set of random waiting times), and 5 random labels in the inner loop. In all three networks, estimation provided by CONTINEST fits accurately the ground truth, and the relative error decreases quickly as we increase the number of samples and labels (Figures 1(b) and 1(c)). For 10,000 random samples with 5 random labels, the relative error is smaller than 0.01. (see Appendix F for additional results on the random and hierarchal networks) Scalability. We compare CONTINEST to the state-of-the-art method INFLUMAX [7] and the Naive Sampling (NS) method in terms of runtime for the continuous-time influence estimation and maximization. For CONTINEST, we draw 10,000 samples in the outer loop, each having 5 random labels in the inner loop. For NS, we also draw 10,000 samples. The first two experiments are carried out in a single 2.4GHz processor. First, we compare the performance of increasingly selecting sources (from 1 to 10) on small core-periphery networks (Figure 2(a)). When the number of selected sources is 1, different algorithms essentially spend time estimating the influence for each node. CONTINEST outperforms other methods by order of magnitude and for the number of sources larger than 1, it can efficiently reuse computations for estimating influence for individual nodes. Dashed lines mean that a method did not finish in 24 hours, and the estimated run time is plotted. Next, we compare the run time for selecting 10 sources on core-periphery networks of 128 nodes with increasing densities (or the number of edges) (Figure 2(a)). Again, INFLUMAX and NS are order of magnitude slower due to their respective exponential and quadratic computational complexity in network density. In contrast, the run time of CONTINEST only increases slightly with the increasing density since its computational complexity is linear in the number of edges (see Appendix F for additional results on the random and hierarchal networks). Finally, we evaluate the speed on large core-periphery networks, ranging from 100 to 1,000,000 nodes with density 1.5 in Figure 2(c). We report the parallel run time   only for CONTINEST and NS (both are implemented by MPI running on 192 cores of 2.4Ghz) since INFLUMAX is not scalable. In contrast to NS, the performance of CONTINEST increases linearly with the network size and can easily scale up to one million nodes.\nReal-world data. We first quantify how well each method can estimate the true influence in a real-world dataset. Then, we evaluate the solution quality of the selected sources for influence maximization. We use the MemeTracker dataset [23] which has 10,967 hyperlink cascades among 600 media sites. We repeatedly split all cascades into a 80% training set and a 20% test set at random for five times. On each training set, we learn the continuous-time model using NETRATE [10] with exponential transmission functions. For discrete-time model, we learn the infection probabilities using [24] for IC, SP1M and PMIA. Similarly, for LT, we follow the methodology by [1]. Let C(u) be the set of all cascades where u was the source node. Based on C(u), the total number of distinct nodes infected before T quantifies the real influence of node u up to time T . In Figure 3(a), we report the Mean Absolute Error (MAE) between the real and the estimated influence. Clearly, CON-TINEST performs the best statistically. Because the length of real cascades empirically conforms to a power-law distribution where most cascades are very short (2-4 nodes), the gap of the estimation error is relatively not large. However, we emphasize that such accuracy improvement is critical for maximizing long-term influence. The estimation error for individuals will accumulate along the spreading paths. Hence, any consistent improvement in influence estimation can lead to significant improvement to the overall influence estimation and maximization task, which is further confirmed by Figures 3(b) and 3(c) where we evaluate the influence of the selected nodes in the same spirit as influence estimation: the true influence is calculated as the total number of distinct nodes infected before T based on C(u) of the selected nodes. The selected sources given by CONTINEST achieve the best performance as we vary the number of selected sources and the observation time window.", "publication_ref": ["b19", "b20", "b21", "b9", "b15", "b15", "b6", "b22", "b9", "b23", "b0"], "figure_ref": ["fig_2", "fig_2", "fig_3", "fig_3", "fig_3", "fig_5", "fig_5"], "table_ref": []}, {"heading": "Conclusions", "text": "We propose a randomized influence estimation algorithm in continuous-time diffusion networks, which can scale up to networks of millions of nodes while significantly improves over previous stateof-the-arts in terms of the accuracy of the estimated influence and the quality of the selected nodes in maximizing the influence. In future work, it will be interesting to apply the current algorithm to other tasks like influence minimization and manipulation, and design scalable algorithms for continuous-time models other than the independent cascade model.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Maximizing the spread of influence through a social network", "journal": "", "year": "2003", "authors": "David Kempe; Jon Kleinberg; Tardos And\u00e9va"}, {"ref_id": "b1", "title": "Efficient influence maximization in social networks", "journal": "", "year": "2009", "authors": "Wei Chen; Yajun Wang; Siyu Yang"}, {"ref_id": "b2", "title": "Scalable influence maximization in social networks under the linear threshold model", "journal": "", "year": "2010", "authors": "Wei Chen; Yifei Yuan; Li Zhang"}, {"ref_id": "b3", "title": "A data-based approach to social influence maximization", "journal": "", "year": "2011", "authors": "Amit Goyal; Francesco Bonchi; V S Laks;  Lakshmanan"}, {"ref_id": "b4", "title": "Cost-effective outbreak detection in networks", "journal": "", "year": "2007", "authors": "Jure Leskovec; Andreas Krause; Carlos Guestrin; Christos Faloutsos; Jeanne M Vanbriesen; Natalie S Glance"}, {"ref_id": "b5", "title": "Mining knowledge-sharing sites for viral marketing", "journal": "", "year": "2002", "authors": "Matthew Richardson; Pedro Domingos"}, {"ref_id": "b6", "title": "Influence maximization in continuous time diffusion networks", "journal": "", "year": "2012", "authors": "Manuel Gomez; - Rodriguez; Bernhard Sch\u00f6lkopf"}, {"ref_id": "b7", "title": "Learning networks of heterogeneous influence", "journal": "", "year": "2012", "authors": "Nan Du; Le Song; Alexander J Smola; Ming Yuan"}, {"ref_id": "b8", "title": "Uncover topic-sensitive information diffusion networks", "journal": "", "year": "2013", "authors": "Nan Du; Le Song; Hyenkyun Woo; Hongyuan Zha"}, {"ref_id": "b9", "title": "Uncovering the temporal dynamics of diffusion networks", "journal": "", "year": "2011", "authors": "Manuel Gomez-Rodriguez; David Balduzzi; Bernhard Sch\u00f6lkopf"}, {"ref_id": "b10", "title": "Structure and Dynamics of Information Pathways in On-line Media", "journal": "", "year": "2013", "authors": "Manuel Gomez-Rodriguez; Jure Leskovec; Bernhard Sch\u00f6lkopf"}, {"ref_id": "b11", "title": "Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes", "journal": "", "year": "2013", "authors": "Ke Zhou; Le Song; Hongyuan Zha"}, {"ref_id": "b12", "title": "Learning triggering kernels for multi-dimensional hawkes processes", "journal": "", "year": "2013", "authors": "Ke Zhou; Hongyuan Zha; Le Song"}, {"ref_id": "b13", "title": "Modeling information propagation with survival theory", "journal": "", "year": "2013", "authors": "Manuel Gomez-Rodriguez; Jure Leskovec; Bernhard Sch\u00f6lkopf"}, {"ref_id": "b14", "title": "Mixture of mutually exciting processes for viral diffusion", "journal": "", "year": "2013", "authors": "Shuanghong Yang; Hongyuan Zha"}, {"ref_id": "b15", "title": "Statistical Models and Methods for Lifetime Data", "journal": "Wiley-Interscience", "year": "2002", "authors": "Jerald F Lawless"}, {"ref_id": "b16", "title": "Size-estimation framework with applications to transitive closure and reachability", "journal": "Journal of Computer and System Sciences", "year": "1997", "authors": "Edith Cohen"}, {"ref_id": "b17", "title": "An analysis of approximations for maximizing submodular set functions", "journal": "Mathematical Programming", "year": "1978", "authors": " Gl Nemhauser; M L Wolsey;  Fisher"}, {"ref_id": "b18", "title": "", "journal": "", "year": "2008", "authors": "Andreas Krause"}, {"ref_id": "b19", "title": "Kronecker graphs: An approach to modeling networks", "journal": "JMLR", "year": "2010", "authors": "Jure Leskovec; Deepayan Chakrabarti; Jon M Kleinberg; Christos Faloutsos; Zoubin Ghahramani"}, {"ref_id": "b20", "title": "Inferring networks of diffusion and influence", "journal": "", "year": "2010", "authors": "Manuel Gomez-Rodriguez; Jure Leskovec; Andreas Krause"}, {"ref_id": "b21", "title": "Networks, Crowds, and Markets: Reasoning About a Highly Connected World", "journal": "Cambridge University Press", "year": "2010", "authors": "David Easley; Jon Kleinberg"}, {"ref_id": "b22", "title": "Meme-tracking and the dynamics of the news cycle", "journal": "", "year": "2009", "authors": "Jure Leskovec; Lars Backstrom; Jon M Kleinberg"}, {"ref_id": "b23", "title": "Learning the graph of epidemic cascades", "journal": "ACM", "year": "2012", "authors": "Praneeth Netrapalli; Sujay Sanghavi"}, {"ref_id": "b24", "title": "Scalable influence maximization for prevalent viral marketing in large-scale social networks", "journal": "", "year": "2010", "authors": "Wei Chen; Chi Wang; Yajun Wang"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": ") Finally, to estimate |N (s, T )|, we generate m i.i.d. collections of random labels, run Algorithm 1 on each collection, and obtain m values {r u * } m u=1 , which we use on Eq. (9) to estimate |N (i, T )|. The computational complexity of Algorithm 1 is O(|E| log |V| + |V| log 2 |V|), with expected size of each r * (s) being O(log |V|).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "A:|A|\u2264C 2\u03c3(A, T ) 2 /(m \u2212 2) + 2V ar(|N (A, T )|)(m \u2212 1)/(m \u2212 2) + 2a /3 and |N (A, T )| \u2264 a, and for each set of random transmission times, draw m set of random labels. Then | \u03c3(A, T ) \u2212 \u03c3(A, T )| uniformly for all A with |A| C, with probability at least 1 \u2212 \u03b4.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 1 :1Figure1: For core-periphery networks with 1,024 nodes and 2,048 edges, (a) estimated influence for increasing time window T , and (b) fixing T = 10, relative error for increasing number of samples with 5 random labels, and (c) for increasing number of random labels with 10,000 random samples.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 2 :2Figure2: For core-periphery networks with T = 10, runtime for (a) selecting increasing number of sources in networks of 128 nodes and 320 edges; for (b)selecting 10 sources in networks of 128 nodes with increasing density; and for (c) selecting 10 sources with increasing network size from 100 to 1,000,000 fixing 1.5 density.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Influence estimation error (b) Influence vs. #sources (c) Influence vs. time", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 3 :3Figure 3: In MemeTracker dataset, (a) comparison of the accuracy of the estimated influence in terms of mean absolute error, (b) comparison of the influence of the selected nodes by fixing the observation window T = 5 and varying the number sources, and (c) comparison of the influence of the selected nodes by by fixing the number of sources to 50 and varying the time window.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "p ({t i } i\u2208V ) = i\u2208V p (t i |{t j } j\u2208\u03c0i ) ,(1)", "formula_coordinates": [3.0, 230.39, 183.9, 273.61, 14.14]}, {"formula_id": "formula_1", "formula_text": "p {\u03c4 ji } (j,i)\u2208E = (j,i)\u2208E f ji (\u03c4 ji ),(2)", "formula_coordinates": [3.0, 231.27, 270.27, 272.73, 14.13]}, {"formula_id": "formula_2", "formula_text": "t i = g i {\u03c4 ji } (j,i)\u2208E := min q\u2208Qi (j,l)\u2208q \u03c4 jl ,(3)", "formula_coordinates": [3.0, 217.69, 356.52, 286.31, 14.58]}, {"formula_id": "formula_3", "formula_text": "Pr {t i \u2264 T } = Pr g i {\u03c4 ji } (j,i)\u2208E \u2264 T . (4", "formula_coordinates": [3.0, 217.25, 403.65, 282.88, 9.96]}, {"formula_id": "formula_4", "formula_text": ")", "formula_coordinates": [3.0, 500.13, 403.97, 3.87, 8.64]}, {"formula_id": "formula_5", "formula_text": "\u03c3(A, T ) = E i\u2208V I {t i \u2264 T } = i\u2208V E [I {t i \u2264 T }] = i\u2208V Pr {t i \u2264 T } ,(5)", "formula_coordinates": [3.0, 138.13, 564.91, 365.87, 14.13]}, {"formula_id": "formula_6", "formula_text": "Pr{t i \u2264 T } = \u221e 0 \u2022 \u2022 \u2022 T ti=0 \u2022 \u2022 \u2022 \u221e 0 j\u2208V p t j |{t l } l\u2208\u03c0j j\u2208V dt j ,(6)", "formula_coordinates": [3.0, 149.12, 648.32, 354.88, 26.29]}, {"formula_id": "formula_7", "formula_text": "\u03c3(A, T ) = i\u2208V Pr g i {\u03c4 ji } (j,i)\u2208E \u2264 T = E i\u2208V I g i {\u03c4 ji } (j,i)\u2208E \u2264 T , (7)", "formula_coordinates": [4.0, 122.12, 238.02, 381.88, 14.13]}, {"formula_id": "formula_8", "formula_text": "N (s, T ) = i g i {\u03c4 ji } (j,i)\u2208E \u2264 T, i \u2208 V .(8)", "formula_coordinates": [4.0, 211.11, 491.94, 292.89, 9.96]}, {"formula_id": "formula_9", "formula_text": "|N (s, T )| \u2248 m \u2212 1 m u=1 r u * .(9)", "formula_coordinates": [4.0, 258.44, 589.35, 245.56, 24.8]}, {"formula_id": "formula_10", "formula_text": "\u221e > d (1) > d (2) > . . . > d (|r * (s)|) = 0 (10) r (1) < r (2) < . . . < r (|r * (s)|) ,(11)", "formula_coordinates": [5.0, 226.38, 171.69, 277.62, 25.16]}, {"formula_id": "formula_11", "formula_text": "d (l\u22121) > T \u2265 d (l) .(12", "formula_coordinates": [5.0, 303.1, 239.75, 196.75, 9.96]}, {"formula_id": "formula_12", "formula_text": "N (A, T ) = i\u2208A N (i, T ). (13", "formula_coordinates": [5.0, 249.35, 418.39, 250.5, 14.13]}, {"formula_id": "formula_13", "formula_text": ")", "formula_coordinates": [5.0, 499.85, 418.71, 4.15, 8.64]}, {"formula_id": "formula_15", "formula_text": "\u03c3(A, T ) = E {\u03c4ji} (j,i)\u2208E [|N (A, T )|] = E {\u03c4ji} E {r 1 ,...,r m }|{\u03c4ji} m \u2212 1 m u=1 r u * ,(15)", "formula_coordinates": [5.0, 153.24, 623.49, 350.76, 24.8]}, {"formula_id": "formula_16", "formula_text": "{r u i } i\u2208V \u223c i\u2208V exp(\u2212r i ) 3. Estimate \u03c3(A, T ) by sample averages \u03c3(A, T ) \u2248 1 n n l=1 (m \u2212 1)/ m u l =1 r u l *", "formula_coordinates": [5.0, 137.29, 702.23, 364.67, 27.8]}, {"formula_id": "formula_17", "formula_text": "n C\u039b 2 log 2|V| \u03b4 (16", "formula_coordinates": [6.0, 262.45, 194.19, 237.4, 22.31]}, {"formula_id": "formula_18", "formula_text": ")", "formula_coordinates": [6.0, 499.85, 201.25, 4.15, 8.64]}, {"formula_id": "formula_19", "formula_text": "A * = argmax |A| C \u03c3(A, T ),(17)", "formula_coordinates": [6.0, 244.57, 409.1, 259.43, 12.67]}, {"formula_id": "formula_20", "formula_text": "f (t; \u03b1, \u03b2) = \u03b2 \u03b1 t \u03b1 \u03b2\u22121 e \u2212(t/\u03b1) \u03b2 , t 0,", "formula_coordinates": [7.0, 108.0, 345.49, 163.78, 15.56]}], "doi": ""}