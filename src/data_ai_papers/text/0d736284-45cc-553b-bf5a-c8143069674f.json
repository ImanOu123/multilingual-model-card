{"title": "A Unifying View on Individual Bounds and Heuristic Inaccuracies in Bidirectional Search", "authors": "Vidal Alc\u00e1zar", "pub_date": "", "abstract": "In the past few years, new very successful bidirectional heuristic search algorithms have been proposed. Their key novelty is a lower bound on the cost of a solution that includes information from the g values in both directions. Kaindl and Kainz (1997) proposed measuring how inaccurate a heuristic is while expanding nodes in the opposite direction, and using this information to raise the f value of the evaluated nodes. However, this comes with a set of disadvantages and remains yet to be exploited to its full potential. Additionally, Sadhukhan (2013) presented BAE * , a bidirectional best-first search algorithm based on the accumulated heuristic inaccuracy along a path. However, no complete comparison in regards to other bidirectional algorithms has yet been done, neither theoretical nor empirical. In this paper we define individual bounds within the lower-bound framework and show how both Kaindl and Kainz's and Sadhukhan's methods can be generalized thus creating new bounds. This overcomes previous shortcomings and allows newer algorithms to benefit from these techniques as well. Experimental results show a substantial improvement, up to an order of magnitude in the number of necessarily-expanded nodes compared to state-ofthe-art near-optimal algorithms in common benchmarks.", "sections": [{"heading": "Introduction", "text": "Front-to-end bidirectional heuristic search (Bi-HS) was proposed by Pohl (1969) shortly after A * was presented (Hart, Nilsson, and Raphael 1968). However, Bi-HS was never much better empirically than either A * or blind bidirectional search, and pathologically expanded nodes that blind bidirectional search would not expand despite being more informed (Barker and Korf 2015). Recently, though, the idea of delaying the expansion of nodes with high g addressed this problem partially (Holte et al. 2017;Shaham et al. 2017; or totally (Barley et al. 2018;Shperberg et al. 2019b). Also, a theoretical analysis on how the g values of nodes from both sides interact (Eckerle et al. 2017) led to the development of algorithms with strong theoretical properties, like NBS's near-optimality (Chen et al. 2017) -meaning that NBS will never expand more than twice the number of necessarily-expanded nodes of any other Bi-HS algorithm.\nReducing the depth of the search is not the only advantage of Bi-HS. Kaindl and Kainz (1997) showed how consistent heuristics can be strengthened by checking how inaccurate they are for nodes in the opposite direction. Naively strengthening them renders them inconsistent, and so far no general method has been widely used in this context.\nAnother algorithm that uses heuristic inaccuracies is BAE * (Sadhukhan 2013), which adds the estimated error to the target and the heuristic inaccuracy to the source. This value, the total accumulated error, is used both as a criterion to keep consistency (as it depends only on one direction, unlike Kaindl and Kainz's) and to compute a global lower bound. Nevertheless, the relationship to Kaindl and Kainz's methods is unclear, and the empirical evaluation is limited.\nAn important observation is that both approaches provide global lower bounds. In this paper we delve deeper into the lower-bound framework that modern Bi-HS algorithms use and propose the use of individual lower bounds. These bounds allow integrating recent approaches and the use of heuristic inaccuracies in a simple and general way. Furthermore, bound propagation techniques like those of Shperberg et.al. (2019b) can be also seen as a usage of individual lower bounds, with a straightforward way to exploit global bounds for individual nodes too. Empirical results show that, by using heuristic inaccuracies, a substantial increase in performance can be obtained. In fact, we observe that using heuristic inaccuracies allows expanding fewer than half of the necessarily-expanded nodes of near-optimal algorithms, which again emphasizes the importance of the theoretical implications of our approach.\nThe contributions of this paper are organized by sections: first, we extend the lower-bound framework, introducing the concepts of individual bounds, delayed nodes and relative minimum node values, and proposing a fixpoint computation for the latter; then, Kaindl and Kainz's work is integrated into the framework by creating new bounds, which solves its problematic aspects and finally allows using it to its full potential. Afterwards, Sadhukhan's work is also generalized as an individual bound and linked to the bounds created in the previous section; finally, we present experiments that show a substantial improvement over the state of the art, and outline future lines of research.", "publication_ref": ["b16", "b8", "b2", "b11", "b20", "b3", "b23", "b6", "b5", "b12", "b18"], "figure_ref": [], "table_ref": []}, {"heading": "Background", "text": "A search problem is a tuple P = (G = (S, E), start, goal, h f , h b ). G is an implicit directed graph; S is the set of vertices (which correspond to states in explicit-state search); E is the set of edges, each of which has a non-negative arbitrary cost; start \u2208 S is the initial state; goal \u2208 S is the goal; h f , h b are the forward and backward heuristics respectively. is the value of the edge with minimum cost, \u03b9 is the greatest common denominator among the cost of all non-zero-cost edges, e.g. if edges have costs 1.0 and 1.5, = 1.0 and \u03b9 = 0.5.\nThe cost of the shortest path between two states in S is c : S \u00d7 S \u2192 R \u22650 . Search algorithms keep track of previously seen states using nodes; a node makes reference to a single state, but a single state can be referenced by different nodes. Nodes have node values g, h and f that can be labeled with the direction of the search, like h f and h b . When the direction is the same in an equation but can be either one, the label is x, like f x . Other terms subject to the concept of direction can also be labeled this way, e.g. Open x is the open list of direction x. The opposite direction of x is x. Given a node n referencing a state s \u2208 S, g f (n) is the cost of the forward path from start to n, g b (n) is the cost of the backward path from goal to n, h\nf (n) = h f (s, goal), h b (n) = h b (s, start) and f x (n) = g x (n) + h x (n). For g f (n) and g b (n) to be optimal, g f (n) = c(start, s) and g b (n) = c(s, goal) respectively. h f and h b are admissible iff, for any state s \u2208 S, h f (s) \u2264 c(s, goal) and h b (s) \u2264 c(start, s) respectively. h x is consistent iff it is admissible and h x (n) \u2264 c(n, n ) + h x (n ) for any pair of nodes n, n .\nThe priority function of a best-first search algorithm is a ranking function that maps a node n to a value that determines the order of expansion.\nC * = c(start, goal) is the cost of an optimal solution. U is the cost of the best solution found so far, and thus monotonically decreasing. For an algorithm to be optimal, C * = U at the end of the execution if there is at least one solution path. C is a lower bound on the cost of any new solution at any given moment, and thus monotonically increasing. When C \u2265 U , necessarily C * = U and thus an optimal solution has been found. For algorithms to expand nodes with optimal g x , consistent heuristics are needed. All heuristics in this paper are assumed to be consistent.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Individual Bounds and Relative Minimum Node Values", "text": "All consistent optimal algorithms work with C either implicitly or explicitly, e.g. in A* (Hart, Nilsson, and Raphael 1968) the implicit C is the minimum f value in the open list. However, keeping track of C explicitly allows implementing more complex techniques (Chen et al. 2017;Barley et al. 2018;Shperberg et al. 2019a;2019b;Alc\u00e1zar, Barley, and Riddle 2019). Both Shperberg et al. (2019b) and Alc\u00e1zar et al. (2019) propose a high-level algorithm to keep track of C, but the former expands whole layers and the latter defines how states are alternatively expanded. Algorithm 1 defines a more general high-level algorithm that keeps the option of using a last-layer tie-breaking routine like Alc\u00e1zar et al. (2019) but without the specificity of either algorithm. The purpose of the main loop is to raise C as fast as possible so it converges to U . The purpose of RunTieBreaker() is to check whether a solution of cost C exists so U converges to C. UpdateC() returns true if C has been increased i.e. a higher lower bound has been found. Eckerle et al. (2017) defined a lower bound for any solution path through nodes n \u2208 Open f , n \u2208 Open b such that the cost of the path is at least max(g f (n\n) + g b (n ) + , f f (n), f b (n )).\nThe minimum lower bound among all possible pairs of states from opposite directions is a lower bound on the solution, and thus can be used to increase C. Let us temporarily define fMin x and gMin x as the minimum f and g values respectively in Open x ; then a global lower bound is max(gMin f + gMin b + , fMin f , fMin b ). Because this lower bound takes the maximum of three different equations, and because new bounds will be introduced in subsequent sections, let us individually define the bounds. Definition 1. (g bound). The g bound is defined as gMin f + gMin b + . Definition 2. (f bounds). The forward f bound is defined as fMin f . The backward f bound is defined as fMin b .\nWhen fMin x and gMin x are indeed the global minimum node values in the open list, C can directly take the value of the highest bound. However, both Shperberg et al. (2019b) in Section 4.2 and Alc\u00e1zar et al. (2019) in Theorem 1 pointed out how only nodes such that their f value is equal or lower than C need to be taken into account when computing gMin x , the way NBS (Chen et al. 2017) implicitly does when pairing nodes. In fact, this can be extended to any minimum node value. In order to prove this, let us introduce first the concepts of delayed and expandable nodes. Definition 3. (Expandable and delayed node). A node n is delayed at layer C if it can be proven that no solution path of cost C can go through n. A non-delayed node is expandable. Shperberg et al. (2019b) defined a new heuristic h lb (n) based on the lower bound on individual nodes. h lb (n) depends on C and its purpose is in fact to prevent the expansion of the node at a given C. Hence, the obtained numeric value has no bearing other than to be compared with C: if it is higher than C, then delay its expansion until C is increased, turning the node from expandable to delayed.\nWe now redefine fMin x and gMin x as the minimum node values among expandable nodes, meaning they are relative to C. Because fewer nodes are considered, higher values for the minimum node values for a given C can be obtained.", "publication_ref": ["b8", "b5", "b3", "b22", "b23", "b0", "b23", "b0", "b0", "b6", "b23", "b0", "b5", "b23"], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 1. (Minimum node values only relevant among expandable nodes). When computing minimum node values at a given layer C, only expandable nodes have to be taken into account.", "text": "Proof. (Proof sketch). Let a solution of cost C pass through nodes n \u2208 Open x and n \u2208 Openx. Their lower bound relative to C must not be higher than C, and thus both must be expandable.\nDelayed nodes can also be linked to the concept of individual bounds in a very simple way: for a node generated in direction x, substitute the minimum node values in direction x by the corresponding values of the node. We call this the delaying rule of a bound. For instance, a forward node n is delayed by the g bound if g f (n) + gMin b + > C; similarly, a backward node n is delayed by the backward f bound if f b (n ) > C. However, if the minimum values are relative, C cannot take the value of the global lower bound equation, as admissibility may be compromised. Also, because delaying nodes may cause the minimum node values to increase, and because increasing the minimum node values may cause extra nodes to be delayed, computing the minimum node values and the set of delayed nodes requires a fixpoint computation. Figure 1 illustrates all this. \u2022 The value of the g bound is now gMin f + gMin b + = 11 > C, so C must be increased. It would be a mistake to assign 11 to C, as there may be solutions of lower cost e.g. a solution of cost 8 through F2 and G2. As all solution costs are a multiple of \u03b9, increasing C by \u03b9 means that no C value will be skipped, and thus C is increased to 8 instead. All nodes become expandable again.\n\u2022 G1 is delayed by the backward f bound, because f b (G1) > C. Thus, gMin b = 6.\n\u2022 F1 is delayed by the g bound, because g f (F 1) + gMin b + > C. Thus, fMin f = 8.\n\u2022 No more nodes can be delayed, and the bounds are not greater than C, so the fixpoint computation stops.\nIn the end, C = 8, gMin f = 1, fMin f = 8, gMin b = 6 and fMin b = 7. Note that fMin f = 8 and not 7, which will be relevant once new bounds are introduced. Another criterion to increase C is running out of expandable nodes in either direction instead of checking the value of the bounds. This criterion is equivalent, but checking the bounds gives additional information that may help to decide which criteria should be used as part of the priority function. Following this, we can describe in pseudocode a general way of implementing UpdateC() in Algorithm 2 assuming that fMin x and gMin x are relative and not global minimum values. \nC \u21d0 C + \u03b9 4: updated \u21d0 True 5:\nUpdateMinValues() 6: end while 7: return updated This fixpoint computation can be expensive. A way of speeding it up is using g-f buckets (Burns et al. 2012) and caching results until the addition or removal of a bucket may change the values. Also, if this computation becomes a bottleneck in terms of time, it can be terminated earlier at the expense of having lower minimum node values.\nKaindl and Kainz's Heuristic Inaccuracies Kaindl and Kainz (1997) observed that, when using consistent heuristics, the lower bound of a node can be increased by exploiting the inaccuracy of the heuristic. This inaccuracy is measured comparing the g value of a node with what the opposite heuristic yields: if a forward node n has g f (n) = 3 and h b (n) = 2, the heuristic inaccuracy of h b for that node is 1. This value was called diff x (n), but we will call it just d for succinctness and consistency with other values. Definition 4. (d value of a node). The d value of a node n is defined as\nd x (n) = g x (n) \u2212 hx(n).\ndMin x is the minimum d value of a set of nodes in direction x. Originally the set of nodes was Open x and thus dMin x was non-relative. Two different methods were proposed, the Add and the Max method, which we will call KKAdd and KKMax, as other works in the literature have done. KKAdd increases the f value of a node by adding the value of dMin in the opposite direction, that is, KKMax, uses the d value of the node and adds the minimum f in the other direction, that is, KKMax x (n) = d x (n) + fMinx. Similarly, Figure 3 is the original figure that shows how KKMax is computed.\nKKAdd x (n) = f x (n) + dMinx.\nThe main disadvantage of this method is the loss of consistency when KKAdd or KKMax are used as the priority function. Other works have tried to exploit KKAdd and Figure 2: Figure 7 of Kaindl and Kainz (1997).\nFigure 3: Figure 8 of Kaindl and Kainz (1997).\nKKMax in different ways, like computing d in one direction only (Kaindl et al. 1999;Wilt and Ruml 2013) or using it only to discard nodes after a solution has been found (Auer and Kaindl 2004). Still, this does not exploit all the information derived from heuristic inaccuracies, often requires multiple decisions and/or parameters and is difficult to integrate with other Bi-HS algorithms.\nNevertheless, KKAdd and KKMax are in fact a lower bound on the cost of any solution going through a given node, and thus can fulfill the same role as the g bound and the f bounds. In addition, the minimum node values used can be relative, and not absolute like in the original definition, if the purpose is delaying a node at level C. For instance, a forward node n can be delayed if f f (n)+dMin b > C -which corresponds to the value of KKAdd f (n) -even if dMin x is relative. Likewise, a backward node n can be delayed if Because the KK bounds trivially dominate the f bounds, the condition in Line 2 of Algorithm 2 can be replaced by:\nfMin f + d b (n ) > C,\nC < max(gMin f + gMin b + , fMin f + dMin b , fMin b + dMin f ) (1)\nInterestingly, the delaying rule of the forward KK bound corresponds to KKAdd for forward nodes and to KKMax for backward nodes, and vice versa for the backward KK bound. Thus, both methods, originally thought to be different techniques, are in fact part of the same lower-bound definition, exemplifying how the lower bound framework can easily integrate Kaindl and Kainz's contribution.\nTo compute the KK bounds, three-dimensional g-f-d buckets can be used instead of g-f ones. The fixpoint computation of minimum node values can also be modified to account for dMin x and the delaying rule of the KK bounds.", "publication_ref": ["b4", "b12", "b12", "b12", "b13", "b25", "b1"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Bidirectional Estimates and BAE *", "text": "Before the interest on bidirectional search was rekindled, Sadhukhan proposed an interesting bidirectional best-first algorithm based on accumulated errors along paths, BAE * 1 , first at a national conference (Sadhukhan 2012) and later in a journal article (Sadhukhan 2013) with a correction on the latter that drops the need for symmetric heuristics (Sadhukhan 2015). Given node n, BAE * uses a priority function defined as the total accumulated error TE\nx (n) = FE x (n) + BE x (n) = (g x (n) + h x (n) \u2212 h 0 ) + (g x (n) \u2212 hx(n)),\nwhere h 0 is h f (start) forward and h b (goal) backward. To prove optimality BAE * uses the lower bound 1 2 (h f (start) + h b (goal)) + 1 2 (TEMin f + TEMin b ). Note however that h 0 in direction x is a constant subtracted from all nodes, so one may choose not to subtract it without changing the ranking of the priority function. Such a priority function can be reformulated in terms more similar to the previous ones: \nTE x (n) + h 0 = f x (n) + d x (n).\n(n) = f x (n) + d x (n).\nWe choose b because it aggregates estimates from both h f and h b and so b is a bidirectional estimate. f and d are monotonically increasing along paths and maintain consistency (Hart, Nilsson, and Raphael 1968;Wilt and Ruml 2013), so we can prove as a corollary that b does too. The same result can be derived from Sadhukhan's proofs about the total accumulated error along paths (Sadhukhan 2013). bMin b , let P be an optimal path, no solution has been found, and C = C * . There are three possibilities:\n\u2022 Both nodes belong to the same optimal path, that is,\nn, n \u2208 P . The sum b f (n) + b b (n ) can be decom- posed as f f (n) + d f (n) + f b (n ) + d b (n )\n. From Corollaries 5.1 and 5.2 of Kaindl and Kainz (1997) we know that\nf f (n) + d b (n ) \u2264 C * and f b (n ) + d f (n) \u2264 C * . Hence, f f (n) + d b (n ) + f b (n ) + d f (n) \u2264 2C, so b f (n) + b b (n ) \u2264 2C and thus b f (n) \u2264 2C \u2212 bMin b and b b (n ) \u2264 2C \u2212 bMin f\n, and neither will be delayed. \u2022 n \u2208 P but n \u2208 P and there is at least one expandable node n such that n \u2208 P and b x (n ) \u2265 b x (n ). Then the value of the sum b f (n) + b b (n ) cannot be higher than in the previous case and hence n will not be delayed. The opposite case in which n \u2208 P but n \u2208 P is analogous.\n\u2022 n \u2208 P but n \u2208 P and all nodes both in Openx and in P have already been delayed by another bound. This cannot happen, as a node on an optimal path cannot be delayed when C = C * by a bound that maintains admissibility.\nHaving proved this, the b bound can be added to the condition in Line 2 of Algorithm 2, making it:\nC < max(gMin f + gMin b + , fMin f + dMin b , fMin b + dMin f , \u03b9 (bMin f + bMin b )/2 \u03b9 )(2)\nInformally, the relationship between the KK bounds and the b bound can be described the following way: given two nodes n \u2208 Open x and n \u2208 Openx, when n tries to use fx(n ) or dx(n ) to check if it is delayed by a KK bound, the KK bound in the opposite direction may delay either node as well using the opposite pair of node values. Since computing all pairwise combinations of KK bounds is akin to a front-to-front heuristic and hence a priori computationally expensive, the averaged minimum b values are taken instead.\nBecause b depends on f and d, it can be easily computed using the g-f-d buckets used with the KK bounds. Nevertheless, explicitly keeping b values can lead to a more efficient implementation, as in our implementation of BAE * . Also, both bMin x and the delaying rule of the b bound can be included in the fixpoint computation of minimum node values.", "publication_ref": ["b17", "b18", "b19", "b8", "b25", "b18", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Comparison of b and KK bounds", "text": "Now we show that the b bound and the KK bounds do not dominate each other. Figures 4 and 5 prove this. In these pictures, bidirectional arrows represent the heuristic value of both h f and h b , and all visible edges have a cost of 1.\nFigure 4 shows how the forward KK bound yields a higher value than the b bound.    \n(bMin f + M f M b G S \u2190 \u2192 0 \u2190 \u2192 0 G 1 \u2190 \u2192 1 \u2190 \u2192 1 S 1\n\u2190 \u2192 0 \u2190 \u2192 1 G 1 \u2190 \u2192 0 \u2190 \u2192 1 S 1 U=4", "publication_ref": [], "figure_ref": ["fig_6", "fig_6"], "table_ref": []}, {"heading": "Experiments", "text": "In this section we present an exhaustive experimental evaluation of relevant Bi-HS algorithms. All algorithms use if applicable. The algorithms used are:\n\u2022 A* and BS*. BS* (p) is the original BS* (Kwa 1989); it uses Pohl's cardinality criterion, expanding in the direction of the smallest open list. BS* (a) alternates directions. \u2022 NBS and NBB. NBS (Chen et al. 2017) and NBB (Alc\u00e1zar, Barley, and Riddle 2019), both near-optimal algorithms. NBB is equivalent to NBS a (Shperberg et al. 2019a) apart from its pseudocode; we choose NBB because its bucket-based implementation is the basis for DBS and DBBS (described below). \u2022 DVCBS and DVCBS a . Developed by Shperberg et al. (2019a), the reported state of the art. \u2022 GBFHS and GBFHS e . GBFHS as in Barley et al. (2018), but it uses Pohl's cardinality criterion as the split function: when updating its g limits, GBFHS computes the number of expandable nodes on both open lists after increasing  06 5798 5703 0.86 94k 93k 0.96 482k 479k 0.70 937k 899k 0.20 1130k 1039k 0.02 1168k 1053k 0  DVCBS a 365 46 0 10681 4595 0.44 122k 83k 0.36 630k 452k 0.14 1060k 897k 0 1162k 1039k 0 1238k 1053k 0  GBFHS 988 42 0 58126 5190 0 717k 116k 0 1686k 632k 0 1080k 914k 0 1066k 1039k 0 1064k 1053k 0  GBFHS e 112 44 0 5226 5007 0 105k 104k 0 584k 581k 0 923k 913k 0 1063k 1039k 0 1081k 1053k  Table 1: Pancakes. Dashed entries mean that there were instances in which the solver ran out of memory. the g limit of either direction, and increases the limit that leads to having fewer expandable nodes. Initially the f limit is set to max(h f (start), h b (goal)) and both g limits are set to 0. All limits are increased by \u03b9 and not by 1. GBFHS can behave badly in the last layer, as it expands nodes such that f (n) = C * before increasing the g limits, delaying the collision. GBFHS e (eager GBFHS) increases the g limits as soon as the f limit is increased except in the initial step, losing some information when deciding which g limit to increase but allowing early collisions.\n\u2022 DBS and DBBS. DBS (d-using Bidirectional Search) uses g-f-d buckets and the g and KK bounds to delay nodes and prove optimality, and performs a fixpoint computation of all minimum node values. DBBS (d and busing Bidirectional Search) also uses the b bound. Both expand by minimum g and break ties by minimum f , and additionally among d buckets, by minimum d. We choose this because the most successful algorithms so far (NBB/NBS a , DVCBS and GBFHS) do so as well, and because we want to display how using additional bounds increasingly improves the performance of NBB. However, other criteria may be better both to raise C faster and to have a better last-layer tie-break. DBS (a) and DBBS (a) expand alternating directions like NBB, and thus retain near-optimality. DBS (p) and DBBS (p) use Pohl's cardinality criterion, but count only expandable nodes with minimum g, similar to DVCBS and GBFHS. \u2022 BAE*. Same as BS*, but the priority function uses b x (n) instead and the termination criterion is the b bound.\nExperiments show average total expanded nodes, average necessarily-expanded nodes (expanded when C < C * ) and the ratio of problems with no expansions in the last layer, that is, an optimal solution was found before C reached C * . For nodes, best results are in bold. NBS, NBB, DBS (a) and DBBS (a) are listed first, as they are near-optimal.\nTable 1 shows results for 100 random instances in the 14-Pancake Puzzle with the GAP heuristic (Helmert 2010). The first k pancakes of the target state are ignored to get an asymmetric weaker heuristic. In terms of necessarily-expanded nodes, DBS (a) is clearly stronger than NBB, the difference increasing as the heuristic degrades. DBBS expands fewer nodes than DBS, especially the (p) version for heuristics of intermediate strength. BAE * is very competitive for heuristics of intermediate strength, but the advantage of using the b bound decreases relative to the g bound for weak heuristics, and becomes the worst algorithm among the modern Bi-HS ones for GAP-6. DBS and DBBS keep a robust behavior thanks to their combination of bounds, and become the best algorithms for GAP-5 and GAP-6.\nWe also made the heuristic symmetric by abstracting the first k pancakes away using a relative-order abstraction (Helmert and R\u00f6ger 2010) and then computing GAP. We omit the results for lack of space, but DBBS in this case notably outperforms BAE * even for heuristics of intermediate strength. We hypothesize that, because the heuristic is symmetric and the search space is largely so as well, the best splits for all but the strongest heuristics will occur around the middle, in which case the g bound is most useful.    (Felner, Korf, and Hanan 2004). The KK bounds are very useful e.g. DBS (a) expands almost half of NBB's nodes with (10+2). The b bound is even stronger, making DBBS and BAE* the most efficient algorithms. BAE* has an edge over DBBS because it expands nodes by minimum b instead of minimum g, which raises C faster in this domain. As the heuristic degrades, DBS' advantage decreases, but DBBS and BAE* retain a substantial margin. The b bound seems to be more useful than the KK bounds because additive heuristics compensate for their weaknesses and avoid extreme fMin x and dM in x values, probably benefiting the averaging behavior of the b bound. Still, a deeper analysis is necessary to better understand this.   3 shows results for 100 instances of the 15 Sliding Tile Puzzle (Korf 1985) with Manhattan Distance. DBS (p) and DBBS (p) are much better than their alternating counterparts, which implies that the new bounds are useful in finding good splits too. Expanding by b like BAE * is very advantageous, but DBBS (p) is close despite expanding by g. DBS and DBBS expand many more total nodes than necessarilyexpanded nodes due to delayed nodes along optimal paths.\nTable 4 shows results for grid-based pathfinding benchmarks (Sturtevant 2012) with the octile heuristic, using mazes and Dragon Age: Origins (DAO) maps. Diagonal moves are allowed with a cost of 1.5, so costs are nonunitary. Mazes are built to misguide the heuristic, and indeed DBS, DBBS and BAE* are able to leverage this. DVCBS and GBFHS are negatively affected, with only GBFHS e able to find good splits. DAO maps are more conventional, and using heuristic inaccuracies is not much better than just using A*, although DBS and DBBS are still better than NBB.\nIn terms of nodes per second, using more dimensions in the open list and doing a fixpoint computation can affect performance. With a small range of node values (all unitarycost domains here), DBS and DBBS are not substantially slower. The opposite is true in Mazes and DAO, with a large range of node values. Here the algorithms that use a heap (A * , BS * , BAE * , NBS) are the fastest; those that use  bi-dimensional buckets (NBB, DVCBS, GBFHS) are up to 1 order of magnitude slower; those with three-dimensional buckets and fixpoint computation (DBS and DBBS) are up to 2 orders of magnitude slower. A preliminary analysis shows that the fixpoint computation ends on average after a few steps. However, a high range of node values means that the number of buckets is high (so iterating through them is costlier) and the buckets are smaller (so minimum node values are recomputed often). Nevertheless, results may be different when the bottleneck is the heuristic or the successor generation, like in automated planning. Also, more efficient implementations should be investigated and additional experimentation should find which bounds are worth using.\nRegarding total nodes, the new bounds often delay nodes on optimal paths e.g. in Pancake GAP-1, NBB explores the last layer only 8% of the time, but DBS (a) does it 94% of the time, with catastrophic results in terms of total nodes. GBFHS and DVCBS a display sometimes a very bad lastlayer behavior too. Hence, implementing RunTieBreaker() is an interesting alternative for these algorithms.\nOverall, BAE * stands out as the most efficient algorithm in the presented data. However, this does not mean that BAE * will always expand fewer nodes, as other priority functions may yield better results. For example, DBBS expanding by b and DBS expanding by f are often similar or better than BAE * e.g. in Sliding Tile Puzzle, the best domain for BAE * , DBS (a) by f expands 1806k necessarilyexpanded nodes, and DBBS (a) by b, 1701k, compared to BAE * 's 2700k. Time can also be improved by using fewer node values e.g. just g and b values. Unfortunately, both questions are out of scope here, and belong to future work.", "publication_ref": ["b15", "b5", "b0", "b22", "b22", "b3", "b10", "b9", "b7", "b14", "b24"], "figure_ref": [], "table_ref": ["tab_2", "tab_4", "tab_5"]}, {"heading": "Conclusions and Future Work", "text": "In this paper we have defined individual bounds within the lower-bound framework of bidirectional search. These bounds seamlessly integrate both modern techniques and techniques that for years remained hard to exploit. They generalize over Kaindl and Kainz's and Sadhukhan's works and are easy to understand and to exploit in modern Bi-HS algorithms. Results show a great leap in performance, breaking the limits imposed by near-optimality thanks to the use of heuristic inaccuracies and pushing the state of the art. Due to this and to how relatively simple it is to implement algorithms using the newer bounds, we personally argue that, if backward search is possible and consistent heuristics are available, front-to-end bidirectional search should be tried first over unidirectional algorithms like A * .\nTwo main lines of research are now open, one theoretical and one empirical: first, the must-expand pairs defined by Eckerle et al. (2017) and its derived definitions, like near-optimality, must be modified to work with individual bounds. Second, a thorough empirical analysis is necessary to understand when and why the different bounds are useful, which criteria to use to expand nodes (e.g. if the forward KK bound is the one raising C, expand by f forward and by d backward), how the last-layer behavior is different from the C-rising process, and how to modify newer algorithms (like NBS, DVCBS and GBFHS, arguably more complex than DBS and DBBS) to exploit the individual bounds.", "publication_ref": ["b6"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "A theoretical comparison of the bounds of MM, NBS, and GBFHS", "journal": "", "year": "2019", "authors": "V Alc\u00e1zar; M Barley; P J Riddle"}, {"ref_id": "b1", "title": "A case study of revisiting bestfirst vs. depth-first search", "journal": "", "year": "2004", "authors": "A Auer; H Kaindl"}, {"ref_id": "b2", "title": "Limitations of front-to-end bidirectional heuristic search", "journal": "", "year": "2015", "authors": "J K Barker; R E Korf"}, {"ref_id": "b3", "title": "GBFHS: A generalized breadth-first heuristic search algorithm", "journal": "", "year": "2018", "authors": "M W Barley; P J Riddle; C Linares L\u00f3pez; S Dobson; I Pohl"}, {"ref_id": "b4", "title": "Implementing fast heuristic search code", "journal": "", "year": "2012", "authors": "E A Burns; M Hatem; M J Leighton; W Ruml"}, {"ref_id": "b5", "title": "Frontto-end bidirectional heuristic search with near-optimal node expansions", "journal": "", "year": "2017", "authors": "J Chen; R C Holte; S Zilles; N R Sturtevant"}, {"ref_id": "b6", "title": "Sufficient conditions for node expansion in bidirectional heuristic search", "journal": "", "year": "2017", "authors": "J Eckerle; J Chen; N R Sturtevant; S Zilles; R C Holte"}, {"ref_id": "b7", "title": "Additive pattern database heuristics", "journal": "JAIR Journal of Artificial Intelligence Research", "year": "2004", "authors": "A Felner; R E Korf; S Hanan"}, {"ref_id": "b8", "title": "A formal basis for the heuristic determination of minimum cost paths", "journal": "IEEE Transactions on Systems Science and Cybernetics", "year": "1968", "authors": "P E Hart; N J Nilsson; B Raphael"}, {"ref_id": "b9", "title": "Relative-order abstractions for the pancake problem", "journal": "", "year": "2010", "authors": "M Helmert; G R\u00f6ger"}, {"ref_id": "b10", "title": "Landmark heuristics for the pancake problem", "journal": "", "year": "2010", "authors": "M Helmert"}, {"ref_id": "b11", "title": "MM: A bidirectional search algorithm that is guaranteed to meet in the middle", "journal": "Artif. Intell", "year": "2017", "authors": "R C Holte; A Felner; G Sharon; N R Sturtevant; J Chen"}, {"ref_id": "b12", "title": "Bidirectional heuristic search reconsidered", "journal": "J. Artif. Intell. Res", "year": "1997", "authors": "H Kaindl; G Kainz"}, {"ref_id": "b13", "title": "Switching from bidirectional to unidirectional search", "journal": "", "year": "1999", "authors": "H Kaindl; G Kainz; R Steiner; A Auer; K Radda"}, {"ref_id": "b14", "title": "Depth-first iterative-deepening: An optimal admissible tree search", "journal": "Artif. Intell", "year": "1985", "authors": "R E Korf"}, {"ref_id": "b15", "title": "BS*: An admissible bidirectional staged heuristic search algorithm", "journal": "Artif. Intell", "year": "1989", "authors": "J B H Kwa"}, {"ref_id": "b16", "title": "Bi-directional and heuristic search in path problems", "journal": "Ph.D. Dissertation, Stanford Linear Accelerator Center", "year": "1969", "authors": "I Pohl"}, {"ref_id": "b17", "title": "A new approach to bidirectional heuristic search using error functions", "journal": "", "year": "2012", "authors": "S K Sadhukhan"}, {"ref_id": "b18", "title": "Bidirectional heuristic search using error estimate", "journal": "CSI Journal of Computing", "year": "2013", "authors": "S K Sadhukhan"}, {"ref_id": "b19", "title": "Letter to the editor -corrections", "journal": "CSI Journal of Computing", "year": "2015", "authors": "S K Sadhukhan"}, {"ref_id": "b20", "title": "The minimal set of states that must be expanded in a front-to-end bidirectional search", "journal": "", "year": "2017", "authors": "E Shaham; A Felner; J Chen; N R Sturtevant"}, {"ref_id": "b21", "title": "Minimizing node expansions in bidirectional search with consistent heuristics", "journal": "", "year": "2018", "authors": "E Shaham; A Felner; N R Sturtevant; J S Rosenschein"}, {"ref_id": "b22", "title": "Enriching non-parametric bidirectional search algorithms", "journal": "", "year": "2019", "authors": "S Shperberg; A Felner; N R Sturtevant; A Hayoun; E S Shimony"}, {"ref_id": "b23", "title": "Improving bidirectional heuristic search by bound propagation", "journal": "", "year": "2019", "authors": "S S Shperberg; A Felner; N R Sturtevant; S E Shimony; A Hayoun"}, {"ref_id": "b24", "title": "Benchmarks for grid-based pathfinding", "journal": "IEEE Trans. Comput. Intellig. and AI in Games", "year": "2012", "authors": "N R Sturtevant"}, {"ref_id": "b25", "title": "Robust bidirectional search via heuristic improvement", "journal": "", "year": "2013", "authors": "C M Wilt; W Ruml"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "F1Figure 1 :1Figure 1: Example of fixpoint computation of minimum node values. First number is f value, second is g value. Assume C = 7, = \u03b9 = 1; initially gMin f = 1, fMin f = 7, gMin b = 2 and fMin b = 7. The following steps are done: \u2022 F2 and G1 are delayed by the f bounds, because f f (F 2) > C and f b (G1) > C. Thus, gMin f = 4 and gMin b = 6.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 is the original figure that shows how KKAdd is computed.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "which corresponds to KKMax b (n ). This allows us to define two KK bounds, one per direction. Definition 5. (KK bounds). The forward KK bound is defined as fMin f + dMin b . The backward KK bound is defined as fMin b + dMin f .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "This can be represented by a single node value, which we define as b. Definition 6. (b value of a node). The b value of a node n is defined as b x", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Corollary 1. (Consistency of the b value). If h f and h b are consistent, b is monotonically increasing along paths, and expanding by minimum b ensures that the g value of a node upon expansion is optimal. bMin x is then the minimum b value among all expandable nodes in Open x . Reformulating BAE * 's global lower bound, we can define a new bound: the b bound. Definition 7. (b bound). The b bound is defined as (bMin f + bMin b )/2 rounded up to the next multiple of \u03b9, that is, \u03b9 (bMin f + bMin b )/2 \u03b9 . The corresponding delaying rule using the individual b bound is b x (n) > 2C \u2212 bMinx. A proof of the admissibility of the b bound can be produced from BAE * 's own proofs, but here we will prove it using Kaindl and Kainz's terms to offer an alternative and hopefully clearer picture on the relationship between BAE * and Kaindl and Kainz's work. Theorem 2. (Admissibility of the b bound). If a problem has a solution and C = C * , the b bound will not delay a node belonging to a path of cost C. Proof. Let n \u2208 Open x and n \u2208 Openx be expandable nodes at layer C such that b f (n) = bMin f and b b (n ) =", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Assume that S, G, M f , and M b have been expanded, so a solution of cost U = 3 has been found. All nodes n in S 1 have f f (n) = 2 and d f (n) = 0; all nodes n in G 1 have f b (n ) = 1 and d b (n ) = 1. In this case, fMin f = 2, dMin f = 0, bMin f = 2, fMin b = 1, dMin b = 1 and bMin b = 2, so the value of the forward KK bound is fMin f +dMin b = 3, and the value of the b bound is", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 4 :4Figure 4: The forward KK bound is higher than the b bound.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 5 :5Figure 5: The b bound is higher than either KK bound.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 55Figure 5 shows the opposite case. Assume that S, S', G and G' have been expanded, and a solution of cost U = 4 has been found. S 1 contains nodes such that f f (n) = 3 and d f (n) = 1 and such that f f (n) = 2 and d f (n) = 2, and similarly G 1 contains nodes such that f b (n) = 3 and d b (n) = 1 and such that f b (n) = 2 and d b (n) = 2. Thus, fMin f = 2, dMin f = 1, bMin f = 4, fMin b = 2, dMin b = 1 and bMin b = 4, so the value of either KK bound is fMin x + dMinx = 3, and the value of the b bound is (bMin f + bMin b )/2 = 4. The b bound proves optimality, as C = U = 4, but if only the KK bounds are used an arbitrary number of additional nodes will have to be expanded.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "111k 0.96 620k 617k 0.98 1346k 1345k 0.94 1598k 1598k 0.84 1626k 1622k 0.54 DBS (a) 521 58 0.06 23724 3308 0.06 163k 54k 0.14 425k 289k 0.20 549k 510k 0.28 665k 628k 0.30 786k 717k 0.28 DBBS (a) 521 58 0.06 13924 1780 0.12 136k 40k 0.16 404k 240k 0.22 544k 486k 0.28 664k 617k 0.30 786k 711k 0", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "293 45 0.02 9027 2672 0.28 81k 46k 0.24 317k 250k 0.30 512k 464k 0.30 667k 617k 0.24 794k 718k 0.28 DBBS (p) 293 45 0.02 4110 902 0.22 34k 21k 0.48 230k 170k 0.44 474k 430k 0.36 649k 587k 0.36 791k 702k 0.22", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Algorithm ToH-12 (10+2) ToH-12 (8+4) ToH-12 (6+6) NBS 233k 233k 1 654k 653k 0.94 682k 663k 0.56 NBB 230k 230k 0.98 645k 645k 0.90 678k 662k 0.56 DBS (a) 140k 118k 0.38 531k 488k 0.12 640k 606k 0.14 DBBS (a) 70k 66k 0.74 307k 286k 0.52 621k 583k 0p) 46k 45k 0 185k 182k 0 375k 374k 0 DBS (p) 113k 105k 0.70 463k 443k 0.58 601k 570k 0.24 DBBS (p) 58k 54k 0.80 232k 221k 0.66 496k 479k 0.58", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Open f \u21d0 {start}; Open b \u21d0 {goal} 3: while Open f = \u2205 \u2227 Open b = \u2205 do", "figure_data": "Algorithm 1 Main Lower Bound Loop1: U \u21d0 \u221e; C \u21d0 02: 4:if UpdateC() then5:RunTieBreaker()6:end if7:if C \u2265 U then8:return U9:end if10:Expand()11: end while12: return U"}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "while C < max(gMin f + gMin b + , fMin f , fMin b ) do", "figure_data": "Algorithm 2 UpdateC1: updated \u21d0 False2: 3:"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Towers of Hanoi", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": "shows results for 50 instances of the 12-disk4-peg Towers of Hanoi problem with (10+2), (8+4) and"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Sliding Tile PuzzleTable", "figure_data": ""}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Grids    ", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "f (n) = h f (s, goal), h b (n) = h b (s, start) and f x (n) = g x (n) + h x (n). For g f (n) and g b (n) to be optimal, g f (n) = c(start, s) and g b (n) = c(s, goal) respectively. h f and h b are admissible iff, for any state s \u2208 S, h f (s) \u2264 c(s, goal) and h b (s) \u2264 c(start, s) respectively. h x is consistent iff it is admissible and h x (n) \u2264 c(n, n ) + h x (n ) for any pair of nodes n, n .", "formula_coordinates": [2.0, 54.0, 312.75, 238.5, 76.46]}, {"formula_id": "formula_1", "formula_text": ") + g b (n ) + , f f (n), f b (n )).", "formula_coordinates": [2.0, 323.54, 317.28, 234.44, 21.67]}, {"formula_id": "formula_2", "formula_text": "C \u21d0 C + \u03b9 4: updated \u21d0 True 5:", "formula_coordinates": [3.0, 324.48, 251.61, 86.95, 31.25]}, {"formula_id": "formula_3", "formula_text": "d x (n) = g x (n) \u2212 hx(n).", "formula_coordinates": [3.0, 362.11, 515.56, 99.86, 10.71]}, {"formula_id": "formula_4", "formula_text": "KKAdd x (n) = f x (n) + dMinx.", "formula_coordinates": [3.0, 319.5, 606.86, 127.19, 10.71]}, {"formula_id": "formula_5", "formula_text": "fMin f + d b (n ) > C,", "formula_coordinates": [4.0, 54.0, 476.77, 90.45, 11.77]}, {"formula_id": "formula_6", "formula_text": "C < max(gMin f + gMin b + , fMin f + dMin b , fMin b + dMin f ) (1)", "formula_coordinates": [4.0, 87.94, 573.48, 204.56, 27.34]}, {"formula_id": "formula_7", "formula_text": "x (n) = FE x (n) + BE x (n) = (g x (n) + h x (n) \u2212 h 0 ) + (g x (n) \u2212 hx(n)),", "formula_coordinates": [4.0, 319.5, 180.71, 238.5, 21.67]}, {"formula_id": "formula_8", "formula_text": "TE x (n) + h 0 = f x (n) + d x (n).", "formula_coordinates": [4.0, 319.5, 282.54, 128.81, 10.71]}, {"formula_id": "formula_9", "formula_text": "(n) = f x (n) + d x (n).", "formula_coordinates": [4.0, 371.4, 319.07, 89.23, 10.71]}, {"formula_id": "formula_10", "formula_text": "n, n \u2208 P . The sum b f (n) + b b (n ) can be decom- posed as f f (n) + d f (n) + f b (n ) + d b (n )", "formula_coordinates": [5.0, 63.96, 95.38, 228.54, 21.67]}, {"formula_id": "formula_11", "formula_text": "f f (n) + d b (n ) \u2264 C * and f b (n ) + d f (n) \u2264 C * . Hence, f f (n) + d b (n ) + f b (n ) + d f (n) \u2264 2C, so b f (n) + b b (n ) \u2264 2C and thus b f (n) \u2264 2C \u2212 bMin b and b b (n ) \u2264 2C \u2212 bMin f", "formula_coordinates": [5.0, 63.96, 126.89, 228.54, 44.96]}, {"formula_id": "formula_12", "formula_text": "C < max(gMin f + gMin b + , fMin f + dMin b , fMin b + dMin f , \u03b9 (bMin f + bMin b )/2 \u03b9 )(2)", "formula_coordinates": [5.0, 88.49, 329.32, 204.01, 53.74]}, {"formula_id": "formula_13", "formula_text": "(bMin f + M f M b G S \u2190 \u2192 0 \u2190 \u2192 0 G 1 \u2190 \u2192 1 \u2190 \u2192 1 S 1", "formula_coordinates": [5.0, 254.45, 57.26, 275.42, 647.98]}, {"formula_id": "formula_14", "formula_text": "\u2190 \u2192 0 \u2190 \u2192 1 G 1 \u2190 \u2192 0 \u2190 \u2192 1 S 1 U=4", "formula_coordinates": [5.0, 330.61, 223.43, 216.27, 67.05]}], "doi": ""}