{"title": "An LP View of the M-best MAP problem", "authors": "Menachem Fromer; Amir Globerson", "pub_date": "", "abstract": "We consider the problem of finding the M assignments with maximum probability in a probabilistic graphical model. We show how this problem can be formulated as a linear program (LP) on a particular polytope. We prove that, for tree graphs (and junction trees in general), this polytope has a particularly simple form and differs from the marginal polytope in a single inequality constraint. We use this characterization to provide an approximation scheme for non-tree graphs, by using the set of spanning trees over such graphs. The method we present puts the M -best inference problem in the context of LP relaxations, which have recently received considerable attention and have proven useful in solving difficult inference problems. We show empirically that our method often finds the provably exact M best configurations for problems of high tree-width.", "sections": [{"heading": "", "text": "A common task in probabilistic modeling is finding the assignment with maximum probability given a model. This is often referred to as the MAP (maximum a-posteriori) problem. Of particular interest is the case of MAP in graphical models, i.e., models where the probability factors into a product over small subsets of variables. For general models, this is an NP-hard problem [11], and thus approximation algorithms are required. Of those, the class of LP based relaxations has recently received considerable attention [3,5,18]. In fact, it has been shown that some problems (e.g., fixed backbone protein design) can be solved exactly via sequences of increasingly tighter LP relaxations [13].\nIn many applications, one is interested not only in the MAP assignment but also in the M maximum probability assignments [19]. For example, in a protein design problem, we might be interested in the M amino acid sequences that are most stable on a given backbone structure [2]. In cases where the MAP problem is tractable, one can devise tractable algorithms for the M best problem [8,19]. Specifically, for low tree-width graphs, this can be done via a variant of max-product [19]. However, when finding MAPs is not tractable, it is much less clear how to approximate the M best case. One possible approach is to use loopy max-product to obtain approximate max-marginals and use those to approximate the M best solutions [19]. However, this is largely a heuristic and does not provide any guarantees in terms of optimality certificates or bounds on the optimal values. LP approximations to MAP do enjoy such guarantees. Specifically, they provide upper bounds on the MAP value and optimality certificates. Furthermore, they often work for graphs with large tree-width [13]. The goal of the current work is to leverage the power of LP relaxations to the M best case. We begin by focusing on the problem of finding the second best solution. We show how it can be formulated as an LP over a polytope we call the \"assignment-excluding marginal polytope\". In the general case, this polytope may require an exponential number of inequalities, but we prove that when the graph is a tree it has a very compact representation. We proceed to use this result to obtain approximations to the second best problem, and show how these can be tightened in various ways. Next, we show how M best assignments can be found by relying on algorithms for second best assignments, and thus our results for the second best case can be used to devise an approximation algorithm for the M best problem.\nWe conclude by applying our method to several models, showing that it often finds the exact M best assignments.\n1 The M-best MAP problem and its LP formulation Consider a function on n variables defined as:\nf (x 1 , . . . , x n ; \u03b8) = ij\u2208E \u03b8 ij (x i , x j ) + i\u2208V \u03b8 i (x i ) (1)\nwhere V and E are the vertices and nodes of a graph G with n nodes. We shall be interested in the M assignments with largest f (x; \u03b8) value. 1 Denote these by x (1) , . . . , x (M) , so that\nx (1) is the assignment that maximizes f (x; \u03b8), x (2) is the 2 nd best assignment, etc.\nThe MAP problem (i.e., finding x (1) ) can be formulated as an LP as follows [15]. Let \u00b5 be a vector of distributions that includes {\u00b5 ij (x i , x j )} ij\u2208E over edge variables and {\u00b5 i (x i )} i\u2208V over nodes. The set of \u00b5 that arise from some joint distribution is known as the marginal polytope [15] and is denoted by M(G). Formally:\nM(G) = {\u00b5 | \u2203p(x) \u2208 \u2206 s.t. p(x i , x j ) = \u00b5 ij (x i , x j ) , p(x i ) = \u00b5 i (x i )} .\nwhere \u2206 is the set of distributions on x. The MAP problem can then be shown to be equivalent to the following LP:\n2 max x f (x; \u03b8) = max \u00b5\u2208M(G) \u00b5 \u2022 \u03b8 ,(2)\nIt can be shown that this LP always has a maximizing \u00b5 that is a vertex of M(G) and is integral. Furthermore, this \u00b5 corresponds to the MAP assignment x (1) . Although the number of variables in this LP is only O(|E| + |V |), the difficulty comes from an exponential number of linear inequalities generally required to describe the marginal polytope M(G).\nWe shall find it useful to define a mapping between assignments x and integral vertices of the polytope. Given an integral vertex v \u2208 M(G), define x(v) to be the assignment that maximizes v i (x i ). And, given an assignment z define v(z) to be the integral vertex in M(G) corresponding to the assignment z. Thus the LP in Eq. 2 will be maximized by v(x (1) ).\nOne simple outer bound of the marginal polytope is the local polytope M L (G), which only enforces pairwise constraints between variables:\nM L (G) = \uf8f1 \uf8f2 \uf8f3 \u00b5 \u2265 0 xj \u00b5 ij (x i , x j ) = \u00b5 i (x i ), xi \u00b5 ij (x i , x j ) = \u00b5 j (x j ), xi \u00b5 i (x i ) = 1 \uf8fc \uf8fd \uf8fe (3)\nThe LP relaxation is then to maximize \u00b5 \u2022 \u03b8 where \u00b5 \u2208 M L (G). For tree structured graphs, M L (G) = M(G) [15] and thus the LP relaxation yields the exact MAP x (1) .\n2 An LP Formulation for the 2 nd -best MAP Assume we found the MAP assignment x (1) and are now interested in finding x (2) . Is there a simple LP whose solution yields x (2) ? We begin by focusing on the case where G is a tree so that the local LP relaxation is exact. We first treat the case of a connected tree.\nTo construct an LP whose solution is x (2) , a natural approach is to use the LP for x (1) (i.e., the LP in Eq. 2) but somehow eliminate the solution x (1) using additional constraints. This, however, is somewhat trickier than it sounds. The key difficulty is that the new constraints should not generate fractional vertices, so that the resulting LP is still exact.\nWe begin by defining the polytope over which we need to optimize in order to obtain x (2) .\n1 This is equivalent to finding the maximum probability assignments for a model p(x) \u221d e f (x;\u03b8) . 2 We use the notation\n\u00b5 \u2022 \u03b8 = P ij\u2208E P x i ,x j \u00b5ij (xi, xj)\u03b8ij(xi, xj) + P i P x i \u00b5i(xi)\u03b8i(xi)\nDefinition 1. The assignment-excluding marginal polytope is defined as:\nM(G, z) = {\u00b5 | \u2203p(x) \u2208 \u2206 s.t. p(z) = 0, p(x i , x j ) = \u00b5 ij (x i , x j ), p(x i ) = \u00b5 i (x i )} . (4)\nM(G, z) is simply the convex hull of all (integral) vectors v(x) for x = z.\nThe following result shows that optimizing overM(G, x (1) ) will yield the second best solution x (2) , so that we refer toM(G, x (1) ) as the second-best marginal polytope. Lemma 1. The 2 nd best solution is obtained via the following LP:\nmax x =x (1) f (x; \u03b8) = max \u00b5\u2208M(G,x (1)\n) \u00b5 \u2022 \u03b8. Furthermore, the \u00b5 that maximizes the LP on the right is integral and corresponds to the second-best MAP assignment x (2) .\nThe proof is similar to that of Eq. 2: instead of optimizing over x, we optimize over distributions p(x), while enforcing that p(x (1) ) = 0 so that x (1) is excluded from the maximization.\nThe key question which we now address is how to obtain a simple characterization of M(G, z). Intuitively, it would seems thatM(G, z) should be \"similar\" to M(G), such that it can be described as M(G) plus some constraints that \"block\" the assignment z.\nTo illustrate the difficulty in finding such \"blocking\" constraints, consider the following constraint, originally suggested by Santos [10]:\ni \u00b5 i (z i ) \u2264 n \u2212 1.\nThis inequality is not satisfied by \u00b5 = v(z) since v(z) attains the value n for the LHS of the above. Furthermore, for any x = z and \u00b5 = v(x), the LHS would be n \u2212 1 or less. Thus, this inequality separates v(z) from all other integral vertices. One might conclude that we can defineM(G, z) by adding this inequality to M(G). The difficulty is that the resulting polytope has fractional vertices, 3 and maximizing over it won't generally yield an integral solution.\nIt turns out that there is a different inequality that does yield an exact characterization of M(G, z) when G is a tree. We now define this inequality and state our main theorem. Definition 2. Consider the functional I(\u00b5, z) (which is linear in \u00b5):\nI(\u00b5, z) = i (1 \u2212 d i )\u00b5 i (z i ) + ij\u2208E \u00b5 ij (z i , z j ) (5)\nwhere d i is the degree of node i in the tree graph G. Theorem 1. Adding the single inequality\nI(\u00b5, z) \u2264 0 to M(G) yieldsM(G, z). M(G, z) = {\u00b5 | \u00b5 \u2208 M(G), I(\u00b5, z) \u2264 0 } (6)\nThe theorem is proved in the appendix. Taken together with Lemma 1, it implies that x (2) may be obtained via an LP that is very similar to the MAP-LP, but has an additional constraint. We note the interesting similarity between I(\u00b5, z) and the Bethe entropy [20]. The only difference is that in Bethe, \u00b5 i , \u00b5 ij are replaced by H(X i ), H(X i , X j ) respectively. 4 The theorem also generalizes to the case where G is not a tree, but we have a junction tree for G. In this case, the theorem still holds if we define a generalized I(\u00b5, z) inequality as:\nS\u2208S (1 \u2212 d S )\u00b5 S (z S ) + C\u2208C \u00b5 C (z C ) \u2264 0 (7)\nwhere C and S are the junction tree cliques and their separators, respectively, and d S is the number of cliques that intersect on separator S. In this case, the marginal polytope should enforce consistency between marginals \u00b5 C (z C ) and their separators \u00b5 S (z S ). However, such a characterization requires variables whose cardinality is exponential in the tree-width and is thus tractable only for graphs of low tree-width. In the next section, we address approximations for general graphs.\nA corresponding result exists for the case when G is a forest. In this case, the inequality in Eq. 6 is modified to: I(\u00b5, z) \u2264 |P | \u2212 1, where |P | denotes the number of connected components of G. Interestingly, for a graph without edges, this gives the Santos inequality.\n3 2 nd best LPs for general graphs -Spanning tree inequalities\nWhen the graph G is not a tree, the marginal polytope M(G) generally requires an exponential number of inequalities. However, as mentioned above, it does have an exact description in terms of marginals over cliques and separators of a junction tree. Given such marginals on junction tree cliques, we also have an exact characterization ofM(G, z) via the constraint in Eq. 7. However, in general, we cannot afford to be exponential in tree-width. Thus a common strategy [15] is to replace M(G) with an outer bound that enforces consistency between marginals on overlapping sets of variables. The simplest example is M L (G) in Eq. 3.\nIn what follows, we describe an outer-bound approximation scheme forM(G, z). We use M L (G) as the approximation for M(G) (more generally M L (G) can enforce consistency between any set of small regions, e.g., triplets). When G is not a tree, the linear constraint in Eq. 6 will no longer suffice to deriveM(G, z). Moreover, direct application of the inequality will incorrectly remove some integral vertices. An alternative approach is to add inequalities that separate v(z) from the other integral vertices. This will serve to eliminate more and more fractional vertices, and if enough constraints are added, this may result in an integral solution. One obvious family of such constraints are those corresponding to spanning trees in G and have the form of Eq. 5. Definition 3. Consider any T that is a spanning tree of G. Define the functional I T (\u00b5, z):\nI T (\u00b5, z) = i (1 \u2212 d T i )\u00b5 i (z i ) + ij\u2208T \u00b5 ij (z i , z j ) (8)\nwhere d T i is the degree of i in T . We refer to I T (\u00b5, z) \u2264 0 as a spanning tree inequality.\nFor any sub-tree T of G, the corresponding spanning tree inequality separates the vertex v(z) from the other vertices. This can be shown via similar arguments as in the proof of Theorem 1. Note, however, that the resulting polytope may still have fractional vertices.\nThe above argument shows that any spanning tree provides a separating inequality for M(G, z). In principle, we would like to use as many such inequalities as possible.\nDefinition 4. The spanning tree assignment-excluding marginal polytope is defined as:\nM ST L (G, z) = \u00b5 | \u00b5 \u2208 M L (G), \u2200 tree T \u2286 E I T (\u00b5, z) \u2264 0 (9)\nwhere the ST notation indicates the inclusion of all spanning tree inequalities for G. 5 Thus, we would actually like to perform the following optimization problem: max\n\u00b5\u2208M ST L (G,z) \u00b5\u2022\u03b8\nas an approximation to optimization overM(G, z); i.e., we seek the optimal \u00b5 subject to all spanning tree inequalities for G with the ambition that this \u00b5 be integral and thus provide the non-z MAP assignment, with a certificate of optimality.\nAlthough the number of spanning trees is exponential in n, it turns out that all spanning inequalities can be used in practice. One way to achieve this is via a cutting plane algorithm [12] that finds the most violated spanning tree inequality and adds it to the LP. To implement this efficiently, we note that for a particular \u00b5 and a spanning tree T , the value of I T (\u00b5, z) can be decomposed into a sum over the edges in T (and a T -independent constant):\nI T (\u00b5, z) = ij\u2208T \u00b5 ij (z i , z j ) \u2212 \u00b5 i (z i ) \u2212 \u00b5 j (z j ) + i \u00b5 i (z i ) (10\n)\nThe tree maximizing the above is the maximum-weight spanning tree with edge-weights\nw ij = \u00b5 ij (z i , z j ) \u2212 \u00b5 i (z i ) \u2212 \u00b5 j (z j )\n. It can thus be found efficiently.\nThe cutting plane algorithm proceeds as follows. We start by adding an arbitrary spanning tree. Then, as long as the optimal \u00b5 is fractional, we find the spanning tree inequality that \u00b5 most violates (where this is implemented via the maximum-weight spanning tree). This constraint will necessarily remove \u00b5 from the polytope. If there are no violated inequalities but \u00b5 is still fractional, then spanning tree inequalities do not suffice to find an integral solution (but see below on hypertree constraints to add in this case). In practice, we found that only a relatively small number of inequalities are needed to successfully yield an integral solution, or determine that all such inequalities are already satisfied.\nAn alternative approach for solving the all spanning-tree problem is to work via the dual.\nThe dual variables roughly correspond to points in the spanning tree polytope [16], optimization over which can be done in polynomial time, e.g., via the ellipsoid algorithm. We do not pursue this here since the cutting plane algorithm performed well in our experiments.\nAs mentioned earlier, we can exactly characterizeM(G, z) using Eq. 7, albeit at a cost exponential in the tree-width of the graph. A practical compromise would be to use inequalities over clique trees of G, where the cliques are relatively small, e.g., triplets. The corresponding constraint (Eq. 7 with the small cliques and their separators) will necessarily separate v(z) from the other integral vertices. Finding the maximally violated such inequality is an NP-hard problem, equivalent to a prize collecting Steiner tree problem, but recent work has found that such problems are often exactly solvable in practice [7]. It thus might be practical to include all such trees as constraints using a cutting plane algorithm.\n4 From 2 nd -best to M-best\nThus far, we only dealt with the 2 nd best case. As we show now, it turns out that the 2 nd -best formalism can be used to devise an algorithm for M best. We begin by describing an algorithm for the exact M best and then show how it can be used to approximate those via the approximations for 2 nd best described above. Fig. 1 describes our scheme, which we call Partitioning for Enumerating Solutions (or PES) for solving the M best problem. The scheme is general and only assumes that MAP-\"like\" problems can be solved. It is inspired by several pre-existing M best solution schemes [4,6,8,19] but differs from them in highlighting the role of finding a second best solution within a given subspace. \n) : * ) is the MAP in the sub-space defined by CONSTRAINTS: Run MAP solver to obtain the second-best solution: y \u2261 arg max\nx (m) i = x (k) i } CONSTRAINTS m \u2190 CONSTRAINTS k \u222a {xv = a} // Eliminate x (k) (as MAP) from subspace m CONSTRAINTS k \u2190 CONSTRAINTS k \u222a {xv = a} // Eliminate x (m) (as 2 nd -best) from subspace k y (k) \u2190 CalcNextBestSolution(CONSTRAINTS k , x (k) ) end y (m) \u2190 CalcNextBestSolution(CONSTRAINTS m , x (m) ) end return {x (m) } M m=1 /* Find next best solution in sub-space defined by CONSTRAINTS */ Function CalcNextBestSolution(CONSTRAINTS, x ( * ) ) // x (\nx =x ( * ) ,CONSTRAINTS f (x; \u03b8), and return y.  solver can be plugged into it, on the condition that it is capable of solving the arg max in the CalcNextBestSolution subroutine. The correctness of PES can be shown by observing that at the M th stage, all previous best solutions are excluded from the optimization and no other assignment is excluded. Of note, this simple partitioning scheme is possible due to the observation that the first-best and second-best MAP assignments must differ in the assignment of at least one variable in the graph.\nThe main computational step of the PES algorithm is to maximize f (x; \u03b8) subject to x = x ( * ) and x \u2208 CONSTRAINTS (see the CalcNextBestSolution subroutine). The CONSTRAINTS set merely enforces that some of the coordinates of x are either equal to or different from specified values. 6 Within the LP, these can be enforced by setting \u00b5 i (x i = a) = 1 or \u00b5 i (x i = a) = 0. It can be shown that if one optimizes \u00b5 \u2022 \u03b8 with these constraints and \u00b5 \u2208M(G, x ( * ) ), the solution is integral. Thus, the only element requiring approximation in the general case is the description ofM(G, x ( * ) ). We choose as this approximation the polytopeM ST L (G, x ( * ) ) in Eq. 9. We call the resulting approximation algorithm Spanning TRee Inequalities and Partitioning for Enumerating Solutions, or STRIPES. In the next section, we evaluate this scheme experimentally.", "publication_ref": ["b10", "b2", "b4", "b17", "b12", "b18", "b1", "b7", "b18", "b18", "b18", "b12", "b0", "b0", "b0", "b1", "b0", "b14", "b14", "b0", "b0", "b14", "b0", "b0", "b1", "b1", "b1", "b0", "b1", "b1", "b0", "b1", "b0", "b1", "b0", "b0", "b9", "b2", "b1", "b19", "b3", "b14", "b2", "b4", "b11", "b15", "b6", "b3", "b5", "b7", "b18", "b5"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Experiments", "text": "We compared the performance of STRIPES to the BMMF algorithm [19] and the Lawler/Nilsson algorithm [6,8]. Nilsson's algorithm is equivalent to PES where the 2 nd best assignment is obtained from maximizations within O(n) partitions, so that its runtime is O(n) times the cost of finding a single MAP. Here we approximated each MAP with its LP relaxation (as in STRIPES), so that both STRIPES and Nilsson come with certificates of optimality when their LP solutions are integral. BMMF relies on loopy BP to approximate the M best solutions. 7 We used M = 50 in all experiments. To compare the algorithms, we pooled all their solutions, noting the 50 top probabilities, and then counted the fraction of these that any particular algorithm found (its solution rank). For run-time comparisons, we normalized the times by the longest-running algorithm for each example.\nWe begin by considering pairwise MRFs on binary grid graphs of size 10 \u00d7 10. In the first experiment, we used an Ising model with attractive (submodular) potentials, a setting in which the pairwise LP relaxation is exact [14]. For each grid edge ij, we randomly chose J ij \u2208 [0, 0.5], and local potentials were randomized in the range \u00b10.5. The results for 25 graphs are shown in Fig. 2. Both the STRIPES and Nilsson algorithms obtained the 50 optimal solutions (as learned from their optimality certificates), while BMMF clearly fared less well for some of the graphs. While the STRIPES algorithm took < 0.5 to 2 minutes to run, the Nilsson algorithm took around 13 minutes. On the other hand, BMMF was quicker, taking around 10 seconds per run, while failing to find a significant portion of the top solutions. Overall, the STRIPES algorithm was required to employ up to 19 spanning tree inequalities per calculation of second-best solution.\nNext, we studied Ising models with mixed interaction potentials (with J ij and the local potentials randomly chosen in [\u22120.5, 0.5]). For almost all of the 25 models, all three algorithms were not able to successfully find the top solutions. Thus, we added regions of triplets (two for every grid face) to tighten the LP relaxation (for STRIPES and Nilsson) and to perform GBP instead of BP (for BMMF). This resulted in STRIPES and Nilsson always provably finding the optimal solutions, and BMMF mostly finding these solutions (Fig. 2). For these more difficult grids, however, STRIPES was the fastest of the algorithms, taking 0.5 -5 minutes. On the other hand, the Nilsson and BMMF algorithms took 18 minutes and 2.5 -7 minutes, respectively. STRIPES added up to 23 spanning tree inequalities per iteration.\nThe protein side-chain prediction (SCP) problem is to to predict the placement of amino acid side-chains given a protein backbone [2,18]. Minimization of a protein energy function corresponds to finding a MAP assignment for a pairwise MRF [19]. We employed the dataset of [18] (up to 45 states per variable, mean approximate tree-width 50), running all algorithms to calculate the optimal side-chain configurations. For 315 of 370 problems in the dataset, the first MAP solution was obtained directly as a result of the LP relaxation having an integral solution (\"easy\" problems). STRIPES provably found the subsequent top 50 solutions within 4.5 hours for all but one of these cases (up to 8 spanning trees per calculation), and BMMF found the same 50 solutions for each case within 0.5 hours; note that only STRIPES provides a certificate of optimality for these solutions. On the other hand, only for 146 of the 315 problems was the Nilsson method able to complete within five days; thus, we do not compare its performance here. For the remaining 55 (\"hard\") problems (Fig. 2), we added problem-specific triplet regions using the MPLP algorithm [13]. We then ran the STRIPES algorithm to find the optimal solutions. Surprisingly, it was able to exactly find the 50 top solutions for all cases, using up to 4 standard spanning tree inequalities per second-best calculation. The STRIPES run-times for these problems ranged from 6 minutes to 23 hours. On the other hand, whether running BMMF without these regions (BP) or with the regions (GBP), it did not perform as well as STRIPES in terms of the number of high-ranking solutions or its speed. To summarize, STRIPES provably found the top 50 solutions for 369 of the 370 protein SCP problems.", "publication_ref": ["b18", "b5", "b7", "b6", "b13", "b1", "b17", "b18", "b17", "b12"], "figure_ref": [], "table_ref": []}, {"heading": "Conclusion", "text": "In this work, we present a novel combinatorial objectM(G, z) and show its utility in obtaining the M best MAP assignments. We provide a simple characterization of it for tree structured graphs, and show how it can be used for approximations in non-tree graphs. As with the marginal polytope, many interesting questions arise about the properties of M(G, z). For example, in which non-tree cases can we provide a compact characterization (e.g., as for the cut-polytope for planar graphs [1]). Another compelling question is in which problems the spanning tree inequalities are provably optimal.\nAn interesting generalization of our method is to predict diverse solutions satisfying some local measure of \"distance\" from each other, e.g., as in [2].\nHere we studied the polytope that results from excluding one assignment. An intriguing question is to characterize the polytope that excludes M assignments. We have found that it does not simply correspond to adding M constraints I(\u00b5, z i ) \u2264 0 for i = 1, . . . , M , so its geometry is apparently more complicated than that ofM(G, z).\nHere we used LP solvers to solve for \u00b5. Such generic solvers could be slow for large-scale problems. However, in recent years, specialized algorithms have been suggested for solving MAP-LP relaxations [3,5,9,17]. These use the special form of the constraints to obtain local-updates and more scalable algorithms. We intend to apply these schemes to our method. Finally, our empirical results show that our method indeed leverages the power of LP relaxations and yields exact M best optimal solutions for problems with large tree-width.", "publication_ref": ["b0", "b1", "b2", "b4", "b8", "b16"], "figure_ref": [], "table_ref": []}, {"heading": "A Proof of Theorem 1", "text": "Recall that for any \u00b5 \u2208 M(G), there exists a probability density p(x) s.t. \u00b5 = x p(x)v(x). Denote p \u00b5 (z) as the minimal value of p(z) among all p(x) that give \u00b5. We prove that p \u00b5 (z) = max(0, I(\u00b5, z)), from which the theorem follows (since p \u00b5 (z) = 0 iff \u00b5 \u2208M(G, z)).\nThe proof is by induction on n. For n = 1, the node has degree 0, so I(\u00b5, z) = \u00b5 1 (z 1 ). Clearly, p \u00b5 (z) = \u00b5 1 (z 1 ), so p \u00b5 (z) = I(\u00b5, z). For n > 1, there must exist a leaf in G (assume that its index is n and its neighbor's is n \u2212 1). Denote\u011c as the tree obtained by removing node n and its edge with n \u2212 1. For any assignment x, denotex as the corresponding sub-assignment for the first n \u2212 1 variables. Also, any \u00b5 can be derived by adding appropriate coordinates to a unique\u03bc \u2208 M(\u011c). For an integral vertex \u00b5 = v(x), denote its projected\u03bc asv(x). Denote by\u00ce(\u03bc,\u1e91) the functional in Eq. 5 applied to\u011c. For any \u00b5 and its projected\u03bc, it can be seen that: I(\u00b5, z) =\u00ce(\u03bc,\u1e91) \u2212 \u03b1 (11) where we define \u03b1 = xn =zn \u00b5 n\u22121,n (z n\u22121 , x n ) (so 0 \u2264 \u03b1 \u2264 1). The inductive assumption gives ap(x) that has marginals\u03bc and alsop(\u1e91) = max(0, I(\u03bc,\u1e91)). We next usep(x) to construct a p(x) that has marginals \u00b5 and the desired minimal p \u00b5 (z). Consider three cases: I. I(\u00b5, z) \u2264 0 and\u00ce(\u03bc,\u1e91) \u2264 0. From the inductive assumption,p\u03bc(\u1e91) = 0, so we define:\np(x) =p(x) \u00b5 n\u22121,n (x n\u22121 , x n ) \u00b5 n\u22121 (x n\u22121 )(12)\nwhich indeed marginalizes to \u00b5, and p(z) = 0 so that p \u00b5 (z) = 0 as required. If \u00b5 n\u22121 (x n\u22121 ) = 0, thenp(x) is necessarily 0, in which case we define p(x) = 0. Note that this construction is identical to that used in proving that M L (G) = M(G) for a tree graph G.\nII. I(\u00b5, z) > 0. Based on Eq. 11 and \u03b1 \u2265 0, we have\u00ce(\u03bc,\u1e91) > 0. Applying the inductive assumption to\u03bc, we obtain\u00ce(\u03bc,\u1e91) =p\u03bc(\u1e91) > 0. Now, define p(x) so that p(z) = I(\u00b5, z): Simple algebra shows that p(x) is non-negative and has \u00b5 as marginals. We now show that p(z) is minimal. Based on the inductive assumption and Eq. 11, it can easily be shown that I(v(z), z) = 1, I(v(x), z) \u2264 0 for x = z. For any p(x) s.t. \u00b5 = x p(x)v(x), from linearity, I(\u00b5, z) = p(z) + x =z p(x)I(v(x), z) \u2264 p(z) (since I(v(x), z) \u2264 0 for x = z). Since the p(z) we define achieves this lower bound, it is clearly minimal.\nIII. I(\u00b5, z) \u2264 0 but\u00ce(\u03bc,\u1e91) > 0. Applying the inductive assumption to\u03bc, we see that p\u03bc(\u1e91) =\u00ce(\u03bc,\u1e91) > 0; Eq. 11 implies \u03b1 \u2212\u00ce(\u03bc,\u1e91) \u2265 0. Define \u03b2 = \u00b5 n\u22121 (z n\u22121 ) \u2212p\u03bc(\u1e91), which is non-negative since \u00b5 n\u22121 (z n\u22121 ) =\u03bc n\u22121 (\u1e91 n\u22121 ) andp marginalizes to\u03bc. Define p(x) as:\nx l , l \u2264 n \u2212 2 \u03b4(xn\u22121 = zn\u22121) \u03b4(xn = zn) p(x)\nno constraint 0 no constraint As in Eq. 12 \u2203 l x l = z l 1 0p(x) which indeed marginalizes to \u00b5, and p(z) = 0 so that p \u00b5 (z) = 0, as required.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "We thank Nati Linial for his helpful discussions and Chen Yanover and Talya Meltzer for their insight and help in running BMMF. We also thank the anonymous reviewers for their useful advice.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "On cuts and matchings in planar graphs", "journal": "Math. Program", "year": "1993", "authors": "F Barahona"}, {"ref_id": "b1", "title": "Accurate prediction for atomic-level protein design and its application in diversifying the near-optimal sequence space", "journal": "Proteins: Structure, Function, and Bioinformatics", "year": "2009", "authors": "M Fromer; C Yanover"}, {"ref_id": "b2", "title": "Fixing max-product: Convergent message passing algorithms for MAP LP-relaxations", "journal": "MIT Press", "year": "2007", "authors": "A Globerson; T Jaakkola"}, {"ref_id": "b3", "title": "An extended dead-end elimination algorithm to determine gap-free lists of low energy states", "journal": "Journal of Comp. Chem", "year": "2007", "authors": "E Kloppmann; G M Ullmann; T Becker"}, {"ref_id": "b4", "title": "Beyond loose LP-relaxations: Optimizing MRFs by repairing cycles", "journal": "Springer", "year": "2008", "authors": "N Komodakis; N Paragios"}, {"ref_id": "b5", "title": "A procedure for computing the K best solutions to discrete optimization problems and its application to the shortest path problem", "journal": "Management Science", "year": "1972", "authors": "E L Lawler"}, {"ref_id": "b6", "title": "An algorithmic framework for the exact solution of the prize-collecting steiner tree problem", "journal": "Mathematical Programming", "year": "2006-02", "authors": "I Ljubic; R Weiskircher; U Pferschy; G W Klau; P Mutzel; M Fischetti"}, {"ref_id": "b7", "title": "An efficient algorithm for finding the M most probable configurations in probabilistic expert systems", "journal": "Statistics and Computing", "year": "1998-06", "authors": "D Nilsson"}, {"ref_id": "b8", "title": "Message-passing for graph-structured linear programs: proximal projections, convergence and rounding schemes", "journal": "ACM", "year": "2008", "authors": "P Ravikumar; A Agarwal; M Wainwright"}, {"ref_id": "b9", "title": "On the generation of alternative explanations with implications for belief revision", "journal": "", "year": "1991", "authors": "E Santos"}, {"ref_id": "b10", "title": "Finding the MAPs for belief networks is NP-hard", "journal": "Aritifical Intelligence", "year": "1994", "authors": "Y Shimony"}, {"ref_id": "b11", "title": "New outer bounds on the marginal polytope", "journal": "MIT Press", "year": "2007", "authors": "D Sontag; T Jaakkola"}, {"ref_id": "b12", "title": "Tightening LP relaxations for MAP using message passing", "journal": "", "year": "2008", "authors": "D Sontag; T Meltzer; A Globerson; T Jaakkola; Y Weiss"}, {"ref_id": "b13", "title": "Structured prediction, dual extragradient and bregman projections", "journal": "J. Mach. Learn. Res", "year": "2006", "authors": "B Taskar; S Lacoste-Julien; M I Jordan"}, {"ref_id": "b14", "title": "Graphical models, exponential families, and variational inference. Found", "journal": "Trends Mach. Learn", "year": "2008", "authors": "M Wainwright; M Jordan"}, {"ref_id": "b15", "title": "A new class of upper bounds on the log partition function", "journal": "IEEE Transactions on Information Theory", "year": "2005", "authors": "M J Wainwright; T Jaakkola; A S Willsky"}, {"ref_id": "b16", "title": "A linear programming approach to max-sum problem: A review", "journal": "IEEE Trans. Pattern Anal. Mach. Intell", "year": "2007", "authors": "T Werner"}, {"ref_id": "b17", "title": "Linear programming relaxations and belief propagation -an empirical study", "journal": "Journal of Machine Learning Research", "year": "2006", "authors": "C Yanover; T Meltzer; Y Weiss"}, {"ref_id": "b18", "title": "Finding the M most probable configurations using loopy belief propagation", "journal": "MIT Press", "year": "2004", "authors": "C Yanover; Y Weiss"}, {"ref_id": "b19", "title": "Constructing free-energy approximations and generalized belief propagation algorithms", "journal": "IEEE Trans. on Information Theory", "year": "2005", "authors": "J Yedidia; W W T Freeman; Y Weiss"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "for m \u2190 11to M do if m = 1 then Run MAP solver to obtain the best assignment: x (1) \u2261 arg max f (x; \u03b8)CONSTRAINTS 1 \u2190 \u2205 else k \u2190\u2212 arg max k \u2032 \u2208{1,...,m\u22121}f (y (k \u2032 ) ; \u03b8) // sub-space containing m th best assignmentx (m) \u2190 y (k) // m th best assignment // A variable choice that distinguishes x (m) from x (k) : (v, a) \u2190 any member of the set {(i, x", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "end", "figure_data": ""}, {"figure_label": "12", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 1 :Figure 2 :12Figure 1: Pseudocode for the PES algorithm.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "xl , l \u2264 n \u2212 2 \u03b4(xn\u22121 = zn\u22121) \u03b4(xn = zn) p", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "f (x 1 , . . . , x n ; \u03b8) = ij\u2208E \u03b8 ij (x i , x j ) + i\u2208V \u03b8 i (x i ) (1)", "formula_coordinates": [2.0, 207.72, 189.17, 296.32, 20.56]}, {"formula_id": "formula_1", "formula_text": "M(G) = {\u00b5 | \u2203p(x) \u2208 \u2206 s.t. p(x i , x j ) = \u00b5 ij (x i , x j ) , p(x i ) = \u00b5 i (x i )} .", "formula_coordinates": [2.0, 147.96, 304.15, 315.97, 10.33]}, {"formula_id": "formula_2", "formula_text": "2 max x f (x; \u03b8) = max \u00b5\u2208M(G) \u00b5 \u2022 \u03b8 ,(2)", "formula_coordinates": [2.0, 242.52, 328.73, 261.52, 31.76]}, {"formula_id": "formula_3", "formula_text": "M L (G) = \uf8f1 \uf8f2 \uf8f3 \u00b5 \u2265 0 xj \u00b5 ij (x i , x j ) = \u00b5 i (x i ), xi \u00b5 ij (x i , x j ) = \u00b5 j (x j ), xi \u00b5 i (x i ) = 1 \uf8fc \uf8fd \uf8fe (3)", "formula_coordinates": [2.0, 116.64, 493.74, 387.4, 45.31]}, {"formula_id": "formula_4", "formula_text": "\u00b5 \u2022 \u03b8 = P ij\u2208E P x i ,x j \u00b5ij (xi, xj)\u03b8ij(xi, xj) + P i P x i \u00b5i(xi)\u03b8i(xi)", "formula_coordinates": [2.0, 209.16, 723.2, 261.23, 11.84]}, {"formula_id": "formula_5", "formula_text": "M(G, z) = {\u00b5 | \u2203p(x) \u2208 \u2206 s.t. p(z) = 0, p(x i , x j ) = \u00b5 ij (x i , x j ), p(x i ) = \u00b5 i (x i )} . (4)", "formula_coordinates": [3.0, 119.76, 99.07, 744.89, 10.33]}, {"formula_id": "formula_6", "formula_text": "max x =x (1) f (x; \u03b8) = max \u00b5\u2208M(G,x (1)", "formula_coordinates": [3.0, 108.0, 172.85, 156.42, 11.84]}, {"formula_id": "formula_7", "formula_text": "i \u00b5 i (z i ) \u2264 n \u2212 1.", "formula_coordinates": [3.0, 330.12, 279.43, 72.25, 11.89]}, {"formula_id": "formula_8", "formula_text": "I(\u00b5, z) = i (1 \u2212 d i )\u00b5 i (z i ) + ij\u2208E \u00b5 ij (z i , z j ) (5)", "formula_coordinates": [3.0, 210.84, 394.75, 293.2, 20.78]}, {"formula_id": "formula_9", "formula_text": "I(\u00b5, z) \u2264 0 to M(G) yieldsM(G, z). M(G, z) = {\u00b5 | \u00b5 \u2208 M(G), I(\u00b5, z) \u2264 0 } (6)", "formula_coordinates": [3.0, 207.96, 433.63, 464.45, 25.2]}, {"formula_id": "formula_10", "formula_text": "S\u2208S (1 \u2212 d S )\u00b5 S (z S ) + C\u2208C \u00b5 C (z C ) \u2264 0 (7)", "formula_coordinates": [3.0, 225.0, 557.95, 279.04, 20.9]}, {"formula_id": "formula_11", "formula_text": "I T (\u00b5, z) = i (1 \u2212 d T i )\u00b5 i (z i ) + ij\u2208T \u00b5 ij (z i , z j ) (8)", "formula_coordinates": [4.0, 206.4, 311.04, 297.64, 22.29]}, {"formula_id": "formula_12", "formula_text": "M ST L (G, z) = \u00b5 | \u00b5 \u2208 M L (G), \u2200 tree T \u2286 E I T (\u00b5, z) \u2264 0 (9)", "formula_coordinates": [4.0, 161.4, 446.05, 342.64, 13.39]}, {"formula_id": "formula_13", "formula_text": "\u00b5\u2208M ST L (G,z) \u00b5\u2022\u03b8", "formula_coordinates": [4.0, 435.72, 488.35, 68.0, 18.58]}, {"formula_id": "formula_14", "formula_text": "I T (\u00b5, z) = ij\u2208T \u00b5 ij (z i , z j ) \u2212 \u00b5 i (z i ) \u2212 \u00b5 j (z j ) + i \u00b5 i (z i ) (10", "formula_coordinates": [4.0, 181.8, 612.36, 317.79, 22.41]}, {"formula_id": "formula_15", "formula_text": ")", "formula_coordinates": [4.0, 499.58, 614.33, 4.45, 9.62]}, {"formula_id": "formula_16", "formula_text": "w ij = \u00b5 ij (z i , z j ) \u2212 \u00b5 i (z i ) \u2212 \u00b5 j (z j )", "formula_coordinates": [4.0, 108.0, 653.47, 145.03, 10.34]}, {"formula_id": "formula_18", "formula_text": "x (m) i = x (k) i } CONSTRAINTS m \u2190 CONSTRAINTS k \u222a {xv = a} // Eliminate x (k) (as MAP) from subspace m CONSTRAINTS k \u2190 CONSTRAINTS k \u222a {xv = a} // Eliminate x (m) (as 2 nd -best) from subspace k y (k) \u2190 CalcNextBestSolution(CONSTRAINTS k , x (k) ) end y (m) \u2190 CalcNextBestSolution(CONSTRAINTS m , x (m) ) end return {x (m) } M m=1 /* Find next best solution in sub-space defined by CONSTRAINTS */ Function CalcNextBestSolution(CONSTRAINTS, x ( * ) ) // x (", "formula_coordinates": [5.0, 117.96, 507.68, 375.51, 135.65]}, {"formula_id": "formula_19", "formula_text": "p(x) =p(x) \u00b5 n\u22121,n (x n\u22121 , x n ) \u00b5 n\u22121 (x n\u22121 )(12)", "formula_coordinates": [8.0, 242.04, 317.69, 262.0, 23.56]}, {"formula_id": "formula_20", "formula_text": "x l , l \u2264 n \u2212 2 \u03b4(xn\u22121 = zn\u22121) \u03b4(xn = zn) p(x)", "formula_coordinates": [8.0, 147.36, 627.4, 270.83, 8.78]}], "doi": ""}