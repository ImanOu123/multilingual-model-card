{"title": "SAT-Based PAC Learning of Description Logic Concepts", "authors": "Balder Ten Cate; Maurice Funk; Jean Christoph Jung; Carsten Lutz", "pub_date": "2023-05-15", "abstract": "We propose bounded fitting as a scheme for learning description logic concepts in the presence of ontologies. A main advantage is that the resulting learning algorithms come with theoretical guarantees regarding their generalization to unseen examples in the sense of PAC learning. We prove that, in contrast, several other natural learning algorithms fail to provide such guarantees. As a further contribution, we present the system SPELL which efficiently implements bounded fitting for the description logic ELH r based on a SAT solver, and compare its performance to a state-of-the-art learner.", "sections": [{"heading": "Introduction", "text": "In knowledge representation, the manual curation of knowledge bases (KBs) is time consuming and expensive, making learning-based approaches to knowledge acquisition an attractive alternative. We are interested in description logics (DLs) where concepts are an important class of expressions, used for querying KBs and also as central building blocks for ontologies. The subject of learning DL concepts from labeled data examples has received great interest, resulting in various implemented systems such as DL-Learner, DL-Foil, and YINYANG [B\u00fchmann et al., 2016;Fanizzi et al., 2018;Iannone et al., 2007]. These systems take a set of positively and negatively labeled examples and an ontology O, and try to construct a concept that fits the examples w.r.t. O. The related fitting problem, which asks to decide the existence of a fitting concept, has also been studied intensely [Lehmann and Hitzler, 2010;.\nThe purpose of this paper is to propose a new approach to concept learning in DLs that we call bounded fitting, inspired by both bounded model checking as known from systems verification [Biere et al., 1999] and by Occam algorithms from computational learning theory [Blumer et al., 1989]. The idea of bounded fitting is to search for a fitting concept of bounded size, iteratively increasing the size bound until a fitting is found. This approach has two main advantages, which we discuss in the following.\nFirst, it comes with formal guarantees regarding the generalization of the returned concept from the training data to previously unseen data. This is formalized by Valiant's framework of probably approximately correct (PAC) learning [Valiant, 1984]. Given sufficiently many data examples sampled from an unknown distribution, bounded fitting returns a concept that with high probability \u03b4 has a classification error bounded by some small . It is well-known that PAC learning is intimately linked to Occam algorithms which guarantee to find a hypothesis of small size [Blumer et al., 1989;Board and Pitt, 1992]. By design, algorithms following the bounded fitting paradigm are Occam, and as a consequence the number of examples needed for generalization depends only linearly on 1/\u03b4, 1/ , and the size of the target concept to be learned. This generalization guarantee holds independently of the DL used to formulate concepts and ontologies. In contrast, no formal generalization guarantees have been established for DL concept learning approaches.\nThe second advantage is that, in important cases, bounded fitting enables learning based on SAT solvers and thus leverages the practical efficiency of these systems. We consider ontologies formulated in the description logic ELH r and concepts formulated in EL, which may be viewed as a core of the ontology language OWL 2 EL. In this case, the size-restricted fitting problem, which is defined like the fitting problem except that the maximum size of fitting concepts to be considered is given as an additional input (in unary), is NP-complete; it is thus natural to implement bounded fitting using a SAT solver. For comparison, we mention that the unbounded fitting problem is EXPTIME-complete in this case .\nAs a further contribution of the paper, we analyze the generalization ability of other relevant approaches to constructing fitting EL-concepts. We start with algorithms that return fittings that are 'prominent' from a logical perspective in that they are most specific or most general or of minimum quantifier depth among all fittings. Algorithms with such characteristics and their applications are discussed in [ten Cate et al., 2023]. Notably, constructing fittings via direct products of positive examples yields most specific fittings [Zarrie\u00df and Turhan, 2013;Jung et al., 2020]. Our result is that, even without ontologies, these types of algorithms are not sample-efficient, that is, no polynomial amount of positive and negative examples is sufficient to achieve generalization in the PAC sense.\nWe next turn to algorithms based on so-called downward refinement operators which underlie all implemented DL learning systems that we are aware of. We consider two natural such operators that are rather similar to one another and combine them with a breadth-first search strategy. The first operator can be described as exploring 'most-general specializations' of the current hypotheses and the second one does the same, but is made 'artificially Occam' (with, most likely, a negative impact on practicality). We prove that while the first operator does not lead to a not sample-efficient algorithm (even without ontologies), the second one does. This leaves open whether or not implemented systems based on refinement operators admit generalization guarantees, as they implement complex heuristics and optimizations.\nAs our final contribution we present SPELL, a SAT-based system that implements bounded fitting of EL-concepts under ELH r -ontologies. We evaluate SPELL on several datasets and compare it to the only other available learning system for EL that we are aware of, the EL tree learner (ELTL) incarnation of the DL-Learner system [B\u00fchmann et al., 2016]. We find that the running time of SPELL is almost always significantly lower than that of ELTL. Since, as we also show, it is the size of the target concept that has most impact on the running time, this means that SPELL can learn larger target queries than ELTL. We also analyze the relative strengths and weaknesses of the two approaches, identifying classes of inputs on which one of the systems performs significantly better than the other one. Finally, we make initial experiments regarding generalization, where both systems generalize well to unseen data, even on very small samples. While this is expected for SPELL, for ELTL it may be due to the fact that some of the heuristics prefer fittings of small size, which might make ELTL an Occam algorithm.\nProof details are provided in the appendix. Related Work Cohen and Hirsh identified a fragment of the early DL CLASSIC that admits sample-efficient PAC learning, even in polynomial time [Cohen and Hirsh, 1994]. For several DLs such as EL and CLASSIC, concepts are learnable in polynomial time in Angluin's framework of exact learning with membership and equivalence queries [Frazier and Pitt, 1996;ten Cate and Dalmau, 2021;Funk et al., 2021;Funk et al., 2022b]. The algorithms can be transformed in a standard way into sample-efficient polynomial time PAC learning algorithms that, however, additionally use membership queries to an oracle [Angluin, 1987]. It is known that sample-efficient PAC learning under certain assumptions implies the existence of Occam algorithms [Board and Pitt, 1992]. These assumptions, however, do not apply to the learning tasks studied here.", "publication_ref": ["b1", "b5", "b0", "b1", "b14", "b1", "b1", "b14", "b7", "b1", "b1", "b1", "b2", "b4", "b0", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "Preliminaries", "text": "Concepts, Ontologies, Queries. Let N C , N R , and N I be countably infinite sets of concept names, role names, and individual names, respectively. An EL-concept is formed according to the syntax rule C, D ::\n= | A | C D | \u2203r.C\nwhere A ranges over N C and r over N R . A concept of the form \u2203r.C is called an existential restriction and the quantifier depth of a concept is the maximum nesting depth of existential restrictions in it. An ELH r -ontology O is a finite set of concept inclusions (CIs) C D, role inclusions r s, and range assertions ran(r) C where C and D range over EL-concepts and r, s over role names. An EL-ontology is an ELH r -ontology that uses neither role inclusions nor range assertions. We also sometimes mention ELI-concepts and ELI-ontologies, which extend their EL-counterparts with inverse roles r \u2212 that can be used in place of role names. See [Baader et al., 2017] for more information. A database D (also called ABox in a DL context) is a finite set of concept assertions A(a) and role assertions r(a, b) where A \u2208 N C , r \u2208 N R , and a, b \u2208 N I . We use adom(D) to denote the set of individual names that are used in D. A signature is a set of concept and role names, in this context uniformly referred to as symbols. For any syntactic object O, such as a concept or an ontology, we use sig(O) to denote the set of symbols used in O and ||O|| to denote the size of O, that is, the number of symbols used to write O encoded as a word over a finite alphabet, with each occurrence of a concept or role name contributing a single symbol.\nThe semantics is defined in terms of interpretations I = (\u2206 I , \u2022 I ) where \u2206 I is the domain of I and \u2022 I assigns a set A I \u2286 \u2206 I to every A \u2208 N C and a binary relation r I \u2286 \u2206 I \u00d7 \u2206 I to every r \u2208 N R . The extension C I of EL-concepts C is then defined as usual [Baader et al., 2017]. An interpretation I satisfies a concept or role inclusion \u03b1 \u03b2 if \u03b1 I \u2286 \u03b2 I , a range assertion ran(r)\nC if the projection of r I to the second component is contained in C I , a concept assertion A(a) if a \u2208 A I , and a role assertion r(a, b) if (a, b) \u2208 r I . We say that I is a model of an ontology/database if it satisfies all inclusions/assertions in it.\nAn EL-concept C can be viewed as an EL-query (ELQ) q, as follows. Let D be a database and O an ELH r -ontology. Then a \u2208 adom(D) is an answer to q on D w.r.t. O if a \u2208 C I for all models I of D and O. In a similar way, we may view ELI-concepts as ELI-queries (ELIQs). We will from now on mostly view EL-concepts as ELQs. This does not, however, restrict their use, which may be as actual queries or as concepts used as building blocks for ontologies.\nAn ontology-mediated query (OMQ) language is a pair (L, Q) with L an ontology language and Q a query language, such as (ELH r , ELQ) and (ELI, ELIQ). For a query language Q and signature \u03a3, we use Q \u03a3 to denote the set of all queries q \u2208 Q with sig(q) \u2286 \u03a3. All query languages considered in this paper are unary, that is, they return a subset of adom(D) as answers. We use q(D \u222a O) to denote the set of answers to q on D w.r.t. O. For an L-ontology O and queries q 1 , q 2 , we write\nO |= q 1 q 2 if for all databases D, q 1 (D \u222a O) \u2286 q 2 (D \u222a O). We say that q 1 and q 2 are equiv- alent w.r.t. O, written O |= q 1 \u2261 q 2 , if O |= q 1 q 2 and O |= q 2 q 1 . When O = \u2205, we write q 1 q 2 and q 1 \u2261 q 2 .\nEvery ELQ q may be viewed as a database D q in an obvious way, e.g. q = \u2203r.\u2203s.A as\nD q = {r(a q , a 1 ), s(a 1 , a 2 ), A(a 2 )}. Let D 1 , D 2 be databases and \u03a3 a signature. A \u03a3-simulation from D 1 to D 2 is a relation S \u2286 adom(D 1 ) \u00d7 adom(D 2 ) such that for all (a 1 , a 2 ) \u2208 S: 1. if A(a 1 ) \u2208 D 1 with A \u2208 \u03a3, then A(a 2 ) \u2208 D 2 ; 2. if r(a 1 , b 1 ) \u2208 D 1 with r \u2208 \u03a3, there is r(a 2 , b 2 ) \u2208 D 2 such that (b 1 , b 2 ) \u2208 S.\nFor a 1 \u2208 adom(D 1 ) and a 2 \u2208 adom(D 2 ), we write\n(D 1 , a 1 ) \u03a3 (D 2 , a 2 )\nif there is a \u03a3-simulation S from D 1 to D 2 with (a 1 , a 2 ) \u2208 S. We generally drop the mention of \u03a3 in case that \u03a3 = N C \u222a N R . The following well-known lemma links simulations to ELQs. Lemma 1. For all ELQs q, databases D, and a \u2208 adom(D): a \u2208 q(D) iff (D q , a q ) (D, a). Consequently, for all ELQs q, p: q p iff (D p , a p ) (D q , a q ). Fitting. A pointed database is a pair (D, a) with D a database and a \u2208 adom(D). A labeled data example takes the form (D, a, +) or (D, a, \u2212), the former being a positive example and the latter a negative example.\nLet O be an ontology, Q a query language, and E a collection of labeled data examples. A query q \u2208 Q fits E w.r.t. O if a \u2208 q(D \u222a O) for all (D, a, +) \u2208 E and a / \u2208 q(D \u222a O) for all (D, a, \u2212) \u2208 E. We then call E a q-labeled data example w.r.t. O. We say that q is a most specific fitting if O |= q q for every q \u2208 Q that fits E, and that it is most general if\nO |= q q for every q \u2208 Q that fits E. Example 1. Consider the collection E 0 of examples ({r(a, a), A(a), B(a)}, a, +), ({A(a), r(a, b), B(b)}, a, +), ({r(a, b)}, b, \u2212).\nIt has several ELQ fittings, the most specific one being A \u2203r.B. There is no most general fitting ELQ as both A and \u2203r.B fit, but no common generalization does.\nA fitting algorithm for an OMQ language (L, Q) is an algorithm that takes as input an L-ontology O and a collection of labeled data examples E and returns a query q \u2208 Q that fits E w.r.t. O, if such a q exists, and otherwise reports non-existence or does not terminate. The size-restricted fitting problem for (L, Q) means to decide, given a collection of labeled data examples E, an L-ontology O, and an s \u2265 1 in unary, whether there is a query q \u2208 Q with ||q|| \u2264 s that fits E w.r.t. O.\nIt is well-known that for every database D and ELH rontology O, we can compute in polynomial time a database U D,O that is universal for ELQs in the sense that a \u2208 q(D \u222a O) iff a \u2208 q(U D,O ) for all ELQs q and a \u2208 adom(D) [Lutz et al., 2009]. Given a collection of labeled data examples E and an ELH r -ontology O, we denote with E O the collection obtained from E by replacing each (positive or negative) example (D, a, \u2022) with (U D,O , a, \u2022). The following proposition shows that a fitting algorithm for ELQ without ontologies also gives rise to a fitting algorithm for (ELH r , ELQ) with at most a polynomial increase in running time. It is immediate from the definition of universality.\nProposition 1. An ELQ q fits a collection of labeled examples E w.r.t. an ELH r -ontology O iff q fits E O w.r.t. \u2205.\nWe remark that in contrast to ELQs, finite databases that are universal for ELIQs need not exist [Funk et al., 2022a]. PAC Learning. We recall the definition of PAC learning, in a formulation that is tailored towards OMQ languages. Let P be a probability distribution over pointed databases and let q T and q H be queries, the target and the hypothesis. The error of q H relative to q T and P is error\nP,q T (q H ) = Pr (D,a)\u223cP (a \u2208 q H (D \u222a O) \u2206 q T (D \u222a O))\nwhere \u2206 denotes symmetric difference and Pr (D,a)\u223cP X is the probability of X when drawing (D, a) randomly according to P . We say that A has sample size m and call A sample-efficient if m is a polynomial.\nNote that a PAC learning algorithm is not required to terminate if no fitting query exists. It would be desirable to even attain efficient PAC learning which additionally requires A to be a polynomial time algorithm. However, ELQs are known to not be efficiently PAC learnable even without ontologies, unless RP = NP [Kietz, 1993;ten Cate et al., 2022]. The same is true for ELIQs and any other class of conjunctive queries that contains all ELQs.", "publication_ref": ["b0", "b0", "b11", "b3", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Bounded Fitting and Generalization", "text": "We introduce bounded fitting and analyze when fitting algorithms are PAC learning algorithms. Definition 2. Let (L, Q) be an OMQ language and let A be an algorithm for the size-restricted fitting problem for (L, Q). Then BOUNDED-FITTING A is the algorithm that, given a collection of labeled data examples E and an L-ontology O, runs A with input (E, O, s) to decide whether there is a q \u2208 Q with ||q|| \u2264 s that fits E w.r.t. O, for s = 1, 2, 3 . . ., returning a fitting query as soon as it finds one. Example 2. Consider again Example 1. For s = 1, bounded fitting tries the candidates , A, B, \u2203r. and returns the fitting A. If started on E 0 extended with ({A(a)}, a, \u2212), it finds one of the fitting ELQs A \u2203r. and \u2203r.B in Round 2.\nIn spirit, bounded fitting focusses on finding fitting queries when they exist, and not on deciding the existence of a fitting query. This is in analogy with bounded model checking, which focusses on finding counterexamples rather than on proving that no such examples exist. If an upper bound on the size of fitting queries is known, however, we can make bounded fitting terminate by reporting non-existence of a fitting query once the bound is exceeded. This is more of theoretical than of practical interest since the size bounds tend to be large. For ELQs without ontologies and for (EL, ELQ), for instance, it is double exponential . It thus seems more realistic to run an algorithm that decides the existence of a fitting in parallel to bounded fitting and to report the result as soon as one of the algorithms terminates. There are also important cases where fitting existence is undecidable, such as for the OMQ language (ELI, ELIQ) .\nBounded fitting may be used also in such cases as long as the size-restricted fitting problem is still decidable. This is the case for (ELI, ELIQ), as a direct consequence of query evaluation to be decidable in this OMQ language [Baader et al., 2008], see Appendix H.\nA major advantage of bounded fitting is that it yields a sample-efficient PAC learning algorithm with sample size linear in the size of the target query. This is because bounded fitting is an Occam algorithm which essentially means that it produces a fitting query that is at most polynomially larger than the fitting query of minimal size [Blumer et al., 1989]. 1 Theorem 1. Let (L, Q) be an OMQ language.\nEvery bounded fitting algorithm for (L, Q) is a (sampleefficient) PAC learning algorithm with sample size\nO 1 \u2022 log 1 \u2022 log 1 \u03b4 \u2022 log |\u03a3| \u2022 ||q T || .\nWe remark that bounded fitting is robust in that other natural measures of query size (such as the number of existential restrictions) and enumeration sequences such as s = 1, 2, 4, 8, . . . also lead to sample-efficient PAC learning algorithms. This results in some flexibility in implementations.\nWe next show that many other fitting algorithms are not sample-efficient when used as PAC learning algorithms. We start with algorithms that return fittings which are most specific or most general or of minimum quantifier depth. No such algorithm is a sample-efficient PAC learning algorithm, even without ontologies.\nTheorem 2. If A is a fitting algorithm for ELQs that satisfies one of the conditions below, then A is not a sample-efficient PAC learning algorithm.", "publication_ref": ["b0", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "1.", "text": "A always produces a most specific fitting, if it exists; 2. A always produces a most general fitting, if it exists; 3. A produces a fitting of minimal quantifier depth, if a fitting exists.\nThe proof of Theorem 2 relies on duals of finite relational structures, which are widely known in the form of homomorphism duals [Nesetril and Tardif, 2000]. Here, we introduce the new notion of simulation duals.\nLet (D, a) be a pointed database and \u03a3 a signature. A set M of pointed databases is a \u03a3-simulation dual of (D, a) if for all pointed databases (D , a ), the following holds:\n(D, a) \u03a3 (D , a ) iff (D , a ) \u03a3 (D , a ) for all (D , a ) \u2208 M.\nFor illustration, consider the simulation dual M of (D q , a q ) for an ELQ q. Then every negative example for q has a simulation into an element of M and q is the most general ELQ that fits {(D, a, \u2212) | (D, a) \u2208 M }. We exploit this in the proof of Theorem 2. Moreover, we rely on the fact that ELQs have simulation duals of polynomial size. In contrast, (non-pointed) homomorphism duals of tree-shaped databases may become exponentially large [Nesetril and Tardif, 2005].\n1 A precise definition of Occam algorithms is based on the notion of VC-dimension; it is not crucial to the main part of the paper, details can be found in the appendix.\nTheorem 3. Given an ELQ q and a finite signature \u03a3, a \u03a3simulation dual M of (D q , a q ) of size ||M || \u2264 3\u2022|\u03a3|\u2022||q|| 2 can be computed in polynomial time. Moreover, if D q contains only a single \u03a3-assertion that mentions a q , then M is a singleton.\nThe notion of simulation duals is of independent interest and we develop it further in the appendix. We show that Theorem 3 generalizes from databases D q to all pointed databases (D, a) such that the directed graph induced by the restriction of D to the individuals reachable (in a directed sense) from a is a DAG. Conversely, databases that are not of this form do not have finite simulation duals. We find it interesting to recall that DAG-shaped databases do in general not have finite homomorphism duals [Nesetril and Tardif, 2000].\nUsing Theorem 3, we now prove Point 2 of Theorem 2. Points 1 and 3 are proved in the appendix.\nProof. To highlight the intuitions, we leave out some minor technical details that are provided in the appendix. Assume to the contrary of what we aim to show that there is a sampleefficient PAC learning algorithm that produces a most general fitting ELQ, if it exists, with associated polynomial function m : R 2 \u00d7 N 4 as in Definition 1. As target ELQs q T , we use concepts C i where C 0 = and C i = \u2203r.(A B C i\u22121 ). Thus, C i is an r-path of length i in which every non-root node is labeled with A and B.\nChoose \u03a3 = {A, B, r}, \u03b4 = = 0.5, and n large enough so that\n2 n > 2m(1/\u03b4, 1/ , 0, |\u03a3|, 3n, 3 \u2022 |\u03a3| \u2022 ||C n || 2 ). Further choose q T = C n .\nWe \nS 0 = { } S i = {\u2203r.(\u03b1 C) | C \u2208 S i\u22121 , \u03b1 \u2208 {A, B}}.\nNote that the ELQs in S resemble q T except that every node is labeled with only one of the concept names A, B. Now consider any q \u2208 S. Clearly, q T q. Moreover, the pointed database (D q , a q ) contains a single assertion that mentions a q . By Theorem 3, q has a singleton \u03a3-simulation dual {(D q , a q )} with ||D q || \u2264 3 \u2022 |\u03a3| \u2022 ||C n || 2 . We shall use these duals as negative examples.\nThe two crucial properties of S are that for all q \u2208 S, 1. q is the most general ELQ that fits (D q , a q , \u2212);\n2. for all T \u2286 S, q / \u2208 T implies p\u2208T p q.\nBy Point 1 and since q T q, each (D q , a q ) is also a negative example for q T . Let the probability distribution P assign probability 1 2 n to all (D q , a q ) with q \u2208 S and probability 0 to all other pointed databases. Now assume that the algorithm is started on a\ncollection of m(1/\u03b4, 1/ , 0, |\u03a3|, 3n, 3 \u2022 |\u03a3| \u2022 ||C n || 2 ) labeled\ndata examples E drawn according to P . It follows from Point 1 that q H = (D q ,a q )\u2208E q is the most general ELQ that fits E. Thus, (an ELQ equivalent to) q H is output by the algorithm.\nTo obtain a contradiction, it suffices to show that with probability 1 \u2212 \u03b4, we have error P,q T (q H ) > . We argue that, in fact, q H violates all (negative) data examples that are not in the sample E, that is, a q \u2208 q H (D p ) for all p \u2208 S with (D p , a p ) / \u2208 E. The definition of P and choice of n then yield that with probability 1, error P,q T (q\nH ) = |S|\u2212|E| |S| > 1 2 .\nThus consider any p \u2208 S such that (D p , a p ) / \u2208 E. It follows from Point 2 that q H p and the definition of duals may now be used to derive a p \u2208 q H (D p ) as desired.", "publication_ref": ["b11", "b11", "b11"], "figure_ref": [], "table_ref": []}, {"heading": "Refinement Operators", "text": "We discuss fitting algorithms based on refinement operators, used in implemented systems such as ELTL, and show that the generalization abilities of such algorithms subtly depend on the exact operator (and strategy) used.\nLet (L, Q) be an OMQ language. A (downward) refinement of a query q \u2208 Q w.r. \nq, p \u2208 Q \u03a3 , O |= p q implies that there is a finite \u03c1, O, \u03a3- refinement sequence from q to p, that is, a sequence of queries q 1 , . . . , q n such that q = q 1 , q i+1 \u2208 \u03c1(q i , O, \u03a3) for 1 \u2264 i < n, and O |= q n \u2261 p.\nWhen O is empty, we write \u03c1(q, \u03a3) in place of \u03c1(q, O, \u03a3).\nFor (EL, ELQ) and thus also for (ELH r , ELQ), it is known that no ideal refinement operator exists [Kriegel, 2019]. This problem can be overcome by making use of Proposition 1 and employing an ideal refinement operator for ELQs without ontologies, which does exist [Lehmann and Haase, 2009]. But also these refinement operators are not without problems. It was observed in [Kriegel, 2021] that for any such operator, non-elementarily long refinement sequences exist, potentially impairing the practical use of such operators. We somewhat relativize this by the following observation. A refinement operator \u03c1 for (L, Q) is f -depth bounded, for f : N \u2192 N, if for all q, p \u2208 Q and all L-ontologies O with O |= p q, there exists a \u03c1, O, \u03a3-refinement sequence from q to p that is of length at most f (||p||).\nTheorem 4. Let (L, Q) be an OMQ-language. If (L, Q) has an ideal refinement operator, then it has a 2 O(n) -depth bounded ideal refinement operator.\nThe depth bounded operator in Theorem 4 is obtained by starting with some operator \u03c1 and adding to each \u03c1(q, O, \u03a3) all p \u2208 Q \u03a3 such that O |= p q, O |= q p, and ||p|| \u2264 ||q||. Note that the size of queries is used in an essential way, as in Occam algorithms.\nA refinement operator by itself is not a fitting algorithm as one also needs a strategy for applying the operator. We use breadth-first search as a simple yet natural such strategy.\nWe consider two related refinement operators \u03c1 1 and \u03c1 2 for ELQs. The definition of both operators refers to (small) query size, inspired by Occam algorithms. Let q be an ELQ. Then \u03c1 1 (q, \u03a3) is the set of all p \u2208 ELQ \u03a3 such that p q, q p, and ||p|| \u2264 2||q|| + 1. The operator \u03c1 2 is defined like \u03c1 1 except that we include in \u03c1 2 (q, \u03a3) only ELQs p that are a (downward) neighbor of q, that is, for all ELQs p , p p q implies p p or q p . The following lemma shows that \u03c1 2 (q, \u03a3) actually contains all neighbors of q with sig(q) \u2286 \u03a3, up to equivalence. An ELQ q is minimal if there is no ELQ p such that ||p|| < ||q|| and p \u2261 q. Lemma 2. For every ELQ q and minimal downward neighbor p of q, we have ||p|| \u2264 2||q|| + 1.\nBoth \u03c1 1 and \u03c1 2 can be computed by brute force. For more elaborate approaches to computing \u03c1 2 , see [Kriegel, 2021] where downward neighbors of ELQs are studied in detail. Lemma 3. \u03c1 1 and \u03c1 2 are ideal refinement operators for ELQ.\nWe next give more details on what we mean by breadth-first search. Started on a collection of labeled data examples E, the algorithm maintains a set M of candidate ELQs that fit all positive examples E + in E, beginning with M = { } and proceeding in rounds. If any ELQ q in M fits E, then we return such a fitting q with ||q|| smallest. Otherwise, the current set M is replaced with the set of all ELQs from q\u2208M \u03c1(q, sig(E)) that fit E + , and the next round begins. For i \u2208 {1, 2}, let A i be the version of this algorithm that uses refinement operator \u03c1 i . Although \u03c1 1 and \u03c1 2 are defined quite similarly, the behavior of the algorithms A 1 and A 2 differs. Theorem 5. A 1 is a sample-efficient PAC learning algorithm, but A 2 is not.\nTo prove Theorem 5, we show that A 1 is an Occam algorithm while A 2 produces a most general fitting (if it exists), which allows us to apply Theorem 2.\nThe above is intended to provide a case study of refinement operators and their generalization abilities. Implemented systems use refinement operators and strategies that are more complex and include heuristics and optimizations. This makes it difficult to analyze whether implemented refinement-based systems constitute a sample-efficient PAC learner.\nWe comment on the ELTL system that we use in our experiments. ELTL is based on the refinement operator for (ELH r , ELQ) presented in [Lehmann and Haase, 2009]. That operator, however, admits only ELH r ontologies of a rather restricted form: all CIs must be of the form A B with A, B concept names. Since no ideal refinement operators for unrestricted (EL, ELQ) exist and ELTL does not eliminate ontologies in the spirit of Proposition 1, it remains unclear whether and how ELTL achieves completeness (i.e., finding a fitting whenever there is one).", "publication_ref": ["b9", "b10", "b10", "b10", "b10"], "figure_ref": [], "table_ref": []}, {"heading": "The SPELL System", "text": "We implemented bounded fitting for the OMQ language (ELH r , ELQ) in the system SPELL (for SAT-based PAC EL concept Learner). It then runs bounded fitting in the variant where in each round n, fitting ELQs with at most n \u2212 1 existential restrictions are considered (rather than fitting ELQs q with ||q|| \u2264 n). The existence of such a fitting is checked using the SAT solver. Also this variant of bounded fitting results in a sample-efficient PAC learning algorithm, with sample size\nO 1 \u2022 log 1 \u2022 log 1 \u03b4 \u2022 |\u03a3| \u2022 ||q T ||\n, see the appendix. We prefer this variant for implementation because it admits a more natural reduction to SAT, described next.\nFrom E O and the bound n, we construct a propositional formula \u03d5 = \u03d5 1 \u2227\u03d5 2 that is satisfiable if and only if there is an ELQ q over \u03a3 = sig(E O ) with at most n\u22121 existential restrictions that fits E O . Indeed, any model of \u03d5 returned by the SAT solver uniquely represents a fitting ELQ q. More precisely, \u03d5 1 ensures that such a model represents EL-concepts C 1 , . . . , C n where each C i only contains existential restrictions of the form \u2203r.C j with j > i, and we take q to be C 1 . We use variables of the form c i,A to express that the concept name A is a conjunct of C i , and variables x j,r and y i,j to express that \u2203r.C j is a conjunct of C i . Then \u03d5 2 enforces that the represented ELQ fits E O . Let D be the disjoint union of all databases that occur in an example in E O . We use variables s i,a , with 1 \u2264 i \u2264 n and a \u2208 adom(D), to express that a \u2208 C i (D); the exact definition of \u03d5 2 uses simulations and relies on Lemma 1. The number of variables in \u03d5 is O n 2 \u2022 |D| , thus linear in |D|.\nWe have implemented several improvements over this basic reduction of which we describe two. The first improvement is based on the simple observation that for computing a fitting ELQ with n \u2212 1 existential restrictions, for every example (D , a, \u00b1) \u2208 E O it suffices to consider individuals that can be reached via at most n \u2212 1 role assertions from a. Moreover, we may restrict \u03a3 to symbols that occur in all n \u2212 1-reachable parts of the positive examples. The second improvement is based on the observation that the search space for satisfying assignments of \u03d5 contains significant symmetries as the same ELQ q may be encoded by many different arrangements of concepts C 1 , . . . C n . We add constraints to \u03d5 so that the number of possible arrangements is reduced, breaking many symmetries. For details see the appendix.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Evaluation", "text": "We evaluate SPELL on several benchmarks 3 and compare it to the ELTL component of the DL-Learner system [B\u00fchmann et al., 2016]. Existing benchmarks do not suit our purpose as they aim at learning concepts that are formulated in more expressive DLs of the ALC family. As a consequence, a fitting EL concept almost never exists. This is the case, for example, in the often used Structured Machine Learning Benchmark . We thus designed several new benchmarks leveraging various existing knowledge bases, making sure that a fitting EL concept always exists. We hope that our benchmarks will provide a basis also for future experimental evaluations of EL learning systems.\nPerformance Evaluation. We carried out two experiments that aim at evaluating the performance of SPELL. The main questions are: Which parameters have most impact on the running time? And how does the running time compare to that of ELTL?\nThe first experiment uses the Yago 4 knowledge base which combines the concept classes of schema.org with data from Wikidata [Tanon et al., 2020]. The smallest version of Yago 4 is still huge and contains over 40 million assertions. We extracted a fragment of 12 million assertions assertions that focusses on movies and famous persons. We then systematically vary the number of labeled examples and the size of the target ELQs. The latter take the form\nC n = \u2203actor. n i=1 r i .\nwhere each r i is a role name that represents a property of actors in Yago and n is increased to obtain larger queries. The positive examples are selected by querying Yago with C n and the negative examples by querying Yago with generalizations of C n . The results are presented in Figure 1. They show that the size of the target query has a strong impact on the running time whereas the impact of the number of positive and negative examples is much more modest. We also find that SPELL performs \u223c1.5 orders of magnitude better than ELTL, meaning in particular that it can handle larger target queries.   Since Yago has only a very restricted ontology that essentially consists of inclusions A B with A, B concept names, we complement the above experiment with a second one based on OWL2Bench. OWL2Bench is a benchmark for ontology-mediated querying that combines a database generator with a hand-crafted ontology which extends the University Ontology Benchmark [Singh et al., 2020;Zhou et al., 2013]. The ontology is formulated in OWL 2 EL and we extracted its ELH r fragment which uses all aspects of this DL and comprises 142 concept names, 83 role names, and 173 concept inclusions. We use datasets that contain 2500-2600 individuals and 100-200 examples, generated as in the Yago case. We designed 6 ELQs with 3-5 occurrences of concept and role names and varying topology. The results are shown in Table 2. The difference in running time is even more pronounced in this experiment, with SPELL returning a fitting ELQ almost instantaneously in all cases. 4 Strengths and Weaknesses. In this experiment, we aim to highlight the respective strengths and weaknesses of SPELL and ELTL or, more generally, of bounded fitting versus refinement-operator based approaches. We anticipated that the performance of bounded fitting would be most affected by the number of existential restrictions in the target query whereas the performance of refinement would be most affected by the (unique) length of the sequence C 1 , . . . , C k such that C 1 = , C i+1 is a downward neighbor of C i for 1 \u2264 i < k, and C k is the target query. Let us call this the depth of C k . The number of existential restrictions and depth are orthogonal parameters. In the k-path benchmark, we use target ELQs of the form \u2203r k . , k \u2265 1. These should be difficult for bounded fitting when the number k of existential restrictions gets large, but easy for refinement as the depth of \u2203r k . is only k. In the k-1conj benchmark, we use ELQs of the form \u2203r.\n< 1 < 1 < 1 < 1 < 1 < 1\nk i=1 A i , k \u2265 1.\nThese have only one existential restriction and depth 2 k . ELQs in the k-2-conj benchmark take the form \u2203r.\u2203r. k i=1 A i and even have depth 2 2 k [Kriegel, 2021]. These should be difficult for refinement when k gets large, but easy for SPELL. There is no ontology and we use only a single positive and a single negative example, which are the target ELQ and its unique upwards neighbor (defined in analogy with downwards neighbors). The results in Table 3 confirm our expectations, with ELTL arguably degrading faster than SPELL.  \nk-path k-1-conj k-2-conj k ELTL SPELL ELTL SPELL ELTL SPELL 4 1 <1 1 <1 1 <1 6 1 <1 2 <1 394 <1 8 1 <1 20 <1 TO <110", "publication_ref": ["b1", "b11", "b14", "b10"], "figure_ref": ["fig_2"], "table_ref": ["tab_3", "tab_5"]}, {"heading": "Conclusion and Future Work", "text": "We have introduced the bounded fitting paradigm along with the SAT-based implementation SPELL for (ELH r , ELQ), with competitive performance and formal generalization guarantees. A natural next step is to extend SPELL to other DLs such as ELI, ALC, or ELU, both with and without ontologies. We expect that, in the case without ontology, a SAT encoding of the size-restricted fitting problem will often be possible. The case with ontology is more challenging; e.g., size-restricted fitting is EXPTIME-complete for (ELI, ELIQ), see Appendix H for additional discussion. It is also interesting to investigate query languages beyond DLs such as conjunctive queries (CQs). Note that the size-restricted fitting problem for CQs is \u03a3 p 2 -complete [Gottlob et al., 1999] and thus beyond SAT solvers; one could resort to using an ASP solver or to CQs of bounded treewidth.\nIt would also be interesting to investigate settings in which input examples may be labeled erroneously or according to a target query formulated in different language than the query to be learned. In both cases, one has to admit non-perfect fittings and the optimization features of SAT solvers and Max-SAT solvers seem to be promising for efficient implementation.", "publication_ref": ["b4"], "figure_ref": [], "table_ref": []}, {"heading": "A Additional Preliminaries", "text": "We make precise how ELQs can be viewed as databases as announced in Section 2 of the main paper. Formally, we inductively associate to every q a pointed database (D q , a q ) with D q tree-shaped (recall that a database is tree-shaped if the directed graph G D = (adom(D), {(a, b) | r(a, b) \u2208 D}) is a tree), as follows:\n\u2022 If q = , then D q contains the single fact (a q ); 5\n\u2022 if q = A, then D q contains the single fact A(a q );\n\u2022 if q = q 1 q 2 , then D q is obtained from (D q1 , d q1 ), (D q2 , d q2\n) by first taking the disjoint union of D q1 and D q2 and then identifying a q1 and a q2 to a q ;\n\u2022 if q = \u2203r.p, then D q is obtained from (D p , a p ) by taking D q = D p \u222a {r(a q , a p )} for a fresh individual a q .\nLet I 1 and I 2 be interpretations. The direct product of I 1 and I 2 , denoted I 1 \u00d7 I 2 , is the interpretation with domain \u2206 I1 \u00d7 \u2206 I2 and such that for all concept names A and role names r:\nA I1\u00d7I2 = A I1 \u00d7 A I2 r I1\u00d7I2 = r I1 \u00d7 r I2 .", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B Occam Algorithms and Proof of Theorem 1", "text": "Let O be an ontology and Q a class of queries. For a set of pointed databases S, we say that Q shatters S w. Theorem 3.2.1 of [Blumer et al., 1989] then implies the following. Lemma 4. If A is an Occam algorithm with the VC-dimension of effective hypothesis spaces bounded by p(s, |\u03a3|) \u2022 m \u03b1 , then A is a PAC learning algorithm with sample size\nr.t. O if for every subset S \u2286 S, there is a q \u2208 Q such that S = {(D, a) \u2208 S | a \u2208 q(D \u222a O)}. The VC-dimension of Q w.r.t. O is\nm(1/ , 1/\u03b4, n) = max 4 log 2 \u03b4 , 8p(s, |\u03a3|) log 13 1/(1\u2212\u03b1) .\nThere are certain difference between the setup used in this paper and the setup in [Blumer et al., 1989]. We comment on why we still obtain Lemma 4 from Theorem 3.2.1 of [Blumer et al., 1989]. The aim of [Blumer et al., 1989] is to study the learning of concept classes which are defined in a general way as a set C of concepts C \u2286 X where X is a fixed set of examples. Consequently, their definition of PAC algorithms refers to concept classes and, in contrast to Definition 1, does neither mention ontologies nor signatures. However, when fixing an L-ontology O and signature \u03a3, we obtain an associated concept class C O,\u03a3 by taking X to be the set of all pointed \u03a3-databases and each query q \u2208 Q as the concept that consists of all pointed \u03a3-databases that are positive examples for q. Moreover, by simply fixing O and \u03a3, any fitting algorithm A for (L, Q) turns into a learning algorithm for C O,\u03a3 in the sense of [Blumer et al., 1989]. Here, 'fixing' means that we promise to only run A on input ontology O and collections of labeled data examples E such that sig(E) \u2286 \u03a3 and E is q T -labeled w.r.t. O according to some q T \u2208 Q \u03a3 . The definition of Occam algorithms in [Blumer et al., 1989] refers to effective hypothesis spaces H A (s, m) and requires that their VC-dimension is bounded by p(s) \u2022 m \u03b1 (where ||O|| and |\u03a3| are considered constants). If A is Occam in our sense, then A with O and \u03a3 fixed is Occam in the sense of [Blumer et al., 1989]. Theorem 3.2.1 of that paper then gives that A with O and \u03a3 fixed is a PAC learning algorithm for C O,\u03a3 with the bound stated in Lemma 4.\nWe remark that the precondition of Theorem 3.2.1 in [Blumer et al., 1989] actually demands that the algorithm runs in polynomial time, but an analysis of the proof shows that this assumption is not used. Then, by Definition 1, every fitting algorithm A that is a PAC learning algorithm when restricted to O and \u03a3, for any O and \u03a3 and with the same function m describing the sample size, is a PAC learning algorithm for (L, Q).\nA final small difference is that, in [Blumer et al., 1989], the function m in the definition of PAC algorithms does not depend on the size of the examples. Our version is a standard variation and does not impair the application of Blumer's Theorem 3.2.1: to see this, it suffices to observe that we do not use this parameter in the definition of effective hypothesis spaces and thus our Occam algorithms (with fixed O and \u03a3) are also Occam algorithms in the sense of Blumer. Moreover, every PAC algorithm in the sense of Blumer is a PAC algorithm in our sense. Intuitively, having the example size as a parameter in the function m makes the lower bounds (results on algorithms not being non-sample PAC learners) stronger as it makes it impossible to use examples of excessive size. It is also more generous regarding the upper bounds (developing PAC algorithms), but we do not make use of that generosity.\nTheorem 1. Let (L, Q) be an OMQ language.\nEvery bounded fitting algorithm for (L, Q) is a (sampleefficient) PAC learning algorithm with sample size We next comment on the fact that, in the i-th round of the SPELL system, we try to fit ELQs that have at most i \u2212 1 existential quantifiers, rather than ELQs of size at most i. By using the following lemma and applying the same arguments as in the proof of Theorem 1, we obtain that our SAT-based approach yields a PAC learning algorithm with sample size\nO 1 \u2022 log 1 \u2022 log 1 \u03b4 \u2022 log |\u03a3| \u2022 ||q T || . Proof. Let B = BOUNDED-FITTING A\nO 1 \u2022 log 1 \u2022 log 1 \u03b4 \u2022 |\u03a3| \u2022 ||q T || . Lemma 5. Let O be an ELH r -ontology, n \u2265 1, and ELQ \u2203 (n)\nthe set of ELQs that have at most n existential restrictions. Then the VC-dimension of ELQ \u2203\n(n) w.r.t. O is at most 2(|\u03a3| + 1)n.\nProof. Let n \u2265 1. We first observe that the number of concepts in ELQ \u2203 (n) is bounded from above by m n = 4 (|\u03a3|+1)n . To see this, note that the number of rooted, directed, unlabeled trees with n nodes is bounded from above by the n-th Catalan number, which in turn is bounded from above by 4 n [Dutton and Brigham, 1986]. Each such tree gives rise to an ELQ by assigning a unique role name from \u03a3 to each of the at most n \u2212 1 edges of the tree and a set of concept names from \u03a3 to each of the at most n nodes of the tree. This clearly yields the stated bound m n . Then trivially, the VC-dimension of ELQ \u2203 (n) w.r.t. the empty ontology is at most log m n , thus 2(|\u03a3| + 1)n. Making the ontology non-empty may only decrease the VCdimension as it may make non-equivalent concepts equivalent, but not vice versa.\nIt is easy to see that (the proof of) Lemma 5 applies also to other DLs such as ELI and ALCI.", "publication_ref": ["b1", "b1", "b1", "b1", "b1", "b1", "b1", "b1", "b1", "b1"], "figure_ref": [], "table_ref": []}, {"heading": "C Proof of Theorem 2", "text": "We split the three Points in Theorem 2 into three separate theorems.\nTheorem 6. Let A be a fitting algorithm for ELQs that always produces a most specific fitting, if it exists. Then A is not a sample-efficient PAC learning algorithm.\nProof. Assume to the contrary of what we aim to show that there is a sample-efficient PAC learning algorithm that produces a most specific fitting concept, if it exists, with polynomial function m : R 2 \u00d7 N 4 \u2192 N as in Definition 1. Choose \u03a3 = {A, r}, q T = A, \u03b4 = = 0.5, and n even and large enough such that\nn n/2 > 2m(1/ , 1/\u03b4, 0, |\u03a3|, ||q T ||, n(n + 1)).\nWe next construct positive examples; negative examples are not used. Let S denote the set of subsets of {1, . . . , n} and let\nD S = {r(b 0 , b 1 ), . . . , r(b n\u22121 , b n )} \u222a {A(b i ) | i \u2208 S}\nas well as the pointed database (D S , a 0 ) that can be obtained by starting with {A(a 0 )} and then taking, for every i \u2208 S, a disjoint copy of D {1,...,n}\\{i} and identifying the root b 0 with a 0 . Note that every (D S , a 0 ) is a positive example for q T . A crucial property of (D S , a 0 ) is that it is a simulation dual of (D S , a 0 ) restricted to structures (D S , a 0 ), meaning the following. 7 Claim. For all S, S \u2208 S:\n(D S , a 0 ) \u03a3 (D S , a 0 ) iff (D S , a 0 ) \u03a3 (D S , a 0 ).\nThe claim is easy to verify. We do not work with unrestricted simulation duals here because we want the databases (D S , a 0 ) to be acyclic, and unrestricted simulation duals are not.\nLet P be the probability distribution that assigns probability 1/|S 1 2 | to every (D S , a 0 ) with S \u2208 S 1 2 , and probability 0 to all other pointed databases. Now assume that the algorithm is started on a collection of\nm(1/ , 1/\u03b4, 0, |\u03a3|, ||q T ||, n(n + 1)) labeled data examples E.\nSince all examples are acyclic, the most specific fitting q H exists [Jung et al., 2020] and is output by the algorithm. It is not important to make explicit at this point the exact details of q H , but it can be thought of as the direct product of all the examples in E, viewed as an ELQ.\nTo obtain a contradiction, it suffices to show that with probability at least 1 \u2212 \u03b4 = 0.5, we have error P,q T (q H ) > = 0.5. We argue that, in fact, q H violates all data examples (D S , a 0 ) with S \u2208 S 1 2 that are not in the sample E. The definition of P and choice of n then yield that with probability 1, error P,q T (q H ) > 0.5.\nThus take S \u2208 S \nNow, a 0 / \u2208 q H (D S ) follows from (D q H , a q H ) (D S , a 0\n) which is ruled out by Points 1 and 2 above and the fact that the composition of two simulations is again a simulation.\nTheorem 7. Let A be a fitting algorithm for ELQs that always produces a most general fitting, if it exists. Then A is not a sample-efficient PAC learning algorithm.\nProof. We only provide the missing details from the proof in the main part, that is, the proof of Points 1 and 2 stated in the main part and the place of the proof that say \"it follows from Point 1 that\": 1. q is the most general ELQ that fits (D q , a q , \u2212);\nLet p be an ELQ such that (D q , a q ) is a negative example for p. We have to show that p q. (D q , a q ) being a negative example for p means that a q / \u2208 p(D q ) and thus (D p , a p ) (D q , a q ) by Lemma 1. The definition of duals thus yields (D q , a q ) (D p , a p ) and Lemma 1 gives p q, as desired.\n2. For all T \u2286 S, q / \u2208 T implies p T q where p T = p\u2208T p. Consider the database D p T . Then clearly a p T \u2208 p T (D p T ). But since q / \u2208 T , D p T contains no r-path outgoing from a p T that contains the A/B-labeling of q, and thus a p T / \u2208 q(D p T ).", "publication_ref": ["b7"], "figure_ref": [], "table_ref": []}, {"heading": "It follows from Point 1 that q", "text": "H = (D q ,a q )\u2208E q is the most general ELQ that fits E. Clearly, q H q for every (D q , a q ) \u2208 E, and thus (D q , a q ) (D q H , a q H ). By Point 1, (D q , a q ) (D q , a q ). Since the composition of two simulations is a simulation, this implies (D q H , a q H ) (D q , a q ). It follows that q H fits E.\nIt remains to show that q H is most general. Assume that some ELQ p fits E. Then a q / \u2208 p(D q ) for all (D q , a q ) \u2208 E and thus (D p , a p ) (D q , a q ). By definition of duals, (D q , a q ) (D p , a p ) and this is witnessed by some simulation S q . But then q S q is a simulation showing (D q H , a q H ) (D p , a p ), and thus p q H as desired.\nTheorem 8. Let A be a fitting algorithm for ELQs that always produces a fitting of minimum quantifier depth. Then A is not a sample-efficient PAC learning algorithm.\nProof. Assume to the contrary of what we aim to show that there is a sample-efficient learning algorithm that produces a most shallow fitting concept, if it exists, with associated polynomial function m : R 2 \u00d7 N 4 \u2192 N as in Definition 1. We are going to use target queries of the form q T = \u2203t n+1 . . Choose \u03a3 = {r, s, t}, \u03b4 = 0.5, = 0.4, and n large enough such that\n2 n ! 2 np(n) (2 n \u2212 p(n))! > 1 \u2212 \u03b4 ( * )\nwhere p(n) is the polynomial\np(n) = m( 1 \u03b4 , 1 , 0, |\u03a3|, n + 1, p (n))\nand p is a fixed polynomial that describes the size of the examples that we are going to use. Lemma 6 below shows that such an n always exists, regardless of the precise polynomial p .\nThe meaning of the expression on the left-hand side of ( * ) will be explained later.\nRecall that the target query q T = \u2203t n+1 . is of quantifier depth n + 1. We construct (both positive and negative) examples such that with high probability, the drawn examples admit a fitting of quantifier depth n that, however, does not generalize well. Define a set of ELQs\nS = {\u2203r 1 . . . . \u2203r n . | r i \u2208 {r, s}, 1 \u2264 i \u2264 n}.\nBy Theorem 3, each q \u2208 S has a polynomially sized \u03a3-dual that consists of a single element (P q , a). By duality, (P q , a) is a positive example for q T . Also by Theorem 3, q T has a polynomially sized \u03a3-dual that contains a single element (D T , a). For each q \u2208 S, we construct a negative example (N q , a) by taking\n(N q , a) = (P q , a) \u00d7 (D T , a)\nwhere \u00d7 denotes the direct product of two pointed databases. Since the direct product is of polynomial size, both the positive examples and the negative examples are of size polynomial in n. We let p (n) be any polynomial that bounds (from above) the size of the examples.\nNote that by the properties of duals and products, for all q \u2208 S and for all \u03a3-ELQs q , we have (i) a \u2208 q (P q ) iff q q, and\n(ii) a \u2208 q (N q ) iff q q and q q T .\nTo see Point (i) note that a \u2208 q (P q ) iff (by Lemma 1)\n(D q , a q ) (P q , a) iff (by duality) (D q , a q ) (D q , a q ) iff (by Lemma 1) q q. Point (ii) can be shown similar and uses that (D, a) (D 1 , a 1 ) \u00d7 (D 2 , a 2 ) iff (D, a) (D 1 , a 1 ) and (D a ) (D 2 , a 2 ), for all pointed databases (D, a), (D 1 , a 1 ), (D 2 , a 2 ).\nLet P be the probability distribution that assigns probability 1 2 n+1 to every (P q , a) and (N q , a), and probability 0 to all other pointed databases. Now, assume that the algorithm is started on a collection of\nk = m(1/\u03b4, 1/ , 0, |\u03a3|, n + 1, p (n))\npointed databases E labeled according to q T and outputs a hypothesis q H . Note that the probability of sampling different objects from an N -element set is the ratio of those sequences of length that contain pairwise distinct elements in the set of all sequences of length , that is,\n\u22121 i=0 (N \u2212 ) N = N ! N \u2022 (N \u2212 )! .\nWe apply this observation to N = 2 n and = k. By choice of n, with probability > 1 \u2212 \u03b4 we have that for no q \u2208 S, both (N q , a) \u2208 E and (P q , a) \u2208 E. To derive a contradiction, we show that the error of q H is strictly larger than if this is the case.\nConsider the ELQ q = (Np,a,\u2212)\u2208E p. We claim that q fits E. Note that q q T for any q \u2208 S. Point (ii) then implies a / \u2208 q(N q ) for all q \u2208 S and thus q fits all negative examples. Together with our assumption that for no q \u2208 S, both (N q , a) \u2208 E and (P q , a) \u2208 E, Point (i) implies that a \u2208 p(P q ) for all (N p , a, \u2212) \u2208 E and (P p , a, +) \u2208 E.\nSince q is a fitting of depth n and the algorithm finds a fitting of minimal depth, q H must have depth at most n, which implies that q H q T . Consider all q \u2208 S. It must be that either q H q or q H q. In the first case, Point (i) implies a / \u2208 q H (P q ), hence q H labels the (positive) example (P q , a) incorrectly. In the second case, Point (ii) implies a \u2208 q H (N q ), hence q H labels the (negative) example (N q , a) incorrectly. Therefore, error P,q T (q H ) \u2265 0.5 > . Lemma 6. For every polynomial p(n),\nlim n\u2192\u221e ( 2 n ! 2 np(n) (2 n \u2212 p(n))! ) = 1.\nProof. As argued in the proof of Theorem 8, the term inside the limit is a probability, so the limit is at most 1. We start with bounding the expression inside the limit from below.\n2 n ! 2 np(n) (2 n \u2212 p(n))! = 2 n \u2022 (2 n \u2212 1) \u2022 \u2022 \u2022 \u2022 \u2022 (2 n \u2212 p(n) + 1) (2 n ) p(n) \u2265 (2 n \u2212 p(n) + 1) p(n) (2 n ) p(n) = 1 \u2212 p(n) + 1 2 n p(n)\nIt clearly suffices to show that the limit of the last expression is 1. In order to do so, we reformulate the expression to avoid the p(n) in the exponent.\nlim n\u2192\u221e ( 1 \u2212 p(n) + 1 2 n p(n) ) = lim n\u2192\u221e (exp(ln( 1 \u2212 p(n) + 1 2 n p(n) ))) = exp( lim n\u2192\u221e (ln( 1 \u2212 p(n) + 1 2 n p(n) ))) = exp( lim n\u2192\u221e (p(n) \u2022 ln(1 \u2212 p(n) + 1 2 n ))).\nTo determine the limit of a product where one factor p(n) converges to \u221e and the other ln(\u2022) converges to 0, we apply l'H\u00f4pital's rule. Set\nf (n) = ln(1 \u2212 p(n)+1 2 n ) and g(n) = 1/p(n), so lim n\u2192\u221e f (n) g(n)\nis exactly the limit we want to determine (inside the exp(\n\u2022)). L'H\u00f4pital's rule says that if lim n\u2192\u221e f (n) g (n) exists, then lim n\u2192\u221e f (n) g (n) = lim n\u2192\u221e f (n) g(n) .\nThe derivations f (n) and g (n) of f (n) and g(n) are:\nf (n) = ln(2)(p(n) + 1) \u2212 p (n) 2 n \u2212 p(n) \u2212 1 g (n) = \u2212p (n) q(n) for some polynomial q(n)\nIt remains to observe that f (n)/g (n) is an expression that has an exponential 2 n in its numerator and everywhere else only polynomials. Thus, lim n\u2192\u221e f (n)\ng (n) = 0 = lim n\u2192\u221e f (n) g(n)\n, which yields exp(0) = 1 as desired.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D Proof of Theorem 3 and Simulation Duals", "text": "Instead of proving Theorem 3, we directly prove the more general version in which databases D q for an ELQ q are replaced with DAG-shaped databases.\nA database D is DAG-shaped if the directed graph G D = (adom(D), {(u, v) | r(u, v) \u2208 D}) is a DAG.\nLet D be a database and a, b \u2208 adom(D). A path from a to b in D is a finite sequence a 1 , r 1 , a 2 , . . . , r k\u22121 , a k such that a 1 = a, a k = b, and r i (a i , a i+1 ) \u2208 D, for 1 \u2264 i < k. Note that role assertions may be traveled forwards, but not backwards. The codepth of an individual a in a DAG-shaped database D is the length of the longest path starting in a; the codepth of an individual a such that there is no assertion r(a, b) \u2208 D is defined to be 0.\nTheorem 9. Let \u03a3 be a finite signature and (D, a) be a pointed database such that D is DAG-shaped. Then, we can compute in polynomial time a \u03a3-simulation dual M of (D, a) such that\n\u2022 ||M || \u2264 3 \u2022 |\u03a3| \u2022 ||D|| 3 , and \u2022 if D is tree-shaped, then ||M || \u2264 3 \u2022 |\u03a3| \u2022 ||D|| 2 .\nMoreover, if D contains exactly one \u03a3-assertion that mentions a, then the computed M is actually a singleton set.\nProof. Let (D, a) be a pointed database with D DAG-shaped and \u03a3 a finite signature. We construct a \u03a3-simulation dual of (D, a) as follows. First, we define a database D * with domain\nadom(D * ) = {b } \u222a { b, A(b) | A(b) \u2208 D, A \u2208 \u03a3} \u222a { b, r(b, c) | r(b, c) \u2208 D, r \u2208 \u03a3}\nand include the following assertions, for all b, A(b) \u2208 adom(D * ) and b, r(b, c) \u2208 adom(D * ):\n(i) B(b ) for all B \u2208 \u03a3 \u2229 N C ; (ii) s(b , b ) for all s \u2208 \u03a3 \u2229 N R ; (iii) B( b, A(b) ) for all B \u2208 \u03a3 \u2229 N C with B = A; (iv) s( b, A(b) , b ) for all s \u2208 \u03a3 \u2229 N R ; (v) B( b, r(b, c) ) for all B \u2208 \u03a3 \u2229 N C ; (vi) s( b, r(b, c) , b ) for all s \u2208 \u03a3 \u2229 N R with s = r; (vii) r( b, r(b, c) , c, \u03b1 ) for all c, \u03b1 \u2208 adom(D * ).\nWe prove two auxiliary claims. \nS = {(c, b, A(b) )} \u222a {(c , b ) | c \u2208 adom(D )} is a \u03a3-simulation from D to D * with (c, b, A(b) ) \u2208 S as required.\nNow, let b have codepth greater than 0 and assume (D, b) \u03a3 (D , c). We distinguish cases on why the latter is the case:\n\u2022 If there is a concept name A \u2208 \u03a3 such that A(b) \u2208 D and A(c) / \u2208 D , we can argue as in the base case that (D , c) \u03a3 (D * , b, A(b) ). \nM a = {(D * , a, \u03b1 ) | a, \u03b1 \u2208 adom(D * )} is a \u03a3-simulation dual of (D, a). Proof of Claim 3. Suppose (D, a) \u03a3 (D , a ) for some (D , a ).\nThen Claim 2 implies that there is some a, \u03b1 \u2208 adom(D * ) with (D , a ) (D * , a, \u03b1 ). It remains to note that (D * , a, \u03b1 ) \u2208 M a . Conversely, suppose that (D, a) \u03a3 (D , a ) and assume for showing a contradiction that (D , a ) \u03a3 (D * , a, \u03b1 ) for some a, \u03b1 \u2208 adom(D * ). Since \u03a3 is transitive, we obtain (D, a) \u03a3 (D * , a, \u03b1 ), in contradiction to Claim 1. This finishes the proof of Claim 3.\nClearly, M a is a singleton set if D contains only a single \u03a3assertion mentioning a. It remains to analyze ||M a ||. We start with analyzing ||D * ||. Points (i) and (ii) together contribute |\u03a3| assertions. Points (iii) and (iv) contribute together |\u03a3| \u2022 n C assertions where n C denotes the number of assertions of shape A(b) in D. Points (v) and (vi) contribute |\u03a3| \u2022 n R assertions where n R denotes the number of assertions of shape r(b, c) in D. Finally, Point (vii) contributes |D| 2 assertions. Overall, we obtain\n||D * || \u2264 |\u03a3| + |\u03a3| \u2022 n C + |\u03a3| \u2022 n R + |D| 2 \u2264 3 \u2022 |\u03a3| \u2022 |D| 2 . Thus, ||M a || \u2264 |D| \u2022 3 \u2022 |\u03a3| \u2022 |D| 2 \u2264 3 \u2022 |\u03a3| \u2022 ||D|| 3 as required.\nIf D is tree-shaped, then the bound on the number of assertions that Point (vii) contributes can be improved. Only a single incoming assertion is added for each c, \u03b1 , resulting in |D| assertions. This improves the overall bounds to\n||D * || \u2264 |\u03a3| + |\u03a3| \u2022 n C + |\u03a3| \u2022 n R + |D| \u2264 3 \u2022 |\u03a3| \u2022 |D|. Thus, ||M a || \u2264 |D| \u2022 3 \u2022 |\u03a3| \u2022 |D| \u2264 3 \u2022 |\u03a3| \u2022 ||D|| 2 as required.\nWe next characterize the pointed databases that admit finite simulation duals. We need some additional notation.\nWe say that b is reachable from a if there is a path from a to b. We use D \u2193a to denote the database that consists of all facts A(b), r(b, b ) \u2208 D with b, b reachable from a. We note that, for some a \u2208 adom(D), D \u2193a might be empty (namely, if there are no assertions of the form A(a), r(a, b) \u2208 D). In a slight abuse of notation, we then allow to write (\u2205, a) and mean the pointed database ({ (a)}, a). We use D \u03a3 to denote the restriction of a database D to its \u03a3-assertions, for any signature \u03a3. Hence, D \u2193a \u03a3 is the restriction of D \u2193a to \u03a3. The proof of the characterization relies on the (standard) notion of unravelings. Let D be a database and a \u2208 adom(D). The unraveling of D at a is the (possibly infinite) database U whose domain adom(U) consists of all paths starting in a and that contains the following assertions for every p = a 1 , r 1 , a 2 , . . . , r k\u22121 , a k \u2208 adom(U):\n\u2022 A(p) for all A(a k ) \u2208 D and \u2022 r k\u22121 (p , p) for p = a 1 , r 1 , . . . , a k\u22121 .\nTheorem 10. Let \u03a3 be a finite signature and (D, a) a pointed database. Then, (D, a) has a finite \u03a3-simulation dual iff D \u2193a \u03a3 is DAG-shaped.\nProof. For the \"if\"-direction, suppose that D \u2193a \u03a3 is DAGshaped. It should be clear that both (D, a) \u03a3 (D \u2193a \u03a3 , a) and (D \u2193a \u03a3 , a) \u03a3 (D, a), and thus (D, a) and (D \u2193a \u03a3 , a) have the same \u03a3-simulation duals. Theorem 9 implies the existence of a finite \u03a3-simulation for (D \u2193a \u03a3 , a) and thus of (D, a). For \"only if\", we assume that D \u2193a \u03a3 is not DAG-shaped and show that there cannot be a finite \u03a3-simulation dual. Assume to the contrary of what is to be shown that M is a finite \u03a3simulation dual of (D, a). Let U be the unraveling of D \u2193a \u03a3 at a. Note that U is an infinite (and tree-shaped) database as D \u2193a \u03a3 is not DAG-shaped. Let, moreover, U i denote the restriction of U to individuals that have distance at most i from the root a, for i \u2265 0. Clearly, we have: (ii) (D, a) \u03a3 (U i , a), for all i \u2265 0.\nBy duality and Point (ii), for every i \u2265 0 there exists some (D , a ) \u2208 M with (U i , a) \u03a3 (D , a ). Since M is finite, there is some (D * , a * ) \u2208 M such that (U i , a) \u03a3 (D * , a * ) for infinitely many i \u2265 0. Using a standard \"simulation skipping\" argument, we can inductively construct a simulation S witnessing (U, a) \u03a3 (D * , a * ). By duality, we obtain (D, a) \u03a3 (U, a), which is in contradiction to Point (i) above.\nLet us now give some details regarding the simulation skipping argument. Let I be an infinite set such that (U i , a) \u03a3 (D * , a * ) for all i \u2208 I, and let (S i ) i\u2208I be a family of \u03a3simulations witnessing that. We provide an infinite family (S * i ) i\u22650 of relations adom(U i ) \u00d7 adom(D * ) such that, for every i \u2265 0:\n(a) S *\ni is a \u03a3-simulation witnessing (U i , a) \u03a3 (D * , a * ), and (b) S * i \u2286 S j , for infinitely many j \u2208 I. We start with setting S * 0 = {(a, a)} which clearly satisfies Points (a) and (b). To obtain S * i+1 from S * i , let B = adom(U i+1 ) \\ adom(U i ). Note that B is finite. By Point (b) applied to S * i , there is an infinite set J \u2286 I such that S * i \u2286 S j for every j \u2208 J. Since both B and D * are finite, we can pick an infinite subset J \u2286 J such that for every b \u2208 B, every d \u2208 adom(D * ), and every j, j \u2208 J , we have \n(b, d) \u2208 S j iff (b, d) \u2208 S j . Obtain S * i+1 from S * i by adding (b, d) \u2208 B \u00d7 adom(D * ) in case (b, d) \u2208 S j for all j \u2208 J . It", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E Proof of Theorem 4", "text": "Let (L, Q) be an OMQ language, O an L-ontology, and \u03a3 a finite signature. A (downward) frontier for a query q \u2208 Q with respect to O and \u03a3 is a finite set F \u2286 Q such that 1. each p \u2208 F is a downward refinement of q w.r.t. O and 2. for each p \u2208 Q \u03a3 that is a downward refinement of q w.r.t. O, there is some p \u2208 F such that O |= p p .\nNote that for both refinement operators \u03c1 1 and \u03c1 2 defined in the main part of the paper and any ELQ q and signature \u03a3, \u03c1 i (q, \u03a3) is a downward frontier for q with respect to the empty ontology and \u03a3.\nThe following clearly implies Theorem 4.   (||p||) . Moreover, q 1 , . . . , q k , p is a \u03c1, O, \u03a3-refinement sequence starting in q and ending in p, a contradiction. Hence, \u03c1 is an ideal downward refinement operator. Furthermore, \u03c1 is 2 O(n) -depth bounded.\nThe implication from 2 to 1 is trivial.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "F Proof of Lemma 2 and Theorem 5", "text": "Before proving Lemma 2 and Theorem 5, we recall some important properties of minimal ELQs. Recall that an ELQ q is minimal if there is no ELQ p with p \u2261 q and ||p|| < ||q||.\nDue to the correspondence of ELQs and EL-concepts, we may speak of minimal EL-concepts. Minimal ELQs (and thus, minimal EL-concepts) can be characterized in terms of functional simulations, where a simulation S between D 1 and D 2 is called functional if for every d \u2208 adom(D 1 ), there is at most one e \u2208 adom(D 2 ) with (d, e) \u2208 S. Lemma 7. An ELQ q is minimal iff the only functional simulation S from D q to D q with (a q , a q ) \u2208 S is the identity.\nThe following lemma shows several ways how to refine a minimal EL-concept. Its proof is straightforward using simulations and Lemmas 1 and 7, details are left to the reader. 1. For all C that can be obtained from C by replacing D with D A for some concept name A / \u2208 {A 1 , . . . , A k }, we have C C and C C .\n2. For all C that can be obtained from C by replacing D with D \u2203r. for some role name r / \u2208 {r 1 , . . . , r }, we have C\nC and C C .\n3. For all C that can be obtained from C by replacing a D with D \u2203r. D for some role name r \u2208 {r 1 , . . . , r } and a concept D such that D j D for all j with r = r j , we have C C and C C .\nThe following is a slight strengthening of [Jung et al., 2020, Lemma 6 in the full paper]. Recall that D \u2193a denotes the set of all assertions A(b), r(b, b ) in D such that b, b are reachable from a, c.f. Section D.\nLemma 9. Let (D 1 , a 1 ) and (D 2 , a 2 ) be pointed databases with D 2 tree-shaped. If (D 1 , a 1 ) (D 2 , a 2 ), then there exists a set D \u2286 D 1 with a 1 \u2208 adom(D 1 ) such that |D| \u2264 |D \u2193a2 2 |+1 and (D, a 1 ) (D 2 , a 2 ).\nProof. The proof is by induction on the depth of D \u2193a2\n2 . Assume first that D \u2193a2 2 has depth 0. If there exists a concept name A \u2208 N C with A(a 1 ) \u2208 D 1 but A(a 2 ) \u2208 D 2 , then D = {A(a 1 )} is as required. Otherwise there exists a role name r \u2208 N R and a with r(a 1 , a ) \u2208 D 1 . Then, D = {r(a 1 , a )} is as required. Now, suppose that D \u2193a2 2 has depth k > 0 and assume (D 1 , a 1 ) (D 2 , a 2 ). If there exists a concept name A \u2208 N C with A(a 1 ) \u2208 D 1 but A(a 2 ) \u2208 D 2 , then D = {A(a 1 )} is as required. Otherwise there exists a role name r \u2208 N R and some r(a 1 , a ) \u2208 D 1 such that for all b with (a 2 , b) \u2208 D Lemma 2. For every ELQ q and minimal downward neighbor p of q, we have ||p|| \u2264 2||q|| + 1.\nProof. Let p, q be ELQs such that p is a minimal downward neighbor of q, that is, p q, q p, and for all p with p p q, we have p \u2261 p or q \u2261 p . Since ||q|| \u2265 ||q || for every minimal ELQ q with q \u2261 q, we may assume that also q is minimal.\nLet (D p , a p ) and (D q , a q ) be the pointed databases associated with p and q, respectively. By Lemma 1, there is a simulation S from D q to D p with (a q , a p ) \u2208 S. We can w.l.o.g. assume S to be functional. Clearly, the inverse S \u2212 of S is not a simulation from D p to D q since q p. We distinguish two cases.\nCase 1. There is (a, a ) \u2208 S such that A(a ) \u2208 D p , but A(a) / \u2208 D q . Obtain D q from D q by adding A(a), and let q be the corresponding ELQ. Clearly, S is a simulation from D q to D p , hence p q . Moreover, by construction and Point 1 of Lemma 8, we have q q and q q . Since p is a downward neighbor of q and p q q, we thus have p \u2261 q . Since q is obtained from q by adding a single atom and ||p|| \u2264 ||q ||, we obtain ||p|| \u2264 2||q|| + 1 as required.\nCase 2. Case 1 does not apply and there is (a, a ) \u2208 S and an assertion r(a , b ) \u2208 D p such that there is no b with (b, b ) \u2208 S. Choose such an (a, a ) such that a has maximal distance from the root a p . We distinguish two subcases. This finishes the proof of the lemma.\nLet \u03a3 be a finite signature and p, q \u2208 ELQ \u03a3 . A \u03a3specialization sequence from p to q is a sequence q 1 , . . . , q k of queries from ELQ \u03a3 such that q 1 = p, q k = q, and q i+1 is a neighbor of q i , that is, q i+1 \u2208 \u03c1 2 (q i , \u03a3), for 1 \u2264 i < k. 8 We recall two useful properties of the EL-subsumption lattice [Kriegel, 2019, Corollary 5.2.3], namely that for all ELQs p, q \u2208 ELQ \u03a3 with p q, (I) there is a (finite) \u03a3-specialization sequence from q to p and\n(II) all \u03a3-specialization sequences from q to p have the same length (Jordan-Dedekind chain condition).\nLemma 3. \u03c1 1 and \u03c1 2 are ideal refinement operators for ELQ.\nProof. Both \u03c1 1 and \u03c1 2 are finite by definition. It follows from Property (I) above and the definition of \u03c1 2 , and Lemma 2 that \u03c1 2 is complete. The same is then true for \u03c1 1 as it contains \u03c1 2 in the sense that \u03c1 1 (q, \u03a3) \u2286 \u03c1 2 (q, \u03a3) for every ELQ q and finite signature \u03a3.\nTheorem 5. A 1 is a sample-efficient PAC learning algorithm, but A 2 is not.\nStop if q j or q j+1 is p m . By construction, ||q j || \u2264 2||q j\u22121 || + 1 for even j \u2265 2. Moreover, for odd j \u2265 2, q j \u2208 \u03c1 2 (q j\u22121 , \u03a3) and thus Lemma 2 implies that ||q j || \u2264 2||q j\u22121 || + 1. Finally, observe that the construction ensures that ||q j+2 || > 2||q j ||, for all odd j and thus the process stops after at most 2 log(s) steps.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "G Details for Section 5", "text": "From E O and the bound n, SPELL constructs a propositional \u03d5 = \u03d5 1 \u2227 \u03d5 2 that is satisfiable if and only if there is an ELQ q over \u03a3 = sig(E O ) with n \u2212 1 existential restrictions that fits E O .\nIntuitively, \u03d5 1 makes sure that every model of \u03d5 encodes an ELQ q in the variables c i,A , x i,r , y i,j as described in the main part. Recall that we use an arrangement of n concepts C 1 , . . . , C n . In what follows, we let q denote the encoded ELQ and assume that D q has individuals 1, . . . , n (as indicated by C 1 , . . . , C n ) with 1 being the root. For encoding a proper arrangement, \u03d5 1 , it contains the following clauses for each i with 2 \u2264 i \u2264 n:\ni\u22121 j=1 y j,i(1)\n\u00acy j1,i \u2228 \u00acy j2,i for all j 1 , j 2 with 1 \u2264 j 1 < j 2 < i (2)\nr\u2208\u03a3\u2229N R x i,r(3)\n\u00acx i,r \u2228 \u00acx i,r for all r, r \u2208 \u03a3 \u2229 N R with r = r (4)\nClauses ( 1) and (2) ensure that C j appears in exactly one C i , i < j as a conjunct of the form \u2203r.C j for some role name r. Clauses ( 3) and ( 4) ensure that there is a unique such role name. The formula \u03d5 2 makes sure that q fits E O by enforcing that ( * ) the variables s i,a are true in a model of \u03d5 iff a \u2208 C i (D) iff (D q , i) (D, a), where D is the disjoint union of all databases that occur in E O . To achieve this, we implement the properties of simulations in terms of clauses. The challenge is to capture both directions of the \"iff\" in ( * ) in an efficient way.\nFor all a \u2208 adom(D), type(a) is the set {A \u2208 N C | A(a) \u2208 D}. Let TP = {type(a) | a \u2208 adom(D)} be the set of all types in that occur D. We introduce auxiliary variables t i,\u03c4 , for every 1 \u2264 i \u2264 n and \u03c4 \u2208 TP with the intuition that t i,\u03c4 is true iff all concept names that occur as a conjunct in C i are contained in \u03c4 . This is enforced by including in \u03d5 2 the following clauses for all i with 1 \u2264 i \u2264 n and all types \u03c4 \u2208 TP: \u00act i,\u03c4 \u2228 \u00acc i,A for all A \u2208 (\u03a3 \u2229 N C \\ \u03c4 ) (5)\nt i,\u03c4 \u2228 A\u2208(\u03a3\u2229N C \\\u03c4 ) c i,A(6)\nThe simulation condition on concept names is now enforced by the following clauses, for i with 1 \u2264 i \u2264 n and all a \u2208 adom(D):\n\u00acs i,a \u2228 t i,type(a)\nThis captures, however, only the \"only if\"-direction of the \"iff\" in ( * ). To implement the other direction and the simulation condition for role names, we introduce further auxiliary variables d i,j,a (d as in defect to indicate non-simulation) with the intuitive meaning that d i,j,a is true iff (D q , i) (D, a) and there is an r-successor to j that is not simulated in any r-successor of a (the r is uniquely determined by j by Clauses (3) and ( 4)). This is achieved by the following clauses for all i, j with 1 \u2264 i < j \u2264 n, and r \u2208 \u03a3\u2229N R , a \u2208 adom(D), and all r(a, b) \u2208 D:\ns i,a \u2228 \u00act i,type(a) \u2228 n k=i+1 d i,k,a(8)\nd i,j,a \u2228 \u00acy i,j \u2228 \u00acx j,r \u2228 r(a,c)\u2208D\ns j,c(9)\n\u00acs i,a \u2228 \u00acd i,j,a (10) \u00acd i,j,a \u2228 y i,j\n(11) \u00acd i,j,a \u2228 \u00acx j,r \u2228 \u00acs j,b\nAs an example, Clause (11) can be read as follows: if there is a defect d i,j,a , then y i,j must be true, meaning that \u2203r.C j occurs as a conjunct in C i .\nIt can be verified that the number of variables is O(n 2 + n \u2022 |D|), the number of clauses is O(n 3 \u2022 |\u03a3| \u2022 |adom(D)|) and that the overall size of the formula is O(n 3 \u2022 |\u03a3| \u2022 |D|) as well.\nNext, we give details on the additional clauses that break some symmetries in \u03d5. As an example for these symmetries, consider the ELQ \u2203r.\u2203s. \u2203t. . In our encoding, it may be represented by the concepts C 1 = \u2203r.C 2 \u2203t.C 3 , C 2 = \u2203s.C 4 , C 3 = C 4 = or equivalently by the concepts C 1 = \u2203r.C 2 \u2203t.C 4 , C 2 = \u2203s.C 3 , C 3 = C 4 = . . The only difference between the arrangements C 1 , . . . , C 4 and C 1 , . . . , C 4 comes from assigning them in a different way to the vertices of G D C 1 .\nTo avoid this, we add in Round n of bounded fitting clauses that permit for every tree-shaped graph G with n vertices only a single canonical assignment of the concepts C 1 , . . . C n to the vertices of G. It suffices to consider tree-shaped graphs since G C is tree-shaped for every EL-concept C. To produce the clauses, we enumerate (outside the SAT solver) all possible tree-shaped graphs with n vertices. For each such graph G, we introduce a propositional variable x G and encode (in a straightforward way) that x G is true iff C 1 , . . . , C n are assigned to the vertices of G in the canonical way. We then assert (with a big disjunction) that one of the x G has to be satisfied. However, note that there are exponentially many possible graphs and therefore we only add these clauses if n < 12, to avoid spending too much time and undoing the benefit of breaking this symmetry. It is an interesting research question how to break even more symmetries.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "H Size-restricted fitting for EL and ELI", "text": "We analyze the complexity of the size-restricted fitting problem for ELQs, for ELIQs, and for the OMQ language (ELI, ELIQ). Recall that universal databases in the sense defined before Proposition 1 do not exist for the latter, and in fact not even for (EL, ELIQ). We discuss this a bit further at the end of this section. Recall that we generally assume unary coding of the input k to the size-restricted fitting problem. 9 An investigation of the problem under binary coding is left as future work; a good starting point for this are results in Jung et al., 2020]. Lemma 10. The following problems are NP-complete:\n\u2022 the size-restricted fitting problem for ELQs;\n\u2022 the problem of deciding given a set of labeled examples E and a number k, whether there is an ELQ that fits E and that uses at most k existential restrictions.\nProof. The arguments are essentially identical, so we give the proof only for the size-restricted fitting problem.\nFor the NP upper bound, let E, k be an input to the sizerestricted fitting problem. Observe that we can guess in polynomial time an ELQ q with ||q|| \u2264 k and verify in polynomial time that a \u2208 q(D) for all (D, a, +) \u2208 E and a / \u2208 q(D) for all (D, a, \u2212) \u2208 E. The latter is true since query evaluation of ELQs is possible in PTIME.\nFor NP-hardness, recall that the fitting problem for every class of unary conjunctive queries that includes all ELQs is NP-hard [ten Cate et al., 2022]. The proof of that statement is by reduction from 3CNF-satisfiability. In more detail, a given 3CNF-formula \u03d5 with m variables is translated to a collection of labeled data examples E such that \u03d5 is satisfiable iff E has a fitting ELQ of size p(m) for some fixed polynomial p. Thus, it actually constitutes a reduction to the size-restricted fitting problem for ELQs.\nTheorem 12. The size-restricted fitting problem is NP-complete for ELIQs and EXPTIME-complete for (ELI, ELIQ).\nProof. We start with the case without ontologies. For the NP upper bound, let E, k be an input to the size-restricted fitting problem. Observe that we can guess in polynomial time an ELIQ q with ||q|| \u2264 k and verify in polynomial time that a \u2208 q(D) for all (D, a, +) \u2208 E and a / \u2208 q(D) for all (D, a, \u2212) \u2208 E. The latter is true since query evaluation of ELIQs is possible in PTIME.", "publication_ref": ["b7", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgements", "text": "Balder ten Cate is supported by the European Union's Horizon 2020 research and innovation programme under grant MSCA-101031081 and Carsten Lutz by the DFG Collaborative Research Center 1320 EASE and by BMBF in DAAD project 57616814 (SECAI).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Proof. We start with analyzing A . Let E be the input to A 2 and let \u03a3 = sig(E). By Theorem 2, it suffices to show that A 2 produces a most general fitting of E (if it exists). By the Jordan-Dedekind chain condition, we can assign a level to every ELQ q defined as the length of \u03a3-specialization sequences from to q. Let M 1 , M 2 , . . . be the sequence of sets M constructed by the breadth-first search algorithm A 2 , that is, M 1 = { } and M i+1 is obtained from M i by applying the refinement operator \u03c1 2 . It is easy to show that for all i \u2265 0, the set M i contains precisely the ELQs of level i that fit the positive examples E + in E.\nSo suppose that a most general fitting q * exists and that A 2 returns some ELQ q after n rounds. Then q \u2208 M n . Since q is a fitting and q * is a most general fitting, we have q q * . By Property (I) above, there is a non-empty \u03a3-specialization sequence from q * to q. Thus, the level of q * is strictly smaller than that of q. But then there is an m < n such that the set M m contains q * , in contradiction to q being output by A 2 .\nTo show that A 1 is a sample-efficient PAC learning algorithm we show that it is an Occam algorithm. Let M 1 , M 2 , . . . be the sequence of sets M constructed by the breadth-first search algorithm A 1 . We show below that (i) for all i \u2265 1, q \u2208 M i implies ||q|| \u2264 2 i \u2212 1, and (ii) if q is an ELQs with ||q|| \u2264 s that fits the positive examples E + in E, then there is an i \u2264 2 log(s) with q \u2208 M i .\nPoints (i) and (ii) imply that A 1 returns a fitting ELQ that is only polynomially larger than a smallest fitting ELQ and is thus Occam. Indeed, let a smallest fitting ELQ q * be of size ||q * || = s and let q be the ELQ returned by A 1 . By (ii), A 1 discovers q * after 2 log(s) rounds, which by definition of A 1 implies that q is returned after at most 2 log(s) rounds. It thus follows from (i) that the returned ELQ q satisfies\nConsequently, there is a polynomial p such that \nApplying the induction hypothesis, we obtain\nFor Point (ii), let q be an ELQ with ||q|| \u2264 s fitting E + . It suffices to show that there is a \u03c1 1 , \u03a3-refinement sequence q 1 , . . . , q k from to q with k \u2264 2 log(s).\nLet p 1 , . . . , p m be a \u03a3-specialization sequence from to q, that is, p i+1 is a downward neighbor of p i (equivalently: p i+1 \u2208 \u03c1 2 (p i , \u03a3)), for all i. Inductively define q 1 , q 2 . . . as follows:\n\u2022 q 1 = p 1 = , and \u2022 for even numbers j \u2265 2, let be maximal with ||p || \u2264 2||q j\u22121 || + 1, and set: q j = p , and q j+1 = p +1 if < m.\nFor NP-hardness, recall that the fitting problem for every class of unary conjunctive queries that includes all ELQs is NP-hard [ten Cate et al., 2022]. The proof of that statement is by reduction from 3CNF-satisfiability. In more detail, a 3CNF-formula \u03d5 with m variables is translated to a collection of labeled data examples E such that \u03d5 is satisfiable iff E has a fitting ELIQ of size p(m) for some fixed polynomial p. Thus, it actually constitutes a reduction to the size-restricted fitting problem.\nWe now consider the OMQ language (ELI, ELIQ). We show EXPTIME-hardness by reduction from subsumption w.r.t. ELI-ontologies which is known to be EXPTIME-hard [Baader et al., 2008]. Let O, A, B be an input to the subsumption problem, that is, the question is to decide whether O |= A B. For the EXPTIME-upper bound let O, E, k be an input to the size-restricted fitting problem. We provide a Turing reduction to subsumption w.r.t. ELI-ontologies. In the reduction, we enumerate all ELIQs q with ||q|| \u2264 k, and test for each whether it fits E w.r.t. O using an oracle for answering instance queries over ELI knowledge bases. Since there are only exponentially many candidates q, each test whether q fits E w.r.t. O uses only |E| calls to the oracle. Since k is encoded in unary, the inputs to the oracle are of polynomial size. Finally, as the oracle itself runs in exponential time [Baader et al., 2008], the EXPTIME-upper bound follows.\nLet us return to the issue of universal databases in (ELI, ELIQ). As mentioned above, universal databases as defined in the main body of the paper do not exist for this OMQ language. For bounded fitting, however, one might consider a weaker notion. For every database D, ELI-ontology O, and k \u2265 1, one can compute a database U D,O,k that is k-universal for ELIQs in the sense that a \u2208 q(D\u222aO) iff a \u2208 q(U D,O,k ) for all ELIQs q with at most k existential restrictions (or of size at most ||k||, a stronger condition) and all a \u2208 adom(D). We do not give a detailed construction here, but only mention that such a database can be obtained from an infinite tree-shaped universal database by cutting off at depth k. What this means is that while we do not have available a universal database that works for all rounds of bounded fitting, for each single round k we can compute a k-universal database to be used in that round. In contrast to the case of (EL, ELQ), these kuniversal databases may become exponential in size. One may hope, though, that their size is still manageable in practical cases. Note that keeping the ontology and treating it in the SAT encoding is not an option due to the EXPTIME-hardness identified by Theorem 12.", "publication_ref": ["b13", "b0", "b0"], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "An Introduction to Description Logics", "journal": "Springer", "year": "1987", "authors": "; Angluin ; Dana Angluin;  Baader"}, {"ref_id": "b1", "title": "DL-Learner -A framework for inductive learning on the semantic web", "journal": "Frazier and Pitt", "year": "1986", "authors": " Blumer"}, {"ref_id": "b2", "title": "Actively learning concept and conjunctive queries under EL r -ontologies", "journal": "", "year": "2021", "authors": ""}, {"ref_id": "b3", "title": "Exact learning of ELI queries in the presence of DL-Lite-Horn ontologies", "journal": "", "year": "2022", "authors": "[ Funk"}, {"ref_id": "b4", "title": "Frontiers and exact learning of ELI queries under DL-Lite ontologies", "journal": "", "year": "1999", "authors": "[ Funk"}, {"ref_id": "b5", "title": "An algorithm based on counterfactuals for concept learning in the semantic web", "journal": "Appl. Intell", "year": "2007", "authors": "[ Iannone"}, {"ref_id": "b6", "title": "Model comparison games for Horn description logics", "journal": "IEEE", "year": "2019", "authors": "[ Jung"}, {"ref_id": "b7", "title": "Least general generalizations in description logic: Verification and existence", "journal": "AAAI Press", "year": "2020", "authors": "[ Jung"}, {"ref_id": "b8", "title": "J\u00f6rg-Uwe Kietz. Some lower bounds for the computational complexity of inductive logic programming", "journal": "", "year": "1993", "authors": "[ Jung"}, {"ref_id": "b9", "title": "Constructing and Extending Description Logic Ontologies using Methods of Formal Concept Analysis", "journal": "", "year": "2019", "authors": " Kriegel"}, {"ref_id": "b10", "title": "Jens Lehmann and Pascal Hitzler. Concept learning in description logics using refinement operators", "journal": "", "year": "2009", "authors": "Jens Kriegel; Christoph Lehmann;  Haase"}, {"ref_id": "b11", "title": "Jaroslav Nesetril and Patrice Ossona de Mendez. Sparsity -Graphs, Structures, and Algorithms", "journal": "Springer", "year": "2000", "authors": "[ Lutz"}, {"ref_id": "b12", "title": "Balder ten Cate and Victor Dalmau. Conjunctive queries: Unique characterizations and exact learnability", "journal": "", "year": "2021", "authors": "Dalmau Cate"}, {"ref_id": "b13", "title": "On the non-efficient PAC learnability of acyclic conjunctive queries", "journal": "", "year": "2022", "authors": "Cate "}, {"ref_id": "b14", "title": "Making the most of your triple store: query answering in OWL 2 using an RL reasoner", "journal": "ACM", "year": "1984", "authors": "Cate "}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "next construct negative examples; positive examples are not used. Define a set of ELQs S = S n where", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "t. an L-ontology O is any p \u2208 Q such that O |= p q and O |= q p. A (downward) refinement operator for (L, Q) is a function \u03c1 that associates every q \u2208 Q \u03a3 , L-ontology O, and finite signature \u03a3 with a set \u03c1(q, O, \u03a3) of downward refinements p \u2208 Q \u03a3 of q w.r.t. O. The operator \u03c1 is ideal if it is finite and complete where \u03c1 is 1. finite if \u03c1(q, O, \u03a3) is finite for all q, O, and finite \u03a3, and 2. complete if for all finite signatures \u03a3 and all", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 1 :1Figure 1: Yago experiment, dark red area indicates timeout (60min)", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "the cardinality of the largest set of pointed databases S that is shattered by Q w.r.t. O. Let (L, Q) be an OMQ language and A a fitting algorithm for (L, Q). For an L-ontology O, a finite signature \u03a3, and s, m \u2265 1, we use H A (O, \u03a3, s, m) to denote the set of all outputs that A makes when started on O and a collection of m data examples E such that sig(E) \u2286 \u03a3 and E is q T -labeled w.r.t. O according to some q T \u2208 Q \u03a3 with ||q T || \u2264 s. This is called an effective hypothesis space of A. We say that A is an Occam algorithm if there exists a polynomial p and a constant \u03b1 \u2208 [0, 1) such that for all L-ontologies O, finite signatures \u03a3, and s, m \u2265 1, the VC-dimension of H A (O, \u03a3, s, m) w.r.t. O is bounded by p(s, |\u03a3|) \u2022 m \u03b1 .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "be a bounded fitting algorithm for (L, Q). Let O be an L-ontology, \u03a3 a finite signature, and s, m \u2265 0. We show that the VC-dimension of H B (O, \u03a3, s, m) is at most O(s \u2022 log |\u03a3|). It is immediate from Definition 2 that when started on O and a collection of m data examples E such that sig(E) \u2286 \u03a3 and E is q T -labeled w.r.t. O according to some q T \u2208 Q \u03a3 with ||q T || \u2264 s, then B returns a fitting q \u2208 Q for E w.r.t. O whose size ||q|| is smallest among all fitting queries. Consequently, H B (O, \u03a3, s, m) consists only of queries q \u2208 Q with ||q|| \u2264 s. There are at most (|\u03a3|+c+1) s such queries for some constant 6 c and since 2 |S| queries are needed to shatter a set S, the VCdimension of H B (O, \u03a3, s, m) is at most log((|\u03a3|+c+1) s ) \u2208 O(s \u2022 log |\u03a3|), as desired. It remains to apply Lemma 4.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "12with (D S , a 0 ) / \u2208 E. To show that a 0 / \u2208 q H (D S ), it suffices to prove the following: 1. (D S , a 0 ) (D q H , a q H ); Let q S be (D S , a 0 ) viewed as an ELQ. We show that q S is a fitting of E. Take any (D S , a 0 ) \u2208 E. Then S = S and thus (D S , a 0 ) (D S , a 0 ). The claim yields (D S , a 0 ) (D S , a 0 ). Thus a 0 \u2208 q S (D S ), and we are done. Since q H is the most specific fitting of E, it follows from q S being a fitting that q H q S , which yields (D S , a 0 ) (D q H , a q H ) as desired. 2. (D S , a 0 ) (D S , a 0 ). Follows from the claim and the fact that (D S , a 0 ) (D S , a 0 ).", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Claim 1 .1For all b \u2208 adom(D) and b, \u03b1 \u2208 adom(D * ), (D, b) \u03a3 (D * , b, \u03b1 ). Proof of Claim 1. We prove the claim by induction on the codepth of b in D. If b has codepth 0, then \u03b1 is of the form A(b), for A(b) \u2208 D. By Point (iii) in the definition of D * , A( b, A(b) ) / \u2208 D * , and thus (D, b) \u03a3 (D * , b, \u03b1 ). Now, let b have codepth greater than 0. We distinguish cases on the shape of \u03b1. \u2022 If \u03b1 is of the form A(b) for some A(b) \u2208 D, then we can argue as in the base case that (D, b) \u03a3 (D * , b, \u03b1 ). \u2022 If \u03b1 is of the form r(b, c) for some r(b, c) \u2208 D, assume for contradiction that there is a \u03a3-simulation S from D to D * with (b, b, r(b, c) \u2208 S). Since S is a simulation and c is an r-successor of b in D, there has to be an r-successor c of b, r(b, c) in D * with (c, c ) \u2208 S. By Point (vi) and (vii), c is of shape c, \u03b1 . But then (D, c) \u03a3 (D , c, \u03b1 ), contradicting the induction hypothesis. Claim 2. For all b \u2208 adom(D) and pointed databases (D , c), if (D, b) \u03a3 (D , c) then there is a b, \u03b1 \u2208 adom(D * ) such that (D , c) \u03a3 (D * , b, \u03b1 ). Proof of Claim 2. We prove the claim by induction on the codepth of b in D. If b has codepth 0 and (D, b) \u03a3 (D , c), then there is a concept name A \u2208 \u03a3 such that A(b) \u2208 D and A(c) / \u2208 D . It can be verified using Points (i)-(iii) above that the relation", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "\u2022If there is an assertion r(b, b ) \u2208 D such that for all r(c, c ) \u2208 D , (D, b ) \u03a3 (D , c ). We show that (D , c) \u03a3 (D * , b, r(b, b ) ). The induction hypothesis implies that for all r(c, c ) \u2208 D there is an b , \u03b2 \u2208 adom(D * ) and a simulation S c from D to D * with (c , b , \u03b2 ) \u2208 S c . It can be verified using Points (v)-(vii) above that S = {(b, b, r(b, b ) )} \u222a {(c , b ) | c \u2208 adom(D )} \u222a r(c,c )\u2208D S c is a simulation from D to D * with (b, b, r(b, b ) ) \u2208 S. This completes the proofs of Claims 1 and 2. The next claim shows how to read off a simulation dual of (D, a) from D * . Claim 3. The set", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "(i) (D, a) \u03a3 (U, a), and", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "is routine to verify that S * i+1 satisfies Points (a) and (b), and that S = i\u22650 S * i witnesses (U, a) \u03a3 (D * , a * ), as desired.", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Theorem 11 .11Let (L, Q) be an OMQ language. The following are equivalent: 1. (L, Q) has an ideal downward refinement operator, 2. (L, Q) has an ideal downward refinement operator that is 2 O(n) -depth bounded, 3. for all L-ontologies O and all finite signatures \u03a3, each q \u2208 Q has a downward frontier w.r.t. O and \u03a3.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Proof. From 1 to 3 .3Let \u03c1 be a downward refinement operator. We claim that, for each L-ontology O and q \u2208 Q and finite signature \u03a3, \u03c1(q, O, \u03a3) is a downward frontier of q w.r.t. O and \u03a3. For Point 1 in the definition of downward frontier, note that any p \u2208 \u03c1(q, O, \u03a3) is a downward refinement of q w.r.t. O. For Point 2, let p \u2208 Q \u03a3 be any downward refinement of q w.r.t. O. By completeness, there is a finite sequence q 1 , . . . , q n with q 1 = q, q n = p, and q i+1 = \u03c1(q i , O, \u03a3) for all i. Note that, necessarily, n \u2265 2. It follows that q 2 \u2208 \u03c1(q, O, \u03a3) and O |= p q 2 .From 3 to 2. Take any L-ontology O and finite signature \u03a3. For each q \u2208 Q, let F (q, O, \u03a3) be a downward frontier for q w.r.t. O and \u03a3. Let \u03c1(q, O, \u03a3) be the union of F (q, O, \u03a3) with the set of all downwards refinements q \u2208 Q \u03a3 of q with ||q || \u2264 ||q||. Clearly, \u03c1 is a finite downward refinement operator. To show that \u03c1 is complete, consider any pair of queries (q, p) from Q such that O |= p q. Suppose for the sake of a contradiction that there is no downward \u03c1, O, \u03a3-refinement sequence starting in q and ending in a query p with O |= p \u2261 p . It then follows from the properties of downward frontiers that there exists an infinite sequence of (pairwise non-equivalent) queries q 1 , q 2 , . . . with q 1 = q and q i+1 \u2208 F (q i , O, \u03a3) for all i \u2265 0, such that p is a downward refinement of each q i w.r.t. O. Let k > 0 be minimal with ||q k || \u2265 ||p||. Clearly, k = 2 O", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "Lemma 8 .8Let C be a minimal EL-concept and D = A 1 \u2022 \u2022 \u2022 A k \u2203r 1 .D 1 \u2022 \u2022 \u2022 \u2203r .D a subconcept of C.Then the following hold:", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "2 , we have (D 1 , a ) (D 2 , b). Fix a . By induction hypothesis, we can fix for every b with r(a 2 , b) \u2208 D 2 , a subset D b \u2286 D 1 with a \u2208 adom(D b ) such that |D b | \u2264 |D \u2193b 2 | + 1 and (D b , a ) (D 2 , b). Let D be the union of {r(a, a )} and all D b with r(a 2 , b) \u2208 D 2 . Then D is as required.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "(a) If a does not have an r-successor in D q , obtain D q from D q by adding an atom r(a, b), for some fresh b.Clearly, S = S\u222a{(b, b )} is a functional simulation from D q to D p with (a q , a p ) \u2208 S , hence p q . Moreover, by construction and Point 2 of Lemma 8, q q and q q . Since p is a downward neighbor of q, we have q \u2261 p. Since p is obtained from q by adding a single atom and ||p|| \u2264 ||q ||, we obtain ||p|| \u2264 2||q|| + 1 as required.(b) Otherwise, a has r-successors a 1 , . . . , a k in D q . Let b 1 , . . . , b k be the (uniquely defined) elements with (a i , b i ) \u2208 S for every i. In particular, b / \u2208 {b 1 , . . . , b k }. Note that (D p , b ) (D q , a i ) for every i \u2208 {1, . . . , k}: otherwise, we would have (D p , b ) (D p , b i ) for some i in contradiction to minimality of p. Let D be a minimal subset of D p such that b \u2208 adom( D) and ( D, b ) (D q , a i ) for all i. By Lemma 9, | D| \u2264 (n 1 + 1) + \u2022 \u2022 \u2022 + (n k + 1) where n i is the number of assertions in the tree rooted at a i . It follows that | D| \u2264 |D q |. Now, obtain D q from D q by adding D (assuming that the individuals in D q and D are disjoint) as well as the assertion r(a, b ). Note that ||q ||= |D q | \u2264 |D q | + | D| + 1 \u2264 2|D q | + 1 = 2||q|| + 1.Clearly, S can be extended to a functional simulation from D q to D p , hence p q . Moreover, by construction and Point 3 of Lemma 8, q q and q q . Since p is a downward neighbor of q, this implies q \u2261 p. Hence, ||p|| \u2264 ||q || \u2264 2||q|| + 1 as required.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "These different representations correspond to different models of \u03d5 1 . Consider the underlying graphsG D C = (adom(D C ), {(a, b) | r(a, b) \u2208 D C }) of concepts, where D C is the concept C viewed as a pointed database. Note that G D C 1 = G D C 1", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "Definition 1. A PAC learning algorithm for an OMQ language (L, Q) is a (potentially randomized) algorithm A associated with a function m : R 2 \u00d7 N 4 \u2192 N such that \u2022 A takes as input an L-ontology O and a collection of labeled data examples E;\u2022 for all , \u03b4 \u2208 (0, 1), all L-ontologies O, all finite signatures \u03a3, all s Q , s E \u2265 0, all probability distributions P over pointed databases (D, c) with sig(D) \u2286 \u03a3 and ||D|| \u2264 s E , and all q T \u2208 Q \u03a3 with ||q T || \u2264 s", "figure_data": "Q , thefollowing holds: when running A on O and a collec-tion E of at least m(1/\u03b4, 1/ , ||O||, |\u03a3|, s Q , s E ) labeleddata examples that are q T -labeled w.r.t. O and drawnaccording to P , it returns a hypothesis q H such that withprobability at least 1 \u2212 \u03b4 (over the choice of E), we haveerror P,q T (q H ) \u2264 ."}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": ".77 0.78 0.85 0.85 0.86 0.89 0.90 0.96 0.96 0.96 0.96 0.98 0.98 0.98 0.98 SPELL 0.80 0.81 0.84 0.85 0.86 0.86 0.89 0.97 0.98 0.98 0.98 0.98 0.98 0.98 0.98", "figure_data": "Sample Size 51015202530354045505560657075ELTL 0"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "", "figure_data": "Generalization experiment accuracieso2b-1 o2b-2 o2b-3 o2b-4 o2b-5 o2b-6ELTLTOTO27458028152SPELL"}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "OWL2Bench running times [s], TO: >60min", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "= | A | C D | \u2203r.C", "formula_coordinates": [2.0, 143.88, 633.37, 94.39, 8.74]}, {"formula_id": "formula_1", "formula_text": "O |= q 1 q 2 if for all databases D, q 1 (D \u222a O) \u2286 q 2 (D \u222a O). We say that q 1 and q 2 are equiv- alent w.r.t. O, written O |= q 1 \u2261 q 2 , if O |= q 1 q 2 and O |= q 2 q 1 . When O = \u2205, we write q 1 q 2 and q 1 \u2261 q 2 .", "formula_coordinates": [2.0, 315.0, 550.31, 244.65, 42.53]}, {"formula_id": "formula_2", "formula_text": "D q = {r(a q , a 1 ), s(a 1 , a 2 ), A(a 2 )}. Let D 1 , D 2 be databases and \u03a3 a signature. A \u03a3-simulation from D 1 to D 2 is a relation S \u2286 adom(D 1 ) \u00d7 adom(D 2 ) such that for all (a 1 , a 2 ) \u2208 S: 1. if A(a 1 ) \u2208 D 1 with A \u2208 \u03a3, then A(a 2 ) \u2208 D 2 ; 2. if r(a 1 , b 1 ) \u2208 D 1 with r \u2208 \u03a3, there is r(a 2 , b 2 ) \u2208 D 2 such that (b 1 , b 2 ) \u2208 S.", "formula_coordinates": [2.0, 315.0, 605.1, 244.74, 80.39]}, {"formula_id": "formula_3", "formula_text": "(D 1 , a 1 ) \u03a3 (D 2 , a 2 )", "formula_coordinates": [3.0, 52.83, 57.16, 87.6, 9.65]}, {"formula_id": "formula_4", "formula_text": "O |= q q for every q \u2208 Q that fits E. Example 1. Consider the collection E 0 of examples ({r(a, a), A(a), B(a)}, a, +), ({A(a), r(a, b), B(b)}, a, +), ({r(a, b)}, b, \u2212).", "formula_coordinates": [3.0, 52.83, 248.57, 244.16, 44.17]}, {"formula_id": "formula_5", "formula_text": "Proposition 1. An ELQ q fits a collection of labeled examples E w.r.t. an ELH r -ontology O iff q fits E O w.r.t. \u2205.", "formula_coordinates": [3.0, 54.0, 543.36, 243.0, 20.68]}, {"formula_id": "formula_6", "formula_text": "P,q T (q H ) = Pr (D,a)\u223cP (a \u2208 q H (D \u222a O) \u2206 q T (D \u222a O))", "formula_coordinates": [3.0, 79.18, 651.18, 212.12, 15.16]}, {"formula_id": "formula_7", "formula_text": "O 1 \u2022 log 1 \u2022 log 1 \u03b4 \u2022 log |\u03a3| \u2022 ||q T || .", "formula_coordinates": [4.0, 54.0, 214.24, 163.74, 13.47]}, {"formula_id": "formula_8", "formula_text": "(D, a) \u03a3 (D , a ) iff (D , a ) \u03a3 (D , a ) for all (D , a ) \u2208 M.", "formula_coordinates": [4.0, 69.42, 543.92, 212.16, 22.75]}, {"formula_id": "formula_9", "formula_text": "2 n > 2m(1/\u03b4, 1/ , 0, |\u03a3|, 3n, 3 \u2022 |\u03a3| \u2022 ||C n || 2 ). Further choose q T = C n .", "formula_coordinates": [4.0, 315.0, 342.43, 243.17, 22.19]}, {"formula_id": "formula_10", "formula_text": "S 0 = { } S i = {\u2203r.(\u03b1 C) | C \u2208 S i\u22121 , \u03b1 \u2208 {A, B}}.", "formula_coordinates": [4.0, 321.03, 393.29, 230.93, 9.65]}, {"formula_id": "formula_11", "formula_text": "collection of m(1/\u03b4, 1/ , 0, |\u03a3|, 3n, 3 \u2022 |\u03a3| \u2022 ||C n || 2 ) labeled", "formula_coordinates": [4.0, 315.0, 588.09, 243.0, 11.23]}, {"formula_id": "formula_12", "formula_text": "H ) = |S|\u2212|E| |S| > 1 2 .", "formula_coordinates": [4.0, 453.93, 692.21, 76.44, 14.38]}, {"formula_id": "formula_13", "formula_text": "q, p \u2208 Q \u03a3 , O |= p q implies that there is a finite \u03c1, O, \u03a3- refinement sequence from q to p, that is, a sequence of queries q 1 , . . . , q n such that q = q 1 , q i+1 \u2208 \u03c1(q i , O, \u03a3) for 1 \u2264 i < n, and O |= q n \u2261 p.", "formula_coordinates": [5.0, 73.93, 260.15, 224.73, 53.49]}, {"formula_id": "formula_14", "formula_text": "O 1 \u2022 log 1 \u2022 log 1 \u03b4 \u2022 |\u03a3| \u2022 ||q T ||", "formula_coordinates": [6.0, 54.0, 340.45, 144.43, 13.47]}, {"formula_id": "formula_15", "formula_text": "C n = \u2203actor. n i=1 r i .", "formula_coordinates": [6.0, 460.6, 560.69, 89.65, 14.11]}, {"formula_id": "formula_16", "formula_text": "< 1 < 1 < 1 < 1 < 1 < 1", "formula_coordinates": [7.0, 108.62, 162.21, 178.7, 7.86]}, {"formula_id": "formula_17", "formula_text": "k i=1 A i , k \u2265 1.", "formula_coordinates": [7.0, 242.08, 558.02, 56.66, 14.11]}, {"formula_id": "formula_18", "formula_text": "k-path k-1-conj k-2-conj k ELTL SPELL ELTL SPELL ELTL SPELL 4 1 <1 1 <1 1 <1 6 1 <1 2 <1 394 <1 8 1 <1 20 <1 TO <110", "formula_coordinates": [7.0, 340.74, 137.28, 191.52, 62.88]}, {"formula_id": "formula_19", "formula_text": "\u2022 if q = q 1 q 2 , then D q is obtained from (D q1 , d q1 ), (D q2 , d q2", "formula_coordinates": [10.0, 65.46, 172.15, 231.54, 20.61]}, {"formula_id": "formula_20", "formula_text": "A I1\u00d7I2 = A I1 \u00d7 A I2 r I1\u00d7I2 = r I1 \u00d7 r I2 .", "formula_coordinates": [10.0, 123.71, 276.03, 102.58, 24.82]}, {"formula_id": "formula_21", "formula_text": "r.t. O if for every subset S \u2286 S, there is a q \u2208 Q such that S = {(D, a) \u2208 S | a \u2208 q(D \u222a O)}. The VC-dimension of Q w.r.t. O is", "formula_coordinates": [10.0, 53.64, 340.82, 243.36, 41.83]}, {"formula_id": "formula_22", "formula_text": "m(1/ , 1/\u03b4, n) = max 4 log 2 \u03b4 , 8p(s, |\u03a3|) log 13 1/(1\u2212\u03b1) .", "formula_coordinates": [10.0, 54.0, 581.56, 255.63, 22.52]}, {"formula_id": "formula_23", "formula_text": "O 1 \u2022 log 1 \u2022 log 1 \u03b4 \u2022 log |\u03a3| \u2022 ||q T || . Proof. Let B = BOUNDED-FITTING A", "formula_coordinates": [10.0, 315.0, 574.21, 163.74, 31.71]}, {"formula_id": "formula_24", "formula_text": "O 1 \u2022 log 1 \u2022 log 1 \u03b4 \u2022 |\u03a3| \u2022 ||q T || . Lemma 5. Let O be an ELH r -ontology, n \u2265 1, and ELQ \u2203 (n)", "formula_coordinates": [11.0, 54.0, 175.97, 242.5, 30.91]}, {"formula_id": "formula_25", "formula_text": "n n/2 > 2m(1/ , 1/\u03b4, 0, |\u03a3|, ||q T ||, n(n + 1)).", "formula_coordinates": [11.0, 85.4, 621.76, 187.54, 22.31]}, {"formula_id": "formula_26", "formula_text": "D S = {r(b 0 , b 1 ), . . . , r(b n\u22121 , b n )} \u222a {A(b i ) | i \u2208 S}", "formula_coordinates": [11.0, 329.37, 85.59, 214.26, 9.65]}, {"formula_id": "formula_27", "formula_text": "(D S , a 0 ) \u03a3 (D S , a 0 ) iff (D S , a 0 ) \u03a3 (D S , a 0 ).", "formula_coordinates": [11.0, 335.15, 204.11, 202.71, 10.62]}, {"formula_id": "formula_28", "formula_text": "m(1/ , 1/\u03b4, 0, |\u03a3|, ||q T ||, n(n + 1)) labeled data examples E.", "formula_coordinates": [11.0, 315.0, 299.99, 244.74, 9.65]}, {"formula_id": "formula_29", "formula_text": "Now, a 0 / \u2208 q H (D S ) follows from (D q H , a q H ) (D S , a 0", "formula_coordinates": [11.0, 315.0, 606.93, 239.79, 10.9]}, {"formula_id": "formula_30", "formula_text": "H = (D q ,a q )\u2208E q is the most general ELQ that fits E. Clearly, q H q for every (D q , a q ) \u2208 E, and thus (D q , a q ) (D q H , a q H ). By Point 1, (D q , a q ) (D q , a q ). Since the composition of two simulations is a simulation, this implies (D q H , a q H ) (D q , a q ). It follows that q H fits E.", "formula_coordinates": [12.0, 72.76, 268.22, 224.24, 83.05]}, {"formula_id": "formula_31", "formula_text": "2 n ! 2 np(n) (2 n \u2212 p(n))! > 1 \u2212 \u03b4 ( * )", "formula_coordinates": [12.0, 119.13, 573.92, 177.87, 24.06]}, {"formula_id": "formula_32", "formula_text": "p(n) = m( 1 \u03b4 , 1 , 0, |\u03a3|, n + 1, p (n))", "formula_coordinates": [12.0, 101.61, 621.97, 147.79, 22.31]}, {"formula_id": "formula_33", "formula_text": "S = {\u2203r 1 . . . . \u2203r n . | r i \u2208 {r, s}, 1 \u2264 i \u2264 n}.", "formula_coordinates": [12.0, 341.34, 118.54, 190.32, 9.65]}, {"formula_id": "formula_34", "formula_text": "(N q , a) = (P q , a) \u00d7 (D T , a)", "formula_coordinates": [12.0, 379.03, 208.41, 114.95, 9.65]}, {"formula_id": "formula_35", "formula_text": "(D q , a q ) (P q , a) iff (by duality) (D q , a q ) (D q , a q ) iff (by Lemma 1) q q. Point (ii) can be shown similar and uses that (D, a) (D 1 , a 1 ) \u00d7 (D 2 , a 2 ) iff (D, a) (D 1 , a 1 ) and (D a ) (D 2 , a 2 ), for all pointed databases (D, a), (D 1 , a 1 ), (D 2 , a 2 ).", "formula_coordinates": [12.0, 313.83, 347.11, 245.33, 53.49]}, {"formula_id": "formula_36", "formula_text": "k = m(1/\u03b4, 1/ , 0, |\u03a3|, n + 1, p (n))", "formula_coordinates": [12.0, 412.98, 434.78, 146.19, 8.74]}, {"formula_id": "formula_37", "formula_text": "\u22121 i=0 (N \u2212 ) N = N ! N \u2022 (N \u2212 )! .", "formula_coordinates": [12.0, 380.36, 517.16, 122.89, 25.41]}, {"formula_id": "formula_38", "formula_text": "lim n\u2192\u221e ( 2 n ! 2 np(n) (2 n \u2212 p(n))! ) = 1.", "formula_coordinates": [13.0, 110.76, 157.27, 129.48, 24.06]}, {"formula_id": "formula_39", "formula_text": "2 n ! 2 np(n) (2 n \u2212 p(n))! = 2 n \u2022 (2 n \u2212 1) \u2022 \u2022 \u2022 \u2022 \u2022 (2 n \u2212 p(n) + 1) (2 n ) p(n) \u2265 (2 n \u2212 p(n) + 1) p(n) (2 n ) p(n) = 1 \u2212 p(n) + 1 2 n p(n)", "formula_coordinates": [13.0, 56.34, 233.91, 238.32, 83.66]}, {"formula_id": "formula_40", "formula_text": "lim n\u2192\u221e ( 1 \u2212 p(n) + 1 2 n p(n) ) = lim n\u2192\u221e (exp(ln( 1 \u2212 p(n) + 1 2 n p(n) ))) = exp( lim n\u2192\u221e (ln( 1 \u2212 p(n) + 1 2 n p(n) ))) = exp( lim n\u2192\u221e (p(n) \u2022 ln(1 \u2212 p(n) + 1 2 n ))).", "formula_coordinates": [13.0, 94.07, 370.75, 162.86, 114.5]}, {"formula_id": "formula_41", "formula_text": "f (n) = ln(1 \u2212 p(n)+1 2 n ) and g(n) = 1/p(n), so lim n\u2192\u221e f (n) g(n)", "formula_coordinates": [13.0, 54.0, 516.25, 243.0, 28.88]}, {"formula_id": "formula_42", "formula_text": "\u2022)). L'H\u00f4pital's rule says that if lim n\u2192\u221e f (n) g (n) exists, then lim n\u2192\u221e f (n) g (n) = lim n\u2192\u221e f (n) g(n) .", "formula_coordinates": [13.0, 54.0, 547.18, 244.74, 25.69]}, {"formula_id": "formula_43", "formula_text": "f (n) = ln(2)(p(n) + 1) \u2212 p (n) 2 n \u2212 p(n) \u2212 1 g (n) = \u2212p (n) q(n) for some polynomial q(n)", "formula_coordinates": [13.0, 88.52, 595.33, 173.97, 49.85]}, {"formula_id": "formula_44", "formula_text": "g (n) = 0 = lim n\u2192\u221e f (n) g(n)", "formula_coordinates": [13.0, 189.8, 678.76, 104.81, 14.38]}, {"formula_id": "formula_45", "formula_text": "A database D is DAG-shaped if the directed graph G D = (adom(D), {(u, v) | r(u, v) \u2208 D}) is a DAG.", "formula_coordinates": [13.0, 315.0, 96.33, 244.16, 30.87]}, {"formula_id": "formula_46", "formula_text": "\u2022 ||M || \u2264 3 \u2022 |\u03a3| \u2022 ||D|| 3 , and \u2022 if D is tree-shaped, then ||M || \u2264 3 \u2022 |\u03a3| \u2022 ||D|| 2 .", "formula_coordinates": [13.0, 326.46, 270.96, 200.58, 27.01]}, {"formula_id": "formula_47", "formula_text": "adom(D * ) = {b } \u222a { b, A(b) | A(b) \u2208 D, A \u2208 \u03a3} \u222a { b, r(b, c) | r(b, c) \u2208 D, r \u2208 \u03a3}", "formula_coordinates": [13.0, 340.2, 381.74, 190.9, 38.7]}, {"formula_id": "formula_48", "formula_text": "(i) B(b ) for all B \u2208 \u03a3 \u2229 N C ; (ii) s(b , b ) for all s \u2208 \u03a3 \u2229 N R ; (iii) B( b, A(b) ) for all B \u2208 \u03a3 \u2229 N C with B = A; (iv) s( b, A(b) , b ) for all s \u2208 \u03a3 \u2229 N R ; (v) B( b, r(b, c) ) for all B \u2208 \u03a3 \u2229 N C ; (vi) s( b, r(b, c) , b ) for all s \u2208 \u03a3 \u2229 N R with s = r; (vii) r( b, r(b, c) , c, \u03b1 ) for all c, \u03b1 \u2208 adom(D * ).", "formula_coordinates": [13.0, 312.79, 458.52, 216.67, 107.97]}, {"formula_id": "formula_49", "formula_text": "S = {(c, b, A(b) )} \u222a {(c , b ) | c \u2208 adom(D )} is a \u03a3-simulation from D to D * with (c, b, A(b) ) \u2208 S as required.", "formula_coordinates": [14.0, 54.0, 248.47, 243.0, 37.48]}, {"formula_id": "formula_50", "formula_text": "M a = {(D * , a, \u03b1 ) | a, \u03b1 \u2208 adom(D * )} is a \u03a3-simulation dual of (D, a). Proof of Claim 3. Suppose (D, a) \u03a3 (D , a ) for some (D , a ).", "formula_coordinates": [14.0, 52.83, 549.33, 244.16, 53.08]}, {"formula_id": "formula_51", "formula_text": "||D * || \u2264 |\u03a3| + |\u03a3| \u2022 n C + |\u03a3| \u2022 n R + |D| 2 \u2264 3 \u2022 |\u03a3| \u2022 |D| 2 . Thus, ||M a || \u2264 |D| \u2022 3 \u2022 |\u03a3| \u2022 |D| 2 \u2264 3 \u2022 |\u03a3| \u2022 ||D|| 3 as required.", "formula_coordinates": [14.0, 314.69, 128.15, 245.06, 29.99]}, {"formula_id": "formula_52", "formula_text": "||D * || \u2264 |\u03a3| + |\u03a3| \u2022 n C + |\u03a3| \u2022 n R + |D| \u2264 3 \u2022 |\u03a3| \u2022 |D|. Thus, ||M a || \u2264 |D| \u2022 3 \u2022 |\u03a3| \u2022 |D| \u2264 3 \u2022 |\u03a3| \u2022 ||D|| 2 as required.", "formula_coordinates": [14.0, 314.69, 208.7, 245.05, 29.99]}, {"formula_id": "formula_53", "formula_text": "(a) S *", "formula_coordinates": [15.0, 57.89, 218.0, 26.8, 10.53]}, {"formula_id": "formula_54", "formula_text": "(b, d) \u2208 S j iff (b, d) \u2208 S j . Obtain S * i+1 from S * i by adding (b, d) \u2208 B \u00d7 adom(D * ) in case (b, d) \u2208 S j for all j \u2208 J . It", "formula_coordinates": [15.0, 54.0, 345.34, 243.0, 38.95]}, {"formula_id": "formula_55", "formula_text": "i\u22121 j=1 y j,i(1)", "formula_coordinates": [17.0, 328.42, 343.81, 229.58, 30.32]}, {"formula_id": "formula_56", "formula_text": "r\u2208\u03a3\u2229N R x i,r(3)", "formula_coordinates": [17.0, 328.42, 397.72, 229.58, 20.81]}, {"formula_id": "formula_57", "formula_text": "t i,\u03c4 \u2228 A\u2208(\u03a3\u2229N C \\\u03c4 ) c i,A(6)", "formula_coordinates": [17.0, 329.4, 680.09, 228.6, 21.2]}, {"formula_id": "formula_59", "formula_text": "s i,a \u2228 \u00act i,type(a) \u2228 n k=i+1 d i,k,a(8)", "formula_coordinates": [18.0, 102.74, 229.58, 194.26, 30.55]}, {"formula_id": "formula_60", "formula_text": "s j,c(9)", "formula_coordinates": [18.0, 233.9, 268.25, 63.1, 9.65]}], "doi": ""}