{"title": "Passive Ultra-Wideband Single-Photon Imaging", "authors": "Mian Wei; Sotiris Nousias; Rahul Gulve; David B Lindell; Kiriakos N Kutulakos", "pub_date": "", "abstract": "We consider the problem of imaging a dynamic scene over an extreme range of timescales simultaneously-seconds to picoseconds-and doing so passively, without much light, and without any timing signals from the light source(s) emitting it. Because existing flux estimation techniques for single-photon cameras break down in this regime, we develop a flux probing theory that draws insights from stochastic calculus to enable reconstruction of a pixel's timevarying flux from a stream of monotonically-increasing photon detection timestamps. We use this theory to (1) show that passive free-running SPAD cameras have an attainable frequency bandwidth that spans the entire DC-to-31 GHz range in low-flux conditions, (2) derive a novel Fourier-domain flux reconstruction algorithm that scans this range for frequencies with statistically-significant support in the timestamp data, and (3) ensure the algorithm's noise model remains valid even for very low photon counts or non-negligible dead times. We show the potential of this asynchronous imaging regime by experimentally demonstrating several never-seen-before abilities: (1) imaging a scene illuminated simultaneously by sources operating at vastly different speeds without synchronization (bulbs, projectors, multiple pulsed lasers), (2) passive non-line-ofsight video acquisition, and (3) recording ultra-wideband video, which can be played back later at 30 Hz to show everyday motions-but can also be played a billion times slower to show the propagation of light itself.", "sections": [{"heading": "Introduction", "text": "A basic rule of thumb in high-speed imaging is that speed needs light: the faster a scene changes, the more light we need to image it accurately without excessive noise or motion blur. Over the decades, high-speed light sources [1], fast cameras [2][3][4], and depth sensors [5,6] have made it possible to image dynamic phenomena occurring in eversmaller time intervals with the help of actively-controlled light sources and synchronization: to collect enough light, the same picosecond-or nanosecond-scale event may be imaged millions of times by operating a camera and a source in lockstep, at MHz repetition rates or more.\nAcquiring videos of ultrafast phenomena this way-from imaging light in flight [7] to fast biological processes [8]is now quite common. Unfortunately, while these techniques do capture ultrafast events, they cannot simultaneously capture slower ones too: time wraps at the sync period, blurring out anything occurring over longer timespans.\nBut how do we image highly dynamic scenes-both slow and ultrafast-passively, without any light sources under our control, no synchronization, and not much light? Very little is known about this problem because existing models for passive low-light imaging [9][10][11][12][13] break down at timescales much shorter than the timespan between photon arrivals. As a result, ultrafast imaging in low light has remained beyond the reach of passive methods.\nIn this work we seek to bridge these two regimes, active and passive, by revisiting the need for synchronization when imaging ultrafast scenes in low light. Working from first principles, we develop a novel theory of passive singlephoton imaging that is specifically designed to eliminate synchronization between a camera and the light sources in a scene. The only requirements are that (1) the camera's pixels can detect and time-stamp individual photons and (2) their dead-time period does not impair detection of photons from one source significantly more than any other. In this imaging regime, each camera pixel time-stamps the photons it detects using an internal clock that follows the arrow of time, obviating the need for any external timing signals.\nOur work is based on the observation that passive (syncfree) imaging is fundamentally more powerful than active imaging in such settings. Specifically, without the periodic timing signal from a light source, time never wraps at a sync period; ultrafast scenes can be imaged for arbitrarily long timespans; and flux variations that occur concurrently across 12 orders of magnitude in time (picoseconds to seconds)-and that involve many unknown sources-can be recorded with just one camera.", "publication_ref": ["b0", "b1", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b9", "b10", "b11", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Because photon timestamps due to all light sources and all", "text": "This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version; the final published version of the proceedings is available on IEEE Xplore. In a real, captured experiment, an unsynchronized single-photon avalanche diode (SPAD) passively records indirect light coming from multiple sources operating asynchronously from each other (unsynchronized picosecond lasers, projectors, etc.). See Figure 5 (row 2, middle) for actual scene. The incident flux exhibits simultaneous intensity variations with a bandwidth that spans roughly 9 orders of magnitude in frequency. Bottom right: Multiple concurrently-occurring phenomena in the flux function can be identified after acquisition: video flicker (58 Hz), the pulsewidth modulation of an LED light bulb (900 Hz), a movie projected onto a nearby wall by a raster-scanning laser projector (up to 5 MHz), and two unsynchronized picosecond lasers (40 MHz-10 GHz). Top right: By reconstructing the time-varying flux function of the laser projector, video frames are reconstructed at 1280x720 resolution using roughly 450-4500 photons collected during each 1/58 s frame.\ntimescales are recorded concurrently, the choice of which timescale to show and which light source(s) to use for visual processing can be done after acquisition (Figure 1). Thus, just like light field cameras [14] enable post-capture refocusing in space, this new imaging regime enables postcapture refocusing in time-from transient to everyday timescales. We demonstrate this one-of-a-kind capability experimentally in Figure 5, where we use photon timestamp data captured by a free-running SPAD camera to play back video of a rapidly-spinning fan at both 1,000 and 250 billion frames per second. We call this novel regime passive ultra-wideband imaging.\nThe key challenge in this regime is how to reconstruct flux functions with a ultra-wide spectrum (DC to over 10 GHz) from a stream of photon timestamps that increase monotonically. To tackle it, we develop a flux probing theory that draws on results from stochastic calculus [15,16] to relate the Fourier series decomposition of a time-varying flux function to the timestamp realizations of an underlying stochastic process [17,18]. The mathematical underpinnings of our approach are grounded in statistics [19][20][21] and time series analysis [22][23][24][25][26][27], and similar methods have explored flux function estimation in optical communications [28][29][30].\nOur work ties together several lines of prior research on \"extreme\" imaging, both passive and active. In passive settings, several techniques have recently been proposed for estimating flux from photon data [13,[31][32][33]. These rely on a variety of flux constancy assumptions and, as a result, are not applicable to the ultra-wideband regime we consider. In ac-tive settings, single-photon imaging techniques have relied exclusively on sync-relative timestamps [34][35][36][37][38], where information about sub-MHz flux variations has already been lost. Aside from single-photon imaging, active ultrafast imaging techniques have also used heterodyning to measure flux at one specific modulation frequency [39][40][41][42][43]. These techniques have neither the light efficiency nor the ultrawide bandwidth we demonstrate in this paper.", "publication_ref": ["b14", "b15", "b16", "b17", "b18", "b19", "b20", "b21", "b22", "b23", "b24", "b25", "b26", "b27", "b28", "b29", "b30", "b13", "b31", "b32", "b34", "b35", "b36", "b37", "b38", "b39", "b40", "b41", "b42", "b43", "b44"], "figure_ref": ["fig_7", "fig_0", "fig_7"], "table_ref": []}, {"heading": "Passive Ultra-Wideband Imaging", "text": "Passive, sync-less imaging. We assume that the imaging system exerts no control over a scene's appearance: the scene's light source(s) can be natural, artificial, or both, and their number, operating principle, and time-varying properties are unknown and unconstrained (Figure 1). Importantly, we assume that no electronic timing signals, such as triggers or sync pulses, are received from any of them.\nThe time-varying flux function. Following standard radiometric conventions [44], we express incident light at a pixel as an unknown time-varying function \u03d5(t) that represents the pixel's instantaneous flux at time t \u2265 0. Our goal is to acquire a continuous representation of the flux function over a possibly unbounded acquisition interval [0,t] (milliseconds, seconds or much longer). In the following we assume that \u03d5(t) is expressed in units of photons per second, is continuous, and has finite spectral support bounded by frequencies f min and f max .\nUltra-wideband flux. We seek to reconstruct flux functions that have ultra-wide bandwidth, i.e., whose fre-quency content spans the entire range from constant flux ( f min = 0 Hz) to extreme time-of-flight timescales ( f max \u2265 10 GHz) [43,45]. Moreover, we assume that no prior information is available about the spectrum of \u03d5(t).\nPhoton arrival model. Our work applies to the singlephoton imaging regime, where the timespan between consecutive photon arrivals is not negligible. In this setting, \u03d5(t) is the rate function of an inhomogeneous Poisson process governing photon arrivals [29,46]. The mean value of \u03d5(t) represents the average flux received over the observation interval [0,t] in units of photons per second and its inverse, denoted by T avg , is the average timespan between consecutive photon arrivals [33].\nLow-flux photon detection model. Modern SPADs can detect and time-stamp the arrival of individual photons with extremely high temporal precision (typically tens of picoseconds [3,47]). SPADs are not perfect detectors, however, as they exhibit four main non-idealities: quantum efficiency, dead time, timestamp quantization and jitter. Quantum efficiency refers to the pixel's probability of actually detecting a photon when it is in its active state. This probability can be well below 1 depending on wavelength; since it can be thought of as scaling the flux function, we assume it is absorbed in \u03d5(t). After a photon detection, SPADs are blind to subsequent photon arrivals for an interval known as the dead time. Dead time can skew photon detection statistics quite significantly when photons arrive closely enough in time to fall within a SPAD's dead-time window with high probability [32,48,49]. For simplicity, we focus on lowflux imaging in the main paper, where consecutive arrivals are spaced much farther apart than the SPAD's dead time. 1 In this case, detections are governed by the same stochastic process that describes photon arrivals [50], with rate function \u03d5(t) and average timespan T avg between detections.\nNon-negligible dead time. When dead-time intervals become comparable to T avg (or longer), photon detections are not Poisson because the detection of a photon may impact the detection of subsequent ones. We show in supplementary Section C that our stochastic calculus framework covers this case as well, enabling acquisition of \u03d5(t) by slightly amending the equations and algorithm in the main paper. Timestamp model. Photon timestamps are subject to quantization from the time-to-digital conversion process and jitter, i.e., instabilities in timing electronics. Both can be as low as a few picoseconds for SPADs in the visible range [51]. To simplify our analysis, we assume without loss of generality that timestamp resolution and timestamp accuracy are identical, so that the timestamps' bin size Q accounts for jitter as well. 2 The stream of absolute detection timestamps. Since no external timing signal is available to serve as a reference, we assume that photon detection timestamps follow the arrow of time, increasing monotonically according to the SPAD's internal clock. This results in a stream of timestamps T = (\u03c4 1 , . . . , \u03c4 N(t) ), where \u03c4 i is the elapsed time from the beginning of acquisition until the i-th photon detection, and N(t) counts the total photons detected up to time t. We refer to timestamps \u03c4 i as absolute timestamps. Absolute timestamps can be acquired by operating SPAD pixels in their \"passive free-running\" mode [32].\nPaper roadmap. The remainder of the main paper is aimed at readers with no background in stochastic calculus, as implementation of our flux acquisition algorithms is straightforward and can be done without it. Readers may skip the formal definition of a martingale (supplement Section A) and focus on the comparisons in Section 2.1, the high-level description of our theoretical results in Section 3, and the algorithms in Section 4 (for low-flux settings) and Section C.1 (for non-negligible dead time). For readers familiar with statistical estimation, Section D includes simpler proofs of Section 3's results, graciously provided by anonymous reviewer R1, which do not invoke stochastic calculus but apply only to low-flux settings where dead time is negligible.", "publication_ref": ["b45", "b44", "b46", "b29", "b47", "b34", "b2", "b48", "b32", "b49", "b50", "b0", "b51", "b52", "b1", "b32"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Imaging with Photon Timestamps", "text": "The particular imaging regime outlined above generalizes two broad classes of single-photon imaging research, both of which use photon timestamps as their main input. We distinguish between the two by considering the relation between (a) the rate of photon detections and (b) the maximum reconstructible frequency in each case (Table 1).\nPassive inter-photon imaging. Recent work in passive single-photon imaging has proposed treating the timespan between consecutive detections as a noisy sample of the scene's flux [32,33]. This implicitly assumes that flux does not vary in that timespan, which makes the rate of photon detections a (loose) upper bound on f max . As a result, passive low-flux imaging with SPADs has so far been restricted to slow speeds, with f max on the order of tens of kHz [13].", "publication_ref": ["b32", "b34", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Active histogram-based imaging.", "text": "Approaches that employ synchronized light sources [50,56] occupy the other extreme of the frequency range. Their basic principle is to time-stamp detections relative to a sync signal of a known frequency f sync , so that all timestamps wrap to the same brief interval [0, 1/ f sync ] regardless of the actual timespan between them. This forces photons to accumulate in a relatively small number of time bins-typically a few timestamps' effective number of bits is reduced [52]. Our system's timestamps, for example, are quantized to 4 picoseconds but the standard deviation of jitter is 16 picoseconds, so we conservatively use Q = 16 for performance modeling purposes. Explicit treatment of jitter is beyond this paper's scope (e.g., jitter can actually improve timing resolution [53][54][55]).\nimaging regime passive inter-photon imaging active histogram-based imaging passive ultra-wideband imaging (interdetection-limited) (sync-and quantization-limited) (quantization-limited only)\nf max < 1/T avg f min \u2265 f sync , f max \u2264 1/(2Q) f max \u2264 1/(2Q)\nlight source(s) one or more sources, no sync one source only, periodic with period 1/ f sync , sync required one or more sources, no sync typical freq. range low Hz to tens of kHz (plus DC) low MHz to well above 10 GHz (plus DC) DC to well above 10 GHz valid frequencies all frequencies in range all frequencies in \u03d5(t) must be integer multiples of f sync all frequencies in range corrupting flux any flux with frequencies > 1/T avg any flux with frequencies that are not integer multiples of f sync frequencies > 31 GHz input data stream of absolute timestamps stream of sync-relative timestamps stream of absolute timestamps # distinct time bins not applicable thousands (typical) billions to trillions (increases with t) # photons per bin not applicable a non-negative integer; Poisson-distributed, mean proportional to \u230at f sync \u230b 0 or 1, vast majority of bins have 0   1: Low-flux imaging with photon timestamps. Left column: Passive imaging has so far assumed that photons can be detected at a rate (much) greater than the highest flux frequency. Middle column: Active techniques are designed to handle the opposite case, where photon detections occur at a rate (much) lower than the flux function's frequencies. If a light source's frequency is not a multiple of f sync (e.g., 5 Hz for \u03d5 2 photons and 7 Hz for \u03d5 3 photons in third row above), its photons will land in the wrong time bin. This contributes to noise instead of signal, i.e., the histogram will be \"flattened\"' (compare the two red and two green histograms, respectively, in third row). Moreover, even when f sync is well-matched to one light source, other sources emitting at non-multiples of f sync will corrupt the histogram (third row, gray histograms). Please refer to the supplementary video for another illustration of these effects. Right column: Our approach inherits the most important features of both regimes, without their limitations.\n\u03d5 1 (t) = 5 + 5 sin(2\u03c0t) \u03d5 2 (t) = 5 + 5 sin(7 \u00d7 6 \u00d7 2\u03c0t) \u03d5 3 (t) = 5 + 5 sin(5 \u00d7 8 \u00d7 2\u03c0t) \u03d5 4 (t) = \u03d5 1 (t) + \u03d5 2 (t) + \u03d5 3 (t)\nthousand-and yields a photon-count histogram [57] that is a noisy sampling of the scaled and time-wrapped flux function, \u230at f sync \u230b\u03d5(t \u2212 \u230at f sync \u230b/ f sync ).\nThe maximum reconstructible frequency in this case is governed by the Nyquist theorem, not the photon interdetection time: a bin size of 16 picoseconds, for example, theoretically enables flux acquisition with f max equal to 31.25 GHz. 3 Although this general approach achieves extremely high imaging speeds [12], its reliance on relative timestamps comes with a major constraint: the incident flux must also be a periodic function with a period equal to 1/ f sync , to ensure that \u03d5(t) and its time-wrapped counterpart are identical. This can be trivially satisfied when the only light in the scene comes from a precisely-synchronized source (a pulsed laser, light-emitting diode, etc.), but flux variations due to other causes cannot be reconstructed. This includes variations caused by scene motion; light sources that emit at frequencies lower than f sync ; and sources that emit at higher frequencies that are not integer multiples of f sync . Photons from such sources result in histogram artifacts in the form 3 As a reference, 31.25 GHz is the \u22123 dB cut-off frequency of a Gaussian pulse with a full-width-at-half-max of 36 picoseconds. of additional photon noise [58], beat signals [45], or both.\nRole of the sync frequency f sync . Sync frequencies are typically in the low-MHz range in single-photon imaging applications that involve pulsed sources [35,50,59,60]. This choice balances improved signal-to-noise ratio (a faster sync means more laser pulses, more photons detected in each histogram bin, and fewer time bins for them to accumulate in) against the likelihood of photons being missed due to dead time [48,49,58], or photons arriving \"too late\" because time has wrapped already [12,61]. At such MHz sync frequencies, the memory and compute cost of reconstructing histograms from timestamps can be significant, prompting several recent schemes for just-in-time processing of (sync-relative) photon timestamps [37,38,62].\nThe passive ultra-wideband imaging regime. Intuitively, the regime we tackle in this paper can be understood as the limit case of photon histogramming, where the sync frequency is reduced all the way to zero. Specifically, as f sync decreases, the interval [0, 1/ f sync ] increases; more histogram bins are needed to span it; fewer photons land into each bin; the time-wrapped flux function is able to represent variations that take place over longer timespans; and the space of reconstructible frequencies (i.e., the integer mul- tiples of f sync ) expands. In the limit when f sync is exactly zero, there is no sync at all, timestamps become absolute and every photon lands into its own unique time bin. Crucially, all frequencies from DC up to the Nyquist limit-and from any light source-become potentially reconstructible.\nMathematical modeling of this limit case, however, is nontrivial because the concept of a histogram breaks down: photons never accumulate, and the contents-0 or 1-of any given bin provide almost no information about the flux function. 4 On the computational side, the entire acquisition interval [0,t] is effectively partitioned into time bins at the SPAD's timing resolution, so acquisitions of a second or more can potentially involve trillions of time bins (most of which are empty). Fortunately, as we show in the next section, both these challenges can be overcome by formulating flux reconstruction in terms of the photon counting process, which is not degenerate even when f sync = 0.", "publication_ref": ["b51", "b57", "b53", "b54", "b55", "b56", "b58", "b2", "b11", "b2", "b59", "b46", "b36", "b51", "b60", "b61", "b49", "b50", "b59", "b11", "b62", "b38", "b39", "b63", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Probing Flux Functions", "text": "Our approach establishes a direct mathematical link between (1) the stream of absolute timestamps detected at a pixel-however few or far apart they may be-and (2) the flux function that produced them. This link allows us to \"probe\" the Fourier spectrum of an unknown flux function across the entire DC-to-GHz range for frequencies that have statistically-significant support in the timestamp data. We introduce our flux probing theory below and address flux reconstruction in Section 4. For the sake of generality, we consider timestamps to be continuous-valued random variables and model quantization as part of our theory.\nThe photon counting process. Even though a single absolute timestamp provides (almost) no information about the underlying flux function, the stream of absolute timestamps as a whole contains considerable information about it. The specific relation between the two comes from stochastic calculus [15]. Specifically, in the continuous-time domain, a stream T of real-valued absolute timestamps provides a noisy \"reconstruction\" of the integral of \u03d5(t) (Figure 2):\nN(t) counting process = t 0 \u03d5(u)du flux integral up to time t + M(t) martingale noise . (1)\nThe function N(t) in Eq. (1) counts the photons received up to time t and is completely determined by T ; formally, it is a counting process [15,19]. Viewed from the perspective of histogram-based single-photon imaging (Table 1, middle), N(t) is the continuous-time analog of the cumulative photon-count histogram over the interval [0,t], for f sync = 0. The function M(t) in Eq. ( 1) is a continuous-time random process called a martingale [64] that can be thought of as a form of additive zero-mean noise. 5 As can be seen from the example of Figure 2, a single random realization of the counting process (cyan curve) is a highly discontinuous function that, on first inspection, bears no resemblance to the flux integral it is supposed to approximate in Eq. (1). These discontinuities introduce dense, spurious frequencies in the Fourier-domain representation of N(t) that do not exist in the actual flux integral.", "publication_ref": ["b15", "b15", "b19", "b65", "b4"], "figure_ref": ["fig_2", "fig_2"], "table_ref": []}, {"heading": "Theory of Flux Probing", "text": "Our theoretical results use tools from stochastic calculus to address two basic questions. First, what is the highest possible frequency f max that can be recovered by a passive single-photon imaging system that outputs quantized absolute timestamps? Second, for frequencies within the attainable bandwidth, how can we derive a noise model that allows spurious frequencies to be efficiently detected and discarded, and the accuracy of real frequencies to be quantified as a function of the acquired timestamp stream? We summarize these results below and defer proofs to Section B.\nThe probing operation. Proposition 1 tells us that we can always probe the flux function to recover a (noisy) measurement of its inner product with practically any other function. Moreover, probing is efficient to compute from the timestamp stream and can be thought of as a continuous-time and sync-free generalization of compressive acquisition schemes for conventional photon-counting histograms [37,38,62]. In particular, let T be the stream of real-valued absolute timestamps up to time t and let p(t) be an arbitrary known and square-integrable function:\nProposition 1 (Flux Probing Equation). The inner product of the probing function p(t) and the unknown flux function \u03d5(t) over the time interval [0,t] satisfies the relation\np(T ) = p, \u03d5 + M p (t)(2)\nwhere p(T ) are \"probing measurements\" which sum the values of the probing function at the absolute timestamps\np(T ) def = \u2211 \u03c4\u2208T p(\u03c4) ,(3)\nM p (t) is a martingale, and the inner product is defined as t 0 p(u)\u03d5(u) du.\nFundamental limit on bandwidth. In the special case of probing with the Fourier basis functions p f (t) = e \u2212 j2\u03c0 f t , we prove in supplement Section B that probing with f > 1/2Q yields aliased measurements that \"wrap around\" the frequency spectrum and are identical to-and indistinguishable from-lower-frequency measurements:\nProposition 2. Given timing resolution Q, the maximum recoverable frequency is f max = 1 2Q . Intuitively, Proposition 2 says that flux frequencies above 1/2Q are unrecoverable regardless of whether we detect a few photons or a million.\nNoise model. Our model accounts for the inhomogeneous Poisson nature of photon detections and treats the general case of real-valued timestamps. The model is valid for arbitrary flux levels within the low-flux regime and, as we show in supplement Section G.4, it remains valid for low-count acquisitions (e.g., as few as ten photons). More specifically, Proposition 3 tells us that the noise in probing measurements has a distribution that can be estimated from the timestamp stream through another probing operation. Thus, probing gives the means both to observe a flux function and to quantify the uncertainty of that observation:", "publication_ref": ["b38", "b39", "b63"], "figure_ref": [], "table_ref": []}, {"heading": "Proposition 3 (Distribution of Probing Measurements).", "text": "The probing measurements p(T ) are approximately normally distributed with mean p, \u03d5 and variance p 2 , \u03d5 .\nFourier probing noise. Finally, Corollaries 1 and 2 allow us to quantify the accuracy by which specific flux frequencies can be estimated from a given timestamp stream:\nCorollary 1 (Distribution of Fourier Probing). The Fourier probing measurements p f (T ) approximately follow a complex normal distribution with mean and covariance matrix\n\u00b5 = cos(2\u03c0 f t), \u03d5(t) \u2212 sin(2\u03c0 f t), \u03d5(t)(4)\n\u03a3 = cos 2 (2\u03c0 f t), \u03d5(t) 0 0 sin 2 (2\u03c0 f t), \u03d5(t) . (5\n)\nCorollary 2 (Distribution of Fourier Probing Energy). The normalized energy of the Fourier basis probing measurements\np E f (T ) def = Re p f (T ) \u03a3 1,1 2 + Im p f (T ) \u03a3 2,2 2 (6)\nfollows a non-central \u03c7 2 distribution with 2 degrees of freedom and non-centrality parameter \u00b5 2 1 /\u03a3 1,1 + \u00b5 2 2 /\u03a3 2,2 . In supplement Section B we show that unbiased estimators of the parameters of the above distributions can be obtained via probing.\nFrequency detection. Given the estimated distribution of the Fourier Probing Energy, we derive the constant false alarm rate (CFAR) detector [65] (see supplement Section B) to identify and remove noisy frequencies based on a desired probability of false alarm \u03b1. False alarms occur when we keep f and\nE[|p f (T )|] = 0; we remove f if p E f (T ) is lower than CDF \u22121 \u03c7 2 (1 \u2212 \u03b1)\n, derived from Corollary 2. Specifically, we detect frequencies for which\n|p f (T )| 2 \u2265 CDF \u22121 \u03c7 2 (1 \u2212 \u03b1) N(t) 2t 2 . (7\n)\nNote that (1) for a fixed \u03b1, the probability of detecting a frequency is proportional to the total number of photons detected, and (2) for flux functions dominated by a particular frequency such that |p f i (T )| 2 is large, N(t) also tends to become proportionally larger, reducing the probability of detecting other frequencies.\nImplications for passive single-photon imaging. Proposition 2 implies that rather than being a hindrance, syncless imaging with absolute timestamps confers an extreme bandwidth advantage to SPAD cameras: systems with 16picosecond resolution, such as our own, can simultaneously acquire flux variations that span the entire DC-to-31 GHz range of frequencies, and that are due to any number of unknown light sources operating independently. This bandwidth is orders of magnitude broader than intensity cameras-SPADs or otherwise-were thought capable of acquiring directly [41][42][43]45], i.e., without resorting to homodyne [43] or heterodyne [41,42,45] detection schemes. While Proposition 2 describes reconstructability (i.e., frequencies above the limit are unreconstructible), Proposition 3 and Eq. ( 7) provide insights about the accuracy and detectability of flux variations at different frequencies.\nLastly, although we have not verified the theorized DCto-31 GHz bandwidth experimentally due to unavailability of lasers that are fast enough, we show several real-world demonstrations of simultaneous DC-to-16.9 GHz imaging under very challenging low-flux conditions (see Figure 1, Section 5, and Section E). These validate our noise models in Eqs. ( 4)-( 6) and (partially) confirm our theoretical bound.\nprocedure FLUXREC(T , t, f max , \u03b1) // Frequency scanning. \u2206 f = 0.6/t (see supp. Section B) F = freqs from 0 to f max with step \u2206 f loop f \u2208 F p f (T ) = (1/t) \u2211 \u03c4\u2208T e \u2212 j2\u03c0 f \u03c4 // Frequency detection.\nF used = / 0 loop f \u2208 F A f = |p f (T )|, \u03c6 f = \u2220p f (T )\nreject f using CFAR (Eq.( 7))  Frequency detection: For each of the probed frequencies, we detect whether it contributes to the flux function if its corresponding amplitude is greater than a threshold (top) which is selected to achieve the desired probability of false alarm. (bottom). Flux reconstruction: Finally, we reconstruct a continuous-time flux function from the amplitudes and phases of detected frequencies.\nF used = F used \u222a { f } if not rejected // Flux reconstruction. \u03d5(t) = \u2211 f \u2208F used A f cos(2\u03c0 f t + \u03c6 f )\n\u03d5(t) = \u2211 f \u2208F A f cos(2\u03c0 f t + \u03c6 f ) p f (T ) = (1/t) \u2211\u03c4\u2208T e \u2212 j2\u03c0 f \u03c4\u03c6 (t) = \u2211 f \u2208F used A f cos(2\u03c0 f t + \u03c6 f )", "publication_ref": ["b66", "b42", "b43", "b44", "b46", "b44", "b42", "b43", "b46"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Imaging by Flux Probing", "text": "Our probing theory leads directly to an algorithm that reconstructs the Fourier transform of the flux function by frequency-scanning the entire DC-to-GHz bandwidth (Figure 3). This algorithm is similar to the Fourier-domain histogramming technique used in conventional active settings [62], but also differs in two key respects: (1) it provides a principled way to estimate frequency uncertainty in an acquired timestamp stream, and (2) it enables tractable operation in a regime involving potentially billions of candidate frequencies-e.g., a 1 Hz-resolution scan of DC-to-20 GHz-by rejecting spurious frequencies and reducing storage requirements. The frequency detection step uses the CFAR detector of Section 3, where we set \u03b1 so that the expected number of false alarms is less than 1. Figure 3 includes a visual depiction of the flux reconstruction algorithm, along with a complete description in pseudocode.", "publication_ref": ["b63"], "figure_ref": ["fig_4", "fig_4"], "table_ref": []}, {"heading": "Experiments", "text": "We validate our theory experimentally with (1) passive ultra-wideband sensing of both 1D intensity signals and 2D video signals ranging from DC to 16.9 GHz, (2) passive non-line-of-sight (NLOS) video via MHz-rate flux function reconstruction, (3) generalization to 2D SPAD arrays for high speed video, and (4) simulation-based quantitative evaluation of flux probing. We refer readers to the supplemental video and to supplement Sections E, F, and G for more experiments and implementation details.\nPassive ultra-wideband sensing. We demonstrate recovering signals with frequencies spanning roughly 9 orders of magnitude from DC to 10 GHz (Figure 1). We place a single-pixel SPAD in the scene to capture flux variations from (1) pulse-width modulation of a light bulb (900 Hz),\n(2) backscattered light from a raster-scanning laser projector (60 Hz-10 MHz), and (3) two unsynchronized picosecond lasers (40 MHz-10 GHz). Remarkably, the flux function is reconstructed from only 77,000 photon timestamps. 6 We recover time-varying flux across billions of frequencies from this minuscule set of photons. Moreover, by employing a brighter and faster laser, we achieve passive DC-to-16.9 GHz sensing over room-size distances (Section E.2.2).\nWe also demonstrate ultra-wideband video (Figure 5, top) by raster scanning a scene in which a pulsed laser, with 20 MHz repetition and 80 ps FWHM, is diffused to illuminate a fan spinning at 54 Hz. We detect frequencies from DC to 10 GHz and render flux functions at 1 kfps and 250 Gfps, showing both the fan blades rotating and the propagation of the laser pulse. In contrast, conventional approaches reconstruct the scene at only one of the aforementioned frame rates, temporally blurring either slow or fast events. Furthermore, our method can render the flux at whatever timescale, essentially freezing time at all timescales. Note that because we only had access to a single pixel SPAD, the timestamps were collected by scanning across the field of view of the SPAD. To temporally align the flux functions between pixels, we use synchronization signals from both the laser and the fan. We emphasize that no synchronization signals were used to reconstruct the flux functions themselves-we are demonstrating a new capability of reconstructing the appearance of the scene as it appeared during each laser pulse-this is distinct from the use of synchronization and histogramming to estimate the average appearance of the flux function over time [7,12,66]. We also emphasize that the images are rendered by integrating the flux function over the exposure of each frame. As such, these images exhibit not only high dynamic range but their intensities are also expressed in physical units of photons, thereby ensuring radiometric calibration by nature. We show another video example in Figure 5 (row 2), where the same picosecond laser illuminates a Coca-Cola bottle filled with water and a small amount of milk to scatter the light. Within the same scene, a compact fluorescent lightbulb (CFL) flickers at 120 Hz. We render videos at 10 kfps and 200 Gfps to visualize the CFL flicker and light pulses propagating through the bottle (Figure 5, rows 3-4). For the same reasons outlined in the previous paragraph, we use synchronization signals from the laser and the bulb.\nRecovering passive NLOS videos. We demonstrate passive NLOS video reconstruction using light measured indirectly from a raster-scanning laser projector (see illustration in Figure 1 and photo in Figure 5, row 2). The SPAD observes a single point on a diffuse box during the projector beam's raster scan, collecting light that bounced twice (i.e., diffuser\u2192diffuse box\u2192SPAD). This configuration is analogous to dual photography [67]. By reconstructing the 1D flux function over a one-second span, we recover the video being played. We show results for the multi-illumination setting of Figure 1 and for a projector-only setting. In the latter case, we recover fine details of each video frame (Figure 5, rows 5-6) even though only 3000 photons were collected on average during a frame's 1/58 s raster scan.\nProbing with SPAD arrays. Our method can be applied off the shelf to data from 2D SPAD sensors. To demonstrate this, we compare to Seets et al. [13] who recover highspeed video with a 32\u00d732 SPAD array. They assume flux is piecewise constant and identify contiguous sets of timestamps with the same flux. Photon inter-arrivals are then averaged to obtain a single flux estimate per set (Figure 5, bottom right). In contrast, we recover a time-varying flux function by probing (Figure 5, bottom left). Because the sensor outputs just one timestamp per 20 microseconds for each pixel-a dead time too long to ignore even at relatively low flux levels-we probe using the generalized algorithm of Section C.1. This yields a periodic flux function truer to the rotating fan's motion, whereas periodicity and highfrequency variations are lost by the method in [13].", "publication_ref": ["b5", "b6", "b11", "b67", "b68", "b13", "b13"], "figure_ref": ["fig_0", "fig_7", "fig_7", "fig_7", "fig_0", "fig_7", "fig_0", "fig_7", "fig_7", "fig_7"], "table_ref": []}, {"heading": "Simulations.", "text": "Lastly, we consider reconstruction of a flux function corresponding to 20 MHz pulse trains from an ultrafast laser with frequency support of 12.5 GHz and 125 GHz, respectively, i.e., up to the theoretically-attainable limit of a jitter-less SPAD with 4 ps timestamp quantization (Proposition 2). Figure 4 compares the result of three methods: (1) conventional photon-count histogramming which requires synchronization, (2) our sync-less reconstruction algorithm in Figure 3, and (3) \"oracle-based\" flux probing, which probes the ground-truth set of frequencies instead of relying on frequency scanning. As can be seen, probing can recover pulses up to the theoretical limit from just 50 timestamps and, despite being passive, outperforms histogramming considerably as photon counts increase. Please see Section G for a more detailed quantitative evaluation.", "publication_ref": [], "figure_ref": ["fig_5", "fig_4"], "table_ref": []}, {"heading": "Concluding Remarks", "text": "The sheer amount of data involved in probing timestamp streams cannot be ignored: even a single pixel can output tens of thousands of timestamps per second in low light, and our ultrawide-bandwidth results require probing billions of frequencies. Sketching [38] and Non-Uniform FFT [68] may offer ways forward but major challenges remain. That said, we believe that passive acquisition and processing of timestamp streams from free-running SPADs opens new directions in dynamic imaging: completely unsynchronized, single-shot observations of ultrafast phenomena with multiple light sources across different timescales; passive depth imaging using uncooperative, environmental light sources; compressive ultrafast video recording from sparse timestamps; temporal \"microscopes\" that allow monitoring intensity fluctuations across timescales spanning the nine-plus orders of magnitude (i.e., DC to 31 GHz) theoretically captured by SPADs; and more. We are thus looking forward to more advances on these remarkable sensors.  Rows 5-6: Passive NLOS acquisition using a raster-scanning laser projector with ground truth and reconstructed frames. Rows 7-8: We use SPAD array data from Seets et al. [13] to reconstruct per-pixel flux (left). The common assumption of piecewise constant flux (right) does not hold even for this simple scene of a rotating fan.", "publication_ref": ["b39", "b69", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "", "text": "Acknowledgements We thank the anonymous reviewers, and R1 in particular, for their invaluable comments and suggestions. We also thank Louis Zhang for creating an interactive tool for visualizing and sampling flux integrals efficiently using OpenCL, and John Hancock for configuring the servers used in our experiments. Lastly, KNK and DBL gratefully acknowledge the support of NSERC under the RGPIN and RTI programs.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Femtosecond Laser Pulses", "journal": "Springer", "year": "2005", "authors": "C Rulli\u00e8re"}, {"ref_id": "b1", "title": "Direct linear measurement of ultrashort light pulses with a picosecond streak camera", "journal": "Opt. Commun", "year": "1971", "authors": "D J Bradley; B Liddy; W E Sleat"}, {"ref_id": "b2", "title": "Principles and features of single-photon avalanche diode arrays", "journal": "Sens. Actuators A: Phys", "year": "2007", "authors": "F Zappa; S Tisa; A Tosi; S Cova"}, {"ref_id": "b3", "title": "Single-shot compressed ultrafast photography at one hundred billion frames per second", "journal": "Nature", "year": "2014", "authors": "L Gao; J Liang; C Li; L V Wang"}, {"ref_id": "b4", "title": "Design and characterization of a CMOS 3-D image sensor based on single photon avalanche diodes", "journal": "IEEE J. Solid-State Circuits", "year": "2005", "authors": "C Niclass; A Rochas; P.-A Besse; E Charbon"}, {"ref_id": "b5", "title": "New electrooptical mixing and correlating sensor: Facilities and applications of the photonic mixer device (PMD)", "journal": "", "year": "1997", "authors": "R Schwarte; Z Xu; H.-G Heinol; J Olk; R Klein; B Buxbaum; H Fischer; J Schulte"}, {"ref_id": "b6", "title": "Single-photon sensitive light-in-fight imaging", "journal": "Nat. Commun", "year": "2015", "authors": "G Gariepy; N Krstaji\u0107; R Henderson; C Li; R R Thomson; G S Buller; B Heshmat; R Raskar; J Leach; D Faccio"}, {"ref_id": "b7", "title": "Fluorescence lifetime imagingtechniques and applications", "journal": "J. Microsc", "year": "2012", "authors": "W Becker"}, {"ref_id": "b8", "title": "The quanta image sensor: Every photon counts", "journal": "Sensors", "year": "2016", "authors": "E R Fossum; J Ma; S Masoodian; L Anzagira; R Zizza"}, {"ref_id": "b9", "title": "Megapixel time-gated SPAD image sensor for 2D and 3D imaging applications", "journal": "Optica", "year": "2020", "authors": "K Morimoto; A Ardelean; M.-L Wu; A C Ulku; I M Antolovic; C Bruschini; E Charbon"}, {"ref_id": "b10", "title": "Dynamic low-light imaging with quanta image sensors", "journal": "Springer", "year": "2020", "authors": "Y Chi; A Gnanasambandam; V Koltun; S H Chan"}, {"ref_id": "b11", "title": "Reconstructing transient images from single-photon sensors", "journal": "", "year": "", "authors": "M O'toole; F Heide; D B Lindell; K Zang; S Diamond; G Wetzstein"}, {"ref_id": "b12", "title": "on Computer Vision and Pattern Recognition (CVPR)", "journal": "", "year": "2017", "authors": " Ieee/Cvf;  Conf"}, {"ref_id": "b13", "title": "Motion adaptive deblurring with single-photon cameras", "journal": "", "year": "2021", "authors": "T Seets; A Ingle; M Laurenzis; A Velten"}, {"ref_id": "b14", "title": "Light field photography with a hand-held plenoptic camera", "journal": "", "year": "2005", "authors": "R Ng; M Levoy; M Br\u00e9dif; G Duval; M Horowitz; P Hanrahan"}, {"ref_id": "b15", "title": "Stochastic Processes", "journal": "Wiley", "year": "1953", "authors": "J L Doob"}, {"ref_id": "b16", "title": "Stochastic Calculus and Applications", "journal": "Birkh\u00e4user", "year": "2015", "authors": "S N Cohen; R J Elliott"}, {"ref_id": "b17", "title": "Superresolution estimation of cyclic arrival rates", "journal": "Ann. Stat", "year": "2019", "authors": "N Chen; D K K Lee; S N Negahban"}, {"ref_id": "b18", "title": "Estimation for almost periodic processes", "journal": "Ann. Stat", "year": "2006", "authors": "K.-S Lii; M Rosenblatt"}, {"ref_id": "b19", "title": "The spectral analysis of point processes", "journal": "B: Stat. Methodol", "year": "1963", "authors": "M S Bartlett"}, {"ref_id": "b20", "title": "On the estimation of frequency in point-process data", "journal": "J. Appl. Probab", "year": "1982", "authors": "D Vere-Jones"}, {"ref_id": "b21", "title": "Cox point process regression", "journal": "IEEE Trans. Inf. Theory", "year": "2022", "authors": "\u00c1 Gajardo; H.-G M\u00fcller"}, {"ref_id": "b22", "title": "Periodogram analysis and continuous spectra", "journal": "Biometrika", "year": "1950", "authors": "M S Bartlett"}, {"ref_id": "b23", "title": "On a method of investigating periodicities in disturbed series, with special reference to Wolfer's sunspot numbers", "journal": "Philos. Trans. R. Soc. Lond., A", "year": "1927", "authors": "G U Yule"}, {"ref_id": "b24", "title": "On the analysis of oscillatory timeseries", "journal": "J. R. Stat. Soc", "year": "1945", "authors": "M G Kendall"}, {"ref_id": "b25", "title": "Least-squares frequency analysis of unequally spaced data", "journal": "Astrophys. Space Sci", "year": "1976", "authors": "N R Lomb"}, {"ref_id": "b26", "title": "Fourier techniques for very long astrophysical timeseries analysis", "journal": "Astron. J", "year": "2002", "authors": "S M Ransom; S S Eikenberry; J Middleditch"}, {"ref_id": "b27", "title": "Understanding the Lomb-Scargle periodogram", "journal": "Astrophys. J. Suppl. Ser", "year": "2018", "authors": "J T Vanderplas"}, {"ref_id": "b28", "title": "Estimation and detection of weak optical signals", "journal": "IEEE Trans. Inf. Theory", "year": "1972", "authors": "O Macchi; B Picinbono"}, {"ref_id": "b29", "title": "On optical data communication via direct detection of light pulses", "journal": "Bell Syst. Tech. J", "year": "1976", "authors": "J E Mazo; J Salz"}, {"ref_id": "b30", "title": "Maximum likelihood and minimum mean squared error estimations for measurement of light intensity", "journal": "", "year": "2010", "authors": "A Komaee"}, {"ref_id": "b31", "title": "Quanta burst photography", "journal": "ACM Trans. Graph. (SIGGRAPH)", "year": "2020", "authors": "S Ma; S Gupta; A C Ulku; C Bruschini; E Charbon; M Gupta"}, {"ref_id": "b32", "title": "High flux passive imaging with single-photon sensors", "journal": "", "year": "", "authors": "A Ingle; A Velten; M Gupta"}, {"ref_id": "b33", "title": "on Computer Vision and Pattern Recognition (CVPR)", "journal": "", "year": "2019", "authors": " Ieee/Cvf;  Conf"}, {"ref_id": "b34", "title": "Passive inter-photon imaging", "journal": "", "year": "2021", "authors": "A Ingle; T Seets; M Buttafava; S Gupta; A Tosi; M Gupta; A Velten"}, {"ref_id": "b35", "title": "Towards transient imaging at interactive rates with single-photon detectors", "journal": "", "year": "2018", "authors": "D B Lindell; M O'toole; G Wetzstein"}, {"ref_id": "b36", "title": "Photon-efficient imaging with a single-photon camera", "journal": "Nat. Commun", "year": "2016", "authors": "D Shin; F Xu; D Venkatraman; R Lussana; F Villa; F Zappa; V K Goyal; F N Wong; J H Shapiro"}, {"ref_id": "b37", "title": "Depth and transient imaging with compressive SPAD array cameras", "journal": "", "year": "2018", "authors": "Q Sun; X Dun; Y Peng; W Heidrich"}, {"ref_id": "b38", "title": "Compressive single-photon 3D cameras", "journal": "", "year": "2022", "authors": "F Gutierrez-Barragan; A Ingle; T Seets; M Gupta; A Velten"}, {"ref_id": "b39", "title": "A sketching framework for reduced data transfer in photon counting lidar", "journal": "IEEE Trans. Comput. Imaging", "year": "2021", "authors": "M P Sheehan; J Tachella; M E Davies"}, {"ref_id": "b40", "title": "Low-budget transient imaging using photonic mixer devices", "journal": "ACM Trans. Graph. (SIGGRAPH)", "year": "2013", "authors": "F Heide; M B Hullin; J Gregson; W Heidrich"}, {"ref_id": "b41", "title": "Exploiting wavelength diversity for high resolution time-of-flight 3D imaging", "journal": "IEEE Trans. Pattern Anal. Machine Intell", "year": "2021", "authors": "F Li; F Willomitzer; M M Balaji; P Rangarajan; O Cossairt"}, {"ref_id": "b42", "title": "SH-ToF: Micro resolution timeof-flight imaging with superheterodyne interferometry", "journal": "", "year": "2018", "authors": "F Li; F Willomitzer; P Rangarajan; M Gupta; A Velten; O Cossairt"}, {"ref_id": "b43", "title": "Centimeter-wave free-space neural timeof-flight imaging", "journal": "ACM Trans. Graph. (SIGGRAPH)", "year": "2022", "authors": "S.-H Baek; N Walsh; I Chugunov; Z Shi; F Heide"}, {"ref_id": "b44", "title": "Phasor imaging: A generalization of correlationbased time-of-flight imaging", "journal": "ACM Trans. Graph. (SIGGRAPH)", "year": "2015", "authors": "M Gupta; S K Nayar; M B Hullin; J Martin"}, {"ref_id": "b45", "title": "Radiometry and the Detection of Optical Radiation", "journal": "Wiley", "year": "1983", "authors": "R W Boyd"}, {"ref_id": "b46", "title": "Rethinking machine vision time of flight with GHz heterodyning", "journal": "IEEE Access", "year": "2017", "authors": "A Kadambi; R Raskar"}, {"ref_id": "b47", "title": "Stochastic Processes", "journal": "Wiley", "year": "1983", "authors": "S M Ross"}, {"ref_id": "b48", "title": "Single photon avalanche diodes (SPADs) for 1.5 \u00b5m photon counting applications", "journal": "J. Mod. Opt", "year": "2007", "authors": "M A Itzler; R Ben-Michael; C.-F Hsu; K Slomkowski; A Tosi; S Cova; F Zappa; R Ispasoiu"}, {"ref_id": "b49", "title": "Signal processing based pile-up compensation for gated single-photon avalanche diodes", "journal": "", "year": "2018", "authors": "A K Pediredla; A C Sankaranarayanan; M Buttafava; A Tosi; A Veeraraghavan"}, {"ref_id": "b50", "title": "Dead time compensation for high-flux ranging", "journal": "IEEE Trans. Signal Process", "year": "2019", "authors": "J Rapp; Y Ma; R M A Dawson; V K Goyal"}, {"ref_id": "b51", "title": "Computational Time-resolved Imaging", "journal": "", "year": "2015", "authors": "G A Kirmani"}, {"ref_id": "b52", "title": "Fast-gated 16 \u00d7 16 SPAD array with 16 on-chip 6 ps time-to-digital converters for non-lineof-sight imaging", "journal": "IEEE Sens. J", "year": "2022", "authors": "S Riccardo; E Conca; V Sesta; A Velten; A Tosi"}, {"ref_id": "b53", "title": "Analog Integrated Circuit Design", "journal": "Wiley", "year": "2011", "authors": "T C Carusone; D Johns; K Martin"}, {"ref_id": "b54", "title": "Dithered depth imaging", "journal": "Opt. Express", "year": "2020", "authors": "J Rapp; R M A Dawson; V K Goyal"}, {"ref_id": "b55", "title": "Estimation from quantized Gaussian measurements: When and how to use dither", "journal": "IEEE Trans. Signal Process", "year": "2019", "authors": "J Rapp; R M A Dawson; V K Goyal"}, {"ref_id": "b56", "title": "STORM: Super-resolving transients by oversampled measurements", "journal": "", "year": "2019", "authors": "A Raghuram; A Pediredla; S G Narasimhan; I Gkioulekas; A Veeraraghavan"}, {"ref_id": "b57", "title": "Non-line-of-sight imaging using phasor-field virtual wave optics", "journal": "Nature", "year": "2019", "authors": "X Liu; I Guill\u00e9n; M L Manna; J H Nam; S A Reza; T H Le; A Jarabo; D Gutierrez; A Velten"}, {"ref_id": "b58", "title": "The photon counting histogram in fluorescence fluctuation spectroscopy", "journal": "Biophys. J", "year": "1999", "authors": "Y Chen; J D M\u00fcller; P T C So; E Gratton"}, {"ref_id": "b59", "title": "Asynchronous single-photon 3D imaging", "journal": "", "year": "2019", "authors": "A Gupta; A Ingle; M Gupta"}, {"ref_id": "b60", "title": "Sub-picosecond photon-efficient 3D imaging using single-photon sensors", "journal": "Sci. Rep", "year": "2018", "authors": "F Heide; S Diamond; D B Lindell; G Wetzstein"}, {"ref_id": "b61", "title": "Fluorescence lifetime imaging with a megapixel SPAD camera and neural network lifetime estimation", "journal": "Sci. Rep", "year": "2020", "authors": "V Zickus; M.-L Wu; K Morimoto; V Kapitany; A Fatima; A Turpin; R Insall; J Whitelaw; L Machesky; C Bruschini; D Faccio; E Charbon"}, {"ref_id": "b62", "title": "Single-photon three-dimensional imaging at up to 10 kilometers range", "journal": "Opt. Express", "year": "2017", "authors": "A M Pawlikowska; A Halimi; R A Lamb; G S Buller"}, {"ref_id": "b63", "title": "Phasor field diffraction based reconstruction for fast non-line-of-sight imaging systems", "journal": "Nat. Commun", "year": "2020", "authors": "X Liu; S Bauer; A Velten"}, {"ref_id": "b64", "title": "Random Point Processes in Time and Space", "journal": "Springer", "year": "2012", "authors": "D L Snyder; M I Miller"}, {"ref_id": "b65", "title": "Etude critique de la notion de collectif", "journal": "Bull. Am. Math. Soc", "year": "1939", "authors": "J Ville"}, {"ref_id": "b66", "title": "Statistical Signal Processing: Detection, Estimation, and Time Series Analysis", "journal": "Prentice Hall", "year": "1991", "authors": "L L Scharf; C Demeure"}, {"ref_id": "b67", "title": "Femto-photography: Capturing and visualizing the propagation of light", "journal": "ACM Trans. Graph. (SIGGRAPH)", "year": "2013", "authors": "A Velten; D Wu; A Jarabo; B Masia; C Barsi; C Joshi; E Lawson; M Bawendi; D Gutierrez; R Raskar"}, {"ref_id": "b68", "title": "Dual photography", "journal": "ACM Trans. Graph. (SIGGRAPH)", "year": "2005", "authors": "P Sen; B Chen; G Garg; S R Marschner; M Horowitz; M Levoy; H P A Lensch"}, {"ref_id": "b69", "title": "A parallel nonuniform fast Fourier transform library based on an \"exponential of semicircle\" kernel", "journal": "SIAM J. Sci. Comput", "year": "2019", "authors": "A H Barnett; J Magland; L A Klinteberg"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1photons per sec) 160", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "photon-count histograms 7 Hz 5 Hz corruptions \u03d5 1 ,\u03d5 3 \u03d5 2 photons", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 2 :2photon stream T counting process N(t)", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 3 :3Figure 3: Overview of imaging by flux probing. Left: Flux reconstruction algorithm used in our experiments. Right: Visual illustration of the algorithm. Flux function: A flux function of finite spectral support can be expressed as a sum of sinusoids and produces a stream of absolute timestamps. Frequency scanning: We probe the flux function using a Fourier basis and measure the response at each frequency.Frequency detection: For each of the probed frequencies, we detect whether it contributes to the flux function if its corresponding amplitude is greater than a threshold (top) which is selected to achieve the desired probability of false alarm. (bottom). Flux reconstruction: Finally, we reconstruct a continuous-time flux function from the amplitudes and phases of detected frequencies.", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Figure 4 :4Figure 4: Simulation-based comparisons. Left to right: Laser pulse reconstructed by three methods from 2000 timestamps produced by a 20 MHz pulse train. Reconstruction from a 20 MHz train of much shorter pulses, using just 50 timestamps. Pulse reconstruction error as a function of the number of timestamps given as input. Reconstructed pulses from 100 realizations of a fifty-photon timestamp stream.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "flux rendered at 11kfps AC-powered fluorescent bulb (120 Hz flicker rate) picosecond laser pointing at bottle (20 MHz pulse rate) raster-scanning path of projectors laser beam passive ultra-wideband video acquisition (DC to 10 GHz) reconstructed per-pixel flux (rendered at two timescales) 10,000 fps video 200 billion fps video passive ultrafast single-pixel imaging & NLOS video C B D A bulb too dim at this timescale, pulse propagation visible bulb blinking, light on bottle appears constant reconstructed flux function (4 pixels & 2 timescales shown)", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Figure 5 :5Figure 5: Passive ultra-wideband imaging experiments. Row 1: Simultaneous recovery of spinning fan and light propagation (see text for experiment setup). Rendering the flux function at 1 kfps reveals motion of the fan (yellow arrow), but light propagation is invisible; at 250 Gfps light propagation is visible, and the fan freezes. Conventional histogramming (right) synced to the laser fails to recover the (unsynced) fan rotation. Row 2: Experimental setup for ultra-wideband video acquisition (left) and NLOS video imaging in a scene with multiple light sources (right). Rows 3-4: Flux function images at two timescales (left, bottom right) and for different points in the scene illuminated by a pulsed laser and flickering light bulb (top right). The three peaks at B, C, and D correspond to a light pulse entering the bottle (B) propagating to the cap (C), and reflecting back (D). Rows 5-6: Passive NLOS acquisition using a raster-scanning laser projector with ground truth and reconstructed frames. Rows 7-8: We use SPAD array data from Seets et al. [13] to reconstruct per-pixel flux (left). The common assumption of piecewise constant flux (right) does not hold even for this simple scene of a rotating fan.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "f max < 1/T avg f min \u2265 f sync , f max \u2264 1/(2Q) f max \u2264 1/(2Q)", "formula_coordinates": [4.0, 104.88, 94.55, 385.53, 9.72]}, {"formula_id": "formula_1", "formula_text": "\u03d5 1 (t) = 5 + 5 sin(2\u03c0t) \u03d5 2 (t) = 5 + 5 sin(7 \u00d7 6 \u00d7 2\u03c0t) \u03d5 3 (t) = 5 + 5 sin(5 \u00d7 8 \u00d7 2\u03c0t) \u03d5 4 (t) = \u03d5 1 (t) + \u03d5 2 (t) + \u03d5 3 (t)", "formula_coordinates": [4.0, 103.68, 174.87, 421.5, 8.37]}, {"formula_id": "formula_2", "formula_text": "N(t) counting process = t 0 \u03d5(u)du flux integral up to time t + M(t) martingale noise . (1)", "formula_coordinates": [5.0, 318.36, 172.2, 226.88, 37.13]}, {"formula_id": "formula_3", "formula_text": "p(T ) = p, \u03d5 + M p (t)(2)", "formula_coordinates": [6.0, 117.96, 135.97, 168.56, 11.85]}, {"formula_id": "formula_4", "formula_text": "p(T ) def = \u2211 \u03c4\u2208T p(\u03c4) ,(3)", "formula_coordinates": [6.0, 129.96, 190.48, 156.56, 23.94]}, {"formula_id": "formula_5", "formula_text": "\u00b5 = cos(2\u03c0 f t), \u03d5(t) \u2212 sin(2\u03c0 f t), \u03d5(t)(4)", "formula_coordinates": [6.0, 62.28, 664.98, 224.02, 10.34]}, {"formula_id": "formula_6", "formula_text": "\u03a3 = cos 2 (2\u03c0 f t), \u03d5(t) 0 0 sin 2 (2\u03c0 f t), \u03d5(t) . (5", "formula_coordinates": [6.0, 62.88, 678.75, 219.95, 22.97]}, {"formula_id": "formula_7", "formula_text": ")", "formula_coordinates": [6.0, 282.83, 685.74, 3.48, 9.93]}, {"formula_id": "formula_8", "formula_text": "p E f (T ) def = Re p f (T ) \u03a3 1,1 2 + Im p f (T ) \u03a3 2,2 2 (6)", "formula_coordinates": [6.0, 339.12, 114.64, 206.12, 28.93]}, {"formula_id": "formula_9", "formula_text": "E[|p f (T )|] = 0; we remove f if p E f (T ) is lower than CDF \u22121 \u03c7 2 (1 \u2212 \u03b1)", "formula_coordinates": [6.0, 308.88, 286.69, 236.36, 29.37]}, {"formula_id": "formula_10", "formula_text": "|p f (T )| 2 \u2265 CDF \u22121 \u03c7 2 (1 \u2212 \u03b1) N(t) 2t 2 . (7", "formula_coordinates": [6.0, 358.32, 337.5, 183.01, 22.39]}, {"formula_id": "formula_11", "formula_text": ")", "formula_coordinates": [6.0, 541.33, 342.01, 3.91, 11.04]}, {"formula_id": "formula_12", "formula_text": "F used = / 0 loop f \u2208 F A f = |p f (T )|, \u03c6 f = \u2220p f (T )", "formula_coordinates": [7.0, 55.44, 143.39, 108.45, 28.5]}, {"formula_id": "formula_13", "formula_text": "F used = F used \u222a { f } if not rejected // Flux reconstruction. \u03d5(t) = \u2211 f \u2208F used A f cos(2\u03c0 f t + \u03c6 f )", "formula_coordinates": [7.0, 55.44, 181.19, 122.67, 32.18]}, {"formula_id": "formula_14", "formula_text": "\u03d5(t) = \u2211 f \u2208F A f cos(2\u03c0 f t + \u03c6 f ) p f (T ) = (1/t) \u2211\u03c4\u2208T e \u2212 j2\u03c0 f \u03c4\u03c6 (t) = \u2211 f \u2208F used A f cos(2\u03c0 f t + \u03c6 f )", "formula_coordinates": [7.0, 196.11, 203.94, 360.81, 10.65]}], "doi": ""}