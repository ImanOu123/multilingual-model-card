{"title": "The Complexity of Mining Maximal Frequent Itemsets and Maximal Frequent Patterns", "authors": "Guizhen Yang", "pub_date": "", "abstract": "Mining maximal frequent itemsets is one of the most fundamental problems in data mining. In this paper we study the complexity-theoretic aspects of maximal frequent itemset mining, from the perspective of counting the number of solutions. We present the first formal proof that the problem of counting the number of distinct maximal frequent itemsets in a database of transactions, given an arbitrary support threshold, is #P-complete, thereby providing strong theoretical evidence that the problem of mining maximal frequent itemsets is NP-hard. This result is of particular interest since the associated decision problem of checking the existence of a maximal frequent itemset is in P. We also extend our complexity analysis to other similar data mining problems dealing with complex data structures, such as sequences, trees, and graphs, which have attracted intensive research interests in recent years. Normally, in these problems a partial order among frequent patterns can be defined in such a way as to preserve the downward closure property, with maximal frequent patterns being those without any successor with respect to this partial order. We investigate several variants of these mining problems in which the patterns of interest are subsequences, subtrees, or subgraphs, and show that the associated problems of counting the number of maximal frequent patterns are all either #P-complete or #P-hard.", "sections": [{"heading": "INTRODUCTION", "text": "Since the introduction of the Apriori algorithm about a decade ago [2], the field of data mining has flourished into a research area of significant technological and social importance, with applications ranging from business intelligence to security to bioinformatics. However, in spite of the multitude of data mining algorithms developed, not much effort has been made on the theoretical frontend to study the inherent complexity nature of data mining problems themselves. A thorough investigation of these fundamental problems is greatly needed since it will not only provide invaluable insights into many data mining problems but will also shed new lights on the characteristics of different data mining algorithms and benchmark datasets.\nIn this paper we seek to provide a theoretical account of the computational difficulty of a genre of data mining problems that deal with maximal frequent patterns. These problems can be viewed as instances of the theory extraction problem [10] -they are mainly concerned with enumerating all frequent patterns (described using some language) which satisfy some property and are present in a sufficiently large number of transactions (records) in a database. Examples of this sort include frequent itemsets, association rules, induced subgraphs, etc. Normally, a partial order, , can be defined among all frequent patterns in such a way as to preserve the downward closure property, i.e., given any patterns p1 and p2, if p1 p2 and p2 is frequent, so is p1. Hence maximal frequent patterns are those frequent patterns that do not have any successor with respect to this partial order. Mining maximal frequent patterns has become an important problem because the set of maximal frequent patterns not only uniquely defines a theory given an interestingness criterion, but the number of maximal frequent patterns can be significantly smaller than the number of frequent patterns as well [10].\nWe study the complexity of data mining problems from the perspective of counting the number of solutions. It is natural to assume that any algorithm which can enumerate (compute) all (maximal) frequent patterns should be able to count them as efficiently as well. This counting aspect reveals the inherent complexity nature of data mining problems rather deeply -the expected output is merely a number instead of a presentation of all solutions; and even an exponential number only requires a polynomial number of bits of storage space in binary notation. Therefore, given an enumeration problem, its associated counting problem may have \"lower\" time and/or space complexity.\nWe use the notion of #P-completeness as a theoretical analysis tool to study the complexity of counting problems. The class #P was first introduced in [22] to include all counting problems for which any single solution can be computed by a nondeterministic Turing machine in polynomial time [8]. The notion of #P-completeness is therefore used to capture the \"hardest\" problems in #P (see Section 3.2 for details). These #P-complete problems provide natural candidates for the type of problems that may still remain intractable even if P=NP [8], since under this computation model, an \"efficient\" algorithm for solving a #P-complete problem would behave as if it could, by magic, guess the exact number of correct solutions and simultaneously validate all of them in polynomial time. 1 Our theoretical investigation begins with the problem of mining maximal frequent itemsets -one of the most fundamental problems studied in data mining [28,10,15,5,1,7,9]. We present the first formal proof (see Section 4) that the problem of counting the number of maximal frequent itemsets in a database of transaction, given an arbitrary support threshold, is #P-complete, thereby providing strong theoretical evidence that the problem of mining maximal frequent itemsets is NP-hard, i.e., intractable in the worst case. Since the existence of a maximal frequent itemset can be checked in polynomial time, this result identifies the problem of counting the number of maximal frequent itemsets as one of the few known counting problems whose associated decision problems are \"easy\", i.e., belong to P.\nNote that number of maximal frequent itemsets can be exponentially smaller than the number of frequent itemsets [28,10]. In contrast to mining frequent itemsets, several algorithms have been shown to be able to gain computational efficiency substantially for mining maximal frequent itemsets [28,10,15,5,1,7,9]. Given that the problem of counting the number of frequent itemsets has also been shown to be #P-complete [10], our new complexity result implies a rather unexpected analogy: the problem of mining maximal frequent itemsets is of as great worst-case computational complexity as the problem of mining frequent itemsets.\nHaving established the #P-completeness of the counting problem for maximal frequent itemsets, we also extend our complexity analysis to other similar problems that deal with complex data structures, such as sequences [3,25], trees [26,4,24], and graphs [12,13], which have attracted intensive research interests in recent years. We investigate several variants of these mining problems in which the patterns of interest are subsequences, subtrees, or subgraphs, and show that their associated problems of counting the number of maximal frequent patterns are all either #P-complete or #P-hard (our complexity results are summarized in Table 2).\nThe rest of this paper is organized as follows. Section 2 introduces the basic concepts and notions to be used throughout this paper. In Section 3 we introduce the theory of #P-completeness. Section 4 presents our formal proof that the problem of counting the number of maximal frequent itemsets is #P-complete. The complexity results concerning other maximal frequent patterns, including subsequences, subtrees, and subgraphs, are presented Section 5. Finally, 1 All the complexity results presented in this paper should be interpreted as worst-case time complexity.\nwe discuss related work in Section 6 and conclude this paper in Section 7.", "publication_ref": ["b1", "b9", "b9", "b21", "b7", "b7", "b0", "b27", "b9", "b14", "b4", "b0", "b6", "b8", "b27", "b9", "b27", "b9", "b14", "b4", "b0", "b6", "b8", "b9", "b2", "b24", "b25", "b3", "b23", "b11", "b12", "b0"], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "PRELIMINARIES", "text": "In this section we introduce the important concepts and notations that will be used throughout the paper. First we describe how to represent databases using bipartite graphs and binary matrices (see [27] for a more detailed survey). Then we formalize several notions of itemsets with different support characteristics. Table 1 summarizes the notations that will be used in this paper and their meaning.  ", "publication_ref": ["b26"], "figure_ref": [], "table_ref": ["tab_0"]}, {"heading": "Databases and Itemsets", "text": "A database comprises a set of transactions. Each transaction has a unique transaction identifier (tid) and contains a set of items. For simplicity we will normally omit the tid of a transaction and just list the set of items that it contains. A set of items is often called an itemset. Let I be an itemset and t a transaction. We will use the notation, I \u2286 t, to denote that I is a subset of the set of items that t contains. When the context is clear, we will often directly refer to a transaction as the set of items that it contains.\nGiven a set S, we will use the notation, |S|, to denote the cardinality of S, i.e., the number of elements in S. Let I be an itemset and D a database of transactions. We will use the notation, D(I), to represent the set of transactions of D that are a superset of I, i.e., D(I)\ndef = {t | I \u2286 t, t \u2208 D}.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Bipartite Graphs and Binary Matrices", "text": "A bipartite graph, G, can be represented as a triple, G = (U, V, E), where U and V are disjoint sets of vertices and E is the set of edges between vertices in U and V such that\nE \u2286 U \u00d7 V . A bipartite graph G = (U, V, E\n) is called a bipartite clique if there is an edge between every pair of vertices in U and V , i.e., E = U \u00d7 V . Usually we will omit the set of edges when we represent a bipartite clique. Given a bipartite clique, G = (U, V ), where |U | = m and |V | = n, we will call it a bipartite (m, n)-clique, or a bipartite (m, * )-clique (if the cardinality of V is of no importance), or a bipartite ( * , n)-clique (if the cardinality of U is of no importance).\nWe will say that a bipartite graph,\nG = (U , V , E ), ap- pears in another bipartite graph, G = (U, V, E), if U \u2286 U, V \u2286 V, E \u2286 E.\nOf particular interest are those bipartite cliques that appear in a given bipartite graph. We will say that a bipartite clique, G = (U , V ), is a maximal bipartite clique in a given bipartite graph G, if G appears in G and there exists no other bipartite clique, G = (U , V ), in G such that U \u2286 U and V \u2286 V .\nOne can easily establish a one-to-one correspondence between bipartite graphs and databases of transactions. Given a database D, its corresponding bipartite graph, denoted GD = (U, V, E), can be constructed as follows: U comprises all database transactions in D; V comprises all items appearing in D; for all u \u2208 U , v \u2208 V , (u, v) \u2208 E iff v \u2208 u, i.e., transaction u contains item v. Given a a bipartite graph G, we will use DG to denote its corresponding database of transactions.\nA binary matrix is a matrix in which each entry has value either 0 or 1. A one-to-one correspondence between binary matrices and databases of transactions can also be established rather straightforwardly. Given a database D, we number its transactions as t1, t2, \u2022 \u2022 \u2022 , tm (corresponding to rows 1 to m of a matrix) and all the items as x1, x2, \u2022 \u2022 \u2022 , xn (corresponding to columns 1 to n of a matrix). Then D corresponds to an m\u00d7n matrix, denoted AD, in which its entry aij has value 1 iff transaction ti contains item xj; otherwise, its value is 0. Given a binary matrix A, we will use DA to denote its corresponding database of transactions.\nExample 1 Consider a database D that consists of the following transactions, t1, t2, t3, t4, t5, where\nt1 = {x1, x2}, t2 = {x1, x2, x3}, t3 = {x1, x2, x3, x4}, t4 = {x3, x4}, t5 = {x3, x4}. Here x1, x2, x3, x4 denote different items in D.\nThe corresponding bipartite graph, GD, and binary matrix, AD, are illustrated in Figures 1 and 2, respectively. 2  9 \u00a7 9 9 \u00a7 9 9 \u00a7 9 9 \u00a7 9 9 \u00a7 9 9 \u00a7 9 9 \u00a7 9 9 \u00a7 9 @ \u00a7 @ @ \u00a7 @ @ \u00a7 @ @ \u00a7 @ @ \u00a7 @ @ \u00a7 @ @ \u00a7 @ @ \u00a7 @ \n\u00a1 x 1 \u00a2 \u00a3 x 2 \u00a4 \u00a5 x 3 \u00a6 \u00a7 \u00a6 x 4 \u00a9 t 1 t 2 t 3 t 4 t 5 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ( \u00a7\n\u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 4 \u00a7)\nA \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D\nx 1 x 2 x 3 x 4 t 1 1 1 0 0 t 2 1 1 1 0 t 3 1 1 1 1 t 4 0 0 1 1 t 5 0 0 1 1", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Figure 2: Binary Matrix Representation of the Database in Example 1", "text": "In the sequel, we will use either binary matrices or bipartite graphs to represent databases of transactions.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Support and Maximality", "text": "Classical Data mining problems are usually concerned with itemsets that frequently occur in a database of transactions. The number of occurrences of an itemset in a database is commonly referred to as the support of this itemset, formalized as follows. 2 2 The support of an itemset can be also defined as the percentage of transactions that are a superset of it. For convenience here we use an integer value to define the support of an itemset, since it can always be computed by multiplying the percentage number by the total number of transactions. Note that even if two database transactions contain the same set of items they are still different from each other, since each transaction has its own unique tid. Therefore, they will each contribute one count towards the support of an itemset that they contain. Definition 2 (\u03b4-Occurrent Itemset) For \u03b4 \u2265 1, we will say that an itemset I is \u03b4-occurrent in a database D, if the support of I in D is \u03b4, i.e., fD(I) = \u03b4.\nDefinition 3 (\u03c3-Frequent Itemsets) For 1 \u2264 \u03c3 \u2264 |D|, an itemset I is called \u03c3-frequent in a database D, if fD(I) \u2265 \u03c3, i.e., the support of I in D is at least \u03c3.\nLemma 2 Let D be a database of transactions, I and J two itemsets. If I \u2286 J and both I and J are \u03b4-occurrent itemsets, then D(I) = D(J).\nIn the sequel, when we discuss properties of itemsets with respect to a database D, for simplicity we will usually omit the database D, especially when D is fixed or its existence is clear from the context.\nHaving defined the notion of \u03c3-frequent itemsets, now we can formally state the problem of mining frequent itemsets as follows: Given a database of transactions D and an arbitrary integer value \u03c3 such that 1 \u2264 \u03c3 \u2264 |D|, enumerate all \u03c3-frequent itemsets in D.\nWe should point out the difference between \u03b4-occurrent and \u03c3-frequent itemsets. If an itemset is \u03b4-occurrent, then its support must be exactly \u03b4. The support of a \u03c3-frequent itemset, however, can be any value greater than or equal to \u03c3. Clearly, if an itemset is \u03c3-frequent, then it must be \u03b4-occurrent for some \u03b4 \u2265 \u03c3.\nExample 2 Consider again the database D in Example 1. Its corresponding bipartite graph and binary matrix representations are illustrated in Figures 1 and 2, respectively. One can easily validate the following:\n{x2, x3} is a 2-occurrent itemset (D({x2, x3}) = {t2, t3}); {x1, x2} is a 3-occurrent and 2-frequent itemset (D({x1, x2}) = {t1, t2, t3}). 2\nIf we consider subset inclusion as defining a partial order for itemsets, then we can introduce the notions of maximal \u03b4-occurrent and maximal \u03c3-frequent itemsets, as follows.\nDefinition 4 (Maximal \u03b4-Occurrent Itemsets) Let I be a \u03b4-occurrent itemset in a database D. We say that I is a maximal \u03b4-occurrent itemset in D, if there exists no itemset J such that J \u2283 I and J is \u03b4-occurrent in D. 3 Definition 5 (Maximal \u03c3-Frequent Itemsets) Let I be a \u03c3-frequent itemset in a database D. We say that I is a maximal \u03c3-frequent itemset in D, if there exists no itemset J such that J \u2283 I and J is \u03c3-frequent in D. Now that we have introduced maximal \u03c3-frequent itemsets, we can formally state the problem of mining maximal frequent itemsets as follows: Given a database of transactions D and an arbitrary integer value \u03c3 such that 1 \u2264 \u03c3 \u2264 |D|, enumerate all maximal \u03c3-frequent itemsets in D.\nOne can easily see that if an itemset I is \u03c3-frequent, then any (nonempty) subset J \u2282 I is also \u03c3-frequent. On the other hand, if J \u2282 I is not \u03c3-frequent, then I cannot be \u03c3-frequent either. Note that once all the maximal \u03c3-frequent itemsets have been computed, then all the \u03c3-frequent itemsets can be directly enumerated from them without having to read from the database any more. Conceptually the information about \u03c3-frequent itemsets can be \"summarized\" using maximal \u03c3-frequent itemsets -the number of maximal \u03c3-frequent itemsets can be significantly smaller than the number of \u03c3-frequent itemsets.\nNote that if I is a \u03b4-occurrent itemset, it does not necessarily mean that any subset J \u2282 I is also \u03b4-occurrent. It must be true, however, that J is \u03bb-occurrent for some \u03bb \u2265 \u03b4.\nThe notion of maximal occurrent itemsets plays an important role in our complexity analysis of mining maximal frequent itemsets. In the following Section 4 we will develop lemmas to establish several connections between maximal occurrent and maximal frequent itemsets. The following example illustrates the idea of maximal \u03b4-occurrent and maximal \u03c3-frequent itemsets. Let D be a database and GD its corresponding bipartite graph. In Section 2.2 we show that there is a one-to-one correspondence between bipartite graphs and databases of transactions. In fact, there is also a one-to-one correspondence between maximal occurrent itemsets in D and maximal bipartite cliques in GD. Their relationship is formally stated in the following lemma. ", "publication_ref": ["b2"], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "THEORETICAL FOUNDATIONS", "text": "Most data mining problems espouse two different but in fact closely related perspectives: enumeration of all solutions and counting the number of solutions. In this section we will first discuss the counting aspect of the problem of mining maximal frequent itemsets and then introduce the notion of #P-completeness as a complexity analysis tool for the class #P of counting problems.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Enumeration vs. Counting", "text": "The problem of mining maximal frequent itemsets, as formally defined in Section 2.3, is to enumerate all maximal frequent itemsets whose support is no less than a preset threshold. A natural question that one may ask is: What is the (worst-case) computational complexity of enumerating all maximal frequent itemsets?\nSince all the maximal frequent itemsets must be enumerated, clearly the computational cost must be proportional to at least the number of all maximal frequent itemsets. So it is natural to ask the following question: Is the number of maximal frequent itemsets always polynomial in the size of the database? 4 Unfortunately the answer to the question above turns out to be \"No\". In the following example we will show a database of transactions with an exponential number of maximal frequent itemsets at a certain support threshold.\nExample 5 Let X = {x1, x2, \u2022 \u2022 \u2022 , x2n\u22121,\nx2n} denote a set of 2n items. We will construct a database D with 2n transactions, t1, t2, \u2022 \u2022 \u2022 , t2n\u22121, t2n, as follows: ti = X \u2212 {xi} for all 1 \u2264 i \u2264 2n, i.e., transaction ti comprises all the items in X except item xi. Now we can claim that the number of maximal n-frequent itemsets in D is exactly`2 n n\u00b4. To see why, first we can show that for any itemset I \u2286 X,\nD(I) = {ti | xi \u2208 I, xi \u2208 X}. It follows that if |I| = k then fD(I) (the support of I in D) is exactly 2n\u2212k.\nTherefore any itemset I must be maximal n-frequent iff |I| = n, since for any itemset J, if J \u2283 I then it must be true that fD(J) < n. Clearly, there are exactly`2 n n\u00b4n umber of different itemsets of size n. So the number of maximal n-frequent itemsets is\n2n n\u00b4. The size of D is O(n 2 ). Moreover,`2 n n\u00b4= (2n)! n!\u2022n! \u2265 2 n .\nHence the number of maximal n-frequent itemsets in D is exponential in the size of D. 2\nExample 5 above provides a strong indication that no algorithm can efficiently enumerate all maximal frequent itemsets in the worst case, given an arbitrary support threshold. The reason is just downright straightforward -the number of maximal frequent itemsets may be exponential in the worst case -one would just need to spend at least an exponential amount of time to \"print\" them out, let alone the additional cost to \"compute\" them! However, the argument above is still not convincing enough. First, it does not constitute a formal proof that the problem of mining (enumerating) all maximal frequent itemsets is \"hard\". Second, one may, albeit arguably, claim that only \"printing\" but not \"computing\" of all the maximal frequent itemsets takes an exponential amount of time -an algorithm smart enough might be able to \"compute\" and \"compress\" all maximal frequent itemsets using some efficient data structure in polynomial time. Indeed, such discrepancy between \"printing\" and \"computing\" is not uncommon. For instance, it takes quadratic time to print out all the suffixes of a string; but an efficient data structure, the so-called suffix tree, can be constructed in linear time which encodes all the suffixes of a given string [20].\nNote that if an algorithm can enumerate all maximal frequent itemsets then it should be able to count them also. This counting aspect of data mining problems is important because in contrast to enumeration, the associated counting problem might have \"lower\" complexity. In fact, an exponential number requires only a polynomial number of bits to store. For instance, the number`2 n n\u00b4n eeds just O(n log 2 n) bits to encode in binary notation. Moreover, arithmetic operations, such as addition, subtraction, multiplication, division, etc., only take a polynomial (in the sizes of the two operands) number of steps to finish. Therefore, if an algorithm is claimed to be able to \"compute\" all maximal frequent itemsets in polynomial time, then it is natural to assume that it should be able to count them as efficiently as well; otherwise, such a claim is not justified.\nIn light of this intrinsic connection between computing and counting, from now on we will focus on the counting aspect of data mining problems. First we revise our original problem definition accordingly as follows: Given a database of transactions D and an arbitrary integer value \u03c3 such that 1 \u2264 \u03c3 \u2264 |D|, count the number of all maximal \u03c3-frequent itemsets in D. In the rest of this paper, we will develop theorems to show that the \"easier\" counting problem above is in fact computationally difficult, thereby presenting a formal proof that its associated problem of enumerating (computing) all solutions is hard.", "publication_ref": ["b3", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "The Complexity of Counting", "text": "The theory of NP-completeness is mainly concerned with decision problems asking about the existence of a solution. On the contrary, whereas enumeration problems require explicit output of all solutions, counting problems need to calculate the number of solutions only. 5 Clearly, if a decision problem is NP-complete, then its associated enumeration or counting problem must be NP-hard, because being able to enumerate all solutions or knowing the number of solutions is enough to answer the question of whether there is one.\nThe class #P of counting problems was first introduced by Valiant to give a complexity-theoretic characterization of the computational difficulty of counting [22]. Here we follow the same definitions as in [22]. Definition 6 (Counting Turing Machines) A counting Turing machine is a standard nondeterministic Turing machine with an auxiliary output device that (magically) prints in binary notation on a special tape the number of accepting computations induced by the input. It has (worst-case) time complexity f (n) if the longest accepting computation induced by the set of all inputs of size n takes f (n) steps (when the Turing machine is regarded as a standard nondeterministic machine without the auxiliary device).", "publication_ref": ["b4", "b21", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Definition 7 (#P) A counting problem belongs to #P if this problem can be solved by a counting Turing machine of polynomial time complexity.", "text": "A problem is said to be #P-hard if all problems in #P reduce to it. Note that the notion of reduction used here is polynomial time Turing reduction (or simply Turing reduction; see [8] and [22] for more details). More specifically, a Turing reduction from one problem \u03a0 to another problem \u03a0 is an algorithm that solves \u03a0 using a hypothetical oracle for solving \u03a0 such that, if this oracle solves \u03a0 in polynomial time, then the overall algorithm would be a polynomial-time algorithm for \u03a0.\nJust as the concept of NP-completeness is introduced for the \"hardest\" problems in NP, #P-completeness is used to capture the notion of the \"hardest\" problems in #P. Formally, we have the following definition.\nDefinition 8 (#P-Completeness) A counting problem is called #P-complete if all problems in #P Turing reduce to it and it belongs to #P.\nIt is easy to see that #P is the set of counting problems naturally associated with the decision problems in NP. Therefore, for NP-complete problems, their associated counting problems are #P-complete 6 -the hardness of counting the number of solutions for such problems originates from the computational difficulty of searching for just one! For instance, the problem of counting the number of satisfying truth assignments for an arbitrary 3CNF formula is #P-complete [8].\nHowever, there are very hard counting problems whose associated decision problems can actually be solved in polynomial time. The first such problem was proved by Valiant [22] -the problem of counting the number of perfect matchings in a bipartite graph is #P-complete. In the following Section 4 we will show that the problem of counting the number of maximal frequent itemsets falls into this same category. Clearly, if a counting problem is #P-complete or #P-hard, then its associated problem of enumerating (mining) all solutions must be NP-hard [8,16].", "publication_ref": ["b7", "b21", "b7", "b21", "b7", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "COMPLEXITY ANALYSIS", "text": "In this section we will present a formal proof that the problem of counting the number of maximal frequent itemsets is #P-complete. First we introduce the new notations to be used here.\nLet D be a database of transactions. We will use the notation F\u03c3(D) to denote the set of all \u03c3-frequent itemsets, M\u03c3(D) to denote the set of all maximal \u03c3-frequent itemsets, and C \u03b4 (D) to denote the set of all maximal \u03b4-occurrent itemsets.\nSince our focus is on the number of maximal frequent itemsets, it is important to see how this number changes with respect to different support thresholds. We will begin with the number of frequent itemsets.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Lemma 4 If \u03c3 > \u03bb, then F\u03c3(D) \u2286 F \u03bb (D).", "text": "From the lemma above, we can immediately infer that if \u03c3 > \u03bb, then |F\u03c3(D)| \u2264 |F \u03bb (D)|, i.e. the number of frequent itemsets decreases with increase in support thresholds. However, this nice antimonotonicity property of frequent item-sets does not hold for maximal frequent itemsets in general, as illustrated by the example below.\nExample 6 Consider the database D that is shown in Figure 1. We have the following maximal frequent itemsets at different support thresholds.\nM1(D) = {{x1, x2, x3, x4}} M2(D) = {{x1, x2, x3}, {x3, x4}} M3(D) = {{x1, x2}, {x3, x4}} M4(D) = {{x3}} So |M1(D)| = 1, |M2(D)| = 2, |M3(D)| = 2, |M4(D)| = 1.\nClearly, the aforementioned antimonotonicity property does not hold here. 2\nFrom the example above, we can see that maximal frequent itemsets behave rather \"randomly\" and this adds much difficulty to our search of a complexity-theoretic characterization for them. Next we need to establish lemmas to reveal the connections between maximal frequent and maximal occurrent itemsets. Our final formal proof builds on these lemmas.\nLemma 5 Let I and J be two different maximal \u03b4-occurrent itemsets in a database D. Then neither I nor J is a subset of the other, i.e., I \u2282 J and J \u2282 I.\nProposition 6 Let I be a maximal \u03b4-occurrent itemset and J a maximal \u03bb-occurrent itemset in a database D. If I \u2282 J, then \u03b4 > \u03bb. Note that Proposition 9 above gives an upper bound on the number of maximal frequent itemsets. However, the claim in Proposition 9 does not always hold with equality, as illustrated by the example below.\nExample 7 Consider the database D in Figure 1. We have the following different categories of itemsets.\nM1(D) = {{x1, x2, x3, x4}} M2(D) = {{x1, x2, x3}, {x3, x4}} C1(D) = {{x1, x2, x3, x4}} C2(D) = {{x1, x2, x3}} C3(D) = {{x1, x2}, {x3, x4}} C4(D) = {{x3}} C5(D) = \u2205 Clearly, |M1(D)| = 1 but P |D| i=1 |Ci(D)| = 5; |M2(D)| = 2 but |C2(D)| = 1 and P |D| i=2 |Ci(D)| = 4. 2\nWe will now present our proof that the problem of counting the number of maximal frequent itemsets is #P-complete. We will reduce the problem of counting the number of maximal bipartite cliques in a bipartite graph, which has been shown to be #P-complete, to the problem of counting the number of maximal frequent itemsets in a database of transactions.", "publication_ref": [], "figure_ref": ["fig_1", "fig_1"], "table_ref": []}, {"heading": "Theorem 10 ([18])", "text": "The problem of counting the number of maximal bipartite cliques in a given bipartite graph is #P-complete. 7 Corollary 11 Let D be a database of transactions. It is a #P-complete problem to count the number \nP |D| \u03b4=1 |C \u03b4 (D)|. 8 x1 x2 \u2022 \u2022 \u2022 xn y1 y2 \u2022 \u2022 \u2022 ym W R D 8 > > > < > > > : r1 1 1 \u2022 \u2022 \u2022 1 r2 1 1 \u2022 \u2022 \u2022 1 . . . D . . . . . . \u2022 \u2022 \u2022 . . . rm 1 1 \u2022 \u2022 \u2022 1 W S D 8 > > > < > > > : s1 1 1 \u2022 \u2022 \u2022 1 0 1 \u2022 \u2022 \u2022 1 s2 1 1 \u2022 \u2022 \u2022 1 1 0 \u2022 \u2022 \u2022 1 . . . . . . . . . \u2022 \u2022 \u2022 . . . . . . sm 1 1 \u2022 \u2022 \u2022 1 1 1 \u2022 \u2022 \u2022 0\n(i) ri = ti \u222a Y for all 1 \u2264 i \u2264 m, i.e., the transactions of W R\nD are obtained by extending each transaction in T with the entire set Y of new items; (ii) si = X \u222a (Y \u2212 {yi}) for all 1 \u2264 i \u2264 m, i.e., each transaction si of W S D contains all the items in X and Y except item yi. This transformation is illustrated schematically in Figure 3. Note that we can establish a one-to-one correspondence between transactions in R and T . Clearly, if the size of   \nD is O(d), then the size of WD is O(d 2 ).\nI, J \u2286 X and Y k , Yz \u2286 Y : Y k = Yz iff W S D (I \u222a Y k ) = W S D (J \u222a Yz). x1 x2 x3 x4 y1 y2 y3 y4 y5 r1 1 1 0 0 1 1 1 1 1 r2 1 1 1 0 1 1 1 1 1 r3 1 1 1 1 1 1 1 1 1 r4 0 0 1 1 1 1 1 1 1 r5 0 0 1 1 1 1 1 1 1 s1 1 1 1 1 0 1 1 1 1 s2 1 1 1 1 1 0 1 1 1 s3 1 1 1 1 1 1 0 1 1 s4 1 1 1 1 1 1 1 0 1 s5 1 1 1 1 1 1 1 1 0\n. If I \u2286 X is a maximal (\u03c3 + k)-occurrent itemset in D, where 1 \u2264 \u03c3 \u2264 m, 0 \u2264 k \u2264 m \u2212 \u03c3, then I \u222a Y k is a maximal (\u03c3 + m)-occurrent and maximal (\u03c3 + m)-frequent itemset in WD, where Y k is an arbitrary itemset such that Y k \u2286 Y and |Y k | = k. Proposition 14 Let D be a database of transactions, |D| = m, WD = W R D \u222a W S D the new database transformed from D, X the set of items appearing in D, Y the set of new items introduced into WD, U = I \u222a Y k , where I \u2286 X, Y k \u2286 Y , |Y k | = k. If U is a maximal (\u03c3 + m)-frequent itemset in WD, where 1 \u2264 \u03c3 \u2264 m, then 0 \u2264 k \u2264 m \u2212 \u03c3 and I is a maximal (\u03c3 + k)-occurrent itemset in D. Moreover, U is a maximal (\u03c3 + m)-occurrent itemset in WD.\n|M\u03c3+m(WD)| = m\u2212\u03c3 X k=0 |C \u03c3+k (D)| \u2022 m k ! Theorem 17 Let D be a database of transactions, |D| = m.\nThe problem of counting the number of all maximal \u03c3-frequent itemsets in D, where 1 \u2264 \u03c3 \u2264 m, is #P-complete.", "publication_ref": ["b6"], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Proof.", "text": "Checking whether an itemset is maximal frequent or not can be done in polynomial time. Therefore, the problem of counting the number of maximal frequent itemsets is in #P. We know that the problem of counting the number P m \u03c3=1 |C\u03c3(D)| is #P-complete, by Corollary 11. We will show how this counting problem can be Turing reduced to the problem of counting the number of maximal frequent itemsets, thereby proving that the latter problem is #P-hard.\nFirst, we transform the database D into its corresponding new database WD. We will assume binary matrix representation for databases. Therefore, if the size of D is O(d), then the size of WD is O(d 2 ), and the running time of the transformation algorithm is also O(d 2 ).\nLet C\u03c3 = |C\u03c3(D)|, M\u03c3 = |M\u03c3+m(WD)|, for 1 \u2264 \u03c3 \u2264 m. Then by Proposition 16, we can construct the following linear equations, represented in matrix notation: \n0 B B B B B B B B B @ 1`m 1\u00b4`m 2\u00b4\u2022 \u2022 \u2022`m m\u221210 1`m 1\u00b4\u2022 \u2022 \u2022`m m\u221220 0 1 \u2022 \u2022 \u2022`m m\u22123. . . 0 0 0 \u2022 \u2022 \u2022 1 1 C C C C C C C C C A \u2022 0 B B B B B B B B B @ C1 C2 C3 . . . Cm 1 C C C C C C C C C A = 0 B B B B B B B B B @ M1 M2 M3 . . . Mm 1 C C C C C C C C C A Clearly,", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "MAXIMAL FREQUENT PATTERNS", "text": "A large number of data mining problems dealing with frequent patterns can be viewed as instances of the theory extraction problem [10]. In general, every transaction in a database D is considered as a (large) pattern. A partial order, , can be defined on all patterns such that the support of a pattern p can be formalized as follows: fD(p) def = |{t | p t, t \u2208 D}|. 9 A pattern whose support exceeds a userspecified threshold is called a frequent pattern. Note that this partial order, , preserves the downward closure property, i.e., given any patterns p1 and p2, if p1 p2 and p2 is frequent, so is p1. We will write p1 \u227a p2 if p1 p2 and p1 = p2. Hence a frequent pattern p is maximal if there is no frequent pattern q such that p \u227a q.\nMany problems of mining maximal frequent patterns fall into this line of generalization above. For example, in the problem of mining maximal frequent itemsets, the patterns are sets of items and the partial order is defined on subset inclusion. In this section, we will extend our complexity analysis to several problems of mining maximal frequent patterns studied recently in the literature, in which the patterns of interest are subsequences, subtrees, or subgraphs. In the following, we will just define the data structures used in these problems and specify the partial orders on patterns. Support and maximality of patterns will be defined in the same way as in Section 2.3. Our goal is to show the complexity of the associated counting problems for these maximal frequent patterns.", "publication_ref": ["b9", "b8"], "figure_ref": [], "table_ref": []}, {"heading": "Subsequences", "text": "In problems of mining frequent sequences [3,25], each database transaction is considered as a sequence (string) instead of a set, in which the order of symbols appearing in this sequence is important. Normally the patterns of interest are subsequences. The partial order, , on any two sequences, s1 and s2, is defined as follows: s1 s2 iff s1 is a subsequence of s2, i.e., s1 can be obtained from s2 by removing zero or more symbols from s2. For example, ac is a subsequence of abc. Our complexity result about mining maximal frequent subsequences is stated in Theorem 18 below.\nTheorem 18 Let D be a database of sequences, |D| = m. The problem of counting the number of maximal \u03c3-frequent subsequences in D, where 1 \u2264 \u03c3 \u2264 m, is #P-complete.", "publication_ref": ["b2", "b24"], "figure_ref": [], "table_ref": []}, {"heading": "Subtrees and Subgraphs", "text": "In recent years mining frequent patterns from trees [26,4,24] and graphs [12,13] has attracted a lot of research interests. Normally, the patterns of interest are subtrees or subgraphs. Note that trees are just a special form of connected, acyclic graphs. A graph, G = (V, E), consists of a set of vertices, V , and a set of edges, E \u2286 V \u00d7 V . Subgraph isomorphism can be viewed as defining a partial order among graphs. Given two graphs, G1 = (V1, E1) and G2 = (V2, E2), G1 is called a subgraph of G2, denoted G1 G2, if there is an injective function \u03c1 : V1 \u2192 V2 such that for any (a, b) \u2208 E1, (\u03c1(a), \u03c1(b)) \u2208 E2. Moreover, G1 is called an induced subgraph of G2 if \u03c1 satisfies the following additional condition: for all (\u03c1(a), \u03c1(b)) \u2208 E2, (a, b) \u2208 E1. The complexity results to be presented here apply to either subgraphs or induced subgraphs. But for simplicity we will only mention subgraphs.\nThe definition of subgraph isomorphism can be readily used to define subtree isomorphism on tree data structures, even though definitions of trees usually need to take into account several factors: rooted or unrooted (called free trees); ordered or unordered (the order of sibling nodes is not important); labeled (edge-labeled or node-labeled or both) or unlabeled. Next we present the complexity results on labeled trees and graphs, followed by unlabeled trees and graphs.\nTheorem 19 Let D be a database of (rooted) unordered labeled trees, |D| = m. The problem of counting the number of maximal \u03c3-frequent subtrees in D, where 1 \u2264 \u03c3 \u2264 m, is #P-complete.\nTheorem 20 Let D be a database of (rooted) ordered labeled trees, |D| = m. The problem of counting the number of maximal \u03c3-frequent subtrees in D, where 1 \u2264 \u03c3 \u2264 m, is #P-complete.\nWe should point out that our complexity results can be readily extended to prove the #P-hardness of counting maximal frequent embedded subtrees [26] in a database of labeled trees. Moreover, we can also immediately derive the following corollary for labeled graphs. Note that Corollary 21 below applies to labeled graphs that are either directed or undirected, ordered or unordered.\nCorollary 21 Let D be a database of labeled graphs, |D| = m. It is #P-hard to count the number of maximal \u03c3-frequent subgraphs in D, where 1 \u2264 \u03c3 \u2264 m.\nWe will now extend our complexity results to unlabeled trees and graphs. First we will state the result for unlabeled trees. Extending this result to unlabeled graphs is rather straightforward. To prove the #P-completeness of the problem of counting the number of maximal frequent unlabeled subtrees, we will reduce to it the problem of counting the number of maximal frequent itemsets. Here the proof is rather tricky and omitted for want of space.\nTheorem 22 Let D be a database of (rooted) unlabeled trees, |D| = m. The problem of counting the number of maximal \u03c3-frequent subtrees in D, where 1 \u2264 \u03c3 \u2264 m, is #P-complete.\nIt is worth pointing out that the claims in Theorems 19, 20, and 22 still remain valid even if binary trees are supplied as input. From Theorem 22 we can immediately derive the following claim about unlabeled graphs.\nCorollary 23 Let D be a database of unlabeled graphs, |D| = m. The problem of counting the number of maximal \u03c3-frequent subgraphs in D, where 1 \u2264 \u03c3 \u2264 m, is #P-hard.", "publication_ref": ["b25", "b3", "b23", "b11", "b12", "b25"], "figure_ref": [], "table_ref": []}, {"heading": "RELATED WORK", "text": "Valiant introduced the class #P of counting problems and proved that counting the number of distinct perfect matchings in a bipartite graph is #P-complete [22] -the first counting problem known to be #P-complete whose associated decision problem can be solved in polynomial time. In [18], many counting problems on bipartite graphs, such as vertex cover, independent set, were proved to be #P-complete. The #P-completeness of counting the number of maximal bipartite cliques in a bipartite graph follows readily from the results in [18], although it was not explicitly stated there. A similar claim was also made in [14], but its proof was not correct. However, in [14] it was shown that it is NP-complete to decide whether there is a maximal bipartite (k, * )-clique in a bipartite graph. More recently, Hunt et al. proved the #P-hardness of many graph counting problems when restricted to planar instances [11]. Some of these results were later extended by Vadhan to even more restricted bipartite graphs of bounded degree [21].\nMany algorithms have been proposed in the literature for mining maximal frequent itemsets, such as MaxClique [28], Dualize and Advance [10], Pincer-Search [15], Max-Miner [5], DepthProject [1], MAFIA [7], and GenMax [9]. These algorithms exploited different heuristics for optimization and were shown to have different good scaleup characteristics on certain benchmark datasets. However, theoretical analysis was not the main focus of these works and none of them proved that the problem of counting the number of maximal frequent itemsets is #P-complete.\nThere is a large body of work in the literature on mining frequent and maximal frequent patterns from complex data structures, such as sequences [3,25], trees [26,4,24], and graphs [12,13]. Our complexity results (summarized in Table 2) can be easily extended to problems studied in these works. Specifically, in [26] the patterns of interest are embedded subtrees. Our proof of Theorem 19 implies that it is #P-hard to count the number of maximal frequent embedded subtrees in a database of labeled trees. The #P-completeness of counting the number of frequent closed itemsets [23] also readily follows our complexity results here.\nThe problem of counting the number of frequent itemsets was first shown to be #P-complete in [10]. In [10] it was shown that it is NP-complete to decide if there is a maximal \u03c3-frequent itemset with at least k items. The NP-hardness of mining maximal frequent itemsets was also recently established in [6] by proving the following claim: given a set of maximal frequent itemsets, it is NP-complete to decide whether this set can be grown with a new maximal frequent itemset. These results do not lend themselves to the #P-completeness of counting the number of maximal frequent itemsets. In contrast, our result asserts a much stronger claim about the hardness of mining maximal frequent itemsets -it is #P-complete to decide the exact number of all maximal frequent itemsets -there is no clear clue that this problem would belong to NP! Finally, the work of [27] aimed at providing a latticetheoretic framework for mining frequent itemsets and association rules. Interesting work was also recently reported in [19] on characterization of length distributions of frequent and maximal frequent itemset collections, with a focus on computing tight bounds for feasible distribution. We should point out that neither of these two works subsumes any of the complexity results proved in this paper. Moreover, our results on the complexity of counting maximal frequent itemsets provide theoretical underpinnings for the algorithms proposed in [19] for computing distribution.", "publication_ref": ["b21", "b17", "b17", "b13", "b13", "b10", "b20", "b27", "b9", "b14", "b4", "b0", "b6", "b8", "b2", "b24", "b25", "b3", "b23", "b11", "b12", "b25", "b22", "b9", "b9", "b5", "b26", "b18", "b18"], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "DISCUSSION AND CONCLUSION", "text": "In this paper we study the complexity of mining maximal frequent patterns, from the perspective of counting the number of solutions. We present the first formal proof that the problem of counting the number of maximal frequent itemsets is #P-complete, thereby providing a complexitytheoretic explanation for the (worst-case) computational difficulty of this problem. We also extend our complexity analysis to other data mining problems dealing with complex data structures, in which the patterns of interest are maximal frequent subsequences, subtrees, or subgraphs. The complexity results proved in this paper are summarized in Table 2. To the best of our knowledge, our work is the first comprehensive study of the complexity of mining maximal frequent patterns.\nWe should point out that there are four different but closely related computational aspects of data mining problems:", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "Enumeration Problem (Column 2 of Table 2). Explicit", "text": "output of all solutions is expected.\n2. Counting Problem (Column 3 of Table 2). The goal is to compute the number of all solutions.\n3. Search Problem (Column 4 of Table 2). Output of only one solution is desired, if there is any.\n4. Decision Problem (Column 5 of Table 2). The primary concern is about the existence of one solution.\nTake as an example the problem of mining maximal frequent itemsets. Its associated search problem is to output one maximal frequent itemset, if there is any, while the decision problem is to answer the question of whether a maximal frequent itemset exists. These four different aspects of data mining problems in fact exhibit different levels of computational complexity (see Table 2). For all the problems we study in this paper, their associated decision problems (whether a maximal frequent pattern exists) can all be solved in polynomial time (even for labeled graphs). Their search problems can also be solved in polynomial time except the search for a maximal frequent subgraph. This is due to the computational difficulty of testing for subgraph isomorphism, which is NP-complete [8]. Nevertheless, one can easily design a deterministic polynomial time algorithm to compute a maximal frequent subgraph, given an oracle for solving subgraph isomorphism: start with a graph with one node and grow it until the subgraph isomorphism test fails. This implies that the complexity of searching for a maximal frequent subgraph is FP NP [16]. For the same reason, it is unlikely that the counting problem for maximal frequent subgraphs would belong to #P; but we have proved that it is #P-hard. Finally, we should point out that the NP-hardness of enumeration problems can be readily derived from the #P-hardness of their associated counting problems [8]. Also note that the problem of mining maximal frequent substrings can be efficiently solved in polynomial time, utilizing the data structure of generalized suffix trees [20] -this is not really surprising since substrings do not manifest a combinatorial nature.\nThe complexity results presented in this paper should be interpreted as worst-case time complexity only -the implication being there is little hope a data mining algorithm can execute efficiently on any dataset (if the problem is #P-hard or NP-hard). In recent years many data mining algorithms have been developed for important applications. Most of them have been shown to be efficient or even exhibit linear scaleup property with respective to various test datasets, either synthetic or from real applications. A different analysis tool will be needed to provide a complexity-theoretic explanation for the efficiency of these algorithms and datasets. Recently interesting work was reported in [19] on characterization of length distributions of frequent and maximal frequent itemset collections. We believe research along this line will provide us with good guidance on understanding the algorithms themselves as well as the datasets tested.\nAnother important problem is concerned with data mining algorithms that can \"adapt\" efficiently -if the size of the output is polynomial, then the algorithm runs in polynomial time -the so-called output polynomial algorithms [17]. Recently, in [10], a mildly subexponential algorithm was developed for mining maximal frequent itemsets. But currently it is still an open problem whether an output polynomial algorithm exists for mining maximal frequent itemsets. Our complexity results do not address this problem and we believe that different complexity analysis techniques will be needed. The same complexity results apply to (binary) trees that are either rooted or unrooted, ordered or unordered, labeled or unlabeled (with or without duplicate labels). b The same complexity results apply to graphs that are either directed or undirected, labeled or unlabeled (with or without duplicate labels). ", "publication_ref": ["b7", "b15", "b7", "b19", "b18", "b16", "b9"], "figure_ref": [], "table_ref": ["tab_4", "tab_4", "tab_4", "tab_4"]}, {"heading": "ACKNOWLEDGMENT", "text": "The author would like to thank Leslie G. Valiant, Alan Selman, Mitsunori Ogihara, Heikki Mannila, Mohammed Javeed Zaki, Jian Pei, Yongqiao Xiao, and the anonymous referees for their helpful comments.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Depth first generation of long patterns", "journal": "", "year": "2000", "authors": "R C Agarwal; C C Aggarwal; V V V Prasad"}, {"ref_id": "b1", "title": "Fast algorithms for mining association rules in large databases", "journal": "", "year": "1994", "authors": "R Agrawal; R Srikant"}, {"ref_id": "b2", "title": "Mining sequential patterns", "journal": "", "year": "1995", "authors": "R Agrawal; R Srikant"}, {"ref_id": "b3", "title": "Efficient substructure discovery from large semi-structured data", "journal": "", "year": "2002", "authors": "T Asai; K Abe; S Kawasoe; H Arimura; H Satamoto; S Arikawa"}, {"ref_id": "b4", "title": "Efficiently mining long patterns from databases", "journal": "", "year": "1998", "authors": "R J Bayardo"}, {"ref_id": "b5", "title": "On the complexity of generating maximal frequent and minimal infrequent sets", "journal": "", "year": "2002", "authors": "E Boros; V Gurvich; L Khachiyan; K Makino"}, {"ref_id": "b6", "title": "MAFIA: A maximal frequent itemset algorithm for transactional databases", "journal": "", "year": "2001", "authors": "D Burdick; M Calimlim; J Gehrke"}, {"ref_id": "b7", "title": "Computers and Intractability: A Guide to the Theory of NP-Completeness", "journal": "W. H. Freeman and Company", "year": "1979", "authors": "M R Garey; D S Johnson"}, {"ref_id": "b8", "title": "Efficiently mining maximal frequent itemsets", "journal": "", "year": "2001", "authors": "K Gouda; M J Zaki"}, {"ref_id": "b9", "title": "Discovering all most specific sentences", "journal": "ACM Transactions on Database Systems (TODS)", "year": "2003", "authors": "D Gunopulos; R Khardon; H Mannila; S Saluja; H Toivonen; R S Sharm"}, {"ref_id": "b10", "title": "The complexity of planar counting problems", "journal": "SIAM Journal on Computing", "year": "1998", "authors": "H B Hunt; Iii ; M V Marathe; V Radhakrishnan; R E Stearns"}, {"ref_id": "b11", "title": "An apriori-based algorithm for mining frequent substructures from graph data", "journal": "", "year": "2000", "authors": "A Inokuchi; T Washio; H Motoda"}, {"ref_id": "b12", "title": "Frequent subgraph discovery", "journal": "", "year": "2001", "authors": "M Kuramochi; G Karypis"}, {"ref_id": "b13", "title": "Interpretation on graphs and complexity characteristics of a search for specific patterns. Nauchno-Tekhnicheskaya Informatsiya, Seriya 2 (Automatic Documentation and Mathematical Linguistics", "journal": "", "year": "1989", "authors": "S O Kuznetsov"}, {"ref_id": "b14", "title": "Pincer-Search: An efficient algorithm for discovering the maximum frequent set", "journal": "IEEE Transactions on Knowledge and Data Engineering (TKDE)", "year": "2002", "authors": "D.-I Lin; Z M Kedem"}, {"ref_id": "b15", "title": "Computational Complexity", "journal": "Addison-Wesley", "year": "1994", "authors": "C H Papadimitriou"}, {"ref_id": "b16", "title": "NP-completeness: A retrospective", "journal": "", "year": "1997", "authors": "C H Papadimitriou"}, {"ref_id": "b17", "title": "The complexity of counting cuts and of computing the probability that a graph is connected", "journal": "SIAM Journal on Computing", "year": "1983", "authors": "J S Provan; M O Ball"}, {"ref_id": "b18", "title": "Feasible itemset distributions in data mining: Theory and application", "journal": "", "year": "2003", "authors": "G Ramesh; W Maniatty; M J Zaki"}, {"ref_id": "b19", "title": "On-line construction of suffix trees", "journal": "Algorithmica", "year": "1995", "authors": "E Ukkonen"}, {"ref_id": "b20", "title": "The complexity of counting in sparse, regular, and planar graphs", "journal": "SIAM Journal on Computing", "year": "2001", "authors": "S P Vadhan"}, {"ref_id": "b21", "title": "The complexity of computing the permanent", "journal": "Theoretical Computer Science", "year": "1979", "authors": "L G Valiant"}, {"ref_id": "b22", "title": "CLOSET+: Searching for the best strategies for mining frequent closed itemsets", "journal": "", "year": "2003", "authors": "J Wang; J Han; J Pei"}, {"ref_id": "b23", "title": "Efficient data mining for maximal frequent subtrees", "journal": "", "year": "2003", "authors": "Y Xiao; J.-F Yao; Z Li; M H Dunham"}, {"ref_id": "b24", "title": "SPADE: An efficient algorithm for mining frequent sequences", "journal": "", "year": "2001", "authors": "M J Zaki"}, {"ref_id": "b25", "title": "Efficiently mining frequent trees in a forest", "journal": "", "year": "2002", "authors": "M J Zaki"}, {"ref_id": "b26", "title": "Theoretical foundations of association rules", "journal": "", "year": "1998", "authors": "M J Zaki; M Ogihara"}, {"ref_id": "b27", "title": "New algorithms for fast discovery of association rules", "journal": "", "year": "1997", "authors": "M J Zaki; S Parthasarathy; M Ogihara; W Li"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Da database of transactions I an itemset tid transaction identifier |S| the cardinality of a set S D(I) all transactions in database D that contain I f D (I) the support of I in database D F\u03c3(D) all \u03c3-frequent itemsets in database D M\u03c3(D) all maximal \u03c3-frequent itemsets in database D C \u03b4 (D) all maximal \u03b4-occurrent itemsets in database D", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 1 :1Figure 1: Bipartite Graph Representation of the Database in Example 1", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Definition 1 (1Support) Let I be an itemset and D a database of transactions. The support of I in D, denoted fD(I), is the number of transactions of D in which I occurs as a subset, i.e., fD(I) def = |D(I)|. Lemma 1 Let D be a database of transactions, I and J two itemsets. If I \u2286 J, then D(I) \u2287 D(J) and fD(I) \u2265 fD(J).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Example 33Continue with the previous database example in Example 1. One can easily validate the following: {x2, x3} is a 2-occurrent itemset but not maximal, since {x1, x2, x3} is also a 2-occurrent itemset; {x1, x2, x3} is a maximal 2-frequent itemset; {x1, x2} is a maximal 3-occurrent itemset but not a maximal 2-frequent itemset; {x3, x4} is a maximal 3-occurrent and maximal 2-frequent itemset. 2", "figure_data": ""}, {"figure_label": "34", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Lemma 3 Example 434Let D be a database of transactions and GD the bipartite graph corresponding to D. Then every maximal \u03b4-occurrent itemset in D corresponds to a unique maximal bipartite (\u03b4, * )-clique in GD. Consider the bipartite graph shown in Figure 1 which corresponds to the database in Example 1. Note that {x1, x2} is a maximal 3-occurrent itemset and corresponds to the unique bipartite (3, 2)-clique, ({t1, t2, t3}, {x1, x2}), in Figure 1. 2", "figure_data": ""}, {"figure_label": "78", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Lemma 7 Proposition 878If I is a maximal \u03c3-frequent itemset in a database D and fD(I) = \u03b4, then I is a maximal \u03b4-occurrent itemset. If I is a maximal \u03b4-occurrent itemset in a database D, then I is a maximal \u03b4-frequent itemset in D.Proposition 9 Let D be a database of transactions. Then M\u03c3(D) \u2287 C\u03c3(D) and |M\u03c3(D)| \u2265 |C\u03c3(D)|. Furthermore, M\u03c3(D) \u2286 S |D| i=\u03c3 Ci(D) and |M\u03c3(D)| \u2264 P |D| i=\u03c3 |Ci(D)|.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Figure 3 :3Figure 3: Database Transformation Scheme Let D be a database of transactions. First we transform D to a new database WD as follows. Let T = {t1, t2, \u2022 \u2022 \u2022 , tm} be the set of transactions of D, where m = |D|, and X = {x1, x2, \u2022 \u2022 \u2022 , xn} the set of all items appearing in D. We will introduce a set, Y = {y1, y2, \u2022 \u2022 \u2022 , ym}, of m new items into WD. The new database WD is the union of two databases, W R D = {r1, r2, \u2022 \u2022 \u2022 , rm}, and W S D = {s1, s2, \u2022 \u2022 \u2022 , sm}. The transactions of W R D and W S D are constructed as follows:(i) ri = ti \u222a Y for all 1 \u2264 i \u2264 m, i.e., the transactions of W RD are obtained by extending each transaction in T with the entire set Y of new items; (ii) si = X \u222a (Y \u2212 {yi}) for all 1 \u2264 i \u2264 m, i.e., each transaction si of W S D contains all the items in X and Y except item yi. This transformation is illustrated schematically in Figure3. Note that we can establish a one-to-one correspondence between transactions in R and T . Clearly, if the size of D is O(d), then the size of WD is O(d 2 ).", "figure_data": ""}, {"figure_label": "8212", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "Example 8 2 Lemma 128212The database shown in Figure4is transformed from the database shown in Figure2. Let D be a database of transactions, WD = W R D \u222a W S D the new database transformed from D, X the set of items appearing in D, Y the set of new items introduced into WD. Then for all", "figure_data": ""}, {"figure_label": "4213", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Figure 4 : 2 Proposition 134213Figure 4: The New Database Transformed from the One in Figure 2", "figure_data": ""}, {"figure_label": "15", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Proposition 1515Let D be a database of transactions, |D| = m, WD the new database transformed from D, and 1 \u2264 \u03c3 \u2264 m. Then U is a maximal (\u03c3 + m)-frequent itemset in WD iff U is a maximal (\u03c3 + m)-occurrent itemset in WD. Proposition 16 Let D be a database of transactions, |D| = m, WD the new database transformed from D. Then for all 1 \u2264 \u03c3 \u2264 m:", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "the linear equations above have a unique solution for (C1, C2, \u2022 \u2022 \u2022 , Cm), given the values of (M1, M2, \u2022 \u2022 \u2022 , Mm). For all 0 \u2264 k \u2264 m\u22121,`m k\u00b4\u2264 m m and so`m k\u00b4c an be stored using O(m log 2 m) bits in binary notation and computed in time polynomial in m. Let the size of D be O(d). Then m = O(d) and so all`m k\u00b4c an be stored using O(d log 2 d) bits in binary notation and computed in time polynomial in d. For all 1 \u2264 \u03c3 \u2264 m, C\u03c3 = |C\u03c3(D)| = O(2 d ). So all C\u03c3 can be stored using O(d) bits in binary notation. Moreover, the size of WD is O(d 2 ) and so M\u03c3 = |M\u03c3+m(WD)| = O(2 d 2 ) for all 1 \u2264 \u03c3 \u2264 m. It follows that all M\u03c3 can be represented using O(d 2 ) bits in binary notation. Therefore, given the values of (M1, M2, \u2022 \u2022 \u2022 , Mm), the linear equations above can be solved and hence the values of (C1, C2, \u2022 \u2022 \u2022 , Cm) can be calculated in time polynomial in d, the size of D. Note that the size of WD is O(d 2 ). So if there is a polynomial-time algorithm for counting the number of maximal frequent itemsets, then the values of (M1, M2, \u2022 \u2022 \u2022 , Mm) can be computed in time polynomial in d. Hence the values of (C1, C2, \u2022 \u2022 \u2022 , Cm) and the number P m \u03c3=1 |C\u03c3(D)| = P m \u03c3=1 C\u03c3 can be computed in time polynomial in d. 2", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Summary of Complexity Results", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "def = {t | I \u2286 t, t \u2208 D}.", "formula_coordinates": [2.0, 458.62, 475.66, 81.26, 11.86]}, {"formula_id": "formula_1", "formula_text": "E \u2286 U \u00d7 V . A bipartite graph G = (U, V, E", "formula_coordinates": [2.0, 316.81, 543.01, 129.66, 19.63]}, {"formula_id": "formula_2", "formula_text": "G = (U , V , E ), ap- pears in another bipartite graph, G = (U, V, E), if U \u2286 U, V \u2286 V, E \u2286 E.", "formula_coordinates": [2.0, 316.81, 637.16, 239.09, 30.09]}, {"formula_id": "formula_3", "formula_text": "t1 = {x1, x2}, t2 = {x1, x2, x3}, t3 = {x1, x2, x3, x4}, t4 = {x3, x4}, t5 = {x3, x4}. Here x1, x2, x3, x4 denote different items in D.", "formula_coordinates": [3.0, 53.8, 286.65, 239.09, 30.09]}, {"formula_id": "formula_4", "formula_text": "\u00a1 x 1 \u00a2 \u00a3 x 2 \u00a4 \u00a5 x 3 \u00a6 \u00a7 \u00a6 x 4 \u00a9 t 1 t 2 t 3 t 4 t 5 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! ! \u00a7 ! \u00a7 ! \u00a7 ! \u00a7 ! \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" \" \u00a7 \" \u00a7 \" \u00a7 \" # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # # \u00a7 # $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ $ \u00a7 $ % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % % \u00a7 % & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & & \u00a7 & ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' \u00a7 ' ( \u00a7", "formula_coordinates": [3.0, 103.5, 352.9, 131.74, 65.32]}, {"formula_id": "formula_5", "formula_text": "\u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) ) \u00a7 ) \u00a7 ) \u00a7 ) \u00a7 ) 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 0 \u00a7 0 \u00a7 0 \u00a7 0 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 1 \u00a7 1 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 2 \u00a7 2 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 3 \u00a7 3 4 \u00a7)", "formula_coordinates": [3.0, 121.0, 358.6, 72.4, 61.0]}, {"formula_id": "formula_6", "formula_text": "A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A A \u00a7 A \u00a7 A \u00a7 A \u00a7 A B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B B \u00a7 B \u00a7 B \u00a7 B \u00a7 B C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C C \u00a7 C \u00a7 C D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D D \u00a7 D", "formula_coordinates": [3.0, 187.5, 359.5, 52.0, 56.0]}, {"formula_id": "formula_7", "formula_text": "x 1 x 2 x 3 x 4 t 1 1 1 0 0 t 2 1 1 1 0 t 3 1 1 1 1 t 4 0 0 1 1 t 5 0 0 1 1", "formula_coordinates": [3.0, 133.97, 479.19, 78.25, 53.13]}, {"formula_id": "formula_8", "formula_text": "Definition 3 (\u03c3-Frequent Itemsets) For 1 \u2264 \u03c3 \u2264 |D|, an itemset I is called \u03c3-frequent in a database D, if fD(I) \u2265 \u03c3, i.e., the support of I in D is at least \u03c3.", "formula_coordinates": [3.0, 316.81, 258.6, 239.08, 30.09]}, {"formula_id": "formula_9", "formula_text": "{x2, x3} is a 2-occurrent itemset (D({x2, x3}) = {t2, t3}); {x1, x2} is a 3-occurrent and 2-frequent itemset (D({x1, x2}) = {t1, t2, t3}). 2", "formula_coordinates": [3.0, 316.81, 547.61, 243.59, 30.09]}, {"formula_id": "formula_10", "formula_text": "Example 5 Let X = {x1, x2, \u2022 \u2022 \u2022 , x2n\u22121,", "formula_coordinates": [4.0, 316.81, 301.74, 166.77, 9.16]}, {"formula_id": "formula_11", "formula_text": "D(I) = {ti | xi \u2208 I, xi \u2208 X}. It follows that if |I| = k then fD(I) (the support of I in D) is exactly 2n\u2212k.", "formula_coordinates": [4.0, 316.81, 374.97, 238.99, 19.62]}, {"formula_id": "formula_12", "formula_text": "2n n\u00b4. The size of D is O(n 2 ). Moreover,`2 n n\u00b4= (2n)! n!\u2022n! \u2265 2 n .", "formula_coordinates": [4.0, 321.04, 436.93, 234.87, 13.05]}, {"formula_id": "formula_13", "formula_text": "M1(D) = {{x1, x2, x3, x4}} M2(D) = {{x1, x2, x3}, {x3, x4}} M3(D) = {{x1, x2}, {x3, x4}} M4(D) = {{x3}} So |M1(D)| = 1, |M2(D)| = 2, |M3(D)| = 2, |M4(D)| = 1.", "formula_coordinates": [6.0, 53.8, 129.48, 239.06, 66.64]}, {"formula_id": "formula_14", "formula_text": "M1(D) = {{x1, x2, x3, x4}} M2(D) = {{x1, x2, x3}, {x3, x4}} C1(D) = {{x1, x2, x3, x4}} C2(D) = {{x1, x2, x3}} C3(D) = {{x1, x2}, {x3, x4}} C4(D) = {{x3}} C5(D) = \u2205 Clearly, |M1(D)| = 1 but P |D| i=1 |Ci(D)| = 5; |M2(D)| = 2 but |C2(D)| = 1 and P |D| i=2 |Ci(D)| = 4. 2", "formula_coordinates": [6.0, 53.8, 598.56, 239.07, 122.71]}, {"formula_id": "formula_15", "formula_text": "P |D| \u03b4=1 |C \u03b4 (D)|. 8 x1 x2 \u2022 \u2022 \u2022 xn y1 y2 \u2022 \u2022 \u2022 ym W R D 8 > > > < > > > : r1 1 1 \u2022 \u2022 \u2022 1 r2 1 1 \u2022 \u2022 \u2022 1 . . . D . . . . . . \u2022 \u2022 \u2022 . . . rm 1 1 \u2022 \u2022 \u2022 1 W S D 8 > > > < > > > : s1 1 1 \u2022 \u2022 \u2022 1 0 1 \u2022 \u2022 \u2022 1 s2 1 1 \u2022 \u2022 \u2022 1 1 0 \u2022 \u2022 \u2022 1 . . . . . . . . . \u2022 \u2022 \u2022 . . . . . . sm 1 1 \u2022 \u2022 \u2022 1 1 1 \u2022 \u2022 \u2022 0", "formula_coordinates": [6.0, 337.16, 198.87, 216.89, 147.91]}, {"formula_id": "formula_16", "formula_text": "(i) ri = ti \u222a Y for all 1 \u2264 i \u2264 m, i.e., the transactions of W R", "formula_coordinates": [6.0, 316.81, 468.95, 238.96, 19.63]}, {"formula_id": "formula_17", "formula_text": "D is O(d), then the size of WD is O(d 2 ).", "formula_coordinates": [6.0, 316.81, 542.18, 238.93, 19.63]}, {"formula_id": "formula_18", "formula_text": "I, J \u2286 X and Y k , Yz \u2286 Y : Y k = Yz iff W S D (I \u222a Y k ) = W S D (J \u222a Yz). x1 x2 x3 x4 y1 y2 y3 y4 y5 r1 1 1 0 0 1 1 1 1 1 r2 1 1 1 0 1 1 1 1 1 r3 1 1 1 1 1 1 1 1 1 r4 0 0 1 1 1 1 1 1 1 r5 0 0 1 1 1 1 1 1 1 s1 1 1 1 1 0 1 1 1 1 s2 1 1 1 1 1 0 1 1 1 s3 1 1 1 1 1 1 0 1 1 s4 1 1 1 1 1 1 1 0 1 s5 1 1 1 1 1 1 1 1 0", "formula_coordinates": [6.0, 316.81, 643.17, 238.37, 20.66]}, {"formula_id": "formula_19", "formula_text": ". If I \u2286 X is a maximal (\u03c3 + k)-occurrent itemset in D, where 1 \u2264 \u03c3 \u2264 m, 0 \u2264 k \u2264 m \u2212 \u03c3, then I \u222a Y k is a maximal (\u03c3 + m)-occurrent and maximal (\u03c3 + m)-frequent itemset in WD, where Y k is an arbitrary itemset such that Y k \u2286 Y and |Y k | = k. Proposition 14 Let D be a database of transactions, |D| = m, WD = W R D \u222a W S D the new database transformed from D, X the set of items appearing in D, Y the set of new items introduced into WD, U = I \u222a Y k , where I \u2286 X, Y k \u2286 Y , |Y k | = k. If U is a maximal (\u03c3 + m)-frequent itemset in WD, where 1 \u2264 \u03c3 \u2264 m, then 0 \u2264 k \u2264 m \u2212 \u03c3 and I is a maximal (\u03c3 + k)-occurrent itemset in D. Moreover, U is a maximal (\u03c3 + m)-occurrent itemset in WD.", "formula_coordinates": [7.0, 53.8, 263.73, 239.09, 147.04]}, {"formula_id": "formula_20", "formula_text": "|M\u03c3+m(WD)| = m\u2212\u03c3 X k=0 |C \u03c3+k (D)| \u2022 m k ! Theorem 17 Let D be a database of transactions, |D| = m.", "formula_coordinates": [7.0, 53.8, 515.19, 238.91, 59.86]}, {"formula_id": "formula_21", "formula_text": "0 B B B B B B B B B @ 1`m 1\u00b4`m 2\u00b4\u2022 \u2022 \u2022`m m\u221210 1`m 1\u00b4\u2022 \u2022 \u2022`m m\u221220 0 1 \u2022 \u2022 \u2022`m m\u22123. . . 0 0 0 \u2022 \u2022 \u2022 1 1 C C C C C C C C C A \u2022 0 B B B B B B B B B @ C1 C2 C3 . . . Cm 1 C C C C C C C C C A = 0 B B B B B B B B B @ M1 M2 M3 . . . Mm 1 C C C C C C C C C A Clearly,", "formula_coordinates": [7.0, 316.81, 116.31, 211.34, 98.38]}], "doi": ""}