{"title": "GPolS: A Contextual Graph-Based Language Model for Analyzing Parliamentary Debates and Political Cohesion", "authors": "Ramit Sawhney; Shivam Agarwal; Peter Aldous; Richard Drax", "pub_date": "", "abstract": "Parliamentary debates present a valuable language resource for analyzing comprehensive options in electing representatives under a functional, free society. However, the esoteric nature of political speech coupled with non-linguistic aspects such as political cohesion between party members presents a complex and underexplored task of contextual parliamentary debate analysis. We introduce GPolS, a neural model for political speech stance analysis jointly exploiting both semantic language representations and relations between debate transcripts, motions, and political party members. Through experiments on real-world English data, we provide a use case of GPolS as a tool for political speech analysis and polarity prediction.", "sections": [{"heading": "Introduction", "text": "Politics is broadly defined as the set of activities associated with the governance of a country or a region. It involves various aspects that influence critical decisions having national importance. One such aspect is the conduct of parliamentary debates between political parties having ruling and opposition power. These debates discuss matters affecting the future development of a nation, such as economic and societal growth, policy reforms, and budget revisions. Records of such debates act as a valuable language resource as they provide a wealth of information regarding viewpoints of political representatives over critical societal factors (Abercrombie and Batista-Navarro, 2020b), and also for assessing political candidates and basing voting decisions (Utych, 2019).\nAnalyzing sentiment in such political discourse is propelled by the developments in fields like behavioral economics that bring the psychological aspects of parliamentary decision-making to the forefront (Rheault, 2016). However, under Parliament's Rules of Behavior, 1 the language used in political debates is complex, laden with domain-specific procedural jargon used in the political realm, and obscure (Abercrombie and Batista-Navarro, 2018a). This esoteric and tedious nature of political debates makes their analysis complex, forming a barrier to ordinary citizen's insights into political stances and wide-ranging consequences they entail (Edelman, 1985).\nThe good news is that natural language processing (NLP) shows promise for analyzing voluminous political debates and breaking the understanding barrier towards political ideology to help make informed voting decisions (Davoodi et al., 2020;Eidelman et al., 2018). However, conventional language models (Hasan and Ng, 2013) may not generalize well on understanding the obscure linguistic styles of political debates. This complexity arises due to the lack of political context and procedural parliamentary jargon in generic corpora over which traditional text representation models are trained (Pennington et al., 2014;Bojanowski et al., 2017). For instance, in the political context, Red State is a state that primarily votes for Republicans, whereas a Blue State votes primarily for Democrats. Leveraging the success of unsupervised pre-training in NLP (Devlin et al., 2019;Liu et al., 2019), fine-tuning pre-trained models over the voluminous debate transcripts can lead to drastic advances in analyzing political debates.", "publication_ref": ["b3", "b64", "b56", "b0", "b25", "b21", "b26", "b32", "b52", "b11", "b22", "b42"], "figure_ref": [], "table_ref": []}, {"heading": "U 3", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "DEFENCE REFORMS", "text": "I beg to move, this House notes concerns about the Government's defence reforms in relation to whether its proposals for the reserve forces will deliver anticipated cost saving savings or defence capability...", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Motion Context", "text": "\u2026 I am a former soldier, and holding the land is where we gained information and intelligence\u2026 Those crimes would not be committed if there were a police presence on the ground\u2026I believe the overseas aid budget will balloon to some \u00a320 billion in 2020 \u2026 I have absolutely no objection to money going to overseas aid, but I object \u2026 charity starts at home\u2026 I urge the Government and any right-minded person to consider the target.  The challenging aspect is that analyzing political debates involves multiple contextual elements beyond language, such as political party affiliations and topics of the debates. Consider Figure 1, where we present four speech transcripts over two different motions, from the UK House of Commons. The first two transcripts, T 1 and T 2 over the \"Police Grant Report\" motion, are from members U 1 and U 2 of the Conservative Party, who express similar viewpoints and support the motion under debate. Such a intra-party context and similarity is often indicative and an example of political cohesion within parties (Hug, 2009;Lai et al., 2019). Next, among transcripts T 2 and T 3 , we observe a remarkable similarity between two different transcripts from the same speaker U 2 , debating over two different motions. Such a speaker-self context is characteristic of the linguistic styles of individual speakers that reflect across their speeches (WIEBE, 1994b;Cottam et al., 2015). Lastly, transcripts T 3 and T 4 highlight motion context, the similarity of speeches based on the motion under debate. The psychological impact of the topic of motion in debate and the stances adopted by peer-speakers, jointly tend to influence the stance a speaker likely has towards the motion. The underlying connections between the elements of a debate-such as participants, motions, and speeches; play an essential role in the outcome of the debate. Identifying such similarities in the parliamentary ecosystem unfolds the possibility to learn latent patterns among speakers, the speeches they deliver, their political affiliations, and how they target various motions.\nBuilding on the interdependent nature of participating elements in parliamentary debates, we propose GPolS: Graph Political Sentiment analyzer: a neural framework for speech-level stance analysis of members of the parliament (MPs). First, we fine-tune BERT (Devlin et al., 2019), on a large corpus of debate speeches of the UK Parliament's House of Commons. Through fine-tuning BERT, we extract semantically meaningful representations of political speeches and motions. We empirically validate the presence of similarities between transcripts across debates, motions, and speakers (Sec. 3.2). At the heart of GPolS, we model these similarities through relations between elements in a parliamentary setting as a graph. GPolS, through the use of a Graph Attention Network (GAT) (Sec. 3.3) aggregates features across the contextual relations between motions, transcripts, and speakers to hierarchically learn similarities across transcripts through semantic (token-level attention) and graph based (graph attention) representations. Through experiments (Sec. 4) on more than 33,000 transcripts from the UK House of Commons, we demonstrate GPolS's ability for stance analysis in parliamentary debates (Sec. 5). Lastly, we visualize GPolS's graph attention mechanism (Sec. 5.3) and token-level attention (Sec. 5.4) thus providing a use case for GPolS as a tool for parliamentary debate analysis.", "publication_ref": ["b35", "b38", "b69", "b20", "b22"], "figure_ref": ["fig_0"], "table_ref": []}, {"heading": "Related Work", "text": "Politics and Linguistics Analyzing political data acts as a knowledge source that provides insights into cohesion within political parties, stances of MPs towards critical motions for both the general public, and across domains including humanities, and computational linguistics (Vilares and He, 2017;Sim et al., 2013;Slembrouck, 1992). A developing body of research at the intersection of Politics and Linguistics spans agreement detection (Menini and Tonelli, 2016;M. and M., 2018;Duthie and Budzynska, 2018), emotion analysis (Rheault, 2016;Dzieciatko, 2019), topic-opinion analysis (Nguyen et al., 2015;Abercrombie and Batista-Navarro, 2018b) and, debate stance classification (Proksch et al., 2019). Existing work focuses on these tasks through legislative speeches from the US Congress (Chen et al., 2017), the UK Parliament (Bhavan et al., 2019), and the EU Parliament (Glava\u0161 et al., 2017;Frid-Nielsen, 2018) and through social media such as Twitter (Trilling, 2014;Boutyline and Willer, 2017). Recently, some tools for extracting and annotating political data have also been developed (Haddadan et al., 2019).\nPolitical Stance and Sentiment Analysis NLP has seen a growth in analyzing and mining opinions from political discourse (Cabrio and Villata, 2018;Rheault, 2016;Fi\u0161er et al., 2020). Word embeddings have shown remarkable progress in analyzing political debates and text (Onyimadu et al., 2013;Abercrombie and Batista-Navarro, 2018a;Rheault and Cochrane, 2020). (Rudkowsky et al., 2018) conducted a textual analysis of Austrian parliamentary speeches, demonstrating the effectiveness of using word embeddings instead of conventional approaches such as Bag-of-Words. More recent approaches (Abercrombie et al., 2019;Abercrombie and Batista-Navarro, 2020a) show the ability of pre-trained transformers such as BERT in capturing domain-specific jargon better for feature extraction from debates. A promising new direction at the intersection of Politics and NLP is the inclusion of context such as political party affiliations and engagement in social circles. (Boutyline and Willer, 2017;Lai et al., 2019) study the linguistic patterns of politically engaged users on Twitter by inferring a user's political inclination through the politicians and policy nonprofits they follow. They show that more conservative users exhibit a higher level of homophily and often stick to their political stances even when challenged. Recent works (Bhavan et al., 2020;Bhavan et al., 2019) have shown the presence of herd mentality in political stances through graph embeddings by identifying the linguistic similarity between members of the same political party over a set of 1,251 debates. (Davoodi et al., 2020) study the interactions between the content of a proposed bill and the legislative context in which it is presented. (Al Khatib et al., 2020) models debater characteristics to predict persuasiveness. GPolS builds on and differs from existing work across three pivots: 1) we analyze a substantially larger (34,461) set of parliamentary debates for a more meaningful analysis, 2) we analyze and empirically demonstrate political cohesion, and correlations between MP speeches for political stance analysis, and 3) Joint language and contextual modeling of parliamentary debates through token-level and graph attention.", "publication_ref": ["b67", "b59", "b60", "b46", "b44", "b23", "b56", "b24", "b48", "b1", "b54", "b17", "b8", "b30", "b28", "b63", "b13", "b31", "b15", "b56", "b50", "b0", "b55", "b58", "b4", "b2", "b13", "b38", "b9", "b8", "b21"], "figure_ref": [], "table_ref": []}, {"heading": "Methodology", "text": "We first define the problem of analyzing parliamentary debates, and then present GPolS. Figure 2 presents an overview of GPolS. We fine-tune and use BERT to encode parliamentary debates and motions. We then motivate GPolS by analyzing the similarity across debate transcripts based on three types of context and model them through a heterogeneous graph. Lastly, we detail the Graph Attention Network (GAT) for propagating contextual information across debate transcripts, speakers and motions for classification.", "publication_ref": [], "figure_ref": ["fig_1"], "table_ref": []}, {"heading": "Problem Definition", "text": "We denote a debate transcript as t i \u2208 T = {t 1 , t 2 , . . . , t N } corresponding to the speech made by a MP (speaker) s j \u2208 S = {s 1 , s 2 , . . . , s Z } on one specific motion m k \u2208 M = {m 1 , m 2 , . . . , m Q }. Each speaker s i is affiliated to only one political party p i \u2208 P = {p 1 , p 2 , . . . , p R }. On a debate motion m, given a transcript t spoken by a MP s with a political party affiliation p, the task is to classify the stance Y \u2208 {'Aye', 'No'} of the MP s on the motion m based on the transcript t. 'Aye' and 'No' represent a positive and negative stance on the motion, respectively. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Encoding Parliamentary Debates and Motions through BERT", "text": "A debate comprises Motions, i.e., expressions over policy positions taken by the government, Members of Parliament (MP), etc. The motion is followed by complementary or counter-responses from other MPs, often termed as Utterances, which collectively comprise a Speech. We adopt a transformer language model: Bidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2019) to encode debate transcripts t and motion descriptions m. We fine-tune the BERT-Base-Cased (Wolf et al., 2019) 2 model architecture. Often, fine-tuning BERT on task-specific corpus yields performance gains on downstream NLP tasks (Alsentzer et al., 2019;Sun et al., 2019). The domain-specific nature of political speeches and complex political jargon motivate us to fine-tune the pre-trained BERT language model.\nWe fine-tune BERT on the ParlVote dataset (Abercrombie and Batista-Navarro, 2020a), a corpus of debates from the UK Parliament's House of Commons comprising of 33,461 transcripts of debate speeches from May 7th, 1997 to November 5th, 2019. 3 Following (Abercrombie and Batista-Navarro, 2020a), we only consider the first 512 tokens of speeches in ParlVote (18,253 speeches have less than 512 tokens) 4 . All motions are less than 512 tokens, and describe the topic for a given debate. For each transcript t \u2208 T and, each motion m \u2208 M , we obtain feature vectors h t = BERT(t) and h m = BERT(m) \u2208 R F . The feature vector is a one-dimensional vector of size F = 768 obtained the output of the [CLS] token from the final BERT layer. The pre-processing, training, and hyperparameter tuning are detailed in Section 4.", "publication_ref": ["b22", "b6", "b62"], "figure_ref": [], "table_ref": []}, {"heading": "GPolS: Graph Political Stance analyzer: Context Modeling and Graph Creation", "text": "Decision-makers are subtly influenced by the environment around them (Bode et al., 2014). We identify three major types of contexts in parliamentary debates-intra-party context, speaker-self context and motion context. The first, Intra-Party Context, captures the influence of the same political affiliations and fellow party members over the speeches of a speaker. During debates, some speakers tend to express their raw individual opinions, while some may exhibit homophily: the likeliness of associated individuals to adopt similar viewpoints (Boucek, 2002). Speaker-Self Context captures the unique linguistic style of a speaker based on the similarity between the speeches they deliver (Johnstone, 2009). Lastly, we also present a Motion Context, that captures the relationship between a speech and the motion under debate. Motivated by (Chen et al., 2019a) we use heterogeneous graphs to model such contextual information.\nHypothesising the presence of contextual information in parliamentary debates We perform an experiment to examine the similarity between debate transcripts that are related based on their motion, speaker, and speaker affiliation. For this experiment, we compute the cosine similarity between the finetuned BERT embeddings of each of the debate transcripts in ParlVote. We then compare the distributions   of cosine similarities between transcript embeddings (BERT) from the same speaker, and those from different speakers. Similarly, we compare cosine similarity distributions across transcripts spoken by members of the same party, and across different parties, as well as across the same motion, and different motions. We present the distribution in Figure 3, and observe that transcripts related to each other (based on speaker, transcript and motion) are significantly (p < 0.005) more similar than that from different origins under the Wilcoxon signed-rank test (Woolson, 2007). Based on these empirical similarities between debates, we model these contexts in the form of a heterogeneous graph, which we describe next. \u2022 Speaker-self context captures the relationship between a speaker and the transcript of their speech in a given debate. Each speech is personalized and reflects the mentality of a speaker across different speeches, motions and times (Wiebe, 1994a;Layman et al., 2006). Contrastingly, self-speaker context can also capture the domain expertise of the speakers. Speaker-self context captures the similarity between speeches by the same speaker. It is formally represented as a Speaker-Transcript edge E st between a transcript t and the MP s whose speech that transcript corresponds to.", "publication_ref": ["b10", "b12", "b36", "b18", "b71", "b68", "b39"], "figure_ref": ["fig_2"], "table_ref": []}, {"heading": "Graph Creation for Context Modeling", "text": "\u2022 Intra-party context models the relationship between a MP and the party they belong to. We build on the hypothesis that speakers are influenced by other party members, and there exists a partisan mentality like political cohesion within parties. (Lai et al., 2019;Owens, 2003;Chartash et al., 2018). Formally, intra-party context is represented by a Speaker-Speaker edge E ss between two MPs (speakers) s i , s j \u2208 S if both s i and s j are affiliated to the same political party p \u2208 P .\n\u2022 Motion level context encodes the relation between a transcript and a motion. In debates, a speech is based on the current motion of discussion. Formally, motion context is represented as a Transcript-Motion edge E tm between a transcript t and a motion m corresponding to that debate transcript.\nWe summarize the statistics of the created graph G in Table 1. We now describe the graph attention network for context propagation across nodes and the optimization for political stance analysis.", "publication_ref": ["b38", "b51", "b16"], "figure_ref": [], "table_ref": ["tab_2"]}, {"heading": "Graph Attention Network: Semi-Supervised Node Classification for Stance Prediction", "text": "We treat stance prediction ('Aye' or 'No') as a node classification problem. As labels are available for a subset of nodes in our graph (i.e., speech nodes (transcripts)), we frame the node classification problem in a semi-supervised learning setting, allowing the model to distribute gradient information from the supervised loss on the labeled transcript nodes. The inclusion of unlabeled motion and speaker nodes allow us to not only capture the structural traits of relations between similar transcripts based on contextual relations but also the contextual text representation of each motion. As each context has a different degree of influence on a speaker's speech, it is important that the graph encoding suitably weighs more relevant relations between transcripts, speakers and motions. To this end, we use GATs, that are graph neural networks with node level attention popularly used for node classification (Veli\u010dkovi\u0107 et al., 2017). We first describe a single graph attention layer (Veli\u010dkovi\u0107 et al., 2017) which is used throughout the GAT component. The input to this layer is a set of node features h = {x 1 , x 2 , . . . , x |V | }, x i \u2208 R F where, F is the number of features for each node. For each debate transcript t, we set the node feature as the embedding extracted h t from the text transcript using BERT. Similarly, for each motion m, the node feature is set as h m . As there is no text information available for speakers s \u2208 S, we initialize their feature vectors to zero embeddings. 5 The node features are transformed to context dependent features, h = [q 1 , q 2 , . . . q |V | ]; q i \u2208 R F based on the influence by its neighbors during training. Following (Veli\u010dkovi\u0107 et al., 2017) we first apply a shared linear transform parameterized by W \u2208 R F \u00d7F to all the nodes. Then, we apply a shared self-attention mechanism to each node i in its neighborhood N i . For each node j \u2208 N i , we compute normalized attention coefficients \u03b1 ij which shows the importance of context between nodes i and j. Formally, \u03b1 ij is given as:\n\u03b1 ij = exp (LeakyReLU(a T w [W x i \u2295 W x j ])) k\u2208N i exp (LeakyReLU(a T w [W x i \u2295 W x k ]))(1)\nwhere, . T , \u2295 represent transpose and concatenation, respectively. We use LeakyReLU as the activation function throughout our framework to mitigate vanishing gradients (Maas et al., 2013). Following (Veli\u010dkovi\u0107 et al., 2017) a w \u2208 R 2F is the parameter matrix of a single layer layer feed forward neural network. The attention coefficients are used to weigh and aggregate contextual information from neighboring nodes. Following (Veli\u010dkovi\u0107 et al., 2017) we use multi-head attention to stabilize training (Vaswani et al., 2017). Formally, U independent executors apply the attention mechanism. Their output features are concatenated to yield:\nq i = U k=1 LeakyReLU \uf8eb \uf8ed j\u2208N i \u03b1 k ij W k x j \uf8f6 \uf8f8 (2)\nwhere \u03b1 k ij and W k denote the attention coefficients and linear transform weight matrix computed by the k th attention head. We apply a 2-layer GAT model, the first layer consists of U = 8 attention heads calculating F = 8 features per node. The second layer is used for classification with one attention head and F = 2 (\"Aye\" or \"no\") followed by a softmax activation (Nwankpa et al., 2018).\ny i = Softmax \uf8eb \uf8ed j\u2208N i \u03b2 ij W 2 8 k=1 LeakyReLU \uf8eb \uf8ed j\u2208N i \u03b1 k ij W k x j \uf8f6 \uf8f8 \uf8f6 \uf8f8 (3)\nwhere, \u03b2 ij and W 2 \u2208 R 2\u00d764 denote the attention coefficients and linear transform weight matrix computed by the second attention layer. The entire framework is trained in an end-to-end fashion to minimise the cross entropy loss of labeled nodes using the Adam optimizer (Kingma and Ba, 2014), as:\nL cse = \u2212 |V | i=1 Y i ln(y i ) + (1 \u2212 Y i ) ln(1 \u2212 y i ) (4)\nwhere, Y i is the true stance and, y i is the estimated probability of \"Aye\" or \"No\". During training, we only have labeled transcript nodes for those transcripts in the graph that are part of the train set. Speaker and motion nodes are masked so that losses are propagated only for the labeled nodes.\n4 Experimental setup", "publication_ref": ["b66", "b66", "b66", "b45", "b66", "b66", "b65", "b49"], "figure_ref": [], "table_ref": []}, {"heading": "Dataset and Preprocessing", "text": "We evaluate GPolS on the ParlVote dataset consisting of 33, 461 debate transcripts. On an average, a speech in ParlVote has 760.2 \u00b1 901.3 tokens (max 20, 730). Following (Abercrombie and Batista-Navarro, 2020a), we remove non-speech elements, tokenize motions and transcripts and, preserve the texts' original casing. The speaker names and party affiliations are obtained using TheyWorkForYou. 6 The dataset is fairly balanced with 53.57/46.43% Aye/No labels. The transcripts are labeled based on a speaker's vote to their speech, with votes for 'Aye' and 'no' representing positive and negative sentiment. Following (Abercrombie and Batista-Navarro, 2020a), the dataset is divided into 5 subsets for experimenting with various corpus and debate transcript sizes as: (1) Large is the complete pre-processed subset.\n(2) Medium-any is a random sample with half (18,253) of the total instances. ( 3) Medium (\u2264 512) consists of all speeches and motions in medium-any with 512 tokens or fewer. (4) Small-any is a random sample of the same size as the corpus used by (Abercrombie and Batista-Navarro, 2018a)-1,251 examples. ( 5) Small (\u2264 512) contains speeches+motions in small-any with 512 tokens or fewer.", "publication_ref": ["b2", "b0"], "figure_ref": [], "table_ref": []}, {"heading": "Training setup", "text": "All experiments were performed on an NVIDIA Tesla P100 GPU. For fine-tuning BERT, we explore the following hyperparameters: learning rates \u2208 {2 \u2022 10 \u22125 , 5 \u2022 10 \u22125 , 2 \u2022 10 \u22124 }, batch sizes \u2208 {8, 16, 32}, epochs \u2208 {3, 4, 5, 6, 7, 8, 9, 10}. The optimal hyperparameters for BERT were selected based on validation accuracy, as: learning rate = 5e \u2212 5, batch size of 8, with the AdamW (Loshchilov and Hutter, 2019) optimizer, for 7 epochs on the ParlVote dataset. We use the default dropout (Srivastava et al., 2014) rate (0.1) on self attention layers but do not use additional dropout at the top linear layer.\nTraining GPolS: We use grid search for hyperaparamter selection for all models over all variants of the dataset individually, and select optimal values based on validation accuracy. All intermediate GAT layers are used with 8 attention heads and an output space of 8 with a dropout=0.6. The Adam optimiser is set with default values \u03b2 1 = 0.9, \u03b2 2 = 0.999, = 1e\u22128, weight-decay = 5e\u22124 and an initial learning rate of 0.001. We use a exponential learning rate scheduler with a decay rate of 0.67 (Li and Arora, 2019) and early stopping with a patience of 10 epochs. Following (Abercrombie and Batista-Navarro, 2020a), we evaluated all models using the same randomly selected 80/10/10 training-validation-testing split of the data for each subsection of the corpus, and report mean results over 10 different runs.", "publication_ref": ["b43", "b61", "b40"], "figure_ref": [], "table_ref": []}, {"heading": "Baselines", "text": "Following Abercrombie (2020a), we compare GPolS with baselines on classification accuracy. 7\nMajority class: The majority class in the training set as the predictions for test set. This baseline does not use any textual or contextual features. Support Vector Machines (SVM): A bag-of-words (BoW) model that uses unigram features as input with term frequency-inverse document frequency feature selection (TF-IDF). We use SVM with a linear kernel, L2 regularisation and optimise squared hinge loss (Gentile and Warmuth, 1999).\nMulti-layer Perceptron (MLP): A BoW model that utilises only unigram textual features from transcripts as input with TF-IDF selection. We use a MLP with 1 hidden layer containing 100 units followed by ReLU activation. We use L-BFGS optimisation (Liu and Nocedal, 1989) for training 200 epochs BERT-MLP: BERT (Devlin et al., 2019) embeddings are used on the ParlVote dataset followed by a MLP with the same settings as described above. It is a text only model with no additional context. Deepwalk: Concatenates speaker-speaker graph (speaker-self context) embeddings with a set of language features followed by a MLP (same as above). TF-IDF based BoW features (upto trigrams) were concatenated with subjectivity scores for each speech computed using the Harvard General Inquirer lex- 0.53 \u00b1 1e \u2212 3 0.53 \u00b1 3e \u2212 3 0.50 \u00b1 2e \u2212 3 0.52 \u00b1 5e \u2212 3 0.50 \u00b1 4e \u2212 3 SVM 0.51 \u00b1 4e \u2212 3 0.57 \u00b1 6e \u2212 4 0.68 \u00b1 1e \u2212 3 0.63 \u00b1 3e \u2212 3 0.66 \u00b1 2e \u2212 3 MLP 0.50 \u00b1 2e \u2212 3 0.56 \u00b1 1e \u2212 3 0.63 \u00b1 4e \u2212 3 0.63 \u00b1 8e \u2212 4 0.65 \u00b1 3e \u2212 3 BERT + MLP 0.64 \u00b1 1e \u2212 3 0.53 \u00b1 2e \u2212 3 0.61 \u00b1 9e \u2212 4 0.61 \u00b1 4e \u2212 3 0.67 \u00b1 7e \u2212 3 Deepwalk 0.73 \u00b1 4e \u2212 3 0.73 \u00b1 3e \u2212 3 0.72 \u00b1 9e \u2212 4 0.72 \u00b1 1e \u2212 3 0.72 \u00b1 8e \u2212 4 GPolS 0.80 \u00b1 5e \u2212 4 0.80 \u00b1 4e \u2212 4 0.77 \u00b1 6e \u2212 4 0.77 \u00b1 5e \u2212 4 0.76 \u00b1 3e \u2212 4  icon (Roberts, 1997). Deepwalk (Perozzi et al., 2014) was used to obtain speaker embeddings from a speaker graph based on party affiliation and concatenated with the text features from transcripts. 8\n5 Results and Analysis", "publication_ref": ["b29", "b41", "b22", "b57", "b53"], "figure_ref": [], "table_ref": []}, {"heading": "Performance Comparison with Baselines", "text": "We compare the performance of GPolS with baseline methods in terms of classification accuracy over 10 different runs in Table 2. We note that BERT+MLP significantly (p < 0.05) outperforms Majority class and BoW (TF-IDF) based approaches: SVM and MLP. We postulate this to fine-tuning BERT to obtain rich embeddings that better capture the context within each debate transcript. We observe that graphbased models (Deepwalk, GPolS) outperform text-only models (SVM, MLP, BERT-MLP), reiterating the presence of similarity between related transcripts. GPolS outperforms all baselines significantly (p < 0.05) under the Wilcoxon signed-rank test, by a large margin greater than 6.5%. We attribute this improvement to two aspects: 1) Fine-tuning BERT for domain-specific embeddings, and 2) Graph attention mechanism in GPolS. First, BERT is able to better model political jargon in debate transcripts post fine-tuning. Second, GPolS enhances text features through a context propagation mechanism via graph attention by modeling speaker-self, intra-party, and motion level context. The additional context that GPolS adds by learning the latent patterns between related transcripts, sets GPolS apart from all the baselines. We further analyze these in the following subsections, first through an ablation study, and then by analyzing BERT's token-level attention on debates, and GPolS's graph attention mechanism.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_4"]}, {"heading": "Ablation Study: Quantifying the Impact of Context", "text": "We perform an ablation study over the different kinds of context that GPolS models, in Table 3. All performance differences are statistically significant (p < 0.05) under Wilcoxon's signed rank test. We remove the contexts one by one and find that the speaker-self context leads to an improvement owing to the similarity in transcripts by the same speaker. We also note that the accuracy drop on removing motion context is small but statistically significant (p < 0.05). The small performance change also shows that while there is a content-based similarity between transcripts of the same motion, such context may not be as relevant from the perspective of stance analysis. We also note that speaker-self and intra-party context are slightly more important as compared to motion-context. This is potentially due to existence of larger political cohesion and partisan mentality in political parties. We analyze this next.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_5"]}, {"heading": "Analyzing Political Cohesion and Partisan Identities: Visualizing GPolS's Graph Attention", "text": "Multiple studies have highlighted the presence of political cohesion, and a partisan-like herd mentality in UK-based political parties (Huddy, 2003;Bowler et al., 1999). To analyze this political cohesion, and GPolS's intra-party context, we first calculate the attention scores amongst each member in two wellknown UK political parties, as shown in Figure . 4. A higher attention score between a speaker and their neighbors indicates a higher degree of peer influence on the speaker and a similarity in their political stances. We first analyze the Conservative party, one of the oldest and largest parties in the UK. We observe in Figure 4 (left) that high attention scores exist between speakers and their peers, indicating a high degree of political cohesion between MPs. High political cohesion in the conservative party is further consolidated by the age and large size of the party, as goals and decisions are much more common between members of such large and old parties (Hayton, 2012). On the other end of the spectrum, we analyze the Liberal Democrats, a relatively newer and smaller party as compared to the Conservative party, in Figure 4 (right). We note high attention scores along the diagonal, indicating a large selfdependency of speakers or a lower degree of political cohesion. Through these examples, we show that GPolS effectively learns and weights such latent patterns through context propagation over the speakerspeaker and speaker-transcript relations. The attention mechanism also provides insights into political cohesion across large volumes of transcripts to aid interpretability in fields such as Digital Humanities.", "publication_ref": ["b34", "b14", "b33"], "figure_ref": [], "table_ref": []}, {"heading": "Token-level Attention Visualisation using BERT", "text": "As a concluding use-case, we analyze token-level attention over political debate transcripts. Our goal with this attention analysis is not to study causation or an explanation of GPolS's predictions, but rather analyzing the impacvt of fine-tuning BERT on ParlVote. In Figure 5, we present two snippets of realworld debates over the motion: 'Post Office Reinvention Program'. In T 1 , BERT allots higher attention to terms relevant to motion, such as post office account, cash, liquidity, etc. Similarly in T 2 , BERT allots more attention to the context of senior citizens being very anxious about the new arrangements. BERT also allots high attention to words indicative of stance adoption over motions, such as the arrangement being very disappointing in T 1 . We present two such heads and analyse their corresponding self-attention heat-maps over an input speech snippet from T 1 . Higher attention scores link the 'arrangement' as being 'very disappointing'. Notably, the term surgeries in T 1 and T 2 , get assigned a high attention weight. In the political domain, surgeries are held by MPs where they meet people and discuss matters of concern.", "publication_ref": [], "figure_ref": ["fig_4"], "table_ref": []}, {"heading": "Conclusion", "text": "We propose GPolS, that enhances linguistic analysis of debates with context for political stance detection. Fine-tuning BERT, we encode debates and motions from the UK Parliament's House of Commons to capture semantics in political jargon. We show GPolS practical applicability and interpretability in parliamentary debate settings. Through this work, we hope to complement digital humanities, media, social scientists, political linguistics and any members of the public who wish to scrutinize the activities of their elected representatives. GPolS makes a step towards facilitating the understanding of MP's opinions through for analyzing latent correlations and sentiments in voluminous parliamentary debates.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgement", "text": "Rajiv Ratn Shah is partly supported by the Infosys Center for AI and the Center of Design and New Media at IIIT Delhi.", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "aye' or 'no'? speech-level sentiment analysis of hansard UK parliamentary debate transcripts", "journal": "", "year": "2018", "authors": "Gavin Abercrombie; Riza Batista-Navarro"}, {"ref_id": "b1", "title": "Identifying opinion-topics and polarity of parliamentary debate motions", "journal": "", "year": "2018-10", "authors": "Gavin Abercrombie; Riza Theresa Batista-Navarro"}, {"ref_id": "b2", "title": "ParlVote: A corpus for sentiment analysis of political debates", "journal": "European Language Resources Association", "year": "2020-05", "authors": "Gavin Abercrombie; Riza Batista-Navarro"}, {"ref_id": "b3", "title": "Sentiment and position-taking analysis of parliamentary debates: a systematic literature review", "journal": "Journal of Computational Social Science", "year": "2020-04", "authors": "Gavin Abercrombie; Riza Batista-Navarro"}, {"ref_id": "b4", "title": "Policy preference detection in parliamentary debate motions", "journal": "Association for Computational Linguistics", "year": "2019-11", "authors": "Gavin Abercrombie; Federico Nanni; Riza Batista-Navarro; Simone Paolo Ponzetto"}, {"ref_id": "b5", "title": "Exploiting personal characteristics of debaters for predicting persuasiveness", "journal": "Association for Computational Linguistics", "year": "2020-07", "authors": "Al Khalid; Michael Khatib; Shahbaz V\u00f6lske; Nikolay Syed; Benno Kolyada;  Stein"}, {"ref_id": "b6", "title": "", "journal": "", "year": "2019", "authors": "Emily Alsentzer; John R Murphy; Willie Boag; Wei-Hung Weng; Di Jin; Tristan Naumann; Matthew B A Mcdermott"}, {"ref_id": "b7", "title": "Longformer: The long-document transformer", "journal": "", "year": "2020", "authors": "Iz Beltagy; Matthew E Peters; Arman Cohan"}, {"ref_id": "b8", "title": "Investigating political herd mentality: A community sentiment based approach", "journal": "Association for Computational Linguistics", "year": "2019-07", "authors": "Anjali Bhavan; Rohan Mishra; Prakhar Pradyumna; Ramit Sinha; Rajiv Ratn Sawhney;  Shah"}, {"ref_id": "b9", "title": "Analysis of parliamentary debate transcripts using community-based graphical approaches (student abstract)", "journal": "AAAI Press", "year": "2020-02-07", "authors": "Anjali Bhavan; Mohit Sharma; Ramit Sawhney; Rajiv Ratn Shah"}, {"ref_id": "b10", "title": "Demystifying \"free will\": The role of contextual information and evidence accumulation for predictive brain activity", "journal": "Neuroscience & Biobehavioral Reviews", "year": "2014-11", "authors": "Stefan Bode; Carsten Murawski; Chun Siong Soon; Philipp Bode; Jutta Stahl; Philip L Smith"}, {"ref_id": "b11", "title": "Enriching word vectors with subword information", "journal": "Transactions of the Association for Computational Linguistics", "year": "2017", "authors": "Piotr Bojanowski; Edouard Grave; Armand Joulin; Tomas Mikolov"}, {"ref_id": "b12", "title": "The structure and dynamics of intra-party politics in europe", "journal": "Perspectives on European Politics and Society", "year": "2002", "authors": "Francoise Boucek"}, {"ref_id": "b13", "title": "The social structure of political echo chambers: Variation in ideological homophily in online networks", "journal": "Political Psychology", "year": "2017", "authors": "Andrei Boutyline; Robb Willer"}, {"ref_id": "b14", "title": "Party discipline and parliamentary government", "journal": "The Ohio State University Press", "year": "1999", "authors": "Shaun Bowler; M David; Richard S Farrell;  Katz"}, {"ref_id": "b15", "title": "Five years of argument mining: a data-driven analysis", "journal": "", "year": "2018", "authors": "Elena Cabrio; Serena Villata"}, {"ref_id": "b16", "title": "When the team's jersey is what matters", "journal": "Party Politics", "year": "2018-08", "authors": "David Chartash; J Nicholas; Markus Caruana; Laura B Dickinson;  Stephenson"}, {"ref_id": "b17", "title": "Opinion-aware knowledge graph for political ideology detection", "journal": "", "year": "2017", "authors": "Wei Chen; Xiao Zhang; Tengjiao Wang; Bishan Yang; Yi Li"}, {"ref_id": "b18", "title": "Semi-supervised user profiling with heterogeneous graph attention networks", "journal": "", "year": "2019", "authors": "Weijian Chen; Yulong Gu; Zhaochun Ren; Xiangnan He; Hongtao Xie; Tong Guo; Dawei Yin; Yongdong Zhang"}, {"ref_id": "b19", "title": "Semi-supervised user profiling with heterogeneous graph attention networks", "journal": "In IJCAI", "year": "2019", "authors": "Weijian Chen; Yulong Gu; Zhaochun Ren; Xiangnan He; Hongtao Xie; Tong Guo; Dawei Yin; Yongdong Zhang"}, {"ref_id": "b20", "title": "Introduction to political psychology", "journal": "", "year": "2015", "authors": "Elena Martha L Cottam; Thomas Mastors; Beth Preston;  Dietz"}, {"ref_id": "b21", "title": "Understanding the language of political agreement and disagreement in legislative texts", "journal": "Association for Computational Linguistics", "year": "2020-07", "authors": "Maryam Davoodi; Eric Waltenburg; Dan Goldwasser"}, {"ref_id": "b22", "title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "journal": "Association for Computational Linguistics", "year": "2019-06", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"ref_id": "b23", "title": "A deep modular rnn approach for ethos mining", "journal": "", "year": "2018", "authors": "Rory Duthie; Katarzyna Budzynska"}, {"ref_id": "b24", "title": "Application of text analytics to analyze emotions in the speeches", "journal": "Springer International Publishing", "year": "2019", "authors": "Mariusz Dzieciatko"}, {"ref_id": "b25", "title": "Political language and political reality", "journal": "PS", "year": "1985", "authors": "Murray Edelman"}, {"ref_id": "b26", "title": "How predictable is your state? leveraging lexical and contextual information for predicting legislative floor action at the state level", "journal": "Association for Computational Linguistics", "year": "2018-08", "authors": "Vladimir Eidelman; Anastassia Kornilova; Daniel Argyle"}, {"ref_id": "b27", "title": "2020. Proceedings of the Second ParlaCLARIN Workshop", "journal": "European Language Resources Association", "year": "", "authors": ""}, {"ref_id": "b28", "title": "Human rights or security? positions on asylum in european parliament speeches", "journal": "European Union Politics", "year": "2018", "authors": "Snorre Sylvester Frid-Nielsen"}, {"ref_id": "b29", "title": "Linear hinge loss and average margin", "journal": "MIT Press", "year": "1999", "authors": "Claudio Gentile; Manfred K Warmuth"}, {"ref_id": "b30", "title": "Unsupervised cross-lingual scaling of political texts", "journal": "Association for Computational Linguistics", "year": "2017-04", "authors": "Goran Glava\u0161; Federico Nanni; Simone Paolo Ponzetto"}, {"ref_id": "b31", "title": "Disputool -a tool for the argumentative analysis of political debates", "journal": "", "year": "2019", "authors": "Shohreh Haddadan; Elena Cabrio; Serena Villata"}, {"ref_id": "b32", "title": "Stance classification of ideological debates: Data, models, features, and constraints", "journal": "", "year": "2013", "authors": "Saidul Kazi; Vincent Hasan;  Ng"}, {"ref_id": "b33", "title": "Reconstructing Conservatism?: The Conservative party in opposition", "journal": "", "year": "1997", "authors": "Richard Hayton"}, {"ref_id": "b34", "title": "Group identity and political cohesion", "journal": "", "year": "2003", "authors": "Leonie Huddy"}, {"ref_id": "b35", "title": "Selection effects in roll call votes", "journal": "British Journal of Political Science", "year": "2009-10", "authors": "Simon Hug"}, {"ref_id": "b36", "title": "Stance, style, and the linguistic individual. Stance: sociolinguistic perspectives", "journal": "", "year": "2009", "authors": "Barbara Johnstone"}, {"ref_id": "b37", "title": "Adam: A method for stochastic optimization", "journal": "", "year": "2014", "authors": "P Diederik; Jimmy Kingma;  Ba"}, {"ref_id": "b38", "title": "Stance polarity in political debates: A diachronic perspective of network homophily and conversations on twitter", "journal": "Data & Knowledge Engineering", "year": "2019", "authors": "Mirko Lai; Marcella Tambuscio; Viviana Patti; Giancarlo Ruffo; Paolo Rosso"}, {"ref_id": "b39", "title": "PARTY POLARIZATION IN AMERICAN POLITICS: Characteristics, causes, and consequences", "journal": "", "year": "2006-06", "authors": "Geoffrey C Layman; Thomas M Carsey; Juliana Menasce Horowitz"}, {"ref_id": "b40", "title": "An exponential learning rate schedule for deep learning", "journal": "", "year": "2019", "authors": "Zhiyuan Li; Sanjeev Arora"}, {"ref_id": "b41", "title": "On the limited memory BFGS method for large scale optimization", "journal": "Mathematical Programming", "year": "1989-08", "authors": "C Dong; Jorge Liu;  Nocedal"}, {"ref_id": "b42", "title": "Roberta: A robustly optimized bert pretraining approach", "journal": "", "year": "2019", "authors": "Yinhan Liu; Myle Ott; Naman Goyal; Jingfei Du; Mandar Joshi; Danqi Chen; Omer Levy; Mike Lewis; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b43", "title": "Decoupled weight decay regularization", "journal": "", "year": "2019", "authors": "Ilya Loshchilov; Frank Hutter"}, {"ref_id": "b44", "title": "Detecting agreement and disagreement in political debates", "journal": "", "year": "2018", "authors": "M Ahmadalinezhad; M Makrehchi"}, {"ref_id": "b45", "title": "Rectifier nonlinearities improve neural network acoustic models", "journal": "", "year": "2013", "authors": "L Andrew;  Maas; Y Awni; Andrew Y Hannun;  Ng"}, {"ref_id": "b46", "title": "Agreement and disagreement: Comparison of points of view in the political domain", "journal": "", "year": "2016-12", "authors": "Stefano Menini; Sara Tonelli"}, {"ref_id": "b47", "title": "Abusive language detection with graph convolutional networks", "journal": "", "year": "2019", "authors": "Pushkar Mishra; Marco Del Tredici; Helen Yannakoudakis; Ekaterina Shutova"}, {"ref_id": "b48", "title": "Tea party in the house: A hierarchical ideal point topic model and its application to republican legislators in the 112th congress", "journal": "Association for Computational Linguistics", "year": "2015-07", "authors": " Viet-An; Jordan Nguyen; Philip Boyd-Graber; Kristina Resnik;  Miler"}, {"ref_id": "b49", "title": "Activation functions: Comparison of trends in practice and research for deep learning", "journal": "", "year": "2018", "authors": "Chigozie Nwankpa; Winifred Ijomah; Anthony Gachagan; Stephen Marshall"}, {"ref_id": "b50", "title": "Towards sentiment analysis on parliamentary debates in hansard", "journal": "Springer-Verlag", "year": "2013", "authors": "Obinna Onyimadu; Keiichi Nakata; Tony Wilson; David Macken; Kecheng Liu"}, {"ref_id": "b51", "title": "", "journal": "Cohesion. The Journal of Legislative Studies", "year": "2003-12", "authors": "John E Owens"}, {"ref_id": "b52", "title": "Glove: Global vectors for word representation", "journal": "", "year": "2014", "authors": "Jeffrey Pennington; Richard Socher; Christopher D Manning"}, {"ref_id": "b53", "title": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining -KDD '14", "journal": "", "year": "2014", "authors": "Bryan Perozzi; Rami Al-Rfou; Steven Skiena"}, {"ref_id": "b54", "title": "Multilingual sentiment analysis: A new approach to measuring conflict in legislative speeches", "journal": "Legislative Studies Quarterly", "year": "2019", "authors": "Sven-Oliver Proksch; Will Lowe; Jens W\u00e4ckerle; Stuart Soroka"}, {"ref_id": "b55", "title": "Word embeddings for the analysis of ideological placement in parliamentary corpora", "journal": "Political Analysis", "year": "2020", "authors": "Ludovic Rheault; Christopher Cochrane"}, {"ref_id": "b56", "title": "Expressions of anxiety in political texts", "journal": "Association for Computational Linguistics", "year": "2016-11", "authors": "Ludovic Rheault"}, {"ref_id": "b57", "title": "Text analysis for the social sciences : methods for drawing statistical inferences from texts and transcripts", "journal": "", "year": "1997", "authors": "W Carl;  Roberts"}, {"ref_id": "b58", "title": "More than bags of words: Sentiment analysis with word embeddings", "journal": "Communication Methods and Measures", "year": "2018", "authors": "Elena Rudkowsky; Martin Haselmayer; Matthias Wastian; Marcelo Jenny; \u0160tefan Emrich; Michael Sedlmair"}, {"ref_id": "b59", "title": "Measuring ideological proportions in political speeches", "journal": "", "year": "2013", "authors": "Yanchuan Sim; D L Brice; Justin H Acree; Noah A Gross;  Smith"}, {"ref_id": "b60", "title": "The parliamentary hansard 'verbatim'report: the written construction of spoken discourse", "journal": "Language and literature", "year": "1992", "authors": "Stef Slembrouck"}, {"ref_id": "b61", "title": "Dropout: A simple way to prevent neural networks from overfitting", "journal": "J. Mach. Learn. Res", "year": "2014-01", "authors": "Nitish Srivastava; Geoffrey Hinton; Alex Krizhevsky; Ilya Sutskever; Ruslan Salakhutdinov"}, {"ref_id": "b62", "title": "How to fine-tune bert for text classification?", "journal": "", "year": "2019", "authors": "Chi Sun; Xipeng Qiu; Yige Xu; Xuanjing Huang"}, {"ref_id": "b63", "title": "Two different debates? investigating the relationship between a political debate on TV and simultaneous comments on twitter", "journal": "Social Science Computer Review", "year": "2014-07", "authors": "Damian Trilling"}, {"ref_id": "b64", "title": "Speaking style and candidate evaluations", "journal": "", "year": "2019", "authors": "M Stephen;  Utych"}, {"ref_id": "b65", "title": "Attention is all you need", "journal": "Curran Associates, Inc", "year": "2017", "authors": "Ashish Vaswani; Noam Shazeer; Niki Parmar; Jakob Uszkoreit; Llion Jones; Aidan N Gomez; Illia Kaiser;  Polosukhin"}, {"ref_id": "b66", "title": "Graph attention networks", "journal": "", "year": "2017", "authors": "Petar Veli\u010dkovi\u0107; Guillem Cucurull; Arantxa Casanova; Adriana Romero; Pietro Li\u00f2; Yoshua Bengio"}, {"ref_id": "b67", "title": "Detecting perspectives in political debates", "journal": "", "year": "2017", "authors": "David Vilares; Yulan He"}, {"ref_id": "b68", "title": "Tracking point of view in narrative", "journal": "Comput. Linguist", "year": "1994-06", "authors": "Janyce M Wiebe"}, {"ref_id": "b69", "title": "Tracking point of view in narrative", "journal": "Computational linguistics-Association for Computational Linguistics (Print)", "year": "1994", "authors": "J M Wiebe"}, {"ref_id": "b70", "title": "Huggingface's transformers: State-of-theart natural language processing", "journal": "ArXiv", "year": "2019", "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; R'emi Louf; Morgan Funtowicz; Jamie Brew"}, {"ref_id": "b71", "title": "Wilcoxon signed-rank test", "journal": "", "year": "2007", "authors": " Rf Woolson"}], "figures": [{"figure_label": "1", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "Figure 1 :1Figure 1: Four debate transcripts from the UK Parliament's House of Commons, over two different motions. The colors indicate similarity between transcripts based across three different contexts.", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: An overview of the proposed context graph, GPolS model and its components.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Figure 3 :3Figure 3: Box plots show the distribution of pairwise cosine similarity between transcripts (based on speakers, speaker affiliation, and motion) with their corresponding confidence intervals (notch).", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "We represent the relations between transcripts, speakers and motions in the form of a graph G = (V, E). V and E represent the nodes and edges in the graph. The nodes V are consisted of the set of debate transcripts T , speakers S and motions M . The edges E have three types: Speaker-Transcript edges E st based on speaker-self context, Speaker-Speaker edges E ss based on intra-party context, and Transcript-Motion edges E tm based on motion context. G is a heterogeneous graph as it has different types of nodes and edges. We now describe these three relations one by one that capture different contexts based on the similarities observed through Figure3.", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Figure 5 :5Figure 5: Attention visualisation using BERT. Intense red denotes higher attention. Arrows represent similar terms across transcripts. Heatmaps represent BERT heads that encode semantic links in speech.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_0", "figure_caption": "During my nine years in the Army... Their contributions to many recent operations from Afghanistan to Iraq leaves us in no doubt of their valour.", "figure_data": "PoliticiansT 1 \u2026 Setting police presence and Intra-Party Context T 2T 3 Speaker-Self ContextT 4 \u2026 I have seen our reservists in Kevan Jones Labour Partybudgets for 2018-19 has been aaction in Iraq and Afghanistan, andTranscriptsreal challenge both for the Government and for local forces such as Suffolk constabulary\u2026 highest caseload per officer in the country\u2026 yet receives one of the lowest funding settlements\u2026 has to contend with a wide variety ofToday's conflicts require troops to hit the ground running \u2026 Government argue that they inherited multibillion pound hole in defenceI think everyone in the House would like to thank them\u2026 the reason for a gap is previous Labour Governments multibillion black hole in the finances\u2026 it would go up to \u00a336 billion\u2026 the Government reduced the defenceSpeechmodern pressures\u2026 events that can never be predicted will take place\u2026 I urge the Government to instigate the funding reviewbudget ...while starving the organisations that defend our country. I have no problem giving money to overseas aid, but Ibudget by 9%\u2026 it is not acceptable when the defence of our country is at stake\u2026Unless Ministers change tack now, thewithout further delay and asthink\u2026 Charity starts at home,defence capability of this countryquickly as possible.especially in austere times \u2026could be at dire risk.MotionsM 1abc Text Color abcSpeaker-Self Context: Similarity in speeches of a speaker across different motions Motion Context: What it represents Intra-Party Context: Similarity in stance adoptionM 2abcSimilarity in speeches of differentspeakers over the same motion"}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_2", "figure_caption": "Graph statistics", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Classification accuracy averaged over 10 different runs. Bold denotes the best results.", "figure_data": "ModelSpeaker-self contextIntra-party contextMotion contextAccBERT0.67GPolS0.73GPolS0.75GPolS0.76Figure 4: Attention coefficients amongst MPs of Con-servative Party (left) and Liberal Democrats (right)"}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_5", "figure_caption": "Ablation study: We investigate the effect of different contexts by removing contexts.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "\u03b1 ij = exp (LeakyReLU(a T w [W x i \u2295 W x j ])) k\u2208N i exp (LeakyReLU(a T w [W x i \u2295 W x k ]))(1)", "formula_coordinates": [6.0, 189.21, 302.81, 336.33, 36.78]}, {"formula_id": "formula_1", "formula_text": "q i = U k=1 LeakyReLU \uf8eb \uf8ed j\u2208N i \u03b1 k ij W k x j \uf8f6 \uf8f8 (2)", "formula_coordinates": [6.0, 209.37, 447.21, 316.17, 38.0]}, {"formula_id": "formula_2", "formula_text": "y i = Softmax \uf8eb \uf8ed j\u2208N i \u03b2 ij W 2 8 k=1 LeakyReLU \uf8eb \uf8ed j\u2208N i \u03b1 k ij W k x j \uf8f6 \uf8f8 \uf8f6 \uf8f8 (3)", "formula_coordinates": [6.0, 154.33, 555.15, 371.21, 38.0]}, {"formula_id": "formula_3", "formula_text": "L cse = \u2212 |V | i=1 Y i ln(y i ) + (1 \u2212 Y i ) ln(1 \u2212 y i ) (4)", "formula_coordinates": [6.0, 200.31, 649.23, 325.24, 34.74]}], "doi": ""}