{"title": "Unifying Cross-Lingual Semantic Role Labeling with Heterogeneous Linguistic Resources", "authors": "Simone Conia; Andrea Bacciu; Roberto Navigli", "pub_date": "", "abstract": "While cross-lingual techniques are finding increasing success in a wide range of Natural Language Processing tasks, their application to Semantic Role Labeling (SRL) has been strongly limited by the fact that each language adopts its own linguistic formalism, from Prop-Bank for English to AnCora for Spanish and PDT-Vallex for Czech, inter alia. In this work, we address this issue and present a unified model to perform cross-lingual SRL over heterogeneous linguistic resources. Our model implicitly learns a high-quality mapping for different formalisms across diverse languages without resorting to word alignment and/or translation techniques. We find that, not only is our cross-lingual system competitive with the current state of the art but that it is also robust to low-data scenarios. Most interestingly, our unified model is able to annotate a sentence in a single forward pass with all the inventories it was trained with, providing a tool for the analysis and comparison of linguistic theories across different languages. We release our code and model at https://github.com/ SapienzaNLP/unify-srl.", "sections": [{"heading": "Introduction", "text": "Semantic Role Labeling (SRL) -a long-standing open problem in Natural Language Processing (NLP) and a key building block of language understanding (Navigli, 2018) -is often defined as the task of automatically addressing the question \"Who did what to whom, when, where, and how?\" (Gildea and Jurafsky, 2000;M\u00e0rquez et al., 2008). While the need to manually engineer and fine-tune complex feature templates severely limited early work (Zhao et al., 2009), the great success of neural networks in NLP has resulted in impressive progress in SRL, thanks especially to the ability of recurrent networks to better capture relations over sequences (He et al., 2017;. Owing to the recent wide availability of robust multilingual representations, such as multilingual word embeddings (Grave et al., 2018) and multilingual language models (Devlin et al., 2019;Conneau et al., 2020), researchers have been able to shift their focus to the development of models that work on multiple languages (Cai and Lapata, 2019b;.\nA robust multilingual representation is nevertheless just one piece of the puzzle: a key challenge in multilingual SRL is that the task is tightly bound to linguistic formalisms (M\u00e0rquez et al., 2008) which may present significant structural differences from language to language (Hajic et al., 2009). In the recent literature, it is standard practice to sidestep this issue by training and evaluating a model on each language separately (Cai and Lapata, 2019b;Chen et al., 2019;Kasai et al., 2019;. Although this strategy allows a model to adapt itself to the characteristics of a given formalism, it is burdened by the non-negligible need for training and maintaining one model instance for each language, resulting in a set of monolingual systems.\nInstead of dealing with heterogeneous linguistic theories, another line of research consists in actively studying the effect of using a single formalism across multiple languages through annotation projection or other transfer techniques (Akbik et al., 2015(Akbik et al., , 2016Daza and Frank, 2019;Cai and Lapata, 2020;Daza and Frank, 2020). However, such approaches often rely on word aligners and/or automatic translation tools which may introduce a considerable amount of noise, especially in lowresource languages. More importantly, they rely on the strong assumption that the linguistic formalism of choice, which may have been developed with a specific language in mind, is also suitable for other languages.\nIn this work, we take the best of both worlds and propose a novel approach to cross-lingual SRL. Our contributions can be summarized as follows:\n\u2022 We introduce a unified model to perform cross-lingual SRL with heterogeneous linguistic resources;\n\u2022 We find that our model is competitive against state-of-the-art systems on all the 6 languages of the CoNLL-2009 benchmark;\n\u2022 We show that our model is robust to lowresource scenarios, thanks to its ability to generalize across languages;\n\u2022 We probe our model and demonstrate that it implicitly learns to align heterogeneous linguistic resources;\n\u2022 We automatically build and release a crosslingual mapping that aligns linguistic formalisms from diverse languages.\nWe hope that our unified model will further advance cross-lingual SRL and represent a tool for the analysis and comparison of linguistic theories across multiple languages.", "publication_ref": ["b40", "b20", "b37", "b50", "b25", "b21", "b15", "b12", "b6", "b37", "b22", "b6", "b9", "b29", "b0", "b1", "b13", "b7", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Related Work", "text": "End-to-end SRL. The SRL pipeline is usually divided into four steps: predicate identification, predicate sense disambiguation, argument identification, and argument classification. While early research focused its efforts on addressing each step individually (Xue and Palmer, 2004;Bj\u00f6rkelund et al., 2009;Zhao et al., 2009), recent work has successfully demonstrated that tackling some of these subtasks jointly with multitask learning (Caruana, 1997) is beneficial. In particular,  and, subsequently, Cai et al. (2018),  and , indicate that predicate sense signals aid the identification of predicateargument relations. Therefore, we follow this line and propose an end-to-end system for cross-lingual SRL.\nMultilingual SRL. Current work in multilingual SRL revolves mainly around the development of novel neural architectures, which fall into two broad categories, syntax-aware and syntax-agnostic ones. On one hand, the quality and diversity of the information encoded by syntax is an enticing prospect that has resulted in a wide range of contributions:  made use of Graph Convolutional Networks (GCNs) to better capture relations between neighboring nodes in syntactic dependency trees; Strubell et al. (2018) demonstrated the effectiveness of linguisticallyinformed self-attention layers in SRL; Cai and Lapata (2019b) observed that syntactic dependencies often mirror semantic relations and proposed a model that jointly learns to perform syntactic dependency parsing and SRL;  devised syntax-based pruning rules that work for multiple languages. On the other hand, the complexity of syntax and the noisy performance of automatic syntactic parsers have deterred other researchers who, instead, have found methods to improve SRL without syntax: Cai et al. (2018) took advantage of an attentive biaffine layer (Dozat and Manning, 2017) to better model predicate-argument relations; Chen et al. (2019) and  obtained remarkable results in multiple languages by capturing predicate-argument interactions via capsule networks and iteratively refining the sequence of output labels, respectively; Cai and Lapata (2019a) proposed a semi-supervised approach that scales across different languages.\nWhile we follow the latter trend and develop a syntax-agnostic model, we underline that both the aforementioned syntax-aware and syntax-agnostic approaches suffer from a significant drawback: they require training one model instance for each language of interest. Their two main limitations are, therefore, that i) the number of trainable parameters increases linearly with the number of languages, and ii) the information available in one language cannot be exploited to make SRL more robust in other languages. In contrast, one of the main objectives of our work is to develop a unified cross-lingual model which can mitigate the paucity of training data in some languages by exploiting the information available in other, resource-richer languages.", "publication_ref": ["b48", "b3", "b50", "b8", "b4", "b45", "b6", "b4", "b17", "b9", "b5"], "figure_ref": [], "table_ref": []}, {"heading": "Cross-lingual SRL.", "text": "A key challenge in performing cross-lingual SRL with a single unified model is the dissimilarity of predicate sense and semantic role inventories between languages. For example, the multilingual dataset distributed as part of the CoNLL-2009 shared task (Hajic et al., 2009) adopts the English Proposition Bank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) to annotate English sentences, the Chinese Proposition Bank (Xue and Palmer, 2009) for Chinese, the AnCora (Taul\u00e9 et al., 2008) predicate-argument structure inventory for Catalan and Spanish, the German Proposition Bank which, differently from the other PropBanks, is derived from FrameNet (Hajic et al., 2009), and PDT-Vallex (Hajic et al., 2003) for Czech. Many of these inventories are not aligned with each other as they follow and implement different linguistic theories which, in turn, may pose different challenges. Pad\u00f3 and Lapata (2009), and Akbik et al. (2015Akbik et al. ( , 2016 worked around these issues by making the English PropBank act as a universal predicate sense and semantic role inventory and projecting PropBank-style annotations from English onto non-English sentences by means of word alignment techniques applied to parallel corpora such as Europarl (Koehn, 2005). These efforts resulted in the creation of the Universal PropBank, a multilingual collection of semi-automatically annotated corpora for SRL, which is actively in use today to train and evaluate novel cross-lingual methods such as word alignment techniques (Aminian et al., 2019). In the absence of parallel corpora, annotation projection techniques can still be applied by automatically translating an annotated corpus and then projecting the original labels onto the newly created silver corpus (Daza and Frank, 2020;Fei et al., 2020), whereas Daza and Frank (2019) have recently found success in training an encoder-decoder architecture to jointly tackle SRL and translation.\nWhile the foregoing studies have greatly advanced the state of cross-lingual SRL, they suffer from an intrinsic downside: using translation and word alignment techniques may result in a considerable amount of noise, which automatically puts an upper bound to the quality of the projected labels. Moreover, they are based on the strong assumption that the English PropBank provides a suitable formalism for non-English languages, and this may not always be the case. Among the numerous studies that adopt the English PropBank as a universal predicate-argument structure inventory for crosslingual SRL, the work of Mulcaire et al. (2018) stands out for proposing a bilingual model that is able to perform SRL according to two different inventories at the same time, although with significantly lower results compared to the state of the art at the time. With our work, we go beyond current approaches to cross-lingual SRL and embrace the diversity of the various representations made available in different languages. In particular, our model has three key advantages: i) it does not rely on word alignment or machine translation tools; ii) it learns to perform SRL with multiple linguistic inventories; iii) it learns to link resources that would otherwise be disconnected from each other.", "publication_ref": ["b22", "b42", "b38", "b49", "b46", "b22", "b23", "b41", "b0", "b1", "b31", "b2", "b14", "b18", "b13", "b39"], "figure_ref": [], "table_ref": []}, {"heading": "Model Description", "text": "In the wake of recent work in SRL, our model falls into the broad category of end-to-end systems as it learns to jointly tackle predicate identification, predicate sense disambiguation, argument identification and argument classification. The model architecture can be roughly divided into the following components:\n\u2022 A universal sentence encoder whose parameters are shared across languages and which produces word encodings that capture predicate-related information (Section 3.2);\n\u2022 A universal predicate-argument encoder whose parameters are also shared across languages and which models predicate-argument relations (Section 3.3);\n\u2022 A set of language-specific decoders which indicate whether words are predicates, select the most appropriate sense for each predicate, and assign a semantic role to every predicateargument couple, according to several different SRL inventories (Section 3.4).\nUnlike previous work, our model does not require any preexisting cross-resource mappings, word alignment techniques, translation tools, other annotation transfer techniques, or parallel data, to perform high-quality cross-lingual SRL, as it relies solely on implicit cross-lingual knowledge transfer.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Input representation", "text": "Pretrained language models such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2019) and XLM-RoBERTa (Conneau et al., 2020), inter alia, are becoming the de facto input representation method, thanks to their ability to encode vast amounts of knowledge. Following recent studies (Hewitt and Manning, 2019;Kuznetsov and Gurevych, 2020;, which show that different layers of a language model capture different syntactic and semantic characteristics, our model builds a contextual representation for an input word by concatenating the corresponding hidden states of the four top-most inner layers of a language model. More formally, given a word w i in a sentence w = w 0 , w 1 , . . . , w i , . . . , w n\u22121 of n words and its hidden state h k i = l k (w i |w) from the k-th inner layer l k of a language model with K layers, the model computes the word encoding e i as follows:\nh i = h K i \u2295 h K\u22121 i \u2295 h K\u22122 i \u2295 h K\u22123 i e i = Swish(W w h i + b w )\nwhere x \u2295 y is the concatenation of the two vectors x and y, and Swish(x) = x \u2022 sigmoid(x) is a non-linear activation which was found to produce smoother gradient landscapes than the more traditional ReLU (Ramachandran et al., 2018).", "publication_ref": ["b43", "b15", "b12", "b27", "b32", "b44"], "figure_ref": [], "table_ref": []}, {"heading": "Universal sentence encoder", "text": "Expanding on the seminal intuition of Fillmore ( 1968), who suggests the existence of deep semantic relations between a predicate and other sentential constituents, we argue that such semantic relations may be preserved across languages. With this reasoning in mind, we devise a universal sentence encoder whose parameters are shared across languages. Intuitively, the aim of our universal sentence encoder is to capture sentence-level information that is not formalism-specific and spans across languages, such as information about predicate positions and predicate senses. In our case, we implement this universal sentence encoder as a stack of BiLSTM layers (Hochreiter and Schmidhuber, 1997), similarly to , Cai et al. (2018) and , with the difference that we concatenate the output of each layer to its input in order to mitigate the problem of vanishing gradients. More formally, given a sequence of word encodings e = e 0 , e 1 , . . . , e n\u22121 , the model computes a sequence of timestep encodings t as follows:\nt j i = e i if j = 0 t j\u22121 i \u2295 BiLSTM j i (t j\u22121 ) otherwise t = t K 0 , t K 1 , . . . , t K n\u22121\nwhere BiLSTM j i (\u2022) is the i-th timestep of the j-th BiLSTM layer and K is the total number of layers in the stack. Starting from each timestep encoding t i , the model produces a predicate representation p i , which captures whether the corresponding word w i is a predicate, and a sense representation s i which encodes information about the sense of a predicate at position i:\np i = Swish(W p t i + b p ) s i = Swish(W s t i + b s )\nWe stress that the vector representations obtained for each timestep, each predicate and each sense lie in three spaces that are shared across the languages and formalisms used to perform SRL.", "publication_ref": ["b28", "b4"], "figure_ref": [], "table_ref": []}, {"heading": "Universal predicate-argument encoder", "text": "In the same vein, and for the same reasoning that motivated the design of the above universal sentence encoder, our model includes a universal predicate-argument encoder whose parameters are also shared across languages. The objective of this second encoder is to capture the relations between each predicate-argument couple that appears in a sentence, independently of the input language. Similarly to the universal sentence encoder, we implement this universal predicate-argument encoder as a stack of BiLSTM layers. More formally, let w p be a predicate in the input sentence w = w 0 , w 1 , . . . , w p , . . . , w n\u22121 , then the model computes a sequence of predicate-specific argument encodings a as follows:\na j i = t p \u2295 t i if j = 0 a j\u22121 i \u2295 BiLSTM j i (a j\u22121 ) otherwise a = a K 0 , a K 1 , . . . , a K n\u22121\nwhere t i is the i-th timestep encoding from the universal sentence encoder and K is the total number of layers in the stack. Starting from each predicatespecific argument encoding a i , the model produces a semantic role representation r i for word w i :\nr i = Swish(W r a i + b r )\nSimilarly to the predicate and sense representations p and s, since the predicate-argument encoder is one and the same for all languages, the semantic role representation r obtained must draw upon cross-lingual information in order to abstract from language-specific peculiarities.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Language-specific decoders", "text": "The aforementioned predicate encodings p, sense encodings s and semantic role encodings r are shared across languages, forcing the model to learn from semantics rather than from surface-level features such as word order, part-of-speech tags and syntactic rules, all of which may differ from language to language. Ultimately, however, we want our model to provide semantic role annotations according to an existing predicate-argument structure inventory, e.g., PropBank, AnCora, or PDT-Vallex. Our model, therefore, includes a set of linear decoders that indicate whether a word w i is a predicate, what the most appropriate sense for a predicate w p is, and what the semantic role of a word w r with respect to a specific predicate w p is, for each language l:\n\u03c3 p (w i |l) = W p|l p i + b p|l \u03c3 s (w p |l) = W s|l s i + b s|l \u03c3 r (w r |w p , l) = W r|l r i + b r|l\nAlthough we could have opted for more complex decoding strategies, in our case linear decoders have two advantages: 1) they keep the languagespecific part of the model as simple as possible, pushing the model into learning from its universal encoders; 2) they can be seen as linear probes, providing an insight into the quality of the crosslingual knowledge that the model can capture.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Training objective", "text": "The model is trained to jointly minimize the sum of the categorical cross-entropy losses on predicate identification, predicate sense disambiguation and argument identification/classification over all the languages in a multitask learning fashion. More formally, given a language l and the corresponding predicate identification loss L p|l , predicate sense disambiguation loss L s|l and argument identification/classification loss L r|l , the cumulative loss L is:\nL = l\u2208L L p|l + L s|l + L r|l\nwhere L is the set of languages -and the corresponding formalisms -in the training set.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experiments", "text": "We evaluate our model in dependency-based multilingual SRL. The remainder of this Section describes the experimental setup (Section 4.1), provides a brief overview of the multilingual dataset we use for training, validation and testing (Section 4.2), and shows the results obtained on each language (Section 4.3).", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Experimental Setup", "text": "We implemented the model in PyTorch 1 and Py-Torch Lightning 2 , and used the pretrained language models for multilingual BERT (m-BERT) and XLM-RoBERTa (XLM-R) made available by the Transformers library (Wolf et al., 2020). We trained each model configuration for 30 epochs using Adam (Kingma and Ba, 2015) with a \"slanted triangle\" learning rate scheduling strategy which linearly increases the learning rate for 1 epoch and then linearly decreases the value for 15 epochs. We did not perform hyperparameter tuning and opted instead for standard values used in the literature; we provide more details about our model configuration and its hyperparameter values in Appendix A. In the remainder of this Section, we report the F 1 scores of the best models selected according to the highest F 1 score obtained on the validation set at the end of a training epoch. 3", "publication_ref": ["b47"], "figure_ref": [], "table_ref": []}, {"heading": "Dataset", "text": "To the best of our knowledge, the dataset provided as part of the CoNLL-2009 shared task (Hajic et al., 2009) is the largest and most diverse collection of human-annotated sentences for multilingual SRL. Table 1: F 1 scores on the in-domain evaluation CoNLL-2009 with gold pre-identified predicates. \"CoNLL-2009 ST best\" refers to the best results obtained (by different systems) during the Shared Task. We include all the systems that reported results in at least 4 languages. : syntax-aware system. : syntax-agnostic system.", "publication_ref": ["b22"], "figure_ref": [], "table_ref": []}, {"heading": "CONLL-2009 -OOD CZ DE EN", "text": "CoNLL-2009 ST best 85.4 65.9 73.3 Zhao et al. (2009) 82.7 67.8 74.6  87.2 -77.7  jection techniques, and ii) it uses the English Prop-Bank for all languages, which goes against our interest in capturing cross-lingual knowledge over heterogeneous inventories.", "publication_ref": ["b50"], "figure_ref": [], "table_ref": []}, {"heading": "Results", "text": "Cross-lingual SRL. Table 1 compares the results obtained by our unified cross-lingual model against the state of the art in multilingual SRL, including both syntax-agnostic and syntax-aware architectures, on the in-domain test sets of CoNLL-2009 when using gold pre-identified predicates, rather than the predicates identified by the model itself, as standard in the CoNLL-2009 shared task. While proposing a state-of-the-art architecture is not the focus of this work, we believed it was important to build our cross-lingual approach starting from a strong and consistent baseline. For this reason, Table 1 includes the results obtained when training a separate instance of our model for each language, using the same strategy adopted by current multilingual systems (Cai and Lapata, 2019a; and showing results that are competitive with , inter alia. Remarkably, thanks to its universal encoders shared across languages and formalisms, our unified crosslingual model outperforms our state-of-the-art baseline in all the 6 languages at a fraction of the cost in terms of number of trainable parameters (a single cross-lingual model against six monolingual models, each trained on a different language). Similar results can be seen in Table 2 where our crosslingual approach improves over the state of the art on the out-of-domain evaluation of CoNLL-2009, especially in the German and English test sets which were purposely built to include predicates that do not appear in the training set. These results confirm empirically our initial hunch that semantic role labeling relations are deeply rooted beyond languages, independently of their surface realization and their predicate-argument structure inventories.\nFinally, for completeness, Appendix E includes the results of our system on the individual subtasks, namely, predicate identification and predicate sense  The improvements of our cross-lingual approach compared to the more traditional monolingual baseline are evident, especially in lower-resource scenarios, with absolute improvements in F 1 score of 25.5%, 9.7% and 26.9% on the Catalan, German and Spanish test sets, respectively. This is thanks to the ability of the model to use the knowledge from a language to improve its performance on other languages.\nOne-shot cross-lingual SRL. An interesting open question in SRL is whether a system can learn to model the semantic relations between a predicate sense s and its arguments, given a limited number of training samples in which s appears. In particular in our case, we are interested in understanding how the model fares in a synthetic scenario where each sense appears at most once in the training set, that is, we evaluate our model in a one-shot learning setting. As we can see from Table 3 (bottom), our cross-lingual approach outperforms its monolingual counterpart trained on each synthetic dataset separately by a wide margin, once again providing strong absolute improvements -18.7% in Catalan, 9.2% in German and 16.1% in Spanish in terms of F 1 score -for languages where the number of training instances is smaller. It is not uncommon for supervised cross-lingual tasks to feature different amounts of data for each language, depending on how difficult it is to get manual annotations for each language of interest. We simulate this setting in SRL by training our model on 100% of the training data available for the English language, while keeping the one-shot learning setting for all the other languages. As Table 3 (bottom) shows, non-English languages exhibit further improvements as the number of English training samples increases, lending further credibility to the idea that SRL can be learnt across languages even when using heterogeneous resources. Not only do these results suggest that a cross-lingual/cross-resource approach might mitigate the need for a large training set in each language, but also that reasonable cross-lingual results may be obtained by maintaining a single large dataset for a high-resource language, together with several small datasets for low-resource languages.", "publication_ref": ["b5"], "figure_ref": [], "table_ref": ["tab_1", "tab_3", "tab_3"]}, {"heading": "Analysis and Discussion", "text": "Cross-formalism SRL. In contrast to existing multilingual systems, a key benefit of our unified cross-lingual model is its ability to provide annotations for predicate senses and semantic roles in any linguistic formalism. As we can see from Figure 1 (left), given the English sentence \"the cat threw its ball out of the window\", our language-specific decoders produce predicate sense and semantic role labels not only according to the English PropBank inventory, but also for all the other resources, as it correctly identifies the agentive and patientive constituents independently of the formalism of interest. And this is not all, our model may potentially work on any of the 100 languages supported by the underlying language model (m-BERT or XLM-RoBERTa), e.g., in Italian, as shown in Figure 1 (right). This is vital for those languages for which a predicate-argument structure inventory has not yet been developed -an endeavor that may take Figure 1: Thanks to its universal encoders, our unified cross-lingual model is able to provide predicate sense and semantic role labels according to several linguistic formalisms. Left: SRL labels for an English input sentence. Right: SRL labels for an Italian input sentence, which can be translated into English as \"The president refuses the help of the opponents\". Notice that Italian is not among the languages in the training set. years to come to fruition -and, therefore, manually annotated data are unavailable. Thus, as long as a large amount of pretraining data is openly accessible, our system provides a robust cross-lingual tool to compare and analyze different linguistic theories and formalisms across a wide range of languages, on the one hand, and to overcome the issue of performing SRL on languages where no inventory is available, on the other.\nAligning heterogeneous resources. As briefly mentioned previously, the universal encoders in the model architecture force our system to learn cross-lingual features that are important across different formalisms. A crucial consequence of this approach is that the model learns to implicitly align the resources it is trained on, without the aid of word aligners and translation tools, even when these resources may be designed around specific languages and, therefore, present significant differences. In order to bring to light what our model implicitly learns to align in its shared crosslingual space (see Sections 3.2 and 3.3), we exploit its language-specific decoders to build a mapping from any source inventory, e.g., AnCora, to a target inventory, e.g., the English PropBank. In particular, we use our cross-lingual model to label a training set originally tagged with a source inventory to produce silver annotations according to a target inventory, similarly to what is shown in Figure 1. While producing the silver annotations, we keep track of the number of times each predicate sense in the source inventory is associated by the model with a predicate sense of the target inventory. As a result, we produce a weighted directed graph in which the nodes are predicate senses and an edge (a, b) with weight w indicates that our model maps the source predicate sense a to the target predicate sense b at least w times. A portion of this graph is displayed in Figure 2 where, for visualization purposes, we show the most frequent alignments for each language, i.e., the top-3 edges with largest weight from the nodes of each inventory to the nodes of the English PropBank (Figure 2, left) and to the nodes of VerbAtlas (Figure 2, right). 7 For example, Figure 2 (left) shows that our model learns to map the Spanish AnCora sense empezar.c1 and the German PropBank sense starten.2 to the English PropBank sense start.01, but also that, depending on the context, the Chinese Prop-Bank sense \u5f00\u59cb.01 can correspond to both start.01 and begin.01. Figure 2 (right) also shows that our model learns to map senses from different languages and formalisms to the coarse-grained senses of VerbAtlas, even though the latter formalism is quite distant from the others as its frames are based on clustering WordNet synsets -sets of synonymous words -that share similar semantic behavior, rather than enumerating and defining all the possible senses of a lexeme as in the English and Chinese PropBanks. To the best of our knowledge, our unified model is the first transfer-based tool to automatically align diverse linguistic resources across languages without relying on human supervision.", "publication_ref": [], "figure_ref": ["fig_1", "fig_1", "fig_1", "fig_1", "fig_1"], "table_ref": []}, {"heading": "Conclusion and Future Work", "text": "On one hand, recent research in multilingual SRL has focused mainly on proposing novel model architectures that achieve state-of-the-art results, but require a model instance to be trained on and for each language of interest. On the other hand, the latest developments in cross-lingual SRL have revolved around using the English PropBank inventory as a universal resource for other languages through annotation transfer techniques. Following our hunch that semantic relations may be deeply rooted beyond the surface realizations that distinguish one language from another, we propose a new approach to cross-lingual SRL and present a model which learns from heterogeneous linguistic resources in order to obtain a deeper understanding of sentence-level semantics. To achieve this objective, we equip our model architecture with \"universal\" encoders which share their weights across languages and are, therefore, forced to learn knowledge that spans across varying formalisms.\nOur unified cross-lingual model, evaluated on the gold multilingual benchmark of CoNLL-2009, outperforms previous state-of-the-art multilingual systems over 6 diverse languages, ranging from Catalan to Czech, from German to Chinese, and, at the same time, also considerably reduces the amount of trainable parameters required to support different linguistic formalisms. And this is not all. We find that our approach is robust to low-resource scenarios where the model is able to exploit the complementary knowledge contained in the training set of different languages.\nMost importantly, our model is able to provide predicate sense and semantic role labels according to 7 predicate-argument structure inventories in a single forward pass, facilitating comparisons between different linguistic formalisms and investigations about interlingual phenomena. Our analysis shows that, thanks to the prior knowledge encoded in recent pretrained language models and our focus on learning from cross-lingual features, our model can be used on languages that were never seen at training time, opening the door to alignment-free cross-lingual SRL on languages where a predicateargument structure inventory is not yet available. Finally, we show that our model implicitly learns to align heterogeneous resources, providing useful insights into inter-resource relations. We leave an in-depth qualitative and quantitative analysis of the learnt inter-resource mappings for future work.\nWe hope that our work can set a stepping stone for future developments towards the unification of heterogeneous SRL. We release the code to reproduce our experiments and the checkpoints of our best models at https://github. com/SapienzaNLP/unify-srl. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "B Data Statistics", "text": "Tables 5, and 7 provide an overview of the training sets provided as part of the CoNLL-2009 shared task, with statistics about sentences, predicates and arguments.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "C Hardware Infrastructure", "text": "All the experiments were performed on a x86-64 architecture with 64GB of RAM, an 8-core CPU running at 3.60GHz, and a single Nvidia RTX 2080Ti with 11GB of VRAM. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "D Training Details", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "E Other Results", "text": "Predicate identification. In Table 8 we report the results of our model on predicate identification.\nPredicate sense disambiguation. In Table 9 we report the results of our model on predicate sense disambiguation.", "publication_ref": [], "figure_ref": [], "table_ref": ["tab_9", "tab_10"]}, {"heading": "F Alignment Examples", "text": "Figure 3 provides two more examples, one in French (left), the other in Catalan (right). We remark that the training set of CoNLL-2009 does not include sentences in French, however, our crosslingual model correctly outputs SRL tags according to the other seven language-specific decoders.", "publication_ref": [], "figure_ref": ["fig_3"], "table_ref": []}, {"heading": "Sentences", "text": "Predicates Arguments       ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Acknowledgments", "text": "The authors gratefully acknowledge the support of the ERC Consolidator Grant MOUSSE No. 726487 under the European Union's Horizon 2020 research and innovation programme.\nThis work was supported in part by the MIUR under grant \"Dipartimenti di eccellenza 2018-2022\" of the Department of Computer Science of Sapienza University.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "A Model Hyperparameters", "text": "", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Generating high quality proposition banks for multilingual Semantic Role Labeling", "journal": "", "year": "2015", "authors": "Alan Akbik; Laura Chiticariu; Marina Danilevsky; Yunyao Li; Shivakumar Vaithyanathan; Huaiyu Zhu"}, {"ref_id": "b1", "title": "Towards semi-automatic generation of proposition banks for low-resource languages", "journal": "", "year": "2016", "authors": "Alan Akbik; Vishwajeet Kumar; Yunyao Li"}, {"ref_id": "b2", "title": "Cross-lingual transfer of semantic roles: From raw text to semantic roles", "journal": "", "year": "2019", "authors": "Maryam Aminian; Mohammad Sadegh Rasooli; Mona Diab"}, {"ref_id": "b3", "title": "Multilingual Semantic Role Labeling", "journal": "", "year": "2009", "authors": "Anders Bj\u00f6rkelund; Love Hafdell; Pierre Nugues"}, {"ref_id": "b4", "title": "A full end-to-end semantic role labeler, syntacticagnostic over syntactic-aware?", "journal": "", "year": "2018", "authors": "Jiaxun Cai; Shexia He; Zuchao Li; Hai Zhao"}, {"ref_id": "b5", "title": "Semi-supervised Semantic Role Labeling with cross-view training", "journal": "", "year": "2019", "authors": "Rui Cai; Mirella Lapata"}, {"ref_id": "b6", "title": "Syntax-aware Semantic Role Labeling without parsing", "journal": "", "year": "2019", "authors": "Rui Cai; Mirella Lapata"}, {"ref_id": "b7", "title": "Alignment-free cross-lingual Semantic Role Labeling", "journal": "", "year": "2020", "authors": "Rui Cai; Mirella Lapata"}, {"ref_id": "b8", "title": "Multitask learning", "journal": "", "year": "1997", "authors": "Rich Caruana"}, {"ref_id": "b9", "title": "Capturing argument interaction in Semantic Role Labeling with capsule networks", "journal": "", "year": "2019", "authors": "Xinchi Chen; Chunchuan Lyu; Ivan Titov"}, {"ref_id": "b10", "title": "InVeRo: Making Semantic Role Labeling accessible with intelligible verbs and roles", "journal": "", "year": "2020", "authors": "Simone Conia; Fabrizio Brignone; Davide Zanfardino; Roberto Navigli"}, {"ref_id": "b11", "title": "Bridging the gap in multilingual semantic role labeling: a language-agnostic approach", "journal": "", "year": "2020", "authors": "Simone Conia; Roberto Navigli"}, {"ref_id": "b12", "title": "Unsupervised cross-lingual representation learning at scale", "journal": "", "year": "2020", "authors": "Alexis Conneau; Kartikay Khandelwal; Naman Goyal; Vishrav Chaudhary; Guillaume Wenzek; Francisco Guzm\u00e1n; Edouard Grave; Myle Ott; Luke Zettlemoyer; Veselin Stoyanov"}, {"ref_id": "b13", "title": "Translate and label! an encoder-decoder approach for cross-lingual semantic role labeling", "journal": "", "year": "2019", "authors": "Angel Daza; Anette Frank"}, {"ref_id": "b14", "title": "X-SRL: A parallel cross-lingual Semantic Role Labeling dataset", "journal": "", "year": "2020", "authors": "Angel Daza; Anette Frank"}, {"ref_id": "b15", "title": "BERT: Pre-training of deep bidirectional Transformers for language understanding", "journal": "", "year": "2019", "authors": "Jacob Devlin; Ming-Wei Chang; Kenton Lee; Kristina Toutanova"}, {"ref_id": "b16", "title": "VerbAtlas: a novel large-scale verbal semantic resource and its application to Semantic Role Labeling", "journal": "", "year": "2019", "authors": "Andrea Di Fabio; Simone Conia; Roberto Navigli"}, {"ref_id": "b17", "title": "Deep biaffine attention for neural dependency parsing", "journal": "", "year": "2017", "authors": "Timothy Dozat; Christopher D Manning"}, {"ref_id": "b18", "title": "Cross-lingual Semantic Role Labeling with highquality translated training corpus", "journal": "", "year": "2020", "authors": "Meishan Hao Fei; Donghong Zhang;  Ji"}, {"ref_id": "b19", "title": "The case for case. Universals in Linguistic Theory", "journal": "", "year": "1968", "authors": "Charles J Fillmore"}, {"ref_id": "b20", "title": "Automatic labeling of semantic roles", "journal": "", "year": "2000", "authors": "Daniel Gildea; Daniel Jurafsky"}, {"ref_id": "b21", "title": "Learning word vectors for 157 languages", "journal": "", "year": "2018", "authors": "Edouard Grave; Piotr Bojanowski; Prakhar Gupta; Armand Joulin; Tomas Mikolov"}, {"ref_id": "b22", "title": "The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages", "journal": "", "year": "2009-01", "authors": "Jan Hajic; Massimiliano Ciaramita; Richard Johansson; Daisuke Kawahara; Maria Ant\u00f2nia Mart\u00ed; Llu\u00eds M\u00e0rquez; Adam Meyers; Joakim Nivre; Sebastian Pad\u00f3"}, {"ref_id": "b23", "title": "PDT-Vallex: Creating a large-coverage valency lexicon for treebank annotation", "journal": "", "year": "2003", "authors": "Jan Hajic; J Panevov\u00e1; Zdenka Uresov\u00e1; Alevtina B\u00e9mov\u00e1; V Kol\u00e1rov\u00e1; P Pajas"}, {"ref_id": "b24", "title": "Jointly predicting predicates and arguments in neural Semantic Role Labeling", "journal": "", "year": "2018", "authors": "Luheng He; Kenton Lee; Omer Levy; Luke Zettlemoyer"}, {"ref_id": "b25", "title": "Deep Semantic Role Labeling: What works and what's next", "journal": "", "year": "2017", "authors": "Luheng He; Kenton Lee; Mike Lewis; Luke Zettlemoyer"}, {"ref_id": "b26", "title": "Syntaxaware multilingual Semantic Role Labeling", "journal": "", "year": "2019", "authors": "Shexia He; Zuchao Li; Hai Zhao"}, {"ref_id": "b27", "title": "A structural probe for finding syntax in word representations", "journal": "", "year": "2019", "authors": "John Hewitt; Christopher D Manning"}, {"ref_id": "b28", "title": "Long short-term memory", "journal": "Neural Comput", "year": "1997", "authors": "Sepp Hochreiter; J\u00fcrgen Schmidhuber"}, {"ref_id": "b29", "title": "Syntax-aware neural Semantic Role Labeling with supertags", "journal": "", "year": "2019", "authors": "Jungo Kasai; Dan Friedman; Robert Frank; R Dragomir; Owen Radev;  Rambow"}, {"ref_id": "b30", "title": "Adam: A method for stochastic optimization", "journal": "", "year": "2015", "authors": "P Diederik; Jimmy Kingma;  Ba"}, {"ref_id": "b31", "title": "Europarl: A parallel corpus for statistical machine translation", "journal": "", "year": "2005", "authors": "Philipp Koehn"}, {"ref_id": "b32", "title": "A matter of framing: The impact of linguistic formalism on probing results", "journal": "", "year": "2020", "authors": "Ilia Kuznetsov; Iryna Gurevych"}, {"ref_id": "b33", "title": "Dependency or span, end-to-end uniform semantic role labeling", "journal": "", "year": "2019", "authors": "Zuchao Li; Shexia He; Hai Zhao; Yiqing Zhang; Zhuosheng Zhang; Xi Zhou; Xiang Zhou"}, {"ref_id": "b34", "title": "Semantic Role Labeling with iterative structure refinement", "journal": "", "year": "2019", "authors": "Chunchuan Lyu; Shay B Cohen; Ivan Titov"}, {"ref_id": "b35", "title": "A simple and accurate syntax-agnostic neural model for dependency-based Semantic Role Labeling", "journal": "", "year": "2017", "authors": "Diego Marcheggiani; Anton Frolov; Ivan Titov"}, {"ref_id": "b36", "title": "Encoding sentences with graph convolutional networks for Semantic Role Labeling", "journal": "", "year": "2017", "authors": "Diego Marcheggiani; Ivan Titov"}, {"ref_id": "b37", "title": "Semantic Role Labeling: An introduction to the special issue", "journal": "Computational Linguistics", "year": "2008", "authors": "Llu\u00eds M\u00e0rquez; Xavier Carreras; Kenneth C Litkowski; Suzanne Stevenson"}, {"ref_id": "b38", "title": "The NomBank project: An interim report", "journal": "", "year": "2004", "authors": "Adam Meyers; Ruth Reeves; Catherine Macleod; Rachel Szekely; Veronika Zielinska; Brian Young; Ralph Grishman"}, {"ref_id": "b39", "title": "Polyglot Semantic Role Labeling", "journal": "", "year": "2018", "authors": "Phoebe Mulcaire; Swabha Swayamdipta; Noah A Smith"}, {"ref_id": "b40", "title": "Natural Language Understanding: Instructions for (present and future) use", "journal": "", "year": "2018", "authors": "Roberto Navigli"}, {"ref_id": "b41", "title": "Crosslingual annotation projection for semantic roles", "journal": "J. Artif. Intell. Res", "year": "2009", "authors": "Sebastian Pad\u00f3; Mirella Lapata"}, {"ref_id": "b42", "title": "The Proposition Bank: An annotated corpus of semantic roles", "journal": "Computational Linguistics", "year": "2005", "authors": "Martha Palmer; Daniel Gildea; Paul Kingsbury"}, {"ref_id": "b43", "title": "Deep contextualized word representations", "journal": "", "year": "2018", "authors": "Matthew E Peters; Mark Neumann; Mohit Iyyer; Matt Gardner; Christopher Clark; Kenton Lee; Luke Zettlemoyer"}, {"ref_id": "b44", "title": "Searching for activation functions", "journal": "", "year": "2018", "authors": "Prajit Ramachandran; Barret Zoph; Quoc V Le"}, {"ref_id": "b45", "title": "Linguistically-informed self-attention for Semantic Role Labeling", "journal": "", "year": "2018", "authors": "Emma Strubell; Patrick Verga; Daniel Andor; David Weiss; Andrew Mccallum"}, {"ref_id": "b46", "title": "Ancora: Multilevel annotated corpora for catalan and spanish", "journal": "", "year": "2008", "authors": "Mariona Taul\u00e9"}, {"ref_id": "b47", "title": "Transformers: State-of-the-art natural language processing", "journal": "", "year": "2020", "authors": "Thomas Wolf; Lysandre Debut; Victor Sanh; Julien Chaumond; Clement Delangue; Anthony Moi; Pierric Cistac; Tim Rault; Remi Louf; Morgan Funtowicz; Joe Davison; Sam Shleifer; Clara Patrick Von Platen; Yacine Ma; Julien Jernite; Canwen Plu; Teven Le Xu; Sylvain Scao;  Gugger"}, {"ref_id": "b48", "title": "Calibrating features for semantic role labeling", "journal": "", "year": "2004", "authors": "Nianwen Xue; Martha Palmer"}, {"ref_id": "b49", "title": "Adding semantic roles to the chinese treebank", "journal": "Nat. Lang. Eng", "year": "2009", "authors": "Nianwen Xue; Martha Palmer"}, {"ref_id": "b50", "title": "Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies", "journal": "", "year": "2009", "authors": "Hai Zhao; Wenliang Chen; Kiyotaka Jun'ichi Kazama; Kentaro Uchimoto;  Torisawa"}], "figures": [{"figure_label": "", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "This work XLM-R / mono 90.8 73.9 83.7 This work XML-R / cross 91.1 74.2 84.3", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "Figure 2 :2Figure 2: Visualization of the cross-resource mapping learnt by our model. Left: Mapping from Chinese PropBank, German PropBank and AnCora (both Catalan and Spanish) to English PropBank. Right: Mapping from English PropBank, German PropBank, Chinese PropBank and AnCora (both Spanish and Catalan) to VerbAtlas.", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "Training was performed using half-precision via Apex.8  Training times varied considerably depending on the experiment setting: the shorter experiment lasted 26 minutes (training m-BERT on 10% of the Catalan training set), whereas the longest 8 https://github.com/NVIDIA/apex experiment lasted for 46 hours (training XLM-RoBERTa on the union of all the datasets of all the languages).", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Figure 3 :3Figure 3: Output of our cross-lingual system for a French (left) and a Catalan (right) sentence.", "figure_data": ""}, {"figure_label": "2", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "", "figure_data": ""}, {"figure_label": "3", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "F 1 scores on the in-domain evaluation CoNLL-2009 with gold pre-identified predicates for low-resource (top) and one-shot learning (bottom) scenarios. *: the result in EN on the last line is not directly comparable with those above as we use the full English training set.", "figure_data": "disambiguation.Low-resource cross-lingual SRL. We evaluatethe robustness of our model in low-resource cross-lingual SRL by artificially reducing the training setof each language to 10% of its original size. Table3 (top) reports the results obtained by our modelwhen trained separately on the reduced training setof each language (monolingual), and the resultsobtained by the same model when trained on theunion of the reduced training sets (cross-lingual)."}, {"figure_label": "4", "figure_type": "table", "figure_id": "tab_4", "figure_caption": "Hyperparameter values for our model architecture. We use the same hyperparameter values for our monolingual and cross-lingual experiments.", "figure_data": ""}, {"figure_label": "5", "figure_type": "table", "figure_id": "tab_6", "figure_caption": "Overview of the CoNLL-2009 training sets. For each dataset we report the number of sentences (Total s ), the number of sentences with at least an annotated predicate (Annotated), the average number of tokens per sentence (Avg. Len.), the number of predicates (Total p ) and predicate senses (Senses), and also the number of arguments (Total a ) and argument roles (Roles).", "figure_data": "SentencesPredicatesArgumentsTotalsAnnotatedAvg. Len.TotalpSensesTotalaRolesCoNLL-2009CA1,7241,67531.55,1051,43611,52934CZ5,2285,21016.955,5173,46749,07154DE2,00053219.75882551,1699EN1,3341,28325.76,3901,99013,86532ES1,6551,58831.45,0761,56511,60036ZH1,7621,66329.58,1032,53518,55424"}, {"figure_label": "6", "figure_type": "table", "figure_id": "tab_7", "figure_caption": "Overview of the CoNLL-2009 development datasets. For each dataset we report the number of sentences (Total s ), the number of sentences with at least an annotated predicate (Annotated), the average number of tokens per sentence (Avg. Len.), the number of predicates (Total p ) and predicate senses (Senses), and also the number of arguments (Total a ) and argument roles (Roles).", "figure_data": "SentencesPredicatesArgumentsTotalsAnnotatedAvg. Len.TotalpSensesTotalaRolesCoNLL-2009CA1,8621,80229.45,0011,42511,27532CZ4,2134,19616.844,5853,01839,22355DE2,00050620.15502381,0738EN2,0001,91325.08,9872,25419,94935ES1,7251,66330.25,1751,62311,82433ZH2,5562,40030.112,2823,45827,71226"}, {"figure_label": "7", "figure_type": "table", "figure_id": "tab_8", "figure_caption": "Overview of the CoNLL-2009 testing datasets. For each dataset we report the number of sentences (Total s ), the number of sentences with at least an annotated predicate (Annotated), the average number of tokens per sentence (Avg. Len.), the number of predicates (Total p ) and predicate senses (Senses), and also the number of arguments (Total a ) and argument roles (Roles).", "figure_data": "CONLL-2009 -PREDICATE IDENTIFICATION CACZDEENESZHThis work m-BERT frozen / monolingual97.998.690.593.897.894.3This work m-BERT / monolingual98.398.991.494.398.495.0This work m-BERT / cross-lingual98.399.091.694.498.495.1This work XLM-R frozen / monolingual97.998.990.593.998.094.7This work XLM-R / monolingual98.399.291.594.398.495.2This work XLM-R / cross-lingual98.599.391.994.698.695.4"}, {"figure_label": "8", "figure_type": "table", "figure_id": "tab_9", "figure_caption": "F 1 scores on the predicate identification subtask which is not part of the CoNLL-2009 shared task setting.", "figure_data": "CONLL-2009 -PREDICATE DISAMBIGUATION CACZDEENESZHThis work m-BERT frozen / monolingual90.093.286.996.887.394.9This work m-BERT / monolingual90.393.587.397.287.595.0This work m-BERT / cross-lingual90.393.587.397.287.695.3This work XLM-R frozen / monolingual90.193.686.896.887.495.2This work XLM-R / monolingual90.493.787.397.187.695.6This work XLM-R / cross-lingual90.593.987.597.287.895.8"}, {"figure_label": "9", "figure_type": "table", "figure_id": "tab_10", "figure_caption": "Accuracy on the predicate sense disambiguation subtask computed by the official CoNLL-2009 scorer which, by default, takes into account only the sense numbers, e.g., 01 of eat.01.", "figure_data": ""}], "formulas": [{"formula_id": "formula_0", "formula_text": "h i = h K i \u2295 h K\u22121 i \u2295 h K\u22122 i \u2295 h K\u22123 i e i = Swish(W w h i + b w )", "formula_coordinates": [4.0, 100.98, 93.52, 157.55, 29.75]}, {"formula_id": "formula_1", "formula_text": "t j i = e i if j = 0 t j\u22121 i \u2295 BiLSTM j i (t j\u22121 ) otherwise t = t K 0 , t K 1 , . . . , t K n\u22121", "formula_coordinates": [4.0, 82.37, 535.48, 194.07, 47.59]}, {"formula_id": "formula_2", "formula_text": "p i = Swish(W p t i + b p ) s i = Swish(W s t i + b s )", "formula_coordinates": [4.0, 124.03, 709.26, 111.94, 29.67]}, {"formula_id": "formula_3", "formula_text": "a j i = t p \u2295 t i if j = 0 a j\u22121 i \u2295 BiLSTM j i (a j\u22121 ) otherwise a = a K 0 , a K 1 , . . . , a K n\u22121", "formula_coordinates": [4.0, 315.81, 343.27, 197.73, 47.59]}, {"formula_id": "formula_4", "formula_text": "r i = Swish(W r a i + b r )", "formula_coordinates": [4.0, 359.8, 479.9, 110.95, 13.13]}, {"formula_id": "formula_5", "formula_text": "\u03c3 p (w i |l) = W p|l p i + b p|l \u03c3 s (w p |l) = W s|l s i + b s|l \u03c3 r (w r |w p , l) = W r|l r i + b r|l", "formula_coordinates": [5.0, 113.12, 136.68, 133.17, 50.19]}, {"formula_id": "formula_6", "formula_text": "L = l\u2208L L p|l + L s|l + L r|l", "formula_coordinates": [5.0, 116.23, 468.04, 121.95, 24.85]}], "doi": "10.3115/v1/p15-1039"}