{"title": "Training Linear SVMs in Linear Time", "authors": "Thorsten Joachims", "pub_date": "", "abstract": "Linear Support Vector Machines (SVMs) have become one of the most prominent machine learning techniques for highdimensional sparse data commonly encountered in applications like text classification, word-sense disambiguation, and drug design. These applications involve a large number of examples n as well as a large number of features N , while each example has only s << N non-zero features. This paper presents a Cutting-Plane Algorithm for training linear SVMs that provably has training time O(sn) for classification problems and O(sn log(n)) for ordinal regression problems. The algorithm is based on an alternative, but equivalent formulation of the SVM optimization problem. Empirically, the Cutting-Plane Algorithm is several orders of magnitude faster than decomposition methods like SVM-Light for large datasets.", "sections": [{"heading": "INTRODUCTION", "text": "Many applications of machine learning deal with problems where both the number of features N as well as the number of examples n is large (in the millions). Examples of such problems can be found in text classification, word-sense disambiguation, and drug design. While problems of such size seem daunting at first glance, the examples mentioned above have extremely sparse feature vectors, which gives hope that these problems can be handled efficiently.\nLinear Support Vector Machines (SVMs) are among the most prominent machine learning techniques for such highdimensional and sparse data. On text classification prob-lems, for example, linear SVMs provide state-of-the-art prediction accuracy [10,5,17]. While conventional training methods for linear SVMs, in particular decomposition methods like SVM-Light [11], SMO [19], LIBSVM [2], and SVM-Torch [3] handle problems with a large number of features N quite efficiently, their super-linear scaling behavior with n [11,19,9] makes their use inefficient or even intractable on large datasets. On the other hand, while there are training methods that scale linear in n (e.g. [18,7,6,15]), such methods empirically (or at least in the worst case) scale quadratically with the number of features N .\nEven more difficult is the current situation for training linear Ordinal Regression SVMs (OR-SVMs) [8]. In Herbrich et al.'s formulation, an ordinal regression SVM over n examples is solved by translating it into a classification SVM with O(n 2 ) examples, which obviously makes scaling with n even worse than for straightforward classification SVMs. Nevertheless, OR-SVM are very interesting even beyond actual ordinal regression problems like those in information retrieval. When applied to problems with only two ranks, OR-SVMs are know to directly optimize the ROC-Area of the classification rule [20,14]. This is a desirable criterion to optimize in many applications.\nIn this paper, we propose the first general training algorithm for linear SVMs that provably scales O(s n) for classification and O(s n log(n)) for ordinal regression, where s is the average number of non-zero features. Obviously, this scaling is very attractive for high-dimensional and sparse data. The algorithm is based on an alternative, yet equivalent formulation of the SVM training problem. Compared to existing methods, the algorithm has several advantages. First, it is very simple and easy to implement. Second, it is several orders of magnitude faster than existing decomposition methods on large classification problems. On a text classification problem with 800,000 examples and 47,000 features, the new algorithm is roughly 100 times faster than SVM-Light. Third, the algorithm has a meaningful stopping criterion that directly relates to training error. This avoids wasting time on solving the optimization problem to a higher precision than necessary. And, fourth, the algorithm can handle ordinal regression problems with hundred-thousands of examples with ease, while existing methods become intractable with only a few thousand examples.", "publication_ref": ["b9", "b4", "b16", "b10", "b18", "b1", "b2", "b10", "b18", "b8", "b17", "b6", "b5", "b14", "b7", "b1", "b19", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "STRUCTURAL SVMS", "text": "We first introduce the formulation of the SVM optimization problem that provides the basis of our algorithm, both for classification and for ordinal regression SVMs. Both for-mulations are derived from Structural SVMs [24,14] previously used for predicting structured outputs and optimizing to multivariate performance measures. For each alternative formulation, we will show that it is equivalent to the respective conventional SVM optimization problem.", "publication_ref": ["b23", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Classification", "text": "For a given training set (x1, y1), ..., (xn, yn) with xi \u2208 N and yi \u2208 {\u22121, +1}, training a binary classification SVM means solving the following optimization problem. For simplicity of the following theoretical results, we focus on classification rules hw(x) = sign(w T x+b) with b = 0. A non-zero b can easily be modeled by adding an additional feature of constant value to each x (see e.g. [18]).\nOP 1. (Classification SVM (primal)) min w,\u03be i \u22650 1 2 w T w + C n n i=1 \u03bei s.t. \u2200i \u2208 {1, ..., n} : yi(w T xi) \u2265 1\u2212\u03bei\nNote that we adopted the formulation of [22,21] where \u00c8 \u03bei is divided by n to better capture how C scales with the training set size. Most training algorithms solve either OP1 or its dual (see [21] for the dual).\nThe algorithm we explore in the following considers a different optimization problem, which was proposed for training SVMs to predict structured outputs [24] and to optimize multivariate performance measures like F1-Score or the Precision/Recall Break-Even Point [14]. The following is a specialization of this formulation for the case of error rate, and we will refer to it as the \"structural\" formulation. \nw T w + C \u03be s.t. \u2200c \u2208 {0, 1} n : 1 n w T n i=1 ciyixi \u2265 1 n n i=1 ci \u2212 \u03be\nWhile OP2 has 2 n constraints, one for each possible vector c = (c1, ..., cn) \u2208 {0, 1} n , it has only one slack variable \u03be that is shared across all constraints. Each constraint in this structural formulation corresponds to the sum of a subset of constraints from OP1, and the ci select the subset. \n\u03be * = 1 n \u00c8 n i=1 \u03be * i .\nProof. Adapting the proof from [14], we will show that both optimization problems have the same objective value and an equivalent set of constraints. In particular, for every w the smallest feasible \u03be and \u00c8\ni \u03bei are related as \u03be = 1 n \u00c8 i \u03bei.\nFor a given w, the \u03bei in OP1 can be optimized individually, and the optimum is achieved for \u03bei = max{0, 1\u2212yi(w T xi)}. For OP2, the optimal \u03be for a given w is\n\u03be = max c\u2208{0,1} n\u00b41 n n i=1 ci \u2212 1 n n i=1 ciyi(w T xi) \u00b5\nSince the function is linear in ci, each ci can be optimized independently.\nmin C\u03be = n i=1 max c i \u2208{0,1} 1 n ci \u2212 1 n ciyi(w T xi) = n i=1 max 0, 1 n \u2212 1 n yi(w T xi) = min C n n i=1\n\u03bei Therefore, the objective functions of both optimization problems are equal for any w given the optimal \u03be and \u03bei, and consequently so are their optima.\nThe theorem shows that it is possible to solve OP2 instead of OP1 to find the same soft-margin hyperplane. While OP2 does not appear particularly attractive at first glance, we will show in Section 3 that its Wolfe Dual has desirable sparseness properties. Before we show that a similar formulation also exists for Ordinal Regression SVMs [8], we first state the Wolfe dual of OP2, since it will be referred to later. Denote with xc the sum 1 n \u00c8 n i=1 ciyixi and with ||c||1 the L1-norm of c (i.e. the number ones in c for binary c).\nOP 3. (Structural Classification SVM (dual)) max \u03b1\u22650 c\u2208{0,1} n ||c|| 1 n \u03b1c \u2212 1 2 c\u2208{0,1} n c \u2208{0,1} n \u03b1c\u03b1 c x T c x c s.t. c\u2208{0,1} n \u03b1c \u2264 C", "publication_ref": ["b17", "b21", "b20", "b20", "b23", "b13", "b13", "b7"], "figure_ref": [], "table_ref": []}, {"heading": "Ordinal Regression", "text": "In ordinal regression, the label yi of an example (xi, yi) indicates a rank instead of a nominal class. Without loss of generality, let yi \u2208 {1, ..., R} so that the values 1, ..., R are related on an ordinal scale. In the formulation of Herbrich et al. [8], the goal is to learn a function h(x) so that for any pair [12]. Furthermore, if the labels y take only two values, OP4 optimizes the ROC-Area of the classification rule [20,14].\nIn general, OP4 has m \u2208 O(n 2 ) constraints and slack variables. While this problem can be brought into the same form as OP1 by rewriting the constraints as w T (xi \u2212xj ) \u2265 1\u2212\u03beij , even relatively small training sets with only a few thousand examples are already intractable for conventional training methods. So far, researchers have tried to cut down on the number of constraints with various heuristics [20] which, however, cannot guarantee that the computed solution is optimal.\nWe will now derive a similar structural formulation of the ordinal regression SVM as we have already done for the binary classification SVM. \nw T w + C \u03be s.t. \u2200(i,j)\u2208P \u2200cij\u2208{0,1} : 1 m w T m i=1 cij (xi \u2212xj) \u2265 1 m m i=1 cij \u2212\u03be\nLike for classification, the structural formulation has O(2 n ) constraints, but only a single slack variable \u03be. Analogous to the classification SVM, the following theorem establishes that both formulations of the OR-SVM have equivalent solutions.\nTheorem 2. Any solution w * of OP5 is also a solution of OP4 (and vice versa), with\n\u03be * = 1 m \u00c8 (i,j)\u2208P \u03be * ij .\nProof. As mentioned above, the constraints in OP4 can be rewritten as yij (w T (xi \u2212 xj)) \u2265 1 \u2212 \u03beij with all yij set to 1. Theorem 1 applies immediately after substituting xij = xi \u2212 xj, since OP4 has the same form as OP1, and OP5 has the same form as OP2.", "publication_ref": ["b7", "b11", "b19", "b13", "b19"], "figure_ref": [], "table_ref": []}, {"heading": "CUTTING-PLANE ALGORITHM", "text": "While the alternative formulations of the classification and the ordinal regression SVM from above have an exponential number of constraints, they are very convenient in several ways.\nFirst, there is a single slack variable \u03be that measures training loss, and there is a direct correspondence between \u03be and the (in)feasibility of the set of constraints. In particular, if we have a point (w, \u03be) which fulfills all constraints up to precision , then (w, \u03be + ) is feasible. So, the approximation accuracy of an approximate solution to OP2 or OP5 is directly related to training loss, which provides an intuitive precision criterion.\nSecond, OP2 and OP5 are special cases of Structural SVMs [24,14]. As we will detail below, for this type of formulation it is possible to prove bounds on the sparsity of an -approximate solution of the Wolfe dual. In particular, we will show that the sparsity is independent of the training set size n, and that simple Cutting-Plane Algorithms [16] find an -approximate solution in a constant number of iterations for both OP2 or OP5.", "publication_ref": ["b23", "b13", "b15"], "figure_ref": [], "table_ref": []}, {"heading": "Classification", "text": "Algorithm 1 is our adaptation of the Cutting-Plane Algorithm for the Classification SVM optimization problem OP2. It is an adaptation of the Structural SVM training algorithm [24,14]. The algorithm iteratively constructs a sufficient subset W of the set of constraints in OP2. The algorithm starts with an empty set of constraints W. In each iteration, it first computes the optimum over the current working set W (i.e. w = 0 and \u03be = 0 in the first iteration) in Line 4. In Lines 5-7 it then finds the most violated constraint in OP2 and adds it to the working set W in Line 8. (w, \u03be) \u2190 argmin w,\u03be\u22650\n1 2 w T w + C\u03be s.t. \u2200c \u2208 W: 1 n w T n \u00c8 i=1 ciyixi \u2265 1 n n \u00c8 i=1 ci \u2212\u03be 5: for i=1,...,n do 6: ci \u2190 1 yi(w T xi) < 1 0 otherwise 7: end for 8: W \u2190 W \u222a {c} 9: until 1 n n \u00c8 i=1 ci \u2212 1 n n \u00c8 i=1 ciyi(w T xi)} \u2264 \u03be + 10: return(w,\u03be)\nNote that this assignment to (c1, ..., cn) = c corresponds to the constraint in OP2 that requires the largest \u03be to make it feasible given the current w, i.e.\nc = argmax c\u2208{0,1} n\u00b41 n n i=1 ci \u2212 1 n n i=1 ciyi(w T xi) \u00b5 .\nThe algorithm then continues in Line 4 by optimizing over the new working set, unless the most violated constraint is not violated by more than the desired precision .\nIn the following, we will analyze the correctness and the time complexity of the algorithm. We will show that the algorithm always terminates after a polynomial number of iterations that does not depend on the size n of the training set. Regarding its correctness, the following theorem characterizes the accuracy of the solution computed by Algorithm 1.", "publication_ref": ["b23", "b13"], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 3. (Correctness of Algorithm 1)", "text": "For any training sample S = ((x1, y1), . . . , (xn, yn)) and any > 0, if (w * , \u03be * ) is the optimal solution of OP2, then Algorithm 1 returns a point (w, \u03be) that has a better objective value than (w * , \u03be * ), and for which (w, \u03be + ) is feasible in OP2.\nProof. We first verify that Lines 5-7 compute the vector c \u2208 {0, 1} n that maximizes\n\u03be = max c\u2208{0,1} n\u00b41 n n i=1 ci \u2212 1 n n i=1 ciyi(w T xi) \u00b5 .\n\u03be is the minimum value needed to fulfill all constraints in OP2 for the current w. Since the function is linear in ci, each ci can be maximized independently.\n\u03be = 1 n n i=1 max c i \u2208{0,1} {ci \u2212ciyi(w T xi)} = 1 n n i=1 max{0, 1\u2212yi(w T xi)}\nThis directly corresponds to the assignment in Line 6. As checked in Line 9, the algorithm terminates only if \u03be does not exceed the \u03be from the solution over W by more than as desired.\nSince the (w, \u03be) returned by Algorithm 1 is the solution on a subset of the constraints from OP2, it holds that 1 2 w * T w * + C\u03be * \u2265 1 2 w T w + C\u03be.\nUsing a stopping criterion based on the accuracy of the training loss \u03be is very intuitive and practically meaningful, unlike the stopping criteria typically used in decomposition methods. Intuitively, can be used to indicate how close one wants to be to the error rate of the best hyperplane. In most machine learning applications, tolerating a training error that is suboptimal by 0.1% is very acceptable. This intuition makes selecting the stopping criterion much easier than in decomposition methods, where it is usually defined based on the accuracy of the Kuhn-Tucker Conditions of the dual (see e.g. [11]). Solving OP2 to an arbitrary but fixed precision of is essential in our analysis below, making sure that computation time is not wasted on computing a solution that is more accurate than necessary.\nWe next analyze the time complexity of Algorithm 1. It is easy to see that each iteration of the algorithm takes polynomial time, and that time scales linearly with n and s. We then show that the number of iterations until convergence is bounded, and that this upper bound is independent of n. (1)\niterations. R = maxi ||xi|| for Algorithm 1 and for Algorithm 2 it is R = 2 maxi ||xi||.\nProof. Following the proof scheme in [24,13], we will show that adding each new constraint to W increases the objective value at the solution of the quadratic program in Line 4 by at least some constant positive value. Since the objective value of the solution of OP2 is upper bounded by C (since w = 0 and \u03be = 1 is a feasible point in the primal), the algorithm can only perform a constant number of iterations before termination. The amount by which the solution increases by adding one constraint that is violated by more then (i.e. the criteria in Lines 9 and 26 respectively) to W is characterized by Proposition 17 in [24]. A lower bound on the increase is\nmin C 2 , 2 8Q 2\nwhere Q is an upper bound on the L2-norm of the coefficient vectors in the constraints. For OP2\nQ = max c\u2208{0,1} n \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac 1 n n i=1 ciyixi \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u2264 1 n n i=1 ci max i ||xi|| \u2264 R\nin the case of Algorithm 1 and for OP5 Note that the formulation of OP2 with the scaled C n instead of C in the objective is essential for this lemma. We will empirically evaluate the adequacy of this scaling in Section 4. Putting everything together leads to the following bound on the time complexity of Algorithm 1. To our knowledge, Algorithm 1 has the best scaling behavior of all known training algorithms for linear SVMs. Decomposition methods like SVM-Light [11], SMO [19], LIB-SVM [2], and SVMTorch [3] handle sparse problems with a large number of features N quite efficiently. However, their super-linear scaling behavior with n [11,19,9] makes them inefficient or even intractable on large datasets. We will compare our algorithm against SVM-Light as a representative decomposition methods.\nQ = max c\u2208{0,1} m \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac 1 m (i,j)\u2208P cij (xi \u2212xj ) \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u2264 1 m (i,j)\u2208P cij 2 max i ||xi|| \u2264 R in\nOther methods sacrifice the statistical robustness [22] of the \u00c8 \u03bei loss in the objective for the numerically more convenient \u00c8 \u03be 2 i loss. With additional restrictions on how the data is normalized, Core Vector Machines [23] are shown to scale linear in n. However, the restrictions make the method inapplicable to many datasets. Generally applicable are Lagrangian SVM [18] (using the \u00c8 \u03be 2 i loss), Proximal SVM [7] (using an L2 regression loss), and Interior Point Methods [6]. While these method scale linearly with n, they use the Sherman-Morrison-Woodbury formula for inverting the Hessian of the dual. This requires operating on N \u00d7 N matrices, which makes them applicable only for problems with small N . As a representative of this group of methods, we will compare against the Lagrangian SVM in Section 4.\nThe recent L2-SVM-MFN method [15] avoids explicitly representing N \u00d7 N matrices using conjugent gradient techniques. While the worst-case cost is still O(sn min(n,N)) per iteration, they observe that their method empirically scales better. We will compare against this method as well.", "publication_ref": ["b10", "b23", "b12", "b23", "b10", "b18", "b1", "b2", "b10", "b18", "b8", "b21", "b22", "b17", "b6", "b5", "b14"], "figure_ref": [], "table_ref": []}, {"heading": "Ordinal Regression", "text": "Algorithm 2 solves the ordinal regression SVM in the form of OP5 and has a structure that is very similar to Algorithm 1. It is a generalization of the algorithm for optimizing ROC-Area in [14] and similar to the algorithm independently developed in [4]. The key difference to Algorithm 1 lies in computing the most violated constraint of OP5\nc = argmax c\u2208{0,1} m 1 m (i,j)\u2208P cij \u2212 1 m (i,j)\u2208P cij w T (xi \u2212 xj)\nwithout enumerating all m \u2208 O(n 2 ) constraints from OP4.\nTo avoid O(n 2 ) cost, Algorithm 2 makes use of a condensed \nm w T n \u00c8 i=1 (c + i \u2212c \u2212 i )xi \u2265 1 2m n \u00c8 i=1 (c + i +c \u2212 i )\u2212\u03be 5:\nsort S by decreasing w T xi 6:\nc + \u2190 0; c \u2212 \u2190 0 7:\nnr \u2190 number of examples with yi = r 8:\nfor r = 2, ..., R do 9:\ni \u2190 1; j \u2190 1; a \u2190 0; b \u2190 0 10:\nwhile i \u2264 n do 11:\nif yi = r then 12:\nwhile (j \u2264 n) \u2227 (w T xi \u2212 w T xj < 1) do 13:\nif yj < r then 14  \n: b + +; c \u2212 j \u2190 c \u2212 j + (nr \u2212 a +\nW \u2190 W \u222a {(c + , c \u2212 )} 24: until 1 2m n \u00c8 i=1 (c + i +c \u2212 i ) \u2212 1 m n \u00c8 i=1 (c + i \u2212c \u2212 i )(w T xi) \u2264 \u03be\n(c + i \u2212 c \u2212 i )xi \u2265 1 2m n i=1 (c + i + c \u2212 i ) \u2212 \u03be\nwhere c + i is the number of times xi occurs with positive sign (i.e. cij = 1) and c \u2212 i is the number of times xi occurs with negative sign (i.e. cji = 1). If c + and c \u2212 are known, each constraint can be evaluated in time O(sn) instead of O(sm). Furthermore, the right hand side of each constraint can be computed from\nc + and c \u2212 in time O(n) instead of O(m), since 1 m \u00c8 m i=1 cij = 1 2m \u00c8 n i=1 (c + i + c \u2212 i ).\nThe following theorem shows that Algorithm 2 computes the coefficient vectors c + and c \u2212 of the most violated constraint, and therefore converges to the optimal solution in the same sense as Algorithm 1.", "publication_ref": ["b13", "b3"], "figure_ref": [], "table_ref": []}, {"heading": "Theorem 5. (Correctness of Algorithm 2)", "text": "For any training sample S = ((x1, y1), . . . , (xn, yn)) and any > 0, if (w * , \u03be * ) is the optimal solution of OP5, then Algorithm 2 returns (w, \u03be) that have a better objective value than (w * , \u03be * ), and for which (w, \u03be + ) is feasible in OP5.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "Proof. Analogous to the proof of Theorem 3,", "text": "c = argmax c\u2208{0,1} m 1 m (i,j)\u2208P cij \u2212 1 m (i,j)\u2208P cij w T (xi \u2212 xj) is reached for cij \u2190 1 (w T xi) \u2212 (w T xj) < 1 0 otherwise .\nThis means that the number of times xi enters with positive and negative sign is\nc + i = |{j : (yi > yj ) \u2227 ((w T xi) \u2212 (w T xj) < 1)}|, c \u2212 i = |{j : (yj > yi) \u2227 ((w T xj) \u2212 (w T xi) < 1)}|.", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "To compute these quantities efficiently, Algorithm 2 first sorts the training examples by decreasing value of w T xi.", "text": "Then, for each rank r in turn, it updates the values of c + and c + for all constraints (i, j) \u2208 P in OP4 with yi = r. By going through the examples in order of w T xi, the algorithm can keep track of\na = |l : (y l = r) \u2227 (w T x l > w T xi)| b = |l : (y l < r) \u2227 (w T x l > w T xi \u2212 1)|\nvia incremental updates. Whenever it encounters an example with yi = r, there are exactly b constraints (i, j) \u2208 P in OP4 with yj < r and ((w T xi) \u2212 (w T xj) < 1). Similarly, whenever it encounters an example with yj < r, there are exactly (nr \u2212 a) constraints (i, j) \u2208 P in OP4 with yi = r and ((w T xi) \u2212 (w T xj) < 1). By exhaustively going through all r, yi = r, and yj < r and adding the respective quantities to c + i and c \u2212 j , the algorithm implicitly considers all constraints in OP4.\nLike Algorithm 1, the iteration terminate only if no constraint in OP5 is violated by more than , and\n1 2 w * T w * + C\u03be * \u2265 1 2 w T w + C\u03be\nsince W is a subset of the constraints in OP4.\nThe following lemma characterizes the time Algorithm 2 takes in each iteration as a function of n and s.   ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "EXPERIMENTS", "text": "While Theorems 4 and 6 characterize the asymptotic scaling of Algorithms 1 and 2, the behavior for small sample sizes may be different. We will empirically analyze the scaling behavior in the following experiments, as well as its sensitivity to C and . Furthermore, we compare the algorithms against existing methods, in particular the decomposition method SVM-Light.\nWe implemented Algorithms 1 and 2 using SVM-Light as the basic quadratic programming software that is called in Line 4 of each algorithm. However, other quadratic programming tools would work just as well, since |W| remained small in all our experiments. We will refer to our implementation of Algorithms 1 and 2 as SVM-Perf in the following. SVM-Perf is available at http://svmlight.joachims.org.\nWe use 5 datasets in our experiments, selected to cover a wide range of properties. We use the Precision/Recall Break-Even Point (PRBEP) (see e.g. [10]) as the measure of performance for the textclassification tasks, and Accuracy for the other problems.\nThe following parameters are used in our experiments, unless noted otherwise. Both SVM-Light and SVM-Perf use = 0.001 (note that their interpretation of is different, though). As the value of C, we use the setting that achieves the best performance on the test set when using the full training set (C = 10, 000 for Reuters CCAT, C = 50, 000 for Reuters C11, C = 20, 000 for Arxiv astro-ph, C = 1, 000, 000 for Covertype 1, and C = 20, 000 for KDD04 Physics). Whenever possible, runtime comparisons are done on the full set of examples, joining training and test data together to get larger datasets. Experiments that compare prediction performance report results for the standard test/training split. All experiments are run on 3.6 Mhz Intel Xeon processors with 2GB main memory under Linux.", "publication_ref": ["b9"], "figure_ref": [], "table_ref": []}, {"heading": "How Fast are the Algorithms Compared to Existing Methods?", "text": "Table 1 compares the CPU-time of SVM-Perf and SVM-Light on the full data for the 5 tasks described above. For the classification SVM, SVM-Perf is substantially faster than SVM-Light on all problems, achieving a speedup of several orders of magnitude on most problems. We will analyze these results in detail in the following sections.\nWe also applied the ordinal regression SVM to these datasets, treating the binary classification problems as ordinal problems with two classes. An alternative view on this setup is that the OR-SVM learns a classification rule that optimizes ROC Area [20,14]. The runtimes are somewhat slower than for classification, but still very tractable. We tried to train SVM-Light in its ordinal regression mode on these problems as well. However, training with SVM-Light is intractable with more than \u2248 4,000 examples.\nA method that was recently proposed for training linear SVMs is the L2-SVM-MFN algorithm [15]. While they do not provide an implementation of their method, they report training times for the two publicly available dataset i to measure training loss. The LSVM can be very fast if the number of features N is small, scaling roughly as O(nN 2 ). We applied the implementation of Mangasarian and Musicant 3 to the Adult and the Web data using the values of C from above. With 31.4 CPU-seconds, the training time of the LSVM is still comparable on Adult. For the higher-dimensional Web task, the LSVM runs into convergence problems. Applying the LSVM to tasks with thousands of features is not tractable, since the algorithm requires storing and inverting an N \u00d7 N matrix. ), which is consistent with previous observations [11]. SVM-Perf has much better scaling, which is (to some surprise) better than linear with roughly O(n 0.8 ) over much of the range.", "publication_ref": ["b19", "b13", "b14", "b10"], "figure_ref": [], "table_ref": ["tab_3"]}, {"heading": "How does Training Time Scale with the Number of Training Examples?", "text": "Figure 2 gives insight into the reason for this scaling behavior. The graph shows the number of iterations of SVM-Perf (and therefore the maximum number of constraints in the working set) in relation to the training set size n. It turns out that the number of iterations is not only upper bounded independent of n as shown in Lemma 2, but that it does not grow with n even in the non-asymptotic region. In fact, for some of the problems the number of iterations decreases with n, which explains the sub-linear scaling in CPU-time. Another explanation lies in the high \"fixed cost\" that is independent of n, which is mostly the cost for solving a quadratic program in each iteration.\nSince Lemma 2 identifies that the number of iterations depends on the value of C, scaling for the optimal value of C might be different if the optimal C increases with training set size. To analyze this, the middle-right plot of Figure 1 shows training time for the optimal value of C. While the curves look more noisy, the scaling still seems to be roughly linear.\nFinally, the right-most plot in Figure 1 shows training time of SVM-Perf for ordinal regression. The scaling is slightly steeper than for classification as expected. The number of iterations is virtually identical to the case of classification shown in Figure 2. Note that training time of SVM-Light would scale roughly O(n 3.4 ) on this problem. ", "publication_ref": [], "figure_ref": ["fig_0", "fig_3", "fig_3", "fig_0"], "table_ref": []}, {"heading": "Is the Prediction Performance of SVM-Perf Different from SVM-Light?", "text": "One potential worry is that the speedup of SVM-Perf over SVM-Light somehow comes at the expense of prediction accuracy, especially due to the choice of = 0.001. However, this is not the case. Figure 3 shows the difference in test set accuracy / PRBEP between the classifiers produced by SVM-Light and SVM-Perf. For better readability, the difference is shown in terms of percentage points. A positive value indicates that SVM-Perf has higher prediction performance, a negative value indicates that SVM-Light performs better. For almost all values of C both methods perform almost identically. In particular, there is not indication that the rules learned by SVM-Perf are less accurate. One case where there is a large difference is the Covertype 1 task for small values of C, since SVM-Light stops before fully converging.", "publication_ref": [], "figure_ref": ["fig_8"], "table_ref": []}, {"heading": "How Small does need to be?", "text": "The previous section showed that = 0.001 is sufficient to get prediction accuracy comparable to SVM-Light. But maybe a lower precision would suffice and reduce training time? Figure 4 shows the difference (in percentage points) in prediction accuracy / PRBEP compared to the performance SVM-Perf reaches for = 0.001. Values above (below) 0 indicate that the accuracy of SVM-Perf for that is better (worse) than the accuracy at = 0.001. The graph shows that for all \u2264 0.01 the prediction performance is within half a percentage point. For larger values of the resulting rules are starting to have more variable and less reliable performance. So, overall, = 0.001 seems accurate enough with some \"safety margin\". However, one might elect to use larger at the expense of prediction accuracy, if training time was substantially faster. We will evaluate this next.", "publication_ref": [], "figure_ref": ["fig_5"], "table_ref": []}, {"heading": "How does Training Time Scale with ?", "text": "Lemma 2 indicates that the number of iterations, and therefore the training time, should decrease as increases. Figure 5 shows number of iterations as a function of . Interestingly, the empirical scaling of roughly O( 1 0.3 ) is much better than O( 12 ) in the bound from Lemma 2. For training time, as shown in Figure 6, the scaling is O( 1 0.4 ). Could the runtime of SVM-Light be improved by increasing the value of as well? While SVM-Light converges faster for larger values of , the difference is much smaller. Even when increasing to 0.5, the speedup is less than a factor of 2 on all five problems.", "publication_ref": [], "figure_ref": ["fig_2", "fig_9"], "table_ref": []}, {"heading": "Is the Solution Computed by SVM-Perf", "text": "Close to Optimal?\nWhile we have already established that training with = 0.001 gives rules of comparable prediction accuracy, it is also interesting to look at how close the objective value of the relaxed solution is to the true optimum for different values of . As Theorems 3 and 5 show, the objective value is lower than the true objective, but by how much? Figure 7 shows ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "How does Training Time Scale with C?", "text": "Finally, let's examine how the number of iterations of SVM-Perf scales with the value of C. The upper bound of Lemma 2 suggest a linear scaling, however, Figure 8 shows that the actual scaling is much better with O( \u221a C) for classification (and similarly for ordinal regression). Figure 9 shows the resulting training times (left) and compares them against those of SVM-Light (right). Except for excessively large values of C, the training time of SVM-Perf scales sublinearly with C. Note that the optimal values of C lie between 10, 000 and 50, 000 for all tasks except Covertype 1. For all values of C, SVM-Perf is faster than SVM-Light.", "publication_ref": [], "figure_ref": ["fig_16", "fig_17"], "table_ref": []}, {"heading": "ACKNOWLEDGMENTS", "text": "This research was supported under NSF Award IIS-0412894 and through a gift from Google. ", "publication_ref": [], "figure_ref": [], "table_ref": []}, {"heading": "CONCLUSIONS", "text": "We presented a simple Cutting-Plane Algorithm for training linear SVMs that is shown to converge in time O(sn) for classification and O(sn log(n)) for ordinal regression. It is based on an alternative formulation of the SVM optimization problem that exhibits a different form of sparsity compared to the conventional formulation. The algorithm is empirically very fast and has an intuitively meaningful stopping criterion.\nThe algorithm opens several areas for research. Since it takes only a small number of sequential iterations through the data, it is promising for parallel implementations using out-of-core memory. Also, the algorithm can in principle be applied to SVMs with Kernels. While a straightforward implementation is slower by a factor of n, matrix approximation techniques and the use of sampling might overcome this problem. ", "publication_ref": [], "figure_ref": [], "table_ref": []}], "references": [{"ref_id": "b0", "title": "Kddcup 2004: Results and analysis", "journal": "ACM SIGKDD Newsletter", "year": "2004", "authors": "R Caruana; T Joachims; L Backstrom"}, {"ref_id": "b1", "title": "LIBSVM: a library for support vector machines", "journal": "", "year": "2001", "authors": "C.-C Chang; C.-J Lin"}, {"ref_id": "b2", "title": "Svmtorch: Support vector machines for large-scale regression problems", "journal": "Journal of Machine Learning Research (JMLR)", "year": "2001", "authors": "R Collobert; S Bengio"}, {"ref_id": "b3", "title": "A support vector method for ranking minimizing the number of swapped pairs", "journal": "Artificial Intelligence Centre", "year": "2006", "authors": "J Dez; J Coz; A Bahamonde"}, {"ref_id": "b4", "title": "Inductive learning algorithms and representations for text categorization", "journal": "", "year": "1998-11", "authors": "S Dumais; J Platt; D Heckerman; M Sahami"}, {"ref_id": "b5", "title": "Interior-point methods for massive support vector machines", "journal": "SIAM Journal of Optimization", "year": "2003", "authors": "M Ferris; T Munson"}, {"ref_id": "b6", "title": "Proximal support vector classifiers", "journal": "", "year": "2001", "authors": "G Fung; O Mangasarian"}, {"ref_id": "b7", "title": "Large margin rank boundaries for ordinal regression", "journal": "MIT Press", "year": "2000", "authors": "R Herbrich; T Graepel; K Obermayer"}, {"ref_id": "b8", "title": "Polynomial-time decomposition algorithms for support vector machines", "journal": "", "year": "2003", "authors": "D Hush; C Scovel"}, {"ref_id": "b9", "title": "Text categorization with support vector machines: Learning with many relevant features", "journal": "Springer", "year": "1998", "authors": "T Joachims"}, {"ref_id": "b10", "title": "Making large-scale SVM learning practical", "journal": "MIT Press", "year": "1999", "authors": "T Joachims"}, {"ref_id": "b11", "title": "Optimizing search engines using clickthrough data", "journal": "", "year": "2002", "authors": "T Joachims"}, {"ref_id": "b12", "title": "Learning to align sequences: A maximum-margin approach. online manuscript", "journal": "", "year": "2003-08", "authors": "T Joachims"}, {"ref_id": "b13", "title": "A support vector method for multivariate performance measures", "journal": "", "year": "2005", "authors": "T Joachims"}, {"ref_id": "b14", "title": "A modified finite newton method for fast solution of large scale linear svms", "journal": "Journal of Machine Learning Research", "year": "2005", "authors": "S Keerthi; D Decoste"}, {"ref_id": "b15", "title": "The cutting-plane method for solving convex programs", "journal": "Journal of the Society for Industrial Applied Mathematics", "year": "1960", "authors": "J Kelley"}, {"ref_id": "b16", "title": "Rcv1: A new benchmark collection for text categorization research", "journal": "Journal of Machine Learning Research", "year": "2004", "authors": "D Lewis; Y Yang; T Rose; F Li"}, {"ref_id": "b17", "title": "Lagrangian support vector machines", "journal": "Journal of Machine Learning Research (JMLR)", "year": "2001", "authors": "O Mangasarian; D Musicant"}, {"ref_id": "b18", "title": "Fast training of support vector machines using sequential minimal optimization", "journal": "MIT-Press", "year": "1999", "authors": "J Platt"}, {"ref_id": "b19", "title": "Svms and area under roc curve", "journal": "", "year": "2004", "authors": "A Rakotomamonjy"}, {"ref_id": "b20", "title": "Learning with Kernels", "journal": "The MIT Press", "year": "2002", "authors": "B Schoelkopf; A J Smola"}, {"ref_id": "b21", "title": "New support vector algorithms", "journal": "Neural Computation", "year": "2000", "authors": "B Sch\u00f6lkopf; A J Smola; R C Williamson; P L Bartlett"}, {"ref_id": "b22", "title": "Core vector machines: Fast svm training on very large data sets", "journal": "Journal of Machine Learning Research", "year": "2005", "authors": "I Tsang; J Kwok; P.-M Cheung"}, {"ref_id": "b23", "title": "Large margin methods for structured and interdependent output variables", "journal": "Journal of Machine Learning Research", "year": "2005-09", "authors": "I Tsochantaridis; T Joachims; T Hofmann; Y Altun"}], "figures": [{"figure_label": "2", "figure_type": "figure", "figure_id": "fig_0", "figure_caption": "OP 2 .2(Structural Classification SVM (primal))", "figure_data": ""}, {"figure_label": "11", "figure_type": "figure", "figure_id": "fig_1", "figure_caption": "1 nTheorem 1 .11\u00c8 n i=1 ci can be seen as the maximum fraction of training errors possible over each subset, and \u03be is an upper bound on the fraction of training errors made by hw. Interestingly, OP1 and OP2 are equivalent in the following sense. Any solution w * of OP2 is also a solution of OP1 (and vice versa), with", "figure_data": ""}, {"figure_label": "5", "figure_type": "figure", "figure_id": "fig_2", "figure_caption": "OP 5 .5(Structural Ord. Regr. SVM (primal))", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_3", "figure_caption": "Algorithm 11for training Classification SVMs via OP2. 1: Input: S = ((x1, y1), . . . , (xn, yn)), C, 2: W \u2190 \u2205 3: repeat 4:", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_4", "figure_caption": "Lemma 1 .1Each iteration of Algorithm 1 takes time O(sn) for a constant working set size |W|. Proof. Each dot-product in Lines 6 and 9 takes time O(s) when using sparse vector algebra, and n dot-products are computed in each line. Instead of solving the primal quadratic program, one can instead solve the dual OP3 in Line 4. Setting up the dual over W in Line 4 is dominated by computing the O(|W| 2 ) elements of the Hessian, which can be done in O(|W| 2 sn) after first computing 1 n \u00c8 n i=1 ciyixi for each constraint in W. Note that N \u2264 sn. The time for solving the dual is then independent of n and s. This leads to an overall time complexity of O(sn) per iteration. Lemma 2. For any > 0, C > 0, and any training sample S = ((x1, y1), . . . , (xn, yn)), Algorithms 1 and 2 terminate after at most max 2 , 8CR 2 2", "figure_data": ""}, {"figure_label": "4", "figure_type": "figure", "figure_id": "fig_5", "figure_caption": "Theorem 4 .4(Time Complexity of Algorithm 1) For any distribution P (X, Y ) that generates feature vectors of bounded L2-norm ||x|| and any fixed value of C > 0 and > 0, Algorithm 1 has time complexity O(sn) for any training sample of size n and sparsity s. Proof. Lemma 2 bounds the number of iterations (and therefore the maximum working set size |W|) to a constant that is independent of n and s. Each iteration has time complexity O(sn) as established by Lemma 1.", "figure_data": ""}, {"figure_label": "21", "figure_type": "figure", "figure_id": "fig_6", "figure_caption": "Algorithm 2 1 221for training Ord. Regr. SVMs via OP5. 1: Input: S = ((x1, y1), . . . , (xn, yn)), C, 2: W \u2190 \u2205 3: repeat 4: (w, \u03be) \u2190 argmin w,\u03be\u22650 w T w + C\u03be s.t. \u2200(c + ,c \u2212 )\u2208W: 1", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_7", "figure_caption": "+ 25: return(w,\u03be) representation of the constraints as follows. While the lefthand side of the linear constraints in OP4 contains a sum over m vectors of differences (xi \u2212 xj), most individual vectors xi are added and subtracted multiple time. With proper coefficients c + i and c \u2212 j , each constraint can be rewritten as a sum of n", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_8", "figure_caption": "Lemma 3 .3Each iteration of Algorithm 2 requires time O(sn + n log(n) + Rn) for a constant working set size |W|. Proof. The proof is analogous to that of Lemma 1. The greatest expense per iteration in terms of n is the sort in Line 5 and the computation of n inner products w T xi. Lines 8-24 take R \u2212 1 passes through the training set. Due to the condensed representation, setting up the quadratic program in Line 4 can again be done in time O(|W| 2 sn) analogous to Lemma 1.Lemma 2 already established an upper bound on the number of iterations of Algorithm 2. Analogous to Theorem 4, the following characterizes its the scaling behavior.", "figure_data": ""}, {"figure_label": "6", "figure_type": "figure", "figure_id": "fig_9", "figure_caption": "Theorem 6 .6(Time Complexity of Algorithm 2) For any distribution P (X, Y ) that generates feature vectors of bounded L2-norm ||x|| and any fixed value of C > 0 and > 0, Algorithm 2 has time complexity O(sn log(n)) for any training sample of size n and sparsity s. Note that conventional methods for training ordinal regression SVMs based on OP4 have much worse scaling behavior. They scale roughly O(sn 3 ) even under the (optimistic) assumption that a problem with m constraints can be solved in O(m) time. Only small training sets with hundreds or at best a few thousand examples are tractable.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_10", "figure_caption": "Figure 1 :1Figure 1: Training time of SVM-Perf (left) and SVM-Light (left-middle) for classification as a function of n for the value of C that gives best test set performance for the maximum training set size. The middle-right plot shows training time of SVM-Perf for the value of C with optimum test set performance for the respective training set size. The right-most plot is the CPU-time of SVM-Perf for ordinal regression.", "figure_data": ""}, {"figure_label": "1", "figure_type": "figure", "figure_id": "fig_11", "figure_caption": "Figure 11Figure 1 shows log-log plots of how CPU-time increases with the size of the training set. The left-most plot shows the scaling of SVM-Perf for classification, while the left-middle plot shows the scaling of SVM-Light. Lines in a log-log plot correspond to polynomial growth O(n d ), where d corresponds to the slope of the line. The middle plot shows that SVM-Light scales roughly O(n 1.7), which is consistent with previous observations[11]. SVM-Perf has much better scaling, which is (to some surprise) better than linear with roughly O(n 0.8 ) over much of the range.Figure2gives insight into the reason for this scaling behavior. The graph shows the number of iterations of SVM-Perf (and therefore the maximum number of constraints in the working set) in relation to the training set size n. It turns out that the number of iterations is not only upper bounded independent of n as shown in Lemma 2, but that", "figure_data": ""}, {"figure_label": "2", "figure_type": "figure", "figure_id": "fig_12", "figure_caption": "3Figure 2 :2Figure 2: Number of iterations of SVM-Perf for classification as a function of sample size n.", "figure_data": ""}, {"figure_label": "3", "figure_type": "figure", "figure_id": "fig_13", "figure_caption": "Figure 3 :3Figure 3: Difference in prediction performance between SVM-Perf and SVM-Light for classification as a function of C.", "figure_data": ""}, {"figure_label": "4567", "figure_type": "figure", "figure_id": "fig_14", "figure_caption": "Figure 4 :Figure 5 :Figure 6 :Figure 7 :4567Figure 4: Difference in Accuracy or PRBEP of SVM-Perf compared to its performance at = 0.001 as a function of .", "figure_data": ""}, {"figure_label": "", "figure_type": "figure", "figure_id": "fig_15", "figure_caption": "the relative difference Obj(SVM-Light) \u2212 Obj(SVM-Perf) Obj(SVM-Light) between the solution of SVM-Perf and a high-precision solution computed by SVM-Light. The left-hand plot of Figure 7 indicates that for = 0.001 the relative error is roughly between 0.1% and 1% over all values of C. The missing points correspond to values where SVM-Light failed to converge. The right-hand plot shows how the relative error decreases with .", "figure_data": ""}, {"figure_label": "8", "figure_type": "figure", "figure_id": "fig_16", "figure_caption": "Figure 8 :8Figure 8: Number of iterations of SVM-Perf as a function of C.", "figure_data": ""}, {"figure_label": "9", "figure_type": "figure", "figure_id": "fig_17", "figure_caption": "Figure 9 :9Figure 9: CPU-time of SVM-Perf (left) and SVM-Light (right) as a function of C.", "figure_data": ""}, {"figure_label": "", "figure_type": "table", "figure_id": "tab_1", "figure_caption": "the case of Algorithm 2. Due to this constant increase of the objective value in each iteration, either algorithm can add at most max \u00d2 2 , 8CR 2 2 \u00d3 constraints before the objective value exceeds C, which is an upper bound on the objective value at the solution of OP2 and OP5.", "figure_data": ""}, {"figure_label": "1", "figure_type": "table", "figure_id": "tab_3", "figure_caption": "", "figure_data": "ClassificationOrdinal RegressionnNs SVM-Perf SVM-Light SVM-Perf SVM-LightReuters CCAT804,414 47,2360.16%149.720,075.5304.1NAReuters C11804,414 47,2360.16%178.95,187.4499.1NAArxiv astro-ph62,369 99,7570.08%16.980.126.1NACovertype 1522,91154 22.22%171.725,514.31,109.1NAKDD04 Physics150,00078 38.42%31.91,040.2132.5NAHeuristic approaches for pushing the limits by removing con-straints offer no performance guarantees [20]. We will seein the following experiments that Algorithm 2 can handleproblems with hundred-thousands of examples with ease."}], "formulas": [{"formula_id": "formula_0", "formula_text": "OP 1. (Classification SVM (primal)) min w,\u03be i \u22650 1 2 w T w + C n n i=1 \u03bei s.t. \u2200i \u2208 {1, ..., n} : yi(w T xi) \u2265 1\u2212\u03bei", "formula_coordinates": [2.0, 63.72, 213.91, 189.75, 53.06]}, {"formula_id": "formula_1", "formula_text": "w T w + C \u03be s.t. \u2200c \u2208 {0, 1} n : 1 n w T n i=1 ciyixi \u2265 1 n n i=1 ci \u2212 \u03be", "formula_coordinates": [2.0, 77.76, 426.3, 195.32, 46.81]}, {"formula_id": "formula_2", "formula_text": "\u03be * = 1 n \u00c8 n i=1 \u03be * i .", "formula_coordinates": [2.0, 176.64, 578.0, 64.75, 31.19]}, {"formula_id": "formula_3", "formula_text": "i \u03bei are related as \u03be = 1 n \u00c8 i \u03bei.", "formula_coordinates": [2.0, 177.36, 627.2, 118.02, 31.31]}, {"formula_id": "formula_4", "formula_text": "\u03be = max c\u2208{0,1} n\u00b41 n n i=1 ci \u2212 1 n n i=1 ciyi(w T xi) \u00b5", "formula_coordinates": [2.0, 76.68, 674.6, 175.44, 47.15]}, {"formula_id": "formula_5", "formula_text": "min C\u03be = n i=1 max c i \u2208{0,1} 1 n ci \u2212 1 n ciyi(w T xi) = n i=1 max 0, 1 n \u2212 1 n yi(w T xi) = min C n n i=1", "formula_coordinates": [2.0, 321.24, 82.38, 220.85, 57.25]}, {"formula_id": "formula_6", "formula_text": "OP 3. (Structural Classification SVM (dual)) max \u03b1\u22650 c\u2208{0,1} n ||c|| 1 n \u03b1c \u2212 1 2 c\u2208{0,1} n c \u2208{0,1} n \u03b1c\u03b1 c x T c x c s.t. c\u2208{0,1} n \u03b1c \u2264 C", "formula_coordinates": [2.0, 319.92, 288.91, 229.78, 64.2]}, {"formula_id": "formula_7", "formula_text": "w T w + C \u03be s.t. \u2200(i,j)\u2208P \u2200cij\u2208{0,1} : 1 m w T m i=1 cij (xi \u2212xj) \u2265 1 m m i=1 cij \u2212\u03be", "formula_coordinates": [3.0, 59.76, 164.46, 231.32, 46.93]}, {"formula_id": "formula_8", "formula_text": "\u03be * = 1 m \u00c8 (i,j)\u2208P \u03be * ij .", "formula_coordinates": [3.0, 176.64, 270.68, 81.43, 31.31]}, {"formula_id": "formula_9", "formula_text": "1 2 w T w + C\u03be s.t. \u2200c \u2208 W: 1 n w T n \u00c8 i=1 ciyixi \u2265 1 n n \u00c8 i=1 ci \u2212\u03be 5: for i=1,...,n do 6: ci \u2190 1 yi(w T xi) < 1 0 otherwise 7: end for 8: W \u2190 W \u222a {c} 9: until 1 n n \u00c8 i=1 ci \u2212 1 n n \u00c8 i=1 ciyi(w T xi)} \u2264 \u03be + 10: return(w,\u03be)", "formula_coordinates": [3.0, 316.8, 96.92, 226.76, 118.18]}, {"formula_id": "formula_10", "formula_text": "c = argmax c\u2208{0,1} n\u00b41 n n i=1 ci \u2212 1 n n i=1 ciyi(w T xi) \u00b5 .", "formula_coordinates": [3.0, 337.56, 256.28, 179.68, 47.15]}, {"formula_id": "formula_11", "formula_text": "\u03be = max c\u2208{0,1} n\u00b41 n n i=1 ci \u2212 1 n n i=1 ciyi(w T xi) \u00b5 .", "formula_coordinates": [3.0, 336.36, 496.88, 182.08, 47.15]}, {"formula_id": "formula_12", "formula_text": "\u03be = 1 n n i=1 max c i \u2208{0,1} {ci \u2212ciyi(w T xi)} = 1 n n i=1 max{0, 1\u2212yi(w T xi)}", "formula_coordinates": [3.0, 316.8, 586.26, 236.09, 27.13]}, {"formula_id": "formula_13", "formula_text": "min C 2 , 2 8Q 2", "formula_coordinates": [4.0, 131.04, 588.33, 58.02, 21.92]}, {"formula_id": "formula_14", "formula_text": "Q = max c\u2208{0,1} n \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac 1 n n i=1 ciyixi \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u2264 1 n n i=1 ci max i ||xi|| \u2264 R", "formula_coordinates": [4.0, 57.12, 620.84, 214.46, 48.12]}, {"formula_id": "formula_15", "formula_text": "Q = max c\u2208{0,1} m \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac 1 m (i,j)\u2208P cij (xi \u2212xj ) \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u00ac \u2264 1 m (i,j)\u2208P cij 2 max i ||xi|| \u2264 R in", "formula_coordinates": [4.0, 53.76, 57.67, 271.1, 664.92]}, {"formula_id": "formula_16", "formula_text": "c = argmax c\u2208{0,1} m 1 m (i,j)\u2208P cij \u2212 1 m (i,j)\u2208P cij w T (xi \u2212 xj)", "formula_coordinates": [4.0, 316.8, 667.27, 221.51, 24.24]}, {"formula_id": "formula_17", "formula_text": "m w T n \u00c8 i=1 (c + i \u2212c \u2212 i )xi \u2265 1 2m n \u00c8 i=1 (c + i +c \u2212 i )\u2212\u03be 5:", "formula_coordinates": [5.0, 57.72, 96.92, 234.68, 46.06]}, {"formula_id": "formula_18", "formula_text": "c + \u2190 0; c \u2212 \u2190 0 7:", "formula_coordinates": [5.0, 57.72, 143.37, 84.77, 20.6]}, {"formula_id": "formula_19", "formula_text": "while (j \u2264 n) \u2227 (w T xi \u2212 w T xj < 1) do 13:", "formula_coordinates": [5.0, 53.76, 206.58, 215.3, 20.15]}, {"formula_id": "formula_20", "formula_text": ": b + +; c \u2212 j \u2190 c \u2212 j + (nr \u2212 a +", "formula_coordinates": [5.0, 61.55, 226.89, 176.74, 12.34]}, {"formula_id": "formula_21", "formula_text": "W \u2190 W \u222a {(c + , c \u2212 )} 24: until 1 2m n \u00c8 i=1 (c + i +c \u2212 i ) \u2212 1 m n \u00c8 i=1 (c + i \u2212c \u2212 i )(w T xi) \u2264 \u03be", "formula_coordinates": [5.0, 53.76, 318.08, 189.32, 35.87]}, {"formula_id": "formula_22", "formula_text": "(c + i \u2212 c \u2212 i )xi \u2265 1 2m n i=1 (c + i + c \u2212 i ) \u2212 \u03be", "formula_coordinates": [5.0, 111.84, 454.62, 143.72, 27.13]}, {"formula_id": "formula_23", "formula_text": "c + and c \u2212 in time O(n) instead of O(m), since 1 m \u00c8 m i=1 cij = 1 2m \u00c8 n i=1 (c + i + c \u2212 i ).", "formula_coordinates": [5.0, 53.76, 532.16, 239.03, 31.31]}, {"formula_id": "formula_24", "formula_text": "c = argmax c\u2208{0,1} m 1 m (i,j)\u2208P cij \u2212 1 m (i,j)\u2208P cij w T (xi \u2212 xj) is reached for cij \u2190 1 (w T xi) \u2212 (w T xj) < 1 0 otherwise .", "formula_coordinates": [5.0, 53.76, 57.67, 447.52, 662.15]}, {"formula_id": "formula_25", "formula_text": "c + i = |{j : (yi > yj ) \u2227 ((w T xi) \u2212 (w T xj) < 1)}|, c \u2212 i = |{j : (yj > yi) \u2227 ((w T xj) \u2212 (w T xi) < 1)}|.", "formula_coordinates": [5.0, 330.48, 124.77, 193.72, 26.98]}, {"formula_id": "formula_26", "formula_text": "a = |l : (y l = r) \u2227 (w T x l > w T xi)| b = |l : (y l < r) \u2227 (w T x l > w T xi \u2212 1)|", "formula_coordinates": [5.0, 368.64, 224.7, 153.27, 25.57]}, {"formula_id": "formula_27", "formula_text": "1 2 w * T w * + C\u03be * \u2265 1 2 w T w + C\u03be", "formula_coordinates": [5.0, 364.92, 376.75, 125.85, 19.78]}], "doi": ""}